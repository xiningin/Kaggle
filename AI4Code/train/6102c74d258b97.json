{"cell_type":{"75db9a7f":"code","ca50d92b":"code","fcf1f1ca":"code","dd57b803":"code","c4d56a63":"code","c6d93fb4":"code","040b84cb":"code","193bbe93":"code","c47b8bc7":"code","f578d55d":"code","5d956758":"code","a65def55":"markdown","3c8ce27e":"markdown","0a520f8c":"markdown","9c8a8836":"markdown","19e964c8":"markdown","2b60c4c3":"markdown"},"source":{"75db9a7f":"!pip install '..\/input\/faster-rcnn-mmdetection\/fcnn_dep_0\/fcnn_dep_0\/addict-2.4.0-py3-none-any.whl'\n!pip install '..\/input\/faster-rcnn-mmdetection\/fcnn_dep_0\/fcnn_dep_0\/asttokens-2.0.5-py2.py3-none-any.whl'\n!pip install '..\/input\/faster-rcnn-mmdetection\/fcnn_dep_0\/fcnn_dep_0\/executing-0.8.2-py2.py3-none-any.whl'\n!pip install '..\/input\/faster-rcnn-mmdetection\/fcnn_dep_0\/fcnn_dep_0\/yapf-0.32.0-py2.py3-none-any.whl'\n!pip install '..\/input\/faster-rcnn-mmdetection\/faster_rcnn_mmdetection\/fcnn_dep\/torch-1.7.0+cu110-cp37-cp37m-linux_x86_64.whl'\n#!pip install '..\/input\/faster-rcnn-mmdetection\/faster_rcnn_mmdetection\/fcnn_dep\/torchvision-0.8.1+cu110-cp37-cp37m-linux_x86_64.whl'\n!pip install '..\/input\/faster-rcnn-mmdetection\/faster_rcnn_mmdetection\/fcnn_dep\/terminaltables-3.1.10-py2.py3-none-any.whl' \n#!pip install '..\/input\/faster-rcnn-mmdetection\/faster_rcnn_mmdetection\/fcnn_dep\/setuptools-46.4.0-py3-none-any.whl' \n#!pip install '..\/input\/faster-rcnn-mmdetection\/faster_rcnn_mmdetection\/fcnn_dep\/numpy-1.16.0-cp37-cp37m-manylinux1_x86_64.whl'\n!pip install '..\/input\/faster-rcnn-mmdetection\/faster_rcnn_mmdetection\/fcnn_dep\/mmcv_full-1.3.9-cp37-cp37m-manylinux1_x86_64.whl'\n!pip install '..\/input\/faster-rcnn-mmdetection\/faster_rcnn_mmdetection\/fcnn_dep\/imagecorruptions-1.1.2-py3-none-any.whl'\n!pip install '..\/input\/faster-rcnn-mmdetection\/faster_rcnn_mmdetection\/fcnn_dep\/icecream-2.0.0-py2.py3-none-any.whl'\n!pip install '..\/input\/faster-rcnn-mmdetection\/faster_rcnn_mmdetection\/fcnn_dep\/ensemble_boxes-1.0.8-py3-none-any.whl'\n!pip install '..\/input\/faster-rcnn-mmdetection\/faster_rcnn_mmdetection\/fcnn_dep\/albumentations-0.5.0-py3-none-any.whl'\n#!pip install '..\/input\/faster-rcnn-mmdetection\/faster_rcnn_mmdetection\/fcnn_dep\/Pillow-6.2.2-cp37-cp37m-manylinux1_x86_64.whl'\n#!pip install '..\/input\/faster-rcnn-mmdetection\/faster_rcnn_mmdetection\/fcnn_dep\/Cython-0.29.15-cp37-cp37m-manylinux1_x86_64.whl'\n!pip install '..\/input\/faster-rcnn-mmdetection\/faster_rcnn_mmdetection\/fcnn_dep\/mmpycocotools-12.0.3'","ca50d92b":"!cp -r ..\/input\/faster-rcnn-mmdetection\/faster_rcnn_mmdetection\/kaggle_mmdetection \/kaggle\/working\/\n%cd \/kaggle\/working\/kaggle_mmdetection\n!pip install -e .\n%cd ..","fcf1f1ca":"import sys, os\nsys.path.append(r'.\/kaggle_mmdetection')\nsys.path.append(r'..\/input\/tensorflow-great-barrier-reef\/greatbarrierreef')\nimport numpy as np\nimport mmdet\nimport mmcv\nfrom mmdet.datasets.builder import build_dataset\nfrom mmdet.models.builder import build_detector\nfrom mmdet.apis.train import train_detector,set_random_seed\nfrom mmdet.apis.inference import inference_detector, init_detector, show_result_pyplot","dd57b803":"\n\n%%writefile \/kaggle\/working\/kaggle_mmdetection\/output\/faster_rcnn\/faster_rcnn_r50_fpn_1x_coco_starfish.py\n\n\nfp16 = dict(loss_scale=512.)  #\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\n# model settings\nmodel = dict(\n    type='FasterRCNN',  #\u68c0\u6d4b\u7b97\u6cd5\n    pretrained=None,  # \u9884\u8bad\u7ec3\u6a21\u578b,None:\u81ea\u5df1\u52a0\u8f7d\uff0c\u4e0d\u9009\u62e9\u5728\u7ebf\u4e0b\u8f7d\n    backbone=dict(\n        type='ResNet',  #\u9aa8\u5e72\u7f51\n        depth=50,       #\u5c42\u6570\uff1a50,101,152\n        num_stages=4,   #resnet\u7684stage\u6570\u91cf\n        out_indices=(0, 1, 2, 3), # \u8f93\u51fa\u7684stage\u7684\u5e8f\u53f7\n        frozen_stages=1, #\u51bb\u7ed3\u7b2c\u4e00\u4e2astage, \u5373\u8be5stage\u4e0d\u66f4\u65b0\u53c2\u6570\n        norm_cfg=dict(type='BN', requires_grad=True),\n        norm_eval=True,\n        style='pytorch',\n        #init_cfg=dict(type='Pretrained', checkpoint='torchvision:\/\/resnet50')),\n    ),\n    neck=dict(\n        type='FPN',  # neck\u7c7b\u578b\n        in_channels=[256, 512, 1024, 2048],  # \u8f93\u5165\u7684\u5404\u4e2astage\u7684\u901a\u9053\u6570\n        out_channels=256,  # \u8f93\u51fa\u7684\u7279\u5f81\u5c42\u7684\u901a\u9053\u6570\n        num_outs=5),     # \u8f93\u51fa\u7684\u7279\u5f81\u5c42\u7684\u6570\u91cf\n    rpn_head=dict(\n        type='RPNHead',    # RPN\u7f51\u7edc\u7c7b\u578b\n        in_channels=256,   # RPN\u7f51\u7edc\u7684\u8f93\u5165\u901a\u9053\u6570\n        feat_channels=256, # \u7279\u5f81\u5c42\u7684\u901a\u9053\u6570\n        anchor_generator=dict(\n            type='AnchorGenerator',\n            scales=[8],    # \u751f\u6210\u7684anchor\u7684baselen\uff0cbaselen = sqrt(w*h)\uff0cw\u548ch\u4e3aanchor\u7684\u5bbd\u548c\u9ad8\n            ratios=[0.5, 1.0, 2.0],  # anchor\u7684\u5bbd\u9ad8\u6bd4\n            strides=[4, 8, 16, 32, 64]),  # \u5728\u6bcf\u4e2a\u7279\u5f81\u5c42\u4e0a\u7684anchor\u7684\u6b65\u957f\uff08\u5bf9\u5e94\u4e8e\u539f\u56fe\uff09\n        bbox_coder=dict(\n            type='DeltaXYWHBBoxCoder',\n            target_means=[.0, .0, .0, .0],  # \u5747\u503c\n            target_stds=[1.0, 1.0, 1.0, 1.0]),  # \u65b9\u5dee\n        loss_cls=dict(\n            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),   \n            # \u662f\u5426\u4f7f\u7528sigmoid\u6765\u8fdb\u884c\u5206\u7c7b\uff0c\u5982\u679cFalse\u5219\u4f7f\u7528softmax\u6765\u5206\u7c7b\n        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n    roi_head=dict(\n        type='StandardRoIHead',  # RoIExtractor\u7c7b\u578b\n        bbox_roi_extractor=dict(\n            type='SingleRoIExtractor',\n            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),  \n            # ROI\u5177\u4f53\u53c2\u6570\uff1aROI\u7c7b\u578b\u4e3aROIalign\uff0c\u8f93\u51fa\u5c3a\u5bf8\u4e3a7\uff0csample\u6570\u4e3a2\n            out_channels=256,    # \u8f93\u51fa\u901a\u9053\u6570\n            featmap_strides=[4, 8, 16, 32]),   # \u7279\u5f81\u56fe\u7684\u6b65\u957f\n        bbox_head=dict(\n            type='Shared2FCBBoxHead',   # \u5168\u8fde\u63a5\u5c42\u7c7b\u578b\n            in_channels=256,             # \u5168\u8fde\u63a5\u5c42\u6570\u91cf\n            fc_out_channels=1024,       # \u8f93\u5165\u901a\u9053\u6570\n            roi_feat_size=7,            # \u8f93\u51fa\u901a\u9053\u6570\n            #num_classes=12,             # \u5206\u7c7b\u5668\u7684\u7c7b\u522b\u6570\u91cf\n            num_classes=1,             # \u5206\u7c7b\u5668\u7684\u7c7b\u522b\u6570\u91cf\n            bbox_coder=dict(\n                type='DeltaXYWHBBoxCoder',\n                target_means=[0., 0., 0., 0.],\n                target_stds=[0.1, 0.1, 0.2, 0.2]),\n            reg_class_agnostic=False,    \n            # \u662f\u5426\u91c7\u7528class_agnostic\u7684\u65b9\u5f0f\u6765\u9884\u6d4b\uff0cclass_agnostic\u8868\u793a\u8f93\u51fabbox\u65f6\u53ea\u8003\u8651\u5176\u662f\u5426\u4e3a\u524d\u666f\uff0c\n            # \u540e\u7eed\u5206\u7c7b\u7684\u65f6\u5019\u518d\u6839\u636e\u8be5bbox\u5728\u7f51\u7edc\u4e2d\u7684\u7c7b\u522b\u5f97\u5206\u6765\u5206\u7c7b\uff0c\u4e5f\u5c31\u662f\u8bf4\u4e00\u4e2a\u6846\u53ef\u4ee5\u5bf9\u5e94\u591a\u4e2a\u7c7b\u522b\n            loss_cls=dict(\n                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n            loss_bbox=dict(type='L1Loss', loss_weight=1.0))))\n\n# model training and testing settings\ntrain_cfg=dict(\n    rpn=dict(\n        assigner=dict(\n            type='MaxIoUAssigner',  # RPN\u7f51\u7edc\u7684\u6b63\u8d1f\u6837\u672c\u5212\u5206\n            pos_iou_thr=0.7,        # \u6b63\u6837\u672c\u7684iou\u9608\u503c\n            neg_iou_thr=0.3,        # \u8d1f\u6837\u672c\u7684iou\u9608\u503c\n            min_pos_iou=0.3,        # \u6b63\u6837\u672c\u7684iou\u6700\u5c0f\u503c\u3002\n            #\u5982\u679cassign\u7ed9ground truth\u7684anchors\u4e2d\u6700\u5927\u7684IOU\u4f4e\u4e8e0.3\uff0c\u5219\u5ffd\u7565\u6240\u6709\u7684anchors\uff0c\u5426\u5219\u4fdd\u7559\u6700\u5927IOU\u7684anchor\n            match_low_quality=True,\n            ignore_iof_thr=-1),     # \u5ffd\u7565bbox\u7684\u9608\u503c\uff0c\u5f53ground truth\u4e2d\u5305\u542b\u9700\u8981\u5ffd\u7565\u7684bbox\u65f6\u4f7f\u7528\uff0c-1\u8868\u793a\u4e0d\u5ffd\u7565\n        sampler=dict(\n            type='RandomSampler',   # \u6b63\u8d1f\u6837\u672c\u63d0\u53d6\u5668\u7c7b\u578b\n            num=256,                # \u9700\u63d0\u53d6\u7684\u6b63\u8d1f\u6837\u672c\u6570\u91cf\n            pos_fraction=0.5,        # \u6b63\u6837\u672c\u6bd4\u4f8b\n            neg_pos_ub=-1,          # \u6700\u5927\u8d1f\u6837\u672c\u6bd4\u4f8b\uff0c\u5927\u4e8e\u8be5\u6bd4\u4f8b\u7684\u8d1f\u6837\u672c\u5ffd\u7565\uff0c-1\u8868\u793a\u4e0d\u5ffd\u7565\n            add_gt_as_proposals=False),  # \u628aground truth\u52a0\u5165proposal\u4f5c\u4e3a\u6b63\u6837\u672c\n        allowed_border=-1,          # \u4e0d\u5141\u8bb8\u5728bbox\u5468\u56f4\u5916\u6269\u4e00\u5b9a\u7684\u50cf\u7d20, 0\u5141\u8bb8\n        pos_weight=-1,              # \u6b63\u6837\u672c\u6743\u91cd\uff0c-1\u8868\u793a\u4e0d\u6539\u53d8\u539f\u59cb\u7684\u6743\u91cd\n        debug=False),               \n    rpn_proposal=dict(\n        nms_pre=2000,               # \u5728nms\u4e4b\u524d\u4fdd\u7559\u7684\u7684\u5f97\u5206\u6700\u9ad8\u7684proposal\u6570\u91cf\n        max_per_img=1000,           # \u5728nms\u4e4b\u540e\u4fdd\u7559\u7684\u7684\u5f97\u5206\u6700\u9ad8\u7684proposal\u6570\u91cf\n        nms=dict(type='nms', iou_threshold=0.7), # nms\u9608\u503c\n        min_bbox_size=0),           # \u6700\u5c0fbbox\u5c3a\u5bf8\n    rcnn=dict(\n        assigner=dict(\n            type='MaxIoUAssigner',    # RCNN\u7f51\u7edc\u6b63\u8d1f\u6837\u672c\u5212\u5206\n            pos_iou_thr=0.3,           # \u6b63\u6837\u672c\u7684iou\u9608\u503c\n            neg_iou_thr=0.3,           # \u8d1f\u6837\u672c\u7684iou\u9608\u503c\n            min_pos_iou=0.3,           \n# \u6b63\u6837\u672c\u7684iou\u6700\u5c0f\u503c\u3002\u5982\u679cassign\u7ed9ground truth\u7684anchors\u4e2d\u6700\u5927\u7684IOU\u4f4e\u4e8e0.3\uff0c\u5219\u5ffd\u7565\u6240\u6709\u7684anchors\uff0c\u5426\u5219\u4fdd\u7559\u6700\u5927IOU\u7684anchor\n            match_low_quality=False,\n            ignore_iof_thr=-1),        # \u5ffd\u7565bbox\u7684\u9608\u503c\uff0c\u5f53ground truth\u4e2d\u5305\u542b\u9700\u8981\u5ffd\u7565\u7684bbox\u65f6\u4f7f\u7528\uff0c-1\u8868\u793a\u4e0d\u5ffd\u7565\n        sampler=dict(\n            type='RandomSampler',      # \u6b63\u8d1f\u6837\u672c\u63d0\u53d6\u5668\u7c7b\u578b\n            num=512,                   # \u9700\u63d0\u53d6\u7684\u6b63\u8d1f\u6837\u672c\u6570\u91cf\n            pos_fraction=0.25,         # \u6b63\u6837\u672c\u6bd4\u4f8b\n            neg_pos_ub=-1,             # \u6700\u5927\u8d1f\u6837\u672c\u6bd4\u4f8b\uff0c\u5927\u4e8e\u8be5\u6bd4\u4f8b\u7684\u8d1f\u6837\u672c\u5ffd\u7565\uff0c-1\u8868\u793a\u4e0d\u5ffd\u7565\n            add_gt_as_proposals=True), # \u628aground truth\u52a0\u5165proposal\u4f5c\u4e3a\u6b63\u6837\u672c\n        pos_weight=-1,                 # \u6b63\u6837\u672c\u6743\u91cd\uff0c-1\u8868\u793a\u4e0d\u6539\u53d8\u539f\u59cb\u7684\u6743\u91cd\n        debug=False))\n\ntest_cfg=dict(\n    rpn=dict(\n        nms_pre=1000,\n        max_per_img=1000,\n        nms=dict(type='nms', iou_threshold=0.7),\n        min_bbox_size=0),\n    rcnn=dict(\n        score_thr=0.05,\n        nms=dict(type='nms', iou_threshold=0.5),\n        max_per_img=100)\n)\n\n# data setting\ndataset_type = 'StarfishDataset'   # \u6570\u636e\u96c6\u7c7b\u578b\n#data_root = '\/cache\/kaggle_dataset\/'  # \u6570\u636e\u96c6\u6839\u76ee\u5f55\ndata_root = '\/kaggle\/working\/kaggle_mmdetection\/kaggle_dataset\/'  # \u6570\u636e\u96c6\u6839\u76ee\u5f55\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True) \n    # \u8f93\u5165\u56fe\u50cf\u521d\u59cb\u5316\uff0c\u51cf\u53bb\u5747\u503cmean\u5e76\u5904\u4ee5\u65b9\u5deestd\uff0cto_rgb\u8868\u793a\u5c06bgr\u8f6c\u4e3argb\ntrain_pipeline = [\ndict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True),\n    #dict(type='MixUp',p=0.5, lambd=0.5),   #\u56fe\u50cf\u6df7\u5408\n    dict(type='Resize', img_scale=[(4096, 600), (4096, 1000)],\n         multiscale_mode='range', keep_ratio=True),\n    #dict(type='Rotate', prob=0.5,level=10, max_rotate_angle=30), #\u56fe\u50cf\u65cb\u8f6c 30\n    dict(type='RandomFlip', direction=['horizontal'], flip_ratio=0.5),\n    #dict(type='BBoxJitter', min=0.95, max=1.05),   #\u6846\u6296\u52a8\n    dict(type='Normalize', **img_norm_cfg),\n    dict(type='Pad', size_divisor=32),\n    #dict(type='Grid', use_w=True, use_h=True),  #\u63a9\u7801\u906e\u6321\n    dict(type='DefaultFormatBundle'),\n    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels']),\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=[(4096, 600),(4096, 800),(4096, 1000)], # \u8f93\u5165\u56fe\u50cf\u5c3a\u5bf8\n        flip=True,  # \u662f\u5426\u7ffb\u8f6c\n        transforms=[\n            dict(type='Resize', keep_ratio=True),   \n            dict(type='RandomFlip'), \n            dict(type='Normalize', **img_norm_cfg),\n            dict(type='Pad', size_divisor=32),  \n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img']),\n        ])\n]\ndata = dict(\n    samples_per_gpu=1,   # \u6bcf\u4e2agpu\u8ba1\u7b97\u7684\u56fe\u50cf\u6570\u91cf\n    workers_per_gpu=1,   # \u6bcf\u4e2agpu\u5206\u914d\u7684\u7ebf\u7a0b\u6570\n    train=dict(\n        type=dataset_type,\n        ann_file=data_root + 'annotations\/train.json',  # \u6570\u636e\u96c6annotation\u8def\u5f84\n        img_prefix=data_root + 'train2017',    # \u6570\u636e\u96c6annotation\u8def\u5f84\n        pipeline=train_pipeline),\n    val=dict(\n        type=dataset_type,\n        #ann_file=data_root + 'annotations\/instances_train2017.json',\n        ann_file=data_root + 'annotations\/valid.json',\n        img_prefix=data_root + 'val2017',\n        pipeline=test_pipeline),\n    test=dict(\n        type=dataset_type,\n        ann_file='cache\/test.json',\n        img_prefix='cache\/test',\n        pipeline=test_pipeline))\n\n# optimizer\noptimizer = dict(type='SGD',lr=0.00125, momentum=0.9, weight_decay=0.0001)\noptimizer_config = dict(grad_clip=None)\n# learning policy\nlr_config = dict(policy='step', warmup='linear', warmup_iters=500,  \nwarmup_ratio=1.0 \/ 3, step=[8, 11])   \n# \u4f18\u5316\u7b56\u7565, \u521d\u59cb\u7684\u5b66\u4e60\u7387\u589e\u52a0\u7684\u7b56\u7565\uff0clinear\u4e3a\u7ebf\u6027\u589e\u52a0\n# \u5728\u521d\u59cb\u7684500\u6b21\u8fed\u4ee3\u4e2d\u5b66\u4e60\u7387\u9010\u6e10\u589e\u52a0\n# \u8d77\u59cb\u7684\u5b66\u4e60\u7387,\u5728\u7b2c8\u548c11\u4e2aepoch\u65f6\u964d\u4f4e\u5b66\u4e60\u7387\nlog_config = dict(interval=100,   # \u6bcf100\u4e2abatch\u8f93\u51fa\u4e00\u6b21\u4fe1\u606f\n    hooks=[\n        dict(type='TextLoggerHook'),   # \u63a7\u5236\u53f0\u8f93\u51fa\u4fe1\u606f\u7684\u98ce\u683c\n    ])\ncustom_hooks = [dict(type='NumClassCheckHook')] \ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\ncheckpoint_config = dict(interval=1) # \u6bcf1\u4e2aepoch\u5b58\u50a8\u4e00\u6b21\u6a21\u578b\n#evaluation = dict(interval=4, metric='bbox') # \u6bcf4\u4e2aepoch\u6d4b\u8bd5\u4e00\u6b21\nevaluation = dict(interval=2, metric='bbox') # \u6bcf2\u4e2aepoch\u6d4b\u8bd5\u4e00\u6b21\n#runner = dict(type='EpochBasedRunner', max_epochs=12)  # \u6700\u5927epoch\u6570\nrunner = dict(type='EpochBasedRunner', max_epochs=30)  # \u6700\u5927epoch\u6570\n# runtime\n#load_from = r'\/cache\/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth'\nload_from = r'\/kaggle\/working\/pre_model\/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth'\n# \u52a0\u8f7d\u6a21\u578b\u7684\u8def\u5f84\uff0cNone\u8868\u793a\u4ece\u9884\u8bad\u7ec3\u6a21\u578b\u52a0\u8f7d\n#work_dir = r'\/cache\/log\/'  # log\u6587\u4ef6\u548c\u6a21\u578b\u6587\u4ef6\u5b58\u50a8\u8def\u5f84\nwork_dir = r'\/kaggle\/working\/kaggle_mmdetection\/output\/faster_rcnn'  # log\u6587\u4ef6\u548c\u6a21\u578b\u6587\u4ef6\u5b58\u50a8\u8def\u5f84\nresume_from = None    # \u6062\u590d\u8bad\u7ec3\u6a21\u578b\u7684\u8def\u5f84\nworkflow = [('train', 1)]   # \u5f53\u524d\u5de5\u4f5c\u533a\u540d\u79f0\n","c4d56a63":"from mmcv import Config\ncfg = Config.fromfile('\/kaggle\/working\/kaggle_mmdetection\/output\/faster_rcnn\/faster_rcnn_r50_fpn_1x_coco_starfish.py')","c6d93fb4":"%%writefile labels.txt \nstarfish","040b84cb":"def format_prediction_string(boxes, scores):\n    pred_strings = []\n    for j in zip(scores, boxes):\n        pred_strings.append(\"{0:.4f} {1} {2} {3} {4}\".format(j[0], j[1][0], j[1][1], j[1][2], j[1][3]))\n\n    return \" \".join(pred_strings)","193bbe93":"import greatbarrierreef\n\nenv = greatbarrierreef.make_env()   # initialize the environment\niter_test = env.iter_test()  ","c47b8bc7":"model = init_detector(cfg, '\/kaggle\/input\/faster-rcnn-mmdetection\/faster_rcnn_mmdetection\/fcnn_pth\/epoch_4.pth')","f578d55d":"#################################### faster rcnn ############################################\n# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\n# model = build_detector(cfg.model, train_cfg=None, test_cfg=cfg.test_cfg)\n# checkpoint = load_checkpoint(model, WEIGHTS_FILE, map_location='cpu')\n\n# model.CLASSES = dataset.CLASSES\n\n# model = MMDataParallel(model, device_ids=[0])\n# outputs = single_gpu_test(model, data_loader, False, None, 0.5)\n\nresults = []\n\nfor (pixel_array, sample_prediction_df) in iter_test:\n    result = inference_detector(model, pixel_array[:, :, ::-1])\n#     show_result_pyplot(model, pixel_array[:, :, ::-1], result)    \n    boxes = result[0][:, :4]\n    scores = result[0][:, 4]\n\n    boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n    boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n\n    \n    sample_prediction_df['annotations'] = format_prediction_string(boxes, scores)\n    \n    env.predict(sample_prediction_df)","5d956758":"%rm -rf kaggle_mmdetection\n%rm labels.txt","a65def55":"# **Import libraries**","3c8ce27e":"# **Model**","0a520f8c":"# **Install libraries**","9c8a8836":"Reference:https:\/\/www.kaggle.com\/mlneo07\/mmdetection-swin-transfomer-frcnn-inference-0-443","19e964c8":"This is an example of mmdetection using Faster RCNN,you can change the configuration file code and the weight path to fit your own model. ","2b60c4c3":"# **Inference**"}}