{"cell_type":{"001bfd98":"code","b915cb33":"code","c2247b05":"code","e45e5a9f":"code","4b38c8da":"code","f3ca91a2":"code","ed9fbd83":"code","be9bc0e1":"code","286449f8":"code","ae350404":"code","0036f22d":"code","bb9bca23":"code","2b1ac3b4":"code","63605b31":"code","c3655fa7":"code","e3ba099f":"code","67753f17":"code","97da2271":"code","eba96f0f":"code","28a60313":"code","70047dad":"code","e12b1ea1":"code","c9019455":"code","0b660d52":"code","23e1cdf1":"code","cb10edad":"code","446e1959":"code","1fdc7f08":"code","378c3a77":"code","672826ba":"code","49ccae48":"code","f9855ea5":"code","9743378b":"code","050d134e":"code","cd37ee8f":"code","f8f9a9ef":"code","5dc23524":"code","38a377b6":"code","285a0391":"code","40e36ca9":"code","5975bfd0":"code","693761fa":"code","a3beedb3":"code","b46a88d0":"code","43f3588f":"code","1e1999b8":"code","550fefc4":"code","5b120eb2":"code","4e7f7147":"code","7d7fb3d5":"code","b78c1042":"code","4260b99d":"code","84c88abf":"code","6ceed9dc":"code","c18c4cbe":"code","794bc16b":"code","712c2b82":"code","7a67fc9c":"code","4d7bbccb":"code","57efa2b5":"code","0e30f163":"code","47cdb0f6":"code","a1d13731":"code","5e1d602d":"code","9753747d":"code","9ebba73a":"code","92df56ec":"code","277e2ff8":"code","22cb2b64":"code","9a213531":"code","a6c7e2aa":"code","4edf372e":"code","ff1fc6f1":"code","4d214a98":"code","18290bb6":"code","99524a6e":"code","7c1a89a3":"code","5961ccd8":"code","11850d81":"code","940315dd":"code","fe0749e4":"code","21a45566":"code","b8d90c7d":"code","5ca39b7b":"code","6c56f801":"code","ac8bf4e3":"code","d191d006":"code","73da9d53":"code","99c41f95":"code","278731e0":"code","4e1d8edc":"code","f6d78a9a":"code","091d91a6":"code","8e171ecf":"code","895ecd93":"code","270f8b66":"code","e893bec7":"code","223f22e5":"code","b3cf867a":"code","e7954ad1":"code","74874da8":"code","197fa1eb":"code","a31f5604":"code","823bc396":"code","72e7cabb":"code","b6b0ef13":"code","631cdb8e":"code","e26c5f65":"code","f2372cae":"code","3a803579":"code","f51b7e82":"code","bd928b9e":"code","5b57b2a5":"code","8f00ac5f":"code","fea7da4e":"code","370d08bd":"code","5f0c90f3":"code","13c13e2b":"code","ffbb3948":"code","b3507ba3":"code","f3350188":"code","c99b8106":"code","e5285266":"code","e2d4e016":"code","039a099c":"code","ccf5b08e":"code","38e964c9":"code","970c6070":"code","87fc055a":"code","6c79be3a":"code","cf88472b":"code","d1f4860d":"code","a0e80de3":"code","15caae6c":"code","835297e5":"code","0998afad":"code","51be5d53":"code","135aaea9":"code","067a35e1":"code","77095b60":"markdown","4d0f24c8":"markdown","ef4edb04":"markdown","0995c5aa":"markdown","b01dd7cc":"markdown","69122400":"markdown","65202cfd":"markdown","2f5f8d9b":"markdown","9b66cb34":"markdown","9e695bcf":"markdown","af550204":"markdown","4fdd5cd2":"markdown","13498276":"markdown","b1638b05":"markdown","0b4ea20b":"markdown","9ade7fdb":"markdown","0e0dad33":"markdown","2b65a71f":"markdown","88e3f0c1":"markdown","be84fd35":"markdown","de6d536a":"markdown","305d96d8":"markdown","acc9b06d":"markdown","5da4df6c":"markdown","8cf3a43a":"markdown","8914331a":"markdown","5c7e9329":"markdown","72c4abe8":"markdown","83103fdf":"markdown","3276b79d":"markdown","dca6970d":"markdown","4d4f8279":"markdown","9216168b":"markdown","21620bdc":"markdown","e32d4be4":"markdown","939e4fd6":"markdown","4875470d":"markdown"},"source":{"001bfd98":"# importing the libraries\n\nimport pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set_style('darkgrid')\n\nimport re\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nimport xgboost as xg\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.metrics import r2_score, mean_squared_error,mean_squared_log_error\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV\nfrom scipy.stats import uniform, randint\n\n# filter the warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_columns', 100)","b915cb33":"# reading the train data and looking top 5 rows\n\ndf = pd.read_csv('\/kaggle\/input\/buyers-time-prediction-challenge\/ParticipantData_BTPC\/Train.csv')\ndf.head()","c2247b05":"# checking for null values in columns\ndf.isnull().sum()","e45e5a9f":"# looking for big picture of the data\ndf.info()","4b38c8da":"df.session_id.nunique()","f3ca91a2":"df.session_number.nunique()","ed9fbd83":"plt.figure(figsize=(15,5))\n\nplt.subplot(1,2,1)\nsns.scatterplot(x=df.session_number, y=df.time_spent)\nplt.title('session number vs time spent', size=14)\n\nplt.subplot(1,2,2)\nsns.scatterplot(x=df[(df.session_number<2000)&(df.time_spent<15000)]['session_number'], \n                y=df[(df.session_number<2000)&(df.time_spent<15000)]['time_spent'])\nplt.title('zooming in first plot where session number < 2000 and time spent < 15000', size=14)\n\nplt.show()","be9bc0e1":"# looking for count\ndf.device_details.value_counts()","286449f8":"# looking the mean time spent from each device\ndf.groupby('device_details')['time_spent'].mean().round(2).sort_values(ascending=False)","ae350404":"# splitting the columns into the two and removing the white spaces\ndf[['device','browser']] = df['device_details'].str.split('-',expand=True)\ndf['device'] = df['device'].str.strip()\ndf['browser'] = df['browser'].str.strip()","0036f22d":"# checking the mean time spent from each device\ndf.groupby('device')['time_spent'].mean().round(2).sort_values(ascending=False)","bb9bca23":"device_index = df.groupby('device')['time_spent'].mean().sort_values(ascending=False).index\ndevice_value = df.groupby('device')['time_spent'].mean().sort_values(ascending=False).values\n\nplt.figure(figsize=(10,5))\nsns.barplot(y=device_index, x=device_value, color='pink')\nplt.xlabel('Time spent (in seconds)', size=12)\nplt.yticks(size=12)\nplt.ylabel('')\nplt.title('Mean time spent by users from their device',size=15)\nplt.show()","2b1ac3b4":"desktop = df[df.device=='Desktop'].groupby('browser')['time_spent'].mean().round(2).sort_values()\nplt.figure(figsize=(10,5))\ndesktop.plot(kind='bar',color='green',alpha=0.4)\nplt.ylabel('Time spent (in seconds)', size=12)\nplt.xticks(size=12,rotation=45)\nplt.xlabel('')\nplt.title(f'Mean time spent from different desktop\\n{desktop}',size=12)\nplt.show()","63605b31":"plt.figure(figsize=(15,5))\n\nipad = df[df.device=='iPad'].groupby('browser')['time_spent'].mean().round(2).sort_values()\niphone = df[df.device=='iPhone'].groupby('browser')['time_spent'].mean().round(2).sort_values()\n\nplt.subplot(1,2,1)\nipad.plot(kind='bar',color='green',alpha=0.4)\nplt.ylabel('Time spent (in seconds)', size=12)\nplt.xticks(size=12,rotation=45)\nplt.xlabel('')\nplt.title(f'Mean time spent from different ipad\\n{ipad}',size=12)\n\nplt.subplot(1,2,2)\niphone.plot(kind='bar',color='green',alpha=0.4)\nplt.ylabel('Time spent (in seconds)', size=12)\nplt.xticks(size=12,rotation=45)\nplt.xlabel('')\nplt.title(f'Mean time spent from different iphone\\n{iphone}',size=12)\n\nplt.show()","c3655fa7":"plt.figure(figsize=(15,5))\n\nandroid_phone = df[df.device=='Android Phone'].groupby('browser')['time_spent'].mean().round(2).sort_values()\nandroid_tablet = df[df.device=='Android Tablet'].groupby('browser')['time_spent'].mean().round(2).sort_values()\n\nplt.subplot(1,2,1)\nandroid_phone.plot(kind='bar',color='green',alpha=0.4)\nplt.ylabel('Time spent (in seconds)', size=12)\nplt.xticks(size=12,rotation=45)\nplt.xlabel('')\nplt.title(f'Mean time spent from different android phone\\n{android_phone}',size=12)\n\nplt.subplot(1,2,2)\nandroid_tablet.plot(kind='bar',color='green',alpha=0.4)\nplt.ylabel('Time spent (in seconds)', size=12)\nplt.xticks(size=12,rotation=45)\nplt.xlabel('')\nplt.title(f'Mean time spent from different android tablet\\n{android_tablet}',size=12)\n\nplt.show()","e3ba099f":"df.groupby(['device','purchased'])['time_spent'].mean().unstack().plot(kind='bar',figsize=(12,5),color=['grey','red'],alpha=0.7)\nplt.xticks(rotation=45,size=12)\nplt.xlabel('')\nplt.ylabel('mean time spent (in seconds)',size=12)\nplt.title('mean time spent by peoples who purchased using different devices', size=15)\nplt.show()","67753f17":"# merging the categories into 4 - phone, tablet, desktop and other\n\ndf['device'] = df['device'].replace(('Android Phone','Android Tablet','Unknown','iPad','iPhone'),\n                                   ('Phone','Tablet','Other','Tablet','Phone'))","97da2271":"# checking the mean time spent from different browser\ndf.groupby('browser')['time_spent'].mean().round(2).sort_values(ascending=False)","eba96f0f":"browser_index = df.groupby('browser')['time_spent'].mean().sort_values(ascending=False).index\nbrowser_value = df.groupby('browser')['time_spent'].mean().sort_values(ascending=False).values\n\nplt.figure(figsize=(10,5))\nsns.barplot(x=browser_index, y=browser_value, color='pink')\nplt.ylabel('Time spent (in seconds)', size=12)\nplt.xlabel('')\nplt.xticks(size=12,rotation=45)\nplt.title('Time spent by users on the website coming from different browser',size=15)\nplt.show()","28a60313":"df.groupby(['browser','purchased'])['time_spent'].mean().unstack().plot(kind='bar',figsize=(12,5),color=['grey','red'],alpha=0.7)\nplt.xticks(rotation=45,size=12)\nplt.xlabel('')\nplt.title('mean time spent by peoples who purchased using different browsers', size=15)\nplt.show()","70047dad":"df['browser'] = df['browser'].replace(('Android','Chrome','Firefox','IE','MobileWeb','Other','Safari','Web','iOS'),\n                                     ('App','Web','Web','Web','Web','Other','Web','Web','App'))","e12b1ea1":"df.shape","c9019455":"# converting to datetime\ndf['date'] = pd.to_datetime(df['date'])","0b660d52":"print('Minimum date in the data:',min(df['date']))\nprint('Maximum date in the data:',max(df['date']))","23e1cdf1":"# extracting the month, day, weekday and week from the date\ndf['month'] = df['date'].dt.month_name()\ndf['day'] = df['date'].dt.day\ndf['weekday'] = df['date'].dt.day_name()\ndf['week'] = (df.day - 1) \/\/ 7 + 1","cb10edad":"# mean time spent in each month\ndf.groupby('month')['time_spent'].mean().round(2)","446e1959":"month_index = df.groupby('month')['time_spent'].mean().sort_values(ascending=False).index\nmonth_value = df.groupby('month')['time_spent'].mean().sort_values(ascending=False).values\n\nplt.figure(figsize=(12,5))\nsns.barplot(x=month_index, y=month_value, color='pink')\nplt.ylabel('Time spent (in seconds)', size=12)\nplt.xlabel('')\nplt.xticks(size=11,rotation=45)\nplt.title('Mean time spent on website each month',size=15)\nplt.show()","1fdc7f08":"# created new columns based upon time spent\ndf['is_september'] = df['month'].apply(lambda x: 1 if x=='September' else 0)\ndf['is_apr_may_july'] = df['month'].apply(lambda x: 1 if (x=='April' or x=='May' or x=='July') else 0)","378c3a77":"# mean time spent on each day of week\ndf.groupby('weekday')['time_spent'].mean().round(2)","672826ba":"week_index = df.groupby('weekday')['time_spent'].mean().sort_values(ascending=False).index\nweek_value = df.groupby('weekday')['time_spent'].mean().sort_values(ascending=False).values\n\nplt.figure(figsize=(10,5))\nsns.barplot(x=week_index, y=week_value, color='pink')\nplt.ylabel('Time spent (in seconds)', size=12)\nplt.xlabel('')\nplt.ylim(500,800)\nplt.title('Mean time spent on website on each day of week',size=15)\nplt.show()","49ccae48":"# created new column\ndf['is_friday'] = df['weekday'].apply(lambda x: 1 if x=='Friday' else 0)\ndf['is_mon_tue_sat'] = df['weekday'].apply(lambda x: 1 if (x=='Monday' or x=='Tuesday' or x=='Saturday') else 0)","f9855ea5":"day_index = df.groupby('day')['time_spent'].mean().index\nday_value = df.groupby('day')['time_spent'].mean().values\n\nplt.figure(figsize=(15,5))\nplt.plot(day_index, day_value, color='purple')\nplt.ylabel('Time spent (in seconds)', size=12)\nplt.xlabel('Number of days', size=12)\nplt.xlim(1,31)\nplt.hlines(y=round(df.time_spent.mean(),2), xmin=1,xmax=31,linestyles='dashed',label='mean time')\nplt.title('Mean time spent on website on each day throughout the year',size=15)\nplt.legend(loc='center',fontsize=12)\nplt.show()","9743378b":"dayp_index = df.groupby('day')['purchased'].count().index\ndayp_value = df.groupby('day')['purchased'].count().values\n\nplt.figure(figsize=(15,5))\nsns.lineplot(x=dayp_index, y=dayp_value, color='purple')\nplt.ylabel('Number of purchases', size=12)\nplt.xlabel('Number of days', size=12)\nplt.xlim(1,31)\nplt.ylim(50,250)\nplt.vlines(5, ymin=50,ymax=250,linestyles='dashed')\nplt.vlines(18, ymin=50,ymax=250,linestyles='dashed')\nplt.title('Number of purchases on website on each day throughout the year',size=15)\nplt.show()","050d134e":"week_index = df.groupby('week')['time_spent'].mean().index\nweek_value = df.groupby('week')['time_spent'].mean().values\n\nplt.figure(figsize=(15,5))\nsns.lineplot(x=week_index, y=week_value, color='purple')\nplt.ylabel('Time spent (in seconds)', size=12)\nplt.xlabel('Week number', size=12)\nplt.xlim(1,5)\nplt.hlines(y=round(df.time_spent.mean(),2),xmin=1,xmax=5,linestyles='dashed',label='mean time')\nplt.title('Mean time spent on website on each week of month',size=15)\nplt.legend(loc='center',fontsize=12)\nplt.show()","cd37ee8f":"df.purchased.value_counts(normalize=True).round(2)","f8f9a9ef":"df.groupby('purchased')['time_spent'].mean().round(2)","5dc23524":"# proportion of rows\ndf.added_in_cart.value_counts(normalize=True).round(2)","38a377b6":"# mean time spent\ndf.groupby('added_in_cart')['time_spent'].mean().round(2)","285a0391":"# proportion of rows\ndf.checked_out.value_counts(normalize=True).round(3)","40e36ca9":"# mean time spent\ndf.groupby('checked_out')['time_spent'].mean().round(2)","5975bfd0":"df.time_spent.describe(percentiles=[0.25,0.5,0.75,0.9,0.95,0.99])","693761fa":"plt.figure(figsize=(10,5))\n\nsns.distplot(df.time_spent)\nplt.xlabel('Time spent(in seconds)', size=12)\nplt.title('Distribution of time spent on website', size=15)\n\nplt.show()","a3beedb3":"plt.figure(figsize=(15,5))\n\nplt.subplot(1,2,1)\nsns.boxplot(np.log(df.time_spent))\nplt.title('Log distribution of time spent', size=15)\n\nplt.subplot(1,2,2)\nsns.boxplot(np.sqrt(df.time_spent))\nplt.title('Squre root distribution of time spent', size=15)\n\nplt.show()","b46a88d0":"# converting the time with log distribution\ndf['time_spent'] = np.log(df['time_spent'])","43f3588f":"# created a function to find out the platform the user used\n\ndef platform(x):\n    if x.find('Product')!=-1:\n        return 'Product'\n    elif x.find('Chrome')!=-1:\n        return 'Chrome'\n    elif x.find('Safari')!=-1:\n        return 'Safari'\n    elif x.find('Mozilla')!=-1:\n        return 'Mozilla'\n    else:\n        return 'Other'","1e1999b8":"# created a function to find out the device used by the user\n\nimport re\ndef device_used(x):\n    if x.lower().find('windows')!=-1:\n        return 'windowns'\n    elif x.lower().find('iphone')!=-1:\n        return 'iphone'\n    elif x.lower().find('ipad')!=-1:\n        return 'ipad'\n    elif x.lower().find('android')!=-1:\n        return 'android'\n    elif x.lower().find('macintosh')!=-1:\n        return 'macintosh'\n    elif x.lower().find('linux')!=-1:\n        return 'linux'\n    elif len(re.findall(\"cfnetwork|cros\", x.lower())) > 0:\n        return 'apple_device'\n    else:\n        return 'unknown'","550fefc4":"# applying the above two functions on client_agent column\n\ndf['platform'] = df['client_agent'].apply(lambda x: platform(str(x)))\ndf['server'] = df['client_agent'].apply(lambda x: device_used(str(x)))","5b120eb2":"df.platform.value_counts()","4e7f7147":"df.server.value_counts()","7d7fb3d5":"df.head()","b78c1042":"# dropping the unnecessary columns\n\ndf.drop(['session_number','client_agent','device_details','platform','server','date','day',\n         'weekday','month','week','checked_out'], axis=1, inplace=True)","4260b99d":"df.head()","84c88abf":"# making the dummy variables for platform and server\n\ndevicepd = pd.get_dummies(df.device,drop_first=True,prefix='device')\nbrowserpd = pd.get_dummies(df.browser,drop_first=True,prefix='browser')\ndf = pd.concat([df,devicepd,browserpd], axis=1)\ndf.drop(['device','browser'], axis=1, inplace=True)","6ceed9dc":"df.head()","c18c4cbe":"df.drop('session_id', axis=1, inplace=True)","794bc16b":"df.shape","712c2b82":"df.columns","7a67fc9c":"df = df[['time_spent', 'purchased', 'added_in_cart', 'is_september',\n       'is_apr_may_july', 'is_friday', 'is_mon_tue_sat',\n       'device_Other', 'device_Phone', 'device_Tablet', 'browser_Other','browser_Web']]","4d7bbccb":"# looking for the correlation matrix\n\nplt.figure(figsize=(15,10))\nsns.heatmap(df.iloc[:,1:].corr().round(2), annot=True, cmap=\"YlGnBu\")\nplt.show()","57efa2b5":"# a high correlation between device_other and browser_other\n# droping one of the variables \n\ndf.drop('device_Other',axis=1,inplace=True)","0e30f163":"df.shape","47cdb0f6":"# splitting the data into train and test\ndf_train, df_test = train_test_split(df, train_size = 0.7, test_size = 0.3, random_state = 444)","a1d13731":"# using min-max scaler to transform time spent as all the other variables are between 0-1\ndf_train[['time_spent']] = scaler.fit_transform(df_train[['time_spent']])\n\ndf_train.head()","5e1d602d":"# splitting the x's and y\ny_train = df_train.pop('time_spent')\nX_train = df_train","9753747d":"# only transform the test time spent column\n\ndf_test[['time_spent']] = scaler.transform(df_test[['time_spent']])\ndf_test.head()","9ebba73a":"# splitting the x's and y\ny_test = df_test.pop('time_spent')\nX_test = df_test","92df56ec":"df1 = pd.read_csv('\/kaggle\/input\/buyers-time-prediction-challenge\/ParticipantData_BTPC\/Test.csv')\ndf1.head()","277e2ff8":"df1['platform'] = df1['client_agent'].apply(lambda x: platform(str(x)))\ndf1['server'] = df1['client_agent'].apply(lambda x: device_used(str(x)))","22cb2b64":"df1.head()","9a213531":"df1[['device','browser']] = df1['device_details'].str.split('-',expand=True)\ndf1['device'] = df1['device'].str.strip()\ndf1['browser'] = df1['browser'].str.strip()\ndf1['device'] = df1['device'].replace(('Android Phone','Android Tablet','Unknown','iPad','iPhone'),\n                                   ('Phone','Tablet','Other','Tablet','Phone'))\ndf1['browser'] = df1['browser'].replace(('Android','Chrome','Firefox','IE','MobileWeb','Other','Safari','Web','iOS'),\n                                     ('App','Web','Web','Web','Web','Other','Web','Web','App'))","a6c7e2aa":"df1['date'] = pd.to_datetime(df1['date'])\ndf1['month'] = df1['date'].dt.month_name()\ndf1['day'] = df1['date'].dt.day\ndf1['weekday'] = df1['date'].dt.day_name()\ndf1['week'] = (df1.day - 1) \/\/ 7 + 1","4edf372e":"df1['is_september'] = df1['month'].apply(lambda x: 1 if x=='September' else 0)\ndf1['is_apr_may_july'] = df1['month'].apply(lambda x: 1 if (x=='April' or x=='May' or x=='July') else 0)\ndf1['is_friday'] = df1['weekday'].apply(lambda x: 1 if x=='Friday' else 0)\ndf1['is_mon_tue_sat'] = df1['weekday'].apply(lambda x: 1 if (x=='Monday' or x=='Tuesday' or x=='Saturday') else 0)","ff1fc6f1":"devicepd1 = pd.get_dummies(df1.device,drop_first=True,prefix='device')\nbrowserpd1 = pd.get_dummies(df1.browser,drop_first=True,prefix='browser')\ndf1 = pd.concat([df1,devicepd1,browserpd1], axis=1)\ndf1.drop(['device','browser'], axis=1, inplace=True)","4d214a98":"df1.head()","18290bb6":"df1.drop(['session_id','session_number','client_agent','device_details','checked_out','date','month','day','week',\n          'weekday','platform','server'], axis=1,inplace=True)","99524a6e":"df1.drop(['device_Other'],axis=1,inplace=True)","7c1a89a3":"df1.head()","5961ccd8":"df1.columns","11850d81":"df.columns","940315dd":"# Running the linear model \nlm1 = sm.OLS(y_train, sm.add_constant(X_train)).fit()\n\n# Looking for summary\nprint(lm1.summary())","fe0749e4":"# checking again the VIFs\n\n# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","21a45566":"# deleting the variable 'is_apr_may_july' as it is insignificant \nX_train = X_train.drop(['is_apr_may_july'],axis=1)","b8d90c7d":"# Running the linear model \nlm2 = sm.OLS(y_train, sm.add_constant(X_train)).fit()\n\n# Looking for summary\nprint(lm2.summary())","5ca39b7b":"# checking again the VIFs\n\n# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","6c56f801":"# deleting the variable 'device_Tablet' as it is insignificant \nX_train = X_train.drop(['device_Tablet'],axis=1)","ac8bf4e3":"# Running the linear model \nlm3 = sm.OLS(y_train,sm.add_constant(X_train)).fit()\n\n# Looking for summary\nprint(lm3.summary())","d191d006":"# checking again the VIFs\n\n# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","73da9d53":"# predicting on train data\ny_train_time = lm3.predict(sm.add_constant(X_train))","99c41f95":"# Plot the histogram of the error terms\n\nfig = plt.figure()\nsns.distplot((y_train - y_train_time), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20)               \nplt.xlabel('Errors', fontsize = 18)                         \nplt.show()","278731e0":"mse = mean_squared_error(y_train, y_train_time)\nmsle = mean_squared_log_error(y_train,y_train_time)\nr_squared = r2_score(y_train,y_train_time)\n\nprint('RMSE:',np.sqrt(mse))\nprint('RMSLE:',np.sqrt(msle))\nprint('R-squared value:',r_squared)","4e1d8edc":"print('The final columns are:')\nfcol = list(X_train.columns)\nprint(fcol)","f6d78a9a":"# Including only those variables which are selected by third model in training set \n\nX_test = X_test[fcol]","091d91a6":"# Making prediction using the third model on test data\ny_test_time = lm3.predict(sm.add_constant(X_test))","8e171ecf":"mse = mean_squared_error(y_test, y_test_time)\nmsle = mean_squared_log_error(y_test,y_test_time)\nr_squared = r2_score(y_train,y_train_time)\n\nprint('RMSE:',np.sqrt(mse))\nprint('RMSLE:',np.sqrt(msle))\nprint('R-squared value:',r_squared)","895ecd93":"pred_test_lr = lm3.predict(sm.add_constant(df1[fcol])) # using only selected columns","270f8b66":"y_final_lr = np.array(pred_test_lr).reshape(-1,1)","e893bec7":"# using inverse transform and exponential function to get back the actual seconds predicted\ny_final_lr = scaler.inverse_transform(y_final_lr)\ny_final_lr = np.exp(y_final_lr)\ny_final_lr","223f22e5":"# storing it into the dataframe\n\ndf_lr = pd.DataFrame(y_final_lr)\ndf_lr.rename(columns={0:'time_spent_lr'},inplace=True)\ndf_lr = df_lr.round(4)\ndf_lr.head()","b3cf867a":"# Instantiation \nxgb_r = xg.XGBRegressor(objective ='reg:linear', n_estimators = 10, seed = 123) \n  \n# Fitting the model \nxgb_r.fit(X_train, y_train) \n  \n# Predict the model \npred = xgb_r.predict(X_test)\n\nmse = mean_squared_error(y_test, pred)\nr_squared = r2_score(y_test, pred)\n\nprint('RMSE:',np.sqrt(mse))\nprint('R-squared value:',r_squared)","e7954ad1":"# running the cross validation\n\ndef display_scores(scores):\n    print(\"Scores: {0}\\nMean: {1:.3f}\\nStd: {2:.3f}\".format(scores, np.mean(scores), np.std(scores)))\n\nxg_model = xg.XGBRegressor(objective=\"reg:linear\", random_state=42)\n\nscores = cross_val_score(xg_model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=5)\n\ndisplay_scores(np.sqrt(-scores))","74874da8":"def report_best_scores(results, n_top=3):\n    for i in range(1, n_top + 1):\n        candidates = np.flatnonzero(results['rank_test_score'] == i)\n        for candidate in candidates:\n            print(\"Model with rank: {0}\".format(i))\n            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n                  results['mean_test_score'][candidate],\n                  results['std_test_score'][candidate]))\n            print(\"Parameters: {0}\".format(results['params'][candidate]))\n            print(\"\")","197fa1eb":"# use randomizedsearchcv to find the parameters\n\nxgb_model = xg.XGBRegressor()\n\nparams = {\n    \"colsample_bytree\": uniform(0.7, 0.3),\n    \"gamma\": uniform(0, 0.5),\n    \"learning_rate\": uniform(0.03, 0.3), # default 0.1 \n    \"max_depth\": randint(2, 6), # default 3\n    \"n_estimators\": randint(100, 150), # default 100\n    \"subsample\": uniform(0.6, 0.4)\n}\n\nsearch = RandomizedSearchCV(xgb_model, param_distributions=params, random_state=42, n_iter=200, cv=3, verbose=1, \n                            n_jobs=1, return_train_score=True)\n\nsearch.fit(X_train, y_train)\n\nreport_best_scores(search.cv_results_, 1)","a31f5604":"# Instantiation \nxgb_model1 = xg.XGBRegressor(objective ='reg:linear', n_estimators = 144,seed = 123) \n  \n# Fitting the model \nxgb_model1.fit(X_train, y_train) \n  \n# Predict the model \npred = xgb_model1.predict(X_train)\n\nmse = mean_squared_error(y_train, pred)\nmsle = mean_squared_log_error(y_train, pred)\nr_squared = r2_score(y_train, pred)\n\nprint('RMSE:',np.sqrt(mse))\nprint('RMSLE:',np.sqrt(msle))\nprint('R-squared value:',r_squared)","823bc396":"xgb_model1.feature_importances_","72e7cabb":"# Plot the histogram of the error terms\n\nfig = plt.figure()\nsns.distplot((y_train - pred), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20) \nplt.xlabel('Errors', fontsize = 18)                         \nplt.show()","b6b0ef13":"# Making prediction on test data\npred_test = xgb_model1.predict(X_test)","631cdb8e":"mse = mean_squared_error(y_test, pred_test)\nmsle = mean_squared_log_error(y_test, pred_test)\nr_squared = r2_score(y_test, pred_test)\n\nprint('RMSE:',np.sqrt(mse))\nprint('RMSLE:',np.sqrt(msle))\nprint('R-squared value:',r_squared)","e26c5f65":"pred_test_xgb = xgb_model1.predict(df1[fcol])","f2372cae":"y_final_xgb = np.array(pred_test_xgb).reshape(-1,1)","3a803579":"# using inverse transform and exponential function to get back the actual seconds predicted\ny_final_xgb = scaler.inverse_transform(y_final_xgb)\ny_final_xgb = np.exp(y_final_xgb)\ny_final_xgb","f51b7e82":"# storing in the dataframe\ndf_xgb = pd.DataFrame(y_final_xgb)\ndf_xgb.rename(columns={0:'time_spent_xgb'},inplace=True)\ndf_xgb = df_xgb.round(4)\ndf_xgb.head()","bd928b9e":"df_xgb.shape","5b57b2a5":"dtr = DecisionTreeRegressor()\ndtr.fit(X_train, y_train)","8f00ac5f":"# depth of the decision tree\nprint('Depth of the Decision Tree: ', dtr.get_depth())\n\n#checking the training score\nprint('Accuracy on training: ',dtr.score(X_train, y_train))","fea7da4e":"# Implementing grid search\n\nparameter_grid = {\n    'max_depth' : [24,25,26,27,28,29,30],\n    'max_features': [0.3, 0.5, 0.7]\n    }\n\ngridsearch = GridSearchCV(estimator=dtr, param_grid=parameter_grid, scoring='neg_mean_squared_error', cv=5)\n\ngridsearch.fit(X_train, y_train)\n\nprint(gridsearch.best_params_)","370d08bd":"# Implementing random search\n\nparameter_grid = {\n    'max_depth' : [24,25,26,27,28,29,30],\n    'max_features': [0.3, 0.5, 0.7,0.9]\n    }\n\nrandomsearch = RandomizedSearchCV(estimator=dtr, param_distributions=parameter_grid, n_iter= 10, cv=5)\nrandomsearch.fit(X_train, y_train)\n\nprint(randomsearch.best_params_)","5f0c90f3":"# final model\ndtr1 = DecisionTreeRegressor(max_depth=27, max_features=0.5 ,random_state=10)\n\n# fitting the model\ndtr1.fit(X_train, y_train)\n\n# Training score\nprint(dtr1.score(X_train, y_train).round(4))","13c13e2b":"from sklearn import tree\n\nfig = plt.figure(figsize=(15,10))\n_ = tree.plot_tree(dtr1, feature_names=X_train.columns, max_depth=2, filled=True)","ffbb3948":"dtr1.feature_importances_","b3507ba3":"# Predict the model \npred_dt = dtr1.predict(X_train)\n\nmse = mean_squared_error(y_train, pred_dt)\nmsle = mean_squared_log_error(y_train, pred_dt)\nr_squared = r2_score(y_train, pred_dt)\n\nprint('RMSE:',np.sqrt(mse))\nprint('RMSLE:',np.sqrt(msle))\nprint('R-squared value:',r_squared)","f3350188":"# Plot the histogram of the error terms\n\nfig = plt.figure()\nsns.distplot((y_train - pred_dt), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20) \nplt.xlabel('Errors', fontsize = 18)\nplt.show()","c99b8106":"# Making prediction on test data\npred_test_dt = dtr1.predict(X_test)","e5285266":"mse = mean_squared_error(y_test, pred_test_dt)\nmsle = mean_squared_log_error(y_test, pred_test_dt)\nr_squared = r2_score(y_test, pred_test_dt)\n\nprint('RMSE:',np.sqrt(mse))\nprint('RMSLE:',np.sqrt(msle))\nprint('R-squared value:',r_squared)","e2d4e016":"pred_test_dt = dtr1.predict(df1[fcol])","039a099c":"y_final_dt = np.array(pred_test_dt).reshape(-1,1)\n\n# using inverse transform and exponential function to get back the actual seconds predicted\ny_final_dt = scaler.inverse_transform(y_final_dt)\ny_final_dt = np.exp(y_final_dt)\ny_final_dt","ccf5b08e":"df_dt = pd.DataFrame(y_final_dt)\ndf_dt.rename(columns={0:'time_spent_dt'},inplace=True)\ndf_dt = df_dt.round(4)\ndf_dt.head()","38e964c9":"rfr = RandomForestRegressor()\nrfr.fit(X_train, y_train)","970c6070":"#checking the training score\nprint('Accuracy on training: ',rfr.score(X_train, y_train))","87fc055a":"# Implementing grid search\n\nparameter_grid = {\n    'max_depth' : [24,25,26,27,28,29,30],\n    'max_features': [0.3, 0.5, 0.7]\n    }\n\ngridsearch = GridSearchCV(estimator=rfr, param_grid=parameter_grid, scoring='neg_mean_squared_error', cv=5)\n\ngridsearch.fit(X_train, y_train)\n\nprint(gridsearch.best_params_)","6c79be3a":"# Implementing random search\n\nparameter_grid = {\n    'max_depth' : [24,25,26,27,28,29,30],\n    'max_features': [0.3, 0.5, 0.7,0.9]\n    }\n\nrandomsearch = RandomizedSearchCV(estimator=rfr, param_distributions=parameter_grid, n_iter= 10, cv=5)\nrandomsearch.fit(X_train, y_train)\n\nprint(randomsearch.best_params_)","cf88472b":"rfr1 = RandomForestRegressor(max_depth=26, max_features=0.7)\nrfr1.fit(X_train, y_train)\n\n#checking the training score\nprint('Accuracy on training: ',rfr1.score(X_train, y_train))","d1f4860d":"rfr1.feature_importances_","a0e80de3":"# Predict the model \npred_rf = rfr1.predict(X_train)\n\nmse = mean_squared_error(y_train, pred_rf)\nmsle = mean_squared_log_error(y_train, pred_rf)\nr_squared = r2_score(y_train, pred_rf)\n\nprint('RMSE:',np.sqrt(mse))\nprint('RMSLE:',np.sqrt(msle))\nprint('R-squared value:',r_squared)","15caae6c":"# Plot the histogram of the error terms\n\nfig = plt.figure()\nsns.distplot((y_train - pred_rf), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20)              \nplt.xlabel('Errors', fontsize = 18)                     \nplt.show()","835297e5":"# Making prediction on test data\npred_test_rf = rfr1.predict(X_test)","0998afad":"mse = mean_squared_error(y_test, pred_test_rf)\nmsle = mean_squared_log_error(y_test, pred_test_rf)\nr_squared = r2_score(y_test, pred_test_rf)\n\nprint('RMSE:',np.sqrt(mse))\nprint('RMSLE:',np.sqrt(msle))\nprint('R-squared value:',r_squared)","51be5d53":"pred_test_rf = rfr1.predict(df1[fcol])","135aaea9":"y_final_rf = np.array(pred_test_rf).reshape(-1,1)\n\n# using inverse transform and exponential function to get back the actual seconds predicted\ny_final_rf = scaler.inverse_transform(y_final_rf)\ny_final_rf = np.exp(y_final_rf)\ny_final_rf","067a35e1":"df_rf = pd.DataFrame(y_final_rf)\ndf_rf.rename(columns={0:'time_spent_rf'},inplace=True)\ndf_rf = df_rf.round(4)\ndf_rf.head()","77095b60":"##### Prediction on test data","4d0f24c8":"#### weekday","ef4edb04":"---\n#### purchased\nBinary value for any purchase done","0995c5aa":"> Note:<br>\nThis graph shows that the peoples who purchased spent three times more time from the one who dosn't purchase.","b01dd7cc":"> Note:<br>\nIt is been observed that people using **desktop** and **ipad** spent most time on the website followed by android phone and iphone. ","69122400":"**Thank you!**","65202cfd":"#### day","2f5f8d9b":"> Note:<br>\nFrom the above line plot it is seen that from 5th to 18th the time spent on the website is more than mean time and any number of conclusion can be made from this like offer in that period or arrival of new stock in the webiste or purchasing power in that peroid is high, etc.","9b66cb34":"> Note:<br>\nWithin the desktop we see that people use four type of browser among which **firefox** has the highest mean time spent. **So it is been seen that people who login from desktop and uses firefox browser are the one who spent most time.**","9e695bcf":"### II. XG Boost","af550204":"#### device\nCreated from device_details column","4fdd5cd2":"##### Prediction on test data","13498276":"> Note:\n- Within the ipad people who uses iOS i.e. app of the website spent most of the time.\n- Within iphone also people using the application spent the most time.\n- But the point note to be that ipad people spent more time on website from app than the iphone people who uses app. The difference is of 190 seconds i.e. more than 3 minutes.","b1638b05":"### III. Decision Tree Regressor","0b4ea20b":"> Note:\n- Within the android phone people who uses android i.e. app of the website downloaded from app store spent most of the time.\n- Within android tablet also people using the application spent the most time.\n- The mobileweb was second highest in phone and lowest in tablet (graphically) but if we observed then we see that time spent from both the device using mobileweb was not very far from each other. The difference between them is 33 seconds.","9ade7fdb":"> Note:<br>\nIt is been observed that there is no such correlation between the two i.e. session number is not a significant variables in predicting the time. The points are distributed randomly and make no sense. **So we will drop this variable.** ","0e0dad33":"##### Prediction on test set","2b65a71f":"---\n#### checked out\nBinary value for checking out successfully","88e3f0c1":"---\n#### time spent\nTotal time spent in seconds (Target Column)","be84fd35":"---\n#### client agent\nClient-side software details","de6d536a":"---\n#### added in cart\nBinary value for cart activity","305d96d8":"#### month","acc9b06d":"### Problem\nBuyers spend a significant amount of time surfing an e-commerce store, since the pandemic the e-commerce has seen a boom in the number of users across the domains. In the meantime, the store owners are also planning to attract customers using various algorithms to leverage customer behavior patterns.\n\nTracking customer activity is also a great way of understanding customer behavior and figuring out what can actually be done to serve them better. Machine learning and AI has already played a significant role in designing various recommendation engines to lure customers by predicting their buying patterns.\n\n`In this competition provided the visitor's session data, we are challenging the Machinehack community to come up with a regression algorithm to predict the time a buyer will spend on the platform.`\n\n#### What is the Metric In this competition?\nThe submission will be evaluated using the RMSLE metric. \n\nOne can use np.sqrt(mean_squared_log_error(actual, predicted)) to calculate the same.","5da4df6c":"### IV. Random Forest","8cf3a43a":"## In this notebook\n1. Basic EDA with comments and cleaning of data with feature removing and feature extraction.\n2. Use four techniques namely - `linear regression`, `xg boost`, `decision tree` and `random forest` to predict the time and also display the RMSLE of train data.\n3. To check your RMSLE of test data, click [here](https:\/\/www.machinehack.com\/hackathons\/buyers_time_prediction_challenge\/submission)","8914331a":"---\n#### session id\nUnique identifier for every row","5c7e9329":"---\n#### device details\nClient-side software details","72c4abe8":"#### week of months","83103fdf":"### I. Linear Regression","3276b79d":"##### Prediction on test data","dca6970d":"> Note:<br>\nAs all the variables comes significant and VIF < 3. So we will stop here and these are our final columns.","4d4f8279":"---\n#### session number\nSession type identifier","9216168b":"> Note:\n- most of the independent variables are type object and few are binary. It means when we do cleaning and transformation of type object variables they also converted into binary variables.\n- date is not in right data type. currently it is an object and should be changed to datetime.\n- client_agent has 160 missing values.","21620bdc":"### Test Data\n- The data on which the actual prediction has to be done and whose result is to submitted for final evaluation.\n- `All the changes that has been done on train data should also be done on test data`. ","e32d4be4":"### Train data","939e4fd6":"#### browser\nCreated from device_details column","4875470d":"---\n#### date\nDatestamp of the session"}}