{"cell_type":{"f252b968":"code","87027448":"code","932e19ba":"code","d78b60ea":"code","f0b45574":"code","9f08d5d9":"code","f909e281":"code","262f05ae":"code","7ac5bbf3":"code","0ed5201a":"code","687329f7":"code","2f026685":"code","199de9f8":"code","20c46823":"markdown"},"source":{"f252b968":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"..\/input\/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","87027448":"import pandas as pd\nimport numpy as np\nimport glob\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split, KFold\nfrom tqdm import tqdm\n\nimport gc","932e19ba":"platform = 'Kaggle'\n\nif platform == 'Kaggle':\n    config = {'input_trade_path': \"..\/input\/optiver-realized-volatility-prediction\/trade_\",\n              'input_book_path': \"..\/input\/optiver-realized-volatility-prediction\/book_\",\n              'train_path': '..\/input\/optiver-realized-volatility-prediction\/train.csv',\n              'test_path' : '..\/input\/optiver-realized-volatility-prediction\/test.csv'}\n    \nelse:\n    config = {'input_trade_path': \"..\/trade_\",\n              'input_book_path': \"..\/book_\",\n              'train_path': '..\/train.csv',\n              'test_path' : '..\/test.csv'}","d78b60ea":"train_df = pd.read_csv(config['train_path'])\ntest_df = pd.read_csv(config['test_path'])","f0b45574":"def read_trade_and_book_data(stock_id, inp_type, data_type):\n    \n    trade_file = glob.glob(config[inp_type]+f'{data_type}.parquet\/stock_id={stock_id}\/*')[0]\n    trade = pd.read_parquet(trade_file)\n    return trade","9f08d5d9":"def get_consolidated_final_trade_book_df(df, data_type):\n    unique_id = df['stock_id'].unique().tolist()\n    \n    trade_final_df = pd.DataFrame()\n    book_final_df = pd.DataFrame()\n    for stock_id in tqdm(unique_id):\n        # Get book data\n        temp_book_stock_df = read_trade_and_book_data(stock_id=stock_id, \n                                                  inp_type='input_book_path', \n                                                  data_type=data_type)\n        temp_book_stock_df['stock_id'] = stock_id\n        book_final_df = pd.concat([book_final_df, temp_book_stock_df])\n        \n        # Get trade data\n        temp_trade_stock_df = read_trade_and_book_data(stock_id=stock_id, \n                                                   inp_type='input_trade_path', \n                                                   data_type=data_type)\n        temp_trade_stock_df['stock_id'] = stock_id\n        trade_final_df = pd.concat([trade_final_df, temp_trade_stock_df])\n        \n        gc.collect()\n        \n    book_final_df = book_final_df.reset_index(drop=True)\n    trade_final_df = trade_final_df.reset_index(drop=True)\n\n    return book_final_df, trade_final_df","f909e281":"gc.collect()\ntrain_book_final_df, train_trade_final_df = get_consolidated_final_trade_book_df(df=train_df, data_type='train')\ntest_book_final_df, test_trade_final_df = get_consolidated_final_trade_book_df(df=test_df, data_type='test')\n\ntrain_book_final_df.shape, train_trade_final_df.shape, test_book_final_df.shape, test_trade_final_df.shape","262f05ae":"def get_trade_agg_info(df):\n    agg_df = df.groupby(['stock_id', 'time_id']).agg(mean_sec_in_bucket_trade = ('seconds_in_bucket', 'mean'), \n                                                     mean_price = ('price', 'mean'),\n                                                     mean_size = ('size', 'mean'),\n                                                     mean_order = ('order_count', 'mean'),\n                                                     max_sec_in_bucket_trade = ('seconds_in_bucket', 'max'), \n                                                     max_price = ('price', 'max'),\n                                                     max_size = ('size', 'max'),\n                                                     max_order = ('order_count', 'max'),\n                                                     min_sec_in_bucket_trade = ('seconds_in_bucket', 'min'), \n                                                     min_price = ('price', 'min'),\n                                                     min_size = ('size', 'min'),\n                                                     min_order = ('order_count', 'min'),\n                                                     median_sec_in_bucket_trade = ('seconds_in_bucket', 'median'), \n                                                     median_price = ('price', 'median'),\n                                                     median_size = ('size', 'median'),\n                                                     median_order = ('order_count', 'median')\n                                                    ).reset_index()\n    \n    return agg_df\n\ndef get_book_agg_info(df):\n    agg_df = df.groupby(['stock_id', 'time_id']).agg(mean_sec_in_bucket_book = ('seconds_in_bucket', 'mean'),\n                                                     mean_bid_price1 = ('bid_price1', 'mean'),\n                                                     mean_ask_price1 = ('ask_price1', 'mean'),\n                                                     mean_bid_price2 = ('bid_price2',  'mean'),\n                                                     mean_ask_price2 = ('ask_price2',  'mean'),\n                                                     mean_bid_size1 = ('bid_size1',  'mean'),\n                                                     mean_ask_size1 = ('ask_size1',  'mean'),\n                                                     mean_bid_size2 = ('bid_size2', 'mean'),\n                                                     mean_ask_size2 = ('ask_size2', 'mean'),\n                                                     max_sec_in_bucket_book = ('seconds_in_bucket', 'max'),\n                                                     max_bid_price1 = ('bid_price1', 'max'),\n                                                     max_ask_price1 = ('ask_price1', 'max'),\n                                                     max_bid_price2 = ('bid_price2',  'max'),\n                                                     max_ask_price2 = ('ask_price2',  'max'),\n                                                     max_bid_size1 = ('bid_size1',  'max'),\n                                                     max_ask_size1 = ('ask_size1',  'max'),\n                                                     max_bid_size2 = ('bid_size2', 'max'),\n                                                     max_ask_size2 = ('ask_size2', 'max'),\n                                                     min_sec_in_bucket_book = ('seconds_in_bucket', 'min'),\n                                                     min_bid_price1 = ('bid_price1', 'min'),\n                                                     min_ask_price1 = ('ask_price1', 'min'),\n                                                     min_bid_price2 = ('bid_price2',  'min'),\n                                                     min_ask_price2 = ('ask_price2',  'min'),\n                                                     min_bid_size1 = ('bid_size1',  'min'),\n                                                     min_ask_size1 = ('ask_size1',  'min'),\n                                                     min_bid_size2 = ('bid_size2', 'min'),\n                                                     min_ask_size2 = ('ask_size2', 'min'),\n                                                     median_sec_in_bucket_book = ('seconds_in_bucket', 'median'),\n                                                     median_bid_price1 = ('bid_price1', 'median'),\n                                                     median_ask_price1 = ('ask_price1', 'median'),\n                                                     median_bid_price2 = ('bid_price2',  'median'),\n                                                     median_ask_price2 = ('ask_price2',  'median'),\n                                                     median_bid_size1 = ('bid_size1',  'median'),\n                                                     median_ask_size1 = ('ask_size1',  'median'),\n                                                     median_bid_size2 = ('bid_size2', 'median'),\n                                                     median_ask_size2 = ('ask_size2', 'median')\n                                                    ).reset_index()\n    \n    return agg_df","7ac5bbf3":"train_trade_agg = get_trade_agg_info(df=train_trade_final_df)\ntest_trade_agg = get_trade_agg_info(df=test_trade_final_df)\n\ntrain_trade_agg.shape, test_trade_agg.shape","0ed5201a":"train_book_agg = get_book_agg_info(df=train_book_final_df)\ntest_book_agg = get_book_agg_info(df=test_book_final_df)\n\ntrain_book_agg.shape, test_book_agg.shape","687329f7":"train_agg = pd.merge(train_book_agg, train_trade_agg, \n                     on=['stock_id', 'time_id'], \n                     how='left')\n\ntest_agg = pd.merge(test_book_agg, test_trade_agg, \n                    on=['stock_id', 'time_id'], \n                    how='left')\n\ntrain_agg.shape, test_agg.shape","2f026685":"# Merge to get the labels\ntrain_final_df = pd.merge(train_df, train_agg, on=['stock_id', 'time_id'], how='left')\n\n# Merge to get the row-id for submission\ntest_final_df = pd.merge(test_df, test_agg, on=['stock_id', 'time_id'], how='left')\n\nprint(train_final_df.shape, test_final_df.shape)","199de9f8":"train_final_df.to_pickle('..\/train_agg_final_df.pickle')\ntest_final_df.to_pickle('..\/test_agg_final_df.pickle')","20c46823":"#### About this Notebook\n\nThis is a starter preprocessing notebook to create stats features to build the model. However if you run into resource exhausted error when preprocessing as I ran into, since there are few million records to preprocess, you can check this [dataset](https:\/\/www.kaggle.com\/c\/optiver-realized-volatility-prediction\/discussion\/249647#1369316) where I have linked the preprocessed train pickle and csv format created using the code below.\n\nNote: I have not run and saved it for the obvious reason that I might run into memory issue again, so just sharing the code used. "}}