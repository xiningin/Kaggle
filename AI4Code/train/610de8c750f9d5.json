{"cell_type":{"a59a3e0e":"code","63e53396":"code","662ca9e4":"code","ac2f20c5":"code","0f32765e":"code","b068e212":"code","e9ebf987":"code","a793f6e6":"code","b5171d5e":"code","e4708b31":"code","863f80a9":"code","1630c51b":"code","5655fe40":"code","1924657f":"code","b0ddcce5":"code","692951ba":"code","117e793d":"code","766f47f3":"code","16c67f31":"code","29c96334":"code","e9232853":"code","2f7fb91b":"code","a65cd204":"code","c566d83e":"code","baf5e9f8":"code","5766c6a3":"code","9d0a582e":"code","2d74f096":"code","04a08ed8":"code","313d4d89":"code","522bc2f0":"code","72eb12f7":"code","3b48a57e":"code","2d3b69ae":"code","c64bd268":"code","5a9d5fe4":"code","3461a275":"code","defb3afb":"code","fc422d62":"code","993eec7b":"code","37ba7ee7":"code","f3f230f1":"code","2624b1dc":"code","85d3ef45":"code","c6e151e0":"code","bf89dd2b":"code","6793a50c":"code","c8bdbb43":"code","f640c812":"code","c5513369":"code","97d6913e":"code","c68de66d":"code","4a22a32f":"code","e9a43f83":"code","220eee78":"code","d918b85c":"code","5820f568":"code","8336f541":"code","8ed2964c":"code","0939bab1":"code","5752c573":"markdown","227e3c42":"markdown","34899bc6":"markdown","6b167160":"markdown","a4f782f1":"markdown","2644ba13":"markdown","a0ade51d":"markdown","439d2068":"markdown","01bc9875":"markdown","edc4e4fa":"markdown","5431d31a":"markdown","309e47ef":"markdown","b714805a":"markdown","3822fbe4":"markdown","b5d2d32d":"markdown","de896953":"markdown","4aed8d3d":"markdown","b8a4ecf9":"markdown","cc9743d3":"markdown","f41b4075":"markdown","e0957742":"markdown","5d7223f9":"markdown","0910b3ea":"markdown","bfd9fd04":"markdown"},"source":{"a59a3e0e":"# Nativos\nimport random as rn\nimport os\nimport sys\nimport gc\nfrom datetime import datetime\n\n#calculo\nimport numpy as np\nimport pandas as pd\nimport scipy\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\n#grafico\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import display\n%matplotlib inline\nsns.set(style=\"whitegrid\")\n\n#warning ignore future\nimport warnings\nimport gc\n# warnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.filterwarnings(\"ignore\")\ngc.collect()\n\nSEED = 29082013\nos.environ['PYTHONHASHSEED']=str(SEED)\nnp.random.seed(SEED)\nrn.seed(SEED)\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","63e53396":"# link de refuerzo\n# https:\/\/www.kaggle.com\/kvdatadragon\/eda-and-new-variables-by-churn\n\ndef view_cat(data, col_init, col_out, **kwargs):\n    color_label = kwargs.get('color_label', 'black')\n    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n    \n    cross = pd.crosstab(data[col_out], data[col_init])\n    sum_total = sum([cross[col].sum() for col in cross.columns])\n    sns.heatmap(\n        cross\/sum_total, \n        annot=True, ax=axes[0], center=0, cmap=\"YlGnBu\", fmt='.2%'\n    )\n    sns.barplot(\n        x=col_init, y=col_out, data=data, ax=axes[1]\n    )\n\n\ndef view_numeric(data, col_init, col_out, **kwargs):\n    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 4))\n\n    #sns.lineplot(x=col_init, y=col_out, data=data, ax=axes[0])\n    sns.boxplot(x=col_init, y=col_out, data=data, ax=axes[0], orient='h')\n    sns.violinplot(x=col_init, y=col_out, data=data, ax=axes[1], orient='h')","662ca9e4":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndisplay(train.head(10))\ndisplay(train.tail(10))\n\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ndisplay(test.head(10))\n\nsub= pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\ndisplay(sub.head(3))","ac2f20c5":"(test['PassengerId'] == sub['PassengerId']).any()","0f32765e":"train.shape, test.shape, sub.shape","b068e212":"train['Survived'].value_counts(normalize=True, dropna=False)","e9ebf987":"train.isnull().sum()","a793f6e6":"# link de refuerzo\n# https:\/\/github.com\/kendalvictor\/guia_data_ML\/blob\/master\/ANALISIS%20DE%20NULOS%20%20read_csv%2C%20isnull%2C%20any%2C%20sum%2C%20concat.ipynb\n\ndef null_verificator(data):        \n    if data.isnull().any().any():\n        \n        view_info = pd.DataFrame(\n            pd.concat(\n                [data.isnull().any(), \n                 data.isnull().sum(),\n                 data.dtypes], \n                axis=1)\n        )\n        view_info.columns = ['Nulos', 'Cantidad', 'Tipo Col']\n        \n        size = data.shape[0]\n        \n        view_info['Porcentaje'] = view_info['Cantidad'].apply(\n            lambda x: str(np.round(0 if not x else x*100 \/ size, 2)) + ' %'\n        )\n        return view_info\n    else:\n        return pd.DataFrame.from_dict({'msje':\"DATA LIMPIA DE NULOS\"}, orient='index')\n\n","b5171d5e":"display(null_verificator(train))\ndisplay(null_verificator(test))","e4708b31":"train['Pclass'] = train['Pclass'].astype(str)\ntest['Pclass'] = test['Pclass'].astype(str)","863f80a9":"display(train.describe().T)\ndisplay(test.describe().T)","1630c51b":"display(train.describe(include=[object]).T)\ndisplay(test.describe(include=[object]).T)","5655fe40":"for col in ['Pclass', 'Sex', 'Embarked']:\n    compara = pd.concat(\n        [train[col].value_counts(dropna=False, normalize=True).sort_index(),\n        test[col].value_counts(dropna=False, normalize=True).sort_index()], axis=1\n    )\n    compara.columns = ['train-'+col, 'test-'+col]\n    display(compara)\n    del compara","1924657f":"cols_num = list(train.describe().columns)[2:]\ncols_num","b0ddcce5":"train.describe(include=[object]).columns","692951ba":"cols_cat = ['Pclass', 'Sex', 'Embarked']\ncol_target = 'Survived'","117e793d":"for col in cols_cat:\n    print(col)\n    view_cat(train, col, col_target)","766f47f3":"mean_age_train = train.groupby(by=['Pclass', 'Sex'])['Age'].median().reset_index()\nmean_age_train.columns = ['Pclass', 'Sex', 'mean_age']\nmean_age_train","16c67f31":"train = train.merge(mean_age_train, how='left', on=['Pclass', 'Sex'])\ntest = test.merge(mean_age_train, how='left', on=['Pclass', 'Sex'])\n\ntrain['Age'] = train['Age'].combine_first(train['mean_age'])\ntest['Age'] = test['Age'].combine_first(train['mean_age'])\n\ndel train['mean_age']\ndel test['mean_age']\n\ntrain.shape, test.shape","29c96334":"mean_fare_train = train.groupby(by=['Pclass', 'Sex'])['Fare'].median().reset_index()\nmean_fare_train.columns = ['Pclass', 'Sex', 'mean_fare']\n\ntest = test.merge(mean_fare_train, how='left', on=['Pclass', 'Sex'])\ntest['Fare'] = test['Fare'].combine_first(test['mean_fare'])\n\ndel test['mean_fare']\ntrain.shape, test.shape","e9232853":"train['Cabin'].fillna('X', inplace=True)\ntest['Cabin'].fillna('X', inplace=True)\n\ntrain['Cabin'].isnull().sum(), test['Cabin'].isnull().sum()","2f7fb91b":"train['Embarked'].fillna('S', inplace=True)\n\ndisplay(null_verificator(train))\ndisplay(null_verificator(test))","a65cd204":"list(train['Name'])[:100]","c566d83e":"train['Mr'] = train['Name'].apply(lambda _: int('Mr' in _))\ntest['Mr'] = test['Name'].apply(lambda _: int('Mr' in _))\n\ntrain['Mrs'] = train['Name'].apply(lambda _: int('Mrs' in _))\ntest['Mrs'] = test['Name'].apply(lambda _: int('Mrs' in _))\n\ntrain['Miss'] = train['Name'].apply(lambda _: int('Miss' in _))\ntest['Miss'] = test['Name'].apply(lambda _: int('Miss' in _))\n\ntrain['Dr'] = train['Name'].apply(lambda _: int('Dr' in _))\ntest['Dr'] = test['Name'].apply(lambda _: int('Dr' in _))","baf5e9f8":"for col in ['Mr', 'Mrs', 'Miss', 'Dr']:\n    print(col)\n    view_cat(train, col, col_target)","5766c6a3":"train['words_in_name'] = train['Name'].apply(lambda _: len(_.split()))\ntest['words_in_name'] = test['Name'].apply(lambda _: len(_.split()))\n\n\nview_numeric(train, 'words_in_name', col_target)","9d0a582e":"del train['Name']\ndel test['Name']","2d74f096":"display(train['Cabin'].value_counts())\ndisplay(train['Ticket'].value_counts())","04a08ed8":"train.groupby(by=['Cabin'])['PassengerId'].size()","313d4d89":"def decision(cabin_val, num):\n    if cabin_val == 'X':\n        return -1\n    elif num > 1:\n        return 1\n    else:\n        return 0\n\ndef detect_share(data, col_analysis, new_column):\n    _g = data.groupby(by=[col_analysis]).agg({\n        'PassengerId': 'size',\n    }).reset_index()\n    \n    \n    _g[new_column] = _g[[col_analysis, 'PassengerId']].apply(\n        lambda _: decision(_[0], _[1]), axis=1\n    )\n    \n    data = data.merge(_g.drop(['PassengerId'], axis=1), on=col_analysis, how='left')\n    del _g\n    \n    return data","522bc2f0":"train = detect_share(train, 'Cabin', 'shared_cabin')\ntest = detect_share(test, 'Cabin', 'shared_cabin')\n\nview_cat(train, 'shared_cabin', col_target)","72eb12f7":"train = detect_share(train, 'Ticket', 'shared_ticket')\ntest = detect_share(test, 'Ticket', 'shared_ticket')\n\nview_cat(train, 'shared_ticket', col_target)","3b48a57e":"del train['Ticket']\ndel test['Ticket']\ndel train['Cabin']\ndel test['Cabin']","2d3b69ae":"train['total_family'] = train['SibSp'] + train['Parch']\ntest['total_family'] = test['SibSp'] + test['Parch']\n\nview_numeric(train, 'total_family', col_target)","c64bd268":"train['family_greater_than_3'] = train[['SibSp', 'Parch']].apply(lambda _: 1 if _[0] + _[1] > 3 else 0, axis=1)\ntest['family_greater_than_3'] = test[['SibSp', 'Parch']].apply(lambda _: 1 if _[0] + _[1] > 3 else 0, axis=1)\n\nview_cat(train, 'family_greater_than_3', col_target)","5a9d5fe4":"def _range_edad(_):\n    if _ < 0:\n        return 'sin edad'\n    elif _ < 10:\n        return 'ninno'\n    elif _ < 20:\n        return 'adolescente'\n    elif _ < 30:\n        return 'joven'\n    elif _ < 40:\n        return 'adulto'\n    elif _ < 50:\n        return 'adultomayor'\n    else:\n        return 'anciano'\n\ntrain['range_edad'] = train['Age'].apply(_range_edad)\ntest['range_edad'] = test['Age'].apply(_range_edad)\nview_cat(train, 'range_edad', 'Survived')","3461a275":"y_train = train['Survived'].copy()\n\ntrain = train.drop(['PassengerId', 'Survived'], axis=1)\n\ntest = test.drop(['PassengerId'], axis=1)","defb3afb":"train.columns","fc422d62":"test.columns","993eec7b":"train = pd.get_dummies(train, drop_first=True, columns=['Sex'])\ntest = pd.get_dummies(test, drop_first=True, columns=['Sex'])","37ba7ee7":"train = pd.get_dummies(train, drop_first=False)\ntest = pd.get_dummies(test, drop_first=False)","f3f230f1":"train.columns","2624b1dc":"test.columns","85d3ef45":"    train.shape, test.shape","c6e151e0":"train_target = train.copy()\ntrain_target['Survived'] = y_train.copy()\n\n_corr = train_target.corr(method='spearman')","bf89dd2b":"abs(_corr['Survived']).sort_values(ascending=False)","6793a50c":"list_var_relevants = ['Age', 'SibSp', 'Fare', 'Mr', 'Mrs', 'shared_cabin', 'family_greater_than_3', \n                      'total_family', 'words_in_name', 'Sex_male', 'Pclass_1', 'Pclass_3', 'Embarked_S', \n                      'range_edad_joven', 'range_edad_ninno']","c8bdbb43":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n\nc_values = list(np.logspace(-1, 0.5, 50))\nprint(c_values)","f640c812":"param_grid_log = {\n    'penalty': ['l2'],\n    'C': c_values,\n    'class_weight': ['balanced', None],\n    'max_iter': [75],\n    'solver': ['lbfgs']\n}\n\nkfold_on_rf = StratifiedKFold(\n    n_splits=3, \n    shuffle=False, \n    random_state=SEED\n)\n\nmodel_log = LogisticRegression(random_state=SEED, n_jobs = 4)","c5513369":"def apply_grid(X_train, y_train, model, param_grid, kfold_):\n    \n    grid = RandomizedSearchCV(\n        model, \n        {k: [v] if not isinstance(v, list) else v for k, v in param_grid.items()}, \n        cv=kfold_, \n        n_jobs=-1, \n        scoring='accuracy',\n        verbose=1,\n        n_iter=1500\n    )\n    grid.fit(X_train, y_train)\n    \n    print(grid.best_score_, end=' \/ ')\n    return grid.best_estimator_, grid.best_score_, grid.best_params_","97d6913e":"best_model, best_score, best_params = apply_grid(\n    train[list_var_relevants], y_train, model_log, param_grid_log, kfold_on_rf\n)","c68de66d":"from sklearn.metrics import classification_report, accuracy_score, recall_score\n\nresult_0_1_train = best_model.predict(train[list_var_relevants])\nacu = accuracy_score(y_train, result_0_1_train)\nrec = recall_score(y_train, result_0_1_train)\nprint(acu, rec)\n\nprint(classification_report(y_train, result_0_1_train))","4a22a32f":"sub['Survived'] = best_model.predict(test[list_var_relevants]) \nsub['Survived'].value_counts()","e9a43f83":"_date = str(datetime.now()).split('.')[0].replace('-', '_').replace(' ', '_').replace(':', '_')\n\nsub.to_csv('result_log_lassocv_{}_{}_{}.csv'.format(\n    round(acu, 4),round(rec, 4),_date\n), index=False)","220eee78":"### PRE OPTIMIZACI\u00d3ON","d918b85c":"result_prob_train = best_model.predict_proba(train[list_var_relevants])[:,1]\n\naccuracy_score(y_train, np.array([0 if _ < 0.5 else 1 for _ in result_prob_train]))","5820f568":"from scipy.optimize import differential_evolution\n\n\noptimization = differential_evolution(\n    lambda c: -1*accuracy_score(y_train, np.array([0 if _ < c[0] else 1 for _ in result_prob_train])), \n    [(0, 1)]\n)\noptimization","8336f541":"result_0_1_train_opt = np.array([0 if _ < optimization[\"x\"][0] else 1 for _ in result_prob_train])\nacu = accuracy_score(y_train, result_0_1_train_opt)\nrec = recall_score(y_train, result_0_1_train_opt)\nprint(acu, rec)\n\nprint(classification_report(y_train, result_0_1_train_opt))","8ed2964c":"result_0_1_test_opt = np.array(\n    [0 if _ < optimization[\"x\"][0] else 1 for _ in best_model.predict_proba(test[list_var_relevants])[:,1]]\n)\n\nsub['Survived'] = result_0_1_test_opt\nsub['Survived'].value_counts()","0939bab1":"_date = str(datetime.now()).split('.')[0].replace('-', '_').replace(' ', '_').replace(':', '_')\n\nsub.to_csv('result_loglassocv_opt_{}_{}_{}.csv'.format(\n    round(acu, 5),round(rec, 5),_date\n), index=False)","5752c573":"### \u00bfDe cuanto de data estamos hablando?","227e3c42":"### Edad","34899bc6":"### ANALISIS DE CORRELACION","6b167160":"### \u00bfLos PassengerId de la data de prueba corresponde a los de test?","a4f782f1":"### \u00bfTengo nulos?","2644ba13":"#### Descriptivo categ\u00f3rico","a0ade51d":"### Name","439d2068":"#### **supervived**  ---> 0 = No, 1 = S\u00ed\n#### **pclass **                      ---> 1 = 1 \u00b0, 2 = 2 \u00b0, 3 = 3 \u00b0\n#### **Sexo**                         ---> Sexo      \n#### **Edad **                        ---> Edad en a\u00f1os\n#### **sibsp**                        ---> # de hermanos \/ esposas a bordo del Titanic\n#### **parch**                        ---> de padres \/ hijos a bordo del Titanic\n#### **boleto **                      ---> N\u00famero de boleto\n#### **fare**                       ---> tarifa de pasaje\n#### **cabina **                      ---> N\u00famero de cabina\n#### **Puerto de embarque embarcado **---> C = Cherbourg, Q = Queenstown, S = Southampton","01bc9875":"### \u00bfComprendo el significado de cada una de las columnas\/variables? \u00bfComprendo lo que se quiere predecir?","edc4e4fa":"## FEATURE ENGINEERING","5431d31a":"### Fare","309e47ef":"for col in cols_num:\n    print(col)\n    view_numeric(train, col, col_target)","b714805a":"## VISUALIZACIONES","3822fbe4":"### Cabin","b5d2d32d":"  ## ANALISIS DESCRIPTIVO","de896953":"### \u00bfQue tan parecidas son las proporciones de las variables categ\u00f3ricas entre el train y el test?","4aed8d3d":"#### Descriptivo num\u00e9rico:","b8a4ecf9":"### \u00bfTodas las columnas tienen el tipo adecuado?","cc9743d3":"## IMPUTACION","f41b4075":"### Embarked","e0957742":"#### Edad","5d7223f9":"### \u00bfCual es la proporcion de mi target?","0910b3ea":"### Family ","bfd9fd04":"### Ticket - Cabin"}}