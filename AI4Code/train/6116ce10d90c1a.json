{"cell_type":{"9e3ddf54":"code","17d101b8":"code","336effb2":"code","74a37d11":"code","cfa3c21c":"code","38f966d6":"code","9c0ecd2b":"code","3b7ab9bc":"code","2a0e360c":"code","79ba3ffe":"code","425ec76c":"code","be804f92":"code","68d0df37":"code","319e8c67":"code","fa3bdbd2":"code","36f646be":"code","e9711ae0":"markdown","22d0ad4d":"markdown","963556da":"markdown","56db2ab6":"markdown","30c1194b":"markdown","d3f2b25a":"markdown","ba640a22":"markdown","0b096b54":"markdown","22ff82ba":"markdown","cfa5d40a":"markdown","0eb301d6":"markdown","659c253e":"markdown","52f7f846":"markdown"},"source":{"9e3ddf54":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","17d101b8":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_recall_curve\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","336effb2":"data_file_path = '..\/input\/heart-disease-uci\/heart.csv'\ndata_df = pd.read_csv(data_file_path)\n\n#To get information on the number of entries and the datatypes of the features\ndata_df.head()","74a37d11":"data_df.isnull().sum()","cfa3c21c":"data_df.dtypes","38f966d6":"data_df.head(10)","9c0ecd2b":"sns.countplot(data_df['target'])\nplt.title('Countplot of Target')\nplt.xlabel('target')\nplt.ylabel('Patients')\nplt.show()","3b7ab9bc":"y = data_df[\"target\"].values\nx = data_df.drop([\"target\"], axis = 1)\nfrom sklearn.preprocessing import StandardScaler\nss = StandardScaler()\nx = ss.fit_transform(x)\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.3)","2a0e360c":"y = data_df[\"target\"].values\nx = data_df.drop([\"target\"], axis = 1)\nfrom sklearn.preprocessing import StandardScaler\nss = StandardScaler()\nx = ss.fit_transform(x)\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.3) # 70% training and 30% test","79ba3ffe":"train_score = []\ntest_score = []\nk_vals = []\n\nfor k in range(1, 21):\n    k_vals.append(k)\n    knn = KNeighborsClassifier(n_neighbors = k)\n    knn.fit(X_train, y_train)\n    \n    tr_score = knn.score(X_train, y_train)\n    train_score.append(tr_score)\n    \n    te_score = knn.score(X_test, y_test)\n    test_score.append(te_score)","425ec76c":"max_test_score = max(test_score)\ntest_scores_ind = [i for i, v in enumerate(test_score) if v == max_test_score]\nprint('Max test score {} and k = {}'.format(max_test_score * 100, list(map(lambda x: x + 1, test_scores_ind))))","be804f92":"knn = KNeighborsClassifier(3)\nknn.fit(X_train, y_train)\nknn.score(X_test, y_test)","68d0df37":"y_pred = knn.predict(X_test)\nconfusion_matrix(y_test,y_pred)\npd.crosstab(y_test, y_pred, rownames = ['Actual'], colnames =['Predicted'], margins = True)","319e8c67":"print(classification_report(y_test, y_pred))","fa3bdbd2":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 2)  # n_neighbors means k\nknn.fit(X_train, y_train)\nprediction = knn.predict(X_test)\n\nprint(\"{} NN Score: {:.2f}%\".format(2, knn.score(X_test, y_test)*100))","36f646be":"scoreList = []\nfor i in range(1,20):\n    knn = KNeighborsClassifier(n_neighbors = i)  # n_neighbors means k\n    knn.fit(X_train, y_train)\n    scoreList.append(knn.score(X_test, y_test))\n    \nplt.plot(range(1,20), scoreList)\nplt.xticks(np.arange(1,20,1))\nplt.xlabel(\"K value\")\nplt.ylabel(\"Score\")\nplt.show()\n\nacc = max(scoreList)*100\n\nprint(\"Maximum KNN Score is {:.2f}%\".format(acc))","e9711ae0":"Hence we have calculated the final accuacy given below with the help of heart disease dataset","22d0ad4d":"To check the missing value","963556da":"To check how many of them are suffering from heart disease","56db2ab6":"Load the Library","30c1194b":"We are checking of 20 nearest neibhour to be caused with KNN algorithm","d3f2b25a":"Thus, we have obtained the optimum value of k to be 15,16 or 19 with a score of 82.41. We will finalize one of these values and fit the model accordingly","ba640a22":"KNN Prediction for algorithm processing","0b096b54":"Split into training and test data","22ff82ba":"Read The Data","cfa5d40a":"Data Preprocessing","0eb301d6":"Evaluate the training and testing scores for up to 20 nearest neighbors","659c253e":"Now we are implementing the confusion matrix","52f7f846":"To evaluate the max test score"}}