{"cell_type":{"73ae0170":"code","7c3b6a4d":"code","83a9c01b":"code","7f7b2cbe":"code","48880331":"code","2ac0ad15":"code","b0ab8fc4":"code","1ed008ba":"code","b9a6ca8b":"code","d536b956":"code","5e13012f":"code","92b309d5":"code","fc1e7e07":"code","fd5c30f9":"code","c96eeef7":"code","bffa5b8c":"code","aed0cf99":"code","2a152a4b":"code","c30dfc26":"code","e7f7ac2b":"code","e02fff9c":"code","8ff71068":"code","7b8661d7":"code","0d72748c":"code","1cff1cb5":"code","3ab08645":"code","51524020":"code","71cead48":"code","1d05bdfc":"code","bd861423":"code","253860b8":"code","dcea852e":"code","26c188c1":"code","4fe975c8":"code","f4c3297b":"code","2072492b":"code","2512688b":"code","3fdeb535":"code","5238863a":"code","a0372ed4":"markdown","243aa286":"markdown","21c567d5":"markdown","a67f4cea":"markdown","3d4f4fee":"markdown","bdda6efe":"markdown","3fc5e0b6":"markdown","927560cb":"markdown","75591bd4":"markdown","cea93a07":"markdown","7bb4fcd2":"markdown","16054d1b":"markdown","0eb6370a":"markdown","eee8dfa6":"markdown","e51767a5":"markdown","d3b27fcc":"markdown","de5462e3":"markdown","861376b9":"markdown"},"source":{"73ae0170":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.colors import ListedColormap\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.neighbors import KNeighborsClassifier,NeighborhoodComponentsAnalysis, LocalOutlierFactor\nfrom sklearn.decomposition import PCA\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","7c3b6a4d":"data = pd.read_csv(\"..\/input\/breast-cancer-wisconsin-data\/data.csv\")","83a9c01b":"data.head()","7f7b2cbe":"# Dropping useless features\ndata.drop([\"Unnamed: 32\", \"id\"], inplace=True, axis=1)","48880331":"data.shape","2ac0ad15":"data = data.rename(columns = {\"diagnosis\":\"target\"})","b0ab8fc4":"sns.countplot(data[\"target\"])\nprint(data.target.value_counts())","1ed008ba":"data[\"target\"] = [1 if i.strip()==\"M\" else 0 for i in data.target]","b9a6ca8b":"print(len(data))","d536b956":"print(\"Data shape:\", data.shape)","5e13012f":"data.info()","92b309d5":"data.describe()","fc1e7e07":"corr_matrix = data.corr()\nsns.clustermap(corr_matrix, annot=True, fmt=\".1f\")\nplt.title(\"Correlation Between Features\")\nplt.show()","fd5c30f9":"threshold = 0.5\nfiltre = np.abs(corr_matrix[\"target\"]) > threshold\ncorr_features = corr_matrix.columns[filtre].tolist()\nsns.clustermap(data[corr_features].corr(), annot=True, fmt=\".2f\")","c96eeef7":"#box plot\ndata_melted = pd.melt(data, id_vars = \"target\",\n                     var_name = \"features\",\n                     value_name = \"value\")\nplt.figure()\nsns.boxplot(x=\"features\", y=\"value\", hue=\"target\", data=data_melted)\nplt.xticks(rotation=90)\nplt.show()","bffa5b8c":"sns.pairplot(data[corr_features], diag_kind=\"kde\", markers=\"+\", hue=\"target\")\nplt.show()","aed0cf99":"y = data.target\nx = data.drop([\"target\"], axis=1)\ncolumns = x.columns.tolist()","2a152a4b":"clf = LocalOutlierFactor()\ny_pred = clf.fit_predict(x)\ny_pred","c30dfc26":"x_score = clf.negative_outlier_factor_\noutlier_score = pd.DataFrame()\noutlier_score[\"score\"] = x_score","e7f7ac2b":"outlier_score[\"score\"]","e02fff9c":"threshold = -2.5\nfiltre = outlier_score[\"score\"] < threshold\noutlier_index = outlier_score[filtre].index.tolist()\n\nplt.figure()\nplt.scatter(x.iloc[outlier_index, 0], x.iloc[outlier_index, 1], color=\"blue\", s=50, label=\"Outliers\")\nplt.scatter(x.iloc[:,0],x.iloc[:,1], color=\"k\", s=3, label=\"Data Points\")\n\nradius = (x_score.max() - x_score) \/ (x_score.max() - x_score.min())\noutlier_score[\"radius\"] = radius\nplt.scatter(x.iloc[:,0],x.iloc[:,1], edgecolors=\"r\", s=1000*radius, facecolors=\"none\",  label=\"Outlier Scores\")\nplt.legend()\nplt.show()","8ff71068":"#drop outliers\nx = x.drop(outlier_index)\ny = y.drop(outlier_index).values","7b8661d7":"test_size = 0.3\nX_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=test_size, random_state=42)","0d72748c":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","1cff1cb5":"X_train_df = pd.DataFrame(X_train, columns=columns)\nX_train_df_describe = X_train_df.describe()\nX_train_df[\"target\"] = Y_train","3ab08645":"#box plot after standardization\ndata_melted = pd.melt(X_train_df, id_vars = \"target\",\n                     var_name = \"features\",\n                     value_name = \"value\")\nplt.figure(figsize=(20,10))\nsns.boxplot(x=\"features\", y=\"value\", hue=\"target\", data=data_melted)\nplt.xticks(rotation=90)\nplt.legend()\nplt.show()","51524020":"# pairplot after standardization\nsns.pairplot(X_train_df[corr_features], diag_kind=\"kde\", markers=\"+\", hue=\"target\")\nplt.show()","71cead48":"#Basic KNN Method\n\nknn = KNeighborsClassifier(n_neighbors=2)\nknn.fit(X_train, Y_train)\ny_pred = knn.predict(X_test)\ncm = confusion_matrix(Y_test, y_pred)\nacc = accuracy_score(Y_test, y_pred)\nscore = knn.score(X_test, Y_test)\nprint(\"Score: \", score)\nprint(\"CM:\", cm)\nprint(\"Basic KNN Acc: \", acc)\n","1d05bdfc":"def KNN_Best_Params(x_train, x_test, y_train, y_test):\n    k_range = list(range(1,31))\n    weight_options = [\"uniform\", \"distance\"]\n    print()\n    param_grid = dict(n_neighbors=k_range, weights=weight_options)\n    \n    knn = KNeighborsClassifier()\n    grid = GridSearchCV(knn, param_grid, cv=10, scoring=\"accuracy\")\n    grid.fit(x_train, y_train)\n\n    print(\"Best training score: {} with parameters: {}\".format(grid.best_score_, grid.best_params_))\n    print()\n\n    knn = KNeighborsClassifier(**grid.best_params_)\n    knn.fit(x_train, y_train)\n\n    y_pred_test = knn.predict(x_test)\n    y_pred_train = knn.predict(x_train)\n\n    cm_test = confusion_matrix(y_test, y_pred_test)\n    cm_train = confusion_matrix(y_train, y_pred_train)\n\n    acc_test = accuracy_score(y_test, y_pred_test)\n    acc_train = accuracy_score(y_train, y_pred_train)\n    print(\"Test Score: {}, Train Score: {}\".format(acc_test, acc_train))\n    print()\n    print(\"CM Test: \", cm_test)\n    print(\"CM Train: \", cm_train)\n\n    return grid","bd861423":"grid = KNN_Best_Params(X_train, X_test, Y_train, Y_test)","253860b8":"scaler = StandardScaler()\nx_scaled = scaler.fit_transform(x)\n\npca = PCA(n_components=2)\npca.fit(x_scaled)\nX_reduced_pca = pca.transform(x_scaled)\npca_data = pd.DataFrame(X_reduced_pca, columns=[\"p1\", \"p2\"])\npca_data[\"target\"] = y\nplt.figure(figsize=(20,10))\nsns.scatterplot(x=\"p1\", y=\"p2\" , hue=\"target\", data=pca_data)\nplt.title(\"PCA: p1 vs p2\")","dcea852e":"X_train_pca, X_test_pca, Y_train_pca, Y_test_pca = train_test_split(X_reduced_pca, y, test_size=test_size, random_state=42)","26c188c1":"grid_pca = KNN_Best_Params(X_train_pca, X_test_pca, Y_train_pca, Y_test_pca)","4fe975c8":"cmap_light = ListedColormap([\"orange\", \"cornflowerblue\"])\ncmap_bold = ListedColormap([\"darkorange\", \"darkblue\"])\n\nh = 0.05\nX = X_reduced_pca\nx_min, x_max = X[:,0].min() - 1, X[:,0].max() + 1\ny_min, y_max = X[:,1].min() - 1, X[:,1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))\n\nZ = grid_pca.predict(np.c_[xx.ravel(), yy.ravel()])\n\nZ = Z.reshape(xx.shape)\nplt.figure(figsize=(12,9))\nplt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n\nplt.scatter(X[:,0], X[:,1], c=y, cmap=cmap_bold,\n           edgecolors=\"k\", s=20)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nplt.title(\"%i-Class classification (k = %i, weights = %s)\"\n         % (len(np.unique(y)), grid_pca.best_estimator_.n_neighbors, grid_pca.best_estimator_.weights))","f4c3297b":"nca = NeighborhoodComponentsAnalysis(n_components=2, random_state=42)\nnca.fit(x_scaled, y)\nX_reduced_nca = nca.transform(x_scaled)\nnca_data = pd.DataFrame(X_reduced_nca, columns=[\"p1\", \"p2\"])\nnca_data[\"target\"] = y\nsns.scatterplot(x=\"p1\", y=\"p2\", hue=\"target\", data=nca_data)\nplt.title(\"NCA: p1 vs p2\")","2072492b":"X_train_nca, X_test_nca, Y_train_nca, Y_test_nca = train_test_split(X_reduced_nca, y, test_size=test_size, random_state=42)","2512688b":"grid_nca = KNN_Best_Params(X_train_nca, X_test_nca, Y_train_nca, Y_test_nca)","3fdeb535":"cmap_light = ListedColormap([\"orange\", \"cornflowerblue\"])\ncmap_bold = ListedColormap([\"darkorange\", \"darkblue\"])\n\nh = 0.2\nX = X_reduced_nca\nx_min, x_max = X[:,0].min() - 1, X[:,0].max() + 1\ny_min, y_max = X[:,1].min() - 1, X[:,1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))\n\nZ = grid_nca.predict(np.c_[xx.ravel(), yy.ravel()])\n\nZ = Z.reshape(xx.shape)\nplt.figure(figsize=(12,9))\nplt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n\nplt.scatter(X[:,0], X[:,1], c=y, cmap=cmap_bold,\n           edgecolors=\"k\", s=20)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nplt.title(\"%i-Class classification (k = %i, weights = %s)\"\n         % (len(np.unique(y)), grid_nca.best_estimator_.n_neighbors, grid_nca.best_estimator_.weights))","5238863a":"knn = KNeighborsClassifier(**grid_nca.best_params_)\nknn.fit(X_train_nca, Y_train_nca)\ny_pred_nca = knn.predict(X_test_nca)\nacc_test_nca = accuracy_score(y_pred_nca, Y_test_nca)\nknn.score(X_test_nca, Y_test_nca)\n\ntest_data = pd.DataFrame()\ntest_data[\"X_test_nca_p1\"] = X_test_nca[:,0]\ntest_data[\"X_test_nca_p2\"] = X_test_nca[:,1]\ntest_data[\"y_pred_nca\"] = y_pred_nca\ntest_data[\"Y_test_nca\"] = Y_test_nca\n\nplt.figure()\nsns.scatterplot(x=\"X_test_nca_p1\", y=\"X_test_nca_p2\", hue=\"Y_test_nca\", data=test_data)\n\ndiff = np.where(y_pred_nca!=Y_test_nca)[0]\nplt.scatter(test_data.iloc[diff,0],test_data.iloc[diff,1],label = \"Wrong Classified\",alpha = 0.2,color = \"red\",s = 1000)","a0372ed4":"- Positive skewness","243aa286":"## <a id='4.'>4. Outlier Detection<\/a>","21c567d5":"## <a id='2.'>2. Loading and Checking Data<\/a>","a67f4cea":"## <a id='8.'>8. Choosing KNN Best Parameters<\/a>","3d4f4fee":"## <a id='7.'>7. KNN Implementation<\/a>","bdda6efe":"## Content:\n\n- <a href='#1.'> 1. Importing Libraries<\/a>\n- <a href='#2.'> 2. Loading and Checking Data<\/a>\n- <a href='#3.'> 3. Explatory Data Analysis<\/a>\n- <a href='#4.'> 4. Outlier Detection<\/a>\n- <a href='#5.'> 5. Train-Test-Split<\/a>\n- <a href='#6.'> 6. Standardization<\/a>\n- <a href='#7.'> 5. KNN Implementation<\/a>\n- <a href='#8.'> 8. Choosing KNN Best Parameters<\/a>\n- <a href='#9.'> 9. Principal Component Analysis<\/a>\n- <a href='#10.'> 10. Neighborhood Component Analysis<\/a>\n- <a href='#11.'> 11. Evaluating Results<\/a>\n- <a href='#12.'> 12. References<\/a>","3fc5e0b6":"## <a id='6.'>6. Standardization<\/a>","927560cb":"## <a id='11.'>11. Evaluating Results<\/a>","75591bd4":"## <a id='9.'>9. Principal Component Analysis<\/a>","cea93a07":"## <a id='5.'>5. Train-Test-Split<\/a>","7bb4fcd2":"To get a meaningful visual we need stardardization.","16054d1b":"We see that we need stardardization.","0eb6370a":"## <a id='12.'>12. References<\/a>\n\n- https:\/\/www.kaggle.com\/kanncaa1\n\n- https:\/\/www.udemy.com\/course\/machine-learning-ve-python-adan-zye-makine-ogrenmesi-4\/learn\/lecture\/17895310#overview\n\n- https:\/\/www.udemy.com\/course\/python-ile-makine-ogrenmesi-yapay-zeka-projeleri-52\/\n\n- https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neighbors.LocalOutlierFactor.html\n\n- https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neighbors.KNeighborsClassifier.html\n\n- https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.decomposition.PCA.html\n\n- https:\/\/scikit-learn.org\/stable\/auto_examples\/neighbors\/plot_nca_dim_reduction.html","eee8dfa6":"There are no missing values.","e51767a5":"## <a id='1.'>1. Importing Libraries<\/a>","d3b27fcc":"## <a id='3.'>3. Exploratory Data Analysis<\/a>","de5462e3":"There are some correlated features.","861376b9":"## <a id='10.'>10. Neighborhood Component Analysis<\/a>"}}