{"cell_type":{"3fc078c1":"code","d143dd89":"code","d3089ae3":"code","bcc097e3":"code","bee50521":"code","3c1d41fe":"code","ba7e1672":"code","1742bb53":"code","146d37b0":"code","fea50678":"code","72a30436":"code","296e383c":"code","2606f71a":"code","3d25626e":"code","36bb47ee":"code","80e88416":"code","09b5b510":"code","dfcdf96c":"code","aedc6599":"code","8a76b970":"code","c3da465b":"code","e65924dc":"code","5996c519":"code","177db073":"code","b58d21e2":"markdown","bdab604b":"markdown","836f3607":"markdown","bd7f7223":"markdown","11ed0053":"markdown","1e5355a7":"markdown","0fdbc15a":"markdown","3d8da11f":"markdown"},"source":{"3fc078c1":"import numpy as np\nimport random\nimport os\n\nSEED = 1988\n\n\nrandom.seed(SEED)\nos.environ[\"PYTHONHASHSEED\"] = str(SEED)\nnp.random.seed(SEED)","d143dd89":"!git clone https:\/\/github.com\/ultralytics\/yolov5\n#            https:\/\/github.com\/ultralytics\/yolov5\n# %cd yolov5\n# %pip install -qr requirements.txt  # install dependencies\n\nimport torch\n# from IPython.display import Image, clear_output  # to display images\n\n# clear_output()\n# print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")","d3089ae3":"import shutil\nshutil.copy2('.\/yolov5\/requirements.txt', '\/kaggle\/working\/')","bcc097e3":"import shutil\nimport os\n# import numpy as np\nfrom pathlib import Path\nPath(\".\/yolov5\/data\/images\/train\").mkdir(parents=True, exist_ok=True)\nfiless = os.listdir('..\/input\/payment-detection\/train\/train\/')\nfor i in filess:\n    shutil.copy2('..\/input\/payment-detection\/train\/train\/' + i, '.\/yolov5\/data\/images\/train')","bee50521":"#\u043f\u0443\u0442\u0438 \u043a \u0444\u0430\u0439\u043b\u0430\u043c\n# TRAIN_PATH = \"\/kaggle\/input\/dataforsbercomp2\/train\/\"\n\nfrom math import pi\nimport cv2\nimport matplotlib.pyplot as plt\n\n\"\"\" Utility Functions \"\"\"\n\ndef load_image(img_path, shape=None):\n    img = cv2.imread(img_path)\n    if shape is not None:\n        img = cv2.resize(img, shape)\n    \n    return img\n\ndef save_image(img_path, img):\n    cv2.imwrite(img_path, img)\n\ndef get_rad(theta, phi, gamma):\n    return (deg_to_rad(theta),\n            deg_to_rad(phi),\n            deg_to_rad(gamma))\n\ndef get_deg(rtheta, rphi, rgamma):\n    return (rad_to_deg(rtheta),\n            rad_to_deg(rphi),\n            rad_to_deg(rgamma))\n\ndef deg_to_rad(deg):\n    return deg * pi \/ 180.0\n\ndef rad_to_deg(rad):\n    return deg * 180.0 \/ pi\nimport numpy as np\nimport cv2\n\n# Usage: \n#     Change main function with ideal arguments\n#     Then\n#     from image_tranformer import ImageTransformer\n#\n# Parameters:\n#     image_path: the path of image that you want rotated\n#     shape     : the ideal shape of input image, None for original size.\n#     theta     : rotation around the x axis\n#     phi       : rotation around the y axis\n#     gamma     : rotation around the z axis (basically a 2D rotation)\n#     dx        : translation along the x axis\n#     dy        : translation along the y axis\n#     dz        : translation along the z axis (distance to the image)\n#\n# Output:\n#     image     : the rotated image\n# \n# Reference:\n#     1.        : http:\/\/stackoverflow.com\/questions\/17087446\/how-to-calculate-perspective-transform-for-opencv-from-rotation-angles\n#     2.        : http:\/\/jepsonsblog.blogspot.tw\/2012\/11\/rotation-in-3d-using-opencvs.html\n\n\nclass ImageTransformer(object):\n    \"\"\" Perspective transformation class for image\n        with shape (height, width, #channels) \"\"\"\n\n    def __init__(self, image_path):\n        self.image_path = image_path\n        self.image = load_image(image_path)\n \n        self.height = self.image.shape[0]\n        self.width = self.image.shape[1]\n        self.num_channels = self.image.shape[2]\n\n\n    \"\"\" Wrapper of Rotating a Image \"\"\"\n    def rotate_along_axis(self,nbbox, theta=0, phi=0, gamma=0, dx=0, dy=0, dz=0):\n        bbox = [0]*4\n        # Get radius of rotation along 3 axes\n        rtheta, rphi, rgamma = get_rad(theta, phi, gamma)\n        bbox[0] = nbbox[0] + int(0.2 * self.height)\n        bbox[2] = nbbox[2] + int(0.2 * self.height)\n        bbox[1] = nbbox[1] + int(0.2 * self.width)\n        bbox[3] = nbbox[3] + int(0.2 * self.width)\n        # Get ideal focal length on z axis\n        # NOTE: Change this section to other axis if needed\n        d = np.sqrt(self.height**2 + self.width**2)\n        self.focal = d \/ (2 * np.sin(rgamma) if np.sin(rgamma) != 0 else 1)\n        dz = self.focal\n\n        # Get projection matrix\n        mat = self.get_M(rtheta, rphi, rgamma, dx, dy, dz)\n#         print(mat)\n        newy1 = (mat[0][0] * bbox[1] + mat[0][1] * bbox[0] + mat[0][2])\/(mat[2][0] * bbox[1] + mat[2][1] * bbox[0] + mat[2][2])\n        newx1 = (mat[1][0] * bbox[1] + mat[1][1] * bbox[0] + mat[1][2])\/(mat[2][0] * bbox[1] + mat[2][1] * bbox[0] + mat[2][2])\n\n        newy2 = (mat[0][0] * bbox[3] + mat[0][1] * bbox[2] + mat[0][2])\/(mat[2][0] * bbox[3] + mat[2][1] * bbox[2] + mat[2][2])\n        newx2 = (mat[1][0] * bbox[3] + mat[1][1] * bbox[2] + mat[1][2])\/(mat[2][0] * bbox[3] + mat[2][1] * bbox[2] + mat[2][2])\n        \n        newy3 = (mat[0][0] * bbox[3] + mat[0][1] * bbox[0] + mat[0][2])\/(mat[2][0] * bbox[3] + mat[2][1] * bbox[0] + mat[2][2])\n        newx3 = (mat[1][0] * bbox[3] + mat[1][1] * bbox[0] + mat[1][2])\/(mat[2][0] * bbox[3] + mat[2][1] * bbox[0] + mat[2][2])\n        \n        newy4 = (mat[0][0] * bbox[1] + mat[0][1] * bbox[2] + mat[0][2])\/(mat[2][0] * bbox[1] + mat[2][1] * bbox[2] + mat[2][2])\n        newx4 = (mat[1][0] * bbox[1] + mat[1][1] * bbox[2] + mat[1][2])\/(mat[2][0] * bbox[1] + mat[2][1] * bbox[2] + mat[2][2])\n        \n        return (cv2.warpPerspective(cv2.copyMakeBorder( self.image.copy(), int(0.2 * self.height), int(0.2 * self.height) , int(0.2*self.width), int(0.2*self.width), cv2.BORDER_CONSTANT), mat, (int(self.width*1.4), int(self.height*1.4))), \n    (int(max(0, min(newx1, newx2, newx3, newx4))), \n     int(max(0, min(newy1, newy2, newy3, newy4))), \n     int(min(self.height + int(0.35 * self.height), max(newx1, newx2, newx3, newx4))),\n     int(min(self.width + int(0.35*self.width) ,max(newy1, newy2, newy3, newy4)))),self.width + int(0.4*self.width), self.height + int(0.4 * self.height))\n#     (newx1,newy1,newx2,newy2,newx3,newy3,newx4,newy4))\n\n\n    \"\"\" Get Perspective Projection Matrix \"\"\"\n    def get_M(self, theta, phi, gamma, dx, dy, dz):\n        \n        w = self.width\n        h = self.height\n        f = self.focal\n\n        # Projection 2D -> 3D matrix\n        A1 = np.array([ [1, 0, -w\/2],\n                        [0, 1, -h\/2],\n                        [0, 0, 1],\n                        [0, 0, 1]])\n        \n        # Rotation matrices around the X, Y, and Z axis\n        RX = np.array([ [1, 0, 0, 0],\n                        [0, np.cos(theta), -np.sin(theta), 0],\n                        [0, np.sin(theta), np.cos(theta), 0],\n                        [0, 0, 0, 1]])\n        \n        RY = np.array([ [np.cos(phi), 0, -np.sin(phi), 0],\n                        [0, 1, 0, 0],\n                        [np.sin(phi), 0, np.cos(phi), 0],\n                        [0, 0, 0, 1]])\n        \n        RZ = np.array([ [np.cos(gamma), -np.sin(gamma), 0, 0],\n                        [np.sin(gamma), np.cos(gamma), 0, 0],\n                        [0, 0, 1, 0],\n                        [0, 0, 0, 1]])\n\n        # Composed rotation matrix with (RX, RY, RZ)\n        R = np.dot(np.dot(RX, RY), RZ)\n\n        # Translation matrix\n        T = np.array([  [1, 0, 0, dx],\n                        [0, 1, 0, dy],\n                        [0, 0, 1, dz],\n                        [0, 0, 0, 1]])\n\n        # Projection 3D -> 2D matrix\n        A2 = np.array([ [f, 0, w\/2, 0],\n                        [0, f, h\/2, 0],\n                        [0, 0, 1, 0]])\n\n        # Final transformation matrix\n        return np.dot(A2, np.dot(T, np.dot(R, A1)))","3c1d41fe":"from tqdm import tqdm\nfrom matplotlib.pyplot import imshow\nimport numpy as np\nfrom PIL import Image\n\npathd = '.\/yolov5\/'\ndef PerspectiveTransformation(data, datapath):\n    label = []\n    x1 = []\n    y1 = []\n    w = []\n    h = []\n    width = []\n    height = []\n    image = []\n    sett = {'^'}\n    for i in tqdm(range(100,101)):\n        it = ImageTransformer(datapath + data.iloc[i]['image'])\n        bbox = [data.iloc[i]['y1'],data.iloc[i]['x1'],data.iloc[i]['y1'] + data.iloc[i]['h'],data.iloc[i]['x1'] + data.iloc[i]['w']]\n        pil_im = Image.open(datapath + data.iloc[i]['image'], 'r')\n        imshow(np.asarray(pil_im))\n        plt.show()\n        if not(data.iloc[i]['image'] in sett):\n            shutil.copy2(datapath + data.iloc[i]['image'], pathd)\n            sett.add(data.iloc[i]['image'])\n            \n        if not(data.iloc[i]['image'][:-4] + '1.jpg' in sett):\n            newimage, newbbox, newh, neww = it.rotate_along_axis(bbox, theta=-70, phi=0, gamma=27, dx=0, dy=0, dz=0)\n            imshow(np.asarray(newimage))\n            plt.show()\n            # sett.add(data.iloc[i]['image'])\n            if newbbox[3] - newbbox[1]>20 and newbbox[2] - newbbox[0] > 20:\n                label.append(data.iloc[i]['label'])\n                x1.append(newbbox[1])\n                y1.append(newbbox[0])\n                w.append(newbbox[3] - newbbox[1])\n                h.append(newbbox[2] - newbbox[0])\n                width.append(newh)\n                height.append(neww)\n                image.append(data.iloc[i]['image'][:-4] + '1.jpg')\n                filename = data.iloc[i]['image'][:-4] + '1.jpg'\n                cv2.imwrite(pathd+ filename, newimage)\n                imshow(np.asarray(newimage))\n                sett.add(data.iloc[i]['image'][:-4] + '1.jpg')\n        \n        if not(data.iloc[i]['image'][:-4] + '2.jpg' in sett):\n            newimage, newbbox, newh, neww = it.rotate_along_axis(bbox, theta=-70, phi=0, gamma=0, dx=0, dy=0, dz=0)\n            imshow(np.asarray(newimage))\n            plt.show()\n            if newbbox[3] - newbbox[1]>20 and newbbox[2] - newbbox[0] > 20:\n            # sett.add(data.iloc[i]['image'])\n                label.append(data.iloc[i]['label'])\n                x1.append(newbbox[1])\n                y1.append(newbbox[0])\n                w.append(newbbox[3] - newbbox[1])\n                h.append(newbbox[2] - newbbox[0])\n                width.append(newh)\n                height.append(neww)\n                image.append(data.iloc[i]['image'][:-4] + '2.jpg')\n                filename = data.iloc[i]['image'][:-4] + '2.jpg'\n                cv2.imwrite(pathd + filename, newimage)\n                \n                sett.add(data.iloc[i]['image'][:-4] + '2.jpg')\n        \n        if not(data.iloc[i]['image'][:-4] + '3.jpg' in sett):          \n            newimage, newbbox, newh, neww = it.rotate_along_axis(bbox, theta=70, phi=0, gamma=-40, dx=0, dy=0, dz=0)\n            imshow(np.asarray(newimage))\n            plt.show()\n            if newbbox[3] - newbbox[1]>20 and newbbox[2] - newbbox[0] > 20:\n                label.append(data.iloc[i]['label'])\n                x1.append(newbbox[1])\n                y1.append(newbbox[0])\n                w.append(newbbox[3] - newbbox[1])\n                h.append(newbbox[2] - newbbox[0])\n                width.append(newh)\n                height.append(neww)\n                image.append(data.iloc[i]['image'][:-4] + '3.jpg')\n                filename = data.iloc[i]['image'][:-4] + '3.jpg'\n#                 imshow(np.asarray(newimage))\n#                 plt.show()\n                sett.add(data.iloc[i]['image'][:-4] + '3.jpg')\n             \n    return pd.DataFrame(list(zip(label, x1, y1, w, h, width, height, image)), columns = list(traain.columns))","ba7e1672":"import pandas as pd\ntraain = pd.read_csv(\"\/kaggle\/input\/payment-detection\/train.csv\")","1742bb53":"tempordat = PerspectiveTransformation(traain, '..\/input\/payment-detection\/train\/train\/')\n# # tempordat.to_csv('\/content\/drive\/MyDrive\/sber\/data\/trainpart2.csv',index=False)\n# traain = train.append(tempordat, ignore_index=True)\n# # train.to_csv(\"train2.csv\", index=None)","146d37b0":"import os","fea50678":"cards = {'VI':1,\n         'MA':2,\n         'EX':3, \n         'PC':4, \n         'ST':5,\n         'UY':6\n             }","72a30436":"from collections import defaultdict\ndefdict = defaultdict(lambda: [])\nfor i in range(len(traain)):\n    temp = traain.iloc[i]\n    defdict[temp['image']].append([(temp['x1'] + temp['w'] \/ 2)\/temp['width'], (temp['y1'] + temp['h'] \/ 2)\/temp['height'], temp['w']\/temp['width'], temp['h']\/temp['height'], temp['label']])","296e383c":"from tqdm import tqdm","2606f71a":"from pathlib import Path\ndef create_dataset(dictr):\n#   images_path = Path(f\"clothing\/images\/{dataset_type}\")\n#   images_path.mkdir(parents=True, exist_ok=True)\n    labels_path = Path(\".\/yolov5\/data\/labels\/train\/\")\n    labels_path.mkdir(parents=True, exist_ok=True)\n    for img_id, row in enumerate(tqdm(dictr)):\n        image_name = row\n        # img = urllib.request.urlopen(row[\"content\"])\n        # img = Image.open(img)\n        # img = img.convert(\"RGB\")\n        # img.save(str(images_path \/ image_name), \"JPEG\")\n        label_name = f\"{image_name[:-4]}.txt\"\n        with (labels_path \/ label_name).open(mode=\"w\") as label_file:\n            for a in dictr[row]:\n                category_idx = cards[a[4]] - 1\n            # points = a['points']\n            # p1, p2 = points\n            # x1, y1 = a[0], \n            # x2, y2 = p2['x'], p2['y']\n            # bbox_width = x2 - x1\n            # bbox_height = y2 - y1\n                label_file.write(\n                    f\"{category_idx} {a[0]} {a[1]} {a[2]} {a[3]}\\n\"\n                )","3d25626e":"create_dataset(defdict)","36bb47ee":"f = open('yolov5\/data\/data1.yaml', 'w+')\nf.write('train: .\/yolov5\/data\/images\/train' + '\\n')\nf.write('val: .\/yolov5\/data\/images\/train' + '\\n')\nf.write('nc: 6' + '\\n')\nf.write(\"names: ['VI','MA','EX','PC','ST','UY',]\" + '\\n')\nf.close()","80e88416":"%pip install -q wandb\nimport wandb\n# wandb.login()","09b5b510":"os.environ['WANDB_MODE']=\"dryrun\"","dfcdf96c":"!python .\/yolov5\/train.py --img 640 --batch 6 --epochs 70 \\\n  --data .\/yolov5\/data\/data1.yaml --cfg .\/yolov5\/models\/yolov5x.yaml --weights yolov5x.pt \\\n  --name yolov5x_cards  --exist-ok","aedc6599":"!python .\/yolov5\/detect.py --weights runs\/train\/yolov5x_cards\/weights\/best.pt \\\n  --img 640 --conf 0.25 --source ..\/input\/payment-detection\/test\/test --save-txt \\\n  --name exp2 --exist-ok","8a76b970":"cardss = {0:'VI',\n         1:'MA',\n         2:'EX', \n         3:'PC', \n         4:'ST',\n         5:'UY'\n             }","c3da465b":"sub = pd.read_csv('..\/input\/payment-detection\/submission.csv')","e65924dc":"import os\n# if pathofweights.exists():\n#     paths = \"runs\/detect\/exp2\/labels\/\"\n# else:\npaths = \"runs\/detect\/exp2\/labels\/\"\nlistdirlabels = os.listdir(paths)\nnamess = []\nbb = []\n# for i in listdirlabels:\nfor i in listdirlabels:\n    namess.append(i[:-4] + '.jpg')\n    f = open(paths+i, 'r')\n    tbb = []\n    for line in f:\n        a = [float(j) for j in line.split()]\n        tbb.append(a[1:]+[cardss[a[0]]])\n    bb.append(tbb)\ntempnotfound = list(set(sub['image']) - set(namess))\ntempnbb = [[]]*len(tempnotfound)\nnamess = namess + tempnotfound\nbb = bb + tempnbb\ndef c_sort(sub_li):\n    sub_li.sort(key = lambda x: (x[0], x[1]))\n    return sub_li\nfor i in range(len(namess)):\n    bb[i] = c_sort(bb[i])\nlabels = []\nfor i in range(len(bb)):\n    labb = []\n    for j in range(len(bb[i])):\n        # xs = namess[i][j][:4]\n        labb.append(bb[i][j][4])\n    labels.append(\" \".join(labb))\ndictionar = dict(zip(namess, labels))\nlabels2 = []\nfor i in sub['image']:\n    labels2.append(dictionar[i])\npd.DataFrame({'image': sub['image'], 'payment': labels2}).to_csv('submission.csv', index=None)","5996c519":"shutil.rmtree(\".\/yolov5\/data\", ignore_errors=True)\nshutil.rmtree(\".\/runs\", ignore_errors=True)","177db073":"shutil.rmtree(\".\/wandb\", ignore_errors=True)","b58d21e2":"### \u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u0432\u044b\u0432\u043e\u0434\u0430","bdab604b":"### \u0417\u0430\u043f\u0443\u0441\u043a \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f.\n\u0421\u043f\u0438\u0441\u043e\u043a \u0432\u0441\u0435\u0445 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u043c\u043e\u0436\u043d\u043e \u043d\u0430\u0439\u0442\u0438 \u043d\u0430 \u0441\u0442\u0440\u0430\u043d\u0438\u0446\u0435 \u0430\u0432\u0442\u043e\u0440\u0430. \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043b\u0430\u0441\u044c \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u043d\u0430\u044f \u043c\u043e\u0434\u0435\u043b\u044c \u043d\u0430 \u0432\u0435\u0441\u0430\u0445 \u043e\u0434\u043d\u043e\u0433\u043e \u0438\u0437 \u0432\u0438\u0434\u043e\u0432 \u043c\u043e\u0434\u0435\u043b\u0438. \u041f\u0440\u043e\u0431\u043e\u0432\u0430\u043b\u0438\u0441\u044c \u0432\u0441\u0435 \u0438\u0437 \u043d\u0438\u0445. \u0417\u0430\u043c\u0435\u0447\u0430\u043d\u0438\u0435: \u043d\u0435 \u0441\u0440\u0430\u0431\u043e\u0442\u0430\u043b\u0430 \u043d\u0438 \u043e\u0434\u043d\u0430 \u043c\u043e\u0434\u0435\u043b\u044c, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u043e\u0431\u0443\u0447\u0430\u043b\u0430\u0441\u044c \u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0430\u0445 \u0440\u0430\u0437\u043c\u0435\u0440\u0430 1280 pix. \u0421\u0440\u0430\u0431\u043e\u0442\u0430\u043b\u0430 \u043b\u0438\u0448\u044c yolov5x \u043d\u0430 640 pix. \u041c\u0435\u0442\u043e\u0434\u043e\u043c \u043f\u0435\u0440\u0435\u0431\u043e\u0440\u0430 \u0431\u044b\u043b\u0438 \u043f\u043e\u0434\u043e\u0431\u0440\u0430\u043d\u044b \u043e\u043f\u0442\u0438\u043c\u0430\u043b\u044c\u043d\u044b\u0435 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b EPOCH = 70, BATCH = 6. \u0412 \u0444\u0438\u043d\u0430\u043b\u0435 \u0431\u044b\u043b\u043e \u0437\u0430\u043f\u0443\u0449\u0435\u043d\u043e \u043d\u0430 \u0432\u0441\u0435\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435 \u0431\u0435\u0437 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438.\n","836f3607":"\u0423\u0434\u0430\u043b\u0435\u043d\u0438\u0435 \u043b\u0438\u0448\u043d\u0438\u0445 \u0444\u0430\u0439\u043b\u043e\u0432.","bd7f7223":"\u041f\u043e\u0434\u0433\u043e\u0442\u0430\u0432\u043b\u0438\u0432\u0430\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u043f\u043e \u0441\u0445\u0435\u043c\u0435 \u043e\u0442 \u0430\u0432\u0442\u043e\u0440\u0430 \u043c\u043e\u0434\u0435\u043b\u0438.","11ed0053":"\u041d\u0438\u0436\u0435 \u0431\u043b\u043e\u043a\u0438 \u043a\u043e\u0434\u0430 \u0441 \u043f\u043e\u043f\u044b\u0442\u043a\u043e\u0439 \u043e\u0441\u043e\u0431\u043e\u0439 \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 \u0434\u043b\u044f \u0433\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u0438 \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u043d\u044b\u0445 (\u044f \u0431\u044b \u0441\u043a\u0430\u0437\u0430\u043b) \u0440\u0435\u0430\u043b\u0438\u0441\u0442\u0438\u0447\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u043f\u043e\u0432\u043e\u0440\u043e\u0442\u0430 \u0431\u0430\u043d\u043a\u043e\u0432\u0441\u043a\u043e\u0439 \u043a\u0430\u0440\u0442\u044b \u0432 \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0441\u0442\u0432\u0435. \u041a\u043e\u0440\u043e\u0442\u043a\u043e: \u043d\u0435 \u0441\u0440\u0430\u0431\u043e\u0442\u0430\u043b\u043e, \u043d\u0435 \u0434\u0430\u043b\u043e \u043f\u0440\u0438\u0440\u043e\u0441\u0442\u0430 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 (\u0432 \u043a\u0430\u043a\u043e\u043c-\u0442\u043e \u0441\u043c\u044b\u0441\u043b\u0435 \u0434\u0430\u0436\u0435 \u043d\u0430\u043e\u0431\u043e\u0440\u043e\u0442 - \u0443\u0445\u0443\u0434\u0448\u0438\u043b\u0430\u0441\u044c \u043c\u043e\u0434\u0435\u043b\u044c). \u041f\u0440\u0435\u0434\u043f\u043e\u043b\u043e\u0436\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u0438\u0437-\u0437\u0430 \u0441\u043b\u0438\u0448\u043a\u043e\u043c \u0431\u043e\u043b\u044c\u0448\u0438\u0445 \u0437\u043e\u043d \u0447\u0435\u0440\u043d\u043e\u0433\u043e \u0446\u0432\u0435\u0442\u0430 \u043d\u0430 \u0444\u043e\u043d\u0435 \u043f\u043e\u0432\u0435\u0440\u043d\u0443\u0442\u043e\u0439 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438. \u041f\u043e\u0442\u0435\u043d\u0446\u0438\u0430\u043b\u044c\u043d\u043e - \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c \u043c\u043e\u0433 \u0441\u0433\u0435\u043d\u0435\u0440\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u043e\u0433\u0440\u043e\u043c\u043d\u043e\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0434\u0430\u043d\u043d\u044b\u0445. \u041d\u0430 \u043f\u0440\u0430\u043a\u0442\u0438\u043a\u0435 \u043e\u043a\u0430\u0437\u0430\u043b\u043e\u0441\u044c \u0431\u0435\u0441\u043f\u043e\u043b\u0435\u0437\u043d\u043e. \u0418\u0437 \u0444\u0438\u043d\u0430\u043b\u044c\u043d\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u0438 - \u0438\u0441\u043a\u043b\u044e\u0447\u0435\u043d\u043e.   \n\u0427\u0443\u0442\u044c \u043d\u0438\u0436\u0435 \u043f\u0440\u0438\u043c\u0435\u0440 \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438. Bounding Box \u0442\u0430\u043a\u0436\u0435 \u0443\u0447\u0438\u0442\u044b\u0432\u0430\u0435\u0442 \u043f\u043e\u0432\u043e\u0440\u043e\u0442 \u0438 \u0443\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442 \u043d\u0430 \u0442\u0443 \u0436\u0435 \u0437\u043e\u043d\u0443, \u043d\u043e \u0441 \u043f\u043e\u0432\u043e\u0440\u043e\u0442\u043e\u043c.","1e5355a7":"\u041f\u0440\u043e\u0434\u043e\u043b\u0436\u0430\u0435\u043c \u043f\u043e\u0434\u0433\u043e\u0442\u0430\u0432\u043b\u0438\u0432\u0430\u0442\u044c \u0434\u0430\u043d\u043d\u044b\u0435.","0fdbc15a":"### \u0414\u0435\u0442\u0435\u043a\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435.","3d8da11f":"\u041e\u0441\u043d\u043e\u0432\u0430\u043d\u043e \u043d\u0430 \u043c\u043e\u0434\u0435\u043b\u0438 YOLOv5\n\nhttps:\/\/github.com\/ultralytics\/yolov5"}}