{"cell_type":{"46f3045d":"code","c29ae000":"code","9eb5dda2":"code","5afb8431":"code","f2942260":"code","1753927c":"code","b6046292":"code","efd19688":"code","d0c1f660":"code","81739ef9":"code","b5be7fc5":"code","82f04d7f":"code","3913b34d":"code","50c49dcd":"code","455cc798":"code","e88d026c":"code","6c17e9e6":"code","37028883":"code","16836043":"code","5a772522":"code","6c0afea5":"code","e752541a":"markdown","3b801579":"markdown","73ed0516":"markdown","d780ab3f":"markdown","3b2b94b2":"markdown","d378d1b3":"markdown","f5c47679":"markdown","0572b910":"markdown","49b33ab9":"markdown","a4f198a3":"markdown","ca5711be":"markdown","f6ceac13":"markdown","40bc0d2e":"markdown"},"source":{"46f3045d":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport sklearn.utils\nfrom mpl_toolkits.basemap import Basemap\nfrom pylab import rcParams\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler","c29ae000":"# Loading the dataset\nfile_path = '\/kaggle\/input\/weather-stations-in-usa\/weather-stations20140101-20141231.csv'\ndf = pd.read_csv(file_path)\ndf.sample(5)","9eb5dda2":"df.info()","5afb8431":"# Removing the rows that don't have any value for the 'Tm' field\ndf = df[pd.notnull(df['Tm'])]\ndf = df.reset_index(drop=True)","f2942260":"# Plotting map and weather stations on map\ndef plot_map(df):\n    rcParams['figure.figsize'] = (14, 10)\n\n    llon = -140\n    ulon = -50\n    llat = 40\n    ulat = 65\n\n    df = df[(df['Long'] > llon) & (df['Long'] < ulon) & (df['Lat'] > llat) & (df['Lat'] < ulat)]\n\n    my_map = Basemap(\n        projection='merc',\n        resolution='l',\n        area_thresh=1000.0,\n        llcrnrlon=llon,\n        llcrnrlat=llat,  # min longitude (llcrnrlon) and latitude (llcrnrlat)\n        urcrnrlon=ulon,\n        urcrnrlat=ulat\n    )  # max longitude (urcrnrlon) and latitude (urcrnrlat)\n\n    my_map.drawcoastlines()\n    my_map.drawcountries()\n    # my_map.drawmapboundary()\n    my_map.fillcontinents(color='white', alpha=0.3)\n    my_map.shadedrelief()\n\n    # To collect data based on stations\n\n    xs, ys = my_map(np.asarray(df.Long), np.asarray(df.Lat))\n    df['xm'] = xs.tolist()\n    df['ym'] = ys.tolist()\n\n    # Visualization1\n    for index, row in df.iterrows():\n        #   x,y = my_map(row.Long, row.Lat)\n        my_map.plot(\n            row.xm,\n            row.ym,\n            markerfacecolor=([1, 0, 0]),\n            marker='o',\n            markersize=5,\n            alpha=0.75\n        )\n\n    # plt.text(x,y,stn)\n    plt.show()\n\n    return ((llon, ulon, llat, ulat), df)\n\n(llon, ulon, llat, ulat), df = plot_map(df.copy())","1753927c":"sklearn.utils.check_random_state(1000)","b6046292":"Clus_dataSet = df[['xm', 'ym']]\nClus_dataSet = np.nan_to_num(Clus_dataSet)\n\nscaler = StandardScaler()\nClus_dataSet = scaler.fit_transform(Clus_dataSet)\n\nClus_dataSet","efd19688":"db = DBSCAN(eps=0.15, min_samples=10)\ndb.fit(Clus_dataSet)","d0c1f660":"print(set(db.labels_)) # unique clusters\ndb.labels_","81739ef9":"# Lets Replace all elements with 'True' in core_samples_mask that are in the cluster, 'False' if the points are outliers.\ncore_samples_mask = np.zeros_like(db.labels_, dtype=bool)\ncore_samples_mask[db.core_sample_indices_] = True\ncore_samples_mask","b5be7fc5":"labels = db.labels_\ndf['Clus_Db'] = labels\ndf[['Clus_Db']].head()","82f04d7f":"# Number of clusters in labels, ignoring noise if present.\nrealClusterNum = len(set(labels)) - (1 if -1 in labels else 0)\n\n# Remove repetition in labels by turning it into a set.\nclusterNum = len(set(labels))\n\n# A sample of clusters\ndf[['Stn_Name', 'Tx', 'Tm', 'Clus_Db']].head(5)","3913b34d":"set(labels)","50c49dcd":"# Visualisation of clusters based on location\ndef plot_clusters_map(llon, ulon, llat, ulat, labels):\n    rcParams['figure.figsize'] = (14, 10)\n\n    my_map = Basemap(\n        projection='merc',\n        resolution='l',\n        area_thresh=1000.0,\n        llcrnrlon=llon,\n        llcrnrlat=llat,  # min longitude (llcrnrlon) and latitude (llcrnrlat)\n        urcrnrlon=ulon,\n        urcrnrlat=ulat\n    )  # max longitude (urcrnrlon) and latitude (urcrnrlat)\n\n    my_map.drawcoastlines()\n    my_map.drawcountries()\n    #my_map.drawmapboundary()\n    my_map.fillcontinents(color='white', alpha=0.3)\n    my_map.shadedrelief()\n\n    # To create a color map\n    colors = plt.get_cmap('jet')(np.linspace(0.0, 1.0, clusterNum))\n\n    #Visualization1\n    for clust_number in set(labels):\n        c = (\n            ([0.4, 0.4, 0.4])\n            if clust_number == -1 else colors[np.int(clust_number)]\n        )\n        clust_set = df[df.Clus_Db == clust_number]\n        my_map.scatter(\n            clust_set.xm, clust_set.ym, color=c, marker='o', s=20, alpha=0.85\n        )\n        if clust_number != -1:\n            cenx = np.mean(clust_set.xm)\n            ceny = np.mean(clust_set.ym)\n            plt.text(\n                cenx,\n                ceny,\n                str(clust_number),\n                fontsize=30,\n                color='red',\n            )\n            print(\n                \"Cluster \" + str(clust_number) + ', Avg Temp: ' +\n                str(np.mean(clust_set.Tm))\n            )\n\n\nplot_clusters_map(llon, ulon, llat, ulat, labels)","455cc798":"# In this section we re-run DBSCAN, but this time on a 5-dimensional dataset\nClus_dataSet = df[['xm', 'ym', 'Tx', 'Tm', 'Tn']]","e88d026c":"# Data wrangling \nClus_dataSet = np.nan_to_num(Clus_dataSet)\nClus_dataSet = StandardScaler().fit_transform(Clus_dataSet)","6c17e9e6":"db = DBSCAN(eps=0.3, min_samples=10).fit(Clus_dataSet)","37028883":"# Lets Replace all elements with 'True' in core_samples_mask that are in the cluster, 'False' if the points are outliers.\ncore_samples_mask = np.zeros_like(db.labels_, dtype=bool)\ncore_samples_mask[db.core_sample_indices_] = True\n\nlabels = db.labels_\ndf['Clus_Db'] = labels\n\n# Number of clusters in labels, ignoring noise if present.\nrealClusterNum = len(set(labels)) - (1 if -1 in labels else 0)\n\n# Remove repetition in labels by turning it into a set.\nclusterNum = len(set(labels))\n\n# A sample of clusters\ndf[['Stn_Name', 'Tx', 'Tm', 'Clus_Db']].head(5)","16836043":"plot_clusters_map(llon, ulon, llat, ulat, labels)","5a772522":"def model(df, dataset, eps=0.15, min_samples=10):\n    dataset = np.nan_to_num(dataset)\n    \n    # Scaling the dataset\n    dataset = StandardScaler().fit_transform(dataset)\n    \n    # Computer DBSCAN\n    db = DBSCAN(eps=eps, min_samples=min_samples)\n    db.fit(dataset)\n    \n    # Distinguish outliers\n\n    # Lets Replace all elements with 'True' in core_samples_mask that are in the cluster, 'False' if the points are outliers.\n    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n    core_samples_mask[db.core_sample_indices_] = True\n\n    labels = db.labels_\n    df['Clus_Db'] = labels\n\n    # Number of clusters in labels, ignoring noise if present.\n    real_cluster_num = len(set(labels)) - (1 if -1 in labels else 0)\n\n    # Remove repetition in labels by turning it into a set.\n    cluster_num = len(set(labels))\n\n    # Number of clusters in labels, ignoring noise if present.\n    real_cluster_num = len(set(labels)) - (1 if -1 in labels else 0)\n    \n    print(f'Unique clusters: {set(labels)}')\n    \n    return (df, dataset, labels, core_samples_mask, db)","6c0afea5":"dataset = df[['xm', 'ym']]\n_, _, labels, _, _ = model(df, dataset)\nplot_clusters_map(llon, ulon, llat, ulat, labels)","e752541a":"**Compute DBSCAN**","3b801579":"## Modelling","73ed0516":"**Distinguish Outliers**","d780ab3f":"**Compute DBSCAN**","3b2b94b2":"### Clustering the station based on their locations i.e. `Latitude and Longitude`","d378d1b3":"### Helper function for the model","f5c47679":"**Getting dataset**","0572b910":"## Data preparation","49b33ab9":"**Distinguish Outliers**","a4f198a3":"**Getting dataset**","ca5711be":"### Clustering of stations based on their `location`, `mean`, `max`, and `min` `Temperature`","f6ceac13":"# Clustering weather stations in USA\n\nA machine learning model is used to make `clusters` of weather stations of USA using the `DBSCAN clustering algorithm`.\n\nKnow more about `clustering` algorithms - [Source](https:\/\/towardsdatascience.com\/the-5-clustering-algorithms-data-scientists-need-to-know-a36d136ef68).\n\n![](https:\/\/media.giphy.com\/media\/26gsj2EoFmR8qf5PG\/giphy.gif)","40bc0d2e":"---\n\nI'll wrap things up there. If you want to find some other answers then go ahead `edit` this kernel. If you have any `questions` then do let me know.\n\nIf this kernel helped you then don't forget to \ud83d\udd3c `upvote` and share your \ud83c\udf99 `feedback` on improvements of the kernel.\n\n![](https:\/\/media.giphy.com\/media\/xT5LMIp6EnVSEwLUYg\/giphy.gif)\n\n---"}}