{"cell_type":{"c2ec30df":"code","aa137ef6":"code","d97ea8fa":"code","37d600cf":"code","21babe92":"code","4bd851ee":"code","3716f21b":"code","6c66a363":"code","07381806":"code","ff2a2475":"code","f82a6186":"code","6249249c":"code","fc783e9b":"code","7d68f313":"code","05ea667e":"code","92e99091":"code","1942137d":"code","236ab1c3":"code","51fff5fd":"code","723d17fe":"code","d4e30a87":"markdown","ce1963b3":"markdown","fae04d22":"markdown","c5eb7fcd":"markdown","3bf94efe":"markdown","b393b9f0":"markdown"},"source":{"c2ec30df":"import pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score\nimport warnings\nwarnings.filterwarnings('ignore')\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt","aa137ef6":"ls ..\/input","d97ea8fa":"df_train = pd.read_csv('..\/input\/train.csv')\ndf_test = pd.read_csv('..\/input\/test.csv')\ndf_gender_submission = pd.read_csv('..\/input\/gender_submission.csv')","37d600cf":"genders = {'male': 0, 'female': 1} # \u8f9e\u66f8\u3092\u4f5c\u6210\n# Sex\u3092genders\u3092\u7528\u3044\u3066\u5909\u63db\ndf_train['Sex'] = df_train['Sex'].map(genders)\ndf_test['Sex'] = df_test['Sex'].map(genders)\n\n# \u30c0\u30df\u30fc\u5909\u6570\u5316\ndf_train = pd.get_dummies(df_train, columns=['Embarked'])\ndf_test = pd.get_dummies(df_test, columns = ['Embarked'])\n\n# \u4e0d\u8981\u306a\u5217\u306e\u524a\u9664\ndf_train.drop(['PassengerId', 'Name', 'Cabin', 'Ticket'], axis=1, inplace=True)\ndf_test.drop(['PassengerId', 'Name', 'Cabin', 'Ticket'], axis=1, inplace=True)","21babe92":"df_train.head(6)","4bd851ee":"X_train = df_train.iloc[:, 1:]\nY_train = df_train['Survived']","3716f21b":"# 3\u5206\u5272\u4ea4\u5dee\u691c\u8a3c\u3092\u6307\u5b9a\u3057\u3001\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u5316\nkf = KFold(n_splits=3)\n\nscore_list = []\n\n\npred = np.zeros(len(df_test))\n\nfor train_index, test_index in kf.split(X_train, Y_train):\n    X_cv_train = X_train.iloc[train_index]\n    X_cv_test = X_train.iloc[test_index]\n    y_cv_train = Y_train[train_index]\n    y_cv_test = Y_train[test_index]\n\n    gbm = lgb.LGBMClassifier(objective='binary',\n                             num_leaves=300,\n                             learning_rate=0.1,\n                             random_seed=1,\n                             max_depth=2\n                            )\n    gbm.fit(X_cv_train, y_cv_train,\n            eval_set = [(X_cv_test, y_cv_test)],\n            early_stopping_rounds=20,\n            verbose=5)\n    \n    y_pred = gbm.predict(X_cv_test, num_iteration=gbm.best_iteration_)\n    score_list.append(round(accuracy_score(y_cv_test,y_pred)*100,2))\n    print(round(accuracy_score(y_cv_test,y_pred)*100,2))\n    pred += gbm.predict(df_test, num_iteration=gbm.best_iteration_)\/3\npred = (pred > 0.5).astype(np.int)\n    ","6c66a363":"gbm.predict_proba(X_cv_test, num_iteration=gbm.best_iteration_)","07381806":"gbm?","ff2a2475":"gbm.get_params","f82a6186":"score_list","6249249c":"df_gender_submission['Survived'] = pred","fc783e9b":"df_gender_submission.to_csv('lightgbm.csv',index = False)","7d68f313":"X_train = df_train.iloc[:,1:]\nY_train = df_train['Survived']\n\n# 3\u5206\u5272\u4ea4\u5dee\u691c\u8a3c\u3092\u6307\u5b9a\u3057\u3001\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u5316\nskf = KFold(n_splits=3)\n\n# skf.split(X_train.Ytrain)\u3067\u3001X_train\u3068Y_train\u30923\u5206\u5272\u3057\u3001\u4ea4\u5dee\u691c\u8a3c\u3092\u3059\u308b\nfor train_index, test_index in skf.split(X_train, Y_train):\n    X_cv_train = X_train.iloc[train_index]\n    X_cv_test = X_train.iloc[test_index]\n    y_cv_train = Y_train[train_index]\n    y_cv_test = Y_train[test_index]\n    \n    lgb_train = lgb.Dataset(X_cv_train,y_cv_train)\n    lgb_eval = lgb.Dataset(X_cv_test,y_cv_test)\n    \n    lgbm_params = {\n        # \u591a\u5024\u5206\u985e\u554f\u984c\n        'objective': 'binary',\n    }\n    \n    gbm = lgb.train(params = lgbm_params,\n            train_set = lgb_train,\n            num_boost_round=50,\n            valid_sets=lgb_eval,\n            early_stopping_rounds=20,\n            verbose_eval = 5)\n    \n    y_pred = gbm.predict(X_cv_test,num_iteration=gbm.best_iteration)\n\n    # acuuracy\u3092\u8868\u793a\n    preds = np.round(gbm.predict(X_cv_test))\n    print(round(accuracy_score(y_cv_test,preds)*100,2))","05ea667e":"lgb_train = lgb.Dataset(X_train, Y_train)\n\n# LightGBM \u306e\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\nlgbm_params = {\n    # \uff12\u5024\u5206\u985e\u554f\u984c\n    'objective': 'binary',\n}","92e99091":"lgb.cv","1942137d":"gbm = lgb.cv(lgbm_params,\n             train_set = lgb_train,\n             nfold=3,\n             verbose_eval=10)","236ab1c3":"gbm # \u8f9e\u66f8\u306bloss\u3068loss\u306e\u6a19\u6e96\u504f\u5dee\u304c\u306f\u3044\u308a\u307e\u3059\u3002","51fff5fd":"cv_logloss = gbm['binary_logloss-mean']\nround_n = np.arange(len(cv_logloss))\n\nplt.xlabel('round')\nplt.ylabel('logloss')\nplt.plot(round_n, cv_logloss)\nplt.show()","723d17fe":"plt.xlabel('round')\nplt.ylabel('logloss-stdv')\nplt.plot(round_n, gbm['binary_logloss-stdv']);\nplt.show()","d4e30a87":"# \u30bf\u30a4\u30bf\u30cb\u30c3\u30af\u306e\u30c7\u30fc\u30bf\u3067\u8a66\u3059","ce1963b3":"### cv(cross validation)\u3092\u7c21\u5358\u306b\u884c\u3046\u3053\u3068\u304c\u3067\u304d\u308b","fae04d22":"## scikit-learn\u3092\u4f7f\u308f\u306a\u3044","c5eb7fcd":"\u304a\u305d\u3089\u304f\u3001scikit-learn\u304b\u3089\u306f\u3067\u304d\u306a\u304f\u3066\u3001\u6bce\u56destd\u307e\u3067\u51fa\u3057\u3066\u304f\u308c\u308b\u304b\u3089\u4f7f\u3044\u3084\u3059\u3044  \n\n- \u53c2\u8003\uff11\uff1ahttps:\/\/lightgbm.readthedocs.io\/en\/latest\/Python-API.html#lightgbm.cv\n- \u53c2\u8003\uff12\uff1ahttps:\/\/www.kaggle.com\/c\/home-credit-default-risk\/discussion\/58332#339215","3bf94efe":"## scikit-learn\u304b\u3089lightGBM\u3092\u4f7f\u3046","b393b9f0":"# \uff08\u53c2\u8003\uff09lightGBM\u95a2\u9023\u306e\u30ea\u30f3\u30af\u96c6\n- \u516c\u5f0f\uff1ahttps:\/\/github.com\/Microsoft\/LightGBM\n    - example:https:\/\/github.com\/Microsoft\/LightGBM\/tree\/master\/examples\n    - parameters:https:\/\/github.com\/Microsoft\/LightGBM\/blob\/master\/docs\/Parameters.rst\n- \u65e5\u672c\u8a9e\u8cc7\u6599\n    - [LightGBM \u30cf\u30f3\u30ba\u30aa\u30f3 \\- \u3082\u3046\u4e00\u3064\u306eGradient Boosting\u30e9\u30a4\u30d6\u30e9\u30ea \\- Qiita](https:\/\/qiita.com\/TomokIshii\/items\/3729c1b9c658cc48b5cb)\n    - [Python: LightGBM \u3092\u4f7f\u3063\u3066\u307f\u308b \\- CUBE SUGAR CONTAINER](https:\/\/blog.amedama.jp\/entry\/2018\/05\/01\/081842)\n    - [NIPS2017\u8aad\u307f\u4f1a@\u30af\u30c3\u30af\u30d1\u30c3\u30c9\u3067LightGBM\u306e\u8ad6\u6587\u7d39\u4ecb\u3057\u3066\u304d\u305f\uff08\u5168\u767a\u8868\u8cc7\u6599\u30ea\u30f3\u30af\u4ed8\u304d\uff09 \\- tkm2261's blog](http:\/\/yutori-datascience.hatenablog.com\/entry\/2018\/01\/29\/220935)\n    - [Santander Product Recommendation\u306e\u30a2\u30d7\u30ed\u30fc\u30c1\u3068XGBoost\u306e\u5c0f\u30cd\u30bf \\- Speaker Deck](https:\/\/speakerdeck.com\/rsakata\/santander-product-recommendationfalseapurotitoxgboostfalsexiao-neta)\n  "}}