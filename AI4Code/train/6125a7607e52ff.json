{"cell_type":{"9c28f377":"code","31efe293":"code","2d26d5dd":"code","12541688":"code","e3fb4a4a":"code","128e39be":"code","6b8e77c7":"code","16a5ef04":"code","2914fecd":"code","8e91c873":"code","fa55b1b8":"code","e90e6ad6":"code","8824d6b0":"code","950e1914":"code","84c1d6ba":"code","674603b4":"code","9b3a2059":"code","ea8fb60e":"code","05a1190a":"code","62115e24":"markdown","cc150a48":"markdown","0f5f3451":"markdown","9ea41e83":"markdown","939a2db7":"markdown","7b0f63ba":"markdown","3872b9e3":"markdown","c55bf0c6":"markdown"},"source":{"9c28f377":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import f1_score\nimport lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold,KFold,GridSearchCV,GroupKFold,train_test_split\n# from rfpimp import *\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","31efe293":"\n\ndf_train = pd.read_csv('\/kaggle\/input\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/test.csv')\ndf_sub = pd.read_csv('\/kaggle\/input\/sample_submission.csv')\n","2d26d5dd":"df_train.isnull().sum()","12541688":"df_train['Loan_Amount_Requested'] = df_train['Loan_Amount_Requested'].apply(lambda x: eval(''.join(x.split(','))))\ndf_test['Loan_Amount_Requested'] = df_test['Loan_Amount_Requested'].apply(lambda x: eval(''.join(x.split(','))))","e3fb4a4a":"df_train['Closed'] = df_train['Total_Accounts'] - df_train['Number_Open_Accounts']\ndf_test['Closed'] = df_test['Total_Accounts'] - df_test['Number_Open_Accounts']","128e39be":"df_train.replace({'Length_Employed': {'1 year': '0-2 years',\n                                     '2 years':'0-2 years',\n                                     '3 years':'3-5 years',\n                                     '4 years': '3-5 years',\n                                      '5 years': '3-5 years',\n                                     '6 years': '6-7 years',\n                                     '7 years':'6-7 years',\n                                     '8 years':'8-9 years',\n                                     '9 years':'8-9 years',\n                                     '< 1 year':'0-2 years'}},inplace=True)\ndf_test.replace({'Length_Employed': {'1 year': '0-2 years',\n                                     '2 years':'0-2 years',\n                                     '3 years':'3-5 years',\n                                     '4 years': '3-5 years',\n                                      '5 years': '3-5 years',\n                                     '6 years': '6-7 years',\n                                     '7 years':'6-7 years',\n                                     '8 years':'8-9 years',\n                                     '9 years':'8-9 years',\n                                     '< 1 year':'0-2 years'}},inplace=True)","6b8e77c7":"length = {'10+ years': 10,\n '2 years': 2,\n '3 years': 3,\n '< 1 year': 0,\n '5 years': 5,\n '1 year': 1,\n '4 years': 4,\n '7 years': 7,\n '6 years': 6,\n '8 years': 8,\n '9 years': 9}\nlen_new =  {\n    '3-5 years':1,\n    '6-7 years':2,\n    '8-9 years':3,\n    '0-2 years':0,\n    '10+ years':4\n}\nhome = {'Mortgage': 0,\n 'Rent': 1,\n 'Own': 2,\n 'Other': 3,\n 'None': 4}\nincome = {'VERIFIED - income': 0,\n 'VERIFIED - income source': 1,\n 'not verified':2}\npurp = {'debt_consolidation': 0,\n 'credit_card': 1,\n 'home_improvement':2,\n 'other': 3,\n 'major_purchase': 4,\n 'small_business': 5,\n 'car': 6,\n 'medical': 7,\n 'moving': 8,\n 'vacation': 9,\n 'wedding': 10,\n 'house': 11,\n 'renewable_energy': 12,\n 'educational': 13}\ngender = {'Male': 0, 'Female': 1}\ntarget_lgb = {\n    1:0,\n    2:1,\n    3:2\n}\n\nlgb_target = {\n    0:1,\n    1:2,\n    2:3\n}","16a5ef04":"df_train['Length_Employed'] = df_train['Length_Employed'].map(len_new)\ndf_train['Home_Owner'] = df_train['Home_Owner'].map(home)\ndf_train['Home_Owner'] = df_train['Home_Owner'].fillna(-99999)\ndf_train['Income_Verified'] = df_train['Income_Verified'].map(income)\ndf_train['Purpose_Of_Loan'] = df_train['Purpose_Of_Loan'].map(purp)\ndf_train['Gender'] = df_train['Gender'].map(gender)\ndf_train['Interest_Rate'] = df_train['Interest_Rate'].map(target_lgb)","2914fecd":"df_test['Length_Employed'] = df_test['Length_Employed'].map(len_new)\ndf_test['Home_Owner'] = df_test['Home_Owner'].map(home)\ndf_test['Home_Owner'] = df_test['Home_Owner'].fillna(-99999)\ndf_test['Income_Verified'] = df_test['Income_Verified'].map(income)\ndf_test['Purpose_Of_Loan'] = df_test['Purpose_Of_Loan'].map(purp)\ndf_test['Gender'] = df_test['Gender'].map(gender)\n# df_test['Interest_Rate'] = df_test['Interest_Rate'].map(target_lgb)","8e91c873":"df_train.drop('Loan_ID',axis=1,inplace=True)\ndf_test.drop('Loan_ID',axis=1,inplace=True)","fa55b1b8":"df_train = pd.get_dummies(data=df_train,columns=['Home_Owner','Purpose_Of_Loan','Income_Verified'])\ndf_test = pd.get_dummies(data=df_test,columns=['Home_Owner','Purpose_Of_Loan','Income_Verified'])","e90e6ad6":"df_train['Loan_Amount_Requested_New'] = df_train['Loan_Amount_Requested']\ndf_test['Loan_Amount_Requested_New']= df_test['Loan_Amount_Requested']","8824d6b0":"cumulative_sum = df_train.groupby('Loan_Amount_Requested_New')[\"Interest_Rate\"].cumsum() - df_train[\"Interest_Rate\"]\ncumulative_count = df_train.groupby('Loan_Amount_Requested_New').cumcount()\ndf_train['Loan_Amount_Requested_New' + \"_mean_target\"] = cumulative_sum\/cumulative_count","950e1914":"vals = df_train.groupby('Loan_Amount_Requested_New').agg({'Interest_Rate':['mean']})\nvals.columns = [x[0] for x in vals.columns]\nvals.rename(columns={'Interest_Rate':'Loan_Amount_Requested_New_mean_target'},inplace=True)","84c1d6ba":"df_test = pd.merge(df_test,vals,on='Loan_Amount_Requested_New',how='left')\ndf_train.drop(['Loan_Amount_Requested_New'],axis=1,inplace=True)\ndf_test.drop(['Loan_Amount_Requested_New'],axis=1,inplace=True)","674603b4":"X_train = df_train.drop('Interest_Rate',axis=1)\ny_train = df_train['Interest_Rate']","9b3a2059":"k =['Loan_Amount_Requested',\n 'Inquiries_Last_6Mo',\n 'Months_Since_Deliquency',\n 'Purpose_Of_Loan_1',\n 'Annual_Income',\n 'Debt_To_Income',\n 'Income_Verified_2',\n 'Closed',\n 'Income_Verified_0',\n 'Purpose_Of_Loan_3',\n 'Purpose_Of_Loan_0',\n 'Home_Owner_1.0',\n 'Length_Employed',\n 'Purpose_Of_Loan_5',\n 'Total_Accounts',\n 'Purpose_Of_Loan_8',\n 'Purpose_Of_Loan_6',\n 'Number_Open_Accounts',\n 'Home_Owner_0.0',\n 'Purpose_Of_Loan_4',\n 'Purpose_Of_Loan_7',\n 'Purpose_Of_Loan_9',\n 'Purpose_Of_Loan_2',\n 'Purpose_Of_Loan_13',\n 'Income_Verified_1',\n 'Gender',\n 'Home_Owner_-99999.0',\n 'Purpose_Of_Loan_11',\n   'Loan_Amount_Requested_New_mean_target']","ea8fb60e":"splits = 5\nfolds = StratifiedKFold(n_splits=splits, shuffle=True, random_state=22)\n# predictions = np.zeros((len(X_valid), 3))\noof_preds = np.zeros((len(df_test), 3))\nfeature_importance_df = pd.DataFrame()\nfinal_preds = []\n# random_state = [77,89,22,1007,1997,1890,2000,2020,8989,786,787,1999992,2021,7654]\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n        print(\"Fold {}\".format(fold_))\n        X_trn,y_trn = X_train[k].iloc[trn_idx],y_train.iloc[trn_idx]\n        X_val,y_val = X_train[k].iloc[val_idx],y_train.iloc[val_idx]\n        clf = lgb.LGBMClassifier(random_state=22,n_jobs=-1,max_depth=-1,min_data_in_leaf=24,num_leaves=49,bagging_fraction=0.01,\n                        colsample_bytree=1.0,lambda_l1=1,lambda_l2=11,learning_rate=0.1,n_estimators=5000)\n        clf.fit(X_trn, y_trn, eval_metric='multi_logloss', eval_set=[(X_val,y_val)], verbose=False,early_stopping_rounds=100)\n        y_val_preds = clf.predict_proba(X_val)\n        final_preds.append(f1_score(y_pred=[np.argmax(x) for x in y_val_preds],y_true=y_val,average='weighted'))\n#         predictions += clf.predict_proba(X_valid)\n        oof_preds += clf.predict_proba(df_test[k])\n#         counter = counter + 1\noof_preds = oof_preds\/splits\nprint(sum(final_preds)\/5)","05a1190a":"df_sub['Interest_Rate'] = [np.argmax(x) for x in oof_preds]\ndf_sub['Interest_Rate'] = df_sub['Interest_Rate'].map(lgb_target)\ndf_sub.to_csv('5Final.csv',index=False)","62115e24":"For Home_owner i just filled it with -9999 and converted into one hot encoded also,for all the other columns i just didnt fill any value because it just didnt really make sense, The methods i tried was imputation by mean,median or mode(for categorical) also i tried basically filling annual income on the basis of how many years a person is employed For.","cc150a48":"The above feature really bumps up your scores a lot","0f5f3451":"So for the null handelling basically the most null values was in the months since deliquency column and if you see max and min of that ypu will find out that they only check if deliquency occured in last 180 months or not they go beyond that probably it means maybe they don't care if its beyond that so it was apt that I dont fill the Nan's.Let the LGB handle it.","9ea41e83":"I think the most important feature that bumped up my score was mean encoding the Loan Requested feature so i used mean expanded encoding and it worked like a charm and i got a very good score jump.","939a2db7":"I also selected some features using feature importance and my final features were pretty stable.","7b0f63ba":"This Configuration will give you 53.972 Score on the private leaderboard.\nWith blending and some high level feature interactions you can get to the top place.","3872b9e3":"The above were my best features and you can just check if you can get a good score","c55bf0c6":"Firstly i just tried using encoding this length employed ordinally but it really didnt seem to work, so then i just checked some stats so what i found out was the mean values for the loan amount requested for some years was the same.But why did i do that analysis was because it seemed that there was interaction between Length Employed and loan taken column."}}