{"cell_type":{"bae365cf":"code","49a76ac4":"code","fd533c6d":"code","a937c2b3":"code","627d7da8":"code","12c8d927":"code","6587a043":"code","49061c8f":"code","92fe2f53":"code","e2848743":"code","3fef6eb0":"code","d8bc3364":"code","b6ee6de8":"code","d096e4e7":"code","7c190b20":"code","b78f23ed":"code","36e3ffa2":"code","000c8346":"code","3fb239d2":"code","146b87da":"code","77ed92c0":"code","c121da1a":"code","57380138":"code","a08b82d1":"code","af53c1a9":"code","e9ba551d":"code","bcc76341":"code","fec950c7":"code","76b97885":"code","f1d32d8d":"code","3658d375":"markdown","d196bcec":"markdown","3c9ff5fd":"markdown","7c091dca":"markdown","526832e4":"markdown","6e46ed18":"markdown","5bb73ed7":"markdown","52f3bfda":"markdown","958847aa":"markdown","99b70240":"markdown","511dd712":"markdown","7b8e079b":"markdown","5bae7cb7":"markdown","67beef5f":"markdown","cfc4c78b":"markdown"},"source":{"bae365cf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nplt.style.use(\"fivethirtyeight\")\nplt.rcParams['xtick.labelsize']=8\nplt.rcParams['ytick.labelsize']=8\n\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import mean_squared_error, accuracy_score,confusion_matrix, roc_curve, auc,classification_report, recall_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split,RandomizedSearchCV\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","49a76ac4":"train_data = pd.read_csv(\"\/kaggle\/input\/GiveMeSomeCredit\/cs-training.csv\")\ntrain_data.drop(\"Unnamed: 0\", axis=1, inplace=True)\ntrain_data.describe()","fd533c6d":"plt.figure(figsize=(8,3))\ntrain_data['SeriousDlqin2yrs'].value_counts().plot(kind='bar')","a937c2b3":"class0 = train_data['SeriousDlqin2yrs'].value_counts()[0]\nclass1 = train_data['SeriousDlqin2yrs'].value_counts()[1]\nprint(\"class 0 : {}\".format(class0))\nprint(\"class 1 : {}\".format(class1))\nprint(\"delinquency rate: {}\".format(class1\/(class0+class1)))","627d7da8":"train_data[train_data['age'] < 18]","12c8d927":"plt.figure(figsize=(8,3))\nsns.boxplot(train_data['age'])","6587a043":"train_data.loc[train_data['age'] < 18, 'age'] = train_data['age'].median()\ncols =[\"NumberOfTime30-59DaysPastDueNotWorse\",\"NumberOfTime60-89DaysPastDueNotWorse\",\"NumberOfTimes90DaysLate\", \"DebtRatio\",\"NumberOfOpenCreditLinesAndLoans\",\"NumberRealEstateLoansOrLines\", \"RevolvingUtilizationOfUnsecuredLines\"]\nfig, axes = plt.subplots(len(cols),1, figsize=(10,10))\ni = 0\nfor c in cols:\n    ax = sns.boxplot(train_data[c], ax = axes[i])\n    ax.set_ylabel(c, rotation=0,labelpad=150)\n    ax.set_xlabel(\"Number of Times\")\n    i +=1\nplt.show()","49061c8f":"debtratio_q = train_data[\"DebtRatio\"].quantile(0.86)\nprint(\"Debt Ratio: {}\".format(debtratio_q))\n\ncolormap = {0:'blue', 1:'red'}\n\nfig, (ax1, ax2) = plt.subplots(1,2,  figsize=(15,4))\nfor delinquency, color in colormap.items():\n    tmp = train_data[(train_data['DebtRatio'] > debtratio_q) & (train_data['SeriousDlqin2yrs']==delinquency)][['DebtRatio','MonthlyIncome']]\n    ax1.scatter((tmp['DebtRatio']), (tmp['MonthlyIncome']), c=color, alpha=0.8, label= str(delinquency) + \":{}\".format(tmp.shape[0]))\nax1.legend()\nax1.set_title(\"Debt Ratio 86% Quantile against Monthly Income\",fontsize=10)\nax1.set_xlabel(\"DebtRatio\")\nax1.set_ylabel(\"Monthly Income\")\n\nfor delinquency, color in colormap.items():\n    tmp = train_data[(train_data['SeriousDlqin2yrs']==delinquency)][['DebtRatio','MonthlyIncome']]\n    ax2.scatter(np.log(tmp['DebtRatio']), np.log(tmp['MonthlyIncome']), c=color, alpha=0.8, label= str(delinquency) + \":{}\".format(tmp.shape[0]))\nax2.legend()\nax2.set_title(\"Log of Debt Ratio against log of Monthly Income\",fontsize=10)\nax2.set_xlabel(\"log(DebtRatio)\")\nax2.set_ylabel(\"log(Monthly Income)\")\nplt.show()","92fe2f53":"print(\"Number of records with monthly income equals 1: {}\".format(train_data[(train_data['MonthlyIncome'] == 1) ].shape[0]))","e2848743":"train_data[\"DebtRatio\"] = np.log(train_data[\"DebtRatio\"])\nremovedmonthincome_1 = train_data[train_data[\"MonthlyIncome\"] != 1]\nremovedmonthincome_1[\"DebtRatio\"].replace([np.inf, -np.inf], -10, inplace=True)\nremovedmonthincome_1.describe()","3fef6eb0":"u_list = []\nd_list = []\nfor u in range(int(train_data['RevolvingUtilizationOfUnsecuredLines'].max())):\n    default_rate = train_data[train_data['RevolvingUtilizationOfUnsecuredLines'] > u]['SeriousDlqin2yrs'].mean()\n    u_list.append(u)\n    d_list.append(default_rate)\nfig, (ax1,ax2)= plt.subplots(1,2, figsize=(15,4))\ndf = pd.DataFrame({\"utilization\":u_list, \"default\":d_list})\ndf.plot(\"utilization\",\"default\",ax=ax1)\nax1.set_ylabel(\"Default Rate\")\nax1.set_xlabel(\"Utilization Ratio\")\n\nutilization_outlier = df[df.default==0]['utilization'].min()\nprint(\"Remove Outliers at point UtilizatoinRation={}\".format(utilization_outlier))\n\ndftmp = df[df < utilization_outlier]\ndftmp.plot(\"utilization\",\"default\",ax=ax2)\nax2.plot([3500 for i in range(dftmp.shape[0])], np.linspace(0,0.35,dftmp.shape[0]), 'r--')\nax2.plot([6200 for i in range(dftmp.shape[0])], np.linspace(0,0.35,dftmp.shape[0]), 'r--')\nax2.set_ylabel(\"Default Rate\")\nax2.set_xlabel(\"Utilization Ratio\")","d8bc3364":"removedUtilization = train_data[train_data.RevolvingUtilizationOfUnsecuredLines <= utilization_outlier]\n\ndef categorize_utilization(u):\n    if u < 3500:\n        return 0\n    elif (u >= 3500) & (u < 6200):\n        return 1\n    else:\n        return 2\n    \nremovedUtilization[\"UtlizationCategory\"] = removedUtilization[\"RevolvingUtilizationOfUnsecuredLines\"].apply(categorize_utilization)","b6ee6de8":"cols = train_data.columns\nnullcounts = []\nvalue_counts = []\nfor col in cols:\n    nullcounts.append(train_data[col].isnull().sum())\n    value_counts.append(train_data[col].shape[0] - train_data[col].isnull().sum())\n\nfig, ax = plt.subplots(figsize=(10,3))\nax.barh(cols, value_counts, label='not missing')\nax.barh(cols, nullcounts, label='missing', left=value_counts)\nax.set_xlabel('Value Count')\nax.set_ylabel('Labels')\nplt.show()","d096e4e7":"imputedf = train_data[['age','NumberOfDependents','MonthlyIncome']].copy()\n\ndef categorizeAge(age):\n    if (age < 35):\n        return 'junior'\n    elif (age >= 35) & (age < 60):\n        return'senior'\n    else:\n        return 'mature'\n\nimputedf['seniority'] = imputedf['age'].apply(categorizeAge)\nincome_dict = imputedf.groupby('seniority')['MonthlyIncome'].mean().to_dict()\nincome_dict","7c190b20":"#Impute Monthly Income by median of seniority\nfor k, v in income_dict.items():\n    imputedf[\"MonthlyIncome\"] = np.where((imputedf[\"MonthlyIncome\"].isnull()) & (imputedf['seniority'] == k), int(v), imputedf[\"MonthlyIncome\"])\ntrain_data['MonthlyIncome'] = imputedf[\"MonthlyIncome\"]\n# Impute NumberOfDependents with Mode\nprint(train_data['NumberOfDependents'].mode())\n# Fill na with mode \ntrain_data['NumberOfDependents'].fillna(0, inplace=True)","b78f23ed":"corr = train_data.corr()\nplt.figure(figsize=(10,10))\nsns.heatmap(corr, annot=True, fmt=\".2f\")","36e3ffa2":"print(train_data[\"NumberOfTime30-59DaysPastDueNotWorse\"].sort_values().unique())\nprint(train_data[\"NumberOfTime60-89DaysPastDueNotWorse\"].sort_values().unique())\nprint(train_data[\"NumberOfTimes90DaysLate\"].sort_values().unique())","000c8346":"tmpdf = train_data[(train_data[\"NumberOfTime30-59DaysPastDueNotWorse\"] == 98) & (train_data[\"NumberOfTime60-89DaysPastDueNotWorse\"] == train_data[\"NumberOfTime30-59DaysPastDueNotWorse\"]) & (train_data[\"NumberOfTimes90DaysLate\"] == train_data[\"NumberOfTime60-89DaysPastDueNotWorse\"])][cols]\nprint(\"98 times past due where 3 columns have same value: {}\".format(tmpdf.shape[0]))","3fb239d2":"# Impute outliers with max value\ntimes_map = {\"NumberOfTime30-59DaysPastDueNotWorse\": 13, \"NumberOfTime60-89DaysPastDueNotWorse\":11, \"NumberOfTimes90DaysLate\":17}\nfor col, v in times_map.items():\n    train_data.loc[train_data[col] >= 96, col] = times_map[col]\ntrain_data[\"CombinedPastDue\"] = train_data[\"NumberOfTime30-59DaysPastDueNotWorse\"] + train_data[\"NumberOfTime60-89DaysPastDueNotWorse\"] + train_data[\"NumberOfTimes90DaysLate\"]\ntrain_data[\"CombinedCreditLoans\"] = train_data[\"NumberOfOpenCreditLinesAndLoans\"] + train_data[\"NumberRealEstateLoansOrLines\"]\nincome_dict","146b87da":"def categorizeAge(age):\n    if (age < 35):\n        return 'junior'\n    elif (age >= 35) & (age < 60):\n        return'senior'\n    else:\n        return 'mature'\n    \ndef data_preprocess(df, is_submission=False):\n    print(\"Shape before: {}\".format(df.shape))\n    df.loc[df['age'] < 18, 'age'] = df['age'].median()\n    \n    df[\"DebtRatio\"] = np.log(df[\"DebtRatio\"])\n    df[\"DebtRatio\"].replace([np.inf, -np.inf], -10, inplace=True)\n    if not is_submission:\n        df = df[df[\"MonthlyIncome\"] != 1]\n    \n    utilization_outlier = 8328\n    if not is_submission:\n        df = df[df.RevolvingUtilizationOfUnsecuredLines <= utilization_outlier]\n#     df[\"UtlizationCategory\"] = df[\"UtilisationRatio\"].apply(categorize_utilization)\n    \n    imputedf = df[['age','NumberOfDependents','MonthlyIncome']].copy()\n    imputedf['seniority'] = imputedf['age'].apply(categorizeAge)\n    income_dict = imputedf.groupby('seniority')['MonthlyIncome'].mean().to_dict()\n    for k, v in income_dict.items(): \n        imputedf[\"MonthlyIncome\"] = np.where((imputedf[\"MonthlyIncome\"].isnull()) & (imputedf['seniority'] == k), int(v), imputedf[\"MonthlyIncome\"])\n    df['MonthlyIncome'] = imputedf[\"MonthlyIncome\"]\n    df['NumberOfDependents'].fillna(0, inplace=True)\n    \n    times_map = {\"NumberOfTime30-59DaysPastDueNotWorse\": 13, \"NumberOfTime60-89DaysPastDueNotWorse\":11, \"NumberOfTimes90DaysLate\":17}\n    for col, v in times_map.items():\n        df.loc[df[col] >= 96, col] = times_map[col]\n    \n    df[\"CombinedPastDue\"] = df[\"NumberOfTime30-59DaysPastDueNotWorse\"] + df[\"NumberOfTime60-89DaysPastDueNotWorse\"] + df[\"NumberOfTimes90DaysLate\"]\n    \n    df[\"CombinedCreditLoans\"] = df[\"NumberOfOpenCreditLinesAndLoans\"] + df[\"NumberRealEstateLoansOrLines\"]\n    \n    print(\"Shape after: {}\".format(df.shape))\n    return df\n\ntrain_data = pd.read_csv(\"\/kaggle\/input\/GiveMeSomeCredit\/cs-training.csv\")\ntrain_data.drop(\"Unnamed: 0\", axis=1, inplace=True)\n\ntrain_data = data_preprocess(train_data)","77ed92c0":"corr = train_data.corr()\nplt.figure(figsize=(10,10))\nsns.heatmap(corr, annot=True, fmt=\".2f\")","c121da1a":"train_data.columns","57380138":"cols_drop = [\"NumberOfTimes90DaysLate\",\"NumberOfTime60-89DaysPastDueNotWorse\",\"NumberOfOpenCreditLinesAndLoans\",\"NumberRealEstateLoansOrLines\"]\ntrain_data.drop(cols_drop, axis=1, inplace=True)\ntrain_data.sample(5)","a08b82d1":"X_train, X_test, y_train, y_test = train_test_split(train_data.iloc[:,1:], train_data.iloc[:,0], random_state=42)\nscaler = StandardScaler().fit(X_train)\n\nX_train_scaled = scaler.transform(X_train) \nX_test_scaled = scaler.transform(X_test)\nlogit = LogisticRegression(random_state=42)\nl_model = logit.fit(X_train_scaled, y_train)\nlogit_scores_proba  = l_model.predict_proba(X_test_scaled)\nlogit_scores = logit_scores_proba[:,1]\ndef plot_roc(y_test, y_predict):\n    fpr, tpr, _ = roc_curve(y_test, y_predict)\n    roc_auc = auc(fpr,tpr)\n    print(roc_auc)\n    plt.figure(figsize=(10,8))\n    plt.title(\"ROC curve\")\n    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0,1], [0,1],'r--')\n    plt.legend(loc=\"lower right\")\nplot_roc(y_test, logit_scores)","af53c1a9":"random_forest = RandomForestClassifier()\nparam_grid={\n    \"n_estimators\":[9,18,27,36,100],\n    \"max_depth\":[5,7,9],\n    \"min_samples_leaf\":[2,4,6,8]\n}\nrf_model = RandomizedSearchCV(random_forest, param_distributions = param_grid, cv=5)\nrf_model.fit(X_train, y_train)","e9ba551d":"rf_model.best_params_","bcc76341":"best_est_rf = rf_model.best_estimator_\nbest_est_rf.fit(X_train, y_train)\ny_pred_rf = best_est_rf.predict_proba(X_test)[:,1]\nplot_roc(y_test, y_pred_rf)","fec950c7":"def plot_feature_importances(model):\n    plt.figure(figsize=(10,8))\n    n_features = X_train.shape[1]\n    plt.barh(range(n_features), model.feature_importances_, align='center')\n    plt.yticks(np.arange(n_features), X_train.columns)\n    plt.xlabel(\"Feature importance\")\n    plt.ylabel(\"Feature\")\n    plt.ylim(-1, n_features)\n\nplot_feature_importances(best_est_rf)","76b97885":"test_data = pd.read_csv(\"\/kaggle\/input\/GiveMeSomeCredit\/cs-test.csv\")\ntest_data.drop(\"Unnamed: 0\", axis=1, inplace=True)\n\ntest_data = data_preprocess(test_data, True)\n\ncols_drop = [\"SeriousDlqin2yrs\",\"NumberOfTimes90DaysLate\",\"NumberOfTime60-89DaysPastDueNotWorse\",\"NumberOfOpenCreditLinesAndLoans\",\"NumberRealEstateLoansOrLines\"]\ntest_data.drop(cols_drop, axis=1, inplace=True)\ntest_data.shape","f1d32d8d":"submission_score = best_est_rf.predict_proba(test_data)[:,1]\n\nids = np.arange(1,101504)\nsubmission = pd.DataFrame( {'Id': ids, 'Probability': submission_score})\nsubmission.to_csv(\"\/kaggle\/working\/gimme_submision.csv\", index=False)","3658d375":"\u6211\u4eec\u53ef\u4ee5\u770b\u5230\uff0c\u8d1f\u503a\u7387\u6700\u9ad8\u768414%\u7684\u8bb0\u5f55\u7684\u6708\u6536\u5165\u4e3a0\u62161\u3002\u8fd9\u4e9b\u8bb0\u5f55\u4e2d\u7684\u503a\u52a1\u4e0e\u6536\u5165\u4e4b\u6bd4\u8d85\u8fc7453\u500d\u3002\u6000\u7591\u5f53\u6708\u6536\u5165\u4e3a1\uff0c\u800c\u8d1f\u503a\u6bd4\u7387\u8f83\u9ad8\u65f6\uff0c\u7ed9\u51fa\u7684\u6570\u636e\u8f93\u5165\u9519\u8bef\u6216\u4fe1\u606f\u4e0d\u5b8c\u6574\u3002\n\u7531\u6b64\uff0c\u6211\u4eec\u53ef\u4ee5\u53d6\u8d1f\u503a\u7387\u7684\u5bf9\u6570\uff0c\u5220\u9664\u6bcf\u6708\u6536\u5165\u4e3a1\u7684\u8bb0\u5f55","d196bcec":"\u4f7f\u7528\u7387\n\n\u9884\u8ba1\u5229\u7528\u7387\u8d8a\u9ad8\uff0c\u8fdd\u7ea6\u7387\u8d8a\u9ad8\u3002\u901a\u8fc7\u7ed8\u5236\u5229\u7528\u7387\u4e0e\u8fdd\u7ea6\u7387\u7684\u5173\u7cfb\u56fe\u6765\u7814\u7a76\u5b83","3c9ff5fd":"\u6570\u636e\u5904\u7406","7c091dca":"\u903b\u8f91\u56de\u5f52\u6a21\u578b","526832e4":"\u8d1f\u503a\u6bd4\u7387","6e46ed18":"\u968f\u673a\u68ee\u6797","5bb73ed7":"\u4ece\u8fdd\u7ea6\u7387\u4e0e\u5229\u7528\u7387\u7684\u5173\u7cfb\u56fe\u4e2d\u53ef\u4ee5\u89c2\u5bdf\u5230\uff0c\u5f53\u5229\u7528\u7387\u589e\u52a0\u5230\u67d0\u4e2a\u70b9\u65f6\uff0c\u8fdd\u7ea6\u7387\u505c\u6b62\u589e\u52a0\uff0c\u5e76\u8fbe\u5230\u96f6\u3002\u53e6\u5916\uff0c\u4f3c\u4e4e\u6709\u4e09\u7ec4\u5229\u7528\u7387\u4e0e\u8fdd\u7ea6\u7387\u5448\u7ebf\u6027\u5173\u7cfb\u3002\n\u7531\u6b64\uff0c\u6211\u4eec\u53ef\u4ee5\u5f53\u8fdd\u7ea6\u7387\u505c\u6b62\u589e\u52a0\u65f6\uff0c\u5728\u5229\u7528\u7387\u70b9\u5220\u9664\u5f02\u5e38\u503c\u521b\u5efa\u4e00\u4e2a\u65b0\u7279\u6027\uff0c\u5c06\u5229\u7528\u7387\u5206\u4e3a3\u7ec4","52f3bfda":"\u53ea\u6709\u4e24\u4e2a\u7279\u6027\u7f3a\u5c11\u503c\u3002\u7531\u6b64\u6211\u4eec\u53ef\u4ee5\u5c06\u6708\u6536\u5165\u4e0e\u6309\u5e74\u9f84\u5206\u7c7b\u7684\u4e09\u7ec4\u5e73\u5747\u6536\u5165\u76f8\u52a0\uff0c\n\u5e76\u7528\u5b83\u7684\u6a21\u5f0f\u6765\u8ba1\u7b97\u4f9d\u8d56\u6570","958847aa":"\u201cN\u5929\u903e\u671f\u201d\u7279\u6027\u548c\u4e00\u4e9b\u79bb\u7fa4\u503c\u4e4b\u95f4\u5b58\u5728\u9ad8\u5ea6\u76f8\u5173\u6027\uff0c\u7531\u6b64\u6211\u4eec\u53ef\u4ee5\n\u586b\u5145\u79bb\u7fa4\u503c\uff0c\n\u5408\u5e76(N\u5929\u8fc7\u671f)\u4f5c\u4e3a\u65b0\u7279\u5f81\uff0c\n\u5408\u5e76(\u4fe1\u7528\u989d\u5ea6\u548c\u8d37\u6b3e)\u4f5c\u4e3a\u65b0\u7279\u5f81","99b70240":"\u7f3a\u5931\u503c","511dd712":"\u6807\u7b7e\u5206\u914d","7b8e079b":"\u5e74\u9f84","5bae7cb7":"\u5c06\u5e74\u9f84\u5c0f\u4e8e18\u7684\u586b\u5145\u4e3a\u4e2d\u4f4d\u6570","67beef5f":"\u63d0\u4ea4","cfc4c78b":"\u76f8\u5173\u7279\u6027"}}