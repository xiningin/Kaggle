{"cell_type":{"58305a72":"code","ac246b8f":"code","5bc13038":"code","ee7ae406":"code","b596708b":"code","d3167285":"code","9fa43bee":"code","0f9ec9f8":"code","0830645d":"code","6aaa6dc2":"code","e0350c2b":"markdown","8ef77980":"markdown","43451347":"markdown","3bace19e":"markdown"},"source":{"58305a72":"import re\nimport numpy as np\nimport pandas as pd\nfrom string import punctuation, printable, digits\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.layers import Dense\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.models import Sequential, load_model\n\nfrom matplotlib import pyplot as plt\nplt.style.use('ggplot')\n\nimport spacy\nnlp = spacy.load('en_core_web_sm')","ac246b8f":"# Load data\ntrain_df = pd.read_csv('..\/input\/word2vec-nlp-tutorial\/labeledTrainData.tsv.zip', delimiter = \"\\t\", encoding = 'utf-8')\ntest_df = pd.read_csv('..\/input\/word2vec-nlp-tutorial\/testData.tsv.zip', delimiter = \"\\t\", encoding = 'utf-8')\n\ncombined_dfs = [train_df, test_df]","5bc13038":"# Remove HTML tags\ndef remove_html(text: str, replacement = ' ') -> str:\n    return re.sub(r'<.*?>', replacement, text)\n\n# Remove non-ASCII characters\ndef filter_printables(text: str) -> str:\n    return ''.join(filter(lambda x: x in printable, text))\n\n# Remove numbers from the string\ndef remove_numbers(string: str) -> str:\n    return string.translate({ord(d): None for d in digits})\n\n# Remove two backslashes\ndef remove_double_backslashes(text: str) -> str:\n    return text.replace('\\\\', '')\n\n# Remove all punctuations\ndef remove_punctuation(string: str, repl: str = '') -> str:\n    return string.translate(str.maketrans('', '', punctuation))\n\n# Fix multiple spacings\ndef fix_spacing(string: str) -> str:\n    return ' '.join(string.split())\n\n# Lemmatize all words\ndef lemmatize(string: str) -> str:\n    return ' '.join([token.lemma_ for token in nlp(string)])","ee7ae406":"for df in combined_dfs:\n    df['review'] = df['review'].apply(remove_html)\n    df['review'] = df['review'].apply(remove_numbers)\n    df['review'] = df['review'].apply(filter_printables)\n    df['review'] = df['review'].apply(remove_double_backslashes)\n    df['review'] = df['review'].apply(remove_punctuation)\n#     df['review'] = df['review'].apply(lemmatize)\n    df['review'] = df['review'].apply(fix_spacing)","b596708b":"words_counts = train_df['review'].apply(lambda x: len(x.split())).values\nplt.hist(words_counts)\nplt.show()","d3167285":"from keras.preprocessing.text import Tokenizer\n\ntokenizer = Tokenizer(\n  num_words = 1000,       # the maximum number of words to keep (Only the most common num_words-1 words will be kept)\n  lower = True,           # boolean. Whether to convert the texts to lowercase.\n  split = ' ',            # str. Separator for word splitting.\n  char_level = False,     # if True, every character will be treated as a token.\n  oov_token = None        # replaces out-of-vocabulary words during text_to_sequence calls with oov_token\n)\ntokenizer.fit_on_texts(train_df['review'])   # can be a list of strings\n\n# Modes: 'binary', 'count', 'freq', 'tfidf'\nX_train = tokenizer.texts_to_matrix(train_df['review'], mode = 'binary')\nX_test = tokenizer.texts_to_matrix(test_df['review'], mode = 'binary')\n\ny_train = train_df['sentiment']","9fa43bee":"model = Sequential()\nmodel.add(Dense(units = 64, activation = 'relu', input_shape = (X_train.shape[1],)))\nmodel.add(Dense(units = 1, activation = 'relu'))\n\nmodel.compile(\n    optimizer = 'adam',\n    loss = 'binary_crossentropy',\n    metrics = ['accuracy']\n)\nmodel.summary()","0f9ec9f8":"# Define callbacks\ncallbacks = [\n    EarlyStopping(patience = 3),\n    ModelCheckpoint(\n        filepath = 'model.h5',\n        save_best_only = True,\n        monitor = 'val_accuracy',\n        verbose = 1\n    )\n]\n\n# Train the model\nhistory = model.fit(\n    X_train,\n    y_train,\n    epochs = 10,\n    batch_size = 32,\n    validation_split = 0.2,\n    verbose = 2,\n    callbacks = callbacks\n)","0830645d":"fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (10, 5))\nepochs = [i for i in range(len(history.history['loss']))]\n\n# Loss\nax[0].plot(epochs, history.history['loss'], label = 'loss')\nax[0].plot(epochs, history.history['val_loss'], label = 'val_loss')\nax[0].legend()\n\n# Accuracy\nax[1].plot(epochs, history.history['accuracy'], label = 'accuracy')\nax[1].plot(epochs, history.history['val_accuracy'], label = 'val_accuracy')\nax[1].legend()\n\nplt.show()","6aaa6dc2":"# Make prediction\nmodel = load_model('model.h5')\npred = model.predict(X_test)\npred = (pred > 0.5).astype(int).ravel()\n\n# Create submission\nsubmission = pd.DataFrame(data = {\n    'id': test_df['id'],\n    'sentiment': pred\n})\nsubmission.to_csv('submission.csv', index = False)","e0350c2b":"## Imports & Reading the Data","8ef77980":"## Preprocessings","43451347":"Since all reviews have been divided into two balanced groups by their sentiments (Each containing 12500 reviews), we need not to worry about the metrics we are going to use. (*Accuracy* for instance be misleading on an imbalanced dataset!)","3bace19e":"# Bag of Words Meets Bags of Popcorn"}}