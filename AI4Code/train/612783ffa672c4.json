{"cell_type":{"767e4457":"code","bf14266b":"code","3d91c033":"code","86bfdaa3":"code","104aa99c":"code","9976d573":"code","5cfe8700":"code","8baa2ee0":"code","16a6eb5a":"code","fa273f7d":"code","2aa94a96":"code","e5405024":"code","dffa8a49":"code","8e2e0f0d":"code","2c586043":"code","adb86b3e":"code","f95671b7":"code","a4ef63fc":"code","aa161cdf":"code","29d8f516":"code","d4279335":"code","5d2ebccb":"code","42066729":"markdown","7ca2ab0c":"markdown","0f3476c1":"markdown","005c3d10":"markdown","e1b22d46":"markdown","38e36fc1":"markdown","9d7225f1":"markdown","424818ac":"markdown","d9618dde":"markdown","3a241d2c":"markdown","79916c4f":"markdown"},"source":{"767e4457":"# Importing libraries for EDA\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nimport tensorflow as tf\n\n# Creating dataframes for training and testing data\ntrainData = pd.read_csv('..\/input\/assignment3data\/train.csv')\nevalData = pd.read_csv('..\/input\/assignment3data\/eval.csv')\n\n# Looking for missing values\nprint('Missing data in training data: ', trainData.isnull().sum())\nprint('\\n')\nprint('Missing data in the evaluation set: ', evalData.isnull().sum())","bf14266b":"for x in trainData:\n    if (len(trainData[x].unique()) < 6):\n        print(x)\n        print(trainData[x].unique())","3d91c033":"# Unique Values in eat\nprint('Unique values in eat: ', len(trainData['Eat'].unique()))\n\n# Looking for outliers\nsns.boxplot(data=trainData['Eat'])","86bfdaa3":"print('Amount of data where Eat > -3: ', len(trainData.loc[trainData['Eat'] > -3]))\nprint('Amount of observations where Eat is < -20: ', len(trainData.loc[trainData['Eat'] < -22]))","104aa99c":"# Getting rid of the Eat column in the training set\nX = trainData.drop(['Eat'], axis=1)\ny = trainData['Eat']\n\nmodel1scores = pd.DataFrame()\nmodel2scores = pd.DataFrame()\nmodel3scores = pd.DataFrame()\n\n    \n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # I can also mess with the test split if my model overfits perhaps, however it's more likely I'm using too many features if it overfits, but we shall see\n\n\n\n\n# trying to scale data\n#X_train = preprocessing.scale(X_train)\n#X_test = preprocessing.scale(X_test)\n","9976d573":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\n\n# Creating Sequential model object\nmodel1 = Sequential()\n\n# Creating layers to the NN using Dense\nmodel1.add(Dense(512, input_shape = X_train.shape, activation = 'relu'))\nmodel1.add(Dense(128, activation = 'relu'))\nmodel1.add(Dense(64, activation = 'relu'))\n#model.add(Dense(256, activation = 'relu'))\nmodel1.add(Dense(1, activation = 'linear'))","5cfe8700":"# Compiling model\nmodel1.compile(optimizer = 'adam', loss = 'mean_squared_error')\nearlyStop = EarlyStopping(monitor='val_loss', patience = 30)","8baa2ee0":"# Fitting model, hopefully it doesn't take too long!!!!\nhistory = model1.fit(X_train, y_train, epochs=512, validation_data=(X_test, y_test), callbacks = [earlyStop])","16a6eb5a":"# Going to use a nifty little plotting function from DataCamp (Deep learning with Keras in python) in order to visualize whats going on\ndef plot_loss(loss, val_loss):\n    plt.figure()\n    plt.plot(loss)\n    plt.plot(val_loss)\n    plt.title('Loss of Model')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend(['Train', 'Test'], loc='upper right')\n    plt.show()","fa273f7d":"# plotting loss\nplot_loss(history.history['loss'], history.history['val_loss'])","2aa94a96":"# looking at mse\nmse = model1.evaluate(X_test, y_test, verbose = 0)\nprint((mse)**(1\/2))","e5405024":"# Creating Sequential model object\nmodel2 = Sequential()\n\n# Creating layers to the NN using Dense\nmodel2.add(Dense(64, input_shape = X_train.shape, activation = 'relu'))\nmodel2.add(Dense(128, activation = 'relu'))\nmodel2.add(Dense(256, activation = 'relu'))\nmodel2.add(Dense(1024, activation = 'relu'))\n#model2.add(Dense(512, activation = 'relu'))\n#model.add(Dense(256, activation = 'relu'))\nmodel2.add(Dense(1, activation = 'linear'))","dffa8a49":"# Compiling model\ncheckpoint = ModelCheckpoint('best_model.h5', monitor = 'val_loss', save_best_only = True)\nmodel2.compile(optimizer = 'adam', loss = 'mean_squared_error')","8e2e0f0d":"history2 = model2.fit(X_train, y_train, epochs=512, validation_data=(X_test, y_test), callbacks = [earlyStop,checkpoint])","2c586043":"plot_loss(history2.history['loss'], history2.history['val_loss'])\n\n# looking at mse\nmse2 = model2.evaluate(X_test, y_test, verbose = 0)\nprint((mse2)**(1\/2))","adb86b3e":"from keras.metrics import RootMeanSquaredError\nfrom keras_tuner import RandomSearch\nfrom keras_tuner.engine.hyperparameters import HyperParameters","f95671b7":"def build_model(hp):\n    model = Sequential()\n    \n    model.add(Dense(hp.Int(\"input_units\", 64, 2048, 256), input_shape = X_train.shape, activation = 'relu'))\n    for x in range(hp.Int(\"num_layers\", 1,2)):\n        model.add(Dense(hp.Int(\"hidden_units\", 2048, 4096, step=512), activation = hp.Choice(\"activation\", values=['relu','elu'])))\n    \n    model.add(Dense(1, activation = 'linear'))\n    \n    model.compile(optimizer = tf.keras.optimizers.Adam(hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4, 1e-5])), loss = 'mean_squared_error', metrics=[RootMeanSquaredError()])\n    \n    return model","a4ef63fc":"#tuner = RandomSearch(build_model, objective = 'val_loss', max_trials = 100, executions_per_trial = 1)\n#tuner.search(X_train, y_train, epochs = 200, validation_data = (X_test, y_test))\n#best_model = tuner.get_best_models()[0]","aa161cdf":"# Creating Sequential model object\nnormal = tf.keras.layers.Normalization()\nnormal.adapt(np.array(X_train))\n\nmodel3 = Sequential()\n\n# Creating layers to the NN using Dense\nmodel3.add(normal)\n#model3.add(Dense(1024, input_shape = X_train.shape, activation = 'relu'))\nmodel3.add(Dense(512, activation = 'relu'))\nmodel3.add(Dense(1024, activation = 'relu'))\nmodel3.add(Dense(2048, activation = 'relu'))\nmodel3.add(Dense(4096, activation = 'relu'))\nmodel3.add(Dense(4096, activation = 'relu'))\n\n\n\n\n\n\nmodel3.add(Dense(1, activation = 'linear'))\n\n# Compiling model\n\n\nmodel3.compile(optimizer = 'adamax', loss = 'mean_squared_error', metrics=[RootMeanSquaredError()])\nearlyStop3 = EarlyStopping(monitor='val_loss', patience = 150)","29d8f516":"history3 = model3.fit(X_train, y_train, epochs=1024, validation_data=(X_test, y_test), callbacks = [checkpoint])","d4279335":"#plot_loss(history3.history['loss'], history3.history['val_loss'])\nmodel3.load_weights('.\/best_model.h5')\nplot_loss(history3.history['loss'], history3.history['val_loss'])\n# looking at mse\nmodel3.load_weights('.\/best_model.h5')\nmse3 = model3.evaluate(X_test, y_test, verbose = 0)\nprint((mse3))\n\n","5d2ebccb":"# creating a test submission\n#model1Evaluation = model.predict(evalData, verbose = 0)\n#model1Evaluation = np.squeeze(model1Evaluation, axis = 1)\n\n#model2Eval = model2.predict(evalData, verbose = 0)\n#model2Eval = np.squeeze(model2Eval, axis = 1)\n\nmodel3Eval = model3.predict(evalData, verbose = 0)\nmodel3Eval = np.squeeze(model3Eval, axis = 1)\n\noutput = pd.DataFrame({\n    'id': evalData['id'],\n    'Eat': model3Eval\n})\n\n\noutput.to_csv('submission.csv', index=False)\nprint(output.to_string())\n","42066729":"---\n## Model 3","7ca2ab0c":"---\n# Submission","0f3476c1":"After doing a lot of hyperparameter tuning, I discovered a few things. One, I needed to do some preprocessing to get my model to perform better. Another thing was that I was not using enough neurons, and increasing the number of neurons per layer seemed to help quite a lot. However, this biggest thing that helped would be using `tf.keras.layers.Normalization()` and using that as the first layer, this boosted my position on the leaderboard by literally 60 positions. Another thing was using callbacks. Using `modelCheckpoint()` helped increase my score quite a lot, I suppose because I wasn't actually using the best model from every training session. \n\nSo yes score did have quite an impact on why I chose this model, but also I learned the most by training this one. I figured out a bunch of tips and tricks in order to help me get the best score possible. I figured out callbacks earlier in the session, but training this model made me realize I needed to normalize the data which gave me the biggest performance increase. Then it was just messing with layers, neurons, and optimizers in order to turn this into a successful model.","005c3d10":"So this is quite interesting. There's a couple of columns with a very low amount of unique values, however, I don't know what these values actually mean, so I cannot determine whether I should change these values in order to create some sort of ordinal structure. It could be possible that a extremely high value and extremely low value could result in an Eat value that is the same, and some value in that column that falls in the middle produces a different value. So it would likely not help for me to change this to an ordinal structure. Now what do these *Eat* values even mean? It's not quite clear from the documentation, so I should do a little research on it.","e1b22d46":"I called `train_test_split()` here in order to get a shape for the X_train input","38e36fc1":"Well, there's no missing values. So usually what I would do next is make boxplots for every column to check for outliers, however, there's 1277 columns which is way too many boxplots to look at, so I think I'll attempt to find out if there's a pattern to these values.","9d7225f1":"---\n## Model 2\n","424818ac":"I'm not sure whether I should drop these values because realistically, these could provide me with some quality information. It's relatively hard to do EDA on a dataset with so many columns, but perhaps there's a few cheeky things I could try.\n\n#### Note about my EDA\nAfter messing with the first two models, I quickly realized there was more I needed to do with thee data. Since I couldn't figure out exactly what feature was what or even which was the most important, I decided to standardize the data, which *destroyed* my score, in which I decided to just normalize the input, and the helped quite a bit. So later in this notebook you will see me using `tf.keras.layers.Normalization()` and implementing that as my first layer in that model.\n\n---\n# Building Models\n\nGiven the information above, I will build some models just to see what I can get away with here. I can't quite understand what is going on with the data, however, if a model that includes almost all the columns as features performs well, that could give show me whether or not there's some features that are non-helpful","d9618dde":"So it looks like the target vector only contains negative values, it also has a lot of unique values, which likely means that there will be a lot of columns that are important features. The outliers on the boxplot are still likely to be important information that I cannot simply get rid of, but I will look into how many there are go from there.","3a241d2c":"# Assignment 3\n---\n### Information\n* Julian Boaz\n* Assignment 3\n* Due Date: 11\/14\/2021\n---\n# EDA","79916c4f":"I'm going to quickly explain what's going on here so I don't confuse anyone. I was using a Random Search with Keras Tuner in order to attempt to find a better model, however for saving the output I'm going to not keep the keras tuner in the notebook, as it simply takes too many hours for me to work on the project and save it. However, what I've found so far is that a higher amount of layers AND neurons helped dramatically, as well as normalizing the data. Normalizing the data gave me a **huge** boost in performance. I even found that the `adamax` optimizer helped tremedously for my case, even though I'm not 100% familiar with the math behind it."}}