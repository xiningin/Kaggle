{"cell_type":{"785847be":"code","f37c951d":"code","ff7ceee3":"code","5646e162":"code","c3fe6b1a":"code","f835874f":"code","2a3b32eb":"code","0340e4d5":"code","4c2f9163":"code","c87300e7":"code","08a87e76":"code","03ee8c1c":"code","99226250":"code","a500007b":"code","67c0328b":"code","58e2bccd":"code","3c7db237":"code","74c6cdc1":"code","3a787963":"code","166b9ea2":"code","b9bb5831":"code","ff646af6":"code","b737e2e5":"code","49768d80":"code","b3cdca0f":"code","21d3f703":"code","9ced4fc2":"code","72049a13":"code","153eee54":"markdown","515db5ac":"markdown","a58aa1e0":"markdown","68c54153":"markdown","03e2755f":"markdown","1ed75759":"markdown","12666082":"markdown","e1d9125e":"markdown","34ae6c42":"markdown","5201b0e0":"markdown","fce8348b":"markdown","28d25635":"markdown","4ad753c1":"markdown","05fe5ada":"markdown","257ef2f5":"markdown","04dbacf7":"markdown"},"source":{"785847be":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f37c951d":"# Familiar imports\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nimport time \nimport math\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt \n\npd.plotting.register_matplotlib_converters() # register info how to plot  pd.DateTime etc. custom types\n","ff7ceee3":"!pip install sweetviz","5646e162":"\n#df = pd.read_csv(\"\/kaggle\/input\/california-housing-prices\/housing.csv\")\n#df = pd.read_csv(\"\/kaggle\/input\/health-care-data-set-on-heart-attack-possibility\/heart.csv\") #https:\/\/www.kaggle.com\/nareshbhat\/health-care-data-set-on-heart-attack-possibility\n#df = pd.read_csv(\"\/kaggle\/input\/daily-climate-time-series-data\/DailyDelhiClimateTrain.csv\")\ndf = pd.read_csv(\"\/kaggle\/input\/home-data-for-ml-course\/train.csv\")\n\ndf","c3fe6b1a":"df.describe()","f835874f":"import sweetviz as sv\n\nmy_report = sv.analyze(df)\nmy_report.show_html() # Default arguments will generate to \"SWEETVIZ_REPORT.html\"\n","2a3b32eb":"# define target variable\ntarget = df.SalePrice","0340e4d5":"df.columns[df.isna().any()]","4c2f9163":"(df == \" \").any().any()","c87300e7":"(df == \"\").any().any()","08a87e76":"(df == \"0\").any().any()","03ee8c1c":"(df == 0).any()\n","99226250":"# Remove outliers\n\nadditional_columns_to_neglect = [\"YearBuilt\", \"YearRemodAdd\"] # Please fill with your values!\n\nnum_cols = df.drop(columns=[target.name] + additional_columns_to_neglect)\ndf_clean = df.copy()\nfor i,col in enumerate(num_cols):\n    plt.figure(figsize=(20,8))\n    if df[col].dtype == object:\n        sns.histplot(x=df[col].fillna(\"NaN\"), bins=100, data=df)\n    else:\n        sns.histplot(x=df[col].fillna(-10), bins=100, data=df)\n        \n    plt.show()\n\n    if df_clean[col].nunique() < 50:\n        print(\"Low cardinality in. Skipping column\", col)\n        continue\n\n    index = df_clean.loc[(df_clean[col] - df_clean[col].mean()).abs() > 1.6*df_clean[col].std(), col]\n    print(\"%s scanned:\" % col, \"; Found outliers: \", index.size, \"; Avg was: \", df_clean[col].mean())\n    print(df_clean[col][index.index])# Alternative to replace with NaN\n\n    \n    df_clean.drop(index=index.index, inplace=True) # Alternative to drop\n    \nprint(\"DF Original: \", df.shape)\nprint(\"DF Cleaned:\", df_clean.shape)\n\n","a500007b":"plt.figure(figsize=(20,20))\ncorr = df.select_dtypes([int,float]).corr()\nmask = np.triu(np.ones_like(corr, dtype=bool))\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\nsns.heatmap(data=corr[(abs(corr) > 0.5)], mask=mask, cmap=cmap, annot=True)","67c0328b":"# currently only possible through sweetviz\n# Based on dython and https:\/\/towardsdatascience.com\/the-search-for-categorical-correlation-a1cf7f1888c9\nimport sweetviz as sv\nmy_report = sv.analyze(df.select_dtypes(object).join(target), target_feat=target.name)\nmy_report.show_html(\"heatmap_categorical.html\") # Default arguments will generate to \"SWEETVIZ_REPORT.html\"\n\n","58e2bccd":"sns.pairplot(data=df_clean)\n","3c7db237":"\n\nindex = 1\nfor i,col in enumerate(df_clean):\n\n    if df_clean[col].dtype == object or df_clean[col].nunique() < 15:\n        plt.figure(figsize=(10 ,6))\n        sns.violinplot(x=col,y=target.name,data=df_clean, order=df_clean.groupby(col)[target.name].mean().sort_values().index.tolist())        #ax = plt.subplot(subplot_rows, subplot_columns,index+1)\n        #sns.regplot(x=df_clean[col].factorize()[0],y=df_clean[target.name].tolist(), line_kws={\"color\": \"red\"}, truncate=False) # is non-parametric\n\n    else:\n        f, axs = plt.subplots(1, 2, figsize=(13,6)) \n\n        plt.subplot(1, 2,1)\n        try:\n            sns.regplot(x=col,y=target.name,data=df_clean, line_kws={\"color\": \"red\"}, \n                    robust=True, # is better for outliers\n                    truncate=False) \n        except FloatingPointError:\n            print(\"Floating point error for robust on \", col)\n            sns.regplot(x=col,y=target.name,data=df_clean, line_kws={\"color\": \"red\"}, \n                    truncate=False) \n                    \n        ax = plt.subplot(1, 2,2)\n        try:\n            sns.regplot(x=col,y=target.name,data=df_clean, line_kws={\"color\": \"red\"}, \n                    lowess=True, # is non-parametric\n                    truncate=False) \n        except FloatingPointError:\n            print(\"Floating point error for lowess on \", col)\n    index+=2\n    plt.show()","74c6cdc1":"cat_cols = df_clean.select_dtypes([object])\nif(cat_cols.shape[1] > 1): cat_cols = cat_cols.loc[:, cat_cols.nunique() < 5]\n\nlow_card_cols = df_clean.select_dtypes([int, float])\nif(low_card_cols.shape[1] > 1): low_card_cols = low_card_cols.loc[:, low_card_cols.nunique() < 5]\n\nhue_cols = low_card_cols.join(cat_cols)\nhue_cols","3a787963":"num_cols = df_clean.select_dtypes([float, int])\n\nprint(\"Setup figure OK\")\ncurrent_row = 0\nfor i,col in enumerate(num_cols):\n    print(i+1,\" \/ \", num_cols.shape[1], col)\n    for j,inner_col in enumerate(hue_cols):\n        print(j+1,\" \/ \", hue_cols.shape[1], inner_col)\n        for k, hue_value in enumerate(df_clean[inner_col].unique()):\n            print(\"\\tCurrent hue value: \", hue_value, end=\"\")\n\n            ## Filter for person.R > 0.5 \n            matching_rows = df_clean[df_clean[inner_col] == hue_value]\n            \n            matching_rows = matching_rows.drop(matching_rows[matching_rows[col].isna()].index, axis=\"index\")\n            matching_rows = matching_rows.drop(matching_rows[matching_rows[col].isna()].index, axis=\"index\")\n\n            if(matching_rows[col].shape[0] <= 2 or matching_rows[target.name].shape[0] <= 2): \n                print(\"\")\n                continue\n                \n\n            r,p =  stats.pearsonr(matching_rows[col], matching_rows[target.name])\n            print(\" - R: \", r, \" p:\", p)\n\n            if abs(r) > 0.5 : ## END filter for pearson R. Outcomment till here if not needed\n                plt.figure(figsize=(25,10))\n                sns.lmplot(x=col,y=target.name,data=df_clean, col=inner_col, hue=inner_col, line_kws={\"color\": \"red\"}, \n                            #robust=True, \n                            truncate=False) \n         #       ax = plt.subplot(axs[current_row][1])\n        #        sns.regplot(x=col,y=target.name,data=df_clean, line_kws={\"color\": \"red\"}, lowess=True, truncate=False) # is non-parametric\n                plt.show()\n                current_row+=1\n                break","166b9ea2":"anscombe = sns.load_dataset(\"anscombe\")\nsns.lmplot(x=\"x\", y=\"y\", data=anscombe.query(\"dataset == 'I'\"),   ci=None, scatter_kws={\"s\": 80});","b9bb5831":"from scipy import stats\n\nmy_data = anscombe.query(\"dataset == 'I'\")\nmy_data = pd.DataFrame({\"x\":[0,1,2,3,4,5,6,7,8,9], \"y\":[0,0,0,0.01,0.01,0.01,0.01,0.01,0.01,0.01]})\n\nr,p =  stats.pearsonr(my_data.x, my_data.y)\ngraph = sns.jointplot(x=\"x\", y=\"y\", data=my_data, kind=\"reg\")\ngraph.ax_joint.legend(['r={:f}, p={:f}'.format(r,p)])\n","ff646af6":"# inspect promising candidates with reduced sampling\nsns.lmplot(x=\"cont10\",y=\"target\",hue=\"cat3\",data=train[::10],fit_reg=True) # ::10 is downsampling        \nsns.lmplot(x=\"cont8\",y=\"target\",hue=\"cat4\",data=train[::10],fit_reg=True) # ::10 is downsampling        \n\n","b737e2e5":"\n\nsns.lmplot(x=\"OverallQual\", y=\"SalePrice\", data=df_clean, fit_reg=True, lowess=True,  line_kws={\"color\": \"red\"})\n","49768d80":"newdf = train.copy()\n\nnewdf[\"means\"] = train.select_dtypes([float, int]).apply(lambda x: x.mean() , axis=\"columns\")\nnewdf[\"median\"] = train.select_dtypes([float, int]).apply(lambda x: x.median(), axis=\"columns\")\n\nnewdf = newdf.append(train.apply(lambda x: x.mean() if x.dtype != \"object\" else None), ignore_index=True)\n\nprint(newdf)\n\n\n              ","b3cdca0f":"sns.histplot(x=\"Petal Length (cm)\", hue=\"Species\", bins=10,data=df)","21d3f703":"g = sns.FacetGrid(df, col=\"Species\") # Different plots will be created according to column species\nplt.figure(figsize=(200,10))\n\ng.map(sns.histplot, \"Petal Length (cm)\", bins=5) # For each species plot \"Petal Length (cm) as histplot\"\n","9ced4fc2":"# ALWAYS look togehter with Distplot, to not  be confused by different amounts of data and wrong scaling","72049a13":"sns.kdeplot(x=\"Area (mean)\", data=cancer_b_data) # Your code here (benign tumors)\nsns.kdeplot(x=\"Area (mean)\", data=cancer_m_data) # Your code here (benign tumors)\nplt.show()","153eee54":"## 4.2 Pairplot","515db5ac":"## 4.X Drilldown in specific relations","a58aa1e0":"## 1. Read Data","68c54153":"# EDA","03e2755f":"# Create Heatmap with Sum columns \n\n","1ed75759":"## 4.1 Heatmaps","12666082":"### 4.1.2 Heatmap for categorical data with Sweetviz","e1d9125e":"# 3. Preprocessing\n\n## 3.1 Check for empty values and outliers and how to handle these","34ae6c42":"## 4.3 Hue Plots\n\nHue plots are generalle very problematical if two many hues are present. We limit to 5\n","5201b0e0":"## 4.3 LM-Plot \/ Violin Plot on target variable with robust \/ lowess \/ logistic regression","fce8348b":"Attribute Information\n1) age\n2) sex\n3) chest pain type (4 values)\n4) resting blood pressure\n5) serum cholestoral in mg\/dl\n6)fasting blood sugar > 120 mg\/dl\n7) resting electrocardiographic results (values 0,1,2)\n8) maximum heart rate achieved\n9) exercise induced angina\n10) oldpeak = ST depression induced by exercise relative to rest\n11)the slope of the peak exercise ST segment\n12) number of major vessels (0-3) colored by flourosopy\n13) thal: 0 = normal; 1 = fixed defect; 2 = reversable defect\n14) target: 0= less chance of heart attack 1= more chance of heart attack","28d25635":"# 4. graphs, graphs, graphs ...","4ad753c1":"## 0. Load Libraries and define global behaviour","05fe5ada":"### 4.1.1 Heatmap for numerical values with map","257ef2f5":"# Multiple Histograms","04dbacf7":"## 2. Define Target Variable"}}