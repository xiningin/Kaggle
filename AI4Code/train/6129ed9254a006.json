{"cell_type":{"172eaccc":"code","6bfd275e":"code","c889bfdf":"code","41eaebb9":"code","97fc6758":"code","28a0a6ba":"code","f3a8092c":"code","20c2a5f6":"code","069e69c4":"code","f7387ef8":"code","98c726f9":"code","29e9a435":"code","ac30def2":"code","49cdc831":"code","f91f28e9":"code","32a22065":"code","73d384c7":"code","61f55ada":"code","9531ef72":"code","ba3f8bf2":"code","8a528598":"code","fed6d5f9":"code","665f8e9b":"code","36b17164":"code","0be31cd7":"code","f67ffc11":"code","ba4a3632":"code","4f2e11f6":"code","d4d7fc94":"code","c96e2df6":"code","1b95af81":"code","28b06e35":"code","d7e948e3":"code","cba0aafc":"code","dd207de7":"code","033e692a":"code","fcbe6dab":"code","7c9049ed":"code","4c3ffec6":"code","d3eb983e":"code","045b5b55":"code","f1782d65":"code","e8f4c8e0":"code","efcfb314":"code","3c4f5612":"code","72b3911b":"code","bf6682c7":"code","b5c7b320":"code","bee4fed1":"markdown","c6c8418c":"markdown","228a8e46":"markdown","6cb3c477":"markdown","ddf66def":"markdown","90930806":"markdown","ff13d36c":"markdown","59bc008d":"markdown","4f32c6b8":"markdown","3791f2c1":"markdown","044eccc2":"markdown","a2b41b88":"markdown","899529e9":"markdown","9d78485a":"markdown","1be394a3":"markdown","c0dbb44c":"markdown","128cacfb":"markdown","9b759605":"markdown","ae42a9c2":"markdown","60e42fca":"markdown","2121ad5a":"markdown","2ee1dcbf":"markdown","e4941d5c":"markdown","28082174":"markdown"},"source":{"172eaccc":"import pandas as pd\nimport numpy as np\nimport io\nimport matplotlib.pyplot as plt","6bfd275e":"dataf = pd.read_csv('..\/input\/persistent-vs-nonpersistent\/Persistent_vs_NonPersistent.csv')","c889bfdf":"dataf.head()","41eaebb9":"dataf.tail()","97fc6758":"dataf.describe","28a0a6ba":"dataf.info()","f3a8092c":"print (\"Rows     : \" ,dataf.shape[0])\nprint (\"Columns  : \" ,dataf.shape[1])\nprint (\"\\nFeatures : \\n\" ,dataf.columns.tolist())","20c2a5f6":"print (\"\\nMissing values :  \", dataf.isnull().any())","069e69c4":"print (\"\\nUnique values :  \\n\",dataf.nunique())","f7387ef8":"dataf.isnull().sum()","98c726f9":"dataf.value_counts('Persistency_Flag')","29e9a435":"import seaborn as sns","ac30def2":"sns.countplot(x=\"Persistency_Flag\",data=dataf, dodge=True)","49cdc831":"sns.countplot(x=\"Persistency_Flag\",hue='Tscore_Bucket_Prior_Ntm', data=dataf)","f91f28e9":"sns.countplot(x=\"Persistency_Flag\",hue='Adherent_Flag', data=dataf)","32a22065":"sns.countplot(x=\"Persistency_Flag\",hue='Injectable_Experience_During_Rx', data=dataf)","73d384c7":"sns.countplot(x=\"Persistency_Flag\", hue='Age_Bucket', data=dataf)","61f55ada":"sns.countplot(x=\"Persistency_Flag\", hue='Gender', data=dataf)","9531ef72":"sns.countplot(x=\"Persistency_Flag\", hue='Count_Of_Risks', data=dataf)","ba3f8bf2":"X = dataf.drop(columns='Persistency_Flag')\ny = dataf['Persistency_Flag']","8a528598":"X.head()","fed6d5f9":"y.head()","665f8e9b":"print(X.shape)\nprint(y.shape)","36b17164":"from sklearn.preprocessing import LabelEncoder","0be31cd7":"le = LabelEncoder()\ntarget = le.fit_transform(np.ravel(y))","f67ffc11":"target","ba4a3632":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import Pipeline\n\nclass MultiColumnLabelEncoder:\n    def __init__(self,columns = None):\n        self.columns = columns # array of column names to encode\n\n    def fit(self,X,y=None):\n        return self # not relevant here\n\n    def transform(self,X):\n        #Transforms columns of X specified in self.columns using LabelEncoder().\n        #If no columns specified, transforms all columns in X.\n        \n        output = X.copy()\n        if self.columns is not None:\n            for col in self.columns:\n                output[col] = LabelEncoder().fit_transform(output[col])\n        else:\n            for colname,col in output.iteritems():\n                output[colname] = LabelEncoder().fit_transform(col)\n        return output\n\n    def fit_transform(self,X,y=None):\n        return self.fit(X,y).transform(X)","4f2e11f6":"New_dataF = MultiColumnLabelEncoder(columns = ['Ptid', 'Gender', 'Race', 'Ethnicity', 'Region', 'Age_Bucket', 'Ntm_Speciality', 'Ntm_Specialist_Flag', 'Ntm_Speciality_Bucket', 'Gluco_Record_Prior_Ntm', 'Gluco_Record_During_Rx', 'Dexa_During_Rx', 'Frag_Frac_Prior_Ntm', 'Frag_Frac_During_Rx', 'Risk_Segment_Prior_Ntm', 'Tscore_Bucket_Prior_Ntm', 'Risk_Segment_During_Rx', 'Tscore_Bucket_During_Rx', 'Change_T_Score', 'Change_Risk_Segment', 'Adherent_Flag', 'Idn_Indicator', 'Injectable_Experience_During_Rx', 'Comorb_Encounter_For_Screening_For_Malignant_Neoplasms', 'Comorb_Encounter_For_Immunization', 'Comorb_Encntr_For_General_Exam_W_O_Complaint,_Susp_Or_Reprtd_Dx', 'Comorb_Vitamin_D_Deficiency', 'Comorb_Other_Joint_Disorder_Not_Elsewhere_Classified', 'Comorb_Encntr_For_Oth_Sp_Exam_W_O_Complaint_Suspected_Or_Reprtd_Dx', 'Comorb_Long_Term_Current_Drug_Therapy', 'Comorb_Dorsalgia', 'Comorb_Personal_History_Of_Other_Diseases_And_Conditions', 'Comorb_Other_Disorders_Of_Bone_Density_And_Structure', 'Comorb_Disorders_of_lipoprotein_metabolism_and_other_lipidemias', 'Comorb_Osteoporosis_without_current_pathological_fracture', 'Comorb_Personal_history_of_malignant_neoplasm', 'Comorb_Gastro_esophageal_reflux_disease', 'Concom_Cholesterol_And_Triglyceride_Regulating_Preparations', 'Concom_Narcotics', 'Concom_Systemic_Corticosteroids_Plain', 'Concom_Anti_Depressants_And_Mood_Stabilisers', 'Concom_Fluoroquinolones', 'Concom_Cephalosporins', 'Concom_Macrolides_And_Similar_Types', 'Concom_Broad_Spectrum_Penicillins', 'Concom_Anaesthetics_General', 'Concom_Viral_Vaccines', 'Risk_Type_1_Insulin_Dependent_Diabetes', 'Risk_Osteogenesis_Imperfecta', 'Risk_Rheumatoid_Arthritis', 'Risk_Untreated_Chronic_Hyperthyroidism', 'Risk_Untreated_Chronic_Hypogonadism', 'Risk_Untreated_Early_Menopause', 'Risk_Patient_Parent_Fractured_Their_Hip', 'Risk_Smoking_Tobacco', 'Risk_Chronic_Malnutrition_Or_Malabsorption', 'Risk_Chronic_Liver_Disease', 'Risk_Family_History_Of_Osteoporosis', 'Risk_Low_Calcium_Intake', 'Risk_Vitamin_D_Insufficiency', 'Risk_Poor_Health_Frailty', 'Risk_Excessive_Thinness', 'Risk_Hysterectomy_Oophorectomy', 'Risk_Estrogen_Deficiency', 'Risk_Immobilization', 'Risk_Recurring_Falls']).fit_transform(X)","d4d7fc94":"New_dataF.head(10)","c96e2df6":"New_dataF.tail(10)","1b95af81":"New_dataF['Ptid'].nunique()","28b06e35":"##Important packages importing\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, roc_auc_score\nfrom matplotlib import pyplot\nfrom sklearn.metrics import classification_report, confusion_matrix","d7e948e3":"train_X, test_X, train_y, test_y = train_test_split(New_dataF, target, test_size=0.3, random_state=42)","cba0aafc":"# Logistic Regression\n# fit a model\nmodel = LogisticRegression(solver='newton-cg')#, max_iter=3000, penalty='elasticnet',l1_ratio=1)\nmodel.fit(train_X, train_y)","dd207de7":"# Accuracy on Testing Dataset using Logistic Regression\nscore_LR = model.score(test_X, test_y)\nprint(\"Using Logistic Regression Model- Accuracy on Test Dataset is\", score_LR*100, \"%\")","033e692a":"#Import Library\nfrom sklearn import svm\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score\nimport warnings\nwarnings.filterwarnings('ignore')","fcbe6dab":"# Create Linear SVM object\nsupport = svm.LinearSVC(random_state=20)\n\n# Train the model using the training sets and check score on test dataset\nsupport.fit(train_X, train_y)\npredicted= support.predict(test_X)\nscore=accuracy_score(test_y,predicted)\nprint(\"Using Support Vector Machine Model- Accuracy on Test Dataset is\", score*100, \"%\")","7c9049ed":"from mlxtend.evaluate import paired_ttest_5x2cv\n# check if difference between algorithms is real\nt, p = paired_ttest_5x2cv(estimator1=model, \n                          estimator2=support, \n                          X=New_dataF, \n                          y=target, \n                          scoring='accuracy', \n                          random_seed=1)\n# summarize\nprint(f'The P-value is = {p:.3f}')\nprint(f'The t-statistics is = {t:.3f}')\n# interpret the result\nif p <= 0.05:\n    print('Since p<0.05, We can reject the null-hypothesis that both models perform equally well on this dataset. \\\n    \\nWe may conclude that the two algorithms are significantly different.')\nelse:\n    print('Since p>0.05, we cannot reject the null hypothesis. \\\n    \\nWe may conclude that the performance of the two algorithms is not significantly different.')","4c3ffec6":"# predict probabilities\nyhat = model.predict_proba(test_X)\n\n# retrieve just the probabilities for the positive class\npos_probs = yhat[:, 1]\n\n# plot no skill roc curve\npyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill')\n# calculate roc curve for model\nfpr, tpr, _ = roc_curve(test_y, pos_probs)\n# plot model roc curve\npyplot.plot(fpr, tpr, marker='.', label='Logistic')\n# axis labels\npyplot.xlabel('False Positive Rate')\npyplot.ylabel('True Positive Rate')\n# show the legend\npyplot.legend()\n# show the plot\npyplot.show()","d3eb983e":"#Calculating ROC Area Under Curve\nyhat = model.predict_proba(test_X)\npos_probs = yhat[:, 1]\nroc_auc = roc_auc_score(test_y, pos_probs)\nprint('Logistic ROC Area Under Curve %.3f' % roc_auc)","045b5b55":"print('Coefficients of all variables : ', model.coef_)","f1782d65":"print('Intercept of the model : ', model.intercept_)","e8f4c8e0":"print('Predicted Classes are : ', model.classes_)","efcfb314":"print('Predicted probability on training dataset : ', model.predict_proba(train_X))","3c4f5612":"#Accuracy on Training Dataset\nprint('Accuracy on Training Dataset : ', model.score(train_X, train_y))","72b3911b":"confusion_matrix(target, model.predict(New_dataF))","bf6682c7":"cm = confusion_matrix(target, model.predict(New_dataF))\nfig, ax = plt.subplots(figsize=(8, 8))\nax.imshow(cm)\nax.grid(False)\nax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted Non-Persistent', 'Predicted Persistent'))\nax.yaxis.set(ticks=(0, 1), ticklabels=('Actual Non-Persistent', 'Actual Persistent'))\nax.set_ylim(1.5, -0.5)\nfor i in range(2):\n    for j in range(2):\n        ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\nplt.show()","b5c7b320":"print(classification_report(target, model.predict(New_dataF)))","bee4fed1":"##Splitting of data into Training and Testing dataset for ML Models","c6c8418c":"##Support Vector Machine Model","228a8e46":"##Coefficients of variables","6cb3c477":"1. True negatives in the upper-left position\n2. False negatives in the lower-left position\n3. False positives in the upper-right position\n4. True positives in the lower-right position","ddf66def":"##Label Encoder for Non-Numeric columns","90930806":"##New dataframe after label encoding","ff13d36c":"##Predicted Classes","59bc008d":"Here, I choose **Logistic Regression** over svm to calculate the all required details.","4f32c6b8":"##Exploratory Data Analysis","3791f2c1":"##Target Class\nClass \"1\" is Persistent\\\nClass \"0\" is Non-Persistent","044eccc2":"##Logistic Regression Model","a2b41b88":"##ROC Curve and Area Under Curve","899529e9":"##Hyposthesis Results\nIt is clear that the accuracy of **Logistic Regression Model** is much better as compared to support vector machine on same dataset.","9d78485a":"##Seperating input variables and target variables","1be394a3":"##Classification Report on Confusion Matrix","c0dbb44c":"##Loading and reading of dataset","128cacfb":"So, here our samples do not provide the enough evidence to conclude that the assume effect exists or does not exist.","9b759605":"##Descriptive Analysis of dataset","ae42a9c2":"##Target Class\nWhere:\\\nClass \"1\" is Persistent\\\nClass \"0\" is Non-Persistent","60e42fca":"##Hypothesis Testing for Classification Models\n###Steps:\nThe first step would be to to state the null hypothesis statement.\\\nH0: Both models have the same performance on the dataset.\\\nH1: Both models doesn\u2019t have the same performance on the dataset.\\\nLevel of significance is 0.05","2121ad5a":"##Confusion Matrix","2ee1dcbf":"##Intercept of Model","e4941d5c":"##Encoded target variable","28082174":"**If you like this notebook then please upvote the notebook. It will motivate me to work more and more.**"}}