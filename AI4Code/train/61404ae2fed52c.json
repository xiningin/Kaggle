{"cell_type":{"a4418649":"code","d088a738":"code","2b0bb28f":"code","0db6a959":"code","ec9c98bb":"code","ce03b5c8":"code","21b46280":"code","fc942580":"code","63739d98":"code","ebddd3f2":"code","c085c6cc":"code","46c16afd":"code","de343904":"code","4f74b0ce":"code","2697cd4b":"code","cb29cd1b":"code","573b2e88":"code","6233e12b":"code","20e82c13":"code","782ef74e":"code","04cd6fe0":"code","9f1e9407":"code","62bc80db":"code","76bb87c7":"code","64a19a67":"code","5b6bc1b6":"code","a50ae50f":"code","8c0588ab":"code","f26c14ce":"code","7be33ebf":"markdown","d6c15df0":"markdown","aa30aa4d":"markdown","763456f8":"markdown","01a06c42":"markdown","412534e3":"markdown","b46de84d":"markdown","687ca469":"markdown","6ca4ed0f":"markdown","8088b4e7":"markdown","8bb9b9c0":"markdown","2aceb6ad":"markdown","1aa32661":"markdown","42b8e66f":"markdown","b924eaba":"markdown","24fb035e":"markdown","3d14b44d":"markdown","01a43584":"markdown","87391eee":"markdown","a361afb6":"markdown","627f7071":"markdown"},"source":{"a4418649":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d088a738":"df = pd.read_csv('\/kaggle\/input\/hr-analytics-job-change-of-data-scientists\/aug_train.csv')\ndf.head()","2b0bb28f":"df.isnull().sum()","0db6a959":"df.target.value_counts()","ec9c98bb":"df.dtypes","ce03b5c8":"import matplotlib.pyplot as plt \nimport seaborn as sns","21b46280":"plt.figure(figsize=(10,10))\nax = plt.subplot(1,1,1)\nax = sns.countplot(data=df[df.target==1],x='city',orient='v')","fc942580":"plt.figure(figsize=(10,10))\nax = plt.subplot(1,1,1)\nax = sns.countplot(data=df,x='gender')","63739d98":"plt.figure(figsize=(10,10))\nax = plt.subplot(1,1,1)\nax = sns.countplot(data=df[df.target==1],x='gender')","ebddd3f2":"plt.figure(figsize=(10,10))\nax = plt.subplot(1,1,1)\nax = sns.countplot(data=df[df.target==1],x='relevent_experience')","c085c6cc":"plt.figure(figsize=(10,10))\nax = plt.subplot(1,1,1)\nax = sns.countplot(data=df[df.target==1],x='enrolled_university')","46c16afd":"plt.figure(figsize=(10,10))\nax = plt.subplot(1,1,1)\nax = sns.countplot(data=df[df.target==1],x='education_level')","de343904":"df = df.drop(['education_level'],axis=1)","4f74b0ce":"plt.figure(figsize=(10,10))\nax = plt.subplot(1,1,1)\nax = sns.countplot(data=df[df.target==1],x='major_discipline')","2697cd4b":"plt.figure(figsize=(10,10))\nax = plt.subplot(1,1,1)\nax = sns.countplot(data=df[df.target==1],x='experience')","cb29cd1b":"df = df.drop(['experience'],axis=1)","573b2e88":"plt.figure(figsize=(10,10))\nax = plt.subplot(1,1,1)\nax = sns.countplot(data=df[df.target==1],x='company_size')","6233e12b":"df['company_size_new']= \"None\"\n\nfor i in df['company_size'].values:\n    if i in ['<10','10\/49','50-99']:\n        df['company_size_new'][df['company_size']==i]='small'\n    elif i in ['100-500','500-999']:\n        df['company_size_new'][df['company_size']==i]='medium'\n    elif i in ['1000-4999','5000-9999','10000+']:\n        df['company_size_new'][df['company_size']==i]='big'\n\ndf = df.drop(['company_size'],axis=1)      ","20e82c13":"plt.figure(figsize=(10,10))\nax = plt.subplot(1,1,1)\nax = sns.countplot(data=df[df.target==1],x='company_size_new')","782ef74e":"plt.figure(figsize=(10,10))\nax = plt.subplot(1,1,1)\nax = sns.countplot(data=df[df.target==1],x='company_type')","04cd6fe0":"plt.figure(figsize=(10,10))\nax = plt.subplot(1,1,1)\nax = sns.countplot(data=df,x='last_new_job')","9f1e9407":"columns = [f for f in df.columns if f not in ('enrollee_id','target')]\nnumerical_columns = ['city_development_index','training_hours']","62bc80db":"from sklearn.preprocessing import LabelEncoder","76bb87c7":"for col in columns:\n    if col not in numerical_columns:\n        df[col] = df[col].astype(str).fillna(\"None\")\n        lbl = LabelEncoder()\n        lbl.fit(df[col])\n        df[col]= lbl.transform(df[col])","64a19a67":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_auc_score","5b6bc1b6":"X = df[columns].values \ny = df['target'].values\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,stratify=y)","a50ae50f":"rf = RandomForestClassifier(criterion='gini',max_depth=7,n_estimators = 400)\nrf.fit(X_train,y_train)","8c0588ab":"y_pred= rf.predict_proba(X_test)[:,1]","f26c14ce":"print('ROC AUC SCORE: {:.3f}'.format(roc_auc_score(y_test,y_pred)))","7be33ebf":"Number of people searching for job with relevant expierience is much more than those searching without experience. ","d6c15df0":"Since, the data is skewed we would be using AUC score as metrics rather than normal accuracy.","aa30aa4d":"Let us create a new column which would divide this into four categories startups, medium, large and None for companies whose size is unknown.","763456f8":"People who did not go to college are much much larger group who are now searching for a job change.","01a06c42":"## Exploring the target","412534e3":"We would be dropping expereince column as we already have relevant experience column and we would be using that","b46de84d":"We can see that count of one city is much much more than other cities.","687ca469":"## Data type of each column","6ca4ed0f":"## Let us make some graphs to understand things better****","8088b4e7":"Now this looks much a clear picture.","8bb9b9c0":"# This is a good score as we have not done overfitting and not excluded too much training data. Also, we can add more and more complexity to the model but it would hardly import result","2aceb6ad":"We have many features and many columns with null-values so one way is to drop columns such as gender, company_size and company_type but then this would not become a real world problem. Because we would always get some null values. Thus we would fill them by \"None\".","1aa32661":"We would be using label encoding in place of OneHotEncoding","42b8e66f":"## Importing the dataset","b924eaba":"We find that people with professional degree are more likely to search for a new job.","24fb035e":"The two features education_level and enrollment are very much interrelated we are going to drop one of them. Since education_level has more NA values then enrollement we would be dropping education_level.","3d14b44d":"People having jobs in in startups are more likely to change job much more than people working in corporates.","01a43584":"Since people are likely to leave job more in pvt ltd. ","87391eee":"We can see that the number of males are more than any other in sex and they are also high in proportion inleaving the job.","a361afb6":"## Checking null values","627f7071":"## Building the model"}}