{"cell_type":{"a7b7bdb0":"code","82a002f9":"code","1345b023":"code","fd48ef24":"code","f76c9020":"code","4d958b0d":"code","59290a11":"code","cebaf453":"code","97d16ed3":"code","4ca17091":"code","31267be4":"code","d461b6d9":"code","5909c109":"code","e0fd1e9d":"code","e5daf540":"code","ffab4519":"code","e1813dc4":"code","628970e0":"code","5a74ddc2":"code","ce6da1b0":"code","37bf7129":"code","60dc0efe":"code","8d87aab5":"code","33fe0c1a":"code","1effc860":"code","524ece59":"code","8ec476f8":"code","e462c0eb":"code","93006f66":"code","8d95d245":"code","ed0550aa":"code","c16d9251":"code","84b9bc72":"code","9c6b5118":"code","d1b45baf":"code","220b77d5":"code","ece2c196":"code","30d99c77":"markdown"},"source":{"a7b7bdb0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","82a002f9":"import pandas as pd\ndf = pd.read_csv('\/kaggle\/input\/creditcardfraud\/creditcard.csv',sep = ',')","1345b023":"import numpy as np\nimport pandas as pd\nimport sklearn\nimport scipy\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report ,accuracy_score\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.svm import OneClassSVM\nfrom pylab import rcParams\nrcParams  ['figure.figsize'] = 14,8\nRANDOM_SEED =42\nLABELS = ['Normal','Fraud']","fd48ef24":"df.head()","f76c9020":"df.info()","4d958b0d":"#To find whether the dataset is balanced or unbalanced using target column\ndf['Class'].value_counts()\n","59290a11":"#Create dependent and independent value\nindep = df.columns.tolist()\nindep\n","cebaf453":"columns = [c for c in indep if c not in [\"Class\"]]","97d16ed3":"target = 'Class'","4ca17091":"#define in random state\nstate = np.random.RandomState(42)\nx = df[columns]\ny = df['Class']\nprint(x.shape)\nprint(y.shape)","31267be4":"df.isnull().values.any()","d461b6d9":"count_classes = pd.value_counts(df['Class'], sort = True)\n\ncount_classes.plot(kind = 'bar', rot=0)\n\nplt.title(\"Transaction Class Distribution\")\n\nplt.xticks(range(2), LABELS)\n\nplt.xlabel(\"Class\")\n\nplt.ylabel(\"Frequency\")","5909c109":"\n## Get the Fraud and the normal dataset \n\nfraud = df[df['Class']==1]\n\nnormal = df[df['Class']==0]","e0fd1e9d":"print('Fraud  : ' ,fraud.shape)\nprint(\"Normal : \" ,normal.shape)\n","e5daf540":"from imblearn.under_sampling import NearMiss\nnm = NearMiss()\nX_mis,y_mis=nm.fit_sample(x,y)","ffab4519":"X_mis.shape,y_mis.shape","e1813dc4":"from collections import Counter\nprint('Original dataset shape {}'.format(Counter(y)))\nprint('Resampled dataset shape {}'.format(Counter(y_mis)))","628970e0":"from numpy import mean\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier()\nscores = cross_val_score(model, X_mis, y_mis, scoring='roc_auc', n_jobs=-1)\nprint(\"Mean oF roc AUC : %f \"% mean(scores))","5a74ddc2":"#SMOTE\nfrom imblearn.combine import SMOTETomek\nsmote = SMOTETomek()\nx_smote,y_smote = smote.fit_sample(x,y)","ce6da1b0":"print(x_smote.shape,y_smote.shape)","37bf7129":"from numpy import mean\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier()\nscores = cross_val_score(model, x_smote, y_smote, scoring='roc_auc', n_jobs=-1)\nprint(\"Mean oF roc AUC : %f \"% mean(scores))","60dc0efe":"from imblearn.over_sampling import RandomOverSampler\nos =  RandomOverSampler()\nx_ros,y_ros = os.fit_sample(x,y)\n","8d87aab5":"x_ros.shape,y_ros.shape","33fe0c1a":"from numpy import mean\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier()\nscores = cross_val_score(model, x_ros, y_ros, scoring='roc_auc', n_jobs=-1)\nprint(\"Mean oF roc AUC : %f \"% mean(scores))","1effc860":"x.shape,y.shape","524ece59":"#Splitting the x& y for train ,test\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.30,random_state=42)","8ec476f8":"x_train.shape,y_train.shape","e462c0eb":"x_train.head()","93006f66":"y_train.head()","8d95d245":"x_test.head()","ed0550aa":"y_test.head()","c16d9251":"#Apply graident Boosting classifier technique\nfrom sklearn.ensemble import GradientBoostingClassifier\ngbc = GradientBoostingClassifier()\nmodel1 = gbc.fit(x_train,y_train)\npredict = model1.predict(x_test)\npredict","84b9bc72":"accuracy_score(y_test,predict)","9c6b5118":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n#auc calculate\nauc = roc_auc_score(y_test, predict)\nprint('AUC: %.3f' % auc)\n","d1b45baf":"#calculate confusion matrix\nfrom sklearn.metrics import confusion_matrix\nconf = confusion_matrix(y_test,predict)\nconf","220b77d5":"# calculate roc curve\nfrom sklearn.metrics import roc_auc_score, classification_report, roc_curve, auc, plot_confusion_matrix\nfpr,tpr,thresholds = roc_curve(y_test,predict) \nroc_auc = auc(fpr,tpr)\nroc_auc","ece2c196":"from sklearn.metrics import roc_auc_score, classification_report, roc_curve, auc, plot_confusion_matrix\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.axhline()\nplt.axvline(linewidth=5)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","30d99c77":" # Handling Imbalanced by 3 ways\n 1.NearMiss-only undersampling\n 2.SMOTETomek-combine both\n 3.RandomOverSampler-only over sampling"}}