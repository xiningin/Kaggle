{"cell_type":{"a9e9e41d":"code","e879a1a9":"code","48cc9cea":"code","3735a299":"code","6ef5401c":"code","827ea809":"code","6477a36c":"code","7ca3719b":"code","7035db48":"code","5e9c0fde":"code","cb8315a6":"code","a5cf261e":"code","66e741d6":"code","d37b0640":"code","20699f3d":"code","e909e032":"code","f44e9057":"code","095d6e0d":"code","69064a03":"code","c1f43c9a":"code","b35d7d2c":"code","b64331ff":"code","b770176c":"code","8c525958":"code","aa947a20":"code","7cdaec24":"code","dbb1c8a5":"code","3ea77fbc":"code","109594a6":"code","c7e70a57":"code","5b3ffbdb":"code","e9e26821":"code","cbdea62e":"code","4b8adb49":"code","5543e749":"code","4b6f6456":"code","c49725e1":"code","f5fed2e7":"code","41d04bbe":"code","7739218b":"code","fe4f2441":"code","98baa57c":"code","37d284e6":"code","2b50db2d":"code","90f6203d":"code","697bba2e":"code","1c42151b":"code","6cb0c9aa":"code","42913ad0":"code","119c2676":"code","14eeea9e":"code","948fa37b":"code","ed66daf9":"code","ab3bb003":"code","5f360642":"code","655eedc5":"code","3aa34def":"code","bd4b0cbb":"code","58de6ded":"code","7cee6ec2":"code","30ff2c4f":"code","87bdbe68":"code","6b5ef56a":"code","02b25053":"code","d43a38fb":"code","4e36fde3":"code","6cfabc4f":"code","70e493c6":"code","c22bbe3e":"code","fda43a57":"code","29056b8b":"code","1d163da1":"code","3e849e04":"code","e4527ee8":"code","8bdbaddc":"code","ecd03f4f":"code","6bc58434":"code","3826823b":"markdown","3478f52e":"markdown","e5ae4705":"markdown","604ede91":"markdown","60a56ceb":"markdown","02da18b8":"markdown","158ae061":"markdown","8bbcb112":"markdown","439fe8ca":"markdown","9275d0fd":"markdown","49962fc2":"markdown","5a8a950f":"markdown","bd55f6f3":"markdown","5418b992":"markdown","892cbbbd":"markdown","42df3746":"markdown","00d41c4b":"markdown","021542cc":"markdown","c3453971":"markdown","57caacf0":"markdown","6b5ea2c3":"markdown","b7513bf5":"markdown"},"source":{"a9e9e41d":"import pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report,accuracy_score,roc_curve,confusion_matrix\nfrom sklearn.preprocessing import binarize","e879a1a9":"columns=['age','workclass','fnlwgt','education','education-num','marital_status','occupation','relationship','race','sex','capital_gain'\n        ,'capital-loss','hours-per-week','native-country','income']","48cc9cea":"test_dir = '\/kaggle\/input\/us-census-data\/adult-test.csv'\ntraining_dir = '\/kaggle\/input\/us-census-data\/adult-training.csv'","3735a299":"data=pd.read_csv(training_dir,names=columns)","6ef5401c":"data.head()","827ea809":"data.describe()","6477a36c":"data.info()","7ca3719b":"data.isnull().sum()","7035db48":"age_categ=[]\nfor age in data.age:\n    if age<13:\n        age_categ.append('kid')\n    else:\n        if age<19:\n            age_categ.append('teen')\n        else:\n            if age<35:\n                age_categ.append('young')\n            else:\n                if age<50:\n                    age_categ.append('adult')\n                else:\n                    age_categ.append('old')\ndata.insert(1,'age_categ',age_categ)","5e9c0fde":"sns.countplot(data.age_categ)\n","cb8315a6":"data.drop(['age'],axis=1,inplace =True)","a5cf261e":"data.workclass.unique()\n","66e741d6":"(data.workclass==' ?').sum()\/len(data)*100\n# 5 percent of workclass is filled with ?","d37b0640":"data.workclass.replace(' ?',data.workclass.mode()[0],inplace=True)\n","20699f3d":"data.workclass.replace(' Never-worked',' Without-pay',inplace=True)","e909e032":"plt.xticks(rotation=90)\nsns.countplot(data.workclass)","f44e9057":"data.fnlwgt.plot(kind='box')","095d6e0d":"data=data[data.fnlwgt<600000]","69064a03":"data.fnlwgt.plot(kind='box')\n","c1f43c9a":"plt.figure(figsize=(10,10))\nplt.xticks(rotation=90)\nsns.countplot(data.education)","b35d7d2c":"sns.countplot(data['education-num'])\n#education number is alternative way of representating education column so we can drop one of them","b64331ff":"data.drop(['education'],axis=1,inplace=True)","b770176c":"data['marital_status'].unique()","8c525958":"plt.xticks(rotation=90)\nsns.countplot(data['marital_status'])","aa947a20":"data['occupation'].unique()","7cdaec24":"data.occupation.replace(' ?',data.occupation.mode()[0],inplace=True)","dbb1c8a5":"\nplt.xticks(rotation=90)\nsns.countplot(data.occupation)","3ea77fbc":"data.relationship.unique()\n","109594a6":"plt.xticks(rotation=90)\nsns.countplot(data.relationship)","c7e70a57":"plt.xticks(rotation=90)\nsns.countplot(data.race)","5b3ffbdb":"data.race.unique()\n","e9e26821":"replace=data.race.unique()[2:]\nfor to_replace in replace:\n    print(to_replace)\n    data['race'].replace(to_replace,' Other',inplace=True)","cbdea62e":"sns.countplot(data.race)","4b8adb49":"sns.countplot(data.sex)\n","5543e749":"data['is_capital']=[0 if capital==0 else 1 for capital in data['capital_gain']]\n","4b6f6456":"sns.countplot(data['is_capital'])\n","c49725e1":"data['is_loss']=[0 if capital==0 else 1 for capital in data['capital-loss']]\n","f5fed2e7":"sns.countplot(data['is_loss'])\n","41d04bbe":"#dropping capital_gain and capital_loss\ndata.drop(['capital_gain','capital-loss'],axis=1,inplace=True)","7739218b":"data['hours-per-week'].hist(bins=15)\n","fe4f2441":"\ndiff_hours_categ=['>=60','>40&<60','<=40&>30','<=30']\nhours_categ=[]\nfor hours in data['hours-per-week']:\n    if hours>=60:\n        hours_categ.append(diff_hours_categ[0])\n    else:\n        if hours>40:\n            hours_categ.append(diff_hours_categ[1])\n        else:\n            if hours>30:\n                hours_categ.append(diff_hours_categ[2])\n            else:\n                hours_categ.append(diff_hours_categ[3])\ndata['hours_categ_week']=hours_categ","98baa57c":"sns.countplot(data['hours_categ_week'])\n","37d284e6":"#dropping hours per week\ndata.drop(['hours-per-week'],axis=1,inplace=True)","2b50db2d":"data['native-country'].value_counts()\n","90f6203d":"# we can make only two native country United-States and other\ndata['native-country']=[' United-States' if country==' United-States' else ' Other' for country in data['native-country']]\n","697bba2e":"sns.countplot(data['native-country'])\n","1c42151b":"sns.countplot(data.income)\n","6cb0c9aa":"data.head()\n","42913ad0":"\ndiff_categ_count=data['age_categ'].value_counts()\ngroup_table=data.groupby(['age_categ','income']).size().astype(float)\nfor categ in group_table.index.levels[0]:\n    for income in group_table[categ].index:\n        group_table[categ][income]=group_table[categ][income]\/diff_categ_count[categ]*100\ngroup_table.unstack().plot(kind='bar',stacked=True)\nplt.ylabel('percentage of income categ')","119c2676":"#since adult and old distrbution is similar in income so we can make them one \ndata.age_categ.replace('old','adult',inplace=True)","14eeea9e":"diff_categ_count=data['workclass'].value_counts()\ngroup_table=data.groupby(['workclass','income']).size().astype(float)\nfor categ in group_table.index.levels[0]:\n    for income in group_table[categ].index:\n        group_table[categ][income]=group_table[categ][income]\/diff_categ_count[categ]*100\ngroup_table.unstack().plot(kind='bar',stacked=True)\nplt.ylabel('percentage of income categ')","948fa37b":"sns.violinplot(data['income'],data['fnlwgt'],inner='quart')\n","ed66daf9":"data.drop(['fnlwgt'],axis=1,inplace=True)\n","ab3bb003":"diff_categ_count=data['education-num'].value_counts()\ngroup_table=data.groupby(['education-num','income']).size().astype(float)\nfor categ in group_table.index.levels[0]:\n    for income in group_table[categ].index:\n        group_table[categ][income]=group_table[categ][income]\/diff_categ_count[categ]*100\ngroup_table.unstack().plot(kind='bar',stacked=True)\nplt.ylabel('percentage of income categ')","5f360642":"# 15 and 16  , 11 and 12 , 2 and 3 ,4 to 7 can be combined\nreplace_dict={\n    15:16,11:12,3:2,5:4,6:4,7:4\n}\nfor num in replace_dict:\n    data.replace(num,replace_dict[num],inplace=True)","655eedc5":"diff_categ_count=data['education-num'].value_counts()\ngroup_table=data.groupby(['education-num','income']).size().astype(float)\nfor categ in group_table.index.levels[0]:\n    for income in group_table[categ].index:\n        group_table[categ][income]=group_table[categ][income]\/diff_categ_count[categ]*100\ngroup_table.unstack().plot(kind='bar',stacked=True)\nplt.ylabel('percentage of income categ')","3aa34def":"diff_categ_count=data['marital_status'].value_counts()\ngroup_table=data.groupby(['marital_status','income']).size().astype(float)\nfor categ in group_table.index.levels[0]:\n    for income in group_table[categ].index:\n        group_table[categ][income]=group_table[categ][income]\/diff_categ_count[categ]*100\ngroup_table.unstack().plot(kind='bar',stacked=True)\nplt.ylabel('percentage of income categ')","bd4b0cbb":"#reducing some categories\ndata.replace(' Married-civ-spouse',' Married-AF-spouse',inplace=True)\ndata.replace(' Married-spouse-absent',' Widowed',inplace=True)","58de6ded":"\ndiff_categ_count=data['occupation'].value_counts()\ngroup_table=data.groupby(['occupation','income']).size().astype(float)\nfor categ in group_table.index.levels[0]:\n    for income in group_table[categ].index:\n        group_table[categ][income]=group_table[categ][income]\/diff_categ_count[categ]*100\ngroup_table.unstack().plot(kind='bar',stacked=True,figsize=(10,10))\nplt.ylabel('percentage of income categ')","7cee6ec2":"\ndiff_categ_count=data['relationship'].value_counts()\ngroup_table=data.groupby(['relationship','income']).size().astype(float)\nfor categ in group_table.index.levels[0]:\n    for income in group_table[categ].index:\n        group_table[categ][income]=group_table[categ][income]\/diff_categ_count[categ]*100\ngroup_table.unstack().plot(kind='bar',stacked=True)\nplt.ylabel('percentage of income categ')","30ff2c4f":"diff_categ_count=data['race'].value_counts()\ngroup_table=data.groupby(['race','income']).size().astype(float)\nfor categ in group_table.index.levels[0]:\n    for income in group_table[categ].index:\n        group_table[categ][income]=group_table[categ][income]\/diff_categ_count[categ]*100\ngroup_table.unstack().plot(kind='bar',stacked=True)\nplt.ylabel('percentage of income categ')","87bdbe68":"diff_categ_count=data['sex'].value_counts()\ngroup_table=data.groupby(['sex','income']).size().astype(float)\nfor categ in group_table.index.levels[0]:\n    for income in group_table[categ].index:\n        group_table[categ][income]=group_table[categ][income]\/diff_categ_count[categ]*100\ngroup_table.unstack().plot(kind='bar',stacked=True)\nplt.ylabel('percentage of income categ')","6b5ef56a":"\ndiff_categ_count=data['native-country'].value_counts()\ngroup_table=data.groupby(['native-country','income']).size().astype(float)\nfor categ in group_table.index.levels[0]:\n    for income in group_table[categ].index:\n        group_table[categ][income]=group_table[categ][income]\/diff_categ_count[categ]*100\ngroup_table.unstack().plot(kind='bar',stacked=True)\nplt.ylabel('percentage of income categ')","02b25053":"\ndiff_categ_count=data['is_capital'].value_counts()\ngroup_table=data.groupby(['is_capital','income']).size().astype(float)\nfor categ in group_table.index.levels[0]:\n    for income in group_table[categ].index:\n        group_table[categ][income]=group_table[categ][income]\/diff_categ_count[categ]*100\ngroup_table.unstack().plot(kind='bar',stacked=True)\nplt.ylabel('percentage of income categ')","d43a38fb":"diff_categ_count=data['is_loss'].value_counts()\ngroup_table=data.groupby(['is_loss','income']).size().astype(float)\nfor categ in group_table.index.levels[0]:\n    for income in group_table[categ].index:\n        group_table[categ][income]=group_table[categ][income]\/diff_categ_count[categ]*100\ngroup_table.unstack().plot(kind='bar',stacked=True)\nplt.ylabel('percentage of income categ')","4e36fde3":"diff_categ_count=data['hours_categ_week'].value_counts()\ngroup_table=data.groupby(['hours_categ_week','income']).size().astype(float)\nfor categ in group_table.index.levels[0]:\n    for income in group_table[categ].index:\n        group_table[categ][income]=group_table[categ][income]\/diff_categ_count[categ]*100\ngroup_table.unstack().plot(kind='bar',stacked=True)\nplt.ylabel('percentage of income categ')","6cfabc4f":"data.replace('>=60','>40',inplace=True)\ndata.replace('>40&<60','>40',inplace=True)","70e493c6":"data.head()\n","c22bbe3e":"features=list(data.columns)\nprint(features)\n\nfeatures.remove('income')\nX=data[features].copy()\nY=data['income']","fda43a57":"X.head()\n","29056b8b":"le=LabelEncoder()\nfor feature in features:\n    X[feature]=le.fit_transform(X[feature])\nY=[0 if val == ' <=50K' else 1 for val in Y]","1d163da1":"X=pd.get_dummies(X,columns=features)\nX.head()","3e849e04":"train_x,test_x,train_y,test_y=train_test_split(X,Y,test_size=0.20,random_state=9)\n","e4527ee8":"lr=LogisticRegression()\n","8bdbaddc":"lr.fit(train_x,train_y)\nprint('accuracy on training data:',lr.score(train_x,train_y))","ecd03f4f":"predicted_y=lr.predict(test_x)\nprint(classification_report(test_y,predicted_y))\nprint('accuracy_score is on test data: ',accuracy_score(test_y,predicted_y))","6bc58434":"plt.figure(figsize=(5,5))\nsns.heatmap(confusion_matrix(test_y,predicted_y),annot=True,fmt='.5g')\nplt.ylabel('actual class')\nplt.xlabel('predicted class')","3826823b":"## One-Hot Encoding\nIn some categorical features, where the number of unique values is large ,if we do label encoding then our model will bes biased for value assigned to different categories which is not good. So, we will use one-hot encding to solve this issue.","3478f52e":"## Distributing 'age' into different categories\n\n","e5ae4705":"Since,except United-States other countries have low count so they can belong to same category(other)\n\n","604ede91":"Finally,after performing data cleaning and feature engineering let's take a look at our dataset\u00b6\n","60a56ceb":"## Now lets start bivariate analysis\u00b6\n","02da18b8":"Different categories in 'marital_status'\n\n","158ae061":"## Label Encoding\nIn order to pass the features to the model for prediction, they must be continuous. So , we will use LabelEncoder to encode all the categorical variable into continuous values.","8bbcb112":"## Importing all necessary libraries","439fe8ca":"## Building Model\n","9275d0fd":"There are some outliers which needs to be handled.\n\n","49962fc2":"Filling '?' in occupation with mode\n\n","5a8a950f":"Never-worked and Without-pay can be considered as same column\n\n","bd55f6f3":"## cheking for any null value","5418b992":"## Splitting Data Into Train And Test Set\u00b6\n","892cbbbd":"### Dropping 'age' column\n\n","42df3746":"we can make two categories in capital loss one with no capital loss and another with some capital loss\n\n","00d41c4b":"'?' is not any workclass . It needs to be handled.","021542cc":"Asian-Pac-Islander,Amer-Indian-Eskim can be combined to other category because they have very low count\n\n","c3453971":"As we can see that fnlwgt distribution is same for both income types so we can drop it\n\n","57caacf0":"we can make two categories in capital gain one with no capital and another with some capital\n\n","6b5ea2c3":"Dividing 'hours-per-week' into categories\n\n","b7513bf5":"\nFilling '?' in workclass with mode"}}