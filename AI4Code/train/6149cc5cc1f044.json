{"cell_type":{"748683f2":"code","cdc8eae9":"code","f95a6764":"code","78f6e57f":"code","1f0b3a06":"code","27165c5a":"code","360010eb":"code","000b5f4c":"code","ef3e3bfb":"markdown","f4574831":"markdown","fcf7b248":"markdown","a410d195":"markdown","1960dd5b":"markdown","9d9b1bb0":"markdown"},"source":{"748683f2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cdc8eae9":"data = pd.read_csv('\/kaggle\/input\/fetal-health-classification\/fetal_health.csv')\ndata.head()","f95a6764":"data.fetal_health.value_counts()","78f6e57f":"data.isnull().sum()","1f0b3a06":"health_map = {\n    1: 'Normal',\n    2: 'Suspect',\n    3: 'Pathological'\n}\n\nfor i in data.index:\n    data.loc[i,'fetal_health'] = health_map[data.loc[i, 'fetal_health']]\ndata.head(20)","27165c5a":"from sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split as TTS\n\nX = data.drop(columns = 'fetal_health')\ny = data.fetal_health\n\nXtrain, Xtest, ytrain, ytest = TTS(X,y, test_size = .3, random_state = 2601744, stratify = y, shuffle = True)\n#Used the recommended test size of %30","360010eb":"from catboost import CatBoostClassifier\n\ncat = CatBoostClassifier(learning_rate = 0.03, l2_leaf_reg = 1,\n                        iterations = 500, depth = 9,\n                        border_count = 20, eval_metric = 'AUC')\n\ncat = cat.fit(Xtrain, ytrain,\n             eval_set = (Xtest, ytest),\n             early_stopping_rounds = 70, verbose = 20)","000b5f4c":"from sklearn.metrics import plot_confusion_matrix as PCM\n\nPCM(cat, Xtest, ytest, labels = ['Pathological', 'Suspect', 'Normal'], normalize = 'pred',\n   cmap = 'Greens', include_values = True, xticks_rotation = 30)\nplt.title('Confusion Matrix by Prediciton', fontdict = {'fontsize': 18}, pad = 15)","ef3e3bfb":"# Introduction\n\nI'm not doing anything terribly special here. Just creating a catboost classification model and soe visual representations of the results. I know that there's more work to do, but I kind of don't know where I should continue from what I have. Feedback is welcome.","f4574831":"I also wanted the results to be in string form, not integer form so that I wouldn't have to remember what they mean.","fcf7b248":"# CatBoostCalassifier\n\nI used the hyperparameters from a different notebook for a different dataset. I was also unclear on what the roc_auc meant quantitatively, so I plotted the confusion matrix by prediction to help me make sense of it.","a410d195":"Here, I'm not exactly sure of where to continue, partially due to a lack of contextual knowledge and partially due to lack of experience.\n\nOn the one hand, I don't know how good this test is in the context of medical tests in general. I do know that the worst possible outcome for this test is the scenario in the top right cell: the false negative prediction of normal condition. That is the one most likely to lead to the death of a baby. Is about a %1.3 chance of a false positive normal (but acutally Pathological) acceptably low in the context of such a test? Is the false positive Normal in the case that the result should be suspect also disasterous? I don't believe that the dataset gave much of an explanation as to what the difference is between a Pathological case and a Suspect.\n\nOn the other hand, I'm not sure about what I should do first to try to improve this model. I did basically no feature engineering, but I'm not sure what I should start with to improve the model and if the results I'm seeing here indicate that I should do something first. Should I stratify the sampling first or work on tuning the hyperparameters?\n\nThanks for reading and any input is appreciated.","1960dd5b":"# Column Descriptions\n* Baseline value: Baseline Fetal Heart Rate (FHR)\n* accelerations: Number of Accelerations per second\n* fetal_movement: Number of fetal movements per second\n* uterine_contractions: Number of uterine contractions per second\n* light_decelerations: Number of LDs per second\n* severe_decelerations: Number of SDs per second\n* prolonged_decelerations: Number of PDs per second\n* abnormal_short_term_variability: Percentage of time with abnormal short term variability\n* mean_value_of_short_term_variability: Mean value of short term variability\n* percentage_of_time_with_abnormal_long_term_variability: Percentage of time with abnormal long term variability\n* mean_value_of_long_term_viability: Mean value of long term variability\n* histogram_width: Width of the histogram made using all values from a record\n* histogram_min: Histogram minimum value\n* histogram_max: Histogram maximum value\n* histogram_number_of_peaks: Number of peaks in the exam histogram\n* histogram_number_of_zeroes: Number of Zeroes in the exact histogram\n* histogram_mode: Hist mode\n* histogram_mean: Hist mean\n* histogram_median: Hist median\n* histogram_variance: Hist variance\n* histogram_tendency: Histogram trend\n* fetal_health 1=Normal, 2=Suspect, 3=Pathological","9d9b1bb0":"# EDA\nThere isn't much cleaning to do here; There aren't any NaN values to replace, and all of the data is already in numerical values. Like the task for the dataset says, there is a class imbalance, but I ignored that for now, thinking that I would come back and stratify later if it was an issue."}}