{"cell_type":{"c979e98a":"code","61e634af":"code","1eab31bc":"code","91f35e6e":"code","15234ff7":"code","23fa1fb0":"code","9a2323bd":"code","da42cb68":"code","f0330e28":"code","9d143e1d":"code","83ef4980":"code","a0cb80aa":"code","a9092190":"code","7e2d27b9":"code","2f5761f9":"code","2bfa00fa":"code","e44ef043":"code","578c9c9e":"code","ffcc2f94":"code","7ff2e1fb":"code","4bd8fe10":"code","fcfdc5e5":"markdown","e22d2de4":"markdown","2a41f006":"markdown","7d233061":"markdown"},"source":{"c979e98a":"import os\nimport shutil\nimport pandas as pd\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\nfrom tensorflow.python.framework.config import list_physical_devices, set_memory_growth","61e634af":"# To fix \"Image File is truncated\" error during training\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True","1eab31bc":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline","91f35e6e":"# Settings for displaying charts\nplt.rcParams['figure.figsize'] = 12, 8\nplt.rcParams.update({'font.size': 12})","15234ff7":"physical_devices = list_physical_devices('GPU')\nprint(f'Number of GPUs available: {len(physical_devices)}')\n\nif len(physical_devices) > 0:\n    set_memory_growth(physical_devices[0], True)","23fa1fb0":"# TensorFlow settings\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nIMG_SIZE = 299\nBATCH_SIZE = 64","9a2323bd":"# Path to the folder with 9 classes of images:\ndata_path = '\/kaggle\/input\/mushrooms-classification-common-genuss-images\/Mushrooms'","da42cb68":"# Temporary folders for training, validation and test images:\nos.mkdir('\/kaggle\/temp')\nos.chdir('\/kaggle\/temp')\nos.mkdir('train')\nos.mkdir('valid')\nos.mkdir('test')\nos.chdir('\/kaggle\/working')","f0330e28":"# Split images (75%\/15%\/10%) and save to temporary folders:\nfor subfolder in os.listdir(data_path):\n\n    # Making a list of all files in current subfolder:\n    original_path = f'{data_path}\/{subfolder}'\n    original_data = os.listdir(original_path)\n\n    # Number of samples in each group:\n    n_samples = len(original_data)\n    train_samples = int(n_samples * 0.75)\n    valid_samples = int(n_samples * 0.9)\n        \n    train_path = f'\/kaggle\/temp\/train\/{subfolder}'\n    valid_path = f'\/kaggle\/temp\/valid\/{subfolder}'\n    test_path = f'\/kaggle\/temp\/test\/{subfolder}'\n    \n    # New class subfolder for training:\n    os.chdir('\/kaggle\/temp\/train')\n    os.mkdir(subfolder)\n    \n    # Training images:\n    for image in range(train_samples):\n        original_file = f'{original_path}\/{original_data[image]}'\n        new_file = f'{train_path}\/{original_data[image]}'\n        shutil.copyfile(original_file, new_file)\n    \n    # New class subfolder for validation:\n    os.chdir('\/kaggle\/temp\/valid')\n    os.mkdir(subfolder)\n    \n    # Validation images:\n    for image in range(train_samples, valid_samples):\n        original_file = f'{original_path}\/{original_data[image]}'\n        new_file = f'{valid_path}\/{original_data[image]}'\n        shutil.copyfile(original_file, new_file)\n    \n    # New class subfolder for testing:\n    os.chdir('\/kaggle\/temp\/test')\n    os.mkdir(subfolder)\n    \n    # Test images:\n    for image in range(valid_samples, n_samples):\n        original_file = f'{original_path}\/{original_data[image]}'\n        new_file = f'{test_path}\/{original_data[image]}'\n        shutil.copyfile(original_file, new_file)","9d143e1d":"# Displaying examples from each class\nnrows = 3\nncols = 3\n\npos = 0\n\nfor subfolder in os.listdir(data_path):\n    \n    image_file = os.listdir(os.path.join(data_path, subfolder))[0]\n    \n    fig = plt.gcf()\n    fig.set_size_inches(ncols * 4, nrows * 4)\n\n    pos += 1\n    sp = plt.subplot(nrows, ncols, pos)\n\n    cur_image = mpimg.imread(os.path.join(data_path, subfolder, image_file))\n    plt.imshow(cur_image)\n    plt.title(subfolder)\n    plt.axis('Off')","83ef4980":"# Create image datasets\ntrain_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\\\n                    .flow_from_directory(directory='\/kaggle\/temp\/train',\n                                         target_size=(IMG_SIZE, IMG_SIZE),\n                                         class_mode='categorical',\n                                         batch_size=BATCH_SIZE,\n                                         shuffle=True)\nvalid_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\\\n                    .flow_from_directory(directory='\/kaggle\/temp\/valid',\n                                         target_size=(IMG_SIZE, IMG_SIZE),\n                                         class_mode='categorical',\n                                         batch_size=BATCH_SIZE,\n                                         shuffle=True)\ntest_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\\\n                    .flow_from_directory(directory='\/kaggle\/temp\/test',\n                                         target_size=(IMG_SIZE, IMG_SIZE),\n                                         class_mode='categorical',\n                                         batch_size=BATCH_SIZE,\n                                         shuffle=True)","a0cb80aa":"# Pretrained EfficientNetB7 image classification model without final layers\nfeature_model = tf.keras.applications.EfficientNetB7(weights='imagenet',\n                                                     include_top=False,\n                                                     input_shape=(IMG_SIZE, IMG_SIZE, 3),\n                                                     pooling='avg')\n\nfeature_model.summary()","a9092190":"# Construct a new model with the final dense layer for 9 classes\nnew_model = tf.keras.models.Sequential(\n    [\n        feature_model,\n        tf.keras.layers.Dense(9, activation='softmax')\n    ]\n)","7e2d27b9":"# Make all the layers from the original ResNet model untrainable\nnew_model.layers[0].trainable = False","2f5761f9":"# Metrics and optimizer\nnew_model.compile(loss='categorical_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])","2bfa00fa":"# Check the architecture of the new model\nnew_model.summary()","e44ef043":"# Callbacks to be exercised during training\nearly_stop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n                                              patience=10,\n                                              restore_best_weights=True)\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy',\n                                                 factor=0.1,\n                                                 mode='max',\n                                                 cooldown=2,\n                                                 patience=2,\n                                                 min_lr=0)","578c9c9e":"# Train new model:\nhistory = new_model.fit(train_generator,\n                        validation_data=valid_generator,\n                        epochs=100,\n                        steps_per_epoch=79,\n                        validation_steps=16,\n                        verbose=2,\n                        callbacks=[reduce_lr, early_stop],\n                        use_multiprocessing=True,\n                        workers=2)","ffcc2f94":"loss, accuracy = new_model.evaluate(test_generator,\n                                    steps=11, \n                                    verbose=2, \n                                    use_multiprocessing=True, \n                                    workers=2)\nprint(f'Model performance on test images:\\nAccuracy = {accuracy}\\nLoss = {loss}')","7ff2e1fb":"# Loss during training:\nhistory_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot();","4bd8fe10":"# Accuracy during training:\nhistory_frame.loc[:, ['accuracy', 'val_accuracy']].plot();","fcfdc5e5":"# Displaying the results","e22d2de4":"## Creating a model","2a41f006":"# Neural network classifier for mushrooms","7d233061":"## Loading and processing data"}}