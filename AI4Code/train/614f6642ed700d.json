{"cell_type":{"d781e6e4":"code","73481c84":"code","ed725901":"code","55d1b72c":"code","3cc8d287":"code","ccec6efc":"code","03a263f2":"code","3d7f3ba6":"code","cb0f36f6":"code","24372ba5":"code","91498dbd":"code","c4f1967e":"code","3d337371":"code","12e9d486":"code","7475ef39":"code","e2547167":"code","3cd9b036":"code","ebe0e447":"code","872ad134":"code","e42d95af":"code","0bb82fa9":"code","e3aa8fee":"code","0c8e6c2a":"code","4aa4eb19":"code","a53e783e":"code","41c06ae7":"code","daf21561":"code","46e4eae4":"code","8a465955":"code","32431d76":"code","32009633":"code","d8a5deed":"code","63ce30c2":"code","b108d302":"code","efdc693f":"code","c6cc2b15":"code","5f2694a7":"code","39bab34f":"code","b0671f4b":"code","56d3f410":"code","e4af3304":"code","be89a5af":"markdown","18942b90":"markdown","332233a4":"markdown","6ac17429":"markdown","48a27281":"markdown","13cff567":"markdown","b771cd81":"markdown","4dd0ae4e":"markdown","6bb82583":"markdown","075d985e":"markdown","e514134c":"markdown","94d312f3":"markdown","3a8e5a07":"markdown"},"source":{"d781e6e4":"import tensorflow as tf","73481c84":"tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","ed725901":"import numpy as np\nimport pandas as pd\nimport os\nimport rasterio\nimport rasterio.features\nimport rasterio.warp\nfrom rasterio.plot import show\nfrom rasterio.mask import mask\nimport shapely\nfrom fiona.crs import from_epsg\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline","55d1b72c":"def scale(array):\n    arr_min = array.min(axis=(0, 1))\n    arr_max = array.max(axis=(0, 1))\n    return (array - arr_min) \/ (arr_max - arr_min)","3cc8d287":"dataset = rasterio.open('..\/input\/farmboundaries\/train\/Germany.tif')\npolygons = gpd.read_file('..\/input\/farmboundaries\/train\/field_ger.shp')","ccec6efc":"print(\"Dataset's crs \", dataset.crs)\nprint(\"Polygons's crs \", polygons.crs)","03a263f2":"polygons_mercator = polygons.to_crs({'init': 'epsg:3785'}) \nprint(\"polygons_mercator's crs \", polygons_mercator.crs)","3d7f3ba6":"shapes = []\ngeo = polygons_mercator.values[:, 1]\nfor i in range(len(polygons_mercator)):\n    shapes.append(geo[i])","cb0f36f6":"out = rasterio.mask.raster_geometry_mask(dataset, shapes)\nmasks = out[0].astype(np.int8)","24372ba5":"plt.imshow(masks, cmap='gray')","91498dbd":"rgb = dataset.read()","c4f1967e":"print('shape of rgb: ', rgb.shape)\nprint('shape of masks: ', masks.shape)","3d337371":"rgb1 = rgb[:, 2560:12800, 13600:20000]\nmasks1 = masks[2560:12800,  13600:20000]\nrgb2 = rgb[:, 0:2560, 0:5120]\nmasks2 = masks[0:2560,  0:5120]","12e9d486":"fig, ax = plt.subplots(1, 2, figsize=(8, 8))\nax[0].imshow(masks1, cmap = 'gray')\nax[0].set_title('Masks 1')\nax[1].imshow(masks2, cmap = 'gray')\nax[1].set_title('Mask 2')","7475ef39":"print('shape of rgb1: ', rgb1.shape)\nprint('shape of masks1: ', masks1.shape)\nprint('shape of rgb2: ', rgb2.shape)\nprint('shape of masks2: ', masks2.shape)","e2547167":"rgb1 = np.transpose(rgb1, (1, 2, 0))\nrgb1 = scale(rgb1)\nrgb2 = np.transpose(rgb2, (1, 2, 0))\nrgb2 = scale(rgb2)","3cd9b036":"rgb1 = resize(rgb1, (10240, 6400, 1), mode = 'constant', preserve_range = True)\nrgb2 = resize(rgb2, (2560, 5120, 1), mode = 'constant', preserve_range = True)","ebe0e447":"masks1 = resize(masks1, (10240, 6400, 1), mode = 'constant', preserve_range = True)\nmasks2 = resize(masks2, (2560, 5120, 1), mode = 'constant', preserve_range = True)","872ad134":"X = []\ny = []\nfor i in range(0, 10240, 128):\n    for j in range(0, 6400, 128):\n        X.append(rgb1[i:i+128, j:j+128, :])\n        y.append(masks1[i:i+128, j:j+128, :])\nfor i in range(0, 2560, 128):\n    for j in range(0, 5120, 128):\n        X.append(rgb2[i:i+128, j:j+128, :])\n        y.append(masks2[i:i+128, j:j+128, :])","e42d95af":"X = np.asarray(X)\ny = np.asarray(y)","0bb82fa9":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15, random_state=42)","e3aa8fee":"print('X_train: ', X_train.shape)\nprint('y_train: ', y_train.shape)\nprint('X_valid: ', X_valid.shape)\nprint('y_valid: ', y_valid.shape)","0c8e6c2a":"def plot_sample(X, y, id):\n    fig, ax = plt.subplots(1, 2, figsize=(10, 10))\n    ax[0].imshow(X[id, ..., 0])\n    ax[0].set_title('Satellite')\n    ax[1].imshow(y[id,..., 0], cmap = 'gray')\n    ax[1].set_title('Mask')","4aa4eb19":"plot_sample(X, y, 1997)","a53e783e":"import tensorflow as tf\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\nfrom keras.layers.core import Lambda, RepeatVector, Reshape\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\nfrom keras.layers.merge import concatenate, add\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img","41c06ae7":"def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n    # 1st layer\n    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n    if batchnorm:\n        x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    # 2nd layer\n    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n    if batchnorm:\n        x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    return x","daf21561":"def get_unet(input_img, n_filters = 16, dropout = 0.05, batchnorm = True):\n    \"\"\"Function to define the UNET Model\"\"\"\n    # Contracting Path\n    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n    p1 = MaxPooling2D((2, 2))(c1)\n    p1 = Dropout(dropout)(p1)\n    \n    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n    p2 = MaxPooling2D((2, 2))(c2)\n    p2 = Dropout(dropout)(p2)\n    \n    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n    p3 = MaxPooling2D((2, 2))(c3)\n    p3 = Dropout(dropout)(p3)\n    \n    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n    p4 = MaxPooling2D((2, 2))(c4)\n    p4 = Dropout(dropout)(p4)\n    \n    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n    \n    # Expansive Path\n    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n    u6 = concatenate([u6, c4])\n    u6 = Dropout(dropout)(u6)\n    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n    \n    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n    u7 = concatenate([u7, c3])\n    u7 = Dropout(dropout)(u7)\n    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n    \n    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n    u8 = concatenate([u8, c2])\n    u8 = Dropout(dropout)(u8)\n    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n    \n    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n    u9 = concatenate([u9, c1])\n    u9 = Dropout(dropout)(u9)\n    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n    \n    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n    model = Model(inputs=[input_img], outputs=[outputs])\n    return model","46e4eae4":"im_width = 128\nim_height = 128","8a465955":"input_img = Input((im_height, im_width, 1), name='img')\nwith tpu_strategy.scope():\n    model = get_unet(input_img, n_filters=16, dropout=0.1, batchnorm=True)\n    model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])","32431d76":"model.summary()","32009633":"earlyStopping = EarlyStopping(patience=7, verbose=1)\nmcp_save = ModelCheckpoint('farm_model.h5', verbose=1, save_best_only=True, save_weights_only=True)\nreduce_lr_loss = ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.000001, verbose=0)\ncallbacks = [earlyStopping, mcp_save, reduce_lr_loss]","d8a5deed":"results = model.fit(X_train, y_train, batch_size=32, epochs=35, callbacks = callbacks, validation_data=(X_valid, y_valid))","63ce30c2":"plt.figure(figsize=(8, 8))\nplt.title(\"Learning curve\")\nplt.plot(results.history[\"loss\"], label=\"loss\")\nplt.plot(results.history[\"val_loss\"], label=\"val_loss\")\nplt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"log_loss\")\nplt.legend();","b108d302":"model.evaluate(X_valid, y_valid, verbose=1)","efdc693f":"preds_train = model.predict(X_train, verbose=1)\npreds_val = model.predict(X_valid, verbose=1)","c6cc2b15":"preds_train_t = (preds_train > 0.5).astype(np.uint8)\npreds_val_t = (preds_val > 0.5).astype(np.uint8)","5f2694a7":"import random","39bab34f":"def plot_prediction(X, y, preds, binary_preds, id=None):\n    if id is None:\n        id = random.randint(0, len(X))\n\n    has_mask = y[id].max() > 0\n\n    fig, ax = plt.subplots(1, 4, figsize=(20, 10))\n    ax[0].imshow(X[id, ..., 0])\n    if has_mask:\n        ax[0].contour(y[id].squeeze(), colors='k', levels=[0.5])\n    ax[0].set_title('Satellite')\n\n    ax[1].imshow(y[id].squeeze(), cmap = 'gray')\n    ax[1].set_title('Farm')\n\n    ax[2].imshow(preds[id].squeeze(), vmin=0, vmax=1)\n    if has_mask:\n        ax[2].contour(y[id].squeeze(), colors='k', levels=[0.5])\n    ax[2].set_title('Farm Predicted')\n    \n    ax[3].imshow(binary_preds[id].squeeze(), vmin=0, vmax=1, cmap = 'gray')\n    if has_mask:\n        ax[3].contour(y[id].squeeze(), colors='k', levels=[0.5])\n    ax[3].set_title('Farm Predicted binary');","b0671f4b":"plot_prediction(X_train, y_train, preds_train, preds_train_t)","56d3f410":"plot_prediction(X_train, y_train, preds_train, preds_train_t)","e4af3304":"plot_prediction(X_train, y_train, preds_train, preds_train_t)","be89a5af":"Create mask from dataset and shape","18942b90":"T\u1eeb \u1ea3nh g\u1ed1c v\u00e0 masks, ta t\u1ea1o ra b\u1ed9 d\u1eef li\u1ec7u luy\u1ec7n b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng m\u1ed9t c\u1eeda s\u1ed5 tr\u01b0\u1ee3t k\u00edch th\u01b0\u1edbc (128, 128) \u0111\u1ec3 c\u1eaft \u1ea3nh v\u00e0 masks th\u00e0nh nhi\u1ec1u \u1ea3nh nh\u1ecf","332233a4":"# 1. Visualize Dataset","6ac17429":"L\u01b0u l\u1ea1i m\u00f4 h\u00ecnh t\u1ed1t nh\u1ea5t v\u1edbi callbacks","48a27281":"# Semantic Segamantaion with UNET","13cff567":"# 2. Data pre-processing","b771cd81":"![image.png](attachment:image.png)","4dd0ae4e":"split dataset","6bb82583":"dataset's coordinates is different from shape's. So we need change crs of shape (Because dataset is read-only)","075d985e":"Check dataset's coordinates","e514134c":"# 4. Predictions ","94d312f3":"# 3. UNET Model","3a8e5a07":"scale array in range (0, 1) to reduce gradient exploding when train model"}}