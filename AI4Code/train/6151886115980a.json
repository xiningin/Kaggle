{"cell_type":{"abc4c5be":"code","025389bf":"code","a25570a8":"code","38eb6646":"code","4e86b96b":"code","7676ff81":"code","dcb150ba":"code","d01c1bfb":"code","818ee879":"code","104ea4fc":"code","a2dbf8a7":"code","8c74c152":"code","961120cc":"code","0bc29f88":"code","b0db538b":"code","337555f7":"code","e6a74a2f":"code","c2b3c6ca":"code","b5947c9a":"code","93f807d3":"code","5ab2200b":"code","332e7a78":"code","d8d0cf42":"code","95336eac":"code","6ea89577":"code","205900a2":"code","806ecd04":"code","dc7615e6":"code","bc264034":"code","74726afc":"code","43f638f3":"code","6f05b56b":"code","4fd9fce3":"code","d596cfa1":"code","70c479d1":"code","ab58dba3":"code","43e6e968":"code","6fd17f8c":"code","193c8834":"code","a4d0e3a8":"code","c0fb36b5":"code","5d63032b":"code","0a40256a":"code","ddb610e5":"code","e0d23d18":"code","f005b002":"code","92171823":"code","334fbdbe":"code","4e50c32e":"code","51391c62":"code","2e1c9148":"code","742ac4c6":"code","77470027":"code","c489ae49":"code","e4d0c99e":"code","988e4335":"code","8ff2e4a4":"code","a14ab2ca":"code","c5a0bc2c":"code","a65ab4d1":"code","80d761fc":"code","e4985ac4":"code","6d8a1eae":"code","92980dd1":"code","fe684e39":"code","0c8c0459":"code","36a02763":"code","2fd40598":"code","94c6a94d":"code","b3b06127":"markdown","79f82c48":"markdown","36418977":"markdown","626be0f1":"markdown","4e871e48":"markdown","eaf79992":"markdown","393384dc":"markdown","42c15c90":"markdown","3399f272":"markdown","ee83ec28":"markdown","7aaafe65":"markdown","30f682ff":"markdown","9d76dcdf":"markdown","ed63bf3e":"markdown","6a69bdd6":"markdown","56e5f8d5":"markdown","dbebb853":"markdown","db755b36":"markdown","173af8cb":"markdown","dfd81f05":"markdown","85066dc6":"markdown","50e0a4b5":"markdown","e25612c7":"markdown","65f3978e":"markdown","202c3300":"markdown","4355f9a9":"markdown","bf5ad2c8":"markdown","1e561f9e":"markdown","da3728c6":"markdown","0de9a8a1":"markdown"},"source":{"abc4c5be":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","025389bf":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport re\nimport string\nfrom scipy import stats","a25570a8":"df = pd.read_csv(r'\/kaggle\/input\/singapore-airbnb\/listings.csv')","38eb6646":"# first lets evaulate the data in a broad manner \ndf","4e86b96b":"# lets see all the data types present in the data set and understand the data\ndf.info()","7676ff81":"#lets verify if there are null values in the data set \ndf.isnull().sum()","dcb150ba":"# we can use regex wild cards in python to look for unique values by using unique identifying chars\nprint('column name' + '\\t\\t\\t' + 'IsUnique')\ndf.apply(lambda x: x.is_unique,axis=0)","d01c1bfb":"#first we look for the null values in neighbour hood columns in which places\nprint(df[df['neighbourhood_group'].isnull()]['neighbourhood_group'].value_counts())","818ee879":"# we shall drop id since its not unique \ndf = df.drop('id', axis=1)","104ea4fc":"# improvement, since we dropped one column\ndf.apply(lambda x: sum(x.isnull()),axis=0)","a2dbf8a7":"#first we look for the null values in neighbour hood columns, in which places\nprint(df[df['neighbourhood'].isnull()]['neighbourhood_group'].value_counts())","8c74c152":"# we visualize the file here for ease of view\ndf","961120cc":"#thus for the missing reigons we can identify them with the particular city the affliated with the most\nprint(df[df['neighbourhood_group'].isnull()]['neighbourhood'].value_counts())","0bc29f88":"# lets now check if the missing values of 'River Valley' has been filled\nprint(df[df['neighbourhood_group'].isnull()]['neighbourhood'].value_counts())","b0db538b":"# lets examine if there are other missing values in Central reigion \nprint(df[df['neighbourhood_group'] == 'Central Region']['neighbourhood'].value_counts())","337555f7":"# we now replace the central reigon vallues with kallang as its the MODE\ncond = (df['neighbourhood_group'] == 'Central Region') & (df['neighbourhood'].isnull())\ndf.loc[cond, 'neighbourhood'] = 'Kallang'","e6a74a2f":"# Now we shall check if it has been filled \nprint(df[df['neighbourhood'].isnull()]['neighbourhood_group'].value_counts())","c2b3c6ca":"# we check the mode of 'East Region'\nprint(df[df['neighbourhood_group'] == 'East Region']['neighbourhood'].value_counts())\nprint(df[df['neighbourhood_group'] == 'North-East Region']['neighbourhood'].value_counts())\nprint(df[df['neighbourhood_group'] == 'North Region']['neighbourhood'].value_counts())","b5947c9a":"# we replace the value of the missing values of East Region with Bedok\ncond1 = (df['neighbourhood_group'] == 'East Region') & (df['neighbourhood'].isnull())\ndf.loc[cond1, 'neighbourhood'] = 'Bedok'\n# we over here replace the value of the missing values of the North-East region with Hougang\ncond2 = (df['neighbourhood_group'] == 'North-East Region') & (df['neighbourhood'].isnull())\ndf.loc[cond2, 'neighbourhood'] = 'Hougang'\n# we over here replace the value of the missing values of the North Region with Woodlands\ncond3 = (df['neighbourhood_group'] == 'North Region') & (df['neighbourhood'].isnull())\ndf.loc[cond3, 'neighbourhood'] = 'Woodlands'","93f807d3":"# thus we shall now check if all missing value replacement was a success\nprint(df[df['neighbourhood'].isnull()]['neighbourhood_group'].value_counts())","5ab2200b":"df.isnull().sum()","332e7a78":"print(df[df['neighbourhood_group'].isnull()]['neighbourhood'].value_counts())","d8d0cf42":"df['neighbourhood_group'].value_counts()","95336eac":"# we shall use a function with Regex characters in re.match method to fill the null values of Neighbourhood groups as they cant be fecthed\n# using common filling methods due to the presence of a large no of unique values as shown in value counts\nd = df['neighbourhood'].unique()\nfor val in d:\n    i = str(df[df['neighbourhood'] == val]['neighbourhood_group'].value_counts())\n    c = re.match('\\w+(?:-\\w+)+\\s.[a-z]*|.[a-z]*\\s.[a-z]*',i)\n    condo = (df['neighbourhood'] == val) & (df['neighbourhood_group'].isnull())\n    df.loc[condo,'neighbourhood_group'] = c[0]","6ea89577":"# now we check if the neighbourhood_group column  is cleaned by applying lamda to the isnull function for full accuracy\ndf.apply(lambda x: sum(x.isnull()),axis=0)","205900a2":"# we shall replace missing values using the mean\n# by first converting the dataframe to numeric data\ndf['minimum_nights'] = pd.to_numeric(df['minimum_nights'], errors= 'coerce')","806ecd04":"# we now calculate the mean\ndf['minimum_nights'].mean()","dc7615e6":"# we now fill the mean of 17.53 calculated above in the missing values\ndf['minimum_nights'].fillna(17.53, inplace = True)","bc264034":"# lets now test if the null values have been filled\ndf.apply(lambda x: sum(x.isnull()),axis=0)","74726afc":"# Lets check in which columns do missing Values remain \ndf.isnull().sum()","43f638f3":"# we shall first replace all missing values using mode as its not a unique value, but we cannot drop it cause it will\n# create disrepancies in our dataset\ndf['name'].mode()","6f05b56b":"# thus we fill it using the mode of 'Luxury hostel with in-cabin locker - Single mixed\ndf['name'].fillna('Luxury hostel with in-cabin locker - Single mixed', inplace = True)","4fd9fce3":"# now we shall test if that worked \ndf.isnull().sum()","d596cfa1":"df['room_type'].isnull().sum()","70c479d1":"df['room_type'].value_counts()","ab58dba3":"# we shall use groupby to check which room type matches with which neigbourhood_group to atleast know \n# we first convert them both to category variables so they can be correlated\ndf= df.astype({'room_type': 'category', 'neighbourhood_group': 'category' })\n","43e6e968":"df.groupby(['room_type', 'neighbourhood_group']).size()","6fd17f8c":"print(df[df['room_type'].isnull()]['neighbourhood_group'])","193c8834":"# now we shall fill the missing values in room_type based on which region has which highest room_type\n# we here fill the missing values of 1 with east region\nc0 = (df['neighbourhood_group'] == 'East Region') & (df['room_type'].isnull())\ndf.loc[c0, 'room_type'] = 'Private room'\n\nc1 = (df['neighbourhood_group'] == 'Central Region') & (df['room_type'].isnull())\ndf.loc[c1, 'room_type'] = 'Entire home\/apt'\n\n\nc2 = (df['neighbourhood_group'] == 'North Region') & (df['room_type'].isnull())\ndf.loc[c2, 'room_type'] = 'Entire home\/apt'\n\n\nc3 = (df['neighbourhood_group'] == 'West Region') & (df['room_type'].isnull())\ndf.loc[c3, 'room_type'] = 'Shared room'\n\nc4 = (df['neighbourhood_group'] == 'North-East Region') & (df['room_type'].isnull())\ndf.loc[c3, 'room_type'] = 'Private room'","a4d0e3a8":"# now we shall test if all null values have been filled in room_type\ndf.apply(lambda x: sum(x.isnull()))","c0fb36b5":"# we can replace all the missing values using mode as it will place the most common review review\n# in the missing value\ndf['last_review'].mode","5d63032b":"df.last_review.mode()","0a40256a":"# thus we need to place [0] after mode using the fillna function to ensure it places the actual date as the mode\ndf['last_review'].fillna(df['last_review'].mode()[0],inplace = True)","ddb610e5":"# now we test if that succeeded\ndf.apply(lambda x: sum(x.isnull()))","e0d23d18":"df","f005b002":"# we apply mean here to fill the null values , since its only plausible to know Availibility on \n# average in particular durations\ndf['availability_365'].mean","92171823":"df['availability_365'].fillna(df['availability_365'].mean(), inplace = True)","334fbdbe":"# now we test if the null values have been filled in availibility_365\ndf.apply(lambda s: sum(s.isnull()))","4e50c32e":"# we shall use mode here, as it would deem optimal to use the most common review by most customers to fill in \n# the missing values without denting accuracy by a large extent\n\ndf['reviews_per_month'].mode()","51391c62":"# thus we we fill in the mode within the missing values \ndf['reviews_per_month'].fillna(df['reviews_per_month'].mode()[0], inplace = True)","2e1c9148":"# now we confirm if our dataset is clean\ndf.apply(lambda b: sum(b.isnull()))","742ac4c6":"# we replace the remaining null values of room_type with mode\ndf['room_type'].mode","77470027":"df['room_type'].fillna(df['room_type'].mode()[0], inplace= True)","c489ae49":"# now we confirm if our dataset is clean\ndf.apply(lambda b: sum(b.isnull()))","e4d0c99e":"# now we conduct ANOVA and T-test to check the accuracy of our results of cleaning methods \n# we first import the statistics library for it and import stats module from scipy","988e4335":"import statistics as stat\nfrom scipy import stats","8ff2e4a4":"# first we shall conduct the t-test between \n# number_of_reviews and minimum_nights to test how much customers like spendinf time at each lodge and do more \n# nights being spent result in less satisfaction for customer\ndf['number_of_reviews'].astype(int)\ndf['minimum_nights'].astype(int)","a14ab2ca":"test = stats.ttest_ind(df['number_of_reviews'], df['minimum_nights'])","c5a0bc2c":"print(test)","a65ab4d1":"# we now check it for minimum_nights and availibility_365\ntest1 = stats.ttest_ind(df['minimum_nights'], df['availability_365'])\nprint(test1)","80d761fc":"# we now check it for price and host_id\ntest2 = stats.ttest_ind(df['price'], df['minimum_nights'])\nprint(test2)","e4985ac4":"# we first create a list of all num_columns for ease of calculation\nnum_cols = ['latitude','longitude','price','minimum_nights','number_of_reviews','reviews_per_month','calculated_host_listings_count','availability_365','Total_Amount_Paid']","6d8a1eae":"# we convert last_review to datetime to use it in the ANOVA test\ndf['last_review'] = pd.to_datetime(df['last_review'])","92980dd1":"# now we start the ANOVA one_way test between 'last_review' and 'review_per_month'\nANOVA_test = stats.f_oneway(df['last_review'],df['reviews_per_month'])","fe684e39":"print(ANOVA_test)","0c8c0459":"# now we start the ANOVA one_way test between 'minimum_nights' and 'availibility_365'\nANOVA_test2 = stats.f_oneway(df['minimum_nights'],df['availability_365'])","36a02763":"print(ANOVA_test2)","2fd40598":"# now we start the ANOVA one_way test between 'minimum_nights' and 'availibility_365'\nANOVA_test3 = stats.f_oneway(df['price'],df['calculated_host_listings_count'])","94c6a94d":"print(ANOVA_test3)","b3b06127":"thus with probability being less than 0.05 we reject our null hypothesis here, showing there is a relationship \nbetween price and how much customers are willing to stay on.","79f82c48":"#  what is our strategy for filling missing values in the neighborhood group?","36418977":"Thus having a p < 0.05 proves that we can reject our null hypothesis and prove with a 95% assurity that a difference in means exist between minimum_nights and availability_365 thus making it easier for Airbnbs management to claim that customers spedning more nights is affecting space available for more customers throughout the year.","626be0f1":"# Conduct t-test between the relevant columns and explain the result (it should make logical sense to conduct the test)","4e871e48":"Missing values in reviews per Month are being replaced using the mean, and another solutio for this would be using\nthe Mode as we since this a cetegorical variable based on qualititative insights, using the most common review would \ngive us a better view of what most customers are thinking and work according to it in improvements","eaf79992":"Student: Muhammad Ammar Jamshed ","393384dc":"After evaulating the data set we can conclude that the data belongs to the Hoteling industry and is recording information\non customers who are using Airbnb to spend nights in hotels and lodges in Singapore","42c15c90":"thus we succeded in cleaning both Neighbourhood and neighbourhood_group column","3399f272":"#   Conduct ANOVA (one-way, i.e., one string and one numerical column) between the relevant columns and explain the result (it should make logical sense to conduct the test)","ee83ec28":"# Explain how missing values are being replaced in reviews per month. Can you think of another solution for this?","7aaafe65":"# availibility_365","30f682ff":"The values in the host name are being replaced with the value 0 ti avoid inaccuracies of replacing the hostname \nwith the wrong variable.\n\nThere are other solutions available for this as well such as using mode to fill the null values with the most common\nhostname, as the host_id being a unique identifier of each name holds the aunthentic verification of the hostname\nand also using the related neighbourhood_group to fill the missing hostname as Hostname Francesca resides in\nthe north reigion with the host_id 266763, thus we can fill with either and still have relative accuracy but more so with \nhost_id","9d76dcdf":"# Room Type Column","ed63bf3e":" thus we now only have reviews_per_month left ","6a69bdd6":"Thus as shown above we have successfully filled the remaining values of minimum nights with mean","56e5f8d5":"# Replace missing values in minimum nights with the mean","dbebb853":" thus since here the value is less than 0.05 thus we can reject our null hypothesis of there being no difference \n and that minimum_nights and availibility_365 have a relationship as more customers spending nights does affect \n room availibility","db755b36":"# reviews_per_month","173af8cb":"# Explain how missing values are being replaced in hostname. Can you think of another solution for this?","dfd81f05":"# last_review","85066dc6":"# Remove all missing values in the bnb file according to your own plan if needed, i.e. you can change the way for \n# replacing the missings in one or more columns. In this case, mention which changes you have made","50e0a4b5":" since the value is greater than 0.05 thus we fail to reject our null hypothesis that there is no difference\n and number of reviews and minimum_nights dont have a strong","e25612c7":"Thus its succeeded here now we have ti fill the same for East, North and North East by checking their mode ","65f3978e":"# what is our strategy for filling missing values in the neighborhood?","202c3300":"now we are left with the null values of reviews_per_month and availibility_365","4355f9a9":"now we are only left with last_review and reviews_per_month and availability 365\n","bf5ad2c8":"Thus we succed in eliminting the null values in the 'name' column","1e561f9e":"Thus having a p < 0.05 proves that we can reject our null hypothesis and prove with a 95% assurity \nthat a difference in means exist betweem last_review and review_per_month thus making it hard for Airbnb stakeholders \nto deny that 'we are not receieving many customer reviews'","da3728c6":"thus proven we have filled all null values in the Neighbourhood column by using the mode of each Region","0de9a8a1":"Over here we fail to reject our null hypothesis as p > 0.05 proves the means are different betweem prices charged and calculated host lisitings. Thus proving that some hosts may be charging the same prices."}}