{"cell_type":{"701161d0":"code","941fc2da":"code","1a02a14b":"code","7c7ca361":"code","9eaba347":"code","38563312":"code","df903937":"code","e96d94e1":"code","54847a89":"code","b8d81bba":"code","d9d54756":"code","904ecc0a":"code","7cea19b8":"code","2aa2f12c":"code","194e04bc":"code","82a590f6":"code","73a8cd1f":"code","d20af05b":"code","fad548e0":"code","f51e0bd7":"code","2ac2fa54":"code","05610527":"code","f7d4474b":"code","3a9164a0":"code","67cae5b0":"code","bca91de0":"code","ec225a43":"code","a80f72fa":"code","6586d1e9":"code","d0e3c414":"code","1e3fa395":"code","177e3b59":"code","531f8a60":"code","fa3f3ccf":"markdown","da2b9d84":"markdown","f880208a":"markdown","c99cc712":"markdown","88f55ad9":"markdown","4d0f2b39":"markdown","7835e172":"markdown","62dd65ff":"markdown","3f88b6d8":"markdown","5567651d":"markdown","bdbc2056":"markdown","2a04a0f3":"markdown","b5271553":"markdown","e0e6bb7d":"markdown","03ff2272":"markdown","ec77084c":"markdown","03aa5112":"markdown","6b791316":"markdown","878ea1ae":"markdown","67b48f7f":"markdown","1162a6f6":"markdown","3688e5a2":"markdown","4bda2cba":"markdown","e17ab6b9":"markdown","a4bec91b":"markdown","51f102d4":"markdown","f867ac5c":"markdown","11e94b38":"markdown","f7912e73":"markdown","1f609ac0":"markdown","17db8c26":"markdown","17ffd4fb":"markdown","718e18be":"markdown"},"source":{"701161d0":"# Basic packages\nimport pandas as pd\nimport numpy as np\nimport os\n# Analysis visualization packages\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Tensorflow packages for model building\nimport tensorflow as tf\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Conv2D, BatchNormalization, MaxPooling2D, Flatten, Concatenate\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, CSVLogger, TensorBoard\nfrom tensorflow.keras import backend as K\nfrom sklearn.model_selection import train_test_split","941fc2da":"# Find GPU device\nphysical_device = tf.config.experimental.list_physical_devices('GPU')\nprint(f'Device found : {physical_device}')\n# If there is more than 1 visible GPU on the host\nif (len(physical_device) >= 1):\n    # Check if GPU is on used for training or not\n    if (tf.config.experimental.get_memory_growth(physical_device[0]) == 1):\n        # If the check returns False or nothing => set GPU for training\n        tf.config.experimental.set_memory_growth(physical_device[0],True)","1a02a14b":"dir_csv = '..\/input\/petfinder-pawpularity-score\/'\n\ntrain_df = pd.read_csv(dir_csv+'train.csv')\ntest_df = pd.read_csv(dir_csv+'test.csv')\n\n# Check if there are NaN values in the train & test dataset\nprint('Train dataset has NaN values: ', train_df.isnull().values.any())\nprint('Test dataset has NaN values: ', test_df.isnull().values.any())","7c7ca361":"train_df.head()","9eaba347":"corr_train_df = train_df.corr()\nplt.figure(figsize=(14, 8))\nsns.set(font_scale=1)\nax = sns.heatmap(corr_train_df,\n        vmin=-1, vmax=1, annot=True, linewidths=.5,\n        xticklabels=corr_train_df.columns,\n        yticklabels=corr_train_df.columns)\nax.set_ylim(len(corr_train_df.keys()),0)","38563312":"corr_train_df = train_df.corr()\nplt.figure(figsize=(10, 8))\nsns.set(font_scale=1)\nax = sns.heatmap(corr_train_df[['Pawpularity']],\n        vmin=-1, vmax=1, annot=True, linewidths=.5,\n        xticklabels=['Pawpularity'],\n        yticklabels=corr_train_df.columns\n        )\nax.set_ylim(len(corr_train_df.keys()),0)","df903937":"print('Min value of pawpularity: ', train_df['Pawpularity'].values.min())\nprint('Max value of pawpularity: ', train_df['Pawpularity'].values.max())","e96d94e1":"%matplotlib inline\ntrain_df['Pawpularity'].plot(kind=\"hist\", bins=100)","54847a89":"# Number of occurence sorted by pawpularity class\ntrain_df['Pawpularity'].value_counts().sort_index()","b8d81bba":"# Number of occurence sorted by the highest number of occurence\ntrain_df['Pawpularity'].value_counts()","d9d54756":"tr_df, val_df = train_test_split(train_df, test_size=0.1, random_state=2)\nprint(tr_df.shape)\nprint(val_df.shape)","904ecc0a":"tr_df['Pawpularity'].plot(kind=\"hist\", bins=100)","7cea19b8":"# New data fram for sampled train dataset\nsampled_tr_df = pd.DataFrame(columns=tr_df.keys())","2aa2f12c":"# number of max occurence\nmax_occ = tr_df['Pawpularity'].value_counts().max()\n\nfor class_i in range(1,101):\n    # If the class is not the dominating class (i.e. number of occurence <= max_occ), do oversampling\n    # and append to sampled_tr_df\n    if(tr_df[tr_df['Pawpularity'] == class_i]['Pawpularity'].value_counts().values[0] < max_occ):\n        ids_class_i = tr_df.index[tr_df['Pawpularity'] == class_i].tolist()\n        sampled_ids_class_i = np.random.choice(ids_class_i, max_occ)\n        sampled_tr_df = pd.concat([sampled_tr_df, tr_df.loc[sampled_ids_class_i]])\n    # If it is the dominating class, directly append to sampled_tr_df\n    else:\n        ids_class_i = tr_df.index[tr_df['Pawpularity'] == class_i].tolist()\n#         sampled_tr_df = sampled_tr_df.append(tr_df.loc[ids_class_i])\n        sampled_tr_df = pd.concat([sampled_tr_df, tr_df.loc[ids_class_i]])\n        \n# Reindex sampled_tr_df\nsampled_tr_df = sampled_tr_df.reset_index(drop=True)","194e04bc":"sampled_tr_df['Pawpularity'].plot(kind=\"hist\", bins=100)","82a590f6":"# Dataframe info\nprint('tr_df:', tr_df.info())\nprint('sampled_tr_df:', sampled_tr_df.info())","73a8cd1f":"# Change data type (i.e. dtype) of all features except 'Id' to int64 \nfor key in sampled_tr_df.keys()[1:]:\n    sampled_tr_df[key] = sampled_tr_df[key].astype('int64')\nprint('sampled_tr_df:', sampled_tr_df.info())","d20af05b":"class CustomTrainDataGen(Sequence):\n    \n    def __init__(self, df, X_col, y_col,\n                 batch_size,\n                 input_size=(250, 250, 3),\n                 shuffle=True): \n        self.df = df.copy()\n        self.X_col = X_col\n        self.y_col = y_col\n        self.batch_size = batch_size\n        self.input_size = input_size\n        self.list_IDs = np.arange(len(self.df.index))\n        self.indexes = np.arange(len(self.df.index))\n        self.shuffle = shuffle \n        self.n = len(self.df)\n    \n    def on_epoch_end(self):\n        if self.shuffle:\n            self.df = self.df.sample(frac=1).reset_index(drop=True)\n    \n    def __get_input(self, path, target_size):\n        # Check if train dataset: train_df\n        if (len(self.df.keys()) == len(train_df.keys())):\n            img_path = dir_csv+'train\/'+str(path)+'.jpg'\n        else:\n            print(\"Generator Image Data Generation Error\")\n            return -1\n        image = tf.keras.preprocessing.image.load_img(img_path)\n        image_arr = tf.keras.preprocessing.image.img_to_array(image)\n        image_arr = tf.image.resize(image_arr,(target_size[0], target_size[1])).numpy()\n\n        return image_arr\/255.\n    \n    def __get_data(self, batches):\n        # Generates data containing batch_size samples\n        subfocus_batch = self.df.iloc[batches, :]['Subject Focus'].values\n        eyes_batch = self.df.iloc[batches, :]['Eyes'].values\n        face_batch = self.df.iloc[batches, :]['Face'].values\n        near_batch = self.df.iloc[batches, :]['Near'].values\n        action_batch = self.df.iloc[batches, :]['Action'].values\n        acc_batch = self.df.iloc[batches, :]['Accessory'].values\n        group_batch = self.df.iloc[batches, :]['Group'].values\n        collage_batch = self.df.iloc[batches, :]['Collage'].values\n        human_batch = self.df.iloc[batches, :]['Human'].values\n        occlusion_batch = self.df.iloc[batches, :]['Occlusion'].values\n        info_batch = self.df.iloc[batches, :]['Info'].values\n        blur_batch = self.df.iloc[batches, :]['Blur'].values\n        # Resize to (self.batch_size, 1)\n        subfocus_batch = np.expand_dims(subfocus_batch, axis=1)\n        eyes_batch = np.expand_dims(eyes_batch, axis=1)\n        face_batch = np.expand_dims(face_batch, axis=1)\n        near_batch = np.expand_dims(near_batch, axis=1)\n        action_batch = np.expand_dims(action_batch, axis=1)\n        acc_batch = np.expand_dims(acc_batch, axis=1)\n        group_batch = np.expand_dims(group_batch, axis=1)\n        collage_batch = np.expand_dims(collage_batch, axis=1)\n        human_batch = np.expand_dims(human_batch, axis=1)\n        occlusion_batch = np.expand_dims(occlusion_batch, axis=1)\n        info_batch = np.expand_dims(info_batch, axis=1)\n        blur_batch = np.expand_dims(blur_batch, axis=1)\n\n        id_batch = self.df.iloc[batches, :]['Id'].values      \n        image_batch = np.asarray([self.__get_input(id, self.input_size) for id\\\n             in id_batch])\n        # Reshape to (self.batch_size, input_shape[0]*input_shape[1]*input_shape[2])\n        image_batch = np.reshape(image_batch,(self.batch_size,-1))\n        \n        pawpularity_batch = self.df.iloc[batches, :]['Pawpularity'].values\n#         # Convert pawpularity that ranges from 0 to 100 to a range of 0 to 1\n#         pawpularity_batch = pawpularity_batch \/ 100\n\n        X_batch = np.concatenate((subfocus_batch, eyes_batch, face_batch, near_batch,\\\n            action_batch, acc_batch, group_batch, collage_batch, human_batch,\\\n               occlusion_batch, info_batch, blur_batch, image_batch),axis=1)\n        y_batch = pawpularity_batch\n        return X_batch, y_batch\n    \n    def __getitem__(self, index):\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]    \n        X, y = self.__get_data(indexes)  \n        return X, y\n    \n    def __len__(self):\n        return self.n \/\/ self.batch_size","fad548e0":"class CustomTestDataGen(Sequence):\n    \n    def __init__(self, df, X_col,\n                 batch_size,\n                 input_size=(250, 250, 3),\n                 shuffle=True): \n        self.df = df.copy()\n        self.X_col = X_col\n        self.batch_size = batch_size\n        self.input_size = input_size\n        self.list_IDs = np.arange(len(self.df.index))\n        self.indexes = np.arange(len(self.df.index))\n        self.shuffle = shuffle \n        self.n = len(self.df)\n    \n    def on_epoch_end(self):\n        if self.shuffle:\n            self.df = self.df.sample(frac=1).reset_index(drop=True)\n    \n    def __get_input(self, path, target_size):\n        # Check if test dataset: test_df\n        if (len(self.df.keys()) == len(test_df.keys())):\n            img_path = dir_csv+'test\/'+str(path)+'.jpg'\n        else:\n            print(\"Generator Image Data Generation Error\")\n            return -1\n        image = tf.keras.preprocessing.image.load_img(img_path)\n        image_arr = tf.keras.preprocessing.image.img_to_array(image)\n        image_arr = tf.image.resize(image_arr,(target_size[0], target_size[1])).numpy()\n\n        return image_arr\/255.\n    \n    def __get_data(self, batches):\n        # Generates data containing batch_size samples\n        subfocus_batch = self.df.iloc[batches, :]['Subject Focus'].values\n        eyes_batch = self.df.iloc[batches, :]['Eyes'].values\n        face_batch = self.df.iloc[batches, :]['Face'].values\n        near_batch = self.df.iloc[batches, :]['Near'].values\n        action_batch = self.df.iloc[batches, :]['Action'].values\n        acc_batch = self.df.iloc[batches, :]['Accessory'].values\n        group_batch = self.df.iloc[batches, :]['Group'].values\n        collage_batch = self.df.iloc[batches, :]['Collage'].values\n        human_batch = self.df.iloc[batches, :]['Human'].values\n        occlusion_batch = self.df.iloc[batches, :]['Occlusion'].values\n        info_batch = self.df.iloc[batches, :]['Info'].values\n        blur_batch = self.df.iloc[batches, :]['Blur'].values\n\n        # Resize to (self.batch_size, 1)\n        subfocus_batch = np.expand_dims(subfocus_batch, axis=1)\n        eyes_batch = np.expand_dims(eyes_batch, axis=1)\n        face_batch = np.expand_dims(face_batch, axis=1)\n        near_batch = np.expand_dims(near_batch, axis=1)\n        action_batch = np.expand_dims(action_batch, axis=1)\n        acc_batch = np.expand_dims(acc_batch, axis=1)\n        group_batch = np.expand_dims(group_batch, axis=1)\n        collage_batch = np.expand_dims(collage_batch, axis=1)\n        human_batch = np.expand_dims(human_batch, axis=1)\n        occlusion_batch = np.expand_dims(occlusion_batch, axis=1)\n        info_batch = np.expand_dims(info_batch, axis=1)\n        blur_batch = np.expand_dims(blur_batch, axis=1)\n        id_batch = self.df.iloc[batches, :]['Id'].values      \n        image_batch = np.asarray([self.__get_input(id, self.input_size) for id\\\n             in id_batch])\n        # Reshape to (self.batch_size, input_shape[0]*input_shape[1]*input_shape[2])\n        image_batch = np.reshape(image_batch,(self.batch_size,-1))\n\n        X_batch = np.concatenate((subfocus_batch, eyes_batch, face_batch, near_batch,\\\n            action_batch, acc_batch, group_batch, collage_batch, human_batch,\\\n               occlusion_batch, info_batch, blur_batch, image_batch),axis=1)\n        return X_batch\n    \n    def __getitem__(self, index):\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]    \n        X = self.__get_data(indexes)  \n        return X\n    \n    def __len__(self):\n        return self.n \/\/ self.batch_size","f51e0bd7":"def build_model(nb_annotations, image_shape):\n\n    # Our input features of 12 annotations and corresponding image\n    input_shape = nb_annotations + image_shape[0]*image_shape[1]*image_shape[2]\n    inputs = Input(shape=input_shape)\n\n    annotations_input = inputs[:,:nb_annotations]\n    img_input = inputs[:,nb_annotations:]\n    # Reshape flattened image to original image_shape\n    img_input = tf.reshape(img_input,(tf.shape(inputs)[0],image_shape[0],image_shape[1],image_shape[2]))\n\n    # 3 convolution layers\n    x = Conv2D(16, 3, activation='relu')(img_input)\n    x = BatchNormalization(axis=-1)(x)\n    x = MaxPooling2D(2)(x)\n\n    x = Conv2D(32, 3, activation='relu')(x)\n    x = BatchNormalization(axis=-1)(x)\n    x = MaxPooling2D(2)(x)\n\n    x = Conv2D(64, 3, activation='relu')(x)\n    x = BatchNormalization(axis=-1)(x)\n    x = MaxPooling2D(2)(x)\n\n    # Flatten feature map to a 1-dim tensor so we can add fully connected layers\n    x = Flatten()(x)\n\n    # Create a fully connected layer with ReLU activation\n    x = Dense(16, activation='relu')(x)\n    x = BatchNormalization(axis=-1)(x)\n\n    # Concatenate 12 annotation inputs and image embedding\n    x = Concatenate()([annotations_input, x])\n\n    # Simple attention layer\n    attention = Dense(32, activation='relu')(x)\n    attention = Dense(28, activation='softmax')(attention)\n    x = attention*x\n\n    # Create output layer with a single node and linear activation\n    output = Dense(1, activation='linear')(x)\n\n    # Create model\n    model = Model(inputs=inputs, outputs=output)\n    \n    # Compile model\n    model.compile(loss='mse', optimizer='adam', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n    \n    return model","2ac2fa54":"num_epochs = 100\nbatch_size = 32\ntarget_size = (250, 250, 3)\nannotations = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action',\\\n             'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info',\\\n                  'Blur']","05610527":"# IF CPU or GPU\nmodel = build_model(len(annotations), target_size)","f7d4474b":"model.summary()","3a9164a0":"# Train data\ntraingen = CustomTrainDataGen(sampled_tr_df,\n                         X_col={'Id':'Id',\n                         'Subject Focus':'Subject Focus',\n                         'Eyes':'Eyes',\n                         'Face':'Face',\n                         'Near':'Near',\n                         'Action':'Action',\n                         'Accessory':'Accessory',\n                         'Group':'Group',\n                         'Collage':'Collage',\n                         'Human':'Human',\n                         'Occlusion':'Occlusion',\n                         'Info':'Info',\n                         'Blur':'Blur'},\n                         y_col={'Pawpularity': 'Pawpularity'},\n                         batch_size=batch_size,\n                         input_size=target_size)\n# Validation data\nvalgen = CustomTrainDataGen(val_df,\n                       X_col={'Id':'Id',\n                         'Subject Focus':'Subject Focus',\n                         'Eyes':'Eyes',\n                         'Face':'Face',\n                         'Near':'Near',\n                         'Action':'Action',\n                         'Accessory':'Accessory',\n                         'Group':'Group',\n                         'Collage':'Collage',\n                         'Human':'Human',\n                         'Occlusion':'Occlusion',\n                         'Info':'Info',\n                         'Blur':'Blur'},\n                       y_col={'Pawpularity': 'Pawpularity'},\n                       batch_size=batch_size,\n                       input_size=target_size)","67cae5b0":"reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.001)\n\nearly_stop = EarlyStopping(monitor='val_loss', patience=30)\n\ndir_path_batchtr = '.\/Train_logs'\nos.makedirs(dir_path_batchtr, exist_ok=True)\n\n# Checkpoint\ndir_weight_path_batchtr = dir_path_batchtr + '\/Weights'\nos.makedirs(dir_weight_path_batchtr, exist_ok=True)\ncheckpoint_name = dir_weight_path_batchtr + '\/weights_best.hdf5'\ncheckpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True, mode='min')\n\n# Logger for history\ndir_hist_path_batchtr = dir_path_batchtr + '\/Histories'\nos.makedirs(dir_hist_path_batchtr, exist_ok=True)\nlogger_name = dir_hist_path_batchtr + '\/history_log.csv'\nlogger = CSVLogger(logger_name, append=True, separator=',')\n\n# Tensorboard log\ndir_tensorboard_log = \".\/tensorboard_logs\"\nos.makedirs(dir_tensorboard_log, exist_ok=True)\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=dir_tensorboard_log)","bca91de0":"# num_epochs = 100 - 63\n\n# checkpoint_name = '..\/input\/version2\/weights_best.hdf5'\n# model.load_weights(checkpoint_name)","ec225a43":"# # IF CPU or GPU\n# model.fit(traingen,\n#           validation_data=valgen,\n#           epochs=num_epochs,\n#           use_multiprocessing=False,\n#           callbacks=[reduce_lr,early_stop,checkpoint,logger,tensorboard_callback],\n#           verbose=2)","a80f72fa":"checkpoint_name = '..\/input\/version21\/weights_best.hdf5'\nmodel.load_weights(checkpoint_name)","6586d1e9":"testgen = CustomTestDataGen(test_df,\n                         X_col={'Id':'Id',\n                         'Subject Focus':'Subject Focus',\n                         'Eyes':'Eyes',\n                         'Face':'Face',\n                         'Near':'Near',\n                         'Action':'Action',\n                         'Accessory':'Accessory',\n                         'Group':'Group',\n                         'Collage':'Collage',\n                         'Human':'Human',\n                         'Occlusion':'Occlusion',\n                         'Info':'Info',\n                         'Blur':'Blur'},\n                         batch_size=1,\n                         input_size=target_size,\n                         shuffle=False)","d0e3c414":"predictions = model.predict(testgen)","1e3fa395":"# New dataframe for predictions with the id from test_df\npred_df = pd.DataFrame({'Id':test_df['Id']})\npred_df['Pawpularity'] = predictions\n\n# Save as a CSV file\npred_df.to_csv('.\/submission.csv', index=False)","177e3b59":"valgen_test = CustomTrainDataGen(val_df,\n                       X_col={'Id':'Id',\n                         'Subject Focus':'Subject Focus',\n                         'Eyes':'Eyes',\n                         'Face':'Face',\n                         'Near':'Near',\n                         'Action':'Action',\n                         'Accessory':'Accessory',\n                         'Group':'Group',\n                         'Collage':'Collage',\n                         'Human':'Human',\n                         'Occlusion':'Occlusion',\n                         'Info':'Info',\n                         'Blur':'Blur'},\n                       y_col={'Pawpularity': 'Pawpularity'},\n                       batch_size=1,\n                       input_size=target_size,\n                       shuffle=False)","531f8a60":"predictions = model.predict(valgen_test)\nprint(predictions[:10])\nprint(val_df.iloc[:10]['Pawpularity'])","fa3f3ccf":"# Enable GPU Use","da2b9d84":"### Training","f880208a":"### Remarks\nWe can note that the dominating classes are pawpularity=28 and pawpularity=30 with the number of occurence of 318.\nThe remaining classes will be oversampled to the same number of occurence of 318.","c99cc712":"### Pawpularity Min&Max Values","88f55ad9":"### Remarks\nNot all features are positively correlated with our output feature(i.e. pawpularity).\n\n### Solution: Attention layer\nWe will later add an attention layer to our model so that our model can learn to select interesting features and learn from them.","4d0f2b39":"### Generate data for Test dataset","7835e172":"# Import Useful Packages","62dd65ff":"## Testing Data Generator\nLikewise a data generator for the testing is needed.","3f88b6d8":"## Training Data Generator","5567651d":"### Visualize model","bdbc2056":"# Data Generation\nAs the previously loaded datasets(i.e. train and test datasets from the CSV files) do not contain the image data(i.e. only image ids), a custom data generation class could be created. In the custom data generation class, the data will be split into batches, to enable batch training, and the image data of the corresponding image id will be generated along side the other feature data.","2a04a0f3":"### Model training parameters","b5271553":"## Visualize Pawpularity(ylabel) distribution","e0e6bb7d":"## Visualize Correlation for Pawpularity ","03ff2272":"## Train Model","ec77084c":"## Visualize the Sampled Pawpularity(ylabel) distribution","03aa5112":"# Import Dataset from CSV files","6b791316":"### Recheck with validation data","878ea1ae":"## Split Train dataset into Training and Validation datasets\nBefore oversampling split the Train dataset into Training and Validation datasets for the training so the same samples are not seen in the validation dataset (for generalization)\n\nRatio of 0.9 for Train and 0.1 for Validation","67b48f7f":"### Callbacks\nCallbacks used for model training:\n- ReduceLROnPlateau: automatically reduce the learning rate during the training\n- EarlyStopping: automatically stops the training when it doesn't learn anymore\n- ModelCheckpoint: saves the weights as the model trains (here we only save the weights of the best model)\n- CSVLogger: saves the logs as a CSV file\n- Tensorboard: saves the logs for tensorboard visualization","1162a6f6":"### Predict","3688e5a2":"# Model","4bda2cba":"# Analyze Train dataset","e17ab6b9":"### Load pretrained weights","a4bec91b":"### Export prediction as a CSV file","51f102d4":"## Visualize Train dataset","f867ac5c":"## Build model\nWe will build a very simple model(i.e. CNN + DNN + Attention layer).\nThe model embeds the image data with:\n- 3 convolution layers(i.e. Conv2D => BN => MaxPool)\n- 1 dense layer\nThen the other feature data is concatenated with the image embedding.\nAn attention layer is applied and the output is created with a linear activation.","11e94b38":"### Generate data for Train and Validation datasets","f7912e73":"## Visualize Correlation between Train dataset labels","1f609ac0":"### Visualize Training dataset after data splitting","17db8c26":"## Count number of occurence for each pawpularity class","17ffd4fb":"### Remarks\nWe can see from the distribution is our data is imbalanced.\n\n### Solution: Oversampling\nTo address this problem of imbalanced data, we can resample the dataset by oversampling the minority classes.\nHere we can say that each pawpularity score(i.e. integers that ranges from 1 to 100) is an individual class. Thus, we will oversample the minority classes so that we have the same distribution.","718e18be":"### Build model"}}