{"cell_type":{"ef0bfe4e":"code","9a258263":"code","1ac0642c":"code","bab56953":"code","7e4564ca":"code","c3e7e99d":"code","4444606a":"code","37cdfc5a":"code","a79bbd71":"code","ccebbbdf":"code","988ea158":"markdown","654a708f":"markdown"},"source":{"ef0bfe4e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","9a258263":"import io\nimport bson                       # this is installed with the pymongo package\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom skimage.io import imread\n# from skimage.data import imread   # or, whatever image library you prefer\nimport multiprocessing as mp      # will come in handy due to the size of the data","1ac0642c":"# Simple data processing\n\ndata = bson.decode_file_iter(open('..\/input\/train_example.bson', 'rb'))\n\n# prod_to_category = dict()\n# prod_to_img = dict()\n\nprod_id = []\ncat_id = []\nimg_arr = []\n\nfor c, d in enumerate(data):\n    product_id = d['_id']\n    category_id = d['category_id'] # This won't be in Test data\n#     prod_to_category[product_id] = category_id\n    for e, pic in enumerate(d['imgs']):\n        picture = imread(io.BytesIO(pic['picture']))\n        \n        prod_id.append(product_id)\n        cat_id.append(category_id)\n        img_arr.append(picture)\n        \ndf = pd.DataFrame(list(zip(img_arr, prod_id, cat_id)), columns=['img_arr', 'prod_id', 'cat_id'])\n\n# prod_to_category = pd.DataFrame.from_dict(prod_to_category, orient='index')\n# prod_to_category.index.name = '_id'\n# prod_to_category.rename(columns={0: 'category_id'}, inplace=True)\n\n# prod_to_img = pd.DataFrame.from_dict(prod_to_img, orient='index')\n# prod_to_img.index.name = '_id'\n# prod_to_img.rename(columns={0: 'img'}, inplace=True)","bab56953":"df.head()","7e4564ca":"df[df['prod_id'] == 13]","c3e7e99d":"plt.imshow(df['img_arr'][0]);","4444606a":"NCORE =  8\n\nprod_id = mp.Manager().list()\ncat_id = mp.Manager().list()\nimg_arr = mp.Manager().list()\n\ndef process(q, iolock):\n    while True:\n        d = q.get()\n        if d is None:\n            break\n        product_id = d['_id']\n        category_id = d['category_id']\n        for e, pic in enumerate(d['imgs']):\n            picture = imread(io.BytesIO(pic['picture']))\n            # do something with the picture, etc\n            prod_id.append(product_id)\n            cat_id.append(category_id)\n            img_arr.append(picture)\n        \n    \nq = mp.Queue(maxsize=NCORE)\niolock = mp.Lock()\npool = mp.Pool(NCORE, initializer=process, initargs=(q, iolock))\n\n# process the file\n\ndata = bson.decode_file_iter(open('..\/input\/train_example.bson', 'rb'))\nfor c, d in enumerate(data):\n    q.put(d)  # blocks until q below its max size\n\n# tell workers we're done\n\nfor _ in range(NCORE):  \n    q.put(None)\npool.close()\npool.join()\n\nprod_id = list(prod_id)\ncat_id = list(cat_id)\nimg_arr = list(img_arr)\n\ndf = pd.DataFrame(list(zip(img_arr, prod_id, cat_id)), columns=['img_arr', 'prod_id', 'cat_id'])","37cdfc5a":"df.head()","a79bbd71":"df.shape","ccebbbdf":"df['cat_id'].value_counts()","988ea158":"The bson files for this competition contain a list of dictionaries, one dictionary per product. Each dictionary contains a product id (key: _id), the category id of the product (key: category_id), and between 1-4 images, stored in a list (key: imgs). Each image list contains a single dictionary per image, which uses the format: {'picture': b'...binary string...'}. \n\nThe bson file can be read and processed iteratively. The following code shows how to read the data from the `train_example.bson` file.","654a708f":"For more efficient use of your resources, you can use the `multiprocessing` module to read and process the bson file.\n\nInspiration for this code is from:  https:\/\/stackoverflow.com\/questions\/43078980\/python-multiprocessing-with-generator Note this may be slower on a small file, due to the overhead setting up the workers, but will be significantly faster for the large files."}}