{"cell_type":{"4bbf476b":"code","644bcd5c":"code","12b25919":"code","139673fa":"code","c16ca5af":"code","cb196fda":"code","48bcc0b6":"code","8a980d62":"code","298ab294":"code","ef5bbb81":"code","e11dd0f2":"code","14d330e6":"code","9fe30976":"code","d14041ed":"code","d12732d5":"code","f6209834":"code","90797280":"code","8e2b12b8":"code","e67c120f":"code","39e4df54":"code","eb1d2505":"code","cc6ec131":"code","7ae5241c":"code","d81479f5":"code","f2138870":"code","ed5f6e52":"code","3b62ec7f":"code","b485c2e1":"code","bb442fcb":"code","19ff6bb0":"code","00c17f6f":"code","7fb30223":"code","3db61e48":"code","b2c79c6c":"code","9210e27f":"code","ec86666a":"code","3916bdc7":"code","21cca1c0":"code","b1938e17":"markdown","a9091f95":"markdown","033b140a":"markdown","bf923d1a":"markdown","3b7f99ed":"markdown","681550d0":"markdown","d053a188":"markdown","ababd797":"markdown","d467727c":"markdown","c6df1afd":"markdown","1a4d09f3":"markdown","030a5701":"markdown","5cb62ea8":"markdown","378ec98d":"markdown","29301440":"markdown","629f35ae":"markdown","c7b949a2":"markdown","6b356e93":"markdown","6ea9e757":"markdown","11c04a0f":"markdown","2045f1de":"markdown","f980b31c":"markdown","ff82afa8":"markdown","4ad00a26":"markdown","9997a09e":"markdown","203810cb":"markdown","bef43146":"markdown","fe2a7de8":"markdown","11ba1985":"markdown","35908586":"markdown","a811aad1":"markdown","e8850892":"markdown","f91d526f":"markdown","6d110652":"markdown"},"source":{"4bbf476b":"x = 2\ny = 3.0\numa_string = \"aspas simples ou duplas marcam strings\"\nprint(\"x vale:\", x)\nprint(\"x \u00e9 um\", type(x))\nprint(\"y vale:\", y)\nprint(\"y \u00e9 um\", type(y))\nprint(\"uma_string vale:\", uma_string)\nprint(\"uma_string \u00e9 uma\", type(uma_string))","644bcd5c":"x = y\/x # x agora y divido por ele mesmo\n# dividir um inteiro por float resulta em um inteiro\nprint(\"O novo valor de x \u00e9:\", x, \". Seu tipo agora \u00e9\", type(x))\n# somar duas strings concatena ambas\nnova_string = \"+ concatena \" + \"strings\"\nprint(nova_string)","12b25919":"\"R\" > \"Python\"","139673fa":"uma_lista = [1, 2, 3, 4, 5]\nprint(\"Os elementos da lista s\u00e3o:\", uma_lista)","c16ca5af":"print(\"O primeiro elemento \u00e9 o:\", uma_lista[0])\nprint(\"Os elementos de \u00edndice 1 at\u00e9 3 s\u00e3o:\", uma_lista[1:4])","cb196fda":"# trocando o primeiro elemento da lista\numa_lista[0] = \"Zero\"\n# uma lista pode servir como iterador\ncontador = 0                     # iniciando um contador\nfor elemento in uma_lista:       # para cada elemento da lista\n    print(contador, elemento)    # imprime o contado e o valor do elemento\n    contador += 1                # adiciona mais 1 ao contador \n                                 #(<var>+=<valor> \u00e9 o mesmo <var> = <var> + <valor>)","48bcc0b6":"contador = 0            # Iniciamos o contador em zero\nwhile contador < 15:    # enquanto o contador for menor do que 15, repete o loop\n    print(contador)     # imprime o valor do contador\n    if 5%2 == 0:        # o operador % retorna a sobra de uma divisao, entao com <numero>%2 == 0 queremos saber se \u00e9 \n        contador += 1   # se par, soma um\n    else:               # se impar\n        contador += 3   # soma 3\n# o ultimo valor do contador foi:\nprint(\"Contador final:\", contador)","8a980d62":"def soma(a, b):\n    return a + b\nsoma(1,2)","298ab294":"import os           # opera\u00e7\u00f5es do sistema operacional\nimport pandas as pd # leitura e manipulacao de dados\nfrom sklearn.ensemble import RandomForestRegressor # modelos de ML\nimport random       # processos pseudo-aleatorios\nimport numpy as np  # algebra linear","ef5bbb81":"os.getcwd()","e11dd0f2":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","14d330e6":"df_train = pd.read_csv(filepath_or_buffer=\"\/kaggle\/input\/ashrae-energy-prediction\/train.csv\", \n                       sep=\",\", \n                       encoding=\"utf-8\")\n\ndf_train.head()","9fe30976":"df_train.tail()","d14041ed":"(df_train[\"meter_reading\"] == 0).mean()","d12732d5":"df_train.describe()","f6209834":"df_train.shape","90797280":"df_test = pd.read_csv(filepath_or_buffer=\"\/kaggle\/input\/ashrae-energy-prediction\/test.csv\", \n                      sep=\",\", \n                      encoding=\"utf-8\")\ndf_test.head()","8e2b12b8":"df_building = pd.read_csv(filepath_or_buffer=\"\/kaggle\/input\/ashrae-energy-prediction\/building_metadata.csv\", \n                       sep=\",\", \n                       encoding=\"utf-8\")\ndf_building.head()","e67c120f":"print(\"N\u00famero de linhas:\", df_building.shape[0])\nprint(\"N\u00famero de colunas:\", df_building.shape[1])","39e4df54":"print(\"Numero de IDs \u00fanicos de pr\u00e9dio no dataset de treino:\",df_train[\"building_id\"].nunique())","eb1d2505":"print(\"Numero de IDs \u00fanicos de pr\u00e9dio no dataset de teste:\",df_test[\"building_id\"].nunique())","cc6ec131":"porcentagem_do_treino = df_train[\"building_id\"].isin(df_building[\"building_id\"]).mean() * 100\nporcentagem_do_teste = df_test[\"building_id\"].isin(df_building[\"building_id\"]).mean() * 100\n\nprint(\"Treino:\", porcentagem_do_treino, \"%\")\nprint(\"Teste:\", porcentagem_do_teste, \"%\")","7ae5241c":"df_building.isnull().sum()","d81479f5":"print(\"Tipo em df_building:\", df_building[\"building_id\"].dtype)\nprint(\"Tipo em df_train:\", df_train[\"building_id\"].dtype)\nprint(\"Tipo em df_test:\", df_test[\"building_id\"].dtype)","f2138870":"df_train_new = df_train.merge(df_building,            # poderia usar on_left on_right\n                              on=[\"building_id\"],     # coluna chave, tambem pode ser uma lista com mais de uma coluna \n                              how=\"left\",             # left, right, outer, inner\n                              validate=\"many_to_one\") # opicional <many ou one>_to_<many ou one>\ndf_train_new.head()","ed5f6e52":"df_test_new = df_test.merge(df_building, on=\"building_id\", how=\"left\", validate=\"many_to_one\")\ndf_test_new.head()","3b62ec7f":"del df_test, df_train, df_building","b485c2e1":"df_train_new[\"timestamp\"] = pd.to_datetime(df_train_new[\"timestamp\"])\ndf_test_new[\"timestamp\"] = pd.to_datetime(df_test_new[\"timestamp\"])\n\nprint(\"df_train_new come\u00e7a em\", df_train_new[\"timestamp\"].min(), \"e termina em\", df_train_new[\"timestamp\"].max())","bb442fcb":"todos_indices = df_train_new.index.tolist()\nprint(\"15% das obs. de df_train_new s\u00e3o cerca de\",len(todos_indices)*.15)","19ff6bb0":"random.seed(2020)\n# selecionando os indices de b\nindices_b = random.choices(todos_indices, k = 3032415)\n# separando os indices disponiveis\nindices_disponiveis = list( set(todos_indices) - set(indices_b))\n# sorteando os indices de c\nindices_c = random.choices(indices_disponiveis, k = 3032415)\n# separando os indices de a\nindices_a = list( set(indices_disponiveis) - set(indices_c))","00c17f6f":"colunas_categoricas = [\"building_id\", \"site_id\", \"primary_use\"]\n\nfor coluna_categorica in colunas_categoricas:\n    # separando os valores para o encoder\n    # para criar o enconder vamos restringir as dados\n    # da amostra a usando \"df_train_new.loc[indices_a]\"\n    mean_encoder = df_train_new.loc[indices_a].groupby(coluna_categorica)[\"meter_reading\"].mean()\n    # mapeando para os valores da coluna categorica\n    df_train_new[coluna_categorica] = df_train_new[coluna_categorica].map(mean_encoder)\n    # repetimos o mesmo processo para df_test_new\n    df_test_new[coluna_categorica] = df_test_new[coluna_categorica].map(mean_encoder)    ","7fb30223":"df_train_new.min()","3db61e48":"df_test_new.min()","b2c79c6c":"# Pequeno truque para reduzir a memoria\ndf_train_new[\"year_built\"] = df_train_new[\"year_built\"] - 1900\ndf_test_new[\"year_built\"] = df_test_new[\"year_built\"] - 1900\n# Prencheendo vazios\ndf_train_new = df_train_new.fillna(-10)\ndf_test_new = df_test_new.fillna(-10)","9210e27f":"## Function to reduce the DF size\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df\n\ndf_train_new = reduce_mem_usage(df_train_new)\ndf_test_new = reduce_mem_usage(df_test_new)","ec86666a":"df_train_new[\"month\"] = df_train_new[\"timestamp\"].dt.month.astype(\"uint8\")\ndf_train_new = df_train_new.drop(\"timestamp\", 1)\ndf_test_new[\"month\"] = df_test_new[\"timestamp\"].dt.month.astype(\"uint8\")\ndf_test_new = df_test_new.drop(\"timestamp\", 1)","3916bdc7":"features = [\n    \"building_id\",\n    \"meter\",\n    \"site_id\",\n    \"primary_use\",\n    \"square_feet\",\n    \"year_built\",\n    \"floor_count\",\n]\n\ntarget = \"meter_reading\"\n\nmodelo = RandomForestRegressor(n_estimators=10, max_depth=10, random_state=2020)\nmodelo.fit(df_train_new.loc[indices_a, features], df_train_new.loc[indices_a, target])\nforecast = modelo.predict(df_train_new.loc[indices_b, features])","21cca1c0":"modelo = RandomForestRegressor(n_estimators=15, max_depth=10, random_state=2020)\nmodelo.fit(df_train_new.loc[indices_a, features], df_train_new.loc[indices_a, target])\nforecast = modelo.predict(df_train_new.loc[indices_b, features])","b1938e17":"Nenhum n\u00famero negativo. Vou preencher os vazios com -10.","a9091f95":"Tudo certo! Podemos seguir em frente.","033b140a":"Uma pergunta muito importante \u00e9 \"temos dados suficientes?\". Para responder essa pergunta usamos o m\u00e9todo `shape` que devolve uma lista em que o primeiro elemento \u00e9 o n\u00famero de linhas e o segundo \u00e9 o n\u00famero de colunas.","bf923d1a":"Um loop usando while...","3b7f99ed":"Quais s\u00e3o os arquivos dispon\u00edveis?","681550d0":"A fun\u00e7\u00e3o read_csv do pandas permite a leitura de CSVs. Os argumentos que ela recebe s\u00e3o:\n\n* filepath_or_buffer = caminho ate o arquivo (obrigat\u00f3rio) str\n* sep = separador de colunas (opcional, padr\u00e3o \",\") str\n* encoding = encoding do arquivo (opcional, padr\u00e3o \"utf-8\") str - se der errado tente latin1 ou latin3 (mais comuns no BR)\n* outros argumentos https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.read_csv.html\n\nA fun\u00e7\u00e3o `pandas.read_csv()` retorna uma vari\u00e1vel do tipo DataFrame, com seus pr\u00f3prios m\u00e9todos. \u00c9 muito comum depois de ler um CSV, chamar por `.head()` e `.tail()` para ler as primeiras e ultimas linhas respectivamente.","d053a188":"N\u00e3o temos mais de um ano de dados, essa \u00e9 uma not\u00edcia ruim. Idealmente teriamos mais de um ano para A e pelo menos um ano para B e C, assim controlariamos o fator sazonalidade. Dadas as circunst\u00e2ncias optei por n\u00e3o preservar a ordem cronol\u00f3gicae sortear aleatoriamente as observa\u00e7\u00f5es utilizadas. Vamos usar cerca de 70% das observa\u00e7\u00f5es para A, 15% para B e outros 15% para C.","ababd797":"Tudo pronto para o treino e avalia\u00e7\u00e3o!\n\n## <a id=\"train\" href=\"#sumario\">6. Treino e avalia\u00e7\u00e3o<\/a>\n\n","d467727c":"Vamos dar uma olhada no dataset de testes:","c6df1afd":"Para selecionar um elemento da sua lista use a sintaxe `<lista>[indice do elemento]`. Os ind\u00edces come\u00e7am em zero. Voc\u00ea pode fatiar uma lista com a sintaxe `<lista>[indice_inicial : indice_final (nao incluso)]`. Se emitir o indice inicial ele come\u00e7a do primeiro e omitindo o ind\u00edce final ele vai at\u00e9 o \u00faltimo.","1a4d09f3":"Pra salvar mais mem\u00f3ria vou remover os timestamp e deixar s\u00f3 uma vari\u00e1vel que denota m\u00eas como inteiro:","030a5701":"Interessante! Tanto o ano de constru\u00e7\u00e3o do pr\u00e9dio (`year_built`) quanto o n\u00famero de andares (`floor_count`) tem uma grande quantidade de n\u00e3o preenchidos (informa\u00e7\u00f5es faltando). Vamos tentar usar isso ao nosso favor. Agora vamos adicionar essas informa\u00e7\u00f5es ao dataset de treino usando a chave `building_id`.\n\nAntes de fazer essa uni\u00e3o, precisamos garantir que essa coluna est\u00e1 preenchida com o mesmo tipo de vari\u00e1vel nos diferentes datasets:","5cb62ea8":"Vamos separar os \u00edndices de A, B e C.","378ec98d":"Em `df_train[\"meter_reading\"] == 0` estamos criando uma esp\u00e9cie de lista (pandas Series para ser mais exato) e para cada valor da lista retornamos um booleano com True se o target for igual a 0 ou False caso contr\u00e1rio. Em seguida chamamos o m\u00e9todo `mean()` para toda essa s\u00e9rie. Ele vai retornar a m\u00e9dia para tal, interpretando True como 1 e False como 0, logo, o resultado \u00e9 a porcentagem de valores iguais a zero, que foi cerca de 9,27%.\n\nRepare que para selecionar apenas uma coluna do nosso dataset chamamos ele mesmo e em seguida o nome da coluna entre colchetes. Os dois principais m\u00e9todos para \"fatiar\" datasets s\u00e3o `.loc[]` e `.iloc[]`.\n\nAl\u00e9m do `head()` e `tail()`, outro m\u00e9todo muito \u00fatil \u00e9 o `describe()`, que traz algumas estat\u00edsticas descritivas sobre o dataset.","29301440":"# 4\u00ba Simp\u00f3sio de Tecnologias Aplicadas - UNISO\n\n<h2>\n<a id=\"sumario\">Sum\u00e1rio<\/a><br>\n<a href=\"#jupyter\">1. Jupyter Notebook<\/a><br>\n<a href=\"#python\">2. Python - sintaxe b\u00e1sica<\/a><br>\n<a href=\"#dados\">3. Lendo os dados<\/a><br>\n<a href=\"#wrag\">4. Manipulando os dados<\/a><br>\n<a href=\"#prep\">5. Preparando os dados<\/a><br>\n<a href=\"#train\">6. Treino e avalia\u00e7\u00e3o<\/a><\/h2><br>\n\n## <a id=\"jupyter\" href=\"#sumario\">1. Jupyter Notebook<\/a>\n\nUma das ferramentas mais populares do Python \u00e9 o Jupyter Notebook, nele voc\u00ea pode misturar textos (Markdwon) e c\u00f3digo.\nMuito \u00fatil para escrever relat\u00f3rios que incluem sa\u00eddas de c\u00f3digos, gr\u00e1ficos, equa\u00e7\u00f5es.\nPara instanciar um Notebook localmente, siga os seguintes passos:\n\n1. Garanta que o Python instalado (sugiro 3.6+):\n    * https:\/\/www.python.org\/downloads\/\n2. (Opcional) se tiver o Anaconda instalado voc\u00ea pode criar um ambiente virtual para evitar poss\u00edveis conflitos de pacotes. Em seu terminal digite:\n```\nconda create -n iv_simposio\nconda activate iv_simposio\n```\nps: no Linux talvez voc\u00ea tenha que adicionar conda ao .bash. No Windows \u00e9 melhor usar o prompt do Anaconda.\n3. Garanta que o jupyter esta instalado (terminal):\n```\npip install jupyter\n```\n4. Instancie um servidor local jupyter:\n```\njupyter notebook\n```\n\n### Dica Jupyter\n\nNos blocos de codigo, voc\u00ea pode rodar comandos no terminal come\u00e7ando suas linhas com `!`. E.g., `!pip install pandas` instala a biblioteca pandas.\n\n## <a id=\"python\" href=\"#sumario\">2. Python - sintaxe b\u00e1sica<\/a>\n\nN\u00e3o \u00e9 preciso declarar o tipo da vari\u00e1vel. Basta entrar com `<nome_da_variavel> = <valor_da_variavel>` para criar uma nova vari\u00e1vel ou modificar uma existente. ","629f35ae":"Os s\u00edmbolos de soma (+), subtra\u00e7\u00e3o (-), multiplica\u00e7\u00e3o (\\*) e divis\u00e3o (\/) fazem o que voc\u00ea espera que eles fa\u00e7am. Hashtags (\\#) marcam coment\u00e1rios nos c\u00f3digos e n\u00e3o ser\u00e3o executados.","c7b949a2":"Parece tudo certo, mas o seguro morreu de velho. Vamos conferir se tudo que est\u00e1 nos treino\/teste est\u00e1 inclu\u00eddo neste dataset.","6b356e93":"Pronto, agora que mapeamos as categoricas cardinais em categoricas ordinais (isso \u00e9 importante para as florestas aleat\u00f3rias), podemos prosseguir. Vamos escolher um valor arbitr\u00e1rio para os n\u00e3o preenchidos, mas pra isso vamos ver quais s\u00e3o os valores m\u00ednimos observados em cada coluna de ambos datasets.","6ea9e757":"Em que pasta nos estamos?","11c04a0f":"Agora vamos montar um encoder! Para o modelo que vou usar de baseline (Florestas Aleat\u00f3rias), o chamado mean encoder \u00e9 bastante indicado. Para mais sobre mean encoder consulte:\nhttps:\/\/towardsdatascience.com\/why-you-should-try-mean-encoding-17057262cd0\n\nPara quais vari\u00e1veis vamos utilizar o mean encoder?\n\nR: Categoricas (building_id, site_id, primary_use)","2045f1de":"## <a id=\"wrang\" href=\"#sumario\">4. Manipulando os dados<\/a>\n\nMas vamos prever o consumo sem melhorias s\u00f3 com o ID do pr\u00e9dio, tipo de medidor? N\u00e3o! A competi\u00e7\u00e3o tamb\u00e9m disponibilizou dados de clima e informa\u00e7\u00f5es do pr\u00e9dio. Para simplificar vamos ficar s\u00f3 com as informa\u00e7\u00f5es do pr\u00e9dio.","f980b31c":"Vou liberar mem\u00f3ria deletando os antigos dataframes que n\u00e3o ser\u00e3o mais utilizados.","ff82afa8":"O argumento `validate` \u00e9 muito \u00fatil para garantir que linhas adicionais n\u00e3o ser\u00e3o criadas. Devemos adicionar as mesmas linhas ao dataset de teste.","4ad00a26":"Lendo os documentos disponibilizados eu sei que:\n* `building_id` corresponde a um ID \u00fanico do edif\u00edcio;\n* `meter` \u00e9 o tipo de medidor (0 para eletricidade, 1 para \u00e1gua fria, 2 para vapor e 3 para \u00e1gua quente);\n* `timestamp` data de quando a medida foi tirada;\n* `meter_reading` \u00e9 o TARGET, o gasto de energia que queremos prever.","9997a09e":"Me chamou a aten\u00e7\u00e3o a quantidade de zeros que encontramos neste exame r\u00e1pido. Qual a porcentagem de zeros no target do dataset de treino?","203810cb":"## <a id=\"dados\" href=\"#sumario\">3. Lendo os dados<\/a>\n\nUma biblioteca ou m\u00f3dulo \u00e9 um conjunto de fun\u00e7\u00f5es prontas para serem usadas - n\u00e3o \u00e9 preciso reinventar a roda. Para instalar um novo pacote (se dispon\u00edvel no reposit\u00f3rio oficial), basta digitar `pip install <nome_do_modulo>` no terminal. Pacotes devem ser importados no seu programa: `import <nome_do_modulo>`. Voc\u00ea pode dar um apelido para o pacote em seu programa usando `import <nome_do_modulo> as <apelido>`.\n\nOs pacotes que vamos usar s\u00e3o:\n* os - de Operational System, vamos ver quais os arquivos dispon\u00edveis;\n* pandas - um dos mais populares, usado para leitura e manipula\u00e7ao de dados;\n* sklearn - Scikit Learn e um dos frameworks mais populares para treinar modelos.\n\nUsu\u00e1rios de Python costumam carregar todas as bibliotecas necess\u00e1rias no topo do c\u00f3digo.","bef43146":"No mundo real isso serviria como entrada para os nossos modelos depois de treinamos. \u00c9 o que gostariamos de prever! Note que a coluna `meter_reading` n\u00e3o est\u00e1 dispon\u00edvel.","fe2a7de8":"Para definir novas funoes basta seguir a sintaxe:\n\n```\ndef <nome_da_funcao>(argumentos):\n    \\\\ operacoes da funcao\n    return <valor_a_ser_retornado>\n```\n\nPor exemplo:","11ba1985":"Duas coisas chamaram minha aten\u00e7\u00e3o nos metadados dos edif\u00edcios: duas colunas que podem ser utilizadas como vari\u00e1veis categ\u00f3ricas (`primary_use` e `site_id`) e varios NaNs (Not a Number), que correspondem valores vazios no nosso dataset.","35908586":"Para reduzir a memoria ...\n\nKibado de https:\/\/www.kaggle.com\/caesarlupum\/ashrae-start-here-a-gentle-introduction#5.-Reducing-Memory-Size","a811aad1":"## <a id=\"prep\" href=\"#sumario\">5. Preparando os Dados<\/a>\n\nNesta etapa n\u00f3s vamos dividir o dataset de treinamento em tr\u00eas partes:\n* A) Ajustar o modelo\n* B) Encontrar os melhores hiperpar\u00e2metros\n* C) Estimar o desempenho dos modelos (para os mesmos edif\u00edcios)\n\nComo temos dispon\u00edvel uma coluna de tempo, vou fazer o split cronol\u00f3gico, pra isso \u00e9 \u00fatil converter a coluna de tempo no formato datetime. ","e8850892":"Listam ainda podem misturar elementos de diversos tipos. Loops b\u00e1sicos seguem o formato:\n```\nfor <i> in <iterador>:\n    \\\\ operacoes\n```","f91d526f":"Listas s\u00e3o declaradas usando \\[ \\].","6d110652":"Comparar valores com < (menor), <= (menor igual), >= (maior igual) ou > (maior) resulta em vari\u00e1veis boolenas (True ou False)."}}