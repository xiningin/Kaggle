{"cell_type":{"1a3b36c5":"code","54df431c":"code","d8c3a64c":"code","07942754":"code","4f25ca52":"code","ad3bdc82":"code","e4f51513":"code","e52f411a":"code","3a73a855":"code","3615e945":"code","282a3457":"code","99fc32eb":"code","dedb3429":"code","510e4162":"code","d1103740":"code","635b8b5e":"code","d6091812":"code","9b53522e":"code","b92458c2":"code","d7cadb81":"code","152ffb51":"code","d9225b55":"code","80e2637a":"code","09090439":"code","ce5b6a0d":"code","a7495bc3":"markdown","3100ce0f":"markdown","6381aee5":"markdown","57e578f0":"markdown","704e0ea7":"markdown","9a7ebc62":"markdown","5b2402d2":"markdown","f8d27cd3":"markdown","2534f987":"markdown","bbb5acf3":"markdown","f1eafb44":"markdown","e2c711d5":"markdown","109c1826":"markdown","b27f1b6b":"markdown","12d8593f":"markdown","89541d13":"markdown","e6ee6b00":"markdown","882b416e":"markdown","17db2996":"markdown","04b11f75":"markdown","23757a53":"markdown","e1b5c5aa":"markdown","ea66dd70":"markdown"},"source":{"1a3b36c5":"import os \nimport sys\nimport random\nimport math\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport json\nimport pydicom\nfrom imgaug import augmenters as iaa\nfrom tqdm import tqdm\nimport pandas as pd \nimport glob \nimport skimage.draw","54df431c":"!git clone https:\/\/www.github.com\/matterport\/Mask_RCNN.git\n","d8c3a64c":"os.chdir('Mask_RCNN')","07942754":"ROOT_DIR = '\/kaggle\/project'","4f25ca52":"sys.path.append(os.path.join(ROOT_DIR, 'Mask_RCNN'))\nfrom mrcnn.config import Config\nfrom mrcnn import utils\nimport mrcnn.model as modellib\nfrom mrcnn import visualize\nfrom mrcnn.model import log","ad3bdc82":"# Parameter berikut telah dipilih untuk mengurangi runtime untuk tujuan demonstrasi\n# Ini tidak optimal\n\nclass DetectorConfig(Config):\n    \"\"\"Configuration for training pneumonia detection on the RSNA pneumonia dataset.\n    Overrides values in the base Config class.\n    \"\"\"\n    \n    NAME = 'fruits'\n    \n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 8\n    \n    BACKBONE = 'resnet50'\n    \n    NUM_CLASSES = 4  # background + 3 kelas buah\n    \n    IMAGE_MIN_DIM = 256\n    IMAGE_MAX_DIM = 256\n    RPN_ANCHOR_SCALES = (16, 32, 64, 128, 256)\n    TRAIN_ROIS_PER_IMAGE = 32\n\n    STEPS_PER_EPOCH = 25\n    \nconfig = DetectorConfig()\nconfig.display()","e4f51513":"class DetectorDataset(utils.Dataset):\n    \"\"\"Dataset class for training pneumonia detection on the RSNA pneumonia dataset.\n    \"\"\"\n    \n    def load_labels(self, labels_list):\n        for i, label in enumerate(labels_list):\n            self.add_class('fruits', i + 1, label)\n            \n    def load_dataset(self, images_obj):\n        for image_obj in images_obj:\n            image_id = image_obj['image_id']\n            image_path = image_obj['image_path']\n            num_ids = image_obj['num_ids']\n            polygons = image_obj['polygons']\n            width = image_obj['width']\n            height = image_obj['height']\n            self.add_image(\"fruits\", image_id=image_id, path=image_path,\n                           width=width, height=height, polygons=polygons,num_ids=num_ids)\n            \n    def image_reference(self, image_id):\n        info = self.image_info[image_id]\n        return info['path']\n\n    def draw_shape(self, image, shape, dims, color):\n        \"\"\"Draws a shape from the given specs.\"\"\"\n        # Get the center x, y and the size s\n        x, y, s = dims\n        if shape == 'square':\n            cv2.rectangle(image, (x-s, y-s), (x+s, y+s), color, -1)\n        elif shape == \"circle\":\n            cv2.circle(image, (x, y), s, color, -1)\n        elif shape == \"triangle\":\n            points = np.array([[(x, y-s),\n                                (x-s\/math.sin(math.radians(60)), y+s),\n                                (x+s\/math.sin(math.radians(60)), y+s),\n                                ]], dtype=np.int32)\n            cv2.fillPoly(image, points, color)\n        return image\n\n    def load_mask(self, image_id):\n        \"\"\"Generate instance masks for an image.\n       Returns:\n        masks: A bool array of shape [height, width, instance count] with\n            one mask per instance.\n        class_ids: a 1D array of class IDs of the instance masks.\n        \"\"\"\n        info = self.image_info[image_id]\n        num_ids = info['num_ids']\n        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n                        dtype=np.uint8)\n\n        for i, p in enumerate(info[\"polygons\"]):\n            # Get indexes of pixels inside the polygon and set them to 1\n            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n            mask[rr, cc, i] = 1\n\n        num_ids = np.array(num_ids, dtype=np.int32)\n        return mask, num_ids","e52f411a":"train_image_path = os.path.join('..\/..\/input', 'train_zip')\ntest_image_path = os.path.join('..\/..\/input', 'test_zip')","3a73a855":"!pip install xmltodict","3615e945":"labels = [\"apple\", \"banana\", \"orange\"]","282a3457":"def parse_single_annotation(label_obj):\n    #print(label_obj)\n    name = label_obj['name']\n    # Get label\n    num_id = labels.index(name) + 1\n    bb_box = label_obj['bndbox']\n    # Extract the xmin xmax ymin and ymax of bounding box\n    xmin = int(bb_box['xmin'])\n    xmax = int(bb_box['xmax'])\n    ymin = int(bb_box['ymin'])\n    ymax = int(bb_box['ymax'])\n    # Convert it into polygon format. So we need 5 points for both x and y\n    all_points_x = [xmin, xmax, xmax, xmin, xmin]\n    all_points_y = [ymin, ymin, ymax, ymax, ymin]\n    return all_points_x, all_points_y, num_id\n    ","99fc32eb":"import xmltodict\nimport json\ntrain_images = []\ndef transform_annotations(image_path):\n    # Start the index from 100\n    curr_idx = 100\n    images_list = []\n    # List the files in the training or test path\n    for i in os.listdir(os.path.join(image_path)):\n        # Get the image path\n        img_path = os.path.join(image_path, i)\n        split_img_path = i.split('.')\n        # check if the file is a .jpg ext. We ignore .xml file as they will be parsed based on .jpg file name\n        if split_img_path[1] == 'jpg':\n            # Define dict key value pair required in coco dataset\n            polygons = []\n            num_ids = []\n            # Read the image file \n            file_data = cv2.imread(img_path)\n            # Get the heigh and width. OpenCV shape is in the format h, w, depth\n            height, width, _ = file_data.shape\n            # Open the xml file which has the same name of the image we have opened for this iteration\n            with open(os.path.join(image_path, split_img_path[0] + '.xml')) as fd:\n                # Load the xml -> convert xml to dict -> convert to json\n                bb_file = json.loads(json.dumps(xmltodict.parse(fd.read())))\n                # There are two case - bb_file['annotation']['object'] can exist as a single dict or as a list of dict.\n                # Thus, we need to do a check to see whether it is a list or not.\n                # If the value is a data type of list:\n                if isinstance(bb_file['annotation']['object'], list):\n                    # Loop through each dict in the list\n                    for obj in bb_file['annotation']['object']:\n                        # Parse each annotation individually\n                        all_points_x, all_points_y, num_id = parse_single_annotation(obj)\n                        # Append the points into polygon list\n                        polygons.append({\n                            'all_points_x': all_points_x,\n                            'all_points_y': all_points_y\n                        })\n                        # Append the id into the num_ids list\n                        num_ids.append(num_id)\n                # If the ['object'] key only contains a dict value\n                else:\n                    # We just need to parse a single annotation\n                    all_points_x, all_points_y, num_id = parse_single_annotation(bb_file['annotation']['object'])\n                    # Append it into polygon and num_ids list\n                    polygons.append({\n                        'all_points_x': all_points_x,\n                        'all_points_y': all_points_y\n                    })\n                    num_ids.append(num_id)\n            # For this image, we need to create a dict to represent it and all the corresponding annotations represented by polygons and num_ids key list\n            image_label = {\n                'image_path': img_path,\n                'image_id': curr_idx,\n                'polygons': polygons,\n                'num_ids': num_ids,\n                'height': height,\n                'width': width\n            }\n            curr_idx = curr_idx + 1\n            # Append it into the images_list\n            images_list.append(image_label)\n    return images_list\n\n","dedb3429":"train_images = transform_annotations(os.path.join(train_image_path, 'train'))\nprint(train_images[0:5])\ndataset_train = DetectorDataset()\ndataset_train.load_labels(labels)\ndataset_train.load_dataset(train_images)\ndataset_train.prepare()","510e4162":"test_images = transform_annotations(os.path.join(test_image_path, 'test'))\ndataset_val = DetectorDataset()\ndataset_val.load_labels(labels)\ndataset_val.load_dataset(test_images)\ndataset_val.prepare()","d1103740":"from mrcnn import visualize\nfor i in range(5):\n    image_id = train_images[i]['image_id']\n    mask, num_id = dataset_train.load_mask(i)\n    img_data = cv2.imread(train_images[i]['image_path'])\n    num_id = [x - 1 for x in num_id]\n    visualize.display_top_masks(img_data, mask, num_id, labels)","635b8b5e":"!cd \/kaggle && mkdir project\nsys.path.append(ROOT_DIR)\nMODEL_DIR = os.path.join(ROOT_DIR, 'logs')\n# Local path to trained weights file\nCOCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n# Download COCO trained weights from Releases if needed\nif not os.path.exists(COCO_MODEL_PATH):\n    utils.download_trained_weights(COCO_MODEL_PATH)\n\n","d6091812":"# Buat model di training mode\nmodel = modellib.MaskRCNN(mode=\"training\", config=config,\n                          model_dir=MODEL_DIR)","9b53522e":"# Which weights to start with?\ninit_with = \"coco\"  # imagenet, coco, or last\n\nif init_with == \"imagenet\":\n    model.load_weights(model.get_imagenet_weights(), by_name=True)\nelif init_with == \"coco\":\n    # Load weights trained on MS COCO, but skip layers that\n    # are different due to the different number of classes\n    # See README for instructions to download the COCO weights\n    model.load_weights(COCO_MODEL_PATH, by_name=True,\n                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n                                \"mrcnn_bbox\", \"mrcnn_mask\"])\nelif init_with == \"last\":\n    # Load the last model you trained and continue training\n    model.load_weights(model.find_last(), by_name=True)","b92458c2":"# Train the head branches\n# Passing layers=\"heads\" freezes all layers except the head\n# layers. You can also pass a regular expression to select\n# which layers to train by name pattern.\nmodel.train(dataset_train, dataset_val, \n            learning_rate=config.LEARNING_RATE, \n            epochs=30, \n            layers='heads')","d7cadb81":"os.listdir(MODEL_DIR)","152ffb51":"dir_names = os.listdir(MODEL_DIR)\ndir_names = sorted(dir_names)\n\nfps = []\n# Pick last directory\nfor d in dir_names: \n    dir_name = os.path.join(MODEL_DIR, d)\n    # Find the last checkpoint\n    checkpoints = next(os.walk(dir_name))[2]\n    checkpoints = filter(lambda f: f.startswith(\"mask_rcnn\"), checkpoints)\n    checkpoints = sorted(checkpoints)\n    if not checkpoints:\n        print('No weight files in {}'.format(dir_name))\n    else: \n      \n      checkpoint = os.path.join(dir_name, checkpoints[-1])\n      fps.append(checkpoint)\n\nmodel_path = sorted(fps)[-1]\nprint('Found model {}'.format(model_path))","d9225b55":"class InferenceConfig(DetectorConfig):\n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 1\n\ninference_config = InferenceConfig()\n\n# Recreate the model in inference mode\nmodel = modellib.MaskRCNN(mode='inference', \n                          config=inference_config,\n                          model_dir=ROOT_DIR)\n\n# Load trained weights (fill in path to trained weights here)\nassert model_path != \"\", \"Provide path to trained weights\"\nprint(\"Loading weights from \", model_path)\nmodel.load_weights(model_path, by_name=True)","80e2637a":"# set color for class\ndef get_colors_for_class_ids(class_ids):\n    class_ids = [x - 1 for x in class_ids]\n    colors = []\n    for class_id in class_ids:\n        if class_id == 1:\n            colors.append((.941, .204, .204))\n    return colors","09090439":"# Show few example of ground truth vs. predictions on the validation dataset \ndataset = dataset_val\nfig = plt.figure(figsize=(10, 30))\nstart_idx = 0\nfor i in range(start_idx, start_idx + 3):\n    \n    image_id = random.choice(dataset.image_ids)\n    \n    original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n        modellib.load_image_gt(dataset_val, inference_config, \n                               image_id, use_mini_mask=False)\n    plt.subplot(6, 2, 2*(i-start_idx) + 1)\n    visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n                                dataset.class_names,\n                                colors=get_colors_for_class_ids(gt_class_id), ax=fig.axes[-1])\n    \n    plt.subplot(6, 2, 2*(i-start_idx) + 2)\n    results = model.detect([original_image]) #, verbose=1)\n    r = results[0]\n    visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n                                dataset.class_names, r['scores'], \n                                colors=get_colors_for_class_ids(r['class_ids']), ax=fig.axes[-1])","ce5b6a0d":"# remove files to allow committing (hit files limit otherwise)\n# !rm -rf \/kaggle\/working\/Mask_RCNN","a7495bc3":"# Convert xml file information ke dict","3100ce0f":"# Mulai training","6381aee5":"# Buat kelas Konfigurasi untuk Detektor","57e578f0":"# Prediksi output","704e0ea7":"## Sekarang kita bisa mulai melatih dataset yang sebenarnya","9a7ebc62":"# Import utilitas yang diperlukan MaskRCNN ","5b2402d2":"## Download xmltodict helper dependencies","f8d27cd3":"# Visualisasikan gambar output","2534f987":"# Buat konfigurasi inferensi","bbb5acf3":"# Ubah informasi file xml ke dictionary \n## Parsing gambar dan anotasi dan dalam satu array","f1eafb44":"# Perluas kelas Dataset yang ada untuk menyesuaikan metode","e2c711d5":"# Download Mask RCNN library","109c1826":"## Muat dan visualisasikan piksel mask untuk 5 objek pertama","b27f1b6b":"## Tentukan labels","12d8593f":"# Setel direktori root untuk dataset train dan test","89541d13":"## Buat model dengan konfigurasi yang ditentukan yang ditentukan di bagian atas file","e6ee6b00":"## Muat dataset pelataihan dan persiapan","882b416e":"## Muat set data pelatihan dan persiapan","17db2996":"## Parse a single annoation\n- Extract the dict object and convert it into cocos format\n\nExample of format:\n{\n    \"all_points_x\": [...],\n    \"all_points_y\": [...],\n    \"num_id\": 3\n}","04b11f75":"# Simpan anotasi ke dalam set data kereta dan uji masing-masing","23757a53":"## Muat Bobot dari COCO dataset","e1b5c5aa":"## Download the coco weights","ea66dd70":"# Deteksi Buah Dengan Mask RCNN\n# FTI Unisbank\n# Nim : 17.01.53.0022\n\n# Import Modul yang diperlukan"}}