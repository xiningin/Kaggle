{"cell_type":{"eda09ad1":"code","fb536f3f":"code","8178e345":"code","8ad03b3f":"code","b5deec12":"code","d9b62e15":"code","a7588a71":"code","5dfdf0e5":"code","8a7504e5":"markdown","d5ea7c2a":"markdown","cf6cec1f":"markdown"},"source":{"eda09ad1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom keras.preprocessing import image\nfrom keras.models import Sequential\nfrom keras.models import Model\nfrom keras.utils import Sequence\nfrom keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input, Flatten\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom keras import backend as K\nK.set_image_dim_ordering('tf')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n\n\n# Any results you write to the current directory are saved as output.","fb536f3f":"#import os\nimport os\nprint(os.listdir(\"..\/input\"))\nprint (os.listdir(\"..\/input\/test\/test\"))\n\ntrain_data_dir ='..\/input\/train\/train'\nvalidation_data_dir = '..\/input\/test\/test'\n","8178e345":"#Inception input size and input image target size\nbatch_size = 32\nimg_width, img_height = 224, 224\n\n# prepare data augmentation configuration\ntrain_datagen = ImageDataGenerator(\n    rescale=1. \/ 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1. \/ 255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical')\n\ntest_generator = test_datagen.flow_from_directory(\n    validation_data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical')","8ad03b3f":"from keras.applications.densenet import DenseNet201\npretrained_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(224,224,3))\npretrained_model.summary()","b5deec12":"\nfrom keras import layers\nfrom keras import models\n\ntop_model = models.Sequential()\ntop_model.add(Flatten(input_shape=pretrained_model.output_shape[1:]))\n# model.add(pretrained_model)\n#top_model.add(layers.Flatten())\ntop_model.add(layers.Dense(512, activation='relu'))\ntop_model.add(Dropout(0.5))\ntop_model.add(layers.Dense(256, activation='relu'))\ntop_model.add(Dropout(0.5))\ntop_model.add(layers.Dense(67, activation='softmax'))\nmodel = Model(input= pretrained_model.input, output= top_model(pretrained_model.output))\nmodel.summary()","d9b62e15":"from keras import optimizers\nmodel.compile(optimizer=optimizers.SGD(lr=0.00002, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'], )\n#model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'], )\n\nepochs = 120\nbatch_size =128\nnb_train_samples = 5361\nnb_validation_samples = 1340\n\n\n# fine-tune the model\nmodel.fit_generator(\n    train_generator,\n    steps_per_epoch=nb_train_samples \/\/ batch_size,\n    epochs=epochs,\n    validation_data=test_generator,\n    validation_steps=nb_validation_samples \/\/ batch_size)","a7588a71":"for i, layer in enumerate(pretrained_model.layers):\n  print(i, layer.name)\n#freeze the first 704 layers and unfreeze the rest:\nfor layer in model.layers[:704]:\n   layer.trainable = False\nfor layer in model.layers[704:]:\n   layer.trainable = True","5dfdf0e5":"from keras import optimizers\n# model.compile(optimizer=optimizers.RMSprop(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'], )\n\nmodel.compile(optimizer=optimizers.SGD(lr=0.00005, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'], )\n\n\nepochs = 30\nbatch_size = 128\nnb_train_samples = 5361 \nnb_validation_samples = 1340\n\n# fine-tune the model\nmodel.fit_generator(\n    train_generator,\n    steps_per_epoch=nb_train_samples \/\/ batch_size,\n    epochs=epochs,\n    validation_data=test_generator,\n    validation_steps=nb_validation_samples \/\/ batch_size)","8a7504e5":" **Using Desnsnet201 with Tranfser Learning on MIT Indoor 67** dataset","d5ea7c2a":"**Preparing Data Using Data Augmentation**\n","cf6cec1f":"**Importing DenseNet201**\n- Using pretrained imagenet weight and setting top to false\n- We can call the .summary( ) function on the model we downloaded to see its architecture and number of parameters. "}}