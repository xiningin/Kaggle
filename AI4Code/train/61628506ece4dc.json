{"cell_type":{"3fc142c4":"code","a4698948":"code","fc31ad42":"code","6bfd9df9":"code","84c2f740":"code","17a79c8f":"code","ae6d267a":"code","b245c5aa":"code","dadfda3f":"markdown","ed80b5a8":"markdown","0f3042db":"markdown","bb865061":"markdown","aaffbcde":"markdown","d1e22d8a":"markdown","b3b50d0d":"markdown"},"source":{"3fc142c4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a4698948":"import pandas as pd\nimport numpy as np\nwine = pd.read_csv(\"..\/input\/wine-data\/wine_data.csv\")\nwine.head()","fc31ad42":"#Dropping Index\nwine = wine.iloc[:,1:] \nwine.head()","6bfd9df9":"#normalizing the values\n\nfrom sklearn.preprocessing import scale \nwine_norm = scale(wine) \nwine_norm","84c2f740":"\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\npca = PCA()\npca_values = pca.fit_transform(wine_norm)\n\n","17a79c8f":"# The amount of variance that each PCA explains\nvar = pca.explained_variance_ratio_ \nplt.plot(var)\npd.DataFrame(var)\n","ae6d267a":"# Cumulative variance \nvar1 = np.cumsum(np.round(var,decimals = 4)*100) \nvar1\n# Variance plot for PCA components obtained \nplt.plot(var1,color=\"red\")\n\n","b245c5aa":"#storing PCA values to a data frame\nnew_df = pd.DataFrame(pca_values[:,0:4])\nnew_df\n","dadfda3f":"**Varience**","ed80b5a8":"**DATA**","0f3042db":"**Building the PCA model.**","bb865061":"Here, we are going to use a sample pre-processed wine data containing various numerical features of a wine.","aaffbcde":"In this notebook we will use sklearn package for Principal Component Analysis ","d1e22d8a":"**During EDA when we have large set of variables we often get confused and lost deciding which features to choose so that our model will be safe from overfitting. In such cases the Dimension Reduction comes into play.In these cases we can make use of a unsupervised Algorithm known as PCA.\nPCA is used to find inter-relation between variables in the data y reducing the dimensions of a feature in such a way that they are statistically independent & not correlated.**","b3b50d0d":"Here, we can conclude that the out of the 14 principal components the first 4 PC contributes to the 69% of total varience."}}