{"cell_type":{"dbd4f04d":"code","20c1205d":"code","8ed07f1f":"code","3b93680f":"code","8e5dc16a":"code","cc568284":"code","70bb2dd1":"code","7ea4eef1":"code","9a233d8b":"code","253d4b28":"code","b38b411a":"code","e35c8723":"code","c494dc77":"code","763b535d":"code","fbe3724d":"code","f0bcb2cb":"code","60f3a9dc":"code","637e9d24":"code","b50b86b2":"code","ce856b22":"code","be563404":"code","787c60b1":"code","03f82dba":"code","85eceaea":"code","2c5894ca":"code","4186eadf":"code","19f2c438":"code","ac3ec65c":"code","73b79299":"code","b1b29a79":"code","81b14383":"code","4866ff5f":"code","1b7c1d4b":"code","ec5432e9":"code","42c83f1d":"code","b0be1c00":"code","475e043d":"code","b8f05cc7":"markdown"},"source":{"dbd4f04d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport seaborn as sns\nimport os\nimport cv2\nimport glob2\nfrom tqdm import tqdm\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\nprint(os.listdir(\"..\/input\"))\n\nfrom sklearn.model_selection import train_test_split,StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision.models import resnet50, resnet34, densenet201, densenet121\nfrom torch.utils.data import Dataset, DataLoader\n","20c1205d":"train_df = pd.read_csv('..\/input\/aptos2019-blindness-detection\/train.csv')","8ed07f1f":"train_df.head()","3b93680f":"test_df = pd.read_csv('..\/input\/aptos2019-blindness-detection\/test.csv')","8e5dc16a":"test_df.head()","cc568284":"sns.countplot(x='diagnosis',data=train_df)","70bb2dd1":"len(os.listdir('..\/input\/aptos2019-blindness-detection\/train_images'))","7ea4eef1":"len(os.listdir('..\/input\/aptos2019-blindness-detection\/test_images'))","9a233d8b":"train = glob2.glob('..\/input\/aptos2019-blindness-detection\/train_images\/*.png')\ntest = glob2.glob('..\/input\/aptos2019-blindness-detection\/test_images\/*.png')","253d4b28":"def read_image(filename):\n    img = cv2.imread(str(filename))\n    \n    x_tot = img.mean() #image statistics\n    x_rot2 = img.std()\n    return x_tot, x_rot2\n\ndef get_stats(stats): # get dataset statistics \n    x_tot, x2_tot = 0.0, 0.0\n    for x, x2 in stats:\n        x_tot += x\n        x2_tot += x2\n    \n    img_avr =  x_tot\/len(stats)\n    img_std = x2_tot\/len(stats)\n    print('mean:',img_avr, ', std:', img_std)","b38b411a":"trn_stats = []\nfor fname in tqdm(train, total=len(train)):\n    trn_stats.append(read_image(fname))","e35c8723":"test_stats = []        \nfor fname in tqdm(test, total=len(test)):\n    test_stats.append(read_image(fname))","c494dc77":"get_stats(trn_stats)\nget_stats(test_stats)","763b535d":"IMG_SIZE = 512\nBATCH_SIZE = 16","fbe3724d":"\ndef img_to_torch(image):\n    return torch.from_numpy(np.transpose(image, (2, 0, 1)))\n\ndef pad_to_square(image):\n    h, w = image.shape[0:2]\n    new_size = max(h, w)\n    delta_top = (new_size-h)\/\/2\n    delta_bottom = new_size-h-delta_top\n    delta_left = (new_size-w)\/\/2\n    delta_right = new_size-delta_left-w\n    new_im = cv2.copyMakeBorder(image, delta_top, delta_bottom, delta_left, delta_right, \n                                cv2.BORDER_CONSTANT,  value=[0,0,0])\n    return new_im\n\nclass AptosDataset(Dataset):\n    def __init__(self, df,datatype='train'):\n        self.df = df\n        self.datatype = datatype\n        self.image_files_list = [f'..\/input\/aptos2019-blindness-detection\/{self.datatype}_images\/{i}.png' for i in df['id_code'].values]\n        self.cache = {}\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        if index not in range(0, len(self.df)):\n            return self.__getitem__(np.random.randint(0, self.__len__()))\n        \n        # only take on channel\n#         if index not in self.cache:\n        image = cv2.imread(self.image_files_list[index])\n        image = pad_to_square(image)\n        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n#             self.cache[index] = img_to_torch(image)\n\n        return img_to_torch(image)","f0bcb2cb":"train_image = AptosDataset(train_df,datatype='train')\ntrain_image_loader = DataLoader(train_image, batch_size=BATCH_SIZE, shuffle=False, \n                       num_workers=1, pin_memory=True)","60f3a9dc":"class ResnetModel(nn.Module):\n    def __init__(self, resnet_fun=resnet50, freeze_basenet = True):\n        super(ResnetModel, self).__init__()\n        self.resnet = resnet_fun(pretrained=False)\n        if freeze_basenet:\n            for p in self.resnet.parameters():\n                p.requires_grad = False\n       \n    def init_resnet(self, path):\n        state = torch.load(path)\n        self.resnet.load_state_dict(state)\n        \n    def forward(self, x):\n        batch_size = x.shape[0]\n        x = x\/255.0\n        mean = [0.485, 0.456, 0.406]\n        std = [0.229, 0.224, 0.225]\n        x = torch.cat([\n            (x[:, [0]] - mean[0]) \/ std[0],\n            (x[:, [1]] - mean[1]) \/ std[1],\n            (x[:, [2]] - mean[2]) \/ std[2],\n        ], 1)\n        x = self.resnet.conv1(x)\n        x = self.resnet.bn1(x)\n        x = self.resnet.relu(x)\n        x = self.resnet.maxpool(x)\n        x = self.resnet.layer1(x)\n        x = self.resnet.layer2(x)\n        x = self.resnet.layer3(x)\n        x = self.resnet.layer4(x)\n        x = F.adaptive_avg_pool2d(x, output_size=1).view(batch_size, -1)\n        return x","637e9d24":"resnet50_feature = []\nmodel = ResnetModel()\nmodel.init_resnet('..\/input\/pytorch-pretrained-image-models\/resnet50.pth')\nmodel.cuda()\nmodel.eval()\nwith torch.no_grad():\n    for img_batch in tqdm(train_image_loader):\n        img_batch = img_batch.float().cuda()\n        y_pred = model(img_batch)\n        resnet50_feature.append(y_pred.cpu().numpy()) \nresnet50_feature = np.vstack(resnet50_feature)","b50b86b2":"RES50_IMG_FEATURE_DIM = resnet50_feature.shape[1]","ce856b22":"train_df.head()","be563404":"resnet50_feature_df = pd.DataFrame(resnet50_feature, dtype=np.float32,\n                                   columns=['resnet50_%d'%i for i in range(RES50_IMG_FEATURE_DIM)])\nresnet50_feature_df['id_code'] = train_df['id_code'].values","787c60b1":"resnet50_feature_df_avg = resnet50_feature_df.groupby('id_code').agg('mean').reset_index()\nresnet50_feature_df_avg.columns = ['id_code']+['resnet50_mean_%d'%i for i in range(RES50_IMG_FEATURE_DIM)]","03f82dba":"resnet50_feature_df_avg.head()","85eceaea":"resnet50_feature_train = train_df[['id_code','diagnosis']].merge(resnet50_feature_df_avg, on='id_code', how='left')","2c5894ca":"resnet50_feature_train.head()","4186eadf":"test_image = AptosDataset(test_df,datatype='test')\ntest_image_loader = DataLoader(test_image, batch_size=BATCH_SIZE, shuffle=False, \n                       num_workers=1, pin_memory=True)","19f2c438":"resnet50_feature = []\nmodel = ResnetModel()\nmodel.init_resnet('..\/input\/pytorch-pretrained-image-models\/resnet50.pth')\nmodel.cuda()\nmodel.eval()\nwith torch.no_grad():\n    for img_batch in tqdm(test_image_loader):\n        img_batch = img_batch.float().cuda()\n        y_pred = model(img_batch)\n        resnet50_feature.append(y_pred.cpu().numpy()) \nresnet50_feature = np.vstack(resnet50_feature)","ac3ec65c":"RES50_IMG_FEATURE_DIM = resnet50_feature.shape[1]","73b79299":"resnet50_feature_df = pd.DataFrame(resnet50_feature, dtype=np.float32,\n                                   columns=['resnet50_%d'%i for i in range(RES50_IMG_FEATURE_DIM)])\nresnet50_feature_df['id_code'] = test_df['id_code'].values\n#resnet50_feature_df['PicID'] = image_df['PicID'].values\nresnet50_feature_df_avg = resnet50_feature_df.groupby('id_code').agg('mean').reset_index()\nresnet50_feature_df_avg.columns = ['id_code']+['resnet50_mean_%d'%i for i in range(RES50_IMG_FEATURE_DIM)]","b1b29a79":"resnet50_feature_test = test_df[['id_code']].merge(resnet50_feature_df_avg, on='id_code', how='left')","81b14383":"resnet50_feature_test.head()","4866ff5f":"lgb_params = {\n    'boosting_type': 'gbdt',\n    'objective': 'binary',\n    'metric': 'auc',\n    'verbose': 1,\n    'learning_rate': 0.05,\n    'num_leaves': 31,\n    'feature_fraction': 0.7,\n    'min_data_in_leaf': 200,\n    'bagging_fraction': 0.8,\n    'bagging_freq': 20,\n    'min_hessian': 0.01,\n    'feature_fraction_seed': 2,\n    'bagging_seed': 3,\n    \"seed\": 1234\n}","1b7c1d4b":"features = [c for c in resnet50_feature_train.columns if c not in ['id_code', 'diagnosis']]\n\nlen_train = len(resnet50_feature_train)\nresnet50_feature_train['target'] = 1\nresnet50_feature_train = resnet50_feature_train.append(resnet50_feature_test).reset_index(drop = True)\nresnet50_feature_train['target'] = resnet50_feature_train['target'].fillna(0)","ec5432e9":"resnet50_feature_train.head()","42c83f1d":"skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1234)\noof = resnet50_feature_train[['id_code', 'target']]\noof['predict'] = 0\nval_aucs = []","b0be1c00":"for fold, (trn_idx, val_idx) in enumerate(skf.split(resnet50_feature_train, resnet50_feature_train['target'])):\n    X_train, y_train = resnet50_feature_train.iloc[trn_idx][features], resnet50_feature_train.iloc[trn_idx]['target']\n    X_valid, y_valid = resnet50_feature_train.iloc[val_idx][features], resnet50_feature_train.iloc[val_idx]['target']\n    trn_data = lgb.Dataset(X_train, label=y_train)\n    val_data = lgb.Dataset(X_valid, label=y_valid)\n    evals_result = {}\n    lgb_clf = lgb.train(lgb_params,\n                        trn_data,\n                        7500,\n                        valid_sets=[val_data],\n                        early_stopping_rounds=100,\n                        verbose_eval=50,\n                        evals_result=evals_result)\n\n    p_valid = lgb_clf.predict(X_valid[features], num_iteration=lgb_clf.best_iteration)\n\n    oof['predict'][val_idx] = p_valid\n    val_score = roc_auc_score(y_valid, p_valid)\n    val_aucs.append(val_score)","475e043d":"mean_auc = np.mean(val_aucs)\nstd_auc = np.std(val_aucs)\nall_auc = roc_auc_score(oof['target'], oof['predict'])\nprint(\"Mean auc: %.9f, std: %.9f. All auc: %.9f.\" % (mean_auc, std_auc, all_auc))","b8f05cc7":"Since AUC is ` 0.950535932`, LGB can easily differentiate between `train` and `test` set. This means that they come from different distribution. So expect mismatch between CV and public LB. Try making the `train` and `test` set have similar distribution.  "}}