{"cell_type":{"eb7cf7f4":"code","51321640":"code","cb43de79":"code","b71334c3":"code","2d7acd88":"code","eb3cc09e":"code","a5e16c35":"code","0de2a915":"code","04b4ed76":"code","1d68d1e9":"code","fff584e5":"code","90026b55":"code","d0e23f61":"markdown","fc123f75":"markdown","5c4c706b":"markdown","51e0bf59":"markdown","b743d82b":"markdown","8f9416e4":"markdown","13d4624e":"markdown"},"source":{"eb7cf7f4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","51321640":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","cb43de79":"train = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/test.csv')\nsub_xgb = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/sample_submission.csv')\nsub_lgb = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/sample_submission.csv')\nsub_two = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/sample_submission.csv')","b71334c3":"target = train['target'].values","2d7acd88":"columns = test.columns[1:]\ncolumns","eb3cc09e":"cont_cols = [col for col in columns if 'cont' in col]\ncat_cols = [col for col in columns if 'cat' in col]\n\ndef label_encode(train_df, test_df, column):\n    le = LabelEncoder()\n    new_feature = \"{}_le\".format(column)\n    le.fit(train_df[column].unique().tolist() + test_df[column].unique().tolist())\n    train_df[new_feature] = le.transform(train_df[column])\n    test_df[new_feature] = le.transform(test_df[column])\n    return new_feature\n\nle_cols = []\nfor feature in cat_cols:\n    le_cols.append(label_encode(train, test, feature))\n    \ncolumns = cont_cols + le_cols","a5e16c35":"def run_rskf(train, target, clf, params):\n    train_preds = np.zeros((train.shape[0], 2))\n    test_preds = 0\n    rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=1337)\n    for fold, (train_index, val_index) in enumerate(rskf.split(train, target)):\n        print(\"-> Fold {}\".format(fold + 1))\n       \n        x_train, x_valid = train.iloc[train_index][columns], train.iloc[val_index][columns]\n        y_train, y_valid = target[train_index], target[val_index]\n    \n        model = clf(**params)\n        model.fit(x_train, y_train,\n                    eval_set=[(x_valid, y_valid)], \n                    verbose=0,\n                    early_stopping_rounds=500)\n    \n        train_oof_preds = model.predict_proba(x_valid)[:,1]\n        train_preds[val_index, fold\/\/5] = train_oof_preds\n        test_oof_preds = model.predict_proba(test[columns])[:,1]\n        test_preds += test_oof_preds \/ 10\n        print(\"ROC AUC Score = {}\".format(roc_auc_score(y_valid, train_oof_preds)))\n        if fold in [4, 9]:\n            print(\"=> Overall ROC AUC Score = {}\".format(roc_auc_score(target, train_preds[:, fold\/\/5])))\n    return model, test_preds","0de2a915":"params_xgb = {'seed':2021,\n            'n_estimators':10000,\n            'verbosity':1,\n            'objective': 'binary:logistic',\n            'eval_metric':\"auc\",\n            'tree_method':\"gpu_hist\",\n            'use_label_encoder':False,\n            'gpu_id':0,\n            'alpha':7.105038963844129,\n            'colsample_bytree':0.25505629740052566,\n            'gamma':0.4999381950212869,\n            'reg_lambda':1.7256912198205319,\n            'learning_rate':0.011823142071967673,\n            'max_bin':338,\n            'max_depth':8,\n            'min_child_weight':2.286836198630466,\n            'subsample':0.618417952155855}\n\nclf_xgb = XGBClassifier","04b4ed76":"model_xgb, test_preds_xgb = run_rskf(train, target, clf_xgb , params_xgb)","1d68d1e9":"params_lgb = {\n            'cat_smooth':89.2699690675538,\n            'colsample_bytree':0.2557260109926193,\n            'learning_rate':0.00918685483594994,\n            'max_bin':788,\n            'max_depth':81,\n            'metric':\"auc\",\n            'min_child_samples':292,\n            'min_data_per_group':177,\n            'n_estimators':16000,\n            'n_jobs':-1,\n            'num_leaves':171,\n            'reg_alpha':0.7115353581785044,\n            'reg_lambda':5.658115293998945,\n            'subsample':0.9262904583735796,\n            'subsample_freq':1,\n            'verbose':-1\n            }\n\nclf_lgb = LGBMClassifier","fff584e5":"model_lgb, test_preds_lgb = run_rskf(train, target, clf_lgb , params_lgb)","90026b55":"sub_xgb['target'] = test_preds_xgb\nsub_xgb.to_csv('submission_xgb.csv', index=False)\n\nsub_lgb['target'] = test_preds_lgb\nsub_lgb.to_csv('submission_lgb.csv', index=False)\n\nsub_two['target'] = (test_preds_xgb + test_preds_lgb)\/2\nsub_two.to_csv('submission_two.csv', index=False)","d0e23f61":"## Build and Run","fc123f75":"## Submit","5c4c706b":"## Load libraries","51e0bf59":"## Xgboost","b743d82b":"## Read data","8f9416e4":"## Feature engineering","13d4624e":"## Lightgbm"}}