{"cell_type":{"8aa5b633":"code","e194ffe8":"code","94d079d8":"code","9729fab6":"code","d02beef4":"code","1a18fc4e":"code","8f59073c":"code","cdb7fcef":"code","414feb21":"code","fe46a0f5":"code","39aa358d":"code","1fc298f9":"code","5360a496":"code","5dc7f261":"code","4fea9616":"code","87b65d48":"code","3074a3c6":"code","0a7933c4":"code","849bbf73":"code","5052809f":"markdown","166cc193":"markdown","85ffab94":"markdown","8cbaded7":"markdown","a9e1d5df":"markdown","41b1e012":"markdown","730fed81":"markdown","eba14696":"markdown","05e0d3f3":"markdown","42070333":"markdown","0d61db70":"markdown","9731e1f9":"markdown","a381a41c":"markdown","0ee9dbdd":"markdown"},"source":{"8aa5b633":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.layers import Conv2D, Dense, BatchNormalization, Activation, Dropout, MaxPooling2D, Flatten,AveragePooling2D\nfrom keras.optimizers import Adam, SGD\nfrom keras import Sequential\nimport matplotlib.pyplot as plt\nfrom keras.utils import plot_model\nimport cv2\nimport os\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\ntrain_dir = '..\/input\/multiclassimagedatasetairplanecar\/Dataset\/train\/'\ntest_dir = '..\/input\/multiclassimagedatasetairplanecar\/Dataset\/test\/'","e194ffe8":"def count_exp(path, set_):\n    dict_ = {}\n    for expression in os.listdir(path):\n        dir_ = path + expression\n        dict_[expression] = len(os.listdir(dir_))\n    df = pd.DataFrame(dict_, index=[set_])\n    return df\ntrain_count = count_exp(train_dir, 'train')\ntest_count = count_exp(test_dir, 'test')\nprint(train_count)\nprint(test_count)","94d079d8":"print('training pictures\\n')\nplt.figure(figsize=(14,22))\ni = 1\nfor expression in os.listdir(train_dir):\n    img = load_img((train_dir + expression +'\/'+ os.listdir(train_dir + expression)[5]))\n    plt.subplot(1,7,i)\n    plt.imshow(img)\n    plt.title(expression)\n    plt.axis('off')\n    i += 1\nplt.show()\n\nprint('testing pictures\\n')\nplt.figure(figsize=(14,22))\ni = 1\nfor expression in os.listdir(test_dir):\n    img = load_img((test_dir + expression +'\/'+ os.listdir(test_dir + expression)[5]))\n    plt.subplot(1,7,i)\n    plt.imshow(img)\n    plt.title(expression)\n    plt.axis('off')\n    i += 1\nplt.show()","9729fab6":"train_datagen = ImageDataGenerator(rescale=1.\/255,\n                                   zoom_range=0.3,\n                                   rotation_range=30,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   brightness_range=[0.4,1.5],\n                                   horizontal_flip=True)\n\ntraining_set = train_datagen.flow_from_directory(train_dir,\n                                                batch_size=32,\n                                                target_size=(224,224),\n                                                shuffle=True,\n                                                color_mode='rgb',\n                                                class_mode='categorical')\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_set = test_datagen.flow_from_directory(test_dir,\n                                                batch_size=32,\n                                                target_size=(224,224),\n                                                shuffle=True,\n                                                color_mode='rgb',\n                                                class_mode='categorical')","d02beef4":"vgg = VGG16(weights='imagenet',\n              include_top=False,               \n              input_shape = (224,224,3))","1a18fc4e":"for layer in vgg.layers:\n    layer.trainable = False","8f59073c":"vgg16Model = Sequential()\nvgg16Model.add(vgg)\nvgg16Model.add(Flatten())\nvgg16Model.add(Dense( 3, activation = \"softmax\"))\n\nvgg16Model.summary()","cdb7fcef":"plot_model(vgg16Model, to_file='vgg16.png', show_shapes=True, show_layer_names=True)","414feb21":"\nsteps_per_epoch = training_set.n \/\/ training_set.batch_size\nvalidation_steps = test_set.n \/\/ test_set.batch_size\n\ncheckpoint = ModelCheckpoint(\"vgg16.h5\",monitor = \"val_accuracy\",save_best_only = True,verbose=1)\nearlystop = EarlyStopping(monitor=\"val_accuracy\",patience=8,verbose=1)\n\nvgg16Model.compile(optimizer=\"adam\",loss = \"categorical_crossentropy\",metrics = [\"accuracy\"])\n\nhist = vgg16Model.fit(x=training_set,\n                 validation_data=test_set,\n                 epochs=25,\n                 callbacks=[checkpoint,earlystop],\n                 steps_per_epoch=steps_per_epoch,\n                 validation_steps=validation_steps)","fe46a0f5":"def plot_results(history):\n    plt.figure(figsize=(14,5))\n    plt.subplot(1,2,2)\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('Model Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend(['train', 'test'], loc='upper left')\n\n    plt.subplot(1,2,1)\n    plt.plot(hist.history['loss'])\n    plt.plot(hist.history['val_loss'])\n    plt.title('model Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()","39aa358d":"plot_results(hist)","1fc298f9":"resnet = ResNet50(weights='imagenet',\n              include_top=False,               \n              input_shape = (224,224,3))","5360a496":"for layer in resnet.layers:\n    layer.trainable = False","5dc7f261":"Resnet50 = Sequential()\nResnet50.add(resnet)\nResnet50.add(Flatten())\nResnet50.add(Dense(3,activation = \"softmax\"))\n\nResnet50.summary()","4fea9616":"plot_model(Resnet50, to_file='resnet50.png', show_shapes=True, show_layer_names=True)","87b65d48":"steps_per_epoch = training_set.n \/\/ training_set.batch_size\nvalidation_steps = test_set.n \/\/ test_set.batch_size\n\ncheckpoint = ModelCheckpoint(\"resnet50.h5\",monitor = \"val_accuracy\",save_best_only = True,verbose=1)\nearlystop = EarlyStopping(monitor=\"val_accuracy\",patience=8,verbose=1)\n\nResnet50.compile(optimizer=\"adam\",loss = \"categorical_crossentropy\",metrics = [\"accuracy\"])\n\nhist = Resnet50.fit(x=training_set,\n                 validation_data=test_set,\n                 epochs=25,\n                 callbacks=[checkpoint,earlystop],\n                 steps_per_epoch=steps_per_epoch,\n                 validation_steps=validation_steps)","3074a3c6":"plot_results(hist)","0a7933c4":"steps_per_epoch = training_set.n \/\/ training_set.batch_size\nvalidation_steps = test_set.n \/\/ test_set.batch_size\n\ncheckpoint = ModelCheckpoint(\"vgg16.h5\",monitor = \"val_accuracy\",save_best_only = True,verbose=1)\nearlystop = EarlyStopping(monitor=\"val_accuracy\",patience=8,verbose=1)\n\nsgd = SGD(lr=0.01, momentum=0.9, nesterov=True)\nvgg16Model.compile(optimizer=sgd,loss = \"categorical_crossentropy\",metrics = [\"accuracy\"])\n\nhist = vgg16Model.fit(x=training_set,\n                 validation_data=test_set,\n                 epochs=25,\n                 callbacks=[checkpoint,earlystop],\n                 steps_per_epoch=steps_per_epoch,\n                 validation_steps=validation_steps)","849bbf73":"plot_results(hist)","5052809f":"*plot results*","166cc193":"* Try to fine tune VGG16","85ffab94":"* Resnet50","8cbaded7":"build new FC layer to go on top of the downloaded net","a9e1d5df":"# Modeling","41b1e012":" # Preeproccessing Data","730fed81":"# conclusion","eba14696":"* count pictures in each category","05e0d3f3":"This model gives very good results - maybe too good...","42070333":"Do not retrain downloaded net","0d61db70":"* VGG16","9731e1f9":"The VGG16 with optimimaizer Adam was most efficient ","a381a41c":"This model gives unstable results","0ee9dbdd":"* load the pictures with data loaders\n* augmatation"}}