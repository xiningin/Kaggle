{"cell_type":{"c199067b":"code","c46ff43d":"code","b03269e0":"code","ce97a09f":"code","0856ecff":"code","66da4ca9":"code","a5e51c80":"code","494b19a5":"code","99c79580":"code","ca9bbdc7":"code","2982a394":"code","56ddfbf3":"code","c1fd48ed":"code","26649e1c":"code","a270d085":"code","f123a3e0":"code","295a8aad":"code","10dd770d":"code","4c79122b":"code","769d8a83":"code","f9df04f6":"code","3d535d1e":"code","4e1b23d2":"code","a42efb6e":"code","dc1a0eef":"code","e6f8da67":"code","88b7b7bd":"code","c4388b3c":"code","23e51a83":"markdown","d4a78c95":"markdown","0f2904f9":"markdown","c413e079":"markdown","61484885":"markdown","8964c085":"markdown","bf5ef5a9":"markdown","d6abf486":"markdown","77c883fe":"markdown","5fc266aa":"markdown","f6091756":"markdown","07a71be2":"markdown","199d75ac":"markdown","9dc1f9ca":"markdown","382d8922":"markdown","6a474ee6":"markdown","941c653f":"markdown","64cf6f3a":"markdown","29932aa8":"markdown","32e78580":"markdown","18113389":"markdown","707357a6":"markdown","aee27699":"markdown","1f22d39a":"markdown","e43b0953":"markdown","66713eab":"markdown","f9727ca4":"markdown","a12645d9":"markdown","25018349":"markdown","67e53a9b":"markdown","90f42bac":"markdown","2b6346b8":"markdown","93bf5c11":"markdown","6f87e96d":"markdown","a394a883":"markdown","060d7236":"markdown","cb8007a0":"markdown","6d9fbf20":"markdown","1a92006c":"markdown","b80fcffb":"markdown","8b65cd0e":"markdown","d80a6cf6":"markdown","7b365e6b":"markdown","314eb824":"markdown"},"source":{"c199067b":"!pip install pycaret[full] --upgrade --ignore-installed --force-reinstall\n!pip install plotly --upgrade --ignore-installed --force-reinstall\n!pip install pandas --upgrade --ignore-installed\n!pip install smac[all] --upgrade --ignore-installed\n!conda update --all --yes --no-pin --no-channel-priority\n!pip install scikit-learn --upgrade --ignore-installed","c46ff43d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.notebook import tqdm_notebook\nfrom sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\nfrom sklearn.metrics import silhouette_score\nfrom pycaret.clustering import *\nfrom pycaret.utils import enable_colab\nenable_colab()\nimport plotly.offline as pyo\nimport plotly.graph_objs as go\npyo.init_notebook_mode(connected=True)\nimport plotly.io as pio\npio.renderers.default = 'colab'\nfrom sklearn.cluster import AgglomerativeClustering, Birch, KMeans\nfrom sklearn.cluster import MiniBatchKMeans, MeanShift, AffinityPropagation\nfrom sklearn.cluster import DBSCAN, OPTICS,FeatureAgglomeration\nfrom sklearn.cluster import SpectralClustering, SpectralBiclustering, SpectralCoclustering\nfrom sklearn.decomposition import PCA","b03269e0":"dataset = '\/kaggle\/input\/mall-customers\/Mall_Customers.csv'","ce97a09f":"df = pd.read_csv(dataset)","0856ecff":"print(df.head())","66da4ca9":"print(df.shape)","a5e51c80":"print(df.info())","494b19a5":"df.drop(['CustomerID'], axis = 1, inplace = True) ","99c79580":"df = df.rename(columns={\"Genre\": \"Gender\",\"Annual Income (k$)\": \"Annual_Income\", \"Spending Score (1-100)\": \"Spending_Score\"})","ca9bbdc7":"num_cols = df.select_dtypes('number').columns.tolist()\ncat_cols = df.select_dtypes('object').columns.tolist()","2982a394":"oe = OrdinalEncoder()\ndf[cat_cols] = oe.fit_transform(df[cat_cols])","56ddfbf3":"print(df.describe())","c1fd48ed":"df['Age'].hist(bins=5);","26649e1c":"x = df['Age']\ny = df['Annual_Income']\nplt.scatter(x,y)\nplt.xlabel('Age')\nplt.ylabel('Annual Income');","a270d085":"sns.countplot(data=df, x='Gender',order=df['Gender'].value_counts().index);","f123a3e0":"sns.boxplot(y=df['Annual_Income'], x=df['Gender'],order=df['Gender'].value_counts().index);","295a8aad":"sns.pairplot(df[num_cols], plot_kws=dict(alpha=.1, edgecolor='none'));","10dd770d":"sns.heatmap(df[num_cols]);","4c79122b":"corr = df.corr()\nmask = np.triu(corr)\nsns.heatmap(corr, mask=mask, cmap='Wistia', center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5},  annot= True);","769d8a83":"inertias = []\nnum_clusters = range(2,41)\nfor k in num_clusters:\n    kmeans = KMeans(n_clusters=k)\n    kmeans.fit(df)\n    inertias.append(kmeans.inertia_)\n    \nplt.plot(num_clusters,inertias,'bx-')\nplt.xlabel('Values of K') \nplt.ylabel('Inertia') \nplt.title('Elbow Method For Optimal k')\nplt.show()","f9df04f6":"silhouette_avg = []\nn_clusters = range(2,41)\nfor k in n_clusters:\n    kmeans = KMeans(n_clusters=k)\n    kmeans.fit(df)\n    cluster_labels = kmeans.labels_\n    silhouette_avg.append(silhouette_score(df, cluster_labels))\n\nplt.plot(n_clusters,silhouette_avg,'bx-')\nplt.xlabel('Values of K') \nplt.ylabel('Silhouette score') \nplt.title('Silhouette Analysis For Optimal k')\nplt.show()","3d535d1e":"k = 6\nmodels = []\nmodels.append(('Agglomerative', AgglomerativeClustering(n_clusters=k)))\nmodels.append(('Birch', Birch(threshold=0.01, n_clusters=k)))\nmodels.append(('KMeans', KMeans(n_clusters=k)))\nmodels.append(('MiniBatchKMeans', MiniBatchKMeans(n_clusters=k)))\nmodels.append(('Spectral', SpectralClustering(n_clusters=k)))\nmodels.append(('AffinityPropagation',  AffinityPropagation(damping=0.9)))\nmodels.append(('OPTICS', OPTICS(eps=0.8, min_samples=10)))\nresults = []\nnames = []\nfor name, model in tqdm_notebook(models):   \n    model.fit_predict(df)\n    results.append(silhouette_score(df, model.labels_))\n    names.append(name)","4e1b23d2":"# Compare Algorithms\nresults_df = pd.DataFrame({'Clustering_Algorithm': names, 'Silhouette_Score': results})\nresults_df = results_df.sort_values(by=['Silhouette_Score'], ascending=False)\nprint(results_df)\nsns.barplot(data=results_df, x='Silhouette_Score', y='Clustering_Algorithm', orient = 'h');\nplt.title('Algorithms Comparison');","a42efb6e":"pca = PCA(2)\ndata = pca.fit_transform(df)\nkmeans = KMeans(n_clusters= k)\nlabel = kmeans.fit_predict(data)\nu_labels = np.unique(label)\nfor i in u_labels:\n    plt.scatter(data[label == i , 0] , data[label == i , 1] , label = i)\nplt.legend()\nplt.show()","dc1a0eef":"data = df.sample(frac=0.85, random_state=333)\ndata_unseen = df.drop(data.index)\ndata.reset_index(drop=True, inplace=True)\ndata_unseen.reset_index(drop=True, inplace=True)","e6f8da67":"exp_name = setup(data = data, silent=True, preprocess= False, session_id=333)\nkmeans =tune_model(model = 'kmeans', supervised_target = 'Age', fold=22, custom_grid =list(range(2,41)))\nplot_model(kmeans)\nkmeans_predictions = predict_model(model = kmeans, data = data_unseen)\napd = {'Clustering_Algorithm': 'AutoML_PyCaret', 'Silhouette_Score': silhouette_score(data_unseen,list(kmeans_predictions['Cluster']), metric='euclidean')}","88b7b7bd":"print(kmeans)","c4388b3c":"results_df = results_df.append(apd, ignore_index=True)\nresults_df = results_df.sort_values(by=['Silhouette_Score'], ascending=False)\nprint(results_df)\nsns.barplot(data=results_df, x='Silhouette_Score', y='Clustering_Algorithm', orient = 'h');\nplt.title('Algorithms Comparison');","23e51a83":"## Modeling","d4a78c95":"## Recommendations","0f2904f9":"Classifying columns as Numerical or Categorical","c413e079":"For confirmation we also looking at the Silhouette Score Method to get the optimal number of clusters","61484885":"Using automated machine learning yield better results than manual models\n\nFor this dataset we will use PyCaret and compare the results to results obtained before","8964c085":"* Annual Income and Age are the main factors in deciding the clusters\n* There is no target column, so the algorithm will try to figure out the patterns in the data\n* Having both of Elbow method and Silhouette Score method will help in choosing the right number of clusters","bf5ef5a9":"## Packages to be installed","d6abf486":"Features Encoding","77c883fe":"**Actions taken for data cleaning and feature engineering**","5fc266aa":"The goal of the dataset is to segment the customers into distinct groups in order to receive product reccomendations based on their shopping habbits and spending. the data was collected by a mall for its customers with membership cards which benifit them in getting discounted prices for the items they purchased and for mall to collect data about its customer spending amount, frequency and items purchased. based on that they get score in the system, the higher the score, the more that customer shopping and spending at the mall\n\n| S No. | Column | Description| Data Type | Category| Type\n| --- | --- | --- | --- | --- | --- |\n|1 | Customer ID | Customer ID assigned by the mall | Int | Discrete | Variable |\n|2 | Gender | Customer Gender | String | Nominal | Variable |\n|3 | Age | Customer Age | Int | Discrete | Variable |\n|4 | Annual Income (k$) | Annual Income of the customer in Thousand Dollars | Int | Discrete | Variable |\n|5 | Spending score (1-100)| Score from 1 to 100, the higher the score, the better the customer | Int | Discrete | Variable |","f6091756":"**Brief description of the data set you chose and a summary of its attributes**","07a71be2":"Correlation plot of numerical features","199d75ac":"Dataset information","9dc1f9ca":"Distribution of Age for patients","382d8922":"1. pycaret\n2. plotly","6a474ee6":"Reading the dataset into dataframe","941c653f":"Kmeans Clustering have the best score of all clustering models for the training sets,so it will be chosen to make the prediction on the data set","64cf6f3a":"The default configuration for automated machine learning give better results than the model that manually selected and modified","29932aa8":"Train clustering models on the dataset and choosing the best model based on accuracy","32e78580":"Fixing columns names","18113389":"Distribution of Annual Income for each Gender","707357a6":"First we need to identify the best number of clusters, we start with the Elbow Method","aee27699":"**Key Findings and Insights**","1f22d39a":"Count for each Gender","e43b0953":"From the two graphs above, number of clusters will be 6\n\nWe will be using most of the clustering algorithms in the Sikit-Learn library and comparing them according to accuracy","66713eab":"Number of rows and coulmns in dataset","f9727ca4":"Information of the AutoML best model","a12645d9":"1. numpy\n2. pandas\n3. matplotlib\n4. seaborn\n5. sklearn\n6. pycaret\n7. tqdm","25018349":"## Exploratory Data Analysis (EDA)","67e53a9b":"Location of dataset","90f42bac":"Correlation between Age and Annual Income","2b6346b8":"Sampling the data","93bf5c11":"Summary Statistics for Numerical columns","6f87e96d":"Heatmap of numerical features","a394a883":"**Plan for Data Exploration, Feature Engineering and Modelling**","060d7236":"The steps in solving the Regression Problem are as follows:\n1. Packages to be installed\n2. Load the libraries\n3. Load the dataset\n4. General information about the dataset\n5. Exploratory Data Analysis (EDA)\n6. Modeling\n7. Recommendations","cb8007a0":"## Load the libraries","6d9fbf20":"## General information about the dataset","1a92006c":"Pair plot of numerical features","b80fcffb":"Visual Exploration of Categorical columns","8b65cd0e":"Visual Exploration of Numerical Columns","d80a6cf6":"## Load the dataset","7b365e6b":"**Main objective of the analysis that specifies whether your model will be focused on prediction or interpretation.**","314eb824":"Dropping irrelevant columns"}}