{"cell_type":{"0a4db40a":"code","95222b5a":"code","0ca616a2":"code","858e2e2e":"code","983f82e8":"code","96699678":"code","0072cab8":"code","069c586d":"code","dc0f3886":"code","4204e4f5":"code","fbf603fb":"code","63fcfc26":"code","3a81e77e":"code","c94a8beb":"code","c175d154":"code","7a389057":"code","58a4aa57":"code","8297b1b8":"code","46bb7403":"markdown","b937e87f":"markdown","4d40bb9d":"markdown","a6fcdf41":"markdown","86d0cbdc":"markdown","7899602c":"markdown","440f301a":"markdown","7431c25d":"markdown","4c189f61":"markdown","d3fe80c9":"markdown","70f71870":"markdown","f6ab3c96":"markdown","459b816e":"markdown"},"source":{"0a4db40a":"import pandas as pd\ntrain_set = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\n\nX = train_set.drop('label', axis=1)\ny = train_set['label']","95222b5a":"import numpy as np\n\n# Split the train set into two.\nnum = int(len(X)*(3\/5))\nX_train, X_valid = X[:num],X[num:]\ny_train, y_valid = y[:num],y[num:]\n\nprint(\"X_train :\",len(X_train))\nprint(\"y_train :\",len(y_train))\nprint(\"X_valid :\",len(X_valid))\nprint(\"y_valid :\",len(y_valid))","0ca616a2":"# Calculation takes too long, reduce size of data set\n# X_train, X_valid = X_train[:500], X_valid[:200]\n# y_train, y_valid = y_train[:500], y_valid[:200]\n\nprint(\"X_train :\",len(X_train))\nprint(\"y_train :\",len(y_train))\nprint(\"X_valid :\",len(X_valid))\nprint(\"y_valid :\",len(y_valid))","858e2e2e":"import time\nimport pandas as pd\nfrom tqdm.notebook   import tqdm\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import cross_val_predict\n\ndef train(*models,dataset=(X_train,y_train,X_valid, y_valid)):\n    columns = [\"Name\", \"Time(sec)\",\"accuracy(%)\", \"precision(%)\",\"recall(%)\",\"f1-score\",\"confusion\" ,\"model\"]\n    df = pd.DataFrame(columns=columns)\n    \n    X_train,y_train,X_valid,y_valid = dataset\n\n    for model in tqdm(models) :\n        model_name = str(model.__class__.__name__)\n        print(model_name, end=\"...\")\n        \n        # Time measurement\n        start = time.time()\n        \n        # Trainning start\n        model.fit(X_train,y_train)\n        \n        # report\n        y_pred     = cross_val_predict(model, X_valid, y_valid, cv=3)     \n        clf_report = classification_report(y_valid,y_pred, output_dict =True)\n        \n        accuracy   = clf_report[\"accuracy\"]                # accuracy\n        precision  = clf_report['macro avg']['precision']  # precision\n        recall     = clf_report['macro avg']['recall']     # recall\n        f1_score   = clf_report['macro avg']['f1-score']\n        confusion  = confusion_matrix(y_valid, y_pred)     # confusion_matrix\n        \n        accuracy,precision,recall = [round(100*x,2) for x in [accuracy,precision,recall]]\n        \n        train_time = round(time.time() - start,2)\n\n        # save data\n        new_row = {f\"{columns[0]}\":model_name, # name\n                   f\"{columns[1]}\":train_time, # training time\n                   f\"{columns[2]}\":accuracy,   # accuracy\n                   f\"{columns[3]}\":precision,  # precision\n                   f\"{columns[4]}\":recall,     # recall \n                   f\"{columns[5]}\":f1_score,   # f1_score \n                   f\"{columns[6]}\":confusion,  # confusion_matrix \n                   f\"{columns[7]}\":model       # clf model\n                  }\n        \n        df = df.append(new_row,ignore_index=True)    \n        df = df.drop_duplicates([\"Name\"],keep=\"last\")\n        print(\"complite..!\")\n    return df","983f82e8":"from sklearn.ensemble     import ExtraTreesClassifier\nfrom sklearn.ensemble     import RandomForestClassifier\nfrom sklearn.tree         import DecisionTreeClassifier\nfrom sklearn.naive_bayes  import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.svm          import SVC\nfrom sklearn.neighbors    import KNeighborsClassifier\n\n# Random Seed\nrandom_state = 20142927\n\n# Definition of Classifiers\next_clf = ExtraTreesClassifier(n_estimators=20,random_state=random_state)\ndet_clf = det_clf = DecisionTreeClassifier(splitter=\"random\",criterion='entropy',random_state=random_state) # splitter=\"random\" \ube60\ub984\nrdf_clf = RandomForestClassifier(n_estimators=15, random_state=random_state)\nknn_clf = KNeighborsClassifier(n_neighbors=20,leaf_size=50)\ngnb_clf = GaussianNB()\nlog_clf = LogisticRegression()\nsgd_clf = SGDClassifier(random_state=random_state)\nsvc_clf = SVC() \n\n\n# train and save classifiers\nclf_data = train( \n    ext_clf, \n    det_clf, \n    rdf_clf, \n    knn_clf\n)","96699678":"from sklearn.ensemble     import VotingClassifier\nfrom sklearn.ensemble     import BaggingClassifier\nfrom sklearn.ensemble     import AdaBoostClassifier\nfrom sklearn.ensemble     import GradientBoostingRegressor\n\nbag_clf = BaggingClassifier(\n    ExtraTreesClassifier(n_estimators=20,random_state=random_state),\n    n_jobs=-1,\n    n_estimators=5,\n    random_state=random_state\n)\n\nada_clf = AdaBoostClassifier(\n    ExtraTreesClassifier(n_estimators=20,random_state=random_state), \n    n_estimators=50,\n    learning_rate=0.2, \n    algorithm=\"SAMME.R\", \n    random_state=random_state\n)\n\n\nvot_clf = VotingClassifier(\n    estimators= [        \n        (\"ext_clf\",ext_clf),\n        (\"rdf_clf\",rdf_clf),\n#         (\"knn_clf\",knn_clf), # Accurate, but takes long time\n#         (\"det_clf\",det_clf), # The accuracy is too low\n#         (\"svc_clf\",svm_clf), # The accuracy is too low\n#         (\"sgd_clf\",sgd_clf), # Takes too much time\n        (\"bag_clf\",bag_clf),\n        (\"ada_clf\",ada_clf)\n    ] , voting='soft'\n)\n\n\nclf_data = clf_data.append(\n     train(bag_clf, ada_clf, vot_clf),ignore_index=True\n)","0072cab8":"clf_data.iloc[:,[0,1,2,5,6]]","069c586d":"for i in range(len(clf_data)) : \n    print(clf_data[\"Name\"][i], end=\"\\t\")\n    print(clf_data[\"accuracy(%)\"][i], end=\"(%) \\n  f1-score : \")\n    print(clf_data[\"f1-score\"][i],)\n    print(clf_data[\"confusion\"][i])\n    print(\"\\n\")","dc0f3886":"from sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndef show_auc(y_true,y_score):\n    fpr, tpr, _ = roc_curve(y_true, y_score)\n    roc_auc = auc(fpr, tpr)\n    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')    \n    plt.legend(loc=\"lower right\")\n    \n    \ndef Pretreatment_ROC(model, X, y):\n    y_prob = model.predict_proba(X)\n    y_pred = cross_val_predict(model, X, y)\n    y_true = np.array(y == y_pred)\n    y_score = [y_prob[i][y.iloc[i]] for i in range(len(y_prob))]\n                        \n    return y_true, y_score\n\n    \n\ndef ROC_data(*models) :\n    columns = [\"Name\",\"test_time\",\"y_true\",\"y_score\"]\n    df = pd.DataFrame()\n    y_true, y_score =[], []\n  \n    for i in tqdm(range(len(models)))  :\n        model = models[i]\n        model_name = str(model.__class__.__name__) \n#         print(model_name, end=\"...\")\n\n       # Time measurement\n        start = time.time()\n        \n        y_true, y_score = Pretreatment_ROC(model,X_valid,y_valid)\n        \n        test_time = round(time.time() - start,2)\n\n        # data save\n        new_row = {f\"{columns[0]}\":model_name,\n                   f\"{columns[1]}\":test_time,  \n                   f\"{columns[2]}\":y_true,  \n                   f\"{columns[3]}\":y_score,  \n                  }\n        \n        df = df.append(new_row,ignore_index=True)\n        df = df.drop_duplicates([\"Name\"],keep=\"last\")\n#         print(\"complite..!\")\n    return df\n\n\ndef add_data(model,dataset):\n    clf_data = train(model)\n    ROC_dataset = ROC_data(model)\n    new_row = pd.merge(clf_data, ROC_dataset, how='outer')\n    return dataset.append(new_row)","4204e4f5":"models = [    \n    ext_clf, \n    det_clf, \n    rdf_clf, \n    knn_clf, \n    bag_clf, \n    ada_clf, \n    vot_clf]\n\n\n# Train and store data in 'dataset'\n# clf_data = train(*models)\nROC_dataset = ROC_data(*models)\ndataset = pd.merge(clf_data, ROC_dataset, how='outer')\n\ndataset.iloc[:,[0,2,8,9,10]] ","fbf603fb":"plt.figure(figsize=(12,10))   \nfor i in tqdm(range(len(models)))  :\n  \n    # Positioning ==================\n    col=2\n    row = len(models)\/\/col + 1\n    plt.subplot(row,col,i+1)\n    \n    # plot ROC curve ===============\n    y_true  = dataset.iloc[i,10]\n    y_score = dataset.iloc[i,9]\n    show_auc(y_true, y_score)\n    \n    # Get data ====================\n    clf_name = dataset.iloc[i,0]\n    accuracy = dataset.iloc[i,2]\n    \n    # Display Name and Accuracy =====\n    tp = (0.2, 0.7) # Text Position\n    text = \"Accuracy : \"+ str(accuracy)+\"%\"\n    plt.text(tp[0],tp[1], clf_name, fontsize=15)\n    plt.text(tp[0],tp[1]-0.1, text, fontsize=13)\n    \nplt.tight_layout()\nplt.show()","63fcfc26":"import matplotlib\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nimport random\n\nclass MNIST:        \n    def __init__(self, X, y,pca):\n        self.pca = pca\n        self.X = X\n        self.y = y\n        self.ordinal = self.X\n        self.reduced = self.pca.fit_transform(self.ordinal)\n        self.recovered = self.pca.inverse_transform(self.reduced)\n        \n    def show(self,digit=None):\n        if not digit : index = random.randint(0,len(self.X))\n        else : index = int(digit)\n        \n        # Image preprocessing        \n        image_ord = np.array(self.ordinal.iloc[index]).reshape(28, 28)\n        image_rcd = np.array(self.recovered[index]).reshape(28, 28)\n        \n        # Plot Image\n        plt.figure(figsize=(7, 4))\n        pos = 121\n        for img in [image_ord, image_rcd] :\n            plt.subplot(pos)\n            plt.title(f\"y = {self.y[index]}\",fontsize = 15)\n            plt.imshow(img, cmap = matplotlib.cm.binary,interpolation=\"nearest\")\n            plt.axis(\"off\"); pos += 1    \n        plt.tight_layout()\n        print(self.pca)\n        \n        \npca = PCA(n_components=0.8,whiten=True)\npca_train= MNIST(X_train,y_train,pca)\npca_valid = MNIST(X_valid,y_valid,pca)","3a81e77e":"pca_train.show()","c94a8beb":"models = [    \n    ext_clf, \n    det_clf, \n    rdf_clf, \n    knn_clf, \n    bag_clf, \n    ada_clf, \n    vot_clf,\n]\n\n\nprint(\"train ordinal data\")\nclf_ord = train(*models)\n\nprint(\"train redused data\")\nclf_pca = train(*models, dataset=(\n    pca_train.reduced, pca_train.y,\n    pca_valid.reduced,  pca_valid.y\n))","c175d154":"clf_ord.iloc[:,[5]] =  round(100* clf_ord.iloc[:,[5]],2)\nclf_ord_2 = clf_ord.iloc[:,[1,2,3,4,5]]\nclf_ord_2.index = clf_ord[\"Name\"]\nclf_ord_2.columns = [\"time\",\"accuracy\",\"percision\",\"recall\",\"f1-score\"]\n\nclf_pca.iloc[:,[5]] =  round(100* clf_pca.iloc[:,[5]],2)\nclf_pca_2 = clf_pca.iloc[:,[1,2,3,4,5]]\nclf_pca_2.index = clf_ord[\"Name\"]\nclf_pca_2.columns = [\"time\",\"accuracy\",\"percision\",\"recall\",\"f1-score\"]\n\nclf_ord_2,clf_pca_2","7a389057":"label= [x.replace('Classifier', '') for x in clf_pca_2.index]\n\nindex = np.arange(len(label))\n\n# plot Graph  ==================\nfor key in clf_pca_2.keys():\n    plt.figure(figsize=(15,4))   \n    w = 0.4\n    plt.title(key, fontsize=15)\n\n    plt.bar(index-w\/2, clf_ord_2[key], width=w, label = \"ord\")\n    plt.bar(index+w\/2, clf_pca_2[key], width=w, label = \"pca\")\n    \n    # Axis setting\n    y = [*clf_ord_2[key], *clf_pca_2[key]]\n    plt.axis([-w, len(label)-1+w, min(y)*0.98, max(y)+3])\n      \n    # display Value\n    for i in index:\n        fs = 12\n        dx = w*5\/6\n        dy = 0.8\n        if key == \"time\" : d =\"s\";\n        else : d = \"%\"\n        plt.text(i-dx, clf_ord_2[key][i]+dy, str(clf_ord_2[key][i])+d,fontsize=fs)\n        plt.text(i-dx+w, clf_pca_2[key][i]+dy, str(clf_pca_2[key][i])+d,fontsize=fs)\n\n    # Displayed x-axis label\n    plt.xticks(index, label, fontsize=14)\n    plt.ylabel(key, fontsize=20)\n    plt.legend(loc=6,fontsize=15)\n    plt.show()","58a4aa57":"train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest  = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\n\nX = train_set.drop('label', axis=1)\ny = train_set['label']","8297b1b8":"def nameof(obj): return [name for name in globals()  if  globals()[name] is obj][0]\n\n\nsave = False\nsave = True\n\nif save : \n    for i in range(len(models)) : \n        models[i].fit(X,y)\n        models[i].predict(test)\n        pd.DataFrame(models[i].predict(test)).to_csv(f\"{nameof(models[i])}.csv\")\nelse : \n    print(\"if you want to stroe result, set save to True\")","46bb7403":"## 4.2. Plot PCA reduced picture","b937e87f":"Calculation takes too long, reduce size of data set","4d40bb9d":"# 4. PCA\n## 4.1. Define custom function","a6fcdf41":"# 3. Report\n## 3.1. Confusion matrix\n\n| | Predicted NO | Predicted Yes|\n|:---:|:---:|:---:|\n|Actual No| TN | FP|\n|Actual Yes | FN |TP|\n\n\n\n$$ Accuracy = {{TP + TN} \\over {TP + TN + FP + FN}}$$\n\n$$Recall = {TP \\over {TP + FN}}$$\n\n$$Precision = {TP \\over {TP + FP}}$$\n\n$$F1 Score = \\frac{2}{\\frac{1}{Recall} +  \\frac{1}{Presision}}$$","86d0cbdc":"## 4.3. Train with PCA reduced data","7899602c":"# 1. import data set","440f301a":"## 3.2. ROC curve\n\n[MNIST ROC](https:\/\/davidburn.github.io\/notebooks\/mnist-numbers\/MNIST%20Handwrititten%20numbers\/)\n- y_pred : prediction by classifier\n- y_prob : The probability that the data will fall into the classification\n- y_true : Check if the classifier made the correct answer \n- y_scores : Confidence of the n value when the correct answer is n\n\n[how to select rows](https:\/\/stackoverflow.com\/questions\/17071871\/how-to-select-rows-from-a-dataframe-based-on-column-values)\n\n- .loc  : Select a subset of DataFarame as conditional statements\n- .iloc : Select value at specific position in DataFrame\n\n```python\nmodel_name = str(models[i].__class__.__name__) \nclf_data.loc[clf_data[\"Name\"] == model_name]\nROC_dataset.loc[ROC_dataset[\"Name\"] == model_name]\n```\n[merging-dataframes](http:\/\/hleecaster.com\/python-pandas-merging-and-concatenating-multiple-dataframes\/)\n```python\npd.merge(clf_data, ROC_dataset, how='outer')\n```","7431c25d":"# 2. Definition\n## 2.1. Define custom functions","4c189f61":"# A Beginner's Classifier Comparison & PCA\n\n\n1. import data set  \n    1.1.split data set  \n\n2. Definition  \n    2.1. Define custom functions  \n    2.2. Define simple classifiers  \n\n3. Report  \n    3.1. Confusion matrix  \n    3.2. ROC curve  \n\n4. PCA  \n    4,1 Define custom function  \n    4.2 Plot PCA reduced picture  \n    4.3 Train with PCA reduced data  \n    4.4 Compare Ordinal and PCA   \n\n5. Save Output  ","d3fe80c9":"## 4.4. Compare Ordinal and PCA ","70f71870":"## 2.2. Define simple classifiers","f6ab3c96":"## 1.1.split data set\n\nSplit the train set into two.  \ntrain set for learning and a validation set for improving accuracy.","459b816e":"# 5. Save Output"}}