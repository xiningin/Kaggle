{"cell_type":{"863657f9":"code","28a6748d":"code","07e5d0bb":"code","eae6375b":"code","37d7859b":"code","5b87d0b0":"code","7b6ace6c":"code","0bf819f7":"code","36bafb88":"code","7d8af022":"code","39018cd5":"code","e0ed4be0":"code","a663eb78":"code","7a696605":"code","6e6b356b":"code","e84d941e":"code","2d5c1fcc":"code","17f7b992":"code","119bfa5f":"code","48ccd51f":"code","156a2b3d":"code","6a765be0":"code","29957fb8":"code","addb1704":"code","98d2b8f7":"code","1cfd4469":"code","ac6d4556":"code","0c9da309":"code","3ca68195":"code","9f8ca665":"code","482b98a3":"code","f10628ec":"code","f15a738c":"code","d6f8678f":"code","d3151f9f":"code","812ff918":"code","b4bca572":"code","27192f40":"code","80d94609":"code","5ed95f41":"code","11664c57":"code","a8d73f5b":"code","14f47d59":"code","908ec8cb":"code","6a04af08":"code","199a3a61":"code","94bfd81c":"code","41d99d07":"code","8315bf65":"code","8e697a5a":"code","eb6aca98":"code","0fef73fd":"code","f4df99d1":"code","0f0718bd":"code","1b87a100":"code","182600b8":"code","15f672fc":"code","485e1f48":"code","fe64cf79":"code","08fd3094":"code","5f0d5608":"code","735faff5":"code","c1c2f569":"code","b66d0ac7":"code","7ea20fe6":"code","e5351c97":"markdown","c3aaf1a6":"markdown","3f7234f6":"markdown","4a320975":"markdown","5cd706be":"markdown","22dca0a8":"markdown","5c23a971":"markdown","f8925e19":"markdown","86263ab2":"markdown","df221ee6":"markdown","d3338215":"markdown","1dc3d3d1":"markdown","fc7e3431":"markdown","ab68b3c7":"markdown","a6dad9e0":"markdown","074bf263":"markdown","7368c04d":"markdown","80a9e251":"markdown","d01e96e2":"markdown","eff1e583":"markdown","03c04401":"markdown","dbfea4f8":"markdown","b74569c7":"markdown","f0a1e2c3":"markdown","815db747":"markdown"},"source":{"863657f9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","28a6748d":"project_name = 'final-project-jovain.ml'","07e5d0bb":"! pip install jovian --upgrade -q","eae6375b":"import torch\nfrom torch.utils.data import TensorDataset, DataLoader, random_split\n\nfrom PIL import Image\nimport pandas as pd\n\nfrom torchvision.transforms import ToTensor\nimport matplotlib.pyplot as plt\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torchvision.utils import make_grid\n\nimport jovian","37d7859b":"data_dir = \"..\/input\/sign-language-mnist\/\"","5b87d0b0":"test_df = pd.read_csv(data_dir+'sign_mnist_test\/sign_mnist_test.csv')\ntrain_df = pd.read_csv(data_dir+'sign_mnist_train\/sign_mnist_train.csv')","7b6ace6c":"def dataframe_to_nparray(train_df, test_df):\n    train_df1 = train_df.copy(deep = True)\n    test_df1 = test_df.copy(deep = True)\n    train_images = train_df1.iloc[:, 1:].to_numpy(dtype = 'float32')\n    test_images = test_df1.iloc[:, 1:].to_numpy(dtype = 'float32')\n    return train_images,test_images","0bf819f7":"train_img, test_img = dataframe_to_nparray(train_df, test_df)\ntrain_labels = train_df['label'].values\ntest_labels = test_df['label'].values","36bafb88":"train_img.size","7d8af022":"train_images_shaped = train_img.reshape(train_img.shape[0],1,28,28)\ntest_images_shaped = test_img.reshape(test_img.shape[0],1,28,28)","39018cd5":"train_images_tensors = torch.from_numpy(train_images_shaped)\ntrain_labels_tensors = torch.from_numpy(train_labels)\n\ntest_images_tensors = torch.from_numpy(test_images_shaped)\ntest_labels_tensors = torch.from_numpy(test_labels)","e0ed4be0":"# pytorch dataset\ntrain_ds_full = TensorDataset(train_images_tensors, train_labels_tensors) #this dataset will further devided into validation dataset and training dataset\ntest_ds = TensorDataset(test_images_tensors, test_labels_tensors)","a663eb78":"img, label = train_ds_full[0]\nprint(img.shape, label)\nimg","7a696605":"# Hyperparmeters\nbatch_size = 64\nlearning_rate = 0.001\n\n# Other constants\nin_channels = 1\ninput_size = in_channels * 28 * 28\nnum_classes = 26\n","6e6b356b":"random_seed = 11\ntorch.manual_seed(random_seed);","e84d941e":"val_size = 7455\ntrain_size = len(train_ds_full) - val_size\n\ntrain_ds, val_ds = random_split(train_ds_full, [train_size, val_size,])\nlen(train_ds), len(val_ds), len(test_ds)","2d5c1fcc":"train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_dl = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\ntest_dl = DataLoader(test_ds, batch_size*2, num_workers=4, pin_memory=True)","17f7b992":"for img, label in train_dl:\n    print(img.size())\n    break","119bfa5f":"class ASLModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear = nn.Linear(input_size, num_classes)\n        \n    def forward(self, xb):\n        xb = xb.reshape(-1, in_channels*28*28)\n        out = self.linear(xb)\n        return out\n    \n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc.detach()}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n    \nmodel = ASLModel()","48ccd51f":"for images, labels in test_dl:\n    outputs = model(images)\n    print(labels)\n    print(accuracy(outputs, labels))\n    \n    break\n\nprint('outputs.shape : ', outputs.shape)\nprint('Sample outputs :\\n', outputs[:2].data)","156a2b3d":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))\n\ndef evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)","6a765be0":"def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        for batch in train_loader:\n            loss = model.training_step(batch)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","29957fb8":"result0 = evaluate(model, val_dl)\nresult0","addb1704":"history1 = fit(10, 0.001, model, train_dl, val_dl)","98d2b8f7":"history2 = fit(10, 0.0001, model, train_dl, val_dl)","1cfd4469":"history3 = fit(10, 0.00001, model, train_dl, val_dl)","ac6d4556":"history4 = fit(10, 0.000001, model, train_dl, val_dl)","0c9da309":"history = [result0] + history1 + history2 + history3 + history4\naccuracies = [result['val_acc'] for result in history]\nplt.plot(accuracies, '-x')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.title('Accuracy vs. No. of epochs');","3ca68195":"history = [result0] + history1 + history2 + history3 + history4\naccuracies = [result['val_loss'] for result in history]\nplt.plot(accuracies, '-x')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.title('Accuracy vs. No. of epochs');","9f8ca665":"# evaluate on test dataset\nresult = evaluate(model, test_dl)\nresult","482b98a3":"def predict_image(img, model):\n    xb = img.unsqueeze(0)\n    yb = model(xb)\n    _, preds  = torch.max(yb, dim=1)\n    return preds[0].item()","f10628ec":"img, label = test_ds[10]\nplt.imshow(img.view(28,28), cmap='gray')\nprint('Label:', label.item(), ', Predicted:', predict_image(img, model))","f15a738c":"img, label = test_ds[200]\nplt.imshow(img.view(28,28), cmap='gray')\nprint('Label:', label.item(), ', Predicted:', predict_image(img, model))","d6f8678f":"img, label = test_ds[1000]\nplt.imshow(img.view(28,28), cmap='gray')\nprint('Label:', label.item(), ', Predicted:', predict_image(img, model))","d3151f9f":"torch.save(model.state_dict(), 'ASL-logistic.pth')","812ff918":"jovian.commit(project= project_name, enviornment= None)","b4bca572":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))","27192f40":"class ASLModel2(nn.Module):\n    \"\"\"Feedfoward neural network with 2 hidden layer\"\"\"\n    def __init__(self, in_size, out_size):\n        super().__init__()\n        # hidden layer 1\n        self.linear1 = nn.Linear(in_size, 512)\n        # hidden layer 2\n        self.linear2 = nn.Linear(512, 256)\n        # hidden layer 3\n        self.linear3 = nn.Linear(256, 128)\n        # output layer  \n        self.linear4 = nn.Linear(128, out_size)\n        \n    def forward(self, xb):\n        # Flatten the image tensors\n        out = xb.view(xb.size(0), -1)\n        # Get intermediate outputs using hidden layer 1\n        out = self.linear1(out)\n        # Apply activation function\n        out = F.relu(out)\n        # Get intermediate outputs using hidden layer 2\n        out = self.linear2(out)\n        # Apply activation function\n        out = F.relu(out)\n        # Get inermediate outputs using hidden layer 3\n        out = self.linear3(out)\n        # Apply a activation function\n        out = F.relu(out)\n        # Get predictions using output layer\n        out = self.linear4(out)\n        return out\n    \n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss, 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))","80d94609":"torch.cuda.is_available()","5ed95f41":"def get_default_device():\n    if torch.cuda.is_available() == True:\n        return torch.device('cuda')\n    else: \n        return torch.device('cpu')","11664c57":"device = get_default_device()\ndevice","a8d73f5b":"def to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","14f47d59":"train_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\ntest_dl = DeviceDataLoader(test_dl, device)","908ec8cb":"print(train_dl.device)\nprint(test_dl.device)\nprint(val_dl.device)","6a04af08":"def evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        for batch in train_loader:\n            loss = model.training_step(batch)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","199a3a61":"input_size, num_classes","94bfd81c":"model = ASLModel2(input_size, out_size = num_classes)","41d99d07":"# for loading our model into GPU\nmodel = to_device(model, device)","8315bf65":"model","8e697a5a":"history = [evaluate(model, val_dl)]\nhistory","eb6aca98":"history += fit(10, .001, model, train_dl, val_dl)","0fef73fd":"history","f4df99d1":"losses = [x['val_loss'] for x in history]\nplt.plot(losses)\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.title('epoch vs loss')","0f0718bd":"acc = [x['val_acc'] for x in history]\nplt.plot(acc)\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.title('epoch vs accuracy')","1b87a100":"result = evaluate(model, test_dl)","182600b8":"result","15f672fc":"def predict_image(img, model):\n    xb = to_device(img.unsqueeze(0), device)\n    yb = model(xb)\n    _, preds  = torch.max(yb, dim=1)\n    return preds[0].item()","485e1f48":"img, label = test_ds[229]\nplt.imshow(img.view(28,28), cmap='gray')\nprint('Label:', label.item(), ', Predicted:', predict_image(img, model))","fe64cf79":"img, label = test_ds[6767]\nplt.imshow(img.view(28,28), cmap='gray')\nprint('Label:', label.item(), ', Predicted:', predict_image(img, model))","08fd3094":"img, label = test_ds[7171]\nplt.imshow(img.view(28,28), cmap='gray')\nprint('Label:', label.item(), ', Predicted:', predict_image(img, model))","5f0d5608":"img, label = test_ds[6762]\nplt.imshow(img.view(28,28), cmap='gray')\nprint('Label:', label.item(), ', Predicted:', predict_image(img, model))","735faff5":"img, label = test_ds[55]\nplt.imshow(img.view(28,28), cmap='gray')\nprint('Label:', label.item(), ', Predicted:', predict_image(img, model))","c1c2f569":"img, label = test_ds[6766]\nplt.imshow(img.view(28,28), cmap='gray')\nprint('Label:', label.item(), ', Predicted:', predict_image(img, model))","b66d0ac7":"torch.save(model.state_dict(), 'ASL-dnn.pth')","7ea20fe6":"jovian.commit(project=project_name, enviornment=True)","e5351c97":"# saving the Model","c3aaf1a6":"# Prediction","3f7234f6":"# Commit and upload the notebook\nAs a final step, we can save and commit our work using the jovian library. Along with the notebook, we can also attach the weights of our trained model, so that we can use it later.","4a320975":"first, I will import some libraries that i will throughout this project","5cd706be":"Next step is to convert all numpy arrays into pytorch tensors","22dca0a8":"# saving the modal","5c23a971":"## Definging the model","f8925e19":"# Logistic regression","86263ab2":"We can see that we converted each image in a 3-dimensions tensor (1, 28, 28). The first dimension is for the number of channels. The second and third dimensions are for the size of the image, in this case, 28px by 28px.","df221ee6":"so initially, this modal has very small accuracy of almost 3% that is vary low.\nso to improve this, we will iterate the process upto some epochs","d3338215":"# Deep Neural Network","1dc3d3d1":"# Using a GPU \nTo work with GPU's we have to take help of some utility functions, so let's define couple utility functions ","fc7e3431":"# Downloading and exploring the data ","ab68b3c7":"# predictions","a6dad9e0":"Now with 40 iteration we went from 4% acc to 94% accuracy.It's quite amazing","074bf263":"# Training and validation dataset \nNow we are going to use three datasets-\n<ol>\n<li>Training set - used to train the model (compute the loss and adjust the weights of the model using gradient descent).<\/li>\n<li>Validation set - used to evaluate the model while training, adjust hyperparameters (learning rate etc.) and pick the best version of the model.<\/li>\n<li>Test set - used to compare different models, or different types of modeling approaches, and report the final accuracy of the model.<\/li>\n    <\/ol>","7368c04d":"# Models for image classification\nWe are going to create three different models for this project:\n\n1. Logistic Regression\n1. Deep Neural Network\n1. Convolutional Neural Network\n","80a9e251":"# Training the Modal","d01e96e2":"# commiting the notebook ","eff1e583":"# **Image classification with sign langauage MNIST using pytorch**\nThis is a part of course project conducted by jovian.ml with freecodecamp. In this project,I have used sign langauage MNIST dataset to predict sign language images using diffrent modals like loginstic regression, feed forword nn, convolution nn.","03c04401":"Now, I have created a helper function to convert all dataframes into numpy array","dbfea4f8":"Now we will define hyperparameters for our modal","b74569c7":"# sign language MNIST dataset\n","f0a1e2c3":"The initial accuracy is around 4%, which is what one might expect from a randomly intialized model (since it has a 1 in 10 chance of getting a label right by guessing randomly). Also note that we are using the .format method with the message string to print only the first four digits after the decimal point.\n\nWe are now ready to train the model. Let's train for 5 epochs and look at the results.","815db747":"Now we will load the training,validation and test dataset in batches "}}