{"cell_type":{"155845a7":"code","66e8ac74":"code","85c83b2e":"code","720ba2a0":"code","0dbd9bb5":"code","cb011304":"code","0077558d":"code","411c021b":"code","fb896e9e":"code","99a41ba3":"code","a07a180f":"code","ede88f44":"code","692bb95e":"code","99ff1e98":"code","0a2a3bbf":"code","c09aaa1e":"code","03c8b187":"code","deb89153":"code","b1125415":"code","155038fc":"code","3db5d31f":"code","9b8c36b7":"code","c24c0e7e":"code","7f3044c9":"code","e2d97a49":"code","1c068fa7":"code","5db4d555":"code","37d3cb03":"code","b17ec418":"code","60cfdad4":"code","a839906d":"code","c7dd3820":"code","b7594528":"code","37562c78":"code","4bfff60b":"code","6da22065":"code","d14fdd90":"code","a28cf453":"code","2c4ffc4e":"code","6b9a46bb":"code","cb267195":"code","e7af57cf":"code","228bdeef":"code","324f2208":"code","3a16213a":"code","e966a8f5":"markdown","caf21fe8":"markdown","71eaade7":"markdown","9b06ad6a":"markdown","5c8a0be3":"markdown","8e5db117":"markdown","32d868cb":"markdown","5a8a05e3":"markdown","112243b6":"markdown","63e889fc":"markdown","3a1b3345":"markdown","a02b2653":"markdown","ae296831":"markdown","f9831d9a":"markdown","9a86c79e":"markdown","164147d5":"markdown","6799ab0b":"markdown","e770740c":"markdown","294cf9ef":"markdown","5fbbb90d":"markdown","83221b6e":"markdown","3331f769":"markdown","2d9e41c3":"markdown","cd5417bc":"markdown","8b3267f7":"markdown","c56e250b":"markdown","1a67f4ad":"markdown","7b6d0a85":"markdown","60635a67":"markdown","24f66304":"markdown","1a61a94c":"markdown","5207ad90":"markdown","a1ac5103":"markdown","60c8b932":"markdown","c90be76f":"markdown","f4686bd7":"markdown","a7b650ee":"markdown","a5331f48":"markdown","f7eb749c":"markdown","3d994536":"markdown","0c65ab41":"markdown","12cedaa4":"markdown","6cfa04be":"markdown","53e2a917":"markdown","ec02afad":"markdown","41c6d437":"markdown","bdf6ae2d":"markdown","4d7b1971":"markdown","02311d32":"markdown","99e8c940":"markdown","fb9703fe":"markdown","a0a3e690":"markdown","63298e14":"markdown","0176b7b8":"markdown","dc149c2d":"markdown","98eedac7":"markdown","79c83ffa":"markdown","ab6da248":"markdown","2b771160":"markdown","2a89a97b":"markdown","905455c4":"markdown","dc4aaa20":"markdown","642a6243":"markdown","6632baa5":"markdown","cbcf103b":"markdown","9d265e07":"markdown","44fe1aa9":"markdown","05d24ee7":"markdown","951e533b":"markdown","03a4cc5a":"markdown","c8573aa4":"markdown","2121202a":"markdown","5fab1910":"markdown","8acf59a0":"markdown"},"source":{"155845a7":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS ","66e8ac74":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","85c83b2e":"train.head()","720ba2a0":"test.head()","0dbd9bb5":"print(train.shape)\nprint(test.shape)","cb011304":"print(train.isnull().sum())\nprint(test.isnull().sum())","0077558d":"dup = train.duplicated().sum()\ndup1 = test.duplicated().sum()\nprint(\"Number of duplicate values in train data : \" + str(dup))\nprint(\"Number of duplicate values in test data : \" + str(dup))","411c021b":"rev = train['Review Title'].count()\nrev1 = test['Review Title'].count()\nprint(\" Total no. of people who gave Review title in train data are \" + str(rev))\nprint(\" Total no. of people who gave Review title in test data are \" + str(rev1))","fb896e9e":"avg = train['Star Rating'].mean()\nAvg = round(avg,1)\nprint(\"Average rating given by users is \" + str(Avg))","99a41ba3":"oldest = train['App Version Name'].min()\nlatest = train['App Version Name'].max()\n\nprint(\"Oldest App Version is \" + str(oldest))\nprint(\"Latest App version is \" + str(latest))\n\ntrain.loc[(train['App Version Name']<2),'App Version'] = 1      #Version1\ntrain.loc[(train['App Version Name']>=2) ,'App Version'] = 2    #Version2","a07a180f":"train.head()","ede88f44":"sns.countplot(\"App Version\", data = train)\nplt.ylabel('Number of Users')\nplt.show()","692bb95e":"sns.countplot(x=\"Star Rating\" ,data=train)\nplt.show()","99ff1e98":"sns.countplot(x=\"Star Rating\", hue = 'App Version', data=train)\nplt.show()","0a2a3bbf":"df = train[['Review Title','Star Rating']]  #Creating a new dataframe with Review title and rating variable\ndf1 = df.dropna()                           #Removing null values\nsns.countplot('Star Rating', data = df1)\nplt.show()","c09aaa1e":"train[\"Review_Length\"]= train[\"Review Text\"].str.len()     #Calculating and storing review's length\ntrain[\"Title_Length\"] = train[\"Review Title\"].str.len()    #Calculating and storing title's review","03c8b187":"sns.distplot(train['Review_Length'].dropna())\nplt.show()","deb89153":"sns.distplot(train['Title_Length'].dropna())\nplt.show()","b1125415":"plt.scatter(train['Review_Length'], train['Star Rating'])\nplt.title('Review_Length vs Star Rating')\nplt.xlabel('Review Length')\nplt.ylabel('Star Rating')\nplt.show()\nprint(\"Review Length to Star Rating Correlation:\",train['Star Rating'].corr(train['Review_Length']))","155038fc":"plt.scatter(train['Title_Length'], train['Star Rating'])\nplt.title('Title_Length vs Star Rating')\nplt.xlabel('Title Length')\nplt.ylabel('Star Rating')\nplt.show()\nprint(\"Title Length to Star Rating Correlation:\",train['Star Rating'].corr(train['Title_Length']))","3db5d31f":"comment_words = ' '\nstopwords = set(STOPWORDS) \n  \n# iterate through the csv file \nfor val in train[\"Review Text\"]: \n      \n    # typecaste each val to string \n    val = str(val) \n  \n    # split the value \n    tokens = val.split() \n      \n    # Converts each token into lowercase \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower() \n          \n    for words in tokens: \n        comment_words = comment_words + words + ' '\n  \n  \nwordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words) \n  \n# plot the WordCloud image                        \nplt.figure(figsize = (9, 9), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n  \nplt.show() \n","9b8c36b7":"comment_words = ' '\nstopwords = set(STOPWORDS) \n  \n# iterate through the csv file \nfor val in test[\"Review Text\"]: \n      \n    # typecaste each val to string \n    val = str(val) \n  \n    # split the value \n    tokens = val.split() \n      \n    # Converts each token into lowercase \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower() \n          \n    for words in tokens: \n        comment_words = comment_words + words + ' '\n  \n  \nwordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words) \n  \n# plot the WordCloud image                        \nplt.figure(figsize = (9, 9), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n  \nplt.show() \n","c24c0e7e":"f = train['Review Title'].dropna() #Extracting coloumn and removing null values from train data.\ng = test['Review Title'].dropna()  #Extracting coloumn and removing null values from test data.","7f3044c9":"comment_words = ' '\nstopwords = set(STOPWORDS) \n  \n# iterate through the csv file \nfor val in f: \n      \n    # typecaste each val to string \n    val = str(val) \n  \n    # split the value \n    tokens = val.split() \n      \n    # Converts each token into lowercase \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower() \n          \n    for words in tokens: \n        comment_words = comment_words + words + ' '\n  \n  \nwordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words) \n  \n# plot the WordCloud image                        \nplt.figure(figsize = (9, 9), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n  \nplt.show() \n","e2d97a49":"comment_words = ' '\nstopwords = set(STOPWORDS) \n  \n# iterate through the csv file \nfor val in g: \n      \n    # typecaste each val to string \n    val = str(val) \n  \n    # split the value \n    tokens = val.split() \n      \n    # Converts each token into lowercase \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower() \n          \n    for words in tokens: \n        comment_words = comment_words + words + ' '\n  \n  \nwordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words) \n  \n# plot the WordCloud image                        \nplt.figure(figsize = (9, 9), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n  \nplt.show() \n","1c068fa7":"import numpy as np\nimport pandas as pd\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\nfrom sklearn.metrics import f1_score, accuracy_score\nfrom sklearn import model_selection, naive_bayes\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport warnings\nwarnings.filterwarnings(\"ignore\")","5db4d555":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","37d3cb03":"train.head()","b17ec418":"df = train[['Review Text', 'Star Rating']]\ndf.head()","60cfdad4":"print(df.isnull().sum())\nprint('---------')\ndf1 = df.dropna()   # Creating new dataframe without null values\nprint(df1.isnull().sum())","a839906d":"df1['Cleaned'] = df1['Review Text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\ndf1.head()","c7dd3820":"df1['Cleaned'] = df1['Cleaned'].str.replace('[^\\w\\s]','')\ndf1.head()","b7594528":"df1['Cleaned'] = df1['Cleaned'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\ndf1.head()","37562c78":"df1['Cleaned'] = df1['Cleaned'].str.replace('\\d+', '')\ndf1.head()","4bfff60b":"lemmatizer = WordNetLemmatizer()\ndf1['Cleaned'] = [lemmatizer.lemmatize(row) for row in df1['Cleaned']]\ndf1.head()","6da22065":"x = df1['Cleaned']       # Independent Variable\ny = df1['Star Rating']   # Dependent Variable","d14fdd90":"train_x, valid_x, train_y, valid_y = model_selection.train_test_split(x,y, random_state = 2)","a28cf453":"# ngram level tf-idf \ntfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,2), max_features=5000)\ntfidf_vect_ngram.fit(x)\nxtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\nxvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)","2c4ffc4e":"nb = naive_bayes.MultinomialNB(alpha = 0.6)\n\nmodel = nb.fit(xtrain_tfidf_ngram, train_y)\n\npred = model.predict(xvalid_tfidf_ngram)\n\nacc = accuracy_score(valid_y,pred)\n\nprint('Accuracy of validation set is :', acc)","6b9a46bb":"score = f1_score(valid_y, pred, average='weighted')\nprint(\"Weighted F score is \",score)","cb267195":"df2 = test[['id','Review Text']]\ndf3 = df2.dropna()              #Removing null values\ndf3.head()","e7af57cf":"#To lower case\ndf3['Cleaned'] = df3['Review Text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n\n#Removing punctuation\ndf3['Cleaned'] = df3['Cleaned'].str.replace('[^\\w\\s]','')\n\n#Removing Stopwords\ndf3['Cleaned'] = df3['Cleaned'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n\n#Removing digits\ndf3['Cleaned'] = df3['Cleaned'].str.replace('\\d+', '')\n\n#Lemmatizing\nlemmatizer = WordNetLemmatizer()\ndf3['Cleaned'] = [lemmatizer.lemmatize(row) for row in df3['Cleaned']]\ndf3.head()","228bdeef":"x1 = df3['Cleaned']","324f2208":"# ngram level tf-idf \ntfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,2), max_features=5000)\ntfidf_vect_ngram.fit(x1)\nxtest_tfidf_ngram =  tfidf_vect_ngram.transform(x1)","3a16213a":"test_pred = model.predict(xtest_tfidf_ngram)\ndf3['Star Rating'] = test_pred\ndf4 = df3[['id','Star Rating']]\ndf4.to_csv(\"predictions.csv\")","e966a8f5":"1. Firstly we will create the length of review, Title and store it into new variable.\n2. Secondly we will analyse the length of review, title and also analyse w.r.t. Star Rating.","caf21fe8":"Since niki has created only 2 versions of app so i have created a new variable with 2 discrete versions which is easy to analyse","71eaade7":"# Importing Necessary Libraries","9b06ad6a":"Finding out what most of the people say in review of training and testing data.\nFor this a little cleaning is done as per follow:\n1. Each review is converted into string.\n2. Each review is broken down into small words.\n3. Each word is converted to lower case.\n4. Removing stopwords with the help of library (stopword example:- not, the, in, etc) and creating a wordcloud","5c8a0be3":"# Test Data","8e5db117":"# Conerting to lower case","32d868cb":"1. Most of the user write Title under 50 words.\n2. We can see that generally users write Title of about 20-25 words.","5a8a05e3":"# Cons in data","112243b6":"# Creating dependent and independent variable","63e889fc":"# Testing Data","3a1b3345":"# Checking App Version and creating new variable of version for analysis.","a02b2653":"It is clearly visible that there are negative as well as positive titles available\nPositive words :- Good, Awesome, Helpful, Nice app etc\n\nNegative words :- Worst, Useless, Fake App etc.\n\nThese negative title can affect new customers and they are large in number so have to do something about this.","ae296831":"# Approach","f9831d9a":"# Importing Dataset","9a86c79e":"# Predicting and merging Values to dataest","164147d5":"# Let's check what is inside the train data","6799ab0b":"# Creating new dataframe with useful variables","e770740c":"# Number of people who have spent their time on writing \"Review Title\"","294cf9ef":"# Building and validating model","5fbbb90d":"Oh... We do have a lot of unsatisfied users who are not loving us. It's time to improve.","83221b6e":"# Checking and removing null values","3331f769":"# Creating independent variable","2d9e41c3":"# Is there any duplicate values?","cd5417bc":"This shows us that if our length of title increases then our star rating will decrease because of negative correlation but not too much like review length","8b3267f7":"# Training Data","c56e250b":"# Importing Dataset","1a67f4ad":"# Number of users based on app version.\n(I AM NOT CONSIDERING THE NAN VALUES NEITHER I AM REMOVING THEM FOR NOW)","7b6d0a85":"# Approach","60635a67":"# Let's check what is inside the test data","24f66304":"# Removing punctuation","1a61a94c":"# Removing Stopwords","5207ad90":"# Cleaning of testing data","a1ac5103":"# Let's figure out how many users give title to their reviews.","60c8b932":"1. It can be easily seen that App version is not available of many users.\n2. And also many users havn't written Title for their review.","c90be76f":"# Splitting data into training and validation","f4686bd7":"# Removing Digits","a7b650ee":"# Checking if there are some missing values or not in train and test data.","a5331f48":"# Title Length Frequency","f7eb749c":"# Weighted F score","3d994536":"# Creating tf-idf vector with ngram","0c65ab41":"# Checking if new variable is added succesfully or not","12cedaa4":"# Haters and lovers based on App Version","6cfa04be":"# Lemmatizing","53e2a917":"1. This worcloud is also somehow similar to training data's wordcloud.\n2. Most of the people are talking about (offer, recharge, payment, good, cashback etc)","ec02afad":"Ahhh.. During App Version 1 niki was having somehow similar number of haters and lovers.\n\nIn App version 2 niki is still having alot of unsatisfied customers. But a slight improvement is there from Version 1","41c6d437":"We have already seen that there are many people who gave 1 star. To confirm it let us create a wordcloud which will also create negative comments.","bdf6ae2d":"# Now it's time to see what users say about niki in their reviews.","4d7b1971":"1. We can clearly see that users who gave 1 star as well as 5 stars always write \"Review Title\".\n2. This can affect our review page alot on website because title fits into eyes of reader first.","02311d32":"# Importing necessary libraries","99e8c940":"# Review Length vs Star Rating","fb9703fe":"# Title Length vs Star Rating","a0a3e690":"Our data is of mixed type so we will try these two things\n1. Firstly we will try to find out some insights using some basic statistics and graphs.\n2. Secondly we will try to create some new meaningful variables for analysis.\n3. At last we wll try to find out some insights using text data by forming wordcloud.","63298e14":"1. The distribution of 'Star Rating' is not equal. (1 and 5 Star are more in number and others are less so it will affect predictions).\n2. Review Titles are not available of all the users.\n3. Some reviews are in native language.\n4. Spelling Mistakes","0176b7b8":"The whole process is divided into 4 parts.\n1. Data Prepration\n2. Feature Engineering\n3. Model Training\n4. Model Evaluation & Testing\n\nFirst of all we will import our data and then we will create a new dataframe with only 2 useful variables i.e. 'Review Text & 'Star Rating'. We will not take 'Review Title' because more than 80% data is not available for that variable. Now we will process data so that it can ingest into ML model. So, firstly we will convert our reviews into lower form then we will remove punctuation then stopwards and then digits. Now we will lemmatize the data which will convert each word into it's root form.\n(eg. studies :- study).\n\nNow we will create a tf - idf vector of each review because machine can only understand numerical data. After that we will ingest this data to Naive Bayes Algorithm for prediction.","dc149c2d":"# Pros in data","98eedac7":"# Creating tf-idf vector with ngram","79c83ffa":"# Testing Data","ab6da248":"1. All the review's are available which are useful in prediction.","2b771160":"# Here we will see how much long review and title users have given. \n# Also we will find it's relation with Star Rating","2a89a97b":"#  Number of Lovers and haters which belongs to niki","905455c4":"This shows us that if our length of review increases then our star rating will decrease because of negative correlation.","dc4aaa20":"App Version 1 was not popular but in version 2 significant number of customers joined niki.","642a6243":"# Data Overview","6632baa5":"1. Most of the people write review under 200 words.\n2. We can see that generally users write review of about 50-100 words.","cbcf103b":"# Checking number of rows and coloumns in train and test data","9d265e07":"It is clearly visible that there are negative as well as positive titles available\nPositive words :- Good, Great, Nice app etc\n\nNegative words :- Worst, Useless, Fake, bakwas etc.\n\nThese negative title can aafect new customers and they are large in number so have to do something about this.","44fe1aa9":"# Let's see the Average Star rating","05d24ee7":"# Exploratory Data Analysis","951e533b":"# Training Data","03a4cc5a":"# Creating data frame with id, review and no null values","c8573aa4":"# Let's figure out what users have written down in the \"Review Title\"","2121202a":"# Rating Prediction using Naive Bayes Algorithm","5fab1910":"# Review Length Frequency","8acf59a0":"According to this worcloud it can be seen that most of the people maybe use it for\n1. recharge\n2. payment\n3. cashbacks\n4. electricity bill etc.\n\nSome good words are used very frequently like:\nNice, Good, awesome which shows that overall experience among the customers is descent."}}