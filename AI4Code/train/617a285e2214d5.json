{"cell_type":{"2d67fc8e":"code","fbe38f42":"code","73eb5414":"code","9ea67cbb":"code","43cdd815":"code","b7733127":"code","bf2000d9":"code","4fee572a":"code","6c63ca0d":"code","295805fe":"code","2786f20e":"code","76ee4fd9":"code","a24cae83":"code","8882f9f1":"code","fd1da7b1":"code","6ec3cd91":"code","b1dd38ef":"code","24174f5e":"code","f1d2762a":"code","b9e9c71b":"markdown","084314df":"markdown","8eba3e9d":"markdown","e6cd94e7":"markdown","1f9b8e32":"markdown","7b6d595a":"markdown","ee338d6b":"markdown","d776e9a3":"markdown","b829b348":"markdown","f54088e4":"markdown","2a63461c":"markdown","c77bef85":"markdown","d5531062":"markdown","ac2fb421":"markdown","fb9403d3":"markdown","1cbc55a6":"markdown","0f1de321":"markdown"},"source":{"2d67fc8e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fbe38f42":"import pickle\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport sys\nsys.path.append(\"..\/tools\/\")\noriginal = \"\/kaggle\/input\/maindata\/final_project_dataset.pkl\"\ndestination = \"final_dataset.pkl\"\n\ncontent = ''\noutsize = 0\nwith open(original, 'rb') as infile:\n    content = infile.read()\nwith open(destination, 'wb') as output:\n    for line in content.splitlines():\n        outsize += len(line) + 1\n        output.write(line + str.encode('\\n'))\n\nenron = pickle.load(open(\"final_dataset.pkl\", \"rb\"))\ndf=pd.DataFrame.from_dict(enron)\ndf=df.transpose()\nprint(df.info())","73eb5414":"df['salary'] = df['salary'].replace(\"NaN\",0)\ndf['salary']=df['salary'].astype(int)\ndf['to_messages'] = df['to_messages'].replace(\"NaN\",0)\ndf['to_messages']=df['to_messages'].astype(int)\ndf['deferral_payments'] = df['deferral_payments'].replace(\"NaN\",0)\ndf['deferral_payments']=df['deferral_payments'].astype(int)\ndf['total_payments'] = df['total_payments'].replace(\"NaN\",0)\ndf['total_payments']=df['total_payments'].astype(int)\ndf['loan_advances'] = df['loan_advances'].replace(\"NaN\",0)\ndf['loan_advances']=df['loan_advances'].astype(int)\ndf['bonus'] = df['bonus'].replace(\"NaN\",0)\ndf['bonus']=df['bonus'].astype(int)\ndf['email_address'] = df['email_address'].replace(\"NaN\",\"\")\ndf['email_address']=df['email_address'].astype(str)\ndf['restricted_stock_deferred'] = df['restricted_stock_deferred'].replace(\"NaN\",0)\ndf['restricted_stock_deferred']=df['restricted_stock_deferred'].astype(int)\ndf['deferred_income'] = df['deferred_income'].replace(\"NaN\",0)\ndf['deferred_income']=df['deferred_income'].astype(int)\ndf['total_stock_value'] = df['total_stock_value'].replace(\"NaN\",0)\ndf['total_stock_value']=df['total_stock_value'].astype(int)\ndf['from_poi_to_this_person'] = df['from_poi_to_this_person'].replace(\"NaN\",0)\ndf['from_poi_to_this_person']=df['from_poi_to_this_person'].astype(int)\ndf['exercised_stock_options'] = df['exercised_stock_options'].replace(\"NaN\",0)\ndf['exercised_stock_options']=df['exercised_stock_options'].astype(int)\ndf['from_messages'] = df['from_messages'].replace(\"NaN\",0)\ndf['from_messages']=df['from_messages'].astype(int)\ndf['other'] = df['other'].replace(\"NaN\",0)\ndf['other']=df['other'].astype(int)\ndf['from_this_person_to_poi'] = df['from_this_person_to_poi'].replace(\"NaN\",0)\ndf['from_this_person_to_poi']=df['from_this_person_to_poi'].astype(int)\ndf['long_term_incentive'] = df['long_term_incentive'].replace(\"NaN\",0)\ndf['long_term_incentive']=df['long_term_incentive'].astype(int)\ndf['shared_receipt_with_poi'] = df['shared_receipt_with_poi'].replace(\"NaN\",0)\ndf['shared_receipt_with_poi']=df['shared_receipt_with_poi'].astype(int)\ndf['restricted_stock'] = df['restricted_stock'].replace(\"NaN\",0)\ndf['restricted_stock']=df['restricted_stock'].astype(int)\ndf['director_fees'] = df['director_fees'].replace(\"NaN\",0)\ndf['director_fees']=df['director_fees'].astype(int)\ndf['expenses'] = df['expenses'].replace(\"NaN\",0)\ndf['expenses']=df['expenses'].astype(int)\ndf['poi'] = df['poi'].replace(\"NaN\",False)\ndf['poi']=df['poi'].astype(bool)\nprint(df.info())","9ea67cbb":"sns.set(rc={'figure.figsize':(15,10)})\ntrace1 = sns.scatterplot(\n    x=df.salary,\n    y=df.bonus,\n    data=df\n)\nfor line in range(0,df.shape[0]):\n     trace1.text(df.salary[line]+0.2, df.bonus[line], df.index[line], horizontalalignment='left', size='large', color='black', weight='semibold')","43cdd815":"df.drop(['TOTAL'], axis = 0, inplace= True)\ntrace2 = sns.scatterplot(\n    x=df.salary,\n    y=df.bonus,\n    data=df,\n    sizes=(2000,20000)\n)\nfor line in range(0,df.shape[0]):\n     trace2.text(df.salary[line]+0.2, df.bonus[line], df.index[line], horizontalalignment='left', size='small', color='black', weight='semibold')","b7733127":"for i in df.index:\n    print(i)\ndf1=df.transpose()\nprint(\"\\n\\nTHE TRAVEL AGENCY IN THE PARK\")\nprint(df1['THE TRAVEL AGENCY IN THE PARK'])\ndf.drop(['THE TRAVEL AGENCY IN THE PARK'], axis = 0, inplace= True)","bf2000d9":"df[\"fraction_from_poi\"] = df[\"from_poi_to_this_person\"].\\\ndivide(df[\"to_messages\"], fill_value = 0)\n\ndf[\"fraction_to_poi\"] = df[\"from_this_person_to_poi\"].\\\ndivide(df[\"from_messages\"], fill_value = 0)\n\ndf[\"fraction_from_poi\"] = df[\"fraction_from_poi\"].fillna(0.0)\ndf[\"fraction_to_poi\"] = df[\"fraction_to_poi\"].fillna(0.0)\n\nprint(df.info())","4fee572a":"ax1 = sns.scatterplot(x=df[\"from_poi_to_this_person\"], y=df[\"from_this_person_to_poi\"],data=df,size=df.index,hue=df.index,sizes=(20,200))","6c63ca0d":"ax2 = sns.scatterplot(x=df[\"fraction_from_poi\"], y=df[\"fraction_to_poi\"],data=df,size=df.index,hue=df.index,sizes=(20,200))","295805fe":"def featureFormat(dictionary, features, remove_NaN=True, remove_all_zeroes=True, remove_any_zeroes=False, sort_keys=False):\n    return_list = []\n    if isinstance(sort_keys, str):\n        import pickle\n        keys = pickle.load(open(sort_keys, \"rb\"))\n    elif sort_keys:\n        keys = sorted(dictionary.keys())\n    else:\n        keys = dictionary.keys()\n\n    for key in keys:\n        tmp_list = []\n        for feature in features:\n            try:\n                dictionary[key][feature]\n            except KeyError:\n                print(\"error: key \", feature, \" not present\")\n                return\n            value = dictionary[key][feature]\n            if value == \"NaN\" and remove_NaN:\n                value = 0\n            tmp_list.append(float(value))\n        append = True\n        if features[0] == 'poi':\n            test_list = tmp_list[1:]\n        else:\n            test_list = tmp_list\n        if remove_all_zeroes:\n            append = False\n            for item in test_list:\n                if item != 0 and item != \"NaN\":\n                    append = True\n                    break\n        if remove_any_zeroes:\n            if 0 in test_list or \"NaN\" in test_list:\n                append = False\n        if append:\n            return_list.append(np.array(tmp_list))\n    return np.array(return_list)\n\n\ndef targetFeatureSplit(data):\n    target = []\n    features = []\n    for item in data:\n        target.append(item[0])\n        features.append(item[1:])\n\n    return target, features\n","2786f20e":"my_dataset = df.to_dict('index')\n\nfrom sklearn.feature_selection import SelectKBest, f_classif\n\nfeatures_list = [\"poi\", \"bonus\", \"exercised_stock_options\", \"expenses\", \"other\", \"restricted_stock\", \"salary\", \n                  \"shared_receipt_with_poi\", \"total_payments\", \"total_stock_value\", \"fraction_to_poi\",\n                 \"fraction_from_poi\",\"loan_advances\",\"long_term_incentive\"]\n\ndata = featureFormat(my_dataset, features_list, sort_keys = True)\nlabels, features = targetFeatureSplit(data)\n\n# Perform feature selection\nselector = SelectKBest(f_classif, k=5)\nselector.fit(features, labels)\n\n# Get the raw p-values for each feature, and transform from p-values into scores\nscores = -np.log10(selector.pvalues_)\n\nax = sns.barplot(x=features_list[1:], y=scores)\nax.set_xticklabels(ax.get_xticklabels(), rotation=90, horizontalalignment='right')","76ee4fd9":"from sklearn.preprocessing import MinMaxScaler\nX = df.drop(columns = [\"poi\", \"to_messages\", \"email_address\"])\ntemp = df.drop(columns = [\"poi\", \"to_messages\", \"email_address\"])\ny = df[\"poi\"]\nscaler = MinMaxScaler()\nX =  scaler.fit_transform(X)\nX = pd.DataFrame(X)\nX.columns = temp.columns\ny = y.reset_index()\ny = y.drop(columns = \"index\")\nX = pd.concat([X, y], axis = 1)\ndf = X","a24cae83":"from sklearn.model_selection import train_test_split\nscaler = MinMaxScaler()\ny = df[\"poi\"]\nX = df[[\"bonus\",\"exercised_stock_options\",\"salary\",\"total_stock_value\",\"fraction_to_poi\",\"long_term_incentive\"]]\nfeatures_list=[\"bonus\",\"exercised_stock_options\",\"salary\",\"total_stock_value\",\"fraction_to_poi\",\"long_term_incentive\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=1)\nprint(len(y_test))","8882f9f1":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nclf = RandomForestClassifier()\npred = clf.fit(X_train, y_train).predict(X_test)\nacc=accuracy_score(pred,y_test)\nprint(\"Random Forest Classifier\",acc)","fd1da7b1":"from sklearn.ensemble import AdaBoostClassifier\nclf = AdaBoostClassifier()\nclf.fit(X_train, y_train)\npred=clf.predict(X_test)\nacc=accuracy_score(pred,y_test)\nprint(\"AdaBoost\",acc)","6ec3cd91":"from sklearn.naive_bayes import GaussianNB\nclf=GaussianNB()\nclf.fit(X_train, y_train)\npred=clf.predict(X_test)\nacc=accuracy_score(pred,y_test)\nprint(\"G NB\",acc)","b1dd38ef":"from sklearn.tree import DecisionTreeClassifier\nclf1 = DecisionTreeClassifier()\nclf1.fit(X_train, y_train)\npred1=clf1.predict(X_test)\nacc=accuracy_score(pred1,y_test)\nprint(\"Decision Tree\",acc)","24174f5e":"from sklearn.neighbors import KNeighborsClassifier\nclf2=KNeighborsClassifier(n_neighbors=6)\nclf2.fit(X_train, y_train)\npred2=clf.predict(X_test)\nacc=accuracy_score(pred2,y_test)\nprint(\"KNN\",acc)","f1d2762a":"import pickle\npickle.dump(clf1, open(\"my_classifier.pkl\", \"wb\") )\npickle.dump(pred1, open(\"my_dataset.pkl\", \"wb\") )\npickle.dump(features_list, open(\"my_feature_list.pkl\", \"wb\") )","b9e9c71b":"**Identifying the outlier with graph using indexes as labels. Here TOTAL is as outlier**","084314df":"**Below two plots show the difference of feature engineering**","8eba3e9d":"**Using Random Forest Classifier**","e6cd94e7":"**Just to check whether there is any other index like TOTAL which is not a NAME**","1f9b8e32":"**Taking Dataset as input unpickling .pkl file**","7b6d595a":"**USING existing featues to generate new featues**","ee338d6b":"**Converting output to pickle file format**","d776e9a3":"**Using only required featues and dropping all unneccessary featues & Splitting the features using train_test_split**","b829b348":"**Performing Feature selection to find out which features stand out and can be used in classifier for best accuracy**","f54088e4":"**Converting columns of object datatypes to respective datatypes**","2a63461c":"**Using Decision Tree Classifier**","c77bef85":"**Apply Feature scaling using MinMaxScaler to all features**","d5531062":"**Removing TOTAL being an outlier and plotting the rest**","ac2fb421":"**FOUND one as THE TRAVEL AGENCY IN THE PARK**","fb9403d3":"**Using KNN classifier**","1cbc55a6":"**Using AdaBoost Classifier**","0f1de321":"**Using Gaussian Naive Bayes Classifier**"}}