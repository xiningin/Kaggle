{"cell_type":{"bb94436d":"code","63b24cf0":"code","f9d94443":"code","43df5847":"code","d793d29f":"code","e76eee76":"code","3ac4d2ef":"code","e6ce8bec":"code","33da2f9b":"code","9475c96d":"code","6f22b3e6":"code","7d556767":"code","78cfa46f":"code","5b7f615f":"code","1cc78a54":"code","977d85a4":"code","1f3b3b59":"code","6b7caa9f":"code","224e2e6f":"code","1287b008":"code","78f90bbf":"code","6478c5cf":"code","4f46e6ee":"code","4aeea7f4":"code","496a7204":"code","0d45ad6a":"code","9ddb839e":"code","cc333e26":"code","bbbb341a":"code","85f2cd7a":"code","56cd0ba7":"code","044f6c46":"code","3f0bb6d3":"code","14dc4f38":"code","d62567fc":"code","96f95a1a":"code","85acd0ae":"code","207d8fae":"code","0def7a63":"code","bf6b5c4a":"code","e1e2c295":"code","6a6a5ef4":"code","41c61061":"code","13ae283d":"code","3c5d5fac":"markdown","742e5ae3":"markdown","1ce119fa":"markdown","f39e3b67":"markdown","6b7cbb45":"markdown","908e19b7":"markdown","63bd0148":"markdown","26a398ab":"markdown","c7db64c6":"markdown","a7423930":"markdown","002603c2":"markdown","4a71581b":"markdown","29629c97":"markdown","9ec928d7":"markdown","9f36a5f7":"markdown","12d61128":"markdown","6eb4672d":"markdown","cd7b49d6":"markdown","5f743559":"markdown","36b3c960":"markdown","19c0adbe":"markdown","b3e6d730":"markdown","b94dfe2b":"markdown"},"source":{"bb94436d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing\nimport statsmodels.api as smt\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler\nimport torch\nimport torch.nn as nn\nimport warnings\nimport random\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")","63b24cf0":"# Import train and test data\nraw_train_data = pd.read_csv('UnemploymentRate_InSample.csv')\nraw_test_data = pd.read_csv('UmemploymentRate_OutofSample.csv')\nraw_train_data.head()","f9d94443":"raw_test_data.head()","43df5847":"# Check for missing values\nprint(raw_train_data.isna().sum())\nprint(raw_test_data.isna().sum())","d793d29f":"# Convert to index column\nraw_train_data['Date'] = pd.to_datetime(raw_train_data['Date'], format = '%b-%y')\ntrain = raw_train_data.set_index('Date')\n\nraw_test_data['Date'] = pd.to_datetime(raw_test_data['Date'], format = '%b-%y')\ntest = raw_test_data.set_index('Date')\n\ntrain.head()","e76eee76":"test.head()","3ac4d2ef":"# Whole visualization\nmean = np.mean(train['Unemployment_Rate'])\nplt.figure(figsize=(15,6))\nplt.plot(train.index, train['Unemployment_Rate'], label='Unemployment Rate')\nplt.axhline(y=mean, color='r', linestyle='-', label='Average Unemployment Rate')\nplt.title(\"1978-2017 Unemployment Rate\")\nplt.xlabel(\"Year\")\nplt.ylabel(\"Unemployment Rate%\")\nplt.legend()\nplt.show()","e6ce8bec":"# Discovered Seasonality from each Dec to Feb the rate will be high. Use Holt Winters.\nplt.figure(figsize=(12,4))\nplt.plot(train.index[0:50], train['Unemployment_Rate'][0:50])\nplt.title(\"Discover Seasonality\")\nplt.xlabel(\"Year\")\nplt.ylabel(\"Unemployment Rate%\")\nplt.show()","33da2f9b":"# Distribution of the rate\nplt.figure(figsize=(12,4))\nplt.hist(train['Unemployment_Rate'], bins=20, density=True)\nplt.title(\"Unemployment Rate Distribution\")\nplt.xlabel(\"Unemployment Rate%\")\nplt.ylabel(\"Density\")\nplt.show()","9475c96d":"# Create average annual plot\nur_data = train['Unemployment_Rate'].values\ny_data = train.index.values\nfirst_ur = ur_data[0:11]\nfirst_y = y_data[0:11]\n\nav_ur = [float(sum(first_ur)\/12)]\nfor i in range(0,39):\n        max_u = ur_data[11:][i*12:(i*12)+12]\n        av_ur.append(float(float((sum(list(max_u))))\/12))\n\nyear = []\nfor i in range(1978,2018):\n    year.append(i)\n\n# Plot with bar chart\nplt.figure(figsize=(12,4))\nplt.bar(year,av_ur)\nplt.title('Average annual unemployment rate' )\nplt.xlabel(\"Year\")\nplt.ylabel(\"Unemployment Rate%\")\nplt.show()","6f22b3e6":"# Numerical stats\ntrain.describe()","7d556767":"# Boxplot\nfig = px.box(train, y=\"Unemployment_Rate\")\nfig.show()","78cfa46f":"# Initialize seed function\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True","5b7f615f":"seed_everything(0)\n# Normalization\ntrain_nn = train.copy()\nscaler = MinMaxScaler(feature_range=(-1, 1))\ntrain_nn['Unemployment_Rate'] = scaler.fit_transform(train_nn['Unemployment_Rate'].values.reshape(-1, 1))\ntrain_nn.head()","1cc78a54":"lt1 = train.ewm(alpha=0.1, adjust=False).mean()\nlt2 = train.ewm(alpha=0.3, adjust=False).mean()\nlt3 = train.ewm(alpha=0.5, adjust=False).mean()\nlt4 = train.ewm(alpha=0.7, adjust=False).mean()","977d85a4":"# Not work well\nplt.figure(figsize=(20,8))\nplt.plot(train.index, train['Unemployment_Rate'], label='Original data')\nplt.plot(lt1, label = \"Alpha = 0.1\")\nplt.plot(lt2, label = \"Alpha = 0.3\")\nplt.plot(lt3, label = \"Alpha = 0.5\")\nplt.plot(lt4, label = \"Alpha = 0.7\")\nplt.title(\"Unemployement Rate with SES\")\nplt.xlabel(\"Year\")\nplt.ylabel(\"Unemployment Rate%\")\nplt.legend()\nplt.show()","1f3b3b59":"hw_add = ExponentialSmoothing(train['Unemployment_Rate'], seasonal_periods=12, trend='add', seasonal='add').fit() # Holt-Winters additive smoothing\nhw_mul = ExponentialSmoothing(train['Unemployment_Rate'], seasonal_periods=12, trend='add', seasonal='mul').fit() # Holt-Winters multiplicative smoothing","6b7caa9f":"# Check performance\nresults = pd.DataFrame(index=[r\"$\\alpha$\",\\\n                              r\"$\\beta$\",\\\n                              r\"$\\gamma$\",\\\n                              r\"$l_0$\",\\\n                              \"$b_0$\",\\\n                              \"SSE\"])\n\nparams = ['smoothing_level', \\\n          'smoothing_trend', \\\n          'smoothing_seasonal', \\\n          'initial_level', \\\n          'initial_trend']\n\nresults[\"Additive\"]       = [hw_add.params[p] for p in params] + [hw_add.sse]\nresults[\"Multiplicative\"] = [hw_mul.params[p] for p in params] + [hw_mul.sse]\nprint(results)","224e2e6f":"# Obtain fitted values\nsmooth_add = hw_add.fittedvalues\nsmooth_mul = hw_mul.fittedvalues\n\n# Visualization\nplt.figure(figsize=(15,6))\nplt.plot(train['Unemployment_Rate'][1:], 'b-', label = 'Original data')\nplt.plot(smooth_add, 'g--.',label = 'Holt-Winters additivie')\nplt.plot(smooth_mul, 'r--', label = 'Holt-Winters multiplicative')\nplt.xlabel(\"Year\")\nplt.ylabel(\"Unemployment Rate%\")\nplt.title(\"Holt-Winters' methods\")\nplt.legend()\nplt.show()","1287b008":"y_forecast_add = hw_add.forecast(24)\ny_forecast_mul = hw_mul.forecast(24)\n\n# Visualization for forecasts\nplt.figure(figsize=(16,5))\nplt.plot(test.index, y_forecast_add.values, label = 'Holt-Winters additive')\nplt.plot(test.index, y_forecast_mul.values, label = 'Holt-Winters multiplicative')\nplt.plot(test.index, test['Unemployment_Rate'], label = 'Test data')\nplt.xlabel(\"Month\")\nplt.ylabel(\"Unemployment Rate%\")\nplt.title(\" Forecasts from Holt-Winters'methods\")\nplt.legend()\nplt.show()","78f90bbf":"# Plot all\nplt.figure(figsize=(15,6))\nplt.plot(train['Unemployment_Rate'][1:], 'b-', label = 'Original data')\nplt.plot(train.index, smooth_add, 'r-.',label = 'Holt-Winters additivie smoothing')\nplt.plot(train.index, smooth_mul, 'g--', label = 'Holt-Winters multiplicative smoothing')\nplt.plot(test.index, y_forecast_add.values, label = 'Holt-Winters additive forecasts')\nplt.plot(test.index, y_forecast_mul.values, label = 'Holt-Winters multiplicative forecasts')\nplt.plot(test.index, test['Unemployment_Rate'], label = 'Test data')\nplt.xlabel(\"Year\")\nplt.ylabel(\"Unemployment Rate%\")\nplt.title(\"Holt-Winters' methods\")\nplt.legend()\nplt.show()","6478c5cf":"# RMSE\nrms_mul = mean_squared_error(test['Unemployment_Rate'], y_forecast_mul, squared=False)\nrms_add = mean_squared_error(test['Unemployment_Rate'], y_forecast_add, squared=False)\nprint('Multiplicative Holt-Winters RMSE: %.4f' %rms_mul)\nprint('Additive Holt-Winters RMSE: %.4f' %rms_add)","4f46e6ee":"# Extract monthly unemployment rate\nur_in = train['Unemployment_Rate']\nur_out = test['Unemployment_Rate']","4aeea7f4":"#plot the ACF for the in-sample data\n##lags:number of time laggings #alpha:95% CI\nsmt.graphics.tsa.plot_acf(ur_in, lags=30, alpha = 0.05)\nplt.show()\n##non-stationary mean","496a7204":"#plot the sample PACF for the in-sample data\nsmt.graphics.tsa.plot_pacf(ur_in, lags=30, alpha = 0.05)\nplt.show()","0d45ad6a":"#do the first order differencing (d=1)\nur_diff = pd.Series.diff(ur_in)\n\n#checking the first entry in diff_data\nur_diff.iloc[0]","9ddb839e":"#remove the NaN and plot the data\n\n##discard the nan value\nur_diff = ur_diff.dropna()\n\n#plot the differenced in-sample data\nplt.figure(figsize=(15,6))\nplt.plot(ur_diff)\nplt.xlabel('Time')\nplt.title('Monthly Unemployment Rate Differencing')\nplt.show()\n##stable mean","cc333e26":"#plot the ACF for this differenced in-sample data\n##lags:number of time laggings #alpha:95% CI\nsmt.graphics.tsa.plot_acf(ur_diff, lags=30, alpha = 0.05)\nplt.show()\n##sharply cut-off after lag 1 \n##p\n##show seasonal patterns (autocorrelation) at lag=12, 24,etc.","bbbb341a":"#plot the PACF for the differenced data\nsmt.graphics.tsa.plot_pacf(ur_diff, lags=30, alpha = 0.05)\nplt.show()\n##q","85f2cd7a":"ini_sarima = SARIMAX(ur_in, order=(2,1,2),seasonal_order=(0,1,1,12),\n                     enforce_stationarity=False,\n                    enforce_invertibility=False)\nini_sarima_fit = ini_sarima.fit()","56cd0ba7":"print(ini_sarima_fit.summary())","044f6c46":"#obtain the residuals of this model\nresults_AR = ini_sarima.fit(disp=-1) ## Get Fitted Series & Plotfit(disp=-1)\nresiduals = pd.DataFrame(results_AR.resid)\n\n# Plot residual and calculate sum of squared residual (SSR)\nplt.figure(figsize=(15,6))\nplt.plot(residuals)\nplt.title('SARIMA (2,1,2) x (0,1,1)12 Residual plot- SSR: %.4f'% sum((results_AR.resid)**2))\nplt.show()\n\n# Get Fitted Series\nfitted = results_AR.predict(typ = 'levels', dynamic = False)\n\n# Actual vs Fitted\n#results_AR.plot_predict(dynamic=False)\nplt.figure(figsize=(15,6))\nplt.plot(ur_in,label='Actual Unemployment Rate')\nplt.plot(fitted,label='Fitted Unemployment Rate')\nplt.title(\"SARIMA (2,1,2) x (0,1,1)12 Model Actual vs Fitted values\")\nplt.legend(loc=2)\nplt.show()","3f0bb6d3":"\nmodel = SARIMAX(train['Unemployment_Rate'].iloc[0:480], order=(0,1,1), seasonal_order=(0,1,1,7),enforce_stationarity=False,\n                    enforce_invertibility=False).fit(disp = -1)\nres = model.resid\n##fig, ax = plt.subplots(2,1)\n\n\nfig = smt.graphics.tsa.plot_acf(res, lags=30)\n#plt.figure(figsize=(20,6))\nplt.show()\nfig = smt.graphics.tsa.plot_pacf(res, lags=30)\n#plt.figure(figsize=(20,6))\nplt.show()\n","14dc4f38":"#Grid Search\n\nb = [(0, 0, 0),\n(0, 0, 1),\n(2,1,2),\n(0, 1, 0),\n(0, 1, 1),\n(0, 2, 0),\n(0, 2, 1),\n(1, 0, 0),\n(1, 1, 0),\n(1, 1, 1),\n(1, 2, 0),\n(2, 1, 0),\n(2, 1, 1),\n(2, 2, 0),\n(4, 1, 0),\n(4, 1, 1),\n(4, 2, 0),\n(4, 2, 1),\n(6, 1, 0),\n(6, 2, 0),\n(8, 0, 0),\n(8, 1, 0),\n(4,1,3)]\n\n\nc = [(0,0,1),(0,1,1),(1,0,1),(1,0,0),(1,1,0),(0,0,1),(0,0,0),(1,1,1)]\n\nin_test = train.iloc[-24:,:]","d62567fc":"#SARIMA \nans = []\nfor tu in b:\n    for tuc in c:\n        i,j,k = tu\n        x,y,z = tuc\n        model=SARIMAX(train['Unemployment_Rate'].iloc[0:455].dropna(),order=(i,j,k),seasonal_order=(x,y,z,12),\n                     enforce_stationarity=False,\n                    enforce_invertibility=False).fit(disp=-1)\n\n        pred = model.forecast(steps = 24).values\n    \n        pred_list = pred\n        real_list = in_test.values\n        mse = 0\n        for q in range(24):\n            mse+= (pred_list[q]-real_list[q][-1])**2\n        ans.append([(mse\/24)**0.5,i,j,k,x,y,z])\nfor q in ans:\n    print('The paremeter is'+ ' ( '+str(q[-6])+', '+str(q[-5])+', '+str(q[-4])+', '+str(q[-3])+', '+str(q[-2])+', '+str(q[-1])+' ), The RMSE is '+\"%.4f\" % q[0])\nq = sorted(ans,key = lambda x:x[0])[0]\nprint('The BEST paremeter is'+ ' ( '+str(q[-6])+', '+str(q[-5])+', '+str(q[-4])+', '+str(q[-3])+', '+str(q[-2])+', '+str(q[-1])+' ), The RMSE is '+\"%.4f\" % q[0])\ni,j,k,x,y,z = q[1:]\n","96f95a1a":"model=SARIMAX(train['Unemployment_Rate'].iloc[0:480].dropna(),order=(i,j,k),seasonal_order=(x,y,z,12),\n                     enforce_stationarity=False,\n                    enforce_invertibility=False).fit(disp=-1)\n\n\npred = model.forecast(steps = 24).values\npred_list = pred\nreal_list = test.values\nmse = 0\nfor q in range(24):\n    mse+= (pred_list[q]-real_list[q][-1])**2  \nq = [(mse\/24)**0.5,i,j,k,x,y,z]\n\n\nprint('The model is SARIMA'+  ' ( '+str(q[-6])+', '+str(q[-5])+', '+str(q[-4])+' ) x ( '+str(q[-3])+', '+str(q[-2])+', '+str(q[-1])+' )12 , The RMSE is '+ \"%.4f\" % q[0])\n\ndf = pd.concat([test,model.forecast(steps = 24)],axis = 1)\ndf.columns = ['real','predict']\n\nreal_list = test.values   \nfig=plt.figure(figsize=(15,6))\nax=fig.add_subplot(111)\nax.plot(df['real'],label='Actual Unemployment Rate')\nax.plot(df['predict'],label='Predicted Unemployment Rate')\nplt.title(\"Actual Unemployment Rate vs Predicted Unemployment Rate (SARIMA)\")\nplt.xlabel('Time')\nplt.ylabel('Unemployment Rate (%)')\nplt.legend(loc='upper right')\n\n####### GOOD!!!!!!!!!!!!!!!!!!!!!","85acd0ae":"#print the best forecasting results vs the testing (true) values\ndf['predict'] = round(df['predict'], 4)\ndf","207d8fae":"train_window = 12\ntrain_data_normalized = torch.FloatTensor(train_nn['Unemployment_Rate']).view(-1)\n\ndef create_inout_sequences(input_data, tw):\n    inout_seq = []\n    L = len(input_data)\n    for i in range(L-tw):\n        train_seq = input_data[i:i+tw]\n        train_label = input_data[i+tw:i+tw+1]\n        inout_seq.append((train_seq ,train_label))\n    return inout_seq\n\ntrain_inout_seq = create_inout_sequences(train_data_normalized, train_window)\ntrain_inout_seq[:5]","0def7a63":"seed_everything(0)\nclass LSTM(nn.Module):\n    def __init__(self, input_size=1, hidden_layer_size=128, output_size=1):\n        super().__init__()\n        self.hidden_layer_size = hidden_layer_size\n\n        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n\n        self.linear = nn.Linear(hidden_layer_size, output_size)\n\n        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n                            torch.zeros(1,1,self.hidden_layer_size))\n\n    def forward(self, input_seq):\n        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n        pred = self.linear(lstm_out.view(len(input_seq), -1))\n        return pred[-1]\n    \n    \nmodel = LSTM()\ncriterion = nn.SmoothL1Loss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n\nloss_li = []\nrmse_li = []\nepochs = 150\nfor i in range(epochs):\n    \n    model.train()\n    for seq, labels in train_inout_seq:\n        optimizer.zero_grad()\n        model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n                        torch.zeros(1, 1, model.hidden_layer_size))\n\n        y_pred = model(seq)\n        loss = criterion(y_pred, labels)\n        loss.backward()\n        optimizer.step()\n        \n    loss_li.append(round(loss.item(), 4))\n    \n    if i%30 == 0:\n        print(f'epoch: {i:3} loss: {loss.item():10.4f}')\n    \n    model.eval()\n    forecast_li = []\n    forecast_step = 24\n    forecast_inputs = train_data_normalized[-train_window:].tolist()\n    \n    for i in range(forecast_step):\n        seq = torch.FloatTensor(forecast_inputs[-12:])\n        with torch.no_grad():\n            model.hidden = (torch.zeros(1, 1, model.hidden_layer_size),\n                            torch.zeros(1, 1, model.hidden_layer_size))\n            forecast_li.append(model(seq).item())\n\n    reversed_forecast = scaler.inverse_transform(np.array(forecast_li).reshape(-1, 1))\n    error = round(mean_squared_error(test['Unemployment_Rate'].values, reversed_forecast, squared=False), 4)\n    rmse_li.append(error)\n\nprint(f'epoch: {150} loss: {loss.item():10.4f}')","bf6b5c4a":"rmse_lstm = mean_squared_error(test['Unemployment_Rate'].values, reversed_forecast, squared=False)\nprint(\"RMSE: \" + \"%.4f\" % rmse_lstm)","e1e2c295":"# Forecasts vs Tests\nplt.figure(figsize=(16,5))\nplt.plot(test.index, reversed_forecast, label = 'LSTM Forecasts')\nplt.plot(test.index, test['Unemployment_Rate'], label = 'Test data')\nplt.xlabel(\"Month\")\nplt.ylabel(\"Unemployment Rate%\")\nplt.title(\" Frecasts vs Tests\")\nplt.legend()\nplt.show()","6a6a5ef4":"# RMSE\nplt.figure(figsize=(16,5))\nplt.plot(range(1, 151), rmse_li, label = 'RMSE')\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"RMSE\")\nplt.title(\"RMSE\")\nplt.legend()\nplt.show()","41c61061":"plt.figure(figsize=(16,5))\nplt.plot(range(1, 151), loss_li, label = 'Loss')\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.title(\"Loss\")\nplt.legend()\nplt.show()","13ae283d":"# SARIMA is the best model\nprint(\"Final Comparison: \")\nprint('Multiplicative Holt-Winters RMSE: %.4f' %rms_mul)\nprint('SARIMA RMSE: %.4f' % q[0])\nprint(\"LSTM RMSE: %.4f\" % rmse_lstm)","3c5d5fac":"## Modelling & Predicting","742e5ae3":"# Data Pre-processing & EDA","1ce119fa":"## Visualization","f39e3b67":"## Set Seed & Normalization","6b7cbb45":"## Check Missing Values","908e19b7":"## RMSE","63bd0148":"## Visualization","26a398ab":"# Import Packages","c7db64c6":"# LSTM","a7423930":"## Get the summary of this fitted model","002603c2":"## Assessing the Stationarity of the Original Data","4a71581b":"## Convert Datetime Index","29629c97":"## Genereate Input & Output","9ec928d7":"## Train Model","9f36a5f7":"## Data Transformation & Initial Order Selection","12d61128":"## Get Fitted Series & Plot","6eb4672d":"## Create an SARIMA  (2,1,2) x (0,1,1)12 model","cd7b49d6":"# ARIMA","5f743559":"## RMSE","36b3c960":"## Visualization","19c0adbe":"## SES with Different Alphas","b3e6d730":"## Additive & Multiplicative HW","b94dfe2b":"# Holt-Winters' Methods"}}