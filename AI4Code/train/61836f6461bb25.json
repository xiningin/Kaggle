{"cell_type":{"0360751f":"code","514d41eb":"code","cd28051b":"code","846416be":"code","eff63aa8":"code","99c01c44":"code","4971e4ac":"code","62382450":"code","dcd7a206":"code","7cb7a448":"code","28a2e7fb":"code","59d668db":"code","300f2d1a":"code","5c649bd4":"code","bcb24aaa":"code","25dca8da":"code","557bdb1f":"code","a19d2b30":"code","38baa5d0":"code","f62d7fb3":"code","c66baaf3":"code","9929e040":"code","87771d06":"code","91075ee9":"code","15f6862c":"code","24b1a26e":"code","d80142a0":"code","ececa6b5":"code","f69a4c2b":"code","fa696fea":"code","21ba9d30":"code","d4c12b75":"code","c7b43bf1":"code","d79b1d49":"code","f3f97a07":"code","baba8bd0":"code","ac79a120":"code","cac062a3":"code","ec18435a":"code","fbb2bd2e":"code","416a1d43":"code","ef18253c":"code","9a0051e0":"markdown","903c8d95":"markdown","a50159f8":"markdown","2d744f75":"markdown","4a5601db":"markdown","34d11cb9":"markdown","27285c23":"markdown","d860c725":"markdown","e44e8a5f":"markdown","d66ae70b":"markdown","e6693668":"markdown","99c1e44f":"markdown","e6ba9575":"markdown","f95582fe":"markdown","d61e4f71":"markdown","5c8c9b35":"markdown","f20fd542":"markdown"},"source":{"0360751f":"# numpy, pandas, matplot seaborn import \ud558\uae30\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\n\n# matplot \uc2a4\ud0c0\uc77c\uacfc \ud3f0\ud2b8 \uc124\uc815\nplt.style.use('seaborn')\nsns.set(font_scale=2.5)\n\n# matmplot\uc744 \uc0c8\ucc3d\uc774 \uc544\ub2cc \ud604\uc7ac \ub178\ud2b8\ubd81\uc5d0 print \n%matplotlib inline\n\n# \ub370\uc774\ud130\uc14b\uc758 null data\ub97c \uc27d\uac8c \ubcf4\uc5ec\uc8fc\ub294 \ub77c\uc774\ube0c\ub7ec\ub9ac \nimport missingno as msno\n\n# warnings \uc2a4\ud0b5 \uc124\uc815\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n# For ordinal encoding categorical variables, splitting data\nfrom sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n\n# For training random forest model\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import KFold\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","514d41eb":"# \ub370\uc774\ud130 \uc784\ud3ec\ud2b8 \n\ndf_train = pd.read_csv(\"..\/input\/30-days-of-ml\/train.csv\", low_memory=False)\ndf_test = pd.read_csv(\"..\/input\/30-days-of-ml\/test.csv\", low_memory=False)","cd28051b":"# train\ub370\uc774\ud130 info \ud655\uc778\ndf_train.info(memory_usage=\"deep\")","846416be":"# test\ub370\uc774\ud130 info \ud655\uc778\ndf_test.info(memory_usage=\"deep\")","eff63aa8":"# train \ub370\uc774\ud130 \uc0c1\uc704 5\uac1c \ud655\uc778\ndf_train.head()","99c01c44":"# test \ub370\uc774\ud130 \uc0c1\uc704 5\uac1c \ud655\uc778\ndf_test.head()","4971e4ac":"# df_train \ucc28\uc6d0 \ud655\uc778\ndf_train.shape","62382450":"# df_test \ucc28\uc6d0 \ud655\uc778\ndf_test.shape","dcd7a206":"# train data \uac01 \uc5f4\uc5d0 null\ub370\uc774\ud130\uac00 \uba87 \uac1c\uc788\ub294\uc9c0 \ud655\uc778\ud558\uace0 \ud37c\uc13c\ud2b8\ub85c \ud655\uc778\n\nfor col in df_train.columns:\n    msg = 'column: {:>10}\\t Percent of NaN value: {:.2f}%'.format(col, 100 * (df_train[col].isnull().sum() \/ df_train[col].shape[0]))\n    print(msg)","7cb7a448":"# test data \uac01 \uc5f4\uc5d0 null\ub370\uc774\ud130\uac00 \uba87 \uac1c\uc788\ub294\uc9c0 \ud655\uc778\ud558\uace0 \ud37c\uc13c\ud2b8\ub85c \ud655\uc778\n\nfor col in df_test.columns:\n    msg = 'column: {:>10}\\t Percent of NaN value: {:.2f}%'.format(col, 100 * (df_test[col].isnull().sum() \/ df_test[col].shape[0]))\n    print(msg)","28a2e7fb":"# msno(missing no) \ub77c\ub294 \ub77c\uc774\ube0c\ub7ec\ub9ac\ub85c matrix\ub97c \uc0dd\uc131\n# iloc = indexing location \uc774\ub77c\ub294 \ub73b\n# [:, :]\uc740 \ucc98\uc74c coulumn\ubd80\ud130 \ub9c8\uc9c0\ub9c9 column\uae4c\uc9c0 \uc989 \uc804\uccb4\n# color\ub294 rgb\ub85c 0~1\uac12\n# matrix\ub294 \uc5b4\ub290\uc704\uce58\uc5d0 null data\uac00 \ubd84\ud3ec\ud558\ub294\uc9c0 \uc54c\uae30 \uc26c\uc6c0\nmsno.matrix(df=df_train.iloc[:, :], figsize=(8, 8), color=(0, 0.5, 1))","59d668db":"# bar\ud615\ud0dc\ub294 \uc9c1\uc811\uc801\uc778 \ud37c\uc13c\ud2b8\ub97c \ubcf4\uace0\uc2f6\uc744 \ub54c \uc0ac\uc6a9\nmsno.bar(df=df_train.iloc[:, :], figsize=(8, 8), color=(0, 0.5, 1))","300f2d1a":"# test data\uc758 null \uc704\uce58 \ubd84\ud3ec \ud655\uc778\n\n# missingno \ub77c\ub294 \ub77c\uc774\ube0c\ub7ec\ub9ac\ub97c \uc774\uc6a9\ud574\uc11c input\uc5d0 data frame\uc744 \ub118\uaca8\uc8fc\uace0,\n# matrix \ud615\ud0dc\ub97c \ub9cc\ub4e4\uc5b4 \uc8fc\ub294\ub370, \n# index location \uc774\ub77c\ub294 iloc\ub97c \uc774\uc6a9\ud574\uc11c \uc6d0\ud558\ub294 \uc704\uce58\uc5d0 \uc788\ub294 \uceec\ub7fc\uc744 \uac00\uc838\uc640\uc11c \uc0ac\uc6a9\ud560 \uc218 \uc788\ub2e4.\n# figsize\ub294 \uadf8\ub798\ud504 \ud06c\uae30\uc774\uace0, color\ub294 rgb\ub85c \uc774\ub8e8\uc5b4\uc838 \uc788\ub2e4.\n\nmsno.matrix(df=df_test.iloc[:, :], figsize=(8, 8), color = (1, 0.3, 0))","5c649bd4":"\n# test data\uc758 null\uc758 \ud37c\uc13c\ud2b8 \ud655\uc778\n\n# missingno \ub77c\ub294 \ub77c\uc774\ube0c\ub7ec\ub9ac\ub97c \uc774\uc6a9\ud574\uc11c input\uc5d0 data frame\uc744 \ub118\uaca8\uc8fc\uace0,\n# \uc544\ub798\uc640 \uac19\uc740 bar \ud615\ud0dc\ub97c \ub9cc\ub4e4\uc5b4 \uc900\ub2e4.\n# index location \uc774\ub77c\ub294 iloc\ub97c \uc774\uc6a9\ud574\uc11c \uc6d0\ud558\ub294 \uc704\uce58\uc5d0 \uc788\ub294 \uceec\ub7fc\uc744 \uac00\uc838\uc640\uc11c \uc0ac\uc6a9\ud560 \uc218 \uc788\ub2e4.\n# figsize\ub294 \uadf8\ub798\ud504 \ud06c\uae30\uc774\uace0, color\ub294 rgb\ub85c \uc774\ub8e8\uc5b4\uc838 \uc788\ub2e4.\n\nmsno.bar(df=df_test.iloc[:, :], figsize=(8, 8), color = (1, 0.3, 0))","bcb24aaa":"# \ud50c\ub78f\uc5d0 \uc0ac\uc6a9\ud560 \uc0c9\uae54\ub4e4\ncolors = [\"lightcoral\", \"sandybrown\", \"darkorange\", \"mediumseagreen\",\n          \"lightseagreen\", \"cornflowerblue\", \"mediumpurple\", \"palevioletred\",\n          \"lightskyblue\", \"sandybrown\", \"yellowgreen\", \"indianred\",\n          \"lightsteelblue\", \"mediumorchid\", \"deepskyblue\"]","25dca8da":"# \ub370\uc774\ud130\uc14b \uae38\uc774 \ube44\uad50\nfig, ax = plt.subplots(figsize=(5, 5))\npie = ax.pie([len(df_train), len(df_test)],\n            explode=[0, 0.1],\n            shadow=True,\n            labels=['Train dataset', 'Test dataset'],\n            colors=[\"yellowgreen\", 'darkorange'],\n            textprops={\"fontsize\": 17},\n            autopct='%1.1f%%')\nax.axis(\"equal\")\nax.set_title(\"Dataset length comparison\", fontsize=20)\nfig.set_facecolor(\"white\")\nplt.show()","557bdb1f":"# df_train\uc744 describe \uba54\uc18c\ub4dc\ub97c \uc0ac\uc6a9\ud574\uc11c \uac01\uc885 \uc9c0\ud45c\ub97c \ud655\uc778\ud558\ub294\ub370, \n# \uc6d0\ud558\ub294 \ubd84\uc704\uc218\ub97c \ucd9c\ub825\ud558\uae30 \uc704\ud574 (percentiles=[0.1, 0.25, 0.5, 0.75, 0.9]).T \ub97c \uc0ac\uc6a9\ud568\ndf_train.describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9]).T","a19d2b30":"# target destribution \ud655\uc778\ud558\uae30\n\nfig, ax = plt.subplots(figsize=(16, 8))\n\nbars = ax.hist(df_train[\"target\"],\n              bins=100,\n              color = 'deepskyblue',\n              edgecolor = \"black\")\nax.set_title(\"Target distribution\", fontsize = 25, pad = 20)\nax.set_ylabel(\"Amount of values\", fontsize=15, labelpad=17)\nax.set_xlabel(\"Target value\", fontsize=15, labelpad=15)\nax.margins(0.025, 0.12)\nax.grid(axis=\"x\")\nplt.legend(['target'])\n\nplt.show()","38baa5d0":"# target\uc758 value\uac00 5 \ubbf8\ub9cc\uc778 \ube44\uc728 \ud655\uc778\nprint(f\"{(df_train['target'] < 5).sum() \/ len(df_train) * 100:.3f}% of the target values are less than 5\")","f62d7fb3":"# \uce74\ud14c\uace0\ub9ac, \uc218\uce58\ud615 \ud53c\uccd0 \uc5f4 \ubaa9\ub85d\n# Lists of categorical and numerical feature columns\ncat_features = [\"cat\" + str(i) for i in range(10)]\nnum_features = [\"cont\" + str(i) for i in range(14)]","c66baaf3":"# \uce74\ud14c\uace0\ub9ac\ud615\uc740 cat0~cat9 (10\uac1c)\ncat_features","9929e040":"# \uc218\uce58\ud615\uc740 cont0~cont13 (14\uac1c)\nnum_features","87771d06":"# \uc218\uce58\ud615 \ud53c\uccd0\ub9cc\uc744 \ud3ec\ud568\ud558\ub294 \ub370\uc774\ud130 \ud504\ub808\uc784 (train, test \uacb0\ud569)\ndf = pd.concat([df_train[num_features], df_test[num_features]], axis=0)\ncolumns = df.columns.values","91075ee9":"# \ubaa8\ub4e0 \ud53c\uccd0\uc758 \ud50c\ub78f\ub4e4\uc744 \ud45c\uc2dc\ud558\ub294\ub370 \ud544\uc694\ud55c \ub3c4\ud654\uc9c0 \ud589 \uc218 \uacc4\uc0b0\ncols = 3\nrows = len(columns)\/\/cols+1","15f6862c":"# \uc218\uce58\ud615 \ud53c\uccd0 \uc0b4\ud3b4\ubcfc \ud50c\ub78f\uadf8\ub9ac\uae30\nfig, axs = plt.subplots(ncols=cols, nrows=rows, figsize=(16,20), sharex=False)\n\n# \ud50c\ub78f\uc0ac\uc774 \uac04\uaca9 \uc124\uc815\nplt.subplots_adjust(hspace = 0.3)\n\n# \ud50c\ub78f\ni = 0\nfor r in np.arange(0, rows, 1):\n    for c in np.arange(0, cols, 1):\n        if i >= len(columns): #\ud50c\ub78f\uc744 \ub9cc\ub4e4 \ub370\uc774\ud130 column\uc774 \ub354\uc774\uc0c1 \uc5c6\ub294 \uacbd\uc6b0\n            axs[r, c].set_visible(False) #\uae68\ub057\ud55c \ubc30\uacbd\uc774 \ub418\ub3c4\ub85d \ucd95\uc744 \uc228\uae40\n        else:\n            #df_train data \ud788\uc2a4\ud1a0\uadf8\ub7a8\n            hist1 = axs[r, c].hist(df_train[columns[i]].values,\n                                  range=(df[columns[i]].min(),\n                                         df[columns[i]].max()),\n                                  bins=40,\n                                  color = \"yellowgreen\",\n                                  edgecolor=\"black\",\n                                  alpha=0.7,\n                                  label=\"Train Dataset\")\n            #df_test data \ud788\uc2a4\ud1a0\uadf8\ub7a8\n            hist2 = axs[r, c].hist(df_test[columns[i]].values,\n                                  range=(df[columns[i]].min(),\n                                         df[columns[i]].max()),\n                                  bins = 40,\n                                  color = 'darkorange',\n                                  edgecolor = \"black\",\n                                  alpha = 0.7,\n                                  label=\"Test Dataset\")\n            axs[r, c].set_title(columns[i], fontsize=14, pad=5)\n            axs[r, c].tick_params(axis=\"y\", labelsize=13)\n            axs[r, c].tick_params(axis=\"x\", labelsize=13)\n            axs[r, c].grid(axis=\"y\")\n            axs[r ,c].legend(fontsize=13)\n        i+=1\n# plt.suptitle(\"Numerical feature values distribution in both datasets\", y=0.99)\nplt.show()\n                            \n                                \n                                    \n            ","24b1a26e":"# \uce74\ud14c\uace0\ub9ac\ud615 \ud53c\uccd0\ub9cc\uc744 \ud3ec\ud568\ud558\ub294 \ub370\uc774\ud130 \ud504\ub808\uc784 (train, test \uacb0\ud569)\ndf = pd.concat([df_train[cat_features], df_test[cat_features]], axis=0)\ncolumns = df.columns.values","d80142a0":"# \ubaa8\ub4e0 \ud53c\uccd0\uc758 \ud50c\ub78f\ub4e4\uc744 \ud45c\uc2dc\ud558\ub294\ub370 \ud544\uc694\ud55c \ub3c4\ud654\uc9c0 \ud589 \uc218 \uacc4\uc0b0\ncols = 3\nrows = len(columns)\/\/cols+1","ececa6b5":"# \uc218\uce58\ud615 \ud53c\uccd0 \uc0b4\ud3b4\ubcfc \ud50c\ub78f\uadf8\ub9ac\uae30\nfig, axs = plt.subplots(ncols=cols, nrows=rows, figsize=(16, 20), sharex=False)\n\n# \ud50c\ub78f\uc0ac\uc774 \uac04\uaca9 \uc124\uc815\nplt.subplots_adjust(hspace = 0.2, wspace=0.25)\n\n# \ud50c\ub78f\ni = 0\nfor r in np.arange(0, rows, 1):\n    for c in np.arange(0, cols, 1):\n        if i >= len(cat_features): # \ud50c\ub78f\uc744 \ub9cc\ub4e4 \ub370\uc774\ud130 \uc5f4\uc774 \ub354 \uc774\uc0c1 \uc5c6\ub294 \uacbd\uc6b0\n            axs[r, c].set_visible(False) #\uae68\ub057\ud55c \ubc30\uacbd\uc774 \ub418\ub3c4\ub85d \ucd95\uc744 \uc228\uae40\n        else:\n            values = df[cat_features[i]].value_counts().sort_index(ascending=False).index\n            bars_pos = np.arange(0, len(values))\n            if len(values)<4:\n                height=0.1\n            else:\n                height=0.3\n            \n            bars1 = axs[r, c].barh(bars_pos+height\/2,\n                                    [df_train[df_train[cat_features[i]]==x][cat_features[i]].count()for x in values],\n                                    height = height,\n                                    color = \"cornflowerblue\",\n                                    edgecolor=\"black\",\n                                    label=\"Train Dataset\")\n            bars = axs[r, c].barh(bars_pos-height\/2,\n                                    [df_test[df_test[cat_features[i]]==x][cat_features[i]].count() for x in values],\n                                    height = height,\n                                    color = \"lightcoral\",\n                                    edgecolor=\"black\",\n                                    label = \"Test Dataset\")\n            y_labels = [str(x) for x in values]\n            \n            axs[r, c].set_title(cat_features[i], fontsize=14, pad =1)\n            axs[r, c].set_xlim(0, len(df_train[\"id\"])+50)\n            axs[r, c].set_yticks(bars_pos)\n            axs[r, c].set_yticklabels(y_labels)\n            axs[r, c].tick_params(axis=\"y\", labelsize=10)\n            axs[r, c].tick_params(axis=\"x\", labelsize=10)\n            axs[r, c].grid(axis=\"y\")\n            axs[r, c].legend(fontsize=12)\n            axs[r, c].margins(0.1, 0.02)\n            \n        i+=1\n#plt.suptitle(\"Categorical feature values distribution in both datasets\", y=0.99)        \nplt.show()\n                                     \n","f69a4c2b":"# \ubc94\uc8fc\ud615 \ubcc0\uc218\uc758 \uce74\ud14c\uace0\ub9ac \uac2f\uc218 \ud655\uc778\uc6a9 bar\ud615 \ud50c\ub78f \uadf8\ub9ac\uae30\nbars_pos = np.arange(len(cat_features))\n\nwidth=0.3\nfig, ax = plt.subplots(figsize=(14, 6))\n\n# \ub450 \uac1c\uc758 bar\uac1d\uccb4\ub97c \ub9cc\ub4e0\ub2e4. \ub9c9\ub300\ub294 \uc11c\ub85c \ubd99\uc5b4\uc11c \uc67c\ucabd\uc5d0\ud558\ub098, \uc624\ub978\ucabd\uc5d0 \ud558\ub098 \uc874\uc7ac.\nbars1 = ax.bar(bars_pos-width\/2,\n                 df_train[cat_features].nunique().values,\n                 width=width,\n                 color=\"lightskyblue\", edgecolor=\"black\")\nbars2 = ax.bar(bars_pos+width\/2,\n              df_test[cat_features].nunique().values,\n              width=width,\n              color=\"steelblue\", edgecolor=\"black\")\nax.set_title(\"Amount of values in categorical features\", fontsize=25, pad=20)\nax.set_xlabel(\"Categorical feature\", fontsize=15, labelpad=15)\nax.set_xticks(bars_pos)\nax.set_xticklabels(cat_features, fontsize=12)\nax.tick_params(axis=\"y\", labelsize=12)\nax.grid(axis=\"y\")\nplt.margins(0.01, 0.05)","fa696fea":"# df_train\uc5d0 \uc5c6\ub294 \uce74\ud14c\uace0\ub77c\uae30 df_test\uc5d0 \ud3ec\ud568\ub418\uc5b4 \uc788\uc9c0 \uc54a\uc740\uc9c0 \ud655\uc778\ud574\ubcf4\uc790.\nfor col in cat_features:\n    print(set(df_train[col].value_counts().index)==set(df_test[col].value_counts().index))","21ba9d30":"# df_train\uc5d0\uc11c id column drop\ud558\uae30\ndf = df_train.drop(\"id\", axis=1)\n\n# OrdinalEncoder\ub85c \ubc94\uc8fc\ud615 \ud53c\uccd0\ub97c \uc778\ucf54\ub529\ud558\uae30\nfor col in cat_features:\n    encoder = OrdinalEncoder()\n    df[col] = encoder.fit_transform(np.array(df[col]).reshape(-1, 1))\n    \n# \uc0c1\uad00\uad00\uacc4 \uac12 \uacc4\uc0b0\ndf = df.corr().round(2)\n\n# \uc0ac\uc120\uc73c\ub85c \uc911\ubcf5\uc774\ubbc0\ub85c \ud50c\ub78f\uc758 \uc624\ub978\ucabd \uc0c1\ub2e8\ubd80\ubd84\uc744 \uc228\uae30\uae30 (\uc120\ud0dd\uc0ac\ud56d\uc784)\nmask = np.zeros_like(df)\nmask[np.triu_indices_from(mask)] = True\n\n# \ud50c\ub78f \ub9cc\ub4e4\uae30\nplt.figure(figsize=(15,15))\nax = sns.heatmap(df, annot=True, mask=mask, cmap=\"RdBu\",linewidths=0.1, linecolor='white',vmax=0.5, annot_kws={\"weight\":\"normal\", \"fontsize\":9})\nax.set_title(\"Feature correlation heatmap\", fontsize=17)\nplt.setp(ax.get_xticklabels(), rotation=90, ha=\"right\",fontsize=15,\n        rotation_mode=\"anchor\", weight = \"normal\")\nplt.setp(ax.get_yticklabels(), rotation=-0, ha=\"right\",fontsize=15,\n        rotation_mode=\"anchor\", weight=\"normal\")\nplt.show()","d4c12b75":"# \uac01 \ud53c\uccd0\uc640 \ud0c0\uac9f \ub370\uc774\ud130 \uc2dc\uac01\ud654\ncolumns = df_train.drop([\"id\"], axis=1).columns.values\n\n# \ubaa8\ub4e0 \ud53c\uccd0\uc5d0 \ub300\ud55c \ud50c\ub78f\uc744 \ud45c\uc2dc\ud558\ub294\ub370\uc5d0 \ud544\uc694\ud55c \ub3c4\ud654\uc9c0\uc18d \ud589\uc758 \uc218 \uacc4\uc0b0\ncols = 4\nrows = len(columns) \/\/ cols + 1\n\nfig, axs = plt.subplots(ncols=cols, nrows = rows, figsize = (16, 20), sharex=False)\n\n# \ud50c\ub78f\ub4e4 \uc0ac\uc774\uc5d0 \uac04\uaca9 \uc124\uc815\nplt.subplots_adjust(hspace=0.3)\n\ni = 0\nfor r in np.arange(0, rows, 1):\n    for c in np.arange(0, cols, 1):\n        if i >= len(columns):\n            axs[r, c].set_visible(False)\n        else:\n            scatter = axs[r, c].scatter(df_train[columns[i]].values,\n                                       df_train[\"target\"],\n                                       color = random.choice(colors))\n            axs[r, c].set_title(columns[i], fontsize=14, pad=5)\n            axs[r, c].tick_params(axis=\"y\", labelsize=11)\n            axs[r, c].tick_params(axis=\"x\", labelsize=11)\n        \n        i+=1\n# plt.suptitle(\"Features vs target\", y=0.99)\nplt.show()\n\n","c7b43bf1":"# \ubc94\uc8fc\ud615 \ubcc0\uc218\ub85c \uad6c\uc131\ub41c \ud53c\uccd0\ub97c OrdinalEncoder\ub85c \uc778\ucf54\ub529\ud55c\ub2e4.\nfor col in cat_features:\n    encoder = OrdinalEncoder()\n    df_train[col] = encoder.fit_transform(np.array(df_train[col]).reshape(-1, 1))\n    df_test[col] = encoder.transform(np.array(df_test[col]).reshape(-1, 1))","d79b1d49":"# target\ub370\uc774\ud130 \ubd84\ub9ac\nX = df_train.drop([\"id\", \"target\"], axis = 1)\nX_test = df_test.drop([\"id\"], axis = 1)\ny = df_train[\"target\"]","f3f97a07":"# variance\uac00 \uac00\uc7a5 \uc801\uc740 \uc5f4\uc744 \uc0ad\uc81c\ud55c\ub2e4.\nX.drop(\"cat4\", axis = 1, inplace=True)\nX_test.drop(\"cat4\", axis = 1, inplace=True)","baba8bd0":"# cat4 \uc0ad\uc81c\ub41c train \ub370\uc774\ud130 \ud504\ub808\uc784 \ud655\uc778\nX.head()","ac79a120":"# cat4 \uc0ad\uc81c\ub41c test \ub370\uc774\ud130 \ud504\ub808\uc784 \ud655\uc778\n\nX_test.head()","cac062a3":"# \ubaa8\ub378\uc758 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc124\uc815\nxgb_params = {'n_estimators': 10000,\n             'learning_rate' : 0.35,\n             'subsample' : 0.926,\n             'colsample_bytree':0.84,\n             'max_depth' : 5,\n             'booster' : 'gbtree',\n             'reg_lambda' : 20,\n             'reg_alpha' : 20,\n             'random_state' : 42,\n             'n_jobs' : 4}","ec18435a":"%%time\n\n# fold \ub9e4\uac1c\ubcc0\uc218 \uc124\uc815\nsplits = 10\nskf = KFold(n_splits=splits, shuffle=True, random_state=1)\n\n# \"out of fold\" \uc608\uce21\uc744 \uc800\uc7a5\ud558\uae30 \uc704\ud55c \ubc30\uc5f4 \uc0dd\uc131\noof_preds = np.zeros((X.shape[0],))\npreds = 0\nmodel_fi = 0\ntotal_mean_rmse = 0\n\n# \ud3f4\ub4dc \uc0dd\uc131 \ubc0f 10\uac1c\uc758 \ud3f4\ub4dc \uac01\uac01\uc5d0 \ub300\ud55c \ud559\uc2b5 \ubc0f \uc608\uce21\nfor num, (train_idx, valid_idx) in enumerate(skf.split(X)):\n    X_train, X_valid = X.loc[train_idx], X.loc[valid_idx]\n    y_train, y_valid = y.loc[train_idx], y.loc[valid_idx]\n    \n    model = XGBRegressor(**xgb_params)\n    model.fit(X_train, y_train,\n              verbose = False,\n              #\uc774 \uc138 \uac00\uc9c0 \ub9e4\uac1c\ubcc0\uc218\ub294 \ubaa8\ub378\uc774 overfitting\uc774 \ub418\uae30\uc804\uc5d0 \ud559\uc2b5\uc744 \uc911\uc9c0\ud55c\ub2e4.\n              eval_set = [(X_train, y_train), (X_valid, y_valid)],\n              eval_metric=\"rmse\",\n              early_stopping_rounds=100,\n             )\n    # \uac80\uc815 \ub370\uc774\ud130 \uc608\uce21 \ud3c9\uade0 \uc5bb\uae30(ex: \ubd84\ud560 \uc218\ub85c \ub098\ub204\uae30)\n    preds += model.predict(X_test) \/ splits\n    \n    # \ud53c\uccd0 \uc784\ud3ec\ud134\uc2a4\uc758 \ud3c9\uade0 \uc5bb\uae30(\ubd84\ud560 \uc218\ub85c \ub098\ub208 \uac12)\n    model_fi += model.feature_importances_ \/ splits\n    \n    #validation \ub370\uc774\ud130 \uc608\uce21\uc744 \uac00\uc838\uc628\ub2e4. \uac01 fold\ubaa8\ub378\uc740 \ubcf4\uc774\uc9c0 \uc54a\ub294 \ub370\uc774\ud130\ub97c \uc608\uce21\ud55c\ub2e4.\n    #\uacb0\uad6d\uc5d0\ub294 \ubcf4\uc774\uc9c0 \uc54a\ub294 \ub370\uc774\ud130 \uc608\uce21\uc73c\ub85c \ucc44\uc6cc\uc9c4\ub2e4.\n    #\ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130 \uc131\ub2a5\uc744 \ud3c9\uac00\ud558\ub294 \ub370\ub9cc \uc0ac\uc6a9\ub41c\ub2e4.\n    oof_preds[valid_idx] = model.predict(X_valid)\n    \n    # fold model\uc5d0 \ub300\ud55c \uc810\uc218 \uc5bb\uae30\n    fold_rmse = mean_squared_error(y_valid, oof_preds[valid_idx], squared=False)\n    print(f\"Fold {num} RMSE: {fold_rmse}\")\n    \n    \n    #\ubaa8\ub4e0 fold model\uc758 \ud3c9\uade0 \uc810\uc218 \uc5bb\uae30(\ubd84\ud560\uc218\ub85c \ub098\ub208 \uac12)\n    total_mean_rmse += fold_rmse \/ splits\n\n    print(f\"\\nOverall RMSE: {total_mean_rmse}\")\n              ","fbb2bd2e":"# \ud50c\ub78f\uc5d0 \uc0ac\uc6a9\ud560 \ub370\uc774\ud130\ud504\ub808\uc784 \uc0dd\uc131\ndf = pd.DataFrame()\ndf[\"Feature\"] = X.columns\n\n# \ud559\uc2b5\ub41c \ubaa8\ub378\uc5d0\uc11c \ud53c\uccd0 \uc784\ud3ec\ud134\uc2a4 \ucd94\ucd9c\ndf[\"Importance\"] = model_fi \/ model_fi.sum()\n\n# \ud53c\uccd0 \uc784\ud3ec\ud134\uc2a4\uc5d0 \ub530\ub77c \ub370\uc774\ud130\ud504\ub808\uc784 \uc815\ub82c\ndf.sort_values(\"Importance\", axis = 0, ascending=False, inplace=True)","416a1d43":"# \ud50c\ub78f \uc0dd\uc131\nfig, ax = plt.subplots(figsize=(13, 10))\nbars = ax.barh(df[\"Feature\"], df[\"Importance\"], height = 0.4,\n              color = \"yellowgreen\", edgecolor = \"black\")\nax.set_title(\"Feature importances\", fontsize=30, pad=15)\nax.set_ylabel(\"Feature name\", fontsize=20, labelpad=15)\nax.set_xlabel(\"Feature importance\", fontsize=20, labelpad = 15)\nax.set_yticks(df[\"Feature\"])\nax.set_yticklabels(df[\"Feature\"], fontsize=15)\nax.tick_params(axis=\"x\", labelsize=15)\nax.grid(axis=\"x\")\n\n# \uc0c1\ub2e8\uc5d0 \ub77c\ubca8 \ucd94\uac00\nax2 = ax.secondary_xaxis('top')\nax2.set_xlabel(\"Feature importance\", fontsize=20, labelpad=15)\nax2.tick_params(axis=\"x\", labelsize=15)\n\n# \uac12\uc774 \uac10\uc18c\ud558\ub3c4\ub85d y\ucd95 \ubc29\ud5a5\uc744 \ubc18\uc804\nplt.gca().invert_yaxis()","ef18253c":"predictions = pd.DataFrame()\npredictions[\"id\"] = df_test[\"id\"]\npredictions[\"target\"] = preds\n\npredictions.to_csv('submission.csv', index=False, header=predictions.columns)\npredictions.head()","9a0051e0":"# Model development, Model training","903c8d95":"All of the feature columns, cat0 - cat9 are categorical, and the feature columns cont0 - cont13 are continuous.\nThe dataset contains categorical and numerical values. Let's see values distribution for these categories.","a50159f8":"# Predictions submission","2d744f75":"# Feature engineering, Data preprocessing","4a5601db":"# [Data import, Dataset check]","34d11cb9":"\uac01 feature\uc640 target\uc744 \uc2dc\uac01\ud654 \ud574\ubcf4\uc790.","27285c23":"# Feature importances","d860c725":"\uc774\ubc88\uc5d4 \uac01 \ud53c\uccd0\ub4e4\uc758 \uc0c1\uad00\uad00\uacc4\ub97c \uc0b4\ud3b4\ubcf4\uc790.","e44e8a5f":"\uc6b0\ub9ac\uac00 \ubcfc \uc218 \uc788\ub4ef\uc774, target column\uc740 \ubaa8\ub4e0 \ud53c\uccd0\uc640 \ub9e4\uc6b0 \uc57d\ud55c \uc0c1\uad00\uad00\uacc4\uc5d0 \uc788\ub2e4.","d66ae70b":"\uce74\ud14c\uace0\ub9ac\ud615(\ubc94\uc8fc\ud615) \ud53c\uccd0\uc5d0\uc11c \ub370\uc774\ud130 \uc14b\uc758 \uce74\ud14c\uace0\ub9ac \uc218\uac00 \ub2e4\ub978\uc9c0 \ud655\uc778\ud574 \ubcf4\uc790.","e6693668":"\ud655\uc778 \uacb0\uacfc df_train\uacfc df_test\ub294 balance\uac00 \uc798 \ub9de\ub294\ub2e4 \ub77c\uace0 \uc0dd\uac01\ub41c\ub2e4.\n","99c1e44f":"target destribution\uc744 \ud655\uc778\ud574 \ubcf4\uc790.","e6ba9575":"\ud3c9\uade0 \uc81c\uacf1\uadfc \ud3b8\ucc28 (Root-mean-square deviation)","f95582fe":"Welcome to the **[30 Days of ML competition](https:\/\/www.kaggle.com\/c\/30-days-of-ml\/overview)**!  \n\n# Import helpful libraries\n\nWe begin by importing the libraries we'll need.  Some of them will be familiar from the **[Intro to Machine Learning](https:\/\/www.kaggle.com\/learn\/intro-to-machine-learning)** course and the **[Intermediate Machine Learning](https:\/\/www.kaggle.com\/learn\/intermediate-machine-learning)** course.","d61e4f71":"# EDA(Exploratory Data Analysis, \ud0d0\uc0c9\uc801 \ub370\uc774\ud130 \ubd84\uc11d)","5c8c9b35":"describe\uc758 count\uc640 shape\ub97c \ube44\uad50\ud574\uc11c \uacb0\uce21\uac12\ud655\uc778\ud560 \uc218\ub3c4 \uc788\ub2e4.","f20fd542":"df_train, df_test\ubaa8\ub450 \uacb0\uce21\uac12\uc774 \uc5c6\ub2e4."}}