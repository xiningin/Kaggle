{"cell_type":{"95efd001":"code","b0f63c77":"code","7c5f3475":"code","7cbb0ef4":"code","628922eb":"code","8f452277":"code","a69d8d21":"code","7a53c4b4":"code","4b4f358a":"code","f8c0c063":"code","3f6370b3":"code","8058f51b":"code","14c9305a":"code","dace06d9":"markdown","4c3e2e1c":"markdown","fa7ec257":"markdown","cc908f97":"markdown","3de637e7":"markdown","a59c8881":"markdown","fc0591be":"markdown","c691fda1":"markdown"},"source":{"95efd001":"import pandas as pd\nimport numpy as np\n\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\n\n\n\ntrain_data_path = \"..\/input\/train_V2.csv\"#getting the path of the file to be inputed and assigned it\ntrain_data = pd.read_csv(train_data_path)#now reading the csv file to continue the proceaa\ntrain_data.head()#to show the first 5 Columns","b0f63c77":"unwanted_features = ['Id', 'groupId', 'matchId']#making a list of unwanted features\ntrain = train_data.drop(unwanted_features, axis=1)#dropping the unwanted features from the data\ntrain.head()#showing the new head()","7c5f3475":"new_train = pd.get_dummies(train, columns=['matchType'], drop_first = True)#implementing one hot encoding on matchType and storing it on new train data\nnew_train.head()#displaying its head","7cbb0ef4":"new_train.isnull().sum()#sum of number of NaN values in each column","628922eb":"new_train.shape#check the number of rows and columns","8f452277":"new_train.dropna(inplace=True)#dropping all the columns with NaN values\nnew_train.shape#Now again checking the number of columns and rows.","a69d8d21":"new_train.isnull().sum()#YaaaY......!Sum of NaN values became zero","7a53c4b4":"from sklearn.model_selection import train_test_split\n\n\n#Splitting my data into features and Label\nX = new_train.drop(['winPlacePerc'], axis=1)\ny = new_train.winPlacePerc\n\n#Splitting my features and label into train and test set so that I could check the accuracy and improve the model\n\ntrain_X, test_X, train_y, test_y = train_test_split(X, y, random_state= 1, test_size=0.4)\nprint(\"Done\u25c7\")\n","4b4f358a":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\nfrom xgboost import XGBRegressor\n\n\n\nmodels = [ RandomForestRegressor , AdaBoostRegressor, XGBRegressor]","f8c0c063":"#def best_model(n):\n #   model = n()\n  #  model.fit(train_X, train_y)\n   # pred = model.predict(test_X)\n    #Error = mae(pred, test_y)\n    #return Error\n\n\n\n#for i in models:\n    #print(\"MAE of \", i, best_model(i))","3f6370b3":"test_data_path = \"..\/input\/test_V2.csv\"\ntest_data = pd.read_csv(test_data_path)\ntest_data = test_data.drop(unwanted_features, axis=1)\ntest = pd.get_dummies(test_data, columns=[\"matchType\"], drop_first = True)\ntest.head()","8058f51b":"model = RandomForestRegressor()\nmodel.fit(X, y)\npred = model.predict(test)\nprint(\"Done\u2661\")","14c9305a":"test_data_id = pd.read_csv(test_data_path)\noutput = pd.DataFrame({'Id' : test_data_id.Id , 'winPlacePerc' : pred})\noutput.to_csv(\"output.csv\", index=False)","dace06d9":"#### Now looking into the head of the file we can see that the row 'Id', 'groupId' and 'matchId are features which doent affect the result.So we need to remove it from the test data to get better accuracy.","4c3e2e1c":"#### After checking our new dataset we could understand we have an important feature 'matchType' but is in object form, which is a problem as models can't train object type files.So we use \"ONE HOT ENCODING\".","fa7ec257":"#### Now that we have coverted every column of our data to int\/float values  lets check wheater the dataset is clean \/ it contain any NaN values","cc908f97":"# **The PUBG CHALLENGE**","3de637e7":"#### Now its time to choose an algorithm","a59c8881":"####  Only one column has missing value out of 4446966 colums.So I'm going to drop the one column. ","fc0591be":"# TRAINING\n### Now we have our clean dataset we can now start training our model.First step is to split tge data to X, y and train and test dat.","c691fda1":"#### Now we should define a function that could give the mae of each models by itrating through each algorithm"}}