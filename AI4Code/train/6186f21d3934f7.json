{"cell_type":{"14fdb933":"code","39a0a522":"code","59611835":"code","9091518e":"code","b38cc940":"code","ab7d92ab":"code","8a7cdbb9":"code","cf52259a":"code","555a9f47":"code","fee9dab8":"code","8da4f884":"code","1707a7a9":"code","090ef413":"code","082e1da4":"code","4041bf1f":"code","33273338":"code","528e85de":"markdown","9943094d":"markdown"},"source":{"14fdb933":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","39a0a522":"df = pd.read_csv('\/kaggle\/input\/creditcardfraud\/creditcard.csv')\ndf.head(10)","59611835":"hours = df['Time']\/3600\nhours = hours.astype(int)\ndf['Hours'] = hours","9091518e":"df.isnull().sum()","b38cc940":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize= (15,5))\nsns.set(style=\"whitegrid\")\nsns.countplot(x='Hours',data = df , hue = 'Class',palette='BuPu')\nplt.title(\"Graph of Transactions per each hour\\n\", fontsize=16)\nsns.set_context(\"paper\", font_scale=1.4)\n\nplt.show()","ab7d92ab":"a= len(df[df['Class'] == 0] )\nprint (\"Amount of Non Fraud transactions = \" , a)","8a7cdbb9":"b = len(df[df['Class'] == 1])\nprint (\"Amount of Fraud transactions = \" ,b )","cf52259a":"ratio = [ a, b] \ntitle = \"Not Fraud\" , \"Fraud\"\n\nplt.figure(figsize=(9,9))\nplt.pie(ratio, labels= title, shadow=True, startangle=0)\nplt.title('Pie Chart Ratio of Transactions by their Class\\n', fontsize=16)\nsns.set_context(\"paper\", font_scale=1.2)\n\n","555a9f47":"from sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample\n\nY = df.Class\nX = df.drop(['Time','Class', 'Amount'], axis=1)\n\n# setting up testing and training sets\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=2727)\n\n# concatenate our training data back together\nX = pd.concat([X_train, Y_train], axis=1)\n\n","fee9dab8":"notFraud = X[X.Class==0]\nfraud = X[X.Class==1]","8da4f884":"not_fraud_downsampled = resample(notFraud,\n                                 replace = False, # sample without replacement\n                                n_samples = len(fraud), # match minority n\n                                random_state = 27) # reproducible results\n\n# combine minority and downsampled majority\ndownsampled = pd.concat([not_fraud_downsampled, fraud])\n\n# checking counts\ndownsampled.Class.value_counts()","1707a7a9":"sns.countplot('Class', data=downsampled)\nplt.title('Equally Distributed Classes', fontsize=14)\nplt.ylabel(\"Frequency\")\nplt.show()","090ef413":"from xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nY_train = downsampled.Class\nX_train = downsampled.drop('Class', axis=1)\n\nundersampled = XGBClassifier()\nundersampled.fit(X_train, Y_train)\n\n# Predict on test\nundersampled_pred = undersampled.predict(X_test)\n# predict probabilities\nprobs = undersampled.predict_proba(X_test)\n# keep probabilities for the positive outcome only\nprobs = probs[:, 1]\n\naccuracy = accuracy_score(Y_test, undersampled_pred)\nprint(accuracy)","082e1da4":"from sklearn.linear_model import LogisticRegression\n\nlog_model=LogisticRegression()\nlog_model.fit(X_train, Y_train)\nprediction=log_model.predict(X_test)\nscore= accuracy_score(Y_test, prediction)\nprint(score)","4041bf1f":"from sklearn.ensemble import RandomForestClassifier\n\nclf = RandomForestClassifier(n_estimators = 100)\n\nclf.fit(X_train , Y_train)\n\n\n","33273338":"pred=clf.predict(X_test)\nsc= accuracy_score(Y_test, pred)\nprint(sc)","528e85de":"Data is imported","9943094d":"A new column named HOURS is generated from time coloumn"}}