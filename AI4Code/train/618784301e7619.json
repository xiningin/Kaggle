{"cell_type":{"a6239c90":"code","67163d3d":"code","57adae60":"code","d2147edf":"code","1daa0f7f":"code","f187637b":"code","0c0e9623":"code","cfd843b7":"code","4dc9ef12":"code","94612ffd":"code","cb6009ec":"code","eaccdd54":"code","d17d1875":"code","f0fd3eff":"code","bbb45481":"code","559ac473":"code","0b931fed":"code","43bd3212":"code","f28160c6":"code","30f16aa5":"code","cdaba040":"code","cf8cd1af":"code","f0c37772":"code","4bb7a785":"code","deb3371e":"code","3668f5a5":"code","e33ed27e":"code","7ef7d36b":"code","577b7506":"code","3a2b0497":"code","a6c58e98":"code","8946670e":"markdown","93177695":"markdown","bb9088d6":"markdown","689cadac":"markdown","651bbdc6":"markdown","2c65ecdf":"markdown","d48e1cfa":"markdown","31d0ffd1":"markdown","d3a1580b":"markdown","03f5e9b6":"markdown","d4096737":"markdown","b80d9a2f":"markdown","7876db09":"markdown","e8efa8c9":"markdown","28c413b2":"markdown","9c6bea54":"markdown","0f49269a":"markdown","dc084eac":"markdown","0f02884a":"markdown","f20c7ac1":"markdown","90cd8fec":"markdown","fd3027c0":"markdown","b04fce95":"markdown","807f35bf":"markdown","8f898c63":"markdown","d8a90bd6":"markdown","4720536a":"markdown","9d32bd42":"markdown"},"source":{"a6239c90":"!pip install pingouin","67163d3d":"# Carregamos as bibliotecas que ser\u00e3o utilizadas para manipula\u00e7\u00e3o e visualiza\u00e7\u00e3o dos dados\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pingouin as pg\nimport seaborn as sns","57adae60":"# Criamos um pipeline de pr\u00e9-processamento. A ideia \u00e9 utilizar essa fun\u00e7\u00e3o para microdados de\n# diferentes anos \ndef pipeline_notas_Enem(arquivo):\n    # Colunas a serem lidas no arquivo\n    features = [\n        'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT','NU_NOTA_REDACAO','TP_ESCOLA'\n    ]\n    \n    # Lemos o arquivo, retirando os registros em que um dos valores n\u00e3o estivesse presente.\n    df = pd.read_csv(\n        arquivo,\n        #nrows = 5000, # 5k linhas para desenvolvimento inicial\n        encoding = 'latin1',\n        usecols = features,\n        sep = ';'\n    ).dropna()\n    \n    df['NOTA_MEDIA'] = (df['NU_NOTA_CN'] + df['NU_NOTA_CH'] + df['NU_NOTA_LC'] + df['NU_NOTA_MT']) \/ 4\n    \n    # Filtramos os registros de com alunos de escolas p\u00fablicas e privadas (valores 2 e 3 no \n    # campo TP_ESCOLA)\n    df = df.loc[df['TP_ESCOLA'].isin([2, 3])]\n    df.loc[df['TP_ESCOLA']==2, 'TP_ESCOLA'] = 'P\u00fablica'\n    df.loc[df['TP_ESCOLA']==3, 'TP_ESCOLA'] = 'Privada'\n    \n    return df\n\n# Carregamos o dataset a partir da c\u00f3pia do Kaggle\nnotas = pipeline_notas_Enem('\/kaggle\/input\/enem-2019\/DADOS\/MICRODADOS_ENEM_2019.csv')\n\nnotas.head()","d2147edf":"notas.TP_ESCOLA.value_counts().plot(kind='bar')\nplt.show()","1daa0f7f":"notas[['TP_ESCOLA', 'NU_NOTA_REDACAO']].groupby('TP_ESCOLA').describe()","f187637b":"pub = notas.loc[notas.TP_ESCOLA=='P\u00fablica', 'NU_NOTA_REDACAO']\npriv = notas.loc[notas.TP_ESCOLA=='Privada', 'NU_NOTA_REDACAO']\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npg.ttest(priv, pub)","0c0e9623":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 3))\n\np1=sns.distplot(\n    pub,\n    ax=axes[0],\n    axlabel=f'M\u00e9dia: {pub.mean():.2f}\\nDesvio padrao: {pub.std():.2f}'\n).set_title(\"Notas de alunos de escola p\u00fablica\")\np2=sns.distplot(\n    priv,\n    axlabel=f'M\u00e9dia: {priv.mean():.2f}\\nDesvio padrao: {priv.std():.2f}'\n).set_title(\"Notas de alunos de escola privada\")\nplt.show()","cfd843b7":"notas[['TP_ESCOLA', 'NOTA_MEDIA']].groupby('TP_ESCOLA').describe()","4dc9ef12":"pub = notas.loc[notas.TP_ESCOLA=='P\u00fablica', 'NOTA_MEDIA']\npriv = notas.loc[notas.TP_ESCOLA=='Privada', 'NOTA_MEDIA']\npg.ttest(x=priv, y=pub, correction=False).round(2)","94612ffd":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 3))\n\np1=sns.distplot(\n    pub,\n    ax=axes[0],\n    axlabel=f'M\u00e9dia: {pub.mean():.2f}\\nDesvio padrao: {pub.std():.2f}'\n).set_title(\"Nota de alunos de escola p\u00fablica\")\np2=sns.distplot(\n    priv,\n    axlabel=f'M\u00e9dia: {priv.mean():.2f}\\nDesvio padrao: {priv.std():.2f}'\n).set_title(\"Nota de alunos de escola privada\")\nplt.show()","cb6009ec":"std_features = ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO', 'NOTA_MEDIA']\nfrom sklearn.preprocessing import StandardScaler\nstd = StandardScaler()\nnotas[std_features] = std.fit_transform(notas[std_features])","eaccdd54":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    notas.drop(['TP_ESCOLA', 'NOTA_MEDIA'], axis = 1), notas.TP_ESCOLA, test_size=0.2, random_state=42\n)","d17d1875":"# Instanciamos o modelo KNN com dois n\u00facleos\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=2)\n\n# Definimos uma fun\u00e7\u00e3o para treinamento e exbi\u00e7\u00e3o dos resultados de um modelo\ndef pipeline_treino_teste(model):\n    # Ajustamos o modelo\n    model.fit(X_train, y_train)\n    # Submetemos os dados de teste ao classificador \n    y_pred = model.predict(X_test)\n    \n    # E observamos algumas m\u00e9tricas de desempenho desse modelo: acur\u00e1cia, F1-score e matriz de confus\u00e3o\n    from sklearn import metrics\n    print(f'Acur\u00e1cia: {metrics.accuracy_score(y_test, y_pred)}')\n    print(f'F1-score m\u00e9dio: {metrics.f1_score(y_test, y_pred, average=\"weighted\")}')\n    print(f\"F1-score da classe minorit\u00e1ria: {metrics.f1_score(y_test, y_pred, pos_label='Privada')}\")\n    metrics.plot_confusion_matrix(model, X_test, y_test, cmap=plt.cm.Blues, normalize='true')\n    \n# Agora executamos o pipeline\npipeline_treino_teste(knn)","f0fd3eff":"# Instanciamos um modelo SGD (descida do gradiente estoc\u00e1stica)\nfrom sklearn.linear_model import SGDClassifier\nsgd = SGDClassifier(class_weight=\"balanced\", loss='modified_huber', penalty=\"elasticnet\", random_state=42)\n\n# Executamos o pipeline de treino e teste\npipeline_treino_teste(sgd)","bbb45481":"# Instanciamos o modelo de regress\u00e3o log\u00edstica\nfrom sklearn.linear_model import LogisticRegression\nrlog = LogisticRegression(class_weight=\"balanced\")\n\n# E submetemos ao pipeline de treino e teste\npipeline_treino_teste(rlog)","559ac473":"# Instanciamos uma \u00e1rvore de decis\u00e3o, com altura m\u00e1xima de 3 n\u00f3s\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\ntree = DecisionTreeClassifier(class_weight=\"balanced\", max_depth=7, random_state=42)\n\n# Executamos o pipeline de treino e teste\npipeline_treino_teste(tree)","0b931fed":"# Instanciamos o classificador Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(class_weight=\"balanced\", n_estimators=300, random_state=42)\n\n# Executamos o pipeline de treino e teste\npipeline_treino_teste(rf)","43bd3212":"# Instanciamos o classificador SVM\nfrom sklearn.svm import LinearSVC\nlsvm = LinearSVC(class_weight=\"balanced\", max_iter=3000, random_state=42, tol=5e-4)\n\n# Submetemos o classificador ao treino e teste\npipeline_treino_teste(lsvm)","f28160c6":"from xgboost import XGBClassifier\nxgb = XGBClassifier(\n    objective = 'multi:softmax',\n    booster = 'gbtree',\n    num_class = 2,\n    eval_metric = 'logloss',\n    eta = .1,\n    max_depth = 14,\n    colsample_bytree = .4,\n    n_jobs=-1\n)\n\npipeline_treino_teste(xgb)","30f16aa5":"# Instanciamos o classficador por votos, passando os classificadores j\u00e1 treinados\nfrom mlxtend.classifier import EnsembleVoteClassifier\n\nvote = EnsembleVoteClassifier(\n    clfs=[knn, sgd, rlog, tree, rf, lsvm, xgb],\n    weights=[1, 1, 1, 1, 1, 1, 1],\n    refit=False\n)\n\n# Submetemos esse classificador ao teste\npipeline_treino_teste(vote)","cdaba040":"from fastai.tabular import *\n\ndep_var = 'TP_ESCOLA'\ncont_names = ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO', 'NOTA_MEDIA']\n\nstart = int(len(notas)*.7)\nend = int(len(notas)*.1) + start\n\n              \ntest = TabularList.from_df(notas.iloc[start:end], cont_names=cont_names)\n\ndata = (\n    TabularList\n        .from_df(notas, cont_names=cont_names)\n        .split_by_idx(list(range(start,end)))\n        .label_from_df(cols=dep_var)\n        .add_test(test)\n        .databunch()\n)\n\ndata.show_batch(rows=10)","cf8cd1af":"learn = tabular_learner(data, layers=[200,100], metrics=accuracy)\nlearn.fit_one_cycle(1, 5e-3)","f0c37772":"ClassificationInterpretation.from_learner(learn).plot_confusion_matrix(normalize=True)","4bb7a785":"nX = notas[['NOTA_MEDIA', 'NU_NOTA_REDACAO']]\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nny = le.fit_transform(notas.TP_ESCOLA)","deb3371e":"from mlxtend.plotting import plot_decision_regions\nimport matplotlib.gridspec as gridspec\nimport itertools\n\ngs = gridspec.GridSpec(2, 2)\nfig = plt.figure(figsize=(10,8))\n\nlabels = ['K-nearest Neighbour', 'Stochastic Gradient Descent', 'Logistic Regression', 'Decision Tree']\n\nfor clf, lab, grd in zip([knn, sgd, rlog, tree],\n                         labels,\n                         itertools.product([0, 1], repeat=2)):\n    clf.fit(nX, ny)\n    ax = plt.subplot(gs[grd[0], grd[1]])\n    fig = plot_decision_regions(X=nX.to_numpy(), y=ny, clf=clf)\n    plt.title(lab)","3668f5a5":"# Criamos um pipeline de pr\u00e9-processamento. A ideia \u00e9 utilizar essa fun\u00e7\u00e3o para microdados de\n# diferentes anos \ndef pipeline_SocioEconomico_Enem(arquivo):\n    # Colunas a serem lidas no arquivo\n    features = [\n        'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO',  'TP_ESCOLA', \n        'TP_ENSINO', 'SG_UF_ESC', 'TP_COR_RACA', 'TP_SEXO', 'Q001', 'Q002', 'Q005', 'Q006', 'Q007',\n        'NU_IDADE'\n    ]\n\n    # Carregamos o dataset a partir do arquivo\n    df = pd.read_csv(\n        arquivo,\n        nrows = 5000, # 5k linhas para desenvolvimento inicial\n        encoding = 'latin1',\n        usecols = features,\n        sep = ';'\n    )#.dropna()\n    \n    # Filtramos os registros de com alunos de escolas p\u00fablicas e privadas (valores 2 e 3 no campo TP_ESCOLA)\n    df = df.loc[df['TP_ESCOLA'].isin([2, 3])]\n    df.loc[df['TP_ESCOLA']==2, 'TP_ESCOLA'] = 'P\u00fablica'\n    df.loc[df['TP_ESCOLA']==3, 'TP_ESCOLA'] = 'Privada'\n\n    # Vamos atribuir o tipo de ensino com base na idade do aluno\n    df = df.loc[df['NU_IDADE'].notna()]\n    df.loc[df['TP_ENSINO'].isna() & df['NU_IDADE']>21, 'TP_ENSINO'] = 3\n    df.loc[df['TP_ENSINO'].isna(), 'TP_ENSINO'] = 1\n    \n    # Filtramos os demais valores ausentes\n    df.dropna(inplace=True)\n    \n    # Realizamos uma normaliza\u00e7\u00e3o dos valores das notas\n    std_features = ['NOTA_MEDIA', 'NU_NOTA_REDACAO']\n    df['NOTA_MEDIA'] = (df['NU_NOTA_CN'] + df['NU_NOTA_CH'] + df['NU_NOTA_LC'] + df['NU_NOTA_MT']) \/ 4\n    \n    \n    from sklearn.preprocessing import StandardScaler\n    std = StandardScaler()\n    df[std_features] = std.fit_transform(df[std_features])\n    \n    # Usamos um encoder ordinal para transformar os valores presentes na coluna 'Q006' (faixa de renda) em valores \n    # num\u00e9ricos, crescentes.\n    ord_enc_features = ['Q001', 'Q002', 'Q001']\n    from sklearn.preprocessing import OrdinalEncoder\n    ord_enc = OrdinalEncoder()\n    df[ord_enc_features] = ord_enc.fit_transform(df[ord_enc_features])\n\n    ## - Colunas que passar\u00e3o por um processo de codifica\u00e7\u00e3o\n    #onehot_enc_features = ['TP_COR_RACA', 'TP_SEXO', 'TP_ENSINO', 'SG_UF_ESC']\n    #from sklearn.preprocessing import OneHotEncoder\n    #onehot_enc = OneHotEncoder()\n    #df.enc = onehot_enc.fit_transform(df[onehot_enc_features])\n\n    # Retira as colunas usadas para c\u00e1lculos intermedi\u00e1rios\n    return df.drop(['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT'], axis = 1)\n\n# Carregamos o dataset a partir da c\u00f3pia do Kaggle, retirando os registros em que um dos valores n\u00e3o estivesse presente.\nse = pipeline_SocioEconomico_Enem('.\/dados\/MICRODADOS_ENEM_2019.csv')\n\nse.head()","e33ed27e":"ord_enc_features = ['Q005', 'Q006', 'Q007']\nfrom sklearn.preprocessing import OrdinalEncoder\nenc = OrdinalEncoder()\nse[ord_enc_features] = enc.fit_transform(se[ord_enc_features])\nse.head()","7ef7d36b":"onehot_enc_features = ['TP_ESCOLA', 'TP_COR_RACA', 'TP_SEXO', 'TP_ENSINO', 'SG_UF_ESC']\nse = pd.get_dummies(se, prefix=onehot_enc_features, columns=onehot_enc_features, drop_first=True)\nse.head()","577b7506":"X_train, X_test, y_train, y_test = train_test_split(\n    se.drop(['NOTA_MEDIA'], axis = 1), se.NOTA_MEDIA, test_size=0.2, random_state=42\n)","3a2b0497":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X_train, y_train)\n\nfrom sklearn.metrics import mean_squared_error\nmean_squared_error(y_test, lr.predict(X_test))","a6c58e98":"X_train, X_test, y_train, y_test = train_test_split(\n    se.drop(['NU_NOTA_REDACAO'], axis = 1), se.NU_NOTA_REDACAO, test_size=0.2, random_state=42\n)\n\nlr2 = LinearRegression()\nlr2.fit(X_train, y_train)\n\nmean_squared_error(y_test, lr.predict(X_test))","8946670e":"## Prevendo a nota dos alunos a partir de seus dados socioecon\u00f4micos","93177695":"Nossa vari\u00e1vel alvo, nesse experimento ser\u00e1 a nota m\u00e9dias nas provas objetivas. Com o dataset subdividido em treino e teste, ajustamos um modelo de regress\u00e3o linear.","bb9088d6":"O resultado desse classificador \u00e9, na verdade, uma composi\u00e7\u00e3o de resultados dos 300 estimadores criados internamente. \u00c9 interessante notar que, embora haja uma diferen\u00e7a significativa na acur\u00e1cia, a melhora se d\u00e1 apenas na classe majorit\u00e1ria: agora, com apenas 3% de erros. O modelo erra, no entanto, em cerca de 72% das ocorr\u00eancias da classe minorit\u00e1ria.\n\nA seguir, testamos um modelo de m\u00e1quinas de vetores-suporte. Trata-se de um modelo que busca maximizar as fronteiras de separa\u00e7\u00e3o entre classes. Neste experimento, utilizamos a vers\u00e3o linear do classificador, pois o custo de computa\u00e7\u00e3o da vers\u00e3o n\u00e3o linear (SVC) \u00e9 quadr\u00e1tico em rela\u00e7\u00e3o ao n\u00famero de registros na amostra, o que o torna invi\u00e1vel para um dataset com mais de 1 milh\u00e3o de registros.","689cadac":"Utilizamos um encoder ordinal, para as vari\u00e1veis em que h\u00e1 uma grada\u00e7\u00e3o de valores categ\u00f3ricos\n","651bbdc6":"Alteramos a vari\u00e1vel-alvo e ","2c65ecdf":"## An\u00e1lise explorat\u00f3ria\n\nOs dados utilizados neste experimento s\u00e3o disponibilizados pelo Inep em http:\/\/inep.gov.br\/web\/guest\/microdados. Para os modelos de classifica\u00e7\u00e3o de alunos, foram utilizados os dados mais recentes, do Enem 2019. Para os modelos de classifica\u00e7\u00e3o de escolas, foram utilizados os dados dos tr\u00eas \u00faltimos anos dispon\u00edveis: 2019, 2018 e 2017.\n\nPara o primeiro grupo de modelos, usamos as seguintes propriedades do registro:\n\n\n|Propriedade      | Descri\u00e7\u00e3o                             |\n|:--------------- |:--------------------------------------|\n| TP_ESCOLA\t      | Tipo de escola do Ensino M\u00e9dio <sup>1<\/sup>|\n| NU_NOTA_CN      |Nota da prova de Ci\u00eancias da Natureza  |\n| NU_NOTA_CH\t  |Nota da prova de Ci\u00eancias Humanas      |\n| NU_NOTA_LC\t  |Nota da prova de Linguagens e C\u00f3digos  |\n| NU_NOTA_MT\t  |Nota da prova de Matem\u00e1tica            |\n| NU_NOTA_REDACAO |Nota da prova de reda\u00e7\u00e3o               |\n\nPara o segundo grupo, foram utilizadas as seguintes propriedades:\n\n|Propriedade     | Descri\u00e7\u00e3o                              |\n|:---------------|:-------------------------------------- |\n| TP_ESCOLA\t     | Tipo de escola do Ensino M\u00e9dio         |\n| TP_ENSINO\t     | Tipo de institui\u00e7\u00e3o que concluiu ou concluir\u00e1 o Ensino M\u00e9dio|\n| SG_UF_ESC\t     | Sigla da Unidade da Federa\u00e7\u00e3o da escola|\n| TP_SEXO\t     | Sexo                                   |\n| TP_COR_RACA\t | Cor\/ra\u00e7a                               |\n| Q001\t         | Forma\u00e7\u00e3o acad\u00eamica do pai              |\n| Q002           | Forma\u00e7\u00e3o acad\u00eamica da m\u00e3e              |\n| Q005           | N\u00famero de pessoas na resid\u00eancia        |\n| Q006           | Faixa de renda familiar mensal         |\n| Q007           | Fam\u00edlia contrata empregada dom\u00e9stica   |\n| NOTA_MEDIA     | M\u00e9dia das notas objetivas <sup>2<\/sup> |\n| NU_NOTA_REDACAO| Nota da reda\u00e7\u00e3o                        |\n\n**Observa\u00e7\u00f5es:**\n\n1. Os valores poss\u00edveis para esse campo s\u00e3o: 1. N\u00e3o informou; 2. P\u00fablica; 3. Privada; 4. Exterior. Utilizamos nesta an\u00e1lise apenas os registros que apresetnem valor 1 ou 2 nesta propriedade.\n2. A *feature* NOTA_MEDIA \u00e9 calculada da seguinte forma: NOTA_MEDIA = (NU_NOTA_CN + NU_NOTA_CH + NU_NOTA_LC + NU_NOTA_MT) \/ 4\n","d48e1cfa":"### Prevendo a m\u00e9dia das provas objetivas","31d0ffd1":"###  Simplificando o problema\n\nA seguir, testamos alguns dos modelos utilizados anteriormente num problemas mais simples: reduzimos as dimens\u00f5es do dataset, utilizando apenas a nota m\u00e9dia das provas objetivas e a nota da reda\u00e7\u00e3o. Isso nos permite visualizar a dispers\u00e3o dos registros num plano.","d3a1580b":"Esse modelo tem acur\u00e1cia maior, mas, assim como o modelo de Random Forest, esse ganho se d\u00e1 como resultado de um vi\u00e9s de classifica\u00e7\u00e3o para a classe majorit\u00e1ria. Quando observamos a matriz de confus\u00e3o, percebemos que o modelo erra em quase 70% dos registros da classe minorit\u00e1ria.\n\nPor fim, usaremos um classificador que utiliza os modelos j\u00e1 treinados anteriormente como estimadores subjacentes para gerar uma classifica\u00e7\u00e3o pr\u00f3pria. Neste caso, atribu\u00edmos pesos iguais para todos modelos e o resultado da classifica\u00e7\u00e3o ser\u00e1 dado pela maioria simples de votos. \u00c9 poss\u00edvel testar diferentes combina\u00e7\u00f5es de pesos e alcan\u00e7ar um desempenho superior.","03f5e9b6":"### Pr\u00e9 processamento\n\nAgora, realizamos a normaliza\u00e7\u00e3o dos dados, a fim de acelerarmos o treinamento e teste dos modelos preditivos","d4096737":"**Autor:** Stefano Mozart Pontes Canedo de Souza.\n\n**Objetivo:**\n\nO objetivo deste projeto \u00e9 utilizar as t\u00e9cnicas apresentadas no curso para analisar poss\u00edveis diferen\u00e7as de rendimento entre escolas p\u00fablicas e privadas presentes nos microdados do Enem. A intui\u00e7\u00e3o, baseada em todo o hist\u00f3rico da educa\u00e7\u00e3o p\u00fablica no Brasil, \u00e9 que o rendimento dos egressos do ensino p\u00fablico seja, na m\u00e9dia, inferior \u00e0quele observado entre alunos de escolas privadas. \n\n**M\u00e9todo:**\n\nO m\u00e9todo de an\u00e1lise empregado contar\u00e1 com a constru\u00e7\u00e3o de dois grupos de modelos de classifica\u00e7\u00e3o: o primeiro, tentando classificar o aluno como egresso de escola p\u00fablica ou privada, a partir de suas notas. O segundo grupo, parte de informa\u00e7\u00f5es sociecon\u00f4micas, incluindo a classifica\u00e7\u00e3o da escola, para prever a nota esperada para um dado aluno.\n\nO que se deseja demonstrar com esses modelos \u00e9 que, caso os dados de fato apresentem uma diferen\u00e7a significativa nos resultados obtidos por alunos de escolas p\u00fablicas e privadas, essas diferen\u00e7as se refletir\u00e3o no poder de classifica\u00e7\u00e3o dos modelos treinados a partir desses dados.","b80d9a2f":"O mesmo se aplica \u00e0 nota m\u00e9dia nas provas objetivas:","7876db09":"### Utilizando um modelo mais complexo\n\nOs modelos utilizados at\u00e9 aqui s\u00e3o considerados modelos \"cl\u00e1ssicos\" de Machine Learning. A maior parte desses modelos prioriza a simplicidade e explicabilidade dos resultados. Mas \u00e9 poss\u00edvel que modelos de Deep Learning, mais compexos e mais dif\u00edceis de analizar, apresentem resultados superiores em termos de acur\u00e1cia.\n\nA seguir, utilizamos a biblioteca fast.ai, que utiliza embbedings e outras t\u00e9cnicas avan\u00e7adas para sele\u00e7\u00e3o, ajuste e treinamento de modelos.","e8efa8c9":"### Distribui\u00e7\u00e3o entre as classes\n\nAo analisarmos a distribui\u00e7\u00e3o de alunos entre os dois grupos, tanto no dataset original quanto nos subconjuntos de teste e treinamento, percebemos que o dataset \u00e9 bastante desbalanceado. Cerca de 83% dos elementos da amostra pertencem \u00e0 classe majorit\u00e1ria: alunos de escolas p\u00fablicas. Esse desbalanceamento ser\u00e1 levado em conta na an\u00e1lise dos modelos a seguir.","28c413b2":"## Classificando alunos a partir de suas notas\n\nPara o primeiro grupo de classificadores, utilizaremos as notas dos alunos, bem como sua classe de renda no question\u00e1rio s\u00f3cio-econ\u00f4mico, para classificar se o aluno \u00e9 egresso de escola p\u00fablica ou privada. \n\nO primeiro classificador utilizado \u00e9 o KNN, que agrupa ocorr\u00eancias da amostra a partir de um crit\u00e9rio de similaridade. O hiper-par\u00e2metro mais importante desse modelo \u00e9 justamente o n\u00famero de n\u00facleos a partir dos quais o modelo realizar\u00e1 o agrupamento. Nesse caso, utilizamos dois n\u00facleos, seguindo a intui\u00e7\u00e3o de que h\u00e1 dois grupos distintos no *dataset*: alunos egressos de escolas p\u00fablicas e privadas.","9c6bea54":"O desempenho do modelo de regress\u00e3o log\u00edstica \u00e9 ligeiramente superior ao do modelo anterior. A matriz de confus\u00e3o acima, no entanto n\u00e3o apresenta uma redu\u00e7\u00e3o significativa no vi\u00e9s de classifica\u00e7\u00e3o. Cerca de 26% das ocorr\u00eancias da classe minorit\u00e1ria foram classificadas incorretamente.\n\nA seguir, testaremos um modelo de \u00e1rvore de decis\u00e3o.","0f49269a":"Criamos vari\u00e1veis dummies para as demais colunas categ\u00f3rcas","dc084eac":"Para garantir a capacidade de compara\u00e7\u00e3o entre modelos, separamos o dataset em treinamento em teste, numa propor\u00e7\u00e3o de 80%\/20%.","0f02884a":"### Diferen\u00e7as entre as classes\n\nAo analizarmos, por exemplo, a nota da reda\u00e7\u00e3o, podemos concluir que existe uma diferen\u00e7a estatisticamente significante entre os dois grupos","f20c7ac1":"Esse classificador tem desempenho ligeriamente superior ao dos modelos de regress\u00e3o log\u00edstica e \u00e1rvore de decis\u00e3o. Sua acur\u00e1cia, assim como nos classificadores anteriores, \u00e9 afetada pela porcentagem de erros na classe majorit\u00e1ria.\n\nO pr\u00f3ximo classificador utilizado \u00e9 o XGBoost (eXtreme Gradient Boosting), que utiliza diversos modelos de \u00e1rvore de decis\u00e3o como estimadores subjacentes, mas faz uma otimiza\u00e7\u00e3o da busca por hiperpar\u00e2metros \u00f3timos, de acordo com a tarefa selecionada. Nesse experimento, utilizamos o par\u00e2metro objective='multi:softmax' para que modelo otimize os par\u00e2metros para classifica\u00e7\u00e3o.","90cd8fec":"E, para fins de compara\u00e7\u00e3o dos modelos, separamos o dataset em treinamento em teste, numa propor\u00e7\u00e3o de 80%\/20%\n","fd3027c0":"O teste nos mostra que a diferen\u00e7a entre as m\u00e9dias \u00e9 estatisticamente significativa. O poder do teste \u00e9 1. Abaixo, vemos os histogramas das duas classes.","b04fce95":"### Prevendo a nota da reda\u00e7\u00e3o\n\nAlteramos a vari\u00e1vel-alvo e repetimos o processo de particionamento do dataset.","807f35bf":"## Enap - Machine Learning em Projetos\n\n### Projeto Final\n\n# An\u00e1lise de microdados do Enem: diferen\u00e7as de rendimento entre alunos de escolas p\u00fablicas e privadas","8f898c63":"O resultado acima, com acur\u00e1cia de cerca de 83%, que \u00e9 a propor\u00e7\u00e3o de elementos da classe majorit\u00e1ria (escola p\u00fablica), com score F1 da classe minorit\u00e1ria (privada) abaixo de 30%, indicam que, muito provavelmente, o classificador KNN \u00e9 simples demais para modelar o problema proposto. O poder de classifica\u00e7\u00e3o modelado ainda n\u00e3o apresenta evidencia forte o suficiente da diferen\u00e7a de rendimento entre alunos de escolas p\u00fablicas e privadas. A matriz de confus\u00e3o acima, por sua vez, indica que o modelo erra bastante dado ao vi\u00e9s da classe majorit\u00e1ria. Prosseguimos, ent\u00e3o, nosso experimento com mais 3 classificadores.\n\nO pr\u00f3ximo modelo utilizado \u00e9 o de descida de gradiente estoc\u00e1stica (SGD), selecionamos a fun\u00e7\u00e3o de custo (loss) do tipo 'modified_huber', que resulta num modelo de regress\u00e3o linear que \u00e9 mais robusto contra outliers. A fun\u00e7\u00e3o de custo (loss) do tipo \"elasticnet\" favorece a sele\u00e7\u00e3o de vari\u00e1veis (feature selection) durante o pr\u00f3prio treinamento. Tendo em vista o desbalanceamento entre as classes, utilizaremos o par\u00e2metro class_weight=\"balanced\", que pondera a fun\u00e7\u00e3o de erro por um fator inversamente proporcional \u00e0 participa\u00e7\u00e3o da classe na amostra.","d8a90bd6":"O classificador final tem acur\u00e1cia semelhante a dos modelos de Random Forest e XGBoost, mas com desempenho superior quando consideramos sua atua\u00e7\u00e3o na classe minorit\u00e1ria.\n\nEsse resultado nos mostra que os modelos de fato captam uma diferen\u00e7a nas notas de alunos de escolas p\u00fablicas e privadas. Todos os modelos foram instanciados com a maior parte dos hiperpar\u00e2metros em seu valor padr\u00e3o. \u00c9 poss\u00edvel que a aplica\u00e7\u00e3o de t\u00e9cnicas de otimiza\u00e7\u00e3o de hiperpar\u00e2metros produza modelos ainda melhores.","4720536a":"Embora apresente um score f1 melhor para a classe minorit\u00e1ria, e tenha acur\u00e1cia melhor para essa classe (a matriz de confus\u00e3o nos mostra 75% de acerto na classe minorit\u00e1ria), a acur\u00e1cia ponderada para todo a amostra \u00e9 baixa, tendo em vista o percentual de 26% erros na classe majorit\u00e1ria.\n\nO pr\u00f3ximo modelo utilizado ser\u00e1 o de regress\u00e3o log\u00edstica.","9d32bd42":"O modelo de \u00e1rvore de decis\u00e3o teve desempenho muito similar ao do modelo de regress\u00e3o log\u00edstica, em ambas as classes. Mais uma vez, \u00e9 importante notar que a acur\u00e1cia de quase 75% se deve ao fato de que o modelo erra na classifica\u00e7\u00e3o de cerca um quarto dos registros da classe majorit\u00e1ria.\n\nO pr\u00f3ximo modelo utilizado \u00e9 o RandomForest, que cria, internamente, uma s\u00e9rie de \u00e1rvores de decis\u00e3o e apresenta, como resultado de classifica\u00e7\u00e3o, uma combina\u00e7\u00e3o das respostas apresentadas pelas diversas \u00e1rvores treinadas com os dados."}}