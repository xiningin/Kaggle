{"cell_type":{"84778f34":"code","9be47e78":"code","6faf7eca":"code","56cb8fa4":"code","841e5ddc":"code","2fb8a3bb":"code","e03f347a":"code","80815e4c":"code","ea1ec34e":"code","af5d6193":"code","44235e24":"code","24321d17":"code","1589541d":"code","91372899":"code","25e072f7":"code","4be3cd70":"code","907897ec":"code","39f1d9e5":"code","18debd45":"code","c98a662e":"code","9040ba95":"code","017f853c":"code","0bff2436":"code","c6a106bd":"code","90b5e5f6":"code","95350bb9":"code","66d89293":"code","894791ca":"code","e6880807":"code","7801df91":"code","11b14f3b":"code","a905cd91":"code","a7810459":"code","f0749fbc":"code","b4453f8d":"code","f106adfb":"code","5ac15fd3":"code","846e19b6":"code","ac0fe259":"code","dce0fb60":"code","44b7298a":"code","84911512":"markdown","2bc94338":"markdown","7f8d8d57":"markdown","37a25ac7":"markdown","54a844aa":"markdown","2a488ff5":"markdown","c76ba0ab":"markdown","274ba58f":"markdown"},"source":{"84778f34":"# In a regression problem, we aim to predict the output of a continuous value, like a price or a probability. \n# Contrast this with a classification problem, where we aim to predict a discrete label (for example, where a \n# picture contains an apple or an orange).\n# \n# This notebook uses the classic Auto MPG Dataset and builds a model to predict the fuel efficiency of late-1970s \n# and early 1980s automobiles. To do this, we'll provide the model with a description of many models from that time period. \n# \n# This description includes attributes like: cylinders, displacement, horsepower, and weight.\n# \n# This example uses the tf.keras API, and mentioned in TensorFlow tutorial page. Here I tried to use the same\n# dataset and enhanced whenever I could.","9be47e78":"from __future__ import absolute_import, division, print_function\n\nimport pathlib\nimport pandas as pd\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ML Libraries: \nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import preprocessing\nfrom sklearn.utils import shuffle\n\nimport plotly.figure_factory as ff\nimport plotly.offline as py \nimport plotly.graph_objs as go \nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nfrom plotly import tools \npy.init_notebook_mode (connected = True)\n\nimport cufflinks as cf\ncf.go_offline()\nimport platform\n\nprint(tf.__version__)\nprint(platform.python_version())","6faf7eca":"# The Auto MPG dataset\n# --------------------\n# The dataset is available from the UCI Machine Learning Repository.\n# \n# Get the data\n# First download the dataset.\n\n#dataset_path = keras.utils.get_file(\"auto-mpg.data\", \"https:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/auto-mpg\/auto-mpg.data\")\n#dataset_path","56cb8fa4":"# Import it using pandas\n\ncolumn_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n                'Acceleration', 'Model Year', 'Origin'] \n# raw_dataset = pd.read_csv(\"..\/input\/auto-mpg.csv\", names=column_names,\n#                       na_values = \"?\", comment='\\t',\n#                       sep=\" \", skipinitialspace=True)\n\nraw_dataset = pd.read_csv(\"..\/input\/auto-mpg.csv\")\n\ndataset = raw_dataset.copy()\ndataset.tail()","841e5ddc":"# Clean the data\n# --------------\n# The dataset contains a few unknown values.\n\ndataset.isna().sum()","2fb8a3bb":"# To keep this initial tutorial simple drop those rows.\n\ndataset = dataset.dropna()\n\n# The \"Origin\" column is really categorical, not numeric. So convert that to a one-hot:\n\norigin = dataset.pop('origin')\ndataset['USA'] = (origin == 1)*1.0\ndataset['Europe'] = (origin == 2)*1.0\ndataset['Japan'] = (origin == 3)*1.0\ndataset.tail()","e03f347a":"# Split the data into train and test\n# ----------------------------------\n# \n# Now split the data into a train and a test set.\n# We will use the test set in the final evaluation of out model.\n\ntrain_dataset = dataset.sample(frac=0.8,random_state=0)\ntest_dataset = dataset.drop(train_dataset.index)\n\n#Let's copy training dataset into working dataset for data visualization\nworking_dataset = train_dataset.copy();\n\ntrain_dataset.pop('car name')\ntest_dataset.pop('car name')\n# Breif information about the Data Sets\ntrain_dataset.info()\nprint(\"________________________________\")\ntest_dataset.info()\n","80815e4c":"working_dataset['Continent'] = np.where(working_dataset['USA'] == 1.0, 'USA',\n                                np.where(working_dataset['Japan'] == 1.0, 'Japan', 'Europe'))\nworking_dataset.tail()","ea1ec34e":"usa = working_dataset[working_dataset[\"USA\"]==1.0]\neurope = working_dataset[working_dataset[\"Europe\"]==1.0]\njapan = working_dataset[working_dataset[\"Japan\"]==1.0]\n\nusa_car_count = working_dataset[\"USA\"].value_counts()\neurope_car_count = working_dataset[\"Europe\"].value_counts()\njapan_car_count = working_dataset[\"Japan\"].value_counts()\n\nworking_dataset = shuffle(working_dataset)\ntrain_continet_car_count = working_dataset[\"Continent\"].value_counts()\n\ntest_dataset = shuffle(test_dataset)\ntest_continet_car_count = test_dataset[\"mpg\"].count()\n\nprint(usa_car_count)\nprint(europe_car_count)\nprint(japan_car_count)\n\nprint(\"Training Set Car Count \", train_continet_car_count)\nprint(\"Test Set Car Count\", test_continet_car_count)","af5d6193":"#1. Pie Chart for car count\ncolors = ['aqua', 'pink', 'teal']\n\ntrace_train= go.Pie(labels = train_continet_car_count.index,\n              values = train_continet_car_count.values, marker=dict(colors=colors))\n\nlayout = go.Layout(title = \"Training Data :: Car Distribution\")\ndata = [trace_train]\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)","44235e24":"# 1 Boxplot \n\nusa = working_dataset[working_dataset[\"Continent\"]==\"USA\"]\neurope = working_dataset[working_dataset[\"Continent\"]==\"Europe\"]\njapan = working_dataset[working_dataset[\"Continent\"]==\"Japan\"]\n\ntrace = go.Box(y = usa[\"mpg\"],fillcolor=\"aqua\", name= \"USA\" )\ntrace1 = go.Box(y = europe[\"mpg\"], fillcolor=\"pink\", name= \"Europe\" )\ntrace2 = go.Box(y = japan[\"mpg\"], fillcolor=\"teal\", name= \"Japan\" )\n\nlayout = go.Layout(title=\"Fuel Efficiency Distribution w.r.t Continent :: [Box Plot]\", \n                   yaxis=dict(title=\"Fuel Efficiency (mile per gallon)\"), \n                   xaxis= dict(title=\"Continent (USA \/ Europe  \/Japan)\"))\n\ndata=[trace, trace1, trace2]\nfig = go.Figure(data = data, layout=layout)\npy.iplot(fig)\n\n# 2 Violin Plot \ntrace1 = go.Violin( y = usa[\"mpg\"], fillcolor=\"aqua\", name=\"USA\")\ntrace2 = go.Violin( y = europe[\"mpg\"],fillcolor=\"pink\", name=\"Europe\")\ntrace3 = go.Violin( y = japan[\"mpg\"],fillcolor=\"teal\", name=\"Japan\")\n\nlayout = go.Layout(title=\"Fuel Efficiency Distribution w.r.t Continent :: [Violin Plot]\", \n                   yaxis=dict(title=\"Fuel Efficiency (mile per gallon)\"), \n                   xaxis= dict(title=\"Continent (USA \/ Europe  \/Japan)\"))\n\ndata=[trace1, trace2, trace3]\nfig = go.Figure(data = data, layout=layout)\npy.iplot(fig)","24321d17":"# Car vs Mileage \n#age_count = df[\"Age\"].dropna().value_counts()\ntop_fifteen_train_dataset = working_dataset.nlargest(15, 'mpg')\ntrain_car_names = top_fifteen_train_dataset[\"car name\"].dropna()\ntrain_car_mileage = top_fifteen_train_dataset[\"mpg\"].dropna()\nprint(train_car_mileage)\ntrace = go.Bar(x = train_car_names,\n              y = train_car_mileage, \n              marker = dict(color = train_dataset[\"mpg\"],\n                           colorscale = \"Jet\", \n                           showscale = True))\nlayout = go.Layout(title = \"Car Mileage Distribution :: Most Fuel Efficient Cars (Top 15)\", \n                  yaxis = dict(title = \"Fuel Efficiency\"))\ndata = [trace]\nfig = go.Figure(data = data, layout = layout)\npy.iplot(fig)","1589541d":"# Displacement vs Mileage [Scatter Plot]\ntrain_displacements = working_dataset[\"displacement\"].dropna()\ntrace = go.Scatter(x = train_displacements, y = working_dataset[\"mpg\"].dropna(), \n              mode = 'markers',                 \n              marker = dict(color = train_dataset[\"mpg\"],\n                           colorscale = \"Jet\", \n                           showscale = True))\nlayout = go.Layout(title = \"Diasplacement vs Mileage Distribution :: [Scatter Plot]\", \n                  xaxis = dict(title = 'Car Displacement'), \n                  yaxis = dict(title = 'Car Fuel Efficiency (mile per gallon)'))\ndata = [trace]\nfig = go.Figure(data = data, layout = layout)\npy.iplot(fig)","91372899":"# Inspect the data\n# ----------------\n\n# Have a quick look at the joint distribution of a few pairs of columns from the training set.\n\nsns.pairplot(working_dataset[[\"mpg\", \"cylinders\", \"displacement\", \"weight\"]], diag_kind=\"kde\")","25e072f7":"# Also look at the overall statistics:\n\ntrain_stats = train_dataset.describe()\ntrain_stats.pop(\"mpg\")\ntrain_stats = train_stats.transpose()\ntrain_stats","4be3cd70":"# Training Set Car Count\ntrace = go.Bar(x = ['USA', 'Europe', 'Japan'],\n              y = [usa['mpg'].count(),europe['mpg'].count(), japan['mpg'].count()], \n              marker = dict(color = [111, 10, 225, 175],\n                           colorscale = \"Viridis\", \n                           showscale = True))\nlayout = go.Layout(title = \"Training Set Car Count \", \n                  yaxis = dict(title = \"Car Count\"))\ndata = [trace]\nfig = go.Figure(data = data, layout = layout)\npy.iplot(fig)","907897ec":"# Plotting HeatMap\n# print(working_dataset[\"Continent\"].unique())\ntrace = go.Heatmap(z=working_dataset[[\"displacement\", \"mpg\", \"cylinders\", \"horsepower\", \"model year\"]].dropna().values,\n                   x=['Displacement', 'MPG', 'Cylinders', 'Horsepower', 'Model Year'],\n#                    y=['USA', 'Europe', 'Japan'],\n                   colorscale = 'Viridis')\n#                    y=[\"USA\", \"Europe\", \"Japan\"])\nlayout = go.Layout(title = \"Displacement, MPG, Cylinders, Horsepower, Model Year Distribution\",\n                  yaxis = dict(title = \"Car Record Count\"))\ndata = [trace]\nfig = go.Figure(data = data, layout = layout)\npy.iplot(fig)","39f1d9e5":"#Data preparation for plotting various charts\ndf = working_dataset.copy()\ndf['Origin'] = np.where(df['Continent'] == 'USA', 1,\n                                np.where(df['Continent'] == 'Europe', 2, 3))\ndf.tail()    ","18debd45":"#Ploting Stacked Bar Chart\ndf.iplot(kind='bar', barmode='stack', filename='cufflinks\/grouped-bar-chart')\n\n#Plotting Bubble Chart\ndf.iplot(kind='bubble', x='displacement', y='mpg', size='Origin', text='Continent',\n             xTitle='Displacement', yTitle='Fuel Efficiency (mpg)', colors='rgb(255,0,0)', \n             filename='simple-bubble-chart')","c98a662e":"# Separate the target value, or \"label\", from the features. This label is the value that you \n# will train the model to predict.\ntrain_labels = train_dataset.pop('mpg')\ntest_labels = test_dataset.pop('mpg')\ntrain_dataset.tail()","9040ba95":"# Look again at the train_stats block above and note how different the ranges of each feature are.\n# It is good practice to normalize features that use different scales and ranges. Although the model \n# might converge without feature normalization, it makes training more difficult, and it makes the \n# resulting model dependent on the choice of units used in the input.\n\n# This normalized data is what we will use to train the model.\n\ntrain_dataset.dropna()\ntest_dataset.dropna()\n\ntrain_dataset.pop('horsepower')\ntest_dataset.pop('horsepower')\n\ndef norm(x):\n    return (x - train_stats['mean']) \/ train_stats['std']\n\nnormed_train_data = norm(train_dataset)\nnormed_test_data = norm(test_dataset)","017f853c":"# Let's build our model. Here, we'll use a TensorFlow Keras Sequential model with two densely \n# connected hidden layers, and an output layer that returns a single, continuous value. The model \n# building steps are wrapped in a function, build_model, since we'll create a second model, later on.\n\ndef build_model():\n  model = keras.Sequential([\n    layers.Dense(64, activation=tf.nn.relu, input_shape=[len(train_dataset.keys())]),\n    layers.Dense(64, activation=tf.nn.relu),\n    layers.Dense(1)\n  ])\n\n  optimizer = tf.train.RMSPropOptimizer(0.001)\n\n  model.compile(loss='mse',\n                optimizer=optimizer,\n                metrics=['mae', 'mse'])\n  return model\nmodel = build_model()\n","0bff2436":"# Use the .summary method to print a simple description of the model\n\nmodel.summary()","c6a106bd":"# Now try out the model. Take a batch of 10 exampes from the training data and call \n# model.predict on it.\n\nexample_batch = normed_train_data[:10]\nexample_result = model.predict(example_batch)\nexample_result\n","90b5e5f6":"# Train the model\n# ---------------\n\n# The model is trained for 1000 epochs, and record the training and validation accuracy in the history object.\n\n# Display training progress by printing a single dot for each completed epoch\nclass PrintDot(keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs):\n    if epoch % 100 == 0: print('')\n    print('.', end='')\n\nEPOCHS = 1000\n\nhistory = model.fit(\n  normed_train_data, train_labels,\n  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n  callbacks=[PrintDot()])","95350bb9":"# Visualize the model's training progress using the stats stored in the history object.\n\nhist = pd.DataFrame(history.history)\nhist['epoch'] = history.epoch\nhist.tail()","66d89293":"import matplotlib.pyplot as plt\n\ndef plot_history(history):\n  plt.figure()\n  plt.xlabel('Epoch')\n  plt.ylabel('Mean Abs Error [MPG]')\n  plt.plot(hist['epoch'], hist['mean_absolute_error'],\n           label='Train Error')\n  plt.plot(hist['epoch'], hist['val_mean_absolute_error'],\n           label = 'Val Error')\n  plt.legend()\n  plt.ylim([0,5])\n  \n  plt.figure()\n  plt.xlabel('Epoch')\n  plt.ylabel('Mean Square Error [$MPG^2$]')\n  plt.plot(hist['epoch'], hist['mean_squared_error'],\n           label='Train Error')\n  plt.plot(hist['epoch'], hist['val_mean_squared_error'],\n           label = 'Val Error')\n  plt.legend()\n  plt.ylim([0,20])\n\nplot_history(history)","894791ca":"# This graph shows little improvement, or even degradation in the validation error after a few \n# hundred epochs. Let's update the model.fit method to automatically stop training when the \n# validation score doesn't improve. We'll use a callback that tests a training condition for \n# every epoch. If a set amount of epochs elapses without showing improvement, then automatically \n# stop the training.\n\n# You can learn more about this callback here.\n\nmodel = build_model()\n\n# The patience parameter is the amount of epochs to check for improvement\nearly_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n\nhistory = model.fit(normed_train_data, train_labels, epochs=EPOCHS,\n                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])\n\nplot_history(history)","e6880807":"# The graph shows that on the validation set, the average error usually around +\/- 2 MPG. Is this good? \n# We'll leave that decision up to you.\n\n# Let's see how did the model performs on the test set, which we did not use when training the model:\n\nloss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=0)\n\nprint(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae))","7801df91":"# Make predictions\n# ----------------\n\n# Finally, predict MPG values using data in the testing set:\n\ntest_predictions = model.predict(normed_test_data).flatten()\n\nplt.scatter(test_labels, test_predictions)\nplt.xlabel('True Values [MPG]')\nplt.ylabel('Predictions [MPG]')\nplt.axis('equal')\nplt.axis('square')\nplt.xlim([0,plt.xlim()[1]])\nplt.ylim([0,plt.ylim()[1]])\n_ = plt.plot([-100, 100], [-100, 100])","11b14f3b":"error = test_predictions - test_labels\nplt.hist(error, bins = 25)\nplt.xlabel(\"Prediction Error [MPG]\")\n_ = plt.ylabel(\"Count\")","a905cd91":"# This notebook introduced a few techniques to handle a regression problem.\n\n#     1. Mean Squared Error (MSE) is a common loss function used for regression problems \n#        (different than classification problems).\n#     2. Similarly, evaluation metrics used for regression differ from classification. A common \n#        regression metric is Mean Absolute Error (MAE).\n#     3. When input data features have values with different ranges, each feature should be scaled independently.\n#     4. If there is not much training data, prefer a small network with few hidden layers to avoid overfitting.\n#     5. Early stopping is a useful technique to prevent overfitting.","a7810459":"# Features Scaling\ncolumns = normed_train_data.columns\ncolumn_test = normed_test_data.columns\ny_train = train_labels.copy()\n\nlab_enc = preprocessing.LabelEncoder()\ny_train_encoded = lab_enc.fit_transform(y_train)\n\nscaler = preprocessing.Normalizer()\nX_train = scaler.fit_transform(normed_train_data)\nX_train = pd.DataFrame(X_train, columns=columns)\n\nX_test = scaler.transform(normed_test_data)\nX_test = pd.DataFrame(X_test, columns=column_test)","f0749fbc":"# Scikit learn Logistic Regression\nlog = LogisticRegression()\nlog.fit(X_train, y_train_encoded)\n\npred_log = log.predict(X_test)\n\nlog.score(X_train, y_train_encoded)\nlogistic_score = round(log.score(X_train, y_train_encoded)*100,2)\nlogistic_score","b4453f8d":"# Scikit learn RandomForestClassifier\nrf = RandomForestClassifier()\nrf.fit(X_train, y_train_encoded)\npred_random = rf.predict(X_test)\n\nrf.score(X_train, y_train_encoded)\n\nrandom_score = round(rf.score(X_train, y_train_encoded)*100,2)\nrandom_score","f106adfb":"# Scikit learn DecisionTreeClassifier\n\ntree = DecisionTreeClassifier()\ntree.fit(X_train, y_train_encoded)\n\npred_tree = tree.predict(X_test)\n\ntree.score(X_train, y_train_encoded)\ntree_score = round(tree.score(X_train, y_train_encoded)*100,2)\ntree_score","5ac15fd3":"# Scikit learn KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors=1)\nknn.fit(X_train, y_train_encoded)\npred_knn = knn.predict(X_test)\n\nknn.score(X_train, y_train_encoded)\nknn_score = round(knn.score(X_train, y_train_encoded)*100,2)\nknn_score","846e19b6":"# Scikit learn GaussianNB (Gaussian Naive Bayes)\n\ngaus = GaussianNB()\ngaus.fit(X_train, y_train_encoded)\npred_gaus = gaus.predict(X_test)\n\ngaus.score(X_train, y_train_encoded)\ngaus_score = round(gaus.score(X_train, y_train_encoded)*100,2)\ngaus_score","ac0fe259":"# Scikit learn Perceptron\n\nper = Perceptron(max_iter=5)\nper.fit(X_train, y_train_encoded)\n\nperd_per = per.predict(X_test)\n\nper.score(X_train, y_train_encoded)\nperceptron_score = round(per.score(X_train, y_train_encoded) * 100, 2)\nperceptron_score","dce0fb60":"# Scikit learn LinearSVC (Linear Support Vector Machine)\n\nsvc = LinearSVC()\nsvc.fit(X_train, y_train_encoded)\n\npred_svc = svc.predict(X_test)\n\nsvc.score(X_train, y_train_encoded)\nsvc_score = round(svc.score(X_train, y_train_encoded) * 100, 2)\nsvc_score","44b7298a":"df_score = pd.DataFrame({\"Models\": ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', 'Decision Tree'], \n                       \"Score\": [svc_score, knn_score, logistic_score, random_score, gaus_score, \n                                 perceptron_score, tree_score]})\ndf_score.sort_values(by= \"Score\", ascending=False)","84911512":"**Model scores at a glance**","2bc94338":"**Data Visualization**","7f8d8d57":"**Scikit Learn Modeling**","37a25ac7":"**Normalize the data**","54a844aa":"**Inspect the model**","2a488ff5":"**Build the model**","c76ba0ab":"**Split features from labels**","274ba58f":"**Try Different Scikit Learn Models and Evaluate Model Score**"}}