{"cell_type":{"4b4d7fd7":"code","fc317391":"code","296c77c6":"code","1b8a9824":"code","92b6674e":"code","0411009b":"code","63c51935":"code","d9397676":"code","a8ed9f2a":"markdown","0438eb58":"markdown","ba8bf37d":"markdown","8373ed97":"markdown","1ecf6600":"markdown","1bd534f7":"markdown","7c0523f0":"markdown","78019388":"markdown","edcaf1b0":"markdown","e1e74bd0":"markdown","ec91c17a":"markdown"},"source":{"4b4d7fd7":"import os\nimport torch \nimport glob \nimport torch.nn as nn\nimport torchvision.datasets as dsets\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport torchvision\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\n\n\nfrom torchvision import datasets\nfrom torchvision import transforms\nimport copy\nimport tqdm\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\n","fc317391":"if torch.cuda.is_available():        \n    device = torch.device(\"cuda\")\nelse:\n    device = torch.device(\"cpu\")\nprint(\"device:\", device)\n","296c77c6":"def pytorchdata():\n    sz=224\n    train_dir='..\/input\/cat-and-dog\/training_set\/training_set'\n    test_dir='..\/input\/cat-and-dog\/test_set\/test_set'\n    train=glob.glob(f'{train_dir}\/*\/*.jpg')\n    #train_ds=datasets.ImageFolder(train_dir)\n    tfms = transforms.Compose([\n        transforms.Resize((sz, sz)),  # PIL Image\n        transforms.ToTensor(),        # Tensor\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n\n    train_ds = datasets.ImageFolder(train_dir, transform = tfms)\n\n    train_dl = torch.utils.data.DataLoader(train_ds, batch_size=32, \n                                           shuffle=True)\n    test_dir='..\/input\/cat-and-dog\/training_set\/training_set'\n    #test_ds=datasets.ImageFolder(test_dir)\n    tfms1 = transforms.Compose([\n        transforms.Resize((sz, sz)),  # PIL Image\n        transforms.ToTensor()\n    ])\n    test_ds=datasets.ImageFolder(test_dir,transform=tfms1)\n    test_dl=torch.utils.data.DataLoader(test_ds,batch_size=32,shuffle=True)\n    \n    return train_dl,test_dl,train_ds,test_ds\n    \n","1b8a9824":"train_dl,test_dl,train_ds,test_ds=pytorchdata()","92b6674e":"image,label=iter(train_dl).next()\nprint(type(image),type(label))\nprint(image.size(),(label.size()))\n","0411009b":"input_size=224*224*3\nnum_classes=2\nnum_epochs=20\nlrate=0.01","63c51935":"class LogisticRegression(nn.Module):\n    def __init__(self,input_size,input_class):\n        super(LogisticRegression,self).__init__()\n        self.linear=nn.Linear(input_size,num_classes)\n    def forward(self,x):\n        out=self.linear(x)\n        return out\n    \nmodel=LogisticRegression(input_size,num_classes) \ncriterian=nn.CrossEntropyLoss()\noptimizer=torch.optim.SGD(model.parameters(),lr=lrate)\n\n\ndef train(train_dl):\n    model.train()\n    runnig_loss=0\n    for batch_idx , (images,labels) in enumerate(train_dl):\n\n        images=Variable(images.view(-1,224*224*3))\n        labels=Variable(labels)\n        optimizer.zero_grad()\n        outputs=model(images)\n        \n        loss=criterian(outputs,labels)\n        runnig_loss+=loss\n        loss.backward()\n        optimizer.step()\n    train_loss=runnig_loss\/len(train_dl)\n    return train_loss\n        \n        \ndef valid(test_dl):\n    model.eval()\n    runnig_loss=0\n    correct=0\n    total=0\n    for batch_size,(images,labels) in enumerate(test_dl):\n        images=Variable(images.view(-1,224*224*3))\n        labels=Variable(labels)\n        outputs=model(images)\n        loss=criterian(outputs,labels)\n        runnig_loss+=loss\n                       \n        _,predicted=torch.max(outputs.data,1)\n        correct+=(predicted==labels.data).sum()\n        total+=labels.size(0)\n    val_loss=runnig_loss\/len(test_dl)\n    val_acc=correct\/total\n    return val_loss,val_acc\n\n\nloss_list=[]\nval_loss_list=[]\nval_acc_list=[]\nfor epoch in range(num_epochs):\n    loss=train(train_dl)\n    val_loss,val_acc=valid(test_dl)\n    print('epoch %d, loss: %.4f val_loss: %.4f val_acc: %.4f'\n          % (epoch, loss, val_loss, val_acc))\n    \n    loss_list.append(loss)\n    val_loss_list.append(val_loss)\n    val_acc_list.append(val_acc)\n    \n    \n    \n        ","d9397676":"import pathlib \nimport glob as gb\ntrain_path='..\/input\/cat-and-dog\/training_set\/training_set'\n\ndef classes_and_code():\n    root=pathlib.Path(train_path)\n    classes=[ i for i in os.listdir(train_path) if '.' not in i]\n    Code=[]\n    for i in range(len(classes)):\n        Code+={classes[i]}\n        Code+=[i]\n    code={Code[i]:Code[i+1] for i in range(0,len(Code),2)}\n    \n    return classes,code\nclasses,code=classes_and_code()\ndef X_and_Y(size=224):\n    classes,code=classes_and_code()\n    \n    X=[]\n    Y=[]\n    for folder in os.listdir(train_path):\n        files=gb.glob(str(train_path+'\/'+folder+'\/*.jpg'))\n        for file in files:\n            image=cv2.imread(file)\n            image_array=cv2.resize(image,(size,size))\n            X.append(list(image_array))\n            Y.append(code[folder])\n            \n        \n            \n    X=np.array(X)\n    Y=np.array(Y)\n    return X,Y\nX,y=X_and_Y()","a8ed9f2a":"len(files)","0438eb58":"\ndef extract_path(puth):\n    return puth[0]","ba8bf37d":"train_dataset = DataPrepararion(train, transform_pipe, device)\nval_dataset = DataPrepararion(valid, transform_pipe, device)\ntest_dataset = DataPrepararion(test, transform_pipe, device)\n","8373ed97":"\ntrain_imgs, val_imgs, train_target, val_target = train_test_split(train_imgs, train_target, test_size=0.2, random_state=0, stratify=train_target)","1ecf6600":"class CatDogDataset(Dataset):\n    def __init__(self,file_list,dir,mode='train',transform=None):\n        self.file_list=file_list\n        self.dir=dir\n        self.mode=mode\n        self.transform=transform\n        if self.mode=='train':\n            if 'dog'in self.file_list[0]:\n                self.lebel=1\n            else:\n                self.label=0\n                \n    def __len__(self):\n        return len(self.file_list)\n    def __getitem__(self,idx):\n        img=Image.open(os.path.join(self.dir),self.file_list[idx])\n        if self.transform:\n            img=self.transform\n        if self.mode=='train':\n            img=img.numpy()\n            return img.astype('float32'),self.label\n        else:\n            img=img.numpy()\n            return img.astype('float32'),self.file_list[idx]\n        \ndata_transform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.ColorJitter(),\n    transforms.RandomCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.Resize(128),\n    transforms.ToTensor()\n])\ncat_files = [tf for tf in train_files if 'cat' in tf]\ndog_files = [tf for tf in train_files if 'dog' in tf]\n\ncats = CatDogDataset(cat_files, train_dir, transform = data_transform)\ndogs = CatDogDataset(dog_files, train_dir, transform = data_transform)\n\ncatdogs = ConcatDataset([cats, dogs])\n","1bd534f7":"train=pd.concat([train_imgs,train_target],axis=1)\nvalid=pd.concat([val_imgs,val_target],axis=1)\ntest=pd.concat([test_imgs,val_target],axis=1)","7c0523f0":"transform_pipe = transforms.Compose([#transforms.RandomCrop(size=[256, 256], pad_if_needed=True),\n                                     transforms.Resize((256,256),interpolation=Image.BILINEAR),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n                                    ])\n","78019388":"\n\nclass DataPrepararion(Dataset):\n    \n    def __init__(self, data, transform_pipe, device):\n        self.data = data\n        self.transform_pipe = transform_pipe\n        self.device = device\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        item = self.data.iloc[idx, :]\n        image = Image.open(item[\"path\"]).convert(\"RGB\")\n        \n        #image = self.transform_pipe(image).to(self.device)\n        if item[\"label\"] == 0:\n            label = torch.zeros(size=(1,1)).to(self.device)\n        else:\n            label = torch.ones(size=(1,1)).to(self.device)\n        return [image, label]\n\n","edcaf1b0":"def keras_dataset():\n    from keras.preprocessing.image import ImageDataGenerator\n\n\n    train_data = ImageDataGenerator(rescale = 1.\/255,shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n\n\n\n    training_set = train_data.flow_from_directory('..\/input\/cat-and-dog\/training_set\/training_set', batch_size = 64, target_size = (224,224), class_mode = 'binary')\n    \n    test_dir=ImageDataGenerator(rescale=1.\/255)\n    test_set=train_data.flow_from_directory('..\/input\/cat-and-dog\/test_set\/test_set',batch_size=64,target_size=224)\n    return train_set,test_set\n\n","e1e74bd0":"\n\n\ndef train_image_number(print_n=False):\n    summation=[]\n    for folder in os.listdir(train_path):\n        files=glob.glob(str(train_path+'\/'+folder+'\/*.jpg'))\n        if print_n==True:\n            \n            print(f' for training data , found {len(files)} in folder { folder} \\n')\n        summation.append(len(files))\n    return summation  ","ec91c17a":"train=datasets.ImageFolder('..\/input\/cat-and-dog\/training_set\/training_set')\ntest=datasets.ImageFolder('..\/input\/cat-and-dog\/test_set\/test_set')\ntrain_imgs = pd.Series(train.imgs, name = \"path\").apply(func=extract_path)\ntest_imgs = pd.Series(test.imgs, name = \"path\").apply(func=extract_path)\n\n\ntrain_target = pd.Series(train.targets, name =\"label\")\ntest_target = pd.Series(test.targets, name =\"label\")"}}