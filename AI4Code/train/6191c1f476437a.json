{"cell_type":{"1fc96df4":"code","6f0e6927":"code","a7d0cea8":"code","6ddb2e79":"code","9d4694a5":"code","5d49f840":"code","72210f48":"code","1c6a46b4":"code","b004c9e2":"code","1d4816f8":"code","615b909d":"code","51035ac2":"code","a79e612a":"code","1c827c9d":"code","748f934f":"code","a53ae00b":"code","0e6df297":"code","459d16c9":"code","cc957f23":"code","d29e6e7a":"code","a2b08f59":"code","8225b411":"code","8a5350f7":"code","9f3fdb59":"code","6a9dc98a":"code","ecb53516":"code","f5982e49":"code","443acbc4":"code","dca938b5":"code","83bdcf05":"code","bb603cdf":"code","8ae6eadd":"code","23190f2e":"code","6f2e1e37":"code","10f88078":"code","cd366132":"code","a3aebd6f":"code","360c8517":"code","cd006546":"code","45803660":"code","636be19a":"code","215090f0":"code","e33a3492":"code","6658c27b":"code","f96e5d6e":"code","a75ffe06":"code","251f862d":"code","570006c7":"code","d1497759":"code","6c32dbbc":"code","01761426":"code","4bbd46da":"markdown","a2b57c75":"markdown","aee56efb":"markdown","0516b09d":"markdown"},"source":{"1fc96df4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6f0e6927":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader","a7d0cea8":"# Hyperparameters etc.\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nLEARNING_RATE = 1e-4\nBATCH_SIZE = 64\nIMAGE_SIZE = 64\nCHANNELS_IMG = 3\nZ_DIM = 100\nNUM_EPOCHS = 10\nFEATURES_DISC = 64\nFEATURES_GEN = 64\nCRITIC_ITERATIONS = 5\nLAMBDA_GP = 10","6ddb2e79":"transforms = transforms.Compose([\n    transforms.Resize([64,64]),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5 for i in range(CHANNELS_IMG)], [0.5 for i in range(CHANNELS_IMG)])\n])","9d4694a5":"IMAGE_PATH = '..\/input\/celeba-dataset\/img_align_celeba'\nIMAGE_PATH","5d49f840":"dataset = datasets.ImageFolder(IMAGE_PATH, transform = transforms)","72210f48":"img, label = dataset[1]\nimg.shape, label","1c6a46b4":"import random","b004c9e2":"indices = random.sample(range(len(dataset)), 121600)\ndata = torch.tensor(indices)\nlen(data)","1d4816f8":"img, label = dataset[1]\nimg.shape, label","615b909d":"def split_indices(n, val_per, seed = 0):\n    n_val = int(n * val_per)\n    np.random.seed(seed)\n    idx = np.random.permutation(n)\n    return idx[n_val : ], idx[: n_val]","51035ac2":"import numpy as np\nimport matplotlib.pyplot as plt","a79e612a":"val_per = 0.0\nrand_seed = 42\n\ntrain_indices, val_indices = split_indices(len(data), val_per, rand_seed)\n\nprint(len(train_indices), len(val_indices))","1c827c9d":"print(\"Validation Indices: \", val_indices[:20])\nprint(\"Training Indices: \", train_indices[:20])","748f934f":"from torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data.dataloader import DataLoader","a53ae00b":"# training data loader\ntrain_sampler = SubsetRandomSampler(train_indices)\nloader = DataLoader(dataset, BATCH_SIZE, sampler = train_sampler)","0e6df297":"#loader = DataLoader(data, BATCH_SIZE)","459d16c9":"len(loader)","cc957f23":"len(dataset), len(loader), len(data)","d29e6e7a":"def show_img(img, label):\n    print('Label: ', label)\n    plt.imshow(img.permute(1,2,0), cmap = 'gray')","a2b08f59":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","8225b411":"# lets observe some images\nshow_img(*dataset[0])","8a5350f7":"from torchvision.utils import make_grid\n# this will help us to create Grid of images","9f3fdb59":"# We will select first 110 image from first batch of size = 512\ndef show_batch(dl):\n    for img, label in dl:\n        fig, ax = plt.subplots(figsize = (12,8))\n        ax.imshow(make_grid(img[:110], 10).permute(1,2,0))\n        break","6a9dc98a":"show_batch(loader)","ecb53516":"def gradient_panelty(disc, real, fake, device = 'cpu'):\n    \n    BATCH_SIZE, C, H, W = real.shape\n    \n    epsilon = torch.rand((BATCH_SIZE, 1, 1, 1)).to(device)\n    \n    interpolated_image = real * epsilon + fake * (1-epsilon)\n    \n    # Calculate Critic Score\n    \n    mixed_scores = disc(interpolated_image)\n    \n    gradient = torch.autograd.grad(\n                inputs = interpolated_image,\n                outputs = mixed_scores,\n                grad_outputs = torch.ones_like(mixed_scores),\n                create_graph = True, retain_graph = True\n                )[0]\n    \n    gradient = gradient.view(gradient.shape[0], -1)\n    gradient_norm = gradient.norm(2, dim = 1)\n    gradient_panelty = torch.mean((gradient_norm - 1) ** 2)\n    \n    return gradient_panelty","f5982e49":"class Discriminator(nn.Module):\n    \n    def __init__(self, channels_img, features_d):\n        super(Discriminator, self).__init__()\n        \n        self.disc = nn.Sequential(\n            #size = 3*64*64\n            nn.Conv2d(channels_img, features_d, kernel_size = 4, stride = 2, padding = 1), # Size : 32*32\n            nn.LeakyReLU(0.2),\n            \n            nn.Conv2d(features_d, features_d*2, kernel_size = 4, stride = 2, padding = 1), # size = 16*16\n            nn.InstanceNorm2d(features_d*2),\n            nn.LeakyReLU(0.2),\n            \n            nn.Conv2d(features_d*2, features_d*4, kernel_size = 4, stride = 2, padding = 1), # size = 8*8\n            nn.InstanceNorm2d(features_d*4),\n            nn.LeakyReLU(0.2),\n            \n            nn.Conv2d(features_d*4, features_d*8, kernel_size = 4, stride = 2, padding = 1), # size = 4*4\n            nn.InstanceNorm2d(features_d*8),\n            nn.LeakyReLU(0.2),\n            \n            nn.Conv2d(features_d*8, 1, kernel_size = 4, stride = 2, padding = 0) #1*1\n            \n        )\n        \n        \n    def forward(self, x):\n        return self.disc(x)","443acbc4":"class Generator(nn.Module):\n    \n    def __init__(self, z_dim, channels_img, features_g):\n        super(Generator, self).__init__()\n        \n        self.net = nn.Sequential(\n            nn.ConvTranspose2d(z_dim, features_g*16, kernel_size = 4, stride = 1, padding = 0), # size = 4*4\n            nn.BatchNorm2d(features_g*16),\n            nn.ReLU(),\n            \n            nn.ConvTranspose2d(features_g*16, features_g*8, kernel_size = 4, stride = 2, padding = 1), # size = 8*8\n            nn.BatchNorm2d(features_g*8),\n            nn.ReLU(),\n            \n            nn.ConvTranspose2d(features_g*8, features_g*4, kernel_size = 4, stride = 2, padding = 1), # size = 16*16\n            nn.BatchNorm2d(features_g*4),\n            nn.ReLU(),\n            \n            nn.ConvTranspose2d(features_g*4, features_g*2, kernel_size = 4, stride = 2, padding = 1), # size = 32*32\n            nn.BatchNorm2d(features_g*2),\n            nn.ReLU(),\n            \n            nn.ConvTranspose2d(features_g*2, channels_img, kernel_size = 4, stride = 2, padding = 1),\n            nn.Tanh()  # [-1, 1]\n        )\n        \n    \n    def forward(self, x):\n        return self.net(x)","dca938b5":"def initialize_weights(model):\n    # Initializes weights according to the DCGAN paper\n    for m in model.modules():\n        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n            nn.init.normal_(m.weight.data, 0.0, 0.02)","83bdcf05":"def test():\n    N, in_channels, H, W = 8, 3, 64, 64\n    noise_dim = 100\n    x = torch.randn((N, in_channels, H, W))\n    disc = Discriminator(in_channels, 8)\n    assert disc(x).shape == (N, 1, 1, 1), \"Discriminator test failed\"\n    gen = Generator(noise_dim, in_channels, 8)\n    z = torch.randn((N, noise_dim, 1, 1))\n    assert gen(z).shape == (N, in_channels, H, W), \"Generator test failed\"\n    print('Success')","bb603cdf":"test()","8ae6eadd":"dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\ngen = Generator(z_dim = Z_DIM, channels_img = CHANNELS_IMG, features_g = FEATURES_GEN).to(device)\ndisc = Discriminator(CHANNELS_IMG, FEATURES_DISC).to(device)\ninitialize_weights(gen)\ninitialize_weights(disc)","23190f2e":"opt_gen = optim.Adam(gen.parameters(), lr = LEARNING_RATE, betas = (0.0, 0.9))\nopt_disc = optim.Adam(disc.parameters(), lr = LEARNING_RATE, betas = (0.0, 0.9))","6f2e1e37":"opt_gen = optim.Adam(gen.parameters(), lr = LEARNING_RATE, betas = (0.0, 0.9))\nopt_disc = optim.Adam(disc.parameters(), lr = LEARNING_RATE, betas = (0.0, 0.9))\nopt_gen = optim.Adam(gen.parameters(), lr = LEARNING_RATE, betas = (0.0, 0.9))\nopt_disc = optim.Adam(disc.parameters(), lr = LEARNING_RATE, betas = (0.0, 0.9))\ndef reset_grad():\n    opt_disc.zero_grad()\n    opt_gen.zero_grad()","10f88078":"def train_discriminator(images):\n    # create labels, for real image label is 1, for fake \n    \n    # loss for real images\n    \n    for _ in range(CRITIC_ITERATIONS):\n        \n        disc_real = disc(images).reshape(-1)\n        #d_loss_real = torch.mean(disc_real)\n        real_score = torch.mean(disc_real)\n        \n        \n        z = torch.randn(BATCH_SIZE, Z_DIM, 1, 1).to(device)\n        fake_images = gen(z)\n        disc_fake = disc(fake_images).reshape(-1)\n        #d_loss_fake = torch.mean(disc_fake)\n        fake_score = torch.mean(disc_fake)\n        \n        gp = gradient_panelty(disc, images, fake_images, device = device)\n        \n        loss_disc = (\n            -(torch.mean(disc_real) - torch.mean(disc_fake)) \n            + LAMBDA_GP * gp )\n        \n        reset_grad()\n        \n        loss_disc.backward()\n        \n        opt_disc.step()\n        \n        return loss_disc, real_score, fake_score  ","cd366132":"def train_generator():\n    # Generate fake images and calculate loss\n    z = torch.randn(BATCH_SIZE, Z_DIM, 1, 1).to(device)\n    fake_images = gen(z)\n    labels = torch.ones(BATCH_SIZE, 1).to(device)\n    output = disc(fake_images).reshape(-1)\n    g_loss = - torch.mean(output)\n\n    # Backprop and optimize\n    reset_grad()\n    g_loss.backward()\n    opt_gen.step()\n    return g_loss, fake_images","a3aebd6f":"import os\n\nsample_dir = 'samples'\nif not os.path.exists(sample_dir):\n    os.makedirs(sample_dir)","360c8517":"def show_img(img, label):\n    print('Label: ', label)\n    plt.imshow(img.permute(1,2,0), cmap = 'gray')","cd006546":"def denorm(x):\n  out = (x + 1) \/ 2\n  return out.clamp(0, 1)","45803660":"from IPython.display import Image\nfrom torchvision.utils import save_image\n\n# Save some real images\nfor images,_ in loader:\n    images = images.reshape(images.size(0), 3, 64, 64)\n    save_image(denorm(images), os.path.join(sample_dir, 'real_images.png'), nrow=16)\n    break\n   \nImage(os.path.join(sample_dir, 'real_images.png'))","636be19a":"sample_vectors = torch.randn(BATCH_SIZE, Z_DIM, 1, 1).to(device)\n\ndef save_fake_images(index):\n    fake_images = gen(sample_vectors)\n    fake_images = fake_images.reshape(fake_images.size(0), 3, 64, 64)\n    fake_fname = 'fake_images-{0:0=4d}.png'.format(index)\n    print('Saving', fake_fname)\n    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=16)\n    \n# Before training\nsave_fake_images(0)\nImage(os.path.join(sample_dir, 'fake_images-0000.png'))","215090f0":"%%time\n\n\ntotal_step = len(loader)\nd_losses, g_losses, real_scores, fake_scores = [], [], [], []\n\nfor epoch in range(NUM_EPOCHS):\n    for i, (images, _) in enumerate(loader):\n        # Load a batch & transform to vectors\n        images = images.to(device)\n        \n        # Train the discriminator and generator\n        d_loss, real_score, fake_score = train_discriminator(images)\n        g_loss, fake_images = train_generator()\n        \n        # Inspect the losses\n        if (i+1) % 200 == 0:\n            d_losses.append(d_loss.item())\n            g_losses.append(g_loss.item())\n            real_scores.append(real_score.mean().item())\n            fake_scores.append(fake_score.mean().item())\n            print('Epoch [{}\/{}], Step [{}\/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n                  .format(epoch, NUM_EPOCHS, i+1, total_step, d_loss.item(), g_loss.item(), \n                          real_score.mean().item(), fake_score.mean().item()))\n        \n    # Sample and save images\n    save_fake_images(epoch+1)","e33a3492":"plt.plot(d_losses, '-')\nplt.plot(g_losses, '-')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend(['Discriminator', 'Generator'])\nplt.title('Losses');","6658c27b":"plt.plot(real_scores, '-')\nplt.plot(fake_scores, '-')\nplt.xlabel('epoch')\nplt.ylabel('score')\nplt.legend(['Real Score', 'Fake score'])\nplt.title('Scores');","f96e5d6e":"import cv2\nimport os\nfrom IPython.display import FileLink\n\nvid_fname = 'gans_training.avi'\n\nfiles = [os.path.join(sample_dir, f) for f in os.listdir(sample_dir) if 'fake_images' in f]\nfiles.sort()\n\nout = cv2.VideoWriter(vid_fname,cv2.VideoWriter_fourcc(*'MP4V'), 1, (1030,6260))\n[out.write(cv2.imread(fname)) for fname in files]\nout.release()\nFileLink('gans_training.avi')","a75ffe06":"Image('.\/samples\/fake_images-0000.png')","251f862d":"Image('.\/samples\/fake_images-0002.png')","570006c7":"Image('.\/samples\/fake_images-0004.png')","d1497759":"Image('.\/samples\/fake_images-0006.png')","6c32dbbc":"Image('.\/samples\/fake_images-0008.png')","01761426":"Image('.\/samples\/fake_images-0010.png')","4bbd46da":"# Plot Result","a2b57c75":"import random","aee56efb":"# Verify Images After Every Epoch","0516b09d":"This is remarkable, how from Nothing to something meaningful within 10 Iterations. With 100 Epochs, we can get almost 99% similar image as of original Celeb Face Dataset.\n\nI would like if someone can run this for 100 Epochs and result obtained after that, In case anyone able to run for 100, Kindly share link of image transformation.\n\nThat's It for this Notebook, I will come up with more advanced version of GAN with next notebook, for now Wessertein GAN, worked excellently.\n\nThanks and Consider Upvoting !! Keep learning !!"}}