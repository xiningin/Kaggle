{"cell_type":{"fa180aab":"code","3a3da081":"code","164640dc":"code","8e210f3d":"code","5af37140":"code","00eb5eba":"code","366accb7":"code","e4d50b53":"code","9a730b71":"code","b849a99f":"code","84ad9d70":"code","7a84ee65":"code","15d1bc0d":"code","7fc6fce3":"code","2b8e663c":"code","fa292f89":"code","2574fab9":"code","8c313353":"code","55dc31e4":"code","8e35c216":"code","3fa9f38b":"code","21308141":"markdown","1db8927a":"markdown","201917a2":"markdown","7b0b647f":"markdown","c1808a5c":"markdown","50cc006b":"markdown","c6a84593":"markdown","278bda35":"markdown","3267772e":"markdown","d384db6a":"markdown","2caf49c0":"markdown"},"source":{"fa180aab":"#Let's load in some basics and make sure our files are all here\nimport numpy as np\nimport pandas as pd\nimport os\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint(os.listdir(\"..\/input\"))","3a3da081":"train = pd.read_json('..\/input\/train.json')\ntest = pd.read_json('..\/input\/test.json')\nsample_submission = pd.read_csv('..\/input\/sample_submission.csv')","164640dc":"print(train.columns)\nsample_submission.head(3)","8e210f3d":"cols = [\"vid_id\", \"start_time_seconds_youtube_clip\", \"end_time_seconds_youtube_clip\",\n        \"audio_embedding\", \"is_turkey\"]\nprint(train.shape)\nprint(test.shape)\ntrain[train['is_turkey']==1][cols].head(3)","5af37140":"\"is_turkey rate is \" + str(train[train['is_turkey']==1].shape[0] \/ train.shape[0])","00eb5eba":"print(train['audio_embedding'].head())\n\n#see the possible list lengths of the first dimension\nprint(\"train's audio_embedding can have this many frames: \"+ str(train['audio_embedding'].apply(lambda x: len(x)).unique())) \nprint(\"test's audio_embedding can have this many frames: \"+ str(test['audio_embedding'].apply(lambda x: len(x)).unique())) \n\n#see the possible list lengths of the first element\nprint(\"each frame can have this many features: \"+str(train['audio_embedding'].apply(lambda x: len(x[0])).unique()))","366accb7":"sns.countplot(train['audio_embedding'].apply(lambda x: len(x)))\nplt.show()","e4d50b53":"# train[\"time_seconds\"] = train[\"end_time_seconds_youtube_clip\"] - train[\"start_time_seconds_youtube_clip\"]\n# test[\"time_seconds\"] = test[\"end_time_seconds_youtube_clip\"] - test[\"start_time_seconds_youtube_clip\"]\n# sns.countplot(train[\"time_seconds\"])\n# plt.ylim(0,100)\n# plt.show()","9a730b71":"from keras.models import Sequential, Model\nfrom keras.layers import Dense, Bidirectional, LSTM, BatchNormalization, Dropout, Input\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom sklearn.model_selection import train_test_split","b849a99f":"#split the training data to have a validation set\ntrain_train, train_val = train_test_split(train, test_size=0.2, random_state=42, stratify=train[\"is_turkey\"])\nxtrain = [k for k in train_train['audio_embedding']]\nytrain = train_train['is_turkey'].values\n\nxval = [k for k in train_val['audio_embedding']]\nyval = train_val['is_turkey'].values\n\n# Pad the audio features so that all are \"10 seconds\" long\nx_train = pad_sequences(xtrain, maxlen=10)\nx_val = pad_sequences(xval, maxlen=10)\n\ny_train = np.asarray(ytrain)\ny_val = np.asarray(yval)","84ad9d70":"## https:\/\/stackoverflow.com\/questions\/41032551\/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras\nfrom sklearn.metrics import roc_auc_score\nfrom keras.callbacks import Callback\nimport tensorflow as tf\nfrom keras import backend as K\nclass roc_callback(Callback):\n    def __init__(self,training_data,validation_data):\n        self.x = training_data[0]\n        self.y = training_data[1]\n        self.x_val = validation_data[0]\n        self.y_val = validation_data[1]\n\n\n    def on_train_begin(self, logs={}):\n        return\n\n    def on_train_end(self, logs={}):\n        return\n\n    def on_epoch_begin(self, epoch, logs={}):\n        return\n\n    def on_epoch_end(self, epoch, logs={}):\n        y_pred = self.model.predict(self.x)\n        roc = roc_auc_score(self.y, y_pred)\n        y_pred_val = self.model.predict(self.x_val)\n        roc_val = roc_auc_score(self.y_val, y_pred_val)\n        print('\\rroc-auc: %s - roc-auc_val: %s' % (str(round(roc,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n        return\n\n    def on_batch_begin(self, batch, logs={}):\n        return\n\n    def on_batch_end(self, batch, logs={}):\n        return\n    \n    \n## https:\/\/github.com\/keras-team\/keras\/issues\/3230#issuecomment-292535661\n#-----------------------------------------------------------------------------------------------------------------------------------------------------\n# AUC for a binary classifier\ndef auc(y_true, y_pred):   \n    ptas = tf.stack([binary_PTA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n    pfas = tf.stack([binary_PFA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n    pfas = tf.concat([tf.ones((1,)) ,pfas],axis=0)\n    binSizes = -(pfas[1:]-pfas[:-1])\n    s = ptas*binSizes\n    return K.sum(s, axis=0)\n#-----------------------------------------------------------------------------------------------------------------------------------------------------\n# PFA, prob false alert for binary classifier\ndef binary_PFA(y_true, y_pred, threshold=K.variable(value=0.5)):\n    y_pred = K.cast(y_pred >= threshold, 'float32')\n    # N = total number of negative labels\n    N = K.sum(1 - y_true)\n    # FP = total number of false alerts, alerts from the negative class labels\n    FP = K.sum(y_pred - y_pred * y_true)    \n    return FP\/N\n#-----------------------------------------------------------------------------------------------------------------------------------------------------\n# P_TA prob true alerts for binary classifier\ndef binary_PTA(y_true, y_pred, threshold=K.variable(value=0.5)):\n    y_pred = K.cast(y_pred >= threshold, 'float32')\n    # P = total number of positive labels\n    P = K.sum(y_true)\n    # TP = total number of correct alerts, alerts from the positive class labels\n    TP = K.sum(y_pred * y_true)    \n    return TP\/P","7a84ee65":"## https:\/\/www.kaggle.com\/suicaokhoailang\/lstm-with-attention-baseline-0-989-lb\/notebook\nfrom keras import backend as K\nfrom keras.engine.topology import Layer\nfrom keras import initializers, regularizers, constraints\n\n# https:\/\/www.kaggle.com\/qqgeogor\/keras-lstm-attention-glove840b-lb-0-043\nclass Attention(Layer):\n    def __init__(self, step_dim,\n                 W_regularizer=None, b_regularizer=None,\n                 W_constraint=None, b_constraint=None,\n                 bias=True, **kwargs):\n        self.supports_masking = True\n        self.init = initializers.get('glorot_uniform')\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias = bias\n        self.step_dim = step_dim\n        self.features_dim = 0\n        super(Attention, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 3\n\n        self.W = self.add_weight((input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_W'.format(self.name),\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        self.features_dim = input_shape[-1]\n\n        if self.bias:\n            self.b = self.add_weight((input_shape[1],),\n                                     initializer='zero',\n                                     name='{}_b'.format(self.name),\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n        else:\n            self.b = None\n\n        self.built = True\n\n    def compute_mask(self, input, input_mask=None):\n        return None\n\n    def call(self, x, mask=None):\n        features_dim = self.features_dim\n        step_dim = self.step_dim\n\n        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n\n        if self.bias:\n            eij += self.b\n\n        eij = K.tanh(eij)\n\n        a = K.exp(eij)\n\n        if mask is not None:\n            a *= K.cast(mask, K.floatx())\n\n        a \/= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n\n        a = K.expand_dims(a)\n        weighted_input = x * a\n        return K.sum(weighted_input, axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0],  self.features_dim","15d1bc0d":"#Define a basic LSTM model\nmodel = Sequential()\nmodel.add(Bidirectional(LSTM(256, dropout=0.3, recurrent_dropout=0.3, return_sequences=True, input_shape=(10, 128))))\nmodel.add(Bidirectional(LSTM(128, return_sequences=True)))\nmodel.add(Attention(10))\nmodel.add(Dense(64, activation='relu', kernel_initializer='he_normal'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1, activation='sigmoid'))\n\n#maybe there is something better to use, but let's use binary_crossentropy\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=[\"accuracy\", auc])\n\n# Callback\nes = EarlyStopping(monitor='val_auc', min_delta=0, patience=5, verbose=0, mode='max')\nroc_cb = roc_callback(training_data=(x_train, y_train),validation_data=(x_val, y_val))\n\n#fit on a portion of the training data, and validate on the rest\nhistory = model.fit(x_train, y_train,\n                    validation_data=(x_val, y_val),\n                    batch_size=256,\n                    epochs=20,\n                    verbose=2,\n                    callbacks=[es, roc_cb])\n\n# Evaluate\nscore, acc, auc = model.evaluate(x_val, y_val, batch_size=256, verbose=0)\nprint('Validation AUC:', auc)","7fc6fce3":"plt.figure(figsize=(8,5))\nsns.lineplot(range(1, len(history.history['auc'])+1), history.history['auc'], label='Train AUC')\nsns.lineplot(range(1, len(history.history['auc'])+1), history.history['val_auc'], label='Test AUC')\nplt.show()","2b8e663c":"df_val = pd.DataFrame({'vid_id':train_val['vid_id'].values,\n                       'is_turkey':[x for y in model.predict(x_val) for x in y],\n                       'start_time': train_val['start_time_seconds_youtube_clip'].values})\ndf_val.head(3)","fa292f89":"plt.figure(figsize=(6,4))\nsns.distplot(df_val[\"is_turkey\"], bins=20, kde=False)\nplt.show()","2574fab9":"df_val[(df_val[\"is_turkey\"]>0.05) & (df_val[\"is_turkey\"]<0.95)]","8c313353":"test_data = [k for k in test['audio_embedding']]\nsubmission = model.predict(pad_sequences(test_data))\nsubmission = pd.DataFrame({'vid_id':test['vid_id'].values,'is_turkey':[x for y in submission for x in y]})","55dc31e4":"print(submission.head()) #check to see that it looks like the sample submission","8e35c216":"submission.to_csv('lstm_starter.csv', index=False) #drop the index so it matches the submission format.","3fa9f38b":"from IPython.display import YouTubeVideo\nYouTubeVideo(\"HvSsSQddil4\",start=0)","21308141":"## Load and EDA","1db8927a":"---","201917a2":"### Build and Train Model","7b0b647f":"## Don't call *her* turkey! (Just for fun)","c1808a5c":"### Attention","50cc006b":"### Prepare","c6a84593":"## Prediction","278bda35":"I use these:\n- [Based on Starter Kernel](https:\/\/www.kaggle.com\/michaelapers\/lstm-starter-notebook)\n- [LSTM with Attention](https:\/\/www.kaggle.com\/suicaokhoailang\/lstm-with-attention-baseline-0-989-lb)\n- [AUC Metric](https:\/\/github.com\/keras-team\/keras\/issues\/3230#issuecomment-292535661) and [Callback](https:\/\/stackoverflow.com\/questions\/41032551\/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras)","3267772e":"## Evaluation","d384db6a":"### AUC Metric and Callback","2caf49c0":"## Modeling"}}