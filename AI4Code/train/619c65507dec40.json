{"cell_type":{"7a3c68e5":"code","e7579ea9":"code","121ccf34":"code","867db936":"code","2eba461c":"code","a9e36dd7":"code","425f86f2":"code","0e02e036":"code","18d26ae1":"code","9ac5e877":"code","cec96088":"code","3ca30577":"code","326b20f6":"code","baacb386":"code","f3e6e68a":"code","c7bcc0f3":"code","3d26f751":"code","6f95391b":"code","33aa76a4":"code","ec8609cb":"markdown","748e5a1a":"markdown","7d2f2604":"markdown","387b26ee":"markdown","dfc67274":"markdown","d3907b5f":"markdown","f15f32b4":"markdown","3e3232a5":"markdown","8b84fe60":"markdown","51af739c":"markdown","18ef5bb3":"markdown","eec5430e":"markdown","39cf69bc":"markdown","9eb58a96":"markdown","33e7c4d7":"markdown","7b081fec":"markdown","560d6164":"markdown","ca09440e":"markdown","dabf6d9a":"markdown","148cf013":"markdown","a9367612":"markdown","f421dced":"markdown","0e43c511":"markdown","6b2bfbf4":"markdown","c3fb17b3":"markdown","25a0708f":"markdown","ac9bcdcc":"markdown","faa1cef2":"markdown","7dcf752f":"markdown","d1ecf05f":"markdown","3d2d596b":"markdown","a36c5391":"markdown","6956fc24":"markdown","d6a61a18":"markdown","df96b654":"markdown","43817f24":"markdown","c5b362eb":"markdown","b4381dfb":"markdown","6e07216f":"markdown","081e87c8":"markdown","35a0e70e":"markdown","e1155490":"markdown","14ec4e0a":"markdown","8ed4e5bd":"markdown","c3b68565":"markdown","21679024":"markdown"},"source":{"7a3c68e5":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Style\nsns.set(style='darkgrid')\nplt.rcParams[\"patch.force_edgecolor\"] = True\n\nimport os\nprint(os.listdir(\"..\/input\"))","e7579ea9":"df = pd.read_csv('..\/input\/BreadBasket_DMS.csv')\n","121ccf34":"print('Dataset Information: \\n')\nprint(df.info())","867db936":"print('First Ten Rows of the DataFrame: \\n')\nprint(df.head(10))","2eba461c":"print('Unique Items: ', df['Item'].nunique())\nprint( '\\n', df['Item'].unique())","a9e36dd7":"# List how many null values for each feature:\n\nprint(df.isnull().sum().sort_values(ascending=False))","425f86f2":"print(df[df['Item']=='NONE'])","0e02e036":"df.drop(df[df['Item']=='NONE'].index, inplace=True)","18d26ae1":"print(df.info())\n","9ac5e877":"# Year\ndf['Year'] = df['Date'].apply(lambda x: x.split(\"-\")[0])\n# Month\ndf['Month'] = df['Date'].apply(lambda x: x.split(\"-\")[1])\n# Day\ndf['Day'] = df['Date'].apply(lambda x: x.split(\"-\")[2])","cec96088":"print(df.info())\nprint(df.head())","3ca30577":"most_sold = df['Item'].value_counts().head(15)\n\nprint('Most Sold Items: \\n')\nprint(most_sold)","326b20f6":"plt.figure(figsize=(12,6))\n\nplt.subplot(1,2,1)\n#plt.plot(most_sold)\nmost_sold.plot(kind='line')\nplt.title('Items Most Sold')\n\n\nplt.subplot(1,2,2)\nmost_sold.plot(kind='bar')\nplt.title('Items Most Sold')","baacb386":"df.groupby('Month')['Transaction'].nunique().plot(kind='bar', title='Monthly Sales')\nplt.show()","f3e6e68a":"print(df.groupby('Month')['Day'].nunique())","c7bcc0f3":"from mlxtend.preprocessing import TransactionEncoder\nfrom mlxtend.frequent_patterns import association_rules, apriori","3d26f751":"transaction_list = []\n\n# For loop to create a list of the unique transactions throughout the dataset:\nfor i in df['Transaction'].unique():\n    tlist = list(set(df[df['Transaction']==i]['Item']))\n    if len(tlist)>0:\n        transaction_list.append(tlist)\nprint(len(transaction_list))","6f95391b":"te = TransactionEncoder()\nte_ary = te.fit(transaction_list).transform(transaction_list)\ndf2 = pd.DataFrame(te_ary, columns=te.columns_)","33aa76a4":"frequent_itemsets = apriori(df2, min_support=0.01, use_colnames=True)\nrules = association_rules(frequent_itemsets, metric='lift', min_threshold=1.0)\nrules.sort_values('confidence', ascending=False)","ec8609cb":"As we can see above, the Date and Time features are not numerical types. For better future visualization and understanding of the data, we add a few more features to this DataFrame based on the information from these two features.","748e5a1a":"If you'd like to read into how this is done, as well as the library that I use in this Kernel, visit: https:\/\/rasbt.github.io\/mlxtend\/user_guide\/frequent_patterns\/apriori\/","7d2f2604":"<a id='MarketBasketAnalysis'><\/a>","387b26ee":"<a id='AddingtotheDataFrame'><\/a>","dfc67274":"--------------------------------------------------------------------------------------------------","d3907b5f":"So how is this useful knowledge for the bakery? Businesses are always looking to optimize their setup and drive up their sales. Bakeries are no different, and this kind of analysis could have been done for any kind of retail store or market place as well. Because we now know the correlation between items and the common interest of the customers, the business can make decisions based on these findings. For example, this bakery might want to place their freshly baked bread near their pastries, since customers who purchase pastries seem to also be enticed by bread. Besides product placement, the bakery might also be interested in having a promotion of a free item, given the great chances of another item being sold as a result of it (For example, if they were to give away some of their free special toast one day, it might not only attract new frequent customers, but there is also a very good chance that the customer will still spend money on coffee). ","f15f32b4":"<a id='Conclusions'><\/a>","3e3232a5":"Look at that! This intuition was correct. Only 9 days' worth of transactions were recorded for April, and 2 days for October.","8b84fe60":"### Features\nThis dataset contains over 6,000 transactions and over 15,000 observations. The following are the features of this dataset and their definitions.\n \n \n \n \n \n \n    - Date:\n        Categorical variable that tells us the date of the transactions (YYYY-MM-DD format). The column includes dates from 30\/10\/2016 to 09\/04\/2017.\n    - Time:\n        Categorical variable that tells us the time of the transactions (HH:MM:SS format).\n    - Transactions:\n        Quantitative variable that allows us to differentiate the transactions. The rows that share the same value in this field belong to the same transaction, that's why the data set has less transactions than observations.\n    - Item:\n        Categorical variable with the products.","51af739c":"According to the dataset explanation (found at https:\/\/www.kaggle.com\/xvivancos\/market-basket-analysis\/data) this data belongs to a bakery called \"The Bread Basket\", located in Edinburgh, Scotland. This bakery presents a refreshing offer of Argentine and Spanish products.","18ef5bb3":"- [**The Dataset**](#TheDataset)\n    - [Features](#Features)\n    - [The Plan](#ThePlan)\n- [**Theory**](#Theory)\n- [**Exploring the Data**](#ExploringtheData)\n- [**Data Engineering**](#DataEngineering)\n    - [Checking for Null Values](#CheckingforNullValues)\n    - [Adding to the DataFrame](#AddingtotheDataFrame)\n    - [Visualizing and Understanding the Data](#VisualizingandUnderstandingtheData)\n- [**Market Basket Analysis**](#MarketBasketAnalysis)\n- [**Conclusions**](#Conclusions)\n","eec5430e":"Now let's apply apriori. I will use the min_threshold parameter in the association rules for the lift metric to be 1.0 because if it is less than one, then the two items are not likely to be bought together (see Theory above). We will sort the values by confidence to see the likelihood that an item is bought if its antecedent is bought.","39cf69bc":"### - Support\n\n    Support can be thought of as the percentage of the total amount of transactions relevant to an association. This is perhaps better understood by a simple equation:     \n    \n    Support(Item1) = (Transactions containing Item1) \/ (Total transactions) \n\n### - Confidence\n\n    Confidence tells us how likely it is that purchasing Item1 results in a purchase of Item2.\n    \n    Confidence(Item1 -> Item2) = (Transactions containing both Item1 and Item2) \/ (Transactions containing Item1)\n\n### - Lift\n\n    The lift refers to how the chances of Item2 being purchased increased given that Item1 is purchased.\n    \n    Lift(Item1 -> Item2) = (Confidence(Item1 -> Item2)) \/ (Support(Item2))\n    \n    A Lift of 1 means there is no association between products A and B. Lift of greater than 1 means products A and B are more likely to be bought together. Finally, Lift of less than 1 refers to the case where two products are unlikely to be bought together. (https:\/\/stackabuse.com\/association-rule-mining-via-apriori-algorithm-in-python\/)","9eb58a96":"<a id='VisualizingandUnderstandingtheData'><\/a>","33e7c4d7":"# Conclusions","7b081fec":"### Adding to the DataFrame","560d6164":"Let's check the most sold items from the bakery:","ca09440e":"# Table of Contents","dabf6d9a":"### Checking for Null Values\n\nAs always, we check for missing values and zeros and \"None\" values.","148cf013":"<a id='ThePlan'><\/a>","a9367612":"Let's now create a list of the unique transactions so that we can transform our data into the correct format using TransactionEncoder.","f421dced":"Clearly we have 'NONE' values in our dataset. This is either saying that no item was purchased, or the name of the item was not logged. Either way, this is of no use to us so we drop these rows.","0e43c511":"This is getting interesting! We see some big differences here. As an exercise to the curious, perhaps it would be worth finding out if this drastic difference in sales is due to the dataset having less data for April and October. This would make sense, as they are the outlier months in the dataset. Let's check to see if there are less daily transactions recorded for these months in comparison to the others.","6b2bfbf4":"# Market Basket Analysis","c3fb17b3":"# The Dataset","25a0708f":"<a id='CheckingforNullValues'><\/a>","ac9bcdcc":"<a id='Features'><\/a>","faa1cef2":"It seems that our dataset is not missing any values. Let's now check for \"None\" values within the Item feature.","7dcf752f":"<a id='DataEngineering'><\/a> ","d1ecf05f":"***","3d2d596b":"### The Plan\n\nWe will use this dataset to perform a modeling technique known as Market Basket Analysis. This is based on the idea that one can predict purchasing patterns within items, which is what makes it popular in the field of retail and commerce. This form of analysis helps many forms of businesses understand behavioral patterns and purchase patterns.\n\nThe idea is to find the link between purchased items. For example, if someone purchases Item1, how likely are they to then also purchase Item2? The answer to this can be found with the application of the [Apriori Algorithm](https:\/\/www.kdnuggets.com\/2016\/04\/association-rules-apriori-algorithm-tutorial.html\n).","a36c5391":"Let's now import the data into a DataFrame with pandas and exploring its properties:","6956fc24":"***","d6a61a18":"Very cool! We clearly see meaningful results here from our analysis shown above, where the higher the lift value, the stronger the correlation between the items. The data clearly shows that coffee is a popular consequent, which makes sense because it is a bakery. Besides coffee, let's look at the more interesting item correlations (format: antecedant(s) -> consequent):\n\n- Pastry -> Bread\n- Cake -> Tea\n- (Coffee + Tea) -> Cake\n- Sandwhich -> Tea\n- Hot Chocolate -> Cake\n\n    ","df96b654":"<a id='Theory'><\/a>","43817f24":"We first import the libraries we are going to be using for exploratory analysis of the data, as well as style preferences.","c5b362eb":"***","b4381dfb":"# Theory","6e07216f":"We know that this dataset is recorded from 30\/10\/2016 to 09\/04\/2017. Before we engage in modeling, we should explore and visualize the sales within this time period. Which items do customers purchase most? Which months were more successful? Let's answer this visually. ","081e87c8":"The Apriori Algorithm gives us associative properties within transactions. This is also known as [**Association Rules**](https:\/\/www.kdnuggets.com\/2016\/04\/association-rules-apriori-algorithm-tutorial.html) for our dataset. The analysis of these association rules depend on three measures- Support, Confidence, and Lift.","35a0e70e":"<a id='TheDataset'><\/a>","e1155490":"### Visualizing and Understanding the Data","14ec4e0a":"# Exploring the Data\n","8ed4e5bd":"# Data Engineering","c3b68565":"<a id='ExploringtheData'><\/a>","21679024":"Clearly coffee is the most sold item, followed by bread, tea, cake, and pastry, respectively. This makes sense for a bakery. Now that we know which are the most popular items, let's check out which months bring in the most sales."}}