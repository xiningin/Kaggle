{"cell_type":{"36264d3c":"code","250badb8":"code","c9dda214":"code","97d4de69":"code","33893c85":"code","64bbaa56":"code","ca29e50b":"code","f0647132":"code","7f6a8b9f":"code","df796ed5":"code","26d8e9d9":"code","eee02aec":"code","a343ccc8":"code","a1a20934":"code","5774f6e2":"code","68bbbb79":"code","a32087ca":"code","a38405fa":"code","7f198838":"code","6fbd50f4":"code","bc321f2f":"code","8c10844c":"markdown","941d2622":"markdown","a94aaa6b":"markdown","152c603f":"markdown","318772c2":"markdown","9130bd5b":"markdown"},"source":{"36264d3c":"! pip install dexplot","250badb8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c9dda214":"# Importing some of the Library\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px \nimport plotly.graph_objs as go\nfrom plotly.offline import iplot\nimport dexplot as dxp\n","97d4de69":"df = pd.read_csv('\/kaggle\/input\/us-accidents\/US_Accidents_June20.csv')","33893c85":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","64bbaa56":"df = reduce_mem_usage(df)","ca29e50b":"df.head()","f0647132":"# Shape of the data\n\ndf.shape","7f6a8b9f":"# Checking the null value\n\ndf.isnull().sum()","df796ed5":"# Getting the info about the data\n\ndf.info(verbose=True)","26d8e9d9":"df['Start_Lat'].nunique()","eee02aec":"# Counting the unique numbers of Source\ndf['Source'].unique()","a343ccc8":"# Calculating the Contribution of each unique sources in percentage\n\nlabels = df['Source'].value_counts()[:].index\nvalues = df['Source'].value_counts()[:].values\n\ncolors = df['Source']\n\nfig = go.Figure(data=[go.Pie(labels = labels, values=values, textinfo=\"label+percent\", insidetextorientation=\"radial\", marker=dict(colors=colors))])\n\nfig.show()","a1a20934":"# Counting the unique numbers of state\n\ndf['State'].unique()","5774f6e2":"labels = df['State'].value_counts()[:10].index\nvalues = df['State'].value_counts()[:10].values\n\ncolors = df['State']\n\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, textinfo=\"label+percent\", insidetextorientation=\"radial\", marker=dict(colors=colors))])\n\nfig.show()","68bbbb79":"# Counting the unique time zones\n\ndf['Timezone'].unique()","a32087ca":"labels = df['Timezone'].value_counts()[:].index\nvalues = df['Timezone'].value_counts()[:].values\n\ncolors = df['Timezone']\n\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, textinfo=\"label+percent\", insidetextorientation=\"radial\", marker=dict(colors=colors))])\n\nfig.show()","a38405fa":"df['Weather_Timestamp'].unique()","7f198838":"labels = df['Weather_Timestamp'].value_counts()[:10].index\nvalues = df['Weather_Timestamp'].value_counts()[:10].values\n\ncolors = df['Weather_Timestamp']\n\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, textinfo=\"label+percent\", insidetextorientation=\"radial\", marker=dict(colors=colors))])\n\nfig.show()","6fbd50f4":"labels = df['Sunrise_Sunset'].value_counts()[:10].index\nvalues = df['Sunrise_Sunset'].value_counts()[:10].values\n\ncolors = df['Sunrise_Sunset']\n\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, textinfo=\"label+percent\", insidetextorientation=\"radial\", marker=dict(colors=colors))])\n\nfig.show()","bc321f2f":"labels = df['Traffic_Signal'].value_counts()[:10].index\nvalues = df['Traffic_Signal'].value_counts()[:10].values\n\ncolors = df['Sunrise_Sunset']\n\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, textinfo=\"label+percent\", insidetextorientation=\"radial\", marker=dict(colors=colors))])\n\nfig.show()","8c10844c":"We have 3 unique sources for the accident information","941d2622":"C","a94aaa6b":"We can see that most of the accidents has been occured in the Eastern and Pacific Time Zone","152c603f":"So most of the data has been contributed by MapQuest","318772c2":"Since it is taking more memory so defining a function to reduce the memory size","9130bd5b":"Among the state with highest number of accidents California accounts for the most of the accident"}}