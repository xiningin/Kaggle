{"cell_type":{"5e2a22fd":"code","000145d4":"code","05349237":"code","a1e289b1":"code","6dec7eea":"code","7c80acd8":"code","bd213122":"code","38aab5c3":"code","578845e2":"code","6e9cd8f8":"code","f6c2440c":"code","d802d7e6":"code","ea31c833":"code","52c36433":"code","9f6617b6":"code","99c098d8":"code","c11213e7":"code","0608939a":"code","b9cd57a1":"code","fae6bc09":"code","8bd205ae":"markdown","b3285dcb":"markdown","b6eae87f":"markdown","f10cf625":"markdown","541fca9e":"markdown","67fdb029":"markdown","2ec51f6e":"markdown","d752ef53":"markdown","e2b2cad1":"markdown","5bb4a89e":"markdown","18041e39":"markdown","dcd36c87":"markdown","947362be":"markdown"},"source":{"5e2a22fd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","000145d4":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport glob\nimport cv2","05349237":"train_path = \"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train\/\"\nval_path = \"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/val\/\"\ntest_path = \"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/test\/\"","a1e289b1":"normal = glob.glob(train_path+\"NORMAL\/*.jpeg\")\npneumonia = glob.glob(train_path+\"PNEUMONIA\/*.jpeg\")","6dec7eea":"sns.barplot(x=[\"Normal\",\"Pneumonia\"],y=[len(normal),len(pneumonia)])","7c80acd8":"fig, axes = plt.subplots(nrows=1, ncols=6, figsize=(15,10), subplot_kw={'xticks':[], 'yticks':[]})\nfor i, ax in enumerate(axes.flat):\n    img = cv2.imread(pneumonia[i])\n    img = cv2.resize(img, (220,220))\n    ax.imshow(img)\n    ax.set_title(\"Pneumonia\")\n    \nplt.show()\n\nfig, axes = plt.subplots(nrows=1, ncols=6, figsize=(15,10), subplot_kw={'xticks':[], 'yticks':[]})\nfor i, ax in enumerate(axes.flat):\n    img = cv2.imread(normal[i])\n    img = cv2.resize(img, (220,220))\n    ax.imshow(img)\n    ax.set_title(\"Normal\")\nfig.tight_layout()    \nplt.show()","bd213122":"train_val_generator = ImageDataGenerator(rescale=1.\/255,horizontal_flip=True,zoom_range=0.2)\ntest_generator = ImageDataGenerator(rescale=1.\/255)","38aab5c3":"train = train_val_generator.flow_from_directory(train_path,\n                                               batch_size=128,\n                                               target_size=(220,220),\n                                               color_mode=\"rgb\",\n                                               class_mode=\"binary\",\n                                               shuffle=True,\n                                               seed=123,\n                                               subset=\"training\")","578845e2":"val = train_val_generator.flow_from_directory(val_path,\n                                               batch_size=4,\n                                               target_size=(220,220),\n                                               color_mode=\"rgb\",\n                                               class_mode=\"binary\",\n                                               shuffle=True,\n                                               seed=123)","6e9cd8f8":"test = test_generator.flow_from_directory(test_path,\n                                          batch_size=16,\n                                          target_size=(220,220),\n                                          color_mode=\"rgb\",\n                                          class_mode=\"binary\")","f6c2440c":"from keras.layers import Flatten,Dense,BatchNormalization,Dropout,LeakyReLU,GlobalAveragePooling2D\nfrom keras.optimizers import Adam\nfrom keras.losses import BinaryCrossentropy\nfrom keras.applications import ResNet50V2\nfrom keras import Sequential","d802d7e6":"resnet = ResNet50V2(weights=\"imagenet\",input_shape=(220,220,3),include_top=False)\nfor layer in resnet.layers:\n    layer.trainable = False\nmodel = Sequential()\nmodel.add(resnet)\nmodel.add(Flatten())\nmodel.add(Dense(128))\nmodel.add(BatchNormalization())\nmodel.add(LeakyReLU(0.2))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(LeakyReLU(0.2))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1,activation=\"sigmoid\"))\noptim = Adam(1e-3)\nloss = BinaryCrossentropy()\nmodel.compile(optimizer=optim,loss=loss,metrics=[\"accuracy\",\"AUC\"])","ea31c833":"model.summary()","52c36433":"tf.keras.utils.plot_model(\n    model, to_file='model.png', show_shapes=True,\n    show_layer_names=True,\n)","9f6617b6":"from keras.callbacks import EarlyStopping","99c098d8":"early_stop = EarlyStopping(monitor=\"val_loss\",mode=\"min\",patience=3,restore_best_weights=True)","c11213e7":"history = model.fit(train,validation_data=val,verbose=1,epochs=10)","0608939a":"history_df = pd.DataFrame(history.history)\nhistory_df.loc[1:, ['loss', 'val_loss']].plot()\nhistory_df.loc[1:, ['accuracy', 'val_accuracy']].plot()\nhistory_df.loc[1:, ['auc', 'val_auc']].plot()","b9cd57a1":"results = model.evaluate(test)","fae6bc09":"print(f\"Results on test set (loss,accuracy,auc):{results}\")","8bd205ae":"<div style=\"border-radius:25px;width:100%;height:100px;background: linear-gradient(90deg, rgba(131,58,180,1) 0%, rgba(253,29,29,1) 50%, rgba(252,176,69,1) 100%);text-align:center\">\n    <h1 style=\"color:black;padding-top:30px\">Creating our data generator<\/h1>\n<\/div>","b3285dcb":"<img src=\"https:\/\/www.jeremyjordan.me\/content\/images\/2018\/04\/Screen-Shot-2018-04-16-at-6.30.05-PM.png\">","b6eae87f":"<div style=\"border-radius:25px;width:100%;height:100px;background: linear-gradient(90deg, rgba(131,58,180,1) 0%, rgba(253,29,29,1) 50%, rgba(252,176,69,1) 100%);text-align:center\">\n    <h1 style=\"color:black;padding-top:30px\">Model creation<\/h1>\n<\/div>","f10cf625":"<div style=\"border-radius:25px;width:100%;height:100px;background: linear-gradient(90deg, rgba(131,58,180,1) 0%, rgba(253,29,29,1) 50%, rgba(252,176,69,1) 100%);text-align:center\">\n    <h1 style=\"color:black;padding-top:30px\">Plotting accuracy, loss and area under the curve change<\/h1>\n<\/div>","541fca9e":"<h1>We will use ResNet50V2 as our pretrained model where we proone the classifier part and put all layers to untrainable<\/h1>","67fdb029":"<h1>Example of residual network:<\/h1>","2ec51f6e":"<div style=\"border-radius:25px;width:100%;height:100px;background: linear-gradient(90deg, rgba(131,58,180,1) 0%, rgba(253,29,29,1) 50%, rgba(252,176,69,1) 100%);text-align:center\">\n    <h1 style=\"color:black;padding-top:30px\">Results over the test set<\/h1>\n<\/div>","d752ef53":"<div style=\"border-radius:25px;width:100%;height:100px;background: linear-gradient(90deg, rgba(131,58,180,1) 0%, rgba(253,29,29,1) 50%, rgba(252,176,69,1) 100%);text-align:center\">\n    <h1 style=\"color:black;padding-top:30px\">Plotting data samples<\/h1>\n<\/div>","e2b2cad1":"<h1>We can see that class distribution in our training set is highly unbalance (there is around 2.66x more pneumonia images than normal images)<\/h1>\n<h3><i>Solution<\/i>: One way that we can get a good performing model is to use data augmentation and transfer learning (because of relatively small number of images)<\/h3>","5bb4a89e":"<h1>We can see that this simple model without hyperparameter tuning is getting great results.<\/h1><br>\n<h3>Because of high class inbalance, our goto metric for model performace is auc (Area under the curve).<\/h3><br>\n<p>AUC value of 0.9-1 is concidered as excellent <i>(our model has 0.96 which you can see above)<\/i><\/p>","18041e39":"<div style=\"border-radius:25px;width:100%;height:100px;background: linear-gradient(90deg, rgba(131,58,180,1) 0%, rgba(253,29,29,1) 50%, rgba(252,176,69,1) 100%);text-align:center\">\n    <h1 style=\"color:black;padding-top:30px\">Plotting our model<\/h1>\n<\/div>","dcd36c87":"<div style=\"border-radius:25px;width:100%;height:100px;background: linear-gradient(90deg, rgba(131,58,180,1) 0%, rgba(253,29,29,1) 50%, rgba(252,176,69,1) 100%);text-align:center\">\n    <h1 style=\"color:black;padding-top:30px\">Plotting class distribution in our train dataset<\/h1>\n<\/div>","947362be":"<div style=\"border-radius:25px;width:100%;height:100px;background: linear-gradient(90deg, rgba(131,58,180,1) 0%, rgba(253,29,29,1) 50%, rgba(252,176,69,1) 100%);;text-align:center\">\n    <h1 style=\"color:black;padding-top:30px\">Paths to out directories<\/h1>\n<\/div>"}}