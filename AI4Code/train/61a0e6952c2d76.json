{"cell_type":{"dcf1f661":"code","08511df2":"code","2d6443c5":"code","88b6a0bd":"code","22ddc31f":"code","193777db":"code","63523f13":"code","24607e7c":"code","a33e5132":"code","da78f5db":"code","2387d1be":"code","08f18b8c":"code","5a49d5fb":"code","44a6a77d":"code","d3a551c4":"code","fb62b074":"code","613190e5":"code","0ca09843":"code","cdb94d79":"code","c03a532e":"code","49ef251e":"code","9a56f96b":"code","48353768":"code","3d88c510":"code","22fc1340":"code","1d5dee00":"code","a1c9d8a4":"code","bd60dafe":"code","29831888":"code","16a034f8":"code","1d5266da":"code","f3987378":"code","9c8d01c7":"code","8e4a192b":"code","792011d5":"code","8b98f2db":"code","6943aee6":"code","9cf2bf1a":"code","5e1935fa":"code","55a756df":"code","6391b1fd":"code","ed1711b4":"code","7356be2e":"code","3d39fd9d":"code","952bfc66":"code","51f144c1":"code","ebec93d5":"code","4b9850bc":"code","b5dffc1d":"code","081e325a":"markdown","88e2c849":"markdown","3be2a81d":"markdown","58e2c69a":"markdown","7563672a":"markdown","305595b4":"markdown","93413927":"markdown","54768bac":"markdown","b6dba92e":"markdown","09518f91":"markdown","d27bc033":"markdown","21ab9553":"markdown","6bd6133d":"markdown","89219823":"markdown","c28d5a9d":"markdown","6917658b":"markdown","d8b4a1be":"markdown","1a742a49":"markdown","2121ac05":"markdown"},"source":{"dcf1f661":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle'):\n    print(dirname)\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","08511df2":"from shutil import copyfile\nfrom random import seed\nfrom random import random\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom matplotlib import pyplot\nfrom matplotlib.image import imread\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\n","2d6443c5":"PARENT_DIR = '..\/input\/hackerearth-deep-learning-challenge-holidayseason\/dataset'\nprint(os.listdir(PARENT_DIR))\n","88b6a0bd":"train_csv = os.path.join(PARENT_DIR, 'train.csv')\ntrain_dir = os.path.join(PARENT_DIR, 'train')\ntest_dir = os.path.join(PARENT_DIR, 'test')","22ddc31f":"train_labels = pd.read_csv(train_csv)","193777db":"train_labels.Class.value_counts()","63523f13":"sample_images = train_labels.head(20)\nsample_images","24607e7c":"i = 1\nplt.figure(figsize=(10,10))\nfor img in sample_images.Image:\n    img = cv2.imread(os.path.join(train_dir,img),cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (150, 150),interpolation = cv2.INTER_NEAREST)\n    plt.subplot(5,4,i)\n    plt.imshow(img)\n    i+=1","a33e5132":"train_df,val_df = train_test_split(train_labels,test_size=.20,stratify=train_labels['Class'].values,shuffle=True)","da78f5db":"train_df.reset_index(inplace=True,drop=True)\nval_df.reset_index(inplace=True,drop=True)","2387d1be":"train_df.Class.value_counts()\n","08f18b8c":"val_df.Class.value_counts()","5a49d5fb":"train_Airplane = train_df[train_df['Class']=='Airplane']\ntrain_Candle = train_df[train_df['Class']=='Candle']\ntrain_Christmas_Tree = train_df[train_df['Class']=='Christmas_Tree']\ntrain_Jacket = train_df[train_df['Class']=='Jacket']\ntrain_Miscellaneous = train_df[train_df['Class']=='Miscellaneous']\ntrain_Snowman = train_df[train_df['Class']=='Snowman']","44a6a77d":"val_Airplane = val_df[val_df['Class']=='Airplane']\nval_Candle = val_df[val_df['Class']=='Candle']\nval_Christmas_Tree = val_df[val_df['Class']=='Christmas_Tree']\nval_Jacket = val_df[val_df['Class']=='Jacket']\nval_Miscellaneous = val_df[val_df['Class']=='Miscellaneous']\nval_Snowman = val_df[val_df['Class']=='Snowman']","d3a551c4":"# Directory\ndirectory = \"dataset_classes\"\n \n# Parent Directory path\nparent_dir = \"\/kaggle\/working\"\n \n# Path\npath = os.path.join(parent_dir, directory)\ntry:\n    os.makedirs(path, exist_ok = True)\n    print(\"Directory '%s' created successfully\" %directory)\nexcept OSError as error:\n    print(\"Directory '%s' can not be created\")","fb62b074":"dataset_home = '\/kaggle\/working\/dataset_classes\/'\nsubdirs = ['train\/', 'test\/']\nfor subdir in subdirs:\n\t# create label subdirectories\n\tlabeldirs = ['airplane\/', 'candle\/', 'christmas_tree\/', 'jacket\/', 'miscellaneous\/', 'snowman\/']\n\tfor labldir in labeldirs:\n\t\tnewdir = dataset_home + subdir + labldir\n\t\tos.makedirs(newdir)","613190e5":"for dirname, _, filenames in os.walk('\/kaggle\/working'):\n    print(dirname)","0ca09843":"# seed random number generator\nseed(1)\n# define ratio of pictures to use for validation\nval_ratio = 0.20\n# copy training dataset images into subdirectories\nsrc_directory = train_dir\nfor file in os.listdir(src_directory):\n    src = src_directory + '\/' + file\n    dst_dir1 = 'train\/'\n    dst_dir2 = 'test\/'\n    if file in list(train_Airplane.Image):\n        dst = dataset_home + dst_dir1 + 'airplane\/'  + file\n        copyfile(src, dst)\n    elif file in list(train_Candle.Image):\n        dst = dataset_home + dst_dir1 + 'candle\/'  + file\n        copyfile(src, dst)\n    elif file in list(train_Christmas_Tree.Image):\n        dst = dataset_home + dst_dir1 + 'christmas_tree\/'  + file\n        copyfile(src, dst)\n    elif file in list(train_Jacket.Image):\n        dst = dataset_home + dst_dir1 + 'jacket\/'  + file\n        copyfile(src, dst)\n    elif file in list(train_Snowman.Image):\n        dst = dataset_home + dst_dir1 + 'snowman\/'  + file\n        copyfile(src, dst)\n    elif file in list(train_Miscellaneous.Image):\n        dst = dataset_home + dst_dir1 + 'miscellaneous\/'  + file\n        copyfile(src, dst)\n    elif file in list(val_Airplane.Image):\n        dst = dataset_home + dst_dir2 + 'airplane\/'  + file\n        copyfile(src, dst)\n    elif file in list(val_Candle.Image):\n        dst = dataset_home + dst_dir2 + 'candle\/'  + file\n        copyfile(src, dst)\n    elif file in list(val_Christmas_Tree.Image):\n        dst = dataset_home + dst_dir2 + 'christmas_tree\/'  + file\n        copyfile(src, dst)\n    elif file in list(val_Jacket.Image):\n        dst = dataset_home + dst_dir2 + 'jacket\/'  + file\n        copyfile(src, dst)\n    elif file in list(val_Snowman.Image):\n        dst = dataset_home + dst_dir2 + 'snowman\/'  + file\n        copyfile(src, dst)\n    else :\n        dst = dataset_home + dst_dir2 + 'miscellaneous\/'  + file\n        copyfile(src, dst)\n        \n            ","cdb94d79":"# plot airplane photos \n\n# define location of dataset\nfolder = '\/kaggle\/working\/dataset_classes\/train\/airplane\/'\n# plot first few images\nfor i in range(9):\n\t# define subplot\n\tpyplot.subplot(330 + 1 + i)\n\t# define filename\n\tfilename = folder + list(train_Airplane.Image)[i]\n\t# load image pixels\n\timage = imread(filename)\n\t# plot raw pixel data\n\tpyplot.imshow(image)\n# show the figure\npyplot.show()","c03a532e":"# plot candle photos \n\n# define location of dataset\nfolder = '\/kaggle\/working\/dataset_classes\/train\/candle\/'\n# plot first few images\nfor i in range(9):\n\t# define subplot\n\tpyplot.subplot(330 + 1 + i)\n\t# define filename\n\tfilename = folder + list(train_Candle.Image)[i]\n\t# load image pixels\n\timage = imread(filename)\n\t# plot raw pixel data\n\tpyplot.imshow(image)\n# show the figure\npyplot.show()","49ef251e":"# plot christmas_tree photos \n\n# define location of dataset\nfolder = '\/kaggle\/working\/dataset_classes\/train\/christmas_tree\/'\n# plot first few images\nfor i in range(9):\n\t# define subplot\n\tpyplot.subplot(330 + 1 + i)\n\t# define filename\n\tfilename = folder + list(train_Christmas_Tree.Image)[i+10]\n\t# load image pixels\n\timage = imread(filename)\n\t# plot raw pixel data\n\tpyplot.imshow(image)\n# show the figure\npyplot.show()","9a56f96b":"# plot jacket photos \n\n# define location of dataset\nfolder = '\/kaggle\/working\/dataset_classes\/train\/jacket\/'\n# plot first few images\nfor i in range(9):\n\t# define subplot\n\tpyplot.subplot(330 + 1 + i)\n\t# define filename\n\tfilename = folder + list(train_Jacket.Image)[i+5]\n\t# load image pixels\n\timage = imread(filename)\n\t# plot raw pixel data\n\tpyplot.imshow(image)\n# show the figure\npyplot.show()","48353768":"# plot snowman photos \n\n# define location of dataset\nfolder = '\/kaggle\/working\/dataset_classes\/train\/snowman\/'\n# plot first few images\nfor i in range(9):\n\t# define subplot\n\tpyplot.subplot(330 + 1 + i)\n\t# define filename\n\tfilename = folder + list(train_Snowman.Image)[i+33]\n\t# load image pixels\n\timage = imread(filename)\n\t# plot raw pixel data\n\tpyplot.imshow(image)\n# show the figure\npyplot.show()","3d88c510":"# plot miscellaneous photos \n\n# define location of dataset\nfolder = '\/kaggle\/working\/dataset_classes\/train\/miscellaneous\/'\n# plot first few images\nfor i in range(9):\n\t# define subplot\n\tpyplot.subplot(330 + 1 + i)\n\t# define filename\n\tfilename = folder + list(train_Miscellaneous.Image)[i]\n\t# load image pixels\n\timage = imread(filename)\n\t# plot raw pixel data\n\tpyplot.imshow(image)\n# show the figure\npyplot.show()","22fc1340":"model1 = tf.keras.models.Sequential([\n    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.2),\n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(), \n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(512, activation='relu'), \n    # 6 output neuron. It will contain a value from 0-5 for 6 classes\n    tf.keras.layers.Dense(6, activation='softmax')  \n])","1d5dee00":"model1.summary()","a1c9d8a4":"opt = tf.keras.optimizers.Adam(learning_rate=0.001)\nmodel1.compile(optimizer=opt,\n              loss='categorical_crossentropy',\n              metrics = ['categorical_accuracy'])","bd60dafe":"# All images will be rescaled by 1.\/255.\ntrain_datagen = ImageDataGenerator( rescale = 1.0\/255. )\ntest_datagen  = ImageDataGenerator( rescale = 1.0\/255. )\n\n# --------------------\n# Flow training images in batches of 20 using train_datagen generator\n# --------------------\ntrain_generator = train_datagen.flow_from_directory('\/kaggle\/working\/dataset_classes\/train\/',\n                                                    batch_size=20,\n                                                    class_mode='categorical',\n                                                    target_size=(150, 150))     \n# --------------------\n# Flow validation images in batches of 20 using test_datagen generator\n# --------------------\nvalidation_generator =  test_datagen.flow_from_directory('\/kaggle\/working\/dataset_classes\/test\/',\n                                                         batch_size=20,\n                                                         class_mode  = 'categorical',\n                                                         target_size = (150, 150))","29831888":"history1 = model1.fit(train_generator,\n                              validation_data=validation_generator,\n                              steps_per_epoch=100,\n                              epochs=15,\n                              validation_steps=50,\n                              verbose=2)","16a034f8":"#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc      = history1.history[     'categorical_accuracy' ]\nval_acc  = history1.history[ 'val_categorical_accuracy' ]\nloss     = history1.history[    'loss' ]\nval_loss = history1.history['val_loss' ]\n\nepochs   = range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     acc )\nplt.plot  ( epochs, val_acc )\nplt.title ('Training and validation accuracy')\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     loss )\nplt.plot  ( epochs, val_loss )\nplt.title ('Training and validation loss'   )","1d5266da":"train_datagen = ImageDataGenerator(\n      rescale=1.\/255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\n# Flow training images in batches of 20 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(\n        '\/kaggle\/working\/dataset_classes\/train\/',  # This is the source directory for training images\n        target_size=(150, 150),  # All images will be resized to 150x150\n        batch_size=20,\n        # Since we use categorical_crossentropy loss, we need categoricals labels\n        class_mode='categorical')\n\n# Flow validation images in batches of 20 using test_datagen generator\nvalidation_generator = test_datagen.flow_from_directory(\n        '\/kaggle\/working\/dataset_classes\/test\/',\n        target_size=(150, 150),\n        batch_size=20,\n        class_mode='categorical')\n","f3987378":"history2 = model1.fit(\n      train_generator,\n      steps_per_epoch=100,  \n      epochs=15,\n      validation_data=validation_generator,\n      validation_steps=50,  \n      verbose=2)","9c8d01c7":"#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc      = history2.history[     'categorical_accuracy' ]\nval_acc  = history2.history[ 'val_categorical_accuracy' ]\nloss     = history2.history[    'loss' ]\nval_loss = history2.history['val_loss' ]\n\nepochs   = range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     acc )\nplt.plot  ( epochs, val_acc )\nplt.title ('Training and validation accuracy')\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     loss )\nplt.plot  ( epochs, val_loss )\nplt.title ('Training and validation loss'   )","8e4a192b":"from tensorflow.keras.applications.inception_v3 import InceptionV3\n\npre_trained_model1 = InceptionV3(input_shape = (150, 150, 3), \n                                include_top = False, \n                                weights = 'imagenet')\n\n\nfor layer in pre_trained_model1.layers:\n  layer.trainable = False\n  \n\nlast_output1 = pre_trained_model1.output","792011d5":"\n# Flatten the output layer to 1 dimension\nx1 = layers.Flatten()(last_output1)\n\n# Add a fully connected layer with 1,024 hidden units and ReLU activation\nx1 = layers.Dense(1024, activation='relu')(x1)\n\n# Add a dropout rate of 0.2\nx1 = layers.Dropout(0.2)(x1) \n\n# Add a fully connected layer with 512 hidden units and ReLU activation\nx1 = layers.Dense(512, activation='relu')(x1)\n\n# Add a dropout rate of 0.2\nx1 = layers.Dropout(0.2)(x1) \n\n# Add a final sigmoid layer for classification\nx1 = layers.Dense  (6, activation='softmax')(x1)     \n\n\nmodel3 = Model( pre_trained_model1.input, x1) \n\nmodel3.compile(optimizer = opt, \n              loss = 'categorical_crossentropy', \n              metrics = ['categorical_accuracy'])","8b98f2db":"model3.summary()","6943aee6":"history3 = model3.fit(\n            train_generator,\n            validation_data = validation_generator,\n            steps_per_epoch = 100,\n            epochs = 50,\n            validation_steps = 50,\n            verbose = 2)\n","9cf2bf1a":"#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc      = history3.history[     'categorical_accuracy' ]\nval_acc  = history3.history[ 'val_categorical_accuracy' ]\nloss     = history3.history[    'loss' ]\nval_loss = history3.history['val_loss' ]\n\nepochs   = range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     acc )\nplt.plot  ( epochs, val_acc )\nplt.title ('Training and validation accuracy')\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     loss )\nplt.plot  ( epochs, val_loss )\nplt.title ('Training and validation loss'   )","5e1935fa":"from tensorflow.keras.applications.vgg16 import VGG16\n\npretrained_model2 = VGG16(input_shape = (150, 150, 3), # Shape of our images\n                        include_top = False, # Leave out the last fully connected layer\n                        weights = 'imagenet')\n\nfor layer in pretrained_model2.layers:\n    layer.trainable = False","55a756df":"# Flatten the output layer to 1 dimension\nx = layers.Flatten()(pretrained_model2.output)\n\n# Add a fully connected layer with 1024 hidden units and ReLU activation\nx = layers.Dense(1024, activation='relu')(x)\n\n# Add a dropout rate of 0.2\nx = layers.Dropout(0.2)(x)\n\n# Add a fully connected layer with 512 hidden units and ReLU activation\nx = layers.Dense(512, activation='relu')(x)\n\n# Add a dropout rate of 0.2\nx = layers.Dropout(0.2)(x)\n\n# Add a final sigmoid layer for classification\nx = layers.Dense(6, activation='softmax')(x)\n\nmodel4 = tf.keras.models.Model(pretrained_model2.input, x)","6391b1fd":"model4.summary()","ed1711b4":"model4.compile(optimizer = opt,\n               loss = 'categorical_crossentropy',\n               metrics = ['categorical_accuracy'])","7356be2e":"history4 = model4.fit(\n            train_generator,\n            validation_data = validation_generator,\n            steps_per_epoch = 100,\n            epochs = 50,\n            validation_steps = 50,\n            verbose = 2)\n","3d39fd9d":"#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc      = history4.history[     'categorical_accuracy' ]\nval_acc  = history4.history[ 'val_categorical_accuracy' ]\nloss     = history4.history[    'loss' ]\nval_loss = history4.history['val_loss' ]\n\nepochs   = range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     acc )\nplt.plot  ( epochs, val_acc )\nplt.title ('Training and validation accuracy')\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     loss )\nplt.plot  ( epochs, val_loss )\nplt.title ('Training and validation loss'   )","952bfc66":"from keras.preprocessing import image\nprediction = []\nImage = []\nlabels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\n\nfor i, file in enumerate(os.listdir(test_dir)):\n    Image.append(file)\n    file = test_dir +'\/'+ file\n\n    img = image.load_img(file, target_size=(150,150,3)) \n    img = image.img_to_array(img)\n    img = img\/255\n    pred = model4.predict(img.reshape(1,150,150,3))\n\n    prediction.append(labels[np.argmax(pred[0])])","51f144c1":"Submission=pd.DataFrame((zip(Image, prediction)),columns=['Image','Class'])\n","ebec93d5":"Submission.Class.value_counts()","4b9850bc":"Submission['Class'] = Submission['Class'].map({\n'airplane':'Airplane',\n'candle':'Candle',\n'christmas_tree':'Christmas_Tree',\n'jacket':'Jacket',\n'miscellaneous':'Miscellaneous',\n'snowman':'Snowman'\n})","b5dffc1d":"Submission.to_csv('VGG16.csv',index=False)","081e325a":"### Plotting Some Images from each Class.","88e2c849":"### Creating Seperate DataFrames for each classes, for both, training and validation set.","3be2a81d":"## Scores On Submission\n\n### Model 1(Simple CNN) gives score of 60.96496\n### Model 2(Simple CNN with Data Augmentation) gives score of 64.43637\n### Model 3(InceptionV3) gives score of 83.27723\n### Model 4(VGG16) gives score of 76.27789\n## ...","58e2c69a":"### Observing value counts of all Classes.","7563672a":"### 1.InceptionV3 model","305595b4":"### Reading CSV file containing training data labels.","93413927":"### Creating new mentioned directory under mentioned parent directory followed by creating sub directories of training and validation set along all the Classes.","54768bac":"## Applying Transfer Learning.","b6dba92e":"### Creating a Simple CNN model to see how it performs on the prepared data.","09518f91":"### Defining data directories.","d27bc033":"### Creating Submission CSV","21ab9553":"### Defining parent directory and listing files in it.","6bd6133d":"## Importing all used Libraries.","89219823":"### 2.VGG16 Model","c28d5a9d":"### Splitting Training DataSet into Training and Validation Set\n\n*Note* - Doing Stratified Splitting so that the Training and Validation Set have equal proportion of all the Classes.","6917658b":"### Applying Data Augmentation Techniques to the Same Model.","d8b4a1be":"### Viewing Some Images of Training Dataset","1a742a49":"### Copying training data to the respective Class Sub directory,for both, training and validation set.","2121ac05":"## Im going to train few more pretrained models."}}