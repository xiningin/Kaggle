{"cell_type":{"7387fab5":"code","868e0662":"code","855ee750":"code","5de12930":"code","a361ce6d":"code","0c86d5e0":"code","5b8df326":"code","4998d1ab":"code","5010e696":"code","d5f37c76":"code","4bd5138b":"code","1a167986":"code","f3c41898":"code","5ebb66a4":"code","9b16ad38":"code","a1c84862":"code","28ae713a":"markdown","fed5a34e":"markdown","b6107ee8":"markdown"},"source":{"7387fab5":"!pip install kneed","868e0662":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nimport time\n\nimport datetime as datetime\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\n\nfrom kneed import KneeLocator\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\nimport plotly\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport cufflinks as cf\ncf.set_config_file(offline=True)","855ee750":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5de12930":"path_file = r'\/kaggle\/input\/smart-meter-dataset\/'","a361ce6d":"def MinMaxScaler(data):\n    return (data-np.min(data))\/(np.max(data)-np.min(data))\n\ndef Kmeans_clustering(df, clusterNum, max_iter, n_jobs):\n    scaler = StandardScaler()\n    scaler.fit(df)\n    df_std = pd.DataFrame(data=scaler.transform(df), columns=df.columns, index=df.index)\n    km_model = KMeans(n_clusters=clusterNum, max_iter=max_iter, random_state=666)\n    km_model = km_model.fit(df_std)\n    clusterdf= pd.DataFrame(data=km_model.labels_, columns=['ClusterNo'])\n    clusterdf.index = df.index\n    return clusterdf\n\ndef Kmeans_bestClusterNum(df, range_min, range_max, max_iter, n_jobs):\n    silhouette_avgs = []\n    sum_of_squared_distances = []\n    \n    ks = range(range_min,range_max+1)\n    for k in ks:\n        kmeans_fit = KMeans(n_clusters = k, max_iter=max_iter, random_state=666).fit(df)\n        cluster_labels = kmeans_fit.labels_\n        sum_of_squared_distances.append(kmeans_fit.inertia_)\n        \n    kn = KneeLocator(list(ks), sum_of_squared_distances, S=1.0, curve='convex', direction='decreasing')  \n    plt.xlabel('k')\n    plt.ylabel('sum_of_squared_distances')\n    plt.title('The Elbow Method showing the optimal k')\n    plt.plot(ks, sum_of_squared_distances, 'bx-')\n    plt.vlines(kn.knee, plt.ylim()[0], plt.ylim()[1], linestyles='dashed')\n    plt.show()\n    print('Optimal clustering number:'+str(kn.knee))\n    print('----------------------------')    \n    \n    return kn.knee","0c86d5e0":"df_metadata_loop = pd.read_csv(os.path.join(path_file, 'metadata_loop.csv'))\ndf_metadata_loop","5b8df326":"df_metadata_uid = pd.read_csv(os.path.join(path_file, 'metadata_uid.csv'))\ndf_metadata_uid","4998d1ab":"df_powerMeter_pivot_output = pd.read_csv(os.path.join(path_file, 'powerMeter.csv'))\ndf_powerMeter_pivot_output['\u65e5\u671f\u6642\u9593'] = pd.to_datetime(df_powerMeter_pivot_output['\u65e5\u671f\u6642\u9593'])\ndf_powerMeter_pivot_output = df_powerMeter_pivot_output.set_index('\u65e5\u671f\u6642\u9593')\ndf_powerMeter_pivot_output","5010e696":"# Leave meters with building type of '\u884c\u653f\u55ae\u4f4d'\nbuilding_type = '\u884c\u653f\u55ae\u4f4d'\n\ndf_metadata = df_metadata_loop.merge(df_metadata_uid, on='uid')\nlist_powerMeter = df_metadata[df_metadata['buildType1C']==building_type]['\u8ff4\u8def\u7de8\u865f'].to_list()\ndf_powerMeter_pivot_output = df_powerMeter_pivot_output.loc[:, df_powerMeter_pivot_output.columns.str.contains('|'.join(list_powerMeter))]\ndf_powerMeter_pivot_output.columns","d5f37c76":"df_PM_temp = df_powerMeter_pivot_output.copy()\ndf_PM_temp = (df_PM_temp-df_PM_temp.mean())\/df_PM_temp.std()\ndf_PM_temp = df_PM_temp.T\n\ntry:\n    bestClusterNum_dept = Kmeans_bestClusterNum(df=df_PM_temp.fillna(0), range_min=2, range_max=20, max_iter=10000, n_jobs=-1)\nexcept:\n    try:\n        bestClusterNum_dept = Kmeans_bestClusterNum(df=df_PM_temp.fillna(0), range_min=2, range_max=15, max_iter=10000, n_jobs=-1)    \n    except:\n        try:\n            bestClusterNum_dept = Kmeans_bestClusterNum(df=df_PM_temp.fillna(0), range_min=2, range_max=10, max_iter=10000, n_jobs=-1)    \n        except:\n            bestClusterNum_dept = 3\n\ntry:\n    df_PM_temp['ClusterNo'] = Kmeans_clustering(df=df_PM_temp.fillna(0), clusterNum=bestClusterNum_dept, max_iter=100000, n_jobs=-1)\nexcept:\n    bestClusterNum_dept = 3\n    df_PM_temp['ClusterNo'] = Kmeans_clustering(df=df_PM_temp.fillna(0), clusterNum=bestClusterNum_dept, max_iter=100000, n_jobs=-1)\n\nfor ClusterNo in df_PM_temp['ClusterNo'].sort_values().unique():\n    df_plot = df_PM_temp[df_PM_temp['ClusterNo']==ClusterNo].T.drop('ClusterNo')\n    print('ClusterNo: ' + str(ClusterNo))    \n    print('Amount of meters: ' + str(len(df_plot.T)))\n    df_plot.plot(figsize=(15,5),color='black',alpha=0.1,legend=False, ylim=(-5, 10))\n    plt.xlabel(\"\")\n    plt.show()\n    print('---------------------------------------------------------------------------------------------------')","4bd5138b":"df_cluster = df_PM_temp.iloc[:,-1].reset_index().copy()\nfor idx_1 in df_cluster.index:\n    for idx_2 in df_metadata_loop.index:\n        name_loop = df_metadata_loop.loc[idx_2, '\u8ff4\u8def\u7de8\u865f']\n        if name_loop in df_cluster.loc[idx_1, 'index']:\n            df_cluster.loc[idx_1, '\u8ff4\u8def\u7de8\u865f'] = name_loop\ndf_cluster","1a167986":"df_cluster = df_cluster.merge(df_metadata_loop, on='\u8ff4\u8def\u7de8\u865f')\ndf_cluster = df_cluster.merge(df_metadata_uid, on='uid')\ndf_cluster","f3c41898":"df_plot = df_cluster.pivot_table(columns='buildType1C', index='ClusterNo', values='index', aggfunc='count')\ndf_plot.plot.bar(stacked=True, figsize=(15,5), title='Number of meters in each cluster', legend=False)","5ebb66a4":"df_energy = df_powerMeter_pivot_output.mean() * df_powerMeter_pivot_output.count().max()\ndf_energy = df_energy.reset_index().rename(columns={0:'energy_sum'})\ndf_energy = df_energy.merge(df_cluster, on='index')\ndf_energy['EUI'] = df_energy['energy_sum'] \/ df_energy['area'].replace(',','.', regex=True).astype('float')\ndf_energy","9b16ad38":"plt.figure(figsize=(3,5))\nax = sns.boxplot(x=\"buildType1E\", y=\"EUI\", data=df_energy[df_energy['EUI']<10**3].sort_values('buildType1E'))\nax = sns.swarmplot(x=\"buildType1E\", y=\"EUI\", data=df_energy[df_energy['EUI']<10**3].sort_values('buildType1E'), color=\".25\")","a1c84862":"plt.figure(figsize=(10,5))\nax = sns.boxplot(x=\"ClusterNo\", y=\"EUI\", data=df_energy[df_energy['EUI']<10**3])\nax = sns.swarmplot(x=\"ClusterNo\", y=\"EUI\", data=df_energy[df_energy['EUI']<10**3], color=\".25\")","28ae713a":"## Load dataset","fed5a34e":"## Clustering & visualizations","b6107ee8":"## Process dataset (Target: \u884c\u653f\u55ae\u4f4d)"}}