{"cell_type":{"b85aecbd":"code","67561144":"code","c078215f":"code","62cfdcd5":"code","7dc36161":"code","eb41392f":"code","7ee9897d":"code","6bc8920a":"code","929e49b5":"code","906daffa":"code","7d83f36d":"code","17cf72df":"code","02bd9878":"code","c35ae778":"code","d84f4d00":"code","4b3c04bf":"code","d00c92f6":"code","38a8b211":"code","ed6aab60":"code","d5529734":"code","952e1b15":"code","732973aa":"code","f5dc822a":"code","e0486cdb":"code","97855298":"code","685aee9f":"code","fa0a9235":"markdown","3494f223":"markdown","aeb41f3d":"markdown"},"source":{"b85aecbd":"import pandas as pd\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport seaborn as sns\r\nimport xgboost as xg\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.metrics import mean_squared_error as MSE \r\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\r\nfrom sklearn.neighbors import KNeighborsClassifier\r\nfrom sklearn.svm import SVC\r\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\r\nfrom sklearn.naive_bayes import GaussianNB\r\nfrom sklearn.metrics import roc_curve, roc_auc_score, mean_squared_error as MSE, log_loss,r2_score\r\nimport warnings\r\nwarnings.filterwarnings('ignore')","67561144":"DATA_PATH = \"\/kaggle\/input\/water-quality-dataset\/waterPollution.csv\"","c078215f":"data = pd.read_csv(DATA_PATH)","62cfdcd5":"data.head()","7dc36161":"data.isna().sum()","eb41392f":"data.dropna(axis=0,inplace=True)","7ee9897d":"columns = (\"parameterWaterBodyCategory\",\"observedPropertyDeterminandCode\",\"procedureAnalysedFraction\",\"procedureAnalysedMedia\",\"resultUom\",\"parameterSamplingPeriod\",\"waterBodyIdentifier\",\"Country\")\r\nfor i in columns:\r\n  le = LabelEncoder()\r\n  data[i] = le.fit_transform(data[i])","6bc8920a":"x = data.drop([\"resultMeanValue\"],axis = 1)\r\ny = data[\"resultMeanValue\"].values","929e49b5":"data[\"resultMeanValue\"].plot()","906daffa":"x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.3, random_state = 42)","7d83f36d":"def makeClass(y):\r\n  y = [\"Dirty\" if x > 500 else \"Clean\" for x in y]\r\n  return y","17cf72df":"y_train, y_test = makeClass(y_train),makeClass(y_test)","02bd9878":"scaler = MinMaxScaler()\r\nx_train = scaler.fit_transform(x_train)\r\nx_test = scaler.fit_transform(x_test)","c35ae778":"def createModels():\r\n  xgBoost = xg.XGBClassifier()\r\n  knn = KNeighborsClassifier()\r\n  svc = SVC(probability=True)\r\n  randomForest = RandomForestClassifier()\r\n  adaBoost = AdaBoostClassifier()\r\n  nb = GaussianNB()\r\n  return ((xgBoost,\"XGBoost Classifier\"),(knn,\"KNN Classifier\"),(svc,\"SVC Classifier\"),(randomForest,\"Random Forest Classifier\"),(adaBoost,\"AdaBoost Classifier\"),(nb,\"Naive Bayes Classifier\"))\r\n\r\nmodels = createModels()\r\nfor model,name in models:\r\n  model.fit(x_train,y_train)\r\n  print(f\"Accuracy of {name}: {model.score(x_test,y_test)}\")","d84f4d00":"y_test = [0 if i == \"Clean\" else 1 for i in y_test]\r\nfor model,name in models:\r\n  y_score = model.predict_proba(x_test)[:,1] \r\n  false_positive_rate, true_positive_rate, threshold = roc_curve(y_test, y_score)\r\n  print(f'roc_auc_score for {name}: ', roc_auc_score(y_test, y_score))","4b3c04bf":"plt.subplots(nrows=2,ncols=3,figsize = (25,15))\r\nfigurePos = 1\r\nfor model,name in models:\r\n  plt.subplot(2,3,figurePos)\r\n  figurePos += 1\r\n  y_score = model.predict_proba(x_test)[:,1] \r\n  false_positive_rate, true_positive_rate, threshold = roc_curve(y_test, y_score)\r\n  plt.title(f\"ROC Curve {name}\")\r\n  plt.plot(false_positive_rate, true_positive_rate)\r\n  plt.plot([0, 1], ls=\"--\")\r\n  plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\r\n  plt.ylabel('True Positive Rate')\r\n  plt.xlabel('False Positive Rate')\r\nplt.show()","d00c92f6":"features = np.concatenate([data.columns[:7],data.columns[8:]])\r\n\r\nmodel = xg.XGBClassifier()\r\nmodel.fit(x_train,y_train)\r\nfeat_imp = pd.DataFrame({'importance':model.feature_importances_})    \r\nfeat_imp['feature'] = features\r\nfeat_imp.sort_values(by='importance', ascending=False, inplace=True)\r\nfeat_imp = feat_imp.iloc[:12]   \r\nfeat_imp.sort_values(by='importance', inplace=True)\r\nfeat_imp = feat_imp.set_index('feature', drop=True)\r\nfeat_imp.plot.barh(title=\"XGBoost\")\r\nplt.xlabel('Feature Importance Score')\r\nplt.show()","38a8b211":"x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.3, random_state = 42)","ed6aab60":"scaler = MinMaxScaler()\r\nx_train = scaler.fit_transform(x_train)\r\nx_test = scaler.fit_transform(x_test)","d5529734":"regressor = xg.XGBRegressor()\\\r\n            .fit(x_train,y_train)","952e1b15":"preds = regressor.predict(x_test)","732973aa":"preds","f5dc822a":"mse = MSE(y_test,preds)\r\nr2Score = r2_score(y_test,preds)","e0486cdb":"print(\"Metrics for XGBoost Regressor\")\r\nprint(f\"MSE: {mse}\\nRMSE: {mse ** (1\/2)}\\nR^2 Score: {r2Score}\")","97855298":"model = KNeighborsClassifier()\r\n\r\ny = data[\"resultMeanValue\"].values\r\nx = data.drop([\"resultMeanValue\"],axis = 1)\r\n\r\ndef makeClass(y):\r\n  y = [\"Dirty\" if x > 500 else \"Clean\" for x in y]\r\n  return y\r\n\r\n\r\ndef fitData(x,y,model,columns):\r\n  a = x[columns]\r\n  x_train,x_test,y_train,y_test = train_test_split(a,y,test_size = 0.3,random_state=42)\r\n  y_train, y_test = makeClass(y_train),makeClass(y_test)\r\n  scaler = MinMaxScaler()\r\n  x_train = scaler.fit_transform(x_train)\r\n  x_test = scaler.fit_transform(x_test)\r\n  model.fit(x_train,y_train)\r\n  return model.score(x_test,y_test)\r\n\r\nusedCols = list()\r\nscores = list()\r\nfor col in x.columns:\r\n  usedCols.append(col)\r\n  score = fitData(x,y,model,usedCols)\r\n  scores.append(score)\r\n  print(f\"Accuracy with {col} Feature: {score}\")\r\n  print(\"-\"*65)\r\n","685aee9f":"plt.figure(figsize=(25,10))\r\nsns.barplot(x=usedCols,y=scores)\r\nplt.xticks(rotation=60)\r\nplt.show()","fa0a9235":"# Run Classifier By Features","3494f223":"# Regression","aeb41f3d":"# Classification"}}