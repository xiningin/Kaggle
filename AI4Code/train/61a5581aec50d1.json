{"cell_type":{"7fdcb8da":"code","af5f57f6":"code","94ea04cb":"code","0d76cade":"code","e7fa098b":"code","db46d9f5":"code","54a5598f":"code","88ffdccb":"code","02f324e1":"code","4da69219":"code","07c297ee":"code","3c06458e":"code","028ff076":"code","f4b5d963":"code","cd50db82":"code","5f2acc53":"code","aa2949ef":"code","d9dfff2d":"markdown"},"source":{"7fdcb8da":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","af5f57f6":"import matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\n\nimport tensorflow.keras as keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout","94ea04cb":"stock = pd.read_csv(os.path.join(dirname, filename))\nstock.head()","0d76cade":"df = stock[['open','close']]\ndf.head()","e7fa098b":"scaler = MinMaxScaler()\ndf[df.columns] = scaler.fit_transform(df)\ndf.head()","db46d9f5":"df.info()","54a5598f":"train = df.iloc[:1100,:]\ntest = df.iloc[1100:,:]","88ffdccb":"# Function to generate sequences of data\ndef seq_gen(df):\n    X = df[['open','close']].reset_index(drop=True)\n    y = df[['open','close']].reset_index(drop=True)\n\n    seq = []\n    labels = []\n    index = 0\n    \n    seq_length = 50\n    while index != X.iloc[-seq_length:].index[0]:\n        start = index\n        stop = index+seq_length\n        new = np.array(X.iloc[start:stop])\n        label = np.array(y.iloc[stop])\n        seq.append(new)\n        labels.append(label)\n        start += 1\n        stop += 1\n        index += 1\n\n    seq = np.array(seq)\n    labels = np.array(labels)\n    labels = labels.reshape(labels.shape[0], -1)\n\n    return(seq, labels)","02f324e1":"train_seq, train_labels = seq_gen(train)\ntest_seq, test_labels = seq_gen(test)","4da69219":"train_seq.shape, train_labels.shape, test_seq.shape, test_labels.shape","07c297ee":"# Initializing model\nregressor = Sequential()\nregressor.add(LSTM(units = 50, return_sequences = True, input_shape = (50, 2)))\nregressor.add(Dropout(0.2))             \n\nregressor.add(LSTM(units = 50, return_sequences = True))\nregressor.add(Dropout(0.2))\n\nregressor.add(LSTM(units = 50))\nregressor.add(Dropout(0.2))\n\nregressor.add(Dense(units = 2))\n\n\nregressor.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error'])\nregressor.summary()","3c06458e":"# Model training\nepochs = 200\nbatch_size = 80\n\n# fit the network\nhistory = regressor.fit(train_seq, train_labels, epochs=epochs, batch_size=batch_size, validation_data=(test_seq, test_labels), verbose=1)","028ff076":"# Predictions\ntrain_pred = regressor.predict(train_seq)\ntest_pred = regressor.predict(test_seq)","f4b5d963":"open_pred = [i[0] for i in train_pred]\nopen_actual = [i[0] for i in train_labels]\nplt.plot(np.arange(len(open_actual)), open_actual, label='actual')\nplt.plot(np.arange(len(open_pred)), open_pred, label='predicted')\nplt.title('Open')\nplt.legend()\nplt.show()\n\nclose_pred = [i[1] for i in train_pred]\nclose_actual = [i[1] for i in train_labels]\nplt.plot(np.arange(len(close_actual)), close_actual, label='actual')\nplt.plot(np.arange(len(close_pred)), close_pred, label='predicted')\nplt.title('Close')\nplt.legend()\nplt.show()","cd50db82":"open_pred = [i[0] for i in test_pred]\nopen_actual = [i[0] for i in test_labels]\nplt.plot(np.arange(len(open_actual)), open_actual, label='actual')\nplt.plot(np.arange(len(open_pred)), open_pred, label='predicted')\nplt.title('Open')\nplt.legend()\nplt.show()\n\nclose_pred = [i[1] for i in test_pred]\nclose_actual = [i[1] for i in test_labels]\nplt.plot(np.arange(len(close_actual)), close_actual, label='actual')\nplt.plot(np.arange(len(close_pred)), close_pred, label='predicted')\nplt.title('Close')\nplt.legend()\nplt.show()","5f2acc53":"# Predicting the prices of upcomming 5 days\nlatest_prediction = []\nlast_seq = test_seq[-1:]\n\ni=0\nwhile i!=5:\n    prediction = regressor.predict(last_seq)\n    latest_prediction.append(prediction)\n    last_seq = np.append(last_seq[0][1:],prediction,axis=0)\n    last_seq = last_seq.reshape(test_seq[-1:].shape)\n    i += 1","aa2949ef":"open_next = [i[0][0] for i in latest_prediction]\nopen_pred = [i[0] for i in test_pred]\nopen_actual = [i[0] for i in test_labels]\nplt.plot(np.arange(len(open_actual)), open_actual, label='actual')\nplt.plot(np.arange(len(open_pred)), open_pred, label='predicted')\nplt.plot(np.arange(len(open_pred), len(open_pred)+len(open_next)), open_next, label='upcomming 5 days predicted')\nplt.title('Open')\nplt.legend()\nplt.show()\n\nclose_next = [i[0][1] for i in latest_prediction]\nclose_pred = [i[1] for i in test_pred]\nclose_actual = [i[1] for i in test_labels]\nplt.plot(np.arange(len(close_actual)), close_actual, label='actual')\nplt.plot(np.arange(len(close_pred)), close_pred, label='predicted')\nplt.plot(np.arange(len(close_pred), len(close_pred)+len(close_next)), close_next, label='upcomming 5 days predicted')\nplt.title('Close')\nplt.legend()\nplt.show()","d9dfff2d":"# Thus we can say that in the upcomming 5 days, stock price is going to fall."}}