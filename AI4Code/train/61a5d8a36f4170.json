{"cell_type":{"7c92ee51":"code","535bf00a":"code","ae160e50":"code","90ce1bb8":"code","567b1987":"code","53504044":"code","613f1dff":"code","dbaf09da":"code","bcf0425d":"code","122b93c4":"code","75cbd7a0":"code","3404fbe4":"code","d8180789":"code","da9217f2":"code","6035b81a":"code","214f6ed3":"code","91ed9fa4":"code","5f28fa55":"code","25c82840":"code","816587dd":"code","201ff325":"code","73f6858d":"code","0ae309d0":"code","90261171":"code","ff0fc523":"code","35fb1842":"code","cb41dc20":"code","b4cd2b87":"code","ec6bb3aa":"code","81f2c1a8":"code","a5da00d0":"code","dc605361":"code","4a799bb9":"code","c83ea14c":"code","bdd60724":"code","b835599f":"code","dcf32140":"code","be970b58":"code","b31028ce":"markdown","ed4e56ef":"markdown","f484e76d":"markdown","a8ed6190":"markdown","de9902ca":"markdown","4685bb08":"markdown","cc20384d":"markdown"},"source":{"7c92ee51":"import pandas as pd\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize'] = 15,15\nimport seaborn as sns\nimport plotly.express as px\nfrom bokeh.io import output_notebook, show\nfrom bokeh.models import (\n    BasicTicker,\n    ColorBar,\n    ColumnDataSource,\n    LinearColorMapper,\n    PrintfTickFormatter,\n)\nfrom bokeh.plotting import figure\nfrom bokeh.transform import transform\n\nimport numpy as np\n    \nimport xgboost as xgb\nimport lightgbm as lgb\nimport catboost as cb\nfrom sklearn.ensemble import StackingRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom mlxtend.regressor import StackingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import train_test_split,KFold,StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder,StandardScaler\nfrom pandas_profiling import ProfileReport\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.linear_model import Lasso, Ridge, ElasticNet, RANSACRegressor, SGDRegressor, HuberRegressor, BayesianRidge \nfrom sklearn.ensemble import RandomForestRegressor, BaggingRegressor, AdaBoostRegressor, GradientBoostingRegressor, ExtraTreesRegressor \nfrom sklearn.tree import DecisionTreeRegressor \nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.pipeline import Pipeline \nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.decomposition import KernelPCA, PCA,TruncatedSVD \n\nfrom tqdm.notebook import tqdm ,tnrange\nimport gc\nimport regex as re\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","535bf00a":"train_data = pd.read_csv('..\/input\/mathco\/train.csv')\n\ntrain_data = train_data[~train_data.duplicated()].reset_index(drop =True)\n\nprint(train_data.shape)\n\ntrain_data.head()","ae160e50":"test_data = pd.read_csv('..\/input\/mathco\/test.csv')\n\ntest_data.drop(columns = 'Price',inplace = True)\n\nprint(test_data.shape)\n\ntest_data.head()","90ce1bb8":"profile_train = ProfileReport(train_data, title='Pandas Test Profiling Report',html={'style':{'full_width':True}})\n\nprofile_train.to_file(\"train.html\")\n\nprofile_train","567b1987":"profile_test = ProfileReport(test_data, title='Pandas Test Profiling Report',html={'style':{'full_width':True}},minimal=True)\n\nprofile_test.to_file(\"test.html\")\n\nprofile_test","53504044":"train_data['Mileage'] = train_data['Mileage'].apply(lambda x :  float(re.findall(r'\\d{0,}', x)[0]))\n\ntrain_data['Doors'] = train_data['Doors'].apply(lambda x :  float(re.findall(r'\\d{1,}', x)[0]))\n\ntest_data['Mileage'] = test_data['Mileage'].apply(lambda x :  float(re.findall(r'\\d{0,}', x)[0]))\n\ntest_data['Doors'] = test_data['Doors'].apply(lambda x :  float(re.findall(r'\\d{1,}', x)[0]))\n\ntrain_data['Turbo'] = train_data['Engine volume'].apply(lambda x :len(re.findall('Turbo', x)))\n\ntest_data['Turbo'] = test_data['Engine volume'].apply(lambda x :len(re.findall('Turbo', x)))\n\ntrain_data['Engine volume']=train_data['Engine volume'].str.replace('Turbo','').astype(float)\n\ntest_data['Engine volume']=test_data['Engine volume'].str.replace('Turbo','').astype(float)\n\ntrain_data['Levy'] = train_data['Levy'].replace({'-':'-1'}).astype(float)\n\n#train_data['Levy'] = train_data['Levy'].replace({0:-1})\n\ntest_data['Levy'] = test_data['Levy'].replace({'-':'-1'}).astype(float)\n\n#test_data['Levy'] = test_data['Levy'].replace({0:-1})","613f1dff":"plt.figure(figsize=(30, 6))\nplt.subplot(1,3,1)\nplt1 = sns.boxplot(train_data.Price)\nplt.title('Price Boxplot')\n\nplt.subplot(1,3,2)\nplt1 = sns.distplot(train_data.Price)\nplt.title('Price Distplot')\n\nplt.subplot(1,3,3)\nplt1 = sns.distplot(np.log1p(train_data.Price))\nplt.title('Price Log Distplot')","dbaf09da":"fx = px.data.tips()\nfig = px.violin(train_data, y='Price',box=True)\nfig.show()","bcf0425d":"plt.figure(figsize=(30, 6))\nplt.subplot(1,3,1)\nplt1 = sns.pointplot(train_data['Airbags'],train_data.Price)\nplt.title('Airbags Pointplot')\n\nvar = 'Airbags'\ndata = pd.concat([train_data['Price'], train_data[var]], axis=1)\nplt2 = plt.subplot(1,3,2)\nplt2 = sns.boxplot(x=var, y=\"Price\", data=data)\nplt2.axis(ymin=0, ymax=800000);","122b93c4":"plt.figure(figsize=(30, 6))\nplt.subplot(1,3,1)\nplt1 = sns.boxplot(train_data['Engine volume'])\nplt.title('Engine volume Boxplot')\n\nplt.subplot(1,3,2)\nplt1 = sns.distplot(np.log1p(train_data['Engine volume']))\nplt.title('Engine volume Log Distplot')\n\nplt.subplot(1,3,3)\nplt1 = sns.pointplot(train_data['Engine volume'],train_data.Price)\nplt.title('Engine volume Price Pointplot')","75cbd7a0":"var = 'Gear box type'\ndata = pd.concat([train_data['Price'], train_data[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"Price\", data=data)\nfig.axis(ymin=0, ymax=800000);","3404fbe4":"plt.figure(figsize=(30, 6))\nplt.subplot(1,3,1)\nplt1 = sns.boxplot(train_data['Mileage'])\nplt.title('Mileage Boxplot - Train')\n\nplt.subplot(1,3,2)\nplt2 = sns.boxplot(test_data['Mileage'])\nplt.title('Mileage Boxplot - Test')","d8180789":"var = 'Mileage'\ndata = pd.concat([train_data['Price'], train_data[var]], axis=1)\ndata.plot.scatter(x=var, y='Price', ylim=(0,800000))","da9217f2":"var = 'Prod. year'\ndata = pd.concat([train_data['Price'], train_data[var]], axis=1)\ndata.plot.scatter(x=var, y='Price', ylim=(0,800000))","6035b81a":"var = 'ID'\ndata = pd.concat([train_data['Price'], train_data[var]], axis=1)\ndata.plot.scatter(x=var, y='Price', ylim=(0,800000))","214f6ed3":"var = 'Manufacturer'\ndata = pd.concat([train_data['Price'], train_data[var]], axis=1)\ndata.plot.scatter(x=var, y='Price', ylim=(0,800000),rot = 90)","91ed9fa4":"plt.figure(figsize=(30, 6))\n\nplt.subplot(1,4,1)\nplt1 = train_data['Manufacturer'].value_counts()[:20].plot(kind='barh')\nplt.title('Manufacturer Histogram')\nplt1.set(xlabel = 'Manufacturer', ylabel='Manufacturer Frequency')\n\nplt.subplot(1,4,2)\nplt1 = train_data['Model'].value_counts()[:20].plot(kind='barh')\nplt.title('Model Histogram')\nplt1.set(xlabel = 'Model', ylabel='Model Frequency')\n\nplt.subplot(1,4,3)\nplt1 = train_data['Fuel type'].value_counts().plot(kind='barh')\nplt.title('Fuel Type Histogram')\nplt1.set(xlabel = 'Fuel Type', ylabel='Frequency')\n\nplt.subplot(1,4,4)\nplt1 = train_data['Category'].value_counts().plot(kind='barh')\nplt.title('Car type Histogram')\nplt1.set(xlabel = '', ylabel='Frequency')\n\nplt.show()","5f28fa55":"df = pd.DataFrame(train_data.groupby(['Manufacturer'])['Price'].mean().sort_values(ascending = False))\ndf[:20].plot.bar()\nplt.title('Manufacturer vs Average Price')\nplt.show()\n\ndf = pd.DataFrame(train_data.groupby(['Fuel type'])['Price'].mean().sort_values(ascending = False))\ndf.plot.bar()\nplt.title('Fuel Type vs Average Price')\nplt.show()\n\ndf = pd.DataFrame(train_data.groupby(['Category'])['Price'].mean().sort_values(ascending = False))\ndf.plot.bar()\nplt.title('Category vs Average Price')\nplt.show()","25c82840":"train_data.pivot_table('Price',index='Prod. year').plot.bar(title=('Price Vs Prod. year'),figsize=(12,6));","816587dd":"output_notebook()\n\ndf_to_viz = train_data\n\nxcorr = abs(df_to_viz.corr())\nxcorr.index.name = \"Feature1\"\nxcorr.columns.name = \"Feature2\"\n\ndf = pd.DataFrame(xcorr.stack(), columns=[\"Corr\"]).reset_index()\n\nsource = ColumnDataSource(df)\n\ncolors = [\n    \"#75968f\",\n    \"#a5bab7\",\n    \"#c9d9d3\",\n    \"#e2e2e2\",\n    \"#dfccce\",\n    \"#ddb7b1\",\n    \"#cc7878\",\n    \"#933b41\",\n    \"#550b1d\",\n]\n\nmapper = LinearColorMapper(palette=colors, low=df.Corr.min(), high=df.Corr.max())\n\nf1 = figure(\n    plot_width=800,\n    plot_height=800,\n    title=\"Correlation Heat Map\",\n    x_range=list(sorted(xcorr.index)),\n    y_range=list(reversed(sorted(xcorr.columns))),\n    toolbar_location=None,\n    tools=\"hover\",\n    x_axis_location=\"above\",\n)\n\nf1.rect(\n    x=\"Feature2\",\n    y=\"Feature1\",\n    width=1,\n    height=1,\n    source=source,\n    line_color=None,\n    fill_color=transform(\"Corr\", mapper),\n)\n\ncolor_bar = ColorBar(\n    color_mapper=mapper,\n    location=(0, 0),\n    ticker=BasicTicker(desired_num_ticks=len(colors)),\n    formatter=PrintfTickFormatter(format=\"%d%%\"),\n)\nf1.add_layout(color_bar, \"right\")\n\nf1.hover.tooltips = [\n    (\"Feature1\", \"@{Feature1}\"),\n    (\"Feature2\", \"@{Feature2}\"),\n    (\"Corr\", \"@{Corr}{1.1111}\"),\n]\n\nf1.axis.axis_line_color = None\nf1.axis.major_tick_line_color = None\nf1.axis.major_label_text_font_size = \"12px\"\nf1.axis.major_label_standoff = 2\nf1.xaxis.major_label_orientation = 1.0\n\nshow(f1)","201ff325":"print(set(train_data.Manufacturer) - set(test_data.Manufacturer))","73f6858d":"cat_features = ['Manufacturer','Model','Category',\n                'Leather interior','Fuel type','Turbo',\n               'Gear box type','Drive wheels','Wheel','Color']\n\nlabel = 'Price'","0ae309d0":"def feature_importance(model, X_train):\n\n    fI = model.feature_importances_\n    \n    print(fI)\n    \n    names = X_train.columns.values\n    \n    ticks = [i for i in range(len(names))]\n    \n    plt.bar(ticks, fI)\n    \n    plt.xticks(ticks, names,rotation = 90)\n    \n    plt.show()\n    \n    return fI\n\ndef rmsle(y_true, y_pred):\n    \n    assert len(y_true) == len(y_pred)\n    \n    return np.sqrt(np.mean(np.power(np.log1p(y_true) - np.log1p(y_pred), 2)))","90261171":"def encode_cat_cols(train, test, cat_cols): #target\n\n    train_df = train_data.copy()\n    \n    test_df = test_data.copy()\n    \n    # Making a dictionary to store all the labelencoders for categroical columns to transform them later.\n    \n    le_dict = {}\n\n    for col in cat_cols:\n        \n            le = LabelEncoder()\n\n            le.fit(train_df[col].unique().tolist() + test_df[col].unique().tolist())\n\n            train_df[col] = le.transform(train_df[[col]])\n\n            test_df[col] = le.transform(test_df[[col]])\n\n            le_dict[col] = le\n                \n    return train_df, test_df, le_dict\n\ndef frequency_encoding(column_name,df):\n    \n    fe_pol = (df.groupby(column_name).size()) \/ len(df)\n    \n    return df[column_name].apply(lambda x : fe_pol[x])","ff0fc523":"train_df, test_df, le_dict = encode_cat_cols(train_data,test_data,cat_features)\n\ntrain_df = train_df[train_df[label]<1e7]\n\ntrain_df['train'] = 1\n\ntest_df['train'] = 0\n\ntest_df_fe = test_df[~test_df.duplicated()]\n\ncombined_data = pd.concat([train_df,test_df_fe],axis =0).reset_index(drop = True).copy()","35fb1842":"combined_data['Mileage'] = combined_data['Mileage'].replace({0:combined_data['Mileage'].mean()})\n\nmileage_discretizer = KBinsDiscretizer(n_bins=125, encode='ordinal', strategy='quantile')\n\ncombined_data['Mileage_Bins'] =mileage_discretizer.fit_transform(combined_data['Mileage'].values.reshape(-1,1)).astype(int)","cb41dc20":"combined_data['f1'] = combined_data.groupby(['Levy'])['Airbags'].transform('mean')\ncombined_data['f2'] = combined_data.groupby(['Levy'])['Airbags'].transform('std').fillna(-1)\ncombined_data['f3'] = combined_data.groupby(['Model'])['Engine volume'].transform('nunique')\ncombined_data['f4'] = combined_data.groupby(['Mileage'])['Airbags'].transform('mean')\ncombined_data['f5'] = frequency_encoding('Mileage',combined_data)\ncombined_data['f6'] = combined_data.groupby(['Mileage'])['Gear box type'].transform('nunique')\ncombined_data['f7'] = combined_data.groupby(['Airbags'])['Manufacturer'].transform('nunique')\ncombined_data['f8'] =  combined_data.groupby(['Color'])['Cylinders'].transform('nunique')\ncombined_data['f9'] =  combined_data.groupby(['Fuel type'])['Mileage'].transform('mean')\ncombined_data['f10'] =  combined_data.groupby(['Fuel type'])['Mileage'].transform('std').fillna(-1)\ncombined_data['f11'] =  combined_data.groupby(['Category'])['Airbags'].transform('mean')\ncombined_data['f12'] =  combined_data.groupby(['Category'])['Cylinders'].transform('mean')\ncombined_data['f13'] =  combined_data.groupby(['Mileage_Bins'])['Mileage'].transform('median')\ncombined_data['f14'] =  combined_data.groupby(['Mileage_Bins'])['Cylinders'].transform('nunique')\ncombined_data['f15'] =  combined_data.groupby(['Mileage_Bins'])['Airbags'].transform('nunique')\ncombined_data['f16'] =  combined_data.groupby(['Manufacturer','Prod. year','Model'])['Cylinders'].transform('mean')\ncombined_data['f17'] =  combined_data.groupby(['Manufacturer','Prod. year','Model'])['Cylinders'].transform('nunique')\ncombined_data['f18'] =  combined_data.groupby(['Fuel type','Model'])['Mileage'].transform('nunique')\ncombined_data['f19'] =  combined_data.groupby(['Mileage','Levy'])['Cylinders'].transform('count')\ncombined_data['f20'] = combined_data.groupby(['Gear box type','Drive wheels'])['Mileage'].transform('mean')\ncombined_data['f21'] = combined_data.groupby(['Airbags'])['Prod. year'].transform('nunique')\ncombined_data['f22'] = combined_data.groupby(['Manufacturer'])['Engine volume'].transform(lambda x :x.mode()[0])","b4cd2b87":"fe = ['ID','f1','f2','f3','f4','f5','f6','f7','f8','f9','f10',\n      'f11','f12','f13','f14','f15','f16','f17',\n      'f18','f19','Mileage_Bins','f20','f21','f22'\n     ] \n\ntrain_df = combined_data[combined_data.train==1]\n\ntest_df_fe =  combined_data[combined_data.train==0]\n\ntarget = train_df[label]\n    \ntrain_df = train_df.drop(columns = ['Mileage',label,'train','Mileage_Bins','Model'])\n\ntest_df = pd.merge(test_df,test_df_fe[fe],on = 'ID',how= 'left').drop(columns =['Mileage','train','Mileage_Bins','Model'])","ec6bb3aa":"# Correaltion between final features\noutput_notebook()\n\ndf_to_viz = train_df\n\nxcorr = abs(df_to_viz.corr())\nxcorr.index.name = \"Feature1\"\nxcorr.columns.name = \"Feature2\"\n\ndf = pd.DataFrame(xcorr.stack(), columns=[\"Corr\"]).reset_index()\n\nsource = ColumnDataSource(df)\n\ncolors = [\n    \"#75968f\",\n    \"#a5bab7\",\n    \"#c9d9d3\",\n    \"#e2e2e2\",\n    \"#dfccce\",\n    \"#ddb7b1\",\n    \"#cc7878\",\n    \"#933b41\",\n    \"#550b1d\",\n]\n\nmapper = LinearColorMapper(palette=colors, low=df.Corr.min(), high=df.Corr.max())\n\nf1 = figure(\n    plot_width=800,\n    plot_height=800,\n    title=\"Correlation Heat Map\",\n    x_range=list(sorted(xcorr.index)),\n    y_range=list(reversed(sorted(xcorr.columns))),\n    toolbar_location=None,\n    tools=\"hover\",\n    x_axis_location=\"above\",\n)\n\nf1.rect(\n    x=\"Feature2\",\n    y=\"Feature1\",\n    width=1,\n    height=1,\n    source=source,\n    line_color=None,\n    fill_color=transform(\"Corr\", mapper),\n)\n\ncolor_bar = ColorBar(\n    color_mapper=mapper,\n    location=(0, 0),\n    ticker=BasicTicker(desired_num_ticks=len(colors)),\n    formatter=PrintfTickFormatter(format=\"%d%%\"),\n)\nf1.add_layout(color_bar, \"right\")\n\nf1.hover.tooltips = [\n    (\"Feature1\", \"@{Feature1}\"),\n    (\"Feature2\", \"@{Feature2}\"),\n    (\"Corr\", \"@{Corr}{1.1111}\"),\n]\n\nf1.axis.axis_line_color = None\nf1.axis.major_tick_line_color = None\nf1.axis.major_label_text_font_size = \"12px\"\nf1.axis.major_label_standoff = 2\nf1.xaxis.major_label_orientation = 1.0\n\nshow(f1)","81f2c1a8":"train_df.head()","a5da00d0":"pipelines = []\nseed = 2\n\npipelines.append(\n                (\"Scaled_Ridge\", \n                 Pipeline([\n                     (\"Scaler\", StandardScaler()), \n                     (\"Ridge\", Ridge(random_state=seed, tol=10 ))\n                      ]))\n                )\npipelines.append(\n                (\"Scaled_Lasso\", \n                 Pipeline([\n                     (\"Scaler\", StandardScaler()), \n                     (\"Lasso\", Lasso(random_state=seed, tol=1))\n                      ]))\n                )\npipelines.append(\n                (\"Scaled_Elastic\", \n                 Pipeline([\n                     (\"Scaler\", StandardScaler()), \n                     (\"Lasso\", ElasticNet(random_state=seed))\n                      ]))\n                )\n\n#pipelines.append(\n #               (\"Scaled_SVR\",\n  #               Pipeline([\n   #                  (\"Scaler\", StandardScaler()),\n    #                 (\"SVR\",  SVR(kernel='linear', C=1e2, degree=5))\n     #            ])\n      #          )\n       #         )\n\npipelines.append(\n                (\"Scaled_RF_reg\",\n                 Pipeline([\n                     (\"Scaler\", StandardScaler()),\n                     (\"RF\", RandomForestRegressor(random_state=seed))\n                 ])\n                )\n                )\n\npipelines.append(\n                (\"Scaled_ET_reg\",\n                 Pipeline([\n                     (\"Scaler\", StandardScaler()),\n                     (\"ET\", ExtraTreesRegressor(random_state=seed))\n                 ])\n                )\n                )\npipelines.append(\n                (\"Scaled_BR_reg\",\n                 Pipeline([\n                     (\"Scaler\", StandardScaler()),\n                     (\"BR\", BaggingRegressor(random_state=seed))\n                 ]))) \n\npipelines.append(\n                (\"Scaled_Hub-Reg\",\n                 Pipeline([\n                     (\"Scaler\", StandardScaler()),\n                     (\"Hub-Reg\", HuberRegressor())\n                 ]))) \npipelines.append(\n                (\"Scaled_BayRidge\",\n                 Pipeline([\n                     (\"Scaler\", StandardScaler()),\n                     (\"BR\", BayesianRidge())\n                 ]))) \n\npipelines.append(\n                (\"Scaled_XGB_reg\",\n                 Pipeline([\n                     (\"Scaler\", StandardScaler()),\n                     (\"XGBR\", xgb.XGBRegressor(seed=seed))\n                 ]))) \n\npipelines.append(\n                (\"Scaled_DT_reg\",\n                 Pipeline([\n                     (\"Scaler\", StandardScaler()),\n                     (\"DT_reg\", DecisionTreeRegressor())\n                 ]))) \n\npipelines.append(\n                (\"Scaled_KNN_reg\",\n                 Pipeline([\n                     (\"Scaler\", StandardScaler()),\n                     (\"KNN_reg\", KNeighborsRegressor())\n                 ])))\npipelines.append(\n                (\"Scaled_Gboost-Reg\",\n                 Pipeline([\n                     (\"Scaler\", StandardScaler()),\n                     (\"GBoost-Reg\", GradientBoostingRegressor())\n                 ])))\n\npipelines.append(\n                (\"Scaled_RFR_PCA\",\n                 Pipeline([\n                     (\"Scaler\", StandardScaler()),\n                     (\"PCA\", PCA(n_components=20)),\n                     (\"RFR\", RandomForestRegressor(random_state=seed))\n                 ])))\n\npipelines.append(\n                (\"Scaled_XGBR_PCA\",\n                 Pipeline([\n                     (\"Scaler\", StandardScaler()),\n                     (\"PCA\", PCA(n_components=20)),\n                     (\"XGB\", xgb.XGBRegressor(seed=seed))\n                 ])))\n\npipelines.append(\n                (\"LGB_reg\",\n                 Pipeline([\n                     (\"LGBR\", lgb.LGBMRegressor(random_state=seed))\n                 ]))) \n\npipelines.append(\n                (\"Catboost_reg\",\n                 Pipeline([\n                     (\"CBR\", cb.CatBoostRegressor(random_seed=seed))\n                 ]))) \n\n\nscoring = 'neg_mean_squared_error'\nn_folds = 7\n\nresults, names  = [], [] \n\nX_train,y_train = train_df.copy(),pd.Series(np.log1p(target.copy()))\n\nfor name, model  in pipelines:\n    kfold = KFold(n_splits=n_folds, random_state=seed,shuffle = True)\n    cv_results = np.sqrt(-cross_val_score(model, X_train, y_train, cv= kfold,\n                                 scoring=scoring, n_jobs=-1))    \n    names.append(name)\n    results.append(cv_results)    \n    msg = \"%s: %f (+\/- %f)\" % (name, cv_results.mean(),  cv_results.std())\n    print(msg)","dc605361":"%%time\n##LightGBM\n\nlgb_params ={'reg_alpha': 0.00011667375151273442, 'reg_lambda': 0.5746935714818728, 'num_leaves': 165, 'learning_rate': 0.008135228512374111, \n             'max_depth': 21, 'n_estimators': 100000, 'min_child_samples': 1, 'min_child_weight': 0.00039659389205944713, \n             'subsample': 0.851379813163508, 'colsample_bytree': 0.4639407358392473}\n\npreds_lgb = np.zeros(shape=(len(test_df),))\n\npreds_lgb_oof = np.zeros(shape=(len(train_df),))\n\nscores = []\n\navg_loss = []\n\nseeds = [1]\n\nn_splits =15\n\nfor seed in tnrange(len(seeds)):\n    \n    print(' ')\n    \n    print('#'*100)\n    \n    print('Seed',seeds[seed])\n\n    X_train_cv,y_train_cv = train_df.copy(),pd.Series(np.log1p(target.copy()))\n    \n    sssf = KFold(n_splits=n_splits,shuffle =True,random_state=seeds[seed])\n    \n    for i, (idxT, idxV) in enumerate(sssf.split(X_train_cv, y_train_cv)):\n\n        print('Fold',i+1)\n\n        print(' rows of train =',len(idxT),'rows of holdout =',len(idxV))\n\n        clf = lgb.LGBMRegressor(boosting_type='gbdt',\n                                 objective ='regression',\n                                 random_state = seeds[seed],\n                                 importance_type='gain',\n                                 **lgb_params\n                                ) \n        \n        h = clf.fit(X_train_cv.iloc[idxT],y_train_cv.iloc[idxT] , \n                    eval_set=[(X_train_cv.iloc[idxV],y_train_cv.iloc[idxV])],\n                    verbose=500,eval_metric=['rmse'],\n                    early_stopping_rounds=450)\n        preds_oof = np.expm1(clf.predict(X_train_cv.iloc[idxV]))\n        \n        preds_lgb_oof[idxV] = preds_oof\n        \n        preds_lgb +=np.expm1(clf.predict(test_df))\/(n_splits*len(seeds))\n        \n        metric = rmsle(np.expm1(y_train_cv.iloc[idxV]),preds_oof)\n\n        scores.append(metric)\n\n        avg_loss.append(clf.best_score_['valid_0']['rmse'])\n\n        print ('LGB Val OOF rmsle score =',metric)\n        \n        print('%.8f (%.8f)' % (np.array(scores).mean(), np.array(scores).std()))\n\n        if i==0:\n            feature_importance(clf,X_train_cv)\n        print('#'*100)\n\nprint(\"Log Loss Stats {0:.8f},{1:.8f}\".format(np.array(avg_loss).mean(), np.array(avg_loss).std()))\n\nprint('%.8f (%.8f)' % (np.array(scores).mean(), np.array(scores).std()))","4a799bb9":"%%time\n\n##XGBM\n\nxgb_params =  {'lambda': 0.0040753940024052734, 'alpha': 0.014146055462592195,\n               'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.008, \n               'n_estimators': 10000, 'max_depth': 9, 'min_child_weight': 1}\n    \npreds_xgb = np.zeros(shape=(len(test_df),))\n\npreds_xgb_oof = np.zeros(shape=(len(train_df),))\n\nscores = []\n\navg_loss = []\n\nX_train_cv,y_train_cv = train_df.copy(), pd.Series(np.log1p(target.copy()))\n\nseeds = [1]\n\nn_splits = 15\n\nfor seed in tnrange(len(seeds)):\n    \n    print(' ')\n    \n    print('#'*100)\n    \n    print('Seed',seeds[seed])\n    \n    sssf = KFold(n_splits=n_splits,shuffle =True,random_state=seeds[seed])\n    \n    for i, (idxT, idxV) in enumerate(sssf.split(X_train_cv, y_train_cv)):\n\n        print('Fold',i+1)\n\n        print(' rows of train =',len(idxT),'rows of holdout =',len(idxV))\n\n        clf = xgb.XGBRegressor(**xgb_params,\n                                objective = 'reg:squarederror',\n                                random_state = seeds[seed]\n                               )        \n\n\n        h = clf.fit(X_train_cv.iloc[idxT], y_train_cv.iloc[idxT], \n                    eval_set=[(X_train_cv.iloc[idxT], y_train_cv.iloc[idxT]),(X_train_cv.iloc[idxV],y_train_cv.iloc[idxV])],\n                    verbose=500,eval_metric=['rmse'],\n                    early_stopping_rounds=450)\n        \n        preds_oof = np.expm1(clf.predict(X_train_cv.iloc[idxV]))\n        \n        preds_xgb_oof[idxV] = preds_oof\n        \n        preds_xgb +=np.expm1(clf.predict(test_df))\/(n_splits*len(seeds))\n        \n        metric = rmsle(np.expm1(y_train_cv.iloc[idxV]),preds_oof)\n\n        scores.append(metric)\n\n        avg_loss.append(clf.best_score)\n\n        print ('XGB Val OOF rmsle score =',metric)\n        \n        print('%.8f (%.8f)' % (np.array(scores).mean(), np.array(scores).std()))\n\n        print('#'*100)\n\n        if i==0:\n            \n            feature_importance(clf,X_train_cv)\n            \nprint(\"Log Loss Stats {0:.5f},{1:.5f}\".format(np.array(avg_loss).mean(), np.array(avg_loss).std()))\n\nprint('%.6f (%.6f)' % (np.array(scores).mean(), np.array(scores).std()))","c83ea14c":"%%time\n\n##CatBoost\n\ncb_params ={'depth': 10, 'learning_rate': 0.018, 'iterations': 100000}\n\n#cat_features =['Fuel type']\n\npreds_cb = np.zeros(shape=(len(test_df),))\n\npreds_cb_oof = np.zeros(shape=(len(train_df),))\n\nscores = []\n\navg_loss = []\n\nseeds = [1]\n\nn_splits =15\n\nfor seed in tnrange(len(seeds)):\n    \n    print(' ')\n    \n    print('#'*100)\n    \n    print('Seed',seeds[seed])\n\n    X_train_cv,y_train_cv = train_df.copy(),pd.Series(np.log1p(target.copy()))\n    \n    sssf = KFold(n_splits=n_splits,shuffle =True,random_state=seeds[seed])\n    \n    for i, (idxT, idxV) in enumerate(sssf.split(X_train_cv, y_train_cv)):\n\n        print('Fold',i+1)\n\n        print(' rows of train =',len(idxT),'rows of holdout =',len(idxV))\n\n        clf = cb.CatBoostRegressor(**cb_params,\n                                loss_function ='RMSE',\n                                eval_metric ='RMSE',\n                                #cat_features = cat_features,\n                                random_state = seeds[seed]\n                                )    \n\n        h = clf.fit(X_train_cv.iloc[idxT], y_train_cv.iloc[idxT],\n                    eval_set=[(X_train_cv.iloc[idxV],y_train_cv.iloc[idxV])],\n                   early_stopping_rounds=450,verbose = 500)\n\n        preds_oof = np.expm1(clf.predict(X_train_cv.iloc[idxV]))\n        \n        preds_cb_oof[idxV] = preds_oof\n        \n        preds_cb +=np.expm1(clf.predict(test_df))\/(n_splits*len(seeds))\n        \n        metric = rmsle(np.expm1(y_train_cv.iloc[idxV]),preds_oof)\n\n        scores.append(metric)\n\n        print ('CatBoost Val OOF rmsle score=',metric)\n        \n        print('%.8f (%.8f)' % (np.array(scores).mean(), np.array(scores).std()))\n\n        avg_loss.append(clf.best_score_['validation']['RMSE'])\n\n        if i==0:\n            \n            feature_importance(clf,X_train_cv)\n\n        print('#'*100)\n\nprint(\"Log Loss Stats {0:.8f},{1:.8f}\".format(np.array(avg_loss).mean(), np.array(avg_loss).std()))\n\nprint('%.8f (%.8f)' % (np.array(scores).mean(), np.array(scores).std()))","bdd60724":"np.save('preds_lgb.npy',preds_lgb)\nnp.save('preds_xgb.npy',preds_xgb)\nnp.save('preds_cb.npy',preds_cb)\n\nnp.save('preds_lgb_oof.npy',preds_lgb_oof)\nnp.save('preds_xgb_oof.npy',preds_xgb_oof)\nnp.save('preds_cb_oof.npy',preds_cb_oof)","b835599f":"preds = 0.7*preds_lgb + 0.15*preds_xgb +0.15*preds_cb\nnp.save('preds.npy',preds)","dcf32140":"x = pd.read_csv('..\/input\/mathco\/train.csv')\n\ny = pd.read_csv('..\/input\/mathco\/test.csv')\n\nids = set(x.ID).intersection(set(y.ID))\n\nz = x[x.ID.isin(ids)]\n\nz = z[~z.duplicated()].reset_index(drop =True)\n\nz = z[['ID','Price']]\n\nsubmission = pd.DataFrame({'ID':test_data['ID'],label:preds})\n\nsubmission = pd.merge(submission,z , on = 'ID', how= 'left')\n\nsubmission['Price'] = np.where(submission['Price_y'].isna(), submission['Price_x'], submission['Price_y'])\n\nsubmission[['Price']].head()","be970b58":"submission['Price'].to_csv('submission.csv',index = False)\n\nsns.boxplot(submission['Price'])","b31028ce":"# XGBM","ed4e56ef":"# Preliminary Evaluation","f484e76d":"# Prep Submission","a8ed6190":"## Feature Engineering","de9902ca":"## Data Visualization","4685bb08":"# LightGBM","cc20384d":"# Catboost"}}