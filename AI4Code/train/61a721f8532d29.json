{"cell_type":{"cda3ead1":"code","8cd3c964":"code","96c29626":"code","538f4ac4":"code","6214abd3":"code","0eb946f9":"code","b49c68f9":"code","c54e64c5":"code","1541cb91":"code","446139d0":"code","985d505b":"code","d20eb5bf":"code","e56047b0":"code","848894a1":"code","71a18166":"code","e03a78c7":"code","1f92149f":"code","da8a6adb":"code","693a7797":"code","785a29f1":"code","868c9826":"code","df5fba71":"code","8bc0f411":"code","0f31aca3":"code","ae26a48c":"code","e09aefc9":"code","508bfa84":"code","561006b2":"code","cb9e3238":"code","1b2aad9d":"markdown","6d24a876":"markdown","c8546713":"markdown","7e5e69c8":"markdown","6a36e79f":"markdown","53e38a5b":"markdown"},"source":{"cda3ead1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8cd3c964":"data = pd.read_csv('\/kaggle\/input\/entity-annotated-corpus\/ner_dataset.csv', encoding = 'latin1')","96c29626":"data = data.fillna(method = 'ffill')\ndata.head()","538f4ac4":"print(\"no of unique words in datasers: \", data['Word'].nunique())","6214abd3":"print(\"no of unique tags in datasets, \", data['Tag'].nunique())","0eb946f9":"words = list(set(data['Word'].values))","b49c68f9":"words.append('ENDPAD')\nnum_words = len(words)","c54e64c5":"tags = list(set(data['Tag'].values))\nnum_tags = len(tags)","1541cb91":"num_tags","446139d0":"class SentenceGetter(object):\n    def __init__(self, data):\n        self.n_sent = 1\n        self.data = data\n        agg_func = lambda s: [(w,p,t) for w,p,t in zip(s['Word'].values.tolist(),\n                                                      s['POS'].values.tolist(), \n                                                      s['Tag'].values.tolist())]\n        self.grouped = self.data.groupby('Sentence #').apply(agg_func)\n        self.sentences = [s for s in self.grouped]","985d505b":"getter = SentenceGetter(data)\nsentences = getter.sentences","d20eb5bf":"sentences[1]","e56047b0":"word2idx = {w : i+1 for i,w in enumerate(words)}","848894a1":"word2idx","71a18166":"tag2idx = {t : i for i,t in enumerate(tags)}","e03a78c7":"tag2idx","1f92149f":"import matplotlib.pyplot as plt\nplt.hist([len(s) for s in sentences], bins = 50)\nplt.show()","da8a6adb":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.utils import to_categorical\n\nmax_len = 50 \n\nx = [[word2idx[w[0]] for w in s] for s in sentences]\nx = pad_sequences(x, maxlen = max_len, padding = 'post', value = num_words-1)","693a7797":"y = [[tag2idx[w[2]] for w in s] for s in sentences]\ny = pad_sequences(y, maxlen = max_len, padding = 'post', value = tag2idx[\"O\"])\ny = [to_categorical(i, num_classes = num_tags) for i in y]","785a29f1":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(x,y, test_size = 0.1, random_state = 1)","868c9826":"from tensorflow.keras import Model,Input\nfrom tensorflow.keras.layers import LSTM, Dense, Embedding\nfrom tensorflow.keras.layers import TimeDistributed, SpatialDropout1D, Bidirectional","df5fba71":"input_word = Input(shape=(max_len, ))\nmodel = Embedding(input_dim = num_words, output_dim = max_len, input_length = max_len)(input_word)\nmodel = SpatialDropout1D(0.1)(model)\nmodel = Bidirectional(LSTM(units = 100, return_sequences =True, recurrent_dropout = 0.1))(model)\nout = TimeDistributed(Dense(num_tags, activation = 'softmax'))(model)\nmodel = Model(input_word, out)\nmodel.summary()","8bc0f411":"model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])","0f31aca3":"!pip install git+git:\/\/github.com\/stared\/livelossplot.git","ae26a48c":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping","e09aefc9":"early_stopping = EarlyStopping(monitor = 'val_accuracy', patience = 1, verbose = 0, mode = 'max', restore_best_weights = False )\nhistory = model.fit(X_train, np.array(y_train),\n          epochs=3,\n          validation_split = 0.2,\n          batch_size = 32,  \n          verbose=1)","508bfa84":"model.evaluate(X_test,np.array(y_test))","561006b2":"i = np.random.randint(0, X_test.shape[0])\np = model.predict(np.array([X_test[i]]))\np = np.argmax(p,axis = -1)","cb9e3238":"y_true = np.argmax(np.array(y_test), axis = -1)[i]\nprint(\"{:15}{:5}\\t {}\\n\".format(\"Word\",\"True\",\"Y_predict\"))\nprint(\"*\"*40)\nfor w,true,pred in zip(X_test[i],y_true,p[0]):\n    print(\"{:15}{}\\t{}\".format(words[w-1], tags[true], tags[pred] ))","1b2aad9d":"# build and compile bidirectional model","6d24a876":"# Padding input sentence and train test split","c8546713":"# train the model","7e5e69c8":"find no of unique words from datasets","6a36e79f":"# Mapping between sentence and tag","53e38a5b":"# Retrive the sentences and Corrosponding tags"}}