{"cell_type":{"442b2c79":"code","e5067505":"code","18902236":"code","b20d1981":"code","aa2e7b6d":"code","d2b59ad0":"code","30393413":"code","bfa7ce06":"code","09b7f90f":"code","3f343ee6":"code","1dde382f":"code","3f5f6401":"code","c3654c74":"code","3cd786e8":"code","bfa50561":"code","2de3a21e":"code","762e15cf":"code","79ca04a8":"code","0581fbb5":"code","8c0b092a":"code","76a2c296":"code","8c7beaa0":"code","4de6d2f5":"code","bc737b5a":"code","3f75869c":"code","35dc26e8":"code","1d17809e":"code","18702a87":"code","563cdb89":"code","cf569bfb":"code","9afafd01":"code","b691afaf":"code","1712b07d":"code","2d6db144":"code","619a4ff3":"markdown","cb3359c2":"markdown","8c0e68a1":"markdown","f98a20f6":"markdown","672b8d29":"markdown","f90b5fea":"markdown","63ec0489":"markdown","10e95fa0":"markdown","a95422ab":"markdown","c7e43e8a":"markdown","07dc9add":"markdown"},"source":{"442b2c79":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nimport plotly as py\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    \n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e5067505":"df = pd.read_csv(\"..\/input\/undata-country-profiles\/country_profile_variables.csv\")\ndf.info()","18902236":"\ndf.head()","b20d1981":"df = df[df['GDP: Gross domestic product (million current US$)'] > 0.0] \n\nx = df.groupby('Region')['GDP: Gross domestic product (million current US$)'].sum()\nprint(x)","aa2e7b6d":"fig = plt.figure()\nRegions = []\nfor i in df['Region'].unique():\n    Regions.append(i)\nax = fig.add_axes([0,0,2,2])\nplt.ylabel(\"Regions\")\nplt.xlabel(\"GDP based on current prices\")\nax.barh(sorted(Regions),x , color ='orange', edgecolor = 'black')","d2b59ad0":"dict = {'Regions' : df['Region'] , 'GDP' :df['GDP: Gross domestic product (million current US$)'] , 'country': df['country']}\ndf1 = pd.DataFrame(data = dict)\ndf1.head()","30393413":"contrib = df1.groupby('Regions')['GDP'].sum().round().reset_index()\ncontrib[\"Percentage\"] = (contrib.GDP\/sum(contrib.GDP))*100\ncontrib = contrib.drop(columns = [\"GDP\"])\ncontrib\ncontrib.plot(kind = \"pie\",y=\"Percentage\",labels=contrib['Regions'],legend=False,figsize=(10,50),autopct=\"%.2f%%\" )\n","bfa7ce06":"#cleaning.\ndf = df.replace(['-~0.0'],'0.0')\ndf = df.replace(['~0.0'],'0.0')\n\ndf['GDP growth rate (annual %, const. 2005 prices)'] = df['GDP growth rate (annual %, const. 2005 prices)'].astype(float)\ndf['Economy: Agriculture (% of GVA)'] = df['Economy: Agriculture (% of GVA)'].astype(float)","09b7f90f":"plt.figure(figsize=(16, 6))\nheatmap = sns.heatmap(df.corr(), vmin=-1, vmax=1, annot=True)\nheatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);\nsns.heatmap(df.corr())","3f343ee6":"# normalizing both the variables\ngdp_mean = df['GDP: Gross domestic product (million current US$)'].mean()\ngdp_growth_rate_mean = df['GDP growth rate (annual %, const. 2005 prices)'].mean()\n\ngdp_std = df['GDP: Gross domestic product (million current US$)'].std()\ngdp_growth_rate_std = df['GDP growth rate (annual %, const. 2005 prices)'].std()\n\n\ndf['GDP: Gross domestic product (million current US$)'] = df['GDP: Gross domestic product (million current US$)'].map(lambda p: (p - gdp_mean)\/(gdp_std))\ndf['GDP growth rate (annual %, const. 2005 prices)'] = df['GDP growth rate (annual %, const. 2005 prices)'].map(lambda p: (p - gdp_growth_rate_mean)\/(gdp_growth_rate_std))","1dde382f":"plt.figure(figsize=(10,5))\nplt.scatter(x = df['GDP: Gross domestic product (million current US$)'] ,y = df['GDP growth rate (annual %, const. 2005 prices)'])\nplt.xlabel('GDP')\nplt.ylabel('GDP growth rate')\n","3f5f6401":"# data preparation \ndf['Economy: Agriculture (% of GVA)'] = df['Economy: Agriculture (% of GVA)'].astype(float)\n","c3654c74":"# dropping the columns with negative percentage contribution.\n\ndf = df[df['Economy: Agriculture (% of GVA)'] > 0.0] \ndf = df[df['Economy: Services and other activity (% of GVA)'] > 0.0]\ndf = df[df['Economy: Industry (% of GVA)'] > 0.0]","3cd786e8":"agri = df.groupby('Region')['Economy: Agriculture (% of GVA)'].mean()\nindustry = df.groupby('Region')['Economy: Industry (% of GVA)'].mean()\ntertiary = df.groupby('Region')['Economy: Services and other activity (% of GVA)'].mean()\n","bfa50561":"fig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nax.barh(Regions,agri , color ='green', edgecolor = 'black')\nplt.xlabel(\"% GVA in agriculture\")\nplt.ylabel(\"Regions\")\nplt.title(\"Agriculture Sector contribution in GVA\")","2de3a21e":"fig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nax.barh(Regions,industry, color ='orange', edgecolor = 'black')\nplt.xlabel(\"% GVA in industry\")\nplt.ylabel(\"Regions\")\nplt.title(\"Industry Sector contribution in GVA\")","762e15cf":"fig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nax.barh(Regions,tertiary , color ='blue', edgecolor = 'black')\nplt.xlabel(\"% GVA in Tertiary\")\nplt.ylabel(\"Regions\")\nplt.title(\"Tertiary Sector contribution in GVA\")","79ca04a8":"# converting objects to floats\n\ndf = df.replace(['...'],'0.0')\ndf['Employment: Agriculture (% of employed)'] = df['Employment: Agriculture (% of employed)'].astype(float)\ndf['Employment: Industry (% of employed)'] = df['Employment: Industry (% of employed)'].astype(float)\ndf['Employment: Services (% of employed)'] = df['Employment: Services (% of employed)'].astype(float)\ndf['Education: Government expenditure (% of GDP)'] = df['Education: Government expenditure (% of GDP)'].astype(float)","0581fbb5":"# including only the numerical variables and creating a new dataframe...\n\ndf1 = df.select_dtypes(include=np.number)\ndf1.info()        ","8c0b092a":"# normalization of values in the new dataframe\ntry:\n    for i in df1.columns:\n        df1.loc[:,i] = (df1[i] - df1[i].mean())\/(df1[i].std())\nexcept:\n    for i in df1.columns:\n        print('some error')\n\n\ndf1.head()","76a2c296":"#let's make boxplots to get an idea about the outliers as the clustering algorithm gets impacted by the outliers in the data..\nplt.figure(figsize=(15, 15))\nsns.boxplot(x=\"value\", y=\"variable\", data=pd.melt(df1), orient = 'h')\n\nplt.show()\n","8c7beaa0":"# removing outliers for cluster analysis...\n\n\nfor i in df1.columns:\n    sorted(df1[i])\n    \ndf1.head()    \n\nQ1=df1.quantile(0.25)\nQ3=df1.quantile(0.75)\nIQR=Q3-Q1\ncleared_df1 = df1[~((df1 < (Q1 - 1.5 * IQR)) |(df1 > (Q3 + 1.5 * IQR))).any(axis=1)]\ncleared_df1 = cleared_df1.drop(columns = ['Net Official Development Assist. received (% of GNI)'])\ncleared_df1.info()","4de6d2f5":"scaled_features = []\n\nfor i in cleared_df1.columns:\n    scaled_features.append(cleared_df1[i])\n#print(scaled_features)","bc737b5a":"kmeans_kwargs = {\n                \"init\": \"random\",\n                \"n_init\": 10,\n                \"max_iter\": 300,\n                \"random_state\": 42,\n                }\n\nsse = []\n\nfor k in range(1,11):\n    kmeans = KMeans(n_clusters = k, **kmeans_kwargs)\n    kmeans.fit(scaled_features)\n    sse.append(kmeans.inertia_)\n","3f75869c":"plt.style.use(\"fivethirtyeight\")\nplt.plot(range(1,11), sse)\nplt.xticks(range(1,11))\nplt.xlabel(\"Number of Clusters\")\nplt.ylabel(\"SSE\")\nplt.show()","35dc26e8":"kmeans = KMeans(init = \"random\" , n_clusters = 4 , n_init = 10, max_iter = 300 , random_state = 42)\nkmeans.fit(scaled_features)\ny_kmeans = kmeans.predict(scaled_features)\n","1d17809e":"# lowest SSE value..\nkmeans.inertia_","18702a87":"kmeans.cluster_centers_","563cdb89":"kmeans.n_iter_","cf569bfb":"kmeans.labels_[:5]\nlabels = kmeans.labels_","9afafd01":"sample_data = pd.DataFrame(scaled_features)\ncovar_matrix = np.matmul(sample_data.T, sample_data)\nprint(covar_matrix.shape)","b691afaf":"from scipy.linalg import eigh\nvalues, vectors = eigh(covar_matrix, eigvals = (72,73))\nvectors = vectors.T","1712b07d":"new_coordinates = np.matmul(vectors, sample_data.T)\nnew_coordinates = np.vstack((new_coordinates, labels)).T\ndataframe = pd.DataFrame(data = new_coordinates, columns = (\"1st_principal\" ,\"2nd_principal\" , \"labels\"))\nprint(dataframe.head())","2d6db144":"sns.FacetGrid(dataframe, hue = 'labels' , height = 7).map(plt.scatter, \"1st_principal\" , \"2nd_principal\").add_legend()","619a4ff3":"# *Let's group columns based on type being numerical or categorical and also convert some categorical variables to numerical if they make sense as numerical variables. The reason for the same is that we want to implement a clustering algorithm on the data which takes only numerical inputs. *","cb3359c2":"# Based on the results from the correlation heat map shows the correlation between the GDP growth rate and the Per Capita GDP isn't strong (0.19 precisely).Similarly the scatter plot also doesn't seem to tell an interesting story.","8c0e68a1":"# Lets try and explore if there is any pattern between GDP per capita and the growth rate of GDP.","f98a20f6":"# Now for visualization of the clusters based on 21 dimensions is not feasible, so we use the dimensionality reduction technique of Principal Component Analysis to facilitate the same...","672b8d29":"# # # Based on the plot, the optimum number of clusters are 4.","f90b5fea":"#  **Let's make a correlation heat map to see how are the variables we have correlated to each other**","63ec0489":"# So, the above scatter plot is the 2-D plot based on the Principal Component analysis.","10e95fa0":"# **The Pie Chart represents the percentage of GDP per region.**","a95422ab":"# > **Important note : The x-axis in the figure above does not represent exact values and should be interpreted only for relative comparison..**","c7e43e8a":"# **Let's now analyze which sector is more dominant in the economic output based on the region**","07dc9add":"# **Limitation : One of the important thing to note is that the above heatmap does not include the variables of the type object into consideration.**\n"}}