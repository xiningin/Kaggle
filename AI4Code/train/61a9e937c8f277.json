{"cell_type":{"c76a702d":"code","22c90976":"code","2f7e70b1":"code","a12b82a7":"code","46152c58":"code","6a8a6255":"code","648f8253":"code","a40d2f6f":"code","7baf5ef6":"code","a4d0c0c8":"code","fd481907":"code","b0d1293d":"code","6db4d5fb":"code","3228858e":"code","5e671466":"code","f51254fc":"code","ab81df58":"code","3f2d929d":"code","b866e372":"code","45cc2cb9":"code","8f32ad41":"code","d0b24f2b":"code","0111e98a":"code","639021df":"code","c8707fc0":"code","3f983e21":"code","aa83c890":"code","b2ac9bf3":"code","0284f76d":"code","cb38ac0f":"code","0b9f0c5b":"code","addecdf6":"code","30bc4c3c":"code","93171be1":"code","1c1ea565":"code","ec9714fe":"code","13eb07d5":"code","ca9b40d5":"code","8cffaf61":"code","f09b39c4":"code","4d75e1a1":"code","899af46b":"code","8b128e63":"code","98bf1015":"code","f0ed5bc4":"code","46459766":"code","f94e95b2":"code","d542efb5":"code","5f677456":"code","c6b24fa9":"code","753f0c27":"code","ed964b3d":"code","ab573315":"code","4df3c694":"markdown","c015659b":"markdown","e42bbe83":"markdown","307a01d1":"markdown","c1794559":"markdown","73c1325e":"markdown","04face53":"markdown","112b49e9":"markdown","7da656ac":"markdown","3c5f9fe3":"markdown","0ed8990b":"markdown","1d42438e":"markdown","61fe507f":"markdown","e38c4de3":"markdown","8d5edee9":"markdown","a2bb3839":"markdown","77b1b937":"markdown","ec1acf02":"markdown","d6448532":"markdown","8cbd8432":"markdown","a6bb565c":"markdown","a70f8ccf":"markdown","ba2f5f12":"markdown","456f14a7":"markdown","72fdeab2":"markdown","0224d067":"markdown","ca3f9eaf":"markdown","2824ccd6":"markdown","8484c6a5":"markdown"},"source":{"c76a702d":"!pip install fastai2 -q","22c90976":"%load_ext autoreload\n%autoreload 2\n\nimport os\nimport pandas as pd\nimport numpy as np\n\nfrom fastai2.basics import *\nfrom fastai2.callback.all import *\nfrom fastai2.vision.all import *\nfrom fastai2.vision.widgets import *\nfrom fastai2.vision import *\nfrom fastai2.callback.cutmix import *","2f7e70b1":"DATA_DIR = '..\/input\/jovian-pytorch-z2g\/Human protein atlas'\n\nTRAIN_DIR = DATA_DIR + '\/train'                           \nTEST_DIR = DATA_DIR + '\/test'                             \n\nTRAIN_CSV = DATA_DIR + '\/train.csv'                       \nTEST_CSV = '..\/input\/jovian-pytorch-z2g\/submission.csv' ","a12b82a7":"train_df = pd.read_csv(TRAIN_CSV)\ntrain_df['imgPath'] = train_df.apply(lambda x : os.path.join(TRAIN_DIR,str(x['Image'])+'.png'),axis=1)\ntrain_df.head()","46152c58":"split_df = pd.get_dummies(train_df.Label.str.split(\" \").explode())\nsplit_df = split_df.groupby(split_df.index).sum()\nsplit_df.head()","6a8a6255":"X, y = split_df.index.values, split_df.values","648f8253":"from skmultilearn.model_selection import IterativeStratification\n\nnfolds = 5\n\nk_fold = IterativeStratification(n_splits=nfolds, order=1)\n\nsplits = list(k_fold.split(X, y))\n\nfold_splits = np.zeros(train_df.shape[0]).astype(np.int)\n\nfor i in range(nfolds):\n    fold_splits[splits[i][1]] = i","a40d2f6f":"train_df['Split'] = fold_splits","7baf5ef6":"def get_fold(fold):\n    train_df['is_valid'] = False\n    train_df.loc[train_df.Split == fold, 'is_valid'] = True\n    return train_df","a4d0c0c8":"train_df.head()","fd481907":"train_df = get_fold(0)\ntrain_df = train_df.drop(['Split'],axis=1)\ntrain_df.head()","b0d1293d":"test_df = pd.read_csv(TEST_CSV)\ntest_df['imgPath'] = test_df.apply(lambda x : os.path.join(TEST_DIR,str(x['Image'])+'.png'),axis=1)\ntest_df.head()","6db4d5fb":"labels = {\n    0: 'Mitochondria',\n    1: 'Nuclear bodies',\n    2: 'Nucleoli',\n    3: 'Golgi apparatus',\n    4: 'Nucleoplasm',\n    5: 'Nucleoli fibrillar center',\n    6: 'Cytosol',\n    7: 'Plasma membrane',\n    8: 'Centrosome',\n    9: 'Nuclear speckles'\n}","3228858e":"def encode_label(label):\n    target = torch.zeros(10)\n    for l in str(label).split(' '):\n        target[int(l)] = 1.\n    return target\n\ndef decode_target(target, text_labels=False, threshold=0.5):\n    result = []\n    for i, x in enumerate(target):\n        if (x >= threshold):\n            if text_labels:\n                result.append(labels[i] + \"(\" + str(i) + \")\")\n            else:\n                result.append(str(i))\n    return ' '.join(result)","5e671466":"aug_tfms = aug_transforms(mult=1.0, \n               do_flip=True, \n               flip_vert=False, \n               max_rotate=10.0, \n               max_zoom=1.1, \n               max_lighting=0.5, \n               max_warp=0.2, \n               p_affine=0.75, \n               p_lighting=0.75, \n               xtra_tfms=RandomErasing(p=1., max_count=6), \n               size=224, \n               mode='bilinear', \n               pad_mode='reflection', \n               align_corners=True, \n               batch=False, \n               min_scale=0.75)","f51254fc":"def get_x(r): return r['imgPath']\ndef get_y(r): return r['Label'].split(' ')\ndef splitter(df):\n    train = df.index[~df['is_valid']].tolist()\n    valid = df.index[df['is_valid']].tolist()\n    return train,valid","ab81df58":"dblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),\n                   splitter=splitter, \n                   get_x = get_x, get_y = get_y,\n                   item_tfms=Resize(460),\n                   batch_tfms=aug_tfms)","3f2d929d":"dls = dblock.dataloaders(train_df)","b866e372":"dls.train.show_batch(max_n=9)","45cc2cb9":"def accuracy_multi(inp, targ, thresh=0.5, sigmoid=True):\n    \"Compute accuracy when `inp` and `targ` are the same size.\"\n    if sigmoid: inp = inp.sigmoid()\n    return ((inp>thresh)==targ.bool()).float().mean()","8f32ad41":"def F_score(output, label, threshold=0.2, beta=1):\n    prob = output > threshold\n    label = label > threshold\n\n    TP = (prob & label).sum(1).float()\n    TN = ((~prob) & (~label)).sum(1).float()\n    FP = (prob & (~label)).sum(1).float()\n    FN = ((~prob) & label).sum(1).float()\n\n    precision = torch.mean(TP \/ (TP + FP + 1e-12))\n    recall = torch.mean(TP \/ (TP + FN + 1e-12))\n    F2 = (1 + beta**2) * precision * recall \/ (beta**2 * precision + recall + 1e-12)\n    return F2.mean(0)","d0b24f2b":"cutmix = CutMix(1.0)\nlearn = cnn_learner(dls, resnet18, \n                    metrics=[partial(accuracy_multi, thresh=0.2),partial(F_score, threshold=0.2)],\n                    cbs=cutmix,\n                   callback_fns=[partial(EarlyStoppingCallback, monitor='valid_loss', min_delta=0.01, patience=3)])","0111e98a":"learn._do_begin_fit(1)\nlearn.epoch,learn.training = 0,True\nlearn.dl = dls.train\nb = dls.one_batch()\nlearn._split(b)\nlearn('begin_batch')\n_,axs = plt.subplots(3,3, figsize=(9,9))\ndls.show_batch(b=(cutmix.x,cutmix.y), ctxs=axs.flatten())","639021df":"learn.fine_tune(3, base_lr=3e-3, freeze_epochs=2)","c8707fc0":"mixup = MixUp(0.4) \nlearn = cnn_learner(dls, resnet18, \n                    metrics=[partial(accuracy_multi, thresh=0.2),partial(F_score, threshold=0.2)],\n                    cbs=mixup,\n                   callback_fns=[partial(EarlyStoppingCallback, monitor='valid_loss', min_delta=0.01, patience=3)])","3f983e21":"learn._do_begin_fit(1)\nlearn.epoch,learn.training = 0,True\nlearn.dl = dls.train\nb = dls.one_batch()\nlearn._split(b)\nlearn('begin_batch')\n_,axs = plt.subplots(3,3, figsize=(9,9))\ndls.show_batch(b=(mixup.x,mixup.y), ctxs=axs.flatten())","aa83c890":"learn.fine_tune(3, base_lr=3e-3, freeze_epochs=2)","b2ac9bf3":"learn = cnn_learner(dls, resnet18, \n                    metrics=[partial(accuracy_multi, thresh=0.2),partial(F_score, threshold=0.2)],\n                   callback_fns=[partial(EarlyStoppingCallback, monitor='valid_loss', min_delta=0.01, patience=3)])","0284f76d":"learn.fine_tune(3, base_lr=3e-3, freeze_epochs=4)","cb38ac0f":"preds,targs = learn.get_preds()","0b9f0c5b":"xs = torch.linspace(0.05,0.95,29)\naccs = [accuracy_multi(preds, targs, thresh=i, sigmoid=False) for i in xs]\nfscores = [F_score(preds, targs, threshold=i, beta=1) for i in xs]","addecdf6":"plt.plot(xs,accs);","30bc4c3c":"plt.plot(xs,fscores);","93171be1":"learn = cnn_learner(dls, resnet18, \n                    metrics=[partial(accuracy_multi, thresh=0.2),partial(F_score, threshold=0.2)],\n                   callback_fns=[partial(EarlyStoppingCallback, monitor='valid_loss', min_delta=0.01, patience=3)])","1c1ea565":"learn.fine_tune(20, base_lr=3e-3, freeze_epochs=4)","ec9714fe":"learn.show_results()","13eb07d5":"interp = ClassificationInterpretation.from_learner(learn)","ca9b40d5":"interp.plot_top_losses(5, nrows=1)","8cffaf61":"learn.export('export.pkl')","f09b39c4":"dl = learn.dls.test_dl(test_df)","4d75e1a1":"preds,targs = learn.tta(dl=dl)","899af46b":"predictions = [decode_target(x, threshold=0.5) for x in preds]","8b128e63":"submission_df = pd.read_csv(TEST_CSV)\nsubmission_df.Label = predictions\nsubmission_df.head()","98bf1015":"sub_fname = 'submission_fastai_v6_1.csv'","f0ed5bc4":"submission_df.to_csv(sub_fname, index=False)","46459766":"predictions = [decode_target(x, threshold=0.2) for x in preds]","f94e95b2":"submission_df = pd.read_csv(TEST_CSV)\nsubmission_df.Label = predictions\nsubmission_df.head()","d542efb5":"sub_fname = 'submission_fastai_v6_2.csv'","5f677456":"submission_df.to_csv(sub_fname, index=False)","c6b24fa9":"!pip install jovian --upgrade --quiet","753f0c27":"import jovian","ed964b3d":"project_name='protein-advanced'","ab573315":"jovian.commit(project=project_name, environment=None)","4df3c694":"### 2. Using Mixup data augmentation","c015659b":"# Dataloaders","e42bbe83":"#### functions for getting image path and labels in dataloaders","307a01d1":"Cutmix is a data augmentation technique in which parts of images are cut and mixed with another image. It comes from Cutout and Mixup. \nhttps:\/\/arxiv.org\/pdf\/1905.04899.pdf","c1794559":"# Multi-label metrics","73c1325e":"#### Random erasing augmentation have erased regions of the image and replaced them with gaussian noise","04face53":"# Stratification","112b49e9":"### Test time augmentation during prediction of test data","7da656ac":"# Helper functions","3c5f9fe3":"### Data augmentation","0ed8990b":"# Import modules","1d42438e":"fastai is a deep learning library which is easier to use and for people from different backgrounds. It consists of high level API components that can be used to achieve state of the art results quiculy and easily. In this competetion, we experiment with fastai library to see if we can achieve high performance model. \n\nhttps:\/\/arxiv.org\/abs\/2002.04688","61fe507f":"### 3.Without cutmix or mixup","e38c4de3":"As this is a multi-label classification problem we cannot use softwax but use sigmoid activiation with threshold. The threshold is a hyperparameter which determines the prediction of the labels. We have to experiment with different threshold value to find the optimal one. Here we are using two metric accuracy_multi and F1_multi and both takes threshold as input parameter. ","8d5edee9":"#### Create a new column with image paths","a2bb3839":"'is_valid' column will be used to the train and validation split when creating the datablocks. ","77b1b937":"# Model performance","ec1acf02":"using threshold = 0.5","d6448532":"Using threshold = 0.2","8cbd8432":"### 1. Using cutmix data augmentation","a6bb565c":"# Prediction and submission","a70f8ccf":"### Show a batch of train data","ba2f5f12":"# Selecting the suitable threshold for multi-metrics","456f14a7":"# Load the test data and do predictions","72fdeab2":"# CNN learner","0224d067":"Here we implement stratifed split of the training data as compared to random split. This implementation was taken from https:\/\/www.kaggle.com\/ronaldokun\/multilabel-stratification-cv-and-ensemble","ca3f9eaf":"# Data","2824ccd6":"Looking at the graph above 0.2 seems to be thr right threshold","8484c6a5":"# Training"}}