{"cell_type":{"ab239678":"code","ef9a1d17":"code","5d7c75b2":"code","d3f81034":"code","13dea89e":"code","a80879ff":"code","f34e1b2c":"code","4387d2b7":"code","f1688389":"code","44614aa2":"code","c2ccbb92":"code","7d593ddf":"code","4bb37459":"code","8de34778":"code","bba53a9e":"code","606b6435":"code","62a60a5c":"code","52c3d836":"code","67a57f72":"code","b033bbd7":"code","daa5c835":"code","3560b9fe":"code","f175f945":"code","eaf6e963":"code","3bbc4096":"code","f2244c72":"code","bfdd94f8":"code","61b3eaac":"code","d837f11e":"code","7f4e40d8":"code","0d9f5fcf":"code","8e4415f4":"code","e8b0e343":"code","5f74dbb8":"code","9fe8827d":"code","7772ba69":"code","899b50dc":"code","9ced142f":"code","5cf21d90":"code","49a6b7fe":"code","f760b90f":"code","4b26fae6":"code","f6d7bc67":"code","2a2a4749":"code","96fc945a":"code","78d88306":"code","c01cd27c":"code","d133b3a2":"code","872924ff":"markdown","9ef01ce6":"markdown","2480c134":"markdown","fecf9dc1":"markdown","e18a94d1":"markdown","6594f287":"markdown","e5516f0b":"markdown","e837fd61":"markdown","a35041a3":"markdown","879115b5":"markdown","459e8016":"markdown","49d98a34":"markdown","c8b79ae8":"markdown","0836bcda":"markdown","91edf76d":"markdown"},"source":{"ab239678":"pip install autoviz","ef9a1d17":"# Loading packages.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom autoviz.AutoViz_Class import AutoViz_Class\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nfrom matplotlib.ticker import MaxNLocator\nfrom pandas_profiling import ProfileReport\nimport math\nimport random\nimport os\nimport time\n# Setup\n\n# common:\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport plotly.express as px\nimport folium\n\n# preprocessing\nimport sklearn\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, learning_curve, ShuffleSplit\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, accuracy_score, confusion_matrix, explained_variance_score\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.feature_selection import SelectFromModel, SelectKBest, RFE, chi2\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.svm import LinearSVC\n\n\n# models\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import LogisticRegression, LassoCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\nfrom sklearn.naive_bayes import GaussianNB\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\n\n# NN models\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras import optimizers\nfrom keras.wrappers.scikit_learn import KerasClassifier\n\n\n# set some display options:\nsns.set(style=\"whitegrid\")\npd.set_option(\"display.max_columns\", 36)\n\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom numpy import interp\n\n# disabling warnings.\n\nimport warnings\nwarnings.filterwarnings('ignore') ","5d7c75b2":"# Styling...\ncust_palt = [\n    '#111d5e', '#c70039', '#f37121', '#ffbd69', '#ffc93c'\n]\n\nplt.style.use('ggplot')","d3f81034":"# Reading csv file:\n\ntrain = pd.read_csv('..\/input\/heart-disease-cleveland-uci\/heart_cleveland_upload.csv')","13dea89e":"# Taking random samples from data.\n\ntrain.head(5)","a80879ff":"train.info()","f34e1b2c":"train.columns","4387d2b7":"# Renaming columns.\ntrain.columns = ['age', 'sex', 'chest_pain_type', 'resting_blood_pressure', 'cholesterol', 'fasting_blood_sugar',\n                 'rest_ecg', 'max_heart_rate_achieved','exercise_induced_angina', 'st_depression', 'st_slope',\n                 'num_major_vessels', 'thalassemia', 'condition']","f1688389":"# Renaming cateorical data for easier understanding:\n\ntrain['sex'] = train['sex'].map({0:'female',1:'male'})\ntrain['chest_pain_type'] = train['chest_pain_type'].map({3:'asymptomatic', 1:'atypical_angina', 2:'non_anginal_pain', 0:'typical_angina'})\ntrain['fasting_blood_sugar'] = train['fasting_blood_sugar'].map({0:'less_than_120mg\/ml',1:'greater_than_120mg\/ml'})\ntrain['rest_ecg'] = train['rest_ecg'].map({0:'normal',1:'ST-T_wave_abnormality',2:'left_ventricular_hypertrophy'})\ntrain['exercise_induced_angina'] = train['exercise_induced_angina'].map({0:'no',1:'yes'})\ntrain['st_slope'] = train['st_slope'].map({0:'upsloping',1:'flat',2:'downsloping'})\ntrain['thalassemia'] = train['thalassemia'].map({1:'fixed_defect',0:'normal',2:'reversable_defect'})\ntrain['condition'] = train['condition'].map({0:'no_disease', 1:'has_disease'})\n","44614aa2":"# Masks for easier selection in future:\n# Very Important\ncategorical = [i for i in train.loc[:,train.nunique()<=10]]\ncontinuous = [i for i in train.loc[:,train.nunique()>=10]]","c2ccbb92":"[i for i in train.loc[:,train.nunique()<=10]]","7d593ddf":"[i for i in train.loc[:,train.nunique()>=10]]","4bb37459":"total = float(len(train[categorical]))","8de34778":"def ctg_dist(df, cols, hue,rows, columns):\n    \n    '''A function for displaying cateorical distribution'''\n    \n    fig, axes = plt.subplots(rows, columns, figsize=(16, 12))\n    axes = axes.flatten()\n\n    for i, j in zip(df[cols].columns, axes):\n        sns.countplot(x=i,\n                    data=df,\n                    ax=j,\n                    order=df[i].value_counts().index)\n        j.tick_params(labelrotation=10)\n        j.set_title(f'{str(i).capitalize()} Distribution')\n        plt.tight_layout()\n        total = float(len(df[i]))        \n        for p in j.patches:\n            height = p.get_height()\n            j.text(p.get_x() + p.get_width() \/ 2.,\n                    height + 2,\n                    '{:1.2f}%'.format((height \/ total) * 100),\n                    ha='center')","bba53a9e":"total","606b6435":"# Display categorical columns:\n\nctg_dist(train, categorical,hue=None, rows=3,columns=3)","62a60a5c":"# Displaying numeric distribution:\n\nfig = plt.figure(constrained_layout=True, figsize=(16, 12))\n\n\ngrid = gridspec.GridSpec(ncols=6, nrows=3, figure=fig)\n\nax1 = fig.add_subplot(grid[0, :2])\n\nax1.set_title('Trestbps Distribution')\n\nsns.distplot(train[continuous[1]],\n                 hist_kws={\n                 'rwidth': 0.85,\n                 'edgecolor': 'black',\n                 'alpha': 0.8})\n\nax15 = fig.add_subplot(grid[0, 2:3])\n\nax15.set_title('Trestbps')\n\nsns.boxplot(train[continuous[1]], orient='v')\n\nax2 = fig.add_subplot(grid[0, 3:5])\n\nax2.set_title('Chol Distribution')\n\nsns.distplot(train[continuous[2]],\n                 hist_kws={\n                 'rwidth': 0.85,\n                 'edgecolor': 'black',\n                 'alpha': 0.8})\n\nax25 = fig.add_subplot(grid[0, 5:])\n\nax25.set_title('Chol')\n\nsns.boxplot(train[continuous[2]], orient='v')\n\nax3 = fig.add_subplot(grid[1, :2])\n\nax3.set_title('Thalach Distribution')\n\nsns.distplot(train[continuous[3]],\n                 hist_kws={\n                 'rwidth': 0.85,\n                 'edgecolor': 'black',\n                 'alpha': 0.8})\n\nax35 = fig.add_subplot(grid[1, 2])\n\nax35.set_title('Thalach')\n\nsns.boxplot(train[continuous[3]], orient='v')\n\nax4 = fig.add_subplot(grid[1, 3:5])\n\nax4.set_title('Oldpeak Distribution')\n\nsns.distplot(train[continuous[4]],\n                 hist_kws={\n                 'rwidth': 0.85,\n                 'edgecolor': 'black',\n                 'alpha': 0.8})\n\nax45 = fig.add_subplot(grid[1, 5:])\n\nax45.set_title('Oldpeak')\n\nsns.boxplot(train[continuous[4]], orient='v')\n\nax5 = fig.add_subplot(grid[2, :4])\n\nax5.set_title('Age Distribution')\n\nsns.distplot(train[continuous[0]],\n                 hist_kws={\n                 'rwidth': 0.95,\n                 'edgecolor': 'black',\n                 'alpha': 0.8})\n\nax55 = fig.add_subplot(grid[2, 4:])\n\nax55.set_title('Age')\n\nsns.boxplot(train[continuous[0]], orient='h')\n\nplt.show()\n","52c3d836":"def ctg_dist1(df, cols,rows, columns):\n    \n    '''A function for displaying cateorical distribution'''\n    \n    fig, axes = plt.subplots(rows, columns, figsize=(20, 15))\n    axes = axes.flatten()\n\n    for i, j in zip(df[cols].columns, axes):\n        sns.countplot(x=i,\n                    data=df,\n                    ax=j,\n                    order=df[i].value_counts().index,\n                    hue='condition')\n        j.tick_params(labelrotation=10)\n        j.set_title(f'{str(i).capitalize()} Distribution')\n        total = float(len(df[i]))        \n        for p in j.patches:\n            height = p.get_height()\n            j.text(p.get_x() + p.get_width() \/ 2.,\n                    height + 2,\n                    '{:1.2f}%'.format((height \/ total) * 100),\n                    ha='center')\n        plt.tight_layout()","67a57f72":"ctg_dist1(train,categorical,4,2)","b033bbd7":"# Displaying numeric distribution vs condition:\n\nfig = plt.figure(constrained_layout=True, figsize=(16, 12))\n\n\ngrid = gridspec.GridSpec(ncols=4, nrows=3, figure=fig)\n\nax1 = fig.add_subplot(grid[0, :2])\n\nax1.set_title('resting_blood_pressure Distribution')\n\nsns.boxplot(x='condition',\n                    y='resting_blood_pressure',\n                    data=train,\n                    palette=cust_palt[2:],\n                    ax=ax1)\nsns.swarmplot(x='condition',\n                    y='resting_blood_pressure',\n                    data=train,\n                    palette=cust_palt[:2],\n                    ax=ax1)\n\nax2 = fig.add_subplot(grid[0, 2:])\n\nax2.set_title('cholesterol Distribution')\n\nsns.boxplot(x='condition',\n                    y='cholesterol',\n                    data=train,\n                    palette=cust_palt[2:],\n                    ax=ax2)\nsns.swarmplot(x='condition',\n                    y='cholesterol',\n                    data=train,\n                    palette=cust_palt[:2],\n                    ax=ax2)\n\nax3 = fig.add_subplot(grid[1, :2])\n\nax3.set_title('max_heart_rate_achieved Distribution')\n\nsns.boxplot(x='condition',\n                    y='max_heart_rate_achieved',\n                    data=train,\n                    palette=cust_palt[2:],\n                    ax=ax3)\nsns.swarmplot(x='condition',\n                    y='max_heart_rate_achieved',\n                    data=train,\n                    palette=cust_palt[:2],\n                    ax=ax3)\n\nax4 = fig.add_subplot(grid[1, 2:])\n\nax4.set_title('st_depression Distribution')\n\nsns.boxplot(x='condition',\n                    y='st_depression',\n                    data=train,\n                    palette=cust_palt[2:],\n                    ax=ax4)\nsns.swarmplot(x='condition',\n                    y='st_depression',\n                    data=train,\n                    palette=cust_palt[:2],\n                    ax=ax4)\n\nax5 = fig.add_subplot(grid[2, :])\n\nax5.set_title('age Distribution')\n\nsns.boxplot(x='condition',\n                    y='age',\n                    data=train,\n                    palette=cust_palt[2:],\n                    ax=ax5)\nsns.swarmplot(x='condition',\n                    y='age',\n                    data=train,\n                    palette=cust_palt[:2],\n                    ax=ax5)\nplt.show()","daa5c835":"# Numeric data vs each other and condition:\n\nplt.figure(figsize=(16, 10))\nsns.pairplot(train[['resting_blood_pressure','cholesterol','max_heart_rate_achieved','st_depression','age', 'condition']], hue='condition',\n           markers=['o','D'], plot_kws=dict(s=25, alpha=0.75, ci=None)\n            )\n\nplt.show()","3560b9fe":"# 3D scatterplot of numeric data:\n\nfig = px.scatter_3d(train, x='cholesterol', y='max_heart_rate_achieved', z='age', size='st_depression',\n              color='condition', opacity=0.8)\nfig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\nfig.show()","f175f945":"corr_train = pd.read_csv('..\/input\/heart-disease-cleveland-uci\/heart_cleveland_upload.csv')\nfull_data = train","eaf6e963":"corr_train.columns = ['age', 'sex', 'chest_pain_type', 'resting_blood_pressure', 'cholesterol', 'fasting_blood_sugar',\n                 'rest_ecg', 'max_heart_rate_achieved','exercise_induced_angina', 'st_depression', 'st_slope',\n                 'num_major_vessels', 'thalassemia', 'condition']","3bbc4096":"sns.set(font_scale=1.3)\ncorr_categorical=corr_train.corr(method='spearman')\nmask_categorical = np.triu(np.ones_like(corr_categorical, dtype=np.bool))\nplt.figure(figsize=(20, 12))\nsns.heatmap(corr_categorical, annot=True, fmt=\".2f\", cmap='BrBG', vmin=-1, vmax=1, center= 0,\n            square=True, linewidths=2, cbar_kws={\"shrink\": .5}).set(ylim=(14, 0))\nplt.title(\"Correlation Matrix Spearman Method- Categorical Data \",size=15, weight='bold')\n","f2244c72":"sns.set(font_scale=1.3)\ncorr_categorical=corr_train.corr(method='pearson')\nmask_categorical = np.triu(np.ones_like(corr_categorical, dtype=np.bool))\nplt.figure(figsize=(20, 12))\nsns.heatmap(corr_categorical, annot=True, fmt=\".2f\", cmap='BrBG', vmin=-1, vmax=1, center= 0,\n            square=True, linewidths=2, cbar_kws={\"shrink\": .5}).set(ylim=(14, 0))\nplt.title(\"Correlation Matrix Spearman Method- Categorical Data \",size=15, weight='bold')\n","bfdd94f8":"correlations = corr_train.corrwith(corr_train['condition']).iloc[:-1].to_frame()\ncorrelations[0] = correlations[0].abs()\ncorrelations.sort_values(by=0, inplace=True, ascending=False)\nlabels = correlations.index\nax = sns.boxplot(x=0,y=labels, data=correlations, palette = 'pink')\nax.set_yticklabels(labels)\nax.set(xlabel='Correlation', ylabel='Parameter')","61b3eaac":"data = pd.read_csv('..\/input\/heart-disease-cleveland-uci\/heart_cleveland_upload.csv')","d837f11e":"def fe_creation(df):\n    df['age2'] = df['age']\/\/10\n    df['trestbps2'] = df['trestbps']\/\/10\n    df['chol2'] = df['chol']\/\/40\n    df['thalach2'] = df['thalach']\/\/40\n    df['oldpeak2'] = df['oldpeak']\/\/0.4\n    for i in ['sex', 'age2', 'fbs', 'restecg', 'exang','thal', ]:\n        for j in ['cp','trestbps2', 'chol2', 'thalach2', 'oldpeak2', 'slope', 'ca']:\n            df[i + \"_\" + j] = df[i].astype('str') + \"_\" + df[j].astype('str')\n    return df\n\ndata = fe_creation(data)","7f4e40d8":"data.columns","0d9f5fcf":"data.head(3)","8e4415f4":"categorical_columns = {'sex_cp', 'sex_trestbps2',\n       'sex_chol2', 'sex_thalach2', 'sex_oldpeak2', 'sex_slope', 'sex_ca',\n       'age2_cp', 'age2_trestbps2', 'age2_chol2', 'age2_thalach2',\n       'age2_oldpeak2', 'age2_slope', 'age2_ca', 'fbs_cp', 'fbs_trestbps2',\n       'fbs_chol2', 'fbs_thalach2', 'fbs_oldpeak2', 'fbs_slope', 'fbs_ca',\n       'restecg_cp', 'restecg_trestbps2', 'restecg_chol2', 'restecg_thalach2',\n       'restecg_oldpeak2', 'restecg_slope', 'restecg_ca', 'exang_cp',\n       'exang_trestbps2', 'exang_chol2', 'exang_thalach2', 'exang_oldpeak2',\n       'exang_slope', 'exang_ca', 'thal_cp', 'thal_trestbps2', 'thal_chol2',\n       'thal_thalach2', 'thal_oldpeak2', 'thal_slope', 'thal_ca'}","e8b0e343":"#Label Encoding the Categorical Columns\nfor col in categorical_columns:\n      le = LabelEncoder()\n      le.fit(list(data[col].astype(str).values))\n      data[col] = le.transform(list(data[col].astype(str).values))","5f74dbb8":"data.head(3)","9fe8827d":"train = data.copy()\ntarget = train.pop('condition')\ntrain.head(2)","7772ba69":"num_features_opt = 25   # the number of features that we need to choose as a result\nnum_features_max = 35   # the somewhat excessive number of features, which we will choose at each stage\nfeatures_best = []","899b50dc":"#FS by the SelectFromModel with LinearSVC \nlsvc = LinearSVC(C=0.1, penalty=\"l1\", dual=False).fit(train, target)\nmodel = SelectFromModel(lsvc, prefit=True)\nX_new = model.transform(train)\nX_selected_df = pd.DataFrame(X_new, columns=[train.columns[i] for i in range(len(train.columns)) if model.get_support()[i]])\nfeatures_best.append(X_selected_df.columns.tolist())","9ced142f":"#FS by the SelectFromModel with Lasso\nlasso = LassoCV(cv=3).fit(train, target)\nmodel = SelectFromModel(lasso, prefit=True)\nX_new = model.transform(train)\nX_selected_df = pd.DataFrame(X_new, columns=[train.columns[i] for i in range(len(train.columns)) if model.get_support()[i]])\nfeatures_best.append(X_selected_df.columns.tolist())","5cf21d90":"#FS by the SelectKBest with Chi-2\nbestfeatures = SelectKBest(score_func=chi2, k='all')\nfit = bestfeatures.fit(train, target)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(train.columns)\n\n#concat two dataframes for better visualization \nfeatureScores = pd.concat([dfcolumns,dfscores],axis=1)\nfeatureScores.columns = ['Feature','Score']\nfeatureScores = featureScores.sort_values(by='Score', ascending=False)\nfeatures_best.append(featureScores['Feature'].to_list())","49a6b7fe":"#FS by the Recursive Feature Elimination (RFE) with Logistic Regression\nrfe_selector = RFE(estimator=LogisticRegression(), n_features_to_select=num_features_max, step=10, verbose=5)\nrfe_selector.fit(train, target)\nrfe_support = rfe_selector.get_support()\nrfe_feature = train.loc[:,rfe_support].columns.tolist()\nfeatures_best.append(rfe_feature)","f760b90f":"#FS by the VarianceThreshold\nselector = VarianceThreshold(threshold=10)\nnp.shape(selector.fit_transform(data))\nfeatures_best.append(list(np.array(data.columns)[selector.get_support(indices=False)]))","4b26fae6":"features_best","f6d7bc67":"# Most common items in all lists of optimal features\nmain_cols = []\nmain_cols_opt = {feature_name : 0 for feature_name in data.columns.tolist()}\nfor i in range(len(features_best)):\n  for feature_name in features_best[i]:\n        main_cols_opt[feature_name] += 1\ndf_main_cols_opt = pd.DataFrame.from_dict(main_cols_opt, orient='index', columns=['Num'])\ndf_main_cols_opt.sort_values(by=['Num'], ascending=False)","2a2a4749":"main_cols = df_main_cols_opt.nlargest(num_features_opt, 'Num').index.tolist()","96fc945a":"len(main_cols)","78d88306":"X = train[main_cols]\ny = target","c01cd27c":"# define models to test:\nbase_models = [(\"DT_model\", DecisionTreeClassifier(random_state=42)),\n               (\"RF_model\", RandomForestClassifier(random_state=42,n_jobs=-1)),\n               (\"LR_model\", LogisticRegression(random_state=42,n_jobs=-1)),\n               (\"XGB_model\", XGBClassifier(random_state=42, n_jobs=-1)),\n               (\"SVM_model\",LinearSVC(random_state=42)),\n               (\"NB_model\", GaussianNB())]\n# split data into 'kfolds' parts for cross validation,\n# use shuffle to ensure random distribution of data:\nkfolds = 4 # 4 = 75% train, 25% validation\nsplit = KFold(n_splits=kfolds, shuffle=True, random_state=42)\n\nfor name, model in base_models:   \n    # get cross validation score for each model:\n    cv_results = cross_val_score(model, \n                                 X, y, \n                                 cv=split,\n                                 scoring=\"accuracy\",\n                                 n_jobs=-1)\n    # output:\n    min_score = round(min(cv_results), 4)\n    max_score = round(max(cv_results), 4)\n    mean_score = round(np.mean(cv_results), 4)\n    std_dev = round(np.std(cv_results), 4)\n    print(f\"{name} cross validation accuarcy score: {mean_score} +\/- {std_dev} (std) min: {min_score}, max: {max_score}, \")","d133b3a2":"#HyperParameterTuning for LR Model \nmodel = LogisticRegression()\nsolvers = ['newton-cg', 'lbfgs', 'liblinear']\npenalty = ['l2']\nc_values = [100, 10, 1.0, 0.1, 0.01, 101, 99, 102, 98]\n# define grid search\ngrid = dict(solver=solvers,penalty=penalty,C=c_values)\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\ngrid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\ngrid_result = grid_search.fit(X, y)\n# summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","872924ff":"## Numerical Data","9ef01ce6":"## Univariate Analysis\n\n#### For this part we going to inspect how's the data distribution is and what patterns we can inspect.","2480c134":"## ML Prediction","fecf9dc1":"# Bivariate Analysis\n## Categorical Data vs Target\n\n### Here we can do these observations:\n\n- Males are much more likely for heart diseases.\n- Chest pain type is very subjective and has no direct relation on the outcome, asymptomatic chest pains having highest disease outcome.\n- Blood sugar has no direct effect on the disease.\n- Rest ECG results showing no direct results but having normal ECG is pretty good sign. Even though it's pretty rare in the data, if you ST-T wave abnormality you are 3 times more likely to have heart disease.\n- Having exercise induced angina is pretty strong indicator for heart disease, patients are almost 3 times more likely to have disease if they have exercise induced angina. Meanwhile it's less than half for not having it.\n- Patients who had flat slope distribution are more likely to have disease.\n- Number of major vessels observed seems on similar levels for patients who have disease but 0 observations is good sign for not having disease.\n- Having defected thalium test results is pretty strong indicator for heart disease.","e18a94d1":"### Feature Selection","6594f287":"The data includes 303 patient level features including if they have heart disease at the end or not. Features are like;\n\n- Age: Obvious one...\n- Sex:\n    - 0: Female\n    - 1: Male\n- Chest Pain Type: \n    - 0: Typical Angina\n    - 1: Atypical Angina\n    - 2: Non-Anginal Pain\n    - 3: Asymptomatic\n- Resting Blood Pressure: Person's resting blood pressure.\n- Cholesterol: Serum Cholesterol in mg\/dl  \n- Fasting Blood Sugar:\n    - 0:Less Than 120mg\/ml\n    - 1: Greater Than 120mg\/ml\n- Resting Electrocardiographic Measurement:\n    - 0: Normal\n    - 1: ST-T Wave Abnormality\n    - 2: Left Ventricular Hypertrophy\n- Max Heart Rate Achieved: Maximum Heart Rate Achieved\n- Exercise Induced Angina:\n    - 1: Yes\n    - 0: No\n- ST Depression: ST depression induced by exercise relative to rest.\n- Slope: Slope of the peak exercise ST segment:\n    - 0: Upsloping\n    - 1: Flat\n    - 2: Downsloping\n- Thalassemia: A blood disorder called 'Thalassemia':\n    - 0: Normal\n    - 1: Fixed Defect\n    - 2: Reversable Defect\n- Number of Major Vessels: Number of major vessels colored by fluoroscopy.\n\nhttps:\/\/github.com\/HimanshuKGP007\/HeartDiseaseAnalysis","e5516f0b":"Logistic Regression Model gives the best accuracy at 83.52% ","e837fd61":"## Feature Engineering","a35041a3":"## Heart Disease - EDA,FE and ML Prediction","879115b5":"## Correlations","459e8016":"As we can see, after Hyper Parameter tuning of LogisticRegression we get accuracy of 84.26%","49d98a34":"### Most of the continuous variables somewhat close to gaussian distribution with small skews left or right except for oldpeak. Again there are some outliers espacially a strong one in Cholesterol worth to take a look later.","c8b79ae8":"## Categorical Data\n\n### Here we can do these observations:\n- Males on the dataset is more than double of the female observations.\n- Most common ches pain type is 'Asymptomatic' ones which is almost 50% of the data\n- 85% of the patients has no high levels of fastin blood sugar.\n- Resing electrocardiographic observations are evenly distributed between normal and left ventricular hypertrophy with ST-T minority\n- 67% of the patients had no exercise induced angina\n- Peak exercise slope seems mainly divided between upsloping and flat.","0836bcda":"## Numerical Data vs Target\n\n### Here we can do these observations:\n\n- Having higher resting blood pressure shows you are little bit more likely to have heart disease.\n- Again same for Cholesterol, it's not strong indicator but patients are little bit more likely to have disease with high cholesterol. There's is also one outlier there with no disease, pretty interesting.\n- I find max heart rate distribution a bit interesting, expecting the other way around but it might be due to testing conditions and if you have normal results on ECG while exercising instructors might be increasing your excercise density?\n- It's pretty clear that heart disease likelihood increases with ST depression levels...\n- Lastly older patients are more likely to have heart disease.","91edf76d":"# Multivariate Analysis"}}