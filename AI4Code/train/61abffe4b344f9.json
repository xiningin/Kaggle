{"cell_type":{"de963719":"code","278f3e43":"code","651a0ed3":"code","8885f66a":"code","21850206":"code","c0703c0a":"code","9032ae03":"code","85e25310":"code","e62764bd":"code","5c74d228":"code","28e37cce":"code","c29bba26":"code","3d03667c":"code","bdc4d834":"code","3a25a0ee":"code","0a2371ff":"code","e7c40455":"code","56d78a2a":"code","f41694c6":"code","bedb4f56":"code","922d86fc":"code","a09c2779":"code","ff426c8f":"code","679d4787":"code","75bafc3c":"markdown","239f02e2":"markdown","70fbb6d4":"markdown","6ba4942b":"markdown"},"source":{"de963719":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf=pd.read_csv('..\/input\/eeg-signal-processing\/EEG_Clean_Data.csv')\ndf.head()","278f3e43":"# extracting the numbers from the skewness().1 and _kurtosis().1\ndf['EEG _skewness().1']=df['EEG _skewness().1'].str.extract(r\"(\\d+\\.\\d+|\\d+)\").astype(float)\ndf['EEG _kurtosis().1']=df['EEG _kurtosis().1'].str.extract(r\"(\\d+\\.\\d+|\\d+)\").astype(float)\ndf['EEG _skewness()']=df['EEG _skewness()'].str.extract(r\"(\\d+\\.\\d+|\\d+)\").astype(float)\ndf['EEG _kurtosis()']=df['EEG _kurtosis()'].str.extract(r\"(\\d+\\.\\d+|\\d+)\").astype(float)\ndf.head()","651a0ed3":"df.drop('subject',axis=1,inplace=True)","8885f66a":"plt.figure(figsize=(20,20))\nsns.heatmap(df.corr(), cmap=\"YlGnBu\",center=True , robust=False, annot=True)\n","21850206":"sns.countplot(df['state'])\nplt.title(\"The Count of Each Class\")","c0703c0a":"df.info()","9032ae03":"x=df.iloc[:,:-1]\ny=df.iloc[:,-1]\nprint('The X data has a length of {}'.format(len(x)))\nprint('The Y target has a length of {}'.format(len(y)))\nprint('Perfect!')","85e25310":"from sklearn.model_selection import train_test_split\nx_train,x_test_vald,y_train,y_test_vald=train_test_split(x,y,test_size=0.4)\nx_vald,x_test,y_vald,y_test=train_test_split(x,y,test_size=0.5)\nprint('The X_training has a length of {}'.format(len(x_train)))\nprint('The X_vald has a length of {}'.format(len(x_vald)))\nprint('The y_vald has a length of {}'.format(len(y_vald)))\nprint('The X_test has a length of {}'.format(len(x_test)))\nprint('The Y_training has a length of {}'.format(len(y_train)))\nprint('The Y_test has a length of {}'.format(len(y_test)))\nprint('Perfect!')","e62764bd":"from sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\nscaler.fit(x_train)\nscaler.transform(x_vald)\nscaler.transform(x_test)","5c74d228":"from sklearn.metrics import make_scorer\nfrom sklearn.metrics import f1_score\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\nscorer = make_scorer(f1_score)\nparameters = {'C':[1, 10]}\nsvm=SVC()\ngrid = GridSearchCV(estimator=svm,param_grid=parameters,scoring=scorer) ","28e37cce":"grid","c29bba26":"grid_fit=grid.fit(x_train,y_train)\n","3d03667c":"best=grid_fit.best_estimator_\nbest","bdc4d834":"yhat=best.predict(x_vald)","3a25a0ee":"from sklearn.metrics import accuracy_score\nprint(accuracy_score(y_vald,yhat))","0a2371ff":"from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\nrf=RandomForestClassifier(criterion='entropy')\nrf.fit(x_train,y_train)\nyrf=rf.predict(x_vald)\nprint(accuracy_score(y_vald,yrf))","e7c40455":"ada=AdaBoostClassifier()\nada.fit(x_train,y_train)\nyada=ada.predict(x_vald)\nprint(accuracy_score(y_vald,yada))\n","56d78a2a":"from sklearn.neighbors import KNeighborsClassifier\nknn=KNeighborsClassifier()\nknn.fit(x_train,y_train)\nyknn=knn.predict(x_vald)\nprint(accuracy_score(y_vald,yknn))\n","f41694c6":"results=pd.DataFrame({\"Classifier\":['SVM','RF','ADA','KNN'],\"Accuracy\":[accuracy_score(y_vald,yhat),accuracy_score(y_vald,yrf),accuracy_score(y_vald,yada),accuracy_score(y_vald,yknn)]\n                     ,\"f1_score\":[f1_score(y_vald,yhat),f1_score(y_vald,yrf),f1_score(y_vald,yada),f1_score(y_vald,yknn)]})\nresults","bedb4f56":"plt.figure(figsize=(10,5));\nplt.subplot(1,2,1);\nplt.bar(x=results['Classifier'],height=results['Accuracy']*100,width=0.4,color=\"#F39C12\");\nplt.title(\"The Accuracy Results on the Validation Data \")\nplt.subplot(1,2,2);\nplt.bar(x=results['Classifier'],height=results['f1_score']*100,width=0.4,color=\"#581845\");\nplt.title(\"The F1_score Results on the Validation Data \")\nplt.suptitle(\"The Results of on the Validation data \")","922d86fc":"from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\nprint(\"The confusion Matrix of The Performance of the classifieres on the Validation data\")\ncm1=ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_vald,yhat),display_labels=['not_interested','interested'])\ncm1.plot()\nplt.title(\"The confusion Matrix of SVM\")\ncm2=ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_vald,yrf),display_labels=['not_interested','interested'])\ncm2.plot()\nplt.title(\"The confusion Matrix of Random Forest\")\ncm3=ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_vald,yada),display_labels=['not_interested','interested'])\ncm3.plot()\nplt.title(\"The confusion Matrix of Ada Boost\")\ncm4=ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_vald,yknn),display_labels=['not_interested','interested'])\ncm4.plot()\nplt.title(\"The confusion Matrix of KNN\")","a09c2779":"yhat1=best.predict(x_test)\nyrf1=rf.predict(x_test)\nyada1=ada.predict(x_test)\nyknn1=knn.predict(x_test)","ff426c8f":"results1=pd.DataFrame({\"Classifier\":['SVM','RF','ADA','KNN'],\"Accuracy_test\":[accuracy_score(y_test,yhat1),accuracy_score(y_test,yrf1),accuracy_score(y_test,yada1),accuracy_score(y_test,yknn1)]\n                     ,\"f1_score_test\":[f1_score(y_test,yhat1),f1_score(y_test,yrf1),f1_score(y_test,yada1),f1_score(y_test,yknn1)]})\nresults1","679d4787":"print(\"The confusion Matrix of The Performance of the classifieres on the test data\")\ncm1=ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test,yhat1),display_labels=['not_interested','interested'])\ncm1.plot()\nplt.title(\"The confusion Matrix of SVM\")\ncm2=ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test,yrf1),display_labels=['not_interested','interested'])\ncm2.plot()\nplt.title(\"The confusion Matrix of Random Forest\")\ncm3=ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test,yada1),display_labels=['not_interested','interested'])\ncm3.plot()\nplt.title(\"The confusion Matrix of Ada Boost\")\ncm4=ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test,yknn1),display_labels=['not_interested','interested'])\ncm4.plot()\nplt.title(\"The confusion Matrix of KNN\")","75bafc3c":"## Hyperparameters Tuning ","239f02e2":"## The Performance on the test set \n","70fbb6d4":"## Model Selection\nBased on the Model Performance on both the validation and test set, the svm and knn did not perform well in terms of accuracy and f1_score. On the other hand, the results of the adaboost and random forest were significantly high on both but according to the confusion matrix, the random forest miscalssified points on the two classes were less than those of the adaboost which makes it the final model that will be used in building the system.","6ba4942b":"As it can be infered from the above chart, the data is biased towards one class,`class 0` So, the model should be evaluated using the F Score. "}}