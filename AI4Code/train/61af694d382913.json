{"cell_type":{"7193605c":"code","a2a57ffa":"code","2b9d8506":"code","722ff929":"code","c37c264a":"code","f83574cf":"code","cf4155fd":"code","18c9741a":"code","71cedb64":"markdown","bc363afc":"markdown","f25ffb71":"markdown","22f7e8b2":"markdown","e30f2e80":"markdown","4e78d55d":"markdown","6e6254b5":"markdown"},"source":{"7193605c":"from tensorflow.keras import backend as K\nfrom tensorflow.keras import layers as L\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3","a2a57ffa":"K.clear_session()\n\ninput_tensor = L.Input(shape=(299,299,3))\ninception = InceptionV3(include_top=False, # leaves out the classifier end\n                        input_shape=(299,299,3),\n                        pooling=None) # leaves out flattening\/global pooling at end\noutput = inception(input_tensor)\nmodel = Model(input_tensor,output) # as of this moment, this network's shapes are locked.\nmodel.summary()","2b9d8506":"K.clear_session()\n\ninput_tensor = L.Input(shape=(96,96,3))\ninception = InceptionV3(include_top=False,\n                        input_shape=(96,96,3),\n                        pooling=None)\noutput = inception(input_tensor)\nmodel = Model(input_tensor,output)\nmodel.summary()","722ff929":"K.clear_session()\n\ninput_tensor = L.Input(shape=(123,666,3))\ninception = InceptionV3(include_top=False,\n                        input_shape=(123,666,3),\n                        pooling=None)\noutput = inception(input_tensor)\nmodel = Model(input_tensor,output)\nmodel.summary()","c37c264a":"K.clear_session()\n\ninception = InceptionV3(include_top=False,\n                        input_shape=(299,299,3),\n                        pooling=None)\n\nplot_model(inception)","f83574cf":"inception.summary()","cf4155fd":"K.clear_session()\n\ninception = InceptionV3(include_top=False,\n                        input_shape=(256,256,3),\n                        pooling=None)\ninception.summary()","18c9741a":"K.clear_session()\n\ninput_tensor = L.Input(shape=(299,299,3))\ninception = InceptionV3(include_top=False,\n                        input_shape=(299,299,3),\n                        pooling=None) # or make it 'avg' or 'max' and remove global pooling layer\nx = inception(input_tensor)\nx = L.GlobalMaxPooling2D()(x)\nx = L.Dense(1024,activation='relu')(x)\nx = L.Dense(69,activation='softmax',name='predictions_yayyy')(x)\n\nmodel = Model(input_tensor,x)\n\ndisplay(model.summary())\ndisplay(plot_model(model))","71cedb64":"## Input shape: (123,666,3)\nI'm only doing 3 channel inputs because Keras Applications only supports 3 channel input. If you code the inception network yourself, you can make it whatever you please.","bc363afc":"## Ok, now what?\nYou already know this part, but here it is anyway, for a complete mental picture.","f25ffb71":"## Fully exploded examples:\nbetween these next two examples, look at the outputs. The layer-by-layer shapes are different numerically, but the same operations have been performed on them sequentially.\n\nIt will look a bit confusing, since inception networks have concatenations and whatnot going on. So, first, have a look at this visualization, so the linear format (`inception.summary()`) isn't so confusing.","22f7e8b2":"different input shape","e30f2e80":"# InceptionV3 with varying input shapes\n\nThis is to show that the inception architecture is a procedure. Notice that the output shape is relative to the input shape. At the end, I've exploded the entire network layer list, so you can see the inception procedure handling input shapes of varying size.\n\n**Be not confused!** Once a network is made, its shape is forever locked. You can only define shape when a network is created. However, you can *make* the network with whatever shapes you want (so long as they're compatible with the sequential operations of the network).","4e78d55d":"## Input shape: (96,96,3)","6e6254b5":"## Input shape: (299,299,3)"}}