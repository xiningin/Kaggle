{"cell_type":{"8eff01ff":"code","8d46c3f9":"code","abeb8f6e":"code","77f6a11c":"code","a03bd882":"code","174e2340":"code","8556c832":"code","e1dd8c83":"code","ccdbc823":"code","b8d2fa39":"code","16b4c008":"code","68c636c4":"code","ed534476":"code","54cfc73b":"code","f3d2d5e7":"code","5e7392a5":"code","39400bcb":"code","7aca9e87":"code","8fa744d9":"code","98493572":"code","55113615":"code","1968c9c1":"code","30193138":"code","1c5b7f12":"code","14018184":"code","5c63a52c":"code","2fed3ec6":"code","2f9120a5":"code","d596de24":"code","0918072b":"markdown","fc0ab07f":"markdown","475f05cd":"markdown","934b68a4":"markdown","bde1e1bb":"markdown","a98899fb":"markdown","0a07085a":"markdown","a7b86a0b":"markdown","a912db19":"markdown","1b2cbd42":"markdown","6f17fe76":"markdown","76514a3d":"markdown","440aaa21":"markdown","af170910":"markdown","c3bf395e":"markdown","a8dabc5f":"markdown","bdfb7726":"markdown","9c42fb59":"markdown","f9a994ef":"markdown"},"source":{"8eff01ff":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nfrom fastai import *\nfrom fastai.vision import *\n","8d46c3f9":"cd \/kaggle\/input\/","abeb8f6e":"ls","77f6a11c":"cp -R \/kaggle\/input\/mk0907-448\/mk0907-448 \/kaggle\/working\/","a03bd882":"cd \/kaggle\/working\/","174e2340":"ls","8556c832":"path = Path('\/kaggle\/working\/mk0907-448')\npath.ls()","e1dd8c83":"bs = 64","ccdbc823":"ds_tfms = get_transforms(flip_vert=True,max_lighting=0.2,max_zoom=1.3,max_rotate=30)","b8d2fa39":"data = ImageDataBunch.from_folder(path,ds_tfms=ds_tfms,size=448,bs=bs).normalize(imagenet_stats)","16b4c008":"data.show_batch(rows=3, figsize=(12,12))\n","68c636c4":"print(data.classes)","ed534476":"learn = cnn_learner(data, models.resnet34,metrics=accuracy)","54cfc73b":"learn.save('empty')","f3d2d5e7":"learn.load('empty')","5e7392a5":"learn.lr_find()","39400bcb":"learn.recorder.plot()","7aca9e87":"lr=1e-3\ncycle=7","8fa744d9":"learn.fit_one_cycle(cycle,lr)","98493572":"learn.save('stage1')","55113615":"learn.load('stage1')","1968c9c1":"learn.unfreeze()","30193138":"learn.lr_find()","1c5b7f12":"learn.recorder.plot()","14018184":" learn.fit_one_cycle(3,slice(1e-5,lr\/5))","5c63a52c":"learn.save('stage2')","2fed3ec6":"interp = ClassificationInterpretation.from_learner(learn)","2f9120a5":"interp.plot_confusion_matrix(dpi=120)","d596de24":"interp.plot_top_losses(4,largest=True) #moze biti i `False` da ide od najtocnijih","0918072b":"# Dataset","fc0ab07f":"# Learner","475f05cd":"Spremimo model i idemo vidjeti gdje smo fulali.\n","934b68a4":"# Interpretacija","bde1e1bb":"Spremiti cemo model, i idemo na fine tuning","a98899fb":"ovdje predajemo manji learning rate nego u treniranju glave, jer smo vec jako blizu minimuma i trazimo male pomake. `Slice` ce odrediti u kojem ce rasponu lr-a uciti. Prvi broj zelimo uzeti prije nego skoci gore funkcija na grafu, a u ovom slucaju je to `1e-5`. Drugi broj moze biti stari `lr\/5` ili stari `lr\/10`  kao neki broj koji cesto funkcionira. naravno, mozete se igrati s time. ako zelite samo testirati fine tuning, krenete od `load('stage1')`","0a07085a":"Ovdje importamo fast.ai library i podesimo parametre za grafove (nista bitno :))","a7b86a0b":"Eto nam slika da vidimo zasto. Tri su rosignole pretamne, a carbonaca je prelomljena :)\nProbajte slobodno sa drugim velicinama, mozda ce bit bolji accuracy sa 896.","a912db19":"`lr_find` pronalazi learning rate funkciju. Zelimo uzeti onaj broj gdje je nagib najveci. mozemo eksperimentirati sa * 10 vecim ili sa * 10 manjim.\n\n1e-3 znaci 0.001 \n\n10 puta veci je 0.01 ili 1e-2\n\n10 puta manji je 0.0001 ili 1e-4\n\nmozete napisati i sa tockom i sa 1e-5\n\n0.005 je onda 5e-3 ili pola izmedju 1e-2 i 1e-3","1b2cbd42":"# Masline 10.07.","6f17fe76":"Unfreeze ce nam dopustiti da treniramo i dublje slojeve Neuronske mreze, do sada smo samo trenirali \"Glavu\". iliti zadnjih par slojeva.","76514a3d":"Learner je objekt koji ce vrsiti treniranje za nas. Njemu predajemo `data` koji sadrzi nase slike, model koji je vec istreniran `(models.resnet50, models.resnet34, models.resnet100)`. Broj nakon resneta govori koliko ima slojeva model koji mi koristimo.\n`metrics` ne utjece na treniranje, nego nam ispisuje koliko smo uspjesni. npr ako stavimo `error_rate` dobiti cemo postotak greske, a sada imamo `accuracy` koji kaze postotak uspjeha.","440aaa21":"Provjerimo je li zaista kopiran. ","af170910":"[](http:\/\/)Kopiramo folder sa 448 velicinom iz input foldera koji je ReadOnly u working folder. \n\nAko se zelite igrati sa folderima i navigirati, ovo su komande:\n`cd \/ime` ulazi u folder `ime`\n`cd ..` ide jedan folder nazad\n`cd \/` ide u `root` folder ili prvi folder na disku\n`cd \/kaggle\/working\/` ce otici u kaggle working\n`ls` ce ispisati sve foldere u folderu u kojem jeste.\n\nako odemo u input folder, vidimo koje sve velicine dataseta imamo\n","c3bf395e":"Idemo inicijalizirati neke parametre sa kojima se mozemo igrati.\n\n`bs` je batch size. On utvrdjuje koliko uzimamo slika u isto vrijeme u graficku kartu. Ako budemo radili sa slikama vece rezolucije, mozda cemo trebati smanjiti sa 64\n`ds_tfms` su transformacije koje se primjenjuju na slike.\n`size` je velicina slika ","a8dabc5f":"spremimo u `path` varijablu put do naseg odabranog foldera. tako da kada god zelimo koristiti taj folder opet, samo pozovemo path.\nna path isto mozemo pozivati ls() da vidimo sta ima u tom folderu.","bdfb7726":"Spremimo prazan model, tako da ako ikada zelimo ici ispocetka, samo pokrenemo `learn.load(empty)`","9c42fb59":"`data` je varijabla u koju spremamo nas inicijalizirani dataset. Posto radimo transfer learning na modelu koji je vec istreniran na imagenet slikama i poznaje puno razlicitih objekata, moramo primjeniti iste tonove na nase slike (npr, da je zelena boja kod nas ista zelena kao i kod njih)\n\n`data.show_batch` ce nam pokazati par slika iz naseg novog dataseta","f9a994ef":"s ovim se mozete igrati i mijenjati. krenete od `empty` i vidite kako vam baca drugaciji accuracy za razlicite lrove, i za razliciti broj ciklusa\nsto je veci lr (a veci je ako je manji broj poslije minusa 1e-3 < 1e-2 :)) to nam brze ide ucenje. sada nam kroz 7 ciklusa dodje na preko 90%. probajte se igrati sa lr-om, da u manje ciklusa dodjete do 95."}}