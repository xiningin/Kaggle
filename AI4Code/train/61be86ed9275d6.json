{"cell_type":{"58ef2725":"code","38905a83":"code","bfa293e3":"code","76e2d4a8":"code","0e21101d":"code","54517ca3":"code","24fd98f7":"code","32068f18":"code","d131a55c":"code","c3695319":"code","fca14df0":"code","4cf628f9":"code","eb699c69":"code","be83d263":"code","24a97896":"code","e0b889fb":"code","6d61779b":"code","12131643":"code","d411266f":"code","d50c6f26":"code","ce66c996":"code","ae38e440":"code","19eaa437":"code","3d846529":"code","e6434494":"code","0758e111":"code","7483ab83":"code","ddf87bb0":"code","28d9ba8a":"code","58c1c21b":"markdown","5b51eec1":"markdown","124f8989":"markdown","ecbd1a45":"markdown","8864d6ff":"markdown","4e93afb9":"markdown","45db4809":"markdown","c939dc2c":"markdown","948dc42f":"markdown","96cfdeb9":"markdown","fa558de1":"markdown","ca32c8d9":"markdown","73c89642":"markdown","92ecdf79":"markdown","c5893269":"markdown","5bb1c229":"markdown","03da77b1":"markdown","8ba35a3a":"markdown","cb265c86":"markdown","c14f27c1":"markdown","e58b74b0":"markdown","b0b142d1":"markdown","b75b5a68":"markdown","1f8c2bf7":"markdown","c8046778":"markdown"},"source":{"58ef2725":"#!pip install sparkmagic\n#!pip install pyspark","38905a83":"import numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport scipy\n\nfrom plotnine import * # used to plot data\n\n# progress bar\nfrom tqdm import tqdm","bfa293e3":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","76e2d4a8":"os.listdir('\/kaggle\/')","0e21101d":"def  file_to_dataframe(file):\n    # this file is transposed of what we expect in a pandas dataframe\n    # therefore we import the file and transpose it\n    df = pd.read_csv(file,sep=\"\\t\",dtype=object,header=None).T\n\n    # now we can set the header\n    header = df.iloc[0] #grab the first row for the header\n    df = df[1:] #take the data less the header row\n    df.columns = header #set the header row as the df header\n\n    return(df)","54517ca3":"abundance_full_df = file_to_dataframe(\"\/kaggle\/input\/metagenomics\/abundance.txt\")\nabundance_full_df.head()","24fd98f7":"# get the shape of the data frame\nprint(abundance_full_df.shape)\n# are the columns all unique?\nprint(len(abundance_full_df.columns.unique()))","32068f18":"for i in range(0,len(abundance_full_df.columns)):\n    print (\"%i. %s\" % (i, abundance_full_df.columns[i]))","d131a55c":"len(abundance_full_df.iloc[:,0:211].drop_duplicates())","c3695319":"if not \"abundance_id\" in abundance_full_df.columns:\n    abundance_meta_cols= list(abundance_full_df.columns[0:211])\n    abundance_full_df.reset_index(inplace=True)\n    abundance_full_df.rename(columns={'index': 'abundance_id'}, inplace=True)\n    abundance_meta_df = abundance_full_df.iloc[:,0:212].copy()\n    abundance_matrix_df = abundance_full_df.copy()\n    abundance_matrix_df = abundance_matrix_df.drop(abundance_meta_cols,axis=1)","fca14df0":"abundance_stoolsubset_full_df = file_to_dataframe(\"\/kaggle\/input\/metagenomics\/abundance_stoolsubset.txt\")\nprint(abundance_stoolsubset_full_df.shape)\nabundance_stoolsubset_full_df.head()","4cf628f9":"for i in range(0,len(abundance_stoolsubset_full_df.columns)):\n    print (\"%i. %s\" % (i, abundance_stoolsubset_full_df.columns[i]))","eb699c69":"if not \"abundance_id\" in abundance_stoolsubset_full_df.columns:\n    abundance_stoolsubset_meta_cols= list(abundance_stoolsubset_full_df.columns[0:211])\n    for i in range(0,211):\n        if abundance_stoolsubset_meta_cols[i] != abundance_stoolsubset_meta_cols[i]:\n            print(\"FOUND A MISMATCH\")\n            print (abundance_meta_cols[i])\n            print (abundance_stoolsubset_meta_cols[i])","be83d263":"if not \"abundance_ss_id\" in abundance_stoolsubset_full_df.columns:\n    abundance_stoolsubset_full_df.reset_index(inplace=True)\n    abundance_stoolsubset_full_df.rename(\n        columns={'index': 'abundance_ss_id'}, inplace=True)\nabundance_stoolsubset_meta_df = abundance_stoolsubset_full_df.iloc[:,0:212].copy()\nabundance_stoolsubset_matrix_df = abundance_stoolsubset_full_df.copy().drop(\n        abundance_stoolsubset_meta_cols,axis=1)","24a97896":"print(\"length if no duplicates\")\na=len(abundance_stoolsubset_meta_df)+ len(abundance_meta_df)\nprint(a)\nprint(\"length of merged dataframes after dropping duplicates\")\nb=len(pd.concat([abundance_stoolsubset_meta_df.drop(\"abundance_ss_id\", axis=1),\n                 abundance_meta_df.drop(\"abundance_id\", axis=1)]).drop_duplicates())\nprint(b)\nprint(\"number of duplicates\")\nprint(a-b)","e0b889fb":"if not \"abundance_ss_id\" in abundance_meta_df.columns:\n    abundance_meta_df=abundance_meta_df.merge(\n        abundance_stoolsubset_meta_df, how='left', \n        on=abundance_stoolsubset_meta_cols)\nabundance_meta_df.head()","6d61779b":"for col in list(abundance_stoolsubset_matrix_df.columns)[1:]:\n    if not col in list(abundance_matrix_df.columns)[1:]:\n        print (col)","12131643":"# get rows from abundance_df that match abundance_stoolsubset_df\nmatch_id_list = list(\n    abundance_meta_df.loc[abundance_meta_df[\"abundance_ss_id\"].notnull(),\"abundance_id\"])\nfeatures = list(abundance_stoolsubset_full_df.columns)[1:]\ncompare_abundance_df= abundance_full_df.loc[(\n    abundance_full_df[\"abundance_id\"].isin(match_id_list)),features].copy()\ncompare_abundance_df= compare_abundance_df.reset_index(drop=True)\nprint(compare_abundance_df.shape)\n\n# drop the abundance_ss_id from abundance_stoolsubset_df\ncompare_abundance_stoolsubset_df = abundance_stoolsubset_full_df.copy().drop(\"abundance_ss_id\", axis=1)\nprint(compare_abundance_stoolsubset_df.shape)","d411266f":"# sort\ncompare_abundance_df.sort_values(\n    by=abundance_stoolsubset_meta_cols,\n    inplace=True, ignore_index=True)\ncompare_abundance_stoolsubset_df.sort_values(\n    by=abundance_stoolsubset_meta_cols,\n    inplace=True, ignore_index=True)\nprint(compare_abundance_stoolsubset_df.shape)\nprint(compare_abundance_df.shape)","d50c6f26":"compare_abundance_stoolsubset_df.equals(compare_abundance_df)","ce66c996":"import gc\n#delete when no longer needed\ndel compare_abundance_stoolsubset_df\ndel compare_abundance_df\ndel abundance_full_df\ndel abundance_stoolsubset_full_df\ndel abundance_stoolsubset_matrix_df\ndel abundance_stoolsubset_meta_df\nabundance_meta_df.drop(\"abundance_ss_id\",axis=1)\n#collect residual garbage\ngc.collect()","ae38e440":"marker_presence_path=\"\/kaggle\/input\/metagenomics\/marker_presence.txt\"","19eaa437":"marker_presence_top_df = pd.read_csv(marker_presence_path, \n                                      sep=\"\\t\", nrows=1000, dtype=object, \n                                      header=None).T\n# now we can set the header\nheader = marker_presence_top_df.iloc[0] #grab the first row for the header\nmarker_presence_top_df = marker_presence_top_df[1:] #take the data less the header row\nmarker_presence_top_df.columns = header #set the header row as the df header","3d846529":"print(marker_presence_top_df.shape)\nmarker_presence_top_df.head()","e6434494":"for col in range(0,len(marker_presence_top_df.columns)):\n    print(\"%i. %s\" % (col,marker_presence_top_df.columns[col]))","0758e111":"marker_presence_top_matrix = (\n    scipy.sparse.csr_matrix(\n        marker_presence_top_df.iloc[:,range(211,1000)].astype('float64').values))","7483ab83":"%%time\n\nmarker_presence_matrix_file = \"\/kaggle\/input\/starter-metagenomics\/marker_presence_matrix.npz\"\n\nif not os.path.isfile(marker_presence_matrix_file):\n    nfeatures=288558\n    for i in range(1000,288558,1000):\n        skip_rows=int(1000 *(i\/1000))\n\n        marker_presence_sub_df = pd.read_csv(marker_presence_path, \n                                                    sep=\"\\t\", skiprows=skip_rows, \n                                                    nrows=1000, dtype=object, \n                                                    header=None).T\n        # now we can set the header\n        header = marker_presence_sub_df.iloc[0] #grab the first row for the header\n        marker_presence_sub_df = marker_presence_sub_df[1:] #take the data less the header row\n        marker_presence_sub_df.columns = header #set the header row as the df header\n        #print(list(marker_presence_sub_df.columns))\n        marker_presence_sub_matrix = (\n            scipy.sparse.csr_matrix(\n                marker_presence_sub_df.astype('float64').values))\n        marker_presence_top_matrix = (\n            scipy.sparse.hstack([marker_presence_top_matrix, marker_presence_sub_matrix]))\n        if (i%10000 == 0):\n            print((\"%.4f%%\")%((marker_presence_top_matrix.shape[1]+210)\/nfeatures))\n\n    scipy.sparse.save_npz(marker_presence_matrix_file, marker_presence_top_matrix)\nelse:\n    marker_presence_top_matrix = scipy.sparse.load_npz(marker_presence_matrix_file)\n    scipy.sparse.save_npz(marker_presence_matrix_file, marker_presence_top_matrix)","ddf87bb0":"marker_presence_top_matrix.shape","28d9ba8a":"# Opening file\nfile1 = open('\/kaggle\/input\/markers2clades_DB.txt', 'r')\n \n# Using for loop to process the file line by line\nmarkers2clades_dict={}\nfor line in file1:\n    line_arr = line.split(\"\\t\")\n    markers2clades_dict[line_arr[0]]=line_arr[1]\n \n# Closing files\nfile1.close()","58c1c21b":"Once again the first 210 columns are meta-data and the rest of the columns (including the ones not shown) are most likely marker data.\n\nWe noticed the values in the columns after the first 210 columns can be put into a sparse matrix.","5b51eec1":"There are 3610 samples with **unique** 3513 features. ","124f8989":"Yes they are the same, let's split this file into a meta table and an abundance matrix.","ecbd1a45":"using hstack we can then add the other features in the file by adding them to the sparse matrix.","8864d6ff":"### Abundance stoolsubset table\n\n**Spoiler Alert**: this file is trash and COMPLETELY useless.\n\nThe `abundance_stoolsubset.txt` file contains relative abundances for each sample.","4e93afb9":"## Introduction\nThis notebook was created to explore the meta-genomics data on kaggle. The link to the data-set is: https:\/\/www.kaggle.com\/antaresnyc\/metagenomics.","45db4809":"Let's first look at the first 1000 rows","c939dc2c":"This looks very similar to the \"abundance.txt\" file except is seems to have less columns. Is it the same?","948dc42f":"we can merge these meta-tables.","96cfdeb9":"It looks like **ALL** the samples in the \"abundance_stoolsubset.txt\" file match samples in the \"abundance.txt\" file. ","fa558de1":"Indeed there are again 210 meta-data columns, but are they the same?","ca32c8d9":"To save on compute time I want to split this table into two.\nI put the first 210 columns in a dataframe called \"adundance_meta_df\". Then I kept the abundance matrix in the \"abundance_df\" object. If I ever want to rejoin these tables I would use the \"abundance_id\" column.","73c89642":"### Marker Presence table\nThe `marker_presence.txt` file contains the presence of strain-specific markers. It is 288,558 rows (features) x 3,611 columns (samples). However, ideally it would be transposed.","92ecdf79":"use the meta table to find if this file contains extra samples or some of the same ones as found in the abundance.txt file?","c5893269":"WHAT A COMPLETE WASTE OF TIME!","5bb1c229":"### Abundance table\nThe `abundance.txt` file contains relative abundances for each sample.","03da77b1":"## Data\nThe current version of the dataset contains the following tab-delimited files","8ba35a3a":"Are the values the same?","cb265c86":"The features in the columns match those in abundance_matrix_df...","c14f27c1":"Note this file is large so we should delete unnecessary objects from memory","e58b74b0":"# Exploratory Analysis\n## Install Spark\nUncommet the code below to install PySpark and sparkmagic.","b0b142d1":"\n## Libraries\nTo begin this exploratory analysis, first import the main libraries.","b75b5a68":"The tables for the dataset are the transpose of what we want. Therefore I created this function to import the tables.","1f8c2bf7":"It looks like the first 210 columns include meta-data about the sample. They are most likely to be categorical variables. The rest of the columns include the actual abundance data.","c8046778":"### Marker2Clades DB\nThe `markers2clades_DB.txt` file contains a lookup table to associate each marker identifier to the corresponding species."}}