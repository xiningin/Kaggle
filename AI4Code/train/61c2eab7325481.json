{"cell_type":{"9a5b7754":"code","983f7e7c":"code","1889093b":"code","0b215b6c":"code","bfd10e26":"code","b1b4208a":"code","f97e66b7":"code","8645650f":"code","74e6f706":"code","885cf420":"code","1de0c42d":"code","94c27e09":"code","bc35ac52":"code","0fe8f994":"code","b93fab8f":"code","610df921":"code","ae2061ef":"code","d07b4fb3":"code","a077a710":"code","b9a21cc7":"code","788e2a43":"code","5a1f95ba":"code","73ce8995":"code","820fef15":"code","118c547e":"code","13bb3999":"code","9de1f5f5":"code","ba721931":"code","6f835e51":"code","94cc8edd":"code","a3f34226":"code","ecbf8068":"code","a6198cd3":"code","1bd11bd8":"code","c4573b65":"code","c970a358":"code","21fa2cce":"code","e5efa0f2":"code","33c45b51":"code","f77ce07d":"code","f667a1d4":"code","0f35c8c5":"code","5b9590e8":"code","ec113b6f":"code","b095a80a":"code","ccc78f62":"code","a5bb43a4":"code","602356eb":"code","ffda1f33":"code","28850918":"code","c9bc4a18":"code","924c2ff2":"code","b29bfdc5":"code","9ed586cc":"code","ae92fc44":"code","6470e8e3":"code","51b979dd":"code","bfeddf1c":"code","ce3491b9":"code","d66750c6":"code","8e5c8b08":"code","234847a2":"code","5a684a9f":"code","9e9a126d":"code","d334d181":"code","144bd2f0":"code","2b580a7b":"code","007e9954":"code","ae5f44ca":"code","9d389b15":"code","c5f58380":"code","c3375a0e":"code","474d9e5b":"code","421e96fc":"code","ce85f8df":"code","69631daa":"code","05690f44":"code","1d75b958":"code","583ca411":"code","3b691abf":"code","ecc157e4":"code","ef322753":"code","ac07745c":"code","4a588467":"code","97997804":"code","6e8ab7b3":"code","812f33ad":"code","b6bab76d":"markdown","c43de847":"markdown","32167594":"markdown","e8faffef":"markdown","3678c29c":"markdown","d25fe9c8":"markdown","ce587860":"markdown","546412d6":"markdown","0fce5136":"markdown","ab914275":"markdown","95eb1ee3":"markdown","efe80f73":"markdown","53e964c8":"markdown","8583c1ea":"markdown","c3a7657b":"markdown","3e0c12ba":"markdown","ce9deb91":"markdown","184c03c5":"markdown","1a8551e9":"markdown","4c9b4997":"markdown","0f86ce3a":"markdown","2d049115":"markdown","b9234f1e":"markdown","d88557f0":"markdown","8e1ab3fe":"markdown","53006f0a":"markdown","c787092a":"markdown","d9f93d13":"markdown","a8133689":"markdown","c57eeb61":"markdown","299de333":"markdown","d08d34a9":"markdown","87dd65a8":"markdown","d5233c2c":"markdown","1a383902":"markdown","81d8e9f7":"markdown","1bac4feb":"markdown","1b332c8d":"markdown","191f0cb6":"markdown","66c4373e":"markdown"},"source":{"9a5b7754":"import numpy as np#library for numerical computations\nimport pandas as pd#DataFrame Library\nimport matplotlib.pyplot as plt#for plotting images","983f7e7c":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1889093b":"train_df = pd.read_csv('\/kaggle\/input\/emnist\/emnist-letters-train.csv', header=None) #import train dataset","0b215b6c":"print(train_df.shape)\ntrain_df.head()","bfd10e26":"X_train = train_df.loc[:,1:].to_numpy()\ny_train = train_df.loc[:,0].to_numpy()\n\nX_train.shape, y_train.shape","b1b4208a":"label_map = pd.read_csv(\"..\/input\/emnist-lettermapping2\/emnist-letters-mapping2.txt\", delimiter = ' ', index_col=0,header=None, squeeze=True)\nlabel_dict = {}\nfor index, label in enumerate(label_map):\n    label_dict[index] = chr(label)","f97e66b7":"label_dict","8645650f":"W = 28\nH = 28\n#Sample entry\nsample_image = X_train[42] #Select sample image\nsample_label = y_train[42] #Select equivalent label\/target\nprint(sample_image.shape,sample_label)\n\nprint(\"Label entry 42: \", label_dict[sample_label]) #convert label to alphabet based on label_dict\nplt.imshow(sample_image.reshape(W,H), cmap = plt.cm.gray)\nplt.show()","74e6f706":"def reshape_rotate_v(image):\n    W = 28\n    H = 28\n    image = image.reshape(W,H)#Reshape image to enable it to be read as image\n    image = np.fliplr(image)#Flip image\n    image = np.rot90(image)#rot 90\n    image = image.reshape(1,784)#reshape back to feature vector that can be used in algorithm\n    #image = image.reshape(W,H)\n    return image","885cf420":"print(\"Label entry 42:\", label_dict[sample_label])\nplt.imshow(reshape_rotate_v(sample_image).reshape(W,H), cmap=plt.cm.gray)\nplt.show()","1de0c42d":"#Apply the reshape_rotate to all the images on the dataset\nX_train_img2 = np.apply_along_axis(reshape_rotate_v, 1, X_train)","94c27e09":"X_train_img2.shape #check shape","bc35ac52":"X_train_img22 = X_train_img2.reshape(88800, 784) #reshape again for proper use in the algorithm\nX_train_img22[1121]","0fe8f994":"rows = 15 # defining no. of rows in figure\ncols = 16 # defining no. of colums in figure\n\nf = plt.figure(figsize=(1.5*cols,1.5*rows)) # defining a figure \n\nfor i in range(rows*cols): \n    f.add_subplot(rows,cols,i+1) # adding sub plot to figure on each iteration\n    plt.imshow(X_train_img22[i].reshape([28,28]),cmap=plt.cm.gray) \n    plt.axis(\"off\")\n    plt.title(label_dict[y_train[i]], y=-0.15,color=\"green\")\nplt.savefig(\"letters.png\")","b93fab8f":"test_df = pd.read_csv('..\/input\/emnist\/emnist-letters-test.csv',header=None)#Read\ntest_df.head()","610df921":"test_df.shape","ae2061ef":"X_test = test_df.loc[:,1:].to_numpy()\ny_test = test_df.loc[:,0].to_numpy()","d07b4fb3":"X_test_2 = np.apply_along_axis(reshape_rotate_v, 1, X_test)","a077a710":"X_test_2.shape","b9a21cc7":"X_test2 = X_test_2.reshape(14800, 784)","788e2a43":"#Sample entry \nsample_image = X_test2[12100]\nsample_label = y_test[12100]\nsample_image.shape, sample_label\n\nprint(\"Label entry 42:\", label_dict[sample_label])\nplt.imshow(sample_image.reshape(W,H), cmap=plt.cm.gray)\nplt.show()","5a1f95ba":"X_test2.shape, y_test.shape","73ce8995":"import tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import utils","820fef15":"from tensorflow.keras.layers import Dense","118c547e":"X_train_nn = X_train_img22.astype('float32')\/255\nX_test_nn = X_test2.astype('float32')\/255","13bb3999":"X_train_nn.shape","9de1f5f5":"num_classes = 26\ny_train_nn = utils.to_categorical(y_train-1, num_classes)\ny_test_nn = utils.to_categorical(y_test-1, num_classes)\nnum_pixels = X_test2.shape[1]\nnum_classes = y_train_nn.shape[1]","ba721931":"num_classes, num_pixels","6f835e51":"ann_model = tf.keras.Sequential()\nann_model.add(Dense(num_pixels, kernel_initializer='normal', activation='relu', input_shape=(784,)))\nann_model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\nann_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","94cc8edd":"ann_model.output_shape","a3f34226":"ann_model.fit(X_train_nn, y_train_nn, validation_data=(X_test_nn,y_test_nn), epochs=10, batch_size=200, verbose=2)","ecbf8068":"score = ann_model.evaluate(X_test_nn, y_test_nn, verbose = 0)\nprint('Test loss: ', score[0])\nprint('Test Accuracy:: ', score[1])","a6198cd3":"ann_model_json = ann_model.to_json()\nwith open(\"ann_model.json\", \"w\") as json_file:\n    json_file.write(ann_model_json)\n# serialize weights to HDF5\nann_model.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")","1bd11bd8":"ann_model2 = tf.keras.Sequential()\nann_model2.add(Dense(200, kernel_initializer='normal', activation='relu', input_shape=(784,)))\nann_model2.add(Dense(100, kernel_initializer='normal', activation='relu'))\nann_model2.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\nann_model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","c4573b65":"ann_model2.output_shape","c970a358":"history2 = ann_model2.fit(X_train_nn, y_train_nn, validation_data=(X_test_nn,y_test_nn), epochs=10, batch_size=200, verbose=2)","21fa2cce":"score2 = ann_model2.evaluate(X_test_nn, y_test_nn, verbose=2)\nprint('Test loss: ', score2[0])\nprint('Test Accuracy:: ', score2[1])","e5efa0f2":"ann_model2.summary()","33c45b51":"ann_model_json = ann_model2.to_json()\nwith open(\"ann_model2.json\", \"w\") as json_file:\n    json_file.write(ann_model_json)\n# serialize weights to HDF5\nann_model2.save_weights(\"model2.h5\")\nprint(\"Saved model to disk\")","f77ce07d":"ann_model3 = tf.keras.Sequential()\nann_model3.add(Dense(200, kernel_initializer='normal', activation='relu', input_shape=(784,)))\nann_model3.add(Dense(100, kernel_initializer='normal', activation='relu'))\nann_model3.add(Dense(90, kernel_initializer='normal', activation='relu'))\nann_model3.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\nann_model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","f667a1d4":"history3 = ann_model3.fit(X_train_nn, y_train_nn, validation_data=(X_test_nn,y_test_nn), epochs=10, batch_size=200, verbose=2)","0f35c8c5":"score3 = ann_model3.evaluate(X_test_nn, y_test_nn, verbose=3)\nprint('Test loss: ', score3[0])\nprint('Test Accuracy:: ', score3[1])","5b9590e8":"ann_model3.summary()","ec113b6f":"ann_model3.get_config()","b095a80a":"ann_model_json = ann_model3.to_json()\nwith open(\"ann_model3.json\", \"w\") as json_file:\n    json_file.write(ann_model_json)\n# serialize weights to HDF5\nann_model3.save_weights(\"model3.h5\")\nprint(\"Saved model to disk\")","ccc78f62":"test_images = X_test_nn[13213:13217]\ntest_images = test_images.reshape(test_images.shape[0],28,28)\nprint(\"[INFO] test images shape - {}\".format(test_images.shape))\n\nfor i, test_image in enumerate(test_images, start=1):\n    org_image = test_image\n    test_image = test_image.reshape(1,784)\n    predd = np.argmax(ann_model3.predict(test_image), axis=1)\n    \n    print(\"[INFO] I think the letter is - {}\".format(label_dict[predd[0]+1]))\n    plt.subplot(220+i)\n    plt.imshow(org_image, cmap=plt.cm.gray)\n    \nplt.show()","a5bb43a4":"ann_model4 = tf.keras.Sequential()\nann_model4.add(Dense(512, kernel_initializer='normal', activation='relu', input_shape=(784,)))\nann_model4.add(Dense(256, kernel_initializer='normal', activation='relu'))\nann_model4.add(Dense(100, kernel_initializer='normal', activation='relu'))\nann_model4.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\nann_model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","602356eb":"history4 = ann_model4.fit(X_train_nn, y_train_nn, validation_data=(X_test_nn,y_test_nn), epochs=10, batch_size=200, verbose=2)","ffda1f33":"score4 = ann_model4.evaluate(X_test_nn, y_test_nn, verbose=1)\nprint('Test loss: ', score4[0])\nprint('Test Accuracy:: ', score4[1])","28850918":"ann_model_json = ann_model4.to_json()\nwith open(\"ann_model4.json\", \"w\") as json_file:\n    json_file.write(ann_model_json)\n# serialize weights to HDF5\nann_model4.save_weights(\"model4.h5\")\nprint(\"Saved model to disk\")","c9bc4a18":"import os\nos.environ[\"PATH\"] += os.pathsep + 'C:\/Program Files (x86)\/Graphviz2.38\/bin\/'","924c2ff2":"utils.plot_model(ann_model, to_file = 'model.png')","b29bfdc5":"import os\nos.system('pip install \/kaggle\/input\/kerasapplications -q')\nos.system('pip install \/kaggle\/input\/efficientnet-keras-source-code\/ -q --no-deps')","9ed586cc":"import efficientnet.keras as efn ","ae92fc44":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Input\nfrom keras.models import Model\nfrom keras import optimizers\nfrom keras.utils import np_utils\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline","6470e8e3":"X_train_cnn = X_train_nn.reshape(-1,28,28,1)\nX_test_cnn = X_test_nn.reshape(-1,28,28,1)","51b979dd":"X_train_cnn.shape, X_test_cnn.shape","bfeddf1c":"X_train_cnn1 = np.full((88800, 28, 28, 3), 0.0)\n\nfor i, s in enumerate(X_train_cnn):\n    X_train_cnn1[i] = cv2.cvtColor(s, cv2.COLOR_GRAY2RGB)","ce3491b9":"plt.imshow(X_train_cnn1[89])","d66750c6":"X_test_cnn1 = np.full((14800, 28, 28, 3), 0.0)\n\nfor i, s in enumerate(X_test_cnn):\n    X_test_cnn1[i] = cv2.cvtColor(s, cv2.COLOR_GRAY2RGB)","8e5c8b08":"X_test_cnn1.shape, X_train_cnn1.shape","234847a2":"model = efn.EfficientNetB3(weights='imagenet', include_top=False, input_tensor=Input(shape=(28, 28, 3)))","5a684a9f":"model.trainable = False #Make the model non-trainable","9e9a126d":"x=model.output","d334d181":"x = model.output\nx = Flatten()(x)\nx = Dense(1024, activation=\"relu\")(x)\nx = Dropout(0.5)(x)\npredictions = Dense(units = 26, activation=\"softmax\")(x)\ncnn_model = Model(inputs = model.input, outputs = predictions)\ncnn_model.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001),loss='categorical_crossentropy',metrics=['accuracy'])","144bd2f0":"from tensorflow.keras.layers import Dense, Input, Conv2D, MaxPooling2D, Flatten, Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l2","2b580a7b":"def initialize_weights(shape, dtype=None):\n    \n    return np.random.normal(loc = 0.0, scale = 1e-2, size = shape)\n\n# Standard loc and scale values for bias initializer\ndef initialize_bias(shape, dtype=None):\n    \n    return np.random.normal(loc = 0.5, scale = 1e-2, size = shape)","007e9954":"def convolutional_model(input_shape):\n    model = Sequential()\n    \n    model.add(Conv2D(32, (3,3), activation='relu', input_shape=input_shape,\n                   kernel_initializer=initialize_weights, kernel_regularizer=l2(2e-4)))\n    \n    model.add(MaxPooling2D())\n    \n    model.add(Dropout(0.25))\n    \n    model.add(Conv2D(32, (3,3), activation='relu', kernel_initializer=initialize_weights,\n                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n    \n    model.add(MaxPooling2D())\n    \n    model.add(Dropout(0.25))\n    \n    model.add(Conv2D(32, (3,3), activation='relu', kernel_initializer=initialize_weights,\n                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n    \n    model.add(Flatten())\n    \n    model.add(Dense(1024, activation='relu',\n                   kernel_regularizer=l2(1e-3),\n                   kernel_initializer=initialize_weights,bias_initializer=initialize_bias))\n    \n    model.add(Dense(26, activation='softmax',\n                   kernel_regularizer=l2(1e-3),\n                   kernel_initializer=initialize_weights,bias_initializer=initialize_bias))\n    return model","ae5f44ca":"cnn_model2 = convolutional_model((28,28,1))\ncnn_model2.summary()","9d389b15":"# Hyperparameters\nlr = 0.0003\nepochs = 30\nbatch_size = 128\n\noptimizer = Adam(lr)\ncnn_model2.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])","c5f58380":"cnn_history2 = cnn_model2.fit(X_train_cnn, y_train_nn, epochs=epochs, batch_size=batch_size)","c3375a0e":"score6 = cnn_model2.evaluate(X_test_cnn, y_test_nn, verbose=1)\nprint('Test loss: ', score6[0])\nprint('Test Accuracy:: ', score6[1])","474d9e5b":"cnn_model_json = cnn_model2.to_json()\nwith open(\"cnn_model2.json\", \"w\") as json_file:\n    json_file.write(cnn_model_json)\n# serialize weights to HDF5\ncnn_model2.save_weights(\"cnn_model2.h5\")\nprint(\"Saved model to disk\")","421e96fc":"# Set the CNN model \n# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n\ncnn_model3 = Sequential()\n\ncnn_model3.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\ncnn_model3.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\ncnn_model3.add(MaxPooling2D(pool_size=(2,2)))\ncnn_model3.add(Dropout(0.25))\n\n\ncnn_model3.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\ncnn_model3.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\ncnn_model3.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\ncnn_model3.add(Dropout(0.25))\n\n\ncnn_model3.add(Flatten())\ncnn_model3.add(Dense(256, activation = \"relu\"))\ncnn_model3.add(Dropout(0.5))\ncnn_model3.add(Dense(26, activation = \"softmax\"))","ce85f8df":"initial_lr = 0.001\nloss = \"categorical_crossentropy\"\ncnn_model3.compile(Adam(lr=initial_lr), loss=loss ,metrics=['accuracy'])\ncnn_model3.summary()","69631daa":"epochs = 20\nbatch_size = 256\ncnn_history3 = cnn_model3.fit(X_train_cnn, y_train_nn, epochs=epochs, batch_size=batch_size)","05690f44":"score7 = cnn_model3.evaluate(X_test_cnn, y_test_nn, verbose=1)\nprint('Test loss: ', score7[0])\nprint('Test Accuracy:: ', score7[1])","1d75b958":"cnn_model_json = cnn_model3.to_json()\nwith open(\"cnn_model3.json\", \"w\") as json_file:\n    json_file.write(cnn_model_json)\n# serialize weights to HDF5\ncnn_model3.save_weights(\"cnn_model3.h5\")\nprint(\"Saved model to disk\")","583ca411":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ndatagen.fit(X_train_cnn)","3b691abf":"from keras.callbacks import ReduceLROnPlateau\nlrr = ReduceLROnPlateau(monitor='val_accuracy',patience=2,verbose=1,factor=0.5, min_lr=0.00001)","ecc157e4":"epochs = 20\ncnn_history_3aug = cnn_model3.fit_generator(datagen.flow(X_train_cnn,y_train_nn, batch_size=batch_size),steps_per_epoch=int(X_train_cnn.shape[0]\/batch_size)+1,epochs=epochs,callbacks=[lrr])","ef322753":"2+2","ac07745c":"score8 = cnn_model3.evaluate(X_test_cnn, y_test_nn, verbose=1)\nprint('Test loss: ', score8[0])\nprint('Test Accuracy:: ', score8[1])","4a588467":"cnn_model_json = cnn_model3.to_json()\nwith open(\"cnn_model4.json\", \"w\") as json_file:\n    json_file.write(cnn_model_json)\n# serialize weights to HDF5\ncnn_model3.save_weights(\"cnn_model4.h5\")\nprint(\"Saved model to disk\")","97997804":"2+2","6e8ab7b3":"# Defining Figure\nf = plt.figure(figsize=(20,7))\nf.add_subplot(121)\n#title(\"ANN Accuracy\/Loss Curves\")\n\n#Adding Subplot 1 (For Accuracy)\nplt.plot(history4.epoch,history4.history['accuracy'],label = \"accuracy\") # Accuracy curve for training set\n\nplt.title(\"ANN Accuracy Curve\",fontsize=18)\nplt.xlabel(\"Epochs\",fontsize=15)\nplt.ylabel(\"Accuracy\",fontsize=15)\nplt.grid(alpha=0.3)\nplt.legend()\n\n\n#Adding Subplot 1 (For Loss)\nf.add_subplot(122)\n\nplt.plot(history4.epoch, history4.history['loss'],label=\"loss\") # Loss curve for training set\n\nplt.title(\"ANN Loss Curve\",fontsize=18)\nplt.xlabel(\"Epochs\",fontsize=15)\nplt.ylabel(\"Loss\",fontsize=15)\nplt.grid(alpha=0.3)\nplt.legend()\n\nplt.show()\nplt.savefig(\"ANN_accuracy_loss_curve.png\")","812f33ad":"# Diffining Figure\nf = plt.figure(figsize=(20,7))\nf.add_subplot(121)\n\n#Adding Subplot 1 (For Accuracy)\nplt.plot(cnn_history3.epoch+list(np.asarray(cnn_history_3aug.epoch) + len(cnn_history3.epoch)),cnn_history3.history['accuracy']+cnn_history_3aug.history['accuracy'],label = \"accuracy\") # Accuracy curve for training set\n\nplt.title(\"CNN Accuracy Curve\",fontsize=18)\nplt.xlabel(\"Epochs\",fontsize=15)\nplt.ylabel(\"Accuracy\",fontsize=15)\nplt.grid(alpha=0.3)\nplt.legend()\n\n\n#Adding Subplot 1 (For Loss)\nf.add_subplot(122)\n\nplt.plot(cnn_history3.epoch+list(np.asarray(cnn_history_3aug.epoch) + len(cnn_history3.epoch)),cnn_history3.history['loss']+cnn_history_3aug.history['loss'],label=\"loss\") # Loss curve for training set\n\nplt.title(\"CNN Loss Curve\",fontsize=18)\nplt.xlabel(\"Epochs\",fontsize=15)\nplt.ylabel(\"Loss\",fontsize=15)\nplt.grid(alpha=0.3)\nplt.legend()\n\nplt.show()\nplt.savefig(\"CNN_accuracy_loss_curve.png\")","b6bab76d":"#### Normalize Inputs\/One-hot code output","c43de847":"Input Layer\n\nHidden Layer 512-256-100 (relu)\n\nOutput Layer 26","32167594":"## CNN Transfer Learning","e8faffef":"### Create Label Dictionary","3678c29c":"##### Reshape_Rotate_v function","d25fe9c8":"Neural Networks generally work better when the inputs are normalized and are between 0 and 1. Therefore, to normalize the inputs, I am divide by the max. pixel value which is 255.","ce587860":"After sampling the images on the dataset, it appeared that all the images in the dataset appear wrongly after reshaping, so the function below will make the images appear properly after reshaping.","546412d6":"#### Visualizing Test Dataset","0fce5136":"### Augmentation using Keras","ab914275":"Input layer, 2 hidden layer, with 100 neurons and 90 neuros and Output layer\n    As per","95eb1ee3":"## CNN Build","efe80f73":"Below, I will be visualzing  images from X_train_img22 which will be used to train the models. It is important I do this to make sure that the images that I feed the model with are correctly aligned.\n\nTo see more images, the values in the *range()* as well as in the *subplot()* can be tweaked appropriately","53e964c8":"score5 = cnn_model.evaluate(X_test_cnn1, y_test_nn, verbose=1)\nprint('Test loss: ', score5[0])\nprint('Test Accuracy:: ', score5[1])","8583c1ea":"## HRC Notebook","c3a7657b":"## Model Training","3e0c12ba":"cnn_model_json = cnn_model.to_json()\nwith open(\"cnn_model.json\", \"w\") as json_file:\n    json_file.write(cnn_model_json)\n# serialize weights to HDF5\ncnn_model.save_weights(\"cnn_model.h5\")\nprint(\"Saved model to disk\")","ce9deb91":"# Improving Result by Image Augmentation\n\n\n### Augmentation Using Keras\n\n<hr>\n\nHere I am using the ImageDataGenerator() function of Keras for Image augmentation. Parameters to use:\n\n* **rotation_range:**   randomly rotate images in the range (degrees, 0 to 180)\n* **zoom_range:**  Randomly zoom image \n* **width_shift_range:**  randomly shift images horizontally (fraction of total width)\n* **height_shift_range:**   randomly shift images vertically (fraction of total height)\n* **horizontal_flip:**   randomly flip images (Can't be used in this case as it changes the digit)\n* **vertical_flip:**  randomly flip images (Can't be used in this case as it changes the digit)\n\n\nAfter the creation and configuration of the ImageDataGenerator, you must fit it on the data, which calculates any statistics required to perform the transformation on the data. This can be done by calling the fit() function on datagen.","184c03c5":"The code below reads the mapping file, and maps the numbers that characterises the targets(alphabets) from the datasets to the actual alphabet.\n\nSo after the mapping, 1 from the dataset is mapped to A, 2 -> B, 3 -> C, 4 -> D,... 25 -> Y, 26 -> Z","1a8551e9":"### Split train dataframe into X & y","4c9b4997":"### ANN Training","0f86ce3a":"##### ANN Model 3","2d049115":"Reshaping because for CNN's the input is an image.","b9234f1e":"Converting X_train_cnn which is currently a 1 channel image to a 3 channel image. This is because your CNN input requires a 3 channel image","d88557f0":"## CNN Model 3","8e1ab3fe":"### Import Test Dataset","53006f0a":"On examining the dataset above, I can observe that the target(y) of the data, is on the first row, hence the need to split the dataset into X_train and y_train parameters","c787092a":"##### ANN Model 2","d9f93d13":"### Model Data Preparation","a8133689":"##### Base ANN Model 1","c57eeb61":"Input layer, 2 hidden layer, with 200 neurons, 100 neurons and 90 neuros and Output layer","299de333":"# load json and create model\njson_file = open('ann_model.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nann_model = tf.keras.models.model_from_json(loaded_model_json)\n# load weights into new model\nann_model.load_weights(\"model.h5\")\nprint(\"Loaded model from disk\")","d08d34a9":"At this stage, I want to be able to view some of the images on the dataset.\n\nTo provide a correct output, I will have to reshape the image to give W = 28, H = 28. Since each image on the dataset a 28X28 pixel image","87dd65a8":"##### ANN Model 4","d5233c2c":"Flipping and rotating the images to make it conveninent for the model, as we did for the train dataset","1a383902":"### Learning Rate\n\n<hr>\n\nReduceLROnPlateau() is a callback function provided by Keras, which is used to reduce the learning rate if when a metric has stopped improving.\n\n<br>\n\n**Parameters:**\n\n* **monitor:**  takes the metric to observe (In this case val_accuracy)\n* **patience:** waits for that much epochs for the improvements, if not, then decrease the learning rate. (here `2`)\n* **factor:** factor by which the learning rate will be reduced. new_lr = lr * factor (here `0.5`)\n* **min_lr:** lower bound on the learning rate. (here `0.00001`)\n\n**Read More:**\n[Read more](https:\/\/keras.io\/callbacks\/#reducelronplateau)","81d8e9f7":"##### Visualize after Reshape_rotate_v function","1bac4feb":"#### Preview and test ANN Model 3","1b332c8d":"history_cnn = cnn_model.fit(X_train_cnn1, y_train_nn, validation_data=(X_test_cnn1,y_test_nn), epochs=50, batch_size=128,shuffle=True, verbose=2)","191f0cb6":"### Visualizing data","66c4373e":"Input layer, 1 hidden layer, with 774 neurons and Output layer"}}