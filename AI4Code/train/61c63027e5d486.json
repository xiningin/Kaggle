{"cell_type":{"46bfbe25":"code","5b97c055":"code","fd56d362":"code","770590b0":"code","4d1bab3b":"code","c4345ceb":"code","31bac11c":"code","54a75b84":"code","4d4e8f9e":"code","93318a36":"code","26a228d3":"code","5f466036":"code","62778f54":"code","8fa8aa04":"markdown","938f78b5":"markdown","884f28c4":"markdown","1e9822c2":"markdown","c118c71f":"markdown","5c56f0ef":"markdown","b24c18c5":"markdown","44d08625":"markdown","36196117":"markdown","5283486c":"markdown","c0ac431f":"markdown","dbebe614":"markdown"},"source":{"46bfbe25":"# Import general purpose packages\nimport numpy as np \nimport pandas as pd \nimport sys\nimport json\nimport os\nimport re\n\n# This is what we are using for data preparation and ML part (thanks, Rafal, for great tutorial)\nfrom sklearn.feature_extraction import text      \nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import accuracy_score\n# Different ML models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import NuSVC\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\n#Global parameters\nSONGS_PER_GENRE = 10000\nSONGS_PER_TRAINING = 1000\nSONGS_PER_TESTING = 100\n\n#we need to cleanse lyrics to remove special characters and garbage\n#this function cleanses single string\ndef cleanse (text):\n    result = re.sub('[^a-zA-Z0-9 ]', ' ', text)\n    return result\n\n","5b97c055":"partists = pd.read_csv('\/kaggle\/input\/scrapped-lyrics-from-6-genres\/artists-data.csv') #load the list of artists\npsongs = pd.read_csv('\/kaggle\/input\/scrapped-lyrics-from-6-genres\/lyrics-data.csv') #load the list of songs","fd56d362":"\n\npop_artists = partists[partists['Genre']=='Pop'] # filter artists by genre\npop_songs = pd.merge(psongs, pop_artists, how='inner', left_on='ALink', right_on='Link') #inner join of pop artists with songs to get only songs by pop artists\npop_songs = pop_songs[['Genre', 'Artist', 'SName', 'Lyric']].rename(columns={'SName':'Song'})#leave only columns of interest and rename some of them.\npop_songs = pop_songs.dropna() # Remove incomplete records, cleanse lyrics\npop_songs = pop_songs[pop_songs['Lyric']!='Instrumental'].head(SONGS_PER_GENRE).applymap(cleanse) #Remove instrumental compositions  and limit the size of final dataset\npop_songs.head()","770590b0":"#raw data\nsongs = pd.read_csv('\/kaggle\/input\/150k-lyrics-labeled-with-spotify-valence\/labeled_lyrics_cleaned.csv') #load the list of songs\nartists = pd.read_csv('\/kaggle\/input\/ultimate-spotify-tracks-db\/SpotifyFeatures.csv') #load artists by genere spotify database","4d1bab3b":"rap_artists=artists[artists['genre']=='Rap'][['genre','artist_name']].drop_duplicates() #extract only artist names and genres, deduplicate the list\nrap_songs = pd.merge(songs, rap_artists, how='inner', left_on='artist', right_on='artist_name') #inner join of rap artists with songs to get only songs by rap artists\nrap_songs = rap_songs[['genre', 'artist', 'song', 'seq']].rename(columns={'genre':'Genre', 'artist':'Artist', 'song':'Song','seq':'Lyric'}) #leave only columns of interest and rename some\nrap_songs = rap_songs.dropna().head(SONGS_PER_GENRE).applymap(cleanse) #remove incomplete records and limit dataset size\nrap_songs.head()","c4345ceb":"# since I don't need 250K songs for my analysis and I don't want to wait forever for data to load \n# I am going to build a little function, which is going to return required number of songs\ndef list_n_metal_songs (limit):\n    # intputs:\n    # limit - number of songs to return\n    # outputs:\n    # the list of file paths to songs of required length\n    counter = 1\n    result = []\n    # lets repurpose kaggle boilerplate code to obtain the list of all files with lyrics\n    for dirname, _, filenames in os.walk('\/kaggle\/input\/large-metal-lyrics-archive-228k-songs\/metal_lyrics'):\n        for filename in filenames:\n            result.append(os.path.join(dirname, filename))\n            #some really bad programming pattern here\n            if counter >= limit: return result\n            else: counter+=1\n\n# let's get limited set of songs                \nmetal_files = list_n_metal_songs(SONGS_PER_GENRE)\n\n# let's build our dataset \nartist = []\nsong = []\nlyric = []\n\n#we are going to iterate through the list of files\nfor path in metal_files:\n    # now, since the format of the path is known: <letter>\/<artist>\/<album>\/<track #>.<track name>.txt we can obtain all metadata from file path\n    p = path.split('\/')\n    s = p[8].split('.')\n    artist.append(p[6])\n    song.append(s[1].strip())\n    #we can also open and read file content\n    f = open (path, 'r')\n    lyric.append(f.read())\n    f.close()\n\n#finally, we can assemble metal songs dataset\nmetal_songs = pd.DataFrame({'Genre':'Metal', 'Artist' : artist, 'Song' : song,'Lyric' : lyric}).applymap(cleanse)\nmetal_songs.head()","31bac11c":"print(\"Pop -\",len(pop_songs), \"| Rap -\", len(rap_songs), \"| Metal -\",len(metal_songs))","54a75b84":"#prepare training dataset by taking equal scoops from each dataset\ntraining_data = pd.concat([pop_songs.head(SONGS_PER_TRAINING), rap_songs.head(SONGS_PER_TRAINING), metal_songs.head(SONGS_PER_TRAINING)])","4d4e8f9e":"#Creating vocabulary\ncv = CountVectorizer(strip_accents='ascii', lowercase=True, stop_words='english', analyzer='word') #create the CountVectorizer object\ncv.fit(training_data['Lyric'].values) #fit into our dataset\n\n#Creating bag of words representations\nbow = cv.transform(training_data['Lyric'].values) \nprint(bow.shape[0], 'samples x ',bow.shape[1],'words in vocabulary' )","93318a36":"#Create the machine learning classifier object\nmodels = {'Logistic Regression':LogisticRegression(max_iter=500), 'Linear SVC':LinearSVC(max_iter=10000),'Decision Tree': DecisionTreeClassifier(), 'Gradient Descent': SGDClassifier()}\n# things that didn't work 'Nu SVC': NuSVC(), 'SVC': SVC(), 'Naive Bayes': GaussianNB()\nfor the_model in models.keys():\n    print (\"Training\", the_model)\n    models[the_model].fit(bow.toarray(), training_data['Genre'])\n","26a228d3":"#prepare data for testing\ntest_data=pd.concat([pop_songs.iloc[SONGS_PER_TRAINING:SONGS_PER_TRAINING+SONGS_PER_TESTING], rap_songs.iloc[SONGS_PER_TRAINING:SONGS_PER_TRAINING+SONGS_PER_TESTING], metal_songs.iloc[SONGS_PER_TRAINING:SONGS_PER_TRAINING+SONGS_PER_TESTING]])\n\n#convert lyrics to bag of word representation\ntest_bow = cv.transform(test_data['Lyric'].values) ","5f466036":"#predict labels for all the sentences\naccuracy = {}\npg = test_data[['Artist', 'Song','Genre']]\nfor the_model in models.keys():\n    print(\"Evaluating\",the_model)\n    pred_genre= models[the_model].predict(test_bow.toarray())\n    pg[the_model]=pred_genre\n    accuracy[the_model]=accuracy_score(test_data['Genre'],pred_genre)\nprint (\"---Accuracy Scores---\")\nprint(accuracy)","62778f54":"#get user input\nuser_input = input()\n\n#transform it to bag of words\nuser_bow = cv.transform([cleanse(user_input)]) \n\n#run against trained models\nfor the_model in models.keys():\n    print(the_model, models[the_model].predict(user_bow))\n","8fa8aa04":"# Pop, Rap or Heavy Metal?\n## Can we tell by looking at song lyrics?\n\n| Pop | Rap | Heavy Metal |\n| :---: | :---: | :---: |\n| ![](https:\/\/imgix.ranker.com\/user_node_img\/108\/2153992\/original\/taylor-swift-recording-artists-and-groups-photo-u233?w=125&h=125&fit=crop&crop=faces&q=60&fm=pjpg) | ![](https:\/\/imgix.ranker.com\/user_node_img\/3107\/62130966\/original\/kendrick-lamar-photo-u37?w=125&h=125&fit=crop&crop=faces&q=60&fm=pjpg) | ![](https:\/\/imgix.ranker.com\/user_node_img\/88\/1742531\/original\/ozzy-osbourne-recording-artists-and-groups-photo-u41?w=125&h=125&fit=crop&crop=faces&q=60&fm=pjpg) |\n| We could leave the Christmas lights up 'til January<br>This is our place, we make the rules<br>And there's a dazzling haze, a mysterious way about you, dear<br>Have I known you twenty seconds or twenty years? |K-Dot, pick up the phone, nigga<br>Every time I call, it's going to voicemail<br>Don't tell me they got you on some weirdo rap shit, nigga?<br>No socks and skinny jeans and shit, ha<br>Call me on Shaniqua's phone! | Times have changed and times are strange<br>Here I come, but I ain't the same<br>Mama, I'm coming home<br>Times gone by seems to be<br>You could have been a better friend to me<br>Mama, I'm coming home|\n\n\n\n## Can we teach a machine to tell the difference?\nLet's give it a try!\n\n","938f78b5":"# Try it yourself!\nRun the snippet of code down below and put any piece of lyrics into the input field. The panel of artificial experts will rate your song as Pop, Rap or Metal.","884f28c4":"# Lessons Learned\n1. Data preparation is 75% of effort\n2. Data cleansing cannot be finished, it only can be stopped. I still have songs not in english and plenty of garbage in my lyrics\n2. Model selection and tune up is more an art than methodology, hence high salaries of data scientists and my low score on \"Check your understanding 5\"\n3. Every model has its own bias. Some of them lean towards Metal, some towards Rap when they cannot determine the genre. Looks funny sometimes\n4. Lengthier texts do not always provide more accurate classification\n5. More data does not guarantee better accuracy (I wonder why...)","1e9822c2":"### Rap songs\nThings are a little bit more complicated. I am going to use a dataset of lyrics and join it with tracks database from spotify to filter songs by genre.","c118c71f":"## Now let's load some data\nI am utilizing several data sets all having their unique format, while ultimately I want a dataset with just 4 columns:\n* Genre\n* Artist\n* Song title\n* Song lyrics \n\nI have to approach each data set differently.","5c56f0ef":"## Accuracy Evaluation\nLet's use the rest of the dataset to evaluate prediction accuracy","b24c18c5":"## Model training\nNow we are going to train several ML models (sounds much fancier than it is)","44d08625":"## Data preparation for analysis\nWe are going to create \"bag of words\" representation of songs in our datasets. We are going to be using ~half of each dataset for model training","36196117":"## First things first\nLet us plug in all the libraries we need and do all intial setup. We also declare global parameters here, which we are going to use during data preparation and model training.","5283486c":"### Pop songs\nI have a nice and convenient dataset here","c0ac431f":"### Summary of data load\nWe now have datasets of songs in three genres, which we can use to build genre detector","dbebe614":"### Metal songs\nThis is the hardest part of data preparation. I have a massive dataset of metal lyrics, but it is stored as text files in folder structure, so data transformation is going to be totally different."}}