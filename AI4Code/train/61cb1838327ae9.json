{"cell_type":{"87460124":"code","76701cac":"code","9301a2c0":"code","fd6a10c7":"code","48dabe18":"code","92551c15":"code","bc37cbbe":"code","08776a93":"code","87b6d4fc":"code","76f27afc":"code","c93fe4c7":"code","cbfd29be":"code","f8c90c4b":"code","8b363943":"code","724f2721":"code","37adbe01":"code","cb3847d3":"code","5fa904e1":"code","a0d372cd":"code","5d33a174":"code","69b32548":"code","f8acd815":"code","4c749849":"code","34c33ccc":"code","13b8d00d":"code","ba121b92":"code","09675daf":"code","a493dc93":"code","90235043":"code","09cb5ae7":"code","09d2ace4":"code","3acde897":"code","47935743":"code","2be3b747":"code","c96e2862":"code","64377521":"code","19266242":"code","7f87342c":"markdown","023841e9":"markdown","81f47489":"markdown","c8bbe279":"markdown","cac06177":"markdown","6794660f":"markdown","4bca2596":"markdown","b08489c8":"markdown","8ba01608":"markdown","4b28e0d2":"markdown","92723db8":"markdown","f40b3e46":"markdown","ee416485":"markdown"},"source":{"87460124":"import pandas as pd\nimport string\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport plotly.express as px\nimport math\nimport plotly.graph_objects as go\nimport plotly.io as pio\n","76701cac":"df = pd.read_csv(\"..\/input\/breast-cancer\/breast-cancer-wisconsin.csv\",)","9301a2c0":"df = df.drop(['Unnamed: 0'],axis=1)","fd6a10c7":"# checking the top 5 rows of dataframe\ndf.head()","48dabe18":"# checking the shape\ndf.shape","92551c15":"df.describe()","bc37cbbe":"df.info()","08776a93":"# Checking for the null values\ndf.isnull().sum()","87b6d4fc":"alphabet = string.ascii_letters+string.punctuation\nalphabet","76f27afc":"df['Bare Nuclei'].str.strip(alphabet).astype(bool).any()","c93fe4c7":"df.replace({'Bare Nuclei':{'?':'0'}},inplace=True)","cbfd29be":"df['Bare Nuclei'] = df['Bare Nuclei'].astype('int64')","f8c90c4b":"df.info()","8b363943":"df['Class'].unique()","724f2721":"df['Class'].value_counts()","37adbe01":"px.histogram(df,x = 'Class',color='Class')","cb3847d3":"df = df.drop(['Id'],axis=1)","5fa904e1":"corrmat = df.corr()\nf, ax = plt.subplots(figsize=(12,9))\nsns.heatmap(corrmat,annot=True);","a0d372cd":"corrmat1 = df.corr().round(2)\nmask = np.zeros_like(corrmat1,dtype = np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nf, ax = plt.subplots(figsize=(20,20))\ncmap = sns.diverging_palette(220,10,as_cmap=True)\nsns.heatmap(corrmat1,mask = mask,cmap = cmap,vmin=-1,vmax = 1,center=0,square=True,linewidths=.5,annot=True)\nplt.tight_layout()","5d33a174":"df.head(n=10).T","69b32548":"df.mean().sort_values()","f8acd815":"sns.boxplot(data = df,orient=\"h\")","4c749849":"from sklearn.model_selection import train_test_split","34c33ccc":"X = df.drop(['Class'],axis=1)","13b8d00d":"# 2 for benign and 4 for malignant\ndic = {2:0,4:1}","ba121b92":"df = df.replace({'Class':dic})","09675daf":"#0 for benign and 1 for malignant\ny = df['Class']","a493dc93":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)","90235043":"from sklearn.metrics import confusion_matrix\nimport numpy as np","09cb5ae7":"# 4 for malignant and 2 for benign\ny_test.value_counts()","09d2ace4":"def confusion(y_test,pred):\n    cm = confusion_matrix(y_test,pred)\n    print(\"Confusion Matrix : \\n\",cm)\n    \n    tn, fp, fn, tp = confusion_matrix(y_test,pred).ravel()\n    print(\"True Negative : {} \\nFalse Positive : {} \\nFalse Negative : {} \\nTrue Positive : {}\".format(tn,fp,fn,tp))\n    \n    # True positive rate also called sensitivity it is the probability that an actual positive will test positive\n    tpr = tp\/(tp+fn)\n    print(\"True Positive Rate\/Sensitivity : \",tpr)\n    \n    # True negative rate also called specificity it is the probability that an actual negative will test negative  \n    tnr = tn\/(tn+fp)\n    print(\"True Negative Rate\/Specificity : \",tnr)\n    \n    # precision or positive predictive value (PPV)\n    ppv = tp\/(tp+fp)\n    print(\"Positive Predictive Value : \",ppv)\n    \n    # negative predictive value (NPV)\n    npv = tn\/(tn+fn)\n    print(\"Negative Predictive Value : \",npv)\n    \n    # miss rate or false negative rate (FNR)\n    fnr = fn\/(fn+tp)\n    print(\"False Negative Rate : \",fnr)\n    \n    # false positive rate (FPR)\n    fpr = fp\/(fp+tn)\n    print(\"False Positive Rate : \",fpr)\n    \n    # false discovery rate (FDR)\n    fdr = fp\/(fp+tp)\n    print(\"False Discovery Rate : \",fdr)\n    \n    # false omission rate (FOR)\n    FOR = fp\/(fp+tn) \n    print(\"False Omission Rate : \",FOR)\n    \n    # accuracy (ACC)\n    acc = (tp+tn)\/(tn+tp+fn+fp)\n    print(\"Accuracy : \",acc)\n    \n    return\n ","3acde897":"import statsmodels.api as sm","47935743":"log_reg = sm.Logit(y_train,X_train).fit()","2be3b747":"log_reg.summary()","c96e2862":"pred = log_reg.predict(X_test)","64377521":"pred = list(map(round,pred))","19266242":"confusion(y_test,pred)","7f87342c":"Understanding the terminology we have used in the above function :\n1) **positive predictive value and neative predictive value** : Imagine you are a physician discussing the result of a screening test with a patient so let's consider if the test was positive how likely is it that he really **has** the disease? How worried should he be? **or** if the test was negative how likely is it he really **does not** have it?\n\n2) **False Negative Rate and False Positive Rate** : The false negative rate is the proportion of the individuals with a known positive condition for which the test result is negative. This rate is sometimes called the miss rate. The false positive rate is the proportion of the individuals with a known negative condition for which the test result is positive.\n\n3) **False Discovery Rate** : In statistics, the false discovery rate (FDR) is a method of conceptualizing the rate of [type I](https:\/\/en.wikipedia.org\/wiki\/Type_I_and_type_II_errors) errors in null hypothesis testing when conducting multiple comparisons\n\n4) **False Omission Rate** : The false omission rate is the proportion of the individuals with a negative test result for which the true condition is positive.","023841e9":"from above we can see all the count for null values is zero so there is no null values in the dataframe.","81f47489":"Now we have the model which is build using the training data and we also have the prediction of test data so now we need to measure the performance of the model for that we are using here the **Confusion Matrix**.","c8bbe279":"In this kernel tried to predict the breast cancer which is either Malignant or benign, which falls into binary classification problem type, the dataset is taken from [here](https:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/breast-cancer-wisconsin\/). From now i will continuously updating this kernel. so let's start :) \n","cac06177":"Pandas `dataframe.info()` function is used to get a concise summary of the dataframe. It comes really handy when doing exploratory analysis of the data. To get a quick overview of the dataset we use the `dataframe.info()` function","6794660f":"## Modeling ","4bca2596":"Here we define a function named **`confusion()`** which going to return us all the required derivations from confusion matrics using them we can evalute the performmance of the model we have build.","b08489c8":"see datatype has changed and we can move forward","8ba01608":"The **Bare Nuclei** column contain all the numeric value but they are having datatype `object` this may happen if there is other symbol present intead of the **NULL** values. first we find the symbol and replace it with 0 and then change the datatype to int.","4b28e0d2":"## Load Libraries","92723db8":"## Load dataset","f40b3e46":"The describe() method is used for calculating some statistical data like percentile, mean and std of the numerical values of the Series or DataFrame. It analyzes both numeric and object series and also the DataFrame column sets of mixed data types.","ee416485":"if you notice there is only one`object` datatype column we have in the dataset we need to convert it into int."}}