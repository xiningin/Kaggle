{"cell_type":{"b6a19aae":"code","a50de1b2":"code","9a8116e3":"code","28069cfd":"code","3a7246a5":"code","068ae446":"code","795f2238":"code","16ddc290":"code","5034bf34":"code","f2d379f4":"code","87f23e8a":"code","408d5ce5":"code","5b551514":"code","59d6de78":"code","58d004d7":"code","a45f32b2":"code","1ab1cea1":"code","1199643b":"code","1a448fa7":"code","e7a2663f":"code","b5c6d476":"code","b39a3937":"code","f2f7fc0b":"code","01308f5a":"code","3f3c1624":"code","cefceb35":"code","d227fe43":"code","a86519c0":"code","000fd6fa":"code","92437f46":"code","76d87d48":"code","b576432c":"code","fdf0c083":"code","6648a917":"code","6b7a5917":"code","5475b97f":"code","0e93fc04":"code","9d0fa341":"code","fa5072ba":"code","41987441":"code","c225e19e":"code","0ee3c55a":"code","06368e96":"code","964a486c":"code","d0d0637d":"code","f5b41902":"code","e88f938c":"code","af73715b":"code","a5cd342f":"code","aad3d39b":"code","f77b499a":"code","e1e83267":"markdown","22311bbe":"markdown"},"source":{"b6a19aae":"import os\nos.listdir('..\/input\/dogs-cats-images\/dataset\/training_set')","a50de1b2":"from tqdm import tqdm\nimport cv2\nimport os \n\nfeatures = []\nloc = '..\/input\/dogs-cats-images\/dataset\/training_set'\n\nfor dir in tqdm(os.listdir(loc)):\n    for img in os.listdir(os.path.join(loc,dir)):\n        im = cv2.imread(os.path.join(loc,dir,img),0)\n        im = cv2.resize(im,(60,60))\n        features.append(im)","9a8116e3":"labels = []\n\ni = 0\nfor dir in tqdm(os.listdir(loc)):\n    for img in os.listdir(os.path.join(loc,dir)):\n        labels.append(i)\n    i += 1","28069cfd":"char = []\nfor dir in tqdm(os.listdir(loc)):\n    char.append(dir)","3a7246a5":"char","068ae446":"import numpy as np\nX = np.array(features)\nX.shape","795f2238":"#Labels\nY = np.array(labels)\nY.shape","16ddc290":"import pandas as pd\nXp = pd.DataFrame(X.reshape(8000,3600))\nYp = pd.DataFrame(Y.reshape(-1,1))\nYp.columns = ['Labels']\n\ndf = pd.concat((Yp,Xp),axis=1)\ndf.head()\n\ndf.to_csv('cats_vs_dogs.csv')","5034bf34":"#Split the data into train and test\nfrom sklearn.model_selection import train_test_split\nxtrain,xtest,ytrain,ytest = train_test_split(X,Y,train_size=0.85)","f2d379f4":"print(xtrain.shape)\nprint(xtest.shape)\nprint(ytrain.shape)\nprint(ytest.shape)","87f23e8a":"xtrain = xtrain.reshape(6800,3600)\nxtrain_n = xtrain\/xtrain.max()\nxtrain.shape","408d5ce5":"xtest = xtest.reshape(1200,3600)\nxtest_n = xtest\/xtest.max()","5b551514":"from keras.utils import to_categorical\nytrain_e = to_categorical(ytrain.reshape(-1,1))\n\n\n\nytest_e = to_categorical(ytest.reshape(-1,1))","59d6de78":"ytrain_e","58d004d7":"from keras import models\nfrom keras import layers\n\nfrom keras import optimizers\nfrom keras import metrics","a45f32b2":"model = models.Sequential()\n\nmodel.add(layers.Dense(1024,activation='relu',input_dim=xtrain.shape[1]))\nmodel.add(layers.Dropout(0.4))\n\nmodel.add(layers.Dense(512,activation='relu'))\nmodel.add(layers.Dropout(0.5))\n\nmodel.add(layers.Dense(1024,activation='relu'))\nmodel.add(layers.Dropout(0.6))\n\nmodel.add(layers.Dense(256,activation='relu'))\nmodel.add(layers.Dropout(0.5))\n\nmodel.add(layers.Dense(512,activation='relu'))\nmodel.add(layers.Dropout(0.4))\n\nmodel.add(layers.Dense(256,activation='relu'))\nmodel.add(layers.Dropout(0.5))\n\nmodel.add(layers.Dense(2,activation='softmax'))","1ab1cea1":"model.summary()","1199643b":"model.compile(optimizer='sgd',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","1a448fa7":"model.fit(xtrain_n,ytrain_e,epochs=30,\n         validation_data=(xtest_n,ytest_e))","e7a2663f":"model.evaluate(xtest_n,ytest_e)","b5c6d476":"!pip install tflearn","b39a3937":"import tflearn\nfrom tflearn.layers.conv import conv_2d, max_pool_2d\nfrom tflearn.layers.core import input_data,dropout,fully_connected\nfrom tflearn.layers.estimator import regression","f2f7fc0b":"convnet = input_data(shape=[None,60,60,1] , name='input')\n\nconvnet = conv_2d(convnet,32,3,activation='relu')\nconvnet = max_pool_2d(convnet,2)\n\nconvnet = conv_2d(convnet,64,3,activation='relu')\nconvnet = max_pool_2d(convnet,2)\n\nconvnet = conv_2d(convnet,128,3,activation='relu')\nconvnet = max_pool_2d(convnet,2)\n\nconvnet = conv_2d(convnet,254,3,activation='relu')\nconvnet = max_pool_2d(convnet,2)\n\nconvnet = conv_2d(convnet,512,3,activation='relu')\nconvnet = max_pool_2d(convnet,2)\n\nconvnet = fully_connected(convnet,1024,activation='relu')\nconvnet = dropout(convnet,0.5)\n\nconvnet = fully_connected(convnet,2,activation='softmax')\nconvnet = regression(convnet,optimizer='sgd',loss='categorical_crossentropy' , name='target')\n\nmodel = tflearn.DNN(convnet)","01308f5a":"from tqdm import tqdm\nimport cv2\nimport os \n\nfeatures = []\nloc = '..\/input\/dogs-cats-images\/dataset\/training_set'\n\nfor dir in tqdm(os.listdir(loc)):\n    for img in os.listdir(os.path.join(loc,dir)):\n        im = cv2.imread(os.path.join(loc,dir,img),0)\n        im = cv2.resize(im,(60,60))\n        features.append(im)","3f3c1624":"labels = []\n\ni = 0\nfor dir in tqdm(os.listdir(loc)):\n    for img in os.listdir(os.path.join(loc,dir)):\n        labels.append(i)\n    i += 1","cefceb35":"char = []\nfor dir in tqdm(os.listdir(loc)):\n    char.append(dir)","d227fe43":"import numpy as np\nX = np.array(features)\nX.shape","a86519c0":"#Labels\nY = np.array(labels)\nY.shape","000fd6fa":"#Split the data into train and test\nfrom sklearn.model_selection import train_test_split\nxtrain,xtest,ytrain,ytest = train_test_split(X,Y,train_size=0.85)","92437f46":"xtrain_n = xtrain\/xtrain.max()\nxtest_n = xtest\/xtest.max()","76d87d48":"xtrain_n = xtrain_n.reshape(-1,60,60,1)\nxtest_n = xtest_n.reshape(-1,60,60,1)","b576432c":"from keras.utils import to_categorical\nytrain_e = to_categorical(ytrain.reshape(-1,1))\n\nytest_e = to_categorical(ytest.reshape(-1,1))","fdf0c083":"model.fit({'input':xtrain_n} , {'target':ytrain_e},\n         n_epoch=15,\n         validation_set = ({'input':xtest_n} , {'target':ytest_e}),\n         show_metric=True)","6648a917":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Activation,Flatten,Dropout,BatchNormalization\nfrom keras.layers import Conv2D,MaxPooling2D\nfrom keras import regularizers","6b7a5917":"wd = 1e-3\nkmodel = Sequential()\n\nkmodel.add(Conv2D(32 , (3,3) , padding='same', kernel_regularizer=regularizers.l2(wd),  input_shape=xtrain_n.shape[1:]))\nkmodel.add(Activation('relu'))\nkmodel.add(BatchNormalization())\nkmodel.add(Conv2D(32 , (3,3) , kernel_regularizer=regularizers.l2(wd), padding='same'))\nkmodel.add(Activation('relu'))\nkmodel.add(BatchNormalization())\nkmodel.add(MaxPooling2D(pool_size=(2,2)))\nkmodel.add(Dropout(0.4))\n\nkmodel.add(Conv2D(64 , (3,3) , padding='same', kernel_regularizer=regularizers.l2(wd)))\nkmodel.add(Activation('relu'))\nkmodel.add(BatchNormalization())\nkmodel.add(Conv2D(64 , (3,3) , padding='same', kernel_regularizer=regularizers.l2(wd)))\nkmodel.add(Activation('relu'))\nkmodel.add(BatchNormalization())\nkmodel.add(MaxPooling2D(pool_size=(2,2)))\nkmodel.add(Dropout(0.4))\n\nkmodel.add(Conv2D(128 , (3,3), padding='same', kernel_regularizer=regularizers.l2(wd)))\nkmodel.add(Activation('relu'))\nkmodel.add(BatchNormalization())\nkmodel.add(Conv2D(128 , (3,3) , padding='same',kernel_regularizer=regularizers.l2(wd)))\nkmodel.add(Activation('relu'))\nkmodel.add(BatchNormalization())\nkmodel.add(Conv2D(128 , (3,3) , padding='same',kernel_regularizer=regularizers.l2(wd)))\nkmodel.add(Activation('relu'))\nkmodel.add(BatchNormalization())\nkmodel.add(MaxPooling2D(pool_size=(2,2)))\nkmodel.add(Dropout(0.4))\n\nkmodel.add(Conv2D(254 , (3,3), padding='same',kernel_regularizer=regularizers.l2(wd)))\nkmodel.add(Activation('relu'))\nkmodel.add(BatchNormalization())\nkmodel.add(Conv2D(254 , (3,3), padding='same',kernel_regularizer=regularizers.l2(wd)))\nkmodel.add(Activation('relu'))\nkmodel.add(BatchNormalization())\nkmodel.add(Conv2D(254 , (3,3), padding='same',kernel_regularizer=regularizers.l2(wd)))\nkmodel.add(Activation('relu'))\nkmodel.add(BatchNormalization())\nkmodel.add(MaxPooling2D(pool_size=(2,2)))\nkmodel.add(Dropout(0.5))\n\nkmodel.add(Conv2D(512 , (3,3) , padding='same',kernel_regularizer=regularizers.l2(wd)))\nkmodel.add(Activation('relu'))\nkmodel.add(BatchNormalization())\nkmodel.add(Conv2D(512 , (3,3) , padding='same',kernel_regularizer=regularizers.l2(wd)))\nkmodel.add(Activation('relu'))\nkmodel.add(BatchNormalization())\nkmodel.add(Conv2D(512 , (3,3) , padding='same',kernel_regularizer=regularizers.l2(wd)))\nkmodel.add(Activation('relu'))\nkmodel.add(BatchNormalization())\nkmodel.add(MaxPooling2D(pool_size=(2,2)))\nkmodel.add(Dropout(0.4))\n\nkmodel.add(Conv2D(1024 , (3,3) , padding='same',kernel_regularizer=regularizers.l2(wd)))\nkmodel.add(Activation('relu'))\nkmodel.add(BatchNormalization())\n\nkmodel.add(Flatten())\nkmodel.add(Dense(2, Activation('softmax')))\n\nkmodel.summary()","5475b97f":"print(xtrain_n.shape)\nprint(ytrain_e.shape)\nprint(xtest_n.shape)\nprint(ytest_e.shape)","0e93fc04":"sgd = keras.optimizers.SGD(lr=0.01)\nkmodel.compile(loss='categorical_crossentropy',\n               optimizer=sgd,metrics=['accuracy'])","9d0fa341":"kmodel.fit(xtrain_n,ytrain_e,epochs=40,validation_data=(xtest_n,ytest_e))","fa5072ba":"kmodel.evaluate(xtest_n,ytest_e)","41987441":"xtest_n[56].shape","c225e19e":"import matplotlib.pyplot as plt\nplt.imshow(xtest_n[561])\nplt.show()","0ee3c55a":"kmodel.predict(xtest_n[561].reshape(1,60,60,1))","06368e96":"np.argmax(kmodel.predict(xtest_n[561].reshape(1,60,60,1)))","964a486c":"char[np.argmax(kmodel.predict(xtest_n[561].reshape(1,60,60,1)))]","d0d0637d":"char[np.argmax(ytest_e[561])]","f5b41902":"ytestPred = []\nfor val in kmodel.predict(xtest_n):\n    ytestPred.append(np.argmax(val))","e88f938c":"ytest","af73715b":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(ytest,ytestPred)","a5cd342f":"(516+442)\/(516+442+95+147)","aad3d39b":"#Acc. category 0 - \n516\/(516+95)","f77b499a":"#Acc for category 1\n442\/(442+147)","e1e83267":"**TFLearn**","22311bbe":"**Keras for CNN**"}}