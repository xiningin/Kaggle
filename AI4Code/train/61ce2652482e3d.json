{"cell_type":{"61a0bd0b":"code","8732ca98":"code","230cbea2":"code","924e83d0":"code","22a550b6":"code","fc1681c4":"code","527524e5":"code","68dea421":"code","3e936471":"code","89bd6200":"code","1555c696":"code","0ad3bc0e":"code","53c19e24":"code","ac00b9c0":"code","b3cad366":"code","ba23307c":"code","2b642209":"markdown","7cbe7229":"markdown","c72ef7c6":"markdown","82e87383":"markdown","2564cc18":"markdown","ee516c47":"markdown"},"source":{"61a0bd0b":"import pandas as pd       \nimport matplotlib as mat\nimport matplotlib.pyplot as plt    \nimport numpy as np\nimport seaborn as sns\n%matplotlib inline\n\nimport random\nimport os\n\nfrom numpy.random import seed\nseed(42)\n\nrandom.seed(42)\nos.environ['PYTHONHASHSEED'] = str(42)\nos.environ['TF_DETERMINISTIC_OPS'] = '1'\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import RobustScaler\n\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import callbacks\nfrom tensorflow.keras.models import Model\n\n\nfrom tensorflow.random import set_seed\nset_seed(42)\n\nimport warnings\nwarnings.filterwarnings('ignore')","8732ca98":"df_train = pd.read_csv('..\/input\/ventilator-pressure-prediction\/train.csv', index_col = 'id')\nX_test = pd.read_csv('..\/input\/ventilator-pressure-prediction\/test.csv', index_col = 'id')\nsubmission = pd.read_csv('..\/input\/ventilator-pressure-prediction\/sample_submission.csv')\n\nX_train = df_train.copy().drop('pressure', axis = 1)\nY_train = df_train['pressure'].copy()","230cbea2":"df_train","924e83d0":"X_test","22a550b6":"#Inspired by https:\/\/www.kaggle.com\/c\/ventilator-pressure-prediction\/discussion\/273974\nX_train['u_in_cumsum'] = (X_train['u_in']).groupby(X_train['breath_id']).cumsum()\nX_test['u_in_cumsum'] = (X_test['u_in']).groupby(X_test['breath_id']).cumsum()\n\n#Lag features. \n#Number of lag features inspired by https:\/\/www.kaggle.com\/tenffe\/finetune-of-tensorflow-bidirectional-lstm\nX_train['u_in_lag1'] = X_train.groupby('breath_id')['u_in'].shift(1).fillna(0)\nX_test['u_in_lag1'] = X_test.groupby('breath_id')['u_in'].shift(1).fillna(0)\nX_train['u_in_lag2'] = X_train.groupby('breath_id')['u_in'].shift(2).fillna(0)\nX_test['u_in_lag2'] = X_test.groupby('breath_id')['u_in'].shift(2).fillna(0)\nX_train['u_in_lag3'] = X_train.groupby('breath_id')['u_in'].shift(3).fillna(0)\nX_test['u_in_lag3'] = X_test.groupby('breath_id')['u_in'].shift(3).fillna(0)\nX_train['u_in_lag4'] = X_train.groupby('breath_id')['u_in'].shift(4).fillna(0)\nX_test['u_in_lag4'] = X_test.groupby('breath_id')['u_in'].shift(4).fillna(0)\n\nX_train['u_in_lag-1'] = X_train.groupby('breath_id')['u_in'].shift(-1).fillna(0)\nX_test['u_in_lag-1'] = X_test.groupby('breath_id')['u_in'].shift(-1).fillna(0)\nX_train['u_in_lag-2'] = X_train.groupby('breath_id')['u_in'].shift(-2).fillna(0)\nX_test['u_in_lag-2'] = X_test.groupby('breath_id')['u_in'].shift(-2).fillna(0)\nX_train['u_in_lag-3'] = X_train.groupby('breath_id')['u_in'].shift(-3).fillna(0)\nX_test['u_in_lag-3'] = X_test.groupby('breath_id')['u_in'].shift(-3).fillna(0)\nX_train['u_in_lag-4'] = X_train.groupby('breath_id')['u_in'].shift(-4).fillna(0)\nX_test['u_in_lag-4'] = X_test.groupby('breath_id')['u_in'].shift(-4).fillna(0)\n\n#Window features\n#Choice of features inspired vy https:\/\/www.kaggle.com\/tenffe\/finetune-of-tensorflow-bidirectional-lstm\nX_train['breath_id__u_in__max'] = X_train.groupby(['breath_id'])['u_in'].transform('max')\nX_test['breath_id__u_in__max'] = X_test.groupby(['breath_id'])['u_in'].transform('max')\nX_train['breath_id__u_in__mean'] = X_train.groupby(['breath_id'])['u_in'].transform('mean')\nX_test['breath_id__u_in__mean'] = X_test.groupby(['breath_id'])['u_in'].transform('mean')\n\nX_train['breath_id__u_out__max'] = X_train.groupby(['breath_id'])['u_out'].transform('max')\nX_test['breath_id__u_out__max'] = X_test.groupby(['breath_id'])['u_out'].transform('max')\nX_train['breath_id__u_out__mean'] = X_train.groupby(['breath_id'])['u_out'].transform('mean')\nX_test['breath_id__u_out__mean'] = X_test.groupby(['breath_id'])['u_out'].transform('mean')\n\nX_train = X_train.drop(['breath_id'], axis = 1)\nX_test = X_test.drop(['breath_id'], axis = 1)\n\n\nX_train","fc1681c4":"scaler = RobustScaler()\n\nX_train[X_train.columns] = scaler.fit_transform(X_train[X_train.columns])\nX_test[X_test.columns] = scaler.transform(X_test[X_test.columns])","527524e5":"X_train","68dea421":"#Original set lenght\ntrain_len = len(X_train)\ntest_len = len(X_test)","3e936471":"#Reshaping Data\n#80 - timesteps\nY_train = Y_train.values.reshape(-1,80)\nX_train = X_train.values.reshape(-1,80,18)\nX_test = X_test.values.reshape(-1,80,18)\n\nprint(X_train.shape, Y_train.shape, X_test.shape)","89bd6200":"#Defining Callbacks\n\nearly_stopping = callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=15,\n    min_delta=0.0000001,\n    restore_best_weights=True,\n)\n\nplateau = callbacks.ReduceLROnPlateau(\n    monitor='val_loss',\n    factor = 0.5,                                     \n    patience = 3,                                   \n    min_delt = 0.0000001,                                \n    cooldown = 0,                               \n    verbose = 1\n)","1555c696":"#Model\ndef new_model():\n\n    inputs = layers.Input(shape = (80,18))\n    \n    x = layers.Bidirectional(keras.layers.LSTM(1024, return_sequences=True))(inputs)\n    x = layers.Bidirectional(keras.layers.LSTM(512, return_sequences=True))(x)\n    x = layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True))(x)\n    x = layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True))(x)\n    x = layers.Dense(128, activation='selu')(x)\n    \n    #Final Layer (Output)\n    output = layers.Dense(1, activation = 'linear')(x)\n    \n    model = keras.Model(inputs=[inputs], outputs=output)\n    \n    return model","0ad3bc0e":"# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\nwith tpu_strategy.scope():\n        \n    kfold = KFold(n_splits = 5, shuffle=True, random_state = 42)\n\n    pred = np.zeros((test_len,1))\n    #train_oof = np.zeros((train_len,1))\n    train_oof = np.zeros((len(X_train),80,1))\n\n    for fold, idx in enumerate(kfold.split(X=X_train, y=Y_train)):\n        \n        print(20*'--','Fold: ', fold+1, 20*'--')\n        \n        train_idx, val_idx = idx[0], idx[1]\n        xtrain = X_train[train_idx]\n        ytrain = Y_train[train_idx]\n        xval = X_train[val_idx]\n        yval = Y_train[val_idx]\n\n        model = new_model()\n        model.compile(loss='mae', optimizer = keras.optimizers.Adam(learning_rate=0.002),\n                      metrics=[keras.metrics.MeanAbsoluteError()])\n        \n        checkpoint_filepath = f\"folds{fold}.hdf5\"\n        \n        check = keras.callbacks.ModelCheckpoint(\n            checkpoint_filepath,\n            monitor='val_loss',\n            verbose=1,\n            save_best_only=True,\n            save_weights_only=False,\n            mode='auto',\n            save_freq='epoch',\n            options=None\n        )\n\n        model.fit(xtrain, ytrain,\n        batch_size = 1024, epochs = 250,\n        validation_data=(xval, yval),\n        callbacks=[early_stopping, plateau, check]);\n\n        #create predictions\n        pred += model.predict(X_test).reshape(-1,1)\/kfold.n_splits\n        #print(pred)\n\n        val_pred = model.predict(xval)\n\n        # getting out-of-fold predictions on training set\n        train_oof[val_idx] = val_pred","53c19e24":"train_oof = train_oof.reshape(-1,1)\nY_train_reshaped = Y_train.reshape(-1,1)","ac00b9c0":"print(\"OOF - MAE: {0:0.6f}\".format(mean_absolute_error(Y_train_reshaped,train_oof)))","b3cad366":"train_oof = pd.DataFrame(train_oof, columns = ['pressure'])\ntrain_oof.to_csv('train_oof.csv', index=False)\n\ntrain_oof","ba23307c":"submission['pressure'] = pred\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission","2b642209":"## Feature Engineering + Reshaping the Dataset","7cbe7229":"## Defining and Running the Neural Network","c72ef7c6":"# <center>Google Brain - Ventilator Pressure Prediction<center>\n## <center>Starter: LSTM Neural Network (TPU)<center>\n---\nThis is my first notebook with a LSTM Network and also the first time I ran a model on TPU. As the intent of this notebook is to provide a \u2018framework\u2019 for future ones, in this version (could be updated), I\u2019m not using all the engineered features available on the top public notebooks, only those I managed to understand until the moment I created this.","82e87383":"## Generating Outputs","2564cc18":"## Importing Packages and Datasets","ee516c47":"\nSuggestion of EDA notebook in this dataset:\n* [Ventilator Pressure: EDA and simple submission](https:\/\/www.kaggle.com\/carlmcbrideellis\/ventilator-pressure-eda-and-simple-submission) by [Carl McBride Ellis](https:\/\/www.kaggle.com\/carlmcbrideellis)\n    \nNotebook that inspired my work:\n* [Finetune of Tensorflow Bidirectional LSTM](https:\/\/www.kaggle.com\/tenffe\/finetune-of-tensorflow-bidirectional-lstm) by [zhangxin](https:\/\/www.kaggle.com\/tenffe)"}}