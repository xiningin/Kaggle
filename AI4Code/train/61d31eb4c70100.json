{"cell_type":{"35dc784a":"code","cf1c7140":"code","6254f8d3":"code","a2111a4a":"code","3a7a300d":"code","ac5bc585":"code","416c0463":"code","3271c26d":"code","540930cb":"code","aab36c4e":"code","532d57b6":"code","57f1806d":"code","c95ccb2f":"code","f90e218e":"code","d0a27236":"code","99c97670":"code","1a17c8f3":"code","b71817ef":"code","c782ecac":"code","f0ee2ee7":"markdown","e1e7fd6e":"markdown","8d35a0f7":"markdown","58c938eb":"markdown","6021ed62":"markdown","a4eb6e2f":"markdown","6a12a922":"markdown","0577dd3a":"markdown","80b7c361":"markdown","acb900c7":"markdown","4b689ebd":"markdown","8c585abd":"markdown","194b76d9":"markdown","49b26315":"markdown","06d71d46":"markdown","f27732c0":"markdown","c40f1472":"markdown","eb9181b9":"markdown","193ddaf6":"markdown","75b0f07c":"markdown","0dd278aa":"markdown","d691c7f2":"markdown","dabbca5b":"markdown","e0d67984":"markdown"},"source":{"35dc784a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt #Ploting charts\nfrom glob import glob #retriving an array of files in directories\nfrom keras.models import Sequential #for neural network models\nfrom keras.layers import Dense, Dropout, Flatten, ZeroPadding2D, Conv2D, MaxPooling2D\nfrom keras.preprocessing.image import ImageDataGenerator #Data augmentation and preprocessing\nfrom keras.utils import to_categorical #For One-hot Encoding\nfrom keras.optimizers import Adam, SGD, RMSprop #For Optimizing the Neural Network\nfrom keras.callbacks import EarlyStopping","cf1c7140":"#Cheking datasets\nimport os\npaths = os.listdir(path=\"..\/input\")\nprint(paths)","6254f8d3":"path_train = \"..\/input\/chest_xray\/chest_xray\/train\"\npath_val = \"..\/input\/chest_xray\/chest_xray\/val\"\npath_test = \"..\/input\/chest_xray\/chest_xray\/test\"","a2111a4a":"img = glob(path_train+\"\/PNEUMONIA\/*.jpeg\") #Getting all images in this folder","3a7a300d":"img = np.asarray(plt.imread(img[0]))","ac5bc585":"plt.imshow(img)","416c0463":"img.shape #Checking the shape of this image. It seems like a two deminsional shape (1422 x 1152)","3271c26d":"img = glob(path_train+\"\/NORMAL\/*.jpeg\") #Getting all images in this folder","540930cb":"img = np.asarray(plt.imread(img[0]))","aab36c4e":"plt.imshow(img)","532d57b6":"img.shape","57f1806d":"#Data preprocessing and analysis\n\ntrain_data = glob(path_train+\"\/NORMAL\/*.jpeg\")\ntrain_data += glob(path_train+\"\/PNEUMONIA\/*.jpeg\")\ndata_gen = ImageDataGenerator() #Augmentation happens here\nclasses = [\"NORMAL\", \"PNEUMONIA\"]\n#But in this example we're not going to give the ImageDataGenerator method any parameters to augment our data.","c95ccb2f":"val_batches = data_gen.flow_from_directory(path_val, target_size = (226, 226), classes = classes, class_mode = \"categorical\")\ntest_batches = data_gen.flow_from_directory(path_test, target_size = (226, 226), classes = classes, class_mode = \"categorical\")\ntrain_batches = data_gen.flow_from_directory(path_train, target_size = (226, 226), classes = classes, class_mode = \"categorical\")\n","f90e218e":"train_batches.image_shape","d0a27236":"#This is a Convolutional Artificial Neural Network\n#VGG16 Model\nmodel = Sequential()\nmodel.add(ZeroPadding2D((1,1),input_shape=train_batches.image_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(256, (3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(256, (3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(256, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(512, (3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(512, (3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(512, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(512, (3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(512, (3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(512, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(4096, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(4096, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2, activation='softmax'))","99c97670":"#Viewing the summary of the model\nmodel.summary()","1a17c8f3":"optimizer = Adam(lr = 0.0001)\nearly_stopping_monitor = EarlyStopping(patience = 3, monitor = \"val_acc\", mode=\"max\", verbose = 2)\nmodel.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\nhistory = model.fit_generator(epochs=5, callbacks=[early_stopping_monitor], shuffle=True, validation_data=val_batches, generator=train_batches, steps_per_epoch=500, validation_steps=10,verbose=2)\nprediction = model.predict_generator(generator=train_batches, verbose=2, steps=100)","b71817ef":"\n\n# summarize history for accuracy\n\n# summarize history for accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='best')\nplt.show()","c782ecac":"\n# summarize history for loss\n\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='best')\nplt.show()","f0ee2ee7":"#### Normal:","e1e7fd6e":"### Now we're going to explore the dataset that contains chest x-ray images of people who have pneumonia and people who don't.\n# Our main goal is to predict if a person has pneumonia or not based of off their chest x-ray image.\n# \n# #### So now we'll display one chest x-ray image of a person with pneumonia and one with a person without pneumonia, just to have a glimpse of what each image looks like in general.","8d35a0f7":"**The main purpose of this project is to show you how to unleash the power of convolutional neural networks in order to detect pneumonia in a person based of off their chest x-ray image.**\n\n","58c938eb":"One of the best things about being in a tech industry is that fellow smart techies who've created cool and robust neural network are generous enough to share their model architecture with us, so we don't have re-invent the wheel.\n# This will save us some time and headache. We're going to use a method known as **transfer learning**. This means instead of creating a brand new neural net that's going to be time consuming, we can just use a pre-trained [good] model and fine tune it in order for it to work for our own scenario.\n# \n# Usually when people do transfer learning, they use both the architecture and weights of a pre-trained model. But in this tutorial we're only using the architecture of a pretrained model, not their weights.","6021ed62":"Getting all images in the dataset","a4eb6e2f":"Now we're going to plot the model's performance\n# Obsertvation:-\n\n#   If validation\/test accuracy is greater than training accuracy, that's good, it means our model has managed to learn and get a general idea\/pattern of our data.\n#   But if training accuracy is greater than validation\/testing accuracy, tha's not good. That means our model is overfitting.\n#  \n#  \n#  The opposite is true for the loss chart.\n#  The ideal situation is to have validation\/test loss way low. But train loss should not be lower than test\/validation loss.","6a12a922":"### Training the neural net","0577dd3a":"## Ploting the model performance","80b7c361":"Plotting the image","acb900c7":"Exploring the paths of the dataset.\n# This is where our data is stored.","4b689ebd":"# Using VGG16 for Pneumonia classification\n","8c585abd":"Converting the first image we get from the above directory\/path into a numpy array","194b76d9":"#### Importing essential libraries\n# Now we're importing all necesarry libraries for us to work with.","49b26315":"Now the training begins","06d71d46":"#### In our dataset we're given three sets of images:\n# 1. The training set. These are images we're going to train the neural network on.\n# 2. The validation set. These are images we're going to use to check if the model is underfitting or overfitting, while training and compare the training and validation results in real time.\n# 3. The test set. These are images we're going to use to check how good our neural network is with data it has not seen before.","f27732c0":"## Model Accuracy Chart","c40f1472":"We're training our model for 5 epochs.\n# This means we're giving the model 5 chances to learn patterns about our data.\n# \n# During preparing we will apply a method called Early Stopping. This procedure will quit preparing of the model if there's no improvement during the preparation procedure.\n# In the below example of early stopping, our parameter **patience** tells the model to stop training if there's no improvements after 3 consecutive epochs, and monitor tells the model which metric to look at in order to apply early stopping.\n","eb9181b9":"## Fundamental terms:\n\n# 1. ** Overfitting **\n#       Overfitting happens when a neural system model remembers designs in a dataset as opposed to learning the general thought\/example of the information.\n#       This is usually cause by an overly complicated neural network model.\n\n#     \n# 2. **Underfitting**\n#         Underfitting happens when a neural system model doesn't perceive designs in the dataset.\n#         This is usually caused by a too simple neural network model, or when there's too much noise in the dataset.\n#         ","193ddaf6":"## Data Analysis and Preprocessing","75b0f07c":"## The Artificial Neural Network\n# ### This particular neural network is called a convolutional neural network because it has convolutional layers that convolve the images\/arrays of data it's being trained on.\n# This model is based off a model that won the ImageNet competition...","0dd278aa":"### Transforming the images\n# * Now we're applying a technique called Data Augmentation.\n# * We're changing the sizes of the images to 226 x 226 and we'll flip the images horizontally as well so that we can have more data(images) to train on.","d691c7f2":"In the following example, we're attempting to avoid overfitting by augmenting our image data.\n# Data augmentation means we're going to make slight variations to our data so that we have more data, without losing semantic meaning in our data.\n# The augmentation occurs in the parameters of the ImageDataGenerator method. To get a better understanding of these parameters you can check out [this link](https:\/\/machinelearningmastery.com\/image-augmentation-deep-learning-keras\/) and [this one.](https:\/\/keras.io\/preprocessing\/image\/)\n# \n\n# **horizontal_flip** set to true implies that some images in the data will be randomly horizontally flipped, as chest x-ray images don't have any significant meaning when horizontally flipped(at least for machine learning purpose).\n# \n# **channel_shift_range** will randomly shift the channels of our images. Image channel refers to the RGB color scheme, which implies some imges will slightly vary in color.\n# \n# **rotation_range** will slighty rotate the image according value given to it.\n# \n# **zoom_range** will slightly zoom in to the image according value given to it.\n","dabbca5b":"## Model Loss Chart","e0d67984":"#### Pneumonia:"}}