{"cell_type":{"66c6c93e":"code","7146d3ba":"code","64df5cf9":"code","936d0b08":"code","d1170f86":"code","d7c2eae6":"code","956483ae":"code","36f346cb":"code","084dd973":"code","bb4fee5a":"code","4d1780fa":"code","1ab031d9":"code","032b662b":"code","635b062d":"code","547ecf53":"code","fa41e7e5":"code","364b5b27":"code","b1091fdb":"code","bdc0be0a":"code","71908a46":"code","1212e0a3":"code","2c929fa8":"code","620853d0":"code","25eec5fa":"code","c4879087":"code","cf327460":"code","b4be883b":"code","2c402152":"code","9ed56f65":"code","eb0f923c":"code","d051e093":"code","edfa999a":"code","b44b9255":"code","d3d9f8c2":"code","04b9e689":"code","c27d2c0e":"code","0bd8b4aa":"code","5469954c":"markdown","981012ad":"markdown","cff61f23":"markdown","c3024554":"markdown","7ed6196a":"markdown","a927566c":"markdown","d2ef32c8":"markdown","b5666aa8":"markdown","aaebacff":"markdown","b6b7f473":"markdown","b365dccb":"markdown","f0b2a656":"markdown","b235452e":"markdown","c0ee78a5":"markdown"},"source":{"66c6c93e":"import os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image","7146d3ba":"PATH = '\/kaggle\/input'\ndata_folder = os.listdir(PATH)[0]\nmain_path = os.path.join(PATH, data_folder)\nprint(f'the data is in: {main_path}')","64df5cf9":"print(f'The data structure is: {os.listdir(main_path)}')","936d0b08":"# See the shape of all images:\n\n\ndef get_size(folder):\n    sizes = []\n    # Get from main directory all sub-directories\n    for folder_path in os.listdir(folder):\n        # Skip\n\n        if (folder_path == 'train_labels.csv' or folder_path == 'sample_submission.csv'):\n            #print(f'{folder_path}')\n            continue\n        # See Train and Test sub-directories\n        count = 0\n        for filename in os.listdir(os.path.join(folder, folder_path)):\n            if count == 100:\n                break\n            count += 1\n            # take image\n            img = Image.open(os.path.join(folder, folder_path, filename))\n            # Get image with \n            #print(img.size)\n            # Stores data like: (width, height)\n            sizes.append(img.size)\n        \n        print(f'{folder_path}')\n        print(f'the max width is: {max(sizes[0])}, and the min width is: {min(sizes[0])}')\n        print(f'the max height is: {max(sizes[1])}, and the min height is: {min(sizes[1])}')\n        print(f'the mean width is: {np.mean(sizes[0])}, and the mean height is: {np.mean(sizes[1])}')\n\n# Call the function\nget_size(main_path)","d1170f86":"# Paths\n\nimages_folder_train = os.path.join(main_path , 'train\/')\ntrain_path_labels = os.path.join(main_path , 'train_labels.csv')\n\nimages_folder_test = os.path.join(main_path , 'test\/')\ntest_path_labels = os.path.join(main_path , 'sample_submission.csv')","d7c2eae6":"# See some files\nprint(f'the number of images are {len(os.listdir(images_folder_train))}')\nos.listdir(images_folder_train)[:10]","956483ae":"import matplotlib.pyplot as plt\ndef plot_images(axis=(2,2), train = True):\n    \n    if train:\n        img_path = images_folder_train\n        # name of images \n        df = pd.read_csv(train_path_labels)['id']\n        labels = pd.read_csv(train_path_labels)['label']\n    else:\n        img_path = images_folder_test\n        # name of images \n        labels = pd.read_csv(test_path_labels)['label']\n        df = pd.read_csv(test_path_labels)['id']\n        \n    \n        \n    # Grid\n    f, axarr = plt.subplots(axis[0], axis[1], figsize=(30\/axis[1], 10))\n    \n    for i in range(0,axis[0]):\n        for j in range (0,axis[1]):\n            \n            # Choose a random image\n            index_img = np.random.randint(len(df))\n            image_name = df.iloc[index_img]\n            image_path = os.path.join(img_path, image_name)\n            \n            image_label = labels.iloc[index_img]\n            \n            if (not train):\n                image_label = 'No label'\n            elif (image_label == 0):\n                image_label = 'No cancer'\n            elif (image_label == 1):\n                image_label = 'Cancer'\n            \n            # Read Image:\n            img = Image.open(image_path+'.tif').convert('RGB')\n            # To numpy\n            img = np.asarray(img)\n            # print(f'image shape {img.shape}, max: {img.max()}, min: {img.min()}')\n            # Plot\n            axarr[i,j].imshow(img)\n            axarr[i,j].title.set_text(image_label)\n    plt.show()","36f346cb":"plot_images(axis=(3,3), train = True)","084dd973":"plot_images(axis=(3,3), train=False)","bb4fee5a":"# Train Images and labels\ntrain_map = pd.read_csv(train_path_labels)\ntrain_map.head()","4d1780fa":"# Test Images and labels\ntest_map = pd.read_csv(test_path_labels)\ntest_map.head()","1ab031d9":"# Data distribution\ntrain_map.groupby(['label'])['id'].count().plot(kind='bar', stacked=True)","032b662b":"# label datatype to string\ntrain_map['label'] = train_map['label'].astype(str)\ntest_map['label'] = test_map['label'].astype(str)","635b062d":"# add .tif\ntrain_map.id = train_map.id.apply(lambda name: name + '.tif')\ntest_map.id = test_map.id.apply(lambda name: name + '.tif')\n\ntrain_map","547ecf53":"from sklearn.model_selection import train_test_split\n\n# Split Train and test\ntrain, test = train_test_split(train_map, test_size=0.2, random_state=1)\n\n# Split Train and validation\ntrain, validation = train_test_split(train_map, test_size=0.1, random_state=1)","fa41e7e5":"train.head()","364b5b27":"test.head()","b1091fdb":"validation.head()","bdc0be0a":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# We can't load all data in memory at once, so we use a DataGenerator\n#Create instance of ImageDataGenerator Class\nimage_gen_train = ImageDataGenerator(\n                    # Rescale\n                    rescale=1.\/255,\n                    # Rotate 30\n                    rotation_range=30,\n                    # Shift pixel values\n                    width_shift_range=.20,\n                    height_shift_range=.20,\n                    # Flip all image\n                    horizontal_flip=True,\n                    # Random zoom\n                    zoom_range=0.4\n                    )\nimage_gen_test = ImageDataGenerator(rescale=1.\/255)\nimage_gen_valid = ImageDataGenerator(rescale=1.\/255)","71908a46":"width = 96 # width = height\nbatch_size = 32\n\n# Custom datagenerator\ntrain_datagen = image_gen_train.flow_from_dataframe(dataframe=train,\n                                                    directory=images_folder_train,\n                                                    x_col='id',\n                                                    y_col='label',\n                                                    batch_size=batch_size, #16,32,64...\n                                                    seed=1,\n                                                    shuffle=True,\n                                                    class_mode=\"binary\",\n                                                    target_size=(width,width))\n                                                                \ntest_datagen = image_gen_test.flow_from_dataframe(dataframe=test,\n                                                    directory=images_folder_train,\n                                                    x_col='id',\n                                                    y_col='label',\n                                                    batch_size=batch_size, #16,32,64...\n                                                    seed=1,\n                                                    shuffle=False,\n                                                    class_mode=\"binary\",\n                                                    target_size=(width,width))\n\nvalid_datagen = image_gen_valid.flow_from_dataframe(dataframe=validation,\n                                                    directory=images_folder_train,\n                                                    x_col='id',\n                                                    y_col='label',\n                                                    batch_size=batch_size, #16,32,64...\n                                                    seed=1,\n                                                    shuffle=True,\n                                                    class_mode=\"binary\",\n                                                    target_size=(width,width))","1212e0a3":"import matplotlib.pyplot as plt\ndef plot_images_datagen(axis=(2,2), images=None):\n\n    # Grid\n    f, axarr = plt.subplots(axis[0], axis[1], figsize=(30\/axis[1], 10))\n    index = 0\n    for i in range(0,axis[0]):\n        for j in range (0,axis[1]):\n            # Plot\n            axarr[i,j].imshow(images[index])\n            index += 1\n    plt.show()","2c929fa8":"# See Example of image datagenerator\nexample = image_gen_train.flow_from_dataframe(dataframe=validation,\n                                                    directory=images_folder_train,\n                                                    x_col='id',\n                                                    y_col='label',\n                                                    batch_size=batch_size, #16,32,64...\n                                                    seed=1,\n                                                    shuffle=True,\n                                                    class_mode=\"binary\",\n                                                    target_size=(width,width))\n\nimages, _ = next(example)\nexample_images = images[:9]\nplot_images_datagen(axis=(3,3), images=example_images)","620853d0":"# See if GPU is aviable\nimport tensorflow as tf\n\ngpu = len(tf.config.list_physical_devices('GPU'))>0\nprint(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")","25eec5fa":"from tensorflow.keras import applications\n\n# See model\napplications.resnet50.ResNet50(weights= None).summary()","c4879087":"import tensorflow as tf\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\n\nouts = 1\n\n\nclass MyModel(tf.keras.Model):\n\n    def __init__(self, n_outputs=outs, pretrained=False, freeze=False, size = width, depth = 3):\n        \n        super(MyModel, self).__init__()\n        \n        \n        if pretrained:\n            self.model_weights = 'imagenet'\n        else:\n            self.model_weights = None\n        \n        # Download the architecture of ResNet50 with ImageNet weights\n        self.resnet = applications.resnet50.ResNet50(include_top=False, weights=self.model_weights, input_shape= (width,width, depth))\n        \n        # Taking the output of the last convolution block in ResNet50\n        self.res_out = self.resnet.output\n        self.res_in = self.resnet.input\n        \n        self.GlobPoll = GlobalAveragePooling2D()\n        \n        # Adding a fully connected layer having 1024 neurons\n        #self.fc1 = Dense(1024, activation='relu')\n        \n        # Sigmoid Out\n        self.out = Dense(outs, activation='softmax')\n        \n        if freeze:\n            # Training only top layers i.e. the layers which we have added in the end\n            self.resnet.trainable = False\n\n    def call(self, inputs):\n\n        x = self.resnet(inputs)\n        x = self.GlobPoll(x)\n        #x = self.fc1(x)\n        x = self.out(x)\n        \n        return x\n\n\nclass MyModel(tf.keras.Model):\n\n    def __init__(self, n_outputs=outs, pretrained=False, freeze=False, size = width, depth = 3):\n        \n        super(MyModel, self).__init__()\n        \n        \n        if pretrained:\n            self.model_weights = 'imagenet'\n        else:\n            self.model_weights = None\n        \n        # Download the architecture of ResNet50 with ImageNet weights\n        self.resnet = applications.resnet50.ResNet50(include_top=False, weights=self.model_weights, input_shape= (width,width, depth))\n        \n        # Taking the output of the last convolution block in ResNet50\n        self.res_out = self.resnet.output\n        self.res_in = self.resnet.input\n        \n        self.GlobPoll = GlobalAveragePooling2D()\n        \n        # Adding a fully connected layer having 1024 neurons\n        #self.fc1 = Dense(1024, activation='relu')\n        \n        # Sigmoid Out\n        self.out = Dense(outs, activation='sigmoid')\n        \n        if freeze:\n            # Training only top layers i.e. the layers which we have added in the end\n            self.resnet.trainable = False\n\n    def call(self, inputs):\n\n        x = self.resnet(inputs)\n        x = self.GlobPoll(x)\n        #x = self.fc1(x)\n        x = self.out(x)\n        \n        return x\n","cf327460":"np.random.seed(1)\ntf.random.set_seed(1234)\n\n# With Class\nmodel = MyModel()\n#model.build(input_shape=(None,width, width, 3))\n#model.summary()\n# Model \n#model.load_weights('\/kaggle\/working\/Models\/ModelResnet50\/Resnet50_tf_batch32_NoPretrained')","b4be883b":"positive_weights = {}\nnegative_weights = {}\n\npositive_weights['label'] = train.shape[0]\/(2*np.count_nonzero(train['label']=='1'))\nnegative_weights['label'] = train.shape[0]\/(2*np.count_nonzero(train['label']=='0'))\n\nprint(positive_weights)\nprint('----------------------')\nprint(negative_weights)\n","2c402152":"# custon Binary Crossentropy\nimport tensorflow.keras.backend as K\n\ndef loss_fn(y_true,y_pred):\n    \n    y_true = tf.cast(y_true, tf.float32)\n    \n    #print(y_true.dtype)\n    #print(y_pred.dtype)\n    loss = 0\n    loss -= (positive_weights['label']*y_true[0]*K.log(y_pred[0]) + negative_weights['label']*(1-y_true[0])*K.log(1-y_pred[0]))\n    #print(loss)\n    return loss","9ed56f65":"# Compile with custom loss\nmodel.compile(optimizer = tf.keras.optimizers.Adam(3e-5), loss = loss_fn, metrics = ['categorical_accuracy','accuracy'])\n\n#model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['categorical_accuracy','accuracy'])","eb0f923c":"from tensorflow.keras.callbacks import EarlyStopping\n\n# EarlyStopping:\nmonitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, \n        verbose=1, mode='auto', restore_best_weights=True)\n\nSTEP_SIZE_TRAIN = train_datagen.n\/\/train_datagen.batch_size\nSTEP_SIZE_VALID = valid_datagen.n\/\/valid_datagen.batch_size\nSTEP_SIZE_TEST = test_datagen.n\/\/test_datagen.batch_size\n\n\n\n# https:\/\/www.tensorflow.org\/versions\/r2.1\/api_docs\/python\/tf\/keras\/Model#fit\nmodel.fit(x = train_datagen,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=valid_datagen,\n                    validation_steps=STEP_SIZE_VALID,\n                    epochs=1,\n                    callbacks=[monitor]\n)","d051e093":"# Predict \n#test_datagen.reset()\npred = model.predict_generator(test_datagen,\n                            steps=STEP_SIZE_TEST,\n                            verbose=1)","edfa999a":"print('the predictions are: ')\npred","b44b9255":"print('the predictions are: ')\n# Transform predictions to 0 or 1\nround_pred = np.rint(pred)\nround_pred","d3d9f8c2":"y_true = test_datagen.labels\nprint(f'the actual values are: {y_true[:5]}...')\n","04b9e689":"from sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\n\ndef get_metrics(y_true=y_true, round_pred=round_pred):\n\n    y_true = y_true[:round_pred.shape[0]]\n    \n    # accuracy: (tp + tn) \/ (p + n)\n    accuracy = accuracy_score(y_true, round_pred)\n    print('Accuracy: %f' % accuracy)\n    # precision tp \/ (tp + fp)\n    precision = precision_score(y_true, round_pred)\n    print('Precision: %f' % precision)\n    # recall: tp \/ (tp + fn)\n    recall = recall_score(y_true, round_pred)\n    print('Recall: %f' % recall)\n    # f1: 2 tp \/ (2 tp + fp + fn)\n    f1 = f1_score(y_true, round_pred)\n    print('F1 score: %f' % f1)","c27d2c0e":"get_metrics(y_true, round_pred)","0bd8b4aa":"# Save the weights (Class)\nmodel.save_weights('\/kaggle\/working\/Models\/ModelResnet50\/Resnet50_tf_batch32_NoPretrained')","5469954c":"# Modeling","981012ad":"## See Labels","cff61f23":"# Data Preparation","c3024554":"### Custom Loss unbalanced","7ed6196a":"# Evaluation","a927566c":"# Create Model\n* <a href=\"https:\/\/arxiv.org\/abs\/1512.03385\">Resnet 50 <\/a>","d2ef32c8":"# Data Generator and Data Agumentation","b5666aa8":"# Train Model","aaebacff":"# Business understanding","b6b7f473":"## Test Model","b365dccb":"Histopathologic Cancer Detection\n\nWe have a histopathology by light microscopy: It is a sample of dough extracted from an organ (biopsy) with an ematoxylin eosin stain, this staining shows us the cytoplasm, nucleus and the plasma membrane (It only shows the morphology of the cell). For the cell to be normal the image should be like:\n1. The cell must have a polarity (an order in orientation)\n2. Homogeneous cell differentiation: It must have a specialized order, for example, ranging from large to small cells.\n3. That it is not dysmorphic (same size between equal cells)\n4. Neoplasia: Do not exceed the basement membrane (basement membrane discontinuity is cancer)","f0b2a656":"# Data Understanding","b235452e":"## See Images","c0ee78a5":"# Analyze the data structure"}}