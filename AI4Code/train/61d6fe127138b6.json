{"cell_type":{"6065b179":"code","886ce34f":"code","a78112f3":"code","bf6c7f2c":"code","a2b0a732":"code","e7398ba2":"code","b87100ff":"code","a6174c64":"code","824c6222":"code","026cb834":"markdown","1bcb9ffb":"markdown","2e7bfd30":"markdown","e7885eae":"markdown","181ed7ac":"markdown"},"source":{"6065b179":"from tensorflow.keras.layers import Input, Reshape, Dropout, Dense, Flatten, BatchNormalization, Activation, ZeroPadding2D\nfrom tensorflow.keras.layers import UpSampling2D, Conv2D, LeakyReLU\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\nfrom PIL import Image\nfrom tqdm import tqdm\nimport os \nimport matplotlib.pyplot as plt","886ce34f":"# Run this for Google CoLab\nfrom google.colab import drive\ndrive.mount('\/content\/drive')","a78112f3":"# prepare data\n\nmain_path = '\/content\/drive\/My Drive\/pokemon_data\/smd\/'\ntraining_paths = os.listdir(main_path)[1:]\n# training_data = np.array([])\n\nfor i, im_path in tqdm(enumerate(training_paths)):\n  im_path = main_path + im_path\n  image = Image.open(im_path)\n  # .resize((GENERATE_SQUARE,GENERATE_SQUARE),Image.ANTIALIAS)\n  if i == 0:\n    training_data = np.asarray(np.expand_dims(image, 0))\n  else:\n    training_data = np.vstack((training_data, np.expand_dims(image, 0)))\n\nprint(training_data.shape)\n\ntraining_data_T = [np.fliplr(data) for data in training_data]\ntraining_data_T = np.array(training_data_T)\n\ntrain = np.concatenate((training_data, training_data_T))\nnp.save('\/content\/drive\/My Drive\/pokemon_data\/PokiGan_training_data.npy', train)","bf6c7f2c":"training_data = np.load('\/content\/drive\/My Drive\/pokemon_data\/PokiGan_training_data.npy')\ntraining_data.shape","a2b0a732":"def build_generator(seed_size, channels):\n    model = Sequential()\n\n    model.add(Dense(4*4*256,activation=\"relu\",input_dim=seed_size))\n    model.add(Reshape((4,4,256)))\n\n    model.add(UpSampling2D())\n    model.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(Activation(\"relu\"))\n\n    model.add(UpSampling2D())\n    model.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(Activation(\"relu\"))\n   \n    # Output resolution, additional upsampling\n    for i in range(GENERATE_RES):\n      model.add(UpSampling2D())\n      model.add(Conv2D(128,kernel_size=3,padding=\"same\"))\n      model.add(BatchNormalization(momentum=0.8))\n      model.add(Activation(\"relu\"))\n\n    # Final CNN layer\n    model.add(Conv2D(channels,kernel_size=3,padding=\"same\"))\n    model.add(Activation(\"tanh\"))\n\n    input = Input(shape=(seed_size,))\n    generated_image = model(input)\n\n    return Model(input,generated_image)\n\n\ndef build_discriminator(image_shape):\n    model = Sequential()\n\n    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=image_shape, padding=\"same\"))\n    model.add(LeakyReLU(alpha=0.2))\n\n    model.add(Dropout(0.25))\n    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n\n    model.add(Dropout(0.25))\n    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n\n    model.add(Dropout(0.25))\n    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n\n    model.add(Dropout(0.25))\n    model.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(1, activation='sigmoid'))\n\n    input_image = Input(shape=image_shape)\n\n    validity = model(input_image)\n\n    return Model(input_image, validity)\n  \ndef save_images(cnt,noise):\n  image_array = np.full(( \n      PREVIEW_MARGIN + (PREVIEW_ROWS * (GENERATE_SQUARE+PREVIEW_MARGIN)), \n      PREVIEW_MARGIN + (PREVIEW_COLS * (GENERATE_SQUARE+PREVIEW_MARGIN)), 3), \n      255, dtype=np.uint8)\n  \n  generated_images = generator.predict(noise)\n\n  generated_images = 0.5 * generated_images + 0.5\n\n  image_count = 0\n  for row in range(PREVIEW_ROWS):\n      for col in range(PREVIEW_COLS):\n        r = row * (GENERATE_SQUARE+16) + PREVIEW_MARGIN\n        c = col * (GENERATE_SQUARE+16) + PREVIEW_MARGIN\n        image_array[r:r+GENERATE_SQUARE,c:c+GENERATE_SQUARE] = generated_images[image_count] * 255\n        image_count += 1\n\n          \n  output_path = os.path.join(DATA_PATH,'output')\n  # output_path = DATA_PATH\n\n  if not os.path.exists(output_path):\n    os.makedirs(output_path)\n  \n  filename = os.path.join(output_path,f\"train-{cnt}.png\")\n  im = Image.fromarray(image_array)\n  im.save(filename)","e7398ba2":"GENERATE_RES = 2 # (1=32, 2=64, 3=96, etc.)\nGENERATE_SQUARE = 32 * GENERATE_RES # rows\/cols (should be square)\nIMAGE_CHANNELS = 3\n\n# Preview image \nPREVIEW_ROWS = 15\nPREVIEW_COLS = 15\nPREVIEW_MARGIN = 16\nSAVE_FREQ_IMAGES = 100\nSAVE_FREQ_MODEL = 500\n# Size vector to generate images from\nSEED_SIZE = 100\n\n# Configuration\nDATA_PATH = '\/content\/drive\/My Drive\/pokemon_data'\n","b87100ff":"image_shape = (GENERATE_SQUARE,GENERATE_SQUARE,IMAGE_CHANNELS)\noptimizer = Adam(1.5e-4,0.5) # learning rate and momentum adjusted from paper\n\ndiscriminator = build_discriminator(image_shape)\ndiscriminator.compile(loss=\"binary_crossentropy\",optimizer=optimizer,metrics=[\"accuracy\"])\ngenerator = build_generator(SEED_SIZE,IMAGE_CHANNELS)\n\nrandom_input = Input(shape=(SEED_SIZE,))\n\ngenerated_image = generator(random_input)\n\ndiscriminator.trainable = False\n\nvalidity = discriminator(generated_image)\n\ncombined = Model(random_input,validity)\ncombined.compile(loss=\"binary_crossentropy\",optimizer=optimizer,metrics=[\"accuracy\"])\n","a6174c64":"EPOCHS = 1000\nBATCH_SIZE = 32\n\ny_real = np.ones((BATCH_SIZE,1))\ny_fake = np.zeros((BATCH_SIZE,1))\n\nfixed_seed = np.random.normal(0, 1, (PREVIEW_ROWS * PREVIEW_COLS, SEED_SIZE))\n\ncnt = 1\nfor epoch in range(EPOCHS):\n    idx = np.random.randint(0,training_data.shape[0],BATCH_SIZE)\n    x_real = training_data[idx]\n\n    # Generate some images\n    seed = np.random.normal(0,1,(BATCH_SIZE,SEED_SIZE))\n    x_fake = generator.predict(seed)\n\n    # Train discriminator on real and fake\n    discriminator_metric_real = discriminator.train_on_batch(x_real,y_real)\n    discriminator_metric_generated = discriminator.train_on_batch(x_fake,y_fake)\n    discriminator_metric = 0.5 * np.add(discriminator_metric_real,discriminator_metric_generated)\n    \n    # Train generator on Calculate losses\n    generator_metric = combined.train_on_batch(seed,y_real)\n\n    # Time for an update?\n    if epoch % SAVE_FREQ_IMAGES == 0:\n        save_images(cnt, fixed_seed)\n        cnt += 1\n        print(f\"Epoch {epoch}, Discriminator accuarcy: {discriminator_metric[1]}, Generator accuracy: {generator_metric[1]}\")\n    \n    if epoch % SAVE_FREQ_MODEL == 0:\n        generator.save(os.path.join(DATA_PATH,\"PokiGenartor.h5\"))\n        print('genrator saved!')","824c6222":"fixed_seed = np.random.normal(0, 1, (PREVIEW_ROWS * PREVIEW_COLS, SEED_SIZE))\nsave_images(cnt, fixed_seed)","026cb834":"Next we actually build the discriminator and the generator.  Both will be trained with the Adam optimizer.","1bcb9ffb":"The code below creates the generator and discriminator.","2e7bfd30":"The following packages will be used to implement a basic GAN system in Python\/Keras.","e7885eae":"**PokiGan - pokemon genrator**","181ed7ac":"![train-1%20%281%29.png](attachment:train-1%20%281%29.png)"}}