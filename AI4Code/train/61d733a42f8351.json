{"cell_type":{"4cde2f8d":"code","968d9732":"code","6e22fc35":"code","9a982e6f":"code","e4faec6f":"code","c9aa6bfe":"code","5f0a2233":"code","e0362c51":"code","f7df6235":"code","7d4d0d44":"code","ecb25d5b":"code","19f3d121":"markdown","7b4baa5b":"markdown","5ca2a9b5":"markdown","a889de87":"markdown","b9f2f1dd":"markdown","9d6413b0":"markdown","418374fe":"markdown","fee4fd97":"markdown"},"source":{"4cde2f8d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Convolution2D, MaxPooling2D\nfrom keras.utils import np_utils\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# path to images\npath = '\/kaggle\/input\/animal-image-datasetdog-cat-and-panda\/animals\/'\n\n# animal categories\ncategories = ['dogs', 'panda', 'cats']\n    ","968d9732":"# let's display some of the pictures\n\nfor category in categories:\n    fig, _ = plt.subplots(3,4)\n    fig.suptitle(category)\n    for k, v in enumerate(os.listdir(path+category)[:12]):\n        img = plt.imread(path+category+'\/'+v)\n        plt.subplot(3, 4, k+1)\n        plt.axis('off')\n        plt.imshow(img)\n    plt.show()","6e22fc35":"shape0 = []\nshape1 = []\n\nfor category in categories:\n    for files in os.listdir(path+category):\n        shape0.append(plt.imread(path+category+'\/'+ files).shape[0])\n        shape1.append(plt.imread(path+category+'\/'+ files).shape[1])\n    print(category, ' => height min : ', min(shape0), 'width min : ', min(shape1))\n    print(category, ' => height max : ', max(shape0), 'width max : ', max(shape1))\n    shape0 = []\n    shape1 = []\n","9a982e6f":"# initialize the data and labels\ndata = []\nlabels = []\nimagePaths = []\nHEIGHT = 32\nWIDTH = 55\nN_CHANNELS = 3\n\n# grab the image paths and randomly shuffle them\nfor k, category in enumerate(categories):\n    for f in os.listdir(path+category):\n        imagePaths.append([path+category+'\/'+f, k]) # k=0 : 'dogs', k=1 : 'panda', k=2 : 'cats'\n\nimport random\nrandom.shuffle(imagePaths)\nprint(imagePaths[:10])\n\n# loop over the input images\nfor imagePath in imagePaths:\n    # load the image, resize the image to be HEIGHT * WIDTH pixels (ignoring\n    # aspect ratio) and store the image in the data list\n    image = cv2.imread(imagePath[0])\n    image = cv2.resize(image, (WIDTH, HEIGHT))  # .flatten()\n    data.append(image)\n    \n    # extract the class label from the image path and update the\n    # labels list\n    label = imagePath[1]\n    labels.append(label)\n\n","e4faec6f":"# scale the raw pixel intensities to the range [0, 1]\ndata = np.array(data, dtype=\"float\") \/ 255.0\nlabels = np.array(labels)","c9aa6bfe":"# Let's check everything is ok\nplt.subplots(3,4)\nfor i in range(12):\n    plt.subplot(3,4, i+1)\n    plt.imshow(data[i])\n    plt.axis('off')\n    plt.title(categories[labels[i]])\nplt.show()","5f0a2233":"# partition the data into training and testing splits using 80% of\n# the data for training and the remaining 20% for testing\n(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.2, random_state=42)","e0362c51":"# Preprocess class labels\ntrainY = np_utils.to_categorical(trainY, 3)\n\nprint(trainX.shape)\nprint(testX.shape)\nprint(trainY.shape)\nprint(testY.shape)","f7df6235":"model = Sequential()\n\nmodel.add(Convolution2D(32, (2, 2), activation='relu', input_shape=(HEIGHT, WIDTH, N_CHANNELS)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Convolution2D(32, (2, 2), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(3, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nprint(model.summary())","7d4d0d44":"model.fit(trainX, trainY, batch_size=32, epochs=25, verbose=1)","ecb25d5b":"from numpy import argmax\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\npred = model.predict(testX)\npredictions = argmax(pred, axis=1) # return to label\n\ncm = confusion_matrix(testY, predictions)\n\nfig = plt.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(cm)\nplt.title('Model confusion matrix')\nfig.colorbar(cax)\nax.set_xticklabels([''] + categories)\nax.set_yticklabels([''] + categories)\n\nfor i in range(3):\n    for j in range(3):\n        ax.text(i, j, cm[j, i], va='center', ha='center')\n\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()\n\n\naccuracy = accuracy_score(testY, predictions)\nprint(\"Accuracy : %.2f%%\" % (accuracy*100.0))","19f3d121":"<h1>6. Fit model on training data<\/h1>","7b4baa5b":"<h1>4. Split dataset into train and test set<\/h1>","5ca2a9b5":"Since images have different shapes, let's resize pictures to height = 32 and width = 55.","a889de87":"<h1>2. Pictures shape<\/h1>","b9f2f1dd":"<h1>5. Define model architecture<\/h1>","9d6413b0":"<h1>7. Evaluate model on test data<\/h1>","418374fe":"<h1>3. Preprocess data and label inputs<\/h1>","fee4fd97":"<h1>1. Display some pictures<\/h1>"}}