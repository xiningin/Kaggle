{"cell_type":{"81d2acbc":"code","7aeae64c":"code","170ecf14":"code","42713829":"code","6bdebe19":"code","f9bd2c09":"code","12fb4ca8":"code","3f3fba6c":"code","938d879b":"code","6e9df200":"code","e339cd61":"code","b74faabb":"code","21392216":"code","3932f57d":"code","0ef76dc8":"code","7c1734f5":"code","3e18b0f7":"code","b94a8710":"code","12cf137a":"code","40b25105":"code","69981c03":"code","06eb92ea":"code","e8009a8e":"code","e7ac29ff":"code","7037cb99":"code","a32ded7b":"code","e1b62f0b":"code","06040df0":"code","ef109c9e":"code","2f517845":"code","5c572f4e":"code","327d240d":"code","2d97e614":"markdown","33a8aa55":"markdown","60e36a9a":"markdown","aa1557f5":"markdown","104b2b46":"markdown","475a5907":"markdown","f3042920":"markdown","bb230cb9":"markdown","60b36000":"markdown","cf666a40":"markdown","51a2e892":"markdown","fd4cadcb":"markdown","e2dbdfd7":"markdown","1647c8b6":"markdown","16b20951":"markdown","68e039b0":"markdown"},"source":{"81d2acbc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7aeae64c":"train_data = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')\ntrain_data.shape","170ecf14":"test_data = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/test.csv\")\ntest_data.shape","42713829":"train_data.head(5)","6bdebe19":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","f9bd2c09":"train_data['length'] = train_data['text'].apply(len)\ntrain_data.head(5)","12fb4ca8":"train_data['length'].plot(bins=50,kind='hist')","3f3fba6c":"train_data.length.describe()","938d879b":"train_data[(train_data.length == 7)]","6e9df200":"print(train_data[(train_data.length == 157)]['text'].iloc[0])","e339cd61":"train_data['location'].count()","b74faabb":"train_data.hist(column = 'length', by = 'target',bins = 50, figsize=(12,6))","21392216":"import string\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import CountVectorizer","3932f57d":"def process_text(text):\n    \"\"\"\n    Removes punctuations(if any), stopwords and returns a list words\n    \"\"\"\n    rm_pun = [char for char in text if char not in string.punctuation]\n    rm_pun = ''.join(rm_pun)\n    \n    return [word for word in rm_pun.split() if word.lower() not in stopwords.words('english')]","0ef76dc8":"cv = CountVectorizer(analyzer=process_text).fit(train_data['text'])","7c1734f5":"print(len(cv.vocabulary_))","3e18b0f7":"text10 = train_data['text'][9]\ntext10","b94a8710":"cv10 = cv.transform([text10])\nprint(cv10)","12cf137a":"print(cv.get_feature_names()[5375])\nprint(cv.get_feature_names()[11579])\nprint(cv.get_feature_names()[11856])\nprint(cv.get_feature_names()[13190])\nprint(cv.get_feature_names()[25334])","40b25105":"cv10.shape","69981c03":"train_data_cv = cv.transform(train_data['text'])","06eb92ea":"print(train_data_cv.shape)","e8009a8e":"from sklearn.feature_extraction.text import TfidfTransformer\n\ntfidf = TfidfTransformer().fit(train_data_cv)","e7ac29ff":"tfidf10 = tfidf.transform(cv10)\nprint(tfidf10)","7037cb99":"train_data_tfidf = tfidf.transform(train_data_cv)\nprint(train_data_tfidf.shape)","a32ded7b":"from sklearn.naive_bayes import MultinomialNB\ntarget_model = MultinomialNB().fit(train_data_tfidf, train_data['target'])","e1b62f0b":"print('predicted:', target_model.predict(tfidf10)[0])\nprint('expected:', train_data.target[9])","06040df0":"test_data_cv = cv.transform(test_data['text'])\n\ntest_data_tfidf = tfidf.transform(test_data_cv)","ef109c9e":"sample_submission = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/sample_submission.csv\")","2f517845":"sample_submission['target'] = target_model.predict(test_data_tfidf)","5c572f4e":"sample_submission.head(5)","327d240d":"sample_submission.to_csv(\"submission.csv\", index=False)","2d97e614":"**vector representation - an example**","33a8aa55":"**Text with Maximum length**","60e36a9a":"**lets take text #10 **","aa1557f5":"**Remove punctuations and stopwords**","104b2b46":"**tranforming the entire bag of words into the TF-IDF corpus **","475a5907":"**lets take the exampke of text #10**","f3042920":"# **Predictions for test data**\n\n#test data vector and tf-idf****\n","bb230cb9":"# Naive Bayes Classifier\nTraining the model","60b36000":"# TF-IDF\nTerm Frequency, which measures how frequently a term occurs in a document.\nInverse Document Frequency, which measures how important a term is.\n","cf666a40":"**CountVectorizer - to convert the text into a matrix of token counts****","51a2e892":"# Text Preprocessing","fd4cadcb":"**Model Evaluation**","e2dbdfd7":"# Data Visualization","1647c8b6":"**Texts with minimum length**","16b20951":"# file submission","68e039b0":"**transform the entire text data in the dataframe of train_data**"}}