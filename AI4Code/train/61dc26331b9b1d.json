{"cell_type":{"fda7833b":"code","4b75f1ba":"code","81005572":"code","8f95993f":"code","3b8b4af1":"code","2aab7032":"code","eac68893":"code","45fcdc25":"code","00a8b6f5":"code","2062cd88":"code","2df10e2e":"code","3cd54a87":"code","0f226859":"code","3464ce69":"code","22ead513":"code","6338fa72":"code","f6f4d596":"code","5d4c3cbf":"code","e624954e":"code","b1c75526":"code","c44d2655":"code","d80280d1":"markdown"},"source":{"fda7833b":"# setting up the env... (will take some time, please be patient, require active internet connection)\n\n# clone the repo for running evaluation\n!git clone https:\/\/github.com\/AI4Bharat\/indicTrans.git\n%cd indicTrans\n# clone requirements repositories\n!git clone https:\/\/github.com\/anoopkunchukuttan\/indic_nlp_library.git\n!git clone https:\/\/github.com\/anoopkunchukuttan\/indic_nlp_resources.git\n!git clone https:\/\/github.com\/rsennrich\/subword-nmt.git\n%cd ..\n\n# Install the necessary libraries\n!pip install sacremoses pandas mock sacrebleu tensorboardX pyarrow indic-nlp-library\n! pip install mosestokenizer subword-nmt\n# Install fairseq from source\n!git clone https:\/\/github.com\/pytorch\/fairseq.git\n%cd fairseq\n# !git checkout da9eaba12d82b9bfc1442f0e2c6fc1b895f4d35d\n!pip install --editable .\/\n!python setup.py build_ext --inplace\n%cd ..\n\n# this import might not work without restarting runtime\n# from fairseq import checkpoint_utils, distributed_utils, options, tasks, utils","4b75f1ba":"# english-to-indic tranlated (machine generated dataset)\n# model from https:\/\/indicnlp.ai4bharat.org\/indic-trans\/\n# will take some time, so sit back and sip your coffee! (please avoid downloading again and again, push it to a kaggle dataset :pray:)\n\n!wget https:\/\/storage.googleapis.com\/samanantar-public\/V0.2\/models\/en-indic.zip\n!unzip .\/en-indic.zip\n!rm -f en-indic.zip","81005572":"from fairseq import checkpoint_utils, distributed_utils, options, tasks, utils","8f95993f":"from mosestokenizer import *\nfrom indicnlp.tokenize import sentence_tokenize\n\n# this import might not work without restarting runtime (just restart (clear outputs) and then execute this cell only)\nfrom fairseq import checkpoint_utils, distributed_utils, options, tasks, utils\n\n%cd .\/indicTrans\n# load the tranlation model from that directory\n# from indicTrans.inference.engine import Model # because of this import, we have to do cd...\n# en2indic_model = Model(expdir='\/kaggle\/working\/en-indic')\n# en2indic_model","3b8b4af1":"# let's load the sample squad dataset....\nimport pandas as pd\n\ndf = pd.read_csv(\n    \"\/kaggle\/input\/squad-csv-format\/SQuAD_csv.csv\", \n    usecols=[\"context\", \"question\", \"id\", \"text\", \"answer_start\"],\n    nrows = 2**10, # sample\n)\ndf.drop_duplicates(subset=[\"context\"], inplace=True)\ndf.reset_index(drop=True, inplace=True)\n\nprint(df.shape)\n\n# items to translate\nen_context = list(df[\"context\"].values)\nen_question = list(df[\"question\"].values)\nen_answer_text = list(df[\"text\"].values)\n\ndf.head()","2aab7032":"# writing the paragraphs line-by-line\n\nimport io\nfrom tqdm.auto import tqdm\n\nwith io.open(\"en_paragraphs.txt\", \"w\") as f_ptr:\n    for line in en_context:\n        f_ptr.write(line.replace(\"\\n\", \"\").strip())\n        f_ptr.write(\"\\n\")\n\nwith io.open(\"en_question.txt\", \"w\") as f_ptr:\n    for line in en_question:\n        f_ptr.write(line.replace(\"\\n\", \"\").strip())\n        f_ptr.write(\"\\n\")\n\nwith io.open(\"en_answer_text.txt\", \"w\") as f_ptr:\n    for line in en_answer_text:\n        f_ptr.write(line.strip())\n        f_ptr.write(\"\\n\")","eac68893":"# getting the line counts\n!wc -l \"en_paragraphs.txt\" \"en_answer_text.txt\" \"en_question.txt\"","45fcdc25":"%%writefile joint_translate_updated.sh\n\n#!\/bin\/bash\necho `date`\ninfname=$1\noutfname=$2\nsrc_lang=$3\ntgt_lang=$4\nexp_dir=$5\nref_fname=$6\n\nSRC_PREFIX='SRC'\nTGT_PREFIX='TGT'\n\n#`dirname $0`\/env.sh\nSUBWORD_NMT_DIR='subword-nmt'\nmodel_dir=$exp_dir\/model\ndata_bin_dir=$exp_dir\/final_bin\n\n### normalization and script conversion\n\necho \"Applying normalization and script conversion\"\ninput_size=`python scripts\/preprocess_translate.py $infname $outfname.norm $src_lang true`\necho \"Number of sentences in input: $input_size\"\n\n### apply BPE to input file\n\necho \"Applying BPE\"\npython $SUBWORD_NMT_DIR\/subword_nmt\/apply_bpe.py \\\n    -c $exp_dir\/vocab\/bpe_codes.32k.${SRC_PREFIX} \\\n    --vocabulary $exp_dir\/vocab\/vocab.$SRC_PREFIX \\\n    --vocabulary-threshold 5 \\\n    < $outfname.norm \\\n    > $outfname._bpe\n\n# not needed for joint training\n# echo \"Adding language tags\"\npython scripts\/add_tags_translate.py $outfname._bpe $outfname.bpe $src_lang $tgt_lang\n\n### run decoder\n\necho \"Decoding\"\n\nsrc_input_bpe_fname=$outfname.bpe\ntgt_output_fname=$outfname\n\nfairseq-interactive  $data_bin_dir \\\n    -s $SRC_PREFIX -t $TGT_PREFIX \\\n    --distributed-world-size 1 --fp16 \\\n    --path $model_dir\/checkpoint_best.pt \\\n    --batch-size 32 --buffer-size 1024 --data-buffer-size 8 --beam 5 --remove-bpe \\\n    --skip-invalid-size-inputs-valid-test \\\n    --user-dir model_configs \\\n    --input $src_input_bpe_fname  >  $tgt_output_fname.log 2>&1\n\n\necho \"Extracting translations, script conversion and detokenization\"\n# this part reverses the transliteration from devnagiri script to target lang and then detokenizes it.\npython scripts\/postprocess_translate.py $tgt_output_fname.log $tgt_output_fname $input_size $tgt_lang true\necho \"Translation completed\"","00a8b6f5":"%%time\n\n# joint_translate.sh is a shell script that takes args in the following order as inputs <src_file>, <output_fname>, <src_lang>, <tgt_lang>, <model_folder>\n# it's quite fast if you are using GPU, do increase the. batch size from 64 as well in the shell snip that's hard-coded..\n# <6 mins for ~90k sentences is not bad at all....\n\n# src_file -> input text file to be translated\n# output_fname -> name of the output file (will get created) containing the model predictions\n# src_lang -> source lang code of the input text ( in this case we are using en-indic model and hence src_lang would be 'en')\n# tgt_lang -> target lang code of the input text ( tgt lang for en-indic model would be any of the 11 indic langs we trained on:\n# model_folder -> where's the model file located\n\n\n!chmod 777 .\/joint_translate_updated.sh\n\n!.\/joint_translate_updated.sh en_paragraphs.txt ta_paragraphs.txt \"en\" \"ta\" '..\/en-indic'\n!.\/joint_translate_updated.sh en_question.txt ta_question.txt \"en\" \"ta\" '..\/en-indic'\n!.\/joint_translate_updated.sh en_answer_text.txt ta_answer_text.txt \"en\" \"ta\" '..\/en-indic'","2062cd88":"%%time\n\n# en_context, en_question, en_answer_text -- for english stuff\n\n# read the context from the file \"ta_paragraphs.txt\"\nwith io.open(\"ta_paragraphs.txt\", \"r\") as f_ptr:\n    ta_context = [line.strip() for line in f_ptr]\n\n# read the context from the file \"ta_question.txt\"\nwith io.open(\"ta_question.txt\", \"r\") as f_ptr:\n    ta_question = [line.strip() for line in f_ptr]\n\n# read the context from the file \"ta_answer_text.txt\"\nwith io.open(\"ta_answer_text.txt\", \"r\") as f_ptr:\n    ta_en_answer_text = [line.strip() for line in f_ptr]","2df10e2e":"cnt = 0\ngood_ids = set()\nfor idx in range(len(ta_en_answer_text)):\n    if ta_en_answer_text[idx] in ta_context[idx]:\n        # basically naswer is present as-is in the translated text\n        cnt += 1\n        good_ids.add(idx)\ncnt \/ len(ta_en_answer_text), len(good_ids) # 22% is not bad!","3cd54a87":"import pickle\n\nwith open(\"ta_question.pkl\", \"wb\") as f_ptr:\n    pickle.dump(ta_question, f_ptr)\n\nwith open(\"ta_en_answer_text.pkl\", \"wb\") as f_ptr:\n    pickle.dump(ta_en_answer_text, f_ptr)","0f226859":"! cp \"ta_paragraphs.txt\" \"\/kaggle\/working\"\n! cp \"ta_question.txt\" \"\/kaggle\/working\"\n! cp \"ta_answer_text.txt\" \"\/kaggle\/working\"\n\n! cp \"en_paragraphs.txt\" \"\/kaggle\/working\"\n! cp \"en_question.txt\" \"\/kaggle\/working\"\n! cp \"en_answer_text.txt\" \"\/kaggle\/working\"\n\n! cp \"ta_en_answer_text.pkl\" \"\/kaggle\/working\"\n! cp \"ta_question.pkl\" \"\/kaggle\/working\"","3464ce69":"# prepare the dataframe that we can use directly.\n# sample data\nta_question[0], ta_en_answer_text[0], ta_context[0], en_context[0], en_answer_text[0], en_question[0]","22ead513":"from dataclasses import dataclass\n\n@dataclass\nclass TamilExtraData:\n    ta_context :str\n    ta_question :str\n    ta_answer_text :str\n    en_context :str\n    en_question :str\n    en_answer_text :str","6338fa72":"final_data = []\nfor idx in good_ids:\n    final_data.append(\n        TamilExtraData(\n            ta_context=ta_context[idx], ta_answer_text=ta_en_answer_text[idx], ta_question=ta_question[idx],\n            en_context=en_context[idx], en_answer_text=en_answer_text[idx], en_question=en_question[idx],\n        ).__dict__\n    )","f6f4d596":"df = pd.DataFrame.from_records(final_data)\ndf[\"answer_start\"] = df[[\"ta_context\", \"ta_answer_text\"]].apply(lambda row: row[0].find(row[1]), axis=1)\n# df[\"answer_end\"] = df[[\"context\", \"answer_text\"]].apply(lambda row: row[0].find(row[1]) + len(row[1]), axis=1)\ndf","5d4c3cbf":"df.to_csv(\"\/kaggle\/working\/tamil_extra_translated_data.csv\", index=None) # almost extra 1000 tamil dataset rows... Enjoy People...","e624954e":"# clean-up cell [be SUPER careful when you run this guy]\n!rm -rf *\n%cd ..\n!rm -rf .\/en-indic\/\n!rm -rf .\/fairseq\/\n!rm -rf .\/indicTrans\/\n!ls","b1c75526":"!ls # much better!","c44d2655":"# translated texts...\ndf","d80280d1":"- We are trying to translate a [sample] of the squad dataset into tamil and building one for us!\n\n### blue-print...\n- In the first cell, we do some house keeping stuff and setup precisely what we need.\n- In the second cell, we are downloading the model which can translate to 12 different indic languages.\n\n- Rest cells, I believe are intuitive :) (they include doing some prep stuff, laoding model and finally translating them)\n\n\n\n# citation\n\n**Give credits where it's due....**\n\n```\n@misc{ramesh2021samanantar,\n      title={Samanantar: The Largest Publicly Available Parallel Corpora Collection for 11 Indic Languages},\n      author={Gowtham Ramesh and Sumanth Doddapaneni and Aravinth Bheemaraj and Mayank Jobanputra and Raghavan AK and Ajitesh Sharma and Sujit Sahoo and Harshita Diddee and Mahalakshmi J and Divyanshu Kakwani and Navneet Kumar and Aswin Pradeep and Kumar Deepak and Vivek Raghavan and Anoop Kunchukuttan and Pratyush Kumar and Mitesh Shantadevi Khapra},\n      year={2021},\n      eprint={2104.05596},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n```\n\nSquad Dataset Used from Kaggle Datasets (by ananthu017) Ref -> https:\/\/www.kaggle.com\/ananthu017\/squad-csv-format\n\n####\n\n> - **PS Let me know if you are looking for a teammate!**\n> - **If this helped, do let me know if there were improvements!\"\n\n\n# What you get as output from the kernel?\n- Extra ~1k Tamil q&a machine translated for training! (Actually it's infinite because you can translate as many as you want)\n\n# version notes\n\n- in v3, Have updated the snips to remove newlines chars."}}