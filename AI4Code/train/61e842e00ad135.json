{"cell_type":{"a1a1fd74":"code","c2e72df5":"code","3dc2174a":"code","cf491560":"code","082be333":"code","e9a1d338":"code","90c36896":"code","3d8303de":"code","7a37ded1":"code","1483b963":"code","2831ddbf":"code","cc3e48fd":"markdown","76188cc2":"markdown","955c2530":"markdown","57eef8c1":"markdown","559afb2f":"markdown","b1781d26":"markdown","d788a77f":"markdown","ef9a891f":"markdown","a304dcd9":"markdown"},"source":{"a1a1fd74":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.metrics import mean_absolute_error\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=Warning)\n\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object and col_type.name != 'category' and 'datetime' not in col_type.name:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        elif 'datetime' not in col_type.name:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df","c2e72df5":"df_trn = pd.read_csv('..\/input\/pubg-finish-placement-prediction\/train.csv',  nrows=None)\ndf_trn = reduce_mem_usage(df_trn)\n\ndf_tst = pd.read_csv('..\/input\/pubg-finish-placement-prediction\/test.csv',  nrows=None)\ndf_tst = reduce_mem_usage(df_tst)","3dc2174a":"lgbm_trn = pd.read_csv('..\/input\/pubg-survivor-kit\/oof_lgbm1_reg.csv')\nlgbm_trn.columns = [c if 'winPlacePerc' not in c else c+'Pred' for c in lgbm_trn.columns]\n\nlgbm_tst = pd.read_csv('..\/input\/pubg-survivor-kit\/sub_lgbm1_reg.csv')\nlgbm_tst.columns = [c if 'winPlacePerc' not in c else c+'Pred' for c in lgbm_tst.columns]","cf491560":"df_trn2 = pd.concat([df_trn, lgbm_trn['winPlacePercPred']], axis=1)\ndf_tst2 = pd.concat([df_tst, lgbm_tst['winPlacePercPred']], axis=1)","082be333":"df_trn3 = df_trn2.groupby(['matchId','groupId'])['winPlacePercPred'].agg('mean').groupby('matchId').rank(pct=True).reset_index()\ndf_trn3.columns = [c if 'winPlacePerc' not in c else c+'_Rank' for c in df_trn3.columns]\ndf_trn3 = df_trn3.merge(df_trn2, how='left', on=['matchId','groupId'])","e9a1d338":"print('MAE by default: {:.4f}'.format(\n    mean_absolute_error(df_trn3['winPlacePerc'], df_trn3['winPlacePercPred'])\n                                 )\n     )","90c36896":"print('MAE after group ranking: {:.4f}'.format(\n    mean_absolute_error(df_trn3['winPlacePerc'], df_trn3['winPlacePercPred_Rank'])\n                                 )\n     )","3d8303de":"df_tst3 = df_tst2.groupby(['matchId','groupId'])['winPlacePercPred'].agg('mean').groupby('matchId').rank(pct=True).reset_index()\ndf_tst3.columns = [c if 'winPlacePerc' not in c else c+'_Rank' for c in df_tst3.columns]\ndf_tst3 = df_tst2.merge(df_tst3, how='left', on=['matchId','groupId'])","7a37ded1":"del lgbm_tst['winPlacePercPred']\nlgbm_tst['winPlacePerc'] = df_tst3['winPlacePercPred_Rank']","1483b963":"lgbm_tst.to_csv('sub_lgbm_group_ranked_within_game.csv', index=False)","2831ddbf":"!head sub_lgbm_group_ranked_within_game.csv","cc3e48fd":"# winPlacePct as ranked prediction\nI've noticed that in practise `winPlacePct` is:\n\n- fixed within a group\n- within each game the group scores spam from 0 to 1 (inclusive) with a step of `1\/numGroups`.\n\nThe conclusion is that in practice we need to predict **the order** of places for teams (=groups) **within each game(=match)**. It might have been obvious for everyone, but not to me. \n\nMajor consequences are:\n\n- it seems to be meaningful and beneficial **to train on group-level instead of the user-level**\n- it would be useful to be able to put constraints in training to fix the range to [0,1] within each game\n- as post-processing, it is useful to **calculate ranks** and use those as predictions","76188cc2":"Merge predictions with the main datasets","955c2530":"As predictions, I will use output of my user-level kernel, that procudes OOF predictions together with the submission predictions: https:\/\/www.kaggle.com\/mlisovyi\/pubg-survivor-kit\n\nThis allows us to estimate the evaluation metric on OOF and thus to judge about expected level of improvement","57eef8c1":"### Read predictions for the user-level model (OOF and submission)","559afb2f":"## Store submission","b1781d26":"# Rank mean predictions for each group within each game (test)","d788a77f":"# Rank mean predictions for each group within each game (train)","ef9a891f":"Note that here we use an average over player ranking within each team (and that's what many people in public kernels copied over). This is a custom choice. \n\nIt was checked that average performed better than median, min or max.","a304dcd9":"**After group ranking the MAE metric significantly improves**"}}