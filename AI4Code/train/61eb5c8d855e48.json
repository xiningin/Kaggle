{"cell_type":{"91c32f82":"code","14e3499a":"code","1bae9eaf":"code","85e76437":"code","f314a4d9":"code","fc02b982":"code","3f54ee5f":"code","923ab0b3":"code","1506931b":"code","9d3a2b94":"code","76359c46":"code","7834e414":"code","45424232":"code","29d36e9d":"code","928d5ac5":"code","b01516c2":"code","0602361d":"code","3ed1d0e2":"code","47ff1bb7":"code","ecc04592":"code","2276359d":"code","b62709ae":"code","f7499a15":"code","dd634123":"code","c0096a0a":"code","a40ccc1c":"code","ef5a841a":"code","1cf3e590":"code","bde7987c":"code","301d24d5":"code","03680f7d":"code","5f3190b7":"code","1e6ad799":"code","46a27ec8":"code","e76bcc1a":"code","8514b571":"code","aebd12b5":"code","37310751":"code","b8f02e9e":"code","8cd6ae2c":"code","8b527da7":"code","b18d9800":"code","8692ae72":"code","92709eee":"code","d227c991":"code","ed51fbbb":"code","2673de7d":"code","5333b5fa":"code","add8ed49":"code","f50b4f37":"code","72157a04":"code","964d3c3f":"code","bd80692a":"code","9b79de32":"code","954fdff5":"code","5cb1dba3":"code","d8e12d61":"code","88b72527":"code","d4341b1a":"code","711911ef":"code","424b7062":"code","e0561408":"code","0bb9ef4f":"code","5cf805e3":"code","db4e584d":"code","c489940c":"code","a5d9beff":"code","aa161306":"code","9ebd5749":"code","ee64184e":"code","c6076694":"code","13abf4da":"markdown","5bbda53e":"markdown","f806b55b":"markdown","8b0e5b99":"markdown","4e334a26":"markdown","e2a7b765":"markdown","babb52fd":"markdown","2f22a97e":"markdown","8369c60c":"markdown","5fc5cd3c":"markdown","48945aa9":"markdown","9414504c":"markdown","d38173db":"markdown","53f61912":"markdown","5d90773e":"markdown","8e2003bc":"markdown","709dd3e9":"markdown","cefae44e":"markdown","98f0da21":"markdown","0242b011":"markdown","32c762d6":"markdown","36433bd5":"markdown","46dd9b56":"markdown","b7b2fe41":"markdown","9acaf9a0":"markdown","cb5d1893":"markdown","eb98d30c":"markdown"},"source":{"91c32f82":"!pip install pyod","14e3499a":"import numpy as np \nimport pandas as pd\n\nimport seaborn as sns\n\nimport plotly.express as px\nimport plotly.figure_factory as ff\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score, confusion_matrix\nfrom sklearn.feature_selection import RFE\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.cluster import KMeans\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\n\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\n\nimport optuna\nfrom optuna.samplers import TPESampler\n\nfrom pyod.models.copod import COPOD","1bae9eaf":"HEIGHT = 500\nWIDTH = 700\nNBINS = 50\nSCATTER_SIZE=700","85e76437":"df = pd.read_csv('\/kaggle\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')\ndf.head()","f314a4d9":"for col in df.columns:\n    print(col, str(round(100* df[col].isnull().sum() \/ len(df), 2)) + '%')","fc02b982":"df.describe()","3f54ee5f":"def plot_histogram(dataframe, column, color, bins, title, width=WIDTH, height=HEIGHT):\n    figure = px.histogram(\n        dataframe, \n        column, \n        color=color,\n        nbins=bins, \n        title=title, \n        width=width,\n        height=height\n    )\n    figure.show()","923ab0b3":"plot_histogram(df, 'age', 'sex', NBINS, 'Patients age distribution')","1506931b":"plot_histogram(df, 'age', 'DEATH_EVENT', NBINS, 'Patients age distribution')","9d3a2b94":"fig = px.box(\n    df, \n    x=\"DEATH_EVENT\", \n    y=\"age\", \n    points='all',\n    title='Age & DEATH_EVENT box plot',\n    width=WIDTH,\n    height=HEIGHT    \n)\n\nfig.show()","76359c46":"ds = df['anaemia'].value_counts().reset_index()\n\nds.columns = [\n    'anaemia', \n    'count'\n]\n\nfig = px.pie(\n    ds, \n    values='count', \n    names=\"anaemia\", \n    title='Anaemia bar chart', \n    width=WIDTH, \n    height=HEIGHT\n)\n\nfig.show()","7834e414":"plot_histogram(\n    df, \n    'creatinine_phosphokinase', \n    'DEATH_EVENT', \n    2 * NBINS, \n    'Creatinine phosphokinase distribution'\n)","45424232":"ds = df['diabetes'].value_counts().reset_index()\n\nds.columns = [\n    'diabetes', \n    'count'\n]\n\nfig = px.pie(\n    ds, \n    values='count', \n    names=\"diabetes\", \n    title='Diabetes bar chart', \n    width=WIDTH, \n    height=HEIGHT\n)\n\nfig.show()","29d36e9d":"fig = px.histogram(\n    df, \n    \"ejection_fraction\", \n    color='DEATH_EVENT',\n    nbins=NBINS, \n    title='Ejection_fraction distribution',\n    width=WIDTH,\n    height=HEIGHT\n)\n\nfig.show()","928d5ac5":"fig = px.box(\n    df, \n    x=\"DEATH_EVENT\", \n    y=\"ejection_fraction\", \n    points='all',\n    title='Ejection_fraction & DEATH_EVENT box plot',\n    width=WIDTH,\n    height=HEIGHT\n)\n\nfig.show()","b01516c2":"ds = df['high_blood_pressure'].value_counts().reset_index()\n\nds.columns = [\n    'high_blood_pressure', \n    'count'\n]\n\nfig = px.pie(\n    ds, \n    values='count', \n    names=\"high_blood_pressure\", \n    title='High blood pressure bar chart', \n    width=WIDTH, \n    height=HEIGHT\n)\n\nfig.show()","0602361d":"fig = px.histogram(\n    df, \n    \"platelets\", \n    nbins=NBINS, \n    color='DEATH_EVENT', \n    title='Platelets distribution',\n    width=WIDTH,\n    height=HEIGHT\n)\n\nfig.show()","3ed1d0e2":"fig = px.box(\n    df, \n    x=\"DEATH_EVENT\", \n    y=\"platelets\", \n    points='all',\n    title='Platelets & DEATH_EVENT box plot',\n    width=WIDTH,\n    height=HEIGHT\n)\n\nfig.show()","47ff1bb7":"fig = px.histogram(\n    df, \n    \"serum_creatinine\", \n    nbins=NBINS, \n    color='DEATH_EVENT',\n    title='Serum creatinine distribution',\n    width=WIDTH,\n    height=HEIGHT\n)\n\nfig.show()","ecc04592":"fig = px.box(\n    df, \n    x=\"DEATH_EVENT\", \n    y=\"serum_creatinine\", \n    points='all',\n    title='Serum_creatinine & DEATH_EVENT box plot',\n    width=WIDTH,\n    height=HEIGHT\n)\n\nfig.show()","2276359d":"fig = px.histogram(\n    df, \n    \"serum_sodium\",\n    color='DEATH_EVENT',\n    nbins=NBINS, \n    title='Serum sodium distribution', \n    width=WIDTH,\n    height=HEIGHT\n)\n\nfig.show()","b62709ae":"fig = px.box(\n    df, \n    x=\"DEATH_EVENT\", \n    y=\"serum_sodium\", \n    points='all',\n    title='Serum_sodium & DEATH_EVENT box plot',\n    width=WIDTH,\n    height=HEIGHT\n)\n   \nfig.show()","f7499a15":"ds = df['sex'].value_counts().reset_index()\n\nds.columns = [\n    'sex', \n    'count'\n]\n\nfig = px.pie(\n    ds, \n    values='count', \n    names=\"sex\", \n    title='Gender bar chart', \n    width=WIDTH, \n    height=HEIGHT\n)\n\nfig.show()","dd634123":"ds = df['smoking'].value_counts().reset_index()\nds.columns = [\n    'smoking', \n    'count'\n]\n\nfig = px.pie(\n    ds, \n    values='count', \n    names=\"smoking\", \n    title='Smoking bar chart', \n    width=WIDTH, \n    height=HEIGHT\n)\n\nfig.show()","c0096a0a":"ds = df['DEATH_EVENT'].value_counts().reset_index()\n\nds.columns = [\n    'DEATH_EVENT', \n    'count'\n]\n\nfig = px.pie(\n    ds, \n    values='count', \n    names=\"DEATH_EVENT\", \n    title='DEATH_EVENT bar chart', \n    width=WIDTH, \n    height=HEIGHT\n)\n\nfig.show()","a40ccc1c":"sun = df.groupby(['sex', 'diabetes', 'smoking', 'DEATH_EVENT'])['age'].count().reset_index()\n\nsun.columns = [\n    'sex', \n    'diabetes', \n    'smoking', \n    'DEATH_EVENT', \n    'count'\n]\n\nsun.loc[sun['sex'] == 0, 'sex'] = 'female'\nsun.loc[sun['sex'] == 1, 'sex'] = 'male'\nsun.loc[sun['smoking'] == 0, 'smoking'] = \"doesn't smoke\"\nsun.loc[sun['smoking'] == 1, 'smoking'] = 'smoke'\nsun.loc[sun['diabetes'] == 0, 'diabetes'] = \"no diabetes\"\nsun.loc[sun['diabetes'] == 1, 'diabetes'] = 'diabetes'\nsun.loc[sun['DEATH_EVENT'] == 0,'DEATH_EVENT'] = \"ALIVE_EVENT\"\nsun.loc[sun['DEATH_EVENT'] == 1, 'DEATH_EVENT'] = 'DEATH_EVENT'\n\nfig = px.sunburst(\n    sun, \n    path=[\n        'sex',\n        'diabetes',\n        'smoking', \n        'DEATH_EVENT'\n    ], \n    values='count', \n    title='Sunburst chart for all patients',\n    width=WIDTH,\n    height=HEIGHT\n)\n\nfig.show()","ef5a841a":"df = df.drop(['time'], axis=1)","1cf3e590":"f = plt.figure(\n    figsize=(12, 12)\n)\n\nplt.matshow(\n    df.corr(), \n    fignum=f.number\n)\n\nplt.xticks(\n    range(df.shape[1]), \n    df.columns, \n    fontsize=13, \n    rotation=65\n)\n\nplt.yticks(range(df.shape[1]), df.columns, fontsize=13)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=14)","bde7987c":"X = df.copy()\ny = X['DEATH_EVENT']\nX = X.drop(['DEATH_EVENT'], axis=1)","301d24d5":"pca = PCA(\n    n_components=3, \n    random_state=666\n)\n\nX = pd.DataFrame(pca.fit_transform(X))\nX['target'] = y\n\nX","03680f7d":"fig = px.scatter_3d(\n    X, \n    x=0, \n    y=1,\n    z=2, \n    color=\"target\", \n    title='3d scatter for PCA',\n    width=SCATTER_SIZE,\n    height=SCATTER_SIZE\n)\n\nfig.show()","5f3190b7":"X = df.copy()\ny = X['DEATH_EVENT']\nX = X.drop(['DEATH_EVENT'], axis=1)","1e6ad799":"pca = PCA(\n    n_components=2, \n    random_state=666\n)\n\nX = pd.DataFrame(pca.fit_transform(X))\nX['target'] = y\n\nX","46a27ec8":"fig = px.scatter(\n    X, \n    x=0, \n    y=1,\n    color=\"target\", \n    title='2d scatter for PCA',\n    width=SCATTER_SIZE,\n    height=SCATTER_SIZE\n)\n\nfig.show()","e76bcc1a":"X = df.copy()\ny = X['DEATH_EVENT']\nX = X.drop(['DEATH_EVENT'], axis=1)","8514b571":"kmeans = KMeans(\n    n_clusters=2, \n    random_state=666\n).fit(X)","aebd12b5":"train = X.copy()\ntrain['cluster'] = kmeans.labels_\ntrain['target'] = y\n\ntrain","37310751":"print('Kmeans accuracy: ', accuracy_score(train['target'], train['cluster']))\nprint('Kmeans f1_score: ', f1_score(train['target'], train['cluster']))","b8f02e9e":"def plot_confusion_matrix(y_true, y_pred):\n    cm = confusion_matrix(y_true, y_pred)\n    ax= plt.subplot()\n    sns.heatmap(\n        cm, \n        annot=True, \n        ax=ax, \n        fmt='g'\n    )\n\n    ax.set_xlabel('Predicted labels')\n    ax.set_ylabel('True labels')","8cd6ae2c":"plot_confusion_matrix(\n    train['target'], \n    train['cluster']\n)","8b527da7":"response = train['target']\ntrain = train.drop(['target', 'cluster'], axis=1)","b18d9800":"clf = COPOD(\n    contamination=0.3\n)\nclf.fit(train)","8692ae72":"cluster = clf.predict(train)\ntrain['cluster'] = cluster\ntrain['target'] = response\ntrain","92709eee":"train['cluster'].value_counts()","d227c991":"print('COPOD accuracy: ', accuracy_score(train['target'], train['cluster']))\nprint('COPOD f1_score: ', f1_score(train['target'], train['cluster']))","ed51fbbb":"plot_confusion_matrix(\n    train['target'], \n    train['cluster']\n)","2673de7d":"train = train.drop(['target', 'cluster'], axis=1)\ntrain","5333b5fa":"X_embedded = TSNE(\n    n_components=2, \n    random_state=666\n).fit_transform(train)\nX_embedded = pd.DataFrame(X_embedded)","add8ed49":"analysis = pd.DataFrame()\nanalysis['color'] = response\nanalysis['X'] = X_embedded[0]\nanalysis['Y'] = X_embedded[1]\n\nfig = px.scatter(\n    analysis, \n    x='X', \n    y='Y', \n    color=\"color\", \n    title='TSNE for dataset',\n    width=SCATTER_SIZE,\n    height=SCATTER_SIZE\n)\n\nfig.show()","f50b4f37":"X_embedded = TSNE(\n    n_components=3, \n    random_state=666\n).fit_transform(train)\nX_embedded = pd.DataFrame(X_embedded)","72157a04":"analysis = pd.DataFrame()\nanalysis['color'] = response\nanalysis['X'] = X_embedded[0]\nanalysis['Y'] = X_embedded[1]\nanalysis['Z'] = X_embedded[2]\n\nfig = px.scatter_3d(\n    analysis, \n    x='X', \n    y='Y',\n    z='Z', \n    color=\"color\", \n    title='3d scatter for TSNE',\n    width=SCATTER_SIZE,\n    height=SCATTER_SIZE\n)\n\nfig.show()","964d3c3f":"X, X_test, y, y_test = train_test_split(X, y, random_state=0, test_size=0.2, shuffle=True)","bd80692a":"model = LogisticRegression(random_state=0)\nmodel.fit(X, y)\npreds = model.predict(X_test)\n\nprint('Logistic Regression ', accuracy_score(y_test, preds))","9b79de32":"plot_confusion_matrix(\n    y_test, \n    preds\n)","954fdff5":"print('Logistic Regression f1-score', f1_score(y_test, preds))\nprint('Logistic Regression precision', precision_score(y_test, preds))\nprint('Logistic Regression recall', recall_score(y_test, preds))","5cb1dba3":"model = LGBMClassifier(random_state=0)\nmodel.fit(X, y)\npreds = model.predict(X_test)\n\nprint('LightGBM f1-score', f1_score(y_test, preds))\nprint('LightGBM precision', precision_score(y_test, preds))\nprint('LightGBM recall', recall_score(y_test, preds))","d8e12d61":"plot_confusion_matrix(y_test, preds)","88b72527":"for col in X.columns:\n    if abs(X[col].corr(y)) < 0.05:\n        X = X.drop([col], axis=1)\n        X_test = X_test.drop([col], axis=1)","d4341b1a":"X","711911ef":"model = LGBMClassifier(random_state=0)\nmodel.fit(X, y)\npreds = model.predict(X_test)\n\nprint('LightGBM f1-score', f1_score(y_test, preds))\nprint('LightGBM precision', precision_score(y_test, preds))\nprint('LightGBM recall', recall_score(y_test, preds))","424b7062":"plot_confusion_matrix(y_test, preds)","e0561408":"model = XGBClassifier(random_state=666)\nmodel.fit(X, y)\npreds = model.predict(X_test)\n\nprint('XGBClassifier f1-score', f1_score(y_test, preds))\nprint('XGBClassifier precision', precision_score(y_test, preds))\nprint('XGBClassifier recall', recall_score(y_test, preds))","0bb9ef4f":"plot_confusion_matrix(y_test, preds)","5cf805e3":"def create_model(trial):\n    max_depth = trial.suggest_int(\"max_depth\", 2, 6)\n    n_estimators = trial.suggest_int(\"n_estimators\", 1, 100)\n    learning_rate = trial.suggest_uniform('learning_rate', 0.0000001, 1)\n    num_leaves = trial.suggest_int(\"num_leaves\", 2, 5000)\n    min_child_samples = trial.suggest_int('min_child_samples', 3, 200)\n    model = LGBMClassifier(\n        learning_rate=learning_rate, \n        n_estimators=n_estimators, \n        max_depth=max_depth,\n        num_leaves=num_leaves, \n        min_child_samples=min_child_samples,\n        random_state=666\n    )\n    return model\n\nsampler = TPESampler(seed=666)\ndef objective(trial):\n    model = create_model(trial)\n    model.fit(X, y)\n    preds = model.predict(X_test)\n    return f1_score(y_test, preds)\n\nstudy = optuna.create_study(direction=\"maximize\", sampler=sampler)\nstudy.optimize(objective, n_trials=200)\n\nlgb_params = study.best_params\nlgb_params['random_state'] = 666\nlgb = LGBMClassifier(**lgb_params)\nlgb.fit(X, y)\npreds = lgb.predict(X_test)\n\nprint('Optimized LightGBM: ', accuracy_score(y_test, preds))\nprint('Optimized LightGBM f1-score', f1_score(y_test, preds))\nprint('Optimized LightGBM precision', precision_score(y_test, preds))\nprint('Optimized LightGBM recall', recall_score(y_test, preds))","db4e584d":"plot_confusion_matrix(y_test, preds)","c489940c":"check = X_test.copy()\ncheck['preds'] = preds\ncheck['preds_fixed'] = preds\n\ncheck.loc[check['age']>90, 'preds_fixed'] = 1\ncheck.loc[check['age']<42, 'preds_fixed'] = 0\ncheck.loc[check['age'].isin([66, 67, 78, 79]), 'preds_fixed'] = 0\ncheck.loc[check['ejection_fraction']<17, 'preds_fixed'] = 1\ncheck.loc[check['serum_creatinine']>6.1, 'preds_fixed'] = 1","a5d9beff":"preds = check['preds_fixed']\n\nprint('Postprocessed accuracy: ', accuracy_score(y_test, preds))\nprint('Postprocessed f1-score', f1_score(y_test, preds))\nprint('Postprocessed precision', precision_score(y_test, preds))\nprint('Postprocessed recall', recall_score(y_test, preds))","aa161306":"plot_confusion_matrix(y_test, preds)","9ebd5749":"for i in range(1, len(X.columns)+1):\n    rfe = RFE(\n        estimator=DecisionTreeClassifier(\n            random_state=0\n        ), \n        n_features_to_select=i\n    )\n    pipeline = Pipeline(\n        steps=[\n            ('s', rfe),\n            ('m', LGBMClassifier(random_state=0))\n        ]\n    )\n    pipeline.fit(X, y)\n    preds = pipeline.predict(X_test)\n    \n    print('Number of features: ', i)\n    print('LightGBM f1-score', f1_score(y_test, preds))","ee64184e":"def create_model(trial):\n    rfe = RFE(\n        estimator=DecisionTreeClassifier(random_state=0), \n        n_features_to_select=2\n    )\n    max_depth = trial.suggest_int(\"max_depth\", 2, 8)\n    n_estimators = trial.suggest_int(\"n_estimators\", 1, 200)\n    learning_rate = trial.suggest_uniform('learning_rate', 0.0000001, 1)\n    num_leaves = trial.suggest_int(\"num_leaves\", 2, 5000)\n    min_child_samples = trial.suggest_int('min_child_samples', 3, 200)\n    model = Pipeline(\n        steps=[\n            ('s', rfe), \n            ('m', \n             LGBMClassifier(\n                 learning_rate=learning_rate, \n                 n_estimators=n_estimators, \n                 max_depth=max_depth, \n                 num_leaves=num_leaves, \n                 min_child_samples=min_child_samples, \n                 random_state=0\n             )\n            )\n        ]\n    )\n    return model\n\ndef objective(trial):\n    model = create_model(trial)\n    model.fit(X, y)\n    preds = model.predict(X_test)\n    return f1_score(y_test, preds)\n\nstudy = optuna.create_study(direction=\"maximize\", sampler=sampler)\nstudy.optimize(objective, n_trials=150)\n\nlgb_params = study.best_params\nlgb_params['random_state'] = 666\nlgb = LGBMClassifier(**lgb_params)\nrfe = RFE(\n    estimator=DecisionTreeClassifier(\n        random_state=666\n    ), \n    n_features_to_select=2\n)\nmodel = Pipeline(\n    steps=[\n        ('s',rfe), \n        ('m', lgb)\n    ]\n)\nmodel.fit(X, y)\npreds = model.predict(X_test)\n\nprint('Optimized LightGBM: ', accuracy_score(y_test, preds))\nprint('Optimized LightGBM f1-score', f1_score(y_test, preds))\nprint('Optimized LightGBM precision', precision_score(y_test, preds))\nprint('Optimized LightGBM recall', recall_score(y_test, preds))","c6076694":"plot_confusion_matrix(y_test, preds)","13abf4da":"Correlation matrix.","5bbda53e":"Now let's check anaemia cases.","f806b55b":"Install package for outlier detection algorithms.","8b0e5b99":"The results are not really better. Let's try to drop features with absolute correlation with target less than 0.05.","4e334a26":"Lets try XGBoost model.","e2a7b765":"We can see that f1-score became better.","babb52fd":"Let's try to improve our f1-score and use LightGBM model.","2f22a97e":"We can see good scores for N_features = 2 and N_features = 8. For second case we already know results of optimization. Let's check the same for N_feauters = 2.","8369c60c":"Now we will try to improve model using Recursive feature elimination and find best the set of features for empty LightGBM model.","5fc5cd3c":"Let's try unsupervised learning first and will use KMeans algorithm.","48945aa9":"<a id=\"2\"><\/a>\n<h2 style='background:purple; border:0; color:white'><center>2. Data transformations<center><h2>","9414504c":"The score for LightGBM became better. Lets do hyperparameters optimization next. We will use optuna for it.","d38173db":"Let's check a confusion matrix.","53f61912":"First we will look at Age distribution.","5d90773e":"<a id=\"top\"><\/a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:purple; border:0' role=\"tab\" aria-controls=\"home\"><center>Quick navigation<\/center><\/h3>\n\n* [1. Data analysis and Visualization](#1)\n* [2. Data transformations](#2)\n* [3. Modeling](#3)\n* [4. Optimization](#4)\n","8e2003bc":"Let's see percent of NaNs for every column.","709dd3e9":"We can see that this manipulations helped to increase score.","cefae44e":"Let's do postprocessing based on data visualization part.","98f0da21":"In this section we are going to do quick overview of available variables.","0242b011":"<a id=\"1\"><\/a>\n<h2 style='background:purple; border:0; color:white'><center>1. Data analysis and Visualization<center><h2>","32c762d6":"<h1><center>Heart Failure Prediction: Analysis and modeling<\/center><\/h1>\n\n<center><img width=\"800\" height=\"600\" src=\"https:\/\/pediatricheartspecialists.com\/images\/answers\/Normal_Heart_Anatomy_and_Blood_Flow.jpg\"><\/center>","36433bd5":"Let's train Logistic Regression model as a quick baseline and check the results.","46dd9b56":"<a id=\"3\"><\/a>\n<h2 style='background:purple; border:0; color:white'><center>3. Modeling<center><h2>","b7b2fe41":"We deal with imbalanced classification problem so accuracy is not really useful metric. Let's try f1-score and see results.","9acaf9a0":"<a id=\"3\"><\/a>\n<h2 style='background:purple; border:0; color:white'><center>4. Optimization<center><h2>","cb5d1893":"Now let's try to use COPOD anomaly detection model and check results.","eb98d30c":"After removing some features  we have next set:"}}