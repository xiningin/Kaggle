{"cell_type":{"487bb517":"code","a7f8af76":"code","ea6b2764":"code","f9316497":"code","00fa4f0b":"code","0c7eb52f":"code","9f423625":"code","2c363638":"code","14c39205":"code","81f233f8":"code","b5d48a91":"code","1c802c97":"code","e0fd3d2b":"code","690d800c":"code","4002fdff":"code","4628e960":"code","c35c2108":"code","d192b796":"code","8b60a3c3":"code","742a7406":"code","8cd9192c":"code","9446357a":"code","94d45a2c":"code","1773c64c":"code","b6212480":"code","de53b82b":"code","e6b4112b":"code","dbd87012":"code","e9e3d9a0":"code","98220263":"code","418e93ac":"code","abde826d":"markdown","48080cfd":"markdown","be5c130f":"markdown","91b6fb6b":"markdown","63affc31":"markdown","1292c22e":"markdown","2e4366e2":"markdown","e07792b6":"markdown","f17440c3":"markdown"},"source":{"487bb517":"#this is my second basic project on kaggle \n#formally going to use convolution neural network \n#basically this project can help me a lot for understanding CNN and ANN \n\n\n#simple importing the library\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #for data visualization\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","a7f8af76":"#importing the simple library for creating neural network \n#Using keras \n#using tensorflow backend \n#importing sequential library \n\nfrom keras.models import Sequential \nfrom keras.layers import Dense , Dropout , Lambda, Flatten\n\nfrom keras.optimizers import Adam ,RMSprop\nfrom sklearn.model_selection import train_test_split\nfrom keras import  backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\n\n#after running this cell the backend of tensorflow will be activated\n\n","ea6b2764":"#importing the training dataset \ntrain = pd.read_csv(\"..\/input\/train.csv\")\nprint(train.shape)\ntrain.head()\n","f9316497":"#importing the test dataset \n\ntest= pd.read_csv(\"..\/input\/test.csv\")\nprint(test.shape)\ntest.head()\n","00fa4f0b":"#converting all the values of training and testing dataset into floating values\nX_train = (train.iloc[:,1:].values).astype('float32') # features excluding label of images  \ny_train = train.iloc[:,0].values.astype('int32') #labels of images \n\nX_test = test.values.astype('float32') \n\n","0c7eb52f":"#checking the value of training and testing dataset\nX_train\n\ny_train\n\n","9f423625":"#Convert training datset to (num_images, img_rows, img_cols) format\nX_train = X_train.reshape(X_train.shape[0], 28, 28)\n\n","2c363638":"# data visualizing of the images \nfor i in range(6, 9):\n    plt.subplot(330 + (i+1))\n    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n    plt.title(y_train[i]);\n\n","14c39205":"#expand one more dimension in array of x_train as 1 for colour channel gray\nX_train = X_train.reshape(X_train.shape[0], 28, 28,1)\nX_train.shape\t\n","81f233f8":"# same doing with testing dataset\nX_test = X_test.reshape(X_test.shape[0], 28, 28,1)\nX_test.shape","b5d48a91":"# Feature Standardization\n# It is important preprocessing step. \n#It is used to centre the data around zero mean and unit variance.\nmean_px = X_train.mean().astype(np.float32)\nstd_px = X_train.std().astype(np.float32)\ndef standardize(x): \n    return (x-mean_px)\/std_px\n\n","1c802c97":"# One Hot encoding of labels.\n# A one-hot vector is a vector which is 0 in most dimensions, and 1 in a single dimension. In this case, the nth digit will be represented as a vector which is 1 in the nth dimension.\n\n# For example, 3 would be [0,0,0,1,0,0,0,0,0,0].\n\nfrom keras.utils.np_utils import to_categorical\ny_train= to_categorical(y_train)\nnum_classes = y_train.shape[1]\nnum_classes\n","e0fd3d2b":"# plotting the first 10 0 & 1 after one hot encoding\nplt.title(y_train[9])\nplt.plot(y_train[9])\nplt.xticks(range(10));","690d800c":"#knowing that when creating neural networks \n#it's standard practice to create a 'random seed' so that you can get producible results in your models\n#it is designing phase of neural network architecture \nseed = 43\nnp.random.seed(seed)\n\n","4002fdff":"from keras.models import  Sequential\nfrom keras.layers.core import  Lambda , Dense, Flatten, Dropout\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import BatchNormalization, Convolution2D , MaxPooling2D","4628e960":"model= Sequential()\nmodel.add(Lambda(standardize,input_shape=(28,28,1)))\nmodel.add(Flatten())\nmodel.add(Dense(10, activation='softmax'))\nprint(\"input shape \",model.input_shape)\nprint(\"output shape \",model.output_shape)","c35c2108":"from keras.optimizers import RMSprop\nmodel.compile(optimizer=RMSprop(lr=0.001),\n loss='categorical_crossentropy',\n metrics=['accuracy'])","d192b796":"from keras.preprocessing import image\ngen = image.ImageDataGenerator()","8b60a3c3":"from sklearn.model_selection import train_test_split\nX = X_train\ny = y_train\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.10, random_state=42)\nbatches = gen.flow(X_train, y_train, batch_size=64)\nval_batches=gen.flow(X_val, y_val, batch_size=64)","742a7406":"history=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=3, \n                    validation_data=val_batches, validation_steps=val_batches.n)","8cd9192c":"history_dict = history.history\nhistory_dict.keys()","9446357a":"import matplotlib.pyplot as plt\n%matplotlib inline\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\nepochs = range(1, len(loss_values) + 1) #considering all epoch one by one one\n\n# \"bo\" is for \"blue dot\"\nplt.plot(epochs, loss_values, 'bo')\n# b+ is for \"blue crosses\"\nplt.plot(epochs, val_loss_values, 'b+')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\n\nplt.show()","94d45a2c":"plt.clf()   # clear figure\nacc_values = history_dict['acc']\nval_acc_values = history_dict['val_acc']\n\nplt.plot(epochs, acc_values, 'bo')\nplt.plot(epochs, val_acc_values, 'b+')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\n\nplt.show()","1773c64c":"def get_fc_model():\n    model = Sequential([\n        Lambda(standardize, input_shape=(28,28,1)),\n        Flatten(),\n        Dense(512, activation='relu'),\n        Dense(10, activation='softmax')\n        ])\n    model.compile(optimizer='Adam', loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model","b6212480":"fc = get_fc_model()\nfc.optimizer.lr=0.01","de53b82b":"#simple using fit_generator method \nhistory=fc.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, \n                    validation_data=val_batches, validation_steps=val_batches.n)","e6b4112b":"#def get_cnn_model():\n#    model = Sequential([\n #       Lambda(standardize, input_shape=(28,28,1)),\n  #      Convolution2D(32,(3,3), activation='relu'),\n   #     Convolution2D(32,(3,3), activation='relu'),\n    #    MaxPooling2D(),\n     #   Convolution2D(64,(3,3), activation='relu'),\n      #  Convolution2D(64,(3,3), activation='relu'),\n       # MaxPooling2D(),\n#        Flatten(),\n #       Dense(512, activation='relu'),\n  #      Dense(10, activation='softmax')\n   #     ])\n #   model.compile(Adam(), loss='categorical_crossentropy',\n#                  metrics=['accuracy'])\n #   return model","dbd87012":"#model= get_cnn_model()\n#model.optimizer.lr=0.01","e9e3d9a0":"#history=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs= 1, \n #                   validation_data=val_batches, validation_steps=val_batches.n)\n#Sorry very time taking as we have added upto 2 sdense layer","98220263":"fc.optimizer.lr=0.01\ngen = image.ImageDataGenerator()\nbatches = gen.flow(X, y, batch_size=64)\nhistory=fc.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=3)","418e93ac":"#creating a submission dataset for kaggle submission \npredictions = fc.predict_classes(X_test, verbose=0)\n\nsubm =pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n                         \"Label\": predictions})\nsubm.to_csv(\"DR.csv\", index=False, header=True)","abde826d":"**Adding more dense layers**\nAdding more dense layer for increasing accuracy \nAdding Layers in cnn is very easy \nnow creating a function for cnn model\nCommenting this because it will take lot of a time ","48080cfd":"******Visualization of some relation******\n\nVisualizing the realation between epoch and loss\nVisualizing the realation between epoch and accuracy","be5c130f":"Importing imagedatagenerator from preprocessing module of keras \n","91b6fb6b":"****Cross validation phase ****\n\n>In this phase we are now going to split dataset of x train ,ytrain \n\n> Batching the X_train , y_train and X_val , Y_val  for generator for the next step .\n","63affc31":"**Fully Connected Model******\nNeurons in a fully connected layer have full connections to all activations in the previous layer, as seen in regular Neural Networks. Adding another Dense Layer to model.","1292c22e":"****Creating Epoch phase****\n\nIN this we use fit_generator method for fitting our traning neural network ","2e4366e2":"****Submitting the prediction for kaggle ****\nWe have to train with whole dataset now ","e07792b6":"**Compiling phase of network**\n\nBefore making network ready for training we have to make sure to add below things:\n\n>A loss function: to measure how good the network is\n\n>An optimizer: to update network as it sees more data and reduce loss value\n\n>Metrics: to monitor performance of network\n\n","f17440c3":"Lets create a simple model from Keras Sequential layer\n****Linear model****\n\n> we import lambda layer it is used to perform simple arithmetic operations.\n\n> The first layer of the model is defines for the input dimension of our data such as rows, columns, colour channel format .\n\n> flatten will transform input into 1d array\n\n> Dense is used for fully connected layer that means all neurons in previous layers will be connected to all neurons in fully connected layer\n\n> Here it's 10, since we have to output 10 different digit labels.\n\n>Here we use softmax as our activation function of neuron \n\n"}}