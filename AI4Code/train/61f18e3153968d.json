{"cell_type":{"21824794":"code","a1fd2a4e":"code","375cc63b":"code","1907ea79":"code","26d84a4b":"code","eb67f21a":"code","5a9d4b13":"code","d501745f":"code","2e9c4b97":"code","f9a195fb":"code","b539ab79":"code","0c009bfe":"code","a04b0f97":"code","088daf18":"code","a3fb5db2":"code","05bd08d9":"code","42118759":"code","96026014":"code","87292c10":"code","d01fabb7":"code","0e8edfaa":"code","3c96a69a":"code","67f398cd":"code","2288182a":"code","008534f4":"code","7e572423":"code","b3e3cb71":"code","72d2d8bf":"code","50320362":"code","20da5c3c":"code","f5b602da":"code","5db69509":"code","990177dc":"code","df986dab":"code","ca8b5a83":"code","9770c4f9":"code","98c6b493":"markdown","6e350289":"markdown","ec86967a":"markdown","9ace3b25":"markdown","765317c9":"markdown","24bd7d91":"markdown","b43978de":"markdown","fc372371":"markdown","88a9210b":"markdown"},"source":{"21824794":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a1fd2a4e":"BASE = \"..\/input\/tabular-playground-series-feb-2021\"\nTest = pd.read_csv(BASE + '\/test.csv')\n\ntrain = pd.read_csv(BASE + '\/train.csv')\n\nsample_sub = pd.read_csv(BASE + '\/sample_submission.csv')","375cc63b":"import matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n","1907ea79":"sns.set_theme()\n","26d84a4b":"print('Rows and Columns in train dataset:', train.shape)\nprint('Rows and Columns in test dataset:', Test.shape)","eb67f21a":"##Checking for any null-data in the dataset\nprint('Rows and Columns in train dataset:', sum(train.isnull().sum()))\nprint('Rows and Columns in test dataset:', sum(Test.isnull().sum()))","5a9d4b13":"sample_sub.head()","d501745f":"cat_features = [feature for feature in train.columns if 'cat' in feature]\ncont_features = [feature for feature in train.columns if 'cont' in feature]","2e9c4b97":"print('Target')\ntrain['target'].describe()","f9a195fb":"fig = plt.figure(figsize=(15, 10), facecolor='#f6f5f5')\n## a grid of 4 \ngs = fig.add_gridspec(4, 4)\n## to create space\ngs.update(wspace=0.2, hspace=0.05)\n\n## background-color \nbackground_color = \"#f6f5f5\"\n\nrun_no = 0\nfor col in range(0, 4):\n    for row in range(0, 4):\n        locals()[\"ax\"+str(run_no)] = fig.add_subplot(gs[row, col])\n        locals()[\"ax\"+str(run_no)].set_facecolor(background_color)\n        locals()[\"ax\"+str(run_no)].set_yticklabels([])\n        locals()[\"ax\"+str(run_no)].tick_params(axis='y', which=u'both',length=0)\n        for s in [\"top\",\"right\", 'left']:\n            locals()[\"ax\"+str(run_no)].spines[s].set_visible(False)\n        run_no += 1\n\nax0.text(-0.3, 5.3, 'Continuous Features Distribution on Train Dataset', fontsize=20, fontweight='bold', fontfamily='serif')\nax0.text(-0.3, 4.7, 'Continuous features have multimodal', fontsize=13, fontweight='light', fontfamily='serif')        \n\nrun_no = 0\nfor col in cont_features:\n    sns.kdeplot(train[col], ax=locals()[\"ax\"+str(run_no)], shade=True, color='#2f5586', edgecolor='black', linewidth=1.5, alpha=0.9, zorder=3)\n    locals()[\"ax\"+str(run_no)].grid(which='major', axis='x', zorder=0, color='gray', linestyle=':', dashes=(1,5))\n    locals()[\"ax\"+str(run_no)].set_ylabel(col, fontsize=10, fontweight='bold').set_rotation(0)\n    locals()[\"ax\"+str(run_no)].yaxis.set_label_coords(1, 0)\n    locals()[\"ax\"+str(run_no)].set_xlim(-0.2, 1.2)\n    locals()[\"ax\"+str(run_no)].set_xlabel('')\n    run_no += 1\n    \nax14.remove()\nax15.remove()","b539ab79":"sns.kdeplot(train['target'], shade=True, color=\"#003f5c\", edgecolor=\"black\", linewidth= 1.5, alpha=0.9, zorder=3)","0c009bfe":"import warnings\nwarnings.filterwarnings('ignore')\n","a04b0f97":"def Count_diagram(data, background_color=\"#f5f3f3\",cat_features = cat_features):\n    background_color = \"#f5f3f3\"\n\n    fig = plt.figure(figsize=(25, 10), facecolor=background_color)\n    gs = fig.add_gridspec(2, 5)\n    gs.update(wspace=0.2, hspace=0.2)\n\n    run_no = 0\n    for row in range(0,2):\n        for col in range(0,5):\n            locals()[\"ax\"+ str(run_no)] = fig.add_subplot(gs[row, col])\n            locals()[\"ax\" + str(run_no)].set_facecolor(background_color)\n            for s in ['top', 'right', 'left']:\n                locals()[\"ax\"+ str(run_no)].spines[s].set_visible(False)\n            run_no += 1\n\n\n    ax0.text(0, 0,'Count of categorical features on Train dataset (%)', fontsize=20, fontweight=\"bold\", fontfamily=\"serif\")\n    ax0.text(0,0, 'Some features are dominated by one category', fontsize=13, fontweight='light', fontfamily=\"serif\")\n\n\n    run_no = 0\n    for col in cat_features: \n        dataformating = data[col].value_counts() \/len(data) * 100\n        chart_df = pd.DataFrame(dataformating)\n        sns.barplot(x=chart_df.index, y=chart_df[col], ax=locals()[\"ax\" + str(run_no)], color=\"#003f5c\", zorder=3, edgeColor=\"black\", linewidth=1.5)\n        locals()['ax'+str(run_no)].grid(which='major', axis= 'y', zorder=0, color='grey', linestyle=':', dashes=(1,5))\n        run_no += 1\n        \n    plt.show()\n    \n","088daf18":"Count_diagram(train)","a3fb5db2":"Count_diagram(Test)","05bd08d9":"background_color = \"#f6f5f5\"\n\nfig = plt.figure(figsize=(12, 8), facecolor=background_color)\ngs = fig.add_gridspec(1, 1)\nax0 = fig.add_subplot(gs[0, 0])\ncolors = [\"#2f5586\", \"#f6f5f5\",\"#2f5586\"]\ncolormap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n\nax0.set_facecolor(background_color)\nax0.text(-1.1, 0.048, 'Correlation of Continuous Features with Target', fontsize=20, fontweight='bold', fontfamily='serif')\nax0.text(-1.1, 0.045, 'There is no features that pass 0.04 correlation with target', fontsize=13, fontweight='light', fontfamily='serif')\n\nchart_df = pd.DataFrame(train[cont_features].corrwith(train['target']))\nchart_df.columns = ['corr']\nsns.barplot(x=chart_df.index, y=chart_df['corr'], ax=ax0, color='#2f5586', zorder=3, edgecolor='black', linewidth=1.5)\nax0.grid(which='major', axis='y', zorder=0, color='gray', linestyle=':', dashes=(1,5))\nax0.set_ylabel('')\n\nfor s in [\"top\",\"right\", 'left']:\n    ax0.spines[s].set_visible(False)\n\nplt.show()","42118759":"fig = plt.figure(figsize=(15, 15), facecolor = '#f6f5f5')\ngs = fig.add_gridspec(4, 4)\ngs.update(wspace=0.5, hspace=0.5)\n\nbackground_color = \"#f6f5f5\"\n\nrun_no = 0\nfor row in range(0, 4):\n    for col in range(0, 4):\n        locals()[\"ax\"+str(run_no)] = fig.add_subplot(gs[row, col])\n        locals()[\"ax\"+str(run_no)].set_facecolor(background_color)\n        for s in [\"top\",\"right\",\"left\"]:\n            locals()[\"ax\"+str(run_no)].spines[s].set_visible(False)\n        run_no += 1\n\nrun_no = 0\nfor feature in cont_features:\n        sns.scatterplot(x=train[feature], y=train['target'] ,ax=locals()[\"ax\"+str(run_no)], color='#2f5586', linewidth=0.3, edgecolor='black')\n        locals()[\"ax\"+str(run_no)].grid(which='major', zorder=0, color='gray', linestyle=':', dashes=(1,5))\n        run_no += 1\n        \nax0.text(-0.5, 14, 'Features and Target Relation', fontsize=20, fontweight='bold', fontfamily='serif')\nax0.text(-0.5, 12.4, 'cont1 has a distinct separation', fontsize=13, fontweight='light', fontfamily='serif')\n\nax14.remove()\nax15.remove()\n\nplt.show()","96026014":"for cat in cat_features:\n    value = pd.Series(train[cat].value_counts().sort_index().index)\n\n    fig = plt.figure(figsize=(60, 5), facecolor='#f6f5f5')\n    gs = fig.add_gridspec(len(value), 5)\n    gs.update(wspace=0.2, hspace=0.05)\n\n    background_color = \"#f6f5f5\"\n\n    run_no = 0\n    for row in range(0, len(value)):\n        locals()[\"ax\"+str(run_no)] = fig.add_subplot(gs[row, 0])\n        locals()[\"ax\"+str(run_no)].set_facecolor(background_color)\n        locals()[\"ax\"+str(run_no)].set_yticklabels([])\n        locals()[\"ax\"+str(run_no)].tick_params(axis='y', which=u'both',length=0)\n        for s in [\"top\",\"right\", 'left']:\n            locals()[\"ax\"+str(run_no)].spines[s].set_visible(False)\n        run_no += 1\n\n    ax0.text(-0.5, 0.52, 'Target Distribution on {cat} feature '.format(cat=cat), fontsize=20, fontweight='bold', fontfamily='serif')\n    ax0.text(-0.5, 0.46, 'To see how target is distributed across each value', fontsize=13, fontweight='light', fontfamily='serif')        \n\n    run_no = 0\n    for val in value:\n        sns.kdeplot(train[train[cat]==val]['target'], ax=locals()[\"ax\"+str(run_no)], shade=True, color='#2f5586', edgecolor='black', linewidth=1.5, alpha=0.9, zorder=3)\n        locals()[\"ax\"+str(run_no)].grid(which='major', axis='x', zorder=0, color='gray', linestyle=':', dashes=(1,5))\n        locals()[\"ax\"+str(run_no)].set_ylabel(val, fontsize=20, fontweight='bold').set_rotation(0)\n        locals()[\"ax\"+str(run_no)].yaxis.set_label_coords(1.015, 0)\n        locals()[\"ax\"+str(run_no)].set_xlim(-0.5, 10.5)\n        run_no += 1","87292c10":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tqdm import tqdm\nimport gc\nimport matplotlib.pyplot as plt\nimport shap\n\n# load JS visualization code to notebook\nshap.initjs()","d01fabb7":"columns = Test.columns[1:]\ncolumns","0e8edfaa":"target = train['target'].values","3c96a69a":"cat_features = columns[:10]\ncat_features","67f398cd":"for feature in cat_features:\n    le = LabelEncoder()\n    le.fit(train[feature])\n    train[feature] = le.transform(train[feature])\n    Test[feature] = le.transform(Test[feature])","2288182a":"train.head()","008534f4":"Test.head()","7e572423":"!pip install --upgrade xgboost\nimport xgboost as xgb\nxgb.__version__","b3e3cb71":"xgb_params= {\n        \"objective\": \"reg:squarederror\",\n        \"max_depth\": 6,\n        \"learning_rate\": 0.01,\n        \"colsample_bytree\": 0.4,\n        \"subsample\": 0.6,\n        \"reg_alpha\" : 6,\n        \"min_child_weight\": 100,\n        \"n_jobs\": 2,\n        \"seed\": 2001,\n        'tree_method': \"gpu_hist\",\n        \"gpu_id\": 0,\n    }","72d2d8bf":"train_oof = np.zeros((300000,))\ntest_preds = 0\ntrain_oof.shape","50320362":"Test = xgb.DMatrix(Test[columns])","20da5c3c":"NUM_FOLDS = 10\nkf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=0)\n\nfor f, (train_ind, val_ind) in tqdm(enumerate(kf.split(train, target))):\n        #print(f'Fold {f}')\n        train_df, val_df = train.iloc[train_ind][columns], train.iloc[val_ind][columns]\n        train_target, val_target = target[train_ind], target[val_ind]\n        \n        train_df = xgb.DMatrix(train_df, label=train_target)\n        val_df = xgb.DMatrix(val_df, label=val_target)\n        \n        model =  xgb.train(xgb_params, train_df, 3600)\n        temp_oof = model.predict(val_df)\n        temp_test = model.predict(Test)\n\n        train_oof[val_ind] = temp_oof\n        test_preds += temp_test\/NUM_FOLDS\n        \n        print(mean_squared_error(temp_oof, val_target, squared=False))","f5b602da":"mean_squared_error(train_oof, target, squared=False)","5db69509":"np.save('train_oof', train_oof)\nnp.save('test_preds', test_preds)","990177dc":"%%time\nshap_preds = model.predict(test, pred_contribs=True)","df986dab":"train = pd.read_csv('..\/input\/tabular-playground-series-feb-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-feb-2021\/test.csv')\nfor feature in cat_features:\n    le = LabelEncoder()\n    le.fit(train[feature])\n    train[feature] = le.transform(train[feature])\n    test[feature] = le.transform(test[feature])","ca8b5a83":"# summarize the effects of all the features\nshap.summary_plot(shap_preds[:,:-1], test[columns])","9770c4f9":"sample_sub['target'] = test_preds\nsample_sub.to_csv('submission.csv', index=False)","98c6b493":"# Count of Categorical Features\n","6e350289":"# Feature engineering","ec86967a":"# Correlation with Target","9ace3b25":"#  Importing the files","765317c9":"# using the xgBoost model for featuree engineering","24bd7d91":"# Label encoding the categorical features","b43978de":"# 4.2.2 Categorical Features","fc372371":"# Let's see how the submission file looks","88a9210b":"# EDA of the tabular data\n* We have two types of features here \n1. Categorical = 'Cat'\n2. Continuous = 'Cont'\n<h1>ideas<\/h1>\n* We would have to do Categorical encoding for categorical features\n\n\n"}}