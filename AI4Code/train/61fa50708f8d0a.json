{"cell_type":{"d97998af":"code","26e31c34":"code","4639d254":"code","daa20f02":"code","4b1a2130":"code","45fb6d19":"code","8fe56949":"code","8356b030":"code","25c0860d":"code","3691ab47":"code","1357e044":"code","8c2d2a23":"code","4b447eb5":"code","15734bc2":"code","5e11054d":"code","d62735ea":"markdown","885baec3":"markdown","8303752d":"markdown","691a5418":"markdown","c23fe909":"markdown"},"source":{"d97998af":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"..\/input\"))","26e31c34":"train=pd.read_csv(\"..\/input\/train.csv\")\ntest=pd.read_csv(\"..\/input\/test.csv\")\nsample=pd.read_csv(\"..\/input\/sample_submission.csv\")","4639d254":"train.head()","daa20f02":"import matplotlib.pyplot as plt\nimport seaborn as sns","4b1a2130":"sns.countplot(x='diagnosis',data=train)","45fb6d19":"import cv2\nimport glob\n\nX_data = []\nimages = glob.glob (\"..\/input\/train_images\/*.png\")\n","8fe56949":"images[0:5]","8356b030":"import random\nr = random.sample(images, 3)\nr\n\nplt.figure(figsize=(16,16))\nplt.subplot(131)\nplt.imshow(cv2.imread(r[0]))\n\nplt.subplot(132)\nplt.imshow(cv2.imread(r[1]))\n\nplt.subplot(133)\nplt.imshow(cv2.imread(r[2]))","25c0860d":"train_path = '..\/input\/train_images\/'\ntest_path = '..\/input\/test_images\/'","3691ab47":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import to_categorical\nfrom keras.preprocessing import image\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nfrom tqdm import tqdm\nimport os\nimport cv2","1357e044":"train.head()","8c2d2a23":"id_code=train['id_code'].values\ndiagnosis=train['diagnosis'].values\n\n\ntrain=[]\nX=[]\nY=[]\na=0\nIMG_SIZE=150\nfor i in tqdm(sorted(os.listdir(train_path))):\n    path=os.path.join(train_path,i)\n    i=cv2.imread(path,cv2.IMREAD_COLOR)\n    i = cv2.resize(i, (IMG_SIZE, IMG_SIZE))\n    X.append(i)\n    train.append([np.array(diagnosis),diagnosis[a]])\n    a=a+1\n\ntrain=np.array(train)\nY=train[:,1]\ntrain=train[:,0]\nX=np.array(X)\n\nX.shape\n\nX=X\/255\ntrain=train\/255","4b447eb5":"\n\ntest1=[]\nX_test=[]\nIMG_SIZE=150\nfor i in tqdm(os.listdir(test_path)):\n    id_code=i\n    path=os.path.join(test_path,i)\n    i=cv2.imread(path,cv2.IMREAD_COLOR)\n    i = cv2.resize(i, (IMG_SIZE, IMG_SIZE))\n    X_test.append(i)\n    test1.append([np.array(i),id_code])\n\nX_test=np.array(X_test)\nX_test.shape\ntest1=np.array(test1)\nid_test=test1[:,1]\ntest1=test1[:,0]\ntest1.shape\n\nX_test=X_test\/255\ntest1=test1\/255\n\n","15734bc2":"model = Sequential()\nmodel.add(Conv2D(filters=128,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=(150,150,3)))\nmodel.add(MaxPooling2D(pool_size=2,strides=1))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=2,strides=1))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=2,strides=1))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(32,activation=\"relu\"))\nmodel.add(Dropout(0.7))\nmodel.add(Dense(1,activation=\"softmax\"))\nmodel.summary()","5e11054d":"model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\nh=model.fit(X,Y,batch_size=256,validation_split=0.2,epochs=100)","d62735ea":"\n\n    0 - No DR\n\n    1 - Mild\n\n    2 - Moderate\n\n    3 - Severe\n\n    4 - Proliferative DR\n","885baec3":"##### wow our eyes are really beautiful :P","8303752d":"#### Image Handling\n","691a5418":"#### Image path","c23fe909":"### I'll update this kernel soon :)"}}