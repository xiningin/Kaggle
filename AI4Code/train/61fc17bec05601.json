{"cell_type":{"099c9ff5":"code","807d2fd4":"code","92dadfc8":"code","d14d265e":"code","7d131cc3":"code","6d3a6062":"code","8b567788":"code","6f34fbf6":"code","ae8c8a84":"code","3a8f3145":"code","01212b6c":"code","594b9f84":"code","69dc2ce6":"code","15a6dd74":"code","69df568e":"code","d5e2677a":"code","ad25d976":"code","b33995fa":"code","a936ccca":"code","f8fad7e7":"code","13cbc18e":"code","62499ba9":"code","649b9b15":"markdown","6fee217f":"markdown","f49b3de1":"markdown","3b933018":"markdown","1a3b3b36":"markdown","3bd0c357":"markdown","1d0f5b4f":"markdown","a82b2427":"markdown"},"source":{"099c9ff5":"!nvcc -V\n!gcc --version","807d2fd4":"!pip install -U torch==1.7.1+cu110 torchvision==0.8.2+cu110 -f https:\/\/download.pytorch.org\/whl\/torch_stable.html\n!pip install mmcv-full\n!rm -rf mmdetection\n!git clone https:\/\/github.com\/open-mmlab\/mmdetection\n%cd mmdetection\n!pip install -e .","92dadfc8":"import torch, torchvision\nprint(torch.__version__, torch.cuda.is_available())\n\nimport mmdet\nprint(mmdet.__version__)\n\nfrom mmcv.ops import get_compiling_cuda_version, get_compiler_version\nprint(get_compiling_cuda_version())\nprint(get_compiler_version())\nimport os\nfrom mmdet.datasets import build_dataset\nfrom mmdet.models import build_detector\nfrom mmdet.apis import train_detector\nimport glob\nimport cv2\nimport shutil\nimport random\nimport os.path as osp\nimport json\nimport mmcv\nimport random\nimport re\nimport xml.etree.ElementTree as ET\nfrom typing import Dict, List\nfrom mmdet.apis import set_random_seed\nimport pandas as pd\nimport numpy as np\nfrom mmdet.apis import inference_detector, init_detector, show_result_pyplot","d14d265e":"global_seed = 0\n\ndef set_seed(seed=global_seed):\n    \"\"\"Sets the random seeds.\"\"\"\n    set_random_seed(seed, deterministic=False)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nset_seed()","7d131cc3":"%cd ..","6d3a6062":"df = pd.read_csv('..\/input\/license\/license.csv')","8b567788":"val_idx = random.sample(range(0, 236), 20)","6f34fbf6":"len(val_idx)","ae8c8a84":"idx = []\nfor i in range(237):\n    idx.append(i)\ntrain_idx = np.setdiff1d(idx, val_idx)","3a8f3145":"train_idx = train_idx.tolist()","01212b6c":"len(train_idx)","594b9f84":"val_idx.remove(107) #For some reason cv2 can't read the image correctly so I just removed it. ","69dc2ce6":"class NpEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, np.integer):\n            return int(obj)\n        elif isinstance(obj, np.floating):\n            return float(obj)\n        elif isinstance(obj, np.ndarray):\n            return obj.tolist()\n        else:\n            return super(NpEncoder, self).default(obj)","15a6dd74":"!mkdir \/kaggle\/working\/images\n!cp -r ..\/input\/license\/Cars\/. \/kaggle\/working\/images","69df568e":"%%writefile labels.txt\nLicense_Plate","d5e2677a":"def convert_df_to_cocojson(df, idx_list, output_jsonpath='\/kaggle\/working\/output.json', label='License_Plate'):\n    output_json_dict = {\n        \"images\": [],\n        \"annotations\": [],\n        \"categories\": []\n\n    }\n    for i, idx in enumerate(idx_list):\n        img_filepath = df.iloc[idx, 1].split('\/')[-1]\n        xmin = df.iloc[idx, 2]\n        ymin = df.iloc[idx, 3]\n        xmax = df.iloc[idx, 4]\n        ymax = df.iloc[idx, 5]\n        ids = idx\n#         print(img_filepath)\n        img_height, img_width, img_depth = cv2.imread('\/kaggle\/working\/images\/' + img_filepath).shape\n        real_xmin = int(xmin*img_width)\n        real_xmax = int(xmax*img_width)\n        real_ymin = int(ymin*img_height)\n        real_ymax = int(ymax*img_height)   \n        annot_width = int(real_xmax - real_xmin)\n        annot_height = int(real_ymax - real_ymin)\n        annot = {\n            'segmentation': [], \n            'area': annot_width * annot_height,\n            'iscrowd': 0,\n            'image_id': int(idx + 1),\n            'bbox': [real_xmin, real_ymin, annot_width, annot_height],\n            'category_id': 1,\n            'id': int(i + 1)\n        }\n        output_json_dict['annotations'].append(annot)\n        image_info = {\n            'file_name': img_filepath,\n            'height': img_height,\n            'width': img_width,\n            'id': int(idx + 1)\n        }\n        output_json_dict['images'].append(image_info)\n    category_info = {\n        'id': 1, \n        'name': label, \n        'supercategory': 'none'\n    }\n    output_json_dict['categories'].append(category_info)\n    with open(output_jsonpath, 'x') as f:\n        output_json = json.dumps(output_json_dict, cls=NpEncoder)\n        f.write(output_json)","ad25d976":"convert_df_to_cocojson(df=df, idx_list=train_idx)","b33995fa":"convert_df_to_cocojson(df=df, idx_list=val_idx, output_jsonpath='\/kaggle\/working\/val-output.json')","a936ccca":"from mmcv import Config\ncfg = Config.fromfile('\/kaggle\/working\/mmdetection\/configs\/dcn\/cascade_rcnn_r101_fpn_dconv_c3-c5_1x_coco.py')","f8fad7e7":"cfg.dataset_type = 'CocoDataset'\ncfg.classes = '\/kaggle\/working\/labels.txt'\ncfg.data_root = '\/kaggle\/working'\n\nfor head in cfg.model.roi_head.bbox_head:\n    head.num_classes = 1\n    \ncfg.work_dir = '.\/model_output'\n\ncfg.data.test.type = 'CocoDataset'\ncfg.data.test.classes = 'labels.txt'\ncfg.data.test.data_root = '\/kaggle\/working'\ncfg.data.test.ann_file = 'val-output.json'\ncfg.data.test.img_prefix = 'images'\n\ncfg.data.train.type = 'CocoDataset'\ncfg.data.train.data_root = '\/kaggle\/working'\ncfg.data.train.ann_file = 'output.json'\ncfg.data.train.img_prefix = 'images'\ncfg.data.train.classes = 'labels.txt'\n\ncfg.data.val.type = 'CocoDataset'\ncfg.data.val.data_root = '\/kaggle\/working'\ncfg.data.val.ann_file = 'val-output.json'\ncfg.data.val.img_prefix = 'images'\ncfg.data.val.classes = 'labels.txt'\n\nalbu_train_transforms = [\n    dict(type='ShiftScaleRotate', shift_limit=0.0625,\n         scale_limit=0.15, rotate_limit=15, p=0.4),\n#     dict(type='RandomBrightnessContrast', brightness_limit=0.2,\n#          contrast_limit=0.2, p=0.5),\n    dict(type='IAAAffine', shear=(-10.0, 10.0), p=0.4),\n#     dict(type='MixUp', p=0.2, lambd=0.5),\n#     dict(type=\"Blur\", p=1.0, blur_limit=7),\n#     dict(type='CLAHE', p=0.5),\n#     dict(type='Equalize', mode='cv', p=0.4),\n    dict(\n        type=\"OneOf\",\n        transforms=[\n            dict(type=\"GaussianBlur\", p=1.0, blur_limit=7),\n            dict(type=\"MedianBlur\", p=1.0, blur_limit=7),\n        ],\n        p=0.4,\n    ),]\n\ncfg.train_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n    dict(type='RandomFlip', flip_ratio=0.5),\n    dict(\n        type='Albu',\n        transforms=albu_train_transforms,\n        bbox_params=dict(\n        type='BboxParams',\n        format='coco',\n        label_fields=['gt_labels'],\n        min_visibility=0.0,\n        filter_lost_elements=True),\n        keymap=dict(img='image', gt_bboxes='bboxes'),\n        update_pad_shape=False,\n        skip_img_without_anno=True),\n    dict(\n        type='Normalize',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'),\n    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n]\n\ncfg.load_from = '..\/input\/dcn-checkpoint\/cascade_rcnn_r101_fpn_dconv_c3-c5_1x_coco_20200203-3b2f0594.pth'\n\ncfg.work_dir = '\/kaggle\/working\/model_output'\n\ncfg.optimizer.lr = 0.02 \/ 8\ncfg.lr_config = dict(\n    policy='CosineAnnealing', \n    by_epoch=False,\n    warmup='linear', \n    warmup_iters=500, \n    warmup_ratio=0.001,\n    min_lr=1e-07)\n\ncfg.data.samples_per_gpu = 4\ncfg.data.workers_per_gpu = 2\n\ncfg.evaluation.metric = 'bbox'\ncfg.evaluation.interval = 4\n\ncfg.checkpoint_config.interval = 6\ncfg.runner.max_epochs = 12\ncfg.log_config.interval = 50\n\ncfg.seed = 0\nset_random_seed(0, deterministic=False)\ncfg.gpu_ids = [0]\n\nprint(f'Config:\\n{cfg.pretty_text}')","13cbc18e":"datasets = [build_dataset(cfg.data.train)]\nmodel = build_detector(\n cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\nmodel.CLASSES = datasets[0].CLASSES\n\nmmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\ntrain_detector(model, datasets, cfg, distributed=False, validate=True)","62499ba9":"model = init_detector(cfg, '\/kaggle\/working\/model_output\/epoch_12.pth')\nfor i in range(len(val_idx)):\n    img = mmcv.imread('\/kaggle\/input\/license\/Cars\/car' + str(val_idx[i]) + '.jpg')\n    result = inference_detector(model, img)\n    show_result_pyplot(model, img, result)","649b9b15":"# **Set Seeds**","6fee217f":"# **Import Libraries**","f49b3de1":"# **Install MMDetection**","3b933018":"# **Training**","1a3b3b36":"# **Turn CSV to COCO Annotation Format**","3bd0c357":"# **Inference on Validation Set**","1d0f5b4f":"We can keep training for more accuracy, but I chose not to. ","a82b2427":"# **Custom Config File with Deformable CNN V2**"}}