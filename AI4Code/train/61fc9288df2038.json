{"cell_type":{"689e43b4":"code","df393d72":"code","9e855fa3":"code","7c79eef1":"code","c9c003dd":"code","9c006491":"code","93ac51fd":"code","8053191a":"code","85db44e0":"code","1a68a312":"code","cebf7fed":"code","38b4ad64":"code","d18fb971":"code","6a7177cb":"code","edd03a6c":"code","d7994257":"code","0f893c4e":"code","af7b9953":"code","6914c383":"code","7eff5ad0":"code","7ea49e15":"code","aedf8d6b":"code","b5cfbb7e":"code","652e642c":"code","89192a5b":"markdown","cfe74749":"markdown"},"source":{"689e43b4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","df393d72":"#prerequisites\nimport tensorflow as tf\nprint(tf.__version__)\n","9e855fa3":"!pip install git+https:\/\/github.com\/rcmalli\/keras-vggface.git","7c79eef1":"#mtcnn-multi-tasking cnn\n!pip install mtcnn","c9c003dd":"!pip install keras_vggface","9c006491":"#to read and store the image from external storage\n\nimport urllib.request\n\ndef store_image(url, local_file_name):\n    with urllib.request.urlopen(url) as resource:\n        with open(local_file_name, 'wb') as f:\n            f.write(resource.read())","93ac51fd":"store_image('https:\/\/i.guim.co.uk\/img\/media\/cabcfbdafc3b7e0854e07c35c35b18c199aa19a2\/0_0_5130_3078\/master\/5130.jpg?width=620&quality=45&auto=format&fit=max&dpr=2&s=ae80fd89ca23ac48d4bff44aadb7523a','hamilton1.jpg')","8053191a":"store_image('https:\/\/cdn-1.motorsport.com\/images\/mgl\/0k7er3A0\/s1200\/lewis-hamilton-mercedes-1.webp','hamilton2.jpg')","85db44e0":"from matplotlib import pyplot as plt\nfrom mtcnn.mtcnn import MTCNN","1a68a312":"#reading image pixels\nimage = plt.imread('hamilton1.jpg')\n","cebf7fed":"#detection of face in the image and its properties\ndetector = MTCNN()\n\nfaces = detector.detect_faces(image)\nfor face in faces:\n    print(face)","38b4ad64":"#to highlight the face with a rectangle\nfrom matplotlib.patches import Rectangle\ndef highlight_faces(image_path, faces):\n  # display image\n    image = plt.imread(image_path)\n    plt.imshow(image)\n\n    ax = plt.gca()\n\n  # for each face, draw a rectangle based on coordinates\n    for face in faces:\n        x, y, width, height = face['box']\n        face_border = Rectangle((x, y), width, height,\n                          fill=False, color='red')\n        ax.add_patch(face_border)\n    plt.show()","d18fb971":"highlight_faces('hamilton1.jpg', faces)","6a7177cb":"image = plt.imread('hamilton2.jpg')\nfaces = detector.detect_faces(image)\n\nhighlight_faces('hamilton2.jpg', faces)","edd03a6c":"from numpy import asarray\nfrom PIL import Image\n\ndef extract_face_from_image(image_path, required_size=(224, 224)):\n  # load image and detect faces\n    image = plt.imread(image_path)\n    detector = MTCNN()\n    faces = detector.detect_faces(image)\n\n    face_images = []\n\n    for face in faces:\n    # extract the bounding box from the requested face\n        x1, y1, width, height = face['box']\n        x2, y2 = x1 + width, y1 + height\n\n    # extract the face\n        face_boundary = image[y1:y2, x1:x2]\n    # resize pixels to the model size\n        face_image = Image.fromarray(face_boundary)\n        face_image = face_image.resize(required_size)\n        face_array = asarray(face_image)\n        face_images.append(face_array)\n\n    return face_images\n\nextracted_face = extract_face_from_image('hamilton2.jpg')\n\n\n# Display the first face from the extracted faces\n\nplt.imshow(extracted_face[0])\nprint(extracted_face[0].shape)\nplt.show()","d7994257":" !pip install Keras-Applications","0f893c4e":"from keras_applications.imagenet_utils import _obtain_input_shape","af7b9953":"from keras_vggface.utils import preprocess_input\nfrom keras_vggface.vggface import VGGFace\nfrom scipy.spatial.distance import cosine","6914c383":"def get_model_scores(faces):\n    samples = asarray(faces, 'float32')\n    print(samples.shape)\n  \n    print(samples.shape)\n  # prepare the data for the model\n    samples = preprocess_input(samples, version=2)\n  \n\n  # create a vggface model object\n    model = VGGFace(model='resnet50',\n      include_top=False,\n      input_shape=(224, 224, 3),\n      pooling='avg')\n#each feature is down grades to avg value\n\n  # perform prediction\n    return model.predict(samples)\n\nfaces = [extract_face_from_image(image_path)\n         for image_path in ['hamilton1.jpg', 'hamilton2.jpg']]\nmodel_scores1 = get_model_scores(faces[0])\nmodel_scores2 = get_model_scores(faces[1])","7eff5ad0":"#to check if the given faces in both images match or not\nif cosine(model_scores1, model_scores2) <= 0.4:\n    print(\"Faces Matched\")","7ea49e15":"store_image('https:\/\/www.formula1.com\/content\/dam\/fom-website\/sutton\/2019\/AbuDhabi\/Sunday\/DXI14281_20191201120510963.jpg.transform\/9col-retina\/image.jpg','team1.jpg')\nimage = plt.imread('team1.jpg')\nfaces = detector.detect_faces(image)\n\nhighlight_faces('team1.jpg', faces)","aedf8d6b":"store_image('https:\/\/cdn.asiatatler.com\/asiatatler\/i\/ph\/2019\/03\/15162238-1_cover_1920x1280.jpg','team2.jpg')\nimage = plt.imread('team2.jpg')\nfaces1 = detector.detect_faces(image)\n\nhighlight_faces('team2.jpg', faces1)","b5cfbb7e":"team1 = extract_face_from_image('team1.jpg')\nteam2 = extract_face_from_image('team2.jpg')\n\nmodel_scores_team1 = get_model_scores(team1)\nmodel_scores_team2= get_model_scores(team2)","652e642c":"#to display the matching faces\nfor idx, face_score_1 in enumerate(model_scores_team1):\n    for idy, face_score_2 in enumerate(model_scores_team2):\n        score = cosine(face_score_1, face_score_2)\n        if score <= 0.4:\n      # Printing the IDs of faces and score\n            print(idx, idy, score)\n      # Displaying each matched pair of faces\n            plt.imshow(team1[idx])\n            plt.show()\n            plt.imshow(team2[idy])\n            plt.show()","89192a5b":"**Images from external storage**","cfe74749":"**With Multiple faces in a picture**"}}