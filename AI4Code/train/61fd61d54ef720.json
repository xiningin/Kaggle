{"cell_type":{"1a964542":"code","de330ceb":"code","752df3b3":"code","9d71d93a":"code","82229abf":"code","d5b337e0":"code","c22ca4cf":"code","39610e31":"code","2eeb315e":"code","5b1c7d70":"code","ba7ba732":"code","816ae170":"code","8691c774":"code","8b751131":"code","0c6471a7":"code","5972eb51":"code","7cfc16bc":"code","0ad55b97":"code","a0c81706":"code","b666d9fd":"code","777b871c":"code","b0403eab":"markdown","f622e744":"markdown","043f2ae1":"markdown","aac5d809":"markdown","6d2d304b":"markdown","0e34bf7c":"markdown","6dea9789":"markdown","682e6379":"markdown","0d3c97c1":"markdown","5631bb9e":"markdown","6d0d63ca":"markdown","0634a76f":"markdown","8856a0dc":"markdown","01b1d84b":"markdown"},"source":{"1a964542":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\\\nimport re #regular expressions\nimport matplotlib.pyplot as plt #basic visuals\nimport seaborn as sns #more advnced visuals\n\nfrom sklearn.feature_extraction.text import CountVectorizer #count vectorizer\nfrom sklearn.model_selection import train_test_split #train est split\n\nfrom sklearn.pipeline import Pipeline #import the pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer #import Tf idf Vectorizer\n\nfrom sklearn.linear_model import LogisticRegression #logistic regression \nfrom sklearn.svm import LinearSVC #logistic regression \n\nfrom sklearn.metrics import classification_report, plot_confusion_matrix #classification report","de330ceb":"df = pd.read_csv('..\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv')","752df3b3":"df.head()","9d71d93a":"# check for missing values \ndf.isna().sum()","82229abf":"# check for empty string\ndf[df['review'].str.isspace()]","d5b337e0":"# check for empty string\ndf[df['review'].apply(lambda x: x=='')]","c22ca4cf":"# cleand HTML Tags\ndf['review'][3]","39610e31":"# as per recommendation from @freylis, compile once only\nCLEANR = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\ndef cleanhtml(raw_html):\n  cleantext = re.sub(CLEANR, '', raw_html)\n  return cleantext","2eeb315e":"cleanhtml(df['review'][3])","5b1c7d70":"# apply the fuction to the entire column?\ndf['review'] = df['review'].apply(lambda x: cleanhtml(x))","ba7ba732":"df['review'][3]","816ae170":"df['sentiment'].value_counts()","8691c774":"plt.figure(figsize = (8,4), dpi = 100)\nsns.countplot(data = df, x = 'sentiment');","8b751131":"# 1. Negtive reviews\ncount_vect = CountVectorizer(stop_words = 'english')\nmatrix = count_vect.fit_transform(df[df.sentiment == 'negative']['review'])\nfreqs = zip(count_vect.get_feature_names(), matrix.sum(axis = 0).tolist()[0])\n#print sorted words \nprint(sorted(freqs, key = lambda x: -x[1])[:20])            ","0c6471a7":"# 2. Positive reviews\ncount_vect = CountVectorizer(stop_words = 'english')\nmatrix = count_vect.fit_transform(df[df.sentiment == 'positive']['review'])\nfreqs = zip(count_vect.get_feature_names(), matrix.sum(axis = 0).tolist()[0])\n#print sorted words \nprint(sorted(freqs, key = lambda x: -x[1])[:20])            ","5972eb51":"X = df['review']\ny = df['sentiment']","7cfc16bc":"# train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","0ad55b97":"# create the pipline \npipe = Pipeline([('tfidf', TfidfVectorizer()),\n                ('svc', LinearSVC())])\n\n# fit the pipeline  \npipe.fit(X_train, y_train)","a0c81706":"# create the classification report and plot the confusion matrix\npreds = pipe.predict(X_test)\nprint(classification_report(y_test, preds))\nplot_confusion_matrix(pipe, X_test, y_test)","b666d9fd":"pipe.predict(['love movie'])","777b871c":"pipe.predict(['horrible movie'])","b0403eab":"There is no null values or empty strings ","f622e744":"# EDA on the bag of words \nWill figure out how to use a CountVectorizer model to get the top 20 words (that are not english stop words) per label type.","043f2ae1":"# Explanatory data analysis ","aac5d809":"# Imports ","6d2d304b":"Great Job, We reached 90 percent accuracy with a few line of code and a very simple algorithm!\n\nIs not that incredible? \n\nSee you in another project...","0e34bf7c":"# Data cleaning ","6dea9789":"# Load the data","682e6379":"We notice that there is alot of common words between negative and positive reviews such as \"film\", \"movie\", and \"just\". However, there is words that distinguishes negative reviews such as \"bad\" and positive reviews such as \"good\". ","0d3c97c1":"# Model preprocessing ","5631bb9e":"In this project we will have a look on the quickest, yet very precise, way possible to perform NLP and Sentiment analysis. You will learn how to achieve 90 percent accuracy with just a few lines of code and a very simple algorithms!","6d0d63ca":"# Model PipeLine\nCreate a PipeLine that will both create a TF-IDF Vector out of the raw text data and fit a supervised learning model of your choice. Then fit that pipeline on the training data.","0634a76f":"The data is well balanced ","8856a0dc":"## Train test split","01b1d84b":"## split X and y"}}