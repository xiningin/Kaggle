{"cell_type":{"f8e7652d":"code","9a3cdc89":"code","7fae575b":"code","1eae3bbd":"code","9fd7e654":"code","4ad6d635":"code","db0700bf":"code","180e0b48":"code","721889c9":"code","0be26fe3":"markdown"},"source":{"f8e7652d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9a3cdc89":"def asRowMatrix(X):\n    if len(X) == 0:\n        return np.array([])\n    mat = np.empty((0, X[0].size), dtype=X[0].dtype)\n    for row in X:\n        mat = np.vstack((mat, np.asarray(row).reshape(1,-1)))\n    return mat\n\ndef pca(X, y, num_components=0):\n    [n,d] = X.shape\n    if (num_components <= 0) or (num_components>n):\n        num_components = n\n    mu = X.mean(axis=0)\n    X = X - mu\n    if n>d:\n        C = np.dot(X.T,X)\n        [eigenvalues,eigenvectors] = np.linalg.eigh(C)\n    else:\n        C = np.dot(X,X.T)\n        [eigenvalues,eigenvectors] = np.linalg.eigh(C)\n        eigenvectors = np.dot(X.T,eigenvectors)\n        for i in range(n):\n            eigenvectors[:,i] = eigenvectors[:,i]\/np.linalg.norm(eigenvectors[:,i])\n    # or simply perform an economy size decomposition\n    # eigenvectors, eigenvalues, variance = np.linalg.svd(X.T, full_matrices=False)\n    # sort eigenvectors descending by their eigenvalue\n    idx = np.argsort(-eigenvalues)\n    eigenvalues = eigenvalues[idx]\n    eigenvectors = eigenvectors[:,idx]\n    # select only num_components\n    eigenvalues = eigenvalues[0:num_components].copy()\n    eigenvectors = eigenvectors[:,0:num_components].copy()\n    return [eigenvalues, eigenvectors, mu]\n\ndef lda(X, y, num_components=0):\n    print(X.shape)\n    y = np.asarray(y)\n    [n,d] = X.shape\n    c = np.unique(y)\n    if (num_components <= 0) or (num_component>(len(c)-1)):\n        num_components = (len(c)-1)\n    meanTotal = X.mean(axis=0)\n    Sw = np.zeros((d, d), dtype=np.float32)\n    Sb = np.zeros((d, d), dtype=np.float32)\n    for i in c:\n        Xi = X[np.where(y==i)[0],:]\n        meanClass = Xi.mean(axis=0)\n        Sw = Sw + np.dot((Xi-meanClass).T, (Xi-meanClass))\n        Sb = Sb + n * np.dot((meanClass - meanTotal).T, (meanClass - meanTotal))\n    eigenvalues, eigenvectors = np.linalg.eig(np.linalg.inv(Sw)*Sb)\n    idx = np.argsort(-eigenvalues.real)\n    eigenvalues, eigenvectors = eigenvalues[idx], eigenvectors[:,idx]\n    eigenvalues = np.array(eigenvalues[0:num_components].real, dtype=np.float32, copy=True)\n    eigenvectors = np.array(eigenvectors[0:,0:num_components].real, dtype=np.float32, copy=True)\n    return [eigenvalues, eigenvectors]\n\ndef fisherfaces(X,y,num_components=0):\n    y = np.asarray(y)\n    [n,d] = X.shape\n\n    c = len(np.unique(y))\n    [eigenvalues_pca, eigenvectors_pca, mu_pca] = pca(X, y, (n-c))\n    [eigenvalues_lda, eigenvectors_lda] = lda(project(eigenvectors_pca, X, mu_pca), y, num_components)\n    eigenvectors = np.dot(eigenvectors_pca,eigenvectors_lda)\n    return [eigenvalues_lda, eigenvectors, mu_pca]\n\ndef project(W, X, mu=None):\n    if mu is None:\n        return np.dot(X,W)\n    return np.dot(X - mu, W)\ndef reconstruct(W, Y, mu=None):\n    if mu is None:\n        return np.dot(Y,W.T)\n    return np.dot(Y, W.T) + mu\n","7fae575b":"class AbstractDistance(object):\n    def __init__(self, name):\n        self._name = name\n\n    def __call__(self,p,q):\n        raise NotImplementedError(\"Every AbstractDistance must implement the __call__ method.\")\n\n    @property\n    def name(self):\n        return self._name\n\n    def __repr__(self):\n        return self._name\n\nclass EuclideanDistance(AbstractDistance):\n\n    def __init__(self):\n        AbstractDistance.__init__(self,\"EuclideanDistance\")\n\n    def __call__(self, p, q):\n        p = np.asarray(p).flatten()\n        q = np.asarray(q).flatten()\n        return np.sqrt(np.sum(np.power((p-q),2)))\n\nclass CosineDistance(AbstractDistance):\n\n    def __init__(self):\n        AbstractDistance.__init__(self,\"CosineDistance\")\n\n    def __call__(self, p, q):\n        p = np.asarray(p).flatten()\n        q = np.asarray(q).flatten()\n        return -np.dot(p.T,q) \/ (np.sqrt(np.dot(p,p.T)*np.dot(q,q.T)))\n\nclass BaseModel(object):\n    def __init__(self, X=None, y=None, dist_metric=EuclideanDistance(), num_components=0):\n        self.dist_metric = dist_metric\n        self.num_components = 0\n        self.projections = []\n        self.W = []\n        self.mu = []\n        if (X is not None) and (y is not None):\n            self.compute(X,y)\n\n    def compute(self, X, y):\n        raise NotImplementedError(\"Every BaseModel must implement the compute method.\")\n\n    def predict(self, X):\n        minDist = np.finfo('float').max\n        minClass = -1\n        Q = project(self.W, X.reshape(1,-1), self.mu)\n        for i in range(len(self.projections)):\n            dist = self.dist_metric(self.projections[i], Q)\n            if dist < minDist:\n                minDist = dist\n                minClass = self.y[i]\n        return minClass\n\nclass EigenfacesModel(BaseModel):\n\n    def __init__(self, X=None, y=None, dist_metric=EuclideanDistance(), num_components=0):\n        super(EigenfacesModel, self).__init__(X=X,y=y,dist_metric=dist_metric,num_components=num_components)\n\n    def compute(self, X, y):\n        [D, self.W, self.mu] = pca(asRowMatrix(X),y, self.num_components)\n    # store labels\n        self.y = y\n    # store projections\n        for xi in X:\n            self.projections.append(project(self.W, xi.reshape(1,-1), self.mu))\n\nclass FisherfacesModel(BaseModel):\n\n    def __init__(self, X=None, y=None, dist_metric=EuclideanDistance(), num_components=0):\n        super(FisherfacesModel, self).__init__(X=X,y=y,dist_metric=dist_metric,num_components=num_components)\n\n    def compute(self, X, y):\n        [D, self.W, self.mu] = fisherfaces(asRowMatrix(X),y, self.num_components)\n        # store labels\n        self.y = y\n        # store projections\n        for xi in X:\n            self.projections.append(project(self.W, xi.reshape(1,-1), self.mu))\n\n\ndef normalize(X, low, high, dtype=None):\n    X = np.asarray(X)\n    minX, maxX = np.min(X), np.max(X)\n    # normalize to [0...1].\t\n    X = X - float(minX)\n    X = X \/ float((maxX - minX))\n    # scale to [low...high].\n    X = X * (high-low)\n    X = X + low\n    if dtype is None:\n        return np.asarray(X)\n    return np.asarray(X, dtype=dtype)\n\n\n\n","1eae3bbd":"# read images( from the folder containing yalefaces data )\n# print(X)\n\n\nfrom sklearn.model_selection import train_test_split\nX = np.load(\"\/kaggle\/input\/olivetti\/olivetti_faces.npy\")\ny = np.load(\"\/kaggle\/input\/olivetti\/olivetti_faces_target.npy\")\nX_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.3, stratify=y, random_state=0)\nprint(X.shape,y.shape)","9fd7e654":"# compute the eigenfaces model\nmodel = FisherfacesModel (X_train, y_train,CosineDistance() )\n# get a prediction for the first observation\nprint (\" expected \" , y [22] , \"\/\" , \" predicted =\" , model . predict ( X [22]))\n","4ad6d635":"y_pred =np.random.random(y_test.shape)\nfor i in range(len(X_test)):\n    y_pred[i] = model.predict(X_test[i])","db0700bf":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import precision_score, classification_report","180e0b48":"print(classification_report(y_test, y_pred))","721889c9":"print('Accuracy ' + str(accuracy_score(y_test, y_pred)))\nprint('f1_score ' + str(f1_score(y_test, y_pred,average='micro')))\nprint('Recall score ' + str(recall_score(y_test, y_pred,average='micro')))\nprint('Precision ' + str(precision_score(y_test, y_pred,average='micro')))","0be26fe3":"Loading the data"}}