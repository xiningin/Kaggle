{"cell_type":{"e411f919":"code","2e436b1d":"code","5bda09f7":"code","354f6a79":"code","098e38de":"code","c0f6496f":"code","1c73e82a":"code","98ac7176":"code","affffe9f":"code","766af317":"code","d98e54a2":"code","8eaa8096":"code","a50cff93":"markdown","99fa1403":"markdown","304f435a":"markdown","31f361fc":"markdown","808f45ce":"markdown","86451c69":"markdown","b02dcf60":"markdown","7803bb68":"markdown","886a3879":"markdown","da3e1cfd":"markdown","1c68134e":"markdown"},"source":{"e411f919":"! pip install sktime==0.4.3","2e436b1d":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport warnings\nimport itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\nfrom sktime.forecasting.base import ForecastingHorizon\nfrom pylab import rcParams\n\nrcParams['figure.figsize'] = 18, 8\nwarnings.filterwarnings(\"ignore\")\n\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\n#-----------------------Imports from Sktime--------------------------\n\nfrom sktime.transformers.single_series.detrend import Deseasonalizer, Detrender\nfrom sktime.forecasting.trend import PolynomialTrendForecaster\nfrom sktime.forecasting.model_selection import (\n    ForecastingGridSearchCV,\n    SlidingWindowSplitter,\n    temporal_train_test_split,\n)\nfrom sktime.utils.plotting import plot_series\nfrom sktime.forecasting.compose import (\n    TransformedTargetForecaster,\n    ReducedRegressionForecaster\n)","5bda09f7":"#------------------------Reading Data from CSV---------------------------\n\ndf = pd.read_csv(\"\/kaggle\/input\/demand-forecasting-kernels-only\/train.csv\"\n                ,parse_dates=['date'])\ndf.head()","354f6a79":"#--------------------------Data Preparation-------------------------\n\n#For the sake of demonstartion, we will train our model on monthly aggregated Sales data of a particular store \n\n# Select sales for Store 1 Only.\nstore1_agg = df.loc[df['store']==1].groupby(['date'])['sales'].sum()\nstore1_agg.index = pd.to_datetime(store1_agg.index)\n\n#Aggregate the Data on a Monthly basis.\nstore1_agg_monthly = store1_agg.resample('M').sum()\nstore1_agg_monthly.head()","098e38de":"#--------------------Visulaize Data on a Time Plot-------------------\n\nsns.lineplot(\n    data=store1_agg_monthly, \n)\nplt.show()","c0f6496f":"#----------------------Time Series Decomposition---------------------\n\nseasonal_decompose(store1_agg_monthly,model=\"multiplicative\",period=12).plot()\nplt.show()","1c73e82a":"#--------------------Time Series Train-Test split-------------------\n\nstore1_agg_monthly.index = store1_agg_monthly.index.to_period('M') \ny_train, y_test = temporal_train_test_split(store1_agg_monthly, test_size=0.2)","98ac7176":"#--------------------------Detrender-----------------------------\n\n#degree=1 for Linear\nforecaster = PolynomialTrendForecaster(degree=1) \ntransformer = Detrender(forecaster=forecaster)\n\n#Get the residuals after fitting a linear trend\ny_resid = transformer.fit_transform(y_train)\n\n# Internally, the Detrender uses the in-sample predictions\n# of the PolynomialTrendForecaster\nforecaster = PolynomialTrendForecaster(degree=1)\nfh_ins = -np.arange(len(y_train))  # in-sample forecasting horizon\ny_pred = forecaster.fit(y_train).predict(fh=fh_ins)\n\nplot_series(y_train, y_pred, y_resid, labels=[\"y_train\", \"fitted linear trend\", \"residuals\"]);","affffe9f":"#--------------------------Detrender-----------------------------\n\n#Multiplicative Deseasonalizer, period = 12(for Monthly Data)\ndeseasonalizer = Deseasonalizer(model=\"multiplicative\", sp=12)\nplot_series(deseasonalizer.fit_transform(y_train))\nseasonal = deseasonalizer.fit_transform(y_train)","766af317":"#----------------------------Create Pipeline--------------------\n\ndef get_transformed_target_forecaster(alpha,params):\n    \n    #Initialize Light GBM Regressor \n    \n    regressor = lgb.LGBMRegressor(alpha = alpha,**params)\n\n    #-----------------------Forecaster Pipeline-----------------\n    \n    #1.Separate the Seasonal Component.\n    #2.Fit a forecaster for the trend.\n    #3.Fit a Autoregressor to the resdiual(autoregressing on two historic values).\n    \n    forecaster = TransformedTargetForecaster(\n        [\n            (\"deseasonalise\", Deseasonalizer(model=\"multiplicative\", sp=12)),\n            (\"detrend\", Detrender(forecaster=PolynomialTrendForecaster(degree=1))),\n            (\n                # Recursive strategy for Multi-Step Ahead Forecast.\n                # Auto Regress on two previous values\n                \"forecast\",\n                ReducedRegressionForecaster(\n                    regressor=regressor, window_length=4, strategy=\"recursive\",\n                ),\n            ),\n        ]\n    )\n    return forecaster","d98e54a2":"#-------------------Fitting an Auto Regressive Light-GBM-----------------\n\n#Setting Quantile Regression Hyper-parameter.\nparams = {\n    'objective':'quantile'\n}\n\n#A 10 percent and 90 percent prediction interval(0.1,0.9 respectively).\nquantiles = [.1, .5, .9] #Hyper-parameter \"alpha\" in Light GBM\n\n#Capture forecasts for 10th\/median\/90th quantile, respectively.\nforecasts = []\n\n#Iterate for each quantile.\nfor alpha in quantiles:\n    \n    forecaster = get_transformed_target_forecaster(alpha,params)\n    \n    #Initialize ForecastingHorizon class to specify the horizon of forecast\n    fh = ForecastingHorizon(y_test.index, is_relative=False)\n    \n    #Fit on Training data.\n    forecaster.fit(y_train)\n    \n    #Forecast the values.\n    y_pred = forecaster.predict(fh)\n    \n    #List of forecasts made for each quantile.\n    y_pred.index.name=\"date\"\n    y_pred.name=f\"predicted_sales_q_{alpha}\"\n    forecasts.append(y_pred)\n    \n#Append the actual data for plotting.\nstore1_agg_monthly.index.name = \"date\"\nstore1_agg_monthly.name = \"original\"\nforecasts.append(store1_agg_monthly)","8eaa8096":"#-------------------Final Plotting of Forecasts------------------\n\nplot_data = pd.melt(pd.concat(forecasts,axis=1).reset_index(), id_vars=['date'],\\\n        value_vars=['predicted_sales_q_0.1', 'predicted_sales_q_0.5',\n                   'predicted_sales_q_0.9','original'])\nplot_data['date'] = pd.to_datetime(plot_data['date'].astype(str).to_numpy())\nplot_data['if_original'] = plot_data['variable'].apply(\n    lambda r:'original' if r=='original' else 'predicted' \n)\nsns.lineplot(data = plot_data,\n        x='date',\n        y='value',\n        hue='if_original',\n             style=\"if_original\",\n        markers=['o','o'],\n)\nplt.show()","a50cff93":"# Introduction\n<a id=\"intro\"><\/a>\n\nWhen it comes to Auto Regression, the variants of ARIMA dominate the time series market. Can we use machine learning models for the same purpose? We can certainly structure the Time-Series data in a way that it serves our purpose.\nThs notebook focuses on using a new and promising Python library [Sktime](https:\/\/github.com\/alan-turing-institute\/sktime) for multi step ahead forecasts using Tree Ensembles(or any Regression Model).","99fa1403":"### Fitting a Deseasonalizer\nWe fit a Deseasonalizer in this step, we will use this to forecast the seasonality. We extract the Monthly Seasonality in this step(period=12)","304f435a":"## Decomposition of Data\n<a id=\"dcp\"><\/a>\n\nThe above plot gives us an idea that the time series is seasonal and heteroskedastic. We need to use a **multiplicative decomposition** in such a case, to examine its **seasonal and trend** components and the residuals.","31f361fc":"## Preparing the Data","808f45ce":"![image.png](attachment:image.png)","86451c69":"## Conclusion\n<a id=\"conc\"><\/a>\nWill create more notebooks demonstrating other features from this Library.Thanks!","b02dcf60":"### Fitting a Detrender\nWe fit a **Linear Trend**  detector in this step, we will use this to forecast the future trend. ","7803bb68":"### Fitting an Autoregressor.\nAfter removing the Linear Trend and Seasonal Components, we use an Autoregressor to regress on its previous values and forecast. These 3 sequential steps can be conveniently pipelined using **TransformedTargetForecaster**. So it abstracts the steps of first forecasting Seasonality, Trend, the forecasts of the Autoregressor, and then finally combining the three components to get a single forecast! To generate the Prediction Intervals we create three such abstractions.","886a3879":"# Reading Data and Preparation\n<a id=\"rdp\"><\/a>","da3e1cfd":"# Table Of Contents\n* [Introduction](#intro)\n* [Reading Data and Preparation](#rdp)\n* [Decomposition of Data](#dcp)\n* [Model Fitting](#fit)\n* [Conclusion](#conc)","1c68134e":"## Model Fitting\n<a id=\"fit\"><\/a>\nHere we explore Sktime's Regression Wrapper for Time Series Forecating."}}