{"cell_type":{"20483375":"code","26450e25":"code","832533fc":"code","0c425070":"code","56d4a273":"code","6619e104":"code","dac85254":"code","215eac71":"code","001bb5b3":"code","01541470":"code","097921f9":"code","1591a931":"code","574a71ef":"code","c98f94aa":"code","0c73f1c8":"code","952d32d8":"code","1a3e6876":"code","be730044":"code","7d44368f":"code","a7670954":"code","e5a9d176":"code","b485baac":"code","e977c52b":"code","9686937f":"code","fc317475":"code","5ef2fb4c":"code","01ddad27":"code","afb2f2dd":"code","838b5223":"code","fdb2aa5b":"code","31e9697d":"code","b4bed0ba":"code","a114fdb5":"code","213926f7":"code","2f47eb0b":"code","fec2f33e":"code","d15a0433":"code","8cc17d88":"code","dab153dd":"code","66d5b223":"code","18415df3":"code","2a517eab":"code","e434ab71":"code","9d28a77e":"code","ed3c9c4d":"code","d8aa0222":"code","ca5157e6":"code","60a2a0df":"code","634f0361":"code","ee7bb8e6":"code","b1493fbd":"code","ea6025f1":"code","ed742fb9":"code","635c7764":"code","f405f9c3":"code","9ae83229":"code","db3a6f2b":"code","b1f75688":"code","ab259e15":"markdown","512dcdb2":"markdown","b7d95fe6":"markdown","60ef8157":"markdown","a8d9b060":"markdown","a89e8a60":"markdown","f4529862":"markdown","299277de":"markdown","6514f5eb":"markdown","77fce084":"markdown","eff3ed12":"markdown","76d1bbcb":"markdown","b4977dd1":"markdown","3518ebca":"markdown","3f172c86":"markdown","f39522d0":"markdown","ca43c1c4":"markdown","7b87ad68":"markdown","d5b00ff6":"markdown","d5d2de76":"markdown","81ac9c4d":"markdown","f8077316":"markdown","504c1436":"markdown","71c23251":"markdown","30b8d63c":"markdown","a17a99da":"markdown","011108f5":"markdown","de7db52b":"markdown","5963dfe4":"markdown","0c4a0034":"markdown","990b0d34":"markdown","74c30180":"markdown","7cdb18c5":"markdown","f30490bc":"markdown","ddf9de82":"markdown","a3e8f1bf":"markdown","8c5e6082":"markdown","ddd81c7a":"markdown"},"source":{"20483375":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\nimport numpy as np\nstroke_data =pd.read_csv('..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv')\nstroke_data.shape","26450e25":"stroke_data.info()\n","832533fc":"stroke_data.head(5)","0c425070":"stroke_data.tail(5)","56d4a273":"stroke_data.describe()","6619e104":"# Gender column\nstroke_data.gender.value_counts()","dac85254":"# Age column\nstroke_data.age.value_counts()","215eac71":"# Hypertension column\nstroke_data.hypertension.value_counts()","001bb5b3":"# Heart disease column\nstroke_data.heart_disease.value_counts()","01541470":"# Ever-married column\nstroke_data.ever_married.value_counts()","097921f9":"# Work type column\nstroke_data.work_type.value_counts()","1591a931":"# Residence type column\nstroke_data.Residence_type.value_counts()","574a71ef":"# Average glucose level column\nstroke_data.avg_glucose_level.describe()","c98f94aa":"# BMI column\nstroke_data.bmi.isnull().sum()","0c73f1c8":"# Smoking status column\nstroke_data.smoking_status.value_counts()","952d32d8":"# Stroke column\nstroke_data.stroke.value_counts()","1a3e6876":"# Drop ID column.\n\nstroke_data= stroke_data.drop(columns= 'id')\nstroke_data.info()","be730044":"# Change the format of 'hyper tension', 'heart disease', 'stroke' to category.\n\nstroke_data['hypertension'] = stroke_data['hypertension'].astype('category')\nstroke_data['heart_disease'] = stroke_data['heart_disease'].astype('category')\nstroke_data['stroke'] = stroke_data['stroke'].astype('category')\nstroke_data['gender'] = stroke_data['gender'].astype('category')\nstroke_data.info()","7d44368f":"# Fill the 201 null values in 'BMI' column.\n# Let's ignore the 'other' column since it will be removed. \n# We will fill each missing value in 'bmi' column with the mean value for each gender\nstroke_data.groupby('gender')['bmi'].mean()","a7670954":"# Mean bmi for male = 28.6 \/\/ mean bmi for female = 29, So pretty much the same value\nstroke_data = stroke_data.fillna(stroke_data.mean())\n\n# Now let's check that all null values are replaced with the mean values.\nstroke_data.bmi.isnull().sum()","e5a9d176":"# Drop the 'other' category in the gender column.\nother = stroke_data[stroke_data['gender'] == 'Other'].index\nstroke_data.drop(other, axis=0, inplace= True)\nstroke_data.gender.value_counts()","b485baac":"# Add values under children category to those of never worked category.\nstroke_data.work_type = np.where(stroke_data['work_type'] == 'children','Never_worked',stroke_data.work_type)\nstroke_data.work_type.value_counts()","e977c52b":"# Create 'age category' column.\nconditions= [(stroke_data['age'] <=14), \n                 (stroke_data['age'] >=15) & (stroke_data['age']<=24),\n                 (stroke_data['age'] >=25) & (stroke_data['age']<=64),\n                 (stroke_data['age'] >= 65)\n]\n\nvalues= ['Child','Youth','Adult','Senior']\n\n#Create the new column\nstroke_data['Age_Category']= np.select(conditions,values)\n\n#Now we check if the new column is added\nstroke_data.head(5)","9686937f":"stroke_data.loc[stroke_data['bmi'] < 12 ]\n","fc317475":"stroke_data = stroke_data.drop(labels=[1609,2187,3307], axis=0)\n","5ef2fb4c":"#Now let's make sure the records are deleted\nstroke_data.loc[stroke_data['bmi'] < 12 ]\n","01ddad27":"#Investigate records with BMI more than 50\nstroke_data.loc[stroke_data['bmi'] > 50 ]","afb2f2dd":"stroke_data.drop(stroke_data.index[stroke_data['bmi'] > 50], inplace = True)","838b5223":"#Now let's make sure the records are deleted\nstroke_data.loc[stroke_data['bmi'] > 50 ]","fdb2aa5b":"X= stroke_data[['age', 'avg_glucose_level', 'bmi']]\ny= stroke_data['stroke']","31e9697d":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=0) ","b4bed0ba":"logreg= LogisticRegression()\nlogreg.fit(X_train,y_train) ","a114fdb5":"y_pred=logreg.predict(X_test)\nprint (X_test) #test dataset\nprint (y_pred) #predicted values","213926f7":"from sklearn.metrics import confusion_matrix\nmatrix = confusion_matrix(y_test, y_pred, normalize= 'all')\nprint(matrix)\n\n#Let's visualize the matrix\nimport seaborn as sns\nsns.heatmap(matrix, annot=True)","2f47eb0b":"from sklearn import metrics\nprint('Accuracy: ',metrics.accuracy_score(y_test, y_pred))\nprint('Recall: ',metrics.recall_score(y_test, y_pred))\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred))\nprint(\"CL Report:\",metrics.classification_report(y_test, y_pred))","fec2f33e":"#This dataset is fictional and for illustrating only.\nnew_patients= {'age': [20, 35, 70, 80, 90, 100], 'avg_glucose_level': [120, 140, 160, 200, 170, 150], 'bmi': [20, 25, 18, 30, 19, 31]}\nstroke_new= pd.DataFrame(new_patients, columns= ['age', 'avg_glucose_level', 'bmi'])\nstroke_new","d15a0433":"X= stroke_data[['age', 'avg_glucose_level', 'bmi']]\ny= stroke_data['stroke']\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=0) \n\nlogreg= LogisticRegression()\nlogreg.fit(X, y.values.ravel())\n\n\nnew_patients= {'age': [20, 35, 70, 80, 90, 100], 'avg_glucose_level': [120, 140, 160, 200, 170, 150], 'bmi': [20, 25, 18, 30, 19, 31]}\nstroke_new= pd.DataFrame(new_patients, columns= ['age', 'avg_glucose_level', 'bmi'])\n\nstroke_new = pd.DataFrame(new_patients,columns= ['age', 'avg_glucose_level', 'bmi'])\ny_pred=logreg.predict(stroke_new)\n\nprint (stroke_new)\nprint (y_pred)","8cc17d88":"print(y_pred)","dab153dd":"stroke_data.head(5)","66d5b223":"fig,ax = plt.subplots(figsize = (6,8))\n#Create dataset that shows each age value and its corresponding stroke state\nage_data= pd.concat([stroke_data['age'], y], axis=1)\n\n#Create dataset for the plot\nage_plot= pd.melt(age_data, id_vars= 'stroke', var_name= 'age')\n\n#Create the plot\nsns.boxplot(x= 'age', y= 'value', hue= 'stroke', data= age_plot, palette=\"Set2\")","18415df3":"fig,ax = plt.subplots(figsize = (8,10))\n#Create dataset that shows smoking state and its corresponding stroke state\nagecat_data= pd.concat([stroke_data['Age_Category'], y], axis=1)\n\n#Create dataset for the plot\nagecat_plot= stroke_data[['Age_Category', 'stroke']].value_counts().reset_index()\n\n#Create the plot\nsns.barplot(x= 'Age_Category', y= 0, hue= 'stroke', data= agecat_plot, palette=\"Set2\")","2a517eab":"fig,ax = plt.subplots(figsize = (6,8))\n#Create dataset that shows each glucose level value and its corresponding stroke state\nglucose_data= pd.concat([stroke_data['avg_glucose_level'], y], axis=1)\n\n#Create dataset for the plot\nglucose_plot= pd.melt(glucose_data, id_vars= 'stroke', var_name= 'avg_glucose_level')\n\n#Create the plot\nsns.boxplot(x= 'avg_glucose_level', y= 'value', hue= 'stroke', data= glucose_plot, palette=\"Set1\")","e434ab71":"fig,ax = plt.subplots(figsize = (6,8))\n#Create dataset that shows each bmi value and its corresponding stroke state\nbmi_data= pd.concat([stroke_data['bmi'], y], axis=1)\n\n#Create dataset for the plot\nbmi_plot= pd.melt(bmi_data, id_vars= 'stroke', var_name= 'bmi')\n\n#Create the plot\nsns.boxplot(x= 'bmi', y= 'value', hue= 'stroke', data= bmi_plot, palette=\"Set3\")","9d28a77e":"fig,ax = plt.subplots(figsize = (6,8))\n#Create dataset that shows each gender and its corresponding stroke state\ngender_data= pd.concat([stroke_data['gender'], y], axis=1)\n\n#Create dataset for the plot\ngender_plot= stroke_data[['gender', 'stroke']].value_counts().reset_index()\n\n#Create the plot\nsns.barplot(x= 'gender', y= 0, hue= 'stroke', data= gender_plot, palette=\"Set2\")","ed3c9c4d":"gender_plot= stroke_data[['gender', 'stroke']].value_counts().reset_index()\ngender_plot.head(5)","d8aa0222":"fig,ax = plt.subplots(figsize = (6,8))\n#Create dataset that shows hypertension state and its corresponding stroke state\nhypertn_data= pd.concat([stroke_data['hypertension'], y], axis=1)\n\n#Create dataset for the plot\nhypertn_plot= stroke_data[['hypertension', 'stroke']].value_counts().reset_index()\n\n#Create the plot\nsns.barplot(x= 'hypertension', y= 0, hue= 'stroke', data= hypertn_plot, palette=\"Set2\")","ca5157e6":"hypertn_plot= stroke_data[['hypertension', 'stroke']].value_counts().reset_index()\nhypertn_plot.head(5)","60a2a0df":"fig,ax = plt.subplots(figsize = (6,8))\n#Create dataset that shows heart disease state and its corresponding stroke state\nheart_data= pd.concat([stroke_data['heart_disease'], y], axis=1)\n\n#Create dataset for the plot\nheart_plot= stroke_data[['heart_disease', 'stroke']].value_counts().reset_index()\n\n#Create the plot\nsns.barplot(x= 'heart_disease', y= 0, hue= 'stroke', data= heart_plot, palette=\"Set1\")","634f0361":"heart_plot= stroke_data[['heart_disease', 'stroke']].value_counts().reset_index()\nheart_plot.head()","ee7bb8e6":"fig,ax = plt.subplots(figsize = (6,8))\n#Create dataset that shows marital status and its corresponding stroke state\nsocial_data= pd.concat([stroke_data['ever_married'], y], axis=1)\n\n#Create dataset for the plot\nsocial_plot= stroke_data[['ever_married', 'stroke']].value_counts().reset_index()\n\n#Create the plot\nsns.barplot(x= 'ever_married', y= 0, hue= 'stroke', data= social_plot, palette=\"Set1\")","b1493fbd":"social_plot= stroke_data[['ever_married', 'stroke']].value_counts().reset_index()\nsocial_plot.head()","ea6025f1":"fig,ax = plt.subplots(figsize = (6,8))\n#Create dataset that shows work type and its corresponding stroke state\nwork_data= pd.concat([stroke_data['work_type'], y], axis=1)\n\n#Create dataset for the plot\nwork_plot= stroke_data[['work_type', 'stroke']].value_counts().reset_index()\n\n#Create the plot\nsns.barplot(x= 'work_type', y= 0, hue= 'stroke', data= work_plot, palette=\"Set2\")","ed742fb9":"work_plot= stroke_data[['work_type', 'stroke']].value_counts().reset_index()\nwork_plot.head(10)","635c7764":"fig,ax = plt.subplots(figsize = (8,10))\n#Create dataset that shows work type and its corresponding stroke state\nresidence_data= pd.concat([stroke_data['Residence_type'], y], axis=1)\n\n#Create dataset for the plot\nresidence_plot= stroke_data[['Residence_type', 'stroke']].value_counts().reset_index()\n\n#Create the plot\nsns.barplot(x= 'Residence_type', y= 0, hue= 'stroke', data= residence_plot, palette=\"Set2\")","f405f9c3":"fig,ax = plt.subplots(figsize = (8,10))\n#Create dataset that shows smoking state and its corresponding stroke state\nsmoking_data= pd.concat([stroke_data['smoking_status'], y], axis=1)\n\n#Create dataset for the plot\nsmoking_plot= stroke_data[['smoking_status', 'stroke']].value_counts().reset_index()\n\n#Create the plot\nsns.barplot(x= 'smoking_status', y= 0, hue= 'stroke', data= smoking_plot, palette=\"Set2\")","9ae83229":"smoking_plot= stroke_data[['smoking_status', 'stroke']].value_counts().reset_index()\nsmoking_plot.head(10)","db3a6f2b":"stroke_data.to_csv(r'C:\\Users\\sss-a\\Desktop\\Practicum Internship\\Project\\healthcare-dataset-stroke-data.csv')","b1f75688":"stroke_data.head(5)","ab259e15":"#### The result here is quite interesting, it was expected that smokers have a higher risk of a stroke but the data shows that 735 smoker patients never experienced a stroke while 89 non-smoker already had a stroke, so unlike the usual, smoking status is definetely not a good predictor of a stroke.","512dcdb2":"#### II- According to age category","b7d95fe6":"#### We notice here that there're many outliers in bmi values, also some patients with bmi ranging from (28-33) already had a stroke while others with the same bmi didn't, so bmi value is a bit misleading and cannot be considered a good predictor of a stroke.","60ef8157":"#### It's clear that the largest proportion of those who had a stroke are in the private sector (148), although itsn't an important risk factor it's worth taken into consideration","a8d9b060":"### Let's evaluate the model we've just built using model evaluation metrics such as accuracy, recall and precision.","a89e8a60":"#### 1- The relation between 'Age' and 'Stroke'\n#### I- According to age range","f4529862":"#### 5-The relation between 'Hypertension' and 'Stroke'","299277de":"Split the dataset into train and test:","6514f5eb":"#### From the visual we can notice that higher glucose levels are associated with a higher risk of a stroke, also there're too many outliers.\n#### Glucose levels ranging between 80-120 are not a precise indicator to predict a stroke since some patients with this glucose level had a stroke and others didn't.","77fce084":"### III- Build a simple logistic model to predict strokes using other variables.\n","eff3ed12":"#### From the previous we notice that:\n#### 228 patients have heart disease but didn't have a stroke which means that heart disease isn't a propable risk factor for strokes.\n#### 201 patients had a stroke but don't suffer from heart disease and that signifies that stroke isn't necesarily associated with heart disease.\n#### 47 patients both had a stroke and suffer from heart disease, so that's 47 out of 5110 which is clearly not a reliable proportion to tell that heart disease is a crucial predictor.","76d1bbcb":"#### 9-The relation between 'Residence type' and 'Stroke'","b4977dd1":"#### 7-The relation between 'Marital status' and 'Stroke'","3518ebca":"## Perform Exploratory Data Analysis on the data set\n\n### I- Assessing\nIn this stage we display the data we're going to import to assess its Quality and Tidiness.\n\nQuality dimensions or aspects are mainly:\n\n**1**- Completness (checking if there are any missing records).\n\n**2**- Validity (Checking if the values displayed are 'valid' i.e data that follow certain known rules)\n\n**3**- Accuracy (a significant decrease or increase in a value is considered an 'inaccurate data')\n\n**4**- Consistency (There should be only one way to represent or refer to a value otherwise the data is called to be 'inconsistent')","3f172c86":"### This dataset has 5110 records and 12 columns representing 12 different clinical and demographic features.\n#### From the analysis, the following points were concluded:\n#### 1- Seniors have a higher risk of stroke compared to adults and youth, so it's a good indicator.\n#### 2- The level of average glucose isn't a good predictor.\n#### 3- BMI values are misleading and can never be considered a risk factor for strokes.\n#### 4- Gender data showed that both males and females have strokes but more females suffered from strokes than males.\n#### 5- Hypertension is definitely not a good indicator for strokes since many hypertensive patients didn't have a stroke and other who aren't did suffer from a stroke, the same conclusion applies for heart disease which surprisingly was not a propable risk factor.\n#### 6- Marital status, residence type and smoking status are all unimportant in predicting strokes for this dataset.\n#### 7- On the other hand, people working in the private sector showed higher level of stroke than people with other work types, the number isn't significant but it's worth taken into consideration in further studies.","f39522d0":"### II-Cleaning\n- Drop ID column since it's not necessary in our analysis.\n- Change the format of 'hyper tension', 'heart disease', 'stroke', 'Gender' to category.\n- Fill the 201 null values in 'BMI' column.\n- Drop the 'other' category in the gender column.\n- Add values under children category to those of never worked category.\n- Create 'age category' column.","ca43c1c4":"#### 3-The relation between 'BMI' and 'Stroke'","7b87ad68":"#### 2-The relation between 'Glucose level' and 'Stroke'","d5b00ff6":"**Further Exploration**\n- Some values in the BMI column made no sense.\nA mean BMI value of 12 as the lower limit for human survival and the maximum possible BMI is 50 which falls under the 'extremely obese' category.\nHence BMI values less than 12 or more than 50 are considered outliers and should be dealt with.","d5d2de76":"#### It seems that residence type doesn't have much of an effect on predicting strokes.","81ac9c4d":"#### 4-The relation between 'Gender' and 'Stroke'","f8077316":"#### It's clear from the plot that older patients 'seniors' (60-80 years) are more likely to have a stroke than younger people, so age is a crucial factor in predicting strokes.","504c1436":"Now let's try the model on the new dataset:","71c23251":"#### The data shows that marriage is not a significant factor in predicting a stroke.","30b8d63c":"#### 10-The relation between 'Smoking status' and 'Stroke'","a17a99da":"### Model Evaluation using Confusion Matrix\n#### A confusion matrix is a table that is used to evaluate the performance of a classification model. You can also visualize the performance of an algorithm. The fundamental of a confusion matrix is the number of correct and incorrect predictions are summed up class-wise.","011108f5":"Now if we have other patients with different ages, BMI or glucose level, the model can predict if they may have a stroke or not.","de7db52b":"* Note: some values in the 'Age' column doesn't make any sense.","5963dfe4":"* Note: 687 records in this column are assigned under 'children' category which is not a suitable work type.","0c4a0034":"#### 8-The relation between 'Work type' and 'Stroke'","990b0d34":"Create a logistic regression body:","74c30180":"#### From the previous plot & table, it's clear that  females (140) were more likely to have a stroke than males (108).","7cdb18c5":"Record 1609 is a baby so a BMI of 10.3 is acceptable, but the other 2 records are for a 40 year-old male and a 79 year-old female having very low BMI levels. Anyhow, they didn't have a stroke so we can safely remove them.\n","f30490bc":"Split the dataset into X and Y:","ddf9de82":"## Final conclusions","a3e8f1bf":"#### 6-The relation between 'Heart disease' and 'Stroke'","8c5e6082":"#### From the previous we notice that:\n#### 415 patients are hypertensive but didn't have a stroke which means that hypertension isn't a propable risk factor for strokes.\n#### 182 patients had a stroke but aren't hypertensive and that signifies that stroke isn't necesarily associated with hypertension.\n#### 66 patients both had a stroke and are hypertensive, so that's 66 out of 5110 which is clearly not a reliable proportion to tell that hypertension is a crucial predictor.","ddd81c7a":"### IV- Analysis and visualization \n#### We'll now look at the relationships between the stroke and different variables."}}