{"cell_type":{"dfb8fbac":"code","ea64854e":"code","c3eff2fe":"code","e2e0b20d":"code","ae1c2875":"code","792c8cb8":"code","65c6665c":"code","d37be959":"code","98560ea9":"code","a4dcf7a5":"code","9975fa4f":"code","ef7c62f6":"code","0b920788":"code","047b5c7f":"markdown","97504b7f":"markdown","a003ee1c":"markdown","765242f5":"markdown","83ebf444":"markdown","b2cdb4f1":"markdown","46c9e895":"markdown","c4155cb0":"markdown","15d102dd":"markdown","a353ed04":"markdown","4ce16f40":"markdown","c493ae1e":"markdown","b020a370":"markdown","e6b589be":"markdown","fcec79e9":"markdown","becff577":"markdown","a79fe3b5":"markdown","bae8916e":"markdown","f039653f":"markdown","f40dad66":"markdown","cac39bea":"markdown","07feb03c":"markdown","d1861862":"markdown"},"source":{"dfb8fbac":"import cv2\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt","ea64854e":"image = cv2.imread('\/kaggle\/input\/catdataaugmentation\/cat.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #conver image to RGB in order to use in matplotlib.\nimage = cv2.resize(image, (640, 480))\nrows, cols = image.shape[:2]\nplt.figure(figsize=(15, 15))\nplt.axis('off')\nplt.imshow(image)\n","c3eff2fe":"aug_img_H_Flip = cv2.flip(image, 0)  #vertical flipping\naug_img_V_Flip = cv2.flip(image, 1)  #vertical flipping\naug_img_HV_Flip = cv2.flip(image, -1)  #vertical and horizaontal flipping\n\nfig, ax = plt.subplots(nrows=2, ncols=2,sharex=True, figsize=(25, 25))\n\nax[0][0].set_title(\"Original Image\", fontsize=25); ax[0][0].imshow(image)\nax[0][1].set_title(\"Vertical and Horizaontal flip\", fontsize=25); ax[0][1].imshow(aug_img_HV_Flip)\nax[1][0].set_title(\"Horizaontal flip\", fontsize=25); ax[1][0].imshow(aug_img_H_Flip)\nax[1][1].set_title(\"Vertical flip\", fontsize=25); ax[1][1].imshow(aug_img_V_Flip)\n","e2e0b20d":"aug_img = cv2.flip(image,random.randint(-1, 1)) \nplt.figure(figsize=(10, 10))\nplt.imshow(aug_img)","ae1c2875":"matrix = np.float32([[1, 0, 1],\n                     [0,1, 2]])\n\ntst_img = np.uint16([[10, 20, 30, 40, 50, 60],\n                     [70, 80, 90, 100, 110, 120],\n                     [130, 140, 150, 160, 170, 180],\n                     [140, 150, 160, 170, 180, 190],\n                     [200, 210, 220, 230, 240, 250],\n                     [260, 270, 280, 290, 300, 310]])\n\ncv2.warpAffine(tst_img,matrix, (6, 6))\n","792c8cb8":"tx = random.randint(-.25*cols, .25*cols)\nty = random.randint(-.25*rows, .25*rows)\nM = np.float32([[1, 0, tx], [0, 1, ty]])\naug_img = cv2.warpAffine(image, M, (cols, rows))\nplt.imshow(aug_img)","65c6665c":"x, y = max(tx, 0), max(ty, 0)\nw, h = cols - abs(tx), rows - abs(ty)\naug_img = aug_img[y:y+h, x:x+w] \naug_img = cv2.resize(aug_img, (cols, rows))\nplt.imshow(aug_img)","d37be959":"angle = random.randint(0, 180) #angle in degree.\nangle_radian = angle*(np.pi)\/180 # angle in radian.\nCx, Cy = random.randint(0, 50), random.randint(0, 50)\n\nprint(f'Angle is {angle} ||| Cx is {Cx} ||| Cy is {Cy}')\n\nA = (1-np.cos(angle_radian)) * Cx - np.sin(angle_radian)*Cy \nB = np.sin(angle_radian) * Cx + (1-np.cos(angle_radian)) * Cy\nmat_1 = np.float32([[np.cos(angle_radian), np.sin(angle_radian), A], \n                    [-np.sin(angle_radian), np.cos(angle_radian), B]])\nprint(\"\\n our Calculations\")\nprint(mat_1)\nprint('-'*50)\nprint(\"\\n openCV Calculations\")\nmat_2 = cv2.getRotationMatrix2D((Cx, Cy),angle ,1)\nprint(mat_2)\n","98560ea9":"Cx , Cy = rows, cols #center of rotation\nrand_angle = random.randint(-180,180) #random angle range\nM = cv2.getRotationMatrix2D((Cy\/\/2, Cx\/\/2),rand_angle ,1) #center angle scale\naug_imgR = cv2.warpAffine(image, M, (cols, rows))  #apply rotation matrix such as previously explained\nplt.imshow(aug_imgR)","a4dcf7a5":"aug_img = cv2.cvtColor(image, cv2.COLOR_RGB2HSV) # transform to HSV color space .\nh, s, v = cv2.split(aug_img) # split each channel in order to add seperate range of values to each channel.\nh += np.random.randint(0, 100,size=(rows, cols), dtype=np.uint8 )\ns += np.random.randint(0, 20,size=(rows, cols), dtype=np.uint8 )\nv += np.random.randint(0, 10,size=(rows, cols) , dtype=np.uint8 )\naug_img = cv2.merge([h,s,v ])\naug_img = cv2.cvtColor(aug_img, cv2.COLOR_HSV2RGB)\nplt.imshow(aug_img)","9975fa4f":"blur_val = random.randint(5,15) #blur value random\naug_img = cv2.blur(image,(blur_val, blur_val))\nplt.imshow(aug_img)","ef7c62f6":"#function returns augmented image\ndef augment_image(original_image):\n    rows, cols = original_image.shape[:2]\n    #Random flipping\n    aug_img_final = cv2.flip(original_image,random.randint(-1, 1)) \n    \n    #shifting\n    tx = random.randint(-.35*cols, .35*cols)\n    ty = random.randint(-.35*rows, .35*rows)\n    M = np.float32([[1, 0, tx], [0, 1, ty]])\n    aug_img_final = cv2.warpAffine(aug_img_final, M, (cols, rows))  \n    \n    #cropROI \n    x, y = max(tx, 0), max(ty, 0)\n    w, h = cols - abs(tx), rows - abs(ty)\n    aug_img_final = aug_img_final[y:y+h, x:x+w] \n    aug_img_final = cv2.resize(aug_img_final, (cols, rows))        \n    \n    aug_img_final = cv2.cvtColor(aug_img_final, cv2.COLOR_RGB2HSV)\n    h, s, v = cv2.split(aug_img_final)\n    h += np.random.randint(0, 40,size=(rows, cols), dtype=np.uint8 )\n    s += np.random.randint(0, 10,size=(rows, cols), dtype=np.uint8 )\n    v += np.random.randint(0, 10,size=(rows, cols) , dtype=np.uint8 )\n    aug_img_final = cv2.merge([h,s,v ])\n    aug_img_final = cv2.cvtColor(aug_img_final, cv2.COLOR_HSV2RGB)\n    \n    blur_val = random.randint(2,7)\n    aug_img = cv2.blur(aug_img_final,(blur_val, blur_val))\n    \n    #rotation\n    Cx , Cy = rows, cols\n    rand_angle = random.randint(-45,45)\n    M = cv2.getRotationMatrix2D((Cy\/\/2, Cx\/\/2),rand_angle ,1)\n    aug_img_final = cv2.warpAffine(aug_img_final, M, (cols, rows))\n    \n    return aug_img_final\n    ","0b920788":"aug_rows, aug_cols = 3, 3\nfig, ax = plt.subplots(nrows=aug_rows, ncols=aug_cols, figsize=(50, 50))\nfor j in range(aug_rows):\n    for k in range(aug_cols) :\n        img_augf = augment_image(image)\n        ax[j][k].imshow(img_augf)\n# plt.imshow(augment_image(image))","047b5c7f":"final image\n![image.png](attachment:image.png)","97504b7f":"![image.png](attachment:image.png)","a003ee1c":"suppose image was shifted by 1 pixel in x-axis.\nand 2 pixels in y-axis. \nTx = 1 and Ty = 2\nfrom con mat\nM11 = 1 , M12= 0, M21 = 0 and M22\n\n![image.png](attachment:image.png)\n\n\nwhere blue region represents the calculations of X values\nYellow region represents the calculations of Y values\n","765242f5":"Note gold regions cropped because they exceed row or col size. (size of output image is 6*6)","83ebf444":"![image.png](attachment:image.png)","b2cdb4f1":"Flipping image \nopencv flips a 2d array by function \noutput_image = cv2.flip(input_image, flipCode)\n \nAs shown at next figure flip code when passed as a number\n\n\n**greater than 0**\nflip about y-axis in otherwords horizontal flipping\n\n**equal 0**\nflip about x-axis in other words vertical flipping\n\n**smaller than 0**\nabout x-axis and y-axis\n \n![image.png](attachment:image.png)\n\n[More details about function from opencv documentation](https:\/\/docs.opencv.org\/master\/d2\/de8\/group__core__array.html#gaca7be533e3dac7feb70fc60635adf441)","46c9e895":"Load images\n\nsource [Cat Image](https:\/\/pixabay.com\/photos\/white-cat-she-cat-beautiful-home-4557097\/)","c4155cb0":"**Blur noise**","15d102dd":"**Final procesure about flipping**\n\nRandom int number has Range [-1, 1] would be passed to cv2.flip function in order to flip image about random axis.","a353ed04":"As previous table shows.\n\n\nPoint (0, 0) at original image \n\nX axis calculations 0+0+1 = 1   (M11*X + M12*y + M13)\n\ny axis calculations 0+0+1 = 2   (M21*X + M22*y + M23)\n\nso point (0,0) at original image will be transposed to point (1, 2) at new image and so on for all points.\n","4ce16f40":"<p style=\"color:red;\">\n\n**Feel free to ask any questions or give feedback .\n** <br><br>\n\nPlease, If you found this notebook useful, vote for it.\n<br>\nI appreciate your vote.\n\n<\/p>\n","c493ae1e":"**Show examples of augmented images**","b020a370":"* Image augmentation\nIs a common technique to increase training dataset samples by artificially creating images which are artificially exposed to diffrent conditions such as rotation, flipping, noise etc\n\nAlthough there is other methods for augmenting images such as ImageDataGenerator keras with fewer lines of code , but using open-cv let us to do more customization on dataset.\nThrough this notebook each condition will be explained seperatreply, then final cell will have a function that return augmented image which are exposes to all explained conditions.\n","e6b589be":"Shifting image\n\nis done by applying transition matrix to image\n\nTransition Matrix is\n![image.png](attachment:image.png)\n\n\nwhere :\n\n      Tx is shifting value in x-axis .\n\n      Ty is shifting value in y-axis .\n      \n      From transition matrix we deduce that .\n      M 11 = 1 \n      \n      M 12 = 0\n      \n      M 21 = 0\n      \n      M 22 = 1\n      \nFunction warpAffine will be used to apply transition matrix to image by substitute in this relation between source and destination image.\n\n\n![ad](https:\/\/docs.opencv.org\/2.4\/_images\/math\/189dfa6dbab9ff81eaeaa453b1a1e2313dcd3a26.png)\n\n[More details about warpAffine from openCV documentation](https:\/\/docs.opencv.org\/2.4\/modules\/imgproc\/doc\/geometric_transformations.html#void%20warpAffine(InputArray%20src,%20OutputArray%20dst,%20InputArray%20M,%20Size%20dsize,%20int%20flags,%20int%20borderMode,%20const%20Scalar&%20borderValue)\n","fcec79e9":"Based on this relation between source image points and distination image points","becff577":"More details about how warpAffine function work.\nSuppose we have a 6 * 6 pixel photo.\nlike this\n\n![image.png](attachment:image.png)\n\nwhere Yellow region represents the number of axis\n\nOther region represents values of image\n\nGray points represents the points which we will apply our calculations \nfor example point (0, 0) which has value 10 is the first row at next table of calculations","a79fe3b5":"for better understanding, We will calculate exact values of rotation matrix then we will use cv2.getRotationMatric2D to check for our calcuations.","bae8916e":"Feel free to ask any questions or give feedback .","f039653f":"**Rotation**\nIt 's defined by applying rotation matrix to image \n![image.png](attachment:image.png)\n\n\n\n\u03b1 = (1-Cos(\u0398))*Cx - Sin(\u0398)*Cy\n\n\u03b2 = sin(\u0398)*Cx + (1-Cos(\u0398)) * Cy\n\nWhere \nCx is the center of rotation in x-axis.\n\nCy is the center of rotation in y-axis.\n\nopenCV calculate this rotation matrix by using \ncv2.getRotationMatrix2D((Cx, Cy),angle ,1) # center of rotation , angle , scale\n\n\n\n[More detatils from openCV documentation](https:\/\/docs.opencv.org\/2.4\/modules\/imgproc\/doc\/geometric_transformations.html?highlight=cv2.getrotationmatrix#cv2.getRotationMatrix2D)","f40dad66":"Final procesure \nty and ty will be a random number range from .25*axis size to -.25*axis size for example.\n","cac39bea":"**Noise**\n\nWe will add noise at each channel of hsv color space .","07feb03c":"To crop ROI (remove black region).","d1861862":"Final procesure is "}}