{"cell_type":{"55a8b5af":"code","dd42ee7e":"code","d0d16008":"code","26f4bde1":"code","2c1630cd":"code","8a1d6524":"code","82838e6e":"code","fe53d12a":"code","5def8d95":"code","9226031c":"code","3a224f38":"code","7e53046d":"code","a123b9d6":"code","d4394985":"code","8d60524b":"code","60e2dee4":"code","a3b50dc3":"code","5573a274":"code","822b7c51":"code","b3695bcc":"code","522f54fe":"code","ac78da56":"code","b5b1c12c":"code","0d8612d4":"code","60cabd13":"code","1302b1cb":"code","612d9375":"code","b515525b":"code","c9ced988":"code","862ee115":"code","6b93dfb8":"code","adea176a":"markdown","522c119f":"markdown","c36b3731":"markdown","5e7224f7":"markdown","fe369d24":"markdown","dec9e18d":"markdown","0f157498":"markdown","964887c3":"markdown","0227a6bf":"markdown","6f3629e1":"markdown","fbae828e":"markdown"},"source":{"55a8b5af":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dd42ee7e":"from skimage import io\nimport os\nimport glob\nimport random","d0d16008":"# function to plot n images using subplots\ndef plot_image(images, captions=None, cmap=None ):\n    f, axes = plt.subplots(1, len(images), sharey=True)\n    f.set_figwidth(20)\n    for ax,image in zip(axes, images):\n        ax.imshow(image, cmap)","26f4bde1":"DATASET_PATH = '\/kaggle\/input\/flowers-recognition\/flowers\/'\nflowers_cls = ['daisy', 'rose']","2c1630cd":"import os\nimport glob\n\nos.getcwd()","8a1d6524":"flower_path = os.path.join(DATASET_PATH, flowers_cls[1], '*')\nprint(flower_path)\nflower_path = glob.glob(flower_path)\nprint(flower_path[3])","82838e6e":"#Randomly looking for images\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(12,10))\nfor i in range(0,5):\n    plt.subplot(3,2,i+1)\n    rand_index=random.randint(0,len(flower_path))\n    image=io.imread(flower_path[rand_index])\n    plt.imshow(image)","fe53d12a":"import matplotlib.pyplot as plt\nplt.figure(figsize=(12,10))\nfor i in range(0,5):\n    plt.subplot(3,2,i+1)\n    rand_index=random.randint(0,len(flower_path))\n    image=io.imread(flower_path[rand_index])\n    plt.imshow(image)","5def8d95":"print(image.shape)","9226031c":"flower_path = os.path.join(DATASET_PATH, flowers_cls[1], '*')\nflower_path=glob.glob(flower_path)\n\n#Access the element or images in rose directory\nimage=io.imread(flower_path[728])\nplt.imshow(image)","3a224f38":"# plotting the original image and the RGB channels\nf, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, sharey=True)\nf.set_figwidth(15)\nax1.imshow(image)\n\n# RGB channels\nax2.imshow(image[:, : , 0])\nax3.imshow(image[:, : , 1])\nax4.imshow(image[:, : , 2])\nf.suptitle('Different Channels of Image')","7e53046d":"# from keras.preprocessing import image\nbin_image=image[:,:,0]>150\nplot_image([image,bin_image],cmap='gray')","a123b9d6":"from skimage.morphology import binary_closing,binary_dilation,binary_erosion,binary_opening\nfrom skimage.morphology import selem\n\n#generates a flat diamond shape structuring element of a given radius , here 3\nselem=selem.disk(3)\n\n#Oening and closing\nerosion_image=binary_erosion(bin_image,selem)\nplot_image([bin_image,erosion_image],cmap='gray')","d4394985":"dilation_image=binary_dilation(bin_image,selem)\nplot_image([bin_image,dilation_image],cmap='gray')","8d60524b":"open_image=binary_opening(bin_image,selem)\nplot_image([bin_image,erosion_image,open_image],cmap='gray')","60e2dee4":"close_image=binary_closing(bin_image,selem)\nplot_image([bin_image,dilation_image,close_image],cmap='gray')","a3b50dc3":"close_image=binary_closing(bin_image,selem)\nplot_image([bin_image,open_image,close_image,erosion_image,dilation_image],cmap='gray')","5573a274":"image_255=image\/255\nplt.imshow(image_255)","822b7c51":"image_norm=(image-np.min(image))\/(np.max(image)-np.min(image))\nplt.imshow(image_norm)","b3695bcc":"image_percentile=(image-np.percentile(image,50))\/(np.percentile(image,50)-np.percentile(image,5))\nplt.imshow(image_percentile)","522f54fe":"norm3_image = (image - np.percentile(image,25))\/ (np.percentile(image,75) - np.percentile(image,25))\nplt.imshow(norm3_image)","ac78da56":"from skimage import transform\n#flip left-right ,up-donw\n\nimage_flipr=np.fliplr(image)\nimage_flipud=np.flipud(image)\n\nplot_image([image,image_flipr,image_flipud])","b5b1c12c":"image.shape","0d8612d4":"#specifying x and y corrdinates to be used for shifting(mid points)\nshift_x,shift_y=image.shape[0]\/2,image.shape[1]\/2","60cabd13":"#translation by certain units\nmatrix_to_topleft=transform.SimilarityTransform(translation=[-shift_x,-shift_y])\nmatrix_to_centre=transform.SimilarityTransform(translation=[shift_x,shift_y])\n\n#rotaion\nrot_transform=transform.AffineTransform(rotation=np.deg2rad(45))\nrot_matrix=matrix_to_topleft+rot_transform+matrix_to_centre\nrot_image=transform.warp(image,rot_matrix)","1302b1cb":"plt.imshow(rot_image)","612d9375":"#Zoom Out \n\n#scaling\nplt.figure(figsize=(12,10))\nplt.subplot(2,2,1)\nscale_transform=transform.AffineTransform(scale=(2,2))\nscale_matrix=matrix_to_centre+scale_transform+matrix_to_topleft\nscale_image_zoom_out=transform.warp(image,scale_matrix)\nplt.imshow(scale_image_zoom_out)\n\n#scaling\nplt.subplot(2,2,2)\nscale_transform=transform.AffineTransform(scale=(2,2))\nscale_matrix=matrix_to_topleft+scale_transform+matrix_to_centre\nscale_image_zoom_out=transform.warp(image,scale_matrix)\nplt.imshow(scale_image_zoom_out)\n\n\n#scaling\nplt.subplot(2,2,3)\nscale_transform=transform.AffineTransform(scale=(2,2))\nscale_matrix=matrix_to_topleft+scale_transform+matrix_to_centre\nscale_image_zoom_out=transform.warp(image,scale_matrix)\nplt.imshow(scale_image_zoom_out)\n\n#scaling\nplt.subplot(2,2,4)\nscale_transform=transform.AffineTransform(scale=(2,2))\nscale_matrix=matrix_to_topleft+matrix_to_centre+scale_transform\nscale_image_zoom_out=transform.warp(image,scale_matrix)\nplt.imshow(scale_image_zoom_out)","b515525b":"#Zoom In \n\n#scaling\nplt.figure(figsize=(12,10))\nplt.subplot(2,2,1)\nscale_transform=transform.AffineTransform(scale=(0.5,0.5))\nscale_matrix=matrix_to_centre+scale_transform+matrix_to_topleft\nscale_image_zoom_out=transform.warp(image,scale_matrix)\nplt.imshow(scale_image_zoom_out)\n\n#scaling\nplt.subplot(2,2,2)\nscale_transform=transform.AffineTransform(scale=(0.5,0.5))\nscale_matrix=matrix_to_topleft+scale_transform+matrix_to_centre\nscale_image_zoom_out=transform.warp(image,scale_matrix)\nplt.imshow(scale_image_zoom_out)\n\n\n#scaling\nplt.subplot(2,2,3)\nscale_transform=transform.AffineTransform(scale=(0.5,0.5))\nscale_matrix=matrix_to_topleft+scale_transform+matrix_to_centre\nscale_image_zoom_out=transform.warp(image,scale_matrix)\nplt.imshow(scale_image_zoom_out)\n\n#scaling\nplt.subplot(2,2,4)\nscale_transform=transform.AffineTransform(scale=(0.5,0.5))\nscale_matrix=matrix_to_topleft+matrix_to_centre+scale_transform\nscale_image_zoom_out=transform.warp(image,scale_matrix)\nplt.imshow(scale_image_zoom_out)","c9ced988":"#Translation of Image\n\ntranslation_tranforms=transform.AffineTransform(translation=(25,25))\ntranslated_image=transform.warp(image,translation_tranforms)\nplt.imshow(translated_image)","862ee115":"#Shearing  of image\nplt.figure(figsize=(12,10))\nplt.subplot(2,2,1)\nshear_transforms=transform.AffineTransform(shear=np.deg2rad(45))\nshear_matrix=matrix_to_topleft+shear_transforms+matrix_to_centre\nshear_image=transform.warp(image,shear_matrix)\nplt.imshow(shear_image)\n\n#Shearing  of image\nplt.subplot(2,2,2)\nshear_transforms=transform.AffineTransform(shear=np.deg2rad(45))\nshear_matrix=shear_transforms+matrix_to_topleft+matrix_to_centre\nshear_image=transform.warp(image,shear_matrix)\nplt.imshow(shear_image)\n\n#Shearing  of image\nplt.subplot(2,2,3)\nshear_transforms=transform.AffineTransform(shear=np.deg2rad(45))\nshear_matrix=matrix_to_centre+matrix_to_topleft+shear_transforms\nshear_image=transform.warp(image,shear_matrix)\nplt.imshow(shear_image)\n\n#Shearing  of image\nplt.subplot(2,2,4)\nshear_transforms=transform.AffineTransform(shear=np.deg2rad(45))\nshear_matrix=matrix_to_centre+shear_transforms+matrix_to_topleft\nshear_image=transform.warp(image,shear_matrix)\nplt.imshow(shear_image)","6b93dfb8":"#jittering \/adding noise to image\n\nbright_jitter=image*0.999+np.zeros_like(image)*0.001\nplt.imshow(bright_jitter)","adea176a":"## Augmentation-Data Preprocessing\n### Insufficient Data\n* This we use to increase the size of images in data.\n* Also tackling Overfitting\n\n## Types of Augmentation\n* Linear Transformation\n    ** All thing basicallycan be multiply image with matrix and tranform matrix.\n        * Rotation\n        * vertical\/horizontal flipping\n* Affline Transformation\n    ** Translation followed by transformation\n    \n### Advantages\n        * As we know pooling increase the invariance. Training data set consist of data augmentation like flipping,rotation,translation,cropping,illumination,scaling,adding noise etc.the models learns all these variations.\n        * This increases the model accuracy significantly\n        ","522c119f":"2. Transform followed by linear translation(Affline)","c36b3731":"1. Linear Translation(upside-down\/left-right) ","5e7224f7":"* Erosion-shrinks bright regions and enlarge darke region\n* Dilation-shrink dark region and enlarge bright regions\n* Opening- Erosion followed by Dilation(remove bright spots 'salt' and connect small dark cracks).This tends to 'OPEN' up dark gaps between bright features.\n* CLosing-Dilation follwed by Erosion(remove dark spots 'pepper') and connecr small bright cracks.This Tends to 'CLOSE' up dark gaps between bright features.","fe369d24":"## Image Augmentation & Preprocessing\u00b6\n****","dec9e18d":"* It can be observed from the above that in closing process(dilation<-erosion),pepper gets removed and closes the dark gaps","0f157498":"* It can be observed that From the above graph , that in erosion , the white spots i.e salt has been removed and black spots has been enlarged.","964887c3":" ## NORMALISATION\n * Normalisation is crucial step in preprocessing part.[RGB\/GrayScale]\n * There are multiple technique to  normalise images:\n     * In RGB cases , divide the image by 255[maximum intensity that we can have]. Automaticalyy we will end up within range of (0,255)=image\/255\n     * This is kind of normalize one, like subtracting image wih minimum and divided by the range (max-min)","0227a6bf":"## Data Processing : Shape  Size  and Form\n## MORPHOLOGICAL TRANSFORMATION:\n    Images comes in different shape and sizes \n    Also comes through different sources\n    Natural Image:Pctures taken in color, in the real world\n    eg: A picture of flower\n    An X-Ray image is not  a natural image\n\n## Binary Image\nPixels intensities above threshold=1\nPixel intensities below threshold=0\n","6f3629e1":"* It can be observed from the above that dark spots i.e pepper has been removed and bright spots made enlarge****","fbae828e":"* It can be observed from the above that in opening process(erosion<-dilation),slats being removed and open up the dark space"}}