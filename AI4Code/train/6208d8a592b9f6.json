{"cell_type":{"1ab3cdfd":"code","8253e005":"code","db55ad11":"code","9a7ea8e0":"code","08b1e4e4":"code","2422fb06":"code","18904899":"code","861ee695":"code","63e1d42c":"code","764c7458":"code","3e28f81c":"code","55a19629":"markdown","4164ddcd":"markdown","0711cb7b":"markdown","dc33824e":"markdown","dee21685":"markdown","36d0ebf2":"markdown","0cfb6b5f":"markdown","fe72ef41":"markdown","b77486ae":"markdown"},"source":{"1ab3cdfd":"import io\nimport openpyxl\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nfrom tensorflow import keras","8253e005":"#Copying current content to new editable directory\n\n!cp -r \"..\/input\/skin-cancer-malignant-vs-benign\/train\" \"\/kaggle\/working\/\"\n!cp -r \"..\/input\/skin-cancer-malignant-vs-benign\/test\" \"\/kaggle\/working\/\"\n\n#Selecting datasets directories\n\nds_cancer_train_dir = \"\/kaggle\/working\/train\"\nds_cancer_test_dir = \"\/kaggle\/working\/test\"\n\n#Generating the datasets\n\ncancer_train_ds = tf.keras.preprocessing.image_dataset_from_directory(ds_cancer_train_dir)\ncancer_test_ds = tf.keras.preprocessing.image_dataset_from_directory(ds_cancer_test_dir)","db55ad11":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"none\"\n\n#Listing directory. You can find the class names in the class_names attribute on these datasets. These correspond to the directory names in alphabetical order.\n\n!ls \"\/kaggle\/working\/train\"\n\n#Showing index + class\n\npd.DataFrame(cancer_train_ds.class_names)","9a7ea8e0":"#Checking images and labels shapes (amount of images, height, width, color channels)\n\nfor image_batch, labels_batch in cancer_train_ds:\n  print(image_batch.shape)\n  print(labels_batch.shape)\n  break","08b1e4e4":"#Displaying some picture\u00b4s size\n\nfrom PIL import Image\nimg =  Image.open(\"\/kaggle\/working\/train\/benign\/100.jpg\")\nwidth, height = img.size\nprint(f\"Image sample with width={width} and height={height}.\")","2422fb06":"#Displaying image samples\n\nplt.figure(figsize=(10, 10))\nfor images, labels in cancer_train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(int(labels[i]))\n        plt.axis(\"off\")","18904899":"#Defining parameters for the loader\n\nbatch_size = 32\nimg_height = 64\nimg_width = 64\n\n#Filtering out corrupted images\n\nimport os\nnum_skipped = 0\nfor folder_name in (\"benign\",\"malignant\"):\n    folder_path = os.path.join(ds_cancer_train_dir, folder_name)\n    for fname in os.listdir(folder_path):\n        fpath = os.path.join(folder_path, fname)\n        try:\n            fobj = open(fpath, \"rb\")\n            is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n        finally:\n            fobj.close()\n        if not is_jfif:\n            num_skipped += 1\n            # Delete corrupted image\n            os.remove(fpath)\nprint(\"Deleted %d images\" % num_skipped)\n\n#Augmenting the images\n\nfrom keras.preprocessing.image import ImageDataGenerator\ndata_augmentation = ImageDataGenerator(rotation_range=15, rescale=1\/255, zoom_range=0.1, horizontal_flip=True,\n                                       width_shift_range=0.1, height_shift_range=0.1, validation_split=0.2)\n\n#Setting train\/test split\n\ncancer_train_ds = data_augmentation.flow_from_directory(directory=ds_cancer_train_dir, target_size=(img_height, img_width),\n                                                     class_mode=\"categorical\", batch_size=batch_size, subset=\"training\")\n\ncancer_test_ds = data_augmentation.flow_from_directory(directory=ds_cancer_test_dir, target_size=(img_height, img_width),\n                                                    class_mode=\"categorical\", batch_size=batch_size, subset=\"validation\")","861ee695":"from keras.layers import Conv2D,MaxPool2D,Dropout,Flatten,Dense\n\n#Checking if the data format i.e the RGB channel is coming first or last so, whatever it may be, model will check first and then input shape will be feeded accordingly.\n\nfrom keras import backend as K\nif K.image_data_format() == \"channels_first\":\n    input_shape = (3, img_height, img_width)\nelse:\n    input_shape = (img_height, img_width, 3)\n\n#Creating a model\n\nmodel_dl = keras.Sequential()\nmodel_dl.add(Conv2D(16,(3,3),activation=\"relu\",input_shape=(input_shape)))\nmodel_dl.add(MaxPool2D(2,2))\nmodel_dl.add(Dropout(0.2))\nmodel_dl.add(Conv2D(32,(3,3),activation=\"relu\"))\nmodel_dl.add(MaxPool2D(2,2))\nmodel_dl.add(Dropout(0.2))\nmodel_dl.add(Conv2D(64,(3,3),activation=\"relu\"))\nmodel_dl.add(MaxPool2D(2,2))\nmodel_dl.add(Dropout(0.2))\nmodel_dl.add(Flatten())\nmodel_dl.add(Dense(128,activation=\"relu\"))\nmodel_dl.add(Dropout(0.2))\nmodel_dl.add(Dense(2,activation=\"sigmoid\"))","63e1d42c":"#Compiling the neural network\n\nmodel_dl.compile(optimizer=\"Adam\", loss=\"BinaryCrossentropy\", metrics=[\"BinaryAccuracy\"])\n\n#Fitting to the model\n\nfrom keras.callbacks import EarlyStopping,ReduceLROnPlateau #Import callback functions\nearlystop=EarlyStopping(patience=10) #Monitor the performance. If it dips, then stop training\nlearning_rate_reduce=ReduceLROnPlateau(monitor=\"val_acc\",min_lr=0.001) #Change learning rate if not performing good enough\ncallbacks=[earlystop,learning_rate_reduce]\n\nmodel_dl.fit(cancer_train_ds, validation_data=cancer_test_ds, callbacks=callbacks, epochs=30)","764c7458":"#Saving the model\n\nmodel_dl.save(\"model_dl.h5\")\n\n#Loading themodel\n\nmodel_dl = keras.models.load_model(\"model_dl.h5\") #look for local saved file","3e28f81c":"#We\u00b4ll use any image sample from the Kaggle dataset to test it \n\nfrom keras.preprocessing import image\n\n#Creating a dictionary to map each of the indexes to the corresponding number or letter\n\ndict = {0:\"benign\",1:\"malignant\"}\n\n#Predicting images\n\nimg = image.load_img(\"\/kaggle\/working\/train\/benign\/1000.jpg\", target_size=(img_width, img_height))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\n\nimage = np.vstack([x])\nclasses = model_dl.predict_classes(image, batch_size=batch_size)\nprobabilities = model_dl.predict_proba(image, batch_size=batch_size)\nprobabilities_formatted = list(map(\"{:.2f}%\".format, probabilities[0]*100))\n\nprint(classes) #displaying matrix prediction position\n\nprint(f'The predicted image corresponds to \"{dict[classes.item()]}\" with {probabilities_formatted[classes.item()]} probability.') #displaying matrix prediction position name (number or letter)","55a19629":"# 9. Conclusions\n\nIF YOU LIKE IT OR IF IT HELPS YOU SOMEHOW, COULD YOU PLEASE UPVOTE? THANK YOU VERY MUCH!!!\n\nWe were able to develop a neural netork model with 83% accuracy when identifying pictures of Skin Cancer, what hopefully could be further developed to help on early detection and medical treatment, saving lifes.","4164ddcd":"# 8. Model Deployment","0711cb7b":"# 1. Introduction: Business Goal & Problem Definition\n\nIF YOU LIKE IT OR IF IT HELPS YOU SOMEHOW, COULD YOU PLEASE UPVOTE? THANK YOU VERY MUCH!!!\n\nThis project\u00b4s goal is developing a deep learning model able to identify Skin Cancer in photos, so in the future it can be automatically detected and medical treatments can start as soon as possible. I\u00b4m using a Kaggle dataset containing 3297 benign and malignant photos.","dc33824e":"# 7. Deep Learning Algorithm Implementation & Assessment","dee21685":"# 2. Importing Basic Libraries","36d0ebf2":"# 6. Data Modelling","0cfb6b5f":"# 3. Data Collection","fe72ef41":"# 5. Data Preparation","b77486ae":"# 4. Data Preliminary Exploration"}}