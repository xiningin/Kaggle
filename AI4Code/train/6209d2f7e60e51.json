{"cell_type":{"928861a5":"code","aba9ba83":"code","1c680dc3":"code","63c274e8":"code","fd8a169f":"code","ba308b6e":"code","c5fd00eb":"code","f7fc2bc8":"code","2c589be2":"code","87f36748":"code","7465299b":"code","5ccba27d":"code","c2a0068d":"code","a75e8e3c":"code","64dbf412":"code","c1cf837f":"code","9314112d":"code","0baf916b":"code","16fec9df":"code","14ff1b69":"code","b5248ee6":"code","ef0ab2c5":"code","3b6da9ff":"code","c3962c6e":"code","a590d053":"markdown","9131d383":"markdown","49032513":"markdown","0e894ba1":"markdown","7ff065fe":"markdown","01b81013":"markdown","7c441b8a":"markdown","ed0b2584":"markdown","db5d659b":"markdown","01d64778":"markdown","dff54b67":"markdown","df29024d":"markdown","5e18b689":"markdown","4dc350fc":"markdown","cc530d12":"markdown","05881cbb":"markdown","ef6ee1fa":"markdown","977c5542":"markdown","fde3c6b4":"markdown","81f64c43":"markdown","1b405440":"markdown","12bf6e3f":"markdown"},"source":{"928861a5":"# Modules\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib import rcParams\nimport seaborn as sb\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom textblob import TextBlob\n\nimport nltk\nimport re\nimport random\n\n#\nrcParams['figure.figsize'] = 20.7,8.27 \nsb.set_style(\"whitegrid\")\npd.set_option('display.max_colwidth', None)\npd.set_option('display.max_columns', None)","aba9ba83":"# read the data\ndonald_df = pd.read_csv(\"..\/input\/us-election-2020-tweets\/hashtag_donaldtrump.csv\", lineterminator='\\n')\nbiden_df = pd.read_csv(\"..\/input\/us-election-2020-tweets\/hashtag_joebiden.csv\", lineterminator='\\n')\n\n# Combine into 1 Dataframe\ndonald_df[\"hashtag\"] = \"trump\"\nbiden_df[\"hashtag\"] = \"biden\"\ndf = pd.concat([donald_df, biden_df])\n\n# overt to datetime format\ndf[\"created_at\"] = pd.to_datetime(df.created_at) ","1c680dc3":"df.head()","63c274e8":"#check for duplicates\nprint(\"Count of duplicates: {}\".format(df.duplicated(subset=[\"tweet\"]).sum()))","fd8a169f":"# Dropping all duplicates\nprint(\"Original size of df: {}\".format(len(df)))\ndf.drop_duplicates(subset=[\"tweet\"], inplace=True, keep=False)\nprint(\"No duplicates size of df : {}\".format(len(df)))","ba308b6e":"sb.catplot(x=\"hashtag\", y=\"count\", kind=\"bar\", palette=['r', 'b'],data=pd.DataFrame(df[[\"hashtag\"]].value_counts()).reset_index().rename(columns={0:\"count\"}))","c5fd00eb":"# Hashtag Timeline\ntimeline = df.resample('D', on='created_at')[\"hashtag\"].value_counts().unstack(1)\n\ntimeline.reset_index(inplace=True)\n\ntimeline = timeline.melt(\"created_at\", var_name='hashtag',  value_name='vals')\n\nsb.set_style(\"whitegrid\")\nsb.lineplot(x=\"created_at\", y=\"vals\", hue=\"hashtag\", data=timeline, palette=[\"b\", \"r\"])","f7fc2bc8":"# Top 10 countries \ndf[\"country\"] = df[\"country\"].replace({\"United States\":\"United States of America\"})\ndata = df[(df.country.isin(df.country.value_counts()[:10].index))].groupby([\"country\", \"hashtag\"]).count().sort_values(by=[\"user_id\"], ascending=False)[\"user_id\"].reset_index()\n\n\nax=sb.catplot(x=\"country\", y=\"user_id\", hue=\"hashtag\", kind=\"bar\", aspect=20.5\/8.27,palette=['r', 'b'], data=data)\nax.set_xticklabels(rotation=30)","2c589be2":"ax=sb.catplot(x=\"state\", y=\"user_id\", hue=\"hashtag\", kind=\"bar\", aspect=20.5\/8.27, palette=['r', 'b'],\n              data = df[(df.country == \"United States of America\") & (df.state.isin(df.state.value_counts()[:15].index))].groupby([\"state\", \"hashtag\"])\n                  .count()\n                  .sort_values(by=[\"user_id\"], ascending=False)[\"user_id\"]\n                  .reset_index())\nax.set_xticklabels(rotation=30)","87f36748":"fig, (ax1, ax2) = plt.subplots(2,1, figsize=(10, 16), sharex=True)\nsb.barplot(x=\"user_followers_count\", y=\"user_name\", orient=\"h\", ax=ax1, palette=[\"r\"],\n           data=df[(df.hashtag == \"trump\")]\\\n           .drop_duplicates(subset=[\"user_name\"])\\\n           .sort_values(by=[\"user_followers_count\"], ascending=False)[[\"user_name\", \"user_followers_count\"]][:10])\nax1.set_title('People with Highest Followers who tweet #trump')\n\nsb.barplot(x=\"user_followers_count\", y=\"user_name\", orient=\"h\", ax=ax2, palette=[\"b\"],\n           data=df[(df.hashtag == \"biden\")]\n           .drop_duplicates(subset=[\"user_name\"])\\\n           .sort_values(by=[\"user_followers_count\"], ascending=False)[[\"user_name\", \"user_followers_count\"]][:10])\nax2.set_title('People with Highest Followers who tweet #biden')\nfig.show()","7465299b":"ax = sb.stripplot(data=df[df.user_followers_count < df.user_followers_count.quantile(.999)].drop_duplicates(subset=[\"user_id\"]), palette=[\"r\", \"b\"],\n                  x=\"user_followers_count\",\n                  y=\"hashtag\")\nax.set_title(\"User Follower counts\")","5ccba27d":"ax = sb.stripplot(data=df[df.retweet_count < df.retweet_count.quantile(.999)].drop_duplicates(subset=[\"user_id\"]), palette=[\"r\", \"b\"],\n                  x=\"retweet_count\",\n                  y=\"hashtag\")\nax.set_title(\"Retweet counts\")","c2a0068d":"ax= sb.stripplot(data=df[df.likes < df.likes.quantile(.999)].drop_duplicates(subset=[\"user_id\"]), palette=[\"r\", \"b\"],\n                 x=\"likes\",\n                 y=\"hashtag\")\nax.set_title(\"Likes count\")","a75e8e3c":"# Helper functions\n\ndef get_hashtags(df):\n    df[\"hashtags\"] = df.tweet.apply(lambda x: \",\".join([tag.strip(\"#\") for tag in x.split() if tag.startswith(\"#\")]))\n    allhashtags = \",\".join(df[\"hashtags\"].values.tolist()).split(\",\")\n    allhashtags = [i.upper() for i in allhashtags if i != \"\"]\n    \n    return allhashtags\n\ndef generate_wordcloud(text, color_func, max_words=100, font_path=\"..\/input\/us-elections-external-data\/TypoSlab Irregular shadowed_demo.otf\"):\n    \n    wordcloud = WordCloud(width=2560, \n                          height=800,\n                          max_font_size=200, \n                          max_words=max_words, \n                          background_color=\"white\",\n                          collocations=False,\n                          color_func=color_func,\n                          font_path=font_path).generate(text)\n    \n    plt.figure(figsize=(29,9))\n    plt.imshow(wordcloud, interpolation=\"bilinear\")\n    plt.axis(\"off\")\n    plt.show()\n    \ndef random_red_color_func(word=None, *args, **kwargs):\n    h = int(11)\n    s = 100\n    l = int(float(random.randint(30, 65)))\n\n    return \"hsl({}, {}%, {}%)\".format(h, s, l)\n\ndef random_blue_color_func(word=None, *args, **kwargs):\n    h = int(245)\n    s = 100\n    l = int(float(random.randint(20, 65)))\n\n    return \"hsl({}, {}%, {}%)\".format(h, s, l)","64dbf412":"allhashtags = get_hashtags(df) #creates a list of all the hashtags (text that starts with #)","c1cf837f":"pd.Series(allhashtags).value_counts()[:30].sort_values(ascending=True).plot(kind=\"barh\")","9314112d":"stophashtags = [\"trump\", \"biden\", \"joebiden\", \"election2020\", \"donaldtrump\",\"elections2020\", \"election\", \"ellecciones\",\"elecciones\", \"republican\", \"democrat\", \"usa\"]\n\nfiltered_hashtags = [tags for tags in allhashtags if (not any([x in tags.lower() for x in stophashtags]))]\n\npd.Series(filtered_hashtags).value_counts()[:30].sort_values(ascending=True).plot(kind=\"barh\")","0baf916b":"trump_hastags = get_hashtags(df[df.hashtag == \"trump\"].copy())\n\n# Filter trump hashtags\nfiltered_trump_hashtags = [tags for tags in trump_hastags if (not any([x in tags.lower() for x in stophashtags]))]\ntext = \" \".join(filtered_trump_hashtags)\n\n#color red\ngenerate_wordcloud(text, random_red_color_func)","16fec9df":"biden_hastags = get_hashtags(df[df.hashtag == \"biden\"].copy())\n\n# Filter trump hashtags\nfiltered_biden_hastags = [tags for tags in biden_hastags if (not any([x in tags.lower() for x in stophashtags]))]\ntext = \" \".join(filtered_trump_hashtags)\n\n#color blue\ngenerate_wordcloud(text, random_blue_color_func)","14ff1b69":"stop_words = stopwords.words('english')\n\n# Text cleaning\nREPLACE_BY_SPACE_RE = re.compile('[\/(){}\\[\\]\\|@,;]')\nBAD_SYMBOLS_RE = re.compile('[#+_$]')\nSTOPWORDS = set(stopwords.words('english'))\nLINKS = r'(https?:\\\/\\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\\/\\w \\.-]*)'\n\ndef regex_strip(s):\n    s = re.sub(r'([a-z])([A-Z])', r'\\1\\. \\2', s)  # before lower case\n    s = s.lower()\n    s = re.sub(r'&gt|&lt', ' ', s)\n    s = re.sub(r'([a-z])\\1{2,}', r'\\1', s)\n    s = re.sub(r'([\\W+])\\1{1,}', r'\\1', s)\n    s = re.sub(r'\\*|\\W\\*|\\*\\W', '. ', s)\n    s = re.sub(r'\\(.*?\\)', '. ', s)\n    s = re.sub(r'product received for free[.| ]', ' ', s)\n    s = re.sub(r'(.{2,}?)\\1{1,}', r'\\1', s)\n\n    return s.strip()\n\ndef textCleaner(text):\n    text = re.sub(\"\u2018\", '', text)\n    text = re.sub(\"#\", '', text)\n    text = re.sub(LINKS, '', text, flags=re.MULTILINE) #remove links\n    text = re.sub(r'@[A-Za-z0-9_]+', '', text) # remove mentions\n    text = re.sub(REPLACE_BY_SPACE_RE, \"\", text)\n    text = re.sub(BAD_SYMBOLS_RE, \"\", text)\n    tokenized_words = text.split()\n    \n    string_list = []\n    for string in tokenized_words:\n        if string not in STOPWORDS:\n            string_list.append(regex_strip(string))\n\n    return (\" \".join(string_list))","b5248ee6":"# Run the text cleaner\ndf[\"clean_tweet\"] = df.tweet.apply(lambda x: textCleaner(x))\ndf[\"clean_tweet_length\"] = df.tweet.apply(lambda x: len(x))","ef0ab2c5":"regex = re.compile(r\"^(?=.*trump)(?=.*biden)\")\n\nmask = df.clean_tweet.apply(lambda x: False if regex.match(x) else True)\n\nfiltered_df = df[mask]\n\nfiltered_df[\"polarity\"] = [TextBlob(tweet).polarity for tweet in filtered_df.clean_tweet.values ]\nfiltered_df[\"subjectivity\"] = [TextBlob(tweet).subjectivity for tweet in filtered_df.clean_tweet.values ]","3b6da9ff":"trump_hastags = get_hashtags(filtered_df[(filtered_df.hashtag==\"trump\") & (filtered_df.polarity<-0.5)].copy())\n\n# Filter trump hashtags\nfiltered_trump_hashtags = [tags for tags in trump_hastags if (not any([x in tags.lower() for x in stophashtags]))]\ntext = \" \".join(filtered_trump_hashtags)\n\n#color red\ngenerate_wordcloud(text, random_red_color_func)","c3962c6e":"biden_hastags = get_hashtags(filtered_df[(filtered_df.hashtag==\"biden\") & (filtered_df.polarity<-0.5)].copy())\n\n# Filter biden hashtags\nfiltered_biden_hashtags = [tags for tags in biden_hastags if (not any([x in tags.lower() for x in stophashtags]))]\ntext = \" \".join(filtered_biden_hashtags)\n\n#color red\ngenerate_wordcloud(text, random_blue_color_func)","a590d053":"\nIt seems there are more tweets tagged with #Trump than #Biden. Now lets look at it over a period of time","9131d383":"Interesting to see that #MAGA is associated in both trump and biden hashtags, maybe an indicator to the success of MAGA as a catchy marketing\/campaign slogan.","49032513":"Something to note is that we still have tweets that mention both candidates in the same sentence altough one of them without the hashtag.\n\nSo this still presents a problem for something like sentiment analysis as we can't determine to whom the polarity is directed towards if both trump and biden are present in the same text. It may be good idea to later remove tweets that mention both candidates when doing sentiment analsysis or topic modeling, although the drawback is we would be dropping quite a bit of data.","0e894ba1":"It seems public reach of a celebrity endorsement contributed quite alot for #biden","7ff065fe":"Okay this looks a little bit better. \n\n### Now lets make some wordclouds","01b81013":"## Likes, Retweets and user_followers distribution\n\nNext I wanted to take a look at the density distribution for likes and user_followers who use either hashtags. \nHere I just limited the outliers by removing data that are below the .999 percentile in the dataframe","7c441b8a":"# Twitter reaction to the Season finale of the 2020 Election (End of the Trump Biden ARC)\n\nQuick Navigation\n* [1. Getting a feel for the data (Data Exploration)](#1)\n* [2. Hashtags (Word Clouds)](#2)\n* [3. Sentiment Analysis with some more Word Clouds](#3)\n* [4. Topic Modeling (In-progress)](#4)\n\nOne of my first few notebooks, comments, suggestions and criticisms are all welcome :)","ed0b2584":"## Now lets look at what a negative wordcloud of hashtags on trump looks like","db5d659b":"## So what does negative Biden hashtags look like","01d64778":"Most of these hashtags seem to be redundant and dont really offer anything new. To fix this, I have created a sample of stopwords to remove and filter out the redundant hashtags.\n\nSo lets see what are the hashtags filtered if I take out some of the redundant hashtags","dff54b67":"## Top 10 Countries ","df29024d":"<a id=\"4\"><\/a>\n# Topic Modeling for both sides (In-progress)","5e18b689":"It seems there are quite a bit of duplicates present\n\nFew thoughts on this:\n* Dropping duplicates wont help as the original tweet will be assigned to just 1 candidate, duplicates may be better off removed all together.\n* Removing duplicates may not be enough, #Trump tweets still mention biden without the hashtag. We would need to remove all tweets that mention both in the same tweet","4dc350fc":"<a id=\"2\"><\/a>\n# Hashtags associated with Trump and Biden\n\nHere I want to take a look specifically at hashtags people use when associating a tweet with trump or biden","cc530d12":"![biden%20trump%20arc.jpg](attachment:biden%20trump%20arc.jpg)","05881cbb":"First lets take a look at the top hashtags","ef6ee1fa":"## Top 10 States","977c5542":"<a id=\"3\"><\/a>\n# Diving into some sentiment\n\nSo my objective here is to try and get the most polirizing tweets and remove neutral tweets. \nBefore running sentiment analysis, I wanted to clean out all tweets that mention both trump and biden in the same text. Just so we can properly attach the polarity of a tweet to either of them","fde3c6b4":"TODO: How about top Bigrams for both hashtags","81f64c43":"## Top 10 People with Highest Followers who tweet trump or biden","1b405440":"Lets check if there are any duplicates","12bf6e3f":"<a id=\"1\"><\/a>\n# 1. Data Exploration\n"}}