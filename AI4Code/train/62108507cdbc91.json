{"cell_type":{"858f9525":"code","a13279ea":"code","06c53b59":"code","7205491d":"code","47bdcda9":"code","291aed9c":"code","3846c404":"code","d881d20d":"code","75806624":"code","c6c5d38e":"code","175794ff":"code","c339c119":"code","36e092ee":"code","fa905a78":"code","c6b3b02b":"code","303d4f82":"code","aaadb83a":"code","d38e8da2":"code","3a88b6c6":"code","1e2d3ebf":"code","d9f8bc4f":"code","a338818c":"code","acf5fd69":"code","967e7106":"markdown","43180930":"markdown","182bb0f2":"markdown","86c01bc6":"markdown","4fa76546":"markdown","eff7d889":"markdown","673018f9":"markdown","b6f12a87":"markdown","db68f03b":"markdown","07696179":"markdown","78a70422":"markdown","b8d132d7":"markdown","1451e5b5":"markdown","f66fd06e":"markdown","d67f1901":"markdown","2ecb6a2c":"markdown","b63b503f":"markdown"},"source":{"858f9525":"from __future__ import absolute_import, division, print_function, unicode_literals\nimport numpy as np\nimport pandas as pd\n# Visualisation\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns; sns.set()\nimport missingno as msno\n\nfrom sklearn.model_selection import train_test_split\n\n# Configure visualisations\n%matplotlib inline\nmpl.style.use( 'ggplot' )\nplt.style.use('fivethirtyeight')\nsns.set(context=\"notebook\", palette=\"dark\", style = 'whitegrid' , color_codes=True)\n\n\n# %tensorflow_version 2.x\n# TensorFlow and tf.keras\nimport tensorflow as tf\nfrom tensorflow.python.client import device_lib\n\n# Deep Learning Libraries\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D,AveragePooling2D\nfrom tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras import applications\nfrom tensorflow.keras.regularizers import l2\ntf.random.set_seed(42)","a13279ea":"import requests\nimport pandas as pd\nimport io\n\nBASE_URL = 'https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/'\nCONFIRMED = 'time_series_covid19_confirmed_global.csv'\nDEATH = 'time_series_covid19_deaths_global.csv'\nRECOVERED = 'time_series_covid19_recovered_global.csv'\nCONFIRMED_US = 'time_series_covid19_confirmed_US.csv'\nDEATH_US = 'time_series_covid19_deaths_US.csv'\n\ndef get_covid_data(subset = 'CONFIRMED'):\n    \"\"\"This function returns the latest available data subset of COVID-19. \n        The returned value is in pandas DataFrame type.\n    Args:\n        subset (:obj:`str`, optional): Any value out of 5 subsets of 'CONFIRMED',\n        'DEATH', 'RECOVERED', 'CONFIRMED_US' and 'DEATH_US' is a valid input. If the value\n        is not chosen or typed wrongly, CONFIRMED subet will be returned.\n    \"\"\"    \n    switcher =  {\n                'CONFIRMED'     : BASE_URL + CONFIRMED,\n                'DEATH'         : BASE_URL + DEATH,\n                'RECOVERED'     : BASE_URL + RECOVERED,\n                'CONFIRMED_US'  : BASE_URL + CONFIRMED_US,\n                'DEATH_US'      : BASE_URL + DEATH_US,\n                }\n\n    CSV_URL = switcher.get(subset, BASE_URL + CONFIRMED)\n\n    with requests.Session() as s:\n        download        = s.get(CSV_URL)\n        decoded_content = download.content.decode('utf-8')\n        data            = pd.read_csv(io.StringIO(decoded_content))\n\n    return data","06c53b59":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","7205491d":"##Online data\n# death = get_covid_data(subset = 'DEATH')\n# confirmed =  get_covid_data(subset = 'CONFIRMED')\n# recovered = get_covid_data(subset = 'RECOVERED')\n# death.to_csv(DEATH,index=False)\n# confirmed.to_csv(CONFIRMED,index=False)\n# recovered.to_csv(RECOVERED,index=False)\n\n#Local data\ndeath = pd.read_csv('\/kaggle\/input\/ece657aw20asg4coronavirus\/time_series_covid19_deaths_global.csv')\nconfirmed = pd.read_csv('\/kaggle\/input\/ece657aw20asg4coronavirus\/time_series_covid19_confirmed_global.csv')\nrecovered = pd.read_csv('\/kaggle\/input\/ece657aw20asg4coronavirus\/time_series_covid19_recovered_global.csv')","47bdcda9":"confirmed.head()","291aed9c":"\ncanada_cases = confirmed.loc[confirmed['Country\/Region']=='Canada'].iloc[:,4:].sum(axis=0)\nplot_range = range(len(canada_cases))\nplt.bar(plot_range,canada_cases,label='Canada')\nplt.legend()\nplt.title('Total Number of COVID-19 Canada')\nplt.xlabel('Day')\nplt.ylabel('Number of Cases')\nplt.show()","3846c404":"#Daily cases Canada\ndaily_canada = canada_cases.diff()\ndaily_canada = daily_canada.fillna(canada_cases[0])\nplot_range = range(len(daily_canada))\nplt.bar(plot_range,daily_canada,label='Canada')\nplt.legend()\nplt.title('Daily Number of COVID-19 Canada')\nplt.show()\n# print(daily_canada)","d881d20d":"confirmed = confirmed.drop(columns=['Province\/State','Lat','Long'])\ndeath = death.drop(columns=['Province\/State','Lat','Long'])\nrecovered = recovered.drop(columns=['Province\/State','Lat','Long'])","75806624":"world_cases = confirmed.iloc[:,1:].sum(axis=0)\nworld_death = death.iloc[:,1:].sum(axis=0)\nworld_recovered = recovered.iloc[:,1:].sum(axis=0)","c6c5d38e":"daily_world_cases = world_cases.diff()\ndaily_world_cases = daily_world_cases.fillna(world_cases[0])\n\ndaily_world_death = world_death.diff()\ndaily_world_death = daily_world_death.fillna(world_death[0])\n\ndaily_world_recovered = world_recovered.diff()\ndaily_world_recovered = daily_world_recovered.fillna(world_recovered[0])\n","175794ff":"\nplot_range = range(len(world_cases))\nplt.plot(plot_range,world_cases,color='black',label='Confirmed')\nplt.bar(plot_range,world_cases,color='black')\nplt.plot(plot_range,world_death,color='red',label='Death')\nplt.bar(plot_range,world_death,color='red')\nplt.plot(plot_range,world_recovered,color='green',label='Recovered')\nplt.bar(plot_range,world_recovered,color='green')\nplt.legend()\nplt.xlabel('Time', size=10)\nplt.ylabel('# Cases', size=10)\nplt.xticks(size=10)\nplt.title('Total cases - Word')\nplt.show()\n\n\nplot_range = range(len(daily_world_cases))\nplt.plot(plot_range,daily_world_cases,color='black',label='Confirmed')\nplt.bar(plot_range,daily_world_cases,color='black')\nplt.plot(plot_range,daily_world_death,color='red',label='Death')\nplt.bar(plot_range,daily_world_death,color='red')\nplt.plot(plot_range,daily_world_recovered,color='green',label='Recovered')\nplt.bar(plot_range,daily_world_recovered,color='green')\nplt.legend()\nplt.xlabel('Time', size=10)\nplt.ylabel('# Cases', size=10)\nplt.xticks(size=10)\nplt.title('Daily new cases - Word')\nplt.show()\n","c339c119":"print(daily_world_cases.isnull().any())\nprint(daily_world_cases.isna().any())\nprint(daily_world_death.isnull().any())\nprint(daily_world_death.isna().any())\nprint(daily_world_recovered.isnull().any())\nprint(daily_world_recovered.isna().any())","36e092ee":"data = pd.DataFrame([])\n# data['Date'] = world_cases.index.tolist()\ndata['world_confirmed'] = world_cases.values\ndata['daily_world_confirmed'] = daily_world_cases.values\ndata['world_death'] = world_death.values\ndata['daily_world_death'] = daily_world_death.values\ndata['world_recovered'] = world_recovered.values\ndata['daily_world_recovered'] = daily_world_recovered.values\nprint(\"Yesterday\")\ndata.tail(1)\n","fa905a78":"features_list = ['world_death','world_recovered','world_confirmed']\nfeatures = data[features_list]\nlabels = data['world_confirmed']\n\n","c6b3b02b":"def create_data(dataset, target, start_index, end_index, history_size):\n  data = []\n  labels = []\n\n  start_index = start_index + history_size\n  if end_index is None:\n    end_index = len(dataset)\n\n  for i in range(start_index, end_index):\n    indices = range(i-history_size, i)\n    data.append(dataset[indices])\n    labels.append(target[i])\n\n\n  return np.array(data), np.array(labels)","303d4f82":"from sklearn.preprocessing import MinMaxScaler\nscaler_features = MinMaxScaler(feature_range=(0, 1))\nscaler_labels = MinMaxScaler(feature_range=(0, 1))\n\nfuture = 14 #Number of predictions to the future (days)\n\n#How much data for training\nTRAIN_SPLIT = len(data) - future -1 #How much data for training\nprint(TRAIN_SPLIT)\n\n#Data scaling\ndataset = features.values\nscaler_features.fit(dataset[:TRAIN_SPLIT])\nscaler_labels.fit(dataset[:TRAIN_SPLIT,2].reshape(-1,1))\ndataset = scaler_features.transform(dataset)\nprint(dataset.shape)\n# print(dataset)","aaadb83a":"past_history = 5\n\nx_train, y_train = create_data(dataset, dataset[:, 2], 0,\n                              TRAIN_SPLIT, past_history)\nx_val, y_val = create_data(dataset, dataset[:, 2],\n                            TRAIN_SPLIT, None, past_history)\n\nprint(y_train.shape)\nprint(x_train.shape)\nprint(y_val.shape)\nprint(x_val.shape)","d38e8da2":"print ('Single window of past history')\nprint (x_train[1])\nprint ('\\n Target value to predict: ')\nprint (y_train[1])","3a88b6c6":"lstm_model = tf.keras.models.Sequential([\n    tf.keras.layers.LSTM(50, input_shape=x_train.shape[-2:],activation='relu'),\n    tf.keras.layers.Dense(1)\n])\n# reduce_lr = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)\noptimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999 )\nlstm_model.compile(optimizer='adam', loss='mae')\n\n","1e2d3ebf":"history = lstm_model.fit(x_train,y_train, batch_size =8,epochs = 100, validation_data=(x_val,y_val), verbose=2)","d9f8bc4f":"for sample in range(4):\n  print('Predict')\n  predict = lstm_model.predict(x_val)\n  # print(predict[sample])\n  print(scaler_labels.inverse_transform(predict[sample].reshape(1,-1)))\n  print(\"Actual\")\n  # print(y_val[sample])\n  print(scaler_labels.inverse_transform(y_val[sample].reshape(1,-1)))\n  # show_plot([x_val_single[sample,2], y_val_single[sample],predict[sample]], 0, 'Sample Example')\n  # plt.show()","a338818c":"predict_confirmed = np.copy(dataset)\nfuture = 14\nfor i in range(future):\n#     print(TRAIN_SPLIT+i+1)\n    sample = predict_confirmed[TRAIN_SPLIT-past_history+i:TRAIN_SPLIT+i]\n    # print(sample.shape)\n    sample = sample.reshape((1,sample.shape[0],sample.shape[1]))\n    predict = lstm_model.predict(sample)\n#     print(\"Predict: \", predict)\n#     print(\"Actual: \", dataset[TRAIN_SPLIT+i+1,2])\n    try:\n        predict_confirmed[TRAIN_SPLIT+i+1,2] = predict\n    except:\n        print()\n    \n# i = 0\n# sample = dataset[TRAIN_SPLIT-5+i:TRAIN_SPLIT+i]\n# print(sample)\n# sample = sample.reshape((1,5,3))\n# predict = simple_lstm_model.predict(sample)\n# print(\"Predict: \", predict)\n# print(dataset[TRAIN_SPLIT+i])\n# print(\"Actual: \",dataset[TRAIN_SPLIT+i,2])\n# dataset_new[TRAIN_SPLIT+i+1,2] = predict\n# print(dataset_new[TRAIN_SPLIT+i+1,2])\n# print(dataset_new[TRAIN_SPLIT-5+i+1:TRAIN_SPLIT+i+1])\n# plt.plot(dataset_new[:,2])\n# plt.plot(dataset[:,2])","acf5fd69":"# dataset_scale = scaler_features.inverse_transform(dataset)\npredict_confirmed_scale = scaler_features.inverse_transform(predict_confirmed)\n\nplt.figure(figsize=(10,8))\nplt.plot(features[\"world_confirmed\"],label=\"Actual\",color='g')\nplt.plot(predict_confirmed_scale[:,2],label=\"Prediction\",marker=\"o\")\nplt.xlabel(\"Day n-th since 1\/22\/2020\", size = 20)\nplt.ylabel(\"Number of cases\", size = 20)\nplt.title(\"World - number of confirmed cases\", size = '20')\nplt.legend()\nplt.show()\n\npredict_daily = pd.DataFrame(predict_confirmed_scale[:,2]).diff()\npredict_daily.fillna(0)\n# print(predict_daily.shape)\n# print(data['daily_world_confirmed'].shape)\nplt.figure(figsize=(10,8))\nplt.plot(data['daily_world_confirmed'],label=\"Actual\",color='g')\nplt.plot(predict_daily,label=\"Prediction\",marker=\"o\")\nplt.xlabel(\"Day n-th since 1\/22\/2020\", size = 20)\nplt.ylabel(\"Number of cases\", size = 20)\nplt.title(\"World - number of confirmed cases\", size = '20')\nplt.legend()\nplt.show()","967e7106":"**Check if any missing data and null values**","43180930":"**Plotting number of confimed cases and number of daily cases of Canada**","182bb0f2":"# Introduction\n\nWe would like to predict the world number of confirmed cases using a LSTM networks. The future prediction will base on three past data: number of confirmed cases, number of death cases and number of recovered cases. ","86c01bc6":"**Testing**\n\nTesting with some samples from the validation data.","4fa76546":"This is how the data is used to make prediction. The data of past 5 days is used to predict the next day world confirmed cases.","eff7d889":"The prediction will work better with the latest data and Google colab.","673018f9":"**Prediction**\n\nTo predict 14 days in the future, we will predict a next day and include append the prediction into the data to predict the day after the next day. We repeat the procedure 14 times until we get 14 days of predictions.","b6f12a87":"**Training**\n\nWe train on 100 epochs and batch size is 8.","db68f03b":"**Loading Libaries**","07696179":"We use history from past 5 days to predict the next day.","78a70422":"I couldn't get the internet in Kaggle to work so I had to use the local dataset from kaggle. If you have internet kaggle, please uncomment the online data scripts to load the last test data.","b8d132d7":"**Time series data** \n\nWe need a function to convert the data to time series data","1451e5b5":"**Model**\n\n1 LTSM layer with 50 nodes, and activation is ReLu\n\n1 Dense layer with 1 nodes for the final predictions.\n\nOptimizer is Adam with learning rate = 0.001, beta1 = 0.9 and beta2 = 0.999.\n\nThe loss function is Mean Absolute Error","f66fd06e":"**Data preparation**","d67f1901":"**Data scaling**\n\nWe scale the data to the range [0,1] (at least for the past data, the future data can be greater than 1 because we are not sure the how large the data in the future can be). The data in rage [0,1] will benefit the training of LSTM network.","2ecb6a2c":"**Organising data to a panda frame**","b63b503f":"**We use 3 features** : *'world_death','world_recovered','world_confirmed'* to predict the world confirmed cases for the next day"}}