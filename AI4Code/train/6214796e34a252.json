{"cell_type":{"8648065e":"code","de4b2348":"code","e2900bf3":"code","85a75d7c":"code","99dfa9f8":"code","1df1147a":"code","bd9e995b":"code","bdd47fee":"code","3f5bca67":"code","131dc729":"code","cb529f59":"code","0577377e":"code","49e1f1dc":"code","9da6760f":"code","3c078170":"code","f3eac6c1":"code","4aa749ba":"code","48a30f91":"code","40dd60b9":"code","605923a7":"code","73f2bc76":"code","e17e7796":"code","a7599b45":"code","66832980":"code","39f114b5":"code","2f9fd483":"code","62c854e8":"code","dfd1bb3e":"code","cb1ce7a3":"code","58b3ba5e":"code","48f64d6d":"code","edce9ad0":"code","7206c80b":"code","a23484c6":"code","16bb8e1a":"code","9a7466a9":"code","6da9bf8d":"code","5f48bb16":"code","b5247481":"code","2e2d7f50":"markdown","aebe863c":"markdown","3c391b1a":"markdown","293911ad":"markdown","63a4a04c":"markdown","9e6a8b1f":"markdown","83354465":"markdown","e16af795":"markdown","048bded7":"markdown","447a4160":"markdown","04339181":"markdown","785c3942":"markdown","9e753724":"markdown","fa463f0a":"markdown","df1924c1":"markdown","36c5b4d1":"markdown","eeeee3ac":"markdown","74f32eed":"markdown","83e11fee":"markdown","73fcd8af":"markdown","04ecb09c":"markdown","543f8d9f":"markdown","ec01045b":"markdown","07494399":"markdown","5da7d7c6":"markdown","9522a931":"markdown","d919b770":"markdown","90a8ebfc":"markdown","fac62392":"markdown","52b732cc":"markdown","df5a8e0c":"markdown","bd5c65e8":"markdown","08080406":"markdown","83844372":"markdown","86964ec7":"markdown","5cd77b24":"markdown","86a7ce74":"markdown","b2583d07":"markdown","46dbd73b":"markdown","e8f7f5b3":"markdown","a2239dfe":"markdown","113801d6":"markdown","876f58cf":"markdown","6f5bd226":"markdown","649523f4":"markdown","a537f611":"markdown","450bbf9c":"markdown","4bb4e9fc":"markdown","c6ea7609":"markdown","146d6e8d":"markdown","de319659":"markdown","4041e4c5":"markdown","ba2b8d3e":"markdown","841362a3":"markdown","4861f15d":"markdown","67a48b41":"markdown","7ce462bc":"markdown","f1b70b01":"markdown","a18c4e2c":"markdown","2fe9c5db":"markdown"},"source":{"8648065e":"# Basic packages\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport random as rd # generating random numbers\nimport datetime # manipulating date formats\n# Viz\nimport matplotlib.pyplot as plt # basic plotting\nimport seaborn as sns # for prettier plots","de4b2348":"# time-series prediction packages\nfrom statsmodels.tsa.statespace import sarimax as smt # sarimax algorithm for actual predictions\nfrom statsmodels.graphics.tsaplots import plot_pacf # partial auto-correlation plotting tool for stationarity test\nfrom statsmodels.graphics.tsaplots import plot_acf # auto-correlation plotting tool for stationarity test\nfrom statsmodels.tsa.arima_process import ArmaProcess # arma process for simulation ","e2900bf3":"sales = pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/sales_train.csv\")\n\nimport warnings\n\n# settings\nwarnings.filterwarnings('ignore')\n\n\nitem_cat = pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/item_categories.csv\")\nitems = pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/items.csv\")\nsub = pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv\")\nshop = pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/shops.csv\")\ntest = pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/test.csv\")","85a75d7c":"ar1 = np.array([1, 0.33])\nma1 = np.array([1, 0.9])\nsimulated_ARMA_data = ArmaProcess(ar1, ma1).generate_sample(nsample=10000)","99dfa9f8":"plt.figure(figsize=[15, 7.5]); # Set dimensions for figure\nplt.plot(simulated_ARMA_data)\nplt.title(\"Simulated ARMA(1,1) Process\")\nplt.xlim([0, 200])\nplt.show()","1df1147a":"plot_pacf(simulated_ARMA_data);\nplot_acf(simulated_ARMA_data);","bd9e995b":"! pip install yfinance","bdd47fee":"import yfinance as yf\n\nmsft = yf.Ticker(\"MSFT\")\n\n# get historical market data\nhist = msft.history(period=\"5y\")","3f5bca67":"df_settle = hist['Close'].resample('MS').ffill().dropna()","131dc729":"df_settle.tail()","cb529f59":"from statsmodels.tsa.stattools import adfuller\n\nresult = adfuller(df_settle)\nprint('ADF result', result[0])\nprint('p-value = ', result[1])\n\ncritical_values = result[4]\n\nfor key, value, in critical_values.items():\n  print(\"critical values (%s): %.3f\" % (key, value))","0577377e":"import itertools\nimport warnings\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\n# from statsmodels.api.tsa.statespace import SARIMAX\n\nwarnings.filterwarnings(\"ignore\")\n\ndef arima_grid_search(dataframe, s):\n  p = d = q = range(2)\n  param_combinations = list(itertools.product(p, d, q))\n\n  lowest_aic, pdq, pdqs = None, None, None\n\n  total_iterations = 0\n  for order in param_combinations:\n    for (p, d, q) in param_combinations:\n      seasonal_order = (p, d, q, s)\n      total_iterations +=1\n      try:\n        model = SARIMAX(df_settle, order=order,\n                        seasonal_order = seasonal_order,\n                        enforce_stationarity=False,\n                        enforce_invertibility=False,\n                        disp=False\n                      )\n        model_result = model.fit(maxiter=200, disp=False)\n\n        if not lowest_aic or model_result.aic < lowest_aic:\n          lowest_aic = model_result.aic\n          pdq, pdqs = order, seasonal_order\n\n      except Exception as ex:\n        continue\n\n  return lowest_aic, pdq, pdqs","49e1f1dc":"lowest_aic, order, seasonal_order = arima_grid_search(df_settle, 12)","9da6760f":"print('ARIMA{}x{}'.format(order, seasonal_order))\nprint('Lowest AIC: %.3f' % (lowest_aic))","3c078170":"model = SARIMAX(\n    df_settle, \n    order=order,\n    seasonal_order = seasonal_order,\n    enforce_stationarity=False,\n    enforce_invertibility=False,\n    disp=False\n)\n\nmodel_results = model.fit(maxiter=200, disp=False)","f3eac6c1":"print(model_results.summary())","4aa749ba":"model_results.plot_diagnostics(figsize=(12,8));","48a30f91":"model_results.resid.describe()","40dd60b9":"n = len(df_settle.index)\nprediction = model_results.get_prediction(\n    start=n-14*5, #changed from 12\n    end=n+5\n)\n\nprediction_ci = prediction.conf_int()","605923a7":"prediction_ci.head(3)","73f2bc76":"plt.figure(figsize=(12,8))\nax = df_settle['2008':].plot(label='actual')\nprediction_ci.plot(\n    ax=ax, style=['--', '--'],\n    label='predicted\/forecasted')\n\nci_index = prediction_ci.index\nlower_ci = prediction_ci.iloc[:, 0]\nupper_ci = prediction_ci.iloc[:, 1]\n\nax.fill_between(ci_index, lower_ci, upper_ci,\n                color='r', alpha= .1)\n\nax.set_xlabel('Time (years)')\nax.set_ylabel('Prices')\n\nplt.legend()\nplt.show()","e17e7796":"#formating dates as a date object\nsales.date = sales.date.apply(lambda x: datetime.datetime.strptime(x, \"%d.%m.%Y\"))\n# check\nprint(sales.info())","a7599b45":"sales_monthly = sales.groupby(\n    [\"date_block_num\", \"shop_id\", \"item_id\"])[\"date\",\"item_price\",\n                                              \"item_cnt_day\"].agg({\n        \"date\":[\"min\",\"max\"],\n        \"item_price\":\"mean\",\n        \"item_cnt_day\":\"sum\"})","66832980":"sales_monthly.head(20)","39f114b5":"# number of items per cat \nitems.head()\nx = items.groupby(['item_category_id']).count() # but count is in column item_id ?\nx = x.sort_values(by='item_id',ascending=False)\nx=x.iloc[0:10].reset_index()\nx\n# plot\nplt.figure(figsize=(8,4))\nax=sns.barplot(x.item_category_id, x.item_id, alpha=0.8)\nplt.title(\"Items per Category\")\nplt.ylabel(\"# of items\", fontsize=12)\nplt.xlabel(\"Category\", fontsize=12)\nplt.show()\n","2f9fd483":"ts = sales.groupby(['date_block_num'])['item_cnt_day'].sum()\n# ts = sales.groupby(['date_block_num','shop_id'])['item_cnt_day'].sum()","62c854e8":"out = sales.pivot_table(index='shop_id', \n                        columns='date_block_num',\n                        values='item_cnt_day',\n                        aggfunc='sum')\nout = out.fillna(out.mean())\nout.head()","dfd1bb3e":"plt.figure(figsize=(16,8))\nplt.plot(ts)\nplt.title(\"Total sales of the company\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"# sales\")\nplt.show()","cb1ce7a3":"plt.figure(figsize=(16,8))\nfor i,row in out.iterrows():\n  plt.scatter(out.columns, row)\nplt.title(\"Total sales of the company\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"# sales\")\nplt.show()","58b3ba5e":"plt.figure(figsize=(16,6))\nplt.plot(ts.rolling(window=12,center=False).mean(), label = \"rolling mean\")\nplt.plot(ts.rolling(window=12, center=False).std(), label = \"rolling std\")\nplt.legend()\nplt.show()","48f64d6d":"import statsmodels.api as sm\nres = sm.tsa.seasonal_decompose(ts.values, freq=12, model=\"multiplicative\")\nfig=res.plot()","edce9ad0":"import statsmodels.api as sm\nres = sm.tsa.seasonal_decompose(ts.values, freq=12, model=\"addidtive\")\nfig=res.plot()","7206c80b":"import statsmodels.api as smt\nimport statsmodels\nimport scipy.stats as scs\nfrom pandas import Series\n\nts = sales.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\n\ndef difference(dataset, interval=1):\n  diff = list()\n  for i in range(interval, len(dataset)):\n    value = dataset[i] - dataset[i - interval]\n    diff.append(value)\n  return Series(diff)\n\nnew_ts = difference(ts, 12)\n\n\ndef tsplot(y, lags=None, figsize=(10, 8), style='bmh',title=''):\n    if not isinstance(y, pd.Series):\n        y = pd.Series(y)\n    with plt.style.context(style):    \n        fig = plt.figure(figsize=figsize)\n        #mpl.rcParams['font.family'] = 'Ubuntu Mono'\n        layout = (3, 2)\n        ts_ax = plt.subplot2grid(layout, (0, 0), colspan=2)\n        acf_ax = plt.subplot2grid(layout, (1, 0))\n        pacf_ax = plt.subplot2grid(layout, (1, 1))\n        qq_ax = plt.subplot2grid(layout, (2, 0))\n        pp_ax = plt.subplot2grid(layout, (2, 1))\n        \n        y.plot(ax=ts_ax)\n        ts_ax.set_title(title)\n        statsmodels.graphics.tsaplots.plot_acf(y, lags=lags, ax=acf_ax, alpha=0.5)\n        statsmodels.graphics.tsaplots.plot_pacf(y, lags=lags, ax=pacf_ax, alpha=0.5)\n        smt.qqplot(y, line='s', ax=qq_ax)\n        qq_ax.set_title('QQ Plot')        \n        scs.probplot(y, sparams=(y.mean(), y.std()), plot=pp_ax)\n\n        plt.tight_layout()\n    return \n\nmax_lag = 12\n_ = tsplot(ts.values, lags=max_lag,title=\"My De-trend and De-seasonalized values process\");","a23484c6":"sales_monthly = sales.groupby(\n    [\"date_block_num\", \"shop_id\", \"item_id\"])[\"date\", \"item_price\",\n                                              \"item_cnt_day\"].agg({\n    \"date\": [\"min\", \"max\"],\n    \"item_price\": \"mean\",\n    \"item_cnt_day\": \"sum\"})","16bb8e1a":"sales_monthly.head()","9a7466a9":"import more_itertools as mit\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\n\n\narray = []\n\nfor i, row in test.iterrows():\n   \n    try:\n        # We get all the dates\/indexes in order to fill the blanks of the time series with 0s later on \n        # We have a KeyError issue at row['shop_id']:  5  row['item_id']:  5003 which I don't have in my local notebook\n        existing_indexes = [x[0] \n                            for x in sales_monthly.loc[pd.IndexSlice[:, \n                            [row['shop_id']], [row['item_id']]], :].index]\n        # We multiply the price of the item by the number of this kind of item sold\n        ts = pd.DataFrame(sales_monthly.loc[pd.IndexSlice[:, # We have a key error here\n                      [row['shop_id']], [row['item_id']]], :]['item_price'].values *\n                      sales_monthly.loc[pd.IndexSlice[:, \n                      [row['shop_id']], [row['item_id']]], :]['item_cnt_day'].values).T.iloc[0]\n        ts_values = list(ts.values)\n        if ts.values != [] and len(ts.values) > 4:\n          # if this item isn't sold every month, we need to fill the gaps in the \n          # sellings list\n          if len(ts.values<3):\n            all_indexes = list(range(33))\n            insert_at_indexes = set(all_indexes) - set(existing_indexes)\n            insert_at_indexes = [list(group) \n                        for group in mit.consecutive_groups(insert_at_indexes)][1:]\n            insert_at_indexes = [item for sublist in insert_at_indexes for item in sublist]\n            # we only take the last one \n            for insert_at in insert_at_indexes:\n              ts_values[insert_at:insert_at] = [0.]\n          best_aic = np.inf\n          best_order = None\n          best_model = None\n\n          # we need to test different orders, but let's have a go with that ...\n          ranges = range(1, 5)\n          for difference in ranges:\n              tmp_model = SARIMAX(ts_values, order=(0, 1, 0), trend='t').fit()\n              tmp_aic = tmp_model.aic\n              if tmp_aic < best_aic:\n                  best_aic = tmp_aic\n                  best_difference = difference\n                  best_model = tmp_model\n          if best_model is not None:\n              y_hat = best_model.forecast()[0]\n              if y_hat < 0:\n                  y_hat = 0.5\n          else:\n              y_hat = 0.5\n        else:\n            y_hat = 0.5\n    except KeyError:\n        y_hat = 0.5\n    d = {'id': row['ID'], 'item_cnt_month': y_hat}\n    array.append(d)\n\ndf = pd.DataFrame(array)\ndf.reset_index(drop=True, inplace=True)","6da9bf8d":"df.head()","5f48bb16":"df.to_csv(\"submission.csv\")","b5247481":" df.to_csv(\"submission.csv\", index=False)","2e2d7f50":"This criterion is useful for selecting the order (p,d,q) of an ARIMA model. The AIC is expressed as:\n\n$$AIC = -2\\log(L) + 2k$$","aebe863c":"And our score is ... 3556.23468 whereas the sample submission was 1.23646.","3c391b1a":"I didn't knew how to model time series so I started by learning about that. It seems that one of the very common model for that are Auto-Regressive Moving Average processes. You must know what are random walk, moving average process (MA) and autoregressive models (AR) before tackling this notebook where we mix everything up with ARMA model. \n\nThere are notebooks about that there:\n\n- [Understanding the random walk and the moving average](https:\/\/towardsdatascience.com\/how-to-model-time-series-in-python-9983ebbf82cf)\n- [A hands-on tutorial on AR(p) process for time series analysis in Python](https:\/\/towardsdatascience.com\/time-series-forecasting-with-autoregressive-processes-ba629717401)\n- [Understand and implement ARMA and ARIMA models for time series forcasting Python](https:\/\/towardsdatascience.com\/advanced-time-series-analysis-with-arma-and-arima-a7d9b589ed6d)","293911ad":"The first (and most important) step in fitting an ARIMA model is the determination of the order of differencing needed to stationarize the series.","63a4a04c":"## 1. Competition Outline","9e6a8b1f":"Now, we can print a summary of the best model, which an ARIMA (1,1,0).","83354465":"We just need to find the model minimizing the AIC","e16af795":">  *Time series forecasting is the use of a model to predict future values based on previously observed values.* ","048bded7":"<img src=\"https:\/\/img.freepik.com\/free-vector\/financial-forecast-illustration-flat-tiny-economical-persons-concept_126608-1324.jpg?size=626&ext=jpg&ga=GA1.2.1775781678.1609891200\"><\/img>","447a4160":"There is clearly a seasonality and a trend.\n\nLet's check that with a quick decomposition into Trend, seasonality and residuals.\n\n","04339181":"We now find these couples iterating through `test` and creating the related SARIMAX model if we have enough data (at least 33 month of sales)","785c3942":"Ok, now that we are wise, let's do a little example on how to predict a financial stock with ARMA before we dive into our competition","9e753724":"# Conclusion","fa463f0a":"First let's compute the total sales per month and plot that data.\n\n","df1924c1":"The sales by category seem to be unbalanced.","36c5b4d1":"## 2. Data ","eeeee3ac":"It is important to note that the AIC cannot be used to select the order of differencing (d). Differencing the data will the change the likelihood (L) of the data. The AIC of models with different orders of differencing are therefore not comparable.\n\nAlso, notice that since we select the model with the lowest AIC, more parameters will increase the AIC score and thus penalize the model. While a model with more parameters could perform better, the AIC is used to find the model with the least number of parameters that will still give good results.\nA final note on AIC is that it can only be used relative to other models. A small AIC value is not a guarantee that the model will have a good performance on unsee data, or that its SSE will be small.","74f32eed":"The order of differencing (d) process is 1. But it's not related to the AIC, it has been found by the grid search model itself.","83e11fee":"All right, so what data are we provided for which we need to predict the future values?","73fcd8af":"Where L is the likelihood of the data and k is the number of parameters.\nIn practice, we select the model with the lowest AIC compared to other models.","04ecb09c":"## 4. Exploratory Data Analysis","543f8d9f":"First, let's visit the dataset `sales_train.csv` that we talked about previously.","ec01045b":"This is my second challenge on Kaggle, but my first for almost five years! When I joined, I had (still have) some very big issues in understanding not only the rules of submission, but also the data and ... what everything mean?\n\nSo, as I go along I will try to bring some clear understanding and also point to some fruitful discussions. Ok, here we go!","07494399":"Therefore, this suggests are ARIMA model with an AR(1) process and a MA(0).","5da7d7c6":"We could try to find the model parameters by detrending with a log-difference `np.log(df_settle)` and differenciating `df_settle.diff(seasonality)` and then run the Augmented Dickey-Fuller test again to see if we have a stationary time series.","9522a931":"Therefore, how can we make sure that we choose the right order for both the AR(p) and MA(q) processes?\n\nWe will need try different combinations of orders, fit an ARIMA model with those orders, and use a criterion for order selection.\n\nThis brings us to the topic of Akaike\u2019s Information Criterion or AIC.","d919b770":"## fitting the SARIMAX model","90a8ebfc":"In this competition we work with time-series dataset consisting of daily sales data, kindly provided by one of the largest Russian software firms - 1C Company. \n\nWe are asked to predict total sales for every product and store in the next month.\n\nBut what is time series prediction?","fac62392":"Normally, the correct amount of differencing is the lowest order of differencing that yields a time series which fluctuates around a well-defined mean value and whose autocorrelation function (ACF) plot decays fairly rapidly to zero, either from above or below. If the series still exhibits a long-term trend, or otherwise lacks a tendency to return to its mean value, or if its autocorrelations are are positive out to a high number of lags (e.g., 10 or more), then it needs a higher order of differencing","52b732cc":"### ARMA\n\nan ARMA(p,q) is simply the combination of both Moving Average process and Auto Regressive process into a single equation. $y_t$ value is equal to:\n\n$$y_t = \\overbrace{c + \\theta_1 \\epsilon_{t-1} + \\theta_{t-2} + ... + \\theta_q \\epsilon_{t-q}}^{Moving-Average(q)} + \\\\ \\underbrace{\\phi_1 y_{t-1} + \\phi_2 y_{t-2} + ... + \\phi_q y_{t-p}}_{Auto-regression(p)}$$","df5a8e0c":"We probably need to\n- get the right orders.\n- do further data cleaning:\n- Maybe the (shop,item) couples which don't generate any revenues anymore are not detected despite.\n- Maybe ARIMA isn't a good model for this case and we should rather use a RNN model?","bd5c65e8":"Therefore grid searching (p, d, q, s), allows to feed the data as it is without any transformation since SARIMAX will do the transformation for you under the hood.","08080406":"## Predicting the model","83844372":"Each `\"shop_id\", \"item_id\"` is a time series for which we will find and create a SARIMAX model.","86964ec7":"<h1>\ud83d\udcb0Predict Future Sales Competiton\ud83d\udcb0: time series prediction with ARIMA<\/h1>","5cd77b24":"# ARMA","86a7ce74":"Allright ! We are all done, let's have a look at what we predicted.","b2583d07":"Here would be a simulated ARMA model:","46dbd73b":"So let's take a look at the ACF and PACF plots:","e8f7f5b3":"## 3. Example: time series forecasting with ARMA","a2239dfe":"Although these plots can give us a rough idea of the processes in play, it is better to test multiple scenarios and choose the model that yield the lowest AIC.","113801d6":"As we are calculating the root mean square error, the the differences between values (sample or population values) predicted by a model or an estimator and the values observed, this is not very good. ","876f58cf":"We are now going to buil our model to predict the future sales for the company.","6f5bd226":"- `sales_train.csv` - the training set. Daily historical data from January 2013 to October 2015. It has 1034 unique values `item_id` that were sold at a given `shop_id` at `date_block_num` time.\n- test.csv - the test set. You need to forecast the sales for these shops and products for November 2015. 214k `item_id` sales to predict at `shop_id` for next `date_block_num` time.\n- `sample_submission.csv` - a sample submission file in the correct format.\n- items.csv - supplemental information about the items\/products. 22170\nunique values, with the categories.\n- item_categories.csv  - supplemental information about the items categories. 84\nunique values.\n- shops.csv- supplemental information about the shops. The name and sometimes the categories: TPK|\u0422\u0426|\u0422\u041a|\u0422\u0420\u0426|\u041c\u0422\u0420\u0426|\u0422\u0426","649523f4":"Here, the p-value is larger than 0.05, meaning the we cannot reject the null hypothesis stating that the time series is non-stationary.\nTherefore, we must apply some transformation and some differencing to remove the trend and remove the change in variance.","a537f611":"Differencing is a method of transforming a time series dataset. It can be used to remove the series dependence on time, so-called temporal dependence.","450bbf9c":"From the normal Q-Q plot, we can see that we almost have a straight line, which suggest no systematic departure from normality. Also, the correlogram on the bottom right suggests that there is no autocorrelation in the residuals, and so they are effectively white noise.","4bb4e9fc":"Now we know how to do time-series prediction! We are all set and ready for our competition.","c6ea7609":"Now I need to predict at the (shop,item_level)","146d6e8d":"# SARIMAX","de319659":"Ok, that sounds good. But what libraries do we need to do the prediction?","4041e4c5":"We are ready to plot the predictions of our model and forecast into the future:","ba2b8d3e":"So we have ~2M sales of items in the period we were given.","841362a3":"We first need to create a multi-index dataframe with `(\"date_block_num\", \"shop_id\", \"item_id\")` as index in order to easily find the number of time an `item_id` was sold at month `date_block_num`.","4861f15d":"Let\u2019s use Microoft stock and model the time series with an ARIMA(p,d,q) model.","67a48b41":"### Akaike Information Criterion","7ce462bc":"### Finding model parameters by grid search","f1b70b01":"## 3. Libraries \ud83d\udcda","a18c4e2c":"As you can see, we cannot infer the order of the ARMA process by looking at these plots. In fact, looking closely, we can see some sinusoidal shape in both ACF and PACF functions. This suggests that both processes are in play.","2fe9c5db":"How do they look like?"}}