{"cell_type":{"bcd7096d":"code","9dac1645":"code","5a5c986c":"code","ab6a3a13":"code","0bdd5bf3":"code","23d19527":"code","8313efee":"code","e9e2b9f5":"code","296a7cfd":"code","e581b09c":"code","a87f83f4":"code","3efbb900":"code","9b456d02":"code","3c4cd2ec":"code","ffa9215e":"code","0d9aad9b":"code","1a2dbb64":"code","d79ebb2f":"code","9241f06b":"code","96bd8aa8":"code","547c9cb9":"code","56ffc3bb":"code","912cb2ef":"code","58c48c3d":"code","303e66d0":"code","d7fbc97f":"code","2815849f":"code","2ca5fbaf":"code","95715500":"code","f00c86b8":"code","b03f9e98":"code","d3d48671":"code","ead1d395":"code","e18b7694":"code","da66fd3b":"code","0c3e3568":"code","52227452":"code","7ed250f2":"code","72238dc8":"code","65a8d7c1":"code","25965f5e":"code","a834c21b":"code","8053c45c":"code","20955904":"markdown"},"source":{"bcd7096d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","9dac1645":"#Let's load our data with pandas\ntrain_data = pd.read_csv(\"..\/input\/train.csv\")\nprint(type(train_data))","5a5c986c":"#Let us look what kind of shape we have and what our data says to have an understanding of it\nprint(train_data.shape)","ab6a3a13":"train_data.head()","0bdd5bf3":"#Let's see also what data we are dealing with\ntrain_data.dtypes","23d19527":"#I will resolve to using decision trees to make predictions, but for that I also need prepared data. First\n#I want to check if there is missing data and then also reduce the table to work with only to the dimensions that seem actually\n#matter.\ntrain_data.isnull().sum()\n#Well, there are few missing values...which is not a good thing for us as Age is definitelly one of the dimensions\n#that could matter highly on this\n#Interpolation on this might not be a good idea, but then that means we would want to drop it for future use","8313efee":"#Let us create a new data frame\ndf_train = train_data[[\"Pclass\", \"Sex\", \"Fare\"]] #from theoretical approach - these \n                                                 #are the main factors that can matter\n                                                 #in determening whether someone survived or not\n#And we need our labels        \ndf_label = train_data[[\"Survived\"]]","e9e2b9f5":"df_train.head()","296a7cfd":"df_label.head()","e581b09c":"#It would be really good to convert Sex into integers say 0 = male, 1 = female\ndf_train.dtypes","a87f83f4":"#We need to check if everything is written in the same fashion \"male\" and no \"Male\" or \"mALE\" and so on.\ndf_train.Sex.unique()","3efbb900":"df_train.loc[df_train[\"Sex\"] == 'male', \"Sex\"] = 0\ndf_train.loc[df_train[\"Sex\"] == 'female', \"Sex\"] = 1","9b456d02":"#Alright, everything changed, let's make our training system\nprint(df_train.dtypes)\ndf_train.head(10)","3c4cd2ec":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import make_classification\n#We will use a standart sklearn model\nclf = RandomForestClassifier(n_estimators=10000, max_depth=4, random_state=666)\n\n#And we want some data for validation later\nfrom sklearn.model_selection import train_test_split","ffa9215e":"X_train, X_test, y_train, y_test = train_test_split(df_train, df_label, test_size=0.10, random_state=1337)","0d9aad9b":"#Let's see what goes into our splitted variables for training and testing\nprint(X_train.head())\nprint(y_train.head())\nprint()\nprint(\"Amount of records:\", len(X_train))","1a2dbb64":"#Alright, now let's train our decision tress based system\nclf.fit(X_train, y_train)","d79ebb2f":"clf.score(X_test, y_test)","9241f06b":"#And also let's try K-nn\nfrom sklearn.neighbors import KNeighborsClassifier\nneigh = KNeighborsClassifier(n_neighbors=7)","96bd8aa8":"neigh.fit(X_train, y_train) ","547c9cb9":"neigh.score(X_test, y_test)","56ffc3bb":"#We can easily experiment with the K-nn\nneigh_list = [1,3,5,7,9,11,12]\nfor i in neigh_list:\n    neigh = KNeighborsClassifier(n_neighbors=i)\n    neigh.fit(X_train, y_train) \n    print(i, neigh.score(X_test, y_test))\n    \n#Accuracy is best on 7 neighbours","912cb2ef":"#And lets look at SVMs\nfrom sklearn.svm import SVC\nsvm_clf = SVC(gamma='auto')\nsvm_clf.fit(X_train, y_train) ","58c48c3d":"svm_clf.score(X_test, y_test)","303e66d0":"array_predictions = clf.predict(X_test)","d7fbc97f":"import numpy as np\ny_test_array = np.array(y_test)","2815849f":"print(array_predictions.shape)\nprint(y_test_array.shape)","2ca5fbaf":"y_test_array_new = y_test_array.T[0]\ny_test_array_new","95715500":"print(array_predictions.shape)\nprint(y_test_array_new.shape)","f00c86b8":"import matplotlib.pyplot as plt\nplt.style.use('seaborn-deep')\n\nbins = np.linspace(0, 1, 4)\n\nplt.hist([array_predictions, y_test_array_new], bins, label=['Predicted', 'Real'])\nplt.legend(loc='best')\nplt.show()\n\n#It predicts that a bit more people died than there should be","b03f9e98":"#The issue here will be once more with loading and cleaning the data slightly to our liking. Luckily, this also means we can re-use our code from the before.\ndf_test = pd.read_csv(\"..\/input\/test.csv\")","d3d48671":"df_test.head()","ead1d395":"#Update our information and quickly glance at our data\ndf_test.loc[df_test[\"Sex\"] == 'male', \"Sex\"] = 0\ndf_test.loc[df_test[\"Sex\"] == 'female', \"Sex\"] = 1\ndf_test_pred = df_test[[\"Pclass\", \"Sex\", \"Fare\"]]\nprint(df_test_pred.dtypes)\nprint()\nprint(\"Missing values information:\")\nprint(df_test_pred.isnull().sum())","e18b7694":"#oh no there is one missing point for the fare...let's cheat and take an average for it just because there is only 1 missing point and not many\n#Let's take a look where the missing point of info is\nnull_data = df_test_pred[df_test_pred.isnull().any(axis=1)]\nnull_data\n#Row 152, good, let's remember it","da66fd3b":"#To check if we are right\ndf_test_pred.iloc[152]\n#We are swagaliciously right","0c3e3568":"#Let's fix it and check\ndf_test_pred[\"Fare\"].fillna(df_test_pred[\"Fare\"].mean(), inplace=True)\ndf_test_pred.iloc[152]\n#Well...this more or less works","52227452":"#Now let's use our model for making of quick predictions \/\/ Naturally we need to save our output somewhere\npredictions_variable = clf.predict(df_test_pred)","7ed250f2":"#and as we can see all of our predictions got saved into a nice array.\npredictions_variable","72238dc8":"#Now let us add them to the file...and let's try using pandas for that as well. We are learning :) \n#Do notice that we need to include passengersID as well. So we need preparation of that.\n#Even though numbers go from 1 to ..., in the real world it would be better to show such practices where you assume you do not know that and numbers could be anything.\nidx = df_test[\"PassengerId\"]","65a8d7c1":"#And let's set our both variables to arrays to work with them in the same format\nimport numpy as np\nidx_array = np.array(idx)\nidx_array","25965f5e":"#Let's create a dataframe to hold these both variables\nfinal_df = pd.DataFrame({'PassengerId':idx_array, 'Survived':predictions_variable})","a834c21b":"#Let's take a look at our prepared data\nfinal_df.head(15)\n#Great, now we can save it into a file","8053c45c":"#This should do the trick\nfinal_df.to_csv('Titanic_Submission.csv', index=False, header=True)","20955904":"Eitherway, that was a very quick and short look into couple of sklearn machine learning algorithms that potentially allow us to make conclusions on the Titanic data set. No fancy Neural Nets are required here. And naturally optimizations can be done, with just an hours work for preparing this file - these results are sufficient to at least be happy with the fact that we tried.\n\nNow, let's prepare the file for submission."}}