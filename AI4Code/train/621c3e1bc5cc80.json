{"cell_type":{"6efe4c4e":"code","49a4c94d":"code","055765b8":"code","d623f004":"code","1df3c418":"code","56fdbfdd":"code","897b3ad3":"code","b3339ffd":"code","8a8f509c":"code","f861d3b6":"code","4d3cd43a":"code","042c380a":"code","93640ee2":"code","99e25225":"code","5f28dfdb":"code","6d1bfc9c":"code","f548111a":"code","a1ce7fb8":"code","b4fa67b9":"code","28e3b904":"code","797bdf2f":"markdown","f77c994d":"markdown","db81fa93":"markdown","e7f45e2f":"markdown","eb77b32f":"markdown","206ffb78":"markdown","a8198027":"markdown","bb3c3678":"markdown"},"source":{"6efe4c4e":"import numpy as np\nimport pandas as pd\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.models import Sequential\n\nimport optuna\nfrom optuna.samplers import TPESampler\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score","49a4c94d":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","055765b8":"train.head()","d623f004":"train['LastName'] = train['Name'].str.split(',', expand=True)[0]\ntest['LastName'] = test['Name'].str.split(',', expand=True)[0]\nds = pd.concat([train, test])\n\nsur = []\ndied = []\nfor index, row in ds.iterrows():\n    s = ds[(ds['LastName']==row['LastName']) & (ds['Survived']==1)]\n    d = ds[(ds['LastName']==row['LastName']) & (ds['Survived']==0)]\n    s=len(s)\n    if row['Survived'] == 1:\n        s-=1\n    d=len(d)\n    if row['Survived'] == 0:\n        d-=1\n    sur.append(s)\n    died.append(d)\nds['FamilySurvived'] = sur\nds['FamilyDied'] = died\n\nds['FamilySize'] = ds['SibSp'] + ds['Parch'] + 1\nds['IsAlone'] = 0\nds.loc[ds['FamilySize'] == 1, 'IsAlone'] = 1\nds['Fare'] = ds['Fare'].fillna(train['Fare'].median())\nds['Embarked'] = ds['Embarked'].fillna('Q')\n\ntrain = ds[ds['Survived'].notnull()]\ntest = ds[ds['Survived'].isnull()]\ntest = test.drop(['Survived'], axis=1)\n\ntrain['rich_woman'] = 0\ntest['rich_woman'] = 0\ntrain['men_3'] = 0\ntest['men_3'] = 0\n\ntrain.loc[(train['Pclass']<=2) & (train['Sex']=='female'), 'rich_woman'] = 1\ntest.loc[(test['Pclass']<=2) & (test['Sex']=='female'), 'rich_woman'] = 1\ntrain.loc[(train['Pclass']==3) & (train['Sex']=='male'), 'men_3'] = 1\ntest.loc[(test['Pclass']==3) & (test['Sex']=='male'), 'men_3'] = 1\n\ntrain['rich_woman'] = train['rich_woman'].astype(np.int8)\ntest['rich_woman'] = test['rich_woman'].astype(np.int8)\n\ntrain[\"Cabin\"] = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in train['Cabin']])\ntest['Cabin'] = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in test['Cabin']])\n\ntrain = train.drop(['PassengerId', 'Ticket', 'LastName', 'SibSp', 'Parch'], axis=1)\ntest = test.drop(['PassengerId', 'Ticket', 'LastName', 'SibSp', 'Parch'], axis=1)\n\ncategorical = ['Pclass', 'Sex', 'Embarked', 'Cabin']\nfor cat in categorical:\n    train = pd.concat([train, pd.get_dummies(train[cat], prefix=cat)], axis=1)\n    train = train.drop([cat], axis=1)\n    test = pd.concat([test, pd.get_dummies(test[cat], prefix=cat)], axis=1)\n    test = test.drop([cat], axis=1)\n    \ntrain = train.drop(['Sex_male', 'Name'], axis=1)\ntest =  test.drop(['Sex_male', 'Name'], axis=1)\n\ntrain = train.fillna(-1)\ntest = test.fillna(-1)\ntrain.head()","1df3c418":"EPOCHS = 15\n\ninitial_keras_params = {\n    'layers_number': 1,\n    'n_units_l_0': 128,\n    'activation_l_0': 'relu',\n    'dropout_l_0': 0.5,\n    'lr': 0.001\n}","56fdbfdd":"def keras_classifier(parameters):\n    \n    model = Sequential()\n    layers_number = int(parameters['layers_number'])\n    \n    for i in range(layers_number):\n        model.add(Dense(int(parameters['n_units_l_' + str(i)]), activation=parameters['activation_l_' + str(i)]))\n        model.add(Dropout(int(parameters['dropout_l_' + str(i)])))\n    model.add(Dense(2, activation='softmax'))\n    model.compile(\n        loss='categorical_crossentropy', \n        optimizer=tf.keras.optimizers.Adam(lr=float(parameters['lr'])), \n        metrics=['accuracy']\n    )\n    return model","897b3ad3":"model = keras_classifier(initial_keras_params)","b3339ffd":"y = train['Survived']\ny = tf.keras.utils.to_categorical(y, num_classes=2, dtype='float32')\nX = train.drop(['Survived', 'Cabin_T'], axis=1)\nX_test = test.copy()\n\nX, X_val, y, y_val = train_test_split(X, y, random_state=0, test_size=0.2, shuffle=False)","8a8f509c":"model.fit(X, y, validation_split=0.2, epochs=EPOCHS, batch_size=32)","f861d3b6":"preds = model.predict(X_val)\npreds = np.argmax(preds, axis=1)\n\nprint('accuracy: ', accuracy_score(np.argmax(y_val, axis=1), preds))\nprint('f1-score: ', f1_score(np.argmax(y_val, axis=1), preds))","4d3cd43a":"def create_model(trial):\n    n_layers = trial.suggest_int(\"layers_number\", 1, 2)\n    model = Sequential()\n    for i in range(n_layers):\n        num_hidden = trial.suggest_int(\"n_units_l_{}\".format(i), 2, 16)\n        activation = trial.suggest_categorical('activation_l_{}'.format(i), ['relu', 'sigmoid', 'tanh', 'elu'])\n        model.add(Dense(num_hidden, activation=activation))\n        dropout = trial.suggest_uniform(\"dropout_l_{}\".format(i), 0.1, 0.4)\n        model.add(Dropout(dropout))\n    model.add(Dense(2, activation='softmax'))\n\n    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-1)\n\n    model.compile(\n        loss='categorical_crossentropy',\n        optimizer=tf.keras.optimizers.Adam(lr=lr),\n        metrics=['accuracy']\n    )\n\n    return model","042c380a":"def objective(trial):\n    model = create_model(trial)\n    \n    epochs = trial.suggest_int(\"epochs\", 3, 20)\n    batch = trial.suggest_int(\"batch\", 1, X.shape[0] \/ 4)\n    \n    model.fit(\n        X, \n        y, \n        batch_size=batch, \n        epochs=epochs, \n        verbose=0\n    )\n    preds = model.predict(X_val)\n    return accuracy_score(np.argmax(y_val, axis=1), np.argmax(preds, axis=1))\n","93640ee2":"def optimize():\n    sampler = TPESampler(seed=666)\n    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n    study.optimize(objective, n_trials=80)\n    return study.best_params","99e25225":"params = optimize()","5f28dfdb":"params","6d1bfc9c":"epochs = params['epochs']\nbatch = params['batch']\ndel params['epochs']\ndel params['batch']\n\nopt_model = keras_classifier(params)\nopt_model.fit(X, y, validation_split=0.2, epochs=epochs, batch_size=batch)","f548111a":"preds = opt_model.predict(X_val)\npreds = np.argmax(preds, axis=1)\nprint('accuracy: ', accuracy_score(np.argmax(y_val, axis=1), preds))\nprint('f1-score: ', f1_score(np.argmax(y_val, axis=1), preds))","a1ce7fb8":"preds = opt_model.predict(X_test)\npreds = np.argmax(preds, axis=1)\npreds = preds.astype(np.int16)","b4fa67b9":"submission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nsubmission['Survived'] = preds\nsubmission.to_csv('submission.csv', index=False)","28e3b904":"submission.head()","797bdf2f":"Let's start optimization process","f77c994d":"#### In this kernel I present a simple approach to optimize keras neural network architecture using optuna. Method is similar to one presented here: <a href=\"https:\/\/www.kaggle.com\/isaienkov\/top-10-efficient-ensembling-in-few-lines-of-code\">Top 10%. Efficient ensembling in few lines of code<\/a>","db81fa93":"Our best parameters","e7f45e2f":"Let's check our initial model","eb77b32f":"First let's do some feature engineering.","206ffb78":"Here we specify default keras parameters for initial model","a8198027":"Now we build our keras classifier that will be used for optimization","bb3c3678":"<h1><center>Titanic: Keras Neural Network architecture optimization<\/center><\/h1>\n\n<center><img src=\"https:\/\/www.dlt.travel\/immagine\/33923\/magazine-titanic2.jpg\"><\/center>"}}