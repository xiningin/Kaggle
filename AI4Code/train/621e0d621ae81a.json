{"cell_type":{"90b3b969":"code","6613a606":"code","dcabe119":"code","2dcf29a1":"code","3d2e356c":"code","000ebca8":"code","eb608725":"code","1f7201ea":"code","436a7baa":"code","74a5ae25":"code","2c857a71":"code","552c9e22":"code","e0a3f686":"code","146d1c43":"code","27344ff5":"code","6a8a8674":"code","96604882":"code","fb3a3215":"code","3da1a121":"code","9f76e22f":"code","d2bd41d8":"code","cb1b2a55":"code","44dc9fbc":"code","20b2162f":"code","c1f47a3c":"code","a8f9acbb":"code","db677f2b":"code","1214c892":"code","323f6a74":"code","487a1231":"code","3d95448e":"code","a16f252b":"code","341586f1":"code","76c77cd3":"code","45c647b9":"code","d4d2599e":"code","5c5c4188":"code","7f749e9c":"code","5313cfcb":"code","a9386109":"code","ae98c6b6":"code","6756bb1e":"code","a87cc7de":"code","da128704":"code","eb8aa10d":"code","db198d1b":"code","2abdb45c":"code","d7220e56":"code","497ce647":"code","c381447f":"code","0504b21c":"code","89cdfb1f":"code","3356e521":"code","175c9b60":"code","271b4e95":"code","a556e81e":"code","e0187ad7":"code","4a963f83":"code","205100b8":"code","cd83de47":"code","88ecbc37":"code","a7504bbb":"code","1eab7e0f":"markdown","3f809e91":"markdown","c4cc0891":"markdown","ce0cc5fa":"markdown","3fd243e8":"markdown","56b1484e":"markdown","7c230293":"markdown","3dc20445":"markdown","295ea2d2":"markdown","a650b18d":"markdown","26411d4c":"markdown","769e544c":"markdown","61917c16":"markdown","37022e13":"markdown","aa9ee257":"markdown","5a7ce335":"markdown","763bb8cf":"markdown","f0e57d74":"markdown","c8f8a6f2":"markdown","6c135fb7":"markdown","94fadcd2":"markdown","83c0a763":"markdown","74b25f18":"markdown","b512a961":"markdown"},"source":{"90b3b969":"import tensorflow as tf\nimport pathlib\ndataset_url = \"https:\/\/storage.googleapis.com\/download.tensorflow.org\/example_images\/flower_photos.tgz\"\ndata_dir = tf.keras.utils.get_file(origin=dataset_url,\n                                   fname='flower_photos',\n                                   untar=True)\ndata_dir = pathlib.Path(data_dir)","6613a606":"image_count = len(list(data_dir.glob('*\/*.jpg')))\nprint(image_count)","dcabe119":"# input image shape is 224x224\nbatch_size = 32\nimg_height = 224\nimg_width = 224","2dcf29a1":"# training dataset is 80 perent of total dataset i.e 0.8*3670=2936\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"training\",\n  seed=123,\n  image_size=(img_height, img_width),batch_size=batch_size)","3d2e356c":"#validation dataset is 20 perent of total dataset i.e 0.2*3670=734\nval_ds = tf.keras.utils.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"validation\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","000ebca8":"# Finding total classes in our dataset\nclass_names = train_ds.class_names\nprint(class_names)","eb608725":"#Checking some of the images with labels\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(class_names[labels[i]])\n    plt.axis(\"off\")","1f7201ea":"# Checking image shape, channel numbers, filter numbers\n# image shape=224x224 , filter numbers=3 , channel number=32\nfor image_batch, labels_batch in train_ds:\n  print(image_batch.shape)\n  print(labels_batch.shape)\n  break","436a7baa":"# resaling the pixels\nnormalization_layer = tf.keras.layers.Rescaling(1.\/255)","74a5ae25":"normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\nimage_batch, labels_batch = next(iter(normalized_ds))\nfirst_image = image_batch[0]\nprint(np.min(first_image))\nprint(np.max(first_image))","2c857a71":"AUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)","552c9e22":"num_classes = 5\n\nmodel1 = tf.keras.Sequential([\n  tf.keras.layers.Rescaling(1.\/255),\n\n  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n\n  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n\n  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n\n  tf.keras.layers.Flatten(),\n\n  tf.keras.layers.Dense(128, activation='relu'),\n\n  tf.keras.layers.Dense(num_classes, activation='softmax')\n])\n\n","e0a3f686":"model1.compile(\n  optimizer='adam',\n  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])","146d1c43":"# Batch size=32\nmodel1.fit(\n  train_ds,\n  validation_data=val_ds,\n  validation_batch_size=batch_size,\n  epochs=20,verbose=2\n)","27344ff5":"model1.summary()","6a8a8674":"#model1.save_weights('\/content\/drive\/MyDrive\/Colab Notebooks\/Flower_classification_CNN_project\/model1_best.h5')","96604882":"score_train = model1.evaluate(train_ds, verbose=2)\naccuracy_train = 100*score_train[1]\n\nprint('Train accuracy = %.4f%% ' % accuracy_train)","fb3a3215":"score_val = model1.evaluate(val_ds, verbose=2)\naccuracy_val = 100*score_val[1]\n\n\nprint('Validate accuracy = %.4f%% ' % accuracy_val)","3da1a121":"num_classes = 5\n\nmodel2 = tf.keras.Sequential([\n  tf.keras.layers.Rescaling(1.\/255),\n\n  tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n  tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n  tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n\n  tf.keras.layers.Conv2D(64, 3, activation='relu'),\n  tf.keras.layers.Conv2D(64, 3, activation='relu'),\n  tf.keras.layers.Conv2D(64, 3, activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n\n  tf.keras.layers.Conv2D(128, 3, activation='relu'),\n  tf.keras.layers.Conv2D(128, 3, activation='relu'),\n  tf.keras.layers.Conv2D(128, 3, activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n\n  tf.keras.layers.Flatten(),\n\n  tf.keras.layers.Dense(128, activation='relu'),\n\n  tf.keras.layers.Dense(num_classes, activation='softmax')\n])\n","9f76e22f":"model2.compile(\n  optimizer='adam',\n  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])","d2bd41d8":"model2.fit(\n  train_ds,\n  validation_data=val_ds,\n  validation_batch_size=batch_size,\n  epochs=20,verbose=2\n)","cb1b2a55":"model2.summary()","44dc9fbc":"#model2.save_weights('\/content\/drive\/MyDrive\/Colab Notebooks\/Flower_classification_CNN_project\/model2_best.h5')","20b2162f":"score_train = model2.evaluate(train_ds, verbose=2)\naccuracy_train = 100*score_train[1]\n\nprint('Train accuracy = %.4f%% ' % accuracy_train)","c1f47a3c":"score_val = model2.evaluate(val_ds, verbose=2)\naccuracy_val = 100*score_val[1]\n\nprint('Validate accuracy = %.4f%% ' % accuracy_val)","a8f9acbb":"num_classes = 5\n\nmodel3 = tf.keras.Sequential([\n  tf.keras.layers.Rescaling(1.\/255),\n\n  tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n  tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n  tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n\n  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n\n  tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\n  tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\n  tf.keras.layers.BatchNormalization(),\n\n  tf.keras.layers.Flatten(),\n\n  tf.keras.layers.Dense(128, activation='relu'),\n\n  tf.keras.layers.Dense(num_classes, activation='softmax')\n])\n","db677f2b":"model3.compile(\n  optimizer='adam',\n  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])","1214c892":"model3.fit(\n  train_ds,\n  validation_data=val_ds,\n  validation_batch_size=batch_size,\n  epochs=20,verbose=2\n)","323f6a74":"model3.summary()","487a1231":"#model3.save_weights('\/content\/drive\/MyDrive\/Colab Notebooks\/Flower_classification_CNN_project\/model3_best.h5')","3d95448e":"score_train = model3.evaluate(train_ds, verbose=2)\naccuracy_train = 100*score_train[1]\nprint('Train accuracy = %.4f%% ' % accuracy_train)\n\nscore_val = model3.evaluate(val_ds, verbose=2)\naccuracy_val = 100*score_val[1]\nprint('Validate accuracy = %.4f%% ' % accuracy_val)","a16f252b":"num_classes = 5\n\nmodel4 = tf.keras.Sequential([\n  tf.keras.layers.Rescaling(1.\/255),\n\n  tf.keras.layers.Conv2D(32, 3, padding='valid', activation='relu'),\n  tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n  tf.keras.layers.BatchNormalization(),\n\n  tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Dropout(0.1),\n\n  tf.keras.layers.Conv2D(64, 3,  padding='valid', activation='relu'),\n  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n  tf.keras.layers.BatchNormalization(),\n\n  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Dropout(0.1),  \n\n  tf.keras.layers.Conv2D(128, 3,  padding='valid', activation='relu'),\n  tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\n  tf.keras.layers.BatchNormalization(),\n\n  tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Dropout(0.1),   \n\n  tf.keras.layers.Flatten(),\n\n  tf.keras.layers.Dense(128, activation='relu'),\n\n  tf.keras.layers.Dense(num_classes, activation='softmax')\n])\n","341586f1":"model4.compile(\n  optimizer='adam',\n  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])\n\n","76c77cd3":"model4.fit(\n  train_ds,\n  validation_data=val_ds,\n  validation_batch_size=batch_size,\n  epochs=20,verbose=2\n)","45c647b9":"model4.summary()","d4d2599e":"#model4.save_weights('\/content\/drive\/MyDrive\/Colab Notebooks\/Flower_classification_CNN_project\/model4_best.h5')","5c5c4188":"score_train = model4.evaluate(train_ds, verbose=2)\naccuracy_train = 100*score_train[1]\nprint('Train accuracy = %.4f%% ' % accuracy_train)\n\nscore_val = model4.evaluate(val_ds, verbose=2)\naccuracy_val = 100*score_val[1]\nprint('Validate accuracy = %.4f%% ' % accuracy_val)","7f749e9c":"num_classes = 5\n\nmodel5 = tf.keras.Sequential([\n  tf.keras.layers.Rescaling(1.\/255),\n\n  tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n  tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n  tf.keras.layers.Conv2D(64, 3,  padding='same', activation='relu'),\n  tf.keras.layers.BatchNormalization(),\n  tf.keras.layers.MaxPooling2D(),\n\n  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n  tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\n  tf.keras.layers.Conv2D(256, 3,  padding='same', activation='relu'),\n  tf.keras.layers.BatchNormalization(),\n  tf.keras.layers.MaxPooling2D(),\n\n  tf.keras.layers.Flatten(),\n\n  tf.keras.layers.Dense(128, activation='relu'),\n\n  tf.keras.layers.Dense(num_classes, activation='softmax')\n])\n","5313cfcb":"model5.compile(\n  optimizer='adam',\n  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])\n\n","a9386109":"model5.fit(\n  train_ds,\n  validation_data=val_ds,\n  validation_batch_size=batch_size,\n  epochs=20,verbose=2\n)","ae98c6b6":"model5.summary()","6756bb1e":"#model5.save_weights('\/content\/drive\/MyDrive\/Colab Notebooks\/Flower_classification_CNN_project\/model5_best.h5')","a87cc7de":"score_train = model5.evaluate(train_ds, verbose=2)\naccuracy_train = 100*score_train[1]\nprint('Train accuracy = %.4f%% ' % accuracy_train)\n\nscore_val = model5.evaluate(val_ds, verbose=2)\naccuracy_val = 100*score_val[1]\nprint('Validate accuracy = %.4f%% ' % accuracy_val)","da128704":"GCS_PATTERN = 'gs:\/\/flowers-public\/tfrecords-jpeg-192x192-2\/*.tfrec'\nIMAGE_SIZE = [192, 192]\n\nBATCH_SIZE = 32\nEPOCHS = 10\n\nVALIDATION_SPLIT = 0.20\nCLASSES = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips'] \n\n# splitting data files between training and validation\nfilenames = tf.io.gfile.glob(GCS_PATTERN)\nsplit = int(len(filenames) * VALIDATION_SPLIT)\ntraining_filenames = filenames[split:]\nvalidation_filenames = filenames[:split]\nprint(\"Pattern matches {} data files. Splitting dataset into {} training files and {} validation files\".format(len(filenames), len(training_filenames), len(validation_filenames)))\nvalidation_steps = int(3670 \/\/ len(filenames) * len(validation_filenames)) \/\/ BATCH_SIZE\nsteps_per_epoch = int(3670 \/\/ len(filenames) * len(training_filenames)) \/\/ BATCH_SIZE\nprint(\"With a batch size of {}, there will be {} batches per training epoch and {} batch(es) per validation run.\".format(BATCH_SIZE, steps_per_epoch, validation_steps))","eb8aa10d":"def dataset_to_numpy_util(dataset, N):\n  dataset = dataset.batch(N)\n  \n  for images, labels in dataset:\n    numpy_images = images.numpy()\n    numpy_labels = labels.numpy()\n    break;\n\n  return numpy_images, numpy_labels\n\ndef title_from_label_and_target(label, correct_label):\n  correct = (label == correct_label)\n  return \"{} [{}{}{}]\".format(CLASSES[label], str(correct), ', shoud be ' if not correct else '',\n                              CLASSES[correct_label] if not correct else ''), correct\n\ndef display_one_flower(image, title, subplot, red=False):\n    plt.subplot(subplot)\n    plt.axis('off')\n    plt.imshow(image)\n    plt.title(title, fontsize=16, color='red' if red else 'black')\n    return subplot+1\n  \ndef display_9_images_from_dataset(dataset):\n  subplot=331\n  plt.figure(figsize=(13,13))\n  images, labels = dataset_to_numpy_util(dataset, 9)\n  for i, image in enumerate(images):\n    title = CLASSES[labels[i]]\n    subplot = display_one_flower(image, title, subplot)\n    if i >= 8:\n      break;\n              \n  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n  plt.show()\n  \ndef display_9_images_with_predictions(images, predictions, labels):\n  subplot=331\n  plt.figure(figsize=(13,13))\n  classes = np.argmax(predictions, axis=-1)\n  for i, image in enumerate(images):\n    title, correct = title_from_label_and_target(classes[i], labels[i])\n    subplot = display_one_flower(image, title, subplot, not correct)\n    if i >= 8:\n      break;\n              \n  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n  plt.show()\n  \ndef display_training_curves(training, validation, title, subplot):\n  if subplot%10==1: \n    plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n\n  ax = plt.subplot(subplot)\n  ax.set_facecolor('#F8F8F8')\n  ax.plot(training)\n  ax.plot(validation)\n  ax.set_title('model '+ title)\n  ax.set_ylabel(title)\n  ax.set_xlabel('epoch')\n  ax.legend(['train', 'valid.'])","db198d1b":"def read_tfrecord(example):\n    features = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), \n        \"class\": tf.io.FixedLenFeature([], tf.int64),  \n    }\n    example = tf.io.parse_single_example(example, features)\n    image = tf.io.decode_jpeg(example['image'], channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0  \n    image = tf.reshape(image, [*IMAGE_SIZE, 3]) \n    class_label = example['class']\n    return image, class_label\n\n# loading the datasets\n\ndef load_dataset(filenames):\n\n  option_no_order = tf.data.Options()\n  option_no_order.experimental_deterministic = False\n\n  dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n  dataset = dataset.with_options(option_no_order)\n  dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTOTUNE)\n  return dataset","2abdb45c":"display_9_images_from_dataset(load_dataset(training_filenames))","d7220e56":"def get_batched_dataset(filenames, train=False):\n  dataset = load_dataset(filenames)\n  dataset = dataset.cache() \n  if train:    \n    dataset = dataset.repeat()\n  dataset = dataset.batch(BATCH_SIZE)\n  dataset = dataset.prefetch(AUTOTUNE) \n  return dataset\n  \n\n# instantiate the datasets\ntraining_dataset = get_batched_dataset(training_filenames, train=True)\nvalidation_dataset = get_batched_dataset(validation_filenames, train=False)","497ce647":"pretrained_model_VGG16 = tf.keras.applications.VGG16(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\npretrained_model_VGG16.trainable = False\n\nmodel6 = tf.keras.Sequential([\n    pretrained_model_VGG16,\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(5, activation='softmax')\n])\n\nmodel6.compile(\n    optimizer='adam',\n    loss = 'sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel6.summary()","c381447f":"history = model6.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=20,\n                    validation_data=validation_dataset, validation_steps=validation_steps)","0504b21c":"print(history.history.keys())\ndisplay_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'accuracy', 211)\ndisplay_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 212)","89cdfb1f":"flowers, labels = dataset_to_numpy_util(load_dataset(validation_filenames).skip(np.random.randint(300)), 9)\n\npredictions = model6.predict(flowers, steps=1)\nprint(np.array(CLASSES)[np.argmax(predictions, axis=-1)].tolist())","3356e521":"display_9_images_with_predictions(flowers, predictions, labels)","175c9b60":"#model6.save_weights('\/content\/drive\/MyDrive\/Colab Notebooks\/Flower_classification_CNN_project\/model6_best.h5')","271b4e95":"batch_size = 32\nimg_height = 150\nimg_width = 150","a556e81e":"train_ds = tf.keras.utils.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"training\",\n  seed=123,\n  image_size=(img_height, img_width),batch_size=batch_size)","e0187ad7":"val_ds = tf.keras.utils.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"validation\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","4a963f83":"IMAGE_SIZE = [150,150]\nMobileNetV2_model = tf.keras.applications.MobileNetV2(input_shape=[*IMAGE_SIZE, 3], include_top=False)\nMobileNetV2_model.trainable=False\n","205100b8":"model7 = tf.keras.Sequential([MobileNetV2_model,\n                              tf.keras.layers.Flatten(),\n                              tf.keras.layers.Dense(5, activation='softmax')                             \n])\n\nmodel7.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nmodel7.summary()","cd83de47":"model7.fit(\n  train_ds,\n  validation_data=val_ds,\n  validation_batch_size=batch_size,\n  epochs=20,verbose=2\n)","88ecbc37":"#model7.save_weights('\/content\/drive\/MyDrive\/Colab Notebooks\/Flower_classification_CNN_project\/model7_best.h5')","a7504bbb":"score_train = model7.evaluate(train_ds, verbose=2)\naccuracy_train = 100*score_train[1]\nprint('Train accuracy = %.4f%% ' % accuracy_train)\n\nscore_val = model7.evaluate(val_ds, verbose=2)\naccuracy_val = 100*score_val[1]\nprint('Validate accuracy = %.4f%% ' % accuracy_val)\n\n","1eab7e0f":"# Checking the model accuracy","3f809e91":"\n# \n# <a id=\"1\"><\/a> <p style=\"background-color:#615154;font-family:newtimeroman;color:#CABFC1;font-size:150%;text-align:center;border-radius:40px 40px;\">MODEL-2<\/p>","c4cc0891":"# \n#  <a id=\"1\"><\/a> <p style=\"background-color:#615154;font-family:newtimeroman;color:#CABFC1;font-size:150%;text-align:center;border-radius:40px 40px;\"> Pretrained Model-1 (VGG16)<\/p>","ce0cc5fa":"# <a id=\"1\"><\/a> <p style=\"background-color:#615154;font-family:newtimeroman;color:#CABFC1;font-size:150%;text-align:center;border-radius:40px 40px;\">MODEL-4<\/p>","3fd243e8":"# Finding the summary of our architecture ","56b1484e":"<a id=\"6\"><\/a>\n# <p style=\"background-color:#615154;font-family:newtimeroman;color:#CABFC1;font-size:250%;text-align:center;border-radius:40px 40px;\">KEEP LEARNING AND KEEP UPVOTING\n<\/p>","7c230293":"# \n# <a id=\"1\"><\/a> <p style=\"background-color:#615154;font-family:newtimeroman;color:#CABFC1;font-size:150%;text-align:center;border-radius:40px 40px;\">MODEL-5<\/p>","3dc20445":"# Saving the model for using it to predict in future","295ea2d2":"# Compiling the model","a650b18d":" \n# <a id=\"1\"><\/a> <p style=\"background-color:#615154;font-family:newtimeroman;color:#CABFC1;font-size:150%;text-align:center;border-radius:40px 40px;\">MODEL-1<\/p>","26411d4c":"<a id=\"6\"><\/a>\n# <p style=\"background-color:#615154;font-family:newtimeroman;color:#CABFC1;font-size:250%;text-align:center;border-radius:40px 40px;\">---------------THE END----------------<\/p>","769e544c":"# Training the model on 20 epochs","61917c16":"<a id=\"6\"><\/a>\n# <p style=\"background-color:#615154;font-family:newtimeroman;color:#CABFC1;font-size:150%;text-align:center;border-radius:40px 40px;\">Importing the dataset<\/p>","37022e13":"<a id=\"6\"><\/a>\n# <p style=\"background-color:#615154;font-family:newtimeroman;color:#CABFC1;font-size:150%;text-align:center;border-radius:40px 40px;\">Enter Image size and shape (preferrably use the image shape based upon the paper you are using.) <\/p>\n","aa9ee257":"<a id=\"6\"><\/a>\n# <p style=\"background-color:#615154;font-family:newtimeroman;color:#CABFC1;font-size:150%;text-align:center;border-radius:40px 40px;\">Finding the classes in dataset<\/p>\n","5a7ce335":"<p style=\"background-color:#CABFC1;font-family:newtimeroman;font-size:200%;text-align:left;\"> \ud83d\udcccThis notebook is beginner friendly and contains an end to end deployed project.\n<\/p>\n\n*  **https:\/\/github.com\/raj-gupta1\/Flower-Species-Classification** \n\n* **Architecture used**<br>\n    1. VGG16\n    2. MobileNetV2\n    3. Self created 5 CNN models\n    4. No. of classes: 5\n    <br><br>","763bb8cf":"<a id=\"6\"><\/a>\n# <p style=\"background-color:#615154;font-family:newtimeroman;color:#CABFC1;font-size:150%;text-align:center;border-radius:40px 40px;\">Normalization of image datasets<\/p>\n","f0e57d74":"<p style=\"background-color:#CABFC1;font-family:newtimeroman;font-size:200%;text-align:left;\"> \ud83d\udcccThis notebook contains 7 different models:-\n<\/p>\n\n* 5 CNN models created using keras\n* Pretrained VGG16 model \n* Pretrained MobileNetV2 model ","c8f8a6f2":"<a id=\"6\"><\/a>\n# <p style=\"background-color:#615154;font-family:newtimeroman;color:#CABFC1;font-size:250%;text-align:center;border-radius:40px 40px;\">FLOWER SPECIES PREDICTION<\/p>","6c135fb7":"# \n# <a id=\"1\"><\/a> <p style=\"background-color:#615154;font-family:newtimeroman;color:#CABFC1;font-size:150%;text-align:center;border-radius:40px 40px;\"> Pretrained Model-2 (MobileNetV2)<\/p>","94fadcd2":"<a id=\"6\"><\/a>\n# <p style=\"background-color:#615154;font-family:newtimeroman;color:#CABFC1;font-size:150%;text-align:center;border-radius:40px 40px;\">Splitting the data into train and validate<\/p>\n","83c0a763":"# \n \n# <a id=\"1\"><\/a> <p style=\"background-color:#615154;font-family:newtimeroman;color:#CABFC1;font-size:150%;text-align:center;border-radius:40px 40px;\">MODEL-3<\/p>","74b25f18":"<p style=\"background-color:#CABFC1;font-family:newtimeroman;font-size:200%;text-align:left;\"> \ud83d\udcccTools for project deployment.\n<\/p>\n\n* **Libraries used**<br>\n    1. Flask==1.1.2\n    2. numpy==1.18.4\n    3. tensorflow==2.2.0\n    4. Werkzeug==1.0.1\n    <br><br>\n\n* **Tools used**<br>\n    1. Pycharm\n    2. Google Colab\n    3. git\n    <br><br>","b512a961":"**Model is overfitted as train accuracy is 100 and validation accuracy is 64**"}}