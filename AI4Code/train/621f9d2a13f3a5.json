{"cell_type":{"3c6026ae":"code","2a8fb286":"code","5778225a":"code","8c86ffa9":"code","90b7ddcf":"code","27c908e7":"code","856c146b":"code","5dff9178":"code","3b39d97e":"code","b190a2dd":"code","c03c868d":"code","4f01b1ef":"code","8389bb1d":"code","fbcbc08a":"code","2b57e999":"code","7029a03e":"code","41f07029":"code","dd28d0a9":"code","3b3fa402":"code","0daf2681":"code","30798aff":"code","166e06db":"code","96f9d7d3":"code","9d5db8b3":"code","483873ec":"code","cb6550d4":"code","5bfef45b":"code","a88f533e":"code","c1ce7376":"code","bee7322f":"code","47030018":"code","560b2232":"code","6fbe3b1e":"code","902c7b67":"code","95b81bd8":"code","6453310b":"code","78a56663":"code","a84c2104":"code","4104b990":"code","ece83c55":"code","56786a49":"code","616a03a8":"code","76ec0152":"code","eb29c4e9":"code","460ca129":"code","ebd5a87a":"code","33e1ce0b":"code","d920568f":"code","6758ecc5":"code","7c6879ab":"code","62f6964b":"code","9884b565":"code","4ed2335a":"code","ce5f5fd1":"code","8d074d00":"code","e6349598":"code","a17fde88":"code","d460d9bd":"code","f173fbd9":"code","5ef6b397":"code","f5b5194a":"code","7da44e76":"code","bd963af8":"code","fe073f83":"code","aa4b8871":"code","6d6cf3ab":"code","fcbee4cc":"code","8b7acfb9":"code","17017ee2":"code","4ea8be1a":"code","9a14c965":"code","8937d06b":"code","8d9cbf90":"markdown","a691707a":"markdown","bd1bccf9":"markdown","46ef269c":"markdown","71da8b24":"markdown","019d07b0":"markdown","cb902901":"markdown","76f18180":"markdown","79503124":"markdown","448dbe70":"markdown","065ee185":"markdown","ea5c01fd":"markdown","d9b702dc":"markdown","19538852":"markdown","0e05f687":"markdown","3376be08":"markdown","dcfdf416":"markdown","281469a7":"markdown","f5fc90e8":"markdown","bc2c030d":"markdown","eb5cb6f6":"markdown","2f69cba2":"markdown","df1cde81":"markdown","95a7712e":"markdown","94c39100":"markdown","c563ca7c":"markdown","9f0320f3":"markdown","20e45c06":"markdown","e76f997d":"markdown","1cec8f3a":"markdown","03b14405":"markdown","90db4f86":"markdown","21be6298":"markdown"},"source":{"3c6026ae":"import pandas as pd\nimport numpy as np\nimport re\nimport os\n\nimport missingno as msno\n\n#Sklearn\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import confusion_matrix,precision_score,recall_score,roc_auc_score,plot_roc_curve,PrecisionRecallDisplay\n\n#Plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#Others\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","2a8fb286":"from warnings import simplefilter\nfrom sklearn.exceptions import ConvergenceWarning\nsimplefilter(\"ignore\", category=ConvergenceWarning)","5778225a":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","8c86ffa9":"# To display all rows and columns\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)","90b7ddcf":"#Reading Dataframes\ndf = pd.read_csv(\"..\/input\/ml-lab-i-c31\/train.csv\", index_col=0)\nunseen = pd.read_csv(\"..\/input\/ml-lab-i-c31\/test.csv\", index_col=0)\nsample = pd.read_csv(\"..\/input\/ml-lab-i-c31\/sample.csv\")\ndata_dict = pd.read_csv(\"..\/input\/ml-lab-i-c31\/data_dictionary.csv\")","27c908e7":"data_dict","856c146b":"sample.head()","5dff9178":"print(df.shape)\ndf.head()","3b39d97e":"print(unseen.shape)\nunseen.head()","b190a2dd":"df.describe()","c03c868d":"# Dropping variables with same numeric values in all rows\ndf = df.drop(columns=['circle_id','loc_og_t2o_mou','std_og_t2o_mou','loc_ic_t2o_mou','std_og_t2c_mou_6','std_og_t2c_mou_7','std_og_t2c_mou_8',\n                      'std_ic_t2o_mou_6','std_ic_t2o_mou_7','std_ic_t2o_mou_8'])","4f01b1ef":"df.describe(include='object').transpose()","8389bb1d":"# Dropping variables with same unique value in all rows\ndf = df.drop(columns=['last_date_of_month_6','last_date_of_month_7','last_date_of_month_8'])","fbcbc08a":"df.info(verbose=1)","2b57e999":"# Finding columns with null values (in percentage)\nnull_pct = 100*df.isnull().sum()\/len(df)\nnull_pct[null_pct>0]","7029a03e":"# Dropping extreme null value columns (over 40%)\ndf = df.drop(null_pct[null_pct>40].index,1)\ndf.shape","41f07029":"msno.matrix(df)","dd28d0a9":"null_pct = 100*df.isnull().sum()\/len(df)","3b3fa402":"# columns with null values\nnull_cols = null_pct[null_pct>0].index\n\n# numeric & object columns with null values\nnumeric_null_df = df[null_cols].select_dtypes(exclude='object').columns\nobj_null_df = df[null_cols].select_dtypes(include='object').columns","0daf2681":"# boxplots to analyze outliers in numeric columns with null values\n\nplt.figure(figsize=(20,50))\nn=1\nn_rows= round(len(numeric_null_df)\/3)\n\nfor i in numeric_null_df:\n    plt.subplot(n_rows,3,n)\n    sns.boxplot(df[i])\n    n+=1\n    \nplt.tight_layout()\nplt.show()","30798aff":"# countplots to analyze distribution of values in categorical columns with null values\n\nn = 1\nfig=plt.figure(figsize=(20,15))\nfor i in obj_null_df:\n    plt.subplot(3,1,n)\n    sns.countplot(df[i], order=df[i].value_counts().index, color='skyblue')\n    plt.xticks(rotation=45)\n    n+=1\n    \nplt.tight_layout()\nplt.show()","166e06db":"# Separating numeric and object variables\n\nnum_col_df = df.select_dtypes(exclude='object').copy()\nobj_col_df = df.select_dtypes(include='object').copy()","96f9d7d3":"num_col_df.head()","9d5db8b3":"obj_col_df.head()","483873ec":"# Plotting Churn Probability Ratio\nplt.figure(figsize=(7,7))\nplt.pie(df.churn_probability.value_counts(),explode=(0,0.1), labels=['No','Yes'],autopct='%1.1f%%')\nplt.title('Churn Probability Ratio',fontsize=15)\nplt.show()","cb6550d4":"# Plotting ARPUs of different months for both churn outcomes\nplt.figure(figsize=(20,7))\nplt.suptitle('ARPUs of different months for both churn outcomes', fontsize=20)\nplt.subplot(1,3,1)\nplt.title('June')\nsns.boxplot(y='arpu_6',x='churn_probability',data=df)\nplt.subplot(1,3,2)\nplt.title('July')\nsns.boxplot(y='arpu_7',x='churn_probability',data=df)\nplt.subplot(1,3,3)\nplt.title('August')\nsns.boxplot(y='arpu_8',x='churn_probability',data=df)\nplt.show()","5bfef45b":"\nplt.figure(figsize=(20,15))\nplt.subplot(1,3,1)\nplt.title('June 2G Distribution')\nplt.pie(df.monthly_2g_6.value_counts(),explode=(0,0.1,0.2,0,0), labels=['0','1','2','3','4'],autopct='%1.1f%%')\nplt.legend(round(df.monthly_2g_6.value_counts(normalize=True)*100,1))\nplt.subplot(1,3,2)\nplt.title('July 2G Distribution')\nplt.pie(df.monthly_2g_7.value_counts(),explode=(0,0.1,0.2,0,0,0), labels=['0','1','2','3','4','5'],autopct='%1.1f%%')\nplt.legend(round(df.monthly_2g_7.value_counts(normalize=True)*100,1))\nplt.subplot(1,3,3)\nplt.title('August 2G Distribution')\nplt.pie(df.monthly_2g_8.value_counts(),explode=(0,0.1,0.2,0,0,0), labels=['0','1','2','3','4','5'],autopct='%1.1f%%')\nplt.legend(round(df.monthly_2g_8.value_counts(normalize=True)*100,1))\nplt.show()","a88f533e":"# Plotting 3G volumes (Mb) for June, July, August\nplt.figure(figsize=(20,10))\nplt.suptitle('3G volumes (Mb) for June, July, August', fontsize=20)\nplt.subplot(3,1,1)\nsns.distplot(df.vol_3g_mb_6).set(xlabel='June 3G vloume (Mb)')\nplt.subplot(3,1,2)\nsns.distplot(df.vol_3g_mb_7).set(xlabel='July 3G vloume (Mb)')\nplt.subplot(3,1,3)\nsns.distplot(df.vol_3g_mb_8).set(xlabel='August 3G vloume (Mb)')\nplt.tight_layout()\nplt.show()","c1ce7376":"# Plotting ARPU vs Total Recharge Amount For Different Churn\/No Churn\nplt.figure(figsize=(20,7))\nplt.suptitle('ARPU vs Total Recharge Amount For Different Churn\/No Churn', fontsize=20)\nplt.subplot(1,3,1)\nsns.scatterplot(data=df, x='total_rech_amt_6',y='arpu_6',hue='churn_probability')\nplt.subplot(1,3,2)\nsns.scatterplot(data=df, x='total_rech_amt_7',y='arpu_7',hue='churn_probability')\nplt.subplot(1,3,3)\nsns.scatterplot(data=df, x='total_rech_amt_8',y='arpu_8',hue='churn_probability')\nplt.show()","bee7322f":"# Plotting distribution of age on network vs Churn probability (0,1)\nsns.displot(df, x=\"aon\", hue=\"churn_probability\", kind='kde', height=7).set(title='Distribution of Age on network vs Churn probability')\nplt.show()","47030018":"# Converting to datetime\ndf['date_of_last_rech_6'] = pd.to_datetime(df['date_of_last_rech_6'], format='%m\/%d\/%Y')\ndf['date_of_last_rech_7'] = pd.to_datetime(df['date_of_last_rech_7'], format='%m\/%d\/%Y')\ndf['date_of_last_rech_8'] = pd.to_datetime(df['date_of_last_rech_8'], format='%m\/%d\/%Y')\n\n# Extracting days of the month \ndf['day_of_last_rech_6'] = df['date_of_last_rech_6'].dt.day\ndf['day_of_last_rech_7'] = df['date_of_last_rech_7'].dt.day\ndf['day_of_last_rech_8'] = df['date_of_last_rech_8'].dt.day\n\n# Dropping original unnecessary variables\ndf = df.drop(columns=['date_of_last_rech_6','date_of_last_rech_7','date_of_last_rech_8'])\n\n# Binning to Week of the month\ncols = ['day_of_last_rech_6','day_of_last_rech_7','day_of_last_rech_8']\n\nfor col in cols:\n    df[col] = pd.cut(df[col], [0,7,14,21,28,31], labels=['Week 1','Week 2','Week 3','Week 4','Week 5'])","560b2232":"## For unseen dataset\n# Converting to datetime\nunseen['date_of_last_rech_6'] = pd.to_datetime(unseen['date_of_last_rech_6'], format='%m\/%d\/%Y')\nunseen['date_of_last_rech_7'] = pd.to_datetime(unseen['date_of_last_rech_7'], format='%m\/%d\/%Y')\nunseen['date_of_last_rech_8'] = pd.to_datetime(unseen['date_of_last_rech_8'], format='%m\/%d\/%Y')\n\n# Extracting days of the month \nunseen['day_of_last_rech_6'] = unseen['date_of_last_rech_6'].dt.day\nunseen['day_of_last_rech_7'] = unseen['date_of_last_rech_7'].dt.day\nunseen['day_of_last_rech_8'] = unseen['date_of_last_rech_8'].dt.day\n\n# Dropping original unnecessary variables\nunseen = unseen.drop(columns=['date_of_last_rech_6','date_of_last_rech_7','date_of_last_rech_8'])\n\n# Binning to Week of the month\ncols = ['day_of_last_rech_6','day_of_last_rech_7','day_of_last_rech_8']\n\nfor col in cols:\n    unseen[col] = pd.cut(unseen[col], [0,7,14,21,28,31], labels=['Week 1','Week 2','Week 3','Week 4','Week 5'])","6fbe3b1e":"# Plotting again to see last recharge distributions as per week of month\n\nn=1\nplt.figure(figsize=(20,7))\nplt.suptitle('Weekly Count Distribution of Last Recharge', fontsize=20)\nmonths = ['June','July','August']\n\nfor col in cols:\n    plt.subplot(1,len(cols),n)\n    sns.countplot(df[col], color='salmon')\n    plt.title(months[n-1])\n    n+=1\n    \nplt.show()","902c7b67":"# creating function\ndef Aug_vs_rest(col1,col2,col3):\n    return (df[[col1,col2]].mean(axis=1) >= df[col3]).astype(int)\n\n# ARPU\ndf['arpu67_8'] = Aug_vs_rest('arpu_6','arpu_7','arpu_8')\n\n# Total outgoing minutes\ndf['total_og67_8'] = Aug_vs_rest('total_og_mou_6','total_og_mou_7','total_og_mou_8')\n\n# Total incoming min\ndf['total_ic67_8'] = Aug_vs_rest('total_ic_mou_6','total_ic_mou_7','total_ic_mou_8')\n\n# Total recharge\ndf['tot_rech_amt67_8'] = Aug_vs_rest('total_rech_amt_6','total_rech_amt_7','total_rech_amt_8')\n\n# Max Recharge\ndf['max_rech_amt67_8'] = Aug_vs_rest('max_rech_amt_6','max_rech_amt_7','max_rech_amt_8')\n\n# mean of total outgoing vs incoming\ndf['avg_og_mou'] = df[['total_og_mou_6','total_og_mou_7','total_og_mou_8']].mean(axis=1)\ndf['avg_ic_mou'] = df[['total_ic_mou_6','total_ic_mou_7','total_ic_mou_8']].mean(axis=1)\n\n# comparing average outgoing is higher or lower than incoming\ndf['avgIC_>_avgOG'] = (df['avg_ic_mou'] >= df['avg_og_mou']).astype(int)","95b81bd8":"## For unseen data\n# creating function\ndef Aug_vs_rest(col1,col2,col3):\n    return (unseen[[col1,col2]].mean(axis=1) >= unseen[col3]).astype(int)\n\n# ARPU\nunseen['arpu67_8'] = Aug_vs_rest('arpu_6','arpu_7','arpu_8')\n\n# Total outgoing minutes\nunseen['total_og67_8'] = Aug_vs_rest('total_og_mou_6','total_og_mou_7','total_og_mou_8')\n\n# Total incoming min\nunseen['total_ic67_8'] = Aug_vs_rest('total_ic_mou_6','total_ic_mou_7','total_ic_mou_8')\n\n# Total recharge\nunseen['tot_rech_amt67_8'] = Aug_vs_rest('total_rech_amt_6','total_rech_amt_7','total_rech_amt_8')\n\n# Max Recharge\nunseen['max_rech_amt67_8'] = Aug_vs_rest('max_rech_amt_6','max_rech_amt_7','max_rech_amt_8')\n\n# mean of total outgoing vs incoming\nunseen['avg_og_mou'] = unseen[['total_og_mou_6','total_og_mou_7','total_og_mou_8']].mean(axis=1)\nunseen['avg_ic_mou'] = unseen[['total_ic_mou_6','total_ic_mou_7','total_ic_mou_8']].mean(axis=1)\n\n# comparing average outgoing is higher or lower than incoming\nunseen['avgIC_>_avgOG'] = (unseen['avg_ic_mou'] >= unseen['avg_og_mou']).astype(int)","6453310b":"# Plotting average outgoing and incoming to churn probability\nplt.figure(figsize=(20,10))\nplt.suptitle('Average outgoing and incoming to churn probability', fontsize=20)\nplt.subplot(2,1,1)\nsns.scatterplot(data=df, y='avg_og_mou',x=df.index, hue='churn_probability')\nplt.subplot(2,1,2)\nsns.scatterplot(data=df, y='avg_ic_mou',x=df.index, hue='churn_probability')\nplt.show()","78a56663":"# Changing datatype from category to object for ease of use\ndf[['day_of_last_rech_6','day_of_last_rech_7','day_of_last_rech_8']] = df[['day_of_last_rech_6','day_of_last_rech_7','day_of_last_rech_8']].astype('object')","a84c2104":"# Independent and dependent variable\nX=df.drop('churn_probability',1)\ny=df.churn_probability","4104b990":"# Train Test Split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","ece83c55":"# Separating numeric and object variables\n\nnum_col_df = X_train.select_dtypes(exclude='object').columns\nobj_col_df = X_train.select_dtypes(include='object').columns","56786a49":"# As per our observations in dataframe describe as well as EDA, it is best to cap the variables at 99 and 1 percentile as there are highly skewed outliers\n\nfor col in num_col_df:\n    percentiles_1_99 = X_train[col].quantile([0.01,0.99]).values\n    X_train[col] = np.clip(X_train[col], percentiles_1_99[0], percentiles_1_99[1])\n    \nfor col in num_col_df:\n    percentiles_1_99 = X_test[col].quantile([0.01,0.99]).values\n    X_test[col] = np.clip(X_test[col], percentiles_1_99[0], percentiles_1_99[1])","616a03a8":"# Categorical columns \ncategorical_cols = [col for col in X_train if X_train[col].dtype == \"object\"]\n\n# Numerical columns\nnumerical_cols = [col for col in X_train if X_train[col].dtype in ['int64', 'float64']]","76ec0152":"# Impute numerical variables\nimputer = SimpleImputer(strategy='median')\nX_train[numerical_cols]=imputer.fit_transform(X_train[numerical_cols])\nX_test[numerical_cols]=imputer.transform(X_test[numerical_cols])\nunseen[numerical_cols]=imputer.transform(unseen[numerical_cols])","eb29c4e9":"# Impute categorical variables with mode\nfor col in categorical_cols:\n    X_train[col].fillna(X_train[col].mode()[0],inplace=True)\n    X_test[col].fillna(X_test[col].mode()[0],inplace=True)\n    unseen[col].fillna(unseen[col].mode()[0],inplace=True)","460ca129":"X_train = pd.concat([X_train,pd.get_dummies(X_train[categorical_cols],drop_first=True)],axis=1)\nX_test = pd.concat([X_test,pd.get_dummies(X_test[categorical_cols])],axis=1)\nunseen = pd.concat([unseen,pd.get_dummies(unseen[categorical_cols])],axis=1)\n\nX_train = X_train.drop(columns=['day_of_last_rech_6','day_of_last_rech_7','day_of_last_rech_8'])\nX_test = X_test[X_train.columns]\nunseen = unseen[X_train.columns]","ebd5a87a":"X_train.shape,X_test.shape,unseen.shape","33e1ce0b":"# Define the logistic model\nlr = LogisticRegression(n_jobs=-1,random_state=0)\nscaler = StandardScaler()\npca = PCA(0.90)\n\npipe_lr = Pipeline(steps=[('scaler',scaler),\n                          ('pca',pca),\n                          ('model',lr)])\n\nparams = [{\"model__max_iter\": [200,500],\n           \"model__C\": np.logspace(0, 4, 10)}]\n\nsearch = GridSearchCV(pipe_lr,params,n_jobs=-1,cv=5,verbose=True)\n\nbest_model = search.fit(X_train,y_train)\n\nprint(\"Best parameter (CV score=%0.3f):\" % best_model.best_score_)\nprint(best_model.best_params_)\nprint(best_model.score(X_test,y_test))\nprint(best_model.best_estimator_)","d920568f":"best_model.best_estimator_","6758ecc5":"confusion_matrix(y_train, best_model.best_estimator_.predict(X_train))","7c6879ab":"confusion_matrix(y_test, best_model.best_estimator_.predict(X_test))","62f6964b":"precision_score(y_test, best_model.best_estimator_.predict(X_test))","9884b565":"recall_score(y_test, best_model.best_estimator_.predict(X_test))","4ed2335a":"roc_auc_score(y_test, best_model.best_estimator_.predict(X_test))","ce5f5fd1":"plot_roc_curve(best_model.best_estimator_,X_test, y_test)\nplt.show()","8d074d00":"# commented out for faster notebook runtime\n# # Define basic random forest model\n# rf = RandomForestClassifier(random_state=0,n_jobs=-1,verbose=1)\n\n# # Setting hyperparameters\n# params_rf = {'max_depth': [5,10,25],\n#              'max_features': [10,15,25],\n#              'n_estimators': [200,300]}\n\n# # model building with 4-fold cv\n# model_cv = GridSearchCV(estimator=rf, \n#                         param_grid=params_rf,\n#                         verbose=1,\n#                         n_jobs=-1,\n#                         return_train_score=True,\n#                         cv=4)\n\n# # Fitting the model with hyperparams and cv\n# model_cv.fit(X_train,y_train)","e6349598":"# #best score from models\n# model_cv.best_score_","a17fde88":"# # Build dataframe to see average test and train data to decide hyperparameters of final model\n# cv_df = pd.DataFrame(model_cv.cv_results_)\n# cv_df.sort_values(by='rank_test_score').head()","d460d9bd":"# Final model built after choosing the ideal hyperparameters from the dataframe cv_df\nfinal_model = RandomForestClassifier(random_state=0, n_jobs=-1, max_depth=10, max_features=25, oob_score=True, n_estimators=300)","f173fbd9":"final_model.fit(X_train,y_train)","5ef6b397":"# Out of bag score\nfinal_model.oob_score_","f5b5194a":"confusion_matrix(y_train, final_model.predict(X_train))","7da44e76":"confusion_matrix(y_test, final_model.predict(X_test))","bd963af8":"precision_score(y_test, final_model.predict(X_test))","fe073f83":"recall_score(y_test, final_model.predict(X_test))","aa4b8871":"roc_auc_score(y_test, final_model.predict(X_test))","6d6cf3ab":"plot_roc_curve(final_model,X_test, y_test)\nplt.show()","fcbee4cc":"# Create dataframe with features and their importance given by the model\nfeature_names = [cname for cname in X_train.columns]\nfeature_imp = final_model.feature_importances_\n\nfeature_importance = pd.DataFrame(feature_imp)\nfeature_importance.index = feature_names\nfeature_importance.columns = ['Importance']","8b7acfb9":"# Top 10 important features\nfeature_importance.sort_values(by='Importance',ascending=False).head(10)","17017ee2":"submission_data = unseen[X_train.columns]\nsubmission_data.shape","4ea8be1a":"unseen.head()","9a14c965":"unseen['churn_probability'] = final_model.predict(submission_data)\nunseen.reset_index(inplace=True)\noutput = unseen[['id','churn_probability']]\noutput.head()","8937d06b":"# output.to_csv('tel_churn_nandish_08dec.csv',index=False)","8d9cbf90":"**Inference:** For all 3 months, it can be observed that significantly higher counts of recharge are taking place in the last few days of the month, while almost negligible counts are seen during first few days.","a691707a":"# Visualizing Missing Values In The Dataset","bd1bccf9":"**Inference:** Very high skewness can be observed in all 3 months","46ef269c":"# Reading Datasets","71da8b24":"**Inference:** Very high values of 0 can be observed, followed by 1. Rest are negligible in all 3 months.","019d07b0":"**Inference:** Very high number of significant outliers can be observed for all variables with null values.","cb902901":"**Inference:** Lot more churns can be observed  when average outgoing is on the higher side compared to incoming","76f18180":"## Logistic Regression model with PCA","79503124":"# Problem Statement","448dbe70":"## Binning Days In Datetime Variables","065ee185":"# Preprocessing","ea5c01fd":"# Dataset Analysis","d9b702dc":"# Exploratory Data Analysis","19538852":"We will try to observe whether data in last month(8) is increasing or decreasing compared to average of previous two, for different variables","0e05f687":"**Inference:** Skewness can be seen in churns, with majority of churns happening under 1000 aon","3376be08":"**Note:** It can be observed that model #1 has better performance but it has comparatively overfitted the data, so we will choose model #2 for our final build.<br\/>\n**NB:** Keeping Verbose=1 because the time taken for model build is quite high.","dcfdf416":"## Imputation","281469a7":"# Submitting csv for predictions on unseen data","f5fc90e8":"**Inference:** \n* The most important feature that stands out, is total incoming minutes in the last month(August). Business should keep an eye for significant change in this for customers to watchout for churn possibility.\n* The second important feature is total outgoing for last month(August). So basically both imcoming and outgoing minutes of last month are very important to predict churn of the customer.\n* From top 10 features, 9 of them are from last month(August) which shows that the churn reaction is immediate by the customer in most cases, and not something that has built up over past few months.\n* ARPU, Total and Maximum recharge amounts for the last month are also very strong indicators of churn possibility and among the top 5 features.","bc2c030d":"In the telecom industry, customers are able to choose from multiple service providers and actively switch from one operator to another. In this highly competitive market, the telecommunications industry experiences an average of 15-25% annual churn rate. Given the fact that it costs 5-10 times more to acquire a new customer than to retain an existing one, customer retention has now become even more important than customer acquisition.\n\nFor many incumbent operators, retaining high profitable customers is the number one business\ngoal. To reduce customer churn, telecom companies need to predict which customers are at high risk of churn. In this project, you will analyze customer-level data of a leading telecom firm, build predictive models to identify customers at high risk of churn.\n\nIn this competition, your goal is to build a machine learning model that is able to predict churning customers based on the features provided for their usage.","eb5cb6f6":"## Create Dummies","2f69cba2":"**Inference:** Around 10% churn has been observed, at a ratio of 1:9","df1cde81":"## RandomForest Classifier Model\nTo learn about top important features and performance comparision","95a7712e":"# Train Test Split","94c39100":"# Important Features","c563ca7c":"# Build Models Using Pipeline","9f0320f3":"## Capping Outliers","20e45c06":"**Inference:** Extremely high outliers do not show churn, but other than that they are equally distributed among total recharge amount vs arpu, in all three months","e76f997d":"# Visualizing Outliers In Variables With Null","1cec8f3a":"**Inference:** Significant outliers are visible in ARPU for both churn and no churn","03b14405":"# Feature Engineering","90db4f86":"**Inference:** It can be seen that this model is better than the logistic regression model in all counts; accuracy, precision, and recall. So we will choose it as the final model for the churn prediction.","21be6298":"## New Variables"}}