{"cell_type":{"2dd22a7c":"code","637109d3":"code","34f19303":"code","fa9b732f":"code","db39aaff":"code","18e259f3":"code","8f5280ac":"code","080c552e":"code","dcb32735":"code","c42e077f":"code","59fa715f":"code","77b89f80":"code","438266c1":"code","cd997df9":"code","01962bd2":"code","9c55cc99":"code","c7d0998f":"code","677303bb":"code","8b0ce9f2":"code","5b3bc1bb":"code","c1f628b3":"code","dce523c6":"code","9df16915":"code","9590c6c3":"code","35ef7721":"code","e155ebf6":"code","0cfda3a1":"code","0baa849e":"code","368ce06e":"code","ca485403":"code","ade77d62":"code","9cf96054":"code","18fae762":"code","c70cf652":"code","73d70246":"code","600f8403":"code","c09122cf":"code","fbdf87ce":"code","0429f596":"code","85ebcabd":"code","49022a3f":"code","94562c26":"code","513c535a":"code","2f0fab4e":"code","33781f0c":"code","f3dfa4e3":"code","6d4fdf09":"code","38b95bc4":"code","3bb4ce0a":"code","19b31700":"code","ff3ed1d8":"code","6cc99e89":"code","79707905":"code","b1f90d3a":"code","6bf9f0f5":"markdown","2fba49a3":"markdown","ed6ae5ea":"markdown","edf63ee2":"markdown","e2d10597":"markdown","8696762b":"markdown","b54c91cc":"markdown","6eb4650c":"markdown","741a414b":"markdown","702d1a15":"markdown","8324537d":"markdown","c8d5f947":"markdown","0f4aaa87":"markdown","17747666":"markdown","a001d1d1":"markdown","5f8c7c62":"markdown","86d87755":"markdown","969f522d":"markdown","f49091fc":"markdown","5376b104":"markdown","85e7f363":"markdown","90ffd0ca":"markdown","5f59b398":"markdown","7914d10c":"markdown","3342bb62":"markdown","fff9cabc":"markdown","b7e8518c":"markdown","7c0ea0b5":"markdown","b4056a0f":"markdown","0e524ece":"markdown","79c3c2d3":"markdown","86933853":"markdown","04f5a6ca":"markdown","c0b5f196":"markdown","b373c388":"markdown","8fd0a4a1":"markdown","efbd698a":"markdown","34fa0fc8":"markdown","5b1381ad":"markdown","135f5948":"markdown","75b9154c":"markdown","c956c483":"markdown","5c92ca90":"markdown","49e5bc04":"markdown","3f9cdfee":"markdown","5f7e0548":"markdown","48c27d90":"markdown","6fdeb999":"markdown","bd73b753":"markdown","9036bfa4":"markdown","12de9651":"markdown","06f425d2":"markdown","a56f6e17":"markdown","d5817337":"markdown","d37d3b5b":"markdown","50f6ab37":"markdown","edfa2314":"markdown","003e16d0":"markdown","4818e853":"markdown","cfbc6b0d":"markdown","ddce8366":"markdown","ed721f56":"markdown","35313b98":"markdown","da7d9a40":"markdown","1e94c3b7":"markdown","ed70a5ba":"markdown","481d5679":"markdown","119cf8bd":"markdown","8885cfd2":"markdown"},"source":{"2dd22a7c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib as mpl\nfrom sklearn import preprocessing\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import tree\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import precision_recall_fscore_support as score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.datasets import load_digits\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import ShuffleSplit","637109d3":"# import and loading\ndf = pd.read_csv(\"..\/input\/StudentsPerformance.csv\")","34f19303":"# data cleaning\ndf.rename(columns={\"race\/ethnicity\": \"ethnicity\", \n\"parental level of education\":\"parent_education\",\n\"test preparation course\":\"preparation\",\n\"math score\":\"m_score\",\n\"reading score\": \"r_score\",\n\"writing score\": \"w_score\"}, inplace = True)\n\n# feature engineering on the data to visualize and solve the dataset more accurately\ndf['avg_score'] = (df['m_score'] + df['r_score'] + df['w_score'])\/3\ndf.head()","fa9b732f":"df.isnull().sum()","db39aaff":"# start data exploration\ncorr=df.corr()\ncorr","18e259f3":"ax = sns.heatmap(corr, annot=True, square=True, vmin=0, vmax=1, cmap=\"RdBu_r\")","8f5280ac":"df.describe()","080c552e":"sns.set(rc={'figure.figsize':(10,7)})\nsns.countplot(y = \"ethnicity\", data = df.sort_values(\"ethnicity\"))\nplt.show()","dcb32735":"sns.countplot(x = \"gender\", data = df)\nplt.show()","c42e077f":"sns.countplot(x = \"ethnicity\", hue=\"gender\", data = df.sort_values(\"ethnicity\"))\nplt.show()","59fa715f":"# visualizing the differnt parental education levels\nsns.countplot(x = \"parent_education\", data = df, order=df['parent_education'].value_counts().index)\nplt.xticks(rotation=45)\nplt.show()","77b89f80":"# Come varia la distribuzione dei voti al variare del livello di educazione dei genitori?\"\nsns.set(rc={'figure.figsize':(20,7)})\nfig, axs = plt.subplots(ncols=3)\n\nsns.violinplot(x = \"parent_education\", y = \"w_score\",  data = df, ax=axs[0])\nsns.violinplot(x = \"parent_education\", y = \"r_score\",  data = df, ax=axs[1])\nsns.violinplot(x = \"parent_education\", y = \"m_score\",  data = df, ax=axs[2])\nfor ax in axs:\n    ax.tick_params(labelrotation=45)\n    ax.tick_params(labelsize=12)\nplt.show()\n","438266c1":"# Come varia tra i gruppi la distribuzione dei voti?\nsns.set(rc={'figure.figsize':(18,6)})\nfig, axs = plt.subplots(ncols=3)\n\nsns.violinplot(x = \"ethnicity\", y = \"w_score\",  data = df.sort_values('ethnicity'), ax=axs[0])\nsns.violinplot(x = \"ethnicity\", y = \"r_score\",  data = df.sort_values('ethnicity'), ax=axs[1])\nsns.violinplot(x = \"ethnicity\", y = \"m_score\",  data = df.sort_values('ethnicity'), ax=axs[2])\nfor ax in axs:\n    ax.tick_params(labelrotation=45,labelsize=12)\nplt.show()","cd997df9":"# Come varia tra i generi la distribuzione dei voti?\nsns.set(rc={'figure.figsize':(18,6)})\nfig, axs = plt.subplots(ncols=3)\n\nsns.barplot(x = \"gender\", y = \"w_score\",  data = df, ax=axs[0])\nsns.barplot(x = \"gender\", y = \"r_score\",  data = df, ax=axs[1])\nsns.barplot(x = \"gender\", y = \"m_score\",  data = df, ax=axs[2])\n\nplt.show()","01962bd2":"# Come influisce il tipo di pasto sulla distribuzione dei voti?\nsns.set(rc={'figure.figsize':(18,6)})\nfig, axs = plt.subplots(ncols=3)\n\nsns.violinplot(x = \"lunch\", y = \"w_score\",  data = df, ax=axs[0])\nsns.violinplot(x = \"lunch\", y = \"r_score\",  data = df, ax=axs[1])\nsns.violinplot(x = \"lunch\", y = \"m_score\",  data = df, ax=axs[2])\n\nplt.show()","9c55cc99":"# Come influisce il tipo di pasto sulla distribuzione dei voti?\nsns.boxplot(x = \"ethnicity\", y = \"avg_score\",  data = df.sort_values(\"ethnicity\"), hue=\"lunch\")\n\nplt.show()","c7d0998f":"df.groupby(\"lunch\")[\"ethnicity\"].value_counts().unstack()","677303bb":"v = df.groupby(\"lunch\")[\"ethnicity\"].value_counts().unstack()\nlunch_ratio = v.div(v.sum(axis=\"rows\"), axis=\"columns\")\n\nfig, axs = plt.subplots(2, 3, figsize=(12,12))\nfig.suptitle('Percentuale tipo di lunch al variare del gruppo')\naxs[0, 0].pie(lunch_ratio[\"group A\"], labels=lunch_ratio.index.values, autopct='%1.1f%%')\naxs[0, 0].set_title('Group A')\naxs[0, 1].pie(lunch_ratio[\"group B\"], labels=lunch_ratio.index.values, autopct='%1.1f%%')\naxs[0, 1].set_title('Group B')\naxs[0, 2].pie(lunch_ratio[\"group C\"], labels=lunch_ratio.index.values, autopct='%1.1f%%')\naxs[0, 2].set_title('Group C')\naxs[1, 0].pie(lunch_ratio[\"group D\"], labels=lunch_ratio.index.values, autopct='%1.1f%%')\naxs[1, 0].set_title('Group D')\naxs[1, 1].pie(lunch_ratio[\"group E\"], labels=lunch_ratio.index.values, autopct='%1.1f%%')\naxs[1, 1].set_title('Group E')\naxs[1, 2].axis('off')\n\nplt.show()","8b0ce9f2":"df.groupby(\"lunch\")[\"parent_education\"].value_counts().unstack()","5b3bc1bb":"v = df.groupby(\"lunch\")[\"parent_education\"].value_counts().unstack()\nlunch_ratio = v.div(v.sum(axis=\"rows\"), axis=\"columns\")\n\nfig, axs = plt.subplots(2, 3, figsize=(12,12))\nfig.suptitle('Percentuale tipo di lunch al variare del titolo di studio dei genitori')\naxs[0, 0].pie(lunch_ratio[\"associate's degree\"], labels=lunch_ratio.index.values, autopct='%1.1f%%')\naxs[0, 0].set_title(\"associate's degree\")\naxs[0, 1].pie(lunch_ratio[\"bachelor's degree\"], labels=lunch_ratio.index.values, autopct='%1.1f%%')\naxs[0, 1].set_title(\"bachelor's degree\")\naxs[0, 2].pie(lunch_ratio[\"high school\"], labels=lunch_ratio.index.values, autopct='%1.1f%%')\naxs[0, 2].set_title(\"high school\")\naxs[1, 0].pie(lunch_ratio[\"master's degree\"], labels=lunch_ratio.index.values, autopct='%1.1f%%')\naxs[1, 0].set_title(\"master's degree\")\naxs[1, 1].pie(lunch_ratio[\"some college\"], labels=lunch_ratio.index.values, autopct='%1.1f%%')\naxs[1, 1].set_title(\"some college\")\naxs[1, 2].pie(lunch_ratio[\"some high school\"], labels=lunch_ratio.index.values, autopct='%1.1f%%')\naxs[1, 2].set_title(\"some high school\")\n\nplt.show()","c1f628b3":"plt.figure(figsize=(9,6))\nsns.countplot(x = \"preparation\", hue=\"gender\", data = df)\n\nplt.show()","dce523c6":"fig, axs = plt.subplots(ncols=3)\ncolors = [ \"amber\", \"windows blue\",\"dusty purple\",\"faded green\", ]\ncolor = sns.xkcd_palette(colors)\n\nsns.violinplot(x = \"preparation\", y = \"w_score\", hue=\"gender\", data = df, ax=axs[0])\nsns.violinplot(x = \"preparation\", y = \"r_score\",  hue=\"gender\", data = df, ax=axs[1],palette=color[2:])\nsns.violinplot(x = \"preparation\", y = \"m_score\",  hue=\"gender\", data = df, ax=axs[2], palette=color)\nplt.show()","9df16915":"fig, axs = plt.subplots(ncols=3)\ncolors = [ \"amber\", \"windows blue\",\"dusty purple\",\"faded green\", ]\ncolor = sns.xkcd_palette(colors)\n\nsns.violinplot(x = \"preparation\", y = \"w_score\",  data = df, ax=axs[0])\nsns.violinplot(x = \"preparation\", y = \"r_score\",  data = df, ax=axs[1],palette=color[2:])\nsns.violinplot(x = \"preparation\", y = \"m_score\", data = df, ax=axs[2], palette=color)\nplt.show()","9590c6c3":"sns.catplot(y=\"parent_education\", hue=\"ethnicity\", col=\"preparation\", data=df.sort_values('ethnicity'), kind=\"count\")\nplt.show()","35ef7721":"# Data to plot\nlabels = ['group A', 'group B', 'group C', 'group D','group E']\nsizes_r = df.groupby('ethnicity')['r_score'].mean().values\nsizes_w = df.groupby('ethnicity')['w_score'].mean().values\nsizes_m = df.groupby('ethnicity')['m_score'].mean().values\n \n# Plot\nsns.set(rc={'figure.figsize':(16,11)})\nfig, axs = plt.subplots(nrows=3)\nfig.suptitle('Voto medio per materia al variare del gruppo')\nax = sns.barplot(y=labels ,x=sizes_r,data=df, ax = axs[0])\nax.set(ylabel='ethnicity', xlabel='r_score mean')\nax = sns.barplot(y=labels ,x=sizes_w,data=df, ax = axs[1])\nax.set(ylabel='ethnicity', xlabel='w_score mean')\nax = sns.barplot(y=labels ,x=sizes_m,data=df, ax = axs[2])\nax.set(ylabel='ethnicity', xlabel='m_score mean')\nplt.show() \n","e155ebf6":"# Assigning grades to the grades according to the following criteria :\n# A: 90-100\n# B: 80-89\n# C: 70-79\n# D: 60-69\n# F: 0-59\n\ndef getgrade(score):\n  if(score >= 90):\n    return 'A'\n  if(score >= 80):\n    return 'B'\n  if(score >= 70):\n    return 'C'\n  if(score >= 60):\n    return 'D'\n  else:\n    return 'F'\n\ndf['grades_w'] = df.apply(lambda x: getgrade(x['w_score']), axis = 1 )\ndf['grades_r'] = df.apply(lambda x: getgrade(x['r_score']), axis = 1 )\ndf['grades_m'] = df.apply(lambda x: getgrade(x['m_score']), axis = 1 )\n\ndf.head(5)\n","0cfda3a1":"sns.set(rc={'figure.figsize':(18,6)})\nfig, axs = plt.subplots(ncols=3)\n\nsns.countplot(x = \"grades_w\", data = df.sort_values('grades_w'), ax=axs[0])\nsns.countplot(x = \"grades_r\", data = df.sort_values('grades_r'), ax=axs[1])\nsns.countplot(x = \"grades_m\", data = df.sort_values('grades_m'), ax=axs[2])\nplt.show()","0baa849e":"# setting a passing mark for the students to pass on the three subjects individually\npassmarks = 60\n\n# creating a new column pass_math, this column will tell us whether the students are pass or fail\ndf['pass_math'] = np.where(df['m_score']< passmarks, 'Fail', 'Pass')\ndf['pass_reading'] = np.where(df['r_score']< passmarks, 'Fail', 'Pass')\ndf['pass_writing'] = np.where(df['w_score']< passmarks, 'Fail', 'Pass')\n\n# checking which student is fail overall\n\ndf['status'] = df.apply(lambda x : 'Fail' if x['pass_math'] == 'Fail' or \n                           x['pass_reading'] == 'Fail' or x['pass_writing'] == 'Fail'\n                           else 'Pass', axis = 1)\n\nsns.set(rc={'figure.figsize':(10,7)})\nsns.countplot(x = \"status\", data = df)\nplt.show()","368ce06e":"sns.set(rc={'figure.figsize':(10,5)})\nsns.countplot(x = \"ethnicity\", hue=\"status\", data = df.sort_values(\"ethnicity\"))\nplt.show()","ca485403":"X_fair=pd.DataFrame(df[[\"gender\", \"ethnicity\", \"parent_education\", \"lunch\", \"preparation\",\"status\"]])\nX=pd.DataFrame(df[[\"gender\", \"ethnicity\", \"parent_education\", \"lunch\", \"preparation\"]])\nlabel=df[\"status\"]\nX.head(5)","ade77d62":"from sklearn.preprocessing import LabelEncoder\n\nX[\"gender\"]=LabelEncoder().fit_transform(X[\"gender\"])\nX[\"ethnicity\"]=LabelEncoder().fit_transform(X[\"ethnicity\"])\nX[\"parent_education\"]=LabelEncoder().fit_transform(X[\"parent_education\"])\nX[\"lunch\"]=LabelEncoder().fit_transform(X[\"lunch\"])\nX[\"preparation\"]=LabelEncoder().fit_transform(X[\"preparation\"])\n\nX.head(5)","9cf96054":"X_train, X_test, y_train, y_test =  train_test_split(X, label, test_size=0.2, random_state=0)\n\ndef plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"blue\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"orange\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"blue\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"orange\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt\n\nnames = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"AdaBoost\", \"Naive Bayes\", \"QDA\", \n    \"Random Forest\", \"Decision Tree\", \"Log Regression\"]\n\nnames = [\"Linear SVM\", \"Random Forest\", \"Log Regression\"]\n\nclassifiers = [\n    #KNeighborsClassifier(3),\n    SVC(kernel=\"linear\", C=1, probability=1, random_state=1),\n    #SVC(gamma=1, C=1, probability=1, random_state=1),\n    #AdaBoostClassifier(random_state=1),\n    #GaussianNB(),\n    #QuadraticDiscriminantAnalysis(), \n    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1, random_state=1),\n    #DecisionTreeClassifier(max_depth=5, random_state=1),\n    LogisticRegression(C=1, random_state=2, solver='lbfgs')]\n\n\nxx, yy = np.mgrid[-1:2:.01, -1:2:.01]\ngrid = np.c_[xx.ravel(), yy.ravel()]\ndecision_tree=0\nfi=0\nfi1=0\nconfusion_matrixs=[]\n\nfor name, model, ax in zip(names, classifiers, grid.flatten() ):\n    clf = model.fit(X_train, y_train) \n    a=clf.score(X_test, y_test)\n    #if name == \"Decision Tree\":\n        #decision_tree=clf\n        #fi=np.array(sorted(zip(X.columns[0:], clf.feature_importances_), key=lambda x: x[1], reverse=False))\n    if name == ('Random Forest'):\n        fi1=np.array(sorted(zip(X.columns[0:], clf.feature_importances_), key=lambda x: x[1], reverse=False))\n    print(name)\n    print(\"Score on test set: %0.3f\" % (a))\n    scores = cross_val_score(clf, X, label, cv=5)\n    print(\"Accuracy: %0.2f (+\/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n    predict = clf.predict(X_test)\t\n    cm=confusion_matrix(y_test, predict)\n    confusion_matrixs.append(cm)\n\n    cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n    plot_learning_curve(model, name, X, label, ylim=(0.1, 1.05), cv=cv, n_jobs=-1)\n    \n    \n    precision, recall, fscore, support = score(y_test, predict)\n    print('precision: {}'.format(precision))\n    print('recall: {}'.format(recall))\n    print('fscore: {}'.format(fscore))\n    print('support: {}'.format(support))\n    print('confusion matrix: ')\n    print(cm)\n    print()\n    print(\"____________________________________________\")    \n    \n ","18fae762":"fig=plt.figure(figsize=(10, 10))\nplt.bar(\n    x=fi1[:, 0],\n    height=fi1[:, 1],\n    tick_label=fi1[:, 0]\n)\nplt.ylabel('Feature importance')\nplt.xlabel('Feature')\nplt.title('Importanza feature nel Random Forest')\nplt.show()","c70cf652":"if (len(names) <= 3):\n    fig, axs = plt.subplots(nrows=1, ncols=3)\nelif ((len(names) > 3) & (len(names) <= 6)):\n    fig, axs = plt.subplots(nrows=2, ncols=3)\nelse:\n    fig, axs = plt.subplots(nrows=3,ncols=3)\n    \nfig.tight_layout(h_pad=5)\nsns.set(rc={'figure.figsize':(20,10)})\n\nfor i, cm , name in zip(enumerate(names), confusion_matrixs, names):\n    cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis] #normalizzo cm\n    \n    df_cm = pd.DataFrame(cm, index = ['fail', 'pass'],\n                  columns = ['fail', 'pass'])\n    \n    if(i[0]<3):\n        ax = sns.heatmap(df_cm, annot=True, square=True, vmin=0, vmax=1, cbar=False, cmap=\"RdBu_r\", ax=axs[i[0] % 3])\n    elif((i[0] >= 3) & (i[0]<6)):\n        ax = sns.heatmap(df_cm, annot=True, square=True, vmin=0, vmax=1, cbar=False, cmap=\"RdBu_r\", ax=axs[1,i[0] % 3])\n    else:\n        ax = sns.heatmap(df_cm, annot=True, square=True, vmin=0, vmax=1, cbar=False, cmap=\"RdBu_r\", ax=axs[2,i[0] % 3])\n    ax.set(title=name, ylabel='classe reale', xlabel='classe predetta')","73d70246":"predict = clf.predict(X)\ndf_predictions = pd.DataFrame(predict)\nX_fair[\"predicted\"] = df_predictions","600f8403":"X_fair.head(5)","c09122cf":"sns.set(rc={'figure.figsize':(18,6)})\nfig, axs = plt.subplots(ncols=2)\n\nsns.countplot(x = \"lunch\", hue=\"status\", data = X_fair, ax=axs[0]).set_ylim(0,630)\nsns.countplot(x = \"lunch\", hue=\"predicted\", data = X_fair, ax=axs[1]).set_ylim(0,630)\nplt.show()","fbdf87ce":"v = X_fair.groupby(\"status\")[\"lunch\"].value_counts().unstack()\nstatus_ratio = v.div(v.sum(axis=\"rows\"), axis=\"columns\")\nprint(status_ratio)","0429f596":"v = X_fair.groupby(\"predicted\")[\"lunch\"].value_counts().unstack()\npredicted_ratio = v.div(v.sum(axis=\"rows\"), axis=\"columns\")\nprint(predicted_ratio)","85ebcabd":"fig, axs = plt.subplots(2, 2, figsize=(12,12))\n\nfig.suptitle('Rapporto Fail\/Pass reale e predetto per \"lunch\" a confronto')\naxs[0, 0].pie(status_ratio[\"standard\"], labels=status_ratio.index.values, autopct='%1.1f%%')\naxs[0, 0].set_title('Standard Reale')\naxs[0, 1].pie(predicted_ratio[\"standard\"], labels=predicted_ratio.index.values, autopct='%1.1f%%')\naxs[0, 1].set_title('Standard Predetto')\naxs[1, 0].pie(status_ratio[\"free\/reduced\"], labels=status_ratio.index.values, autopct='%1.1f%%')\naxs[1, 0].set_title('Free\/Reduced Reale')\naxs[1, 1].pie(predicted_ratio[\"free\/reduced\"], labels=predicted_ratio.index.values, autopct='%1.1f%%')\naxs[1, 1].set_title('Free\/Reduced Predetto')\n\nplt.show()","49022a3f":"sns.set(rc={'figure.figsize':(18,6)})\nfig, axs = plt.subplots(ncols=2)\n\nsns.countplot(x = \"ethnicity\", hue=\"status\", data = X_fair.sort_values(\"ethnicity\"), ax=axs[0]).set_ylim(0,260)\nsns.countplot(x = \"ethnicity\", hue=\"predicted\", data = X_fair.sort_values(\"ethnicity\"), ax=axs[1]).set_ylim(0,260)\nplt.show()","94562c26":"v = X_fair.groupby(\"status\")[\"ethnicity\"].value_counts().unstack()\nstatus_ratio = v.div(v.sum(axis=\"rows\"), axis=\"columns\")\nprint(status_ratio)","513c535a":"v = X_fair.groupby(\"predicted\")[\"ethnicity\"].value_counts().unstack()\npredicted_ratio = v.div(v.sum(axis=\"rows\"), axis=\"columns\")\nprint(predicted_ratio)","2f0fab4e":"fig, axs = plt.subplots(3, 4, figsize=(12,12))\n\nfig.suptitle('Rapporto Fail\/Pass reale e predetto a confronto')\naxs[0, 0].pie(status_ratio[\"group A\"], labels=status_ratio.index.values, autopct='%1.1f%%')\naxs[0, 0].set_title('Group A Reale')\naxs[0, 1].pie(predicted_ratio[\"group A\"], labels=predicted_ratio.index.values, autopct='%1.1f%%')\naxs[0, 1].set_title('Group A Predetto')\naxs[0, 2].pie(status_ratio[\"group B\"], labels=status_ratio.index.values, autopct='%1.1f%%')\naxs[0, 2].set_title('Group B Reale')\naxs[0, 3].pie(predicted_ratio[\"group B\"], labels=predicted_ratio.index.values, autopct='%1.1f%%')\naxs[0, 3].set_title('Group B Predetto')\naxs[1, 0].pie(status_ratio[\"group C\"], labels=status_ratio.index.values, autopct='%1.1f%%')\naxs[1, 0].set_title('Group C Reale')\naxs[1, 1].pie(predicted_ratio[\"group C\"], labels=predicted_ratio.index.values, autopct='%1.1f%%')\naxs[1, 1].set_title('Group C Predetto')\naxs[1, 2].pie(status_ratio[\"group D\"], labels=status_ratio.index.values, autopct='%1.1f%%')\naxs[1, 2].set_title('Group D Reale')\naxs[1, 3].pie(predicted_ratio[\"group D\"], labels=predicted_ratio.index.values, autopct='%1.1f%%')\naxs[1, 3].set_title('Group D Predetto')\naxs[2, 0].pie(status_ratio[\"group E\"], labels=status_ratio.index.values, autopct='%1.1f%%')\naxs[2, 0].set_title('Group E Reale')\naxs[2, 1].pie(predicted_ratio[\"group E\"], labels=predicted_ratio.index.values, autopct='%1.1f%%')\naxs[2, 1].set_title('Group E Predetto')\naxs[2, 2].axis('off')\naxs[2, 3].axis('off')\n\nplt.show()","33781f0c":"sns.set(rc={'figure.figsize':(18,6)})\nfig, axs = plt.subplots(ncols=2)\n\nsns.countplot(x = \"ethnicity\", hue=\"predicted\", data = X_fair.sort_values(\"ethnicity\"), ax=axs[0])\nsns.countplot(x = \"lunch\", hue=\"predicted\", data = X_fair, ax=axs[1])\nplt.show()","f3dfa4e3":"# Y = 0\ny0_filter = X_fair[\"status\"] == \"Fail\"\n# Y = 1\ny1_filter = X_fair[\"status\"] == \"Pass\"\n# R = 0\nr0_filter = X_fair[\"predicted\"] == \"Fail\"\n# R = 1\nr1_filter = X_fair[\"predicted\"] == \"Pass\"\n\ndef falseRates(a_filter):\n    FP = X_fair[y0_filter & r1_filter & a_filter]\n    TN = X_fair[y0_filter & r0_filter & a_filter]\n    FN = X_fair[y1_filter & r0_filter & a_filter]\n    TP = X_fair[y1_filter & r1_filter & a_filter]\n    \n    FP_n = FP.shape[0]\n    FN_n = FN.shape[0]\n    TP_n = TP.shape[0]\n    TN_n = TN.shape[0]\n    \n    PPV = TP_n\/(TP_n+FP_n)\n    FPR = FP_n\/(FP_n + TN_n)\n    FNR = FN_n\/(FN_n + TP_n)\n\n    return PPV, FPR, FNR\n    \ndef positiveRates(a_filter):    \n    FP = X_fair[y0_filter & r1_filter & a_filter]\n    TP = X_fair[y1_filter & r1_filter & a_filter]\n    tot_F = X_fair[y0_filter & a_filter]\n    tot_T = X_fair[y1_filter & a_filter]\n    \n    FP_n = FP.shape[0]\n    TP_n = TP.shape[0]\n    tot_F_n = tot_F.shape[0]\n    tot_T_n = tot_T.shape[0]\n    \n    FP_per = FP_n\/tot_F_n\n    TP_per = TP_n\/tot_T_n\n\n    return FP_n, TP_n","6d4fdf09":"a_filter = X_fair[\"lunch\"] == \"standard\"\nb_filter = X_fair[\"lunch\"] == \"free\/reduced\"\n\na_FP_per, a_TP_per = positiveRates(a_filter)\nb_FP_per, b_TP_per = positiveRates(b_filter)\na_tot = X_fair[a_filter]\nb_tot = X_fair[b_filter]\n\nprint(\"Veri positivi, lunch 'standard': {0:d}\\nFalsi positivi, lunch 'standard': {1:d}\\nTotali, lunch 'standard': {2:d}\\n\".format(a_TP_per, a_FP_per, a_tot.shape[0]))\nprint(\"Veri positivi, lunch 'free\/reduced': {0:d}\\nFalsi positivi, lunch 'free\/reduced': {1:d}\\nTotali, lunch 'free\/reduced': {2:d}\".format(b_TP_per, b_FP_per, b_tot.shape[0]))","38b95bc4":"a_filter = X_fair[\"lunch\"] == \"standard\"\nb_filter = X_fair[\"lunch\"] == \"free\/reduced\"\n\na_PPV, a_FPR, a_FNR = falseRates(a_filter)\nb_PPV, b_FPR, b_FNR = falseRates(b_filter)\n\nprint(\"Valore predittivo positivo, lunch 'standard': {0:.2f}\\nValore predittivo positivo, lunch 'free\/reduced': {1:.2f}\\n\".format(a_PPV, b_PPV))\nprint(\"Tasso falsi positivi, lunch 'standard': {0:.2f}\\nTasso falsi positivi, lunch 'free\/reduced': {1:.2f}\\n\".format(a_FPR, b_FPR))\nprint(\"Tasso falsi negativi, lunch 'standard': {0:.2f}\\nTasso falsi negativi, lunch 'free\/reduced': {1:.2f}\\n\".format(a_FNR, b_FNR))","3bb4ce0a":"df_sep_lunch = pd.DataFrame(columns=['lunch', 'TP', 'FP', 'PPV', 'FPR', 'FNR', 'TPR'])\ndf_sep_lunch = df_sep_lunch.append({\n     \"lunch\": \"standard\",\n     \"TP\": a_TP_per,\n     \"FP\": a_FP_per,\n     \"PPV\": a_PPV,\n     \"FPR\": a_FPR,\n     \"FNR\": a_FNR,\n     \"TPR\": 1-a_FNR\n      }, ignore_index=True)\ndf_sep_lunch = df_sep_lunch.append({\n     \"lunch\": \"free\/reduced\",\n     \"TP\": b_TP_per,\n     \"FP\": b_FP_per,\n     \"PPV\": b_PPV,\n     \"FPR\": b_FPR,\n     \"FNR\": b_FNR,\n     \"TPR\": 1-b_FNR\n      }, ignore_index=True)","19b31700":"df_sep_lunch","ff3ed1d8":"a_filter = X_fair[\"ethnicity\"] == \"group A\"\nb_filter = X_fair[\"ethnicity\"] == \"group B\"\nc_filter = X_fair[\"ethnicity\"] == \"group C\"\nd_filter = X_fair[\"ethnicity\"] == \"group D\"\ne_filter = X_fair[\"ethnicity\"] == \"group E\"\n\na_FP_per, a_TP_per = positiveRates(a_filter)\nb_FP_per, b_TP_per = positiveRates(b_filter)\nc_FP_per, c_TP_per = positiveRates(c_filter)\nd_FP_per, d_TP_per = positiveRates(d_filter)\ne_FP_per, e_TP_per = positiveRates(e_filter)\n\na_tot = X_fair[a_filter]\nb_tot = X_fair[b_filter]\nc_tot = X_fair[c_filter]\nd_tot = X_fair[d_filter]\ne_tot = X_fair[e_filter]\n\nprint(\"Veri positivi, ethnicity 'group A': {0:d}\\nFalsi positivi, ethnicity 'group A': {1:d}\\nTotali, ethnicity 'group A': {2:d}\\n\".format(a_TP_per, a_FP_per, a_tot.shape[0]))\nprint(\"Veri positivi, ethnicity 'group B': {0:d}\\nFalsi positivi, ethnicity 'group B': {1:d}\\nTotali, ethnicity 'group B': {2:d}\\n\".format(b_TP_per, b_FP_per, b_tot.shape[0]))\nprint(\"Veri positivi, ethnicity 'group C': {0:d}\\nFalsi positivi, ethnicity 'group C': {1:d}\\nTotali, ethnicity 'group C': {2:d}\\n\".format(c_TP_per, c_FP_per, c_tot.shape[0]))\nprint(\"Veri positivi, ethnicity 'group D': {0:d}\\nFalsi positivi, ethnicity 'group D': {1:d}\\nTotali, ethnicity 'group D': {2:d}\\n\".format(d_TP_per, d_FP_per, d_tot.shape[0]))\nprint(\"Veri positivi, ethnicity 'group E': {0:d}\\nFalsi positivi, ethnicity 'group E': {1:d}\\nTotali, ethnicity 'group E': {2:d}\".format(e_TP_per, e_FP_per, e_tot.shape[0]))","6cc99e89":"a_filter = X_fair[\"ethnicity\"] == \"group A\"\nb_filter = X_fair[\"ethnicity\"] == \"group B\"\nc_filter = X_fair[\"ethnicity\"] == \"group C\"\nd_filter = X_fair[\"ethnicity\"] == \"group D\"\ne_filter = X_fair[\"ethnicity\"] == \"group E\"\n\nletters = [\"a\",\"b\",\"c\",\"d\",\"e\"]\n\na_PPV, a_FPR, a_FNR = falseRates(a_filter)\nb_PPV, b_FPR, b_FNR = falseRates(b_filter)\nc_PPV, c_FPR, c_FNR = falseRates(c_filter)\nd_PPV, d_FPR, d_FNR = falseRates(d_filter)\ne_PPV, e_FPR, e_FNR = falseRates(e_filter)\n\nprint(\"Valore predittivo positivo, ethnicity 'group A': {0:.2f}\\nValore predittivo positivo, ethnicity 'group B': {1:.2f}\\nValore predittivo positivo, ethnicity 'group C': {2:.2f}\\nValore predittivo positivo, ethnicity 'group D': {3:.2f}\\nValore predittivo positivo, ethnicity 'group E': {4:.2f}\\n\".format(a_PPV, b_PPV, c_PPV, d_PPV, e_PPV))\nprint(\"Tasso falsi positivi, ethnicity 'group A': {0:.2f}\\nTasso falsi positivi, ethnicity 'group B': {1:.2f}\\nTasso falsi positivi, ethnicity 'group C': {2:.2f}\\nTasso falsi positivi, ethnicity 'group D': {3:.2f}\\nTasso falsi positivi, ethnicity 'group E': {4:.2f}\\n\".format(a_FPR, b_FPR, c_FPR, d_FPR, e_FPR))\nprint(\"Tasso falsi negativi, ethnicity 'group A': {0:.2f}\\nTasso falsi negativi, ethnicity 'group B': {1:.2f}\\nTasso falsi negativi, ethnicity 'group C': {2:.2f}\\nTasso falsi negativi, ethnicity 'group D': {3:.2f}\\nTasso falsi negativi, ethnicity 'group E': {4:.2f}\\n\".format(a_FNR, b_FNR, c_FNR, d_FNR, e_FNR))","79707905":"df_sep_eth = pd.DataFrame(columns=['ethnicity', 'TP', 'FP', 'PPV', 'FPR', 'FNR', 'TPR'])\ndf_sep_eth = df_sep_eth.append({\n     \"ethnicity\": \"group A\",\n     \"TP\": a_TP_per,\n     \"FP\": a_FP_per,\n     \"PPV\": a_PPV,\n     \"FPR\": a_FPR,\n     \"FNR\": a_FNR,\n     \"TPR\": 1-a_FNR\n      }, ignore_index=True)\ndf_sep_eth = df_sep_eth.append({\n     \"ethnicity\": \"group B\",\n     \"TP\": b_TP_per,\n     \"FP\": b_FP_per,\n     \"PPV\": b_PPV,\n     \"FPR\": b_FPR,\n     \"FNR\": b_FNR,\n     \"TPR\": 1-b_FNR\n      }, ignore_index=True)\ndf_sep_eth = df_sep_eth.append({\n     \"ethnicity\": \"group C\",\n     \"TP\": c_TP_per,\n     \"FP\": c_FP_per,\n     \"PPV\": c_PPV,\n     \"FPR\": c_FPR,\n     \"FNR\": c_FNR,\n     \"TPR\": 1-c_FNR\n      }, ignore_index=True)\ndf_sep_eth = df_sep_eth.append({\n     \"ethnicity\": \"group D\",\n     \"TP\": d_TP_per,\n     \"FP\": d_FP_per,\n     \"PPV\": d_PPV,\n     \"FPR\": d_FPR,\n     \"FNR\": d_FNR,\n     \"TPR\": 1-d_FNR\n      }, ignore_index=True)\ndf_sep_eth = df_sep_eth.append({\n     \"ethnicity\": \"group E\",\n     \"TP\": e_TP_per,\n     \"FP\": e_FP_per,\n     \"PPV\": e_PPV,\n     \"FPR\": e_FPR,\n     \"FNR\": e_FNR,\n     \"TPR\": 1-e_FNR\n      }, ignore_index=True)","b1f90d3a":"df_sep_eth","6bf9f0f5":"Il gruppo di minoranza A sembra essere quello che soffre di pi\u00f9 l'influenza negativa del 'free\/reduced' lunch (la distanza dal centro del box, indice del suo valore medio, rispetto al suo margine superiore \u00e8 pi\u00f9 grande di tutte le altre).","2fba49a3":"### Numero di studenti per ogni genere:","ed6ae5ea":"### Studenti senza insufficienze divisi per gruppo etnico:","edf63ee2":"### Modifica del dataset di partenza con l'integrazione di alcune informazioni utili per ulteriori statistiche:\n* **grades**: una valutazione complessiva ricavata dalla media dei voti e basata sul sistema americano.\n\n   [ A: 90-100\n    B: 80-89\n    C: 70-79\n    D: 60-69\n    F: 0-59 ]\n* **status**: indica se lo studente ha superato tutte le materie (superando una certa soglia di voto scelta pari a 60, corrispondente ad una valutazione superiore ad \"F\").\n\nGli studenti che non hanno superato tutte le materie ottengono un \"Fail\" come valutazione finale.","e2d10597":"Per la classificazione si prende in considerazione un dataset ridotto, costituito solo da alcuni attributi del dataset di partenza, quali: \ngender, ethnicity, parent_education, lunch, preparation. \nCome etichetta per la classificazione viene usato l'attributo status. \nNon sono state considerate le grandezze r_score, w_score, m_score e grades_r, grades_w, grades_m poich\u00e8 \ndirettamente correlate con 'status'. ","8696762b":"Nell'analisi della correlazione non viene presa in considerazione la correlazione con l'attributo 'avg_score' essendo questo derivato matematicamente dagli altri tre punteggi. Si pu\u00f2 comunque notare un alto fattore di correlazione tra i tre punteggi, in particolar modo tra 'w_score' e 'r_score'. ","b54c91cc":"Si pu\u00f2 notare una distribuzione pressoch\u00e8 omogenea, con una piccola maggioranza nel gruppo 'female'. ","6eb4650c":"### Numero di studenti per ogni genere all'interno di ogni gruppo:","741a414b":"### Ripartizione dei pasti, intero o ridotto, a seconda dei diversi titoli di studio dei genitori:","702d1a15":"La medesima analisi viene ripetuta al variare dell'attributo sensibile *ethnicity*.","8324537d":" # Students Performance in Exams\n ## Data Impact Assessment - Tecnologie Digitali e Societa'\n ---\n ### Collaboratori (in ordine alfabetico):\n ##### Flavio Emanuele Cannavo'\n ##### Margheret Casaletto\n ##### Ambra Destino\n ##### Giuseppe Di Bartolomeo\n ##### Angelo Laudani\n  ","c8d5f947":"### Distribuzione dei voti a seconda del gruppo etnico:","0f4aaa87":"Il rapporto tra studenti con pasto \"standard\" e con pasto \"reduced\" \u00e8 circa uguale in tutti i gruppi, con l'eccezione del **gruppo E** che presenta una pi\u00f9 marcata predominanza di studenti con pasto \"standard\". Si pu\u00f2 dunque supporre che il **gruppo E** sia il pi\u00f9 benestante","17747666":"Il **gruppo C** \u00e8 quello pi\u00f9 numeroso, ma anche quello con il rapporto pi\u00f9 grande di presenza femminile.","a001d1d1":"La distribuzione dei gruppi \u00e8 abbastanza eterogenea e si possono individuare due **minoranze**, gruppo A e gruppo E, che sono rappresentate con un numero di elementi minore della met\u00e0 del gruppo predominante, gruppo C. ","5f8c7c62":"Si evince che soltanto poco pi\u00f9 di un terzo degli studenti, indipendentemente dal genere, completa la preparazione al test.","86d87755":"Gli studenti che assumono un pasto completo (si suppone dunque abbiano una situazione economica agiata) hanno una media dei voti sostanzialmente pi\u00f9 alta in tutte le materie.","969f522d":"Dopo aver correttamente codificato le varie classi del dataset si prosegue con la classificazione, eseguendo un processo di training e test su diversi tipi di classificatore:","f49091fc":"### Verifica della presenza di righe nulle:","5376b104":"# Abstract\n\n Il dataset di partenza contiene un totale di 1000 osservazioni con i seguenti attributi:\n * **gender**: male\/female\n * **race\/ethnicity**: cinque differenti gruppi (fittizi) - A,B,C,D,E\n * **parental level of education**:\n     masters, bachelors, associate, some college, high school, some high school (in ordine discendente, il \"some\" indica il non completamento degli studi)\n * **lunch**: standard\/free or reduced\n * **test preparation course**: none\/completed\n * **math score**\n * **reading score**\n * **writing score**\n \nL'obiettivo dell'analisi \u00e8 la verifica dell'omogeneit\u00e0 dei dati e l'utilizzo di criteri di equit\u00e0 per capire come la distribuzione originale del dataset, qualora affetta da bias intrinseci, possa influenzare i risultati ottenuti dai modelli di apprendimento automatico.\n\n Viene verificato se i gruppi etnici rappresentati nel dataset sono distribuiti in modo omogeneo per etnia e genere, ovvero se ciascun gruppo all'interno del dataset viene rappresentato da un numero di individui equiparabile.\n\nUlteriore attenzione viene rivolta all'osservazione dell'attributo \"lunch\", in quanto si rivela indice di una condizione sociale particolare. Infatti, gli studenti possono usufruire di pasti gratis o ridotti attraverso la partecipazione a cosiddetti *Federal Assistance Programs*  o in base alla loro condizione di senza tetto, immigrati, rifugiati, o in affidamento. A questi casi particolari inoltre si aggiungono il reddito familiare e la grandezza della famiglia (https:\/\/www.fns.usda.gov\/nslp\/nslp-fact-sheet). \n     \nSi verifica inoltre come impattino sui risultati finali il genere, l'educazione dei genitori, e il completamento della preparazione al test osservando la correlazione tra  gli attributi.\n\nL'analisi si conclude, grazie all'applicazione dei criteri di sufficienza e di separazione, individuando la presenza di fattori di rischio legati agli attributi sensibili ethnicity e lunch, che inducono il classificatore ad un alto tasso di predizioni erronee.\n\n---\n\n\n","85e7f363":"### Correlazione delle features numeriche:","90ffd0ca":"Anche in questo caso la variabile target presenta un andamento estremamente eterogeneo al variare dell'attributo sensibile nel dataset di partenza, ed il classificatore in tutti quanti i gruppi incorpora questa sproporzione accentuandola notevolmente.\n\nLa conclusione che ne deriva \u00e8 che il criterio di sufficienza **non \u00e8 rispettato**.","5f59b398":"Effettuando una separazione per gruppo etnico e per livello di educazione dei genitori si ottengono alcune distribuzioni diverse da quella di partenza. \nIn questa analisi si definisce una distribuzione in **controtendenza**, rispetto alla distribuzione generale esaminata in precedenza, se:\n>il numero di studenti che completano il test di preparazione \u00e8 uguale (o superiore) a quello degli studenti che non completano il test di preparazione\n\nNel gruppo A\n* **Tutti i ragazzi** figli di laureati magistrali **decidono di non prepararsi al test**.\n\nNel gruppo B\n* Sebbene i figli di laureati triennali, che per la maggior parte preferiscono non prepararsi, abbiano all'incirca gli stessi risultati (poco inferiori) dei **figli di laureati magistrali**, questi ultimi sono in **controtendenza**.\n\n* Nei restanti livelli di istruzione, la situazione rispecchia quella generale, ma c'e' un'ulteriore anomalia tra **i figli di persone che non hanno completato gli studi** (*some high school*), infatti anche questi sono in **controtendenza**.\n\nNel gruppo C\n* **Controtendenza** dei ragazzi figli di **laureati triennali**.\n* Tra i figli di **laureati magistrali**, seppur non vi sia controtendenza, \u00e8 interessante notare un equilibiro maggiore rispetto all'andamento generale.\n\nNel gruppo D\n* Rispecchia l'andamento generale senza particolari anomalie.\n\nNel gruppo E\n* **Controtendenza** dei ragazzi figli di **laureati triennali**, i quali **per la maggior parte decidono di prepararsi al test**.\n* **Controtendenza** dei ragazzi figli di genitori che **non hanno completato gli studi**.\n* Seppur non vi sia controtendenza, \u00e8 presente un maggiore equilibrio nella scelta dei ragazzi **figli di genitori con diploma associato**.  ","7914d10c":"Anche in questo caso viene calcolato il valore di *veri positivi* e *falsi positivi* per i gruppi formati dall'attributo sensibile, questa volta *ethnicity*.","3342bb62":"### Numero studenti che non presentano valutazioni insufficienti:\nGli studenti con esito \"Pass\" hanno ottenuto una valutazione superiore ad F (insufficienza) in tutte e tre le materie.","fff9cabc":"# 4. Criterio Separazione\n    P{R = 1 | Y = 1, A = a} = P{R = 1 | Y = 1, A = b}\n    P{R = 1 | Y = 0, A = a} = P{R = 1 | Y = 0, A = b}\nIl criterio di separazione impone un'uguaglianza tra i tassi di veri positivi e di falsi positivi al variare dell'attributo sensibile. Impone un'equit\u00e0 dei tassi di errore.\n\nAnche in questo caso gli attributi sensibili che vengono presi in considerazione sono: **ethnicity** e **lunch**.","b7e8518c":"La feature di maggiore rilevanza, nel caso del \"Random Forest\", rimane 'lunch' seguita da 'ethnicity'. L'attributo 'gender' sembra non avere alcuna rilevanza nel decisore.","7c0ea0b5":"### Ripartizione di studenti con pasto intero o ridotto all'interno dei vari gruppi:","b4056a0f":"Il **gruppo A** \u00e8 l'unico con un numero di esiti negativi maggiore rispetto a quelli positivi. \nIl **gruppo E** \u00e8 invece quello con il pi\u00f9 alto rapporto di promossi rispetto a bocciati.","0e524ece":"Il primo grafico mette in luce che il completamento della preparazione per affrontare i test permette di ottenere risultati migliori nelle prove (circa 5-10 punti in pi\u00f9) rispetto a chi non li completa, indipendentemente dal genere.\n\nPer completezza \u00e8 stato rappresentato anche un grafico che fa riferimento alla preparazione al test in base al punteggio ottenuto, senza distinzione di genere. In esso vengono confermati gli stessi risultati.","79c3c2d3":"### Si osservi il dataset dopo qualche piccola modifica:","86933853":"### Numero di ragazzi e ragazze che decidono di completare il test di preparazione:","04f5a6ca":"<a id='p4'><\/a>","c0b5f196":"Si considerino ora le matrici di confusione dei vari classificatori utilizzati.","b373c388":"Il grafico rappresenta il punteggio medio per ogni materia, tra i vari individui suddivisi per genere. Le donne vengono superate dagli uomini solo in matematica.","8fd0a4a1":"Al dataframe viene aggiunto l'esito del classificatore per ogni elemento, al fine di poter effettuare una pi\u00f9 agevole valutazione dei paramentri di *\"fairness\"*.","efbd698a":"<a id='p2'><\/a>","34fa0fc8":"Il Data Impact Assessment eseguito, seppur con diversi limiti quali l'esiguo numero di dati disponibili e il conseguente utilizzo di classificatori con un test score non elevato, ha messo in luce alcune criticit\u00e0. \n\nUn classificatore (e dunque una scelta quale *\"la possibilit\u00e0 di avere o meno un voto sufficiente in tutte le materie\"*) basato sui valori forniti da un dataset di questo tipo \u00e8 fortemente influenzato dagli attributi **ethnicity** e **lunch**.\n\nL'attributo sensibile *gender*, come dimostrato dall'analisi e dall'importanza riservata a questa feature nel classificatore, non ha un impatto discriminatorio su quest'ultimo (il numero di studenti maschi e femmine \u00e8 circa uguale e con una distribuzione simile all'interno dei vari gruppi etnici, non andando ad influenzare i voti conseguiti nelle materie). Un discorso simile pu\u00f2 essere fatto per *parent education*.  \n  L'attributo *preparation* ha invece un impatto leggermente pi\u00f9 significativo sul classificatore, dovuto a come il completamento di un corso di preparazione comporti un miglioramento del punteggio in tutte le materie, ovvero un risultato coerente ed auspicabile.\n\nSe vengono presi in considerazione gli attributi *ethnicity* e *lunch* (con quest'ultimo legato ad eventuali agevolazioni sui pasti a mensa, da considerare come una sorta di indicatore economico della famiglia dello studente) l'equit\u00e0 del classificatore rischia di essere seriamente compromessa. Il numero considerevolmente diverso di studenti all'interno dei vari gruppi, i differenti risultati conseguiti in termini di voto e risultato, portano ad una classificazione che non rispetta n\u00e9 il criterio di sufficienza n\u00e9 quello di separazione. I tassi di falsi positivi e negativi sono estremamente variabili e il classificatore sembra inglobare totalmente le tendenze della maggioranza, accentuando qualsiasi sproporzione presente nel dataset di partenza.   \n  Uno studente brillante appartenente ad un gruppo etnico di minoranza e con difficolt\u00e0 economiche, che possono dare diritto alla modalit\u00e0 di pasto *\"free\/reduced\"*, avr\u00e0 elevate possibilit\u00e0 di venir erroneamente classificato con esito *\"Fail\"*.","5b1381ad":"### Distribuzione dei voti al variare del livello di educazione dei genitori:","135f5948":"Calcolo dei valori *veri positivi* e *falsi positivi* per i due gruppi formati dall'attributo sensibile.","75b9154c":"I tassi di falsi positivi e falsi negativi sono molto variabili anche all'interno dei vari gruppi dell'attributo sensibile *ethnicity*.","c956c483":"Vengono riproposti i grafici che mostrano l'esito del classificatore, *Pass* o *Fail*, per entrambi gli attributi sensibili considerati.","5c92ca90":"### Statistiche riassuntive riguardo le features numeriche:","49e5bc04":"Il **gruppo E** presenta valutazioni migliori degli altri.","3f9cdfee":"# 1. Analisi Esplorativa","5f7e0548":"La distribuzione dei voti \u00e8 circa uguale in *writing* e *reading*. Invece *mathematic* presenta dei voti tendenzialmente peggiori.","48c27d90":"Osservando i valori percentuali della variabile target, al variare dell'attributo sensibile, si pu\u00f2 notare come questi non siano bilanciati nel dataset di partenza, e questa sproporzione viene notevolmente accentuata dal classificatore.","6fdeb999":"<a id='p6'><\/a>","bd73b753":"I figli dei laureati hanno tendenzialmente punteggi migliori.","9036bfa4":"# 2. Classificazione","12de9651":"<a id='p3'><\/a>","06f425d2":"### Score ottenuti nelle varie materie:\nLe materie sono tre: *reading*, *writing* e *mathematic*.","a56f6e17":"<a id='p5'><\/a>","d5817337":"### Numero di studenti per ogni gruppo:","d37d3b5b":"### Numero di studenti in base alla *\"Parental Education\"*:","50f6ab37":"### Relazione tra preparazione ai test e punteggi conseguiti:\n\nNel primo grafico si tiene in considerazione anche il genere. ","edfa2314":"# 3. Criterio Sufficienza\n    P{Y = 1 | R = r, A = a} = P{Y = 1 | R = r, A = b}\nIl criterio di sufficienza implica che sia sufficiente il punteggio R del classificatore per prevedere la variabile target Y (*Pass* o *Fail*), l\u2019attributo sensibile non serve nel modello. \n\nEssendo un caso di classificazione binaria, *Pass* o *Fail*, il criterio di sufficienza implica dunque l\u2019equit\u00e0 di valori predittivi positivi\/negativi in tutti i gruppi.\n\nGli attributi sensibili che vengono presi in considerazione, vista la loro importanza nella decisione del classificatore, sono: **ethnicity** e **lunch**.","003e16d0":"<h1>Sommario<span class=\"tocSkip\"><\/span><\/h1><br>\n<div class=\"toc\">\n    <ul class=\"toc-item\">\n    <li><span><a href=\"#p1\" >Abstract<\/a><\/span><\/li>\n    <li><span><a href=\"#p2\" ><span class=\"toc-item-num\">1&nbsp;&nbsp;<\/span>Analisi esplorativa<\/a><\/span><\/li>\n    <li><span><a href=\"#p3\" ><span class=\"toc-item-num\">2&nbsp;&nbsp;<\/span>Classificazione<\/a><\/span><\/li>\n    <li><span><a href=\"#p4\" ><span class=\"toc-item-num\">3&nbsp;&nbsp;<\/span>Criterio Sufficienza<\/a><\/span><\/li>\n    <li><span><a href=\"#p5\" ><span class=\"toc-item-num\">4&nbsp;&nbsp;<\/span>Criterio Separazione<\/a><\/span><\/li>\n    <li><span><a href=\"#p6\" ><span class=\"toc-item-num\">5&nbsp;&nbsp;<\/span>Fattori di Rischio e Conclusioni<\/a><\/span><\/li>\n    <\/ul>\n<\/div>","4818e853":"<a id='p1'><\/a>","cfbc6b0d":"### Relazione tra il tipo di pasto e distribuzione voti:","ddce8366":"### Relazione tra il tipo di pasto e media dei voti al variare del gruppo:","ed721f56":"Il rapporto rimane pressoch\u00e9 uguale al variare del livello d'istruzione dei genitori. Interessante notare come siano i figli di genitori con \"master's degree\" ad essere quelli con il pi\u00f9 alto numero di pasto \"reduced\" rispetto a \"standard\" nonostante il pi\u00f9 elevato livello d'istruzione da parte dei genitori (tale anomalia potrebbe essere legata al basso numero di osservazioni per questa specifica categoria).","35313b98":"I classificatori utilizzati, di cui viene visualizzato un grafico che mostra il relativo punteggio \"score\" ottenuto in fase di training e di cross-validation, sono: *SVM Lineare*, *Random Forest* e *Logistic Regression*.\n\nL'accuratezza dei classificatori si attesta intorno al **63%**","da7d9a40":"Il grafico a sinistra mostra i reali valori della variabile target *status* al variare dell'attributo sensibile *lunch* (ovvero tipo di pasto), il grafico a destra riporta invece l'esito del classificatore, con i valori della variabile target predetti *predicted*.","1e94c3b7":"# 5. Fattori di Rischio e Conclusioni","ed70a5ba":"### Distribuzione dei voti ottenuti nelle varie materie:","481d5679":"### Relazione tra 'Parent Education' e preparazione al test a seconda del gruppo etnico:","119cf8bd":"### Distribuzione dei voti al variare del genere:","8885cfd2":"Si pu\u00f2 notare un *valore predittivo positivo* migliore del caso di lunch \"standard\". Per la classe lunch \"standard\" si pu\u00f2 inoltre notare un valore estremamente alto nel tasso di falsi positivi, ovvero il numero di casi negativi classificati incorrettamente come positivi \u00e8 quasi della totalit\u00e0. Lunch \"standard\" presenta anche un comportamento estremo nel tasso di falsi negativi, che \u00e8 quasi nullo, implicando un elevato tasso di veri positivi (FNR = 1 -TPR), ovvero quasi tutti i casi con valore positivo vengono classificati correttamente."}}