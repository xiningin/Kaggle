{"cell_type":{"54ce5f0e":"code","c22c73e1":"code","c0cc49be":"code","0dd3e897":"code","089908f3":"code","ea227b74":"code","58c73d4d":"code","466b7f18":"code","badb0eae":"code","f7545530":"code","5f434618":"code","47462ee1":"code","fc662288":"code","b42c99a3":"code","c62f0032":"code","a658f621":"code","a43cec50":"code","d1d3dc79":"code","1cf5f175":"code","23def74a":"code","abd62638":"code","a923745b":"code","7a8e062e":"code","4a8da652":"code","355c1c0d":"code","017da9fe":"code","bcb7e041":"code","fc8b5b68":"code","8d77aa77":"code","112b383b":"code","624827bb":"code","a57335cc":"code","400a1749":"markdown","a6feece2":"markdown","f2be2d0e":"markdown","cb4e9b7b":"markdown","fd397daf":"markdown","7dd4ca09":"markdown","de3948c2":"markdown","bb3d7296":"markdown"},"source":{"54ce5f0e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\n\nimport random\n\nimport cv2 as cv","c22c73e1":"train_csv_path: str = \"..\/input\/digit-recognizer\/train.csv\"\n\ndata: pd.DataFrame = pd.read_csv(train_csv_path)\ndata.info()","c0cc49be":"data.head()","0dd3e897":"X_train: np.ndarray = data.drop('label', axis=1).to_numpy()\ny_train: np.ndarray = data['label'].to_numpy()","089908f3":"# create sub plot for each digit\nfig, ax = plt.subplots(2,5, figsize=(7,4))\n# loop over each subplot to add its digit\nfor i, ax in enumerate(ax.flatten()):\n    # find index for image with the corresponding digit\n    img_idx: int = np.argwhere(y_train == i)[0]\n    # get the image and reshape to 28X28\n    img: np.ndarray = np.reshape(X_train[img_idx], (28, 28))\n    # plot digit image\n    ax.imshow(img, cmap=\"gray_r\")\n    # add digit label\n    ax.set_title(f\"Label: {i}\")\n    # remove gridlines\n    ax.grid(False)\n# add title to the plot\nfig.suptitle(\"MNIST Images Sample And Their Labels\")\n# adjust the padding between and around subplots\nfig.tight_layout()\n# show plot\nplt.show()","ea227b74":"plt.figure(figsize = (10,8))\nA = np.array(data.iloc[259, 1:]) # 139\n\nB = np.reshape(A, (28, 28))\n\nplt.imshow(B, cmap='gray');","58c73d4d":"plt.figure(figsize = (10,8))\n\nkernel = (3, 3)\nB = np.array(B)\nc = B.astype('uint8')\n\ndst = cv.GaussianBlur(c, kernel ,cv.BORDER_DEFAULT)\n\n\nplt.imshow(dst, cmap='gray');","466b7f18":"from skimage.feature import hog\nfrom skimage import exposure\n\ndef imgHOG(img):\n  image = img\n\n  resized_img = np.resize(image, (28,28)) \n\n  #print(resized_img.shape)\n\n  fd, hog_image = hog(resized_img, orientations=8, pixels_per_cell=(8, 8),\n                      cells_per_block=(2, 2), visualize=True)\n\n  # Rescale histogram for better display\n  fd = exposure.rescale_intensity(fd, in_range=(0, 10))\n\n  return fd","badb0eae":"hogimg = imgHOG(dst)\nplt.hist(hogimg);","f7545530":"def apply_IMP_techniques(data):\n  newConvertedData = []\n\n  for row in range(data.shape[0]):\n    \n    A = np.array(data.iloc[row])\n\n    B = np.reshape(A, (28, 28))\n\n    kernel = (3, 3)\n\n    B = np.array(B)\n    c = B.astype('uint8')\n\n    dst = cv.GaussianBlur(c, kernel ,cv.BORDER_DEFAULT)\n\n    hogimg = imgHOG(dst)\n    \n    d = hogimg.flatten();\n\n    result = d.flatten()\n\n    newConvertedData.append(result)\n\n  return newConvertedData","5f434618":"data = data.sample(frac=1)\n\nX = data.drop('label', axis = 1)\ny = data['label']\n\nX.shape, y.shape","47462ee1":"newData = pd.DataFrame(apply_IMP_techniques(X))","fc662288":"newData.head()","b42c99a3":"X_train_valid = newData.iloc[:40000]\ny_train_valid = y.iloc[:40000]\n\nX_test = newData.iloc[40000:]\ny_test = y.iloc[40000:]\n\nX_train_valid.shape, y_train_valid.shape, X_test.shape, y_test.shape","c62f0032":"import tensorflow as tf\ntf.__version__","a658f621":"from sklearn.model_selection import train_test_split\n\ntf.random.set_seed(42)\n\nX_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size=0.2, random_state=42)\n\nX_train.shape, X_valid.shape, y_train.shape, y_valid.shape","a43cec50":"# let's build a model to find patterns in it\n\n# Set random seed\ntf.random.set_seed(42)\n\n# 1. Create a model\nmodel_1 = tf.keras.Sequential([\n            tf.keras.layers.Dense(128, activation='relu'),\n           tf.keras.layers.Dense(256, activation='relu'),\n           tf.keras.layers.Dense(80, activation='relu'),\n           tf.keras.layers.Dense(150, activation='relu'),\n           tf.keras.layers.Dense(60, activation='relu'),\n           tf.keras.layers.Dense(10, activation='softmax')\n])\n\n# 2. Comile the model\nmodel_1.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n                 optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n                 metrics=['accuracy'])\n\n# 3. Fit the model\nnorm_history = model_1.fit(X_train, \n                                tf.one_hot(y_train, depth=10), \n                                epochs=200,\n                                verbose = 1,\n                                validation_data=(X_valid, tf.one_hot(y_valid, depth=10)))","d1d3dc79":"plt.plot(norm_history.history['accuracy'], label='accuracy')\nplt.plot(norm_history.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.6, 1.1])\nplt.legend(loc='lower right');","1cf5f175":"plt.plot(norm_history.history['loss'], label='loss')\nplt.plot(norm_history.history['val_loss'], label = 'val_loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.ylim([0.0, 1])\nplt.legend(loc='upper right');","23def74a":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\nplt.figure(figsize=(15, 10))\nsns.heatmap(confusion_matrix(y_true=y_test, \n                 y_pred=model_1.predict(X_test).argmax(axis=1)), annot=True,\n                 fmt=\"d\");","abd62638":"model_1.evaluate(X_test, tf.one_hot(y_test, depth=10))[1] * 100","a923745b":"model_1.summary()","7a8e062e":"# Let's check out a way of viewing our deep learning models\nfrom tensorflow.keras.utils import plot_model\n\n# See the inputs and outputs of each layer\nplot_model(model_1, show_shapes=True)","4a8da652":"test_csv_path: str = \"..\/input\/digit-recognizer\/test.csv\"\n    \ntestData = pd.read_csv(test_csv_path)","355c1c0d":"testData.info()","017da9fe":"testData.head()","bcb7e041":"testDataIMP = pd.DataFrame(apply_IMP_techniques(testData))","fc8b5b68":"testDataIMP.head()","8d77aa77":"y_pred = model_1.predict(testDataIMP).argmax(axis=1)","112b383b":"fig, axes = plt.subplots(4, 8, figsize=(15, 8),\n                         subplot_kw={'xticks':[], 'yticks':[]},\n                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n\nrandnums= np.random.randint(0 ,len(testData),32)\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(np.reshape(np.array(testData.iloc[randnums[i]]), (28, 28)), cmap='binary', interpolation='nearest')\n    ax.text(0.85, 0.85, str(y_pred[randnums[i]]),\n            transform=ax.transAxes,\n            fontsize=16,\n            color='green'\n           )","624827bb":"submission_df = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/sample_submission.csv\")\nsubmission_df['Label'] = y_pred\nsubmission_df.to_csv('submission.csv', index=False)","a57335cc":"submission_df","400a1749":"## Mustafa Mohammed Kataa\n# Import Packages\nLets load all the needed packages for this notebook:","a6feece2":"# Split labels and pixels\nLet's create variables for the pixels and the labels we want to predict:","f2be2d0e":"# Plot a Single Sample for each Digit\nLet's plot a single sample of each digit as the original image:","cb4e9b7b":"# Image processing techniques","fd397daf":"# Quick Look at the Data\u00b6\nLet\u2019s take a look at the top five rows:\n","7dd4ca09":"# The Dataset\nFor this notebook we will use the Digit Recognizer competition dataset.\n\nLet's define the path to the dataset:","de3948c2":"Test Data 'Without labels'","bb3d7296":"# Import TensorFlow"}}