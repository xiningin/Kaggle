{"cell_type":{"2aa5d8fd":"code","c3243a03":"code","8eedf365":"code","3ea81d67":"code","4028d81d":"code","16adf921":"code","ba319ff2":"code","821acd86":"code","5e5e199c":"code","a759205a":"code","68598229":"code","54574b0f":"code","7baa5d52":"code","d459c8a9":"code","f3357bbd":"code","9a9f1f29":"code","0242398a":"code","de73a3e0":"code","ca7973c5":"code","275eda51":"code","5181f640":"code","a8d15c6a":"code","4d88d84c":"code","78e07926":"code","be2d23d0":"code","11cf3187":"code","01b572f7":"code","6f0fc8f4":"code","48ea4df1":"markdown","23f0ff39":"markdown","178ac496":"markdown","2151b2fe":"markdown","adeacc1e":"markdown","648caa38":"markdown","07051739":"markdown","4f3af45e":"markdown","9c439b03":"markdown","cad1be11":"markdown","23889a4e":"markdown","9b526697":"markdown","3148fed7":"markdown","8a899838":"markdown","98d9c294":"markdown","798c1e90":"markdown","15104a07":"markdown","10adef4b":"markdown","43e81a7e":"markdown","d56f1a69":"markdown","3a574324":"markdown","d7555ff2":"markdown","ed08f0dc":"markdown","c2c13d21":"markdown","b017e3e4":"markdown","e289f049":"markdown"},"source":{"2aa5d8fd":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport re\nsns.set_style('darkgrid')","c3243a03":"#reading the data\ndf = pd.read_csv('..\/input\/sms-spam-collection-dataset\/spam.csv',encoding='latin1')\n\n#printing data information\ndf.info()","8eedf365":"#Exploring some parts of the data where messages are found in Unnamed:3 and Unnamed:4 columns.\n\ndf[df.columns.drop(['v1','v2'])].dropna(how='all').head(10)","3ea81d67":"df.loc[df['v1'] == 'spam',df.columns.drop(['v1','v2'])].dropna()","4028d81d":"#Assigning label ham to messages in Unnamed: 2, Unnamed: 3, Unnamed: 4 and concatenating them with v2\ntemp1 = df[['v2','v1']]\n\ntemp2 = df['Unnamed: 2'].to_frame()\ntemp2.loc[:,'v1'] = 'ham'\ntemp2 = temp2.rename(columns={'Unnamed: 2':'v2'})\n\ntemp3 = df['Unnamed: 3'].to_frame()\ntemp3.loc[:,'v1'] = 'ham'\ntemp3 = temp3.rename(columns={'Unnamed: 3':'v2'})\n\ntemp4 = df['Unnamed: 4'].to_frame()\ntemp4.loc[:,'v1'] = 'ham'\ntemp4 = temp4.rename(columns={'Unnamed: 4':'v2'})\n\ndf = pd.concat([temp1,temp2,temp3,temp4],axis=0).dropna().reindex(columns=['v1','v2'])","16adf921":"#Let's print the last 10 messages in our dataframe\ndf.tail(10)","ba319ff2":"#rename the columns for readability\ndf.columns = ['label','message']","821acd86":"df[df['label'] == 'spam'].head(10)","5e5e199c":"#plotting frequency vs label name\n_=sns.countplot(data=df,x='label',palette='viridis')\nprint(\"percentage of labels:\",f\"{100*df.groupby('label').count()\/len(df)}\")","a759205a":"#prepare a length column\ndf['len'] = df['message'].apply(len)","68598229":"fig,ax=plt.subplots(figsize=(12,8))\ncheck = 'ham'\nsns.histplot(df[df['label']==check],x='len',color='green',ax=ax,alpha=0.7)\nymin, ymax = plt.gca().get_ylim()\nplt.vlines(x=df.loc[df['label']==check,'len'].median(),ymin=ymin,ymax=ymax,color='green',alpha=0.5,linestyles='dashed')\ncheck = 'spam'\nsns.histplot(df[df['label']==check],x='len',color='orange',ax=ax,alpha=0.9)\nplt.vlines(x=df.loc[df['label']==check,'len'].median(),ymin=ymin,ymax=ymax,color='orange',linestyles='dashed')\nplt.legend(['median ham lengths','median spam lengths'])\n_=plt.title('Distribution of message sizes')\n_=plt.ylabel('Count or Frequency')\n_=plt.xlabel('Message Length  (in characters)')\n","54574b0f":"#importing functions that helps in feature engineering\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nimport string","7baa5d52":"#Collecting words and punctuations to be removed in a list\nremove_list = set(list(string.punctuation) + stopwords.words('english'))\n#defining a function that can tokenize the messages, remove unwanted words and punctuations\nporterstemmer = PorterStemmer()\ndef message_cleaner(message):\n    cleaned_message = []\n    for word in word_tokenize(message.lower()):\n        word = re.sub('[^a-zA-Z]','',word)\n        if(word == ''):\n            continue\n        if(word not in remove_list):\n            cleaned_message.append(porterstemmer.stem(word))\n    return cleaned_message","d459c8a9":"message_cleaner('Hey, Are you attending that guitar competition?')","f3357bbd":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split","9a9f1f29":"df['label'] = df['label'].map(lambda x: 0 if(x=='ham') else 1)","0242398a":"#splitting the dataset\nX_train,X_test,y_train,y_test = train_test_split(df['message'],df['label'],test_size=0.25)","de73a3e0":"from sklearn.pipeline import FeatureUnion \n#FeatureUnion is used to concat feaatures obtained using different transform functions\nfrom sklearn.preprocessing import FunctionTransformer\n#FunctionTransformer can create a transform function from any arbitrary or user defined function\nfrom scipy.sparse import csr_matrix","ca7973c5":"def get_length(df):\n    df = df.apply(len)\n    return csr_matrix(df.to_numpy().reshape(-1,1))","275eda51":"feature_pipe = FeatureUnion([\n    ('tfidf',TfidfVectorizer(analyzer=message_cleaner)),\n    ('length',FunctionTransformer(get_length))])\ntfidf_mat = feature_pipe.fit_transform(X_train)","5181f640":"print('Shape of the matrix:', tfidf_mat.shape) # This is a very sparse matrix","a8d15c6a":"message_num=0 #give the index value of message in DataFrame df\n\n#get the indices of the token words in any message and its length\nind = tfidf_mat[message_num].nonzero()[1]\n#print the corresponding word and its tf-idf weights, and the length of the whole message\nfor index in ind:\n    if(index == (tfidf_mat.shape[1]-1)):\n        print('\\nmessage length:',tfidf_mat[message_num,index])\n    else:\n        print('Word:',feature_pipe.transformer_list[0][1].get_feature_names()[index],'  tf-idf:',tfidf_mat[message_num,index])","4d88d84c":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import GridSearchCV","78e07926":"#define grid search\nparams =  {'alpha':[0.001,0.01,0.1,0.25,0.3,0.35,0.5,0.6,0.7,0.8,0.9,1,2,5]}\ngrid = GridSearchCV(MultinomialNB(),param_grid=params,cv=6,scoring='recall')\ngrid.fit(tfidf_mat,y_train)","be2d23d0":"#print accuracy score\nprint(f'Accuracy score is: {grid.score(feature_pipe.transform(X_test),y_test):.2f}')\n#Print the best parameter\nprint('Best parameter:',grid.best_params_)","11cf3187":"from sklearn.metrics import classification_report,confusion_matrix","01b572f7":"#transform test data before predicting\ntransformed_X_test = feature_pipe.transform(X_test)\n\n#classify test messages\npredictions = grid.predict(transformed_X_test)\n#print classification report\nprint(classification_report(y_test,predictions))","6f0fc8f4":"#create a confusion matrix\nsns.heatmap(confusion_matrix(y_test,predictions),annot=True,fmt='d')\nplt.xlabel(['ham predict','spam predict'])\n_=plt.ylabel(['spam actual','ham actual'])","48ea4df1":"Let's test the message cleaner function using a dummy messsage.","23f0ff39":"**The columns other than v1 and v2 also have messages (shown above).**","178ac496":"**Let's map labels *spam* to 1 and *ham* to 0**","2151b2fe":"**ham** messages are high in number compared to **spam** messages. The dataset is slightly imbalanced or skewed. We have to take this imbalance into account while training the model.","adeacc1e":"## Natural Language Processing - SMS Spam Detection\n\n**Let's train a model to predict spam messages!**\n\nDescription of the data:\nThe SMS Spam Collection is a set of SMS tagged messages that have been collected for SMS Spam research. It contains one set of SMS messages in English of 5,574 messages, tagged acording being ham (legitimate) or spam.\n\n\nDataset used: SMS Spam Collection Dataset, UCI\n\n### Importing Initial Libraries","648caa38":"**Let's print and plot the result scores**","07051739":"**The 2nd, 3rd, and 4th columns are having too many null values.**\n\n**Let's explore these columns in detail.**\n","4f3af45e":"**Let's print the shape of the feature matrix**","9c439b03":"**Let's check out the tf-idf features of words in the first message (message_num=0)**","cad1be11":"Let's have a look at distribution of message sizes.","23889a4e":"Cool. The function seems to do it's job. Now let's calculate tf-idf features from the messages.\n\n**The TfidfVectorizer function will run the analyzer (message_cleaner) through each of the messages and create a sparse matrix of words and it's frequency. It then calculates the tf-idf features from this matrix. The length for each message is also calculated and appended to the matrix as a feature.**\n\n**We must split the dataset into train and test data for further processing.**","9b526697":"**Let's change the column labels of the dataframe for readability.**","3148fed7":"**Let's unite the TfidfVectorizer and get_length features to a single matrix using a FeatureUnion pipeline. The features matrix can then be created using the fit and transform method on this FeatureUnion object.**","8a899838":"**Spam** messages seem to be well structured and lengthy.","98d9c294":"**Writing a function that can calculate and return the length of messages in sparse matrix format**","798c1e90":"**None of the columns Unnamed: 2, Unnamed: 3 and Unnamed: 4 have any *Spam* messages.**\n\n**Hence we are labelling the messages in these columns as *ham***\n\n**Let's try to rearrage these columns to a two column dataframe, where one is for labels and the other is for  messages.**","15104a07":"**Since the labels are imbalanced, we choose recall as the scoring method. Tuning the model using recall score will improve predictability of the spam messages.**","10adef4b":"**We have a good recall and f1-score for both labels!**","43e81a7e":"## Data Cleaning and Preparation","d56f1a69":"Usually spam messages are larger than personal messages. Let's comapare the distribution of the lengths of **spam** and **ham** messages.","3a574324":"## Thank You","d7555ff2":"## Feature Engineering","ed08f0dc":"Let's have a look at the countplot of labels.","c2c13d21":"Let's have a look at the messages labelled as **spam**.","b017e3e4":"**The median of both the frequency distributions indicate that personal messages are mostly short and spam messages are lengthy! Hence we can use the length of messages as a feature while training the model.**","e289f049":"## Training and tuning the model\n\nLet's use the Multinomial naive bayes classifier to train the model and GridSearchCV to tune it"}}