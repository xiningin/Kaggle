{"cell_type":{"45e46115":"code","653afe61":"code","b51ad7c7":"code","84f803ad":"code","b6d30cfb":"code","96fa6de0":"code","8b0b1690":"code","dea80a4c":"code","7b4c976b":"code","1616cba5":"code","f150a546":"code","cddf03f8":"code","e5d269ff":"code","3414fba6":"code","526d3ca8":"code","33a14cbc":"code","bf1ffc5c":"code","c72b184f":"code","8ba04060":"code","1c069a30":"code","242e9e97":"code","f7cc2b2b":"code","e6a167aa":"code","9f107379":"code","70522d0e":"code","42bb679c":"code","7ffc4e2e":"code","8b3e957c":"markdown"},"source":{"45e46115":"packages = [\n    '..\/input\/indoor-locationnavigation-2021\/indoor-location-competition-20-master\/indoor-location-competition-20-master'\n]\nimport sys\nfor pth in packages:\n    sys.path.append(pth)","653afe61":"from io_f import read_data_file ","b51ad7c7":"def all_files(f_list,directory):\n    for info in walk(directory):\n        dirpath,dirnames,filenames =  info\n        for fname in filenames:\n            f_list.append(dirpath+'\/'+fname)\n        for dname in dirnames:\n            all_files(f_list,dirpath+'\/'+dname)\n        return f_list\n        ","84f803ad":"import pandas as pd\nimport numpy as np\nimport os","b6d30cfb":"train = pd.read_parquet('..\/input\/indoor-prediction-data-manager\/train_data.parquet')\ntest = pd.read_parquet('..\/input\/indoor-prediction-data-manager\/test_data.parquet')","96fa6de0":"unique_bssid = pd.read_csv('..\/input\/indoor-prediction-data-manager\/unique_bssid.csv') ","8b0b1690":"train.x = train.x.astype('float')\ntrain.y = train.y.astype('float')\ntrain.f = train.f.astype('int')","dea80a4c":"train.td = train.td.astype('int')\ntrain = train[train.td<2000]","7b4c976b":"bssids = {}\nfor i,val in enumerate(unique_bssid['0'].to_numpy()):\n    bssids[val] = i","1616cba5":"submission = pd.read_csv('..\/input\/indoor-location-navigation\/sample_submission.csv')","f150a546":"!pip install tf-models-official","cddf03f8":"import tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.model_selection import GroupKFold,KFold\nimport numpy as np\nfrom time import time\nfrom contextlib import contextmanager\nfrom psutil import virtual_memory, Process","e5d269ff":"from official.nlp.transformer import model_utils\nfrom official.nlp.transformer import transformer","3414fba6":"import gc\nfrom tqdm.notebook import tqdm","526d3ca8":"def mpe_error(pred,tar):\n    xy = np.sqrt(np.square(pred[:,0]-tar[:,0])+np.square(pred[:,1]-tar[:,1]))\n    f = 15*np.abs(pred[:,2]-tar[:,2])\n    return (xy+f).mean()\n\ndef mpe_loss(tar,pred):\n    tar = tf.expand_dims(tar,1)\n    xy = tf.sqrt(tf.square(pred[:,:,0]-tar[:,:,0])+tf.square(pred[:,:,1]-tar[:,:,1]))\n    f = 15*tf.abs(pred[:,:,2]-tar[:,:,2])\n    return tf.reduce_mean(xy+f)","33a14cbc":"@contextmanager\ndef timer():\n    start = time()\n    yield\n    end = time()\n    m,s = (end-start)\/\/60, (end-start)%60\n    print(f\"Training ended in {m} min {s} sec. Current Memory Usage: {virtual_memory().percent} \\n\")\n    ","bf1ffc5c":"class ChangeModes(keras.callbacks.Callback):\n    def __init__(self,model,features,targ,max_f,min_f):\n        self.model = model\n        self.fea = features\n        self.tar = np.expand_dims(targ,1)\n        self.min_f = min_f\n        self.max_f = max_f\n    def on_train_begin(self, logs=None):\n        self.model.training()\n    def on_test_begin(self, logs=None):\n        self.model.testing()\n    def on_epoch_end(self,epoch,logs=None):\n        pred = model.predict(self.fea)*(self.max_f-self.min_f)+self.min_f\n        xy = np.sqrt(np.square(pred[:,:,0]-self.tar[:,:,0])+np.square(pred[:,:,1]-self.tar[:,:,1]))\n        f = (15*np.abs(pred[:,:,2]-self.tar[:,:,2]))\n        print(f\"Epoch:{epoch},Est_lbscore:{(xy+f).mean()} validation loss: {logs['val_mpe_loss']}, building_loss={f.mean()}, location_loss = {xy.mean()}\")","c72b184f":"class IndoorPrediction(keras.Model):\n    def __init__(self,inp_shape,params,emb_length,emb_dim_bssid, emb_dim_rssi,bssid_dict):\n        super(IndoorPrediction, self).__init__()\n        self.train=True\n        self.bssid_dict = bssid_dict\n        self.inp_shape = inp_shape\n        self.embedding_bssid = keras.layers.Embedding(emb_length,emb_dim_bssid)\n        self.embedding_rssi = keras.layers.Embedding(1000,emb_dim_rssi) # (0-999) Most of these are not used.\n        self.encoder = transformer.EncoderStack(params)\n        self.encoder.build(inp_shape)\n        \n        self.fc = keras.layers.Dense(3,activation='sigmoid')\n        \n    def training(self):\n        self.train =True\n    def testing(self):\n        self.train =False\n    def buildModel(self):\n        self.build(self.inp_shape)\n    def process_data(self,i):\n        bs,rs = i[:,:100],i[:,100:]*-1\n        return bs,rs\n    def call(self,i):\n        bs,rs = self.process_data(i)\n        attention_bias = model_utils.get_padding_bias(bs)\n        x = tf.concat([self.embedding_bssid(bs),self.embedding_rssi(rs)],2)\n        return self.fc(self.encoder.call(x,attention_bias,None,self.train)[:,-50:-1,:])","8ba04060":"batch_size=64\nseq_len = 100\nemb_dim_bssid= 36\nemb_dim_rssi = 18","1c069a30":"params = {\n    \"hidden_size\": emb_dim_bssid+emb_dim_rssi,\n#     Attention-layer parameters\n    \"num_hidden_layers\":8,\n    \"attention_dropout\":0.0,\n    \"layer_postprocess_dropout\": 0.0,\n    \"num_heads\": 6,\n#     Feed-Forward parameters\n    \"filter_size\": 64,\n    \"relu_dropout\": 0.0\n}","242e9e97":"fea,tar = train.iloc[:,:200].values,train.iloc[:,200:203].values\ntest_fea = test.iloc[:,:200].values","f7cc2b2b":"max_f,min_f = tar.max(0),tar.min(0)\ntar= (tar- min_f)\/(max_f-min_f) ","e6a167aa":"splits=5\npredict = np.zeros((test_fea.shape[0],3))\nfor i in range(splits):\n        mask = np.random.rand(len(tar))<0.8\n        X_train, Y_train = fea[mask], tar[mask]\n        X_valid, Y_valid = fea[~mask], tar[~mask]\n        print(f\"{i}-fold model training starting...\");\n        model = IndoorPrediction((batch_size,seq_len), params,len(bssids),emb_dim_bssid,emb_dim_rssi,bssids)\n        model.compile(optimizer = tf.keras.optimizers.Adam(\n                        learning_rate=5e-4, beta_1=0.9, \n                        beta_2=0.999, epsilon=1e-07, \n                        amsgrad=False,name='Adam'), loss=mpe_loss,metrics=[mpe_loss])\n        earlystop = keras.callbacks.EarlyStopping(monitor='val_loss',patience=8)\n        changemode = ChangeModes(model,X_valid,Y_valid,max_f,min_f)\n        save_point = 'checkpoint.ckpt'\n        model_checkpoint = keras.callbacks.ModelCheckpoint(save_point,monitor='val_loss',mode='min',\n                                                           verbose=1,save_best_only=True,save_weights_only=True)\n        reducelr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=0, mode='min')\n        with timer():\n            history = model.fit(X_train,Y_train,batch_size=batch_size,\n                                validation_data = (X_valid,Y_valid),epochs=30,\n                                callbacks=[earlystop,reducelr,changemode,model_checkpoint],verbose=0)\n        model.load_weights(save_point)\n        Y_predict = model.predict(test_fea)[:,-1,:]*(max_f-min_f)+min_f\n        predict += Y_predict\n        gc.collect()\npredict \/=splits","9f107379":"sub_other = pd.read_csv('..\/input\/simple-99-accurate-floor-model\/submission.csv')","70522d0e":"submission['floor'] = sub_other['floor']\nsubmission['x'] = predict[:,0]\nsubmission['y'] = predict[:,1]","42bb679c":"submission['floor'] = submission['floor'].astype('int32')","7ffc4e2e":"submission.to_csv('submission.csv',index=False)","8b3e957c":"validation with 19 entries 1 epoch:  \nEpoch:0, validation loss: 0.08501642197370529, building_loss=21.83549779882712, location_loss = 169.73047401256605\n\nvalidation with 9 entries 1 epoch:  \nloss: 0.4561 - mpe_loss: 0.4561 Epoch:0,Est_lbscore:188.62509873283773 validation loss: 0.10268882662057877, building_loss=21.53930707612264, location_loss = 167.0857916567151\n\nvalidation with 29 entries 1 epoch:  \nloss: 0.4266 - mpe_loss: 0.4266 - val_loss: 0.1043 - val_mpe_loss: 0.1049\nEpoch:0,Est_lbscore:193.9539121881643 validation loss: 0.10486969351768494, building_loss=22.04513628422682, location_loss = 171.90877590393754"}}