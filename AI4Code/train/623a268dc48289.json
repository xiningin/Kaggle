{"cell_type":{"4b094e8c":"code","0106c24b":"code","02f4fa26":"code","ca13fa62":"code","3ef734d3":"code","e82bce87":"code","58e438e3":"code","c8113b71":"code","53c6bed6":"code","e4477c93":"code","dd2f966f":"code","308dd6b8":"code","8c909462":"code","9e07eefd":"code","6bbad724":"code","3c402ec2":"code","ae907b76":"code","00860a1c":"code","3aa82119":"markdown","d68b29ca":"markdown","ef4cc75d":"markdown","e509427d":"markdown","3ad22cc9":"markdown","8eb93a9a":"markdown","7c9d062a":"markdown","4fa7c5dd":"markdown"},"source":{"4b094e8c":"# Importing basic libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport sklearn","0106c24b":"# Read the data\nad_data = pd.read_csv('..\/input\/advertising-dataset\/advertising.csv')","02f4fa26":"ad_data.head()","ca13fa62":"# Print the summary of the data\nad_data.describe()","3ef734d3":"sns.boxplot(data=ad_data, x='Newspaper')\nplt.show()","e82bce87":"# clip the values to 0.98 percentile\nmax_val = np.percentile(ad_data['Newspaper'], q=98)\nmin_val = np.percentile(ad_data['Newspaper'], q=0)\n\nad_data['Newspaper'] = np.clip(ad_data['Newspaper'], min_val, max_val)","58e438e3":"# Divide the data into dependent and independent variables\nX = ad_data.drop('Sales', axis=1)\ny = ad_data['Sales']\n\n# calculate the total rows and columns\ntotal_rows, total_columns = X.shape","c8113b71":"# Scale the data\nss = sklearn.preprocessing.StandardScaler()\nX_scaled = ss.fit_transform(X)","53c6bed6":"# add the bias term to the data\nbias_col = np.ones(shape=(total_rows, 1))\nX_scaled = np.concatenate((bias_col, X_scaled), axis=1)","e4477c93":"class LinearRegression_Custom:\n    \n    # Constructor\n    def __init__(self, X, y, lr=0.01, n_iter=1000):\n        \n        self.X = X\n        self.y = y\n        self.lr = lr\n        self.n_iter = n_iter\n        self.theta = np.zeros(shape = (self.X.shape[1],))\n        self.error_list = []\n        \n    # 1. Predictions\n    def predictions(self, data):\n        \n        return np.dot(data, self.theta)\n    \n    # 2. Loss Function\n    def loss_function(self):\n        \n        preds = self.predictions(data=self.X)\n        act = self.y\n        \n        mse = np.mean((act-preds)**2)\n        \n        return mse\n    \n    # 3. Gradient\n    def gradient(self):\n        \n        preds = self.predictions(data=self.X)\n        act = self.y\n        m = self.X.shape[0]\n        \n        error = (act - preds)\n        \n        return -2*(np.dot(self.X.T, error)\/m)\n    \n    # 4. Gradient Descent\n    def train(self):\n        \n        for _ in range(self.n_iter):\n            \n            # Compute gradient\n            grad = self.gradient()\n            \n            # Calculate Error\n            error = self.loss_function()\n            self.error_list.append(error)\n            \n            # perform the gradient descent algorithm\n            self.theta = self.theta - self.lr*grad\n            \n    # 5. Compute the R squared Score\n    def score_R2(self, data, test):\n        \n        '''\n        R2 Score = 1 - summation((actual - predictions)**2)\/summation((actual - mean)**2)\n        '''\n        \n        # 1. Make Predictions\n        preds = self.predictions(data=data)\n        act = test\n        \n        # 2. Compute RSS: Residula Sum Squared\n        rss = np.sum((preds - act)**2)\n        \n        # 3. Cmpute TSS: Total Squared Error\n        tss = np.sum((preds - np.mean(act))**2)\n        \n        # 4. Compute R Squared\n        r2_score = 1 - (rss\/tss)\n        \n        return r2_score ","dd2f966f":"# Split the data into train and test\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=42)","308dd6b8":"# Create the model object and train the model using the train function\nlr = LinearRegression_Custom(X_train, y_train, lr = 0.1, n_iter=500)\nlr.train()","8c909462":"# Make Predictions\ny_preds = lr.predictions(data=X_test)","9e07eefd":"print(y_preds)","6bbad724":"# Compute the R2 Score\nprint(sklearn.metrics.r2_score(y_test, y_preds))","3c402ec2":"# Plot the predictions with actual values and plot the error as well.\n\nfig, ax = plt.subplots(1, 2, figsize=(12, 4))\nax[0].plot(lr.error_list)\nsns.scatterplot(x=y_test, y=y_preds, ax=ax[1])\nax[1].plot(np.arange(5.0, 25.0), np.arange(5.0, 25.0), color='orange', label=\"45 Degree Line\")\nax[0].set_xlabel(\"Number of Iterations\")\nax[0].set_ylabel(\"Error\")\nax[1].set_xlabel(\"Actual Values\")\nax[1].set_ylabel(\"Predicted Values\")\nplt.legend()\nplt.show()","ae907b76":"# Import the LinearRegression class from sklearn\nfrom sklearn.linear_model import LinearRegression\n\n# Create the model object\nlr_sk = LinearRegression()\n\n# Fit the model\nlr_sk.fit(X_train, y_train)\n\n# Make predictions\nlr_preds = lr_sk.predict(X_test)\n\n# Check the R Squared Score\nlr_sk.score(X_test, y_test )","00860a1c":"# Compare the parameters\nprint(\"Sklearn's Linear Regression Parameter:\", lr_sk.coef_[1:])\nprint(\"Custom Linear Regression Parameter:\", lr.theta[1:])\n\nprint()\n\n# Compare the bias terms\nprint(\"Sklearn's Linear Regression Bias:\", lr_sk.intercept_)\nprint(\"Customer Linear Regression Bias:\", lr.theta[0])","3aa82119":"**Both models fetch the same R Squared Score.**","d68b29ca":"## In this notebook, I created a custom Linear Regressor and compared its performance with the scikit learn Linear Regressor. If you find the notebook informative please do give it an upvote. I would love to hear your feedback in the comments section. \n\n### <p style=\"color:Crimson\"> I have also written a detailed explaination of the Linear Regression model on my personal blog. You can refer the same <a href=\"https:\/\/keepingupwithdatascience.wordpress.com\/\"> here <\/a>.<\/p>","ef4cc75d":"# Error Analysis","e509427d":"# Linear Regression from Scratch\n\n![](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/b\/be\/Normdist_regression.png)\n\n### In this notebook, I create a custom Linear Regression class and train it on the advertisemnet data and then compare the result with Scikit Learn's in built Linear Regression.","3ad22cc9":"**Newspaper column probably has some outliers.**","8eb93a9a":"# Building a cusom Linear Regression Class","7c9d062a":"# Compare the results with Sklearn's Linear Regression Model","4fa7c5dd":"**We get the exact same model parameters.**"}}