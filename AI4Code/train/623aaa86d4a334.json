{"cell_type":{"72002ce2":"code","0715bdba":"code","0d4725f8":"code","66711f1a":"code","2c9205c5":"code","dcc7a920":"code","afe14254":"code","11bb95b6":"code","9be5ce3d":"code","ab0e793b":"code","e5ffe27d":"markdown","a62720fe":"markdown"},"source":{"72002ce2":"# install PyTorch Tabular first\n!pip install pytorch_tabular\n# This is for a custom optimizer. PyTorch Tabular is flexible enough to use custom optimizers\n!pip install torch_optimizer\n!pip install pandas==1.1.5","0715bdba":"# packages\n\n# standard\nimport numpy as np\nimport pandas as pd\nimport time\n\n# plots\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# NODE and ML tools\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom pytorch_tabular import TabularModel\nfrom pytorch_tabular.models import CategoryEmbeddingModelConfig, NodeConfig, TabNetModelConfig\nfrom pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig\nfrom pytorch_tabular.categorical_encoders import CategoricalEmbeddingTransformer\nfrom torch_optimizer import QHAdam\nimport category_encoders as ce\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor","0d4725f8":"# load training data\ndf_train = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/train.csv')\ndisplay(df_train.head())\n# load test data\ndf_test = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/test.csv')\ndisplay(df_test.head())","66711f1a":"df_train.columns","2c9205c5":"def get_configs(train):\n    epochs = 25\n    batch_size = 1024\n    steps_per_epoch = int((len(train)\/\/batch_size)*0.9)\n    data_config = DataConfig(\n        target=['target'], #target should always be a list. Multi-targets are only supported for regression. Multi-Task Classification is not implemented\n        continuous_cols=['cont0', 'cont1', 'cont2', 'cont3', 'cont4',\n       'cont5', 'cont6', 'cont7', 'cont8', 'cont9', 'cont10'],\n        categorical_cols=['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7',\n       'cat8', 'cat9', 'cat10', 'cat11', 'cat12', 'cat13', 'cat14', 'cat15',\n       'cat16', 'cat17', 'cat18'],\n        continuous_feature_transform=\"quantile_normal\"\n    )\n    trainer_config = TrainerConfig(\n        auto_lr_find=True, # Runs the LRFinder to automatically derive a learning rate\n        batch_size=batch_size,\n        max_epochs=epochs,\n#         gpus=1, #index of the GPU to use. 0, means CPU\n    )\n    optimizer_config = OptimizerConfig(lr_scheduler=\"OneCycleLR\", lr_scheduler_params={\"max_lr\":0.005, \"epochs\": epochs, \"steps_per_epoch\":steps_per_epoch})\n    model_config = CategoryEmbeddingModelConfig(\n        task=\"classification\",\n        layers=\"500-200\",  # Number of nodes in each layer\n        activation=\"ReLU\", # Activation between each layers\n        learning_rate = 1e-3,\n        batch_norm_continuous_input=True,\n        use_batch_norm =True,\n        dropout=0.1,\n        embedding_dropout=0.05,\n        initialization=\"kaiming\",\n        metrics=[\"auroc\"],\n        metrics_params = [{}]\n    )\n    return data_config, trainer_config, optimizer_config, model_config","dcc7a920":"data_config, trainer_config, optimizer_config, model_config = get_configs(df_train)\ntabular_model = TabularModel(\n    data_config=data_config,\n    model_config=model_config,\n    optimizer_config=optimizer_config,\n    trainer_config=trainer_config\n)\n# fit model\ntabular_model.fit(train=df_train, optimizer=QHAdam, \n              optimizer_params={\"nus\": (0.7, 1.0), \"betas\": (0.95, 0.998)})","afe14254":"pred_df = tabular_model.predict(df_test)","11bb95b6":"pred_df","9be5ce3d":"# prepare submission\ndf_sub = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/sample_submission.csv')\ndf_sub.target = pred_df['1_probability'].values\ndf_sub.head()","ab0e793b":"df_sub.to_csv(\"submission.csv\", index=False)","e5ffe27d":"# What is PyTorch Tabular?\n\n![PyTorch Tabular](https:\/\/deepandshallowml.files.wordpress.com\/2021\/01\/pytorch_tabular_logo.png)\n\nPyTorch Tabular is a framework\/ wrapper library which aims to make Deep Learning with Tabular data easy and accessible to real-world cases and research alike. The core principles behind the design of the library are:\n\n- Low Resistance Usability\n- Easy Customization\n- Scalable and Easier to Deploy\n\nInstead of starting from scratch, the framework has been built on the shoulders of giants like **PyTorch**(obviously), and **PyTorch Lightning**.\n\nIt also comes with state-of-the-art deep learning models that can be easily trained using pandas dataframes.\n\nThe high-level config driven API makes it very quick to use and iterate. You can just use a **pandas dataframe** and all of the heavy lifting for normalizing, standardizing, encoding categorical features, and preparing the dataloader is handled by the library.\n\nThe `BaseModel` class provides an easy to extend abstract class for implementing custom models and still leverage the rest of the machinery packaged with the library.\nState-of-the-art networks like **Neural Oblivious Decision Ensembles(NODE)** for Deep Learning on Tabular Data, and **TabNet**: Attentive Interpretable Tabular Learning are implemented. See examples from the [documentation](https:\/\/pytorch-tabular.readthedocs.io\/en\/latest\/) for how to use them.\n\nBy using PyTorch Lightning for the training, PyTorch Tabular inherits the flexibility and scalability that Pytorch Lightning provides\n\n- GitHub: [https:\/\/github.com\/manujosephv\/pytorch_tabular](https:\/\/github.com\/manujosephv\/pytorch_tabular)\n- Documentation: [https:\/\/pytorch-tabular.readthedocs.io\/en\/latest\/](https:\/\/pytorch-tabular.readthedocs.io\/en\/latest\/)\n- Accompanying Blog: [PyTorch Tabular \u2013 A Framework for Deep Learning for Tabular Data](https:\/\/deep-and-shallow.com\/2021\/01\/27\/pytorch-tabular-a-framework-for-deep-learning-for-tabular-data\/)\n","a62720fe":"## Defining the configs for the data, training, model, and optimizer"}}