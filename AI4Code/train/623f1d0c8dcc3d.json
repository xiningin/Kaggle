{"cell_type":{"f2907355":"code","1383c31f":"code","8c234fa6":"code","f8de292d":"code","2eec24da":"code","0e6dd415":"code","726a44e8":"code","923f8095":"code","3de4be89":"code","49647c97":"markdown","3a56bff6":"markdown","cd846d0d":"markdown","c1528f6c":"markdown","e766f129":"markdown","98fd37da":"markdown","84d80c90":"markdown","6fd3ea9f":"markdown","37398651":"markdown"},"source":{"f2907355":"import os\nimport pandas as pd\nimport numpy as np\nimport xgboost as xgb\nimport warnings \nwarnings.filterwarnings('ignore')","1383c31f":"df = pd.read_csv('..\/input\/iris\/Iris.csv')\nprint('Shape :', df.shape)\ndf.head()","8c234fa6":"df.Species.value_counts()","f8de292d":"dep_var_encode = dict([(i,x) for x,i in enumerate(sorted(df.Species.unique()))])\ndf['Species'] = df['Species'].replace(dep_var_encode)\ndf.drop('Id', axis=1, inplace = True)","2eec24da":"SEED = 35\nTEST_SIZE = 0.3\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(df.drop('Species',axis=1), df.Species, test_size = TEST_SIZE, random_state = SEED)\nprint('X_train Shape :', X_train.shape)\nprint('X_test  Shape :', X_test.shape)\nprint('y_train Shape :', y_train.shape)\nprint('y_test  Shape :', y_test.shape)","0e6dd415":"train_dm = xgb.DMatrix(data = X_train, label = y_train)\ntest_dm = xgb.DMatrix(data = X_test, label = y_test)\nOBJECTIVE = 'multi:softprob'\nparams = {\n    'num_class': 3,\n    'num_boost_round': 1000,\n    'objective': OBJECTIVE,\n    'max_depth' : 4,\n    'eta': 0.003,\n    'min_child_weight': 3,\n    'verbosity': 0\n}\nmodel = xgb.train(params, train_dm, num_boost_round = params['num_boost_round'])\ntrain_preds = model.predict(train_dm)\ntest_preds = model.predict(test_dm)","726a44e8":"from sklearn.metrics import f1_score\nif OBJECTIVE == 'multi:softprob':\n    y_pred_train =[np.argmax(x) for x in train_preds]\n    y_pred_test = [np.argmax(x) for x in test_preds]\nelif OBJECTIVE == 'multi:softmax':\n    y_pred_train = train_preds\n    y_pred_test = test_preds\n\nprint('Train F1 Score :',f1_score(y_train, y_pred_train, average=None))\nprint('Test F1 Score :',f1_score(y_test, y_pred_test, average=None))\n\nprint('Train weighted F1 Score :',f1_score(y_train, y_pred_train, average='weighted'))\nprint('Test weighted F1 Score :',f1_score(y_test, y_pred_test, average='weighted'))","923f8095":"from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\ncm_train = confusion_matrix(y_train, y_pred_train)\ncm_test = confusion_matrix(y_test, y_pred_test)\nf,ax = plt.subplots(1,2, figsize = (15,6))\ndisp_train = ConfusionMatrixDisplay(confusion_matrix=cm_train, display_labels=['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])\ndisp_test = ConfusionMatrixDisplay(confusion_matrix=cm_test, display_labels=['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])\ndisp_train.plot(ax = ax[0], cmap='Blues')\ndisp_test.plot(ax = ax[1], cmap='Blues')\nax[0].set_title('Train')\nax[1].set_title('Test')\nplt.suptitle('Train & Test Confusion Matrix')\nplt.show()","3de4be89":"from sklearn.metrics import accuracy_score\nprint('Train Accuracy :',accuracy_score(y_train, y_pred_train))\nprint('Test Accuracy :',accuracy_score(y_test, y_pred_test))","49647c97":"## Model Evaluation\n\n#### using Weighted F1-Score\nFor a multi-class classification problem, we don\u2019t calculate an overall F-1 score. Instead, we calculate the F-1 score per class in a one-vs-rest manner. In this approach, we rate each class\u2019s success separately, as if there are distinct classifiers for each class. More details in the link - https:\/\/www.baeldung.com\/cs\/multi-class-f1-score","3a56bff6":"## Preprocessing","cd846d0d":"#### Distribution of Label\n\nEquallty Distritbuted","c1528f6c":"## Model Building\n#### Using `multi:softprob`","e766f129":"## Loading Data","98fd37da":"## Train Test Split","84d80c90":"#### using Accuracy Metric","6fd3ea9f":"#### Using Confusion Matrix","37398651":"## Loading Libraries"}}