{"cell_type":{"36f47b00":"code","2c25ce00":"code","064750da":"code","416e2151":"code","499aefa5":"code","23d13b75":"code","8746f6ce":"code","ebd9e4e0":"code","1c630ad3":"code","621e7680":"code","b1bd89cc":"code","b00012d9":"code","b14c7109":"code","ef383b15":"code","e42caca4":"code","0879afc9":"code","996232ee":"code","3bf66075":"code","47189b94":"code","95a594de":"code","88177b35":"code","d35180f7":"code","99ba8f52":"code","d5381fb8":"code","a75cd365":"code","2ececb5f":"code","8c8193b8":"code","f8fa033c":"code","803022bb":"code","389a0a48":"code","4ae933f7":"code","0520f711":"code","b60a57eb":"code","70d5d508":"code","092c816f":"code","aea4a3d2":"code","ac7b0fd7":"code","7eaea852":"code","68bbdece":"markdown"},"source":{"36f47b00":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input director\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2c25ce00":"train = pd.read_csv(\"\/kaggle\/input\/siim-isic-melanoma-classification\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/siim-isic-melanoma-classification\/test.csv\")","064750da":"train.head()","416e2151":"test.head()","499aefa5":"import seaborn as sn","23d13b75":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10,6))\nsn.countplot(train[\"benign_malignant\"])","8746f6ce":"train[\"benign_malignant\"].value_counts()","ebd9e4e0":"train[\"diagnosis\"].value_counts()","1c630ad3":"plt.figure(figsize=(15,9))\nsn.countplot(train[\"diagnosis\"])","621e7680":"plt.figure(figsize=(10,6))\nsn.countplot(train[\"anatom_site_general_challenge\"])","b1bd89cc":"train.head()","b00012d9":"plt.figure(figsize=(15,9))\nmalignant_body_part = train[train[\"benign_malignant\"]==\"malignant\"][\"anatom_site_general_challenge\"]\nsn.countplot(malignant_body_part)","b14c7109":"plt.figure(figsize=(15,9))\nsn.boxplot(x=\"benign_malignant\",y=\"age_approx\",data=train)","ef383b15":"plt.figure(figsize=(10,6))\nsn.distplot(train[\"age_approx\"])","e42caca4":"plt.figure(figsize=(15,9))\nsn.boxplot(x=\"anatom_site_general_challenge\",y=\"age_approx\",data=train)","0879afc9":"train.head()","996232ee":"sn.countplot(x = \"benign_malignant\",hue=\"sex\",data=train)","3bf66075":"import pydicom\nfrom pydicom import dcmread","47189b94":"ex1 = \"\/kaggle\/input\/siim-isic-melanoma-classification\/train\/ISIC_6692344.dcm\"\nex2 = \"\/kaggle\/input\/siim-isic-melanoma-classification\/train\/ISIC_6652710.dcm\"\nex1_img = dcmread(ex1)\nex2_img = dcmread(ex2)","95a594de":"fig,(ax1,ax2) = plt.subplots(1,2)\nax1.imshow(ex1_img.pixel_array,cmap=plt.cm.bone)\nax2.imshow(ex2_img.pixel_array,cmap=plt.cm.bone)","88177b35":"import os\ndef show_images(n = 5, rows=1, cols=5, title=\"Skin Cancer\"):\n    plt.figure(figsize=(16,4))\n\n    for k, path in enumerate(list(os.listdir('..\/input\/siim-isic-melanoma-classification\/train'))[:n]):\n        image = pydicom.read_file('..\/input\/siim-isic-melanoma-classification\/train\/'+path)\n        image = image.pixel_array\n\n        plt.suptitle(title, fontsize = 16)\n        plt.subplot(rows, cols, k+1)\n        plt.imshow(image)\n        plt.axis('off')","d35180f7":"show_images(n=10, rows=2, cols=5)","99ba8f52":"import matplotlib.image as mpimg\ndef show_images_jpeg(n = 5, rows=1, cols=5, title=\"Skin Cancer\"):\n    plt.figure(figsize=(16,4))\n\n    for k, path in enumerate(list(os.listdir('..\/input\/siim-isic-melanoma-classification\/jpeg\/train'))[:n]):\n        image = mpimg.imread('..\/input\/siim-isic-melanoma-classification\/jpeg\/train\/'+path)\n        plt.suptitle(title, fontsize = 16)\n        plt.subplot(rows, cols, k+1)\n        plt.imshow(image)\n        plt.axis('off')","d5381fb8":"show_images_jpeg(n=10, rows=2, cols=5)","a75cd365":"path = '..\/input\/siim-isic-melanoma-classification\/jpeg\/train\/'\ntrain[\"path\"] = path+train[\"image_name\"]+'.jpg'","2ececb5f":"from sklearn.model_selection import train_test_split","8c8193b8":"X_train,X_val = train_test_split(train,test_size=0.2)","f8fa033c":"X_train.shape,X_val.shape","803022bb":"X_train[\"target\"] = X_train[\"target\"].astype(str)","389a0a48":"from keras.models import Sequential, Model,load_model\nfrom keras.applications.vgg16 import VGG16,preprocess_input\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten,BatchNormalization,Activation\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.models import Model\nfrom keras.optimizers import Adam, SGD, RMSprop\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\nfrom keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport gc\nimport skimage.io\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.python.keras import backend as K","4ae933f7":"train_datagen = ImageDataGenerator(rescale=1.\/255,rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,horizontal_flip=True)\nval_datagen=ImageDataGenerator(rescale=1.\/255)\ntrain_generator = train_datagen.flow_from_dataframe(\n    X_train,\n    x_col='path',\n    y_col='target',\n    target_size=(224, 224),\n    batch_size=8,\n    shuffle=True,\n    class_mode='raw')\n\nvalidation_generator = val_datagen.flow_from_dataframe(\n    X_val,\n    x_col='path',\n    y_col='target',\n    target_size=(224, 224),\n    shuffle=False,\n    batch_size=8,\n    class_mode='raw')","0520f711":"from tensorflow.keras.applications import DenseNet121","b60a57eb":"dense_model = DenseNet121(include_top=False,\n    weights=\"imagenet\",\n    input_shape=(224,224,3))","70d5d508":"model = Sequential()\nmodel.add(dense_model)\nmodel.add(GlobalMaxPooling2D())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))","092c816f":"from tensorflow.keras.metrics import AUC","aea4a3d2":"def focal_loss(alpha=0.25,gamma=2.0):\n    def focal_crossentropy(y_true, y_pred):\n        bce = K.binary_crossentropy(y_true, y_pred)\n        \n        y_pred = K.clip(y_pred, K.epsilon(), 1.- K.epsilon())\n        p_t = (y_true*y_pred) + ((1-y_true)*(1-y_pred))\n        \n        alpha_factor = 1\n        modulating_factor = 1\n\n        alpha_factor = y_true*alpha + ((1-alpha)*(1-y_true))\n        modulating_factor = K.pow((1-p_t), gamma)\n\n        # compute the final loss and return\n        return K.mean(alpha_factor*modulating_factor*bce, axis=-1)\n    return focal_crossentropy","ac7b0fd7":"opt = Adam(lr=1e-5)\nmodel.compile(loss=focal_loss(), metrics=[AUC()],optimizer=opt)","7eaea852":"nb_epochs = 2\nbatch_size=8\nnb_train_steps = X_train.shape[0]\/\/batch_size\nnb_val_steps=X_val.shape[0]\/\/batch_size\nprint(\"Number of training and validation steps: {} and {}\".format(nb_train_steps,nb_val_steps))","68bbdece":"# Training the model next...."}}