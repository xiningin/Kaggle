{"cell_type":{"75578c7c":"code","5541c721":"code","3e081ef6":"code","0361f8ed":"code","a5358939":"code","d9738f3d":"code","088543ec":"code","85fee263":"code","831ab69e":"code","cceb25f5":"code","cd79d831":"code","5c451e10":"code","1a615a3f":"code","082277a8":"code","15847f77":"markdown","04a242a7":"markdown","f464cd22":"markdown","ee2f2b6c":"markdown","e8c4d4d7":"markdown","8d1c4fd2":"markdown"},"source":{"75578c7c":"#Importing Libraries\nimport numpy as np\nimport pandas as pd","5541c721":"#Loading the Dataset\ndf = pd.read_csv('..\/input\/churn-prediction\/Churn_Modelling.csv')\ndf.head()","3e081ef6":"#Extracting the Dependent & Independent Variables\nX = df.iloc[:,3:13].values\nY = df.iloc[:,13].values\n\nprint(X)\nprint(Y)","0361f8ed":"#To create Dummy Variables\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nX[:,2] = le.fit_transform(X[:,2])\nprint(X)","a5358939":"#Creating separate columns for each Country as the potential Dummy Variable would have had 3 levels\n#Thereby, nullifying any sort of ordinalities\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\ncol_tr = ColumnTransformer([('one_hot_encoder', OneHotEncoder(), [1])],remainder = 'passthrough')\nX = np.array(col_tr.fit_transform(X))\nprint(X)","d9738f3d":"#Remove Dummy Variable Trap\nX = X[:,1:]\nprint(X)\n","088543ec":"#Splitting the Data into Train & Test Set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=0)\n","85fee263":"#Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","831ab69e":"import tensorflow as tf\nann = tf.keras.models.Sequential()\n\n# Input and First Hidden Layers\nann.add(tf.keras.layers.Dense(units = 6, activation ='relu'))\n\n#Second Hidden Layer\nann.add(tf.keras.layers.Dense(units = 6, activation ='relu'))\n\n#Output Layer\nann.add(tf.keras.layers.Dense(units = 1, activation ='sigmoid'))","cceb25f5":"#Compilation\nann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","cd79d831":"#Training the Model\nann.fit(X_train, y_train, batch_size = 40, epochs = 100)","5c451e10":"#Prediction\ny_pred = ann.predict(X_test)\nprint(y_pred)","1a615a3f":"#To get the predicted classes (0 or 1) corresponding to the observed classes\ny_pred = (y_pred > 0.5)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","082277a8":"#Creating Confusion Matrix and measuring the test accuracy\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncon_mat = confusion_matrix(y_test, y_pred)\nprint('Confusion Matrix:\\n',con_mat)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint('Accuracy of the Model on the Test Set:\\t',accuracy)","15847f77":"**Therefore, the Artificial Neural Network predicted the churn on the Test Set with an accuracy of 86%.**","04a242a7":"**Dataset** - https:\/\/www.kaggle.com\/ranitradas\/churn-prediction","f464cd22":"# **C. Prediction & Evaluation**","ee2f2b6c":"# **A.** **Data Processing**","e8c4d4d7":"# **To predict whether a customer will close her\/his bank account or not using Artificial Neural Network.**","8d1c4fd2":"# **B. Building the ANN**"}}