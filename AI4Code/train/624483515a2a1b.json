{"cell_type":{"1b3359e9":"code","1364cda8":"code","cbf8c7bb":"code","52b9d65c":"code","76a08800":"code","9e078911":"code","c470d94c":"code","aee9ca54":"code","b3c0d965":"code","c0360a1b":"code","04888d21":"code","6804bb88":"code","04c5fc22":"code","44df085b":"code","fc6fa251":"code","c0e0a01e":"code","17067a88":"code","e9d30868":"code","3fd34f66":"code","127545d2":"code","e9646cc5":"code","b6db2b21":"code","59fbf762":"code","ef8ea97c":"code","7149f644":"code","9d77fcfc":"code","9cea6056":"code","37c75f6f":"code","2a68c95d":"code","e766e9d8":"code","336e5c13":"code","41364ca5":"code","25703c2f":"code","bbc611b2":"code","f0a78827":"markdown"},"source":{"1b3359e9":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf","1364cda8":"tf.__version__","cbf8c7bb":"ls ..\/input\/rabindranath-tagore-online-variorum\/","52b9d65c":"path_to_file = '..\/input\/rabindranath-tagore-online-variorum\/bangla_poems_and_songs_all.txt'","76a08800":"\ntext = open(path_to_file, 'r',encoding='utf-8',\n                 errors='ignore').read()","9e078911":"print(text[:500])","c470d94c":"# The unique characters in the file\nvocab = sorted(set(text))\nprint(vocab)\nlen(vocab)","aee9ca54":"char_to_ind = {u:i for i, u in enumerate(vocab)}","b3c0d965":"ind_to_char = np.array(vocab)","c0360a1b":"encoded_text = np.array([char_to_ind[c] for c in text])","04888d21":"seq_len = 250","6804bb88":"total_num_seq = len(text)\/\/(seq_len+1)","04c5fc22":"total_num_seq","44df085b":"# Create Training Sequences\nchar_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\n","fc6fa251":"sequences = char_dataset.batch(seq_len+1, drop_remainder=True)","c0e0a01e":"def create_seq_targets(seq):\n    input_txt = seq[:-1]\n    target_txt = seq[1:]\n    return input_txt, target_txt","17067a88":"dataset = sequences.map(create_seq_targets)","e9d30868":"# Batch size\nbatch_size = 128\n\n# Buffer size to shuffle the dataset so it doesn't attempt to shuffle\n# the entire sequence in memory. Instead, it maintains a buffer in which it shuffles elements\nbuffer_size = 10000\n\ndataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)","3fd34f66":"# Length of the vocabulary in chars\nvocab_size = len(vocab)\n\n# The embedding dimension\nembed_dim = 64\n\n# Number of RNN units\nrnn_neurons = 2052","127545d2":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout,GRU","e9646cc5":"from tensorflow.keras.losses import sparse_categorical_crossentropy","b6db2b21":"def sparse_cat_loss(y_true,y_pred):\n  return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)","59fbf762":"def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n    model = Sequential()\n    model.add(Embedding(vocab_size, embed_dim,batch_input_shape=[batch_size, None]))\n    model.add(GRU(rnn_neurons,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n    # Final Dense Layer to Predict\n    model.add(Dense(vocab_size))\n    model.compile(optimizer='adam', loss=sparse_cat_loss) \n    return model","ef8ea97c":"model = create_model(\n  vocab_size = vocab_size,\n  embed_dim=embed_dim,\n  rnn_neurons=rnn_neurons,\n  batch_size=batch_size)","7149f644":"model.summary()","9d77fcfc":"epochs = 50","9cea6056":"model.fit(dataset,epochs=epochs)","37c75f6f":"model.save('tagore_poem_gen.h5') ","2a68c95d":"from tensorflow.keras.models import load_model","e766e9d8":"model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size=1)\n\nmodel.load_weights('..\/input\/rabindranath-tagore-online-variorum\/tagore_poem_gen.h5')\n\nmodel.build(tf.TensorShape([1, None]))\n","336e5c13":"model.summary()","41364ca5":"def generate_text(model, start_seed,gen_size=100,temp=1.1):\n  num_generate = gen_size\n  input_eval = [char_to_ind[s] for s in start_seed]\n  input_eval = tf.expand_dims(input_eval, 0)\n  text_generated = []\n  temperature = temp\n  model.reset_states()\n  for i in range(num_generate):\n      predictions = model(input_eval)\n      predictions = tf.squeeze(predictions, 0)\n      predictions = predictions \/ temperature\n      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n      input_eval = tf.expand_dims([predicted_id], 0)\n      text_generated.append(ind_to_char[predicted_id])\n  return (start_seed + ''.join(text_generated))","25703c2f":"print(generate_text(model,\"\u099b\u09be\u09df\u09be\u099b\u09ac\u09bf\",gen_size=1000))","bbc611b2":"print(generate_text(model,\"\u0997\u09c0\u09a4\u09ac\u09bf\u09a4\u09be\u09a8\",gen_size=2000))","f0a78827":"# Asking machine learning to write a bengali poem like Tagore"}}