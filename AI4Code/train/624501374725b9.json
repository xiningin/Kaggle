{"cell_type":{"e3e0fd70":"code","6f668420":"code","4ff31907":"code","41fc93ef":"code","a94de245":"code","dc4e30c8":"code","8b568d7e":"code","87eab7b1":"code","766f0f7c":"code","e581d465":"code","dc11ef69":"code","a28479bc":"code","7568504f":"code","c06a3d24":"code","713ced30":"code","6fb98a2f":"code","6edaa66b":"code","7677157b":"code","ad65719e":"code","9a5c565d":"code","c1812d52":"code","61a60b40":"code","3e104d81":"code","aecfec4d":"code","737be7bc":"code","8590443c":"code","2bd0f7e2":"code","30dcd3db":"code","ca254fac":"code","64214906":"markdown","3399bc11":"markdown","e2b7719c":"markdown","62a71526":"markdown","da8107e7":"markdown","c87ace7b":"markdown","84ae0c2b":"markdown","1985e253":"markdown","45bd3cbd":"markdown","d66e5351":"markdown","b9ce9864":"markdown","9c25abdc":"markdown","de510d78":"markdown","39f477f3":"markdown"},"source":{"e3e0fd70":"!pip install bs4","6f668420":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport json\nimport requests\nimport time\nfrom bs4 import BeautifulSoup \nfrom tqdm import tqdm","4ff31907":"session = requests.Session()\nheaders = {\n    \"User-Agents\" : \"Mozilla\/5.0 (iPhone; CPU iPhone OS 7_1_2 like Mac OS X) App leWebKit\/537.51.2 (KHTML, like Gecko) Version\/7.0 Mobile\/11D257 Safari\/9537.53\",\n    \"Accpet\" : \"text\/html,application\/xhtml+xml,application\/xml;q=0.9,image\/webp,*\/*;q=0.8\",\n    \"content-encoding\" : \"gzip\"\n}","41fc93ef":"def extract_response(soup):\n    json_response = soup.prettify()\n    json_dict = json.loads(json_response)\n    info_list = []\n    for item in json_dict['data']['list']:\n        info_map = {}\n        info_map['post_id'] = item['post']['post_id']\n        info_map['subject'] = item['post']['subject']\n        info_map['content'] = item['post']['content']\n        info_map['is_official'] = item['post']['post_status']['is_official']\n        info_map['max_floor'] = item['post']['max_floor']\n        info_map['reply_time'] = item['post']['reply_time']\n        info_map['forum'] = item['forum']['name']\n        info_map['user_level'] = item['user']['level_exp']['level']\n        info_map['view_num'] = item['stat']['view_num']\n        info_map['reply_num'] = item['stat']['reply_num']\n        info_map['like_num'] = item['stat']['like_num']\n        info_map['bookmark_num'] = item['stat']['bookmark_num']\n        info_map['is_official_master'] = item['is_official_master']\n        info_map['is_user_master'] = item['is_user_master']\n        info_map['created_at'] = item['post']['created_at']\n        idx = 1\n        for topic in item['topics']:\n            info_map['topic_' + str(idx)] = topic['name']\n            idx += 1\n        info_list.append(info_map)\n    return info_list, json_dict['data']['last_id']","a94de245":"# target url\nmys_url = \"\"\nnext_page_sfx = \"\"\nnext_page_id = None\ninfo_list = []\n# retrieve data\nfor page_num in range(200):\n    if next_page_id is not None:\n        tar_mys_url = mys_url + next_page_sfx + next_page_id\n    else:\n        tar_mys_url = mys_url\n    my_request = session.get(tar_mys_url, headers=headers)\n    res_msg = my_request.content\n    soup = BeautifulSoup(res_msg, 'html.parser')\n    cur_info_list, next_page_id = extract_response(soup)\n    info_list.extend(cur_info_list)\n    time.sleep(.5)\n    if (page_num + 1) % 10 == 0:\n        print(\"Now in page:\", page_num+1)","dc4e30c8":"data_source = pd.DataFrame(info_list)\ndata_source.to_csv(\"mys_fourm_514.csv\", encoding=\"utf-8\")\ndata_source.head()","8b568d7e":"data_source.info()","87eab7b1":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\ndata_source = pd.read_csv('..\/input\/mrsailmysdataset\/mys_fourm_514.csv')","766f0f7c":"from wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nimport string\nimport jieba\n\nchinese_stopwords = [k.strip() for k in open('..\/input\/english-and-chinese-stopwords\/cn_stopwords.txt', encoding='utf8').readlines() if k.strip() != '']\njieba.enable_paddle()\n\ndef jieba_tokenize(text):\n    punctuations=set(['\uff0c', '\u3002', '\u201c', '\u201d', '\uff1a', '\uff1b', '\uff1f', '\uff01', '\uff08', '\uff09', '*', '\u3010', '\u3011', '\u2019', '\u2018', '\u2014'])\n    for punctuation in punctuations:\n        if punctuation in text:\n            text = text.replace(punctuation, '')\n    tokens = [token for token in list(jieba.cut(text, use_paddle=True)) if token not in chinese_stopwords]\n    return tokens\n\ndef word_count(all_tokens):\n    punctuations = set(string.punctuation)\n    word_cloud = WordCloud(\n        max_words=100, \n        background_color='white', \n        colormap='rainbow', \n        height=600, \n        width=1400, \n        stopwords = punctuations,\n        font_path='..\/input\/mrsailmysdataset\/SIMFANG.TTF'\n    )\n    subjects = all_tokens\n    word_cloud.generate(str(subjects))\n    fig = plt.figure()\n    plt.imshow(word_cloud)\n    fig.set_figwidth(10)\n    fig.set_figheight(10)\n    plt.show()\n\nall_tokens_subject = data_source.subject.apply(lambda x : jieba_tokenize(str(x)))\nword_count(all_tokens_subject)","e581d465":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ncon_attrs = ['max_floor', 'view_num', 'reply_num', 'like_num']\nplt.figure(figsize=(24, 8))\nfor idx in range(len(con_attrs)):\n    plt.subplot(2, 2, idx+1)\n    sns.boxplot(\n        data=data_source,\n        x=con_attrs[idx]\n    )\nplt.show()\ncon_attrs.append('user_level')\nplt.figure(figsize=(9, 5))\nsns.histplot(\n    data=data_source,\n    x='user_level',\n    kde=True\n)\nplt.title(\"Distribution of user level\")\nplt.show()","dc11ef69":"plt.figure(figsize=(20, 20))\nsns.pairplot(\n    data=data_source[con_attrs]\n)\nplt.show()","a28479bc":"corr = data_source[con_attrs].corr()\nplt.figure(figsize=(16, 14))\nsns.heatmap(\n    data=corr,\n    annot=True,\n    square=True\n)\nplt.title(\"Pearson correlation between continous vars\")\nplt.show()","7568504f":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ndata_source['view_like'] = data_source.like_num \/ data_source.view_num\ndata_source['view_reply'] = data_source.reply_num \/ data_source.view_num\ndata_source['like_reply_rate'] = data_source.like_num \/ (data_source.like_num + data_source.reply_num + 1)\ndata_source['avg_reply_floor'] = data_source.reply_num \/ (data_source.max_floor + 1)\n\nfeature_list = ['view_like', 'view_reply', 'like_reply_rate', 'avg_reply_floor']\nplt.figure(figsize=(18,11))\nfor idx in range(len(feature_list)):\n    plt.subplot(2, 2, idx + 1)\n    sns.histplot(\n        data=data_source,\n        x=data_source[feature_list[idx]],\n        kde=True\n    )\nplt.show()","c06a3d24":"# view: 1pt; like: 3pt; reply: 5pt\ndata_source['heat_score'] = np.log(data_source.view_num) + 3 * np.log(data_source.like_num + 1) + 5 * np.log(data_source.reply_num + 1)\n# \u6d4f\u89c8\u8f6c\u5316\u5230\u70b9\u8d5e\uff0c\u56de\u590d\u7684\u51e0\u7387\u66f4\u9ad8\uff0c\u66f4\u591a\u4eba\u53c2\u4e0e\u4ea4\u4e92\u8ba8\u8bba\uff0c\u6bcf\u5c42\u5e73\u5747\u53c2\u4e0e\u56de\u590d\u6570\u9ad8\uff0c\u5e76\u4e14\u5177\u6709\u4e00\u5b9a\u91cf\u4ee5\u4e0a\u7684\u6d4f\u89c8\uff0c\u6d4f\u89c8\u91cf\u6536\u76ca\u4ee5\u5bf9\u6570\u589e\u957f\ndata_source['quality_score'] = (data_source.view_like + 2 * data_source.view_reply + data_source.avg_reply_floor) * np.log(data_source.view_num)\nplt.figure(figsize=(18,5))\nplt.subplot(1, 2, 1)\nsns.histplot(\n    data=data_source['heat_score'],\n    kde=True\n)\nplt.subplot(1, 2, 2)\nsns.histplot(\n    data=data_source['quality_score'],\n    kde=True\n)\nplt.show()\nplt.figure(figsize=(18,2))\nplt.subplot(1, 2, 1)\nsns.boxplot(\n    data=data_source['heat_score'],\n    orient='h'\n)\nplt.subplot(1, 2, 2)\nsns.boxplot(\n    data=data_source['quality_score'],\n    orient='h'\n)\nplt.show()","713ced30":"# 0.0~0.6 (p) | 0.6~0.8 (cr) | 0.8~outlier (d) | outliers\npost_level_dict = {\n    'heat_p' : data_source['heat_score'].quantile(.6),\n    'heat_cr' :  data_source['heat_score'].quantile(.8),\n    'heat_d' : (data_source['heat_score'].quantile(.75) - data_source['heat_score'].quantile(.25)) * 1.5 + data_source['heat_score'].quantile(.75),\n    'qual_p' : data_source['quality_score'].quantile(.6),\n    'qual_cr' :  data_source['quality_score'].quantile(.8),\n    'qual_d' : (data_source['quality_score'].quantile(.75) - data_source['quality_score'].quantile(.25)) * 1.5 + data_source['quality_score'].quantile(.75)\n}\noutstanding_heat_post = data_source[data_source.heat_score > post_level_dict['heat_d']]\noutstanding_quality_post = data_source[data_source.quality_score > post_level_dict['qual_d']]\noutstanding_post = outstanding_heat_post[data_source.quality_score > post_level_dict['qual_d']]\nprint(\"Number of outstanding posts regard to heat score:\", outstanding_heat_post.post_id.count())\nprint(\"Number of outstanding posts regard to quality score:\", outstanding_quality_post.post_id.count())\nprint(\"Number of outstanding posts regard to quality & heat score:\", outstanding_post.post_id.count())","6fb98a2f":"outstanding_post_tokens_subject = outstanding_post.subject.apply(lambda x : jieba_tokenize(str(x)))\nword_count(outstanding_post_tokens_subject)\noutstanding_post_tokens_content = outstanding_post.content.apply(lambda x : jieba_tokenize(str(x)))\nword_count(outstanding_post_tokens_content)","6edaa66b":"outstanding_heat_post_tokens = outstanding_heat_post.subject.apply(lambda x : jieba_tokenize(str(x)))\nword_count(outstanding_heat_post_tokens)\noutstanding_heat_post_tokens_content = outstanding_heat_post.content.apply(lambda x : jieba_tokenize(str(x)))\nword_count(outstanding_heat_post_tokens_content)","7677157b":"outstanding_quality_post_tokens = outstanding_quality_post.subject.apply(lambda x : jieba_tokenize(str(x)))\nword_count(outstanding_quality_post_tokens)\noutstanding_quality_post_tokens_content = outstanding_quality_post.content.apply(lambda x : jieba_tokenize(str(x)))\nword_count(outstanding_quality_post_tokens_content)","ad65719e":"plt.figure(figsize=(24, 5))\nplt.subplot(1, 3, 1)\nsns.histplot(\n    data=outstanding_heat_post,\n    x='user_level',\n    kde=True\n)\nplt.title(\"Distribution of user level - heat posts\")\nplt.subplot(1, 3, 2)\nsns.histplot(\n    data=outstanding_quality_post,\n    x='user_level',\n    kde=True\n)\nplt.title(\"Distribution of user level - quality posts\")\nplt.subplot(1, 3, 3)\nsns.histplot(\n    data=outstanding_post,\n    x='user_level',\n    kde=True\n)\nplt.title(\"Distribution of user level - outstanding posts\")\nplt.show()","9a5c565d":"hd_heat_posts = data_source[data_source.quality_score <= post_level_dict['heat_d']][data_source.quality_score > post_level_dict['heat_cr']]\nhd_qual_posts = data_source[data_source.quality_score <= post_level_dict['qual_d']][data_source.quality_score > post_level_dict['qual_cr']]\nhd_heat_posts_tokens = hd_heat_posts.subject.apply(lambda x : jieba_tokenize(str(x)))\nword_count(hd_heat_posts_tokens)\nhd_qual_posts_tokens = hd_qual_posts.subject.apply(lambda x : jieba_tokenize(str(x)))\nword_count(hd_qual_posts_tokens)","c1812d52":"plt.figure(figsize=(16, 5))\nplt.subplot(1, 2, 1)\nsns.histplot(\n    data=hd_heat_posts,\n    x='user_level',\n    kde=True\n)\nplt.title(\"Distribution of user level - heat posts\")\nplt.subplot(1, 2, 2)\nsns.histplot(\n    data=hd_qual_posts,\n    x='user_level',\n    kde=True\n)\nplt.title(\"Distribution of user level - quality posts\")\nplt.show()","61a60b40":"def heat_level(heat_score, post_level_dict):\n    if heat_score <= post_level_dict['heat_p']:\n        return 0\n    elif heat_score <= post_level_dict['heat_cr']:\n        return 1\n    elif heat_score <= post_level_dict['heat_d']:\n        return 2\n    else:\n        return 3\n\ndef qual_level(qual_score, post_level_dict):\n    if qual_score <= post_level_dict['qual_p']:\n        return 0\n    elif qual_score <= post_level_dict['qual_cr']:\n        return 1\n    elif qual_score <= post_level_dict['qual_d']:\n        return 2\n    else:\n        return 3\n\ndata_source['heat_level'] = data_source.heat_score.apply(lambda x: heat_level(x, post_level_dict))\ndata_source['qual_level'] = data_source.quality_score.apply(lambda x: qual_level(x, post_level_dict))\ndata_source['overall_rating'] = data_source['heat_level'] + data_source['qual_level']","3e104d81":"plt.figure(figsize=(24, 6))\nsns.countplot(\n    data=data_source,\n    x='user_level',\n    hue='overall_rating'\n)\nplt.title(\"Distribution of overall rating w.r.t. user level\")\nplt.show()\nplt.figure(figsize=(24, 6))\nsns.countplot(\n    data=data_source,\n    x='user_level',\n    hue='qual_level'\n)\nplt.title(\"Distribution of quality level rating w.r.t. user level\")\nplt.show()\nplt.figure(figsize=(24, 6))\nsns.countplot(\n    data=data_source,\n    x='user_level',\n    hue='heat_level'\n)\nplt.title(\"Distribution of heat level rating w.r.t. user level\")\nplt.show()","aecfec4d":"import torch\nimport gc\nfrom transformers import AutoModel, AutoConfig, AutoTokenizer, AdamW\nfrom torch.utils.data import TensorDataset, Dataset, DataLoader, RandomSampler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\npretrained = 'bert-base-chinese'\ntokenizer = AutoTokenizer.from_pretrained(pretrained)\n\nbatch_size = 32\nepoch_num = 10\nmax_seq_length = 64","737be7bc":"class PostEvaluator(torch.nn.Module):\n    def __init__(self, bert_model=pretrained, num_class=7):\n        super(PostEvaluator, self).__init__()\n        self.bert_layer = AutoModel.from_pretrained(pretrained_model_name_or_path=bert_model)\n        self.bert_config = AutoConfig.from_pretrained(pretrained_model_name_or_path=bert_model)\n        self.output = torch.nn.Sequential(\n            torch.nn.Linear(self.bert_config.hidden_size, self.bert_config.hidden_size\/\/4),\n            torch.nn.LeakyReLU(),\n            torch.nn.Linear(self.bert_config.hidden_size\/\/4, self.bert_config.hidden_size\/\/2),\n            torch.nn.LeakyReLU(),\n            torch.nn.Linear(self.bert_config.hidden_size\/\/2, num_class),\n        )\n    def forward(self, input_ids, attn_mask=None):\n        bert_out = self.bert_layer(input_ids=input_ids, attention_mask=attn_mask)[1]\n        output = self.output(bert_out)\n        return output\n    \ndef covertTokenFormat(df, tokenizer, max_seq_len):\n    df.content.fillna(' ', inplace=True)\n    texts = df.subject + df.content\n    texts = texts.to_list()\n    title_tokens = tokenizer(texts, padding='max_length', max_length=max_seq_len, truncation=True, return_tensors=\"pt\")\n    labels = torch.tensor(df.overall_rating.to_list(), dtype=torch.long)\n    return title_tokens, labels\n\ndef model_report(pred, label):\n    tar_y = label.squeeze()\n    pred_y = pred.squeeze()\n    acc = accuracy_score(tar_y, pred_y)\n    print(\"accuracy: \", acc)","8590443c":"post_evaluator = PostEvaluator(bert_model=pretrained)\noptimiser = AdamW(post_evaluator.parameters(), lr=1e-5)\nloss_func = torch.nn.CrossEntropyLoss()\ntrain_set, test_set = train_test_split(data_source, test_size=0.2, random_state=77)\n\ntext_tokens, labels = covertTokenFormat(train_set, tokenizer, max_seq_length)\ntrain_data = TensorDataset(text_tokens.input_ids, text_tokens.attention_mask, labels)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)","2bd0f7e2":"def train(post_evaluator, train_dataloader):\n    post_evaluator = post_evaluator.to(device)\n    post_evaluator.train()\n    for epoch in range(epoch_num): \n        epoch_loss = 0\n        pred_lis = torch.Tensor()\n        label_lis = torch.Tensor()\n        for batch, (token_ids, attn_mask, label) in enumerate(train_dataloader):\n            # keep all the parameters in the same device\n            token_ids = token_ids.to(device)\n            attn_mask = attn_mask.to(device)\n            label = label.to(device)\n            # the output will be in the same device with the model\n            outputs = post_evaluator(token_ids, attn_mask)\n            loss = loss_func(outputs.squeeze(), label.squeeze())\n            # do the backprop and update the parameters\n            optimiser.zero_grad()\n            loss.backward()\n            optimiser.step()\n            epoch_loss += loss.cpu().data.numpy()\n            pred_lis = torch.cat([pred_lis, outputs.cpu().squeeze()])\n            label_lis = torch.cat([label_lis, label.cpu().squeeze()])\n        print(\"Now epoch :\", epoch+1, \" Total epoch loss is: \", epoch_loss)\n        model_report(pred_lis.argmax(dim=1).numpy(), label_lis.numpy())\n    torch.save(post_evaluator, '.\/post_evaluator.weights')\n    \ntrain(post_evaluator, train_dataloader)\ngc.collect()\ntorch.cuda.empty_cache()","30dcd3db":"post_evaluator = PostEvaluator(bert_model=pretrained)\npost_evaluator = torch.load('.\/post_evaluator.weights')\npost_evaluator = post_evaluator.to(device)\npost_evaluator.eval()\n\ntest_tokens, test_labels = covertTokenFormat(test_set, tokenizer, max_seq_length)\ntest_data = TensorDataset(test_tokens.input_ids, test_tokens.attention_mask, test_labels)\ntest_sampler = RandomSampler(test_data)\ntest_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=8)\n\nwith torch.no_grad():\n    pred_lis = torch.Tensor()\n    label_lis = torch.Tensor()\n    for batch, (token_ids, attn_mask, label) in enumerate(test_dataloader):\n        token_ids = token_ids.to(device)\n        attn_mask = attn_mask.to(device)\n        label = label.to(device)\n        outputs = post_evaluator(token_ids, attn_mask)\n        pred_lis = torch.cat([pred_lis, outputs.cpu().squeeze()])\n        label_lis = torch.cat([label_lis, label.cpu().squeeze()])\n    model_report(pred_lis.argmax(dim=1).detach().numpy(), label_lis.detach().numpy())","ca254fac":"# # the Stanford Core NLP cannot be used in kaggle notebooks \n# # \u8bb2\u9053\u7406\u56e0\u4e3a\u6ca1\u6cd5\u540c\u65f6\u542f\u52a8\u4e24\u4e2a\u7ebf\u7a0b\uff0c\u4e5f\u5c31\u662f\u8bf4\u4e00\u542f\u52a8\u670d\u52a1\u5668\uff0cnotebook\u5c31\u5361\u5728\u54ea\u91cc\u7b49\u4ed6\u8fd0\u884c\u5b8c\u6bd5\u9000\u51fa\u4e86\uff0c\u7528\u4e0b\u5934\u7684console\u4e5f\u4e0d\u597d\u4f7f\n# # \u7528subprocess.Popen\u4e4b\u7c7b\u53ef\u4ee5\u89e3\u51b3\u5417\uff1f\u8bd5\u8bd5\u770b\uff1f\n# !wget http:\/\/nlp.stanford.edu\/software\/stanford-corenlp-full-2016-10-31.zip\n# !unzip stanford-corenlp-full-2016-10-31.zip && cd stanford-corenlp-full-2016-10-31\n# !wget http:\/\/nlp.stanford.edu\/software\/stanford-chinese-corenlp-2016-10-31-models.jar\n# !wget https:\/\/raw.githubusercontent.com\/stanfordnlp\/CoreNLP\/master\/src\/edu\/stanford\/nlp\/pipeline\/StanfordCoreNLP-chinese.properties \n\n# !cd stanford-corenlp-full-2016-10-31\n\n# !java -Xmx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer \\\n# !-serverProperties ..\/StanfordCoreNLP-chinese.properties \\\n# !-preload tokenize,ssplit,pos,lemma,ner,parse \\\n# !-status_port 9001  -port 9001 -timeout 15000\n\n# from nltk.parse.corenlp import CoreNLPParser \n# text = u'\u4f18\u83c8\u8001\u5a46\u5feb\u6765\u9e2d\uff0c\u6211\u8fd9\u8fb9\u8fd8\u5dee\u51e0\u5341\u672c\u7ecf\u9a8c\u4e66\u8ddf\u5929\u8d4b\u4e66\u5c31\u597d\u5566\uff0c\u8bdd\u8bf4\u4f60\u4eec\u51c6\u5907\u4e86\u591a\u5c11\u5ac1\u5986\u7ed9\u8001\u5a46'\n# # nltk 3.2.4\n# corenlp_parser = CoreNLPParser('http:\/\/localhost:9001', encoding='utf8')\n# result = corenlp_parser.api_call(text, {'annotators': 'tokenize,ssplit'})\n# tokens = [token['originalText'] or token['word'] for sentence in result['sentences'] for token in sentence['tokens']]\n# # nltk 3.2.5\n# sttok = CoreNLPTokenizer('http:\/\/localhost:9001')\n# stoken = sttok.tokenize(text)\n\n# # \u4e2d\u79d1\u9662\u8ba1\u7b97\u6240NLPIR http:\/\/ictclas.nlpir.org\/nlpir\/ \n# # ansj\u5206\u8bcd\u5668 https:\/\/github.com\/NLPchina\/ansj_seg\n# # \u54c8\u5de5\u5927\u7684LTP https:\/\/github.com\/HIT-SCIR\/ltp\n# # \u6e05\u534e\u5927\u5b66THULAC https:\/\/github.com\/thunlp\/THULAC\n# # \u65af\u5766\u798f\u5206\u8bcd\u5668 https:\/\/nlp.stanford.edu\/software\/segmenter.shtml\n# # Hanlp\u5206\u8bcd\u5668 https:\/\/github.com\/hankcs\/HanLP\n# # \u7ed3\u5df4\u5206\u8bcd https:\/\/github.com\/yanyiwu\/cppjieba\n# # KCWS\u5206\u8bcd\u5668(\u5b57\u5d4c\u5165+Bi-LSTM+CRF) https:\/\/github.com\/koth\/kcws\n# # ZPar https:\/\/github.com\/frcchang\/zpar\/releases\n# # IKAnalyzer https:\/\/github.com\/wks\/ik-analy","64214906":"## \u8fd9\u513f\u662f\u4e2a\u6ca1\u80fd\u7528\u6210\u7684\u6211\u6bd4\u8f83\u4e60\u60ef\u7684\u5206\u8bcd\u5668\n- \u53ea\u662f\u6254\u5728\u8fd9\u91cc\u800c\u5df2\uff08x\uff09\n- \u8fd9\u7bc7notebook\u5728\u8fd9\u91cc\u5c31\u7ed3\u675f\u4e86\uff0c\u4e0d\u7528\u7ffb\u5566","3399bc11":"- \u6765\u5427\uff0c\u7ee7\u7eed\u5047\u8bbe\uff0c\u7ed9\u5f97\u5206\u5212\u56db\u4e2a\u7b49\u7ea7\uff1a\n    - p\uff1a\u5dee\uff0c\u5176\u5b9e\u662f\u4e00\u822c\u5566\uff0c\u6bd5\u7adf\u7edd\u5927\u591a\u6570\u5e16\u5b50\u5b83\u90fd\u5f97\u6c89\uff0c\u635e\u90fd\u635e\u4e0d\u52a8\u7684\uff08\u5f97\u5206\u5904\u4e8e\u540e60%\u7684\u5e16\u5b50\uff09\n    - cr\uff1a\u8fd8\u6210\uff0c\u8fd9\u5e16\u5b50\u5e73\u5747\u6c34\u5e73\u671d\u4e0a\u4e86\uff0860%~80%\uff0c\u6709\u4e0d\u5c11\u4eba\u966a\u4f60\u804a\u5929\u54af\u5e16\u4e3b\uff09\n    - d\uff1a\u4f18\u79c0\uff0c\u8fd9\u5e16\u5b50\u4e92\u52a8\u7a0b\u5ea6\u8fd8\u633a\u5f3a\uff0c\u8d34\u4e3b\u8d5a\u4e86\u4e0d\u5c11\u7ecf\u9a8c\u5427\uff1f\uff0880%~outliers\uff09\n    - hd\uff1a\u4e00\u9a91\u7edd\u5c18\uff0c\u4f60\u5df2\u7ecf\u706b\u51fa\u4e86\u6b63\u5e38\u8303\u7574\uff0c\u4e5f\u5c31\u662f\u8bf4\u4f60\u5df2\u7ecf\u706b\u51fa\u5927\u6c14\u5c42\uff0c\u662f\u4e2a\u592a\u7a7a\u4eba\u4e86\uff08\uff1f\uff09\uff0c\u597d\u5e16\uff08outliers\uff09\n- \u53ea\u7edf\u8ba1\u4e86\u5206\u6570\u5927\u7684outliers\u54e6\uff0c\u4e5f\u5c31\u662f\uff1a\u5927\u4e8e`1.5*IQR + Q3`\u7684\u90e8\u5206\n- \u8d85\u7ea7\u5e16\u5b50\u4eec\uff0c\u6765\u4e86\u5c31\u522b\u8d70\u4e86\uff0c\u9664\u4e86\u4e3b\u9898\uff0c\u987a\u8def\u628a\u5185\u5bb9\u4e5f\u4ea4\u51fa\u6765\u8ba9\u5927\u5bb6\u770b\u770b\u4f60\u4eec\u7684\u9ad8\u9891\u8bcd\u662f\u5565\u5457\uff08\u5230\u5e95\u90fd\u5728\u8ba8\u8bba\u5565\uff0c\u8fd9\u4e48\u8d5a\u7ecf\u9a8c\u7684\u5417\uff09\n    - \u70ed\u5ea6\u548c\u8d28\u91cf\u4e24\u8fb9\u7684\u4f18\u8d28\u9009\u624b\u4e5f\u6765\u554a\uff0c\u53d1\u597d\u8d34\u7684\u65b9\u6cd5\uff0c\u90a3\u4e0d\u662f\u8d8a\u591a\u8d8a\u597d","e2b7719c":"- \u6765\u770b\u770b\u8fd9\u51e0\u9879\u8fde\u7eed\u53d8\u91cf\u4e4b\u95f4\u6709\u6ca1\u6709\u4ec0\u4e48\u6bd4\u8f83\u660e\u663e\u7684\u7ebf\u6027\u5173\u7cfb\n- pairplot\u770b\u4e0d\u51fa\u6765\u522b\u62c5\u5fc3\uff0c\u8fd8\u6709heatmap\u5462\uff0c\u79bb0\u8d8a\u8fdc\u4e24\u8005\u8d8a\u76f8\u5173\uff08\u4f60\u53d8\u6211\u4e5f\u53d8\uff09","62a71526":"- \u9664\u4e86\u6700\u9876\u7684\u5e16\u5b50\u4eec\uff0c\u90a3\u4e9b\u8d28\u91cf\u76f8\u5f53\u4e0d\u9519\u7684\u5e16\u5b50\u4eec\u53c8\u5728\u8bf4\u4e9b\u4ec0\u4e48\u5462\n    - \u8bb2\u9053\u7406\u6216\u8bb8\u5b83\u4eec\u624d\u66f4\u7b26\u5408\u6211\u4eec\u5e73\u65f6\u6c34\u5e16\u7684\u6c34\u5e73.jpg\n- \u4e00\u6837\u7684\u6d41\u7a0b\uff0c\u6765\u770b\u770bHD\u5e16\u5b50\u4eec\u5728\u8bf4\u5565\u5427\n    - \u9664\u4e86\u89d2\u8272\u672c\u8eab\uff0c\u89d2\u8272\u57f9\u517b\u4e4b\u7c7b\u7684\u8ba8\u8bba\uff0c\u4f1a\u6709\u4e9b\u65e5\u5e38\u8bdd\u9898\u5417\uff1f","da8107e7":"- \u829c\u6e56\uff0c\u8fd9\u91cc\u6211\u53ef\u628a\u94fe\u63a5\u85cf\u8d77\u6765\u54af\uff08x","c87ace7b":"## \u4ed6\u4eec\u5230\u5e95\u90fd\u5728\u8bf4\u4e9b\u4ec0\u4e48\u554a\n- \u8bfb\u5165\u6574\u4f53\u6570\u636e\uff0c\u6211\u4eec\u6839\u636e\u5e16\u5b50\u7684\u6807\u9898\u6765\u770b\u770b\u73b0\u5728\u5927\u5bb6\u90fd\u5728\u8ba8\u8bba\u4ec0\u4e48\uff1a\n    - \u6b64\u65f6\u6211\u4eec\u628a\u6240\u6709\u62ff\u5230\u7684\u5e16\u5b50\u90fd\u7eb3\u5165\u8003\u8651\n    - \u53ea\u5229\u7528\u5e16\u5b50\u7684\u6807\u9898\uff0c\u5e76\u4e14\u5c06\u5176\u884c\u8fdb\u5206\u8bcd\uff08tokenize\uff09\n    - \u62c6\u89e3\u6210\u8bcd\u65f6\uff0c\u7b5b\u9664\u90a3\u4e9b\u6807\u70b9\u7b26\u53f7\u548c\u505c\u7528\u8bcd\uff08\u672c\u8eab\u4e0d\u542b\u6709\u4ec0\u4e48\u610f\u4e49\u7684\u8bcd\u8bed\u4eec\uff09\uff0c\u6211\u4eec\u60f3\u66f4\u591a\u7684\u53bb\u5173\u5fc3\u540d\u8bcd\u52a8\u8bcd\u4e4b\u7c7b\n    - \u7136\u540e\u5462\uff0c\u628a\u8fd9\u4e9b\u8bcd\u753b\u5230\u56fe\u4e0a\u53bb\uff0c\u51fa\u73b0\u9891\u7387\u8d8a\u9ad8\u5c31\u7ed9\u4ed6\u5199\u8d8a\u5927\uff08\u8fd9\u4e0d\u6bd4\u6253\u5728\u63a7\u5236\u53f0\u91cc\u597d\u770b\u591a\u4e86\uff09\n- \u4f46\u662f\u53ea\u770b\u6574\u4f53\u6570\u636e\u53ef\u4e0d\u592a\u884c\uff0c\u867d\u7136\u5e16\u5b50\u90fd\u633a\u65b0\u7684\uff08\u6700\u8fd1\u624d\u53d1\u5e03\/\u88ab\u56de\u590d\uff09\uff0c\u53ef\u662f\u65b0\u5e16\u5b50\u4e0d\u4ee3\u8868\u5c31\u662f\u70ed\u95e8\u8bdd\u9898\u554a\uff1a\n    - \u9605\u8bfb\u91cf\uff0c\u70b9\u8d5e\u6570\uff0c\u56de\u590d\u91cf\uff0c\u697c\u5c42\u6570\uff0c\u6211\u5047\u8bbe\u8fd9\u4e9b\u80fd\u4f53\u73b0\u5e16\u5b50\u70ed\u5ea6\uff0c\u5f88\u7b80\u5355\uff0c\u5176\u5b9e\u5c31\u662f\u5927\u5bb6\u5728\u548c\u8fd9\u7c7b\u5e16\u5b50\u9ad8\u5f3a\u5ea6\u4e92\u52a8\n    - \u9605\u8bfb\u8f6c\u5316\u6210\u4e3a\u70b9\u8d5e\u548c\u8bc4\u8bba\u7684\u6982\u7387\uff0c\u6211\u5047\u8bbe\u8fd9\u4e2a\u6570\u636e\u80fd\u591f\u4f53\u73b0\u5e16\u5b50\u7684\u8d28\u91cf\uff0c\u540c\u4eba\u653b\u7565\u7c7b\u7684\u597d\u5e16\u5b50\u5927\u6982\u4f1a\u6709\u4e0d\u9519\u7684\u70b9\u8d5e\u8f6c\u5316\u7387\uff0c\u7528\u6237\u53c2\u4e0e\u5ea6\u9ad8\u7684\u5e16\u5b50\u5927\u6982\u7387\u4f1a\u6709\u4e0d\u5c11\u4eba\u8fdb\u6765\u540e\u4f1a\u53d1\u8868\u56de\u590d\n    - \u5e16\u5b50\u8d28\u91cf\uff0c\u70ed\u5ea6\u4f1a\u548c\u8d34\u4e3b\u7684\u7279\u5f81\u76f8\u5173\u5417\uff0c\u6211\u662f\u8bf4\uff0c\u4f1a\u4e0d\u4f1a\u597d\u5e16\u5b50\u597d\u8bdd\u9898\u5927\u591a\u90fd\u662f\u90a3\u4e9b\u7b49\u7ea7\u633a\u9ad8\u7684\u7528\u6237\u4eec\u53d1\u5e03\u7684\u5462\uff1f\n    - \u5f53\u7136\u4e86\uff0c\u4e5f\u8981\u53bb\u770b\u770b\u8fd9\u4e9b\u88ab\u6211\u5b9a\u4e49\u4e3a\u201c\u9ad8\u70ed\u5ea6\u201d\uff0c\u201c\u9ad8\u8d28\u91cf\u201d\u7684\u5e16\u5b50\uff0c\u4ed6\u4eec\u4e3b\u8981\u7684\u8bdd\u9898\u5927\u81f4\u90fd\u662f\u4ec0\u4e48\n- \u554a\u54c8\uff0c\u80fd\u753b\u56fe\uff0c\u5c31\u4e0d\u6253\u6587\u5b57\u4fe1\u606f\uff0c\u8fd8\u662f\u56fe\u597d\u770b","84ae0c2b":"## \u7c73\u6e38\u793e-\u539f\u795e\u677f\u5757\uff1a\u8fd9\u4f1a\u513f\u73a9\u5bb6\u4eec\u90fd\u5728\u4e89\u8bba\u5565\uff1f\n- \u6570\u636e\u6765\u6e90\u4e3a\u7c73\u6e38\u793e\u539f\u795e\u677f\u5757\u6536\u96c6\n- \u6570\u636e\u96c6\u4e0d\u505a\u5f00\u653e\uff0c\u6240\u6709\u6536\u96c6\u6570\u636e\u5747\u4f1a\u5728\u5206\u6790\u540e\u5220\u9664\n- \u6570\u636e\u6293\u53d6\u90e8\u5206\u6709\u6240\u6539\u52a8\uff0c\u4e0d\u76f4\u63a5\u63d0\u4f9b\u6570\u636e\u6293\u53d6\u5730\u5740\n\n## \u6700\u8fd1\u8bba\u575b\u90e8\u5206\u6570\u636e\u7684\u83b7\u53d6\n- \u53ea\u6293\u53d6\u5e16\u5b50\u4eec\u7684\u7b80\u4ecb\u4fe1\u606f\uff0c\u4e0d\u518d\u6df1\u5165\u8c03\u67e5\u6bcf\u4e2a\u5e16\u5b50\uff0c\u8fd9\u4ee3\u8868\uff1a\n    - \u6211\u4eec\u53ea\u6709\u6bcf\u4e2a\u5e16\u5b50\u7684\u4e3b\u9898\uff0c\u4e00\u697c\u5185\u5bb9\uff0c\u4ee5\u53ca\u5176\u6d4f\u89c8\u70b9\u8d5e\u56de\u590d\u6536\u85cf\u91cf\u7b49\u6570\u636e\n    - \u5f53\u7136\u8fd8\u6709\u8d34\u4e3b\u7684\u4e00\u4e9b\u4fe1\u606f\uff0c\u6bd4\u5982\u5176\u6635\u79f0\uff0c\u7b49\u7ea7\u548c\u662f\u5426\u662f\u8ba4\u8bc1\u7528\u6237\u8fd9\u7c7b\u4fe1\u606f\n    - \u5e16\u5b50\u91cc\u7684\u56de\u5e16\uff0c\u697c\u4e2d\u697c\u4e4b\u7c7b\uff0c\u90a3\u4e9b\u5e76\u6ca1\u6709\u6293\u53d6\n- \u5f53\u7136\u4e86\uff0c\u4e0d\u4f1a\u4e00\u6b21\u6027\u6252\u62c9\u592a\u591a\u8d34\u5b50\uff0c\u4e5f\u5c31\u662f\u8bf4\uff1a\n    - \u6211\u4eec\u6bd4\u8f83\u5173\u6ce8\u6700\u8fd1\u5927\u5bb6\u90fd\u5728\u8ba8\u8bba\u5565\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c\u60f3\u770b\u770b\u65b0\u5e16\u5b50\u90fd\u662f\u5173\u4e8e\u5565\u7684\n    - \u5f53\u7136\u4e00\u4e9b\u8001\u662f\u88ab\u9876\u4e0a\u6765\u7684\u8001\u5e16\u5b50\uff0c\u90a3\u5f53\u7136\u4e5f\u662f\u5173\u6ce8\u7684\u5bf9\u8c61\uff0c\u8bc1\u660e\u8bdd\u9898\u70ed\u5ea6\u4e00\u76f4\u6ca1\u6709\u6d88\u9000\u5462\n    - \u6c89\u7684\u98de\u5feb\u7684\u5e16\u5b50\u5f53\u7136\u4e5f\u4e0d\u5728\u70ed\u95e8\u8ba8\u8bba\u4e4b\u5217\uff0c\u5927\u5bb6\u5e76\u4e0d\u5173\u6ce8\n    - \u6211\u4eec\u53ea\u662f\u635e\u70b9\u6570\u636e\u6765\u81ea\u52a8\u5206\u6790\uff0c\u522b\u7ed9\u670d\u52a1\u5668\u592a\u591a\u538b\u529b\uff0c\u70b9\u5230\u4e3a\u6b62\uff0c\u5f71\u54cd\u522b\u7684\u7528\u6237\u6b63\u5e38\u6c34\u5e16\u8ba8\u8bba\u548c\u8bba\u575b\u9ad8\u5f3a\u5ea6PVP\u53ef\u4e0d\u662f\u4ec0\u4e48\u597d\u4e8b","1985e253":"### \u51c6\u5907\u5de5\u4f5c\n- \u6253\u5f00Session\uff0c\u51c6\u5907header\u5c5e\u6027\uff0c\u6211\u4eec\u8981\u53bb\u81ea\u52a8\u8bbf\u95ee\u7c73\u6e38\u793e\u4e86\n- \u83b7\u53d6\u7684\u6570\u636e\u5728\u53d8\u4e3ajson\u683c\u5f0f\u540e\uff0c\u6211\u4eec\u4ece\u4e2d\u63d0\u53d6\u4e00\u4e9b\u4fe1\u606f\uff0c\u653e\u5165\u4e00\u4e2apandas\u7684DataFrame\u4e4b\u4e2d\uff0c\u867d\u7136\u53ef\u4ee5\u7528`post_id`\u4f5c\u4e3aidentity\u4e0d\u8fc7\uff0c\u8fd8\u662f\u8ba9\u5b83\u81ea\u5df1\u4ece0\u6392\u4e00\u4e2a\u65b0\u5217\u65b9\u4fbf\u4f7f\u7528\u5427\n- \u5728\u5199\u5165\u6570\u636e\u96c6\u540e\uff0c\u770b\u770b\u6570\u636e\u7684\u7b80\u7565\u72b6\u6001\uff08\u6bcf\u4e2a\u5c5e\u6027\u4e0b\u4e1c\u897f\u90fd\u957f\u5565\u6837\uff0c\u6bcf\u4e2a\u5c5e\u6027\u91cc\u7684\u6570\u636e\u5b8c\u6574\u5ea6\u5982\u4f55\uff09","45bd3cbd":"- \u8fd8\u8bb0\u5f97\u4e00\u5f00\u59cb\u7684\u8bf4\u6cd5\u5417\uff0c\u6765\u770b\u770b\u53d1\u597d\u5e16\u5b50\u7684\u7528\u6237\u7b49\u7ea7\u5206\u5e03\u6210\u5565\u6837\n    - \u4e0d\u8fc7\u5e16\u5b50\u70ed\u5ea6\u9ad8\uff0c\u4e0d\u7ba1\u600e\u4e48\u6837\u7b49\u7ea7\u90fd\u4f1a\u4e0a\u53bb\u5427\uff08\u7ecf\u9a8c\u8d5a\u7684\u591a\u554a\uff09\n    - \u8003\u8651\u5230\u7c73\u6e38\u793e\u7684\u7ecf\u9a8c\u673a\u5236\uff0c\u5e94\u8be5\u60c5\u51b5\u4e0d\u4f1a\u592a\u4e25\u91cd\uff1f","d66e5351":"## \u5411\u5e16\u5b50\u4eec\u7ed9\u51fa\u7efc\u5408\u8bc4\u5206\n- \u6839\u636e\u70ed\u5ea6\u548c\u8d28\u91cf\uff0c\u7ed9\u5e16\u5b50\u4eec\u6253\u5206\n    - \u60f3\u6c34\u5230\u633a\u591a\u7ecf\u9a8c\u7684\u8bdd\uff0c\u603b\u52063\u5206\u603b\u8981\u6709\u5427\n    - 4\u5206\u7684\uff0c\u5df2\u7ecf\u662f\u975e\u5e38\u524d\u6392\u7684\u5e16\u5b50\u4e86\n    - 5\u4e0e6\u5206\uff0c\u662f\u7ecf\u9a8c\u6536\u5272\u673a\u5462\n- \u628a\u5404\u5206\u6bb5\u7684\u5e16\u5b50\u753b\u51fa\u6765\u770b\u770b\u5404\u6709\u591a\u5c11\u5427","b9ce9864":"- \u8fd9\u91cc\u5c31\u662f\u5047\u8bbe\u533a\u4e86\uff0c\u70ed\u95e8\u8bdd\u9898\uff0c\u9ad8\u8d28\u91cf\u8bdd\u9898\uff0c\u8fd8\u6709\u4e24\u8005\u517c\u5907\u7684\u8d85\u7ea7\u8bdd\u9898\uff1a\n    - \u8fd9\u4e2a\u7ed9\u5206\u52a0\u6743\u7684\u5047\u8bbe\u53ef\u4ee5\u66f4\u6539\uff0c\u4e5f\u53ef\u4ee5\u5229\u7528\u5176\u4ed6\u66f4\u806a\u660e\u7684\u7b56\u7565\uff0c\u603b\u4e4b\uff0c\u6211\u60f3\u4e86\u60f3\u7136\u540e\u51b3\u5b9a\u7b80\u5355\u7c97\u66b4\u7684\u6765\u7b97\n    - \u6211\u4e0d\u5e0c\u671b\u70ed\u5ea6\u6839\u636e\u56de\u590d\u91cf\u7b49\u6570\u636e\u5448\u5b8c\u5168\u7684\u7ebf\u6027\u589e\u957f\uff0c\u6bd5\u7adf\u6709\u4e9b\u65b0\u5e16\u5b50\u786e\u5b9e\u633a\u70ed\u95e8\u7684\uff0c\u4f46\u662f\uff0c\u6ca1\u6709\u65f6\u95f4\u7684\u79ef\u7d2f\u561b\uff0c\u6240\u4ee5\u6211\u7ed9\u4ed6\u5957\u4e0a\u4e86\u5bf9\u6570\u51fd\u6570\uff08\u4f60\u53ef\u6da8\u6162\u70b9\u5427\uff09\n    - \u540c\u6837\u7684\uff0c\u867d\u7136\u8f6c\u5316\u7387\uff0cPVP\u6fc0\u70c8\u7a0b\u5ea6\uff08\u96fe\uff09\u80fd\u4f53\u73b0\u5e16\u5b50\u8bdd\u9898\u7684\u8d28\u91cf\uff08\u662f\u4e0d\u662f\u5438\u5f15\u4eba\uff09\uff0c\u4f46\u662f\u8bb2\u9053\u7406\u561b\uff0c\u4f60\u5f97\u6709\u70b9\u57fa\u7840\u6d4f\u89c8\u91cf\u505a\u652f\u6491\uff0c\u5341\u4e2a\u4eba\u7684\u610f\u89c1\u6bd5\u7adf\u4e0d\u597d\u76f4\u63a5\u62ff\u6765\u548c\u51e0\u5343\u4eba\u6bd4\n    - \u6240\u4ee5\u554a\uff0c\u6700\u540e\u62ff\u6d4f\u89c8\u91cf\u52a0\u4e2a\u6743\uff0c\u4e0d\u8fc7\u8fd8\u662f\u5f97\u6ce8\u610f\uff0c\u6709\u70b9\u70b9\u57fa\u6570\u5c31\u884c\u4e86\uff0c\u5927\u6570\u5b9a\u7406\u561b\uff08\u5927\u96fe -> \u5176\u5b9e\u662f\u91c7\u6837\u6e10\u6e10\u80fd\u4f53\u73b0\u6574\u4f53\u6570\u636e\u7684\u5b9e\u9645\u5206\u5e03\u4e86 -> \u5f25\u5929\u5927\u96fe\uff09\n- \u8001\u6837\u5b50\uff0c\u662f\u9aa1\u5b50\u662f\u9a6c\u753b\u51fa\u6765\u770b\u770b\uff08\uff1f\uff09\n    - \u5bf9\uff0c\u8fd9\u4e0boutliers\u66f4\u6709\u4ef7\u503c\u4e86\uff0c\u8fd9\u4e9boutliers\u53ef\u662f\u70ed\u5ea6\u548c\u8d28\u91cf\u7684\u4f7c\u4f7c\u8005\u554a\uff08\u5f53\u7136\uff0c\u90a3\u5f97\u662f\u70ed\u5ea6\u548c\u8d28\u91cf\u8bc4\u4f30\u8fd8\u7b97\u5408\u7406\u7684\u524d\u63d0\u6761\u4ef6\u4e0b\uff09","9c25abdc":"- \u6839\u636e\u5047\u8bbe\uff0c\u628a\u70b9\u8d5e\u8f6c\u5316\u7387\u554a\uff0c\u56de\u590d\u8f6c\u5316\u7387\u554a\uff0c\u70b9\u8d5e\u5728\u56de\u590d\u548c\u70b9\u8d5e\u603b\u6570\u4e2d\u7684\u5360\u6bd4\u4ee5\u53ca\u5e73\u5747\u6bcf\u5c42\u56de\u590d\u6570\u7b97\u51fa\u6765\n    - \u524d\u4e24\u8005\u5df2\u7ecf\u5728\u4e0a\u5934\u89e3\u91ca\u4e86\u4e00\u4e0b\n    - \u7b2c\u4e09\u9879\u5462\uff0c\u662f\u6211\u731c\u67d0\u4e9b\u8d28\u91cf\u5947\u9ad8\u7684\u5e16\u5b50\uff0c\u6216\u8005\u5185\u5bb9\u53ca\u5176\u7cbe\u5f69\u7684\u5e16\u5b50\uff0c\u4e0d\u5c11\u4eba\u8fdb\u6765\u70b9\u8d5e\uff0c\u8fd8\u88ab\u60ca\u5230\u8bf4\u4e0d\u51fa\u8bdd\u6765\n    - \u7b2c\u56db\u9879\u5c31\u6709\u8da3\u4e86\uff0c\u697c\u4e2d\u697c\u7801\u7684\u8d8a\u9ad8\uff0c\u90a3\u4e48\u5e16\u5b50\u5185\u5c31\u53ef\u4ee5\u8bf4\u662f\u7528\u6237\u4eec\u9891\u7e41\u4ea4\u950b\uff0c\u9ad8\u5f3a\u5ea6PVP\u5e76\u6df1\u5ea6\u4ea4\u6d41\u610f\u89c1\uff0c\u5e16\u5b50\u7684\u8bdd\u9898\u6027\uff0c\u8bdd\u9898\u7684\u70ed\u5ea6\u4ee5\u53ca\u51b2\u7a81\u7a0b\u5ea6\uff0c\u5e94\u8be5\u662f\u76f8\u5f53\u7684\u9ad8\n- \u60ef\u4f8b\uff0c\u628a\u5206\u5e03\u753b\u51fa\u6765\n    - \u56fe\u4e2d\u76840\u5e94\u5f53\u662f\u4e0d\u5c11\uff0c\u90a3\u4e5f\u6ca1\u529e\u6cd5\uff0c\u6bd4\u8f83\u5f88\u591a\u5e16\u5b50\u6ca1\u4eba\u70b9\u8d5e\u6ca1\u4eba\u56de\u590d\uff0c\u53ea\u6709\u5e16\u4e3b\u81ea\u5df1\u53ef\u601c\u76841\u6709\u6548\u6d4f\u89c8\u91cf\uff08\u554a\u8fd9\uff09\n    - \u5f53\u7136\u4e3a\u4e86\u907f\u514d\u96640\u561b\uff0c\u540e\u4e24\u8005\u8ba1\u7b97\u7684\u65f6\u5019\u7ed9\u5206\u6bcd\u52a0\u4e0a\u4e86\u4e2a1\uff08\u4e0d\u8fc7\u6211\u5012\u662f\u6ca1\u53bb\u6ce8\u610f\u662f\u4e0d\u662fmax_floor\u4e5f\u662f\u6700\u5c11\u67091\u7684\u5e16\u4e3b\u81ea\u5df1\u90a3\u5c42\uff09","de510d78":"## \u7b80\u5355\u7684\u505a\u4e00\u70b9\u70b9\u70b9\u70b9NLP\uff0c\u6839\u636e\u5e16\u5b50\u4e3b\u9898\u5185\u5bb9\uff0c\u6765\u5224\u65ad\u8fd9\u4e2a\u5e16\u5b50\u80fd\u4e0d\u80fd\u706b\n- \u6bd4\u8f83\u73a9\u7b11\u6027\u8d28\uff0c\u7eaf\u5c5e\u4e2a\u4eba\u7ec3\u624b\uff0c\u540e\u5934\u57fa\u672c\u6ca1\u5565\u5206\u6790\u5185\u5bb9\u4e86\n- \u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u8fd9\u53ef\u662f\u4e2a\u597d\u4e1c\u897f\n- huggingface\u7684\u4e2d\u6587tokenizer\u5176\u5b9e\u50bb\u50bb\u7684\uff0c\u5b83\u76f4\u63a5\u6309\u5355\u5b57\u62c6\u5206\uff08\u8c01\u7ba1\u4f60\u6210\u4e0d\u6210\u8bcd\uff09\n- \u800c\u4e14\u6211\u603b\u89c9\u5f97BERT\u5427\uff0c\u5b83\u4e0d\u662f\u7279\u522b\u7684\u5173\u6ce8\u8bed\u5e8f\u8fd9\u4ef6\u4e8b\u60c5\uff08\u4e0d\u7136\u5e72\u561b\u52a0\u5165PosEncoding\uff09\n- \u5bb3\uff0c\u8fd9\u4e9b\u90fd\u4e0d\u8be5\u662f\u6211\u8fd9\u83dc\u9e1f\u62c5\u5fc3\u7684\u4e8b\u513f","39f477f3":"- \u6765\u770b\u770b\u51e0\u4e2a\u8fde\u7eed\u6570\u636e\u5404\u81ea\u7684\u5206\u5e03\u72b6\u51b5\uff0c\u8fd9\u91cc\u51fa\u73b0\u7684outliers\u79bb\u7fa4\u503c\u76f8\u5f53\u6709\u4ef7\u503c\uff08\u603b\u6709\u90a3\u4e48\u51e0\u4e2a\u5e16\u5b50\u9e64\u7acb\u9e21\u7fa4\uff0c\u5927\u6982\uff09\n- \u8fd8\u6709\u5e16\u4e3b\u7684\u7b49\u7ea7\u5206\u5e03\uff08\u540e\u8fb9\u53ef\u4ee5\u7528\u6765\u5bf9\u6bd4\u770b\u770b\u53d1\u5e03\u201c\u597d\u201d\u5e16\u5b50\u7684\u7528\u6237\u7b49\u7ea7\u5206\u5e03\u72b6\u51b5\uff09"}}