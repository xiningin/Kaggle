{"cell_type":{"bea2bd6e":"code","4e050128":"code","689db3e9":"code","4fab2920":"code","f4cf03ce":"code","45eb457f":"code","b3b57586":"code","44609629":"code","24f882ee":"code","c2563be1":"code","725dda52":"code","80e773b1":"code","b2f16016":"code","5b1817b6":"code","a5113480":"code","50100965":"code","2ea2f8e5":"code","81ca7348":"code","1784e60b":"code","3299481e":"code","3ceac426":"code","68fbe49d":"code","c2694e57":"code","41af9e90":"code","bef650b0":"code","063d7b81":"code","5c511b98":"code","01413a1d":"code","a9c271c0":"code","2fbdbabf":"code","d6a103fd":"code","50c7d750":"code","2f4717c1":"code","a2275b43":"code","2f8722c6":"code","4c96e9d4":"code","d3d72584":"code","911f4c3f":"code","337230cc":"code","4181741e":"code","58cfff27":"code","b6a6f777":"code","25f97519":"code","6d27e1d5":"code","0ec088a0":"code","c61ea5d7":"code","0e35e008":"markdown","969d03cd":"markdown","cdf27a57":"markdown","1d96bb12":"markdown","ab358786":"markdown","34465438":"markdown","48f306a6":"markdown","f10e69c2":"markdown","b11463f8":"markdown","30793780":"markdown","c2fd96c9":"markdown","fe59728e":"markdown","6cf22ad9":"markdown","666c0273":"markdown","1cb8e89e":"markdown","c3d6de8a":"markdown","95903a25":"markdown"},"source":{"bea2bd6e":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set_theme(style=\"darkgrid\")","4e050128":"df=pd.read_csv('..\/input\/employee-future-prediction\/Employee.csv')","689db3e9":"df","4fab2920":"df.head()","f4cf03ce":"df.columns","45eb457f":"df.corr()","b3b57586":"#Global declartions of function names\nglobal Head\nglobal Size\nglobal Column_names\nglobal Describe\nglobal Shape\nglobal Count\nglobal Value_count\nglobal ISNULL\nglobal Tail\nglobal Ndim\nglobal Nunique\nglobal Memory_usage\nglobal Duplicated\nglobal ISNA\nglobal DTYPES\nglobal CORR\nglobal Info\nglobal operations\n        \n\n        \n        ","44609629":" def Tail():\n    print('\\033[1m'+\"The last five rows of the dataframe are\"+'\\033[0m')\n    co3=df.tail()\n    return(co3)\n    print(\"--------------------------------------------------------------------------\")\nTail()\n","24f882ee":"def Describe():\n    print('\\033[1m'+\"The Description of our dataset is:\"+'\\033[0m')\n    des=df.describe()\n    return(des)\n    print(\"--------------------------------------------------------------------------\")\nDescribe()","c2563be1":"def Count():\n    print('\\033[1m'+\"The count of non null values are:\"+'\\033[0m')\n    co=df.count()\n    print(co,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nCount()\n","725dda52":"def Memory_usage():\n    print('\\033[1m'+\"The total memory used is :\"+'\\033[0m')\n    co6=df.memory_usage()\n    print(co6,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nMemory_usage()","80e773b1":"def DTYPES():\n    print('\\033[1m'+\"The datatypes are :\"+'\\033[0m')\n    co9=df.dtypes\n    print(co9,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nDTYPES()","b2f16016":"def Info():\n    print('\\033[1m'+\"The info of data set is :\"+'\\033[0m')\n    co11=df.info()\n    print(\"--------------------------------------------------------------------------\")\nInfo()","5b1817b6":"def operations(df,x):\n    if df[x].dtype==\"float64\":\n        print('\\033[1m'+'', x, 'rows'+'\\033[0m')\n        print('\\033[1m'+\"It is a quantitaive data \\n\"+'\\033[0m')\n        print(\"The mean is :\\n\",df[x].mean())\n        print(\"The median is :\\n\",df[x].median())\n        print(\"The Standard Deviation is \\n\",df[x].std())\n        q1=df[x].quantile(0.25)\n        q2=df[x].quantile(0.5)\n        q3=df[x].quantile(0.75)\n        IQR=q3-q1\n        LLP=q1-1.5*IQR\n        ULP=q3+1.5*IQR\n        print(\"The quartiles are q1 : \\n\",q1)\n        print(\"The quartiles are q2 : \\n\",q2)\n        print(\"The quartiles are q3 :\\n \",q3)\n        print(\"The Uppler limit point of the data is \\n\",ULP)\n        print(\"The lower limit point of the data is \\n \",LLP)\n        if df[x].min()>LLP and df[x].max()<ULP:\n            print(\"The outliers are not present \\n\")\n            print(\"--------------------------------------------------------------------------\")\n\n        else:\n\n            print(\"The outliers are present \\n\")\n            print(\"The outliers are :\")\n            print(df[df[x].values>ULP][x])\n            print(df[df[x].values<LLP][x])\n\n            print(\"--------------------------------------------------------------------------\")\n\n\n    elif df[x].dtype==\"int64\":\n        print('\\033[1m'+'', x, 'rows'+'\\033[0m')\n        print('\\033[1m'+\"It is a quantitaive data \\n\"+'\\033[0m')\n        print(\"The mean is : \\n\",df[x].mean())\n        print(\"The median is : \\n\",df[x].median())\n        print(\"The Standard Deviation is \\n\",df[x].std())\n        q1=df[x].quantile(0.25)\n        q2=df[x].quantile(0.5)\n        q3=df[x].quantile(0.75)\n        IQR=q3-q1\n        LLP=q1-1.5*IQR\n        ULP=q3+1.5*IQR\n        print(\"The quartiles are q1 : \\n\",q1)\n        print(\"The quartiles are q2 : \\n\",q2)\n        print(\"The quartiles are q3 : \\n\",q3)\n        print(\"The Uppler limit point of the data is \\n\",ULP)\n        print(\"The lower limit point of the data is \\n\",LLP)\n        if df[x].min()>LLP and df[x].max()<ULP:\n            print(\"The outliers are not present \\n\")\n\n            print(\"--------------------------------------------------------------------------\")\n\n        else:\n\n            print(\"The outliers are present \\n\")\n            print(\"The outliers are :\")\n            print(df[df[x].values>ULP][x])\n            print(df[df[x].values<LLP][x])\n            print(\"--------------------------------------------------------------------------\")\n\n\n\n\n\n\n\n    else:\n\n        print('\\033[1m'+\"The data is Qualitative \\n\"+'\\033[0m')\n\n\n        if df[x].nunique()==1:\n            print('\\033[1m'+\"The data is singular \\n\"+'\\033[0m')\n            print(\"The mode is :\",df[x].mode())\n            print(\"The count of mode is \\n\",df[x].value_counts())\n        elif df[x].nunique()==2:\n            print('\\033[1m'+\"The data is Binary \\n\"+'\\033[0m')\n            print(\"The mode is :\",df[x].mode())\n            print(\"The count of mode is \\n\",df[x].value_counts())\n        elif df[x].nunique()>2:\n            print('\\033[1m'+\"The data is Multi \\n\"+'\\033[0m')\n            print(\"The mode is :\",df[x].mode())\n            print(\"The count of mode is \\n\",df[x].value_counts())\n\n        print(\"--------------------------------------------------------------------------\")\n\nc=df.columns\nfor i in c:\n    operations(df,i)\n    print(\"\\n\")\n\n\n","a5113480":"def Summary():\n        print('\\033[1m'+\"The Summary of data is  \\n\"+'\\033[0m')\n        print(\"The shape of the datset is :\",df.shape)\n        print(\"The sixe o the data set is :\",df.size)\n        print(\"The dimensions of the dataset are:\",df.ndim)\n        print(\"The memory usage of the data set are\",df.memory_usage())\n        print(\"The data types of the dataset are:\",df.dtypes)\n        print(\"--------------------------------------------------------------------------\")\n\nSummary()     \n","50100965":" def Column_Summary():\n        print('\\033[1m'+\"The Column wise Summary of data is  \\n\"+'\\033[0m')\n        k=df.columns\n        for i in k:\n            print('\\033[1m'+'', i, 'rows'+'\\033[0m')\n            print(\"The Shape of the column \",i,\"is \",df[i].shape)\n            print(\"The Size of the column \",i,\"is \",df[i].size)\n            print(\"The Dimensions of the column \",i,\"is \",df[i].ndim)\n            print(\"The Memory used by the column \",i,\"is \",df[i].memory_usage())\n            print(\"The Data types  of the column \",i,\"is \",df[i].dtypes)\n            print(\"--------------------------------------------------------------------------\")\nColumn_Summary()","2ea2f8e5":"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n\nnewdf = df.select_dtypes(include=numerics)\nl=newdf.columns","81ca7348":"for i in l:\n    sns.distplot(df[i],kde=True)\n    plt.show()\n    ","1784e60b":"\nsns.countplot(data=df,x='JoiningYear',hue='LeaveOrNot')","3299481e":"sns.countplot(data=df,x='EverBenched',hue='LeaveOrNot')","3ceac426":"sns.countplot(data = df ,x='ExperienceInCurrentDomain',hue='LeaveOrNot')","68fbe49d":"sns.countplot(data = df ,x='Education',hue='LeaveOrNot')","c2694e57":"sns.countplot(data = df ,x='City',hue='LeaveOrNot')","41af9e90":"sns.countplot(data = df ,x='Age',hue='LeaveOrNot')","bef650b0":"sns.countplot(data = df ,x='JoiningYear',hue='Gender')","063d7b81":"plt.figure(figsize=(10,16))\nax = sns.heatmap(df.corr(),annot = True, cmap = 'viridis')\nplt.show()","5c511b98":"df.isnull().sum()","01413a1d":"def count_outliers(data,col):\n        q1 = data[col].quantile(0.25,interpolation='nearest')\n        q2 = data[col].quantile(0.5,interpolation='nearest')\n        q3 = data[col].quantile(0.75,interpolation='nearest')\n        q4 = data[col].quantile(1,interpolation='nearest')\n        IQR = q3 -q1\n        global LLP\n        global ULP\n        LLP = q1 - 1.5*IQR\n        ULP = q3 + 1.5*IQR\n        if data[col].min() > LLP and data[col].max() < ULP:\n            print(\"No outliers in\",i)\n        else:\n            print(\"There are outliers in\",i)\n            x = data[data[col]<LLP][col].size\n            y = data[data[col]>ULP][col].size\n            a.append(i)\n            print('Count of outliers are:',x+y)\nglobal a\na = []\nfor i in l:\n    count_outliers(df,i)","a9c271c0":"def LABEL_ENCODING(c1):\n    from sklearn import preprocessing\n    # label_encoder object knows how to understand word labels.\n    label_encoder = preprocessing.LabelEncoder()\n \n    # Encode labels in column 'species'.\n    df[c1]= label_encoder.fit_transform(df[c1])\n \n    df[c1].unique()\n    return df","2fbdbabf":"LABEL_ENCODING('Education')","d6a103fd":"LABEL_ENCODING('Gender')","50c7d750":"LABEL_ENCODING('City')","2f4717c1":"LABEL_ENCODING('EverBenched')","a2275b43":"feature=df.drop('LeaveOrNot',axis=1)","2f8722c6":"label=df['LeaveOrNot']","4c96e9d4":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(feature)","d3d72584":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nX_train,X_test,y_train,y_test=train_test_split(feature,label,test_size=.3)\n","911f4c3f":"!python3 -m pip install -q evalml==0.28.0","337230cc":"!pip install delayed","4181741e":"import evalml\nevalml.problem_types.ProblemTypes.all_problem_types","58cfff27":"from evalml.automl import AutoMLSearch\nautoml = AutoMLSearch(X_train=X_train, y_train=y_train, problem_type='binary')\nautoml.search()","b6a6f777":"automl.rankings","25f97519":"automl.best_pipeline","6d27e1d5":"best_pipeline=automl.best_pipeline","0ec088a0":"automl.describe_pipeline(automl.rankings.iloc[0][\"id\"])","c61ea5d7":"### Evaluate on hold out data\nbest_pipeline.score(X_test, y_test, objectives=[\"auc\",\"f1\",\"Precision\",\"Recall\"])","0e35e008":"# Data Modelling ","969d03cd":"From the above observation we can say that employess with Bachelors degree have the highest exits,followed by Masters and PHD.","cdf27a57":"From the above observation we can say that,The employees with experience 2 years have highest number of exits from the company","1d96bb12":"## Encoding","ab358786":"# Feature Engineering","34465438":"# Exploratory Data Analysis","48f306a6":"# Data Visulaization","f10e69c2":"# Importing Required Libraries","b11463f8":"## Count of Outliers","30793780":"# EDA Summary","c2fd96c9":"## Distribution Plots","fe59728e":"## Relation Plots","6cf22ad9":"from the above observation we can say that employess who have been benched have never left the company","666c0273":"Employees from city Pune has highest exits followed by Banglore and New Delhi","1cb8e89e":"In the year 2017 there are highest number of joinings for male and females in the company ","c3d6de8a":"From the above observation we can say that in the year 2018 most employess left.\nIn the year 2012 least people have left the company.","95903a25":"# Data Cleaning and Preproccessing"}}