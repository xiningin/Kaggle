{"cell_type":{"c38edfa2":"code","696a8777":"code","222b5d3c":"code","d3e17db9":"code","05f8afcf":"code","fa6c0ddf":"code","5c829e46":"code","5fed4894":"code","f0f31d91":"code","247fdfc6":"code","0c7602f3":"code","b45c647d":"code","78b3fd00":"code","2aa17fdb":"code","7ce5b63c":"code","30cb8bf0":"code","b974b08a":"code","c9aa29c1":"code","10d81fea":"code","cc82d65f":"code","3436bf08":"code","9d0786bc":"code","a5acf29d":"code","d8f8cbf2":"code","1b674b2f":"code","7d10bedd":"code","3bd45c97":"code","6fdc6301":"code","6d7b89a3":"code","10bfc1e4":"code","a4992dfd":"code","17019d57":"code","cbbb88f2":"code","695acbad":"code","7b842e19":"code","7be07d90":"code","880136b8":"code","d710d0ce":"code","9c04c4f0":"code","1209207f":"markdown","516db71f":"markdown","883e9f19":"markdown","d725fe5c":"markdown","6994d05b":"markdown","37f02b95":"markdown","571ddca3":"markdown","6e87d681":"markdown","a8a4fc07":"markdown","8e049356":"markdown","1ea0a053":"markdown","0f89869b":"markdown","9b76a15c":"markdown","671bcf38":"markdown","62b5c675":"markdown"},"source":{"c38edfa2":"#importing libraries.\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","696a8777":"df = pd.read_csv('\/kaggle\/input\/breast-cancer-wisconsin-data\/data.csv')","222b5d3c":"df","d3e17db9":"df.shape # The number of rows and columns","05f8afcf":"df.info()","fa6c0ddf":"df.describe()","5c829e46":"df.diagnosis","5fed4894":"df.diagnosis.values","f0f31d91":"df.diagnosis.value_counts()","247fdfc6":"df.diagnosis.value_counts().plot(kind=\"bar\", \n                                 title=\"Counts of Diagnosis Types\", \n                                 xlabel=\"Type\", \n                                 ylabel=\"Count\")","0c7602f3":"x = df.diagnosis.value_counts()\nlabels = [ \"Benign\",\"Malignant\"]\nplt.pie(x, labels =labels, autopct = '%.0f%%')\nplt.show()","b45c647d":"df.corr()","78b3fd00":"df_mean = df.loc[: , 'radius_mean' : \"fractal_dimension_mean\" ] ","2aa17fdb":"df_mean","7ce5b63c":"df_mean.corr()","30cb8bf0":"corr = df_mean.corr()\nplt.figure(figsize=(10,8))\nsns.heatmap(corr,  cmap= \"Greens\", linewidths=1.25 )\nplt.show()","b974b08a":"sns.pairplot(df_mean)","c9aa29c1":"#for se columns\nse_df = df.loc[:, \"radius_se\" : \"fractal_dimension_se\"]","10d81fea":"se_df.corr()","cc82d65f":"plt.figure(figsize=(10,8))\nsns.heatmap(se_df.corr(),  cmap= \"Blues\", linewidths=1.25, linecolor= \"black\" )\nplt.show()","3436bf08":"#importing the necessary libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import scale \nfrom sklearn.svm import SVC\nfrom sklearn import metrics\nfrom sklearn.metrics import (precision_score,\n                            accuracy_score,\n                            recall_score,\n                            f1_score)\n","9d0786bc":"#To ferform feature engineering is to select the atrributes needed for model development\ndf.info()","a5acf29d":"df = df.drop(\"id\", axis = 1)","d8f8cbf2":"df = df.drop(\"Unnamed: 32\", axis = 1)","1b674b2f":"df","7d10bedd":"# To divide our features from target\nX = df.loc[:, \"radius_mean\" : \"fractal_dimension_worst\"] #features\ny = df[\"diagnosis\"] # target","3bd45c97":"X","6fdc6301":"y","6d7b89a3":"y = y.replace({\"M\" : 1, \"B\" : 0}) # changing the diagnosis to numbers so that we can pass it to our model","10bfc1e4":"y","a4992dfd":"X_train, X_test, y_train, y_test = train_test_split(X,y,)\n#splitting the data into trainnig and testing set.\n#using default hyper peremeters.","17019d57":"# to normalize the data we scale it.\nX_train_scaled = scale(X_train)\nX_test_scaled = scale(X_test)","cbbb88f2":"svc=SVC() \nsvc.fit(X_train_scaled,y_train)\ny_pred=svc.predict(X_test_scaled)","695acbad":"print(f'Accuracy Score is {accuracy_score(y_test,y_pred)}')","7b842e19":"# precision tp \/ (tp + fp)\nprecision = precision_score(y_test, y_pred)\nprint('Precision: %f' % precision)","7be07d90":"# recall: tp \/ (tp + fn)\nrecall = recall_score(y_test, y_pred)\nprint('Recall: %f' % recall)\n","880136b8":"f1score = 2*((precision*recall)\/(precision+recall))\nprint('F1 score: %f' % f1score)","d710d0ce":"def find_TP(y, y_pred):\n    # counts the number of true positives (y = 1, y_pred = 1)\n    return sum((y == 1) & (y_pred == 1))\ndef find_FP(y, y_pred):\n    # counts the number of false negatives (y = 1, y_pred = 0)\n    return sum((y == 0) & (y_pred == 1))\ndef find_FN(y, y_pred):\n    # counts the number of false positives (y = 0, y_pred = 1)\n    return sum((y == 1) & (y_pred == 0))\ndef find_TN(y, y_pred):\n    # counts the number of true negatives (y = 0, y_pred = 0)\n    return sum((y == 0) & (y_pred == 0))","9c04c4f0":"print('TP:',find_TP(y_test, y_pred))\nprint('FN:',find_FN(y_test, y_pred))\nprint('FP:',find_FP(y_test, y_pred))\nprint('TN:',find_TN(y_test, y_pred))","1209207f":"This marks the end of our module. \nThank you!!!","516db71f":"Plotting the correlation graph(also known as heatmap) for all the columns of the dataset will not make it easy to get insight.\nFrom the description of our dataset, only ten real-valued features were computed for each cell nucleus.The mean, standard error and \"worst\" or largest (mean of the three largest values) of these features were computed for each image,resulting in 30 features.\nWe can therefore divide the dataset into 3 parts, the mean standard error and the worst for easy anlysis.","883e9f19":"## PERFORMANCE","d725fe5c":"In this section we dive into our dataset and provide an analysis of the attributes of the datset.\nOur main focus will be on:\n(a) Finding is thier exist a correlation between the attributes of our dataset.\n(b) Providing a visual proof of the correlation.\nThe class distribution of the diagnosis column will also be discussed here.","6994d05b":"In these section, we\n(a) Ferform feature engineering.\n(b) Standardize our data.\n(c) Split our data for trainning and testing.\n(d) Build our model and\n(e) Measure it's performance.","37f02b95":"## Correlation","571ddca3":"In these section, we: \n(a)import the necessary librarires to perform data analysis and\n(b)Provide a description of our dataset.","6e87d681":"# Data Analysis","a8a4fc07":"# INTRODUCTION\n","8e049356":"### Obsevations","1ea0a053":"## Class distribution","0f89869b":"For our feature engineering we remove the first and the last column titled: \"ID\" and \"Unnamed: 32\" respectively because:\n1. The id column is an identifier and not a property of the nuclei.\n2. The column unmaned does not contain any value.","9b76a15c":"!!!\nHere also all the relations found in the mean columns are also present.\nWe can therefore conclude that the relations will also hold for the worst columns.","671bcf38":"We can now see that the columns\n(a) Radius, perimeter, area and concave points are related to one another.\n(b) compactness, concavity and concave point are related to one another.\n(b) Texture, smoothness symmetry and fractal_dimension do not relate to any column.","62b5c675":"# MODEL DEVELOPMENT"}}