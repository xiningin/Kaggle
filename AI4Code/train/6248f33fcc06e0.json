{"cell_type":{"d0d0618d":"code","b89e496f":"code","8dcb8d50":"code","c0c9d09c":"code","ab8bda95":"code","aac2c5e6":"code","80850a58":"code","dd2cab7d":"code","139b9d88":"code","03a95267":"code","e9ffe9f1":"code","34d7ef2b":"code","542f696e":"code","2825e7fc":"code","21795f18":"code","0ae5ae1a":"code","3d31d91f":"code","b0408da3":"code","08122404":"code","e61e4df5":"code","5b2f9f48":"code","788e68be":"markdown","f351837b":"markdown","77e71ef7":"markdown","8b626355":"markdown","eab44f81":"markdown","23094ded":"markdown","eae901b8":"markdown","6aeb380a":"markdown","ac1ac12b":"markdown","8428a925":"markdown"},"source":{"d0d0618d":"!python --version\nimport torch # For Convolutional Neural Network\nimport torchvision # \"\"\nimport torchvision.transforms as transforms # \"\"\nimport torch.nn as nn # \"\"\nimport torch.nn.functional as F # \"\"\nimport torch.optim as optim # Neural net optimizer\nimport pandas as pd # For loading csv data\nimport matplotlib.pyplot as plt # For showing images\nimport os, os.path # For sorting training images\nimport shutil # \"\"\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","b89e496f":"train_data = pd.read_csv(\"..\/input\/melanoma-image-data\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/melanoma-image-data\/test.csv\")","8dcb8d50":"train_data.head()","c0c9d09c":"test_data.head()","ab8bda95":"def move_images(data, root):\n    images = [name for name in os.listdir(root) \n              if os.path.isfile(os.path.join(root, name))]\n    if images:\n        file_names = data['image_name'].tolist()\n        for file in file_names:\n            classification = data[data['image_name'] == \n                                  file]['benign_malignant'].values[0]\n            shutil.move(root + file + '.jpg', \n                        root + classification + '\/' + file + '.jpg')","aac2c5e6":"move_images(train_data, '..\/input\/melanoma-image-data\/train\/train\/')","80850a58":"train_image_data = torchvision.datasets.ImageFolder(\n        '..\/input\/melanoma-image-data\/train\/train\/',\n        transform=transforms.Compose([\n                  transforms.Resize((512, 512)),\n                  transforms.RandomHorizontalFlip(),\n                  transforms.RandomVerticalFlip(),\n                  transforms.ToTensor()])\n)\nn = len(train_image_data)  # total number of examples\nn_valid = int(0.1 * n)  # take ~10% for validation\nvalid_set, train_set = torch.utils.data.random_split(train_image_data, [n_valid, n - n_valid])\n\nvalidationloader = torch.utils.data.DataLoader(valid_set, shuffle=True)","dd2cab7d":"images, labels = next(iter(validationloader))\nplt.imshow(images[0][0])\nprint(labels[0].item())\nprint(images[0][0].shape)","139b9d88":"class Net(nn.Module): \n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, 3, 2)\n        self.conv2 = nn.Conv2d(32, 64, 3, 2)\n        self.conv3 = nn.Conv2d(64, 128, 3, 2)\n        self.norm1 = nn.BatchNorm2d(32)\n        self.norm2 = nn.BatchNorm2d(64)\n        self.norm3 = nn.BatchNorm2d(128)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(6272, 128)\n        self.fc2 = nn.Linear(128, 64)\n        self.fc3 = nn.Linear(64, 1)\n        self.dropout1 = nn.Dropout(p=0.1, inplace=False)\n\n    def forward(self, x):\n        x = self.norm1(self.pool(F.relu(self.conv1(x))))\n        x = self.norm2(self.pool(F.relu(self.conv2(x))))\n        x = self.norm3(self.pool(F.relu(self.conv3(x))))\n        x = self.dropout1(x)\n        x = x.view(-1, 6272)\n        x = self.dropout1(x)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x","03a95267":"def binary_acc(y_pred, y_test):\n    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n    acc = (y_pred_tag == y_test).sum().float()\n    acc = torch.round(acc * 100)\n    \n    return acc","e9ffe9f1":"count = train_data.groupby('benign_malignant').count()\nfor index, row in count.iterrows():\n    print(f'Count {index}: {row[0]}')","34d7ef2b":"# got to get array of labels. This is slowwwwwwwwwwwwwwwwwwwwwwwwwww\nclass_arr = [0 if label == 0 else 1 for _, label in train_set]\nreciprocal_weights = [0 for index in range(len(train_set))]\ncount0, count1 = 32542, 584\n\nmarg = count0 + count1\nprob = [count0 \/ marg, count1 \/ marg]\nfor index in range(len(train_set)):\n    reciprocal_weights[index] = prob[class_arr[index]]\n\nweights = (1 \/ torch.Tensor(reciprocal_weights))\nprint(torch.unique(weights))","542f696e":"num_samples = 1024\nbatch_size = 64\nnets = [Net() for i in range(3)]\ncriterion = nn.BCEWithLogitsLoss()\n\nfor n in nets:\n    n.cuda()","2825e7fc":"for index, n in enumerate(nets):\n    PATH = f'..\/input\/net-data\/ensemble_net_{index}.pth'\n    n.load_state_dict(torch.load(PATH))","21795f18":"for index, net in enumerate(nets):\n    optimizer = optim.Adam(net.parameters(), lr=0.001)\n    net.train()\n    EPOCHS = 10\n    print(f'STARTING TRAINING NET {index}')\n    running_loss, running_acc = 0, 0\n    for e in range(EPOCHS):\n        sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, \n                             num_samples, replacement=True)\n        sampler = torch.utils.data.BatchSampler(sampler, batch_size, \n                             drop_last=True)\n        loader = torch.utils.data.DataLoader(train_set,\n                                     batch_sampler = sampler,\n                                     num_workers = 8) # stable\n        for i, (x, y) in enumerate(loader, 0):\n            images, labels = x.cuda(), y.cuda()\n            labels = labels.float()\n            optimizer.zero_grad()\n\n            y_pred = net(images).cuda()\n            loss = criterion(y_pred, labels.unsqueeze(1))\n            acc = binary_acc(y_pred, labels.unsqueeze(1))\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item() \n            running_acc += acc.item() \n\n        print('#', end='')\n        if e % 10 == 9:\n            print('|', end='')\n    print('\\n[net %d epochs %d], loss: %.3f, acc: %2.2f%%' %\n          (index, EPOCHS, \n           running_loss \/ (EPOCHS * num_samples), \n           running_acc \/ (EPOCHS * num_samples)))\n    PATH = f'.\/ensemble_net_{index}.pth'\n    torch.save(net.state_dict(), PATH)  \n    ","0ae5ae1a":"def get_majority_vote(pred_list):\n    return 1 if sum(pred_list) >= (len(pred_list) \/ 2) else 0","3d31d91f":"for net in nets:\n    net.eval()\ncorrect, total, tp, tn, fn, fp = 0, 0, 0, 0, 0, 0\nwith torch.no_grad():\n    for (x, y) in validationloader:\n        images, labels = x.to(device), y.to(device)\n        pred_list = [0 for i in nets]\n        for index, net in enumerate(nets):\n            y_pred = net(images)\n            pred_list[index] = torch.round(torch.sigmoid(y_pred))\n        y_pred_tag =  get_majority_vote(pred_list)\n        if y_pred_tag == labels.unsqueeze(1):\n            correct += 1\n            if labels.item() == 1:\n                tp += 1\n            else:\n                tn += 1\n        else:\n            if labels.item() == 1:\n                fn += 1\n            else:\n                fp += 1\n        total += 1\nprint()     \nprint(f'*********************************')\nprint('| TP = %2.2f%%  \\t| FP = %2.2f%% \\t|' % (tp\/total*100, fp\/total*100))\nprint(f'*********************************')\nprint('| FN = %2.2f%%  \\t| TN = %2.2f%% \\t|' % (fn\/total*100, tn\/total*100))\nprint(f'*********************************')  \nprint('Validation Accuracy: %2.2f%%' % (100*correct\/\/total))\nprint('Precision: %2.2f%%    Recall: %2.2f%%' % (100 * tp \/ (tp + fp),\n                                                100 * tp \/ (tp + fn)))","b0408da3":"test_image_data = torchvision.datasets.ImageFolder(\n        '..\/input\/melanoma-image-data\/test\/test\/',\n        transform=transforms.Compose([\n                  transforms.Resize((512, 512)),\n                  transforms.ToTensor()])\n    )\ntestloader = torch.utils.data.DataLoader(test_image_data, shuffle=False)","08122404":"test_frame = pd.DataFrame(test_data['image_name'])\ntest_frame['target'] = [0 for i in range(len(test_frame))]\ntest_frame.head()","e61e4df5":"for net in nets:\n    net.eval()\nwith torch.no_grad():\n    for j, (x, y) in enumerate(testloader):\n        images, labels = x.cuda(), y.cuda()\n        pred_list = [0 for i in nets]\n        for index, net in enumerate(nets):\n            y_pred = net(images).cuda()\n            pred_list[index] = torch.round(torch.sigmoid(y_pred))\n        test_frame.at[j, 'target'] =  get_majority_vote(pred_list)\n        ","5b2f9f48":"test_frame.to_csv('.\/ensemble_net_submission.csv', index = False)","788e68be":"## Loading in data","f351837b":"These neural nets have already been trained on my local machine for 350 epochs. Doing 10 more here on kaggle. I creating a new weighted sampler every epoch to resample the data with replacement. That's how I'm accomplishing bagging.","77e71ef7":"### Loading in training images","8b626355":"## Getting test set predictions","eab44f81":"There are two thing I think I could do to improve the perfomance of this model:\n1. Some form of data augmentation over bagging\n2. Add boosting to the weighted random sampler. However, given that creating the class array for the random sampler's construction is currently very slow, I'm not sure I have thee patience to implement this...","23094ded":"# Diagnosing skin cancer lesions\n\nAuthor: Caleb Woy\n\nMaking models that can diagnose skin cancer.","eae901b8":"## Training an ensemble of models with weighted sampling","6aeb380a":"## Validating","ac1ac12b":"## Defining a CNN","8428a925":"Training data successfully loaded."}}