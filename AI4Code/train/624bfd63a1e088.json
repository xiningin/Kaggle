{"cell_type":{"1468a8d8":"code","cdde0d46":"code","86f0ccda":"code","94c657de":"code","a2f06194":"code","540fa07b":"code","68f4b2e2":"code","807143d0":"code","dafb4a84":"code","4a5bc38b":"code","11bc9434":"code","e7d199df":"code","7bf9aed4":"code","6d7f0979":"code","b1966369":"code","7b71b830":"code","49999f36":"markdown","d65f6afe":"markdown","778cff32":"markdown","6449073b":"markdown","00fbe2fc":"markdown","01127fd3":"markdown","09342bf9":"markdown","7f536a63":"markdown","65f22f0d":"markdown","ea027a59":"markdown","7bcafb91":"markdown","0080c100":"markdown","03356760":"markdown","e569bd4a":"markdown","2c4070fa":"markdown","ab35d74d":"markdown","18a0b5d7":"markdown","c6ef0fdf":"markdown","70374b9d":"markdown"},"source":{"1468a8d8":"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.base import TransformerMixin\nimport warnings\nwarnings.filterwarnings(\"ignore\")","cdde0d46":"#getting training and test data\ntrain=pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\n#just taking a look at our data\ntrain.head(10)\n","86f0ccda":"train.info()","94c657de":"#describing basics\ntrain.describe()","a2f06194":"sns.distplot(train['SalePrice'])\nplt.xticks(rotation=30)","540fa07b":"#skewness and kurtosis\nprint(\"Skewness:{}\".format(train['SalePrice'].skew()))\nprint(\"Kurtosis:{}\".format(train['SalePrice'].kurt()))","68f4b2e2":"train['SalePrice']=np.log(train['SalePrice'])\nsns.distplot(train['SalePrice'])","807143d0":"print(\"Skewness:{}\".format(train['SalePrice'].skew()))\nprint('kurtosis:{}'.format(train['SalePrice'].kurt()))","dafb4a84":"\nsns.scatterplot(data=train,x='GrLivArea',y='SalePrice')\n","4a5bc38b":"sns.scatterplot(data=train,x='GarageArea',y='SalePrice')","11bc9434":"categorical=['SaleCondition','YrSold','OverallQual','LotShape','CentralAir','HouseStyle']\nfig,ax=plt.subplots(2,3,figsize=(15,10))\nfor var,subplot in zip(categorical,ax.flatten()):\n    sns.boxplot(data=train,x=var,y='SalePrice',ax=subplot)\nplt.tight_layout()    ","e7d199df":"#correlation\ncorr=train.corr()\nfig,ax=plt.subplots(figsize=(15,10))\nsns.heatmap(corr)","7bf9aed4":"corr_with_sale=corr['SalePrice'].nlargest(10)\n\ns=sns.barplot(x=corr_with_sale.index,y=corr_with_sale.values)\nplt.xticks(rotation=90)","6d7f0979":"#fucntion to get missing percentage value\ndef get_perctg(data):\n    nan=data.isna().sum()\/data.shape[0]\n    perctg=nan*100\n    return perctg[perctg>0]\nget_perctg(train)","b1966369":"thresh=np.ceil((20\/100)*train.shape[0])\ntrain=train.dropna(thresh=thresh,how='any',axis=1)","7b71b830":"class Impute(TransformerMixin):\n    def __init__(self):\n        \"\"\"\"impute missing categorical as well as\n        numericla \"\"\"\n    def fit(self,X,y=None):\n        self.fill=pd.Series([X[c].value_counts().index[0]\n                           if X[c].dtype==np.dtype('O') else X[c].mean() for c in X],\n                            index=X.columns)\n        return self\n    def transform(self,X,y=None):\n        return X.fillna(self.fill)\n                            \n                            \n    \n\nimputer=Impute()\n\ntrain=imputer.fit_transform(train)","49999f36":"<blockquote>here both variable are linearly moving in general trend but what does the straight line of points say us .They are basically saying that many houses with no garage houses are sold at some selling price.We may consider them at outlier and remove them.<\/blockquote>","d65f6afe":"<\/blockquote>Here we have some descriptive statistcs .the first four are easily understandable.here 25%,75% and 50% say about the quartile values.<\/blockquote>","778cff32":"<h3>Scrubbing data<\/h3>\n<\/blockquote>In the follwing code we will load the train and test data.get a look on the fisrt 10 rows .Know how many missing values are in the data.Check for duplicated data ,remove them and get some descriptive statistics of training data. \n<\/blockquote>","6449073b":"<h3>Imports<\/h3>\n    <blockquote>we will import some libraries that will help us in eda,visualisation and prediction.We import pandas and numpy for crunching our data,Matplotlib and seaborn for visualisations ,warnings to filter warnings.<\/blockquote>","00fbe2fc":"<h2>Missing Values<\/h2>\n<blockquote>missing values are very much undesirable things in data analysis.We must treat them efficiently .There are several methods to handle them .Here ,we should have a clear mindset of deletiing them when percentage of missing values is greater than 20, impute them with some suitable statistics in other case.<\/blockquote>","01127fd3":"<blockquote>These boxplot  are very usefull for taking a look at the realtions between categorical data and continuos variable. Here somthing is clear from the plots that overallqual is related to saleprice follwed by LotShape.YrSold is seems to have very bad relation with saleprice.<\/blockquote>","09342bf9":"<blockquote>So,here we have oyr nice heatmap of our correlation.The bright square represent very much linear relation between the variables.One thing we notice is their is a diagonal trend .It is easy to understand as any variable is realted to itself.Now there are also two big white squares.The first one tells that 1stFlrSf and TotalBsmtSf are linearly related.The thing to see here is that they represent the case of muticollinearity or anty of them give us the same amount of information,so if we ought to remove any one we will not lose much information.\n                                  Now coming to the second white square the GarageArea seems related to Garage car.it's normal logic why it's so.So here also we can experience muticollenearity .Muticollenarity doesn't help our linear model to learn much .So if two variable are corelated to each other ,other than target variable then we should remove one of the featuresthat are related. <\/blockquote>","7f536a63":"<h3>Relations with SalePrice<\/h3>\n<blockquote>Now ,here will visualize the relations saleprice having with other varibales.<\/blockquote>\n","65f22f0d":"<h3>Conclusions<\/h3> \nSo here that's all for now.In this kernel we have a light analysis of data.We see the descriptive statistics,followed by some visulizations and then filling the Nans.In this dataset we also see how muticollinearity occured and how it's not desirables.At last,ifyou have any suggestion regarding my kernel , i definetely welcome it.Thank You!","ea027a59":"So, here we have the varibles with the percentage of Nan varibles.Here we can see that MiscFeature, PoolQc Alley have more than 90 percent of Nan.Here ,we will delete all the columns having more than 20 percent of Nan and fill up the rest.","7bcafb91":"<blockquote>So,SalePrice is linearly related with GrLivArea.So GrLivarea might be a good predictor of saleprice in linear model.<\/blockquote>","0080c100":"So,here we have a bargraph of top ten  varible with high correletion related to 'SalePrice'.  ","03356760":"<h1>Light Eda<\/h1>\n<blockquote>EDA or exploratory data analysis is type of analysis in which there is exploration of data .Like how varibles are related to each other ,how some continuos varibles are distributed etc. This dataset contains 78 varibles we will just explore the data,visualise some varibles and handle misssing values.<\/blockquote>\n    \n   \n","e569bd4a":"<\/blockquote>Ta da !! here it's better .So , there's a problem if we will take log, how we gonna predict the actual target .The solution is we will take antilog of the prediction given by our model. <\/blockquote>","2c4070fa":"time to impute some value for this part i have taken help from stackoverflow.I will going to make a mixin which have an important part in pipeline.They have two methods fit and transform.they make our task much easier.As you can see below i have make a baseclass mixin imputer which will fill the columns if it's dtype is int or float, otherwise it will fill the column with it's mode or frequently occcured value.Mixins must have two methods fit and transform which we define by ourselves and the rest thing neceesaary are provided by base class transformixin.","ab35d74d":"<blockquote>\nHere we see lots of non-nullable variable.There we see some variables with dtypes object which means categorical variable,some are integers and some variables are float values.Some of the above variables contain few non nullable values.They are the ones containing  lots of Nan values.We will deal with them after some times.\n\n<\/blockquote>","18a0b5d7":"<h4>Correlations<\/h4>\n<blockquote>here we wiil take help from seaborn to visualise the correlations of features with target variable.Heatmaps are particulary useful to visualise the correlation of all varibles independently with target values.lets's see.<\/blockquote>","c6ef0fdf":"<h3>Univariate Analysis of SalePrice<\/h3>","70374b9d":"<\/blockquote>The saleprice which is our target varible  is slightly skewed towards left.Linear regression assumes target varible to be normally distributed .So we will make some transformations.We will take the log of saleprict and see if it is near normal distribution.<\/blockquote>"}}