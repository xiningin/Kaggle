{"cell_type":{"8de9d7fd":"code","65b05b81":"code","cacb7b19":"code","a4684700":"code","1664015d":"code","5ef31091":"code","8e6fea0a":"code","4d229261":"code","fa45f0cd":"code","6de592d7":"code","824bd090":"code","dde0dbe9":"markdown"},"source":{"8de9d7fd":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","65b05b81":"import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nimport joblib\n\nimport warnings\nwarnings.simplefilter(\"ignore\")","cacb7b19":"BASE_PATH = '\/kaggle\/input\/liverpool-ion-switching\/'\nMODEL_PATH = '\/kaggle\/input\/ensemble-models\/'\n\nROW_PER_BATCH = 500000\n\nWINDOW_SIZES = [10, 50]\nRANDOM_STATE = 42","a4684700":"def add_test_batch_rem_drift(test):\n\n    test['batch'] = 0\n\n    for i in range(0, test.shape[0]\/\/ROW_PER_BATCH):\n        test.iloc[i * ROW_PER_BATCH: (i+1) * ROW_PER_BATCH,2] = i\n\n    test['signal_undrifted'] = test.signal\n    # REMOVE BATCH 1 DRIFT\n    start=500\n    a = 0; b = 100000\n    test.loc[test.index[a:b],'signal_undrifted'] = test.signal.values[a:b] - 3*(test.time.values[a:b]-start)\/10.\n    start=510\n    a = 100000; b = 200000\n    test.loc[test.index[a:b],'signal_undrifted'] = test.signal.values[a:b] - 3*(test.time.values[a:b]-start)\/10.\n    start=540\n    a = 400000; b = 500000\n    test.loc[test.index[a:b],'signal_undrifted'] = test.signal.values[a:b] - 3*(test.time.values[a:b]-start)\/10.\n\n    # REMOVE BATCH 2 DRIFT\n    start=560\n    a = 600000; b = 700000\n    test.loc[test.index[a:b],'signal_undrifted'] = test.signal.values[a:b] - 3*(test.time.values[a:b]-start)\/10.\n    start=570\n    a = 700000; b = 800000\n    test.loc[test.index[a:b],'signal_undrifted'] = test.signal.values[a:b] - 3*(test.time.values[a:b]-start)\/10.\n    start=580\n    a = 800000; b = 900000\n    test.loc[test.index[a:b],'signal_undrifted'] = test.signal.values[a:b] - 3*(test.time.values[a:b]-start)\/10.\n\n    # REMOVE BATCH 3 DRIFT\n    def f(x):\n        return -(0.00788)*(x-625)**2+2.345 +2.58\n    a = 1000000; b = 1500000\n    test.loc[test.index[a:b],'signal_undrifted'] = test.signal.values[a:b] - f(test.time[a:b].values)\n    return test","1664015d":"def create_advance_features(df, window_sizes):\n    for window in window_sizes:\n        df[\"rolling_mean_\" + str(window)] = df['signal_undrifted'].rolling(window=window).mean()\n        df[\"rolling_std_\" + str(window)] = df['signal_undrifted'].rolling(window=window).std()\n        df[\"rolling_var_\" + str(window)] = df['signal_undrifted'].rolling(window=window).var()\n        df[\"rolling_min_\" + str(window)] = df['signal_undrifted'].rolling(window=window).min()\n        df[\"rolling_max_\" + str(window)] = df['signal_undrifted'].rolling(window=window).max()\n        df[\"rolling_min_max_ratio_\" + str(window)] = df[\"rolling_min_\" + str(window)] \/ df[\"rolling_max_\" + str(window)]\n        df[\"rolling_min_max_diff_\" + str(window)] = df[\"rolling_max_\" + str(window)] - df[\"rolling_min_\" + str(window)]\n        a = (df['signal'] - df['rolling_min_' + str(window)]) \/ (df['rolling_max_' + str(window)] - df['rolling_min_' + str(window)])\n        df[\"norm_\" + str(window)] = a * (np.floor(df['rolling_max_' + str(window)]) - np.ceil(df['rolling_min_' + str(window)]))\n\n    df = df.replace([np.inf, -np.inf], np.nan)    \n    df.fillna(0, inplace=True)\n\n    return df\n\n\ndef features(df):\n    \n    df = df.sort_values(by=['time']).reset_index(drop=True)\n    df.index = ((df.time * 10_000) - 1).values\n    \n    df['batch'] = df.index \/\/ 50_000\n    df['batch_index'] = df.index  - (df.batch * 50_000)\n    df['batch_slices'] = df['batch_index']  \/\/ 5_000\n    df['batch_slices2'] = df.apply(lambda r: '_'.join([str(r['batch']).zfill(3), str(r['batch_slices']).zfill(3)]), axis=1)\n    for c in ['batch','batch_slices2']:\n        d = {}\n        d['mean'+c] = df.groupby([c])['signal_undrifted'].mean()\n        d['median'+c] = df.groupby([c])['signal_undrifted'].median()\n        d['max'+c] = df.groupby([c])['signal_undrifted'].max()\n        d['min'+c] = df.groupby([c])['signal_undrifted'].min()\n        d['std'+c] = df.groupby([c])['signal_undrifted'].std()\n        d['mean_abs_chg'+c] = df.groupby([c])['signal_undrifted'].apply(lambda x: np.mean(np.abs(np.diff(x))))\n        d['abs_max'+c] = df.groupby([c])['signal_undrifted'].apply(lambda x: np.max(np.abs(x)))\n        d['abs_min'+c] = df.groupby([c])['signal_undrifted'].apply(lambda x: np.min(np.abs(x)))\n        for v in d:\n            df[v] = df[c].map(d[v].to_dict())\n        df['range'+c] = df['max'+c] - df['min'+c]\n        df['maxtomin'+c] = df['max'+c] \/ df['min'+c]\n        df['abs_avg'+c] = (df['abs_min'+c] + df['abs_max'+c]) \/ 2\n    \n    #add shifts\n    df['signal_shift_+1'] = [0,] + list(df['signal_undrifted'].values[:-1])\n    df['signal_shift_-1'] = list(df['signal_undrifted'].values[1:]) + [0]\n    for i in df[df['batch_index']==0].index:\n        df['signal_shift_+1'][i] = np.nan\n    for i in df[df['batch_index']==49999].index:\n        df['signal_shift_-1'][i] = np.nan\n        \n\n    for c in [c1 for c1 in df.columns if c1 not in ['time', 'signal_undrifted', 'open_channels', 'batch', 'batch_index', 'batch_slices', 'batch_slices2']]:\n        df[c+'_msignal'] = df[c] - df['signal_undrifted']\n        \n    return df","5ef31091":"test = pd.read_csv(BASE_PATH + 'test.csv')\n\ntest = add_test_batch_rem_drift(test)\ntest = create_advance_features(test, WINDOW_SIZES)\ntest = features(test)","8e6fea0a":"cols_to_remove = ['time','signal','open_channels','batch','batch_index','batch_slices','batch_slices2']\ncols = [c for c in test.columns if c not in cols_to_remove]\n\ntest = test[cols]","4d229261":"model = joblib.load(MODEL_PATH + 'lgb_0.sav')","fa45f0cd":"y_pred = model.predict(test, num_iteration=model.best_iteration)\ny_pred = np.round(np.clip(y_pred, 0, 10)).astype(int)","6de592d7":"y_pred","824bd090":"sub = pd.read_csv(BASE_PATH + 'sample_submission.csv')\nsub['open_channels'] =  np.array(np.round(y_pred,0), np.int) \n\nsub.to_csv('submission.csv', index=False, float_format='%.4f')\nsub.head(10)","dde0dbe9":"## for training related part please visit: \nhttps:\/\/www.kaggle.com\/rohitsingh9990\/lgb-featureengineering-lb-0-940?scriptVersionId=30607395\n\n### version1\nLinear Regression + create_advance_features only + Standard Scaler\nLB: 0.239\n\n### version2\nLogistic Regression + create_advance_features only + Standard Scaler\nLB: 0.345\n\n### version3\nLasso Regressor + create_advance_features only + Standard Scaler\nLB: 0.081\n\n### version4\nRidge Regressor + create_advance_features only + Standard Scaler\nLB: 0.239\n\n### version5\nRf Regressor + create_advance_features only + Standard Scaler\nLB: 0.256\n\n### version6\nLogistic Regression + Drift Removal + create_advance_features only + Standard Scaler \nLB: 0.754\n\n\n### version 12\nLightGBM + Drift Removal + create_advance_features only\nLB: 0.913\n\n### version 13\nLightGBM + Drift Removal + create_advance_features only + extra features\nLB: 0.939"}}