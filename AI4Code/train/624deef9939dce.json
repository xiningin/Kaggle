{"cell_type":{"f72f4548":"code","8cc00bba":"code","a3babe12":"code","0b299b7c":"code","f9da3db1":"code","ca62b930":"code","a5cfe601":"code","a9f62c1b":"code","40a0a06f":"code","d30962f0":"code","fdb2c179":"code","34b551da":"code","59d2806a":"code","8742d564":"code","3730f11e":"code","e259f00b":"markdown"},"source":{"f72f4548":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8cc00bba":"#load training set\ntraining_set = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/train.csv\", index_col= 'id')","a3babe12":"#glance at the dataset\ntraining_set.describe()","0b299b7c":"#view shape of data\ntraining_set.shape","f9da3db1":"#print the number different data types\nprint(training_set.dtypes.unique())","ca62b930":"#print na values\n#looks like every row has about 15000 na values\nwith pd.option_context('display.max_rows', 119, 'display.max_columns', 10):\n    print(training_set.isna().sum())","a5cfe601":"#plot a quick histogram of all of our features\n#we see that there are many different kinds of distributions which will have to be addressed later\n_ = training_set.hist(bins = 50, figsize = (20,15))","a9f62c1b":"#appears to be little correlation between features\ncorr = training_set.corr()\ndisplay(corr)","40a0a06f":"#lets see which features look most correlated with our target\n#there is little correlation between any features and the target\ntraining_set.corr()[['claim']].sort_values(by='claim', ascending=False)","d30962f0":"y = training_set['claim']\ntraining_set.drop(['claim'], axis=1, inplace=True)\nX = training_set","fdb2c179":"from sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split\n\n\nfrom xgboost import XGBRegressor\n\n\nnum_cols = training_set.select_dtypes(exclude=\"object\").columns\n\n#define numerical transformer pipeline\nnum_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant')),\n    ('scaler', StandardScaler())\n])\n\n#pass numerical transformer to the preprocessor to pass into our model\npreprocessor = ColumnTransformer([\n    ('numerical', num_transformer, num_cols),\n])\n\nmodel = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('model', XGBRegressor(n_estimators = 100,max_dept = 6,\n                                             verbosity = 2,early_stopping_rounds = 20,\n                                             learning_rate = 0.1, random_state = 1))])\n","34b551da":"#split data into groups\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size = 0.8,\n                                                      test_size=0.2, random_state = 1,\n                                                      stratify = y)\n#fit model with our training data\nmodel.fit(X_train, y_train)\n","59d2806a":"from sklearn.metrics import mean_squared_error\npredictions = model.predict(X_valid)\n\nrmse = np.sqrt(mean_squared_error(predictions, y_valid))\nprint('RMSE:', rmse)","8742d564":"testing_set = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/test.csv\", index_col= 'id')","3730f11e":"final_pred = model.predict(testing_set)\n\noutput = pd.DataFrame({'id': testing_set.index,\n                       'claim': final_pred})\noutput.to_csv('submission.csv', index=False)\n\n","e259f00b":"# Quick Early Exploration of data and sklearn RandForrestRegressor Benchmark"}}