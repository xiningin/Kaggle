{"cell_type":{"97ac90d2":"code","167d871b":"code","36676e19":"code","a04f43ab":"code","3eb866b2":"code","dc535980":"code","413fae03":"code","62dafb65":"code","b9b6da40":"code","d350b3cc":"code","a0475505":"code","d2cd2aec":"code","e3c43027":"code","001e001b":"code","001da104":"code","a9767e3e":"code","403386db":"code","30c962f8":"code","a5c8912b":"code","bde55b98":"code","140366b8":"code","f41e339f":"code","f92aecbd":"code","bc4e13f2":"code","92f8b30b":"code","552ece3a":"code","f470b77c":"code","e769701e":"code","3fad6315":"code","64eebfdf":"code","15d80b48":"code","ca5af375":"code","b9fd3ca5":"code","bdf85b6d":"code","e416bf30":"code","727d1780":"code","215005dd":"code","77f70aa7":"code","17545b73":"code","a5512a3e":"code","78fd9435":"code","4d1d9812":"code","feaf21f8":"code","bd9f8ff0":"code","ff536387":"code","45c31d7a":"code","b8686055":"code","6a76cda3":"code","1d8cc335":"code","5ed99014":"code","d3cb1218":"code","5963e0fa":"code","6a8cf0f0":"markdown","e7c613c0":"markdown","fc8ef7d5":"markdown","b110e8ec":"markdown","9148e6dd":"markdown","6a2c69ed":"markdown","19b31183":"markdown","55b8ddfe":"markdown","ecf73fb5":"markdown","ea34890d":"markdown","49877b75":"markdown","c17e0329":"markdown","3de8ff9f":"markdown"},"source":{"97ac90d2":"''' This project is to predict whether a Candidate will attend the interview or not.'''","167d871b":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n \nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","36676e19":"df = pd.read_csv('\/kaggle\/input\/the-interview-attendance-problem\/Interview.csv')","a04f43ab":"### Run this to Profile data\n\nimport pandas_profiling as pp\nprofile = pp.ProfileReport(    df, title=\"Campus Recruitment Profile\", html={\"style\": {\"full_width\": True}}, sort=None)\nprofile","3eb866b2":"print(df.isnull().sum())","dc535980":"# Drop last row as it has all NaN\n#df = df[:-1] \ndf = df.drop(df.tail(1).index)\n# drop irrelevant columns \ndf.drop(['Unnamed: 23', 'Unnamed: 24', 'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27', 'Name(Cand ID)'], \n                  axis=1, inplace=True)\nprint(\"Dataset Shape : \", df.shape)","413fae03":"# change column name to shorter names\ndf=df.rename(columns={'Date of Interview':'weekday',\n                          'Client name':'client',\n                          'Gender':'gender',\n                          'Industry':'industry',\n                          'Location':'location',\n                          'Position to be closed':'job_skills_required',\n                          'Nature of Skillset':'candidate_skills',\n                          'Interview Type':'interview_type',\n                          'Candidate Current Location':'candidate_loc',\n                          'Candidate Job Location':'job_location',\n                          'Interview Venue':'venue',\n                          'Candidate Native location':'native_loc',\n                          'Have you obtained the necessary permission to start at the required time':'permission',\n                          'Hope there will be no unscheduled meetings':'hope',\n                          'Can I Call you three hours before the interview and follow up on your attendance for the interview':'3_hour_call',\n                          'Can I have an alternative number\/ desk number. I assure you that I will not trouble you too much':'alt_number',\n                          'Have you taken a printout of your updated resume. Have you read the JD and understood the same':'resume_printout',\n                          'Has the call letter been shared':'share_letter',\n                          'Are you clear with the venue details and the landmark.':'knows_location',\n                          'Expected Attendance':'expected_attendance',\n                          'Observed Attendance':'observed_attendance'\n                         })\nprint(df.columns)","62dafb65":"print(df.isnull().sum())","b9b6da40":"sns.countplot(df['hope'])","d350b3cc":"sns.countplot(df['expected_attendance'])","a0475505":"#lets automate the plots\nfig,axes = plt.subplots(len(df.columns),figsize=(10,5*len(df.columns)))\nplt.tight_layout()\nfor idx,col in enumerate(df.columns):\n    sns.countplot(df[col],ax=axes[idx])","d2cd2aec":"df.gender.unique()","e3c43027":"df.job_skills_required.unique()","001e001b":"# group them into skilled and routine(production-Sterile and Routine)\ndef rename_job_skill(data):\n    if data == 'Routine' or data == 'Production- Sterile':\n        return 'routine'\n    else:\n        return 'skilled'\n    \ndf.job_skills_required = df.job_skills_required.apply(rename_job_skill)","001da104":"print(\"Total count\",df.job_skills_required.count())\nprint(\"Unique categories:\\n\",df.job_skills_required.value_counts())","a9767e3e":"df.candidate_skills.unique()","403386db":"df.share_letter.unique()","30c962f8":"df.drop(['candidate_skills','share_letter'], \n                  axis=1, inplace=True)\nprint(\"Dataset Length : \", len(df))\nprint(\"Dataset Shape : \", df.shape)\nprint(\"list of columns\",df.columns)","a5c8912b":"df.interview_type.unique()","bde55b98":"#We will re-classify them into walkin, scheduled and scheduled_walkin\ndef rename_interview_type(data):\n    interview_type=data.rstrip().lower()\n    if interview_type=='walkin':\n        return 'walkin'\n    elif interview_type =='scheduled':\n        return 'scheduled'\n    else:\n        return 'scheduled_walkin'\ndf.interview_type=df.interview_type.apply(rename_interview_type)","140366b8":"print(\"Total count\",df.interview_type.count())\nprint(\"Unique categories:\\n\",df.interview_type.value_counts())","f41e339f":"# Industry\ndf.industry.unique()","f92aecbd":"# Group IT in one category\ndef rename_industry(data):\n    if 'IT' in data:\n        return 'IT'\n    else:\n        return data\ndf.industry=df.industry.apply(rename_industry)","bc4e13f2":"print(\"Total count\",df.industry.count())\nprint(\"Unique categories:\\n\",df.industry.value_counts())","92f8b30b":"df[(pd.isnull(df.knows_location)) | (df.knows_location == 'na') | (df.knows_location == 'Na')]","552ece3a":"def rename_know_location(data):\n    if pd.isnull(data) or data =='na' or data =='Na':\n        return np.nan\n    knows=data.rstrip().lower()\n    if knows=='yes':\n        return 'yes'\n    else:\n        return 'no'\ndf.knows_location=df.knows_location.apply(rename_know_location)","f470b77c":"print(\"Total count\",df.knows_location.count())\nprint(\"Unique categories:\\n\",df.knows_location.value_counts())","e769701e":"#Let's replace missing values with the mode\nmost_freq_loc=df.knows_location.mode().iloc[0]\n# set missing value with the mode\ndf.knows_location=df.knows_location.apply(lambda x:most_freq_loc if pd.isnull(x) else x)","3fad6315":"print(\"Total count\",df.knows_location.count())\nprint(\"Unique categories:\\n\",df.knows_location.value_counts())","64eebfdf":"print(\"Unique Expected Attendance\",df.expected_attendance.unique())\nprint(\"Unique Observed Attendance\", df.observed_attendance.unique())","15d80b48":"def rename_expected_attendance(data):\n    if pd.isnull(data):\n        return np.nan\n    attendance=data.rstrip().lower()\n    if attendance =='no' or attendance == 'uncertain':\n        return attendance\n    else:\n        return 'yes'\n    \ndf.expected_attendance=df.expected_attendance.apply(rename_expected_attendance)","ca5af375":"print(\"Total count\",df.expected_attendance.count())\nprint(\"Unique categories:\\n\",df.expected_attendance.value_counts())","b9fd3ca5":"#expected_attendance is missing some value , let's replace them with mode\nmost_freq_loc=df.expected_attendance.mode().iloc[0]\n# set missing value with the mode\ndf.expected_attendance=df.expected_attendance.apply(lambda x:   most_freq_loc if pd.isnull(x) else x)\n\nprint(\"Total count\",df.expected_attendance.count())\nprint(\"Unique categories:\\n\",df.expected_attendance.value_counts())","bdf85b6d":"# We should not care if candidate is not expected to come so lets drop those rows\ndf=df[df.expected_attendance !='no']\nprint(\"Dataset Length : \", len(df))\nprint(\"Dataset Shape : \", df.shape)\n","e416bf30":"def rename_hope(data):\n    if pd.isnull(data):\n        return np.nan\n    value=data.rstrip().lower()\n    if value == 'unsure' or value == 'not sure' or value == 'cant say' or value == 'nan' or value == 'na':\n        return 'no'\n    else:\n        return 'yes'\ndf.hope = df.hope.fillna('unsure')\ndf.hope=df.hope.apply(rename_hope)\n\nprint(\"Total count\",df.hope.count())\nprint(\"Unique categories:\\n\",df.hope.value_counts())","727d1780":"def rename_permission(data):\n    if pd.isnull(data):\n        return np.nan\n    value=data.rstrip().lower()\n    if value == 'not yet' or value == 'na' or value =='no':\n        return 'no'\n    elif value == 'yet to confirm' or value == 'yes':\n        return 'yes'\n    else:\n        return data\n    \ndf.permission = df.permission.fillna('no')\ndf.permission=df.permission.apply(rename_permission)\n\nprint(\"Total count\",df.permission.count())\nprint(\"Unique categories:\\n\",df.permission.value_counts())","215005dd":"def rename_observed_attendance(data):\n    if pd.isnull(data):\n        return np.nan\n    attendance=data.rstrip().lower()\n    if attendance =='no':\n        return attendance\n    else:\n        return 'yes'\n    \ndf.observed_attendance=df.observed_attendance.apply(rename_observed_attendance)\n\nprint(\"Total count\",df.observed_attendance.count())\nprint(\"Unique categories:\\n\",df.observed_attendance.value_counts())","77f70aa7":"from datetime import datetime\n\n#function to check if a character is between a-z or 1-9\ndef is_myalnum(char):\n    return (ord(char.lower()) in range(ord('a'), ord('z')+1)\n            or char.isdigit())\n\n#extracts the day, month and year from the data\ndef parse_string(date_str):\n\n    date = [] #contain [day, month, year]\n    val = \"\"\n    \n    counter = 0\n    str_len = len(date_str)\n    \n    while (len(date) < 3):\n        char = date_str[counter]\n        #print(counter, str_len, char, is_myalnum(char))\n        \n        if is_myalnum(char):\n            val += char\n        \n        elif not is_myalnum(char) and not val == \"\":\n            date.append(val)\n            val = \"\"\n\n        if counter == (str_len - 1) and not val == \"\":\n            date.append(val)\n            val = \"\"\n        \n        counter += 1\n    return date\n    \n#converts the date into a weekday\ndef convert_date(data):\n\n    [day, month, year]= parse_string(data)\n\n    year = int(year)\n    day = int(day)\n    if month.isdigit(): \n        date = datetime(year, int(month), day)\n                        \n    else:\n        month = int(datetime.strptime(month, \"%b\").strftime(\"%m\"))\n        date = datetime(year, month, day)\n\n    return date.strftime('%A')\n        \ndf.weekday = df.weekday.apply(convert_date)\nprint(\"Total count\",df['weekday'].count())\nprint(\"Unique categories:\\n\",df['weekday'].value_counts())","17545b73":"df['3_hour_call'] = df['3_hour_call'].fillna('no')\nfor i,v in enumerate(df['3_hour_call']):\n    value = v.lower()\n    if value == 'no dont' or value == 'na':\n        df['3_hour_call'].iloc[i] = 'no'\n    else:\n         df['3_hour_call'].iloc[i] = value\n\nprint(\"Total count\",df['3_hour_call'].count())\nprint(\"Unique categories:\\n\",df['3_hour_call'].value_counts())","a5512a3e":"def rename_altnum(data):\n    if pd.isnull(data):\n        return np.nan\n    value=data.rstrip().lower()\n    if value == 'no i have only this number' or value == 'na':\n        return 'no'\n    else:\n        return 'yes'\ndf.alt_number = df.alt_number.fillna('no')\ndf.alt_number=df.alt_number.apply(rename_altnum)\n\nprint(\"Total count\",df.alt_number.count())\nprint(\"Unique categories:\\n\",df.alt_number.value_counts())","78fd9435":"def rename_print(data):\n    if pd.isnull(data):\n        return np.nan\n    value=data.rstrip().lower()\n    if value == 'no- will take it soon' or value == 'not yet' or value == 'na' or value=='no':\n        return 'no'\n    elif value == 'yes':\n        return 'yes'\n\ndf.resume_printout = df.resume_printout.fillna('NA')\ndf.resume_printout=df.resume_printout.apply(rename_print)\n\nprint(\"Total count\",df.resume_printout.count())\nprint(\"Unique categories:\\n\",df.resume_printout.value_counts())","4d1d9812":"print(df.columns)\nfor col in df.columns:\n    print(\"Unique \",col,\"\\n\",df[col].unique())","feaf21f8":"df.describe()","bd9f8ff0":"#lets plot the clean data(subset)\nfig,axes = plt.subplots(len(df.columns),figsize=(10,5*len(df.columns)))\nplt.tight_layout()\nfor idx,col in enumerate(df.columns):\n    sns.countplot(df[col],ax=axes[idx])","ff536387":"# Lets drop native location and 'Marital Status' columns as well\ndf.drop(['native_loc','Marital Status'], \n                  axis=1, inplace=True)","45c31d7a":"df.head()","b8686055":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\nencoder.fit(df['observed_attendance'])\ndf.observed_attendance = encoder.fit_transform(df['observed_attendance'])\nfor col in df.drop(['observed_attendance'],axis=1).columns :\n    encoder.fit(df[col])\n    df[col] = encoder.transform(df[col])\ndf.head()","6a76cda3":"y=df.pop(\"observed_attendance\")","1d8cc335":"from sklearn.feature_selection import RFE\nfrom sklearn import linear_model\nregr=linear_model.LinearRegression()\nrfe=RFE(regr, 3)\nfit=rfe.fit(df,y)\nprint(\"coeficient ie. scores is  \",fit.ranking_)\n\nprint (\"Features sorted by their rank:\")\nprint (sorted(zip(map(lambda X: round(X, 4), fit.ranking_), df.columns)))","5ed99014":"df1=df[['candidate_loc', 'expected_attendance', 'job_skills_required', 'location', 'knows_location',\n       'interview_type', 'alt_number', 'venue', 'job_location', 'industry']]\n","d3cb1218":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(df1, y, train_size=0.7, random_state=123)","5963e0fa":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nimport lightgbm\nimport xgboost\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\n\nnames = [\n    \"CatBoostClassifier\",\n    \"Logistic Regression\",\n    \"Support Vector Machine\",\n    \"Decision Tree\",\n    \"Neural Network\",\n    \"Random Forest\",\n    \"XGBoost\",\n    \"LGBMClassifier\",\n    \"XGBRFClassifier\",\n    \"GradientBoosting\",\n    \"GaussianNB\",\n    \"KNeighborsClassifier\"\n]\nmodels = [\n    CatBoostClassifier(verbose= False),\n    LogisticRegression(),\n    SVC(),\n    DecisionTreeClassifier(),\n    MLPClassifier(),\n    RandomForestClassifier(),\n    XGBClassifier(),\n    lightgbm.LGBMClassifier(max_depth=2, random_state=4),\n    xgboost.XGBRFClassifier(max_depth=3, random_state=1),\n    GradientBoostingClassifier(max_depth=2, random_state=1),\n    GaussianNB(),\n    KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n]\n\naccuracy=[]\nfor model, name in zip(models,names):\n    model.fit(X_train, y_train)\n    \n    y_pred = model.predict(X_test)\n    print('Confusion matrix of ',name)\n    print(confusion_matrix(y_test, y_pred))\n    ac = accuracy_score(y_test, y_pred)\n    print('Accuracy score is ',ac)\n    accuracy.append(ac)\n    print('='*50)\n\nAccuracy_list = pd.DataFrame(list(zip(names, accuracy)),columns =['Model', 'Accuracy'])\nAccuracy_list= Accuracy_list.sort_values('Accuracy', axis=0, ascending=False, inplace=False, kind='quicksort', na_position='last', ignore_index=True, key=None)\n\nplt.rcParams['figure.figsize']=20,6 \nsns.set_style(\"darkgrid\")\nax = sns.barplot(x = 'Model',y = 'Accuracy',data = Accuracy_list , palette = \"rocket\", saturation =1.5)\nplt.xlabel(\"Model\", fontsize = 20 )\nplt.ylabel(\"Accuracy\", fontsize = 20)\nplt.title(\"Sorted Accuracy of different Models\", fontsize = 20)\nplt.xticks(fontsize = 11, horizontalalignment = 'center', rotation = 8)\nplt.yticks(fontsize = 13)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(f'{height:.2%}', (x + width\/2, y + height*1.02), ha='center', fontsize = 'x-large')\nplt.show()","6a8cf0f0":"# About Data\n\n\nThe Dataset consists of details of 1200 + candidates and the interviews they have attended during the course of the period 2014-2016.\n\nSource: https:\/\/www.kaggle.com\/vishnusraghavan\/the-interview-attendance-problem\n\n### Attribute Information:\n\nDate of Interview\nThis date refers to the day the candidates were scheduled for the interview. The formats vary.\n\nClient name\nThe clients that gave the recruitment vendor the requisite mandate\n\nIndustry\nThis refers to the vertical the client belongs(Note Candidates can jump across verticals in their job hunt)\n\nLocation\nRefers to the current location of the candidate\n\nPosition to be closed\nNiche refers to rare skill sets while routine refers to more common skill sets\n\nNature of Skillset\nThis refers to the skill the client has and specifies the same\n\nInterview Type\nThere are three types of interview- Walkin drives- these are unscheduled. Candidates are either contacted or they come to the interview on their own volition, Scheduled- Here the candidates profiles are screened by the client and subsequent to this, the vendor fixes an appointment between the client and the candidate. The third one is a scheduled walkin. Here the number of candidates is larger and the candidates are informed beforehand of a tentative date to ascertain their availability. The profiles are screened as in a scheduled interview. In a sense it bears features of both a walk-in and a scheduled interview\n\nName(Cand ID)\nThis is a substitute to keep the candidates identity a secret\n\nGender\nWhether the candidate is male or female\n\nCandidate Current Location\n\nCandidate Job Location\n\nInterview Venue\n\nCandidate Native location\n\nHave you obtained the necessary permission to start at the required time\n\nHope there will be no unscheduled meetings\n\nCan I Call you three hours before the interview and follow up on your attendance for the interview\n\nCan I have an alternative number\/ desk number. I assure you that I will not trouble you too much\n\nHave you taken a printout of your updated resume. Have you read the JD and understood the same\n\nAre you clear with the venue details and the landmark.\n\nHas the call letter been shared\n\nExpected Attendance\n\nWhether the candidate was expected to attend the interview. Here the it is either yes no or uncertain\n\nObserved Attendance\nWhether the candidate attended the interview. This is binary and will form our dependent variable\n\nMarital Status\nWhether the candidate is married or Single","e7c613c0":"# Preprocessing","fc8ef7d5":"Data has variations and doesn't  seem relevant, drop it for now","b110e8ec":"# Import Libraries\n","9148e6dd":"# Import data","6a2c69ed":"Data has so much variations and is hard to categorize, we will exclude it for now","19b31183":" # Please let me know in the comments what improvements can be done ","55b8ddfe":"Observations:\n\nlast 5 colums are blank\n\nlast 1 row is blank\n\nContains null values in 8 columns\n\ncontains missplled data in multiple columns","ecf73fb5":"## Convert date into weekdays","ea34890d":"We notice that there is large overlap between the nan in known_location and expected_attendance","49877b75":"# Profile data","c17e0329":" Lets review the knows_location data which corresponds to na , NA and nan ","3de8ff9f":"# Models"}}