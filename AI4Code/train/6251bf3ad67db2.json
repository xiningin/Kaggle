{"cell_type":{"bc3032de":"code","de062c36":"code","df66f515":"code","85e6bd07":"code","bc2fa1e0":"code","434e04b4":"code","2b45d195":"code","eeeefe11":"code","2788356f":"code","9619a043":"code","9d501515":"code","ccbe5c1a":"code","1ec743ad":"code","6db3e62f":"code","7391bf38":"code","b7a43f00":"code","5d91fb32":"code","f41245d7":"code","26b19bfb":"code","07a503d4":"code","11b860eb":"code","0b592067":"code","6fd9d29b":"code","ff4877f2":"code","a152d165":"code","1893c0eb":"code","d533695f":"code","1d974c0d":"code","46a37800":"code","927a0608":"code","8900cde8":"code","4f5dff9d":"code","c0c515a8":"code","7b7a8709":"code","70b4310e":"code","ed91eca5":"code","7eb82462":"code","591c65e4":"code","6d595378":"code","80dcdf1b":"code","c6c3f62a":"code","60f8aa5a":"code","c602a4c1":"code","59f6a4c7":"code","fe85ab5f":"code","4d499f12":"markdown","833e1454":"markdown","f2abe2e6":"markdown","c83c2b7b":"markdown","2990a6f5":"markdown","965cd515":"markdown","b2283891":"markdown","1d6a0611":"markdown","f9c202d1":"markdown","18191780":"markdown","79cd84dc":"markdown","d77a5828":"markdown","f0311ac1":"markdown","a2b71ccc":"markdown","64a4a074":"markdown","004e1bc0":"markdown","b517267d":"markdown","5177fbf7":"markdown","bc0a08b3":"markdown"},"source":{"bc3032de":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","de062c36":"train = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")\nsample = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\")","df66f515":"train.head()","85e6bd07":"test.head()","bc2fa1e0":"sample.head()","434e04b4":"train_copy = train.copy()\ntest_copy = test.copy()","2b45d195":"train.drop('Id', axis=1, inplace=True)\ntest.drop('Id', axis=1, inplace=True)","eeeefe11":"train.info()","2788356f":"train.describe()","9619a043":"import matplotlib.pyplot as plt\nimport seaborn as sns","9d501515":"train_cat_null_cols = ['Alley', 'MasVnrType', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', \n                 'BsmtFinType2', 'Electrical', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual',\n                'GarageCond', 'PoolQC', 'Fence', 'MiscFeature']\n\ntest_cat_null_cols = ['MSZoning', 'Alley', 'Utilities', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n                     'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'KitchenQual',\n                     'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n                     'PoolQC', 'Fence', 'MiscFeature', 'SaleType']\n\ntrain_cont_null_cols = ['LotFrontage', 'MasVnrArea', 'GarageYrBlt', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n                 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'GarageCars', 'GarageArea']\n\ntest_cont_null_cols = ['LotFrontage', 'MasVnrArea', 'GarageYrBlt', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n                 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'GarageCars', 'GarageArea', 'TotalBsmtSF']","ccbe5c1a":"from sklearn.impute import SimpleImputer\n\nimputer = SimpleImputer(strategy='most_frequent')\n\nfor col in train_cat_null_cols:\n    train[col] = imputer.fit_transform(train[col].values.reshape(-1,1))\n    \nfor col in test_cat_null_cols:\n    test[col] = imputer.fit_transform(test[col].values.reshape(-1,1))","1ec743ad":"for col in train_cont_null_cols:\n    train[col] = train[col].fillna(train[col].median())\n\nfor col in test_cont_null_cols:\n    test[col] = test[col].fillna(test[col].median())","6db3e62f":"train.isnull().sum().any()","7391bf38":"test.isnull().sum().any()","b7a43f00":"cat_cols = train.select_dtypes(object).columns\n\ncont_cols = ['MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt',\n       'YearRemodAdd', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n       '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath',\n       'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr',\n       'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF',\n       'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n       'MiscVal', 'MoSold', 'YrSold', 'SalePrice', 'LotFrontage', 'MasVnrArea', 'GarageYrBlt']","5d91fb32":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\n\nfor col in cat_cols:\n    train[col] = le.fit_transform(train[col])\n    test[col] = le.transform(test[col])","f41245d7":"corr = train.corr()\nplt.figure(figsize=(30, 30))\nsns.heatmap(corr, cmap='coolwarm')\nplt.show()","26b19bfb":"target = abs(corr['SalePrice'])\n\nrelevant_features = target[target>0.25]\nrelevant_features","07a503d4":"train = train[['LotFrontage', 'LotArea', 'LotShape', 'OverallQual', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea',\n              'ExterQual', 'Foundation', 'BsmtQual', 'BsmtExposure', 'BsmtFinSF1', 'TotalBsmtSF', 'HeatingQC',\n              'CentralAir', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'FullBath', 'KitchenQual', 'TotRmsAbvGrd',\n              'Fireplaces', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'WoodDeckSF',\n              'OpenPorchSF', 'SalePrice']]\n\ntest = test[['LotFrontage', 'LotArea', 'LotShape', 'OverallQual', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea',\n              'ExterQual', 'Foundation', 'BsmtQual', 'BsmtExposure', 'BsmtFinSF1', 'TotalBsmtSF', 'HeatingQC',\n              'CentralAir', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'FullBath', 'KitchenQual', 'TotRmsAbvGrd',\n              'Fireplaces', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'WoodDeckSF',\n              'OpenPorchSF']]","11b860eb":"from sklearn.preprocessing import RobustScaler, MinMaxScaler","0b592067":"x_train, y_train = train.drop('SalePrice', axis=1), train['SalePrice']\nx_test = test","6fd9d29b":"minmax = MinMaxScaler()\nrobust = RobustScaler()\n\nfor col in x_train.columns:\n  x_train[col] = robust.fit_transform(x_train[col].values.reshape(-1,1))\n  x_train[col] = minmax.fit_transform(x_train[col].values.reshape(-1,1))\n\n  x_test[col] = robust.transform(x_test[col].values.reshape(-1,1))\n  x_test[col] = minmax.transform(x_test[col].values.reshape(-1,1))","ff4877f2":"y_train = robust.fit_transform(y_train.values.reshape(-1,1))\ny_train = minmax.fit_transform(y_train.reshape(-1,1))","a152d165":"x_train = pd.DataFrame(x_train, columns=train.columns.drop('SalePrice'))\nx_test = pd.DataFrame(x_test, columns=test.columns)\n\ny_train = pd.DataFrame(y_train, columns=['SalePrice'])","1893c0eb":"from sklearn.model_selection import train_test_split","d533695f":"x_train_, x_val, y_train_, y_val = train_test_split(x_train, y_train, test_size=0.2)","1d974c0d":"from sklearn.ensemble import ExtraTreesRegressor, GradientBoostingRegressor, RandomForestRegressor, AdaBoostRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom catboost import CatBoostRegressor\nfrom sklearn.linear_model import SGDRegressor, LinearRegression","46a37800":"from sklearn.metrics import mean_squared_error, r2_score","927a0608":"def model_selection(x_train_, x_val, y_train_, y_val, model):\n  model = model()\n  model.fit(x_train_, y_train_)\n\n  train_pred = model.predict(x_train_)\n  val_pred = model.predict(x_val)\n\n  val_error = np.sqrt(mean_squared_error(y_val, val_pred))\n  train_error = np.sqrt(mean_squared_error(y_train_, train_pred))\n  train_acc = r2_score(y_train_, train_pred)\n  val_acc = r2_score(y_val, val_pred)\n\n  print('Train Error:', train_error)\n  print('\\n')\n  print('Val Error:', val_error)\n  print('\\n')\n  print('Train ACC :', train_acc*100)\n  print('\\n')\n  print('Val ACC :', val_acc*100)\n  print('\\n')\n  print('Is overfitting:', True if train_acc>val_acc else False)\n  print('\\n')\n  print('Overfitting by:',train_acc*100-val_acc*100)","8900cde8":"extratrees = model_selection(x_train_, x_val, y_train_, y_val, ExtraTreesRegressor)\nextratrees","4f5dff9d":"gradient = model_selection(x_train_, x_val, y_train_, y_val, GradientBoostingRegressor)\ngradient","c0c515a8":"randomforest = model_selection(x_train_, x_val, y_train_, y_val, RandomForestRegressor)\nrandomforest","7b7a8709":"ada = model_selection(x_train_, x_val, y_train_, y_val, AdaBoostRegressor)\nada","70b4310e":"xgb = model_selection(x_train_, x_val, y_train_, y_val, XGBRegressor)\nxgb","ed91eca5":"lgbm = model_selection(x_train_, x_val, y_train_, y_val, LGBMRegressor)\nlgbm","7eb82462":"tree = model_selection(x_train_, x_val, y_train_, y_val, DecisionTreeRegressor)\ntree","591c65e4":"catboost = model_selection(x_train_, x_val, y_train_, y_val, CatBoostRegressor)\ncatboost","6d595378":"sgd = model_selection(x_train_, x_val, y_train_, y_val, SGDRegressor)\nsgd","80dcdf1b":"linear = model_selection(x_train_, x_val, y_train_, y_val, LinearRegression)\nlinear","c6c3f62a":"model = LinearRegression()\nmodel.fit(x_train, y_train)","60f8aa5a":"pred = model.predict(x_test)\npred","c602a4c1":"pred_ = minmax.inverse_transform(pred.reshape(-1,1))\npred_ = robust.inverse_transform(pred_.reshape(-1,1))\n\nPred = pd.DataFrame(pred_, columns=['SalePrice'])\nPred","59f6a4c7":"IDS = test_copy['Id']\n\nPredictions = pd.concat([IDS, Pred], axis=1)\nPredictions","fe85ab5f":"Predictions.to_csv(\"\/kaggle\/working\/Predictions.csv\", index=False)","4d499f12":"**these are all the relevant features i want to keep and drop everything else**","833e1454":"Feature Correlation","f2abe2e6":"# **Saving a copy of the datasets**","c83c2b7b":"# **Data processing**","2990a6f5":"# Splitting training data","965cd515":"# **understanding the data**","b2283891":"# Loading the datasets","1d6a0611":"# **Saving the predictions file**","f9c202d1":"lets find relevant features which support predictions","18191780":"I will choose LinearRegression","79cd84dc":"# Predictions","d77a5828":"null values?","f0311ac1":"Feature Selection via Feature Correlation","a2b71ccc":"# Model selection","64a4a074":"# Model building and training","004e1bc0":"inverse transformations","b517267d":"Scaling the data","5177fbf7":"dropping id","bc0a08b3":"Encoding categorical data to numeric data"}}