{"cell_type":{"2c397f0e":"code","3023b806":"code","681fee1d":"code","088c4c5e":"code","8474e42b":"code","90037e3c":"code","08a986e6":"code","93263ea2":"code","f5495de6":"code","3c09db48":"code","8dc5edd3":"code","e9c29dd6":"code","7b9e207d":"code","fb3f317f":"code","60a44289":"code","a8d5f937":"code","29e94a23":"code","dd8a262f":"markdown","ca42a727":"markdown","523b9855":"markdown","c5a177e3":"markdown"},"source":{"2c397f0e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3023b806":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom time import sleep\nimport itertools\nimport cv2\nimport os\nimport numpy as np\nimport os\nimport ipywidgets as widgets\nfrom IPython.display import display","681fee1d":"# Define a useful function\ndef get_image(f_path):\n    '''\n    Returns the image from a path\n    '''\n    img_labs = ['jpg','png']\n    if any(x in img_labs for x in f_path.split('.')):\n        file = os.path.join(folder,f_path)\n        image = open(file,'rb').read()\n        return image\n    \n# Do the actual work here\nfolder = '..\/input\/petfinder-pawpularity-score\/train'\nfiles  = os.listdir(folder)\nsample_files = files[0:18]","088c4c5e":"images = [get_image(x) for x in sample_files]\nchildren = [widgets.Image(value = img) for img in images if str(type(img)) != '<class \\'NoneType\\'>']\nlabels = ['{}'.format(i) for i in range(len(children))]\n\n# Customize your layout here:\nbox_layout = widgets.Layout(\n    display='flex',\n    flex_flow='column',\n    align_items='stretch',\n    border='solid',\n    width='50%')\n\n# Create the widget\ntab = widgets.Tab()\ntab.children = children\n\n# Label em'!\nfor i in range(len(children)):\n    tab.set_title(i,labels[i])\n\ndisplay(tab)","8474e42b":"df_train = pd.read_csv('..\/input\/petfinder-pawpularity-score\/train.csv')","90037e3c":"#Generating file name with proper extension\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndf_train['FileName'] = df_train['Id']+\".jpg\"\n\ndef augmentData(df,img_width,img_height,x_col,y_col,batch_size):\n    datagen = ImageDataGenerator(rescale = 1.\/255, horizontal_flip = True,\n                                   fill_mode = \"nearest\", zoom_range = 0.2,\n                                   width_shift_range = 0.2, height_shift_range=0.2,\n                                   rotation_range=30,validation_split=0.20)\n    \n    #Creating training generator and validation generator\n    train_generator = datagen.flow_from_dataframe(dataframe=df, directory=\"..\/input\/petfinder-pawpularity-score\/train\/\", \n                                              x_col=x_col, y_col=y_col, \n                                              class_mode=\"raw\", target_size=(img_width, img_height), \n                                              batch_size=batch_size,shuffle=True)\n    \n    validation_generator = datagen.flow_from_dataframe(dataframe=df, directory=\"..\/input\/petfinder-pawpularity-score\/train\/\", \n                                              x_col=x_col, y_col=y_col, \n                                              class_mode=\"raw\", target_size=(img_width, img_height), \n                                              batch_size=batch_size,subset='validation',shuffle=True)\n    return train_generator,validation_generator\n\n#We are using the function to augment and generate and each time you call the function it is going to shuffle\n#the data for generator which can also used for cross validation\ntrain_generator,validation_generator = augmentData(df_train,100,100,\"FileName\",\"Pawpularity\",64)","08a986e6":"# generate samples and plot\nfrom matplotlib import pyplot\nbatch=next(train_generator)  # returns the next batch of images and labels \nprint(batch[0].shape) # batch[0] is the images, batch[1] are the labels\nimg=batch[0][0]   # this is the first image  batch[0][1] would be the next image\nprint (img.shape)\nplt.imshow(img) ","93263ea2":"#We are going to use resnet for transfer learning and for regression task\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import datasets, layers, models, losses, Model\n#Construct resnet model\ndef resNet_152(height,width,fc_layer_nodes):\n    base_model = tf.keras.applications.ResNet152(weights = '..\/input\/resnet152-weight-file\/resnet152_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top = False, input_shape = (height,width,3))\n    #Freeze weights\n    for layer in base_model.layers:\n        layer.trainable = False\n    x = layers.Flatten()(base_model.output)\n    x = layers.Dense(fc_layer_nodes, activation='relu')(x)\n    prediction = layers.Dense(1)(x)\n    resNet_152_regression = Model(inputs = base_model.input, outputs = prediction)\n    return resNet_152_regression\n\nresNet_152_head_regression = resNet_152(32,32,1000)\nresNet_152_head_regression.compile(optimizer='adam', loss=losses.mean_squared_error, metrics=['mse'])\ncallback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n#Since resnet will accept 32*32 in top layer hence we need to adjust the generators\ntrain_generator,validation_generator = augmentData(df_train,32,32,\"FileName\",\"Pawpularity\",64)\n\nhistory = resNet_152_head_regression.fit(train_generator,steps_per_epoch=100,epochs=15,validation_data= validation_generator,callbacks=[callback])","f5495de6":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model Loss')\nplt.ylabel('Loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","3c09db48":"import numpy as np\ndef preprocessImagePrediction(imagePath,width,height):\n    image = tf.keras.preprocessing.image.load_img(imagePath, target_size=(width,height))\n    input_arr = tf.keras.preprocessing.image.img_to_array(image)\n    input_arr = np.array([input_arr])  \n    return input_arr\n\nprediction = resNet_152_head_regression.predict(preprocessImagePrediction('..\/input\/petfinder-pawpularity-score\/test\/4128bae22183829d2b5fea10effdb0c3.jpg',32,32))","8dc5edd3":"result = []\nimport os\n# assign directory\ndirectory = '..\/input\/petfinder-pawpularity-score\/test'\n \n# iterate over files in\n# that directory\nfor filename in os.listdir(directory):\n    f = os.path.join(directory, filename)\n    # checking if it is a file\n    prediction = resNet_152_head_regression.predict(preprocessImagePrediction(f,32,32))\n    result.append(round(prediction[0][0],2))","e9c29dd6":"submission_10thOct_2021 = pd.read_csv('..\/input\/petfinder-pawpularity-score\/sample_submission.csv')[['Id','Pawpularity']]","7b9e207d":"submission_10thOct_2021['Pawpularity'] = result","fb3f317f":"submission_10thOct_2021.to_csv('.\/submission.csv',index=False)","60a44289":"resNet_152_head_regression.save('.\/resnet152')","a8d5f937":"from tensorflow.keras.models import model_from_json","29e94a23":"# serialize model to JSON\nmodel_json = resNet_152_head_regression.to_json()\nwith open(\"resNet_152_head_regression.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nresNet_152_head_regression.save_weights(\"resNet_152_head_regression.h5\")\nprint(\"Saved model to disk\")","dd8a262f":"# First I am going to start with res net and do transfer learning for regression to start with\n\n![](https:\/\/www.researchgate.net\/publication\/322621180\/figure\/fig2\/AS:584852684410885@1516451154473\/The-representation-of-model-architecture-image-for-ResNet-152-VGG-19-and-two-layered.png)","ca42a727":"**Let us view some sample Images which are augmented**\n\nThis will help us understand the variety of images ","523b9855":"> ******Let us first view couple of images to understad what is in it","c5a177e3":"# We are creating a function for transforming and augmenting the image\n\nYou can see the tutorial below\n\nhttps:\/\/www.tensorflow.org\/tutorials\/load_data\/images"}}