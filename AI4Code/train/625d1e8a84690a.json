{"cell_type":{"1714c98a":"code","468b6b58":"code","451b5d59":"code","0192cf0a":"code","9be98312":"code","7d2455dd":"code","fdec9625":"code","c1c00806":"code","e31c7450":"code","dae85134":"code","c90f015d":"code","f205aaec":"code","b8ccbd7a":"code","ff974867":"code","4291fe42":"code","8087744e":"code","ebe175cc":"code","b91a12ee":"code","386badec":"code","bc025c6a":"code","fe911ea4":"code","137afbf8":"code","69c75f06":"code","9424fe0c":"code","14fcf892":"code","9f89e911":"code","dea6c061":"code","3dc8e682":"code","355111a9":"code","29152579":"code","175a7941":"code","670166ba":"code","23869718":"code","565a9a8e":"code","7956bdc7":"code","35583b8b":"code","65149a5d":"code","f428ca68":"code","ea5f5c8f":"code","542112c3":"code","f09f347c":"code","a4409f01":"code","2448df72":"code","31492372":"code","32f1fe2a":"code","2569f38c":"code","c9e9b705":"code","eded9ac7":"code","8b4f9763":"code","6498bdee":"code","5f9f6bcc":"code","0f433989":"code","e19cc5ff":"code","3de094c2":"code","07c0386a":"code","30a2eb5d":"code","ca5ebc83":"code","f8b0ad4d":"code","3ba09f0e":"code","a3c01a08":"code","75be7b60":"code","de64ce05":"code","9f4b1390":"code","925e79ec":"code","c42d3132":"code","3315cc15":"code","519e8c48":"code","9ff45c1f":"code","a71d1acf":"code","a73e86d6":"code","f77d52ba":"code","3b82aa9b":"code","5e2477c3":"code","01bcec2f":"code","ebe6b1ee":"code","2da9a903":"code","f3377970":"code","0220c61b":"code","825f08a0":"code","8bedded1":"code","5cf723fa":"code","057a875d":"code","133620cf":"code","e7b968a1":"code","a4c0d811":"code","e635b6e7":"code","8baaf959":"code","0dcf318c":"code","4d8a6ee2":"code","eb133a56":"code","57824ac4":"code","bb495542":"code","4ab191a0":"code","900c26af":"code","a5ccfc04":"code","e5b4d829":"code","54e16fde":"code","9b73433e":"code","7c7af7d3":"code","006611e4":"code","81997426":"code","1c266d21":"code","7e73b665":"code","321ecd51":"code","dff2e7ee":"code","17cbd23c":"code","9bce9cb1":"markdown","a6c4deed":"markdown","0e75e148":"markdown","ec123b89":"markdown","7733a340":"markdown","343c0633":"markdown","e276f4ba":"markdown","0012716c":"markdown","05428f5c":"markdown","48812388":"markdown","9e51e69e":"markdown","464c8ed3":"markdown","57ff5672":"markdown","08357582":"markdown","ada2e2ee":"markdown","5948b5bc":"markdown","202b6cbc":"markdown","7ece5bab":"markdown","b0987b0f":"markdown","bab2538b":"markdown","1b695d10":"markdown","4b08f61d":"markdown","4b6a7679":"markdown","416fe0c5":"markdown","47fc6770":"markdown","29974e6f":"markdown","75253ab3":"markdown","5ef6a45a":"markdown","af90e63f":"markdown","5e127b87":"markdown","334644b3":"markdown","a49dda42":"markdown","8e8aee2a":"markdown"},"source":{"1714c98a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","468b6b58":"# Python >3.5 version required\nimport sys\nassert sys.version_info >= (3,5)\n\n# Scikit=learn version >=0.20 is required\nimport sklearn\nassert sklearn.__version__ >= '0.20'\n\n# handle os specifics\nimport os\n\n# usual imports #\nimport pandas as pd\nimport numpy as np\n\n# visualization imports\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# consistent plots\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 12,5\nrcParams['xtick.labelsize'] = 9\nrcParams['ytick.labelsize'] = 9\nrcParams['axes.labelsize'] = 10\n\n# ignore unwanted warnings\nimport warnings \nwarnings.filterwarnings(action='ignore',message='^internal gelsd')","451b5d59":"# handle data and path to save the plots created during project - Optional \nROOT_DIR = '.'\nTRAIN_DATA = 'train'\nTEST_DATA = 'test'\nSUBMIT_SAMPLE = 'gender_submission'\n\nextension = '.csv'\n\nTRAIN_DATA_PATH = os.path.join(ROOT_DIR,TRAIN_DATA + extension)\nTEST_DATA_PATH = os.path.join(ROOT_DIR,TEST_DATA + extension)\nSUBMIT_SAMPLE_PATH = os.path.join(ROOT_DIR,SUBMIT_SAMPLE + extension)\n\nIMAGE_DIR =  'images'\nIMAGE_PATH = os.path.join(ROOT_DIR,IMAGE_DIR)\nos.makedirs(IMAGE_PATH,exist_ok=True)","0192cf0a":"# define function to save the figures\ndef save_figures(filename,extension='png',resolution=300,tight=True):\n    figure = os.path.join(IMAGE_PATH,filename + '.' + extension)\n    print (f'Saving the figure, please wait .....')\n    # save the figure \n    if tight:\n        plt.tight_layout()\n    plt.savefig(figure,format=extension,dpi=resolution)\n    print (f'your plot has been saved in {IMAGE_PATH}')","9be98312":"train_titanic =pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_titanic =pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","7d2455dd":"train_titanic.head(20)","fdec9625":"train_titanic.columns","c1c00806":"train_titanic.describe()","e31c7450":"train_titanic.info()","dae85134":"train_titanic['Survived'].value_counts()","c90f015d":"# remove duplicate rows from the dataset if any .. \ntrain_titanic = train_titanic.drop_duplicates()","f205aaec":"len(train_titanic)  # seems like there were no duplicate rows","b8ccbd7a":"titanic = train_titanic.copy()","ff974867":"sns.countplot(titanic['Survived'],palette='winter');","4291fe42":"sns.countplot(x='Survived',hue='Sex',data=titanic,palette='winter');","8087744e":"sns.boxplot(x='Survived',y='Age',hue='Sex',data=titanic,palette='winter');","ebe175cc":"sns.boxplot(x='Survived',y='Age',hue='Sex',data=titanic[titanic['Age']<13],palette='winter')\nplt.title('Children Under the Age of 13')","b91a12ee":"# check total casualties in child under 10 years of age\nlen(titanic[(titanic['Age']<13) & (titanic['Survived']==0)])","386badec":"# remove the unwanted column PassengerID from the dataset\ntitanic.drop('PassengerId',axis=1,inplace=True)","bc025c6a":"titanic.head()","fe911ea4":"sns.violinplot(x=\"Pclass\", y=\"Age\", data=titanic,jitter=True,hue='Sex',palette='Set1');","137afbf8":"sns.stripplot(x=\"Pclass\", y=\"Age\", data=titanic,jitter=True,hue='Survived',palette='Set1')\nplt.title('Classwise Survival Distribution');","69c75f06":"sns.swarmplot(x=\"Pclass\", y=\"Age\", data=titanic,hue='Survived',palette='Set1');\nplt.title('Classwise Survival Distribution')","9424fe0c":"# plot the passengers who were accompanied by spouse or siblings\ntitanic['SibSp'].value_counts().plot(kind='bar')\nplt.title('Passengers with Siblings or Spouse')\nplt.xlabel('Number of siblings or spouse')\nplt.ylabel('Number of primary passenger (ticket name)')","14fcf892":"# check the values explicitly\ntitanic['SibSp'].value_counts()","9f89e911":"titanic['Parch'].value_counts().plot(kind='bar')\nplt.title('Passengers with parents or child')\nplt.xlabel('Number of parents or child')\nplt.ylabel('Number of primary passenger (ticket name)')","dea6c061":"titanic['Parch'].value_counts()","3dc8e682":"class3 = titanic[titanic['Pclass']==3]","355111a9":"class3.info()","29152579":"# port of embarkment of class 3\nsns.swarmplot(x='Survived',y='Embarked',hue='Sex',data=class3)","175a7941":"class3['SibSp'].value_counts().plot(kind='bar')\nplt.title('Passengers with Siblings or Spouse in 3rd Class')\nplt.xlabel('Number of siblings or spouse')\nplt.ylabel('Number of primary passenger (ticket name)')","670166ba":"class3['Parch'].value_counts().plot(kind='bar')\nplt.title('Passengers with parents or child in 3rd class')\nplt.xlabel('Number of parents or child')\nplt.ylabel('Number of primary passenger (ticket name)')","23869718":"# port of embarkment of all passengers\nsns.swarmplot(x='Pclass',y='Embarked',hue='Survived',data=titanic)\nplt.legend(loc='upper center')","565a9a8e":"# putting multiple insights in a single view\nsns.lmplot(x='Age',y='Fare',data=titanic,row = 'Survived',col='Pclass',hue='Sex',markers=['v','o'],\n          scatter_kws={'s':100})","7956bdc7":"sns.heatmap(titanic.corr())","35583b8b":"titanic.corr()['Survived'][1:]","65149a5d":"titanic[titanic['Pclass']==1]['Cabin']","f428ca68":"# number of 1st class passengers whose cabin is missing\ntitanic[titanic['Pclass']==1]['Cabin'].isnull().sum()","ea5f5c8f":"# cabin information missing for survived passengers\ntitanic[titanic['Survived']==1]['Cabin'].isnull().sum()","542112c3":"titanic['Cabin'].isnull().sum()\/len(titanic)","f09f347c":"titanic.head(2)","a4409f01":"titanic.info()","2448df72":"titanic[titanic['Age'].isnull()]","31492372":"# determine the median age of the passengers in various passenger class categories\nmed_age_class_1 = titanic[titanic['Pclass']==1]['Age'].median()\nmed_age_class_2 = titanic[titanic['Pclass']==2]['Age'].median()\nmed_age_class_3 = titanic[titanic['Pclass']==3]['Age'].median()","32f1fe2a":"med_age_class_1, med_age_class_2, med_age_class_3","2569f38c":"# define a function to impute the median age Pclass wise\ndef impute_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n        if Pclass ==1:\n            return med_age_class_1\n        elif Pclass==2:\n            return med_age_class_2\n        else:\n            return med_age_class_3\n    else:\n        return Age","c9e9b705":"titanic['Age'] = titanic[['Age','Pclass']].apply(impute_age,axis=1)","eded9ac7":"titanic.info()","8b4f9763":"# visualize which feature has null values\nsns.heatmap(titanic.isnull(),cbar=False,xticklabels=True,yticklabels=False,cmap='viridis');","6498bdee":"titanic[titanic['Embarked'].isnull()]","5f9f6bcc":"# check the Emabarked port for similar passengers --> Pclass, Sex and SibSp and Parch\ntitanic[(titanic['Pclass']==1) & (titanic['Sex']=='female')]['Embarked'].value_counts().sort_values(ascending=False)","0f433989":"# fill the embarked null values\ndef impute_embarked(cols):\n    Pclass = cols[0]\n    Sex = cols[1]\n    Embarked = cols[2]\n    \n    if pd.isnull(Embarked):\n        return 'S'\n    else:\n        return Embarked  ","e19cc5ff":"titanic['Embarked']= titanic[['Pclass','Sex','Embarked']].apply(impute_embarked,axis=1)","3de094c2":"# visualize which feature has null values\nsns.heatmap(titanic.isnull(),cbar=False,xticklabels=True,yticklabels=False,cmap='viridis');","07c0386a":"titanic.drop('Cabin',axis=1,inplace=True)","30a2eb5d":"# drop additional columns - feature engineering on Name an Ticket in next iteration depending on model\n# performance\ntitanic.drop(['Name','Ticket'],axis=1,inplace=True)","ca5ebc83":"titanic.head()","f8b0ad4d":"# round off the Fare column to 2 decimal places --> helps model to converge\ntitanic['Fare'] = round(titanic['Fare'],2)","3ba09f0e":"sex_cat = pd.get_dummies(data=titanic['Sex'],drop_first=True)","a3c01a08":"embark_cat = pd.get_dummies(data=titanic['Embarked'],drop_first=True)","75be7b60":"# concat the categorical encoded features\ntitanic = pd.concat([titanic,sex_cat,embark_cat],axis=1)","de64ce05":"# drop the redundant\/duplicate categorical features\ntitanic.drop(['Sex','Embarked'],axis=1,inplace=True)","9f4b1390":"titanic.head(2)","925e79ec":"from sklearn.model_selection import train_test_split\nX = titanic.drop('Survived',axis=1)\ny = titanic['Survived']\nX_train,X_valid,y_train,y_valid = train_test_split(X,y,test_size=0.30, random_state=42)","c42d3132":"X_train.head()","3315cc15":"y_train.head()","519e8c48":"# import various classification models\nfrom sklearn.linear_model import LogisticRegression,RidgeClassifier,SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,BaggingClassifier,AdaBoostClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom lightgbm import LGBMClassifier","9ff45c1f":"# import cross validation\nfrom sklearn.model_selection import cross_val_predict, cross_val_score,KFold,RepeatedStratifiedKFold","a71d1acf":"# check the performance metrics of the various models before training\ndef cross_validate(X=X_train,y=y_train):\n    warnings.filterwarnings(action='ignore',message='')\n    models = []\n    models.append(('RF',RandomForestClassifier()))\n    models.append(('GB',GradientBoostingClassifier()))\n    models.append(('SVC',SVC()))\n    models.append(('SGD',SGDClassifier()))\n    models.append(('LogReg',LogisticRegression()))\n    models.append(('AdaBoost',AdaBoostClassifier()))\n    models.append(('Bag',BaggingClassifier()))\n    models.append(('xgboost',XGBClassifier()))\n    models.append(('lightgbm',LGBMClassifier()))\n    models.append(('Dtree',DecisionTreeClassifier()))\n    models.append(('KNeigbors',KNeighborsClassifier()))\n    \n    names =[]\n    results = []\n    scoring = 'accuracy'\n    \n    for name,model in models:\n        kfold = KFold(n_splits=10)\n        cv_score = cross_val_score(model,X,y,scoring=scoring)\n        results.append(cv_score)\n        names.append(name)\n        print(f'Model {name}, Mean Accuracy {round(cv_score.mean(),5)}, Std Deviation {round(cv_score.std(),5)}')","a73e86d6":"# run the function and check the scores\ncross_validate(X_train,y_train)","f77d52ba":"# import libraries for grid and randomized search\nfrom sklearn.model_selection import GridSearchCV,RandomizedSearchCV","3b82aa9b":"from scipy.stats import randint\n\n# Random Forest\nparam_distribs = {\n        'n_estimators': randint(low=1, high=500),\n        'max_depth': randint(low=1, high=10),\n        'max_features':randint(low=1,high=10),\n        \n    }\n\nrf_clf = RandomForestClassifier(random_state=42)\nrnd_search_rf = RandomizedSearchCV(rf_clf, param_distributions=param_distribs,\n                                n_iter=10, cv=5, scoring='accuracy', random_state=42)\nrnd_search_rf.fit(X_train,y_train)","5e2477c3":"rnd_search_rf.best_params_","01bcec2f":"# XGBoost\nparam_distribs = {\n        'n_estimators': randint(low=1, high=500),\n        'max_depth': randint(low=1, high=10),\n        \n        \n    }\n\nxgb_clf = XGBClassifier(random_state=42)\nrnd_search_xgb = RandomizedSearchCV(xgb_clf, param_distributions=param_distribs,\n                                n_iter=10, cv=5, scoring='accuracy', random_state=42)\nrnd_search_xgb.fit(X_train,y_train)","ebe6b1ee":"# display the best parameter\nrnd_search_xgb.best_params_","2da9a903":"# define model with the hyperparaters returned from Randomized search\nrf_clf = rnd_search_rf.best_estimator_\nxgb_clf = rnd_search_xgb.best_estimator_","f3377970":"# KNN Grid Search\n\nknn_clf = KNeighborsClassifier()\n\n## Define grid params\nparam_grid = {\"n_neighbors\":[3,4,5,6,7],\\\n             \"weights\":[\"uniform\",\"distance\"],\\\n             \"p\":[1,2]}\n## Define Kfold\nkfold = RepeatedStratifiedKFold(n_splits=5,n_repeats=3,random_state=42)\n\n## Define and execute Grid Search\ngrid_search_knn = GridSearchCV(knn_clf, param_grid=param_grid,\\\n                                       scoring=\"accuracy\",cv=kfold)\ngrid_search_knn.fit(X_train, y_train)","0220c61b":"knn_clf = grid_search_knn.best_estimator_","825f08a0":"# feature scaling using standardization\nfrom sklearn.preprocessing import StandardScaler\nscalar = StandardScaler()\nX_train = scalar.fit_transform(X_train)\nX_valid = scalar.transform(X_valid)","8bedded1":"rf_clf.fit(X_train,y_train)\nxgb_clf.fit(X_train,y_train)\nknn_clf.fit(X_train,y_train)","5cf723fa":"# predict using the validation dataset\npredictions_rf =  rf_clf.predict(X_valid)\npredictions_xgb = xgb_clf.predict(X_valid)\npredictions_knn = knn_clf.predict(X_valid)","057a875d":"# check the scores\nfrom sklearn.metrics import accuracy_score,confusion_matrix,precision_score,recall_score,classification_report\n\nprint('Accuracy XGBoost = {}'.format(round(accuracy_score(y_valid,predictions_xgb),3)))\nprint('Accuracy RForest = {}'.format(round(accuracy_score(y_valid,predictions_rf),3)))\nprint('Accuracy KNN = {}'.format(round(accuracy_score(y_valid,predictions_knn),3)))\nprint('\\n')\nprint('Precision XGBoost = {}'.format(round(precision_score(y_valid,predictions_xgb),3)))\nprint('Precision RForest = {}'.format(round(precision_score(y_valid,predictions_rf),3)))\nprint('Precision KNN = {}'.format(round(precision_score(y_valid,predictions_knn),3)))\nprint('\\n')\nprint('Recall XGBoost = {}'.format(round(recall_score(y_valid,predictions_xgb),3)))\nprint('Recall RForest = {}'.format(round(recall_score(y_valid,predictions_rf),3)))\nprint('Recall KNN = {}'.format(round(recall_score(y_valid,predictions_knn),3)))","133620cf":"print('XGBoost_Confusion Matrix')\nprint(confusion_matrix(y_valid,predictions_xgb))\nprint('RandomForest_Confusion Matrix')\nprint(confusion_matrix(y_valid,predictions_rf))\nprint('KNN_Confusion Matrix')\nprint(confusion_matrix(y_valid,predictions_knn))","e7b968a1":"print('XGBoost_Classification Report')\nprint(classification_report(y_valid,predictions_xgb))\nprint('\\n')\nprint('RandomForest_Classification Report')\nprint(classification_report(y_valid,predictions_rf))\nprint('KNN_Classification Report')\nprint(classification_report(y_valid,predictions_knn))","a4c0d811":"sns.heatmap(test_titanic.isnull(),yticklabels=False,cbar=False)","e635b6e7":"test_prep = test_titanic.copy()","8baaf959":"from sklearn.impute import SimpleImputer","0dcf318c":"# drop the Cabin feature \ntest_prep.drop('Cabin',axis=1,inplace=True)","4d8a6ee2":"test_prep['Age'] = test_prep[['Age','Pclass']].apply(impute_age,axis=1)","eb133a56":"# numerical imputer \nimpute = SimpleImputer(strategy='median')","57824ac4":"# remove the columns Name and Ticket\ntest_prep.drop(['Name','Ticket'],axis=1,inplace=True)","bb495542":"# create a numeric only dataset to fit the simple imputer\ntest_non_cat = test_prep.drop(['Embarked','Sex'],axis=1)","4ab191a0":"# replace null values with the median\nimpute.fit(test_non_cat)\nimpute.statistics_","900c26af":"test_non_cat.median().values","a5ccfc04":"# transform the dataset - impute the values\ntransformer = impute.transform(test_non_cat)","e5b4d829":"# conver to a dataframe \ntest_non_cat_tr =  pd.DataFrame(transformer,columns=test_non_cat.columns,index=test_non_cat.index)","54e16fde":"test_non_cat_tr.head()","9b73433e":"test_prep['Age'] =  test_non_cat_tr['Age']\ntest_prep['Fare'] =  test_non_cat_tr['Fare']","7c7af7d3":"test_prep.drop('PassengerId',axis=1,inplace=True)\ntest_prep.info()","006611e4":"embark_cat = pd.get_dummies(test_prep['Embarked'],drop_first=True)\nsex_cat = pd.get_dummies(test_prep['Sex'],drop_first=True)","81997426":"test_prep = pd.concat([test_prep,embark_cat,sex_cat],axis=1)","1c266d21":"test_prep.drop(['Embarked','Sex'],axis=1,inplace=True)","7e73b665":"test_prep.head()","321ecd51":"# arrange the columns in the same order as in the training set \nX_test = test_prep[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'male', 'Q', 'S']]","dff2e7ee":"# scale the X_test using the same scalar as in training set\nX_test = scalar.transform(X_test) ","17cbd23c":"# use the classifiers on the grid\/randomized search best estimators\npredictions_xgb = xgb_clf.predict(X_test)\npredictions_rf = rf_clf.predict(X_test)\npredictions_knn = knn_clf.predict(X_test)","9bce9cb1":"Two ensemble techniques Random Forest and XGBoost (robust to unbalanced dataset) is chosen. Add a model based on different \ntechnique. Selected KNN but as the default performance was not as good, base kfold on RepeatedStratifiedKFold","a6c4deed":"- Casualties in males were way more compared to the females","0e75e148":"### Explore the survivors based on port of embarkment","ec123b89":"### Encode the categorical features","7733a340":"***There were altogether 29 child casualties under the age of 13***","343c0633":"##### Impute the missing age with the median age of the respective passenger class","e276f4ba":"***Same features as in training set. Also Fare has rows which are blank***","0012716c":"### Study the raw data","05428f5c":"### Impute the missing values in the numerical columns - Fare and Age\n- Apply the same strategy to impute the Age. For imputing null values in Fare feature, use standard simple imputer. KNN Imputer can also be a reasoble choice.  \n- Another method could be to create a Pipeline for data transformation for all the transformations done on the training dataset","48812388":"### Environment Set Up","9e51e69e":"### Explore the passengers in third class","464c8ed3":"### Get the data","57ff5672":"***Age has null values. Study the dataset and decide on the imputation strategy for missing ages***","08357582":"### ML Model Selection for Classification","ada2e2ee":"- The Fare feature is in 4 decimal places. Will intentionally not round off values here","5948b5bc":"### Prediction on the test set","202b6cbc":"#### Visualize the null values\n- Use exactly the same imputation strategy as in the training set for same features \n- Any new feature with null values would be imputed based on available standard techiques rather than studying the test data !","7ece5bab":"The median age of the survivors and casualties is very similar in both males and females\nit would be interesting to explore what percentage were children under 13 years of age","b0987b0f":"### Split dataset into training and validation set","bab2538b":"### Exploratory Data Analysis","1b695d10":"The dataset is nearly balanced. Synthetic data generation may not be required in initial iteration. ","4b08f61d":"***Now only the Cabin feature has null values***\n- As seen earlier 77% of the data is missing in Cabin feature. \n- Imputing certain values or to create a model to impute values are viable options.\nI decide to simply drop it :) ","4b6a7679":"- Passengers boarding from Queenstown were mostly 3rd class passengers\n- Majority of the casualties in 3rd class were from Queenstown or Southampton\n- 3rd class passengers had the least survivors. Seems like 90% of them died\n- Maximum survivors were from 1st class and that too who boarded from Cherbourg","416fe0c5":"- Maximum of class 3 female who survived had embarked from Queenstown\n- Females in class 3 had mainly survived while very few males in class 3 survive","47fc6770":"Cabin has a lot of occurrence of Null values. A few rows in Embarked is also null","29974e6f":"- Agewise the Class1 passenger's age distribution shows they were relatively older than the ones in the other class. The youngest were in Class 3.","75253ab3":"### Train the Models","5ef6a45a":"### Kaggle Submission\n- Scored above 75% accuracy \n- Model can be improved , try feature engineering on Name and Ticket\n- Try ANN with regularization","af90e63f":"77% of the dataset does not have information on the Cabin the passengers belonged\nRemoving this feature is a better idea","5e127b87":"### Search for the best hyperparameter","334644b3":"### Prepare the test data for final prediction\n- Efficient way is to create a transformation pipeline rather repeating the steps again !!\n","a49dda42":"- There were more survivors in 1st class compared to the other classes\n- Children casualties were maximum in Class 3 and hardly no one survived above the age of 50 in class-3\n","8e8aee2a":"### Encode Categorical Features"}}