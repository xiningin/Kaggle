{"cell_type":{"a50f22ee":"code","d425e072":"code","2e4a3590":"code","f4872e99":"code","a28b8274":"code","cce40ff7":"code","428d3e5c":"code","148ad995":"code","084992db":"code","9f958b1b":"code","fd17f934":"code","d0b4142e":"code","c3602e3e":"code","6f45b885":"code","93d5be4e":"code","041f2079":"code","b48b92da":"code","cb7213f6":"code","a82792b5":"code","cc15b6ab":"code","e9ec9ba0":"code","14dabc6b":"code","75b4e25e":"code","b9214e08":"code","87265f69":"code","3793dc85":"code","c4763f7b":"code","06eb84cc":"code","1a38145f":"code","78473232":"code","bd8a1a6a":"code","d188846b":"markdown","46dc84aa":"markdown","2fc3aadf":"markdown","77f0c7a8":"markdown","1d62dc27":"markdown"},"source":{"a50f22ee":"import cv2\nimport torch\nimport os\nimport random\nimport math\nimport glob \nimport pathlib\nimport csv, PIL\nimport time, zipfile\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n\nfrom tqdm import tqdm\nfrom PIL import Image\nfrom os import listdir\nfrom torchvision import*\n\n%matplotlib inline","d425e072":"print(os.listdir('..\/input\/'))","2e4a3590":"basepath = '..\/input\/irail-lab-pneumonia-detection-challenge'\nprint(os.listdir(basepath +'\/RSNA_train_img_1024_png\/'))","f4872e99":"data_dir = basepath + '\/RSNA_train_img_1024_png'\ntrain_img  =  glob.glob(data_dir+os.sep+\"\/*\/*.png\")\n\nnormal_path = basepath + '\/RSNA_train_img_1024_png\/normal\/'\nnormal_img  =  glob.glob(normal_path+os.sep+\"\/*.png\")\n\nopacity_path = basepath + '\/RSNA_train_img_1024_png\/opacity\/'\nopacity_img  =  glob.glob(opacity_path+os.sep+\"\/*.png\")\n\nprint(f\"The total number of the Data: {len(train_img)}\")\nprint(f\"The number of the normal Data: {len(normal_img)} \\nThe number of the opacity Data: {len(opacity_img)}\")","a28b8274":"train_img[:3]","cce40ff7":"rand_path = random.choice(normal_img)\nrand_img = mpimg.imread(rand_path)\nplt.imshow(rand_img, cmap='gray')\n\nprint( f\"Type of the random image: {type(rand_img)} \\nShape of the random image: '{rand_img.shape}, \\nPath : {rand_path}\")","428d3e5c":"from tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset, random_split\nfrom torchvision import models\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as transforms\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"'{device}' is avilable.\")","148ad995":"classes = os.listdir(data_dir)\ntransformations = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n\ndataset = ImageFolder(data_dir, transform = transformations)\nprint(f'The classes for the data : {classes}\\n\\n', dataset)","084992db":"def image_information(img, label):\n    print(f\"Label : {dataset.classes[label]} (Class No : {str(label)})\")\n    plt.imshow(img.permute(1, 2, 0))\n    plt.show","9f958b1b":"img, label = dataset[1]\nimage_information(img, label)\nprint(f\"If the data is '{dataset.classes[label]}' class of the image is '{str(label)}' \")\n\nimg, label = dataset[9999]\nprint(f\"If the data is '{dataset.classes[label]}' class of the image is '{str(label)}' \")","fd17f934":"img, label = dataset[9999]\nprint(f\"If the data is '{dataset.classes[label]}' class of the image is '{str(label)}' \")\nprint(f\"Image Size: {img.shape}\")\nprint(f\"Label: {label}\")\nprint('\\n', img, '\\n')\nprint(img.min(), img.max())","d0b4142e":"n_train = (round(len(train_img)*0.8))\nn_val = round(len(train_img)*0.1)\nn_test = round(len(train_img)*0.1)","c3602e3e":"print(f\"Total Number of the images : {len(train_img)} \\nThe proportion of the [8:1:1] : {round(len(train_img)*0.8)}, {round(len(train_img)*0.1)}, {round(len(train_img)*0.1)}\")","6f45b885":"train_ds, val_ds, test_ds = torch.utils.data.random_split(dataset, [n_train+1, n_val, n_test])\nrandom_seed = 42 \ntorch.manual_seed(random_seed)\nbatch_size = 32\n\ntrain_dl = DataLoader(train_ds, batch_size, shuffle = True, num_workers = 4, pin_memory = True) \nval_dl = DataLoader(val_ds, batch_size*2, num_workers = 4, pin_memory = True) \n\nprint(f'Train : {len(train_ds)}, Validation : {len(val_ds)}, Test : {len(test_ds)}')","93d5be4e":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))","041f2079":"! pip install timm","b48b92da":"import sys\nsys.path.append('..\/input\/pytorch-image-models\/pytorch-image-models-master')\nimport timm\nfrom pprint import pprint\npprint(timm.list_models(pretrained = True))","cb7213f6":"import torch.nn as nn\n\nclass Effnet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.effnet = timm.create_model(model_name = \"tf_efficientnet_b7\", pretrained = False)\n        n_features = self.effnet.classifier.in_features\n        self.effnet.classifier = nn.Linear(n_features, len(dataset.classes))\n    \n    def forward(self, x):\n        x = self.effnet(x)\n        return x","a82792b5":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))\n\nclass CxrClassificationModel(nn.Module):\n    def training_step(self, batch): \n        images, labels = batch \n        out = self(images)      \n        loss = F.cross_entropy(out, labels)      \n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        output, hidden = model(data)\n        out = self(images)                    \n        loss = F.cross_entropy(out, labels)   \n        acc = accuracy(out, labels)           \n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   \n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      \n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch {}: train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch+1, result['train_loss'], result['val_loss'], result['val_acc']))","cc15b6ab":"model = Effnet()","e9ec9ba0":"def get_default_device():\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        return len(self.dl)","14dabc6b":"device = get_default_device()\ndevice","75b4e25e":"puttrain_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\nto_device(model, device)","b9214e08":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval() \n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        \n        model.train() # Training \n        train_losses = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n    \n        result = evaluate(model, val_loader) # Validation \n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","87265f69":"model = to_device(Effnet(), device)","3793dc85":"evaluate(model, val_dl)","c4763f7b":"num_epochs = 25\nopt_func = torch.optim.Adam\nlr = 1e-5\nweight_decay = 1e-4\n\nhistory = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)","06eb84cc":"# log\ub97c csv\ud30c\uc77c\ub85c \uc800\uc7a5, \n# Best epoch\uc774 \ub098\uc624\uba74 ","1a38145f":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');\n\nplot_accuracies(history)","78473232":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');\n\nplot_losses(history)","bd8a1a6a":"# Grad CAM \n# Tensor board ","d188846b":"## Model","46dc84aa":"## Model : Transform.","2fc3aadf":"## Brief EDA","77f0c7a8":"Train : 8, Test : 1, Valid : 1","1d62dc27":"## Loading and split"}}