{"cell_type":{"fa7d54a9":"code","bd691df8":"code","048b0ec8":"code","22184f09":"code","0fe09a68":"code","8b087dbf":"code","bfd6a884":"code","7849c518":"code","954aea27":"code","84f53544":"code","cded40a6":"code","fc4aa187":"code","9a1b9fa9":"code","a6d0d108":"code","6e991f86":"code","d62d4a68":"code","cd35571f":"code","febdc700":"code","07538980":"code","b928f639":"code","aa906e18":"code","977add13":"code","bacc6731":"code","18d346f8":"markdown","f67ee60a":"markdown","04c8deb5":"markdown","09c3f40e":"markdown","1dae9c14":"markdown","527e105e":"markdown","0d330f44":"markdown","631870fb":"markdown","6ca75343":"markdown"},"source":{"fa7d54a9":"# import basic packages \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\n#import warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","bd691df8":"train=pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","048b0ec8":"train.head()","22184f09":"# shape of train and test\nprint('Shape of train',train.shape)\nprint('Shape of test',test.shape)","0fe09a68":"# split data into target and features\ny = train[\"label\"]\nX = train.drop(labels=[\"label\"],axis=1)","8b087dbf":"# count of values in target feature\nplt.figure(figsize=(12,6))\nsns.countplot(y)\n\n","bfd6a884":"y.value_counts()","7849c518":"# lets check one picture\nplt.figure(figsize=(8,6))\nimg=X.iloc[200].to_numpy()\nimg=img.reshape((28,28))\nplt.imshow(img,cmap='gray')\nplt.title(train.iloc[200,0])\nplt.grid()\nplt.show()","954aea27":"# Normalize the data\nX = X \/ 255.0\ntest = test \/ 255.0\nprint(\"X shape: \",X.shape)\nprint(\"test shape: \",test.shape)","84f53544":"# Reshape \nX = X.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)\nprint(\"X shape: \",X.shape)\nprint(\"test shape: \",test.shape)","cded40a6":"from keras.utils.np_utils import to_categorical\ny = to_categorical(y, num_classes = 10)\ny","fc4aa187":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.1,random_state=42)\nprint(\"x_train shape\",X_train.shape)\nprint(\"x_test shape\",X_test.shape)\nprint(\"y_train shape\",y_train.shape)\nprint(\"y_test shape\",y_test.shape)","9a1b9fa9":"# model making using Keras\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPool2D\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nmodel= Sequential()\nmodel.add(Conv2D(filters=8, kernel_size=(5,5), padding='Same', activation='relu', input_shape=(28,28,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters=16, kernel_size=(3,3), padding='Same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n# Fully Connected\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","a6d0d108":"# Define the optimizer\noptimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)","6e991f86":"model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","d62d4a68":"epochs = 100  \nbatch_size = 250","cd35571f":"# Data Augmentation\ndatagen = ImageDataGenerator(featurewise_center=False,  \n        samplewise_center=False, \n        featurewise_std_normalization=False,  \n        samplewise_std_normalization=False,  \n        zca_whitening=False, \n        rotation_range=5,  \n        zoom_range = 0.1, \n        width_shift_range=0.1,  \n        height_shift_range=0.1,  \n        horizontal_flip=False,  \n        vertical_flip=False) \n\ndatagen.fit(X_train)","febdc700":"# Early stopping\n\nfrom tensorflow.keras.callbacks import EarlyStopping\nearly_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=6)","07538980":"# fit the model\n\nhistory = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_test,y_test), steps_per_epoch=X_train.shape[0] \/\/ batch_size,\n                              callbacks=[early_stopping])","b928f639":"# model Success\nprint(\"Accuracy of the model is --> \" , model.evaluate(X_test, y_test, batch_size=batch_size)[1]*100 , \"%\")\nprint(\"Loss of the model is --> \" , model.evaluate(X_test, y_test, batch_size=batch_size)[0])","aa906e18":"# Loss Chart\nplt.figure()\nplt.plot(history.history[\"loss\"],label=\"Train Loss\",color='black')\nplt.plot(history.history[\"val_loss\"],label = \"Validation Loss\", color = \"darkred\", marker = \"+\", linestyle=\"dashed\",markeredgecolor = \"purple\", markeredgewidth = 2)\nplt.title(\"Model Loss\", color = \"darkred\", size = 13)\nplt.legend()\nplt.show()","977add13":"# Accuracy chart\nplt.figure()\nplt.plot(history.history[\"accuracy\"],label = \"Train Accuracy\", color = \"black\")\nplt.plot(history.history[\"val_accuracy\"],label = \"Validation Accuracy\", color = \"darkred\", marker = \"+\", linestyle=\"dashed\",markeredgecolor = \"purple\", markeredgewidth = 2)\nplt.title(\"Model Accuracy\", color = \"darkred\", size = 13)\nplt.legend()\nplt.show()","bacc6731":"# Confusion matrix\nfrom sklearn.metrics import confusion_matrix\n\nY_pred = model.predict(X_test)\n# argmax = To briefly mention it, it will give the index of the value with the highest value.\nY_pred_classes = np.argmax(Y_pred,axis = 1) \n\n# We do the same for the y_val values. because we will compare these values. \nY_true = np.argmax(y_test,axis = 1)\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n\n# define the colors\n\n\n# plot the confusion matrix\nf,ax = plt.subplots(figsize=(10, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap='Greens',linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\", color = \"blue\")\nplt.ylabel(\"True Label\", color = \"red\")\nplt.title(\"Confusion Matrix\", color = \"darkred\", size = 15)\nplt.show()","18d346f8":"### Data Augmentation","f67ee60a":"# Train Test Split","04c8deb5":"# Model","09c3f40e":"# Normalization","1dae9c14":"# Load Datasets","527e105e":"# Reshape","0d330f44":"# Label Encoding","631870fb":"# Model Evaluation","6ca75343":"##### **Optimizers**: Optimizers are algorithms or methods used to change the attributes of your neural network such as weights and learning rate in order to reduce the losses."}}