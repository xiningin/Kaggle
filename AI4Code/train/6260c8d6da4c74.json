{"cell_type":{"8ae8bec3":"code","aabad112":"code","c4fce388":"code","791b144d":"code","5deb268b":"code","5c468cdf":"code","f168e239":"code","83d4cd4b":"code","5f8995e5":"code","588dbbae":"code","67e69a20":"code","68cef16a":"code","28d60fa1":"code","879f4cc4":"code","5a94b318":"code","9a995bd7":"code","4a7680be":"code","795e72a4":"code","721ce12d":"code","08c2f2c9":"code","8bf51491":"code","1966df1b":"code","4d2804d3":"code","cd806f5d":"code","2168910e":"code","a3696ea8":"code","9118758e":"code","046fd0be":"markdown","c81b7a48":"markdown","346f8ebc":"markdown","7934912b":"markdown","833e1da3":"markdown","336110b2":"markdown","45ca072a":"markdown","c3a69e19":"markdown","fa4c19f0":"markdown","3ac2a670":"markdown","0d0b1a26":"markdown","19c8cf54":"markdown","f54a5fb7":"markdown","9d4d6766":"markdown","eaaf46a9":"markdown","cef1bea9":"markdown","6bd9b1b8":"markdown","d562864f":"markdown","1b0d8727":"markdown"},"source":{"8ae8bec3":"import numpy as np\nfrom numpy import random\nfrom numpy import vstack\nimport pandas as pd\nimport os\nprint(os.listdir(\"..\/input\"))\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport zipfile","aabad112":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Reshape\nfrom keras.layers import Flatten\nfrom keras.layers import Conv2D\nfrom keras.layers import Conv2DTranspose\nfrom keras.layers import LeakyReLU\nfrom keras.layers import Dropout\nfrom keras.optimizers import Adam\nfrom keras.utils.vis_utils import plot_model\nfrom keras.models import load_model","c4fce388":"!tar xzvf ..\/input\/cifar-10-python.tar.gz","791b144d":"def load_data():\n    \"\"\"\n    Loads CIFAR10 dataset and returns tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n    \"\"\"\n    import os\n    import sys\n    from six.moves import cPickle\n    import numpy as np\n    \n    def load_batch(fpath):\n        with open(fpath, 'rb') as f:\n            d = cPickle.load(f, encoding='bytes')  \n        data = d[b'data']\n        labels = d[b'labels']\n        data = data.reshape(data.shape[0], 3, 32, 32)\n        return data, labels\n    \n    path = 'cifar-10-batches-py'\n    num_train_samples = 50000\n    x_train = np.empty((num_train_samples, 3, 32, 32), dtype='uint8')\n    y_train = np.empty((num_train_samples,), dtype='uint8')\n    for i in range(1, 6):\n        fpath = os.path.join(path, 'data_batch_' + str(i))\n        (x_train[(i - 1) * 10000:i * 10000, :, :, :],\n         y_train[(i - 1) * 10000:i * 10000]) = load_batch(fpath)\n    x_test, y_test = load_batch(os.path.join(path, 'test_batch'))\n    y_train = np.reshape(y_train, (len(y_train), 1))\n    y_test = np.reshape(y_test, (len(y_test), 1))\n    x_train = x_train.transpose(0, 2, 3, 1)\n    x_test = x_test.transpose(0, 2, 3, 1)\n    return (x_train, y_train), (x_test, y_test)","5deb268b":"(X_train, Y_train), (X_test, Y_test) = load_data()\nprint(X_train.shape, Y_train.shape)\nprint(X_test.shape, Y_test.shape)","5c468cdf":"n_x = 32     # size of image n_x by n_x\nn_c = 3      # number of channels\nX = np.concatenate((X_train, X_test))     # combine X_train and X_test\nY = np.concatenate((Y_train, Y_test))     # combine Y_train and Y_test\nprint(X.shape, Y.shape)","f168e239":"apl_indices = np.array(np.where(Y[:,0] == 0))\nprint(apl_indices.shape)\nprint(apl_indices)","83d4cd4b":"# pick out all airplane images\napls = X[apl_indices[0,:]]\nprint(apls.shape)","5f8995e5":"# pick some apl images and look at these\nplt.figure(figsize=(10,10))\nn_images = 64\nfor i in range(n_images):  \n    plt.subplot(8, 8, i+1)\n    plt.imshow(apls[i])\n    plt.axis('off')\nplt.subplots_adjust(wspace=0.3, hspace=-0.1)\nplt.show()","588dbbae":"# scale from [0,255] to [-1,1]\napls = (apls - 127.5)\/127.5","67e69a20":"def define_discriminator(in_shape=(n_x,n_x,n_c)):\n    \"\"\"\n    Define the conv net for the discriminator\n    \"\"\"\n    model = Sequential()\n    model.add(Conv2D(64,kernel_size=3,padding='same',input_shape=in_shape))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Conv2D(128,kernel_size=3,strides=2,padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Conv2D(128,kernel_size=3,strides=2,padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Conv2D(256,kernel_size=3,strides=2,padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Flatten())\n    model.add(Dropout(rate=0.4))\n    model.add(Dense(1,activation='sigmoid'))\n    opt = Adam(lr=0.0002,beta_1=0.5) # define optimizer\n    model.compile(loss='binary_crossentropy',optimizer=opt,metrics=['accuracy'])\n    return model","68cef16a":"discriminator = define_discriminator()\ndiscriminator.summary()","28d60fa1":"def generate_real_samples(data, n_samples):\n    \"\"\"\n    Pick 'n_samples' randomly from 'data'\n    \"\"\"\n    idx = random.randint(low=0,high=data.shape[0],size=n_samples)\n    X = data[idx]\n    Y = np.ones((n_samples,1))\n    return X, Y","879f4cc4":"def define_generator(latent_dim):\n    \"\"\"\n    Define the conv net for the generator\n    \"\"\"\n    n_nodes = 256*4*4\n    model = Sequential()\n    model.add(Dense(n_nodes,input_dim=latent_dim)) # foundation for 4*4 image\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Reshape((4,4,256)))\n    model.add(Conv2DTranspose(128,kernel_size=4,strides=2,padding='same')) # up-sample to 8*8 image\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Conv2DTranspose(128,kernel_size=4,strides=2,padding='same')) # up-sample to 16*16 image\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Conv2DTranspose(128,kernel_size=4,strides=2,padding='same')) # up-sample to 32*32 image\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Conv2D(3,kernel_size=3,activation='tanh',padding='same'))\n    return model","5a94b318":"latent_dim = 100 # define size of latent space\ngenerator = define_generator(latent_dim)\ngenerator.summary()","9a995bd7":"def generate_latent_points(latent_dim, n_samples):\n    \"\"\"\n    This generates points in the latent space as input for the generator\n    \"\"\"\n    x_input = random.randn(latent_dim * n_samples)\n    x_input = x_input.reshape(n_samples, latent_dim)     # reshape into a batch of inputs for the network\n    return x_input","4a7680be":"def generate_fake_samples(g_model, latent_dim, n_samples):\n    \"\"\"\n    Generate 'n_samples' of fake samples from the generator\n    \"\"\"\n    X_input = generate_latent_points(latent_dim, n_samples)\n    X = g_model.predict(X_input)    # generator predicts output\n    Y = np.zeros((n_samples,1))     # create class labels '0' for fake sample\n    return X, Y","795e72a4":"def define_gan(g_model, d_model):\n    \"\"\"\n    This takes as arguments the generator and discriminator and creates the GAN subsuming these two models. \n    The weights in the discriminator are marked as not trainable, \n    which only affects the weights as seen by the GAN and not the standalone discriminator model.\n    \"\"\"\n    d_model.trainable = False     # make weights in the discriminator not trainable\n    model = Sequential()\n    model.add(g_model)\n    model.add(d_model)\n    opt = Adam(lr=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt)\n    return model","721ce12d":"gan = define_gan(generator, discriminator)\ngan.summary()","08c2f2c9":"def save_plot(examples, epoch, n=10):\n    \"\"\"\n    This creates and save a plot of generated images\n    \"\"\"\n    examples = (examples+1)\/2.0\n    for i in range(n * n):\n        plt.subplot(n, n, 1 + i)\n        plt.axis('off')\n        plt.imshow(examples[i])\n    filename = 'generated_plot_e%03d.png' % (epoch+1)\n    plt.savefig(filename)\n    plt.close()","8bf51491":"# evaluate the discriminator, plot generated images, save generator model\ndef summarize_performance(epoch, g_model, d_model, data, latent_dim, n_samples=150):\n    \"\"\"\n    This evaluates the discriminator, plot generated images, save generator model\n    \"\"\"\n    X_real, Y_real = generate_real_samples(data, n_samples)\n    _, acc_real = d_model.evaluate(X_real, Y_real, verbose=0)   # evaluate discriminator on real samples\n    X_fake, Y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n    _, acc_fake = d_model.evaluate(X_fake, Y_fake, verbose=0)   # evaluate discriminator on fake samples\n    print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))    # summarize discriminator performance\n    save_plot(X_fake, epoch)\n    filename = 'generator_model_%03d.h5' % (epoch + 1)\n    g_model.save(filename)","1966df1b":"def train(g_model, d_model, gan_model, data, latent_dim, n_epochs=900, batch_size=128):\n    \"\"\"\n    This trains the combined generator and discriminator models in the GAN\n    \"\"\"\n    batch_per_epoch = data.shape[0] \/\/ batch_size\n    half_batch = batch_size \/\/ 2\n    for i in range(n_epochs):\n        for j in range(batch_per_epoch):\n            X_real, Y_real = generate_real_samples(data, half_batch)   # randomly select real samples\n            d_loss1, _ = d_model.train_on_batch(X_real, Y_real)   # update discriminator model weights\n            X_fake, Y_fake = generate_fake_samples(g_model, latent_dim, half_batch)   # generate fake samples\n            d_loss2, _ = d_model.train_on_batch(X_fake, Y_fake)   # update discriminator model weights\n            X_gan = generate_latent_points(latent_dim, batch_size)   # as input for generator\n            Y_gan = np.ones((batch_size, 1))\n            g_loss = gan_model.train_on_batch(X_gan, Y_gan)   # update generator via the discriminator's error\n            # print('>%d, %d\/%d, d1=%.3f, d2=%.3f, g=%.3f' % (i+1, j+1, batch_per_epoch, d_loss1, d_loss2, g_loss)) # summarize loss for batch\n        # evaluate the model performance, sometimes\n        if (i+1) % 100 == 0: \n            summarize_performance(i, g_model, d_model, data, latent_dim)","4d2804d3":"latent_dim = 100\nd_model = define_discriminator()\ng_model = define_generator(latent_dim)\ngan_model = define_gan(g_model, d_model)\ndata = apls\ntrain(g_model, d_model, gan_model, data, latent_dim)","cd806f5d":"image = Image.open('generated_plot_e900.png')\nplt.figure(figsize=(15,15))\nplt.axis('off')\nplt.imshow(image)","2168910e":"def show_plot(examples, n):\n    \"\"\"\n    This shows the plots from the GAN\n    \"\"\"\n    plt.figure(figsize=(10,10))\n    for i in range(n * n):\n        plt.subplot(n, n, 1 + i)\n        plt.axis('off')\n        plt.imshow(examples[i,:,:])\n    plt.subplots_adjust(wspace=0.3, hspace=-0.1)\n    plt.show()","a3696ea8":"latent_points = generate_latent_points(100, 10000)\nnew_images = g_model.predict(latent_points)\nnew_images = (new_images+1)\/2.0\nshow_plot(new_images, 8)","9118758e":"z = zipfile.PyZipFile('images.zip', mode='w')\nfor d in range(10000):\n    apl_image = Image.fromarray((255*new_images[d]).astype('uint8').reshape((32,32,3)))\n    f = str(d)+'.png'\n    apl_image.save(f,'PNG')\n    z.write(f)\n    os.remove(f)\nz.close()","046fd0be":"The Generator creates new, fake but plausible images. It works by taking a point from a latent space as input and output an image.\n\n**Inputs:** Point in latent space, e.g. a 100-element vector of Gaussian random numbers.\n\n**Outputs:** 2D color image (3 channels; RGB) of 32x32 pixels with pixel values in [-1,1].","c81b7a48":"# Using the final Generator model to generate images","346f8ebc":"# Create zip file to save generated images","7934912b":"**Best Practice:** To scale the pixel values from the range of unsigned integers in [0,255] to the normalized range of [-1,1]. The generator model will generate images with pixel values in the range [-1,1] as it will use the tanh activation function, a best practice. Hence, the real images are to be scaled to the same range.","833e1da3":"All CIFAR10 image samples will be labelled '1' (real). Need to create fake samples labelled as '0'. The fake samples will be created by the Generator. The real and fake samples will be fed into the Discriminator by batches.","336110b2":"The function 'load_data()' is taken from [Reference 2.][1]\n\n[1]: https:\/\/www.kaggle.com\/xhlulu\/simple-load-data-function-for-keras","45ca072a":"I'm using the tutorial in [Reference 1][1] on GAN to generate particular CIFAR10 images.\n\n[1]: https:\/\/machinelearningmastery.com\/how-to-develop-a-generative-adversarial-network-for-a-cifar-10-small-object-photographs-from-scratch\/","c3a69e19":"The generation of each image requires a point in the latent space as input.","fa4c19f0":"# Introduction","3ac2a670":"# The Generator","0d0b1a26":"### Training of the Discriminator","19c8cf54":"# The Discriminator","f54a5fb7":"# Load & prepare CIFAR10 dataset","9d4d6766":"### Define the Discriminator","eaaf46a9":"Started on 8 July 2019\n\n**Reference:**\n1. https:\/\/machinelearningmastery.com\/how-to-develop-a-generative-adversarial-network-for-a-cifar-10-small-object-photographs-from-scratch\/\n2. https:\/\/www.kaggle.com\/xhlulu\/simple-load-data-function-for-keras\n3. https:\/\/www.kaggle.com\/rhodiumbeng\/generating-handwritten-digits-gan\/output","cef1bea9":"# Train the GAN","6bd9b1b8":"The discriminator takes a sample \"image\" from our dataset and says whether it is real or fake.\n\n**Inputs:** \"image\" 32x32 pixels in size; three channels (RGB).\n\n**Outputs:** binary classification, likelihood the sample is real.","d562864f":"# Combining the Discriminator & Generator as a GAN","1b0d8727":"# Functions to evaluate performance of GAN"}}