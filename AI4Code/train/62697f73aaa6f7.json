{"cell_type":{"5e2fcb25":"code","d1111566":"code","e7b97f42":"code","4b138d78":"code","aa49272c":"code","5f1ae7bc":"code","821de6c4":"code","86366c88":"code","d9556729":"code","3d283311":"code","bd4cb889":"code","8b63b177":"code","edf4e359":"code","cc83fea2":"code","89e848cd":"code","5c0cb2dd":"code","54721ecd":"code","8fc213f3":"code","5169a9c1":"code","eaadb719":"code","2d3362ba":"code","9d415f1f":"code","5539cf01":"code","a41ae2bf":"code","980c0d2c":"code","d8f0596c":"code","fd99ce0d":"code","e00b4c05":"code","ecc6bd92":"code","a8378ee7":"code","f2a207a7":"code","b528e62a":"code","8a3557cd":"code","5fb7cd75":"code","c83fad87":"code","3f1d2a25":"code","398680a7":"code","a99f4307":"code","da7913e4":"code","8cf9b62f":"code","7687c37e":"code","389db06d":"markdown","10f51a95":"markdown","250efcd7":"markdown","db1ff68f":"markdown","14fe28e7":"markdown","73456336":"markdown","598d9737":"markdown","1f8a72d7":"markdown","e225092a":"markdown","d6d5afb7":"markdown","23c601f5":"markdown","5210f877":"markdown","e50e2394":"markdown","8c35f012":"markdown","d7340694":"markdown","dadd03b2":"markdown","c8af50ce":"markdown","a008f9ea":"markdown","b43d6417":"markdown","fa3fed71":"markdown","bc908cfb":"markdown","6ce7df70":"markdown","414a415b":"markdown","6733bca5":"markdown","579e4ca4":"markdown"},"source":{"5e2fcb25":"## for eda and visuls:\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport plotly.express as px\nimport missingno\nimport matplotlib.pyplot as plt\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\n\n\n","d1111566":"# Reading Data:\ndf=pd.read_csv(\"\/kaggle\/input\/adult-census-income\/adult.csv\")\ndf.head()  #Loading the First Five Rows:","e7b97f42":"# Let's Look The Dimensions Of The Data:\nprint(f'The Data-Set Contain {df.shape[0]} Rows and {df.shape[1]} Columns')\n","4b138d78":"#Check Data Types\ndf.dtypes","aa49272c":"# loop through the columns and check the missing values\nfor col in df.columns:\n    pct_missing = df[col].isnull().sum()\n    print(f'{col} - {pct_missing :.1%}')","5f1ae7bc":"# Build a matrix of missing values\nmissingno.matrix(df, fontsize = 16)\nplt.show()","821de6c4":"#Check The Duplicates In the Data-Set:\ndf.duplicated().sum()","86366c88":"# We will drop the Duplicate value:\ndf=df.drop_duplicates(keep=\"first\")","d9556729":"df[\"workclass\"]=df[\"workclass\"].replace(\"?\",np.nan)\ndf[\"occupation\"]=df[\"occupation\"].replace(\"?\",np.nan)\ndf[\"native.country\"]=df[\"native.country\"].replace(\"?\",np.nan)","3d283311":"df.isna().sum()","bd4cb889":"df[\"workclass\"]=df[\"workclass\"].fillna(df[\"workclass\"].mode()[0])\ndf[\"occupation\"]=df[\"occupation\"].fillna(df[\"occupation\"].mode()[0])\ndf[\"native.country\"]=df[\"native.country\"].fillna(df[\"native.country\"].mode()[0])","8b63b177":"fig =  plt.figure(figsize = (15,6))\nfig.patch.set_facecolor('#f5f6f6')\n\n\n                                                   \ngs = fig.add_gridspec(2,3)\ngs.update(wspace=0.2,hspace= 0.2)\n\nax0 = fig.add_subplot(gs[0,0])\nax1 = fig.add_subplot(gs[0,1])\nax2 = fig.add_subplot(gs[0,2])\nax3 = fig.add_subplot(gs[1,0])\nax4 = fig.add_subplot(gs[1,1])\nax5 = fig.add_subplot(gs[1,2])\n\naxes=[ax0,ax1,ax2,ax3,ax4,ax5]\nfor ax in axes:\n    ax.set_facecolor('#f5f6f6')\n    ax.tick_params(axis='x',\n                   labelsize = 12, which = 'major',\n                   direction = 'out',pad = 2,\n                   length = 1.5)\n    ax.tick_params(axis='y', colors= 'black')\n    ax.axes.get_yaxis().set_visible(False)\n    \n    for loc in ['left', 'right', 'top', 'bottom']:\n        ax.spines[loc].set_visible(False)\n\n\n        \ncols = df.select_dtypes(exclude = 'object').columns\n\nsns.kdeplot(x = df[cols[0]],color=\"green\",fill=True,ax = ax0)\nsns.kdeplot(x = df[cols[1]],color=\"red\",fill=True,ax = ax1)\nsns.kdeplot(x = df[cols[2]],color=\"blue\",fill=True,ax = ax2)\nsns.kdeplot(x = df[cols[3]],color=\"black\",fill=True,ax = ax3)\nsns.kdeplot(x = df[cols[4]],color=\"pink\",fill=True,ax = ax4)\nsns.kdeplot(x = df[cols[5]],color=\"green\",fill=True,ax = ax5)\n\nfig.text(0.2,0.98,\"Univariate Analysis on Numerical Columns:\",**{'font':'serif', 'size':18,'weight':'bold'}, alpha = 1)\nfig.text(0.1,0.90,\"Most of the adults are range of 20-45 and on average an adult spend around 40hrs per week on work\\n Also as we can see there is so much otliers present in the numerical columns:\",**{'font':'serif', 'size':12,'weight':'bold'}, alpha = 1)\n","edf4e359":"df.select_dtypes(include=\"object\").columns","cc83fea2":"income=df[\"income\"].reset_index()\npx.pie(values=income[\"index\"],names=income[\"income\"], color_discrete_sequence=px.colors.sequential.RdBu,\n      title='Income of the Adults')","89e848cd":"sex=df[\"sex\"].reset_index()\npx.pie(values=sex[\"index\"],names=sex[\"sex\"],title='%AGE OF MALE AND FEMALE', hole=.3)\n","5c0cb2dd":"race=df[\"race\"].reset_index()\npx.pie(values=race[\"index\"],names=race[\"race\"])","54721ecd":"relationship=df[\"relationship\"].reset_index()\npx.pie(values=relationship[\"index\"],names=relationship[\"relationship\"])","8fc213f3":"occupation=df[\"occupation\"].reset_index()\npx.pie(values=occupation[\"index\"],names=occupation[\"occupation\"])","5169a9c1":"marital_status=df[\"marital.status\"].reset_index()\npx.pie(values=marital_status[\"index\"],names=marital_status[\"marital.status\"])","eaadb719":"education=df[\"education\"].reset_index()\npx.pie(values=education[\"index\"],names=education[\"education\"])","2d3362ba":"\nfig=plt.figure(figsize=(10,6))\nax=sns.countplot(df[\"workclass\"])\nplt.title(\"COUNT OF WORK CLASS\")\n\nfor loc in ['left', 'right', 'top', 'bottom']:\n    ax.spines[loc].set_visible(False)\n    \n\nfig.show()\n\n#workcls=df[\"workclass\"].reset_index()\n#px.pie(values=workcls[\"index\"],names=workcls[\"workclass\"])","9d415f1f":"df.head(1)","5539cf01":"fig=plt.figure(figsize=(10,6))\nax=sns.kdeplot(x=df[\"age\"],hue=df[\"income\"],fill=True)\nax.set_facecolor('#f5f6f6')\nfor loc in ['left', 'right', 'top', 'bottom']:\n    ax.spines[loc].set_visible(False)\n \nfig.text(0.4,1,\"Distribution of income with age:\",**{'font':'serif', 'size':18,'weight':'bold'}, alpha = 1)\nfig.text(0.1,0.90,\"First of all most of the adults have income less than 50k \\n But With increasing in age Income is also increasing :\",**{'font':'serif', 'size':12,}, alpha = 1)\n\n\nfig.show()\n","a41ae2bf":"fig=plt.figure(figsize=(10,6))\nax=sns.kdeplot(x=df[\"education.num\"],hue=df[\"income\"],fill=True,)\nax.set_facecolor('#f5f6f6')\nfor loc in ['left', 'right', 'top', 'bottom']:\n    ax.spines[loc].set_visible(False)\n \nfig.text(0.2,1,\"Distribution of Number of years of Education with Income:\",**{'font':'serif', 'size':18,'weight':'bold'}, alpha = 1)\nfig.text(0.1,0.90,\"With increasing in years of education Income is also increasing :\",**{'font':'serif', 'size':12,'weight':'bold'}, alpha = 1)\n\n\nfig.show()","980c0d2c":"df.income.unique()","d8f0596c":"df[\"income\"]=df[\"income\"].map({\"<=50K\":0,\">50K\":1})","fd99ce0d":"X = df.drop(['income'], axis=1)\ny = df['income']","e00b4c05":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)","ecc6bd92":"from sklearn import preprocessing\n\ncategorical = ['workclass','education', 'marital.status', 'occupation', 'relationship','race', 'sex','native.country',]\nfor feature in categorical:\n        le = preprocessing.LabelEncoder()\n        X_train[feature] = le.fit_transform(X_train[feature])\n        X_test[feature] = le.transform(X_test[feature])","a8378ee7":"\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nX_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X.columns)\n\nX_test = pd.DataFrame(scaler.transform(X_test), columns = X.columns)","f2a207a7":"from sklearn.ensemble import RandomForestClassifier\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, y_train)\ny_pred = random_forest.predict(X_test)\n\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test,y_pred))","b528e62a":"\nfrom sklearn.linear_model import LogisticRegression\nmodel=LogisticRegression()\nmodel.fit(X_train,y_train)\n\ny_test_pred=model.predict(X_test)\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test,y_pred))","8a3557cd":"from sklearn.metrics import accuracy_score","5fb7cd75":"test_score = accuracy_score(y_test, model.predict(X_test)) * 100\ntrain_score = accuracy_score(y_train, model.predict(X_train)) * 100\n\nresults_df = pd.DataFrame(data=[[\"Logistic Regression\", train_score, test_score]], \n                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\nresults_df","c83fad87":"from sklearn.tree import DecisionTreeClassifier\nmodel=DecisionTreeClassifier()\nmodel.fit(X_train,y_train)\ndt=model.predict(X_test)\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test,y_pred))","3f1d2a25":"from sklearn.svm import SVC\nmodel=SVC(kernel=\"rbf\")\nmodel.fit(X_train,y_train)\nsv=model.predict(X_test)\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test,y_pred))","398680a7":"from sklearn.ensemble import AdaBoostClassifier\n\nmodel=AdaBoostClassifier(learning_rate= 0.15,n_estimators= 25)\nmodel.fit(X_train,y_train)\nab=model.predict(X_test)\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test,y_pred))","a99f4307":"from sklearn.model_selection import GridSearchCV","da7913e4":"clf = DecisionTreeClassifier()\n# Hyperparameter Optimization\nparameters = {'max_features': ['log2', 'sqrt','auto'], \n              'criterion': ['entropy', 'gini'],\n              'max_depth': [2, 3, 5, 10, 50], \n              'min_samples_split': [2, 3, 50, 100],\n              'min_samples_leaf': [1, 5, 8, 10]\n             }\n\n# Run the grid search\ngrid_obj = GridSearchCV(clf, parameters)\ngrid_obj = grid_obj.fit(X_train, y_train)\n\n# Set the clf to the best combination of parameters\nclf = grid_obj.best_estimator_\n\n# Train the model using the training sets \nclf.fit(X_train, y_train)","8cf9b62f":"y_pred = clf.predict(X_test)","7687c37e":"# Calculating the accuracy\nacc_dt = round( metrics.accuracy_score(y_test, y_pred) * 100, 2 )\nprint( 'Accuracy of Decision Tree model : ', acc_dt )","389db06d":"<p id=\"part5\"><\/p>\n\n<p style=\"font-family: Arials; font-size: 16px; font-style: normal; font-weight: normal; letter-spacing: 3px; color: #FF8C00; line-height:1.0\">2.2 Data Types<\/p>","10f51a95":"<p style = \"font-family: Inter, sans-serif; font-size: 14px; color: rgba(0,0,0,.7)\"> Let's calculate the percentage of blanks and filled values for all columns.<\/p>","250efcd7":"<p id=\"part13\"><\/p>\n\n<p style=\"font-family: Arials; font-size: 16px; font-style: bold; font-weight: bold; letter-spacing: 3px; color: #FF8C00; line-height:1.0\">5. Modelling:<\/p>\n\n","db1ff68f":"<p id=\"part11\"><\/p>\n\n<p style=\"font-family: Arials; font-size: 16px; font-style: normal; font-weight: normal; letter-spacing: 3px; color: #FF8C00; line-height:1.0\">3.3 Multi-Variate Analysis:<\/p>","14fe28e7":"## hyper para meter tuning:","73456336":"### In some columns there is ? present or null values let's handle that also:","598d9737":"## knn","1f8a72d7":"from sklearn.neighbors import KNeighborsClassifier\nneig = np.arange(1, 25)\ntrain_accuracy = []\ntest_accuracy = []\n# Loop over different values of k\nfor i, k in enumerate(neig):\n    # k from 1 to 25(exclude)\n    knn = KNeighborsClassifier(n_neighbors=k)\n    # Fit with knn\n    knn.fit(X_train,y_train)\n    #train accuracy\n    train_accuracy.append(knn.score(X_train, y_train))\n    # test accuracy\n    test_accuracy.append(knn.score(X_test, y_test))\n\n# Plot\nplt.figure(figsize=[13,8])\nplt.plot(neig, test_accuracy, label = 'Testing Accuracy')\nplt.plot(neig, train_accuracy, label = 'Training Accuracy')\nplt.legend()\nplt.title('-value VS Accuracy')\nplt.xlabel('Number of Neighbors')\nplt.ylabel('Accuracy')\nplt.xticks(neig)\nplt.savefig('graph.png')\nplt.show()\nprint(\"Best accuracy is {} with K = {}\".format(np.max(test_accuracy),1+test_accuracy.index(np.max(test_accuracy))))","e225092a":"<p id=\"part3\"><\/p>\n\n# <span style=\"font-family: Arials; font-size: 16px; font-style: normal; font-weight: bold; letter-spacing: 3px; color: #FF8C00\">2 DATA DESCRIPTION AND DATA CLEANING<\/span>\n<hr style=\"height: 0.5px; border: 0; background-color: #808080\">\n\n<p style=\"font-family: Arials, sans-serif; font-size: 14px; color: rgba(0,0,0,.7)\">In this block, cleaning part will be carried out, data types, missing values, duplicates.<\/p>","d6d5afb7":"<p id=\"part6\"><\/p>\n\n<p style=\"font-family: Arials; font-size: 16px; font-style: normal; font-weight: normal; letter-spacing: 3px; color: #FF8C00; line-height:1.0\">2.3 Missing values<\/p>","23c601f5":"<p style=\"font-family: Arials; line-height: 1.5; font-size: 16px; font-weight: bold; letter-spacing: 2px; text-align: center; color: #FF8C00\">If you liked this notebook, please upvote.<\/p>\n<p style=\"text-align: center\">\ud83d\ude0a\ud83d\ude0a\ud83d\ude0a<\/p>","5210f877":"<p id=\"part8\"><\/p>\n\n<p style=\"font-family: Arials; font-size: 16px; font-style: normal; font-weight: normal; letter-spacing: 3px; color: #FF8C00; line-height:1.0\">3. Analysis:<\/p>","e50e2394":"<p id=\"part7\"><\/p>\n\n<p style=\"font-family: Arials; font-size: 16px; font-style: normal; font-weight: normal; letter-spacing: 3px; color: #FF8C00; line-height:1.0\">2.4 Duplicates<\/p>","8c35f012":"<p style = \"font-family: Inter, sans-serif; font-size: 14px; color: rgba(0,0,0,.7)\">There are 24 Duplicate Value Present in the Data-set.<\/p>","d7340694":"<p id=\"part2\"><\/p>\n\n# <span style=\"font-family: Arials; font-size: 16px; font-style: normal; font-weight: bold; letter-spacing: 3px; color: #FF8C00\">1 IMPORTING LIBRARIES<\/span>\n<hr style=\"height: 0.5px; border: 0; background-color: #808080\">\n\n<p style=\"font-family: Arials, sans-serif; font-size: 14px; line-height:1.0; color: rgba(0,0,0,.7)\"><strong>LIBRARIES:<\/strong><\/p>\n\n<ol style=\"font-family: Arials, sans-serif; font-size: 14px; line-height:1.5; color: rgba(0,0,0,.7)\">\n<li>Library <strong>pandas<\/strong> will be required to work with data in tabular representation.<\/li>\n<p><\/p>\n<li>Library <strong>numpy<\/strong> will be required to round the data in the correlation matrix.<\/li>\n<p><\/p>\n<li>Library <strong>missingno<\/strong> will be required to visualize missing values in the data.<\/li>\n<p><\/p>   \n<li>Library <strong>matplotlib, seaborn, plotly<\/strong> required for data visualization.<\/li>\n<p><\/p>\n<\/ol>","dadd03b2":"<p style=\"font-family: Arials; font-size: 16px; font-style: bold; font-weight: bold; letter-spacing: 3px; color: #FF8C00; line-height:1.0\">5.0 Make data ready for Modelling:<\/p>","c8af50ce":"<p id=\"part10\"><\/p>\n\n<p style=\"font-family: Arials; font-size: 16px; font-style: normal; font-weight: normal; letter-spacing: 3px; color: #FF8C00; line-height:1.0\">3.2 Bi-Variate Analysis:<\/p>","a008f9ea":"## Random forest","b43d6417":"<p id=\"part9\"><\/p>\n\n<p style=\"font-family: Arials; font-size: 16px; font-style: normal; font-weight: normal; letter-spacing: 3px; color: #FF8C00; line-height:1.0\">3.1 Uni-variate Analysis:<\/p>","fa3fed71":"<p id=\"part0\"><\/p>\n\n<p style=\"font-family: Arials; line-height: 2; font-size: 24px; font-weight: bold; letter-spacing: 2px; text-align: center; color: #FF8C00\">Adult Income \ud83d\udcb8\ud83e\udd11\ud83d\udcb0 <\/p>\n\n<img src=\"https:\/\/miro.medium.com\/max\/1000\/1*08ltbgXFxujakJZSJswp1Q.png\" width=\"100%\" align=\"center\" hspace=\"5%\" vspace=\"5%\"\/>\n\n<p style = \"font-family: Inter, sans-serif; font-size: 14px; color: rgba(0,0,0,.7)\"> An individual\u2019s annual income results from various factors. Intuitively, it is influenced by the individual\u2019s education level, age, gender, occupation, and etc.<\/p>\n\n\n<p style=\"font-family: Arials; font-size: 20px; font-style: normal; font-weight: bold; letter-spacing: 3px; color: #808080; line-height:1.0\">TABLE OF CONTENT<\/p>\n\n<p style=\"font-family: Arials; font-size: 16px; font-style: normal; font-weight: bold; letter-spacing: 2px; color: #808080; line-height:1.3\"><a href=\"#part1\" style=\"color:#808080\">0 PROLOGUE<\/a><\/p>\n\n<p style=\"font-family: Arials; font-size: 16px; font-style: normal; font-weight: bold; letter-spacing: 2px; color: #808080; line-height:1.3\"><a href=\"#part2\" style=\"color:#808080\">1 IMPORTING LIBRARIES<\/a><\/p>\n\n<p style=\"font-family: Arials; font-size: 16px; font-style: normal; font-weight: bold; letter-spacing: 2px; color: #808080; line-height:1.3\"><a href=\"#part3\" style=\"color:#808080\">2 DATA DESCRIPTION AND DATA CLEANING<\/a><\/p>\n\n<p style=\"text-indent: 1vw; font-family: Arials; font-size: 14px; font-style: normal; font-weight: bold; letter-spacing: 2px; color: #808080; line-height:1.3\">\n<a href=\"#part4\" style=\"color:#808080\">2.1 Import Data<\/a><\/p>\n\n<p style=\"text-indent: 1vw; font-family: Arials; font-size: 14px; font-style: normal; font-weight: bold; letter-spacing: 2px; color: #808080; line-height:1.3\">\n<a href=\"#part5\" style=\"color:#808080\">2.2 Data types<\/a><\/p>\n\n<p style=\"text-indent: 1vw; font-family: Arials; font-size: 14px; font-style: normal; font-weight: bold; letter-spacing: 2px; color: #808080; line-height:1.3\">\n<a href=\"#part6\" style=\"color:#808080\">2.3 Missing values<\/a><\/p>\n\n<p style=\"text-indent: 1vw; font-family: Arials; font-size: 14px; font-style: normal; font-weight: bold; letter-spacing: 2px; color: #808080; line-height:1.3\"> \n<a href=\"#part7\" style=\"color:#808080\">2.4 Duplicates<\/a><\/p>\n\n\n<p style=\"font-family: Arials; font-size: 16px; font-style: normal; font-weight: bold; letter-spacing: 2px; color: #808080; line-height:1.3\"><a href=\"#part8\" style=\"color:#808080\">3 ANALYSIS<\/a><\/p>\n\n<p style=\"text-indent: 1vw; font-family: Arials; font-size: 14px; font-style: normal; font-weight: bold; letter-spacing: 2px; color: #808080; line-height:1.3\"> \n<a href=\"#part9\" style=\"color:#808080\">3.1 Uni-Vriate Analysis:<\/a><\/p>\n\n<p style=\"text-indent: 1vw; font-family: Arials; font-size: 14px; font-style: normal; font-weight: bold; letter-spacing: 2px; color: #808080; line-height:1.3\"> \n<a href=\"#part10\" style=\"color:#808080\">3.2 Bi-Vriate Analysis:<\/a><\/p>\n\n<p style=\"text-indent: 1vw; font-family: Arials; font-size: 14px; font-style: normal; font-weight: bold; letter-spacing: 2px; color: #808080; line-height:1.3\"> \n<a href=\"#part11\" style=\"color:#808080\">3.3 Multi-Vriate Analysis:<\/a><\/p>\n\n\n<p style=\"font-family: Arials; font-size: 16px; font-style: normal; font-weight: bold; letter-spacing: 2px; color: #808080; line-height:1.3\"><a href=\"#part12\" style=\"color:#808080\">4 FINAL CONCLUSIONS<\/a><\/p>\n\n<p style=\"font-family: Arials; font-size: 16px; font-style: normal; font-weight: bold; letter-spacing: 2px; color: #808080; line-height:1.3\"><a href=\"#part13\" style=\"color:#808080\">5 MODELLING<\/a><\/p>","bc908cfb":"<div style=\"background: #DCDCDC\"><p style=\"font-family: Arials, sans-serif; font-size: 16px; color: #000000\"><strong>CONCLUSION:<\/strong> The data has no missing values, so no further transformations are required.<\/p><\/div>","6ce7df70":"<div style=\"background: #DCDCDC\"><p style=\"font-family: Arials, sans-serif; font-size: 16px; color: #000000\"><strong>CONCLUSION:<\/strong>Now our Data is Clean We can do Further Analysis.<\/p><\/div>","414a415b":"<p id=\"part4\"><\/p>\n\n<p style=\"font-family: Arials; font-size: 16px; font-style: normal; font-weight: normal; letter-spacing: 3px; color: #FF8C00; line-height:1.0\">2.1 Import Data<\/p>","6733bca5":"<p style=\"font-family: Arials; line-height: 1.5; font-size: 16px; font-weight: bold; letter-spacing: 2px; text-align: center; color: #FF8C00\">Thank you for reading this work!\nAny feedback on this work would be very grateful.\nIf you liked this notebook, Upvote.<\/p>\n    <p style=\"text-align: center\">\ud83d\ude0a\ud83d\ude0a\ud83d\ude0a<\/p>","579e4ca4":"<p id=\"part1\"><\/p>\n\n<p style=\"font-family: Arials; font-size: 16px; font-style: bold; font-weight: bold; letter-spacing: 3px; color: #FF8C00\">0 PROLOGUE<\/p>\n<hr style=\"height: 0.5px; border: 0; background-color: #808080\">\n\n\n\n<p style=\"font-family: Arials, sans-serif; font-size: 14px; color: rgba(0,0,0,.7)\"><strong>FEATURES:<\/strong><\/p>\n\n<ol style=\"font-family: Arials, sans-serif; font-size: 14px; line-height:1.5; color: rgba(0,0,0,.7)\">\n<li><strong>AGE<\/strong> -continuous. <\/li>\n<p><\/p>    \n<li><strong> workclass<\/strong> -Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.<\/li>\n<p><\/p>\n<li><strong>fnlwgt<\/strong> -continuous.<\/li>\n<p><\/p>    \n<li><strong>education<\/strong> - Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.<\/li>   \n<p><\/p>    \n<li><strong>education-num<\/strong> - continuous.<\/li>   \n<p><\/p>    \n<li><strong>marital-status<\/strong> -Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.<\/li>    \n<p><\/p>    \n<li><strong>occupation<\/strong> -Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.<\/li>      \n<p><\/p>     \n<li><strong>relationship<\/strong> -Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.<\/li>    \n<p><\/p> \n<li><strong>race<\/strong> -White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.<\/li>    \n<p><\/p> \n<li><strong>sex<\/strong> -Female, Male.<\/li>    \n<p><\/p>\n<li><strong>capital-gain<\/strong> -continuous.<\/li>    \n<p><\/p> \n<li><strong>capital-loss<\/strong> -continuous.<\/li>    \n<p><\/p>\n<li><strong>hours-per-week<\/strong> -continuous.<\/li>    \n<p><\/p>\n<li><strong>native-country<\/strong> -United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.<\/li>    \n<p><\/p>\n<li><strong>class<\/strong> - >50K, <=50K<\/li>    \n<p><\/p>\n   \n<\/ol>\n\n\n\n"}}