{"cell_type":{"fc260082":"code","fb6f6b4f":"code","7946ff0d":"code","78185324":"code","5a66bbf2":"code","f5a5b855":"code","19bf198b":"code","fdbf4aef":"code","18ccc865":"code","79d9e4b8":"code","ac7b965e":"code","5a371d8a":"code","bd62eb32":"code","3016d6c2":"code","21ac09b5":"code","28681d8b":"code","e924be3f":"code","46e19b11":"code","b1f527cf":"code","455b40e8":"code","5cf27d58":"code","6c6f0bc6":"code","d06b325e":"code","03268d67":"code","57c81353":"code","0ae22d64":"code","3c200579":"code","ea1b5783":"code","07deddb2":"code","2450eaf7":"code","a90b7b6f":"code","eb816b87":"code","c594db65":"code","5e2d56db":"code","e30d2dcb":"code","7c63c18a":"code","b69653f1":"code","89bd5a08":"markdown","f4258940":"markdown","9cd385f5":"markdown","a82e6aa5":"markdown","527030c3":"markdown","e8857d6f":"markdown","d1d9b52a":"markdown","7cc27726":"markdown","bc409e3a":"markdown","b62ccc40":"markdown","120ef8fb":"markdown","77f3de9d":"markdown","155b613c":"markdown","871c22fd":"markdown","91f30e21":"markdown","e3f4de20":"markdown","b8d3bc33":"markdown","8c773c72":"markdown","0a993e56":"markdown"},"source":{"fc260082":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fb6f6b4f":"import numpy as np \nimport pandas as pd\nimport calendar\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport squarify\nimport gc\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\nimport time\nimport datetime\nfrom datetime import datetime\nimport calendar\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.cluster import KMeans\n\nsns.set_style('white')\n\n\npd.options.display.float_format = '{:,.2f}'.format","7946ff0d":"df_sorted = pd.read_pickle('\/kaggle\/input\/easymoney\/EasyMoney_base.pkl',compression='zip')","78185324":"df_sorted.info()","5a66bbf2":"df_sorted['hayAlta']=0","f5a5b855":"df_sorted.loc[ (df_sorted['dif_debit_card']==1) |        \n            (df_sorted['dif_em_account_p']==1) |                \n            (df_sorted['dif_em_account_pp']==1) |              \n            (df_sorted['dif_em_account_pp']==1) |              \n            (df_sorted['dif_em_acount']==1) |                   \n            (df_sorted['dif_emc_account']==1) |                 \n            (df_sorted['dif_payroll']==1) |                     \n            (df_sorted['dif_payroll_account']==1) |             \n            (df_sorted['dif_funds']==1) |                        \n            (df_sorted['dif_long_term_deposit']==1) |            \n            (df_sorted['dif_mortgage']==1) |                    \n            (df_sorted['dif_pension_plan']==1) |                \n            (df_sorted['dif_securities']==1) |                 \n            (df_sorted['dif_short_term_deposit']==1) |          \n            (df_sorted['dif_loans']==1) |                      \n            (df_sorted['dif_credit_card']==1),'hayAlta']=1 ","19bf198b":"df_sorted['hayAlta'].value_counts()","fdbf4aef":"df_altas=df_sorted[['pk_cid','pk_partition','hayAlta']].sort_values(by=['pk_cid','pk_partition'])","18ccc865":"df_altas","79d9e4b8":"df_altas['diasLastAlta']=df_altas.groupby(['pk_cid','hayAlta'])['pk_partition'].diff()","ac7b965e":"df_altas","5a371d8a":"df_sorted = pd.read_pickle('\/kaggle\/input\/easymoney\/EasyMoney_base.pkl',compression='zip')","bd62eb32":"df_altas=df_sorted[['pk_cid','pk_partition','hayAlta']].sort_values(by=['pk_cid','pk_partition'])","3016d6c2":"df_altas['diasLastAlta']=0","21ac09b5":"len(df_altas)","28681d8b":"j=0\nfor x in range(1,20):\n    if (x%5==0): print(x)","e924be3f":"j=0\nfechaAlta=pd.Timedelta(days=1)\nfor x in df_altas.index.tolist():\n    # Si es el primer paso por este punto recogemos el pk_cid en la variable cliente\n    if (j==0):\n        cliente=df_altas.iloc[x]['pk_cid']\n    # Vemos si el cliente ha cambiao o sigue siendo el mismo en otra fecha posterior\n    if (cliente == df_altas.iloc[x]['pk_cid']):\n        # Si es el mismo comprobamos si hay alta ese mes. Si la hay ponemos un 0 en diasLastAlta\n        # y metemos la fecha del mes en curso en fechaAlta\n        if (df_altas.iloc[x]['hayAlta']==1):\n            df_altas.iloc[x,3]=pd.Timedelta(days=0)\n            fechaAlta=df_altas.iloc[x]['pk_partition']\n        else:\n            if (fechaAlta != pd.Timedelta(days=1)):\n                df_altas.iloc[x,3]=df_altas.iloc[x]['pk_partition']-fechaAlta\n            else:\n                df_altas.iloc[x,3]=pd.Timedelta(days=1)\n            #print(df_altas.iloc[x]['pk_partition']-fechaAlta)\n    else:\n        if (df_altas.iloc[x]['hayAlta']==1):\n            df_altas.iloc[x,3]=pd.Timedelta(days=0)\n            fechaAlta=df_altas.iloc[x]['pk_partition']\n        else:\n            df_altas.iloc[x,3]=pd.Timedelta(days=1) \n            fechaAlta=pd.Timedelta(days=1)\n    cliente=df_altas.iloc[x]['pk_cid']\n    j+=1\n    if(j % 100 == 0): print(j,time.strftime(\"%d\/%m\/%y %H:%M:%S\"))","46e19b11":"df_altas.head(1800)","b1f527cf":"len(df_altas['pk_cid'].unique().tolist())","455b40e8":"lista1=[]\nlista2=[]\nlista3=[]\nlista4=[]\nj=4\nfor x in df_altas['pk_cid'].unique().tolist():\n    if (j % 4 == 0): lista1.append(x)\n    if (j % 4 == 1): lista2.append(x)\n    if (j % 4 == 2): lista3.append(x)\n    if (j % 4 == 3): lista4.append(x)\n    j+=1","5cf27d58":"len (lista1),len (lista2),len (lista3),len (lista4)","6c6f0bc6":"print(len (lista1)+len (lista2)+len (lista3)+len (lista4))","d06b325e":"df_altas1=df_altas[df_altas['pk_cid'].isin(lista1)]","03268d67":"df_altas2=df_altas[df_altas['pk_cid'].isin(lista2)]","57c81353":"df_altas3=df_altas[df_altas['pk_cid'].isin(lista3)]","0ae22d64":"df_altas4=df_altas[df_altas['pk_cid'].isin(lista4)]","3c200579":"df_altas1.to_pickle('df_altas1.pkl',compression='zip')\ndf_altas2.to_pickle('df_altas2.pkl',compression='zip')\ndf_altas3.to_pickle('df_altas3.pkl',compression='zip')\ndf_altas4.to_pickle('df_altas4.pkl',compression='zip')\n","ea1b5783":"df_altas=pd.read_pickle('..\/Datos\/df_altasFecha_1.pkl',compression='zip')\nfor x in range(2,9):\n    df_=pd.read_pickle('..\/Datos\/df_altasFecha_'+str(x)+'.pkl',compression='zip')\n    df_altas=pd.concat([df_altas,df_], axis=0)","07deddb2":"df_sorted=pd.merge(df_sorted,df_altas, how=\"inner\",on=['pk_cid','pk_partition' ])","2450eaf7":"df_sorted = pd.read_pickle('\/kaggle\/input\/easymoney\/EasyMoney_base.pkl',compression='zip')","a90b7b6f":"lista_mostrar=['pk_cid','pk_partition','isNewClient','isActive','totalAssets','totalCuentas','totalAhorro','totalFinanciacion','totalIngresos','totalBeneficio','hayAlta','diasDesdeUltimaAlta']","eb816b87":"df_sorted[df_sorted['pk_cid']==1515194][lista_mostrar]","c594db65":"df_sorted['diasDesdeUltimaAlta']","5e2d56db":"df_sorted['diasDesdeUltimaAltaInt']=pd.to_timedelta(df_sorted['diasDesdeUltimaAlta']).dt.days","e30d2dcb":"lista_mostrar=['pk_cid','pk_partition','isNewClient','isActive','totalAssets',\n               'totalCuentas','totalAhorro','totalFinanciacion','totalIngresos',\n               'totalBeneficio','hayAlta','diasDesdeUltimaAlta','diasDesdeUltimaAltaInt']","7c63c18a":"df_sorted[df_sorted['pk_cid']==1515194][lista_mostrar]","b69653f1":"df_sorted.info()","89bd5a08":"La opcion que se me ha ocurrido es partir el dataset en 4 y correrlo en 4 procesos simultaneos en una m\u00e1quina de 4 cores.\nDe esta manera nos aseguramos un maximo rendimiento en ese hardware.","f4258940":"La unimos al dataset base:","9cd385f5":"Agrupamos por ['pk_cid','hayAlta'] y hacemos un diff() para que reste cada valor con el anterior. Asi intentamos sacar los dias desde el ultimo alta de un producto Easymoney","a82e6aa5":"Como esta serie esta en un formato fecha\/object lo mejor es cambiarlo a Timedelta y sacar los dias.","527030c3":"los escribimos a disco:","e8857d6f":"Sacamos 4 listas con los ids de clientes repartidos de forma \"aleatoria\" entre ellas:","d1d9b52a":"No funciona bien. probamos otra froma de hacerlo:","7cc27726":"Una vez procesada cada parte las juntamos de nuevo:","bc409e3a":"Generamos la variable 'diasLastAlta' a 0:","b62ccc40":"Y nos queda:","120ef8fb":"Ordenamos el dataset por cliente, fecha. Nos quedamos un subconjunto de este solo con los campos:\n'pk_cid','pk_partition','hayAlta'","77f3de9d":"Creamos la variable hayAlta que si no la hay sera 0 y si ese mes se ha dado el alta de algun producto ,el que sea, sera 1.","155b613c":"Vemos que las altas son bastante menos comunes que los meses dondo no hya cambios","871c22fd":"# Lo multiplexamos en 4 procesos","91f30e21":"# Metodo 2 de obtencion:","e3f4de20":"# Pasamos el campo diasDesdeUltimaAlta' a integer","b8d3bc33":"El proceso es muy lento y no es un problema solucionable con fuerza bruta, ya que el bucle recorre\nde forma secuencial el dataset y no importa el numero de procesadores disponibles en la maquina. \nEste proceso solo cojera un procesador y no usara el resto. ","8c773c72":"Las abriremos despues cada una en un notebook y ejecutaremos el bucle anterior","0a993e56":"Hacemos los 4 nuevos subdatasets:"}}