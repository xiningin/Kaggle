{"cell_type":{"5d04ada4":"code","94ec8723":"code","bf74d563":"code","0f8e7c48":"code","aed19c9a":"code","6a20ccec":"code","84c8f5f4":"code","adc379f8":"code","88f3aa93":"code","b9e97e22":"code","66166fbc":"code","d727f2a2":"code","705fafdc":"code","b957bdaf":"code","567d1430":"markdown","98704bf8":"markdown","1a2ef79b":"markdown","e15190e3":"markdown","f6079a61":"markdown","8f6160e7":"markdown","a7e69a7a":"markdown","da388e81":"markdown","fd7c40d9":"markdown","a18dd2be":"markdown","dc9677a8":"markdown","56c2bac1":"markdown","a6994c8e":"markdown","ce939965":"markdown","74bb0f9c":"markdown","b8d22bae":"markdown","4356550f":"markdown","12a4415f":"markdown","9ece6ec3":"markdown","710d8dad":"markdown","03b7c756":"markdown"},"source":{"5d04ada4":"import numpy as np\nimport pandas as pd \nimport keras\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport random\nimport os\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import GridSearchCV\n","94ec8723":"# dog image\nfilenames = os.listdir(\"..\/input\/cat-and-dog\/training_set\/training_set\/dogs\")\n# choose a random image\nsample = random.choice(filenames)\nimage = load_img(\"..\/input\/cat-and-dog\/training_set\/training_set\/dogs\/\"+sample)\nplt.imshow(image)","bf74d563":"# sample image of cat\nfilenames = os.listdir(\"..\/input\/cat-and-dog\/training_set\/training_set\/cats\")\nsample = random.choice(filenames)\nimage = load_img(\"..\/input\/cat-and-dog\/training_set\/training_set\/cats\/\"+sample)\nplt.imshow(image)","0f8e7c48":"FAST_RUN = False\nIMAGE_WIDTH=128\nIMAGE_HEIGHT=128\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\nIMAGE_CHANNELS=3\nbatch_size=15","aed19c9a":"# train image generator\ntrain_datagen = ImageDataGenerator(\n    rotation_range=15,\n    rescale=1.\/255,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)\n\ntrain_generator = train_datagen.flow_from_directory(\n    \"..\/input\/cat-and-dog\/training_set\/training_set\/\", \n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","6a20ccec":"# validation image generator\nvalidation_datagen = ImageDataGenerator(rescale=1.\/255)\nvalidation_generator = validation_datagen.flow_from_directory(\n    \"..\/input\/cat-and-dog\/test_set\/test_set\/\", \n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","84c8f5f4":"# initializing the CNN\nmodel = Sequential()\n\n# Convolution layer-1\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# Convolution layer-2\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# Convolution layer-3\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# flattening layer\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n# Output layer\nmodel.add(Dense(2, activation='softmax')) # 2 because we have cat and dog classes\n\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n# summary of model\nmodel.summary()","adc379f8":"# EarlyStopping\nearlystop = EarlyStopping(monitor = 'val_loss',\n                          min_delta = 0,\n                          patience = 7,\n                          verbose = 1,\n                          restore_best_weights = True)\n\n# ModelCheckPoint\ncheckPoint = keras.callbacks.ModelCheckpoint(filepath=\"\/content\/sample_data\/cd_model.h5\",\n                             monitor='val_loss',\n                             mode='min',\n                             save_best_only=True,\n                             verbose=1)\n\n# ReduceLROnPlateau\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n\n# TBoard = tf.keras.callbacks.TensorBoard(log_dir='.\/logs')","88f3aa93":"callbacks = [earlystop , checkPoint, learning_rate_reduction]","b9e97e22":"# this code is to show how much time required to train the model using different algorithms\nfrom datetime import datetime\ndef timer(start_time= None):\n  if not start_time:\n    start_time=datetime.now()\n    return start_time\n  elif start_time:\n    thour,temp_sec=divmod((datetime.now()-start_time).total_seconds(),3600)\n    tmin,tsec=divmod(temp_sec,60)\n    print('\\n Time taken: %i hours %i minutes and %s seconds. '% (thour,tmin,round(tsec,2)))","66166fbc":"start_time=timer(None)\nepochs=3 if FAST_RUN else 40   # 37 is good\nclassifier = model.fit_generator(\n    train_generator, \n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=2023\/\/batch_size, # 2023 is training data size\n    steps_per_epoch=8005\/\/batch_size,  # 8005 is testing data size\n    callbacks=callbacks\n)\ntimer(start_time)","d727f2a2":"# As we have used ModelCheckpoint callback function.So no need to save again if your model trained completely.\n#Saving Scikitlearn models\nmodel.save(\"cat_dog_classifierr.h5\")","705fafdc":"from keras.models import load_model\nnew_model = load_model('cat_dog_classifierr.h5')","b957bdaf":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n\n# plot graph of training loss & validation loss\nax1.plot(classifier.history['loss'], color='b', label=\"Training loss\")\nax1.plot(classifier.history['val_loss'], color='r', label=\"validation loss\")\nax1.set_xticks(np.arange(1, 30, 1))\nax1.set_yticks(np.arange(0, 1, 0.1))\nax1.set_xlabel(\"epochs\")\nax1.set_ylabel(\"loss\")\nax1.set_title(\"Graph of training loss & validation loss\")\n\n# plot graph of training accuracy & validation accuracy\nax2.plot(classifier.history['accuracy'], color='b', label=\"Training accuracy\")\nax2.plot(classifier.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nax2.set_xticks(np.arange(1, 30, 1))\nax1.set_xlabel(\"epochs\")\nax1.set_ylabel(\"accuracy\")\nax1.set_title(\"Graph of training accuracy & validation accuracy\")\n\nlegend = plt.legend(loc='best', shadow=True)\nplt.tight_layout()\nplt.show()","567d1430":"## **3.1. Define Constants**","98704bf8":"# **Table of Contents**\n\n1. Introduction\n1. Import library\n1. Prepare training data\n1. Data pre-processing\n1. Model building\n\n\n","1a2ef79b":"# **6. Save the Model**","e15190e3":"## **3.2. Training Generator**","f6079a61":"## **4.3. Validation Generator**","8f6160e7":"# **5. Model Fitting**","a7e69a7a":"# **2. Prepare Training Data**","da388e81":"## **5.1. Callback Functions**\nA callback is a set of functions to be applied at given stages of the training procedure. You can use callbacks to get a view on internal states and statistics of the model during training.\n- **EarlyStopping** : Used to avoid overfitting.Here we'll stop the training if there is no improvement in 3 conjecutive epochs.\n- **ModelCheckpoint** : This callback saves the model after every epoch.The model'll save in a particular location with minimun 'val_loss'.\n- **ReduceLROnPlateau** : It reduces learning rate when a metric has stopped improving.\nFor more about callback function click [here](https:\/\/www.kdnuggets.com\/2019\/08\/keras-callbacks-explained-three-minutes.html) [here](https:\/\/keras.io\/api\/callbacks\/)","fd7c40d9":"# **Introduction**\n\nIn this project, we'll write an algorithm to classify whether images contain either a dog or a cat.  This is easy for humans, dogs, and cats but our computer will find it a bit more difficult.\n### Data Description\nThe folder \"train\" contains two sub-folders \"cats\" & \"dogs\" which contain images of cats and dogs respectively.The folder \"test1\" contain unknown images which we have to classify.\n### Data\nTo download the Dataset click [here](https:\/\/www.kaggle.com\/c\/dogs-vs-cats\/data)\n### Objective\nTo build a deep learning classification model which classify whether images contain either a dog or a cat. \n\n","a18dd2be":"If you get any issues during run this notebook.Feel free to contact.\n[Linkedin](https:\/\/www.linkedin.com\/in\/sidharth178),\n[Github](https:\/\/github.com\/sidharth178)\n\nThank You.\n","dc9677a8":"# **5. Model Building**\n<img src=\"https:\/\/media.geeksforgeeks.org\/wp-content\/uploads\/cat-vs-dog.jpg\" width=\"100%\"\/>","56c2bac1":"<a href=\"https:\/\/colab.research.google.com\/github\/sidharth178\/Cat-Dog-Classification-Flask-App\/blob\/master\/cat_dog_classification.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>","a6994c8e":"# **7. Visualize training accuracy and loss**","ce939965":"## **Dog**","74bb0f9c":"## **6.2. Load Model**","b8d22bae":"## **Cat**","4356550f":"## **2.1. Sample Image**","12a4415f":"# **1. Import Library**","9ece6ec3":"### The complete code of \"Cat Dog Classification Flask App\" is available on my github profile.\n### Click [here](https:\/\/github.com\/sidharth178\/Cat-Dog-Classification-Flask-App) to access.","710d8dad":"# **3.Data Pre-processing**","03b7c756":"* **Conv Layer**: Convolutional layers are the layers where filters are applied to the original image, or to other feature maps in a deep CNN.\n* **Conv2D Layer**: Conv2D is a 2D Convolution Layer, this layer creates a convolution kernel that is wind with layers input which helps produce a tensor of outputs.\n* **Pooling Layer**: Its function is to progressively reduce the spatial size of the representation to reduce the amount of parameters and computation in the network.\n* **Fully Connected Layer**: It connect the network from a layer to another layer\n* **Output Layer**: It is the predicted values layer. \n* **BatchNormalization**: Layer that normalizes its inputs.Batch normalization applies a transformation that maintains the mean output close to 0 and the output standard deviation close to 1."}}