{"cell_type":{"c8270b68":"code","b0b3ba4c":"code","635d9793":"code","f0b7fb58":"code","2ce9c897":"code","da5c0b36":"code","0777430b":"code","f251ed7b":"code","52440001":"code","a563ceea":"markdown","04025951":"markdown","f48be2eb":"markdown","2ed2a031":"markdown","9f6afbdf":"markdown","01e6b185":"markdown"},"source":{"c8270b68":"# Import essentials\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# You should see `train.xlsx` and `test.xlsx` here","b0b3ba4c":"train_df = pd.read_excel('..\/input\/train.xlsx') # Load the `train` file\ntrain_df.sample(frac=0.1)[:10] # Show a sample of the dataset","635d9793":"test_df = pd.read_excel('..\/input\/test.xlsx') # Load the `test` file\ntest_df.sample(frac=0.1)[:10] # Show a sample of the dataset","f0b7fb58":"for x in test_df.sample(frac=0.1)[:5]['text']:\n    print(x)\n    print(\"---------------\")","2ce9c897":"import re\nfrom stop_words import get_stop_words\n\ndef stop_words():\n    \"\"\"Retrieve the stop words for vectorization -Feel free to modify this function\n    \"\"\"\n    return get_stop_words('es') + get_stop_words('ca') + get_stop_words('en')\n\n\ndef filter_mentions(text):\n    \"\"\"Utility function to remove the mentions of a tweet\n    \"\"\"\n    return re.sub(\"@\\S+\", \"\", text)\n\n\ndef filter_hashtags(text):\n    \"\"\"Utility function to remove the hashtags of a tweet\n    \"\"\"\n    return re.sub(\"#\\S+\", \"\", text)","da5c0b36":"# Preprocess data\nfrom sklearn.feature_extraction.text import CountVectorizer\nvectorizer = CountVectorizer(stop_words=stop_words())\nX = vectorizer.fit_transform(train_df['text']).toarray()\ny = train_df['party'].values","0777430b":"from sklearn.naive_bayes import BernoulliNB\nfrom sklearn.model_selection import train_test_split\n\n# Split train and test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n\n# My first Naive Bayes classifier!\nclf = BernoulliNB()\nclf.fit(X_train, y_train)\nprediction = clf.predict(X_test)\nprint(np.mean([prediction == y_test]))","f251ed7b":"# 1 Train the classifier\nclf = BernoulliNB()\nclf.fit(X_train, y_train)\n\n# 2 Predict the data (We need to tokenize the data using the same vectorizer object)\nX_test = vectorizer.transform(test_df['text']).toarray()\nprediction = clf.predict(X_test)\n\n# 3 Create a the results file\noutput = pd.DataFrame({'Party': prediction})\noutput.index.name = 'Id'\noutput.to_csv('sample_submission.csv')\n\n# TIP - Copy and paste this function to generate the output file in your code\ndef save_submission(prediction):\n    import datetime\n    t = datetime.datetime.now().strftime(\"%Y%m%d-%H:%M:%S\")\n    output = pd.DataFrame({'Party': prediction})\n    output.index.name = 'Id'\n    output.to_csv(f'sample_submission{t}.csv')","52440001":"output[:10] # This is how your result file might look like","a563ceea":"## 2. Are you able to manually classify these tweets?","04025951":"## 5. Create submission file\n\nTo create submission file we need to predict the categories for the test tweets, to do so we need to:\n1. Train a classifier with `train.xslx` data.\n2.  Predict the labels for `test.xlsx` tweets\n3. Generate an output file in csv format\n4. Upload the results to Kaggle","f48be2eb":"## 3. Data Processing","2ed2a031":"## 1. Load Data","9f6afbdf":"# Politician Tweets - Classification Baseline","01e6b185":"## 4. Classification - Bernoulli Naive Bayes"}}