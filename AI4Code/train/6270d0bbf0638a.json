{"cell_type":{"30d24876":"code","b33fd13b":"code","6bc1c6c8":"code","e7431bfb":"code","8b027bb5":"code","c01b7b93":"code","3679ed8b":"code","07d7ec2d":"code","19a80483":"code","8611e051":"code","830f4a65":"code","2c847deb":"code","bde08596":"code","07751811":"code","bb1ac4c7":"code","8e457df7":"code","03806dd3":"code","d341c485":"code","593f1394":"code","7623cd9a":"code","a4646882":"code","9c697d9f":"code","a8f1a442":"code","f2fbe15a":"code","2d148a05":"code","fc423f37":"code","118a9fd9":"code","a0fb28fe":"code","e5be18da":"code","971fbc98":"code","4902c5d4":"code","e795b521":"code","6bb73e94":"code","3ae8e13a":"code","97f41d31":"markdown","e772c57d":"markdown","fedf0687":"markdown","308f62fc":"markdown","4937d651":"markdown","e9a098b3":"markdown"},"source":{"30d24876":"import os\nimport numpy as np\nimport pandas as pd","b33fd13b":"ROOT = \"..\/input\/hpa-single-cell-image-classification\/\"\nos.listdir(ROOT)","6bc1c6c8":"train =  pd.read_csv(ROOT+\"train.csv\")\ntrain.head()","e7431bfb":"sub =  pd.read_csv(ROOT+\"sample_submission.csv\")\nsub.head()","8b027bb5":"train.shape","c01b7b93":"len(os.listdir(ROOT+\"train\/\"))","3679ed8b":"assert len(os.listdir(ROOT+\"train\/\")) == (4 * train.shape[0])\nassert set([i.split(\"_\")[0] for i in os.listdir(ROOT+\"train\/\")]) == set(train.ID.unique())","07d7ec2d":"sub.shape","19a80483":"len(os.listdir(ROOT+\"test\/\"))","8611e051":"os.listdir(ROOT+\"train\/\")[:5]","830f4a65":"import cv2\nimport matplotlib.pyplot as plt","2c847deb":"red = cv2.imread(ROOT+\"train\/5e3a2e6a-bb9c-11e8-b2b9-ac1f6b6435d0_red.png\", cv2.IMREAD_UNCHANGED)\nyellow = cv2.imread(ROOT+\"train\/5e3a2e6a-bb9c-11e8-b2b9-ac1f6b6435d0_yellow.png\", cv2.IMREAD_UNCHANGED)\nblue = cv2.imread(ROOT+\"train\/5e3a2e6a-bb9c-11e8-b2b9-ac1f6b6435d0_blue.png\", cv2.IMREAD_UNCHANGED)\ngreen = cv2.imread(ROOT+\"train\/5e3a2e6a-bb9c-11e8-b2b9-ac1f6b6435d0_green.png\", cv2.IMREAD_UNCHANGED)\nred.shape, yellow.shape, blue.shape, green.shape","bde08596":"plt.imshow(green, cmap='gray');\nplt.show()","07751811":"plt.imshow(yellow, cmap='gray');\nplt.show()","bb1ac4c7":"plt.imshow(blue, cmap='gray');\nplt.show()","8e457df7":"plt.imshow(red, cmap='gray');\nplt.show()","03806dd3":"img = cv2.merge((red, green, blue))  \nplt.imshow(img);\nplt.show()","d341c485":"train.head()","593f1394":"train.Label = train.Label.apply(lambda x: x.split(\"|\"))\ntrain.head()","7623cd9a":"# There are total 18 labels\n\nlabels = {\n0: \"Nucleoplasm\",\n1: \"Nuclear membrane\",\n2: \"Nucleoli\",\n3: \"Nucleoli fibrillar center\",\n4: \"Nuclear speckles\",\n5: \"Nuclear bodies\",\n6: \"Endoplasmic reticulum\",\n7: \"Golgi apparatus\",\n8: \"Intermediate filaments\",\n9: \"Actin filaments\",\n10: \"Microtubules\",\n11: \"Mitotic spindle\",\n12: \"Centrosome\",\n13: \"Plasma membrane\",\n14: \"Mitochondria\",\n15: \"Aggresome\",\n16: \"Cytosol\",\n17: \"Vesicles and punctate cytosolic patterns\",\n18: \"Negative\",\n}","a4646882":"import itertools\nimport seaborn as sns","9c697d9f":"fig, ax = plt.subplots(1,1, figsize=(14, 7))\nsns.countplot([labels[int(i)] for i in itertools.chain.from_iterable(train.Label)], axes=ax);\nplt.title(\"Distribution of labels in training data\")\nplt.xticks(rotation=90)\nplt.show()","a8f1a442":"u = pd.get_dummies(pd.DataFrame(train.Label.tolist()), prefix='', prefix_sep='').groupby(level=0, axis=1).sum()\nv = u.T.dot(u)\nv.values[(np.r_[:len(v)], ) * 2] = 0\nv = v.reindex([str(i) for i in range(1, 19)], axis=1)\nv = v.reindex([str(i) for i in range(1, 19)], axis=0)\nv","f2fbe15a":"co_mat = v\nfig, ax = plt.subplots(1, 1, figsize=(10, 8))\nsns.heatmap((v \/ np.sum(v, axis=0)).T, cbar=True, annot=False)\nplt.show()","2d148a05":"counts = np.bincount(green.reshape(-1))\ncounts = counts \/ np.sum(counts)","fc423f37":"train.head()","118a9fd9":"import tqdm.auto as tqdm","a0fb28fe":"def plotdist(k, color):\n    sample = train.sample(k)\n    count_list = []\n    for i in tqdm.tqdm(sample.ID, leave=False):\n        path = ROOT+\"train\/\"+i+\"_\"+color+\".png\"\n        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n        counts = np.bincount(img.reshape(-1), minlength=256)\n        counts = counts \/ np.sum(counts)\n        count_list.append(counts)\n    sample['counts'] = count_list\n\n    fig, ax =  plt.subplots(1,1, figsize=(12, 7))\n    for class_id in range(19):\n        cts = sample[sample.Label.apply(lambda x: str(class_id) in x)].counts.tolist()\n        stats = (np.array(cts).sum(axis=0) \/ len(cts))\n        if (not np.isnan(stats).any()):\n            # Not ploting 0 as it is outlier\n            plt.plot([i for i in range(1, 256)], stats[1:], label=\"class \"+str(class_id));\n    plt.legend()\n    plt.xlabel(\"Pixel value\")\n    plt.title(color+\" Pixel Value Distribution for images containing different classes\")\n    plt.show()","e5be18da":"plotdist(500, 'green')","971fbc98":"plotdist(500, 'red')","4902c5d4":"plotdist(500, 'blue')","e795b521":"plotdist(500, 'yellow')","6bb73e94":"def plotimg(axes, ID):\n    red = cv2.imread(ROOT+\"train\/\"+ID+\"_red.png\", cv2.IMREAD_UNCHANGED)\n    green = cv2.imread(ROOT+\"train\/\"+ID+\"_green.png\", cv2.IMREAD_UNCHANGED)\n    blue = cv2.imread(ROOT+\"train\/\"+ID+\"_blue.png\", cv2.IMREAD_UNCHANGED)\n    img = cv2.merge((red, green, blue))\n    axes.imshow(img)","3ae8e13a":"for k in range(0, 19):\n    IDS = train[train.Label.apply(lambda x: str(k) in x)].sample(4).ID.tolist()\n    fig,axes = plt.subplots(1, 4, figsize=(16, 4))\n    for ID, ax in zip(IDS, axes):\n        plotimg(ax, ID)\n    fig.suptitle(labels[k] + \" samples\")\n    plt.show()","97f41d31":"### Labels","e772c57d":"## Human Protein Atlas - Single Cell Classification\n### Finding individual human cell differences in microscope images\n![image](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/23823\/logos\/header.png?t=2020-11-24-14-18-10)\n","fedf0687":"the notebook is still WIP but\n### do upvote if it helped :)","308f62fc":"**Given that we dont have pixel level labels for each class let's see how   \ncan we guess presence and absence of a class by just using raw image pixel values**","4937d651":"### Co-occurrence Matrix","e9a098b3":"**We have 4 images per training example. The important one is green one.\nOthers can be used if needed**"}}