{"cell_type":{"8a01d484":"code","114a46d2":"code","bf2403e8":"code","80db0661":"code","94ecc905":"code","bb3f64b6":"code","fef7e9a9":"code","a1fe3688":"code","f2bc39f0":"code","aa591ee0":"code","8a17c344":"code","7889720e":"code","51f77f18":"code","807f4ea8":"code","7c638359":"code","0c2ff6c2":"code","0af4d348":"code","de3b9246":"code","568226d8":"code","b4d32cff":"code","c71f3795":"code","d8fc2e8a":"code","a72a8d06":"code","9c107434":"code","393d7044":"code","789700c5":"code","bce529bf":"code","beeecf9e":"code","0d610014":"code","564dcf42":"code","ed46a45e":"code","b301ba15":"markdown","1ca89fa1":"markdown","a66d0a30":"markdown","2e962b13":"markdown","6fd7c5b5":"markdown","a70ad774":"markdown","12414e62":"markdown","7e05f35f":"markdown","99bf4cb7":"markdown","09ea6900":"markdown"},"source":{"8a01d484":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n### Graphic libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns","114a46d2":"df_train =pd.read_csv(\"..\/input\/tabular-playground-series-jan-2021\/train.csv\")","bf2403e8":"df_train.head()","80db0661":"df_train.info()","94ecc905":"df_train.isna().sum()","bb3f64b6":"df_train.describe()","fef7e9a9":"df_test=pd.read_csv(\"..\/input\/tabular-playground-series-jan-2021\/test.csv\")","a1fe3688":"df_test.head()","f2bc39f0":"df_test.isnull().sum()\n","aa591ee0":"df_train.shape","8a17c344":"df_train[\"target\"].hist(bins=40, edgecolor='y', linewidth=1.0,\n              xlabelsize=8, ylabelsize=8, grid=False, figsize=(6,2), color='green')    \nplt.tight_layout(rect=(0, 0, 1.2, 1.2))   \nplt.suptitle('Target Plot', x=0.65, y=1.25, fontsize=14); ","7889720e":"sns.boxplot('target', data = df_train)","51f77f18":"sns.set_style(\"white\")\nsns.set_color_codes(palette='deep')\nf, ax = plt.subplots(figsize=(8, 7))\n#Check the new distribution \nsns.distplot(df_train['target'], color=\"b\");\nax.xaxis.grid(False)\nax.set(ylabel=\"Frequency\")\nax.set(xlabel=\"Target\")\nax.set(title=\"Target distribution\")\nsns.despine(trim=True, left=True)\nplt.show()","807f4ea8":"#data = pd.concat([_train['target'], train['OverallQual']], axis=1)\ncorrelation_train=df_train.corr()\nsns.set(font_scale=2)\nplt.figure(figsize = (35,35))\nax = sns.heatmap(correlation_train, annot=True,annot_kws={\"size\": 30},fmt='.1f',cmap='PiYG', linewidths=.5)","7c638359":"#plotting correlations\nnum_feat=df_train.columns[df_train.dtypes!=object]\nnum_feat=num_feat[1:-1] \nlabels = []\nvalues = []\nfor col in num_feat:\n    labels.append(col)\n    values.append(np.corrcoef(df_train[col].values, df_train.target.values)[0,1])\n    \nind = np.arange(len(labels))\nwidth = 0.2\nfig, ax = plt.subplots(figsize=(10,10))\nrects = ax.barh(ind, np.array(values), color='green')\nax.set_yticks(ind+((width)\/2.))\nax.set_yticklabels(labels, rotation='horizontal')\nax.set_xlabel(\"Correlation coefficient\")\nax.set_title(\"Correlation Coefficients w.r.t TArget\");","0c2ff6c2":"df_train.columns","0af4d348":"x = df_train.iloc[:, 1:15].values  \nprint(x) \ny = df_train.iloc[:, -1].values ","de3b9246":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=0)","568226d8":"# Feature Scaling\n#from sklearn.preprocessing import StandardScaler\n\n#sc = StandardScaler()\n#X_train = sc.fit_transform(X_train)\n#X_test = sc.transform(X_test)","b4d32cff":"from sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics","c71f3795":"from xgboost import XGBRegressor\n\nXGB = XGBRegressor(max_depth=3,learning_rate=0.1,n_estimators=1000,reg_alpha=0.001,reg_lambda=0.000001,n_jobs=-1,min_child_weight=3)\nXGB.fit(X_train,y_train)","d8fc2e8a":"y_pred = XGB.predict(X_test)","a72a8d06":"len(y_pred)","9c107434":"from sklearn import metrics\n\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","393d7044":"from sklearn import metrics\n\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","789700c5":"#X_t = sc.transform(df_test[:,1:])","bce529bf":"# Make prediction for submission using best_estimators from grid search.\npreds = XGB.predict(df_test.iloc[:,1:].values)\n#preds=XGB.predict(df_test.iloc[:,1:].values)","beeecf9e":"sub=pd.read_csv(\"..\/input\/tabular-playground-series-jan-2021\/sample_submission.csv\")","0d610014":"sub.head()","564dcf42":"sub.target =preds\nsub.to_csv(\"submission.csv\", index=False)","ed46a45e":"sub.head()","b301ba15":"## Prepare predictions for submission.csv","1ca89fa1":"Correlations","a66d0a30":"Now let's check test data.","2e962b13":"Data is clean with continues target variable. let's make split into 70:20 train and validation data. and drop id column. ","6fd7c5b5":"### Grid-search to find optimal hyper-parameters for XGB regressor","a70ad774":"## EDA\n\n","12414e62":"Storing values in numpy array saves memory.","7e05f35f":"## Split data for training & validation","99bf4cb7":"## Loading train and test data sets","09ea6900":"Some columns have little negative correlation with target variable.\n\nThese can prove to be important features to predict target."}}