{"cell_type":{"4c60d81a":"code","0557d8b7":"code","e5425635":"code","bc260812":"code","d1ba5a15":"code","116ae828":"code","ba445712":"code","051b2b72":"code","1d07a312":"code","938e944b":"code","3afda3e2":"code","dabd126c":"code","47af46f3":"code","1dc0dbf3":"code","c09fb82d":"code","8e6be4f7":"code","ecd3f3e1":"code","4d17acc7":"code","0901a078":"code","5fcca998":"code","4704d473":"code","1aa576d2":"markdown","1310aa0c":"markdown","7349be74":"markdown","ea082e9b":"markdown","078db989":"markdown","f917a7c5":"markdown","ad64af6e":"markdown","b0ca6837":"markdown","09a83037":"markdown","ccab52d2":"markdown","0a44285d":"markdown","bafb2088":"markdown","79285d92":"markdown","d095c453":"markdown","42a93af1":"markdown","f50d764d":"markdown","c152b3b1":"markdown","ab682adf":"markdown","7e65267b":"markdown","c11c04af":"markdown","e8ca197a":"markdown","b4fe29f1":"markdown","08a5642b":"markdown","9e7b3b36":"markdown","51932ca3":"markdown","8adca29f":"markdown","0a9bc3dd":"markdown"},"source":{"4c60d81a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0557d8b7":"import tensorflow as tf\nprint(tf.__version__)","e5425635":"!pip -q install tensorflow==2.4.1","bc260812":"import numpy as np\nimport os\nfrom PIL import Image \nimport tensorflow as tf \nimport tensorflow_datasets as tfds\nimport pathlib","d1ba5a15":"print(tf.__version__)","116ae828":"\ndata_dir = \"..\/input\/flowers-recognition\/flowers\"\n\ndata_dir = pathlib.Path(data_dir)\n\n\nimage_count = len(list(data_dir.glob('*\/*.jpg')))\nprint(image_count)\n\n\nlist_ds = tf.data.Dataset.list_files(str(data_dir \/ '*\/*'), shuffle = False)\nlist_ds = list_ds.shuffle(image_count, reshuffle_each_iteration = False)","ba445712":"for file in list_ds.take(5):\n    print(file)","051b2b72":"for file in list_ds.take(5):\n    print(file.numpy())","1d07a312":"for file in list_ds.take(5):\n    print(file.numpy().decode('utf-8'))","938e944b":"val_size = int(image_count * 0.2)\n\ntrain_ds = list_ds.skip(val_size)\n\nval_ds = list_ds.take(val_size)","3afda3e2":"print(tf.data.experimental.cardinality(train_ds).numpy())\n\nprint(tf.data.experimental.cardinality(val_ds).numpy())","dabd126c":"def process_path(file_path):\n    \n    \n    # Step 1 -- Get the label of the image (Function get_label handles this operation)\n    label = get_label(file_path)\n    \n    \n    # Step 2 - Read the file path\n    img = tf.io.read_file(file_path)\n    \n    \n    # Step 3 - The file path is in binary format. Either define the steps to read the img here only or make a new function\n    img = decode_img(img)\n    \n    return img, label","47af46f3":"class_names = np.array(sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))\nprint(class_names)","1dc0dbf3":"def get_label(file_path):\n    \n    parts = tf.strings.split(file_path, os.path.sep)\n    \n    one_hot = parts[-2] == class_names\n    \n    return tf.argmax(one_hot)","c09fb82d":"def decode_img(img):\n    \n    # you can also use tf.io.decode_raw(). However, if you have prior information that the image will be of jpeg format, use tf.io.decode_jpeg()\n    img = tf.io.decode_jpeg(img, channels = 3)\n    \n    return tf.image.resize(img, [img_height, img_width])","8e6be4f7":"AUTOTUNE = tf.data.AUTOTUNE","ecd3f3e1":"train_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\nval_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)","4d17acc7":"def post_processing_steps(ds):\n    \n    ds = ds.cache()\n    ds = ds.shuffle(buffer_size = 1000)\n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(buffer_size = AUTOTUNE)\n    \n    return ds\n\n\ntrain_ds = post_processing_steps(train_ds)\nval_ds = post_processing_steps(val_ds)\n    ","0901a078":"image_batch, label_batch = next(iter(train_ds))\n\nplt.figure(figsize = (15, 15))\n\nfor i in range(9):\n    \n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n    label = label_batch[i]\n    plt.title(class_names[label])\n    plt.axis(\"off\")   ","5fcca998":"model.fit(\ntrain_ds, \n    validation_data = val_ds, \n    epochs = 5\n)","4704d473":"# def load_images(imagePath):\n    \n#     image = tf.io.read_file(imagePath)\n#     image = tf.image.decode_png(image, channels = 3)\n#     image = tf.image.resize(image, (256, 256)) \/ 255.0\n    \n#     label = tf.strings.split(imagePath, os.path.sep)[-2]\n#     oneHot = label == classNames\n#     encodedLabel = tf.argmax(oneHot)\n#     # return the image and the integer encoded label\n#     return (image, encodedLabel)","1aa576d2":"Now, while using TF, you might be dealing with different kind of datasets. \n* Images\n* CSV\n* TFRecords\n* Text\n\nWe'll be going through each of them one-by-one","1310aa0c":"## I. tf.data (Images)","7349be74":"Let's pick a good dataset representing the vast majority in images domain.","ea082e9b":"Our next step would be to read images using those path and assign each image the label (label of the image would be the parent folder from which it was read)","078db989":"Let's apply the transformations on our dataset using map() method.","f917a7c5":"We're going forward with [Flowers Recognition Dataset](https:\/\/www.kaggle.com\/alxmamaev\/flowers-recognition). The dataset has subfolders with labels as class name. Please feel free to explore the dataset","ad64af6e":"Primarily, tf.data is based on basic data processing principles, i.e., ETL (Extraction -> Transformation -> Loading)","b0ca6837":"![img](https:\/\/miro.medium.com\/max\/1045\/1*3Zi3_VUAYh5w78KGLoO37g.png)","09a83037":"Sources: (Selected Portions from each source along with some original input)\n* https:\/\/www.tensorflow.org\/tutorials\/load_data\/images ","ccab52d2":"The dataset is finally ready! Let's head on to **model training** (5 epochs only)","0a44285d":"Greetings!<br>\nIn this notebook, we'll try to learn and get acquainted with Tensorflow's tf.data pipeline. <br>\n","bafb2088":"Till now, we have successfully extracted the list of data files & split them into train and validation","79285d92":"## III. tf.data (numpy arrays)","d095c453":"Introducing AUTOTUNE. What is it? <br>\n\nIt helps in syncing the batches the data batches during runtime in an optimized manner.","42a93af1":"1. get file labels","f50d764d":"## II. tf.data (CSV Files)","c152b3b1":"Configuring the dataset","ab682adf":"#### I. Introduction","7e65267b":"convert to numpy","c11c04af":"Utility functions to achieve the same","e8ca197a":"How do we head forward from here? <br>\nWe have successfully gathered datasets which have list of file names. By natural instinct, we need to follow the following steps to get the work done successfully. <br>\n* get the file path & the parent folder name (label)\n* read the image using the file path & map it with its label extracted in the previous step\n* write a function to decode the jpeg images","b4fe29f1":"Contrary to skip is take. ","08a5642b":"decode the byte strings","9e7b3b36":"Let's check the dataset. As of now, we should have successfully obtained the files list. <br>\ntake() is a method available in tf.data API","51932ca3":"We'll add the preliminary transformation steps to the dataset. <br>\n* Shuffling the data\n* Making batches of the data\n* Prefetch to ensure that batches are available and prepared for the gpu calls","8adca29f":"## Notebook in Making","0a9bc3dd":"Did we sucessfully read the data and apply the processing steps? <br>\nThere's only one way to figure it out. **Visualize the dataset**"}}