{"cell_type":{"88d2cd73":"code","1f19027b":"code","ed33f141":"code","70cc010a":"code","03bca3e6":"code","0243e589":"code","20966920":"code","be0b8aae":"code","a14b7612":"code","941f79f4":"code","9abac711":"code","cdf84be5":"code","159fa264":"markdown","d16e41b6":"markdown","5d017e8a":"markdown"},"source":{"88d2cd73":"import numpy as np \nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","1f19027b":"# faster downloading\nimport datatable as dt\ntrain = dt.fread(r'\/kaggle\/input\/tabular-playground-series-nov-2021\/train.csv').to_pandas()\ntest = dt.fread(r'\/kaggle\/input\/tabular-playground-series-nov-2021\/test.csv').to_pandas()","ed33f141":"# Reduce memory usage if PC is \n# train features\nfor col in train.columns:\n    if train[col].dtype == \"float64\":\n        train[col]=pd.to_numeric(train[col], downcast=\"float\")\n    if train[col].dtype == \"int64\":\n        train[col]=pd.to_numeric(train[col], downcast=\"integer\")\n    \n\n# test features\nfor col in test.columns:\n    if test[col].dtype == \"float64\":\n        test[col]=pd.to_numeric(test[col], downcast=\"float\")\n    if train[col].dtype == \"int64\":\n        test[col]=pd.to_numeric(test[col], downcast=\"integer\")  ","70cc010a":"id = test['id'].copy()\ntrain = train.drop('id' ,axis = 1)\ntest = test.drop('id', axis = 1)","03bca3e6":"X = train.drop('target', axis = 1).copy()\ny = train['target'].copy()\nX_test = test.copy()\n\ndel train\ndel test","0243e589":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import roc_curve, auc","20966920":"import time\nstart = time.perf_counter()\nprint(\"--------\u23f1start-----------\")","be0b8aae":"splits = 5\nseed = 42\nskf = StratifiedKFold(n_splits = splits, shuffle=True, random_state=seed)\n\nscores = []\npred= []\n\nfor fold, (idx_train, idx_valid) in enumerate(skf.split(X, y)):\n    \n    X_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n    X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n\n    model = MLPClassifier()\n    model.fit(X_train, y_train)\n    \n    pred_valid = model.predict_proba(X_valid)[:,1]\n    fpr, tpr, _ = roc_curve(y_valid, pred_valid)\n    score = auc(fpr, tpr)\n    scores.append(score)\n\n    test_preds = model.predict_proba(X_test)[:,1]\n    pred.append(test_preds)\n    print(\"fold :  \",fold, \" MLPsore : \", score)","a14b7612":"p_1 = sum(scores)\/splits\nprint(p_1)\nprint(scores)","941f79f4":"time_end = time.perf_counter()\nprocess_time = time_end - start\nprint(\"process_time:{0}\".format(process_time) )","9abac711":"predictions = np.mean(np.column_stack(pred) ,axis = 1)\nsubmission = pd.DataFrame({'id' : id, 'target' : predictions})\nsubmission.to_csv(\"submission.csv\", index = False)\n\nsubmission.head()","cdf84be5":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nsns.kdeplot(submission['target'],fill=True, color = \"#20B2AA\")\nplt.title('MLPClassifier ')","159fa264":"---------------\n","d16e41b6":"# improved tips\ud83d\udca1\n> * This is basic model. so you may\n> * add parameters like this -> (max_iter = 1000, hidden_layer_sizes = (10, 10), alpha = 0.0001, solver = 'adam', random_state = 42)\n> * using scaler, adding or choosing feature, more folds, random_state etc...Good luck!","5d017e8a":"# NN(Neural network model) : Multi-layer perceptron (MLP)\n> * I try Neural network model \"multi-layer Perceptron classifier\".\n> * This is the advanced models of Deep Learning.\n> * I hope this will help you.Please excuse if there are any mistakes\ud83d\ude4f"}}