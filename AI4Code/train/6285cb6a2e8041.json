{"cell_type":{"bc82326c":"code","82561e6d":"code","2942bcb8":"code","c9e4ff51":"code","5b0b3280":"code","5fda6fe2":"code","269be20b":"code","4c5d2f9d":"code","92d6adfb":"code","6a99b7fb":"code","cc5a5367":"code","eb7f89b8":"code","d5744599":"code","cfcf35a1":"code","c9b2d968":"code","337c47b3":"code","4b7e1048":"code","b7982160":"code","6c13a823":"code","d6ed152a":"code","9069b124":"code","cf6ce621":"code","ca2305d3":"code","10c08a17":"markdown","1a95a9c3":"markdown","c8016b06":"markdown","c9ac63a2":"markdown","0b242e75":"markdown","381eb84d":"markdown","5cc69249":"markdown","474d2c04":"markdown","7ad481f5":"markdown","4c748986":"markdown","d87a010e":"markdown","719f4254":"markdown","03623f0f":"markdown","9a7360a3":"markdown","6dcef5aa":"markdown","29e36117":"markdown","a9308f97":"markdown","9e3c27c5":"markdown","eba2d034":"markdown","79575a4d":"markdown"},"source":{"bc82326c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.rcParams.update({'font.size': 14})\n\nimport re\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ndistricts_info = pd.read_csv(\"..\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv\")\nproducts_info = pd.read_csv(\"..\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv\")","82561e6d":"districts_info = districts_info[districts_info.state.notna()].reset_index(drop=True)","2942bcb8":"temp_sectors = products_info['Sector(s)'].str.get_dummies(sep=\"; \")\ntemp_sectors.columns = [f\"sector_{re.sub(' ', '', c)}\" for c in temp_sectors.columns]\nproducts_info = products_info.join(temp_sectors)\nproducts_info.drop(\"Sector(s)\", axis=1, inplace=True)\n\ndel temp_sectors","c9e4ff51":"products_info['primary_function_main'] = products_info['Primary Essential Function'].apply(lambda x: x.split(' - ')[0] if x == x else x)\nproducts_info['primary_function_sub'] = products_info['Primary Essential Function'].apply(lambda x: x.split(' - ')[1] if x == x else x)\n\n# Synchronize similar values\nproducts_info['primary_function_sub'] = products_info['primary_function_sub'].replace({'Sites, Resources & References' : 'Sites, Resources & Reference'})\nproducts_info.drop(\"Primary Essential Function\", axis=1, inplace=True)","5b0b3280":"PATH = '..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data' \n\ntemp = []\n\nfor district in districts_info.district_id.unique():\n    df = pd.read_csv(f'{PATH}\/{district}.csv', index_col=None, header=0)\n    df[\"district_id\"] = district\n    temp.append(df)\n    \n    \nengagement = pd.concat(temp)\nengagement = engagement.reset_index(drop=True)","5fda6fe2":"engagement.head()","269be20b":"engagement.groupby('district_id').time.nunique()","4c5d2f9d":"fig, ax = plt.subplots(1, 1, figsize=(8,4))\n\nsns.histplot(engagement.groupby('district_id').time.nunique(), bins=30)\nax.set_title('Unique Days of Engagement Data per District')\nplt.show()","92d6adfb":"# Delete previously created engagement dataframe and create a new one\ndel engagement\n\ntemp = []\n\nfor district in districts_info.district_id.unique():\n    df = pd.read_csv(f'{PATH}\/{district}.csv', index_col=None, header=0)\n    df[\"district_id\"] = district\n    if df.time.nunique() == 366:\n        temp.append(df)\n\nengagement = pd.concat(temp)\nengagement = engagement.reset_index(drop=True)\n\n# Only consider districts with full 2020 engagement data\ndistricts_info = districts_info[districts_info.district_id.isin(engagement.district_id.unique())].reset_index(drop=True)\nproducts_info = products_info[products_info['LP ID'].isin(engagement.lp_id.unique())].reset_index(drop=True)","6a99b7fb":"for district in districts_info.district_id.unique()[:10]:\n    df = pd.read_csv(f'{PATH}\/{district}.csv', index_col=None, header=0)\n    print(f'District {district} uses {df.lp_id.nunique()} unique products.')\n    \nprint(f'\\nConcatenated engagement data contains {engagement.lp_id.nunique()} unique products.')\n","cc5a5367":"print(len(engagement))\nengagement = engagement[engagement.lp_id.isin(products_info['LP ID'].unique())]\nprint(len(engagement))","eb7f89b8":"engagement.time = engagement.time.astype('datetime64[ns]')","d5744599":"us_state_abbrev = {\n    'Alabama': 'AL',\n    'Alaska': 'AK',\n    'American Samoa': 'AS',\n    'Arizona': 'AZ',\n    'Arkansas': 'AR',\n    'California': 'CA',\n    'Colorado': 'CO',\n    'Connecticut': 'CT',\n    'Delaware': 'DE',\n    'District Of Columbia': 'DC',\n    'Florida': 'FL',\n    'Georgia': 'GA',\n    'Guam': 'GU',\n    'Hawaii': 'HI',\n    'Idaho': 'ID',\n    'Illinois': 'IL',\n    'Indiana': 'IN',\n    'Iowa': 'IA',\n    'Kansas': 'KS',\n    'Kentucky': 'KY',\n    'Louisiana': 'LA',\n    'Maine': 'ME',\n    'Maryland': 'MD',\n    'Massachusetts': 'MA',\n    'Michigan': 'MI',\n    'Minnesota': 'MN',\n    'Mississippi': 'MS',\n    'Missouri': 'MO',\n    'Montana': 'MT',\n    'Nebraska': 'NE',\n    'Nevada': 'NV',\n    'New Hampshire': 'NH',\n    'New Jersey': 'NJ',\n    'New Mexico': 'NM',\n    'New York': 'NY',\n    'North Carolina': 'NC',\n    'North Dakota': 'ND',\n    'Northern Mariana Islands':'MP',\n    'Ohio': 'OH',\n    'Oklahoma': 'OK',\n    'Oregon': 'OR',\n    'Pennsylvania': 'PA',\n    'Puerto Rico': 'PR',\n    'Rhode Island': 'RI',\n    'South Carolina': 'SC',\n    'South Dakota': 'SD',\n    'Tennessee': 'TN',\n    'Texas': 'TX',\n    'Utah': 'UT',\n    'Vermont': 'VT',\n    'Virgin Islands': 'VI',\n    'Virginia': 'VA',\n    'Washington': 'WA',\n    'West Virginia': 'WV',\n    'Wisconsin': 'WI',\n    'Wyoming': 'WY'\n}\n\ndistricts_info['state_abbrev'] = districts_info['state'].replace(us_state_abbrev)\ndistricts_info_by_state = districts_info['state_abbrev'].value_counts().to_frame().reset_index(drop=False)\ndistricts_info_by_state.columns = ['state_abbrev', 'num_districts']\n\nfig = go.Figure()\nlayout = dict(\n    title_text = \"Number of Available School Districts per State\",\n    geo_scope='usa',\n)\n\nfig.add_trace(\n    go.Choropleth(\n        locations=districts_info_by_state.state_abbrev,\n        zmax=1,\n        z = districts_info_by_state.num_districts,\n        locationmode = 'USA-states', # set of locations match entries in `locations`\n        marker_line_color='white',\n        geo='geo',\n        colorscale=px.colors.sequential.Teal, \n    )\n)\n            \nfig.update_layout(layout)   \nfig.show()","cfcf35a1":" districts_info['state_abbrev'].value_counts().to_frame()","c9b2d968":"districts_info.pp_total_raw.unique()\ntemp = districts_info.groupby('locale').pp_total_raw.value_counts().to_frame()\ntemp.columns = ['amount']\n\ntemp = temp.reset_index(drop=False)\n\ntemp = temp.pivot(index='locale', columns='pp_total_raw')['amount']\ntemp = temp[['[4000, 6000[', '[6000, 8000[', '[8000, 10000[', '[10000, 12000[',\n       '[12000, 14000[', '[14000, 16000[', '[16000, 18000[', \n       '[18000, 20000[', '[20000, 22000[', '[22000, 24000[', ]]\n\n\nfig, ax = plt.subplots(1, 2, figsize=(24,4))\n\nsns.countplot(data=districts_info, x='locale', ax=ax[0], palette='GnBu')\n\nsns.heatmap(temp, annot=True,  cmap='GnBu', ax=ax[1])\nax[1].set_title('Heatmap of Districts According To locale and pp_total_raw')\nplt.show()","337c47b3":"fig, ax = plt.subplots(2, 2, figsize=(16,8))\n\nsns.countplot(data=districts_info, x='pct_black\/hispanic', order=['[0, 0.2[', '[0.2, 0.4[', '[0.4, 0.6[', '[0.6, 0.8[','[0.8, 1[', ], palette='GnBu', ax=ax[0,0])\nax[0,0].set_ylim([0,135])\nsns.countplot(data=districts_info, x='pct_free\/reduced', order=['[0, 0.2[', '[0.2, 0.4[', '[0.4, 0.6[', '[0.6, 0.8[','[0.8, 1[', ], palette='GnBu', ax=ax[0,1])\nax[0,1].set_ylim([0,135])\n\nsns.countplot(data=districts_info, x='county_connections_ratio', palette='GnBu', ax=ax[1,0])\nax[1,0].set_ylim([0,135])\nsns.countplot(data=districts_info, x='pp_total_raw', order=['[4000, 6000[', '[6000, 8000[', '[8000, 10000[', '[10000, 12000[',\n       '[12000, 14000[', '[14000, 16000[', '[16000, 18000[', \n       '[18000, 20000[', '[20000, 22000[', '[22000, 24000[', ], palette='GnBu', ax=ax[1,1])\nax[1,1].set_ylim([0,135])\nax[1,1].set_xticklabels(ax[1,1].get_xticklabels(), rotation=90)\n\nplt.tight_layout()\nplt.show()","4b7e1048":"def replace_ranges_pct(range_str):\n    if range_str == '[0, 0.2[':\n        return 0.1\n    elif range_str == '[0.2, 0.4[':\n        return 0.3\n    elif range_str == '[0.4, 0.6[':\n        return 0.5\n    elif range_str == '[0.6, 0.8[':\n        return 0.7\n    elif range_str == '[0.8, 1[':\n        return 0.9\n    else:\n        return np.nan\n    \ndef replace_ranges_raw(range_str):\n    if range_str == '[4000, 6000[':\n        return 5000\n    elif range_str == '[6000, 8000[':\n        return 7000\n    elif range_str == '[8000, 10000[':\n        return 9000\n    elif range_str == '[10000, 12000[':\n        return 11000\n    elif range_str ==  '[12000, 14000[':\n        return 13000\n    elif range_str ==  '[14000, 16000[':\n        return 15000\n    elif range_str == '[16000, 18000[':\n        return 17000\n    elif range_str ==  '[18000, 20000[':\n        return 19000\n    elif range_str ==  '[20000, 22000[':\n        return 21000\n    elif range_str ==  '[22000, 24000[':\n        return 21000\n    else: \n        return np.nan\n    \ndistricts_info['pct_black_hispanic_num'] = districts_info['pct_black\/hispanic'].apply(lambda x: replace_ranges_pct(x))\ndistricts_info['pct_free_reduced_num'] = districts_info['pct_free\/reduced'].apply(lambda x: replace_ranges_pct(x))\ndistricts_info['pp_total_raw_num'] = districts_info['pp_total_raw'].apply(lambda x: replace_ranges_raw(x))\n\ndef plot_state_mean_for_var(col):\n    temp = districts_info.groupby('state_abbrev')[col].mean().to_frame().reset_index(drop=False)\n\n    fig = go.Figure()\n    layout = dict(\n        title_text = f\"Mean {col} per State\",\n        geo_scope='usa',\n    )\n\n    fig.add_trace(\n        go.Choropleth(\n            locations=temp.state_abbrev,\n            zmax=1,\n            z = temp[col],\n            locationmode = 'USA-states', # set of locations match entries in `locations`\n            marker_line_color='white',\n            geo='geo',\n            colorscale=px.colors.sequential.Teal, \n        )\n    )\n\n    fig.update_layout(layout)   \n    fig.show()\n\nplot_state_mean_for_var('pct_black_hispanic_num')\nplot_state_mean_for_var('pct_free_reduced_num')\nplot_state_mean_for_var('pp_total_raw_num')","b7982160":"fig, ax = plt.subplots(1, 2, figsize=(16,4))\nsns.countplot(data=products_info, x='primary_function_main', palette ='GnBu', ax=ax[0])\nax[0].set_title('Main Categories in Primary Functions')\n\nsns.countplot(data=products_info[products_info.primary_function_main == 'LC'], x='primary_function_sub', palette ='GnBu', ax=ax[1])\nax[1].set_title('Sub-Categories in Primary Function LC')\nax[1].set_xticklabels(ax[1].get_xticklabels(), rotation=90)\nplt.show()","6c13a823":"virtual_classroom_lp_id = products_info[products_info.primary_function_sub == 'Virtual Classroom']['LP ID'].unique()\n\n# Remove weekends from the dataframe\nengagement['weekday'] = pd.DatetimeIndex(engagement['time']).weekday\nengagement_without_weekends = engagement[engagement.weekday < 5]\n\n# Figure 1\nf, ax = plt.subplots(nrows=1, ncols=1, figsize=(24, 6))\nfor virtual_classroom_product in virtual_classroom_lp_id:\n    temp = engagement_without_weekends[engagement_without_weekends.lp_id == virtual_classroom_product].groupby('time').pct_access.mean().to_frame().reset_index(drop=False)\n    sns.lineplot(x=temp.time, y=temp.pct_access, label=products_info[products_info['LP ID'] == virtual_classroom_product]['Product Name'].values[0])\nplt.legend()\nplt.show()\n\n# Figure 2\nf, ax = plt.subplots(nrows=1, ncols=1, figsize=(24, 6))\nfor virtual_classroom_product in virtual_classroom_lp_id:\n    temp = engagement_without_weekends[engagement_without_weekends.lp_id == virtual_classroom_product].groupby('time').engagement_index.mean().to_frame().reset_index(drop=False)\n    sns.lineplot(x=temp.time, y=temp.engagement_index, label=products_info[products_info['LP ID'] == virtual_classroom_product]['Product Name'].values[0])\nplt.legend()\nplt.show()","d6ed152a":"products_info['lp_id'] = products_info['LP ID'].copy()\n\nf, ax = plt.subplots(nrows=3, ncols=3, figsize=(18, 8))\n\ni = 0\nj = 0\nfor subfunction in products_info[products_info.primary_function_main == 'LC'].primary_function_sub.unique():\n    lp_ids = products_info[products_info.primary_function_sub == subfunction]['LP ID'].unique()\n\n    temp = engagement_without_weekends[engagement_without_weekends.lp_id.isin(lp_ids)]\n    temp = temp.groupby('lp_id').pct_access.mean().sort_values(ascending=False).to_frame().reset_index(drop=False)\n    temp = temp.merge(products_info[['lp_id', 'Product Name']], on='lp_id').head()\n    \n    sns.barplot(data=temp, x='pct_access', y='Product Name', palette='GnBu', ax=ax[i, j])\n    \n    ax[i, j].set_title(f'Top 5 in \\n{subfunction}', fontsize=12)\n    ax[i, j].set_xlim([0, 20])\n    j = j + 1\n    if j == 3:\n        i = i + 1\n        j = 0\n        \nf.delaxes(ax[2, 1])\nf.delaxes(ax[2, 2])\n\nplt.tight_layout()\nplt.show()\n","9069b124":"products_info[products_info['Product Name'] == 'Among Us']","cf6ce621":"engagement['quarter'] = pd.DatetimeIndex(engagement['time']).quarter.astype(str)\n\ntemp = engagement.merge(products_info[['lp_id', 'Product Name', 'primary_function_main', 'primary_function_sub']], on='lp_id')\ntemp = temp[temp.primary_function_sub.notna()]\ntemp = temp.groupby(['quarter', 'primary_function_sub'])['pct_access', 'engagement_index'].mean().reset_index(drop=False)\n\ntemp = temp.pivot(index='primary_function_sub', columns='quarter')[['pct_access', 'engagement_index']].fillna(0)\n\ntemp.columns = [\"_\".join(a) for a in temp.columns.to_flat_index()]\n\ntemp['pct_access_delta'] = temp['pct_access_4'] - temp['pct_access_1']\ntemp['engagement_index_delta'] = temp['engagement_index_4'] - temp['engagement_index_1']\ntemp=temp.reset_index(drop=False)\n#temp = temp.merge(products_info[['lp_id', 'Product Name', 'primary_function_sub']], on='lp_id')\n\nf, ax = plt.subplots(nrows=1, ncols=2, figsize=(20, 10))\n\ndf = temp.sort_values(by='pct_access_delta', ascending=False)#.head(5)\n\nsns.barplot(data=df, x='pct_access_delta', y='primary_function_sub', palette='GnBu', ax=ax[0])\n\ndf = temp.sort_values(by='engagement_index_delta', ascending=False)#.head(5)\n\nsns.barplot(data=df, x='engagement_index_delta', y='primary_function_sub', palette='GnBu', ax=ax[1])\nplt.tight_layout()\nplt.show()","ca2305d3":"\ntemp = engagement.fillna(0).groupby(['quarter', 'lp_id'])['pct_access', 'engagement_index'].mean().reset_index(drop=False)\n\ntemp = temp.pivot(index='lp_id', columns='quarter')[['pct_access', 'engagement_index']].fillna(0)\n\ntemp.columns = [\"_\".join(a) for a in temp.columns.to_flat_index()]\n\ntemp['pct_access_delta'] = temp['pct_access_4'] - temp['pct_access_1']\ntemp['engagement_index_delta'] = temp['engagement_index_4'] - temp['engagement_index_1']\ntemp = temp.merge(products_info[['lp_id', 'Product Name', 'primary_function_sub']], on='lp_id')\n\nf, ax = plt.subplots(nrows=1, ncols=2, figsize=(14, 5))\n\ndf = temp.sort_values(by='pct_access_delta', ascending=False).head(10)\n\nsns.barplot(data=df, x='pct_access_delta', y='Product Name', palette='GnBu', ax=ax[0])\n\ndf = temp.sort_values(by='engagement_index_delta', ascending=False).head(10)\n\nsns.barplot(data=df, x='engagement_index_delta', y='Product Name', palette='GnBu', ax=ax[1])\nplt.tight_layout()\nplt.show()","10c08a17":"The most common category in the column Primary Essential Function is Learning & Curriculum (LC) as shown on the below left figure. For the categories Classroom Management (CM) and School & District Operations (SDO) there are far fewer tool options available. ","1a95a9c3":"Note that at this stage, we have **removed quite a bit of data**. This obviously can lead to loss of information. However, on the other hand this makes the data easier to compare and therefore, it can help us in finding insights more quickly. \nTo summarize, we have **removed districts** without any information on the location \nand we have **removed districts** with incomplete data in 2020.","c8016b06":"<font color='turquoise'>One-Hot Encoding the Product Sectors<\/font>","c9ac63a2":"If we look at the **distributions of the remaining columns** in `districts_info`, you can quickly see that `county_connections_ratio` only has one unique value which is `[0.18, 1[`.  So, this column does not really contain any valuable information.","0b242e75":"In above example to showcase the difference between `pct_access` and `engagement_index`, we intuitively chose products from the subfunction 'Virtual Classroom' based on our \"domain knowledge\" that in-person education does not need video conferencing tools but during the pandemic these tools gained a lot of popularity. Let's do a quick analysis and see whether the avaiable data reflects the assumption we had made before.\n\nFor this purpose, we will **average the `pct_access` and `engagement_index` data over each quarter in 2020 and then take the difference between the last quarter of 2020 and the first quarter of 2020.** Based on this approach, we should be able to see which subfunction category that gained the most engagement over the course of the pandemic in 2020.\n\nAs you can see in the below left figure, the data reflects our assumption that products of the subfunction 'Virtual Classroom' gained the most change in `pct_access`. At second place, we have Learning Management Systems (LMS). These top two categories are also the top two categories from the `engagement_index` point of view.","381eb84d":"For the majority of school districts (133) there are 366 unique days available. However, for 43 school districts there are less than 366 unique days of data available. For example for district 3670 there is only data available from 2020-02-15 to 2020-03-02 or for district 2872 there is only data available for January 2020 and then two more single days in Feburary and March.","5cc69249":"Furthermore, if we look at a few sample districts, we can quickly see that most districts use more than the 369 unique products from `products_info`. In fact, the concatenated engagement data contains more than 8000 unique products. Since we don't have any additional information the majority of these products, we will remove engagement data for unknown products. This reduces the engagement data roughly by half.","474d2c04":"Finally, we will convert the `time` column to the type `datetime64[ns]` for easier handling.","7ad481f5":"To make the data easier to compare, we will only consider distrcits with engagement data for everyday in 2020.","4c748986":"Just on a side note because I saw this on accident: **'Among Us'**, which is a multiplayer game that was quite popular during 2020, **is also listed as a product under the main category LC**. So, we need to take the list of products with a grain of salt when we are evaluating them as 'digital learning products'. ","d87a010e":"<font color='orange'>Splitting up the Primary Essential Function<\/font>","719f4254":"**Summary**\n* Depending on what you want to achieve you might want to carefully preselect districts. Note that we approach in this notebook might not necessarily suit your individual purposes.\n* When looking at digital learning, you might want to spend sometime in figuring out which districts actually applied digital learning","03623f0f":"Now we will try to understand that meaning behind `pct_access` and `engagement_index`.\n\n* `pct_access`: **% of students in the district have at least one page-load event** of a given product and on a given day\n* `engagement_index`: **Total page-load events per 1000 students** of a given product and on a given day\n\nIn the first figure below, you can see the overall mean `pct_access` of all products of the category 'Virtual Classroom'. For better understanding, weekends are removed from this visualization as students will not attend classes on weekends and this would add a disturbing visual effect and make the plot more difficult to understand. Let's summarize what we see:\n* the home schooling phase starts at the beginning of March\n* there is a bell-shape between March and July\n* during July and August there are summer holidays and therefore no classes to attend\n* after the summer holidays the `pct_access` increases to a higher level as observed at the beginning of the pandemic and it stays somewhat constant\n* there are a few drops in `pct_access` visible throughout the year - these might be national holidays or other holidays\n* Zoom and Meet seem to be the two most popular products for virtual classrooms\n\nOver the last quarter of 2020, we can see a `pct_access` of roughly 15. What does this mean? 15 % of students in the district have at least one page-load event of Zoom or Meet. To be honest, that seems a little bit low from the home schooling point of view given that every student needs to attend classes on a school day. However, this seems to hint at the fact that not all students had to attend classes virtually but were able to physically go to school. Judging from [this State-by-State Map of Where School Buildings Are Opened or Closed](https:\/\/www.edweek.org\/leadership\/map-where-are-schools-closed\/2020\/07) it seems like a lot of schools offered in-person education in 2020. **That means, when looking at digital learning, we should probably focus our analysis on districts where digital learning was actually applied to get some key insights**.\n\nWhile for `pct_access` Zoom and Meet seem to have roughly similiar values, we can see in the lower graph that Meet has more than 4 times the value of Zoom for `engagement_index` in the last quarter of 2020. What does this mean? If we have 1000 page-load events per 1000 students for Zoom on a given day that means that one student uses Zoom once a day. In contrast, Meet is used 4 or 5 times daily on average per student.\n\nTo make things a little bit clearer: If every students has two applications on their phone, the `pct_access` indicates **how many of the students** access this app on a daily basis but the `engagement_index` tells you **how much the students engage** with that application on a daily basis.","9a7360a3":"# Initial Exploratory Data Analysis (EDA)\n\nLet's begin with a simple EDA. First of all, I am interested **how diverse the available school districts are**. As you can see in below plot, the available data does not cover all the states in the U.S. (19\/50). The states with the most available school districts are CT (29) and UT (24) while there are also states with only one school district (FL, TN, NY, AZ).","6dcef5aa":"# Getting An Overview of the Dataset\n\n we are given multiple .csv files as shown in below figure. The main information contained in these files is **which tools are used with what engagement in which school district** in the United States of America in 2020.\n\nThe **districts_info.csv** file contains information about each school district and the **products_info.csv** file contains information about the top 370 tools used for digital learning. For each school district, there is an additional file that contains the engagement for each tool for everyday in 2020. The files can be joined by the key columns <font color='lightblue'>district_id<\/font> and <font color='orange'>lp_id<\/font>.\n\n![learnplatform.001.jpeg](attachment:10d597ce-2a66-4e0f-a16f-ea0a95f2cd18.jpeg)","29e36117":"# Preprocessing\n\n\nIn the following subsections, I will proceed with the following basic preprocessing steps:\n- <font color='salmon'>dropping 57 school districts with NaN states (57\/233 ~ 25%)<\/font>\n- <font color='turquoise'>one-hot encoding the product sectors<\/font>\n- <font color='orange'>splitting up the primary essential function into main and sub category<\/font>\n![learnplatform.002.jpeg](attachment:f85cb16a-6095-4175-8f94-4b1c4f390289.jpeg)\n\n<font color='salmon'>Dropping Districts with NaN States<\/font>","a9308f97":"The same approach as above is used below for the product level instead of the subfunction level. ","9e3c27c5":"After preprocessing, we are left with a reduced `districts_info` dataframe with 176 districts and the `product_info` dataframe looks are follows:\n\n![learnplatform.003.jpeg](attachment:2cd2325d-8bc7-4a87-8a62-75ba9fd94069.jpeg)","eba2d034":"Below we can see the top 5 most accessed products for each LC sub-category sorted by the mean `pct_access` for 2020 over all districts. We can see that most of the products are on average accessed by less than 5 % of students on a daily basis. Exceptions are YouTube, Google Docs, and Canvas. YouTube in this case is a difficult one to evaluate since it can be used for leisure in addition to education, so we need to be careful here. Google Docs seems to make a lot of sense since students can use Google Docs. According to [Canvas](https:\/\/community.canvaslms.com\/t5\/Canvas-Basics-Guide\/What-is-Canvas\/ta-p\/45) it is \n> Canvas is a web-based learning management system, or LMS. It is used by learning institutions, educators, and students to access and manage online course learning materials and communicate about skill development and learning achievement.\n\nso it also makes sense that this one is quite often accessed.\n\nRegarding the sub-category 'Career Planning & Job Search' the average `pct_access` is very low. This is probably due top the fact that career planning is only relevant to older students. Therefore, we can probably exclude this subcategory when inspecting the digital learning aspect.","79575a4d":"Furthermore, we will concatenate the engagement data from all remaining districts in one dataframe by adding the key column `district_id` to each engagement file as shown below.\n![learnplatform4.001.jpeg](attachment:830ae306-55d8-45e8-817d-20d8bb758cda.jpeg)"}}