{"cell_type":{"b0af6873":"code","21616ce9":"code","1554efc9":"code","61df7b19":"code","c4a9cf0f":"code","dc5fa627":"code","5effe26a":"code","f032f04a":"code","bbaaa775":"code","81a9b6f9":"code","b006bb9b":"code","030ecc4c":"code","a5808f09":"code","f8ff90d2":"code","d625d8c5":"code","ecf34357":"code","13283fd9":"code","e178dfa5":"code","3c87e1dc":"code","0ccb9441":"code","3e063df9":"code","429743ab":"code","94e70ca1":"code","a8eb5db4":"code","72db53d3":"code","5c95e3e4":"code","d26b6038":"code","c72120a6":"code","ebd028c0":"code","acdd19d7":"code","278069d2":"code","b09503f0":"code","0aa5e151":"code","5e6559a1":"markdown","8e3b6eb6":"markdown","21f908e7":"markdown","67226f2c":"markdown","b11e1c5e":"markdown","c32415e1":"markdown","e511b5c5":"markdown","c1f2fe43":"markdown","245ff692":"markdown","fa84258e":"markdown"},"source":{"b0af6873":"!pip install -q efficientnet","21616ce9":"#P7.17 \u5bfc\u5165\u5e93\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\ntqdm.pandas()\nimport cv2\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom sklearn.model_selection import train_test_split\nfrom kaggle_datasets import KaggleDatasets\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nfrom tensorflow.keras.applications import DenseNet121\nimport efficientnet.tfkeras as efn","1554efc9":"#P7.18 \u8bfb\u53d6\u6570\u636e\u96c6\uff0c\u5212\u5206\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\nEPOCHS = 20\nSAMPLE_LEN = 100\nIMAGE_PATH = \"..\/input\/plant-pathology-2020-fgvc7\/images\/\"\nTEST_PATH = \"..\/input\/plant-pathology-2020-fgvc7\/test.csv\"\nTRAIN_PATH = \"..\/input\/plant-pathology-2020-fgvc7\/train.csv\"\nSUB_PATH = \"..\/input\/plant-pathology-2020-fgvc7\/sample_submission.csv\"\n\nsub = pd.read_csv(SUB_PATH)\ntest_data = pd.read_csv(TEST_PATH)\ntrain_data = pd.read_csv(TRAIN_PATH)\n","61df7b19":"train_data.head()","c4a9cf0f":"test_data.head()","dc5fa627":"AUTO = tf.data.experimental.AUTOTUNE\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\nstrategy = tf.distribute.experimental.TPUStrategy(tpu)\n\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()","5effe26a":"def format_path(image_id):\n    return  GCS_DS_PATH + '\/images\/' + image_id + '.jpg'\ntrain_paths = train_data.image_id.apply(format_path).values\ntrain_labels = np.float32(train_data.loc[:, 'healthy':'scab'].values)\ntest_paths = test_data.image_id.apply(format_path).values\ntrain_paths, valid_paths, train_labels, valid_labels = train_test_split( \\\n               train_paths, train_labels, test_size=0.3, random_state=2020)","f032f04a":"#P7.19 \u56fe\u50cf\u6570\u636e\u52a0\u8f7d\u4e0e\u89e3\u7801\u51fd\u6570\ndef decode_image(filename, label=None, image_size=(512, 512)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.image.resize(image, image_size)\n    \n    if label is None:\n        return image\n    else:\n        return image, label\n\n#P7.20 \u6570\u636e\u589e\u5f3a\u51fd\u6570\ndef data_augment(image, label=None):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    \n    if label is None:\n        return image\n    else:\n        return image, label","bbaaa775":"#P7.21 \u6784\u5efa\u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6\ntrain_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((train_paths, train_labels))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .map(data_augment, num_parallel_calls=AUTO)\n    .repeat()\n    .shuffle(512)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n\nvalid_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((valid_paths, valid_labels))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n    .cache()\n    .prefetch(AUTO)\n)\n\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(test_paths)\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n)","81a9b6f9":"#P7.22 \u5b9a\u4e49\u5b66\u4e60\u7387\u52a8\u6001\u8c03\u5ea6\u51fd\u6570\ndef build_lrfn(lr_start=0.00001, lr_max=0.00005, \n               lr_min=0.00001, lr_rampup_epochs=5, \n               lr_sustain_epochs=0, lr_exp_decay=.8):\n    lr_max = lr_max * strategy.num_replicas_in_sync\n\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) \/ lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) *\\\n                 lr_exp_decay**(epoch - lr_rampup_epochs\\\n                                - lr_sustain_epochs) + lr_min\n        return lr\n    return lrfn\nlrfn = build_lrfn()\nSTEPS_PER_EPOCH = train_labels.shape[0] \/\/ BATCH_SIZE\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)","b006bb9b":"#P7.23\u4e0b\u8f7d\u5e76\u91cd\u5b9a\u4e49DenseNet121\u8fc1\u79fb\u6a21\u578b\u6a21\u578b\nwith strategy.scope():\n    model = tf.keras.Sequential([DenseNet121(input_shape=(512, 512, 3),\n                                             weights='imagenet',\n                                             include_top=False),\n                                 L.GlobalAveragePooling2D(),\n                                 L.Dense(train_labels.shape[1],\n                                         activation='softmax')])\n        \n    model.compile(optimizer='adam',\n                  loss = 'categorical_crossentropy',\n                  metrics=['categorical_accuracy'])\n    model.summary()","030ecc4c":"%%time\n#P7.24 DenseNet121\u6a21\u578b\u8bad\u7ec3\nEPOCHS=20\nhistory = model.fit(train_dataset,\n                    epochs=EPOCHS,\n                    callbacks=[lr_schedule],\n                    steps_per_epoch=STEPS_PER_EPOCH,\n                    validation_data=valid_dataset)","a5808f09":"%%time\n#P7.25 \u7ed8\u5236\u6a21\u578b\u7684\u5b66\u4e60\u66f2\u7ebf\ndef display_training_curves(training, validation, yaxis):\n    if yaxis == \"loss\":\n        ylabel = \"Loss\"\n        title = \"Loss vs. Epochs\"\n    else:\n        ylabel = \"Accuracy\"\n        title = \"Accuracy vs. Epochs\"        \n    fig = go.Figure()        \n    fig.add_trace(\n        go.Scatter(x=np.arange(1, EPOCHS+1), mode='lines+markers', y=training, marker=dict(color=\"dodgerblue\"),\n               name=\"Train\"))    \n    fig.add_trace(\n        go.Scatter(x=np.arange(1, EPOCHS+1), mode='lines+markers', y=validation, marker=dict(color=\"darkorange\"),\n               name=\"Val\"))    \n    fig.update_layout(title_text=title, yaxis_title=ylabel, xaxis_title=\"Epochs\")\n    fig.show()\n    ","f8ff90d2":"#P7.26 \u7ed8\u5236\u51c6\u786e\u7387\u66f2\u7ebf\ndisplay_training_curves(\n    history.history['categorical_accuracy'], \n    history.history['val_categorical_accuracy'], \n    'accuracy')","d625d8c5":"#P7.27 \u7528DenseNet\u6a21\u578b\u5bf9\u56db\u79cd\u6807\u7b7e\u505a\u62bd\u6837\u9884\u6d4b\u5e76\u5206\u6790\u7ed3\u679c\n\ndef load_image(image_id):\n    file_path = image_id + \".jpg\"\n    image = cv2.imread(IMAGE_PATH + file_path)\n    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\ntrain_images = train_data[\"image_id\"][:4].progress_apply(load_image)  # \u524d\u56db\u5e45\u56fe\u50cf\n\ndef process(img):\n    return cv2.resize(img\/255.0, (512, 512)).reshape(-1, 512, 512, 3)\ndef predict(img):\n    return model.layers[2](model.layers[1](model.layers[0](process(img)))).numpy()[0]\n\ndef displayResult(img, preds, title):\n    fig = make_subplots(rows=1, cols=2)\n    colors = {\"Healthy\":px.colors.qualitative.Plotly[0], \"Scab\":px.colors.qualitative.Plotly[0],\n              \"Rust\":px.colors.qualitative.Plotly[0], \"Multiple diseases\":px.colors.qualitative.Plotly[0]}\n    if list.index(preds.tolist(), max(preds)) == 0:\n        pred = \"Healthy\"\n    if list.index(preds.tolist(), max(preds)) == 1:\n        pred = \"Scab\"\n    if list.index(preds.tolist(), max(preds)) == 2:\n        pred = \"Rust\"\n    if list.index(preds.tolist(), max(preds)) == 3:\n        pred = \"Multiple diseases\"\n\n    colors[pred] = px.colors.qualitative.Plotly[1]\n    colors[\"Healthy\"] = \"seagreen\"\n    colors = [colors[val] for val in colors.keys()]\n    fig.add_trace(go.Image(z=cv2.resize(img, (205, 136))), row=1, col=1)\n    fig.add_trace(go.Bar(x=[\"Healthy\", \"Multiple diseases\", \"Rust\", \"Scab\"], \n                         y=preds, marker=dict(color=colors)), row=1, col=2)\n    fig.update_layout(height=400, width=800, title_text=title, showlegend=False)\n    fig.show()\n    \npreds = predict(train_images[2])\ndisplayResult(train_images[2], preds, \"DenseNet Predictions\")\n\npreds = predict(train_images[0])\ndisplayResult(train_images[0], preds, \"DenseNet Predictions\")\n\npreds = predict(train_images[3])\ndisplayResult(train_images[3], preds, \"DenseNet Predictions\")\n\npreds = predict(train_images[1])\ndisplayResult(train_images[1], preds, \"DenseNet Predictions\")\n","ecf34357":"%%time\n#P7.28 \u5bf9\u6d4b\u8bd5\u96c6\u505a\u9884\u6d4b\uff0c\u4fdd\u5b58\u9884\u6d4b\u7ed3\u679c\nprobs_densenet = model.predict(test_dataset, verbose=1)\nsub.loc[:, 'healthy':] = probs_densenet\nsub.to_csv('submission_densenet.csv', index=False)\nsub.head()","13283fd9":"#P7.29 \u4e0b\u8f7d\u5e76\u5b9a\u4e49EfficientNetB7\u6a21\u578b\nwith strategy.scope():\n    model = tf.keras.Sequential([efn.EfficientNetB7(input_shape=(512, 512, 3),\n                                                    weights='imagenet',\n                                                    include_top=False),\n                                 L.GlobalAveragePooling2D(),\n                                 L.Dense(train_labels.shape[1],\n                                         activation='softmax')])\n    \n    \n        \n    model.compile(optimizer='adam',\n                  loss = 'categorical_crossentropy',\n                  metrics=['categorical_accuracy'])\n    model.summary()","e178dfa5":"#P7.30 EfficientNetB7\u6a21\u578b\u8bad\u7ec3\nhistory = model.fit(train_dataset,\n                    epochs=EPOCHS,\n                    callbacks=[lr_schedule],\n                    steps_per_epoch=STEPS_PER_EPOCH,\n                    validation_data=valid_dataset)","3c87e1dc":"#P7.31 \u7ed8\u5236EfficientNetB7\u6a21\u578b\u51c6\u786e\u7387\u66f2\u7ebf\ndisplay_training_curves(\n    history.history['categorical_accuracy'], \n    history.history['val_categorical_accuracy'], \n    'accuracy')\n","0ccb9441":"# \u4fdd\u5b58\u6a21\u578b\ntf.keras.models.save_model(\n    model, 'EfficientNetB7.h5', save_traces=False\n)","3e063df9":"model.save('Apple-EfficientNetB7.h5')","429743ab":"#P7.32 EfficientNetB7\u6a21\u578b\u62bd\u6837\u68c0\u6d4b\npreds = predict(train_images[2])\ndisplayResult(train_images[2], preds, \"EfficientNetB7 Predictions\")\n\npreds = predict(train_images[0])\ndisplayResult(train_images[0], preds, \"EfficientNetB7 Predictions\")\n\npreds = predict(train_images[3])\ndisplayResult(train_images[3], preds, \"EfficientNetB7 Predictions\")\n\npreds = predict(train_images[1])\ndisplayResult(train_images[1], preds, \"EfficientNetB7 Predictions\")\n","94e70ca1":"probs_efnB7 = model.predict(test_dataset, verbose=1)\nsub.loc[:, 'healthy':] = probs_efnB7\nsub.to_csv('submission_efnB7.csv', index=False)\nsub.head()","a8eb5db4":"#P7.34 \u5b9a\u4e49EfficientNet NoisyStudent\u6a21\u578b\nwith strategy.scope():\n    model = tf.keras.Sequential([efn.EfficientNetB7(input_shape=(512, 512, 3),\n                                                    weights='noisy-student',\n                                                    include_top=False),\n                                 L.GlobalAveragePooling2D(),\n                                 L.Dense(train_labels.shape[1],\n                                         activation='softmax')])\n    \n    \n        \n    model.compile(optimizer='adam',\n                  loss = 'categorical_crossentropy',\n                  metrics=['categorical_accuracy'])\n    model.summary()","72db53d3":"#P7.35 \u6a21\u578b\u8bad\u7ec3\nhistory = model.fit(train_dataset,\n                    epochs=EPOCHS,\n                    callbacks=[lr_schedule],\n                    steps_per_epoch=STEPS_PER_EPOCH,\n                    validation_data=valid_dataset)","5c95e3e4":"#P7.36 \u7ed8\u5236\u51c6\u786e\u7387\u66f2\u7ebf\ndisplay_training_curves(\n    history.history['categorical_accuracy'], \n    history.history['val_categorical_accuracy'], \n    'accuracy')","d26b6038":"# \u62bd\u6837\u68c0\u6d4b\npreds = predict(train_images[2])\ndisplayResult(train_images[2], preds, \" Noisy Student Predictions\")\n\npreds = predict(train_images[0])\ndisplayResult(train_images[0], preds, \" Noisy Student Predictions\")\n\npreds = predict(train_images[3])\ndisplayResult(train_images[3], preds, \" Noisy Student Predictions\")\n\npreds = predict(train_images[1])\ndisplayResult(train_images[1], preds, \" Noisy Student Predictions\")","c72120a6":"# P7.37 \u4fdd\u5b58\u6d4b\u8bd5\u96c6\u9884\u6d4b\u7ed3\u679c\nprobs_efnns = model.predict(test_dataset, verbose=1)\nsub.loc[:, 'healthy':] = probs_efnns\nsub.to_csv('submission_efnns.csv', index=False)\nsub.head()","ebd028c0":"#P7.38 \u6a21\u578b\u96c6\u6210\nensemble_1, ensemble_2, ensemble_3 =[sub]*3\n#\u96c6\u6210\u6a21\u578b1\nensemble_1.loc[:, 'healthy':] = 0.50*probs_efnB7 + 0.50*probs_densenet \nensemble_1.to_csv('submission_ensemble_1.csv', index=False)\n#\u96c6\u6210\u6a21\u578b2\nensemble_2.loc[:, 'healthy':] = 0.25*probs_efnB7 + 0.75*probs_densenet\nensemble_2.to_csv('submission_ensemble_2.csv', index=False)\n#\u96c6\u6210\u6a21\u578b3\nensemble_3.loc[:, 'healthy':] = 0.75*probs_efnB7 + 0.25*probs_densenet\nensemble_3.to_csv('submission_ensemble_3.csv', index=False)\n#\u663e\u793a\u96c6\u6210\u6a21\u578b1\nensemble1 = pd.read_csv('submission_ensemble_1.csv')\nensemble1.head()","acdd19d7":"#P7.39 \u96c6\u6210\u6a21\u578b1\u9884\u6d4b\u7684\u6700\u5927\u6982\u7387\u503c\u5206\u5e03\nimport matplotlib.pyplot as plt\nmodel1 = ensemble1.drop('image_id',axis = 1)\nlabel_values1 = [np.max(model1.loc[i]) for i in range(1821)]\nx=range(1821)\nplt.figure(figsize=(5,5))\nplt.scatter(x,label_values1)\nplt.xlabel('test_id',size=16)\nplt.ylabel('Maximum probability',size=16)\nplt.show()\nprint('\u6982\u7387\u503c\u4f4e\u4e8e0.5\u7684\u6837\u672c\u6570\u91cf\u4e3a\uff1a{0}'.format(np.sum(np.array(label_values1)<0.5)))","278069d2":"print('\u6982\u7387\u503c\u5927\u4e8e0.9\u7684\u6837\u672c\u6570\u91cf\u4e3a\uff1a{0}'.format(np.sum(np.array(label_values1)>=0.9)))","b09503f0":"1428\/1821","0aa5e151":"ensemble1 = pd.read_csv('submission_ensemble_1.csv')\nensemble1.head()","5e6559a1":"# 7.15 EfficientNet Noisy Student\u6a21\u578b","8e3b6eb6":"# 7.17 \u6a21\u578b\u96c6\u6210","21f908e7":"# 7.12 EfficientNet\u6a21\u578b\u5b9a\u4e49","67226f2c":"# 7.13 EfficientNet\u6a21\u578b\u8bad\u7ec3","b11e1c5e":"# 7.11 DenseNet\u6a21\u578b\u9884\u6d4b\u4e0e\u8bc4\u4f30","c32415e1":"## Acknowledgements\n<a href=\"https:\/\/www.kaggle.com\/tarunpaparaju\/plant-pathology-2020-eda-models\">Plant Pathology 2020 : EDA + Models \ud83c\udf3f<\/a>","e511b5c5":"### \u914d\u7f6eTPU ","c1f2fe43":"## 7.9 DenseNet\u6a21\u578b\u5b9a\u4e49","245ff692":"# 7.14 EfficientNet\u6a21\u578b\u9884\u6d4b\u4e0e\u8bc4\u4f30","fa84258e":"# 7.10 DenseNet\u6a21\u578b\u8bad\u7ec3"}}