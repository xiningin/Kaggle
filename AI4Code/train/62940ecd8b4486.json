{"cell_type":{"c742cd46":"code","fe55e6e6":"code","342b4434":"code","f8f6a269":"code","2932622e":"code","02fd7462":"code","298d46dc":"code","34b75be8":"code","7eae138f":"code","106ec260":"code","7fffb6e5":"code","f65c42a6":"code","1b29a21d":"code","e7a60f2e":"code","5f4582f2":"code","9e835a19":"code","cb1d27d6":"code","d51965eb":"code","c7b4c446":"code","31b5237f":"code","64d26fb8":"code","27e1e32d":"code","04d3ce1a":"code","1618890f":"code","d84422e5":"code","a93f91a3":"code","39e5cfb3":"code","b2acd082":"code","80f7c62b":"code","ee7e1525":"markdown","2529ab5e":"markdown","b997dc01":"markdown","1584211b":"markdown","f4fda36b":"markdown","dad8625b":"markdown"},"source":{"c742cd46":"#The aim of the data analysis is to select the suitable methods to forcast the students' grades in period three by using some parameters that have correlations with G3.\n#import necessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LinearRegression, SGDRegressor, Ridge\nfrom sklearn.model_selection import GridSearchCV","fe55e6e6":"# Reading data\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","342b4434":"data=pd.read_csv('\/kaggle\/input\/student-grade-prediction\/student-mat.csv')","f8f6a269":"data.head()","2932622e":"#Showing all columns of the data\ndata.columns","02fd7462":"#We need to predict the grade of G3 by using the data including G1, G2, health, absences.\n#We will decide which colunmns we need to set as the features\n#The features we choose based on the common sense are \"Medu\", \"Fedu\", \"traveltime\", \"studytime\", \"famrel\", \"Dalc\", \"Walc\" , \"health\", \"absences\", \"G1\", and \"G2\"\n#Setting these columns as x\nx=data[[\"Medu\", \"Fedu\", \"traveltime\", \"studytime\", \"famrel\", \"Dalc\", \"Walc\" , \"health\", \"absences\", \"G1\", \"G2\"]]\nprint(x)","298d46dc":"x.head()","34b75be8":"y=data[\"G3\"]\nprint(y.head())","7eae138f":"#Check if the data contains Nan value\nna_cols=data.isna().any()\nna_cols = na_cols[na_cols == True] \nprint(na_cols)\n#It turns out the data do not contain any Nan","106ec260":"#The statistics of G3\nm= y.value_counts().sort_values()\nprint(m)","7fffb6e5":"#We can draw some pictures to mark the relationship between the factors that may influence G3 \nplt.figure(figsize=(20, 8), dpi=100)\nplt.bar(data[\"Medu\"], y, width=0.5)\nplt.show()\n#The higer their mothers' education levels are, the higer the grade students can achieve in the period three.","f65c42a6":"plt.figure(figsize=(20, 8), dpi=100)\nplt.bar(data[\"Fedu\"], y, width=0.5)\nplt.show()\n#The connection between fathers' education and students' grades are weak.","1b29a21d":"plt.figure(figsize=(20, 8), dpi=100)\nplt.bar(data[\"traveltime\"], y, width=0.5)\nplt.show()\n#It seems that less travel time contributes to a higher grade.","e7a60f2e":"plt.figure(figsize=(20, 8), dpi=100)\nplt.bar(data[\"studytime\"], y, width=0.5)\nplt.show()\n#The grades are not obviously different when the students spend different time in studying. The tendency is that more studytime may contribute to a better grade.","5f4582f2":"plt.figure(figsize=(20, 8), dpi=100)\nplt.bar(data[\"famrel\"], y, width=0.5)\nplt.show()\n#The high quality family relationship promotes the students' performance on grades ","9e835a19":"plt.figure(figsize=(20, 8), dpi=100)\nplt.bar(data[\"Dalc\"], y, width=0.5)\nplt.show()","cb1d27d6":"plt.figure(figsize=(20, 8), dpi=100)\nplt.bar(data[\"Walc\"], y, width=0.5)\nplt.show()\n#The students using alchohol at weekends does littel influence on their grades. However, the students using much alchohol at weekdays tend to have higher grades.","d51965eb":"plt.figure(figsize=(20, 8), dpi=100)\nplt.scatter(data[\"health\"], y)\nplt.show()\n#It seems that the students whose health level is two have the competitive advantage in grades","c7b4c446":"plt.figure(figsize=(20, 8), dpi=100)\nplt.bar(data[\"absences\"], y, width=0.5)\nplt.show()\n#It is obvious that less absence number links to a higher degree","31b5237f":"plt.figure(figsize=(20, 8), dpi=100)\nplt.bar(data[\"G1\"], y, width=0.5)\nplt.show()\n#The students who acquire the higher grade in period one tend to gain the higer grade in period three","64d26fb8":"plt.figure(figsize=(20, 8), dpi=100)\nplt.bar(data[\"G2\"], y, width=0.5)\nplt.show()\n#The students who acquire the higher grade in period two tend to gain the higer grade in period three","27e1e32d":"#After the analysis, we can exclude factor of \"Walc\" and \"Fedu\" , which have less correlation with G3 \nx_new=x.drop([\"Walc\", \"Fedu\"], axis=1)\nprint(x_new.head())","04d3ce1a":"#Dividing the data as parts of test and train\nx_train, x_test, y_train, y_test=train_test_split(x_new, y, random_state=6)\n#standardizing x data\ntransfer = StandardScaler()\nx_train = transfer.fit_transform(x_train)\nx_test = transfer.transform(x_test)","1618890f":"#Using Random Forest\nestimator=RandomForestClassifier(n_estimators=10, criterion=\"entropy\", max_depth=8, bootstrap=True, max_features=\"auto\")\nestimator.fit(x_train, y_train)\ny_predict=estimator.predict(x_test)\naccuracy = estimator.score(x_test, y_test)\nprint(\"The accuracy by RandomForest:\\n\", accuracy)","d84422e5":"#Using Xgboost\nestimator= XGBClassifier()\nestimator.fit(x_train, y_train)\ny_predict=estimator.predict(x_test)\naccuracy = estimator.score(x_test, y_test)\nprint(\"The accuracy by Xgboost:\\n\", accuracy)","a93f91a3":"#Using linear Regression\nestimator=LinearRegression(fit_intercept=True)\nestimator.fit(x_train, y_train)\nprint(estimator.coef_)\nprint(estimator.intercept_)\ny_predict=estimator.predict(x_test)\nprint(\"Forcasted number by Linear regression\uff1a\\n\", y_predict)\nprint(\"The accuracy by linear regression:\\n\", accuracy)","39e5cfb3":"#Using Ridge\nestimator=Ridge(alpha=1, max_iter=10000)\nestimator.fit(x_train, y_train)\nprint(estimator.coef_)\nprint(estimator.intercept_)\ny_predict=estimator.predict(x_test)\nprint(\"Forcasted number by Ridge\uff1a\\n\", y_predict)\naccuracy = estimator.score(x_test, y_test)\nprint(\"The accuracy by Ridge:\\n\", accuracy)","b2acd082":"#Using gridsearch to find the best parameters\nparam_dict = {\"alpha\": [0.5, 0.6, 0.7, 0.8, 0.9, 1], \"max_iter\":[10000, 50000, 100000, 150000, 200000]}\nestimator = GridSearchCV(estimator, param_grid=param_dict, cv=10)\nestimator.fit(x_train,y_train)\nprint(\"best parameters:\\n\", estimator.best_params_)\nprint(\"best estimator\uff1a\\n\", estimator.best_estimator_)\nprint(\"best score:\\n\", estimator.best_score_)","80f7c62b":"#Using SDGRegressor\nestimator=SGDRegressor(max_iter=10000)\nestimator.fit(x_train, y_train)\nprint(estimator.coef_)\nprint(estimator.intercept_)\ny_predict=estimator.predict(x_test)\nprint(\"Forcasted number by SDGRegressor\uff1a\\n\", y_predict)\naccuracy = estimator.score(x_test, y_test)\nprint(\"The accuracy by SGDRegressor:\\n\", accuracy)","ee7e1525":"4. Preparing data for machine learning","2529ab5e":"3. Drawing pictures","b997dc01":"5. Machine learning methods","1584211b":"conclusion: \n1. As we can see, the best forcasting methods are SGDRegressor and Ridge to forcast the students' grades in the third period. \n2. The past grades in period 1 and period 2 play the key roles in determining the final grades of the students. Study is a continued process. Please build the foundation at the beginning!","f4fda36b":"1. Reading data","dad8625b":"2. Processing data"}}