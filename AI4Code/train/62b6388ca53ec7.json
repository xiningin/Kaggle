{"cell_type":{"1df7acf8":"code","9a1e6bbb":"code","f961af00":"code","76e0bbcd":"code","b4cb8bc7":"code","509b8ba1":"code","ec30817e":"code","aea83d79":"code","f9f257dd":"code","c8d2f534":"code","d5e9c178":"code","b54907a1":"code","c53af73a":"code","e55cc831":"code","3375091d":"code","a8968903":"code","ff634629":"code","e1c2bb97":"code","24fe1e83":"markdown","66505c1b":"markdown","6a326afa":"markdown","f105ff94":"markdown","6a631f74":"markdown","3a6321ba":"markdown"},"source":{"1df7acf8":"# In this study I have utilized a dataset that exist at: \n# https:\/\/moodle.telt.unsw.edu.au\/mod\/resource\/view.php?id=2535204.\n# AND I UPLOADED THE SAME IN MY KAGGLE FOLDER INPUT\\Credit Card Balanced Data. \n# Please don't get confused by MY folder name, \n# the folder has UN-BALANCED DATA, WHICH WILL BE BALANCED as we PROCEED.\n\n# Please note, this\n# dataset used in my Research Report is not exactly the same as the one used in the paper\n# by Wickramasinghe, R. I. P. (2017), but very close. \n\nimport pandas as pd\ncreditcard = pd.read_csv(\"..\/input\/credit-card-balanced-data\/creditcard.csv\")\n\n# ****** THE PAPER by Wickramasinghe, R. I. P. (2017). \n# titled \"Attribute Noise, Classification Technique, and Classification Accuracy\". \n# In Data Analytics and Decision Support for Cybersecurity (pp. 201-220). Springer, Cham. \n# USES THE FOLLOWING DATASET \n# This secondary dataset has been modified from the initial dataset, which contains\n# credit cards\u2019 transactions by European credit cards holders within two days in\n# September 2013. This dataset includes 29 features including time, amount, and the\n# time duration of the transaction in seconds\n# Copyright\u00a9: This dataset is made available under the Open Database License\n# (http:\/\/opendatacommons.org\/licenses\/odbl\/1.0\/). The Open Database License\n# (ODbL) is license agreement intended to allow users to freely share, modify,\n# and use this Dataset while maintaining this freedom for others, provided that the\n# original source and author(s) are credited.\n\n# *** BUT I AM NOT USING THE SAME for my Research Report *** BUT THE ONE PICKED FROM  \n# https:\/\/moodle.telt.unsw.edu.au\/mod\/resource\/view.php?id=2535204\n# AND UPLOADED IN MY KAGGLE FOLDER INPUT\\Credit Card Balanced Data. Please don't get confused by folder name, \n# the folder has UN-BALANCED DATA, WHICH WILL BE BALANCED as we PROCEED.","9a1e6bbb":"# Importing necessary libraries\nimport sys\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","f961af00":"# Loading data\ndata = pd.read_csv('..\/input\/credit-card-balanced-data\/creditcard.csv')","76e0bbcd":"# View DataFrame\ndata.head()","b4cb8bc7":"data.shape","509b8ba1":"data.columns","ec30817e":"data.info()","aea83d79":"data.describe()  #statistical inference","f9f257dd":"# Visualising every feature\ndata.hist(figsize=(20,20))\nplt.show()","c8d2f534":"# Determine number of fraud cases in dataset\nFraud = data[data['Class'] == 1]\nValid = data[data['Class'] == 0]\n\noutlier_fraction = len(Fraud)\/(len(Valid))\nprint(outlier_fraction)\n\nprint('Fraud Cases : {}'.format(len(Fraud)))\nprint('Valid Cases : {}'.format(len(Valid)))","d5e9c178":"# Correlation\ncorr = data.corr()\nfigure = plt.figure(figsize=(12,10))\nsns.heatmap(corr)","b54907a1":"# Splitting data\nx = data.iloc[:,:-1].values\ny = data.iloc[:,-1].values\n\nfrom sklearn.model_selection import train_test_split\nxtr,xtest,ytr,ytest = train_test_split(x,y,test_size=0.3,random_state=0)","c53af73a":"xtr.shape,ytr.shape","e55cc831":"xtest.shape,ytest.shape","3375091d":"from xgboost import XGBClassifier\nxg = XGBClassifier(random_state=0)\nxg.fit(xtr,ytr)\nxg.score(xtr,ytr)","a8968903":"pred = xg.predict(xtest)","ff634629":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(pred,ytest)\n","e1c2bb97":"from sklearn.metrics import accuracy_score\naccuracy_score(pred,ytest)","24fe1e83":"<p>I can see we don't have any missing values in our data<\/p>\n<p>30 columns in my dataset is float, and 1 is int<\/p>","66505c1b":"<h2>Implement XGBoost Algorithm to find its Accuracy to Detect Fraud Records in Credit Card Dataset<\/h2>\n<p>I would like to verify the number of fraud and non-fraud algorithm using XGBoost Algorithm.\nIt has been shown that even a very simple logistic regression model can achieve good recall, while a much more complex Random Forest model improves upon logistic regression in terms of AUC( Area Under the Curve). However, XGBoost model improves upon both models.\nXGBoost stands for eXtreme Gradient Boosting, it was developed by Tianqi Chen and now is part of a wider collection of open-source libraries developed by the Distributed Machine Learning Community (DMLC). XGBoost is a scalable and accurate implementation of gradient boosting machines and it has proven to push the limits of computing power for boosted trees algorithms as it was built and developed for the sole purpose of model performance and computational speed. XGBoost is an implementation of gradient boosted decision trees designed for speed and performance.    \n <\/p>","6a326afa":"<h3>Checking Accuracy<\/h3>","f105ff94":"<h1>Data Preprocessing<\/h1>","6a631f74":"<h3>Initialising and Fitting Data to the Model<\/h3>","3a6321ba":"<h3>Validating on Test Data<\/h3>"}}