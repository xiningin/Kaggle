{"cell_type":{"eeb900d0":"code","e1924a55":"code","26618bd3":"code","7b1ed783":"code","408c3238":"code","aba25b9a":"code","be370100":"code","d131cbcb":"code","4cccc7b3":"markdown","c0e2ecd5":"markdown","4a6a0df5":"markdown","586aecf7":"markdown","24b5eca3":"markdown","f1ff6b0d":"markdown","fb6210e4":"markdown","ffeb967d":"markdown"},"source":{"eeb900d0":"from __future__ import print_function, division\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nimport csv\nimport warnings  \nwarnings.filterwarnings('ignore')","e1924a55":"def column(matrix, i):\n    return [row[i] for row in matrix]\n\nclass PokemonDataset(object):\n    def __init__(self, root, transforms):\n        self.root = root\n        self.transforms = transforms\n        # load all image files, sorting them to\n        # ensure that they are aligned\n        self.imgs = list(sorted(os.listdir(os.path.join(root, \"images\", \"images\"))))\n        with open(os.path.join(root, \"pokemon.csv\"), newline='') as f:\n            reader = csv.reader(f)\n            data = list(reader)\n        self.data = data\n        self.All_names = column(data, 0)\n        self.classes = ['Normal', 'Fighting', 'Flying', 'Poison', 'Ground', 'Rock', 'Bug', 'Ghost', 'Steel',\n               'Fire', 'Water', 'Grass', 'Electric', 'Psychic', 'Ice', 'Dragon', 'Dark', 'Fairy', '']\n\n    def __getitem__(self, idx):\n        # load images ad masks\n        img_path = os.path.join(self.root, \"images\", \"images\", self.imgs[idx])\n        img = Image.open(img_path).convert(\"RGB\")\n\n        image_id = torch.tensor([idx])\n        image_name = str(self.imgs[idx])[:-4]\n        index = self.All_names.index(image_name)\n        tester = self.data[index]\n\n        target = {}\n        target[\"pokedex\"] = self.All_names.index(image_name)\n        target[\"image_id\"] = image_id\n        target[\"name\"] = image_name\n        target[\"label\"] = tester[1]\n        target[\"label2\"] = ''\n        types = torch.tensor([0]*len(self.classes))\n        types[self.classes.index(tester[1])] = 1\n        if(len(tester) == 3):\n            target[\"label2\"] = tester[2]\n            types[self.classes.index(tester[2])] = 1\n        else:\n            target[\"label2\"] = ''\n            types[-1] = 1\n\n        if self.transforms is not None:\n            img = self.transforms(img)\n\n        return img, types, target\n\n    def __len__(self):\n        return len(self.imgs)","26618bd3":"data_transforms = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n    \ndef train_val_dataset(dataset, val_split=0.25):\n    train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=val_split)\n    datasets = {}\n    datasets['train'] = torch.utils.data.Subset(dataset, train_idx)\n    datasets['val'] = torch.utils.data.Subset(dataset, val_idx)\n    return datasets","7b1ed783":"data_dir = '\/kaggle\/input\/pokemon-images-and-types\/'\nx = 'images'\ndataset = PokemonDataset(data_dir, transforms=data_transforms)\nimage_datasets = train_val_dataset(dataset)\nclasses = ['Normal', 'Fighting', 'Flying', 'Poison', 'Ground', 'Rock', 'Bug', 'Ghost', 'Steel',\n           'Fire', 'Water', 'Grass', 'Electric', 'Psychic', 'Ice', 'Dragon', 'Dark', 'Fairy', '']\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n                                             shuffle=True, num_workers=4)\n              for x in ['train', 'val']}\n    \ninputs, types, cat  = next(iter(dataloaders['train']))\nprint(inputs.shape)\nsub_names = cat[\"name\"]\nsub_types = cat[\"label\"]\nsub_types2 = cat[\"label2\"]\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    \n    \ndef imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n \nimshow(out, title=sub_names)","408c3238":"def myCrit(xs, labs):\n    return torch.sum(-torch.sum(torch.log(xs)*labs + torch.log(1 - xs)*(1 - labs), dim = 1))# + torch.log(torch.sum(torch.exp(xs), dim = 1)))\n\ndef train_model(model, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n    \n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    \n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n    \n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n    \n            # Iterate over data.\n            for inputs, labels, _ in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n   \n                # zero the parameter gradients\n                optimizer.zero_grad()\n    \n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = torch.sigmoid(model(inputs))\n                    outputs_2 = outputs.clone()\n                    preds = outputs.argmax(1)\n                    preds_0 = torch.zeros(outputs.shape).to(device).scatter(1, preds.unsqueeze(1), 1)\n                    outputs_2 = outputs_2*(1 - preds_0)\n                    preds2 = outputs_2.argmax(1)\n                    preds_f = preds_0 + torch.zeros(outputs.shape).to(device).scatter(1, preds2.unsqueeze(1), 1)\n                    loss = myCrit(outputs, labels)\n    \n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n    \n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += .5*torch.sum(labels.data*preds_f)\n            if phase == 'train':\n                scheduler.step()\n    \n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n    \n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n    \n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n    \n        print()\n    \n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n    \n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","aba25b9a":"def visualize_model(model, num_images=10):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n    \n    with torch.no_grad():\n        for i, (inputs, labels, _) in enumerate(dataloaders['val']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n    \n            outputs = torch.sigmoid(model(inputs))\n            outputs = outputs.to(device)\n            outputs_2 = outputs.clone()\n            preds = outputs.argmax(1)\n            preds = preds.to(device)\n            preds_0 = torch.zeros(outputs.shape).to(device).scatter(1, preds.unsqueeze(1), 1)\n            outputs_2 = outputs_2*(1 - preds_0)\n            preds2 = outputs_2.argmax(1)\n    \n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images\/\/2, 2, images_so_far)\n                ax.axis('off')\n                ax.set_title('predicted: {}'.format(classes[preds[j]] + ',' + classes[preds2[j]]))\n                imshow(inputs.cpu().data[j])\n    \n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)","be370100":"model_conv = torchvision.models.resnet50(pretrained=True)\nfor param in model_conv.parameters():\n    #Change this to false to train over just the output layer, easier if no GPU available\n    param.requires_grad = True\nnum_ftrs = model_conv.fc.in_features\nmodel_conv.fc = nn.Linear(num_ftrs, len(classes))\n    \nmodel_conv = model_conv.to(device)\n    \noptimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9, weight_decay=1)\n    \n# Decay LR by a factor of 0.15 every 4 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=4, gamma=0.15)\nmodel_conv = train_model(model_conv, optimizer_conv, exp_lr_scheduler, num_epochs=25)\nvisualize_model(model_conv)\n\nplt.ioff()\nplt.show()","d131cbcb":"import scipy.signal as signal\nimport statistics\n\ndataloader = torch.utils.data.DataLoader(dataset, batch_size=4,\n                                                 shuffle=False, num_workers=0)\nmodel = model_conv\nwith torch.no_grad():\n    indexes = []\n    names = []\n    corr = []\n    type_count = torch.tensor([0]*len(classes))\n    type_corr = torch.tensor([0]*len(classes))\n    counter = 1\n    for i, (inputs, labels, info) in enumerate(dataloader):\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n \n        outputs = torch.sigmoid(model(inputs))\n        outputs_2 = outputs.clone()\n        a = outputs.argmax(1)\n        preds_0 = torch.zeros(outputs.shape).to(device).scatter(1, a.unsqueeze(1), 1)\n        outputs_2 = outputs_2*(1 - preds_0)\n        b = outputs_2.argmax(1)\n        preds_1 = torch.zeros(outputs.shape).to(device).scatter(1, b.unsqueeze(1), 1)\n        preds = preds_0 + preds_1\n        corrs = .5*torch.sum(labels*preds, dim = 1)\n        \n        corrs = corrs.to('cpu')\n        labels = labels.to('cpu')\n        for j in range(inputs.size()[0]):\n            indexes.append(info[\"pokedex\"][j].tolist())\n            names.append(info[\"name\"][j])\n            type_count = type_count + labels[j]\n            type_corr = type_corr + corrs[j]*labels[j]\n            corr.append(.5*torch.sum(corrs[j]*labels[j]))\n            counter += 1\n        \n    type_avg = (type_corr\/type_count)\n    type_count = type_count.tolist()\n    type_corr = type_corr.tolist()\n    type_avg = type_avg.tolist()\n    \ncorr = [correct.tolist() for (ind,correct) in sorted(zip(indexes, corr))]\nnames = [name for (ind,name) in sorted(zip(indexes, names))]\nindexes = sorted(indexes)\n    \nsmoothCorr = signal.savgol_filter(corr, 25, 1)\n#plt.plot(indexes, corr, 'go')\nplt.plot(indexes, smoothCorr)\nplt.xlabel(\"Pokedex Number\")\nplt.ylabel(\"p correct\")\nplt.show()\n    \npertype = type_count\/(np.sum(type_count))\nsortClass = [classy for (per, classy) in sorted(zip(type_avg, classes))]\nsortPer = [tp for (per, tp) in sorted(zip(type_avg, pertype))]\nx_pos = [i for i, _ in enumerate(classes)] \n\nplt.bar(x_pos, sorted(type_avg), color = 'green')\nplt.xlabel(\"Pokemon Type\")\nplt.ylabel(\"p correct\")     \nplt.xticks(x_pos, sortClass, rotation = 90)\nplt.show()\n\nplt.bar(x_pos, sorted(type_avg), color = 'green')\nplt.bar(x_pos, sortPer, color='red')\nplt.xlabel(\"Pokemon Type\")\nplt.ylabel(\"p correct and p of type\")    \nplt.xticks(x_pos, sortClass, rotation = 90)\nplt.show()\n    \nplt.scatter(sortPer[:-1], sorted(type_avg)[:-1])\nplt.xlabel('p of Pokemon of Type')\nplt.ylabel('p correct')\nplt.show()\n    \ngens = ['gen 1', 'gen 2', 'gen 3', 'gen 4', 'gen 5', 'gen 6', 'gen 7']\npokenum = [151, 251, 386, 493, 649, 721, 809]\ncorr_by_gen = [0]*len(gens)\ncorr_by_gen[0] = statistics.mean(corr[0:pokenum[0]])\nfor i in range(1, len(pokenum)):\n    corr_by_gen[i] = statistics.mean(corr[pokenum[i-1]:pokenum[i]])\n \ngen_pos = [i for i, _ in enumerate(gens)]    \nplt.bar(gen_pos, corr_by_gen, color='green')\nplt.xlabel(\"Generation Number\")\nplt.ylabel(\"p correct\")\n    \nplt.xticks(gen_pos, gens)\n   \nplt.show()\n","4cccc7b3":"Train the program and plot a set of 10 resulting guesses.","c0e2ecd5":"Make summary plots. Note that guessing accuracy depends on the rarity of a pokemon's type and that it has become more difficult to guess pokemon types over time and over generations.","4a6a0df5":"Define the classes into which pokemon will be sorted, load the data into dataloaders, plot example images of loaded data.","586aecf7":"Define the training procedure. Note that logistic regression must be changed slightly from torch's default in order to accomodate two correct guesses for type for each pokemon.","24b5eca3":"Define a way to plot resulting guesses","f1ff6b0d":"This program fine-tunes a pretrained neural network to generate predictions for a pokemon's two types based on its sprite image. It achieves moderate success, guessing well above random chance but still with error rates of approximately 50%. Note that 'no type' is treated as a type that can be guessed, and the network rarely guesses two types, generally choosing 'no type' as one of the types.\n\nNote that code is adapted from the torchvision tutorials here: https:\/\/pytorch.org\/tutorials\/beginner\/transfer_learning_tutorial.html","fb6210e4":"Import packages, mostly torch packages","ffeb967d":"Define transformation to regularize images and seperate the input images into train and validation datasets."}}