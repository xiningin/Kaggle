{"cell_type":{"388a4019":"code","ecdaf432":"code","29062f51":"code","052b024f":"code","c1865bd2":"code","45a1bf72":"code","1fe8ad77":"code","ec743728":"code","d3dee551":"code","d7424355":"code","331a6cf5":"code","b5690119":"code","74e0efef":"code","4f4b39e3":"code","f2f1f12b":"code","b20e80ef":"code","c77490b1":"code","a22029d4":"code","e714fde9":"code","2ac37332":"code","3c7c02a0":"markdown","010c42fc":"markdown","a4f79640":"markdown","a520684e":"markdown","b62b80cd":"markdown","a3fb2dea":"markdown","d60e31c2":"markdown","8a58615a":"markdown","a0ec9fbe":"markdown","7e6a5671":"markdown"},"source":{"388a4019":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#Settings\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n#Probably can`t be finished because of huge amount of data with kaggle hardware, add nrows parameter to run here\n#Load Data\n\ncols = [' Bwd Packet Length Std',' PSH Flag Count',' min_seg_size_forward',' Min Packet Length',' ACK Flag Count',' Bwd Packet Length Min',' Fwd IAT Std','Init_Win_bytes_forward',' Flow IAT Max',' Bwd Packets\/s',' URG Flag Count','Bwd IAT Total',' Label']\ndf1=pd.read_csv(\"\/kaggle\/input\/cicids2017\/MachineLearningCSV\/MachineLearningCVE\/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\", usecols = cols)#,nrows = 50000\ndf2=pd.read_csv(\"\/kaggle\/input\/cicids2017\/MachineLearningCSV\/MachineLearningCVE\/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\", usecols = cols)\ndf3=pd.read_csv(\"\/kaggle\/input\/cicids2017\/MachineLearningCSV\/MachineLearningCVE\/Friday-WorkingHours-Morning.pcap_ISCX.csv\", usecols = cols)\ndf5=pd.read_csv(\"\/kaggle\/input\/cicids2017\/MachineLearningCSV\/MachineLearningCVE\/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\", usecols = cols)\ndf6=pd.read_csv(\"\/kaggle\/input\/cicids2017\/MachineLearningCSV\/MachineLearningCVE\/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\", usecols = cols)\n\n# df4, df7 and df8 are being left out as they only have the benign samples\n\ndf = pd.concat([df1,df2])\ndel df1,df2\ndf = pd.concat([df,df3])\ndel df3\ndf = pd.concat([df,df5])\ndel df5\ndf = pd.concat([df,df6])\ndel df6\n\ndata = df.copy()\n# data = data[:100000]\n\ny = data[' Label'].copy()\nX = data.drop([' Label'],axis=1)\n","ecdaf432":"y_true=y.copy()\nattack = ['DDoS', 'PortScan', 'Bot', 'Infiltration', 'Web Attack \ufffd Brute Force', 'Web Attack \ufffd XSS', 'Web Attack \ufffd Sql Injection']\nnormal = 'BENIGN'\ny_true=y_true.replace(attack, 1)\ny_true=y_true.replace(normal, 0)\ny_true.unique()","29062f51":"from sklearn.ensemble import IsolationForest\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nclass Isolation_Forest:\n    def __init__(self, max_samples = 10000):\n        rng = np.random.RandomState(42)\n        self.model = IsolationForest(max_samples = max_samples, random_state=rng)\n        \n    def fit(self, X):\n        self.model.fit(X)\n        \n    def predict(self, X):\n        pred = self.model.predict(X)\n        pred[pred==1] = 0\n        pred[pred==-1] = 1\n#         self.pred = pred\n        return pred\n    \n    @staticmethod\n    def evaluate(pred, ytrue):\n        print(\"percentage of Legit:\", (list(pred).count(0)\/pred.shape[0])*100)\n        print(\"percentage of Anomaly:\",(list(pred).count(1)\/pred.shape[0])*100)\n        cf_matrix = confusion_matrix(y_true, pred)\n        tn, fp, fn, tp = cf_matrix.ravel()\n        recall = tp\/(tp+fn)\n        precision = tp\/(tp+fp)\n        f1 = 2 * (precision*recall)\/(precision+recall)\n#         f1, self.fn = f1, fn\n        print(\"Confusion Matrix:\",cf_matrix)\n        print(f\"True Positive {tp}, True Negetive {tn}\")\n        print(f\"False Positive {fp}, False Negetive {fn}\")        \n        print(\"Recall\", recall, \"\\nPrecision\", precision)\n        print(\"F1 Score\", f1)","052b024f":"def filter_anomaly(df, y_pred):\n    df[\"pred\"] = y_pred\n    valuesX = df[df.pred== 1]\n    valuesX.drop(['pred'],axis=1, inplace=True)\n    return valuesX","c1865bd2":"model1 = Isolation_Forest(10000)\nmodel1.fit(X)\nx = filter_anomaly(X.copy(), model1.predict(X))\nprint(len(x))","45a1bf72":"model2 = Isolation_Forest(1000)\nmodel2.fit(x)","1fe8ad77":"pred1 = model1.predict(X)\npred2 = model2.predict(X)","ec743728":"model1.evaluate(pred1, y_true)","d3dee551":"list(pred1).count(1), list(pred2).count(1)","d7424355":"list(pred1 & pred2).count(1)","331a6cf5":"model = Isolation_Forest(max_samples = 10000)\nmodel.fit(X)\ny_pred = model.predict(X)","b5690119":"model.evaluate(y_true)","74e0efef":"from sklearn.ensemble import IsolationForest\n\nrng = np.random.RandomState(42)\n\nmodel = IsolationForest(max_samples=10000, random_state=rng)\nmodel.fit(X)\ny_pred = model.predict(X)\n# Convert 1 to zero and -1 to one \n\nprint(y_pred)\nprint(y_pred.shape)\n\nprint(\"percentage of Legit:\", (list(y_pred).count(1)\/y_pred.shape[0])*100)\nprint(\"percentage of Anomaly:\",(list(y_pred).count(-1)\/y_pred.shape[0])*100)","4f4b39e3":"print (len(y_true))\ny_true.value_counts()","f2f1f12b":"print(len(y_pred))\npd.Series(y_pred).value_counts()","b20e80ef":"from sklearn.metrics import confusion_matrix\ncf_matrix = confusion_matrix(y_true, y_pred)\ntn, fp, fn, tp = cf_matrix.ravel()\ncf_matrix","c77490b1":"import seaborn as sns\nimport matplotlib.pyplot as plt \nax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n\nax.set_title('Confusion Matrix with labels\\n\\n');\nax.set_xlabel('\\nPredicted Values')\nax.set_ylabel('Actual Values ');\n\n## Ticket labels - List must be in alphabetical order\nax.xaxis.set_ticklabels(['False','True'])\nax.yaxis.set_ticklabels(['False','True'])\n\n## Display the visualization of the Confusion Matrix.\nplt.show()\n","a22029d4":"print (\"True Negetive\", tn, \n       \"\\nTrue Positive\", tp)\nprint (\"False Negetive\", fn, \n       \"\\nFalse Positive\", fp)","e714fde9":"recall = tp\/(tp+fn)\nprecision = tp\/(tp+fp)\nprint(\"Recall\", recall, \"\\nPrecision\", precision)","2ac37332":"f1 = 2 * (precision*recall)\/(precision+recall)\nprint(\"F1 Score\", f1)","3c7c02a0":"## Data Loading","010c42fc":"# CICIDS Anomaly detection","a4f79640":"## Inference Pipeline","a520684e":"# Creating True Data ","b62b80cd":"### Training Pipeline","a3fb2dea":"1. Data Loading\n2. Data Preprocessing\n4. Machine Learning Models Isolation Forest To detect anomaly","d60e31c2":"## Machine Learning Models Isolation Forest","8a58615a":"# Evaluation ","a0ec9fbe":"# Extra Clutter","7e6a5671":"## PipeLine"}}