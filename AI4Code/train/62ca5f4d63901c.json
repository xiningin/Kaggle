{"cell_type":{"0f031a39":"code","9377628e":"code","e4ee9233":"code","503cc90d":"code","c3f1b830":"code","f2b3fadd":"code","78076834":"code","2674e9b6":"code","4fee3652":"code","9c68880b":"code","2c811c07":"code","d9931399":"code","70d49634":"code","50a4ccf0":"code","9cb57720":"code","4c9ea86c":"code","53080e34":"markdown","586d63a1":"markdown","21dfc942":"markdown","64ba4693":"markdown","78165fe0":"markdown","82a26f7c":"markdown","21aa8179":"markdown","9654f5a2":"markdown","9f6ab32f":"markdown","3479b90a":"markdown","b3810200":"markdown","4de4bffe":"markdown"},"source":{"0f031a39":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9377628e":"df=pd.read_csv('\/kaggle\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndf.head()","e4ee9233":"#describe data set\ndf.describe()","503cc90d":"#check data set contain null value or not\ndf.isnull().sum()","c3f1b830":"#shape of data set\nprint('shape of data set',df.shape)\n# number of feature\nprint('Number of feature',len(df.columns)-1)\n# feature type\nprint(df.dtypes)","f2b3fadd":"import matplotlib.pyplot as plt\nimport seaborn as sns","78076834":"# check dataset balance or umbalance\nsns.countplot(x='Churn',data=df)","2674e9b6":"from sklearn.preprocessing import LabelEncoder\ncol=df.columns\ncategorical=[i for i in col if df[i].dtype==object]\nprint('categorical feature are',categorical)\n\nle=LabelEncoder()\nfor i in categorical:\n    df[i]=le.fit_transform(df[i])","4fee3652":"categorical=[i for i in col if df[i].dtype==object]\nprint('categorical feature are',categorical)","9c68880b":"from sklearn.model_selection import train_test_split\nx=df.iloc[:,0:-1]\ny=df['Churn']\nx_train,x_test,y_train,y_test=train_test_split(x,y,stratify=y)","2c811c07":"def auc_roc(y_predict):\n    from sklearn.metrics import roc_auc_score,roc_curve\n    plt.figure(figsize=(10,5))\n    fpr,tpr,_=roc_curve(y_test,y_predict)\n    auc_score=roc_auc_score(y_test,y_predict)\n    plt.plot(fpr,tpr,label='auc score= '+str(auc_score))\n    plt.xlabel('fpr')\n    plt.ylabel('tpr')\n    plt.plot([0,1],[0,1],'--')\n    plt.title('AUC ROC Curve')\n    plt.show()","d9931399":"def confusion_(y_predict):\n    from sklearn.metrics import confusion_matrix\n    plt.figure(figsize=(10,5))\n    confusion=confusion_matrix(y_test,y_predict)\n    norm_cm = confusion.astype('float') \/ confusion.sum(axis=1)[:, np.newaxis]\n    sns.heatmap(norm_cm,annot=confusion,center =2.2,fmt='2g', xticklabels=['Predicted: No','Predicted: Yes'], yticklabels=['Actual: No','Actual: Yes'])\n    plt.title('confusion matrix')\n    plt.show()","70d49634":"from sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nmodel=RandomForestClassifier()\nmodel.fit(x_train,y_train)\nprint('train accuracy',model.score(x_train,y_train))\ny_predict=model.predict(x_test)\nprint('test accuracy',accuracy_score(y_test,y_predict))\nauc_roc(y_predict)\nconfusion_(y_predict)","50a4ccf0":"from sklearn.linear_model import LogisticRegression\nmodel=LogisticRegression()\nmodel.fit(x_train,y_train)\nprint('train accuracy',model.score(x_train,y_train))\ny_predict=model.predict(x_test)\nprint('test accuracy',accuracy_score(y_test,y_predict))\nauc_roc(y_predict)\nconfusion_(y_predict)","9cb57720":"from sklearn.neighbors import KNeighborsClassifier\nn_neighbors=[1,3,5,7,11,15,50]\ntest_acc=[]\ntrain_acc=[]\nfor i in n_neighbors:    \n    model=KNeighborsClassifier(n_neighbors=i)\n    model.fit(x_train,y_train)\n    train_acc_score=model.score(x_train,y_train)\n    #print('train accuracy',train_acc_score)\n    train_acc.append(train_acc_score)\n    y_predict=model.predict(x_test)\n    test_acc_score=accuracy_score(y_test,y_predict)\n    #print('test accuracy',test_acc_score)\n    test_acc.append(test_acc_score)\nplt.plot(n_neighbors,train_acc,label='train accuracy')\nplt.plot(n_neighbors,test_acc,label='test accuracy')\nplt.xlabel('K')\nplt.ylabel('accuracy')\nplt.show()\nprint(train_acc)\nprint(test_acc)","4c9ea86c":"k=13\nmodel=KNeighborsClassifier(n_neighbors=k)\nmodel.fit(x_train,y_train)\ntrain_acc_score=model.score(x_train,y_train)\nprint('train accuracy',train_acc_score)\ny_predict=model.predict(x_test)\ntest_acc_score=accuracy_score(y_test,y_predict)\nprint('test accuracy',test_acc_score)\nauc_roc(y_predict)\nconfusion_(y_predict)","53080e34":"> <font color='Blue'>Build model<font>","586d63a1":"> Feature Encoding","21dfc942":"### Exploratory Data Analysis","64ba4693":"> Split Dataset","78165fe0":"> AUC ROC Curve","82a26f7c":"Read Data","21aa8179":"### Data Preprocessing","9654f5a2":"> Logistic Regression","9f6ab32f":"> confusion matrix","3479b90a":"### Data overview\n","b3810200":"> Random Forest","4de4bffe":"> KNN"}}