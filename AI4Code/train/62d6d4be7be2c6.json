{"cell_type":{"ee61cdc2":"code","de01bd5c":"code","f5db6b32":"code","ebadbcad":"code","08819ade":"code","894561ed":"code","06b8ad24":"code","6ff68740":"markdown","0410344e":"markdown"},"source":{"ee61cdc2":"# import standard libraries\nimport pandas as pd\nimport numpy as np\nfrom catboost import CatBoostRegressor\nimport optuna\nimport matplotlib.pyplot as plt\nfrom sklearn import model_selection, metrics\nimport seaborn as sns\nfrom functools import partial\n\n# show all columns\npd.set_option('max_columns', None)","de01bd5c":"# read the data\ntrain = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/test.csv')\nsample = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/sample_submission.csv')\n\n# drop id columns from train and test sets\ntrain = train.drop('id', axis=1)\ntest = test.drop('id', axis=1)","f5db6b32":"# histogramse for all variables with KDE\nplt.figure(figsize=(24, 6*(104\/4)))\nfor i in range(len(train.columns.tolist())):\n    plt.subplot(26, 4, i+1)\n    if i <= 99:\n        sns.histplot(train[f'f{i}'], kde=True)\n    else:\n        sns.histplot(train['loss'], kde=True)\nplt.show()","ebadbcad":"# correlation matrix with heat map\ncorr = train.corr()\nplt.figure(figsize=(20, 20))\nsns.heatmap(corr)\nplt.show()","08819ade":"# the ten highest correlated features for each feature\ncols = train.columns.tolist()\nfor col in cols:\n    print(col)\n    print(corr[col].sort_values(ascending=False)[1:11])\n    print('=======================')","894561ed":"# extract X and y for training set\nX = train.drop('loss', axis=1).values\ny = train['loss'].values","06b8ad24":"params = {\n        \"depth\": 5,\n        \"grow_policy\": \"Lossguide\",\n        \"l2_leaf_reg\": 29.6703901792061,\n        \"random_strength\": 0.00156814441573572\n        }\n\n\n# KFold\nn_splits=5\nkf = model_selection.KFold(n_splits=n_splits)\nscores_train = []\nscores_valid = []\npreds_valid_array = np.zeros((X.shape[0], ))\npreds_test_array = np.zeros((test.shape[0], ))\n\nfor fold, (train_idx, valid_idx) in enumerate(kf.split(X)):\n\n    print(f\"Fold {fold+1} -------------->\")\n    x_train, y_train = X[train_idx], y[train_idx]\n    x_valid, y_valid = X[valid_idx], y[valid_idx]\n\n    y_train_log = y_train\n    y_valid_log = y_valid\n\n    model = CatBoostRegressor(\n                           **params,\n                           learning_rate=0.03,\n                           iterations=10000,\n                           loss_function='RMSE',\n                           eval_metric='RMSE',\n                           use_best_model=True,\n                           early_stopping_rounds=100,\n                           task_type=\"GPU\",\n                           devices='0:1'\n                           )\n\n        \n    model.fit(\n          x_train, y=y_train,\n          #embedding_features=None,\n          use_best_model=True,\n          eval_set=[(x_valid, y_valid)],\n          verbose=100\n             )\n\n\n\n    preds_train = np.clip(model.predict(x_train), 0, 50)\n    preds_valid = np.clip(model.predict(x_valid), 0, 50)\n    preds_test = np.clip(model.predict(test), 0, 50)\n    \n    preds_valid_array[valid_idx] += preds_valid\n    preds_test_array += preds_test \/ n_splits\n    \n    try:\n        score_train = np.sqrt(metrics.mean_squared_error(y_train, preds_train))\n        score_valid = np.sqrt(metrics.mean_squared_error(y_valid, preds_valid))\n        print(score_valid)\n        scores_train.append(score_train)\n        scores_valid.append(score_valid)\n    except:\n        pass\n\nprint('Mean train score =', np.mean(scores_train), 'STD train =', np.std(scores_train, ddof=1))\nprint('Mean valid score =', np.mean(scores_valid), 'STD valid =', np.std(scores_valid, ddof=1))\n\npd.DataFrame({'loss': preds_valid_array}).to_csv('catboost1_valid.csv', index=False)\nsample.iloc[:, 1] = preds_test_array\nsample.to_csv('catboost1_test.csv', index=False)","6ff68740":"# Simple EDA","0410344e":"# CatBoost with Optimized Hyperparameters"}}