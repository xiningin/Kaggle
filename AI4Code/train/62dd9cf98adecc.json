{"cell_type":{"a0c0aac6":"code","21f2a76d":"code","f912e81f":"code","f7996d65":"code","938688c5":"code","2cba0ec5":"code","c40ececa":"code","d8af3970":"code","c5beeffc":"code","26b4b37d":"code","d2116bb1":"code","9a548560":"code","694ffc82":"code","f9f31d86":"code","113bcafe":"code","3b739794":"code","9b860152":"code","4eda5476":"code","a5e1e433":"code","27f5e0e0":"code","d4f3b14e":"code","8812f7d3":"code","c06dbd42":"code","33c34415":"code","b750562e":"code","0a662b3e":"code","d905a783":"code","745af2e5":"code","62eb794c":"code","c639a166":"code","933ebc97":"code","db8734b6":"code","70901212":"markdown","da5a1584":"markdown","d74059e0":"markdown","6564af00":"markdown","3de8fe97":"markdown","2141eec0":"markdown","7395fc65":"markdown","9b2b5fec":"markdown","61e655cb":"markdown"},"source":{"a0c0aac6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nfrom sklearn.neighbors import DistanceMetric\nfrom math import radians\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\n\n\nfrom sklearn import svm\nfrom sklearn import metrics\n\n\nfrom sklearn.datasets import make_moons, make_blobs\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\nfrom sklearn.metrics import make_scorer, classification_report, make_scorer, recall_score, f1_score\nfrom sklearn.metrics import roc_curve,auc\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.tree import DecisionTreeClassifier","21f2a76d":"df = pd.read_csv(\"\/kaggle\/input\/weather-dataset-rattle-package\/weatherAUS.csv\")\naus_town_gps = pd.read_csv(\"..\/input\/aus-town-gps\/aus_town_gps.csv\",sep=\",\")\nclimatsaus = pd.read_csv(\"..\/input\/climatsaus-v2\/climatsAUS_v2.csv\",sep=\";\")","f912e81f":"df.info()","f7996d65":"df.describe(include='object')","938688c5":"#Attribution de la classe de climat (classification de K\u00f6ppen) pour chaque ville\nclimatsaus.head()","2cba0ec5":"# Pour simplifier, on regroupe les climats en 4 cat\u00e9gories : chaud_humide, temp\u00e9r\u00e9_froid, sec et m\u00e9diterran\u00e9en. On pourra ainsi faire des visualisations plus facilement.\n\nclimats_type = {'Am':'chaud_humide',\n                'Aw':'chaud_humide',\n                'Cfa':'chaud_humide',\n                'Cfb':'temp\u00e9r\u00e9_froid', \n                'Cfc':'temp\u00e9r\u00e9_froid', \n                'BSh':'sec',\n                'BSk':'sec',\n                'Bsk':'sec', \n                'Bwh':'sec',\n                'Csa':'m\u00e9diterran\u00e9en',\n                'Csb':'m\u00e9diterran\u00e9en'              \n               }\n\nclimatsaus['Clim_type']=climatsaus['Climat_Koppen'].map(climats_type)","c40ececa":"#Fusion des dataframes\n\ndf = pd.merge(df, aus_town_gps, how='left', left_on=\"Location\",right_on=\"Location\")\ndf = pd.merge(df, climatsaus, how='left', left_on=\"Location\",right_on=\"Location\")\ndf.head(10)","d8af3970":"df.info()","c5beeffc":"#cr\u00e9ation de quelques variables de date et conversion de raintoday et raintomorrow en num\u00e9riques\ndf['RainToday_Num'] = (df['RainToday'] ==  'Yes')*1\ndf['RainTomorrow_Num'] = (df['RainTomorrow'] ==  'Yes')*1\ndf['Date'] = pd.to_datetime(df['Date'])\ndf['Mois'] = df['Date'].dt.month\ndf['Trimestre'] = df['Date'].dt.quarter\ndf['Annee'] = df['Date'].dt.year","26b4b37d":"#cr\u00e9ation d'un dictionnaire associant la direction du vent \u00e0 l'angle correspondant (en degr\u00e9s) sur le cercle trigonom\u00e9trique (ie. E=0\u00b0 et rotation dans le sens direct)\nangles = {'E':0, \n          'ENE':22.5, \n          'NE':45, \n          'NNE':67.5, \n          'N':90, \n          'NNW':112.5, \n          'NW':135, \n          'WNW':157.5, \n          'W':180, \n          'WSW':202.5, \n          'SW':225, \n          'SSW':247.5, \n          'S':270, \n          'SSE':292.5, \n          'SE':315, \n          'ESE':337.5}\n\n#ajout des variables indiquant l'angle du vent au DF\ndf['WindGust_Ang']=df['WindGustDir'].map(angles)\ndf['Wind9am_Ang'] = df['WindDir9am'].map(angles)\ndf['Wind3pm_Ang'] = df['WindDir3pm'].map(angles)\n\n#ajout de variables correspondant au cosinos de l'angle (abscisse des coordonn\u00e9es trigo). Un cosinus n\u00e9gatif correspond \u00e0 un vent d'ouest, un cosinus positif \u00e0 un vent d'est.\ndf['WindGust_cos'] = np.cos(np.radians(df['WindGust_Ang']))\ndf['Wind9am_cos'] = np.cos(np.radians(df['Wind9am_Ang']))\ndf['Wind3pm_cos'] = np.cos(np.radians(df['Wind3pm_Ang']))\n\n#ajout de variables correspondant au sinus de l'angle (ordonn\u00e9e des coordonn\u00e9es trigo). Un sinus n\u00e9gatif correspond \u00e0 un vent de sud, un sinus positif \u00e0 un vent de nord.\ndf['WindGust_sin'] = np.sin(np.radians(df['WindGust_Ang']))\ndf['Wind9am_sin'] = np.sin(np.radians(df['Wind9am_Ang']))\ndf['Wind3pm_sin'] = np.sin(np.radians(df['Wind3pm_Ang']))","d2116bb1":"df[\"LogRainfall\"] = np.log(df[\"Rainfall\"])\ndf[\"LogEvaporation\"] = np.log(df[\"Evaporation\"])\n\ndf= df.sort_values([\"Location\",\"Date\"])\ndf[\"Rain_J-1\"] = df[\"RainToday_Num\"].shift(1)\ndf[\"Rain_J-2\"] = df[\"RainToday_Num\"].shift(2)\ndf[\"Rain_J+2\"] = df[\"RainToday_Num\"].shift(-2)\ndf[\"Rain_J+3\"] = df[\"RainToday_Num\"].shift(-3)\n","9a548560":"df.describe()","694ffc82":"df.info()","f9f31d86":"#On supprime toutes les observations avec des NA pour le moment\ndf1 = df.dropna()\n\nlabelencoder = LabelEncoder()\ndf1['Clim_type1'] = labelencoder.fit_transform(df1['Clim_type'])\n\n#Pour les algos de detection d'anomalie, la convention est de mettre -1 pour la modalit\u00e9 \u00e0 d\u00e9tecter*\/\n\ndf1[\"Class\"] = df1[\"RainTomorrow_Num\"]\ndf1['Class'].replace({1: -1}, inplace=True)\ndf1['Class'].replace({0: 1}, inplace=True)\n\n\nfeatures = [\"RainToday_Num\",\"Rain_J-1\",\"Rain_J-2\",\"MinTemp\",\"MaxTemp\",\"Mois\",\"Sunshine\",\"Evaporation\",\n            \"Humidity3pm\",\"Humidity9am\",\"Pressure9am\",\"Pressure3pm\",\"Cloud3pm\",\"Cloud9am\", \n            \"Wind9am_cos\",\"Wind3pm_cos\",\"WindGust_cos\",\"Wind9am_sin\",\"Wind3pm_sin\",\"WindGust_sin\", \"Clim_type1\"]\n\ntarget = df1[\"RainTomorrow_Num\"]\ntarget_ano = df1[\"Class\"]\ndata = df1[features]","113bcafe":"X_train, X_test, y_train, y_test, y_train_ano, y_test_ano = train_test_split(data, target, target_ano, test_size=0.2, random_state=123)","3b739794":"#Grille de recherche pour avoir les meilleurs hyperparametres pour le criterion et max_depth.\n\nparam_grid = { 'criterion':['gini','entropy'],'max_depth': np.arange(3, 15),'min_samples_split':[300],'min_samples_leaf':[100]}\nnfolds = 3\n\nresc_dt = make_scorer(f1_score,pos_label=1)\n\n# decision tree model\ndtree_model=DecisionTreeClassifier()\n#use gridsearch to test all values\ndtree_gscv = GridSearchCV(dtree_model, param_grid, cv=nfolds, scoring=resc_dt)\n#fit model to data\ndtree_gscv.fit(X_train, y_train)\n\ndtree_gscv.best_params_","9b860152":"#Cr\u00e9ation de l'arbre avec les meilleurs hyperparametres calcules ci dessus\n\ndt_clf = DecisionTreeClassifier(criterion='gini', max_depth=7,random_state=123,)\ndt_clf.fit(X_train , y_train)","4eda5476":"# Ins\u00e9rez votre code ici\n\ny_pred = dt_clf.predict(X_test)\n\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n\n## M\u00e9thode 2 : \u00e0 l'aide de pandas\ncm = pd.crosstab(y_test, y_pred, rownames=['Classe r\u00e9elle'], colnames=['Classe pr\u00e9dite'])\ncm","a5e1e433":"feats = {}\nfor feature, importance in zip(data.columns, dt_clf.feature_importances_):\n    feats[feature] = importance \n    \nimportances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Importance'})\nimportances.sort_values(by='Importance', ascending=False).head(8)","27f5e0e0":"import matplotlib.pyplot as plt\nfrom sklearn.tree import plot_tree\nplt.figure(figsize=(20,15))\nplot_tree(dt_clf,feature_names = list(features),filled=True,proportion=True,max_depth=2)\nplt.show()","d4f3b14e":"probs_dt = dt_clf.predict_proba(X_test)\n\nfpr_dt, tpr_dt, seuils_dt = roc_curve(y_test,probs_dt[:,1],pos_label=1)\n#fpr1, tpr1, seuils1 = det_curve(y_test,probs[:,1],pos_label=1)\nroc_auc_dt = auc(fpr_dt, tpr_dt)\n\nplt.figure(figsize=(20,6))\nplt.subplot(121)\nplt.plot(fpr_dt, tpr_dt, color='purple', lw=2, label='Decision Tree (auc = %0.2f)' % roc_auc_dt)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Al\u00e9atoire (auc = 0.5)')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('Taux faux positifs')\nplt.ylabel('Taux vrais positifs')\nplt.title('Courbe ROC')\nplt.legend(loc=\"lower right\")","8812f7d3":"ac = AdaBoostClassifier(base_estimator=dt_clf,n_estimators=400)\nac.fit(X_train , y_train)\nac.score(X_test, y_test)","c06dbd42":"probs_ada = ac.predict_proba(X_test)\n\nfpr_ada, tpr_ada, seuils_ada = roc_curve(y_test,probs_ada[:,1],pos_label=1)\nroc_auc_ada = auc(fpr_ada, tpr_ada)\n\nplt.figure(figsize=(20,6))\nplt.subplot(121)\nplt.plot(fpr_ada, tpr_ada, color='purple', lw=2, label='Ada Boost Classifier (auc = %0.2f)' % roc_auc_ada)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Al\u00e9atoire (auc = 0.5)')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('Taux faux positifs')\nplt.ylabel('Taux vrais positifs')\nplt.title('Courbe ROC')\nplt.legend(loc=\"lower right\")","33c34415":"sns.countplot(target_ano);","b750562e":"frac = df1[df1['Class']==-1]['Class'].count()\/df1['Class'].count()\nfrac","0a662b3e":"from sklearn.ensemble import IsolationForest\nIsoF = IsolationForest(n_estimators=100,contamination=0.2)\nIsoF.fit(X_train)","d905a783":"y_pred = IsoF.predict(X_test)\n\npd.crosstab(y_test_ano, y_pred, rownames=['Classes r\u00e9elles'], colnames=['Classes pr\u00e9dites'])","745af2e5":"print(classification_report(y_test_ano, y_pred))","62eb794c":"# On d\u00e9coupe manuellement nos jeu de donn\u00e9es de validation crois\u00e9e au sein de l'\u00e9chantillon d'apprentissage\nskf = StratifiedKFold(n_splits=3) \nfolds = list(skf.split(X_train, y_train_ano))\nforest = IsolationForest()\n\n# Dans la situation o\u00f9 on ne connait pas \u00e0 priori le param\u00e8tre de contamination,\n# on ajoutera la contamination dans la grille de recherche\n\n#resc = make_scorer(recall_score,pos_label=-1)\nresc = make_scorer(f1_score,pos_label=-1)\n\nparams = {'contamination': np.linspace(0.1, 0.8, 20), 'n_estimators': [200]}\n\nsearch = GridSearchCV(estimator=forest, param_grid=params, scoring=resc, cv=folds, n_jobs=-1)\nsearch.fit(X_train, y_train_ano)\n\n# predict\noptimal_forest = search.best_estimator_\ny_pred = optimal_forest.predict(X_test)\n\n\npd.crosstab(y_test_ano, y_pred, rownames=['Classes r\u00e9elles'], colnames=['Classes pr\u00e9dites'])","c639a166":"print(classification_report(y_test_ano, y_pred))","933ebc97":"probs_IsoForest = optimal_forest.score_samples(X_test)\nfpr_IsoForest, tpr_IsoForest, seuils_IsoForest = roc_curve(y_test_ano,probs_IsoForest)\nroc_auc_IsoForest = auc(fpr_IsoForest, tpr_IsoForest)","db8734b6":"plt.figure(figsize=(20,6))\nplt.plot(fpr_dt, tpr_dt, color='purple', lw=2, label='Decision Tree (auc = %0.2f)' % roc_auc_dt)\nplt.plot(fpr_ada, tpr_ada, color='red', lw=2, label='Ada Boost Classifier (auc = %0.2f)' % roc_auc_ada)\nplt.plot(fpr_IsoForest , tpr_IsoForest , color='green', lw=2, label='Isolation Forest (auc = %0.2f)' % roc_auc_IsoForest)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Al\u00e9atoire (auc = 0.5)')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('Taux faux positifs')\nplt.ylabel('Taux vrais positifs')\nplt.title('Courbe ROC')\nplt.legend(loc=\"lower right\")\n","70901212":"Le jeu de donn\u00e9es poss\u00e8de 145 460 entr\u00e9es et 23 colonnes dont :\n- La date de l'observation.\n- La ville dans laquelle se situe la station m\u00e9t\u00e9o.\n- 20 variables d\u00e9crivant les conditions atmosph\u00e9riques du jour de l\u2019observation. *\n- La variable cible RainTomorrow dont la valeur (Yes ou No) indique s'il a plu le lendemain de l'observation.\n\n*Le jeu de donn\u00e9es contient un m\u00e9lange de variables explicatives cat\u00e9gorielles (type object) et de variables explicatives num\u00e9riques (type float64) :\n- 14 variables continues : MinTemp, MaxTemp, Rainfall, Evaporation, Sunshine, WindGustSpeed, WindSpeed9am, WindSpeed3pm, Humidity9am, Humidity3pm, Pressure9am, Pressure3pm, Temp9am, Temp3pm\n- 2 variables discr\u00e8tes (Nombre d'octas, de 0 \u00e0 9) : Cloud9am, Cloud3pm\n- 4 variables cat\u00e9gorielles non-num\u00e9riques : WinGustDir, WindDir3am, WindDir3pm, RainToday.\n- Les valeurs de la variable RainToday (Yes, No) sont d\u00e9finies par la variable Rainfall (Yes si pr\u00e9cipitations > 1mm)*\n\nPlusieurs variables poss\u00e8dent de nombreuses valeurs manquantes qu'il faudra g\u00e9rer.\n\nLe jeu de donn\u00e9es comporte 3436 journ\u00e9es d'observations m\u00e9t\u00e9orologiques (entre d\u00e9cembre 2008 et juin 2017) r\u00e9alis\u00e9es par 49 stations m\u00e9t\u00e9o (Location).","da5a1584":"## Import des fichiers de travail","d74059e0":"# Decouverte du dataframe - Pr\u00e9processing","6564af00":"# Boosting \u00e0 partir de l'arbre optimal ci dessus","3de8fe97":"# Algorithmes de d\u00e9tections d'anomalies","2141eec0":"# Arbre de d\u00e9cision","7395fc65":"## Num\u00e9risation des vents","9b2b5fec":"**Chargements des jeux de donn\u00e9es :**\n - df : donn\u00e9es m\u00e9t\u00e9o en australie sur 10 ans\n - aus_town_gps : localisation des stations m\u00e9t\u00e9o (x,y) => ce jeu de donn\u00e9es va nous permettre de repr\u00e9senter les indicateurs sur une carte et de calculer des distances entre stations m\u00e9t\u00e9o\n - climatsaus : climat des stations m\u00e9teo ","61e655cb":"# Pr\u00e9paration des bases d'entrainement et de validation"}}