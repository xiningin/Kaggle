{"cell_type":{"d23ebe05":"code","c447cc77":"code","32e68835":"code","c44d08e4":"code","4d6df2e4":"code","b63649aa":"code","181ca0e2":"code","5f893d32":"code","00a4ab92":"code","5fe7c2b4":"code","b21fcb89":"code","5c8d24be":"markdown","570e792a":"markdown","b2637992":"markdown","c4d58374":"markdown","bbdc02d4":"markdown","897e952c":"markdown","eb30897c":"markdown","bf4fd739":"markdown","a80b2585":"markdown"},"source":{"d23ebe05":"import os\nimport random\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nimport seaborn\nimport albumentations as A\nimport pandas as pd\nimport tqdm\nfrom tqdm import notebook\n%matplotlib inline","c447cc77":"images_dir = '\/kaggle\/input\/cityscapes-image-pairs\/cityscapes_data'\ntrain_images_dir = os.path.join(images_dir, 'train')\nval_images_dir = os.path.join(images_dir, 'val')\nworking_dir = '\/kaggle\/working'\nweights_path = os.path.join(working_dir, 'unet4_weights.h5')\nlogs_path = os.path.join(working_dir, 'logs')","32e68835":"class Generator(tf.keras.utils.Sequence):\n    def __init__(self, images_dir, batch_size, is_augmentation, shuffle = True, rescale = 1.00, target_size = (128, 128)):\n        super(Generator, self).__init__()\n        self.images_dir = images_dir\n        self.batch_size = batch_size\n        self.rescale = rescale\n        self.shuffle = shuffle\n        self.is_augmentation = is_augmentation\n        self.target_size = target_size\n        self.filenames = [os.path.join(self.images_dir, filename) for filename in os.listdir(self.images_dir)]\n        self.current_step = 0\n        self.count_images = len(self.filenames)\n        self.available_steps = int(self.count_images \/\/ self.batch_size)\n        \n        self.transforms = A.Compose([\n            A.Rotate(25), \n            A.OneOf([\n                A.RGBShift(), A.HueSaturationValue()\n            ]),\n            A.OneOf([\n                A.CLAHE(), A.RandomBrightnessContrast(), A.RandomGamma()\n            ]), \n        ])\n    \n    def augmentate(self, batch):\n        batch = batch.astype(np.uint8)\n        batch = [self.transforms(image = image, mask = mask) for (image, mask) in batch]\n        batch = np.array([(transformed['image'], transformed['mask']) for transformed in batch], dtype = np.float32)\n        return batch\n    \n    def on_epoch_end(self):\n        if self.shuffle:\n            random.shuffle(self.filenames)\n            \n    def generate_batch(self):\n        start = self.current_step * self.batch_size\n        stop = (self.current_step + 1) * self.batch_size\n        filenames_batch = self.filenames[start:stop]\n        \n        # batch of original images from directory\n        images_batch = [cv2.imread(filename) for filename in filenames_batch]\n        \n        # change channeld order to rgb\n        images_batch = np.array([cv2.cvtColor(image, cv2.COLOR_BGR2RGB) for image in images_batch])\n        \n        # split original images by image and mask\n        images_batch = np.array([(image[:, :256,], image[:, 256:]) for image in images_batch]) \n        \n        # resize images\n        images_batch = np.array([(cv2.resize(image, self.target_size), cv2.resize(mask, self.target_size)) for (image, mask) in images_batch], dtype = np.float32)\n        \n        # augmentation\n        if self.is_augmentation:\n            images_batch = self.augmentate(images_batch)\n        \n        # rescaling \n        images_batch \/= self.rescale\n        \n        return np.moveaxis(images_batch, 1, 0)\n    \n    def __getitem__(self, index):\n        \n        self.current_step = index\n        images, masks = self.generate_batch()\n        return images, masks\n    \n    def __len__(self):\n        return self.available_steps","c44d08e4":"generator = Generator(images_dir = train_images_dir, batch_size = 8, is_augmentation = True, rescale = 255.0)","4d6df2e4":"def show_examples(generator, num_batches):\n    sample = np.hstack([np.concatenate([np.hstack(sample) for sample in np.moveaxis(generator[iteration], 0, 1)]) for iteration in range(num_batches)])\n    plt.figure(figsize = (30, 30))\n    plt.axis('off')\n    plt.imshow(sample)","b63649aa":"show_examples(generator = generator, num_batches = 3)","181ca0e2":"tf.keras.backend.set_image_data_format('channels_last')\n\nclass unet(object):\n    def __init__(self, image_shape):\n        super(unet, self).__init__()\n        assert len(image_shape) == 3\n        self.image_shape = image_shape\n        self.optimizer = tf.keras.optimizers.Adam(lr=1e-4)\n        self.model = self.build_model()\n        \n    \n    def convolution(self, inputs, num_filters, kernel_size, name):\n        x = tf.keras.layers.Conv2D(num_filters, kernel_size, padding = 'same', name = f'{name}_conv_1')(inputs)\n        x = tf.keras.layers.LeakyReLU(alpha = 0.2, name = f'{name}_activation_1')(x)\n        x = tf.keras.layers.Conv2D(num_filters, kernel_size, padding = 'same', name = f'{name}_conv_2')(x)\n        x = tf.keras.layers.LeakyReLU(alpha = 0.2, name = f'{name}_activation_2')(x)\n        return x\n    \n    def downsample(self, inputs, num_filters, kernel_size, number):\n        conv = self.convolution(inputs, num_filters, kernel_size, name = f'conv_block_{number}')\n        pool = tf.keras.layers.MaxPooling2D((2, 2), name = f'conv_block_{number}_pool')(conv)\n        return conv, pool\n    \n    def upsample(self, inputs_1, inputs_2, num_filters, kernel_size, number):\n        up = tf.keras.layers.UpSampling2D((2, 2), name = f'deconv_block_upsampling_{number}')(inputs_1)\n        concat = tf.keras.layers.concatenate([up, inputs_2], axis = 3, name = f'deconv_block_concat_{number}')\n        outputs = self.convolution(inputs = concat, num_filters = num_filters, kernel_size = (3, 3), name = f'deconv_block_{number}')\n        return outputs\n    \n    def dice_coeff(self, y_true, y_pred):\n        y_true_f = tf.keras.backend.flatten(y_true)\n        y_pred_f = tf.keras.backend.flatten(y_pred)\n        intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n        return (2. * intersection + 1.0) \/ (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + 1.0)\n    \n    def dice_coeff_loss(self, y_true, y_pred):\n        return 1 - self.dice_coeff(y_true, y_pred)\n    \n    def IoU_loss(y_true, y_pred):\n        nb_classes = K.int_shape(y_pred)[-1]\n        iou = []\n        pred_pixels = K.argmax(y_pred, axis=-1)\n        for i in range(0, nb_classes):  # exclude first label (background) and last label (void)\n            true_labels = K.equal(y_true[:, :, 0], i)\n            pred_labels = K.equal(pred_pixels, i)\n            inter = tf.cast(true_labels & pred_labels, dtype=tf.int32)\n            union = tf.cast(true_labels | pred_labels, dtype=tf.int32)\n            legal_batches = K.sum(tf.cast(true_labels, dtype=tf.int32), axis=1) > 0\n            ious = K.sum(inter, axis=1) \/ K.sum(union, axis=1)\n            iou.append(K.mean(ious[legal_batches]))\n\n        iou = tf.stack(iou)\n        legal_labels = ~tf.math.is_nan(iou)\n        iou = iou[legal_labels]\n        return K.mean(iou)\n    \n    def build_model(self):\n        inputs = tf.keras.layers.Input(shape = self.image_shape, name = 'input')\n        \n        min_power = 5\n        conv1, pool1 = self.downsample(inputs = inputs, \n                                       num_filters = 2 ** min_power, \n                                       kernel_size = (3,3), \n                                       number = 1)\n        conv2, pool2 = self.downsample(inputs = pool1, \n                                       num_filters = 2 ** (min_power + 1), \n                                       kernel_size = (3,3), \n                                       number = 2)\n        conv3, pool3 = self.downsample(inputs = pool2, \n                                       num_filters = 2 ** (min_power + 2), \n                                       kernel_size = (3,3), \n                                       number = 3)\n        conv4, pool4 = self.downsample(inputs = pool3, \n                                       num_filters = 2 ** (min_power + 3), \n                                       kernel_size = (3,3), \n                                       number = 4)\n        \n        conv5 = self.convolution(inputs = pool4, \n                                 num_filters = 2**(min_power + 4), \n                                 kernel_size = (3,3), \n                                 name = 'conv_block_5')\n        \n        upsampling_1 = self.upsample(inputs_1 = conv5, \n                                     inputs_2 = conv4, \n                                     num_filters = 2 ** (min_power + 3), \n                                     kernel_size = (3,3), \n                                     number = 1)\n        upsampling_2 = self.upsample(inputs_1 = upsampling_1, \n                                     inputs_2 = conv3, \n                                     num_filters = 2 ** (min_power + 2), \n                                     kernel_size = (3,3), \n                                     number = 2)\n        upsampling_3 = self.upsample(inputs_1 = upsampling_2, \n                                     inputs_2 = conv2, \n                                     num_filters = 2 ** (min_power + 1), \n                                     kernel_size = (3,3), \n                                     number = 3)\n        upsampling_4 = self.upsample(inputs_1 = upsampling_3, \n                                     inputs_2 = conv1, \n                                     num_filters = 2 ** min_power, \n                                     kernel_size = (3,3), \n                                     number = 4)\n        \n        last_conv = tf.keras.layers.Conv2D(filters = 3, \n                                           kernel_size = (1, 1), \n                                           name = 'last_conv')(upsampling_4)\n        \n        outputs = tf.keras.layers.Activation('softmax', name = 'output')(last_conv)\n        \n        model = tf.keras.models.Model(inputs = inputs, outputs = outputs, name = 'Unet4')\n        model.compile(optimizer=self.optimizer, \n                      loss='binary_crossentropy', \n                      metrics=[self.dice_coeff, \n                               tf.keras.metrics.MeanIoU(30, name = 'iou')])\n        return model\n    \n    def train(self, epochs):\n        self.my_callbacks =  [tf.keras.callbacks.ModelCheckpoint(filepath=weights_path, monitor = 'val_loss', best_only = True),\n                              tf.keras.callbacks.TensorBoard(log_dir=logs_path),\n                              tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', patience = 3, factor = 0.2, min_lr = 1e-7, verbose = True)]\n        \n        self.train_generator = Generator(images_dir = train_images_dir, \n                                       batch_size = 8, \n                                       is_augmentation = True, \n                                       rescale = 255.0,\n                                       shuffle = True)\n        \n        self.test_generator = Generator(images_dir = val_images_dir, \n                                       batch_size = 8, \n                                       is_augmentation = False, \n                                       rescale = 255.0, \n                                       shuffle = False)\n    \n        \n        self.history = self.model.fit(self.train_generator, \n                                      validation_data = self.test_generator, \n                                      epochs = epochs, \n                                      callbacks = self.my_callbacks, \n                                      verbose = True, \n                                      use_multiprocessing = True, \n                                      workers = 4)\n    \n    def predict(self, x):\n        return self.model.predict(x)\n    \n    def __call__(self, x):\n        return self.model(x)\n    \n    def plot_yourself(self, show_shapes):\n        return tf.keras.utils.plot_model(self.model, show_shapes = show_shapes)\n        \n    \nUnet = unet(image_shape = (128, 128, 3))\nprint(f'\\n number of parameters in the model: {Unet.model.count_params()}\\n')\nUnet.plot_yourself(show_shapes = True)","5f893d32":"Unet.model.optimizer.learning_rate = 1e-6\nUnet.model.load_weights('\/kaggle\/input\/unet4-cityscapes\/unet4_weights.h5')","00a4ab92":"def show_results(epoch):\n    generator = Generator(images_dir = val_images_dir, \n                           batch_size = 1, \n                           is_augmentation = True, \n                           rescale = 255.0)\n    result = []\n    for iteration in range(3):\n        images, masks = generator[iteration]\n        prediction = np.concatenate(Unet.predict(images))\n        images = np.concatenate(images)\n        masks = np.concatenate(masks)\n        outputs = np.hstack([images, masks, prediction])\n        result.append(outputs)\n    result = np.hstack(result)\n    plt.figure(figsize = (10, 20))\n    plt.title(f'epoch - {epoch}')\n    plt.axis('off')\n    plt.imshow(result)","5fe7c2b4":"Unet = unet(image_shape = (128, 128, 3))\n\nfor iteration in range(5):\n    print(f'\\niteration - {iteration + 1}\\n')\n    Unet.train(epochs = 10)\n    show_results(epoch = (iteration + 1) * 10)","b21fcb89":"def show_final_results(epoch):\n    generator = Generator(images_dir = val_images_dir, \n                           batch_size = 8, \n                           is_augmentation = True, \n                           rescale = 255.0)\n    result = []\n    for iteration in range(2):\n        images, masks = generator[iteration]\n        prediction = np.concatenate(Unet.predict(images))\n        images = np.concatenate(images)\n        masks = np.concatenate(masks)\n        merged = np.add(images, prediction)\n        outputs = np.hstack([images, masks, prediction, merged])\n        result.append(outputs)\n    result = np.hstack(result)\n    plt.figure(figsize = (30, 30))\n    plt.axis('off')\n    plt.imshow(result)\n\nshow_final_results(epoch = 0)","5c8d24be":"![image.png](attachment:f45864b3-eabf-431b-ae0b-bba39382a97e.png)","570e792a":"so now I decided to write generator which compatable with model.fit() method","b2637992":"# Conclusion","c4d58374":"# Model","bbdc02d4":"# Custom Generator compatible with Keras","897e952c":"I losted output from this cell","eb30897c":"here example of generators output:","bf4fd739":"# Define Path Variables","a80b2585":"so in this notebook I tried to use Unet4 network with 7 million parameters, probably its possible to run it real-time, the model shows good result for 15 minutes of training on GPU, but sometimes we can see mistakes and so on. In conclusion I wanna say that I'm gonna make many posts like this tensorflow\/torch implemetation, and with different architectures, u can get pretrained weights for this model in source folder"}}