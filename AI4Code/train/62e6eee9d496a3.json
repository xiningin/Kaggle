{"cell_type":{"f0bfa197":"code","66bdbf2f":"code","2bac8b0f":"code","553cdeef":"code","b4ac0766":"code","8c22b1df":"code","e1cb35fe":"code","b463093e":"code","55af7ab7":"code","7fa7388f":"code","f840ea81":"code","bf82b2b6":"code","7d800edb":"code","c5e72fe0":"code","893f5310":"code","967682d3":"code","3ea77e80":"code","17ad2c83":"code","76622538":"code","bb2b5369":"code","c70b4f97":"markdown","fadef09c":"markdown","02523e3b":"markdown","065aeb88":"markdown","54f7c0fd":"markdown","104a1561":"markdown","6cb3f142":"markdown","b627b96b":"markdown","bd5b388f":"markdown","728295a1":"markdown","f9b97a04":"markdown"},"source":{"f0bfa197":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","66bdbf2f":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","2bac8b0f":"df = pd.read_csv(\"\/kaggle\/input\/kc-housesales-data\/kc_house_data.csv\")","553cdeef":"print(df.shape)\ndf.info()\ndf.describe()","b4ac0766":"df.head()","8c22b1df":"#dropping date and id as they won't affect the prcie prediction\ndf.drop(['date','id'], inplace = True, axis=1)","e1cb35fe":"df['age'] = 2020-df['yr_built']","b463093e":"df.drop('yr_built', axis=1, inplace=True)","55af7ab7":"import seaborn as sns\nsns.distplot(df['price'])\nprint(\"skewness :\", df['price'].skew())\nprint(\"kurtosis :\",df['price'].kurt())","7fa7388f":"df_boxplot = df[['sqft_living', 'sqft_above', 'sqft_basement', 'sqft_living15', 'age']]\ndf_barplot = df[['bedrooms', 'bathrooms', 'floors', 'waterfront', 'view', 'grade']]","f840ea81":"for i in df_boxplot.columns:\n    #sns.set(style='white')\n    plt.figure(figsize=(15,5))\n    #print(\"boxplot of %s\" %(i))\n    sns.boxplot(x=i, data=df)\n    plt.show()","bf82b2b6":"for i in df_barplot.columns:\n    plt.figure(figsize=(10,5))\n    cat_num = df[i].value_counts()\n    sns.barplot(x=cat_num.index, y=cat_num)\n    plt.show()","7d800edb":"sns.set()\nplt.figure(figsize=(20,10))\nsns.heatmap(df.corr(),annot=True)","c5e72fe0":"df.drop(['sqft_lot','condition','yr_renovated','zipcode','long','sqft_lot15'],axis=1, inplace=True)","893f5310":"X = df.drop('price',1)\ny=df['price']\ny = np.log(y) #since the price distribution is positively skewed, thus, doing logarithmic transformation","967682d3":"X","3ea77e80":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=33)","17ad2c83":"from sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit(X_train,y_train)\npredictions = model.predict(X_test)","76622538":"sns.set_style(\"whitegrid\")\nsns.regplot(y_test,predictions)","bb2b5369":"from sklearn.metrics import r2_score\nprint(\"score : \",r2_score(y_test,predictions))","c70b4f97":"# Splitting the Data\n We're going to split the data between training and test sets, in a 75:25 ratio.","fadef09c":" Creating an age column so, age will become a numerical variable and can be used in prediction. So, drop 'yr_built'.","02523e3b":"Also, dropping the outliers from the dataframe, using z-score method","065aeb88":"This shows that the 'price' variable is positively skewed, so while training the model we'll have to use log transformation of 'price'","54f7c0fd":"# Evaluation and Understanding Results","104a1561":"The accuracy score of our model is 0.7697 which means 76.97% of the predications made our correct.","6cb3f142":"The heatmap above suggests following independent variables don't affect the price much:\n* sqft_lot\n* condition\n* yr_renovated\n* zipcode\n* long\n* sqft_lot15\n\nSo, let's drop these from our dataframe","b627b96b":"# Training the Model and predictions","bd5b388f":"# Exploaratory Data Analysis\n## Univariate Analysis","728295a1":"## Bivariate Analysis","f9b97a04":"# Data Cleaning"}}