{"cell_type":{"0508a4ed":"code","808e3a32":"code","7255a5b6":"code","f6a10a54":"code","e9ef3e02":"code","5cc9a34f":"code","931a0b9a":"code","b3d887a1":"code","d4caf535":"code","5d9cb008":"code","7f16ee67":"code","f3f49767":"code","e4c6186c":"code","1adab355":"code","6ef2d38f":"code","15d778db":"code","c9b9e48f":"code","1e63e81e":"code","3381a807":"code","899637bc":"code","6049167b":"code","72bbd522":"code","a121f907":"code","962e3d24":"code","5549c8db":"code","5ee152ba":"code","fb11844a":"code","9d5619a3":"code","e0578877":"code","8e1f6eeb":"code","7cb6ca2a":"code","0ef301ae":"code","48ced683":"code","59058723":"code","d86cb377":"code","b5b8b130":"code","83cd43d4":"code","2f06b740":"code","8f7cf8c2":"code","bdc8b8a6":"code","c1f77b58":"code","1ae222da":"code","d67fcc61":"code","2874d9e6":"code","096282d5":"code","876e3540":"code","21451720":"code","59732bce":"code","e79fd29f":"code","9c4aaed4":"code","4bb2a041":"code","596a66a9":"markdown","e035aa7b":"markdown","e45d49c0":"markdown","2524aa67":"markdown","350be70f":"markdown","c33c425e":"markdown","119e450f":"markdown","e3a6a453":"markdown","daf28425":"markdown","c652d19b":"markdown","80d12b6e":"markdown","041e5104":"markdown","9c7801d1":"markdown","00cda4b5":"markdown"},"source":{"0508a4ed":"# importing libraries\nimport os, time, random, sys\nos.environ['PYTHONHASHSEED']=str(1)\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set_style('whitegrid')\nplt.style.use('seaborn-deep')\nplt.style.use('fivethirtyeight')\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.serif'] = 'Ubuntu'\nplt.rcParams['font.monospace'] = 'Ubuntu Mono'\nplt.rcParams['font.size'] = 10\nplt.rcParams['axes.labelsize'] = 12\nplt.rcParams['axes.titlesize'] = 12\nplt.rcParams['xtick.labelsize'] = 8\nplt.rcParams['ytick.labelsize'] = 8\nplt.rcParams['legend.fontsize'] = 12\nplt.rcParams['figure.titlesize'] = 14\nplt.rcParams['figure.figsize'] = (12, 8)\n\npd.options.mode.chained_assignment = None\npd.options.display.float_format = '{:.2f}'.format\npd.set_option('display.max_columns', 200)\npd.set_option('display.width', 400)\nimport warnings\nwarnings.filterwarnings('ignore')\nimport sklearn.metrics as skm\nimport sklearn.model_selection as skms\nimport sklearn.preprocessing as skp\nimport sklearn.utils as sku\nfrom skimage.io import imread\nfrom skimage.transform import resize\nseed = 12","808e3a32":"import tensorflow as tf\nimport tensorflow_addons as tfa\nprint(\"TF version:-\", tf.__version__)\nimport keras as k\nfrom keras import backend as K","7255a5b6":"def runSeed():\n    global seed\n    os.environ['PYTHONHASHSEED']=str(seed)\n    tf.random.set_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n\nrunSeed()\n\n## Checking the GPU configuration\n!nvidia-smi","f6a10a54":"# from google_drive_downloader import GoogleDriveDownloader as gdd\n\n# gdd.download_file_from_google_drive(file_id='1H0rJmSBmYQoWM2w2tqy-jmX0Y2Wg6k2v', \n#                                     dest_path='content\/flowers.zip', unzip=True)","e9ef3e02":"basePath = '\/kaggle\/input\/flowers-dataset\/'\ntrainPath = basePath + 'train\/'\nos.listdir(trainPath)","5cc9a34f":"submission_test_set = pd.read_csv(basePath + 'Testing_set_flower.csv')\nsubmission_test_set.head()","931a0b9a":"def showImage(img):\n    plt.figure(figsize=(3,3))\n    plt.imshow(img)\n    plt.show()","b3d887a1":"# constants\nbatch_size = 128\nimg_dim = 299\ndef getImgTensor(img_d):\n    return (img_d, img_d, 3)\ngetImgTensor(img_dim)","d4caf535":"# reading training and validation separately to prevent overlapping \n\ntrain_datagen = k.preprocessing.image.ImageDataGenerator(rescale=1.\/255, \n                                                         validation_split=0.2,\n                                                         shear_range=0.2, \n                                                         zoom_range=0.2, \n                                                         horizontal_flip=True, \n                                                         rotation_range=45,\n                                                         width_shift_range=0.1, \n                                                         height_shift_range=0.1,\n                                                         fill_mode='nearest'\n                                                        )\n\ntrain_generator=train_datagen.flow_from_directory(directory=trainPath,\n                                                  subset=\"training\",\n                                                  batch_size=batch_size,\n                                                  color_mode=\"rgb\",\n                                                  seed=seed,\n                                                  shuffle=True,\n                                                  class_mode=\"categorical\",\n                                                  target_size=getImgTensor(img_dim)[:2])","5d9cb008":"# generate class weights as classes are imbalanced\nclass_weights = sku.class_weight.compute_class_weight('balanced',\n                                                      np.unique(train_generator.classes), \n                                                      train_generator.classes)\ntrain_class_weights = {i:x for i, x in enumerate(class_weights)}\ntrain_class_weights","7f16ee67":"batch = train_generator.next()[0]\nshowImage(batch[0])\nshowImage(batch[1])","f3f49767":"valid_generator=train_datagen.flow_from_directory(directory=trainPath,\n                                                  subset=\"validation\",\n                                                  batch_size=batch_size,\n                                                  color_mode=\"rgb\",\n                                                  seed=seed,\n                                                  shuffle=True,\n                                                  class_mode=\"categorical\",\n                                                  target_size=getImgTensor(img_dim)[:2])","e4c6186c":"test_datagen = k.preprocessing.image.ImageDataGenerator(rescale=1.\/255)\n\ntest_generator=test_datagen.flow_from_directory(basePath, \n                                                batch_size=1,\n                                                color_mode=\"rgb\",\n                                                seed=seed,\n                                                shuffle=False,\n                                                classes=['test'],\n                                                target_size=getImgTensor(img_dim)[:2])","1adab355":"def plotModelHistory(h):\n    fig, ax = plt.subplots(1, 2, figsize=(15,4))\n    ax[0].plot(h.history['loss'])   \n    ax[0].plot(h.history['val_loss'])\n    ax[0].legend(['loss','val_loss'])\n    ax[0].title.set_text(\"Train loss vs Validation loss\")\n\n    ax[1].plot(h.history['categorical_accuracy'])   \n    ax[1].plot(h.history['val_categorical_accuracy'])\n    ax[1].legend(['categorical_accuracy','val_categorical_accuracy'])\n    ax[1].title.set_text(\"Train accuracy vs Validation accuracy\")\n\n    print(\"Max. Training Accuracy\", max(h.history['categorical_accuracy']))\n    print(\"Max. Validaiton Accuracy\", max(h.history['val_categorical_accuracy']))","6ef2d38f":"class myCallback(k.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        ACCURACY_THRESHOLD = 0.99\n        if(logs.get('categorical_accuracy') > ACCURACY_THRESHOLD):\n            print(\"\\n\\nStopping training as we have reached %2.2f%% accuracy!\" %(ACCURACY_THRESHOLD*100))   \n            self.model.stop_training = True","15d778db":"def trainModel(model, epochs, optimizer, vb=1, modelName='model'):\n    bestModelPath = '.\/'+modelName+'_model.hdf5'\n    callback = myCallback()\n    callbacks_list = [\n        callback,\n        k.callbacks.ReduceLROnPlateau(monitor = 'val_loss', patience = 5, verbose = 1, min_lr=0.00001), \n        k.callbacks.EarlyStopping(monitor = 'val_loss', patience = 15, verbose = 1, restore_best_weights = True), \n        k.callbacks.ModelCheckpoint(filepath=bestModelPath, monitor='val_loss', verbose=1, save_best_only=True)\n    ]\n    model.compile(optimizer=optimizer,\n                  loss=k.losses.CategoricalCrossentropy(label_smoothing=.05),\n                  metrics=[k.metrics.CategoricalAccuracy()]\n    )\n    train_generator.reset()\n    \n    steps_per_epoch = np.ceil(train_generator.n\/train_generator.batch_size)\n    validation_steps = np.ceil(valid_generator.n\/valid_generator.batch_size)\n\n    return model.fit_generator(generator=train_generator, steps_per_epoch=steps_per_epoch, \n                               validation_data=valid_generator, validation_steps=validation_steps, \n                               epochs=epochs, verbose=vb,\n                              #  class_weight=train_class_weights,\n                               callbacks=callbacks_list)","c9b9e48f":"# evaluate model with time\ndef evaluateModel(model, path=True):\n    batch_size = valid_generator.batch_size\n    num_train_sequences = valid_generator.n\n    valid_generator.reset()\n    steps_per_epoch = 0\n    if (valid_generator.n%valid_generator.batch_size) == 0:\n        steps_per_epoch = int(valid_generator.n\/valid_generator.batch_size)\n    else:\n        steps_per_epoch = int(valid_generator.n\/\/valid_generator.batch_size) + 1\n\n    t1 = time.time()\n    if path:\n        model = k.models.load_model(model)\n    eval_results = model.evaluate_generator(valid_generator, steps=steps_per_epoch)\n    t2 = time.time()\n    print(f'\\nLoss: {eval_results[0]}, Accuracy: {eval_results[1]}')\n    print(f'Prediction Time per Image: {(t2-t1)\/valid_generator.n}')","1e63e81e":"# predict images using model\ndef predictModel(modelPath):\n    batch_size = test_generator.batch_size\n    num_train_sequences = test_generator.n\n    steps_per_epoch = 0\n    if (test_generator.n%test_generator.batch_size) == 0:\n        steps_per_epoch = int(test_generator.n\/test_generator.batch_size)\n    else:\n        steps_per_epoch = int(test_generator.n\/\/test_generator.batch_size) + 1\n\n    test_generator.reset()\n\n    t1 = time.time()\n    model = k.models.load_model(modelPath)\n    predictions = model.predict_generator(test_generator, steps=steps_per_epoch, verbose=1)\n    t2 = time.time()\n    print(f'Prediction Time per Image: {(t2-t1)\/test_generator.n}')\n    \n    print(\"Generating Predictions file..\")\n    labels = (train_generator.class_indices)\n    labels = dict((v,k) for k,v in labels.items())\n    predicted_class_indices=np.argmax(predictions, axis=1)\n    predictions_label = [labels[k] for k in predicted_class_indices]\n    filenames = list(map(lambda x: x.split('\/')[-1], test_generator.filenames))\n    submission=pd.DataFrame({\n        \"Filename\":filenames, \n        \"Class\":predictions_label\n    })\n    # generate series of predictions as per testing_set\n    submission_final = pd.Series([submission[submission['Filename'] == x].iloc[0,1] for x in np.ravel(submission_test_set.values)])\n    submission_file = \"submission_\"+modelPath.split('\/')[-1].split('_')[0]+\".csv\"\n    submission_final.to_csv(submission_file,index=False, header=['prediction'])\n    print(f\"Submission file with {len(submission.values)} rows generated:\", submission_file)\n    submission.head()","3381a807":"img_dim=224\nmobilenet = k.applications.mobilenet_v2.MobileNetV2(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\nmobilenet.trainable = False\n\nmodel = k.models.Sequential([\n                             mobilenet,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.4),\n                             k.layers.Dense(256, activation='relu'),\n                            #  k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.3),\n                             k.layers.Dense(128, activation='relu'),\n#                              k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.2),\n                             k.layers.Dense(5, activation='softmax')\n])\nprint(model.summary())","899637bc":"history_1 = trainModel(model, 50, 'adam', modelName='mobilenet')","6049167b":"plotModelHistory(history_1)","72bbd522":"img_dim=224\nresnet152 = k.applications.ResNet152V2(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\nresnet152.trainable = False\n\nmodel_2 = k.models.Sequential([\n                             resnet152,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.4),\n                            #  k.layers.Dense(1024, activation='relu'),\n                            #  k.layers.BatchNormalization(),\n                            #  k.layers.Dropout(0.3),\n\n                             k.layers.Dense(512, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.3),\n\n                             k.layers.Dense(256, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.3),\n                             k.layers.Dense(5, activation='softmax')\n])\nprint(model_2.summary())","a121f907":"history_2 = trainModel(model_2, 50, 'adam', modelName='resnet152')","962e3d24":"plotModelHistory(history_2)","5549c8db":"img_dim=224\ninceptionv3 = k.applications.InceptionV3(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\ninceptionv3.trainable = False\n\nmodel_3 = k.models.Sequential([\n                             inceptionv3,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.4),\n                             k.layers.Dense(256, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.3),\n                            #  k.layers.Dense(128, activation='relu'),\n                            #  k.layers.BatchNormalization(),\n                            #  k.layers.Dropout(0.2),\n                             k.layers.Dense(5, activation='softmax')\n])\nprint(model_3.summary())","5ee152ba":"history_3 = trainModel(model_3, 50, 'adam', modelName='inceptionv3')","fb11844a":"plotModelHistory(history_3)","9d5619a3":"img_dim=331\nnasnet = k.applications.nasnet.NASNetLarge(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\nnasnet.trainable = False\n\nmodel_4 = k.models.Sequential([\n                             nasnet,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.4),\n                             k.layers.Dense(256, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.3),\n                            #  k.layers.Dense(128, activation='relu'),\n                            #  k.layers.BatchNormalization(),\n                            #  k.layers.Dropout(0.2),\n                             k.layers.Dense(5, activation='softmax')\n])\nprint(model_4.summary())","e0578877":"history_4 = trainModel(model_4, 50, 'adam', modelName='nasnet_large')","8e1f6eeb":"plotModelHistory(history_4)","7cb6ca2a":"img_dim=299\ninceptionresnet = k.applications.InceptionResNetV2(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\ninceptionresnet.trainable = False\n\nmodel_5 = k.models.Sequential([\n                             inceptionresnet,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.4),\n                             k.layers.Dense(256, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.3),\n                            #  k.layers.Dense(128, activation='relu'),\n                            #  k.layers.BatchNormalization(),\n                            #  k.layers.Dropout(0.2),\n                             k.layers.Dense(5, activation='softmax')\n])\nprint(model_5.summary())","0ef301ae":"history_5 = trainModel(model_5, 50, 'adam', modelName='inceptionresnet')","48ced683":"plotModelHistory(history_5)","59058723":"img_dim=299\ndensenet152 = k.applications.DenseNet169(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\ndensenet152.trainable = False\n\nmodel_6 = k.models.Sequential([\n                             densenet152,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.4),\n                             k.layers.Dense(256, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.3),\n                            #  k.layers.Dense(128, activation='relu'),\n                            #  k.layers.BatchNormalization(),\n                            #  k.layers.Dropout(0.2),\n                             k.layers.Dense(5, activation='softmax')\n])\nprint(model_6.summary())","d86cb377":"history_6 = trainModel(model_6, 50, 'adam', modelName='densenet169')","b5b8b130":"plotModelHistory(history_6)","83cd43d4":"model_7 = k.Model(model_5.input, model_5.layers[-3].output)\ntrain_generator.reset()\n# scan model feature representations\nX_train_embed = []\ny_train_embed = []\nfor x in range(int(np.ceil(train_generator.n\/train_generator.batch_size))):\n    x_batch, y_batch = next(train_generator)\n    x_last = model_7.predict(x_batch)\n    X_train_embed.extend(x_last)\n    y_train_embed.extend(y_batch)\n\n# generate predictions for embeddings\ny_train_embed = np.array(np.argmax(y_train_embed, axis=1))\nX_train_embed = np.array(X_train_embed)\nprint(y_train_embed.shape)","2f06b740":"# create xgb classifier for classification\nfrom xgboost import XGBClassifier\nxgb = XGBClassifier(max_depth=10, objective='multi:softmax', n_estimators=1000, num_classes=5,\n                    tree_meth ='gpu_hist', gpu_id=0, n_jobs=-1)\nxgb.fit(X_train_embed,y_train_embed)","8f7cf8c2":"# generate predictions for test data\nimg_dim=299\nX_test_embed = np.array(model_7.predict(test_generator))\npredictions_xgb = xgb.predict(X_test_embed)\n\n# generate submission file for predictions\nlabels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions_label = [labels[k] for k in predictions_xgb]\nfilenames = list(map(lambda x: x.split('\/')[-1], test_generator.filenames))\nsubmission=pd.DataFrame({\n    \"Filename\":filenames, \n    \"Class\":predictions_label\n})\n# generate series of predictions as per testing_set\nsubmission_final = pd.Series([submission[submission['Filename'] == x].iloc[0,1] for x in np.ravel(submission_test_set.values)])\nsubmission_file = \"submission_DENSENET169_XGB.csv\"\nsubmission_final.to_csv(submission_file,index=False)\nprint(f\"Submission file with {len(submission.values)} rows generated:\", submission_file)\nsubmission.head()","bdc8b8a6":"# mobile net\nimg_dim=224\nevaluateModel('.\/mobilenet_model.hdf5')","c1f77b58":"# resnet152\nimg_dim=224\nevaluateModel('.\/resnet152_model.hdf5')","1ae222da":"# inceptionv3\nimg_dim=224\nevaluateModel('.\/inceptionv3_model.hdf5')","d67fcc61":"# nasnet\nimg_dim=331\nevaluateModel('.\/nasnet_large_model.hdf5')\n# evaluateModel(model_4, False)","2874d9e6":"# inceptionresnet\nimg_dim=299\nevaluateModel('.\/inceptionresnet_model.hdf5')","096282d5":"# densenet169\nimg_dim=299\nevaluateModel('.\/densenet169_model.hdf5')","876e3540":"# mobile net\nimg_dim=224\npredictModel('.\/mobilenet_model.hdf5')","21451720":"# resnet152\nimg_dim=224\npredictModel('.\/resnet152_model.hdf5')","59732bce":"# inceptionv3\nimg_dim=224\npredictModel('.\/inceptionv3_model.hdf5')","e79fd29f":"# nasnet\nimg_dim=331\npredictModel('.\/nasnet_large_model.hdf5')","9c4aaed4":"# inceptionresnet\nimg_dim=299\npredictModel('.\/inceptionresnet_model.hdf5')","4bb2a041":"# densenet169\nimg_dim=299\npredictModel('.\/densenet169_model.hdf5')","596a66a9":"## Train NASNetLarge - Heavy Model","e035aa7b":"## CNN + XGB Model","e45d49c0":"# Model Building","2524aa67":"# Model Evaluation","350be70f":"## Setup Image Generator","c33c425e":"## Train ResNet152 - Heavy Model","119e450f":"# Data Preparation\n","e3a6a453":"## Train DenseNet169 - Light Model","daf28425":"## Train InceptionResNetV2 - Heavy Model","c652d19b":"# DPhi - Flower Recognition Challenge\n\nThe dataset contains images of 5 types of flowers.\n\nClasses:-\n- daisy\n- dandelion\n- rose\n- sunflower\n- tulip\n\n# Reading & Understanding Data\n## Importing Libraries","80d12b6e":"## Train InceptionV3 - Medium Model","041e5104":"## Train MobileNetV2 - Light Model","9c7801d1":"### Loading Dataset","00cda4b5":"# Model Prediction"}}