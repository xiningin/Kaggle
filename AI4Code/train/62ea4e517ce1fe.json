{"cell_type":{"5bab4b54":"code","919c50fd":"code","2c5aaa8e":"code","f85a7fd6":"code","92f03075":"code","8a6a7d54":"code","cc1aa4c5":"code","1a226eec":"code","2656dd04":"code","d177b03d":"code","3301a0ec":"code","be61027e":"code","6db23246":"code","623f9fd5":"code","dfac98c5":"code","1ce47c82":"code","3c1844dd":"code","eaa84716":"code","4ad73b40":"code","88ca1b4f":"code","d84eec2a":"code","5dc7a8cc":"code","0e20546b":"code","c0094b03":"code","f5e33a23":"code","7dd8f64b":"code","18278abd":"code","590b164c":"code","abc2b2ca":"code","7368f963":"code","e42f4587":"code","b246ed9b":"code","ca07e358":"code","9de5a259":"code","4d8eb557":"code","7e63e7b4":"code","29e8fed8":"code","f05a29b2":"code","4216f589":"code","1836eac0":"code","58539188":"code","a7f596ef":"code","cab17319":"code","03ec600c":"code","26ae569f":"code","3ab6abe8":"code","1ed5d10d":"code","725b88cb":"code","15fad037":"code","662675d3":"code","fc4a20c9":"code","f3b9fe62":"code","b75fca42":"code","dfde775f":"code","923a0631":"code","b07dc7d5":"code","0a7176f4":"code","3c2a0edc":"code","9a8de5ca":"code","8b857c25":"code","80b8c1eb":"code","5718701c":"code","b9edc27d":"code","066cf28f":"code","618f17a3":"code","7c402331":"code","7ccd37d6":"code","3d45b9b5":"code","2df7bd22":"code","c059c550":"code","53116748":"code","4da339d5":"code","730e9ed2":"code","48915eca":"code","41046b88":"code","a768d49c":"code","161ea03d":"code","fc3623e8":"code","4f166f9b":"code","e43d90fe":"code","d32b6961":"code","1541576e":"code","85afd342":"code","5198d97e":"code","cb110c68":"code","b6af7be6":"code","a2524985":"code","e79ace75":"code","17a28df7":"code","29ec6efb":"code","a4bc7e82":"code","a706de1f":"code","63950b89":"code","1373e326":"code","3f26c61f":"code","fb07656b":"code","d4a182a8":"code","2403d09a":"code","f75184ea":"code","67be90c2":"code","4982ff08":"code","b3bc01e4":"code","addaf53d":"code","5a78edaa":"code","e0b4e664":"code","bebb5dc9":"code","9db987ce":"code","1f4a9ad0":"code","6c7a1f8e":"markdown","c293c459":"markdown","1bbd469d":"markdown","4f3abd08":"markdown","617dcb7b":"markdown","e047f3a0":"markdown","8fce106f":"markdown","40cfaadc":"markdown","7ce7184c":"markdown","ac7f8a60":"markdown","0c81aad1":"markdown","04231e8d":"markdown","73d7f844":"markdown","0a25dd6e":"markdown","09571042":"markdown","994695c4":"markdown","85f5ee69":"markdown","9bfb93e8":"markdown","d67a772f":"markdown","325c54eb":"markdown","c7e2851c":"markdown","552b4caa":"markdown","2c7209a8":"markdown","3d09915e":"markdown","473ffc63":"markdown","1ddb05c7":"markdown","d950917d":"markdown","5e428e75":"markdown","8d418312":"markdown","525e3b43":"markdown","277c0a33":"markdown","c81e8914":"markdown","b1be8358":"markdown","b2be4abe":"markdown","98808a27":"markdown","d8178280":"markdown","3acefa88":"markdown","dbf4e98f":"markdown","2255c4f2":"markdown","f190282e":"markdown","6ca3c8f1":"markdown","141c27ea":"markdown","ee45b450":"markdown","047326f3":"markdown","7d5223f3":"markdown","553ab799":"markdown","b9e3346d":"markdown","0baf6367":"markdown","7ac3f973":"markdown","a811343b":"markdown","c4bcfe30":"markdown","7beb4903":"markdown","76c5acb0":"markdown","0a8a1923":"markdown","9c55bcbe":"markdown","905a21ab":"markdown","009fa39e":"markdown","39a48978":"markdown","af2a9cce":"markdown","45ac6967":"markdown","05a09269":"markdown","cd2e8814":"markdown","37e4a659":"markdown","cd2d916b":"markdown","e2e1322e":"markdown","39daad90":"markdown","416608f1":"markdown","3e715e16":"markdown","971fda5d":"markdown","6234ff2d":"markdown","9a25c4e0":"markdown","adcce6b5":"markdown","d6b488c7":"markdown","8e3cbc07":"markdown","412034f1":"markdown","18678085":"markdown","de5f0866":"markdown","0243cbe9":"markdown","d7ffeec8":"markdown","7fc88433":"markdown","643e1876":"markdown","fbe19dc0":"markdown","b380f695":"markdown","28dec90b":"markdown"},"source":{"5bab4b54":"# Supress Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","919c50fd":"# Importing libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","2c5aaa8e":"# visulaisation\nfrom matplotlib.pyplot import xticks\n%matplotlib inline","f85a7fd6":"# Data display coustomization\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', -1)","92f03075":"# To perform Hierarchical clustering\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import cut_tree\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.cluster import KMeans","8a6a7d54":"# import all libraries and dependencies for machine learning\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.decomposition import IncrementalPCA\nfrom sklearn.neighbors import NearestNeighbors\nfrom random import sample\nfrom numpy.random import uniform\nfrom math import isnan","cc1aa4c5":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","1a226eec":"ngo= pd.read_csv(r\"\/kaggle\/input\/help-international\/Country-data.csv\")\nngo.head()","2656dd04":"word=pd.read_csv(r\"\/kaggle\/input\/help-international\/data-dictionary.csv\")\nword.head(len(word))","d177b03d":"ngo_dub = ngo.copy()\n\n# Checking for duplicates and dropping the entire duplicate row if any\nngo_dub.drop_duplicates(subset=None, inplace=True)\n","3301a0ec":"ngo_dub.shape","be61027e":"ngo.shape","6db23246":"ngo.shape","623f9fd5":"ngo.info()","dfac98c5":"ngo.describe()","1ce47c82":"(ngo.isnull().sum() * 100 \/ len(ngo)).value_counts(ascending=False)","3c1844dd":"ngo.isnull().sum().value_counts(ascending=False)","eaa84716":"(ngo.isnull().sum(axis=1) * 100 \/ len(ngo)).value_counts(ascending=False)","4ad73b40":"ngo.isnull().sum(axis=1).value_counts(ascending=False)","88ca1b4f":"# Child Mortality Rate : Death of children under 5 years of age per 1000 live births\nplt.figure(figsize = (30,5))\nchild_mort = ngo[['country','child_mort']].sort_values('child_mort', ascending = False)\nax = sns.barplot(x='country', y='child_mort', data= child_mort)\nax.set(xlabel = '', ylabel= 'Child Mortality Rate')\nplt.xticks(rotation=90)\nplt.show()","d84eec2a":"plt.figure(figsize = (10,5))\nchild_mort_top10 = ngo[['country','child_mort']].sort_values('child_mort', ascending = False).head(10)\nax = sns.barplot(x='country', y='child_mort', data= child_mort_top10)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01 , p.get_height() * 1.01))\nax.set(xlabel = '', ylabel= 'Child Mortality Rate')\nplt.xticks(rotation=90)\nplt.show()","5dc7a8cc":"# Fertility Rate: The number of children that would be born to each woman if the current age-fertility rates remain the same\nplt.figure(figsize = (30,5))\ntotal_fer = ngo[['country','total_fer']].sort_values('total_fer', ascending = False)\nax = sns.barplot(x='country', y='total_fer', data= total_fer)\nax.set(xlabel = '', ylabel= 'Fertility Rate')\nplt.xticks(rotation=90)\nplt.show()\n","0e20546b":"plt.figure(figsize = (10,5))\ntotal_fer_top10 = ngo[['country','total_fer']].sort_values('total_fer', ascending = False).head(10)\nax = sns.barplot(x='country', y='total_fer', data= total_fer_top10)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01 , p.get_height() * 1.01))\nax.set(xlabel = '', ylabel= 'Fertility Rate')\nplt.xticks(rotation=90)\nplt.show()","c0094b03":"# Life Expectancy: The average number of years a new born child would live if the current mortality patterns are to remain same\nplt.figure(figsize = (32,5))\nlife_expec = ngo[['country','life_expec']].sort_values('life_expec', ascending = True)\nax = sns.barplot(x='country', y='life_expec', data= life_expec)\nax.set(xlabel = '', ylabel= 'Life Expectancy')\nplt.xticks(rotation=90)\nplt.show()","f5e33a23":"plt.figure(figsize = (10,5))\nlife_expec_bottom10 = ngo[['country','life_expec']].sort_values('life_expec', ascending = True).head(10)\nax = sns.barplot(x='country', y='life_expec', data= life_expec_bottom10)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01 , p.get_height() * 1.01))\nax.set(xlabel = '', ylabel= 'Life Expectancy')\nplt.xticks(rotation=90)\nplt.show()","7dd8f64b":"# Health :Total health spending as %age of Total GDP.\nplt.figure(figsize = (32,5))\nhealth = ngo[['country','health']].sort_values('health', ascending = True)\nax = sns.barplot(x='country', y='health', data= health)\nax.set(xlabel = '', ylabel= 'Health')\nplt.xticks(rotation=90)\nplt.show()","18278abd":"plt.figure(figsize = (10,5))\nhealth_bottom10 = ngo[['country','health']].sort_values('health', ascending = True).head(10)\nax = sns.barplot(x='country', y='health', data= health_bottom10)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01 , p.get_height() * 1.01))\nax.set(xlabel = '', ylabel= 'Health')\nplt.xticks(rotation=90)\nplt.show()","590b164c":"# The GDP per capita : Calculated as the Total GDP divided by the total population.\nplt.figure(figsize = (32,5))\ngdpp = ngo[['country','gdpp']].sort_values('gdpp', ascending = True)\nax = sns.barplot(x='country', y='gdpp', data= gdpp)\nax.set(xlabel = '', ylabel= 'GDP per capita')\nplt.xticks(rotation=90)\nplt.show()","abc2b2ca":"plt.figure(figsize = (10,5))\ngdpp_bottom10 = ngo[['country','gdpp']].sort_values('gdpp', ascending = True).head(10)\nax = sns.barplot(x='country', y='gdpp', data= gdpp_bottom10)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01 , p.get_height() * 1.01))\nax.set(xlabel = '', ylabel= 'GDP per capita')\nplt.xticks(rotation=90)\nplt.show()","7368f963":"# Per capita Income : Net income per person\nplt.figure(figsize = (32,5))\nincome = ngo[['country','income']].sort_values('income', ascending = True)\nax = sns.barplot(x='country', y='income', data=income)\nax.set(xlabel = '', ylabel= 'Per capita Income')\nplt.xticks(rotation=90)\nplt.show()","e42f4587":"plt.figure(figsize = (10,5))\nincome_bottom10 = ngo[['country','income']].sort_values('income', ascending = True).head(10)\nax = sns.barplot(x='country', y='income', data= income_bottom10)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01 , p.get_height() * 1.01))\nax.set(xlabel = '', ylabel= 'Per capita Income')\nplt.xticks(rotation=90)\nplt.show()","b246ed9b":"# Inflation: The measurement of the annual growth rate of the Total GDP\nplt.figure(figsize = (32,5))\ninflation = ngo[['country','inflation']].sort_values('inflation', ascending = False)\nax = sns.barplot(x='country', y='inflation', data= inflation)\nax.set(xlabel = '', ylabel= 'Inflation')\nplt.xticks(rotation=90)\nplt.show()","ca07e358":"plt.figure(figsize = (10,5))\ninflation_top10 = ngo[['country','inflation']].sort_values('inflation', ascending = False).head(10)\nax = sns.barplot(x='country', y='inflation', data= inflation_top10)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01 , p.get_height() * 1.01))\nax.set(xlabel = '', ylabel= 'Inflation')\nplt.xticks(rotation=90)\nplt.show()","9de5a259":"# Exports: Exports of goods and services. Given as %age of the Total GDP\nplt.figure(figsize = (32,5))\nexports = ngo[['country','exports']].sort_values('exports', ascending = True)\nax = sns.barplot(x='country', y='exports', data= exports)\nax.set(xlabel = '', ylabel= 'Exports')\nplt.xticks(rotation=90)\nplt.show()","4d8eb557":"plt.figure(figsize = (10,5))\nexports_bottom10 = ngo[['country','exports']].sort_values('exports', ascending = True).head(10)\nax = sns.barplot(x='country', y='exports', data= exports_bottom10)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01 , p.get_height() * 1.01))\nax.set(xlabel = '', ylabel= 'Exports')\nplt.xticks(rotation=90)\nplt.show()","7e63e7b4":"# Imports: Imports of goods and services. Given as %age of the Total GDP\nplt.figure(figsize = (32,5))\nimports = ngo[['country','imports']].sort_values('imports', ascending = True)\nax = sns.barplot(x='country', y='imports', data= imports)\nax.set(xlabel = '', ylabel= 'Imports')\nplt.xticks(rotation=90)\nplt.show()","29e8fed8":"plt.figure(figsize = (10,5))\nimports_bottom10 = ngo[['country','imports']].sort_values('imports', ascending = True).head(10)\nax = sns.barplot(x='country', y='imports', data= imports_bottom10)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01 , p.get_height() * 1.01))\nax.set(xlabel = '', ylabel= 'Imports')\nplt.xticks(rotation=90)\nplt.show()","f05a29b2":"fig, axs = plt.subplots(3,3,figsize = (18,18))\n\n# Child Mortality Rate : Death of children under 5 years of age per 1000 live births\n\ntop5_child_mort = ngo[['country','child_mort']].sort_values('child_mort', ascending = False).head()\nax = sns.barplot(x='country', y='child_mort', data= top5_child_mort, ax = axs[0,0])\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01 , p.get_height() * 1.01))\nax.set(xlabel = '', ylabel= 'Child Mortality Rate')\n\n# Fertility Rate: The number of children that would be born to each woman if the current age-fertility rates remain the same\ntop5_total_fer = ngo[['country','total_fer']].sort_values('total_fer', ascending = False).head()\nax = sns.barplot(x='country', y='total_fer', data= top5_total_fer, ax = axs[0,1])\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01 , p.get_height() * 1.01))\nax.set(xlabel = '', ylabel= 'Fertility Rate')\n\n# Life Expectancy: The average number of years a new born child would live if the current mortality patterns are to remain same\n\nbottom5_life_expec = ngo[['country','life_expec']].sort_values('life_expec', ascending = True).head()\nax = sns.barplot(x='country', y='life_expec', data= bottom5_life_expec, ax = axs[0,2])\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01 , p.get_height() * 1.01))\nax.set(xlabel = '', ylabel= 'Life Expectancy')\n\n# Health :Total health spending as %age of Total GDP.\n\nbottom5_health = ngo[['country','health']].sort_values('health', ascending = True).head()\nax = sns.barplot(x='country', y='health', data= bottom5_health, ax = axs[1,0])\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01 , p.get_height() * 1.01))\nax.set(xlabel = '', ylabel= 'Health')\n\n# The GDP per capita : Calculated as the Total GDP divided by the total population.\n\nbottom5_gdpp = ngo[['country','gdpp']].sort_values('gdpp', ascending = True).head()\nax = sns.barplot(x='country', y='gdpp', data= bottom5_gdpp, ax = axs[1,1])\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01 , p.get_height() * 1.01))\nax.set(xlabel = '', ylabel= 'GDP per capita')\n\n# Per capita Income : Net income per person\n\nbottom5_income = ngo[['country','income']].sort_values('income', ascending = True).head()\nax = sns.barplot(x='country', y='income', data= bottom5_income, ax = axs[1,2])\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01 , p.get_height() * 1.01))\nax.set(xlabel = '', ylabel= 'Per capita Income')\n\n\n# Inflation: The measurement of the annual growth rate of the Total GDP\n\ntop5_inflation = ngo[['country','inflation']].sort_values('inflation', ascending = False).head()\nax = sns.barplot(x='country', y='inflation', data= top5_inflation, ax = axs[2,0])\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01 , p.get_height() * 1.01))\nax.set(xlabel = '', ylabel= 'Inflation')\n\n\n# Exports: Exports of goods and services. Given as %age of the Total GDP\n\nbottom5_exports = ngo[['country','exports']].sort_values('exports', ascending = True).head()\nax = sns.barplot(x='country', y='exports', data= bottom5_exports, ax = axs[2,1])\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01 , p.get_height() * 1.01))\nax.set(xlabel = '', ylabel= 'Exports')\n\n\n# Imports: Imports of goods and services. Given as %age of the Total GDP\n\nbottom5_imports = ngo[['country','imports']].sort_values('imports', ascending = True).head()\nax = sns.barplot(x='country', y='imports', data= bottom5_imports, ax = axs[2,2])\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01 , p.get_height() * 1.01))\nax.set(xlabel = '', ylabel= 'Imports')\n\nfor ax in fig.axes:\n    plt.sca(ax)\n    plt.xticks(rotation = 90)\n    \nplt.tight_layout()\nplt.savefig('EDA')\nplt.show()","4216f589":"# Let's check the correlation coefficients to see which variables are highly correlated\n\nplt.figure(figsize = (10, 10))\nsns.heatmap(ngo.corr(), annot = True, cmap=\"rainbow\")\nplt.savefig('Correlation')\nplt.show()","1836eac0":"sns.pairplot(ngo,corner=True,diag_kind=\"kde\")\nplt.show()","58539188":"# Converting exports,imports and health spending percentages to absolute values.\n\nngo['exports'] = ngo['exports'] * ngo['gdpp']\/100\nngo['imports'] = ngo['imports'] * ngo['gdpp']\/100\nngo['health'] = ngo['health'] * ngo['gdpp']\/100","a7f596ef":"ngo.head()","cab17319":"# Dropping Country field as final dataframe will only contain data columns\n\nngo_drop = ngo.copy()\ncountry = ngo_drop.pop('country')","03ec600c":"ngo_drop.head()","26ae569f":"# Standarisation technique for scaling\nscaler = StandardScaler()\nngo_scaled = scaler.fit_transform(ngo_drop)","3ab6abe8":"ngo_scaled","1ed5d10d":"pca = PCA(svd_solver='randomized', random_state=50)\n","725b88cb":"# Lets apply PCA on the scaled data\n\npca.fit(ngo_scaled)","15fad037":"# PCA components created \n\npca.components_","662675d3":"# Variance Ratio\n\npca.explained_variance_ratio_","fc4a20c9":"# Variance Ratio bar plot for each PCA components.\nplt.figure(figsize = (10, 5))\nax = plt.bar(range(1,len(pca.explained_variance_ratio_)+1), pca.explained_variance_ratio_)\nplt.xlabel(\"PCA Components\",fontweight = 'bold')\nplt.ylabel(\"Variance Ratio\",fontweight = 'bold')\n\nplt.show()","f3b9fe62":"# Scree plot to visualize the Cumulative variance against the Number of components\n\nfig = plt.figure(figsize = (12,5))\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.vlines(x=3, ymax=1, ymin=0, colors=\"r\", linestyles=\"--\")\nplt.hlines(y=0.93, xmax=8, xmin=0, colors=\"g\", linestyles=\"--\")\nplt.xlabel('Number of PCA components')\nplt.ylabel('Cumulative Explained Variance')\nplt.show()","b75fca42":"# Checking which attributes are well explained by the pca components\n\norg_col = list(ngo.drop(['country'],axis=1).columns)\nattributes_pca = pd.DataFrame({'Attribute':org_col,'PC_1':pca.components_[0],'PC_2':pca.components_[1],'PC_3':pca.components_[2]})","dfde775f":"attributes_pca","923a0631":"# Plotting the above dataframe for better visualization with PC1 and PC2\n\nsns.pairplot(data=attributes_pca, x_vars=[\"PC_1\"], y_vars=[\"PC_2\"], hue = \"Attribute\" ,height=6)\nplt.xlabel(\"Principal Component 1\",fontweight = 'bold')\nplt.ylabel(\"Principal Component 2\",fontweight = 'bold')\n\nfor i,txt in enumerate(attributes_pca.Attribute):\n    plt.annotate(txt, (attributes_pca.PC_1[i],attributes_pca.PC_2[i]))","b07dc7d5":"# Plotting the above dataframe with PC1 and PC3 to understand the components which explains inflation.\n\nsns.pairplot(data=attributes_pca, x_vars=[\"PC_1\"], y_vars=[\"PC_3\"], hue = \"Attribute\" ,height=8)\nplt.xlabel(\"Principal Component 1\",fontweight = 'bold')\nplt.ylabel(\"Principal Component 3\",fontweight = 'bold')\n\nfor i,txt in enumerate(attributes_pca.Attribute):\n    plt.annotate(txt, (attributes_pca.PC_1[i],attributes_pca.PC_3[i]))","0a7176f4":"# Building the dataframe using Incremental PCA for better efficiency.\n\ninc_pca = IncrementalPCA(n_components=3)","3c2a0edc":"# Fitting the scaled df on incremental pca\n\ndf_inc_pca = inc_pca.fit_transform(ngo_scaled)\ndf_inc_pca","9a8de5ca":"# Creating new dataframe with Principal components\n\ndf_pca = pd.DataFrame(df_inc_pca, columns=[\"PC_1\", \"PC_2\",\"PC_3\"])\ndf_pca_final = pd.concat([country, df_pca], axis=1)\ndf_pca_final.head()","8b857c25":"# Plotting Heatmap to check is there still dependency in the dataset.\n\nplt.figure(figsize = (5,5))        \nax = sns.heatmap(df_pca_final.corr(),annot = True,cmap='winter')","80b8c1eb":"# Scatter Plot to visualize the spread of data across PCA components\n\nplt.figure(figsize=(20, 5))\nplt.subplot(1,3,1)\nsns.scatterplot(data=df_pca_final, x='PC_1', y='PC_2')\nplt.subplot(1,3,2)\nsns.scatterplot(data=df_pca_final, x='PC_1', y='PC_3')\nplt.subplot(1,3,3)\nsns.scatterplot(data=df_pca_final, x='PC_3', y='PC_2')\nplt.show()","5718701c":"outliers = ['PC_1','PC_2','PC_3']\nplt.rcParams['figure.figsize'] = [10,5]\nsns.violinplot(data = df_pca_final[outliers])\nplt.title(\"Outliers Variable Distribution\", fontsize = 14, fontweight = 'bold')\nplt.ylabel(\"Range\", fontweight = 'bold')\nplt.xlabel(\"PC Components\", fontweight = 'bold')\nplt.show()","b9edc27d":"# Statstical Outlier treatment for PC_1\n\nQ1 = df_pca_final.PC_1.quantile(0.05)\nQ3 = df_pca_final.PC_1.quantile(0.95)\nIQR = Q3 - Q1\ndf_pca_final = df_pca_final[(df_pca_final.PC_1 >= Q1) & (df_pca_final.PC_1 <= Q3)]","066cf28f":"# Statstical Outlier treatment for PC_2\n\nQ1 = df_pca_final.PC_2.quantile(0.05)\nQ3 = df_pca_final.PC_2.quantile(0.95)\nIQR = Q3 - Q1\ndf_pca_final = df_pca_final[(df_pca_final.PC_2 >= Q1) & (df_pca_final.PC_2 <= Q3)]","618f17a3":"# Statstical Outlier treatment for PC_3\n\nQ1 = df_pca_final.PC_3.quantile(0.05)\nQ3 = df_pca_final.PC_3.quantile(0.95)\nIQR = Q3 - Q1\ndf_pca_final = df_pca_final[(df_pca_final.PC_3 >= Q1) & (df_pca_final.PC_3 <= Q3)]","7c402331":"# Plot after Outlier removal \n\noutliers = ['PC_1','PC_2','PC_3']\nplt.rcParams['figure.figsize'] = [20,5]\nsns.violinplot(data = df_pca_final[outliers], orient=\"v\", palette=\"Set2\" )\nplt.title(\"Outliers Variable Distribution\", fontsize = 14, fontweight = 'bold')\nplt.ylabel(\"Range\", fontweight = 'bold')\nplt.xlabel(\"PC Components\", fontweight = 'bold')\nplt.show()","7ccd37d6":"# Reindexing the df after outlier removal\n\ndf_pca_final = df_pca_final.reset_index(drop=True)\ndf_pca_final_data = df_pca_final.drop(['country'],axis=1)\ndf_pca_final.head()","3d45b9b5":"# Calculating Hopkins score to know whether the data is good for clustering or not.\n\ndef hopkins(X):\n    d = X.shape[1]\n    n = len(X)\n    m = int(0.1 * n) \n    nbrs = NearestNeighbors(n_neighbors=1).fit(X.values)\n \n    rand_X = sample(range(0, n, 1), m)\n \n    ujd = []\n    wjd = []\n    for j in range(0, m):\n        u_dist, _ = nbrs.kneighbors(uniform(np.amin(X,axis=0),np.amax(X,axis=0),d).reshape(1, -1), 2, return_distance=True)\n        ujd.append(u_dist[0][1])\n        w_dist, _ = nbrs.kneighbors(X.iloc[rand_X[j]].values.reshape(1, -1), 2, return_distance=True)\n        wjd.append(w_dist[0][1])\n \n    HS = sum(ujd) \/ (sum(ujd) + sum(wjd))\n    if isnan(HS):\n        print(ujd, wjd)\n        HS = 0\n \n    return HS\n","2df7bd22":"# Hopkins score\nHopkins_score=round(hopkins(df_pca_final_data),2)","c059c550":"print(\"{} is a good Hopkins score for Clustering.\".format(Hopkins_score))","53116748":"# Elbow curve method to find the ideal number of clusters.\nssd = []\nfor num_clusters in list(range(1,8)):\n    model_clus = KMeans(n_clusters = num_clusters, max_iter=150,random_state= 50)\n    model_clus.fit(df_pca_final_data)\n    ssd.append(model_clus.inertia_)\n\nplt.plot(ssd);","4da339d5":"# Silhouette score analysis to find the ideal number of clusters for K-means clustering\n\nrange_n_clusters = [2, 3, 4, 5, 6, 7, 8]\n\nfor num_clusters in range_n_clusters:\n    \n    # intialise kmeans\n    kmeans = KMeans(n_clusters=num_clusters, max_iter=50,random_state= 100)\n    kmeans.fit(df_pca_final_data)\n    \n    cluster_labels = kmeans.labels_\n    \n    # silhouette score\n    silhouette_avg = silhouette_score(df_pca_final_data, cluster_labels)\n    print(\"For n_clusters={0}, the silhouette score is {1}\".format(num_clusters, silhouette_avg))","730e9ed2":"#K-means with k=4 clusters\n\ncluster4 = KMeans(n_clusters=4, max_iter=150, random_state= 50)\ncluster4.fit(df_pca_final_data)","48915eca":"# Cluster labels\n\ncluster4.labels_","41046b88":"# Assign the label\n\ndf_pca_final['Cluster_Id4'] = cluster4.labels_\ndf_pca_final.head()","a768d49c":"# Number of countries in each cluster\n\ndf_pca_final['Cluster_Id4'].value_counts()","161ea03d":"# Scatter plot on Principal components to visualize the spread of the data\n\nfig, axes = plt.subplots(1,2, figsize=(15,5))\n\nsns.scatterplot(x='PC_1',y='PC_2',hue='Cluster_Id4',legend='full',palette=\"Set1\",data=df_pca_final,ax=axes[0])\nsns.scatterplot(x='PC_1',y='PC_3',hue='Cluster_Id4',legend='full',palette=\"Set2\",data=df_pca_final,ax=axes[1])\nplt.show()","fc3623e8":"# Lets drop the Cluster Id created with 4 clusters and proceed with 5 clusters.\n\ndf_pca_final = df_pca_final.drop('Cluster_Id4',axis=1)","4f166f9b":"#K-means with k=5 clusters\n\ncluster5 = KMeans(n_clusters=5, max_iter=120,random_state=70)\ncluster5.fit(df_pca_final_data)","e43d90fe":"# Cluster labels\n\ncluster5.labels_","d32b6961":"# assign the label\n\ndf_pca_final['Cluster_Id'] = cluster5.labels_\ndf_pca_final.head()","1541576e":"# Number of countries in each cluster\n\ndf_pca_final['Cluster_Id'].value_counts()","85afd342":"# Scatter plot on Principal components to visualize the spread of the data\nfig, axes = plt.subplots(1,2, figsize=(15,5))\n\nsns.scatterplot(x='PC_1',y='PC_2',hue='Cluster_Id',legend='full',palette=\"Set2\",data=df_pca_final,ax=axes[0])\nsns.scatterplot(x='PC_1',y='PC_3',hue='Cluster_Id',legend='full',palette=\"Set3\",data=df_pca_final,ax=axes[1])\nplt.show()","5198d97e":"# Merging the df with PCA with original df\n\ndf_merge = pd.merge(ngo,df_pca_final,on='country')\ndf_merge_col = df_merge[['country','child_mort','exports','imports','health','income','inflation','life_expec','total_fer','gdpp','Cluster_Id']]\n\n# Creating df with mean values\ncluster_child = pd.DataFrame(df_merge_col.groupby([\"Cluster_Id\"]).child_mort.mean())\ncluster_export = pd.DataFrame(df_merge_col.groupby([\"Cluster_Id\"]).exports.mean())\ncluster_import = pd.DataFrame(df_merge_col.groupby([\"Cluster_Id\"]).imports.mean())\ncluster_health = pd.DataFrame(df_merge_col.groupby([\"Cluster_Id\"]).health.mean())\ncluster_income = pd.DataFrame(df_merge_col.groupby([\"Cluster_Id\"]).income.mean())\ncluster_inflation = pd.DataFrame(df_merge_col.groupby([\"Cluster_Id\"]).inflation.mean())         \ncluster_lifeexpec = pd.DataFrame(df_merge_col.groupby([\"Cluster_Id\"]).life_expec.mean())\ncluster_totalfer = pd.DataFrame(df_merge_col.groupby([\"Cluster_Id\"]).total_fer.mean())\ncluster_gdpp = pd.DataFrame(df_merge_col.groupby([\"Cluster_Id\"]).gdpp.mean())\n\ndf_concat = pd.concat([pd.Series([0,1,2,3,4]),cluster_child,cluster_export,cluster_import,cluster_health,cluster_income\n                       ,cluster_inflation,cluster_lifeexpec,cluster_totalfer,cluster_gdpp], axis=1)\ndf_concat.columns = [\"Cluster_Id\", \"Child_Mortality\", \"Exports\", \"Imports\",\"Health_Spending\",\"Income\",\"Inflation\",\"Life_Expectancy\",\"Total_Fertility\",\"GDPpcapita\"]\ndf_concat.head()","cb110c68":"df_merge_col.head()","b6af7be6":"# Scatter plot on Original attributes to visualize the spread of the data\n\nplt.figure(figsize = (20,30))\nplt.subplot(3,1,1)\nsns.scatterplot(x = 'income', y = 'child_mort',hue='Cluster_Id',data = df_merge_col,legend='full',palette=\"ocean\")\nplt.subplot(3,1,2)\nsns.scatterplot(x = 'gdpp', y = 'income',hue='Cluster_Id', data = df_merge_col,legend='full',palette=\"rainbow_r\")\nplt.subplot(3,1,3)\nsns.scatterplot(x = 'child_mort', y = 'gdpp',hue='Cluster_Id', data=df_merge_col,legend='full',palette=\"rainbow\")\nplt.show()","a2524985":" #Violin plot on Original attributes to visualize the spread of the data\n\nfig, axes = plt.subplots(2,2, figsize=(15,12))\n\nsns.violinplot(x = 'Cluster_Id', y = 'child_mort', data = df_merge_col,ax=axes[0][0])\nsns.violinplot(x = 'Cluster_Id', y = 'income', data = df_merge_col,ax=axes[0][1])\nsns.violinplot(x = 'Cluster_Id', y = 'inflation', data=df_merge_col,ax=axes[1][0])\nsns.violinplot(x = 'Cluster_Id', y = 'gdpp', data=df_merge_col,ax=axes[1][1])\nplt.show()","e79ace75":"# Violin plot to visualise the mean value of few original attributes.\n\nfig, axes = plt.subplots(2,2, figsize=(15,12))\n\nsns.violinplot(x = 'Cluster_Id', y = 'Child_Mortality', data = df_concat,ax=axes[0][0])\nsns.violinplot(x = 'Cluster_Id', y = 'Income', data = df_concat,ax=axes[0][1])\nsns.violinplot(x = 'Cluster_Id', y = 'Inflation', data=df_concat,ax=axes[1][0])\nsns.violinplot(x = 'Cluster_Id', y = 'GDPpcapita', data=df_concat,ax=axes[1][1])\nplt.show()","17a28df7":"# List of countries in Cluster 0\n\ndf_merge_col[df_merge_col['Cluster_Id']==0]","29ec6efb":"# List of countries in Cluster 4\n\ndf_merge_col[df_merge_col['Cluster_Id']==4]","a4bc7e82":"df_clus0 = df_merge_col[df_merge_col['Cluster_Id'] ==0]\ndf_clus0.head()","a706de1f":"df_clus4 = df_merge_col[df_merge_col['Cluster_Id'] ==4]\ndf_clus4.head()","63950b89":"# List of countries which need help\n\ndf_append= df_clus0.append(df_clus4)\ndf_append.head()","1373e326":"df_append.describe()","3f26c61f":"# Based on final clusters information we are going to deduce the final list.\n# We observed that mean child mortality is 54.67 for the selected clusters and hence \n# let's take all the countries with more than this child mortality .\n\ndf_final_list = ngo[ngo['child_mort']>55]\ndf_final_list.shape","fb07656b":"df_final_list.head()","d4a182a8":"# Let's check the demographic of the resultant data again\n\ndf_final_list.describe()\n","2403d09a":"# We observed that mean income is 3518.36 for the selected clusters and hence \n# let's take all the countries with less than this income .\n\ndf_final_list1 = df_final_list[df_final_list['income']<=3519]\ndf_final_list1.shape","f75184ea":"df_final_list1.head()","67be90c2":"df_final_list1.describe()","4982ff08":"# We observed that mean gdpp is 831.2 for the selected clusters and hence \n# let's take all the countries with less than this gdpp .\n\ndf_final_list2 = df_final_list1[df_final_list1['gdpp']<=832]\ndf_final_list2.shape","b3bc01e4":"df_final_list2.head()","addaf53d":"df_final_list2.sort_values(by = ['gdpp','income','child_mort'], ascending = [True, True, False],inplace=True)\ndf_final_list2.head()","5a78edaa":"df_final_list2['country']","e0b4e664":"# BarPlot for Child Mortality of countries which are in need of aid\n\ndf_list_cm = pd.DataFrame(df_final_list2.groupby(['country'])['child_mort'].mean().sort_values(ascending = False))\ndf_list_cm.plot.bar()\nplt.title('Country and Child Mortality')\nplt.xlabel(\"Country\",fontweight = 'bold')\nplt.ylabel(\"Child Mortality\", fontsize = 12, fontweight = 'bold')\nplt.show()","bebb5dc9":"# BarPlot for Per Capita Income of countries which are in need of aid\n\ndf_list_in = pd.DataFrame(df_final_list2.groupby(['country'])['income'].mean().sort_values(ascending = True))\ndf_list_in.plot.bar()\nplt.title('Country and Per Capita Income')\nplt.xlabel(\"Country\",fontweight = 'bold')\nplt.ylabel(\"Per Capita Income\", fontsize = 12, fontweight = 'bold')\nplt.show()","9db987ce":"# BarPlot for GDP of countries which are in need of aid\n\ndf_list_gdp = pd.DataFrame(df_final_list2.groupby(['country'])['gdpp'].mean().sort_values(ascending = True))\ndf_list_gdp.plot.bar()\nplt.title('Country and GDP per capita')\nplt.xlabel(\"Country\",fontweight = 'bold')\nplt.ylabel(\"GDP per capita\", fontsize = 12, fontweight = 'bold')\nplt.show()","1f4a9ad0":"# Final countries list\ndf_final_list2.reset_index(drop=True).country[:5]","6c7a1f8e":"## K- means Clustering","c293c459":"Deducing imports,exports and health spending from percentage values to actual values of their GDP per capita .Because the percentage values don't give a clear picture of that country. For example few coutries Austria and Belarus have almost same exports % but their gdpp has a huge gap which doesn't give an accurate idea of which country is more developed than the other.","1bbd469d":"## Duplicate Check","4f3abd08":"We are able to see how Child Mortality Rate is distributed across the all countries. Focus on the objective of the task.","617dcb7b":"# Exploratory Data Analytics","e047f3a0":"## Silhouette Analysis","8fce106f":"Top 10 Countries having lowest health spending are mix bag of countries where per Capita income is very high or involved in unrest activities.","40cfaadc":"It is evident from the above Scree plot that more than 90% variance is explained by the first 3 principal components. Hence, we will use these components only going forward for Clustering process.","7ce7184c":"We are able to see how GDP per capita is distributed across the all countries. Focus on the objective of the task.","ac7f8a60":"There are no missing \/ Null values either in columns or rows","0c81aad1":"Top 10 Countries having highest Inflation are from countries where there is social \/ political unrest in progress","04231e8d":"### Null Percentage: Columns","73d7f844":"## Data Cleaning","0a25dd6e":"We have used PCA above to reduce the variables involved and then done the clustering of countries based on those Principal components and then later we identified few factors like child mortality, income etc which plays a vital role in deciding the development status of the country and builded clusters of countries based on that. Based on those clusters we have identified the below list of countries which are in dire need of aid. The list of countries are subject to change as it is based on the few factors like Number of components chosen, Number of Clusters chosen, Clustering method used etc.which we have used to build the model.","09571042":"####  We will have a look on the lowest 5 countries for each factor. ","994695c4":"## Data Preparation","85f5ee69":"Since 90% variance is explained by 3 principal components, lets build the dataframe using those 3 components only.","9bfb93e8":"## PCA Application","d67a772f":"We are able to see how Exports is distributed across the all countries. Focus on the objective of the task.","325c54eb":"We are able to see how Total health spending is distributed across the all countries. Focus on the objective of the task.","c7e2851c":"It seems there are good number of countries in each clusters.","552b4caa":"- Child Mortality is highest for Cluster 0 and Cluster 4.These clusters need some aid.\n- Income and Gdpp are measures of development. Higher the per capita income and gdpp better is the country's development. Income per capita and gdpp seems lowest for countries in clusters 0 and 4. Hence, these countries need some help.","2c7209a8":"We are able to see how Per capita Income is distributed across the all countries. Focus on the objective of the task.","3d09915e":"# Introduction ","473ffc63":"# Objectives","1ddb05c7":"We need to choose the countries that are in the direst need of aid. Hence, we need to identify those countries with using some socio-economic and health factors that determine the overall development of the country.\n","d950917d":"Here also we got the same issue as with 4 clusters but we got a new segment, so lets proceed with K means using 5 clusters.","5e428e75":"The mean values suggests the same story as above i.e.\n- Child Mortality is highest for Cluster 0 and Cluster 4.These clusters need some aid.\n- Income and Gdpp are measures of development. Higher the per capita income and gdpp better is the country's development. Income per capita and gdpp seems lowest for countries in clusters 0 and 4. Hence, these countries need some help.","8d418312":"# Conclusion","525e3b43":"Top 10 Countries having lowest Life Expectancy are places where healthcare system is not available or efficient.","277c0a33":"Top 10 Countries having lowest GDP per capita are from East Africa","c81e8914":"**HELP International** is an international humanitarian NGO that is committed to fighting poverty and providing the people of backward countries with basic amenities and relief during the time of disasters and natural calamities. It runs a lot of operational projects from time to time along with advocacy drives to raise awareness as well as for funding purposes.\n\n \n\nAfter the recent funding programmes, they have been able to raise around $ 10 million. Now the CEO of the NGO needs to decide how to use this money strategically and effectively. The significant issues that come while making this decision are mostly related to choosing the countries that are in the direst need of aid. \n\n\n\nAnd this is where I come in as a data analyst. My job is to categorise the countries using some socio-economic and health factors that determine the overall development of the country. Then I  need to suggest the countries which the CEO needs to focus on the most. ","b1be8358":"We are doing PCA because we want to remove the redundancies in the data and find the most important directions where the data was aligned. A somewhat similar heuristic is also used by the United Nations to calculate the Human Development Index(HDI) to rank countries on the basis of their development.\n\nPrincipal component analysis (PCA) is one of the most commonly used dimensionality reduction techniques in the industry. By converting large data sets into smaller ones containing fewer variables, it helps in improving model performance, visualising complex data sets, and in many more areas.\n\nLet's use PCA for dimensionality reduction as from the heatmap it is evident that correlation exists between the attributes.","b2be4abe":"Resources are limited, so we selected only 5 countries for Supporting help who have high child mortality, low income & low GDP","98808a27":"Top 10 Countries having highest Child Mortality Rate are present in **Africa** having poor healthcare facilities.","d8178280":"silhouette score=(p\u2212q)\/max(p,q)\n \n**p**  is the mean distance to the points in the nearest cluster that the data point is not a part of\n\n**q**  is the mean intra-cluster distance to all the points in its own cluster.\n\nThe value of the silhouette score range lies between -1 to 1.\n\nA score closer to 1 indicates that the data point is very similar to other data points in the cluster,\n\nA score closer to -1 indicates that the data point is not similar to the data points in its cluster.","3acefa88":"We are able to see how Inflation is distributed across the all countries. Focus on the objective of the task.","dbf4e98f":"My main task is to cluster the countries by the factors mentioned above and then present the solution. The following approach is suggested :\n\n- Start off with the necessary data inspection and EDA tasks suitable for this dataset - data cleaning, univariate analysis, bivariate analysis etc.\n\n\n\n\n- **Outlier Analysis:** We must perform the Outlier Analysis on the dataset. However, We do have the flexibility of not removing the outliers if it suits the business needs or a lot of countries are getting removed. Hence, all we need to do is find the outliers in the dataset, and then choose whether to keep them or remove them depending on the results We get.\n\n\n- Try K-means on this dataset to create the clusters. \n\n\n- Analyse the clusters and identify the ones which are in dire need of aid. We can analyse the clusters by comparing how these three variables - [**gdpp, child_mort and income**] vary for each cluster of countries to recognise and differentiate the clusters of developed countries from the clusters of under-developed countries.\n\n\n- Also, We need to perform visualisations on the clusters that have been formed.  We can do this by choosing any two of the three variables mentioned above on the X-Y axes and plotting a scatter plot of all the countries and differentiating the clusters. Make sure We create visualisations for all the three pairs. We can also choose other types of plots like boxplots, etc. \n\n\n- K-means may give different results because of previous analysis (whether We chose to keep or remove the outliers, how many clusters We chose,  etc.) Hence, there might be some subjectivity in the final number of countries that We think should be reported back to the CEO since they depend upon the preceding analysis as well. Here, make sure that We report back at least 5 countries which are in direst need of aid from the analysis work that we perform.","2255c4f2":"# Data Preparation","f190282e":"# Let's check the demographic of the resultant data again\n\n","6ca3c8f1":"## Data Dictionary","141c27ea":"The Hopkins statistic (introduced by Brian Hopkins and John Gordon Skellam) is a way of measuring the cluster tendency of a data set.It acts as a statistical hypothesis test where the null hypothesis is that the data is generated by a Poisson point process and are thus uniformly randomly distributed. A value close to 1 tends to indicate the data is highly clustered, random data will tend to result in values around 0.5, and uniformly distributed data will tend to result in values close to 0.\n- If the value is between {0.01, ...,0.3}, the data is regularly spaced.\n\n- If the value is around 0.5, it is random.\n\n- If the value is between {0.7, ..., 0.99}, it has a high tendency to cluster.","ee45b450":"Visualization each columns using violinplot","047326f3":"# Finding the Optimal Number of Clusters","7d5223f3":"We have visualized the data on the principal components and saw some good clusters were formed but some were not so good hence let's now visualize the data on the original attributes.","553ab799":"- child_mortality and life_expentency are highly correlated with correlation of -0.89\n- child_mortality and total_fertility are highly correlated with correlation of 0.85\n- imports and exports are highly correlated with correlation of 0.99\n- life_expentency and total_fertility are highly correlated with correlation of -0.76","b9e3346d":"## Univariate Analysis","0baf6367":"We are able to see how Life Expectancy is distributed across the all countries. Focus on the objective of the task.","7ac3f973":"The datasets containing those socio-economic factors and the corresponding data dictionary are provided.","a811343b":"- inflation is well explained by PC3","c4bcfe30":"We have removed few countries during outlier treatment but we might have dropped some countries which might be in need of help. Let's iterate our final list based on the information from the clusters which were in need of aid.ie, **Cluster 0 and Cluster 4**","7beb4903":"Looking at the above elbow curve it looks good to proceed with either 4 or 5 clusters.","76c5acb0":"A fundamental step for any unsupervised algorithm is to determine the optimal number of clusters into which the data may be clustered. The Elbow Method is one of the most popular methods to determine this optimal value of k.","0a8a1923":"From the business understanding we have learnt that **Child_Mortality, Income, Gdpp** are some important factors which decides the development of any country. We have also cross checked with Principal components and found that these variables have good score in PCA. Hence, we will proceed with analyzing these 3 components to build some meaningful clusters.","9c55bcbe":"## Rescaling the Features","905a21ab":"Top 10 Countries having lowest Per capita Income are from East Africa","009fa39e":"### Null Percentage: Rows","39a48978":"### Elbow Curve to get the right number of Clusters","af2a9cce":"## Final List of countries which are in need of the aid based on socio-economic factors.","45ac6967":"### Null Count: Rows","05a09269":"As we can see from above heatmap that the correlation among the attributes is almost 0, we can proceed with this dataframe.","cd2e8814":"## Outlier Analysis","37e4a659":"# Model Building","cd2d916b":"The shape after running the drop duplicate command is same as the original dataframe.\n\nHence we can conclude that there were zero duplicate values in the dataset.","e2e1322e":"### Null Count: Columns","39daad90":"# Final Analysis","416608f1":"# Data Collected \/ Received","3e715e16":"K-means clustering is one of the simplest and popular unsupervised machine learning algorithms.\n\nThe algorithm works as follows:\n\nFirst we initialize k points, called means, randomly. We categorize each item to its closest mean and we update the mean\u2019s coordinates, which are the averages of the items categorized in that mean so far. We repeat the process for a given number of iterations and at the end, we have our clusters.","971fda5d":"Most software packages use SVD to compute the principal components and assume that the data is scaled and centred, so it is important to do standardisation\/normalisation. There are two common ways of rescaling:\n\n- Min-Max scaling\n- Standardisation (mean-0, sigma-1)\n\n\nHere, we will use Standardisation Scaling.","6234ff2d":"### Derived Metrices","9a25c4e0":"- With first component variance explained is almost 60%.\n- For second component variance explained is almost 20%.","adcce6b5":"5 reasons why we used a violin graph over boxplot\n- Violin graph is like box plot, but better\n- Violin graph is like density plot, but much useful\n- Violin graph is visually intuitive and attractive\n- Violin graph is non-parametric\n- There are many ways to use violin graphs","d6b488c7":"## Data Loading","8e3cbc07":"We are able to see how Fertility Rate is distributed across the all countries.","412034f1":"- life expectency, income, gdpp and health are very well explained by PC1.\n- imports and exports are well explained by both the components PC1 and PC2.\n- child mortality and total fertility are well explained by PC2.\n- inflation is neither explained by PC1 nor with PC2","18678085":"In plot 1, it seems lot of intra-distance between the cluster elements, which is not a good sign.","de5f0866":"Top 10 Countries having lowest Imports are from mostly from Developed nations who are **Atma-Nirbhar** aka Self-Reliant, who manufacture locally to support own market or the underdeveloped \/ developing countries who are poor to afford imports due to political \/ economical turmoil","0243cbe9":"We got Cluster 0 and Cluster 4 which are in need of aid.","d7ffeec8":"## Data Inspection","7fc88433":"We are able to see how Imports is distributed across the all countries. Focus on the objective of the task.","643e1876":"Top 10 Countries having highest Fertility Rate are places where people are poorest in all.","fbe19dc0":"It seems there are good number of countries in each clusters.","b380f695":"## Hopkins Statistics Test","28dec90b":"Top 10 Countries having lowest Exports are from mostly from underdeveloped \/ developing countries "}}