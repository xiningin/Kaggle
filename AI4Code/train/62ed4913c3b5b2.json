{"cell_type":{"1f701248":"code","fd5881ec":"code","b5800994":"code","b2894b9b":"code","6b0b9e71":"code","9a201ee5":"code","541606b1":"code","051dec33":"code","81b9c060":"code","089f7e5a":"code","3961f4c9":"code","eb021a35":"code","081873b0":"code","5cfd8923":"code","142dbc0c":"markdown","5700ec4f":"markdown","b1e5bd77":"markdown"},"source":{"1f701248":"!pip install kneed","fd5881ec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nimport time\n\nimport datetime as datetime\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\n\nfrom kneed import KneeLocator\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\nimport plotly\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport cufflinks as cf\ncf.set_config_file(offline=True)","b5800994":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b2894b9b":"path_file = r'\/kaggle\/input\/smart-meter-dataset\/'","6b0b9e71":"def MinMaxScaler(data):\n    return (data-np.min(data))\/(np.max(data)-np.min(data))\n\ndef Kmeans_clustering(df, clusterNum, max_iter, n_jobs):\n    scaler = StandardScaler()\n    scaler.fit(df)\n    df_std = pd.DataFrame(data=scaler.transform(df), columns=df.columns, index=df.index)\n    km_model = KMeans(n_clusters=clusterNum, max_iter=max_iter, random_state=666)\n    km_model = km_model.fit(df_std)\n    clusterdf= pd.DataFrame(data=km_model.labels_, columns=['ClusterNo'])\n    clusterdf.index = df.index\n    return clusterdf\n\ndef Kmeans_bestClusterNum(df, range_min, range_max, max_iter, n_jobs):\n    silhouette_avgs = []\n    sum_of_squared_distances = []\n    \n    ks = range(range_min,range_max+1)\n    for k in ks:\n        kmeans_fit = KMeans(n_clusters = k, max_iter=max_iter, random_state=666).fit(df)\n        cluster_labels = kmeans_fit.labels_\n        sum_of_squared_distances.append(kmeans_fit.inertia_)\n        \n    kn = KneeLocator(list(ks), sum_of_squared_distances, S=1.0, curve='convex', direction='decreasing')  \n    plt.xlabel('k')\n    plt.ylabel('sum_of_squared_distances')\n    plt.title('The Elbow Method showing the optimal k')\n    plt.plot(ks, sum_of_squared_distances, 'bx-')\n    plt.vlines(kn.knee, plt.ylim()[0], plt.ylim()[1], linestyles='dashed')\n    plt.show()\n    print('Optimal clustering number:'+str(kn.knee))\n    print('----------------------------')    \n    \n    return kn.knee","9a201ee5":"df_metadata_loop = pd.read_csv(os.path.join(path_file, 'metadata_loop.csv'))\ndf_metadata_loop","541606b1":"df_metadata_uid = pd.read_csv(os.path.join(path_file, 'metadata_uid.csv'))\ndf_metadata_uid","051dec33":"df_powerMeter_pivot_output = pd.read_csv(os.path.join(path_file, 'powerMeter.csv'))\ndf_powerMeter_pivot_output['\u65e5\u671f\u6642\u9593'] = pd.to_datetime(df_powerMeter_pivot_output['\u65e5\u671f\u6642\u9593'])\ndf_powerMeter_pivot_output = df_powerMeter_pivot_output.set_index('\u65e5\u671f\u6642\u9593')\ndf_powerMeter_pivot_output","81b9c060":"# Leave meters with building type of '\u884c\u653f\u55ae\u4f4d'\nbuilding_type = '\u884c\u653f\u55ae\u4f4d'\n\ndf_metadata = df_metadata_loop.merge(df_metadata_uid, on='uid')\nlist_powerMeter = df_metadata[df_metadata['buildType1C']==building_type]['\u8ff4\u8def\u7de8\u865f'].to_list()\ndf_powerMeter_pivot_output = df_powerMeter_pivot_output.loc[:, df_powerMeter_pivot_output.columns.str.contains('|'.join(list_powerMeter))]\ndf_powerMeter_pivot_output.columns","089f7e5a":"# Normalize the energy data and take average of all meters' trends\ndf_powerMeter_pivot_output = (df_powerMeter_pivot_output-df_powerMeter_pivot_output.mean())\/df_powerMeter_pivot_output.std()\ndf_powerMeter_pivot_output[building_type + '_mean'] = df_powerMeter_pivot_output.mean(axis=1)\n\nmeter_name = building_type + '_mean'\n\n# Reshape the dataframe\ndf_temp = df_powerMeter_pivot_output.loc[:, meter_name].reset_index().copy()\ndf_temp['date'] = df_temp['\u65e5\u671f\u6642\u9593'].dt.date    \ndf_temp['hour'] = df_temp['\u65e5\u671f\u6642\u9593'].dt.hour\ndf_temp_pivot = df_temp.pivot_table(index='hour', columns='date')\ndf_temp_pivot","3961f4c9":"df_temp_pivot.plot(figsize=(15,5),color='black',alpha=0.1,legend=False)","eb021a35":"# Do clustering for daily load profiles!\n\ndf_PM_temp = df_temp_pivot.copy()\ndf_PM_temp = df_PM_temp.T\n\ntry:\n    bestClusterNum_dept = Kmeans_bestClusterNum(df=df_PM_temp.fillna(0), range_min=2, range_max=20, max_iter=10000, n_jobs=-1)\nexcept:\n    try:\n        bestClusterNum_dept = Kmeans_bestClusterNum(df=df_PM_temp.fillna(0), range_min=2, range_max=15, max_iter=10000, n_jobs=-1)    \n    except:\n        try:\n            bestClusterNum_dept = Kmeans_bestClusterNum(df=df_PM_temp.fillna(0), range_min=2, range_max=10, max_iter=10000, n_jobs=-1)    \n        except:\n            bestClusterNum_dept = 3\n\ntry:\n    df_PM_temp['ClusterNo'] = Kmeans_clustering(df=df_PM_temp.fillna(0), clusterNum=bestClusterNum_dept, max_iter=100000, n_jobs=-1)\nexcept:\n    df_PM_temp['ClusterNo'] = Kmeans_clustering(df=df_PM_temp.fillna(0), clusterNum=bestClusterNum_dept, max_iter=100000, n_jobs=-1)\n\nfor ClusterNo in df_PM_temp['ClusterNo'].sort_values().unique():\n    df_plot = df_PM_temp[df_PM_temp['ClusterNo']==ClusterNo].T.drop('ClusterNo')\n    print('ClusterNo: ' + str(ClusterNo))    \n    print('Amount of meters: ' + str(len(df_plot.T)))\n    df_plot.plot(figsize=(15,5),color='black',alpha=0.1,legend=False)\n    plt.show()\n    print('---------------------------------------------------------------------------------------------------')","081873b0":"plt.figure(figsize=(15,6))\nax = sns.lineplot(x=\"hour\", y=\"value\", hue=\"ClusterNo\",\n                  data=df_PM_temp.melt(id_vars='ClusterNo'))","5cfd8923":"df_temp = df_temp.merge(df_PM_temp.reset_index()[['date', 'ClusterNo']], on='date')\ndf_temp = df_temp.pivot_table(columns='ClusterNo', index='\u65e5\u671f\u6642\u9593', values=meter_name)\ndf_temp.iplot()","142dbc0c":"## Process dataset (Target: \u884c\u653f\u55ae\u4f4d)","5700ec4f":"## Clustering & visualizations","b1e5bd77":"## Load dataset"}}