{"cell_type":{"5f277ac3":"code","b9ba9cf8":"code","92743c8d":"code","d53317ee":"code","cf1f6176":"code","62a1d257":"code","d36a0cb8":"code","b953c3fd":"code","a121a60e":"code","32c4345c":"code","8fa568c8":"code","8ef6c585":"code","b004469b":"code","41287a23":"code","223974ae":"code","091faac0":"code","dcbd2c30":"code","8868d9af":"code","4804e66d":"code","7d4db0f3":"code","53db267e":"code","5c0bcf43":"code","e99734fb":"code","5b41ff14":"code","8534931f":"code","5353fd1a":"code","c497a14b":"code","8fee60bb":"code","6ae7349c":"code","738090af":"code","df848da0":"code","6894674c":"code","0df792ea":"code","adc0be72":"code","84f9b9e1":"code","8bb72ea3":"code","ff8acffb":"code","d5f36027":"code","10b0699c":"code","02f74309":"code","1e6f56c1":"code","c821abcb":"code","1253eb5b":"code","898517bd":"markdown","71605357":"markdown","0e2e67ac":"markdown","8a5e2880":"markdown","1e533ca3":"markdown","1013a3e4":"markdown","974da78c":"markdown","6a64f62b":"markdown","bfbfcebe":"markdown","b44a2e1d":"markdown","b485b240":"markdown","1565c375":"markdown","81a9742a":"markdown","782786d3":"markdown","488b59cb":"markdown","c7e3e06b":"markdown","8068f561":"markdown","a0c5235e":"markdown","1f98f5be":"markdown","cd3ed812":"markdown","99a77acd":"markdown","472094d8":"markdown","abba6df3":"markdown","0f5d581d":"markdown","f023d342":"markdown","21427e39":"markdown","8e49cc18":"markdown","76f990c1":"markdown"},"source":{"5f277ac3":"# import packages\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\n# for printing training progress\nfrom IPython.display import clear_output","b9ba9cf8":"# initialize the seed and define batch size: \ntorch.manual_seed(2326)\nnp.random.seed(2326)\n\nBATCH_SIZE = 32\nEPOCHS = 200","92743c8d":"# check if GPU is available\ncuda = torch.cuda.is_available()\nprint(\"GPU available:\", cuda)","d53317ee":"# code imported and modified from pytorch tutorial\n# load data into trainset and testset\n\ntransform = transforms.ToTensor()\n\ntrainset = torchvision.datasets.CIFAR10(root='.\/data', train=True,\n                                        download=True, transform=transform)\n\ntestset = torchvision.datasets.CIFAR10(root='.\/data', train=False,\n                                       download=True, transform=transform)\n\n# project numerical values to actual classes\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\nNUM_ROUNDS = len(trainset) \/ BATCH_SIZE","cf1f6176":"!mkdir LeNet_MSE","62a1d257":"# show histogram fuction\n\ndef getHistograms(img, intensity_range,num_bins=10):\n    histograms = list()\n    for i in range(3):\n        hist, edge = np.histogram(img[:,:,i], bins=num_bins, range=intensity_range)\n        edge = (edge[:-1] + edge[1:]) \/2 # use the middle point as bin representation\n        histograms.append((edge, hist))\n    return histograms","d36a0cb8":"# Display one random sample of each class and its histogram\n\n# Because each batch only has 32 samples, it's possible that each batch won't have\n# any image of some classes\n\n# Define trainset data loader\ndataiter = iter(torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n                                          shuffle=True, num_workers=1))\n\n# load the first batch of images and find the first image with label==0\nimages, labels = dataiter.next()\nindex = (np.where(labels == 0))\n\nplt.figure(figsize=(20, 60))\n\n#reference https:\/\/thispointer.com\/find-the-index-of-a-value-in-numpy-array\/\n\nfor i in range(10): # for each class\n    \n    # find until batch has images in this category, store in images and labels\n    while len(np.where(labels == i)[0]) == 0:\n        images, labels = dataiter.next()\n    \n    # select the first image in this class to be displayed\n    index = np.where(labels == i)[0]\n    image = images[index][0,:,:,:]\n    \n    #display the image\n    plt.subplot(10,4,4*i+1)\n    plt.title(classes[i]+' - traning set')\n    npimg = np.transpose(image.numpy(), (1, 2, 0)) \n    plt.imshow(npimg)\n    \n    # show the histogram in each channel\n    plt.subplot(10,4,4*i+2)\n    plt.title('Histogram')\n    histograms = getHistograms(npimg, intensity_range=(0.0, 1.0), num_bins=10)\n    colors = ('Red', 'Green', 'Blue')\n    for i in range(3):\n        plt.plot(histograms[i][0],histograms[i][1],c=colors[i], alpha=0.8,label='Channel {0}'.format(colors[i]))\n    plt.xlabel('Intensity')\n    plt.ylabel('Abundance')\n    plt.legend()\n    \n    \n    \n# repeat the process with the testset\ndataiter = iter(torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n                                          shuffle=True, num_workers=1))\nimages, labels = dataiter.next()\nindex = (np.where(labels == 0))\n\nfor i in range(10):\n    \n    while len(np.where(labels == i)[0]) == 0:\n        images, labels = dataiter.next()\n\n    index = np.where(labels == i)[0]\n    image = images[index][0,:,:,:]\n    \n    plt.subplot(10,4,4*i+3)\n    plt.title(classes[i]+' - test set')\n    npimg = np.transpose(image.numpy(), (1, 2, 0)) \n    plt.imshow(npimg)\n    \n    plt.subplot(10,4,4*i+4)\n    plt.title('Histogram')\n    histograms = getHistograms(npimg, intensity_range=(0.0, 1.0), num_bins=10)\n    colors = ('Red', 'Green', 'Blue')\n    for i in range(3):\n        plt.plot(histograms[i][0],histograms[i][1],c=colors[i], alpha=0.8,label='Channel {0}'.format(colors[i]))\n    plt.xlabel('Intensity')\n    plt.ylabel('Abundance')\n    plt.legend()\n        \n\nplt.show() \n    \n    ","b953c3fd":"#https:\/\/medium.com\/@sergioalves94\/deep-learning-in-pytorch-with-cifar-10-dataset-858b504a6b54","a121a60e":"# validation set size equal to test set size\n\nvali_size = len(testset) \n\n# rest of the train set become the new train set\n\ntrain_size = len(trainset) - vali_size \ntrainset, valiset = torch.utils.data.random_split(trainset, [train_size, vali_size])\n\n#\n\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n                                          shuffle=True, num_workers=1)\nvaliloader = torch.utils.data.DataLoader(valiset, batch_size=BATCH_SIZE,\n                                          shuffle=True, num_workers=1)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n                                         shuffle=False, num_workers=1)","32c4345c":"# given a data loader, find the number of samples in each classes in the whole dataset\n\ndef countLoader(dataloader):\n    \n    count = np.zeros(10)\n    \n    for i, data in enumerate(dataloader):\n    \n        inputs, labels = data\n                    \n        for j in range(labels.shape[0]):\n            count[labels[j]] += 1\n        \n    return count","8fa568c8":"print(\"No. of samples in: \\n Train set: {} \\n Validation set: {} \\n Test set: {}\".format(len(trainset), len(valiset),len(testset)))\n\ntrain_count = countLoader(trainloader)\n\nvali_count = countLoader(valiloader)\n\ntest_count = countLoader(testloader)","8ef6c585":"plt.figure(figsize=(12,6))\nplt.title('data distribution')\nplt.xticks(range(10), labels=range(10))\nplt.xlabel('Number')\nplt.ylabel('Number of samples')\nplt.bar(range(10), train_count, label='Train')\nplt.bar(range(10), vali_count, label='Validation', bottom=train_count)\nplt.bar(range(10), test_count, label='Test', bottom=vali_count+train_count)\nplt.legend()\nplt.savefig('DataDistribution.png')\nplt.show()","b004469b":"# Formula to calculate shape as we go through layer by layer = [(X - F + 2P)\/S] + 1\n# Here,\n# X = Width \/ Height\n# F = Kernel size\n# P = Padding\n# S = Strides (default = 1)\n\n# Our input to the first layer is going to be [batchsize, 1, 32, 32]\n# substitute, =[(32 - 5 + 2(0))\/1] + 1\n#             = 28\n\n#reference: https:\/\/github.com\/icpm\/pytorch-cifar10\/blob\/master\/models\/LeNet.py\n\nclass Model(nn.Module):\n    '''ConvNet -> Max_Pool -> RELU -> ConvNet -> Max_Pool -> RELU -> FC -> RELU -> FC -> SOFTMAX'''\n    def __init__(self):\n        '''Define model modules.'''\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n        self.fc1 = nn.Linear(16*5*5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x)) # convolution 1\n        x = F.max_pool2d(x, 2)    # max pooling 1\n        x = F.relu(self.conv2(x)) # cconvolution 2\n        x = F.max_pool2d(x, 2)    # max pooling 2\n        x = x.view(x.size(0), -1) # flatterning\n        x = F.relu(self.fc1(x))   # reshape\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nLeNet = Model()\n\n# If GPU available, move the model to GPU.\nif cuda:\n    LeNet.cuda()\n\nprint(LeNet)","41287a23":"# [Create your optimiser and loss function here]","223974ae":"optimizer = optim.Adam(LeNet.parameters(), lr=0.0001)\ncriterion = nn.MSELoss()","091faac0":"print('Started Training')\n\ntrain_epoch_loss = []\nvalidation_epoch_loss = []\n\nfor epoch in range(EPOCHS):  # loop over the dataset multiple times\n\n    train_loss = []\n    validation_loss = []\n    loss = 0.0 # loss is a temporary variable used in loops\n    \n    print('Progress: {:2.0f}%'.format(epoch\/EPOCHS*100),end=' ')\n    clear_output(wait=True)\n    \n    #######################################################\n    ####################### Train #########################\n    #######################################################\n    # Set the model to train mode so that the parameters can be updated.\n        \n    LeNet.train()\n    \n    for i, data in enumerate(trainloader):\n        \n        # If GPU is available, move the data to the GPU for faster computation.\n        if cuda:\n                \n            # get the inputs; data is a list of [inputs, labels]\n            inputs, labels = data\n            labels = F.one_hot(labels.cuda(), num_classes=10).float()\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward + backward + optimize\n            outputs = LeNet(inputs.cuda())\n            \n            loss = criterion(outputs.cuda(), labels.cuda())\n            train_loss.append(loss.cpu().data.item())\n            \n            loss.backward()\n            \n            optimizer.step()\n\n                                    \n        else:\n           \n            # get the inputs; data is a list of [inputs, labels]\n            inputs, labels = data\n            labels = F.one_hot(labels, num_classes=10).float()\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward + backward + optimize\n            outputs = LeNet(inputs)\n            \n            loss = criterion(outputs, labels)\n            train_loss.append(loss.cpu().data.item())\n            \n            loss.backward()\n            \n            optimizer.step()\n            \n    #######################################################\n    ###################### Validation #####################\n    #######################################################\n    # Set the model to evaluation mode so that parameters are fixed.          \n    \n    LeNet.eval()\n    \n    for j, validation_data in enumerate(valiloader):           \n            \n        if cuda:\n\n            # get the inputs; data is a list of [inputs_validation, labels_validation]\n            validation_input, validation_labels = validation_data\n            validation_labels = F.one_hot(validation_labels.cuda(), num_classes=10).float()\n                \n            validation_output = LeNet(validation_input.cuda())\n                \n            loss = criterion(validation_output.cuda(), validation_labels.cuda())\n            validation_loss.append(loss.cpu().data.item()) # why cpu?\n        \n        else:\n          \n            # get the inputs; data is a list of [inputs_validation, labels_validation]\n            validation_input, validation_labels = validation_data\n            validation_labels = F.one_hot(validation_labels, num_classes=10).float()\n                \n            validation_output = LeNet(validation_input)\n                \n            loss = criterion(validation_output, validation_labels)\n            validation_loss.append(loss.cpu().data.item())\n                \n    train_epoch_loss.append(np.mean(train_loss))\n    validation_epoch_loss.append(np.mean(validation_loss))\n    \n   \n    # save models\n    torch.save(LeNet.state_dict(), '.\/LeNet_MSE\/checkpoint_epoch_%s.pth' % (epoch))\n    \nprint('Finished Training')","dcbd2c30":"plt.figure(figsize = (12, 8))\nplt.plot(train_epoch_loss, '-o', label = 'training loss', markersize = 3)\nplt.plot(validation_epoch_loss, '-o', label = 'validation loss', markersize = 3)\nplt.legend(loc = 'upper right');","8868d9af":"best_epoch = np.argmin(validation_epoch_loss)\nprint('best epoch: ', best_epoch)","4804e66d":"# [Your code here for loading the best model, testing on the test set, and displaying the confusion matrix as well as the classification report]","7d4db0f3":"# load the best model\nstate_dict = torch.load('.\/LeNet_MSE\/checkpoint_epoch_%s.pth' % (best_epoch))\nprint(state_dict.keys())\nLeNet.load_state_dict(state_dict)","53db267e":"full_test_labels = []\nfull_predicted_labels = []\nfull_images = []\n        \nLeNet.eval()\n\nfor i, test_data in enumerate(testloader):\n    \n    if cuda:\n    \n        # get the inputs; data is a list of [test_inputs, test_labels]\n        test_input, test_labels = test_data\n        test_labels = F.one_hot(test_labels.cuda(), num_classes=10).float()\n                \n        test_output = LeNet(test_input.cuda())\n        \n        for j in range(test_labels.shape[0]):\n            full_test_labels.append(test_labels.tolist()[j])\n            full_predicted_labels.append(test_output.tolist()[j])\n            full_images.append(test_input.tolist()[j])\n                \n       \n    else:\n\n        # get the inputs; data is a list of [test_inputs, test_labels]\n        test_input, test_labels = test_data\n        test_labels = F.one_hot(test_labels, num_classes=10).float()\n                \n        test_output = LeNet(test_input)\n        \n        for j in range(test_labels.shape[0]):\n            full_test_labels.append(test_labels.tolist()[j])\n            full_predicted_labels.append(test_output.tolist()[j])\n            full_images.append(test_input.tolist()[j])","5c0bcf43":"# check number of samples tested\nprint(\"number of samples tested:\",len(full_test_labels))\n\n# convert probability into prediction labels\n\nfull_test_labels_num = np.argmax(full_test_labels, axis=1)\nfull_predicted_labels_num = np.argmax(full_predicted_labels, axis=1)\n\n# an array of whether the prediction of each element is right\n\ntest_result = full_test_labels_num == full_predicted_labels_num\n\n","e99734fb":"# manual confusion matrix output\n\nconfusion_matrix_num = np.zeros((10,10))\nfor i in range(len(full_test_labels)):\n    \n    confusion_matrix_num[full_test_labels_num[i], full_predicted_labels_num[i]] += 1\n    \nprint(confusion_matrix_num)\n\n","5b41ff14":"confusion_matrix_num.trace()\/ len(testset)\nprint(\"Total correct rate is: {:2.2f} %\".format(confusion_matrix_num.trace()\/len(testset)*100))","8534931f":"CM = confusion_matrix(full_test_labels_num, full_predicted_labels_num)\n\nplt.figure(figsize = (12,10))\nsns.heatmap(CM, annot = True, annot_kws = {\"size\": 10})\nplt.ylim([0, 10]);\nplt.ylabel('True labels');\nplt.xlabel('predicted labels');","5353fd1a":"# [Your code here]","c497a14b":"#reshape the data for visualization\n\nprint(\"The original dimension of the list is: {} * {} * {} * {}\".format(len(full_images),len(full_images[0]),len(full_images[0][0]), len(full_images[0][0][0])))\n\nfull_images_swaped = np.swapaxes(np.swapaxes(full_images,1,3),1,2)\n\nprint(\"The dimension of the list after transform is: {} * {} * {} * {}\".format(len(full_images_swaped),len(full_images_swaped[0]),len(full_images_swaped[0][0]), len(full_images_swaped[0][0][0])))","8fee60bb":"# generate one image from each class with labels and predictions\n\nplt.figure(figsize=(20, 60))\nfor i in range(10):\n    class_index = np.where(full_test_labels_num == i)                  # find the images with label i\n    \n    random_indexes = np.random.choice(class_index[0], replace=True, size=5)   # randomly choose 5 samples from the list\n    for j in range(5):\n        \n        random_index = random_indexes[j]\n        plt.subplot(10, 5, i*5+j+1)\n        plt.title(\"Actual Label:{} \\n Predicted Label:{}\".format(classes[full_test_labels_num[random_index]],\n                                                            classes[full_predicted_labels_num[random_index]]))\n        plt.imshow(full_images_swaped[random_index])","6ae7349c":"# [Your code here]","738090af":"!mkdir LeNet_CrossEntropy","df848da0":"print(\"No. of samples in: \\n Train set: {} \\n Validation set: {} \\n Test set: {}\".format(len(trainset), len(valiset),len(testset)))","6894674c":"#reference: https:\/\/github.com\/icpm\/pytorch-cifar10\/blob\/master\/models\/LeNet.py\n\nclass Model2(nn.Module):\n    '''ConvNet -> Max_Pool -> RELU -> ConvNet -> Max_Pool -> RELU -> FC -> RELU -> FC -> SOFTMAX'''\n    def __init__(self):\n        '''Define model modules.'''\n        super(Model2, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n        self.fc1 = nn.Linear(16*5*5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x)) # convolution 1\n        x = F.max_pool2d(x, 2)    # max pooling 1\n        x = F.relu(self.conv2(x)) # cconvolution 2\n        x = F.max_pool2d(x, 2)    # max pooling 2\n        x = x.view(x.size(0), -1) # flatterning\n        x = F.relu(self.fc1(x))   # reshape\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nLeNet2 = Model2()\n\n# If GPU available, move the model to GPU.\nif cuda:\n    LeNet2.cuda()\n\nprint(LeNet2)","0df792ea":"optimizer = optim.Adam(LeNet2.parameters(), lr=0.005)\ncriterion = nn.CrossEntropyLoss()","adc0be72":"print('Started Training')\n\ntrain_epoch_loss = []\nvalidation_epoch_loss = []\n\nfor epoch in range(EPOCHS):  # loop over the dataset multiple times\n\n    train_loss = []\n    validation_loss = []\n    loss = 0.0 # loss is a temporary variable used in loops\n    \n    print('Progress: {:2.0f}%'.format(epoch\/EPOCHS*100),end=' ')\n    clear_output(wait=True)\n    \n    #######################################################\n    ####################### Train #########################\n    #######################################################\n    # Set the model to train mode so that the parameters can be updated.\n        \n    LeNet2.train()\n    \n    for i, data in enumerate(trainloader):\n        \n        # If GPU is available, move the data to the GPU for faster computation.\n        if cuda:\n                \n            # get the inputs; data is a list of [inputs, labels]\n            inputs, labels = data\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward + backward + optimize\n            outputs = LeNet2(inputs.cuda())\n            \n            loss = criterion(outputs.cuda(), labels.cuda())\n            train_loss.append(loss.cpu().data.item())\n            \n            loss.backward()\n            \n            optimizer.step()\n\n                                    \n        else:\n           \n            # get the inputs; data is a list of [inputs, labels]\n            inputs, labels = data\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward + backward + optimize\n            outputs = LeNet2(inputs)\n            \n            loss = criterion(outputs, labels)\n            train_loss.append(loss.cpu().data.item())\n            \n            loss.backward()\n            \n            optimizer.step()\n            \n    #######################################################\n    ###################### Validation #####################\n    #######################################################\n    # Set the model to evaluation mode so that parameters are fixed.          \n    \n    LeNet2.eval()\n    \n    for j, validation_data in enumerate(valiloader):           \n            \n        if cuda:\n\n            # get the inputs; data is a list of [inputs_validation, labels_validation]\n            validation_input, validation_labels = validation_data\n                \n            validation_output = LeNet2(validation_input.cuda())\n                \n            loss = criterion(validation_output.cuda(), validation_labels.cuda())\n            validation_loss.append(loss.cpu().data.item()) # why cpu?\n        \n        else:\n          \n            # get the inputs; data is a list of [inputs_validation, labels_validation]\n            validation_input, validation_labels = validation_data\n                \n            validation_output = LeNet2(validation_input)\n                \n            loss = criterion(validation_output, validation_labels)\n            validation_loss.append(loss.cpu().data.item())\n                \n    train_epoch_loss.append(np.mean(train_loss))\n    validation_epoch_loss.append(np.mean(validation_loss))\n    \n   \n    # save models\n    torch.save(LeNet2.state_dict(), '.\/LeNet_CrossEntropy\/checkpoint_epoch_%s.pth' % (epoch))\n    \nprint('Finished Training')","84f9b9e1":"plt.figure(figsize = (12, 8))\nplt.plot(train_epoch_loss, '-o', label = 'training loss', markersize = 3)\nplt.plot(validation_epoch_loss, '-o', label = 'validation loss', markersize = 3)\nplt.legend(loc = 'upper right');","8bb72ea3":"best_epoch = np.argmin(validation_epoch_loss)\nprint('best epoch: ', best_epoch)\n\nstate_dict = torch.load('.\/LeNet_CrossEntropy\/checkpoint_epoch_%s.pth' % (best_epoch))\nprint(state_dict.keys())\nLeNet2.load_state_dict(state_dict)","ff8acffb":"full_test_labels = []\nfull_predicted_labels = []\nfull_images = []\n\nLeNet2.eval()\n\nfor i, test_data in enumerate(testloader):\n    \n    if cuda:\n\n        # get the inputs; data is a list of [test_inputs, test_labels]\n        test_input, test_labels = test_data\n        test_labels = F.one_hot(test_labels.cuda(), num_classes=10).float()\n                \n        test_output = LeNet2(test_input.cuda())\n        \n        for j in range(test_labels.shape[0]):\n            full_test_labels.append(test_labels.tolist()[j])\n            full_predicted_labels.append(test_output.tolist()[j])\n            full_images.append(test_input.tolist()[j])\n                \n       \n    else:\n\n        # get the inputs; data is a list of [test_inputs, test_labels]\n        test_input, test_labels = test_data\n        test_labels = F.one_hot(test_labels, num_classes=10).float()\n                \n        test_output = LeNet2(test_input)\n        \n        for j in range(test_labels.shape[0]):\n            full_test_labels.append(test_labels.tolist()[j])\n            full_predicted_labels.append(test_output.tolist()[j])\n            full_images.append(test_input.tolist()[j])","d5f36027":"print(\"Number of samples tested: {}\".format(len(full_test_labels)))\n\n# convert probability into final label \n\nfull_test_labels_num = np.argmax(full_test_labels, axis=1)\nfull_predicted_labels_num = np.argmax(full_predicted_labels, axis=1)\n\n# an array of whether the prediction of each element is right\ntest_result = full_test_labels_num == full_predicted_labels_num\n","10b0699c":"# manual output the confusion matrix \n\nconfusion_matrix_num = np.zeros((10,10))\nfor i in range(len(full_test_labels)):\n    \n    confusion_matrix_num[full_test_labels_num[i], full_predicted_labels_num[i]] += 1\n    \nprint(confusion_matrix_num)","02f74309":"confusion_matrix_num.trace()\/ len(testset)\nprint(\"Total correct rate is: {:2.2f} %\".format(confusion_matrix_num.trace()\/len(testset)*100))","1e6f56c1":"CM = confusion_matrix(full_test_labels_num, full_predicted_labels_num)\n\nplt.figure(figsize = (12,10))\nsns.heatmap(CM, annot = True, annot_kws = {\"size\": 10})\nplt.ylim([0, 10]);\nplt.ylabel('True labels');\nplt.xlabel('predicted labels');","c821abcb":"print(\"The original dimension of the list is: {} * {} * {} * {}\".format(len(full_images),len(full_images[0]),len(full_images[0][0]), len(full_images[0][0][0])))\n\n#reshape the data for visualization\nfull_images_swaped = np.swapaxes(np.swapaxes(full_images,1,3),1,2)\n\nprint(\"The dimension of the list after transform is: {} * {} * {} * {}\".format(len(full_images_swaped),len(full_images_swaped[0]),len(full_images_swaped[0][0]), len(full_images_swaped[0][0][0])))","1253eb5b":"# generate one image from each class with labels and predictions\n\nplt.figure(figsize=(20, 60))\nfor i in range(10):\n    class_index = np.where(full_test_labels_num == i)                  # find the images with label i\n    \n    random_indexes = np.random.choice(class_index[0], replace=True, size=5)   # randomly choose 5 samples from the list\n    for j in range(5):\n        \n        random_index = random_indexes[j]\n        plt.subplot(10, 5, i*5+j+1)\n        plt.title(\"Actual Label:{} \\n Predicted Label:{}\".format(classes[full_test_labels_num[random_index]],\n                                                            classes[full_predicted_labels_num[random_index]]))\n        plt.imshow(full_images_swaped[random_index])","898517bd":"### 5. (5 pts.) Split up the train set into new train and validation sets so that the number of samples in the validation set is equal to the number of samples in the test set. Then create a [```DataLoader```](https:\/\/pytorch.org\/docs\/stable\/data.html#torch.utils.data.DataLoader) for each set, including the test set, with a batch size of 32.\nThe [Pytorch CIFAR10](https:\/\/pytorch.org\/tutorials\/beginner\/blitz\/cifar10_tutorial.html) tutorial will also help you here.\nMake sure none of the samples in the validation set exists in the new train set.","71605357":"### 7. (10 pts.) According to the LeNet architecture below, create a fully-connected model. Also, identify the architeture's hyper-parameters, activation functions, and tensor shapes.\nArchitecture hyper-parameter includes the number of layers, number of kernels in each layer, size of the kernels, stride, zero-padding size. Just by looking at the architecture itself, you should be able to identify the hyper-parameters. Keep in mind that you identified the $W, H$, and $N$ (Which refers to the number of classes) in the first question.\nFor more help, look at this [implementation](https:\/\/github.com\/icpm\/pytorch-cifar10\/blob\/master\/models\/LeNet.py).\n![LeNet Architecture](https:\/\/raw.githubusercontent.com\/soroush361\/DeepLearningInBME\/main\/Ass1_Arch1.png)","0e2e67ac":"the lowest validation error to allows for best generalization results","8a5e2880":"### 13. (20 pts.) Repeat the training, validation, and testing with the [Cross-Entropy](https:\/\/pytorch.org\/docs\/stable\/generated\/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss) loss function and initial learning rate of $0.005$. Explain how the model's performance changed.\nEssentially you need to copy all the codes above and just change the loss function and edit the learning rate. Obviously, you don't need to re-import the dataset and the libraries. However, you need to create a new instance of the architecture. Otherwise, the weights would be the same as the last epoch (or the best epoch) in the last part. To avoid overwriting your previously trained model, change the save directories in the training loop.","1e533ca3":"### 2. (0 pts.) Import the required packages in the following code block. \nYou can always come back here and import another package; please keep them all in the following block to make your code well-organized.","1013a3e4":"### 4. (10 pts.) Using the 'matplotlib' library, make a figure with $N\\times4$ grid cells where $N$ is the number of classes. Display one random sample of each class pulled from the train set in its corresponding row that depends on its class index and the first column and its histogram in the second column. Repeat this for the third and fourth columns but pull images from the test set.","974da78c":"This model achieved ~62% error rate with 2 epochs, ~51% error rate with 10 epochs.\n\nHowever after 200 epochs the model based on cross entropy failed to converge. This probably indicates that the learning rate is too high and model doesn't generalize well compared to the previous model.","6a64f62b":"### 10. (5 pts.) Display the learning curve and illustrate the best epoch. Explain your criteria for the best epoch.\nThe learning curve shows the model's loss and accuracy at the end of each epoch for all epochs (200 epochs). The criteria for the best epoch can be the minimum loss or maximum accuracy or other criteria.","bfbfcebe":"### 1. (5 pts.) According to the [CIFAR10](http:\/\/www.cs.toronto.edu\/~kriz\/cifar.html) dataset descriptions and other online resources, please identify the quantities below:\n\na) Total Number of samples \\\nb) Number of classes \\\nc) Image size \\\nd) Write class names and their corresponding label index (e.g., 0. cats, 1. dogs, ...) \\\ne) Intensity range","b44a2e1d":"<font color='red'>[Comment about the performance changes]<\/font>","b485b240":" <font color='red'>[Describe the model's architecture hyper-parameters]<\/font>","1565c375":"# Deep Learning in Biomedical Engineering","81a9742a":"## Xin Gao xg2326","782786d3":"### 9. (15 pts.) Train the model for 200 epochs using the train set and validate your model's performance at the end of each epoch using the validation sets.\nTo increase the training speed, use the GPU accelerator.\nLook at the '[FirstTutorial](https:\/\/www.kaggle.com\/soroush361\/deeplearninginbme-firsttutorial)' for more help.\nDo not forget to save the model at the end of each epoch.","488b59cb":"\na) total number of samples: 60,000  \nb) number of classes: 10  \nc) image size: 3*32*32  \nd) 0. airplane 1. automobile 2. bird 3. cat 4. deer 5. dog 6. frog 7. horse 8. ship 9. truck   \ne) intensity range: 0-255     \n","c7e3e06b":"## Introduction\nIn this assignment, you will implement, train, and test [LeNet](https:\/\/en.wikipedia.org\/wiki\/LeNet) model to classify [CIFAR10](http:\/\/www.cs.toronto.edu\/~kriz\/cifar.html) dataset.\n\n## Instructions\nDepending on each question, there are empty blocks you need to fill. The code blocks are only for Python codes and comments and currently have a comment like ```# [Your code here]```. The markdown blocks are only for plain or laTex text that you may use for answering descriptive questions. Currently, the markdown blocks have a comment like <font color='red'>[your answer here]<\/font>. Please remove the comments before filling the blocks. You can always add more blocks if you need to, or it just makes your answers well-organized.\n\nAlthough you may use other available online resources (such as GitHub, Kaggle Notebooks), it is highly recommended to try your best to do it yourself. If you are using an online code or paper, make sure you cite their work properly to avoid plagiarism. Using other students' works is absolutely forbidden and considered cheating.\n\nWrite comments for your codes in the big picture mode. One comment line at the top of each code block is necessary to explain what you did in that block. Don't comment on every detail.\n\nName your variables properly that represent the data they are holding, such as ``` test_set = ..., learning_rate = ...``` not ```a = ..., b = ...```.\n\nImplementing and reporting results using other architectures than LeNet will grant you an extra 20% on grade.\n\nIn this [Kaggle Notebook](https:\/\/www.kaggle.com\/roblexnana\/cifar10-with-cnn-for-beginer), you may find useful information about how your outputs must look. Just remember, they are using a different architecture, and they are using TensorFlow for implementations.\n\n\n## How to submit:\nAfter you have completed the assignment: \n1. Save a version (You can use 'Quick Save' to avoid re-running the whole notebook)\n2. Make the saved version public (Share -> Public)\n3. Copy the 'Public URL'\n4. Download your completed notebook as a '.ipynb' file (File -> Download)\n5. Upload the 'Public URL' and the '.ipynb' files on the [CourseWorks](https:\/\/courseworks2.columbia.edu\/).","8068f561":"### 8. (5 pts.) Create an instance of [ADAM optimizer](https:\/\/pytorch.org\/docs\/stable\/optim.html#torch.optim.Adam) with an initial learning rate of $0.0001$ and an instance of [Mean Squared Error (MSE)](https:\/\/pytorch.org\/docs\/stable\/generated\/torch.nn.MSELoss.html#torch.nn.MSELoss) loss function. Briefly explain the ADAM optimizer algorithm and the MSE loss function.\nFor ADAM optimizer, keep other arguments as default. \n\nFor your information, here is the mathematics behind the ADAM optimizer: \\\nFor each parameter $w^j$\n$$\nv_t = \\beta_1v_{t-1}-(1-\\beta_1)g_t \\\\\ns_t = \\beta_2s_{t-1}-(1-\\beta_2)g_t^2 \\\\\n\\Delta w^j = -\\eta\\frac{v_t}{\\sqrt{s_t+\\epsilon}}g_t \\\\\nw^j_{t+1} = w^j_t+\\Delta w^j\n$$\nWhere $\\eta$ is the initial learning rate, $g_t$ is the gradient at time $t$ along $w^j$, $v_t$ is the exponential average of gradients along $w^j$, $s_t$ is the exponential average of squares of gradients along $w^j$, $\\beta_1, \\beta_2$ are the hyper-parameters, and $\\epsilon$ is a small number to avoid dividing by zero.\n\nThe MSE loss function is:\n$$\nL(y,\\hat{y}) = \\frac{1}{N}\\sum_{i=1}^N{(y_i-\\hat{y}_i)^2}\n$$\nWhere $y$ is the true value, $\\hat{y}$ is the predicted value, $N$ is the number of classes. Keep in mind that $y$ is a one-hot vector like $y=\\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\\\ \\vdots \\end{bmatrix}$ (This example of $y$ indicates that the sample belongs to class ID 2, remember it is zero-indexed) and $\\hat{y}=\\begin{bmatrix} 0.1 \\\\ 0.03 \\\\ 0.8 \\\\ \\vdots \\end{bmatrix}$ shows the probability of belonging to each class for the same sample and predicted by the model.\n\nFor other optimization algorithms and loss functions, check the links below:\n\n[Optimizers list](https:\/\/pytorch.org\/docs\/stable\/optim.html#algorithms) \n\n[Loss function list](https:\/\/pytorch.org\/docs\/stable\/nn.html#loss-functions)","a0c5235e":"<font color='red'>[Comment about the model's performance]<\/font>","1f98f5be":"Conv1 + MaxPool1:   \n    kernel size = 5*5  \n    stride = 1  \n    no zero-padding  \n    maxpool: 2*2 with stride=2  \n    input channel=3  \n    output channel=6   \n    \nConv2 + MaxPool2:   \n    kernel size = 5*5  \n    stride = 1  \n    no zero-padding  \n    maxpool: 2*2 with stride=2  \n    input channel=6  \n    output channel=16  ","cd3ed812":"## Assignment 2\n### Due date:<font color='red'> 11:59 pm, Febraury 25, 2021<\/font>","99a77acd":"<font color='red'>[Explaine ADAM and MSE here]<\/font>","472094d8":"### 3. (5 pts.) Load train and test sets using Pytorch datasets functions.\nMake sure the intensity range is between $[0, 1]$ and images are stored as 'tensor' type. \nYou may use transformers while downloading the dataset to do the job. Look at this tutorial: [Pytorch CIFAR10](https:\/\/pytorch.org\/tutorials\/beginner\/blitz\/cifar10_tutorial.html))","abba6df3":"Adam is a optimized gradien descent that combines the AdaGrad and RMSProp algorithms to provide an optimization algorithm that can handle sparse gradients on noisy problems.\n\nMSE is just the mean square error loss function. It represents the second moment of the error and is prompt to large varience by small perturbation in certain regions.","0f5d581d":"### 6. (5 pts.) Display the number of samples for each class in the train, validation, and test sets as a stacked bar plot similar to the '[FirstTutorial](https:\/\/www.kaggle.com\/soroush361\/deeplearninginbme-firsttutorial)'.","f023d342":"<font color='red'>[Describe your criteria for choosing the best epoch]<\/font>","21427e39":"This model achieved ~60% error rate with 2 epochs, 50% error rate with 10 epochs","8e49cc18":"### 12. (5 pts.) Display five random samples of each class titled with the true label and the predicted label. Comment on your model's performance.\nSamples must be pulled from the test set.","76f990c1":"### 11. (10 pts.) Load the model's weights at the best epoch and test your model performance on the test set. Display the confusion matrix and classification report."}}