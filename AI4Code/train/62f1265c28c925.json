{"cell_type":{"79ebf3f3":"code","b596bba8":"code","b9c0fa97":"code","cf1933e0":"code","e4fa2c2c":"code","809aeb72":"code","36172d1b":"code","4c30d2fa":"code","700bd64d":"code","93285668":"code","ecfc87e7":"code","5c2554b7":"code","8ea91ef0":"code","09da79bd":"code","e57b197d":"markdown","50cd9dbd":"markdown","85dadbcf":"markdown","b86ada1a":"markdown","0575271c":"markdown","aeb09a87":"markdown","f2af0eb3":"markdown","554fc7a4":"markdown","96694711":"markdown","e35a9fa6":"markdown"},"source":{"79ebf3f3":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","b596bba8":"import pandas as pd\nimport numpy as np\nimport tensorflow_hub as hub\nfrom sklearn import metrics\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\n\ntarget = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')['target']\ntrain = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/test.csv')\nssub = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/sample_submission.csv')\n","b9c0fa97":"import pandas_profiling as pp","cf1933e0":"pp.ProfileReport(train)","e4fa2c2c":"import re\n\n#extracting hashtags using simple regex\ntrain['hashtags']=train['text'].apply(lambda x:re.findall('#\\w*',x))","809aeb72":"train.head(5)","36172d1b":"import matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nlabels=['Negative','Positive']\nno_clusters=2\nfor c in range(2):\n    print('Target:-',labels[c])\n    hts=list(train[train['target']==c]['hashtags'])\n\n    hashes=[]\n    for ht in  hts:\n        for h in ht:\n            hashes.append(h.strip())\n\n    string_hash=' '.join(hashes)\n\n    hash_values=pd.Series(hashes).value_counts()\n\n    hval=hash_values.reset_index()\n\n    #wordcloud plot\n    d = {}\n    for a, x in hval.values:\n        d[a] = x\n\n    wordcloud = WordCloud(max_font_size=40)\n    wordcloud.generate_from_frequencies(frequencies=d)\n    plt.figure(figsize=(70,70))\n    plt.imshow(wordcloud, interpolation=\"bilinear\")\n    plt.axis(\"off\")\n    plt.show()","4c30d2fa":"\nembed = hub.load(\"https:\/\/tfhub.dev\/google\/universal-sentence-encoder\/3\")\nX_train_embeddings = embed(train.text.values)\nX_test_embeddings = embed(test.text.values)","700bd64d":"from sklearn.manifold import TSNE\n\n#2-D dimensional representation\nX_embedded = TSNE(n_components=2,perplexity=50).fit_transform(X_train_embeddings['outputs'])\nxy_df=pd.DataFrame(X_embedded)\nxy_df['tweets']=train.text.values\nxy_df['Target']=target\nxy_df.columns=['x', 'y', 'tweets','Target']","93285668":"from bokeh.models import ColumnDataSource\nfrom bokeh.models import HoverTool\nfrom bokeh.io import output_file\nfrom bokeh.io import output_notebook, show\nfrom bokeh.plotting import figure\n\noutput_notebook()","ecfc87e7":"colormap = {1: 'red',0: 'blue'}\ncolors = [colormap[x] for x in xy_df['Target']]\nxy_df['colors'] = colors\n\nsrc = ColumnDataSource(xy_df)\n\n\np = figure(plot_height=650, title=\"TSNE Tweet Embedding Viz \")\np.circle(x='x', y='y',source=src,legend='Target',color='colors')\np.xgrid.grid_line_color = None\np.y_range.start = 0\np.xaxis.axis_label = \"x\"\np.yaxis.axis_label = \"y\"\np.xaxis.major_label_orientation = 1\n\nfrom bokeh.models import CustomJS\n\ncallback = CustomJS(code=\"\"\"\n    var tooltips = document.getElementsByClassName(\"bk-tooltip\");\n    for (var i = 0, len = tooltips.length; i < len; i ++) {\n        tooltips[i].style.top = \"\"; \/\/ unset what bokeh.js sets\n        tooltips[i].style.left = \"\";\n        tooltips[i].style.bottom = \"0px\";\n        tooltips[i].style.left = \"0px\";\n    }\n    \"\"\")\nhover = HoverTool(callback=callback,tooltips = [('Tweet', '@tweets'),('Target','@Target')])\n\np.add_tools(hover)\nshow(p)","5c2554b7":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n#using top 50 words as the features\nvectorizer = TfidfVectorizer(max_features=30,stop_words='english')\nall_tweets=list(train['text'])+list(test['text'])\nX = vectorizer.fit_transform(all_tweets)\n\ntweet_array=X.toarray()\ntf_train=tweet_array[0:len(train)]\ntf_test=tweet_array[len(train):len(tweet_array)]\n\n## Merging TF-IDF and Universal Sentence Encoder\ntrain_df=np.concatenate([X_train_embeddings['outputs'],tf_train],axis=1)\ntest_df=np.concatenate([X_test_embeddings['outputs'],tf_test],axis=1)","8ea91ef0":"import lightgbm as lgb\ntext_clf = lgb.LGBMClassifier(n_estimators=3000, learning_rate=0.05)\n\ntext_clf.fit(train_df, target)","09da79bd":"pred=text_clf.predict(test_df)\n\nssub[\"target\"] = pred\nssub.to_csv(\"submission.csv\",index=False)","e57b197d":"## LGBM Model (TFIDF + Sentence Encoding)","50cd9dbd":"****Use your mouse cursor to see the tweets in the tooltips","85dadbcf":"## TF-IDF Encoding","b86ada1a":"# Basic Exploratory Analysis","0575271c":"## Encoding tweets using Universal Sentence Encoder","aeb09a87":"## Hashtag Vizualization","f2af0eb3":"## Prediction","554fc7a4":"Lets use nice pandas profiling which has nice boiler plate code for EDA.","96694711":"## Interactive Tweet Embeddings Vizualization ","e35a9fa6":"Hi Everyone, \nLets see  \n* How variables are distributed (EDA)\n* How the tweets are represented in 2D sentence embedding space with interactive tweet 2D Viz. \n* How to build a LGBM model using both TF-IDF Encoding and Sentence Embedding"}}