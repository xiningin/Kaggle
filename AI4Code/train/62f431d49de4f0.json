{"cell_type":{"d628769b":"code","01a2c52c":"code","bfc34c03":"code","4c6e160b":"code","8b0bfc5e":"code","bd30ec1a":"code","4c2c1cf3":"code","8b11fd61":"code","0276231d":"code","c69d65b6":"code","d5290587":"code","c79f4419":"code","db152674":"code","51e15b77":"code","fb449435":"code","8e2b5543":"code","e50f79bb":"code","4cae112c":"code","ed046c51":"code","8bee3ffe":"code","3fe5078c":"code","31035302":"code","2bf8414a":"code","f5257316":"code","9b2a494b":"code","95e903ad":"code","6e5b3e2c":"code","2abc2f90":"code","8a767901":"code","f4a5b059":"code","f4594659":"code","afeb3575":"code","b8e12aed":"code","a1da77fa":"code","5f04f654":"code","ee4ce008":"code","127f3d45":"code","b2235a43":"code","fed9d4e3":"code","0bb0de72":"code","367481b5":"code","cbc30751":"markdown","e86d370e":"markdown","630f78d3":"markdown","8fd7ee1b":"markdown","af27e89e":"markdown","225ab980":"markdown","2737ede6":"markdown","a69391a5":"markdown","c02ebcf3":"markdown","79f7146b":"markdown","d3fff40a":"markdown","1ee0675a":"markdown","d50eab3b":"markdown","85a461ed":"markdown","52846489":"markdown","bb00a28b":"markdown","747e17a5":"markdown","1718d609":"markdown","23ddd3fc":"markdown","48cf6f52":"markdown","8c2b38d2":"markdown","c8911c44":"markdown","93ae94bf":"markdown","5b937a7a":"markdown","c200a571":"markdown","4f94b8bf":"markdown","9dd42179":"markdown"},"source":{"d628769b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","01a2c52c":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport math\n\n#classification\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n \n#Regression\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge, RidgeCV, ElasticNet\nfrom sklearn.ensemble import RandomForestRegressor, BaggingRegressor, GradientBoostingRegressor,AdaBoostRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neural_network import MLPRegressor\n\n# Modelling Helpers \nfrom sklearn.preprocessing import Normalizer , scale\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.model_selection import GridSearchCV , KFold , cross_val_score\n\n#preprocessing\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n\n#evaluation matrics\n\n# Regression\nfrom sklearn.metrics import mean_squared_log_error,mean_squared_error, r2_score,mean_absolute_error \n\n# Classification\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n\n\n#visualisation\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\nimport missingno as msno\n\n\n\n# Configure visualisations\n%matplotlib inline\nmpl.style.use( 'ggplot' )\nplt.style.use('fivethirtyeight')\nsns.set(context=\"notebook\", palette=\"dark\", style = 'whitegrid' , color_codes=True)\nparams = { \n    'axes.labelsize': \"large\",\n    'xtick.labelsize': 'x-large',\n    'legend.fontsize': 20,\n    'figure.dpi': 150,\n    'figure.figsize': [25, 7]\n    }\nplt.rcParams.update(params)","bfc34c03":"from IPython.core.display import HTML\nHTML(\"\"\"\n<style>\n.output_png {\n    display: table-cell;\n    text-align: center;\n    vertical-align: middle;\n}\n<\/style>\n\"\"\");","4c6e160b":"df = pd.read_csv(\"\/kaggle\/input\/insurance\/insurance.csv\")\ninsurance = df.copy","8b0bfc5e":"df.info()","bd30ec1a":"df.describe()","4c2c1cf3":"df.describe( include = ['O'])","8b11fd61":"df.head(10)","0276231d":"print(df.loc[df.bmi == 0])","c69d65b6":"sns.factorplot(data = df, kind = 'box', size = 7, aspect = 2.5)","d5290587":"df_correlation = df.corr()\nfig = plt.figure(0,figsize = (5,5))\nsns.heatmap(data = df_correlation, annot = True)","c79f4419":"sns.kdeplot(df.age, shade = True, color = 'orange')","db152674":"sns.factorplot(data = df, x = \"age\", y = \"charges\", kind = \"box\", aspect = 3.5)","51e15b77":"sns.kdeplot(df.bmi, shade = True, color = 'r')","fb449435":"sns.regplot(data = df, x = \"bmi\", y = \"charges\")","8e2b5543":"sns.kdeplot(df.children, shade = True, color = 'r')","e50f79bb":"sns.factorplot(data = df, x = \"children\", y = \"charges\", kind = \"box\", aspect = 3.5)","4cae112c":"plt.hist(df.sex)\nplt.show()","ed046c51":"sns.factorplot(data = df, x = \"sex\", y = \"charges\", kind = \"box\", aspect = 3.5)","8bee3ffe":"plt.hist(df.smoker)\nplt.show()","3fe5078c":"sns.factorplot(data = df, x = \"smoker\", y = \"charges\", kind = \"box\", aspect = 3.5)","31035302":"plt.hist(df.region)\nplt.show()","2bf8414a":"sns.factorplot(data = df, x = \"region\", y = \"charges\", kind = \"box\", aspect = 3.5)","f5257316":"label_sex = LabelEncoder()\nlabel_smoker = LabelEncoder()\nlabel_region = LabelEncoder()\n\ndf.sex = label_sex.fit_transform(df.sex)\ndf.smoker = label_smoker.fit_transform(df.smoker)\ndf.region = label_region.fit_transform(df.region)","9b2a494b":"df.head()","95e903ad":"input_cols = [\"age\",\"sex\",\"bmi\",\"children\",\"smoker\",\"region\"]\noutput_cols = [\"charges\"]","6e5b3e2c":"X_train,X_test,y_train,y_test = train_test_split(df[input_cols],df[output_cols],test_size = 0.3, random_state = 30)","2abc2f90":"ss = StandardScaler()\nX_train = ss.fit_transform(X_train)\nX_test = ss.transform(X_test)","8a767901":"accuracy = []\nmodels = [\"Linear regression\",\"Lasso\",\"Ridge\",\"Random Forest Regressor\",\"Gradient Boost\", \"AdaBoost\", \"SVR\",\"KNeighbors\",\"MLPRegressor\"]","f4a5b059":"mod = LinearRegression()\nmod.fit(X_train,y_train)\na = mod.score(X_test,y_test)\nprint(a)\naccuracy.append(a)","f4594659":"mod = Lasso()\nmod.fit(X_train,y_train)\na = mod.score(X_test,y_test)\nprint(a)\naccuracy.append(a)","afeb3575":"mod = Ridge()\nmod.fit(X_train,y_train)\na = mod.score(X_test,y_test)\nprint(a)\naccuracy.append(a)","b8e12aed":"for i in range (1,10):\n    mod = RandomForestRegressor( max_depth = i)\n    mod.fit(X_train,y_train)\n    a = mod.score(X_test,y_test)\n    print(a)\n#accuracy.append(a)","a1da77fa":"no_of_test = [100]\nparams_dict = {\"n_estimators\": no_of_test,\n               \"max_depth\":[4],\n              \"n_jobs\":[-1],\n              \"max_features\":[\"auto\",\"sqrt\",\"log2\"]}\nmod = GridSearchCV(estimator = RandomForestRegressor(),param_grid = params_dict, scoring = \"r2\")\nmod.fit(X_train,y_train)\na = mod.score(X_test,y_test)\nprint(a)\naccuracy.append(a)","5f04f654":"mod = GradientBoostingRegressor()\nmod.fit(X_train,y_train)\na = mod.score(X_test,y_test)\nprint(a)\naccuracy.append(a)","ee4ce008":"mod = AdaBoostRegressor()\nmod.fit(X_train,y_train)\na = mod.score(X_test,y_test)\nprint(a)\naccuracy.append(a)","127f3d45":"mod = SVR(kernel = \"linear\", C=5.0)\nmod.fit(X_train,y_train)\na = mod.score(X_test,y_test)\nprint(a)\naccuracy.append(a)","b2235a43":"for i in range(1,50):  \n    mod = KNeighborsRegressor(n_neighbors=i)\n    mod.fit(X_train,y_train)\n    a = mod.score(X_test,y_test)\n    print(a)\n#accuracy.append(a)","fed9d4e3":"no_of_test = [100]\nparams_dict = {\"n_neighbors\": no_of_test,\n              \"n_jobs\":[-1]\n              }\nmod = GridSearchCV(estimator = KNeighborsRegressor(),param_grid = params_dict, scoring = \"r2\")\nmod.fit(X_train,y_train)\na = mod.score(X_test,y_test)\nprint(a)\naccuracy.append(a)","0bb0de72":"mod = MLPRegressor(hidden_layer_sizes = (100,))\nmod.fit(X_train,y_train)\na = mod.score(X_test,y_test)\nprint(a)\naccuracy.append(a)","367481b5":"sns.factorplot(data = df, x = models, y = accuracy, size = 6, aspect = 4)","cbc30751":"Tuning KNeighbors","e86d370e":"### A higher price is paid by male","630f78d3":"The data is well encoded now. Can proceed for model application. First we need to do some scaling.","8fd7ee1b":"# Sex vs Charges","af27e89e":"# BMI","225ab980":"Random Forest","2737ede6":"Tuning Random Forest","a69391a5":"### We can see that most of the people taking insurance are of age 20 - 25","c02ebcf3":"Lasso","79f7146b":"### the price for the southeast region is quite high","d3fff40a":"#### Highest price is paid by senior citizens of age more than 60","1ee0675a":"Ridge","d50eab3b":"### the charges for smoker is remarkably high","85a461ed":"# Age vs Charge","52846489":"# Sex","bb00a28b":"# BMI vs Charges","747e17a5":"# Children","1718d609":"# BMI vs Charge","23ddd3fc":"KNeighbors Regressor","48cf6f52":"## Maximum accuracy by random forest regressor (84.5%)","8c2b38d2":"AdaBoost Regressor","c8911c44":"Linear Regression","93ae94bf":"Gradient Boost Regressor","5b937a7a":"# Region","c200a571":"# Age","4f94b8bf":"# Smoker","9dd42179":"SVR"}}