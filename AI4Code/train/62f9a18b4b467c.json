{"cell_type":{"c5af841d":"code","fd2f331f":"code","f736e9c9":"code","9baf6dff":"code","e2c4e60e":"code","f7ef78cc":"code","967948d5":"code","71ce71dd":"code","6cd093b2":"code","445e23ed":"code","2188ffda":"code","28989f00":"code","74f6d8ba":"code","e7b8543b":"code","7ac025df":"code","a986f1f8":"code","a492ae75":"code","59872b3f":"code","dbaf112d":"code","a45fe6b7":"code","50b4931f":"code","2c699c30":"code","9b068976":"code","8a8f3d80":"code","1ab567b2":"code","774cab05":"code","1d0ef0d3":"code","6f1db7a0":"code","198841a0":"code","c28ad572":"code","5ca8215f":"code","d8b2df7d":"code","a30f1495":"code","9effe6c7":"code","2b9499b5":"code","7de7a845":"markdown","3ad0bf99":"markdown","baec4282":"markdown","68756477":"markdown","873b38e3":"markdown","ed986517":"markdown","6980ffe1":"markdown","4eccdc29":"markdown","b3a13474":"markdown","66193f3a":"markdown"},"source":{"c5af841d":"!pip install ml_metrics","fd2f331f":"import pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nimport re\nimport random\nfrom sklearn import metrics\nimport ml_metrics as metrics\n\nfrom scipy.sparse.linalg import svds\nfrom scipy.sparse import csr_matrix, coo_matrix\n\nfrom catboost import CatBoostClassifier\n\npd.set_option('max_columns', 100)","f736e9c9":"train = pd.read_csv(\"..\/input\/amexpert-2021-challenge\/train_go05W65.csv\")\ntest = pd.read_csv(\"..\/input\/amexpert-2021-challenge\/test_VkM91FT.csv\")\nsample_submission = pd.read_csv(\"..\/input\/amexpert-2021-challenge\/sample_submission_kF044ur.csv\")","9baf6dff":"train.Product_Holding_B1 = train.Product_Holding_B1.map(lambda x : re.findall(\"P\\d+\", x))\ntrain.Product_Holding_B2 = train.Product_Holding_B2.map(lambda x : re.findall(\"P\\d+\", x))\ntest.Product_Holding_B1 = test.Product_Holding_B1.map(lambda x : re.findall(\"P\\d+\", x))","e2c4e60e":"b1_products = sorted(list(set(sum(train.Product_Holding_B1.to_list(), []))))\nb2_products = sorted(list(set(sum(train.Product_Holding_B2.to_list(), []))))","f7ef78cc":"for p in b1_products:\n    train[p] = train.Product_Holding_B1.map(lambda x : 1 if p in x else 0)\n    test[p] = test.Product_Holding_B1.map(lambda x : 1 if p in x else 0)","967948d5":"train_labels = train[['Customer_ID', 'Product_Holding_B2']]\ntest_labels = test[['Customer_ID']]\n\nfor p in b2_products:\n    train_labels[p] = train_labels.Product_Holding_B2.map(lambda x : 1 if p in x else 0)\n    test_labels[p] = 0\ntrain_labels.drop('Product_Holding_B2', axis = 1, inplace = True)\ntrain_labels = train_labels.melt(id_vars=['Customer_ID']).rename(columns = {'variable' : 'product', 'value' : 'target'})\ntest_labels = test_labels.melt(id_vars=['Customer_ID']).rename(columns = {'variable' : 'product'}).drop('value', axis =1)\ntrain1 = train.merge(train_labels, on = 'Customer_ID')\ntest1 = test.merge(test_labels, on = 'Customer_ID')\n","71ce71dd":"product_counts = train[b1_products].append(test[b1_products]).sum().to_dict()\ntrain1['product_counts'] = train1['product'].map(product_counts)\ntest1['product_counts'] = test1['product'].map(product_counts)","6cd093b2":"count_matrix = train[b1_products].append(test[b1_products])\ncount_matrix = pd.DataFrame(np.matmul(count_matrix.values.T, count_matrix.values), columns = b1_products)\ncount_matrix['product'] = b1_products\ncount_matrix = count_matrix.set_index('product')","445e23ed":"train1['pair_count_max'] = [max([count_matrix[p][row.product] for p in row.Product_Holding_B1]) \n                            for row in train1.itertuples()]\ntest1['pair_count_max'] = [max([count_matrix[p][row.product] for p in row.Product_Holding_B1]) \n                           for row in test1.itertuples()]\n\ntrain1['pair_count_min'] = [min([count_matrix[p][row.product] for p in row.Product_Holding_B1]) \n                            for row in train1.itertuples()]\ntest1['pair_count_min'] = [min([count_matrix[p][row.product] for p in row.Product_Holding_B1]) \n                           for row in test1.itertuples()]","2188ffda":"train1['product_count_max'] = train1['Product_Holding_B1'].map(lambda x : max([product_counts[p] for p in x]))\ntrain1['product_count_min'] = train1['Product_Holding_B1'].map(lambda x : min([product_counts[p] for p in x]))\n\ntest1['product_count_max'] = test1['Product_Holding_B1'].map(lambda x : max([product_counts[p] for p in x]))\ntest1['product_count_min'] = test1['Product_Holding_B1'].map(lambda x : min([product_counts[p] for p in x]))\n","28989f00":"train1['Gender_Male'] = 1*(train1['Gender'] == \"Male\")\ntest1['Gender_Male'] = 1*(test1['Gender'] == \"Male\")\n\ntrain1['City_Category_C1'] = 1*(train1.City_Category == \"C1\")\ntest1['City_Category_C1'] = 1*(test1.City_Category == \"C1\")\n\ntrain1['Customer_Category_S1'] = 1*(train1.Customer_Category == \"S1\")\ntrain1['Customer_Category_S2'] = 1*(train1.Customer_Category == \"S2\")\ntest1['Customer_Category_S1'] = 1*(test1.Customer_Category == \"S1\")\ntest1['Customer_Category_S2'] = 1*(test1.Customer_Category == \"S2\")","74f6d8ba":"train1['Product_Holding_B1_len'] = train1['Product_Holding_B1'].map(len)\ntest1['Product_Holding_B1_len'] = test1['Product_Holding_B1'].map(len)","e7b8543b":"train1['self'] = [row.product in row.Product_Holding_B1 for row in train1.itertuples()]\ntest1['self'] = [row.product in row.Product_Holding_B1 for row in test1.itertuples()]","7ac025df":"train1 = train1[~((train1['self'] == 1) & (train1['product'] != \"P00\"))]\ntest1 = test1[~((test1['self'] == 1) & (test1['product'] != \"P00\"))]","a986f1f8":"train1['vintage_by_age'] = train1['Vintage'] \/ train1['Age']\ntest1['vintage_by_age'] = test1['Vintage'] \/ test1['Age']","a492ae75":"train1['id'] = train1['Customer_ID'].map(lambda x : int(x.replace(\"CC\", \"\")))\ntest1['id'] = test1['Customer_ID'].map(lambda x : int(x.replace(\"CC\", \"\")))","59872b3f":"from scipy.sparse.linalg import svds\nfrom scipy.sparse import csr_matrix, coo_matrix\n\ndf = train1[['id'] + b1_products].append(test1[['id'] + b1_products]).drop_duplicates()\ndf['id'] = df['id'] \/\/ 10\ndf = df.groupby('id').sum()\n                                        \nR = coo_matrix(df.values).asfptype()\nU, sigma, Vt = svds(R, k = 8)\ndf1 = pd.DataFrame(np.matmul(U, Vt))\ndf1['id'] = df.index\ndf1 = df1.set_index('id')\ndf1.columns = b1_products\nsvd_score = df1.to_dict()\n\ntrain1['svd_score1'] = [svd_score[row.product][row.id \/\/10] for row in train1.itertuples()]\ntest1['svd_score1'] = [svd_score[row.product][row.id \/\/ 10] for row in test1.itertuples()]\n","dbaf112d":"from scipy.sparse.linalg import svds\nfrom scipy.sparse import csr_matrix, coo_matrix\n\ndf = train1[['id'] + b1_products].append(test1[['id'] + b1_products]).drop_duplicates()\ndf['id'] = df['id'] \/\/ 100\ndf = df.groupby('id').sum()\n                                        \nR = coo_matrix(df.values).asfptype()\nU, sigma, Vt = svds(R, k = 8)\ndf1 = pd.DataFrame(np.matmul(U, Vt))\ndf1['id'] = df.index\ndf1 = df1.set_index('id')\ndf1.columns = b1_products\nsvd_score = df1.to_dict()\n\ntrain1['svd_score2'] = [svd_score[row.product][row.id \/\/100] for row in train1.itertuples()]\ntest1['svd_score2'] = [svd_score[row.product][row.id \/\/ 100] for row in test1.itertuples()]\n","a45fe6b7":"from scipy.sparse.linalg import svds\nfrom scipy.sparse import csr_matrix, coo_matrix\n\ndf = train1[['id'] + b1_products].append(test1[['id'] + b1_products]).drop_duplicates()\ndf['id'] = df['id'] \/\/ 1000\ndf = df.groupby('id').sum()\n                                        \nR = coo_matrix(df.values).asfptype()\nU, sigma, Vt = svds(R, k = 8)\ndf1 = pd.DataFrame(np.matmul(U, Vt))\ndf1['id'] = df.index\ndf1 = df1.set_index('id')\ndf1.columns = b1_products\nsvd_score = df1.to_dict()\n\ntrain1['svd_score3'] = [svd_score[row.product][row.id \/\/1000] for row in train1.itertuples()]\ntest1['svd_score3'] = [svd_score[row.product][row.id \/\/ 1000] for row in test1.itertuples()]\n","50b4931f":"target_counts = train1[train1['target'] == 1]['product'].value_counts().to_dict()\n\ntrain1['product_target_count'] = train1['product'].map(target_counts)\ntest1['product_target_count'] = test1['product'].map(target_counts)\n","2c699c30":"b1_count = train.append(test).Product_Holding_B1.astype(str).value_counts().to_dict()\ntrain1['b1_count'] = train1['Product_Holding_B1'].astype(str).map(b1_count)\ntest1['b1_count'] = test1['Product_Holding_B1'].astype(str).map(b1_count)\n","9b068976":"train1['product1'] = train1['product'].map(lambda x : int(x.replace(\"P\", \"\")))\ntest1['product1'] = test1['product'].map(lambda x : int(x.replace(\"P\", \"\")))","8a8f3d80":"train1.columns","1ab567b2":"indep_vars = [\n    'Age',\n    'Vintage', 'Is_Active', 'P00',\n       'P1', 'P10', 'P11', 'P12', 'P13', 'P14', 'P15', 'P16', 'P17', 'P18',\n       'P19', 'P2', 'P20', 'P21', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'product_counts', 'pair_count_max',\n              'Gender_Male',\n       'City_Category_C1', 'Customer_Category_S1', 'Customer_Category_S2', 'Product_Holding_B1_len',\n             'vintage_by_age', 'product_count_max',\n       'product_count_min', 'pair_count_min', 'svd_score1', 'svd_score2', \n    'svd_score3',\n    'product_target_count', 'b1_count', 'id',\n              'product1'\n             ]\nlen(indep_vars)","774cab05":"clf = CatBoostClassifier(\n    iterations=8000,\n    eval_metric = 'AUC',\n    learning_rate = 0.03,\n    verbose=500,\n)\n\nrandom.seed(2)\ndev_ids = random.sample(train.Customer_ID.to_list(), 30000)\ndev = train1[train1.Customer_ID.isin(dev_ids)]\nval = train1[train1.Customer_ID.isin(dev_ids) == False]\n\n\nclf.fit(\n    dev[indep_vars], dev.target,\n    eval_set=(val[indep_vars], val.target),\n)","1d0ef0d3":"val['pred_cat'] = clf.predict_proba(val[indep_vars])[:,1]","6f1db7a0":"df = val.sort_values(by = ['Customer_ID', 'pred_cat'], ascending = False)\nactuals = df[df.target == 1][['Customer_ID', 'product']].groupby('Customer_ID').agg(list)['product'].to_list()\npredicted = df.groupby('Customer_ID').head(3).groupby('Customer_ID').agg(list)['product'].to_list()\nmetrics.mapk(actuals, predicted, k=3)","198841a0":"params = {\n    'task': 'train',\n    'boosting_type': 'gbdt',\n    'objective':'binary',\n    'metric': {'auc'},\n    'num_leaves': 96,\n    'learning_rate': 0.01,\n    'feature_fraction': 0.5,\n    'bagging_fraction': 0.5,\n    'bagging_freq': 1,\n    'verbose': 1,\n    'min_data_in_leaf' : 1,\n    'max_bin' : 255,\n    'lambda_l1' : 0.00002,\n    'lambda_l2' : 0.00001,\n    'min_gain_to_split' : 0.001\n}\n\n# random.seed(2)\n# dev_ids = random.sample(train.Customer_ID.to_list(), 30000)\n# dev = train1[train1.Customer_ID.isin(dev_ids)]\n# val = train1[train1.Customer_ID.isin(dev_ids) == False]\nlgb_dev = lgb.Dataset(dev[indep_vars], dev['target'])\nlgb_val = lgb.Dataset(val[indep_vars], val['target'])\n\nmodel = lgb.train(params, lgb_dev, num_boost_round = 5000, valid_sets = (lgb_val), early_stopping_rounds = 500,\n                 verbose_eval = 100)","c28ad572":"val['pred_lgb'] = model.predict(val[indep_vars])\ndf = val.sort_values(by = ['Customer_ID', 'pred_lgb'], ascending = False)\nactuals = df[df.target == 1][['Customer_ID', 'product']].groupby('Customer_ID').agg(list)['product'].to_list()\npredicted = df.groupby('Customer_ID').head(3).groupby('Customer_ID').agg(list)['product'].to_list()\nmetrics.mapk(actuals, predicted, k=3)","5ca8215f":"val['pred'] = (val['pred_cat']**2 * 0.05 + val['pred_lgb']**2 * 0.95).map(np.sqrt)\ndf = val.sort_values(by = ['Customer_ID', 'pred'], ascending = False)\nactuals = df[df.target == 1][['Customer_ID', 'product']].groupby('Customer_ID').agg(list)['product'].to_list()\npredicted = df.groupby('Customer_ID').head(3).groupby('Customer_ID').agg(list)['product'].to_list()\nmetrics.mapk(actuals, predicted, k=3)","d8b2df7d":"clf = CatBoostClassifier(\n    iterations=7777,\n    learning_rate = 0.03,\n    verbose=500,\n    eval_metric = 'AUC'\n)\nclf.fit(train1[indep_vars], train1.target)","a30f1495":"lgb_train = lgb.Dataset(train1[indep_vars], train1['target'])\nmodel = lgb.train(params, lgb_train, num_boost_round = 3690)","9effe6c7":"test1['pred_cat'] = clf.predict_proba(test1[indep_vars])[:,1]\ntest1['pred_lgb'] = model.predict(test1[indep_vars])\ntest1['pred'] = (test1['pred_cat']* 0.5 + test1['pred_lgb']* 0.5)","2b9499b5":"test1.sort_values(by = ['Customer_ID', 'pred'], ascending = False).groupby('Customer_ID').head(3).groupby(\n    'Customer_ID').agg(list)['product'].reset_index().rename(columns = {\"product\" : \"Product_Holding_B2\"}).to_csv(\".\/submission.csv\", index = False)","7de7a845":"## 2. Import the train, test and sample submission csv file","3ad0bf99":"## 8. Create the parameter list for running Light GBM algorithm\n\nBelow article has sample code and good explaination about how this algorithm works\n\nhttps:\/\/www.geeksforgeeks.org\/lightgbm-light-gradient-boosting-machine\/","baec4282":"## 4. Feature engineering to create some additional independent variables","68756477":"## 3. Data transformations to ensure the product holding are in correct format","873b38e3":"## 9. Predicting the output as average of the prediction coming from LightGBM and Catboost algorithm","ed986517":"## 5. Create binary variables for categorical variables like Gender, City etc.","6980ffe1":"## All credit of this notebook goes to @sourabhjha, who is Kaggle competition master and just won top honors at Analytics Vidhya competition as well.","4eccdc29":"## 6. Create SVD (Singular Value Decomposition) matrix based on the product holdings\n\nPlease refer to this wiki link for more details\n\nhttps:\/\/en.wikipedia.org\/wiki\/Singular_value_decomposition","b3a13474":"## 7. Create a list of independent variables for running the CatBoost algorithm\n\nArticle below has comprehensive coverage of CatBoost algorithm\n\nhttps:\/\/towardsdatascience.com\/https-medium-com-talperetz24-mastering-the-new-generation-of-gradient-boosting-db04062a7ea2","66193f3a":"## 1. Import the necessary libraries"}}