{"cell_type":{"2d4358f5":"code","0b278d11":"code","80dccee9":"code","d9a48297":"code","759d45aa":"code","2749af3a":"code","ee2b2b45":"code","b3cb97f3":"code","9cb0adee":"code","35b57b10":"code","805df99b":"code","6e2e1315":"code","94e69e42":"code","2646f674":"code","8626bea8":"code","4ccd5144":"code","73e9a6d9":"code","8de03f12":"code","b26f8f97":"code","8a66ea8a":"code","1c9d7cbf":"code","e235d492":"code","4a0a1688":"code","6143626c":"code","4f4e44ce":"code","ffc70f1f":"code","c81c11dc":"markdown","a157714d":"markdown","d535ace2":"markdown","aded6ba1":"markdown","4821b0f4":"markdown","8541a6bf":"markdown","470a101d":"markdown","feafe13f":"markdown","4604e80e":"markdown","c4bef7b8":"markdown","568101c6":"markdown","f3686a1d":"markdown","7a5ed1e5":"markdown","fa37fcd4":"markdown","51012143":"markdown","81af681e":"markdown","eca819c1":"markdown","d7df8644":"markdown","28a64960":"markdown","317fed80":"markdown","61c85dba":"markdown","ea2ca4fd":"markdown","4ce8aeb2":"markdown","5c73b588":"markdown"},"source":{"2d4358f5":"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"ticks\")\n%matplotlib inline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten ,Conv2D, MaxPooling2D\nfrom keras.preprocessing.image import ImageDataGenerator","0b278d11":"train_data = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\n\nprint(f'Training Data size is : {train_data.shape}')\nprint(f'Test Data size is : {test_data.shape}')","80dccee9":"train_data.head()\n","d9a48297":"test_data.head()","759d45aa":"train_data.shape","2749af3a":"# Then we can define X & y data\n\nX = train_data.drop(['label'], axis=1, inplace=False)\ny = train_data['label']\n\nprint('X shape is ' , X.shape)\nprint('y shape is ' , y.shape)","ee2b2b45":"plt.figure(figsize=(12,10))\nplt.style.use('ggplot')\nfor i in  range(20)  :\n    plt.subplot(4,5,i+1)\n    plt.imshow(X.values[ np.random.randint(1,X.shape[0])].reshape(28,28))","b3cb97f3":"y.value_counts()","9cb0adee":"plt.figure(figsize=(12,12))\nplt.pie(y.value_counts(),labels=list(y.value_counts().index),autopct ='%1.2f%%' ,\n        labeldistance = 1.1,explode = [0.05 for i in range(len(y.value_counts()))] )\nplt.show()","35b57b10":"X = X \/ 255.0\ntest_data = test_data \/ 255.0","805df99b":"X.shape\n","6e2e1315":"X = X.values.reshape(-1,28,28,1)\ntest_data = test_data.values.reshape(-1,28,28,1)","94e69e42":"X.shape\n","2646f674":"test_data.shape","8626bea8":"ohe  = OneHotEncoder()\ny = np.array(y)\ny = y.reshape(len(y), 1)\nohe.fit(y)\ny = ohe.transform(y).toarray()","4ccd5144":"y.shape","73e9a6d9":"X_part, X_cv, y_part, y_cv = train_test_split(X, y, test_size=0.15, random_state=44, shuffle =True)\n\nprint('X_train shape is ' , X_part.shape)\nprint('X_test shape is ' , X_cv.shape)\nprint('y_train shape is ' , y_part.shape)\nprint('y_test shape is ' , y_cv.shape)","8de03f12":"X_train, X_test, y_train, y_test = train_test_split(X_part, y_part, test_size=0.25, random_state=44, shuffle =True)\n\nprint('X_train shape is ' , X_train.shape)\nprint('X_test shape is ' , X_test.shape)\nprint('y_train shape is ' , y_train.shape)\nprint('y_test shape is ' , y_test.shape)","b26f8f97":"image_shape = (28,28,1)\nDigiModel = keras.models.Sequential([\n        keras.layers.Conv2D(filters = 32, kernel_size = (5,5),  activation = tf.nn.relu , padding = 'same',input_shape=(28, 28, 1)),\n        keras.layers.Conv2D(filters = 32, kernel_size = (5,5),  activation = tf.nn.relu , padding = 'same'),\n        keras.layers.MaxPool2D(pool_size=(2,2), strides=None, padding='valid'),\n        keras.layers.Dropout(0.25),\n        keras.layers.BatchNormalization(),\n    \n        keras.layers.Conv2D(filters=64, kernel_size=(3,3),activation = tf.nn.relu , padding='same'),\n        keras.layers.Conv2D(filters=64, kernel_size=(3,3),activation = tf.nn.relu , padding='same'),\n        keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n        keras.layers.Dropout(0.25),\n        keras.layers.BatchNormalization(),\n            \n        keras.layers.Flatten(),           \n        keras.layers.Dense(256, activation=\"relu\"),    \n        keras.layers.Dropout(0.45),            \n        keras.layers.Dense(units= 10,activation = tf.nn.softmax ),                \n\n    ])","8a66ea8a":"DigiModel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n","1c9d7cbf":"DigiModel.fit(X_train,y_train,validation_data=(X_cv, y_cv),epochs=16,batch_size=64,verbose=1)","e235d492":"DigiModel.summary()","4a0a1688":"ModelLoss, ModelAccuracy = DigiModel.evaluate(X_test, y_test)\n\nprint('Test Loss is {}'.format(ModelLoss))\nprint('Test Accuracy is {}'.format(ModelAccuracy ))","6143626c":"y_pred = DigiModel.predict(X_test)\n\nprint('Prediction Shape is {}'.format(y_pred.shape))","4f4e44ce":"for i in list(np.random.randint(0,len(X_test) ,size= 20)) : \n    print(f'for sample  {i}  the predicted value is   {np.argmax(y_pred[i])}   , while the actual letter is {np.argmax(y_test[i])}')\n    if np.argmax(y_pred[i]) != np.argmax(y_test[i]) : \n        print('==============================')\n        print('Found mismatch . . ')\n        plt.figure(figsize=(5,5))\n        plt.style.use('ggplot')\n        plt.imshow(X_test[i].reshape(28,28))\n        plt.show()","ffc70f1f":"FinalResults = DigiModel.predict(test_data)\nFinalResults = pd.Series(np.argmax(FinalResults,axis = 1) ,name=\"Label\")\n\nFileSubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),FinalResults],axis = 1)\nFileSubmission.to_csv(\"sample_submission.csv\",index=False)","c81c11dc":"Great result","a157714d":"Check X dimension","d535ace2":"# Model Summery","aded6ba1":"Check test data dimension","4821b0f4":" Check X dimension again","8541a6bf":"Checking accuracy on test data","470a101d":"We have to categorize y then convert single numbers like (7) into One Hot Matrix like [0 0 0 0 0 0 1 0 0 0]","feafe13f":"Then we need to reshape them , to be 4 dimensions , so first dimension will be open for all sample size , then 28 x 28 as image size , then 1","4604e80e":"Check y dimension","c4bef7b8":"Check random 20 samples,  \nWe need to have a look to any mismatch images, to see why it confused","568101c6":"# Building The Model","f3686a1d":" Start training for 16 epochs, Without exceeding to avoid any OverFitting","7a5ed1e5":"Checking Random Numbers from the data","fa37fcd4":"Predict the result","51012143":"We also need to be sure that output numbers are kinda equally distributed\n\n","81af681e":"# IMPOR LIBRARIES ","eca819c1":"# Submission ","d7df8644":"Complie the model using adam optimizer & loss function: categorical crossentropy, since it's multilassifier\n\n","28a64960":"LETS CHECK THE DATA","317fed80":"# Data Splitting \n\nWe have to split our data twice,\nfirst to get cross-validation data,then to get test data\nso first we'll get X_part, X_cv, y_part, y_cv,\nthen later we'll divide \"part\" into training & testing data","61c85dba":"# LOADING DATA","ea2ca4fd":"# Dimension Adjusting\nit;s very important to adjust dimensions for data before building the CNN , let;s first normalize both X & test data .\n\nofcourse y will not be normalized or it will mislead the training","4ce8aeb2":"Great,let's make a pie chart for it\n\n","5c73b588":"Great, Now we'll split part into train & test data,\nso we can test the accuracy percisely\n\n"}}