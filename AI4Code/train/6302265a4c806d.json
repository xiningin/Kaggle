{"cell_type":{"e431efa5":"code","f1d1f9d0":"code","fe2ffb3c":"code","ca3ea72c":"code","28765782":"code","4024b4a4":"code","a4dabf6b":"code","6bcabf24":"code","4d500e17":"code","5be0299e":"code","c593ccd9":"code","179c0fed":"code","9c5e8455":"code","b9ca3b0f":"code","46ec5554":"code","1f767bcf":"code","d034c66a":"code","fc9bd19a":"code","740f5a49":"code","94f55769":"code","e8d1eac4":"code","f0d1188b":"code","c32e04d0":"code","ee70c41f":"code","b5e1f61b":"code","76cad113":"code","63f854d9":"code","97699e02":"code","544bc9b7":"code","2a6d1bfa":"code","85cc984b":"code","52ce6ca2":"code","893a500b":"code","ba950d1a":"code","c223b66a":"code","2b883111":"code","571b838d":"code","16b3c43e":"code","bba8fd31":"code","2bb6a611":"code","cc2d2513":"code","6af15a62":"code","bc33fe45":"code","f89907e5":"markdown"},"source":{"e431efa5":"# loading all necessary libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport xgboost as xgb\nimport os\n\nfrom itertools import product\nfrom tqdm import tqdm_notebook\n\nprint(os.listdir(\"..\/input\"))","f1d1f9d0":"# loading competition data\nitems = pd.read_csv('..\/input\/items.csv')\nitem_categories = pd.read_csv('..\/input\/item_categories.csv')\nshops = pd.read_csv('..\/input\/shops.csv')\nsales = pd.read_csv('..\/input\/sales_train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","fe2ffb3c":"# sales are groupedby category_id\nsales = pd.merge(sales, items, on='item_id', how='left')\nsales = sales.drop('item_name', axis=1)\nsales.head()","ca3ea72c":"index_cols = ['shop_id', 'item_id', 'date_block_num']","28765782":"# creating df of all item and store combos in order to assure the ML algorithim knows the sales are 0\ngrid = []\nfor block_num in sales['date_block_num'].unique():\n    cur_shops = sales.loc[sales['date_block_num'] == block_num, 'shop_id'].unique()\n    cur_items = sales.loc[sales['date_block_num'] == block_num, 'item_id'].unique()\n    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])), dtype='int32'))\ngrid = pd.DataFrame(np.vstack(grid), columns = index_cols, dtype=np.int32)","4024b4a4":"# display the grid and make observations that determine if im ready to move onto the next step\ngrid.head()","a4dabf6b":"# preparing to create mean encodings by grouping the sales in order to create much needed lagged values for this time-series problem\nmean_sales = sales.groupby(['date_block_num', 'shop_id', 'item_id']).agg({'item_cnt_day':'sum','item_price':np.mean}).reset_index()","6bcabf24":"#filling in NAs with 0s\nmean_sales = pd.merge(grid,mean_sales,on=['date_block_num', 'shop_id', 'item_id'],how='left').fillna(0)","4d500e17":"# merge back to grid\nmean_sales = pd.merge(mean_sales, items, on='item_id',how='left')","5be0299e":"mean_sales.head()","c593ccd9":"# actually creating the mean encoding feature now\n# added a total of 9 features to further develop and prepare the data\nfor type_id in ['item_id', 'shop_id', 'item_category_id']:\n    for column_id, aggregator, aggtype in [('item_price',np.mean,'avg'),('item_cnt_day',np.sum,'sum'),('item_cnt_day',np.mean,'avg')]:\n# grouping indivudally by shop, item, and category id which was hinted at during the lectures from the course        \n        mean_df = sales.groupby([type_id,'date_block_num']).aggregate(aggregator).reset_index()[[column_id,type_id,'date_block_num']]\n        mean_df.columns = [type_id+'_'+aggtype+'_'+column_id,type_id,'date_block_num']\n        mean_sales = pd.merge(mean_sales, mean_df, on=['date_block_num',type_id], how='left')\n","179c0fed":"mean_sales.head(25)","9c5e8455":"# creating lag features in order to achieve a lag value which is crucial to predictting\nlag_variables  = list(mean_sales.columns[7:])+['item_cnt_day']\nlags = [1, 2, 3, 6]\nfor lag in tqdm_notebook(lags):\n# this should keep the same mean encoded features that are needed but lagging them\n    sales_new_df = mean_sales.copy()\n    sales_new_df.date_block_num += lag\n    sales_new_df = sales_new_df[['date_block_num','shop_id','item_id']+lag_variables]\n    sales_new_df.columns = ['date_block_num','shop_id','item_id']+ [lag_feat+'_lag_'+str(lag) for lag_feat in lag_variables]\n    mean_sales = pd.merge(mean_sales, sales_new_df,on=['date_block_num','shop_id','item_id'] ,how='left')","b9ca3b0f":"mean_sales.head()","46ec5554":"# filling all of the N\/As with 0s again\nmean_sales = mean_sales[mean_sales['date_block_num']>12]","1f767bcf":"# filling N\/As with 0s cont.\nfor feat in mean_sales.columns:\n    if 'item_cnt' in feat:\n        mean_sales[feat]=mean_sales[feat].fillna(0)\n    elif 'item_price' in feat:\n        mean_sales[feat]=mean_sales[feat].fillna(mean_sales[feat].median())","d034c66a":"# dropping all of the non-lagged columns\ncols_to_drop = lag_variables[:-1] + ['item_price', 'item_name']","fc9bd19a":"training = mean_sales.drop(cols_to_drop,axis=1)","740f5a49":"# begin the training of the model!\n# xgboost seemed to me to be the most time efficient while remaining the most accurate and percise so i settled on it\n# as well as it making the most sense to me through lectures\nxgbtrain = xgb.DMatrix(training.iloc[:, training.columns != 'item_cnt_day'].values, training.iloc[:, training.columns == 'item_cnt_day'].values)","94f55769":"# specifying parameters to train and eventually obtain a predcition from...these were selected specifically so they would not crash the jupyter notebook\nparam = {'max_depth':10, \n         'subsample':1,\n         'min_child_weight':0.5,\n         'eta':0.3, \n         'num_round':1000, \n         'seed':1,\n         'silent':0,\n         'eval_metric':'rmse'}\nbst = xgb.train(param, xgbtrain)","e8d1eac4":"x=xgb.plot_importance(bst)\nx.figure.set_size_inches(10, 20) ","f0d1188b":"cols = list(training.columns)\ndel cols[cols.index('item_cnt_day')] # eliminate target feature col name","c32e04d0":"# based on xgb.plot_importance it is clear these are the most important features and were selected for that very reason\n[cols[x] for x in [5, 8, 0, 2, 3, 4, 9, 33, 23]]","ee70c41f":"# prep the predictions data\ntraining.columns","b5e1f61b":"test = pd.read_csv('..\/input\/test.csv')\ntest.head()","76cad113":"# add the month which we are trying to predict sales for\ntest['date_block_num'] = 34","63f854d9":"# adding category ids\ntest = pd.merge(test, items, on='item_id', how='left')","97699e02":"# lastly, adding lagging to our prediction\nfrom tqdm import tqdm_notebook\nfor lag in tqdm_notebook(lags):\n\n    sales_new_df = mean_sales.copy()\n    sales_new_df.date_block_num += lag\n    sales_new_df = sales_new_df[['date_block_num','shop_id','item_id']+lag_variables]\n    sales_new_df.columns = ['date_block_num','shop_id','item_id']+ [lag_feat+'_lag_'+str(lag) for lag_feat in lag_variables]\n    test = pd.merge(test, sales_new_df,on=['date_block_num','shop_id','item_id'] ,how='left')","544bc9b7":"# now time to validate the lag\n_test = set(test.drop(['ID', 'item_name'], axis=1).columns)\n_training = set(training.drop('item_cnt_day',axis=1).columns)\nfor i in _test:\n    assert i in _training\nfor i in _training:\n    assert i in _test","2a6d1bfa":"assert _training == _test","85cc984b":"test = test.drop(['ID', 'item_name'], axis=1)","52ce6ca2":"for feat in test.columns:\n    if 'item_cnt' in feat:\n        test[feat]=test[feat].fillna(0)\n    elif 'item_price' in feat:\n        test[feat]=test[feat].fillna(test[feat].median())","893a500b":"test[['shop_id','item_id']+['item_cnt_day_lag_'+str(x) for x in [1,2,3]]].head()","ba950d1a":"print(training[training['shop_id'] == 5][training['item_id'] == 5037][training['date_block_num'] == 33]['item_cnt_day'])\nprint(training[training['shop_id'] == 5][training['item_id'] == 5037][training['date_block_num'] == 32]['item_cnt_day'])\nprint(training[training['shop_id'] == 5][training['item_id'] == 5037][training['date_block_num'] == 31]['item_cnt_day'])","c223b66a":"# Predicition Time!\nxgbpredict = xgb.DMatrix(test.values)","2b883111":"pred = bst.predict(xgbpredict)","571b838d":"pd.Series(pred).describe()","16b3c43e":"pred = pred.clip(0, 20)","bba8fd31":"pred.sum()","2bb6a611":"pd.Series(pred).describe()","cc2d2513":"sub_df = pd.DataFrame({'ID':test.index,'item_cnt_month': pred })","6af15a62":"sub_df.head()","bc33fe45":"sub_df.to_csv('submission.csv',index=False)","f89907e5":"squashed all of the bugs!"}}