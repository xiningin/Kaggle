{"cell_type":{"b0231aed":"code","48a31dbb":"code","d4c5d39a":"code","e1bb38a0":"code","f3564ccf":"code","90bff5cd":"code","39ffe3b4":"code","f3005915":"code","ecc694e2":"code","cee3bccd":"code","a804f06e":"code","8d510094":"code","11329f35":"code","4ba83337":"code","18b58a7a":"code","2921f5c5":"code","ade5ef73":"code","d588bf63":"code","86175d9c":"code","674e6254":"code","09259090":"code","9667e207":"code","c816e468":"code","979956d1":"code","e5801551":"code","2d5333ef":"code","cc93f4c6":"code","d8a33f8f":"code","35c2d5ec":"code","e3cd2648":"code","494d0b91":"code","7b7f85c1":"code","718069d7":"code","c4fa70af":"code","3184e49e":"code","a01d268a":"code","67b0bfb4":"code","ba77ccbe":"code","3a42e4ad":"code","6d70fcd7":"code","1f95918c":"code","ecadd298":"code","f2877074":"code","0d9ed8d5":"code","09c1a8c9":"code","7ee623af":"code","22136538":"code","5750cf10":"code","75b9caae":"code","1350b3b4":"code","c157e838":"code","04d79b3a":"code","de2c5b60":"code","25740dfd":"code","2b29fcf3":"code","c35c0cb1":"code","d22f2868":"code","6ef56dc0":"code","30590e36":"code","9616db70":"code","7b6002a9":"code","91af7c1a":"code","5bf471d8":"code","d9ba9cfa":"code","059dff92":"code","9d2fbadf":"code","7263f2ec":"code","b3abc6a3":"code","4e86e779":"code","4c838994":"code","cc1e08f6":"code","67e01aeb":"code","519f0491":"code","791da367":"code","b8d0efd9":"code","b83f84f0":"code","b42ebe43":"code","e937b55b":"code","df7b5f28":"code","78cc3bdb":"code","452dbe51":"code","38768508":"code","a33726b8":"code","1af151e5":"code","49bf79cc":"code","929351ab":"code","f1eae963":"code","173ee151":"code","3cf4aead":"code","4703dabf":"code","4829e4e3":"code","19dda3d7":"code","4974c208":"code","336d6f57":"code","da18ac2f":"code","08a84328":"code","4b707d0d":"code","a6789af2":"code","ba238933":"code","4fc86afe":"code","3f11ba26":"code","00c781ff":"code","0b71e6d6":"code","b657eab9":"code","5302b059":"code","e498a8d9":"code","4761018a":"code","0a2e4130":"code","8f3d3d8d":"code","123b35f5":"code","32577455":"markdown","350eee0a":"markdown","0316c01c":"markdown","1a1acce8":"markdown","4d36ee1d":"markdown","cd44b9e2":"markdown","32640d63":"markdown","77fdec8d":"markdown","6e2deb98":"markdown","a87d06f6":"markdown","09c1f822":"markdown","335e7bf5":"markdown","ef035884":"markdown","d93d2406":"markdown","44089f34":"markdown","a6396874":"markdown","2a73c0d5":"markdown","2a8d2a5b":"markdown","63ee6667":"markdown","4ab80140":"markdown","28361ae1":"markdown","49fd7a5f":"markdown","8e3daa93":"markdown","a9ee321d":"markdown","0f47b5b9":"markdown","f9bddabb":"markdown","8cc0d1d2":"markdown","f19f9fe2":"markdown","5f8a1c6b":"markdown","8805ec62":"markdown","b7230500":"markdown"},"source":{"b0231aed":"!pip install scikit-learn --upgrade\n!pip install scipy --upgrade\n!pip install sklearn --upgrade","48a31dbb":"!pip install scikit-learn==0.22.2","d4c5d39a":"\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\nimport os\n\nimport pandas as pd \n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\n\nfrom pandas.api.types import is_string_dtype\nfrom pandas.api.types import is_numeric_dtype\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.externals.six import StringIO  \nfrom sklearn import tree\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import export_graphviz\n\nimport statsmodels\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\nimport pydotplus\nfrom IPython.display import Image  \nimport graphviz\n\n","e1bb38a0":"pd.options.display.max_columns = None\n\npd.options.display.max_rows = None\n\nnp.set_printoptions(suppress=True)","f3564ccf":"df=pd.read_csv('..\/input\/mri-and-alzheimers\/oasis_longitudinal.csv')\ndf.head()","90bff5cd":"df.shape","39ffe3b4":"df.describe()","f3005915":"df.describe(include='object')","ecc694e2":"df = df.loc[df['Visit']==1] # use first visit data only because of the analysis we're doing\ndf = df.reset_index(drop=True) # reset index after filtering first visit data\ndf['M\/F'] = df['M\/F'].replace(['F','M'], [0,1]) # M\/F column\ndf['Group'] = df['Group'].replace(['Converted'], ['Demented']) # Target variable\ndf['Group'] = df['Group'].replace(['Demented', 'Nondemented'], [1,0]) # Target variable\ndf = df.drop(['MRI ID', 'Visit', 'Hand'], axis=1) # Drop unnecessary columns","cee3bccd":"df.head()","a804f06e":"sns.countplot(df['M\/F'],hue=df['Group'])","8d510094":"col=['EDUC','MMSE','eTIV','nWBV','ASF'] #SES CDR categorical ","11329f35":"plt.rcParams['figure.figsize']=(15,10)\n\n# plot the histogram of numeric variables\n# Note: the hist() function considers the numeric variables only, by default\nfig, ax = plt.subplots(3,2, figsize=(25, 20))\nfor i, subplot in zip(col, ax.flatten()):\n    sns.kdeplot(df[i],ax=subplot)","4ba83337":"facet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\nfacet.map(sns.kdeplot,'MMSE',shade= True)\nfacet.set(xlim=(0, df['MMSE'].max()))\nfacet.add_legend()\nplt.xlim(15.30)\n    ","18b58a7a":"#bar_chart('ASF') = Atlas Scaling Factor\nfacet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\nfacet.map(sns.kdeplot,'ASF',shade= True)\nfacet.set(xlim=(0, df['ASF'].max()))\nfacet.add_legend()\nplt.xlim(0.5, 2)\n\n#eTIV = Estimated Total Intracranial Volume\nfacet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\nfacet.map(sns.kdeplot,'eTIV',shade= True)\nfacet.set(xlim=(0, df['eTIV'].max()))\nfacet.add_legend()\nplt.xlim(900, 2100)\n\n#'nWBV' = Normalized Whole Brain Volume\n# Nondemented = 0, Demented =1\nfacet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\nfacet.map(sns.kdeplot,'nWBV',shade= True)\nfacet.set(xlim=(0, df['nWBV'].max()))\nfacet.add_legend()\nplt.xlim(0.6,0.9)","2921f5c5":"#AGE. Nondemented =0, Demented =0\nfacet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, df['Age'].max()))\nfacet.add_legend()\nplt.xlim(50,100)","ade5ef73":"sns.barplot(y=df.MMSE, x=df.Group)","d588bf63":"ax = (df['Group'].value_counts()*100.0 \/len(df))\\\n.plot.pie(autopct='%.1f%%', labels = ['No', 'Yes'],figsize =(5,5), fontsize = 12,explode=(0.1,0))\nax.set_ylabel('Group',fontsize = 12)\nax.set_title('% of Group', fontsize = 12)","86175d9c":"#'EDUC' = Years of Education\n# Nondemented = 0, Demented =1\nfacet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\nfacet.map(sns.kdeplot,'EDUC',shade= True)\nfacet.set(xlim=(df['EDUC'].min(), df['EDUC'].max()))\nfacet.add_legend()\nplt.ylim(0, 0.16)","674e6254":"df.isnull().sum()","09259090":"df[\"SES\"].fillna(df.groupby(\"EDUC\")[\"SES\"].transform(\"median\"), inplace=True)","9667e207":"df.isnull().sum()","c816e468":"df['Group'].value_counts()","979956d1":"df=df.drop('MR Delay',axis=1)","e5801551":"corr = df.corr()\ncorr","2d5333ef":"# set the figure size\nplt.figure(figsize=(15, 8))\n\n# use 'mask' to plot a diagonal correlation matrix \n# 'triu_indices_from' returns the indices for the upper-triangle of matrix\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask, k = 1)] = True\n\n# plotting the heat map\n# corr: give the correlation matrix\n# cmap: color code used for plotting\n# vmax: gives a maximum range of values for the chart\n# vmin: gives a minimum range of values for the chart\n# annot: prints the correlation values in the chart\n# annot_kws: Sets the font size of the annotation\nsns.heatmap(corr, cmap='YlGnBu', vmax=1.0, vmin=-1.0, annot = True, annot_kws={\"size\": 12}, mask=mask)\n\n# specify name of the plot\nplt.title('Correlation between numeric features')\nplt.show()","cc93f4c6":"df.columns","d8a33f8f":"plt.rcParams['figure.figsize']=(20,10)\n\n# plot multiple boxplots\ndf.boxplot()\nplt.show()","35c2d5ec":"df.head()","e3cd2648":"df= pd.get_dummies(df, columns = ['SES','CDR'], drop_first = True)","494d0b91":"df.head()","7b7f85c1":"X=df.drop('Group',axis=1)\n","718069d7":"X.head()","c4fa70af":"y=df['Group']","3184e49e":"X=X.drop('Subject ID',axis=1)","a01d268a":"X.head()","67b0bfb4":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 0)\n\n# print dimensions of train and test sets\nprint(\"X_train\",X_train.shape)\nprint(\"X_test\",X_test.shape)\nprint(\"y_train\",y_train.shape)\nprint(\"y_test\",y_test.shape)","ba77ccbe":"sc = StandardScaler()\n\n# scaling the train set\nX_train_scaled = sc.fit_transform(X_train)\n\n# scaling the test set\nX_test_scaled = sc.fit_transform(X_test)","3a42e4ad":"logreg_scaled_features = LogisticRegression()\n\n# fit the logistic regression function\nlogreg_scaled_features.fit(X_train_scaled,y_train)","6d70fcd7":"y_pred = logreg_scaled_features.predict(X_test_scaled)","1f95918c":"cm = confusion_matrix(y_test, y_pred)\n\n# label the confusion matrix  \nconf_matrix=pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\n\n# set size of the plot\nplt.figure(figsize = (8,5))\n\n# plot a heatmap\nsns.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"YlGnBu\")\nplt.show()","ecadd298":"TN = cm[0,0]\n\n# True Positives are denoted by 'TP'\n# Actual '1' values which are classified correctly\nTP = cm[1,1]\n\n# False Negatives are denoted by 'FN'\n# Actual '1' values which are classified wrongly as '0'\nFN = cm[1,0]\n\n# False Positives are denoted by 'FP'\n# Actual 'O' values which are classified wrongly as '1'\nFP = cm[0,1]","f2877074":"result = classification_report(y_test,y_pred)\n\n# print the result\nprint(result)","0d9ed8d5":"# set the figure size\nplt.rcParams['figure.figsize']=(8,5)\n\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\n\n# plot the ROC curve\nplt.plot(fpr,tpr)\n\n# set limits for x and y axes\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\n\n# plot the straight line showing worst prediction for the model\nplt.plot([0, 1], [0, 1],'r--')\n\n# add the AUC score\nplt.text(x = 0.05, y = 0.8, s =('AUC Score:', round(metrics.roc_auc_score(y_test, y_pred),4)))\n\n# name the plot, and both axes\nplt.title('ROC curve for Renal Gland Disorder Classifier')\nplt.xlabel('False positive rate (1-Specificity)')\nplt.ylabel('True positive rate (Sensitivity)')\n\n# plot the grid\nplt.grid(True)","09c1a8c9":"cols = ['Model', 'AUC Score', 'Precision Score', 'Recall Score','Accuracy Score','f1-score']\n\n# creating an empty dataframe of the colums\nresult_tabulation = pd.DataFrame(columns = cols)\nLogistic_regression_ScaledFeatures_metrics = pd.Series({'Model': \"Logistic regression (ScaledFeatures) \",\n                     'AUC Score' : metrics.roc_auc_score(y_test, y_pred),\n                 'Precision Score': metrics.precision_score(y_test, y_pred),\n                 'Recall Score': metrics.recall_score(y_test, y_pred),\n                 'Accuracy Score': metrics.accuracy_score(y_test, y_pred),\n                  'f1-score': metrics.f1_score(y_test, y_pred)})\n\n\n# appending our result table\nresult_tabulation = result_tabulation.append(Logistic_regression_ScaledFeatures_metrics , ignore_index = True)\n\n# view the result table\nresult_tabulation","7ee623af":"logreg_scaled_features = LogisticRegression()\n\n# fit the logistic regression function\nlogreg_scaled_features.fit(X_train,y_train)","22136538":"y_pred = logreg_scaled_features.predict(X_test)","5750cf10":"cm = confusion_matrix(y_test, y_pred)\n\n# label the confusion matrix  \nconf_matrix=pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\n\n# set size of the plot\nplt.figure(figsize = (8,5))\n\n# plot a heatmap\nsns.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"YlGnBu\")\nplt.show()","75b9caae":"TN = cm[0,0]\n\n# True Positives are denoted by 'TP'\n# Actual '1' values which are classified correctly\nTP = cm[1,1]\n\n# False Negatives are denoted by 'FN'\n# Actual '1' values which are classified wrongly as '0'\nFN = cm[1,0]\n\n# False Positives are denoted by 'FP'\n# Actual 'O' values which are classified wrongly as '1'\nFP = cm[0,1]","1350b3b4":"result = classification_report(y_test,y_pred)\n\n# print the result\nprint(result)","c157e838":"# set the figure size\nplt.rcParams['figure.figsize']=(8,5)\n\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\n\n# plot the ROC curve\nplt.plot(fpr,tpr)\n\n# set limits for x and y axes\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\n\n# plot the straight line showing worst prediction for the model\nplt.plot([0, 1], [0, 1],'r--')\n\n# add the AUC score\nplt.text(x = 0.05, y = 0.8, s =('AUC Score:', round(metrics.roc_auc_score(y_test, y_pred),4)))\n\n# name the plot, and both axes\nplt.title('ROC curve for Renal Gland Disorder Classifier')\nplt.xlabel('False positive rate (1-Specificity)')\nplt.ylabel('True positive rate (Sensitivity)')\n\n# plot the grid\nplt.grid(True)","04d79b3a":"Logistic_regression_Without_ScaledFeatures_metrics = pd.Series({'Model': \"Logistic regression (Without ScaledFeatures) \",\n                     'AUC Score' : metrics.roc_auc_score(y_test, y_pred),\n                 'Precision Score': metrics.precision_score(y_test, y_pred),\n                 'Recall Score': metrics.recall_score(y_test, y_pred),\n                 'Accuracy Score': metrics.accuracy_score(y_test, y_pred),\n                  'f1-score': metrics.f1_score(y_test, y_pred)})\n\n\n# appending our result table\nresult_tabulation = result_tabulation.append(Logistic_regression_Without_ScaledFeatures_metrics , ignore_index = True)\n\n# view the result table\nresult_tabulation","de2c5b60":"# instantiate the 'SGDClassifier' to bild model using SGD\nlogreg_with_SGD = SGDClassifier()\n\n# fit the model on training data\nlogreg_with_SGD.fit(X_train_scaled, y_train)","25740dfd":"logreg_with_SGD_pred = logreg_with_SGD.predict(X_test_scaled)","2b29fcf3":"# compute the confusion matrix\ncm = confusion_matrix(y_test, logreg_with_SGD_pred)\n\n# label the confusion matrix  \nconf_matrix = pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\n\n# set sizeof the plot\nplt.figure(figsize = (8,5))\n\n# plot a heatmap\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap=\"YlGnBu\")\nplt.show()","c35c0cb1":"TN = cm[0,0]\n\n# True Positives are denoted by 'TP'\n# Actual '1' values which are classified correctly\nTP = cm[1,1]\n\n# False Negatives are denoted by 'FN'\n# Actual '1' values which are classified wrongly as '0'\nFN = cm[1,0]\n\n# False Positives are denoted by 'FP'\n# Actual 'O' values which are classified wrongly as '1'\nFP = cm[0,1]","d22f2868":"# accuracy measures by classification_report()\nresult = classification_report(y_test,logreg_with_SGD_pred)\n\n# print the result\nprint(result)","6ef56dc0":"# set the figure size\nplt.rcParams['figure.figsize']=(8,5)\n\nfpr, tpr, thresholds = roc_curve(y_test, logreg_with_SGD_pred)\n\n# plot the ROC curve\nplt.plot(fpr,tpr)\n\n# set limits for x and y axes\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\n\n# plot the straight line showing worst prediction for the model\nplt.plot([0, 1], [0, 1],'r--')\n\n# add the AUC score\nplt.text(x = 0.05, y = 0.8, s =('AUC Score:', round(metrics.roc_auc_score(y_test, logreg_with_SGD_pred),4)))\n\n# name the plot, and both axes\nplt.title('ROC curve for Renal Gland Disorder Classifier')\nplt.xlabel('False positive rate (1-Specificity)')\nplt.ylabel('True positive rate (Sensitivity)')\n\n# plot the grid\nplt.grid(True)","30590e36":"Logistic_regression_SGD_metrics = pd.Series({'Model': \"Logistic regression (SGD) \",\n                     'AUC Score' : metrics.roc_auc_score(y_test, logreg_with_SGD_pred),\n                 'Precision Score': metrics.precision_score(y_test, logreg_with_SGD_pred),\n                 'Recall Score': metrics.recall_score(y_test, logreg_with_SGD_pred),\n                 'Accuracy Score': metrics.accuracy_score(y_test, logreg_with_SGD_pred),\n                \n                 'f1-score':metrics.f1_score(y_test, logreg_with_SGD_pred)})\n\n# appending our result table\nresult_tabulation = result_tabulation.append(Logistic_regression_SGD_metrics , ignore_index = True)\n\n# view the result table\nresult_tabulation","9616db70":"# instantiate the 'DecisionTreeClassifier' object using 'entropy' criterion\ndecision_tree_classification = DecisionTreeClassifier(criterion='entropy')\n\n# train model\ndecision_tree = decision_tree_classification.fit(X_train, y_train)","7b6002a9":"# plot the decision tree\nlables = X_train.columns\n\ndot_data = tree.export_graphviz(decision_tree, out_file=None, \n                         feature_names= lables,  \n                         class_names=[\"0\",\"1\"])  \n\n# plot the decision tree\ngraph = pydotplus.graph_from_dot_data(dot_data)  \nImage(graph.create_png())\n\n","91af7c1a":"# predict the model using 'X_test'\ndecision_tree_pred = decision_tree.predict(X_test)","5bf471d8":"cm = confusion_matrix(y_test, decision_tree_pred)\n\n# label the confusion matrix  \nconf_matrix = pd.DataFrame(data = cm, columns = ['Predicted:0','Predicted:1'], index = ['Actual:0','Actual:1'])\n\n# set sizeof the plot\nplt.figure(figsize = (8,5))\n\n# plot a heatmap\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap=\"YlGnBu\")\nplt.show()","d9ba9cfa":"TN = cm[0,0]\n\n# True Positives are denoted by 'TP'\n# Actual '1' values which are classified correctly\nTP = cm[1,1]\n\n# False Negatives are denoted by 'FN'\n# Actual '1' values which are classified wrongly as '0'\nFN = cm[1,0]\n\n# False Positives are denoted by 'FP'\n# Actual 'O' values which are classified wrongly as '1'\nFP = cm[0,1]","059dff92":"# accuracy measures by classification_report()\nresult = classification_report(y_test, decision_tree_pred)\n\n# print the result\nprint(result)","9d2fbadf":"# set the figure size\nplt.rcParams['figure.figsize']=(8,5)\n\nfpr, tpr, thresholds = roc_curve(y_test, decision_tree_pred)\n\n# plot the ROC curve\nplt.plot(fpr,tpr)\n\n# set limits for x and y axes\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\n\n# plot the straight line showing worst prediction for the model\nplt.plot([0, 1], [0, 1],'r--')\n\n# add the AUC score\nplt.text(x = 0.05, y = 0.8, s =('AUC Score:', round(metrics.roc_auc_score(y_test, decision_tree_pred),4)))\n\n\n# name the plot, and both axes\nplt.title('ROC curve for Renal Gland Disorder Classifier')\nplt.xlabel('False positive rate (1-Specificity)')\nplt.ylabel('True positive rate (Sensitivity)')\n\n# plot the grid\nplt.grid(True)","7263f2ec":"Decision_tree_metrics = pd.Series({'Model': \"Decision Tree \",\n                     'AUC Score' : metrics.roc_auc_score(y_test, decision_tree_pred),\n                 'Precision Score': metrics.precision_score(y_test, decision_tree_pred),\n                 'Recall Score': metrics.recall_score(y_test, decision_tree_pred),\n                 'Accuracy Score': metrics.accuracy_score(y_test, decision_tree_pred),\n                 \n                  'f1-score':metrics.f1_score(y_test, decision_tree_pred)})\n\n\n\n# appending our result table\nresult_tabulation = result_tabulation.append(Decision_tree_metrics , ignore_index = True)\n\n# view the result table\nresult_tabulation","b3abc6a3":"pruned = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5)\n\n# train the classifier\ndecision_tree_prune = pruned.fit(X_train,y_train)","4e86e779":"lables = X_train.columns\n\ndot_data = tree.export_graphviz(decision_tree_prune, out_file=None, \n                         feature_names= lables,  \n                         class_names=[\"0\",\"1\"])  \n\n# plot the decision tree\ngraph = pydotplus.graph_from_dot_data(dot_data)  \nImage(graph.create_png())","4c838994":"decision_tree_prune_pred = decision_tree_prune.predict(X_test)","cc1e08f6":"cm = confusion_matrix(y_test, decision_tree_prune_pred)\n\n# label the confusion matrix  \nconf_matrix = pd.DataFrame(data = cm, columns = ['Predicted:0','Predicted:1'], index = ['Actual:0','Actual:1'])\n\n# set sizeof the plot\nplt.figure(figsize = (8,5))\n\n# plot a heatmap\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap=\"YlGnBu\")\nplt.show()","67e01aeb":"TN = cm[0,0]\n\n# True Positives are denoted by 'TP'\n# Actual '1' values which are classified correctly\nTP = cm[1,1]\n\n# False Negatives are denoted by 'FN'\n# Actual '1' values which are classified wrongly as '0'\nFN = cm[1,0]\n\n# False Positives are denoted by 'FP'\n# Actual 'O' values which are classified wrongly as '1'\nFP = cm[0,1]","519f0491":"result = classification_report(y_test,decision_tree_prune_pred)\n\n# print the result\nprint(result)","791da367":"plt.rcParams['figure.figsize']=(8,5)\n\nfpr, tpr, thresholds = roc_curve(y_test, decision_tree_prune_pred)\n\n# plot the ROC curve\nplt.plot(fpr,tpr)\n\n# set limits for x and y axes\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\n\n# plot the straight line showing worst prediction for the model\nplt.plot([0, 1], [0, 1],'r--')\n\n# add the AUC score\nplt.text(x = 0.05, y = 0.8, s =('AUC Score:', round(metrics.roc_auc_score(y_test, decision_tree_prune_pred),4)))\n\n\n# name the plot, and both axes\nplt.title('ROC curve for Renal Gland Disorder Classifier')\nplt.xlabel('False positive rate (1-Specificity)')\nplt.ylabel('True positive rate (Sensitivity)')\n\n# plot the grid\nplt.grid(True)","b8d0efd9":"Pruned_Decision_tree_metrics = pd.Series({'Model': \"Pruned Decision Tree \",\n                     'AUC Score' : metrics.roc_auc_score(y_test, decision_tree_prune_pred),\n                 'Precision Score': metrics.precision_score(y_test, decision_tree_prune_pred),\n                 'Recall Score': metrics.recall_score(y_test, decision_tree_prune_pred),\n                 'Accuracy Score': metrics.accuracy_score(y_test, decision_tree_prune_pred),\n               \n                  'f1-score':metrics.f1_score(y_test, decision_tree_prune_pred)})\n\n\n\n# appending our result table\nresult_tabulation = result_tabulation.append(Pruned_Decision_tree_metrics , ignore_index = True)\n\n# view the result table\nresult_tabulation","b83f84f0":"# 'criterion': The function to measure the quality of split\n# 'max_depth': The maximum depth of the tree\n# 'max_leaf_nodes': The maximum number of leaf nodes required\n# 'min_samples_leaf': The minimum number of samples required to be at a leaf node\n# 'min_samples_split': The minimum number of samples required to split an internal node\n\n\n# set of parameters to test\nparam_grid = {\"criterion\": [\"gini\", \"entropy\"],\n              \"min_samples_split\": [10, 20],\n              \"max_depth\": [3, 5, 10, 20],\n              \"min_samples_leaf\": [30, 100, 300],\n              \"max_leaf_nodes\": [None,2,3,5],\n              }","b42ebe43":"decision_tree_Gridsearch = DecisionTreeClassifier()\ndecision_tree_Gridsearch = GridSearchCV(decision_tree_Gridsearch, param_grid, cv=10)\ndecision_tree_Gridsearch.fit(X_train, y_train)","e937b55b":"decision_tree_Gridsearch.best_params_","df7b5f28":"decision_tree_best_parameters = DecisionTreeClassifier(max_depth= decision_tree_Gridsearch.best_params_.get('max_depth'), \n                                                       min_samples_leaf= decision_tree_Gridsearch.best_params_.get('min_samples_leaf'), \n                                                       min_samples_split= decision_tree_Gridsearch.best_params_.get('min_samples_split'),\n                                                       criterion=decision_tree_Gridsearch.best_params_.get('criterion')).fit(X_train, y_train)","78cc3bdb":"lables = X_train.columns\n\ndot_data = tree.export_graphviz(decision_tree_best_parameters, out_file=None, \n                         feature_names= lables,  \n                         class_names=[\"0\",\"1\"])  \n\n# plot the decision tree\ngraph = pydotplus.graph_from_dot_data(dot_data)  \nImage(graph.create_png())","452dbe51":"decision_tree_best_parameters_pred = decision_tree_best_parameters.predict(X_test)","38768508":"cm = confusion_matrix(y_test, decision_tree_best_parameters_pred)\n\n# label the confusion matrix  \nconf_matrix = pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\n\n# set sizeof the plot\nplt.figure(figsize = (8,5))\n\n# plot a heatmap\nsns.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"YlGnBu\")\nplt.show()","a33726b8":"TN = cm[0,0]\n\n# True Positives are denoted by 'TP'\n# Actual '1' values which are classified correctly\nTP = cm[1,1]\n\n# False Negatives are denoted by 'FN'\n# Actual '1' values which are classified wrongly as '0'\nFN = cm[1,0]\n\n# False Positives are denoted by 'FP'\n# Actual 'O' values which are classified wrongly as '1'\nFP = cm[0,1]","1af151e5":"result = classification_report(y_test,decision_tree_best_parameters_pred)\n\n# print the result\nprint(result)","49bf79cc":"plt.rcParams['figure.figsize']=(8,5)\n\nfpr, tpr, thresholds = roc_curve(y_test, decision_tree_best_parameters_pred)\n\n# plot the ROC curve\nplt.plot(fpr,tpr)\n\n# set limits for x and y axes\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\n\n# plot the straight line showing worst prediction for the model\nplt.plot([0, 1], [0, 1],'r--')\n\n# add the AUC score\nplt.text(x = 0.05, y = 0.8, s =('AUC Score:', round(metrics.roc_auc_score(y_test, decision_tree_best_parameters_pred),4)))\n\n\n# name the plot, and both axes\nplt.title('ROC curve for Renal Gland Disorder Classifier')\nplt.xlabel('False positive rate (1-Specificity)')\nplt.ylabel('True positive rate (Sensitivity)')\n\n# plot the grid\nplt.grid(True)","929351ab":"Decision_tree_GridSearch_metrics = pd.Series({'Model': \"Decision Tree (GridSearchCV) \",\n                     'AUC Score' : metrics.roc_auc_score(y_test, decision_tree_best_parameters_pred),\n                 'Precision Score': metrics.precision_score(y_test, decision_tree_best_parameters_pred),\n                 'Recall Score': metrics.recall_score(y_test, decision_tree_best_parameters_pred),\n                 'Accuracy Score': metrics.accuracy_score(y_test, decision_tree_best_parameters_pred),\n     \n                 'f1-score':metrics.f1_score(y_test, decision_tree_best_parameters_pred)})\n\n\n\n# appending our result table\nresult_tabulation = result_tabulation.append(Decision_tree_GridSearch_metrics , ignore_index = True)\n\n# view the result table\nresult_tabulation","f1eae963":"param_grid_svm = {'kernel': ['linear', 'rbf', 'poly'], 'C' : [0.001, 0.01, 0.1, 1, 100]}","173ee151":"svm_Gridsearch = SVC()\n\n# use GridSearchCV to find best parameter\nsvm_Gridsearch = GridSearchCV(svm_Gridsearch, param_grid_svm, cv=10)\n\n# fit the model\nsvm_Gridsearch.fit(X_train_scaled, y_train)","3cf4aead":"svm_Gridsearch.best_params_","4703dabf":"svm_best_parameters = SVC(kernel= svm_Gridsearch.best_params_.get('kernel'), C = svm_Gridsearch.best_params_.get('C') )\n\n# fit the model\nsvm_best_parameters.fit(X_train_scaled, y_train)\n\n# get accuracy \n#Note: In case of classification algorithms score method represents accuracy.\nsvm_best_parameters.score(X_test_scaled,y_test)","4829e4e3":"y_pred_svm_GridSearch = svm_best_parameters.predict(X_test_scaled)","19dda3d7":"cm = confusion_matrix(y_test, y_pred_svm_GridSearch)\n\n# label the confusion matrix  \nconf_matrix = pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\n\n# set sizeof the plot\nplt.figure(figsize = (8,5))\n\n# plot a heatmap\nsns.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"YlGnBu\")\nplt.show()","4974c208":"result = classification_report(y_test,y_pred_svm_GridSearch)\n\nprint(result)","336d6f57":"plt.rcParams['figure.figsize']=(8,5)\n\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_svm_GridSearch)\n\n# plot the ROC curve\nplt.plot(fpr,tpr)\n\n# set limits for x and y axes\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\n\n# plot the straight line showing worst prediction for the model\nplt.plot([0, 1], [0, 1],'r--')\n\n# add the AUC score\nplt.text(x = 0.05, y = 0.8, s =('AUC Score:', round(metrics.roc_auc_score(y_test, y_pred_svm_GridSearch),4)))\n\n\n# name the plot, and both axes\nplt.title('ROC curve for Renal Gland Disorder Classifier')\nplt.xlabel('False positive rate (1-Specificity)')\nplt.ylabel('True positive rate (Sensitivity)')\n\n# plot the grid\nplt.grid(True)","da18ac2f":"svm_GridSearch_metrics = pd.Series({'Model': \"SVM (GridSearchCV) \",\n                     'AUC Score' : metrics.roc_auc_score(y_test, y_pred_svm_GridSearch),\n                 'Precision Score': metrics.precision_score(y_test, y_pred_svm_GridSearch),\n                 'Recall Score': metrics.recall_score(y_test, y_pred_svm_GridSearch),\n                 'Accuracy Score': metrics.accuracy_score(y_test, y_pred_svm_GridSearch),\n                 \n                 'f1-score': metrics.f1_score(y_test, y_pred_svm_GridSearch)})\n\n\n\n# appending our result table\nresult_tabulation = result_tabulation.append(svm_GridSearch_metrics , ignore_index = True)\n\n# view the result table\nresult_tabulation","08a84328":"from sklearn.ensemble import RandomForestClassifier","4b707d0d":"clf=RandomForestClassifier(n_estimators=5)\n#Train the model using the training sets y_pred=clf.predict(X_test)\nran=clf.fit(X_train,y_train)\n\n#predict the model\ny_pred=clf.predict(X_test)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","a6789af2":"cm = confusion_matrix(y_test, y_pred)\n\n# label the confusion matrix  \nconf_matrix = pd.DataFrame(data = cm, columns = ['Predicted:0','Predicted:1'], index = ['Actual:0','Actual:1'])\n\n# set sizeof the plot\nplt.figure(figsize = (8,5))\n\n# plot a heatmap\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap=\"YlGnBu\")\nplt.show()","ba238933":"TN = cm[0,0]\n\n# True Positives are denoted by 'TP'\n# Actual '1' values which are classified correctly\nTP = cm[1,1]\n\n# False Negatives are denoted by 'FN'\n# Actual '1' values which are classified wrongly as '0'\nFN = cm[1,0]\n\n# False Positives are denoted by 'FP'\n# Actual 'O' values which are classified wrongly as '1'\nFP = cm[0,1]","4fc86afe":"result = classification_report(y_test, y_pred)\n\n# print the result\nprint(result)","3f11ba26":"plt.rcParams['figure.figsize']=(8,5)\n\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\n\n# plot the ROC curve\nplt.plot(fpr,tpr)\n\n# set limits for x and y axes\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\n\n# plot the straight line showing worst prediction for the model\nplt.plot([0, 1], [0, 1],'r--')\n\n# add the AUC score\nplt.text(x = 0.05, y = 0.8, s =('AUC Score:', round(metrics.roc_auc_score(y_test, y_pred),4)))\n\n\n# name the plot, and both axes\nplt.title('ROC curve for Renal Gland Disorder Classifier')\nplt.xlabel('False positive rate (1-Specificity)')\nplt.ylabel('True positive rate (Sensitivity)')\n\n# plot the grid\nplt.grid(True)","00c781ff":"ran_metrics = pd.Series({'Model': \"RandomForest \",\n                     'AUC Score' : metrics.roc_auc_score(y_test, y_pred),\n                 'Precision Score': metrics.precision_score(y_test, y_pred),\n                 'Recall Score': metrics.recall_score(y_test, y_pred),\n                 'Accuracy Score': metrics.accuracy_score(y_test, y_pred),\n\n                  'f1-score':metrics.f1_score(y_test, y_pred)})\n\n\n\n# appending our result table\nresult_tabulation = result_tabulation.append(ran_metrics , ignore_index = True)\n\n# view the result table\nresult_tabulation","0b71e6d6":"print(\"Feature importance: \")\nnp.array([X.columns.values.tolist(), list(ran.feature_importances_)]).T","b657eab9":"from xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score","5302b059":"model=XGBClassifier(random_state=10, n_jobs=-1, learning_rate=0.1,\n                  n_estimators=100, max_depth=3)\nmodel = model.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint('Final prediction score: [%.8f]' % accuracy_score(y_test, y_pred))","e498a8d9":"cm = confusion_matrix(y_test, y_pred)\n\n# label the confusion matrix  \nconf_matrix = pd.DataFrame(data = cm, columns = ['Predicted:0','Predicted:1'], index = ['Actual:0','Actual:1'])\n\n# set sizeof the plot\nplt.figure(figsize = (8,5))\n\n# plot a heatmap\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap=\"YlGnBu\")\nplt.show()","4761018a":"result = classification_report(y_test, y_pred)\n\n# print the result\nprint(result)","0a2e4130":"plt.rcParams['figure.figsize']=(8,5)\n\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\n\n# plot the ROC curve\nplt.plot(fpr,tpr)\n\n# set limits for x and y axes\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\n\n# plot the straight line showing worst prediction for the model\nplt.plot([0, 1], [0, 1],'r--')\n\n# add the AUC score\nplt.text(x = 0.05, y = 0.8, s =('AUC Score:', round(metrics.roc_auc_score(y_test, y_pred),4)))\n\n\n# name the plot, and both axes\nplt.title('ROC curve for Renal Gland Disorder Classifier')\nplt.xlabel('False positive rate (1-Specificity)')\nplt.ylabel('True positive rate (Sensitivity)')\n\n# plot the grid\nplt.grid(True)","8f3d3d8d":"Xgb = pd.Series({'Model': \"XGBClassifier \",\n                     'AUC Score' : metrics.roc_auc_score(y_test, y_pred),\n                 'Precision Score': metrics.precision_score(y_test, y_pred),\n                 'Recall Score': metrics.recall_score(y_test, y_pred),\n                 'Accuracy Score': metrics.accuracy_score(y_test, y_pred),\n            \n                  'f1-score':metrics.f1_score(y_test, y_pred)})\n\n\n\n# appending our result table\nresult_tabulation = result_tabulation.append(Xgb , ignore_index = True)\n\n# view the result table\nresult_tabulation","123b35f5":"plt.rcParams['figure.figsize']=(28,10)\n\nresult_tabulation.plot(secondary_y=['Accuracy Score','Precision Score'], mark_right=True)\n\nplt.xticks([0,1,2,3,4,5,6,7,8,9], list(result_tabulation.Model))\nplt.show()","32577455":" <a id='usingSGD'><\/a>\n### 5.3 Logistic Regression (using SGD)","350eee0a":"<table align=\"left\">\n    <tr>\n        <td>\n            <div align=\"left\", style=\"font-size:120%\">\n                <font color=\"#21618C\">\n                    <b>\n                        There are some null values in SES<br>\n                    <\/b>\n                <\/font>\n            <\/div>\n        <\/td>\n    <\/tr>\n<\/table>","0316c01c":"<table align=\"left\">\n    <tr>\n        <td>\n            <div align=\"left\", style=\"font-size:120%\">\n                <font color=\"#21618C\">\n                    <b>\n                        The data is well Balanced<br>\n                    <\/b>\n                <\/font>\n            <\/div>\n        <\/td>\n    <\/tr>\n<\/table>","1a1acce8":"<table align=\"left\">\n    <tr>\n        <td>\n            <div align=\"left\", style=\"font-size:120%\">\n                <font color=\"#21618C\">\n                    <b>From the above graph, demented patients have less MMSE and Non Demented patients have more MMSE value.Generally the MMSE  indicates value  less than  24 indicates Abnormality, which implies the observations are true as the MMSE Metrics   <br>\n                        <\/b>\n                <\/font>\n            <\/div>\n        <\/td>\n    <\/tr>\n<\/table>","4d36ee1d":"<a id='withScaledFeatures'><\/a>\n### 5.1 Logistic Regression (MLE with Scaled Features)","cd44b9e2":"<a id='LogisticReg'><\/a>\n## 5. Logistic Regression ","32640d63":"<table align=\"left\">\n    <tr>\n        <td>\n            <div align=\"left\", style=\"font-size:120%\">\n                <font color=\"#21618C\">\n                    <b>\n                        <h>--- Intermediate Result Summary<\/h><br>\n- Men are more likely with demented, an Alzheimer's Disease, than Women.<br>\n- Demented patients were less educated in terms of years of education.<br>\n- Nondemented group has higher brain volume than Demented group.<br>\n- Higher concentration of 70-80 years old in Demented group than those in the nondemented patients.<br>\n                    <\/b>\n                <\/font>\n            <\/div>\n        <\/td>\n    <\/tr>\n<\/table>","77fdec8d":"##  COLUMN DESCRIPTORS\n\n**EDUC**    -  Years of education\n\n**SES**     -\tSocioeconomic Status\n\n**MMSE** -\tMini Mental State Examination\n\n**CDR**  -\tClinical Dementia Rating\n\n**eTIV** -\tEstimated Total Intracranial Volume\n\n**nWBV** -\tNormalize Whole Brain Volume\n\n**ASF**  -\tAtlas Scaling Factor","6e2deb98":"## Table of Content\n\n1. **[Import Libraries](#import_lib)**\n2. **[Set Options](#set_options)**\n3. **[Read Data](#RD)**\n4. **[Data Analysis and Preparation](#data_preparation)**\n5. **[Logistic Regression](#LogisticReg)**\n    - 5.1 - [Logistic Regression (MLE with Scaled Features)](#withScaledFeatures)\n    - 5.2 - [Logistic Regression (using SGD)](#usingSGD)\n6. **[Decision Tree](#DecisionTree)**\n    - 6.1 - [Decision Tree](#DecisionTreeWFS)\n    - 6.2 - [Prune a Decision Tree](#DecisionTreePruning)\n    - 6.3 - [Decision Tree (using GridSearchCV)](#DecisionTreewithGridSearchCv)\n\n7. **[Support Vector Machine (using GridSearchCV and Regularization)](#SVM)**\n9. **[Conclusion and Interpretation](#conclusion)**","a87d06f6":"<table align=\"left\">\n    <tr>\n        <td>\n            <div align=\"left\", style=\"font-size:120%\">\n                <font color=\"#21618C\">\n                    <b>\n                        The chart indicates that Nondemented group has higher brain volume ratio than Demented group. This is assumed to be because the diseases affect the brain to be shrinking its tissue.<br>   \n                    <\/b>\n                <\/font>\n            <\/div>\n        <\/td>\n    <\/tr>\n<\/table>","09c1f822":"<a id='import_lib'><\/a>\n## 1. Import Libraries","335e7bf5":"**-** Alzheimer's disease (AD) is a neurodegenerative disorder of uncertain cause and pathogenesis that primarily affects older adults and is the most common cause of dementia.\n\n**-** The earliest clinical manifestation of AD is selective memory impairment and while treatments are available to ameliorate some symptoms, there is no cure currently available.\n\n**-** Brain Imaging via magnetic resonance imaging (MRI), is used for evaluation of patients with suspected AD.\n\n**-** MRI findings include both, local and generalized shrinkage of brain tissue.\n\n**-** Some studies have suggested that MRI features may predict rate of decline of AD and may guide therapy in the future.\n\n**-** However in order to reach that stage clinicians and researchers will have to make use of machine learning techniques that can accurately predict progress of a patient from mild cognitive impairment to dementia.\n\n**-** We propose to develop a sound model that can help clinicians do that and predict early alzheimer's.","ef035884":"<table align=\"left\">\n    <tr>\n        <td>\n            <div align=\"left\", style=\"font-size:120%\">\n                <font color=\"#21618C\">\n                    <b>\n                        The chart shows Nondemented group got much more higher MMSE scores than Demented group.<br>\n                        <\/b\n                <\/font>\n            <\/div>\n        <\/td>\n    <\/tr>\n<\/table>","d93d2406":"<a id='RD'><\/a>\n## 3. Read Data","44089f34":"<a id=\"conclusion\"> <\/a>\n## 9. Conclusion and Interpretation","a6396874":"##  DATASET DESCRIPTION\n\n\n\n**-** We will be using the longitudinal MRI data.\n\n**-** The dataset consists of a longitudinal MRI data of 150 subjects aged 60 to 96.\n\n**-** Each subject was scanned at least once.\n\n**-** Everyone is right-handed.\n\n**-** 72 of the subjects were grouped as 'Nondemented' throughout the study.\n\n**-** 64 of the subjects were grouped as 'Demented' at the time of their initial visits and remained so throughout the study.\n\n**-** 14 subjects were grouped as 'Nondemented' at the time of their initial visit and were subsequently characterized as 'Demented' at a later visit. These fall under the 'Converted' category.","2a73c0d5":"<table align=\"left\">\n    <tr>\n        <td>\n            <div align=\"left\", style=\"font-size:120%\">\n                <font color=\"#21618C\">\n                    <b>\n                       There is a higher concentration of 70-80 years old in the Demented patient group than those in the nondemented patients. We guess patients who suffered from that kind of disease has lower survival rate so that there are a few of 90 years old.<br>\n                        <\/b>\n                <\/font>\n            <\/div>\n        <\/td>\n    <\/tr>\n<\/table>","2a8d2a5b":"<a id='DecisionTree'> <\/a>\n## 6. Decision Tree","63ee6667":"<a id='DecisionTreewithGridSearchCv'> <\/a>\n###  6.3 Decision Tree (using GridSearchCV)","4ab80140":"<table align=\"left\">\n    <tr>\n        <td>\n            <div align=\"left\", style=\"font-size:120%\">\n                <font color=\"#21618C\">\n                    <b>\n                        The above graph indicates that men are more likely with dementia than women<br>   \n                    <\/b>\n                <\/font>\n            <\/div>\n        <\/td>\n    <\/tr>\n<\/table>","28361ae1":"<a id='data_preparation'><\/a>\n## 4. Data Analysis and Preparation","49fd7a5f":"<a id=\"SVM\"> <\/a>\n## 7. Support Vector Machine (using GridSearchCV and Regularization)","8e3daa93":"<a id='set_options'><\/a>\n## 2. Set Options","a9ee321d":"<table align=\"left\">\n    <tr>\n        <td>\n            <div align=\"left\", style=\"font-size:120%\">\n                <font color=\"#21618C\">\n                    <b>\n                        - we have changed the values of Gender to 0,1<br>\n                        - we have changed the targer value to 0,1<br>\n                        - we have dropped the MRI ID,Visit,Hand columns<br>    \n                    <\/b>\n                <\/font>\n            <\/div>\n        <\/td>\n    <\/tr>\n<\/table>","0f47b5b9":"<a id='DecisionTreeWFS'> <\/a>\n### 6.1 Decision Tree ","f9bddabb":"<table align=\"left\">\n    <tr>\n        <td>\n            <div align=\"left\", style=\"font-size:120%\">\n                <font color=\"#21618C\">\n                    <b>We see that there are 373 observations and 12 features <\/br><\/b>\n                <\/font>\n            <\/div>\n        <\/td>\n    <\/tr>\n<\/table>\n\n\n","8cc0d1d2":"<table align=\"left\" width=100%>\n    <tr>\n        <td>\n            <div align=\"left\">\n                <font color=\"#21618C\" size=5px>\n                  <b>DETECTING EARLY ALZHEIMER'S USING MRI DATA AND MACHINE LEARNING\n                    <\/b>\n                <\/font>\n            <\/div>\n        <\/td>\n    <\/tr>\n<\/table>","f19f9fe2":"<a id='DecisionTreePruning'><\/a>\n### 6.2 Prune the Decision Tree ","5f8a1c6b":"## Problem Statement\n\n","8805ec62":"### 5.2 Logistic Regression (MLE without Scaled Features)","b7230500":"<table align=\"left\">\n    <tr>\n        <td>\n            <div align=\"left\", style=\"font-size:120%\">\n                <font color=\"#21618C\">\n                    <b>\n                        The above graph indicates that almost half of the patients, visiting for the first time are detected with Alzhimers<br>\n                    <\/b>\n                <\/font>\n            <\/div>\n        <\/td>\n    <\/tr>\n<\/table>"}}