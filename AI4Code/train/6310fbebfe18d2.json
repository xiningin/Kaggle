{"cell_type":{"d5543d49":"code","68aadd03":"code","697bde3e":"code","753c548a":"code","24c9206d":"code","ed576096":"code","3efa0ead":"code","52d03d36":"code","250bad95":"code","744a6358":"code","85cf748f":"code","4cf17cd9":"code","b972a8c1":"code","9a2f53df":"code","6c7c6928":"code","8bac24b1":"code","5eb592fc":"code","8925a9e2":"code","33b92c95":"code","0127a3fe":"code","a8d8a322":"code","d828f37f":"code","d68d82a9":"code","dfead803":"code","de103d31":"code","32758d23":"code","7b436b20":"code","84154489":"code","a25e0b39":"code","7efbe165":"code","72b2c458":"code","b3e50e4d":"code","26c3338b":"code","52500308":"code","c570f1fa":"code","c7d7f2a1":"code","31cbffbe":"code","9c2ed042":"markdown","23b3c8b0":"markdown","e4608cf8":"markdown","2ec4b7a8":"markdown","3442ee0b":"markdown","2f97e3c9":"markdown","7b0763d4":"markdown","ae1fca8f":"markdown","910f4bb3":"markdown","006347eb":"markdown","40a74860":"markdown","17554c0f":"markdown","32fdac30":"markdown","ce335e61":"markdown"},"source":{"d5543d49":"#importing libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","68aadd03":"#loading dataset\ndf = pd.read_csv(\"..\/input\/startup50\/50_Startups.csv\")\ndf.head()","697bde3e":"#shape of our dataset\ndf.shape","753c548a":"#information about the data\ndf.info()","24c9206d":"#checking for missing data\ndf.isnull().sum()\n#there is no missing value in the data","ed576096":"#description about data\ndf.describe()","3efa0ead":"#Box Plot of independent variables an it seems we dont have outliers in our independent varables\nplt.figure(figsize=(20,3))\nfor i,col in zip(range(1,4),df.columns):\n    plt.subplot(1,4,i)\n    sns.boxplot(x=col,data=df,color='pink')\n    plt.title(f\"Box Plot of {col}\")\n    plt.tight_layout()","52d03d36":"#Distribution Plot of independent variables an it seems  all variables are Normally distributed.\nplt.figure(figsize=(20,3))\nfor i,col in zip(range(1,4),df.columns):\n    plt.subplot(1,4,i)\n    sns.distplot(a=df[col],color='orange')\n    plt.tight_layout()","250bad95":"#Box Plot and Distribution Plot for Dependent variable PROFIT\nplt.figure(figsize=(20,3))\n\nplt.subplot(1,2,1)\nsns.boxplot(df.Profit,color='#005030')\nplt.title('Box Plot of Profit')\n\nplt.subplot(1,2,2)\nsns.distplot(a=df.Profit,color='#500050')\nplt.title('Distribution Plot of Profit')\nplt.show()","744a6358":"#This is the outlier, since we see blow the R&D is higly correlated to the Proft\n#Here R&D spend is zero so its obious the profit is very low for this startup\ndf[df['Profit']<25000]","85cf748f":"df[df['R&D Spend']<10000]","4cf17cd9":"#After observing above few startup data, We can say that for Index 49 (which is Outlier) there is some error in Profit\n#typo error maybe. Sonce Profit for other startups with very R&D Spend is much higher than this\n#We will be removing the outlier from the dataset\ndf.drop(index=49,axis=0,inplace=True)\ndf.shape","b972a8c1":"#Distribution Plot of independent variables an it seems  all variables are Normally distributed.\nplt.figure(figsize=(20,3))\nfor i,col in zip(range(1,4),df.columns):\n    plt.subplot(1,4,i)\n    sns.scatterplot(x=col,y='Profit',data=df,color='blue')\n    plt.title(f\"{col} vs Profit\")\n    plt.tight_layout()","9a2f53df":"#we can see that R&D is highly linearly correalted with Profit\n#let us look at correlation matrix\nplt.title(\"Correlation Matrix\")\nsns.heatmap(data=df.corr(),annot=True,cmap='coolwarm',linewidths=0.1)","6c7c6928":"#This shows linear relationship between R&D Spend and Marketing Spend\nsns.scatterplot(x='R&D Spend',y='Marketing Spend',data=df)\nplt.title(\"R&D Spend vs Marketing Spend\")","8bac24b1":"df1 = df.copy()\ndf1.head()","5eb592fc":"#droping column Marketing Spend (because of Multicollinearity with R&D Spend) \n#droping column Adminstration(because of very low correlation with Proft)\ndf2 = df1.drop(columns=['Marketing Spend','Administration'],axis=1)\ndf2.head()","8925a9e2":"sns.heatmap(df2.corr(),annot=True)","33b92c95":"#we have one Catgorical variable column also 'State'\n#Lets explore and analyse it\n\ndf2.State.unique()","0127a3fe":"#There are three unique states and their counts are given below. They are equally distributed.\n\ndf2.groupby('State')['State'].count()","a8d8a322":"#We will convert this column into dummy variables\ndf3 = pd.get_dummies(data=df2)\ndf3.head()","d828f37f":"#To avoid dummy variable Trap, we will drop one dummy variable. Let us remove State_California\ndf4 = df3.drop(labels=['State_California'],axis=1)\ndf4.head()","d68d82a9":"#Now we are done with data preprocessing steps\n#Now will split our dataset into Dependent variable and Independent variable\n\nX = df4.iloc[:,[0,2,3]].values\ny = df4.iloc[:,1].values","dfead803":"print(f\"Shape of Dependent Variable X = {X.shape}\")\nprint(f\"Shape of Independent Variable y = {y.shape}\")","de103d31":"#Now we will spit our data into Train set and Test Set\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 101)","32758d23":"print(f\"Shape of X_train = {X_train.shape}\")\nprint(f\"Shape of X_test = {X_test.shape}\")\nprint(f\"Shape of y_train = {y_train.shape}\")\nprint(f\"Shape of y_test = {y_test.shape}\")","7b436b20":"#Now we will build regression model on Training Set and Test it on our Test Set\n\nfrom sklearn.linear_model import LinearRegression\nlm = LinearRegression()\nlm.fit(X=X_train,y=y_train)","84154489":"#Now it's time to test the accuracy of the model on our Test Data\n#this is very good accuracy on training set\nlm.score(X_train,y_train)","a25e0b39":"from sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(lm,X_train,y_train,cv=5)\nprint(f\"Accuracies obtained from 5-cross validation = {accuracies}\")\nprint(f'Mean of all accuracies = {accuracies.mean()}')\nprint(f\"Standard Deviation of accuracies = {accuracies.std()}\")","7efbe165":"#from sklearn.cross_validation import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\ngrid_search = GridSearchCV(estimator=lm,param_grid={'normalize':[True,False]})\ngrid_search = grid_search.fit(X_train,y_train)\nprint(f\"Best Parameter for our model is {grid_search.best_params_}\")\nprint(f\"Best score for the model is {grid_search.best_score_}\")","72b2c458":"# Taking best parameter\nlm = LinearRegression(normalize=True)\nlm.fit(X_train,y_train)","b3e50e4d":"#Now it's time to test the accuracy of the model on our Test Data\n#this is very good accuracy on training set\nlm.score(X_train,y_train)","26c3338b":"#Since we have already taken best parameter for our linear model.\n#Now we can see how model performs on test dataset\ny_pred = lm.predict(X_test)\ndata = {'y_test':y_test,'y_pred':y_pred.round(2)}\npd.DataFrame(data=data)","52500308":"#coefficients of regression model\ncoeff = f'Profit = ({lm.intercept_} x Bias) '\nfor i,col in zip(range(3),df4.columns[[0,2,3]]):\n    coeff+=f'+\\n ({lm.coef_[i]} x {col}) '\n\nprint(coeff)","c570f1fa":"plt.title('Residual Plot',size=20)\nsns.residplot(y_test,y_pred,color='purple')\nplt.xlabel('y_pred',size=15)\nplt.ylabel('Residues',size=15)\n\n#we can not see any pattern in the plot => model is good","c7d7f2a1":"sns.scatterplot(y_test,y_pred)\nplt.xlabel('y_test',size=15)\nplt.ylabel('y_pred',size=15)","31cbffbe":"from sklearn import metrics\nr2= metrics.r2_score(y_test,y_pred)\nN,p = X_test.shape\nadj_r2 = 1-((1-r2)*(N-1))\/(N-p-1)\nprint(f'R^2 = {r2}')\nprint(f'Adjusted R^2 = {adj_r2}')","9c2ed042":"# Multiple Linear Regression Model","23b3c8b0":"# 6. Building Linear Regression Model","e4608cf8":"# 0. Overview\nWe have data of 50 Startups operating in United States of America and the data used in this notebook obtained from Kaggle.\nDataset contain several variables, which ar as follows:\n1. R&D Spend - Amount spent by startup in Research and Development wing (in 1000s).\n2. Administration - Amount spent by startup in Adminstration wing (in 1000s).\n3. Marketing Spend - Amount spent by startup in Marketing wing (in 1000s).\n4. State - State in which startup is operating.\n5. Profit - Profit made by the startup (in 1000s).\n\n\n## Objective:\n1. First objective of this project (notebook) is to predict the profit of Startups based upon certain factors like R&D Spend, Administration Spend, Marketing Spend and State in which theey are operating.\n2. Second objective is to determine which in which company should operate in order to maximize their Profit.\n\n## Table of Contents:\n1. Importing needfull libraries required to process the data.\n2. Importing dataset using Pandas library and checking for missing values and description about the dataset.\n3. Visualising the dataset and handling outliers if exists.\n4. Wrangling data and encoding categorical variable.\n5. Splittin dataset into Training Set and Test Set.\n6. Building Linear Regression Model.\n7. Evaluation of Model through various methods and plotting techniques.\n8. Interpreting the results obtained from the data and model.\n9. Conclusion\n---","2ec4b7a8":"# 3. Visualising Dataset","3442ee0b":"# 5. Splitting Dataset into Train and Test Set for ML model","2f97e3c9":"# 7. Model Evaluation","7b0763d4":"# 9. Conclusion\n\nAfter observing the whole model we can conclude that:\n\n**1. Profit for a startup is highly dependent on how much they spend on R&D i.e Research and Development. Higher R&D Spent higher is the Profit and vica-versa.**\n\n\n**2. Start opearting in CALIFORNIA are expecting more Profit than operating in other two states 'Florida' and 'New York' with an assuption R&D Spent for all three states are same.**\n\n**So based on the data provided and our Machine Learning Model we can say that it is Good to start a business in CALFORNIA (do consider other factors also which are not covered in the model)**","ae1fca8f":"# 4. Wrangling Dataset","910f4bb3":"**Our Linear Regression Model for Test Set gives**\n\nR^2 = 0.92\n\nAdjusted R^2 = 0.87\n\n**Profit = (49491.02605460257 x Bias) + (0.8577919938062496 x R&D Spend) + (-695.5899394338772 x State_Florida) + (-3010.1465064603767 x State_New York)**\n\n\n****\n\n**Interpreting Coefficients**\n1. It means that taking other variables constant, for every 1 unit increase in R&D Spent -> Profit INCREASE by 0.86 units.\n\n2. Remaining other variables constant, if Startup operates in Florida -> Profit will DECREASE by 695.59 units.\n\n3. Remaining other variables constant, if Startup operates in Nw York -> Profit will DECREASE by 3010.15 units.","006347eb":"# -----------------------------------Thank You---------------------------------\n\n    Please leave your valuable feedback on this and if you liked the notebook, please upvote it.","40a74860":"# 2. Loading Dataset and checking information","17554c0f":"# 8. Interpreting Results","32fdac30":"# 1. Importing libraries","ce335e61":"1. We can see that R&D Spend and Marketing Spend are 0.98 and 0.75 correlated with Profit which is very high.\n\n\n2. And Adminstration Spend is very less correlated, so we can drop that feature for buliding model.\n\n\n3. Also, we can see that R&D and Marketing are correlated with 0.72 which is high => Multicollinearity in independent variables.\n\n**We cannot have Multicollinearity in the dataset**"}}