{"cell_type":{"b40f34ec":"code","0fc4d19e":"code","56244e97":"code","ad712d68":"code","400b5f49":"code","686bcb13":"code","e3124c05":"code","6763bdf3":"code","eedbbc46":"code","03b13b43":"code","a0a2c4fa":"code","243f4951":"code","ca55e807":"code","e9b96830":"code","abe81674":"markdown","5a04df9b":"markdown","ca3afdc3":"markdown","ce6010d5":"markdown","4a54b1ba":"markdown"},"source":{"b40f34ec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0fc4d19e":"train_data = pd.read_csv('\/kaggle\/input\/ag-news-classification-dataset\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/ag-news-classification-dataset\/test.csv')","56244e97":"train_data.head()","ad712d68":"import nltk\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nimport string\nfrom nltk.stem import PorterStemmer\nimport numpy as np\nfrom nltk.stem import WordNetLemmatizer\nimport re\nimport matplotlib.pyplot as plt","400b5f49":"fig = plt.figure(figsize=(5,5))\nlabels = 'world', 'sports', 'business' , 'Science'\nsizes = [len(train_data[train_data['Class Index']==1]), len(train_data[train_data['Class Index']==2]), len(train_data[train_data['Class Index']==3]), len(train_data[train_data['Class Index']==4])]\nplt.pie(sizes, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nplt.axis('equal')  \nplt.show()","686bcb13":"def tokenize(data):\n    data = [word_tokenize(sent) for sent in data]\n    return data","e3124c05":"def remove_punc(data):\n    for i in range(len(data)-1):\n        data[i] = [w for w in data[i] if w not in string.punctuation]\n    return data","6763bdf3":"nltk_stop_words = nltk.corpus.stopwords.words('english')\ndef remove_stop(data):    \n    for i in range(len(data)-1):\n        data[i] = [w for w in data[i] if w not in nltk_stop_words]\n    return data","eedbbc46":"stemmer = PorterStemmer()\ndef stemming(data):    \n    for i in range(len(data)-1):\n        data[i] = [stemmer.stem(w) for w in data[i]]\n    return data","03b13b43":"lemmatizer = WordNetLemmatizer()\ndef lemma(data):    \n    for i in range(len(data)-1):\n        data[i] = [lemmatizer.lemmatize(w) for w in data[i]]\n    return data","a0a2c4fa":"regex = re.compile('[^a-zA-Z]')\ndef remove_nonalpha(data):\n    for i in range(len(data)-1):\n        data[i] = [regex.sub('', w) for w in data[i]]\n    return data","243f4951":"train_data['Title'] = tokenize(train_data['Title'])\ntrain_data['Title'] = remove_punc(train_data['Title'])\ntrain_data['Title'] = remove_stop(train_data['Title'])\ntrain_data['Title'] = stemming(train_data['Title'])\ntrain_data['Title'] = lemma(train_data['Title'])\ntrain_data['Title'] = remove_nonalpha(train_data['Title'])","ca55e807":"train_data['Description'] = tokenize(train_data['Description'])\ntrain_data['Description'] = remove_punc(train_data['Description'])\ntrain_data['Description'] = remove_stop(train_data['Description'])\ntrain_data['Description'] = stemming(train_data['Description'])\ntrain_data['Description'] = lemma(train_data['Description'])\ntrain_data['Description'] = remove_nonalpha(train_data['Description'])","e9b96830":"train_data.head()","abe81674":"# **Lemmatization Step**","5a04df9b":"# **Stemming Step**","ca3afdc3":"# **Tokenization Step**","ce6010d5":"# **Removing Stop words**","4a54b1ba":"# **Removing punctuations**"}}