{"cell_type":{"a28478e2":"code","5685b0ff":"code","1c8ccac9":"code","d0ab7924":"code","aaec423f":"code","a96071f7":"code","a2085b77":"code","bfcbe8a1":"code","a8167546":"code","7e59d770":"code","e7832ce5":"code","27005fc7":"code","fca97a2f":"code","30a22633":"code","1908dfde":"code","a49264a9":"code","f80f6b59":"code","0502d0f9":"code","24f05448":"code","248d284d":"code","6958334b":"code","56569228":"code","70426c31":"code","df888ad7":"code","5d312554":"code","3c8c9190":"code","b59b88fd":"code","6a2a33f3":"code","ff543832":"code","1e438a25":"code","871976eb":"code","a586e36e":"code","3287ae5f":"code","6215df4a":"code","d9b1e299":"markdown","38f5e9e4":"markdown","577caa57":"markdown","96070da0":"markdown","44402aa5":"markdown","9dfa5798":"markdown","9f6188f2":"markdown","2103295b":"markdown","e1f92480":"markdown","003a6c38":"markdown","7bb09b44":"markdown","279d6651":"markdown","ddf39486":"markdown","5ea29962":"markdown","9644bad6":"markdown","10c55a78":"markdown","0f7df8ea":"markdown","68bb9b2e":"markdown","13f0d041":"markdown","8d65f7ee":"markdown","f58e4bf5":"markdown","2fc74f83":"markdown","89e3f288":"markdown","1875e63f":"markdown","e8870621":"markdown","3fd1da80":"markdown","e71240c6":"markdown","a1defc7a":"markdown","513b6eed":"markdown"},"source":{"a28478e2":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LinearRegression\nfrom lightgbm import LGBMRegressor\nfrom sklearn.model_selection import (StratifiedKFold, KFold, cross_validate)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\npd.options.display.max_columns= None\npd.options.display.max_rows= None\nnp.set_printoptions(suppress=True)\nprint('All libraries imported.')","5685b0ff":"train_df= pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv', index_col= 'Id')\ntest_df= pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv', index_col= 'Id')\ndf= pd.concat([train_df, test_df], axis= 0)\nprint(len(df.columns), ' columns:')\nprint(df.columns) # lots of columns present","1c8ccac9":"print(df.isna().sum().sum(), ' total missing values.')\nprint(len(df), ' is the number of rows.')","d0ab7924":"print('Column\\t\\t\\tDtype\\t\\t\\tMissing\\t\\tMissing%')\nl= len(df)\nfor i in df.columns:\n    n= df[i].isna().sum()\n    print(i, '\\t\\t', df[i].dtype, '\\t\\t', n, '\\t\\t', (n*100)\/l)","aaec423f":"df[['Neighborhood', 'SalePrice']].groupby(['Neighborhood'], as_index=True).mean().sort_values(by='SalePrice', ascending=False)","a96071f7":"df.replace({\n    'BsmtCond': {'Ex':3, 'Gd':3, 'TA':2, 'Fa':1, 'Po':1},\n    'BsmtQual': {'Ex':3, 'Gd':3, 'TA':2, 'Fa':1, 'Po':1},\n    'CentralAir': {'N': 0, 'Y': 1},\n    'ExterQual': {'Ex':3, 'Gd':3, 'TA':2, 'Fa':1, 'Po':1},\n    'ExterCond': {'Ex':3, 'Gd':3, 'TA':2, 'Fa':1, 'Po':1},\n    'Functional': {'Typ':3, 'Min1':2, 'Min2':2, 'Mod':2, 'Maj1':1, 'Maj2':1, 'Sev':0, 'Sal':0},\n    'HeatingQC': {'Ex':3, 'Gd':3, 'TA':2, 'Fa':1, 'Po':1},\n    'HouseStyle': {'1Story':1, '1.5Fin':1, '1.5Unf':1, '2Story':2, '2.5Fin':2, '2.5Unf':2, 'SFoyer':0, 'SLvl':0},\n    'KitchenQual': {'Ex':3, 'Gd':3, 'TA':2, 'Fa':1, 'Po':1},\n    'Street': {'Pave':1, 'Grvl':0},\n    'PavedDrive': {'Y':1, 'P':1, 'N':0}\n}, inplace= True)","a2085b77":"df.replace({\n    'Neighborhood': {'NoRidge':3, 'NridgHt':3, 'StoneBr':3, 'Timber':2, 'Veenker':2, 'Somerst':2, 'ClearCr':2,\n                     'Crawfor':2, 'CollgCr':2, 'Blmngtn':2, 'Gilbert':2, 'NWAmes':2, 'SawyerW':2, 'Mitchel':1,\n                     'NAmes':1, 'NPkVill':1, 'SWISU':1, 'Blueste':1, 'Sawyer':1, 'OldTown':1, 'Edwards':1,\n                     'BrkSide':1, 'BrDale':1, 'IDOTRR':1, 'MeadowV':1}\n}, inplace= True)","bfcbe8a1":"df['Age']= ' '\ndf['Age']= df['YrSold']-df['YearRemodAdd']","a8167546":"df['AlleyAccess']= ' '\ndf['AlleyAccess'][df['Alley'].isna()]= 0 \ndf['AlleyAccess'][df['Alley'].notna()]= 1","7e59d770":"df['Bathrooms']= ' '\ndf['Bathrooms']= (2*df['BsmtFullBath'])+df['BsmtHalfBath']+(2*df['FullBath'])+df['HalfBath']","e7832ce5":"df['BsmtRating']= ' '\ndf['BsmtRating']= df['BsmtQual']*df['BsmtCond']\ndf['BsmtRating'][df['BsmtRating'].isna()]= 0","27005fc7":"df['BsmtYN']= ' '\ndf['BsmtYN'][df['BsmtQual'].isna()]= 0\ndf['BsmtYN'][df['BsmtQual'].notna()]= 1\ndf['BsmtFinSF1'][df['BsmtQual'].isna()]= 0\ndf['BsmtFinSF1'][df['BsmtQual'].isna()]= 0\ndf['BsmtUnfSF'][df['BsmtQual'].isna()]= 0\ndf['TotalBsmtSF'][df['BsmtQual'].isna()]= 0","fca97a2f":"df['TotalSqFt']= ' '\ndf['TotalSqFt']= df['1stFlrSF']+df['2ndFlrSF']+df['LowQualFinSF']+df['TotalBsmtSF']+df['BsmtFinSF2']+df['BsmtFinSF1']+df['GrLivArea']+df['BsmtUnfSF']","30a22633":"df['BsmtCond'][df['BsmtYN']==0]= 0\ndf['BsmtCond'][df['BsmtCond'].isna()]= 0\ndf['BsmtQual'][df['BsmtYN']==0]= 0\ndf['Functional'][df['Functional'].isna()]= 0\ndf['GarageArea'][df['GarageArea'].isna()]= df['GarageArea'].mean()\ndf['KitchenQual'][df['KitchenQual'].isna()]= 2 # imputing with mode value\ndf['TotalSqFt'][df['TotalSqFt'].isna()]= df['TotalSqFt'].mean()\ndf['Bathrooms'][df['Bathrooms'].isna()]= 4 # imputing with mode value","1908dfde":"df['Cond1']= ' '\ndf['Cond1'][df['Condition1']=='Norm']= 0\ndf['Cond1'][df['Condition1']!='Norm']= 1\ndf['Cond2']= ' '\ndf['Cond2'][df['Condition2']=='Norm']= 0\ndf['Cond2'][df['Condition2']!='Norm']= 1\ndf['Condition']= df['Cond1']+df['Cond2']","a49264a9":"df['FenceYN']= ' '\ndf['FenceYN'][df['Fence'].isna()]= 0 \ndf['FenceYN'][df['Fence'].notna()]= 1","f80f6b59":"df['FireplaceYN']= ' '\ndf['FireplaceYN'][df['FireplaceQu'].isna()]= 0 \ndf['FireplaceYN'][df['FireplaceQu'].notna()]= 1\ndf['Fireplaces'][df['FireplaceQu'].isna()]= 0 ","0502d0f9":"df['GarageYN']= ' '\ndf['GarageYN'][df['GarageType'].isna()]= 0\ndf['GarageYN'][df['GarageType'].notna()]= 1\ndf['GarageArea'][df['GarageType'].isna()]= 0","24f05448":"df['MasVnrYN']= ' '\ndf['MasVnrYN'][df['MasVnrType'].isna()]= 0\ndf['MasVnrYN'][df['MasVnrType'].notna()]= 1\ndf['MasVnrArea'][df['MasVnrType'].isna()]= 0","248d284d":"df['Amenities']= ' '\ndf['Amenities'][df['MiscFeature'].isna()]= 0\ndf['Amenities'][df['MiscFeature'].notna()]= 1\ndf['Amenities'][df['MiscFeature'].isna()]= 0","6958334b":"df['PavedYN']= ' '\ndf['PavedYN']= (2*df['Street'])+df['PavedDrive']","56569228":"df['PoolYN']= ' '\ndf['PoolYN'][df['PoolQC'].isna()]= 0\ndf['PoolYN'][df['PoolQC'].notna()]= 1\ndf['PoolArea'][df['PoolQC'].isna()]= 0","70426c31":"df['PorchArea']= ' '\ndf['PorchArea']= df['OpenPorchSF']+df['EnclosedPorch']+df['3SsnPorch']+df['ScreenPorch']","df888ad7":"df['Rating']= ' '\ndf['Rating']= df['OverallQual']*df['OverallCond']","5d312554":"df['Utilities'][df['Utilities'].isna()]= 'AllPub' # imputing with mode value\n\ndf['Gas']= ' '\ndf['Water']= ' '\ndf['Septic']= ' '\n\ndf['Gas'][df['Utilities']=='AllPub']= 1\ndf['Water'][df['Utilities']=='AllPub']= 1\ndf['Septic'][df['Utilities']=='AllPub']= 1\n\ndf['Gas'][df['Utilities']=='NoSewr']= 1\ndf['Water'][df['Utilities']=='NoSewr']= 1\ndf['Septic'][df['Utilities']=='NoSewr']= 0\n\ndf['Gas'][df['Utilities']=='NoSeWa']= 1\ndf['Water'][df['Utilities']=='NoSeWa']= 0\ndf['Septic'][df['Utilities']=='NoSeWa']= 0\n\ndf['Gas'][df['Utilities']=='ELO']= 0\ndf['Water'][df['Utilities']=='ELO']= 0\ndf['Septic'][df['Utilities']=='ELO']= 0","3c8c9190":"df.drop(['1stFlrSF','2ndFlrSF','Alley','BsmtFinSF1', 'BsmtFinSF2','BsmtFinType1','BsmtFinType2','BsmtFullBath','BsmtHalfBath',\n         'BsmtUnfSF','Fence','FireplaceQu','FullBath','GarageCars','GarageCond','GarageFinish','GarageQual','GarageType',\n         'GarageYrBlt','GrLivArea','HalfBath','PoolQC', 'Condition1', 'Condition2', 'BedroomAbvGr', 'YrSold', 'YearBuilt', \n        'Cond1', 'Cond2', 'Electrical', 'Street', 'PavedDrive', 'SaleType', 'SaleCondition', 'OverallQual'], axis= 1, inplace= True)","b59b88fd":"df.drop(['LandContour','LandSlope', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'RoofStyle', 'RoofMatl',\n        'MoSold','TotalBsmtSF', 'BldgType', 'BsmtExposure', 'Exterior1st', 'Exterior2nd', 'Foundation', 'Heating',\n        'KitchenAbvGr','LotFrontage', 'LotShape', 'LotConfig', 'LowQualFinSF', 'MSZoning', 'MasVnrType', 'MiscFeature',\n         'OverallCond', 'YearRemodAdd', 'Utilities'], axis= 1, inplace= True)","6a2a33f3":"train_df= df[df['SalePrice'].notna()]\ntest_df= df[df['SalePrice'].isna()]","ff543832":"train_df.drop(train_df[train_df['TotalSqFt']>15000].index, inplace= True)\nsns.scatterplot(x= train_df['TotalSqFt'], y= train_df['SalePrice'])","1e438a25":"lr= LinearRegression()\nskf= StratifiedKFold(n_splits= 10, shuffle= True)\nresult= cross_validate(lr, train_df[['Neighborhood', 'TotalSqFt']], train_df['SalePrice'], cv= skf, scoring= ['r2', 'neg_mean_absolute_error', 'neg_mean_squared_error'])\nprint('Model 0b:\\tMAE: %.8f\\t\\tMSE: %.6f\\t\\t\\tR2: %.6f'%(result['test_neg_mean_absolute_error'].mean(), result['test_neg_mean_squared_error'].mean(), result['test_r2'].mean()))","871976eb":"lr= LinearRegression()\nskf= StratifiedKFold(n_splits= 10, shuffle= True)\nresult= cross_validate(lr, train_df.drop(['SalePrice'], axis= 1), train_df['SalePrice'], cv= skf, scoring= ['r2', 'neg_mean_absolute_error', 'neg_mean_squared_error'])\nprint('Model 0b:\\tMAE: %.8f\\t\\tMSE: %.6f\\t\\t\\tR2: %.6f'%(result['test_neg_mean_absolute_error'].mean(), result['test_neg_mean_squared_error'].mean(), result['test_r2'].mean()))","a586e36e":"train_df= train_df.astype(np.float64)\ntest_df= test_df.astype(np.float64)\nlgbm = LGBMRegressor(objective='regression', \n       num_leaves=5, #was 3\n       learning_rate=0.01, \n       n_estimators=11000, #8000\n       max_bin=200, \n       bagging_fraction=0.75,\n       bagging_freq=5, \n       bagging_seed=7,\n       feature_fraction=0.4, # 'was 0.2'\n)\nlgbm.fit(train_df.drop(['SalePrice'], axis= 1), train_df['SalePrice'], eval_metric='rmse')\npred= lgbm.predict(test_df.drop(['SalePrice'], axis= 1))","3287ae5f":"lr= LinearRegression()\nskf= StratifiedKFold(n_splits= 10, shuffle= True)\nlr.fit(train_df.drop(['SalePrice'], axis= 1), train_df['SalePrice'])\npred= lr.predict(test_df.drop(['SalePrice'], axis= 1))\npred","6215df4a":"sub= pd.DataFrame({\n    \"Id\": test_df.index,\n    \"SalePrice\": pred\n})\nsub.to_csv('houseprice1.csv', index= False)","d9b1e299":"Uniting the number of bathrooms into a single variable:","38f5e9e4":"<h2><U>Model 1<\/u><\/h2>","577caa57":"<h2><U>Model 2<\/u><\/h2>","96070da0":"**Our simple linear model Model2 yields a r2 value of 0.84, that is, we are able to explain almost 84% of the total variance in the dataset using our engineered features. This is a high enough score for our simple linear model, so we stick with it. We apply this model to predict the prices for the test set.**","44402aa5":"If house has fireplaces or not.","9dfa5798":"<h4>This dataset contains 80 columns originally. As we shall see later, many of them have missing values for lack of missing features in the house itself. Hence, we should not remove missing values initially for this dataset, because that will result in loss of important information. Instead, we can encode these values as YN features: if values are missing, then they do not have that feature and vice versa.<\/h4>","9f6188f2":"Finding out the total number of missing values and rows just for reference purposes:","2103295b":"What is the condition of the house basement. Creating the rating from both 'BsmtQual' and 'BsmtCond'","e1f92480":"<h2><u>Some simple feature engineering<\/u><\/h2>\nAge of the house may be relevant. House prices generally decrease with increased age.","003a6c38":"**Dropping the unnecessary columns. Please note that before dropping them, we have retained information from each of these columns in our engineered columns, so we are not really losing any information. Retaining these columns will simply be an overhead for us at this point, and contribute to multicollinearity.**","7bb09b44":"<h2>Importing all the necessary libraries.<\/h2>","279d6651":"Imputing some more missing values.","ddf39486":"**The column 'Neighborhood' is an interesting feature; it is a categorical variable, each category corresponding to neighborhoods within Ames. Since we are not familiar with the neighborhoods, we cannot differentiate between them; however we know neighborhoods do influence house prices. For example, houses in affluent neighborhoods are likely to be more costly than those in poor neighborhoods. We can obtain that information using the average house prices to know which neighborhoods are costly to live in, and which are cheaper.**","5ea29962":"If the house has alley access or not. People generally prefer houses with direct alley access.","9644bad6":"Calculating the total square feet area of the house into a single variable. House prices increase with the increase in total square feet.","10c55a78":"Separating the whole dataframe into training & testing dataframes:","0f7df8ea":"Presence of pool is also likely to be a deciding factor. Houses with pools generally command higher prices, and are found in rich neighborhoods.","68bb9b2e":"If house has fence or not. This is important because people with pets prefer fenced houses","13f0d041":"If house has various amenities(specified in the author's pdf file) or not.","8d65f7ee":"**Imputing the missing values with their proper values. If values are missing, then they should have a zero value because we have already quantified the other categories.**","f58e4bf5":"    The author states in his documentation that \"about 80% of the variation in residential sales price can be explained by simply taking into consideration the neighborhood and total square footage (TOTAL BSMT SF+ GR LIV AREA) of the dwelling.\" Here we try to reproduce the same, using only those 2 featues, and end up with the following results:","2fc74f83":"<h2><u>Encoding the categorical variables:<\/u><\/h2>\nWe simply replace the categorical variables with numerical values corresponding to their categorical values. We could use LabelEncoder() for this purpose, but we want to give lower values to lower categories & vice versa. We choose to do this manually.","89e3f288":"If house has garage or not. People with multiple cars will generally prefer houses wth garage. They are also more likely to be rich, being able to afford higher house prices. This is a good deciding factor.","1875e63f":"<h5> To understand this dataset properly, we must have a proper grasp on the details provided by the author at https:\/\/ww2.amstat.org\/publications\/jse\/v19n3\/decock.pdf .<br><br>\nJust as the author of the dataset states, we shall construct a simple model(Model1), then a complex model(Model2) all the while trying to adhere to the guidelines specified in the file.<br><br>\nNext we shall move to stacking and ensembling, as and when needed. <\/h5>","e8870621":"**2 data points were found to be outliers in the scatterplot; those 2 observations had total square feet area of more than 15000 sqft with prices less than 400000. Those 2 can be explained by either anomalies in the dataset, or deeply discounted sales. Either way, we remove them; removal of only 2 data points is not likely to affect our regression model adversely.**","3fd1da80":"**    Earlier, we constructed a naive linear model using all the original featues present in the dataset to predict the prices. The naive model worked surprisingly well, with an r2 value of 0.80. However, we chose not to stick with it, and wanted to see if it could be increased any more. Hence all these feature engineering steps from simple intuition to construct models 1 & 2.**","e71240c6":"If the house has basement or not.","a1defc7a":"**The Model1 yields a r2 value of 0.77, which is well, adequate. Even though we could not obtain the author's claimed 80%, we came close. We move on to our next model.**","513b6eed":"If house has veneer or not."}}