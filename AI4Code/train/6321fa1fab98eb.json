{"cell_type":{"35f73d2b":"code","8f659476":"code","4850a858":"code","5968c2c8":"code","eb83a047":"code","f31bd3d8":"code","82b4e03d":"code","59576a94":"code","be797567":"code","6974520e":"code","6056f016":"code","e1e1f89c":"code","dd050f40":"code","44582d81":"code","6f388951":"code","3539c374":"code","ff4df416":"code","ca30cc93":"code","76b74b32":"code","07b633c7":"markdown","bf35e31e":"markdown","38475490":"markdown","5d14adcd":"markdown","98e9f8b5":"markdown","963722c2":"markdown","5d4a3240":"markdown","f0a84d23":"markdown","dafd458b":"markdown","31fc23c4":"markdown","2b9b3c0a":"markdown","8fd43352":"markdown","e08309ad":"markdown","4732b22f":"markdown","75b68b18":"markdown","e6d82e2f":"markdown","7f2a4027":"markdown"},"source":{"35f73d2b":"pip install nltk","8f659476":"nltk.download(\"punkt\")\nimport string\nimport re\nimport nltk\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.tokenize import TreebankWordTokenizer, RegexpTokenizer, WhitespaceTokenizer","4850a858":"text = \"I have been working at amazon full-time for more than two years. Yet, I don't have a close relationship with my manager Dr. Smith. \" + \\\n       \"No work\/life balance. \" + \\\n       \"so realistically you only will have 8 days off a year when you combine the two together. \" + \\\n       \"I live on the eastside of New York (18mi from office), and my manager isnot flexible on my start time. \" + \\\n       \"salaries in Minimum wage, Benefits capped to $100,000 per calendar year! \" + \\\n       \"there is no Principle around treating employees well. Managers' attitude is negative and treat employees with no respect. \"       \ntext","5968c2c8":"len(text)","eb83a047":"Sentence_tkns = nltk.sent_tokenize(text)\nSentence_tkns","f31bd3d8":"pnkt_sntnce_tknzr = nltk.PunktSentenceTokenizer()\npnkt_sntnce_tknzr.tokenize(text)","82b4e03d":"len(Sentence_tkns)","59576a94":"print(Sentence_tkns[0])\nprint(Sentence_tkns[7])","be797567":"print(word_tokenize(text))","6974520e":"print(nltk.word_tokenize(Sentence_tkns[4]))","6056f016":"Word_tkns = [nltk.word_tokenize(Sentence_tkns) for Sentence_tkns in Sentence_tkns]\n\nfor element in Word_tkns:\n    print(element)\n","e1e1f89c":"TBW_tkns = nltk.TreebankWordTokenizer()\nprint(TBW_tkns.tokenize(Sentence_tkns[4]))","dd050f40":"Ptrn_words = r'\\w+' \nRGX_tkns = nltk.RegexpTokenizer(pattern=Ptrn_words, gaps=False)\nprint(RGX_tkns.tokenize(Sentence_tkns[4]))","44582d81":"Ptrn_whiteSp = r'\\s+'\nRGX_tkns = nltk.RegexpTokenizer(pattern=Ptrn_whiteSp, gaps=True)\nprint(RGX_tkns.tokenize(Sentence_tkns[4]))","6f388951":"WST = nltk.WhitespaceTokenizer()\nprint(WST.tokenize(Sentence_tkns[5]))","3539c374":"def lower_tokens(tokens):\n    return [token.lower() for token in tokens]\n\nprint(lower_tokens(nltk.word_tokenize(Sentence_tkns[5])))","ff4df416":"string.punctuation","ca30cc93":"# let's create a function to remove all punctuation in each token in a list\n\ndef remove_punct(tokens):\n    punct_regex = re.compile('[{}]'.format(re.escape(string.punctuation)))\n    return [a for a,b in zip(tokens, [punct_regex.sub('', token) for token in tokens]) if b != '']","76b74b32":"print(remove_punct(lower_tokens(nltk.word_tokenize(Sentence_tkns[6]))))","07b633c7":"##### $\\color{#10A2DF}{\\text{Use the function for a text.}}$","bf35e31e":"##### $\\color{#10A2DF}{\\text{Create a function that removes punctuation.}}$","38475490":"##### $\\color{#10A2DF}{\\text{Use string punctuation to remove all punctuation from t.}}$","5d14adcd":"##### $\\color{#10A2DF}{\\text{Instal NLTK toolkit for text processing.}}$","98e9f8b5":"## <font color=#10A2DF> <p style=\"text-align: center;\">&#9733; Natural Language Processing  &#9733;<\/p><\/font> ","963722c2":"##### $\\color{#10A2DF}{\\text{Import NLTK and necessary modules and components.}}$","5d4a3240":"##### $\\color{#10A2DF}{\\text{Convert upercase words to lower case.}}$","f0a84d23":"##### $\\color{#10A2DF}{\\text{Tokenize all sentences in Sentence_tkns.}}$","dafd458b":"##### $\\color{#10A2DF}{\\text{Untrained: Create a Punkt sentence tokenizer.}}$","31fc23c4":"##### $\\color{#10A2DF}{\\text{Use Regexp Tokenizer to segment text by word characters and remove punctuations.}}$","2b9b3c0a":"##### $\\color{#10A2DF}{\\text{Trained: Convert the text to sentence tokens}}$","8fd43352":"##### $\\color{#10A2DF}{\\text{Use Whitespace Tokenizer to explicitly segment text by whitespace characters (space, tab, newline).}}$","e08309ad":"##### $\\color{#10A2DF}{\\text{Use Treebank to split standard contractions and split off commas.}}$","4732b22f":"##### $\\color{#10A2DF}{\\text{Tokenize the text by words.}}$","75b68b18":"##### $\\color{#10A2DF}{\\text{Create a body of text}}$","e6d82e2f":"##### $\\color{#10A2DF}{\\text{Word_tokenize a specific sentence with index of tokens.}}$","7f2a4027":"##### $\\color{#10A2DF}{\\text{Use Regexp Tokenizer to segment text by whitespace characters.}}$"}}