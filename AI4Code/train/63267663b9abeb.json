{"cell_type":{"a9fb3653":"code","94404022":"code","4d508e27":"code","2658ea6e":"code","baf4979e":"code","1a3534f7":"code","c87bbcd2":"code","a7fadcc5":"code","99879378":"code","36a84b8d":"code","e7c003de":"code","7a2c108b":"code","9a46da8a":"code","1f45d725":"code","c9e43043":"code","d9b39110":"code","d08060e4":"code","d57a1427":"code","1f25baba":"markdown","88836ed3":"markdown"},"source":{"a9fb3653":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans, DBSCAN\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.neighbors import NearestNeighbors\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","94404022":"# read data\ndf = pd.read_csv('\/kaggle\/input\/spotify-top-2000s-mega-dataset\/Spotify-2000.csv', delimiter=',')\ndf.dataframeName = 'Spotify-2000.csv'\ndf.shape","4d508e27":"df.columns","2658ea6e":"df.head()","baf4979e":"# convert relevant categorical variables to dummy variables\ntemp_df = pd.get_dummies(df[['Artist', 'Top Genre']])\nrelevant_df = df.join(temp_df, how='left')\nrelevant_df = relevant_df.drop(columns = ['Artist', 'Top Genre', 'Title', 'Year', 'Index', 'Length (Duration)'], axis=1)\nrelevant_df.shape","1a3534f7":"# perform PCA with 20 components\nsong_std = StandardScaler().fit_transform(relevant_df)\npca = PCA(n_components=20)\nprincipalComponents = pca.fit_transform(song_std)\npca_df = pd.DataFrame(principalComponents)","c87bbcd2":"# calculate distances for different k values\ndistortions = []\nK = range(2,10)\nfor k in K:\n    kmeanModel = KMeans(n_clusters=k, random_state=1000)\n    kmeanModel.fit(pca_df)\n    distortions.append(kmeanModel.inertia_)","a7fadcc5":"# plot elbow graph\nplt.figure(figsize=(16,8))\nplt.plot(K, distortions, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Distortion')\nplt.title('The Elbow Method showing the optimal k')\nplt.show()","99879378":"# use silhouette method to determine optimal k value\nsil = []\nfor k in K:\n    kmeanModel = KMeans(n_clusters=k, random_state=1000)\n    kmeanModel.fit(pca_df)\n    labels = kmeanModel.labels_\n    sil.append(silhouette_score(relevant_df, labels, metric = 'euclidean'))","36a84b8d":"# plot silhouette graph\nplt.figure(figsize=(16,8))\nplt.plot(K, sil, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Silhouette Score')\nplt.title('The Silhouette Method showing the optimal k')\nplt.show()","e7c003de":"# perform k-means with k=2\nsongs_kmeans = KMeans(n_clusters=2, random_state=1000).fit(pca_df)\nrelevant_df = df.drop(columns = ['Index', 'Year'], axis=1)\nrelevant_df['kmeans'] = songs_kmeans.labels_","7a2c108b":"kmeans_stats = relevant_df.groupby(['kmeans']).mean()\n\n# normalize\nkmeans_statmeans = kmeans_stats.mean(axis=0)\nkmeans_range = kmeans_stats.max(axis=0) - kmeans_stats.min(axis=0)\nkmeans_statnorm = (kmeans_stats - kmeans_statmeans) \/ kmeans_range\nkmeans_statnorm = kmeans_statnorm\n\n# make plot\nfig, (axis1, axis2) = plt.subplots(2,1,figsize=(14,14))\nkmeans_statnorm.iloc[:,:300].plot.bar(ax=axis2).legend(loc='lower left')","9a46da8a":"# relevant_df['type'] = 'NA'\n# relevant_df.loc[(relevant_df['kmeans']==0),'type8'] = 'Regular'\n# relevant_df.loc[(relevant_df['kmeans']==1),'type8'] = 'Ballad'\n\n# sort and write the results to relevant file\nrelevant_df_sorted = relevant_df[['Title', 'Artist', 'Top Genre', 'kmeans','Beats Per Minute (BPM)', 'Energy', 'Danceability', 'Loudness (dB)', 'Valence', 'Acousticness']].sort_values(['kmeans'])\nrelevant_df_sorted.to_csv('songClusterKMeans.csv',index=True)\nrelevant_df_sorted","1f45d725":"# calculate nearest neighbors\nneigh = NearestNeighbors(n_neighbors=2)\nnbrs = neigh.fit(pca_df)\ndistances, indices = nbrs.kneighbors(pca_df)","c9e43043":"# sort distances and plot graph to determine epsilon value\ndistances = np.sort(distances, axis=0)\ndistances = distances[:,1]\nplt.grid(b=True, which='major', color='#666666', linestyle='-')\nplt.plot(distances)","d9b39110":"# perform dbscan\ndbscan = DBSCAN(eps = 3, min_samples = 50)\ndbscan.fit(pca_df)\nrelevant_df = df.drop(columns = ['Index', 'Year'], axis=1)\nrelevant_df['dbscan'] = dbscan.labels_\n\ndbscan_stats = relevant_df.groupby(['dbscan']).mean()\n\n# normalize\ndbscan_statmeans = dbscan_stats.mean(axis=0)\ndbscan_range = dbscan_stats.max(axis=0) - dbscan_stats.min(axis=0)\ndbscan_statnorm = (dbscan_stats - dbscan_statmeans) \/ dbscan_range\ndbscan_statnorm = dbscan_statnorm\n\n# make plot\nfig, (axis1, axis2) = plt.subplots(2,1,figsize=(14,14))\ndbscan_statnorm.iloc[:,:7].plot.bar(ax=axis2).legend(loc='lower left')","d08060e4":"relevant_df['dbscan'].value_counts()","d57a1427":"# relevant_df['type'] = 'NA'\n# relevant_df.loc[(relevant_df['dbscan']==-1),'type8'] = 'Pop'\n# relevant_df.loc[(relevant_df['dbscan']==0),'type8'] = 'Acoustic Ballads'\n# relevant_df.loc[(relevant_df['dbscan']==1),'type8'] = 'Fast & Heavy'\n# relevant_df.loc[(relevant_df['dbscan']==2),'type8'] = 'Live'\n# relevant_df.loc[(relevant_df['dbscan']==3),'type8'] = 'Classical Rock'\n# relevant_df.loc[(relevant_df['dbscan']==4),'type8'] = 'Fast'\n# relevant_df.loc[(relevant_df['dbscan']==5),'type8'] = 'Metal'\n\n# sort and write to the relevant file\nrelevant_df_sorted = relevant_df[['Title', 'Artist', 'Top Genre', 'dbscan','Beats Per Minute (BPM)', 'Energy', 'Danceability', 'Loudness (dB)', 'Valence', 'Acousticness']].sort_values(['dbscan'])\nrelevant_df_sorted.to_csv('songClusterDBSCAN.csv',index=True)\nrelevant_df_sorted","1f25baba":"We can see from the graph that 3 is a good value for epsilon.\nI also decided to set the minimum sample variable to 50, based on domain knowledge.","88836ed3":"Elbow method was indecisive, so we tried the sillhouette method to determine the optimal k value.\nThe results were again dissapointed with the maximum score appearing for k=2"}}