{"cell_type":{"69c8e2bc":"code","443037be":"code","89aebd68":"code","1356fdfc":"code","044b06d6":"code","67c453eb":"code","98ea0e92":"code","cdcf95b5":"code","fdf64203":"code","a5dba7cd":"code","8352e079":"code","9c5e8750":"code","b0486e8b":"markdown","89fd24eb":"markdown","645bfce2":"markdown","34e37887":"markdown","52c59c60":"markdown","24075e8c":"markdown","949556e2":"markdown","9fc0bf9b":"markdown","bddb83c4":"markdown","ae3474df":"markdown","d513a504":"markdown","5514f909":"markdown","d995c6c1":"markdown","78ed37d6":"markdown"},"source":{"69c8e2bc":"# Classical array manipulation\nimport numpy as np\n\n# Image manipulation | OpenCV\nimport cv2\n\n# Showing images and evaluating model results\nimport matplotlib.pyplot as plt\n\n# VGG19 Model \nfrom keras.applications.vgg19 import VGG19\n\n# Preparing VGG19 Model\nfrom keras.layers import Dense,Flatten,Input\nfrom keras.models import Sequential\n\n# One hot label encoding\nfrom keras.utils import to_categorical\n\n# CIFAR10 dataset\nfrom keras.datasets import cifar10\n","443037be":"(x_train,y_train),(x_test,y_test) = cifar10.load_data()\nprint(\"Shape of x_train is \",x_train.shape)\nprint(\"Shape of y_train is \",y_train.shape)\nprint(\"Shape of x_test  is \",x_test.shape)\nprint(\"Shape of y_test  is\",y_test.shape)","89aebd68":"def resize_img(img):\n    numberOfImage = img.shape[0]\n    new_array = np.zeros((numberOfImage, 48,48,3))\n    for i in range(numberOfImage):\n        new_array[i] = cv2.resize(img[i,:,:,:],(48,48))\n    return new_array","1356fdfc":"x_train = resize_img(x_train)\nx_test = resize_img(x_test)\nprint(\"New shape of x_train is \",x_train.shape)\nprint(\"New shape of x_test  is \",x_test.shape)\n","044b06d6":"# one hot encoding\ny_train = to_categorical(y_train,num_classes=10)\ny_test = to_categorical(y_test,num_classes=10)\n\nprint(\"New shape of y_train is \",y_train.shape)\nprint(\"New shape of y_test  is \",y_test.shape)","67c453eb":"# Include top = add fully connected layers to layer.\n# Weights = use pretrained weights (trained in imagenet)\nvgg = VGG19(include_top=False,weights=\"imagenet\",input_shape=(48,48,3))\n\nvgg.summary()","98ea0e92":"model = Sequential()\n\n# Adding layers to the blank model\nfor layer in vgg.layers:\n    model.add(layer)\n    \n# Don't train layers again, because they are already trained\nfor layer in model.layers:\n    layer.trainable = False\n    \n# Adding fully connected layers\nmodel.add(Flatten())\nmodel.add(Dense(128))\nmodel.add(Dense(10,activation=\"softmax\"))\n\n# Checking model\nmodel.summary()","cdcf95b5":"# However before this, we need to compile the model\nmodel.compile(optimizer=\"RMSprop\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n\n# Let's train.\nhist = model.fit(x_train,y_train,validation_split=0.15,epochs=20,batch_size=1000)\n\n# We use %15 of the train set as validation set.","fdf64203":"plt.subplots(figsize=(6,4))\nplt.plot(hist.epoch,hist.history[\"loss\"],color=\"green\",label=\"Train Loss\")\nplt.plot(hist.epoch,hist.history[\"val_loss\"],color=\"blue\",label=\"Validation Loss\")\nplt.xlabel(\"Epoch Number\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.title(\"Loss Graph\")\nplt.show()","a5dba7cd":"plt.subplots(figsize=(6,4))\nplt.plot(hist.epoch,hist.history[\"accuracy\"],color=\"green\",label=\"Train Accuracy\")\nplt.plot(hist.epoch,hist.history[\"val_accuracy\"],color=\"blue\",label=\"Validation Accuracy\")\nplt.xlabel(\"Epoch Number\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.title(\"Accuracy Graph\")\nplt.show()","8352e079":"model.evaluate(x_test,y_test)","9c5e8750":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\ny_pred = model.predict_classes(x_test)\nconf_matrix = confusion_matrix(y_pred=y_pred,y_true=[np.where(r==1)[0][0] for r in y_test])\n\nplt.subplots(figsize=(7,7))\nsns.heatmap(conf_matrix,annot=True,linewidths=1.5,fmt=\".1f\",cmap=\"RdYlGn\")\nplt.show()","b0486e8b":"* As we can see our images are 32x32x3, they are too small for using them in VGG19. Therefore, we need to expand them.","89fd24eb":"# Importing Necessary Libraries and CIFAR10","645bfce2":"# Introduction\n\nHello everyone! Nowadays I've learnt what is transfer learning and why should we use transfer learning. And in this kernel I am going to apply what I have learnt. Before starting, let's take a look at the content of this kernel\n\n# Notebook Content\n1. Importing Necessary Libraries \n1. Preparing CIFAR10 Dataset\n1. Preparing VGG19 Model\n1. Fitting and Evaluating Results\n1. Final Test \n1. Conclusion","34e37887":"* Now, let's use this function in order to expand our images to 48x48","52c59c60":"* What a graph!","24075e8c":"* Everything is ready, yayy. \n* Let's train our model and test it.","949556e2":"# Preparing CIFAR10 Dataset\n\nIn this section I am going to load CIFAR10 dataset. But before, I want to explain what is CIFAR10\n\n*The CIFAR-10 dataset (Canadian Institute For Advanced Research) is a collection of images that are commonly used to train machine learning and computer vision algorithms. It is one of the most widely used datasets for machine learning research. The CIFAR-10 dataset contains 60,000 32x32 color images in 10 different classes. The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. There are 6,000 images of each class.*\n\n*From Wikipedia*","9fc0bf9b":"# Preparing VGG19 Model\n\nOur dataset is ready, now we need a model. In this section I am going to prepare pre trained VGG19 model.","bddb83c4":"# Fitting and Evaluating Model\nIn this section I am going to fit the model. It will be easyyy.","ae3474df":"# Final Test\nIn this section I am going to test the model using our test set.","d513a504":"# Conclusion\n\nThanks for your attention, if you have questions in your mind, please ask, I will definetely return to you. ","5514f909":"* VGG19 looks good, but it needs fully connected layers \ud83d\ude1c\n* Now I am going to create a blank model, then I will add all the layers of VGG19 to that model and add fully connnected layers.\n","d995c6c1":"* Our images are ready, but I can't say the same for labels. Let's prepare our labels.","78ed37d6":"In this section I am going to import necessary libraries."}}