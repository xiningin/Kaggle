{"cell_type":{"ad691813":"code","cba6c666":"code","d920a8d7":"code","ed8f481c":"code","bedac263":"code","e377c3d4":"code","7937ea8d":"code","d0892eae":"code","e5c81c46":"code","2047704b":"code","2643154a":"code","29fb80fc":"code","5653cd47":"code","38c5e93c":"code","8beaf9ad":"code","dc861675":"code","06652afd":"code","3c60dce4":"code","4058b2b6":"code","b754d60c":"code","fa27dd77":"code","f815f8db":"code","c9e3b223":"code","6f49b6da":"code","25abe96d":"code","633ceb91":"code","31df27f4":"code","00977c32":"code","45ef00ee":"code","50014087":"code","191fe86b":"code","59a8adc1":"code","40460586":"code","ed20b36a":"code","05770520":"code","bb24b6fa":"code","43d55e8e":"code","9179be7b":"code","297026c2":"code","5e12c0c8":"code","298d35d9":"code","7805b53f":"code","c7ddd9c3":"code","3475676b":"code","72c098e3":"code","2b50d31e":"code","b91b0fc1":"code","7e0be024":"code","66ebaf76":"code","0591b988":"code","2c05cae8":"code","10e67ec4":"code","10131028":"code","303e76b6":"code","d67a825a":"code","04d0e3e6":"code","bdb26d58":"code","72ce5f5a":"code","3902df7d":"markdown","de54d007":"markdown","1d30e1ae":"markdown","0c7585f8":"markdown","bad29c04":"markdown","671f72ec":"markdown","1eaa4088":"markdown","b504dc48":"markdown","182392e8":"markdown","d2e93b73":"markdown","838e701c":"markdown","8ccb9b80":"markdown","cd988a38":"markdown","27a460aa":"markdown","a2935a85":"markdown","aa60cfcd":"markdown","1a204077":"markdown","285e0aa1":"markdown","cfdc9408":"markdown","d0fb91ad":"markdown"},"source":{"ad691813":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cba6c666":"df = pd.read_csv('\/kaggle\/input\/zomato-restaurants-hyderabad\/Restaurant names and Metadata.csv')\ndf1 = pd.read_csv('\/kaggle\/input\/zomato-restaurants-hyderabad\/Restaurant reviews.csv')","d920a8d7":"df.shape, df1.shape","ed8f481c":"df.describe(include = 'all')","bedac263":"df1.isnull().sum()[df1.isnull().sum()>0]","e377c3d4":"df1 = df1.dropna()","7937ea8d":"df1['Rating'] =df1['Rating'].str.replace('Like', '5')","d0892eae":"df1['Rating'] = df1['Rating'].astype(float)","e5c81c46":"df1['Time'] = pd.to_datetime(df1['Time'])\ndf1['Time'].min(),df1['Time'].max()","2047704b":"df1['Metadata'] =df1['Metadata'].str.replace(' Review', ' Reviews')","2643154a":"df1['reviews'] = df1['Metadata'].str.replace('[^0-9,]','').str.split(',').str[0].astype(float)\ndf1['followers'] = df1['Metadata'].str.replace('[^0-9,]','').str.split(',').str[1].astype(float)","29fb80fc":"df1['reviews'] = df1['reviews'].astype(float)","5653cd47":"df1['followers'].fillna('0', inplace = True)","38c5e93c":"df1['followers'] = df1['followers'].astype(float)","8beaf9ad":"df1['Time'] = pd.to_datetime(df1['Time'])\ndf1['Day'] = df1['Time'].dt.day\ndf1['Month'] = df1['Time'].dt.month\ndf1['Year'] = df1['Time'].dt.year","dc861675":"import matplotlib.pyplot as plt\nimport seaborn as sns","06652afd":"plt.figure(figsize=(15, 8))\nres_rating_5 = df1.groupby(['Restaurant','Rating'])['Rating'].count()\ntop_res_having_5_ratings = res_rating_5.sort_values(ascending = False).head(11)\nchart1 = top_res_having_5_ratings[::-1].plot.bar()\nfor p in chart1.patches:\n    chart1.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() \/ 2., \n                                                   p.get_height()), ha = 'center', va = 'center', \n                   xytext = (0, 10), textcoords = 'offset points')\nplt.ylabel('Number_of_5_Ratings')\nplt.xlabel('Restaurant_Name')","3c60dce4":"plt.figure(figsize=(15, 4))\nres_max_pics = df1.groupby('Restaurant')['Pictures'].max()\nres_with_more_pics = res_max_pics.sort_values(ascending = False).head(21)\nchart1 = res_with_more_pics[::-1].plot.bar()\nfor p in chart1.patches:\n    chart1.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() \/ 2., \n                                                   p.get_height()), ha = 'center', va = 'center', \n                   xytext = (0, 10), textcoords = 'offset points')\nplt.ylabel('Pictures_Count')\nplt.xlabel('Restaurant_Name')","4058b2b6":"plt.figure(figsize=(20, 8))\nchart1 = sns.countplot(x = 'Reviewer', data=df1,\n              order=df1.Reviewer.value_counts().iloc[:10].index)\nfor p in chart1.patches:\n    chart1.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() \/ 2., \n                                                   p.get_height()), ha = 'center', va = 'center', \n                   xytext = (0, 10), textcoords = 'offset points')","b754d60c":"plt.figure(figsize=(15, 4))\nres_avg_rating = df1.groupby('Restaurant')['Rating'].mean()\ntop10_res = res_avg_rating.sort_values(ascending = False).head(10)\nchart1 = top10_res[::-1].plot.bar()\nfor p in chart1.patches:\n    chart1.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() \/ 2., \n                                                   p.get_height()), ha = 'center', va = 'center', \n                   xytext = (0, 10), textcoords = 'offset points')\nplt.xlabel('Restaurant_Name')\nplt.ylabel('Avg_Rating')","fa27dd77":"plt.figure(figsize=(25, 6))\nreviewers_total_pics_posted = df1.groupby('Reviewer')['Pictures'].sum()\nreviewers_with_30_or_more_pics = reviewers_total_pics_posted.sort_values(ascending = False).head(33)\nchart1 = reviewers_with_30_or_more_pics[::-1].plot.bar()\nfor p in chart1.patches:\n    chart1.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() \/ 2., \n                                                   p.get_height()), ha = 'center', va = 'center', \n                   xytext = (0, 10), textcoords = 'offset points')\nplt.ylabel('Total Number of Pictures Posted by Reviewer')\nplt.xlabel('Reviewer_Name')","f815f8db":"plt.figure(figsize=(15, 6))\ntotal_reviews_of_reviewers = df1.groupby('Reviewer')['reviews'].sum()\ntop10_reviewers = total_reviews_of_reviewers.sort_values(ascending = False).head(10)\nchart1 = top10_reviewers[::-1].plot.bar()\nfor p in chart1.patches:\n    chart1.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() \/ 2., \n                                                   p.get_height()), ha = 'center', va = 'center', \n                   xytext = (0, 10), textcoords = 'offset points')\nplt.xlabel('Reviewers_Name')\nplt.ylabel('Total_Views_on-the_Reviews_by_Reviewers')","c9e3b223":"plt.figure(figsize=(15, 6))\ntotal_followers_of_reviewers = df1.groupby('Reviewer')['followers'].sum()\ntop10_reviewers = total_followers_of_reviewers.sort_values(ascending = False).head(10)\nchart1 = top10_reviewers[::-1].plot.bar()\nfor p in chart1.patches:\n    chart1.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() \/ 2., \n                                                   p.get_height()), ha = 'center', va = 'center', \n                   xytext = (0, 10), textcoords = 'offset points')\nplt.xlabel('Reviewers_Name')\nplt.ylabel('Total_Followers_of_the_Reviewers')","6f49b6da":"plt.figure(figsize=(15, 4))\nres_avg_rating = df1.groupby(['Restaurant', 'Year'])['Rating'].mean()\ntop10_res = res_avg_rating.sort_values(ascending = False).head(10)\nchart1 = top10_res[::-1].plot.bar()\nfor p in chart1.patches:\n    chart1.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() \/ 2., \n                                                   p.get_height()), ha = 'center', va = 'center', \n                   xytext = (0, 10), textcoords = 'offset points')\nplt.ylabel('Rating')\nplt.xlabel('Restaurant_Name')","25abe96d":"plt.figure(figsize=(15, 4))\ndf1.resample('1D',on='Time')['Restaurant'].size().plot.line() ## Instead of '1Y' we can use '1d' or '1m' or '1H'\nplt.xlabel('Date')\nplt.ylabel('No. of Reviews')\nplt.show()","633ceb91":"from wordcloud import WordCloud\n\nplt.figure(figsize=(15, 4))\nip_string = ' '.join(df1['Review'].dropna().to_list())\n\nwc = WordCloud(background_color='white').generate(ip_string.lower())\nplt.imshow(wc)","31df27f4":"# Word_Count\ndf1['Word_Count'] = df1['Review'].apply(lambda x: len(str(x).split()))","00977c32":"# Character_Count\ndf1['Char_Count'] = df1['Review'].apply(lambda x: len(x))","45ef00ee":"# Count hashtags(#) and @ mentions\n\ndf1['hashtags_count'] = df1['Review'].apply(lambda x: len([t for t in x.split() if t.startswith('#')]))\ndf1['mention_count'] = df1['Review'].apply(lambda x: len([t for t in x.split() if t.startswith('@')]))","50014087":"# If numeric digits are present in tweets\n\ndf1['numerics_count'] = df1['Review'].apply(lambda x: len([t for t in x.split() if t.isdigit()]))","191fe86b":"# UPPER_case_words_count#\n\ndf1['UPPER_CASE_COUNT'] = df1['Review'].apply(lambda x: len([t for t in  x.split()\n                                                             if t.isupper() and len(x)>3]))","59a8adc1":"import re","40460586":"# Count and Removing Emails\ndf1['Emails'] = df1['Review'].apply(lambda x: re.findall(r'([a-zA-Z0-9+._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+)',x))\ndf1['Review'] = df1['Review'].apply(lambda x: re.sub(r'([a-zA-Z0-9+._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+)', '',x))","ed20b36a":"# Count and Remove URL's\ndf1['URL_Flags'] = df1['Review'].apply(lambda x: len(re.findall(r'(http|ftp|https):\/\/([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\/~+#-]*[\\w@?^=%&\/~+#-])?', x)))\ndf1['Review'] = df1['Review'].apply(lambda x: re.sub(r'(http|ftp|https):\/\/([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\/~+#-]*[\\w@?^=%&\/~+#-])?', '', x))","05770520":"# Removing RE_REVIEWS\ndf1['Review'] = df1['Review'].apply(lambda x: re.sub('RT', '', x))","bb24b6fa":"# Punctuation_Count\ndf1['punct_count'] = df1['Review'].apply(lambda x: len(re.findall('[^a-z A-Z 0-9-]+', x)))","43d55e8e":"# Removal of special chars and punctuation\ndf1['Review'] = df1['Review'].apply(lambda x: re.sub('[^a-z A-Z 0-9-]+', '', x))","9179be7b":"# Removing_Multiple_Spaces\ndf1['Review'] = df1['Review'].apply(lambda x: ' '.join(x.split()))","297026c2":"# Preprocessing and cleaning\n\ncontractions = {\n\"aight\": \"alright\",\n\"ain't\": \"am not\",\n\"amn't\": \"am not\",\n\"aren't\": \"are not\",\n\"can't\": \"can not\",\n\"cause\": \"because\",\n\"could've\": \"could have\",\n\"couldn't\": \"could not\",\n\"couldn't've\": \"could not have\",\n\"daren't\": \"dare not\",\n\"daresn't\": \"dare not\",\n\"dasn't\": \"dare not\",\n\"didn't\": \"did not\",\n\"doesn't\": \"does not\",\n\"don't\": \"do not\",\n\"d'ye\": \"do you\",\n\"e'er\": \"ever\",\n\"everybody's\": \"everybody is\",\n\"everyone's\": \"everyone is\",\n\"finna\": \"fixing to\",\n\"g'day\": \"good day\",\n\"gimme\": \"give me\",\n\"giv'n\": \"given\",\n\"gonna\": \"going to\",\n\"gon't\": \"go not\",\n\"gotta\": \"got to\",\n\"hadn't\": \"had not\",\n\"had've\": \"had have\",\n\"hasn't\": \"has not\",\n\"haven't\": \"have not\",\n\"he'd\": \"he would\",\n\"he'dn't've'd\": \"he would not have had\",\n\"he'll\": \"he will\",\n\"he's\": \"he is\",\n\"he've\": \"he have\",\n\"how'd\": \"how did\",\n\"howdy\": \"how do you do\",\n\"how'll\": \"how will\",\n\"how're\": \"how are\",\n\"I'll\": \"I will\",\n\"I'm\": \"I am\",\n\"I'm'a\": \"I am about to\",\n\"I'm'o\": \"I am going to\",\n\"innit\": \"is it not\",\n\"I've\": \"I have\",\n\"isn't\": \"is not\",\n\"it'd\": \"it would\",\n\"it'll\": \"it will\",\n\"it's\": \"it is\",\n\"let's\": \"let us\",\n\"ma'am\": \"madam\",\n\"mayn't\": \"may not\",\n\"may've\": \"may have\",\n\"methinks\": \"me thinks\",\n\"mightn't\": \"might not\",\n\"might've\": \"might have\",\n\"mustn't\": \"must not\",\n\"mustn't've\": \"must not have\",\n\"must've\": \"must have\",\n\"needn't\": \"need not\",\n\"ne'er\": \"never\",\n\"o'clock\": \"of the clock\",\n\"o'er\": \"over\",\n\"ol'\": \"old\",\n\"oughtn't\": \"ought not\",\n\"'s\": \"is, has, does, or us\",\n\"shalln't\": \"shall not\",\n\"shan't\": \"shall not\",\n\"she'd\": \"she had\",\n\"she'll\": \"she will\",\n\"she's\": \"she is\",\n\"should've\": \"should have\",\n\"shouldn't\": \"should not\",\n\"shouldn't've\": \"should not have\",\n\"somebody's\": \"somebody is\",\n\"someone's\": \"someone is\",\n\"something's\": \"something is\",\n\"so're\": \"so are\",\n\"that'll\": \"that will\",\n\"that're\": \"that are\",\n\"that's\": \"that is\",\n\"that'd\": \"that would\",\n\"there'd\": \"there had\",\n\"there'll\": \"there will\",\n\"there're\": \"there are\",\n\"there's\": \"there is\",\n\"these're\": \"these are\",\n\"these've\": \"these have\",\n\"they'd\": \"they had\",\n\"they'll\": \"they will\",\n\"they're\": \"they are\",\n\"they've\": \"they have\",\n\"this's\": \"this is\",\n\"those're\": \"those are\",\n\"those've\": \"those have\",\n\"'tis\": \"it is\",\n\"to've\": \"to have\",\n\"'twas\": \"it was\",\n\"wanna\": \"want to\",\n\"wasn't\": \"was not\",\n\"we'd\": \"we had\",\n\"we'll\": \"we will\",\n\"we're\": \"we are\",\n\"we've\": \"we have\",\n\"weren't\": \"were not\",\n\"what'd\": \"what did\",\n\"what'll\": \"what will\",\n\"what're\": \"what are\",\n\"what's\": \"what is\",\n\"what've\": \"what have\",\n\"when's\": \"when is\",\n\"where'd\": \"where did\",\n\"where'll\": \"where will\",\n\"where're\": \"where are\",\n\"where's\": \"where is\",\n\"where's\": \"where does\",\n\"where've\": \"where have\",\n\"which'd\": \"which would\",\n\"which'll\": \"which will\",\n\"which're\": \"which are\",\n\"which's\": \"which is\",\n\"which've\": \"which have\",\n\"who'd\": \"who would\",\n\"who'd've\": \"who would have\",\n\"who'll\": \"who will\",\n\"who're\": \"who are\",\n\"who's\": \"who does\",\n\"who've\": \"who have\",\n\"why'd\": \"why did\",\n\"why're\": \"why are\",\n\"why's\": \"why does\",\n\"won't\": \"will not\",\n\"would've\": \"would have\",\n\"wouldn't\": \"would not\",\n\"wouldn't've\": \"would not have\",\n\"y'all\": \"you all\",\n\"y'all'd've\": \"you all would have\",\n\"y'all'dn't've'd\": \"you all would not have had\",\n\"y'all're\": \"you all are\",\n\"you'd\": \"you would\",\n\"you'll\": \"you will\",\n\"you're\": \"you are\",\n\"you've\": \"you have\",\n\" u \": \"you\",\n\" ur \": \"your\",\n\" n \": \"and\"\n}","5e12c0c8":"def cont_to_exp(x):\n    if type(x) is str:\n        for key in contractions:\n            value = contractions[key]\n            x = x.replace(key,value)\n        return x\n    else:\n        return x","298d35d9":"df1['Review'] = df1['Review'].apply(lambda x: cont_to_exp(x))","7805b53f":"from textblob import TextBlob\n\npol = lambda x: TextBlob(x).sentiment.polarity\nsub = lambda x: TextBlob(x).sentiment.subjectivity\n\ndf1['polarity'] = df1['Review'].apply(pol)\ndf1['subjectivity'] = df1['Review'].apply(sub)\ndf1.head()","c7ddd9c3":"df1['Sentiments'] = df1['polarity'].apply(lambda v: 'Positive' if v>0.000000 else ('Negative' if v<0.000000 else 'Neutral'))","3475676b":"import spacy\nnlp = spacy.load('en_core_web_sm')\nimport string","72c098e3":"from spacy.lang.en.stop_words import STOP_WORDS","2b50d31e":"stopwords = list(STOP_WORDS)","b91b0fc1":"punct = string.punctuation","7e0be024":"def text_data_cleaning(sentence):\n    doc = nlp(sentence)\n    tokens = []\n    for token in doc:\n        if token.lemma_ != '-PRON-':\n            temp = token.lemma_.lower().strip()\n        else:\n            temp = token.lower_\n        tokens.append(temp)\n    \n    cleaned_tokens = []\n    for token in tokens:\n        if token not in stopwords and token not in punct:\n            cleaned_tokens.append(token)\n    return cleaned_tokens","66ebaf76":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import LinearSVC\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\nfrom sklearn.preprocessing import MinMaxScaler","0591b988":"tfidf = TfidfVectorizer(tokenizer = text_data_cleaning)\nclassifier = LinearSVC()","2c05cae8":"X = df1['Review']\ny = df1['Sentiments']","10e67ec4":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","10131028":"X_train.shape, X_test.shape","303e76b6":"clf = Pipeline([('tfidf', tfidf), ('clf', classifier)])","d67a825a":"clf.fit(X_train, y_train)","04d0e3e6":"y_pred = clf.predict(X_test)","bdb26d58":"print(classification_report(y_test,y_pred))","72ce5f5a":"confusion_matrix(y_test,y_pred)","3902df7d":"### Top 10 Reviewers whose Reviews are most seen by other people","de54d007":"### Top Restaurants having 60% and above with 5 ratings","1d30e1ae":"### Reviewers_names who have written review for more than 10 Restaurants","0c7585f8":"In 'Metadata' column we can see there are number of reviews and number of followers given. And for some rows there are just '1 Review' but no followers given. In order to seperate the column in two different columns for number of 'reviews' and 'followers' I have replaced the Review with Reviews.","bad29c04":"### And, only 2 Restaurants have got rating in the year 2016\n- Labonel\n- Chinese Pavilion","671f72ec":"### Reviewers who have posted 30 and more Pictures","1eaa4088":"### Top 10 Restaurants based on average Ratings.","b504dc48":"### Only 8 Restaurants have got ratings in the year 2017\n- Labonel\n- Chinese Pavilion\n- Cascade - Radisson Hyderabad Hitec City\n- Collage - Hyatt Hyderabad Gachibowli\n- Al Saba Restaurant\n- T Grill\n- Dunkin' Donuts\n- KS Bakers","182392e8":"### As, we can see for some Restaurant the ratings went too down in 2019 as compared to 2018.\n- Hitech Bawarchi Food Zone---3.33---1.84       \n- Royal Spicy Restaurant---3.90---2.69       \n- Owm Nom Nom---3.65---2.09       \n- Hyderabadi Daawat---4.30---3.28       \n- Kritunga Restaurant---3.66---2.40       \n- Domino's Pizza---3.32---1.54       \n- Triptify---3.83---2.28       \n- Shree Santosh Dhaba Family Restaurant---3.10---1.75       \n- Mathura Vilas---3.24---2.41       \n- Mohammedia Shawarma---3.21---1.73       \n- La La Land - Bar & Kitchen---3.56---2.85       \n- SKYHY---3.75---2.91       \n- Green Bawarchi Restaurant---3.63---2.75       \n- Hotel Zara Hi-Fi---2.77---1.93\n- Collage - Hyatt Hyderabad Gachibowli---3.64---2.62\n- Al Saba Restaurant---3.25---2.50\n- Dunkin' Donuts---3.14---2.29\n- KS Bakers---3.75---3.27","d2e93b73":"In 'Rating' column there were some columns given as like. I have converted them as 5 ratings.","838e701c":"### Finding the Polarity and Subjectivity of Reviews","8ccb9b80":"### Restaurants in which Reviewers have posted 20 and more pictures","cd988a38":"### Top 10 Restaurants in 2019 based on average ratings\n- AB's - Absolute Barbecues\n- B-Dubs\n- 3B's - Buddies, Bar & Barbecue\n- Paradise\n- Flechazo\n- Cascade - Radisson Hyderabad Hitec City\n- The Indi Grill\n- Karachi Bakery\n- Zega - Sheraton Hyderabad Hotel\n- Over The Moon Brew Company","27a460aa":"From above observations we can conclude that people have attached more photos in their reviews for the restaurants where they didn't liked the food.","a2935a85":"For Restaurants KS Bakers, Dunkin' Donuts , T Grill, Al Saba Restaurant, Collage - Hyatt Hyderabad Gachibowli Ratiings have been gradually decreasing over the year.\n\nFor Restaurants Cascade - Radisson Hyderabad Hitec City, Barbeque Nation, The Foodie Monster Kitchen, Dine O China, Pista House, Delhi-39, Sardarji's Chaats & More, Karachi Bakery Ratings have been increasing over the year.","aa60cfcd":"### Top 10 Reviewers having most followers","1a204077":"Out of all Reviews there are 7457 Positive reviews, 1994 Negative Reviews and 504 Neutral Reviews.","285e0aa1":"### Top 10 Restaurants in 2018 based on average ratings\n- Feast - Sheraton Hyderabad Hotel\n- Zega - Sheraton Hyderabad Hotel\n- Mazzo - Marriott Executive Apartments\n- Hyderabadi Daawat\n- Cascade - Radisson Hyderabad Hitec City\n- NorFest - The Dhaba\n- Udipi's Upahar\n- American Wild Wings\n- Amul\n- Barbeque Nation","cfdc9408":"The given Restaurant Reviews Data is for 3  Years.","d0fb91ad":"There are 1341 People who have written reviews for more than 1 Restaurant. Out of which 150 People have written reviews for 5 or more Restaurants."}}