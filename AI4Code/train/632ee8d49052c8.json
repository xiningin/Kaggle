{"cell_type":{"a17bde26":"code","80c11ce3":"code","da588812":"code","9fdbe70d":"code","6f31a9a8":"code","21d99d01":"code","fb92a6c2":"code","c86047a1":"code","6aabfd84":"code","796f97d8":"code","a6b3a782":"code","08907508":"markdown"},"source":{"a17bde26":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn import preprocessing\nfrom sklearn.metrics import log_loss\n\nimport pandas as pd\nimport numpy as np\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import activations,callbacks\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\n\nfrom keras.models import Model","80c11ce3":"train = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/test.csv')","da588812":"target = pd.get_dummies(train['target'])\ny = train['target']","9fdbe70d":"X = train.iloc[:,1:-1]\ntest = test.iloc[:,1:]\nX.shape, test.shape","6f31a9a8":"def api_func_embedding():\n    inputs_API_Embedding = layers.Input(shape = (75,), name = 'API_input_Embedding')\n    x = layers.Embedding(400, 10, input_length = 256)(inputs_API_Embedding)\n    x = layers.Flatten()(x)\n    x = layers.Dropout(0.3)(x)\n    x = layers.Dense(100, activation='relu')(x)\n    x = layers.Dense(50, activation='relu')(x)\n    x = layers.Dense(18, activation = 'sigmoid')(x)\n    out = layers.Dense(9, activation = 'softmax', name = 'out')(x)\n    model = Model (inputs_API_Embedding,out)\n    \n    return model","21d99d01":"es = callbacks.EarlyStopping(\n                monitor = 'val_categorical_crossentropy', \n                min_delta = 0.0000001, \n                patience = 2,\n                mode = 'min',\n                baseline = None, \n                restore_best_weights = True,\n                verbose = 1)\n\nplateau  = callbacks.ReduceLROnPlateau(\n                monitor = 'val_categorical_crossentropy',\n                factor = 0.5, \n                patience = 2, \n                mode = 'min', \n                min_delt = 0.0000001,\n                cooldown = 0, \n                min_lr = 1e-7,\n                verbose = 1) \n\nmetrics = [tf.keras.metrics.CategoricalCrossentropy()]\nloss = tf.keras.losses.CategoricalCrossentropy(\n                from_logits=False,\n                label_smoothing=0,\n                reduction=\"auto\",\n                name=\"categorical_crossentropy\")","fb92a6c2":"N_FOLDS = 10\nSEED = 2021\noof = np.zeros((X.shape[0],9))\npred = np.zeros((test.shape[0],9))\n\n\nskf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n\nfor fold, (tr_idx, ts_idx) in enumerate(skf.split(X, y)):\n    print(f\"===== FOLD {fold} =====\")\n       \n    x_tr = X.iloc[tr_idx] \n    y_tr = target.iloc[tr_idx] \n    \n    x_ts = X.iloc[ts_idx] \n    y_ts = target.iloc[ts_idx] \n\n    model_nn= api_func_embedding()\n\n    model_nn.compile(tf.keras.optimizers.Adam(learning_rate=0.0001),\n            loss = loss ,\n            metrics = metrics)\n    \n    model_nn.fit(\n                    x_tr,\n                    y_tr,\n                    validation_data = (\n                    x_ts,\n                    y_ts),\n                    batch_size = 256,\n                    epochs = 50,\n                    verbose = 1,\n                    callbacks = [es,plateau])\n    \n    \n    oof[ts_idx] = model_nn.predict(x_ts)\n\n    score = log_loss(y_ts, oof[ts_idx])\n    print(f\"FOLD {fold} Score {score}\\n\")\n    \n    pred += model_nn.predict(test)\/ N_FOLDS\n\nscore = log_loss(target, oof)\nprint(f\"Score total {score}\\n\")  ","c86047a1":"submission = pd.read_csv(\"..\/input\/tabular-playground-series-jun-2021\/sample_submission.csv\")","6aabfd84":"pred_embedding = pred","796f97d8":"\nsubmission['Class_1']=pred_embedding[:,0]\nsubmission['Class_2']=pred_embedding[:,1]\nsubmission['Class_3']=pred_embedding[:,2]\nsubmission['Class_4']=pred_embedding[:,3]\nsubmission['Class_5']=pred_embedding[:,4]\nsubmission['Class_6']=pred_embedding[:,5]\nsubmission['Class_7']=pred_embedding[:,6]\nsubmission['Class_8']=pred_embedding[:,7]\nsubmission['Class_9']=pred_embedding[:,8]\nsubmission.head()","a6b3a782":"submission.to_csv(\"Keras_embedding.csv\", index=False)","08907508":"<h4> The number of columns in the dataset encourages to try embedding and it gives quite good result.\n    The onehot encoding leads to around 3300 columns and don't give good results.\n    The vertical embedding (by columns) is a bit disapointing but needs more investigation.\n    This notebook don't perform any features engineering, so it could be a way of improvement.\n    There are no missing values and no negative values.\n   "}}