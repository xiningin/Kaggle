{"cell_type":{"c87c6450":"code","ba6219b2":"code","a017005c":"code","2d8356d7":"code","74f64f3f":"code","184fbb5a":"code","56c7b29b":"code","ab2cb8e9":"code","1ef45eaf":"code","32e4de9f":"code","19065886":"code","cc5e6a8f":"code","6c64033c":"code","72b03369":"markdown"},"source":{"c87c6450":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n","ba6219b2":"import numpy as np\nimport pandas as pd\n\nfrom random import randint\n\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-white')\nimport seaborn as sns\nsns.set_style(\"white\")\n\nfrom sklearn.model_selection import train_test_split\n\nfrom skimage.transform import resize\n\nfrom keras.preprocessing.image import load_img\nfrom keras import Model\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.models import load_model\nfrom keras.optimizers import Adam\nfrom keras.utils.vis_utils import plot_model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout\n\nfrom tqdm import tqdm_notebook","a017005c":"img_size_ori = 101\nimg_size_target = 101\n","2d8356d7":"train_df = pd.read_csv(\"..\/input\/train.csv\", index_col=\"id\", usecols=[0])\ndepths_df = pd.read_csv(\"..\/input\/depths.csv\", index_col=\"id\")\n\ntrain_df = train_df.join(depths_df)\n\ntest_df = depths_df[~depths_df.index.isin(train_df.index)]","74f64f3f":"len(test_df)","184fbb5a":"train_df[\"images\"] = [np.array(load_img(\"..\/input\/train\/images\/{}.png\".format(idx), grayscale=False)) \/ 255 for idx in tqdm_notebook(train_df.index)]","56c7b29b":"train_df[\"masks\"] = [np.array(load_img(\"..\/input\/train\/masks\/{}.png\".format(idx), grayscale=True)) \/ 255 for idx in tqdm_notebook(train_df.index)]","ab2cb8e9":"# Simple split of images into training and testing sets\nids_train, ids_valid, x_train, x_valid, y_train, y_valid = train_test_split(\n    train_df.index.values,\n    np.array(train_df.images.tolist()).reshape(-1, img_size_target, img_size_target, 3), \n    np.array(train_df.masks.tolist()).reshape(-1, img_size_target, img_size_target, 1), \n    test_size=0.1, random_state=1234 )","1ef45eaf":"from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\nfrom keras.applications.mobilenet import MobileNet\nfrom keras.applications import Xception, InceptionResNetV2\nfrom keras import optimizers","32e4de9f":"base_model = Xception( include_top=False, input_shape=((101,101,3)))","19065886":"def conv_block_simple(prevlayer, filters, strides=(1, 1)):\n    conv = Conv2D(filters, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", strides=strides)(prevlayer)\n    conv = BatchNormalization()(conv)\n    conv = Activation('relu')(conv)\n    return conv","cc5e6a8f":"def build_model(start_neurons=16):\n    \n    for l in base_model.layers:\n        l.trainable = True\n    #--------------------------------------------------------------------------------------\n    conv0 = base_model.get_layer('block1_conv1_act').output # 50\n    conv1 = base_model.get_layer('block2_sepconv2_bn').output # 48\n    conv2 = base_model.get_layer('block3_sepconv2_bn').output # 24\n    conv3 = base_model.get_layer('block4_sepconv2_bn').output # 12\n    conv4_1 = base_model.get_layer('block5_sepconv1').output # 6\n    conv4 = base_model.get_layer('block13_sepconv2_bn').output # 6\n    conv5 = base_model.get_layer('conv2d_4').output # 3 ----- \u0435\u0431\u0430\u043d\u0430\u0448\u043a\u0430 \u043a\u0435\u0440\u0430\u0441, \u043d\u0435 \u043d\u043e\u0440\u043c. \u0438\u043c\u044f, \u0432\u0441\u0435\u0433\u0434\u0430 \u0440\u0430\u0437\u043d\u043e\u0435\n    conv6 = base_model.get_layer('block14_sepconv2_act').output # 3\n    \n    midlle = concatenate([conv5, conv6], axis=-1)\n    convm = conv_block_simple(midlle, start_neurons * 16)\n    convm = conv_block_simple(convm, start_neurons * 16)\n    \n    deconv1 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n    deconv1 = concatenate([deconv1, conv4])\n    deconv1 = conv_block_simple(deconv1, start_neurons * 8)\n    deconv1 = conv_block_simple(deconv1, start_neurons * 8)\n    deconv1 = concatenate([deconv1, conv4_1])\n    deconv1 = conv_block_simple(deconv1, start_neurons * 8)\n    \n    deconv2 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(deconv1)\n    deconv2 = concatenate([deconv2, conv3])\n    deconv2 = conv_block_simple(deconv2, start_neurons * 4)\n    deconv2 = conv_block_simple(deconv2, start_neurons * 4)\n    \n    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(deconv2)\n    deconv3 = concatenate([deconv3, conv2])\n    deconv3 = conv_block_simple(deconv3, start_neurons * 4)\n    deconv3 = conv_block_simple(deconv3, start_neurons * 4)\n    \n    deconv4 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(deconv3)\n    deconv4 = concatenate([deconv4, conv1])\n    deconv4 = conv_block_simple(deconv4, start_neurons * 2)\n    deconv4 = conv_block_simple(deconv4, start_neurons * 2)\n    \n    deconv5 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(1, 1), padding=\"valid\")(deconv4)\n    deconv5 = concatenate([deconv5, conv0])\n    deconv5 = conv_block_simple(deconv5, start_neurons * 1)\n    deconv5 = conv_block_simple(deconv5, start_neurons * 1)    \n    \n    inp = base_model.input\n    deconv6 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"valid\")(deconv5)\n    deconv6 = concatenate([deconv6, inp])\n    deconv6 = conv_block_simple(deconv6, start_neurons * 1)\n    deconv6 = conv_block_simple(deconv6, start_neurons * 1)     \n    \n    output = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(deconv6)\n    \n    return Model(base_model.input, output)\n","6c64033c":"model = build_model(start_neurons=4)","72b03369":"# basic Xception Unet Yielda model; XUY model(XYU model) or simply Yielda net model"}}