{"cell_type":{"0f73c71b":"code","4a9b890c":"code","cd45c35b":"code","79c71a0c":"code","1d14e6ef":"code","a256542b":"code","68e2716e":"code","c6a9f8db":"code","9369e6fb":"code","dc5a677e":"code","893fa2c3":"code","1533e2c1":"code","14af4ef9":"code","1b56fde9":"code","87463321":"code","3a69f3e6":"code","e0a9ca6a":"code","7aacc398":"code","6f8cb745":"code","bc31be83":"code","c36d1d51":"code","fe2cc8d3":"code","135aaf58":"code","b2a6a4ec":"code","e59eab87":"code","9aaccfd7":"code","f70aef76":"code","d4232695":"code","e38fe1c4":"code","8cfb6fcd":"code","7505bd21":"code","326e2030":"code","86963090":"code","40a9f569":"code","2c0030b8":"code","79688eb7":"code","03a7e76c":"code","5872b759":"code","aa5814fd":"code","e6e8d953":"code","d153a0ea":"code","0290beaf":"code","0293b194":"code","b10784a1":"code","a4416a49":"markdown","73f6756b":"markdown","b4f8de68":"markdown","cf268634":"markdown","42870fc5":"markdown","25f328a4":"markdown","82b2c936":"markdown","8071547d":"markdown"},"source":{"0f73c71b":"import numpy as np\nimport pandas as pd  \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nimport nltk\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\nimport string\n%matplotlib inline\n%precision 3","4a9b890c":"train = pd.read_csv('..\/input\/tmdb-box-office-prediction\/train.csv')\ntest = pd.read_csv('..\/input\/tmdb-box-office-prediction\/test.csv')","cd45c35b":"train.head()","79c71a0c":"train.loc[train['id'] == 1336,'runtime'] = 130 #kololyov\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntrain.loc[train['id'] == 2303,'runtime'] = 80 #HappyWeekend\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntrain.loc[train['id'] == 391,'runtime'] = 96 #The Worst Christmas of My Life\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntrain.loc[train['id'] == 592,'runtime'] = 90 #\u0410 \u043f\u043e\u0443\u0442\u0440\u0443 \u043e\u043d\u0438 \u043f\u0440\u043e\u0441\u043d\u0443\u043b\u0438\u0441\u044c\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntrain.loc[train['id'] == 925,'runtime'] = 86 #\u00bfQui\u00e9n mat\u00f3 a Bambi?\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntrain.loc[train['id'] == 978,'runtime'] = 93 #La peggior settimana della mia vita\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntrain.loc[train['id'] == 1256,'runtime'] = 92 #Cry, Onion!\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntrain.loc[train['id'] == 1542,'runtime'] = 93 #All at Once\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntrain.loc[train['id'] == 1875,'runtime'] = 93 #Vermist\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntrain.loc[train['id'] == 2151,'runtime'] = 108 #Mechenosets\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntrain.loc[train['id'] == 2499,'runtime'] = 86 #Na Igre 2. Novyy Uroven\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntrain.loc[train['id'] == 2646,'runtime'] = 98 #My Old Classmate\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntrain.loc[train['id'] == 2786,'runtime'] = 111 #Revelation\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntrain.loc[train['id'] == 2866,'runtime'] = 96 #Tutto tutto niente niente\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntest.loc[test['id'] == 3244,'runtime'] = 93 #La caliente ni\u00f1a Julietta\t\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntest.loc[test['id'] == 4490,'runtime'] = 90 #Pancho, el perro millonario\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntest.loc[test['id'] == 4633,'runtime'] = 108 #Nunca en horas de clase\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntest.loc[test['id'] == 6818,'runtime'] = 90 #Miesten v\u00e4lisi\u00e4 keskusteluja\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntest.loc[test['id'] == 4074,'runtime'] = 103 #Shikshanachya Aaicha Gho\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntest.loc[test['id'] == 4222,'runtime'] = 91 #Street Knight\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntest.loc[test['id'] == 4431,'runtime'] = 96 #Plus one\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntest.loc[test['id'] == 5520,'runtime'] = 86 #Glukhar v kino\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntest.loc[test['id'] == 5845,'runtime'] = 83 #Frau M\u00fcller muss weg!\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntest.loc[test['id'] == 5849,'runtime'] = 140 #Shabd\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntest.loc[test['id'] == 6210,'runtime'] = 104 #The Last Breath\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntest.loc[test['id'] == 6804,'runtime'] = 140 #Chaahat Ek Nasha...\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntest.loc[test['id'] == 7321,'runtime'] = 87 #El truco del manco\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b","1d14e6ef":"train_add = pd.read_csv('..\/input\/tmdb-competition-additional-features\/TrainAdditionalFeatures.csv')\ntest_add = pd.read_csv('..\/input\/tmdb-competition-additional-features\/TestAdditionalFeatures.csv')\n\ntrain = pd.merge(train, train_add, how='left', on=['imdb_id'])\ntest = pd.merge(test, test_add, how='left', on=['imdb_id'])","a256542b":"df = pd.concat([train, test]).set_index(\"id\")","68e2716e":"df.loc[df.index == 90,'budget'] = 30000000\ndf.loc[df.index == 118,'budget'] = 60000000\ndf.loc[df.index == 149,'budget'] = 18000000\ndf.loc[df.index == 464,'budget'] = 20000000\ndf.loc[df.index == 819,'budget'] = 90000000\ndf.loc[df.index == 1112,'budget'] = 6000000\ndf.loc[df.index == 1131,'budget'] = 4300000\ndf.loc[df.index == 1359,'budget'] = 10000000\ndf.loc[df.index == 1570,'budget'] = 15800000\ndf.loc[df.index == 1714,'budget'] = 46000000\ndf.loc[df.index == 1865,'budget'] = 80000000\ndf.loc[df.index == 2602,'budget'] = 31000000\n#id\u304c105\u30682941\u306e\u3082\u306e\u306e\u4e88\u7b97\u306f\u4e0d\u660e","c6a9f8db":"# \u5404\u30ef\u30fc\u30c9\u306e\u6709\u7121\u3092\u8868\u3059 01 \u306e\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u3092\u4f5c\u6210\ndef count_word_list(series):\n    len_max = series.apply(len).max() # \u30b8\u30e3\u30f3\u30eb\u6570\u306e\u6700\u5927\u5024\n    tmp = series.map(lambda x: x+[\"nashi\"]*(len_max-len(x))) # list\u306e\u9577\u3055\u3092\u305d\u308d\u3048\u308b\n    \n    word_set = set(sum(list(series.values), [])) # \u5168\u30b8\u30e3\u30f3\u30eb\u540d\u306eset\n    for n in range(len_max):\n        word_dfn = pd.get_dummies(tmp.apply(lambda x: x[n]))\n        word_dfn = word_dfn.reindex(word_set, axis=1).fillna(0).astype(int)\n        if n==0:\n            word_df = word_dfn\n        else:\n            word_df = word_df + word_dfn\n    \n    return word_df#.drop(\"nashi\", axis=1)","9369e6fb":"import datetime","dc5a677e":"df[df[\"release_date\"].isnull()]","893fa2c3":"# \u516c\u958b\u65e5\u306e\u6b20\u640d1\u4ef6 id=3829\n# May,2000 (https:\/\/www.imdb.com\/title\/tt0210130\/) \n# \u65e5\u306f\u4e0d\u660e\u30021\u65e5\u3092\u5165\u308c\u3066\u304a\u304f\ndf.loc[3829, \"release_date\"] = \"5\/1\/00\"","1533e2c1":"df[\"release_year\"] = pd.to_datetime(df[\"release_date\"]).dt.year.astype(int)\n# \u5e74\u306e20\u4ee5\u964d\u3092\u30012020\u5e74\u3088\u308a\u5f8c\u306e\u672a\u6765\u3068\u5224\u5b9a\u3057\u3066\u3057\u307e\u3046\u306e\u3067\u3001\u88dc\u6b63\u3002\ndf.loc[df[\"release_year\"]>2020, \"release_year\"] = df.loc[df[\"release_year\"]>2020, \"release_year\"]-100\n\ndf[\"release_month\"] = pd.to_datetime(df[\"release_date\"]).dt.month.astype(int)\ndf[\"release_day\"] = pd.to_datetime(df[\"release_date\"]).dt.day.astype(int)","14af4ef9":"train[\"release_year\"] = pd.to_datetime(train[\"release_date\"]).dt.year.astype(int)\n# \u5e74\u306e20\u4ee5\u964d\u3092\u30012020\u5e74\u3088\u308a\u5f8c\u306e\u672a\u6765\u3068\u5224\u5b9a\u3057\u3066\u3057\u307e\u3046\u306e\u3067\u3001\u88dc\u6b63\u3002\ntrain.loc[train[\"release_year\"]>2020, \"release_year\"] = train.loc[train[\"release_year\"]>2020, \"release_year\"]-100\n\ntrain[\"release_month\"] = pd.to_datetime(train[\"release_date\"]).dt.month.astype(int)\ntrain[\"release_day\"] = pd.to_datetime(train[\"release_date\"]).dt.day.astype(int)","1b56fde9":"plt.figure(figsize=(15,8))\nsns.lineplot(x=\"release_year\", y=\"budget\", data=train)","87463321":"plt.figure(figsize=(15,8))\nsns.lineplot(x=\"release_year\", y=\"revenue\", data=train)","3a69f3e6":"plt.figure(figsize=(15,8))\nsns.countplot(train.release_year)\nplt.xticks(rotation=90)\nplt.xlabel('Years')","e0a9ca6a":"train['budget_releaseyear_ratio'] = train['budget']\/train['release_year']","7aacc398":"plt.figure(figsize=(15,8))\nsns.distplot(train['budget_releaseyear_ratio'])","6f8cb745":"df['isbelongs_to_collectionNA'] = 1\ndf.loc[pd.isnull(df['belongs_to_collection']) ,\"isbelongs_to_collectionNA\"] = 0","bc31be83":"train['isbelongs_to_collectionNA'] = 1\ntrain.loc[pd.isnull(train['belongs_to_collection']) ,\"isbelongs_to_collectionNA\"] = 0","c36d1d51":"plt.figure(figsize=(15,8))\nsns.countplot(x='isbelongs_to_collectionNA', data=train)","fe2cc8d3":"plt.figure(figsize=(15,8))\nsns.boxplot(x='isbelongs_to_collectionNA', y='revenue', data=train);","135aaf58":"# JSON text \u3092\u8f9e\u66f8\u578b\u306e\u30ea\u30b9\u30c8\u306b\u5909\u63db\nimport ast\ndict_columns = ['belongs_to_collection', 'genres', 'production_companies',\n                'production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew']\n\nfor col in dict_columns:\n    df[col]=df[col].apply(lambda x: [] if pd.isna(x) else ast.literal_eval(x) )\n    train[col]=train[col].apply(lambda x: [] if pd.isna(x) else ast.literal_eval(x) )","b2a6a4ec":"df[\"genre_names\"] = df[\"genres\"].apply(lambda x : [ i[\"name\"] for i in x])\ntrain[\"genre_names\"] = train[\"genres\"].apply(lambda x : [ i[\"name\"] for i in x])","e59eab87":"df['num_genres'] = df['genres'].apply(lambda x: len(x) if x != {} else 0)\ntrain['num_genres'] = train['genres'].apply(lambda x: len(x) if x != {} else 0)","9aaccfd7":"plt.figure(figsize=(15,8))\nsns.barplot(x='num_genres', y='revenue', data=train);","f70aef76":"df[\"production_names\"] = df[\"production_companies\"].apply(lambda x : [ i[\"name\"] for i in x])","d4232695":"df['production_companies_count'] = df['production_companies'].apply(lambda x : len(x))\ntrain['production_companies_count'] = train['production_companies'].apply(lambda x : len(x))","e38fe1c4":"train['production_companies']","8cfb6fcd":"train['production_companies_count'].describe()","7505bd21":"plt.figure(figsize=(15,8))\nsns.countplot(x='production_companies_count', data=train)","326e2030":"plt.figure(figsize=(15,8))\nsns.stripplot(x='production_companies_count', y='revenue', data=train);","86963090":"tmp = count_word_list(df[\"production_names\"])","40a9f569":"df[\"production_names\"]","2c0030b8":"train['temp_list'] = train['title'].apply(lambda x:str(x).split())\ntop = Counter([item for sublist in train['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Blues')\n","79688eb7":"#\u8a18\u53f7\u306e\u6392\u9664\ndef remove_punct(text):\n    table=str.maketrans('','',string.punctuation)\n    return text.translate(table)","03a7e76c":"train[\"title\"]=train[\"title\"].apply(lambda x : remove_punct(x))","5872b759":"#\u5168\u3066\u5c0f\u6587\u5b57\u306b\u5909\u63db\ndef lower_text(text):\n    return text.lower()","aa5814fd":"train[\"title\"]=train[\"title\"].apply(lambda x : lower_text(x))","e6e8d953":"#\u77ed\u7e2e\u5f62\u3092\u5143\u306b\u623b\u3059\nshortened = {\n    '\\'m': ' am',\n    '\\'re': ' are',\n    'don\\'t': 'do not',\n    'doesn\\'t': 'does not',\n    'didn\\'t': 'did not',\n    'won\\'t': 'will not',\n    'wanna': 'want to',\n    'gonna': 'going to',\n    'gotta': 'got to',\n    'hafta': 'have to',\n    'needa': 'need to',\n    'outta': 'out of',\n    'kinda': 'kind of',\n    'sorta': 'sort of',\n    'lotta': 'lot of',\n    'lemme': 'let me',\n    'gimme': 'give me',\n    'getcha': 'get you',\n    'gotcha': 'got you',\n    'letcha': 'let you',\n    'betcha': 'bet you',\n    'shoulda': 'should have',\n    'coulda': 'could have',\n    'woulda': 'would have',\n    'musta': 'must have',\n    'mighta': 'might have',\n    'dunno': 'do not know',\n}\ndf[\"title\"] = df[\"title\"].replace(shortened)\ntrain[\"title\"] = train[\"title\"].replace(shortened)","d153a0ea":"def remove_stopword(text):\n    return [w for w in text if not w in stop]","0290beaf":"train['temp_list'] = train['title'].apply(lambda x:str(x).split())\ntrain['temp_list'] = train['temp_list'].apply(lambda x:remove_stopword(x))","0293b194":"train['temp_list']","b10784a1":"top = Counter([item for sublist in train['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Blues')","a4416a49":"## \u6b20\u640d\u5024\u306e\u88dc\u5b8c\u3068\u8ffd\u52a0\u30c7\u30fc\u30bf","73f6756b":"## production company","b4f8de68":"## genres","cf268634":"## title","42870fc5":"## belongstocollection","25f328a4":"genre\u6570\u304c3,4\u304c\u53ce\u76ca\u306f\u9ad8\u3044","82b2c936":"## ralease date","8071547d":"\u30b7\u30ea\u30fc\u30ba\u3082\u306e\u306frevenue\u304c\u9ad8\u3044\u306e\u3067\u30b7\u30ea\u30fc\u30ba\u304c\u3042\u308b\u304b\u3069\u3046\u304b\u3092\u7279\u5fb4\u91cf\u306b\u5165\u308c\u3066\u307f\u308b"}}