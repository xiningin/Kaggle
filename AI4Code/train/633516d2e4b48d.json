{"cell_type":{"2ad2535c":"code","91521ce5":"code","64255e76":"code","c25d44f4":"code","21e40623":"code","1ef18989":"code","e3daede9":"code","f0124afe":"code","75370dc5":"code","10083918":"markdown","70fc9c8b":"markdown","1ef3813c":"markdown","68dfad4b":"markdown","0c1ab899":"markdown","f937aab1":"markdown","a3df15ec":"markdown","547f62c3":"markdown","664f5102":"markdown"},"source":{"2ad2535c":"import tensorflow as tf\nimport numpy as np\nimport math\nimport h5py\nimport keras\nfrom keras.utils import np_utils\nfrom keras import models\nfrom keras.layers import InputLayer,Input,Reshape,MaxPooling2D,Conv2D,Dense,Flatten\nfrom keras.datasets import mnist\nimport matplotlib.pyplot as plt\nfrom keras.optimizers import Adam\nfrom keras import backend as K","91521ce5":"#\u914d\u7f6e\u795e\u7ecf\u7f51\u7edc\nimg_size=28 #\u56fe\u50cf\u7684\u6bcf\u4e2a\u7ef4\u5ea6\u4e2d\u7684\u50cf\u7d20\u6570\nimg_size_flat=28*28#\u56fe\u50cf\u5b58\u50a8\u5728\u4e00\u7ef4\u77e9\u9635\u4e2d\u7684\u603b\u957f\u5ea6\nimg_shape=(28,28)#\u7528\u6765\u91cd\u5851\u56fe\u50cf\u7684\u9ad8\u5ea6\u548c\u5bbd\u5ea6\u7684\u5143\u7956\nimg_shape_full=(28,28,1)#\u7528\u6765\u91cd\u5851\u56fe\u50cf\u7684\u9ad8\u5ea6\uff0c\u5bbd\u5ea6\u548c\u6df1\u5ea6\u7684\u5143\u7956\nnum_classes=10#\u7c7b\u522b\u6570\u91cf\nnum_channels=1#\u56fe\u50cf\u7684\u901a\u9053\u6570","64255e76":"#\u8f7d\u5165\u6570\u636e\npath='..\/input\/mnist-numpy\/mnist.npz'\nf=np.load(path)\nx_train,y_train=f['x_train'],f['y_train']\nx_test,y_test=f['x_test'],f['y_test']\nf.close()\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)","c25d44f4":"#\u7ed8\u5236\u56fe\u50cf\u7684\u8f85\u52a9\u51fd\u6570\ndef plot_images(images,cls_true,cls_pred=None):\n    assert len(images)==len(cls_true)==9\n    fig,axes=plt.subplots(3,3)\n    fig.subplots_adjust(hspace=0.3,wspace=0.3)\n\n    for i,ax in enumerate(axes.flat):\n        ax.imshow(images[i].reshape(img_shape),cmap=\"binary\")\n        if cls_pred is None:\n            xlabel=\"True:{0}\".format(cls_true[i])\n        else:\n            xlabel=\"True:{0},Pred:{1}\".format(cls_true[i],cls_pred[i])\n        ax.set_xlabel(xlabel)\n        ax.set_xticks([])\n        ax.set_yticks([])\n    plt.show()\n\n#\u7ed8\u5236\u9519\u8bef\u5206\u7c7b\u56fe\u50cf\u7684\u8f85\u52a9\u51fd\u6570\ndef plot_example_errors(cls_pred,correct):\n    incorrect=(correct==False)\n    images=x_test[incorrect]\n    cls_pred=cls_pred[incorrect]\n    cls_true=y_test[incorrect]\n    plot_images(images=images[0:9],cls_true=cls_true[0:9],cls_pred=cls_pred[0:9])","21e40623":"#\u5e8f\u5217\u6a21\u578b\nmodel=models.Sequential()\n#\u6dfb\u52a0\u4e00\u4e2a\u8f93\u5165\u5c42\nmodel.add(InputLayer(input_shape=(img_size_flat,)))\n#\u8f93\u5165\u662f\u4e00\u4e2a\u5305\u542b784\u4e2a\u5143\u7d20\u7684\u6241\u5e73\u6570\u7ec4\uff0c\u6539\u53d8\u5f62\u72b6\u4e3a\uff0828\uff0c28\uff0c1\uff09\nmodel.add(Reshape(img_shape_full))\n#\u5177\u6709Relu\u6fc0\u6d3b\u548c\u6700\u5927\u6c60\u5316\u7684\u7b2c\u4e00\u4e2a\u5377\u79ef\u5c42\nmodel.add(Conv2D(kernel_size=5,strides=1,filters=16,padding='same',activation='relu',name='layer_conv1'))\nmodel.add(MaxPooling2D(pool_size=2,strides=2))\n#\u5177\u6709Relu\u6fc0\u6d3b\u548c\u6700\u5927\u6c60\u5316\u7684\u7b2c\u4e8c\u4e2a\u5377\u79ef\u5c42\nmodel.add(Conv2D(kernel_size=5,strides=1,filters=36,padding='same',activation='relu',name='layer_conv2'))\nmodel.add(MaxPooling2D(pool_size=2,strides=2))\n#\u5c06\u5377\u79ef\u5c42\u76844\u7ea7\u8f93\u51fa\u4e3a2\u7ea7\uff0c\u53ef\u4ee5\u8f93\u5165\u5230\u5b8c\u5168\u8fde\u63a5\u5c42\nmodel.add(Flatten())\n#\u5177\u6709Relu\u6fc0\u6d3b\u7684\u7b2c\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\nmodel.add(Dense(128,activation='relu'))\n#\u6700\u540e\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\uff0c\u5177\u6709softmax\u6fc0\u6d3b\u529f\u80fd\uff0c\u7528\u4e8e\u5206\u7c7b\nmodel.add(Dense(num_classes,activation='softmax'))\n#\u7f16\u8bd1\u6a21\u578b\nmodel.compile(optimizer=Adam(lr=1e-3),loss='categorical_crossentropy',metrics=['accuracy'])\nmodel.summary()\n#\u8bad\u7ec3\u6a21\u578b\nx_train=x_train.reshape(60000,784)#\u5c06\u56fe\u7247\u644a\u5e73\nx_test=x_test.reshape(10000,784)\n#\u5f52\u4e00\u5316\nx_train=x_train\/255\nx_test=x_test\/255\n#one-hot\u7f16\u7801\ny_train=keras.utils.to_categorical(y_train,10)\ny_test=keras.utils.to_categorical(y_test,10)\nmodel.fit(x_train,y_train,epochs=1,batch_size=128,validation_split=1\/12,verbose=2)\n#\u8bc4\u4f30\u4e0e\u6027\u80fd\u6307\u6807\nresult=model.evaluate(x_test,y_test,verbose=1)\nprint(\"loss\",result[0])\nprint(\"acc\",result[1])\n#\u9884\u6d4b\npredict=model.predict(x_test)\npredict=np.argmax(predict,axis=1)\ny_test=np.argmax(y_test,axis=1)\nplot_images(x_test[0:9],y_test[0:9],predict[0:9])\n#\u9519\u5206\u7c7b\u7684\u56fe\u7247\ny_pred=model.predict(x_test)\ncls_pred=np.argmax(y_pred,axis=1)\ncorrect=(cls_pred==y_test)\nplot_example_errors(cls_pred,correct=correct)","1ef18989":"#\u529f\u80fd\u6a21\u578b\n#\u521b\u5efa\u4e00\u4e2a\u8f93\u5165\u5c42\u3002\ninputs=Input(shape=(img_size_flat,))\n#\u7528\u4e8e\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u7684\u53d8\u91cf\nnet=inputs\n#\u8f93\u5165\u662f\u4e00\u4e2a\u5305\u542b784\u4e2a\u5143\u7d20\u7684\u6241\u5e73\u6570\u7ec4\n#\u6539\u53d8\u5f62\u72b6\nnet=Reshape(img_shape_full)(net)\n#\u5177\u6709relu\u6fc0\u6d3b\u548c\u6700\u5927\u6c60\u5316\u7684\u7b2c\u4e00\u4e2a\u5377\u79ef\u5c42\nnet=Conv2D(kernel_size=5,strides=1,filters=16,padding='same',activation='relu',name='layer_conv1')(net)\nnet=MaxPooling2D(pool_size=2,strides=2)(net)\n#\u5177\u6709Relu\u6fc0\u6d3b\u548c\u6700\u5927\u6c60\u5316\u7684\u7b2c\u4e8c\u4e2a\u5377\u79ef\u5c42\nnet=Conv2D(kernel_size=5,strides=1,filters=36,padding='same',activation='relu',name='layer_conv2')(net)\nnet=MaxPooling2D(pool_size=2,strides=2)(net)\n#\u5c06\u5377\u79ef\u5c42\u76844\u7ea7\u8f93\u51fa\u5c55\u5e73\u4e3a2\u7ea7\uff0c\u53ef\u4ee5\u8f93\u5165\u5230\u5168\u8fde\u63a5\u5c42\nnet=Flatten()(net)\n#\u5177\u6709relu\u6fc0\u6d3b\u7684\u7b2c\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\nnet=Dense(128,activation='relu')(net)\n#\u6700\u540e\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\nnet=Dense(num_classes,activation='softmax')(net)\n#\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\noutputs=net\n#\u6a21\u578b\u7f16\u8bd1\nmodel2=models.Model(inputs=inputs,outputs=outputs)\nmodel2.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\nmodel.summary()\n#\u8bad\u7ec3\nmodel2.fit(x_train,y_train,batch_size=128,epochs=1,validation_split=1\/12,verbose=2)\ny_test_h=keras.utils.to_categorical(y_test,10)\nresult=model2.evaluate(x_test,y_test_h,verbose=1)\nprint(model2.metrics_names[0],result[0])\nprint(model2.metrics_names[1],result[1])\n#\u9884\u6d4b\npredict=model2.predict(x_test)\npredict=np.argmax(predict,axis=1)\nplot_images(x_test[0:9],y_test[0:9],predict[0:9])\n#\u9519\u5206\u7c7b\u7684\u7167\u7247\ny_pred=model2.predict(x_test)\ncls_pred=np.argmax(y_pred,axis=1)\ncorrect=(cls_pred==y_test)\nplot_example_errors(cls_pred,correct=correct)","e3daede9":"#\u4fdd\u5b58\u6a21\u578b\npath_model=\"..\/output\/model2.pkl\"\nmodel2.save(path_model)\n#\u5220\u9664\u6a21\u578b\ndel model2\n#\u52a0\u8f7d\u6a21\u578b3\nmodel3=models.load_model(path_model)\n#\u6a21\u578b3\u9884\u6d4b\npredict=model3.predict(x_test)\npredict=np.argmax(predict,axis=1)\nplot_images(x_test[0:9],y_test[0:9],predict[0:9])","f0124afe":"#\u5377\u79ef\u6743\u91cd\u7684\u8f85\u52a9\u51fd\u6570\ndef plot_conv_weights(weights,input_channel=0):\n    #\u83b7\u53d6\u6743\u91cd\u7684\u6700\u9ad8\u3001\u4f4e\u503c\n    #\u8fd9\u7528\u4e8e\u77eb\u6b63\u56fe\u50cf\u7684\u989c\u8272\u5f3a\u5ea6\n    w_min=np.min(weights)\n    w_max=np.max(weights)\n    #\u5377\u79ef\u5c42\u4e2d\u7684\u5377\u79ef\u6838\u6570\u91cf\n    num_filters=weights.shape[3]\n    #\u8981\u7ed8\u5236\u7684\u7f51\u683c\u6570\n    #\u5377\u79ef\u6838\u7684\u5e73\u65b9\u6839\n    num_grids=math.ceil(math.sqrt(num_filters))\n    #\u521b\u5efa\u5e26\u6709\u7f51\u683c\u5b50\u56fe\u7684\u56fe\u50cf\n    fig,axes=plt.subplots(num_grids,num_grids)\n    #\u753b\u51fa\u6240\u6709\u5377\u79ef\u6838\u7684\u8f93\u51fa\u56fe\u50cf\n    for i,ax in enumerate(axes.flat):\n     #\u4ec5\u753b\u51fa\u6709\u6548\u5377\u79ef\u6838\u56fe\u50cf\n        if i<num_filters:\n            #\u83b7\u53d6\u7b2ci\u4e2a\u5377\u79ef\u6838\u7684\u8f93\u51fa\u56fe\u50cf\n            img=weights[:,:,input_channel,i]\n            #\u753b\u56fe\n            ax.imshow(img,vmin=w_min,vmax=w_max,interpolation='nearest',cmap='seismic')\n        #\u6ea2\u51fa\u523b\u5ea6\u7ebf\n        ax.set_xticks([])\n        ax.set_yticks([])\n    plt.show()\n#\u5377\u79ef\u5c42\u8f93\u51fa\u7684\u5e2e\u52a9\u51fd\u6570\ndef plot_conv_output(values):\n    #\u5377\u79ef\u5c42\u4e2d\u7684\u5377\u79ef\u6838\u6570\u91cf\n    num_filters=values.shape[3]\n    #\u8981\u7ed8\u5236\u7684\u7f51\u683c\u6570\n    #\u5377\u79ef\u6838\u7684\u5e73\u65b9\u6839\n    num_grids=math.ceil(math.sqrt(num_filters))\n    #\u521b\u5efa\u5e26\u6709\u7f51\u683c\u5b50\u56fe\u7684\u56fe\u50cf\n    fig,axes=plt.subplots(num_grids,num_grids)\n    #\u753b\u51fa\u6240\u6709\u5377\u79ef\u6838\u7684\u8f93\u51fa\u56fe\u50cf\n    for i,ax in enumerate(axes.flat):\n        #\u4ec5\u753b\u51fa\u6709\u6548\u5377\u79ef\u6838\u56fe\u50cf\n        if i<num_filters:\n            #\u83b7\u53d6\u7b2ci\u4e2a\u5377\u79ef\u6838\u7684\u8f93\u51fa\u56fe\u50cf\n            img=values[0,:,:,i]\n            #\u753b\u56fe\n            ax.imshow(img,interpolation='nearest',cmap='binary')\n        #\u6ea2\u51fa\u523b\u5ea6\u7ebf\n        ax.set_xticks([])\n        ax.set_yticks([])\n    plt.show()\n#\u8f93\u5165\u56fe\u50cf\ndef plot_image(image):\n    plt.imshow(image.reshape(img_shape),\n              interpolation='nearest',cmap='binary')\n    plt.show()","75370dc5":"#\u5f97\u5230\u5c42\nmodel3.summary()\nlayer_input=model3.layers[0]\nlayer_conv1=model3.layers[2]\nlayer_conv2=model3.layers[4]\n#\u5377\u79ef\u6743\u91cd\nweights_conv1=layer_conv1.get_weights()[0]\nplot_conv_weights(weights=weights_conv1,input_channel=0)\nweights_conv2=layer_conv2.get_weights()[0]\nplot_conv_weights(weights=weights_conv2,input_channel=0)\n#\u8f93\u5165\u56fe\u50cf\nimage1=x_test[0]\nplot_image(image1)\n#\u5377\u79ef\u5c42\u8f93\u51fa\u4e00\noutput_conv1=K.function(inputs=[layer_input.input],outputs=[layer_conv1.output])\nlayer_output1=output_conv1(np.array([image1]))[0]\nprint(layer_output1.shape)\nplot_conv_output(values=layer_output1)\n#\u5377\u79ef\u5c42\u8f93\u51fa\u4e8c\noutput_conv2=models.Model(inputs=layer_input.input,outputs=layer_conv2.output)\nlayer_output2=output_conv2(np.array([image1]))\nprint(layer_output2.shape)\nplot_conv_output(values=layer_output2)\n","10083918":"# \u4fdd\u5b58\u52a0\u8f7d\u6a21\u578b","70fc9c8b":"# \u7ed8\u5236\u8bad\u7ec3\u7ed3\u679c\u56fe\u50cf\uff0c\u9519\u56fe\u5206\u7c7b\u56fe\u50cf\u51fd\u6570","1ef3813c":"# \u8f93\u51fa\u5404\u5377\u79ef\u5c42\u7684\u8f93\u51fa\u56fe\u50cf","68dfad4b":"# \u529f\u80fd\u6a21\u578b","0c1ab899":"# \u5e8f\u5217\u6a21\u578b","f937aab1":"# \u914d\u7f6e\u795e\u7ecf\u7f51\u7edc","a3df15ec":"# \u5bfc\u5165\u6570\u636e\u96c6","547f62c3":"# \u5bfc\u5165\u76f8\u5173\u5305","664f5102":"# \u753b\u5377\u79ef\u6743\u91cd\u7684\u8f85\u52a9\u51fd\u6570 \u753b\u5377\u79ef\u5c42\u8f93\u51fa\u7684\u8f85\u52a9\u51fd\u6570"}}