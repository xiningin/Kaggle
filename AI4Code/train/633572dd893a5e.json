{"cell_type":{"1fc8f58b":"code","181cd004":"code","fb6cd0dc":"code","17dc21b7":"code","75c82680":"code","258e6908":"code","7a1cc257":"code","a78d3641":"code","96b6ec6e":"code","9f476743":"code","013bd3a8":"code","062f1bbf":"code","2a68f900":"code","3bf00829":"code","068a5b7c":"code","a3e07486":"code","085024da":"code","48be5dc0":"code","ce1e14c1":"code","25f2ab19":"code","0356908b":"code","f6b9bf66":"code","a672dd91":"code","a4ec84a1":"code","1e73e95b":"code","1d77f392":"code","5254960f":"code","59cb957b":"code","62fb7223":"code","0556a6d0":"code","29609935":"code","88759f9d":"code","0f67f7df":"code","28ee8e23":"code","8ec8c108":"code","9a45f17d":"markdown","0dfe3475":"markdown","c7dc2e6a":"markdown","cae4277c":"markdown","2398cb06":"markdown","92eb222d":"markdown","b3a2abb9":"markdown","722a750d":"markdown","ea131329":"markdown","1d350b5e":"markdown"},"source":{"1fc8f58b":"# Importing all necessary libraries.\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os","181cd004":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","fb6cd0dc":"# Renaming the columns based on their features.\ndata_path = \"\/kaggle\/input\/wineuci\/Wine.csv\"\n\ncolumns = ['class','alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium',\n    'total_phenols', 'flavanoids', 'nonflavanoid_phenols',\n    'proanthocyanins', 'color_intensity', 'hue',\n    'od280\/od315_of_diluted_wines', 'proline']\n\ndf = pd.read_csv(data_path, names=columns, header=0)","17dc21b7":"df.head()","75c82680":"df.info()","258e6908":"df.isnull().sum()","7a1cc257":"# Using the standard scaler method to get the values converted into integers between -3 and +3.\nX = df.iloc[:, 1:14].values\nfrom sklearn.preprocessing import StandardScaler\nX = StandardScaler().fit_transform(X)","a78d3641":"X.shape","96b6ec6e":"X","9f476743":"# Using Principal Component Analysis or PCA in short to reduce the dimensionality of the data in order to optimize the result of the clustering.\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=2)\nprincipalComponents1 = pca.fit_transform(X)","013bd3a8":"principalComponents1","062f1bbf":"# Creating a dataframe featuring the two Principal components that we acquired through PCA.\nPCA_dataset1 = pd.DataFrame(data = principalComponents1, columns = ['component1', 'component2'] )\nPCA_dataset1.head()","2a68f900":"# Extracting the two features from above in order to add them to the dataframe.\nprincipal_component1 = PCA_dataset1['component1']\nprincipal_component2 = PCA_dataset1['component2']","3bf00829":"# Visualizing the effects of the Principal Component Analysis.\nplt.figure()\nplt.figure(figsize=(10,10))\nplt.xlabel('Component 1')\nplt.ylabel('Component 2')\nplt.title('2 Component PCA')\nplt.scatter(PCA_dataset1['component1'], PCA_dataset1['component2'])","068a5b7c":"# Using Principal Component Analysis or PCA in short to reduce the dimensionality of the data in order to optimize the result of the clustering.\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=3)\nprincipalComponents2 = pca.fit_transform(X)","a3e07486":"principalComponents2","085024da":"# Creating a dataframe featuring the three Principal components that we acquired through PCA.\nPCA_dataset2 = pd.DataFrame(data = principalComponents2, columns = ['component3', 'component4', 'component5'] )\nPCA_dataset2.head()","48be5dc0":"# Extracting the three features from above in order to add them to the dataframe.\nprincipal_component3 = PCA_dataset2['component3']\nprincipal_component4 = PCA_dataset2['component4']\nprincipal_component5 = PCA_dataset2['component5']","ce1e14c1":"# Visualizing the results of the 3D PCA.\nax = plt.figure(figsize=(10,10)).gca(projection='3d')\nplt.title('3D Principal Component Analysis (PCA)')\nax.scatter(\n    xs=principal_component3, \n    ys=principal_component4, \n    zs=principal_component5, \n)\nax.set_xlabel('pca-one')\nax.set_ylabel('pca-two')\nax.set_zlabel('pca-three')\nplt.show()","25f2ab19":"# Implementing t-SNE.\nfrom sklearn.manifold import TSNE\ntsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\ntsne_results1 = tsne.fit_transform(X)","0356908b":"tsne_results1","f6b9bf66":"# Creating a dataframe featuring the two principal components that we acquired through t-SNE.\ntsne_dataset1 = pd.DataFrame(data = tsne_results1, columns = ['component1', 'component2'] )\ntsne_dataset1.head()","a672dd91":"# Extracting the two features from above in order to add them to the dataframe.\ntsne_component1 = tsne_dataset1['component1']\ntsne_component2 = tsne_dataset1['component2']","a4ec84a1":"# Visualizing the effects of the T-distributed Stochastic Neighbour Embedding.\nplt.figure()\nplt.figure(figsize=(10,10))\nplt.xlabel('Component 1')\nplt.ylabel('Component 2')\nplt.title('2 Component TSNE')\nplt.scatter(tsne_component1, tsne_component2)","1e73e95b":"tsne = TSNE(n_components=3, verbose=1, perplexity=40, n_iter=300)\ntsne_results2 = tsne.fit_transform(X)","1d77f392":"tsne_results2","5254960f":"# Creating a dataframe featuring the three Principal components that we acquired through t-SNE.\ntsne_dataset2 = pd.DataFrame(data = tsne_results2, columns = ['component3', 'component4', 'component5'] )\ntsne_dataset2.head()","59cb957b":"# Extracting the three features from above in order to add them to the dataframe.\ntsne_component3 = tsne_dataset2['component3']\ntsne_component4 = tsne_dataset2['component4']\ntsne_component5 = tsne_dataset2['component5']","62fb7223":"# Visualizing the 3D t-SNE.\nax = plt.figure(figsize=(10,10)).gca(projection='3d')\nplt.title('3D T-distributed Stochastic Neighbor Embedding (TSNE)')\nax.scatter(\n    xs=tsne_component3, \n    ys=tsne_component4, \n    zs=tsne_component5, \n    #c = x_kmeans\n)\nax.set_xlabel('tsne-one')\nax.set_ylabel('tsne-two')\nax.set_zlabel('tsne-three')\nplt.show()","0556a6d0":"# Implementing UMAP.\nimport umap\nembedding = umap.UMAP(n_neighbors=50,\n                      min_dist=0.3,\n                      metric='correlation').fit_transform(X)","29609935":"umap_component1 = embedding[:,0]\numap_component2 = embedding[:,1]","88759f9d":"# Visualizing the effects of the Uniform Manifold Approximation and Projection.\nplt.figure()\nplt.figure(figsize=(10,10))\nplt.xlabel('Component 1')\nplt.ylabel('Component 2')\nplt.title('2 Component UMAP')\nplt.scatter(umap_component1, umap_component2)","0f67f7df":"import umap\nembedding2 = umap.UMAP(n_components=3,\n                      n_neighbors=50,\n                      min_dist=0.3,\n                      metric='correlation').fit_transform(X)","28ee8e23":"umap_component3 = embedding2[:,0]\numap_component4 = embedding2[:,1]\numap_component5 = embedding2[:,2]","8ec8c108":"# Visualizing the effects of the 3D UMAP.\nax = plt.figure(figsize=(10,10)).gca(projection='3d')\nplt.title('3D Uniform Manifold Approximation and Projection (UMAP)')\nax.scatter(\n    xs=umap_component3, \n    ys=umap_component4, \n    zs=umap_component5, \n    #c = x_kmeans\n)\nax.set_xlabel('umap-3d-one')\nax.set_ylabel('umap-3d-two')\nax.set_zlabel('umap-3d-three')\nplt.show()","9a45f17d":"# 2D Uniform Manifold Approximation and Projection ","0dfe3475":"# 2D&3D PCA, t-SNE, and UMAP on Wine Dataset","c7dc2e6a":"# 3D Uniform Manifold Approximation and Projection ","cae4277c":"# Data","2398cb06":"In this notebook I explore three different dimensionality reduction techniques - PCA, t-SNE, and UMAP. Although they are three different methods\/techniques, they all aim to reduce the dimensionality of the data by reducing the original number of features in to just two or three principal features. ","92eb222d":"# 3D Principal Component Analysis","b3a2abb9":"# Importing Libraries","722a750d":"# 2D Principal Component Analysis","ea131329":"# 3D T-distributed Stochastic Neighbour Embedding","1d350b5e":"# 2D T-distributed Stochastic Neighbour Embedding"}}