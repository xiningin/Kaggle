{"cell_type":{"f4ea946c":"code","e0ce83be":"code","bd7f41ab":"code","41c99cc1":"code","e992ed88":"code","56aed3f2":"code","a3d268b8":"code","d9a79df5":"code","a0ddb5e9":"code","2989187e":"code","2f8fd226":"code","40eb3053":"code","c8df41c2":"code","91af9d43":"code","a4d79158":"code","cc977231":"code","146baef4":"code","c7f3ffad":"code","c5b12560":"code","95ee2e7c":"markdown","68322590":"markdown","830dec78":"markdown","6e5bfdea":"markdown","54a7246d":"markdown","6edd4737":"markdown"},"source":{"f4ea946c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","e0ce83be":"df=pd.read_csv(\"..\/input\/ChurnData.csv\")","bd7f41ab":"df.dropna().head()","41c99cc1":"df[\"churn\"]=df[\"churn\"].astype(int)","e992ed88":"df.head()","56aed3f2":"X=np.asarray(df[['age','income','tenure']])","a3d268b8":"y=np.asarray(df[\"churn\"])","d9a79df5":"from sklearn import preprocessing","a0ddb5e9":"X=preprocessing.StandardScaler().fit(X).transform(X)","2989187e":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)","2f8fd226":"from sklearn.linear_model import LogisticRegression","40eb3053":"LR=LogisticRegression(C=0.1,solver='liblinear').fit(X_train,y_train)","c8df41c2":"yhat=LR.predict(X_test)","91af9d43":"yhat","a4d79158":"yhat_prob=LR.predict_proba(X_test)","cc977231":"yhat_prob","146baef4":"from sklearn.metrics import jaccard_similarity_score as jcs","c7f3ffad":"score=jcs(yhat,y_test)","c5b12560":"print(score)","95ee2e7c":"# About Dataset:\nWe\u2019ll use a telecommunications data for predicting customer churn. This is a historical customer data where each row represents one customer. The data is relatively easy to understand, and you may uncover insights you can use immediately. Typically it\u2019s less expensive to keep customers than acquire new ones, so the focus of this analysis is to predict the customers who will stay with the company.\n\nThis data set provides info to help you predict behavior to retain customers. You can analyze all relevant customer data and develop focused customer retention programs.\n\nThe data set includes information about:\n\nCustomers who left within the last month \u2013 the column is called Churn\nServices that each customer has signed up for \u2013 phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies\nCustomer account information \u2013 how long they\u2019ve been a customer, contract, payment method, paperless billing, monthly charges, and total charges\nDemographic info about customers \u2013 gender, age range, and if they have partners and dependents","68322590":"# The jaccard score comes out to be 0.65 which means that our model has prediction score of 65% ","830dec78":"# Calculating the probability score for each classification","6e5bfdea":"# Applying Logistic Regression","54a7246d":"# Splitting the data for training and testing\n","6edd4737":"# Calculating jaccard score"}}