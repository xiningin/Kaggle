{"cell_type":{"d10c286e":"code","e90456a9":"code","907718ed":"code","a6807528":"code","fc7d2a9e":"code","4cfc8a8d":"code","aabe0f99":"code","dd7e78ab":"code","40b16603":"code","0dd52828":"code","a9498cf0":"code","52a87230":"code","5b2db59f":"code","821d82b2":"code","30215adc":"code","ddb6337e":"code","2b15fcf0":"code","06cbb038":"code","e9c232f5":"code","1e1ede67":"code","7dd4c5d7":"code","1924e846":"code","621d50ab":"code","39389e26":"code","1151aa24":"code","effa2c29":"code","d30141a9":"code","9d0c012e":"markdown","fe30777c":"markdown","8e7e8a4c":"markdown","6cac511b":"markdown","a21f1f84":"markdown","87441a23":"markdown","bfd4efc6":"markdown","a5605e37":"markdown","e6b270c2":"markdown","23686c0e":"markdown","f771d4b5":"markdown","ac4b38fc":"markdown","fe7ffa2d":"markdown","c6995e39":"markdown","53abb94b":"markdown","10aedee5":"markdown","5ae8d719":"markdown","cdfdcb38":"markdown","3145f2ab":"markdown","4f1dce09":"markdown","905f24b5":"markdown","f5e0ca9b":"markdown","829b0576":"markdown","84c9e77a":"markdown","93936e8e":"markdown","f2d66986":"markdown","9edf6d7d":"markdown","e4e5d447":"markdown"},"source":{"d10c286e":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib as mpl\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport warnings\nwarnings.filterwarnings(action='ignore')","e90456a9":"# Data reading and first column removing\nsv = pd.read_csv('\/kaggle\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv')\nquest = sv.iloc[0, :]\nsv = sv.iloc[1:, :]\nsv.reset_index()\nsv=sv.astype({\"Time from Start to Finish (seconds)\":'int64'})\nsv=sv.rename(columns={\"Time from Start to Finish (seconds)\":\"Seconds\"})\n\n#Map ISO field add for mapping purpose\nlistc=[['Argentina','ARG'],\t['Australia','AUS'],\t['Bangladesh','BGD'],\t['Belarus','BLR'],\t['Belgium','BEL'],\t['Brazil','BRA'],\n      ['Canada','CAN'],\t['Chile','CHL'],\t['China','CHN'],\t['Colombia','COL'],\t['Egypt','EGY'],\t['France','FRA'],\t['Germany','DEU'],\t\n      ['Ghana','GHA'],\t['Greece','GRC'],\t['India','IND'],\t['Indonesia','IDN'],\t['Iran, Islamic Republic of...','IRN'],\t['Ireland','IRL'],\n      ['Israel','ISR'],\t['Italy','ITA'],\t['Japan','JPN'],\t['Kenya','KEN'],\t['Malaysia','MYS'],\t['Mexico','MEX'],\t['Morocco','MAR'],\n      ['Nepal','NPL'],\t['Netherlands','NLD'],\t['Nigeria','NGA'],\t['Other','Other'],\t['Pakistan','PAK'],\t['Peru','PER'],\t['Philippines','PHL'],\n      ['Poland','POL'],\t['Portugal','PRT'],\t['Republic of Korea','PRK'],\t['Romania','ROU'],\t['Russia','RUS'],\t['Saudi Arabia','SAU'],\t\n      ['Singapore','SGP'],\t['South Africa','ZAF'],\t['South Korea','KOR'],\t['Spain','ESP'],\t['Sri Lanka','LKA'],\t['Sweden','SWE'],\t\n      ['Switzerland','CHE'],\t['Taiwan','TWN'],\t['Thailand','THA'],\t['Tunisia','TUN'],\t['Turkey','TUR'],\t['Ukraine','UKR'],\t\n      ['United Arab Emirates','ARE'],\t['United Kingdom of Great Britain and Northern Ireland','GBR'],\t['United States of America','USA'],\t\n      ['Viet Nam','VNM']]\ncnty = pd.DataFrame(listc, columns =['Q3', 'ISO'])\nsurvey=sv.merge(cnty, on='Q3', how='left')\nsurvey.loc[survey['Q3']==\"United Kingdom of Great Britain and Northern Ireland\", \"Q3\"] = \"United Kingdom\"\nsurvey.loc[survey['Q4']==\"Some college\/university study without earning a bachelor\u2019s degree\", \"Q4\"] = \"Some college\/university\"\nsurvey.loc[survey['Q4']==\"No formal education past high school\", \"Q4\"] = \"No formal education\"\n\n#Segmentation breakdown and NULL replacement\nlist1=[['Data Analyst','Data Enthusiasts'],\t['Business Analyst','Data Enthusiasts'],\t['Data Engineer','Data Enthusiasts'],\t['DBA\/Database Engineer','Data Enthusiasts'],\t\n       ['Software Engineer','Data Enthusiasts'],\t['Statistician','Data Enthusiasts'],\t['Product\/Project Manager','Data Enthusiasts'],\t['Research Scientist','Data Enthusiasts'],\t\n       ['Student','Student'],  ['Data Scientist','Data Scientist'],\t['Machine Learning Engineer','ML Engineer'],\t['Other','Data Imposters'],\t['','Data Imposters'],\n       ['Currently not employed','Data Imposters']]\ncnty1 = pd.DataFrame(list1, columns =['Q5', 'Segm'])\nsurvey=survey.merge(cnty1, on='Q5', how='left')\nsurvey['Segm'].fillna(\"Data Imposters\", inplace = True)\n#Average Salary Numbers\nlists=[['No Data','0'],\t['100,000-124,999','112500'],\t['15,000-19,999','17500'],\t['125,000-149,999','137500'],\t['70,000-79,999','75000'],\t['30,000-39,999','35000'],\t['90,000-99,999','95000'],\t['1,000-1,999','1500'],\t['$0-999','500'],\t['10,000-14,999','12500'],\t\n ['150,000-199,999','175000'],\t['60,000-69,999','65000'],\t['4,000-4,999','4500'],\t['> $500,000','500000'],\t['300,000-500,000','400000'],\t['40,000-49,999','45000'],\t['25,000-29,999','27500'],\t\n ['80,000-89,999','85000'],\t['7,500-9,999','8750'],\t['50,000-59,999','55000'],\t['250,000-299,999','275000'],\t['5,000-7,499','6250'],\t['2,000-2,999','2500'],\t['20,000-24,999','22500'],\t['200,000-249,999','225000'],\t\n ['3,000-3,999','3500']]\nsalary=pd.DataFrame(lists, columns =['Q24', 'Salary'])\nsurvey=survey.merge(salary, on='Q24', how='left')\nsurvey['Salary'].fillna(0, inplace = True)\nsurvey['Salary']=pd.to_numeric(survey['Salary'])\n#Some Data correction\nsurvey['Average Age'] = pd.to_numeric(survey['Q1'].str[:2], errors='coerce')+2 #Average Age\nsurvey['Q1'].fillna(\"No Data\", inplace = True)\nsurvey['Q2'].fillna(\"No Data\", inplace = True)\nsurvey['Q3'].fillna(\"No Data\", inplace = True)\nsurvey['Q4'].fillna(\"No Data\", inplace = True)\nsurvey['Q5'].fillna(\"No Data\", inplace = True)\nsurvey['Q6'].fillna(\"No Data\", inplace = True)\nsurvey['Q8'].fillna(\"No Data\", inplace = True)\nsurvey['Q11'].fillna(\"No Data\", inplace = True)\nsurvey['Q24'].fillna(\"No Data\", inplace = True)\nsurvey['Q25'].fillna(\"No Data\", inplace = True)\nsurvey['Resp']=1","907718ed":"%%html\n<div class='tableauPlaceholder' id='viz1609910936706' style='position: relative'><noscript><a href='#'><img alt=' ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Ka&#47;KaggleSurvey2020_16095313150070&#47;MAIN&#47;1_rss.png' style='border: none' \/><\/a><\/noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' \/> <param name='embed_code_version' value='3' \/> <param name='site_root' value='' \/><param name='name' value='KaggleSurvey2020_16095313150070&#47;MAIN' \/><param name='tabs' value='yes' \/><param name='toolbar' value='yes' \/><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Ka&#47;KaggleSurvey2020_16095313150070&#47;MAIN&#47;1.png' \/> <param name='animate_transition' value='yes' \/><param name='display_static_image' value='yes' \/><param name='display_spinner' value='yes' \/><param name='display_overlay' value='yes' \/><param name='display_count' value='yes' \/><param name='language' value='en' \/><\/object><\/div>                <script type='text\/javascript'>                    var divElement = document.getElementById('viz1609910936706');                    var vizElement = divElement.getElementsByTagName('object')[0];                    vizElement.style.width='750px';vizElement.style.height='1250px';                    var scriptElement = document.createElement('script');                    scriptElement.src = 'https:\/\/public.tableau.com\/javascripts\/api\/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                <\/script>","a6807528":"#Map countries\ncountry=survey[[\"Q3\", \"ISO\", \"Resp\"]]\ncountry=country.groupby([\"Q3\",\"ISO\"])[\"Resp\"].sum().reset_index()\ncountry.columns=['Country', 'ISO', 'Count']\nfig = px.choropleth(data_frame=country,\n                    locations='ISO',\n                    color='Count',\n                    color_continuous_scale='inferno',\n                    hover_name='Country',\n                    labels={'Count':'Respondents'},\n                    title='Kaggle 2020 Responses by Country - MAP - Hover on country for details')\nfig.show()\n#Country Age and Average Salary chart\nsal_country=survey[survey['Q24'] !='No Data']\nsal_country=sal_country[[\"Q3\",  \"Salary\",\"Average Age\",\"Resp\"]]\nsal_country=sal_country.groupby(['Q3']).agg({'Salary':'mean', 'Average Age':'mean','Resp':'sum'}).reset_index()\nsal_country=sal_country.round({'Salary': 1, 'Average Age': 1})\nfig = px.scatter(sal_country, x=\"Salary\", y=\"Average Age\", size=\"Resp\", color=\"Salary\",color_continuous_scale='inferno',title='Kaggle 2020: Average Age and Salary by Country (hover for details)',\n           hover_name=\"Q3\",  size_max=40)\nfor annotation in fig.layout.annotations:\n    annotation.text = annotation.text.split(\"=\")[1]\n    fig.update_xaxes(showticklabels=True)\n    fig.layout.showlegend = False\nfig.show()","fc7d2a9e":"#3D data and chart\nsal_3d=survey[survey['Q24'] !='No Data']\nsal_3d=sal_3d[[\"Q3\",  \"Salary\",\"Average Age\",\"Resp\"]]\nsal_3d=sal_3d.groupby(['Q3']).agg({'Salary':'mean', 'Average Age':'mean','Resp':'sum'}).reset_index()\nsal_3d=sal_3d.round({'Salary': 1, 'Average Age': 1})\nfig = px.scatter_3d(sal_3d, x=\"Average Age\", y=\"Resp\", z=\"Salary\", color=\"Salary\", size=\"Salary\",hover_name=\"Q3\", height =800,opacity=0.8,size_max=70)\nfig.layout.showlegend = False\nfig.show()","4cfc8a8d":"top10list=['India',\t'United States of America',\t'Other', 'Brazil', 'Japan',\t'Russia', 'United Kingdom',\t'Nigeria', 'China', 'Germany', 'Turkey']\n#Building the dataframe for SEGMENTATION\nmenu1=survey[[\"Q3\", \"Segm\", \"Resp\"]]\nmenu=menu1[menu1[\"Q3\"].isin(top10list)]\nmenu=menu.groupby([\"Q3\",\"Segm\"])[\"Resp\"].sum().reset_index()\nmenu.columns=[\"Country\", \"Segment\", \"Count\"]\nmenu=menu.pivot(index=\"Segment\", columns=\"Country\", values=\"Count\").reset_index()\nmenu1=menu1.groupby([\"Segm\"])[\"Resp\"].sum().reset_index()\nmenu1.columns=[\"Segment\", \"All\"]\nmenu=pd.merge(menu,menu1[[\"Segment\", \"All\"]],on=\"Segment\", how='left')\nsegmentation_bar = menu # <-- Name of the Dataframe (bar - used for a bar chart)\n#Building the dataframe for AGE\nmenu1=survey[[\"Q3\", \"Q1\", \"Resp\"]]\nmenu=menu1[menu1[\"Q3\"].isin(top10list)]\nmenu=menu.groupby([\"Q3\",\"Q1\"])[\"Resp\"].sum().reset_index()\nmenu.columns=[\"Country\", \"Age\", \"Count\"]\nmenu=menu.pivot(index=\"Age\", columns=\"Country\", values=\"Count\").reset_index()\nmenu1=menu1.groupby([\"Q1\"])[\"Resp\"].sum().reset_index()\nmenu1.columns=[\"Age\", \"All\"]\nmenu=pd.merge(menu,menu1[[\"Age\", \"All\"]],on=\"Age\", how='left')\nage_bar=menu\ntop10age=[\"Age\", \"All\",\"India\", \"United States of America\", \"Brazil\", \"Japan\",\t\"Russia\", \"United Kingdom\",\t\"Nigeria\", \"China\", \"Germany\", \"Turkey\", \"Other\"]\nage_bar=age_bar[top10age]\nage_bar=age_bar.groupby([\"Age\"])[top10age].sum()\n#age_bar # <-- Name of the Dataframe (bar - used for a bar chart)\n\n#Building the dataframe for Experince\nmenu1=survey[[\"Q3\", \"Q6\", \"Resp\"]]\nmenu=menu1[menu1[\"Q3\"].isin(top10list)]\nmenu=menu.groupby([\"Q3\",\"Q6\"])[\"Resp\"].sum().reset_index()\nmenu.columns=[\"Country\", \"Experience\", \"Count\"]\nmenu=menu.pivot(index=\"Experience\", columns=\"Country\", values=\"Count\").reset_index()\nmenu1=menu1.groupby([\"Q6\"])[\"Resp\"].sum().reset_index()\nmenu1.columns=[\"Experience\", \"All\"]\nmenu=pd.merge(menu,menu1[[\"Experience\", \"All\"]],on=\"Experience\", how='left')\nexp_bar=menu\ntop10exp=[\"Experience\", \"All\",\"India\", \"United States of America\", \"Brazil\", \"Japan\",\t\"Russia\", \"United Kingdom\",\t\"Nigeria\", \"China\", \"Germany\", \"Turkey\", \"Other\"]\nexp_bar=exp_bar[top10exp]\nexp_bar=exp_bar.groupby([\"Experience\"])[top10exp].sum()\n#exp_bar # <-- Name of the Dataframe (bar - used for a bar chart)\n\n#Building the dataframe for Education\nmenu1=survey[[\"Q3\", \"Q4\", \"Resp\"]]\nmenu=menu1[menu1[\"Q3\"].isin(top10list)]\nmenu=menu.groupby([\"Q3\",\"Q4\"])[\"Resp\"].sum().reset_index()\nmenu.columns=[\"Country\", \"Education\", \"Count\"]\nmenu=menu.pivot(index=\"Education\", columns=\"Country\", values=\"Count\").reset_index()\nmenu1=menu1.groupby([\"Q4\"])[\"Resp\"].sum().reset_index()\nmenu1.columns=[\"Education\", \"All\"]\nmenu=pd.merge(menu,menu1[[\"Education\", \"All\"]],on=\"Education\", how='left')\nedu_bar=menu\ntop10edu=[\"Education\", \"All\",\"India\", \"United States of America\", \"Brazil\", \"Japan\",\t\"Russia\", \"United Kingdom\",\t\"Nigeria\", \"China\", \"Germany\", \"Turkey\", \"Other\"]\nedu_bar=edu_bar[top10edu]\nedu_bar=edu_bar.groupby([\"Education\"])[top10edu].sum()\n#exp_bar # <-- Name of the Dataframe (bar - used for a bar chart)\n\n#segmentation_bar\n","aabe0f99":"top10=[\"Segment\", \"All\",\"India\", \"United States of America\", \"Brazil\", \"Japan\",\t\"Russia\", \"United Kingdom\",\t\"Nigeria\", \"China\", \"Germany\", \"Turkey\", \"Other\"]\ndf=segmentation_bar[top10]\ndf=df.groupby([\"Segment\"])[top10].sum()\ndefault_v=\"All\"\ndef multi_plot(df,title):\n    fig = go.Figure()\n    for column in df.columns.to_list():\n        fig.add_trace(\n            go.Bar(\n            x = df.index,\n            y = df[column],\n            \n            text=df[column],\n            textposition='auto',\n            name = column,\n                visible=(column==default_v)\n            )\n        )\n    def create_layout_button(column):\n        return dict(label = column,\n                    method = 'update',\n                    args = [{'visible': df.columns.isin([column]),\n                                                          'showlegend': False}])\n    fig.update_layout(\n            width =800,\n            title=title,\n        title_x=0.5,\n        updatemenus=[go.layout.Updatemenu(\n            active = 0,\n            buttons =  list(df.columns.map(lambda column: create_layout_button(column))),\n            x=0.0,\n            y=1.2,\n            xanchor=\"left\",\n            yanchor=\"top\"\n                     )],\n    )\n    fig.show()\n  ","dd7e78ab":"  multi_plot(df,\"Segmentation\")","40b16603":"education=survey[[\"Segm\", \"Q4\", \"Q11\",\"Q8\",\"Q25\",\"Resp\"]]\neducation=education.groupby([\"Segm\", \"Q4\", \"Q11\",\"Q8\",\"Q25\"])[\"Resp\"].sum().reset_index()\neducation.columns=[\"Segment\", \"Education Level\", \"Platform\",\"Pr. Language Rec.\",\"Money Spent Learning\",\"Resp\"]\n\nimposters_ed = education[(education[\"Segment\"] == \"Data Imposters\")]\nimposters_ed=imposters_ed.drop(columns=['Segment']).reset_index(drop=True)\n\nenthusiast_ed=education[(education[\"Segment\"] == \"Data Enthusiasts\")]\nenthusiast_ed=enthusiast_ed.drop(columns=['Segment']).reset_index(drop=True)\n\nstudent_ed=education[(education[\"Segment\"] == \"Student\")]\nstudent_ed=student_ed.drop(columns=['Segment']).reset_index(drop=True)\n\nscientist_ed=education[(education[\"Segment\"] ==  \"Data Scientist\")]\nscientist_ed=scientist_ed.drop(columns=['Segment']).reset_index(drop=True)\n\nmachinel_ed=education[(education[\"Segment\"] == \"ML Engineer\")]\nmachinel_ed=machinel_ed.drop(columns=['Segment']).reset_index(drop=True)\n\n","0dd52828":"fin=survey[[\"Q1\",\"Q2\", \"Segm\", \"Salary\",\"Average Age\",\"Resp\"]]\nfin.columns=[\"Age\",\"Gender\", \"Segm\", \"Salary\",\"Average Age\",\"Resp\"]\n# Build parcats dimensions\ncategorical_dimensions = ['Age', 'Gender', 'Segm']\ndimensions = [dict(values=fin[label], label=label) for label in categorical_dimensions]\n# Build colorscale\ncolor = 'lightseagreen'\ncmin = -0.5\ncmax = 2.5\nfig = go.FigureWidget(\n    data=[go.Scatter(x=fin.Salary, y=fin['Average Age'], \n                marker={ 'color':color, 'cmin': cmin, 'cmax': cmax,\n                         'showscale': False,\n                       },\n                     mode='markers'),\n      go.Parcats(domain={'y': [0, 0.4]}, dimensions=dimensions,\n                   line={'color':color, 'cmin': cmin,\n                   'cmax': cmax,  'shape': 'hspline'})]\n)\nfig.update_layout(height=800, width=800,title= \"All respondents on the map + Sankey with breakdown by Age, Gender and Segment\", xaxis={'title': 'Salary'},\n                  yaxis={'title': 'Age', 'domain': [0.6, 1]},\n                  dragmode='lasso', hovermode='closest')\nfig.show()","a9498cf0":"fig = px.sunburst(imposters_ed,\n                  path=[\"Education Level\", \"Platform\",\"Pr. Language Rec.\",\"Money Spent Learning\"],\n                  values='Resp',\n                  branchvalues='total',\n                  height=600,\n                  title=\"<b> Education Analysis for - Data Imposters (click on chart to interact)<\/b>\"\n                  )\nfig.update_layout(\n    font_size=12,\n    title_font_color=\"black\",\n)\nfig.show()\n\nfig = px.sunburst(student_ed,\n                  path=[\"Education Level\", \"Platform\",\"Pr. Language Rec.\",\"Money Spent Learning\"],\n                  values='Resp',\n                  branchvalues='total',\n                  height=600,\n                  title=\"<b>Education Analysis for - Students (click on chart to interact)<\/b>\"\n                  )\nfig.update_layout(\n    font_size=12,\n    title_font_color=\"black\",\n)\nfig.show()\nfig = px.sunburst(enthusiast_ed,\n                  path=[\"Education Level\", \"Platform\",\"Pr. Language Rec.\",\"Money Spent Learning\"],\n                  values='Resp',\n                  branchvalues='total',\n                  height=600,\n                  title=\"<b>Education Analysis for - Data Enthusiasts (click on chart to interact)<\/b>\"\n                  )\nfig.update_layout(\n    font_size=12,\n    title_font_color=\"black\",\n)\nfig.show()\nfig = px.sunburst(scientist_ed,\n                  path=[\"Education Level\", \"Platform\",\"Pr. Language Rec.\",\"Money Spent Learning\"],\n                  values='Resp',\n                  branchvalues='total',\n                  height=600,\n                  title=\"<b>Education Analysis for - Data Scientists (click on chart to interact)<\/b>\"\n                  )\nfig.update_layout(\n    font_size=12,\n    title_font_color=\"black\",\n)\nfig.show()\n\nfig = px.sunburst(machinel_ed,\n                  path=[\"Education Level\", \"Platform\",\"Pr. Language Rec.\",\"Money Spent Learning\"],\n                  values='Resp',\n                  branchvalues='total',\n                  height=600,\n                  title=\"<b>Education Analysis for - ML Engineers (click on chart to interact)<\/b>\"\n                  )\nfig.update_layout(\n    font_size=12,\n    title_font_color=\"black\",\n)\nfig.show()","52a87230":"multi_plot(age_bar,\"Age\")\n#Age breakdown by Segment\nage_facet=survey[[\"Segm\", \"Q1\",\"Resp\"]]\nage_facet=age_facet.groupby([\"Segm\", \"Q1\"])[\"Resp\"].sum().reset_index()\nage_facet.columns=[\"Segment\", \"Age\", \"Respondents\"]\nfig = px.bar(age_facet, x=\"Age\", y=\"Respondents\", text=\"Respondents\",\n            color=\"Respondents\", title = \"Age - Segmentation Breakdown\", facet_col_wrap=3, height=800,\n            # barmode=\"group\",\n            # facet_row=\"time\", \n             facet_col=\"Segment\")\nfig.update_traces(texttemplate='%{text:.2s}', textposition='inside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n\nfor annotation in fig.layout.annotations:\n    annotation.text = annotation.text.split(\"=\")[1]\nfig.show()","5b2db59f":"multi_plot(exp_bar,\"Experience\")\n#Experience breakdown by Segment\nexp_facet=survey[[\"Segm\", \"Q6\",\"Resp\"]]\nexp_facet=exp_facet.groupby([\"Segm\", \"Q6\"])[\"Resp\"].sum().reset_index()\nexp_facet.columns=[\"Segment\", \"Experience\", \"Respondents\"]\nfig = px.bar(exp_facet, x=\"Experience\", y=\"Respondents\", text=\"Respondents\",\n            color=\"Respondents\", title = \"Experience - Segmentation Breakdown\", facet_col_wrap=3, height=800,\n            # barmode=\"group\",\n            # facet_row=\"time\", \n             facet_col=\"Segment\")\nfig.update_traces(texttemplate='%{text:.2s}', textposition='inside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\nfor annotation in fig.layout.annotations:\n    annotation.text = annotation.text.split(\"=\")[1]\nfig.show()","821d82b2":"multi_plot(edu_bar,\"Education\")\n#Education breakdown by Segment\nedu_facet=survey[[\"Segm\", \"Q4\",\"Resp\"]]\nedu_facet=edu_facet.groupby([\"Segm\", \"Q4\"])[\"Resp\"].sum().reset_index()\nedu_facet.columns=[\"Segment\", \"Education Level\", \"Respondents\"]\nfig = px.bar(edu_facet, x=\"Education Level\", y=\"Respondents\", text=\"Respondents\",\n            color=\"Respondents\", title = \"Education Level - Segmentation Breakdown\", facet_col_wrap=3, height=800,\n            # barmode=\"group\",\n            # facet_row=\"time\", \n             facet_col=\"Segment\")\nfig.update_traces(texttemplate='%{text:.2s}', textposition='inside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n\nfor annotation in fig.layout.annotations:\n    annotation.text = annotation.text.split(\"=\")[1]\nfig.show()","30215adc":"#Programming Languages\nquestion=survey[['Segm','Q7_Part_1','Q7_Part_2','Q7_Part_3','Q7_Part_4','Q7_Part_5','Q7_Part_6','Q7_Part_7','Q7_Part_8','Q7_Part_9','Q7_Part_10','Q7_Part_11','Q7_Part_12',\t'Q7_OTHER']]\nquestion.columns=['Segm','Python' ,'R','SQL' ,'C' ,'C++' ,'Java' ,'Javascript' ,'Julia' ,'Swift' ,'Bash' ,'MATLAB' ,'None' ,'Other']\nquestion=question.groupby(by=[\"Segm\"]).count()\nstacked=question.stack().reset_index()\nstacked.columns=['Label', 'Answer', 'Respondents']\nfig = px.bar(stacked, x=\"Answer\", y=\"Respondents\", text=\"Respondents\",\n            color=\"Respondents\", title = \"Programming Languages\", facet_col_wrap=2, \n              facet_row_spacing=0.1, \n              facet_col_spacing=0.05, \n             height=1100,\n             facet_col=\"Label\")\nfig.update_traces(texttemplate='%{text:.2s}', textposition='inside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n\nfor annotation in fig.layout.annotations:\n    annotation.text = annotation.text.split(\"=\")[1]\nfig.show()","ddb6337e":"#Hosted Notebooks\nquestion=survey[['Segm','Q10_Part_1','Q10_Part_2','Q10_Part_3','Q10_Part_4','Q10_Part_5','Q10_Part_6','Q10_Part_7','Q10_Part_8','Q10_Part_9','Q10_Part_10','Q10_Part_11','Q10_Part_12',\t'Q10_Part_13',\t'Q10_OTHER']]\nquestion.columns=['Segm','Kaggle Notebooks','Colab Notebooks','Azure Notebooks',\t'Paperspace \/ Gradient','Binder \/ JupyterHub','Code Ocean','IBM Watson Studio','Amazon Sagemaker Studio','Amazon EMR Notebooks','Google Cloud AI Platform Notebooks','Google Cloud Datalab Notebooks','Databricks Collaborative Notebooks','None','Other']\nquestion=question.groupby(by=[\"Segm\"]).count()\nstacked=question.stack().reset_index()\nstacked.columns=['Label', 'Answer', 'Respondents']\nfig = px.bar(stacked, x=\"Answer\", y=\"Respondents\", text=\"Respondents\",\n            color=\"Respondents\", title = \"Hosted Notebooks\", facet_col_wrap=2, \n              facet_row_spacing=0.1, \n              facet_col_spacing=0.05, \n             height=1100,\n             facet_col=\"Label\")\nfig.update_traces(texttemplate='%{text:.2s}', textposition='inside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n\nfor annotation in fig.layout.annotations:\n    annotation.text = annotation.text.split(\"=\")[1]\nfig.show()","2b15fcf0":"#Specialized Harware\nquestion=survey[['Segm','Q12_Part_1',\t'Q12_Part_2',\t'Q12_Part_3',\t'Q12_OTHER']]\nquestion.columns=['Segm','GPUs',\t'TPUs',\t'None',\t'Other']\nquestion=question.groupby(by=[\"Segm\"]).count()\nstacked=question.stack().reset_index()\nstacked.columns=['Label', 'Answer', 'Respondents']\nfig = px.bar(stacked, x=\"Answer\", y=\"Respondents\", text=\"Respondents\",\n            color=\"Respondents\", title = \"Specialized Harware\", facet_col_wrap=2, \n              facet_row_spacing=0.1, \n              facet_col_spacing=0.05, \n             height=1100,\n             facet_col=\"Label\")\nfig.update_traces(texttemplate='%{text:.2s}', textposition='inside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\nfig.update_xaxes(showticklabels=True)\nfor annotation in fig.layout.annotations:\n    annotation.text = annotation.text.split(\"=\")[1]\nfig.show()","06cbb038":"#Visualization Libraries\nquestion=survey[['Segm','Q14_Part_1',\t'Q14_Part_2',\t'Q14_Part_3',\t'Q14_Part_4',\t'Q14_Part_5',\t'Q14_Part_6',\t'Q14_Part_7',\t'Q14_Part_8',\t'Q14_Part_9',\t'Q14_Part_10',\t'Q14_Part_11',\t'Q14_OTHER']]\nquestion.columns=['Segm','Matplotlib',\t'Seaborn',\t'Plotly \/ Plotly Express',\t'Ggplot \/ ggplot2',\t'Shiny',\t'D3.js',\t'Altair',\t'Bokeh',\t'Geoplotlib',\t'Leaflet \/ Folium',\t'None',\t'Other']\nquestion=question.groupby(by=[\"Segm\"]).count()\nstacked=question.stack().reset_index()\nstacked.columns=['Label', 'Answer', 'Respondents']\nfig = px.bar(stacked, x=\"Answer\", y=\"Respondents\", text=\"Respondents\",\n            color=\"Respondents\", title = \"Visualization Libraries\", facet_col_wrap=2, \n              facet_row_spacing=0.1, \n              facet_col_spacing=0.05, \n             height=1200,\n             facet_col=\"Label\")\nfig.update_traces(texttemplate='%{text:.2s}', textposition='inside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n\nfor annotation in fig.layout.annotations:\n    annotation.text = annotation.text.split(\"=\")[1]\nfig.show()","e9c232f5":"#Machine Learnning Frameworks\nquestion=survey[['Segm','Q16_Part_1',\t'Q16_Part_2',\t'Q16_Part_3',\t'Q16_Part_4',\t'Q16_Part_5',\t'Q16_Part_6',\t'Q16_Part_7',\t'Q16_Part_8',\t'Q16_Part_9',\t'Q16_Part_10',\t'Q16_Part_11',\t'Q16_Part_12',\t'Q16_Part_13',\t'Q16_Part_14',\t'Q16_Part_15',\t'Q16_OTHER']]\nquestion.columns=['Segm','Scikit-learn',\t'TensorFlow',\t'Keras',\t'PyTorch',\t'Fast.ai',\t'MXNet',\t'Xgboost',\t'LightGBM',\t'CatBoost',\t'Prophet',\t'H20-3',\t'Caret',\t'Tidymodels',\t'JAX',\t'None',\t'Other']\nquestion=question.groupby(by=[\"Segm\"]).count()\nstacked=question.stack().reset_index()\nstacked.columns=['Label', 'Answer', 'Respondents']\nfig = px.bar(stacked, x=\"Answer\", y=\"Respondents\", text=\"Respondents\",\n            color=\"Respondents\", title = \"Machine Learnning Frameworks\", facet_col_wrap=2, \n              facet_row_spacing=0.1, \n              facet_col_spacing=0.05, \n             height=1100,\n             facet_col=\"Label\")\nfig.update_traces(texttemplate='%{text:.2s}', textposition='inside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n\nfor annotation in fig.layout.annotations:\n    annotation.text = annotation.text.split(\"=\")[1]\nfig.show()","1e1ede67":"#Machine Learnning Algorithms\nquestion=survey[['Segm','Q17_Part_1',\t'Q17_Part_2',\t'Q17_Part_3',\t'Q17_Part_4',\t'Q17_Part_5',\t'Q17_Part_6',\t'Q17_Part_7',\t'Q17_Part_8',\t'Q17_Part_9',\t'Q17_Part_10',\t'Q17_Part_11',\t'Q17_OTHER']]\nquestion.columns=['Segm','Linear or Logistic Regression',\t'Decision Trees or Random Forests',\t'Gradient Boosting Machines (xgboost, lightgbm, etc)',\t'Bayesian Approaches',\t'Evolutionary Approaches',\t'Dense Neural Networks (MLPs, etc)',\t'Convolutional Neural Networks',\t'Generative Adversarial Networks',\t'Recurrent Neural Networks',\t'Transformer Networks (BERT, gpt-3, etc)',\t'None',\t'Other']\nquestion=question.groupby(by=[\"Segm\"]).count()\nstacked=question.stack().reset_index()\nstacked.columns=['Label', 'Answer', 'Respondents']\nfig = px.bar(stacked, x=\"Answer\", y=\"Respondents\", text=\"Respondents\",\n            color=\"Respondents\", title = \"Machine Learnning Algorithms\", facet_col_wrap=2, \n              facet_row_spacing=0.1, \n              facet_col_spacing=0.05, \n             height=1200,\n             facet_col=\"Label\")\nfig.update_traces(texttemplate='%{text:.2s}', textposition='inside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n\nfor annotation in fig.layout.annotations:\n    annotation.text = annotation.text.split(\"=\")[1]\nfig.show()","7dd4c5d7":"#Computer Vision\nquestion=survey[['Segm','Q18_Part_1',\t'Q18_Part_2',\t'Q18_Part_3',\t'Q18_Part_4',\t'Q18_Part_5',\t'Q18_Part_6',\t'Q18_OTHER']]\nquestion.columns=['Segm','General purpose image\/video tools (PIL, cv2, skimage, etc)',\t'Image segmentation methods (U-Net, Mask R-CNN, etc)',\t'Object detection methods (YOLOv3, RetinaNet, etc)',\t'Image classification (VGG, Inception, ResNet, ResNeXt, NASNet, EfficientNet, etc)',\t'Generative Networks (GAN, VAE, etc)',\t'None',\t'Other']\nquestion=question.groupby(by=[\"Segm\"]).count()\nstacked=question.stack().reset_index()\nstacked.columns=['Label', 'Answer', 'Respondents']\nfig = px.bar(stacked, x=\"Answer\", y=\"Respondents\", text=\"Respondents\",\n            color=\"Respondents\", title = \"Computer Vision\", facet_col_wrap=2, \n              facet_row_spacing=0.1, \n              facet_col_spacing=0.05, \n             height=1100,\n             facet_col=\"Label\")\nfig.update_traces(texttemplate='%{text:.2s}', textposition='inside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n\nfor annotation in fig.layout.annotations:\n    annotation.text = annotation.text.split(\"=\")[1]\nfig.show()","1924e846":"#NLP - Neuro Linguistic Programming\nquestion=survey[['Segm','Q19_Part_1',\t'Q19_Part_2',\t'Q19_Part_3',\t'Q19_Part_4',\t'Q19_Part_5',\t'Q19_OTHER']]\nquestion.columns=['Segm','Word embeddings\/vectors (GLoVe, fastText, word2vec)',\t'Encoder-decoder models (seq2seq, vanilla transformers)',\t'Contextualized embeddings (ELMo, CoVe)',\t'Transformer language models (GPT-3, BERT, XLnet, etc)',\t'None',\t'Other']\nquestion=question.groupby(by=[\"Segm\"]).count()\nstacked=question.stack().reset_index()\nstacked.columns=['Label', 'Answer', 'Respondents']\nfig = px.bar(stacked, x=\"Answer\", y=\"Respondents\", text=\"Respondents\",\n            color=\"Respondents\", title = \"NLP - Neuro Linguistic Programming\", facet_col_wrap=2, \n              facet_row_spacing=0.1, \n              facet_col_spacing=0.05, \n             height=1100,\n             facet_col=\"Label\")\nfig.update_traces(texttemplate='%{text:.2s}', textposition='inside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n\nfor annotation in fig.layout.annotations:\n    annotation.text = annotation.text.split(\"=\")[1]\nfig.show()","621d50ab":"#Activities at work\nquestion=survey[['Segm','Q23_Part_1',\t'Q23_Part_2',\t'Q23_Part_3',\t'Q23_Part_4',\t'Q23_Part_5',\t'Q23_Part_6',\t'Q23_Part_7',\t'Q23_OTHER']]\nquestion=question[question['Segm'] !='Student']\nquestion.columns=['Segm','Analyze and understand data to influence product or business decisions',\t'Build and\/or run the data infrastructure',\t'Build prototypes to explore applying ML to new areas',\t'Build and\/or run a ML service that operationally improves my product or workflows',\t'Experimentation and iteration to improve existing ML models',\t'Do research that advances the state of the art of machine learning',\t'None of these activities are an important partk',\t'Other']\nquestion=question.groupby(by=[\"Segm\"]).count()\nstacked=question.stack().reset_index()\nstacked.columns=['Label', 'Answer', 'Respondents']\nfig = px.bar(stacked, x=\"Answer\", y=\"Respondents\", text=\"Respondents\",\n            color=\"Respondents\", title = \"Activities at work\", facet_col_wrap=2, \n              facet_row_spacing=0.1, \n              facet_col_spacing=0.05, \n             height=1100,\n             facet_col=\"Label\")\nfig.update_traces(texttemplate='%{text:.2s}', textposition='inside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n\nfor annotation in fig.layout.annotations:\n    annotation.text = annotation.text.split(\"=\")[1]\nfig.show()","39389e26":"#Platforms to Learn Data Science\nquestion=survey[['Segm','Q37_Part_1',\t'Q37_Part_2',\t'Q37_Part_3',\t'Q37_Part_4',\t'Q37_Part_5',\t'Q37_Part_6',\t'Q37_Part_7',\t'Q37_Part_8',\t'Q37_Part_9',\t'Q37_Part_10',\t'Q37_Part_11',\t'Q37_OTHER']]\nquestion.columns=['Segm','Coursera',\t'EdX',\t'Kaggle Learn Courses',\t'DataCamp',\t'Fast.ai',\t'Udacity',\t'Udemy',\t'LinkedIn Learning',\t'Cloud-certification programs',\t'University Courses',\t'None',\t'Other']\nquestion=question.groupby(by=[\"Segm\"]).count()\nstacked=question.stack().reset_index()\nstacked.columns=['Label', 'Answer', 'Respondents']\nfig = px.bar(stacked, x=\"Answer\", y=\"Respondents\", text=\"Respondents\",\n            color=\"Respondents\", title = \"Platforms to Learn Data Science\", facet_col_wrap=2, \n              facet_row_spacing=0.1, \n              facet_col_spacing=0.05, \n             height=1100,\n             facet_col=\"Label\")\nfig.update_traces(texttemplate='%{text:.2s}', textposition='inside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n\nfor annotation in fig.layout.annotations:\n    annotation.text = annotation.text.split(\"=\")[1]\nfig.show()","1151aa24":"top10list=['India',\t'United States of America',\t'Other', 'Brazil', 'Japan',\t'Russia', 'United Kingdom',\t'Nigeria', 'China', 'Germany', 'Turkey']\nsal=survey[survey['Q24'] !='No Data']\n\nsal=sal[sal[\"Q3\"].isin(top10list)]\nsal=sal[[\"Q3\", \"Q5\", \"Salary\",\"Average Age\",\"Resp\"]]\nsal=sal.groupby(['Q3',\"Q5\"]).agg({'Salary':'mean', 'Average Age':'mean','Resp':'sum'}).reset_index()\nsal=sal.round({'Salary': 1, 'Average Age': 1})\nfig = px.scatter(sal, x=\"Salary\", y=\"Average Age\", size=\"Resp\", color=\"Q5\",facet_col=\"Q3\",facet_col_wrap=2,height=1200,\n           hover_name=\"Q5\",  size_max=40)\nfor annotation in fig.layout.annotations:\n    annotation.text = annotation.text.split(\"=\")[1]\n    fig.update_xaxes(showticklabels=True)\n    fig.layout.showlegend = False\nfig.show()","effa2c29":"money=survey[[\"Segm\", \"Q5\", \"Q6\",\"Q24\",\"Resp\"]]\nmoney=money.groupby([\"Segm\", \"Q5\", \"Q6\",\"Q24\"])[\"Resp\"].sum().reset_index()\nmoney.columns=[\"Segment\", \"Current Role\", \"Years Experience\",\"Compensation\",\"Resp\"]\nindex_names = money[ money[\"Compensation\"] == \"No Data\" ].index\nmoney.drop(index_names, inplace = True) \n\nimposters_mo = money[(money[\"Segment\"] == \"Data Imposters\")]\nimposters_mo=imposters_mo.drop(columns=['Segment']).reset_index(drop=True)\n\nenthusiast_mo=money[(money[\"Segment\"] == \"Data Enthusiasts\")]\nenthusiast_mo=enthusiast_mo.drop(columns=['Segment']).reset_index(drop=True)\n\nstudent_mo=money[(money[\"Segment\"] == \"Student\")]\nstudent_mo=student_mo.drop(columns=['Segment']).reset_index(drop=True)\n\nscientist_mo=money[(money[\"Segment\"] ==  \"Data Scientist\")]\nscientist_mo=scientist_mo.drop(columns=['Segment']).reset_index(drop=True)\n\nmachinel_mo=money[(money[\"Segment\"] == \"ML Engineer\")]\nmachinel_mo=machinel_mo.drop(columns=['Segment']).reset_index(drop=True)\n\nfig = px.sunburst(imposters_mo,\n                  path=[\"Current Role\", \"Years Experience\",\"Compensation\"],\n                  values='Resp',\n                  branchvalues='total',\n                  height=600,\n                  title=\"<b>Compensation Analysis for - Data Imposters (click on chart to interact) <br>Empty Data - excluded<\/b>\" \n                  )\nfig.update_layout(\n    font_size=12,\n    title_font_color=\"black\",\n)\nfig.show()\nfig = px.sunburst(enthusiast_mo,\n                  path=[\"Current Role\", \"Years Experience\",\"Compensation\"],\n                  values='Resp',\n                  branchvalues='total',\n                  height=600,\n                  title=\"<b>Compensation Analysis for - Data Enthusiasts (click on chart to interact) <br>Empty Data - excluded<\/b>\" \n                  )\nfig.update_layout(\n    font_size=12,\n    title_font_color=\"black\",\n)\nfig.show()\nfig = px.sunburst(scientist_mo,\n                  path=[\"Current Role\", \"Years Experience\",\"Compensation\"],\n                  values='Resp',\n                  branchvalues='total',\n                  height=600,\n                  title=\"<b>Compensation Analysis for - Data Scientists (click on chart to interact) <br>Empty Data - excluded<\/b>\" \n                  )\nfig.update_layout(\n    font_size=12,\n    title_font_color=\"black\",\n)\nfig.show()\nfig = px.sunburst(machinel_mo,\n                  path=[\"Current Role\", \"Years Experience\",\"Compensation\"],\n                  values='Resp',\n                  branchvalues='total',\n                  height=600,\n                  title=\"<b>Compensation Analysis for - ML Engineers (click on chart to interact) <br>Empty Data - excluded<\/b>\" \n                  )\nfig.update_layout(\n    font_size=12,\n    title_font_color=\"black\",\n)\nfig.show()","d30141a9":"q26a = {\n    'Amazon Web Services (AWS)' : (survey['Q26_A_Part_1'].count()),\n    'Microsoft Azure': (survey['Q26_A_Part_2'].count()),\n    'Google Cloud Platform (GCP)' : (survey['Q26_A_Part_3'].count()),\n    'IBM Cloud \/ Red Hat' : (survey['Q26_A_Part_4'].count()),\n    'Oracle Cloud' : (survey['Q26_A_Part_5'].count()),\n    'SAP Cloud' : (survey['Q26_A_Part_6'].count()),\n    'Salesforce Cloud' : (survey['Q26_A_Part_7'].count()),\n    'VMware Cloud' : (survey['Q26_A_Part_8'].count()),\n    'Alibaba Cloud' : (survey['Q26_A_Part_9'].count()),\n    'Tencent Cloud' : (survey['Q26_A_Part_10'].count()),\n    'None' : (survey['Q26_A_Part_11'].count()),\n    'Other' : (survey['Q26_A_OTHER'].count())\n}\n\nq26b = {\n    'Amazon Web Services (AWS)' : (survey['Q26_B_Part_1'].count()),\n    'Microsoft Azure': (survey['Q26_B_Part_2'].count()),\n    'Google Cloud Platform (GCP)' : (survey['Q26_B_Part_3'].count()),\n    'IBM Cloud \/ Red Hat' : (survey['Q26_B_Part_4'].count()),\n    'Oracle Cloud' : (survey['Q26_B_Part_5'].count()),\n    'SAP Cloud' : (survey['Q26_B_Part_6'].count()),\n    'Salesforce Cloud' : (survey['Q26_B_Part_7'].count()),\n    'VMware Cloud' : (survey['Q26_B_Part_8'].count()),\n    'Alibaba Cloud' : (survey['Q26_B_Part_9'].count()),\n    'Tencent Cloud' : (survey['Q26_B_Part_10'].count()),\n    'None' : (survey['Q26_B_Part_11'].count()),\n    'Other' : (survey['Q26_B_OTHER'].count())\n}\n\nq27a = {\n    'Amazon EC2' : (survey['Q27_A_Part_1'].count()),\n    'AWS Lambda': (survey['Q27_A_Part_2'].count()),\n    'Amazon Elastic Container Service' : (survey['Q27_A_Part_3'].count()),\n    'Azure Cloud Services' : (survey['Q27_A_Part_4'].count()),\n    'Microsoft Azure Container Instances' : (survey['Q27_A_Part_5'].count()),\n    'Azure Functions' : (survey['Q27_A_Part_6'].count()),\n    'Google Cloud Compute Engine' : (survey['Q27_A_Part_7'].count()),\n    'Google Cloud Functions' : (survey['Q27_A_Part_8'].count()),\n    'Google Cloud Run' : (survey['Q27_A_Part_9'].count()),\n    'Google Cloud App Engine' : (survey['Q27_A_Part_10'].count()),\n    'No \/ None' : (survey['Q27_A_Part_11'].count()),\n    'Other' : (survey['Q27_A_OTHER'].count())\n}\n\nq27b = {\n    'Amazon EC2' : (survey['Q27_B_Part_1'].count()),\n    'AWS Lambda': (survey['Q27_B_Part_2'].count()),\n    'Amazon Elastic Container Service' : (survey['Q27_B_Part_3'].count()),\n    'Azure Cloud Services' : (survey['Q27_B_Part_4'].count()),\n    'Microsoft Azure Container Instances' : (survey['Q27_B_Part_5'].count()),\n    'Azure Functions' : (survey['Q27_B_Part_6'].count()),\n    'Google Cloud Compute Engine' : (survey['Q27_B_Part_7'].count()),\n    'Google Cloud Functions' : (survey['Q27_B_Part_8'].count()),\n    'Google Cloud Run' : (survey['Q27_B_Part_9'].count()),\n    'Google Cloud App Engine' : (survey['Q27_B_Part_10'].count()),\n    'No \/ None' : (survey['Q27_B_Part_11'].count()),\n    'Other' : (survey['Q27_B_OTHER'].count())\n}\n\nq28a = {\n    'Amazon SageMaker' : (survey['Q28_A_Part_1'].count()),\n    'Amazon Forecast': (survey['Q28_A_Part_2'].count()),\n    'Amazon Rekognition' : (survey['Q28_A_Part_3'].count()),\n    'Azure Machine Learning Studio' : (survey['Q28_A_Part_4'].count()),\n    'Azure Cognitive Services' : (survey['Q28_A_Part_5'].count()),\n    'Google Cloud AI Platform \/ Google Cloud ML Engine' : (survey['Q28_A_Part_6'].count()),\n    'Google Cloud Video AI' : (survey['Q28_A_Part_7'].count()),\n    'Google Cloud Natural Language' : (survey['Q28_A_Part_8'].count()),\n    'Google Cloud Vision AI' : (survey['Q28_A_Part_9'].count()),\n    'No \/ None' : (survey['Q28_A_Part_10'].count()),\n    'Other' : (survey['Q28_A_OTHER'].count())\n}\n\nq28b = {\n    'Amazon SageMaker' : (survey['Q28_B_Part_1'].count()),\n    'Amazon Forecast': (survey['Q28_B_Part_2'].count()),\n    'Amazon Rekognition' : (survey['Q28_B_Part_3'].count()),\n    'Azure Machine Learning Studio' : (survey['Q28_B_Part_4'].count()),\n    'Azure Cognitive Services' : (survey['Q28_B_Part_5'].count()),\n    'Google Cloud AI Platform \/ Google Cloud ML Engine' : (survey['Q28_B_Part_6'].count()),\n    'Google Cloud Video AI' : (survey['Q28_B_Part_7'].count()),\n    'Google Cloud Natural Language' : (survey['Q28_B_Part_8'].count()),\n    'Google Cloud Vision AI' : (survey['Q28_B_Part_9'].count()),\n    'No \/ None' : (survey['Q28_B_Part_10'].count()),\n    'Other' : (survey['Q28_B_OTHER'].count())\n}\n\n\nq29a = {\n    'MySQL' : (survey['Q29_A_Part_1'].count()),\n    'PostgreSQL': (survey['Q29_A_Part_2'].count()),\n    'SQLite' : (survey['Q29_A_Part_3'].count()),\n    'Oracle Database' : (survey['Q29_A_Part_4'].count()),\n    'MongoDB' : (survey['Q29_A_Part_5'].count()),\n    'Snowflake' : (survey['Q29_A_Part_6'].count()),\n    'IBM Db2' : (survey['Q29_A_Part_7'].count()),\n    'Microsoft SQL Server' : (survey['Q29_A_Part_8'].count()),\n    'Microsoft Access' : (survey['Q29_A_Part_9'].count()),\n    'Microsoft Azure Data Lake Storage' : (survey['Q29_A_Part_10'].count()),\n    'Amazon Redshift' : (survey['Q29_A_Part_11'].count()),\n    'Amazon Athena' : (survey['Q29_A_Part_12'].count()),\n    'Amazon DynamoDB' : (survey['Q29_A_Part_13'].count()),\n    'Google Cloud BigQuery' : (survey['Q29_A_Part_14'].count()),\n    'Google Cloud SQL' : (survey['Q29_A_Part_15'].count()),\n    'Google Cloud Firestore' : (survey['Q29_A_Part_16'].count()),\n    'None' : (survey['Q29_A_Part_17'].count()),\n    'Other' : (survey['Q29_A_OTHER'].count())\n}\n\n\nq29b = {\n    'MySQL' : (survey['Q29_B_Part_1'].count()),\n    'PostgreSQL': (survey['Q29_B_Part_2'].count()),\n    'SQLite' : (survey['Q29_B_Part_3'].count()),\n    'Oracle Database' : (survey['Q29_B_Part_4'].count()),\n    'MongoDB' : (survey['Q29_B_Part_5'].count()),\n    'Snowflake' : (survey['Q29_B_Part_6'].count()),\n    'IBM Db2' : (survey['Q29_B_Part_7'].count()),\n    'Microsoft SQL Server' : (survey['Q29_B_Part_8'].count()),\n    'Microsoft Access' : (survey['Q29_B_Part_9'].count()),\n    'Microsoft Azure Data Lake Storage' : (survey['Q29_B_Part_10'].count()),\n    'Amazon Redshift' : (survey['Q29_B_Part_11'].count()),\n    'Amazon Athena' : (survey['Q29_B_Part_12'].count()),\n    'Amazon DynamoDB' : (survey['Q29_B_Part_13'].count()),\n    'Google Cloud BigQuery' : (survey['Q29_B_Part_14'].count()),\n    'Google Cloud SQL' : (survey['Q29_B_Part_15'].count()),\n    'Google Cloud Firestore' : (survey['Q29_B_Part_16'].count()),\n    'None' : (survey['Q29_B_Part_17'].count()),\n    'Other' : (survey['Q29_B_OTHER'].count())\n}\n\nq31a = {\n    'Amazon QuickSight' : (survey['Q31_A_Part_1'].count()),\n    'Microsoft Power BI': (survey['Q31_A_Part_2'].count()),\n    'Google Data Studio' : (survey['Q31_A_Part_3'].count()),\n    'Looker' : (survey['Q31_A_Part_4'].count()),\n    'Tableau' : (survey['Q31_A_Part_5'].count()),\n    'Salesforce' : (survey['Q31_A_Part_6'].count()),\n    'Einstein Analytics' : (survey['Q31_A_Part_7'].count()),\n    'Qlik' : (survey['Q31_A_Part_8'].count()),\n    'Domo' : (survey['Q31_A_Part_9'].count()),\n    'TIBCO Spotfire' : (survey['Q31_A_Part_10'].count()),\n    'Alteryx' : (survey['Q31_A_Part_11'].count()),\n    'Sisense' : (survey['Q31_A_Part_12'].count()),\n    'SAP Analytics Cloud' : (survey['Q31_A_Part_13'].count()),\n    'None' : (survey['Q31_A_Part_14'].count()),\n    'Other' : (survey['Q31_A_OTHER'].count())\n}\n\nq31b = {\n    'Amazon QuickSight' : (survey['Q31_B_Part_1'].count()),\n    'Microsoft Power BI': (survey['Q31_B_Part_2'].count()),\n    'Google Data Studio' : (survey['Q31_B_Part_3'].count()),\n    'Looker' : (survey['Q31_B_Part_4'].count()),\n    'Tableau' : (survey['Q31_B_Part_5'].count()),\n    'Salesforce' : (survey['Q31_B_Part_6'].count()),\n    'Einstein Analytics' : (survey['Q31_B_Part_7'].count()),\n    'Qlik' : (survey['Q31_B_Part_8'].count()),\n    'Domo' : (survey['Q31_B_Part_9'].count()),\n    'TIBCO Spotfire' : (survey['Q31_B_Part_10'].count()),\n    'Alteryx' : (survey['Q31_B_Part_11'].count()),\n    'Sisense' : (survey['Q31_B_Part_12'].count()),\n    'SAP Analytics Cloud' : (survey['Q31_B_Part_13'].count()),\n    'None' : (survey['Q31_B_Part_14'].count()),\n    'Other' : (survey['Q31_B_OTHER'].count())\n}\n\nq33a = {\n    'Automated data augmentation (e.g. imgaug, albumentations)' : (survey['Q33_A_Part_1'].count()),\n    'Automated feature engineering\/selection (e.g. tpot, boruta_py)': (survey['Q33_A_Part_2'].count()),\n    'Automated model selection (e.g. auto-sklearn, xcessiv)' : (survey['Q33_A_Part_3'].count()),\n    'Automated model architecture searches (e.g. darts, enas)' : (survey['Q33_A_Part_4'].count()),\n    'Automated hyperparameter tuning (e.g. hyperopt, ray.tune, Vizier)' : (survey['Q33_A_Part_5'].count()),\n    'Automation of full ML pipelines (e.g. Google AutoML, H20 Driverless AI)' : (survey['Q33_A_Part_6'].count()),\n    'No \/ None' : (survey['Q33_A_Part_7'].count()),\n    'Other' : (survey['Q33_A_OTHER'].count())\n}\n\nq33b = {\n    'Automated data augmentation (e.g. imgaug, albumentations)' : (survey['Q33_B_Part_1'].count()),\n    'Automated feature engineering\/selection (e.g. tpot, boruta_py)': (survey['Q33_B_Part_2'].count()),\n    'Automated model selection (e.g. auto-sklearn, xcessiv)' : (survey['Q33_B_Part_3'].count()),\n    'Automated model architecture searches (e.g. darts, enas)' : (survey['Q33_B_Part_4'].count()),\n    'Automated hyperparameter tuning (e.g. hyperopt, ray.tune, Vizier)' : (survey['Q33_B_Part_5'].count()),\n    'Automation of full ML pipelines (e.g. Google AutoML, H20 Driverless AI)' : (survey['Q33_B_Part_6'].count()),\n    'No \/ None' : (survey['Q33_B_Part_7'].count()),\n    'Other' : (survey['Q33_B_OTHER'].count())\n}\n\nq34a = {\n    'Google Cloud AutoML' : (survey['Q34_A_Part_1'].count()),\n    'H20 Driverless AI': (survey['Q34_A_Part_2'].count()),\n    'Databricks AutoML' : (survey['Q34_A_Part_3'].count()),\n    'DataRobot AutoML' : (survey['Q34_A_Part_4'].count()),\n    'Tpot' : (survey['Q34_A_Part_5'].count()),\n    'Auto-Keras' : (survey['Q34_A_Part_6'].count()),\n    'Auto-Sklearn' : (survey['Q34_A_Part_7'].count()),\n    'Auto_ml' : (survey['Q34_A_Part_8'].count()),\n    'Xcessiv' : (survey['Q34_A_Part_9'].count()),\n    'MLbox' : (survey['Q34_A_Part_10'].count()),\n    'No \/ None' : (survey['Q34_A_Part_11'].count()),\n    'Other' : (survey['Q34_A_OTHER'].count())\n}\n\nq34b = {\n    'Google Cloud AutoML' : (survey['Q34_B_Part_1'].count()),\n    'H20 Driverless AI': (survey['Q34_B_Part_2'].count()),\n    'Databricks AutoML' : (survey['Q34_B_Part_3'].count()),\n    'DataRobot AutoML' : (survey['Q34_B_Part_4'].count()),\n    'Tpot' : (survey['Q34_B_Part_5'].count()),\n    'Auto-Keras' : (survey['Q34_B_Part_6'].count()),\n    'Auto-Sklearn' : (survey['Q34_B_Part_7'].count()),\n    'Auto_ml' : (survey['Q34_B_Part_8'].count()),\n    'Xcessiv' : (survey['Q34_B_Part_9'].count()),\n    'MLbox' : (survey['Q34_B_Part_10'].count()),\n    'No \/ None' : (survey['Q34_B_Part_11'].count()),\n    'Other' : (survey['Q34_B_OTHER'].count())\n}\n\n\nq35a = {\n    'Neptune.ai' : (survey['Q35_A_Part_1'].count()),\n    'Weights & Biases': (survey['Q35_A_Part_2'].count()),\n    'Comet.ml' : (survey['Q35_A_Part_3'].count()),\n    'Sacred + Omniboard' : (survey['Q35_A_Part_4'].count()),\n    'TensorBoard' : (survey['Q35_A_Part_5'].count()),\n    'Guild.ai' : (survey['Q35_A_Part_6'].count()),\n    'Polyaxon' : (survey['Q35_A_Part_7'].count()),\n    'Trains' : (survey['Q35_A_Part_8'].count()),\n    'Domino Model Monitor' : (survey['Q35_A_Part_9'].count()),\n    'No \/ None' : (survey['Q35_A_Part_10'].count()),\n    'Other' : (survey['Q35_A_OTHER'].count())\n}\n\n\nq35b = {\n    'Neptune.ai' : (survey['Q35_B_Part_1'].count()),\n    'Weights & Biases': (survey['Q35_B_Part_2'].count()),\n    'Comet.ml' : (survey['Q35_B_Part_3'].count()),\n    'Sacred + Omniboard' : (survey['Q35_B_Part_4'].count()),\n    'TensorBoard' : (survey['Q35_B_Part_5'].count()),\n    'Guild.ai' : (survey['Q35_B_Part_6'].count()),\n    'Polyaxon' : (survey['Q35_B_Part_7'].count()),\n    'Trains' : (survey['Q35_B_Part_8'].count()),\n    'Domino Model Monitor' : (survey['Q35_B_Part_9'].count()),\n    'No \/ None' : (survey['Q35_B_Part_10'].count()),\n    'Other' : (survey['Q35_B_OTHER'].count())\n}\n#del list\ndf_q26a = pd.DataFrame(list(q26a.items()),columns = ['Answer','Responses'])\ndf_q26b = pd.DataFrame(list(q26b.items()),columns = ['Answer','Responses'])\ndf_q27a=pd.DataFrame(list(q27a.items()),columns = ['Answer','Responses'])\ndf_q27b=pd.DataFrame(list(q27b.items()),columns = ['Answer','Responses'])\ndf_q28a=pd.DataFrame(list(q28a.items()),columns = ['Answer','Responses'])\ndf_q28b=pd.DataFrame(list(q28b.items()),columns = ['Answer','Responses'])\ndf_q29a=pd.DataFrame(list(q29a.items()),columns = ['Answer','Responses'])\ndf_q29b=pd.DataFrame(list(q29b.items()),columns = ['Answer','Responses'])\ndf_q31a=pd.DataFrame(list(q31a.items()),columns = ['Answer','Responses'])\ndf_q31b=pd.DataFrame(list(q31b.items()),columns = ['Answer','Responses'])\ndf_q33a=pd.DataFrame(list(q33a.items()),columns = ['Answer','Responses'])\ndf_q33b=pd.DataFrame(list(q33b.items()),columns = ['Answer','Responses'])\ndf_q34a=pd.DataFrame(list(q34a.items()),columns = ['Answer','Responses'])\ndf_q34b=pd.DataFrame(list(q34b.items()),columns = ['Answer','Responses'])\ndf_q35a=pd.DataFrame(list(q35a.items()),columns = ['Answer','Responses'])\ndf_q35b=pd.DataFrame(list(q35b.items()),columns = ['Answer','Responses'])\n\n\n\n# Q26 Which of the following cloud computing platforms do you hope to become more familiar with in the next 2 years?\nfig = go.Figure()\nfig.add_trace(go.Bar(\n    x=df_q26a['Answer'],\n    y=df_q26a['Responses'],\n    name='Present',\n    marker_color='LightSlateGray'\n))\nfig.add_trace(go.Bar(\n    x=df_q26b['Answer'],\n    y=df_q26b['Responses'],\n    text=df_q26b['Responses'],\n    textposition='inside',\n    name='Future',\n    marker_color='LightSeaGreen'\n))\nfig.update_layout(\n    title=\"Which of the following cloud computing platforms do you hope to become more <br> familiar with in the next 2 years?\",\n    barmode='group', xaxis_tickangle=-45)\nfig.show()\n\n#q27 In the next 2 years, do you hope to become more familiar with any of these specific cloud computing products?\nfig = go.Figure()\nfig.add_trace(go.Bar(\n    x=df_q27a['Answer'],\n    y=df_q27a['Responses'],\n    name='Present',\n    marker_color='LightSlateGray'\n))\nfig.add_trace(go.Bar(\n    x=df_q27b['Answer'],\n    y=df_q27b['Responses'],\n    text=df_q27b['Responses'],\n    textposition='inside',\n    name='Future',\n    marker_color='LightSeaGreen'\n))\nfig.update_layout(\n    title=\"In the next 2 years, do you hope to become more familiar with any of these specific <br> cloud computing products?\",\n    barmode='group', xaxis_tickangle=-45)\nfig.show()\n\n#q28 In the next 2 years, do you hope to become more familiar with any of these specific machine learning products?\n\nfig = go.Figure()\nfig.add_trace(go.Bar(\n    x=df_q28a['Answer'],\n    y=df_q28a['Responses'],\n    name='Present',\n    marker_color='LightSlateGray'\n))\nfig.add_trace(go.Bar(\n    x=df_q28b['Answer'],\n    y=df_q28b['Responses'],\n    text=df_q28b['Responses'],\n    textposition='inside',\n    name='Future',\n    marker_color='LightSeaGreen'\n))\nfig.update_layout(\n    title=\"In the next 2 years, do you hope to become more familiar with any of these specific <br> machine learning products?\",\n    barmode='group', xaxis_tickangle=-45)\nfig.show()\n\n#q29 Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you hope to become more familiar with in the next 2 years?\n\nfig = go.Figure()\nfig.add_trace(go.Bar(\n    x=df_q29a['Answer'],\n    y=df_q29a['Responses'],\n    name='Present',\n    marker_color='LightSlateGray'\n))\nfig.add_trace(go.Bar(\n    x=df_q29b['Answer'],\n    y=df_q29b['Responses'],\n    text=df_q29b['Responses'],\n    textposition='inside',\n    name='Future',\n    marker_color='LightSeaGreen'\n))\nfig.update_layout(\n    title=\"Which of the following big data products (relational databases, data warehouses,<br> data lakes, or similar) do you hope to become more familiar with in the next 2 years?\",\n    barmode='group', xaxis_tickangle=-45)\nfig.show()\n\n#q31 Which of the following business intelligence tools do you hope to become more familiar with in the next 2 years? \n\nfig = go.Figure()\nfig.add_trace(go.Bar(\n    x=df_q31a['Answer'],\n    y=df_q31a['Responses'],\n    name='Present',\n    marker_color='LightSlateGray'\n))\nfig.add_trace(go.Bar(\n    x=df_q31b['Answer'],\n    y=df_q31b['Responses'],\n    text=df_q31b['Responses'],\n    textposition='inside',\n    name='Future',\n    marker_color='LightSeaGreen'\n))\nfig.update_layout(\n    title=\"Which of the following business intelligence tools do you hope to become <br> more familiar with in the next 2 years? \",\n    barmode='group', xaxis_tickangle=-45)\nfig.show()\n\n#q33 Which categories of automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?\n\nfig = go.Figure()\nfig.add_trace(go.Bar(\n    x=df_q33a['Answer'],\n    y=df_q33a['Responses'],\n    name='Present',\n    marker_color='LightSlateGray'\n))\nfig.add_trace(go.Bar(\n    x=df_q33b['Answer'],\n    y=df_q33b['Responses'],\n    text=df_q33b['Responses'],\n    textposition='inside',\n    name='Future',\n    marker_color='LightSeaGreen'\n))\nfig.update_layout(\n    title=\"Which categories of automated machine learning tools (or partial AutoML tools)<br> do you hope to become more familiar with in the next 2 years?\",\n    barmode='group', xaxis_tickangle=-45)\nfig.show()\n\n#q34 Which specific automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?\n\nfig = go.Figure()\nfig.add_trace(go.Bar(\n    x=df_q34a['Answer'],\n    y=df_q34a['Responses'],\n    name='Present',\n    marker_color='LightSlateGray'\n))\nfig.add_trace(go.Bar(\n    x=df_q34b['Answer'],\n    y=df_q34b['Responses'],\n    text=df_q34b['Responses'],\n    textposition='inside',\n    name='Future',\n    marker_color='LightSeaGreen'\n))\nfig.update_layout(\n    title=\"Which specific automated machine learning tools (or partial AutoML tools) <br>do you hope to become more familiar with in the next 2 years?\",\n    barmode='group', xaxis_tickangle=-45)\nfig.show()\n\n#q35 In the next 2 years, do you hope to become more familiar with any of these tools for managing ML experiments?\n\nfig = go.Figure()\nfig.add_trace(go.Bar(\n    x=df_q35a['Answer'],\n    y=df_q35a['Responses'],\n    name='Present',\n    marker_color='LightSlateGray'\n))\nfig.add_trace(go.Bar(\n    x=df_q35b['Answer'],\n    y=df_q35b['Responses'],\n    text=df_q35b['Responses'],\n    textposition='inside',\n    name='Future',\n    marker_color='LightSeaGreen'\n))\nfig.update_layout(\n    title=\"In the next 2 years, do you hope to become more familiar with any of these tools <br>for managing ML experiments?\",\n    barmode='group', xaxis_tickangle=-45)\nfig.show()\n","9d0c012e":"<u>Extended analysis for the charts above.<\/u>\n\nSelect on all 5 charts <a>Master's Degree -> A personal computer or laptop <\/a>\n\nIn the end you should get 5 selection like in the picture below.\n![Education.png](attachment:Education.png)\nFrom this analysis it is easy to see that most of the Kagglers with Master's Degree use personal laptop for ML projects and main programming language is Python.\n\n<a>Data Imposters: <\/a> 60-70% aren't spending money on spcialized courses.\n\n<a>Students:<\/a> No data available for courses spending and looks like the programming language proportion is respected.\n\n<a>Data Enthusiasts:<\/a> 25% not spending money on courses and 25% are spending. Main programming languages are Python, R and SQL. SQL prove the right segmentation for the Data Enthusiasts.\n\n<a>Data Scientist:<\/a> 40% spend money on courses and they also work with SQL (might be transitional).\n\n<a>ML Engineers:<\/a> They are not using R and SQL, which speak about focus on algorithms and model implementation focus.\n\nSame as this example, you can click\/select other interested dimensions and analyze them.\n\n\n# **Age**\n\n<a>\u201c Age isn't how old you are but how old you feel. Age appears to be best in four things. Old wood best to burn, old wine to drink, old friends to trust, and old authors to read. Middle age is youth without levity, and age without decay.\u201d<\/a> [source](https:\/\/www.wisesayings.com\/age-quotes\/)\n\nAge breakdown by countries. Please interact with the charts and menu.","fe30777c":"# Specialized Harware\n<a> \u201cBefore software can be reusable it first has to be usable.\u201d<\/a> \u2013 Ralph Johnson","8e7e8a4c":"# Kaggle Survey 2020 - Why you are here?\n\n<a id=\"table-of-contents\"><\/a>\n\n**[Introduction](#Introduction)**<br>\n**[Kaggle User Segmentation](#section-two)**<br>\n**[Education \/ Technology](#section-three)**<br>\n**[Money Analysis](#section-four)**<br>\n**[Present and Future Technology Trends](#section-five)**<br>\n**[SUMMARY](#section-six)**<br>","6cac511b":"From this chart we can easily see Top 10 and Other countries and the relationship of Age vs Salary.<br>\nThe leading position is USA followed by UK. Hover on bubbles to check averages overall by country. <br>\nData Scientists are leading overall by number of respondents and salary. Average age of a Data Scientist in the USA is almost 38 y.o. and 142K dollars\/year vs 36 y.o. and 90K dollars\/year in UK. <br>\nAlso we cannot underestimate Product\/Project Managers who are paid even better in most of the cases and play a huge role in the success of each team. <br>\n","a21f1f84":"<a>SEGMENTATION: <\/a> This is the breakdown segmentation result by TOP 10 countries, All and Other. Please interact with the filter to change specific dimension.  ","87441a23":"# Compensation by Kaggle User Types\n\nFrom our survey the most important hierarchical approach questions for compensation analysis will be:\n\n<a> CURRENT ROLE > EXPERIENCE > COMPENSATION <\/a>\n\nHere is the list of charts for this analysis. Click on specific measure one by one on each chart and see the differences.","bfd4efc6":"[back to top](#table-of-contents)\n<a id=\"section-two\"><\/a>\n#  **Kaggle User Segmentation**\n\nWe identified here 5 types of Kagglers position based. \nPlease click on MAP to check ALL Survey Details for that specific country!","a5605e37":"[back to top](#table-of-contents)\n<a id=\"section-five\"><\/a>\n# Present and Future Technology Trends\n\nIn 2020 we\u2019ll see a growing trend for applying recurrent neural networks for time series analysis and forecasting. \nRecurrent neural networks, which are an application of deep learning, are one reason we believe that deep learning will end up replacing traditional machine learning. \nFor example, deep learning can forecast data, such as future exchange rates for currency with a surprisingly high degree of accuracy.\n\nThe research into time series classification has made substantial progress in recent years. The problem being solved is complex, offering both high dimensionality and large numbers. \nSo far, no industry applications have been achieved. However, this is set to change as the research into this field has produced many promising results.\n","e6b270c2":"[back to top](#table-of-contents)\n<a id=\"section-four\"><\/a>\n# **Money Analysis**\n\n<a>Employee Remuneration <\/a> refers to the reward or compensation given to the employees for their work performances. Remuneration provides basic attraction to a employee to perform job efficiently and effectively.\n\nRemuneration leads to employee motivation. Salaries constitutes an important source of income for employees and determine their standard of living. Salaries effect the employees productivity and work performance. Thus the amount and method of remuneration are very important for both management and employees\n\nIn the following analysis we can analyze average salary and average age based on working position. \n\nTop 10 countries and \u201cOther\u201d compensation analysis. Hove or select Salary range to see the interaction on all countries.\n","23686c0e":"[back to top](#table-of-contents)\n<a id=\"section-six\"><\/a>\n# **SUMMARY**\n\n   During the recent 2020 global urgency, scientists, clinicians, and healthcare experts around the globe keep on searching for a new technology to support in tackling the Covid-19 pandemic. The Machine Learning (ML) and Artificial Intelligence (AI) application on the previous epidemic encourage researchers by giving a new angle to fight against the novel Coronavirus outbreak. <br>\nKaggle Survey 2020 show especially useful information about the behaviour of the main Key Kaggle Players. <br>\nWe can see a huge trend in pursuing a career in Data Science and Machine Learning Engineering as a global trend. The focus is to learn more, keeping current working position and finding a better paid job. <br>\nThere is an increase need for visualization tools and AutoML tools, which will lead to a faster and flexible solution. <br>\nStay safe and have a great learning journey. <br>","f771d4b5":"<u>Extended analysis for the charts above. <\/u><br>\nSelect on all 4 charts <a>20+ years <\/a><br>\n![Compensation.png](attachment:Compensation.png)\nIn the end you should get 4 selection like in the picture below. For the ML Engineers we do not have this breakdown so we will choose 10-20 years.<br>\n<a>Data Imposters: <\/a> 25% have a salary more than 100K\/year.<br>\n<a>Data Enthusiasts:<\/a> 50% have a range of 60k-200k\/year. Also, there are a lot of high paid ranges over 200k related to leadership positions like Project \/ Product Management.<br>\n<a>Data Scientist:<\/a> 50% have a range of 90k-200k\/year. This is the target profession aimed by most of the data people like Data Engineers, DB Analysts etc.<br>\n<a>ML Engineers:<\/a> There are no experts with more than 20+ years of ML experience and most of them are highly paid. <br>\nSame as this example, you can click\/select other interested dimensions and analyze them.<br>\n","ac4b38fc":"[back to top](#table-of-contents)\n<a id=\"section-three\"><\/a>\n# **Education \/ Technology**\nEducation is one of the most important steps for a good job. \nIn our case we need to do a comparison in between the segmentation elements. \nFrom our survey the most important hierarchical approach questions will be:\n\n<a>EDUCATION LEVEL > COMPUTING PLATFORM > PROPOSED PROGRAMMING LANGUAGE > MONEY SPENT ON ML COURSES<\/a>\n\nHere is the list of charts for this analysis. Click on specific measure one by one on each chart and see the differences.","fe7ffa2d":"# Hosted Notebooks\n<a> \u201cOptimism is an occupational hazard of programming: feedback is the treatment. \u201c<\/a> \u2013 Kent Beck","c6995e39":"<a>SEGMENTATION: Dimensional analysis<\/a> \nThis is a dimensional analysis for ALL respondents from the dataset. The analysis let you see the respondents by Age and Salary with the option on selecting them for further investigation. <br>\nThis type of analysis is good for a dimensional analysis and checking specific slice of data. The cons are \u2013 too many points plotted will decrease the performance. <br>\n","53abb94b":"# Computer Vision\n<a> \"If you're using a computer as an artist and expressing your personal vision, I think your personal vision comes through.\" <\/a> \u2013 Dave Gibbson","10aedee5":"# **Introduction**\n\nWhy are you here? What do you need from Kaggle? What Kaggle needs from you?\nEveryone has a purpose being on Kaggle, whether it is learning, technologies, information, recognition and even money. \n\nLet us keep it short and fun and try to break this down to small pieces. \nThe goal of this notebook is to spend around 10 minutes from which 8 minutes should be charts analysis and identifying yourself in all this story, also to find some good takeaways for future.\n","5ae8d719":"# Visualization Libraries\n<a> \"The inadequacy of uni-dimensional plotting along a continuum (in this case the diagonal of a symmetric matrix) inevitably would make \u201cbuffer\u201d elements appear non-conformist when in fact they may be part of an interconnected pattern.\"<\/a> \u2013  Jennifer K. McArthur","cdfdcb38":"# **Experience**\n\n<a>\u201c The only source of knowledge is experience.\u201d<\/a> Albert Einstein\n\nFrom the other side most of the companies value at least 3 years of experince.","3145f2ab":"# Programming Langage\n<a> \u201cAny fool can write code that a computer can understand. Good programmers write code that humans can understand.\u201d<\/a> \u2013 Martin Fowler","4f1dce09":"**CLICK ON THE MAP TO SEE DETAILS** \ud83d\udccc\n\nPictures source: free samples on Behance.\n\nTableau is amazing for data visualization but let us try to crack it down with Python.\n\n<a>Data Imposters: <\/a> (Other, Currently not employed and Blanks). These are specialists who cannot identify themselves as data specialists or most probable don\u2019t want to disclose their position. This could be: businessperson responsible for the budgets, product managers, supervisor, directors, CEO etc.\n\n<a>Students:<\/a> (Students). Studying and learning are main activities.\n\n<a>Data Enthusiasts:<\/a> (Data Analyst, Business Analyst, Data Engineer, DBA\/Database Engineer,  Software Engineer, Statistician, Product\/Project Manager, Research Scientist). These are the specialist who work on data and knowledge side, but don\u2019t really created Data Science or Machine Learning notebooks. For example, Data Analyst may be busy with curing the data for a Data Scientist. Or a Statistician can work on a complex problem, but the model is built by a Machine Learning Engineer. Basically, they want to try themselves and see what the hell is Machine Learning, how hard is it and if it is possible to learning and get that promotion (this is where I am).\n\n<a>Data Scientist and ML Engineers:<\/a> These are the next level specialists, and they are here the be recognized and continue their career as best in class.","905f24b5":"# Platforms to Learn Data Science\n<a> \u201cThe biggest benefit of eLearning is the utter lack of pressure. Because you get to set your own schedule and study only when you have time, eLearning makes learning not something you have to get over with, but something you look forward to! From experience, you learn more when you enjoy the process.\u201d<\/a> \u2013 Mark Hayes, Head of Marketing at Kintell","f5e0ca9b":"# References & Acknowledgement\n\n* Key Players Images: <a href=\"http:\/\/www.behance.net\">Behance.net<\/a>\n* [2020 Kaggle Data Science & Machine Learning Survey](https:\/\/www.kaggle.com\/paultimothymooney\/2020-kaggle-data-science-machine-learning-survey) by Paul Mooney\n* [Python Plotly Dropdown Demo](https:\/\/www.kaggle.com\/benhamner\/python-plotly-dropdown-demo) by Ben Hamner\n* [Plotly Express in Python](https:\/\/plotly.com\/python\/plotly-express\/)","829b0576":"# NLP - Neuro Linguistic Programming\n<a> \u201cNeuro-linguistic programming is to Neuroscience what Astrology is to Astronomy.\u201d<\/a> \u2013 Abhijit Naskar","84c9e77a":"# Machine Learnning Algorithms\n<a> \u201cWe are entering a new world. The technologies of machine learning, speech recognition, and natural language understanding are reaching a nexus of capability. The end result is that we\u2019ll soon have artificially intelligent assistants to help us in every aspect of our lives.\u201d<\/a> \u2013 Amy Stapleton","93936e8e":"<a>**3D Chart by Country Age and Salary**<\/a> \n\nImagine you have a transparent box with country balls with higher respondends on top and higher salary away from the corner. (Mighty Plotly Express in 1 line of code)","f2d66986":"# **Level of Formal Education**\n\n<a>\u201cAnyone who has never made a mistake has never tried anything new\u201d<\/a> Albert Einstein\n\nIf you want to lead a happy life and enjoy the good things the world has to offer, you certainly need to get educated. A great job, a good social reputation are few of the many benefits of being an educated person. Education is a must for a promising and secure future and a stable life.\n\nPlease interact with the menu.","9edf6d7d":"# Activities at work\n<a> \"Intelligence is the ability to adapt to change.\" <\/a> \u2013 Kent Beck","e4e5d447":"# Machine Learnning Frameworks\n<a> \u201cArtificial Intelligence, deep learning, machine learning\u200a\u2014\u200awhatever you\u2019re doing if you don\u2019t understand it\u200a\u2014\u200alearn it. Because otherwise you\u2019re going to be a dinosaur within 3 years.\u201d<\/a> \u2013 Mark Cuban"}}