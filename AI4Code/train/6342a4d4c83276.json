{"cell_type":{"bc241e60":"code","43b5f37e":"code","43891f3f":"code","fe1ca9dc":"code","3ac72df8":"code","806d01e9":"code","58c08af0":"code","07d2b89c":"code","43cf269c":"code","8d8779f4":"code","c023168a":"code","3c7aa316":"code","9de34099":"code","3d14f92b":"code","818ace34":"code","1cbe4038":"code","91d557d9":"code","991eafea":"code","a85ea275":"code","186c52b1":"code","b4b9c426":"code","a0b5d891":"code","6a3fc4c2":"code","6159e14d":"code","3fd16a64":"code","8d30ac6e":"code","0a5eadf4":"code","56574b17":"code","9dd917ad":"code","e3426270":"code","ea8223ea":"code","92c7f13b":"code","5a72fff4":"code","bb30f08d":"code","17f4c813":"code","8ff5791c":"code","bd5a8f59":"code","8e33ec59":"code","b0c29747":"code","f15c75c9":"code","c9ab23b0":"code","fa5d3d27":"code","e191a55e":"code","5477acf6":"code","30cd6f36":"code","76ac0478":"code","5c3982b2":"code","2977dc0b":"code","6d573adb":"code","a3ca41c6":"code","e4d62a74":"code","60c9b29a":"code","b3ba8eb2":"code","6da0e9eb":"code","34252c8a":"code","4b87dae9":"code","e68600d4":"code","b22f6c0f":"code","bae22812":"code","abc074f6":"code","c50d13c2":"code","ea44eee1":"code","f14d642f":"code","c50e1fae":"markdown","63b44492":"markdown","2a62eb40":"markdown","e3a4d6b3":"markdown","94fadfd7":"markdown","bfe8b3a3":"markdown","6b63f5da":"markdown","fb40290b":"markdown","63234226":"markdown","6abc81f1":"markdown","c1625012":"markdown","4a4b1784":"markdown","128a6afd":"markdown","e25a66dc":"markdown","9d9a6015":"markdown","5558fd63":"markdown","599be030":"markdown","e16f1394":"markdown","744aafc5":"markdown","5ab9fba7":"markdown","6c3f7d38":"markdown","85c78c69":"markdown","bb0af6fc":"markdown","3283a41b":"markdown","38a3e220":"markdown","c8e30181":"markdown","d1565cef":"markdown","48daf572":"markdown","97e1c2fe":"markdown","7181137d":"markdown","894f9c3c":"markdown","857f0080":"markdown","9856c1d6":"markdown","e2f91bd4":"markdown"},"source":{"bc241e60":"import pandas as pd\nimport numpy as np","43b5f37e":"#rides dataframe has rides data\nrides_df = pd.read_csv('..\/input\/los-angeles-metro-bike-share-trip-data\/metro-bike-share-trip-data.csv')\n#stations df has station level data\nstations_df = pd.read_csv('..\/input\/metro-bike-share-stations-2017-02-09.csv\/metro-bike-share-stations-2017-02-09.csv')","43891f3f":"rides_df.head(5)","fe1ca9dc":"stations_df.head(5)\n#Go_live_date format changes? :(","3ac72df8":"rides_df.columns","806d01e9":"#first, remove spaces in columns names, so it is easier to work with pandas \nrides_df.columns = [c.replace(' ', '_').lower() for c in rides_df.columns]\nstations_df.columns = [c.replace(' ', '_').lower() for c in stations_df.columns]","58c08af0":"#merge starting station name\nrides_df = rides_df.rename(columns={'starting_station_id': 'station_id'})\nrides_df = rides_df.merge(stations_df[['station_id', 'station_name', 'region']], on='station_id', how='left')\nrides_df = rides_df.rename(columns={'station_id': 'starting_station_id',\n                                    'station_name': 'station_name_start',\n                                    'region': 'region_start'})\n#merge ending station name\nrides_df = rides_df.rename(columns={'ending_station_id': 'station_id'})\nrides_df = rides_df.merge(stations_df[['station_id', 'station_name', 'region']], on='station_id', how='left')\nrides_df = rides_df.rename(columns={'station_id': 'ending_station_id',\n                                    'station_name': 'station_name_end',\n                                    'region': 'region_end'})","07d2b89c":"rides_df.columns","43cf269c":"rides_df.trip_id.nunique()","8d8779f4":"#just to check that table is unique at trip level\n#and it is\nrides_df.shape[0]","c023168a":"#does not exactly match, so i guess we could say we have only 67 stations in our dataset\nrides_df.starting_station_id.nunique(), stations_df.shape[0]","3c7aa316":"#Duration column, as informed in https:\/\/bikeshare.metro.net\/about\/data\/ is in minutes\n#The average trip length is 1555.3 minutes (25.9 hours)???\n#The median trip length is 600 minutes (10 hours)???\n#These numbers strikes me quite a bit, how is this possible?\nrides_df.duration.mean(), rides_df.duration.median()","9de34099":"#lets look again at the data\nrides_df[['duration', 'start_time', 'end_time']].head(5)","3d14f92b":"#duration (in minuts) column\nrides_df['duration_mins'] = rides_df.duration \/ 60.\nrides_df.duration_mins.mean(), rides_df.duration_mins.median()","818ace34":"#Let's look at the data distribution...\nrides_df.duration_mins.hist()","1cbe4038":"#lets remove entries with more than hours of duration\nrides_clean = rides_df[rides_df.duration_mins < 180]\nrides_clean.shape[0], rides_df.shape[0] - rides_clean.shape[0]","91d557d9":"rides_clean.duration_mins.hist(bins=25)","991eafea":"rides_clean.duration_mins.quantile(q=[0, 0.01, 0.05])","a85ea275":"#NA entries?\nrides_clean[['starting_station_longitude', 'starting_station_latitude',\\\n                                            'ending_station_longitude','ending_station_latitude']].isna().sum()","186c52b1":"#remove NA entries\nrides_clean = rides_clean.loc[(rides_clean.starting_station_longitude.notna()) & \\\n                              (rides_clean.ending_station_longitude.notna())]","b4b9c426":"#Entries with lon \/ lat set to 0?\n(rides_clean[['starting_station_longitude', 'starting_station_latitude',\\\n                                            'ending_station_longitude','ending_station_latitude']]==0).sum()","a0b5d891":"#station 4108 is either a station located here: https:\/\/www.latlong.net\/c\/?lat=0.000000&long=0.000000\n#or it is some kind of auxilair station\nrides_clean.loc[rides_clean.starting_station_longitude==0, 'starting_station_id'].unique()","6a3fc4c2":"stations_df.loc[stations_df.station_id == 4108]","6159e14d":"#Remove entries starting or ending in the warehouse\nrides_clean = rides_clean.loc[~((rides_clean.starting_station_id == 4108) \\\n                                | (rides_clean.ending_station_id == 4108))]","3fd16a64":"#Haversine distance\n#from https:\/\/stackoverflow.com\/questions\/19412462\/getting-distance-between-two-points-based-on-latitude-longitude\nfrom math import sin, cos, sqrt, atan2, radians\n\ndef hav_distance(row):\n    \"\"\"\n    Calculates the haversine distance, given a pandas row with the following row format:\n    lon1, lat1, lon2, lat2\n    \n    Returns the distance in KM.\n    \"\"\"\n    # approximate radius of earth in km\n    R = 6373.0\n\n    dlon = radians(row[2]) - radians(row[0])\n    dlat = radians(row[3]) - radians(row[1])\n\n    a = sin(dlat \/ 2)**2 + cos(radians(row[1])) * cos(radians(row[3])) * sin(dlon \/ 2)**2\n    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n\n    return R * c","8d30ac6e":"rides_clean['trip_distance'] = rides_clean[['starting_station_longitude', 'starting_station_latitude',\\\n                                            'ending_station_longitude','ending_station_latitude']]\\\n                                          .apply(hav_distance, axis=1)","0a5eadf4":"#distance distribution\nrides_clean.trip_distance.hist()","56574b17":"rides_clean.loc[rides_clean.duration_mins < 3].trip_distance.head(10)","9dd917ad":"rides_clean.loc[rides_clean.trip_distance == 0].duration_mins.hist()","e3426270":"rides_clean.loc[rides_clean.trip_distance == 0].trip_route_category.value_counts()","ea8223ea":"#mislabeled entry?\n#I don't know what is the round trip definition, but this looks quite round trip to me\nrides_clean.loc[rides_clean.trip_distance == 0].loc[rides_clean.trip_route_category=='One Way'][['starting_station_id', 'ending_station_id']]","92c7f13b":"rides_clean = rides_clean.loc[~((rides_clean.duration_mins <= 2) & (rides_clean.trip_distance == 0))]","5a72fff4":"rides_clean.shape[0], rides_df.shape[0] - rides_clean.shape[0]\n#we have filtered out 3.5K rides from since the beginning...","bb30f08d":"import seaborn as sns\nsns.jointplot(x=rides_clean.trip_distance,\n              y=rides_clean.duration_mins,kind='hex', \n              size = 7, \n              joint_kws=dict(gridsize=200),\n              xlim=(0, 5),\n              ylim=(0, 30))","17f4c813":"#calculate avg speed\n#Initialized to 0, so that when we are in a Round trip we do not get a divided by 0 \nrides_clean['avg_speed'] = 0\n#one way indeces\now_idx = rides_clean.loc[rides_clean.trip_route_category != 'Round Trip'].index\nrides_clean.loc[ow_idx, 'avg_speed'] = rides_clean.loc[ow_idx, 'trip_distance'] \/ (rides_clean.loc[ow_idx, 'duration_mins'] \/ 60.0)\nrides_clean.loc[ow_idx].avg_speed.mean()","8ff5791c":"#format is ISO 8601 (info from the webpage)\nrides_clean['start_time'].head(5)","bd5a8f59":"#as datetime\nrides_clean['start_time_dt'] = pd.to_datetime(rides_clean.start_time)\nrides_clean['end_time_dt'] = pd.to_datetime(rides_clean.end_time)\nrides_clean[['start_time', 'start_time_dt']].head(5)\n#the transformation looks all right","8e33ec59":"#Extract year, month, day, and day of the week from the datetime column \nrides_clean['year'] = rides_clean.start_time_dt.dt.year\nrides_clean['month'] = rides_clean.start_time_dt.dt.month\nrides_clean['day'] = rides_clean.start_time_dt.dt.day\n#The day of the week with Monday=0, Sunday=6\nrides_clean['dayweek'] = rides_clean.start_time_dt.dt.dayofweek","b0c29747":"rides_clean.start_time_dt.min()","f15c75c9":"rides_clean.groupby(['year', 'month'])['trip_id'].count().plot.bar(figsize = (8, 6))","c9ab23b0":"rides_clean.groupby(['day'])['trip_id'].count().plot.bar(figsize = (8, 6))","fa5d3d27":"rides_clean.groupby(['dayweek'])['trip_id'].count().plot.bar(figsize = (8, 6))","e191a55e":"rides_clean.groupby(['station_name_start'])['trip_id'].count().sort_values().plot.barh(figsize = (9, 12))","5477acf6":"rides_clean.groupby(['station_name_end'])['trip_id'].count().sort_values().plot.barh(figsize = (9, 12))","30cd6f36":"rides_clean['route'] = rides_clean.station_name_start + '-->' + rides_clean.station_name_end","76ac0478":"#we have 3585 routes, lets plot top 50\nrides_clean.route.nunique()","5c3982b2":"rides_clean.groupby(['route'])['trip_id'].count().sort_values()[-55:].plot.barh(figsize = (9, 14))","2977dc0b":"#we will use folium, nice package for geographical data\nimport folium\n\ndef get_base_map(rides_clean):\n    return folium.Map(location=[rides_clean.starting_station_latitude.mean(),\n                             rides_clean.starting_station_longitude.mean()],\n                   zoom_start=14,\n                   tiles='cartodbpositron')\n\n#base map\nbase = get_base_map(rides_clean)\nbase","6d573adb":"def add_station_markers(initial_map, rides_clean):\n    #station location visualization\n    statdf = rides_clean.drop_duplicates(subset=['starting_station_id'])\n    out_map = initial_map\n    for lat, lon, name in zip(statdf['starting_station_latitude'], statdf['starting_station_longitude'], statdf['station_name_start']):\n        out_map.add_child(folium.Marker(location=[lat,lon], popup=(folium.Popup(name))))\n    return out_map\n\nmarkers = add_station_markers(base, rides_clean)\nmarkers","a3ca41c6":"#groupby route\nroute_cnt = pd.DataFrame(rides_clean.groupby(['station_name_start', 'station_name_end', 'route'])['trip_id'].count()).reset_index()\nroute_cnt_swap = route_cnt.rename(columns = {'station_name_start': 'station_name_end',\n                                             'station_name_end': 'station_name_start'})\n#merge data for the routes, taking into account both directions\nroute_cnt_all = route_cnt.merge(route_cnt_swap, on=['station_name_start', 'station_name_end'])\n#sum the trips count if it has two directions (do not sum twice round trips)\nroute_cnt_all['route_count'] = route_cnt_all['trip_id_x']\nupdate_idx = route_cnt_all.station_name_start != route_cnt_all.station_name_end\nroute_cnt_all.loc[update_idx, 'route_count'] = route_cnt_all[update_idx].trip_id_x + route_cnt_all[update_idx].trip_id_y \nroute_cnt_all.head(5)","e4d62a74":"#final steps, and filter only those with a volume > 200\nroute_cnt_all = route_cnt_all.rename(columns = {'route_x': 'route'})\nroutedf = rides_clean.drop_duplicates(subset=['route'])\nroutedf = routedf.merge(route_cnt_all, on = 'route')\nroutedf_vol = routedf.loc[routedf.route_count > 200]\ndef draw_route_lines(initial_map, routedf_vol):\n    out_map = initial_map\n    #draw every route as a line\n    for ix, row  in routedf_vol[['starting_station_latitude', 'starting_station_longitude', 'ending_station_latitude', 'ending_station_longitude', 'route_count']].iterrows():\n        #draw a line for every route\n        folium.PolyLine([(row['starting_station_latitude'], row['starting_station_longitude']), \\\n                         (row['ending_station_latitude'], row['ending_station_longitude'])],\n                         weight = row['route_count'] \/ 150.,\n                         opacity = float(row['route_count']) \/ routedf_vol['route_count'].max(),\n                         popup= str(int(row['route_count'])))\\\n              .add_to(out_map)\n    return out_map\n\ndraw_route_lines(markers, routedf_vol)","60c9b29a":"#I would like to have done something like this:\n#https:\/\/python-graph-gallery.com\/300-draw-a-connection-line\/\n#but it did not seem so simple with folium :(","b3ba8eb2":"from folium import plugins\n#mostly taken from https:\/\/alysivji.github.io\/getting-started-with-folium.html\n# convert to (n, 2) nd-array format for heatmap\n#limited to 40K obs, as with more than that it dies\nstationArr = rides_clean[['starting_station_latitude', 'starting_station_longitude']][:40000].as_matrix()\n# plot heatmap\n# - get base map\n# - then draw the actual HeatMap\nget_base_map(rides_clean).add_child(plugins.HeatMap(stationArr, radius=40, max_val=300))","6da0e9eb":"#same as before, but adding route lines\n(draw_route_lines(get_base_map(rides_clean), routedf_vol)).add_child(plugins.HeatMap(stationArr, radius=40, max_val=300))","34252c8a":"#Extrat the hour from the start time\nrides_clean['hour'] = rides_clean.start_time_dt.dt.hour","4b87dae9":"#pick top 15 starting stations \ntop_15_stations = rides_clean.groupby(['station_name_start'])['trip_id']\\\n                             .count().sort_values(ascending=False)[:15]\\\n                             .index.values.tolist()\n#assignt a rank for each of the stations\nrank = [(top_15_stations[i], i + 1) for i in range(len(top_15_stations))]","e68600d4":"#filter only rides that belong to top stations\nrides_filt = rides_clean.loc[rides_clean.station_name_start.isin(top_15_stations)]\n#capture the hourly count by station\nrides_hourly = rides_filt.groupby(['hour', 'station_name_start'])['station_name_start'].count()\nrides_hourly = pd.DataFrame(rides_hourly)\nrides_hourly = rides_hourly.rename(columns={'station_name_start': 'count'})\nrides_hourly = rides_hourly.reset_index()\n\n#get the global station trips rank\nrides_hourly['rank'] = rides_hourly.station_name_start.apply(lambda x: [r[1] for r in rank if r[0] == x][0])","b22f6c0f":"#prepare the actual plot\n#inspiration from https:\/\/www.kaggle.com\/aashita\/guide-to-animated-bubble-charts-using-plotly\n#awesome package by \nfrom bubbly.bubbly import bubbleplot \nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode()","bae22812":"figure = bubbleplot(dataset=rides_hourly, x_column='rank', y_column='count', \n    bubble_column='station_name_start', time_column='hour', size_column='count', \n    x_title=\"Rank\", y_title=\"Hourly count\", title='Stations hourly trips', scale_bubble=3, height=650)\n\n\nfigure['layout']['xaxis']['range'] = [0, 16]\nfigure['layout']['yaxis']['range'] = [-20, 1500]\niplot(figure, config={'scrollzoom': True})","abc074f6":"#most of it from\n#https:\/\/plot.ly\/python\/animations\/\n\nfigure = bubbleplot(dataset=rides_hourly, x_column='rank', y_column='count', \n    bubble_column='station_name_start', time_column='hour', size_column='count', \n    x_title=\"Rank\", y_title=\"Hourly count\", title='Stations hourly trips', scale_bubble=3, height=650)\n\nsliders_dict = {\n    'active': 0,\n    'yanchor': 'top',\n    'xanchor': 'left',\n    'currentvalue': {\n        'font': {'size': 20},\n        'prefix': 'Hour:',\n        'visible': True,\n        'xanchor': 'right'\n    },\n    'transition': {'duration': 300, 'easing': 'cubic-in-out'},\n    'pad': {'b': 10, 't': 50},\n    'len': 0.9,\n    'x': 0.1,\n    'y': 0,\n    'steps': []\n}\n\n# make frames\nfor hour in rides_hourly.hour.unique():\n    for station in rides_hourly.station_name_start.unique():\n        dataset_by_hour_and_station = rides_hourly.loc[(rides_hourly.hour == hour) & (rides_hourly.station_name_start == station)]\n    slider_step = {'args': [\n        [hour],\n        {'frame': {'duration': 300, 'redraw': False},\n         'mode': 'immediate',\n       'transition': {'duration': 300}}\n     ],\n     'label': str(hour),\n     'method': 'animate'}\n    sliders_dict['steps'].append(slider_step)\n\nfigure['layout']['sliders'] = [sliders_dict]   \n    \nfigure['layout']['xaxis']['range'] = [0, 16]\nfigure['layout']['yaxis']['range'] = [-20, 1500]\niplot(figure, config={'scrollzoom': True})","c50d13c2":"#generate a 'weight' count columns\nrides_hourly['count_w'] = rides_hourly['count'] \/ rides_hourly['count'].max()\n#merge lat\/lon to this df\nrides_hourly = rides_hourly.merge(rides_clean.drop_duplicates(subset='station_name_start')[['station_name_start', 'starting_station_latitude', 'starting_station_longitude']], on='station_name_start')","ea44eee1":"#? plugins.HeatMapWithTime\n## Need to pass a list of lists!\nh_out = []\nfor h in rides_hourly.hour.unique():\n    list_h = rides_hourly.loc[rides_hourly.hour == h][['starting_station_latitude', 'starting_station_longitude', 'count_w']].values.tolist()\n    h_out.append(list_h)","f14d642f":"get_base_map(rides_clean).add_child(plugins.HeatMapWithTime(h_out, auto_play=True, radius=60, gradient={.2: 'blue', .4: 'lime', .6: 'red'}))\n#get_base_map(rides_clean).add_child(plugins.HeatMapWithTime(h_out, auto_play=True, radius=60))","c50e1fae":"### With almost out of the shelf bubbleplot ","63b44492":"### Starting Time analysis","2a62eb40":"### Input data structure","e3a4d6b3":"### Hourly rides plot","94fadfd7":"### What is the average duration of each trip?","bfe8b3a3":"Interesting, we can that round trips are 'breaking' the correlation estimation, as no matter the duration, they will always have 0 distance. But in the other samples we could fit a line and get the average speed.","6b63f5da":"### Station trip volume analysis","fb40290b":"It is interesting to see that the day of the week with the highest trip volume is on Thursday","63234226":"## Dynamic time plots","6abc81f1":"## High level analysis & data preparation","c1625012":"### Route frequency analysis","4a4b1784":"### base map","128a6afd":"Yup, it seems that there are many trips with 0 distance. I do not think that all of them should be removed, as some of them can be 'round trips'.","e25a66dc":"### Heatmap with time animation","9d9a6015":"### Rides HeatMap","5558fd63":"The highest number of trips were during August 2016. This high volume might have been related to good weather, tourism and that most of the people have summer vacations during that month. After August the volume reduced, reaching to around 10K monthly trips from December to February. In march we can see a increase in the volume.","599be030":"It is interesting to see that the 'Main & 1st-->Union Station West Portal' route is top one while the same route, in opposite direction has a significant lower volume (is it downhill in one direction?)","e16f1394":"### Station & top routes, taking into account both directions for every route","744aafc5":"### Handling the slider label","5ab9fba7":"Before closing the duration topic, what is the trip_distance - duration (speed) looks like in our trips?","6c3f7d38":"Yup, most of them are round trips, and data distribution seems quite ok","85c78c69":"There are extreme values in the dataset, 1400 minutes (23.3 hours) ride seems quite too high! \nAlso, reading from the bikeshare page: \"Some short round trips or long trips may be the result of system or user error, but have been kept in the dataset for completeness\".","bb0af6fc":"## Data overview","3283a41b":"7.14 KM\/h seems reasonable. (According to Google, the average cycling speed in Copenhagen is 15.5 km\/h)","38a3e220":"Now that we have removed extremely large duration trips, let's look at extremely short trips.","c8e30181":"## Geographical visualization","d1565cef":"This kernel runs an analysis on the L.A. bike share data. It uses not only the data published in the https:\/\/www.kaggle.com\/cityofLA\/los-angeles-metro-bike-share-trip-data dataset page, but also another csv that contains extra information from the stations (downloaded from https:\/\/bikeshare.metro.net\/wp-content\/uploads\/2018\/02\/metro-bike-share-stations-2017-02-09.csv)\n\nTable of Contents:\n-  [Data overview](##Data overview)\n    -  [Input data structure](### Input data structure)\n-  [High level analysis & data preparation](## High level analysis & data preparation)\n    -  [How many trips and stations do we have in the dataset? ](### How many trips and stations do we have in the dataset? )\n    -  [What is the average duration of each trip?](### What is the average duration of each trip?)\n    -  [Starting Time analysis](### Starting Time analysis)\n    -  [Station trip volume analysis](### Station trip volume analysis)\n    -  [Route frequency analysis](### Route frequency analysis)\n-  [Geographical visualization](## Geographical visualization)\n    -  [Base map](### Base map)\n    -  [Station locations](### Station locations)\n    -  [Station & top routes, taking into account both directions for every route](### Station & top routes, taking into account both directions for every route)\n    -  [Rides HeatMap](### Rides HeatMap)\n- [Dynamic time plots](## Dynamic time plots)\n    - [Hourly rides plot](### Hourly rides plot)\n    - [Heatmap with time animation] (### Heatmap with time animation)","48daf572":"### How many trips and stations do we have in the dataset? ","97e1c2fe":"Aha! So it is the LA warehouse. I would say that it is also interesting to remove trips starting or ending in the warehouse.","7181137d":"### Station locations","894f9c3c":"We have trips with one minute length (someone who picks a bike and decides to leave it back?). Also, 5% of the trips have duration lower than 3 minutes. To asses whether if it is too short, let's look at the distance (in straight line) between starting and ending stations. But first, less assess the quality of the input coordinates.","857f0080":"So, we can see that looking at start times, and end times, the duration seems to be measured not in minutes, but in seconds, that makes a bit more of sense to me!","9856c1d6":"Now that the 0s issues is shorted out, let's follow with the distance calculation.","e2f91bd4":"So, after all of this, I think it would be interesting to remove rides with 0 distance and duration lower than 2 minutes."}}