{"cell_type":{"3e2a10d7":"code","2cf891d9":"code","6386bc98":"code","033bd68d":"code","1c053d35":"code","1dd0de7f":"code","60e6feaa":"code","599b6e48":"code","674aedfe":"code","456f7a6e":"code","194714eb":"code","79537e8f":"code","28afd63a":"code","64b469fb":"code","9ef9d385":"code","9ef988ed":"code","a5d32b8e":"code","d36520ca":"code","20c6d5ff":"code","20df96f1":"code","b56d1416":"code","05e7173f":"code","f0d9a80f":"code","a0d5fdef":"code","b94407c3":"code","08a36b71":"code","f6324f4a":"code","8f654892":"code","43b7714c":"code","9948e8c3":"code","7dd42796":"code","e98a7f25":"code","17c8395a":"code","acabe1b8":"code","e4981339":"code","5e6d904f":"code","07720be3":"code","58be5758":"code","a7330db3":"code","6a334b24":"code","28e2a5a8":"code","92a26906":"code","1e48576a":"code","8687ff80":"code","42de141e":"code","ec2afb44":"code","7966b602":"code","5108b89c":"code","3d64bdfb":"code","06db59fb":"code","1991de58":"code","db368915":"markdown","3e29704d":"markdown","5c695393":"markdown","22371ed8":"markdown","5fd0f219":"markdown","90c995b2":"markdown","8f152b13":"markdown","a89157ca":"markdown","2ac97c83":"markdown","3c50e37c":"markdown"},"source":{"3e2a10d7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2cf891d9":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom sklearn import preprocessing \nfrom category_encoders import *\nfrom sklearn.preprocessing import LabelEncoder\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score,mean_squared_error\nfrom sklearn import datasets, linear_model, metrics\nfrom sklearn.metrics import  confusion_matrix","6386bc98":"df = pd.read_csv('..\/input\/health-insurance-cost-prediction\/insurance.csv')\ndf","033bd68d":"df.head()","1c053d35":"df.tail()","1dd0de7f":"df.shape","60e6feaa":"df.size","599b6e48":"df.dtypes","674aedfe":"df.columns","456f7a6e":"df.info()","194714eb":"df.describe()","79537e8f":"df.duplicated().sum()","28afd63a":"a = df[df.duplicated().values]\na","64b469fb":"df.drop([581],axis = 0,inplace = True)\ndf","9ef9d385":"df.reset_index(inplace = True,drop=True)","9ef988ed":"df.drop(['sex','smoker','region'],axis=1).skew()","a5d32b8e":"df.drop(['sex','smoker','region'],axis=1).corr()","d36520ca":"df.isnull().sum()","20c6d5ff":"! pip install Autoviz","20df96f1":"! pip install xlrd","b56d1416":"from autoviz.AutoViz_Class import AutoViz_Class\nAV = AutoViz_Class()\ndf_av = AV.AutoViz('..\/input\/health-insurance-cost-prediction\/insurance.csv')","05e7173f":"df['age'].value_counts()","f0d9a80f":"fig = px.histogram(x = df['age'])\nfig.show()","a0d5fdef":"df['sex'].value_counts()","b94407c3":"sns.countplot(x = 'sex',data=df)\nplt.show()","08a36b71":"fig = px.histogram(df, 'charges',             \n                   color=\"sex\",\n                   title=\"<b>Average charges<\/b>\")\n\nfig.add_vline(x=df['charges'].mean(), line_width=2, line_dash=\"dash\", line_color=\"black\")\n\nfig.show()\n#AS we can see that in majority of the cases females are paying more charges\n# majority of the payers were paying lessthan 10k insurance charges","f6324f4a":"df['smoker'].value_counts()","8f654892":"sns.countplot(x = 'smoker',data=df)\nplt.show()","43b7714c":"fig = px.histogram(df, 'charges',             \n                   color=\"smoker\",\n                   title=\"<b>Average charges<\/b>\")\n\nfig.add_vline(x=df['charges'].mean(), line_width=2, line_dash=\"dash\", line_color=\"black\")\n\nfig.show()\n#AS we can see that upto 10k majority of insurance payers were non smokers and after 10k majority of payers were smokers","9948e8c3":"df['region'].value_counts()","7dd42796":"sns.countplot(x = 'region',data=df)\nplt.show()","e98a7f25":"fig = px.histogram(df, 'charges',             \n                   color=\"region\",\n                   title=\"<b>Average charges<\/b>\")\n\nfig.add_vline(x=df['charges'].mean(), line_width=2, line_dash=\"dash\", line_color=\"black\")\n\nfig.show()\n#AS we can see that upto 10k majority of insurance payers were non smokers and after 10k majority of payers were smokers","17c8395a":"plt.figure(figsize=(16,9))\nx = df.drop(['sex','smoker','region'],axis = 1)\nax = sns.heatmap(x.corr(),annot = True,cmap = 'viridis')\nplt.show()","acabe1b8":"plt.figure(figsize=(6,8))\nx = df.drop(['sex','smoker','region'],axis = 1)\nfor i in x.columns:\n    sns.histplot(x[i],kde = True)\n    plt.show()","e4981339":"x = df.drop(['sex','smoker','region'],axis = 1)\nfor i in x.columns:\n    sns.boxplot(x = i, data = x,color = 'yellowgreen')\n    plt.xlabel(i)\n    plt.show()","5e6d904f":"x = df.drop(['sex','smoker','region'],axis = 1)\nfor i in x.columns:\n    sns.violinplot(x = i, data = x)\n    plt.xlabel(i)\n    plt.show()","07720be3":"plt.figure(figsize=(6,8))\nx = df.drop(['sex','smoker','region'],axis = 1)\nfor i in x.columns[:-1]:\n    sns.scatterplot(x = 'charges' ,y = i, data = df, color = 'red')\n    plt.show()","58be5758":"sns.pairplot(df)","a7330db3":"def count_outliers(data,col):\n        q1 = data[col].quantile(0.25,interpolation='nearest')\n        q2 = data[col].quantile(0.5,interpolation='nearest')\n        q3 = data[col].quantile(0.75,interpolation='nearest')\n        q4 = data[col].quantile(1,interpolation='nearest')\n        IQR = q3 -q1\n        global LLP\n        global ULP\n        LLP = q1 - 1.5*IQR\n        ULP = q3 + 1.5*IQR\n        if data[col].min() > LLP and data[col].max() < ULP:\n            print(\"No outliers in\",i)\n        else:\n            print(\"There are outliers in\",i)\n            x = data[data[col]<LLP][col].size\n            y = data[data[col]>ULP][col].size\n            a.append(i)\n            print('Count of outliers are:',x+y)\nglobal a\na = []\nfor i in x.columns:\n    count_outliers(x,i)","6a334b24":"df","28e2a5a8":"n = 'sex'\nencoded_method = LabelEncoder.fit_transform(LabelEncoder,df[n])\npd.DataFrame(df[n].value_counts().index, pd.Series(encoded_method).value_counts().index)\ndf = df.copy()\nlabel_1 = pd.get_dummies(df,columns=[n],drop_first=True)\nlabel_1.insert(loc=2, column=n, value=df[n].values)\nlabel_1.drop([n],axis = 1,inplace = True)\nlabel_1","92a26906":"n = 'smoker'\nencoded_method = LabelEncoder.fit_transform(LabelEncoder,df[n])\npd.DataFrame(df[n].value_counts().index, pd.Series(encoded_method).value_counts().index)\nlabel_1 = label_1.copy()\nlabel_2 = pd.get_dummies(label_1,columns=[n],drop_first=True)\nlabel_2.insert(loc=4, column=n, value=df[n].values)\nlabel_2.drop([n],axis = 1,inplace = True)\nlabel_2","1e48576a":"n = 'region'\nencoded_method = LabelEncoder.fit_transform(LabelEncoder,df[n])\npd.DataFrame(df[n].value_counts().index, pd.Series(encoded_method).value_counts().index)\nlabel_2 = label_2.copy()\nlabel_3 = pd.get_dummies(label_2,columns=[n],drop_first=True)\nlabel_3.insert(loc=4, column=n, value=df[n].values)\nlabel_3.drop([n],axis = 1,inplace = True)\nlabel_3","8687ff80":"scaler = StandardScaler()\nscaler.fit(label_3.drop(['charges'],axis = 1))","42de141e":"X = label_3.drop(['charges'],axis = 1)\nY = label_3['charges']\nX_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.3,random_state=44)","ec2afb44":"poly = PolynomialFeatures(degree=2)","7966b602":"X_poly = poly.fit_transform(X_train)","5108b89c":"L1 = LinearRegression()\nL1.fit(X_poly,Y_train)","3d64bdfb":"X_test_poly =poly.fit_transform(X_test)","06db59fb":"Y_pred=L1.predict(X_test_poly)\nY_pred","1991de58":"print(\"R2 score\",r2_score(Y_test,Y_pred))\nprint(\"MSE\",np.sqrt(mean_squared_error(Y_test,Y_pred)))","db368915":"# Prediction using polynomial regression of degree 2","3e29704d":"# Feature Scaling","5c695393":"# Data Visualisation","22371ed8":"# Exploratory Data Analysis","5fd0f219":"# Data Visualisation Using Autoviz","90c995b2":"# Feature Selection","8f152b13":"# Count of Outliers","a89157ca":"# Loading DataSet","2ac97c83":"# Data Preprocessing","3c50e37c":"# Impoerting Libraries"}}