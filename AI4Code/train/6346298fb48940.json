{"cell_type":{"ef6d9f17":"code","bb17ea82":"code","011bc362":"code","54bd9d2b":"code","90c09705":"code","4c2d6f73":"code","41356866":"code","ad88ac4a":"code","cae5b053":"code","a29722b1":"code","f6ad04dd":"code","553dbab1":"code","c551538b":"code","8be54d3f":"code","ecec6983":"code","68131cb1":"code","4eddea96":"code","91e78a58":"code","0945c546":"code","d3268815":"code","a4b611ea":"code","f775c532":"code","5b7aefcd":"code","afbc3719":"markdown","7aa589aa":"markdown","c22368f2":"markdown","0ff33a97":"markdown","840feb8c":"markdown","fb128cf8":"markdown","6f16c9c3":"markdown","04375f4b":"markdown","d7d71bea":"markdown","4b5040bd":"markdown","d8d720da":"markdown","a3d8d692":"markdown","28556857":"markdown","f6694f1b":"markdown","7c08a123":"markdown","7d371738":"markdown"},"source":{"ef6d9f17":"import warnings\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport math\nimport numpy as np\n\nwarnings.filterwarnings(\"ignore\")","bb17ea82":"!pip install nb_black -q","011bc362":"%load_ext nb_black","54bd9d2b":"test = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")\nsample = pd.read_csv(\n    \"\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\"\n)\ntrain = pd.read_csv(\n    \"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\"\n)","90c09705":"def plot_hists(df, labels):\n    row = 1\n    col = 1\n    num_graphs = len(labels)\n    rows = math.ceil(num_graphs \/ 2)\n    fig = make_subplots(rows=rows, cols=2, subplot_titles=labels)\n\n    index = []\n    for row in range(1, rows + 1):\n        for col in range(1, 3):\n            index.append({\"row\": row, \"col\": col})\n\n    graphs = []\n    pos_g = 0\n    for label in labels:\n        local_data = df[label].value_counts()\n        x = list(local_data.index)\n        y = list(local_data)\n        fig.add_trace(\n            go.Histogram(x=df[label]), row=index[pos_g][\"row\"], col=index[pos_g][\"col\"],\n        )\n        pos_g = pos_g + 1\n\n    fig.update_layout(\n        autosize=False,\n        width=1200,\n        height=300 * rows,\n        margin=dict(l=50, r=50, b=100, t=100, pad=4),\n        #         paper_bgcolor=\"LightSteelBlue\",\n    )\n\n    fig.show()","4c2d6f73":"def plot_dists(df, labels):\n    row = 1\n    col = 1\n    num_graphs = len(labels)\n    rows = math.ceil(num_graphs \/ 3)\n    fig = make_subplots(rows=rows, cols=3, subplot_titles=labels)\n\n    index = []\n    for row in range(1, rows + 1):\n        for col in range(1, 4):\n            index.append({\"row\": row, \"col\": col})\n\n    graphs = []\n    pos_g = 0\n    for label in labels:\n        local_data = df[label].value_counts()\n        x = list(local_data.index)\n        y = list(local_data)\n        fig.add_trace(\n            go.Bar(x=x, y=y, text=y, textposition=\"auto\",),\n            row=index[pos_g][\"row\"],\n            col=index[pos_g][\"col\"],\n        )\n        pos_g = pos_g + 1\n    \n    fig.update_layout(\n        autosize=False,\n        width=1200,\n        height=300*rows,\n        margin=dict(\n            l=50,\n            r=50,\n            b=100,\n            t=100,\n            pad=4\n        ),\n#         paper_bgcolor=\"LightSteelBlue\",\n    )\n\n    fig.show()\n","41356866":"train.info()","ad88ac4a":"cat_col = [\n    \"MSSubClass\",\n    \"MSZoning\",\n    \"Street\",\n    \"Alley\",\n    \"LotShape\",\n    \"LandContour\",\n    \"Utilities\",\n    \"LotConfig\",\n    \"LandSlope\",\n    \"Neighborhood\",\n    \"Condition1\",\n    \"Condition2\",\n    \"BldgType\",\n    \"HouseStyle\",\n    \"OverallQual\",\n    \"OverallCond\",\n    \"YearBuilt\",\n    \"YearRemodAdd\",\n    \"RoofStyle\",\n    \"RoofMatl\",\n    \"Exterior1st\",\n    \"Exterior2nd\",\n    \"MasVnrType\",\n    \"ExterQual\",\n    \"ExterCond\",\n    \"Foundation\",\n    \"BsmtQual\",\n    \"BsmtCond\",\n    \"BsmtExposure\",\n    \"BsmtFinType1\",\n    \"BsmtFinType2\",\n    \"Heating\",\n    \"HeatingQC\",\n    \"CentralAir\",\n    \"Electrical\",\n    \"BsmtFullBath\",\n    \"BsmtHalfBath\",\n    \"FullBath\",\n    \"HalfBath\",\n    \"BedroomAbvGr\",\n    \"KitchenAbvGr\",\n    \"KitchenQual\",\n    \"TotRmsAbvGrd\",\n    \"Functional\",\n    \"Fireplaces\",\n    \"FireplaceQu\",\n    \"GarageType\",\n    \"GarageYrBlt\",\n    \"GarageFinish\",\n    \"GarageCars\",\n    \"GarageQual\",\n    \"GarageCond\",\n    \"PavedDrive\",\n    \"PoolQC\",\n    \"Fence\",\n    \"MiscFeature\",\n    \"MoSold\",\n    \"YrSold\",\n    \"SaleType\",\n    \"SaleCondition\",\n]\nplot_dists(\n    train, cat_col,\n)","cae5b053":"set_cat_col = set(cat_col)\nset_all_col = set(train.columns)\nset_num_col = set_all_col - set_cat_col - {\"Id\"}\nplot_hists(train, list(set_num_col))","a29722b1":"with sns.axes_style(\"white\"):\n    table = train.corr()\n    mask = np.zeros_like(table)\n    mask[np.triu_indices_from(mask)] = True\n    plt.figure(figsize=(20, 20))\n    sns.heatmap(\n        table, cmap=\"Reds\", mask=mask, center=0, linewidths=0.5, annot_kws={\"size\": 15},\n    )","f6ad04dd":"# Creating correlation matrix\ncorr = pd.DataFrame(train.corr()[\"SalePrice\"])\n# Set feature as index\ncorr[\"Feature\"] = corr.index\ncorr.sort_values(\"SalePrice\", inplace=True, ascending=False)\n# Plot our feature lest in dataset\nfig = px.bar(corr, x=\"Feature\", y=\"SalePrice\", color=\"SalePrice\", height=400)\nfig.show()","553dbab1":"from sklearn.preprocessing import LabelEncoder\n\nlb_make = LabelEncoder()\n\n\ndef fromat(dataset):\n    # Defing not a numbers in all columns\n    dataset[\"MSSubClass\"].fillna(0, inplace=True)\n    dataset[\"MSZoning\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"Street\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"Alley\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"LotShape\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"LandContour\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"Utilities\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"LotConfig\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"LandSlope\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"Neighborhood\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"Condition1\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"Condition2\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"BldgType\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"HouseStyle\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"OverallQual\"].fillna(0, inplace=True)\n    dataset[\"OverallCond\"].fillna(0, inplace=True)\n    dataset[\"YearBuilt\"].fillna(0, inplace=True)\n    dataset[\"YearRemodAdd\"].fillna(0, inplace=True)\n    dataset[\"RoofStyle\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"RoofMatl\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"Exterior1st\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"Exterior2nd\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"MasVnrType\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"ExterQual\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"ExterCond\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"Foundation\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"BsmtQual\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"BsmtCond\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"BsmtExposure\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"BsmtFinType1\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"BsmtFinType2\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"Heating\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"HeatingQC\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"CentralAir\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"Electrical\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"BsmtFullBath\"].fillna(0, inplace=True)\n    dataset[\"BsmtHalfBath\"].fillna(0, inplace=True)\n    dataset[\"FullBath\"].fillna(0, inplace=True)\n    dataset[\"HalfBath\"].fillna(0, inplace=True)\n    dataset[\"BedroomAbvGr\"].fillna(0, inplace=True)\n    dataset[\"KitchenAbvGr\"].fillna(0, inplace=True)\n    dataset[\"KitchenQual\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"TotRmsAbvGrd\"].fillna(0, inplace=True)\n    dataset[\"Functional\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"Fireplaces\"].fillna(0, inplace=True)\n    dataset[\"FireplaceQu\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"GarageType\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"GarageYrBlt\"].fillna(0, inplace=True)\n    dataset[\"GarageFinish\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"GarageCars\"].fillna(0, inplace=True)\n    dataset[\"GarageQual\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"GarageCond\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"PavedDrive\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"PoolQC\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"Fence\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"MiscFeature\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"MoSold\"].fillna(0, inplace=True)\n    dataset[\"YrSold\"].fillna(0, inplace=True)\n    dataset[\"SaleType\"].fillna(\"Not Know\", inplace=True)\n    dataset[\"SaleCondition\"].fillna(\"Not Know\", inplace=True)\n    dataset['BsmtFinSF2'].fillna(0.0, inplace=True)\n    dataset['GarageArea'].fillna(0.0, inplace=True)\n    dataset['PoolArea'].fillna(0.0, inplace=True)\n    dataset['ScreenPorch'].fillna(0.0, inplace=True)\n    dataset['LotArea'].fillna(0.0, inplace=True)\n    dataset['1stFlrSF'].fillna(0.0, inplace=True)\n    dataset['LotFrontage'].fillna(0.0, inplace=True)\n    dataset['OpenPorchSF'].fillna(0.0, inplace=True)\n    dataset['GrLivArea'].fillna(0.0, inplace=True)\n    dataset['MiscVal'].fillna(0.0, inplace=True)\n    dataset['BsmtUnfSF'].fillna(0.0, inplace=True)\n    dataset['EnclosedPorch'].fillna(0.0, inplace=True)\n    dataset['WoodDeckSF'].fillna(0.0, inplace=True)\n    dataset['LowQualFinSF'].fillna(0.0, inplace=True)\n    dataset['MasVnrArea'].fillna(0.0, inplace=True)\n    dataset['BsmtFinSF1'].fillna(0.0, inplace=True)\n    dataset['2ndFlrSF'].fillna(0.0, inplace=True)\n    dataset['3SsnPorch'].fillna(0.0, inplace=True)\n    dataset['TotalBsmtSF'].fillna(0.0, inplace=True)   \n    \n    # Defining type for categories\n    dataset[\"MSSubClass\"].astype(int)\n    dataset[\"MSZoning\"].astype(str)\n    dataset[\"Street\"].astype(str)\n    dataset[\"Alley\"].astype(str)\n    dataset[\"LotShape\"].astype(str)\n    dataset[\"LandContour\"].astype(str)\n    dataset[\"Utilities\"].astype(str)\n    dataset[\"LotConfig\"].astype(str)\n    dataset[\"LandSlope\"].astype(str)\n    dataset[\"Neighborhood\"].astype(str)\n    dataset[\"Condition1\"].astype(str)\n    dataset[\"Condition2\"].astype(str)\n    dataset[\"BldgType\"].astype(str)\n    dataset[\"HouseStyle\"].astype(str)\n    dataset[\"OverallQual\"].astype(int)\n    dataset[\"OverallCond\"].astype(int)\n    dataset[\"YearBuilt\"].astype(int)\n    dataset[\"YearRemodAdd\"].astype(int)\n    dataset[\"RoofStyle\"].astype(str)\n    dataset[\"RoofMatl\"].astype(str)\n    dataset[\"Exterior1st\"].astype(str)\n    dataset[\"Exterior2nd\"].astype(str)\n    dataset[\"MasVnrType\"].astype(str)\n    dataset[\"ExterQual\"].astype(str)\n    dataset[\"ExterCond\"].astype(str)\n    dataset[\"Foundation\"].astype(str)\n    dataset[\"BsmtQual\"].astype(str)\n    dataset[\"BsmtCond\"].astype(str)\n    dataset[\"BsmtExposure\"].astype(str)\n    dataset[\"BsmtFinType1\"].astype(str)\n    dataset[\"BsmtFinType2\"].astype(str)\n    dataset[\"Heating\"].astype(str)\n    dataset[\"HeatingQC\"].astype(str)\n    dataset[\"CentralAir\"].astype(str)\n    dataset[\"Electrical\"].astype(str)\n    dataset[\"BsmtFullBath\"].astype(int)\n    dataset[\"BsmtHalfBath\"].astype(int)\n    dataset[\"FullBath\"].astype(int)\n    dataset[\"HalfBath\"].astype(int)\n    dataset[\"BedroomAbvGr\"].astype(int)\n    dataset[\"KitchenAbvGr\"].astype(int)\n    dataset[\"KitchenQual\"].astype(str)\n    dataset[\"TotRmsAbvGrd\"].astype(int)\n    dataset[\"Functional\"].astype(str)\n    dataset[\"Fireplaces\"].astype(int)\n    dataset[\"FireplaceQu\"].astype(str)\n    dataset[\"GarageType\"].astype(str)\n    dataset[\"GarageYrBlt\"].astype(int)\n    dataset[\"GarageFinish\"].astype(str)\n    dataset[\"GarageCars\"].astype(int)\n    dataset[\"GarageQual\"].astype(str)\n    dataset[\"GarageCond\"].astype(str)\n    dataset[\"PavedDrive\"].astype(str)\n    dataset[\"PoolQC\"].astype(str)\n    dataset[\"Fence\"].astype(str)\n    dataset[\"MiscFeature\"].astype(str)\n    dataset[\"MoSold\"].astype(int)\n    dataset[\"YrSold\"].astype(int)\n    dataset[\"SaleType\"].astype(str)\n    dataset[\"SaleCondition\"].astype(str)\n    \n    # Defining type for numeric\n    dataset['BsmtFinSF2'].astype(float)\n    dataset['GarageArea'].astype(float)\n    dataset['PoolArea'].astype(float)\n    dataset['ScreenPorch'].astype(float)\n    dataset['LotArea'].astype(float)\n    dataset['1stFlrSF'].astype(float)\n    dataset['LotFrontage'].astype(float)\n    dataset['OpenPorchSF'].astype(float)\n    dataset['GrLivArea'].astype(float)\n    dataset['MiscVal'].astype(float)\n    dataset['BsmtUnfSF'].astype(float)\n    dataset['EnclosedPorch'].astype(float)\n    dataset['WoodDeckSF'].astype(float)\n    dataset['LowQualFinSF'].astype(float)\n    dataset['MasVnrArea'].astype(float)\n    dataset['BsmtFinSF1'].astype(float)\n    dataset['2ndFlrSF'].astype(float)\n    dataset['3SsnPorch'].astype(float)\n    dataset['TotalBsmtSF'].astype(float)\n\n    \n    types = pd.DataFrame(\n        dataset.dtypes, columns=[\"type\"]\n    )  # prepare the categorical columns\n    columns = list(\n        types[types.type == \"object\"].index\n    )  # making a list to the 'for' loop\n\n\n    lb_make = LabelEncoder()\n    for column in columns:\n        dataset[column] = lb_make.fit_transform(dataset[column])\n\n    return dataset\n","c551538b":"# Train dataset formatted\ntrain_fmt = fromat(train)\ntrain_fmt = train_fmt.fillna(0)\ntrain_fmt.set_index(\"Id\", inplace=True)\n\n# Test dataset formatted\ntest_fmt = fromat(test)\ntest_fmt.set_index(\"Id\", inplace=True)\ntest_fmt = test_fmt.fillna(0)","8be54d3f":"def verify_outline(df, quants):\n    for quant in quants:\n        if df[quant[\"col\"]] > quant[\"max_val\"]:\n            return \"Yes\"\n    return \"No\"\n\n\ndef remove_outline(df, plot=True, quant=0.90, set_num_col=set_num_col):\n    Id = list(df.index)\n    quants = []\n    for col in set_num_col:\n        quants.append({\"col\": col, \"max_val\": df[col].quantile(quant)})\n\n    # Verifying the dataset\n    df[\"isOutline\"] = [verify_outline(df[1], quants) for df in train_fmt.iterrows()]\n\n    # plot if flag is true\n    if plot:\n        fig = px.scatter(df, x=\"GrLivArea\", y=\"SalePrice\", color=\"isOutline\")\n        fig.show()\n    # removing outlines from dataset\n    df = df[df.isOutline == \"No\"]\n    df.drop(\"isOutline\", axis=1)\n    # plot if flag is true\n    if plot:\n        print(\"Starting with {} lines\".format(len(Id)))\n        print(\"Finishing with {} lines\".format(len(df)))\n    # returing the dataset without outlines\n    return df","ecec6983":"%%time\ntrain_no_out = remove_outline(train_fmt, True, 0.80, ['SalePrice'])","68131cb1":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import r2_score\n\n\ndef split(data, plot=False):\n    # seed\n    # train_test_split\n    train_x, test_x, train_y, test_y = train_test_split(\n        data.drop(\"SalePrice\", axis=1),\n        data[\"SalePrice\"],\n        test_size=0.2,\n        random_state=42367,\n    )\n    if plot:\n        print(\n            \"sizes: train (x,y) and test (x,y)\",\n            train_x.shape,\n            train_y.shape,\n            test_x.shape,\n            test_y.shape,\n        )\n    return train_x, test_x, train_y, test_y\n\n\ndef run_reg_linear(train_x, test_x, train_y, test_y, model, plot=False):\n    #     model = LinearRegression()\n    scaler = StandardScaler()\n    train_x_s = scaler.fit_transform(train_x)\n    model.fit(train_x_s, train_y)\n    test_pred = model.predict(scaler.transform(test_x))\n\n    mse = mean_squared_error(test_y, test_pred)\n    mae = mean_absolute_error(test_y, test_pred)\n    r2 = r2_score(test_y, test_pred)\n\n    if plot:\n        print(\"*\" * 80)\n        print(\"r2 score\", r2)\n        print(\"mse\", mse)\n        print(\"mae\", mae)\n        print(\"*\" * 80)\n\n    return model, r2\n\n\ndef r2_outline_qantile(q, model):\n    train_no_out = remove_outline(train_fmt, False, q, [\"SalePrice\"])\n    try:\n        train_no_out.drop(\"isOutline\", axis=1, inplace=True)\n    except:\n        pass\n    train_x, test_x, train_y, test_y = split(train_no_out)\n    model, r2 = run_reg_linear(train_x, test_x, train_y, test_y, model)\n    return r2","4eddea96":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import NearestCentroid\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\n\nfrom sklearn.linear_model import (\n    LinearRegression,\n    Ridge,\n    Lasso,\n    BayesianRidge,\n)\n\nvalores = []\nmodels = [\n    (\"LinearRegresion\", LinearRegression()),\n    (\"BayesianRidge\", BayesianRidge()),\n    (\"Ridge\", Ridge(alpha=0.5)),\n    (\"Lasso\", Lasso(alpha=0.1)),\n    (\"DecisionTreeRegressor\", DecisionTreeRegressor()),\n    (\"NearestCentroid\", NearestCentroid()),\n    (\"RandomForestRegressor\", RandomForestRegressor()),\n    (\"SVR\", SVR(C=1000000)),\n]\nfor model in models:\n    print(model[0])\n    for q in range(95, 101):\n        quantile = q \/ 100.0\n        valores.append((quantile, r2_outline_qantile(quantile, model[1]), model[0]))\n\ndf_hist = pd.DataFrame(valores, columns=[\"quantile\", \"r2\", \"model\"])\nfig = px.line(df_hist, x=\"quantile\", y=\"r2\", color=\"model\", title=\"R2 Curve \/ Quantile\")\nfig.show()","91e78a58":"from yellowbrick.regressor import PredictionError\n\ntrain_no_out = remove_outline(train_fmt, False, 1.0, [\"SalePrice\"])\ntry:\n    train_no_out.drop(\"isOutline\", axis=1, inplace=True)\nexcept:\n    pass\n\ntrain_x, test_x, train_y, test_y = split(train_no_out)\nmodel, r2 = run_reg_linear(train_x, test_x, train_y, test_y, BayesianRidge())\n\nprint(model, \"\\n\", r2)\n\n\ndef visualiza_erros(train_x, train_y, test_x, test_y, model):\n    scaler = StandardScaler()\n    train_x_s = scaler.fit_transform(train_x)\n    test_x_s = scaler.fit_transform(test_x)\n    visualizer = PredictionError(model)\n    visualizer.fit(train_x_s, train_y)\n    visualizer.score(test_x_s, test_y)\n    visualizer.poof()\n\n\nvisualiza_erros(train_x, train_y, test_x, test_y, model)","0945c546":"from sklearn.model_selection import RandomizedSearchCV\nimport numpy as np\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n# Number of features to consider at every split\nmax_features = [\"auto\", \"sqrt\"]\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num=11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {\n    \"n_estimators\": n_estimators,\n    \"max_features\": max_features,\n    \"max_depth\": max_depth,\n    \"min_samples_split\": min_samples_split,\n    \"min_samples_leaf\": min_samples_leaf,\n    \"bootstrap\": bootstrap,\n}\n\n# Use the random grid to search for best hyperparameters\n# First create the base model to tune\nrf = RandomForestRegressor()\n# Random search of parameters, using 3 fold cross validation,\n# search across 100 different combinations, and use all available cores\nrf_random = RandomizedSearchCV(\n    estimator=rf,\n    param_distributions=random_grid,\n    n_iter=100,\n    cv=3,\n    verbose=2,\n    random_state=42,\n    n_jobs=-1,\n)\n# Fit the random search model\nrf_random.fit(\n    train_fmt.drop([\"SalePrice\", \"isOutline\"], axis=1), train_fmt[\"SalePrice\"]\n)","d3268815":"rf_random.best_params_","a4b611ea":"# Plot-outputs\nmodel = RandomForestRegressor(\n    n_estimators=600,\n    min_samples_split=5,\n    min_samples_leaf=1,\n    max_features=\"sqrt\",\n    max_depth=60,\n    bootstrap=False,\n)\nmodel.fit(train_fmt.drop([\"SalePrice\", \"isOutline\"], axis=1), train_fmt[\"SalePrice\"])\ny_predict = model.predict(train_fmt.drop([\"SalePrice\", \"isOutline\"], axis=1))\nprint(\"MSE: \", mean_squared_error(train_fmt[\"SalePrice\"], y_predict))\nprint(\"R2: \", r2_score(train_fmt[\"SalePrice\"], y_predict))\n# Fig-size\nfig = go.Figure()\nfig.add_trace(\n    go.Scatter(\n        x=train_fmt.drop([\"SalePrice\", \"isOutline\"], axis=1).index,\n        y=y_predict,\n        mode=\"lines\",\n        name=\"Predict\",\n    )\n)\nfig.add_trace(\n    go.Scatter(\n        x=train_fmt.drop([\"SalePrice\", \"isOutline\"], axis=1).index,\n        y=train_fmt[\"SalePrice\"],\n        mode=\"markers\",\n        name=\"Real\",\n    )\n)\nfig.update_layout(title=\"Real X Pedricted\", xaxis_title=\"Sample\", yaxis_title=\"Price\")\nfig.show()","f775c532":"model","5b7aefcd":"# creating our submission csv\nmodel.fit(train_no_out.drop(\"SalePrice\", axis=1), train_no_out.SalePrice)\ny_test = model.predict(test_fmt)\nsample[\"SalePrice\"] = y_test\nsample.to_csv(\"submission_competion_RandomForestRegressor.csv\", index=False)\nsample","afbc3719":"This kernel is a approach to solve the competion [House Prices](https:\/\/www.kaggle.com\/c\/house-prices-advanced-regression-techniques).","7aa589aa":"# Starting libs and dataset","c22368f2":"## Category","0ff33a97":"Another point of view with PedrictionErro, using the BayesianRidge as an example.","840feb8c":"# Feature engineering","fb128cf8":"Training our model with all data and predict our test dataset.","6f16c9c3":"Plotting all scores for different quantiles (*0.90 ~ 1.00*) and 5 models.","04375f4b":"A example using quantile as 0.80 we mark the outline with red.","d7d71bea":"## Feature transformation","4b5040bd":"Formating dataset: train and test.","d8d720da":"# Submission","a3d8d692":"# EDA","28556857":"## Numeric","f6694f1b":"### That's all people :D","7c08a123":"### Removing outlines\nThe function veirfy_outline will verify if the row is an outline.","7d371738":"# Train\nThe train function will be used to train and plot variables from the process."}}