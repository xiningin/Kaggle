{"cell_type":{"c96fc2a5":"code","d0aea900":"markdown"},"source":{"c96fc2a5":"dist = Counter(reduce_train['accuracy_group'])\nfor k in dist:\n    dist[k] \/= len(reduce_train)\nreduce_train['accuracy_group'].hist()\n\nacum = 0\nbound = {}\nfor i in range(3):\n    acum += dist[i]\n    bound[i] = np.percentile(final_pred, acum * 100)\nprint(bound)\n\ndef classify(x):\n    if x <= bound[0]:\n        return 0\n    elif x <= bound[1]:\n        return 1\n    elif x <= bound[2]:\n        return 2\n    else:\n        return 3\n    \nfinal_pred = np.array(list(map(classify, final_pred)))\n\nsample_submission['accuracy_group'] = final_pred.astype(int)\nsample_submission.to_csv('submission.csv', index=False)\nsample_submission['accuracy_group'].value_counts(normalize=True)","d0aea900":"**\"Train data distribution and test data distribution are identical\"\n**\n\nBe careful of this false assumption, We are not sure if the train data distribution and the test data distribution are identical. I have used this code in all my top kernels and I got worse results."}}