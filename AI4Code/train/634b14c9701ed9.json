{"cell_type":{"df98cb6a":"code","4e523ef9":"code","9b1aaa58":"code","9c4328da":"code","b7c67591":"code","4131abe7":"code","bcf38d29":"code","27388757":"code","e70135ab":"code","709fc626":"code","0112749c":"code","fc35848f":"code","5ebc785a":"code","3456b097":"code","845dbf44":"code","8b41205a":"code","b428991e":"code","2e9f6089":"code","546dd5dc":"code","097f2100":"code","61331528":"code","25dc8d8e":"code","0add9bed":"code","0a42bae6":"code","e912ba9a":"code","bbca0c24":"code","b66ed7f3":"code","68454ecd":"code","36e0489e":"markdown","1bf33bfe":"markdown","3a7f60b3":"markdown","9ef5d556":"markdown","5e2b2442":"markdown","442f9d9c":"markdown","08de0ba1":"markdown","03e44db1":"markdown","9546e709":"markdown","4eb1cd17":"markdown","0bc6350b":"markdown"},"source":{"df98cb6a":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4e523ef9":"!pip install arabic-reshaper\n!pip install python-bidi\nimport pandas as pd\nimport numpy as np\nimport re\nimport arabic_reshaper\nfrom bidi.algorithm import get_display\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport collections\nimport pprint\nfrom wordcloud import WordCloud , ImageColorGenerator\nimport arabic_reshaper\nfrom nltk.probability import FreqDist\nfrom bidi.algorithm import get_display\nfrom IPython.display import Image\nfrom PIL import Image \nplt.figure(figsize=(8,8));","9b1aaa58":"\ndata = pd.read_csv(dirname + '\/Sahih Bukhari Without_Tashkel.csv')\ndata.head()","9c4328da":"all_hadith = list(data['Sahih Bukhari Without_Tashkel'])","b7c67591":"for i in range(10,15):\n    print(all_hadith[i])\n    print('-'*50)","4131abe7":"all_hadith_split_words = []\nfor each_h in all_hadith:\n    for each_w in each_h.split():\n        all_hadith_split_words.append(each_w)\n        \ntemp = collections.Counter(all_hadith_split_words)\ncollections_of_word = dict(sorted(temp.items(), key=lambda item: item[1], reverse= True))\nprint(f'There are {len(collections_of_word)} unique word.')\n","bcf38d29":"list(collections_of_word.items())[:10]","27388757":"splitting_words= ['\u0639\u0646' , '\u062d\u062f\u062b\u0646\u0627', '\u0633\u0645\u0639\u062a']","e70135ab":"count = []\nwordcount = 0\nmy_word=\"\u0639\u0646\"\nfor i in range(len(all_hadith)):\n    wordcount = 0\n    for word in all_hadith[i].split():\n        if(my_word == word):\n            wordcount +=1\n        count.append(wordcount)\n\nprint(max(count), min(count))\nsns.countplot(count)\nAr_title = get_display(arabic_reshaper.reshape('\u0639\u062f\u062f \u062a\u0643\u0631\u0627\u0631 \u0643\u0644\u0645\u0629 \"\u0639\u0646\"'))\nplt.title(Ar_title);        ","709fc626":"count = []\nwordcount = 0\nmy_word=\"\u062d\u062f\u062b\u0646\u0627\"\nfor i in range(len(all_hadith)):\n    wordcount = 0\n    for word in all_hadith[i].split():\n        if(my_word == word):\n            wordcount +=1\n        count.append(wordcount)\n\nprint(max(count), min(count))\nsns.countplot(count)\nAr_title = get_display(arabic_reshaper.reshape('\u0639\u062f\u062f \u062a\u0643\u0631\u0627\u0631 \u0643\u0644\u0645\u0629 \"\u062d\u062f\u062b\u0646\u0627\"'))\nplt.title(Ar_title);","0112749c":"count = []\nwordcount = 0\nmy_word=\"\u0633\u0645\u0639\u062a\"\nfor i in range(len(all_hadith)):\n    wordcount = 0\n    for word in all_hadith[i].split():\n        if(my_word == word):\n            wordcount +=1\n        count.append(wordcount)\n\nprint(max(count), min(count))\nsns.countplot(count)\nAr_title = get_display(arabic_reshaper.reshape('\u0639\u062f\u062f \u062a\u0643\u0631\u0627\u0631 \u0643\u0644\u0645\u0629 \"\u0633\u0645\u0639\u062a\"'))\nplt.title(Ar_title);","fc35848f":"count = []\nmy_word_1=\"\u0639\u0646\"\nmy_word_2=\"\u062d\u062f\u062b\u0646\u0627\"\nmy_word_3=\"\u0633\u0645\u0639\u062a\"\nfor i in range(len(all_hadith)):\n    wordcount_1, wordcount_2, wordcount_3 = 0, 0 ,0, \n    for word in all_hadith[i].split():\n        if(my_word_1 == word):\n            wordcount_1 +=1\n        elif(my_word_2 == word):\n            wordcount_2 +=1\n        elif(my_word_3 == word):\n            wordcount_3 +=1\n    count.append({\"Hadith_num\": i, \"An\": wordcount_1, \"Hadathna\": wordcount_2, \"Samaat\": wordcount_3}) \ncount[:10] # ['\u0639\u0646 , \u062d\u062f\u062b\u0646\u0627 , \u0633\u0645\u0639\u0646\u0627']\n","5ebc785a":"def normalize(sentence):\n    \"\"\"\n        replace all  \u0635\u0644\u064a or \u0627\u0644\u0646\u0628\u064a with \u0635\u0644\u0649 or \u0627\u0644\u0646\u0628\u0649\n    \"\"\"\n    sentence = re.sub(\"\u0635\u0644\u064a\", \"\u0635\u0644\u0649\", sentence)\n    sentence = re.sub(\"\u0627\u0644\u0646\u0628\u064a\", \"\u0627\u0644\u0646\u0628\u0649\", sentence)\n    return sentence\n\ntest_st = \"\u0642\u0627\u0644 \u0631\u0633\u0648\u0644 \u0627\u0644\u0644\u0647 \u0635\u0644\u064a \u0627\u0644\u0644\u0647 \u0639\u0644\u064a\u0647 \u0648\u0633\u0644\u0645 \u060c \u0642\u0627\u0644 \u0627\u0644\u0646\u0628\u064a \u0635\u0644\u0649 \u0627\u0644\u0644\u0647 \u0639\u0644\u064a\u0647 \u0648\u0633\u0644\u0645\"\nprint(test_st)\nprint(normalize(test_st))","3456b097":"all_hadith_with_normalization = []\nfor hadith in all_hadith:\n    all_hadith_with_normalization.append(normalize(hadith)) \n","845dbf44":"all_hadith_split_words_normalized = []\nfor each_h in all_hadith_with_normalization:\n    for each_w in each_h.split():\n        all_hadith_split_words_normalized.append(each_w)\n        \ntemp = collections.Counter(all_hadith_split_words_normalized)\ncollections_of_word_normalized = dict(sorted(temp.items(), key=lambda item: item[1], reverse= True))\n\nprint(\"\\t***The Same Length Here***\\t\")\nprint(f\"all summation of \u0635\u0644\u0649 is = {collections_of_word_normalized['\u0635\u0644\u0649'] }\")\nprint(f\"all summation of \u0627\u0644\u0646\u0628\u0649 is = {collections_of_word_normalized['\u0627\u0644\u0646\u0628\u0649'] }\")","8b41205a":"# just for testing code\n\na = \"\u0631\u0636\u064a \u0627\u0644\u0644\u0647 \u0639\u0646\u0647\u0645\u0627 \u0648 \u0631\u0636\u064a \u0627\u0644\u0644\u0647 \u0639\u0646\u0647 \u0633\u0645\u0639\u062a \u0639\u0646 \u0641\u0644\u0627 \u0639\u0646 \u0641\u0644\u0627\u0646 \u0642\u0627\u0644\"\n\nall_matches = [(m.group(0), (m.start(), m.end()-1)) for m in re.finditer('\u0639\u0646', a)]\nprint(all_matches)\nlast_matche , last_indecies= zip(*all_matches)\nfirst_index, last_index = last_indecies[-1][0], last_indecies[-1][1]\nsanad = a[0:first_index]\nmatn = a[last_index+1:]\n\nprint(sanad)\nprint(matn)","b428991e":"\"\"\"\n    Here get all not work well hadith\n\"\"\"\n\ntest_hadith = all_hadith_with_normalization\nsplited_hadiths = []\nsearching_word_1 = \" \u0631\u0633\u0648\u0644 \u0627\u0644\u0644\u0647 \"\nsearching_word_2 = \" \u0627\u0644\u0646\u0628\u0649 \"\npadding_word =\" \u0635\u0644\u0649 \u0627\u0644\u0644\u0647 \u0639\u0644\u064a\u0647 \u0648\u0633\u0644\u0645 \"\nf1, f2 = 0 , 0\nn_not = 0\nhadith_not_work_well = []\nfor i, hadith in enumerate(test_hadith):\n    st = \"\"\n    st_1 = re.search(searching_word_1, hadith)\n    st_2 = re.search(searching_word_2, hadith)\n    if st_1 == None and st_2 == None:\n        n_not +=1\n        hadith_not_work_well.append(hadith)\n\nprint(n_not)    ","2e9f6089":"for i in range(10):\n    print(hadith_not_work_well[i])\n    print('-'*50)","546dd5dc":"def splilt_hadith_book(data):\n    \"\"\"\n        I will check if the hadith contain the exact search words\n        if it conain:\n            split it\n        else:\n            put whole hadith in sanad and matn\n    \"\"\"\n    splited_hadiths = []\n    searching_word_1 = \" \u0631\u0633\u0648\u0644 \u0627\u0644\u0644\u0647 \"\n    searching_word_2 = \" \u0627\u0644\u0646\u0628\u0649 \"\n    padding_word = \" \u0635\u0644\u0649 \u0627\u0644\u0644\u0647 \u0639\u0644\u064a\u0647 \u0648\u0633\u0644\u0645 \"\n    f1, f2 = 0 , 0\n    n_not = 0\n\n    for i, hadith in enumerate(data):\n        st = \"\"\n        st_1 = re.search(searching_word_1, hadith)\n        st_2 = re.search(searching_word_2, hadith)\n        # if hadith didn't containt specific spliting word\/s\n        if st_1 == None and st_2 == None:\n            n_not +=1\n            splited_hadiths.append({\"sanad\" : hadith,\n                               \"matn\": hadith})\n            continue\n\n         # take the not None\n        if st_1 == None:\n            st = st_2 \n            f2 = 1\n        else:\n            st = st_1\n            f1 = 1\n        sanad = hadith[ : st.start()] + (searching_word_2 if f2 else searching_word_1)  + padding_word\n\n        matn = hadith[st.end()-1 + len(padding_word) : ]\n\n        splited_hadiths.append({\"sanad\" : sanad,\n                               \"matn\": matn})\n    return splited_hadiths\n","097f2100":"splited_hadiths = splilt_hadith_book(all_hadith_with_normalization)\nfor i in range(2):\n    print(splited_hadiths[i])\n    print('-'*50)","61331528":"print(f\"The percentage of good RegEx work {round((len(splited_hadiths) - n_not)\/ len(splited_hadiths),2) * 100}%\")","25dc8d8e":"all_bukhari_matn_, all_bukhari_matn_words = [], []\n\nfor hadith in splited_hadiths:\n    all_bukhari_matn_.append(hadith['matn'])\n#     all_bukhari_matn_words.append(hadith['matn'].split())\n    for word in hadith['matn'].split():\n        all_bukhari_matn_words.append(word)            ","0add9bed":"temp = collections.Counter(all_bukhari_matn_words)\ncollections_of_word = dict(sorted(temp.items(), key=lambda item: item[1], reverse= True))\nprint(f'There are {len(collections_of_word)} unique word.')","0a42bae6":"list(collections_of_word.items())[:10]","e912ba9a":"print(len(all_bukhari_matn_), len(all_bukhari_matn_words))\nlist_for_wordcloud = \" \".join(word for word in all_bukhari_matn_words ) ","bbca0c24":"font_path = \"..\/arial-bold.ttf\"\nimage_path = \"..\/bukhari_1.jpg\"","b66ed7f3":"Image.open(image_path)","68454ecd":"# coustom image\nmask = np.array(Image.open(image_path))\n\nreshaped_text = arabic_reshaper.reshape(list_for_wordcloud)\nartext = get_display(reshaped_text)\n\nmask_colors = ImageColorGenerator(mask)\n\nwc = WordCloud(font_path=font_path,\n               mask=mask, background_color=\"white\",\n               max_words=2000, max_font_size=256,\n               random_state=42, width=mask.shape[1],\n               height=mask.shape[0], color_func=mask_colors)\n\nplt.figure(figsize=(16, 12))\nwc.generate(artext)\nplt.imshow(wc, interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()\n","36e0489e":"### Ther are differance between in `\u064a \u0649`\n* \"\u0631\u0633\u0648\u0644 \u0627\u0644\u0644\u0647 \u0635\u0644\u064a \u0627\u0644\u0644\u0647 \u0639\u0644\u064a\u0647 \u0648\u0633\u0644\u0645\"\n* \"\u0631\u0633\u0648\u0644 \u0627\u0644\u0644\u0647 \u0635\u0644\u0649 \u0627\u0644\u0644\u0647 \u0639\u0644\u064a\u0647 \u0648\u0633\u0644\u0645\"\n\n-----\n* \"\u0627\u0644\u0646\u0628\u064a \u0635\u0644\u0649 \u0627\u0644\u0644\u0647 \u0639\u0644\u064a\u0647 \u0648\u0633\u0644\u0645\"\n* \"\u0627\u0644\u0646\u0628\u064a \u0635\u0644\u0649 \u0627\u0644\u0644\u0647 \u0639\u0644\u064a\u0647 \u0648\u0633\u0644\u0645\"\n\n* \"\u0631\u0633\u0648\u0644 \u0627\u0644\u0644\u0647 \u0635\u0644\u0649 \u0627\u0644\u0644\u0647 \u0639\u0644\u064a\u0647 \u0648\u0633\u0644\u0645\"\n\nSo we need to normalize **\u0635\u0644\u064a** with **\u0635\u0644\u0649**  \n","1bf33bfe":"![wc_h.png](attachment:wc_h.png)","3a7f60b3":"# EDA","9ef5d556":"### Most commen words in whole hadith \"Mode\"","5e2b2442":"### Most commen words in whole Matn","442f9d9c":"![bukhari_1.jpg](attachment:bukhari_1.jpg)","08de0ba1":"## How many \u0639\u0646 in each hadith?\n","03e44db1":"### Here we have 690 not contain the ideicator of splited words!\n\nsearching_word_1 = \" \u0631\u0633\u0648\u0644 \u0627\u0644\u0644\u0647 \"\n\nsearching_word_2 = \" \u0627\u0644\u0646\u0628\u0649 \"\n","9546e709":"## Some insights!\n* Most of the Hadiths has a lot of \u0639\u0646, and some of the just \u062d\u062f\u062b\u0646\u0627 , and some mixed of \u062d\u062f\u062b\u0646\u0627 and \u0639\u0646 , so:\n    * if there is at least on \"\u0639\u0646\", split from after it till the end.\n    * else, there will be at least one of \u062d\u062f\u062b\u0646\u0627 split after it till the end.\n* But it didn't work well because there are a lot of \"\u0639\u0646\" in the context of hadith not just using for rwah, so i will split the hadith if i found one of this  two cases:\n    * 1- if i foud \" \u0631\u0633\u0648\u0644 \u0627\u0644\u0644\u0647 \" split from it.\n    * 2- if i foud \" \u0627\u0644\u0646\u0628\u0649 \" split from it.\n* if i found each case from the upove i will split from it and the previous part will be `Sanad` and the after one will be `Matn`.        \n  ","4eb1cd17":"### Number of each word occurred in each hadith ['\u0639\u0646' , '\u062d\u062f\u062b\u0646\u0627', '\u0633\u0645\u0639\u062a']","0bc6350b":"# Wordcloud for all matn"}}