{"cell_type":{"3507fedf":"code","3d699447":"code","94a52063":"code","9c9cc1a6":"code","9e43be57":"code","b64ba652":"code","0aa0aa4f":"code","18f57dc7":"code","bf46d83a":"code","c74e22b5":"code","67f4927b":"code","c0feaab0":"code","a386f372":"code","c6f5f668":"code","758bfd96":"code","0b439d7a":"code","f7730e25":"code","93eb9d40":"code","6bc90269":"markdown","f5fabbac":"markdown","f0f3e246":"markdown","43f48fd3":"markdown","abc3dd5c":"markdown","0d30af43":"markdown","fb2dd868":"markdown","7b32b52c":"markdown","cc993e35":"markdown","3c8803c3":"markdown","d6298825":"markdown","8d8f9e9b":"markdown","434f41d0":"markdown","515ac1c9":"markdown","054a84e8":"markdown"},"source":{"3507fedf":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport pydicom\nimport matplotlib.pylab as plt\nfrom matplotlib import rcParams\nimport os\n\nrcParams['figure.figsize'] = 11.7,8.27\n\ntraindir = \"\/kaggle\/input\/rsna-intracranial-hemorrhage-detection\/stage_1_train_images\"\ntestdir = \"\/kaggle\/input\/rsna-intracranial-hemorrhage-detection\/stage_1_test_images\"","3d699447":"!ls \/kaggle\/input\/rsna-intracranial-hemorrhage-detection\/","94a52063":"train_csv = pd.read_csv(\"\/kaggle\/input\/rsna-intracranial-hemorrhage-detection\/stage_1_train.csv\")","9c9cc1a6":"train_csv.head(5)","9e43be57":"train_csv[\"type\"] = train_csv[\"ID\"].apply(lambda a:a.split(\"_\")[2])\ntrain_csv[\"ID\"] = train_csv[\"ID\"].apply(lambda a:\"_\".join(a.split(\"_\")[0:2]))","b64ba652":"train_csv.head(10)","0aa0aa4f":"sns.countplot(train_csv.Label)","18f57dc7":"train_csv.groupby(\"type\").sum()","bf46d83a":"\n\nlabel_distribution = train_csv.groupby(\"type\").sum().reset_index()\nsns.barplot(x=label_distribution.type,y=label_distribution.Label)","c74e22b5":"type_count_distribution = train_csv.groupby(\"ID\").sum().reset_index()\nvc = type_count_distribution.Label.value_counts()\nsns.barplot(x=vc.index,y=vc)","67f4927b":"def plot_images(hem_type):\n    images = train_csv[(train_csv[\"type\"] == hem_type) & (train_csv[\"Label\"] == 1)][\"ID\"].values[:100]\n    width = 5\n    height = 2\n    fig, axs = plt.subplots(height, width, figsize=(15,5))\n\n    for im in range(0, height * width):\n        image = pydicom.read_file(os.path.join(traindir,images[im]+ '.dcm')).pixel_array\n        i = im \/\/ width\n        j = im % width\n        axs[i,j].imshow(image, cmap=plt.cm.bone) \n        axs[i,j].axis('off')\n\n    plt.suptitle(hem_type)\n    plt.show()","c0feaab0":"plot_images(\"intraparenchymal\")","a386f372":"plot_images(\"epidural\")","c6f5f668":"plot_images(\"intraventricular\")","758bfd96":"plot_images(\"subarachnoid\")","0b439d7a":"plot_images(\"subdural\")","f7730e25":"train_csv.drop_duplicates(inplace=True)\npivot = train_csv.pivot(index='ID', columns='type', values='Label').reset_index()","93eb9d40":"corrs = pivot[[\"epidural\",\"intraparenchymal\",\"intraventricular\",\"subarachnoid\",\"subdural\"]].corr()\ncorrs.style.background_gradient(cmap='coolwarm')","6bc90269":"### Image containing intraventricular","f5fabbac":"#### If you find the kernel helpfull please upvote","f0f3e246":"# Lets plot some images","43f48fd3":"## Distribution of label count","abc3dd5c":"### Image containing subdural","0d30af43":"## Lets look at the distibution of Labels","fb2dd868":"## Lets dig into the traing labels csv","7b32b52c":"### Image containing intraparenchymal","cc993e35":"### The file structure looks very simple.Two folders with images and two csv files one with training labels and other is sample submission file","3c8803c3":"## What is the distribution of labels","d6298825":"# Lets look at the list of files given","8d8f9e9b":"### Image containing subarachnoid","434f41d0":"### Image containing epidural","515ac1c9":"### Lets see if any corelation between occurence of any type of hemorrhage","054a84e8":"### This gives us the insight that this is a multi class classification problem"}}