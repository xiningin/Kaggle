{"cell_type":{"6eb2b7b2":"code","248cd16d":"code","5b78e29e":"code","ad0b9159":"code","aa2bb97e":"code","6676f30d":"code","4fc0e500":"code","aec29c04":"code","edcac423":"code","a9acb688":"code","d25ac63a":"code","783ad3b3":"code","ad84fdfc":"code","c72977df":"code","b728c098":"code","5d825854":"code","a3607b03":"code","b485e1ab":"code","e5003885":"code","a2e8adb4":"code","b3b9a413":"code","a2bf3a1e":"code","40ec23d6":"code","6721105d":"code","b43116bd":"code","25b01629":"code","9393bffb":"markdown","a5f8f921":"markdown"},"source":{"6eb2b7b2":"from datetime import datetime, timedelta\nimport time\nfrom collections import namedtuple\nimport pandas as pd\nimport requests\nimport matplotlib.pyplot as plt","248cd16d":"API_KEY = '7b5a0c2e6087b43e' #please use your own api key for uninterrupted service\nBASE_URL = \"http:\/\/api.wunderground.com\/api\/{}\/history_{}\/q\/26.9124,75.7873.json\"","5b78e29e":"target_date = datetime(2018, 3, 12)\nfeatures = [\"date\", \"meantempm\", \"meandewptm\", \"meanpressurem\", \"maxhumidity\", \"minhumidity\", \"maxtempm\",\n            \"mintempm\", \"maxdewptm\", \"mindewptm\", \"maxpressurem\", \"minpressurem\", \"precipm\"]\nDailySummary = namedtuple(\"DailySummary\", features)","ad0b9159":"def extract_weather_data(url, api_key, target_date, days):\n    records = []\n    for _ in range(days):\n        request = BASE_URL.format(API_KEY, target_date.strftime('%Y%m%d'))\n        response = requests.get(request)\n        if response.status_code == 200:\n            data = response.json()['history']['dailysummary'][0]\n            records.append(DailySummary(\n                date=target_date,\n                meantempm=data['meantempm'],\n                meandewptm=data['meandewptm'],\n                meanpressurem=data['meanpressurem'],\n                maxhumidity=data['maxhumidity'],\n                minhumidity=data['minhumidity'],\n                maxtempm=data['maxtempm'],\n                mintempm=data['mintempm'],\n                maxdewptm=data['maxdewptm'],\n                mindewptm=data['mindewptm'],\n                maxpressurem=data['maxpressurem'],\n                minpressurem=data['minpressurem'],\n                precipm=data['precipm']))\n        time.sleep(6)\n        target_date += timedelta(days=1)\n    return records","aa2bb97e":"records = extract_weather_data(BASE_URL, API_KEY, target_date, 10)","6676f30d":"#change the date on the above cell to further add more data\nrecords += extract_weather_data(BASE_URL, API_KEY, target_date, 30)","4fc0e500":"df = pd.DataFrame(records, columns=features).set_index('date')","aec29c04":"tmp = df[['meantempm', 'meandewptm']].tail(10)\ntmp","edcac423":"tmp = df[['meantempm', 'meandewptm']].head(10)\ntmp","a9acb688":"#df.to_csv('JaipurRawData3.csv')","d25ac63a":"#df = pd.read_csv('JaipurRawData3.csv').set_index('date')","783ad3b3":"tmp = df[['meantempm', 'meandewptm']].tail(10)  \ntmp ","ad84fdfc":"# 1 day prior\nN = 1\n\n# target measurement of mean temperature\nfeature = 'meantempm'\n\n# total number of rows\nrows = tmp.shape[0]\n\n# a list representing Nth prior measurements of feature\n# notice that the front of the list needs to be padded with N\n# None values to maintain the constistent rows length for each N\nnth_prior_measurements = [None]*N + [tmp[feature][i-N] for i in range(N, rows)]\n\n# make a new column name of feature_N and add to DataFrame\ncol_name = \"{}_{}\".format(feature, N)\ntmp[col_name] = nth_prior_measurements\ntmp","c72977df":"def derive_nth_day_feature(df, feature, N):\n    rows = df.shape[0]\n    nth_prior_meassurements = [None]*N + [df[feature][i-N] for i in range(N, rows)]\n    col_name = \"{}_{}\".format(feature, N)\n    df[col_name] = nth_prior_meassurements","b728c098":"for feature in features:\n    if feature != 'date':\n        for N in range(1, 4):\n            derive_nth_day_feature(df, feature, N)","5d825854":"df.columns","a3607b03":"# make list of original features without meantempm, mintempm, and maxtempm\nto_remove = [feature \n             for feature in features \n             if feature not in ['meantempm', 'mintempm', 'maxtempm']]\n\n# make a list of columns to keep\nto_keep = [col for col in df.columns if col not in to_remove]\n\n# select only the columns in to_keep and assign to df\ndf = df[to_keep]\ndf.columns","b485e1ab":"df.info()","e5003885":"df = df.apply(pd.to_numeric, errors='coerce')\ndf.info()","a2e8adb4":"# Call describe on df and transpose it due to the large number of columns\nspread = df.describe().T\n\n# precalculate interquartile range for ease of use in next calculation\nIQR = spread['75%'] - spread['25%']\n\n# create an outliers column which is either 3 IQRs below the first quartile or\n# 3 IQRs above the third quartile\nspread['outliers'] = (spread['min']<(spread['25%']-(3*IQR)))|(spread['max'] > (spread['75%']+3*IQR))\n\n# just display the features containing extreme outliers\nspread.ix[spread.outliers,]","b3b9a413":"%matplotlib inline\nplt.rcParams['figure.figsize'] = [14, 8]\ndf.maxhumidity_1.hist()\nplt.title('Distribution of maxhumidity_1')\nplt.xlabel('maxhumidity_1')\nplt.show()","a2bf3a1e":"df.minpressurem_1.hist()\nplt.title('Distribution of minpressurem_1')\nplt.xlabel('minpressurem_1')\nplt.show()","40ec23d6":"# iterate over the precip columns\nfor precip_col in ['precipm_1', 'precipm_2', 'precipm_3']:\n    # create a boolean array of values representing nans\n    missing_vals = pd.isnull(df[precip_col])\n    df[precip_col][missing_vals] = 0","6721105d":"df = df.dropna()","b43116bd":"df.info()","25b01629":"df.to_csv('JaipurFinalCleanData.csv')","9393bffb":"tmp = df[['meantempm', 'meandewptm']].head(10)  \ntmp ","a5f8f921":"**A Second Kernel will be uploaded with the above clean Dataset to get the final Neural Network Prediction model**"}}