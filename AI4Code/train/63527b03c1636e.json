{"cell_type":{"a50ba078":"code","2972b39a":"code","7659bd64":"code","6f6d10dc":"code","63d5686c":"code","4ed50b58":"code","9e4f3b0f":"code","706ed2f0":"code","2d549e05":"code","9402c65e":"code","13d7af69":"code","0f294d59":"code","0a616524":"code","a7a104db":"code","cb5d7bfe":"code","8fe2d0eb":"code","9c125271":"code","f9ae798e":"code","285ef195":"code","c17c1ba8":"code","c49558ef":"markdown"},"source":{"a50ba078":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2972b39a":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\nprint(\"Tensorflow version \" + tf.__version__)\nnp.random.seed(10)","7659bd64":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","6f6d10dc":"training_csv_data = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\nsubmission_test_data = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","63d5686c":"training_csv_data.info()","4ed50b58":"train_data, test_data = train_test_split(training_csv_data,test_size=0.2,random_state=10)\nprint(train_data.info())\nprint(test_data.info())\n","9e4f3b0f":"y_train = train_data[\"label\"]\nx_train = train_data.drop([\"label\"],axis=1)\ny_test = test_data[\"label\"]\nx_test = test_data.drop([\"label\"],axis=1)\n","706ed2f0":"print(x_train.loc[3698,:].values.tolist())","2d549e05":"y_train.head()","9402c65e":"print(x_train.shape)\nprint(y_train.shape)","13d7af69":"x_train_norm = x_train\/255\nx_test_norm = x_test\/255\nx_train = x_train_norm\nx_test = x_test","0f294d59":"x_train = x_train.values\ny_train = y_train.values\nx_test = x_test.values\ny_test = y_test.values","0a616524":"# x_train =x_train.reshape(-1,28,28)\n# x_test =x_test.reshape(-1,28,28)\n# print(x_train.shape)\n# print(y_train.shape)\n# print(x_test.shape)\n# print(y_test.shape)\n","a7a104db":"model = tf.keras.models.Sequential()\nmodel.add(tf.keras.Input(shape=(784,)))\nmodel.add(tf.keras.layers.Dense(256, activation = tf.nn.relu))\nmodel.add(tf.keras.layers.Dense(10, activation = tf.nn.softmax))\n\nmodel.compile(optimizer='adam',\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\nmodel.summary()\n# history = model.fit(x_train, y_train, epochs=10)","cb5d7bfe":"model.fit(x_train,y_train,epochs = 10)","8fe2d0eb":"y_pred = model.predict(x_test)","9c125271":"y_pred = np.argmax(y_pred,axis =1)","f9ae798e":"y_test","285ef195":"count = 0\nfor v in range(0,len(y_test)):\n\n    if y_test[v] != y_pred[v]:\n        count=count+1\nprint(count)","c17c1ba8":"results = model.predict(submission_test_data)\n\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")\n\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"anmol_submission.csv\",index=False)\n\nsubmission.head()","c49558ef":"load data"}}