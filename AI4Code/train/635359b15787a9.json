{"cell_type":{"9f14bfac":"code","61bfa311":"code","11b468b7":"code","86844c74":"code","9a490a60":"code","a0d4e59d":"code","74d97e76":"code","c2cf0057":"code","eb71802b":"code","300829fa":"code","01502193":"code","767caefe":"code","c04ff390":"code","545c0d06":"code","bca94d57":"code","00e7d347":"code","66978be7":"code","c577f465":"code","9becd744":"code","106f763f":"code","26105ea3":"markdown","a30dd079":"markdown","6559e2dc":"markdown","5965f21e":"markdown","b679458f":"markdown","64952d6f":"markdown","7324c1fc":"markdown","92e1388c":"markdown","b9624994":"markdown","ce88a66b":"markdown","12414f66":"markdown","f41b86a8":"markdown","4363a79d":"markdown","2d83ee35":"markdown","15ecda74":"markdown","9b24cb55":"markdown","fce48247":"markdown","58991966":"markdown","9a21ac9e":"markdown"},"source":{"9f14bfac":"import pandas as pd\nimport numpy as np\nimport sklearn as sk\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom mlxtend.preprocessing import TransactionEncoder\nfrom mlxtend.frequent_patterns import apriori, association_rules\nfrom scipy.stats import probplot","61bfa311":"df = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")","11b468b7":"df.head()","86844c74":"df.isna().sum()     # count of missing values","9a490a60":"df.info()","a0d4e59d":"df.describe()","74d97e76":"# col = df.Cabin\n# for i in range(len(col)):\n#     if(df.Cabin.isna()[i] !=True):\n#         col[i] = df.Cabin[i][0]\n# df.Cabin = col\n# df.Cabin.fillna(df.Cabin.mode(), inplace=True)\n# sns.scatterplot(df.Cabin,df.Survived)","c2cf0057":"nominal_cols = ['Embarked','Pclass','Age', 'Survived', 'Sex']\ncat_cols = ['Embarked','Pclass','Age', 'Survived', 'Title']\ndf['Title'] = df.Name.str.extract('\\, ([A-Z][^ ]*\\.)',expand=False)\ndf['Title'].fillna('Title_UK', inplace=True)\ndf['Embarked'].fillna('Unknown',inplace=True)\ndf['Age'].fillna(df.Age.interpolate(), inplace=True)           # Resconsidering age\n# Replacing Binary with String\nrep = {0: \"Dead\", 1: \"Survived\"}\ndf.replace({'Survived' : rep}, inplace=True)\n\ndf.fillna(value=df.interpolate(),inplace=True)\ndf.fillna(value=df.mode(),inplace=True)\n\n\n\ntest['Title'] = test.Name.str.extract('\\, ([A-Z][^ ]*\\.)',expand=False)\ntest['Title'].fillna('Title_UK', inplace=True)\ntest['Embarked'].fillna('Unknown',inplace=True)\ntest['Age'].fillna(test.Age.interpolate(), inplace=True)           # Resconsidering age\n# Replacing Binary with String\nrep = {0: \"Dead\", 1: \"Survived\"}\ndf.replace({'Survived' : rep}, inplace=True)\n\ntest.fillna(value=df.interpolate(),inplace=True)\ntest.fillna(value=df.mode(),inplace=True)","eb71802b":"# fig,axes = plt.subplots(3,4,figsize=(15,10))\n# for i,ax in zip(df.columns, axes.flatten()):\n#     if((df[i].dtype == np.float) or (df[i].dtype == np.int)):\n#         sns.histplot(data=df, x=i,ax=ax)\n#         plt.show()","300829fa":"fig,axis = plt.subplots(3,3,figsize=(15,15))\naxis = axis.flatten()\nsns.histplot(data=df, x=\"Pclass\",ax=axis[0])\n\nsns.histplot(data=df, x=\"Fare\",ax=axis[1])\nsns.histplot(data=df, x=\"Age\",ax=axis[2])\nsns.histplot(data=df, x=\"SibSp\",ax=axis[3])\nsns.histplot(data=df, x=\"Survived\",ax=axis[4])\nsns.histplot(data=df, x=\"Sex\",ax=axis[5])\nsns.histplot(data=df, x=\"Embarked\",ax=axis[6])\nplt.figure(figsize=(15,5))\nsns.histplot(data=df, x=\"Title\",ax=axis[7])\nplt.show()","01502193":"qplot = probplot(df[\"Fare\"],dist='norm',plot=plt)\nplt.show()\nfrom scipy.stats import yeojohnson, yeojohnson_normplot, yeojohnson_normmax\n\noptimum_lmbda = yeojohnson_normmax(df[\"Fare\"])\nqplot_trans = probplot(yeojohnson(df[\"Fare\"],lmbda=optimum_lmbda),dist='norm',plot=plt)\n\ndf[\"Fare\"] = yeojohnson(df[\"Fare\"])[0]\n","767caefe":"def binning(col, cut_points, labels=None):\n  minval = col.min()\n  maxval = col.max()\n  break_points = [minval] + cut_points + [maxval]\n  if not labels:\n    labels = range(len(cut_points)+1)\n  colBin = pd.cut(col,bins=break_points,labels=labels,include_lowest=True)\n  return colBin\n\ncut_points = [10, 20, 50 ]\nlabels = [\"Child\", \"Teen\", \"Adult\", \"Old\"]\ndf['Age'] = binning(df['Age'], cut_points, labels)\nin_titanic = df[nominal_cols]\ncat_titanic = df[cat_cols]\ndf.drop([\"PassengerId\",\"Ticket\", \"Cabin\",\"Name\"],axis=1,inplace=True)\n\n\ntest['Age'] = binning(test['Age'], cut_points, labels)\ntest.drop([\"PassengerId\",\"Ticket\", \"Cabin\",\"Name\"],axis=1,inplace=True)","c04ff390":"df_store = df.copy()","545c0d06":"dataset = []\nfor i in range(0, df.shape[0]-1):\n    dataset.append([str(df.values[i,j]) for j in range(0, df.shape[1])])\n# dataset = in_titanic.to_xarray()\n\noht = TransactionEncoder()\noht_ary = oht.fit(dataset).transform(dataset)\ndf = pd.DataFrame(oht_ary, columns=oht.columns_)\ndf.head()\n# x_train,x_test","bca94d57":"output = apriori(df, min_support=0.2, use_colnames=oht.columns_)\noutput.head()","00e7d347":"output = apriori(df, min_support=0.2, use_colnames=oht.columns_)\nconfig = [\n    ('antecedent support', 0.7),\n    ('confidence', 0.8),\n    ('conviction', 3)\n]\n\nfor metric_type, th in config:\n    rules = association_rules(output, metric=metric_type, min_threshold=th)\n    if rules.empty:\n        print ('Empty Data Frame For Metric Type : ',metric_type,' on Threshold : ',th)\n        continue\n    print (rules.columns.values)\n    print ('-------------------------------------')\n    print ('Configuration : ', metric_type, ' : ', th)\n    print ('-------------------------------------')\n    print (rules)\n    support=rules['support']\n    confidence=rules['confidence']\n\n    plt.scatter(support, confidence, edgecolors='red')\n    plt.xlabel('support')\n    plt.ylabel('confidence')\n    plt.title(metric_type+' : '+str(th))\n    plt.legend()\n    plt.show()","66978be7":"rules = association_rules(output, metric=\"confidence\", min_threshold=0.7)","c577f465":"rules","9becd744":"rules[(rules.consequents == frozenset({\"Dead\"}))]","106f763f":"rules[(rules.consequents == frozenset({\"Survived\"}))]","26105ea3":"Top 5 tuples of the given data","a30dd079":"Understanding the distribution of some attributes.","6559e2dc":"## Data Analysis,Cleaning and Transformation ","5965f21e":"### Data Transformation","b679458f":"Statistical description of numerical attribute.","64952d6f":"## Finding Association Rules for Titanic Survival Dataset\nVariable\tDefinition\t                  Key\n* survival  |\tSurvival\t           |     0 = No, 1 = Yes <>\n* pclass\t|    Ticket class    \t    |    1 = 1st, 2 = 2nd, 3 = 3rd\n* sex\t    |    Sex\t\n* Age\t    |    Age in years\t\n* sibsp\t    |    Number of siblings \/ spouses aboard the Titanic\t\n* parch\t    |    Number of parents \/ children aboard the Titanic\t\n* ticket\t|    Ticket number\t\n* fare\t    |    Passenger fare\t\n* cabin\t    |    Cabin number\t\n* embarked  |\tPort of Embarkation\t     |   C = Cherbourg, Q = Queenstown, S = Southampton","7324c1fc":"### Plotting Data","92e1388c":"### Data Cleaning","b9624994":"Count of missing values in the dataset.","ce88a66b":"Changing the support and confidence will add or remove rules.<br>\nFrozenset can be used to find where Dead or Survived are present as a subset.","12414f66":"Data-type of each attribute ","f41b86a8":"Binning the Age into 4 groups (Child, Teen, Adult, and Old) for ease of interpretation and building simpler model","4363a79d":"## Basic Data Understanding","2d83ee35":"## Model building for generating Association Rules","15ecda74":"Association Rules:","9b24cb55":"Dividing the columns, and extracting Titles (Mr. Mrs, Miss. , ..etc) from the names of the passenger and dropping the rest. Names are useful but the title depict the rank of the passenger in the society, and it might affect the survival. <br>\nFilling the missing values using interpolation.","fce48247":"Using Apriori algorithm on the dataset, and the result has 263 itemset that have support greater than our _min_support=0.2_ ","58991966":"Preparing the dataset for Apriori algorithm, it requires data to be in boolean form.<br>\nThe resulting dataset has 2003 columns","9a21ac9e":"From the above plots, we see that _Fare_ is skewed, so plotted the Quantile Plot, and applied yeo-johnson transformation, so the transformation gets closer to normal distribution.<br>\nYeo-johnson was chosen cause log and simple power transformer were insufficient, and boxcox was also not yielding good result."}}