{"cell_type":{"b7f82b03":"code","ccc7db7f":"code","f1c57fb8":"code","780892b6":"code","10749493":"code","bd15531e":"code","db6a0156":"code","f52443d8":"code","05361408":"code","53bef1b5":"code","c6b7409d":"code","42a30d5c":"code","c5a7a16a":"code","639b1d53":"code","dc414418":"code","c03e84ac":"code","67118827":"code","1d2b2832":"code","f989eb80":"code","129226be":"code","72917e59":"code","89bc7476":"code","90dce4c3":"code","41e195f7":"code","c9980995":"code","cda24551":"code","cc895e64":"code","291bdfc4":"code","a0500f1e":"code","4c35ee05":"code","bf711b80":"code","d084f3a3":"markdown","02c2e804":"markdown","7f57b175":"markdown","ee9a0410":"markdown","45131f65":"markdown","f277c9b4":"markdown","87bec398":"markdown","ded5fd53":"markdown","0e3ae5bb":"markdown","d56fce5c":"markdown","f8b9833a":"markdown","2f2b11d7":"markdown","66747b26":"markdown","b5d5440d":"markdown","e5012e0f":"markdown","bc7b431b":"markdown","72684b92":"markdown","054a8b90":"markdown"},"source":{"b7f82b03":"import pandas as pd\nimport numpy as np\nfrom math import sqrt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense, Input\nimport matplotlib.pyplot as plt","ccc7db7f":"train = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","f1c57fb8":"train.head()","780892b6":"train.shape","10749493":"width = height = int(sqrt(train.shape[1]))\ntotal = train.shape[0]","bd15531e":"X_train = train.to_numpy()\nX_train = np.resize(X_train, (total, width, height))","db6a0156":"X_train.shape","f52443d8":"rows, cols = 6, 20\nfig, axs = plt.subplots(rows, cols, figsize = (20, 6))\nfor i in range(rows):\n    for j in range(cols):\n        axs[i][j].imshow(X_train[cols*i + j], cmap='gray')\nfig.tight_layout(pad=0.5)\nplt.show()","05361408":"import tensorflow as tf\nmnist = tf.keras.datasets.mnist\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()","53bef1b5":"x_train = np.array(x_train, dtype = np.float16)\nx_train = np.resize(x_train, (* x_train.shape[:3], 1))","c6b7409d":"x_train.shape","42a30d5c":"model = keras.Sequential([\n    Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu', input_shape = (28, 28, 1)),\n    MaxPooling2D((2, 2)),\n    Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'),\n    MaxPooling2D((2, 2)),\n    Conv2D(filters = 128, kernel_size = 3, padding = 'same', activation = 'relu', input_shape = (28, 28, 1)),\n    MaxPooling2D((2, 2)),\n    Flatten(),\n    Dropout(0.2),\n    Dense(128, activation = 'relu'),\n    Dropout(0.2),\n    Dense(10, activation = 'softmax')\n])","c5a7a16a":"model.compile(\n    optimizer = 'adam',\n    loss = 'sparse_categorical_crossentropy',\n    metrics = ['accuracy']\n)","639b1d53":"print(model.summary())","dc414418":"from keras.callbacks import EarlyStopping\nearly_stopping = EarlyStopping(patience = 10, min_delta = 0.0001, restore_best_weights = True)","c03e84ac":"history = model.fit(x_train, y_train, validation_split = 0.2, epochs = 100, callbacks = early_stopping)","67118827":"metrics = pd.DataFrame(history.history)\nmetrics[['loss', 'accuracy']].plot()","1d2b2832":"x_test = np.resize(x_test, (* x_test.shape[:3], 1))","f989eb80":"pred = model.predict(x_test)","129226be":"rows, cols = 6, 6\nfig, axs = plt.subplots(rows, cols, figsize = (15, 15))\nfor i in range(rows):\n    for j in range(cols):\n        axs[i][j].imshow(x_test[rows*i + j], cmap='gray')\n        axs[i][j].set_title(\"Predicted: \"+str(list(pred[rows*i + j]).index(max(list(pred[rows*i + j])))))\nfig.tight_layout(pad=3.0)\nplt.show()","72917e59":"def histogram(pred):\n    xhist = []\n    for item in range(10):\n        for j in range(int(pred[item] * 100)):\n            xhist.append(item)\n    return xhist\n    \ndef c(item):\n    return [0 if i != item.index(max(item)) else 1 for i in item]","89bc7476":"rows, cols = 6, 6\nfig, axs = plt.subplots(rows, cols, figsize = (15, 15))\nfor i in range(rows):\n    for j in range(cols):\n        axs[i][j].hist(histogram(pred[rows*i + j]), bins = np.linspace(-0.25, 9.25, 20))\n        axs[i][j].set_xticks(range(10))\n        axs[i][j].set_ylim((0, 100))\n        axs[i][j].set_title(\"Real: \"+str(y_test[rows*i + j]))\nfig.tight_layout(pad=3.0)\nplt.show()","90dce4c3":"def setup(pred):\n    return list(map(lambda x: list(x).index(np.max(x)), pred))","41e195f7":"final_pred = setup(pred)","c9980995":"from sklearn.metrics import confusion_matrix\ndf_conf=pd.DataFrame(confusion_matrix(final_pred, y_test), columns = range(10))\ndf_conf","cda24551":"from sklearn.metrics import classification_report\nprint(classification_report(final_pred, y_test))","cc895e64":"test = test.to_numpy()\ntest = np.resize(test, (total, width, height))\ntest = np.resize(test, (* test.shape[:3], 1))","291bdfc4":"pred = model.predict(test)\nfinal_pred = setup(pred)","a0500f1e":"output = pd.DataFrame(final_pred, columns = ['Label']); output.index += 1; output.head()","4c35ee05":"final_pred[:5]","bf711b80":"output.to_csv('output.csv', index_label = 'ImageId')","d084f3a3":"Another resize is require because the input for a CNN is **W x H x C**, where **C** corresponds to the **number of channels**. Given that our images are in grayscale, the number of channels will be 1.","02c2e804":"It is always important to take a look to the **accuracy** and **loss** evolution while training","7f57b175":"<a id=\"section-eight\"><\/a>\n# Final evaluation of our model\n\nAccuracy and loss are not the only metrics you must take into account. **Recall**, **precision** and, above all, **F1-Score**, give us another perspective of our model performance. The three of them are calculated from the **confusion matrix**. Take a look at what these parameters are and the meaning of confusion matrix clicking [here](https:\/\/en.wikipedia.org\/wiki\/Confusion_matrix).\n\n**Scikit-learn** has built-in methods that provide us with this useful information easily.","ee9a0410":"<a id=\"section-seven\"><\/a>\n# Predicting on the test set\nThe majority of times, the test set will also require some preprocessing","45131f65":"<a id=\"section-zero\"><\/a>\n# Setup\nFirst, import required libraries","f277c9b4":"# DIGITS RECOGNIZER WITH 99% ACCURACY\n\nEasy approach to a basic Computer Vision task: number recognition.\n\n**Computer Vision** takes advantage of Deep Learning using **Convolutional Neural Networks** to extract Features Map that make it possible for the computer to understand the characteristics of any image. Here, I'll show how to implement a basic CNN to achieve a great result.\n\n* [Setup](#section-zero)\n* [Data loading](#section-one)\n* [Data preprocessing](#section-two)\n* [Data visualization](#section-three)\n* [MNIST dataset](#section-four)\n* [Model implementation](#section-five)\n* [Model training](#section-six)\n* [Predicting on the test set](#section-seven)\n* [Final evaluation of our model](#section-eight)\n* [Saving predicted data](#section-nine)","87bec398":"##### Tip! **Model Summary**\n\nHere is a useful tool to understand a neural network architecture from the inside: **model.summary()**. Sometimes, at first, it may be confusing to fully understand output shapes from every layer in the CNN. ","ded5fd53":"**Earlystopping callback** will prevent us from waiting more than necessary","0e3ae5bb":"<a id=\"section-three\"><\/a>\n# Data visualization\nIn computer vision, visualizing our data is a key task.","d56fce5c":"<a id=\"section-four\"><\/a>\n# MNIST Dataset\nWe will use the complete MNIST Dataset to improve our model behavior","f8b9833a":"<a id=\"section-two\"><\/a>\n# Data preprocessing\n\nThe **head()** method is a must-do in order to make it easy to have an overall understanding of our data","2f2b11d7":"In order to be able to use a CNN, we will reshape our image as follows.","66747b26":"We can observe below that we don't have the right size for implementing a CNN algorithm given that pixels appeared as a 1D array for each image, instead of a matrix corresponding to the matrix formed by the pixels forming an image.","b5d5440d":"<a id=\"section-six\"><\/a>\n# Model training","e5012e0f":"Now we can see that we have achieve the required format for the input of our neural network","bc7b431b":"<a id=\"section-one\"><\/a>\n# Data loading\n\nHere I'll show how to read our files from the dataset on Kaggle. However, later on I'll use MINST dataset from Keras to better perform the task.\n\nThe dataset provided in Kaggle is just a slice of the whole MNIST dataset","72684b92":"<a id=\"section-five\"><\/a>\n# Model implementation","054a8b90":"<a id=\"section-nine\"><\/a>\n# Saving predicted data\nTo submit our predictions we will predict now on the Kaggle DataSet"}}