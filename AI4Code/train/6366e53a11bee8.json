{"cell_type":{"64eb9f23":"code","4d1cb4d1":"code","0f43ae6d":"code","44cf7557":"code","5297a765":"code","bfbc55b5":"code","dfbac646":"code","b9bbf89d":"code","c2bdae59":"code","157b8d37":"code","8dc53150":"code","2ece2f79":"code","ea6b32cd":"code","450f916f":"code","9ce05d81":"code","8237bfa9":"code","e3935d3a":"code","ee802fe3":"code","68d80a92":"code","7cd4c967":"code","661a2c25":"code","89c039a6":"code","54d9e400":"code","59bcfb30":"code","a7eacaa4":"code","78a059ea":"code","21c36037":"code","671ae77a":"code","d375ac6a":"code","600b4115":"code","30773190":"code","f6169863":"code","5212acd0":"code","6f288ccb":"markdown","026091e2":"markdown","6a7772ca":"markdown","af0cc25e":"markdown","b6b7aed7":"markdown","d2bf541e":"markdown","16f8720c":"markdown","e2ac3c54":"markdown","7b9798df":"markdown","5e330a4f":"markdown","9946417f":"markdown","ec28c6b0":"markdown","b1900ad6":"markdown","7bbe1963":"markdown","ce3b10e0":"markdown","77971704":"markdown","8549e8cd":"markdown","dcc356ec":"markdown","2bc167aa":"markdown","2a1f0cac":"markdown","99d90ef8":"markdown","c685e5af":"markdown","faafdf07":"markdown"},"source":{"64eb9f23":"#import libraries\nimport re\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport emoji","4d1cb4d1":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","0f43ae6d":" def read_file(file):\n    x = open(file,'r', encoding = 'utf-8') #Opens the text file into variable x but the variable cannot be explored yet\n    y = x.read() #By now it becomes a huge chunk of string that we need to separate line by line\n    content = y.splitlines() #The splitline method converts the chunk of string into a list of strings\n    return content\nchat = read_file('\/kaggle\/input\/chat.txt')\nlen(chat)","44cf7557":" #Remove new lines\nchat = [line.strip() for line in chat]\nprint(\"length of chat is:\")\nprint(len(chat))\n\n#Clean out the join notification lines\nclean_chat = [line for line in chat if not \"joined using this\" in line]\n\n#Further cleaning\n#Remove empty lines\nclean_chat = [line for line in clean_chat if len(line) > 1]\nprint(\"length of clean_chat is:\")\nprint(len(clean_chat))","5297a765":"msgs = [] #message container\npos = 0 #counter for position of msgs in the container\n\"\"\"\nFlow:\nFor every line, see if it matches the expression which is starting with the format \"number(s)+slash\" eg \"12\/\"\nIf it does, it is a new line of conversion as they begin with dates, add it to msgs container\nElse, it is a continuation of the previous line, add it to the previous line and append to msgs, then pop previous line.\n\"\"\"\nfor line in clean_chat:\n    if re.findall(\"\\A\\d+[\/]\", line):\n        msgs.append(line)\n        pos += 1\n    else:\n        take = msgs[pos-1] + \". \" + line\n        msgs.append(take)\n        msgs.pop(pos-1)\nlen(msgs) ","bfbc55b5":"msgs[0:10] #displays the top 10 messages in the chat ","dfbac646":"time = [msgs[i].split(' ')[1].split(' ,')[0] for i in range(len(msgs))]\n# split(' ') and split(',')to consider the text after date ends i.e. after dd\/mm\/yy,  and before the name of the author \n# you can change the position of the array from 0 to 1 to see how it works \n\nprint(\"length of time is:\")\nprint(len(time))\ntime\n#shows only time ","b9bbf89d":"date = [msgs[i].split(',')[0] for i in range(len(msgs))]\n#considers the text before , \nlen(date)\ndate\n#shows only date","c2bdae59":"name  = [msgs[i].split(' ')[3].split(':')[0] for i in range(len(msgs))]\n#considers the text after i.e. split(\" \") the time series ends and before the content of the message begins i.e. split(\":\")\nlen(name)\nname","157b8d37":"content = [] #list to contain the text messages\nfor i in range(len(msgs)):\n  try:\n    content.append(msgs[i].split(':')[4]) \n  except IndexError:\n    content.append('Missing Text')\nlen(content)\ncontent","8dc53150":"#merging date time name and content into our dataframe\ndf = pd.DataFrame(list(zip(date, time, name, content)), columns = ['Date', 'Time', 'Name', 'Content'])\ndf[0:40]","2ece2f79":"#these are total number of media files sent in the entire conversation and stored in a different dataframe so now we can drop \n#these noisy values from the original dataframe\nimg = df[df['Content'].str.contains('omitted>')]\nimg","ea6b32cd":"img.count()\n#total 28 media files where sent\n#let's differentiate it into who sent video, image and gif","450f916f":"plt.title(\"Histogram\")\nplt.xlabel(\"Names\")\nplt.ylabel(\"Frequency\")\n\nplt.hist(img.Name)\nplt.show()\n#turns out preeti sent the highest number of media files","9ce05d81":"img_ = df[df['Content'].str.contains('image')]\nimg_","8237bfa9":"#img_.count()\nimg_count = img_.count()\nimg_count\n#hence, out of 28 total media files, 24 of them were images","e3935d3a":"import matplotlib.pyplot as plt\nplt.title(\"Histogram\")\nplt.xlabel(\"Names\")\nplt.ylabel(\"Frequency\")\n\nplt.hist(img_.Name)\nplt.show()\n#turns out that preeti sent the highest number of images , wow preeti must really has some important media files to share","ee802fe3":"vid = df[df['Content'].str.contains('video')]\nvid\n","68d80a92":"#leaving us with only 1 gif file sent by preeti\ngif = df[df['Content'].str.contains('GIF')]\ngif","7cd4c967":"missing_text = df[df['Content'].str.contains('Missing Text')]\nmissing_text","661a2c25":"missing_text.count()\n#there are total 20 rows containing such missing text","89c039a6":"#now let's drop it\ndf.drop(df[df['Content'].str.contains('Missing Text')].index, inplace = True) \ndf","54d9e400":"df['Date'].value_counts().head(10).plot.barh() # Top 10 Dates on which the most number of messages were sent\nplt.xlabel('Number of Messages')\nplt.ylabel('Date')","59bcfb30":"df['Time'].value_counts().head(10).plot.barh() # Top 10 Time on which the most number of messages were sent\nplt.xlabel('Number of Messages')\nplt.ylabel('Time')","a7eacaa4":"df['Name'].value_counts()","78a059ea":"df['Name'].value_counts().plot.barh()","21c36037":"#texts from unknown number\nfor i in df['Name']:\n        if '+91' in i :\n            print(i)","671ae77a":"import numpy as np\ndef select_rows(df,search_strings):\n    unq,IDs = np.unique(df,return_inverse=True)\n    unqIDs = np.searchsorted(unq,search_strings)\n    return df[((IDs.reshape(df.shape) == unqIDs[:,None,None]).any(-1)).all(0)]","d375ac6a":"select_rows(df,['\u202a+91 97360 22813\u202c'])","600b4115":"#dropping media files\ndf = df.drop(img.index)","30773190":"#words and letters\ndf['Letter_Count'] = df['Content'].apply(lambda s : len(s))\ndf['Word_Count'] = df['Content'].apply(lambda s : len(s.split(' ')))\ndf.head(10)","f6169863":"columns = ['Letter_Count', 'Word_Count']\ndf[columns].describe()","5212acd0":"#wordcloud\nfrom wordcloud import WordCloud\ntext = df['Content'].values \n\nwordcloud = WordCloud().generate(str(text))\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.show()","6f288ccb":"Let's see on which date, most number of messages were recieved!","026091e2":"***What about Videos and GIFs?***","6a7772ca":"Seems like, Vishnu is the most talkative followed by Shahain and Preeti, Preeti also shares the most media files as we saw above.","af0cc25e":"I guess, the controverial gossips were spilled on 11\/1\/17 but let's dig deeper","b6b7aed7":"***What to do with the 'Missing Text'?***\n\nthese are all messages concerned with who added whom in the whatsapp chat or if anyone left the group and stored in a different dataframe\n we wont need these messages in analyzing the groupchat so we will drop these rows","d2bf541e":"Lol, it was just a happy birthday text. I was actually hoping to find something more interesting, but anyway let's move forward\n\nTo dive deeper into words and letters, lets remove the media texts from the dataframe to get accurate results","16f8720c":"1. Time","e2ac3c54":"hence, as we can see out of 28 total media files only 3 were video files\nand khushbu sent the maximum amount of video files followed by vishnu","7b9798df":"From this, we can say that the group is higly active after midnight. Let's do some more exploration!","5e330a4f":"Done, now we have to merge all those into one dataframe so its easier to look at and perform further operations.","9946417f":"4. Message","ec28c6b0":"This is it! I hope this helps, however I have not applied advanced techniques into this and tried to keep as easily understandable as it can be! If you found this helpful in any sort of way, dont forget to upvote! Thanks. <3","b1900ad6":"So, now our dataset contains messages that are either textual or media files","7bbe1963":"**Visualization**","ce3b10e0":"Maximum number of words used is as many as 1500, damn! Let's dive into more visualisations","77971704":"The length of the chat here shpws 372 instead of 477 because it doesnt consider the messages such as\n\n'[name1] added [name2]' or '[name3] left the group chat'\n","8549e8cd":"Note that, here first two are missing text because it contains messages such as 'Vishnu created this group' and 'You were added'\n\nLet's begin with the questions!","dcc356ec":"Seems like there is only one unknown number chatting in the group and we have already seen that the least amount of texts were sent from this number i.e. 1","2bc167aa":" ***How many media files were sent and by whom?***","2a1f0cac":"Okay, so now let's save TIME, DATE, SENDER NAME, MESSAGE in different array","99d90ef8":"3. Name","c685e5af":"Let's see how many Images were sent in this group","faafdf07":"2. Date"}}