{"cell_type":{"130af779":"code","7f4ebefc":"code","e21a92ab":"code","5888398e":"code","1ed7ee44":"code","3004fe88":"code","aff0cc76":"code","af994fde":"code","33ac30db":"code","67d97ce1":"code","fc1595e0":"code","9862dab1":"code","5537a132":"code","e177a060":"code","59e38235":"code","7ebddda9":"code","449c829d":"code","b0ad687c":"code","f554b274":"code","145e2d9a":"code","9f5f5857":"code","432d5ff0":"code","39d81697":"code","743c470e":"code","d5684bfd":"code","be2d52e0":"code","d78d24b6":"code","d3506bab":"code","dd5ad61c":"code","c3a4a39f":"code","9ad49aea":"code","01dc0b27":"code","d26852bc":"code","7274468f":"code","435408fb":"code","d81af5a1":"code","9813995a":"code","eccd35ce":"code","164efe39":"code","932c1698":"code","e9739dd7":"code","4895fe77":"code","dda9725a":"code","6e20e953":"code","051d4d0f":"code","93b33f03":"code","ed13ed5e":"code","f6712dff":"code","2dcd987a":"code","151573f4":"markdown","e33c1d21":"markdown","d8e1d922":"markdown","dcb50458":"markdown","cccf6ce5":"markdown","d8ba9bba":"markdown","a547514e":"markdown","e6b54efa":"markdown","6b717bdc":"markdown","56c3e21b":"markdown","9a49db62":"markdown"},"source":{"130af779":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","7f4ebefc":"###\u00a0Import Data\ntrain_data = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntest_data  = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")","e21a92ab":"print(\"train_data shape\" , train_data.shape)\nprint(\"test_data shape\" , test_data.shape)","5888398e":"train_data['train_set'] = 1\ntest_data['train_set'] = 0\ndata = pd.concat([train_data , test_data] , axis = 0 )","1ed7ee44":"data.head()","3004fe88":"print(\"Data Shape : train data + test data is \" , data.shape)","aff0cc76":"sns.heatmap(data.isna())","af994fde":"# Check the missing values\ndef Missing_values(df):\n    list_missing_values = []\n    for col in data:\n        percentage = (df[col].isna().sum()\/ df.shape[0])*100\n        list_missing_values.append((col , percentage))\n    Missing_values = pd.DataFrame(list_missing_values , columns = ['Name' , 'Percentage %'])\n    return Missing_values","33ac30db":"MISS_VAL = Missing_values(data)\nMISS_VAL[MISS_VAL['Percentage %'] > 70 ]","67d97ce1":"# Drop all columns have more than 70 % of missing values .\ndata_edit = data.drop(['Id' ,'Alley' , 'PoolQC' , 'Fence' , 'MiscFeature' ] , axis = 1)","fc1595e0":"data_edit.head()","9862dab1":"print(data_edit.shape)","5537a132":"# % of value types \nprint(data.dtypes.value_counts())\ndata.dtypes.value_counts().plot.pie()","e177a060":"def Get_Categorical_features(df):\n    for col in data.select_dtypes('object'):\n        print(f'{col :-<10} {data[col].unique()}')\n","59e38235":"# Here we can get the unique values of each column\nGet_Categorical_features(data_edit)","7ebddda9":"data_categorical = data_edit.select_dtypes('object')","449c829d":"print(\"Shape of Categorical data is :\",data_categorical.shape )\ndata_categorical.head()","b0ad687c":"for col in data_categorical:\n    plt.figure()\n    sns.countplot(y = col , data = data_categorical)\n    plt.title(col)\n    ","f554b274":"data_categorical.isna().sum()","145e2d9a":"def Fill_missing_values(data):\n    for col in data:\n        data[col] = data[col].fillna(data[col].mode()[0])\n                                     \n    \n            ","9f5f5857":"Fill_missing_values(data_categorical)\ndata_categorical.isna().sum()","432d5ff0":"data_numerical = data.select_dtypes(exclude=['object'])\ndata_numerical.head()","39d81697":"# Target variable :\nsns.distplot(data_numerical['SalePrice'])","743c470e":"data_numerical.isna().sum()","d5684bfd":"data_numerical['LotFrontage'].describe()","be2d52e0":"#\u00a0We fill values of LotFrontage with 68\ndata_numerical['LotFrontage'] = data_numerical['LotFrontage'].fillna(68)","d78d24b6":"#\u00a0We fill values of GarageYrBlt using this way :\ndiff = (data_numerical['YrSold'] - data_numerical['YearBuilt']).median()\ndata_numerical['GarageYrBlt'] = data_numerical['GarageYrBlt'].fillna(data_numerical['YrSold'] - diff)","d3506bab":"for col in data_numerical:\n    data_numerical[col] = data_numerical[col].fillna(data_numerical[col].mode()[0])","dd5ad61c":"data_numerical.loc[: , ['YearBuilt'  , 'YearRemodAdd' , 'YrSold' ]]\ndata_numerical['House_Age'] = data_numerical['YrSold'] - data_numerical['YearBuilt']\ndata_numerical['Remod_First_Age'] = data_numerical['YearRemodAdd'] - data_numerical['YearBuilt']","c3a4a39f":"def State_Feature(Remod_First_Age) : \n    if (Remod_First_Age < 10):\n        return 3\n    elif (Remod_First_Age >= 10) & (Remod_First_Age < 30):\n        return 2\n    elif (Remod_First_Age >= 30) & (Remod_First_Age < 100):\n        return 1\n    else:\n        return 0\n","9ad49aea":"data_numerical['State'] = data_numerical['Remod_First_Age'].apply(lambda x : State_Feature(x))","01dc0b27":"data_numerical[data_numerical['House_Age'] < 0] \nprint(data_numerical[data_numerical['House_Age'] < 0]['YrSold'])\nprint(data_numerical[data_numerical['House_Age'] < 0]['YearBuilt'])","d26852bc":"data_numerical.loc[data_numerical['House_Age'] < 0, ['YrSold']] = 2008","7274468f":"data_categorica_encoding = pd.get_dummies(data_categorical , drop_first= True)","435408fb":"data_final = pd.concat([data_categorica_encoding , data_numerical] , axis = 1 , sort = False)","d81af5a1":"# divide the data_final to train and test data :\ntrain_data_final = data_final[data_final['train_set'] == 1]\ntest_data_final = data_final[data_final['train_set'] == 0]","9813995a":"train_data_final.head()\ny = train_data_final['SalePrice']\ntrain_data_final.drop(['SalePrice' , 'train_set'] , axis = 1 , inplace = True)\ntest_data_final.drop(['SalePrice' , 'train_set'] , axis = 1 , inplace = True)\n","eccd35ce":"import xgboost as xgb\nfrom sklearn.model_selection import train_test_split , RandomizedSearchCV ","164efe39":"model = xgb.XGBRegressor()\nmodel","932c1698":"booster=['gbtree','gblinear']\nbase_score=[0.25,0.5,0.75,1 ,1.25]\nmax_depth = [2, 3 , 5 ,7 , 9 , 11 ,15]\nn_estimators = [100, 500, 800, 1200, 1500]\nlearning_rate=[0.05,0.1,0.15,0.20 , 0.25 , 0.30]\nmin_child_weight=[1,2,3,4,5]\n\nparams_grid = {\n    'booster' : booster ,\n    'base_score' : base_score , \n    'max_depth' : max_depth , \n    'n_estimators' : n_estimators ,\n    'learning_rate' : learning_rate , \n    'min_child_weight' : min_child_weight\n}\n","e9739dd7":"RSCV_model = RandomizedSearchCV(\n            estimator=model,\n            param_distributions=params_grid,\n            cv=5, n_iter=60,\n            scoring = 'neg_mean_absolute_error',\n            n_jobs = 4,\n            verbose = 5, \n            return_train_score = True,\n            random_state=42 )","4895fe77":"X_train , X_test , y_train , y_test = train_test_split(train_data_final.values , y.values , test_size = 0.3 ,\n                                                       random_state = 42)","dda9725a":"RSCV_model.fit(X_train , y_train )","6e20e953":"RSCV_model.best_estimator_","051d4d0f":"XGB_Regressor = RSCV_model.best_estimator_\nXGB_Regressor.fit(X_train , y_train)","93b33f03":"test_data_final","ed13ed5e":"y_pred = XGB_Regressor.predict(test_data_final.values)","f6712dff":"Submission = pd.DataFrame(\n{\n    \"ID\" : test_data_final['Id'] ,\n    'SalePrice' : y_pred\n})","2dcd987a":"Submission.to_csv('Submission.csv' , index = False)","151573f4":"# <h3 style=\"color:blue;\"> Conclusion <\/h3>\nWe have concatenated train and test data in order to have more informations . ","e33c1d21":"# <h1 style=\"color:red;\"> IV - MODELISATION <\/h1>","d8e1d922":"# <h2 style=\"color:green;\"> 2 - Numerical Features <\/h2>","dcb50458":"<h5>With Count Plots , we can have an idea how we can fill miss values . <\/h5>","cccf6ce5":"# <h1 style=\"color:red;\"> II- DATA PREPROCESSING <\/h1>","d8ba9bba":"<h1 style=\"color:red;\"> I- DATA UNDERSTUNDING<\/h1>","a547514e":"<h3>Encoding : <\/h3>","e6b54efa":"<h3 style=\"color:blue;\"> Conclusion <\/h3>\n- Enconding with dummies variables <br><\/br> \n- Separating data into train and test to begin our modelisation\n","6b717bdc":"# <h1 style=\"color:red;\"> III - EXPLORATORY DATA ANALYTICS <\/h1>","56c3e21b":"# <h3 style=\"color:blue;\"> Conclusion <\/h3>\nChecking missing data is one of the important tasks in a model of ML : <br><\/br>\nWe have deleted all features with % of missing values > 70% ( depending on the model ) ","9a49db62":"# <h2 style=\"color:green;\"> 1 - Categorical Features <\/h2>"}}