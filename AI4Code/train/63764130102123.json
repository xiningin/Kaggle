{"cell_type":{"f31acf0a":"code","c69a342f":"code","06fb25a7":"code","712a28a1":"code","ea1e9329":"code","dc8136e1":"code","aed38657":"code","b28d34a6":"code","aa4e53ad":"code","1f8bdf86":"code","bf8a1384":"code","92e5687d":"code","e44e8fc2":"code","900294f7":"code","ca9accbb":"code","b796fe42":"code","75fd377e":"code","ef24ddd1":"code","8f092c1e":"code","235ccae2":"code","c769e7e8":"code","827265c7":"code","6923ae32":"code","87eebb15":"code","2286aa4f":"code","534c9dab":"code","8e3ab190":"code","de6a0f70":"code","28ff16fc":"code","f77a4ec0":"code","b110f245":"code","7f101d76":"code","d27236d5":"code","9de534b1":"code","988d7cea":"code","4e95d2be":"code","48e80fad":"code","d44115c4":"code","b7fddfcd":"code","7e285e8d":"code","1782856b":"code","7e70cbda":"code","80148876":"code","a012adcc":"markdown","81e28bd6":"markdown","c3a36e9f":"markdown","739fec4a":"markdown","eaec3302":"markdown","d71214bf":"markdown","77d49cba":"markdown","c6d0e4a6":"markdown","2e8a6245":"markdown","385788c7":"markdown","3f0847b4":"markdown","e1729870":"markdown","7df8f690":"markdown","7f3589c6":"markdown","8b9decd3":"markdown","7732ebff":"markdown","84d1a64f":"markdown","222fca26":"markdown","befffc0d":"markdown","5fd3ddb0":"markdown","b7a5befa":"markdown","5a84f2f7":"markdown","866ec459":"markdown","cb95eb42":"markdown","2de30c12":"markdown","a3df07fe":"markdown","6f43d41b":"markdown","c6648206":"markdown","9fa8c260":"markdown"},"source":{"f31acf0a":"# Importing necessary packages \n\nimport numpy as np \nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","c69a342f":"twitter = pd.read_csv('..\/input\/twitter-user-gender-classification\/gender-classifier-DFE-791531.csv',encoding='latin-1')\ntwitter.head()","06fb25a7":"twitter.shape","712a28a1":"twitter.describe()","ea1e9329":"twitter.info()","dc8136e1":"twitter.columns","aed38657":"twitter.isnull().sum()","b28d34a6":"twitter['tweet_count'].value_counts()","aa4e53ad":"twitter['retweet_count'].value_counts()","1f8bdf86":"sns.barplot (x = 'gender', y = 'tweet_count',data = twitter)","bf8a1384":"sns.barplot (x = 'gender', y = 'retweet_count',data = twitter)","92e5687d":"# Visualizing null values to get a better idea of the dataset & it's trends\n\nplt.subplots(figsize=(15,15))\nsns.heatmap(twitter.isnull(), cbar=False)","e44e8fc2":"#Dropping irrelevant columns from dataset\n\ntwitter = twitter.drop(['_unit_id', '_golden', '_unit_state', '_last_judgment_at', 'gender:confidence', 'profile_yn', 'profile_yn:confidence', \n                        'created', 'fav_number', 'gender_gold', 'name', 'profile_yn_gold', 'profileimage', 'retweet_count', \n                        'tweet_coord', 'tweet_count', 'tweet_created', 'tweet_id', 'tweet_location', 'user_timezone', \n                        '_trusted_judgments'], axis = 1)","900294f7":"twitter.head()","ca9accbb":"twitter['gender'].count()","b796fe42":"twitter['gender'].value_counts(dropna=False) ","75fd377e":"sns.countplot(twitter['gender'],label=\"Gender\")","ef24ddd1":"# dropping all the null values from 'gender'\n\ntwitter = twitter.dropna(subset=['gender'],how ='any')  \ntwitter.head()","8f092c1e":"# Merging the 'text' & 'description' to combine all sorts of text and then find out common words\n\ntwitter['text_description'] = twitter['text'].str.cat(twitter['description'], sep=' ')","235ccae2":"twitter = twitter.drop(['description','text'],axis=1)","c769e7e8":"twitter.head()","827265c7":"# Junk words & letters other than the English vocab words are filtered out\nimport re\ndef cleaning(s):\n    s = str(s)\n    s = s.lower()\n    s = s.replace(\",\",\"\")\n    s = re.sub('[!@#$_]', '', s)\n    s = re.sub('\\W,\\s',' ',s)\n    s = re.sub(r'[^\\w]', ' ', s)\n    s = re.sub('\\s\\W',' ',s)\n    s = re.sub(\"\\d+\", \"\", s)\n    s = re.sub('\\s+',' ',s)\n    s = s.replace(\"co\",\"\")\n    s = s.replace(\"https\",\"\")\n    s = s.replace(\"[\\w*\",\" \")\n    return s\n\ntwitter['text_description'] = [cleaning(s) for s in twitter['text_description']]\ntwitter.head()","6923ae32":"from collections import Counter\nwords = Counter()\nfor twit in twitter['text_description']:\n    for x in twit.split(' '):\n        words[x] += 1\n\nwords.most_common(20)","87eebb15":"# Filtering out 'text_description' and printing most commonly used words by elimination stopwords\n\nfrom nltk.corpus import stopwords\nstopwords = stopwords.words('english')\nwords_filtered = Counter()\nfor x, y in words.items():\n    if not x in stopwords:\n        words_filtered[x]=y\n\nwords_filtered.most_common(20)","2286aa4f":"# This will clear out the rest of the remaining junk\n\nimport re\ndef preprocessor(text_description):\n    text_description = re.sub(\"[^a-zA-z]\", \" \",text_description)\n    text_description = re.sub('<[^>]*>', '', text_description)\n    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text_description)\n    text_description = (re.sub('[\\W]+', ' ', text_description.lower()) + ' ' + ' '.join(emoticons).replace('-', ''))\n    return text_description","534c9dab":"from nltk.stem import PorterStemmer\n\nporter = PorterStemmer()\n\ndef tokenizer(text_description): #tokenizer to break down our twits in individual words\n    return text_description.split()\n\ndef tokenizer_porter(text_description):\n    return [porter.stem(word) for word in text_description.split()]","8e3ab190":"twitter.text_description\n","de6a0f70":"male_sidebar_color = twitter[twitter['gender'] == 'male']['sidebar_color'].value_counts().head(7)\nmale_sidebar_color_idx = male_sidebar_color.index\nmale_top_color = male_sidebar_color_idx.values\n\nmale_top_color[2] = '000000'\nprint (male_top_color)\n\nl = lambda x: '#'+x\n\nsns.set_style(\"darkgrid\")\nsns.barplot (x = male_sidebar_color, y = male_top_color) ","28ff16fc":"female_sidebar_color = twitter[twitter['gender'] == 'female']['sidebar_color'].value_counts().head(7)\nfemale_sidebar_color_idx = female_sidebar_color.index\nfemale_top_color = female_sidebar_color_idx.values\n\nfemale_top_color[2] = '000000'\nprint (female_top_color)\n\nl = lambda x: '#'+x\n\nsns.set_style(\"darkgrid\")\nsns.barplot (x = female_sidebar_color, y = female_top_color)","f77a4ec0":"male_link_color = twitter[twitter['gender'] == 'male']['link_color'].value_counts().head(7)\nmale_link_color_idx = male_link_color.index\nmale_top_color = male_link_color_idx.values\nmale_top_color[1] = '009999'\nmale_top_color[5] = '000000'\nprint(male_top_color)\n\nl = lambda x: '#'+x\n\nsns.set_style(\"whitegrid\", {\"axes.facecolor\": \"white\"})\nsns.barplot (x = male_link_color, y = male_link_color_idx)","b110f245":"female_link_color = twitter[twitter['gender'] == 'female']['link_color'].value_counts().head(7)\nfemale_link_color_idx = female_link_color.index\nfemale_top_color = female_link_color_idx.values\n\nl = lambda x: '#'+x\n\nsns.set_style(\"whitegrid\", {\"axes.facecolor\": \"white\"})\nsns.barplot (x = female_link_color, y = female_link_color_idx, palette=list(map(l, female_top_color)))","7f101d76":"# The frequency of the words will be helpful in classifying the gender of the users.\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n# Setting up training and testing data \nencoder = LabelEncoder()\ny = encoder.fit_transform(twitter['gender'])\nX = twitter['text_description']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)","d27236d5":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import accuracy_score\n\ntfidf = TfidfVectorizer(lowercase=False,\n                        tokenizer=tokenizer_porter)\nclf = Pipeline([('vect', tfidf),\n                ('clf', LogisticRegression(multi_class='ovr', random_state=0))])\n\nclf.fit(X_train, y_train)\n\npredictions = clf.predict(X_test)\nprint('Accuracy:',accuracy_score(y_test,predictions))","9de534b1":"from sklearn.ensemble import RandomForestClassifier\n\nn = range (1,100,10)\n\ntfidf = TfidfVectorizer(lowercase=False,\n                        tokenizer=tokenizer_porter)\nclf = Pipeline([('vect', tfidf),\n                ('clf', RandomForestClassifier(n_estimators = 40, random_state=0))])\n\nclf.fit(X_train, y_train)\n\npredictions = clf.predict(X_test)\nprint('Accuracy:',accuracy_score(y_test,predictions))","988d7cea":"from sklearn.svm import SVC\n\ntfidf = TfidfVectorizer(lowercase=False,\n                        tokenizer=tokenizer_porter)\nclf = Pipeline([('vect', tfidf),\n                ('clf', SVC(kernel = 'linear'))])\n\nclf.fit(X_train, y_train)\n\npredictions = clf.predict(X_test)\nprint('Accuracy:',accuracy_score(y_test,predictions))","4e95d2be":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nencoder = LabelEncoder()\ny = encoder.fit_transform(twitter['gender'])\nX = twitter['sidebar_color']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)","48e80fad":"from sklearn.linear_model import LogisticRegression\n\ntfidf = TfidfVectorizer(lowercase=False,\n                        tokenizer=tokenizer_porter)\nclf = Pipeline([('vect', tfidf),\n                ('clf', LogisticRegression(multi_class='ovr', random_state=0))])\n\nclf.fit(X_train, y_train)\n\npredictions = clf.predict(X_test)\nprint('Accuracy:',accuracy_score(y_test,predictions))","d44115c4":"from sklearn.ensemble import RandomForestClassifier\n\nn = range (1,100,10)\n\ntfidf = TfidfVectorizer(lowercase=False,\n                        tokenizer=tokenizer_porter)\nclf = Pipeline([('vect', tfidf),\n                ('clf', RandomForestClassifier(n_estimators = 40, random_state=0))])\n\nclf.fit(X_train, y_train)\n\npredictions = clf.predict(X_test)\nprint('Accuracy:',accuracy_score(y_test,predictions))","b7fddfcd":"from sklearn.svm import SVC\n\ntfidf = TfidfVectorizer(lowercase=False,\n                        tokenizer=tokenizer_porter)\nclf = Pipeline([('vect', tfidf),\n                ('clf', SVC(kernel = 'linear'))])\nclf.fit(X_train, y_train)\n\npredictions = clf.predict(X_test)\nprint('Accuracy:',accuracy_score(y_test,predictions))","7e285e8d":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nencoder = LabelEncoder()\ny = encoder.fit_transform(twitter['gender'])\nX = twitter['link_color']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)","1782856b":"from sklearn.linear_model import LogisticRegression\n\ntfidf = TfidfVectorizer(lowercase=False,\n                        tokenizer=tokenizer_porter)\nclf = Pipeline([('vect', tfidf),\n                ('clf', LogisticRegression(multi_class='ovr', random_state=0))])\n\nclf.fit(X_train, y_train)\n\npredictions = clf.predict(X_test)\nprint('Accuracy:',accuracy_score(y_test,predictions))","7e70cbda":"from sklearn.ensemble import RandomForestClassifier\n\nn = range (1,100,10)\n\ntfidf = TfidfVectorizer(lowercase=False,\n                        tokenizer=tokenizer_porter)\nclf = Pipeline([('vect', tfidf),\n                ('clf', RandomForestClassifier(n_estimators = 40, random_state=0))])\n\nclf.fit(X_train, y_train)\n\npredictions = clf.predict(X_test)\nprint('Accuracy:',accuracy_score(y_test,predictions))","80148876":"from sklearn.svm import SVC\n\ntfidf = TfidfVectorizer(lowercase=False,\n                        tokenizer=tokenizer_porter)\nclf = Pipeline([('vect', tfidf),\n                ('clf', SVC(kernel = 'linear'))])\nclf.fit(X_train, y_train)\n\npredictions = clf.predict(X_test)\nprint('Accuracy:',accuracy_score(y_test,predictions))","a012adcc":"#### Modelling for SVM(sidebar_color) >>>","81e28bd6":"#### Modelling on SVM >>>","c3a36e9f":"#### __Lemmatization__\nFor reducing our vocabulary and consolidate words to their roots, we'll use __stemming \/ Lemmatizing__ \nWe will be using __Porter algorithm__ for stemming\n","739fec4a":"These are the number of most common stopwords used in the whole dataset\nThese words are considered 'noise' which can be eliminated","eaec3302":"#### Modelling on Logistic Regression >>>","d71214bf":"## Training for Text :","77d49cba":"#### Side bar color >>>","c6d0e4a6":"As by observing the above representations\nWe will reduce down to only the following columns which are required for ML algorithm implimentation :\n\n   1. 'gender'\n   2. 'link_color'\n   3. 'sidebar_color'\n   4. 'text'\n   4. 'description'\n","2e8a6245":"There is still some trash to clear out such as HTML tags, emojis & unfinished words","385788c7":"### __Experimental Results__\n\nAccuracy for 'sidebar_color':\n\n    Logistic Regression: 37.71%\n    Random Forest: 37.62%\n    SVM: 37.77%\n\n## <u>Winner: __SVM__ model<\/u>\n\nAccuracy for 'link_color':\n\n    Logistic Regression: 40.34%\n    Random Forest: 40.47%\n    SVM: 40.36%\n\n## <u>Winner: __Random Forest__ model<\/u>\n\n\n","3f0847b4":"#### As seen from plots displayed above, most users have not changed the default color of their profile, but if these are discarded, then there is significant dataset to be used for classification.\n\n## <u>__Answer 2__ : The most primiarly used color for both 'sidebar' & 'link color' is Blue followed by Orange and the rest of them. <\/u>","e1729870":"### __Color attribute analysis :__","7df8f690":"## __Preliminary Data Assessment__","7f3589c6":"### __Text Analysis :__","8b9decd3":"### Text cleaning\nIn this phase, we will filtering out text and perform other functions like Normalizing, Lemmatizing etc","7732ebff":"## __Problem Statement:__\n\nFor the given dataset, perform EDA with visualization, I'll formulate 2 questions on the given data and answer the same. Then proceed to to build an ensemble classifier using 3 ML algorithms and find out which algorithm best suits the dataset with respect to the accuracy of the algorithm.\n#### __Procedure:__\n\n   1. The dataset is to be analysed and preliminary data cleaning is to be done.\n   2. Data exploration and feature engineering are to done for fine tuning of dataset.\n   3. ML modelling and accuracy checking to find the optimal algorithm for the dataset.\n\n\n#### __Questions to be answered at the end of EDA:__\n   1. Text analysis based on common words used by Males & Females ?\n   2. How significant are the color attributes used by the users ?\n\n","84d1a64f":"#### Link color >>>","222fca26":"#### Modelling on Random Forest >>>","befffc0d":"## __Data Exploration & Feature Engineering__\nHere we are going to explore the relationships of the independent and dependent variables, modify the features and look for anomalies to present a better dataset for the ML models.","5fd3ddb0":"## <u>__Answer 1__ : The most used words by the users are words like Love, Like, Life, Time etc <\/u>","b7a5befa":"## Training for color attributes :","5a84f2f7":"#### Modelling for SVM(link_color) >>>","866ec459":"#### Modelling on Logistic Regression(sidebar_color) >>>","cb95eb42":"## __Training & Testing of ML algorithms__\nThe following classifiers have been chosen for training on the dataset :-\n\n    1. Logistic Regression\n    2. Random forest\n    3. SVM Classifier\n\nThe ML algorithms are trained on each feature of the dataset and the algorithm with the maximum accuracy is the most optimal model for this dataset and the feature that gives maximum accuracy is the optimal feature for classification of this data.","2de30c12":"#### Modelling for Random Forest(sidebar_color) >>>","a3df07fe":"#### Removing __Stop words__ from 'text_description'","6f43d41b":"#### Modelling for Random Forest(link_color) >>>","c6648206":"### __Experimental Results__\n\nAccuracy:\n\n    Logistic Regression: 57.90%\n    Random Forest: 53.92%\n    SVM: 57.85%\n\n## <u>Winner: __Logistic Regression__ model<\/u>\n","9fa8c260":"#### Modelling on Logistic Regression(link_color) >>>"}}