{"cell_type":{"e5c127ac":"code","b29c6f9d":"code","0f6d926b":"code","d38dcb8b":"code","aedf83be":"code","d76becaf":"code","a99d1230":"code","e344747f":"code","a5e17e76":"code","adbac1e1":"code","ff9e51dd":"code","1cf8fd7d":"code","5a23b372":"code","bc258260":"code","3d63ce1e":"markdown","a5e5cfed":"markdown","0038a602":"markdown","06580f23":"markdown","4eb9c9cc":"markdown","ba2a9ea8":"markdown","3d24fb8c":"markdown","c19e92e4":"markdown","0ac106af":"markdown"},"source":{"e5c127ac":"%matplotlib inline\nfrom functools import reduce\nimport pandas as pd\nimport numpy as np\nimport re\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import recall_score,precision_score,f1_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom IPython.core.display import display, HTML","b29c6f9d":"# read a list of 200 common drugs\ndrugs = pd.read_html('https:\/\/clincalc.com\/DrugStats\/Top200Drugs.aspx')[0]\n# add known interesting theraputics\npromising = pd.Series(['chloroquine','hydrochloroquine','remdesivir','quercetin']).to_frame()\npromising.columns =  ['Drug Name']\npromising['Rank'] = np.nan\npromising['Total Prescriptions (2017)'] = np.nan\npromising['Annual Change'] = np.nan\ndrugs = drugs.append(promising,ignore_index=True,sort=False)","0f6d926b":"drugs.head()","d38dcb8b":"metadata = pd.read_csv('\/kaggle\/input\/CORD-19-research-challenge\/metadata.csv')\ndisplay(HTML(f'meta data shape: {metadata.shape}'))\nhas_abstract = metadata.abstract.apply(lambda x: str(x)!='nan')\nmetadata = metadata.iloc[has_abstract.values,:]\ndisplay(HTML(f'meta data shape after dropping docs without abstracts: {metadata.shape}'))\nmetadata.head(n=2).transpose()","aedf83be":"def has_word(text_string,filter_words):\n    def has_this_word(has_one,word):\n        if has_one:\n            return True\n        else:\n            if word in text_string:\n                return True\n            else:\n                return False\n    return reduce(has_this_word,filter_words,False)\n\nFILTER_WORDS = ['SARS','MERS','corona','Cov','COV'] #keyword strings used to filter titles\n\n# filter to titles with covid words\nhave_filter_word = metadata.abstract.apply(lambda x: has_word(x,FILTER_WORDS)) \nmetadata_has_corona = metadata[have_filter_word]\n\n# filter to drug words\nhave_filter_word = metadata.abstract.apply(lambda x: has_word(x,drugs['Drug Name']))  \nmetadata_has_drug = metadata[have_filter_word]\n\n# filter to theraputics\ntheraputic_words = ['anti-viral','antiviral']\nhave_filter_word = metadata.abstract.apply(lambda x: has_word(x,theraputic_words))  \nmetadata_has_theraputic = metadata[have_filter_word]\n\n# filter for antivirals and arb_blockers\ndef regex_search(string,pattern):\n    return True if re.search(pattern,string) else False\n\nhave_filter_word = metadata.abstract.apply(lambda x: regex_search(x,'[a-zA-Z]+vir ')) \nmetadata_has_antiviral = metadata[have_filter_word]\n\n# filter for arb blockers\nhave_filter_word = metadata.abstract.apply(lambda x: regex_search(x,'[a-zA-Z]+sartan ')) \nmetadata_has_arb_blocker = metadata[have_filter_word]\n\n","d76becaf":"#build positives\nX1 = metadata_has_drug.append(metadata_has_antiviral)\nX2 = X1.append(metadata_has_arb_blocker)\n\n#build negatives \nnegatives_index = np.random.choice(metadata.index,size=1000,replace=False)\nnegatives_index = [x for x in negatives_index if x not in X2.index]\nX = X2.append(metadata.loc[negatives_index]).abstract\n\n# build ground truth\ny = pd.Series([1]*len(X2) + [0]*(len(X) - len(X2)))\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\ntfidf = TfidfVectorizer(ngram_range=(1,1),stop_words='english',max_df=.75,min_df=1)\nbow = pd.DataFrame((tfidf.fit_transform(X_train).todense()))\ndisplay(HTML( f'Bag of Words shape {bow.shape}'))\n\nrf = RandomForestClassifier(n_estimators=300,\n    min_samples_leaf=5,\n    oob_score=True)\nrf.fit(bow,y_train)\ndisplay(HTML(f'RandomForest Out-of-Bag Score: {rf.oob_score_}'))","a99d1230":"bow_test = pd.DataFrame((tfidf.transform(X_test).todense()))\ny_prob = rf.predict_proba(bow_test)[:,1]\ny_pred = [1 if x > .5 else 0 for x in y_prob]\n_ = plt.hist(y_prob[y_test==1],bins=20,label='Positives',alpha=.5)\n_ = plt.hist(y_prob[y_test==0],bins=20,label='Negatives',alpha=.5)\nplt.legend(loc='upper right')\n_ = plt.title('Class Probability Distribution')\nplt.gcf().set_size_inches((8,5))","e344747f":"thresh = .5  # adjust to tune precision, recall\ny_pred = pd.Series([1 if x > thresh else 0 for x in y_prob])\ndisplay(HTML('Confusion Matrix' ))\ndisplay_df = pd.DataFrame(confusion_matrix(y_test,y_pred))\ndisplay_df.columns = ['Predicted 0','Predicted 1']\ndisplay_df.index = ['True 0','True 1']\ndisplay(HTML(display_df.to_html()))","a5e17e76":"display(HTML(f'Recall {recall_score(y_test,y_pred)}'))\ndisplay(HTML(f'Precision {precision_score(y_test,y_pred)}'))\n","adbac1e1":"bow_covid = tfidf.transform(metadata_has_corona.abstract)\ny_prob = rf.predict_proba(bow_covid)[:,1]\ny_pred = [True if x > thresh else False for x in y_prob]\ndisplay(HTML( f'Bag of Words shape {bow_covid.shape}'))","ff9e51dd":"def print_sample(docs,n=20):\n    for d in docs[0:n]:\n        print(d + '\\n')\n\nprint_sample(metadata_has_corona.abstract.loc[y_pred])","1cf8fd7d":"display(HTML(f'Found {np.sum(y_pred)} papers'))","5a23b372":"df_s = metadata_has_corona.loc[y_pred,['title','abstract','doi']]\n#convert to html\ndf_s['title'] = '<span style=\"float: left; width: 100%; text-align: left;\">' + df_s['title'] + '<\/span>'\ndf_s['abstract'] = '<span style=\"float: left; width: 80%; text-align: left;\">' + df_s['abstract'] + '<\/span>'\ndf_s['doi'] = '<a href = \"https:\/\/doi.org' + df_s['doi'] + '\" target=\"_blank\">link<\/a>'\nresult = HTML(df_s.to_html(escape=False))\ndisplay(result)\ndisplay(HTML(\"<style>div.output_scroll { height: 44em; }<\/style>\"))","bc258260":"# Save file\nmetadata_has_corona.loc[y_pred].to_csv('\/kaggle\/working\/theraputics_compounds_alh.csv')","3d63ce1e":"### Read the Covid-19 dataset metadata","a5e5cfed":"## Ideas for further work\n\n* increase training set size\n* improve text preprocessing e.g add stemming, elimnate noise e.g standalone numbers\n* rerun classifier on most important features\n* try other classifiers. e.g. FastText\n* summarize key findings\n* show stats on drugs e.g. number of mentions\n\n","0038a602":"### Display papers classified as showing therapeutic efforts\n\n\nThese are availables as as csv file as well","06580f23":"## What Treatments Are Being Tried?\n\nAssociated with the task: 'What do we know about therapeutics?' is the specific subtask:\n'Clinical and bench trials to investigate less common viral inhibitors against COVID-19 such as naproxen, clarithromycin, and minocyclinethat that may exert effects on viral replication'.\n\nThis notebook uncovers two to three hundred papers detailing treatment efforts with specific drugs and compounds.\n\n### Methodology\n\nWe used a RandomForest Classifier to classify documents as relevant to the task above.  First a train,test data set was built utilizing abstracts containing drug and antiviral names.  After training, the classifier achieved precision of 84% and recall of 82%.  Sample reading of the final output shows similar precision.\n\nThe articles are displayed interactively below with links and a separate csv file is available for download.","4eb9c9cc":"### List of 200 common drugs with Covid-19 specific additions","ba2a9ea8":"### Examine classifier performance","3d24fb8c":"### Sample output for quality review\nReadings of several samples of 20 docs shows precision consistent with the test set precision score.","c19e92e4":"###  Classify COVID papers","0ac106af":"## Build the train, test sets and train classifier"}}