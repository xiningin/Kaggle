{"cell_type":{"bffaa784":"code","850e7dd9":"code","410e5ef9":"code","afbf7458":"code","9155e185":"code","21d29eb6":"code","dd9464bc":"code","cbae7138":"code","c4813d8d":"code","6adba110":"code","b02bc9e6":"code","d5f0670f":"code","1f73cafc":"code","86d7e4e9":"code","1ccbe36c":"code","2bfb8a6c":"code","49835c40":"code","b61b7e80":"markdown"},"source":{"bffaa784":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport time\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","850e7dd9":"#importing all the packages\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import models, datasets, transforms\nfrom torch.autograd import Variable\nfrom torch.utils.data.sampler import SubsetRandomSampler","410e5ef9":"data_dir = \"..\/input\/car_data\/car_data\/\"\n# names = \"..\/input\/names.csv\"\n# annoTrain = \"..\/input\/anno_train.csv\"\n# anno = pd.read_csv(annoTrain)\n# anno.head()","afbf7458":"# Transform the image (scaling, flipping and normalisation)\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize(255),\n        transforms.RandomRotation(30),\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(20),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], \n                             [0.229, 0.224, 0.225])\n    ]),\n    'test': transforms.Compose([\n        transforms.Resize(255),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], \n                             [0.229, 0.224, 0.225])\n    ]),\n}\n\n\n# image_datasets = {x: datasets.ImageFolder(data_dir, data_transforms[x])\n#                   for x in ['train', 'valid']}\n\n# #info about no. of datapoints\n# image_datasets","9155e185":"valid_size = 0.2\nbatch_size = 64\n\ndataset = torchvision.datasets.ImageFolder(root=data_dir+\"train\", transform = data_transforms['train'])\ntrainloader = torch.utils.data.DataLoader(dataset, batch_size = 32, shuffle=True, num_workers = 2)\n\ndataset2 = torchvision.datasets.ImageFolder(root=data_dir+\"test\", transform = data_transforms['test'])\ntestloader = torch.utils.data.DataLoader(dataset2, batch_size = 32, shuffle=False, num_workers = 2)\nprint(len(trainloader), len(testloader))","21d29eb6":"# pd_names = pd.read_csv(names)\n# print(pd_names.shape) # number of target output classes\n# pd_names","dd9464bc":"def show(image):\n    if isinstance(image, torch.Tensor):\n        image = image.numpy().transpose((1, 2, 0))\n    else:\n        image = np.array(image).transpose((1, 2, 0))\n    # denormalisation\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    image = std * image + mean\n    image = np.clip(image, 0, 1)\n    # plot\n    fig, Xaxis = plt.subplots(1, 1, figsize=(9, 9))\n    %matplotlib inline\n    plt.imshow(image)\n    Xaxis.axis('off') ","cbae7138":"# Make a grid from batch (for training data)\n# This grid shows the images which are present in 1 batch\nimages, _ = next(iter(trainloader))\n#print(train_loader.dataset.targets)\ntrainGrid = torchvision.utils.make_grid(images, nrow=8)\n\nshow(trainGrid)","c4813d8d":"# Make a grid from batch (for validation\/test data)\nimages, _ = next(iter(testloader))\ntestGrid = torchvision.utils.make_grid(images, nrow=8)\n\nshow(testGrid)","6adba110":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","b02bc9e6":"# Use GPU if it's available\n\nmodel = models.resnet34(pretrained=True)\n\n# Freeze parameters so we don't backprop through them\n# for param in model.parameters():\n#     param.requires_grad = False\n    \nmodel.fc = nn.Linear(512, 196)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)\nmodel.to(device)","d5f0670f":"def train(model, trainloader, testloader, criterion, optimizer, scheduler, epochs=5):\n  \n    losses = []\n    accuracies = []\n    test_accuracies = []\n    # set the model to train mode initially\n    model.train()\n    for epoch in range(epochs):\n        since = time.time()\n        running_loss = 0.0\n        running_correct = 0.0\n        for i, data in enumerate(trainloader, 0):\n\n            # get the inputs and assign them to cuda\n            inputs, labels = data\n            #inputs = inputs.to(device).half() # uncomment for half precision model\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            optimizer.zero_grad()\n            \n            outputs = model(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            # calculate the loss\/acc later\n            running_loss += loss.item()\n            running_correct += (labels==predicted).sum().item()\n\n        epoch_duration = time.time()-since\n        epoch_loss = running_loss\/len(trainloader)\n        epoch_acc = 100\/32*running_correct\/len(trainloader)\n        print(\"Epoch %s, duration: %d s, loss: %.4f, acc: %.4f\" % (epoch+1, epoch_duration, epoch_loss, epoch_acc))\n        \n        losses.append(epoch_loss)\n        accuracies.append(epoch_acc)\n        \n        # switch the model to eval mode to evaluate on test data\n        model.eval()\n        \n        test_acc = validation(model, testloader, criterion)\n        test_accuracies.append(test_acc)\n        \n        # re-set the model to train mode after validating\n        model.train()\n        scheduler.step(test_acc)\n        since = time.time()\n#         print(scheduler.get_lr())\n    print('Finished Training')\n    return model, losses, accuracies, test_accuracies\n                \n                # Make sure dropout and grads are on for training\n#             model.train()    \n\ndef validation(model, testloader, criterion):\n  \n    correct = 0.0\n    total = 0.0\n    with torch.no_grad():\n        for i, data in enumerate(testloader, 0):\n            images, labels = data\n            #images = images.to(device).half() # uncomment for half precision model\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            \n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    test_acc = 100.0 * correct \/ total\n    print('Accuracy of the network on the test images: %d %%' % (\n        test_acc))\n    return test_acc","1f73cafc":"submit = pd.read_csv('..\/input\/sampleSubmission.csv')\nsubmit.head()","86d7e4e9":"# uncomment these two lines when you want to re-train\n\ntrain(model, trainloader, testloader, criterion, optimizer, scheduler, epochs=20)\n# validation(model, valid_loader, criterion)","1ccbe36c":"model.eval()\npredict = []\nfor batch_i, (data, target) in enumerate(testloader):\n    data, target = data.to(device), target.to(device)\n    output = model(data)\n    print(data)\n    pr = output[:,1].detach().cpu().numpy()\n    for i in pr:\n        predict.append(i)\n\nsubmit['Predicted'] = predict\nsubmit.to_csv('submission.csv', index=False)\nsubmit.head()\n    \n            ","2bfb8a6c":"len(predict)","49835c40":"submit","b61b7e80":"## Training the model"}}