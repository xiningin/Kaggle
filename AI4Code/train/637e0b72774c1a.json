{"cell_type":{"a25c54a2":"code","c1b86c75":"code","c4227252":"code","ce15b0a0":"code","27628dba":"code","f0c21c7f":"code","4c3817a4":"code","80fa320b":"code","e1d512f9":"code","2eb1724b":"code","7c78f790":"code","f1b2d366":"code","fa26f95d":"code","2618e5f6":"code","e7490aff":"code","497f90a9":"code","b40f48d7":"code","c0a51bc0":"code","5465726a":"markdown","142b8b50":"markdown","06e95c8b":"markdown","9abe540e":"markdown","de6da82c":"markdown","c7335c5b":"markdown","a6cbd6a4":"markdown","f079ef30":"markdown","5bc3f84d":"markdown","b3b10406":"markdown","b3398a37":"markdown","73f8f85e":"markdown","128e51c5":"markdown","890d81ad":"markdown","d87bf8c2":"markdown","d0af0186":"markdown","a621a01e":"markdown","95b5d9dc":"markdown"},"source":{"a25c54a2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c1b86c75":"from torchvision import datasets,transforms\n#root_dir = \"\/kaggle\/input\/flowers-recognition\/flowers\/flowers\"\nroot_dir = \"\/kaggle\/input\/final-flowers-course-project-dataset\/newFlowers\"\nflower_transform = transforms.Compose([transforms.Resize((512,512)),transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\nflower_dataset = datasets.ImageFolder(root_dir,transform=flower_transform)","c4227252":"### Train Test Parameters ####\n\nbatch_size = 8\nvalid_split = 0.2\nshuffle_dataset = True\nrandom_seed = 42\nflower_dataset.classes","ce15b0a0":"### Split dataset into train and test #####\nimport numpy as np \nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data import DataLoader\ndataset_size = len(flower_dataset)\nindices = list(range(dataset_size))\nsplit = int(np.floor(valid_split * dataset_size))\nif shuffle_dataset :\n    np.random.seed(random_seed)\n    np.random.shuffle(indices)\ntrain_indices,val_indices = indices[split:],indices[:split]\ntrain_sampler = SubsetRandomSampler(train_indices)\nvalid_sampler = SubsetRandomSampler(val_indices)\n\ntrain_loader = DataLoader(flower_dataset,batch_size=batch_size,sampler=train_sampler)\nvalid_loader = DataLoader(flower_dataset,batch_size=batch_size,sampler=valid_sampler)\n\n\n","27628dba":"#### Visualize Images in Train and Test #####\nfrom torchvision.transforms import ToPILImage\nimport matplotlib.pyplot as plt\n\ntrain_batch,label_train = next(iter(train_loader))\nvalid_batch,label_val = next(iter(valid_loader))\n\n\n\n\n\ndef img_plotter(batch,rows=8,cols=8):\n    fig,axs = plt.subplots(nrows=rows,ncols=cols,figsize=(30,30))\n    for i in range(rows):\n        for j in range(cols):\n            axs[i,j].imshow(batch[rows*i+j].permute(1,2,0))\n        \n","f0c21c7f":"train_batch,label_train = next(iter(train_loader))\nvalid_batch,label_val = next(iter(valid_loader))\n","4c3817a4":"### Visualize training images ####\nimg_plotter(train_batch,rows=4,cols=4)","80fa320b":"####Visualize validation images ####\nimg_plotter(valid_batch,rows=4,cols=4)","e1d512f9":"##### Design Custom Network ######\nimport torch.nn as nn\n'''class Flower_Net(nn.Module):\n    def __init__(self):\n        \n        super(Flower_Net,self).__init__()\n        self.layer1 = nn.Sequential(\n        nn.Conv2d(3,64,kernel_size=5,padding=2),\n        nn.BatchNorm2d(64),\n        nn.Dropout(0.8),\n        nn.MaxPool2d(kernel_size=3,padding=1),\n        \n        )\n        self.layer2 = nn.Sequential(\n        nn.Conv2d(64,64,kernel_size=5,padding=2),\n        nn.Dropout(0.8),\n        nn.BatchNorm2d(64),\n        nn.MaxPool2d(kernel_size=3,padding=1),\n        \n        )\n        self.layer3 = nn.Sequential(\n        nn.Conv2d(64,32,kernel_size=3,padding=1),\n        nn.BatchNorm2d(32),\n        nn.Dropout(0.8),\n        nn.MaxPool2d(kernel_size=3,padding=1),\n        )\n        self.layer4 = nn.Sequential(\n        nn.Conv2d(32,32,kernel_size=3,padding=1),\n        nn.Dropout(0.8),\n        nn.BatchNorm2d(32),\n        #nn.MaxPool2d(kernel_size=3,padding=1),\n        )\n        self.layer5 = nn.Sequential(\n        nn.Conv2d(32,16,kernel_size=3,padding=1),\n        nn.BatchNorm2d(16),\n        nn.Dropout(0.8),\n        nn.MaxPool2d(kernel_size=3,padding=1),\n        )\n        self.layer6 = nn.Sequential(\n        nn.Conv2d(16,8,kernel_size=3,padding=1),\n        nn.BatchNorm2d(8),\n        nn.Dropout(0.8),\n        nn.MaxPool2d(kernel_size=3,padding=1),\n        )\n        self.flat = nn.Flatten()\n        self.fc = nn.Linear(72,5)\n    \n    def forward(self,x):\n        x = F.relu(self.layer1(x))\n        x = F.relu(self.layer2(x))\n        x = F.relu(self.layer3(x))\n        x = F.relu(self.layer4(x))\n        x = F.relu(self.layer5(x))\n        x = F.relu(self.layer6(x))\n        x = F.relu(self.flat(x))\n        out = self.fc(x)\n        return out\n    \n\nclass Flower_Net(nn.Module):\n    def __init__(self):\n        super(Flower_Net,self).__init__()\n        self.layer1 = nn.Sequential(nn.Conv2d(3,16,kernel_size=3,padding=1),nn.AvgPool2d(kernel_size=3,padding=1))\n        self.layer2 = nn.Sequential(nn.Conv2d(16,8,kernel_size=3,padding=1),nn.MaxPool2d(kernel_size=3,padding=1))\n        \n        self.layer3 = nn.Dropout(0.5)\n        \n        self.layer4 = nn.Sequential(nn.Conv2d(8,16,kernel_size=3,padding=1))\n        \n        self.layer5 = nn.Flatten()\n        self.layer6 = nn.Linear(51984,3000)\n        self.layer7 = nn.Dropout(0.4)\n        self.layer8 = nn.Linear(3000,64)\n        self.layer9 = nn.Linear(64,5)\n        self.layer10 = nn.LogSoftmax(dim=1)\n    def forward(self,x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = F.relu(self.layer3(x))\n        x = F.relu(self.layer4(x))\n        x = self.layer5(x)\n        x = F.relu(self.layer6(x))\n        x = F.relu(self.layer7(x))\n        x = F.relu(self.layer8(x))\n        out = self.layer9(x)\n        #out = self.layer10(x)\n        return out'''\n        \n\nclass Flower_Net(nn.Module):\n    def __init__(self):\n        super(Flower_Net,self).__init__()\n        self.layer1 = nn.Sequential(nn.Conv2d(3,16,kernel_size=3,padding=1),\n                                    nn.Conv2d(16,8,kernel_size=3,padding=1),\n                                    nn.AvgPool2d(kernel_size=3,padding=1))\n        self.layer2 = nn.Sequential(nn.Conv2d(8,8,kernel_size=3,padding=1),\n                                    nn.Conv2d(8,4,kernel_size=3,padding=1)\n                                    ,nn.MaxPool2d(kernel_size=3,padding=1))\n        self.layer3 = nn.Flatten()\n        self.layer4 = nn.Linear(12996,512)\n        self.layer5 = nn.Dropout(0.7)\n        \n        self.layer6 = nn.Linear(512,5)\n        \n    def forward(self,x):\n        x = self.layer1(x)\n        x = F.relu(self.layer2(x))\n        x = self.layer3(x)\n        x = F.relu(self.layer4(x))\n        x = self.layer5(x)\n        out = self.layer6(x)\n        return out\n        \n            \nmodel = Flower_Net()\nmodel\n    \n        ","2eb1724b":"#### Ensemble ###\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\ntorch.manual_seed(42)\n\nclass Flower_Net_1(nn.Module):\n    def __init__(self):\n        super(Flower_Net_1,self).__init__()\n        self.layer1 = nn.Sequential(nn.Conv2d(3,128,kernel_size=3,padding=1),nn.AvgPool2d(kernel_size=3,padding=1))\n        self.layer2 = nn.Sequential(nn.Conv2d(128,64,kernel_size=3,padding=1),nn.MaxPool2d(kernel_size=5,padding=2))\n        self.layer3 = nn.Sequential(nn.Conv2d(64,32,kernel_size=3,padding=1),nn.MaxPool2d(kernel_size=5,padding=2))\n        self.flatten = nn.Flatten()\n\n    def forward(self,x):\n        x = F.relu(self.layer1(x))\n        x = F.relu(self.layer2(x))\n        x = F.relu(self.layer3(x))\n        out = self.flatten(x)\n        return out\n\nclass Flower_Net_2(nn.Module):\n    def __init__(self):\n        super(Flower_Net_2,self).__init__()\n        self.layer1 = nn.Sequential(nn.Conv2d(3,64,kernel_size=3,padding=1),nn.AvgPool2d(kernel_size=3,padding=1))\n        self.layer2 = nn.Sequential(nn.Conv2d(64,32,kernel_size=3,padding=1),nn.MaxPool2d(kernel_size=3,padding=1))\n        self.layer3 = nn.Sequential(nn.Conv2d(32,16,kernel_size=3,padding=1),nn.MaxPool2d(kernel_size=3,padding=1))\n        self.flatten = nn.Flatten()\n\n    def forward(self,x):\n        x = F.relu(self.layer1(x))\n        x = F.relu(self.layer2(x))\n        x = F.relu(self.layer3(x))\n        out = self.flatten(x)\n        return out\n\nclass Flower_Net_3(nn.Module):\n    def __init__(self):\n        super(Flower_Net_3,self).__init__()\n        self.layer1 = nn.Sequential(nn.Conv2d(3,32,kernel_size=3,padding=1),nn.AvgPool2d(kernel_size=3,padding=1))\n        self.layer2 = nn.Sequential(nn.Conv2d(32,8,kernel_size=3,padding=1),nn.MaxPool2d(kernel_size=3,padding=1))\n        self.layer3 = nn.Sequential(nn.Conv2d(8,8,kernel_size=3,padding=1),nn.MaxPool2d(kernel_size=3,padding=1))\n        self.flatten = nn.Flatten()\n\n    def forward(self,x):\n        x = F.relu(self.layer1(x))\n        x = F.relu(self.layer2(x))\n        x = F.relu(self.layer3(x))\n        out = self.flatten(x)\n        return out\n\nclass ensemble_Net(nn.Module):\n    \n    def __init__(self):\n        super(ensemble_Net,self).__init__()\n        f1 = Flower_Net_1()\n        f2 = Flower_Net_2()\n        f3 = Flower_Net_3()\n        self.e1 = f1\n        self.e2 = f2\n        self.e3 = f3\n        self.avgpool = nn.AvgPool1d(kernel_size=1)\n        self.fc1 = nn.Linear(10232,3000)\n        self.fc2 = nn.Linear(3000,5)\n    \n    def forward(self,x):\n        o1 = self.e1(x)\n    \n        o2 = self.e2(x)\n        o3 = self.e3(x)\n        x = torch.cat((o1,o2,o3),dim=1)\n        #print(x.size())\n        x = self.fc1(x)\n        out = self.fc2(x)\n        \n        return out\n    \n        \nmodel = ensemble_Net()\nmodel","7c78f790":"\nimport torch\nimport torch.nn.functional as F\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n#print(device)\n#model=vgg\nmodel.to(device)\nfrom torch.optim import Adam,SGD\ncriterion = nn.CrossEntropyLoss()\noptim = Adam(model.parameters(),lr=1e-5,weight_decay=1e-5)\n\n\n","f1b2d366":"### Training Loop ####\nimport torch.nn.functional as F \nn_epochs = 8\n\nfor epoch in range(n_epochs):\n    train_loss = 0\n    val_loss = 0\n    acc = 0.0\n    print(\"Training....\")\n    model.train()\n    for batch_num,(batch,labels) in enumerate(train_loader):\n        inp,target = batch.to(device),labels.to(device)\n        optim.zero_grad()\n        output = model.forward(inp)\n        \n        op = F.softmax(output,dim=1)\n        \n        final_op = torch.argmax(op,dim=1)\n        \n        acc += torch.sum(final_op==target).item()\/len(target)\n        loss = criterion(output,target)\n        \n        loss.backward()\n        optim.step()\n        \n        train_loss+=(loss.item()\/len(batch))\n        if batch_num%50 ==0 and batch_num!=0:\n            print(\"TARGET: \",target)\n            print(\"OUTPUT: \",final_op)\n            print(\"Accuracy after \",batch_num,\"steps: \",acc\/batch_num)\n        \n    \n    acc = acc\/len(train_loader)\n    print(\"Epoch: \",epoch,\"Loss: \",train_loss,\" Accuracy: \",acc)\n    \n    \n    eval_acc = 0\n\n    model.eval()\n    print(\"Validating.....\")\n    for batch in valid_loader:\n        inp,target = batch[0].to(device),batch[1].to(device)\n        op = F.softmax(model.forward(inp))\n        final_op = torch.argmax(op,dim=1)\n       \n    \n        eval_acc += np.sum(final_op.detach().cpu().numpy()==target.detach().cpu().numpy())\/len(target)\n        \n    print(\"Validation accuracy: \",eval_acc\/len(valid_loader))\n    #print(\"FOP\",final_op)\n    #print(\"TARGET\",target)\n    \n    \n    \n\n            \n","fa26f95d":"torch.save(model,\"ensemble.pt\")","2618e5f6":"### Single Image Results #####\nbatch,label = next(iter(valid_loader))\nimg = batch[0]\nlabel = label[0]\nplt.imshow(img.permute(1,2,0))\nimg = torch.reshape(img,(1,3,224,224))\nimg = img.to(device)\nwith torch.no_grad():\n    op = model.forward(img)\n    out = torch.argmax(F.softmax(op))\nactual = flower_dataset.classes[label]\npred = flower_dataset.classes[out]\nprint(\"Out\",out.item())\nprint(\"Predicted\",pred)\nprint(\"Actual\",actual)","e7490aff":"import torchvision\nfrom torchvision.models import vgg16\nvgg = torchvision.models.vgg16(pretrained=True)","497f90a9":"import torch.nn as nn\nvgg.classifier[6] = nn.Linear(in_features=4096,out_features=5,bias=True)","b40f48d7":"from torch.optim import Adam\nimport torch\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nvgg.to(device)\nfrom torch.optim import Adam,SGD\ncriterion = nn.CrossEntropyLoss()\noptim = Adam(vgg.parameters(),lr=1e-5,weight_decay=1e-5)\n","c0a51bc0":"### Training Loop ####\nimport torch.nn.functional as F \nn_epochs = 8\nmax_acc=0\nfor epoch in range(n_epochs):\n    train_loss = 0\n    val_loss = 0\n    acc = 0.0\n    print(\"Training....\")\n    vgg.train()\n    for batch_num,(batch,labels) in enumerate(train_loader):\n        inp,target = batch.to(device),labels.to(device)\n        optim.zero_grad()\n        output = vgg.forward(inp)\n        \n        op = F.softmax(output,dim=1)\n        \n        final_op = torch.argmax(op,dim=1)\n        \n        acc += torch.sum(final_op==target).item()\/len(target)\n        loss = criterion(output,target)\n        \n        loss.backward()\n        optim.step()\n        \n        train_loss+=(loss.item()\/len(batch))\n        if batch_num%50 ==0 and batch_num!=0:\n            print(\"TARGET: \",target)\n            print(\"OUTPUT: \",final_op)\n            print(\"Accuracy after \",batch_num,\"steps: \",acc\/batch_num)\n        \n    \n    acc = acc\/len(train_loader)\n    print(\"Epoch: \",epoch,\"Loss: \",train_loss,\" Accuracy: \",acc)\n    \n    \n    eval_acc = 0\n\n    vgg.eval()\n    print(\"Validating.....\")\n    for batch in valid_loader:\n        inp,target = batch[0].to(device),batch[1].to(device)\n        op = F.softmax(vgg.forward(inp))\n        final_op = torch.argmax(op,dim=1)\n           \n    \n        eval_acc += np.sum(final_op.detach().cpu().numpy()==target.detach().cpu().numpy())\/len(target)\n        \n    print(\"Validation accuracy: \",eval_acc\/len(valid_loader))\n    if eval_acc>max_acc:\n        max_acc = eval_acc\n        torch.save(vgg,\"vgg.pt\")\n    #print(\"FOP\",final_op)\n    #print(\"TARGET\",target)\n    \n    \n    \n\n            \n","5465726a":"Set final layer output = number of classes","142b8b50":"# 4. Define samplers for sampling data little by little","06e95c8b":"# 5. Define image plotting function","9abe540e":"# 2. Make Pytorch dataset for fetching images","de6da82c":"# 12. Save the model","c7335c5b":"Define parameters","a6cbd6a4":"# 11. Define the training loop","f079ef30":"# 6. Get batch and labels to plot","5bc3f84d":"# 9. Define an ensemble Model (best custom model performance)","b3b10406":"# 1. Import required Libraries","b3398a37":"Train the vgg model","73f8f85e":"# 10. Set Parameters and Metric","128e51c5":"# 3. Define parameters","890d81ad":"# 7. Plot available images","d87bf8c2":"Import VGG16 from torchvision","d0af0186":"# 14. Train VGG16 from scratch","a621a01e":"# 8.Define Custom Models","95b5d9dc":"# 13. Visualise results for single images"}}