{"cell_type":{"b6dbcaa5":"code","14528bb7":"code","b9240bae":"code","94421b1d":"code","20e00184":"code","8ca76c54":"code","94c633cc":"code","abcf23f8":"code","b2374937":"code","1f2ebf4e":"code","01ce977b":"code","a6801f2f":"code","d412c796":"code","e3bbd608":"code","29f2e06c":"code","aaf3f601":"code","6250f914":"code","f23dcd4e":"code","1d3bc0c9":"code","2363508d":"code","240c72d2":"code","8b007742":"code","cf8baef6":"code","9b68ea2a":"markdown","b1f4b3ab":"markdown","e1b90934":"markdown","a49fc343":"markdown","eb7961d5":"markdown","5d4910c3":"markdown"},"source":{"b6dbcaa5":"from PIL import Image \nImage.open(\"..\/input\/picdiabetes\/diabetes-overview-1579871892.jpg\")","14528bb7":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\npd.set_option(\"display.max_columns\", None)\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split, cross_validate\nfrom sklearn.preprocessing import StandardScaler","b9240bae":"df = pd.read_csv(\"..\/input\/diabetes-data-set\/diabetes.csv\")\ndf.head()","94421b1d":"df.describe().T","20e00184":"df[\"Outcome\"].value_counts()             #let's see the number of classes of people with diabetes and without diabetes\nsns.countplot(x=\"Outcome\", data=df, palette=['#432371',\"#FAAE7B\"])      #let's visualize it with countplot\nplt.show()","8ca76c54":"#Let's show it as a percentage of the cases of being and not having diabetes.\n#While 65% do not have diabetes, the remaining 35% of observations show that they suffer from diabetes.\n\n100 * df[\"Outcome\"].value_counts() \/ len(df)\n","94c633cc":"#Let's see the pregnancy averages of those with and without diabetes.\n# The average number of pregnancies of those with diabetes is 4.86,\n# and the average number of pregnancies of those without diabetes is 3.29\n\ndf.groupby(\"Outcome\").agg({\"Pregnancies\": \"mean\"})","abcf23f8":"plt.figure(figsize=(15,8))\nax = sns.kdeplot(df[\"Age\"][df.Outcome == 1], color=\"darkturquoise\", shade=True)\nsns.kdeplot(df[\"Age\"][df.Outcome == 0], color=\"lightcoral\", shade=True)\nplt.legend(['Has Diabete', 'Has no Diabete'])\nplt.title('Density Plot of Age That is Having Diabete or Not')\nax.set(xlabel='Age')\nplt.xlim(-10,85)\nplt.show()","b2374937":"#let's check for missing observations.\n# It seems that there are no missing observations.\ndf.isnull().sum()","1f2ebf4e":"#  Outliers\n\n#Let's check the outliers\n#In this problem, according to the number of observations respectively\n# the first quarter and third quarter values were taken as 0.05 and 0.95.\n\n#The function describes up and low tresholds.\ndef outlier_thresholds(dataframe, col_name, q1=0.05, q3=0.95): \n    quartile1 = dataframe[col_name].quantile(q1)\n    quartile3 = dataframe[col_name].quantile(q3)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit","01ce977b":"#The function check dataframe's outliers in the columns.\n#According to this function,\n# there are outliers only in the insulin variable\ndef check_outlier(dataframe, col_name):                           \n    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n        return True\n    else:\n        return False\n\nfor col in df.columns:\n    print(col, check_outlier(df, col))","a6801f2f":"#The function replace the outliers with up and low value.\ndef replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n\n#Now that we a function replace_with_tresholds, let's use it.\nreplace_with_thresholds(df, \"Insulin\")","d412c796":"# Features Creating\n\n# is pregnancy\n# Let's creat new variable calls \"Pregnancies_yes_no\".\n# Yes means being pregnacy otherwise no\ndf.loc[((df['Pregnancies']) > 0), \"Pregnancies_yes_no\"] = \"yes\"\ndf.loc[((df['Pregnancies']) == 0), \"Pregnancies_yes_no\"] = \"no\"\n\n# risk level according to having diabete or not as ages\n#Adapting the WHO (World Health Organization) datas\ndf.loc[(df['Age'] > 20) & (df['Age'] < 34),'age_vs_diabete'] = 'low_risky'\ndf.loc[(df['Age'] >= 35) & (df['Age'] < 44), 'age_vs_diabete'] = 'risky'\ndf.loc[(df['Age'] >= 45) & (df['Age'] < 54),'age_vs_diabete'] = 'too_risky'\ndf.loc[(df['Age'] >= 55),'age_vs_diabete'] = 'high_risky'\n\n# glucose and levels\n# These levels are determined according to the accepted glucose values.\ndf.loc[(df['Glucose'] > 0) & (df['Glucose'] < 70), 'level_glucose'] = 'hypoglosemia'\ndf.loc[(df['Glucose'] >= 71) & (df['Glucose'] < 100), 'level_glucose'] = 'normall'\ndf.loc[(df['Glucose'] >= 101) & (df['Glucose'] < 125), 'level_glucose'] = 'hidden_diabete'\ndf.loc[(df['Glucose'] >= 126), 'level_glucose'] = 'diabete'\n\n# age level\ndf.loc[(df['Age'] < 18), 'new_age'] = 'young'\ndf.loc[(df['Age'] >= 19) & (df['Age'] < 55), 'new_age'] = 'mature'\ndf.loc[(df['Age'] >= 56), 'new_age'] = 'older'\n\n#BMI level\n#These levels are determined according to the\n# accepted Body mass indicator (BMI) values.\ndf.loc[(df['BMI'] < 18),'new_BMI'] = 'unhealthy'\ndf.loc[(df['BMI'] >= 19) & (df['BMI'] < 25), 'new_BMI'] = 'normall'\ndf.loc[(df['BMI'] >= 26) & (df['BMI'] < 30),'new_BMI'] = 'overweight'\ndf.loc[(df['BMI'] >= 31),'new_BMI'] = 'obese'\n\n#Insulin level\n#In this problem 2 hours after glucose administration\n#16-166 mIU\/L is normal level of Insulin.\ndf.loc[(df['Insulin'] >= 16) & (df['Insulin'] <= 166) , 'new_Insulin'] = 'normal'\ndf.loc[(df['Insulin'] < 16), 'new_Insulin'] = 'not_normal'\ndf.loc[(df['Insulin'] > 166) ,'new_Insulin'] = 'not_normal'\ndf.loc[(df['Insulin'] == 0.0 ), 'new_Insulin'] = 'not_normal'","e3bbd608":"df.head(10)","29f2e06c":"#After creating new categorical variables,\n#let's convert these categorical variables\n#into a numeric variable using the one hot encoding method.\n\ndef grab_col_names(dataframe, cat_th=10, car_th=20):\n     # cat_cols, cat_but_car\n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n\n    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n                   dataframe[col].dtypes != \"O\"]\n\n    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n                   dataframe[col].dtypes == \"O\"]\n\n    cat_cols = cat_cols + num_but_cat\n\n    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n\n    # num_cols\n    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n\n    num_cols = [col for col in num_cols if col not in num_but_cat]\n\n    print(f\"Observations: {dataframe.shape[0]}\")\n    print(f\"Variables: {dataframe.shape[1]}\")\n    print(f'cat_cols: {len(cat_cols)}')\n    print(f'num_cols: {len(num_cols)}')\n    print(f'cat_but_car: {len(cat_but_car)}')\n    print(f'num_but_cat: {len(num_but_cat)}')\n\n    return cat_cols, num_cols, cat_but_car\ncat_cols, num_cols, cat_but_car = grab_col_names(df)","aaf3f601":"#One-Hot Encoding\ndef one_hot_encoder(dataframe, categorical_cols, drop_first=False):\n    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)\n    return dataframe\n\n#ohe_cols will convert into a numerical columns\nohe_cols = ['Pregnancies_yes_no',\n 'age_vs_diabete',\n 'level_glucose',\n 'new_age',\n 'new_BMI',\n 'new_Insulin']\n\ndf = one_hot_encoder(df, ohe_cols)\ndf.head()","6250f914":"#Let's scale our numerical colums to get most appreciate results.\n#Standard Scaler\n\ndef grab_col_names(dataframe, cat_th=10, car_th=20):\n    # cat_cols, cat_but_car\n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n\n    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n                   dataframe[col].dtypes != \"O\"]\n\n    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n                   dataframe[col].dtypes == \"O\"]\n\n    cat_cols = cat_cols + num_but_cat\n\n    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n\n    # num_cols\n    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n\n    num_cols = [col for col in num_cols if col not in num_but_cat]\n\n    print(f\"Observations: {dataframe.shape[0]}\")\n    print(f\"Variables: {dataframe.shape[1]}\")\n    print(f'cat_cols: {len(cat_cols)}')\n    print(f'num_cols: {len(num_cols)}')\n    print(f'cat_but_car: {len(cat_but_car)}')\n    print(f'num_but_cat: {len(num_but_cat)}')\n\n    return cat_cols, num_cols, cat_but_car\ncat_cols, num_cols, cat_but_car = grab_col_names(df)\n\nscaler = StandardScaler()\ndf[num_cols] = scaler.fit_transform(df[num_cols])\ndf[num_cols].head()\ndf.head()","f23dcd4e":"#since this problem addresses a classification problem,\n# it has been considered to use a logistic regression model.\n# And in this model, while the outcome is the dependent variable,\n# all other variables constitute the independent variables.\n\ny = df[\"Outcome\"]\nX = df.drop([\"Outcome\"], axis=1)\n\n# Model:\nlog_model = LogisticRegression().fit(X, y)\n\nlog_model.intercept_            \nlog_model.coef_\n\n\n# y_pred\ny_pred = log_model.predict(X)","1d3bc0c9":"#Let's use cross validation method to explain success of model\ncv_results = cross_validate(log_model,\n                            X, y,\n                            cv=5,\n                            scoring=[\"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"])\n\n\n# Let's see the report of accuracy, precision, recall and f1 score.\nprint(classification_report(y, y_pred))","2363508d":"# Confusion Matrix\ndef plot_confusion_matrix(y, y_pred):\n    acc = round(accuracy_score(y, y_pred), 2)\n    cm = confusion_matrix(y, y_pred)\n    sns.heatmap(cm, annot=True, fmt=\".0f\")\n    plt.xlabel('y_pred')\n    plt.ylabel('y')\n    plt.title('Accuracy Score: {0}'.format(acc), size=10)\n    plt.show()\n\nplot_confusion_matrix(y, y_pred)","240c72d2":"# ROC AUC\ny_prob = log_model.predict_proba(X)[:, 1]\nroc_auc_score(y, y_prob) ","8b007742":"# Let's Predict the person which is given by random is having diabet or not\n\nX.columns\n\nrandom_user = X.sample(1, random_state=44)\nlog_model.predict(random_user)                 # Prediction is 0, it means the person has not diabet\n\n","cf8baef6":"random_user = X.sample(1, random_state=26)\nlog_model.predict(random_user)                 # Prediction is 1, it means the person has diabet","9b68ea2a":"**Exploratory Data Analysis**","b1f4b3ab":"**Data Preprocessing**","e1b90934":"**Model & Prediction**","a49fc343":"In this study, the diabetes data set was reviewed and it was tried to predict whether a person has diabetes with a Logistic Regression model. Firstly, the dependent variable \"outcome\" was reviewed in the study. In the last step, new variables were produced and the success of the model was tried to be increased. The accuracy rate and F1 score of the established model were determined as 0.78 and the AUC value was determined as 0.86. Finally, it was estimated by the established model whether a randomly selected person has diabetes or not.","eb7961d5":"**Required Libraries and Modules**","5d4910c3":"\n# **Diabetes Prediction with Logistic Regression**\n\n\n**Business Problem**\n\nCharacteristics of people with diabetes\nwill be able to predict whether they have a patient or not\nit is desirable to develop a machine learning model.\n\n**Story of Dataset**\n\nThe data set is part of a large data set maintained at the National\nInstitutes of Diabetes-dIgestive-Kidney Diseases in the United States.\nthis  data used for a diabetes study conducted on Pima Indian women\naged 21 years and older living in the city of Phoenix, which is their city.\nThe data consists of 768 observations and 8 numerical independent variables.\nThe target variable is specified as \"output\";\n\n*1 diabetes test result is positive,\n0 indicates that it is negative.*\n\n **Variables**\n \n* Pregnancies: Number of pregnancies\n* Glucose: 2 Hours plasma glucose concentration in the oral glucose tolerance test\n* Blood Pressure: mm Hg \n* SkinThickness:\n* Insulin: 2 Hours serum insulin (mu U\/ml)\n* DiabetesPedigreeFunction\n* Age: years\n* Outcome: Having diabete (1) or not (0)"}}