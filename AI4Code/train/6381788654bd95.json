{"cell_type":{"caacc484":"code","e42203cb":"code","34a8fe6e":"code","5a66805f":"code","8a402306":"code","6517115a":"code","797139bd":"code","21016e0d":"code","d04cd2b0":"code","44db6428":"code","63f12ee4":"code","38b4476b":"markdown","3066f6e6":"markdown","a915637a":"markdown","327bae4f":"markdown","dc667a06":"markdown","a5927590":"markdown","39262f4d":"markdown","8ad06ad3":"markdown","316ccee4":"markdown","27fc0bc3":"markdown"},"source":{"caacc484":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pylab as plt\nfrom sklearn.model_selection import StratifiedShuffleSplit\nimport csv\n\nconfig = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=2, \n                                  inter_op_parallelism_threads=2, \n                                  allow_soft_placement=True) # TensorFlow config\npd.options.mode.chained_assignment = None # Pandas config","e42203cb":"import os\nimport PIL\n\npath = '..\/input\/petfinder-pawpularity-score\/train\/'\ntraining_img = os.listdir(path) # list all training images names\nprint('There are {} images in the training directory'.format(len(training_img)))\n\nimg_sz = {'width': list(),\n          'height': list()} # store image attributes for further analysis\nwidth, height = 9999, 9999 # start with fixed very high image size, and keep reducing it when iterating over images in the dataset\n\nfor im in training_img:\n    img = PIL.Image.open(path+im)\n    w, h = img.size\n    if w < width:\n        width = w\n    if h < height:\n        height = h\n\nIMG_WIDTH = width\nIMG_HEIGHT = height\nIMG_CHANNELS = 3\n\nprint('Min training image width: {} px'.format(IMG_WIDTH))\nprint('Min training image height: {} px'.format(IMG_HEIGHT))","34a8fe6e":"def read_and_decode(filename, reshape_dims=(IMG_HEIGHT, IMG_WIDTH)):\n    # Read an image file to a tensor as a sequence of bytes\n    image = tf.io.read_file(filename)\n    # Convert the tensor to a 3D uint8 tensor\n    image = tf.image.decode_jpeg(image, channels=IMG_CHANNELS)\n    # Convert 3D uint8 tensor with values in [0, 1]\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    # Resize the image to the desired size\n    return tf.image.resize(image, reshape_dims).numpy()\n\ndef show_image(filename):\n    image = read_and_decode(filename, [IMG_HEIGHT, IMG_WIDTH])\n    plt.imshow(image);\n    plt.axis('off');\n\ndef training_plot(metrics, history):\n    f, ax = plt.subplots(1, len(metrics), figsize=(5*len(metrics), 5))\n    for idx, metric in enumerate(metrics):\n        ax[idx].plot(history.history[metric], ls='dashed')\n        ax[idx].set_xlabel('Epochs')\n        ax[idx].set_ylabel(metric)\n        ax[idx].plot(history.history['val_'+metric]);\n        ax[idx].legend(['train_'+metric, 'val_'+metric])","5a66805f":"# Display a random image from the dataset\n\nrand_idx = np.random.randint(0, len(training_img)-1)\nrand_img = training_img[rand_idx]\n\nshow_image(path+rand_img)","8a402306":"path = \"..\/input\/petfinder-pawpularity-score\/\"\n\ndata = pd.read_csv(path+\"\/train.csv\") # Dataset for images\ndata['Id'] = data['Id'].apply(lambda x: path+'train\/'+x+'.jpg')\nx, y = data.drop([\"Id\", \"Pawpularity\"], axis=1), data[\"Pawpularity\"] # Subsets of the dataset for tabular data\n\n# Create training, validation and test sets for tabular and image data\n# First: test set is created by keeping apart 20% of the dataset\n# Second: validation set is created by keeping apart 20% of the remaining dataset\n# Third: Training set consists of the remaining samples after test and validation set creation\n\nsssplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2) # Use stratified sampling\nfor train_index, test_index in sssplit.split(x, y):\n    # Tabular tmp training and test sets\n    x_train_tmp, y_train_tmp = x.iloc[train_index], y.iloc[train_index]\n    x_test, y_test = x.iloc[test_index], y.iloc[test_index]\n    # Image tmp training and test sets\n    train_img_tmp = data.iloc[train_index]\n    test_img = data.iloc[test_index][['Id', 'Pawpularity']]\n    \nsssplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2)\nfor train_index, val_index in sssplit.split(x_train_tmp, y_train_tmp):\n    # Tabular training and validation set\n    x_train, y_train = x_train_tmp.iloc[train_index], y_train_tmp.iloc[train_index]\n    x_val, y_val = x_train_tmp.iloc[val_index], y_train_tmp.iloc[val_index]\n    # Image training and validation set\n    train_img = train_img_tmp.iloc[train_index][['Id', 'Pawpularity']]\n    val_img = train_img_tmp.iloc[val_index][['Id', 'Pawpularity']]\n    \n# Export image sets for futher loading and processing\ntrain_img.to_csv('\/kaggle\/working\/training_img.csv', header=False, index=False)\nval_img.to_csv('\/kaggle\/working\/val_img.csv', header=False, index=False)\ntest_img.to_csv('\/kaggle\/working\/test_img.csv', header=False, index=False)","6517115a":"# Pre-process tabular data for further input to the neural network\n\nx_train, y_train = np.asarray(x_train), np.asarray(y_train).astype('float32')\nx_val, y_val = np.asarray(x_val), np.asarray(y_val).astype('float32')\nx_test, y_test = np.asarray(x_test), np.asarray(y_test).astype('float32')","797139bd":"# Store images into arrays for further processing by the network\n\ntrain_dataset = list()\nprint('Loading training images...')\nwith open('\/kaggle\/working\/training_img.csv', 'r') as file:\n    reader = csv.reader(file) \n    for i, row in enumerate(reader):\n        train_dataset.append(read_and_decode(row[0]))\nprint('...done!\\n')\ntrain_dataset = np.array(train_dataset)\nprint('Training dataset shape:', train_dataset.shape)\nprint()\n        \nval_dataset = list()\nprint('Loading validation images...')\nwith open('\/kaggle\/working\/val_img.csv', 'r') as file:\n    reader = csv.reader(file)\n    for i, row in enumerate(reader):\n        val_dataset.append(read_and_decode(row[0]))\nprint('...done!')\nval_dataset = np.array(val_dataset)\nprint('Validation dataset shape:', val_dataset.shape)\nprint()\n        \ntest_dataset = list()\nwith open('\/kaggle\/working\/test_img.csv', 'r') as file:\n    reader = csv.reader(file)\n    for i, row in enumerate(reader):\n        test_dataset.append(read_and_decode(row[0]))\ntest_dataset = np.array(test_dataset)\nprint('Test dataset shape:', test_dataset.shape)","21016e0d":"# Build models for each data type using Keras Functional API\n\nBATCH_SIZE = 128\nIMG_WIDTH = width\nIMG_HEIGHT = height\nIMG_CHANNELS = 3\n\n# Image data\ninput_img = tf.keras.layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\nx = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(input_img)\nx = tf.keras.layers.MaxPooling2D((2, 2))(x)\nx = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\n\n# Tabular data\ninput_tab = tf.keras.layers.Input(shape=(12,))\ny = tf.keras.layers.Dense(16, activation='relu')(input_tab)\ny = tf.keras.layers.Dense(32, activation='relu')(y)\n\n# Concatenate models outputs\nconcatenated = tf.keras.layers.concatenate([x, y], axis=-1)\n\n# Pass concatenated vector through a Dense layer with no activation to output a `Pawpularity` score prediction\noutput_score = tf.keras.layers.Dense(1, activation=None)(concatenated)\n\n# Build general model with Keras Functional API\nmodel = tf.keras.models.Model([input_img, input_tab], output_score)\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.MeanSquaredError(),\n              metrics=[tf.keras.metrics.RootMeanSquaredError()])","d04cd2b0":"print(model.summary())\ntf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=False)","44db6428":"history = model.fit([train_dataset, tf.convert_to_tensor(x_train)], tf.convert_to_tensor(y_train), epochs=20, batch_size=BATCH_SIZE,\n                    validation_data=([val_dataset, tf.convert_to_tensor(x_val)], tf.convert_to_tensor(y_val)))","63f12ee4":"training_plot(['loss', 'root_mean_squared_error'], history)","38b4476b":"## Training the model","3066f6e6":"## Building the model","a915637a":"Input data are manipulated as tensors, the basic data structures of TensorFlow. Images generally have 3 dimensions: height, width, and number of colour channels. An image dataset is most of the time represented as a rank-4 tensor (or 4D tensor) of shape (samples, height, width, channels). For example, a batch of 32 colour images of size 150 x 150 pixels can be stored in the rank-4 tensor (32, 150, 150, 3).\n\nOur network will have to receive images of a fixed size. The images in the dataset being of different size, we'll have to resize them, here to the size of the smallest image. Let's explore some image attributes.","327bae4f":"The general architecture we'd like to use should accept two inputs: tabular and image data, and from there produce one input: a prediction for `Pawpularity`. \n\nTabular data is passed to a dense NN and image data is passed to a CNN. Outputs from both the newtorks are concatenated, and the resulting vector passes through a series of consecutive output units.","dc667a06":"Let's create training, validation and test sets of images and their corresponding metadata. `Pawpularity` is the target to predict, we'll then create sets ensuring its distribution remains the same in each set. This is carried out using stratified sampling instead of random sampling.","a5927590":"## Get the data","39262f4d":"## Images attributes definition","8ad06ad3":"The previous experiments we've conducted lead us to believe that a multimodal input approach would produce better results. Photo metadata and images consist in our two sources of data. They're of different nature. For example a densely connected network could tackle the metadata information, whilst a 2D convolutional neural network would deal with image data.\n\nHere we'll try to jointly learn information from both the data sources by using a model that can see all available input modalities simulataneously. Our model will have two input branches.","316ccee4":"# Multi-input Neural Network","27fc0bc3":"## Data handlers"}}