{"cell_type":{"030eaaf3":"code","0806860c":"code","a668c260":"code","4a9d39f6":"code","1e6087a8":"code","71c70ecc":"code","29ec29f1":"code","680b754c":"code","4fe574d0":"code","bd605ac3":"code","72b6fc44":"code","1cd2f23c":"code","f4acd690":"code","401f25e9":"code","fc4b4936":"code","3cf04328":"code","86d84ea1":"code","7629cc1f":"code","94f4a19d":"code","0f147c81":"code","3d46e74a":"code","113c12aa":"code","4ea05433":"code","4ebc1d00":"code","9155a413":"code","382e85a8":"code","f64ca901":"code","b55e9325":"code","271462cb":"markdown","5657c72c":"markdown","3ed8afab":"markdown","6aef3887":"markdown","fa66ca14":"markdown","b9bb4e99":"markdown","1367adf3":"markdown","385f0707":"markdown","0a0c8477":"markdown","6330ff5a":"markdown","54c33e20":"markdown","c2b235cf":"markdown","c73de9a8":"markdown","3fbea71a":"markdown","38661998":"markdown","65f8bb02":"markdown","c9d0359e":"markdown","c3dda9eb":"markdown","126945cd":"markdown","624b12e7":"markdown","c428bc33":"markdown","c9a4fbd0":"markdown"},"source":{"030eaaf3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0806860c":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom scipy.stats import ttest_1samp\n\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n\nfrom sklearn.model_selection import ParameterGrid\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.statespace.tools import diff","a668c260":"temp_series = pd.read_csv('\/kaggle\/input\/daily-climate-time-series-data\/DailyDelhiClimateTrain.csv',\n                          index_col=0,\n                          usecols=['date','meantemp'],\n                          parse_dates=True,\n                          squeeze=True\n                         )\ntemp_series = temp_series.asfreq('D')\n\ntemp_series.describe()","4a9d39f6":"temp_series.plot(title='mean daily temperature in Delhi',ylabel='temperature (C)')","1e6087a8":"# We use this small code a couple of times, so it's best to make a function of it\ndef dickely_fuller_test(time_series,treshold=0.05):\n    \n    # Dickely-Fuller test\n    df_test = adfuller(time_series)\n\n    test_statistics = df_test[0]\n    p_value = df_test[1]\n\n    print('The Dickey-Fuller test statistics has value {:.3f} with p-value {:.3f}.'.format(test_statistics,p_value))\n\n    # Hp testing (NULL HP = there are unit roots in the time series)\n    if p_value < treshold:\n        print('We can reject the null hp that there are unit roots.')\n    else:\n        print('We cannot reject the null hp (that is, there might be unit roots).')","71c70ecc":"autocorrelations_temperature = plot_acf(temp_series, title='ACF - 40 lags', alpha=0.05)","29ec29f1":"dickely_fuller_test(temp_series)","680b754c":"temp_diff = temp_series.diff(periods=1)\ntemp_diff.dropna(inplace=True)\n\ntemp_diff.plot(title='1-day change in temperature',ylabel='temperature (C)')","4fe574d0":"autocorrelations_difference = plot_acf(temp_diff, title='ACF - 40 lags', alpha=0.05)","bd605ac3":"autocorrelations_difference = plot_pacf(temp_diff, title='PACF - 40 lags', alpha=0.05)","72b6fc44":"T = 365\ntemp_seasonal_diff = temp_diff.diff(periods=T)\ntemp_seasonal_diff.dropna(inplace=True)\n\ntemp_seasonal_diff.plot(title='seasonal change in temperature',ylabel='temperature (C)')","1cd2f23c":"autocorrelations_difference = plot_acf(temp_seasonal_diff, title='ACF seasonal adjusted temperature', alpha=0.05)","f4acd690":"autocorrelations_difference = plot_pacf(temp_seasonal_diff, title='PACF seasonal adjusted temperature', alpha=0.05)","401f25e9":"# Parameter grid for our search\nparams = {}\nparams['p'] = np.arange(0,6,dtype=np.int)\nparams['d'] = np.arange(0,3,dtype=np.int)\nparams['q'] = np.arange(0,6,dtype=np.int)\nparams['D'] = np.arange(0,2,dtype=np.int)\n\n# periodicity\ns = 365\n\ndf_results = pd.DataFrame()\n\nfor param in ParameterGrid(params):\n    \n    # instantiate ARIMA model\n    model = SARIMAX(endog = temp_series,\n                    order=(param['p'],param['d'],param['q']),\n                    seasonal_order=(0,param['D'],0,s),\n                    simple_differencing=True\n                   )\n    \n    # Fit the model\n    results = model.fit(maxiter=500)\n    \n    param['aic'] = results.aic\n    param['bic'] = results.bic\n    \n    # Save parameters and AIC\/BIC of the model\n    df_results = df_results.append(param,ignore_index=True)","fc4b4936":"df_results.sort_values('aic').head()","3cf04328":"df_results.sort_values('bic').head()","86d84ea1":"model = SARIMAX(endog=temp_series,order=(5,1,5),seasonal_order=(0,1,0,365),simple_differencing=True)\nresults = model.fit(maxiter=500)","7629cc1f":"results.summary()","94f4a19d":"temp_residuals = results.resid\n\nautocorrelations_residuals = plot_acf(temp_residuals, title='ACF residuals', alpha=0.05)","0f147c81":"autocorrelations_residuals = plot_pacf(temp_residuals, title='PACF residuals', alpha=0.05)","3d46e74a":"bins = 50\nplt.hist(temp_residuals,bins)\nplt.xlabel('residual')\nplt.ylabel('frequency')\nplt.show()","113c12aa":"temp_series_test = pd.read_csv('\/kaggle\/input\/daily-climate-time-series-data\/DailyDelhiClimateTest.csv',\n                               index_col=0,\n                               usecols=['date','meantemp'],\n                               parse_dates=True,\n                               squeeze=True\n                              )\ntemp_series_test = temp_series_test.asfreq('D')\n\ntemp_series_test.describe()","4ea05433":"temp_series_test.plot(title='mean daily temperature in Delhi',ylabel='temperature (C)')","4ebc1d00":"# size of the test series\ntest_size = temp_series_test.size\n\n# concatenate the training and test series\ntemp_series_full = pd.concat((temp_series,temp_series_test))\n\n# difference by 1 lag and T=365\ndiff_series_full = diff(temp_series_full, k_diff=1, k_seasonal_diff=1, seasonal_periods=T)\ndiff_series_full.dropna(inplace=True)\n\ndiff_series_train = diff_series_full[:-test_size]\ndiff_series_test = diff_series_full[-test_size:]\n\n# # Plot the full series after differencing as done while fitting the model\ndiff_series_full.plot(title='differenced temperature in Delhi - full',ylabel='temperature (C)')","9155a413":"# In-sample forcasting for the diff of the temperature in Delhi\npredict_in_sample = results.get_prediction(start='2014-01-02',end='2017-01-01')\n\n# The mean temperature and confidence interval for the in-sample forcast, to be compared with the training set\ntemp_forcast_is_mean = predict_in_sample.predicted_mean\ntemp_forcast_is_CI = predict_in_sample.conf_int(alpha=0.5)\n\ntemp_forcast_is_lower = temp_forcast_is_CI['lower D.DS365.meantemp'].to_numpy()\ntemp_forcast_is_upper = temp_forcast_is_CI['upper D.DS365.meantemp'].to_numpy()\n\ndates = diff_series_train.index","382e85a8":"fig, ax = plt.subplots(figsize=(12,6))\n\nax.plot(dates,diff_series_train, label = 'train series')\nax.plot(dates,temp_forcast_is_mean, 'k--', label = 'in-sample forcast')\nax.fill_between(dates,temp_forcast_is_lower, temp_forcast_is_upper, alpha=0.15)\nax.legend()\nax.set_xlabel('Date')\nax.set_ylabel('Diff temperature Delhi')\nfig.show()","f64ca901":"# out-of-sample forcasting for the temperature in Delhi\npredict = results.get_prediction(start='2017-01-01',end='2017-04-24')\n\n# The mean temperature and confidence interval for the out-of-sample forcast, to be compared with the test set\ntemp_forcast_oos_mean = predict.predicted_mean\ntemp_forcast_oos_CI = predict.conf_int(alpha=0.5)\n\ntemp_forcast_oos_lower = temp_forcast_oos_CI['lower D.DS365.meantemp'].to_numpy()\ntemp_forcast_oos_upper = temp_forcast_oos_CI['upper D.DS365.meantemp'].to_numpy()\n\ndays_in_future = np.arange(test_size)","b55e9325":"fig, ax = plt.subplots(figsize=(12,6))\n\nax.plot(days_in_future, diff_series_test, label = 'test series')\nax.plot(days_in_future, temp_forcast_oos_mean, 'k--', label = 'oos forcast')\nax.fill_between(days_in_future, temp_forcast_oos_lower, temp_forcast_oos_upper, alpha=0.15)\nax.legend()\nax.set_xlabel('Days ahead')\nax.set_ylabel('Diff temperature Delhi')\nfig.show()","271462cb":"We can now differenciate the training and test time series in the same way we did before fitting the ARIMA,\n\n$x_t \\rightarrow (1-L)(1-L^T) x_t$,\n\nwhere $T = 365$ and $L$ is the shift operator.","5657c72c":"### Autocorrelations\n\nLet's have a look at the acf and pacf of the residuals. From the JB test, we know that there should not be autocorrelations, and we'd like to confirm this visually.","3ed8afab":"Let's visualize the result","6aef3887":"### Out-of-sample temperature forcasting\n\nLet's now do out-of-sample forcasting using the model we trained, and check it with the test set we are given.","fa66ca14":"Let's see if we can get rid of the unit root by differencing. First, let's just visualize the time seties of $\\delta x_t$.","b9bb4e99":"The distribution is indeed a bit skewed, and the tails are probabily fat becasue of a few outliers.\n\n# Temperature forcasting\n\nNow that the model is trained and we checked the residual, we can check the in- and out-of-sample forcasting. First, let's load the test series and visulize it,","1367adf3":"\n### In-sample temperature forcasting\n\nWe can now do in-sample forcasting by 1 step ahead, and compare it to the time-series,","385f0707":"## Seasonality\n\nClearly the data are seasonal, with a period of ~ 365 days. We might try to add this contribution to the ARIMA we fit below.\n\nLet's check the effects of differencing by both $\\Delta t = 1$ and $\\Delta t = T$\n\nHIGH-LEVEL IDEA:\n\nSuppose that the signal is $x_t = \\mu \\, t + \\alpha \\, f \\left( t \\right) + u_t$, where $f(t)$ is a periodic function with period $T$. \n\nLet's consider $(1-L)(1-L^{T})x_t$, were we are differencing by both $\\Delta t = 1$ and $\\Delta t = T$. It is easy to show that, under the above assumption, the resulting time series is $(1-L)(1-L^{T})x_t = u_t$ where $u_t$ is white-noise.\n\nOne might indeed expect that the temperauture in Delhi behaves as the model above, with a period of approx $T=365$. Let's check if this is the case,","0a0c8477":"# Model evaluation\n\nNow we can use the optimal parameters discovered above to fit the seasonal ARIMA, and then check if the residuals are distributed as white-noise or not (they should). ","6330ff5a":"We see that differencing by $\\Delta t = T$ is not changing the acf an pacf from just differencing by $\\Delta t = 1$. We could have expected this, since the periodic function $f(t)$ has a long period $T \\gg 1$, and therefore $\\Delta x_t \\approx u_t$ anyway under the model assumed above.","54c33e20":"### Dickley-Fuller test\n\nNow we can use the Dickley-Fuller test, checking for units root in the time series.\n\nHIGH LEVEL IDEA\n\nIf the time series is $x_t = s \\, x_{t-1} + u_t$, then we can regress $\\Delta x_t = x_t - x_{t-1}$ on $x_t$, and estimate the linear coefficient (in the above series this will be $s-1$). Then we can perform a t-test on the estimated coefficient, with $H_0$ being that the linear coefficient is 0 (that implies that a unit root is present, since $s-1 = 0$ implies $s = 1$). ","c2b235cf":"And we can visualize it,","c73de9a8":"All as expected!\n\n### Residual distribution\n\nWe can now check the distribution of the residuals, that the JB test says is not really Normal.","3fbea71a":"Seems pretty stationary, but let's check with acf, pacf, and Dickely-Fuller test,","38661998":"Let's see the optimal parameter choice according to AIC,","65f8bb02":"## Stationarity\n\nLet's check if the time series is stationary . We will look at the acf and use the Dickey-Fuller test.","c9d0359e":"Let's see the acf and the pcf,","c3dda9eb":"And the optimal parameters according ot BIC (it will be a simpler model),","126945cd":"# Box\u2013Jenkins method\n\nIn the following, we implement the Box-Jenkins method for time-series analysis. We consider the daily temperature in Delhi, recorded from 2013 to 2017. The method is composed of 3 main parts\n\n- Model identification\n    - Stationarity\n    - Seasonality\n- Model fit (seasonal ARIMA)\n- Model evaluation\n\nAfter we select a model and we have tested it, we will use it to forcast the temperature in Delhi for the first 6 months of 2017, and we'll check it using the test dataset we are given.\n\n# Load the time series and analyse it\n\nLet's load the time series of average daily temperatures in Delhi and check its statistics and visualize its trend.","624b12e7":"Let's first visualize the autocorrelation plot up to 40 lags. If the series is non-stationary, we would expect a slow decay of correlations here, which we do find","c428bc33":"The summary already tells us a lot,\n\n- Ljung-Box test : the NULL HP is that the autorcorrelations are 0.\n- Heteroskedasticity : the NULL HP is that there is no heterosketasticity.\n\nWe see that indeed, the residual we get are not autocorrelated and are homoskedastic, that is, they seem to behave as white-noise, as we would hope. The JB test check if the residuals are distributed as a nornal distribution, and this is not the case it seems (the distribution is not simmetric, and the tails ar a bit fatter.","c9a4fbd0":"# Fitting a model\n\nGiven the above observation, we can now fit a model for our time series. We can fit an ARIMA model with\n\n- p (Autoregression order) in $[0,5]$\n- q (Moving average order) in $[0,2]$\n- d (order of differencing) in $[0,5]$\n\nand we can add the seasonal component $s = 365$ with\n\n- D (order of seasonal differencing) in $[0,1]$\n\nNOTE: Such a high value of $s$ will make the fit SARIMAX model impossible (at least for the computational resources we are given here), see also this [issue](https:\/\/github.com\/statsmodels\/statsmodels\/issues\/5727). As a result, we instatiate the model with option `simple_differencing = True`, that first differentiate the time series and then fit an ARIMA.\n\nWe then select the model using AIC (or we could do it with BIC, which select less complex models)"}}