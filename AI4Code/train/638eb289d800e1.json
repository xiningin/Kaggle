{"cell_type":{"aa16fd07":"code","6288bf59":"code","87a0bd8f":"code","e148b187":"code","e033bdab":"code","33d51721":"code","5fe4a4d7":"code","7213e8d0":"code","921c02ce":"code","f1b87d8c":"code","486ece50":"code","df983239":"code","d1ec74c0":"code","b3542b8d":"code","94d5f969":"code","f8ff98c7":"code","00e0d50f":"code","2458d90b":"code","b9296dea":"code","7025daf5":"code","950ea91b":"code","f39100fa":"code","4531d4f1":"code","fba5acea":"code","aa2fd923":"code","6690bdbd":"code","a9c66848":"markdown","d17527e0":"markdown","96cc5522":"markdown"},"source":{"aa16fd07":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport tensorflow as tf \n\n!pip install -U efficientnet\n\nimport efficientnet.tfkeras as eff\nfrom kaggle_datasets import KaggleDatasets","6288bf59":"# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","87a0bd8f":"AUTO = tf.data.experimental.AUTOTUNE\nignore_order = tf.data.Options()\nignore_order.experimental_deterministic = False","e148b187":"gcs_path=KaggleDatasets().get_gcs_path('melanoma-512x512')","e033bdab":"filepaths=tf.io.gfile.glob(gcs_path+'\/train*.tfrec')","33d51721":"filepaths_train=filepaths[:-1]\nfilepaths_valid=filepaths[-1]","5fe4a4d7":"BATCH_SIZE=8*tpu_strategy.num_replicas_in_sync\nTRAIN_STEPS=int(30952\/(BATCH_SIZE))+1\nVALID_STEPS=int(2174\/(BATCH_SIZE))+1","7213e8d0":"def make_augmentations(image):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_saturation(image, 0.7, 1.3)\n    image = tf.image.random_contrast(image, 0.8, 1.2)\n    image = tf.image.random_brightness(image, 0.1)\n    return image","921c02ce":"def read_tfrec_train(example):\n    feature_description={'image_name':tf.io.FixedLenFeature([],tf.string),\n                     'image':tf.io.FixedLenFeature([],tf.string),\n                     'target':tf.io.FixedLenFeature([],tf.int64)}\n    example=tf.io.parse_single_example(example,feature_description)\n    return example['image'],example['target']","f1b87d8c":"def make_train_dataset(filepaths,batch_size,train=True):\n    ds=tf.data.TFRecordDataset(filepaths,num_parallel_reads=AUTO)\n    ds=ds.with_options(ignore_order)\n    ds=ds.map(read_tfrec_train,num_parallel_calls=AUTO)\n    ds=ds.repeat()\n    ds=ds.shuffle(1024)\n    ds=ds.map(lambda img,label : (tf.io.decode_image(img,channels=3),label),num_parallel_calls=AUTO)\n    ds=ds.map(lambda img,label:(tf.cast(img,dtype=tf.float32),label),num_parallel_calls=AUTO)\n    if train:\n        ds=ds.map(lambda img,label :(make_augmentations(img),label),num_parallel_calls=AUTO)\n    ds=ds.map(lambda img,label:(tf.reshape(img,[512,512,3]),label),num_parallel_calls=AUTO)\n    ds=ds.batch(batch_size)\n    ds=ds.prefetch(AUTO)\n    return ds\ntrain_ds=make_train_dataset(filepaths_train,batch_size=BATCH_SIZE,train=True)\nvalid_ds=make_train_dataset(filepaths_valid,batch_size=BATCH_SIZE,train=False)","486ece50":"train_ds,valid_ds","df983239":"class early_stopping(tf.keras.callbacks.Callback):\n    def __init__(self,patience=1):\n        self.auc_op=-1.0\n        self.patience=patience\n        self.count=0\n    def on_epoch_end(self,epoch,logs={}):\n                    \n        if logs['val_auc']>=self.auc_op:\n            self.weights_op=self.model.get_weights()\n            self.auc_op=logs['val_auc']\n            self.count=0\n            print('\\nVALIDATION AUC INCREASED')\n        else:\n            self.count=self.count+1\n            print('\\nVALIDATION AUC DID NOT INCREASE ES COUNT :{}\/{}'.format(self.count,self.patience))\n            if(self.count==self.patience):\n                print('EARLY STOPPING ACTIVATED')\n                self.model.stop_training=True\n                print('RESTORING WEIGHTS OF EPOCH {} . BEST VALID AUC = {}'.format(epoch-self.patience+1,self.auc_op))\n                self.model.set_weights(self.weights_op)\n                \ndef schedule(epoch):\n    return 0.0001*(2.71828**(-0.5*epoch))\n\nlr_scheduler=tf.keras.callbacks.LearningRateScheduler(schedule)","d1ec74c0":"train=pd.read_csv('..\/input\/melanoma-512x512\/train.csv')\nfrom sklearn.utils.class_weight import compute_class_weight\ncw=compute_class_weight('balanced',np.unique(train['target']),train['target'])\ncw_dict={0:cw[0],1:cw[1]}\ncw_dict","b3542b8d":"with tpu_strategy.scope():\n    input_layer=tf.keras.layers.Input(shape=(512,512,3))\n    common_input=tf.keras.layers.Lambda(lambda x:x)(input_layer)\n\n\n    model_b0=eff.EfficientNetB1(weights='imagenet',input_shape=(512,512,3),include_top=False)(common_input)\n    model_b1=eff.EfficientNetB2(weights='imagenet',input_shape=(512,512,3),include_top=False)(common_input)\n    model_b2=eff.EfficientNetB3(weights='imagenet',input_shape=(512,512,3),include_top=False)(common_input)\n\n\n    gapb0=tf.keras.layers.GlobalAveragePooling2D()(model_b0)\n    predsb0=tf.keras.layers.Dense(1)(gapb0)\n\n\n    gapb1=tf.keras.layers.GlobalAveragePooling2D()(model_b1)\n    predsb1=tf.keras.layers.Dense(1)(gapb1)\n\n\n    gapb2=tf.keras.layers.GlobalAveragePooling2D()(model_b2)\n    predsb2=tf.keras.layers.Dense(1)(gapb2)\n\n\n    output_concat=tf.keras.layers.Concatenate()([predsb0,predsb1,predsb2])\n    real_out=tf.keras.layers.Dense(1,activation='sigmoid')(output_concat)\n    ensem_model=tf.keras.models.Model(inputs=[input_layer],outputs=[real_out])\n    \n    \n    roc_score=tf.keras.metrics.AUC(curve='ROC')\n    \n\n    ensem_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=[roc_score])\n","94d5f969":"history=ensem_model.fit(train_ds,epochs=100,steps_per_epoch=TRAIN_STEPS,class_weight=cw_dict,validation_data=valid_ds,validation_steps=VALID_STEPS,callbacks=[early_stopping(patience=6),lr_scheduler])","f8ff98c7":"filepaths_test=tf.io.gfile.glob(gcs_path+'\/test*.tfrec')","00e0d50f":"def read_tfrec_test(example,read_filenames):\n    feature_description={'image_name':tf.io.FixedLenFeature([],tf.string),\n                     'image':tf.io.FixedLenFeature([],tf.string)}\n    example=tf.io.parse_single_example(example,feature_description)\n    if read_filenames:\n        return example['image'],example['image_name']\n    else:\n        return example['image']","2458d90b":"def make_test_dataset(filepaths,batch_size,read_filenames=False):\n    ds=tf.data.TFRecordDataset(filepaths,num_parallel_reads=AUTO)\n    ds=ds.map(lambda example: read_tfrec_test(example,read_filenames),num_parallel_calls=AUTO)\n    if read_filenames:\n        ds=ds.map(lambda img,label: (tf.io.decode_image(img,channels=3),label),num_parallel_calls=AUTO)\n        ds=ds.map(lambda img,label:(tf.cast(img,dtype=tf.float32),label),num_parallel_calls=AUTO)\n        ds=ds.map(lambda img,label:(tf.reshape(img,[512,512,3]),label),num_parallel_calls=AUTO)\n        \n    else:\n        ds=ds.map(lambda img:tf.io.decode_image(img,channels=3),num_parallel_calls=AUTO)\n        ds=ds.map(lambda img:tf.cast(img,dtype=tf.float32),num_parallel_calls=AUTO)\n        ds=ds.map(lambda img:tf.reshape(img,[512,512,3]),num_parallel_calls=AUTO)\n        \n    ds=ds.batch(batch_size)\n    ds=ds.prefetch(AUTO)\n    return ds","b9296dea":"test_ids_ds=make_test_dataset(filepaths_test,batch_size=BATCH_SIZE,read_filenames=True)","7025daf5":"test_imagenames=[]\nfor item in test_ids_ds.unbatch():\n    test_imagenames.append(item[1].numpy().decode('utf-8'))","950ea91b":"test_ds=make_test_dataset(filepaths_test,batch_size=BATCH_SIZE,read_filenames=False)","f39100fa":"preds=ensem_model.predict(test_ds)","4531d4f1":"submit=pd.DataFrame(dict(image_name=test_imagenames,target=preds.ravel()))","fba5acea":"submit=submit.sort_values('image_name')","aa2fd923":"submit.to_csv('final_submit_5.csv',index=False)","6690bdbd":"print('DONE , HURRAY')","a9c66848":"# image augmentations","d17527e0":"# with ensemble without metadata","96cc5522":"# now for the predictions"}}