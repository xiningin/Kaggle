{"cell_type":{"e383dcc4":"code","00ebc20e":"code","3cc8995c":"code","30ef9f49":"code","be85342a":"code","db6ed9eb":"code","f3e28503":"code","4e4fd6f9":"code","44f7b2ae":"code","8beebfe6":"code","6fb9ed52":"code","944c92e0":"code","a7b7206a":"code","ed5ab9a1":"code","c59b73c4":"code","31f3dd9e":"markdown","c0c8a538":"markdown","105714f8":"markdown","b2a4620f":"markdown"},"source":{"e383dcc4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","00ebc20e":"from keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D\nfrom keras.layers import Activation, Dropout, BatchNormalization, Flatten, Dense, AvgPool2D,MaxPool2D\nfrom keras.models import Sequential, Model\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.optimizers import Adam, SGD, RMSprop\n\nimport tensorflow as tf\n\nimport os\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","3cc8995c":"DATASET_DIR = \"..\/input\/covid-19-x-ray-10000-images\/dataset\"\n","30ef9f49":"os.listdir(DATASET_DIR)","be85342a":"import glob\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\n\nprint(\"-----------------------\")\nnormal_images = []\nfor img_path in glob.glob(DATASET_DIR + '\/normal\/*'):\n    normal_images.append(mpimg.imread(img_path))\n\nfig = plt.figure()\nfig.suptitle('normal')\nplt.imshow(normal_images[0], cmap='gray') \n\n\ncovid_images = []\nfor img_path in glob.glob(DATASET_DIR + '\/covid\/*'):\n    covid_images.append(mpimg.imread(img_path))\n\nfig = plt.figure()\nfig.suptitle('covid')\nplt.imshow(covid_images[0], cmap='gray')","db6ed9eb":"print(len(normal_images))\nprint(len(covid_images))","f3e28503":"IMG_W = 150\nIMG_H = 150\nCHANNELS = 3\n\nINPUT_SHAPE = (IMG_W, IMG_H, CHANNELS)\nNB_CLASSES = 2\nEPOCHS = 20\nBATCH_SIZE = 20\n","4e4fd6f9":"model=tf.keras.models.Sequential([\n    \n    tf.keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(INPUT_SHAPE)),\n    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    \n    tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n    tf.keras.layers.Conv2D(256,(3,3),activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    \n    tf.keras.layers.Conv2D(256,(3,3),activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512,activation='relu'),\n     tf.keras.layers.Dense(128,activation='relu'),\n    #tf.keras.layers.Dropout(0.25)\n    tf.keras.layers.Dense(1,activation='sigmoid')\n    \n    \n])","44f7b2ae":"from tensorflow.keras.optimizers import RMSprop\n\nmodel.compile(loss='binary_crossentropy',\n                  optimizer=RMSprop(lr=0.001),\n                  metrics=['accuracy'])\n","8beebfe6":"print(model.summary())","6fb9ed52":"train_datagen = ImageDataGenerator(rescale=1.\/255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.3)\n\ntrain_generator = train_datagen.flow_from_directory(\n    DATASET_DIR,\n    target_size=(IMG_H, IMG_W),\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    subset='training')\n\nvalidation_generator = train_datagen.flow_from_directory(\n    DATASET_DIR, \n    target_size=(IMG_H, IMG_W),\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    shuffle= False,\n    subset='validation')\n\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch = train_generator.samples \/\/ BATCH_SIZE,\n    validation_data = validation_generator, \n    validation_steps = validation_generator.samples \/\/ BATCH_SIZE,\n    epochs = EPOCHS)","944c92e0":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","a7b7206a":"print(\"training_accuracy\", history.history['accuracy'][-1])\nprint(\"validation_accuracy\", history.history['val_accuracy'][-1])","ed5ab9a1":"label = validation_generator.classes\n","c59b73c4":"pred= model.predict(validation_generator)\npredicted_class_indices=np.argmax(pred,axis=1)\nlabels = (validation_generator.class_indices)\nlabels2 = dict((v,k) for k,v in labels.items())\npredictions = [labels2[k] for k in predicted_class_indices]\nprint(predicted_class_indices)\nprint (labels)\nprint (predictions)","31f3dd9e":"CNN","c0c8a538":"**Load Data**","105714f8":"prediction","b2a4620f":"Graphical Visulization train vs test."}}