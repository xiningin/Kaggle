{"cell_type":{"ba7e3d14":"code","3c74f410":"code","3a838905":"code","e6c4aa65":"code","1a5395e9":"code","eb1eb63e":"code","7415b2bb":"code","4b3d5058":"code","1144cc0d":"code","1acba4f1":"code","74646b4f":"code","854e751b":"code","f266e384":"code","1b6d4754":"code","8a9a6ab9":"code","3ef8d6fa":"code","af740da9":"code","b6bf695e":"code","5810d50b":"code","8d4c624b":"code","0c29cb02":"code","de89af64":"code","44e1f180":"code","0e6190d3":"code","eedd4acb":"code","39cf858e":"code","1754b933":"code","148b0407":"code","fa1a5101":"code","8afa302f":"markdown","33ff8240":"markdown","1cf2d1eb":"markdown","1fe3bf56":"markdown","403db9a1":"markdown","c2668964":"markdown","330163bb":"markdown","ee2f247e":"markdown","be07a38d":"markdown"},"source":{"ba7e3d14":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nimport torch.nn as nn \nimport torch\nimport torch.nn.functional as f\nimport torch\nfrom torch.autograd import Variable\nimport itertools\nfrom sklearn import datasets, svm, metrics\nfrom sklearn.model_selection import train_test_split\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","3c74f410":"train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","3a838905":"train.head(3)","e6c4aa65":"y_train=train[[\"label\"]]\nx_train=train.loc[:,train.columns != \"label\"]","1a5395e9":"x_train.head(3)","eb1eb63e":"y_train.head(3)","7415b2bb":"ax = sns.countplot(x=\"label\", data=y_train, palette=\"Set3\")#Visualize the count of labels","4b3d5058":"x_t=x_train.to_numpy().reshape((-1,28,28))\ny_t=y_train.to_numpy().reshape((-1))\nx_t.shape\nfor i in range(6):\n  plt.subplot(2,3,i+1)\n  plt.imshow(x_t[i],cmap='gray')\n  plt.title(\"value of frame:\"+str(y_t[i]))\n  plt.xticks([])","1144cc0d":"Y_train = train.label.values","1acba4f1":"X_train = x_train\/255 #rescale image\nX_test = test\/255\n","74646b4f":"i_test=[i+1 for i in range(len(X_test))]","854e751b":"X_test","f266e384":"X_train=np.array(X_train)\nX_test=np.array(X_test)","1b6d4754":"X_train, X_val, Y_train, Y_val = train_test_split(X_train,Y_train, test_size = 0.2, random_state = 42)","8a9a6ab9":"X_train_s = X_train#For SVM Model\nY_train_s = Y_train\n\nX_train = torch.Tensor(X_train)\nX_val = torch.Tensor(X_val)\nX_test = torch.Tensor(X_test)\ni_test = torch.Tensor(i_test)\nY_train = torch.Tensor(Y_train).type(torch.LongTensor) \nY_val = torch.Tensor(Y_val).type(torch.LongTensor) ","3ef8d6fa":"X_test.shape","af740da9":"class CNN_Model(nn.Module):\n    def __init__(self):\n        super(CNN_Model,self).__init__()\n        \n        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0)\n        self.relu1 = nn.ReLU()\n        \n        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n     \n        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=0)\n        self.relu2 = nn.ReLU()\n        \n        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n        \n        self.fc1 = nn.Linear(32 * 4 * 4, 10)\n        \n    def forward(self, x):\n        # Convolution 1\n        out = self.cnn1(x)\n        out = self.relu1(out)\n        \n        # Max pool 1\n        out = self.maxpool1(out)\n        \n        # Convolution 2 \n        out = self.cnn2(out)\n        out = self.relu2(out)\n        \n        # Max pool 2 \n        out = self.maxpool2(out)\n        \n        # flatten\n        out = out.view(out.size(0), -1)\n\n        # Linear function (readout)\n        out = self.fc1(out)\n        \n        return out\n","b6bf695e":"batch_size = 100\nn_iters = 2500\nnum_epochs = n_iters \/ (len(X_train) \/ batch_size)\nnum_epochs = int(num_epochs)\n\ntrn = torch.utils.data.TensorDataset(X_train,Y_train)\nval = torch.utils.data.TensorDataset(X_val,Y_val)\ntst = torch.utils.data.TensorDataset(X_test,i_test)\n\ntrain_loader = torch.utils.data.DataLoader(trn, batch_size = batch_size, shuffle = False)\nval_loader = torch.utils.data.DataLoader(val, batch_size = batch_size, shuffle = False)\ntest_loader = torch.utils.data.DataLoader(tst, batch_size = batch_size, shuffle = False)\n\nmodel = CNN_Model()\n\nlearning_rate = 0.1\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n\nerror = nn.CrossEntropyLoss()","5810d50b":"count = 0\nloss_list = []\niteration_list = []\naccuracy_list = []\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):\n        \n        train = Variable(images.view(100,1,28,28))\n        labels = Variable(labels)\n        \n        optimizer.zero_grad()\n        \n        # Forward propagation\n        outputs = model(train)\n        \n        loss = error(outputs, labels)\n        \n        loss.backward()\n        \n        # Update parameters\n        optimizer.step()\n        \n        count += 1\n        \n        if count % 50 == 0:\n                    \n            correct = 0\n            total = 0\n            for images, labels in val_loader:\n                \n                val = Variable(images.view(100,1,28,28))\n                \n                outputs = model(val)\n                \n                predicted = torch.max(outputs.data, 1)[1]\n                \n                total += len(labels)\n                \n                correct += (predicted == labels).sum()\n            \n            accuracy = 100 * correct \/ float(total)\n            \n            # store loss and iteration\n            loss_list.append(loss.data)\n            iteration_list.append(count)\n            accuracy_list.append(accuracy)\n        if count % 500 == 0:\n            # Print Loss\n            print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.data, accuracy))","8d4c624b":"type(test_loader)","0c29cb02":"f = plt.figure(figsize=(20,6))\nax = f.add_subplot(121)\nax2 = f.add_subplot(122)\n\nax.plot(iteration_list,loss_list,color = \"red\")\nax.set_xlabel(\"Number of iteration\")\nax.set_ylabel(\"Loss\")\nax.set_title(\"CNN: Loss vs Number of iteration\")\n\nax2.plot(iteration_list,accuracy_list,color = \"green\")\nax2.set_xlabel(\"Number of iteration\")\nax2.set_ylabel(\"Accuracy\")\nax2.set_title(\"CNN: Accuracy vs Number of iteration\")\n","de89af64":"test_outputs=[]\nfor images, index in test_loader:\n                \n    val = Variable(torch.Tensor(np.array(images).reshape(100,1,28,28)))\n                \n    outputs = model(val)\n                \n    predicted = torch.max(outputs.data, 1)[1]\n    \n    predicted = predicted.tolist()\n    \n    test_outputs.append(predicted)\n","44e1f180":"test_outputs = list(itertools.chain.from_iterable(test_outputs))","0e6190d3":"len(test_outputs)","eedd4acb":"Label = pd.Series(test_outputs, name = \"Label\").astype(int)\nImageId =  pd.Series(i_test, name = \"ImageId\").astype(int)\nresults = pd.concat([ImageId, Label],axis = 1)\nresults.to_csv(\"digits.csv\", index = False)","39cf858e":"results.head()","1754b933":"classifier = svm.SVC(gamma=0.001)\nclassifier.fit(X_train_s,Y_train_s)","148b0407":"y_pred = classifier.predict(X_train_s)\n\ncm=metrics.confusion_matrix(Y_train_s,y_pred)","fa1a5101":"plt.figure(figsize=(15,8))\nax=sns.heatmap(cm\/np.sum(cm), annot=True, \n            fmt='.2%')\nax.set(xlabel='Target', ylabel='Predicted Values',title=\"SVM CONFUSION MATRIX\")\n","8afa302f":"## SVM Clasiffier","33ff8240":"<a id=\"2\"> <\/a>\n# Load and Examine Data","1cf2d1eb":"## Visualize Result ","1fe3bf56":"<br>\n<h1 style = \"font-size:40px; font-family:Garamond ; font-weight : normal; background-color: #C66363 ; color : #E8D6D8; text-align: center; border-radius: 100px 100px;\">CONTENT <\/h1>\n<br>","403db9a1":"<a id=\"3\"> <\/a>\n# Create and Train Models","c2668964":"## Output ","330163bb":"* [Add Libaries](#1)\n* [Load and Examine Data](#2)\n    * Examine Data\n    * Handle Data\n* [Create and Train Models](#3)\n    * CNN Clasiffier\n    * Visualize Result\n    * CNN Output\n    * SVM Clasiffier\n    ","ee2f247e":"<a id=\"1\"> <\/a>\n# Add Libaries","be07a38d":"## CNN Clasiffier"}}