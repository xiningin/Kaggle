{"cell_type":{"36ebff51":"code","b8de2567":"code","f09517a1":"code","19096918":"code","1ca3d72e":"code","894563a2":"code","e89daebf":"code","c87db9bb":"code","234497ab":"code","d205de61":"code","0e5fc3d6":"code","d3a360ec":"code","c1bd456f":"code","2a8b0a74":"code","fe20ab3b":"code","d211c669":"code","155aec54":"code","fe0c9796":"code","bf31cf29":"markdown","60dd97c2":"markdown","006413f8":"markdown","ba67d235":"markdown","04486480":"markdown","c0b48476":"markdown","fbb07b5d":"markdown","aff020f1":"markdown","0502bd54":"markdown","d0a0bb99":"markdown","4f277fe5":"markdown","8bf1791f":"markdown"},"source":{"36ebff51":"# Import dependencies \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \n%matplotlib inline\n\nimport os, sys, glob, gc \nimport math, random, time\nfrom tqdm import tqdm \nimport cv2, pydicom\n\nfrom sklearn.model_selection import StratifiedKFold \n\nimport tensorflow as tf","b8de2567":"# Params\nconfig = {\n    'data_path': '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification',\n    'model_path': '..\/input\/keras-pretrained-models\/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n    'input_path': '..\/input', \n    'output_path': '.\/',\n    'nfolds': 5, \n    'batch_size': 16,\n    'learning_rate': 1e-4,\n    'num_epochs': 10\n}\nAUTO = tf.data.AUTOTUNE\n\n# For reproducible results    \ndef seed_all(s):\n    random.seed(s)\n    np.random.seed(s)\n    tf.random.set_seed(s)\n    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n    os.environ['PYTHONHASHSEED'] = str(s) \nglobal_seed = 42\nseed_all(global_seed)\n\ninput_modality = [\"FLAIR\", \"T1w\", \"T1wCE\", \"T2w\"]\nmodality_list = [\"FLAIR\", \"T1w\", \"T2w\"] \n\ntrain_folder = os.path.join(config['data_path'], 'train')\ntest_folder = os.path.join(config['data_path'], 'test')\nsample_submission_path = os.path.join(config['data_path'], 'sample_submission.csv')\n\ntrain_df = pd.read_csv(os.path.join(config['data_path'], 'train_labels.csv')); print(train_df.shape)\nsample_df = pd.read_csv(sample_submission_path); print(sample_df.shape)\ntest_df = sample_df.copy(); print(test_df.shape)","f09517a1":"# \u4ea4\u5dee\u691c\u8a3c\u7528\u306b5\u5206\u5272\uff08\u3057\u304b\u3057\u3001\u3053\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u3067\u306f\u30db\u30fc\u30eb\u30c9\u30a2\u30a6\u30c8\u691c\u8a3c\u3057\u304b\u3057\u3066\u3044\u306a\u3044\uff09\n\nskf = StratifiedKFold(n_splits=config['nfolds'], shuffle=True, random_state=global_seed)\n\nfor index, (train_index, val_index) in enumerate(skf.split(X=train_df.index, y=train_df.MGMT_value)):\n    train_df.loc[val_index, 'fold'] = index\n    \nprint(train_df.groupby(['fold', train_df.MGMT_value]).size())","19096918":"# BraTS21ID\u3054\u3068\u306b\u30d5\u30a9\u30eb\u30c0\u30d1\u30b9\u3092\u53d6\u5f97\n\ntrain_df['imfolder'] = ['{:05d}'.format(s) for s in train_df['BraTS21ID']]\ntrain_df['path'] = [os.path.join(train_folder, s) for s in train_df['imfolder']]\ntrain_df","1ca3d72e":"# BraTS21ID\u3054\u3068\u306b\u3001\"FLAIR\", \"T1w\", \"T1wCE\", \"T2w\"\u306e\u5404\u30d5\u30a9\u30eb\u30c0\u306e\u4e2d\u8eab\u3092\u30ab\u30a6\u30f3\u30c8\n\ninput_modality = [\"FLAIR\", \"T1w\", \"T1wCE\", \"T2w\"] \nfor modality in input_modality:   \n    modality_count = []\n    for i in range(len(train_df)):\n        sample_folder = train_df['path'].iloc[i]\n        modality_folder = os.path.join(sample_folder, modality)\n        if os.path.exists(modality_folder):\n            modality_count.append(len(os.listdir(modality_folder)))\n        else:\n            modality_count.append(0)\n        \n    train_df[f'{modality}_count'] = modality_count    \n    \ntrain_df","894563a2":"# \u5148\u306e\u30ab\u30a6\u30f3\u30c8\u6570\u3092\u3082\u3068\u306b\u3001\"FLAIR\", \"T1w\", \"T2w\"\u30d5\u30a9\u30eb\u30c0\u3054\u3068\u306b\u4e2d\u592e\u306e\u753b\u50cf\u30c7\u30fc\u30bf\u30d1\u30b9\u3092\u53d6\u5f97\n\ndef get_mid_path(path, modality='FLAIR'):\n    modality_path = os.path.join(path, modality)\n    img_list = os.listdir(modality_path)\n\n    img_num = [s.split('-')[1] for s in img_list]\n    img_num = [s.split('.')[0] for s in img_num]\n\n    img_path_list = [os.path.join(modality_path, s) for s in img_list]\n\n    tempdf = pd.DataFrame()\n    tempdf['img_num'] = img_num\n    tempdf['img_num'] = tempdf['img_num'].astype('int')\n    tempdf['img_path'] = img_path_list\n\n    tempdf = tempdf.sort_values('img_num').reset_index(drop=True)\n\n    num_imgs = len(img_list)\n    mid_img_path = tempdf['img_path'].iloc[num_imgs\/\/2]\n    return mid_img_path\n\nfor modality in input_modality:\n    train_df[f'{modality}_mid'] = [ get_mid_path(s, modality=modality) for s in train_df['path'] ]\n    \ntrain_df","e89daebf":"test_df['imfolder'] = ['{:05d}'.format(s) for s in test_df['BraTS21ID']]\ntest_df['path'] = [os.path.join(test_folder, s) for s in test_df['imfolder']]\ntest_df","c87db9bb":"input_modality = [\"FLAIR\", \"T1w\", \"T1wCE\", \"T2w\"] \nfor modality in input_modality:   \n    modality_count = []\n    for i in range(len(test_df)):\n        sample_folder = test_df['path'].iloc[i]\n        modality_folder = os.path.join(sample_folder, modality)\n        if os.path.exists(modality_folder):\n            modality_count.append(len(os.listdir(modality_folder)))\n        else:\n            modality_count.append(0)\n        \n    test_df[f'{modality}_count'] = modality_count    \n    \ntest_df","234497ab":"for modality in input_modality:\n    test_df[f'{modality}_mid'] = [ get_mid_path(s, modality=modality) for s in test_df['path'] ]\n    \ntest_df","d205de61":"@tf.function\ndef preprocessing_img(img, threashold=5):\n    img_mean = tf.math.reduce_mean(img)\n    img = img - img_mean\n    img_var = tf.math.reduce_variance(img)\n    img = img \/ img_var\n    img_min = tf.math.reduce_min(img)\n    img = img - img_min\n    img = tf.where(img<threashold, img, threashold)    # \u5165\u529b\u5024\u304c\u5927\u304d\u304f\u306a\u308a\u3059\u304e\u308b\u5834\u5408\u306b\u306f\u5236\u9650\n    img = tf.squeeze(img)    # \u4f59\u8a08\u306a\u6b21\u5143\u306f\u30ab\u30c3\u30c8\n    return img\n\n    \nclass ImageGenerator(tf.keras.utils.Sequence):\n    def __init__(self, df, modality_list):\n        self.df = df\n        self.modality_list = modality_list\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, index):\n        img_list = []\n        for modality in self.modality_list:\n            path = self.df[f'{modality}_mid'].iloc[index]\n            dicom = pydicom.read_file(path)\n            img = dicom.pixel_array\n            img = np.expand_dims(img, -1)\n            img = tf.constant(img)\n            img = tf.image.resize(img, [224, 224])    # concat\u3059\u308b\u305f\u3081\u3001\u3053\u3053\u3067\u753b\u50cf\u306e\u5927\u304d\u3055\u3092\u63c3\u3048\u308b\n            img_list.append(img)\n        multi_ch_img = tf.concat(img_list, axis=-1)\n        multi_ch_img = preprocessing_img(multi_ch_img)\n        return multi_ch_img         # shape=(224, 224, 3)\n    \n    \ndef parse(x):\n    result = tf.io.parse_tensor(x, out_type=tf.float32)\n    result = tf.reshape(result, [224, 224, 3])\n    return result\n\n\ndef build_3ch_train_dataloader(train_df, modality_list, p_fold=0):\n    p_train = train_df.query(f'fold != {p_fold}').reset_index(drop=True)\n    p_valid = train_df.query(f'fold == {p_fold}').reset_index(drop=True)\n\n    AUTOTUNE = tf.data.experimental.AUTOTUNE\n\n    train_datasets = []\n    for mode, df in zip(['train', 'valid'], [p_train, p_valid]):\n        i_g = ImageGenerator(df, modality_list)\n        img_ds = tf.data.Dataset.from_generator(lambda: map(tuple, i_g),\n                                                output_types=(tf.float32),\n                                                output_shapes=(tf.TensorShape([224, 224, 3])),\n                                                 )\n        \n        serial_ds = img_ds.map(tf.io.serialize_tensor)\n\n        if not os.path.exists(f'{mode}-{p_fold}-img.tfrec'):\n            img_tfrec = tf.data.experimental.TFRecordWriter(f'{mode}-{p_fold}-img.tfrec')\n            img_tfrec.write(serial_ds)\n        serial_ds = tf.data.TFRecordDataset(f'{mode}-{p_fold}-img.tfrec')\n        serial_ds = serial_ds.map(parse, num_parallel_calls=AUTOTUNE)\n\n        labels = df['MGMT_value']\n        label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(labels, tf.int32))\n\n        ds = tf.data.Dataset.zip((img_ds, label_ds))\n        \n        ds = ds.cache(filename=f'.\/cache.tf-{mode}-{p_fold}-data')\n        if mode == 'train':\n            train_count = len(df)\n            ds = ds.shuffle(buffer_size=train_count)\n        ds = ds.batch(config['batch_size'], drop_remainder=True)\n        ds = ds.prefetch(buffer_size=AUTOTUNE)\n        train_datasets.append(ds)\n\n    return train_datasets","0e5fc3d6":"# Dataset\u306e\u4f5c\u6210\np_fold = 0\nmodality_list = [\"FLAIR\", \"T1w\", \"T2w\"] \n\ntrain_datasets = build_3ch_train_dataloader(train_df, modality_list, p_fold=p_fold)\ntrain_ds = train_datasets[0]\nvalid_ds = train_datasets[1]\n\nfor d, l in train_ds.take(1):\n    print('Train Data shape: ', d.shape)\n    print('Train Label shape: ', l.shape)\n    \nfor d, l in valid_ds.take(1):\n    print('Valid Data shape: ', d.shape)\n    print('Valid Label shape: ', l.shape)","d3a360ec":"# \u30e9\u30d9\u30eb\u306a\u3057\u306eTestDataset\u3092\u4f5c\u6210\ndef build_3ch_test_dataloader(test_df, modality_list):\n    AUTOTUNE = tf.data.experimental.AUTOTUNE\n\n    i_g = ImageGenerator(test_df, modality_list)\n    img_ds = tf.data.Dataset.from_generator(lambda: map(tuple, i_g),\n                                         output_types=(tf.float32),\n                                         output_shapes=(tf.TensorShape([224, 224, 3])),\n                                                 )\n    serial_ds = img_ds.map(tf.io.serialize_tensor)\n\n    if not os.path.exists('test-img.tfrec'):\n        img_tfrec = tf.data.experimental.TFRecordWriter('test-img.tfrec')\n        img_tfrec.write(serial_ds)\n    serial_ds = tf.data.TFRecordDataset('test-img.tfrec')\n    test_ds = serial_ds.map(parse, num_parallel_calls=AUTOTUNE)\n\n    test_ds = test_ds.cache(filename='.\/cache.tf-test-data')\n    test_ds = test_ds.batch(config['batch_size'], drop_remainder=False)\n    test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)\n\n    return test_ds","c1bd456f":"test_ds = build_3ch_test_dataloader(test_df, modality_list)\n\nfor d in test_ds.take(1):\n    print('Test Data shape: ', d.shape)","2a8b0a74":"# \u30e2\u30c7\u30eb\u69cb\u7bc9\u7528\u95a2\u6570\ndef build_model():    \n    vgg_layers = tf.keras.applications.vgg16.VGG16(weights=config['model_path'],\n                                          include_top=False,\n                                          pooling='avg',\n                                          input_shape=None)\n    vgg_layers.trainable = False\n    vgg_norm = tf.keras.layers.BatchNormalization(name='vgg_norm')\n    \n    model = tf.keras.Sequential()\n    model.add(vgg_layers)\n    model.add(vgg_norm)\n    model.add(tf.keras.layers.Dense(units=256, name='d_1', activation='relu'))\n    model.add(tf.keras.layers.Dense(units=1, name='d_out', activation='sigmoid'))\n    \n    return model","fe20ab3b":"# \u30e2\u30c7\u30eb\u69cb\u7bc9\nif tf.test.is_gpu_available():\n    device_name = tf.test.gpu_device_name()\nelse:\n    device_name = 'cpu:0'\n\nwith tf.device(device_name):\n    model = build_model()\n\nmodel.summary()","d211c669":"# \u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=config['learning_rate']),\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n              metrics=['accuracy'])\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n    filepath=config['output_path'],\n    save_weights_only=True,\n    monitor='val_loss',\n    mode='min',\n    save_best_only=True)\n\nhistory = model.fit(train_ds, epochs=config['num_epochs'],\n                    validation_data=valid_ds, shuffle=True,\n                    callbacks=[early_stopping, model_checkpoint],\n                    )\n\ntrain_losses = history.history['loss']\nvalid_losses = history.history['val_loss']\nnum_epochs = config['num_epochs']","155aec54":"proba = model.predict(test_ds, batch_size=16, verbose=1)\nproba\n\ntest_df['prediction'] = proba\nsample_df['MGMT_value'] = test_df['prediction']\nsample_df","fe0c9796":"sample_df.to_csv(\"submission.csv\", index=False)","bf31cf29":"\u30fb \u3053\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u3067\u306f\u3001TensorFlow\u306e\u5b66\u7fd2\u306e\u305f\u3081\u306b\u3001VGG16\u30e2\u30c7\u30eb\u3092\u7528\u3044\u305f\u4e88\u6e2c\u30e2\u30c7\u30eb\u306e\u69cb\u7bc9\u3092\u884c\u3044\u307e\u3057\u305f\u3002\n\n\u30fb TensorFlow\u306e\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u306b\u306f\u3001\u516c\u5f0f\u30b5\u30a4\u30c8\u3084\u4e0b\u8a18\u65e5\u672c\u8a9e\u30b5\u30a4\u30c8\u306a\u3069\u306b\u304a\u4e16\u8a71\u306b\u306a\u308a\u307e\u3057\u305f\u3002\n\n\u3000\u3000[@IT; TensorFlow 2\uff0bKeras\uff08tf.keras\uff09\u5165\u9580][1]\n\n\u3000\u3000[TensorFlow\u306e\u516c\u5f0f\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u300ctf.data\u3092\u4f7f\u3063\u3066\u753b\u50cf\u3092\u30ed\u30fc\u30c9\u3059\u308b\u300d\u3092\u3082\u3046\u3061\u3087\u3063\u3068\u30b9\u30ea\u30e0\u306b\u3057\u3066\u8aad\u3080][2]\n\n\n\u30fb \u4eca\u56de\u306e\u4e88\u6e2c\u7cbe\u5ea6\u306f\u30b5\u30c3\u30d1\u30ea\u3067\u3059\u304c\u3001\u4eca\u5f8c\u306f\u7528\u3044\u308b\u30c7\u30fc\u30bf\u3092\u5909\u3048\u305f\u308a\u30013DCNN\u30e2\u30c7\u30eb\u3092\u7528\u3044\u308b\u306a\u3069\u3057\u3066\u6539\u5584\u3067\u304d\u308c\u3070\u3068\u601d\u3063\u3066\u3044\u307e\u3059\u3002\n\n\u30fb \u521d\u5b66\u8005\u306a\u306e\u3067\u3001\u3088\u304b\u3089\u306c\u66f8\u304d\u65b9\u3084\u9593\u9055\u3063\u3066\u3044\u308b\u7b87\u6240\u306a\u3069\u3082\u3042\u308b\u304b\u3068\u601d\u3044\u307e\u3059\u3002\u304a\u6c17\u3065\u304d\u306e\u969b\u306b\u306f\u6559\u3048\u3066\u3044\u305f\u3060\u3051\u308b\u3068\u3042\u308a\u304c\u305f\u3044\u3067\u3059\u3002\n\n\u30fb \u305d\u306e\u4ed6\u3001\u3054\u610f\u898b\u3054\u611f\u60f3\u306a\u3069\u3082\u3044\u305f\u3060\u3051\u308b\u3068\u5b09\u3057\u304f\u601d\u3044\u307e\u3059\u3002\u3088\u308d\u3057\u304f\u304a\u9858\u3044\u3057\u307e\u3059\u3002\n\n[* The English version of this notebook][5]\n\n---\n\u3010\u5165\u529b\u30c7\u30fc\u30bf\u306b\u3064\u3044\u3066\u3011\n\n\u30fb VGG16\u306e\u5165\u529b\u30c1\u30e3\u30cd\u30eb\u306f3\u306a\u306e\u3067\u3001\"FLAIR\", \"T1w\", \"T2w\"\u306e\u753b\u50cf3\u679a\u3092concat\u3057\u30661\u3064\u306e\u30c7\u30fc\u30bf\u306b\u3057\u3066\u3044\u307e\u3059\u3002\n\n\u30fb \u305d\u306e\u305f\u3081\u306b\u3001\u5404BraTS21ID\u306e\"FLAIR\", \"T1w\", \"T2w\"\u30d5\u30a9\u30eb\u30c0\u304b\u3089\u3001\u4e2d\u592e\u306e\u753b\u50cf\u30c7\u30fc\u30bf\u3092\u53d6\u5f97\u3057\u3066\u3044\u307e\u3059\u3002\n\n---\nEDA\u306b\u95a2\u3057\u3066\u3001\u4e0b\u8a18\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u3092\u53c2\u8003\u306b\u3055\u305b\u3066\u3044\u305f\u3060\u304d\u307e\u3057\u305f\u3002\u3042\u308a\u304c\u3068\u3046\u3054\u3056\u3044\u307e\u3059\u3002\n\n1. [[TF]: 3D & 2D Model for Brain Tumor Classification][3]\n\n2. [\u3010Brain Tumor\u3011EDA for starter(\u65e5\u672c\u8a9eversion)][4]\n\n---\n\n[1]: https:\/\/atmarkit.itmedia.co.jp\/ait\/subtop\/features\/di\/tf2keras_index.html\n \n[2]: https:\/\/zenn.dev\/tokyoyoshida\/articles\/5c3270ce0d4c91\n\n[3]: https:\/\/www.kaggle.com\/ipythonx\/tf-3d-2d-model-for-brain-tumor-classification\n\n[4]: https:\/\/www.kaggle.com\/chumajin\/brain-tumor-eda-for-starter-version\n\n[5]: https:\/\/www.kaggle.com\/masatomurakawamm\/tensorflow-simple-prediction-with-2d-vgg16","60dd97c2":"\u30fb \u306f\u3058\u3081\u306f\u5358\u7d14\u306btf.data.Dataset.from_tensor_slices()\u3092\u4f7f\u304a\u3046\u3068\u601d\u3063\u3066\u3044\u305f\u306e\u3067\u3059\u304c\u3001dcm\u30d5\u30a1\u30a4\u30eb\u306e\u8aad\u307f\u8fbc\u307f\u304c\u4e0a\u624b\u304f\u3044\u304b\u305a\u3001Keras Sequence\u3092\u4f7f\u3044\u307e\u3057\u305f\u3002\n\n\u30fb \u9ad8\u901f\u5316\u306e\u305f\u3081\u3001TFRecord\u306e\u4f5c\u6210\u3068\u8aad\u307f\u8fbc\u307f\u3082\u884c\u306a\u3063\u3066\u3044\u307e\u3059\u3002","006413f8":"# 2. DataLoader","ba67d235":"# 1. EDA","04486480":"# RSNA-MICCAI Brain Tumor Radiogenomic Classification","c0b48476":"## 1.1 Train DataFrame","fbb07b5d":"## 2.1 Train Dataset","aff020f1":"# 0. Settings","0502bd54":"## 2.2 Test Dataset","d0a0bb99":"# 4. Prediction ","4f277fe5":"# 3. Train","8bf1791f":"## 1.2 Test DataFrame\uff08\u5148\u306eTrain DataFrame\u3068\u540c\u69d8\u306e\u6d41\u308c\uff09"}}