{"cell_type":{"3b26e03d":"code","b48fc7a5":"code","faed0980":"code","884a9e01":"code","5c156cad":"code","9921e9bc":"code","99796ae9":"code","386a146d":"code","3765b26f":"code","80078b4d":"code","f234408e":"code","5285705a":"code","0bacb108":"code","42c7f83c":"code","fcd25f2d":"code","ddb93140":"code","46a0f7a4":"code","12a30ce9":"code","bcf9b67d":"code","18ccbed9":"code","2ff83b64":"code","5a1d3109":"code","9d75e27e":"code","39666d6d":"code","a5ac4bb5":"code","86b09fe5":"code","b7196e0f":"code","988b601f":"code","d895ac1c":"code","67bd99d6":"code","e1312faf":"code","86a16243":"code","d32d6fb8":"code","178b004a":"code","818edcfd":"code","399aacc9":"code","3e334e11":"code","ba260c66":"code","96f0d105":"code","f1ac985e":"code","198c3e77":"code","8c4c5579":"code","08d8e1fe":"code","0716d8e9":"code","5eadf4ce":"code","00d1733f":"code","e8fe0784":"code","63bf8528":"code","ca08fda6":"code","4f966d53":"code","6af6b063":"code","12055cb7":"code","a971ceda":"code","91a0dc35":"code","f716521a":"code","c0e78c94":"code","a055ef07":"code","cb8328c3":"code","34f6dcb6":"code","c79a818a":"code","8b27d28f":"code","a841df16":"code","f92c688a":"code","5831936d":"code","0433ccfa":"code","a891da96":"code","38f3cb02":"code","a06e9b95":"markdown"},"source":{"3b26e03d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport seaborn as sns\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b48fc7a5":"# Directive pour afficher les graphiques dans Jupyter\n%matplotlib inline","faed0980":"# Pandas : librairie de manipulation de donn\u00e9es\n# NumPy : librairie de calcul scientifique\n# MatPlotLib : librairie de visualisation et graphiques\n# SeaBorn : librairie de graphiques avanc\u00e9s\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","884a9e01":"#importer les donn\u00e9es et les afficher\nt = pd.read_csv(\"..\/input\/pima-indians-diabetes-database\/diabetes.csv\")\nt.head()","5c156cad":"display(t.info(),t.head())","9921e9bc":"#Comptage par colonne\nt.count()","99796ae9":"# Compl\u00e9ter les donn\u00e9es manquantes\n\ndiabetes = t.fillna(value = {'Glucose':t.BloodPressure.mean()})","386a146d":" plt.hist(t.Glucose,bins=100)\n    ","3765b26f":"diabetes.count()","80078b4d":"diabetes1 = diabetes.fillna(value = {'SkinThickness':t.SkinThickness.mean()})","f234408e":"plt.hist(diabetes1.SkinThickness, bins=100)","5285705a":"diabetes1.count()","0bacb108":"# BloodPressure\n\ndiabetes2 = diabetes1.fillna(value = {'BloodPressure':t.BloodPressure.mean()})","42c7f83c":"plt.hist(diabetes2.BloodPressure, bins=100)","fcd25f2d":"diabetes2.count()","ddb93140":"diabetes3 = diabetes2.fillna(value = {'Insulin':t.Insulin.mean()})","46a0f7a4":"plt.hist(diabetes3.Insulin, bins=100)","12a30ce9":"diabetes3.count()","bcf9b67d":"diabetes4 = diabetes3.fillna(value = {'BMI':t.BMI.mean()})","18ccbed9":"plt.hist(diabetes4.BMI, bins=100)","2ff83b64":"diabetes4.count()","5a1d3109":"# distributionsd\u00e9s\u00e9quilibr\u00e9es\n\nsns.distplot(diabetes4.Insulin, color='blue')","9d75e27e":"# Am\u00e9lioration de l'\u00e9quilibre avec une transformation log\n\ndiabetes4['log_Insulin'] = np.log(diabetes4.Insulin+1)","39666d6d":"sns.kdeplot(diabetes4.log_Insulin, color='blue')","a5ac4bb5":"diabetes4[['Age','log_Insulin']].describe()","86b09fe5":"sns.kdeplot(diabetes4.log_Insulin, color='blue')\nsns.kdeplot(diabetes4.Age, color='red')","b7196e0f":"from sklearn import preprocessing","988b601f":"#Normaliser les valeurs min et \u00e0 max (valeurs ramen\u00e9es entre 0 et 1)\n\nminmax = preprocessing.MinMaxScaler(feature_range=(0, 1))\ndiabetes4[['Age', 'log_Insulin']] = minmax.fit_transform(diabetes4[['Age', 'log_Insulin']])","d895ac1c":"sns.distplot(diabetes4.log_Insulin, color='blue')\nsns.distplot(diabetes4.Age, color='red')","67bd99d6":"#StandardScaler pour ramener la moyenne \u00e0 0 et l'\u00e9cart type \u00e0 1\n\nscaler = preprocessing.StandardScaler()\ndiabetes4[['Age', 'log_Insulin']] = scaler.fit_transform(diabetes4[['Age', 'log_Insulin']])","e1312faf":"sns.kdeplot(diabetes4.log_Insulin, color='blue')\nsns.kdeplot(diabetes4.Age, color='red')","86a16243":"X = diabetes4.drop(['Outcome'], axis=1)\ny = diabetes4.Outcome","d32d6fb8":"#importer train test split function de sklearn library\n\nfrom sklearn.model_selection import train_test_split","178b004a":"# On s\u00e9pare le dataset en deux parties (80% pour l'apprentissage et 30% pour le test) \n\nX_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.3, random_state=1)","818edcfd":"print(X_train.shape)\nprint(X_test.shape)","399aacc9":"#R\u00e9gression logistique\n\nfrom sklearn.linear_model import LogisticRegression\n","3e334e11":"lr = LogisticRegression()\nlr.fit(X_train,y_train)","ba260c66":"y_lr = lr.predict(X_test)","96f0d105":"#On importe le classificateur de la librairie sklearn\n\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score","f1ac985e":"# \u00c9valuer la matrice de confusion\n\nprint(confusion_matrix(y_test,y_lr))","198c3e77":"# \u00c9valuer la qualit\u00e9 de la pr\u00e9cision avec sklearn library\n\nprint(accuracy_score(y_test,y_lr))","8c4c5579":"# \u00c9valuer le rappart de classification \n\nprint(classification_report(y_test, y_lr))","08d8e1fe":"#Tableau de couples de probabilit\u00e9s\n\nprobas = lr.predict_proba(X_test)","0716d8e9":"print(probas)","5eadf4ce":"#Dataframe\n\ndfprobas = pd.DataFrame(probas,columns=['proba_0','proba_1'])\ndfprobas['y'] = np.array(y_test)","00d1733f":"dfprobas","e8fe0784":"# Graphique de distribution des probabilit\u00e9s de pr\u00e9diction\n\nplt.figure(figsize=(10,10))\nsns.distplot(1-dfprobas.proba_0[dfprobas.y==0], bins=50)\nsns.distplot(dfprobas.proba_1[dfprobas.y==1], bins=50)","63bf8528":"false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,probas[:, 1])\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint (roc_auc)","ca08fda6":"plt.figure(figsize=(12,12))\nplt.title('Receiver Operating Characteristic')\nplt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.2f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')        \nplt.plot([0,0,1],[0,1,1],'g:')     \nplt.xlim([-0.1,1.2])\nplt.ylim([-0.1,1.2])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","4f966d53":"#Random forest\n\nfrom sklearn import ensemble\nrf = ensemble.RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_rf = rf.predict(X_test)","6af6b063":"print(classification_report(y_test, y_rf))","12055cb7":"cm = confusion_matrix(y_test, y_rf)\nprint(cm)","a971ceda":"rf1 = ensemble.RandomForestClassifier(n_estimators=10, min_samples_leaf=10, max_features=3)\nrf1.fit(X_train, y_train)\ny_rf1 = rf.predict(X_test)\nprint(classification_report(y_test, y_rf1))","91a0dc35":"# La validation_curve \n\nfrom sklearn.model_selection import validation_curve\nparams = np.arange(1, 300,step=30)\ntrain_score, val_score = validation_curve(rf, X, y, 'n_estimators', params, cv=7)\nplt.figure(figsize=(12,12))\nplt.plot(params, np.median(train_score, 1), color='blue', label='training score')\nplt.plot(params, np.median(val_score, 1), color='red', label='validation score')\nplt.legend(loc='best')\nplt.ylim(0, 1)\nplt.xlabel('n_estimators')\nplt.ylabel('score');","f716521a":"from sklearn import model_selection","c0e78c94":"param_grid = {\n              'n_estimators': [10, 100, 500],\n              'min_samples_leaf': [1, 20, 50]\n             }\nestimator = ensemble.RandomForestClassifier()\nrf_gs = model_selection.GridSearchCV(estimator, param_grid)","a055ef07":"rf_gs.fit(X_train, y_train)","cb8328c3":"print(rf_gs.best_params_)","34f6dcb6":"rf2 = rf_gs.best_estimator_","c79a818a":"y_rf2 = rf2.predict(X_test)","8b27d28f":"print(classification_report(y_test, y_rf2))","a841df16":"#Importance des caract\u00e9ristiques\n\nimportances = rf2.feature_importances_\nindices = np.argsort(importances)","f92c688a":"plt.figure(figsize=(8,5))\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), X_train.columns[indices])\nplt.title('Importance des caracteristiques')","5831936d":"#XGBOOST\n\n!pip install xgboost","0433ccfa":"import xgboost as XGB\nxgb  = XGB.XGBClassifier()\nxgb.fit(X_train, y_train)\ny_xgb = xgb.predict(X_test)\ncm = confusion_matrix(y_test, y_xgb)\nprint(cm)\nprint(classification_report(y_test, y_xgb))","a891da96":"#modification de dataframe\ndef replace_0(df,col) :\n    df1 = df.copy()\n    n = df.shape[0]\n    m = df[col].mean()\n    s = df[col].std()\n    for i in range(n) :\n        if df.loc[i,col]==0 :\n            df1.loc[i,col] = np.random.normal(m,s)\n    return df1","38f3cb02":"df = replace_0(df,\"Glucose\")","a06e9b95":"#Interpr\u00e9tation des param\u00e8tres : \nPregnancies = nombre de grossesse\nGlucose = taux de glucose\nBloodPressure = Pression dans le sang \nSkinThickness = Epaisseur de la peau\nInsulin = insulin \nBMI = IMC \/ \nDiabetesPedigreeFunction = l'h\u00e9r\u00e9dit\u00e9 \/ \nAge = age \nOutcome = R\u00e9sultat (0= pas de diab\u00e8te, 1 = diab\u00e8te)"}}