{"cell_type":{"537c41e4":"code","a715f57d":"code","6c64bb58":"code","6750b5ba":"code","35ea6796":"code","6585e574":"code","3e5af66e":"code","ca120a41":"code","f372c62f":"code","7ce7ded1":"code","33d1105b":"code","9da7a138":"code","d35a845c":"code","0d9ee4f0":"code","f2b33f0b":"code","19da2e75":"code","723e44e8":"code","efa2d010":"code","05fc3a73":"code","6eedcd97":"code","b7cadc4d":"code","ef085b3c":"code","0a5d9ace":"code","75e49bfd":"code","a86fc68d":"markdown","49f956db":"markdown","6330a609":"markdown","c789dbe5":"markdown"},"source":{"537c41e4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pylab as plt\nfrom matplotlib import cm\nimport math\nimport pandas as pd\nimport random\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a715f57d":"%matplotlib inline \nplt.style.use('seaborn-whitegrid')\n# plt.rc('text', usetex=False)\nplt.rc('font', family='times')\nplt.rc('xtick', labelsize=10) \nplt.rc('ytick', labelsize=10) \nplt.rc('font', size=12) ","6c64bb58":"data = pd.read_csv(\"\/kaggle\/input\/ense3-lesson\/files\/ch04\/ACCIDENTS_GU_BCN_2013.csv\", encoding='latin-1')\nprint (data.columns)","6750b5ba":"#Create a new column which is the date\ndata['Date'] = '2013-'+data['Mes de any'].apply(lambda x : str(x)) + '-' +  data['Dia de mes'].apply(lambda x : str(x))\ndata['Date'] = pd.to_datetime(data['Date'])\naccidents = data.groupby(['Date']).size()\nprint (\"Mean:\", accidents.mean())","35ea6796":"fig, ax = plt.subplots(1, 1, figsize=(12, 4))\nplt.ylabel('Number of accidents')\nplt.xlabel('Day')\nplt.plot(range(0, 365), np.array(accidents), 'b-+', lw=0.7, alpha=0.7)\nplt.plot(range(0, 365), [accidents.mean()]*365, 'r-', lw=0.7, alpha=0.9)\nplt.show()","6585e574":"fig, ax = plt.subplots(1, 1, figsize=(12, 3))\nplt.ylabel('Frequency')\nplt.xlabel('Number of accidents')\nplt.hist(np.array(accidents), bins=20)\nax.axvline(x=accidents.mean(), ymin=0, ymax=40, color=[1, 0, 0])\nplt.savefig(\"bootmean.png\",dpi=300, bbox_inches='tight')\nplt.show()","3e5af66e":"print (\"Mean:\", accidents.mean(), \"; STD:\", accidents.std())","ca120a41":"\ndf = accidents.to_frame()\nm = []\n\nfor i in range(10):\n    df['for_testing'] = False\n    # get a 25% sample \n    sampled_ids = np.random.choice(df.index,\n                                   size=np.int64(np.ceil(df.index.size * 0.25)),\n                                   replace=False)\n    df.loc[sampled_ids, 'for_testing'] = True\n    accidents_sample = df[df['for_testing'] == True]\n    m.append(accidents_sample[0].mean())\n    print  ('Sample '+str(i)+': Mean', '%.2f' % accidents_sample[0].mean())\n    ","f372c62f":"fig, ax = plt.subplots(1, 1, figsize=(12, 2))\nx = range(10)\nax.step(x,m, where='mid')\nax.set_ylabel('Mean')\nax.set_xlabel('Sample')","7ce7ded1":"plt.autumn()\n\n# population\ndf = accidents.to_frame()    \nN_test = 10000              \nelements = 200             \n\n# mean array of samples\nmeans = [0] * N_test             \n\n# sample generation\nfor i in range(N_test):          \n    rows = np.random.choice(df.index.values, elements)\n    sampled_df = df.loc[rows]\n    means[i] = sampled_df.mean()\n    \nfig, ax = plt.subplots(1, 1, figsize=(12,3))\n\nplt.hist(np.array(means),bins=50)\nplt.ylabel('Frequency')\nplt.xlabel('Sample mean value')\nax.axvline(x = np.array(means).mean(), \n           ymin = 0, \n           ymax = 700, \n           color = [1, 0, 0])\nplt.savefig(\"empiricalmean.png\",dpi=300, bbox_inches='tight')\nplt.show()\nplt.set_cmap(cmap=cm.Pastel2)\n\nprint (\"Sample mean:\", np.array(means).mean())","33d1105b":"rows = np.random.choice(df.index.values, 200)\nsampled_df = df.loc[rows]\nest_sigma_mean = sampled_df.std()\/math.sqrt(200)\n\nprint ('Direct estimation of SE from one sample of 200 elements:', \\\n       est_sigma_mean[0])\nprint ('Estimation of the SE by simulating 10000 samples of 200 elements:',  \\\n       np.array(means).std())","9da7a138":"def meanBootstrap(X,numberb):\n    import numpy as np\n    x = [0]*numberb\n    for i in range(numberb):\n        sample = [X[_] for _ in np.random.randint(len(X), size=len(X))]\n        x[i] = np.mean(sample)\n    return x\n\nm = meanBootstrap(accidents, 10000)\nprint (\"Mean estimate:\", np.mean(m))","d35a845c":"fig, ax = plt.subplots(1, 1, figsize=(12, 3))\nplt.ylabel('Frequency')\nplt.xlabel('Sample mean value')\nplt.hist(m, \n         bins = 50, \n         normed = True)\nax.axvline(x = np.mean(m), \n           ymin = 0.0, \n           ymax = 1.0, \n           color = [1, 0, 0])","0d9ee4f0":"def medBootstrap(X,numberb):\n    import numpy as np\n    x = [0]*numberb\n    for i in range(numberb):\n        sample = [X[_] for _ in np.random.randint(len(X), size=len(X))]\n        x[i] = np.median(sample)\n    return x\n\nmed = medBootstrap(accidents, 10000)\nprint (\"Median estimate:\", np.mean(med))\nfig, ax = plt.subplots(1, 1, figsize=(12, 3))\nplt.hist(med, bins=5, normed=True)\nplt.ylabel('Frequency')\nplt.xlabel('Sample median value')\nax.axvline(x = np.array(med).mean(), \n           ymin = 0, \n           ymax = 1.0, \n           color = [1, 0, 0])","f2b33f0b":"m = accidents.mean()\nse = accidents.std()\/math.sqrt(len(accidents))\nci = [m - se*1.96, m + se*1.96]\nprint (\"Confidence interval:\", ci)","19da2e75":"m = meanBootstrap(accidents, 10000)\nsample_mean = np.mean(m)\nsample_se =  np.std(m)\n\nprint (\"Mean estimate:\", sample_mean)\nprint (\"SE of the estimate:\", sample_se)\n\nci = [np.percentile(m,2.5), np.percentile(m,97.5)]\nprint (\"Confidence interval:\", ci)","723e44e8":"df = accidents   \n\nn = 100                                               # number of observations\nN_test = 100                                          # number of samples with n observations\nmeans = np.array([0.0] * N_test)                      # samples' mean\ns = np.array([0.0] * N_test)                          # samples' std\nci = np.array([[0.0,0.0]] * N_test)\ntm = df.mean()                                        # \"true\" mean\n\nfor i in range(N_test):                               # sample generation and CI computation\n    rows = np.random.choice(df.index.values, n)\n    sampled_df = df.loc[rows]\n    means[i] = sampled_df.mean()\n    s[i] = sampled_df.std()\n    ci[i] = means[i] + np.array([-s[i] *1.96\/np.sqrt(n), s[i]*1.96\/np.sqrt(n)])    \n\nout1 = ci[:,0] > tm                                   # CI that do not contain the \"true\" mean\nout2 = ci[:,1] < tm\n\nfig, ax = plt.subplots(1, 1, figsize=(12, 5))\nind = np.arange(1, N_test+1)\nax.axhline(y = tm, \n           xmin = 0, \n           xmax = N_test+1, \n           color = [0, 0, 0])\nci = np.transpose(ci)\nax.plot([ind,ind], \n        ci, \n        color = '0.75', \n        marker = '_', \n        ms = 0, \n        linewidth = 3)\nax.plot([ind[out1],ind[out1]], \n        ci[:, out1], \n        color = [1, 0, 0, 0.8], \n        marker = '_', \n        ms = 0, \n        linewidth = 3)\nax.plot([ind[out2],ind[out2]], \n        ci[:, out2], \n        color = [1, 0, 0, 0.8], \n        marker = '_',\n        ms = 0, \n        linewidth = 3)\nax.plot(ind, \n        means, \n        color = [0, .8, .2, .8], \n        marker = '.',\n        ms = 10, \n        linestyle = '')\nax.set_ylabel(\"Confidence interval for the samples' mean estimate\",\n              fontsize = 12)\nax.set_xlabel('Samples (with %d observations). '  %n, \n              fontsize = 12)\nplt.savefig(\"confidence.png\",\n            dpi = 300, \n            bbox_inches = 'tight')\nplt.show()","efa2d010":"data = pd.read_csv(\"\/kaggle\/input\/ense3-lesson\/files\/ch04\/ACCIDENTS_GU_BCN_2010.csv\", encoding='latin-1')\n#Create a new column which is the date\ndata['Date'] = data['Dia de mes'].apply(lambda x : str(x)) + '-' +  \\\n               data['Mes de any'].apply(lambda x : str(x))\ndata2 = data['Date']\ncounts2010 =data['Date'].value_counts()\nprint ('2010: Mean', counts2010.mean())\n\ndata = pd.read_csv(\"\/kaggle\/input\/ense3-lesson\/files\/ch04\/ACCIDENTS_GU_BCN_2013.csv\", encoding='latin-1')\n#Create a new column which is the date\ndata['Date'] = data['Dia de mes'].apply(lambda x : str(x)) + '-' +  \\\n               data['Mes de any'].apply(lambda x : str(x))\ndata2 = data['Date']\ncounts2013 = data['Date'].value_counts()\nprint ('2013: Mean', counts2013.mean())","05fc3a73":"n = len(counts2013)\nmean = counts2013.mean()\ns = counts2013.std()\nci = [mean - s*1.96\/np.sqrt(n),  mean + s*1.96\/np.sqrt(n)] \nprint ('2010 accident rate estimate:', counts2010.mean())\nprint ('2013 accident rate estimate:', counts2013.mean())\nprint ('CI for 2013:',ci)","6eedcd97":"m = len(counts2010)\nn = len(counts2013)\np = (counts2013.mean() - counts2010.mean())\nprint ('m:',m, 'n:', n)\nprint ('mean difference: ', p)","b7cadc4d":"x = counts2010\ny = counts2013\npool = np.concatenate([x,y])\nnp.random.shuffle(pool)\n\nfig, ax = plt.subplots(1, 1, figsize=(12, 3))\nplt.hist(pool, \n         bins = 25, \n         normed = True)\nplt.ylabel('Frequency')\nplt.xlabel('Number of accidents')\nplt.title(\"Pooled distribution\")","ef085b3c":"N = 10000 # number of samples\ndiff = [i for i in range(N)]\nfor i in range(N):\n    p1 = [random.choice(pool) for _ in range(n)]\n    p2 = [random.choice(pool) for _ in range(n)]\n    diff[i] = (np.mean(p1)-np.mean(p2))\n\nfig, ax = plt.subplots(1, 1, figsize=(12, 3))\nplt.hist(diff, \n         bins = 50, \n         normed = True)\nplt.ylabel('Frequency')\nplt.xlabel('Difference in the mean')","0a5d9ace":"# counting how many differences are larger than the observed one\ndiff2 = np.array(diff)\nw1 = np.where(diff2 > p)[0]      \nlen(w1)","75e49bfd":"print ('p-value (Simulation)=', len(w1)\/float(N), '(', len(w1)\/float(N)*100 ,'%)', 'Difference =', p)\nif len(w1)\/float(N)<0.05:\n    print ('The effect is likely')\nelse:\n    print ('The effect is not likely')","a86fc68d":"We have defined the effect as a difference in mean as big or bigger than the observed difference, taking into account the sign. A test like this is called one-sided.\n\nIf the relevant question is whether accident rates are different, then it makes sense to test the absolute difference in means. This kind of test is called two-sidedbecause it counts both sides of the distribution of differences.","49f956db":"To give a measure of variability of our estimates is a way of producing a statistical proposition about the population, but not the only one. R.A.Fisher (1890-1962) proposed an alternative, known as hypothesis testing, that is based on the concept of statistical significance.\n\nLet\u2019s suppose that a deeper analysis of traffic accidents in Barcelona results in a difference between 2010 and 2013. Of course, the diference could be caused only by chance, because of the variability of both estimates. But it could also be the case that traffic conditions are very diferent in Barcelona during these two periods and, because of this, data from these two periods can be considered as belonging to two diferent populations. Then, the relevant question is: Are the observed effects real or not?\n\nThe process of determining the statistical significance of an effect is called hypothesis testing. This process starts by simplifying the options into two competing hypotheses:\n\nH0 : The mean number of daily traffic accidents is the same in 2013 and 2010 (there is only one population, one true mean, and 2010 and 2013 are just different samples from the same population).\nHA : The mean number of daily traffic accidents for 2010 and for 2013 is different (2010 and 2013 are two samples from two different populations).\nWe call  H0  the null hypothesis and it represents a skeptical point of view: the effect we have observed is due to chance (due to the specific sample bias).\n\nHA  is the alternative hypothesis and it represents the other point of view: the effect is real.\n\nThe general rule of frequentist hypothesis testing is: We will not discard  H0  (and hence we will not consider  HA ) unless the observed effect is implausible under  H0 .\n\nTesting hypotheses using confidence intervals.\n\nWe can use the concept represented by confidence intervals to measure the plausibility of an hypothesis.\n\nWe can illustrate the evaluation of the hypotheses setup by comparing the mean rate of traffic accidents in Barcelona during 2010 and 2013 using a point estimate from the 2013 sample:","6330a609":"Lecture des data","c789dbe5":"To approximate the p-value, we can follow the following procedure:\n\nPool the distributions, generate samples with size  n  and compute the difference in the mean.\nGenerate samples with size  n  and compute the difference in the mean.\nCount how many differences are larger than the observed one"}}