{"cell_type":{"9782105e":"code","233e8c52":"code","06984206":"code","57e767ee":"code","9a5210f8":"code","b9a162be":"code","79c871bf":"code","afd27f65":"code","4a811e49":"code","c427f80f":"markdown"},"source":{"9782105e":"import pandas as pd\nimport numpy as np\nimport nltk\nnltk.download('punkt')\nimport re\nfrom nltk.corpus import stopwords\n","233e8c52":"df = pd.read_csv(\"..\/input\/reports\/tennis.csv\")\ndf.head()","06984206":"import random\ni=random.randint(0,len(df))\ndf['article_text'][i]","57e767ee":"from nltk.tokenize import sent_tokenize\nsentences = []\nfor s in df['article_text']:\n    sentences.append(sent_tokenize(s))\n\nsentences = [y for x in sentences for y in x]","9a5210f8":"word_embeddings = {}\nf = open('..\/input\/glove6b\/glove.6B.300d.txt', encoding='utf-8')\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    word_embeddings[word] = coefs\nf.close()\n\nclean_sentences = pd.Series(sentences).str.replace(\"[^a-zA-Z]\", \" \")\nclean_sentences = [s.lower() for s in clean_sentences]\nstop_words = stopwords.words('english')\ndef remove_stopwords(sen):\n    sen_new = \" \".join([i for i in sen if i not in stop_words])\n    return sen_new\nclean_sentences = [remove_stopwords(r.split()) for r in clean_sentences]","b9a162be":"sentence_vectors = []\nfor i in clean_sentences:\n  if len(i) != 0:\n    v = sum([word_embeddings.get(w, np.zeros((300,))) for w in i.split()])\/(len(i.split())+0.001)\n  else:\n    v = np.zeros((300,))\n  sentence_vectors.append(v)","79c871bf":"sim_mat = np.zeros([len(sentences), len(sentences)])\nfrom sklearn.metrics.pairwise import cosine_similarity\nfor i in range(len(sentences)):\n  for j in range(len(sentences)):\n    if i != j:\n      sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,300), sentence_vectors[j].reshape(1,300))[0,0]\n","afd27f65":"import networkx as nx\n\nnx_graph = nx.from_numpy_array(sim_mat)\nscores = nx.pagerank(nx_graph)","4a811e49":"ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\nfrom termcolor import colored\ni=random.randint(0,len(df))\nprint(colored((\"ARTICLE:\".center(50)),'yellow'))\nprint('\\n')\nprint(colored((df['article_text'][i]),'blue'))\nprint('\\n')\nprint(colored((\"SUMMARY:\".center(50)),'green'))\nprint('\\n')\nprint(colored((ranked_sentences[i][1]),'cyan'))\n","c427f80f":"Text Summarization involves condensing a piece of text into a shorter version, reducing the size of the original text while preserving key information and the meaning of the content. Since manual text synthesis is a long and generally laborious task, task automation is gaining in popularity and therefore a strong motivation for academic research. "}}