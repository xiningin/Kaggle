{"cell_type":{"32e7e6d8":"code","0a8eb1d1":"code","a6d91923":"code","85f13f54":"code","268afab6":"code","d7874989":"code","9fba80bd":"code","7e6a3916":"code","0ea89846":"code","6a8a60b8":"code","ec42737e":"code","1e1047c9":"code","8f1c4471":"code","e3f34560":"code","f16fb0cf":"code","e431a464":"code","09b602b2":"code","511285bb":"code","ad44f92e":"markdown","446a45bc":"markdown","c949c348":"markdown","440b92b9":"markdown","4aa4a5e0":"markdown","71cd59de":"markdown","b7c1c5c0":"markdown","9b5bd728":"markdown","8b823ae8":"markdown","b028ed58":"markdown","6405d388":"markdown","c382f057":"markdown","51f87bf9":"markdown","1499f6a2":"markdown"},"source":{"32e7e6d8":"%%time\nimport sys\n!cp ..\/input\/rapids\/rapids.0.15.0 \/opt\/conda\/envs\/rapids.tar.gz\n!cd \/opt\/conda\/envs\/ && tar -xzvf rapids.tar.gz > \/dev\/null\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.7\/site-packages\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.7\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\"] + sys.path \n!cp \/opt\/conda\/envs\/rapids\/lib\/libxgboost.so \/opt\/conda\/lib\/","0a8eb1d1":"import cudf, cuml\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, KFold\nfrom cuml.manifold import TSNE\nimport matplotlib.pyplot as plt\n%matplotlib inline\nprint('cuML version',cuml.__version__)","a6d91923":"IMAGE_PATH = '..\/\/input\/\/chinese-mnist\/\/data\/\/data\/\/'\nIMAGE_WIDTH = 64\nIMAGE_HEIGHT = 64\nIMAGE_CHANNELS = 1\nTEST_SIZE = 0.2\nVAL_SIZE = 0.2","85f13f54":"import os\nos.listdir(\"..\/\/input\/\/chinese-mnist\")","268afab6":"data_df=pd.read_csv('..\/\/input\/\/chinese-mnist\/\/chinese_mnist.csv')","d7874989":"image_files = list(os.listdir(IMAGE_PATH))\nprint(\"Number of image files: {}\".format(len(image_files)))","9fba80bd":"def create_file_name(x):\n    file_name = f\"input_{x[0]}_{x[1]}_{x[2]}.jpg\"\n    return file_name","7e6a3916":"data_df[\"file\"] = data_df.apply(create_file_name, axis=1)","0ea89846":"file_names = list(data_df['file'])\nprint(\"Matching image names: {}\".format(len(set(file_names).intersection(image_files))))","6a8a60b8":"train_df, test_df = train_test_split(data_df, test_size=TEST_SIZE, random_state=42, stratify=data_df[\"code\"].values)","ec42737e":"print(\"Train set rows: {}\".format(train_df.shape[0]))\nprint(\"Test  set rows: {}\".format(test_df.shape[0]))","1e1047c9":"import cv2\ndef read_image(file_name):\n    image_data = cv2.imread(IMAGE_PATH + file_name, cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image_data, (IMAGE_WIDTH * IMAGE_HEIGHT, 1))\n\n    return image[0,:]","8f1c4471":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nle.fit(train_df['character'])\nprint(le.classes_)","e3f34560":"def prepare_data(dataset,label_encoding=le):\n    X = np.stack(dataset['file'].apply(read_image))\n    y = label_encoding.transform(dataset['character'])\n    return X, y","f16fb0cf":"X_train, y_train = prepare_data(train_df)\nX_test, y_test = prepare_data(test_df)","e431a464":"%%time\ntsne = TSNE(n_components=2, perplexity=10)\ntrain_2D = tsne.fit_transform(X_train)","09b602b2":"plt.scatter(train_2D[:,0], train_2D[:,1], c = y_train, s = 1)","511285bb":"for i in range(5,50, 5):\n    tsne = TSNE(n_components=2, perplexity=i)\n    train_2D = tsne.fit_transform(X_train)\n    plt.title(f\"perplexity: {i}\")\n    plt.scatter(train_2D[:,0], train_2D[:,1], c = y_train, s = 1)\n    plt.show()","ad44f92e":"## Split the data\n\nFirst, we split the whole dataset in train and test. We will use **random_state** to ensure reproductibility of results. We also use **stratify** to ensure balanced train\/validation\/test sets with respect of the labels. \n\nThe train-test split is **80%** for training set and **20%** for test set.\n","446a45bc":"There is a dataset file and a folder with images.  \n\nLet's load the dataset file first.","c949c348":"We load the packages used for the analysis.","440b92b9":"<a href=\"#0\"><font size=\"1\">Go to top<\/font><\/a>  \n\n\n## Load the data\n\nLet's see first what data files do we have in the root directory.","4aa4a5e0":"We can observe that the categories are very much mixed. Let's take advantage of the very high speed and run multiple experiments in a row.","71cd59de":"We also set a number of parameters for the data and model.","b7c1c5c0":"# <a id='3'>Classes distribution visualization with t-SNE<\/a>\n\n","9b5bd728":"Let's check the shape of the three datasets.","8b823ae8":"# <a id='2'>Prepare the analysis<\/a>   \n\n\nBefore starting the analysis, we need to make few preparation: install RAPIDS from the dataset, load the packages, load and inspect the data.\n\n","b028ed58":"Now we are ready to start experiment with the the 2D t-SNE model.","6405d388":"## Install RAPIDS & load packages\n\n\n","c382f057":"<h1><center><font size=\"6\">Chinese MNIST 2D t-SNE using RAPIDS<\/font><\/center><\/h1>\n\n\n# <a id='0'>Content<\/a>\n\n- <a href='#1'>Introduction<\/a>  \n- <a href='#2'>Prepare the analysis<\/a>   \n- <a href='#3'>Classes distribution visualization with t-SNE<\/a>             \n","51f87bf9":"Next, we will split further the **train** set in **train** and **validation**. We want to use as well a validation set to be able to measure not only how well fits the model the train data during training (or how well `learns` the training data) but also how well the model is able to generalize so that we are able to understands not only the bias but also the variance of the model.  \n\nThe train-validation split is **80%** for training set and **20%** for validation set.","1499f6a2":"# <a id='1'>Introduction<\/a>  \n\n\nWe will use RAPIDS to solve Chinese MNIST problem.\n\nFor more details about the problem, you can check this Notebook: [Tensorflow\/Keras\/GPU for Chinese MNIST Prediction](https:\/\/www.kaggle.com\/gpreda\/tensorflow-keras-gpu-for-chinese-mnist-prediction)\n\n\nWe will follow the preparation steps in the model Notebook, and then apply the 2D t-SNE solution presented by Bojan Tunguz in [MNIST 2D t-SNE with Rapids](https:\/\/www.kaggle.com\/tunguz\/mnist-2d-t-sne-with-rapids).\n\nNote: I updated the installation steps for RAPIDS using inspiration from this Notebook: [\ud83d\udc68\u200d\ud83c\udf93Answer Correctness - RAPIDS crazy fast](https:\/\/www.kaggle.com\/andradaolteanu\/answer-correctness-rapids-crazy-fast)\n\n<a href=\"#0\"><font size=\"1\">Go to top<\/font><\/a>  "}}