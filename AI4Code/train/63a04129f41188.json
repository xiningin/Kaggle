{"cell_type":{"eecca9a5":"code","d19e5960":"code","aa67b20d":"code","538aa580":"code","d70dd84d":"code","78734e13":"code","3463c86c":"code","4e0690dc":"code","591d1295":"code","c14b04d6":"code","9441f7e7":"code","ead94414":"code","136e0f60":"code","98d575e4":"code","cd619a1b":"code","420adb33":"code","05ad8d93":"code","8d7ad925":"code","8d0276ef":"code","8a41cd72":"code","d5467232":"code","a19453b6":"code","e6d9f0d9":"code","a5b826df":"code","e94be152":"code","6600002f":"code","0710e06f":"code","cc54f59b":"code","f8cc8622":"code","6a144f7f":"markdown","b12eb686":"markdown","51bc3357":"markdown","63f38fa1":"markdown","545862dc":"markdown","56368c91":"markdown","d5ba10ca":"markdown"},"source":{"eecca9a5":"#import warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np # linear algebra\nimport pandas as pd\nimport zipfile\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras.optimizers import Adam,RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator \nfrom keras import backend\nimport cv2 \nfrom keras import applications\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n\n\nfrom keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\n\nprint(\"Cats&Dogs Dataset Folder Contain:\",os.listdir(\"..\/input\"))\n        \n        \n%matplotlib inline","d19e5960":"# Extract data because we have data in zip file\nwith zipfile.ZipFile(\"\/kaggle\/input\/dogs-vs-cats\/train.zip\",\"r\") as z:\n    z.extractall(\".\")\n    \nwith zipfile.ZipFile(\"\/kaggle\/input\/dogs-vs-cats\/test1.zip\",\"r\") as z:\n    z.extractall(\".\")\n    ","aa67b20d":"# lets check our data extracted or not\n#print(os.listdir(\"\/kaggle\/working\/test1\"))\n#print(os.listdir(\"\/kaggle\/working\/train\"))\n","538aa580":"main = \"\/kaggle\/working\"\ntrain = \"train\"\ntrain = os.path.join(main,train)\n\ntest = \"test1\"\ntest = os.path.join(main,test)\n\n\nIMAGE_FOLDER_PATH=\"..\/working\/train\"\nFILE_NAMES=os.listdir(IMAGE_FOLDER_PATH)\nWIDTH=150\nHEIGHT=150","d70dd84d":"\n# random choose a single image from train dataset\nfor p in os.listdir(train):\n    category = p.split(\".\")[0]\n    image_read = cv2.imread(os.path.join(train,p),cv2.IMREAD_GRAYSCALE)\n    img = cv2.resize(image_read,dsize=(240,240))\n    plt.imshow(img,cmap=\"gray\")\n    break","78734e13":"from matplotlib.image import imread\n# create a grid of 3x3 images\nfor i in range(9):\n    plt.subplot(331+i)\n    filename=train+'\/cat.'+str(i)+'.jpg'\n    image=imread(filename)\n    plt.imshow(image)\nplt.show()    ","3463c86c":"# create a grid of 3x3 images\nfor i in range(9):\n    plt.subplot(331+i)\n    filename=train+'\/dog.'+str(i)+'.jpg'\n    image=imread(filename)\n    plt.imshow(image)\nplt.show()  ","4e0690dc":"# create dataset\ntargets=list()\nfull_paths=list()\nfor file_name in FILE_NAMES:\n    target=file_name.split(\".\")[0]\n    full_path=os.path.join(IMAGE_FOLDER_PATH, file_name)\n    full_paths.append(full_path)\n    targets.append(target)\n\ndataset=pd.DataFrame()\ndataset['image_path']=full_paths\ndataset['target']=targets\n\n        \n","591d1295":"dataset.head(10)","c14b04d6":"# count of dogs and cats\ntarget_counts=dataset['target'].value_counts()\nprint(\"Number of dogs in the dataset:{}\".format(target_counts['dog']))\nprint(\"Number of cats in the dataset:{}\".format(target_counts['cat']))","9441f7e7":"# lets check our train data\nsns.countplot(y='target',data=dataset)\ndataset['target'].value_counts()    # we have equal images of both cat and Dog","ead94414":"\ndef show_model_history(modelHistory, model_name):\n    history=pd.DataFrame()\n    history[\"Train Loss\"]=modelHistory.history['loss']\n    history[\"Validatin Loss\"]=modelHistory.history['val_loss']\n    history[\"Train Accuracy\"]=modelHistory.history['accuracy']\n    history[\"Validatin Accuracy\"]=modelHistory.history['val_accuracy']\n  \n    history.plot(figsize=(12,8))\n    plt.title(\" Convulutional Model {} Train and Validation Loss and Accuracy History\".format(model_name))\n    plt.show()","136e0f60":"# Dataset split\ndataset_train, dataset_test=train_test_split(dataset,\n                                                 test_size=0.2,\n                                                 random_state=42)","98d575e4":"train_datagen=ImageDataGenerator(\nrotation_range=15,\nrescale=1.\/255,\nshear_range=0.1,\nzoom_range=0.2,\nhorizontal_flip=True,\nwidth_shift_range=0.1,\nheight_shift_range=0.1)\n\ntrain_datagenerator=train_datagen.flow_from_dataframe(dataframe=dataset_train,\n                                                     x_col=\"image_path\",\n                                                     y_col=\"target\",\n                                                     target_size=(WIDTH, HEIGHT),\n                                                     class_mode=\"binary\",\n                                                     batch_size=150)","cd619a1b":"test_datagen=ImageDataGenerator(rescale=1.\/255)\ntest_datagenerator=test_datagen.flow_from_dataframe(dataframe=dataset_test,\n                                                   x_col=\"image_path\",\n                                                   y_col=\"target\",\n                                                   target_size=(WIDTH, HEIGHT),\n                                                   class_mode=\"binary\",\n                                                   batch_size=150)","420adb33":"# CNN\nmodel=Sequential()\nmodel.add(layers.Conv2D(32, (3,3), activation=\"relu\", input_shape=(WIDTH, HEIGHT, 3)))\nmodel.add(layers.Conv2D(32, (3,3), activation=\"relu\"))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.add(layers.Dropout(0.25))\n\nmodel.add(layers.Conv2D(64, (3,3), activation=\"relu\"))\nmodel.add(layers.Conv2D(64, (3,3), activation=\"relu\"))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D(2,2))\nmodel.add(layers.Dropout(0.25))\n\nmodel.add(layers.Conv2D(128, (3,3), activation=\"relu\"))\nmodel.add(layers.Conv2D(128, (3,3), activation=\"relu\"))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.add(layers.Dropout(0.25))\n\nmodel.add(layers.Conv2D(64, (3,3), activation=\"relu\"))\nmodel.add(layers.Conv2D(64, (3,3), activation=\"relu\"))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.add(layers.Dropout(0.25))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, activation=\"relu\"))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(1, activation=\"sigmoid\"))\nmodel.summary()","05ad8d93":"model.compile(loss=\"binary_crossentropy\", \n             optimizer=RMSprop(lr=1e-4),\n             metrics=[\"accuracy\"])\nprint(\"[INFO]: model compiled...\")","8d7ad925":"#from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\n#earlystop = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=6)\n\n#learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n\n#callbacks = [earlystop]","8d0276ef":"modelHistory=model.fit_generator(train_datagenerator,\n                                epochs=50,\n                                validation_data=test_datagenerator,\n                                validation_steps=dataset_test.shape[0]\/\/150,\n                                steps_per_epoch=dataset_train.shape[0]\/\/150\n                                )\n","8a41cd72":"print(\"Train Accuracy:{:.3f}\".format(modelHistory.history['accuracy'][-1]))\nprint(\"Test Accuracy:{:.3f}\".format(modelHistory.history['val_accuracy'][-1]))\nshow_model_history(modelHistory=modelHistory, model_name=\"\")","d5467232":"model=applications.InceptionV3(weights=\"imagenet\", include_top=False, input_shape=(WIDTH, HEIGHT, 3))\nmodel.summary()","a19453b6":"counter=0\nfeatures=list()\nfor path, target in zip(full_paths, targets):\n    img=load_img(path, target_size=(WIDTH, HEIGHT))\n    img=img_to_array(img)\n    img=np.expand_dims(img, axis=0)\n    feature=model.predict(img)\n    features.append(feature)\n    counter+=1\n    if counter%2500==0:\n        print(\"[INFO]:{} images loaded\".format(counter))","e6d9f0d9":"features=np.array(features)\nprint(\"Before reshape,features.shape:\",features.shape)\nfeatures=features.reshape(features.shape[0], 3*3*2048)\nprint(\"After reshape, features.shape:\",features.shape)","a5b826df":"from sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\ntargets=le.fit_transform(targets)","e94be152":"print(\"features.shape:\",features.shape)\nprint(\"targets.shape:\",targets.shape)","6600002f":"X_train, X_test, y_train, y_test=train_test_split(features, targets, test_size=0.2, random_state=42)","0710e06f":"clf=LogisticRegression(solver=\"lbfgs\")\nprint(\"{} training...\".format(clf.__class__.__name__))\nclf.fit(X_train, y_train)\ny_pred=clf.predict(X_test)\nprint(\"The model trained and used to predict the test data...\")","cc54f59b":"print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(\"Confusion Matrix:\\n\",metrics.confusion_matrix(y_test, y_pred))\nprint(\"Classification Report:\\n\",metrics.classification_report(y_test, y_pred, target_names=[\"cat\", \"dog\"]))","f8cc8622":"#from sklearn.model_selection import cross_val_score\n#cv_scores=cross_val_score(LogisticRegression(solver=\"lbfgs\"), features, targets, cv=3 )\n#print(\"Cross validation scores obtained...\")\n#print(\"Cross validated scores:{}\".format(cv_scores))\n#print(\"Mean of cross validated scores:{:.3f}\".format(cv_scores.mean()))","6a144f7f":"# Import Packages","b12eb686":"# Build Model\n\n![image.png](attachment:c3174a7a-b725-482c-9769-903d09a52ab2.png)","51bc3357":"- Early stopping: if there is no change in model the neural network will stop after patience() steps for preventing Overfitting.\n\n- Learning Rate reduction : it will reduce the learning rate when then accuracy not increase for 2 steps.","63f38fa1":"# Feature Extraction\n**We will extract feature using Inceptionv3(It is a Transfer Learning Method)**","545862dc":"# Load Data\nAs we see train and test both are zip file.So we have to unzip them and extract there data ","56368c91":"# Cross_validation\n**If you want to check cross val score just uncomment next cell then you will get your cross val score**","d5ba10ca":"# Data Augmentation"}}