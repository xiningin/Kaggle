{"cell_type":{"52d353b1":"code","bcb25386":"code","351c08dd":"code","d04309de":"code","e8a7b39a":"code","7a337e13":"code","e9287c1c":"code","c813cb75":"code","35b145fc":"code","abd9d317":"code","aff85b86":"markdown"},"source":{"52d353b1":"import warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_absolute_error as mae\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay","bcb25386":"train = pd.read_csv('\/kaggle\/input\/ventilator-pressure-prediction\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/ventilator-pressure-prediction\/test.csv')\nss = pd.read_csv('\/kaggle\/input\/ventilator-pressure-prediction\/sample_submission.csv')","351c08dd":"def fe(data):\n    data['u_in_lag1'] = data['u_in'].shift(1)\n    data['u_in_lag2'] = data['u_in'].shift(2)\n    data['u_in_lag3'] = data['u_in'].shift(3)\n    data['u_in_lag4'] = data['u_in'].shift(4)\n    data['ts_lag1'] = data['time_step'].shift(1)\n    data.loc[data['time_step'] == 0, 'ts_lag1'] = 0\n    data['area'] = data['u_in'] * (data['time_step'] - data['ts_lag1'])\n    data = data.fillna(0)\n    data['sum_area'] = data.groupby('breath_id')['area'].cumsum()\n    \n    data['u_inout'] = data['u_in'] * data['u_out']\n    data['u_in_time'] = data['u_in'] * data['time_step']\n    data['u_out_time'] = data['time_step'] * data['u_out']\n    \n    data['rolling_10_mean'] = data.groupby('breath_id')['u_in'].rolling(window=10, min_periods=1).mean().reset_index(level=0,drop=True)\n    data['rolling_10_std'] = data.groupby('breath_id')['u_in'].rolling(window=10, min_periods=1).std().reset_index(level=0,drop=True)\n    data['expand_mean'] = data.groupby('breath_id')['u_in'].expanding(2).mean().reset_index(level=0,drop=True)\n    data['expand_std'] = data.groupby('breath_id')['u_in'].expanding(2).std().reset_index(level=0,drop=True)\n    data['ewm_u_in_mean'] = data.groupby('breath_id')['u_in'].ewm(halflife=10).mean().reset_index(level=0,drop=True)\n    data['ewm_u_in_std'] = data.groupby('breath_id')['u_in'].ewm(halflife=10).std().reset_index(level=0,drop=True)\n    data = data.fillna(0)\n    \n    data['R'] = data['R'].astype(str)\n    data['C'] = data['C'].astype(str)\n    data['RC'] = data['R'] + data['C']\n    data = pd.get_dummies(data)\n    \n    return data","d04309de":"train = fe(train)\ntest = fe(test)","e8a7b39a":"train.drop(['id', 'breath_id'], axis = 1, inplace = True)\ntest.drop(['id', 'breath_id'], axis = 1, inplace = True)","7a337e13":"features = train.columns.tolist()\nfeatures = [col for col in features if col not in ['pressure']]","e9287c1c":"RS = RobustScaler()\ntrain[features] = RS.fit_transform(train[features])\ntest[features] = RS.transform(test[features])","c813cb75":"targets = train[['pressure']].to_numpy().reshape(-1, 80)\ntrain.drop('pressure', axis = 1, inplace = True)\ntrain = train.to_numpy().reshape(-1, 80, train.shape[-1])\ntest = test.to_numpy().reshape(-1, 80, test.shape[-1])","35b145fc":"EPOCH = 300\nBATCH_SIZE = 1024\n\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\nwith tpu_strategy.scope():\n    kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n    test_preds = []\n    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n        print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n        X_train, X_valid = train[train_idx], train[test_idx]\n        y_train, y_valid = targets[train_idx], targets[test_idx]\n        model = keras.models.Sequential([\n            keras.layers.Input(shape = train.shape[-2:]),\n            keras.layers.Bidirectional(keras.layers.LSTM(320, return_sequences = True)),\n            keras.layers.Bidirectional(keras.layers.LSTM(240, return_sequences = True)),\n            keras.layers.Bidirectional(keras.layers.LSTM(160, return_sequences = True)),\n            keras.layers.Dense(80, activation = 'selu'),\n            keras.layers.Dense(1),\n        ])\n        model.compile(optimizer = \"adam\", loss = \"mae\")\n\n        scheduler = ExponentialDecay(1e-3, 400*((len(train)*0.8)\/BATCH_SIZE), 1e-5)\n        lr = LearningRateScheduler(scheduler, verbose = 1)\n\n        model.fit(X_train, y_train, validation_data = (X_valid, y_valid), epochs = EPOCH, batch_size = BATCH_SIZE, callbacks = [lr])\n\n        test_preds.append(model.predict(test).squeeze().reshape(-1, 1).squeeze())","abd9d317":"ss['pressure'] = sum(test_preds) \/ 5\nss.to_csv('lstm7.csv', index = False)","aff85b86":"# MODEL"}}