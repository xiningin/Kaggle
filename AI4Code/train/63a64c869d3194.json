{"cell_type":{"189aace1":"code","a35b8908":"code","8b1aa746":"code","2d135a83":"code","3c8f456b":"code","df3f5ae2":"code","cef40108":"code","b3eb4808":"code","9f64ba4f":"code","5c43494a":"code","fba1897e":"code","16fd5854":"code","9b6f56d7":"code","5c67a5f3":"code","ff881dd7":"code","b40d343c":"code","de3e1bd3":"code","96e842e1":"code","453a5be2":"code","90790699":"code","900f9e3c":"code","1d3d9bcf":"code","299c714c":"code","1d32aa5a":"code","4e0a6aa8":"code","8d75d389":"code","bb991c15":"code","77b53f61":"code","18e5905e":"code","9a065eb1":"code","be2ed090":"code","0bce8609":"code","40ac4f81":"code","484abd55":"code","657b778e":"code","39f877ef":"code","cd257e78":"code","22cdeb89":"code","ffd0ff9f":"code","334559fe":"code","c00317c1":"code","ef8ad480":"code","a6cc80c2":"code","e21aea2a":"code","56cbf88e":"code","53f43248":"code","ca0c07ee":"code","c2dfcce2":"code","cb03a2f5":"code","b2822aec":"code","d299b058":"code","bec0e86c":"code","b9e522f5":"code","13bffe04":"code","96337889":"code","4422e7b0":"code","1fce7615":"code","356191ce":"code","55855b59":"code","9d35b356":"code","943dde27":"code","ee25a32d":"code","848cbb1e":"code","d9181089":"code","f656b930":"code","a4996020":"code","baab6e12":"code","78de9117":"code","09c61152":"code","3f77a580":"code","9d85882e":"code","e127b96b":"code","6700413c":"code","253709eb":"code","172026b5":"code","c07c98f7":"code","d779dcbe":"code","ed9bca41":"code","6b4b7b26":"code","568b9f39":"code","07c69f8e":"code","204fbb80":"code","bcd9bcdc":"code","013da25a":"code","70c60c85":"code","80accb0d":"code","5e205193":"code","e0873eff":"code","218e1dd2":"code","a6ff191d":"code","fed30474":"code","0df3b74b":"code","c636a518":"code","59b6fc32":"markdown","1e8a9866":"markdown","478346b6":"markdown","435d0ebd":"markdown","ca90b5ad":"markdown","4cd55cd0":"markdown","e6db674f":"markdown","4e1fb994":"markdown","0d6f34a7":"markdown","29db0906":"markdown","3cd74b69":"markdown","78685737":"markdown","7dacf064":"markdown","c1c23710":"markdown","db16b3e7":"markdown","c2f60446":"markdown","39e93488":"markdown","b3da51eb":"markdown","26e7c942":"markdown","818b2fae":"markdown","f040041c":"markdown","43da3632":"markdown"},"source":{"189aace1":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\n\ntrain = pd.read_csv(\"..\/input\/train.tsv\", sep = '\\t')\ntest = pd.read_csv(\"..\/input\/test.tsv\", sep = '\\t')\nsub = pd.read_csv(\"..\/input\/sampleSubmission.csv\")","a35b8908":"train['Phrase'] = train['Phrase'].str.replace(r'\\'s', '')\ntrain['Phrase'] = train['Phrase'].str.replace(r'.', '')\ntrain['Phrase'] = train['Phrase'].str.replace(r',', '')\ntrain['Phrase'] = train['Phrase'].str.replace(r'does n\\'t', 'does not')\ntrain['Phrase'] = train['Phrase'].str.replace(r'is n\\'t', 'is not')\ntrain['Phrase'] = train['Phrase'].str.replace(r'were n\\'t', 'were not')\ntrain['Phrase'] = train['Phrase'].str.replace(r'are n\\'t', 'are not')\ntrain['Phrase'] = train['Phrase'].str.replace(r'had n\\'t', 'had not')\ntrain['Phrase'] = train['Phrase'].str.replace(r'have n\\'t', 'have not')\ntrain['Phrase'] = train['Phrase'].str.replace(r'would n\\'t', 'would not')\ntrain['Phrase'] = train['Phrase'].str.replace(r'ca n\\'t', 'can not')\ntrain['Phrase'] = train['Phrase'].str.replace(r'could n\\'t', 'could not')\ntrain['Phrase'] = train['Phrase'].str.replace(r'must n\\'t', 'must not')\ntrain['Phrase'] = train['Phrase'].str.replace(r'should n\\'t', 'should not')\ntrain['Phrase'] = train['Phrase'].str.replace(r'wo n\\'t', 'will not')\ntrain['Phrase'] = train['Phrase'].str.replace(r'n\\'t', 'not')","8b1aa746":"test['Phrase'] = test['Phrase'].str.replace(r'\\'s', '')\ntest['Phrase'] = test['Phrase'].str.replace(r'.', '')\ntest['Phrase'] = test['Phrase'].str.replace(r',', '')\ntest['Phrase'] = test['Phrase'].str.replace(r'does n\\'t', 'does not')\ntest['Phrase'] = test['Phrase'].str.replace(r'is n\\'t', 'is not')\ntest['Phrase'] = test['Phrase'].str.replace(r'were n\\'t', 'were not')\ntest['Phrase'] = test['Phrase'].str.replace(r'are n\\'t', 'are not')\ntest['Phrase'] = test['Phrase'].str.replace(r'had n\\'t', 'had not')\ntest['Phrase'] = test['Phrase'].str.replace(r'have n\\'t', 'have not')\ntest['Phrase'] = test['Phrase'].str.replace(r'would n\\'t', 'would not')\ntest['Phrase'] = test['Phrase'].str.replace(r'ca n\\'t', 'can not')\ntest['Phrase'] = test['Phrase'].str.replace(r'could n\\'t', 'could not')\ntest['Phrase'] = test['Phrase'].str.replace(r'must n\\'t', 'must not')\ntest['Phrase'] = test['Phrase'].str.replace(r'should n\\'t', 'should not')\ntest['Phrase'] = test['Phrase'].str.replace(r'wo n\\'t', 'will not')\ntest['Phrase'] = test['Phrase'].str.replace(r'n\\'t', 'not')","2d135a83":"y_train = train['Sentiment']","3c8f456b":"#train = train.drop('Sentiment', axis=1)\n#train","df3f5ae2":"# Vectorization\n\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ncv = CountVectorizer(binary=True)\ncv.fit(train.Phrase)\nX = cv.transform(train.Phrase)\nX_test = cv.transform(test.Phrase)","cef40108":"pos = [3,4]\nneg = [0,1]\nneutral = 2\n\ntrain_pos = train[train.Sentiment.isin(pos)]\ntrain_pos = train_pos['Phrase']\ntrain_neg = train[train.Sentiment.isin(neg)]\ntrain_neg = train_neg['Phrase']","b3eb4808":"from wordcloud import WordCloud,STOPWORDS\n\ndef wordcloud_draw(data, color = 'black'):\n    words = ' '.join(data)\n    cleaned_word = \" \".join([word for word in words.split()\n                            if not word.startswith(',')\n                            ])\n    wordcloud = WordCloud(stopwords=STOPWORDS,\n                      background_color=color,\n                      width=2500,\n                      height=2000\n                     ).generate(cleaned_word)\n    plt.figure(1,figsize=(13, 13))\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()\n    \nprint(\"Positive words\")\nwordcloud_draw(train_pos,'white')\nprint(\"Negative words\")\nwordcloud_draw(train_neg)","9f64ba4f":"# Building Classifier","5c43494a":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings('ignore')\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y_train, train_size = 0.75\n)\n\nfor c in [0.01, 0.05, 0.25, 0.5, 1]:\n    \n    lr = LogisticRegression(C=c)\n    lr.fit(X_train, y_train)\n    print (\"Accuracy for C=%s: %s\" \n           % (c, accuracy_score(y_val, lr.predict(X_val))))","fba1897e":"y_train.shape","16fd5854":"final_model = LogisticRegression(C=1)\n\nfinal_model.fit(X_train, y_train)","9b6f56d7":"len(cv.get_feature_names())","5c67a5f3":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer()\ncv.fit(train.Phrase)","ff881dd7":"neg_doc_mat = train.Phrase[train['Sentiment'] == 0]\nneg_document_matrix = cv.transform(train.Phrase[train['Sentiment'] == 0])","b40d343c":"pos_doc_mat = train.Phrase[train['Sentiment'] == 4]\npos_document_matrix = cv.transform(pos_doc_mat)","de3e1bd3":"neu_doc_mat = train.Phrase[train['Sentiment'] == 2]\nneu_document_matrix = cv.transform(neu_doc_mat)","96e842e1":"sneg_doc_mat = train.Phrase[train['Sentiment'] == 1]\nsneg_document_matrix = cv.transform(sneg_doc_mat)","453a5be2":"spos_doc_mat = train.Phrase[train['Sentiment'] == 3]\nspos_document_matrix = cv.transform(spos_doc_mat)","90790699":"%%time\nneg_batches = np.linspace(0,156061,100).astype(int)\ni=0\nneg_tf = []\nwhile i < len(neg_batches)-1:\n    batch_result = np.sum(neg_document_matrix[neg_batches[i]:neg_batches[i+1]].toarray(),axis=0)\n    neg_tf.append(batch_result)\n    if (i % 10 == 0) | (i == len(neg_batches)-2):\n        print(neg_batches[i+1],\"entries' term frequency calculated\")\n    i += 1","900f9e3c":"%%time\npos_batches = np.linspace(0,156061,100).astype(int)\ni=0\npos_tf = []\nwhile i < len(pos_batches)-1:\n    batch_result = np.sum(pos_document_matrix[pos_batches[i]:pos_batches[i+1]].toarray(),axis=0)\n    pos_tf.append(batch_result)\n    if (i % 10 == 0) | (i == len(pos_batches)-2):\n        print(pos_batches[i+1],\"entries' term frequency calculated\")\n    i += 1","1d3d9bcf":"%%time\nneu_batches = np.linspace(0,156061,100).astype(int)\ni=0\nneu_tf = []\nwhile i < len(neu_batches)-1:\n    batch_result = np.sum(neu_document_matrix[neu_batches[i]:neu_batches[i+1]].toarray(),axis=0)\n    neu_tf.append(batch_result)\n    if (i % 10 == 0) | (i == len(neu_batches)-2):\n        print(neu_batches[i+1],\"entries' term frequency calculated\")\n    i += 1","299c714c":"%%time\nsneg_batches = np.linspace(0,156061,100).astype(int)\ni=0\nsneg_tf = []\nwhile i < len(sneg_batches)-1:\n    batch_result = np.sum(sneg_document_matrix[sneg_batches[i]:sneg_batches[i+1]].toarray(),axis=0)\n    sneg_tf.append(batch_result)\n    if (i % 10 == 0) | (i == len(sneg_batches)-2):\n        print(sneg_batches[i+1],\"entries' term frequency calculated\")\n    i += 1","1d32aa5a":"%%time\nspos_batches = np.linspace(0,156061,100).astype(int)\ni=0\nspos_tf = []\nwhile i < len(spos_batches)-1:\n    batch_result = np.sum(spos_document_matrix[spos_batches[i]:spos_batches[i+1]].toarray(),axis=0)\n    spos_tf.append(batch_result)\n    if (i % 10 == 0) | (i == len(spos_batches)-2):\n        print(spos_batches[i+1],\"entries' term frequency calculated\")\n    i += 1","4e0a6aa8":"neg = np.sum(neg_tf,axis=0)\npos = np.sum(pos_tf,axis=0)\nneu = np.sum(neu_tf,axis=0)\nsneg = np.sum(sneg_tf,axis=0)\nspos = np.sum(spos_tf,axis=0)\nterm_freq_df = pd.DataFrame([neg,pos, neu, sneg, spos],columns=cv.get_feature_names()).transpose()\nterm_freq_df.head()","8d75d389":"term_freq_df.columns = ['negative', 'positive', 'neutral', 'somewhat negative', 'somewhat positive']\nterm_freq_df['total'] = term_freq_df['negative'] + term_freq_df['positive'] + term_freq_df['neutral'] + term_freq_df['somewhat negative'] + term_freq_df['somewhat positive']\nterm_freq_df.sort_values(by='total', ascending=False).iloc[:10]","bb991c15":"type(term_freq_df)","77b53f61":"neg_phrases = train[train.Sentiment == 0]\nneg_string = []\nfor t in neg_phrases.Phrase:\n    neg_string.append(t)\nneg_string = pd.Series(neg_string).str.cat(sep=' ')\nfrom wordcloud import WordCloud\n\nwordcloud = WordCloud(width=1600, height=800,max_font_size=200).generate(neg_string)\nplt.figure(figsize=(12,10))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","18e5905e":"pos_phrases = train[train.Sentiment == 4]\npos_string = []\nfor t in pos_phrases.Phrase:\n    pos_string.append(t)\npos_string = pd.Series(pos_string).str.cat(sep=' ')\nfrom wordcloud import WordCloud\n\nwordcloud = WordCloud(width=1600, height=800,max_font_size=200).generate(pos_string)\nplt.figure(figsize=(12,10))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","9a065eb1":"y_pos = np.arange(500)\nplt.figure(figsize=(10,8))\ns = 1\nexpected_zipf = [term_freq_df.sort_values(by='total', ascending=False)['total'][0]\/(i+1)**s for i in y_pos]\nplt.bar(y_pos, term_freq_df.sort_values(by='total', ascending=False)['total'][:500], align='center', alpha=0.5)\nplt.plot(y_pos, expected_zipf, color='r', linestyle='--',linewidth=2,alpha=0.5)\nplt.ylabel('Frequency')\nplt.title('Top 500 tokens in the Phrases')","be2ed090":"from sklearn.feature_extraction.text import CountVectorizer\ncvec = CountVectorizer(stop_words='english',max_features=10000)\ncvec.fit(train.Phrase)","0bce8609":"neg_document_matrix_nostop = cvec.transform(train.Phrase[train['Sentiment'] == 0])","40ac4f81":"%%time\nneg_batches = np.linspace(0,156061,100).astype(int)\ni=0\nneg_tf = []\nwhile i < len(neg_batches)-1:\n    batch_result = np.sum(neg_document_matrix_nostop[neg_batches[i]:neg_batches[i+1]].toarray(),axis=0)\n    neg_tf.append(batch_result)\n    print(neg_batches[i+1],\"entries' term frequency calculated\")\n    i += 1","484abd55":"pos_document_matrix_nostop = cvec.transform(train.Phrase[train['Sentiment'] == 4])","657b778e":"%%time\npos_batches = np.linspace(0,156061,100).astype(int)\ni=0\npos_tf = []\nwhile i < len(pos_batches)-1:\n    batch_result = np.sum(pos_document_matrix_nostop[pos_batches[i]:pos_batches[i+1]].toarray(),axis=0)\n    pos_tf.append(batch_result)\n    print(pos_batches[i+1],\"entries' term frequency calculated\")\n    i += 1","39f877ef":"neg = np.sum(neg_tf,axis=0)\npos = np.sum(pos_tf,axis=0)\nterm_freq_df2 = pd.DataFrame([neg,pos],columns=cvec.get_feature_names()).transpose()\nterm_freq_df2.columns = ['negative', 'positive']\nterm_freq_df2['total'] = term_freq_df2['negative'] + term_freq_df2['positive']\nterm_freq_df2.sort_values(by='total', ascending=False).iloc[:10]","cd257e78":"y_pos = np.arange(50)\nplt.figure(figsize=(12,10))\nplt.bar(y_pos, term_freq_df2.sort_values(by='negative', ascending=False)['negative'][:50], align='center', alpha=0.5)\nplt.xticks(y_pos, term_freq_df2.sort_values(by='negative', ascending=False)['negative'][:50].index,rotation='vertical')\nplt.ylabel('Frequency')\nplt.xlabel('Top 50 negative words')\nplt.title('Top 50 tokens in negative sentiments')","22cdeb89":"y_pos = np.arange(50)\nplt.figure(figsize=(12,10))\nplt.bar(y_pos, term_freq_df2.sort_values(by='positive', ascending=False)['positive'][:50], align='center', alpha=0.5)\nplt.xticks(y_pos, term_freq_df2.sort_values(by='positive', ascending=False)['positive'][:50].index,rotation='vertical')\nplt.ylabel('Frequency')\nplt.xlabel('Top 50 positive tokens')\nplt.title('Top 50 tokens in positive sentiments')","ffd0ff9f":"import seaborn as sns\nplt.figure(figsize=(8,6))\nax = sns.regplot(x=\"negative\", y=\"positive\",fit_reg=False, scatter_kws={'alpha':0.5},data=term_freq_df2)\nplt.ylabel('Positive Frequency')\nplt.xlabel('Negative Frequency')\nplt.title('Negative Frequency vs Positive Frequency')","334559fe":"term_freq_df2['pos_rate'] = term_freq_df2['positive'] * 1.\/term_freq_df2['total']\nterm_freq_df2.sort_values(by='pos_rate', ascending=False).iloc[:10]","c00317c1":"term_freq_df2['pos_freq_pct'] = term_freq_df2['positive'] * 1.\/term_freq_df2['positive'].sum()\nterm_freq_df2.sort_values(by='pos_freq_pct', ascending=False).iloc[:10]","ef8ad480":"from scipy.stats import hmean\n\nterm_freq_df2['pos_hmean'] = term_freq_df2.apply(lambda x: (hmean([x['pos_rate'], x['pos_freq_pct']])\n                                                                   if x['pos_rate'] > 0 and x['pos_freq_pct'] > 0 \n                                                                   else 0), axis=1)                                                        \nterm_freq_df2.sort_values(by='pos_hmean', ascending=False).iloc[:10]","a6cc80c2":"import warnings\nwarnings.filterwarnings('ignore')\n\nterm_freq_df2['neg_rate'] = term_freq_df2['negative'] * 1.\/term_freq_df2['total']\nterm_freq_df2['neg_freq_pct'] = term_freq_df2['negative'] * 1.\/term_freq_df2['negative'].sum()\nterm_freq_df2['neg_hmean'] = term_freq_df2.apply(lambda x: (hmean([x['neg_rate'], x['neg_freq_pct']])\n                                                                   if x['neg_rate'] > 0 and x['neg_freq_pct'] > 0 \n                                                                   else 0), axis=1)                                                        \n#term_freq_df2['neg_rate_normcdf'] = normcdf(term_freq_df2['neg_rate'])\n#term_freq_df2['neg_freq_pct_normcdf'] = normcdf(term_freq_df2['neg_freq_pct'])\n#term_freq_df2['neg_normcdf_hmean'] = hmean([term_freq_df2['neg_rate_normcdf'], term_freq_df2['neg_freq_pct_normcdf']])\n#term_freq_df2.sort_values(by='neg_normcdf_hmean', ascending=False).iloc[:10]","e21aea2a":"from scipy.stats import norm\ndef normcdf(x):\n    return norm.cdf(x, x.mean(), x.std())\n\nterm_freq_df2['pos_rate_normcdf'] = normcdf(term_freq_df2['pos_rate'])\nterm_freq_df2['pos_freq_pct_normcdf'] = normcdf(term_freq_df2['pos_freq_pct'])\n#term_freq_df2['pos_normcdf_hmean'] = hmean([term_freq_df2['pos_rate_normcdf'], term_freq_df2['pos_freq_pct_normcdf']])\n#term_freq_df2.sort_values(by='pos_normcdf_hmean', ascending=False).iloc[:10]","56cbf88e":"plt.figure(figsize=(8,6))\nax = sns.regplot(x=\"neg_hmean\", y=\"pos_hmean\",fit_reg=False, scatter_kws={'alpha':0.5},data=term_freq_df2)\nplt.ylabel('Positive Rate and Frequency Harmonic Mean')\nplt.xlabel('Negative Rate and Frequency Harmonic Mean')\nplt.title('neg hmean vs pos hmean')","53f43248":"x = train.Phrase\ny = train.Sentiment\nfrom sklearn.cross_validation import train_test_split\n\nSEED = 2000\n\nx_train, x_validation_and_test, y_train, y_validation_and_test = train_test_split(x, y, test_size=.02, random_state=SEED)\nx_validation, x_test, y_validation, y_test = train_test_split(x_validation_and_test, y_validation_and_test, test_size=.5, random_state=SEED)","ca0c07ee":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom time import time\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score","c2dfcce2":"def accuracy_summary(pipeline, x_train, y_train, x_test, y_test):\n    if len(x_test[y_test == 0]) \/ (len(x_test)*1.) > 0.5:\n        null_accuracy = len(x_test[y_test == 0]) \/ (len(x_test)*1.)\n    else:\n        null_accuracy = 1. - (len(x_test[y_test == 0]) \/ (len(x_test)*1.))\n    t0 = time()\n    sentiment_fit = pipeline.fit(x_train, y_train)\n    y_pred = sentiment_fit.predict(x_test)\n    train_test_time = time() - t0\n    accuracy = accuracy_score(y_test, y_pred)\n    print(\"null accuracy: {0:.2f}%\".format(null_accuracy*100))\n    print(\"accuracy score: {0:.2f}%\".format(accuracy*100))\n    if accuracy > null_accuracy:\n        print(\"model is {0:.2f}% more accurate than null accuracy\".format((accuracy-null_accuracy)*100))\n    elif accuracy == null_accuracy:\n        print(\"model has the same accuracy with the null accuracy\")\n    else:\n        print(\"model is {0:.2f}% less accurate than null accuracy\".format((null_accuracy-accuracy)*100))\n    print(\"train and test time: {0:.2f}s\".format(train_test_time))\n    print(\"-\"*80)\n    return accuracy, train_test_time\ncvec = CountVectorizer()\nlr = LogisticRegression()\nn_features = np.arange(10000,100001,10000)\n\ndef nfeature_accuracy_checker(vectorizer=cvec, n_features=n_features, stop_words=None, ngram_range=(1, 1), classifier=lr):\n    result = []\n    print (classifier)\n    print(\"\\n\")\n    for n in n_features:\n        vectorizer.set_params(stop_words=stop_words, max_features=n, ngram_range=ngram_range)\n        checker_pipeline = Pipeline([\n            ('vectorizer', vectorizer),\n            ('classifier', classifier)\n        ])\n        print(\"Validation result for {} features\".format(n))\n        nfeature_accuracy,tt_time = accuracy_summary(checker_pipeline, x_train, y_train, x_validation, y_validation)\n        result.append((n,nfeature_accuracy,tt_time))\n    return result","cb03a2f5":"# Just to check if these top 10 words in term frequency data frame are actually included in Sklearn\u2019s stop words list","b2822aec":"from sklearn.feature_extraction import text\n\na = frozenset(list(term_freq_df.sort_values(by='total', ascending=False).iloc[:10].index))\nb = text.ENGLISH_STOP_WORDS\nset(a).issubset(set(b))","d299b058":"my_stop_words = frozenset(list(term_freq_df.sort_values(by='total', ascending=False).iloc[:10].index))","bec0e86c":"print(\"RESULT FOR UNIGRAM WITHOUT STOP WORDS\\n\")\nfeature_result_wosw = nfeature_accuracy_checker(stop_words='english')\n\nprint(\"RESULT FOR UNIGRAM WITH STOP WORDS\\n\")\nfeature_result_ug = nfeature_accuracy_checker()\n\nprint(\"RESULT FOR UNIGRAM WITHOUT CUSTOM STOP WORDS (Top 10 frequent words)\\n\")\nfeature_result_wocsw = nfeature_accuracy_checker(stop_words=my_stop_words)","b9e522f5":"nfeatures_plot_ug = pd.DataFrame(feature_result_ug,columns=['nfeatures','validation_accuracy','train_test_time'])\nnfeatures_plot_ug_wocsw = pd.DataFrame(feature_result_wocsw,columns=['nfeatures','validation_accuracy','train_test_time'])\nnfeatures_plot_ug_wosw = pd.DataFrame(feature_result_wosw,columns=['nfeatures','validation_accuracy','train_test_time'])\n\nplt.figure(figsize=(8,6))\nplt.plot(nfeatures_plot_ug.nfeatures, nfeatures_plot_ug.validation_accuracy, label='with stop words')\nplt.plot(nfeatures_plot_ug_wocsw.nfeatures, nfeatures_plot_ug_wocsw.validation_accuracy,label='without custom stop words')\nplt.plot(nfeatures_plot_ug_wosw.nfeatures, nfeatures_plot_ug_wosw.validation_accuracy,label='without stop words')\nplt.title(\"Without stop words VS With stop words (Unigram): Accuracy\")\nplt.xlabel(\"Number of features\")\nplt.ylabel(\"Validation set accuracy\")\nplt.legend()","13bffe04":"print(\"RESULT FOR BIGRAM WITH STOP WORDS\\n\")\nfeature_result_bg = nfeature_accuracy_checker(ngram_range=(1, 2))\n\nprint(\"RESULT FOR TRIGRAM WITH STOP WORDS\\n\")\nfeature_result_tg = nfeature_accuracy_checker(ngram_range=(1, 3))","96337889":"nfeatures_plot_tg = pd.DataFrame(feature_result_tg,columns=['nfeatures','validation_accuracy','train_test_time'])\nnfeatures_plot_bg = pd.DataFrame(feature_result_bg,columns=['nfeatures','validation_accuracy','train_test_time'])\nnfeatures_plot_ug = pd.DataFrame(feature_result_ug,columns=['nfeatures','validation_accuracy','train_test_time'])\n\nplt.figure(figsize=(8,6))\nplt.plot(nfeatures_plot_tg.nfeatures, nfeatures_plot_tg.validation_accuracy,label='trigram')\nplt.plot(nfeatures_plot_bg.nfeatures, nfeatures_plot_bg.validation_accuracy,label='bigram')\nplt.plot(nfeatures_plot_ug.nfeatures, nfeatures_plot_ug.validation_accuracy, label='unigram')\nplt.title(\"N-gram(1~3) test result : Accuracy\")\nplt.xlabel(\"Number of features\")\nplt.ylabel(\"Validation set accuracy\")\nplt.legend()","4422e7b0":"print(\"RESULT FOR BIGRAM WITHOUT STOP WORDS\\n\")\nfeature_result_bg_nostop = nfeature_accuracy_checker(ngram_range=(1, 2), stop_words='english')\n\nprint(\"RESULT FOR TRIGRAM WITHOUT STOP WORDS\\n\")\nfeature_result_tg_nostop = nfeature_accuracy_checker(ngram_range=(1, 3), stop_words='english')","1fce7615":"nfeatures_plot_bg_nostop = pd.DataFrame(feature_result_bg_nostop,columns=['nfeatures','validation_accuracy','train_test_time'])\nnfeatures_plot_tg_nostop = pd.DataFrame(feature_result_tg_nostop,columns=['nfeatures','validation_accuracy','train_test_time'])\n\nplt.figure(figsize=(8,6))\nplt.plot(nfeatures_plot_tg_nostop.nfeatures, nfeatures_plot_tg_nostop.validation_accuracy,label='trigram')\nplt.plot(nfeatures_plot_bg_nostop.nfeatures, nfeatures_plot_bg_nostop.validation_accuracy,label='bigram')\nplt.title(\"N-gram(2~3) test result : Accuracy\")\nplt.xlabel(\"Number of features\")\nplt.ylabel(\"Validation set accuracy\")\nplt.legend()","356191ce":"plt.figure(figsize=(8,6))\nplt.plot(nfeatures_plot_bg.nfeatures, nfeatures_plot_bg.validation_accuracy, label='Bigram')\nplt.plot(nfeatures_plot_bg_nostop.nfeatures, nfeatures_plot_bg_nostop.validation_accuracy, label='Bigram-Nostop')\nplt.title(\"N-gram(2~3) test result : Accuracy\")\nplt.xlabel(\"Number of features\")\nplt.ylabel(\"Validation set accuracy\")\nplt.legend()","55855b59":"def train_test_and_evaluate(pipeline, x_train, y_train, x_test, y_test):\n    if len(x_test[y_test == 0]) \/ (len(x_test)*1.) > 0.5:\n        null_accuracy = len(x_test[y_test == 0]) \/ (len(x_test)*1.)\n    else:\n        null_accuracy = 1. - (len(x_test[y_test == 0]) \/ (len(x_test)*1.))\n    sentiment_fit = pipeline.fit(x_train, y_train)\n    \n    y_pred = sentiment_fit.predict(x_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    conmat = np.array(confusion_matrix(y_test, y_pred, labels=[0,1,2,3,4]))\n    confusion = pd.DataFrame(conmat, index=['negative','somewhat negative', 'neutral','somewhat positive', 'positive'],\n                         columns=['predicted negative','predicted somewhat negative', 'predicted neutral','predicted somewhat positive', 'predicted positive'])\n    \n    print(\"null accuracy: {0:.2f}%\".format(null_accuracy*100))\n    print(\"accuracy score: {0:.2f}%\".format(accuracy*100))\n    if accuracy > null_accuracy:\n        print(\"model is {0:.2f}% more accurate than null accuracy\".format((accuracy-null_accuracy)*100))\n    elif accuracy == null_accuracy:\n        print(\"model has the same accuracy with the null accuracy\")\n    else:\n        print(\"model is {0:.2f}% less accurate than null accuracy\".format((null_accuracy-accuracy)*100))\n    print(\"-\"*80)\n    print(\"Confusion Matrix\\n\")\n    print(confusion)\n    print(\"-\"*80)\n    print(\"Classification Report\\n\")\n    print(classification_report(y_test, y_pred, target_names=['negative','somewhat negative', 'neutral','somewhat positive', 'positive']))","9d35b356":"%%time\ntg_cvec = CountVectorizer(max_features=80000,ngram_range=(1, 3))\ntg_pipeline = Pipeline([\n        ('vectorizer', tg_cvec),\n        ('classifier', lr)\n    ])\ntrain_test_and_evaluate(tg_pipeline, x_train, y_train, x_validation, y_validation)","943dde27":"%%time\nbg_cvec = CountVectorizer(max_features=80000,ngram_range=(1, 2))\nbg_pipeline = Pipeline([\n        ('vectorizer', bg_cvec),\n        ('classifier', lr)\n    ])\ntrain_test_and_evaluate(bg_pipeline, x_train, y_train, x_validation, y_validation)","ee25a32d":"cv_train = bg_cvec.fit_transform(train.Phrase)\nprint(cv_train.shape)\n\ncv_test = bg_cvec.transform(test.Phrase)\nprint(cv_test.shape)","848cbb1e":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import MultinomialNB, BernoulliNB\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.neighbors import NearestCentroid\nfrom sklearn.feature_selection import SelectFromModel\n\nlr = LogisticRegression()\nmn = MultinomialNB()\nbnb = BernoulliNB()\nrc = RidgeClassifier()\nabc = AdaBoostClassifier()\nlsvc = LinearSVC()\n\nlr.fit(cv_train,y)\nmn.fit(cv_train,y)\nbnb.fit(cv_train,y)\nrc.fit(cv_train,y)\nabc.fit(cv_train,y)\nlsvc.fit(cv_train,y)","d9181089":"lr_y_pred = lr.predict(cv_test)\n\nlr_sub = pd.DataFrame({\"PhraseId\": sub['PhraseId'], \"Sentiment\" : lr_y_pred})\n\nlr_sub.to_csv(\"LR_submission.csv\",index=False)","f656b930":"mn_y_pred = mn.predict(cv_test)\n\nmn_sub = pd.DataFrame({\"PhraseId\": sub['PhraseId'], \"Sentiment\" : mn_y_pred})\n\nmn_sub.to_csv(\"MN_submission.csv\",index=False)","a4996020":"rc_y_pred = rc.predict(cv_test)\n\nrc_sub = pd.DataFrame({\"PhraseId\": sub['PhraseId'], \"Sentiment\" : rc_y_pred})\n\nrc_sub.to_csv(\"RC_submission.csv\",index=False)","baab6e12":"abc_y_pred = abc.predict(cv_test)\n\nabc_sub = pd.DataFrame({\"PhraseId\": sub['PhraseId'], \"Sentiment\" : abc_y_pred})\n\nabc_sub.to_csv(\"abc_submission.csv\",index=False)","78de9117":"bnb_y_pred = bnb.predict(cv_test)\n\nbnb_sub = pd.DataFrame({\"PhraseId\": sub['PhraseId'], \"Sentiment\" : bnb_y_pred})\n\nbnb_sub.to_csv(\"bnb_submission.csv\",index=False)","09c61152":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom wordcloud import WordCloud, STOPWORDS\ntvec = TfidfVectorizer(smooth_idf=False, sublinear_tf=False, norm=None, analyzer='word')","3f77a580":"txt_fitted = tvec.fit(train.Phrase)\ntxt_transformed = txt_fitted.transform(train.Phrase)","9d85882e":"idf = tvec.idf_\nprint(dict(zip(txt_fitted.get_feature_names(), idf)))","e127b96b":"# Instantiate the vectorizer\n\nword_vectorizer = TfidfVectorizer(\n    stop_words='english',\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='word',\n   # token_pattern=r'\\w{2,}',  #vectorize 2-character words or more\n    ngram_range=(1, 2),\n    max_features=80000)\n\n# fit and transform on it the training features\nword_vectorizer.fit(train.Phrase)\nX_train_word_features = word_vectorizer.transform(train.Phrase)\n\n#transform the test features to sparse matrix\ntest_features = word_vectorizer.transform(test.Phrase)","6700413c":"td_train = word_vectorizer.fit_transform(train.Phrase)\nprint(td_train.shape)\n\ntd_test = word_vectorizer.transform(test.Phrase)\nprint(td_test.shape)","253709eb":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import MultinomialNB, BernoulliNB\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.neighbors import NearestCentroid\nfrom sklearn.feature_selection import SelectFromModel\n\nlr = LogisticRegression()\nmn = MultinomialNB()\nbnb = BernoulliNB()\nrc = RidgeClassifier()\nabc = AdaBoostClassifier()\nlsvc = LinearSVC()","172026b5":"lr.fit(td_train,y)\nmn.fit(td_train,y)\nbnb.fit(td_train,y)\nrc.fit(td_train,y)\nabc.fit(td_train,y)\nlsvc.fit(td_train,y)","c07c98f7":"lr_y_pred_td = lr.predict(td_test)\n\nlr_sub_td = pd.DataFrame({\"PhraseId\": sub['PhraseId'], \"Sentiment\" : lr_y_pred_td})\n\nlr_sub_td.to_csv(\"LR_td_submission.csv\",index=False)","d779dcbe":"mn_y_pred_td = mn.predict(td_test)\n\nmn_sub_td = pd.DataFrame({\"PhraseId\": sub['PhraseId'], \"Sentiment\" : mn_y_pred_td})\n\nmn_sub_td.to_csv(\"MN_td_submission.csv\",index=False)","ed9bca41":"bnb_y_pred_td = bnb.predict(td_test)\n\nbnb_sub_td = pd.DataFrame({\"PhraseId\": sub['PhraseId'], \"Sentiment\" : bnb_y_pred_td})\n\nbnb_sub_td.to_csv(\"BN_td_submission.csv\",index=False)","6b4b7b26":"rc_y_pred_td = rc.predict(td_test)\n\nrc_sub_td = pd.DataFrame({\"PhraseId\": sub['PhraseId'], \"Sentiment\" : rc_y_pred_td})\n\nrc_sub_td.to_csv(\"RC_td_submission.csv\",index=False)","568b9f39":"abc_y_pred_td = rc.predict(td_test)\n\nabc_sub_td = pd.DataFrame({\"PhraseId\": sub['PhraseId'], \"Sentiment\" : abc_y_pred_td})\n\nabc_sub_td.to_csv(\"ABC_td_submission.csv\",index=False)","07c69f8e":"lsvc_y_pred_td = lsvc.predict(td_test)\n\nlsvc_sub_td = pd.DataFrame({\"PhraseId\": sub['PhraseId'], \"Sentiment\" : lsvc_y_pred_td})\n\nlsvc_sub_td.to_csv(\"LSVC_td_submission.csv\",index=False)","204fbb80":"%%time\nprint(\"RESULT FOR UNIGRAM WITH STOP WORDS (Tfidf)\\n\")\nfeature_result_ugt = nfeature_accuracy_checker(vectorizer=tvec)\n\nprint(\"RESULT FOR UNIGRAM WITHOUT STOP WORDS (Tfidf)\\n\")\nfeature_result_ugt_nostop = nfeature_accuracy_checker(vectorizer=tvec, stop_words = 'english')","bcd9bcdc":"max(feature_result_ugt)","013da25a":"%%time\nprint(\"RESULT FOR BIGRAM WITH STOP WORDS (Tfidf)\\n\")\nfeature_result_bgt = nfeature_accuracy_checker(vectorizer=tvec,ngram_range=(1, 2))","70c60c85":"%%time\nprint(\"RESULT FOR TRIGRAM WITH STOP WORDS (Tfidf)\\n\")\nfeature_result_tgt = nfeature_accuracy_checker(vectorizer=tvec,ngram_range=(1, 3))","80accb0d":"nfeatures_plot_tgt = pd.DataFrame(feature_result_tgt,columns=['nfeatures','validation_accuracy','train_test_time'])\nnfeatures_plot_bgt = pd.DataFrame(feature_result_bgt,columns=['nfeatures','validation_accuracy','train_test_time'])\nnfeatures_plot_ugt = pd.DataFrame(feature_result_ugt,columns=['nfeatures','validation_accuracy','train_test_time'])\n\nplt.figure(figsize=(8,6))\nplt.plot(nfeatures_plot_tgt.nfeatures, nfeatures_plot_tgt.validation_accuracy, label='trigram tfidf vectorizer',color='royalblue')\nplt.plot(nfeatures_plot_tg.nfeatures, nfeatures_plot_tg.validation_accuracy, label='trigram count vectorizer',linestyle=':', color='royalblue')\nplt.plot(nfeatures_plot_bgt.nfeatures, nfeatures_plot_bgt.validation_accuracy, label='bigram tfidf vectorizer',color='orangered')\nplt.plot(nfeatures_plot_bg.nfeatures, nfeatures_plot_bg.validation_accuracy, label='bigram count vectorizer',linestyle=':',color='orangered')\nplt.plot(nfeatures_plot_ugt.nfeatures, nfeatures_plot_ugt.validation_accuracy, label='unigram tfidf vectorizer',color='gold')\nplt.plot(nfeatures_plot_ug.nfeatures, nfeatures_plot_ug.validation_accuracy, label='unigram count vectorizer',linestyle=':',color='gold')\nplt.title(\"N-gram(1~3) test result : Accuracy\")\nplt.xlabel(\"Number of features\")\nplt.ylabel(\"Validation set accuracy\")\nplt.legend()","5e205193":"%%time\nprint(\"RESULT FOR UNIGRAM WITHOUT STOP WORDS (Tfidf)\\n\")\nfeature_result_ugt_nostop = nfeature_accuracy_checker(vectorizer=tvec, stop_words=STOPWORDS)","e0873eff":"%%time\nprint(\"RESULT FOR BIGRAM WITHOUT STOP WORDS (Tfidf)\\n\")\nfeature_result_bgt_nostop = nfeature_accuracy_checker(vectorizer=tvec,ngram_range=(1, 2),stop_words=STOPWORDS)","218e1dd2":"%%time\nprint(\"RESULT FOR TRIGRAM WITH STOP WORDS (Tfidf)\\n\")\nfeature_result_tgt_nostop = nfeature_accuracy_checker(vectorizer=tvec,ngram_range=(1, 3),stop_words=STOPWORDS)","a6ff191d":"nfeatures_plot_tgt_nostop = pd.DataFrame(feature_result_tgt_nostop,columns=['nfeatures','validation_accuracy','train_test_time'])\nnfeatures_plot_bgt_nostop = pd.DataFrame(feature_result_bgt_nostop,columns=['nfeatures','validation_accuracy','train_test_time'])\nnfeatures_plot_ugt_nostop = pd.DataFrame(feature_result_ugt_nostop,columns=['nfeatures','validation_accuracy','train_test_time'])\n\nplt.figure(figsize=(8,6))\nplt.plot(nfeatures_plot_tgt_nostop.nfeatures, nfeatures_plot_tgt.validation_accuracy,label='trigram tfidf vectorizer',color='royalblue')\nplt.plot(nfeatures_plot_tg.nfeatures, nfeatures_plot_tg.validation_accuracy,label='trigram count vectorizer',linestyle=':', color='royalblue')\nplt.plot(nfeatures_plot_bgt_nostop.nfeatures, nfeatures_plot_bgt.validation_accuracy,label='bigram tfidf vectorizer',color='orangered')\nplt.plot(nfeatures_plot_bg.nfeatures, nfeatures_plot_bg.validation_accuracy,label='bigram count vectorizer',linestyle=':',color='orangered')\nplt.plot(nfeatures_plot_ugt_nostop.nfeatures, nfeatures_plot_ugt.validation_accuracy, label='unigram tfidf vectorizer',color='gold')\nplt.plot(nfeatures_plot_ug.nfeatures, nfeatures_plot_ug.validation_accuracy, label='unigram count vectorizer',linestyle=':',color='gold')\nplt.title(\"N-gram(1~3) test result : Accuracy\")\nplt.xlabel(\"Number of features\")\nplt.ylabel(\"Validation set accuracy\")\nplt.legend()","fed30474":"print(\"RESULT FOR BIGRAM WITHOUT STOP WORDS\\n\")\nfeature_result_bg_nostop = nfeature_accuracy_checker(vectorizer=cvec, ngram_range=(1, 2), stop_words=STOPWORDS)\n\nprint(\"RESULT FOR TRIGRAM WITHOUT STOP WORDS\\n\")\nfeature_result_tg_nostop = nfeature_accuracy_checker(vectorizer=cvec, ngram_range=(1, 3), stop_words=STOPWORDS)\n\nprint(\"RESULT FOR UNIGRAM WITHOUT STOP WORDS\\n\")\nfeature_result_ug_nostop = nfeature_accuracy_checker(vectorizer=cvec, ngram_range=(1, 1), stop_words=STOPWORDS)","0df3b74b":"nfeatures_plot_tg_nostop = pd.DataFrame(feature_result_tg_nostop, columns=['nfeatures','validation_accuracy','train_test_time'])\nnfeatures_plot_bg_nostop = pd.DataFrame(feature_result_bg_nostop, columns=['nfeatures','validation_accuracy','train_test_time'])\nnfeatures_plot_ug_nostop = pd.DataFrame(feature_result_ug_nostop, columns=['nfeatures','validation_accuracy','train_test_time'])","c636a518":"nfeatures_plot_tgt_nostop = pd.DataFrame(feature_result_tgt_nostop,columns=['nfeatures','validation_accuracy','train_test_time'])\nnfeatures_plot_bgt_nostop = pd.DataFrame(feature_result_bgt_nostop,columns=['nfeatures','validation_accuracy','train_test_time'])\nnfeatures_plot_ugt_nostop = pd.DataFrame(feature_result_ugt_nostop,columns=['nfeatures','validation_accuracy','train_test_time'])\n\nplt.figure(figsize=(8,6))\nplt.plot(nfeatures_plot_tgt_nostop.nfeatures, nfeatures_plot_tgt_nostop.validation_accuracy,label='trigram tfidf vectorizer',color='royalblue')\nplt.plot(nfeatures_plot_tg_nostop.nfeatures, nfeatures_plot_tg_nostop.validation_accuracy,label='trigram count vectorizer',linestyle=':', color='royalblue')\nplt.plot(nfeatures_plot_bgt_nostop.nfeatures, nfeatures_plot_bgt_nostop.validation_accuracy,label='bigram tfidf vectorizer',color='orangered')\nplt.plot(nfeatures_plot_bg_nostop.nfeatures, nfeatures_plot_bg_nostop.validation_accuracy,label='bigram count vectorizer',linestyle=':',color='orangered')\nplt.plot(nfeatures_plot_ugt_nostop.nfeatures, nfeatures_plot_ugt_nostop.validation_accuracy, label='unigram tfidf vectorizer',color='gold')\nplt.plot(nfeatures_plot_ug_nostop.nfeatures, nfeatures_plot_ug_nostop.validation_accuracy, label='unigram count vectorizer',linestyle=':',color='gold')\nplt.title(\"N-gram(1~3) test result : Accuracy\")\nplt.xlabel(\"Number of features\")\nplt.ylabel(\"Validation set accuracy\")\nplt.legend()","59b6fc32":"### In both Negative and positive plot, neutral words such as film, movie, story are quite high up in the rank.","1e8a9866":"<a id='wcp'><\/a>\n\n####  WORD CLOUD OF THE POSITIVE SENTIMENT PHRASES","478346b6":"<a id='tfv'><\/a>\n\n### Tfidf Vectorizer","435d0ebd":"<a id='wcn'><\/a>\n\n####  WORD CLOUD OF THE NEGATIVE SENTIMENT PHRASES","ca90b5ad":"### Comparison of Bigram Vs Trigram Vs Unigram for Count Vectorizer ","4cd55cd0":"### Top 50 Tokens among the positive sentiment","e6db674f":"### Other Approaches to follow in the next kernels","4e1fb994":"<a id='rcd'><\/a>\n\n## Reading and Cleaning","0d6f34a7":"<a id='cvbt'><\/a>\n\n#### Count Vectorizer - Bigram and trigram method","29db0906":"<a id='cvs'><\/a>\n\n## Count Vectorizer with Stopwords","3cd74b69":"### Without Stop words in tfidf vector","78685737":"### Top 50 Tokens among the negative sentiment","7dacf064":"<a id='cbwwo'><\/a>\n\n#### Comparing Bi-grams - With and without stop words","c1c23710":"<a id='vpw'><\/a>\n\n#### Visualising phrase words without stopwords","db16b3e7":"<a id='cvbtns'><\/a>\n\n#### Count Vectorizer - Bigram and trigram method without stop words","c2f60446":"### Best performing number of features with each n-gram","39e93488":"#### Count vectorizer Bigram and trigram plot - Without Stop words","b3da51eb":"### Bigram model is better among the 3 ","26e7c942":"### For Count Vectorizer, validation set accuracy is better without the custom stop words","818b2fae":"<a id='swtf'><\/a>\n\n### Sentiment-wise term frequency","f040041c":"## Table of Contents\n\n1. [Reading and Cleaning the dataset](#rcd)\n2. [Count Vectorizer with Stopwords](#cvs)\n3. [Sentiment wise term frequency](#swtf)\n4. [Word Cloud of the Negative Sentiment](#wcn)\n5. [Word Cloud of the Positive Sentiment](#wcp)\n6. [Count Vectorizer - Bigram and trigram method](#cvbt)\n7. [Count Vectorizer - Bigram and trigram method without stop words](#cvbtns)\n8. [Comparing Bi-grams - With and without stop words](#cbwwo)\n9. [Tfidf Vectorizer](#tfv)","43da3632":"### Comparing count vectorizer & TFIDF Vectorizer"}}