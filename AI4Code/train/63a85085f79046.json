{"cell_type":{"1a127c3d":"code","28b4d3cd":"code","aff1ee8f":"code","45f6647a":"code","8a61b175":"code","ebfa42d6":"code","d8944c0f":"code","1c05e200":"code","41b58bfc":"code","ebb87a11":"markdown","04ce021b":"markdown","efbaff3f":"markdown"},"source":{"1a127c3d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nimport operator\nimport math\nimport random\n\nimport numpy\n\nfrom deap import algorithms\nfrom deap import base\nfrom deap import creator\nfrom deap import tools\nfrom deap import gp\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom colorama import Fore, Back, Style \ndef prRed(skk): print(\"\\033[91m {}\\033[00m\" .format(skk))","28b4d3cd":"class Reader(object):\n    \n    def __init__(self,root = '\/kaggle\/input\/titanic\/',FE=False):\n        \n        self.train = pd.read_csv(root+'train.csv')\n        self.test = pd.read_csv(root+'test.csv')\n        self.simplified = FE\n        \n    def get(self):\n        train = self.train\n        test = self.test\n        train['is_train'] = 1\n        test['is_train'] = 0\n        total = pd.concat([train,test],ignore_index=True,sort=False)\n        \n        if self.simplified==False:\n            \n            print('FE == FALSE')\n            \n            prRed('##Title##')\n            total['Title'] = total.Name.str.split(\".\").str.get(0).str.split(',').str.get(1)\n            #title_dict = {i:idx for idx, i in enumerate(total.Title.unique())}\n            #total['Title'] = total.Title.map(title_dict)\n            prRed('##Cabin##')\n            total['Cabin'] = total.Cabin.str.get(0)\n            cabin_dict = {i:idx for idx, i in enumerate(total.Cabin.unique())}\n            total['Cabin'] = total.Cabin.map(cabin_dict)\n            prRed('##Sex##')\n            sex_dict = {i: idx for idx , i in enumerate(total.Sex.unique())}\n            total['Sex'] = total.Sex.map(sex_dict)\n            prRed('##Embarked##')\n            embarked_dict = {i: idx for idx, i in enumerate(total.Embarked.unique())}\n            total['Embarked'] = total.Embarked.map(embarked_dict)\n            prRed('##Age##')\n            age_dict = total.groupby('Title').Age.mean().to_dict()\n            total.loc[total.Age.isnull(),'Age'] = total.loc[total.Age.isnull()].Title.map(age_dict)\n            total.drop(columns=['Name','Ticket','PassengerId','PassengerId','Cabin', 'Ticket'],inplace=True)\n        else:\n            \n            print('FE == TRUE')\n            stat_min = 10\n            prRed('##Title##')\n            total['Title'] = total.Name.str.split(\".\").str.get(0).str.split(',').str.get(1)\n            title_names = (total['Title'].value_counts() < stat_min)\n            total['Title'] = total['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n            \n            prRed('##Age##')\n            age_dict = total.groupby('Title').Age.mean().to_dict()\n            total.loc[total.Age.isnull(),'Age'] = total.loc[total.Age.isnull()].Title.map(age_dict)\n            total['AgeBin'] = pd.cut(total['Age'].astype(int), 5)\n            agebin_dict = {i:idx for idx, i in enumerate(total.AgeBin.unique())}\n            total['AgeBin'] = total.AgeBin.map(agebin_dict)\n            \n            prRed('##Embarked##')\n            total['Embarked'].fillna(total['Embarked'].mode()[0], inplace = True)\n            prRed('##Fare##')\n            total['Fare'].fillna(total['Fare'].median(), inplace = True)\n            total['FareBin'] = pd.qcut(total['Fare'], 4)\n            agebin_dict = {i:idx for idx, i in enumerate(total.FareBin.unique())}\n            total['FareBin'] = total.FareBin.map(agebin_dict)\n            \n            prRed('##FamilySize##')\n            total['FamilySize'] = total.SibSp + total.Parch + 1\n            \n            prRed('##Alone##')\n            total['Alone'] = 1\n            total['Alone'].loc[total['FamilySize'] > 1] = 0\n            \n            total.loc[(total.Age<=13)|(total.Title=='Master'),'Kid'] = 1\n            \n            prRed('##Kid##')\n            total['Kid'].fillna(0,inplace=True)\n\n            \n            prRed('##Drop and OHE##')\n            total.drop(columns=['Age', 'SibSp', 'Parch', 'Fare','Name','PassengerId','Cabin', 'Ticket'], axis=1, inplace = True)\n            total = pd.get_dummies(total,columns=['Sex','Pclass', 'Embarked', 'Title','FareBin', 'AgeBin', 'Alone','Kid'])\n            \n        train = total.loc[total.is_train==1]\n        test = total.loc[total.is_train==0]\n        train.drop(columns=['is_train'],inplace=True)\n        test.drop(columns=['is_train','Survived'],inplace=True)\n        test.fillna(0,inplace=True)\n        print('Done!')\n        print(f'Train : {train.shape} , Test : {test.shape}')\n        return train,test","aff1ee8f":"reader = Reader(FE=True)\ntrain,test = reader.get()","45f6647a":"class GP(object):\n    def __init__(self,features,target):\n        self.features = features.values.tolist()\n        self.target = target.values.tolist()\n        \n    def fit(self):\n        \n        pset = gp.PrimitiveSet(\"MAIN\", 27)\n        pset.addPrimitive(operator.add,2)\n        pset.addPrimitive(operator.sub,2)\n        pset.addPrimitive(operator.mul,2)\n        pset.addPrimitive(self.div,2)\n        pset.addPrimitive(math.cos,1)\n        pset.addPrimitive(math.sin,1)\n        pset.addPrimitive(math.tanh,1)\n        pset.addPrimitive(math.floor,1)\n        pset.addPrimitive(math.ceil,1)\n        pset.addPrimitive(self.sqrt,1)\n        pset.addPrimitive(self.abs,1)\n        \n        \n        def evaluation(individual):\n        \n            func = toolbox.compile(expr=individual)\n            result =sum(round(1.-(1.\/(1.+np.exp(-func(*in_))))) == out for in_, out in zip(self.features,self.target))\/len(self.features)\n            return result,\n        \n        \n        creator.create('FitnessMin', base.Fitness, weights=(1.0,))\n        creator.create('Individual', gp.PrimitiveTree, fitness=creator.FitnessMin)\n        \n        toolbox = base.Toolbox()\n        toolbox.register('expr', gp.genHalfAndHalf,pset=pset, min_=1,max_=10)\n        toolbox.register('individual', tools.initIterate, creator.Individual,toolbox.expr)\n        toolbox.register('population', tools.initRepeat, list, toolbox.individual)\n        toolbox.register('compile', gp.compile, pset=pset)\n        \n        toolbox.register('evaluate', evaluation)\n        toolbox.register('select', tools.selTournament, tournsize=5)\n        toolbox.register('mate', gp.cxOnePoint)\n        toolbox.register('expr_mut', gp.genFull, min_=1,max_=10)\n        toolbox.register('mutate', gp.mutUniform, expr=toolbox.expr_mut,pset=pset)\n        toolbox.decorate(\"mate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=80))\n        toolbox.decorate(\"mutate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=80))\n        \n        pop = toolbox.population(n=2000)\n        hof = tools.HallOfFame(1)\n        stats_fit = tools.Statistics(lambda ind: ind.fitness.values)\n        stats_size = tools.Statistics(len)\n        mstats = tools.MultiStatistics(fitness=stats_fit, size=stats_size)\n        mstats.register(\"max\", numpy.max)\n        pop, log = algorithms.eaSimple(pop, toolbox, 0.2, 0.5, 200, stats=mstats,\n                                   halloffame=hof, verbose=True)\n        \n        print('Expression')\n        print(hof[0])\n        \n        return toolbox,hof[0]\n    \n    def div(self,left,right):\n        try : \n            return left\/right\n            \n        except ZeroDivisionError:\n            return left\/1e-4\n        \n    def sqrt(self,inp):\n        \n        return math.sqrt(abs(inp))\n    \n    def log1p(self,inp):\n        \n        return np.log1p(abs(inp))\n    \n    def abs(self,inp):\n        \n        return abs(inp)","8a61b175":"GPro = GP(train.iloc[:,1:],train.iloc[:,0])","ebfa42d6":"prediction  = []\nfor i in range(1):\n    toolbox,hof = GPro.fit()\n    func = toolbox.compile(expr=hof)\n    prediction.append([np.round(1.-(1.\/(1.+np.exp(-func(*x))))) for x in test.values.tolist()])","d8944c0f":"submission = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')","1c05e200":"submission['Survived'] = np.round(np.mean(np.vstack(prediction),axis=0))\nsubmission['Survived'] = submission['Survived'].astype(int)","41b58bfc":"submission.to_csv('submission.csv', index=False)","ebb87a11":"#### This is for a practice of Genetic Programming(GP).","04ce021b":"# Genetic Programming\n\nI cited GP from\nhttps:\/\/github.com\/DEAP\/deap\/blob\/454b4f65a9c944ea2c90b38a75d384cddf524220\/examples\/gp\/symbreg.py\nhttps:\/\/www.kaggle.com\/paulorzp\/titanic-gp-model-training\n\nAfter setting some primitives listed below(i.e. operations), this descriptively builds something like expression tree and select best fitted individuals and evolves generation by generation given some parameters.\n\nHere I populate 2000 individuals evolving for 300 generations","efbaff3f":"# Preprocessing\n\nI do not focus on Feature Engineering in here.\n\n#### FE == False\nDo not augment new features here(just did label-encoding on non-numeric features and fill nan values with mean and zeros)\n\n#### FE == True\nIn this case, I cited partially from \nhttps:\/\/www.kaggle.com\/avelinocaio\/top-5-voting-classifier-in-python\n"}}