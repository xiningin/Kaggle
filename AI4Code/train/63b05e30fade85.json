{"cell_type":{"e08ae354":"code","8a6b7031":"code","6685cbfc":"code","32dc5c27":"code","b369cbcc":"code","ad932d04":"code","a923b027":"code","bff1fe1b":"code","da9142c2":"code","867fd468":"code","1ae5e7e4":"code","74e5cd95":"code","23533e96":"code","1a008ee1":"markdown","c09ea909":"markdown","dabaf9b9":"markdown","2e3e0426":"markdown","a5b31b4b":"markdown","a2abe755":"markdown","0420a64b":"markdown","769417f3":"markdown","c064fa67":"markdown","39614168":"markdown","3e18e5ca":"markdown","8042c26b":"markdown","50066c5b":"markdown"},"source":{"e08ae354":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Dropout, Activation, Conv2D, MaxPooling2D\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\n\nfrom PIL import Image\nimport cv2\nfrom zipfile import ZipFile\nimport os","8a6b7031":"file_train = \"..\/input\/dogs-vs-cats\/train.zip\"\nfile_test = \"..\/input\/dogs-vs-cats\/test1.zip\"\n\nwith ZipFile(file_train, 'r') as zip:\n    zip.extractall('\/train')\n    print('Train Extract Done!') \n    \nwith ZipFile(file_test,'r') as zip:\n    zip.extractall('\/test1')\n    print('Test Extract Done!')","6685cbfc":"print('Train Data ',len(os.listdir('\/train\/train\/')))\nprint('Test Data ',len(os.listdir('\/test1\/test1\/')))","32dc5c27":"rand_pic = np.random.randint(0,len(os.listdir('\/train\/train\/')))\ndc_pic = os.listdir('\/train\/train\/')[rand_pic]\n\n# Load the images\ndc_load = Image.open('\/train\/train\/' + dc_pic)\ncategory = dc_pic.split(\".\")[0]\nplt.title(category)\nimg_plot = plt.imshow(dc_load)","b369cbcc":"train_path = '\/train\/train\/'\n\nX_train = []\ny_train = []\n\nconvert = lambda category : int(category == 'dog')\n\ndef create_train_data(path):\n    for p in os.listdir(path):\n        category = p.split(\".\")[0]\n        category = convert(category)\n        img_array = cv2.imread(os.path.join(path,p),cv2.IMREAD_GRAYSCALE)\n        new_img_array = cv2.resize(img_array, dsize=(80, 80))\n        X_train.append(new_img_array)\n        y_train.append(category)\n        \ncreate_train_data(train_path)\n\nX_train = np.array(X_train).reshape(-1, 80,80,1)\ny_train = np.array(y_train)\nX_train = X_train\/255.0","ad932d04":"test_path = \"\/test1\/test1\/\"\n\nX_test = []\ntest_id = []\n\ndef create_test_data(path):\n    for p in os.listdir(path):\n        test_id.append(p.split(\".\")[0])\n        img_array = cv2.imread(os.path.join(path,p),cv2.IMREAD_GRAYSCALE)\n        new_img_array = cv2.resize(img_array, dsize=(80, 80))\n        X_test.append(new_img_array)\n\ncreate_test_data(test_path)\n\nX_test = np.array(X_test).reshape(-1,80,80,1)\nX_test = X_test\/255","a923b027":"model = Sequential()\n\nmodel.add(Conv2D(16,(3,3), activation = 'relu', input_shape = X_train.shape[1:]))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\n\nmodel.add(Conv2D(32,(3,3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\n\nmodel.add(Conv2D(64,(3,3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\n\nmodel.add(Conv2D(128,(3,3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.3))\nmodel.add(Flatten())\n\nmodel.add(Dense(512, activation='relu'))\n\nmodel.add(Dense(1, activation='sigmoid'))","bff1fe1b":"model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])","da9142c2":"history = model.fit(X_train, y_train, epochs = 20, batch_size = 100, validation_split=0.3)","867fd468":"import matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and Validation accuracy')\nplt.legend(loc=0)\nplt.figure()\n\nplt.show()","1ae5e7e4":"predictions = model.predict(X_test)\npredicted_val = [int(round(p[0])) for p in predictions]","74e5cd95":"submission_df = pd.DataFrame({'id':test_id, 'label':predicted_val})\nsubmission_df.to_csv(\"submission.csv\", index=False)","23533e96":"sample_test = submission_df.head(60)\nplt.figure(figsize=(12, 24))\nfor index, row in sample_test.iterrows():\n    filename = row['id']\n    category = row['label']\n    img = load_img(\"\/test1\/test1\/\"+filename+\".jpg\", target_size=(128,128))\n    plt.subplot(10, 6, index+1)\n    plt.imshow(img)\n    if(category == 1):\n        plt.title( '(' + \"Dog\"+ ')' )\n    else:\n        plt.title( '(' + \"Cat\"+ ')' )\nplt.tight_layout()\nplt.show()","1a008ee1":"## Data Description\n\nThe training archive contains 25,000 images of dogs and cats. Train your algorithm on these files and predict the labels for test1.zip (1 = dog, 0 = cat).\n\nYou can find the dataset [here](https:\/\/www.kaggle.com\/c\/dogs-vs-cats\/data).","c09ea909":"## Files\n* test1.zip\n* train.zip","dabaf9b9":"### Number of training data and testing data","2e3e0426":"## Creating Model","a5b31b4b":"## Fitting Data in Model","a2abe755":"## The Asirra data set\n\nWeb services are often protected with a challenge that\u2019s supposed to be easy for people to solve, but difficult for computers. Such a challenge is often called a CAPTCHA (Completely Automated Public Turing test to tell Computers and Humans Apart) or HIP (Human Interactive Proof). HIPs are used for many purposes, such as to reduce email and blog spam and prevent brute-force attacks on web site passwords.\n\nAsirra (Animal Species Image Recognition for Restricting Access) is a HIP that works by asking users to identify photographs of cats and dogs. This task is difficult for computers, but studies have shown that people can accomplish it quickly and accurately. Many even think it\u2019s fun! Here is an example of the Asirra interface:\n\nAsirra is unique because of its partnership with Petfinder.com, the world\u2019s largest site devoted to finding homes for homeless pets. They\u2019ve provided Microsoft Research with over three million images of cats and dogs, manually classified by people at thousands of animal shelters across the United States. Kaggle is fortunate to offer a subset of this data for fun and research.","0420a64b":"### Opening a Train Image","769417f3":"## Evaluate the model","c064fa67":"## Overview\n\nHere you\u2019ll write an algorithm to classify whether images contain either a dog or a cat. This is easy for humans, dogs, and cats. Your computer will find it a bit more difficult.","39614168":"## Extracting Files from zip file","3e18e5ca":"## Predicting Test Images","8042c26b":"## So let\u2019s begin here\u2026","50066c5b":"## Prediction"}}