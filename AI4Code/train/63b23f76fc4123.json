{"cell_type":{"2b39576b":"code","6950677f":"code","2146034b":"code","af8f837c":"code","fe5799ea":"code","8e34c29a":"code","dec2b905":"code","f3a64ee4":"code","0670446d":"code","d569b585":"code","1c2efa18":"code","70615bcd":"code","fc82c7fa":"code","8bc3ff3e":"code","973bce75":"code","5b0ad146":"code","bd574355":"code","fa65bf5d":"code","86dace87":"code","1e930522":"code","1fed5838":"code","e4ab591c":"code","1ba5f447":"code","add0e497":"code","4d1edc9a":"code","a42dae8e":"code","0c47c4e2":"code","6718606d":"code","ffd9f0ec":"code","06b9469b":"code","fe7a850a":"code","d4f064cd":"code","56ea7564":"code","0c5bf6ba":"code","f2a6d7eb":"code","fba0f874":"code","7e7d955b":"code","a9c039d2":"code","c6fc58a9":"code","c7d354b7":"code","97e52161":"code","2c1b98e9":"code","b9c05d7a":"code","80bd5a7f":"code","734f5e75":"markdown","3657f8be":"markdown","cc6c94fd":"markdown","9c982b52":"markdown","3840e22d":"markdown"},"source":{"2b39576b":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom datetime import date\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.\n# Following the notes from fast.aitutorial docs - https:\/\/docs.fast.ai\/tutorial.data.html\n# Adding Resnet 18 dataset\n\n#Learnt a lot from these two.. https:\/\/www.kaggle.com\/hortonhearsafoo\/fast-ai-lesson-2\n#From: https:\/\/nbviewer.jupyter.org\/github\/arunoda\/fastai-courses\/blob\/master\/dl1\/lesson3-planet.ipynb#Test-Dataset\n\n# First of all, we need to find some metrics \n# Basically these are just for printing only.\n# Since this is a multi classification problem, we need to use a threshold for the \n# accuracy.\ndef p_accuracy(pred, act, **kwargs):\n    return accuracy_thresh(pred, act, thresh=0.2, **kwargs)\n#This kaggle competition uses f2 score for the final eval. So we should use that as well.\ndef f2_score(pred, act, **kwargs):\n    return fbeta(pred, act, beta=2, thresh=0.2, **kwargs)\n","6950677f":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","2146034b":"# This file contains all the main external libs we'll use - fastai v1\nfrom fastai import *\nfrom fastai.vision import *","af8f837c":"debug = 0\nPATH = \"\/kaggle\/input\/planet-understanding-the-amazon-from-space\/\"\n# 32 when testing variable building to 256 when for real\nif debug:\n    sz=32 \n    print(\"In low res debug mode - quick but not accurate at all\")\nelse:\n    sz=256\n    print(\"In high res mode - slow, looking for that final result\")\nTMP_PATH = \"\/tmp\/tmp\"\nMODEL_PATH = \"\/tmp\/model\/\"\narch = 'resnet18' #just for naming the submission file\ncomp_name = \"planet\"","fe5799ea":"!ls {PATH} # directory for training and test files","8e34c29a":"label_df = pd.read_csv(f'{PATH}train_v2.csv')","dec2b905":"#what does the csv file look like id is the file name (minus .jpg), breed is the classification\nlabel_df.head()","f3a64ee4":"# What are the different tags? \nlabel_df.pivot_table(index='tags', aggfunc=len).sort_values('image_name', ascending=False)","0670446d":"# GPU required\ntorch.cuda.is_available()","d569b585":"torch.backends.cudnn.enabled","1c2efa18":"# Fix to enable Resnet to live on Kaggle - creates a writable location for the models\ncache_dir = os.path.expanduser(os.path.join('~', '.torch'))\nif not os.path.exists(cache_dir):\n    os.makedirs(cache_dir)\n   # print(\"directory created :\" .cache_dir)\nmodels_dir = os.path.join(cache_dir, 'models')\nif not os.path.exists(models_dir):\n    os.makedirs(models_dir)\n  #  print(\"directory created :\" . cache_dir)","70615bcd":"#copying model to writable location\n#cd \/kaggle\/working\nshutil.copy(\"\/kaggle\/input\/resnet18\/resnet18.pth\", \"\/tmp\/.torch\/models\/resnet18-5c106cde.pth\")","fc82c7fa":"tfms = get_transforms(do_flip=True, max_lighting=0.1, max_zoom=1.05, max_warp=0.)\n","8bc3ff3e":"def get_data(sz):\n    tfms = get_transforms(do_flip=True, max_lighting=0.1, max_zoom=1.05, max_warp=0.)\n    \n    data = (\n        ImageItemList\n            .from_csv(PATH, 'train_v2.csv', folder=\"train-jpg\", suffix=\".jpg\")\n            .random_split_by_pct(0.2)\n            .label_from_df(sep=' ')\n            .transform(tfms, size=sz)\n            .add_test_folder('test-jpg-v2')\n            .databunch(num_workers=0)\n            .normalize(imagenet_stats)\n    )\n    return data\n#crashes with too many workers (remove numworkers while testing with a small image size ~ 64), keep for the bigger images for accuracy\n","973bce75":"#Cause learning on 64x64\nsz=64\ndata = get_data(sz)","5b0ad146":"len(data.classes), data.classes","bd574355":"data.show_batch(rows=3, figsize=(10,12))","fa65bf5d":"img = plt.imread(f'{PATH}train-jpg\/{label_df.iloc[0,0]}.jpg')\nplt.imshow(img);\n# all images are 256 x 256","86dace87":"img.size","1e930522":"learn = create_cnn(data, models.resnet18, model_dir=MODEL_PATH, metrics=[p_accuracy])","1fed5838":"learn.lr_find()\nlearn.recorder.plot()","e4ab591c":"lr = 1e-1\nlearn.fit_one_cycle(5, slice(lr))","1ba5f447":"learn.metrics = [p_accuracy, f2_score]","add0e497":"learn.unfreeze() ","4d1edc9a":"learn.lr_find()\nlearn.recorder.plot()","a42dae8e":"if debug:\n    learn.fit_one_cycle(1, max_lr=(1e-6, 1e-5, 1e-4))\nelse:\n    learn.fit_one_cycle(3, max_lr=(1e-6, 1e-5, 1e-4))","0c47c4e2":"sz=128\nlearn.data = get_data(sz)\nlearn.freeze()\nlearn.lr_find()\nlearn.recorder.plot()","6718606d":"if debug:\n    learn.fit_one_cycle(1, slice(1e-5, 1e-3))\nelse: \n    learn.fit_one_cycle(3, slice(1e-5, 1e-3))","ffd9f0ec":"sz=256\nlearn.data = get_data(sz)\nlearn.freeze()\nlearn.lr_find()\nlearn.recorder.plot()","06b9469b":"if debug:\n    learn.fit_one_cycle(1, slice((1e-2)\/2, (1e-1)\/2))\nelse:\n    learn.fit_one_cycle(3, slice((1e-2)\/2, (1e-1)\/2))","fe7a850a":"learn.unfreeze();\nlearn.lr_find()\nlearn.recorder.plot()","d4f064cd":"if debug:\n    learn.fit_one_cycle(1,  slice(1e-6, 1e-5))\nelse:\n    learn.fit_one_cycle(5,  slice(1e-6, 1e-5))","56ea7564":"learn.show_results(rows=3, figsize=(12,15))","0c5bf6ba":"# from https:\/\/nbviewer.jupyter.org\/github\/arunoda\/fastai-courses\/blob\/master\/dl1\/lesson3-planet.ipynb#Test-Dataset\ndef get_tags(pred, thresh):\n    classes = \"\"\n    best_guess = \"\"\n    tags = 0\n    high_val = 0\n    if debug:\n        thresh = 0.2\n        print(f\"Debug - using low threshold {thresh}\")\n    for idx, val in enumerate(pred):\n        if val > thresh:\n            classes = f'{classes} {learn.data.classes[idx]}'\n            tags = tags+1\n        if val > high_val:\n            high_val = val\n            best_guess = f'{learn.data.classes[idx]}'\n    if tags == 0:\n        classes = best_guess\n    return classes.strip()","f2a6d7eb":"def predict(idx):\n    pred_vals = predictions[0][idx]\n    tags = get_tags(pred_vals, 0.2)\n    print(tags)\n    img = learn.data.test_ds[idx][0]\n    return img","fba0f874":"def get_row(idx):\n    pred = predictions[0][idx]\n    tags = get_tags(pred, 0.2)\n    image_path = learn.data.test_ds.x.items[idx]\n    image_name = re.search(r'([^\/]+)$', f'{image_path}')[0].replace('.jpg', '') \n    return image_name, tags","7e7d955b":"len(learn.data.test_ds)","a9c039d2":"predictions = learn.get_preds(ds_type=DatasetType.Test)","c6fc58a9":"predict(0)","c7d354b7":"df = pd.DataFrame(columns=['image_name', 'tags'])\nfor idx in range(len(predictions[0])):\n    if idx % 5000 == 0:\n        print(f\"Completed: {idx}\")\n        \n    image_name, tags = get_row(idx)\n    df.loc[idx] = [image_name, tags]","97e52161":"df.head()","2c1b98e9":"dt = date.today()\ndate_str = dt.isoformat()\nsubmission_path = f'submission-256-{date_str}-size.csv'","b9c05d7a":"df.to_csv(submission_path, index=False)","80bd5a7f":"!head {submission_path}","734f5e75":"### Unfreeze","3657f8be":"### Look at the images as 128 px resolution","cc6c94fd":"### Unfreeze","9c982b52":"### Let's add f2 as an metric","3840e22d":"### Intial model "}}