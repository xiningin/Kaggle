{"cell_type":{"9739815e":"code","6767aaf3":"code","cc2e31bc":"code","f6cbecab":"code","eeed889d":"code","5f1170df":"code","fba16801":"code","f162e959":"code","d66ef202":"code","0fde3c4a":"code","42aa6600":"code","d6ab09bd":"code","0c54b18b":"code","0a196838":"code","c7c10baa":"code","7505d430":"code","66ce9662":"code","603cf44a":"markdown","6523e6c1":"markdown","30fb1897":"markdown","0e4ca40b":"markdown","11e285a0":"markdown","11d07613":"markdown","8c1f57fe":"markdown","13aeb5e8":"markdown","aad2f770":"markdown","5c442acf":"markdown","2f4b3d1c":"markdown","90012490":"markdown","33598db5":"markdown","2e08d677":"markdown","214822f9":"markdown","dba2a76c":"markdown","2b8c0b16":"markdown","5da8c5e5":"markdown","99430a48":"markdown"},"source":{"9739815e":"import warnings\nfrom sklearn.exceptions import DataConversionWarning\n# Suppress warnings\nwarnings.filterwarnings(action='ignore', category=DataConversionWarning)\nwarnings.filterwarnings(action='ignore', category=DeprecationWarning)\nwarnings.filterwarnings(action='ignore', category=FutureWarning)","6767aaf3":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport os\nfrom sklearn.feature_selection import SelectKBest, f_regression\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler, StandardScaler\n\n# Set pandas data display option\npd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 500)\n\n# Display all filenames\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","cc2e31bc":"# Load csv data\ntrain = pd.read_csv(\"..\/input\/train.csv\")\ncompe = pd.read_csv(\"..\/input\/test.csv\")\nsample_sub = pd.read_csv(\"..\/input\/sample_submission.csv\")\n\n# All data\ndata  = train.append(compe, sort=False)","f6cbecab":"# Columns\nprint(len(data.columns))\ndata.columns","eeed889d":"# Data example\ndata.sample(n=10)","5f1170df":"data.dtypes.sort_values(ascending=False)","fba16801":"# Check missing values\ndef check_missing(df):\n    null_val = df.isnull().sum()\n    percent = 100 * df.isnull().sum()\/len(df)\n    missing_table = pd.concat([null_val, percent], axis=1)\n    col = missing_table.rename(columns = {0 : '#', 1 : '%'})\n    return col\n\n# Display columns missing values are under 1%.\nprint(\"Data #\"+str(len(data)))\ncols = check_missing(data)\n# available_cols = cols[cols['%'] < 1]\n# print(available_cols)\nprint(cols.sort_values(by=\"%\", ascending=False))","f162e959":"# Drop more than 40% missing variables\ndata.drop(['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu'], axis=1, inplace = True)","d66ef202":"# Fill missing data and replace with dummy value\ncategorical_variables_string = \\\n    ['MSZoning', 'Street', 'LotShape', 'LandContour', \n     'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', \n     'Condition1', 'Condition2', 'BldgType', 'HouseStyle', \n     'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', \n     'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', \n     'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', \n     'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', \n     'Electrical', 'KitchenQual', 'Functional', 'GarageType', \n     'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', \n     'SaleType', 'SaleCondition']\n\nfor v in categorical_variables_string:\n    # Fill NaN with mode\n    data[v] = data[v].fillna(data[v].mode()[0])\n    # Categorize\n    data[v] = pd.factorize(data[v])[0]","0fde3c4a":"# There's no missing data\ncategorical_variables_int = \\\n    ['OverallQual', 'OverallCond', 'MoSold']","42aa6600":"# Fill missing data\nnumerical_variavles = \\\n    ['MSSubClass', 'LotFrontage', 'LotArea', 'YearBuilt', \n     'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', \n     'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', \n     'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', \n     'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', \n     'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', \n     'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', \n     '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'YrSold']\n\nss = StandardScaler()\nfor v in numerical_variavles:\n    # Fill NaN with mode\n    data[v] = data[v].fillna(data[v].mean())\n    # Standardize values\n    data[v] = ss.fit_transform(data[[v]])","d6ab09bd":"# Data example\ndata.sample(n=10)","0c54b18b":"# Set data\ntrain = data[:1460]\ntest  = data[1460:]","0a196838":"possible_features = categorical_variables_string + categorical_variables_int + numerical_variavles\n\n# Check feature importances\nselector = SelectKBest(f_regression, len(possible_features))\nselector.fit(train[possible_features], train['SalePrice'])\nscores = -np.log10(selector.pvalues_)\nindices = np.argsort(scores)[::-1]\n\nprint('Feature importances:')\nfor i in range(len(scores)):\n    print('%.2f %s' % (scores[indices[i]], possible_features[indices[i]]))","c7c10baa":"# Feature params\nfparams = \\\n    ['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF',\n    '1stFlrSF', 'FullBath', 'TotRmsAbvGrd', 'YearBuilt', 'YearRemodAdd',\n    'MasVnrArea', 'GarageYrBlt', 'Fireplaces', 'Foundation', 'HeatingQC',\n    'BsmtFinSF1', 'BsmtFinType1', 'LotFrontage', 'WoodDeckSF', '2ndFlrSF',\n    'OpenPorchSF', 'HalfBath', 'LotShape', 'ExterQual', 'LotArea',\n    'CentralAir', 'Electrical', 'BsmtExposure', 'BsmtFullBath', 'BsmtUnfSF',\n    'PavedDrive', 'HouseStyle', 'BedroomAbvGr', 'Exterior2nd', 'RoofStyle',\n    'Neighborhood', 'SaleCondition', 'GarageFinish', 'KitchenAbvGr', 'EnclosedPorch',\n    'ExterCond', 'Exterior1st', 'MSZoning', 'KitchenQual', 'BldgType',\n    'GarageCond', 'ScreenPorch', 'LotConfig', 'Functional', 'Heating',\n    'GarageType', 'PoolArea', 'LandContour', 'MSSubClass', 'BsmtCond',\n    'OverallCond', 'SaleType', 'GarageQual', 'LandSlope', 'BsmtFinType2',\n    'MoSold', 'Condition1', '3SsnPorch']\n\n# Get params\ntrain_target = train[\"SalePrice\"].values\ntrain_features = train[fparams].values\ntest_features  = test[fparams].values","7505d430":"from sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\n\nrfgs_parameters = {\n    'n_estimators': [50],\n    'max_depth'   : [n for n in range(2, 16)],\n    'max_features': [n for n in range(2, 16)],\n    \"min_samples_split\": [n for n in range(2, 8)],\n    \"min_samples_leaf\": [n for n in range(2, 8)],\n    \"bootstrap\": [True,False]\n}\n\nrfr_cv = GridSearchCV(RandomForestRegressor(), rfgs_parameters, cv=8, scoring= 'neg_mean_squared_log_error')\nrfr_cv.fit(train_features, train_target)\nprint(\"RFR GridSearch score: \"+str(rfr_cv.best_score_))\nprint(\"RFR GridSearch params: \")\nprint(rfr_cv.best_params_)","66ce9662":"prediction = rfr_cv.best_estimator_.predict(test_features)\npred = pd.DataFrame(pd.read_csv(\"..\/input\/test.csv\")['Id'])\npred['SalePrice'] = prediction\npred.to_csv(\"..\/working\/submission.csv\", index = False)","603cf44a":"# Data Pre-Processing <a id=\"pre-processing\"><\/a>","6523e6c1":"# Training and Prediction <a id=\"training-prediction\"><\/a>","30fb1897":"Process numerical variables\n1. Just fill missing data with average\n2. Standardize values","0e4ca40b":"Data after processing is like this","11e285a0":"Here's just use RandomForestRegressor for prediction, and do GridSearch","11d07613":"There's 81 columns in data","8c1f57fe":"For data pre-processing, categorize variables into 'Numerical Variables', 'Categorical Variables(int)', 'Categorical Variables(string)'  \n  \n**Numerical Variables: **float and int variables  \n['MSSubClass', 'LotFrontage', 'LotArea', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'YrSold']  \n  \n**Categorical Variables(int): **some of int variables  \n['OverallQual', 'OverallCond', 'MoSold']  \n  \n**Categorical Variables(string): **string variables  \n['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']","13aeb5e8":"Check types of each variables","aad2f770":"This time, pick variables by their importances  \n  \n**Possible features:**  \n['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF',  \n'1stFlrSF', 'FullBath', 'TotRmsAbvGrd', 'YearBuilt', 'YearRemodAdd',  \n'MasVnrArea', 'GarageYrBlt', 'Fireplaces', 'Foundation', 'HeatingQC',  \n'BsmtFinSF1', 'BsmtFinType1', 'LotFrontage', 'WoodDeckSF', '2ndFlrSF',  \n'OpenPorchSF', 'HalfBath', 'LotShape', 'ExterQual', 'LotArea',  \n'CentralAir', 'Electrical', 'BsmtExposure', 'BsmtFullBath', 'BsmtUnfSF',  \n'PavedDrive', 'HouseStyle', 'BedroomAbvGr', 'Exterior2nd', 'RoofStyle',  \n'Neighborhood', 'SaleCondition', 'GarageFinish', 'KitchenAbvGr', 'EnclosedPorch',  \n'ExterCond', 'Exterior1st', 'MSZoning', 'KitchenQual', 'BldgType',  \n'GarageCond', 'ScreenPorch', 'LotConfig', 'Functional', 'Heating',  \n'GarageType', 'PoolArea', 'LandContour', 'MSSubClass', 'BsmtCond',  \n'OverallCond', 'SaleType', 'GarageQual', 'LandSlope', 'BsmtFinType2',  \n'MoSold', 'Condition1', '3SsnPorch', 'Street', 'RoofMatl',  \n'YrSold', 'LowQualFinSF', 'MiscVal', 'BsmtHalfBath', 'Utilities',  \n'BsmtFinSF2', 'MasVnrType', 'Condition2', 'BsmtQual']","5c442acf":"Process categorical variables(string)\n1. Fill missing data by most frequent value\n2. Replace with dummy data","2f4b3d1c":"Output prediction result to a file","90012490":"# Load Data and Libraries <a id=\"load\"><\/a>","33598db5":"To select parameters for training, use feature selection library","2e08d677":"Drop variables more than 40% data was missing..","214822f9":"# Check Data <a id=\"check-data\"><\/a>","dba2a76c":"Check what types of data in each columns","2b8c0b16":"Check how many data is missing","5da8c5e5":"Process categorical variables(int)\n1. Do nothing, because there's no missing data","99430a48":"* [Load Data and Libraries](#load)\n* [Check Data](#check-data)\n* [Data Pre-Processing](#pre-processing)\n* [Training and Prediction](#training-prediction)"}}