{"cell_type":{"15b7b94e":"code","6aafb23d":"code","e9ed699a":"code","97612183":"code","91edfb28":"code","04fc87b7":"code","f1b9aa28":"code","048331f4":"code","d453b8d8":"code","8f0b0697":"code","d7e8e69b":"code","d910a783":"code","28aa245d":"code","134201cf":"code","e7db198a":"code","996eb6ef":"code","406f72d4":"code","b5c65f97":"code","67505845":"code","f92febd0":"code","38f987ec":"code","cb04cbd3":"code","bcdef49c":"code","075cd11d":"code","51891d16":"code","8b5d1fd8":"code","c9d3f901":"code","98c18a67":"markdown","4f4fba81":"markdown","4bac3498":"markdown","d6f999e1":"markdown","1b63038a":"markdown","6a9ee0c3":"markdown","2d57347b":"markdown","b6061f71":"markdown","d006d83d":"markdown","b32f4cd1":"markdown","89cf6a79":"markdown","e6f0ea6b":"markdown","6cbf3898":"markdown","d5b0a60d":"markdown","b8b8b610":"markdown","b60a5f60":"markdown","f35d4c3a":"markdown","da41514f":"markdown","0228717d":"markdown","93210d85":"markdown","8d2166ac":"markdown","4321e22a":"markdown","728158bb":"markdown","45dceb8b":"markdown","a6347fda":"markdown","4883230a":"markdown","2e9498b6":"markdown","402d894d":"markdown","e5ca67f0":"markdown","72122ada":"markdown","c2cc6949":"markdown","2a313db6":"markdown","88f73350":"markdown","5c81d62f":"markdown","8b2091c1":"markdown","89f9e58b":"markdown"},"source":{"15b7b94e":"import scipy\nfrom scipy import stats, integrate\nimport numpy as np # linear algebra\nimport matplotlib.pyplot as plt\nfrom matplotlib import figure\nimport matplotlib.ticker as mtick\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\n\n# Loading the dataset\n\ndata = pd.read_csv(\"\/kaggle\/input\/dataset\/session_dataset_scoring.csv\")","6aafb23d":"data.shape","e9ed699a":"data.head() # shows the first 5 rows and all columns of the dataframe","97612183":"data.dtypes","91edfb28":"data.total_time_spent = pd.to_numeric(data.total_time_spent, errors='coerce')","04fc87b7":"data.dtypes","f1b9aa28":"# Checking for null values\n\ndata.isnull().sum()","048331f4":"data['zone'].unique()","d453b8d8":"data['source_of_enquiry'].unique()","8f0b0697":"data.describe()","d7e8e69b":"data.describe(include='object')","d910a783":"ax = data['Retail'].value_counts().plot(kind = 'bar',rot = 0, width = 0.3)\nax.set_ylabel('Number of Customers')\nax.set_title('Retail - Yes or No')","28aa245d":"cat_feats = [x for x in data.columns if data[x].dtype == \"object\" and x != \"customer_code\"]\ncat_feats","134201cf":"fig = plt.figure(figsize=(18, 30))\n\nfor i, col in enumerate(cat_feats):\n    plt.subplot(10, 3, i+1)\n    sns.countplot(x=data[col],palette = 'Set2')\n    plt.tight_layout()\nfig.show()","e7db198a":"data_temp = data.iloc[:,1:]\n\n#transform to binary code\ndata_temp['Retail'].replace(to_replace='Yes', value=1, inplace=True)\ndata_temp['Retail'].replace(to_replace='No',  value=0, inplace=True)","996eb6ef":"data_dummies = pd.get_dummies(data_temp, drop_first=True)\ndata_dummies.head()","406f72d4":"data_dummies = data_dummies.dropna()\ndata_dummies.shape","b5c65f97":"data_corr = data_dummies.iloc[:,0:]\n\n# plt.figure(figsize=(20,5))\n# data_corr.corr()['Retail'].sort_values(ascending = False).plot(kind='bar')\na4_dims = (17, 15)\nfig, ax = plt.subplots(figsize=a4_dims)\nsns.heatmap(data_corr.corr(), annot=True, ax=ax)\n","67505845":"from sklearn import metrics\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, recall_score, precision_score, f1_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\n# from sklearn.linear_model import LogisticRegression","f92febd0":"X = data_dummies.drop(columns = ['Retail'])\ny = data_dummies['Retail']","38f987ec":"# Scaling all the variables to a range of 0 to 1\n\nfeatures = X.columns.values\nscaler = MinMaxScaler(feature_range = (0,1))\nscaler.fit(X)\nX = pd.DataFrame(scaler.transform(X))\nX.columns = features\n\nX","cb04cbd3":"# Create Train & Test Data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","bcdef49c":"X_train.shape","075cd11d":"# Running regression model\nmodel_rf = RandomForestClassifier(n_estimators=1000 , oob_score = True, n_jobs = -1,\n                                  random_state =50, max_features = \"auto\",\n                                  max_leaf_nodes = 30)\nmodel_rf.fit(X_train, y_train)","51891d16":"prediction_test = model_rf.predict(X_test)\n\n# Print the prediction accuracy\nprint(metrics.accuracy_score(y_test, prediction_test))","8b5d1fd8":"importances = model_rf.feature_importances_\nweights = pd.Series(importances,\n                 index=X.columns.values)\nweights.sort_values()[:].plot(kind = 'barh')","c9d3f901":"cfm = confusion_matrix(y_test, prediction_test)\n\nplt.figure(figsize=(10, 8))\nax = plt.subplot()\n\nsns.heatmap(cfm, annot=True, ax=ax, fmt='g'); # annot=True to annotate cells\n# labels, title and ticks\nax.set_xlabel('Predicted labels');\nax.set_ylabel('Actual labels');\nax.set_title('Confusion Matrix - Test Data');\nax.xaxis.set_ticklabels(['No', 'Yes']);\nax.yaxis.set_ticklabels(['No', 'Yes'])\nplt.show()","98c18a67":"# 4. Modelling and Evaluation \ud83d\udcc9","4f4fba81":"We covered the basic steps to approach a machine learning problem. This can serve as a template that can help you get started with your first project but these steps are non-exhaustive; there are other data preparation and result improvement tasks which one can learn as they move further from the basics.\n\n<h3> What can you do next? <\/h3>\n\n* **Learn Machine Learning.** <br>\nAndrew Ng's [Machine Learning course](https:\/\/www.coursera.org\/learn\/machine-learning?utm_source=gg&utm_medium=sem&utm_campaign=94-BrandedSearch-IN&utm_content=94-BrandedSearch-IN&campaignid=1776545273&adgroupid=69298819109&device=c&keyword=andrew%20ng%20machine%20learning&matchtype=e&network=g&devicemodel=&adpostion=&creativeid=346568280203&hide_mobile_promo&gclid=EAIaIQobChMIo_Pnx5nr7wIVwnwrCh2tNwE4EAAYASAAEgJGU_D_BwE) offered by Standford University (available on Cousera) and [Machine Learning A-Z](https:\/\/www.udemy.com\/course\/machinelearning\/) (available on Udemy) are great places to get started. You will get a broad introduction to machine learning, datamining, and statistical pattern recognition.\n<br>\n\n* **Pick up a programming language.** <br>\nWhile there are other languages you can use for Machine Learning like R, Scala, etc. Python is currently the most popular language for ML. In fact, there are many Python libraries that are specifically useful for Artificial Intelligence and Machine Learning such as Keras, TensorFlow, Scikit-learn, etc. \nYou can explore the [Python Bootcamp](https:\/\/www.udemy.com\/course\/complete-python-bootcamp\/) course where you learn the basics and go all the way to creating your own applications.\n<br>\n\n* **Build porjects.** <br>\nThe best way to learn machine learning is by designing and completing small projects. Few data resources for starting your own project are - Kaggle, Data.gov, Google Public Datasets, UCI Machine Learning Repository.\nYou can check [this article](http:\/\/www.intellspot.com\/data-science-project-ideas\/) for some project ideas to get started with.\n<br>\n\n* **Ask questions!** <br>\nThis will be the most important step of your learning process and this must never stop. Take advantage of online communities, write to people and reach out for help and never stop learning!\n\n![](https:\/\/i.ytimg.com\/vi\/ObBbF96rjmo\/maxresdefault.jpg)","4bac3498":"We will now convert categorical variables into numeric data by a method called **one-hot encoding.** \n\n![One-Hot Encoding](https:\/\/miro.medium.com\/max\/1400\/1*ggtP4a5YaRx6l09KQaYOnw.png)","d6f999e1":"Now the **total_time_spent** variable has been converted to float.","1b63038a":"# Conclusion","6a9ee0c3":"Natrurally, the number of leads actually turning into customers is lower i.e. the class 'Yes' is smaller than 'No'.","2d57347b":"As we can see, 'zone' has 3 categories and 'source_of_enquiry' has 4 categories.\nThis will help us get a better picture of our data in an easier way, rather than scanning csv files manually.\n\nWe can also get a statistical summary of this data for further understanding.","b6061f71":"Here, we have basic statistical information of the numeric features. Mean value, standard deviation, quartiles etc. On an average, a customer visits the webiste 32 times. And the average time spent by customer on the website in the last week is 64 minutes. \nBut most of these parameters cannot be computed for categorical variables.\nWhen we add **include = 'object'** in the **describe** method, we also receive some information about categorical variables. Here!","d006d83d":"We will now plot the **correlation matrix** of the data.\n\n**Correlation** is statistical technique which determines how one variables moves\/changes in relation with the other variable. It gives us the idea about the degree of the relationship of the two variables. It\u2019s a bi-variate analysis measure which describes the association between different variables. In most of the business, it\u2019s useful to express one subject in terms of its relationship with others.\n\n**Positive Correlation:** Two features (variables) can be positively correlated with each other. It means that when the value of one variable increase then the value of the other variable(s) also increases.\n\n![Positive Correlation](https:\/\/miro.medium.com\/max\/1064\/1*tESnC588CAVypsg7HudpgA.png)\n\n**Negative Correlation:** Two features (variables) can be negatively correlated with each other. It means that when the value of one variable increase then the value of the other variable(s) decreases.\n\n![Negative Correlation](https:\/\/miro.medium.com\/max\/1152\/1*VxbqTp-OjYMpqDI0_taHSA.png)\n\n**No Correlation:** Two features (variables) are not correlated with each other. It means that when the value of one variable increase or decrease then the value of the other variable(s) doesn\u2019t increase or decreases.\n\n![No Correlation](https:\/\/miro.medium.com\/max\/1152\/1*g3PZJ1XmAE5ISmwRLrVz7Q.png)","b32f4cd1":"At first look, this data has <span style=\"color:green;\"> **20 features** <\/span>. This data lists the behaviour of over <span style=\"color:green;\">**7000 potential customers** <\/span>on an automobile company's website. The last column, 'Retail', tells us whether the person ended up buying a vehicle or not. \nThe problem statment is derivative from here: we need to predict whether a person browsing the website will actually buy the vehicle or not, based on the behaviour of previous potential customers. Since we have the ground truth available, this becomes a **supervised machine learning problem** And if we look at the target variable 'Retail', we can see that it has only two possible discrete outcomes - Yes or No. So, this is a classification use case, and more precisely, a **binary classification** use case.\n\nLet's have a look at the data.","89cf6a79":"A big part of machine learning is classification \u2014 we want to know what class (a.k.a. group) an observation belongs to. The ability to precisely classify observations is extremely valuable for various business applications like predicting whether a particular user will buy a product or forecasting whether a given loan will default or not. Data science provides a plethora of classification algorithms such as logistic regression, support vector machine, naive Bayes classifier, and decision trees. But near the top of the classifier hierarchy is the random forest classifier.\n\nFirst, let\u2019s quickly go over **decision trees** as they are the building blocks of the random forest model. Fortunately, they are pretty intuitive.\n\n![](https:\/\/miro.medium.com\/max\/900\/1*LMoJmXCsQlciGTEyoSN39g.jpeg)\n\nImagine that our dataset consists of the numbers at the top of the figure to the left. We have two 1s and five 0s (1s and 0s are our classes) and desire to separate the classes using their features. The features are color (red vs. blue) and whether the observation is underlined or not. So how can we do this?\n\nColor seems like a pretty obvious feature to split by as all but one of the 0s are blue. So we can use the question, \u201cIs it red?\u201d to split our first node. You can think of a node in a tree as the point where the path splits into two \u2014 observations that meet the criteria go down the Yes branch and ones that don\u2019t go down the No branch.\n\nThe No branch (the blues) is all 0s now so we are done there, but our Yes branch can still be split further. Now we can use the second feature and ask, \u201cIs it underlined?\u201d to make a second split.\n\nThe two 1s that are underlined go down the Yes subbranch and the 0 that is not underlined goes down the right subbranch and we are all done. Our decision tree was able to use the two features to split up the data perfectly. Victory!\n\nObviously in real life our data will not be this clean but the logic that a decision tree employs remains the same. At each node, it will ask \u2014 *What feature will allow me to split the observations at hand in a way that the resulting groups are as different from each other as possible (and the members of each resulting subgroup are as similar to each other as possible)?*\n\n# Random Forest\n\nRandom forest, like its name implies, consists of a large number of individual decision trees that operate as an ensemble. Each individual tree in the random forest spits out a class prediction and the class with the most votes becomes our model\u2019s prediction (see figure below).\n\n![](https:\/\/miro.medium.com\/max\/900\/1*VHDtVaDPNepRglIAv72BFg.jpeg)","e6f0ea6b":"We are going to import scipy, numpy, matplotlib, pandas right now.\nWe will also import some scikit-learn modules. **Scikit-learn** is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection and evaluation, and many other utilities.","6cbf3898":"<h1><center><b> Customer Scoring: Your First Machine Learning Project in Python Step-By-Step <\/b><\/center><\/h1>","d5b0a60d":"In case the correlation between two variable is high, we remove one of the variables depending on how important each variable is to the dataset. We don't have such high degree of correlation here.\n","b8b8b610":"As you can see above, all variables have been scaled and have taken values from 0 to 1.","b60a5f60":"We will now split our data into training and testing datasets.\n![](https:\/\/cs.csub.edu\/~clei\/teaching\/files\/DataScience\/_CrossValidation\/CV_holdout.png)","f35d4c3a":"![](https:\/\/miro.medium.com\/max\/2800\/0*Vvv85FQ9KAqfyb54.png)","da41514f":"For a better understanding of the results, we will plot a **confusion matrix**.\n\nA confusion matrix is an N x N matrix used for evaluating the performance of a classification model, where N is the number of target classes. The matrix compares the actual target values with those predicted by the machine learning model. This gives us a holistic view of how well our classification model is performing and what kinds of errors it is making.","0228717d":"Machine learning algorithm just sees number \u2014 if there is a vast difference in the range say few ranging in thousands and few ranging in the tens, and it makes the underlying assumption that higher ranging numbers have superiority of some sort. So these more significant number starts playing a more decisive role while training the model.\nTherefore, we will scale all variables to a range of 0 to 1, using **MinMaxScaler**.\n![https:\/\/miro.medium.com\/max\/458\/0*Gy668nQfirqf6W4c](http:\/\/miro.medium.com\/max\/458\/0*Gy668nQfirqf6W4c)","93210d85":"# 5. Implement, Document and Maintain \ud83d\uddc2","8d2166ac":"The variable <span style=\"color:blue;\"> **total_time_spent**<\/span> is an object type variable which is not correct. It must be converted to a numeric (float) type variable before we can process it any further.","4321e22a":"The fundamental concept behind random forest is a simple but powerful one \u2014 the wisdom of crowds. In data science speak, the reason that the random forest model works so well is: A large number of relatively uncorrelated models(trees) operating as a committee will outperform any of the individual constituent models\n\nThe reason for this wonderful effect is that the trees protect each other from their individual errors (as long as they don\u2019t constantly all err in the same direction). While some trees may be wrong, many other trees will be right, so as a group the trees are able to move in the correct direction.\n\nParameters that we commonly use are :\n\n* **n_estimators** = number of trees in the foreset\n* **max_features** = max number of features considered for splitting a node\n* **max_depth** = max number of levels in each decision tree\n* **min_samples_split** = min number of data points placed in a node before the node is split\n* **min_samples_leaf** = min number of data points allowed in a leaf node","728158bb":"The objective is to estimate the performance of the machine learning model on new data: **data not used to train the model.**\n\nThis is how we expect to use the model in practice. That is, to fit it on available data with known inputs and outputs, then make predictions on new examples in the future where we do not have the expected output or target values.","45dceb8b":"**Observations**:\n* From random forest algorithm, number of pages visited, time spent in the last week, west zone, source of enquiry and total time spent on the webiste are the most important predictor variables to predict retail.\n","a6347fda":"11 NA cells in total_time_spent. This is a very small number and these rows can just be dropped from the dataset.","4883230a":"As we know, our target variable has two classes - Yes and No. But we need to convert this to numeric data for our models to be able to process the data. \nBy convention, 'Yes' will be replaced by 1 and 'No' will be replaced by 0.","2e9498b6":"![](https:\/\/miro.medium.com\/max\/638\/1*lfsNq-qhWwOo-bzqwh7Igw.jpeg)\n\nDeployment of an ML model simply means the integration of the model into an existing production environment which can take in an input and return an output that can be used in making practical business decisions. \n\nAfter testing the model on various datasets and getting a green light to productionise, we do the following:\n* Set up batch or API prediction system (depending on the use case)\n* Document modelling process for reproducibility\u00a0\n* Create model monitoring and maintenance plan\n\n\nThere are frameworks like Tensorflow, Pytorch, and Scikit-Learn for training, running and deploying models, programming languages like Python, Java, and Go, and even cloud environments like AWS, GCP, and Azure. ","402d894d":"# 1. Define Project Objectives \ud83c\udfaf\n\nCustomer Scoring is an approach to find whether a lead will buy our product or not. This method uses personal information of the lead and his activities on the company's website. We try to track the activities of the lead and find whether he in interested in buying our products or not.\n","e5ca67f0":"# 3. Data Preparation \ud83d\udee0","72122ada":"\nWe mostly have categorical features with varying number of categories.\n\nHow do we check the number of categories in a feature when it's not clear from a look at the 'head'?\n\nWe can use the following pandas method.","c2cc6949":"Here, the first column i.e colour_red can be dropped. Because for instances where both the other colours are 0, it belongs to red automatically, like in the first row. This helps us reduce the number of redundant features which make the model unnecessarily complex.\nProgrammatically, we do this by adding drop_first variable to the get_dummies fucntion.","2a313db6":"![lead_scoring.png](https:\/\/www.gofcr.com\/wp-content\/upload\/2018\/05\/yes-no-qualityFB.jpg)","88f73350":"The above sneak peak at the data reveals the features we have. For instance, gender, own_vehicle, homepage, first_enquiry, zone etc. are all categorical variables with two categories each - Yes and No. **Zone** has three categories - North, South, West. \nWe have to handle these categorical features (which we will come to in a short while), since machine learning models can only process numeric data.\n\n* customer_code - alphanumeric unique code\n* gender - Male, Female\n* dealer_search - 0 means no and 1 means yes - whether a person visited dealer page or not\n* own_vehicle - yes or no \n* homepage - yes or no - whether a person visited home page or not\n* no_of_pages_visited - integer values - total number of pages visited\n* first_enquiry - yes or no \n* parts\/service - yes or no - whether a person visited parts\/service page or not\n* p1 - enquiry made for this product? yes or no\n* p2 - enquiry made for this product? yes or no\n* p3 - enquiry made for this product? yes or no\n* p4 - enquiry made for this product? yes or no\n* p5 - enquiry made for this product? yes or no\n* p6 - enquiry made for this product? yes or no\n* zone - North, South, West\n* model_page_visited - yes or no - whether a person visited the product page of the model he is interested in or not\n* source_of_enquiry - search engine, social networking, etc.\n* time_spent_last_1_week - float variable\n* total_time_spent - float variable\n* Retail - Our target variable\n\n\nLet us check the type of each column.","5c81d62f":"The best way to learn a new concept is to work through it, end-to-end. When you are applying machine learning to your own datasets, you get a better understanding of the key steps that are involved in the successful application of ML to a use case.\n\nA machine learning project has a number of well known steps:\n\n\n1. Define project objectives.\n2. Acquire and explore data.\n3. Data preparation.\n4. Modelling and evaluation.\n5. Implement, document and maintain.\n\n\n\n\n\n","8b2091c1":"# 2. Acquire and Explore Data \ud83d\udd0d\n\nLet us begin by importing some basic and most widely used ML libraries. There are 5 key libraries that you will need to install. \n<span style=\"color:blue;\"> SciPy <\/span> (pronounced \u201cSigh Pie\u201d) is a Python-based ecosystem of open-source software for mathematics, science, and engineering. In particular, these are some of the core packages: \n\n![Screenshot%202021-03-22%20at%202.26.44%20PM.png](attachment:Screenshot%202021-03-22%20at%202.26.44%20PM.png)","89f9e58b":"We will now have a look at the categorical variables in our data."}}