{"cell_type":{"ba9748d6":"code","22bd6d79":"code","2dbc38b2":"code","992198a9":"code","d825bae4":"code","75edd317":"code","c4bfb74e":"code","27b78faf":"code","a0fb5c07":"code","a0d65ba2":"code","b6a98a8a":"code","af83e417":"code","a32e8a5e":"code","ed1d65a3":"code","b5a1fa7e":"code","01820846":"code","556ef225":"code","729ffa01":"code","f541d7e9":"code","8faa9089":"code","790229d6":"code","5e6c0f07":"code","eedcc277":"code","50a733fd":"code","9b1f1080":"code","6103d130":"markdown","54883f42":"markdown","621c5f2e":"markdown","e398118a":"markdown","9fd8b278":"markdown"},"source":{"ba9748d6":"import warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nimport numpy as np\nimport json\nimport networkx as nx\nfrom networkx.drawing.nx_agraph import graphviz_layout\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\n\nimport re","22bd6d79":"#OUTPUT_FILE = \"..\/input\/hasthagscambiemos\/Hashtags_Cambiemos_28SEP.json\"\nOUTPUT_FILE = \"..\/input\/hashtagsfrente\/Hashtags_Frente_28SEP.json\"\n\n# Initialize empty list to store tweets\ntweets_data = []\n\n# Open connection to file\nwith open(OUTPUT_FILE, \"r\") as tweets_file:\n    # Read in tweets and store in list\n    for line in tweets_file:\n        tweet = json.loads(line)\n        tweets_data.append(tweet)","2dbc38b2":"df = pd.DataFrame(tweets_data, columns=['user','created_at', 'text'])\ndf.head()","992198a9":"def populate_tweet_df(tweets):\n \n    df['user_id'] = list(map(lambda tweet: tweet['user']['id'], tweets))\n \n    df['user_name'] = list(map(lambda tweet: tweet['user']['name'], tweets))\n    \n    df['location'] = list(map(lambda tweet: tweet['user']['location'], tweets))\n \n    df['retweeted_from'] = list(map(lambda tweet: tweet['retweeted_status']['user']['id']\n                                  if 'retweeted_status' in tweet.keys() else '', tweets))\n \n    df['orignal_text'] = list(map(lambda tweet: tweet['retweeted_status']['text']\n                                  if 'retweeted_status' in tweet.keys() else '', tweets))\n    \n    df['tweet_id'] = list(map(lambda tweet: tweet['retweeted_status']['id']\n                                  if 'retweeted_status' in tweet.keys() else '', tweets))\n    \n    \n    return df\n\n\ndf = populate_tweet_df(tweets_data)\ndf.head()","d825bae4":"nodes = df['user_id'].drop_duplicates().dropna()","75edd317":"edges = df[df['retweeted_from']!=''][['user_id', 'retweeted_from']].drop_duplicates()","c4bfb74e":"nodes = pd.merge(nodes, edges.groupby('user_id').count().rename(columns={'retweeted_from': 'out'}), how='left',\n            left_on='user_id', right_on='user_id').fillna(0)\n\nnodes = pd.merge(nodes, edges.groupby('retweeted_from').count().rename(columns={'user_id': 'in'}), how='left',\n            left_on='user_id', right_on='retweeted_from').fillna(0)\n\nnodes = nodes[nodes['in'] > 0]\nnodes = nodes[nodes['out'] > 0]","27b78faf":"G = nx.from_pandas_edgelist(edges, 'user_id', 'retweeted_from', create_using=nx.DiGraph())\nnx.set_node_attributes(G, pd.Series(nodes['in'].to_list(), index=nodes.user_id).to_dict(), 'in')\nnx.set_node_attributes(G, pd.Series(nodes['out'].to_list(), index=nodes.user_id).to_dict(), 'out')","a0fb5c07":"degrees = G.degree()\nout_degrees = G.out_degree()\nin_degrees = G.in_degree()","a0d65ba2":"with plt.style.context('ggplot'):\n    \n    plt.loglog(sorted([n[1] for n in list(out_degrees)], reverse=True))\n    plt.loglog(sorted([n[1] for n in list(in_degrees)], reverse=True))\n    plt.title(\"Degree rank plot\")\n    plt.legend(['Out', 'In'])\n    plt.ylabel(\"degree\")\n    plt.xlabel(\"rank\")","b6a98a8a":"def get_strongly_cc(G, node):\n    \"\"\" get storngly connected component of node\"\"\" \n    for cc in nx.strongly_connected_components(G):\n        if node in cc:\n            return cc\n    else:\n        return set()\n\ndef get_weakly_cc(G, node):\n    \"\"\" get weakly connected component of node\"\"\" \n    for cc in nx.weakly_connected_components(G):\n        if node in cc:\n            return cc\n    else:\n        return set()","af83e417":"SGcc = []\nfor node in G.nodes():\n    strong_component = get_strongly_cc(G, node)  # Weakly connected component of node in G\n    if len(strong_component) > len(SGcc):\n        SGcc = strong_component","a32e8a5e":"SGcc = G.subgraph(SGcc)","ed1d65a3":"SGcc = SGcc.to_undirected()\nSGcc_degree = SGcc.degree()","b5a1fa7e":"plt.figure(num=None, figsize=(25, 25), dpi=100, facecolor='w', edgecolor='k')\n\npos = nx.spring_layout(SGcc)\n\nnx.draw(SGcc, pos, nodelist=dict(SGcc_degree).keys(), node_size=[v * 50 for v in dict(SGcc_degree).values()], \n       width=0.5, alpha=0.5, edge_color='b')\n\nplt.axis('off')\nplt.show()","01820846":"max_degree = sorted(dict(SGcc_degree).values())[-1]\nlargest_hub = [n for n in dict(SGcc_degree) if SGcc_degree[n]==max_degree]\n\nhub_ego = nx.ego_graph(SGcc, largest_hub[0])\n\nplt.figure(num=None, figsize=(15, 15), dpi=80, facecolor='w', edgecolor='k')\n\npos = nx.spring_layout(SGcc)\n\n#nx.draw(hub_ego, pos, node_size=50, width=0.5, alpha=0.5, edge_color='b')\n#nx.draw_networkx_nodes(hub_ego, pos, nodelist=largest_hub, node_size=300, node_color='r')\n\nnx.draw(hub_ego, nodelist=hub_ego.nodes(), node_size=[v * 10 for v in dict(hub_ego.degree()).values()], \n       width=0.5, alpha=0.5, edge_color='b')\n\nplt.axis('off')\nplt.show()","556ef225":"SGcc.remove_edges_from(SGcc.selfloop_edges())","729ffa01":"i=1\nwhile True:\n    if len(nx.k_core(SGcc, i)) == 0:\n        break\n    else:\n        print('Core exists for K=%d' % i)\n        i += 1","f541d7e9":"MaxKCore = nx.k_core(SGcc, i-1)\ndegrees_MaxKCore = MaxKCore.degree()","8faa9089":"plt.figure(num=None, figsize=(15, 15), dpi=80, facecolor='w', edgecolor='k')\n\npos = nx.spring_layout(MaxKCore)\n\nnx.draw(MaxKCore, pos, nodelist=dict(degrees_MaxKCore).keys(), node_size=[v * 10 for v in dict(degrees_MaxKCore).values()], \n       width=0.5, alpha=0.5, edge_color='b')\n\nplt.axis('off')\nplt.show()","790229d6":"def extract(start, tweet):\n\n    words = tweet.split()\n    return [word[1:] for word in words if word[0] == start]\n\ndef strip_punctuation(s):\n    #return s.translate(None, '!\"#$%&\\'()*+,-.\/:;<=>?@[\\\\]^_`{|}~')\n    return s.translate(str.maketrans('','','!\"$%&\\'()*+,-.\/:;<=>?@[\\\\]^_`{|}~'))\n\ndef extract_hashtags(tweet):\n    # strip the punctuation on the tags you've extracted (directly)\n    hashtags = [strip_punctuation(tag) for tag in extract('#', tweet)]\n    # hashtags is now a list of hash-tags without any punctuation, but possibly with duplicates\n\n    result = []\n    for tag in hashtags:\n        if tag not in result:  # check that we haven't seen the tag already (we know it doesn't contain punctuation at this point)\n            result.append(tag)\n    return result","5e6c0f07":"df['hashtags'] = df['orignal_text'].apply(extract_hashtags)\ndf2 = df[['orignal_text', 'hashtags']]\ndf2 = df2[[len(p)>1 for p in df2['hashtags']]]\ndf2.head()","eedcc277":"list_Hashtags = df2['hashtags'].tolist()\n                   \nH = nx.Graph()\n\nfor L in list_Hashtags:\n    for i in range(len(L)):\n        for j in range(i,len(L)):\n            H.add_edge(L[i], L[j])","50a733fd":"H = sorted(nx.connected_component_subgraphs(H), key=len, reverse=True)[0]\ndegrees_h = H.degree()","9b1f1080":"plt.figure(num=None, figsize=(20, 20), dpi=150, facecolor='w', edgecolor='k')\n\npos = nx.spring_layout(H)\n\n# nodes\nnx.draw_networkx_nodes(H, pos, nodelist=dict(degrees_h).keys(), \n                       node_size=[v * 40 for v in dict(degrees_h).values()], alpha=0.5)\n\n# edges\nnx.draw_networkx_edges(H, pos, width=0.3, alpha=0.3, edge_color='b')\n\n# labels\nnx.draw_networkx_labels(H, pos, font_size=7, font_family='sans-serif')\n\nplt.axis('off')\nplt.show()","6103d130":" ## Connected Components","54883f42":"## K Core","621c5f2e":"## Degrees","e398118a":"## Ego Network","9fd8b278":"## Hashtag Concurrency"}}