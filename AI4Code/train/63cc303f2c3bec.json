{"cell_type":{"0b23d87a":"code","17764e2d":"code","3f508b9e":"code","c37b9202":"code","2572ab89":"code","1ab055b5":"code","6c1260bd":"code","cf45b777":"code","93e3abb4":"code","e59541b0":"code","b0738b7f":"code","d3f484ec":"code","2a8500b8":"code","5752f8a8":"code","7844f1fe":"code","9bc41065":"code","bbcd5e24":"code","d6b897e3":"code","f0eb751b":"code","0bb607fb":"code","0f068cfb":"code","ac0edc4f":"code","b46ed3cc":"code","88004e01":"code","ef2a7d09":"code","8b662442":"code","a028c86e":"code","237cd607":"code","15190c4a":"code","8ac7065f":"code","80b3fe6d":"code","1fc213c0":"code","0cd783ea":"code","c581414e":"code","89050be0":"code","652a2e4c":"code","03e92ade":"code","91884d72":"code","16d56d70":"code","93ff5ac1":"code","5c91ae26":"code","c3c47e3e":"code","2e9321d5":"code","c93d7737":"code","48354cbd":"code","e8943e7d":"code","ced9cc26":"code","f5e2e777":"code","5fbfc0d3":"code","92224050":"code","d5b88dc4":"code","b6c76b9b":"code","29411b59":"code","2185e856":"code","cb1bcc05":"markdown","7c59a403":"markdown","2346eceb":"markdown","c02ead20":"markdown","6f4ca6c9":"markdown","5fb30984":"markdown","fd9b7c30":"markdown","611819b1":"markdown","11e88bad":"markdown","4d4c89b2":"markdown","a4278c5b":"markdown"},"source":{"0b23d87a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\n\n# to display all columns and rows:\npd.set_option('display.max_columns', None); pd.set_option('display.max_rows', None);\n\n#to arrange the decimals\npd.set_option('display.float_format', lambda x: '%.2f' % x)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","17764e2d":"#Load Data\ndata=pd.read_csv(\"..\/input\/supermarket-sales\/supermarket_sales - Sheet1.csv\")\ndata.head()","3f508b9e":"data.shape","c37b9202":"data['Invoice ID'].nunique()","2572ab89":"a=data.groupby(['Invoice ID', 'Rating']).agg({'Rating' : \"nunique\"})\na[a[\"Rating\"]>1]","1ab055b5":"# Define categoric features with function\n\ndef grab_cat_names(dataframe, cat_th = 10, car_th = 20):\n# all categoric columns\n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == 'O']  \n    \n # data type is not categoric but the number of unique values are less than 10\n    num_but_cat =  [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n                    dataframe[col].dtypes != 'O' ]\n    \n # data type is categoric and number of unique values are greater then 20\n    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n                   dataframe[col].dtypes == 'O']      \n    \n # all categoric columns + non-categorical value with unique value less than 10\n    final_cat_cols = cat_cols + num_but_cat   \n    \n # without cat_but_car\n    final_cat_cols =  [col for col in final_cat_cols if col not in cat_but_car]   \n    return  cat_cols, num_but_cat, cat_but_car, final_cat_cols\n\ncat_cols, num_but_cat, cat_but_car, final_cat_cols = grab_cat_names(data)","6c1260bd":"cat_cols","cf45b777":"num_but_cat","93e3abb4":"cat_but_car","e59541b0":"final_cat_cols","b0738b7f":"# But I will not add gross margin percentage\nfinal_cat_cols=['Branch', 'City', 'Customer type', 'Gender', 'Product line', 'Payment']","d3f484ec":"# This data includes selected categoric features and total revenue and rating\n\nagg_df = data.groupby(by=['Branch', 'City', 'Customer type',\n                          'Gender', 'Product line', 'Payment', 'Rating']).\\\n                          agg({\"Total\" : \"sum\"}).sort_values(\"Total\", ascending=False)","2a8500b8":"agg_df.head()","5752f8a8":"agg_df.reset_index(inplace=True)","7844f1fe":"data[\"Rating\"].describe().T","9bc41065":"# Lets convert Rating to categoric with cut functions\nbins = [agg_df[\"Rating\"].min(), 5.5, 7, 8.5, agg_df[\"Rating\"].max()]\nmylabels = [str(agg_df[\"Rating\"].min()) + '-5,5',\n            '5,5-7', '7-8,5',\n            '8,5-'+str(agg_df[\"Rating\"].max())]\nagg_df[\"Rating_cat\"] = pd.cut(agg_df[\"Rating\"], bins, labels=mylabels)","bbcd5e24":"agg_df.head()","d6b897e3":"#Select categoric features\nagg_df['customer_level_based'] = [row[0] + \"_\" + row[1].upper() + \"_\"\n                                  + row[2].upper() + \"_\" + row[3].upper() + \"_\"\n                                  + row[4].upper() + \"_\" + row[5].upper() + \"_\"\n                                  + str(row[8]) for row in agg_df.values]","f0eb751b":"[row[0] + \"_\" + row[1].upper() + \"_\"\n + row[2].upper() + \"_\" + row[3].upper() + \"_\"\n + row[4].upper() + \"_\" + row[5].upper() + \"_\"\n + str(row[8]) for row in agg_df.values][0:5]","0bb607fb":"# Now we summarized one features to all categorics features\nagg_df.head()","0f068cfb":"agg_df = agg_df[[\"customer_level_based\", \"Total\"]]\n\n# Let's find the average total revenues according to the customer_level_based segmentation.\nagg_df = agg_df.groupby(\"customer_level_based\").agg({\"Total\": \"mean\"})\nagg_df.head()","ac0edc4f":"agg_df = agg_df.reset_index()","b46ed3cc":"# Assign segment to using qcut\nagg_df[\"segment\"] = pd.qcut(agg_df[\"Total\"], 4, labels = [\"D\", \"C\", \"B\", \"A\"])","88004e01":"agg_df.head()","ef2a7d09":"new_user = \"B_MANDALAY_NORMAL_FEMALE_ELECTRONIC ACCESSORIES_CREDIT CARD_5,5-7\"\nagg_df[agg_df[\"customer_level_based\"] == new_user]","8b662442":"pip install openpyxl","a028c86e":"# To automatize data importing\n\ndef load_online_retail_II():\n    df_ = pd.read_excel(\"..\/input\/online-retail\/online_retail_II.xlsx\",\n                       sheet_name = \"Year 2010-2011\")\n    return df_\n\ndf_ = load_online_retail_II()\ndf = df_.copy()\n\ndf.head()","237cd607":"df.describe([0.01, 0.05, 0.10, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99]).T","15190c4a":"df.dropna(inplace = True)","8ac7065f":"# To automatize outlier detection and replace outliers to Percentile Capping (lower and upper bound)\ndef outlier_thresholds(dataframe, variable):         \n    quartile1 = dataframe[variable].quantile(0.01)\n    quartile3 = dataframe[variable].quantile(0.99)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit\n\n\ndef replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n\n\ndef crm_data_prep(dataframe):\n    dataframe.dropna(axis=0, inplace=True)\n    dataframe = dataframe[~dataframe['Invoice'].str.contains(\"C\", na=False)]\n    dataframe = dataframe[dataframe[\"Quantity\"] > 0]\n    replace_with_thresholds(dataframe, \"Quantity\")\n    replace_with_thresholds(dataframe, \"Price\")\n    dataframe[\"TotalPrice\"] = dataframe[\"Quantity\"] * dataframe[\"Price\"]\n    return dataframe","80b3fe6d":"df = crm_data_prep(df)","1fc213c0":"#Changing type of Customer ID from float to int\ndf[\"Customer ID\"] = df[\"Customer ID\"].astype(int)\ndf.head()","0cd783ea":"import datetime as dt\ndf[\"InvoiceDate\"].max()","c581414e":"today_date = dt.datetime(2011,12,11)","89050be0":"rfm = df.groupby('Customer ID').agg({'InvoiceDate': lambda date: (today_date - date.min()).days,   # Recency\n                                    'Invoice': lambda num: num.nunique(),                          # Frewuency\n                                    'TotalPrice': lambda TotalPrice: TotalPrice.sum()})            # Monetary\n\nrfm.columns = ['Recency', 'Frequency', 'Monetary']\n\n\nrfm = rfm[(rfm[\"Monetary\"] > 0) & (rfm[\"Frequency\"] > 0)] ","652a2e4c":"rfm.head()","03e92ade":"##Normally the smallest of the recency scoring, which is 1, is the best recency score. \n#However, we will define this in reverse and put the value 5 as the best recency value so that it will be the same as the others, \n#so score 5 will be the most recent and the best recency score:\n\nrfm[\"RecencyScore\"] = pd.qcut(rfm['Recency'], 5, labels = [5, 4, 3, 2, 1])","91884d72":"cut_bins = [0,1,2,3,9,210]\n\nrfm[\"FrequencyScore\"] = pd.cut(rfm[\"Frequency\"], bins = cut_bins, labels = [1, 2, 3, 4, 5])","16d56d70":"rfm[\"MonetaryScore\"] = pd.qcut(rfm['Monetary'], 5, labels = [1, 2, 3, 4, 5])\nrfm.head()","93ff5ac1":"rfm[\"RFM_SCORE\"] = (rfm[\"RecencyScore\"].astype(str) +\n                    rfm[\"FrequencyScore\"].astype(str) +\n                    rfm[\"MonetaryScore\"].astype(str))","5c91ae26":"# Champions are your best customers which is;\n\nrfm[rfm[\"RFM_SCORE\"] == \"455\"].head()\n","c3c47e3e":"# Hibernating\n\nrfm[rfm[\"RFM_SCORE\"] == \"111\"].head()","2e9321d5":"# Naming RFM\nseg_map = {\n    r'[1-2][1-2]': 'Hibernating',\n    r'[1-2][3-4]': 'At_Risk', \n    r'[1-2]5': 'Cant_Loose',\n    r'3[1-2]': 'About_to_Sleep',\n    r'33': 'Need_Attention',\n    r'[3-4][4-5]': 'Loyal_Customers',\n    r'41': 'Promising', \n    r'51': 'New_Customers',\n    r'[4-5][2-3]': 'Potential_Loyalists',\n    r'5[4-5]': 'Champions'\n}\n\nrfm['Segment'] = rfm['RecencyScore'].astype(str) + rfm['FrequencyScore'].astype(str)\n\nrfm['Segment'] = rfm['Segment'].replace(seg_map, regex=True)","c93d7737":"rfm[[\"Segment\", \"Recency\", \"Frequency\", \"Monetary\"]].groupby(\"Segment\").agg([\"mean\", \"count\"])","48354cbd":"df.head()","e8943e7d":"cltv_df = df.groupby(\"Customer ID\").agg({\"Invoice\": lambda x: len(x),     # total transaction\n                                         \"Quantity\": lambda x: x.sum(),   # total unit\n                                         \"TotalPrice\": lambda x:x.sum()}) # total price\ncltv_df.columns = ['total_transaction', 'total_unit', 'total_price']\n\ncltv_df.head()","ced9cc26":"#CLTV Calculation Formula \n\n# CLTV = (Customer_Value \/ Churn_Rate) * Profit_margin\n# Customer_Value = Average_Order_Value * Purchase_Frequency\n# Average_Order_Value = Total_Revenue \/ Total_Number_of_Orders\n# Purchase_Frequency = Total_Number_of_Orders \/ Total_Number_of_Customers\n# Churn_Rate = 1 - Repeat_Rate\n# Profit_Margin","f5e2e777":"# Calculate Average Order Value\ncltv_df['avg_order_value'] = cltv_df['total_price'] \/ cltv_df['total_transaction']","5fbfc0d3":"# Calculate Purchase Frequency\ncltv_df['purchase_frequency'] = cltv_df['total_transaction'] \/ cltv_df.shape[0]","92224050":"# Calculate Repeat Rate and Churn Rate\nrepeat_rate = cltv_df[cltv_df.total_transaction > 1].shape[0] \/ cltv_df.shape[0]\nchurn_rate = 1 - repeat_rate","d5b88dc4":"# Calculate Profit Margin\ncltv_df['profit_margin'] = cltv_df['total_price'] * 0.05","b6c76b9b":"# Calculate Customer Lifetime Value\n\ncltv_df['CV'] = (cltv_df['avg_order_value'] * cltv_df['purchase_frequency']) \/ churn_rate\n\ncltv_df['CLTV'] = cltv_df['CV'] * cltv_df['profit_margin']\n\ncltv_df.sort_values(\"CLTV\", ascending = False).head(10)","29411b59":"# Using Min Max Scaler CLTV in order to standardize\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler(feature_range=(1, 100))\nscaler.fit(cltv_df[['CLTV']])\ncltv_df[\"SCALED_CLTV\"] = scaler.transform(cltv_df[[\"CLTV\"]])\n\ncltv_df.sort_values(\"CLTV\", ascending = False).head(10)","2185e856":"cltv_df[\"segment\"] = pd.qcut(cltv_df[\"SCALED_CLTV\"],\n                             4, labels=[\"D\", \"C\", \"B\", \"A\"])\n\ncltv_df[[\"segment\", \"total_transaction\", 'total_unit', \n         'total_price', 'CLTV', 'SCALED_CLTV']].sort_values(by=\"SCALED_CLTV\", \n                                                            ascending=False).head()\n\ncltv_df.groupby(\"segment\")[[\"total_transaction\", 'total_unit',\n                            'total_price', 'CLTV', 'SCALED_CLTV']].agg({\"mean\", \n                                                                        \"count\", \n                                                                        \"sum\"})","cb1bcc05":"[LEVEL BASED PERSONA](#1)\n\n[RFM METRICS](#2)\n\n[CLV CALCULATION](#3)","7c59a403":"In describe method, we see negative quantity and price values. As these values are due to the cancellation, we must drop refunds.","2346eceb":"<a id=\"2\"><\/a> <br>\n\n**RFM Metrics**\n\nRFM marketing analysis method is used in order to segmentation of customers.  It is another way to define customer segmentation.\n\n* Recency: How recently a customer has made a purchase , The freshness of the customer aivity, be it purchases or visits. Time since last order.\n* Frequency: How often a customer makes a purchase , The frequency of customer transactions or visits.\n* Monetary Value: How much money a customer spends on purchases , The intention of customer to spend or purchasing power of customer\n\nRFM analysis numerically ranks a customer in each of these three categories, generally on a scale of 1 to 5 (the higher the number, the better the result). The \"best\" customer would receive a top score in every category. This 3 historical metrics calculated for each individual customer for more personalized and impactful targeting.","c02ead20":"Calculating RFM Scores","6f4ca6c9":"For example new user information;","5fb30984":"<a id=\"3\"><\/a> <br>\n**CLV CALCULATION**\n\nCustomer lifetime value (CLTV or CLV) can be defined as the present value of a customer for the company based on projected future cash flows from the customer relationship. CLTV represents the total amount of money spent on the business or products over lifetime of a customer.\n\nThe predictive CLTV models are built around 4 key metrics. These are:\n\n1. Recency\n2. Monetary\n3. Frequency\n4. Tenure (Customer age)","fd9b7c30":"**Check Duplicate ID**","611819b1":"Calculating RFM Metrics","11e88bad":"Naming & Analysing RFM Segments","4d4c89b2":" Let's take a closer look at the features.\n \n * InvoiceNo: Invoice number.If this code starts with C, it means refund. \n * StockCode: Product code. Unique number for each product \n * Description: Product name \n * Quantity: Number of products. Those who start with C get negative value\n * InvoiceDate: Invoice date and time \n * UnitPrice: Product price (in pounds) \n * CustomerID: Customer number. Unique number for each customer \n * Country: Country name.","a4278c5b":"<a id=\"1\"><\/a> <br>\n**Level Based Persona**\n\nLet's learn how to do simple segmentation in a world without machine learning!\n\nSteps:\n\n1. First of all, we must make sure that our data is unique on the basis of customer id.\n2. We must select the features from data. The selected features type (numeric or categoric etc.) is not important for now. Because we will then categorize the numerics by dividing them into intervals to using cut function."}}