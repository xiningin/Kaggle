{"cell_type":{"0507e2d3":"code","db12eca3":"code","3d122735":"code","1176c916":"code","1f01030e":"code","05ca5f5a":"code","4820fd40":"code","9483be11":"code","eb5580d4":"code","58ae8847":"code","df97e523":"code","0795e3c6":"code","4069f50f":"code","f290d1f4":"code","501afc90":"code","090fcbaf":"code","51b3d927":"code","21321dca":"code","8b1d609d":"code","8c7a1ea8":"code","cd371500":"code","4b4675bd":"code","13b7e815":"code","0b3ca0d5":"code","d84ab737":"markdown","e3b964b6":"markdown","188fdbcd":"markdown","670212e0":"markdown","b2fa0d45":"markdown","89d03ffa":"markdown","faa9828e":"markdown","2f2d3f48":"markdown","fd6eb823":"markdown","c94126df":"markdown","303171e5":"markdown","dbf2368e":"markdown","86094bcc":"markdown","26d637a0":"markdown","b91214e3":"markdown","e1a0e6c8":"markdown","15f314f7":"markdown","d3a10347":"markdown","fa324f40":"markdown","067639b1":"markdown","431befa2":"markdown","3da6a07d":"markdown","2c0df970":"markdown"},"source":{"0507e2d3":"import tensorflow as tf\nimport glob\nimport imageio\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport PIL\nfrom tensorflow.keras import layers\nimport time\nimport random","db12eca3":"(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data() # Will work with only train_images","3d122735":"train_images[0].shape","1176c916":"train_images_to_show=train_images[0:49] # 50 images to show\nfig = plt.figure(figsize=(30, 15)) # width and hieght in inches\ncolumns = 10\npictures_count = train_images_to_show.shape[0]\nrows = np.ceil(pictures_count \/ columns)\nfor i in range(50):\n    fig.add_subplot(rows, columns, i + 1)\n    plt.imshow(train_images[i])# an array of (28,28) shape  ","1f01030e":"train_images=train_images[train_labels==5]","05ca5f5a":"plt.imshow(train_images[random.randint(1,4251)])","4820fd40":"train_images.shape","9483be11":"train_images=train_images.reshape(5421,28,28,1) # add one more dimension to indicate a single channel ","eb5580d4":"train_images = (train_images - 127.5) \/ 127.5 # Normalize the images to [-1, 1]","58ae8847":"latent_dim=100 # dimension of noise distribution which will be fed to the Generator to produce images","df97e523":"def build_generator():\n    model=tf.keras.Sequential()\n    model.add(layers.Dense(128*7*7,use_bias=False,input_shape=(100,)))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Reshape((7, 7, 128)))\n    assert model.output_shape == (None, 7, 7, 128) # Note: None is the batch size\n\n    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(1, 1), padding='same', use_bias=False))## half padding is used. \n    assert model.output_shape == (None, 7, 7, 64)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n    assert model.output_shape == (None, 14, 14, 32)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n    assert model.output_shape == (None, 28, 28, 1)\n\n    return model","0795e3c6":"generator=build_generator()\nnoise=tf.random.normal([1,100])\ngenerated_image=generator(noise,training=False)\nplt.imshow(generated_image[0, :, :, 0], cmap='gray')","4069f50f":"def build_discriminator():\n    model=tf.keras.Sequential()\n    model.add(layers.Conv2D(64,(5,5),strides=(2,2),padding='same',input_shape=[28,28,1]))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Flatten())\n    model.add(layers.Dense(1))\n\n    return model","f290d1f4":"discriminator = build_discriminator()\ndecision = discriminator(generated_image)\nprint (decision)","501afc90":"cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)","090fcbaf":"def discriminator_loss(real_output, fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss","51b3d927":"def generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output), fake_output)","21321dca":"generator_optimizer = tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)","8b1d609d":"EPOCHS = 50\nnoise_dim = 100\nnum_examples_to_generate = 1 \n# We will reuse this seed overtime (so it's easier)\n# to visualize progress in the animated GIF)\nseed = tf.random.normal([num_examples_to_generate, noise_dim])","8c7a1ea8":"def train_step(images):\n    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n      generated_images = generator(noise, training=True)\n\n      real_output = discriminator(images, training=True)\n      fake_output = discriminator(generated_images, training=True)\n\n      gen_loss = generator_loss(fake_output)\n      disc_loss = discriminator_loss(real_output, fake_output)\n\n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))","cd371500":"# a small code to shuffle and divide our data into batches\nBATCH_SIZE=256\ntrain_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(5421).batch(BATCH_SIZE)","4b4675bd":"def generate_and_save_images(model, epoch, test_input):\n  # Notice `training` is set to False.\n  # This is so all layers run in inference mode (batchnorm).\n  predictions = model(test_input, training=False)\n  plt.imshow(predictions[0, :, :, 0] * 127.5 + 127.5, cmap='gray')\n  plt.axis('off')\n  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n  plt.show()","13b7e815":"for epoch in range(EPOCHS):\n    for image_batch in train_dataset:\n        train_step(image_batch)\n        generate_and_save_images(generator,\n                                 epoch + 1,\n                                 seed)","0b3ca0d5":"from PIL import Image  \nim = Image.open('image_at_epoch_{:04d}.png'.format(50))\nim=im.resize((int(im.size[0]\/2),int(im.size[1]\/2)), 0)\nim","d84ab737":"![image_4](https:\/\/miro.medium.com\/max\/4688\/1*FbQLpEVQKsMSK-c7_5KcWw.png)\n**We maximmize loss for discriminator and minimize for Generator.**  ","e3b964b6":"## Discriminator ","188fdbcd":"### Random Noise Generation ","670212e0":"![image_5](https:\/\/3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com\/wp-content\/uploads\/2019\/05\/Summary-of-the-Generative-Adversarial-Network-Training-Algorithm-1024x669.png)","b2fa0d45":"![image_1](https:\/\/www.researchgate.net\/profile\/Lukas_Mosser\/publication\/321719286\/figure\/fig3\/AS:570220121161728@1512962479306\/Architecture-of-the-neural-network-used-to-represent-the-generator-function-G-th-z-The.png)","89d03ffa":"## Parameters and Training","faa9828e":"## Loss Functions ","2f2d3f48":"## Generator ","fd6eb823":"Now for generator since it wants to fool the discriminator it should get label 1 for its fake output. \nIt means fake output corrosponds to true label for generator\n\n- generator: minimize log(1 \u2013 D(G(z)))","c94126df":"Discriminator is a simple **CNN** that accepts inputs as image dimension both from **Generator and Train_Data** and penalizez the generator for creating fake data based on loss function given by **Ian Goodfellow**.","303171e5":"We train Discriminator and Generator **one by one and not together** . Therefore while training the generator use generator variables only and while for discriminator discriminator variables only. ","dbf2368e":"From Input repeteadly **upsample** its shape to match the dimensions of that of real image.","86094bcc":"## What GANS are?\n\nGANS are basically networks that take in trash and produce outputs that is similar but not exact to what is provided. In the architecture of GANS there are two seperate neural networks(Generators and Discriminators) which , and it is interesting to note that the network that produces predictive images does not have a clue about what the actual image is . It generates image from a noisy distribution which is iteratively penalized for being wrong by the discriminator , finally when it somewhat replicates the distribution that the real image follows the discriminator network is said to be fooled discontinuing the penalizing process.\n\n![image_0](https:\/\/miro.medium.com\/max\/720\/1*Y_AGVp0EEGEpB1Q25G6edQ.jpeg)","26d637a0":"## Load and Visualize Data ","b91214e3":"![image_3](https:\/\/cdn-images-1.medium.com\/max\/800\/1*EJPT0utTkQ2qrHfjDID5RA.png)","e1a0e6c8":"## Import Libraries","15f314f7":"keras provides a **MNIST** datset which will prove handy and easy to perform on our GAN ","d3a10347":"#### Loss for Discriminator\nThe Basic conclusion from the above series of formulas can be drawn that the while feeding the data to the discriminator from data set or real images it should be passed with label 1 for real iamges and 0 for fake images. \n\n- discriminator: maximize log D(x) + log(1 \u2013 D(G(z)))","fa324f40":"![image_2](https:\/\/images.squarespace-cdn.com\/content\/v1\/5acd141d1137a6066ac14dbe\/1523493050989-MJ1ETC2BAGAV2POWEWW2\/ke17ZwdGBToddI8pDm48kO2lZq944C5Q5o9ZL4LXfvQUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKccxvpO24GfTw40GA0EpjBhwc1qf-Cs2eKUPEC4dw6cFlAO5yXUL1_-J7hp019X7v0\/DCGAN.png?format=2500w)","067639b1":"There is an issue of **Mode Collaspse** concerned with GAN , to avoid any instance of it lets train our model to generate just a specific digit. \nIn my case that is going to be **5**.","431befa2":"A very neat and detectable **5** has been generated from distribution of noise data .","3da6a07d":"### The GoodFellow Approach for Minimizing Loss and Optimizing Algorithm","2c0df970":"Let's visualize and peek a little into **MNIST** Collection "}}