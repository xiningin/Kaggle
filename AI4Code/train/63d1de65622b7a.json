{"cell_type":{"1cef6eba":"code","67afa68c":"code","7b357db1":"code","df7863f0":"code","b9a84121":"code","c2e3c066":"code","a3ad1a4b":"code","820c5e66":"code","5360b09f":"code","39b6fd1f":"code","c2aaa071":"code","dc03a932":"code","2df1e1dc":"code","61c937cd":"code","f5da6f06":"code","c5342715":"code","d935e8ed":"code","c74efca4":"code","54c3387b":"code","0116e6f2":"code","20c0547f":"code","5ab89195":"code","b6d8ad57":"code","4c52ec34":"code","7617f5b4":"code","7f8ab73a":"code","1628202f":"code","804216cf":"code","0b3300e7":"code","21b3cf09":"code","6db43a3d":"markdown","2aeab40c":"markdown","6ff22f4c":"markdown","1191c63b":"markdown","e8b417c8":"markdown","e4a8a86d":"markdown","701a04ac":"markdown","54efc42c":"markdown","55ca24c8":"markdown","a7c9acc5":"markdown","1ea8af09":"markdown","fdc172af":"markdown","9ab20e83":"markdown","09e1a267":"markdown","8455dc64":"markdown","eada0461":"markdown"},"source":{"1cef6eba":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot\nimport matplotlib.pyplot as plt\nimport seaborn as sns","67afa68c":"path='https:\/\/raw.githubusercontent.com\/rohailkhan\/data\/main\/BostonHousing.csv'\nhousing=pd.read_csv(path)\nhousing.head()","7b357db1":"housing.shape","df7863f0":"\nfig, axes = plt.subplots( 1,2, figsize=(8,5)) # matplot part for defining figure and no of axes(plots)\n\naxes[0].set_title('first chart')\naxes[1].set_xlabel('y label size 15',color='r',size=15)\nplt.show()","b9a84121":"# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(15, 12))\nmask = np.triu(housing.corr())\n# Draw the heatmap with the mask and correct aspect ratio\n\nsns.heatmap(housing.corr(),mask = mask, fmt = \".2f\",annot=True,lw=1,cmap = 'plasma')\n\nplt.yticks(rotation = 0,size=15)\nplt.xticks(rotation = 90,size=15)\nplt.title('Correlation Heatmap')\nplt.show()","c2e3c066":"Y=housing.iloc[:,13]\nX=housing.iloc[:,0:13]","a3ad1a4b":"housing.describe()","820c5e66":"from sklearn.model_selection import cross_val_score\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom keras.wrappers.scikit_learn import KerasRegressor\n\nfrom sklearn.model_selection import KFold\n","5360b09f":"from keras.models import Sequential\nfrom keras.layers import Dense","39b6fd1f":"def base_model():\n  model=Sequential()\n  model.add(Dense(13,input_dim==13,activation='relu',kernel_initializer='glorot_uniform')) # or input_shape=(13,) because only 1 dimentions\n  model.add(Dense(64,activation='relu',kernel_initializer='glorot_uniform'))\n  model.add(Dense(1,kernel_initializer='glorot_uniform'))\n  model.compile(loss='mean_squared_error', optimizer='adam')\n  return model\n# fix random seed for reproducibility\nimport numpy\nseed = 7\nnumpy.random.seed(seed)","c2aaa071":"estimators=[ ('STANDARDIZE' , StandardScaler()) , ('KeraRegressor' , KerasRegressor(build_fn=base_model , epochs=50 ,batch_size=5,verbose=0))]\n","dc03a932":"pipe=Pipeline(steps=estimators)","2df1e1dc":"# results =cross_val_score( estimator=pipe , X=X , y=y , cv = KFold(n_splits=5, shuffle=True ,random_state=seed))","61c937cd":"def base_model():\n  model=Sequential()\n  model.add(Dense(13,input_dim=13,activation='relu',kernel_initializer='uniform')) # or input_dim=3 because only 1 dimentions\n  model.add(Dense(64,activation='relu',kernel_initializer='uniform'))\n  model.add(Dense(1,kernel_initializer='glorot_uniform'))\n  model.compile(loss='mean_squared_error', optimizer='adam')\n  return model\n# fix random seed for reproducibility\nimport numpy\nseed = 7\nnumpy.random.seed(seed)\n\nestimators=[ ('STANDARDIZE' , StandardScaler()) , ('KeraRegressor' , KerasRegressor(build_fn=base_model , epochs=50 ,batch_size=5,verbose=0))]\n\npipe=Pipeline(steps=estimators)\n\n\nresults =cross_val_score( estimator=pipe , X=X , y=Y , cv = KFold(n_splits=5, shuffle=True ,random_state=seed))\n","f5da6f06":"print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))","c5342715":"def wide_model():\n  model=Sequential()\n  model.add(Dense(20,input_dim=13,activation='relu',kernel_initializer='uniform')) # or input_dim=3 because only 1 dimentions\n  model.add(Dense(64,activation='relu',kernel_initializer='uniform'))\n  model.add(Dense(1,kernel_initializer='glorot_uniform'))\n  model.compile(loss='mean_squared_error', optimizer='adam')\n  return model\n  \n# fix random seed for reproducibility\nimport numpy\nseed = 7\nnumpy.random.seed(seed)\n\nestimators=[ ('STANDARDIZE' , StandardScaler()) , ('KeraRegressor' , KerasRegressor(build_fn=wide_model , epochs=50 ,batch_size=5,verbose=0))]\n\npipe=Pipeline(steps=estimators)\n\n\nresults =cross_val_score( estimator=pipe , X=X , y=Y , cv = KFold(n_splits=5, shuffle=True ,random_state=seed))\n","d935e8ed":"print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std())) #Standardized: -15.15 (5.33) MSE","c74efca4":"def wide_model():\n  model=Sequential()\n  model.add(Dense(20,input_dim=13,activation='relu',kernel_initializer='uniform')) # or input_dim=3 because only 1 dimentions\n  model.add(Dense(64,activation='relu',kernel_initializer='uniform'))\n  model.add(Dense(1,kernel_initializer='glorot_uniform'))\n  model.compile(loss='mae', optimizer='adam',metrics=['mae'])\n  return model\n  \n# fix random seed for reproducibility\nimport numpy\nseed = 7\nnumpy.random.seed(seed)\n\nestimators=[ ('STANDARDIZE' , StandardScaler()) , ('KeraRegressor' , KerasRegressor(build_fn=wide_model , epochs=50 ,batch_size=5,verbose=0))]\n\npipe=Pipeline(steps=estimators)\n\n\nresults =cross_val_score( estimator=pipe , X=X , y=Y , cv = KFold(n_splits=5, shuffle=True ,random_state=seed))\n\n","54c3387b":"print(\"Standardized: %.2f (%.2f)Mean Absolute Error\" % (results.mean(), results.std())) ","0116e6f2":"def wide_model_rmsprop():\n  model=Sequential()\n  model.add(Dense(20,input_dim=13,activation='relu',kernel_initializer='uniform')) # or input_dim=3 because only 1 dimentions\n  model.add(Dense(64,activation='relu',kernel_initializer='uniform'))\n  model.add(Dense(1,kernel_initializer='glorot_uniform'))\n  model.compile(loss='mae', optimizer='rmsprop',metrics=['mae'])\n  return model\n  \n# fix random seed for reproducibility\nimport numpy\nseed = 7\nnumpy.random.seed(seed)\n\nestimators=[ ('STANDARDIZE' , StandardScaler()) , ('KeraRegressor' , KerasRegressor(build_fn=wide_model , epochs=50 ,batch_size=5,verbose=0))]\n\npipe=Pipeline(steps=estimators)\n\n\nresults_rmsprop =cross_val_score( estimator=pipe , X=X , y=Y , cv = KFold(n_splits=5, shuffle=True ,random_state=seed))\n\n","20c0547f":"print(\"Standardized: %.2f (%.2f)Mean Absolute Error\" % (results_rmsprop.mean(), results_rmsprop.std())) ","5ab89195":"Y=housing.iloc[:,13]\nX=housing.iloc[:,0:13]","b6d8ad57":"from sklearn.model_selection import train_test_split\nseed = 7\nnumpy.random.seed(seed)\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30, random_state=seed)","4c52ec34":"m=wide_model_rmsprop()\nm.fit(X_train,Y_train,epochs=400,batch_size=64)","7617f5b4":"Dense_model_training_loss_mae=m.evaluate(X_train, Y_train)","7f8ab73a":"print(\"Dense Model Training loss (MAE)=%.2f\" % Dense_model_training_loss_mae[0])","1628202f":"Dense_model_test_loss_mae = evm.aluate(X_test, Y_test)\n","804216cf":"print(\"Dense Model Validation loss (MAE)=%.2f\" % Dense_model_loss_mae[0])","0b3300e7":"predictions=m.predict(X_test)","21b3cf09":"predictions.reshape(-1).shape","6db43a3d":"# Making predictions with this model","2aeab40c":"### 1- Base Sequential Model","6ff22f4c":"## Using a  wider model with 20 input Neurons","1191c63b":"Note : In KerasRegressor all parameters of Sequential.fit() can be used i.e:\nhttps:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/Model#fit \n\nfit(    \n    x=None,\n    \n    y=None, \n    \n    batch_size=None, \n    \n    epochs=1 etc\n)","e8b417c8":"# The Boston Housing Dataset\n\nThe Boston Housing Dataset is a derived from information collected by the U.S. Census Service concerning housing in the area of Boston MA. The following describes the dataset columns:\n\n**CRIM - per capita crime rate by town**\n\n**ZN - proportion of residential land zoned for lots over 25,000 sq.ft.**\n\n**INDUS - proportion of non-retail business acres per town.**\n\n**CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)**\n\n**NOX - nitric oxides concentration (parts per 10 million)**\n\n**RM - average number of rooms per dwelling**\n\n**AGE - proportion of owner-occupied units built prior to 1940**\n\n**DIS - weighted distances to five Boston employment centres**\n\n**RAD - index of accessibility to radial highways**\n\n**TAX - full-value property-tax rate per $10,000**\n\n**PTRATIO - pupil-teacher ratio by town**\n\n**B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town**\n\n**LSTAT - % lower status of the population**\n\n## **Trget column -->> MEDV - Median value of owner-occupied homes in $1000's**\n","e4a8a86d":"### All steps together","701a04ac":"## Basic Deep Learning Model","54efc42c":"### important  No activation function is used for the output layer because it is a regression","55ca24c8":"## Using RMSPROP on the same model","a7c9acc5":"# Result\n## We acheived 2.79 MAE on training and 3.23 MAE on test data which are good results","1ea8af09":"We will check cross validation score using:\n\n**cross_val_score ( pipeline[standardization & regression) , X , Y , CV=(Kfold or Startified)**\n\nLinear regression will be used Keras Linear regression API having build= basic deep learning model \n","fdc172af":"### 2- Standardization and Regression ","9ab20e83":"# Result\n# The last model with RMSPROP optimizer is selected with lower MAE= -2.44","09e1a267":"## 4- Cross Validation Score with KFold as cross validation","8455dc64":"### 3- Adding steps (i.e Standardization & Regression) to Pipeline\n","eada0461":"## Important note\n\n'accuracy' metric is used only for classification.\nAlso confusion matrix is only for classification"}}