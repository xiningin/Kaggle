{"cell_type":{"ec326322":"code","69fd5ad6":"code","78f255f5":"code","add6421f":"code","7732f745":"code","7c29ea39":"code","2799a0d6":"code","3d31fa41":"code","3e354027":"code","6a46ac41":"code","ed5f122e":"code","61db168b":"code","26374d82":"code","e6b9549e":"markdown","ef1b13e4":"markdown","69c5aca1":"markdown","533d41aa":"markdown","0d76474c":"markdown","3b259cbc":"markdown","e7c5c2f6":"markdown","05089ee3":"markdown"},"source":{"ec326322":"%matplotlib inline \nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport os\nfrom PIL import Image\n\n\ndata_train_dir = r'..\/input\/train'\nanswer_file_path = r'..\/input\/train.csv'\n\nchannels = ['_yellow', '_red', '_green', '_blue']\n\nindex_class_dict = {\n    0: \"Nucleoplasm\",\n    1: \"Nuclear membrane\",\n    2: \"Nucleoli\",\n    3: \"Nucleoli fibrillar center\",\n    4: \"Nuclear speckles\",\n    5: \"Nuclear bodies\",\n    6: \"Endoplasmic reticulum\",\n    7: \"Golgi apparatus\",\n    8: \"Peroxisomes\",\n    9: \"Endosomes\",\n    10: \"Lysosomes\",\n    11: \"Intermediate filaments\",\n    12: \"Actin filaments\",\n    13: \"Focal adhesion sites\",\n    14: \"Microtubules\",\n    15: \"Microtubule ends\",\n    16: \"Cytokinetic bridge\",\n    17: \"Mitotic spindle\",\n    18: \"Microtubule organizing center\",\n    19: \"Centrosome\",\n    20: \"Lipid droplets\",\n    21: \"Plasma membrane\",\n    22: \"Cell junctions\",\n    23: \"Mitochondria\",\n    24: \"Aggresome\",\n    25: \"Cytosol\",\n    26: \"Cytoplasmic bodies\",\n    27: \"Rods & rings\"\n}\n","69fd5ad6":"train_df = pd.read_csv(answer_file_path)\ntrain_df.head()","78f255f5":"train_df[f'target_vec'] = train_df['Target'].map(lambda x: list(map(int, x.strip().split())))\nfor i in range(28):\n    train_df[f'{index_class_dict[i]}'] = train_df['Target'].map(\n             lambda x: 1 if str(i) in x.strip().split() else 0)\ntrain_df.head()\n","add6421f":"class_index = 1  # Nuclear membrane\ncurrent_part = train_df[train_df[index_class_dict[class_index]] == 1]\nprint(f'shape before {train_df.shape}, shape after {current_part.shape}')\ncurrent_part.head()","7732f745":"def make_rgb_image_from_four_channels(channels: list, image_width=512, image_height=512) -> np.ndarray:\n    \"\"\"\n    It makes literally RGB image from source four channels, \n    where yellow image will be yellow color, red will be red and so on  \n    \"\"\"\n    rgb_image = np.zeros(shape=(image_height, image_width, 3), dtype=np.float)\n    yellow = np.array(Image.open(channels[0]))\n    # yellow is red + green\n    rgb_image[:, :, 0] += yellow\/2   \n    rgb_image[:, :, 1] += yellow\/2\n    # loop for R,G and B channels\n    for index, channel in enumerate(channels[1:]):\n        current_image = Image.open(channel)\n        rgb_image[:, :, index] += current_image\n    # Normalize image\n    rgb_image = rgb_image \/ rgb_image.max() * 255\n    return rgb_image.astype(np.uint8)","7c29ea39":"def visualize_part(start_class_index=0, nrows=4, ncols=3):\n    \"\"\"\n    Visualize the part of classes, started from class with index start_class_index,\n    make nrows classes, ncols examples for each one\n    \"\"\"\n    fig, ax = plt.subplots(nrows = nrows, ncols=ncols, figsize=(15, 25))\n    for class_index in range(nrows):\n        current_index = class_index + start_class_index\n        for sample in range(ncols):\n            current_part = train_df[train_df[index_class_dict[current_index]] == 1] \n            # 0 index is id\n            random_index = np.random.choice(current_part.values.shape[0], 1, replace=False)\n            # random line from data with selected class\n            current_line = current_part.values[random_index][0]\n            image_names = [os.path.join(data_train_dir, current_line[0]) \n                           + x + '.png' for x in channels]\n            rgb_image = make_rgb_image_from_four_channels(image_names)\n            # text annotations, main title and subclasses (may be empty in case one label)\n            main_class = index_class_dict[current_index]+'\\n'\n            # 2 index is vector with classes, split version of Target col\n            other_classes = [index_class_dict[x] for x in current_line[2] \n                             if x != (current_index)]\n            subtitle = ', '.join(other_classes)\n            # show image\n            ax[class_index, sample].set_title(main_class, fontsize=18)\n            ax[class_index, sample].text(250, -10, subtitle, \n                                         fontsize=14, horizontalalignment='center')\n            ax[class_index, sample].imshow(rgb_image)\n            ax[class_index, sample].set_xticklabels([])\n            ax[class_index, sample].set_yticklabels([])\n            ax[class_index, sample].tick_params(left=False, bottom=False)\n","2799a0d6":"visualize_part(0)","3d31fa41":"visualize_part(4)","3e354027":"visualize_part(8)","6a46ac41":"visualize_part(12)","ed5f122e":"visualize_part(16)","61db168b":"visualize_part(20)","26374d82":"visualize_part(24)","e6b9549e":"## Conclusion\nIn fact, I don't see any special features for each class and don't understand what differences really are. Provably, addition of yellow channel is a bad idea (yellow color is red + green) or we have to analyse only green one, but I did't get good results in my experiments yet. I guess I will allow to network choose the correct features.","ef1b13e4":"## Create cols for each class:","69c5aca1":"## Get part of data with specific class:","533d41aa":"## Functions for visualization:","0d76474c":"## Load data:","3b259cbc":"## Introduction\nThe hypothesis: if we visualize a few examples for each class, we will get the visual patterns for each class.\n\nAlso, we will get the method for merge channels into one image","e7c5c2f6":"## Let's visualize 3 examples for each class:","05089ee3":"## Imports and constants:"}}