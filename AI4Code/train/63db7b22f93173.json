{"cell_type":{"c418eb47":"code","b783c7f9":"code","dca4c64d":"code","75f822e4":"code","da64290f":"code","489384a7":"code","40e1fbea":"code","875e97bb":"code","01e91ef9":"code","c02957b6":"code","ba58f760":"code","851a05df":"code","b8c1259f":"code","86c20219":"code","1a1f3f66":"code","6ad30561":"code","a21d6431":"code","242fbcaf":"code","b30a1881":"code","da88bf47":"code","e8dc08bf":"code","d76602a6":"code","54cd3b80":"code","9f5126da":"code","beb7dddf":"code","af53d78b":"code","98fc1c28":"code","6e824aed":"code","500a4ca7":"code","6182a3a3":"code","f77e9289":"code","e5590def":"code","f5d68669":"code","1af97c0c":"code","3646b52f":"code","5a66e63a":"code","b5e82719":"code","99290fd9":"code","c390be8c":"code","9149ab85":"code","e2afca38":"code","0892a509":"code","5746a88b":"code","58d4d627":"code","fe431588":"code","ca12a337":"markdown","44549a00":"markdown","7d4caf36":"markdown","e6d354a5":"markdown","fbc1da71":"markdown","6e68c61c":"markdown","2d03edb7":"markdown","e80e4a76":"markdown","a6fab34a":"markdown","726cd0b7":"markdown"},"source":{"c418eb47":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b783c7f9":"import warnings\nwarnings.filterwarnings('ignore')","dca4c64d":"df = pd.read_csv(\"..\/input\/pima-indians-diabetes-database\/diabetes.csv\")","75f822e4":"df.head()","da64290f":"df.isna().sum()","489384a7":"df.shape","40e1fbea":"df.describe","875e97bb":"px.histogram(df,color='Outcome',x='Pregnancies',barmode='group')","01e91ef9":"df.head()","c02957b6":"plt.figure(figsize=(10,10))\npx.histogram(df,color='Outcome',x='BloodPressure',barmode='group')\n\n","ba58f760":"plt.figure(figsize=(10,10))\npx.histogram(df,x='SkinThickness',color='Outcome',barmode='group')","851a05df":"plt.figure(figsize=(10,10))\nsns.countplot(x=\"Outcome\", data=df)","b8c1259f":"df.head()","86c20219":"plt.figure(figsize=(10,10))\nsns.scatterplot(y='DiabetesPedigreeFunction',x='Age',data=df)","1a1f3f66":"df.columns","6ad30561":"col=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin','BMI', 'DiabetesPedigreeFunction', 'Age']","a21d6431":"def dist_plot_graphs(col):\n    for c in col:\n        plt.figure(figsize=(10,10))\n        sns.distplot(df.loc[df['Outcome']==1][c],kde_kws={'label':'Diabetes +ve 1'},color='red')\n        sns.distplot(df.loc[df['Outcome']==0][c],kde_kws={'label':'Diabetes -ve 1'},color='green')\n        plt.title(f'{c} Density Plot')\n        plt.legend(labels=['Diabetes +ve 1','Diabetes -ve 0'])\n    ","242fbcaf":"dist_plot_graphs(col)","b30a1881":"plt.figure(figsize=(10,10))\nsns.boxplot(data=df)\nplt.xticks(rotation=45)\nplt.show()","da88bf47":"pd.plotting.scatter_matrix(df, figsize=(20, 20));\n","e8dc08bf":"plt.figure(figsize=(10,10))\n\ncorrMatrix=df.corr()\nsns.heatmap(corrMatrix,annot=True)\nplt.show()","d76602a6":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split","54cd3b80":"df.head()","9f5126da":"mms=MinMaxScaler()","beb7dddf":"df[['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age']]=mms.fit_transform(df[['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age']])","af53d78b":"df.head()","98fc1c28":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score,confusion_matrix\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import plot_roc_curve,roc_auc_score,roc_curve","6e824aed":"X=df.drop('Outcome',axis=1)\ny=df['Outcome']","500a4ca7":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=0)","6182a3a3":"logisticRegr = LogisticRegression()\nlogisticRegr.fit(X_train, y_train)\nlog_accuracy=accuracy_score(y_test,logisticRegr.predict(X_test))\nprint(f'The accuracy for logisitic regression is {log_accuracy*100}%')","f77e9289":"r_fpr,r_tpr,_=roc_curve(y_test,logisticRegr.predict(X_test))\nr_auc=roc_auc_score(y_test,logisticRegr.predict(X_test))\nplt.plot(r_fpr,r_tpr,linestyle='--',label='Logistic Regression (area={:.3f})'.format(r_auc))\nplt.title('Logistic Regression')\nplt.xlabel('False Positive rate')\nplt.ylabel('True Positive rate')\nplt.legend(loc='best')\nplt.show()","e5590def":"decision_tree=DecisionTreeClassifier()\ndecision_tree.fit(X_train, y_train)\nlog_accuracy_decision_tree=accuracy_score(y_test,decision_tree.predict(X_test))\nprint(f'The accuracy score for decision tree is {log_accuracy_decision_tree*100}%')","f5d68669":"r_fpr,r_tpr,_=roc_curve(y_test,decision_tree.predict(X_test))\nr_auc=roc_auc_score(y_test,decision_tree.predict(X_test))\nplt.plot(r_fpr,r_tpr,label='Decision Tree Classifier (area={:.3f})'.format(r_auc))\nplt.title('Decision Tree Classifier')\nplt.xlabel('False Positive rate')\nplt.ylabel('True Positive rate')\nplt.legend(loc='best')\nplt.show()","1af97c0c":"clf=RandomForestClassifier()\nclf.fit(X_train,y_train)\nlog_accuracy_rfc=accuracy_score(y_test,clf.predict(X_test))\nprint(f'The accuracy score for decision tree is {log_accuracy_rfc*100}%')","3646b52f":"r_fpr,r_tpr,_=roc_curve(y_test,clf.predict(X_test))\nr_auc=roc_auc_score(y_test,clf.predict(X_test))\nplt.plot(r_fpr,r_tpr,label='Random Forest Classifier (area={:.3f})'.format(r_auc))\nplt.title('Random Forest Classifier')\nplt.xlabel('False Positive rate')\nplt.ylabel('True Positive rate')\nplt.legend(loc='best')\nplt.show()","5a66e63a":"clf_GB = GaussianNB()\nclf_GB.fit(X_train,y_train)\nlog_accuracy_GNB=accuracy_score(y_test,clf_GB.predict(X_test))\nprint(f'The accuracy score for decision tree is {log_accuracy_GNB*100}%')","b5e82719":"r_fpr,r_tpr,_=roc_curve(y_test,clf_GB.predict(X_test))\nr_auc=roc_auc_score(y_test,clf_GB.predict(X_test))\nplt.plot(r_fpr,r_tpr,label='Random Forest Classifier (area={:.3f})'.format(r_auc))\nplt.title('Gaussian NB')\nplt.xlabel('False Positive rate')\nplt.ylabel('True Positive rate')\nplt.legend(loc='best')\nplt.show()","99290fd9":"clf_bagging_classifier=BaggingClassifier(base_estimator=SVC(),n_estimators=10,random_state=0).fit(X_train,y_train)\nclf_bagging_classifier.fit(X_train,y_train)\nlog_accuracy_bagging_classifier=accuracy_score(y_test,clf_bagging_classifier.predict(X_test))\nprint(f'The accuracy score for Bagging classifier is {log_accuracy_bagging_classifier*100}%')","c390be8c":"r_fpr,r_tpr,_=roc_curve(y_test,clf_bagging_classifier.predict(X_test))\nr_auc=roc_auc_score(y_test,clf_bagging_classifier.predict(X_test))\nplt.plot(r_fpr,r_tpr,label=' Bagging Classifier (area={:.3f})'.format(r_auc))\nplt.title('Bagging Classifier')\nplt.xlabel('False Positive rate')\nplt.ylabel('True Positive rate')\nplt.legend(loc='best')\nplt.show()","9149ab85":"clf_GBC = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0).fit(X_train, y_train)\nclf_GBC.fit(X_train,y_train)\nlog_accuracy_GBC=accuracy_score(y_test,clf_GBC.predict(X_test))\nprint(f'The accuracy score for Bagging classifier is {log_accuracy_GBC*100}%')","e2afca38":"r_fpr,r_tpr,_=roc_curve(y_test,clf_GBC.predict(X_test))\nr_auc=roc_auc_score(y_test,clf_GBC.predict(X_test))\nplt.plot(r_fpr,r_tpr,label=' Gradient Boosting (area={:.3f})'.format(r_auc))\nplt.title('Gradient Boosting Classifier')\nplt.xlabel('False Positive rate')\nplt.ylabel('True Positive rate')\nplt.legend(loc='best')\nplt.show()","0892a509":"models=pd.DataFrame({'Model':['LogisticRegression','DecisionTreeClassifier','RandomForestClassifier','GaussianNB','BaggingClassifier','GradientBoostingClassifier'],\n                     'Score':[log_accuracy,log_accuracy_decision_tree,log_accuracy_rfc,log_accuracy_GNB,log_accuracy_bagging_classifier,log_accuracy_GBC]\n                    })","5746a88b":"models","58d4d627":"models['Score']=models['Score']*100","fe431588":"fig=plt.figure(figsize=(10,10))\nsns.barplot(x=models.Model,y=models.Score)\nplt.xticks(rotation=90)\nfig.show()","ca12a337":"# Density Plots for Diabetes Outcome vs different features in the data set","44549a00":"# Box Plot Analysis for Target and Features\n","7d4caf36":"# Correlation Matrix","e6d354a5":"# Pregnancy Analysis Analysis with Diabetes Outcome","fbc1da71":"# Count Plot for Non Diabetic People vs Diabetic People","6e68c61c":"# Graphical Representation showing how different models preformed","2d03edb7":"# Normalizing the input features using Min-Max Scaler","e80e4a76":"# Blood Pressure Analysis with Diabetes Outcome","a6fab34a":"# Peeking into the Data Frame","726cd0b7":"# Splitting the data using Train,Test"}}