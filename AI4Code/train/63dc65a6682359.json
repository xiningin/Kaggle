{"cell_type":{"0701b938":"code","09e274d1":"code","a4e10b1c":"code","bcb01a9b":"code","bf2d5b9f":"code","c9170f90":"code","1513ff72":"code","bd2f40a4":"code","564b9739":"code","abcd3752":"code","0a8471f5":"code","855a321b":"code","27dbf01f":"code","38536a31":"code","7a86141b":"code","1f573461":"code","8512b457":"code","12eba3ee":"code","e945a0fe":"code","12f04524":"code","49fcea31":"code","69868831":"code","24d1d88f":"markdown","1df3faaa":"markdown","b0c3f760":"markdown","1d71bf70":"markdown","6ac85bde":"markdown","def4e872":"markdown"},"source":{"0701b938":"import matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport tqdm\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler as SRS\nimport os, sys\nimport pandas as pd #for data analysis\nimport time # for time profiling\nimport torchvision # popular lib for different models, different datasets, image pre-processing methods and\n                    # saving tensors in image forms.\nfrom torchvision import transforms\nimport torch.nn as nn \nimport cv2 as cv\nimport torch.optim as optimizers # reponsible for holding the current state of the parameters and updating based\n                                # on the computed gradients\nimport torch.optim.lr_scheduler as lr_sched\n# use_device = torch.device(\"cpu\")\ntry:\n  use_device = torch.device(\"cuda:0\")\n  print(\"Found GPU\")\nexcept Exception as e:\n  print(e)\ntorch.cuda.empty_cache()","09e274d1":"train_dir = '\/kaggle\/input\/person\/resized_img\/resized_img'\ntrain_annotation = '\/kaggle\/input\/person\/test_images\/annotations.csv'\ntest_dir = '\/kaggle\/input\/person\/test_images\/test_images\/'\ntest_annotation = '\/kaggle\/input\/person\/test_images\/test_annotations.csv'","a4e10b1c":"!ls '.\/runs\/Dec17_20-42-09_33a52861e410'\n!ls '.\/runs\/Dec17_20-43-01_33a52861e410'\n!ls '.\/runs\/Dec17_20-46-02_33a52861e410'\n!ls '.\/runs\/Dec17_20-46-24_33a52861e410'","bcb01a9b":"!ls '.\/runs\/Dec17_20-41-05_33a52861e410\/events.out.tfevents.1608237665.33a52861e410.38.3'","bf2d5b9f":"\nfrom IPython.display import FileLink\nFileLink(r'.\/runs\/Dec17_20-42-09_33a52861e410\/events.out.tfevents.1608237729.33a52861e410.38.4')\n# FileLink(r'.\/runs\/Dec17_20-43-01_33a52861e410\/events.out.tfevents.1608237781.33a52861e410.38.5')\n# FileLink(r'.\/runs\/Dec17_20-46-02_33a52861e410\/events.out.tfevents.1608237962.33a52861e410.38.6')\n# FileLink(r'.\/runs\/Dec17_20-46-24_33a52861e410\/events.out.tfevents.1608237984.33a52861e410.38.7')","c9170f90":"# prep images for display\n\nfig = plt.figure(figsize=(16,16))\nfiles =  os.listdir(train_dir)\nfor idx, filename in enumerate(files):          \n    if idx > 15: break\n    image = os.path.join(train_dir, filename)\n    image = plt.imread(image)\n    # plot the images along with predicted and true labels\n    ax = fig.add_subplot(4, 4, idx+1, xticks=[], yticks=[])\n    ax.imshow(image)\n    ","1513ff72":"# Train, Valid and Test Dataloader\nfrom skimage import transform\nclass PersonDataset(Dataset):\n    def __init__(self, annotation_file, dataset_dir, transforms=None):\n        \n        self.root_dir = dataset_dir\n        self.data = pd.read_csv(annotation_file, encoding='utf-8', engine='python')\n        self.transform = transforms\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, item_idx):\n        if torch.is_tensor(item_idx):\n            idx = item_idx.tolist()\n        img_name = os.path.join(self.root_dir,\n                                self.data.iloc[item_idx, 0])\n        image = plt.imread(img_name)\n#         print(image.shape)\n        labels = self.data.iloc[item_idx, 1]\n        labels = np.array(labels)\n        # labels = labels.astype('float').reshape(-1, 2)\n        sample = {'image': image, 'labels': labels}\n        # sample = (image, labels)\n\n        if self.transform:\n            sample = self.transform(sample)\n\n        return sample['image'], sample['labels']\n\nclass CustomResize(object):\n    def __init__(self, output_size):\n        assert isinstance(output_size, (int, tuple))\n        self.output_size = output_size\n\n    def __call__(self, sample):\n        image, labels = sample['image'], sample['labels']\n        h, w = image.shape[:2]\n\n        if isinstance(self.output_size, int):\n            if h>w:\n                new_h, new_w = self.output_size*(h\/w), self.output_size\n            else:\n                new_w, new_h = self.output_size * (w \/ h), self.output_size\n        else:\n            new_h, new_w = self.output_size\n\n        new_h, new_w = int(new_h), int(new_w)\n\n        img = transform.resize(image, (new_h, new_w))\n\n        return {'image': img, 'labels': labels}\n\n\nclass CusToTensor(object):\n    def __call__(self, sample):\n        image, labels = sample['image'], sample['labels']\n        image = image.transpose((2,0,1))\n        \n        return {'image': torch.from_numpy(image),\n                'labels': torch.from_numpy(labels)}\n","bd2f40a4":"trans = transforms.Compose([CustomResize((100,100)), CusToTensor()])\ntrain_dataset = PersonDataset(train_annotation, train_dir, transforms=trans)\ntest_dataset = PersonDataset(test_annotation, test_dir, transforms=trans)","564b9739":"val_data_percentage = 0.2\nindices = list(range(len(train_dataset)))\nnp.random.shuffle(indices)\n\n# Get the split indices between train and val set\nsplit_indices = int(np.floor(len(train_dataset)*val_data_percentage))\n\n# after split the indices are\ntrain_indices_split, val_indices_split = indices[:-split_indices], indices[-split_indices:]\n\ntrain_sampler = SRS(train_indices_split)\nval_sampler = SRS(val_indices_split)","abcd3752":"num_workers=2\nbatch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size,\n                               shuffle=True, num_workers=num_workers)\nval_loader = DataLoader(train_dataset, batch_size=batch_size,\n                             sampler=val_sampler, num_workers=num_workers)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size,\n                              shuffle=True, num_workers=num_workers)","0a8471f5":"k_size = 3\nactivation = 'RELU'\nglobal learning_rate\nlearning_rate = 1e-4\n\nFC_neurons = 4096\nnum_workers = 0\nclasses = 2\nepochs = 10\nhyp_params = {'I_H1': 3, 'H1_H2': 256, 'H2_H3':256, 'H3_H4':512, 'H4_H5':512, 'H5_H6':512*2, 'H6_H7':512*2}\n\nclass INRAICnn(nn.Module):\n  def __init__(self):\n    super(INRAICnn, self).__init__()\n    self.conv1 = nn.Conv2d(hyp_params['I_H1'], hyp_params['H1_H2'], k_size)\n    self.bn_cn1 = nn.BatchNorm2d(hyp_params['H1_H2'])\n    \n    self.conv2 = nn.Conv2d(hyp_params['H1_H2'], hyp_params['H2_H3'], k_size)\n    self.bn_cn2 = nn.BatchNorm2d(hyp_params['H2_H3'])\n    \n    self.conv3 = nn.Conv2d(hyp_params['H2_H3'], hyp_params['H3_H4'], k_size)\n    self.bn_cn3 = nn.BatchNorm2d(hyp_params['H3_H4'])\n    self.max_pool = nn.MaxPool2d(2,2)\n    self.drop_out = nn.Dropout(.50)\n    \n    self.conv4 = nn.Conv2d(hyp_params['H3_H4'], hyp_params['H4_H5'], k_size)\n    self.bn_cn4 = nn.BatchNorm2d(hyp_params['H4_H5'])\n    \n    self.conv5 = nn.Conv2d(hyp_params['H4_H5'], hyp_params['H5_H6'], k_size)\n    self.bn_cn5 = nn.BatchNorm2d(hyp_params['H5_H6'])\n    \n#     self.conv6 = nn.Conv2d(hyp_params['H5_H6'], hyp_params['H6_H7'], k_size)\n#     self.bn_cn6 = nn.BatchNorm2d(hyp_params['H6_H7'])\n    \n    self.fcl1 = nn.Linear(1024, 2)\n#     self.fcl2 = nn.Linear(128, 2)\n  \n  def forward(self, x):\n    x = F.relu(self.conv1(x))\n    x = self.bn_cn1(x)\n    x = self.max_pool(x)\n    \n    x = F.relu(self.conv2(x))  \n    x = self.drop_out(x)\n    x = self.bn_cn2(x)\n    x = self.max_pool(x)\n    \n    \n    x = F.relu(self.conv3(x))\n    x = self.drop_out(x)\n    x = self.bn_cn3(x)\n    x = self.max_pool(x)\n    \n    x = F.relu(self.conv4(x))\n    x = self.drop_out(x)\n    x = self.bn_cn4(x)\n    x = self.max_pool(x)\n    \n    x = F.relu(self.conv5(x))\n    x = self.drop_out(x)\n    x = self.bn_cn5(x)\n    x = self.max_pool(x)\n    \n#     x = F.relu(self.conv6(x))\n#     x = self.drop_out(x)\n#     x = self.bn_cn6(x)\n#     x = self.max_pool(x)\n#     print(x.shape, x.size(0))\n    x = x.view(-1, 1024)\n    x = self.fcl1(x) # for last layer no need of the activation funtion. \n                     # Optimizer takes care of it\n#     x = self.fcl2(x)\n    return x\n\nmodel = INRAICnn()\nmodel_cpu = INRAICnn()\nmodel.to(use_device)","855a321b":"def total_parameters_to_train():\n    t_params, t_layers = 0, 0\n    for i, v in enumerate(model.named_parameters()):\n        parameter, l_name = v[1], v[0]\n        if not v[1].requires_grad: continue\n        param = parameter.numel()\n        t_layers += 1\n#         table.add_row([l_name, param])\n        t_params += param\n    print(f\"Layers: {int(t_layers\/2)} \\nTotal Param: {t_params}\")\n\ntotal_parameters_to_train()","27dbf01f":"import shutil\ndef save_checkpoint(state, is_best, filename='\/kaggle\/working\/models\/checkpoint.pth.tar'):\n    torch.save(state, filename)\n    if is_best:\n        shutil.copyfile(filename, '\/kaggle\/working\/models\/model_best.pth.tar')","38536a31":"def adjust_learning_rate(optimizer, epoch):\n    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n    lr = learning_rate * (0.1 ** (epoch \/\/ 30))\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr\n","7a86141b":"from tqdm import tqdm as tq\n\ndef train_net(train_loader, model, criterion, optimizer, epoch):\n    \n      # set for training\n    model.train()\n    tr_total = train_true_positive = train_loss= 0\n    for i_step, batch in enumerate(train_loader):\n        # set all the intial gradients to 0\n\n        optimizer.zero_grad()\n\n        imgs, labels = batch\n        labels = labels.type(torch.LongTensor)\n        imgs = imgs.to(use_device)\n        labels = labels.to(use_device)\n        \n        pred = model(imgs)\n        loss = criterion(pred, labels)\n\n        #back propogate\n        loss.backward()\n\n        # update weights and bias with the new values calculated during optimization\n        optimizer.step()\n\n        train_loss += loss.item()*imgs.size(0)\n        _, _pred = torch.max(pred.data, 1)\n        tr_total += labels.size(0)\n        train_true_positive += (_pred == labels).sum().item()\n    train_loss = train_loss \/ (tr_total)\n    acc = 100*train_true_positive\/tr_total\n    return acc, train_loss","1f573461":"def validate(val_loader, model, criterion):\n    # Set model for evaluation\n    model.eval()\n\n    val_total = val_true_positive = 0\n    for i_step, batch in enumerate(val_loader):\n        imgs, labels = batch\n        labels = labels.type(torch.LongTensor)\n        imgs, labels = imgs.to(use_device), labels.to(use_device)\n        \n        val_pred = model(imgs)\n        loss = criterion(val_pred, labels)\n        # Update loss for validation\n        valid_loss = loss.item()*imgs.size(0)\n        _, _pred = torch.max(val_pred.data, 1)\n        val_total += labels.size(0)\n        val_true_positive += (_pred == labels).sum().item()\n\n      # Output the validation and training stats\n    valid_loss = valid_loss \/ (val_total)\n    acc = 100*val_true_positive\/val_total\n    return acc, valid_loss","8512b457":"#tensoboard writer\nwriter = SummaryWriter()","12eba3ee":"# Define Optimizers\n# For multi-class classification we need categorical cross entropy in Pytorch\n# case its CrossEntropyLoss\nentropy_loss = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","e945a0fe":"best_acc1 = 0\ndef start_training(epochs=15):\n    global best_acc1\n    for epoch in range(epochs):\n        print('Epoch: ', epoch)\n        # before training starts adjust the lr if required\n#         adjust_learning_rate(optimizer, epoch)\n\n        # train for one epoch\n        acc_train, tr_loss = train_net(train_loader, model, entropy_loss, optimizer, epoch)\n\n        #evaluate on validation set\n        acc_val, val_loss = validate(val_loader, model, entropy_loss)\n        \n        print('Train loss {:.3f} Train Acc {:.3f}, Val Loss {:.3f} Val Acc {:.3f}'.format(\n        tr_loss, acc_train, val_loss, acc_val))\n        \n        is_best = acc_val > best_acc1\n        best_acc1 = max(acc_val, best_acc1)\n        # Save best model\n        save_checkpoint({'epoch': epoch + 1, 'state_dict': model.state_dict(),\n                         'best_acc1': best_acc1,\n                         'optimizer' : optimizer.state_dict(),\n                        }, is_best)\n        \n        writer.add_scalar('train_loss', tr_loss , epoch)\n        writer.add_scalar('val_loss', val_loss, epoch)\n        writer.add_scalar('train_acc', acc_train, epoch)\n        writer.add_scalar('val_loss', val_loss, epoch)","12f04524":"start_training(epochs=15)","49fcea31":"import matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\nsamples_to_visualize = 4\ndef test_net():\n    correct = 0\n    total = 0    \n    \n#     ax1 = fig.add_subplot(2,1,1)\n    \n    with torch.no_grad():\n        for i_batch, data in enumerate(test_loader):\n            fig = plt.figure(figsize=(16,16))\n            images, labels = data\n            images, labels = images.to(use_device), labels.to(use_device)\n            outputs = model(images.float())\n            _, predicted = torch.max(outputs.data, 1)  \n            \n            for i in range(samples_to_visualize):\n                img = images[i, ...].permute(1,2, 0)\n                img = img.cpu().numpy()\n                label = str(labels[i].cpu().numpy())\n#                 print(label)\n                ax = fig.add_subplot(4,4,i+1)\n                ax.imshow(img)\n                ax.set_title(str(label[0]))\n            \n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            figure_name = '\/kaggle\/working\/batch_'+str(i_batch)+'_fig.png'\n            fig.savefig(figure_name)\n            plt.show()\n\n    print('Accuracy of the network on the {} test images: {}'.format(total, 100 * correct \/ total))","69868831":"test_net()","24d1d88f":"# Constructing Model Architecture","1df3faaa":"# Spliting into Training and Validation set","b0c3f760":"for name, param in model.named_parameters():\n    print(name,'\\t', param.device,'\\t\\t', param.shape)","1d71bf70":"# Number of parameters to train","6ac85bde":"for name, param in model_cpu.named_parameters():\n    print(name,'\\t', param.device,'\\t\\t', param.shape)","def4e872":"from torch.utils.tensorboard import SummaryWriter\nos.mkdir('\/kaggle\/working\/plot\/')\nos.mkdir('\/kaggle\/working\/results\/')\nos.mkdir('\/kaggle\/working\/models\/')"}}