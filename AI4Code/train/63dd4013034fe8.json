{"cell_type":{"3c8d181a":"code","9a612c76":"code","5d35e60c":"code","b774c79c":"code","83a6f13b":"code","af0b4f71":"code","d0bdf816":"code","5f18399d":"code","18f5ae33":"code","6f084ae6":"code","03f8cb15":"code","e314e8fa":"markdown","85bc181d":"markdown","57174a86":"markdown","02775965":"markdown","23618a2e":"markdown","ce34b44f":"markdown","f116c0bb":"markdown","b101b93b":"markdown"},"source":{"3c8d181a":"from scipy import stats\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pymc3 as pm\nimport pystan\nimport arviz as az\nplt.rcParams[\"figure.figsize\"] = (18,8)","9a612c76":"# Create an array with our data (order is not relevant - these are assumed to be independent trials)\nobservations = pd.Series([\"w\", \"l\", \"w\", \"w\", \"w\",\"l\",\"w\", \"l\", \"w\"])\n\n# Convert to binomial representation\nobservations_binom = (observations == \"w\").astype(int).values\nobservations_binom","5d35e60c":"# Compute the number of 'water' observations and total number of observations.\nwater_observations = sum(observations_binom)\ntotal_observations = len(observations_binom)\n\nwater_observations, total_observations","b774c79c":"# Variable for the domain of possible values for p.  This is our 'grid'.\npossible_probabilities = np.linspace(0,1,100)\n# Flat prior\nprior = np.repeat(1,100)\n\n# Evaluate the likelihood function at every point in the domain.\n# We use stats.binom.pmf(k,n,p) where:\n# k = # succeses\n# n = # trials \n# p = probability of sucess in a single trial\nlikelihood = stats.binom.pmf(water_observations, total_observations, possible_probabilities)\n\n# Apply Bayes Theorem (Multuply likelihood by prior, then divide by the sum to normalize to sum to 1.)\nposterior_unstandardized = likelihood * prior\nposterior_grid_search = posterior_unstandardized \/ sum(posterior_unstandardized)\n\n# Plot the result\nfig, ax = plt.subplots()\nplt.plot(possible_probabilities, posterior_grid_search)\nax.set_yticks([])\nfig.suptitle(\"Posterior through Grid Approximation\");","83a6f13b":"# The paramters for the flat prior\nalpha = 1\nbeta = 1\n\n# The parameters for the resulting posterior probability distribution.\n_alpha = 1 + water_observations\n_beta = 1 + total_observations - water_observations\n\n# Possible values for p.  (Calling this x because its the input into a function, to distinguish from sampling methods.)\nx = np.linspace(0,1,100)\n# Formula for the posterior probability distribution on p.\nposterior_conjugate = stats.beta.pdf(x, a=_alpha, b=_beta)\n\nfig, ax = plt.subplots()\nplt.plot(x,posterior_conjugate)\nax.set_yticks([])\nfig.suptitle(\"Exact Posterior through Conjugate Prior\");","af0b4f71":"with pm.Model() as mcmc_nuts:\n    p_water = pm.Uniform(\"p\", 0 ,1)\n    w = pm.Binomial(\"w\", p=p_water, n=total_observations, observed=water_observations)\n    trace = pm.sample(50000, chains=2)\n    \naz.plot_posterior(trace)","d0bdf816":"with pm.Model() as advi:\n    p_water = pm.Uniform(\"p\", 0 ,1)\n    w = pm.Binomial(\"w\", p=p_water, n=total_observations, observed=water_observations)\n    mean_field = pm.fit(method='advi', n=50000)\n\nadvi_samples = mean_field.sample(50000).get_values(\"p\")\naz.plot_posterior(advi_samples)","5f18399d":"advi_elbo = pd.DataFrame(\n    {'log-ELBO': -np.log(mean_field.hist),\n     'n': np.arange(mean_field.hist.shape[0])})\n\n_ = sns.lineplot(y='log-ELBO', x='n', data=advi_elbo)","18f5ae33":"with pm.Model() as normal_aproximation:\n    p = pm.Uniform('p', 0, 1)\n    w = pm.Binomial('w', n=total_observations, p=p, observed=water_observations)\n    mean_q = pm.find_MAP()\n    std_q = ((1\/pm.find_hessian(mean_q, vars=[p]))**0.5)[0]\nmean_q['p'], std_q","6f084ae6":"possible_probabilities = np.linspace(0,1,100)\nposterior_laplace = stats.norm.pdf(possible_probabilities, mean_q['p'], std_q)\nfig, ax = plt.subplots()\nax.set_yticks([])\nplt.plot(possible_probabilities, posterior_laplace)\nfig.suptitle(\"Posterior Approximation through Quadratic Approximation\");","03f8cb15":"plt.plot(possible_probabilities, posterior_grid_search*99,\n              c='b', label='Grid Search'); \n#Note: We needed to multiply posterior_grid_search by 99 because grid search method did not scale using dx.)\nplt.plot(possible_probabilities, posterior_conjugate,\n              '--', c='k', label='Conjugate Prior (Exact Formula)');\nplt.plot(possible_probabilities, posterior_laplace,\n              c='g', label='Laplace Approximation');\nsns.distplot(trace.get_values(\"p\"), hist=False, kde=True, \n             bins=int(100), color = 'orange', label='PYMC3 MCMC');\nsns.distplot(advi_samples, hist=False, kde=True, \n             bins=int(100), color = 'red', label='PYMC3 Variational Inference');\nplt.legend(loc=2);","e314e8fa":"# 5. Quadratic (Laplace) Approximation","85bc181d":"# The Problem: Inferring the proportion of the earth's surface covered by water from 9 observations\n\n**Data**: 9 observations, 6 of which are 'water' and 3 of which are 'land'.\n\n**Assumptions**:  The oservations are from random independent events, each of which consists of randomly sampling a location on the Earth and documenting wether the location is land or water.  Thus:\n- The value $p$ is the proportion of the earth consisting of water, and this value is the probability of getting 'water' from one of our independent Bernoili trials.\n- The likehood function for getting $k$ 'water' observations given $n$ observations and a value of $p$ is given by the *binomial distribution* (https:\/\/en.wikipedia.org\/wiki\/Binomial_distribution):\n$$\nP(k|n,p)={n \\choose k}p^k(1-p)^{n-k}.\n$$\n\n**Goal**:  Determine the probablity distribution for the value of $p$.","57174a86":"# 2. Conjugate Prior\nIf we use a conjugate prior, we get an exact formula for the posterior probability distribution.\n\nWe use a flat prior, which is given by a *beta distribution* (https:\/\/en.wikipedia.org\/wiki\/Beta_distribution) with $\\alpha=1$ and $\\beta=1$.\n\nThe resulting posterior distribution is also a beta distribution, but with parameters $\\_\\alpha=\\alpha+k$ and $\\_\\beta=\\beta+n-k$.","02775965":"# 1. Grid Search\nFor each point in the domain, we compute the posterior probaiblity distribution from the likelihood function.","23618a2e":"# 4. PyMC3 Variational Inference (Specifically Automatic Differentiation Variational Inference)","ce34b44f":"# Comparinson Plot","f116c0bb":"# This notebook is built from the excellent blog post https:\/\/ravinkumar.com\/pages\/InferenceCheatsheet.html by Ravin Kumar","b101b93b":"# 3. PyMC3 MCMC Hamiltonian Monte Carlo (Specifically No U Turn Sampler)"}}