{"cell_type":{"aa3116fb":"code","46e39a77":"code","f4ae2e5b":"code","204755f3":"code","c69c0fa2":"code","78ee5700":"code","c3b7a03e":"code","0366089d":"code","44823b48":"code","70727319":"code","9f6ab37b":"code","112f7e19":"code","f6233764":"code","86f94727":"code","f790b45a":"code","937a401e":"code","1ad6e83c":"code","6188f5a5":"code","d5c5d304":"code","92b4e920":"code","43cb3d5b":"code","c64ec764":"code","3480f34f":"code","5edf67cf":"code","4923e496":"code","ab7824d4":"code","5f9ecc86":"code","6ac959f2":"code","ad944431":"code","ecaee747":"code","466aebfe":"code","faf6ca35":"code","ed8a5624":"code","275ce25b":"code","d2e960ba":"code","d27a0b7f":"code","8ef1d730":"code","502ef61d":"code","0182bd08":"code","e08c1d96":"markdown","c89ca050":"markdown","f59baaa7":"markdown","55b67e53":"markdown","0d7e1c0e":"markdown","c5413779":"markdown","6b9892a9":"markdown","8c0b28a6":"markdown","fd4d28ce":"markdown","93a0f73d":"markdown","3e30abbc":"markdown","4b44ca35":"markdown","0fa81dfe":"markdown","5d2da392":"markdown","48b268ae":"markdown","bdaf7fc5":"markdown","b8b592af":"markdown","579fd8dd":"markdown","a7d3b8e0":"markdown","4dda9a8e":"markdown","3731282c":"markdown","c46f62e9":"markdown","e44b3a01":"markdown","5c1debeb":"markdown","979ee6e9":"markdown","1e67ae78":"markdown","6d29d4d6":"markdown","5e17a254":"markdown","62075c42":"markdown","1cf5ccbc":"markdown","d39205a9":"markdown","b5522d6f":"markdown","5ff73862":"markdown","f3b9963f":"markdown","b9262292":"markdown","25d8688f":"markdown","99002fb9":"markdown","21bb60b9":"markdown","81e892e6":"markdown","f0d427ce":"markdown","acabf096":"markdown","1e3c7eae":"markdown","ca2f0f46":"markdown","99b80985":"markdown","5a1aaa7c":"markdown","3e3905f1":"markdown","8916ba01":"markdown"},"source":{"aa3116fb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nsns.set(style=\"whitegrid\")\nimport warnings\nwarnings.filterwarnings(\"ignore\") \n\n# Machine learning libraries\nfrom sklearn.model_selection import train_test_split\n# split test and train data\nfrom sklearn.model_selection import KFold,cross_val_score,cross_val_predict\n# K Fold cross validation \nfrom sklearn import metrics\n# metrics will be use later to get a accuracy score \n\n# Prediction algoritms that I will use in this study \nfrom sklearn import svm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","46e39a77":"# load csv file\ndf = pd.read_csv(\"\/kaggle\/input\/breast-cancer-wisconsin-data\/data.csv\")","f4ae2e5b":"df.head()\n# load 5 rows of df \n# There are a few unnecessary columns","204755f3":"df.drop(['id','Unnamed: 32'],axis=1,inplace=True)\n#In this study 'id' and 'Unnamed: 32' are not needed \n#So drop both columns ","c69c0fa2":"df.isna().sum()\n# checking missing value \n# No missing values","78ee5700":"df.info()\n# get a information about each column","c3b7a03e":"df.shape\n# rows and columns","0366089d":"df.columns\n# all columns in df ","44823b48":"#countplot\nplt.subplots(figsize=(10,5))\nsns.countplot(data=df,x='diagnosis');\n\nplt.title('Diagnosis counting'.title(),\n         fontsize = 14, weight=\"bold\")\n\nplt.xlabel('Type of diagonosis'.title(),\n          fontsize=14,weight=\"bold\")\n\nplt.ylabel('Count'.title(),\n           fontsize=14,weight=\"bold\")\n\nplt.legend(['malignant','benign'],loc='center right',bbox_to_anchor=(1.2, 0.93), \n           title=\"Diagonisis\", title_fontsize = 14);","70727319":"#pie chart  \n\nplt.figure(figsize=(15,7))\nsorted_counts = df['diagnosis'].value_counts()\n# count the value of diagnosis \nax=plt.pie(sorted_counts, labels = sorted_counts.index, startangle = 90,\n        counterclock = False,pctdistance=0.8 ,wedgeprops = {'width' : 0.4}, autopct='%1.0f%%');\n\n\nplt.title('Proprotion of malignant and benign'.title(),\n         fontsize = 14, weight=\"bold\");\n\nplt.legend(['Benign(B)','Malignant(M)'],bbox_to_anchor=(1,0.9));","9f6ab37b":"#distplot = histogram + curveline \n# for example : radius mean\n\nplt.subplots(figsize=(15,7))\nx = df.radius_mean\nbins = np.arange(0,30,1)\nsns.distplot(x,bins=bins,color='black')\n\n#ax.set_yticklabels([], minor = True);\n\n\nplt.title('radius mean Histogram'.title(),\n         fontsize = 14, weight=\"bold\")\n\nplt.xlabel('radius mean range'.title(),\n          fontsize=14,weight=\"bold\")\n\nplt.ylabel('Count in percentage'.title(),\n           fontsize=14,weight=\"bold\");","112f7e19":"# split table into different valriables \ny=df.diagnosis \nx = df.iloc[:,1:] \n\n# standardization\nstand = (x - x.mean()) \/ (x.std())             ","f6233764":"# Because we have 30 sub features we'll divide 3 groups to visualize\n\ndata = pd.concat([y,stand.iloc[:,0:10]],axis=1)\ndata = pd.melt(data,id_vars=\"diagnosis\",\n                    var_name=\"features\",\n                    value_name='value')\n\n# In order to visualize different type of numeric value in one graph.We're going to melt df_new table into the new table called `data`.\n# id_var : Column(s) to use as identifier variables.\n# var_name : Name to use for the \u2018variable\u2019 column. If None it uses frame.columns.name or \u2018variable\u2019.\n# value_name : Name to use for the \u2018value\u2019 column. \n\n\nplt.figure(figsize=(15,7))\nsns.violinplot(x=\"features\", y=\"value\", hue=\"diagnosis\", data=data,split=True, inner=\"quart\")\n\n\nplt.title('Sub features with standardization (first 10 features with violinplot)'.title(),\n         fontsize = 14, weight=\"bold\")\n\nplt.xlabel('Sub features'.title(),\n          fontsize=14,weight=\"bold\")\n\nplt.ylabel('z score'.title(),\n           fontsize=14,weight=\"bold\");\n\nplt.xticks(rotation=45);\n","86f94727":"data = pd.concat([y,stand.iloc[:,10:20]],axis=1)\ndata = pd.melt(data,id_vars=\"diagnosis\",\n                    var_name=\"features\",\n                    value_name='value')\n\n# In order to visualize different type of numeric value in one graph.We're going to melt df_new table into the new table called `data`.\n# id_var : Column(s) to use as identifier variables.\n# var_name : Name to use for the \u2018variable\u2019 column. If None it uses frame.columns.name or \u2018variable\u2019.\n# value_name : Name to use for the \u2018value\u2019 column. \n\n\nplt.figure(figsize=(15,7))\nsns.violinplot(x=\"features\", y=\"value\", hue=\"diagnosis\", data=data,split=True, inner=\"quart\")\n\n\nplt.title('Sub features with standardization (Second 10 features with violinplot)'.title(),\n         fontsize = 14, weight=\"bold\")\n\nplt.xlabel('Sub features'.title(),\n          fontsize=14,weight=\"bold\")\n\nplt.ylabel('z score'.title(),\n           fontsize=14,weight=\"bold\");\nplt.xticks(rotation=45);\n","f790b45a":"data = pd.concat([y,stand.iloc[:,20:31]],axis=1)\ndata = pd.melt(data,id_vars=\"diagnosis\",\n                    var_name=\"features\",\n                    value_name='value')\n\n# In order to visualize different type of numeric value in one graph.We're going to melt df_new table into the new table called `data`.\n# id_var : Column(s) to use as identifier variables.\n# var_name : Name to use for the \u2018variable\u2019 column. If None it uses frame.columns.name or \u2018variable\u2019.\n# value_name : Name to use for the \u2018value\u2019 column. \n\n\nplt.figure(figsize=(15,7))\nsns.violinplot(x=\"features\", y=\"value\", hue=\"diagnosis\", data=data,split=True, inner=\"quart\")\n\n\nplt.title('Sub features with standardization (last 10 features with violinplot)'.title(),\n         fontsize = 14, weight=\"bold\")\n\nplt.xlabel('Sub features'.title(),\n          fontsize=14,weight=\"bold\")\n\nplt.ylabel('z score'.title(),\n           fontsize=14,weight=\"bold\");\n\nplt.xticks(rotation=45);\n","937a401e":"data = pd.concat([y,stand.iloc[:,0:10]],axis=1)\ndata = pd.melt(data,id_vars=\"diagnosis\",\n                    var_name=\"features\",\n                    value_name='value')\n\nplt.subplots(figsize=(15,7))\nbase_color = sns.color_palette()[6]\nsns.pointplot(data=data,x='features',y='value',hue='diagnosis',dodge=True,ci=30,\n              color=base_color)\n# dodge: amount to separate the points for each level of the hue variable along the categorical axis.\n\n\nplt.title('Sub features with standardization (first 10 features with pointplot)'.title(),\n         fontsize = 14, weight=\"bold\")\n\nplt.xlabel('Sub features'.title(),\n          fontsize=14,weight=\"bold\")\n\nplt.ylabel('z score'.title(),\n           fontsize=14,weight=\"bold\");\n\nplt.xticks(rotation=45);\n","1ad6e83c":"data = pd.concat([y,stand.iloc[:,10:20]],axis=1)\ndata = pd.melt(data,id_vars=\"diagnosis\",\n                    var_name=\"features\",\n                    value_name='value')\n\nplt.subplots(figsize=(15,7))\nbase_color = sns.color_palette()[6]\nsns.pointplot(data=data,x='features',y='value',hue='diagnosis',dodge=True,ci=30,\n              color=base_color)\n# dodge: amount to separate the points for each level of the hue variable along the categorical axis.\n\n\nplt.title('Sub features with standardization (Second 10 features with pointplot)'.title(),\n         fontsize = 14, weight=\"bold\")\n\nplt.xlabel('Sub features'.title(),\n          fontsize=14,weight=\"bold\")\n\nplt.ylabel('z score'.title(),\n           fontsize=14,weight=\"bold\");\n\nplt.xticks(rotation=45);\n","6188f5a5":"data = pd.concat([y,stand.iloc[:,20:31]],axis=1)\ndata = pd.melt(data,id_vars=\"diagnosis\",\n                    var_name=\"features\",\n                    value_name='value')\n\nplt.subplots(figsize=(15,7))\nbase_color = sns.color_palette()[6]\nsns.pointplot(data=data,x='features',y='value',hue='diagnosis',dodge=True,ci=30,\n              color=base_color)\n# dodge: amount to separate the points for each level of the hue variable along the categorical axis.\n\n\nplt.title('Sub features with standardization (last 10 features with pointplot)'.title(),\n         fontsize = 14, weight=\"bold\")\n\nplt.xlabel('Sub features'.title(),\n          fontsize=14,weight=\"bold\")\n\nplt.ylabel('z score'.title(),\n           fontsize=14,weight=\"bold\");\n\nplt.xticks(rotation=45);\n","d5c5d304":"data_new = pd.concat([y,stand],axis=1)\n# build a new dataset with y and stand\n# if you forgot what y and stand are. Just look at below \n\n# y=df.diagnosis \n# x = df.iloc[:,1:]  and stand = (x - x.mean()) \/ (x.std())          ","92b4e920":"# scatterplot with 2 high related sub features. Addtionally diagnosis will be used as a hue of different type of tumors\n# Before we're going to plot scatter we'll find out which sub features are related together strongly \n# For that we will use pearson corrla\n\nplt.figure(figsize=(28,13))\nc= data_new.corr()\nmask = np.triu(np.ones_like(c, dtype=np.bool))\ncmap = sns.diverging_palette(220, 10, as_cmap=True) \n# color choose\nsns.heatmap(c,cmap=cmap,mask=mask,center=0,annot=True);\n\n\nplt.title('Sub title correlation'.title(),\n         fontsize=20,weight='bold');","43cb3d5b":"f,ax = plt.subplots(1,2,figsize=(20,7))\n\nsns.scatterplot(data=data_new,x='radius_worst',y='perimeter_mean',hue='diagnosis',x_jitter=0.04,ax=ax[0])\nax[0].set_title('radius_worst vs perimeter_mean')\nsns.scatterplot(data=data_new,x='area_mean',y='radius_mean',hue='diagnosis',x_jitter=0.04,ax=ax[1])\nax[1].set_title('area_mean vs radius_mean');","c64ec764":"f,ax = plt.subplots(1,2,figsize=(20,7))\n\nsns.scatterplot(data=data_new,x='fractal_dimension_mean',y='radius_mean',hue='diagnosis',x_jitter=0.04,ax=ax[0])\nax[0].set_title('radius_worst vs perimeter_mean')\nsns.scatterplot(data=data_new,x='fractal_dimension_mean',y='area_mean',hue='diagnosis',x_jitter=0.04,ax=ax[1])\nax[1].set_title('area_mean vs radius_mean');","3480f34f":"train,test = train_test_split(df,test_size=0.2,random_state=2019)\n\n# test size =0.2 means I will use 20% for testing and 80% for training \n# Spliting test-set and training-set is very important.Because we have to use testdata to examine our prediction model and get a performance in numeric value.\n# So never use testdata for training.Otherwise we can't get a exact result of prediction model.\n# Reason why we use random_state : https:\/\/stackoverflow.com\/questions\/28064634\/random-state-pseudo-random-number-in-scikit-learn\n\nx_train = train.drop(['diagnosis'],axis=1)\ny_train = train.diagnosis\n\n# we should think about why we drop diagonosis column.Because we want to know the diagnosis in the end (That mean malignant or benign)\n# We're going to use other columns as a x variable to get a diagonosis(y variable).That's the reason why we drop diagnosis in x_train and x_test\n\nx_test = test.drop(['diagnosis'],axis=1)\ny_test = test.diagnosis \n\nprint(len(train),len(test))","5edf67cf":"model = svm.SVC(gamma='scale')\nmodel.fit(x_train,y_train)\n# learning train dataset\n\ny_pred = model.predict(x_test)\n# prediction test dataset\n\nprint('SVM: %.2f' % (metrics.accuracy_score(y_pred,y_test)*100))\n# metrics.accuracy_score : measure the accurace_score\n# so we compare prediction of y (prediction, y_pred) and test result of y (fact,y_test) how close our y_pred to y_test","4923e496":"model = DecisionTreeClassifier()\nmodel.fit(x_train,y_train)\n\ny_pred = model.predict(x_test)\n\nprint('DecisionTreeClassifier: %.2f' % (metrics.accuracy_score(y_pred,y_test)*100))\n","ab7824d4":"model = KNeighborsClassifier()\nmodel.fit(x_train,y_train)\n\ny_pred = model.predict(x_test)\n\nprint('KNeighborsClassifier: %.2f' % (metrics.accuracy_score(y_pred,y_test)*100))","5f9ecc86":"model = LogisticRegression(solver='lbfgs',max_iter=2000)\n# about parameters: https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.LogisticRegression.html\nmodel.fit(x_train,y_train)\n\ny_pred = model.predict(x_test)\n\nprint('LogisticRegression: %.2f' % (metrics.accuracy_score(y_pred,y_test)*100))\n","6ac959f2":"model = RandomForestClassifier(n_estimators=100)\nmodel.fit(x_train,y_train)\n\ny_pred = model.predict(x_test)\n\nprint('RandomForestClassifier: %.2f' % (metrics.accuracy_score(y_pred,y_test)*100))\n","ad944431":"features = pd.Series(\n     model.feature_importances_,\n    index=x_train.columns).sort_values(ascending=False)\n\n# model.feature_importances_ shows which paramet is important to predict the model \n# we are matching train dataset columns with model.feature_importances and saved in pandas series as a numeric values \nprint(features)","ecaee747":"### Extract Top 5 Features\ntop_5_features = features.keys()[:5]\n# series.keys() : this function is an alias for index. It returns the index labels of the given series object.\n\nprint(top_5_features)","466aebfe":"model = svm.SVC(gamma='scale')\nmodel.fit(x_train[top_5_features],y_train)\n\ny_pred = model.predict(x_test[top_5_features])\n# prediction test dataset\n\nprint('SVM(Top5): %.2f' % (metrics.accuracy_score(y_pred,y_test)*100))","faf6ca35":"model = svm.SVC(gamma='scale')\n\ncv = KFold(n_splits=5,random_state=2019)\n# Interation : K=5\n\naccs = []\n\nfor train_index,test_index in cv.split(df[top_5_features]):\n    x_train = df.iloc[train_index][top_5_features]\n    y_train = df.iloc[train_index].diagnosis\n    \n    x_test = df.iloc[test_index][top_5_features]\n    y_test = df.iloc[test_index].diagnosis\n    \n    \n    model.fit(x_train,y_train)\n    y_pred = model.predict(x_test)\n    accs.append(metrics.accuracy_score(y_pred,y_test))\n    # position of y_pred and y_test are not important\n    \nprint(accs)\n    ","ed8a5624":"model = svm.SVC(gamma='scale')\ncv = KFold(n_splits=5,random_state=2019)\n\naccs = cross_val_score(model,df[top_5_features],df.diagnosis,cv=cv)\n# cross_vall_score : apply cross validation (in our case would be KFold) and learning.\n# In the end will be print out the model score\n# x variable : df[top_5_features] , y variable : di.diagnosis\nprint(accs)","275ce25b":"model = {\n    'SVM': svm.SVC(gamma='scale'),\n    'DecisionTreeClassifier':DecisionTreeClassifier(),\n    'KNeighborsClassifier': KNeighborsClassifier(),\n    'LogisticRegression': LogisticRegression(solver='lbfgs',max_iter=2000),\n    'RandomForestClassifier': RandomForestClassifier(n_estimators=100)\n    \n}\n\ncv = KFold(n_splits=5,random_state=2019)\n\nfor name, model in model.items():\n    scores = cross_val_score(model,df[top_5_features],df.diagnosis,cv=cv)\n    \n    print('%s:%.2f%%' % (name,np.mean(scores)*100))\n\n","d2e960ba":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler(feature_range=(0,1))\n# scale the range between 0 and 1 \nscaled_data = scaler.fit_transform(df[top_5_features])\n\nmodel = {\n    'SVM': svm.SVC(gamma='scale'),\n    'DecisionTreeClassifier':DecisionTreeClassifier(),\n    'KNeighborsClassifier': KNeighborsClassifier(),\n    'LogisticRegression': LogisticRegression(solver='lbfgs',max_iter=2000),\n    'RandomForestClassifier': RandomForestClassifier(n_estimators=100)\n    \n}\n\ncv = KFold(n_splits=5,random_state=2019)\n\nfor name, model in model.items():\n    scores = cross_val_score(model,scaled_data,df.diagnosis,cv=cv)\n    \n    print('%s:%.2f%%' % (name,np.mean(scores)*100))","d27a0b7f":"# First we will have a new table which contains only feature mean \nfeatures_mean = list(df.columns[1:11])\n\n# And then change diagnosis name\ndf['diagnosis']=df['diagnosis'].map({'M':0,'B':1})","8ef1d730":"from pandas.plotting import scatter_matrix\n\ncolor_function = {0: \"blue\", 1: \"red\"} \ncolors = df[\"diagnosis\"].map(lambda x: color_function.get(x))\n# mapping the color fuction with diagnosis column\npd.plotting.scatter_matrix(df[features_mean], c=colors, alpha = 0.5, figsize = (15, 15)); \n# plotting scatter plot matrix","502ef61d":"df_new = pd.DataFrame(df,columns=['diagnosis','radius_mean','perimeter_mean','area_mean','compactness_mean','concavity_mean','concavity_mean'] )\ntrain,test = train_test_split(df_new,test_size=0.2,random_state=2019)\n\nx_train = train.drop(['diagnosis'],axis=1)\ny_train = train.diagnosis\n\nx_test = test.drop(['diagnosis'],axis=1)\ny_test = test.diagnosis \n","0182bd08":"model = {\n    'SVM': svm.SVC(gamma='scale'),\n    'DecisionTreeClassifier':DecisionTreeClassifier(),\n    'KNeighborsClassifier': KNeighborsClassifier(),\n    'LogisticRegression': LogisticRegression(solver='lbfgs',max_iter=2000),\n    'RandomForestClassifier': RandomForestClassifier(n_estimators=100)\n    \n}\n\ncv = KFold(n_splits=5,random_state=2019)\n\nprediction_var=['radius_mean','perimeter_mean','area_mean','compactness_mean','concavity_mean','concavity_mean']\ndf_new[prediction_var]\n\nfor name, model in model.items():\n    scores = cross_val_score(model,df_new[prediction_var],df_new.diagnosis,cv=cv)    \n    print('%s:%.2f%%' % (name,np.mean(scores)*100))\n","e08c1d96":"### SVM ","c89ca050":"### RandomForestClassifier","f59baaa7":"### Normalization","55b67e53":"> These are not a better result than normalization","0d7e1c0e":"#### Observation\n\n> Those visualizations show negative corrlation but not absolutely strong. ","c5413779":"### 1. Univariate Exploration of data\n\nUsing only one variable to visualize **df_new table**","6b9892a9":"# Data Visualization ","8c0b28a6":">Normalization is a technique often applied as part of data preparation for machine learning. The goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values. Normalization rescales the values into a range of **[0,1]**.\n\n>This might be useful in some cases where all parameters need to have the same positive scale. However, the outliers from the data set are \nlost.For machine learning, every dataset does not require normalization. It is required only when features have different ranges.\n\n\n## $$ X_{normalization} = \\frac {x- x_{min}}{x_{max}-x_{min}}$$\n\n##### This is also we called Min-Max scaler \nMin Max scaler responds well if the standard deviation is small and when a distribution is not Gaussian. This Scaler is sensitive to outliers.\n\n\n\n\n\n#### But people can ask a question again : Why do we need scaling? \n\n> Machine learning algorithm just sees number.That means if there is a vast difference in the range say few ranging in thousands and few ranging in the tens, and it makes the underlying assumption that higher ranging numbers have superiority of some sort. \n\n> So these more significant number starts playing a more decisive role while training the model.The machine learning algorithm works on numbers and does not know what that number represents.0\n\n> For example, a weight of 10 grams and a price of 10 dollars represents completely two different things \u2014 which is a no brainer for humans, but for a model as a feature, it treats both as same.\n\n> That why we need scaling \n\n\n#### Some examples of algorithms where feature scaling matters are:\n> K-nearest neighbors (KNN) with a Euclidean distance measure is sensitive to magnitudes and hence should be scaled for all features to weigh in equally.\n\n> K-Means uses the Euclidean distance measure here feature scaling matters.\n\n> PCA tries to get the features with maximum variance, and the variance is high for high magnitude features and skews the PCA towards high magnitude features.\n\n> We can speed up gradient descent by scaling because \u03b8 descends quickly on small ranges and slowly on large ranges, and oscillates inefficiently down to the optimum when the variables are very uneven.","fd4d28ce":"# Notice !!!! \n\n## MinMaxScaler is normalization libarary","93a0f73d":"better than all features??? \n\n\nhttps:\/\/www.kaggle.com\/gargmanish\/basic-machine-learning-with-cancer","3e30abbc":"### 3.Multivariate Exploration of Data\n\n> Using more than two variables to visualize data_new table which is standardized form of df table. We will use `Scatterplot`","4b44ca35":"#### Observation \n\n> Violinplot tells us the distribution of z-score with different type of tumors","0fa81dfe":"### Split Train and Test","5d2da392":"# Data Wrangling","48b268ae":"## Prediction with new variables","bdaf7fc5":"## Prediction ","b8b592af":"#### Observaion \n\n> This result is mostly better than without normalization ","579fd8dd":"### 2.Bivariate Exploration of Data\n\nUsing only one variable to visualize `df_new` table. We will use `violinplot`,`pointplot`","a7d3b8e0":"#### Observation\n\n> Approximately normal distributed graph","4dda9a8e":"## 2. Assessing & Cleaning  ","3731282c":"# Introduction \n\n Breast cancer is cancer that forms in the cells of the breasts.\n\n After skin cancer, breast cancer is the most common cancer diagnosed in women in the United States. Breast cancer can occur in both men and women, but it's far more common in women.Substantial support for breast cancer awareness and research funding has helped created advances in the diagnosis and treatment of breast cancer. \n\nBreast cancer survival rates have increased, and the number of deaths associated with this disease is steadily declining, largely due to factors such as earlier detection, a new personalized approach to treatment and a better understanding of the disease.\n\nIn this study you'll get a csv file called 'breast-cancer-wisconsin-data'.From there you will get informations about diagnosis and specific data in numeric value.Our goal of this study is prediction of the breast cancer whether they have **benign or malignant** by using factor columns \n\n\nAdditionally I used some resources for my sutdy\n- https:\/\/towardsdatascience.com\/all-about-feature-scaling-bcc0ad75cb35\n- https:\/\/medium.com\/@urvashilluniya\/why-data-normalization-is-necessary-for-machine-learning-models-681b65a05029","c46f62e9":"> Now explore a little bit more about features_mean.I will try to find the variable which can be use for classify.So lets plot a scatter plot for identify those variable who have a separable boundary between two class of cancer","e44b3a01":"#### Observation\n\n> As you can see on the pie chart benign possesses 63% of the total dataset.","5c1debeb":"> We have total 31 columns which consist of 1 categorical and 30 quantitative values. \nSo we gonna use `diagonisis` for final result.That means using different kind of cancer factors(30 quantitative values) we will get `diagonisis` prediction. ","979ee6e9":"> In this lat part we'll do a prediction.For that we'll use **SVM,RandomForest,DecisionTree,KNN,LogisticRegression** which are the most popular and fundamental machine learning algorithms in Data science. If you don't have any idea of it, please check how work each of algorithms above before you dive into the last part of this study","1e67ae78":"### LogisticRegression","6d29d4d6":"## 1. Gathering  ","5e17a254":"### SVM(Top 5 features)","62075c42":"Of course that's really good if we use all factor columns to guess who has probably have a different type of `diagnosis`.But it takes a lot of time. Also it's really **hard to read at a glance**.So what we`re going to do now is copy the original file and filter columns that I want to use. \n\n**Notice**\n- Copying the file is also important process.Because keeping the original file is more easiler when you use that file again later. \n\n**Columns information**\n- mean : average\n- se(standard error) : quantifies the variation in the means from multiple sets of measurements.In other words standard error is the mean of standard deviation.\n- standard deviation : quantifies the variation within a set of measurements \n- worst : worst or largest mean value from each data\n\nThe confusing things between **standard error** and **standard deviation** is that the standard error can be estimated from a single set of measurements, even though it describes the means from multiple sets. Thus,even if you only have a singel set of measurements, you are often given the option to plot the standard error. ","1cf5ccbc":"#### Observation \n\n> There are a lot more benign than malignant.So we called `inbalanced data`.This is actually not a extreme case. If it`s too strong.We should have a balance between two type of diagnosis in order to get a right prediction later.","d39205a9":"### Cross Validation (principle version) for SVM(Top5 features)","b5522d6f":"### Compute Feature Importances","5ff73862":"> Why we're doing standardization? because columns with `mean`,`se` and `worst` have different size of value.So it's hard to compare with raw data.That's why we're doing standardization to make it comparable.\n\n\n## $$ z_{score} = \\frac {(x- \\mu)}{\\sigma}$$\n\n###### This is also we called `Standard Scaler` \n\nThe Standard Scaler assumes data is normally distributed within each feature and scales them such that the distribution centered around 0, with a standard deviation of 1.\nCentering and scaling happen independently on each feature by computing the relevant statistics on the samples in the training set. If data is not normally distributed, this is not the best Scaler to use.\n\n\n- Z = standard score or z score , this score tells us you how many standard deviations from the mean your score is.\n- x = observed value\n- $\\mu$ = mean value of dataset\n- $\\sigma$ = standard deviation of dataset","f3b9963f":"## Conclusion\n\nSo in the end we will compare all results that we did before\n\n(SVM \/ DecisionTreeClassifier \/ KNeighborClassifier \/ LogisticRegression \/ RandomForestClassifier)\n\n1. Prediction with all features \n> 91.23% \/ 89.47% \/ 92.48% \/ 94.74% \/ 93.86%\n\n2. Prediction with top 5 features according to computation of the importance\n> 90.34% \/ 91.21% \/ 88.40% \/ 90.69% \/ 92.97% \n\n3. Normalization with top 5 features according to computation of the importance\n> 93.85% \/ 91.21% \/ 93.15% \/ 93.85% \/ 92.97%\n\n4. Filtering the data with strong linear relationship \n> 87.71% \/ 89.28% \/ 86.82% \/ 89.64% \/ 91.92%\n\n\nSo third result(Normalization) had 3 best cross validation scores from 5 differrent prediciton-methods ","b9262292":"### Cross Validation (simple version) for SVM(Top5 features)","25d8688f":"> We got 455 rows for trainig and 114 rows for testing","99002fb9":"> You can directly use existed library from sklearn.But you have to understand what K-Fold cross validation is and how it works.","21bb60b9":"### DecisionTreeClassifier","81e892e6":"#### Obervation  \n\n>Those visualizations show very strong positive correlation.","f0d427ce":"## Filtering features mean ","acabf096":"#### Observation \n\n> Pointplot tells us  the distribution of z-score with different type of tumors","1e3c7eae":"#### Observation\n\n> So I will pick following combination, which tell us one of the positively and negatively heighest corrleation \n\n**Positive correlation**\n- radius_worst & perimeter_mean \n- area_mean & radius_mean\n**Negative correlation**\n- fractal_dimension_mean & radius_mean\n- fractal_dimension_mean & area_mean ","ca2f0f46":"#### What is different between standardization and normalization ? \n\n> Normalization is used when we want to bound our values between two numbers, typically, between [0,1] or [-1,1]. While Standardization transforms the data to have zero mean and a variance of 1, they make our data **unitless**. Refer to the below diagram, which shows how data looks after scaling in the X-Y plane.\n\n![std%20vs%20nor.JPG](attachment:std%20vs%20nor.JPG)","99b80985":"### KNeighborsClassifier","5a1aaa7c":"### Test all Models with Top5 features","3e3905f1":"## What is\/are the main feature(s) of interest in your dataset?\n- diagnosis \n\n## What features in the dataset do you think will help support your investigation into your feature(s) of interest?\n\n- all the other columns  \n\n## Unnecessary featues in the dataset do you think\n- Nothings, we will use all columns for factors of breast cancer ","8916ba01":"Observation\n\n>  1. Radius, area and perimeter have a strong linear relationship as expected and the features like as **texture_mean, smoothness_mean, symmetry_mean and fractal_dimension_mean** can't be used for classify two category because both category are mixed there is no separable plane\n\n> 2. So we can build a new prediction features without **texture_mean, smoothness_mean, symmetry_mean and fractal_dimension_mean** "}}