{"cell_type":{"a47f0966":"code","76d194fb":"code","6a0798e5":"code","73ff16f2":"code","8a43c1c6":"code","176428be":"code","2189c856":"code","a020cc2b":"markdown","e53fec0a":"markdown","65e676ae":"markdown","9926ef98":"markdown"},"source":{"a47f0966":"import cv2\nfrom tqdm import tqdm_notebook as tqdm\nimport fastai\nfrom fastai.vision import *\nimport os\nfrom mish_activation import *\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport skimage.io\nimport numpy as np\nimport pandas as pd\nsys.path.insert(0, '..\/input\/semisupervised-imagenet-models\/semi-supervised-ImageNet1K-models-master\/')\nfrom hubconf import *","76d194fb":"DATA = '..\/input\/prostate-cancer-grade-assessment\/test_images'\nTEST = '..\/input\/prostate-cancer-grade-assessment\/test.csv'\nSAMPLE = '..\/input\/prostate-cancer-grade-assessment\/sample_submission.csv'\nMODELS = [f'..\/input\/panda-starter-models\/RNXT50_{i}.pth' for i in range(4)]\n\nsz = 128\nbs = 2\nN = 12\nnworkers = 2","6a0798e5":"def _resnext(url, block, layers, pretrained, progress, **kwargs):\n    model = ResNet(block, layers, **kwargs)\n    #state_dict = load_state_dict_from_url(url, progress=progress)\n    #model.load_state_dict(state_dict)\n    return model\n\nclass Model(nn.Module):\n    def __init__(self, arch='resnext50_32x4d', n=6, pre=True):\n        super().__init__()\n        #m = torch.hub.load('facebookresearch\/semi-supervised-ImageNet1K-models', arch)\n        m = _resnext(semi_supervised_model_urls[arch], Bottleneck, [3, 4, 6, 3], False, \n                progress=False,groups=32,width_per_group=4)\n        self.enc = nn.Sequential(*list(m.children())[:-2])       \n        nc = list(m.children())[-1].in_features\n        self.head = nn.Sequential(AdaptiveConcatPool2d(),Flatten(),nn.Linear(2*nc,512),\n                Mish(),nn.BatchNorm1d(512),nn.Dropout(0.5),nn.Linear(512,n))\n        \n    def forward(self, x):\n        shape = x.shape\n        n = shape[1]\n        x = x.view(-1,shape[2],shape[3],shape[4])\n        x = self.enc(x)\n        shape = x.shape\n        x = x.view(-1,n,shape[1],shape[2],shape[3]).permute(0,2,1,3,4).contiguous()\\\n          .view(-1,shape[1],shape[2]*n,shape[3])\n        x = self.head(x)\n        return x","73ff16f2":"models = []\nfor path in MODELS:\n    state_dict = torch.load(path,map_location=torch.device('cpu'))\n    model = Model()\n    model.load_state_dict(state_dict)\n    model.float()\n    model.eval()\n    model.cuda()\n    models.append(model)\n\ndel state_dict","8a43c1c6":"def tile(img):\n    shape = img.shape\n    pad0,pad1 = (sz - shape[0]%sz)%sz, (sz - shape[1]%sz)%sz\n    img = np.pad(img,[[pad0\/\/2,pad0-pad0\/\/2],[pad1\/\/2,pad1-pad1\/\/2],[0,0]],\n                 constant_values=255)\n    img = img.reshape(img.shape[0]\/\/sz,sz,img.shape[1]\/\/sz,sz,3)\n    img = img.transpose(0,2,1,3,4).reshape(-1,sz,sz,3)\n    if len(img) < N:\n        img = np.pad(img,[[0,N-len(img)],[0,0],[0,0],[0,0]],constant_values=255)\n    idxs = np.argsort(img.reshape(img.shape[0],-1).sum(-1))[:N]\n    img = img[idxs]\n    return img\n\nmean = torch.tensor([1.0-0.90949707, 1.0-0.8188697, 1.0-0.87795304])\nstd = torch.tensor([0.36357649, 0.49984502, 0.40477625])\n\nclass PandaDataset(Dataset):\n    def __init__(self, path, test):\n        self.path = path\n        self.names = list(pd.read_csv(test).image_id)\n\n    def __len__(self):\n        return len(self.names)\n\n    def __getitem__(self, idx):\n        name = self.names[idx]\n        img = skimage.io.MultiImage(os.path.join(DATA,name+'.tiff'))[-1]\n        tiles = torch.Tensor(1.0 - tile(img)\/255.0)\n        tiles = (tiles - mean)\/std\n        return tiles.permute(0,3,1,2), name","176428be":"sub_df = pd.read_csv(SAMPLE)\nif os.path.exists(DATA):\n    ds = PandaDataset(DATA,TEST)\n    dl = DataLoader(ds, batch_size=bs, num_workers=nworkers, shuffle=False)\n    names,preds = [],[]\n\n    with torch.no_grad():\n        for x,y in tqdm(dl):\n            x = x.cuda()\n            #dihedral TTA\n            x = torch.stack([x,x.flip(-1),x.flip(-2),x.flip(-1,-2),\n              x.transpose(-1,-2),x.transpose(-1,-2).flip(-1),\n              x.transpose(-1,-2).flip(-2),x.transpose(-1,-2).flip(-1,-2)],1)\n            x = x.view(-1,N,3,sz,sz)\n            p = [model(x) for model in models]\n            p = torch.stack(p,1)\n            p = p.view(bs,8*len(models),-1).mean(1).argmax(-1).cpu()\n            names.append(y)\n            preds.append(p)\n    \n    names = np.concatenate(names)\n    preds = torch.cat(preds).numpy()\n    sub_df = pd.DataFrame({'image_id': names, 'isup_grade': preds})\n    sub_df.to_csv('submission.csv', index=False)\n    sub_df.head()","2189c856":"sub_df.to_csv(\"submission.csv\", index=False)\nsub_df.head()","a020cc2b":"# Data","e53fec0a":"# Description\nThis kernel performs inference for [PANDA concat tile pooling starter](https:\/\/www.kaggle.com\/iafoss\/panda-concat-fast-ai-starter) kernel with use of multiple models and 8 fold TTA. Check it for more training details. The image preprocessing pipline is provided [here](https:\/\/www.kaggle.com\/iafoss\/panda-16x128x128-tiles).","65e676ae":"# Prediction","9926ef98":"# Model"}}