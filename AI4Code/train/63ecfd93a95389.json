{"cell_type":{"2c5c63ec":"code","f2651283":"code","35ac47ba":"code","217e4a5d":"code","25751c09":"code","90b82e8b":"code","4abf67b3":"code","6643d8f3":"code","e368422e":"code","303f9937":"code","61fe5f35":"code","522c23c9":"code","a0ffe0cf":"code","449b4907":"code","5fbab1c2":"code","4fc5eddc":"code","b95ae228":"code","da4a1d65":"code","7dbfb55b":"code","e5de7bd8":"markdown","beed83dc":"markdown","f613fb98":"markdown","23e4607a":"markdown","a1908a96":"markdown","ccb9934d":"markdown","61ce1fe0":"markdown","77a44a9b":"markdown","2536b51e":"markdown","d3a41bdd":"markdown","2b05bdbe":"markdown"},"source":{"2c5c63ec":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use(\"bmh\")\n\n# model\nfrom sklearn.ensemble import ExtraTreesClassifier\nimport optuna\n\n# misc\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics","f2651283":"df = pd.read_csv('..\/input\/heart-disease-uci\/heart.csv')\ndf","35ac47ba":"df.isnull().values.any()","217e4a5d":"df.dtypes","25751c09":"df.describe()","90b82e8b":"df.hist(figsize = (12, 12));","4abf67b3":"corr = df.corr()\nplt.figure(figsize=(14,14))\nsns.heatmap(corr, annot = True, vmin=-1, vmax=1, center= 0, cmap= 'coolwarm'); # greens","6643d8f3":"features_names = [c for c in df.columns if c != 'target']\ntarget_name = 'target'\n\nfeatures = df.loc[:, features_names]\ntarget = df.loc[:, target_name]","e368422e":"X_train, X_valid, y_train, y_valid = train_test_split(features, \n                                                    target,\n                                                    test_size = 0.15,\n                                                    stratify = target,\n                                                    random_state = 0)","303f9937":"def etr(X_train, y_train,\n        X_valid, y_valid):\n  \n  # instantiate model\n  etr = ExtraTreesClassifier(n_estimators = 100,\n                             max_depth = 12,\n                             criterion = 'gini',\n                             bootstrap = False,\n                             class_weight = None,\n                             warm_start = True,\n                             max_leaf_nodes = 20,\n                             random_state = 0)\n\n  etr.fit(X_train, y_train) # train on train data\n  etr_score = round(etr.score(X_valid, y_valid), 5) # validate on validation data\n\n  print('ExtraTreesClassifier score: ', etr_score)\n\n  return etr_score\n\netr_score = etr(X_train, y_train, X_valid, y_valid)","61fe5f35":"def objective(trial):\n\n    ### define params grid to search maximum accuracy\n    n_estimators = trial.suggest_int('n_estimators', 50, 120)\n    max_depth = trial.suggest_int('max_depth', 10, 16)\n    max_leaf_nodes = trial.suggest_int('max_leaf_nodes', 15, 25)\n    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n\n    ### modeling with suggested params\n    model = ExtraTreesClassifier(n_estimators = n_estimators,\n                                 max_depth = max_depth,\n                                 max_leaf_nodes = max_leaf_nodes,\n                                 criterion = criterion,\n                                 random_state = 0) # do not tune the seed\n\n    ### cross validation score\n    # score = cross_val_score(model, X_train, y_train, n_jobs=-1, cv=3)\n    # etr_score = score.mean()\n\n    ### fit\n    model.fit(X_train, y_train) # train on train data\n    accuracy = round(model.score(X_valid, y_valid), 5) # validate on validation data\n\n    return accuracy\n    \nstudy = optuna.create_study(direction='maximize') # maximize accuracy\nstudy.optimize(objective, n_trials=30)","522c23c9":"# best params\nstudy.best_trial.params","a0ffe0cf":"# best score (accuracy)\nstudy.best_value","449b4907":"# param importances dictionary\noptuna.importance.get_param_importances(study)","5fbab1c2":"### plot param importances\n# optuna.visualization.plot_param_importances(study)\n\n### This method is not working in kaggle notebooks due to old version of optuna (1.5.0)\n### It works on colab though (optuna version: 2.10.0)\n### below is a picture of what this plot looks like on colab","4fc5eddc":"# plot optimization history\noptuna.visualization.plot_optimization_history(study)","b95ae228":"# plot parallel coordinate\noptuna.visualization.plot_parallel_coordinate(study)","da4a1d65":"# slice plot\noptuna.visualization.plot_slice(study)","7dbfb55b":"names = np.array(['ETR', 'ETR tuned'])\nvalues = np.array([etr_score, study.best_value])\n\nplt.figure(figsize=(8,8))\nplt.title(\"Accuracy: Before and After Tuning\", fontsize=18)\nplt.ylim(0.5, 1)\nbar1 = sns.barplot(x = names, y = values);\n\nfor p in bar1.patches:\n  _x = p.get_x() + p.get_width() \/ 2\n  _y = p.get_y() + p.get_height() + (p.get_height()*0.01)\n  value = '{:.4f}'.format(p.get_height())\n  plt.text(_x, _y, value, ha=\"center\", fontsize=16, fontweight = 'bold') ","e5de7bd8":"# Imports","beed83dc":"# Split","f613fb98":"# Load data","23e4607a":"![image.png](attachment:16996abb-74cd-4090-b3d4-b780d80308dd.png)","a1908a96":"# Extra Trees Classifier","ccb9934d":"# Results","61ce1fe0":"# Features and target","77a44a9b":"Upvote if you found value in this notebook! \ud83d\ude00","2536b51e":"# About this notebook\n\n- heart disease prediction with [Extra Trees Classifier](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.ExtraTreesClassifier.html)\n- hyper parameter tuning using [optuna](https:\/\/optuna.org\/)","d3a41bdd":"# Tuning with Optuna\n\nHyper Parameter Optimization\n\n[Optuna docs](https:\/\/optuna.readthedocs.io\/en\/stable\/reference\/generated\/optuna.trial.Trial.html)","2b05bdbe":"# Optuna visualization"}}