{"cell_type":{"662466a5":"code","a2379f21":"code","53d9bbba":"code","973acc38":"code","eea7cc44":"code","b3e38748":"code","053ffdf4":"code","20a4ee4d":"code","3f657f82":"code","2d7a612e":"code","377b4ca2":"markdown","c6e4f4dc":"markdown","528acfc6":"markdown","057ef75e":"markdown","eee8d91f":"markdown","4bf09d22":"markdown","9c75cdaf":"markdown","463f6363":"markdown","c00daa40":"markdown"},"source":{"662466a5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a2379f21":"import shutil\nimport errno\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns","53d9bbba":"# data generator\n# source from https:\/\/medium.com\/@ensembledme\/writing-custom-keras-generators-fe815d992c5a\nfrom skimage.io import imread\n\ndef get_input(path):\n    \"\"\"get specific image from path\"\"\"\n    img = imread(path)\n    return img\n\ndef get_output(path, label_file = None):\n    \"\"\"get all the labels relative to the image of path\"\"\"\n    img_id = path.split('\/')[-1]\n    labels = label_file.loc[img_id].values\n    return labels\n\ndef preprocess_input(img):\n    # convert between 0 and 1\n    return img.astype('float32') \/ 127.5 -1\n\ndef image_generator(files, label_file, batch_size = 32):\n    while True:\n\n        batch_paths = np.random.choice(a = files, size = batch_size)\n        batch_input = []\n        batch_output = []\n\n        for input_path in batch_paths:\n\n            input = get_input(input_path)\n            input = preprocess_input(input)\n            output = get_output(input_path, label_file = label_file)\n            batch_input += [input]\n            batch_output += [output]\n        batch_x = np.array(batch_input)\n        batch_y = np.array(batch_output)\n\n        yield batch_x, batch_y\n\ndef auto_encoder_generator(files, batch_size = 32):\n    while True:\n        batch_paths = np.random.choice(a = files, size = batch_size)\n        batch_input = []\n        batch_output = []\n\n        for input_path in batch_paths:\n            input = get_input(input_path)\n            input = preprocess_input(input)\n            output = input\n            batch_input += [input]\n            batch_output += [output]\n        batch_x = np.array(batch_input)\n        batch_y = np.array(batch_output)\n\n        yield batch_x, batch_y","973acc38":"import pandas as pd\nattr = pd.read_csv('..\/input\/celeba-dataset\/list_attr_celeba.csv')\nattr = attr.set_index('image_id')\n\n# check if attribute successful loaded\nattr.describe()","eea7cc44":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nIMG_NAME_LENGTH = 6\nfile_path = \"..\/input\/celeba-dataset\/img_align_celeba\/img_align_celeba\/\"\nimg_id = np.arange(1,len(attr.index)+1)\nimg_path = []\nfor i in range(len(img_id)):\n    img_path.append(file_path + (IMG_NAME_LENGTH - len(str(img_id[i])))*'0' + str(img_id[i]) + '.jpg')\n# pick 80% as training set and 20% as validation set\ntrain_path = img_path[:int((0.8)*len(img_path))]\nval_path = img_path[int((0.8)*len(img_path)):]\ntrain_generator = auto_encoder_generator(train_path,32)\nval_generator = auto_encoder_generator(val_path,32)","b3e38748":"fig, ax = plt.subplots(1, 5, figsize=(12, 4))\nfor i in range(5):    \n    ax[i].imshow(get_input(img_path[i]))\n    ax[i].axis('off')\n    ax[i].set_title(img_path[i][-10:])\nplt.show()\n    \nattr.iloc[:5]","053ffdf4":"plt.figure(figsize = (20,20))\nsns.heatmap(attr.corr())","20a4ee4d":"from tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dropout, Flatten, Dense, Conv2D, MaxPooling2D, Input, Reshape, UpSampling2D, InputLayer, Lambda, ZeroPadding2D, Cropping2D, Conv2DTranspose, BatchNormalization\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.losses import mse, binary_crossentropy","3f657f82":"img_sample=get_input(img_path[0])","2d7a612e":"import tensorflow as tf\nimport random\n#tf.config.run_eagerly(True)\nwith tf.compat.v1.Session() as sess:\n    b_size = 128\n    n_size = 512\n    def sampling(args):\n        z_mean, z_log_sigma = args\n        epsilon = K.random_normal(shape = (n_size,) , mean = 0, stddev = 1)\n        return z_mean + K.exp(z_log_sigma\/2) * epsilon\n  \n    def build_conv_vae(input_shape, bottleneck_size, sampling, batch_size = 32):\n    \n        # ENCODER\n        input = Input(shape=(input_shape[0],input_shape[1],input_shape[2]))\n        x = Conv2D(32,(3,3),activation = 'relu', padding = 'same')(input)    \n        x = BatchNormalization()(x)\n        x = MaxPooling2D((2,2), padding ='same')(x)\n        x = Conv2D(64,(3,3),activation = 'relu', padding = 'same')(x)\n        x = BatchNormalization()(x)\n        x = MaxPooling2D((2,2), padding ='same')(x)\n        x = Conv2D(128,(3,3), activation = 'relu', padding = 'same')(x)\n        x = BatchNormalization()(x)\n        x = MaxPooling2D((2,2), padding ='same')(x)\n        x = Conv2D(256,(3,3), activation = 'relu', padding = 'same')(x)\n        x = BatchNormalization()(x)\n        x = MaxPooling2D((2,2), padding ='same')(x)\n    \n        # Latent Variable Calculation\n        shape = K.int_shape(x)\n        flatten_1 = Flatten()(x)\n        dense_1 = Dense(bottleneck_size, name='z_mean')(flatten_1)\n        z_mean = BatchNormalization()(dense_1)\n        flatten_2 = Flatten()(x)\n        dense_2 = Dense(bottleneck_size, name ='z_log_sigma')(flatten_2)\n        z_log_sigma = BatchNormalization()(dense_2)\n        z = Lambda(sampling)([z_mean, z_log_sigma])\n        encoder = Model(input, [z_mean, z_log_sigma, z], name = 'encoder')\n    \n        # DECODER\n        latent_input = Input(shape=(bottleneck_size,), name = 'decoder_input')\n        x = Dense(shape[1]*shape[2]*shape[3])(latent_input)\n        x = Reshape((shape[1],shape[2],shape[3]))(x)\n        x = UpSampling2D((2,2))(x)\n        x = Cropping2D([[0,0],[0,1]])(x)\n        x = Conv2DTranspose(256,(3,3), activation = 'relu', padding = 'same')(x)\n        x = BatchNormalization()(x)\n        x = UpSampling2D((2,2))(x)\n        x = Cropping2D([[0,1],[0,1]])(x)\n        x = Conv2DTranspose(128,(3,3), activation = 'relu', padding = 'same')(x)\n        x = BatchNormalization()(x)\n        x = UpSampling2D((2,2))(x)\n        x = Cropping2D([[0,1],[0,1]])(x)\n        x = Conv2DTranspose(64,(3,3), activation = 'relu', padding = 'same')(x)\n        x = BatchNormalization()(x)\n        x = UpSampling2D((2,2))(x)\n        x = Conv2DTranspose(32,(3,3), activation = 'relu', padding = 'same')(x)\n        x = BatchNormalization()(x)\n        output = Conv2DTranspose(3,(3,3), activation = 'tanh', padding ='same')(x)\n        decoder = Model(latent_input, output, name = 'decoder')\n\n        output_2 = decoder(encoder(input)[2])\n        vae = Model(input, output_2, name ='vae')\n        return vae, encoder, decoder, z_mean, z_log_sigma\n\n    vae_2, encoder, decoder, z_mean, z_log_sigma = build_conv_vae(img_sample.shape, n_size, sampling, batch_size = b_size)\n    print(\"encoder summary:\")\n    encoder.summary()\n    print(\"decoder summary:\")\n    decoder.summary()\n    print(\"vae summary:\")\n    vae_2.summary()\n    \n    def vae_loss(input_img, output):\n        # Compute error in reconstruction\n        reconstruction_loss = mse(K.flatten(input_img) , K.flatten(output))\n    \n        # Compute the KL Divergence regularization term\n        kl_loss = - 0.5 * K.sum(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis = -1)\n    \n        # Return the average loss over all images in batch\n        total_loss = (reconstruction_loss + 0.0001 * kl_loss)    \n        return total_loss\n    vae_2.compile(optimizer='rmsprop', loss= vae_loss)\n    encoder.compile(optimizer = 'rmsprop', loss = vae_loss)\n    decoder.compile(optimizer = 'rmsprop', loss = vae_loss)\n    vae_2.fit_generator(train_generator, steps_per_epoch = 4000, validation_data = val_generator, epochs=7, validation_steps= 500)\n    \n    \n    x_test = []\n    for i in range(64):\n        x_test.append(get_input(img_path[random.randint(0,len(img_id))]))\n    x_test = np.array(x_test)\n    figure_Decoded = vae_2.predict(x_test.astype('float32')\/127.5 -1, batch_size = b_size)\n    figure_original = x_test[0]\n    figure_decoded = (figure_Decoded[0]+1)\/2\n    for i in range(4):\n        plt.axis('off')\n        plt.subplot(2,4,1+i*2)\n        plt.imshow(x_test[i])\n        plt.axis('off')\n        plt.subplot(2,4,2 + i*2)\n        plt.imshow((figure_Decoded[i]+1)\/2)\n        plt.axis('off')\n    plt.show()\n    \n    # Choose two images of different attributes, and plot the original and latent space of it\n    \n    x_test1 = []\n    for i in range(64):\n        x_test1.append(get_input(img_path[np.random.randint(0,len(img_id))]))\n    x_test1 = np.array(x_test)\n    x_test_encoded = np.array(encoder.predict(x_test1\/127.5-1, batch_size = b_size))\n    figure_original_1 = x_test[0]\n    figure_original_2 = x_test[1]\n    Encoded1 = (x_test_encoded[0,0,:].reshape(32, 16,)+1)\/2 \n    Encoded2 = (x_test_encoded[0,1,:].reshape(32, 16)+1)\/2\n    \n    plt.figure(figsize=(8, 8))\n    plt.subplot(2,2,1)\n    plt.imshow(figure_original_1)\n    plt.subplot(2,2,2)\n    plt.imshow(Encoded1)\n    plt.subplot(2,2,3)\n    plt.imshow(figure_original_2)\n    plt.subplot(2,2,4)\n    plt.imshow(Encoded2)\n    filename = 'Fig_001.png'\n    plt.savefig(filename)\n    plt.show()\n    plt.close()\n    # Randomly generated 15 images from 15 series of noise information\n    n = 3\n    m = 5\n    digit_size1 = 218\n    digit_size2 = 178\n    figure = np.zeros((digit_size1 * n, digit_size2 * m,3))\n     \n    for i in range(3):\n        for j in range(5):\n            z_sample = np.random.rand(1,512)\n            x_decoded = decoder.predict([z_sample])\n            figure[i * digit_size1: (i + 1) * digit_size1,\n                   j * digit_size2: (j + 1) * digit_size2,:] = (x_decoded[0]+1)\/2 \n    plt.figure(figsize=(10, 10))\n    plt.imshow(figure)\n    filename = 'Fig_002.png'\n    plt.savefig(filename)\n    plt.show()\n    plt.close()","377b4ca2":"b_size = 128\nn_size = 512\n\n\ndef sampling(args):\n    z_mean, z_log_sigma = args\n    epsilon = K.random_normal(shape = (n_size,) , mean = 0, stddev = 1)\n    return z_mean + K.exp(z_log_sigma\/2) * epsilon\n  \ndef build_conv_vae(input_shape, bottleneck_size, sampling, batch_size = 32):\n    \n    # ENCODER\n    input = Input(shape=(input_shape[0],input_shape[1],input_shape[2]))\n    x = Conv2D(32,(3,3),activation = 'relu', padding = 'same')(input)    \n    x = BatchNormalization()(x)\n    x = MaxPooling2D((2,2), padding ='same')(x)\n    x = Conv2D(64,(3,3),activation = 'relu', padding = 'same')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D((2,2), padding ='same')(x)\n    x = Conv2D(128,(3,3), activation = 'relu', padding = 'same')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D((2,2), padding ='same')(x)\n    x = Conv2D(256,(3,3), activation = 'relu', padding = 'same')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D((2,2), padding ='same')(x)\n    \n    # Latent Variable Calculation\n    shape = K.int_shape(x)\n    flatten_1 = Flatten()(x)\n    dense_1 = Dense(bottleneck_size, name='z_mean')(flatten_1)\n    z_mean = BatchNormalization()(dense_1)\n    flatten_2 = Flatten()(x)\n    dense_2 = Dense(bottleneck_size, name ='z_log_sigma')(flatten_2)\n    z_log_sigma = BatchNormalization()(dense_2)\n    z = Lambda(sampling)([z_mean, z_log_sigma])\n    encoder = Model(input, [z_mean, z_log_sigma, z], name = 'encoder')\n    \n    # DECODER\n    latent_input = Input(shape=(bottleneck_size,), name = 'decoder_input')\n    x = Dense(shape[1]*shape[2]*shape[3])(latent_input)\n    x = Reshape((shape[1],shape[2],shape[3]))(x)\n    x = UpSampling2D((2,2))(x)\n    x = Cropping2D([[0,0],[0,1]])(x)\n    x = Conv2DTranspose(256,(3,3), activation = 'relu', padding = 'same')(x)\n    x = BatchNormalization()(x)\n    x = UpSampling2D((2,2))(x)\n    x = Cropping2D([[0,1],[0,1]])(x)\n    x = Conv2DTranspose(128,(3,3), activation = 'relu', padding = 'same')(x)\n    x = BatchNormalization()(x)\n    x = UpSampling2D((2,2))(x)\n    x = Cropping2D([[0,1],[0,1]])(x)\n    x = Conv2DTranspose(64,(3,3), activation = 'relu', padding = 'same')(x)\n    x = BatchNormalization()(x)\n    x = UpSampling2D((2,2))(x)\n    x = Conv2DTranspose(32,(3,3), activation = 'relu', padding = 'same')(x)\n    x = BatchNormalization()(x)\n    output = Conv2DTranspose(3,(3,3), activation = 'tanh', padding ='same')(x)\n    decoder = Model(latent_input, output, name = 'decoder')\n\n    output_2 = decoder(encoder(input)[2])\n    vae = Model(input, output_2, name ='vae')\n    return vae, encoder, decoder, z_mean, z_log_sigma\n\nvae_2, encoder, decoder, z_mean, z_log_sigma = build_conv_vae(img_sample.shape, n_size, sampling, batch_size = b_size)\nprint(\"encoder summary:\")\nencoder.summary()\nprint(\"decoder summary:\")\ndecoder.summary()\nprint(\"vae summary:\")\nvae_2.summary()","c6e4f4dc":"import tensorflow as tf\ntf.config.run_eagerly(True)\nvae_2.fit_generator(train_generator, steps_per_epoch = 4000, validation_data = val_generator, epochs=7, validation_steps= 500)","528acfc6":"# Choose two images of different attributes, and plot the original and latent space of it\n\nx_test1 = []\nfor i in range(64):\n    x_test1.append(get_input(img_path[np.random.randint(0,len(img_id))]))\nx_test1 = np.array(x_test)\nx_test_encoded = np.array(encoder.predict(x_test1\/127.5-1, batch_size = b_size))\nfigure_original_1 = x_test[0]\nfigure_original_2 = x_test[1]\nEncoded1 = (x_test_encoded[0,0,:].reshape(32, 16,)+1)\/2 \nEncoded2 = (x_test_encoded[0,1,:].reshape(32, 16)+1)\/2\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2,2,1)\nplt.imshow(figure_original_1)\nplt.subplot(2,2,2)\nplt.imshow(Encoded1)\nplt.subplot(2,2,3)\nplt.imshow(figure_original_2)\nplt.subplot(2,2,4)\nplt.imshow(Encoded2)\nplt.show()","057ef75e":"def vae_loss(input_img, output):\n    # Compute error in reconstruction\n    reconstruction_loss = mse(K.flatten(input_img) , K.flatten(output))\n    \n    # Compute the KL Divergence regularization term\n    kl_loss = - 0.5 * K.sum(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis = -1)\n    \n    # Return the average loss over all images in batch\n    total_loss = (reconstruction_loss + 0.0001 * kl_loss)    \n    return total_loss","eee8d91f":"import random\nx_test = []\nfor i in range(64):\n    x_test.append(get_input(img_path[random.randint(0,len(img_id))]))\nx_test = np.array(x_test)\nfigure_Decoded = vae_2.predict(x_test.astype('float32')\/127.5 -1, batch_size = b_size)\nfigure_original = x_test[0]\nfigure_decoded = (figure_Decoded[0]+1)\/2\nfor i in range(4):\n    plt.axis('off')\n    plt.subplot(2,4,1+i*2)\n    plt.imshow(x_test[i])\n    plt.axis('off')\n    plt.subplot(2,4,2 + i*2)\n    plt.imshow((figure_Decoded[i]+1)\/2)\n    plt.axis('off')\nplt.show()","4bf09d22":"vae_2.compile(optimizer='rmsprop', loss= vae_loss)\nencoder.compile(optimizer = 'rmsprop', loss = vae_loss)\ndecoder.compile(optimizer = 'rmsprop', loss = vae_loss)","9c75cdaf":"## Due to improper config of tensorflow and keras\n## had to combine the cells to run in a single session.\n## Below is the collapsed markdown for it.","463f6363":"# Initial Assessment of Dataset\nSo being male has no correlation with being attractive - fair enough <br>\nSurprising Bangs and Bald are correlated - <br>\nWait what!! <br>\nAnyways,","c00daa40":"# We randomly generated 15 images from 15 series of noise information\nn = 3\nm = 5\ndigit_size1 = 218\ndigit_size2 = 178\nfigure = np.zeros((digit_size1 * n, digit_size2 * m,3))\n \nfor i in range(3):\n    for j in range(5):\n        z_sample = np.random.rand(1,512)\n        x_decoded = decoder.predict([z_sample])\n        figure[i * digit_size1: (i + 1) * digit_size1,\n               j * digit_size2: (j + 1) * digit_size2,:] = (x_decoded[0]+1)\/2 \nplt.figure(figsize=(10, 10))\nplt.imshow(figure)\nplt.show()"}}