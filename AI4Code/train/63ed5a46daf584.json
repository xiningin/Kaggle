{"cell_type":{"eea518ad":"code","ee857ee2":"code","92fa255a":"code","b4879e35":"code","1d7a6a55":"code","2c16582a":"code","7340e8bc":"code","5d02419e":"code","d34a0603":"code","8b61fb4d":"code","a5d9ebb1":"code","47f2d0b6":"code","e92fc0d8":"code","7a58b1dc":"code","3f312d28":"code","813506d7":"code","dc93789b":"markdown","b5829349":"markdown","b23293e5":"markdown","b9311070":"markdown","8a23e5f2":"markdown","3e5c52e6":"markdown","ca38bf6e":"markdown","36c2912a":"markdown","73b7ea29":"markdown","a017a233":"markdown","7e82c7b2":"markdown"},"source":{"eea518ad":"# This Python 3 environment \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport os\nprint(os.listdir(\"..\/input\"))\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, make_scorer, recall_score, precision_score, f1_score, roc_auc_score\n\nfrom sklearn.model_selection import GridSearchCV","ee857ee2":"!pip install statsmodels==0.10.0rc2 --pre  # Statsmodel has sme problem with factorial in latest lib","92fa255a":"# Install the Library (Refer: https:\/\/pypi.org\/project\/kesh-utils\/ )\n!pip install kesh-utils","b4879e35":"# Ignore the warnings if any\nimport warnings  \nwarnings.filterwarnings('ignore')","1d7a6a55":"# Load the dataset \nadult_income_df = pd.read_csv('..\/input\/adult.csv')","2c16582a":"adult_income_df.head()","7340e8bc":"# Quick known cleanup for this dataset\nadult_income_df['workclass']=adult_income_df['workclass'].replace('?','Unknown') # Treat ? workclass as unknown\nadult_income_df = adult_income_df[adult_income_df['occupation'] != '?'] # Remove rows with occupation =?\nadult_income_df['native.country']=adult_income_df['native.country'].replace('?', adult_income_df['native.country'].mode()[0]) # Replace ? with mode\nadult_income_df['fnlwgt']=np.log(adult_income_df['fnlwgt']) # Convert to antural log\nadult_income_df.loc[adult_income_df['native.country']!='United-States','native.country'] = 'non_usa' # Two many category level, convert just US and Non-US","5d02419e":"# We will use Label encoder for all categorical variables\nfrom sklearn import preprocessing\n\n# encode categorical variables using Label Encoder\n# select all categorical variables\ndf_categorical = adult_income_df.select_dtypes(include=['object'])\ndf_categorical.head()\n\n# apply Label encoder to df_categorical\nle = preprocessing.LabelEncoder()\ndf_categorical = df_categorical.apply(le.fit_transform)\ndf_categorical.head()\n\n# concat df_categorical with original df\nadult_income_df = adult_income_df.drop(df_categorical.columns, axis=1)\nadult_income_df = pd.concat([adult_income_df, df_categorical], axis=1)","d34a0603":"# Scale the numerical features using StandardScalar\nfrom sklearn.preprocessing import StandardScaler\nnumerical_column_names = ['age','fnlwgt','education.num', 'capital.gain', 'capital.loss', 'hours.per.week']\nscaler = StandardScaler()\n\nadult_income_df[numerical_column_names] = scaler.fit_transform(\n    adult_income_df[numerical_column_names])","8b61fb4d":"# Final cleaned dataset \nadult_income_df.head()","a5d9ebb1":"# Prepare the data for model building and evaluation\nX = adult_income_df.drop('income', axis=1)\ny = adult_income_df['income'] \nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=43)","47f2d0b6":"# Load the custom library\nfrom KUtils.classifier import generic_classifier_utils as gcu","e92fc0d8":"from sklearn.tree import DecisionTreeClassifier\n\nscores = gcu.single_hyperparameter_multiple_scoring_tuning(\n    X_train, y_train,\n    cv_folds=5, \n    hyper_parameter_name='max_depth',\n    hyper_parameter_range = range(3, 21, 3),\n    model_scoring = {'F1': make_scorer(f1_score),\n                     'AUC': make_scorer(roc_auc_score),\n                     'Accuracy': make_scorer(accuracy_score)        #  'Accuracy': make_scorer(accuracy_score),\n                    },\n    refit='AUC',\n    classifier_algo=DecisionTreeClassifier())","7a58b1dc":"from sklearn.ensemble import RandomForestClassifier\n\nscores = gcu.single_hyperparameter_multiple_scoring_tuning(\n    X_train, y_train,\n    cv_folds=10, \n    hyper_parameter_name='n_estimators',\n    hyper_parameter_range =range(5, 200, 25),   \n    model_scoring = {'F1': make_scorer(f1_score),\n                     'AUC': make_scorer(roc_auc_score),\n                     'Accuracy': make_scorer(accuracy_score)        #  'Accuracy': make_scorer(accuracy_score),\n                    },\n    refit='AUC',\n    classifier_algo=RandomForestClassifier(max_depth=4))","3f312d28":"from xgboost.sklearn import XGBClassifier\n\nscores = gcu.single_hyperparameter_multiple_scoring_tuning(\n    X_train, y_train,\n    cv_folds=10, \n    hyper_parameter_name='learning_rate',\n    hyper_parameter_range = [0.1, 0.2, 0.3, 0.4, 0.5, 0.9],\n    model_scoring = {'F1': make_scorer(f1_score),\n                     'AUC': make_scorer(roc_auc_score),\n                     'Accuracy': make_scorer(accuracy_score)        #  'Accuracy': make_scorer(accuracy_score),\n                    },\n    refit='AUC',\n    classifier_algo=XGBClassifier(objective= 'binary:logistic'))","813506d7":"import lightgbm as lgb\n\nscores = gcu.single_hyperparameter_multiple_scoring_tuning(\n    X_train, y_train,\n    cv_folds=10,\n    hyper_parameter_name='num_leaves',\n    hyper_parameter_range = [2, 5, 10, 50, 100, 200],\n    model_scoring = {'F1': make_scorer(f1_score),\n                     'AUC': make_scorer(roc_auc_score),\n                     'Accuracy': make_scorer(accuracy_score)        #  'Accuracy': make_scorer(accuracy_score),\n                    },\n    refit='Accuracy',\n    classifier_algo=lgb.LGBMClassifier(n_jobs=-1))","dc93789b":"#### I will stop here. This is just a demo how to use the library for using multiple Classifer with different scoring.\n\n#### You can try to finetune for different classifier with different scoring and different hyperparamaters.\n\n### Check other methods in the library.\n","b5829349":"# 4. lightgbm - LGBMClassifier() and Hyperparameter 'num_leaves' with values [2, 5, 10, 50, 100, 200]","b23293e5":"# 3. XGBClassifier() and Hyperparameter 'learning_rate' with values [0.1, 0.2, 0.3, 0.4, 0.5, 0.9]","b9311070":"# 1. DecisionTreeClassifier() and Hyperparameter 'max_depth' with range range(3, 21, 3)","8a23e5f2":"#### Accuracy best at learning rate 0.3, however F1 best at 0.4","3e5c52e6":"### In a single chart you can see which scoring is improving and which one deteriorating\n\nIn the above chart at max_depth=9 all three (AUC, Accuracy, F1) are at its best**","ca38bf6e":"# Multi scoring Hyperparemeter Tuning using GCU(Generic classifier Utility)\n\nWhile finetuning hyperparameter for a specific scoring strategy there is a chances other scores dropping.\ne.g: Accuracy might be increasing but Precision or Recall or ROC dropping.\nIn order to balance the lossess in other metrics we need multiple scoring evaluation in a single graph.\n\nFor this I developed a <b><u>Generic classifier Utility<\/u><\/b> library which will display multiple scoring for different Tree based Boosting technique.\ni.e: A single library can accomodate multiple Tree Boosting technique along with multiple scoring.\n\nSource code available [here](https:\/\/github.com\/KeshavShetty\/kesh-utils\/tree\/master\/KUtils\/classifier) and PyPi package [here](https:\/\/pypi.org\/project\/kesh-utils\/)\n\nFor this demo I used Adult Census Income dataset.","36c2912a":"### Upvote if you liked the Kernel. Leave comments if any","73b7ea29":"# 2. RandonForestClassifier() and Hyperparameter 'n_estimator' with range range(5, 200, 25)","a017a233":"# GCU in Action\n### The method used is KUtils.classifier.single_hyperparameter_multiple_scoring_tuning()","7e82c7b2":"### We will use\n- DecisionTreeClassifier\n- RandomForestClassifier\n- XGBClassifier\n- LGBMClassifier\n\nFor scoring we will use\n\nmodel_scoring = {'F1': make_scorer(f1_score),\n    'AUC': make_scorer(roc_auc_score),\n    'Accuracy': make_scorer(accuracy_score)\n}\n\nAt a time you can send single hyper parameter and multiple scoring for hyperparameter tuning."}}