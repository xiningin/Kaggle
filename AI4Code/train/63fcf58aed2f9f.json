{"cell_type":{"fd689068":"code","6a83f499":"code","62d21b4a":"code","a08a4315":"code","8b30e5ad":"code","2f2486b0":"code","5cffba27":"code","8b573d3d":"code","a25f01ca":"code","9223c546":"code","a5e0aadf":"code","88dc58c2":"code","efdf35d3":"code","e52ded95":"code","60e6be7c":"code","19247133":"code","135771a1":"code","7d7cda54":"code","fd471a32":"code","f56a57e5":"code","b97d4cbc":"code","39e7ec93":"code","46bd8a4b":"code","d9b5ddb4":"code","9b6f5f0d":"markdown","d5736cc6":"markdown","0b33078f":"markdown","f29d106f":"markdown","46afe349":"markdown","4b6ccd0a":"markdown","f5ede7d0":"markdown","22dabc45":"markdown","d2cb6006":"markdown","0eecd57c":"markdown","77ed4634":"markdown","6ba42a00":"markdown","26f52001":"markdown","61fa6529":"markdown","c377de1a":"markdown","aec02380":"markdown"},"source":{"fd689068":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport os\nimport pathlib\nfrom pprint import pprint\n\n#img\nimport cv2\n\n#pytorch\nimport torch\n\nfrom torch import nn\nfrom torch import functional as F\nfrom torch import optim\nfrom torch.utils.data import Dataset,DataLoader,random_split\nfrom torchvision import transforms\nfrom torch.nn import Module\nfrom torchvision import models\nfrom PIL import Image\n#dicom\nimport pydicom\n\nfrom torchvision.models.detection import FasterRCNN\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection.rpn import AnchorGenerator\nfrom torch.utils.data import DataLoader\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom tqdm.notebook import tqdm\nimport albumentations as A\n\n#set Device\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(device)","6a83f499":"#-----path-----\n#train csv\ntrain_csv_path=pathlib.\\\n        Path(\"..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train.csv\")\nsample_sub_path=pathlib.\\\n        Path(\"..\/input\/vinbigdata-chest-xray-abnormalities-detection\/sample_submission.csv\")\n#dicom data\ntrain_data_path=pathlib.\\\n        Path(\"..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\")\ntest_data_path=pathlib.\\\n        Path(\"..\/input\/vinbigdata-chest-xray-abnormalities-detection\/test\")\n\n#path\u306e\u78ba\u8a8d\nprint(pathlib.Path.exists(train_csv_path),\n      pathlib.Path.exists(train_data_path),\n      pathlib.Path.exists(test_data_path)\n     )","62d21b4a":"#train\u30c7\u30fc\u30bf\u306eindex\u30ea\u30b9\u30c8\u3092\u53d6\u5f97\u3059\u308b\u3002\nimage_ids=[x for x in train_data_path.iterdir() if x.is_file()]\nlen(image_ids)\n","a08a4315":"#train csv\ndf=pd.read_csv(train_csv_path)\ndf.head()","8b30e5ad":"#image id\u90e8\u5206\u306e\u307f\u3092\u5206\u5272\nsample_=pathlib.\\\n    Path('..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\/000434271f63a053c4128a0ba6352c7f.dicom')\n#\u62e1\u5f35\u5b50\u306e\u307f\u3092\u53d6\u5f97\u3059\u308b\nprint(\"\u62e1\u5f35\u5b50\uff1b\",image_ids[0].suffix)\n#\u62e1\u5f35\u5b50\u306a\u3057\u306eid\u306e\u307f\u3092\u53d6\u5f97\nprint(\"\u62e1\u5f35\u5b50\u306a\u3057\u306e\u30d5\u30a1\u30a4\u30eb\u540d\u53d6\u5f97:\",image_ids[0].stem)","2f2486b0":"#bounding box\u3092\u53d6\u5f97\u3059\u308b\u3053\u3068\u306f\u53ef\u80fd\u3002\ndf[df[\"image_id\"]==sample_.stem]","5cffba27":"print(df.isnull().sum())\n#\u4e0a\u8a18\u610f\u5916\u306b\u6b20\u640d\u5024\u306f\u306a\u3055\u305d\u3046\u3002\n#bounding box\u304c\u306a\u3044\u5834\u5408Nan\u3068\u306a\u3063\u3066\u3044\u308b\u305f\u3081\u3001\u7a74\u57cb\u3081 \ndf.fillna(0,inplace=True)","8b573d3d":"#classid\n\"\"\"\n>0 - Aortic enlargement\n1 - Atelectasis\n2 - Calcification\n3 - Cardiomegaly\n4 - Consolidation\n5 - ILD\n6 - Infiltration\n7 - Lung Opacity\n8 - Nodule\/Mass\n9 - Other lesion\n10 - Pleural effusion\n11 - Pleural thickening\n12 - Pneumothorax\n13 - Pulmonary fibrosis\n\"\"\"\nprint(df[\"class_id\"].unique())\nprint(len(df[\"class_id\"].unique()))","a25f01ca":"# dicom\u30c7\u30fc\u30bf\u306e\u753b\u50cf\u8868\u793a\u4f8b\nsample_ids=image_ids[10]\nprint(sample_ids.stem)\nprint(sample_ids.suffix)","9223c546":"dicom=pydicom.dcmread(sample_ids)\ndicom","a5e0aadf":"import pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nfrom skimage import exposure\n\n\n#[reference]\\\n#https:\/\/www.kaggle.com\/raddar\/popular-x-ray-image-normalization-techniques\n\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    \n    data = data - np.min(data)\n        \n    return data","88dc58c2":"# 1. Non normalization\n\nimg = read_xray(str(sample_ids))\nplt.figure(figsize=(7,7))\nplt.imshow(img, 'gray')\nplt.show()","efdf35d3":"img = read_xray(str(sample_ids))\nimg = exposure.equalize_hist(img)\nplt.figure(figsize = (7,7))\nplt.imshow(img, 'gray')\nplt.show()","e52ded95":"img = read_xray(str(sample_ids))\nimg = exposure.equalize_adapthist(img\/np.max(img))\nplt.figure(figsize = (7,7))\nplt.imshow(img, 'gray')\nplt.show()","60e6be7c":"#[reference]\n#https:\/\/www.kaggle.com\/raddar\/popular-x-ray-image-normalization-techniques\n\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    \n    data = data - np.min(data)\n        \n    return data","19247133":"#Set Image Augumentation\nfrom torchvision import transforms\nimport albumentations\n\n#transforms.Grayscale(3)\n\ntransform=transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.Grayscale(3),\n        transforms.ToTensor(),\n        ]) ","135771a1":"# Resize Bounding Box\n\ndef resize(image, boxes, width, height):\n    # \u73fe\u5728\u306e\u9ad8\u3055\u3068\u5e45\u3092\u53d6\u5f97\u3057\u3066\u304a\u304f\n    c_height, c_width = image.shape[:2]\n    img = cv2.resize(image, (width, height))\n    \n    # \u5727\u7e2e\u3059\u308b\u6bd4\u7387(rate)\u3092\u8a08\u7b97\n    r_width = width \/ c_width\n    r_height = width \/ c_height\n    \n    # \u6bd4\u7387\u3092\u4f7f\u3063\u3066BoundingBox\u306e\u5ea7\u6a19\u3092\u4fee\u6b63\n    new_boxes = []\n    for box in boxes:\n        x,y,w,h=box\n        x = int(x * r_width)\n        y = int(y * r_height)\n        w = int(w * r_width)\n        h = int(h * r_height)\n        new_box =[x, y, w, h]\n        new_boxes.append(new_box)\n    return img, new_boxes","7d7cda54":"class My_Dataset(Dataset):\n    def __init__(self,df,):\n        \n        #dataframe\u3092\u683c\u7d0d\u3059\u308b\n        self.df = df\n        self.image_ids=df[\"image_id\"].unique()\n        self.image_dir=pathlib.\\\n                    Path(\"..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\")\n        #columns\u3092\u8a2d\u5b9a\u3059\u308b\n        self.box_col=[\"y_min\",\"y_min\",\"x_max\",\"y_max\"]\n        #transform\n        self.transform=transforms.Compose(\n            [\n            transforms.ToPILImage(),\n            transforms.Grayscale(3),\n            transforms.ToTensor(),\n            ]) \n\n    def __len__(self):\n        return len(self.image_ids)\n    \n    def __getitem__(self,index,transform=False):\n        \n        #train_data(dicom)\u3088\u308arandom\u3067dicom\u30c7\u30fc\u30bf\u3092\u53d6\u5f97\n        image_id=self.image_ids[index]\n        #print(image_id)\n        \n        #[dicom_data] #array\u306b\u5909\u63db\u3055\u308c\u3066\u51fa\u529b\n        image=read_xray(str(self.image_dir\/image_id)+\".dicom\")\n\n        #Histogram normalization(type:ndarray)\n        image = exposure.equalize_hist(image)\n        \n        \n        #-----bbox\u304c\u8907\u6570\u306e\u53ef\u80fd\u6027\u3042\u308a\u3001\u8907\u6570\u306e\u30c7\u30fc\u30bf\u3092\u53d6\u5f97\u3059\u308b\u5fc5\u8981\u3042\u308a\u3002-----\n        records = self.df[(self.df['image_id'] == image_id)]\n        records = records.reset_index(drop=True)\n        \n        if records.loc[0, \"class_id\"] == 0:\n            records = records.loc[[0], :]\n        #records = self.df.loc[self.df.image_id == img_path.split('.')[0],:].reset_index(drop = True)\n        \n        #-----bounding box-----\n        boxes = records[self.box_col].values.astype(np.float32)\n        #----area-----\n        #bbox:[x,y,w,h]\u3068\u3059\u308b\u3068\u3001(w-x)*(h-y)\u3067\u51fa\u529b\u3055\u308c\u308b\u3002\n        area = (boxes[:,2] - boxes[:,0]) * (boxes[:,3] - boxes[:,1])\n        area = area.astype(np.float32)\n        \n        #----labels-----\n        \"\"\"\n        0 - Aortic enlargement,1 - Atelectasis,2 - Calcification,3 - Cardiomegaly,4 - Consolidation,\n        5 - ILD,6 - Infiltration,7 - Lung Opacity,8 - Nodule\/Mass,9 - Other lesion,10 - Pleural effusion,\n        11 - Pleural thickening,12 - Pneumothorax,13 - Pulmonary fibrosis\n        15\u306b\u8a72\u5f53\u3059\u308b\u306e\u306fNone\u3063\u307d\u3044\n        \"\"\"\n        \n        labels = torch.tensor(records[\"class_id\"].values, dtype=torch.int64)\n        \n        # suppose all instances are not crowd\n        #iscrowd = torch.zeros((records.shape[0],), dtype=torch.int64)\n        \n        #\u5143\u306e\u753b\u50cf\u30c7\u30fc\u30bf\u306e\u753b\u50cf\u30b5\u30a4\u30ba\u3092\u53d6\u5f97\u3059\u308b\n        \n        #-----[target]:dict-----\n        target = {}\n        target['boxes'] = torch.tensor(boxes)\n        target['labels'] = labels\n        target['image_id'] = torch.tensor([index])\n        #target['area'] = torch.tensor(area)\n        #target['iscrowd'] = iscrowd\n        target[\"image_row_shape\"]=torch.tensor(image.shape)\n        target[\"dicom_id\"]=image_id\n        \n        #Transoformed Image\n        #transform\n        #image_transformed=self.transform(image.astype(np.float32))\n        \n        #width,height=[512,512]\u3067resize\u3059\u308b\n        width=512\n        height=512\n        image_resized,boxes_resized=resize(image,boxes,width, height)\n        #print(\"boxes_resized:\",boxes_resized)\n        target[\"boxes_resized\"]=torch.tensor(boxes_resized)\n        \n        #transform\n        image_transformed=self.transform(image_resized.astype(np.float32))\n        \n        return image_transformed, target","fd471a32":"def collate_fn(batch):\n    imgs, targets= list(zip(*batch))\n    imgs = torch.stack(imgs)\n    #torch.stack\u3092\u304b\u3051\u308b\u3068\u51fa\u529b\u3054\u3068\u306b\u7570\u306a\u308b\u305f\u3081\u3001torch.stack\u3067\u304d\u306a\u3044\n    #list or\u3000tupple\u3067\u8fd4\u305b\u3070\u3046\u307e\u304f\u3044\u304f\u3002\n    targets = list(targets)\n    #bc = torch.stack(bc)\n    return imgs,targets","f56a57e5":"train_dataset=My_Dataset(df=df)\ntrain_dataloader=DataLoader(train_dataset,\n                            batch_size=2,shuffle=True, \n                            collate_fn= collate_fn)\n\n# Output Sample\nimage,target =next(iter(train_dataloader))\nprint(\"------image-----\")\nprint(\"image_tensor:\",image.shape)\nprint(\"-----target-----\")\nprint(target[0])\nprint(target[1])","b97d4cbc":"def draw_boundingbox(target):\n    \n    #\u3068\u308a\u3042\u3048\u305a\u4e0a\u8a18\u307e\u3067\u53d6\u5f97\u3057\u3066\u304a\u3051\u3070\u826f\u3044\u304b\u3002\n    \n    #-----image-----\n    image_dir=pathlib.\\\n        Path(\"..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\")\n    image_id=target[\"dicom_id\"]\n    img=read_xray(str(image_dir\/image_id)+\".dicom\")\n    \n    #-----bounding box-----\n    bboxes=target[\"boxes\"].detach().numpy().astype(int)\n    #print(\"bounding_box:\\n\",bboxes)\n    print(\"bounding box:\",bboxes)\n        \n    #-----label name-----\n    labels=target[\"labels\"].detach().numpy()\n    print(\"label:\",labels)\n        \n    #Plot Image with Bounding Box\n    for bbox,label in zip(bboxes,labels):\n\n        x = int(bbox[0])\n        y = int(bbox[1])\n        w = int(bbox[2])\n        h = int(bbox[3])\n        color = (0,0,255)\n        \n        #label\u3092\u4ed8\u4e0e(string\u306b\u5909\u63db\u3059\u308b\u5fc5\u8981\u3042\u308a)\n        cv2.putText(img,str(label), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1.5, color, 3)\n        #cv2.rectangle\u306etupple\u306b\u306fint\u3092\u5165\u529b\u3059\u308b(float\u306f\u4e0d\u53ef)\n        cv2.rectangle(img, (x, y), (w, h), (255,0,0), 2)\n    \n    plt.figure(num=None, figsize=(5,5), dpi=80, facecolor='w', edgecolor='k')\n    plt.imshow(img,cmap=\"bone\")\n    plt.show()","39e7ec93":"for i in range(len(target)):\n    data=target[i]\n    draw_boundingbox(data)    ","46bd8a4b":"def draw_boundingbox_resized(target):\n    \n    #\u3068\u308a\u3042\u3048\u305a\u4e0a\u8a18\u307e\u3067\u53d6\u5f97\u3057\u3066\u304a\u3051\u3070\u826f\u3044\u304b\u3002\n    \n    #-----image-----\n    image_dir=pathlib.\\\n        Path(\"..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\")\n    image_id=target[\"dicom_id\"]\n    img=read_xray(str(image_dir\/image_id)+\".dicom\")\n    width,height=512,512\n    img=cv2.resize(img, (width, height))\n    \n    #-----bounding box-----\n    bboxes=target[\"boxes_resized\"].detach().numpy().astype(int)\n    #print(\"bounding_box:\\n\",bboxes)\n    print(\"bounding box:\",bboxes)\n        \n    #-----label name-----\n    labels=target[\"labels\"].detach().numpy()\n    print(\"label:\",labels)\n    #Plot Image with Bounding Box\n    for bbox,label in zip(bboxes,labels):\n\n        x = int(bbox[0])\n        y = int(bbox[1])\n        w = int(bbox[2])\n        h = int(bbox[3])\n        color = (0,0,255)\n        \n        #cv2.rectangle\u306etupple\u306b\u306fint\u3092\u5165\u529b\u3059\u308b(float\u306f\u4e0d\u53ef)\n        cv2.rectangle(img, (x, y), (w, h), (255,0,0), 1)\n        \n        #label\u3092\u4ed8\u4e0e(string\u306b\u5909\u63db\u3059\u308b\u5fc5\u8981\u3042\u308a)\n        cv2.putText(img,str(label), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1.5, color, 1)\n    \n    plt.figure(num=None, figsize=(5,5), dpi=80, facecolor='w', edgecolor='k')\n    plt.imshow(img,cmap=\"bone\")\n    plt.show()","d9b5ddb4":"for i in range(len(target)):\n    draw_boundingbox_resized(target[i])","9b6f5f0d":"# 4. dataframe\u306e\u6b20\u640d\u5024\u3092\u4fee\u6b63\n\n\n### class Name: No finding \u306f\u30c7\u30fc\u30bf\u306a\u3057\u306b\u8a72\u5f53\n\n>0 - Aortic enlargement\n1 - Atelectasis\n2 - Calcification\n3 - Cardiomegaly\n4 - Consolidation\n5 - ILD\n6 - Infiltration\n7 - Lung Opacity\n8 - Nodule\/Mass\n9 - Other lesion\n10 - Pleural effusion\n11 - Pleural thickening\n12 - Pneumothorax\n13 - Pulmonary fibrosis\n\n### No_finding\u306b\u8a72\u5f53\u3059\u308b\u306b\u306f15\u306b\u6307\u5b9a\u3059\u308b\u304b\n\n\n#### columns;x_min\ty_min\tx_max\ty_max\u306fNaN\u306b\u306a\u3063\u3066\u3044\u308b\u305f\u3081\u6b20\u640d\u5024\u88dc\u5b8c\u304c\u5fc5\u8981\n\n\n\n","d5736cc6":"# 3. Read DataFrame : Train Data","0b33078f":"# next: How to Use EfficientDet-pytorch...","f29d106f":"### [1] No-Normalization","46afe349":"###  6.2 Resize Image and BoundingBox","4b6ccd0a":"# 1. Import Packages\n","f5ede7d0":"### [2] Histogram normalization\nThe general idea is to make pixel distribution uniform. This makes X-rays appear a little darker. This generates view, which radiologist would not see in his standard workplace.\\\nSuch normalization is used in popular open-source X-ray datasets, such as CheXpert.","22dabc45":"# 2.Path","d2cb6006":"## 6.3 Sample Image with Bounding Box","0eecd57c":"## 6.4 resized_Image and Bounding Box","77ed4634":"### Dataloader\u3067\u51fa\u529b\u3059\u308b\u5834\u5408\n\n\u5404\u753b\u50cf\u3054\u3068\u306bbounding_box\u306e\u6570\u304c\u7570\u306a\u308b\u305f\u3081\u3001collate_fn\u3092\u5909\u66f4\u3059\u308b\u5fc5\u8981\u3042\u308a\u3002","6ba42a00":"### 6.1 Data Augmentation","26f52001":"# 5.1 Dicom Example","61fa6529":"## 6. Data Augmentation and DataSet\n\n>1. multi boudingbox\u306e\u51fa\u529b\u306b\u5bfe\u5fdc\u3059\u308b\u305f\u3081\u306b train_data\u306b\u3042\u308bimage_id\u3092\u307e\u305a\u53d6\u5f97\u3057\u3066\u3001\u305d\u306eID\u306b\u8a72\u5f53\u3059\u308bdataFrame\u30c7\u30fc\u30bf\u3092\u53d6\u5f97\u3059\u308b\u3002\n\n>2.target\u304c\u30de\u30eb\u30c1\u51fa\u529b\u306b\u306a\u308b\u305f\u3081\u3001dict\u5f62\u5f0f\u3067\u51fa\u529b\u3059\u308b\n\nreference\nhttps:\/\/www.kaggle.com\/pestipeti\/vinbigdata-fasterrcnn-pytorch-train","c377de1a":"### [3] CLAHE normalization\nThis method produces sharper images and is quite often used in chest X-ray research. This generates view, which radiologist would not see in his standard workplace. However, it closely resembles the \"bone-enhanced\" view in some X-rays done (usually due to broken ribs).\n\n","aec02380":"# 5.2 Normalize Dicom Image\n\n[reference]\nhttps:\/\/www.kaggle.com\/raddar\/popular-x-ray-image-normalization-techniques"}}