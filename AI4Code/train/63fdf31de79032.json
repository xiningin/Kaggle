{"cell_type":{"6574fdf2":"code","658af7b3":"code","bf2f315a":"code","154962f0":"code","79c99263":"code","938c145a":"code","12f2f17b":"code","38f2c759":"code","e0ed05e6":"code","f74debf7":"code","751b35e1":"code","8b3cff3f":"code","31ed6839":"code","e9db69e9":"code","69982317":"code","8f254f9b":"code","16925c77":"code","464a01de":"code","70b20b86":"code","679222e3":"code","9f178033":"code","49d738f3":"code","9e62f740":"code","14a9689e":"code","63f28e45":"code","e7ae9737":"code","9e1c5cea":"code","cfb2fda5":"code","702bc0ad":"code","5ade3824":"code","3e0f90c6":"code","4f9b0aaa":"code","3a6ae8c7":"code","fbf818f6":"code","fba91c6a":"code","08670719":"code","5e5d1325":"code","f2ed00a4":"code","3b868c90":"code","9876defb":"code","516ea684":"code","765c9938":"code","f5826796":"code","6ade253d":"code","450c8ee3":"code","2e61a932":"code","8ed73fd7":"code","e6e48bad":"code","8cea3692":"code","14ce3c46":"code","758b364d":"code","0a3c0929":"code","bef4e97c":"code","96cdecac":"code","1a2fcaac":"code","6b723780":"code","54f68963":"code","2455626d":"code","53b45b2e":"code","87c19b29":"code","1739131b":"code","ca942205":"code","18139dd3":"code","2b11f873":"code","44926613":"code","af9f1a45":"code","7379f097":"code","3268e994":"markdown","27d26e8d":"markdown","f7875608":"markdown","14e77bdf":"markdown","48595709":"markdown","da6339d0":"markdown","224ab49f":"markdown","0386bc07":"markdown","f148543f":"markdown","1c0e826d":"markdown","16709715":"markdown","0805a6bc":"markdown","742a0303":"markdown","c352d133":"markdown","7cd4c66c":"markdown","7d4a89c1":"markdown","0f90a85c":"markdown","6fd56e93":"markdown","5d0132a8":"markdown"},"source":{"6574fdf2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","658af7b3":"df_items=pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/items.csv')\ndf_items.head()","bf2f315a":"df_items.shape","154962f0":"df_item_Categories=pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\ndf_item_Categories.head()","79c99263":"df_item_Categories['item_category_id'].unique()","938c145a":"df_item_Categories.shape","12f2f17b":"df_sales_train=pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\ndf_sales_train.head()","38f2c759":"df_sales_train.shape","e0ed05e6":"df_shops=pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/shops.csv')\ndf_shops.head()","f74debf7":"df_shops.shape","751b35e1":"df_test=pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv')\ndf_test.head()","8b3cff3f":"df_test.shape","31ed6839":"#Merge the dataset df_items,df_items_categories on item_category_id\ndf_item=pd.merge(df_items,df_item_Categories,on='item_category_id',how='inner')\ndf_item.tail(12)","e9db69e9":"df_item.shape","69982317":"# Now merge 2 dataset df_sales_train,df_shops on shop_id\ndf_sales_train=pd.merge(df_sales_train,df_shops,on='shop_id',how='inner')\ndf_sales_train.head(12)","8f254f9b":"df_sales_train.shape","16925c77":"# item_cnt_day - number of products sold. You are predicting a monthly amount of this measure\n#item_price= current price of an item\n# item_price*item_cnt_day=tatal sales of particular item monthly\ndf_sales_train['total_Sales_monthly']=df_sales_train['item_price']*df_sales_train['item_cnt_day']\ndf_sales_train.head(5)","464a01de":"#Now we will merge df_sales_train,df_item on item_id\ndf_sales_train=pd.merge(df_sales_train,df_item,on='item_id',how='inner')\ndf_sales_train.head(7)","70b20b86":"df_sales_train.shape","679222e3":"df_sales_train.describe()","9f178033":"df_sales_train.info()","49d738f3":"df_sales_train['date']=pd.to_datetime(df_sales_train['date'],format='%d.%M.%Y')\ndf_sales_train.head(5)","9e62f740":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom statsmodels.tsa.holtwinters import SimpleExpSmoothing\nfrom sklearn.metrics import mean_squared_error\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.stattools import kpss\nfrom scipy.stats import boxcox\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX","14a9689e":"df_sales_train.columns","63f28e45":"#Find out the total income of each item_category in each shop\nitem_category_income=df_sales_train.groupby(['shop_id','item_category_id'])['total_Sales_monthly'].sum()\nitem_category_income.head(20)","e7ae9737":"top_items=df_sales_train.groupby(['item_category_id'],as_index = False)['item_cnt_day'].count()\ntop_items.sort_values(by=['item_cnt_day'],ascending=False,inplace=True)\ntop_items.head(10)","9e1c5cea":"#plot it on graph\nplt.figure(figsize=(20,8))\nsns.barplot(data=top_items,x='item_category_id',y='item_cnt_day')\nplt.xlabel('Item_Category_ID',fontsize=20)\nplt.ylabel('Item_Cnt_Day',fontsize=20)\nplt.title('Top Item Graph',fontsize=20)\nplt.show()","cfb2fda5":"df_sales_train.date[0],df_sales_train.date[-1:]","702bc0ad":"#Find out the month in which maximum sale\n# date_block_num - a consecutive month number, used for convenience. January 2013 is 0, February 2013 is 1,..., October 2015 is 33\nmonthly_sales=df_sales_train.groupby(['date_block_num'],as_index=False)['item_cnt_day'].sum()","5ade3824":"plt.figure(figsize=(20,8))\nsns.barplot(data=monthly_sales,x='date_block_num',y='item_cnt_day')\nplt.xlabel('Month',fontsize=20)\nplt.ylabel('Item_Cnt_Day',fontsize=20)\nplt.title('Monthly Sales Graph',fontsize=20)\nplt.show()","3e0f90c6":"# total Income of each shop\nShops_Monthly_income=df_sales_train.groupby(['shop_id'],as_index=False)['total_Sales_monthly'].sum()","4f9b0aaa":"plt.figure(figsize=(20,8))\nsns.barplot(data=Shops_Monthly_income,x='shop_id',y='total_Sales_monthly')\nplt.xlabel('Shop ID',fontsize=20)\nplt.ylabel('Income Monthly',fontsize=20)\nplt.title('Monthly Sales Graph',fontsize=20)\nplt.show()","3a6ae8c7":"Shops_Monthly_income.plot(figsize=(12,4))\nplt.title('Time series Plot')\nplt.legend(loc='best')\nplt.show()","fbf818f6":"#Let's See the income of shop_id=31 monthly wise\nshop31Monthly_Income=pd.DataFrame(df_sales_train[df_sales_train['shop_id']==31])\nshop31Monthly_Income.head()\nshop31Monthly_Income=shop31Monthly_Income.groupby(['date_block_num'],as_index=False)['total_Sales_monthly'].sum()\nshop31Monthly_Income","fba91c6a":"plt.figure(figsize=(20,8))\nsns.barplot(data=shop31Monthly_Income,x='date_block_num',y='total_Sales_monthly')\nplt.xlabel('Months',fontsize=20)\nplt.ylabel('Income Monthly',fontsize=20)\nplt.title('Monthly Sales Graph of Shop 31',fontsize=20)\nplt.show()","08670719":"shop31Monthly_Income.plot(figsize=(12, 4))\nplt.legend(loc='best')\nplt.title('Time Series Plot shop31')\nplt.show()","5e5d1325":"#  We have total 33 months\n#so, I split the data upto 25 months for training and remaining for Validation dataset\ntrain_len=25\ntrain_dataset=shop31Monthly_Income[:train_len]\ntest_dataset=shop31Monthly_Income[train_len:]","f2ed00a4":"#Check stationarity and seasonality of the model\nfrom statsmodels.tsa.stattools import adfuller\nadf_test = adfuller(shop31Monthly_Income['total_Sales_monthly'])\n\nprint('ADF Statistic: %f' % adf_test[0])\nprint('Critical Values @ 0.05: %.2f' % adf_test[4]['5%'])\nprint('p-value: %f' % adf_test[1])","3b868c90":"from statsmodels.tsa.stattools import kpss\nkpss_test = kpss(shop31Monthly_Income['total_Sales_monthly'])\n\nprint('KPSS Statistic: %f' % kpss_test[0])\nprint('Critical Values @ 0.05: %.2f' % kpss_test[3]['5%'])\nprint('p-value: %f' % kpss_test[1])\n","9876defb":"#Now make the data stationary\n# use either differencing or log transform\n# Differencing removes the trend present in the series \n# while log transformation is for handling high variance in the series.\n\n# So i will go for log transformation\ntrain_dataset['log_total_Sales_monthly'] = pd.Series(np.log(train_dataset['total_Sales_monthly']),index=train_dataset.index)\ntrain_dataset['log_total_Sales_monthly'] =pd.Series(train_dataset['log_total_Sales_monthly'] - train_dataset['log_total_Sales_monthly'].shift(1),index=train_dataset.index)\ntrain_dataset['log_total_Sales_monthly'].dropna().plot()\n","516ea684":"train_dataset['log_total_Sales_monthly']=train_dataset['log_total_Sales_monthly'].fillna(0)","765c9938":"# check for stationarity\nfrom statsmodels.tsa.stattools import adfuller\nadf_test = adfuller(train_dataset['log_total_Sales_monthly'])\n\nprint('ADF Statistic: %f' % adf_test[0])\nprint('Critical Values @ 0.05: %.2f' % adf_test[4]['5%'])\nprint('p-value: %f' % adf_test[1])","f5826796":"#Performing Box-cox transformation to get the data set stationary.\nfrom scipy.stats import boxcox\nshop_31_boxcox = pd.Series(boxcox(shop31Monthly_Income['total_Sales_monthly'], lmbda=0), index = shop31Monthly_Income.index)\n\nplt.figure(figsize=(12,4))\nplt.plot(shop_31_boxcox, label='After Box Cox tranformation')\nplt.legend(loc='best')\nplt.title('After Box Cox transform')\nplt.show()","6ade253d":"shop31_boxcox_diff = pd.Series(shop_31_boxcox - shop_31_boxcox.shift(), shop31Monthly_Income.index)\nplt.figure(figsize=(12,4))\nplt.plot(shop31_boxcox_diff, label='After Box Cox tranformation and differencing')\nplt.legend(loc='best')\nplt.title('After Box Cox transform and differencing')\nplt.show()","450c8ee3":"shop31_boxcox_diff.dropna(inplace=True)","2e61a932":"adf_test = adfuller(shop31_boxcox_diff)\n\nprint('ADF Statistic: %f' % adf_test[0])\nprint('Critical Values @ 0.05: %.2f' % adf_test[4]['5%'])\nprint('p-value: %f' % adf_test[1])","8ed73fd7":"from statsmodels.graphics.tsaplots import plot_acf\nplt.figure(figsize=(8,4))\nplot_acf(np.array(shop31Monthly_Income['total_Sales_monthly']),ax=plt.gca(),lags=15)\nplt.show()","e6e48bad":"plt.figure(figsize=(8,4))\nplot_pacf(shop31Monthly_Income[\"total_Sales_monthly\"], ax=plt.gca(), lags = 15)\nplt.show()","8cea3692":"shop31_boxcox_diff=pd.DataFrame(shop31_boxcox_diff,columns=['Values'])","14ce3c46":"#Our stationary dataset is obtained after boxcox implementation\n#  So divide the data into training and validation set\ntrain_shop31_boxcox_diff=shop31_boxcox_diff[:train_len-1]\ntest_shop31_boxcox_diff=shop31_boxcox_diff[train_len-1:]","758b364d":"test_shop31_boxcox_diff","0a3c0929":"pip install pmdarima","bef4e97c":"\n# import pmdarima as pm\nfrom pmdarima import auto_arima\nstepwise_fit=auto_arima(shop31_boxcox_diff,trace=True,supress_warnings=True)\nstepwise_fit.summary()","96cdecac":"# Best model:  ARIMA(0,0,0)(0,0,0)[0] \nmodel=ARIMA(train_shop31_boxcox_diff['Values'],order=(1,0,1))","1a2fcaac":"model=model.fit()\nmodel.summary()","6b723780":"y_pred=shop31_boxcox_diff.copy()\ny_pred['ARIMA_Pred_boxcox_diff']=model.predict(shop31_boxcox_diff.index.min(),shop31_boxcox_diff.index.max())\ny_pred['ARIMA_Pred_boxCox']=y_pred['ARIMA_Pred_boxcox_diff'].cumsum()\ny_pred['ARIMA_Pred_boxCox']=y_pred['ARIMA_Pred_boxCox'].add(shop_31_boxcox[0])\ny_pred['ARIMA_pred']=np.exp(y_pred['ARIMA_Pred_boxCox'])","54f68963":"plt.figure(figsize=(12,4))\nplt.plot(train_dataset['total_Sales_monthly'], label='Train')\nplt.plot(test_dataset['total_Sales_monthly'], label='Test')\nplt.plot(y_pred['ARIMA_pred'][test_dataset.index.min():], label='Auto regression forecast')\nplt.legend(loc='best')\nplt.title('Auto Regression I.M.A. Method')\nplt.show()","2455626d":"y_pred","53b45b2e":"rmse = np.sqrt(mean_squared_error(test_dataset['total_Sales_monthly'], y_pred['ARIMA_pred'][test_dataset.index])).round(2)\nrmse","87c19b29":"#Moving Average\nmodel_av = ARIMA(train_shop31_boxcox_diff, order=(0, 0, 1)) \nmodel_fit = model_av.fit()\nprint(model_fit.params)","1739131b":"y_pred=shop31_boxcox_diff.copy()\ny_pred['MA_Pred_boxcox_diff']=model_fit.predict(shop31_boxcox_diff.index.min(),shop31_boxcox_diff.index.max())\ny_pred['MA_Pred_boxCox']=y_pred['MA_Pred_boxcox_diff'].cumsum()\ny_pred['MA_Pred_boxCox']=y_pred['MA_Pred_boxCox'].add(shop_31_boxcox[0])\ny_pred['MA_pred']=np.exp(y_pred['MA_Pred_boxCox'])","ca942205":"# y_pred\nrmse = np.sqrt(mean_squared_error(test_dataset['total_Sales_monthly'], y_pred['MA_pred'][test_dataset.index])).round(2)\nrmse","18139dd3":"plt.figure(figsize=(8,4))\nplt.plot(train_dataset['total_Sales_monthly'], label='Train')\nplt.plot(test_dataset['total_Sales_monthly'], label='Test')\nplt.plot(y_pred['MA_pred'][test_dataset.index.min():], label='MA forecast')\nplt.legend(loc='best')\nplt.title('M.A. Method')\nplt.show()","2b11f873":"model = SARIMAX(train_shop31_boxcox_diff, order=(1, 0, 1), seasonal_order=(1, 0, 1, 15)) \nmodel_fit = model.fit()\nprint(model_fit.params)","44926613":"y_hat_sarima = shop31_boxcox_diff.copy()\ny_hat_sarima['sarima_forecast_boxcox'] = model_fit.predict(shop31_boxcox_diff.index.min(), shop31_boxcox_diff.index.max())\ny_hat_sarima['sarima_forecast'] = np.exp(y_hat_sarima['sarima_forecast_boxcox'])","af9f1a45":"# y_hat_sarima\nplt.figure(figsize=(12,4))\nplt.plot(train_dataset['total_Sales_monthly'], label='Train')\nplt.plot(test_dataset['total_Sales_monthly'], label='Test')\nplt.plot(y_hat_sarima['sarima_forecast'][test_dataset.index.min():], label='SARIMA forecast')\nplt.legend(loc='best')\nplt.title('Seasonal autoregressive integrated moving average (SARIMA) method')\nplt.show()","7379f097":"rmse = np.sqrt(mean_squared_error(test_dataset['total_Sales_monthly'], y_hat_sarima['sarima_forecast'][test_dataset.index])).round(2)\nrmse","3268e994":"# ARIMA model","27d26e8d":"**11th month have maximum sale**","f7875608":"**Now the DataSet is ready to Analyse**","14e77bdf":"**p value>0.05 - Non-Stationary**","48595709":"**All the correlation value from 1 to 24 lies beyond shaded reason ,so we will not take it into effect**","da6339d0":"**EDA part is over**\n\n**Now coming to training of Data**","224ab49f":"**Above given data is daily historical sales data of one of the largest Russian software firms - 1C Company.**\n\n**The task is to forecast the total amount of products sold in every shop for the test set.We are trying to predict total sales for every product and store in the next month by applying time series algorithm.**","0386bc07":"**Shop id - 31 have maximum Income**","f148543f":"**Item_category_id=40 have maximum sale**","1c0e826d":"**Date is of object data type . Convert it to DateTime data type **","16709715":"**Order =1 for Moving Average,According to above graph**","0805a6bc":"**Now try different different model for predicting the Monthly Price**","742a0303":"**Order=1 for AR model ,According to above graph**","c352d133":"# SARIMAX","7cd4c66c":"**p-value <0.05 ,then Non-Stationary**","7d4a89c1":"**Now the data becomes Stationary**","0f90a85c":"**it means all the id's are unique**","6fd56e93":"**Metrics function that i will use to evaluate the model is RMSE**","5d0132a8":"# Boxcox transformation"}}