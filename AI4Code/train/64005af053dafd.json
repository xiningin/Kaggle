{"cell_type":{"51221453":"code","a43162a0":"code","ed04815c":"code","a484fbb8":"code","d7162652":"code","3cc04768":"code","d16d9ca1":"code","05113a5a":"code","7f3f496d":"code","a5ad175a":"code","3d99a55c":"code","7e22db63":"code","0131598c":"code","5e26c36d":"code","9e2a6d97":"code","5466bee4":"code","7f3b3042":"code","aa7d25ce":"code","a40f7007":"code","93ea648f":"code","40efa1c4":"code","13c36844":"code","7e0ad0a9":"code","1f869e19":"code","4743a507":"markdown","17530c43":"markdown","60d41057":"markdown","f7af1fc0":"markdown","b1decada":"markdown","0312428a":"markdown","92e54dbb":"markdown","e5ef1887":"markdown","192e4056":"markdown","1d043cdd":"markdown","ea2f4651":"markdown","ca7b720a":"markdown","02b37859":"markdown"},"source":{"51221453":"import os\nimport copy\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import OneCycleLR\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\nplt.style.use('ggplot')\n\ndevice = (\"cuda\" if torch.cuda.is_available() else \"cpu\")","a43162a0":"train_file = os.path.join('..\/input\/gtsrb-german-traffic-sign\/Train.csv')\ntest_file = os.path.join('..\/input\/gtsrb-german-traffic-sign\/Test.csv')","ed04815c":"df_train = pd.read_csv(train_file)\ndf_train.head()","a484fbb8":"df_test = pd.read_csv(test_file)\ndf_test.head()","d7162652":"print(f'Train csv shape: {df_train.shape} \\nTest csv shape: {df_test.shape}')","3cc04768":"c = df_train['ClassId'].nunique()\nx = df_train['ClassId'].value_counts()\n\nplt.bar(x=x.index.sort_values(), height=x, color='#0066ff')\nplt.title('Numbers of sample in each class', color='black')\nplt.xlabel(\"Classes\", color='black')\nplt.ylabel(\"Samples\", color='black')\nplt.tick_params(colors='black')","d16d9ca1":"class GTSRBDataset(Dataset):\n    def __init__(self, image_info, target_shape=(32, 32)):\n        self.target_height = target_shape[0]\n        self.target_width = target_shape[1]\n\n        # read data \n        self.images_path, self.labels, self.nSample = self.read_label_data(image_info)\n\n    def read_label_data(self, image_info):\n        # load labels data\n        images_path = []\n        labels = []\n        number_data = 0\n        \n        # read label data from csv file\n        image_data = pd.read_csv(image_info)\n        \n        for index, data in image_data.iterrows():\n            images_path.append('..\/input\/gtsrb-german-traffic-sign\/' + data['Path'])\n            labels.append(data['ClassId'])\n            number_data += 1\n        \n        return images_path, labels, number_data\n\n    def read_image(self, img_path):\n        \n        img = cv2.imread(img_path)\n        img = cv2.resize(img, (self.target_width, self.target_height), cv2.INTER_CUBIC)\n        img = img.transpose(2, 0, 1)\n        img = img \/ 255.0\n\n        return img\n\n    def __getitem__(self, idx):\n        img_path = self.images_path[idx]\n        label = self.labels[idx]\n        img = self.read_image(img_path)\n\n        return (img, label)\n\n    def __len__(self):\n        return self.nSample\n\n    def visualize_random_images(self, nb_row=2, nb_col=3):\n        fig, axes = plt.subplots(nb_row,nb_col, figsize=(18, 18))\n\n        for i,ax in enumerate(axes.flat):\n            r = np.random.randint(self.nSample)\n            img = cv2.imread(self.images_path[r])\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            ax.imshow(img)\n            ax.grid(False)\n            ax.axis('off')\n            ax.set_title('Label: '+ str(self.labels[r]))\n\n\nclass Collator(object):\n    def __call__(self, batch):\n        images = []\n        labels = []\n\n        for sample in batch:\n            img, label = sample\n            \n            if img is None:\n                continue\n            images.append(img)\n            labels.append(label)\n\n        return torch.FloatTensor(images), torch.LongTensor(labels)","05113a5a":"dataset = GTSRBDataset(image_info='..\/input\/gtsrb-german-traffic-sign\/Train.csv', target_shape=(32, 32))\nnb_classes = len(np.unique(dataset.labels))\nprint('The number of data: {} \\nThe number of classes: {}'.format(len(dataset), nb_classes))","7f3f496d":"split_ratio = 0.8\nn_train = int(len(dataset) * split_ratio)\nn_val = len(dataset) - n_train\ntrain_dataset, val_dataset = random_split(dataset, [n_train, n_val])\n\nprint(\"The number of train data: \", len(train_dataset))\nprint(\"The number of val data: \", len(val_dataset))","a5ad175a":"# Create se_block\nclass SEBlock(nn.Module):\n\n    def __init__(self, input_channels, internal_neurons):\n        super(SEBlock, self).__init__()\n        self.down = nn.Conv2d(in_channels=input_channels, out_channels=internal_neurons, kernel_size=1, stride=1, bias=True)\n        self.up = nn.Conv2d(in_channels=internal_neurons, out_channels=input_channels, kernel_size=1, stride=1, bias=True)\n        self.input_channels = input_channels\n\n    def forward(self, inputs):\n        x = F.avg_pool2d(inputs, kernel_size=inputs.size(3))\n        x = self.down(x)\n        x = F.relu(x)\n        x = self.up(x)\n        x = torch.sigmoid(x)\n        x = x.view(-1, self.input_channels, 1, 1)\n        \n        return inputs * x","3d99a55c":"# Create repvgg_block\ndef conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n    result = nn.Sequential()\n    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n    return result\n\nclass RepVGGBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size,\n                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', deploy=False, use_se=False):\n        super(RepVGGBlock, self).__init__()\n        self.deploy = deploy\n        self.groups = groups\n        self.in_channels = in_channels\n\n        assert kernel_size == 3\n        assert padding == 1\n\n        padding_11 = padding - kernel_size \/\/ 2\n\n        self.nonlinearity = nn.ReLU()\n\n        if use_se:\n            self.se = SEBlock(out_channels, internal_neurons=out_channels \/\/ 16)\n        else:\n            self.se = nn.Identity()\n\n        if deploy:\n            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)\n\n        else:\n            self.rbr_identity = nn.BatchNorm2d(num_features=in_channels) if out_channels == in_channels and stride == 1 else None\n            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n            # print('RepVGG Block, identity = ', self.rbr_identity)\n\n\n    def forward(self, inputs):\n        if hasattr(self, 'rbr_reparam'):\n            return self.nonlinearity(self.se(self.rbr_reparam(inputs)))\n\n        if self.rbr_identity is None:\n            id_out = 0\n        else:\n            id_out = self.rbr_identity(inputs)\n\n        return self.nonlinearity(self.se(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out))\n\n    def get_equivalent_kernel_bias(self):\n        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n\n    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n        if kernel1x1 is None:\n            return 0\n        else:\n            return torch.nn.functional.pad(kernel1x1, [1,1,1,1])\n\n\n    def _fuse_bn_tensor(self, branch):\n        if branch is None:\n            return 0, 0\n\n        if isinstance(branch, nn.Sequential):\n            kernel = branch.conv.weight\n            running_mean = branch.bn.running_mean\n            running_var = branch.bn.running_var\n            gamma = branch.bn.weight\n            beta = branch.bn.bias\n            eps = branch.bn.eps\n        else:\n            assert isinstance(branch, nn.BatchNorm2d)\n            if not hasattr(self, 'id_tensor'):\n                input_dim = self.in_channels \/\/ self.groups\n                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)\n                for i in range(self.in_channels):\n                    kernel_value[i, i % input_dim, 1, 1] = 1\n                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n            kernel = self.id_tensor\n            running_mean = branch.running_mean\n            running_var = branch.running_var\n            gamma = branch.weight\n            beta = branch.bias\n            eps = branch.eps\n            \n        std = (running_var + eps).sqrt()\n        t = (gamma \/ std).reshape(-1, 1, 1, 1)\n        return kernel * t, beta - running_mean * gamma \/ std\n\n    def switch_to_deploy(self):\n        if hasattr(self, 'rbr_reparam'):\n            return\n        kernel, bias = self.get_equivalent_kernel_bias()\n        self.rbr_reparam = nn.Conv2d(in_channels=self.rbr_dense.conv.in_channels, out_channels=self.rbr_dense.conv.out_channels,\n                                     kernel_size=self.rbr_dense.conv.kernel_size, stride=self.rbr_dense.conv.stride,\n                                     padding=self.rbr_dense.conv.padding, dilation=self.rbr_dense.conv.dilation, groups=self.rbr_dense.conv.groups, bias=True)\n        self.rbr_reparam.weight.data = kernel\n        self.rbr_reparam.bias.data = bias\n        for para in self.parameters():\n            para.detach_()\n        self.__delattr__('rbr_dense')\n        self.__delattr__('rbr_1x1')\n        if hasattr(self, 'rbr_identity'):\n            self.__delattr__('rbr_identity')","7e22db63":"# Create repvgg model\nclass RepVGG(nn.Module):\n\n    def __init__(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False, use_se=False):\n        super(RepVGG, self).__init__()\n\n        assert len(width_multiplier) == 4\n\n        self.deploy = deploy\n        self.override_groups_map = override_groups_map or dict()\n        self.use_se = use_se\n\n        assert 0 not in self.override_groups_map\n\n        self.in_planes = min(64, int(64 * width_multiplier[0]))\n\n        self.stage0 = RepVGGBlock(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=2, padding=1, deploy=self.deploy, use_se=self.use_se)\n        self.cur_layer_idx = 1\n        self.stage1 = self._make_stage(int(64 * width_multiplier[0]), num_blocks[0], stride=2)\n        self.stage2 = self._make_stage(int(128 * width_multiplier[1]), num_blocks[1], stride=2)\n        self.stage3 = self._make_stage(int(256 * width_multiplier[2]), num_blocks[2], stride=2)\n        self.stage4 = self._make_stage(int(512 * width_multiplier[3]), num_blocks[3], stride=2)\n        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n        self.linear = nn.Linear(int(512 * width_multiplier[3]), num_classes)\n\n\n    def _make_stage(self, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        blocks = []\n        for stride in strides:\n            cur_groups = self.override_groups_map.get(self.cur_layer_idx, 1)\n            blocks.append(RepVGGBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n                                      stride=stride, padding=1, groups=cur_groups, deploy=self.deploy, use_se=self.use_se))\n            self.in_planes = planes\n            self.cur_layer_idx += 1\n        return nn.Sequential(*blocks)\n\n    def forward(self, x):\n        out = self.stage0(x)\n        out = self.stage1(out)\n        out = self.stage2(out)\n        out = self.stage3(out)\n        out = self.stage4(out)\n        out = self.gap(out)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n\n        return out\n\ndef create_RepVGG_A0(num_classes, deploy=False):\n    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=num_classes, width_multiplier=[0.75, 0.75, 0.75, 2.5], override_groups_map=None, deploy=deploy)","0131598c":"repvgg_model = create_RepVGG_A0(num_classes=nb_classes)\nrepvgg_model = repvgg_model.to(device)","5e26c36d":"batch_size = 128\nvalid_every = 2000\nprint_every = 500\nlr = 0.001\nnum_iters = 12000","9e2a6d97":"train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=Collator(), shuffle=True, num_workers=2, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=Collator(), shuffle=False, num_workers=2, pin_memory=True, drop_last=True)\ndata_iter = iter(train_loader)","5466bee4":"criterion = nn.CrossEntropyLoss()\noptimizer = AdamW(repvgg_model.parameters(), lr=lr, betas=(0.9, 0.98), eps=1e-09)\nscheduler = OneCycleLR(optimizer, max_lr=lr, total_steps=num_iters, pct_start=0.1)","7f3b3042":"def batch_to_device(images, gts):\n    images = images.to(device, non_blocking=True)\n    gts = gts.to(device, non_blocking=True)\n    \n    return images, gts","aa7d25ce":"def cal_acc(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))","a40f7007":"def validate():\n    repvgg_model.eval()\n    total_loss = []\n    total_acc = []\n    \n    with torch.no_grad():\n        for batch in val_loader:\n            images, gts = batch\n            images, gts = batch_to_device(images, gts)\n            outputs = repvgg_model(images)\n            loss = criterion(outputs, gts)\n            acc = cal_acc(outputs, gts)\n            \n            total_loss.append(loss.item())\n            total_acc.append(acc)\n            \n            del outputs\n            del loss\n            \n    val_loss = np.mean(total_loss)\n    val_acc = np.mean(total_acc)\n    repvgg_model.train()\n    \n    return val_loss, val_acc","93ea648f":"def train_step(batch):\n    # get the inputs\n    images, gts = batch\n    images, gts = batch_to_device(images, gts)\n\n    # zero the parameter gradients\n    optimizer.zero_grad()\n\n    # forward + backward + optimize + scheduler\n    outputs = repvgg_model(images)\n    loss = criterion(outputs, gts)\n    loss.backward()\n    torch.nn.utils.clip_grad_norm_(repvgg_model.parameters(), 1) \n    optimizer.step()\n    scheduler.step()\n\n    loss_item = loss.item()\n    \n    return loss_item","40efa1c4":"total_loss = 0\nbest_acc = 0\nglobal_step = 0\nweight_path = 'repvgg.pth.tar'\n\ntorch.backends.cudnn.benchmark = True\n\nfor i in range(num_iters):\n    repvgg_model.train()\n    \n    try:\n        batch = next(data_iter)\n    except StopIteration:\n        data_iter = iter(train_loader)\n        batch = next(data_iter)\n        \n    global_step += 1\n    loss = train_step(batch)\n    total_loss += loss\n\n    if global_step % print_every == 0:\n        print('step: {:06d}, train_loss: {:.4f}'.format(global_step, total_loss \/ print_every))\n        total_loss = 0\n        \n    if global_step % valid_every == 0:\n        # validate \n        val_loss, val_acc = validate()\n        \n        if val_acc > best_acc:\n            best_acc = val_acc\n            torch.save(repvgg_model.state_dict(), weight_path)\n            \n        print(\"==============================================================================\")\n        print(\"val_loss: {:.4f}, val_acc: {:.4f}\".format(val_loss, val_acc))\n        print(\"==============================================================================\")","13c36844":"def repvgg_model_convert(model:torch.nn.Module, save_path=None, do_copy=True):\n    if do_copy:\n        model = copy.deepcopy(model)\n    for module in model.modules():\n        if hasattr(module, 'switch_to_deploy'):\n            module.switch_to_deploy()\n    if save_path is not None:\n        torch.save(model.state_dict(), save_path)\n    return model\n    \n    \n# weight path\nweight_path = 'repvgg.pth.tar'\nconvert_weight_path = 'convert_weight_path.pth.tar'\n\n# create model\nrepvgg_model = create_RepVGG_A0(num_classes=43)\nrepvgg_model.load_state_dict(torch.load(weight_path, map_location=device), strict=False)\n\n# convert multi branch model to single branch model\nconvert_model = repvgg_model_convert(repvgg_model, save_path=convert_weight_path)\nconvert_model = convert_model.to(device)","7e0ad0a9":"def predict(model, images, device):\n    images = images.to(device, non_blocking=True)\n    outputs = model(images)\n    _, preds = torch.max(outputs, dim=1)\n    \n    return preds","1f869e19":"# Number of image predict true\nlst_wrong_img = []\ntp = 0\n\nfor index, data in df_test.iterrows():\n    img = cv2.imread('..\/input\/gtsrb-german-traffic-sign\/' + data['Path'])\n    \n    preprocess_img = cv2.resize(img, (32, 32), cv2.INTER_AREA)\n    preprocess_img = preprocess_img.transpose(2, 0, 1)\n    preprocess_img = preprocess_img \/ 255.0\n    preprocess_img = np.expand_dims(preprocess_img, axis=0)\n    preprocess_img = torch.FloatTensor(preprocess_img)\n    \n    output = predict(convert_model, preprocess_img, device)\n    output = output.cpu().detach().numpy()\n    \n    if(int(output[0]) == data['ClassId']):\n        tp += 1\n    else:\n        lst_wrong_img.append([data['Path'], data['ClassId'], int(output[0])])\n\ndf = pd.DataFrame(lst_wrong_img, columns = ['Path', 'ClassId', 'Predict'])\ndf.to_csv('list_wrong_imgs.csv', index=False)\n\nprint(\"Accuracy in test dataset: \", float(tp\/df_test.shape[0])*100)","4743a507":"## Create model","17530c43":"## Check model in test dataset","60d41057":"## Data distribution\nDisplaying a bar chart which shows the sample of class occurences within the dataset.","f7af1fc0":"## Define a loss function and optimizer","b1decada":"## Create dataloader for loading data","0312428a":"## Data\nLoad the csv files and view some of the data","92e54dbb":"## Define config","e5ef1887":"## Train model","192e4056":"## Convert the training-time models into inference-time","1d043cdd":"## Import lib","ea2f4651":"## Custom Dataset\nCreate a custom dataset class with the proper methods for importing the data","ca7b720a":"## Create Dataset","02b37859":"## Split train and val dataloader"}}