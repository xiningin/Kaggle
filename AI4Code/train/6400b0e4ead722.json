{"cell_type":{"972b8b66":"code","73a29c62":"code","39877770":"code","a2931d78":"code","add7748f":"code","813aa848":"code","49007fb9":"code","3fa3684c":"code","fd497841":"code","3ed82b3b":"code","41e6bbc5":"code","8db73151":"code","5c1c7559":"code","1bbcccd8":"code","5bdf2b76":"code","72fe8b7e":"code","9109370a":"code","e9d0f81a":"code","078558a9":"code","0fca77a2":"code","f1dd1cca":"code","f1b0fa94":"code","8fbc8323":"code","ffc06d03":"code","30417212":"code","14533197":"code","686597a7":"markdown","a3ab6a93":"markdown","115fdd48":"markdown"},"source":{"972b8b66":"DEBUG = False","73a29c62":"import os\nimport sys\nsys.path = [\n    '..\/input\/efficientnet-pytorch\/EfficientNet-PyTorch\/EfficientNet-PyTorch-master',\n] + sys.path","39877770":"import skimage.io\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom efficientnet_pytorch import model as enet\n\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook as tqdm\n","a2931d78":"data_dir = '..\/input\/prostate-cancer-grade-assessment'\ndf_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\ndf_test = pd.read_csv(os.path.join(data_dir, 'test.csv'))\ndf_sub = pd.read_csv(os.path.join(data_dir, 'sample_submission.csv'))\n\nmodel_dir = '..\/input\/panda-public-models'\nimage_folder = os.path.join(data_dir, 'test_images')\nis_test = os.path.exists(image_folder)  # IF test_images is not exists, we will use some train images.\nimage_folder = image_folder if is_test else os.path.join(data_dir, 'train_images')\n\ndf = df_test if is_test else df_train.loc[:10]\n\ntile_size = 256\nimage_size = 256\nn_tiles = 36\nbatch_size = 8\nnum_workers = 4\n\ndevice = torch.device('cuda')\nprint(image_folder)\n","add7748f":"class enetv2(nn.Module):\n    def __init__(self, backbone, out_dim):\n        super(enetv2, self).__init__()\n        self.enet = enet.EfficientNet.from_name(backbone)\n        self.myfc = nn.Linear(self.enet._fc.in_features, out_dim)\n        self.enet._fc = nn.Identity()\n\n    def extract(self, x):\n        return self.enet(x)\n\n    def forward(self, x):\n        x = self.extract(x)\n        x = self.myfc(x)\n        return x\n    \n    \ndef load_models(model_files):\n    models = []\n    for model_f in model_files:\n        model_f = os.path.join(model_dir, model_f)\n        backbone = 'efficientnet-b0'\n        model = enetv2(backbone, out_dim=5)\n        model.load_state_dict(torch.load(model_f, map_location=lambda storage, loc: storage), strict=True)\n        model.eval()\n        model.to(device)\n        models.append(model)\n        print(f'{model_f} loaded!')\n    return models\n\n\nmodel_files = [\n    'cls_effnet_b0_Rand36r36tiles256_big_bce_lr0.3_augx2_30epo_model_fold0.pth'\n]\n\nmodels = load_models(model_files)\n\n\n\nmodel_dir2 = '..\/input\/pandaenetb042x256x256x3'\ndef load_models2(model_files):\n    models = []\n    for model_f in model_files:\n        model_f = os.path.join(model_dir2, model_f)\n        backbone = 'efficientnet-b1'\n        model = enetv2(backbone, out_dim=5)\n        model.load_state_dict(torch.load(model_f, map_location=lambda storage, loc: storage), strict=True)\n        model.eval()\n        model.to(device)\n        models.append(model)\n        print(f'{model_f} loaded!')\n    return models\n\n\nmodel_files2 = [\n    'enet_b1_8ep_fold0.pth'\n]\n\nmodels2 = load_models2(model_files2)","813aa848":"def get_tiles(img, mode=0):\n        result = []\n        h, w, c = img.shape\n        pad_h = (tile_size - h % tile_size) % tile_size + ((tile_size * mode) \/\/ 2)\n        pad_w = (tile_size - w % tile_size) % tile_size + ((tile_size * mode) \/\/ 2)\n\n        img2 = np.pad(img,[[pad_h \/\/ 2, pad_h - pad_h \/\/ 2], [pad_w \/\/ 2,pad_w - pad_w\/\/2], [0,0]], constant_values=255)\n        img3 = img2.reshape(\n            img2.shape[0] \/\/ tile_size,\n            tile_size,\n            img2.shape[1] \/\/ tile_size,\n            tile_size,\n            3\n        )\n\n        img3 = img3.transpose(0,2,1,3,4).reshape(-1, tile_size, tile_size,3)\n        n_tiles_with_info = (img3.reshape(img3.shape[0],-1).sum(1) < tile_size ** 2 * 3 * 255).sum()\n        if len(img) < n_tiles:\n            img3 = np.pad(img3,[[0,n_tiles-len(img3)],[0,0],[0,0],[0,0]], constant_values=255)\n        idxs = np.argsort(img3.reshape(img3.shape[0],-1).sum(-1))[:n_tiles]\n        img3 = img3[idxs]\n        for i in range(len(img3)):\n            result.append({'img':img3[i], 'idx':i})\n        return result, n_tiles_with_info >= n_tiles\n\n\nclass PANDADataset(Dataset):\n    def __init__(self,\n                 df,\n                 image_size,\n                 n_tiles=n_tiles,\n                 tile_mode=0,\n                 rand=False,\n                 sub_imgs=False,\n                 transform=None\n                ):\n\n        self.df = df.reset_index(drop=True)\n        self.image_size = image_size\n        self.n_tiles = n_tiles\n        self.tile_mode = tile_mode\n        self.rand = rand\n        self.sub_imgs = sub_imgs\n        self.transform = transform\n\n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        img_id = row.image_id\n        \n        tiff_file = os.path.join(image_folder, f'{img_id}.tiff')\n        image = skimage.io.MultiImage(tiff_file)[1]\n        tiles, OK = get_tiles(image, self.tile_mode)\n\n        if self.rand:\n            idxes = np.random.choice(list(range(self.n_tiles)), self.n_tiles, replace=False)\n        else:\n            idxes = list(range(self.n_tiles))\n        idxes = np.asarray(idxes) + self.n_tiles if self.sub_imgs else idxes\n\n        n_row_tiles = int(np.sqrt(self.n_tiles))\n        images = np.zeros((image_size * n_row_tiles, image_size * n_row_tiles, 3))\n        for h in range(n_row_tiles):\n            for w in range(n_row_tiles):\n                i = h * n_row_tiles + w\n    \n                if len(tiles) > idxes[i]:\n                    this_img = tiles[idxes[i]]['img']\n                else:\n                    this_img = np.ones((self.image_size, self.image_size, 3)).astype(np.uint8) * 255\n                this_img = 255 - this_img\n                h1 = h * image_size\n                w1 = w * image_size\n                images[h1:h1+image_size, w1:w1+image_size] = this_img\n\n        if self.transform is not None:\n            images = self.transform(image=images)['image']\n            \n        images = images.astype(np.float32)\n        images \/= 255\n        images = images.transpose(2, 0, 1)\n\n        return torch.tensor(images)\n","49007fb9":"if not is_test:\n    dataset_show = PANDADataset(df, image_size, n_tiles, 0)\n    from pylab import rcParams\n    rcParams['figure.figsize'] = 20,10\n    for i in range(2):\n        f, axarr = plt.subplots(1,5)\n        for p in range(5):\n            idx = np.random.randint(0, len(dataset_show))\n            img = dataset_show[idx]\n            axarr[p].imshow(1. - img.transpose(0, 1).transpose(1,2).squeeze())\n            axarr[p].set_title(str(idx))","3fa3684c":"import albumentations\n\ntransforms_train = albumentations.Compose([\n    albumentations.Transpose(p=0.5),\n    albumentations.VerticalFlip(p=0.5),\n    albumentations.HorizontalFlip(p=0.5),\n])\n\n\ntransforms_val = albumentations.Compose([])\n\ntransforms_val1 = albumentations.Compose([\n    albumentations.Transpose(p=1)\n])\n\ntransforms_val2 = albumentations.Compose([\n    albumentations.VerticalFlip(p=1)\n])\n\ntransforms_val3= albumentations.Compose([\n    albumentations.HorizontalFlip(p=1),\n])\n\ntransforms_val4= albumentations.Compose([\n    albumentations.Transpose(p=1),\n    albumentations.VerticalFlip(p=1),\n    albumentations.HorizontalFlip(p=1),\n])","fd497841":"\ndataset = PANDADataset(df, image_size, n_tiles, 0, False, False, transforms_val )  # mode == 0\nloader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n\ndataset2 = PANDADataset(df, image_size, n_tiles, 2, False, False, transforms_val )  # mode == 2\nloader2 = DataLoader(dataset2, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n\n\nLOGITS = []\nLOGITS2 = []\nLOGITS3 = []\nLOGITS4 = []\nwith torch.no_grad():\n    for data in tqdm(loader):\n        data = data.to(device)\n        logits = models[0](data)\n        LOGITS.append(logits)\n        logits = models2[0](data)\n        LOGITS3.append(logits)\n        \n    for data in tqdm(loader2):\n        data = data.to(device)\n        logits = models[0](data)\n        LOGITS2.append(logits)\n        logits = models2[0](data)\n        LOGITS4.append(logits)\n        \nLOGITS = (torch.cat(LOGITS).sigmoid().cpu()+torch.cat(LOGITS2).sigmoid().cpu()+torch.cat(LOGITS3).sigmoid().cpu()+torch.cat(LOGITS4).sigmoid().cpu()) \/ 4\nPREDS = LOGITS.sum(1).numpy()\n\n","3ed82b3b":"\ndataset = PANDADataset(df, image_size, n_tiles, 0, False, False, transforms_val1 )  # mode == 0\nloader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n\ndataset2 = PANDADataset(df, image_size, n_tiles, 2, False, False, transforms_val1 )  # mode == 2\nloader2 = DataLoader(dataset2, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n\n\nLOGITS = []\nLOGITS2 = []\nLOGITS3 = []\nLOGITS4 = []\nwith torch.no_grad():\n    for data in tqdm(loader):\n        data = data.to(device)\n        logits = models[0](data)\n        LOGITS.append(logits)\n        logits = models2[0](data)\n        LOGITS3.append(logits)\n        \n    for data in tqdm(loader2):\n        data = data.to(device)\n        logits = models[0](data)\n        LOGITS2.append(logits)\n        logits = models2[0](data)\n        LOGITS4.append(logits)\n        \nLOGITS = (torch.cat(LOGITS).sigmoid().cpu()+torch.cat(LOGITS2).sigmoid().cpu()+torch.cat(LOGITS3).sigmoid().cpu()+torch.cat(LOGITS4).sigmoid().cpu()) \/ 4\nPREDS1 = LOGITS.sum(1).numpy()\n","41e6bbc5":"dataset = PANDADataset(df, image_size, n_tiles, 0, False, False, transforms_val2 )  # mode == 0\nloader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n\ndataset2 = PANDADataset(df, image_size, n_tiles, 2, False, False, transforms_val2 )  # mode == 2\nloader2 = DataLoader(dataset2, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n\n\nLOGITS = []\nLOGITS2 = []\nLOGITS3 = []\nLOGITS4 = []\nwith torch.no_grad():\n    for data in tqdm(loader):\n        data = data.to(device)\n        logits = models[0](data)\n        LOGITS.append(logits)\n        logits = models2[0](data)\n        LOGITS3.append(logits)\n        \n    for data in tqdm(loader2):\n        data = data.to(device)\n        logits = models[0](data)\n        LOGITS2.append(logits)\n        logits = models2[0](data)\n        LOGITS4.append(logits)\n        \nLOGITS = (torch.cat(LOGITS).sigmoid().cpu()+torch.cat(LOGITS2).sigmoid().cpu()+torch.cat(LOGITS3).sigmoid().cpu()+torch.cat(LOGITS4).sigmoid().cpu()) \/ 4\nPREDS2 = LOGITS.sum(1).numpy()\n","8db73151":"dataset = PANDADataset(df, image_size, n_tiles, 0, False, False, transforms_val3 )  # mode == 0\nloader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n\ndataset2 = PANDADataset(df, image_size, n_tiles, 2, False, False, transforms_val3 )  # mode == 2\nloader2 = DataLoader(dataset2, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n\n\nLOGITS = []\nLOGITS2 = []\nLOGITS3 = []\nLOGITS4 = []\nwith torch.no_grad():\n    for data in tqdm(loader):\n        data = data.to(device)\n        logits = models[0](data)\n        LOGITS.append(logits)\n        logits = models2[0](data)\n        LOGITS3.append(logits)\n        \n    for data in tqdm(loader2):\n        data = data.to(device)\n        logits = models[0](data)\n        LOGITS2.append(logits)\n        logits = models2[0](data)\n        LOGITS4.append(logits)\n        \nLOGITS = (torch.cat(LOGITS).sigmoid().cpu()+torch.cat(LOGITS2).sigmoid().cpu()+torch.cat(LOGITS3).sigmoid().cpu()+torch.cat(LOGITS4).sigmoid().cpu()) \/ 4\nPREDS3 = LOGITS.sum(1).numpy()","5c1c7559":"dataset = PANDADataset(df, image_size, n_tiles, 0, False, False, transforms_val4 )  # mode == 0\nloader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n\ndataset2 = PANDADataset(df, image_size, n_tiles, 2, False, False, transforms_val4 )  # mode == 2\nloader2 = DataLoader(dataset2, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n\n\nLOGITS = []\nLOGITS2 = []\nLOGITS3 = []\nLOGITS4 = []\nwith torch.no_grad():\n    for data in tqdm(loader):\n        data = data.to(device)\n        logits = models[0](data)\n        LOGITS.append(logits)\n        logits = models2[0](data)\n        LOGITS3.append(logits)\n        \n    for data in tqdm(loader2):\n        data = data.to(device)\n        logits = models[0](data)\n        LOGITS2.append(logits)\n        logits = models2[0](data)\n        LOGITS4.append(logits)\n        \nLOGITS = (torch.cat(LOGITS).sigmoid().cpu()+torch.cat(LOGITS2).sigmoid().cpu()+torch.cat(LOGITS3).sigmoid().cpu()+torch.cat(LOGITS4).sigmoid().cpu()) \/ 4\nPREDS4 = LOGITS.sum(1).numpy()\n","1bbcccd8":"!pip install ..\/input\/kaggle-efficientnet-repo\/efficientnet-1.0.0-py3-none-any.whl\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\nimport argparse\nimport os\nimport skimage.io\nfrom scipy.ndimage import measurements\nimport os\nimport numpy as np\nimport pandas as pd\nimport argparse\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import categorical_crossentropy\nfrom tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy\nfrom kaggle_datasets import KaggleDatasets\nfrom tensorflow.keras import layers as L\nimport efficientnet.tfkeras as efn\nfrom tensorflow.keras.utils import to_categorical\nimport gc\nimport albumentations\ngc.enable()\n\n\n\nsz = 256\nN = 48\ndef tile(img):\n    result = []\n    shape = img.shape\n    pad0,pad1 = (sz - shape[0]%sz)%sz, (sz - shape[1]%sz)%sz\n    img = np.pad(img,[[pad0\/\/2,pad0-pad0\/\/2],[pad1\/\/2,pad1-pad1\/\/2],[0,0]],constant_values=255)\n    img = img.reshape(img.shape[0]\/\/sz,sz,img.shape[1]\/\/sz,sz,3)\n    img = img.transpose(0,2,1,3,4).reshape(-1,sz,sz,3)\n    if len(img) < N:\n        img = np.pad(img,[[0,N-len(img)],[0,0],[0,0],[0,0]],constant_values=255)\n    idxs = np.argsort(img.reshape(img.shape[0],-1).sum(-1))[:N]\n    img = img[idxs]\n    return img\n\ndef tile2(img):\n    result = []\n    shape = img.shape\n    pad0,pad1 = (sz - shape[0]%sz)%sz + ((sz * 2) \/\/ 2), (sz - shape[1]%sz)%sz + ((sz * 2) \/\/ 2)\n    img = np.pad(img,[[pad0\/\/2,pad0-pad0\/\/2],[pad1\/\/2,pad1-pad1\/\/2],[0,0]],constant_values=255)\n    img = img.reshape(img.shape[0]\/\/sz,sz,img.shape[1]\/\/sz,sz,3)\n    img = img.transpose(0,2,1,3,4).reshape(-1,sz,sz,3)\n    if len(img) < N:\n        img = np.pad(img,[[0,N-len(img)],[0,0],[0,0],[0,0]],constant_values=255)\n    idxs = np.argsort(img.reshape(img.shape[0],-1).sum(-1))[:N]\n    img = img[idxs]\n    return img\n\n\n\n\nclass ConvNet(tf.keras.Model):\n\n    def __init__(self, engine, input_shape, weights):\n        super(ConvNet, self).__init__()\n        \n        self.engine = engine(\n            include_top=False, input_shape=input_shape, weights=weights)\n        \n        \n        self.avg_pool2d = tf.keras.layers.GlobalAveragePooling2D()\n        self.dropout = tf.keras.layers.Dropout(0.5)\n        self.dense_1 = tf.keras.layers.Dense(1024)\n        self.dense_2 = tf.keras.layers.Dense(5,activation='sigmoid')\n\n    @tf.function\n    def call(self, inputs, **kwargs):\n        x = tf.reshape(inputs, (-1, IMG_SIZE, IMG_SIZE, 3))\n        x = self.engine(x)\n        shape = x.shape\n        x = tf.reshape(x, (-1, N_TILES, shape[1], shape[2], shape[3])) \n        x = tf.transpose(x, perm=[0, 2, 1, 3, 4])\n        x = tf.reshape(x, (-1, shape[1], N_TILES*shape[2], shape[3])) \n        x = self.avg_pool2d(x)\n        x = self.dropout(x, training=False)\n        x = self.dense_1(x)\n        x = tf.nn.relu(x)\n        return self.dense_2(x)\n    \nis_ef = True\nbackbone_name = 'efficientnet-b0'\n\nN_TILES = 48\nIMG_SIZE = 256\n\nif backbone_name.startswith('efficientnet'):\n    model_fn = getattr(efn, f'EfficientNetB{backbone_name[-1]}')\n\n    \nmodel = ConvNet(engine=model_fn, input_shape=(IMG_SIZE, IMG_SIZE, 3), weights=None)\n\n\n\nTRAIN = '..\/input\/prostate-cancer-grade-assessment\/train_images\/'\nMASKS = '..\/input\/prostate-cancer-grade-assessment\/train_label_masks\/'\nBASE_PATH = '..\/input\/prostate-cancer-grade-assessment\/'\ntrain = pd.read_csv(BASE_PATH + \"train.csv\")\ntrain.head()\n\nsub = pd.read_csv(\"..\/input\/prostate-cancer-grade-assessment\/sample_submission.csv\")\nsub.head()\n\ntest = pd.read_csv(\"..\/input\/prostate-cancer-grade-assessment\/test.csv\")\ntest.head()\n\nTEST = '..\/input\/prostate-cancer-grade-assessment\/test_images\/'\n\n\nPRED_PATH = TEST \ndf = sub\nt_df = test\n\n\n\n\n####\n\n\ntransforms_val0 = albumentations.Compose([])\n\n\ntransforms_val1 = albumentations.Compose([\n    albumentations.VerticalFlip(p=1)\n])\n\ntransforms_val2= albumentations.Compose([\n    albumentations.HorizontalFlip(p=0.5),\n    albumentations.VerticalFlip(p=0.5),    \n])\n\ntransforms_val3= albumentations.Compose([\n    albumentations.HorizontalFlip(p=0.5),\n    albumentations.VerticalFlip(p=0.5),    \n])\n\n\n\nn_TTA = 2        \ndummy_data = tf.zeros((n_TTA * N_TILES, IMG_SIZE, IMG_SIZE, 3), dtype=tf.float32)\n_ = model(dummy_data)        \n        ","5bdf2b76":"model.compile(optimizer = tf.keras.optimizers.Adam(lr= 1e-05), loss= tf.nn.sigmoid_cross_entropy_with_logits)\nmodel.load_weights('..\/input\/pandaenetb042x256x256x3\/efficientnet-b0-48-full-epochs60.h5')\n\n####\n\nif os.path.exists(PRED_PATH):\n    predictions10 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile(img)\n\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches3, patches4])\n        image = image \/ 255.0\n        \n        pred = model.predict(image) \n        isup = 0.5*np.sum(pred)\n        predictions10.append(isup)\n\n        del patches, img\n        gc.collect()\n\nelse:\n    PRED_PATH = TRAIN\n    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n    df = df_train.loc[:10]\n    df = df[['image_id','isup_grade']].copy()\n    predictions10 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile(img)\n\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches3, patches4])\n        image = image \/ 255.0\n        \n        pred = model.predict(image) \n        isup = 0.5*np.sum(pred)\n        predictions10.append(isup)\n\n        del patches, img\n        gc.collect()\n\n\n####\n\nif os.path.exists(PRED_PATH):\n    predictions12 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile2(img)\n\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches3, patches4])\n        image = image \/ 255.0\n        \n        pred = model.predict(image) \n        isup = 0.5*np.sum(pred)\n        predictions12.append(isup)\n\n        del patches, img\n        gc.collect()\n\nelse:\n    PRED_PATH = TRAIN\n    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n    df = df_train.loc[:10]\n    df = df[['image_id','isup_grade']].copy()\n    predictions12 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile2(img)\n\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches3, patches4])\n        image = image \/ 255.0\n        \n        pred = model.predict(image) \n        isup = 0.5*np.sum(pred)\n        predictions12.append(isup)\n\n        del patches, img\n        gc.collect()","72fe8b7e":"\nclass ConvNet(tf.keras.Model):\n\n    def __init__(self, engine, input_shape, weights):\n        super(ConvNet, self).__init__()\n        \n        self.engine = engine(\n            include_top=False, input_shape=input_shape, weights=weights)\n        \n        \n        self.avg_pool2d = tf.keras.layers.GlobalAveragePooling2D()\n        self.dropout = tf.keras.layers.Dropout(0.5)\n        self.dense_1 = tf.keras.layers.Dense(1024)\n        self.dense_2 = tf.keras.layers.Dense(5,activation='sigmoid')\n\n    @tf.function\n    def call(self, inputs, **kwargs):\n        x = tf.reshape(inputs, (-1, IMG_SIZE, IMG_SIZE, 3))\n        x = self.engine(x)\n        shape = x.shape\n        x = tf.reshape(x, (-1, N_TILES, shape[1], shape[2], shape[3])) \n        x = tf.transpose(x, perm=[0, 2, 1, 3, 4])\n        x = tf.reshape(x, (-1, shape[1], N_TILES*shape[2], shape[3])) \n        x = self.avg_pool2d(x)\n        x = self.dropout(x, training=False)\n        x = self.dense_1(x)\n        x = tf.nn.relu(x)\n        return self.dense_2(x)\n    \nis_ef = True\nbackbone_name = 'efficientnet-b1'\nN_TILES = 48\nIMG_SIZE = 256\n\n\nif backbone_name.startswith('efficientnet'):\n    model_fn = getattr(efn, f'EfficientNetB{backbone_name[-1]}')\n    \nmodel = ConvNet(engine=model_fn, input_shape=(IMG_SIZE, IMG_SIZE, 3), weights=None)\n\n\n\n\nn_TTA = 2        \ndummy_data = tf.zeros((n_TTA * N_TILES, IMG_SIZE, IMG_SIZE, 3), dtype=tf.float32)\n_ = model(dummy_data)        \n\n\nTRAIN = '..\/input\/prostate-cancer-grade-assessment\/train_images\/'\nMASKS = '..\/input\/prostate-cancer-grade-assessment\/train_label_masks\/'\nBASE_PATH = '..\/input\/prostate-cancer-grade-assessment\/'\ntrain = pd.read_csv(BASE_PATH + \"train.csv\")\ntrain.head()\n\nsub = pd.read_csv(\"..\/input\/prostate-cancer-grade-assessment\/sample_submission.csv\")\nsub.head()\n\ntest = pd.read_csv(\"..\/input\/prostate-cancer-grade-assessment\/test.csv\")\ntest.head()\n\nTEST = '..\/input\/prostate-cancer-grade-assessment\/test_images\/'\n\n\nPRED_PATH = TEST \ndf = sub\nt_df = test","9109370a":"model.compile(optimizer = tf.keras.optimizers.Adam(lr= 1e-05), loss= tf.nn.sigmoid_cross_entropy_with_logits)\nmodel.load_weights('..\/input\/pandaenetb042x256x256x3\/efficientnet-b1-48-full-epochs60.h5')\n\n####\n\nif os.path.exists(PRED_PATH):\n    predictions20 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile(img)\n\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches3, patches4])\n        image = image \/ 255.0\n        \n        pred = model.predict(image) \n        isup = 0.5*np.sum(pred)\n        predictions20.append(isup)\n\n        del patches, img\n        gc.collect()\n\nelse:\n    PRED_PATH = TRAIN\n    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n    df = df_train.loc[:10]\n    df = df[['image_id','isup_grade']].copy()\n    predictions20 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile(img)\n\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches3, patches4])\n        image = image \/ 255.0\n        \n        pred = model.predict(image) \n        isup = 0.5*np.sum(pred)\n        predictions20.append(isup)\n\n        del patches, img\n        gc.collect()\n\n\n####\n\nif os.path.exists(PRED_PATH):\n    predictions22 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile2(img)\n\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches3, patches4])\n        image = image \/ 255.0\n        \n        pred = model.predict(image) \n        isup = 0.5*np.sum(pred)\n        predictions22.append(isup)\n\n        del patches, img\n        gc.collect()\n\nelse:\n    PRED_PATH = TRAIN\n    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n    df = df_train.loc[:10]\n    df = df[['image_id','isup_grade']].copy()\n    predictions22 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile2(img)\n\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches3, patches4])\n        image = image \/ 255.0\n        \n        pred = model.predict(image) \n        isup = 0.5*np.sum(pred)\n        predictions22.append(isup)\n\n        del patches, img\n        gc.collect()","e9d0f81a":"\nclass ConvNet(tf.keras.Model):\n\n    def __init__(self, engine, input_shape, weights):\n        super(ConvNet, self).__init__()\n        \n        self.engine = engine(\n            include_top=False, input_shape=input_shape, weights=weights)\n        \n        \n        self.avg_pool2d = tf.keras.layers.GlobalAveragePooling2D()\n        self.dropout = tf.keras.layers.Dropout(0.5)\n        self.dense_1 = tf.keras.layers.Dense(1024)\n        self.dense_2 = tf.keras.layers.Dense(5,activation='sigmoid')\n\n    @tf.function\n    def call(self, inputs, **kwargs):\n        x = tf.reshape(inputs, (-1, IMG_SIZE, IMG_SIZE, 3))\n        x = self.engine(x)\n        shape = x.shape\n        x = tf.reshape(x, (-1, N_TILES, shape[1], shape[2], shape[3])) \n        x = tf.transpose(x, perm=[0, 2, 1, 3, 4])\n        x = tf.reshape(x, (-1, shape[1], N_TILES*shape[2], shape[3])) \n        x = self.avg_pool2d(x)\n        x = self.dropout(x, training=False)\n        x = self.dense_1(x)\n        x = tf.nn.relu(x)\n        return self.dense_2(x)\n    \nis_ef = True\nbackbone_name = 'efficientnet-b2'\nN_TILES = 48\nIMG_SIZE = 256\n\n\nif backbone_name.startswith('efficientnet'):\n    model_fn = getattr(efn, f'EfficientNetB{backbone_name[-1]}')\n    \nmodel = ConvNet(engine=model_fn, input_shape=(IMG_SIZE, IMG_SIZE, 3), weights=None)\n\n\nn_TTA = 2        \ndummy_data = tf.zeros((n_TTA * N_TILES, IMG_SIZE, IMG_SIZE, 3), dtype=tf.float32)\n_ = model(dummy_data)           \n\n\n\nTRAIN = '..\/input\/prostate-cancer-grade-assessment\/train_images\/'\nMASKS = '..\/input\/prostate-cancer-grade-assessment\/train_label_masks\/'\nBASE_PATH = '..\/input\/prostate-cancer-grade-assessment\/'\ntrain = pd.read_csv(BASE_PATH + \"train.csv\")\ntrain.head()\n\nsub = pd.read_csv(\"..\/input\/prostate-cancer-grade-assessment\/sample_submission.csv\")\nsub.head()\n\ntest = pd.read_csv(\"..\/input\/prostate-cancer-grade-assessment\/test.csv\")\ntest.head()\n\nTEST = '..\/input\/prostate-cancer-grade-assessment\/test_images\/'\n\n\nPRED_PATH = TEST \ndf = sub\nt_df = test","078558a9":"model.compile(optimizer = tf.keras.optimizers.Adam(lr= 1e-05), loss= tf.nn.sigmoid_cross_entropy_with_logits)\nmodel.load_weights('..\/input\/pandaenetb042x256x256x3\/efficientnet-b2-48-full-epochs60.h5')\n\n####\n\nif os.path.exists(PRED_PATH):\n    predictions30 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile(img)\n\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches3, patches4])\n        image = image \/ 255.0\n        \n        pred = model.predict(image) \n        isup = 0.5*np.sum(pred)\n        predictions30.append(isup)\n\n        del patches, img\n        gc.collect()\n\nelse:\n    PRED_PATH = TRAIN\n    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n    df = df_train.loc[:10]\n    df = df[['image_id','isup_grade']].copy()\n    predictions30 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile(img)\n\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches3, patches4])\n        image = image \/ 255.0\n        \n        pred = model.predict(image) \n        isup = 0.5*np.sum(pred)\n        predictions30.append(isup)\n\n        del patches, img\n        gc.collect()\n\n\n####\n\nif os.path.exists(PRED_PATH):\n    predictions32 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile2(img)\n\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches3, patches4])\n        image = image \/ 255.0\n        \n        pred = model.predict(image) \n        isup = 0.5*np.sum(pred)\n        predictions32.append(isup)\n\n        del patches, img\n        gc.collect()\n\nelse:\n    PRED_PATH = TRAIN\n    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n    df = df_train.loc[:10]\n    df = df[['image_id','isup_grade']].copy()\n    predictions32 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile2(img)\n\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches3, patches4])\n        image = image \/ 255.0\n        \n        pred = model.predict(image) \n        isup = 0.5*np.sum(pred)\n        predictions32.append(isup)\n\n        del patches, img\n        gc.collect()\n        \n","0fca77a2":"\nfrom tensorflow.keras.applications import densenet as den\n\n\n\nclass ConvNet(tf.keras.Model):\n\n    def __init__(self, engine, input_shape, weights):\n        super(ConvNet, self).__init__()\n        \n        self.engine = engine(\n            include_top=False, input_shape=input_shape, weights=weights)\n        \n        \n        self.avg_pool2d = tf.keras.layers.GlobalAveragePooling2D()\n        self.dropout = tf.keras.layers.Dropout(0.5)\n        self.dense_1 = tf.keras.layers.Dense(1024)\n        self.dense_2 = tf.keras.layers.Dense(5,activation='sigmoid')\n\n    @tf.function\n    def call(self, inputs, **kwargs):\n        x = tf.reshape(inputs, (-1, IMG_SIZE, IMG_SIZE, 3))\n        x = self.engine(x)\n        shape = x.shape\n        x = tf.reshape(x, (-1, N_TILES, shape[1], shape[2], shape[3])) \n        x = tf.transpose(x, perm=[0, 2, 1, 3, 4])\n        x = tf.reshape(x, (-1, shape[1], N_TILES*shape[2], shape[3])) \n        x = self.avg_pool2d(x)\n        x = self.dropout(x, training=False)\n        x = self.dense_1(x)\n        x = tf.nn.relu(x)\n        return self.dense_2(x)\n    \n\n\nN_TILES = 48\nIMG_SIZE = 256\n\n\n\nmodel_fn = getattr(den, 'DenseNet121')\n    \nmodel = ConvNet(engine=model_fn, input_shape=(IMG_SIZE, IMG_SIZE, 3), weights=None)\n\n\nn_TTA = 4        \ndummy_data = tf.zeros((n_TTA * N_TILES, IMG_SIZE, IMG_SIZE, 3), dtype=tf.float32)\n_ = model(dummy_data)      \n\n\n\nTRAIN = '..\/input\/prostate-cancer-grade-assessment\/train_images\/'\nMASKS = '..\/input\/prostate-cancer-grade-assessment\/train_label_masks\/'\nBASE_PATH = '..\/input\/prostate-cancer-grade-assessment\/'\ntrain = pd.read_csv(BASE_PATH + \"train.csv\")\ntrain.head()\n\nsub = pd.read_csv(\"..\/input\/prostate-cancer-grade-assessment\/sample_submission.csv\")\nsub.head()\n\ntest = pd.read_csv(\"..\/input\/prostate-cancer-grade-assessment\/test.csv\")\ntest.head()\n\nTEST = '..\/input\/prostate-cancer-grade-assessment\/test_images\/'\n\n\nPRED_PATH = TEST \ndf = sub\nt_df = test","f1dd1cca":"model.compile(optimizer = tf.keras.optimizers.Adam(lr= 1e-05), loss= tf.nn.sigmoid_cross_entropy_with_logits)\nmodel.load_weights('..\/input\/pandaenetb042x256x256x3\/DenseNet121-48-full-epochs60.h5')\n\n####\n\nif os.path.exists(PRED_PATH):\n    predictions40 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile(img)\n        patches1 = patches.copy()\n        patches2 = patches.copy()\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches1[k, ] = transforms_val0(image=patches1[k, ])['image']\n            patches2[k, ] = transforms_val1(image=patches2[k, ])['image']\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches1, patches2, patches3, patches4])\n        image = image \/ 255.0\n        \n        pred = model.predict(image) \n        isup = 0.25*np.sum(pred)\n        predictions40.append(isup)\n\n        del patches, img\n        gc.collect()\n\nelse:\n    PRED_PATH = TRAIN\n    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n    df = df_train.loc[:10]\n    df = df[['image_id','isup_grade']].copy()\n    predictions40 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile(img)\n        patches1 = patches.copy()\n        patches2 = patches.copy()\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches1[k, ] = transforms_val0(image=patches1[k, ])['image']\n            patches2[k, ] = transforms_val1(image=patches2[k, ])['image']\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches1, patches2, patches3, patches4])\n        image = image \/ 255.0\n        \n        pred = model.predict(image) \n        isup = 0.25*np.sum(pred)\n        predictions40.append(isup)\n\n        del patches, img\n        gc.collect()\n\n\n####\n\nif os.path.exists(PRED_PATH):\n    predictions42 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile2(img)\n        patches1 = patches.copy()\n        patches2 = patches.copy()\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches1[k, ] = transforms_val0(image=patches1[k, ])['image']\n            patches2[k, ] = transforms_val1(image=patches2[k, ])['image']\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches1, patches2, patches3, patches4])\n        image = image \/ 255.0\n        \n        pred = model.predict(image) \n        isup = 0.25*np.sum(pred)\n        predictions42.append(isup)\n\n        del patches, img\n        gc.collect()\n\nelse:\n    PRED_PATH = TRAIN\n    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n    df = df_train.loc[:10]\n    df = df[['image_id','isup_grade']].copy()\n    predictions42 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile2(img)\n        patches1 = patches.copy()\n        patches2 = patches.copy()\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches1[k, ] = transforms_val0(image=patches1[k, ])['image']\n            patches2[k, ] = transforms_val1(image=patches2[k, ])['image']\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches1, patches2, patches3, patches4])\n        image = image \/ 255.0\n        \n        pred = model.predict(image) \n        isup = 0.25*np.sum(pred)\n        predictions42.append(isup)\n\n        del patches, img\n        gc.collect()\n\n\n        \ndel model, dummy_data, sub, pred, train, isup, image\ndel patches1,patches2,patches3,patches4    \n\ngc.collect()  ","f1b0fa94":"\nsz = 256\nN = 42\ndef tile(img):\n    result = []\n    shape = img.shape\n    pad0,pad1 = (sz - shape[0]%sz)%sz, (sz - shape[1]%sz)%sz\n    img = np.pad(img,[[pad0\/\/2,pad0-pad0\/\/2],[pad1\/\/2,pad1-pad1\/\/2],[0,0]],constant_values=255)\n    img = img.reshape(img.shape[0]\/\/sz,sz,img.shape[1]\/\/sz,sz,3)\n    img = img.transpose(0,2,1,3,4).reshape(-1,sz,sz,3)\n    if len(img) < N:\n        img = np.pad(img,[[0,N-len(img)],[0,0],[0,0],[0,0]],constant_values=255)\n    idxs = np.argsort(img.reshape(img.shape[0],-1).sum(-1))[:N]\n    img = img[idxs]\n    return img\n\ndef tile2(img):\n    result = []\n    shape = img.shape\n    pad0,pad1 = (sz - shape[0]%sz)%sz + ((sz * 2) \/\/ 2), (sz - shape[1]%sz)%sz + ((sz * 2) \/\/ 2)\n    img = np.pad(img,[[pad0\/\/2,pad0-pad0\/\/2],[pad1\/\/2,pad1-pad1\/\/2],[0,0]],constant_values=255)\n    img = img.reshape(img.shape[0]\/\/sz,sz,img.shape[1]\/\/sz,sz,3)\n    img = img.transpose(0,2,1,3,4).reshape(-1,sz,sz,3)\n    if len(img) < N:\n        img = np.pad(img,[[0,N-len(img)],[0,0],[0,0],[0,0]],constant_values=255)\n    idxs = np.argsort(img.reshape(img.shape[0],-1).sum(-1))[:N]\n    img = img[idxs]\n    return img\n\n\n\n\nclass ConvNet(tf.keras.Model):\n\n    def __init__(self, engine, input_shape, weights):\n        super(ConvNet, self).__init__()\n        \n        self.engine = engine(\n            include_top=False, input_shape=input_shape, weights=weights)\n        \n        \n        self.avg_pool2d = tf.keras.layers.GlobalAveragePooling2D()\n        self.dropout = tf.keras.layers.Dropout(0.5)\n        self.dense_1 = tf.keras.layers.Dense(1024)\n        self.dense_2 = tf.keras.layers.Dense(1)\n\n    @tf.function\n    def call(self, inputs, **kwargs):\n        x = tf.reshape(inputs, (-1, IMG_SIZE, IMG_SIZE, 3))\n        x = self.engine(x)\n        shape = x.shape\n        x = tf.reshape(x, (-1, N_TILES, shape[1], shape[2], shape[3])) \n        x = tf.transpose(x, perm=[0, 2, 1, 3, 4])\n        x = tf.reshape(x, (-1, shape[1], N_TILES*shape[2], shape[3])) \n        x = self.avg_pool2d(x)\n        x = self.dropout(x, training=False)\n        x = self.dense_1(x)\n        x = tf.nn.relu(x)\n        return self.dense_2(x)\n    \nis_ef = True\nbackbone_name = 'efficientnet-b0'\n\nN_TILES = 42\nIMG_SIZE = 256\n\nif backbone_name.startswith('efficientnet'):\n    model_fn = getattr(efn, f'EfficientNetB{backbone_name[-1]}')\n\n    \nmodel = ConvNet(engine=model_fn, input_shape=(IMG_SIZE, IMG_SIZE, 3), weights=None)\n\n\n\nTRAIN = '..\/input\/prostate-cancer-grade-assessment\/train_images\/'\nMASKS = '..\/input\/prostate-cancer-grade-assessment\/train_label_masks\/'\nBASE_PATH = '..\/input\/prostate-cancer-grade-assessment\/'\ntrain = pd.read_csv(BASE_PATH + \"train.csv\")\ntrain.head()\n\nsub = pd.read_csv(\"..\/input\/prostate-cancer-grade-assessment\/sample_submission.csv\")\nsub.head()\n\ntest = pd.read_csv(\"..\/input\/prostate-cancer-grade-assessment\/test.csv\")\ntest.head()\n\nTEST = '..\/input\/prostate-cancer-grade-assessment\/test_images\/'\n\n\nPRED_PATH = TEST \ndf = sub\nt_df = test\n\n\n\n\n####\n\n\n\n\n\nn_TTA = 2        \ndummy_data = tf.zeros((n_TTA * N_TILES, IMG_SIZE, IMG_SIZE, 3), dtype=tf.float32)\n_ = model(dummy_data)   \n\n","8fbc8323":"model.compile(optimizer = tf.keras.optimizers.Adam(lr= 1e-05), loss= tf.nn.sigmoid_cross_entropy_with_logits)\nmodel.load_weights('..\/input\/pandaenetb042x256x256x3\/efficientnet-b0-fold0-epochs40.h5')\n\n####\n\nif os.path.exists(PRED_PATH):\n    predictions50 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile(img)\n\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches3, patches4])\n        image = image \/ 255.0\n        \n        pred = model.predict(image)\n        isup = np.mean(pred)\n        predictions50.append(isup)\n\n        del patches, img\n        gc.collect()\n\nelse:\n    PRED_PATH = TRAIN\n    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n    df = df_train.loc[:10]\n    df = df[['image_id','isup_grade']].copy()\n    predictions50 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile(img)\n\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches3, patches4])\n        image = image \/ 255.0\n        \n        pred = model.predict(image)\n        isup = np.mean(pred)\n        predictions50.append(isup)\n\n        del patches, img\n        gc.collect()\n\n\n####\n\nif os.path.exists(PRED_PATH):\n    predictions52 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile2(img)\n\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches3, patches4])\n        image = image \/ 255.0\n        \n        pred = model.predict(image)\n        isup = np.mean(pred)\n        predictions52.append(isup)\n\n        del patches, img\n        gc.collect()\n\nelse:\n    PRED_PATH = TRAIN\n    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n    df = df_train.loc[:10]\n    df = df[['image_id','isup_grade']].copy()\n    predictions52 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile2(img)\n\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches3, patches4])\n        image = image \/ 255.0\n        \n        pred = model.predict(image)\n        isup = np.mean(pred)\n        predictions52.append(isup)\n\n        del patches, img\n        gc.collect()\n        \n","ffc06d03":"\n\nmodel.compile(optimizer = tf.keras.optimizers.Adam(lr= 1e-05), loss= tf.nn.sigmoid_cross_entropy_with_logits)\nmodel.load_weights('..\/input\/pandaenetb042x256x256x3\/efficientnet-b0-fold4-epochs60.h5')\n\n####\n\nif os.path.exists(PRED_PATH):\n    predictions60 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile(img)\n\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches3, patches4])\n        image = image \/ 255.0\n        \n        pred = model.predict(image)\n        isup = np.mean(pred)\n        predictions60.append(isup)\n\n        del patches, img\n        gc.collect()\n\nelse:\n    PRED_PATH = TRAIN\n    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n    df = df_train.loc[:10]\n    df = df[['image_id','isup_grade']].copy()\n    predictions60 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile(img)\n\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches3, patches4])\n        image = image \/ 255.0\n        \n        pred = model.predict(image)\n        isup = np.mean(pred)\n        predictions60.append(isup)\n\n        del patches, img\n        gc.collect()\n\n\n####\n\nif os.path.exists(PRED_PATH):\n    predictions62 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile2(img)\n\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches3, patches4])\n        image = image \/ 255.0\n        \n        pred = model.predict(image)\n        isup = np.mean(pred)\n        predictions62.append(isup)\n\n        del patches, img\n        gc.collect()\n\nelse:\n    PRED_PATH = TRAIN\n    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n    df = df_train.loc[:10]\n    df = df[['image_id','isup_grade']].copy()\n    predictions62 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile2(img)\n\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches3, patches4])\n        image = image \/ 255.0\n        \n        pred = model.predict(image)\n        isup = np.mean(pred)\n        predictions62.append(isup)\n\n        del patches, img\n        gc.collect()\n        \n\n\n\n\n\n","30417212":"model.compile(optimizer = tf.keras.optimizers.Adam(lr= 1e-05), loss= tf.nn.sigmoid_cross_entropy_with_logits)\nmodel.load_weights('..\/input\/pandaenetb042x256x256x3\/efficientnet-b0-fold2-epochs40.h5')\n\n####\n\nif os.path.exists(PRED_PATH):\n    predictions70 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile(img)\n\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches3, patches4])\n        image = image \/ 255.0\n        \n        pred = model.predict(image)\n        isup = np.mean(pred)\n        predictions70.append(isup)\n\n        del patches, img\n        gc.collect()\n\nelse:\n    PRED_PATH = TRAIN\n    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n    df = df_train.loc[:10]\n    df = df[['image_id','isup_grade']].copy()\n    predictions70 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile(img)\n\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches3, patches4])\n        image = image \/ 255.0\n        \n        pred = model.predict(image)\n        isup = np.mean(pred)\n        predictions70.append(isup)\n\n        del patches, img\n        gc.collect()\n\n\n####\n\nif os.path.exists(PRED_PATH):\n    predictions72 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile2(img)\n\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches3, patches4])\n        image = image \/ 255.0\n        \n        pred = model.predict(image)\n        isup = np.mean(pred)\n        predictions72.append(isup)\n\n        del patches, img\n        gc.collect()\n\nelse:\n    PRED_PATH = TRAIN\n    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n    df = df_train.loc[:10]\n    df = df[['image_id','isup_grade']].copy()\n    predictions72 = []\n    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n        \n        \n        image_id = row['image_id']\n        \n        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n        \n        img = skimage.io.MultiImage(img_path)[1]\n        \n        patches = tile2(img)\n\n        patches3 = patches.copy()\n        patches4 = patches.copy() \n        \n        k = 0\n        while k < N_TILES:\n            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n            k += 1\n        \n        image = np.stack([patches3, patches4])\n        image = image \/ 255.0\n        \n        pred = model.predict(image)\n        isup = np.mean(pred)\n        predictions72.append(isup)\n\n        del patches, img\n        gc.collect()\n        \n\n\n\ndel model, dummy_data, sub, pred, train, isup, image\ndel patches3,patches4    \n\ngc.collect()  ","14533197":"\nPREDS = (1\/5)*PREDS + (1\/5)*PREDS1 + (1\/5)*PREDS2 + (1\/5)*PREDS3 + (1\/5)*PREDS4\n\nFINAL = np.round( (6\/10)*PREDS +\n                  (2\/60)*np.array(predictions10) + (2\/60)*np.array(predictions12) + \n                  (2\/60)*np.array(predictions20) + (2\/60)*np.array(predictions22) +\n                  (2\/60)*np.array(predictions30) + (2\/60)*np.array(predictions32) +\n                  (0.5\/10)*np.array(predictions40) + (0.5\/10)*np.array(predictions42) +\n                  (1\/60)*np.array(predictions50) + (1\/60)*np.array(predictions52) +\n                  (1\/60)*np.array(predictions60) + (1\/60)*np.array(predictions62) +\n                  (1\/60)*np.array(predictions70) + (1\/60)*np.array(predictions72) )\n\n\ndf['isup_grade'] = FINAL.astype(int)\ndf[['image_id', 'isup_grade']].to_csv('submission.csv', index=False)\nprint(df.head())\nprint()\nprint(df.isup_grade.value_counts())","686597a7":"# Prediction","a3ab6a93":"# Model","115fdd48":"# Dataset"}}