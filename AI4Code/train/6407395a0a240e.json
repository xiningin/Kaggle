{"cell_type":{"be0fee34":"code","bff742f9":"code","0d744775":"code","705ab08e":"code","9f9f6d6c":"code","287556fe":"code","39c43d65":"code","803fdd5e":"code","ebeca18a":"code","d16db312":"code","3af2e81b":"code","e723083f":"code","8b911ac4":"code","0f6a674d":"code","26d7a5ae":"code","65f1b7c9":"code","dbffddf1":"code","d205b346":"code","f9a566ee":"code","cfda40fc":"code","922b08a4":"markdown","2c7bb4cf":"markdown","e27b180e":"markdown","20764de5":"markdown","3c7de0ea":"markdown","8257724d":"markdown","671c9ace":"markdown","ce80bcb8":"markdown","fcb33426":"markdown","0ba83e19":"markdown","43fb7142":"markdown","a6ce8bc7":"markdown","39ad57bb":"markdown","82507e55":"markdown","1f6e0385":"markdown","07e215d2":"markdown","3e416106":"markdown","6c856228":"markdown","527d5123":"markdown","429484eb":"markdown","b4feb749":"markdown","5bac94c0":"markdown","e9b13e55":"markdown","dcf25903":"markdown","c8c5b057":"markdown","29dff30f":"markdown","9c111edc":"markdown","f4668555":"markdown","53abf669":"markdown","1d8994eb":"markdown","ac28c23b":"markdown","207851ab":"markdown","517e6418":"markdown","ecabbfa9":"markdown","386b1fe5":"markdown"},"source":{"be0fee34":"# Importing necessary Python libraries (Hidden Input)\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\nfrom plotly import tools\nfrom plotly.subplots import make_subplots\nimport plotly.offline as py\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom yellowbrick.cluster import SilhouetteVisualizer\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\n# from scipy.cluster.hierarchy import cut_tree\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')","bff742f9":"# Reading the data (Hidden Input)\n\ndf = pd.read_csv(\"..\/input\/fish-market\/Fish.csv\")\ndf.head().style.background_gradient(cmap='YlGnBu')","0d744775":"# Checking the number of rows and columns (Hidden Input)\n\nprint(\"Number of Rows:\", df.shape[0])\nprint(\"Number of Columns:\", df.shape[1])","705ab08e":"# Checking for any missing values in all features (Hidden Input)\n\nprint(\"*\" * 30)\nprint(df.isnull().sum())\nprint(\"*\" * 30)\nprint(\"No Missing Values Detected!\")","9f9f6d6c":"# All Credits for the following code to : https:\/\/www.kaggle.com\/jeongbinpark\/how-to-emphasize-your-think-at-viusalization for amazing Lesson on Visualization\n\n# Visualizing the Number of Species in the Market; Finding the most popular one. (Hidden Input)\n\nfig, ax = plt.subplots(figsize=(20,10), facecolor=\"w\")\n\n# I wanted to have the highest value in the middle, so i wrote the following two code lines\nfish = ['Whitefish','Parkki','Bream','Perch','Roach','Pike','Smelt']\ncount_of_fish = [6, 11, 35, 56, 20, 17, 14] \n\ncolor = ['#07689F', '#34656D','#29BB89','#3797A4','#FCF876','#00A19D','#00A19D'] # Deciding the color\nwidth = [0.8, 0.8, 0.8, 1.0, 0.8, 0.8, 0.8] # The Width\nalpha = [0.3, 0.55, 0.8, 1.0, 0.6, 0.55, 0.3] # The Opacity\n\nfontsize= [20, 20, 30, 45, 30, 20, 20]\nx_num = [0,1,2,3,4,5,6]\n\nfor i in range(7):\n    plt.bar(x=fish[i],height=count_of_fish[i], width=width[i], color=color[i], alpha=alpha[i])\n    plt.text(s=fish[i],x=x_num[i],y=count_of_fish[i],va='bottom',ha='center',font='Comic Sans MS',fontsize=fontsize[i], alpha=alpha[i])\n    plt.text(s=\"Popular Choice of Fish in the Market\",x=3,y=65,font='Comic Sans MS', fontsize=50,va='bottom',ha='center')\n\nplt.axis('off')\nplt.show()","287556fe":"# All Credits for the following code to : https:\/\/www.kaggle.com\/jeongbinpark\/how-to-emphasize-your-think-at-viusalization for amazing Lesson on Visualization\n\n# Visualizing the Average Weight of Each Species of Fish in the Market; Finding the most popular one. (Hidden Input)\n\nfig, ax = plt.subplots(figsize=(20,10), facecolor=\"w\")\n\n# I wanted to have the highest value in the middle, so i wrote the following two code lines\nfish = ['Smelt','Roach','Bream','Pike','Whitefish','Perch','Parkki']\ncount_of_fish = [11.17, 152.05, 617.82, 718.70, 531, 382.34, 154.81] \n\ncolor = ['#07689F', '#34656D','#29BB89','#3797A4','#FCF876','#00A19D','#00A19D'] # Deciding the color\nwidth = [0.8, 0.8, 0.8, 1.0, 0.8, 0.8, 0.8] # The Width\nalpha = [0.3, 0.55, 0.8, 1.0, 0.6, 0.55, 0.3] # The Opacity\n\nfontsize= [20, 20, 30, 45, 25, 20, 20]\nx_num = [0,1,2,3,4,5,6]\n\nfor i in range(7):\n    plt.bar(x=fish[i],height=count_of_fish[i], width=width[i], color=color[i], alpha=alpha[i])\n    plt.text(s=fish[i],x=x_num[i],y=count_of_fish[i],va='bottom',ha='center',font='Comic Sans MS',fontsize=fontsize[i], alpha=alpha[i])\n    plt.text(s=\"Average Weight of Fish in the Market\",x=3,y=850,font='Comic Sans MS', fontsize=50,va='bottom',ha='center')\n\nplt.axis('off')\nplt.show()","39c43d65":"# All Credits for the following code to : https:\/\/www.kaggle.com\/jeongbinpark\/expensive-football-players-analysis for amazing Lesson on Visualization\n\n# Visualizing the Average Height of Each Species of Fish in the Market; Finding the most popular one. (Hidden Input)\n\nfish = ['Bream','Whitefish','Parkki','Perch','Pike','Roach','Smelt']\nHeights = [15.18, 10.02, 8.96, 7.86, 7.71, 6.69, 2.20]\n\nfig = plt.figure(figsize=(20,8))\nplt.barh(width=Heights, y=fish, height=0.7, color = ['#C6D57E', '#D57E7E','#A2CDCD','#FFE1AF','#316B83', '#5E454B', '#986D8E'], alpha=0.65)\n\n##################### For the Weight #################################\ns = ['15.18cm', '10.02cm', '8.96cm', '7.86cm', '7.71cm', '6.69cm', '2.20cm']\nx = [16.9, 11.8, 10.5, 9.4, 9.2, 8.2, 3.7]\ny = [0,1,2,3,4,5,6]\n##################### For the Fish ###################################\ns1 = ['Bream','Whitefish','Parkki','Perch','Pike','Roach','Smelt']\nx1 = [15, 9.8, 8.8, 7.7, 7.5, 6.5, 2]\ny1 = [0,1,2,3,4,5,6]\n\n\nfor i in range(7):\n    plt.text(s = s[i], x=x[i], y=y[i] ,font = 'Comic Sans MS', fontsize=25,va='center',ha='right')\n    plt.text(s = s1[i], x=x1[i], y=y1[i] ,font = 'Comic Sans MS', fontsize=25,va='center',ha='right')\n\nplt.title(\"Average Height of Each Species of Fish in the Market\",font='Comic Sans MS', fontsize=42, pad=20)\nplt.axis('off')\nplt.gca().invert_yaxis()\nplt.show()","803fdd5e":"# From our dataframe, we will drop the \"Species\" feature, since this is what we are going to predict.\n\ndf.drop(columns=\"Species\", axis=1, inplace=True)","ebeca18a":"# Next, we will check for any Outliers in the data.\n\n# Checking the Descriptive statistics of the numerical columns (Hidden Input)\n\ndf.describe(percentiles=[0.01,0.98,0.99]).T.style.bar(\n    subset=['mean'],\n    color='lightsalmon').background_gradient(\n    subset=['std'], cmap='plasma').background_gradient(subset=['99%'], cmap='plasma').background_gradient(\n    subset=['max'], cmap='plasma')","d16db312":"# Fixing the weight related issue\n\ndf['Weight'] = df['Weight'].apply(lambda x: 152.05 if x == 0 else x)","3af2e81b":"# Standardizing the data\n\nscaler = StandardScaler()\n\ndf_scaled = scaler.fit_transform(df)","e723083f":"# Building the K-Means model\n\nkmeans = KMeans(n_clusters=4, max_iter=50)\n\nkmeans.fit(df_scaled)","8b911ac4":"# Making the Elbow Curve (Hidden Input)\n\nsns.set_style(\"darkgrid\")\nplt.figure(figsize=[16,8])\n\nssd = [] # Sum of squared distances\nrange_n_clusters = [1,3,5,7,9]\n\nfor num_clusters in range_n_clusters:\n    kmeans = KMeans(n_clusters=num_clusters, max_iter=50)\n    kmeans.fit(df_scaled)\n    ssd.append(kmeans.inertia_) # Sum of squared distances of samples to their closest cluster center. See Sklearn documentation for more.\n\nplt.xticks(ticks=[0.0,0.5,1.0,1.5,2.0,2.5,3.0,3.5,4.0],labels=[1,2,3,4,5,6,7,8,9]) # Fixing the xticks\nplt.plot(ssd, '--bo', markersize=15)\nplt.show()","0f6a674d":"# Silhouette Analysis (Hidden Input)\n\nrange_n_clusters = [3,5,7,9] # Trying these clusters\n\nfor num_clusters in range_n_clusters:\n    kmeans = KMeans(n_clusters=num_clusters, max_iter=50)\n    kmeans.fit(df_scaled)\n    cluster_labels = kmeans.labels_\n    \n    # Silhouettte Score\n    silhouette_avg = silhouette_score(df_scaled, cluster_labels)\n    print(\"For n_clusters={0}, the Silhouette Score is {1}\".format(num_clusters, silhouette_avg))","26d7a5ae":"# Visualizing the Silhouette plot (Hidden Input)\nplt.figure(figsize=[16,10])\n\nvisualizer = SilhouetteVisualizer(kmeans, colors='yellowbrick')\n\nvisualizer.fit(df_scaled)        # Fit the data to the visualizer\nvisualizer.show()        # Finalize and render the figure\nplt.show()","65f1b7c9":"# Fitting the model with n_clusters=7 as per our analysis\n\nkmeans = KMeans(n_clusters=7, max_iter=50)\n\nkmeans.fit(df_scaled)","dbffddf1":"# Creating a dataframe with the Cluster Labels\n\ndf1 = pd.DataFrame(df_scaled)\ndf1.columns=['Weight','Length1','Length2','Length3','Height','Width']\ndf1['ClusterID'] = kmeans.labels_\ndf1.head()","d205b346":"# Visualizing \"Different Clusters of Fish Species based on Height(x) and Weight(y)\" (Hidden Input)\n\nplt.figure(figsize=[16,8])\nsns.scatterplot(data = df1, x = \"Height\", y = \"Weight\", hue = df1.ClusterID, palette = \"plasma\", s=70)\nplt.axis()\nplt.title(\"Different Clusters of Fish Species based on Height(x) and Weight(y)\",font='Comic Sans MS', fontsize=35, pad=20)\nplt.xlabel(\"Height\", size=18)\nplt.ylabel(\"Weight\", size=18)\nplt.show()","f9a566ee":"# 3d scatterplot using plotly (Credits to: https:\/\/www.kaggle.com\/naren3256\/kmeans-clustering-and-cluster-visualization-in-3d) (Hidden Input)\nScene = dict(xaxis = dict(title  = 'Height -->'),yaxis = dict(title  = 'Weight--->'),zaxis = dict(title  = 'Width-->'))\n\n\nlabels = kmeans.labels_\ntrace = go.Scatter3d(x=df1['Height'], y=df1['Weight'], z=df1['Width'], mode='markers',\n                     marker=dict(color = labels, size= 10, line=dict(color= 'black',width = 10)))\n\nlayout = go.Layout(margin=dict(l=0,r=0),scene = Scene,height = 800,width = 800, title=\"3D Scatter Plot to view different Clusters\")\ndata = [trace]\nfig = go.Figure(data = data, layout = layout)\nfig.show()","cfda40fc":"# Complete Linkage \nmergings = linkage(df_scaled, method='complete')\n\n# Visualizing\nplt.figure(figsize=[20,8])\n\nplt.title(\"Dedrogram for Hierarchical Clustering (Fish Analysis)\", size=25, pad=20)\ndendrogram(mergings)\n\nplt.show()","922b08a4":"### Conclusion:\n\n<p style=\"font-size:120%;\"> From the above plot, the Data Scientist and the Business group can have a discussion and suggest the best\/optimal cluster that will be beneficial for the business purpose.<\/p>\n\n<p style=\"font-size:120%;\"> If a company is looking to enter the market, they can take the necessary insights from the EDA and target the specific customers based on the clustering that has been made.<\/p>","2c7bb4cf":"<p style=\"font-size:120%\"> When we check the average height of all the fish, we see that Bream, Whitefish and Parkki are relatively long. Especially Bream.<\/p>\n<p style=\"font-size:120%\"> Perch which is popular, has an average height out of all the fish. This can be due to the fact that it is consumed almost everytime by the people.<\/p>\n<p style=\"font-size:120%\"> Therefore, Perch is for daily consumption whereas, Bream preferably on a special occasion. Okay, I might have to try this fish someday :P .<\/p>","e27b180e":"<img src=\"https:\/\/i.redd.it\/u9r45ih6jrs11.gif\" style=\"display: block; margin-left: auto; margin-right: auto; width: 50%;\"><\/img>","20764de5":"### Silhouette Analysis:\n\n![image.png](attachment:9f61a169-4f45-4f3f-8f07-13ff6516af7b.png)\n\n<p style=\"font-size:120%;\"> <strong>b<\/strong> is the mean distance to the points in the nearest cluster that the datapoint is not a part of.<\/p>\n\n<p style=\"font-size:120%;\"> <strong>a<\/strong> is the mean intra-cluster distance to all the points in its own cluster.<\/p>\n\n<ul>\n<li style=\"font-size:120%;\"> The value of the Silhouette Score lies between -1 and 1. <\/li>\n<li style=\"font-size:120%;\"> A score closer to 1 signifies that the data point is very similar to other data points in the cluster. <\/li>\n<li style=\"font-size:120%;\"> A score closer to -1 signifies that the data point is not similar to other data points in the cluster. <\/li>\n<\/ul>","3c7de0ea":"<div class=\"alert alert-success\">\n    <p style=\"color:Black;font-size:120%\">\ud83c\udfaf Before we proceed with the Clustering Techniques, let's understand our data better with some EDA and gain some insights on the same.<\/p>\n<\/div>    ","8257724d":"<div class=\"alert alert-block alert-info\" >\n    <a id=\"3\" style=\"text-decoration:None;\">\n    <h1 style=\"text-align:center;font-weight: 20px; color:black;\">\n       Clustering is an Unsupervised Task <\/h1>\n    <\/a>    \n<\/div>","671c9ace":"<p style=\"font-size:120%\"> This Analysis has been performed on the basis of the count of species that was available in the dataset. <\/p>\n<p style=\"font-size:120%\"> Here, we are assuming that a higher count signifies the fact that the fish is readily available in the market. It also hints that it is popular among the people in that area.<\/p>\n<p style=\"font-size:120%\"> Perch is the most popular type of fish here, followed by Bream.<\/p>","ce80bcb8":"<div class=\"alert alert-success\">\n    \n<ol>    \n<li style=\"font-size:120%;color:black\"><a href=\"#1\" style=\"text-decoration:None\"> Reading our Data and Initial Clean <\/a><\/li>\n    \n<li style=\"font-size:120%;color:black\"><a href=\"#2\" style=\"text-decoration:None\"> Exploratory Data Analysis <\/a><\/li>\n    \n<li style=\"font-size:120%;color:black\"><a href=\"#3\" style=\"text-decoration:None\"> Clustering is an Unsupervised Task <\/a><\/li>\n    \n<li style=\"font-size:120%;color:black\"><a href=\"#4\" style=\"text-decoration:None\"> Let's learn about K-Means <\/a><\/li>\n    \n<li style=\"font-size:120%;color:black\"><a href=\"#5\" style=\"text-decoration:None\"> K-Means Python Implementation<\/a><\/li>\n<\/ol>\n    \n    \n<h2 style=\"color:Black;\">Legend:<\/h2>\n<p style=\"color:Black;font-size:120%\">\ud83c\udfaf: Important Steps or points<\/p>\n<p style=\"color:Black;font-size:120%\">\ud83d\udc8e: Important tips<\/p>\n<p style=\"color:Black;font-size:120%\">\u2b50: Reference Links<\/p>\n<p style=\"color:Black;font-size:120%\">\ud83d\udcc4: Article, thread or informations<\/p>\n<\/div>","fcb33426":"<div class=\"alert alert-success\">\n    <p style=\"color:Black;font-size:120%\">\ud83c\udfaf <strong>Aways Remember!<\/strong> Choosing the number of clusters is also dependent on the Business Decision that you are about to make. Consult with other teams who might have expert domain knowledge to proceed further.<\/p>\n<\/div>    ","0ba83e19":"<div class=\"alert alert-success\">\n    <p style=\"color:Black;font-size:120%\">\ud83c\udfaf Now, this was our short and cute EDA on this data. Maybe in the future, if I get sometime, I will improve this further.<\/p>\n    <p style=\"color:Black;font-size:120%\">\ud83c\udfaf Next, we will have a look into some Unsupervised techniques.<\/p>\n<\/div>    ","43fb7142":"<p style=\"font-size:120%\"> This dataset is a record of <strong>7 common different fish species<\/strong> in fish market sales. <\/p>\n\n<p style=\"font-size:120%\"> <strong>Metadata<\/strong> <\/p>\n\n- Species: Type of Fish\n- Weight: Weight of the Fish in grams\n- Length1: Vertical length of the Fish in centimeters\n- Length2: Diagonal length of the Fish in centimeters\n- Length3: Cross length of the Fish in centimeters\n- Height: Height of the Fish in centimeters\n- Width: Diagonal width of the Fish in centimeters","a6ce8bc7":"<p style=\"font-size:120%\"> When we check the average weight of all the fish, we see that Bream, Whitefish and Pike are relatively heavy. <\/p>\n<p style=\"font-size:120%\"> Another thing to notice here is that, Bream is a popular fish. Maybe people eat this fish during some occasion or celebration!.<\/p>","39ad57bb":"<div class=\"alert alert-block alert-info\" >\n    <a id=\"2\" style=\"text-decoration:None;\">\n    <h1 style=\"text-align:center;font-weight: 20px; color:black;\">\n       Exploratory Data Analysis <\/h1>\n    <\/a>    \n<\/div>","82507e55":" <p style=\"text-align:center; font-size:150%\"><i><strong> \"When life gets you down, you know what you gotta do? Just keep swimming.\" <\/i>\u2013 Dory (Finding Nemo) <\/strong><\/p>","1f6e0385":"<div class=\"alert alert-block alert-info\" >\n    <a id=\"1\" style=\"text-decoration:None;\">\n    <h1 style=\"text-align:center;font-weight: 20px; color:black;\">\n       Reading and Cleaning the Data <\/h1>\n    <\/a>    \n<\/div>","07e215d2":"<p style=\"font-size:120%;\"> Now, is the value of k correct? Is it optimal?<\/p>\n\n<p style=\"font-size:120%;\"> The answer depends on various factors. There are two methods that we can go by to check and verify our understanding.<\/p>\n\n### Elbow Curve:","3e416106":"### Theory:\n\n<p style=\"font-size:120%;\"> The <strong>K-Means algorithm<\/strong> is a simple algorithm capable of clustering datasets very quickly and efficiently, often in just a few iterations. <strong>It was proposed by Stuart Lloyd at Bell labs in 1957<\/strong> as a technique for pulse-code modulation, but it was only published outside of the company in 1982.<\/p>\n\n<p style=\"font-size:120%;\"> In 1965, Edward W.Forgy had published virtually the same algorithm, so <mark>K-Means is sometimes referred to as Lloyd-Forgy.<\/mark><\/p>\n\n### How does it work?\n\n<p style=\"font-size:120%;\"> Well, suppose you were given the centroids. You could easily label all the instances in the dataset by assigning each of them to the cluster whose centroid is the closest. Conversely, if you were given all the instances labels, you could easily locate all the centroids by computing the mean of all the instances for each cluster. But if you were given neither the labels nor the centroids, <mark>we can start by placing the centroids randomly (eg. by picking k instances at random and using their locations as centroids). Then label the instances, update the centroids until centroids stop moving.<\/mark> The algorithm is guaranteed to converge in a finite number of steps; it will not oscillate forever.<\/p>\n\n<img src=\"https:\/\/miro.medium.com\/max\/1280\/1*rwYaxuY-jeiVXH0fyqC_oA.gif\" style=\"display: block; margin-left: auto; margin-right: auto; width: 50%;\"><\/img>\n\n<p style=\"font-size:120%;text-align:center\"> In the above figure, the algorithm converges after a cerain iteration. <\/p>\n\n### Cost Function:\n\n<img src=\"https:\/\/www.saedsayad.com\/images\/Clustering_kmeans_c.png\" style=\"display: block; margin-left: auto; margin-right: auto; width: 50%;height:10%;\"><\/img>\n\n<p style=\"font-size:120%\"> \u2b50 Reference Book: <a href=\"https:\/\/www.oreilly.com\/library\/view\/hands-on-machine-learning\/9781492032632\/\"> Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition <\/a> <\/p>","6c856228":"<div class=\"alert alert-block alert-info\" >\n    <h1 style=\"text-align:center;font-weight: 20px; color:black;\">\n       Table of Contents <\/h1>\n<\/div>","527d5123":"<div class=\"alert alert-block alert-info\" >\n    <a id=\"6\" style=\"text-decoration:None;\">\n    <h1 style=\"text-align:center;font-weight: 20px; color:black;\">\n       Hierarchical Clustering<\/h1>\n    <\/a>    \n<\/div>","429484eb":"### Limits of K-Means algorithm:\n\n<p style=\"font-size:120%;\"> Despite its many merits, most notably being fast and scalable, K-Means is not perfect. As we saw, it is necessary to run the algorithm several times to avoid sub-optimal results, plus you need to specify the clusters, which is quite the hassle. Moreover, K-Means do not behave very well when the clusters have varying sizes, different densities or non-spherical shapes. See the image below.<\/p>\n\n![image.png](attachment:5ab5357d-a08b-4c61-be5c-f975d635cb1f.png)\n\n<p style=\"font-size:120%;\"> As you can see, neither of these solutions is any good. The solution on the left is vetter, but it still chops off 25% of the middle cluster and assigns it to the cluster on the right. The solution on the right is just terrible, even though the inertia is lower. So, depending on the data, different clustering algorithms may perform better. On these type of elliptical clusters, Gaussian mixture model workds great!<\/p>\n\n<p style=\"font-size:120%\"> \u2b50 Reference Book: <a href=\"https:\/\/www.oreilly.com\/library\/view\/hands-on-machine-learning\/9781492032632\/\"> Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition <\/a> <\/p>","b4feb749":"<div class=\"alert alert-block alert-info\" >\n    <a id=\"4\" style=\"text-decoration:None;\">\n    <h1 style=\"text-align:center;font-weight: 20px; color:black;\">\n       Let's learn about K-Means <\/h1>\n    <\/a>    \n<\/div>","5bac94c0":"<div class=\"alert alert-success\">\n    <p style=\"color:Black;font-size:120%\">\ud83c\udfaf In this section, we will look at the K-Means implementation in Python.<\/p>\n    <p style=\"color:Black;font-size:120%\">\ud83c\udfaf The objective here is to find how many different kinds of fish are there in the market. In other words, to find all the possible species of fish.<\/p>\n    <p style=\"color:Black;font-size:120%\">\ud83c\udfaf Even if we are unable to find that, we will atleast try and check what our K-Means model picks up. Let's begin!<\/p>\n<\/div>    ","e9b13e55":"<p style=\"font-size:120%;\"> From the above Silhouette Scores, we can see that after cluster 7, the score does not improve drastically further.<\/p>\n\n<p style=\"font-size:120%;\"> Therefore, it is safe to assume that, there are 7 distinct species in the dataset.<\/p>","dcf25903":"### Theory:\n\n<p style=\"font-size:120%\"> As you enjoy a hike in the mountains, you stumble upon a plant you have never seen before. You look around and you notice a few more. They are not identical, yet they are sufficiently similar for you to know that they most likely belong to the same species (or atleast the same genus). You may need a botanist to tell you what species that is, but you certainly don't need an expert to identify all similar looking objects. This is called <strong>Clustering<\/strong>. It is the task of <mark>identifying similar instances and assign them to clusters<\/mark>, or groups of similar instances.<\/p>\n\n<p style=\"font-size:120%\"> Clustering can be used in a wide variety of applications, including: <\/p>\n\n<ul>\n<li style=\"font-size:120%\"> <strong>For Customer Segmentation:<\/strong> You can cluster customers based on theirpurchases and their activity on your website. This is helpful to understand who your customers are and what they need.<\/li>\n<li style=\"font-size:120%\"> <strong>As a Dimensionality Reduction Technique:<\/strong> Once a dataset has been clustered, it is usually possible to measure each instance's affinity with each cluster (affinity is how well an instance fits into a cluster).<\/li>\n <li style=\"font-size:120%\"> <strong>For Anomaly Detection:<\/strong> Any instance that has a low affinity to a cluster is likely to be an anomaly. For example, if you have clustered the users of your website based on their behavior, you can detect users with unusual number of requests per second. Anomaly detection is particularly helpful in detecting defects in manufacturing, or for fraud detection.<\/li>\n<\/ul>\n\n<p style=\"font-size:120%\"> \u2b50 Reference Book: <a href=\"https:\/\/www.oreilly.com\/library\/view\/hands-on-machine-learning\/9781492032632\/\"> Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition <\/a> <\/p>","c8c5b057":"<div class=\"alert alert-block alert-success\" >\n    <a id=\"3\" style=\"text-decoration:None;\">\n    <h3 style=\"text-align:center;font-weight: 20px; color:black;\">\n       If you like\/fork my work, please consider leaving an upvote or your valuable feedbacks. They will help me grow. Thanks for reading, I hope it helped! \ud83d\ude01\ud83d\udc4d <\/h3>\n    <\/a>    \n<\/div>","29dff30f":"<div class=\"alert alert-block alert-info\" >\n    <a id=\"5\" style=\"text-decoration:None;\">\n    <h1 style=\"text-align:center;font-weight: 20px; color:black;\">\n       K-Means Python Implementation<\/h1>\n    <\/a>    \n<\/div>","9c111edc":"<p style=\"font-size:120%;\"> Here, <mark>we notice that for one of the fish, the weight is 0 grams<\/mark>. That is not possible! Hence, we are going to replace this value with the mean of the weight of this fish. This fish is Roach btw.<\/p>\n\n<p style=\"font-size:120%;\"> Since there are no outliers, we will proceed with standardizing the data.<\/p>\n\n### Standardizing:","f4668555":"### Theory\n\n<p style=\"font-size:120%;\"> <strong>Heirarchial or Agglomerative Clustering<\/strong> is built from bottom up. Think of many tiny bubbles of water attaching one by one into a bigger droplet. That is the idea of this algorithm<\/p>\n\n<p style=\"font-size:120%;\"> At the initial step, it considers each instance as a single cluster. So if we have 159 points in the dataset, there will be 159 clusters initially. Then, from each instance, the nearest instance is picked and is coaleased to convert into a bigger cluster.<\/p>\n\n<p style=\"font-size:120%;\"> Linkage is a concept that helps identify which instance should be fused with which cluster based on some rules. You can learn more about them <a href=\"https:\/\/www.displayr.com\/what-is-hierarchical-clustering\/\" style=\"text-decoration:none\">here<\/a>.<\/p>\n\n<p style=\"font-size:120%;\"> Now, since this is a bottom up approach, it has to iteratively calculate the Eucledian Distances between all the clusters and each instance. <mark>This makes Hierarchical Clustering relatively slower than Kmeans.<\/mark><\/p>\n\n<p style=\"font-size:120%;\"> However, unlike KMeans, <mark>we do not need to choose the initial value of 'k' or decide where our centroids will be placed.<\/mark><\/p>\n\n<p style=\"font-size:120%;\"> This method is not suggested for larger datasets.<\/p>","53abf669":"<p style=\"font-size:120%;\"> The Elbow Curve shows the sum of squared distances of each point from the clusters (This can be found out using <strong>kmeans.inertia_<\/strong> method) versus the number of clusters.<\/p>\n\n<p style=\"font-size:120%;\"> It is evident from this plot that beyond 7, the sum of squared distance do no change significantly. This might be the elbow! Hence, we can set the <strong>n_clusters to 7<\/strong>.<\/p>","1d8994eb":"<div class=\"alert alert-block alert-info\" >\n    <a id=\"7\" style=\"text-decoration:None;\">\n    <h1 style=\"text-align:center;font-weight: 20px; color:black;\">\n       Hierarchical Clustering Python Implementation<\/h1>\n    <\/a>    \n<\/div>","ac28c23b":"<img src=\"https:\/\/i.stack.imgur.com\/SeaSS.png\" style=\"display: block; margin-left: auto; margin-right: auto; width: 50%;\"><\/img>\n\n<p style=\"font-size:120%;text-align:center\"> Above Figure is a simple example of clustering. (Voronoi tessellation)<\/p>","207851ab":"<div class=\"alert alert-success\">\n    <p style=\"color:Black;font-size:120%\">\ud83c\udfaf <strong>Removing Outliers<\/strong> is a very important step in clustering as the models are highly influenced by them.<\/p>\n<\/div>    ","517e6418":"### Model Building:\n\n<p style=\"font-size:120%;\"> Initially in this step, we are going to build the model using an arbitrary value of <strong>\"k\"<\/strong> (in this case 4).<\/p>\n\n<p style=\"font-size:120%;\"> Assume that we do not know that the number of species are 7.<\/p>","ecabbfa9":"<div class=\"alert alert-block alert-info\" >\n    <h1 style=\"text-align:center;font-weight: 20px; color:black;\">\n       Understanding our Data <\/h1>\n<\/div>","386b1fe5":"<div class=\"alert alert-block alert-info\" >\n    <h1 style=\"text-align:center;font-weight: 20px; color:black;\">\n       Fish Market Analysis<\/h1>\n<\/div>"}}