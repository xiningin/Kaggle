{"cell_type":{"7ea4ff5b":"code","b03e6149":"code","7d0d98cf":"code","eb4965c8":"code","a751c847":"code","b61f0d0e":"code","c340882f":"code","fb54d566":"code","09f8e7b3":"code","076bcbfa":"code","933647a3":"code","9a0c5799":"code","384728b8":"code","141c29ce":"code","b86a5e36":"markdown","6d49d2fa":"markdown"},"source":{"7ea4ff5b":"!nvcc --version\n!python --version","b03e6149":"# Double check the versions aboce and modify \"cuda110\" to match whatever you have. More information here\n# https:\/\/github.com\/google\/jax\n!pip install --upgrade \"jax[cuda110]\" -f https:\/\/storage.googleapis.com\/jax-releases\/jax_releases.html","7d0d98cf":"# Copy the stuff we need to the working directory. This just makes life easier\nimport shutil\nshutil.copytree(\"..\/input\/perceiverio\/perceiver\",\".\/perceiver\")","eb4965c8":"# Install the requirements\n!pip install -r .\/perceiver\/requirements.txt","a751c847":"# This just makes sure we're using GPU\nfrom jax.lib import xla_bridge\nprint(xla_bridge.get_backend().platform)","b61f0d0e":"import functools\nimport itertools\nimport pickle\n\nimport haiku as hk\nimport jax\nimport jax.numpy as jnp\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport cv2\nimport imageio\n\nfrom perceiver import perceiver, io_processors","c340882f":"# I moved all the downloading here so that you only have to run this once, the weights can take some time.\n!wget -O sintel_frame1.png https:\/\/storage.googleapis.com\/perceiver_io\/sintel_frame1.png\n!wget -O sintel_frame2.png https:\/\/storage.googleapis.com\/perceiver_io\/sintel_frame2.png\n!wget -O optical_flow_checkpoint.pystate https:\/\/storage.googleapis.com\/perceiver_io\/optical_flow_checkpoint.pystate","fb54d566":"#@title Model construction\n\nFLOW_SCALE_FACTOR = 20\n# The network assumes images are of the following size\nTRAIN_SIZE = (368, 496)\n\ndef optical_flow(images):\n  \"\"\"Perceiver IO model for optical flow.\n\n  Args:\n    images: Array of two stacked images, of shape [B, 2, H, W, C]\n  Returns:\n    Optical flow field, of shape [B, H, W, 2].\n  \"\"\"\n  input_preprocessor = io_processors.ImagePreprocessor(\n      position_encoding_type='fourier',\n      fourier_position_encoding_kwargs=dict(\n          num_bands=64,\n          max_resolution=TRAIN_SIZE,\n          sine_only=False,\n          concat_pos=True,\n      ),\n      n_extra_pos_mlp=0,\n      prep_type='patches',\n      spatial_downsample=1,\n      conv_after_patching=True,\n      temporal_downsample=2)\n\n  encoder = encoder = perceiver.PerceiverEncoder(\n      num_self_attends_per_block=24,\n      # Weights won't be shared if num_blocks is set to 1.\n      num_blocks=1,\n      z_index_dim=2048,\n      num_cross_attend_heads=1,\n      num_z_channels=512,\n      num_self_attend_heads=16,\n      cross_attend_widening_factor=1,\n      self_attend_widening_factor=1,\n      dropout_prob=0.0,\n      z_pos_enc_init_scale=0.02,\n      cross_attention_shape_for_attn='kv',\n      name='perceiver_encoder')\n\n  decoder = perceiver.FlowDecoder(\n      TRAIN_SIZE,\n      rescale_factor=100.0,\n      use_query_residual=False,\n      output_num_channels=2,\n      output_w_init=jnp.zeros,\n      # We query the decoder using the first frame features\n      # rather than a standard decoder position encoding.\n      position_encoding_type='fourier',\n      fourier_position_encoding_kwargs=dict(\n          concat_pos=True,\n          max_resolution=TRAIN_SIZE,\n          num_bands=64,\n          sine_only=False\n      )\n  )\n\n  model = perceiver.Perceiver(\n      input_preprocessor=input_preprocessor,\n      encoder=encoder,\n      decoder=decoder,\n      output_postprocessor=None)\n\n  return model(io_processors.patches_for_flow(images),\n               is_training=False) * FLOW_SCALE_FACTOR\n\n\noptical_flow = hk.transform(optical_flow)","09f8e7b3":"#@title Function to compute flow between pairs of images\n\n# If you encounter GPU memory errors while running the function below,\n# you can run it on the CPU instead:\n# _apply_optical_flow_model = jax.jit(optical_flow.apply, backend=\"cpu\")\n_apply_optical_flow_model = jax.jit(optical_flow.apply)\n\ndef compute_grid_indices(image_shape, patch_size=TRAIN_SIZE, min_overlap=20):\n  if min_overlap >= TRAIN_SIZE[0] or min_overlap >= TRAIN_SIZE[1]:\n    raise ValueError(\n        f\"Overlap should be less than size of patch (got {min_overlap}\"\n        f\"for patch size {patch_size}).\")\n  ys = list(range(0, image_shape[0], TRAIN_SIZE[0] - min_overlap))\n  xs = list(range(0, image_shape[1], TRAIN_SIZE[1] - min_overlap))\n  # Make sure the final patch is flush with the image boundary\n  ys[-1] = image_shape[0] - patch_size[0]\n  xs[-1] = image_shape[1] - patch_size[1]\n  return itertools.product(ys, xs)\n\ndef compute_optical_flow(params, rng, img1, img2, grid_indices,\n                       patch_size=TRAIN_SIZE):\n  \"\"\"Function to compute optical flow between two images.\n\n  To compute the flow between images of arbitrary sizes, we divide the image\n  into patches, compute the flow for each patch, and stitch the flows together.\n\n  Args:\n    params: model parameters\n    rng: jax.random.PRNGKey, not used in this model\n    img1: first image\n    img2: second image\n    grid_indices: indices of the upper left corner for each patch.\n    patch_size: size of patch, should be TRAIN_SIZE.\n  \"\"\"\n  imgs = jnp.stack([img1, img2], axis=0)[None]\n  height = imgs.shape[-3]\n  width = imgs.shape[-2]\n\n  if height < patch_size[0]:\n    raise ValueError(\n        f\"Height of image (shape: {imgs.shape}) must be at least {patch_size[0]}.\"\n        \"Please pad or resize your image to the minimum dimension.\"\n    )\n  if width < patch_size[1]:\n    raise ValueError(\n        f\"Width of image (shape: {imgs.shape}) must be at least {patch_size[1]}.\"\n        \"Please pad or resize your image to the minimum dimension.\"\n    )\n\n  flows = 0\n  flow_count = 0\n\n  for y, x in grid_indices:\n    inp_piece = imgs[..., y : y + patch_size[0],\n                     x : x + patch_size[1], :]\n    flow_piece = _apply_optical_flow_model(params, rng, inp_piece)\n    weights_x, weights_y = jnp.meshgrid(\n        jnp.arange(patch_size[1]), jnp.arange(patch_size[0]))\n\n    weights_x = jnp.minimum(weights_x + 1, patch_size[1] - weights_x)\n    weights_y = jnp.minimum(weights_y + 1, patch_size[0] - weights_y)\n    weights = jnp.minimum(weights_x, weights_y)[jnp.newaxis, :, :,\n                                                jnp.newaxis]\n    padding = [(0, 0), (y, height - y - patch_size[0]),\n               (x, width - x - patch_size[1]), (0, 0)]\n    flows += jnp.pad(flow_piece * weights, padding)\n    flow_count += jnp.pad(weights, padding)\n\n  flows \/= flow_count\n  return flows","076bcbfa":"#@title Load parameters from checkpoint\n\nrng = jax.random.PRNGKey(42)\nwith open(\"optical_flow_checkpoint.pystate\", \"rb\") as f:\n  params = pickle.loads(f.read())\n\nstate = {}","933647a3":"# Download two example frames from the Sintel dataset.\n# These files are obtained from the Sintel dataset test split,\n# downloaded from http:\/\/sintel.is.tue.mpg.de\/downloads.\n# They correspond to MPI-Sintel-testing\/test\/clean\/cave_3\/frame_0001.png\n# and MPI-Sintel-testing\/test\/clean\/cave_3\/frame_0002.png.\n#\n# Citation for Sintel dataset:\n# D. J. Butler, J. Wulff, G. B. Stanley, and M. J. Black.\n# A naturalistic open source movie for optical flow evaluation.\n# European Conf. on Computer Vision (ECCV), 2012.\n# https:\/\/files.is.tue.mpg.de\/black\/papers\/ButlerECCV2012.pdf\n#\n# The Sintel images are originally generated for the Durian Open Movie project\n# and are licensed under the Creative Commons Attribution 3.0 license (https:\/\/durian.blender.org\/sharing\/).\n# The images are copyrighted by the Blender Foundation (https:\/\/durian.blender.org).\n\n\nwith open(\"sintel_frame1.png\", \"rb\") as f:\n  im1 = imageio.imread(f)\nwith open(\"sintel_frame2.png\", \"rb\") as f:\n  im2 = imageio.imread(f)","9a0c5799":"#@title Image Utility Functions\n\ndef normalize(im):\n  return im \/ 255.0 * 2 - 1\n\ndef visualize_flow(flow):\n  flow = np.array(flow)\n  # Use Hue, Saturation, Value colour model \n  hsv = np.zeros((flow.shape[0], flow.shape[1], 3), dtype=np.uint8)\n  hsv[..., 2] = 255\n\n  mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n  hsv[..., 0] = ang \/ np.pi \/ 2 * 180\n  hsv[..., 1] = np.clip(mag * 255 \/ 24, 0, 255)\n  bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n  plt.imshow(bgr)","384728b8":"# Compute optical flow\n\n# Divide images into patches, compute flow between corresponding patches\n# of both images, and stitch the flows together\ngrid_indices = compute_grid_indices(im1.shape)\nflow = compute_optical_flow(params, rng, normalize(im1), normalize(im2), grid_indices)","141c29ce":"# Visualize the computed flow\nvisualize_flow(flow[0])","b86a5e36":"## Optical Flow Colab Starts Here","6d49d2fa":"# **PerceiverIO Optical Flow Notebook Example**\n\n\nThis is a sample notebook I threw together to get DeepMind's Perceiver IO Optical Flow working on Kaggle.\n\nThe perceiver folder from the deepmind repo has been uploaded as a dataset, then imported into this notebook.\nI removed the train and colab folder since they are not needed. I will work on getting the train folder running in a notebook at some point.\n\n**This is not my code, it was copied from the colab folder in** https:\/\/github.com\/deepmind\/deepmind-research\/tree\/master\/perceiver\n\n\nYou will notice there is a cell that outputs the python and cuda version currently running. \nAt the time of making this notebook, cuda was 11.0 and python was 3.7.10\n\nThis corresponds to jax\\[110\\] which needs to be installed.\n\nThe requirements file has been modified to avoid dependency conflicts which haven't been fixed in the original GitHub Repo.\n"}}