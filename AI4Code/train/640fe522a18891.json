{"cell_type":{"b402e0e9":"code","8ef9abfe":"code","d04a4ebc":"code","e6d4397d":"code","3b0878e6":"code","ed4733eb":"code","9f6f6fbc":"code","9dbc0d06":"code","ef8f0b4b":"code","135e14df":"code","e6c26d28":"code","7796994b":"code","00a5537f":"code","4d2e1941":"code","510a365d":"code","25dae09b":"code","0e82a6a7":"code","ba010b7f":"code","5292e3c0":"code","b046bece":"code","b017b837":"code","04a7c0bf":"code","291a708c":"code","dc4cdd19":"code","1d2f4540":"code","b6a2ec0d":"code","11ff1252":"code","1d1969a3":"code","fe197dca":"code","b850e424":"code","bd803c6e":"code","e8ada619":"code","aa7af3c7":"code","302b4a6c":"code","4285c96c":"code","5fabf6a7":"code","fca68231":"code","c68b881b":"code","0ec4e2cb":"code","46814f70":"code","6a9761e7":"code","724657b8":"code","f3108ecc":"code","09240f26":"code","c125fad4":"code","d89b7ebb":"code","1ebeb02c":"code","e49d9188":"code","47a083ee":"code","d33071d3":"code","06b88c94":"code","d70bdebc":"code","91b2b919":"code","6dad48a4":"code","55c3ad26":"code","77af233f":"markdown","84f45d4a":"markdown","ea4cb2cb":"markdown","c4b2b055":"markdown","80058ce4":"markdown","ac5d66b7":"markdown","7d7f735f":"markdown","40e8c4dc":"markdown","f00b4ad2":"markdown","4561f54c":"markdown","c54313ce":"markdown","205a21d1":"markdown","3886ecb3":"markdown","cd98894b":"markdown","8dae8e3d":"markdown","9a30d2e5":"markdown","cba06125":"markdown","8cd1544b":"markdown","5018b643":"markdown","1bbd6915":"markdown","f90e3409":"markdown","710f859d":"markdown","aa2d9753":"markdown","e5fad73f":"markdown","558aef12":"markdown","e22a805a":"markdown","9aa15c18":"markdown","5cffcf87":"markdown","5c41df53":"markdown","cf18cd6b":"markdown","45286647":"markdown","158b8ef9":"markdown","3ba119cb":"markdown","23e98bf3":"markdown","5944786b":"markdown","c5a9c16d":"markdown","65063d69":"markdown","2f6522f9":"markdown"},"source":{"b402e0e9":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom datetime import datetime, date\nimport seaborn as sns\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.linear_model import LinearRegression, Lasso\nfrom sklearn.kernel_ridge import KernelRidge\n\n%matplotlib inline","8ef9abfe":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","d04a4ebc":"print('train data shape: ', train.shape)\nprint('test data shape: ', test.shape)\nprint('feature columns not in test data: ', set(train.columns[:-1]).difference(set(test.columns)))","e6d4397d":"train.isnull().values.any(), test.isnull().values.any()","3b0878e6":"train.dtypes","ed4733eb":"train.describe()","9f6f6fbc":"def transform_time(d):\n    d['hour'] = d['datetime'].apply(lambda x: int(x[11:13]))\n    d['date'] = d['datetime'].apply(lambda x: x[:10])\n    d['weekday'] = d['date'].apply(lambda s: date(*(int(i) for i in s.split('-'))).weekday() + 1)\n    d['month'] = d['date'].apply(lambda s: int(s[5:7]))\n    d['day'] = d['date'].apply(lambda s: int(s[8:10]))\n    d['year'] = d['date'].apply(lambda s: int(s[:4]))\n    # \u6ce8\u610fmonday\u662f0\uff0c sunday\u662f6\uff0c\u6240\u4ee5\u6700\u540e\u52a01\n\ntransform_time(train)\ntrain.head()","9dbc0d06":"train.drop(['datetime', 'date'], axis=1, inplace=True)","ef8f0b4b":"from sklearn.feature_selection import mutual_info_regression\n\ndf_corr = pd.DataFrame(train.corr()['count'])\ndf_corr.columns = ['corr_coef']\nmut_reg = mutual_info_regression(train, train['count'])\ndf_corr['mut_reg'] = mut_reg.tolist()\ndf_corr.sort_values(by='corr_coef', ascending=False)","135e14df":"from scipy.stats import norm, skew\nplt.subplots(1, 2, figsize=(10,4))\nplt.subplot(1, 2, 1)\nsns.distplot(train['count'], fit=norm);\nplt.subplot(1, 2, 2)\nsns.distplot(np.log2(train['count']), fit=norm);\nprint('skewness before transformation', np.abs(skew(train['count'])))\n# transform count\ntrain['count'] = np.log2(train['count'] + 1)\nprint('skewness after transformation', np.abs(skew(train['count'])))","e6c26d28":"sns.distplot(train.loc[train['season']==1]['count'], label='1')\nsns.distplot(train.loc[train['season']==2]['count'], label='2')\nsns.distplot(train.loc[train['season']==3]['count'], label='3')\nplt.legend()","7796994b":"sns.boxplot('season', 'count', data=train);","00a5537f":"sns.boxplot('holiday', 'count', data=train);","4d2e1941":"plt.subplots(1, 4, figsize=(20,4))\nplt.subplot(1, 4, 1)\nsns.boxplot('holiday', 'count', hue='season',  data=train.loc[train['season']==1]);\n\nplt.subplot(1, 4, 2)\nsns.boxplot('holiday', 'count', hue='season',  data=train.loc[train['season']==2]);\n\nplt.subplot(1, 4, 3)\nsns.boxplot('holiday', 'count', hue='season',  data=train.loc[train['season']==3]);\n\nplt.subplot(1, 4, 4)\nsns.boxplot('holiday', 'count', hue='season',  data=train.loc[train['season']==4]);\n\n","510a365d":"train.groupby(['holiday','season'])['count'].median().unstack()","25dae09b":"sns.lineplot('holiday', 'count', hue='season', data=train, estimator=np.median, markers=True,palette=\"ch:2.5,.25\");","0e82a6a7":"sns.boxplot('workingday', 'count', data=train);","ba010b7f":"sns.distplot(train.loc[train['workingday']==0]['count'], label='0')\nsns.distplot(train.loc[train['workingday']==1]['count'], label='1')\n\nplt.legend()","5292e3c0":"train.groupby(['workingday', 'holiday'])['count'].median().unstack()","b046bece":"sns.boxplot('workingday', 'count', data=train, hue='holiday');","b017b837":"sns.lineplot('workingday', 'count', data=train, hue='season', estimator=np.median);","04a7c0bf":"sns.boxplot('weather','count', data=train)","291a708c":"sns.boxplot('season','count', data=train, hue='weather')","dc4cdd19":"train.groupby(['weather', 'season'])['count'].median().unstack()","1d2f4540":"sns.lineplot('season', 'count', data=train, hue='weather');","b6a2ec0d":"tempbin = pd.qcut(train['temp'], 5)\nsns.boxplot(tempbin, 'count', data=train)","11ff1252":"tempbin = pd.qcut(train['temp'], 5)\nsns.boxplot(tempbin, 'count', data=train, hue='season');","1d1969a3":"train.groupby(['season', pd.qcut(train['temp'], 5)])['count'].size().unstack()","fe197dca":"plt.subplot(1,2,1)\nsns.scatterplot('temp', 'atemp', data=train);\nplt.subplot(1,2,2)\nsns.scatterplot('temp', 'atemp', data=test);","b850e424":"df_unusual = test.loc[(test['atemp']<15) & (test['temp']>20)]\nplt.subplot(1,2,1)\nplt.plot(df_unusual.atemp)\nplt.subplot(1,2,2)\nplt.plot(df_unusual.temp)\ndf_unusual","bd803c6e":"humidbin = pd.qcut(train['humidity'], 5)\nsns.boxplot(humidbin, 'count', data=train)","e8ada619":"humidbin = pd.qcut(train['humidity'], 5)\nsns.boxplot(tempbin, 'count', data=train, hue=humidbin)","aa7af3c7":"windbin = pd.qcut(train['windspeed'], 8)\nsns.boxplot(windbin, 'count', data=train)\nplt.xticks(rotation=90);","302b4a6c":"train['bi_humid'] = 0\ntrain.loc[train['humidity'] <=15, 'bi_humid'] = 1","4285c96c":"sns.boxplot('hour', 'count', data=train)","5fabf6a7":"sns.lineplot('weekday', 'count', data=train, hue='holiday')","fca68231":"train.loc[(train.holiday==0) & (train.weekday<=5)]['workingday'].unique(), train.loc[ (train.weekday>=6) ]['workingday'].unique()","c68b881b":"sns.boxplot('month', 'count', data=train, hue='workingday')","0ec4e2cb":"\ntrain['month_working'] = 0\ntrain.loc[(train['month']>4) & (train['workingday']==1), 'month_working'] = 0\ntrain.loc[(train['month']>4) & (train['workingday']==0), 'month_working'] = 1\ntrain.loc[(train['month']<=4) & (train['workingday']==1), 'month_working'] = -1\ntrain.loc[(train['month']<=4) & (train['workingday']==0), 'month_working'] = -2","46814f70":"sns.boxplot('day', 'count', data=train)","6a9761e7":"sns.boxplot('year', 'count', data=train)","724657b8":"df_data = pd.read_csv('..\/input\/train.csv')\ndf_test = pd.read_csv('..\/input\/test.csv')\n\ndf_train = df_data.iloc[:, :-3]\ndf_label = df_data['count']\ntrain_ohc = pd.DataFrame()\ntest_ohc = pd.DataFrame()\n\nX = pd.concat([df_train, df_test]).reset_index(drop=True)\n# log label\ndf_label = np.log2(df_data['count'] + 1)\n# transform tim\ntransform_time(X)\nX.drop(['datetime', 'date', 'atemp', 'day'], axis=1, inplace=True)\n\nX['bi_humid'] = 0\n\nX.loc[X['humidity'] <=15, 'bi_humid'] = 1\n\nX['month_working'] = 0\nX.loc[(X['month']>4) & (X['workingday']==1), 'month_working'] = 0\nX.loc[(X['month']>4) & (X['workingday']==0), 'month_working'] = 1\nX.loc[(X['month']<=4) & (X['workingday']==1), 'month_working'] = -1\nX.loc[(X['month']<=4) & (X['workingday']==0), 'month_working'] = -2\n\nX['weekday_holiday'] = 0\nX.loc[(X['holiday']==0), 'weekday_holiday'] = 1\nX.loc[(X['weekday']<=3) & (X['holiday']==1), 'weekday_holiday'] = 2\nX.loc[(X['weekday']>3) & (X['month']<=5) & (X['workingday']==1), 'weekday_holiday'] = 3\nX.loc[(X['weekday']>5) & (X['holiday']==1), 'weekday_holiday'] = 4\n\n#X.drop(['weekday'], axis=1, inplace=True)\n\nclass_features = [\n    'season', 'weather', 'month', 'year', 'hour', 'weekday', 'weekday_holiday', 'month_working'\n]\n\n# data_ohc = pd.get_dummies(X, columns=class_features, drop_first=True)\ndef ohc(data, columns):\n    for col in columns:\n        temp = pd.get_dummies(X[col], prefix=col+'_', drop_first=True)\n        data = pd.concat([data, temp], axis=1)\n        data.drop(col, axis=1, inplace=True)\n    return data\n\ndata_ohc = ohc(X, class_features)\n","f3108ecc":"data_ohc.head()","09240f26":"# shuffle and split train and test\n# data_ohc = data_ohc.sample(frac=1).reset_index(drop=True)\ntrain_ohc = data_ohc[:df_train.shape[0]]\ntest_ohc = data_ohc[df_train.shape[0]:]\n\n\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nscaler = StandardScaler()\nXtrain_ohc = scaler.fit_transform(train_ohc)\nXtest_ohc = scaler.transform(test_ohc)\n\n# to dataframe with column names\ntrain_ohc = pd.DataFrame(Xtrain_ohc, columns=train_ohc.columns)\ntest_ohc = pd.DataFrame(Xtest_ohc, columns=test_ohc.columns)\n\ntrain_ohc['count'] = df_label\nall_features = test_ohc.columns","c125fad4":"# try linear regression\nmodel_base = LinearRegression()\nmodel_base.fit(train_ohc[all_features], train_ohc['count'])\nkf = KFold(n_splits=3, shuffle=True, random_state=42)\ncv = np.sqrt(-cross_val_score(model_base, train_ohc[all_features], train_ohc['count'], cv=kf, scoring='neg_mean_squared_error').mean())\ncv","d89b7ebb":"from sklearn.tree import DecisionTreeRegressor\ndt = DecisionTreeRegressor()\ndt.fit(train_ohc[all_features], train_ohc['count'])\nkf = KFold(n_splits=3, shuffle=True, random_state=42)\ncv = np.sqrt(-cross_val_score(dt, train_ohc[all_features], train_ohc['count'], cv=kf, scoring='neg_mean_squared_error').mean())\ncv","1ebeb02c":"from sklearn.preprocessing import PolynomialFeatures\npoly = PolynomialFeatures(degree=3)\nX = poly.fit_transform(train_ohc[all_features])\ny = train_ohc['count']","e49d9188":"all_features_after_poly = poly.get_feature_names(all_features)","47a083ee":"from sklearn.linear_model import Ridge, Lasso\ndef try_model1(features, data=train, target='count', alpha=1, degree=3):\n    X = data\n    y = target\n    \n    # model_lin = KernelRidge(alpha=alpha, kernel='polynomial', degree=degree)\n    model_lin = Lasso(alpha=0.1)\n    kf = KFold(n_splits=3, shuffle=True, random_state=42)\n    cv1 = np.sqrt(-cross_val_score(model_lin, X, y, cv=kf, scoring='neg_mean_squared_error').mean())\n#     cv2 = -cross_val_score(model_ker, X, y, cv=kf, scoring='neg_mean_squared_error').mean()\n    print('average cross validation score', cv1)\n    return model_lin\n#     print('Kernel Ridge', cv2)\n\n\nmodel = try_model1(data=X, features=all_features, target=y)","d33071d3":"model = Lasso(alpha=0.1)\nmodel.fit(X, y)","06b88c94":"feature_imp = pd.DataFrame({'feature':all_features_after_poly, 'weight':model.coef_}).sort_values(by='weight', ascending=False)","d70bdebc":"feature_imp[np.abs(feature_imp['weight']) > 0.03]","91b2b919":"# from sklearn.model_selection import GridSearchCV\n\n# gs = GridSearchCV(KernelRidge(kernel='polynomial'), scoring=\"neg_mean_squared_error\", cv=3, verbose=3,\n#                   param_grid={\"degree\": [i for i in range(1, 6)], \n#                               \"alpha\":[i*0.1 for i in range(1, 11)]}, )\n# gs.fit(train_ohc[test_ohc.columns], train_ohc['count'])","6dad48a4":"# gs.best_params_, gs.best_score_","55c3ad26":"# model = KernelRidge(alpha=1., kernel='polynomial', degree=3)\n# model.fit(train_ohc[test_ohc.columns], train_ohc['count'])\n\npred = model.predict(poly.transform(test_ohc))\n# transform pred back np.log2(df_data['count'] + 1)\npred = 2 ** pred - 1\n# save result\npd.DataFrame({'datetime': df_test.datetime, 'count': pred}).to_csv('submission.csv', index=False, header=True)","77af233f":"### temp vs count","84f45d4a":"### windspeed vs count","ea4cb2cb":"### season, temp vs count","c4b2b055":"- the distribution of season 1 is very different from ohter seasons\n- other seasons have similar distribution","80058ce4":"### holiday vs count","ac5d66b7":"count increases over season","7d7f735f":"### workingday vs count","40e8c4dc":"- only in season 4, count on holiday is slighly higher than count on non-holiday\n- in season 2, count on holiday is much lower than count on non-holiday\n- season 1 and 3, count on holiday is slightly lower than count on non-holiday","f00b4ad2":"## Extract time information","4561f54c":"# Part1. EDA","c54313ce":"### weekday vs count","205a21d1":"### hour vs count","3886ecb3":"- the error come to sense when using decision trees, basic linear regression dont work well, suggests the relationship is not linear\n- throught EDA, we see feature interations, try use kernel to construct high order features, and also use ridge to control the tendency of overfitting with large number of features","cd98894b":"### year vs count","8dae8e3d":"count is slightly higher on holidays","9a30d2e5":"### season vs count","cba06125":"### temp vs atemp","8cd1544b":"### workingday, holiday vs count","5018b643":"### month vs count","1bbd6915":"### day vs count","f90e3409":"## Linear and non-linear relationships","710f859d":"- before may, count on wokringday is higher than not working day\n- after may, count on wokringday is lower than not working day","aa2d9753":"### Count distribution","e5fad73f":"highly correlated, but in test, there are unusual temp or atemp","558aef12":"when holiday=1, workingday=0","e22a805a":"- most important positive related feature is \n    - interaction term between temp and month_working__-1\n    - interaction term between workingday and hour 6,7,8\n    - month_working__1\n    - year__2012 month_working__-1^2\n- most important negative related feature is \n    - interaction term between workingday and hour1,2,3\n- hour is very important as a single predictor (hour^3==hour, lasso randomly selects the feature that has the same content)","9aa15c18":" when humidity < 15, count increase as humidity increases, else, count doesn't change much","5cffcf87":"after log transformation, skewness of count decreases","5c41df53":"hour, temp, atemp, year, month, season, windspeed have larger impact on count","cf18cd6b":"# train with different models","45286647":"### humidity vs count","158b8ef9":"drop datetime","3ba119cb":"overfitting","23e98bf3":"### workingday, season vs count","5944786b":"### holiday, season vs count","c5a9c16d":"- all unusual point belong to 2012-08-17, according to weather, atemp seems missing\n- since atemp and temp are highly correlated, remove atemp","65063d69":"## Count Correlations","2f6522f9":"### weather vs count"}}