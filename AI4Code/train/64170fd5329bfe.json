{"cell_type":{"263a2316":"code","01de9f70":"code","b080def8":"code","3cb162de":"code","1ddeaa1b":"code","85d2be7d":"code","bbbc5156":"code","c6567dfb":"code","df780c6e":"code","837adf28":"code","f9640435":"code","746b2600":"code","e8f040d5":"code","83891727":"code","8fcfa036":"code","1e676279":"code","17ab0455":"code","296257cc":"code","419237cc":"code","0f017a0e":"code","ecf185ae":"code","98b5f038":"code","874fe589":"code","a9fadf85":"code","7d97a8bd":"code","c590b0bc":"code","27318f48":"code","dbbb328f":"code","8ad0b000":"code","ff2cac09":"code","31ecfc27":"code","d3dc0871":"markdown","89ab6083":"markdown","12776a22":"markdown","bc444cb4":"markdown","af8b05cc":"markdown","98e09d59":"markdown","dc657d12":"markdown","eb5c6259":"markdown","4fd0407d":"markdown","01190b34":"markdown","9493823d":"markdown","381a09ef":"markdown","3f992b9c":"markdown","202b6aa5":"markdown","a68de220":"markdown","9f6f8906":"markdown","408185ce":"markdown","40058bfe":"markdown"},"source":{"263a2316":"import pandas as pd\nimport numpy as np","01de9f70":"# Reading the Training Data\ndocs = pd.read_table('..\/input\/sms-data-labelled-spam-and-non-spam\/SMSSpamCollection',names = ['Class', 'sms'])\ndocs.head()","b080def8":"# Number of SMS\nlen(docs)","3cb162de":"# Counting spam and ham instances\ndocs['Class'].value_counts()","1ddeaa1b":"docs['Class'].value_counts(normalize = True)*100","85d2be7d":"# Mapping class labels to 0 and 1\ndocs['Class'] = docs['Class'].map({'ham':0,'spam':1})\ndocs.head()","bbbc5156":"X = docs.sms\ny = docs.Class\nprint(X.shape)\nprint(y.shape)","c6567dfb":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 1)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","df780c6e":"# Vectorizing the each corpus of documnent and removing stop words\nfrom sklearn.feature_extraction.text import CountVectorizer","837adf28":"# Instantiate an object of CounVectorizer Class\nvect = CountVectorizer(stop_words = 'english')\n\n# Fitting of Training Dataset\nvect.fit(X_train)","f9640435":"doc_feature = vect.vocabulary_\ncount = 0\nfor i in doc_feature:\n    print(i)\n    count = count + 1\n    if (count == 10):\n        break","746b2600":"# Vocab Size\nlen(vect.vocabulary_)","e8f040d5":"# Transforming the Training and Test Dataset\nX_train_transformed = vect.transform(X_train)\nX_test_transformed = vect.transform(X_test)","83891727":"print(X_train_transformed)","8fcfa036":"print(X_test_transformed)","1e676279":"from sklearn.naive_bayes import MultinomialNB\n\n# Instantiate an object the NB Model\nmnb = MultinomialNB()\n\n# Fitting the Model\nmnb.fit(X_train_transformed, y_train)\n\n# Predict Class\ny_pred_class = mnb.predict(X_test_transformed)\n\n# Predict Probabilities\ny_pred_proba = mnb.predict_proba(X_test_transformed)\n","17ab0455":"print(y_pred_class)","296257cc":"print(y_pred_proba)","419237cc":"y_pred_proba[:,1]","0f017a0e":"print(mnb)","ecf185ae":"from sklearn import metrics\n\n# Print the Overall Accuracy\nmetrics.accuracy_score(y_test,y_pred_class)","98b5f038":"# Confusion Matrix\nconfusion = metrics.confusion_matrix(y_test, y_pred_class)\nconfusion","874fe589":"TN = confusion[0, 0]\nFP = confusion[0, 1]\nFN = confusion[1, 0]\nTP = confusion[1, 1]","a9fadf85":"# Sensitivity : True Positive Rate\nsensitivity = TP\/(TP+FN)\nprint('Sensitivity = ',round((sensitivity),2))","7d97a8bd":"# Specificity : True Negative Rate\n\nspecificity = TN\/(TN+FP)\nprint('Specificity = ',round(specificity,2))","c590b0bc":"# Precision : Liklihood to predict positive (spam)\nprecision = TP \/(TP + FP)\nprint(\"precision = \",round(precision,2))","27318f48":"print(\"PRECISION SCORE :\",metrics.precision_score(y_test, y_pred_class))\nprint(\"RECALL SCORE :\", metrics.recall_score(y_test, y_pred_class))\nprint(\"F1 SCORE :\",metrics.f1_score(y_test, y_pred_class))","dbbb328f":"# creating an ROC curve\nfrom sklearn.metrics import confusion_matrix as sk_confusion_matrix\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred_proba[:,1])\nroc_auc = auc(false_positive_rate, true_positive_rate)","8ad0b000":"# area under the curve\nprint (roc_auc)","ff2cac09":"# matrix of thresholds, tpr, fpr\npd.DataFrame({'Threshold': thresholds, \n              'TPR': true_positive_rate, \n              'FPR':false_positive_rate\n             })","31ecfc27":"# plotting the ROC curve\n%matplotlib inline  \nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC')\nplt.plot(false_positive_rate, true_positive_rate)\nplt.show()","d3dc0871":"### STEP 2 : Building and Evaluating the Model","89ab6083":"> As we know Maximum area coved by the ROC curve is good sign , here we can see 99% Area under the curve is occupied","12776a22":"> Our expectation from ROC Curve was like False Positive Rate to be very less and True Postive Rate to be Very High\nand it seems we have achieved our expectation because we got 99% AUC.","bc444cb4":"> by defauilt train_size = 0.75 , train data 75% and Test data 25%","af8b05cc":"> There is 96% Chances are there that Model will predict a message as spam","98e09d59":"> If we look back to the problem statement, We are fine if some of the Spams are classified as Hams, but it will not be good if an important Ham is classified as Spam by our model. So our motive is to maximise Specificity.\n\n\n> ***The Important matrics for this problem statement is Specificity which 99% which is very Good.***","dc657d12":"### Splitting into Train and Test","eb5c6259":"> spam rate is basically 13.4% ","4fd0407d":"> Sensitivity is 95% , it means Model can predict 95% of spam message accurately.","01190b34":"### Convert to X and y","9493823d":"> Model Accuarcy is 98% However we concered about individual class predictability accuracy","381a09ef":"> **Specificity is 99% it means the Model is able to accurate predict 99% of ham SMS.**","3f992b9c":"## **SMS Spam Classifier: Multinomial Naive Bayes**\n\nThe notebook is divided into the following sections:\n1. Importing and preprocessing data\n2. Building the model: Multinomial Naive Bayes\n    - Model building \n    - Model evaluation","202b6aa5":"### **ROC CURVE**","a68de220":"### STEP 1: Importing and Preprocessing Data","9f6f8906":"### *Vectorization*","408185ce":"> By defalut alpha is 1 used for Smoothing","40058bfe":"### Model Evaluation"}}