{"cell_type":{"57392472":"code","18b19bb8":"code","b8595da3":"code","3a651321":"code","5b42c969":"code","e7cbc85e":"code","aa234d16":"code","86dda244":"code","9e1da6fd":"code","ed18a614":"code","7566c945":"code","673ddb09":"code","857c24a2":"code","0fce0a28":"code","111f393c":"code","04350175":"code","5dfdffcf":"code","23b77dd3":"code","9249500b":"code","c74fbbad":"code","fea2d9dc":"code","ef6b74a0":"code","2b4fe9d1":"code","c9ee936a":"code","d2da2880":"code","89d21e3f":"code","7d667db7":"code","a3d2c67d":"code","2c669bd4":"code","2d4a6246":"code","06d83231":"code","feb792cc":"code","b916e09e":"code","6d664d98":"code","cd300427":"code","f6aad507":"code","c1a222b1":"code","17b06594":"code","89b82530":"code","8d1f5ada":"code","a3db1536":"code","c33d0616":"code","05cc6d57":"code","14c7dd08":"code","0995a803":"code","d9acaa8b":"code","102a0d25":"markdown","bef57b43":"markdown","4430351c":"markdown","df585f2b":"markdown","a8bab038":"markdown","7379e356":"markdown","c0ea7227":"markdown","51372088":"markdown","f57caa6c":"markdown","5dbf7c54":"markdown","b4725f53":"markdown","5cac7025":"markdown","1630711d":"markdown","6b0bfceb":"markdown","deb59b91":"markdown","d23cc5c5":"markdown","0b95fe18":"markdown","dd2291ae":"markdown","d2666746":"markdown","b10748ef":"markdown","d1732567":"markdown","a0b16688":"markdown","0bed7a31":"markdown","e995d341":"markdown","8ff589d5":"markdown","4f0fbfa9":"markdown","fb272226":"markdown","b764eddf":"markdown","9f483ae6":"markdown","eb2ca151":"markdown","c12c82f2":"markdown","d3d3ed32":"markdown"},"source":{"57392472":"import numpy as np\nimport pandas as pd \nimport keras\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport random\nimport os\nprint(os.listdir(\"..\/input\"))\n","18b19bb8":"# assign FAST_RUN=True to train the model with three epochs\nFAST_RUN = False\n\n# input image dimensions\nIMAGE_WIDTH=128\nIMAGE_HEIGHT=128\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n\n# red, green and blue channels\nIMAGE_CHANNELS=3","b8595da3":"# get a list of file names from the train folder\nfilenames = os.listdir(\"..\/input\/train\/train\")\nfilenames","3a651321":"# an empty list which will contain all the labels of the train images.\n# for example: for cat.8937.jpg- 0 will be appended to the list. for dog.695.jpg- 1 will be \n# appended to the list\ncategories = []\nfor filename in filenames:\n    \n    # split the filename using delimiter '.'.\n    # for example, 'cat.8937.jpg' will be splitted into 'cat','8937','jpg'. we will take the\n    # first string 'cat' as the category of that image\n    category = filename.split('.')[0]\n    \n    # We will label all the images with dog photos as 1's and cat photos as 0's\n    if category == 'dog':\n        categories.append(1)\n    else:\n        categories.append(0)\n\n# we will create a dataframe which will contain the filenames and the labels of our train set\ndf = pd.DataFrame({\n    'filename': filenames,\n    'category': categories\n})","5b42c969":"df.head()","e7cbc85e":"df.tail()","aa234d16":"# create a barplot showing the amount of cat and dog pictures\ndf['category'].value_counts().plot.bar()","86dda244":"# randomly choose an image for display\nsample = random.choice(filenames)\nimage = load_img(\"..\/input\/train\/train\/\"+sample)\nplt.imshow(image)","9e1da6fd":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n\nmodel = Sequential()\n\n# layer 1\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\nmodel.add(BatchNormalization())\n\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n#layer 2\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n#layer 3\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n#fully connected layer\nmodel.add(Flatten())\n\nmodel.add(Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(2, activation='softmax')) # 2 because we have cat and dog classes","ed18a614":"model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n\nmodel.summary()","7566c945":"from keras.callbacks import EarlyStopping, ReduceLROnPlateau","673ddb09":"earlystop = EarlyStopping(patience=10)","857c24a2":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","0fce0a28":"callbacks = [earlystop, learning_rate_reduction]","111f393c":"df[\"category\"] = df[\"category\"].replace({0: 'cat', 1: 'dog'}) ","04350175":"# do a train-validation split on the whole set.\ntrain_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)\n\n# drop the indexes of train and validation dataframe\ntrain_df = train_df.reset_index(drop=True)\nvalidate_df = validate_df.reset_index(drop=True)","5dfdffcf":"# see the amount of cat and dog photos in the train dataframe\ntrain_df['category'].value_counts().plot.bar()","23b77dd3":"# see the amount of cat and dog photos in the train dataframe\nvalidate_df['category'].value_counts().plot.bar()","9249500b":"# get the total amount of data in train and validation set\ntotal_train = train_df.shape[0]\ntotal_validate = validate_df.shape[0]\n\n# set the minibatch size to 15\nbatch_size=15","c74fbbad":"# ImageDataGenerator?","fea2d9dc":"#  Generate batches of tensor image data with real-time data augmentation.\n#  The data will be looped over (in batches)\n\n# Degree range for random rotations is 15\n# rescaling factor is 1\/255, meaning that the image pixel values will be multiplied by 1\/255\n# Shear angle in counter-clockwise direction in degrees is 0.1\n# Range for random zoom is 0.2\n# Randomly flip inputs horizontally\n# width_shift_range 0.1 fraction of total width\n# height_shift_range 0.1 fraction of total height\ntrain_datagen = ImageDataGenerator(\n    rotation_range=15,\n    rescale=1.\/255,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)","ef6b74a0":"# train_datagen.flow_from_dataframe?","2b4fe9d1":"# Takes the dataframe and the path to a directory\n#  and generates batches of augmented\/normalized data.\n\n# target_size: The dimensions to which all images found will be resized\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df, \n    \"..\/input\/train\/train\/\", \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","c9ee936a":"# we will definitely not need to zoom, shear, or any kind of bullshit to increase validation\n# set but we will divide the pixel values by 255\n\nvalidation_datagen = ImageDataGenerator(rescale=1.\/255)\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    validate_df, \n    \"..\/input\/train\/train\/\",\n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","d2da2880":"# here we will create a dataframe with one row from the training dataframe for demonstrating\n# how the datagenerator works\nexample_df = train_df.sample(n=1).reset_index(drop=True)\nexample_generator = train_datagen.flow_from_dataframe(\n    example_df, \n    \"..\/input\/train\/train\/\", \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical'\n)","89d21e3f":"# we will generate 15 random image from our example data generator and show them using\n# matplotlib\nplt.figure(figsize=(12, 12))\nfor i in range(0, 15):\n    plt.subplot(5, 3, i+1)\n    #on each iteration of the for loop, the generator returns the same amount of random \n    #images as the original dataframe on which the generator was created\n    for X_batch, Y_batch in example_generator:\n        #get the first image of the generated batch\n        image = X_batch[0]\n        plt.imshow(image)\n        break\nplt.tight_layout()\nplt.show()","7d667db7":"if(os.path.isfile('saved_model\/history.csv') and pd.read_csv('saved_model\/history.csv').shape[0]>0):\n    iteration_to_be_loaded=pd.read_csv('saved_model\/history.csv').shape[0]-1\n    model.load_weights(\"saved_model\/model_\"+str(iteration_to_be_loaded)+\".h5\")\n    print(\"saved_model\/model_\"+str(iteration_to_be_loaded)+\".h5\"+\" loaded!\")","a3d2c67d":"epochs=3 if FAST_RUN else 50\nhistory = model.fit(\n    train_generator, \n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=total_validate\/\/batch_size,\n    steps_per_epoch=total_train\/\/batch_size,\n    callbacks=callbacks\n)","2c669bd4":"# assert(False)","2d4a6246":"model.save_weights(\"saved_model\/model.h5\")\n\nimport pickle\nwith open('saved_model\/history.pickle', 'wb') as f:\n    pickle.dump(history, f)","06d83231":"model.load_weights(\"saved_model\/model.h5\")","feb792cc":"import pickle\nwith open('saved_model\/history.pickle','rb') as f:\n    history = pickle.load(f)","b916e09e":"# create a figure with two subplots in 2 rows and one column\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n\n#draw losses on the first subplot\n# plot the training loss\nax1.plot(history.history['loss'], color='b', label=\"Training loss\")\n#plot the validation loss\nax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n\nax1.set_xticks(np.arange(1, epochs, 1))\nax1.set_yticks(np.arange(0, 1, 0.1))\n\n#draw accuracy on the second subplot\n# training accuracy\nax2.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n# validation accuracy\nax2.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n\nax2.set_xticks(np.arange(1, epochs, 1))\n\nlegend = plt.legend(loc='best', shadow=True)\nplt.tight_layout()\nplt.show()","6d664d98":"test_filenames = os.listdir(\"..\/input\/test1\/test1\")\ntest_df = pd.DataFrame({\n    'filename': test_filenames\n})\nnb_samples = test_df.shape[0]","cd300427":"test_gen = ImageDataGenerator(rescale=1.\/255)\n\n#remember to not shuffle the test set\ntest_generator = test_gen.flow_from_dataframe(\n    test_df, \n    \"..\/input\/test1\/test1\/\", \n    x_col='filename',\n    y_col=None,\n    class_mode=None,\n    target_size=IMAGE_SIZE,\n    batch_size=batch_size,\n    shuffle=False\n)","f6aad507":"predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples\/batch_size))","c1a222b1":"predict","17b06594":"test_df['category'] = np.argmax(predict, axis=-1)","89b82530":"test_df['category']","8d1f5ada":"label_map = dict((v,k) for k,v in train_generator.class_indices.items())\ntest_df['category'] = test_df['category'].replace(label_map)","a3db1536":"test_df['category']","c33d0616":"test_df['category'] = test_df['category'].replace({ 'dog': 1, 'cat': 0 })","05cc6d57":"test_df['category'].value_counts().plot.bar()","14c7dd08":"sample_test = test_df.head(18)\nsample_test.head(18)","0995a803":"plt.figure(figsize=(12, 24))\n\n# iterrows() will return index and each row of a dataframe\nfor index, row in sample_test.iterrows():\n    filename = row['filename']\n    category = row['category']\n    img = load_img(\"..\/input\/test1\/test1\/\"+filename, target_size=IMAGE_SIZE)\n    plt.subplot(6, 3, index+1)\n    plt.imshow(img)\n    plt.xlabel(filename + '(' + \"{}\".format(category) + ')' )\nplt.tight_layout()\nplt.show()","d9acaa8b":"submission_df = test_df.copy()\nsubmission_df['id'] = submission_df['filename'].str.split('.').str[0]\nsubmission_df['label'] = submission_df['category']\nsubmission_df.drop(['filename', 'category'], axis=1, inplace=True)\n# I added this line\nsubmission_df=submission_df.astype({'id': 'int32'})\nsubmission_df=submission_df.sort_values('id',ascending=True)\n\nsubmission_df.to_csv('submission.csv', index=False)","102a0d25":"* **Input Layer**: It represent input image data. It will reshape image into single diminsion array. Example your image is 64x64 = 4096, it will convert to (4096,1) array.\n* **Conv Layer**: This layer will extract features from image.\n* **Pooling Layer**: This layerreduce the spatial volume of input image after convolution.\n* **Fully Connected Layer**: It connect the network from a layer to another layer\n* **Output Layer**: It is the predicted values layer. ","bef57b43":"# Create Testing Generator","4430351c":"# Prepare data","df585f2b":"# Prepare Testing Data","a8bab038":"##### my understanding on the last layer:\nwe will use a softmax activation on the last layer when we have categorical dependent variable. otherwise, we will use a normal dense layer","7379e356":"Uncomment the following cell to run training","c0ea7227":"From our data we have 12000 cats and 12000 dogs","51372088":"# Visualize Training","f57caa6c":"**Early Stop**\n\nTo prevent over fitting we will stop the learning after 10 epochs and val_loss value not decreased","5dbf7c54":"Because we will use image genaretor `with class_mode=\"categorical\"`. We need to convert column category into string. Then imagenerator will convert it one-hot encoding which is good for our classification. \n\nSo we will convert 1 to dog and 0 to cat","b4725f53":"# Build Model\n\n<img src=\"https:\/\/i.imgur.com\/ebkMGGu.jpg\" width=\"100%\"\/>","5cac7025":"Seem to be nice ","1630711d":"# Submission","6b0bfceb":"### Visualize Result","deb59b91":"# Predict","d23cc5c5":"# See how our generator work","0b95fe18":"# See sample image","dd2291ae":"# Define Constants","d2666746":"# Fit Model","b10748ef":"# Traning Generator","d1732567":"# Import Library","a0b16688":"We will convert the predict category back into our generator classes by using `train_generator.class_indices`. It is the classes that image generator map while converting data into computer vision","0bed7a31":"### See predicted result with images","e995d341":"**Learning Rate Reduction**\n\nWe will reduce the learning rate when then validation accuracy not increase for 2 steps","8ff589d5":"For categoral classication the prediction will come with probability of each category. So we will pick the category that have the highest probability with numpy average max","4f0fbfa9":"# Save Model","fb272226":"From our prepare data part. We map data with `{1: 'dog', 0: 'cat'}`. Now we will map the result back to dog is 1 and cat is 0","b764eddf":"### See Total In count","9f483ae6":"### Validation Generator","eb2ca151":"# Prepare Traning Data","c12c82f2":"# Callbacks","d3d3ed32":"##### my understanding on loss function:\nwe will use categorical cross entropy for categorical output. we will use mean squared error for non-categorical output.\n##### my understanding on optimizer:\nwe will use Root Mean Square Propogation for categorical output. For non-categorical output, we will use adam optimization.\n##### my understanding on performance metrics:\nwe will use accuracy for categorical output. We will use mean absolute error for non-categorical output"}}