{"cell_type":{"4238cd10":"code","32fd4c74":"code","6bb40e38":"code","edf26eaf":"code","732cb7a9":"code","77af9a90":"code","6d0878de":"code","40849a4e":"code","18bbea27":"code","cd47cbcc":"code","a10dbc48":"code","20950a89":"code","9ede62bd":"code","e5358576":"code","26a4e2a6":"markdown"},"source":{"4238cd10":"from tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport shutil\nimport os","32fd4c74":"train = pd.read_csv('..\/input\/plant-pathology-2021-fgvc8\/train.csv')\nprint(train.shape)\ntrain.head()","6bb40e38":"seed = 32\ntarget_size = (380, 380)\nbatch_size = 16\ntest_img = '..\/input\/plant-pathology-2021-fgvc8\/test_images'\nsubmission = pd.read_csv('..\/input\/plant-pathology-2021-fgvc8\/sample_submission.csv')\nsubmission.head()","edf26eaf":"import cv2\nimport numpy as np\ndef get_cut_image(image):\n    img = cv2.blur(image,(3,3))\n    copy = np.uint8(img)\n    canny = cv2.Canny(copy, 145, 165)\n    box = np.argwhere(canny>0)\n    y1,x1 = box.min(axis=0)\n    y2,x2 = box.max(axis=0)\n    cut_img = img[y1:y2, x1:x2]\n    cut_img = cv2.resize(cut_img, target_size)\n    cut_img = cut_img.astype(\"float32\")*(1.)\/255\n    return np.array(cut_img)","732cb7a9":"from keras.preprocessing.image import ImageDataGenerator\n\npre = ImageDataGenerator(\n    rescale=1.\/255,\n    brightness_range=[0.5, 1.5],\n    rotation_range=45,\n    shear_range=0.2,\n    zoom_range=0.2, \n    horizontal_flip=True,\n    vertical_flip=True,\n    width_shift_range=0.2,\n    height_shift_range=0.2)\n# pos = ImageDataGenerator(\n# #     rescale=1.\/255,\n#     brightness_range=[0.5, 1.5],\n#     rotation_range=45,\n#     shear_range=0.2,\n#     zoom_range=0.2, \n#     horizontal_flip=True,\n#     width_shift_range=0.2,\n#     height_shift_range=0.2,\n#     preprocessing_function = get_cut_image)","77af9a90":"# # # TTA\npos = ImageDataGenerator(\n#     rescale=1.\/255,\n    brightness_range=[0.5, 1.5],\n    rotation_range=15, #45\n    shear_range=0.2,\n    zoom_range=0.3, #0.2 \n    featurewise_center=False, #\n    featurewise_std_normalization=False, #\n    horizontal_flip=True,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    vertical_flip=True,\n    validation_split= 0.2,\n    preprocessing_function = get_cut_image)","6d0878de":"test_generator = pos.flow_from_dataframe(\n                  submission,\n                  directory = test_img,\n                  x_col = 'image',\n                  y_col = 'labels',\n                  class_mode = \"raw\",\n                  batch_size=batch_size,\n                  target_size = target_size,\n                  color_mode=\"rgb\",\n                  shuffle = False,\n                  seed = seed,)","40849a4e":"import keras\ndef load_model():\n    model_pre = keras.models.load_model(\"..\/input\/k3-0726\/B4(oversample)4Fold_cv_BC_2553.h5\",compile=False) #compile=False\n    return model_pre","18bbea27":"model = load_model()\npred = model.predict(test_generator)","cd47cbcc":"model = load_model()\ntta_steps = 5\npredictions = []\n\nfor i in range(tta_steps):\n    preds = model.predict(test_generator)\n    predictions.append(preds)\n\npred = np.mean(predictions, axis=0)","a10dbc48":"perdict = (pred>0.33)\nn_label = ['complex', 'frog_eye_leaf_spot', 'healthy', 'powdery_mildew', 'rust', 'scab']\nanswer = []\n\nfor i in range(perdict.shape[0]):\n    temp = []\n    for j, k in enumerate(n_label):\n        if perdict[i, j]:\n            temp.append(k)\n    answer.append(temp)\n    \nanswer = [' '.join(n) for n in answer]","20950a89":"np.around(pred, decimals=3, out=None)","9ede62bd":"submission['labels'] = np.array(answer)\nsubmission","e5358576":"submission.to_csv('submission.csv', index=False)","26a4e2a6":"## TTA"}}