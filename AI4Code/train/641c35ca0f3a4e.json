{"cell_type":{"314c7b1c":"code","12e93723":"code","2705c660":"code","8ab1ba40":"code","4958e8e5":"code","013ad767":"code","ea77e38a":"code","53266e80":"code","8257a239":"code","d4dea5a9":"code","56585b36":"code","2ec9661e":"code","00c0503f":"code","15885921":"code","b7c72e9c":"code","fd7a2790":"code","6dfdd148":"code","ef2b5e09":"code","8e35417a":"code","4ceb54e9":"code","f85723d0":"code","1388ebd3":"code","9f132942":"code","fd64b031":"code","1fb12ec7":"code","d34b0017":"code","d98c0508":"code","d2211680":"code","689cbc4e":"code","7baa057b":"code","91c3cc4f":"code","e5024e0e":"code","969acd53":"code","85eb2e44":"code","e18df411":"code","45f7ba9d":"code","345bf263":"code","e2946026":"code","5c4f0067":"code","341ea6f8":"code","1a573551":"code","f21794dd":"code","65198183":"code","e91ba46f":"code","dd011396":"code","d3f80ca7":"markdown","ec7cb0c4":"markdown"},"source":{"314c7b1c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","12e93723":"import re","2705c660":"df_train = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/test.csv')","8ab1ba40":"df_train.head()","4958e8e5":"target = df_train['target']","013ad767":"df_train.drop('target', axis=1, inplace=True)","ea77e38a":"join_df = [df_train, df_test]\nboth_df = pd.concat(join_df, sort=True, keys=['x','y'])","53266e80":"both_df.head()","8257a239":"no_na_df = pd.DataFrame()","d4dea5a9":"no_na_df['text'] =  both_df['text'] + both_df['keyword'].apply(lambda x: ' '+str(x)) + both_df['location'].apply(lambda x: ' '+str(x))","56585b36":"no_na_df['text'] = no_na_df['text'].replace(r'http\\S+', '', regex=True).replace(r'www\\S+', '', regex=True)","2ec9661e":"no_na_df","00c0503f":"from nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()\nstop = stopwords.words('english')","15885921":"from nltk.stem import PorterStemmer\npst = PorterStemmer()","b7c72e9c":"no_na_df['text'] = no_na_df['text'].apply(lambda x: \" \".join(re.split(\"[^a-zA-Z]*\", x)) if x else '')","fd7a2790":"no_na_df['text'] = no_na_df['text'].apply(lambda x: x.lower())","6dfdd148":"no_na_df","ef2b5e09":"no_na_df['text'] = no_na_df['text'].apply(lambda x: ' '.join([lemmatizer.lemmatize(i) for i in x.split() if i not in stop]))","8e35417a":"no_na_df['text'] = no_na_df['text'].apply(lambda x: ' '.join([pst.stem(i) for i in x.split() if i not in stop]))","4ceb54e9":"corpus = np.array(no_na_df['text'])","f85723d0":"corpus1 = np.array(no_na_df.loc['y']['text'])","1388ebd3":"len(no_na_df.loc['x']['text'])","9f132942":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features=1000000)\nX = cv.fit_transform(corpus).toarray()\n","fd64b031":"y = cv.transform(corpus1).toarray()","1fb12ec7":"len(X)","d34b0017":"df_submit = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/sample_submission.csv')\ndf_submit.head()","d98c0508":"from sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB","d2211680":"X_train, X_test, y_train, y_test = train_test_split(X[:7613], target.values, test_size=0.8, random_state=0)","689cbc4e":"from sklearn.naive_bayes import MultinomialNB","7baa057b":"from sklearn.linear_model import RidgeClassifier","91c3cc4f":"from sklearn.tree import DecisionTreeClassifier","e5024e0e":"from sklearn.ensemble import RandomForestClassifier","969acd53":"gnb = RandomForestClassifier(max_depth=10, random_state=0)\nclassifier = gnb.fit(X_train, y_train)\ny_pred = gnb.predict(X_test)","85eb2e44":"print(sum([1 for i in range(len(y_pred)) if y_pred[i]!=y_test[i]]),len(y_pred))","e18df411":"gnb = DecisionTreeClassifier(random_state=0)\nclassifier = gnb.fit(X_train, y_train)\ny_pred = gnb.predict(X_test)","45f7ba9d":"print(sum([1 for i in range(len(y_pred)) if y_pred[i]!=y_test[i]]),len(y_pred))","345bf263":"gnb = RidgeClassifier()\nclassifier = gnb.fit(X_train, y_train)\ny_pred = gnb.predict(X_test)","e2946026":"print(sum([1 for i in range(len(y_pred)) if y_pred[i]!=y_test[i]]),len(y_pred))","5c4f0067":"gnb = GaussianNB()\nclassifier = gnb.fit(X_train, y_train)\ny_pred = gnb.predict(X_test)","341ea6f8":"print(sum([1 for i in range(len(y_pred)) if y_pred[i]!=y_test[i]]),len(y_pred))","1a573551":"gnb = MultinomialNB()\nclassifier = gnb.fit(X_train, y_train)\ny_pred = gnb.predict(X_test)","f21794dd":"print(sum([1 for i in range(len(y_pred)) if y_pred[i]!=y_test[i]]),len(y_pred))","65198183":"gnb = MultinomialNB()\nclassifier = gnb.fit(X[:7613], target.values)\ny_pred = gnb.predict(X[7613:])","e91ba46f":"df_submit['target'] = y_pred","dd011396":"df_submit.to_csv('sample_submission.csv', index=False)","d3f80ca7":"loading data*","ec7cb0c4":"new_dict = dict()\nfor i in unique_keywords:\n    full_data_to_train_list = []\n    for j in full_data_to_train:\n        full_data_to_train_list.append(1 if i in j else 0)\n    new_dict[i] = full_data_to_train_list"}}