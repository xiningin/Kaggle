{"cell_type":{"c293823e":"code","ba961f9f":"code","5998b9ae":"code","880f5733":"code","6eb8c47b":"code","289e95fd":"code","5e98bf81":"code","c059d0df":"code","558cceb7":"code","e10af6a8":"code","5630f4d4":"code","38bd065f":"code","4f7be676":"code","88d265e7":"code","118ec1f1":"code","d1de9a5d":"code","4a5bdd26":"code","883d60c5":"code","689bf6c2":"code","a0f039d9":"markdown"},"source":{"c293823e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ba961f9f":"import random\nfrom sklearn.metrics import mean_squared_error,roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold,StratifiedKFold\nfrom lightgbm import LGBMClassifier\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom sklearn import preprocessing\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib.pyplot as plt\n%matplotlib inline","5998b9ae":"train = pd.read_csv('\/kaggle\/input\/tabular-playground-series-mar-2021\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-mar-2021\/test.csv')\nsub = pd.read_csv('\/kaggle\/input\/tabular-playground-series-mar-2021\/sample_submission.csv')","880f5733":"train.head()","6eb8c47b":"categorical_cols = ['cat'+str(i) for i in range(19)]\ncontinous_cols = ['cont'+str(i) for i in range(11)]","289e95fd":"cols=categorical_cols+continous_cols\ntrain_objs_num = len(train)\ndataset = pd.concat(objs=[train[cols], test[cols]], axis=0)\ndataset_preprocessed = pd.get_dummies(dataset,columns=categorical_cols)\ntrain_preprocessed = dataset_preprocessed[:train_objs_num]\ntest_preprocessed = dataset_preprocessed[train_objs_num:]","5e98bf81":"train_preprocessed.head()","c059d0df":"from tensorflow.keras.layers import Input,Dense,Dropout\nfrom tensorflow.keras import Model\nfrom  tensorflow.keras.regularizers import l2\nimport tensorflow as tf","558cceb7":"len(continous_cols)","e10af6a8":"def get_DAE():\n    # denoising autoencoder\n    inputs = Input((11,))\n    x = Dense(1500, activation='relu')(inputs) # 1500 original\n    x = Dense(1500, activation='relu', name=\"feature\")(x) # 1500 original\n    x = Dense(1500, activation='relu')(x) # 1500 original\n    outputs = Dense(11, activation='relu')(x)\n    model = Model(inputs=inputs, outputs=outputs)\n    model.compile(optimizer='adam', loss='mse')\n\n    return model","5630f4d4":"alldata = pd.concat([train[continous_cols],test[continous_cols]],axis=0)\nprint(alldata.shape)\nautoencoder = get_DAE()\nautoencoder.fit(alldata[continous_cols], alldata[continous_cols],\n                    epochs=20,\n                    batch_size=256,\n                    shuffle=True\n                    )","38bd065f":"test_denoised = test_preprocessed.copy()\ntest_denoised[continous_cols] = autoencoder.predict(test_denoised[continous_cols])\ntrain_denoised = train_preprocessed.copy()\ntrain_denoised[continous_cols] = autoencoder.predict(train_denoised[continous_cols])","4f7be676":"train_denoised['target'] = train.target","88d265e7":"X_train = train_denoised.drop(['target'], axis=1)\ny_train = train_denoised.target\nX_test = test_denoised","118ec1f1":"params={'metric': 'auc', 'reg_alpha': 6.010538011450937, 'reg_lambda': 0.031702113663443346, 'colsample_bytree': 0.27,\n   'subsample': 0.6, 'learning_rate': 0.05, 'max_depth': 100, 'num_leaves': 100, 'min_child_samples': 216,\n   'cat_smooth': 87, 'random_state': 48,'n_estimators': 20000}","d1de9a5d":"preds = np.zeros(test.shape[0])        \nkf = StratifiedKFold(n_splits=10,random_state=48,shuffle=True)                  \nauc=[]   # list contains AUC for each fold  \nn=0   \nfor trn_idx, test_idx in kf.split(X_train,train['target']):\n    X_tr,X_val=X_train.iloc[trn_idx],X_train.iloc[test_idx]\n    y_tr,y_val=train['target'].iloc[trn_idx],train['target'].iloc[test_idx]\n    model = LGBMClassifier(**params) \n    model.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=100,verbose=False) \n    preds+=model.predict_proba(X_test)[:, 1]\/kf.n_splits \n    auc.append(roc_auc_score(y_val, model.predict_proba(X_val)[:, 1])) \n    print(n+1,auc[n])                                                                                       \n    n+=1","4a5bdd26":"np.mean(auc)","883d60c5":"sub['target']=preds\nsub.to_csv('submission.csv', index=False)","689bf6c2":"sub","a0f039d9":"------NO NULL VALUES------\n"}}