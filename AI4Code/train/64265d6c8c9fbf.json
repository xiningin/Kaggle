{"cell_type":{"6f1849ca":"code","4da61500":"code","881e70a9":"code","ab36c430":"code","c077ee23":"code","781c810a":"code","f83cb92d":"code","4eabddfc":"code","00bc07a2":"code","4004ae5e":"code","bf1ba9c8":"code","efbeff24":"code","91303d05":"code","a63ce388":"code","88ee3509":"code","b3d94e7a":"code","c1093bcc":"code","02927e73":"code","dd9fc6b4":"code","a9c28f65":"markdown","933a72e6":"markdown"},"source":{"6f1849ca":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4da61500":"train_df = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","881e70a9":"train_df.head()","ab36c430":"train_df.shape","c077ee23":"train_df.describe()","781c810a":"train_df.columns","f83cb92d":"X = train_df.drop('label', axis=1)\ny = train_df['label']\n\n# train test split\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.3, random_state = 100)","4eabddfc":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_valid = scaler.transform(X_valid)","00bc07a2":"# linear model\n\nmodel_linear = SVC(kernel='linear')\nmodel_linear.fit(X_train, y_train)\n\n# predict\ny_valid_pred = model_linear.predict(X_valid)","4004ae5e":"# confusion matrix and accuracy\n\n# accuracy\nprint(\"accuracy:\", metrics.accuracy_score(y_true=y_valid, y_pred=y_valid_pred), \"\\n\")\n\n# confusion matrix\nprint(metrics.confusion_matrix(y_true=y_valid, y_pred=y_valid_pred))","bf1ba9c8":"# non-linear model\n# using rbf kernel, C=1, default value of gamma\n\n# model\nnon_linear_model = SVC(kernel='rbf')\n\n# fit\nnon_linear_model.fit(X_train, y_train)\n\n# predict\ny_valid_pred = non_linear_model.predict(X_valid)","efbeff24":"# confusion matrix and accuracy\n\n# accuracy\nprint(\"accuracy:\", metrics.accuracy_score(y_true=y_valid, y_pred=y_valid_pred), \"\\n\")\n\n# cm\nprint(metrics.confusion_matrix(y_true=y_valid, y_pred=y_valid_pred))","91303d05":"# creating a KFold object with 5 splits \nfolds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n\n# specify range of hyperparameters\n# Set the parameters by cross-validation\nhyper_params = [ {'gamma': [1e-2, 1e-3, 1e-4],\n                     'C': [1, 10, 100, 1000]}]\n\n\n# specify model\nmodel = SVC(kernel=\"rbf\")\n\n# set up GridSearchCV()\nmodel_cv = GridSearchCV(estimator = model, \n                        param_grid = hyper_params, \n                        scoring= 'accuracy', \n                        cv = folds, \n                        n_jobs = -1,\n                        verbose = 1,\n                        return_train_score=True)      \n\n# fit the model\nmodel_cv.fit(X_train, y_train)         ","a63ce388":"# results\ncv_results = pd.DataFrame(model_cv.cv_results_)\ncv_results","88ee3509":"# converting C to numeric type for plotting on x-axis\ncv_results['param_C'] = cv_results['param_C'].astype('int')\n\n# # plotting\nplt.figure(figsize=(16,6))\n\n# subplot 1\/3\nplt.subplot(131)\ngamma_01 = cv_results[cv_results['param_gamma']==0.01]\n\nplt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_test_score\"])\nplt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_train_score\"])\nplt.xlabel('C')\nplt.ylabel('Accuracy')\nplt.title(\"Gamma=0.01\")\nplt.ylim([0.60, 1])\nplt.legend(['test accuracy', 'train accuracy'], loc='lower right')\nplt.xscale('log')\n\n# subplot 2\/3\nplt.subplot(132)\ngamma_001 = cv_results[cv_results['param_gamma']==0.001]\n\nplt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_test_score\"])\nplt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_train_score\"])\nplt.xlabel('C')\nplt.ylabel('Accuracy')\nplt.title(\"Gamma=0.001\")\nplt.ylim([0.60, 1])\nplt.legend(['test accuracy', 'train accuracy'], loc='lower right')\nplt.xscale('log')\n\n\n# subplot 3\/3\nplt.subplot(133)\ngamma_0001 = cv_results[cv_results['param_gamma']==0.0001]\n\nplt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_test_score\"])\nplt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_train_score\"])\nplt.xlabel('C')\nplt.ylabel('Accuracy')\nplt.title(\"Gamma=0.0001\")\nplt.ylim([0.60, 1])\nplt.legend(['test accuracy', 'train accuracy'], loc='lower right')\nplt.xscale('log')\n\nplt.show()","b3d94e7a":"# printing the optimal accuracy score and hyperparameters\nbest_score = model_cv.best_score_\nbest_hyperparams = model_cv.best_params_\n\nprint(\"The best test score is {0} corresponding to hyperparameters {1}\".format(best_score, best_hyperparams))","c1093bcc":"# optimal hyperparameters\nbest_C = 10\nbest_gamma = 0.001\n\n# model\nsvm_final = SVC(kernel='rbf', C=best_C, gamma=best_gamma)\n\n# fit\nsvm_final.fit(X_train, y_train)\n\n# predict\ny_valid_pred = svm_final.predict(X_valid)","02927e73":"# evaluation: CM \nconfusion = metrics.confusion_matrix(y_true=y_valid, y_pred=y_valid_pred)\n\n# measure accuracy\ntest_accuracy = metrics.accuracy_score(y_true=y_valid, y_pred=y_valid_pred)\n\nprint(test_accuracy, \"\\n\")\nprint(confusion)","dd9fc6b4":"test_df = scaler.transform(test_df)\n\npredictions = svm_final.predict(test_df)\n\nmy_submission = pd.read_csv('\/kaggle\/input\/digit-recognizer\/sample_submission.csv')\n\nmy_submission['Label'] = predictions\nmy_submission.to_csv(\"my_submission.csv\",index=False)\nprint(\"Your submission was successfully saved!\")","a9c28f65":"#### RBF Kernel","933a72e6":"#### Linear Kernel"}}