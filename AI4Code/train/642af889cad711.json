{"cell_type":{"3787587e":"code","5f8d1bb3":"code","2061f9ac":"code","818f097c":"code","3c45cfab":"code","8b0d51f3":"code","b5111628":"code","f06107bc":"code","c255d7dd":"code","136ba7af":"code","254032db":"code","c947c1e8":"code","c7e4c36f":"code","eecf0f40":"code","c9cb78c3":"code","27b863a4":"code","60b2abf0":"code","d2d8e1e4":"code","8b39410b":"code","b83100c2":"code","06631e39":"code","00d77234":"code","10ba18ed":"code","4abd089a":"code","33d1e73d":"code","25628cae":"code","fd7a1234":"code","cdfed0b3":"code","fc361451":"markdown","3411496f":"markdown","6619da1e":"markdown","18b0f39a":"markdown","4909e663":"markdown","c6f1f377":"markdown","9d5019fb":"markdown","bcc05c5f":"markdown","7c4d0e15":"markdown"},"source":{"3787587e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5f8d1bb3":"df = pd.read_csv(\"\/kaggle\/input\/mikotojinbatranscript\/discordbot_lines.csv\", delimiter=',', encoding='ISO-8859-2')\ndf.head()","2061f9ac":"df.isnull().sum()","818f097c":"import nltk \nfrom nltk import word_tokenize\nfrom nltk.corpus import stopwords\nimport re\nimport string\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import normalize\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.naive_bayes import GaussianNB","3c45cfab":"##Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(background_color = '#A9A9A9',\n                      height =2000,\n                      width = 2000\n                     ).generate(str(df[\"name\"]))\nplt.rcParams['figure.figsize'] = (10,10)\nplt.axis(\"off\")\nplt.imshow(wordcloud)\nplt.title(\"Mikoto Character\")\nplt.show()","8b0d51f3":"##Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(background_color = 'blue',\n                      height =2000,\n                      width = 2000\n                     ).generate(str(df[\"line\"]))\nplt.rcParams['figure.figsize'] = (12,12)\nplt.axis(\"off\")\nplt.imshow(wordcloud)\nplt.title(\"Mikoto Lines\")\nplt.show()","b5111628":"#Code by Andrea Sindico  https:\/\/www.kaggle.com\/asindico\/love-for-poems\/notebook\n\ndef removePunctuation(x):\n    x = x.lower()\n    x = re.sub(r'[^\\x00-\\x7f]',r' ',x)\n    x = x.replace('\\r','')\n    x = x.replace('\\n','')\n    x = x.replace('  ','')\n    x = x.replace('\\'','')\n    return re.sub(\"[\"+string.punctuation+\"]\", \" \", x)","f06107bc":"#https:\/\/stackoverflow.com\/questions\/51534586\/add-and-remove-words-from-the-nltk-stopwords-list\n\nfrom nltk.corpus import stopwords\n\nstop_words = set(stopwords.words('english'))\n\n#add words that aren't in the NLTK stopwords list\nnew_stopwords = ['off', 'in', 'the', 'of']\nnew_stopwords_list = stop_words.union(new_stopwords)\n\n#remove words that are in NLTK stopwords list\nnot_stopwords = {'analysis', 'ineptitude', 'Warrior'} \nfinal_stop_words = set([word for word in new_stopwords_list if word not in not_stopwords])\n\nprint(final_stop_words)","c255d7dd":"#Code by Andrea Sindico  https:\/\/www.kaggle.com\/asindico\/love-for-poems\/notebook\n\ndef processText(x):\n    x= removePunctuation(x)\n    #x= removeStopwords(x)\n    return x","136ba7af":"from nltk.tokenize import sent_tokenize, word_tokenize\nmikoto = pd.Series([word_tokenize(processText(x)) for x in df['line']])\nmikoto.head(10)","254032db":"#Code by Andrea Sindico  https:\/\/www.kaggle.com\/asindico\/love-for-poems\/notebook\n\nfrom gensim.models import word2vec\n#num_features = 300    # Word vector dimensionality                      \nmin_word_count = 40   # Minimum word count                        \nnum_workers = 4       # Number of threads to run in parallel\ncontext = 10          # Context window size                                                                                    \ndownsampling = 1e-3   # Downsample setting for frequent words\nmodel = word2vec.Word2Vec(mikoto, workers=num_workers, #size=num_features,  was removed\n                          min_count = min_word_count,\n                          window = context, sample = downsampling)","c947c1e8":"from gensim import utils\nimport gensim\nimport logging\nfrom timeit import default_timer\nimport threading\nfrom six.moves import range\nfrom six import itervalues, string_types\nfrom gensim import matutils\nfrom numpy import float32 as REAL, ones, random, dtype\nfrom types import GeneratorType\nfrom gensim.utils import deprecated\nimport os\nimport copy","c7e4c36f":"#I don't know where I found this snippet\n\ndef most_similar(self, positive=None, negative=None, topn=10, restrict_vocab=None, indexer=None):\n        \"\"\"Deprecated, use self.wv.most_similar() instead.\n        Refer to the documentation for :meth:`~gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.most_similar`.\n        \"\"\"\n        return self.wv.most_similar(positive, negative, topn, restrict_vocab, indexer)","eecf0f40":"model.wv.most_similar('Mikoto')","c9cb78c3":"#Since most similar is now in KeyedVectors I copied the snippet below\n#https:\/\/github.com\/RaRe-Technologies\/gensim\/blob\/develop\/gensim\/models\/keyedvectors.py\n\nfrom gensim import models\nfrom gensim.models import KeyedVectors\n\n\nimport gensim.downloader as api\nword_vectors = api.load(\"glove-wiki-gigaword-100\")  # load pre-trained word-vectors from gensim-data \n# Check the \"most similar words\", using the default \"cosine similarity\" measure.\nresult = word_vectors.most_similar(positive=['warrior', 'heroism'], negative=['ineptitude'])\n\nmost_similar_key, similarity = result[0]  # look at the first match\nprint(f\"{most_similar_key}: {similarity:.4f}\")","27b863a4":"#https:\/\/github.com\/RaRe-Technologies\/gensim\/blob\/develop\/gensim\/models\/keyedvectors.py\n\nresult = word_vectors.most_similar(positive=['warships', 'master'], negative=['demands'])\n\nmost_similar_key, similarity = result[0]  # look at the first match\nprint(f\"{most_similar_key}: {similarity:.4f}\") ","60b2abf0":"#Third row, name, 2nd Column line\n\ndf.iloc[3,1]","d2d8e1e4":"#Second row, name, 2nd Column line\n\ndf.iloc[2,1]","8b39410b":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport torchvision\nimport re","b83100c2":"doc_1 = \"And yet it is my ineptitude that demands your presence here. <sigh> I was all but certain that Gerolt and I alone would suffice in this, alas...\"\ndoc_2 = \"You are far too kind. If not for your heroism, Ramza and Alma would have...would have...\"","06631e39":"words_doc1 = {'And', 'yet', 'it', 'is', 'my', 'ineptitude', 'that', 'demands', 'your', 'presence', 'here', 'I', 'was', 'all', 'but', 'certain', 'alone', 'would', 'suffice'}\nwords_doc2 = {'You', 'are', 'far', 'too', 'kind', 'If', 'not', 'for', 'your', 'heroism'}","00d77234":"#Code by https:\/\/studymachinelearning.com\/jaccard-similarity-text-similarity-metric-in-nlp\/\n\ndef Jaccard_Similarity(doc1, doc2): \n    \n    # List the unique words in a document\n    words_doc1 = set(doc1.lower().split()) \n    words_doc2 = set(doc2.lower().split())\n    \n    # Find the intersection of words list of doc1 & doc2\n    intersection = words_doc1.intersection(words_doc2)\n\n    # Find the union of words list of doc1 & doc2\n    union = words_doc1.union(words_doc2)\n        \n    # Calculate Jaccard similarity score \n    # using length of intersection set divided by length of union set\n    return float(len(intersection)) \/ len(union)","10ba18ed":"doc_1 = \"And yet it is my ineptitude that demands your presence here. <sigh> I was all but certain that Gerolt and I alone would suffice in this, alas...\"\ndoc_2 = \"You are far too kind. If not for your heroism, Ramza and Alma would have...would have...\"\n\nJaccard_Similarity(doc_1,doc_2)","4abd089a":"#Code by Dexter https:\/\/www.kaggle.com\/soul9862\/the-movies-recommend-analysis-cosine-similarity\/notebook\n\ntfidf = TfidfVectorizer(stop_words='english')\ntfidf_matrix = tfidf.fit_transform(df['line'])\nprint(tfidf_matrix.shape)","33d1e73d":"#Code by Dexter https:\/\/www.kaggle.com\/soul9862\/the-movies-recommend-analysis-cosine-similarity\/notebook\n\ncosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)","25628cae":"indices = pd.Series(df.index, index=df['name']).drop_duplicates()\nprint(indices)","fd7a1234":"idx = indices['Mikoto']\nprint(idx)","cdfed0b3":"#Code by Dexter https:\/\/www.kaggle.com\/soul9862\/the-movies-recommend-analysis-cosine-similarity\/notebook\n\ndef get_recommendations(title, cosine_sim=cosine_sim):\n    idx = indices[title]\n    sim_scores = list(enumerate(cosine_sim[idx]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    sim_scores = sim_scores[1:11]\n    movie_indices = [i[0] for i in sim_scores]\n\n    return df['name'].iloc[movie_indices]","fc361451":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcT3qiWYxs-WzvFJOSVhp88VXS1MKKUyF-_Dkg&usqp=CAU)bbs.nga.cn","3411496f":"#An attempt with Cosine Similarity.","6619da1e":"![](https:\/\/pbs.twimg.com\/media\/E4ajNElXMAQlmU3.jpg)t.co","18b0f39a":"<center style=\"font-family:verdana;\"><h1 style=\"font-size:200%; padding: 10px; background: #DCDCDC;\"><b style=\"color:black;\">Mikoto Jinba from Final Fantasy XIV<\/b><\/h1><\/center>\n\n\"Mikoto Jinba is a non-playable character from Final Fantasy XIV. She is an Archon from Sharlayan requested to assist Jenomis cen Lexentale in understanding Auracite and its aetherial properties. She has an identical older twin sister named Kagura who is missing.\"\n\n\"Mikoto has an identical twin sister named Kagura, but aside from their appearance and thirst for knowledge, she could not be more different from her sibling. Mikoto is calm and measured.\"\n\nhttps:\/\/finalfantasy.fandom.com\/wiki\/Mikoto_Jinba","4909e663":"#The Jaccard similarity between doc_1 and doc_2 is 0.08108108108108109 .","c6f1f377":"#There is No Mikoto?","9d5019fb":"#We only have one name: Mikoto.","bcc05c5f":"#Trying some Jaccard Similarity","7c4d0e15":"#Get the set of unique words for each document."}}