{"cell_type":{"f73da17a":"code","c126ade8":"code","97b088fd":"code","1c4117f4":"code","4b0f0300":"code","86c84fc4":"code","5e0a59a1":"code","ddf29eaa":"code","d9d6aee4":"code","3c26806b":"code","1cde3ccb":"code","6d026dfa":"code","77fcb9d7":"code","d3d5dbdf":"code","19dcbcdb":"code","e9ea0aa3":"code","df2b64f6":"code","bd00a4e6":"code","96cb4871":"code","be5b6417":"code","104815bf":"code","33310ac2":"code","237f6b42":"code","f2f4fdf2":"code","cee59e61":"code","214eca4d":"code","121f6fe8":"code","81abe8ee":"markdown"},"source":{"f73da17a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c126ade8":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain.head()","97b088fd":"test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest.head()","1c4117f4":"print(train.info())\nprint(\"-------Missing values--------\")\nprint(train.isnull().sum())\nprint(\"-------Missing percentage--------\")\nprint(train.isnull().sum()\/len(train))","4b0f0300":"col = ['Ticket','Cabin']\ntrain = train.drop(col,axis=1)\ntrain.head(2)","86c84fc4":"#train = train.dropna()\ntrain.columns","5e0a59a1":"cols = ['Survived','Pclass','Sex','SibSp','Parch','Embarked']\n\nfor col in cols:\n    print(col)\n    print(train[col].value_counts())","ddf29eaa":"dummies = []\ncols = ['Sex','Embarked','Pclass']\nfor col in cols:\n    dummies.append(pd.get_dummies(train[col]))\n    \ndummies_df = pd.concat(dummies,axis=1)\ndummies_df.head()","d9d6aee4":"train = pd.concat((train,dummies_df),axis=1)\ntrain = train.drop(['Sex','Embarked','Pclass'],axis=1)\ntrain.head(2)","3c26806b":"train.isnull().sum()","1cde3ccb":"train['Age'] = train['Age'].interpolate()","6d026dfa":"#family size is sum of SibSp(siblings \/ spouses aboard the Titanic) and Parch(parents \/ children aboard the Titanic)\ntrain['Family_size']= train['SibSp']+train['Parch']+1\n#creating column title\ntrain['Title'] = train['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n\ntrain['FarePerPerson']= train['Fare']\/train['Family_size']\ntrain.drop(['Name'],axis=1,inplace=True)\ntrain.head()","77fcb9d7":"train['Title'].value_counts()\nfrom sklearn.preprocessing import LabelEncoder\n# process columns, apply LabelEncoder to categorical features\nlbl= LabelEncoder()\n#lbl.fit(list(train['Title'].values)) \ntrain['Title'] = lbl.fit_transform(list(train['Title'].values))\ntrain.head()","d3d5dbdf":"train.describe()","19dcbcdb":"y = train['Survived']\nX = train.drop(['Survived','PassengerId'],axis=1)","e9ea0aa3":"from sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=0)","df2b64f6":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\nmodel = DecisionTreeClassifier(max_depth = 5)\nmodel.fit(X_train,y_train)\ncv = cross_val_score(model,X_train,y_train,cv=10)\nprint(cv)\ny_pred = model.predict(X_test)\naccuracy_score(y_test,y_pred)","bd00a4e6":"from sklearn import ensemble\nclf = ensemble.RandomForestClassifier(n_estimators=100)\nclf.fit (X_train, y_train)\nclf.score (X_test, y_test)\n","96cb4871":"clf = ensemble.GradientBoostingClassifier(n_estimators=50)\nclf.fit (X_train, y_train)\nclf.score (X_test, y_test)\n","be5b6417":"col = ['Ticket','Cabin']\ntest = test.drop(col,axis=1)\ndummies = []\ncols = ['Sex','Embarked','Pclass']\nfor col in cols:\n    dummies.append(pd.get_dummies(test[col]))\n    \ndummies_df = pd.concat(dummies,axis=1)\ntest = pd.concat((test,dummies_df),axis=1)\ntest = test.drop(['Sex','Embarked','Pclass'],axis=1)\ntest.head(2)","104815bf":"test['Age'] = test['Age'].interpolate()\ntest['Fare'] = test['Fare'] .fillna(test['Fare'].mean())","33310ac2":"#family size is sum of SibSp(siblings \/ spouses aboard the Titanic) and Parch(parents \/ children aboard the Titanic)\ntest['Family_size']= test['SibSp']+test['Parch']+1\n#creating column title\ntest['Title'] = test['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n\ntest['FarePerPerson']= test['Fare']\/test['Family_size']\ntest.drop(['Name'],axis=1,inplace=True)\ntest.head()","237f6b42":"# process columns, apply LabelEncoder to categorical features\nlbl= LabelEncoder()\nlbl.fit(list(test['Title'].values)) \ntest['Title'] = lbl.transform(list(test['Title'].values))\ntest.head()","f2f4fdf2":"X_res = test.drop(['PassengerId'],axis=1)","cee59e61":"y_pred = clf.predict(X_res)","214eca4d":"sub = pd.DataFrame(test['PassengerId'])\nsub['Survived'] = y_pred","121f6fe8":"sub.head()\nsub.to_csv('titanic_results1.csv',index=False)","81abe8ee":"# **Get 79% accuracy in easy way. Please upvote if helpfull**"}}