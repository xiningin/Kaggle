{"cell_type":{"3b29fcb7":"code","9059f0d7":"code","10ec95ef":"code","39476469":"code","3fa9f02e":"code","c3d1166b":"code","782bdd5a":"code","aff86f32":"code","0fe42da1":"code","8eea103c":"code","74596491":"code","1e473530":"code","b79ad367":"code","a8d9b207":"code","f93aaf59":"code","d35bc299":"code","89e10065":"code","09f2500e":"code","3289e9c3":"code","d9c8d003":"code","a3ded968":"code","90e12b53":"code","9b2df7c1":"markdown","c652ff3c":"markdown","37b65874":"markdown","595bdcc9":"markdown","cfe48bb9":"markdown","d0ebaac8":"markdown","6cffc86c":"markdown","cbc55d61":"markdown","988c4c47":"markdown","b7dacff6":"markdown","612885da":"markdown","1663205d":"markdown"},"source":{"3b29fcb7":"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler,StandardScaler,LabelEncoder\nimport warnings\nwarnings.filterwarnings(\"ignore\")\ndf_train=pd.read_csv('..\/input\/airplane-accident-dataset\/train.csv')\ndf_test=pd.read_csv('..\/input\/airplane-accident-dataset\/test.csv')\ndf_train.head()","9059f0d7":"obj=LabelEncoder()\ndf_train['target']=obj.fit_transform(df_train['Severity'])\ndf=pd.concat([df_train.drop(['Severity','target'],axis=1),df_test],axis=0,sort=False)\ndf.head()","10ec95ef":"df['Total_Safety_Complaints']=pd.qcut(df['Total_Safety_Complaints'],3)\ndf['Cabin_Temperature']=pd.qcut(df['Cabin_Temperature'],3)\ndf['Violations']=df['Violations'].map({2:0,1:1,3:2,0:4,4:4,5:5})\n\ndf['Adverse_Weather_Metric']=pd.qcut(df['Adverse_Weather_Metric'],3)\n\ndf['Max_Elevation']=pd.qcut(df['Max_Elevation'],3)\n\ndf['Turbulence_In_gforces']=pd.qcut(df['Turbulence_In_gforces'],3)","39476469":"from sklearn.preprocessing import LabelEncoder\nlbl=LabelEncoder()\n\ndf['Total_Safety_Complaints']=lbl.fit_transform(df['Total_Safety_Complaints'])\ndf['Cabin_Temperature']=lbl.fit_transform(df['Cabin_Temperature'])\ndf['Max_Elevation']=lbl.fit_transform(df['Max_Elevation'])\ndf['Turbulence_In_gforces']=lbl.fit_transform(df['Turbulence_In_gforces'])\n\ndf['Adverse_Weather_Metric']=lbl.fit_transform(df['Adverse_Weather_Metric'])","3fa9f02e":"col1=['Safety_Score', 'Days_Since_Inspection', 'Total_Safety_Complaints',\n       'Accident_Type_Code','Control_Metric' ]\ncol3=['Safety_Score', 'Days_Since_Inspection', 'Total_Safety_Complaints',\n       'Accident_Type_Code','Control_Metric','Turbulence_In_gforces', 'Cabin_Temperature',\n        'Violations',\n       'Adverse_Weather_Metric','Max_Elevation']\nobj=StandardScaler()\ndf[col1]=obj.fit_transform(df[col1])\nobj1=MinMaxScaler()\ndf[col3]=obj1.fit_transform(df[col3])","c3d1166b":"column=['Safety_Score', 'Days_Since_Inspection', 'Total_Safety_Complaints',\n       'Accident_Type_Code','Control_Metric','Turbulence_In_gforces', 'Cabin_Temperature','Violations','Adverse_Weather_Metric',\n       'Max_Elevation']","782bdd5a":"X=df.iloc[0:10000,:][column]\ny=df_train['target']\nx=df.iloc[10000:12500,:][column]\nX_train,X_test,y_train,y_test=train_test_split(X,y,random_state=2020,test_size=0.25)\nimport lightgbm as lgb\nfrom sklearn.model_selection import cross_val_score\nmodel = lgb.LGBMClassifier( learning_rate=0.2, n_estimators= 1000)\nresult=cross_val_score(estimator=model,X=X_train,y=y_train,cv=10)\nprint(result)\nprint(result.mean())","aff86f32":"X=df.iloc[0:10000,:][column]\ny=df_train['target']\nx=df.iloc[10000:12500,:][column]\nX_train,X_test,y_train,y_test=train_test_split(X,y,random_state=2020,test_size=0.25)\nimport xgboost as xgb\nfrom sklearn.model_selection import cross_val_score\nmodel1=xgb.XGBClassifier(colsample_bylevel= 1, learning_rate= 0.1,max_depth=10, n_estimators= 1000)\nresult=cross_val_score(estimator=model1,X=X_train,y=y_train,cv=10)\nprint(result)\nprint(result.mean())","0fe42da1":"model.fit(X,y)\nid=df_test['Accident_ID']\ny_pred=model.predict(x)\nsubmission=pd.DataFrame({'Accident_ID':id,'Severity':y_pred})\nsubmission.head()\nsubmission['Severity']=submission['Severity'].map({1:'Minor_Damage_And_Injuries',2:'Significant_Damage_And_Fatalities',3:'Significant_Damage_And_Serious_Injuries',0:'Highly_Fatal_And_Damaging'})\n#submission.to_csv('submission.csv',index=False)","8eea103c":"model1.fit(X,y)\nid=df_test['Accident_ID']\ny_pred1=model1.predict(x)\nsubmission1=pd.DataFrame({'Accident_ID':id,'Severity':y_pred1})\nsubmission1.head()\nsubmission1['Severity']=submission1['Severity'].map({1:'Minor_Damage_And_Injuries',2:'Significant_Damage_And_Fatalities',3:'Significant_Damage_And_Serious_Injuries',0:'Highly_Fatal_And_Damaging'})\n#submission1.to_csv('F:\\\\PYTHON PROGRAM\\\\JAISHREERAMhacker75.csv',index=False)","74596491":"indices=np.argsort(model1.feature_importances_)\nplt.figure(figsize=(10,10))\ng = sns.barplot(y=X_train.columns[indices][:40],x = model1.feature_importances_[indices][:40] , orient='h')","1e473530":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve","b79ad367":"# Cross validate model with Kfold stratified cross val\nkfold = StratifiedKFold(n_splits=10)","a8d9b207":"\nGBC = GradientBoostingClassifier()\ngb_param_grid = {'loss' : [\"deviance\"],\n              'n_estimators' : [400,500],\n              'learning_rate': [0.1, 0.2],\n              'max_depth': [4, 8],\n              'min_samples_leaf': [100,150],\n              'max_features': [0.3, 0.1] \n              }\n\ngsGBC = GridSearchCV(GBC,param_grid = gb_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsGBC.fit(X_train,y_train)\n\nmodel2 = gsGBC.best_estimator_\n\n# Best score\nprint(gsGBC.best_score_)\nprint(gsGBC.best_params_)","f93aaf59":"model2 = gsGBC.best_estimator_","d35bc299":"model2.fit(X,y)\nid=df_test['Accident_ID']\ny_pred2=model2.predict(x)\nsubmission2=pd.DataFrame({'Accident_ID':id,'Severity':y_pred2})\nsubmission2.head()\nsubmission2['Severity']=submission2['Severity'].map({1:'Minor_Damage_And_Injuries',2:'Significant_Damage_And_Fatalities',3:'Significant_Damage_And_Serious_Injuries',0:'Highly_Fatal_And_Damaging'})\n#submission2.to_csv('F:\\\\PYTHON PROGRAM\\\\JAISHREERAMhacker36.csv',index=False)","89e10065":"# RFC Parameters tunning \nRFC = RandomForestClassifier()\n\n\n## Search grid for optimal parameters\nrf_param_grid = {\n              \"max_features\": [1, 3, 10],\n              \"min_samples_split\": [2, 3, 10],\n              \"min_samples_leaf\": [1, 3, 10],\n            \n              \"n_estimators\" :[400,500,1000],\n              \"criterion\": [\"gini\"]}\n\n\ngsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsRFC.fit(X_train,y_train)\n\nmodel3 = gsRFC.best_estimator_\n\n# Best score\nprint(gsRFC.best_score_)\nprint(gsRFC.best_params_)","09f2500e":"model3.fit(X,y)\nid=df_test['Accident_ID']\ny_pred3=model3.predict(x)\nsubmission3=pd.DataFrame({'Accident_ID':id,'Severity':y_pred3})\nsubmission3.head()\nsubmission3['Severity']=submission3['Severity'].map({1:'Minor_Damage_And_Injuries',2:'Significant_Damage_And_Fatalities',3:'Significant_Damage_And_Serious_Injuries',0:'Highly_Fatal_And_Damaging'})\n#submission3.to_csv('F:\\\\PYTHON PROGRAM\\\\JAISHREERAMhacker57.csv',index=False)","3289e9c3":"#ExtraTrees \nExtC = ExtraTreesClassifier()\n\n\n## Search grid for optimal parameters\nex_param_grid = {\"max_depth\": [None],\n              \"max_features\": [1, 3, 10],\n              \"min_samples_split\": [2, 3, 10],\n              \"min_samples_leaf\": [1, 3, 10],\n              \"bootstrap\": [False],\n              \"n_estimators\" :[400,500],\n              \"criterion\": [\"gini\"]}\n\n\ngsExtC = GridSearchCV(ExtC,param_grid = ex_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsExtC.fit(X_train,y_train)\n\nmodel5 = gsExtC.best_estimator_\n\n# Best score\nprint(gsExtC.best_score_)\nprint(gsExtC.best_params_)","d9c8d003":"model5.fit(X,y)\nid=df_test['Accident_ID']\ny_pred5=model5.predict(x)\nsubmission5=pd.DataFrame({'Accident_ID':id,'Severity':y_pred5})\nsubmission5.head()\nsubmission5['Severity']=submission5['Severity'].map({1:'Minor_Damage_And_Injuries',2:'Significant_Damage_And_Fatalities',3:'Significant_Damage_And_Serious_Injuries',0:'Highly_Fatal_And_Damaging'})\n#submission5.to_csv('F:\\\\PYTHON PROGRAM\\\\JAISHREERAMhacker36.csv',index=False)","a3ded968":"model = lgb.LGBMClassifier( learning_rate=0.2, n_estimators= 500,max_depth=10)\nmodel1=xgb.XGBClassifier(colsample_bylevel= 1, learning_rate= 0.1, max_depth= 10, n_estimators= 400)\nmodel2 = GradientBoostingClassifier(learning_rate= 0.2, loss= 'deviance', max_depth= 8, max_features =0.3, min_samples_leaf= 100, n_estimators= 500)\nmodel3 = RandomForestClassifier(criterion= 'gini', min_samples_leaf= 1, min_samples_split= 3, n_estimators= 500)","90e12b53":"from sklearn.ensemble import VotingClassifier\nvotingC = VotingClassifier(estimators=[('gbc',model2),('rfc',model3),('xgb',model1)], voting='soft', n_jobs=4)\nvotingC.fit(X,y)\nid=df_test['Accident_ID']\ny_pred2=votingC.predict(x)\nsubmission=pd.DataFrame({'Accident_ID':id,'Severity':y_pred2})\nsubmission.head()\nsubmission['Severity']=submission['Severity'].map({1:'Minor_Damage_And_Injuries',2:'Significant_Damage_And_Fatalities',3:'Significant_Damage_And_Serious_Injuries',0:'Highly_Fatal_And_Damaging'})\n#submission.to_csv('F:\\\\PYTHON PROGRAM\\\\JAISHREERAMhacker72.csv',index=False)","9b2df7c1":"# If you like my kernel please consider upvoting it\n\n# Don't hesitate to give your suggestions in the comment section\n\n# Thank you...","c652ff3c":"# Xgboost","37b65874":"# Voting Classifier ","595bdcc9":"# Import Required Module","cfe48bb9":"# Extra Tree classifeir","d0ebaac8":"# If you think this notebook is worth reading and has gained some knowledge from this,please consider upvoting my kernel.Your appreciation means a lot to me","6cffc86c":"# Gradient Boosting Classifeir","cbc55d61":"1. LGBM\n2. Xgboost\n3. RandomForestClassifier\n4. Gradient Boosting classifier\n5. Extra Tree classifier\n6. Voting Classifier","988c4c47":"You can try with both hard and soft voting","b7dacff6":"# LGBM","612885da":"As we know dataset does not contain any nan value so direct preprocess the data","1663205d":"# randomForest Classifier"}}