{"cell_type":{"fd0aecf2":"code","d0923618":"code","0a9d33cc":"code","400c636d":"code","d9cb0ad3":"code","4184704b":"code","4514c203":"code","e162546f":"code","80066245":"markdown"},"source":{"fd0aecf2":"import torch\nimport torch.nn as nn\nfrom skimage import io, transform\n\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self,image_path,targets,augmentations=None):\n        self.image_path = image_path\n#         self.features = features\n        self.targets = targets\n        self.augmentations = augmentations\n        \n    def __len__(self):\n        return len(self.image_path)\n    \n    def __getitem__(self,item):\n        image = io.imread(self.image_path[item])\n#         features = self.features[item,:]\n        targets = self.targets[item]\n        \n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented[\"image\"]\n            \n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n#             \"features\": torch.tensor(features, dtype=torch.float),\n            \"targets\": torch.tensor(targets, dtype=torch.float),\n        }\n        ","d0923618":"import sys\nsys.path.append('..\/input\/timm-pytorch-image-models\/pytorch-image-models-master')\nimport timm\n######  Thank you NIKITA KOZODOI https:\/\/www.kaggle.com\/kozodoi\/timm-pytorch-image-models for your kaggle dataset","0a9d33cc":"# timm.list_models('*efficientnet*')","400c636d":"import torch\nimport torch.nn as nn\n\nmodel_name = 'tf_efficientnet_b2_ns'\nfile_name = \"..\/input\/tf-efficientnet-b2-ns\/tf_efficientnet_b2_ns-00306e48.pth\"\nout_dim    = 1\n\ndef get_model():\n    model = timm.create_model(model_name, pretrained=False)\n    \n    model.load_state_dict(torch.load(file_name))\n    model.classifier = nn.Linear(model.classifier.in_features, \n                             out_dim)\n    return model","d9cb0ad3":"import pandas as pd\nimport numpy as np\nfrom sklearn import model_selection\ndf = pd.read_csv('..\/input\/petfinder-pawpularity-score\/train.csv')\ndf[\"kfold\"] = -1\n\ndf = df.sample(frac=1).reset_index(drop=True)\n\nkf = model_selection.StratifiedKFold(n_splits=5, shuffle=False)\n\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X=df,y=df.Pawpularity.values)):\n    print(len(train_idx), len(val_idx))\n    df.loc[val_idx, 'kfold'] = fold","4184704b":"import os\nfrom sklearn import metrics\nimport albumentations\ndevice = 'cuda'\nepochs = 12\ndata_path = '..\/input\/petfinder-pawpularity-score'\ntrain_aug = albumentations.Compose(                  ##  AUGMENTATIONs TAKEN FROM ABHISHEK THAKUR's tez Pawpular training\n    [\n        albumentations.Resize(256,256, p=1),\n        albumentations.HueSaturationValue(\n            hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5\n        ),\n        albumentations.RandomBrightnessContrast(\n            brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5\n        ),\n        albumentations.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),\n    ],\n    p=1.0,\n)\n\nvalid_aug = albumentations.Compose(\n    [\n        albumentations.Resize(256, 256, p=1),\n        albumentations.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),\n    ],\n    p=1.0,\n)\n","4514c203":"scores = []\nfor fold in range(5):\n        model = get_model()\n        model.to(device)\n        df_train = df[df.kfold != fold].reset_index(drop=True)\n        df_valid = df[df.kfold == fold].reset_index(drop=True)\n\n        df_train = df_train.drop(columns = 'kfold')\n        df_valid = df_valid.drop(columns = 'kfold')\n\n        train_images = df_train.Id.values.tolist()\n        train_images = [os.path.join(data_path,'train',i + '.jpg') for i in train_images]\n        valid_images = df_valid.Id.values.tolist()\n        valid_images = [os.path.join(data_path,'train',i + '.jpg') for i in valid_images]\n\n        train_targets = df_train.Pawpularity.values\n        valid_targets = df_valid.Pawpularity.values\n\n        train_dataset = CustomDataset(image_path = train_images,targets = train_targets,augmentations=train_aug)\n        train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=64,shuffle=True,pin_memory=True) \n        valid_dataset = CustomDataset(image_path = valid_images,targets =valid_targets,augmentations=valid_aug)\n        valid_loader = torch.utils.data.DataLoader(valid_dataset,batch_size=64,shuffle=False,pin_memory=True) \n\n        optimizer = torch.optim.Adam(model.parameters(),lr=1e-4)\n        \n        for epoch in range(epochs):\n            \n            model.train()\n            for data in train_loader:\n                inputs = data['image']\n                targets = data['targets']\n\n                inputs = inputs.to(device, dtype=torch.float)\n                targets = targets.to(device, dtype=torch.float)\n\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = nn.MSELoss()(outputs, targets.view(-1, 1))\n                loss.backward()\n                optimizer.step()\n           \n            model.eval()\n            final_targets = []\n            final_outputs = []\n                \n            with torch.no_grad():\n                for data in valid_loader:\n                    inputs = data['image']\n                    targets = data['targets']\n                    inputs = inputs.to(device, dtype=torch.float)\n                    targets = targets.to(device, dtype=torch.float)\n\n                    output = model(inputs)\n\n                    targets = targets.detach().cpu().numpy().tolist()\n                    output = output.detach().cpu().numpy().tolist()\n                    final_outputs.extend(output)\n                    final_targets.extend(targets)\n                    RMSE = np.sqrt(metrics.mean_squared_error(final_targets,final_outputs))\n            \n            print(f'you are in fold {fold} and  Epoch = {epoch}   valid RMSE={RMSE}')\n        torch.save(model.state_dict(),'model-epoch'+str(fold)+'.pth')\n        scores.append(RMSE)\n            ","e162546f":"from itertools import chain\nmax = 200\nmodel_no = 0\nfor i in range(5):\n    if score[i] < max:\n        model_no = i\n        max = scores[i]\n        \n        \nmodel_f = get_model()\nmodel_f.to(device)\nmodel_f.load_state_dict(torch.load('.\/model-epoch'+str(model_no)+'.pth'))\ndata_path = '..\/input\/petfinder-pawpularity-score'\ndevice = 'cuda'\ndf_test = pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')\ntest_images = df_test.Id.values.tolist()\ntest_images = [os.path.join(data_path,'test',i + '.jpg') for i in test_images]\n\ntest_dataset =  CustomDataset(image_path = test_images,targets = np.ones(len(test_images)),augmentations=valid_aug)\ntest_loader = torch.utils.data.DataLoader(test_dataset,batch_size=64,shuffle=False) \n\n\nfinal_outputs = []\n \nwith torch.no_grad():\n    for data in test_loader:\n        inputs = data['image']\n        inputs = inputs.to(device, dtype=torch.float)\n        output = model_f(inputs)\n        output = output.detach().cpu().numpy().tolist()\n        final_outputs.extend(output)\n        \n\nfinal_outputs = list(chain.from_iterable(final_outputs))        \nsubmission = pd.read_csv('..\/input\/petfinder-pawpularity-score\/sample_submission.csv')\nsubmission['Pawpularity'] = final_outputs\nsubmission.to_csv('submission.csv',index = False)","80066245":"#### "}}