{"cell_type":{"39cd5495":"code","a380cbea":"code","478c225a":"code","a5dd7682":"code","215db641":"code","f82d85b7":"code","1f836bd6":"code","20e7da4a":"code","49e346bc":"code","90a253e9":"code","193aa833":"code","38eb4954":"code","75848616":"code","912429f0":"code","37cd76a9":"code","a1a5b7e1":"code","488c092a":"code","fc0c789c":"code","0243c377":"code","9376b631":"code","364d521e":"code","49bbb0ce":"code","e81896db":"code","bfa3ec36":"code","e7fbdf5d":"code","314dd0af":"code","f8418329":"code","e67047c7":"code","dac3feba":"code","c0a27cdc":"code","3c4458e2":"code","ba953c14":"code","bd559c60":"code","83153ac5":"code","337d2389":"code","c116c245":"code","50c22734":"code","9b912bb8":"code","e86bcf46":"code","514090b5":"code","a49d5733":"code","377741f0":"code","5f3fa773":"code","6d32e613":"markdown","f96b8ad1":"markdown","7343130a":"markdown","79e0fb82":"markdown","b815de46":"markdown","44717498":"markdown","f9803732":"markdown","2857d785":"markdown","3653a183":"markdown","ba869fb0":"markdown","f06d9637":"markdown","1768c31c":"markdown","2710afb9":"markdown","d8f93abb":"markdown","d1af33e7":"markdown","d37f0e96":"markdown","afc74da9":"markdown","e858f8a9":"markdown","dae4196b":"markdown","4564b220":"markdown","c9453bbf":"markdown"},"source":{"39cd5495":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","a380cbea":"# ref: https:\/\/www.kaggle.com\/mesadowski\/moneyball-golf-scikit-learn-and-tf-estimator-api\n\n# read data\ndf = pd.read_csv('..\/input\/pga-tour-20102018-data\/PGA_Data_Historical.csv')\n\n# unstack\ndf = df.set_index(['Player Name', 'Variable', 'Season'])['Value'].unstack('Variable').reset_index()\n\n# drop non-numeric features\nkeep_columns = [\n    'Player Name',\n    'Season',\n    'Total Money (Official and Unofficial) - (MONEY)', # \u5e74\u9593\u7372\u5f97\u8cde\u91d1 (\u30c9\u30eb)\n    'Driving Distance - (AVG.)', # \u30c9\u30e9\u30a4\u30d0\u30fc\u306e\u5e73\u5747\u98db\u8ddd\u96e2 (\u30e4\u30fc\u30c9)\n    'Driving Accuracy Percentage - (%)', # \u30c9\u30e9\u30a4\u30d0\u30fc\u306e\u30d5\u30a7\u30a2\u30a6\u30a7\u30a4\u30ad\u30fc\u30d7\u7387\n    'Total Distance Efficiency - (AVERAGE DISTANCE (YARDS))', # \u30c9\u30e9\u30a4\u30d0\u30fc\u306e\u3001\u30dc\u30fc\u30eb \u30b9\u30d4\u30fc\u30c9\u306b\u5bfe\u3059\u308b\u98db\u8ddd\u96e2 (\u9ad8\u3044\u307b\u3046\u304c\u52b9\u7387\u3088\u304f\u98db\u3093\u3067\u3044\u308b)\n    'Average Distance to Hole After Tee Shot - (AVG)', # \u5e73\u5747\u306e\u5e73\u5730\u30b7\u30e7\u30c3\u30c8\u98db\u8ddd\u96e2\n    'Ball Speed - (AVG.)', # \u5e73\u5747\u30dc\u30fc\u30eb\u901f\u5ea6\n    'Scrambling from the Sand - (%)', # \u30d0\u30f3\u30ab\u30fc\u304b\u3089\u306e\u30b9\u30af\u30e9\u30f3\u30d6\u30eb\u7387 (\u30d1\u30fc\u30aa\u30f3\u51fa\u6765\u306a\u304b\u3063\u305f\u30db\u30fc\u30eb\u3067\u3001\u30d1\u30fc\u4ee5\u4e0a\u3067\u3042\u304c\u308b\u3053\u3068)\n    'Scrambling from the Fringe - (%)', # \u30b0\u30ea\u30fc\u30f3\u306e\u30d5\u30ea\u30f3\u30b8\u304b\u3089\u306e\u30b9\u30af\u30e9\u30f3\u30d6\u30eb\u7387\n    'Scrambling from the Rough - (%)', # \u30e9\u30d5\u304b\u3089\u306e\u30b9\u30af\u30e9\u30f3\u30d6\u30eb\u7387\n    '3-Putt Avoidance - (%)', # 3 \u30d1\u30c3\u30c8\u3057\u305f\u30db\u30fc\u30eb\u306e\u5272\u5408\n    'Birdie or Better Conversion Percentage - (%)' # \u30d0\u30fc\u30c7\u30a3\u30fc\u3088\u308a\u826f\u3044\u6210\u7e3e\u3067\u6319\u304c\u308b\u30db\u30fc\u30eb\u306e\u5272\u5408\n]\ndf = df[keep_columns].dropna()\n\n# rename the columns to something shorter\ndf.rename(columns = {'Total Money (Official and Unofficial) - (MONEY)':'Money'}, inplace = True)\ndf.rename(columns = {'3-Putt Avoidance - (%)':'ThreePuttRate'}, inplace = True)\ndf.rename(columns = {'Average Distance to Hole After Tee Shot - (AVG)':'NonDrivingDistance'}, inplace = True)\ndf.rename(columns = {'Total Distance Efficiency - (AVERAGE DISTANCE (YARDS))':'DistanceEfficiency'}, inplace=True)\ndf.rename(columns = {'Ball Speed - (AVG.)':'BallSpeed'}, inplace=True)\ndf.rename(columns = {'Driving Distance - (AVG.)':'DrivingDistance'}, inplace = True)\ndf.rename(columns = {'Driving Accuracy Percentage - (%)':'DrivingAccuracy'}, inplace=True)\ndf.rename(columns = {'Scrambling from the Sand - (%)':'ScramblingSand'}, inplace = True)\ndf.rename(columns = {'Scrambling from the Fringe - (%)':'ScramblingFringe'}, inplace=True)\ndf.rename(columns = {'Scrambling from the Rough - (%)':'ScramblingRough'}, inplace=True)\ndf.rename(columns = {'Birdie or Better Conversion Percentage - (%)':'BirdieConversion'}, inplace=True)\n\n# remove $ and commas from Money\ndf['Money']= df['Money'].str.replace('$','')\ndf['Money']= df['Money'].str.replace(',','')\n\n# make all variables into number\nfor col in  df.columns[2:]:\n   df[col] = df[col].astype(float)","478c225a":"np.random.seed(0)\nindex = np.random.randint(df.shape[0], size=10)\ndf.iloc[index,:]","a5dd7682":"df.mean()","215db641":"df.groupby(\"Season\").mean()","f82d85b7":"df.loc[df.groupby(\"Season\")[\"Money\"].idxmax()]","1f836bd6":"corr = df[df.columns[2:]].corr()\n\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)]= True\n\nf, ax = plt.subplots(figsize=(11, 15))\nheatmap = sns.heatmap(corr, \n                      square = True,\n                      mask = mask,\n                      linewidths = .5,\n                      cmap = 'coolwarm',\n                      cbar_kws = {'shrink': .4, \n                                'ticks' : [-1, -.5, 0, 0.5, 1]},\n                      vmin = -1, \n                      vmax = 1,\n                      annot = True,\n                      annot_kws = {\"size\": 12})\n\nax.set_yticklabels(corr.columns, rotation = 0)\nax.set_xticklabels(corr.columns)\nsns.set_style({'xtick.bottom': True}, {'ytick.left': True})","20e7da4a":"# \u8aac\u660e\u5909\u6570\u3068\u76ee\u7684\u5909\u6570\nX = df[df.columns[3:]]\ny = df[\"Money\"]\n\nprint('X', X.shape)\nprint('y', y.shape)","49e346bc":"from sklearn.datasets import load_boston\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\n# \u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5206\u96e2\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=2018)","90a253e9":"!pip install pygam","193aa833":"from pygam import s, LinearGAM\n\ngam = LinearGAM(s(0) + s(1) + s(2) + s(3) + s(4) + s(5) + s(6) + s(7) + s(8) + s(9))\ngam = gam.fit(X_train, y_train)","38eb4954":"def plot_splines(gam):\n    fig, axes = plt.subplots(2, 5, figsize=(18, 12))\n    axes = np.array(axes).flatten()\n    for i, (ax, title, p_value) in enumerate(zip(axes, X_train.columns, gam.statistics_['p_values'])):\n        XX = gam.generate_X_grid(term=i)\n        ax.plot(XX[:, i], gam.partial_dependence(term=i, X=XX))\n        ax.plot(XX[:, i], gam.partial_dependence(term=i, X=XX, width=.95)[1], c='r', ls='--')\n        ax.axhline(0, c='#cccccc')\n        ax.set_title(\"{0:} (p={1:.2})\".format(title, p_value))\n        ax.set_yticks([])\n        \nplot_splines(gam)","75848616":"from pygam import l, LinearGAM\n\nglm = LinearGAM(l(0) + l(1) + l(2) + l(3) + l(4) + l(5) + l(6) + l(7) + l(8) + l(9))\nglm = glm.fit(X_train, y_train)","912429f0":"plot_splines(glm)","37cd76a9":"!pip install interpret","a1a5b7e1":"from interpret import show\nfrom interpret.data import Marginal\n\nmarginal = Marginal().explain_data(X_test, y_test, name = 'test data')\nshow(marginal)","488c092a":"from interpret.glassbox import ExplainableBoostingRegressor, LinearRegression, RegressionTree\n\nebm = ExplainableBoostingRegressor(random_state=0, scoring=\"mean_squared_error\")\nebm.fit(X_train, y_train)","fc0c789c":"ebm_global = ebm.explain_global(name='EBM')\nshow(ebm_global)","0243c377":"ebm_local = ebm.explain_local(X_test[:5], y_test[:5], name='EBM')\nshow(ebm_local)","9376b631":"from interpret import show\nfrom interpret.perf import RegressionPerf\n\nebm_perf = RegressionPerf(ebm.predict).explain_perf(X_test, y_test, name='EBM')\nshow(ebm_perf)","364d521e":"from interpret.glassbox import LinearRegression, RegressionTree\n\nlr = LinearRegression(random_state=0)\nlr.fit(X_train, y_train)\nrt = RegressionTree(random_state=0)\nrt.fit(X_train, y_train)\n\nmodel_names = [\n    (glm, \"GLM\"),\n    (gam, \"GAM\"),\n    (ebm, \"InterpretML (EBM)\"),\n    (lr, \"InterpretML (LR)\"),\n    (rt, \"InterpretML (RT)\")\n]\nresult = pd.DataFrame()\n\nfor (model, name) in model_names:\n    y_pred = model.predict(X_test)\n    series = pd.Series()\n    series[\"model\"] = name\n    series[\"MSE\"] = mean_squared_error(y_test, y_pred)\n    result = result.append(series, ignore_index=True)\nresult","49bbb0ce":"from lightgbm import LGBMRegressor\nfrom sklearn.model_selection import KFold\n\ndef train_lgbm(params, log=False):\n    fold = KFold(n_splits=8)\n    oof = np.zeros_like(y_train)\n    models = []\n    \n    if log:\n        y = np.log1p(y_train.values)\n    else:\n        y = y_train.values\n\n    for idx_train, idx_valid in fold.split(X_train, y):\n        clf = LGBMRegressor(**params)\n        clf.fit(X_train.values[idx_train], y[idx_train], \n                eval_set=(X_train.values[idx_valid], y[idx_valid]), \n               early_stopping_rounds=100,\n               verbose=50)\n        oof[idx_valid] = clf.predict(X_train.values[idx_valid])\n        models.append(clf)\n    if log:\n        oof = np.expm1(oof)\n    return models, oof","e81896db":"!pip install git+https:\/\/gitlab.com\/nyker510\/vivid","bfa3ec36":"params = {\n    'objective': 'poisson',\n    'learning_rate': .05,\n    'n_estimators': 1000,\n    'reg_lambda': 10.,\n    'colsample_bytree': .7,\n    'importance_type': 'gain',\n    'max_depth': 2 # \u591a\u91cd\u5171\u7dda\u6027\u304c\u60aa\u3055\u3057\u3066\u3044\u308b\u3088\u3046\u3067 depth \u304c\u6df1\u3044\u3068\u7cbe\u5ea6\u304c\u51fa\u306a\u3044\n}\n\nmodels, oof = train_lgbm(params, log=False)","e7fbdf5d":"from vivid.metrics import regression_metrics","314dd0af":"regression_metrics(oof, y_train)","f8418329":"from vivid.visualize import visualize_feature_importance\n\nfig, ax, importance_df = visualize_feature_importance(models, columns=X_train.columns)","e67047c7":"importance_df.groupby('column').mean()","dac3feba":"class LGBMEnsumble:\n    def __init__(self, models, log=False):\n        self.models = models\n        self.log = log\n        \n    def predict(self, x):\n        p = np.mean([m.predict(x) for m in self.models], axis=0)\n        if self.log:\n            p = np.expm1(p)\n        return p","c0a27cdc":"lgbm_ens = LGBMEnsumble(models)","3c4458e2":"import seaborn as sns\nimport matplotlib.pyplot as plt","ba953c14":"fig, ax = plt.subplots(figsize=(6, 6))\nax.scatter(oof, y_train)","bd559c60":"\nmodel_names = [\n    (glm, \"GLM\"),\n    (gam, \"GAM\"),\n    (ebm, \"InterpretML (EBM)\"),\n    (lr, \"InterpretML (LR)\"),\n    (rt, \"InterpretML (RT)\"),\n    (lgbm_ens, 'lgbm')\n]\nresult = pd.DataFrame()\n\nfig, axes = plt.subplots(figsize=(12, 8), nrows=2, ncols=3, sharex=True, sharey=True)\naxes = [a for x in axes for a in x]\n\nfor (model, name), ax in zip(model_names, axes):\n    y_pred = model.predict(X_test)\n    mse = mean_squared_error(y_test, y_pred)\n    ax.scatter(y_pred, y_test, label=name)\n    ax.set_title(f'{mse:.3e}')\n    ax.legend()\n    series = pd.Series()\n    series[\"model\"] = name\n    series[\"MSE\"] = mse\n    result = result.append(series, ignore_index=True)\n\nfig.tight_layout()\n\nresult","83153ac5":"result.plot(kind='bar', x='model')","337d2389":"from vivid.out_of_fold.ensumble import RFRegressorFeatureOutOfFold\nfrom vivid.out_of_fold.boosting import OptunaXGBRegressionOutOfFold, OptunaXGBRegressionOutOfFold","c116c245":"rf = RFRegressorFeatureOutOfFold(name='rf')","50c22734":"rf.fit(X_train, y_train.values)\np = rf.predict(X_test)\nregression_metrics(y_test, p)","9b912bb8":"optuna_lgbm = OptunaXGBRegressionOutOfFold(name='optuna_lgbm', n_trials=200)","e86bcf46":"optuna_lgbm.fit(X_train, y_train.values)","514090b5":"p = optuna_lgbm.predict(X_test)\n\nregression_metrics(y_test, p)","a49d5733":"optuna_xgb = OptunaXGBRegressionOutOfFold(n_trials=200, name='optuna_xgb')","377741f0":"optuna_xgb.fit(X_train, y_train.values)","5f3fa773":"y = optuna_xgb.predict(X_test)\nregression_metrics(y_test, y)","6d32e613":"## \u8aac\u660e\u53ef\u80fd\u306a\u30d6\u30fc\u30b9\u30c6\u30a3\u30f3\u30b0\u30fb\u30e2\u30c7\u30eb\n\n\u3044\u3088\u3044\u3088\u30d6\u30fc\u30b9\u30c6\u30a3\u30f3\u30b0\u30e2\u30c7\u30eb\u3092\u5229\u7528\u3057\u3066\u3001\u8aac\u660e\u53ef\u80fd\u306a\u30e2\u30c7\u30eb\u3092\u5b66\u7fd2\u3059\u308b\u3002","f96b8ad1":"## \u7cbe\u5ea6\u306e\u6bd4\u8f03\n\n\u4ee5\u4e0b\u306e\u30e2\u30c7\u30eb\u306b\u5bfe\u3057\u3001\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3078\u306e MSE (meas squared error) \u3092\u5831\u544a\u3059\u308b\u3002\n\n- `pyGAM` \u306e GLM\n- `pyGAM` \u306e GAM\n- `interpret` \u306e Boosting Model\n- `interpret` \u306e Linear Regression\n- `interpret` \u306e Regression Tree","7343130a":"Thanks @junyan\n\n## Purpose\n\n* Compare GAM models and lightGBM@K-fold","79e0fb82":"## \u7d71\u8a08\u91cf\u306e\u51fa\u529b","b815de46":"# GLM\/GAM \u306b\u3088\u308b\u5206\u6790","44717498":"\u6700\u5f8c\u306b MSE \u306e\u5206\u5e03\u3092\u8868\u793a\u3059\u308b\u3002\n\u6b8b\u5dee\u5206\u5e03\u304c\u6b63\u898f\u5206\u5e03\u306b\u8fd1\u3044\u3053\u3068\u304c\u78ba\u8a8d\u3067\u304d\u308b\u3002","f9803732":"## \u5404\u5e74\u5ea6\u306e\u6700\u5927\u8cde\u91d1\u30d7\u30ec\u30a4\u30e4\u30fc","2857d785":"\u8cde\u91d1\u3068\u6b63\u306e\u76f8\u95a2\u304c\u5f37\u3044\u3082\u306e\n\n- \u30c9\u30e9\u30a4\u30d0\u30fc\u306e\u8ddd\u96e2\n- \u98db\u8ddd\u96e2\u306e\u52b9\u7387\u6027 (\u30b9\u30d4\u30f3\u91cf)\n- \u30dc\u30fc\u30eb\u30b9\u30d4\u30fc\u30c9\n- \u30e9\u30d5\u304b\u3089\u306e\u30ea\u30ab\u30d0\u30ea\u306e\u4e0a\u624b\u3055\n- **\u30d0\u30fc\u30c7\u30a3\u3088\u308a\u3088\u3044\u6210\u7e3e\u3067\u30db\u30fc\u30eb\u3092\u7d42\u3048\u308b\u7387**\n\n\u8cde\u91d1\u3068\u8ca0\u306e\u76f8\u95a2\u304c\u8a8d\u3081\u3089\u308c\u308b\u3082\u306e\n\n- \u30c9\u30e9\u30a4\u30d0\u30fc\u4ee5\u5916\u306e\u30b7\u30e7\u30c3\u30c8\u98db\u8ddd\u96e2\n- 3 \u30d1\u30c3\u30c8\u3059\u308b\u30db\u30fc\u30eb\u306e\u5272\u5408","3653a183":"## Appendix\n\nlightGBM \u3068\u52dd\u8ca0!","ba869fb0":"\u307e\u305a\u306f\u3001`interpret.data.Marginal` \u3092\u4f7f\u3063\u3066\u3001\u30c7\u30fc\u30bf\u306e\u69d8\u5b50 (i.e. \u5404\u7279\u5fb4\u91cf\u306e\u5206\u5e03) \u3092\u898b\u308b","f06d9637":"\u5404\u7279\u5fb4\u91cf\u306e\u4e88\u6e2c\u5024\u3078\u306e\u5bc4\u4e0e\u3092\u898b\u308b\u305f\u3081\u306b\u3001\u30b9\u30d7\u30e9\u30a4\u30f3\u95a2\u6570\u3092\u30d7\u30ed\u30c3\u30c8\u3059\u308b\u3002","1768c31c":"## \u5404\u7279\u5fb4\u91cf\u540c\u58eb\u306e\u76f8\u95a2","2710afb9":"\u5b66\u7fd2\u3057\u305f\u30e2\u30c7\u30eb\u3092\u89e3\u91c8\u3059\u308b\u306b\u306f\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306b `explain_global` \u3092\u7528\u3044\u308b\u3002\n\u30d1\u30cd\u30eb\u3092\u64cd\u4f5c\u3059\u308c\u3070\u3001\u5404\u7279\u5fb4\u91cf\u306b\u5bfe\u3057\u3066\u3001EBM \u304c\u30b9\u30b3\u30a2\u3078\u306e\u5bc4\u4e0e\u3092\u30ce\u30f3\u30d1\u30e9\u30e1\u30c8\u30ea\u30c3\u30af \u30e2\u30c7\u30eb\u3067\u63a8\u5b9a\u3057\u3066\u3044\u308b\u3053\u3068\u304c\u78ba\u8a8d\u3067\u304d\u308b\u3002","d8f93abb":"* BirdieConversion \u304c\u4e00\u756a\u5927\u4e8b\n* NonDrivingDistance \u306f\u3042\u307e\u308a\u5927\u4e8b\u3067\u306f\u306a\u3044\u307f\u305f\u3044","d1af33e7":"## pyGAM \u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\nhttps:\/\/pygam.readthedocs.io\/en\/latest\/","d37f0e96":"# \u30c7\u30fc\u30bf\u306e\u524d\u51e6\u7406","afc74da9":"## pyGAM \u306b\u3088\u308b GLM \u30e2\u30c7\u30eb","e858f8a9":"# InterpretML\n\nhttps:\/\/github.com\/microsoft\/interpret\n\n## \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb","dae4196b":"![](https:\/\/pga-tour-res.cloudinary.com\/image\/upload\/c_fill,f_auto,g_center,h_478,q_auto,w_850\/v1\/pgatour\/editorial\/2019\/08\/18\/JustinThomasTrophyClean-847-KK.jpg)\n\nJustin Thomas \u306f\u3053\u3093\u306a\u4eba\u3089\u3057\u3044\u3002\n\nhttps:\/\/www.pgatour.com\/news\/2019\/08\/18\/justin-thomas-shows-he-still-knows-how-to-win-bmw-championship-medinah-country-club-fedexcup.html","4564b220":"## pyGAM \u306b\u3088\u308b GAM \u30e2\u30c7\u30eb","c9453bbf":"\u3055\u3089\u306b\u30c7\u30fc\u30bf\u70b9\u3078\u306e\u4e88\u6e2c\u306e\u8aac\u660e\u3082\u884c\u3046\u3053\u3068\u304c\u51fa\u6765\u308b\u3002\n\u6700\u521d\u306e 5 \u3064\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u5bfe\u3057\u3066\u4e88\u6e2c\u3092\u884c\u3044\u3001\u305d\u306e\u8aac\u660e\u3092\u3059\u308b\u306b\u306f\u6b21\u306e\u30b3\u30fc\u30c9\u3092\u5b9f\u884c\u3059\u308b\u3002"}}