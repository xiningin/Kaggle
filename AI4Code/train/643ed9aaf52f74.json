{"cell_type":{"5287d570":"code","39667158":"code","d67acd4a":"code","d2f6bd34":"code","bee0cdcf":"code","6f328738":"code","097e86c2":"code","bf8fc593":"code","914eecc6":"code","ff53be04":"code","4de0217d":"code","e6ae0f83":"code","9072fc63":"code","42b3132e":"code","4e942caf":"code","855862e2":"code","105e56a8":"code","c60691dd":"code","68afcda6":"code","30ba745f":"code","6598074d":"code","95d6fc11":"code","1c888ad8":"code","22aa39ff":"code","61a2410e":"code","aaa1ecbc":"code","1d92b800":"code","103975af":"code","2eb55161":"code","17451462":"code","10ddd078":"code","056e796e":"code","b0529bc9":"code","d8f820f9":"code","108a085c":"code","3111241c":"code","47014d26":"code","c4c2febf":"code","dd2394b3":"code","e761c0dd":"code","f625303a":"code","287a5552":"code","23168d04":"code","1ed79422":"code","584b75b0":"code","e37ed691":"code","715e1977":"code","09c4f1a2":"code","1b6ae3c2":"code","f7632ddf":"code","637bd767":"code","eeae27f6":"code","717744e6":"code","1bb885d5":"code","db1d549c":"code","fa7acdc5":"code","0fb54a44":"code","ef00861b":"code","23381889":"code","6471afe8":"code","c50c0af9":"code","bc0407f7":"code","122a3e98":"code","7068ef72":"code","89b09320":"code","5765855d":"code","ad22af90":"code","2cb1f7d0":"code","4257b6f5":"code","0515ac92":"code","204d828a":"code","3ef946e8":"code","0f8bb381":"code","ed3ef832":"code","49fe87e8":"code","c45fa2c9":"code","47aad079":"code","93f5990f":"code","1c319b36":"code","2f137661":"code","cf8afb00":"code","625bcf8f":"markdown","66acc24d":"markdown","84bf4b0f":"markdown","ac8d84cf":"markdown","7dce232e":"markdown","50cfdfbc":"markdown","0092e406":"markdown","04fbafa4":"markdown","4154ac8f":"markdown","ac001a97":"markdown","71fd258f":"markdown","b2ef7cfc":"markdown","3bfbdbc9":"markdown","59e01b2e":"markdown","eff77a73":"markdown","f91f9028":"markdown","960667fa":"markdown","5f54960e":"markdown","6d2fd694":"markdown","1bbda155":"markdown","90525b61":"markdown","cac5ad1c":"markdown","859784a8":"markdown","a5982a43":"markdown","938fa58e":"markdown","9d186234":"markdown","e7557dcb":"markdown","e8cfc4cc":"markdown","e3e60cd1":"markdown","da6b8edf":"markdown","0a7511ff":"markdown","290349ed":"markdown","e813ed57":"markdown","73741e60":"markdown","b34a6c21":"markdown","a7ef6454":"markdown","1a593564":"markdown","65c3280e":"markdown","e39e475a":"markdown","ea8f655a":"markdown","49304cf3":"markdown","6b51e860":"markdown","049993e2":"markdown","1c3d3ef0":"markdown","b4c3a805":"markdown","22ecff34":"markdown","e1f34a2b":"markdown","7e6c996c":"markdown","c2d9abc0":"markdown","5810f4df":"markdown","10f630b9":"markdown","0235813f":"markdown","de019e58":"markdown","d6c451fb":"markdown","3641f88e":"markdown","36f3dff7":"markdown","cd5347cf":"markdown","0b35453b":"markdown","088279be":"markdown","dcdea481":"markdown","717f1fad":"markdown","ae3bc874":"markdown","d5e1fb91":"markdown","101cdfed":"markdown","e3388464":"markdown","0848d91f":"markdown","ecae9a94":"markdown","70e536ad":"markdown","3023667c":"markdown","d072c415":"markdown","5f3c0137":"markdown","a352a895":"markdown","17381979":"markdown","42b8c63f":"markdown","0ccd882d":"markdown","ddff5827":"markdown","ef72be4c":"markdown","a1a89383":"markdown","e0d840f3":"markdown","69461f9e":"markdown","2696ec9f":"markdown","4b4fcb89":"markdown","4ee8eb57":"markdown","5fd1ce8f":"markdown","5361f3c8":"markdown","132ea45b":"markdown"},"source":{"5287d570":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.style as style\nfrom scipy.stats import skew\nfrom scipy import stats\nimport matplotlib.gridspec as gridspec\nimport plotly\nimport plotly.express as px\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\n\n\n\n\n#Model Building\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import ElasticNetCV\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom lightgbm import LGBMRegressor\nimport xgboost as xgb\nfrom mlxtend.regressor import StackingCVRegressor\nfrom sklearn.metrics import mean_squared_error\n\n\n# Color Palette\n\ncustom_colors = [\"#A67BC5\",\"#BB1C8B\",\"#05A4C0\",'#CCEBC5',\"#D2A7D8\",'#FDDAEC',  \"#85CEDA\",]\ncustomPalette = sns.set_palette(sns.color_palette(custom_colors))\n\n# Set size\n\nsns.palplot(sns.color_palette(custom_colors),size=1)\nplt.tick_params(axis='both', labelsize=0, length = 0)\n\n","39667158":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","d67acd4a":"train.info()","d2f6bd34":"# command for work offline\nplotly.offline.init_notebook_mode(connected=True)","bee0cdcf":"fig = px.scatter(train, x='MasVnrArea' , y='SalePrice')\nfig.show()","6f328738":"fig = px.scatter(train, x='TotRmsAbvGrd' , y='SalePrice')\nfig.show()","097e86c2":"fig = px.scatter(train, x=\"LotFrontage\" , y=\"SalePrice\")\nfig.show()","bf8fc593":"fig = px.scatter(train, x=\"TotalBsmtSF\" , y=\"SalePrice\")\nfig.show()","914eecc6":"fig = px.bar(train, x=\"YearBuilt\", y=\"SalePrice\",\n              barmode='group',\n             height=600)\nfig.show()","ff53be04":"fig = px.bar(train, x=\"YearRemodAdd\", y=\"SalePrice\",\n              barmode='group',\n             height=600, color_discrete_sequence=px.colors.qualitative.Set1)\nfig.show()","4de0217d":"N = 2000","e6ae0f83":"train_x = train[\"2ndFlrSF\"]\ntrain_y = train[\"SalePrice\"]\ncolors = np.random.rand(2938)\nsz = np.random.rand(N)*30\n\nfig = go.Figure()\nfig.add_scatter(x = train_x,\n                y = train_y,\n                mode = 'markers',\n                marker = {'size': sz,\n                         'color': colors,\n                         'opacity': 0.6,\n                         'colorscale': 'Portland',\n                          \n                       })\n\nplotly.offline.iplot(fig)","9072fc63":"fig = px.pie(train, names = \"BsmtFinType1\", title = \"Quality of basement finished area\", color_discrete_sequence=px.colors.qualitative.Set3)\nfig.show()","42b3132e":"fig = px.pie(train, names = \"GarageType\", title = \"Garage location\", color_discrete_sequence=px.colors.qualitative.Set2)\nfig.show()","4e942caf":"fig = px.pie(train, names = \"SaleType\", title = \"Type of sale\", color_discrete_sequence=px.colors.qualitative.Set1)\nfig.show()","855862e2":"fig = px.pie(train, names = \"SaleCondition\", title = \"Condition of sale\")\nfig.show()","105e56a8":"fig =px.bar(train,x='ExterQual', y='SalePrice',barmode='group',\n             height=600)\nfig.show()","c60691dd":"fig =px.bar(train,x='MSZoning', y='SalePrice',barmode='group',\n             height=800, color_discrete_sequence=[\"fuchsia\"])\n\nfig.show()","68afcda6":"fig = px.scatter_matrix(train, dimensions=['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF'])\nfig.show()","30ba745f":"train.hist(bins=50, figsize=(20,15), color='orchid')\nplt.show()","6598074d":"print(train.keys())","95d6fc11":"sns.set_style(\"white\")\nsns.set_color_codes(palette=\"deep\")\nf,ax = plt.subplots(figsize=(14,10))\n\nsns.distplot(train['SalePrice'], color=\"Blue\" )\nax.set(ylabel = \"Frequency\")\nax.set(xlabel = \"SalePrice\")\nax.set(title = \"SalePrice Distribution\" )\nsns.despine(trim=True, left=True)\nplt.show()\n\n","1c888ad8":"fig = plt.figure(constrained_layout=True, figsize=(12,8))\ngrid = gridspec.GridSpec(ncols=3, nrows=4, figure=fig)\nsns.set_color_codes(palette=\"deep\")\n\n# QQplot\n\nax2 = fig.add_subplot(grid[2:,:2])\nstats.probplot(train['SalePrice'],plot=ax2)\nax2.set_title(\"QQplot of SalePrice\")\n\n # Boxplot\n    \nax3 = fig.add_subplot(grid[2:,2])\nsns.boxplot(train['SalePrice'],ax=ax3,orient=\"v\",color=\"Blue\")\nax3.set_title(\"Boxplot of SalePrice\")\nplt.show()","22aa39ff":"print(\"Skewness : %f\" % train['SalePrice'].skew() )\nprint(\"Kurtosis : %f\" % train['SalePrice'].kurt())","61a2410e":"# In this case, We use the numpy fuction log1p which  applies log(1+x) to all elements of the column.\n\ntrain['SalePrice'] = np.log1p(train['SalePrice'])\nsns.set_color_codes(palette=\"deep\")\n\n## Visualize of SalePrice after the normalization\nfig,(ax1,ax2) = plt.subplots(2,1,constrained_layout=True,figsize=(12,9))\n\n # Histrogram\nsns.distplot(train['SalePrice'],ax=ax1, color= \"red\")\nax1.set_title(\"Histrogram of SalePrice\")\n # QQplot\nstats.probplot(train['SalePrice'],plot=ax2)\nax2.set_title(\"QQplot of SalePrice\")\n\nplt.show()","aaa1ecbc":"trace0 = go.Box(\n    name = \"GrLivArea\",\n    y = train[\"GrLivArea\"]\n)\n\ntrace1 = go.Box(\n    name = \"MasVnrArea\",\n    y = train[\"MasVnrArea\"]\n)\n\ntrace2 = go.Box(\n    name = \"KitchenAbvGr\",\n    y = train[\"KitchenAbvGr\"]\n)\n\ntrace3 = go.Box(\n    name = \"BedroomAbvGr\",\n    y = train[\"BedroomAbvGr\"] \n)\n\ntrace4 = go.Box(\n    name = \"LotFrontage\",\n    y = train[\"LotFrontage\"]\n)\n\ntrace5 = go.Box(\n    name = \"GarageCars\",\n    y = train[\"GarageCars\"]\n)\ndata = [trace0, trace1, trace2, trace3, trace4,trace5  ]\nplotly.offline.iplot(data)","1d92b800":"fig = px.scatter(train, x='GrLivArea' , y='SalePrice')\nfig.show()","103975af":"train.iloc[np.where(train.GrLivArea > 4000)]","2eb55161":"train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<200000)].index,inplace=True)","17451462":"fig = px.scatter(train, x='GrLivArea' , y='SalePrice')\nfig.show()","10ddd078":"style.use('ggplot')\nsns.set_style('whitegrid')\n\nplt.subplots(figsize = (30,20))\nmask = np.zeros_like(train.corr(), dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nsns.heatmap(train.corr(), \n            cmap=sns.diverging_palette(20, 220, n=200), \n            mask = mask, \n            annot=True, \n            center = 0, \n           );\n \nplt.title(\"Heatmap of the Features\", fontsize = 30);","056e796e":"numerical_features = train.dtypes[train.dtypes != \"object\"].index\nprint(\"Number of Numerical features: \", len(numerical_features))\n\ncategorical_features = train.dtypes[train.dtypes == \"object\"].index\nprint(\"Number of categorical features:\", len(categorical_features))","b0529bc9":"\nplt.figure(figsize=(20,5))\n\nsns.heatmap(train.isnull(), yticklabels=\"None\", cbar=False)\nplt.title(\"Missing Values Heatmap\")","d8f820f9":"total = train.isnull().sum().sort_values(ascending=False)\npercent_1 = train.isnull().sum()\/train.isnull().count()*100\npercent_2 = (round(percent_1, 1)).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent_2], axis=1, keys=['total', 'Missing_Ratio'])\nmissing_data.head(20)","108a085c":"total = test.isnull().sum().sort_values(ascending=False)\npercent_1 = test.isnull().sum()\/test.isnull().count()*100\npercent_2 = (round(percent_1, 1)).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent_2], axis=1, keys=['total', 'Missing_Ratio'])\nmissing_data.head(20)","3111241c":"train['LotFrontage'] = train['LotFrontage'].fillna(train.LotFrontage.mean())\n\ntest['LotFrontage'] = test['LotFrontage'].fillna(test.LotFrontage.mean())","47014d26":"list1 =[\"Alley\",\n                       \"PoolQC\",\n                      \"MiscFeature\",\n                       \"Fence\",\n                       \"GarageCond\",\n                       \"GarageQual\",\n                       \"GarageFinish\",\n                       \"GarageType\",\n                       \"FireplaceQu\",\n                       \"BsmtExposure\",\n                       \"BsmtCond\",\n                       \"BsmtQual\",\n                       \"BsmtFinType1\",\n                       \"BsmtFinType2\",\n                       \"MasVnrType\"]\n                       \nfor i in list1:\n    \n    train[i] = train[i].fillna(\"None\")\n    test[i] = test[i].fillna(\"None\")","c4c2febf":"list2 = [\"MasVnrArea\",\n                          \"BsmtFinSF1\",\n                          \"BsmtFinSF2\",\n                           \"BsmtUnfSF\",\n                          \"TotalBsmtSF\",\n                          \"BsmtFullBath\",\n                          \"BsmtHalfBath\",\n                          \"GarageYrBlt\",\n                          \"GarageCars\",\n                          \"GarageArea\"]\n\nfor i in list2:\n    train[i] = train[i].fillna(0)\n    test[i] = test[i].fillna(0)","dd2394b3":"train [\"Utilities\"]= train [\"Utilities\"].fillna(\"AllPub\")\ntrain [\"Electrical\"] = train [\"Electrical\"] .fillna(\"SBrkr\")\ntrain [\"Functional\"] = train [\"Functional\"] .fillna(\"Typ\")","e761c0dd":"test [\"Utilities\"]=test [\"Utilities\"].fillna(\"AllPub\")\ntest[\"Electrical\"] = test[\"Electrical\"] .fillna(\"SBrkr\")\ntest [\"Functional\"] =test [\"Functional\"] .fillna(\"Typ\")","f625303a":"train [\"Exterior1st\"]= train[\"Exterior1st\"].fillna(train[\"Exterior1st\"].mode()[0])\ntrain [\"Exterior2nd\"]= train[\"Exterior2nd\"].fillna(train[\"Exterior2nd\"].mode()[0])\ntrain[\"KitchenQual\"] = train[\"KitchenQual\"] .fillna(train[\"KitchenQual\"].mode()[0])\ntrain[\"SaleType\"]  =   train[\"SaleType\"] .fillna(train[\"SaleType\"].mode()[0])","287a5552":"test [\"Exterior1st\"]= test[\"Exterior1st\"].fillna(test[\"Exterior1st\"].mode()[0])\ntest [\"Exterior2nd\"]= test[\"Exterior2nd\"].fillna(test[\"Exterior2nd\"].mode()[0])\ntest[\"KitchenQual\"] = test[\"KitchenQual\"] .fillna(test[\"KitchenQual\"].mode()[0])\ntest[\"SaleType\"]  =   test[\"SaleType\"] .fillna(test[\"SaleType\"].mode()[0])\ntest['MSZoning']=test['MSZoning'].fillna(test['MSZoning'].mode()[0])","23168d04":"# Some of the non-numeric predictors are stored as numbers, so we will convert them into strings.\n\n\n# MSSubClass\ntrain['MSSubClass'] = train['MSSubClass'].apply(str)\ntest['MSSubClass'] = test['MSSubClass'].apply(str)\n\n# we Change OverallCond into a categorical variable\ntrain['OverallCond'] = train['OverallCond'].astype(str)\ntest['OverallCond'] = test['OverallCond'].astype(str)\n\n#Year and month sold are transformed into categorical features.\ntrain['YrSold'] = train['YrSold'].astype(str)\ntrain['MoSold'] = train['MoSold'].astype(str)\n\ntest['YrSold'] = test['YrSold'].astype(str)\ntest['MoSold'] = test['MoSold'].astype(str)","1ed79422":"train.shape, test.shape","584b75b0":"cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n        'YrSold', 'MoSold')\n\nfor c in cols:\n    lbl = LabelEncoder() \n    lbl.fit(list(set(train[c].unique().tolist() + test[c].unique().tolist())))\n    train[c] = lbl.transform(list(train[c].values))\n    test[c] = lbl.transform(list(test[c].values))","e37ed691":"# Adding total sqfootage feature \ntrain['TotalSF'] = train['TotalBsmtSF'] + train['1stFlrSF'] + train['2ndFlrSF']\ntest['TotalSF'] = test['TotalBsmtSF'] + test['1stFlrSF'] + test['2ndFlrSF']","715e1977":"y_train = train.SalePrice\ntrain.drop(['SalePrice','Id'],axis=1,inplace=True)\ntest_Ids = test['Id']\ntest.drop('Id',axis=1,inplace=True)","09c4f1a2":"numeric_f = train.dtypes[train.dtypes != \"object\"].index\n\nskewed_f = train[numeric_f].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nskewness = pd.DataFrame({'Skew in train data' :skewed_f})\nskewness.head(10)","1b6ae3c2":"\nskewness = skewness[abs(skewness) > 0.75]\nprint(\"There are {} skewed numerical features in train data to Box Cox transform\".format(skewness.shape[0]))\n\nfrom scipy.special import boxcox1p\nskewed_features = skewness.index\nlam = 0.15\nfor feat in skewed_features:\n    train[feat] = boxcox1p(train[feat], lam)","f7632ddf":"numeric_f = test.dtypes[test.dtypes != \"object\"].index\n\n\nskewed_f = test[numeric_f].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nskewness = pd.DataFrame({'Skew in test data' :skewed_f})\nskewness.head(10)","637bd767":"skewness = skewness[abs(skewness) > 0.75]\nprint(\"There are {} skewed numerical features in test data to Box Cox transform\".format(skewness.shape[0]))\n\nfrom scipy.special import boxcox1p\nskewed_features = skewness.index\nlam = 0.15\nfor feat in skewed_features:\n    test[feat] = boxcox1p(test[feat], lam)","eeae27f6":"\ntrain = pd.get_dummies(train)\ntest = pd.get_dummies(test)\n\n# Balancing DataSets\n\nmissing_cols = set(train.columns) - set(test.columns)\nfor c in missing_cols:\n    test[c] = 0  \n\nmissing_cols = set(test.columns) - set(train.columns)\nfor c in missing_cols:\n    train[c] = 0\n    \ntest = test[train.columns.tolist()]\n\n# Checking Shapes\ntrain.shape,test.shape","717744e6":"X = train\nY = y_train\n\n# Partition the dataset in train + validation sets\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y,test_size = 0.33, random_state = 0)\nprint(\"X_train : \" + str(X_train.shape))\nprint(\"X_test : \" + str(X_test.shape))\nprint(\"y_train : \" + str(y_train.shape))\nprint(\"y_test : \" + str(y_test.shape))","1bb885d5":"kfolds = KFold(n_splits=10, shuffle=True, random_state=42)\n\ndef rmsle(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))\n\ndef cv_rmse(model, X=X):\n    rmse = np.sqrt(-cross_val_score(model, X, Y, scoring=\"neg_mean_squared_error\", cv=kfolds))\n    return (rmse)","db1d549c":"alphas_r =[12.3, 14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\nalphas1 = [1.0, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\nalphas2 = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 1.0]\nl1ratio_en = [0.6, 0.8, 0.85, 0.9, 0.95, 0.99, 1]","fa7acdc5":"Ridge = make_pipeline(RobustScaler(), RidgeCV(alphas= alphas_r, cv=kfolds))","0fb54a44":"Lasso = make_pipeline(RobustScaler(), LassoCV(alphas =alphas1, max_iter=2000,cv=kfolds, random_state= 45))","ef00861b":"ElasNet = make_pipeline(RobustScaler(), ElasticNetCV(alphas=alphas2, max_iter=1e7,cv=kfolds, l1_ratio=l1ratio_en))\n","23381889":"GBR = GradientBoostingRegressor(n_estimators=3000,learning_rate=0.05, max_depth=6, min_samples_split=10, min_samples_leaf=15, random_state=45\n      ,max_features= 'sqrt', loss='huber')","6471afe8":"XGBoost = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.01,\n                max_depth = 5, alpha = 10, n_estimators = 3400)","c50c0af9":"SVR = make_pipeline(RobustScaler(), SVR(C= 20, epsilon= 0.008, gamma=0.0003,))","bc0407f7":"LGBM = LGBMRegressor(objective='regression', \n                                       num_leaves=5,\n                                       learning_rate=0.05, \n                                       n_estimators=5000,\n                                       max_bin=200, \n                                       bagging_fraction=0.75,\n                                       bagging_freq=5, \n                                       bagging_seed=7,\n                                       feature_fraction=0.2,\n                                       feature_fraction_seed=7,\n                                       verbose=-1,\n)","122a3e98":"Stack_reg= StackingCVRegressor (regressors = (Ridge, Lasso, ElasNet, GBR, LGBM),\n                               meta_regressor= XGBoost,\n                               use_features_in_secondary=True)","7068ef72":"\nscore = cv_rmse(Ridge)\nscore = cv_rmse(Lasso)\nprint(\"LASSO: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","89b09320":"\nscore = cv_rmse(ElasNet)\nprint(\"Elastic Net: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n","5765855d":"\nscore = cv_rmse(SVR)\nprint(\"SVR: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","ad22af90":"score = cv_rmse(XGBoost)\nprint(\"XGBoost: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","2cb1f7d0":"\nscore = cv_rmse(GBR)\nprint(\"GBR: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","4257b6f5":"\nscore = cv_rmse(LGBM)\nprint(\"LGBM: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","0515ac92":"print('stacking_model')\n\nstacking_model = Stack_reg.fit(np.array(X), np.array(Y))","204d828a":"\nprint('ElasticNet')\n\nElasNet_model = ElasNet.fit(X, Y)","3ef946e8":"print('lasso')\nlasso_model = Lasso.fit(X, Y)","0f8bb381":"print('Ridge')\nRidge_model = Ridge.fit(X, Y)","ed3ef832":"\nprint('Svr')\nSVR_model = SVR.fit(X, Y)","49fe87e8":"print('GradientBoosting')\nGBR_model = GBR.fit(X, Y)","c45fa2c9":"print('xgboost')\n\nXGBoost_model = XGBoost.fit(X, Y)","47aad079":"print('lightgbm')\nLGBM_model = LGBM.fit(X, Y)","93f5990f":"def blend_models_predict(X):\n    return ((0.1 * ElasNet_model.predict(X)) + \\\n            (0.05 * lasso_model.predict(X)) + \\\n            (0.1 * Ridge_model.predict(X)) + \\\n            (0.1 * SVR_model.predict(X)) + \\\n            (0.1 * GBR_model.predict(X)) + \\\n            (0.15* XGBoost_model.predict(X)) + \\\n            (0.1 * LGBM_model.predict(X)) + \\\n            (0.3 * stacking_model.predict(np.array(X))))","1c319b36":"rmsle(Y, blend_models_predict(X))","2f137661":"submission_results = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\")","cf8afb00":"submission_results.iloc[:,1] = np.floor(np.expm1(blend_models_predict(test)))\n\nsubmission_results.to_csv('submission_results', index=False)","625bcf8f":"![](https:\/\/i.pinimg.com\/564x\/e1\/f0\/b2\/e1f0b20eb0773915fc6e9b91909adfa3.jpg)","66acc24d":"### **Log Transformation of the Dependant Variable(SalePrice)** ","84bf4b0f":"- ## **YearRemodAdd vs SalePrice**","ac8d84cf":"* **Support Vector Regressor**","7dce232e":"- **Seperating Columns for Skew check**","50cfdfbc":"* ###### **Check the percentage of missing values for each columns in test_data**","0092e406":"* Scatter Plot \n* Bar Plot\n* Pie Plot\n* scatter_matrix","04fbafa4":"* **Overview of the features**","4154ac8f":"- **Kurtosis**","ac001a97":"- ## **Garage location**","71fd258f":"### Submission","b2ef7cfc":"- ## **TotalBsmtSF vs SalePrice**","3bfbdbc9":"- ## **Condition of sale**","59e01b2e":"[Stacking Models for Improved Predictions](https:\/\/www.kdnuggets.com\/2017\/02\/stacking-models-imropved-predictions.html)","eff77a73":"* Checking the correlation\n\n* Impute missing values\n\n* Label Encoding\n\n* Transform skewed attributes","f91f9028":"- Exterior1st, Exterior2nd, KitchenQual, SaleType, MSZoning","960667fa":"* ## **Heatmap**","5f54960e":"* **Lasso**","6d2fd694":"* ##### **Check the percentage of missing values for each columns in train_data**","1bbda155":"- ## **Quality of basement finished area**","90525b61":"## **STEP 4 : Transforming and engineering features**","cac5ad1c":"- MasVnrArea, BsmtFinSF1,BsmtFinSF2,BsmtUnfSF,TotalBsmtSF, BsmtFullBath, BsmtHalfBath, GarageYrBlt,GarageCars, GarageArea","859784a8":"- ## **MasVnrArea vs SalePrice**","a5982a43":"- ## **YearBuilt vs SalePrice**","938fa58e":"- ## **TotRmsAbvGrd vs SalePrice**","9d186234":"- ## **Sale Price vs 2nd floor in sq feet**","e7557dcb":"- So now the skewed seems corrected, and the data is normally distributed.","e8cfc4cc":"- **Check the skew of all numerical features in test set**","e3e60cd1":"* ### **Numerical and Categorical Features**","da6b8edf":"#### **Overview of the Target Variable**","0a7511ff":"- **Transforming test Data**","290349ed":"- Utilities, Electrical, Functional","e813ed57":"### Stacked Regressor","73741e60":"![](https:\/\/briefingpapers.co.nz\/wp-content\/uploads\/2017\/05\/1.-Brian-Easton-house-price-inflation-PS.jpg)","b34a6c21":"- ## **MSZoning vs SalePrice**","a7ef6454":"### **Clean Outliers**","1a593564":"* #### **Splitting the data**","65c3280e":"- **Skewness**","e39e475a":"As we can see there is a correlation of:\n    \n- 83% between the TotRmsABVGr and GrLivArea\n- 83% between YearBuilt and Gragae YrBlt\n- 89% between GarageCars and GarageArea","ea8f655a":"* Splitting the data\n\n* Define the validation function\n\n* Modeling the base Models and the stacking model.\n\n* Calculating the Scores of Base models\n\n* Fitting the models\n\n* Blending Models\n","49304cf3":"* **Calcul the skewness and the kurtosis**","6b51e860":"* **Dataset**","049993e2":". Kurtosis is the measure of outliers present in the distribution.\n\n. There are three types of Kurtosis: Mesokurtic, Leptokurtic, and Platykurtic.\n\n. Mesokurtic distribution indicates an excess kurtosis of zero. This means that the data has a normal distribution.\n\n. Leptokurtic shows a positive excess kurtosis, so Leptokurtic distribution indicates heavy tails that's means the existance of large outliers .\n\n. A Platykurtic distribution shows a negative excess kurtosis.","1c3d3ef0":"* #### **After Removing Outliers**","b4c3a805":"* ### **Label Encoding**","22ecff34":"Here's a brief version of what you'll find in the data description file.\n\n* **SalePrice** - the property's sale price in dollars. This is the target variable that you're trying to predict.\n\n* **MSSubClass**: The building class\n\n* **MSZoning**: The general zoning classification\n\n* **LotFrontage**: Linear feet of street connected to property\n\n* **LotArea**: Lot size in square feet\n\n* **Street**: Type of road access\n\n* **Alley**: Type of alley access\n\n* **LotShape**: General shape of property\n\n* **LandContour**: Flatness of the property\n\n* **Utilities**: Type of utilities available\n\n* **LotConfig**: Lot configuration\n\n* **LandSlope**: Slope of property\n\n* **Neighborhood**: Physical locations within Ames city limits\n\n* **Condition1**: Proximity to main road or railroad\n\n* **Condition2**: Proximity to main road or railroad (if a second is present)\n\n* **BldgType**: Type of dwelling\n\n* **HouseStyle**: Style of dwelling\n\n* **OverallQual**: Overall material and finish quality\n\n* **OverallCond**: Overall condition rating\n\n* **YearBuilt**: Original construction date\n\n* **YearRemodAdd**: Remodel date\n\n* **RoofStyle**: Type of roof\n\n* **RoofMatl**: Roof material\n\n* **Exterior1st**: Exterior covering on house\n\n* **Exterior2nd**: Exterior covering on house (if more than one material)\n\n* **MasVnrType**: Masonry veneer type\n\n* **MasVnrArea**: Masonry veneer area in square feet\n\n* **ExterQual**: Exterior material quality\n\n* **ExterCond**: Present condition of the material on the exterior\n\n* **Foundation**: Type of foundation\n\n* |**BsmtQual**: Height of the basement\n\n* **BsmtCond**: General condition of the basement\n\n* **BsmtExposure**: Walkout or garden level basement walls\n\n* **BsmtFinType1**: Quality of basement finished area\n\n* **BsmtFinSF1**: Type 1 finished square feet\n\n* **BsmtFinType2**: Quality of second finished area (if present)\n\n* **BsmtFinSF2**: Type 2 finished square feet\n\n* **BsmtUnfSF**: Unfinished square feet of basement area\n\n* **TotalBsmtSF**: Total square feet of basement area\n\n* **Heating**: Type of heating\n\n* **HeatingQC**: Heating quality and condition\n\n* **CentralAir**: Central air conditioning\n\n* **Electrical**: Electrical system\n\n* **1stFlrSF**: First Floor square feet\n\n* **2ndFlrSF**: Second floor square feet\n\n* **LowQualFinSF**: Low quality finished square feet (all floors)\n\n* **GrLivArea**: Above grade (ground) living area square feet\n\n* **BsmtFullBath**: Basement full bathrooms\n\n* **BsmtHalfBath**: Basement half bathrooms\n\n* **FullBath**: Full bathrooms above grade\n\n* **HalfBath**: Half baths above grade\n\n* **Bedroom**: Number of bedrooms above basement level\n\n* **Kitchen**: Number of kitchens\n\n* **KitchenQual**: Kitchen quality\n\n* **TotRmsAbvGrd**: Total rooms above grade (does not include bathrooms)\n\n* **Functional**: Home functionality rating\n\n* **Fireplaces**: Number of fireplaces\n\n* **FireplaceQu**: Fireplace quality\n\n* **GarageType**: Garage location\n\n* **GarageYrBlt**: Year garage was built\n\n* **GarageFinish**: Interior finish of the garage\n\n* **GarageCars**: Size of garage in car capacity\n\n* **GarageArea**: Size of garage in square feet\n\n* **GarageQual**: Garage quality\n\n* **GarageCond**: Garage condition\n\n* **PavedDrive**: Paved driveway\n\n* **WoodDeckSF**: Wood deck area in square feet\n\n* **OpenPorchSF**: Open porch area in square feet\n\n* **EnclosedPorch**: Enclosed porch area in square feet\n\n* **3SsnPorch**: Three season porch area in square feet\n\n* **ScreenPorch**: Screen porch area in square feet\n\n* **PoolArea**: Pool area in square feet\n\n* **PoolQC**: Pool quality\n\n* **Fence**: Fence quality\n\n* **MiscFeature**: Miscellaneous feature not covered in other categories\n\n* **MiscVal**: $Value of miscellaneous feature\n\n* **MoSold**: Month Sold\n\n* **YrSold**: Year Sold\n\n* **SaleType**: Type of sale\n\n* **SaleCondition**: Condition of sale","e1f34a2b":"  ## STEP 1 : Loading the libraries \ud83d\udcda  & the dataset","7e6c996c":"![](https:\/\/i.pinimg.com\/originals\/c1\/01\/b0\/c101b0da6ea1a0dab31f80d9963b0368.png)","c2d9abc0":"## STEP 3: Preprocessing the dataset \ud83d\udd27","5810f4df":". Skewness is the degree of distortion from the symmetrical bell curve or the normal distribution.\n\n. symmetrical distribution must have a skewness of 0.\n\n. Skewness can be positive or negative.\n\n. Positive Skewness when The mean and median will be greater than the mode.\n\n. Negative Skewness The mean and median will be less than the mode.","10f630b9":"# **STEP 1 : Loading the libraries \ud83d\udcda & the dataset**\n\n# **STEP 2 : Data Visualization\ud83d\udcca\ud83d\udcc8**\n\n# **STEP 3 : Preprocessing the dataset \ud83d\udd27**\n\n# **STEP 4 : Transforming and engineering features**\n\n# **STEP 5 : Model Building**","0235813f":"* **B. Scatter Plot**","de019e58":"- The skewness value is 1, that means that the data are moderately skewed, and the high Kurtosis indicates that the data\n\n  has heavy tails or outliers, so we need to investigate!","d6c451fb":"* **XGB Regressor**","3641f88e":"- ## **MSSubClass vs SalePrice**","36f3dff7":"* We notice in the graph above that the variable target is right skewed, the best way to fix it is to perform a log transformation of the same data.","cd5347cf":"* ### **Adding new Feature**","0b35453b":"- ## **Type of sale**","088279be":"* **As we see, there are some points which are far from the population in the top right corner.**","dcdea481":"* **Gradient Boosting Regressor**","717f1fad":"* ### **Skewed Features**","ae3bc874":"## **Histogram for each numerical attribute**","d5e1fb91":"* **The presence of outliers in the dataset may affect our analysis and they can cause problems in statistical procedures. so we need to remove them.**","101cdfed":"* **Ridge**","e3388464":"* ### **Calculating the Scores of Base models**","0848d91f":"* #### **Getting Dummy Variables**","ecae9a94":"* ### **Base models**","70e536ad":"* ### **Dealing With Missing Values**","3023667c":"* **Before performing statistical analyses,we should identify potential outliers. According to this article [Tha author Dean De Cock ](www.amstat.org\/publications\/jse\/v19n3\/decock.pdf), there are outliers for the GR LIVE AREA, so we will visualize this feature graphically with the BoxPlot and ScatterPlot.**","d072c415":"* ## **LotFrontage vs SalePrice**","5f3c0137":"- ## **Scatterplot matrices** ","a352a895":"### **Discover outliers with visualization tools**","17381979":"* Checking the distribution of 'Sale Price'.\n\n* Log Transformation of the Dependant Variable\n\n* Detect outliers\n\n* Clean Outliers","42b8c63f":"* **light gbm**","0ccd882d":"###  **Skewness and the kurtosis**","ddff5827":"* **ElasticNet**","ef72be4c":"- **LotFrontage**","a1a89383":"- Alley, PoolQC, iscFeature, Fence, GarageCond, GarageQual, GarageFinish, GarageType, FireplaceQu, BsmtExposure, \n\n\n   BsmtCond, BsmtQual, BsmtFinType1, BsmtFinType2, MasVnrType\n\n ","e0d840f3":"A.**Box Plot**","69461f9e":"- **Check the skew of all numerical features in train set**","2696ec9f":"* ## **Blending Models**","4b4fcb89":"# STEP 5: Model Building","4ee8eb57":"* ## **Fitting the models**","5fd1ce8f":"* ### **Validation function**","5361f3c8":"- **Transforming train Data**","132ea45b":" ## **STEP 2 : Data Visualization\ud83d\udcca\ud83d\udcc8**"}}