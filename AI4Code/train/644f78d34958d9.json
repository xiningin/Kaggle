{"cell_type":{"c3604c67":"code","3d6f3353":"code","40c6244f":"code","6cf28ebf":"code","6d83b57c":"code","1b126c1e":"code","b0cf3b4a":"code","be3060c7":"code","f76ad200":"code","1feb45d9":"code","e1c284e9":"code","ef739846":"code","3bb9de11":"code","a5ca5ddb":"code","eed5be1b":"code","d3c0a2fd":"code","f53b8517":"markdown","3cecebc7":"markdown","8000139c":"markdown","00bc7897":"markdown"},"source":{"c3604c67":"import pandas as pd\nimport numpy as np\nimport plotly.express as px\n\ntrain = pd.read_csv('..\/input\/optiver-realized-volatility-prediction\/train.csv')\n\ntrain.head()","3d6f3353":"book_example = pd.read_parquet('..\/input\/optiver-realized-volatility-prediction\/book_train.parquet\/stock_id=0')\ntrade_example = pd.read_parquet('..\/input\/optiver-realized-volatility-prediction\/trade_train.parquet\/stock_id=0')\nstock_id = '0'\nbook_example = book_example[book_example['time_id']==5]\nbook_example.loc[:,'stock_id'] = stock_id\ntrade_example = trade_example[trade_example['time_id']==5]\ntrade_example.loc[:,'stock_id'] = stock_id","40c6244f":"book_example.head()","6cf28ebf":"trade_example.head()","6d83b57c":"book_example['wap'] = (book_example['bid_price1'] * book_example['ask_size1'] +\n                       book_example['ask_price1'] * book_example['bid_size1']) \/ (\n                       book_example['bid_size1']+ book_example['ask_size1'])","1b126c1e":"fig = px.line(book_example, x=\"seconds_in_bucket\", y=\"wap\", title='WAP of stock_id_0, time_id_5')\nfig.show()","b0cf3b4a":"def log_return(list_stock_prices):\n    return np.log(list_stock_prices).diff()","be3060c7":"# To compute the log return, we can simply take the logarithm of the ratio between \n# two consecutive WAP. \n# The first row will have an empty return as the previous book update is unknown, \n# therefore the empty return data point will be dropped.\nbook_example.loc[:,'log_return'] = log_return(book_example['wap'])\nbook_example = book_example[~book_example['log_return'].isnull()]\n","f76ad200":"fig = px.line(book_example, x=\"seconds_in_bucket\", y=\"log_return\", title='Log return of stock_id_0, time_id_5')\nfig.show()","1feb45d9":"# The realized vol of stock 0 in this feature bucket, will be:\n\ndef realized_volatility(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))\n\nrealized_vol = realized_volatility(book_example['log_return'])\nprint(f'Realized volatility for stock_id 0 on time_id 5 is {realized_vol}')\n","e1c284e9":"import os\nfrom sklearn.metrics import r2_score\nimport glob\n\nlist_order_book_file_train = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/book_train.parquet\/*')\n","ef739846":"def realized_volatility_per_time_id(file_path, prediction_column_name):\n    df_book_data = pd.read_parquet(file_path)\n    df_book_data['wap'] =(df_book_data['bid_price1'] * df_book_data['ask_size1']+df_book_data['ask_price1'] * df_book_data['bid_size1'])  \/ (\n                                      df_book_data['bid_size1']+ df_book_data[\n                                  'ask_size1'])\n    df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n    df_book_data = df_book_data[~df_book_data['log_return'].isnull()]\n    df_realized_vol_per_stock =  pd.DataFrame(df_book_data.groupby(['time_id'])['log_return'].agg(realized_volatility)).reset_index()\n    df_realized_vol_per_stock = df_realized_vol_per_stock.rename(columns = {'log_return':prediction_column_name})\n    stock_id = file_path.split('=')[1]\n    df_realized_vol_per_stock['row_id'] = df_realized_vol_per_stock['time_id'].apply(lambda x:f'{stock_id}-{x}')\n    return df_realized_vol_per_stock[['row_id',prediction_column_name]]\n","3bb9de11":"def past_realized_volatility_per_stock(list_file,prediction_column_name):\n    df_past_realized = pd.DataFrame()\n    for file in list_file:\n        df_past_realized = pd.concat([df_past_realized,\n                                     realized_volatility_per_time_id(file,prediction_column_name)])\n    return df_past_realized\n\ndf_past_realized_train = past_realized_volatility_per_stock(list_file=list_order_book_file_train,\n                                                           prediction_column_name='pred')","a5ca5ddb":"# Let's join the output dataframe with train.csv to see the performance of the naive prediction on training set\ntrain['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\ntrain = train[['row_id','target']]\ndf_joined = train.merge(df_past_realized_train[['row_id','pred']], on = ['row_id'], how = 'left')","eed5be1b":"from sklearn.metrics import r2_score\ndef rmspe(y_true, y_pred):\n    return  (np.sqrt(np.mean(np.square((y_true - y_pred) \/ y_true))))\nR2 = round(r2_score(y_true = df_joined['target'], y_pred = df_joined['pred']),3)\nRMSPE = round(rmspe(y_true = df_joined['target'], y_pred = df_joined['pred']),3)\nprint(f'Performance of the naive prediction: R2 score: {R2}, RMSPE: {RMSPE}')","d3c0a2fd":"list_order_book_file_test = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/book_test.parquet\/*')\ndf_naive_pred_test = past_realized_volatility_per_stock(list_file=list_order_book_file_test,\n                                                           prediction_column_name='target')\ndf_naive_pred_test.to_csv('submission.csv',index = False)","f53b8517":"* stockId=1 TimeId=5 Target=0.004136","3cecebc7":"# **Naive prediction: using past realized volatility as target**\n\nhttps:\/\/www.kaggle.com\/jiashenliu\/introduction-to-financial-concepts-and-data","8000139c":"We will evaluate the naive prediction result by two metrics: RMSPE and R squared.","00bc7897":"# Naive prediction: using past realized volatility as target"}}