{"cell_type":{"980dbd70":"code","21a3394e":"code","4df990dc":"code","33a8b365":"code","c474b0c8":"code","46d19148":"code","413b8cc9":"code","b06b265e":"code","f19bc462":"code","90732af6":"code","f1803ba5":"code","028a2734":"code","8c61c212":"code","b7bca230":"code","e10906f1":"code","a80ae30f":"code","bfac29b1":"code","ffbc10ee":"code","838fbbfa":"code","31efbc42":"markdown","bb259610":"markdown"},"source":{"980dbd70":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport pytesseract\n%matplotlib inline","21a3394e":"# First let's see the name of the images and explore the directory\nfilenames = os.listdir('..\/input\/images\/')\nprint(filenames)","4df990dc":"# Let's start with a simple image\nimg = cv2.imread(\"..\/input\/images\/img_en_1.jpg\") # image in BGR format\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nfig = plt.figure(figsize = [10,10])\nheight,width,channel = img.shape\nplt.imshow(img)\n\nprint(type(img))\nprint(height,width,channel)","33a8b365":"# as the image is simple enough, image_to_string method reads all characters almost perfectly!\ntext = pytesseract.image_to_string(img)\nprint(text)","c474b0c8":"# the output of OCR can be saved in a file in necessary\nfile = open('output.txt','a') # file opened in append mode\nfile.write(text)\nfile.close()","46d19148":"## lets start with a bit more complex image\n# the illumination isn't good as previous one. So the accuracy of OCR is deterioorating\n\nimg2 = cv2.imread('..\/input\/images\/img_en_2.jpg')\nimg2 = cv2.cvtColor(img2 , cv2.COLOR_BGR2RGB) # we want the image in RGB mode\n\ntext2= pytesseract.image_to_string(img2)\nfig = plt.figure(figsize = [10,10])\nplt.imshow(img2)\n\nprint(img2.shape)\nprint(text2)\n\n\n#we can see that the OCR for this image isn't that great. \n#Also it accidently read some of the texts form the previous page!","413b8cc9":"## Let's do some image processing for better OCR\n\nimg2= cv2.resize(img2,None, fx=.5, fy=0.5) #resizing the image\nprint(img2.shape)\nfig= plt.figure(figsize= [10,10])\nplt.imshow(img2)","b06b265e":"gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)   # converting image to grayscale\nfig = plt.figure(figsize= [10,10])\nplt.imshow(gray,cmap='gray', vmin=0, vmax=255)  # while plotting grayscale image with matplotlib, cmap should be defined","f19bc462":"text2= pytesseract.image_to_string(gray)\nprint(text2)\n## we can already see the improvement in result","90732af6":"#some letters are coming from previous page.lets try adaptive thresholding\nadaptive_threshold = cv2.adaptiveThreshold(gray,255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY ,85, 11 )\nfig = plt.figure(figsize= [10,10])\nplt.imshow(adaptive_threshold,cmap='gray', vmin=0, vmax=255)","f1803ba5":"text2= pytesseract.image_to_string(adaptive_threshold)\nprint(text2)\n## the accuracy has improved even more!\n# however, still pytesseract couldn't recognize a lot of characters, further processing can improve the scenatio.","028a2734":"img3 = cv2.imread('..\/input\/images\/img_bn_3.png')\ngray3 = cv2.cvtColor(img3, cv2.COLOR_BGR2GRAY)\nplt.imshow(gray3,cmap='gray', vmin=0, vmax=255)","8c61c212":"## the following line will throw error as bengali is not added as language by default\ntext3 = pytesseract.image_to_string(gray3, lang='..\/input\/book-pages\/Bengali.traineddata' )\nprint(text3)","b7bca230":"## From the error messaage, we can see that pytesessaract is installed in the directory called '\/usr\/share\/tesseract-ocr'\n# it is trying to search for the language file in the following directory\nfilenames = os.listdir('\/usr\/share\/tesseract-ocr\/4.00\/tessdata\/')\nprint(filenames)\n\n## we need to add the bengali.tranerdata in this directory","e10906f1":"## this block of code is taken from (https:\/\/realpython.com\/working-with-files-in-python\/) tutorial\n\nimport shutil\nsrc = '..\/input\/Bengali.traineddata'\ndest = '\/usr\/share\/tesseract-ocr\/4.00\/tessdata\/'\nshutil.copy(src, dest)\n\nfilenames = os.listdir('\/usr\/share\/tesseract-ocr\/4.00\/tessdata\/')\nprint(filenames) # check that the file is added in this directory which was not present before.","a80ae30f":"## Now our language is set !\n## let's process the image and detect the characters!\n\nimg3 = cv2.imread('..\/input\/images\/img_bn_3.png')\ngray3 = cv2.cvtColor(img3, cv2.COLOR_BGR2GRAY)\nret,thresh3 = cv2.threshold(img3,127,255,cv2.THRESH_BINARY)  # binary thresholding","bfac29b1":"## this function shows two images side-by-side\n# this function will plot two images side by side\ndef plot_two_images(img1, img2, title1=\"\", title2=\"\"):\n    fig = plt.figure(figsize=[15,15])\n    ax1= fig.add_subplot(121)\n    ax1.imshow(img1, cmap=\"gray\")\n    ax1.set(xticks=[], yticks=[], title=title1)\n    \n    ax2= fig.add_subplot(122)\n    ax2.imshow(img2, cmap=\"gray\")\n    ax2.set(xticks=[], yticks=[], title=title2)","ffbc10ee":"plot_two_images(img3, thresh3, 'Original image', 'Processed image')","838fbbfa":"text3 = pytesseract.image_to_string(thresh3, lang='Bengali' )\nprint(text3)","31efbc42":"# References:\n1. [Text recognition(OCR) with Tesseract and Python](https:\/\/www.youtube.com\/watch?v=JkzFjj2hjtw)\n2. [Pytesseract for Bengali language](https:\/\/stackoverflow.com\/questions\/43034112\/detecting-bangla-character-using-pytesseract)\n3. [Bengali traineddata for pytesseract](https:\/\/github.com\/tesseract-ocr\/tessdata\/blob\/master\/script\/Bengali.traineddata)\n4. [File mapulation with python OS directory](https:\/\/realpython.com\/working-with-files-in-python\/)","bb259610":"## working with Bengali OCR\n* now the language sould be defined. But pytesseract doesn't have Bengali language by default. So a file called Bengali.trineddata needed to be added in the directory in which pytecessaract is installed in this virtual machine!"}}