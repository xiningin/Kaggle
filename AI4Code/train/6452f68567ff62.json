{"cell_type":{"9eeae4d6":"code","1a37ea40":"code","a85e6803":"code","f65ff9a8":"code","d88ec14c":"code","46ae2ae5":"code","25f66589":"code","f1005d6b":"code","7a721159":"code","af1c91c6":"code","81d00427":"code","f7ed8d6b":"code","fd545524":"code","535614f9":"code","0ba55513":"code","3adfb9a9":"code","e6231542":"code","8422fd01":"code","8acf36b6":"code","901888df":"code","92a5a096":"code","83536112":"code","9ee6f1bc":"code","8f490470":"code","64bdec49":"code","2226055c":"code","48caf1b9":"code","9c3a0544":"code","e8381b34":"code","ff4b14f6":"code","8cf05f36":"code","4fbb7afa":"code","97253d04":"code","6bec6482":"code","5f7b828f":"code","e2decf5f":"code","7a00d5fd":"code","4682c88b":"code","551fc301":"code","76a0e72d":"code","88d19e69":"code","a8b1a285":"code","1ce27ee8":"code","6ade307d":"code","7819c8c1":"code","6a957a38":"code","16b209c7":"code","8881b59a":"code","667a74b0":"code","7650b369":"code","7499ec6a":"code","dedd8cf4":"markdown","951c60fb":"markdown","7e98f533":"markdown","78690521":"markdown","0c4a35ac":"markdown","f2190d6f":"markdown","125fae47":"markdown","9b5672bc":"markdown","02022a60":"markdown","094a40ea":"markdown","a9024250":"markdown","3880c898":"markdown","7972019c":"markdown","4220b7f3":"markdown","aca3e85e":"markdown","55cb5c1f":"markdown","c60dbb19":"markdown","f7a2b91f":"markdown"},"source":{"9eeae4d6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1a37ea40":"\nimport matplotlib.pyplot as plt\nimport spacy\nimport string\nimport pickle\nfrom spacy.lang.en.stop_words import STOP_WORDS\nfrom spacy.lang.en import English\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.base import TransformerMixin \nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split","a85e6803":"df=pd.read_csv(\"..\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv\")","f65ff9a8":"df.head()","d88ec14c":"#ONE REVIEW\ndf['review'][0]","46ae2ae5":"#df=df.sample(50000)","25f66589":"df.shape","f1005d6b":"df['sentiment'].replace({'positive':1,'negative':0},inplace=True)","7a721159":"df.head()","af1c91c6":"import re\nclean=re.compile('<.*?>')\nre.sub(clean, '', df.iloc[2].review)","81d00427":"#Function to clean HTML tags\ndef clean_html(text):\n    clean=re.compile('<.*?>')\n    return re.sub(clean, '', text)","f7ed8d6b":"df['review']=df['review'].apply(clean_html)","fd545524":"#Converting to lowercase\n\ndef convert_lower(text):\n    return text.lower()","535614f9":"df['review']=df['review'].apply(convert_lower)","0ba55513":"#function to remove special characters\n\ndef remove_special(text):\n    x=''\n    for i in text:\n        if i.isalnum():\n            x=x+i\n        else:\n            x=x + ' '\n    return x\n    \n\n","3adfb9a9":"remove_special('He lives @ Avenue 45')","e6231542":"df['review']=df['review'].apply(remove_special)","8422fd01":"#Remove stop words\n\nimport nltk","8acf36b6":"from nltk.corpus import stopwords","901888df":"stopwords.words('english')","92a5a096":"len(stopwords.words('english'))","83536112":"def remove_stopwords(text):\n    x=[]\n    for i in text.split():\n        if i not in stopwords.words('english'):\n            x.append(i)\n    y=x[:]\n    x.clear()\n    return y","9ee6f1bc":"df['review']=df['review'].apply(remove_stopwords)","8f490470":"df","64bdec49":"#Now we will perform stemming \n\nfrom nltk.stem.porter import PorterStemmer\nps=PorterStemmer()","2226055c":"y=[]\ndef stem_words(text):\n    for i in text:\n        y.append(ps.stem(i))\n    z=y[:]\n    y.clear()\n    return z","48caf1b9":"stem_words(['I','loving','loved','loves'])","9c3a0544":"df['review']=df['review'].apply(stem_words)","e8381b34":"df","ff4b14f6":"#Join Back\n\ndef join_back(list_input):\n    return \" \".join(list_input)","8cf05f36":"df['review']=df['review'].apply(join_back)","4fbb7afa":"df['review']","97253d04":"from sklearn.feature_extraction.text import CountVectorizer\ncv=CountVectorizer(max_features=1000)","6bec6482":"X=cv.fit_transform(df['review']).toarray()","5f7b828f":"X.shape","e2decf5f":"X[0]","7a00d5fd":"X[0].max()","4682c88b":"y=df.iloc[:,-1].values","551fc301":"y","76a0e72d":"y.shape","88d19e69":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)","a8b1a285":"X_train.shape","1ce27ee8":"X_test.shape","6ade307d":"from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB","7819c8c1":"clf1=GaussianNB()\nclf2=MultinomialNB()\nclf3=BernoulliNB()","6a957a38":"clf1.fit(X_train,y_train)\nclf2.fit(X_train,y_train)\nclf3.fit(X_train,y_train)","16b209c7":"y_pred1=clf1.predict(X_test)\ny_pred2=clf2.predict(X_test)\ny_pred3=clf2.predict(X_test)\n","8881b59a":"from sklearn.metrics import accuracy_score","667a74b0":"print(\"Gaussian\",accuracy_score(y_test,y_pred1))\nprint(\"Multinomial\",accuracy_score(y_test,y_pred2))\nprint(\"Bernoulli\",accuracy_score(y_test,y_pred3))\n\n      ","7650b369":"Finding accuracy using SUPPORT VECTOR MACHINE Model.","7499ec6a":"from sklearn.svm import SVC\nsvc_model=SVC()\n\n\nsvc_model.fit(X_train,y_train)\nprediction=svc_model.predict(X_test)\nprint(accuracy_score(y_test,prediction))\nprint(metrics.confusion_matrix(y_text,prediction))","dedd8cf4":"Applying stem_words function to our review column.","951c60fb":"This means there is one word in the first review which occurs most of the times i.e. 3 in the first review.","7e98f533":"This means in my data set I have 36526 unique words.","78690521":"Replacing positive with 1 and negative with 0","0c4a35ac":"The string is iterating character by character and for every char I'm asking it is alphanumeric or not.If not then I'll simply replace that thing with a space otherwise I'll just concatenate it into an empty string.","f2190d6f":"It means 50000 rows and 2 columns","125fae47":"Applying the function to our review column","9b5672bc":"Applying remove_stopwords function to our review column.\n","02022a60":"# Text Cleaning\n>>1. Sample 10000 rows \n>>2. Remove HTML tags\n>>3. Remove special characters\n>>4. Removing stop words\n>>5. Stemming","094a40ea":"*To remove HTML tags*","a9024250":"Now the review column doesn't have any tags.","3880c898":"We are taking every word of the review and passing it to the stem function.","7972019c":"I'm creating a stopwords function; in this we are taking a text i.e. each review and hen splitting it to convert into list.If any word of our review is not there in the stopwords list then we will append it into an empty list.\nI'm putting all the contents of x into y and then clearing x so that if we get next review that list is empty.","4220b7f3":"Here I have taken the size of the test set to be 30% of the total dataset.","aca3e85e":"Finding acuuracy using NAIVE BAYES Model.","55cb5c1f":"X,y; Splitting my dataset into two parts : Training set and Test set(already known).\n\nWe will compare the true value of the test test with the predicted value of the algorithm to get the accuracy.","c60dbb19":"Applying the remove_special function on our review column.","f7a2b91f":"Extracting the last column which is the labels."}}