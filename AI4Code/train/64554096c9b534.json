{"cell_type":{"5d7741e9":"code","763b7979":"code","fcfe4aa2":"code","912a16ec":"code","a981417e":"code","f5a19431":"code","654ea1da":"code","dfb08dff":"code","2d33ecc5":"code","dbc017dd":"code","a212d226":"code","71f4ab6c":"code","54d04e18":"code","66d19c6d":"code","c67a20ae":"code","2ac6ce11":"code","da5419e0":"code","49f94679":"code","1b5ea412":"code","21ed4c44":"code","f2857300":"code","7a9d997a":"code","2fe11f8a":"code","1d6d7866":"code","db902d9b":"code","d5afabf1":"code","8054ff51":"code","004d7753":"code","7a14c602":"code","1870204c":"code","320c6c7e":"code","80cc4452":"code","59878335":"code","f747cf4b":"code","c65f168e":"code","cd986515":"code","3fcdbb18":"code","3a02304c":"code","3f997c68":"code","2de1d602":"code","f368fdf9":"code","dfe49b41":"code","7a55886a":"code","5678dc01":"code","65a93346":"markdown","3ca04c29":"markdown","ec97a320":"markdown","6daac08e":"markdown","b92ac578":"markdown","0d969187":"markdown","bf7fbe4e":"markdown","1d728637":"markdown","5705f5bc":"markdown","b99cb707":"markdown","eda13ed7":"markdown","cd67174c":"markdown","fbce2a92":"markdown","db032cc0":"markdown","df8500cd":"markdown","6583d007":"markdown"},"source":{"5d7741e9":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","763b7979":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntarget='Survived'","fcfe4aa2":"data = pd.concat([train,test],axis=0)","912a16ec":"data.head()","a981417e":"data[['Name','SibSp','Parch']].isna().sum()","f5a19431":"data['Name_title']=data['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split('.')[0])\ndata['Family_size']=data['SibSp']+data['Parch']+1\ndata['Solo']=0\ndata.loc[data['Family_size']==1,'Solo']=1","654ea1da":"data.describe(include='all')","dfb08dff":"data.nunique()","2d33ecc5":"# data= pd.get_dummies(data,columns=['Pclass','Sex','SibSp','Parch'])","dbc017dd":"data.isna().sum()","a212d226":"plt.figure(figsize=(12,12))\nsns.heatmap(data.corr())","71f4ab6c":"data['Embarked'].isna().sum()","54d04e18":"emb_train = data.loc[data['Embarked'].notna(),['Pclass','Fare','Parch','SibSp','Embarked']]\nemb_missed= data.loc[data['Embarked'].isna(),['Pclass','Fare','Parch','SibSp']]\nemb_train=emb_train.dropna()\nemb_train=pd.get_dummies(emb_train,columns=['Pclass','Parch','SibSp'])\nemb_missed=pd.get_dummies(emb_missed,columns=['Pclass','Parch','SibSp'])","66d19c6d":"emb_x=emb_train.columns[emb_train.columns != 'Embarked'].tolist()\nemb_y='Embarked'\nemb_train1, emb_val, train1_embarked,val_embarked = train_test_split(emb_train[emb_x],emb_train[emb_y],stratify=emb_train[emb_y], test_size=0.15, random_state=122)","c67a20ae":"from sklearn.neighbors import KNeighborsClassifier \nknn = KNeighborsClassifier(n_neighbors = 3).fit(emb_train1, train1_embarked)\nprint('Accuracy: {:.0f}%'.format(knn.score(emb_val,val_embarked)*100))\ndel(emb_train1, emb_val, train1_embarked,val_embarked)","2ac6ce11":"emb_model = KNeighborsClassifier(n_neighbors=3)\nemb_model.fit(emb_train[emb_x],emb_train[emb_y])\ndata_emb=data.copy()\ndata_emb=pd.get_dummies(data_emb,columns=['Pclass','Parch','SibSp'])\ndata.loc[data['Embarked'].isna(),'Embarked']=emb_model.predict(data_emb.loc[data_emb['Embarked'].isna(),emb_x])\ndel(data_emb,emb_x,emb_y)","da5419e0":"data['Embarked'].isna().sum()","49f94679":"data['Fare'].isna().sum()","1b5ea412":"#Function to get the closest value from the dataset for the passed value\ndef get_closest(data,value):\n    a=data.unique().tolist()\n    min_idx=min(range(len(a)),key=lambda i: abs(a[i]-value))\n    return a[min_idx]","21ed4c44":"data[data[target].isna()]['Fare']=data[data[target].isna()]['Fare'].apply(lambda x: get_closest(data[data[target].notna()]['Fare'],x))","f2857300":"data.groupby(['Embarked','Pclass'])['Fare'].mean()","7a9d997a":"#Getting the Pclass and Embarked of the missing value of Fare\ndata.loc[data['Fare'].isna(),['Pclass','Embarked']]","2fe11f8a":"#Since the mean of Pclass=3 and Embarked=S is 14.44\nFare=data.loc[(data[target].isna())&(data['Pclass']==3)&(data['Embarked']=='S'),'Fare'].unique().tolist()\ndata.loc[data['Fare'].isna(),'Fare']=Fare[min(range(len(Fare)),key=lambda i: abs(Fare[i]-14.435422))]","1d6d7866":"data['Fare'].isna().sum()","db902d9b":"data['Age'].isna().sum()","d5afabf1":"data.loc[data['Age'].notna(),'Name_title'].value_counts()","8054ff51":"data.loc[data['Age'].isna(),'Name_title'].value_counts()","004d7753":"from sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nage_df=data[data['Age'].notna()][['Name_title','Solo','Age']]\nage_df=pd.get_dummies(age_df,columns=['Name_title'],drop_first=True)\nage_feat=age_df.columns[age_df.columns != 'Age'].tolist()\nage_train,age_val,age_train_lbl,age_val_lbl=train_test_split(age_df[age_feat],age_df['Age'], test_size = 0.3,random_state=10)\n    \nfrom sklearn.model_selection import GridSearchCV\nparams = {'n_neighbors':range(1,20)}\n\nknn = KNeighborsRegressor()\n\nmodel = GridSearchCV(knn, params, cv=25)\nmodel.fit(age_train,age_train_lbl)\nprint(model.best_params_)\n\ndel(age_train,age_val,age_train_lbl,age_val_lbl,model)","7a14c602":"age_model = KNeighborsRegressor(n_neighbors=18)\nage_model.fit(age_df[age_feat],age_df['Age'])\ndata_age=data.copy()\ndata_age=pd.get_dummies(data_age,columns=['Name_title'])\ndata.loc[data['Age'].isna(),'Age']=age_model.predict(data_age.loc[data_age['Age'].isna(),age_feat])\ndel(age_df,data_age,age_feat,age_model)","1870204c":"data['Age'].isna().sum()","320c6c7e":"data['Age_bins']=pd.qcut(data['Age'],5)\ndata['Fare_bins']=pd.qcut(data['Fare'],4)","80cc4452":"data=data.drop(['PassengerId','Cabin','Name','SibSp','Parch','Ticket','Age','Fare'],axis=1)","59878335":"data['Sex'] = data['Sex'].map({'male':0,'female':1})\ndata.head()","f747cf4b":"data=pd.get_dummies(data,columns=['Pclass','Name_title','Embarked','Age_bins','Fare_bins'],drop_first=True)\nfeatures=data.columns.tolist()\nfeatures.remove(target)\ndata_train=data.loc[data[target].notna()]\ndata_test=data.loc[data[target].isna()]","c65f168e":"x_train=data_train[features]\ny_train=data_train[target].astype(int)\nx_test=data_test[features]","cd986515":"y_train = np.array(y_train)","3fcdbb18":"from sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\nscaler.fit(x_train)\nx_scaled_train=scaler.transform(x_train)\nx_scaled_train","3a02304c":"x_scaled_test=scaler.transform(x_test)\nx_scaled_test","3f997c68":"param_test1 = {'max_depth':range(1,10),\n               'min_child_weight':range(1,6)\n              }\ngsearch1 = GridSearchCV(\n    estimator = XGBClassifier(learning_rate =0.05,\n                              n_estimators=500,\n                              max_depth=5,\n                              min_child_weight=1,\n                              gamma=0,\n                              subsample=0.8,\n                              colsample_bytree=0.8,\n                              objective= 'binary:logistic',\n                              nthread=4,\n                              scale_pos_weight=1,\n                              seed=27),\n    param_grid = param_test1,\n    scoring='roc_auc',\n    n_jobs=4,\n    cv=5)\ngsearch1.fit(x_scaled_train,y_train)\ngsearch1.best_params_, gsearch1.best_score_","2de1d602":"param_test2 = {'gamma':[i\/10.0 for i in range(0,5)]\n              }\ngsearch2 = GridSearchCV(\n    estimator = XGBClassifier(learning_rate =0.05,\n                              n_estimators=500,\n                              max_depth=2,\n                              min_child_weight=2,\n                              gamma=0,\n                              subsample=0.8,\n                              colsample_bytree=0.8,\n                              objective= 'binary:logistic',\n                              nthread=4,\n                              scale_pos_weight=1,\n                              seed=27),\n    param_grid = param_test2,\n    scoring='roc_auc',\n    n_jobs=4,\n    cv=5)\ngsearch2.fit(x_scaled_train,y_train)\ngsearch2.best_params_, gsearch2.best_score_","f368fdf9":"param_test3 = {'subsample':[i\/100.0 for i in range(75,90,5)],\n               'colsample_bytree':[i\/100.0 for i in range(75,90,5)]\n              }\n\ngsearch3 = GridSearchCV(\n    estimator = XGBClassifier(learning_rate =0.05,\n                              n_estimators=500,\n                              max_depth=2,\n                              min_child_weight=2,\n                              gamma=0,\n                              subsample=0.8,\n                              colsample_bytree=0.8,\n                              objective= 'binary:logistic',\n                              nthread=4,\n                              scale_pos_weight=1,\n                              seed=27),\n    param_grid = param_test3,\n    scoring='roc_auc',\n    n_jobs=4,\n    cv=5)\ngsearch3.fit(x_scaled_train,y_train)\ngsearch3.best_params_, gsearch3.best_score_","dfe49b41":"param_test4 = {'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]}\n\ngsearch4 = GridSearchCV(\n    estimator = XGBClassifier(learning_rate =0.05,\n                              n_estimators=500,\n                              max_depth=2,\n                              min_child_weight=2,\n                              gamma=0,\n                              subsample=0.8,\n                              colsample_bytree=0.8,\n                              objective= 'binary:logistic',\n                              nthread=4,\n                              scale_pos_weight=1,\n                              seed=27),\n    param_grid = param_test4,\n    scoring='roc_auc',\n    n_jobs=4,\n    cv=5)\ngsearch4.fit(x_scaled_train,y_train)\ngsearch4.best_params_, gsearch4.best_score_","7a55886a":"predictor=XGBClassifier(learning_rate =0.05,\n                          n_estimators=500,\n                          max_depth=2,\n                          min_child_weight=2,\n                          gamma=0,\n                          subsample=0.8,\n                          colsample_bytree=0.8,\n                          objective= 'binary:logistic',\n                          nthread=4,\n                          reg_alpha=1e-5,\n                          scale_pos_weight=1,\n                          seed=27)\npredictor.fit(x_scaled_train,y_train)\nsubmission=pd.DataFrame(columns=['PassengerId',target])\nsubmission['PassengerId']=test['PassengerId']\nsubmission[target]=predictor.predict(x_scaled_test)\nsubmission[target]=submission[target].apply(lambda x: int(x))\nsubmission.head()","5678dc01":"submission.to_csv('xgb.csv',index=False)","65a93346":"### Preprocessing\n* Drop columns **PassengerId**,**Cabin**,**Name** and **Ticket**.\n* Divide columns **Age** and **Fare** into bins.","3ca04c29":"The fare should be dependent on the Passenger Class and Embarkment location mainly.\nSo testing this hypothesis","ec97a320":"## Loading the Dataset","6daac08e":"### Fare","b92ac578":"## PARAMETER TUNING","0d969187":"## Handling missing values.","bf7fbe4e":"### Age","1d728637":"**Mapping the Fare values of Test data to the closest Fare values for the train data.**","5705f5bc":"It can seen that the fares for different embarkment location has a decreasing mean with the downgradation of Passenger Class.","b99cb707":"The least error is obtained using K = 18","eda13ed7":"Columns with missing values are :\n* Fare\n* Age\n* Cabin\n* Embarked","cd67174c":"Using K-Nearest Neighbours classifier with *n_neighbors = 3* we got a validation accuracy of ~86%. Using this we will impute the missing Embarked values.","fbce2a92":"Few numerical columns are having very few unique values and hence they can be categorical variables.\nSo we need to convert those columns into dummy variables.","db032cc0":"The mean of the Target column is around 0.383 which means there exists class imbalance in the target variable which should be taken care of. The distribution of Survived and Not Survived population is 38% and 62% respectively.","df8500cd":"## Importing Libraries","6583d007":"### Embarked"}}