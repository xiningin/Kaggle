{"cell_type":{"aa999c20":"code","4bd2abc2":"code","7b1adc9b":"code","66b7e5fe":"code","8962228b":"code","e72e26be":"code","62ad86e4":"code","c9597918":"code","51b547a2":"code","670f2574":"code","2df17d64":"code","9a0d57d7":"code","fd6fd51e":"code","e2802406":"code","aed6350b":"code","9d44d920":"code","3c770fd8":"code","47791310":"code","d965f34c":"code","f091fe2d":"code","2a4a14f7":"code","4da6275a":"code","d9d16c1b":"code","0ce84b1a":"code","e87441ad":"code","0640ce18":"code","5bd2c67a":"code","8106c1f9":"code","5bf9d04b":"code","6e840199":"code","2ff51d1f":"code","3b96ce10":"code","1a2bc803":"code","ff2b7673":"code","740b272d":"code","6fd28d3e":"code","4a1a46c0":"code","07bca720":"code","025b2c01":"code","7f2add0b":"code","a733e63c":"code","27b31584":"code","9202f5c0":"code","b930fb04":"code","d11a4ddb":"code","41152366":"code","670d09d5":"code","49879b9a":"code","638614c4":"code","3fd6cf1f":"code","e96c60d9":"code","3b96880b":"code","ca205313":"code","cdc0fc34":"code","0016a72a":"code","4059b9d8":"code","101eb020":"code","005ee42b":"code","b7aad410":"markdown","99bbd1ab":"markdown","6b3ce9f9":"markdown","5310a37d":"markdown","0f45d320":"markdown"},"source":{"aa999c20":"import numpy as np \nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom matplotlib import pyplot as plt\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_curve\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, LabelEncoder\nfrom sklearn.feature_selection import RFE\nfrom sklearn.inspection import permutation_importance\nimport warnings\nwarnings.filterwarnings(\"ignore\")","4bd2abc2":"train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntrain_notarget = train.drop([\"Survived\"], axis=1)\ncomplete = train_notarget.append(test, ignore_index=True)","7b1adc9b":"#Ya\u015ftaki NaN de\u011ferleri veri setinin ya\u015f ortalamas\u0131yla doldurmak ideal gibi\n\n#Kabin kolonunu d\u00fc\u015f\u00fcrmek gerek, herhangi bir imputation metodu uygulamak i\u00e7in \u00e7ok az kullan\u0131labilir veri var\n\n#Embarked kolonundaki iki NaN sat\u0131r\u0131 d\u00fc\u015f\u00fcrmek gerek\ntrain.info()","66b7e5fe":"train.head(15)","8962228b":"train.Embarked.value_counts()","e72e26be":"train.dropna(subset=[\"Embarked\"], inplace=True)\ntrain.drop(\"Cabin\", axis=1, inplace=True)","62ad86e4":"#Ya\u015f s\u00fctunu hari\u00e7 her s\u00fctunda 889 sat\u0131r var, Age s\u00fctununu da ortalamalarla doldurunca 889 olacak\ntrain.info()","c9597918":"#Ya\u015f s\u00fctununu da ortalama ya\u015f\u0131 kullanarak doldurdum\nmean_age = train.Age.mean()\ntrain.fillna(value=mean_age, inplace=True)\ntrain.info()","51b547a2":"#Object veri tiplerini int64'e \u00e7evirerek matematiksel i\u015flem yap\u0131labilecek hale getirdim.\ntrain.replace({\"male\":0, \"female\":1}, inplace = True)\ntrain.replace({\"S\":0, \"C\":1, \"Q\":2}, inplace = True)","670f2574":"#Yolcu isimleri ve bilet kodlar\u0131 algoritma taraf\u0131ndan kullan\u0131labilecek say\u0131sal girdilere \u00e7evrilemez, bu y\u00fczden d\u00fc\u015f\u00fcr\u00fclmesi gerek.\n#Ayr\u0131ca PassengerId s\u00fctununun da her ne kadar int64 olsa da yorumlanabilir (en az\u0131ndan benim yorumlayabilece\u011fim) bir say\u0131sal de\u011fer olmamas\u0131ndan \u00f6t\u00fcr\u00fc d\u00fc\u015f\u00fcr\u00fclmesi \u015fart.\ntrain.drop([\"Ticket\", \"PassengerId\"], axis=1, inplace=True)","2df17d64":"#Veri temiz ve i\u015flenmeye haz\u0131r duruyor.\ntrain.info()\ntrain.columns","9a0d57d7":"#Bo\u015f bir k\u00fcme olu\u015fturup train veri setindeki t\u00fcm isimleri taray\u0131p virg\u00fclle ayr\u0131ld\u0131ktan sonra\n#ikinci s\u0131rada gelen s\u00f6zc\u00fc\u011f\u00fc bu bo\u015f k\u00fcmeye eklettim. Yani ki\u015finin unvan\u0131n\u0131. Ard\u0131ndan unvan\u0131n\n#sonundaki noktay\u0131 kald\u0131rd\u0131m.\ntitles = set()\nfor name in train[\"Name\"]:\n    titles.add(name.split(\",\")[1].split(\".\")[0].strip())\n\n#K\u00fcmedeki unvanlar\u0131 gemi memurlar\u0131, asiller, kad\u0131n ve erkekler olacak \u015fekilde dictionary i\u00e7erisinde\n#s\u0131n\u0131flara ay\u0131rd\u0131m.\ntitle_dict = {'Capt':\"Officer\",\n 'Col':\"Officer\",\n 'Don':\"Royal\",\n 'Dr':\"Officer\",\n 'Jonkheer':\"Royal\",\n 'Lady':\"Royal\",\n 'Major':\"Officer\",\n 'Master':\"Royal\",\n 'Miss':\"Mrs\",\n 'Mlle':\"Mrs\",\n 'Mme':\"Mrs\",\n 'Mr':\"Mr\",\n 'Mrs':\"Mrs\",\n 'Ms':\"Mrs\",\n 'Rev':\"Officer\",\n 'Sir':\"Royal\",\n 'the Countess':\"Royal\"}\n\n#Ard\u0131ndan bu s\u0131n\u0131flar\u0131 veri setindeki unvanlara uygulayarak title ad\u0131nda yeni bir feature kolonu olu\u015fturdum.\ntrain[\"title\"] = train[\"Name\"].map(lambda name: name.split(\",\")[1].split(\".\")[0].strip())\ntrain[\"title\"] = train[\"title\"].map(title_dict)\ntrain.title.value_counts()\ntrain.replace({\"Mr\":1, \"Mrs\":2, \"Royal\":3, \"Officer\":4}, inplace=True)","fd6fd51e":"#Kad\u0131nlar ve \u00e7ocuklar daha fazla hayatta kald\u0131\u011f\u0131ndan \n#ya\u015f ortalamas\u0131n\u0131n alt\u0131ndaki kad\u0131nlar\u0131 g\u00f6steren bir kolon\n#belki bir \u015feyler anlatabilir.\ntrain[\"young_female\"] = (train[\"Age\"] <= train.Age.mean()) & (train[\"Sex\"] == 1)\ntrain[\"young_female\"] = train[\"young_female\"].astype(\"int64\")\ntrain.young_female.isna().value_counts()","e2802406":"#Yukar\u0131daki h\u00fccre ile ayn\u0131 i\u015flem say\u0131l\u0131r, yaln\u0131zca \"ve\" operat\u00f6r\u00fcn\u00fc \"veya\" ile\n#de\u011fi\u015ftirdim. Yani gemidekilerin ortalama ya\u015f\u0131nda ya da ortalamadan daha gen\u00e7\n#ki\u015filer veya kad\u0131n olanlar\u0131 bar\u0131nd\u0131ran bir kolon ekledim. \ntrain[\"young_or_female\"] = (train[\"Age\"] <= train.Age.mean()) | (train[\"Sex\"] == 1)\ntrain[\"young_or_female\"] = train[\"young_or_female\"].astype(\"int64\")\ntrain.young_or_female.isna().value_counts()","aed6350b":"#Ki\u015filerin gemide ka\u00e7 akrabas\u0131 (\u00e7ocuk ve e\u015f\/karde\u015f) oldu\u011funu g\u00f6steren bir kolon olu\u015fturdum \ntrain[\"family_count\"] = train[\"SibSp\"] + train[\"Parch\"]\ntrain[\"family_count\"].astype(\"int64\")\ntrain.family_count.value_counts()","9d44d920":"#Gemide akrabas\u0131 olanlar\u0131n ya\u015fam oran\u0131yla alakal\u0131 bir farkl\u0131l\u0131k olabilir.\ntrain[\"has_family\"] = (train[\"SibSp\"] + train[\"Parch\"]) > 0\ntrain[\"has_family\"].astype(\"int64\")\ntrain.has_family.value_counts()","3c770fd8":"#Gemide akrabas\u0131 olmayanlar\u0131n da ya\u015fam oran\u0131yla alakal\u0131 bir farkl\u0131l\u0131k olabilir.\ntrain[\"no_family\"] = (train[\"SibSp\"] + train[\"Parch\"]) <= 0\ntrain[\"no_family\"].astype(\"int64\")\ntrain.has_family.value_counts()","47791310":"#Gemideki ortalama aile bireyi say\u0131s\u0131n\u0131n \u00fczerinde akrabas\u0131 olanlar\u0131 g\u00f6steren bir kolon olu\u015fturdum.\ntrain[\"crowded_family\"] = train[\"family_count\"] > train[\"family_count\"].mean()\ntrain[\"crowded_family\"].astype(\"int64\")\ntrain.crowded_family.value_counts()","d965f34c":"#Yolcular\u0131n s\u0131n\u0131f\u0131 ve ya\u015flar\u0131 aras\u0131nda negatif bir korelasyon var, yani gen\u00e7 yolcular genelde\n#daha alt s\u0131n\u0131flardan bilet alm\u0131\u015flar. Buna kar\u015f\u0131n, gen\u00e7 yolcular\u0131n gemiden \u00f6ncelikli bi\u00e7imde\n#tahliye edildi\u011fi verisine de sahibiz. Bu \u00e7eli\u015fen iki girdiyi tek bir kolonda toplad\u0131m.\ntrain[\"age_and_class\"] = (train[\"Age\"] <= train.Age.mean()) | (train[\"Pclass\"] == 1)\ntrain[\"age_and_class\"] = train[\"age_and_class\"].astype(\"int64\")\ntrain.age_and_class.isna().value_counts()","f091fe2d":"#Gemiye bindikleri yere g\u00f6re en \u00e7ok \u00f6l\u00fcm Southampton'dan \u00e7\u0131km\u0131\u015f. Southampton'dan\n#binenleri g\u00f6steren bir kolon olu\u015fturdum.\ntrain[\"embarkloc\"] = (train[\"Embarked\"] == 0)\ntrain[\"embarkloc\"] = train[\"embarkloc\"].astype(\"int64\")\ntrain.embarkloc.isna().value_counts()","2a4a14f7":"#Yolcular\u0131n s\u0131n\u0131f\u0131 ve ya\u015flar\u0131 aras\u0131nda negatif bir korelasyon var, yani gen\u00e7 yolcular genelde\n#daha alt s\u0131n\u0131flardan bilet alm\u0131\u015flar. Buna kar\u015f\u0131n, gen\u00e7 yolcular\u0131n gemiden \u00f6ncelikli bi\u00e7imde\n#tahliye edildi\u011fi verisine de sahibiz. Bu \u00e7eli\u015fen iki girdiyi tek bir kolonda toplad\u0131m.\ntrain[\"high_fare\"] = (train[\"Fare\"] >= train.Fare.mean()) | (train[\"Pclass\"] == 1)\ntrain[\"high_fare\"] = train[\"high_fare\"].astype(\"int64\")\ntrain.high_fare.isna().value_counts()","4da6275a":"#Korelasyon matrisini \u00e7izelim\nsns.set_context(\"talk\")\nax = plt.subplots(figsize=(25, 16))\nsns.heatmap(train.corr(), annot=True)\nplt.title(\"Kolonlar\u0131n korelasyon matrisi\")","d9d16c1b":"#Hayatta kalan ve \u00f6lenlerin say\u0131s\u0131\nsns.set_context(\"talk\")\nsns.set_style(\"darkgrid\")\nplt.figure(figsize=(15, 12))\ng = sns.countplot(\"Survived\", data=train)\nplt.title(\"Hayatta kalanlar\u0131n say\u0131s\u0131\")\nplt.xlabel(\"Hayatta kalma durumu\")\nplt.ylabel(\"Say\u0131\")\ng.set_xticklabels([\"\u00d6lenler\", \"Ya\u015fayanlar\"])\nplt.show()","0ce84b1a":"#Yolcular\u0131n hangi s\u0131n\u0131fta seyahat etti\u011fine g\u00f6re bilete \u00f6dedikleri \u00fccretin da\u011f\u0131l\u0131m\u0131n\u0131 g\u00f6steren kutu grafi\u011fi\nsns.set_context(\"talk\")\nplt.figure(figsize=(20, 15))\ng1 = sns.boxenplot(\"Pclass\", \"Fare\", hue=\"Survived\", data=train)\ng1.set_xticklabels([\"1st Class\", \"2nd Class\", \"3rd Class\"])\nplt.title(\"Yolcu s\u0131n\u0131f\u0131na g\u00f6re bilet \u00fccretlerinin da\u011f\u0131l\u0131m grafi\u011fi\")\nplt.ylabel(\"\u00dccret\")\nplt.xlabel(\"Seyahat s\u0131n\u0131f\u0131\")\nplt.show()","e87441ad":"#Yolcular\u0131n seyahat s\u0131n\u0131f\u0131na g\u00f6re hayatta kalma y\u00fczdeleri\nsns.set_context(\"talk\")\nplt.figure(figsize=(15, 12))\ng = sns.barplot(\"Pclass\", \"Survived\", data=train, ci=None)\ng.set_yticklabels([\"%0\", \"%10\", \"%20\", \"%30\", \"%40\", \"%50\", \"%60\", \"%70\"])\ng.set_xticklabels([\"1.s\u0131n\u0131f\", \"2.s\u0131n\u0131f\", \"3.s\u0131n\u0131f\"])\nplt.title(\"Yolcu s\u0131n\u0131f\u0131na g\u00f6re yolcular\u0131n ortalama hayatta kalma y\u00fczdeleri\")\nplt.xlabel(\"Yolcu s\u0131n\u0131f\u0131\")\nplt.ylabel(\"Hayatta kalma y\u00fczdeleri\")","0640ce18":"#Hayatta kalanlar\u0131n cinsiyete g\u00f6re y\u00fczdesel da\u011f\u0131l\u0131m\u0131\nsns.set_context(\"talk\")\nplt.figure(figsize=(15, 12))\ng = sns.barplot(\"Sex\", \"Survived\", data=train, ci=None)\ng.set_yticklabels([\"%0\", \"%10\", \"%20\", \"%30\", \"%40\", \"%50\", \"%60\", \"%70\", \"%80\"])\ng.set_xticklabels([\"Erkek\", \"Kad\u0131n\"])\nplt.title(\"Cinsiyete g\u00f6re yolcular\u0131n ortalama hayatta kalma y\u00fczdeleri\")\nplt.ylabel(\"Hayatta kalma y\u00fczdeleri\")\nplt.xlabel(\"Cinsiyet\")","5bd2c67a":"#Yolcular\u0131n hayatta kalma durumlar\u0131na g\u00f6re ya\u015flar\u0131n\u0131n da\u011f\u0131l\u0131m\u0131n\u0131 g\u00f6steren kutu grafi\u011fi\nsns.set_context(\"talk\")\nplt.figure(figsize=(15, 10))\na = sns.boxenplot(\"Survived\", \"Age\", data=train)\na.set_xticklabels([\"\u00d6lenler\", \"Ya\u015fayanlar\"])\nplt.title(\"Hayatta kal\u0131p kalmamalar\u0131na g\u00f6re yolcular\u0131n ya\u015f da\u011f\u0131l\u0131mlar\u0131\")\nplt.xlabel(\"Hayatta kalma durumu\")\nplt.ylabel(\"Ya\u015f\")","8106c1f9":"#Hayatta kalan ve \u00f6len yolcular\u0131n gemideki akrabas\u0131 olan ve olmayanlar\u0131n oran\u0131n\u0131 g\u00f6steren kutu grafi\u011fi\nsns.set_context(\"talk\")\nplt.figure(figsize=(15, 10))\na = sns.barplot(\"Survived\", \"has_family\", data=train, ci=None)\na.set_yticklabels([\"%0\", \"%10\", \"%20\", \"%30\", \"%40\", \"%50\", \"%60\"])\na.set_xticklabels([\"\u00d6lenler\", \"Ya\u015fayanlar\"])\nplt.title(\"Hayatta kal\u0131p kalmamalar\u0131na g\u00f6re yolcular\u0131n gemide akrabalar\u0131n\u0131n bulunma oran\u0131\")\nplt.ylabel(\"Aileye sahip olanlar\u0131n oran\u0131\")\nplt.xlabel(\"Hayatta kalma durumu\")","5bf9d04b":"#Yolcular\u0131n seyahat s\u0131n\u0131flar\u0131na ve hayatta kal\u0131p kalmama durumlar\u0131na g\u00f6re ya\u015flar\u0131n\u0131n da\u011f\u0131l\u0131m\u0131n\u0131 g\u00f6steren kutu grafi\u011fi\nsns.set_context(\"talk\")\nplt.figure(figsize=(15, 10))\na = sns.boxenplot(\"Survived\", \"Age\", hue=\"Pclass\", data=train)\na.set_xticklabels([\"\u00d6lenler\", \"Ya\u015fayanlar\"])\nplt.title(\"Hayatta kal\u0131p kalmamalar\u0131na ve seyahat s\u0131n\u0131flar\u0131na g\u00f6re yolcular\u0131n gemideki akraba say\u0131s\u0131\")\nplt.ylabel(\"Ya\u015f\")\nplt.xlabel(\"Hayatta kalma durumu\")","6e840199":"#Yolcular\u0131n seyahat s\u0131n\u0131flar\u0131na ve hayatta kal\u0131p kalmama durumlar\u0131na g\u00f6re ya\u015flar\u0131n\u0131n da\u011f\u0131l\u0131m\u0131n\u0131 g\u00f6steren kutu grafi\u011fi\nsns.set_context(\"talk\")\nax = plt.subplots(figsize=(15, 10))\na = sns.countplot(\"Survived\", hue=\"Embarked\", data=train)\na.set_xticklabels([\"\u00d6lenler\", \"Ya\u015fayanlar\"])\nplt.title(\"Gemiye bindikleri yere g\u00f6re hayatta kalan ki\u015fi say\u0131s\u0131\")\nplt.ylabel(\"Say\u0131\")\nplt.xlabel(\"Hayatta kalma durumu\")\nplt.legend([\"Southampton\", \"Cherbourg\", \"Queenstown\"])\nplt.show()","2ff51d1f":"#Veri setini X ve y \u015feklinde ay\u0131rarak tahmin edilecek de\u011fer olan Survived kolonunu ay\u0131ral\u0131m\nX = train[[\"Fare\", \"Pclass\", \"Sex\", \"Age\", \"high_fare\", \"age_and_class\", \"crowded_family\", \"has_family\", \"no_family\", \"title\"]]\ny = np.array(train.Survived)\n\n#Veriyi e\u011fitim ve test setlerine b\u00f6lelim \nX_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42,test_size=0.3)\n\n#Verideki de\u011ferleri farkl\u0131 yakla\u015f\u0131mlarla \u00f6l\u00e7eklendirerek modelin daha do\u011fru tahminler yapmas\u0131n\u0131 ve \n#say\u0131sal de\u011ferlerin a\u011f\u0131rl\u0131klar\u0131n\u0131 yanl\u0131\u015f belirlemesini engelleyebiliriz.\nrob_scaler = RobustScaler()\nrob_x = rob_scaler.fit_transform(X_train)\nrob_xtest = rob_scaler.transform(X_test)\nminmax_scaler = MinMaxScaler()\nminmax_x = minmax_scaler.fit_transform(X_train)\nminmax_xtest = minmax_scaler.transform(X_test)\nstd_scaler = StandardScaler().fit(X_train)\nstandard_x = std_scaler.transform(X_train)\nstandard_xtest = std_scaler.transform(X_test)","3b96ce10":"#k-NN modelini kural\u0131m\nknn = KNeighborsClassifier()\n\n#En iyi k-NN modelini belirlemek i\u00e7in 1'den 30'a kadar n_neighbors parametresine\n#de\u011ferler atayarak en iyi parametreyi bulal\u0131m. Burada standardize etme y\u00f6ntemiyle\n#\u00f6l\u00e7eklendirme yakla\u015f\u0131m\u0131n\u0131 kulland\u0131m.\nparams = {\"n_neighbors\":np.arange(1, 31)}\ngrid_std = GridSearchCV(estimator = knn, param_grid = params, cv=5)\ngrid_std.fit(standard_x, y_train)\nknn_pred_std = grid_std.predict(standard_xtest)\nprint(classification_report(y_test, knn_pred_std))","1a2bc803":"#En iyi k-NN modelini belirlemek i\u00e7in 1'den 30'a kadar n_neighbors parametresine\n#de\u011ferler atayarak en iyi parametreyi bulal\u0131m. Burada MinMax \u00f6l\u00e7eklendirmesi\n#yapmay\u0131 denedim.\nparams = {\"n_neighbors\":np.arange(1, 31)}\ngrid_minmax = GridSearchCV(estimator = knn, param_grid = params, cv=5)\ngrid_minmax.fit(minmax_x, y_train)\nknn_pred_minmax = grid_minmax.predict(minmax_xtest)\nprint(classification_report(y_test, knn_pred_minmax))","ff2b7673":"#En iyi k-NN modelini belirlemek i\u00e7in 1'den 30'a kadar n_neighbors parametresine\n#de\u011ferler atayarak en iyi parametreyi bulal\u0131m. Burada ise robust \u00f6l\u00e7eklendirme\n#yakla\u015f\u0131m\u0131n\u0131 denedim.\nparams = {\"n_neighbors\":np.arange(1, 31)}\ngrid_rob = GridSearchCV(estimator = knn, param_grid = params, cv=5)\ngrid_rob.fit(rob_x, y_train)\nknn_pred_rob = grid_rob.predict(rob_xtest)\nprint(classification_report(y_test, knn_pred_rob))","740b272d":"#k-NN modelinin (standart \u00f6l\u00e7eklendirme) hata matrisini \u00e7izelim.\nax = plt.subplots(figsize=(12, 9))\nsns.heatmap(confusion_matrix(y_test, knn_pred_std), annot=True, xticklabels=[\"\u00d6l\u00fc\", \"Hayatta\"], yticklabels=[\"\u00d6l\u00fc\", \"Hayatta\"], fmt=\"g\")\nplt.ylabel(\"Tahminler\")\nplt.xlabel(\"Ger\u00e7ek de\u011ferler\")\nplt.title(\"k-NN Algoritmas\u0131n\u0131n S\u0131n\u0131fland\u0131rma Performans\u0131 (Standard)\")","6fd28d3e":"#k-NN modelinin (MinMax \u00f6l\u00e7eklendirme) hata matrisini \u00e7izelim.\nax = plt.subplots(figsize=(12, 9))\nsns.heatmap(confusion_matrix(y_test, knn_pred_minmax), annot=True, xticklabels=[\"\u00d6l\u00fc\", \"Hayatta\"], yticklabels=[\"\u00d6l\u00fc\", \"Hayatta\"], fmt=\"g\")\nplt.ylabel(\"Tahminler\")\nplt.xlabel(\"Ger\u00e7ek de\u011ferler\")\nplt.title(\"k-NN Algoritmas\u0131n\u0131n S\u0131n\u0131fland\u0131rma Performans\u0131 (MinMax)\")","4a1a46c0":"#k-NN modelinin (robust \u00f6l\u00e7eklendirme) hata matrisini \u00e7izelim.\nax = plt.subplots(figsize=(12, 9))\nsns.heatmap(confusion_matrix(y_test, knn_pred_rob), annot=True, xticklabels=[\"\u00d6l\u00fc\", \"Hayatta\"], yticklabels=[\"\u00d6l\u00fc\", \"Hayatta\"], fmt=\"g\")\nplt.ylabel(\"Tahminler\")\nplt.xlabel(\"Ger\u00e7ek de\u011ferler\")\nplt.title(\"k-NN Algoritmas\u0131n\u0131n S\u0131n\u0131fland\u0131rma Performans\u0131 (Robust)\")","07bca720":"#S\u0131ras\u0131yla standart, minmax ve robust \u00f6l\u00e7eklendirme metotlar\u0131 uygulanm\u0131\u015f k-NN modellerinin puanland\u0131rmalar\u0131n\u0131 yazd\u0131rd\u0131m.\n\nprint(\"En y\u00fcksek puan (standardize, minmax, robust):\", grid_std.best_score_, grid_minmax.best_score_, grid_rob.best_score_)\nprint(\"En iyi n_neighbors parametresi (standardize, minmax, robust):\",grid_std.best_estimator_.n_neighbors, grid_minmax.best_estimator_.n_neighbors, grid_rob.best_estimator_.n_neighbors)\nprint(\"Ortalama model puan\u0131 (standardize, minmax, robust):\", grid_std.cv_results_[\"mean_test_score\"].mean(), grid_minmax.cv_results_[\"mean_test_score\"].mean(), grid_rob.cv_results_[\"mean_test_score\"].mean())","025b2c01":"#k-NN modeli i\u00e7in yapt\u0131\u011f\u0131m \u015feylerin ayn\u0131s\u0131n\u0131 Lojistik Regresyon ile denedim.\nlogreg = LogisticRegression()\nrfe = RFE(logreg, n_features_to_select=3)\nparams_log = {\"estimator__C\":[0.0001, 0.001, 0.01, 0.1, 1, 1.2, 1.5, 1.8, 2, 2.2, 2.5, 2.7, 2.8, 2.81, 2.82, 2.83, 2.84, 2.85, 2.86, 2.9, 3, 3.1, 3.3, 3.5, 3.8, 10, 100]}\ngrid_log_std = GridSearchCV(estimator=rfe, param_grid = params_log, cv=5)\ngrid_log_std.fit(standard_x, y_train)\nlogreg_pred_std = grid_log_std.predict(standard_xtest)\nprint(classification_report(y_test, logreg_pred_std))","7f2add0b":"grid_log_minmax = GridSearchCV(estimator=rfe, param_grid = params_log, cv=5)\ngrid_log_minmax.fit(minmax_x, y_train)\nlogreg_pred_minmax = grid_log_minmax.predict(minmax_xtest)\nprint(classification_report(y_test, logreg_pred_minmax))","a733e63c":"grid_log_rob = GridSearchCV(estimator=rfe, param_grid = params_log, cv=5)\ngrid_log_rob.fit(rob_x, y_train)\nlogreg_pred_rob = grid_log_rob.predict(rob_xtest)\nprint(classification_report(y_test, logreg_pred_rob))","27b31584":"#Lojistik Regresyon modelinin (standart \u00f6l\u00e7eklendirme) hata matrisi\nax = plt.subplots(figsize=(12, 9))\nsns.heatmap(confusion_matrix(y_test, logreg_pred_std), annot=True, xticklabels=[\"\u00d6l\u00fc\", \"Hayatta\"], yticklabels=[\"\u00d6l\u00fc\", \"Hayatta\"], fmt=\"g\")\nplt.ylabel(\"Tahminler\")\nplt.xlabel(\"Ger\u00e7ek de\u011ferler\")\nplt.title(\"Lojistik Regresyon Algoritmas\u0131n\u0131n S\u0131n\u0131fland\u0131rma Performans\u0131 (Standard)\")","9202f5c0":"#Lojistik Regresyon modelinin (minmax \u00f6l\u00e7eklendirme) hata matrisi\nax = plt.subplots(figsize=(12, 9))\nsns.heatmap(confusion_matrix(y_test, logreg_pred_minmax), annot=True, xticklabels=[\"\u00d6l\u00fc\", \"Hayatta\"], yticklabels=[\"\u00d6l\u00fc\", \"Hayatta\"], fmt=\"g\")\nplt.ylabel(\"Tahminler\")\nplt.xlabel(\"Ger\u00e7ek de\u011ferler\")\nplt.title(\"Lojistik Regresyon Algoritmas\u0131n\u0131n S\u0131n\u0131fland\u0131rma Performans\u0131 (MinMax)\")","b930fb04":"#Lojistik Regresyon modelinin (robust \u00f6l\u00e7eklendirme) hata matrisi\nax = plt.subplots(figsize=(12, 9))\nsns.heatmap(confusion_matrix(y_test, logreg_pred_rob), annot=True, xticklabels=[\"\u00d6l\u00fc\", \"Hayatta\"], yticklabels=[\"\u00d6l\u00fc\", \"Hayatta\"], fmt=\"g\")\nplt.ylabel(\"Tahminler\")\nplt.xlabel(\"Ger\u00e7ek de\u011ferler\")\nplt.title(\"Lojistik Regresyon Algoritmas\u0131n\u0131n S\u0131n\u0131fland\u0131rma Performans\u0131 (Robust)\")","d11a4ddb":"#Lojistik Regresyon modeli i\u00e7in s\u0131ras\u0131yla farkl\u0131 \u00f6l\u00e7eklendirme metotlar\u0131n\u0131n uygulanmas\u0131 sonucu elde edilen puanlar\u0131 yazd\u0131rd\u0131m.\n\nprint(\"En y\u00fcksek puan (standardize, minmax, robust):\", grid_log_std.best_score_, grid_log_minmax.best_score_, grid_log_rob.best_score_)\nprint(\"En iyi C parametresi (standardize, minmax, robust):\",grid_log_std.best_estimator_.estimator_, grid_log_minmax.best_estimator_.estimator_, grid_log_rob.best_estimator_.estimator_)\nprint(\"Ortalama model puan\u0131 (standardize, minmax, robust):\", grid_log_std.cv_results_[\"mean_test_score\"].mean(), grid_log_minmax.cv_results_[\"mean_test_score\"].mean(), grid_log_rob.cv_results_[\"mean_test_score\"].mean())","41152366":"#Modellerin performans\u0131n\u0131 daha iyi k\u0131yaslayabilmek i\u00e7in ROC e\u011frisi \u00e7izdim. Bu noktadan sonra yap\u0131lan b\u00fct\u00fcn model kullan\u0131mlar\u0131nda\n#k-NN modeli i\u00e7in standart \u00f6l\u00e7eklendirilmi\u015f veriyi, Lojistik Regresyon modeli i\u00e7in ise robust metotla \u00f6l\u00e7eklendirilmi\u015f veriyi\n#girdi olarak tercih ettim.\nknn_prob = grid_std.predict_proba(standard_xtest)[:, 1]\nlogreg_prob = grid_log_rob.predict_proba(standard_xtest)[:, 1]\nfprlog, tprlog, thresholdslog = roc_curve(y_test, logreg_prob)\nfpr, tpr, thresholds = roc_curve(y_test, knn_prob)\nsns.set_style(\"darkgrid\")\nsns.set_context(\"poster\")\nax = plt.subplots(figsize=(15, 10))\nplt.plot([0, 1], [0, 1], 'k--')\nsns.lineplot(fpr, tpr, alpha=0.3, ci=None)\nsns.lineplot(fprlog, tprlog, alpha=0.3, ci=None)\nplt.xlabel('Yalanc\u0131 pozitif oran\u0131')\nplt.ylabel('Ger\u00e7ek pozitif oran\u0131')\nplt.title('ROC e\u011frisi')\nplt.legend([\"Baz \u00c7izgisi\", \"k-NN\", \"Lojistik Regresyon\"])\nplt.show()","670d09d5":"#Yukar\u0131da algoritmalar\u0131 kurarken yap\u0131lanlar\u0131 etiketlenmemi\u015f test.csv dosyas\u0131 i\u00e7in tek ad\u0131mda yapal\u0131m \ntest.dropna(subset=[\"Embarked\"], inplace=True)\ntest.drop(\"Cabin\", axis=1, inplace=True)\nmean_age_test = test.Age.mean()\ntest.fillna(value=mean_age_test, inplace=True)\ntest.replace({\"male\":0, \"female\":1}, inplace = True)\ntest.replace({\"S\":0, \"C\":1, \"Q\":2}, inplace = True)\ntest.drop([\"Ticket\"], axis=1, inplace=True)","49879b9a":"titles_test = set()\nfor name in test[\"Name\"]:\n    titles_test.add(name.split(\",\")[1].split(\".\")[0].strip())\n\ntitle_dict_test = {'Capt':\"Officer\",\n 'Col':\"Officer\",\n 'Don':\"Royal\",\n 'Dona':\"Royal\",\n 'Dr':\"Officer\",\n 'Jonkheer':\"Royal\",\n 'Lady':\"Royal\",\n 'Major':\"Officer\",\n 'Master':\"Royal\",\n 'Miss':\"Mrs\",\n 'Mlle':\"Mrs\",\n 'Mme':\"Mrs\",\n 'Mr':\"Mr\",\n 'Mrs':\"Mrs\",\n 'Ms':\"Mrs\",\n 'Rev':\"Officer\",\n 'Sir':\"Royal\",\n 'the Countess':\"Royal\"}\n    \ntest[\"title\"] = test[\"Name\"].map(lambda name: name.split(\",\")[1].split(\".\")[0].strip())\ntest[\"title\"] = test[\"title\"].map(title_dict_test)\ntest.replace({\"Mr\":1, \"Mrs\":2, \"Royal\":3, \"Officer\":4}, inplace=True)\ntest.title.isna().value_counts()","638614c4":"#Burada ve a\u015fa\u011f\u0131daki t\u00fcm h\u00fccrelerde dikkat \u00e7ekmek istedi\u011fim bir nokta var. Mant\u0131k operat\u00f6rleri\n#kullanarak yapt\u0131\u011f\u0131m t\u00fcm filtrelemelerde, \u00f6rne\u011fin ya\u015f gibi say\u0131sal bir kolonun ortalamas\u0131n\u0131\n#kullan\u0131rken sadece e\u011fitim ya da test veri setini de\u011fil, bunlar\u0131n ikisinin birle\u015fiminden olu\u015fan\n#yakla\u015f\u0131k 1200 sat\u0131rl\u0131k \"complete\" ad\u0131 verdi\u011fim tam bir veri seti kulland\u0131m. B\u00f6ylece modelin\n#daha iyi genelleme yapabilece\u011fini d\u00fc\u015f\u00fcnd\u00fcm.\n\ntest[\"young_female\"] = (test[\"Age\"] <= complete.Age.mean()) & (test[\"Sex\"] == 1)\ntest[\"young_female\"] = test[\"young_female\"].astype(\"int64\")\ntest.young_female.isna().value_counts()","3fd6cf1f":"test[\"young_or_female\"] = (test[\"Age\"] <= complete.Age.mean()) | (test[\"Sex\"] == 1)\ntest[\"young_or_female\"] = test[\"young_or_female\"].astype(\"int64\")\ntest.young_or_female.isna().value_counts()","e96c60d9":"test[\"family_count\"] = test[\"SibSp\"] + test[\"Parch\"]\ntest[\"family_count\"].astype(\"int64\")\ntest.family_count.isna().value_counts()","3b96880b":"test[\"has_family\"] = (test[\"SibSp\"] + test[\"Parch\"]) > 0\ntest[\"has_family\"].astype(\"int64\")\ntest.has_family.isna().value_counts()","ca205313":"#Gemide akrabas\u0131 olanlar\u0131n ya\u015fam oran\u0131yla alakal\u0131 bir farkl\u0131l\u0131k olabilir.\ntest[\"no_family\"] = (test[\"SibSp\"] + test[\"Parch\"]) <= 0\ntest[\"no_family\"].astype(\"int64\")\ntest.has_family.isna().value_counts()","cdc0fc34":"test[\"crowded_family\"] = test[\"SibSp\"] > complete.SibSp.mean()\ntest[\"crowded_family\"] = test[\"crowded_family\"].astype(\"int64\")\ntest[\"crowded_family\"].astype(\"int64\")\ntest.crowded_family.isna().value_counts()","0016a72a":"test[\"age_and_class\"] = (test[\"Age\"] <= complete.Age.mean()) | (test[\"Pclass\"] == 1)\ntest[\"age_and_class\"] = test[\"age_and_class\"].astype(\"int64\")\ntest[\"age_and_class\"].isna().value_counts()","4059b9d8":"test[\"embarkloc\"] = test[\"Embarked\"] == 0\ntest[\"embarkloc\"] = test[\"embarkloc\"].astype(\"int64\")\ntest.embarkloc.isna().value_counts()","101eb020":"test[\"crowded_family\"] = test[\"family_count\"] > test[\"family_count\"].mean()\ntest[\"crowded_family\"].astype(\"int64\")\ntest.crowded_family.isna().value_counts()","005ee42b":"X_test = test[[\"Fare\", \"Pclass\", \"Sex\", \"Age\", \"has_family\", \"no_family\", \"crowded_family\", \"title\", \"young_or_female\", \"young_female\", \"age_and_class\", \"embarkloc\"]]\n\nX = train[[\"Fare\", \"Pclass\", \"Sex\", \"Age\", \"has_family\", \"no_family\", \"crowded_family\", \"title\", \"young_or_female\", \"young_female\", \"age_and_class\", \"embarkloc\"]]\ny = np.array(train.Survived)\n\n#k-NN i\u00e7in test verisinin standart \u00f6l\u00e7eklendirmesi\nscaler = StandardScaler().fit(X)\nscaler_test = StandardScaler().fit(X_test)\nstandard_x = scaler.transform(X)\nstandard_test = scaler_test.transform(X_test)\n\n#Lojistik Regresyon i\u00e7in test verisinin robust \u00f6l\u00e7eklendirmesi\nrobust = RobustScaler().fit(X)\nrobust_test = RobustScaler().fit(X_test)\nrob_x = robust.transform(X)\nrob_test = robust_test.transform(X_test)\n\n#Model metriklerini se\u00e7erken yukar\u0131daki e\u011fitim veri setinin de\u011ferlendirmesinde bana en iyi sonu\u00e7lar\u0131 veren\n#parametreleri kulland\u0131m.\nknn = KNeighborsClassifier(n_neighbors=1)\nlogreg = LogisticRegression(C=0.1)\n\n#Robust \u00f6l\u00e7eklendirme uygulanm\u0131\u015f test veri setine Lojistik Regresyon modeli uygulanmas\u0131\nlogreg.fit(rob_x, y)\nlogreg_pred = logreg.predict(rob_test)\ntest[\"Survived\"] = logreg_pred\ntest_logreg = test[[\"PassengerId\", \"Survived\"]].astype(\"int64\")\ntest_logreg.to_csv(\"titanic_logreg.csv\", index=False)\n\n#Standart \u00f6l\u00e7eklendirme uygulanm\u0131\u015f test veri setine k-NN modeli uygulanmas\u0131\nknn.fit(standard_x, y)\nknn_pred = knn.predict(standard_test)\ntest[\"Survived\"] = knn_pred\ntest_knn = test[[\"PassengerId\", \"Survived\"]].astype(\"int64\")\ntest_knn.to_csv(\"titanic_knn.csv\", index=False)","b7aad410":"# Feature engineering","99bbd1ab":"# Algoritman\u0131n kurulmas\u0131","6b3ce9f9":"# Veri g\u00f6rselle\u015ftirme","5310a37d":"## Test verisi \u00fczerinde \u00e7al\u0131\u015fma","0f45d320":"# Veri temizli\u011fi"}}