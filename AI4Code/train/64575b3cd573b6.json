{"cell_type":{"2fb011de":"code","c4b81b87":"code","6a40c100":"code","db52f7a3":"code","a6a99fc6":"code","de784baf":"code","4485f5ac":"code","10e1f69e":"code","6ce51285":"code","c06de39d":"code","eeb2d330":"code","3ec29507":"code","6e6d2fed":"code","8fbdd3cc":"code","edaf4662":"code","7eef042f":"code","e955ebdd":"code","5ac9d86c":"code","fdda6353":"markdown","64243004":"markdown","2d1bf697":"markdown"},"source":{"2fb011de":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(\"Setup finished\")\n\n# Any results you write to the current directory are saved as output.","c4b81b87":"import os\nimport random\nimport numpy as np\nfrom lxml import etree\nfrom skimage import io\nfrom skimage.transform import resize\n\n# parameters that you should set before running this script\nfilter = ['aeroplane', 'boat', 'bus', 'motorbike']\n# select class, this default should yield 1489 training and 1470 validation images\naux_folder= os.path.join(\"..\/input\", os.listdir(\"..\/input\")[0])\nvoc_root_folder=os.path.join(aux_folder, os.listdir(aux_folder)[0])\n\nimage_size = 128    # image size that you will use for your network (input images will be resampled to this size), lower if you have troubles on your laptop (hint: use io.imshow to inspect the quality of the resampled images before feeding it into your network!)\n\n\n# step1 - build list of filtered filenames\nannotation_folder = os.path.join(voc_root_folder, \"VOC2009\/Annotations\/\")\nannotation_files = os.listdir(annotation_folder)\nfiltered_filenames = []\n\n# for a_f in annotation_files[:1500]:\nfor a_f in annotation_files:\n    tree = etree.parse(os.path.join(annotation_folder, a_f))\n    if np.any([tag.text == filt for tag in tree.iterfind(\".\/\/name\") for filt in filter]):\n        filtered_filenames.append(a_f)\nprint(\"Finished filtered images\")\n\n\n\n","6a40c100":"# step3 - build segmentation dataset\nannotation_folder = os.path.join(voc_root_folder, \"VOC2009\/Annotations\/\")\n\nfiltered_segmentation=[]\n\nfor a_f in filtered_filenames:\n    tree = etree.parse(os.path.join(annotation_folder, a_f))\n    for tag in tree.iterfind(\".\/\/segmented\"):\n        if tag.text==\"1\" :\n            filtered_segmentation.append(a_f[:-4])\nprint(\"Finished filtered images\")\n","db52f7a3":"import cv2\n# step3 - build (x,y) for TRAIN\/VAL (segmentation)\nsegmentation_folder = os.path.join(voc_root_folder, \"VOC2009\/ImageSets\/Segmentation\/\")\nsegmentation_files = os.listdir(segmentation_folder)\n\nsegmentation_train=os.path.join(segmentation_folder,'train.txt')\nsegmentation_val=os.path.join(segmentation_folder,'val.txt')\n\n\n\n\ndef build_segmentation_dataset(seg_file,filtered_segmentation):\n    \"\"\" build training or validation set\n\n    :param list_of_files: list of filenames to build trainset with\n    :return: tuple with x np.ndarray of shape (n_images, image_size, image_size, 1) and  y np.ndarray of shape \n    (n_images, image_size, image_size, 1) with segmented masks\n    \"\"\"\n\n    with open(seg_file) as file:\n        lines = file.read().splitlines()\n      \n    train_filter = [item for item in lines if (item in filtered_segmentation)]\n\n#     \"Real Images\"\n    image_folder = os.path.join(voc_root_folder, \"VOC2009\/JPEGImages\/\")\n    image_filenames = [os.path.join(image_folder, file) for f in train_filter for file in os.listdir(image_folder) if f in file]\n    \n#     Segmented Images\n    seg_folder = os.path.join(voc_root_folder, \"VOC2009\/SegmentationClass\/\")\n    seg_filenames = [os.path.join(seg_folder, file) for f in train_filter for file in os.listdir(seg_folder) if f in file]\n    \n    x = np.array([resize(io.imread(img_f), (image_size, image_size, 3)) for img_f in image_filenames]).astype('float32')\n#     x=[cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in aux_x]\n    \n    aux_y = np.array([resize(io.imread(img_f), (image_size, image_size, 3)) for img_f in seg_filenames]).astype('float32')           \n    aux_y_gray = np.array([cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in aux_y])\n\n    mask_val = [0.294, 0.418, 0.572, 0.596]\n    masks = []\n    for elm in aux_y_gray:\n        mask = np.zeros((128,128))\n        for mask_val_int in mask_val:\n            mask[np.array(elm>(mask_val_int-0.005)) * np.array(elm<(mask_val_int+0.005))] = 1\n        masks.append(mask.reshape(image_size, image_size, 1))\n        \n    masks = np.array(masks)\n    return x, masks","a6a99fc6":"# Unet Network\nimport os\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use(\"ggplot\")\n%matplotlib inline\n\n# from tqdm import tqdm_notebook, tnrange\nfrom itertools import chain\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\nfrom keras.layers.core import Lambda, RepeatVector, Reshape\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\nfrom keras.layers.merge import concatenate, add\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n\ndef conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):\n    # first layer\n    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n               padding=\"same\")(input_tensor)\n    if batchnorm:\n        x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    # second layer\n    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n               padding=\"same\")(x)\n    if batchnorm:\n        x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    return x\ndef get_unet(input_img, n_filters=16, dropout=0.5, batchnorm=True):\n    # contracting path\n    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n    p1 = MaxPooling2D((2, 2)) (c1)\n    p1 = Dropout(dropout*0.5)(p1)\n\n    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n    p2 = MaxPooling2D((2, 2)) (c2)\n    p2 = Dropout(dropout)(p2)\n\n    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n    p3 = MaxPooling2D((2, 2)) (c3)\n    p3 = Dropout(dropout)(p3)\n\n    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n    p4 = Dropout(dropout)(p4)\n    \n    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\n    \n    # expansive path\n    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)\n    u6 = concatenate([u6, c4])\n    u6 = Dropout(dropout)(u6)\n    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n\n    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)\n    u7 = concatenate([u7, c3])\n    u7 = Dropout(dropout)(u7)\n    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n\n    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)\n    u8 = concatenate([u8, c2])\n    u8 = Dropout(dropout)(u8)\n    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n\n    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)\n    u9 = concatenate([u9, c1], axis=3)\n    u9 = Dropout(dropout)(u9)\n    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n    \n    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n    model = Model(inputs=[input_img], outputs=[outputs])\n    return model","de784baf":"import keras.backend as K\n# def dice_coef(y_true, y_pred):\n#     y_true_f = K.flatten(y_true)\n#     y_pred_f = K.flatten(y_pred)\n#     intersection = K.sum(y_true_f * y_pred_f)\n#     return (2. * intersection + K.epsilon()) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())\n\ndef dice_coef(y_true, y_pred, smooth=1):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    return (2. * intersection + smooth) \/ (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\ndef dice_coef_loss(y_true, y_pred):\n    return 1-dice_coef(y_true, y_pred)","4485f5ac":"# Dice metric \nim_height=image_size\nim_width=image_size\n\ninput_img = Input((im_height, im_width, 3), name='img')\nmodel = get_unet(input_img, n_filters=32, dropout=0.05, batchnorm=True)\n\nmodel.summary()","10e1f69e":"x_train_seg, y_train_seg = build_segmentation_dataset(segmentation_train,filtered_segmentation)\nx_test_seg, y_test_seg = build_segmentation_dataset(segmentation_val,filtered_segmentation)\nprint(\"Finished\")\n\nx_train_seg_bak, y_train_seg_bak = x_train_seg, y_train_seg\nx_test_seg_bak, y_test_seg_bak = x_test_seg, y_test_seg ","6ce51285":"# #PreProcess\nfrom keras.utils import np_utils\nx_train_seg, y_train_seg = x_train_seg_bak, y_train_seg_bak\nx_test_seg, y_test_seg = x_test_seg_bak, y_test_seg_bak\n\n#z-score\nmean = np.mean(x_train_seg,axis=(0,1,2,3))\nstd = np.std(x_train_seg,axis=(0,1,2,3))\nx_train_seg = (x_train_seg-mean)\/(std+1e-7)\nx_test_seg = (x_test_seg-mean)\/(std+1e-7)\n\n#Data augmentation\n# datagen = ImageDataGenerator(\n#     rotation_range=15,\n#     width_shift_range=0.1,\n#     height_shift_range=0.1,\n#     horizontal_flip=True,\n#     )\n\ndatagen = ImageDataGenerator()\ndatagen.fit(x_train_seg)","c06de39d":"from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\nimport keras\n\ndef lr_schedule(epoch):\n    lrate = 0.001\n    if epoch > 75:\n        lrate = 0.0005\n    if epoch > 100:\n        lrate = 0.0003\n    return lrate\n\n# Prepare callbacks for model saving and for learning rate adjustment.\n# checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_acc', verbose=1, save_best_only=True)\nlr_scheduler = LearningRateScheduler(lr_schedule)\nlr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\nes_callback = EarlyStopping(patience=15, verbose=1),\ncp_callback = ModelCheckpoint('model_dice.h5', verbose=1, save_best_only=True, save_weights_only=True)\n\nopt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\ncallbacks = [cp_callback,lr_reducer, lr_scheduler]\n\nmodel.compile(optimizer=opt_rms, loss=\"mse\", metrics=[dice_coef_loss,'mse','binary_crossentropy',\"accuracy\"])\n\n# callbacks = [\n#     EarlyStopping(patience=15, verbose=1),\n#     ReduceLROnPlateau(factor=0.1, patience=3, min_lr=0.00001, verbose=1)\n#     #ModelCheckpoint('model_seg_dice.h5', verbose=1, save_best_only=True, save_weights_only=True)\n# ]","eeb2d330":"batch_size = 32\nn_epochs = 30\nn_steps = 30 #15*x_train_seg.shape[0] \/\/ batch_size\n\nresults = model.fit_generator(datagen.flow(x_train_seg, y_train_seg, batch_size=batch_size), epochs=n_epochs, steps_per_epoch=n_steps, shuffle=True, validation_data=datagen.flow(x_test_seg, y_test_seg, batch_size=batch_size), validation_steps=10,  verbose=1,callbacks=callbacks)","3ec29507":"model.load_weights('model_dice.h5')","6e6d2fed":"plt.figure(figsize=(8, 8))\nplt.title(\"Learning curve\")\nplt.plot(results.history[\"acc\"], label=\"acc\")\nplt.plot(results.history[\"val_acc\"], label=\"val_acc\")\nplt.plot(np.argmax(results.history[\"val_acc\"]), np.max(results.history[\"val_acc\"]), marker=\"x\", color=\"r\", label=\"best model\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Acc\")\nplt.legend();","8fbdd3cc":"# Predict on train, val and test\npreds_train = model.predict(x_train_seg, verbose=1)\npreds_val = model.predict(x_test_seg, verbose=1)\n\n\n# Threshold predictions\npreds_train_t = (preds_train > 0.05).astype(np.uint8)\npreds_val_t = (preds_val > 0.05).astype(np.uint8)\n\n\nscores_train = model.evaluate(x_train_seg, y_train_seg, verbose=0)\nscores_val = model.evaluate(x_test_seg, y_test_seg, verbose=0)\nprint(scores_train,scores_val)\n","edaf4662":"import numpy as np\nimport matplotlib.pyplot as plt\ndef plot_Results_seg(img11,img12,img13):\n    plt.figure(figsize=(15,20))\n    plt.subplot(1, 3, 1)\n    plt.imshow(img11)\n    plt.title('Orig')\n    plt.axis('off')\n    \n    plt.subplot(1, 3, 2)\n    plt.imshow(img12,cmap=\"gray\")\n    plt.title(\"Orig Segmentation\")\n    plt.axis('off')\n    \n    plt.subplot(1, 3, 3)\n    plt.imshow(img13,cmap=\"gray\")\n    plt.title(\"Predicted Segmentation\")\n    plt.axis('off')\n    plt.show()\n\nx_to_test = x_test_seg_bak\ny_to_test = y_test_seg_bak\nmask_pred = preds_val_t\n\n# fijamos random para comparar dice con mse\n# idx_rnd=[]\n# for el in range(5):\n#     idx_rnd.append(np.random.randint(len(x_test_seg)))\nidx_rnd=[105, 46, 43, 51, 86]\nfor i in range(5):\n    img11=x_to_test[idx_rnd[i]]\n    img12=y_to_test[idx_rnd[i]]\n    img12 = img12.reshape(image_size, image_size) \n    img13 = mask_pred[idx_rnd[i]]\n    img13 = img13.reshape(image_size, image_size) \n    plot_Results_seg(img11,img12,img13)\n\n","7eef042f":"# idx_rnd=[]\n# for el in range(10):\n#     idx_rnd.append(np.random.randint(len(x_test_seg)))\nprint(idx_rnd)","e955ebdd":"x_train_seg,org_mask,b_mask= build_segmentation_dataset(segmentation_train,filtered_segmentation)\n","5ac9d86c":"import numpy as np\nimport matplotlib.pyplot as plt\ndef plot_Results_seg(img11,img12,img13):\n    plt.figure(figsize=(15,20))\n    plt.subplot(1, 3, 1)\n    plt.imshow(img11)\n    plt.title('Orig')\n    plt.axis('off')\n    \n    plt.subplot(1, 3, 2)\n    plt.imshow(img12)\n    plt.title(\"Orig Mask\")\n    plt.axis('off')\n    \n    plt.subplot(1, 3, 3)\n    plt.imshow(img13,cmap=\"gray\")\n    plt.title(\"Binary Mask\")\n    plt.axis('off')\n    plt.show()\n\nidx = np.random.randint(len(x_test_seg))\norg=x_train_seg[idx]\nmask=org_mask[idx]\nbinary_mask=b_mask[idx]\nbinary_mask= binary_mask.reshape(image_size, image_size) \n\nplot_Results_seg(org,mask,binary_mask)\n","fdda6353":"**Plotting Mask transformation**","64243004":"**Plotting**","2d1bf697":"**Plotting Performance Results**"}}