{"cell_type":{"8600c0db":"code","4d4b6f12":"code","7617f093":"code","8ab21023":"code","31038401":"code","b775b8b5":"code","1fb72b68":"code","39911490":"code","6729bee7":"code","1d382920":"code","2f7a4ead":"code","cb4fbc5c":"code","a6d5be25":"code","eb856f9d":"code","8592e50f":"code","634efe9a":"code","ff330074":"code","1222bcd6":"code","28d60076":"code","7cd742f7":"code","f18bd109":"code","b898e1a3":"code","58bacf5f":"code","41c9cd8f":"code","0fb312c3":"code","136e0093":"code","f22eb3cb":"code","51ffd956":"code","9ec02106":"code","8704d2d0":"code","d1b3a881":"code","42ff3fa6":"code","4dd0feb1":"code","2dd326d4":"code","8df95b97":"code","fd46c350":"code","2635d5b3":"code","0d9126fa":"markdown","cf5550e3":"markdown","1a0d2f8f":"markdown","ef9dc51c":"markdown","0367b2a8":"markdown","1f4ac152":"markdown","d8e32c76":"markdown","1b988189":"markdown"},"source":{"8600c0db":"# Importing Packages\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\nsns.set() # By default seaborn theme, scaling, and color palette\n\nimport os\nos.getcwd()","4d4b6f12":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","7617f093":"# Import dataset\n\na = pd.read_csv('\/kaggle\/input\/automobile-price\/AutoData.csv')\ndf = pd.DataFrame(a)\n\n# Understanding the data\ndf.head()","8ab21023":"# Checking data_types\ndf.dtypes","31038401":"# Checking shape : Total number of rows and columns\ndf.shape","b775b8b5":"# Checking Unique values \ndf.nunique()","1fb72b68":"# Describe the data\ndf.describe()","39911490":"# Correlation Matrix\nplt.figure(figsize=(14,7))\ncorr = df.corr()\nsns.heatmap(corr,annot=True)\nplt.show()","6729bee7":"# Bar Graph\nplt.title('Top Car Manufacturers')\nplt.xlabel('Brands')\nplt.ylabel('Number of Vehicles')\ndf['make'].value_counts().nlargest(10).plot(kind='bar',color='grey')\nplt.show()","1d382920":"# Pie Graph\nplt.title('Fuel Type Graph')\ndf['fueltype'].value_counts().plot.pie(figsize=(6,6),autopct='%.2f%%')\nplt.show()","2f7a4ead":"# Area Graph\nplt.title('Drive Wheels Graph')\nplt.xlabel('Drive Wheels')\nplt.ylabel('Number of Vehicles')\ndf['drivewheel'].value_counts().plot(kind='area',color='pink')\nplt.show()","cb4fbc5c":"# Histogram\nplt.title('Vehicle Risk Rating')\nplt.xlabel('Risk Rating')\nplt.ylabel('Number of Vehicles')\ndf['symboling'].plot(kind='hist',color='orange',bins=6)\nplt.show()","a6d5be25":"# Line Graph\nplt.title('Fuel System Graph')\nplt.xlabel('Fuel System')\nplt.ylabel('Number of Vehicles')\ndf['fuelsystem'].value_counts().plot(kind='line',color='black')\nplt.show()","eb856f9d":"# Horizontal Bar Graph\nplt.title('Engine Type Graph')\nplt.ylabel('Engine Type')\nplt.xlabel('Number of Vehicles')\ndf['enginetype'].value_counts().plot(kind='barh',color='violet')\nplt.show()\n","8592e50f":"# Detecting outliers | Boxplot\nplt.title('Price Variation by Car Type')\nplt.xlabel('Car Type')\nplt.ylabel('Price')\nsns.boxplot(df['carbody'],df['price'])\nplt.show()","634efe9a":"# Scatter plot\nplt.title('Price Variation by Horsepower')\nplt.xlabel('Risk Rating')\nplt.ylabel('Price')\nsns.scatterplot(df['horsepower'],df['price'])\nplt.show()","ff330074":"# Checking duplicates\ndf[df.duplicated()]","1222bcd6":"# Checking missing values\ndf.isnull().sum()","28d60076":"# Identifying Categorical & Numerical Cols\ncols = df.columns\nnum_cols = df._get_numeric_data().columns.to_list()\ncat_cols = list(set(cols)-set(num_cols))\n\nprint('Numerical Columns')\nprint(num_cols)\nprint('\\nCategorical Columns')\nprint(cat_cols)","7cd742f7":"# Since 'enginetype', 'carbody', 'enginelocation', 'drivewheel', 'make', 'fueltype', 'doornumber', 'aspiration', 'fuelsystem', 'cylindernumber' is Categorical, coverting it to Numerical form\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\nfor i in df[cat_cols]:\n    df[i] = le.fit_transform(df[i])\n    \ndf.head()","f18bd109":"# Describing Numerical data after Label Encoding\ndf.describe()","b898e1a3":"# One-Hot Encoding\ndf1 = pd.get_dummies(df['symboling'],drop_first=True,prefix='symboling')\ndf2 = pd.get_dummies(df['fueltype'],drop_first=True,prefix='fueltype')\ndf3 = pd.get_dummies(df['aspiration'],drop_first=True,prefix='aspiration')\ndf4 = pd.get_dummies(df['doornumber'],drop_first=True,prefix='doornumber')\ndf5 = pd.get_dummies(df['carbody'],drop_first=True,prefix='carbody')\ndf6 = pd.get_dummies(df['drivewheel'],drop_first=True,prefix='drivewheel')\ndf7 = pd.get_dummies(df['enginelocation'],drop_first=True,prefix='enginelocation')\ndf8 = pd.get_dummies(df['enginetype'],drop_first=True,prefix='enginetype')\ndf9 = pd.get_dummies(df['cylindernumber'],drop_first=True,prefix='cylindernumber')\ndf10 = pd.get_dummies(df['fuelsystem'],drop_first=True,prefix='fuelsystem')\n\n\ndfd = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9,df10],axis=1)\ndfd.head()","58bacf5f":"# Actual Dummies\ndf.drop(['symboling','fueltype','aspiration','doornumber','carbody','drivewheel','enginelocation','enginetype','cylindernumber','fuelsystem'],axis=1,inplace=True)\ndf_dummy = pd.concat([df,dfd],axis=1)\ndf_dummy.head()","41c9cd8f":"# Load from Scikit Learn\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error,r2_score\n\n# train-test split\nX = df['horsepower']\ny = df['price']\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.3,random_state=5)\n\nprint(X.head())\nprint(y.head())","0fb312c3":"# Checking data split\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","136e0093":"# As data is in 1D array, need to convert to 2D array for linear regression\nX_train = X_train.values.reshape(-1,1)\nX_test = X_test.values.reshape(-1,1)","f22eb3cb":"# Scaling\n# Since Price & Horse Power have large gaps in terms of value, Applying Standard Scaling Scaling to make both of them comparable\nfrom sklearn.preprocessing import StandardScaler\nss = StandardScaler()\n\nX_train = ss.fit_transform(X_train)\nX_test = ss.fit_transform(X_test)","51ffd956":"# Linear regression fit\nlr = LinearRegression()\nlr.fit(X_train,y_train)\n\nprint('Intercept is',lr.intercept_) \nprint('Coefficient is',lr.coef_) ","9ec02106":"# Predictions\n# Blue scatter -> actual-training data\n# Orange scatter -> predicted data\n\n# Training\ny_train_pred = lr.predict(X_train)\nplt.title('Training')\nplt.scatter(X_train,y_train)\nplt.scatter(X_train,y_train_pred)\nplt.show()\n\n# Testing\ny_test_pred = lr.predict(X_test)\nplt.title('Testing')\nplt.scatter(X_test,y_test)\nplt.scatter(X_test,y_test_pred)\nplt.show()","8704d2d0":"# Let's check how much good fit it is by calculating R-Squared\n\nprint('Mean Squared Error for training data is',mean_squared_error(y_train,y_train_pred))\nprint('R2 Score for training data in LR is',r2_score(y_train,y_train_pred))\nprint('\\n')\n\nprint('Mean Squared Error for testing data is',mean_squared_error(y_test,y_test_pred))\nprint('R2 Score for testing data in LR is',r2_score(y_test,y_test_pred))\n","d1b3a881":"# Load from Scikit Learn\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error,r2_score\n\n# Since 'symboling',enginetype', 'carbody', 'enginelocation', 'drivewheel', 'fueltype', 'doornumber', 'aspiration', 'fuelsystem', 'cylindernumber' column is categorical so firstly need to handle it\ndf.nunique()","42ff3fa6":"# train-test split\nX = df_dummy.drop(['price'],axis=1)\ny = df_dummy['price']\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.3,random_state=1)\n\nprint(X.head())\nprint(y.head())","4dd0feb1":"# Checking data split\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)\n","2dd326d4":"# Scaling\n\n# Applying Standard Scaling to make both of them comparable\nfrom sklearn.preprocessing import StandardScaler\nmm = StandardScaler()\n\nX_train = mm.fit_transform(X_train)\nX_test = mm.fit_transform(X_test)","8df95b97":"# Multiple regression fit\nmlr = LinearRegression()\nmlr.fit(X_train,y_train)\n\nprint('Intercept is',mlr.intercept_) \nprint('Coefficient is',mlr.coef_) ","fd46c350":"# Predictions\n\n# Training\ny_train_pred = mlr.predict(X_train)\n\n# Testing\ny_test_pred = mlr.predict(X_test)","2635d5b3":"# Let's check how much good fit it is by calculating R-Squared\n\nprint('Mean Squared Error for training data is',mean_squared_error(y_train,y_train_pred))\nprint('R2 Score for training data in MLR is',r2_score(y_train,y_train_pred))\nprint('\\n')\n\nprint('Mean Squared Error for testing data is',mean_squared_error(y_test,y_test_pred))\nprint('R2 Score for testing data in MLR is',r2_score(y_test,y_test_pred))","0d9126fa":"### Perform Data Cleanup on the data","cf5550e3":"Tasks\n    \n- Perform EDA on the data\n- Perform data cleanup as required\n- Pick the best variable for making a simple linear regression model\n- Perform train test split\n- Build model using best variable and report the R2\n- Make a multiple regression model\n- Apply feature selection approaches discussed in the class\n- Final model should be interpretable\n- What is your understanding of the factors that drive price?\n","1a0d2f8f":"### Feature Engineering","ef9dc51c":"### Perform EDA on the data","0367b2a8":"### Linear Regression Model","1f4ac152":"#### Conclusion\n\n\nUsing Multiple Regression gives better results (eg. Like R2 Score in both Training & Testing) than Simple Linear Regression, As it gives more of the information available which estimates the dependent variable. It also enables to fit curves as well as lines.","d8e32c76":"## Predict Automobile Price","1b988189":"### Multiple Linear Regression Model"}}