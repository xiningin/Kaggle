{"cell_type":{"1a918a44":"code","8670fdd8":"code","33bf124b":"code","6b02ef3b":"code","6565d621":"code","d42f2ec2":"code","4138376e":"code","00ae5f32":"code","546f387e":"code","850ab618":"code","0cf7dca3":"code","14c44200":"code","9562088b":"markdown","1d61845b":"markdown","8bb2808c":"markdown","97d5e950":"markdown","ebdfce69":"markdown","848ad772":"markdown","d25d57ca":"markdown","128b556b":"markdown","846b8720":"markdown","39d61c4d":"markdown","0dd65e1f":"markdown","a22a93aa":"markdown"},"source":{"1a918a44":"import numpy as np\nimport pandas as pd\n\nimport gc\n\nfrom IPython.display import clear_output\n!pip install autokeras\nclear_output()\n\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nimport autokeras as ak","8670fdd8":"TRAIN_PATH = \"..\/input\/titanic\/train.csv\"\nTEST_PATH = \"..\/input\/titanic\/test.csv\"\nSAMPLE_SUBMISSION_PATH = \"..\/input\/titanic\/gender_submission.csv\"\nSUBMISSION_PATH = \"submission.csv\"\n\nID = \"PassengerId\"\nTARGET = \"Survived\"\nTEST_SIZE = 0.2\nRANDOM_SEED = 42\nMAX_TRIAL = 20 # for simple test \nEPOCHS = 5  # for simple test \nVALIDATION_SPLIT = 0.12","33bf124b":"train = pd.read_csv(TRAIN_PATH)\ntest = pd.read_csv(TEST_PATH)","6b02ef3b":"#1. delete unnecessary columns\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp','Parch']\ntrain = train.drop(drop_elements, axis = 1)\ntest = test.drop(drop_elements, axis = 1)\n\n#2.find null data and fill new data \ndef checkNull_fillData(df):\n    for col in df.columns:\n        if len(df.loc[df[col].isnull() == True]) != 0:\n            if df[col].dtype == \"float64\" or df[col].dtype == \"int64\":\n                df.loc[df[col].isnull() == True,col] = df[col].mean()\n            else:\n                df.loc[df[col].isnull() == True,col] = df[col].mode()[0]\n                \ncheckNull_fillData(train)\ncheckNull_fillData(test)\n\n#3.one hot encoding \nstr_list = [] \nnum_list = []\nfor colname, colvalue in train.iteritems():\n    if type(colvalue[1]) == str:\n        str_list.append(colname)\n    else:\n        num_list.append(colname)\n        \ntrain = pd.get_dummies(train, columns=str_list)\ntest = pd.get_dummies(test, columns=str_list)","6565d621":"y = train[TARGET]\nX = train.drop([TARGET],axis=1)\nX_test = test\n\ngc.collect()","d42f2ec2":"from sklearn.preprocessing import StandardScaler\ntotal = pd.concat([X,X_test],axis=0)\ntrans = StandardScaler()\ntrans.fit(total)\n\nX= trans.transform(X)\nX_test = trans.transform(X_test)\n\ngc.collect()","4138376e":"X_train,X_val,y_train,y_val=train_test_split(X,y,test_size=TEST_SIZE,random_state=RANDOM_SEED)","00ae5f32":"clf = ak.StructuredDataClassifier(max_trials=MAX_TRIAL,seed=RANDOM_SEED)\nclf.fit(X_train, y_train, epochs=EPOCHS, validation_split=VALIDATION_SPLIT)","546f387e":"clf.evaluate(X_val, y_val)","850ab618":"model = clf.export_model()\nmodel.summary()","0cf7dca3":"pred_test = model.predict(X_test)","14c44200":"sub = pd.read_csv(SAMPLE_SUBMISSION_PATH)\nsub[TARGET]=(pred_test > 0.5).astype(int)\nsub.to_csv(SUBMISSION_PATH,index=False)\nsub.head()","9562088b":"# split data (input data and target data)","1d61845b":"# import libraries","8bb2808c":"# scaling","97d5e950":"# split data (train set and validation set)","ebdfce69":"# search best model and build best model ","848ad772":"# get best model","d25d57ca":"# load data ","128b556b":"# preprocess","846b8720":"# global variables","39d61c4d":"# predict test data using best model","0dd65e1f":"# evaluate model","a22a93aa":"# submission"}}