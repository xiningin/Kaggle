{"cell_type":{"3483ea43":"code","118c71c5":"code","a7f9fec7":"code","dd13382c":"code","024b09ab":"code","15447e95":"code","910be5cc":"code","4d18fe3c":"code","488f3f43":"code","509b51cd":"code","994f181f":"code","b7ee9561":"code","2bc9da6a":"code","72ab5bb2":"code","1b36dfbc":"code","529a0a69":"code","62394356":"code","199919a7":"code","afcecc20":"code","99739f12":"code","f79eb816":"code","947ffa1a":"markdown","874aa3a1":"markdown","3bbfd821":"markdown","8b12d32d":"markdown","2622ce4d":"markdown","039d8f5a":"markdown","595cbe4e":"markdown"},"source":{"3483ea43":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory","118c71c5":"PATH=\"..\/input\/100-bird-species\"\ntrain_dir = os.path.join(PATH, 'train')\nvalidation_dir = os.path.join(PATH, 'valid')\ntest_dir = os.path.join(PATH, 'test')","a7f9fec7":"# Create tf.data.Dataset for training, validation and test using Keras image_dataset_from_directory\n\nBATCH_SIZE = 32\nIMG_SIZE = (224,224)\n\ntrain_dataset = image_dataset_from_directory(train_dir,\n                                             shuffle=True,\n                                             batch_size=BATCH_SIZE,\n                                             image_size=IMG_SIZE)\n\nvalidation_dataset = image_dataset_from_directory(validation_dir,\n                                                  shuffle=True,\n                                                  batch_size=BATCH_SIZE,\n                                                  image_size=IMG_SIZE)\n\ntest_dataset = image_dataset_from_directory(test_dir,\n                                            shuffle=True,\n                                            batch_size=BATCH_SIZE,\n                                            image_size=IMG_SIZE)","dd13382c":"# Control bathches sizes\n\nprint('Number of train batches: %d' % tf.data.experimental.cardinality(train_dataset))\nprint('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\nprint('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))","024b09ab":"# The first nine images and labels from training set\n\nclass_names = train_dataset.class_names\n\nplt.figure(figsize=(12,12))\nfor images, labels in train_dataset.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[labels[i]])\n        plt.axis(\"off\")","15447e95":"# for better data performance using buffered prefetching \n\nAUTOTUNE = tf.data.AUTOTUNE\n\ntrain_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\nvalidation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\ntest_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)","910be5cc":"data_augmentation = tf.keras.Sequential([\n  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n])","4d18fe3c":"# Result for an image after apply the augmentation\n\nfor image, _ in train_dataset.take(1):\n    plt.figure(figsize=(10, 10))\n    first_image = image[0]\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n        plt.imshow(augmented_image[0] \/ 255)\n        plt.axis('off')","488f3f43":"# Download mobilenet_v2 model architecture.\n\npreprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input","509b51cd":"# Create the base model from the pre-trained model MobileNet V2\n\nIMG_SHAPE = IMG_SIZE + (3,)\nbase_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')","994f181f":"# This feature extractor converts each 224x224x3 image into a 7x7x1280 block of features\n\nimage_batch, label_batch = next(iter(train_dataset))\nfeature_batch = base_model(image_batch)\nprint(feature_batch.shape)","b7ee9561":"# Freeze the model weights before compile and train the model.\n\nbase_model.trainable = False","2bc9da6a":"# Convert the features to a single 1280 element vector per image\n\nglobal_average_layer = tf.keras.layers.GlobalAveragePooling2D()\nfeature_batch_average = global_average_layer(feature_batch)\nprint(feature_batch_average.shape)","72ab5bb2":"# Apply a tf.keras.layers.Dense layer to convert these features into 270 predictions per image\n\nprediction_layer = tf.keras.layers.Dense(270, activation = 'softmax')\nprediction_batch = prediction_layer(feature_batch_average)\nprint(prediction_batch.shape)","1b36dfbc":"# Build a model by chaining together the data augmentation, rescaling, base_model and feature extractor layers using the Keras\n\ninputs = tf.keras.Input(shape=(224, 224, 3))\nx = data_augmentation(inputs)\nx = preprocess_input(x)\nx = base_model(x, training=False)\nx = global_average_layer(x)\nx = tf.keras.layers.Dropout(0.2)(x)\noutputs = prediction_layer(x)\nmodel = tf.keras.Model(inputs, outputs)","529a0a69":"# Compile the model before training it. Since there are multi classes, I will use a Sparse Categorical Crossentropy loss \n\nbase_learning_rate = 0.0001\nmodel.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['acc'])","62394356":"model.summary()","199919a7":"initial_epochs = 10\nhistory = model.fit(train_dataset,\n                    epochs=initial_epochs,\n                    validation_data=validation_dataset)","afcecc20":"acc = history.history['acc']\nval_acc = history.history['val_acc']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,max(plt.ylim())])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","99739f12":"# Finaly we can verify the performance of the model on test set.\n\nloss, accuracy = model.evaluate(test_dataset)\nprint('Test accuracy :', accuracy)","f79eb816":"# Plot prediction results\n\nimage_batch, label_batch = test_dataset.as_numpy_iterator().next()\npredicted_batch = model.predict(image_batch)\npredicted_id = np.argmax(predicted_batch, axis=-1)\n\nplt.figure(figsize=(10, 10))\nfor i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(image_batch[i].astype(\"uint8\"))\n    plt.title(class_names[predicted_id[i]])\n    plt.axis(\"off\")","947ffa1a":"### Learning Curves","874aa3a1":"### Train The Model","3bbfd821":"### Create a base pre-trained model","8b12d32d":"### Simple Data Augmentation","2622ce4d":"### Evaluation and prediction","039d8f5a":"### Data Processing","595cbe4e":"### Introduction\n\nIn this project, I will classify images of birds by using transfer learning from a pre-trained network. I will use MobileNet V2 model developed at Google. I am beginner for computer vision and i am trying to learn more about it. I will follow transfer learning and fine-tuning which is tensorflow tutorial for the project as a guideline.\n\nMy aim is to complete an end to end computer vision problem with basic parts, such as bulding an input pipeline, compose the model, data augmentation etc.\n\nLet's get started !!"}}