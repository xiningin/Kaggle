{"cell_type":{"bdfed0a0":"code","f4235c7f":"code","bc9933f1":"code","6bdfccf3":"code","354b0740":"code","c9f9672c":"code","e2e565f3":"code","fb0d63ba":"code","633a9d0f":"code","5bdac081":"code","d22393dd":"code","799f12ee":"code","fa7443b3":"code","774a237d":"code","fbf4170f":"code","367634f9":"code","391bfcfb":"code","07966c4d":"code","9371a909":"code","a6799b35":"code","4314739e":"code","41a6a183":"code","cfd4991f":"code","f9b51243":"code","fe34fffb":"code","8a629d65":"code","292a49e0":"code","3a5fb2c8":"code","60aae1a9":"code","36a9e5a4":"code","755b9403":"code","e8a1b833":"code","50c69693":"code","bafe130f":"code","e5d961f1":"markdown","e8899d0b":"markdown","6fa7a3eb":"markdown","f457c551":"markdown","99255e2a":"markdown","564b3489":"markdown","e11fe9da":"markdown","15b31200":"markdown","b24afbce":"markdown","41b8da8c":"markdown","1a220172":"markdown","281e6ccc":"markdown","98a812b9":"markdown","55003a3d":"markdown"},"source":{"bdfed0a0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport random\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing.image import load_img\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f4235c7f":"#name of the directories\nos.listdir(\"..\/input\/sheep-breed-classification\/SheepFaceImages\")","bc9933f1":"Marino = \"\/kaggle\/input\/sheep-breed-classification\/SheepFaceImages\/Marino\/\"\nWhiteSuffolk = \"\/kaggle\/input\/sheep-breed-classification\/SheepFaceImages\/White Suffolk\"\nPollDorset = \"\/kaggle\/input\/sheep-breed-classification\/SheepFaceImages\/Poll Dorset\"\nSuffolk = \"\/kaggle\/input\/sheep-breed-classification\/SheepFaceImages\/Suffolk\"\n","6bdfccf3":"from tqdm import tqdm \nx = []\ny = []\n\ndef create_dataset(dirname,breedname):\n    for i in tqdm(os.listdir(dirname)):\n        path = os.path.join(dirname,i)\n        try:\n            img = cv2.imread(path)\n            img = cv2.resize(img,(150,150))\n        except:\n            continue\n            \n        x.append(img)\n        y.append(breedname)\n    return x,y\n        ","354b0740":"x,y = create_dataset(Marino,\"Marino\")\nx,y = create_dataset(WhiteSuffolk,\"White Suffolk\")\nx,y = create_dataset(PollDorset,\"Poll Dorset\")\nx,y = create_dataset(Suffolk,\"Suffolk\")","c9f9672c":"x = np.array(x)\ny = np.array(y)\nprint(x.shape,y.shape)","e2e565f3":"plt.figure(figsize = (12,7))\nfor i in range(10):\n    indx = random.randint(0,len(y))\n    img = x[indx]\n    plt.subplot(2,5,i+1)\n    plt.subplots_adjust(hspace=0.3)\n    plt.imshow(img)\n    plt.xlabel(y[indx])\n\nplt.tight_layout()\nplt.show()\n    ","fb0d63ba":"plt.style.use(\"ggplot\")\nplt.figure(figsize=(9,6))\nsns.countplot(y)\nplt.show()","633a9d0f":"from sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical\nle = LabelEncoder()\ny = le.fit_transform(y)\ny = to_categorical(y)","5bdac081":"#divide our dataset into train & test\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)","d22393dd":"img_size=150\nx_train = np.array(x_train)\/255.0\nx_test = np.array(x_test)\/255.0\n\nx_train = x_train.reshape(-1,img_size,img_size,3)\ny_train = np.array(y_train)\n\nx_test = x_test.reshape(-1,img_size,img_size,3)\ny_test = np.array(y_test)","799f12ee":"from tensorflow.keras.applications.resnet50 import ResNet50\nresnet = ResNet50(weights = \"imagenet\",include_top = False,input_shape=(150,150,3))","fa7443b3":"for layer in resnet.layers:\n    layer.trainable = False","774a237d":"from tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Flatten,Dense,Dropout\n\nmodel = Sequential()\nmodel.add(resnet)\nmodel.add(Flatten())\nmodel.add(Dense(4,activation = \"softmax\"))\n\nmodel.summary()","fbf4170f":"from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\ncheckpoint = ModelCheckpoint(\"resnet50.h5\",monitor = \"val_accuracy\",save_best_only = True,verbose=1)\nearlystop = EarlyStopping(monitor=\"val_accuracy\",patience=8,verbose=1)\n\nmodel.compile(optimizer=\"adam\",loss = \"categorical_crossentropy\",metrics = [\"accuracy\"])","367634f9":"history = model.fit(x_train,y_train,batch_size=32,validation_data = (x_test,y_test),\n                    epochs=25,verbose=1,callbacks = [checkpoint,earlystop])","391bfcfb":"loss,accuracy = model.evaluate(x_test,y_test)\nprint(f\"Loss for resnet50: {loss}\")\nprint(f\"Accuracy for resnet50: {accuracy}\")","07966c4d":"from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\ny_pred = model.predict_classes(x_test)\ny_pred[:15]","9371a909":"y_test_resnet = np.argmax(y_test,axis=1)\ny_test_resnet[:15]","a6799b35":"print(classification_report(y_test_resnet,y_pred))","4314739e":"from tensorflow.keras.applications.vgg19 import VGG19\nvgg = VGG19(weights = \"imagenet\",include_top = False,input_shape=(150,150,3))","41a6a183":"for layer in vgg.layers:\n    layer.trainable = False","cfd4991f":"model2 = Sequential()\nmodel2.add(vgg)\nmodel2.add(Flatten())\nmodel2.add(Dense(4,activation = \"softmax\"))\n\nmodel2.summary()","f9b51243":"checkpoint2 = ModelCheckpoint(\"vgg19.h5\",monitor = \"val_accuracy\",save_best_only = True,verbose=1)\nearlystop2 = EarlyStopping(monitor=\"val_accuracy\",patience=8,verbose=1)\nmodel2.compile(optimizer=\"adam\",loss = \"categorical_crossentropy\",metrics = [\"accuracy\"])\n\nhistory2 = model2.fit(x_train,y_train,batch_size=32,validation_data = (x_test,y_test),\n                    epochs=25,verbose=1,callbacks = [checkpoint2,earlystop2])","fe34fffb":"loss2,accuracy2 = model2.evaluate(x_test,y_test)\nprint(f\"Loss for vgg19: {loss2}\")\nprint(f\"Accuracy for vgg19: {accuracy2}\")","8a629d65":"from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\ny_pred = model2.predict_classes(x_test)\ny_pred[:15]","292a49e0":"y_test_vgg = np.argmax(y_test,axis=1)\ny_test_vgg[:15]","3a5fb2c8":"print(classification_report(y_test_vgg,y_pred))","60aae1a9":"from mlxtend.plotting import plot_confusion_matrix\ncm = confusion_matrix(y_test_vgg,y_pred)\nplot_confusion_matrix(conf_mat = cm,show_normed= True,class_names = [\"Marino\",\"Poll Dorset\",\"Suffolk\",\n                                                                     \"Whie Suffolk\"],figsize=(8,7));","36a9e5a4":"def plot_learning_curve_for_resnet(history,epochs):\n    plt.style.use(\"ggplot\")\n    plt.figure(figsize=(12,6))\n    epochs = np.arange(1,epochs+1)\n    plt.subplot(2,2,1)\n    plt.plot(epochs,history.history[\"accuracy\"],\"go-\")\n    plt.plot(epochs,history.history[\"val_accuracy\"],\"ro-\")\n    plt.title(\"Model Accuracy Curve for ResNet50\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend([\"Train\",\"Val\"],loc = \"upper left\")\n    \n    plt.subplot(2,2,2)\n    plt.plot(epochs,history.history[\"loss\"],\"go-\")\n    plt.plot(epochs,history.history[\"val_loss\"],\"ro-\")\n    plt.title(\"Model Loss Curve for ResNet50\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.legend([\"Train\",\"Val\"],loc = \"upper left\")\n    \n    plt.show()\n    ","755b9403":"def plot_learning_curve_for_vgg(history,epochs):   \n    plt.style.use(\"ggplot\")\n    plt.figure(figsize=(12,6))\n    epochs = np.arange(1,epochs+1)\n    plt.subplot(1,2,1)\n    plt.plot(epochs,history.history[\"accuracy\"],\"go-\")\n    plt.plot(epochs,history.history[\"val_accuracy\"],\"ro-\")\n    plt.title(\"Model Accuracy Curve for VGG19\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend([\"Train\",\"Val\"],loc = \"upper left\")\n    \n    plt.subplot(1,2,2)\n    plt.plot(epochs,history.history[\"loss\"],\"go-\")\n    plt.plot(epochs,history.history[\"val_loss\"],\"ro-\")\n    plt.title(\"Model Loss Curve for VGG19\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.legend([\"Train\",\"Val\"],loc = \"upper left\")\n    plt.show()","e8a1b833":"plot_learning_curve_for_resnet(history,25)","50c69693":"plot_learning_curve_for_vgg(history2,25)","bafe130f":"plt.figure(figsize=(12,7))\nfor i in range(10):\n    indx = random.randint(0,len(y_test_vgg))\n    plt.subplot(2,5,i+1)\n    plt.subplots_adjust(hspace=0.3)\n    plt.imshow(x_test[indx])\n    plt.xlabel(f\"Actual: {y_test_vgg[indx]} \\n Predicted: {y_pred[indx]}\")\n    \nplt.tight_layout()\nplt.show()\n    ","e5d961f1":"><h3>Classification Report: <\/h3>","e8899d0b":"><h3>Model Building:<\/h3>","6fa7a3eb":"><h3>Creating Dataset from the images:<\/h3>","f457c551":"><h3>Checking Models Performance:<\/h3>","99255e2a":"> <h3>Learning Curve<\/h3>","564b3489":"- So, here we can see that VGG19 performs better than ResNet50.Resnet50 gives 73% accuracy on the other hand VGG19 gives 92% accuracy","e11fe9da":"><h3>Confusion Matrix:<\/h3>","15b31200":"---\n\n<h1 style=\"text-align: center;font-size: 20px;\">Thanks for Reading!!<\/h1>\n\n---","b24afbce":"><h3>Let's see some of the images:<\/h3>","41b8da8c":"><h4> CNN models can not understand string values,so let's convert our target values into Numerical values,and then convert those values into one hot encoding by using to_categorical method <\/h4>","1a220172":"><h3>1.ResNet50:<\/h3>","281e6ccc":"><h3>2.VGG19:<\/h3>","98a812b9":"---\n\n<h1 style=\"text-align: center;font-size: 40px;\">Sheep Breeds Classification<\/h1>\n\n---\n\n<center><img src=\"https:\/\/domesticanimalbreeds.com\/wp-content\/uploads\/2019\/01\/suffolk-sheep-1024x585.jpg\n\"width=\"600\" height=\"200\"><\/center>\n\n---","55003a3d":"- Here we can see that each of the categories has same number of images,so our image Dataset is Perfectly Balanced"}}