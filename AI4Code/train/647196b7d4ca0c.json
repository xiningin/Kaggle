{"cell_type":{"b0e5b137":"code","ff6fd193":"code","91dd276e":"code","e0f40cb8":"code","4d293be8":"code","ec40c9e5":"code","3e5b3c06":"code","f9549ff1":"code","915ca687":"code","88d2172b":"code","71de4562":"code","26242063":"code","0536f632":"code","0085dcad":"code","38cdc9a3":"code","b5c3147c":"code","d0455d39":"code","2b7d999b":"code","300a4f27":"code","5d8e8348":"code","10f213de":"code","070db33a":"code","cf212e7c":"code","020d1d31":"code","59faa297":"code","b2bd8179":"code","5bd6cfdc":"code","575e8abb":"code","f6cb4189":"code","bb048837":"code","49a19195":"code","aa78d88f":"markdown","d2c7474a":"markdown","627d3d8f":"markdown","d0eb6ed9":"markdown","68dc2f46":"markdown","b7d11a21":"markdown","f9463171":"markdown","7d065281":"markdown","1bf5d450":"markdown","d57e864c":"markdown","d5f48fa8":"markdown","f5f0ec29":"markdown","ad597e83":"markdown","9b5ea395":"markdown","46bfb71b":"markdown","2bf2a1f4":"markdown"},"source":{"b0e5b137":"# To get the input path.\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        break\nprint(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ff6fd193":"import random,os,glob\nimport numpy as np\nimport time\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","91dd276e":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n#from tensorflow.random import set_random_seed\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Conv2D,Dense, Dropout,MaxPooling2D,GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import RMSprop, SGD, Adam, Nadam\nfrom tensorflow.keras.regularizers import l1, l2, L1L2\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n#set_random_seed(0)\n#np.random.seed(0)","e0f40cb8":"# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","4d293be8":"path = \"..\/input\/pavbhaji\"","ec40c9e5":"train_datagen = ImageDataGenerator(\n        rescale = 1.\/255,\n        rotation_range = 20,\n        width_shift_range = 0.2,\n        height_shift_range = 0.2,\n        horizontal_flip = True,\n        vertical_flip = True,\n        fill_mode='nearest')\nvalidation_datagen = ImageDataGenerator(\n        rescale = 1.\/255)\ntest_datagen = ImageDataGenerator(\n        rescale = 1.\/255)","3e5b3c06":"img_shape = (224, 224, 3) # default values\n\ntrain_batch_size = 77 #64\nval_batch_size = 33 #32\n\ntrain_generator = train_datagen.flow_from_directory(\n            directory = path + '\/train', \n            target_size = (img_shape[0], img_shape[1]),\n            batch_size = train_batch_size,\n            class_mode = 'categorical',\n            color_mode=\"rgb\",\n            shuffle = True,\n            seed=42) #binary - not working\n\nvalidation_generator = validation_datagen.flow_from_directory(\n            directory = path + '\/valid',\n            target_size = (img_shape[0], img_shape[1]),\n            batch_size = val_batch_size,\n            class_mode = 'categorical',\n            color_mode=\"rgb\",\n            shuffle = True) #False\n\ntest_generator = test_datagen.flow_from_directory(\n            directory = path + '\/test',\n            target_size = (img_shape[0], img_shape[1]),\n            batch_size = 1,\n            class_mode = None,\n            color_mode=\"rgb\",\n            shuffle = False)","f9549ff1":"for image_batch, label_batch in train_generator:\n  break\nimage_batch.shape, label_batch.shape","915ca687":"print (\"Train_generator\",train_generator.class_indices)\nprint (\"Validation_generator\",validation_generator.class_indices)\nprint (\"Test_generator\",test_generator.class_indices)\nlabels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n\nwith open('labels.txt', 'w') as f:\n  f.write(labels)\nlabels = dict((v,k) for k,v in train_generator.class_indices.items())\nprint(\"Our Labels\",labels)","88d2172b":"def Visualize(image,label):\n     fig, m_axs = plt.subplots(2, 4, figsize = (16, 8))\n     for (img, classs, c_ax) in zip(image, label, m_axs.flatten()):\n         img = np.squeeze(img)\n         c_ax.imshow(img)\n         c_ax.set_title('%s' % labels[np.argmax(classs)])\n         c_ax.axis('off')","71de4562":"image,label = next(train_generator)\nVisualize(image,label)","26242063":"image,label = next(validation_generator)\nVisualize(image,label)","0536f632":"#image,label = next(test_generator)\n#Visualize(image,label)","0085dcad":"from tensorflow.keras.applications import InceptionV3\n#from tensorflow.keras.applications import VGG16\n#from tensorflow.keras.applications import ResNet50\ninception = InceptionV3(weights = 'imagenet',\n              include_top = False,\n              input_shape = img_shape)","38cdc9a3":"print(\"Number of layers in the inception model: \", len(inception.layers))\n# Freeze the layers except the last 30 layers\nfor layer in inception.layers[:-30]:\n    layer.trainable = False","b5c3147c":"with strategy.scope():\n    \n# Create the model\n    model = Sequential()\n\n     # Add the convolutional base model\n    model.add(inception)\n    model.add(Conv2D(128, 3, activation='relu'))# kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)\n    model.add(Dropout(0.2))\n    model.add(GlobalAveragePooling2D())\n    # Add new layers\n    model.add(Flatten())\n\n    model.add(Dense(512, activation='relu'))\n    #model.add(Dropout(0.2))\n    model.add(Dense(512, activation='relu'))\n    # last layer\n    model.add(Dense(2, activation='softmax', kernel_regularizer=l2(0.001))) #relu,sigmoid #not 1 -categorical","d0455d39":"model.summary()","2b7d999b":"model.compile(loss='categorical_crossentropy', #binary, Nadam acc doesn't change\n              optimizer=Adam(lr=1e-4),\n              metrics=['accuracy'])","300a4f27":"es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\nmc = ModelCheckpoint('inception.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True) #Inception.h5\n\nsteps_per_epoch = train_generator.samples\/\/train_generator.batch_size\nvalidation_steps = validation_generator.samples\/\/validation_generator.batch_size\nstart = time.time()\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=steps_per_epoch ,\n    epochs=50,\n    validation_data=validation_generator,\n    validation_steps=validation_steps,\n    verbose=1,\n    workers=4,\n    callbacks=[es, mc])\nend = time.time()\nprint('Execution time: ', end-start)","5d8e8348":"train_acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\ntrain_loss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(train_acc) + 1)\n\nplt.plot(epochs, train_acc, 'b*-', label = 'Training accuracy')\nplt.plot(epochs, val_acc, 'r', label = 'Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, train_loss, 'b*-', label = 'Training loss')\nplt.plot(epochs, val_loss, 'r', label = 'Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","10f213de":"def load_img(img_path):\n    from keras.preprocessing import image\n    img = image.load_img(img_path, target_size=(224, 224))\n    img = image.img_to_array(img, dtype=np.uint8)\n    img = np.array(img)\/255.0\n    \n    plt.title(\"Loaded Image\")\n    plt.axis('off')\n    plt.imshow(img.squeeze())\n    return(img)","070db33a":"def prediction(img):\n    \n     model = tf.keras.models.load_model(\"inception.h5\")\n     p = model.predict(img[np.newaxis, ...])\n     classes=[]\n     prob=[]\n     print(\"\\n-------------------Individual Probability--------------------------------\\n\")\n     for i,j in enumerate (p[0],0):\n         print(labels[i].upper(),':',round(j*100,2),'%')\n         classes.append(labels[i])\n         prob.append(round(j*100,2))\n         \n     def plot_bar_x():\n         # this is for plotting purpose\n         index = np.arange(len(classes))\n         plt.bar(index, prob)\n         plt.xlabel('Labels', fontsize=12)\n         plt.ylabel('Probability', fontsize=12)\n         plt.xticks(index, classes, fontsize=12, rotation=20)\n         plt.title('Probability for loaded image')\n         plt.show()\n     plot_bar_x()","cf212e7c":"img = load_img(path +'\/train\/Not_PavBhaji\/38618427_2227520140864849_2036571121217699840_n.jpg')","020d1d31":"prediction(img)","59faa297":"img = load_img(path +'\/train\/PavBhaji\/20181115_125235.jpg')","b2bd8179":"prediction(img)","5bd6cfdc":"test_steps = test_generator.samples\/\/test_generator.batch_size\ntest_generator.reset()\nmodel = tf.keras.models.load_model(\"inception.h5\")\nprediction = model.predict_generator(test_generator,\n                                steps = test_steps,\n                                verbose=1)\n#import pdb\n#pdb.set_trace()\n#print(prediction)\npred_binary = [np.argmax(value) for value in prediction] \npred_binary = np.array(pred_binary)\n#pred_binary.reshape(24,1)\n#print(pred_binary)\n\nimport collections\nprint(collections.Counter(pred_binary))\n\n##Id = test_generator.index_array\n##Id = os.listdir(\"%s\/test\/PavBhaji\"%path)\n##Id.extend(os.listdir(\"%s\/test\/Not_PavBhaji\"%path))\nId = test_generator.filenames\npred_list_new = [labels[f] for f in pred_binary]\n##print(pred_list_new)\n##print(len(Id))\n\ntest_df = pd.DataFrame({'Image_name': Id,'Predicted_Label': pred_list_new})\ntest_df.to_csv('submission.csv', header=True, index=False)\ntest_df","575e8abb":"validation_steps = validation_generator.samples\/\/validation_generator.batch_size\nmodel.evaluate_generator(validation_generator,\n                        steps = test_steps)","f6cb4189":"images, label = next(validation_generator)\nmodel = tf.keras.models.load_model(\"inception.h5\")\nprobabilities = model.predict(images)\nVisualize(images,probabilities)","bb048837":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nLABELS=['Not_PavBhaji','PavBhaji']\ndef print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n    df_cm = pd.DataFrame(\n        confusion_matrix, index=class_names, columns=class_names, \n    )\n    fig = plt.figure(figsize=figsize, dpi = 300)\n    try:\n        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n    except ValueError:\n        raise ValueError(\"Confusion matrix values must be integers.\")\n    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    return fig\n\nprint_confusion_matrix(confusion_matrix(np.argmax(label,-1),np.argmax(probabilities,-1), labels = range(label.shape[1])), \n                            class_names = LABELS, figsize = (10, 1)).savefig('confusion_matrix.png')\n\nprint(classification_report(np.argmax(label,-1), \n                            np.argmax(probabilities,-1), \n                            target_names = LABELS))","49a19195":"from IPython.display import FileLinks\nFileLinks('.')","aa78d88f":"### Train the model","d2c7474a":"### Confusion Matrix & Sklearn classification report","627d3d8f":"## Import Neccessary Packages","d0eb6ed9":"## Hardware Config","68dc2f46":"## Pre trained model","b7d11a21":"### Prediction on Test Set","f9463171":"## Tensorflow Keras functions","7d065281":"## Validation Evaluation","1bf5d450":"## Data Augmentation\n","d57e864c":"# Generate Data\n","d5f48fa8":"## Importing necessary functions\n","f5f0ec29":"## Load Data Drive","ad597e83":"## Saving File links","9b5ea395":"### Training history","46bfb71b":"# Our model \n","2bf2a1f4":"## Visualize Data samples"}}