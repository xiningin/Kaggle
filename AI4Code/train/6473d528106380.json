{"cell_type":{"ea09526d":"code","a54bb4f3":"code","32c9aea1":"code","68dc1491":"code","81d2c1db":"code","dd0bd409":"code","4808b21f":"code","8142b667":"code","ae8be725":"code","312e0272":"markdown","2c4e013c":"markdown","dc88c99f":"markdown","b498a402":"markdown","e2375bbd":"markdown","f5d7b7ac":"markdown","6a064567":"markdown"},"source":{"ea09526d":"!pip install lofo-importance","a54bb4f3":"import numpy as np\nimport pandas as pd\n\ndf = pd.read_csv(\"..\/input\/train.csv\", index_col='id')\ndf['wheezy-copper-turtle-magic'] = df['wheezy-copper-turtle-magic'].astype('category')\ndf.shape","32c9aea1":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\ndef get_model():\n    return Pipeline([('scaler', StandardScaler()),\n                    ('qda', QuadraticDiscriminantAnalysis(reg_param=0.111))\n                   ])","68dc1491":"from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom lofo import LOFOImportance, FLOFOImportance, plot_importance\n\n\nfeatures = [c for c in df.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic']]\n\n\ndef get_lofo_importance(wctm_num):\n    sub_df = df[df['wheezy-copper-turtle-magic'] == wctm_num]\n    sub_features = [f for f in features if sub_df[f].std() > 1.5]\n    lofo_imp = LOFOImportance(sub_df, target=\"target\",\n                              features=sub_features, \n                              cv=StratifiedKFold(n_splits=4, random_state=42, shuffle=True), scoring=\"roc_auc\",\n                              model=get_model(), n_jobs=4)\n    return lofo_imp.get_importance()\n\nplot_importance(get_lofo_importance(0), figsize=(12, 12))","81d2c1db":"plot_importance(get_lofo_importance(1), figsize=(12, 12))","dd0bd409":"plot_importance(get_lofo_importance(2), figsize=(12, 12))","4808b21f":"from tqdm import tqdm_notebook\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfeatures_to_remove = []\npotential_gain = []\n\nfor i in tqdm_notebook(range(512)):\n    imp = get_lofo_importance(i)\n    features_to_remove.append(imp[\"feature\"].values[-1])\n    potential_gain.append(-imp[\"importance_mean\"].values[-1])\n    \nprint(\"Potential gain (AUC):\", np.round(np.mean(potential_gain), 5))","8142b667":"features_to_remove","ae8be725":"import numpy as np, pandas as pd\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn import svm, neighbors, linear_model, neural_network\nfrom sklearn.svm import NuSVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom tqdm import tqdm\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.feature_selection import VarianceThreshold\n\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\n\noof_svnu = np.zeros(len(train)) \npred_te_svnu = np.zeros(len(test))\n\noof_svc = np.zeros(len(train)) \npred_te_svc = np.zeros(len(test))\n\noof_knn = np.zeros(len(train)) \npred_te_knn = np.zeros(len(test))\n\noof_lr = np.zeros(len(train)) \npred_te_lr = np.zeros(len(test))\n\noof_mlp = np.zeros(len(train)) \npred_te_mlp = np.zeros(len(test))\n\noof_qda = np.zeros(len(train)) \npred_te_qda = np.zeros(len(test))\n\ndefault_cols = [c for c in train.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic']]\n\nfor i in range(512):\n    cols = [c for c in default_cols if c != features_to_remove[i]]\n    \n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n\n    data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n    data2 = StandardScaler().fit_transform(PCA(svd_solver='full',n_components='mle').fit_transform(data[cols]))\n    train3 = data2[:train2.shape[0]]; test3 = data2[train2.shape[0]:]\n    \n    data2 = StandardScaler().fit_transform(VarianceThreshold(threshold=1.5).fit_transform(data[cols]))\n    train4 = data2[:train2.shape[0]]; test4 = data2[train2.shape[0]:]\n    \n    # STRATIFIED K FOLD (Using splits=25 scores 0.002 better but is slower)\n    skf = StratifiedKFold(n_splits=5, random_state=42)\n    for train_index, test_index in skf.split(train2, train2['target']):\n\n        clf = NuSVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=4, nu=0.59, coef0=0.053)\n        clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n        oof_svnu[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n        pred_te_svnu[idx2] += clf.predict_proba(test3)[:,1] \/ skf.n_splits\n        \n        clf = neighbors.KNeighborsClassifier(n_neighbors=17, p=2.9)\n        clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n        oof_knn[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n        pred_te_knn[idx2] += clf.predict_proba(test3)[:,1] \/ skf.n_splits\n        \n        clf = linear_model.LogisticRegression(solver='saga',penalty='l1',C=0.1)\n        clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n        oof_lr[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n        pred_te_lr[idx2] += clf.predict_proba(test3)[:,1] \/ skf.n_splits\n        \n        clf = neural_network.MLPClassifier(random_state=3,  activation='relu', solver='lbfgs', tol=1e-06, hidden_layer_sizes=(250, ))\n        clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n        oof_mlp[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n        pred_te_mlp[idx2] += clf.predict_proba(test3)[:,1] \/ skf.n_splits\n        \n        clf = svm.SVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=42)\n        clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n        oof_svc[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n        pred_te_svc[idx2] += clf.predict_proba(test3)[:,1] \/ skf.n_splits\n        \n        clf = QuadraticDiscriminantAnalysis(reg_param=0.111)\n        clf.fit(train4[train_index,:],train2.loc[train_index]['target'])\n        oof_qda[idx1[test_index]] = clf.predict_proba(train4[test_index,:])[:,1]\n        pred_te_qda[idx2] += clf.predict_proba(test4)[:,1] \/ skf.n_splits\n        \n        \nprint('lr', roc_auc_score(train['target'], oof_lr))\nprint('knn', roc_auc_score(train['target'], oof_knn))\nprint('svc', roc_auc_score(train['target'], oof_svc))\nprint('svcnu', roc_auc_score(train['target'], oof_svnu))\nprint('mlp', roc_auc_score(train['target'], oof_mlp))\nprint('qda', roc_auc_score(train['target'], oof_qda))\nprint('blend 1', roc_auc_score(train['target'], oof_svnu*0.7 + oof_svc*0.05 + oof_knn*0.2 + oof_mlp*0.05))\nprint('blend 2', roc_auc_score(train['target'], oof_qda*0.5+oof_svnu*0.35 + oof_svc*0.025 + oof_knn*0.1 + oof_mlp*0.025))\n\noof_svnu = oof_svnu.reshape(-1, 1)\npred_te_svnu = pred_te_svnu.reshape(-1, 1)\noof_svc = oof_svc.reshape(-1, 1)\npred_te_svc = pred_te_svc.reshape(-1, 1)\noof_knn = oof_knn.reshape(-1, 1)\npred_te_knn = pred_te_knn.reshape(-1, 1)\noof_mlp = oof_mlp.reshape(-1, 1)\npred_te_mlp = pred_te_mlp.reshape(-1, 1)\noof_lr = oof_lr.reshape(-1, 1)\npred_te_lr = pred_te_lr.reshape(-1, 1)\noof_qda = oof_qda.reshape(-1, 1)\npred_te_qda = pred_te_qda.reshape(-1, 1)\n\ntr = np.concatenate((oof_svnu, oof_svc, oof_knn, oof_mlp, oof_lr, oof_qda), axis=1)\nte = np.concatenate((pred_te_svnu, pred_te_svc, pred_te_knn, pred_te_mlp, pred_te_lr, pred_te_qda), axis=1)\nprint(tr.shape, te.shape)\n\noof_lrr = np.zeros(len(train)) \npred_te_lrr = np.zeros(len(test))\nskf = StratifiedKFold(n_splits=5, random_state=42)\n\nfor train_index, test_index in skf.split(tr, train['target']):\n    lrr = linear_model.LogisticRegression()\n    lrr.fit(tr[train_index], train['target'][train_index])\n    oof_lrr[test_index] = lrr.predict_proba(tr[test_index,:])[:,1]\n    pred_te_lrr += lrr.predict_proba(te)[:,1] \/ skf.n_splits\n    \nprint('stack CV score =',round(roc_auc_score(train['target'],oof_lrr),6))\n\nsub = pd.read_csv('..\/input\/sample_submission.csv')\n\nsub['target'] = pred_te_lrr\nsub.to_csv('submission_stack.csv', index=False)","312e0272":"# LOFO Feature Importance\nhttps:\/\/github.com\/aerdem4\/lofo-importance","2c4e013c":"### Top 20 Features for wheezy-copper-turtle-magic = 1","dc88c99f":"### Find the most harmful features for each wheezy-copper-turtle-magic","b498a402":"### Top 20 Features for wheezy-copper-turtle-magic = 2","e2375bbd":"### Top 20 Features for wheezy-copper-turtle-magic = 0","f5d7b7ac":"# Create submission using the current best kernel\nhttps:\/\/www.kaggle.com\/tunguz\/ig-pca-nusvc-knn-qda-lr-stack by Bojan Tunguz","6a064567":"### Use the best model in public kernels"}}