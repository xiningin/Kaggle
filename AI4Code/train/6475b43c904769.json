{"cell_type":{"9e6ef074":"code","c094ad19":"code","10930c10":"code","002886bb":"code","0a6b94f2":"code","e280de77":"code","6611bda1":"code","96e821de":"code","9830c66c":"code","93c67893":"code","82a17170":"code","3a37f2f2":"code","e8606e54":"code","f3af310b":"code","64a6bcbf":"code","b7013041":"code","402e05a4":"markdown","a3804141":"markdown","2fedecd3":"markdown","89425c9b":"markdown","fe210130":"markdown","f971dfbb":"markdown","05f5ac39":"markdown","a28ad0a7":"markdown","664396b5":"markdown"},"source":{"9e6ef074":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","c094ad19":"hist_df = pd.read_csv(\"..\/input\/historical_transactions.csv\")","10930c10":"hist_df.head()","002886bb":"card_id_to_idx = dict((card_id, i) for i, card_id in enumerate(hist_df[\"card_id\"].unique()))\nmerchant_id_to_idx = dict((merchant_id, i) for i, merchant_id in enumerate(hist_df[\"merchant_id\"].unique()))","0a6b94f2":"hist_df[\"u\"] = hist_df[\"card_id\"].apply(lambda x: card_id_to_idx[x])\nhist_df[\"v\"] = hist_df[\"merchant_id\"].apply(lambda x: merchant_id_to_idx[x])\n","e280de77":"import scipy.sparse\n\nm = len(card_id_to_idx)\nn = len(merchant_id_to_idx)\n\nu = hist_df[\"u\"].values\nv = hist_df[\"v\"].values\nw = [1 for _ in u]\n\nmat = scipy.sparse.coo_matrix((w, (u, v)), shape=(m, n)).tocsr()\n\nd1 = np.squeeze(np.sum(mat, axis=1), axis=1).tolist()[0]\nd1tilde = [1. \/ np.sqrt(x) if x > 0 else 0. for x in d1]\n\nd2 = np.squeeze(np.sum(mat, axis=0)).tolist()[0]\nd2tilde = [1. \/ np.sqrt(x) if x > 0 else 0. for x in d2]\n\ndef diags(l):\n    idx = [i for i in range(len(l))]\n    return scipy.sparse.coo_matrix((l, (idx, idx))).tocsr()\n\nmat_tilde = diags(d1tilde).dot(mat).dot(diags(d2tilde))","6611bda1":"import scipy.sparse.linalg\n\nnproj = 50\n\n# proj_mat = np.random.randn(*(n, nproj))\n# feat_mat = mat_tilde.dot(proj_mat)\n# mat = mat.asfptype()\nu, s, vt = scipy.sparse.linalg.svds(mat_tilde, k=nproj)\n\nu.shape, s.shape, vt.shape","96e821de":"import matplotlib.pyplot as plt\nplt.stem(s)\nprint(np.sum(s==1))","9830c66c":"feat_mat = u.dot(np.diag(s))\nfeat_mat.shape","93c67893":"from sklearn.model_selection import train_test_split\n\ndf = pd.read_csv(\"..\/input\/train.csv\")\ntrain_df, val_df = train_test_split(df, test_size=0.1, random_state=2018)\ntest_df = pd.read_csv(\"..\/input\/test.csv\")\n\n","82a17170":"train_df.head()","3a37f2f2":"def get_labeled_data(df):\n    y = None\n    \n    if \"target\" in df.columns:\n        y = df[\"target\"].values\n    \n    X = np.zeros((df.shape[0], nproj))\n    \n    for i, irow in enumerate(df.iterrows()):\n        _, row = irow\n        idx = card_id_to_idx[row[\"card_id\"]]\n        X[i, :] = feat_mat[idx, :]\n    \n    valid_idx = np.sum(np.abs(X), axis=1) > 0\n    \n    return X, y, valid_idx","e8606e54":"train_X, train_y, train_idx = get_labeled_data(train_df)\nval_X, val_y, val_idx = get_labeled_data(val_df)\ntest_X, _, _ = get_labeled_data(test_df)","f3af310b":"from sklearn.ensemble import GradientBoostingRegressor\n\nmodel = GradientBoostingRegressor(verbose=2, n_estimators=50)\nmodel.fit(train_X[train_idx, :], train_y[train_idx])","64a6bcbf":"print(\"Preformance improved to {} from the trivial value of {}\".format(np.sqrt(np.mean(np.square(model.predict(val_X[val_idx, :]) - val_y[val_idx]))), np.sqrt(np.mean(np.square(np.mean(train_y[train_idx]) - val_y[val_idx])))))","b7013041":"pd.DataFrame({\n    \"card_id\": test_df[\"card_id\"],\n    \"target\": model.predict(test_X)\n}).to_csv(\"submission.csv\", index=False)","402e05a4":"# Matrix formulation\nLets see if we get any signal if we draw a graph linking cust_id and merchant_id if there was a purchase\nThe matrix **mat** represents the *adjaceny matrix* and **mat_tilde** represents the *normalized adjacency matrix* of this graph","a3804141":"# We dont improve much over constant predictor","2fedecd3":"# Embedding of card_id using merchant_id s","89425c9b":"# Singular value decomposition of normalized adjacency matrix\n\n* Lets create features using the left singular values of the *normalized adjacency matix* **mat_tilde**\n* We will use 50 singular vectors","fe210130":"# Use embedding to generate features for train, val and test data","f971dfbb":"Lets index card_ids and merchant_ids so that we can use matrix methods","05f5ac39":"Place the indexes in two columns of the dataframe","a28ad0a7":"# Objective of the notebook\n\nThe main objective is to show that there is little information in the merchant_id column by itself (in historical_transactions.csv)","664396b5":"# Lets plot the singular vectors\n* The graph is disconnected with two components (two singular vectors are equal to 1)\n* The other 48 singular vectors should give us a good embedding of card_id if there is one "}}