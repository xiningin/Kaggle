{"cell_type":{"5917fe99":"code","cc36cb39":"code","3ed7e27d":"code","86f4dbc5":"code","febcadc2":"code","c73cb211":"code","0cba4a92":"code","80ec6725":"code","76c70c21":"code","ea9b348f":"code","97151b79":"code","24d43b37":"code","f0197f1c":"code","48ca143d":"code","11fdbf1d":"code","c687c0eb":"code","17e87bb1":"markdown","583c9537":"markdown","629a512c":"markdown","99bbea1a":"markdown","207d877d":"markdown"},"source":{"5917fe99":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cc36cb39":"df = pd.read_csv(\"\/kaggle\/input\/plant-pathology-2020-fgvc7\/train.csv\", index_col=0)\nprint(df.shape)\ndf.head()","3ed7e27d":"from sklearn.model_selection import train_test_split\n\ntrain_set, valid_set = train_test_split(df, test_size=0.2, random_state=42)\n\nprint(train_set.shape)\nprint(valid_set.shape)","86f4dbc5":"import shutil\nfrom shutil import copyfile\n\n# delete temp dir\nif os.path.exists('\/kaggle\/temp\/'):\n    shutil.rmtree('\/kaggle\/temp\/')\n\nos.mkdir('\/kaggle\/temp\/')\n\n# train directory\nos.mkdir('\/kaggle\/temp\/train')\nos.mkdir('\/kaggle\/temp\/train\/healthy')\nos.mkdir('\/kaggle\/temp\/train\/multiple_diseases')\nos.mkdir('\/kaggle\/temp\/train\/rust')\nos.mkdir('\/kaggle\/temp\/train\/scab')\n\n# validation directory\nos.mkdir('\/kaggle\/temp\/valid')\nos.mkdir('\/kaggle\/temp\/valid\/healthy')\nos.mkdir('\/kaggle\/temp\/valid\/multiple_diseases')\nos.mkdir('\/kaggle\/temp\/valid\/rust')\nos.mkdir('\/kaggle\/temp\/valid\/scab')","febcadc2":"SOURCE = '\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/'\n\nTRAIN_DIR = '\/kaggle\/temp\/train\/'\n\n# copy images to train directory\nfor index, data in train_set.iterrows():\n    label = df.columns[np.argmax(data)]\n    filepath = os.path.join(SOURCE, index + \".jpg\")\n    destination = os.path.join(TRAIN_DIR, label, index + \".jpg\")\n    copyfile(filepath, destination)\n    \nfor subdir in os.listdir(TRAIN_DIR):\n    print(subdir, len(os.listdir(os.path.join(TRAIN_DIR, subdir))))","c73cb211":"VALID_DIR = '\/kaggle\/temp\/valid\/'\n\n# copy images to valid directory\nfor index, data in valid_set.iterrows():\n    label = df.columns[np.argmax(data)]\n    filepath = os.path.join(SOURCE, index + \".jpg\")\n    destination = os.path.join(VALID_DIR, label, index + \".jpg\")\n    copyfile(filepath, destination)\n    \nfor subdir in os.listdir(VALID_DIR):\n    print(subdir, len(os.listdir(os.path.join(VALID_DIR, subdir))))","0cba4a92":"healthy_dir = os.path.join(TRAIN_DIR, 'healthy')\nmdiseases_dir = os.path.join(TRAIN_DIR, 'multiple_diseases')\nscab_dir = os.path.join(TRAIN_DIR, 'scab')\nrust_dir = os.path.join(TRAIN_DIR, 'rust')\n\nhealthy_files = os.listdir(healthy_dir)\nmdiseases_files = os.listdir(mdiseases_dir)\nscab_files = os.listdir(scab_dir)\nrust_files = os.listdir(rust_dir) ","80ec6725":"%matplotlib inline\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\npic_index = 2\n\nnext_healthy = [os.path.join(healthy_dir, fname) for fname in healthy_files[pic_index-2:pic_index]]\nnext_mdiseases = [os.path.join(mdiseases_dir, fname) for fname in mdiseases_files[pic_index-2:pic_index]]\nnext_scab = [os.path.join(scab_dir, fname) for fname in scab_files[pic_index-2:pic_index]]\nnext_rust = [os.path.join(rust_dir, fname) for fname in rust_files[pic_index-2:pic_index]]\n\n\nnrows = 4\nncols = 4\n\nfig = plt.gcf()\nfig.set_size_inches(ncols*4, nrows*4)\n\nfor i, img_path in enumerate(next_healthy+next_mdiseases+next_scab+next_rust):\n    sp = plt.subplot(nrows, ncols, i + 1)\n    sp.axis('Off') # Don't show axes (or gridlines)\n    img = mpimg.imread(img_path)\n    plt.title(img_path.split('\/')[-2])\n    plt.imshow(img)\n    \nplt.show()","76c70c21":"import tensorflow as tf\nimport keras_preprocessing\nfrom keras_preprocessing import image\nfrom keras_preprocessing.image import ImageDataGenerator\n\ntraining_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                      rotation_range=40,\n                                      width_shift_range=0.2,\n                                      height_shift_range=0.2,\n                                      shear_range=0.2,\n                                      zoom_range=0.2,\n                                      horizontal_flip=True,\n                                      fill_mode='nearest')\n\nvalidation_datagen = ImageDataGenerator(rescale = 1.\/255)\n\ntrain_generator = training_datagen.flow_from_directory(TRAIN_DIR, target_size=(150,150), class_mode='categorical', batch_size=32)\nvalidation_generator = validation_datagen.flow_from_directory(VALID_DIR, target_size=(150,150), class_mode='categorical', batch_size=32)","ea9b348f":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(4, activation='softmax')\n])\n\nmodel.summary()","97151b79":"model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=5)\ncheckpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"cnn.h5\", save_best_only=True)\n\nhistory = model.fit(train_generator, epochs=50, steps_per_epoch=46, \n                    validation_data = validation_generator, validation_steps=12, callbacks=[early_stopping_cb, checkpoint_cb])","24d43b37":"import matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.show()","f0197f1c":"model = tf.keras.models.load_model(\"cnn.h5\") # rollback to best model\nmodel.evaluate(validation_generator)","48ca143d":"from keras_preprocessing import image\n\ntest_set = pd.read_csv(\"\/kaggle\/input\/plant-pathology-2020-fgvc7\/test.csv\", index_col=0)\n\nX_test = []\nfor index, data in test_set.iterrows():\n    filepath = os.path.join(SOURCE, index + \".jpg\")\n    img = image.load_img(filepath, target_size=(150, 150))\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    X_test.append(x)\n    \nX_test = np.vstack(X_test) \/ 255 # rescale images","11fdbf1d":"y_pred = model.predict(X_test, batch_size=10)\ndf_out = pd.concat([test_set.reset_index(), pd.DataFrame(y_pred, columns = train_generator.class_indices.keys())], axis=1).set_index(\"image_id\")\ndf_out.to_csv('submission.csv')\ndf_out.head()","c687c0eb":"nrows = 4\nncols = 4\n\nfig = plt.gcf()\nfig.set_size_inches(ncols*4, nrows*4)\n\nfor i, (idx, row) in enumerate(df_out.sample(nrows*ncols).iterrows()):\n    filepath = filepath = os.path.join(SOURCE, idx + \".jpg\")\n    sp = plt.subplot(nrows, ncols, i + 1)\n    sp.axis('Off') # Don't show axes (or gridlines)\n    img = mpimg.imread(filepath)\n    plt.title(df_out.columns[np.argmax(row)])\n    plt.imshow(img)\n    \nplt.show()","17e87bb1":"# keras ImageGenerator API","583c9537":"# Make Predictions","629a512c":"# Epxlore Images","99bbea1a":"# Prepare Image Directories","207d877d":"# CNN modeling"}}