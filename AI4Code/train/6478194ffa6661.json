{"cell_type":{"4e031a2a":"code","961e4a72":"code","7c5fcc49":"code","73aa48eb":"code","7df4033a":"code","84cb5ad0":"code","ab14a3db":"code","99cb5270":"code","42ce88f8":"code","8b9bc772":"code","cc75ff0b":"code","00a4e990":"code","7869f7ab":"code","bc320528":"code","3acbf033":"code","ac4d7ced":"code","d246b1a7":"code","b82e6da3":"code","2f64316d":"code","6afdca5c":"code","8aef059c":"code","65c506bb":"code","ffb1aa51":"code","db7d3fdb":"code","9a1387c7":"code","8bb1e6e9":"code","62449d6b":"code","686a86fe":"code","6b065e18":"code","78612eb7":"code","3b6b2ff7":"code","41dc4ea3":"code","ad64832d":"code","b517a4bb":"code","4e2652e9":"code","4ad95aec":"code","be08966c":"code","87f7d470":"code","f556083d":"code","b9eb9802":"code","b67a6f34":"code","91270769":"code","d072bd28":"code","7881b9d3":"code","673dd573":"code","737a92c1":"code","e661ab93":"code","b413d23c":"code","5e7b67ae":"code","bca62acd":"code","3c059655":"code","42a1191c":"code","2c9bbcd1":"code","83e94674":"code","6ddfc934":"code","4cbbd75a":"code","59401bfe":"code","019dcdda":"code","efbe03a0":"code","557c8412":"code","a3d63743":"code","28d81a9f":"code","543afd0b":"code","a0b57d41":"code","1ddcb2c7":"code","f1333f5f":"code","af86e9bb":"markdown","98f091dd":"markdown","a3319689":"markdown","08a53cbc":"markdown","163bb72e":"markdown","1c073c48":"markdown","d5f1ac10":"markdown","4506e387":"markdown","c45fcb93":"markdown","70b68f6a":"markdown","605a8a86":"markdown","96b29099":"markdown","1d9a286b":"markdown","745d083b":"markdown","5ccc2c3b":"markdown","b0a8f8ad":"markdown","3c43e290":"markdown","31cc6218":"markdown","e285741d":"markdown","cb27030f":"markdown","a0f2399b":"markdown","41a64969":"markdown","38b215e7":"markdown","36cb1d22":"markdown","f9d741bc":"markdown","834cf82e":"markdown","37ed6d57":"markdown","8fc7ba17":"markdown","9f773885":"markdown","5d4539ce":"markdown","5a951b45":"markdown","91c33eb4":"markdown","c81626c3":"markdown","058961ce":"markdown","37b4bb25":"markdown","d7e3bf81":"markdown","88da8658":"markdown","35d7ebca":"markdown","772ceee0":"markdown","912108e9":"markdown","79d23622":"markdown","de472db6":"markdown","b289a3c5":"markdown","4d9bd5c6":"markdown","d4f2061f":"markdown","cf51a1fb":"markdown","85c1dc59":"markdown","4ba11499":"markdown","f6d91737":"markdown","87f528e1":"markdown","5cf477c3":"markdown","b00934de":"markdown","51f50ed9":"markdown","d37799df":"markdown","7a93260d":"markdown"},"source":{"4e031a2a":"import pandas as pd\nimport numpy as np","961e4a72":"df = pd.read_excel('..\/input\/covid19\/dataset.xlsx', encoding='utf8')","7c5fcc49":"df.head()","73aa48eb":"print(\"This dataset has {:.1f}\".format(100*df.isna().to_numpy().sum()\/(df.shape[0]*df.shape[1])) + \"% missing values\")","7df4033a":"#Encode the addmission columns into one\ndf2 = df.copy()\n\ndef unit_room(x):\n    if x['Patient addmited to regular ward (1=yes, 0=no)']>0:\n        return 'regular ward'\n    elif x['Patient addmited to semi-intensive unit (1=yes, 0=no)']>0:\n        return 'semi-intensive'\n    elif x['Patient addmited to intensive care unit (1=yes, 0=no)']>0:\n        return 'icu'\n    else:\n        return 'elective'\n\ndf2['unit'] = df2.apply(unit_room, axis=1)","84cb5ad0":"df2[['Patient addmited to regular ward (1=yes, 0=no)', \n     'Patient addmited to semi-intensive unit (1=yes, 0=no)',\n     'Patient addmited to intensive care unit (1=yes, 0=no)',\n     'unit']].head(10)","ab14a3db":"#Conversion from categorical to numerical\nmask = {'positive': 1, \n        'negative': 0,\n        'detected': 1, \n        'not_detected': 0,\n        'not_done': np.NaN,\n        'N\u00e3o Realizado': np.NaN,\n        'absent': 0, \n        'present': 1,\n        'detected': 1, \n        'not_detected': 0,\n        'normal': 1,\n        'light_yellow': 1, \n        'yellow': 2, \n        'citrus_yellow': 3, \n        'orange': 4,\n        'clear': 1, \n        'lightly_cloudy': 2, \n        'cloudy': 3, \n        'altered_coloring': 4,\n        '<1000': 1000,\n        'Ausentes': 0, \n        'Urato Amorfo --+': 1, \n        'Oxalato de C\u00e1lcio +++': 1,\n        'Oxalato de C\u00e1lcio -++': 1, \n        'Urato Amorfo +++': 1}\n\ndf3 = df2.copy()\ndf3 = df2.replace(mask)\n\ndf3['Urine - pH'] = df3['Urine - pH'].astype('float')\ndf3['Urine - Leukocytes'] = df3['Urine - Leukocytes'].astype('float')","99cb5270":"#Removal of exams not performed on positive cases\nexams_cols = df3.columns.to_list()[6:-1]\n\nis_null_columns_covid = df3[df3['SARS-Cov-2 exam result']==1][exams_cols].apply(lambda col: col.isnull().all(), axis=0)\nall_null_columns_covid = is_null_columns_covid[is_null_columns_covid==True]","42ce88f8":"print(\"Exams not performed on positive cases, so they are uninformative:\\n\")\nprint(all_null_columns_covid.index)","8b9bc772":"df4 = df3[set(df3.columns)-set(all_null_columns_covid.index)].copy()\nexams_cols = set(exams_cols) - set(all_null_columns_covid.index)","cc75ff0b":"exams_performed = (-df4[exams_cols].isnull()).astype('uint8')","00a4e990":"exams_performed.head()","7869f7ab":"import seaborn as sns\nimport matplotlib.pyplot as plt","bc320528":"exams_cols_list = list(exams_cols)\nfreqExams = df4.shape[0] - df4[exams_cols_list].isnull().sum()\n\ncovY = (df4[df4['SARS-Cov-2 exam result']==1].shape[0]\n        -df4[df4['SARS-Cov-2 exam result']==1][exams_cols_list].isnull().sum())\/(df4.shape[0] - df4[exams_cols_list].isnull().sum())\ncovN = (df4[df4['SARS-Cov-2 exam result']==0].shape[0]\n        -df4[df4['SARS-Cov-2 exam result']==0][exams_cols_list].isnull().sum())\/(df4.shape[0] - df4[exams_cols_list].isnull().sum())\n\nexamsICU = (df4[df4['unit']=='icu'].shape[0]\n        -df4[df4['unit']=='icu'][exams_cols_list].isnull().sum())\/(df4.shape[0] - df4[exams_cols_list].isnull().sum())\nexamsSemiIntesive = (df4[df4['unit']=='semi-intensive'].shape[0]\n        -df4[df4['unit']=='semi-intensive'][exams_cols_list].isnull().sum())\/(df4.shape[0] - df4[exams_cols_list].isnull().sum())\nexamsRegular = (df4[df4['unit']=='regular ward'].shape[0]\n        -df4[df4['unit']=='regular ward'][exams_cols_list].isnull().sum())\/(df4.shape[0] - df4[exams_cols_list].isnull().sum())\nexamsElective = (df4[df4['unit']=='elective'].shape[0]\n        -df4[df4['unit']=='elective'][exams_cols_list].isnull().sum())\/(df4.shape[0] - df4[exams_cols_list].isnull().sum())\n\nfig, axs = plt.subplots(3, 1, figsize=(25,8))\nfig.patch.set_facecolor('white')\n\n#Frequency plot\npFreq = axs[0].bar(exams_cols_list, freqExams, color='orange', )  \naxs[0].set_title(\"(a) Frequency of tests performed\")\naxs[0].get_xaxis().set_ticks([])\n\n#Admission units over total tests performed\npElective = axs[1].bar(exams_cols_list, examsElective, color='dodgerblue')\npRegular = axs[1].bar(exams_cols_list, examsRegular, bottom=examsElective,  color='lightcoral')\npSemiIntesive = axs[1].bar(exams_cols_list, examsSemiIntesive, bottom=(examsElective+examsRegular), color='orangered')\npICU = axs[1].bar(exams_cols_list, examsICU, bottom=(examsSemiIntesive+examsElective+examsRegular), color='darkred')\naxs[1].set_title(\"(b) Patient admission unit representativeness by test performed\")\naxs[1].legend([\"Elective*\", \"Regular ward\", \"Semi-Intensive\", \"ICU\"], loc=\"lower right\")\naxs[1].get_xaxis().set_ticks([])\n\n#Percentage of COVID cases over total tests performed\npCovY = axs[2].bar(exams_cols_list, covY, color='red')\npCovN = axs[2].bar(exams_cols_list, covN, bottom=covY, color='grey')\nplt.xticks(exams_cols_list, exams_cols_list, rotation='vertical')\naxs[2].set_title(\"(c) Percentage of COVID cases over total tests performed\")\naxs[2].legend([\"COVID POSITIVE\", \"COVID NEGATIVE\"])\n\nplt.xticks(exams_cols_list, exams_cols_list, rotation='vertical')\n\nplt.subplots_adjust(hspace=0.2) \nfig.suptitle(\"Figure 1 - Analysis of variables with respect to frequency, patient admission unit and COVID status\")\nplt.plot()","3acbf033":"plt.figure(figsize=(15,10))\nsns.heatmap(exams_performed, cbar=False)\nsns.set(rc={'axes.facecolor':'white', 'figure.facecolor':'white'})\nplt.title(\"Figure 2 - Presence (white) or absense (black) of exams\")","ac4d7ced":"from sklearn.decomposition import PCA","d246b1a7":"pca_model = PCA(random_state=42).fit(exams_performed)","b82e6da3":"%matplotlib inline\nvariances_explained = pca_model.explained_variance_ratio_.cumsum()\nfig = plt.figure(figsize=(15,5))\nfig.patch.set_facecolor('white')\nplt.step(list(range(1,len(variances_explained)+1)),variances_explained)\nplt.title(\"Figure 3 - Cummulative explained variance of Principal Components\")","2f64316d":"variances_explained","6afdca5c":"pca_model = PCA(n_components=6, random_state=42).fit(exams_performed)","8aef059c":"fig, axs = plt.subplots(2, 3, figsize=(20,10))\nfig.patch.set_facecolor((1,1,1))\nplt.subplots_adjust(wspace=0.5) \npc=-1\nfor i in list(range(2)): #plot lines\n  for j in list(range(3)): #plot cols\n    pc+=1\n    component_feature_explanation = pd.Series(pca_model.components_[pc], index=list(exams_cols)).sort_values()\n    axis_truncated = [txt[:20] for txt in component_feature_explanation[-20:].index]\n    axs[i, j].barh(axis_truncated, component_feature_explanation[-20:])\n    axs[i, j].set_title('PC '+str(pc+1))\nfig.suptitle(\"Figure 4 - Principal Components (PC) explained\")","65c506bb":"pcs_vars = {'respiratory': ['Influenza B', 'Respiratory Syncytial Virus', 'Influenza A',\n                            'Metapneumovirus', 'Parainfluenza 1', 'Inf A H1N1 2009',\n                            'Bordetella pertussis', 'Chlamydophila pneumoniae', 'Coronavirus229E',\n                            'Parainfluenza 2', 'Parainfluenza 3', 'CoronavirusNL63',\n                            'Rhinovirus\/Enterovirus', 'CoronavirusOC43', 'Coronavirus HKU1',\n                            'Adenovirus', 'Parainfluenza 4'],\n            'regular_blood': ['Proteina C reativa mg\/dL',\n                              'Neutrophils', 'Mean platelet volume ', 'Monocytes',\n                              'Red blood cell distribution width (RDW)', 'Red blood Cells',\n                              'Platelets', 'Eosinophils', 'Basophils', 'Leukocytes',\n                              'Mean corpuscular hemoglobin (MCH)', 'Mean corpuscular volume (MCV)',\n                              'Mean corpuscular hemoglobin concentration\\xa0(MCHC)', 'Lymphocytes',\n                              'Hemoglobin', 'Hematocrit'],\n            'liver_kidney_gas': ['Creatine phosphokinase\\xa0(CPK)\\xa0', \n                                 'International normalized ratio (INR)', \n                                 'Alkaline phosphatase', 'Gamma-glutamyltransferase\\xa0',\n                                 'Alanine transaminase', 'Aspartate transaminase',\n                                 'HCO3 (venous blood gas analysis)',\n                                 'Hb saturation (venous blood gas analysis)',\n                                 'Total CO2 (venous blood gas analysis)',\n                                 'pCO2 (venous blood gas analysis)', 'pH (venous blood gas analysis)',\n                                 'pO2 (venous blood gas analysis)',\n                                 'Base excess (venous blood gas analysis)', 'Total Bilirubin',\n                                 'Direct Bilirubin', 'Indirect Bilirubin',\n                                 'Sodium', 'Potassium', 'Urea', 'Creatinine'],\n            'urine': ['Urine - Ketone Bodies', 'Urine - Esterase', 'Urine - Protein',\n                      'Urine - Hyaline cylinders', 'Urine - Urobilinogen',\n                      'Urine - Bile pigments', 'Urine - Hemoglobin', 'Urine - pH',\n                      'Urine - Granular cylinders', 'Urine - Aspect', 'Urine - Density',\n                      'Urine - Color', 'Urine - Red blood cells', 'Urine - Leukocytes',\n                      'Urine - Yeasts', 'Urine - Crystals'],\n            'bone_narrow_cells': ['Metamyelocytes', 'Myelocytes', 'Promyelocytes', 'Rods #',\n                                  'Myeloblasts', 'Segmented'],\n            'influenza_rapid': ['Influenza B, rapid test', 'Influenza A, rapid test']}\n\nvars_analyzed = [var for pc in pcs_vars for var in pcs_vars[pc]]\n#len(vars_analyzed) == len(set(vars_analyzed)) #sanity check must return true\n#len(vars_analyzed) #Output: 77","ffb1aa51":"df5 = df4.copy()\n#Here we create columns to flag the group of tests performed\nfor pc in pcs_vars.keys():\n  df5[pc+\"_tests\"] = df5.apply(lambda x: 0 if x[pcs_vars[pc]].isnull().all() else 1,axis=1)","db7d3fdb":"exams_not_included = list(set(exams_performed.columns) - set(vars_analyzed))\n\nfreqExams = df5.shape[0] - df5[exams_not_included].isnull().sum()\ncovY = (df5[df5['SARS-Cov-2 exam result']==1].shape[0]\n        -df5[df5['SARS-Cov-2 exam result']==1][exams_not_included].isnull().sum())\/(df5.shape[0] - df5[exams_not_included].isnull().sum())\ncovN = (df5[df5['SARS-Cov-2 exam result']==0].shape[0]\n        -df5[df5['SARS-Cov-2 exam result']==0][exams_not_included].isnull().sum())\/(df5.shape[0] - df5[exams_not_included].isnull().sum())\n\n\nfig, axs = plt.subplots(2, 1, figsize=(15,5))\n\n\npFreq = axs[0].bar(exams_not_included, freqExams, color='orange', )  \npCovY = axs[1].bar(exams_not_included, covY, color='red')\npCovN = axs[1].bar(exams_not_included, covN, bottom=covY, color='grey')\naxs[0].get_xaxis().set_ticks([])\nplt.xticks(exams_not_included, exams_not_included, rotation='vertical')\naxs[0].set_title(\"Frequency of tests performed\")\naxs[1].set_title(\"Percentage of COVID cases over total tests perform\")\nplt.legend([\"COVID POSITIVE\", \"COVID NEGATIVE\"])\nplt.subplots_adjust(hspace=0.2) \n\nfig.suptitle(\"Figure 5 - Analysis of variables not included in the 5 proposed groups\")\nplt.plot()","9a1387c7":"inv_pcs_vars = {}\nfor pc in pcs_vars:\n    for var in pcs_vars[pc]:\n        inv_pcs_vars[var]=pc\n\ncols_sorted = pd.DataFrame(data = exams_performed.sum(), columns=[\"count\"]).merge(\n    pd.DataFrame(data = pd.Series(inv_pcs_vars), columns=[\"pc\"]), how=\"left\", left_index=True, \n    right_index=True).sort_values(by=[\"pc\",\"count\"],ascending=False)\n\nrows_order_by = cols_sorted.reset_index().groupby(\"pc\").first().sort_values(by=[\"count\"],ascending=False)[\"index\"].to_list()\n#rows_order_by = ['Respiratory Syncytial Virus', 'Hematocrit', 'Influenza B, rapid test','Creatinine', 'Segmented', 'Urine - Red blood cells']\n\nexams_performed_sorted = exams_performed[cols_sorted.index].sort_values(by=rows_order_by, ascending=False)\n\nplt.figure(figsize=(15,10))\nsns.heatmap(exams_performed_sorted, cbar=False)\nsns.set(rc={'axes.facecolor':'white', 'figure.facecolor':'white'})\nplt.title(\"Figure 6 - Figure 2 reordered by group of exams\")","8bb1e6e9":"def cooc_matrix(dataset):\n  cooc =  dataset.T.dot(dataset)\/dataset.shape[0]\n  cooc_format = cooc.style.format(\"{:.1%}\")\n  return cooc_format\n\ntests_cols = ['respiratory_tests', 'regular_blood_tests', \n              'liver_kidney_gas_tests', 'urine_tests', 'bone_narrow_cells_tests',\n              'influenza_rapid_tests']\n\ncooc_tests_covid_neg = cooc_matrix(df5[df5['SARS-Cov-2 exam result']==0][tests_cols])\ncooc_tests_covid_poz = cooc_matrix(df5[df5['SARS-Cov-2 exam result']==1][tests_cols])\ncooc_tests_icu = cooc_matrix(df5[df5['unit']=='icu'][tests_cols])\ncooc_tests_semi = cooc_matrix(df5[df5['unit']=='semi-intensive'][tests_cols])\ncooc_tests_reg = cooc_matrix(df5[df5['unit']=='regular ward'][tests_cols])\ncooc_tests_ele = cooc_matrix(df5[df5['unit']=='elective'][tests_cols])","62449d6b":"cooc_tests_covid_neg","686a86fe":"cooc_tests_covid_poz","6b065e18":"cooc_tests_icu","78612eb7":"cooc_tests_semi","3b6b2ff7":"cooc_tests_reg","41dc4ea3":"cooc_tests_ele","ad64832d":"#Data split and hyperparameter search\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\n\n#Metrics\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\n\n#Classifiers\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn import svm\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom tensorflow.python.keras.layers import Dense\nfrom tensorflow.python.keras import Sequential\nfrom keras.wrappers.scikit_learn import KerasClassifier","b517a4bb":"selected_vars = ['SARS-Cov-2 exam result', 'unit', 'Patient age quantile'] + pcs_vars['regular_blood']\ndf_red_blood = df5[selected_vars].dropna() #Shape: (420, 19)\n\nX = df_red_blood[pcs_vars['regular_blood']+['Patient age quantile']]\ny = df_red_blood['SARS-Cov-2 exam result']\nstrat = df_red_blood['SARS-Cov-2 exam result'].astype(str) + df_red_blood['unit'] #stratification\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify=strat, shuffle=True, random_state=42)\n#X_train.shape: (294, 17)\n#X_test.shape: (126, 17)","4e2652e9":"blood_with_respiratory = df5[(df5['regular_blood_tests']==1)&(df5['SARS-Cov-2 exam result']==0)][pcs_vars['respiratory']].dropna()\n\nplt.figure(figsize=(8,8))\nsns.set(rc={'axes.facecolor':'white', 'figure.facecolor':'white'})\nsns.heatmap(blood_with_respiratory.T.dot(blood_with_respiratory),annot=True, cbar=False)\nplt.title(\"Figure 8 - Coocurrence of patients diagnosed with respiratory diseases, but SARS-CoV-2 Negative\")","4ad95aec":"df_InfB = df5[(df5['Influenza B']==1) & (df5['regular_blood_tests']==1) & (df5['SARS-Cov-2 exam result']==0)][pcs_vars['regular_blood']+['Patient age quantile', 'SARS-Cov-2 exam result']].dropna()\nX_InfB = df_InfB[pcs_vars['regular_blood']+['Patient age quantile']]\ny_InfB = df_InfB['SARS-Cov-2 exam result']\n\ndf_H1N1 = df5[(df5['Inf A H1N1 2009']==1) & (df5['regular_blood_tests']==1) & (df5['SARS-Cov-2 exam result']==0)][pcs_vars['regular_blood']+['Patient age quantile', 'SARS-Cov-2 exam result']].dropna()\nX_H1N1 = df_H1N1[pcs_vars['regular_blood']+['Patient age quantile']]\ny_H1N1 = df_H1N1['SARS-Cov-2 exam result']\n\ndf_Rhino = df5[(df5['Rhinovirus\/Enterovirus']==1) & (df5['regular_blood_tests']==1) & (df5['SARS-Cov-2 exam result']==0)][pcs_vars['regular_blood']+['Patient age quantile', 'SARS-Cov-2 exam result']].dropna()\nX_Rhino = df_Rhino[pcs_vars['regular_blood']+['Patient age quantile']]\ny_Rhino = df_Rhino['SARS-Cov-2 exam result']","be08966c":"dummy_most_freq_clf = DummyClassifier(strategy=\"most_frequent\")\ndummy_most_freq_clf.fit(X_train, y_train)\ny_dummy_most_freq_pred = dummy_most_freq_clf.predict(X_test)\n\nprint(\"Classification report for Dummy 'Most Frequent' Classifier\")\nprint(classification_report(y_test, y_dummy_most_freq_pred))","87f7d470":"dummy_strat_clf = DummyClassifier(strategy=\"stratified\")\ndummy_strat_clf.fit(X_train, y_train)\ny_dummy_strat_pred = dummy_strat_clf.predict(X_test)\n\nprint(\"Classification report for Dummy Stratified Classifier\")\nprint(classification_report(y_test, y_dummy_strat_pred))","f556083d":"parameters = {'kernel':('linear', 'rbf'), \n              'C':[0.1, 1, 10],\n              'class_weight': [{1: 1}, {1: 2}, {1: 5}, {1: 10}, {1: 15}]\n              }\n\nclf = svm.SVC(random_state=42)\ngrid_search = GridSearchCV(clf, parameters, cv=5, scoring='f1_macro')\ngrid_search.fit(X_train, y_train)\n\nprint(\"Best estimator is:\"+str(grid_search.best_params_))\nprint(\"F1-Score (macro avg) on train: \"+\"{0:.2%}\".format(grid_search.best_score_))\n\n\ny_pred = grid_search.best_estimator_.predict(X_test)\n\nprint(\"\\nClassification report for SVM on test\")\nprint(classification_report(y_test, y_pred))","b9eb9802":"parameters = {'n_estimators': [25,50, 100, 150, 200], \n              'max_depth': [3, 5, 10, 15,20,25],\n              'learning_rate': [1, 0.5, 0.25, 0.1, 0.05, 0.01, 0.001]\n              }\nmodel = GradientBoostingClassifier(random_state=42)\ngrid_search = GridSearchCV(model, parameters, cv=5, scoring='f1_macro')\ngrid_search.fit(X_train, y_train)\n\nprint(\"Best estimator is:\"+str(grid_search.best_params_))\nprint(\"F1-Score (macro avg) on train: \"+\"{0:.2%}\".format(grid_search.best_score_))\n\ny_pred = grid_search.best_estimator_.predict(X_test)\n\nprint(\"\\nClassification report for Gradient Boosting Classifier on test\")\nprint(classification_report(y_test, y_pred))","b67a6f34":"pd.DataFrame(grid_search.best_estimator_.feature_importances_,\n             index = X_train.columns, columns=['importance']).sort_values('importance',ascending=False)","91270769":"#Influenza B\ny_pred = grid_search.best_estimator_.predict(X_InfB)\nprint(\"\\n Accuracy of Gradient Boosting Classifier on Influenza B patients: {:.1f}\".format(accuracy_score(y_InfB, y_pred)*100)+\"%\")","d072bd28":"#H1N1\ny_pred = grid_search.best_estimator_.predict(X_H1N1)\nprint(\"\\n Accuracy of Gradient Boosting Classifier on H1N1 patients: {:.1f}\".format(accuracy_score(y_H1N1, y_pred)*100)+\"%\")","7881b9d3":"#Rhinovirus \ny_pred = grid_search.best_estimator_.predict(X_Rhino)\nprint(\"\\n Accuracy of Gradient Boosting Classifier on Rhinovirus patients: {:.1f}\".format(accuracy_score(y_Rhino, y_pred)*100)+\"%\")","673dd573":"parameters = {'n_estimators': [50, 100, 200], \n              'max_depth': [3, 5, 10, 15],\n              'max_features': [0.6, 0.8, 1.0],\n              'class_weight': [{1: 1}, {1: 2}, {1: 5}, {1: 10}, {1: 15}]\n              }\n\nclf = RandomForestClassifier(random_state=42)\ngrid_search = GridSearchCV(clf, parameters, cv=5, scoring='f1_macro')\ngrid_search.fit(X_train, y_train)\n\nprint(\"Best estimator is:\"+str(grid_search.best_params_))\nprint(\"F1-Score (macro avg) on train: \"+\"{0:.2%}\".format(grid_search.best_score_))\n\ny_pred = grid_search.best_estimator_.predict(X_test)\n\nprint(\"\\nClassification report for Random Forest on test\")\nprint(classification_report(y_test, y_pred))","737a92c1":"parameters = {'n_estimators': [5, 10, 20, 30], \n              'base_estimator': [DecisionTreeClassifier(max_depth=1),\n                                 DecisionTreeClassifier(max_depth=3),\n                                 DecisionTreeClassifier(max_depth=1, class_weight=\"balanced\"),\n                                 DecisionTreeClassifier(max_depth=3, class_weight=\"balanced\")],\n              'learning_rate': [0.01, 0.1, 1.0]\n              }\n\nclf = AdaBoostClassifier(random_state=42)\ngrid_search = GridSearchCV(clf, parameters, cv=5, scoring='f1_macro')\ngrid_search.fit(X_train, y_train)\n\nprint(\"Best estimator is:\"+str(grid_search.best_params_))\nprint(\"F1-Score (macro avg) on train: \"+\"{0:.2%}\".format(grid_search.best_score_))\n\ny_pred = grid_search.best_estimator_.predict(X_test)\n\nprint(\"\\nClassification report for AdaBoost on test\")\nprint(classification_report(y_test, y_pred))","e661ab93":"importances = grid_search.best_estimator_.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in grid_search.best_estimator_.estimators_],\n             axis=0)\nindices = np.argsort(importances)[::-1]\n\n# Plot the feature importances of the forest\nplt.figure(figsize=(10,5))\nplt.title(\"Figure 9 - AdaBoost Feature importances\")\nplt.bar(range(X.shape[1]), importances[indices],\n       color=\"r\", align=\"center\")\nplt.xticks(range(X.shape[1]), X_train.columns, rotation='vertical')\nplt.xlim([-1, X.shape[1]])\nplt.show()\n\n# Print the feature ranking\nprint(\"Feature ranking:\")\n\nfor f in range(X.shape[1]):\n    print(\"%d. %s (%f)\" % (f + 1, X_train.columns[f], importances[indices[f]]))\n","b413d23c":"#Influenza B\ny_pred = grid_search.best_estimator_.predict(X_InfB)\nprint(\"\\n Accuracy of Ada Boost Classifier on Influenza B patients: {:.1f}\".format(accuracy_score(y_InfB, y_pred)*100)+\"%\")","5e7b67ae":"#H1N1\ny_pred = grid_search.best_estimator_.predict(X_H1N1)\nprint(\"\\n Accuracy of Ada Boost Classifier on H1N1 patients: {:.1f}\".format(accuracy_score(y_H1N1, y_pred)*100)+\"%\")","bca62acd":"#Rhinovirus \ny_pred = grid_search.best_estimator_.predict(X_Rhino)\nprint(\"\\n Accuracy of Ada Boost Classifier on Rhinovirus patients: {:.1f}\".format(accuracy_score(y_Rhino, y_pred)*100)+\"%\")","3c059655":"selected_vars = ['SARS-Cov-2 exam result', 'unit', 'Patient age quantile'] + pcs_vars['respiratory']\ndf_respiratory = df5[selected_vars].dropna() #Shape: (420, 19)\n\nX = df_respiratory[pcs_vars['respiratory']+['Patient age quantile']]\ny = df_respiratory['SARS-Cov-2 exam result']\nstrat = df_respiratory['SARS-Cov-2 exam result'].astype(str) + df_respiratory['unit'] #stratification\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify=strat, shuffle=True, random_state=42)\n#X_train.shape: (946, 18)\n#X_test.shape: (406, 18)","42a1191c":"dummy_most_freq_clf = DummyClassifier(strategy=\"most_frequent\")\ndummy_most_freq_clf.fit(X_train, y_train)\ny_dummy_most_freq_pred = dummy_most_freq_clf.predict(X_test)\n\nprint(\"Classification report for Dummy 'Most Frequent' Classifier\")\nprint(classification_report(y_test, y_dummy_most_freq_pred))","2c9bbcd1":"dummy_strat_clf = DummyClassifier(strategy=\"stratified\")\ndummy_strat_clf.fit(X_train, y_train)\ny_dummy_strat_pred = dummy_strat_clf.predict(X_test)\n\nprint(\"Classification report for Dummy Stratified Classifier\")\nprint(classification_report(y_test, y_dummy_strat_pred))","83e94674":"parameters = {'kernel':('linear', 'rbf'), \n              'C':[0.1, 1, 10],\n              'class_weight': [{1: 1}, {1: 2}, {1: 5}, {1: 10}, {1: 15}]\n              }\n\nclf = svm.SVC(random_state=42)\ngrid_search = GridSearchCV(clf, parameters, cv=5, scoring='f1_macro')\ngrid_search.fit(X_train, y_train)\n\nprint(\"Best estimator is:\"+str(grid_search.best_params_))\nprint(\"F1-Score (macro avg) on train: \"+\"{0:.2%}\".format(grid_search.best_score_))\n\ny_pred = grid_search.best_estimator_.predict(X_test)\n\nprint(\"\\nClassification report for SVM on test\")\nprint(classification_report(y_test, y_pred))","6ddfc934":"parameters = {'n_estimators': [25,50, 100, 150, 200], \n              'max_depth': [3, 5, 10, 15,20,25],\n              'learning_rate': [1, 0.5, 0.25, 0.1, 0.05, 0.01, 0.001]\n              }\nmodel = GradientBoostingClassifier()\ngrid_search = GridSearchCV(model, parameters, cv=5, scoring='f1_macro')\ngrid_search.fit(X_train, y_train)\n\nprint(\"Best estimator is:\"+str(grid_search.best_params_))\nprint(\"F1-Score (macro avg) on train: \"+\"{0:.2%}\".format(grid_search.best_score_))\n\ny_pred = grid_search.best_estimator_.predict(X_test)\n\nprint(\"\\nClassification report for Gradient Boosting Classifier on test\")\nprint(classification_report(y_test, y_pred))","4cbbd75a":"parameters = {'n_estimators': [50, 100, 200], \n              'max_depth': [3, 5, 10, 15],\n              'max_features': [0.6, 0.8, 1.0],\n              'class_weight': [{1: 1}, {1: 2}, {1: 5}, {1: 10}, {1: 15}]\n              }\n\nclf = RandomForestClassifier(random_state=42)\ngrid_search = GridSearchCV(clf, parameters, cv=5, scoring='f1_macro')\ngrid_search.fit(X_train, y_train)\n\nprint(\"Best estimator is:\"+str(grid_search.best_params_))\nprint(\"F1-Score (macro avg) on train: \"+\"{0:.2%}\".format(grid_search.best_score_))\n\ny_pred = grid_search.best_estimator_.predict(X_test)\n\nprint(\"\\nClassification report for Random Forest on test\")\nprint(classification_report(y_test, y_pred))","59401bfe":"pd.DataFrame(grid_search.best_estimator_.feature_importances_,\n             index = X_train.columns, columns=['importance']).sort_values('importance',ascending=False)","019dcdda":"parameters = {'n_estimators': [5, 10, 20, 30], \n              'base_estimator': [DecisionTreeClassifier(max_depth=1),\n                                 DecisionTreeClassifier(max_depth=3),\n                                 DecisionTreeClassifier(max_depth=1, class_weight=\"balanced\"),\n                                 DecisionTreeClassifier(max_depth=3, class_weight=\"balanced\")],\n              'learning_rate': [0.01, 0.1, 1.0]\n              }\n\nclf = AdaBoostClassifier(random_state=42)\ngrid_search = GridSearchCV(clf, parameters, cv=5, scoring='f1_macro')\ngrid_search.fit(X_train, y_train)\n\nprint(\"Best estimator is:\"+str(grid_search.best_params_))\nprint(\"F1-Score (macro avg) on train: \"+\"{0:.2%}\".format(grid_search.best_score_))\n\ny_pred = grid_search.best_estimator_.predict(X_test)\n\nprint(\"\\nClassification report for Random Forest on test\")\nprint(classification_report(y_test, y_pred))","efbe03a0":"selected_vars = ['SARS-Cov-2 exam result', 'unit', 'Patient age quantile'] + pcs_vars['influenza_rapid']\ndf_influenza = df5[selected_vars].dropna() #Shape: (820, 5)\n\nX = df_influenza[pcs_vars['influenza_rapid']+['Patient age quantile']]\ny = df_influenza['SARS-Cov-2 exam result']\nstrat = df_influenza['SARS-Cov-2 exam result'].astype(str) + df_influenza['unit'] #stratification\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify=strat, shuffle=True, random_state=42)\n#X_train.shape: (574, 3)\n#X_test.shape: (246, 3)","557c8412":"dummy_most_freq_clf = DummyClassifier(strategy=\"most_frequent\")\ndummy_most_freq_clf.fit(X_train, y_train)\ny_dummy_most_freq_pred = dummy_most_freq_clf.predict(X_test)\n\nprint(\"Classification report for Dummy 'Most Frequent' Classifier\")\nprint(classification_report(y_test, y_dummy_most_freq_pred))","a3d63743":"dummy_strat_clf = DummyClassifier(strategy=\"stratified\")\ndummy_strat_clf.fit(X_train, y_train)\ny_dummy_strat_pred = dummy_strat_clf.predict(X_test)\n\nprint(\"Classification report for Dummy Stratified Classifier\")\nprint(classification_report(y_test, y_dummy_strat_pred))","28d81a9f":"parameters = {'kernel':('linear', 'rbf'), \n              'C':[0.01, 0.1, 1, 10],\n              'class_weight': [{1: 1}, {1: 2}, {1: 5}, {1: 10}, {1: 15}]\n              }\n\nclf = svm.SVC(random_state=42)\ngrid_search = GridSearchCV(clf, parameters, cv=5, scoring='f1_macro')\ngrid_search.fit(X_train, y_train)\n\nprint(\"Best estimator is:\"+str(grid_search.best_params_))\nprint(\"F1-Score (macro avg) on train: \"+\"{0:.2%}\".format(grid_search.best_score_))\n\ny_pred = grid_search.best_estimator_.predict(X_test)\n\nprint(\"\\nClassification report for SVM on test\")\nprint(classification_report(y_test, y_pred))","543afd0b":"parameters = {'n_estimators': [25,50, 100, 150, 200], \n              'max_depth': [3, 5, 10, 15,20,25],\n              'learning_rate': [1, 0.5, 0.25, 0.1, 0.05, 0.01, 0.001]\n              }\nmodel = GradientBoostingClassifier()\ngrid_search = GridSearchCV(model, parameters, cv=5, scoring='f1_macro')\ngrid_search.fit(X_train, y_train)\n\nprint(\"Best estimator is:\"+str(grid_search.best_params_))\nprint(\"F1-Score (macro avg) on train: \"+\"{0:.2%}\".format(grid_search.best_score_))\n\ny_pred = grid_search.best_estimator_.predict(X_test)\n\nprint(\"\\nClassification report for Gradient Boosting Classifier on test\")\nprint(classification_report(y_test, y_pred))","a0b57d41":"parameters = {'n_estimators': [50, 100, 200], \n              'max_depth': [3, 5, 10, 15],\n              'max_features': [0.6, 0.8, 1.0],\n              'class_weight': [{1: 1}, {1: 2}, {1: 5}, {1: 10}, {1: 15}]\n              }\n\nclf = RandomForestClassifier(random_state=42)\ngrid_search = GridSearchCV(clf, parameters, cv=5, scoring='f1_macro')\ngrid_search.fit(X_train, y_train)\n\nprint(\"Best estimator is:\"+str(grid_search.best_params_))\nprint(\"F1-Score (macro avg) on train: \"+\"{0:.2%}\".format(grid_search.best_score_))\n\ny_pred = grid_search.best_estimator_.predict(X_test)\n\nprint(\"\\nClassification report for Random Forest on test\")\nprint(classification_report(y_test, y_pred))","1ddcb2c7":"parameters = {'n_estimators': [5, 10, 20, 30], \n              'base_estimator': [DecisionTreeClassifier(max_depth=1),\n                                 DecisionTreeClassifier(max_depth=3),\n                                 DecisionTreeClassifier(max_depth=1, class_weight=\"balanced\"),\n                                 DecisionTreeClassifier(max_depth=3, class_weight=\"balanced\")],\n              'learning_rate': [0.01, 0.1, 1.0]\n              }\n\nclf = AdaBoostClassifier(random_state=42)\ngrid_search = GridSearchCV(clf, parameters, cv=5, scoring='f1_macro')\ngrid_search.fit(X_train, y_train)\n\nprint(\"Best estimator is:\"+str(grid_search.best_params_))\nprint(\"F1-Score (macro avg) on train: \"+\"{0:.2%}\".format(grid_search.best_score_))\n\ny_pred = grid_search.best_estimator_.predict(X_test)\n\nprint(\"\\nClassification report for Random Forest on test\")\nprint(classification_report(y_test, y_pred))","f1333f5f":"from IPython.display import HTML\n\nHTML('<iframe width=\"560\" height=\"315\" src=\"https:\/\/www.youtube.com\/embed\/gxAaO2rsdIs\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen><\/iframe>')","af86e9bb":"#### Gradient Boosting Classifier\n","98f091dd":"Coocurence matrix for test on UCI patients:","a3319689":"We merged PCs 3 and 4. We also created a group containing the influenza rapid tests (these exams are not present in the PC analysis because don't co-occur with others, but are relatively commom in the dataset.\n\nNotice that 22 tests were not included in the 6 major groups proposed . On Figure 5 we plot the frequency of these exams. They are usually very low frequency tests. ","08a53cbc":"#### Baseline: Dummy classifiers\n\nSince this dataset is imbalanced, dummy classifiers get high accuracy, but low F1-Score (**0.87** and **0.46**, respectively).","163bb72e":"#### SVM","1c073c48":"Coocurence matrix for test on semi-intensive patients:","d5f1ac10":"Coocurence matrix for test on COVID negative patients:","4506e387":"Gradient Boosting discussion uses the table below:","c45fcb93":"##### Backtest against H1N1","70b68f6a":"Some models do not accept null values. Inputation in the medical context is hard and must consider demographic characteristics (like gender, race, etc.) that are not provided in the dataset. **The result above can be helpful to fit partial models on chunks of exams available (since we observed that some of them occur together).**\n\n","605a8a86":"##### Backtest against Rhinovirus","96b29099":"## Prediction of confirmed COVID19","1d9a286b":"Coocurence matrix for test on regular ward patients:","745d083b":"##### Backtest against Influenza B","5ccc2c3b":"#### AdaBoost (on Decision Trees)","b0a8f8ad":"#### Random Forest","3c43e290":"## Data prep\n","31cc6218":"## Refer\u00eancias\n\n1. Milton Ossamu Tanizaka. **Exploratory Data Analysis and Feature Importance.** Kernel on Kaggle. Available at: https:\/\/www.kaggle.com\/ossamum\/exploratory-data-analysis-and-feature-importance\n2. Nasser Boan. **null_values_exploration + logreg**. Kernel on Kaggle. Available at: https:\/\/www.kaggle.com\/nazeboan\/null-values-exploration-logreg-67-acc\n3. Blann A. **Routine blood tests 1: why do we test for urea and electrolytes?** Nursing Times; 110: 5, 19-21. 2014. Available at: https:\/\/www.nursingtimes.net\/clinical-archive\/assessment-skills\/why-do-we-test-for-urea-and-electrolytes-24-01-2014\/\n4. Andrew Gonzalez, MD. **Red Cell Distribution Width (RDW) Test**. Healthline. Available at: https:\/\/www.healthline.com\/health\/rdw-blood-test\n5. Nardocci Paula, Gullo Caio Eduardo, Lobo Suzana Margareth. **Severe virus influenza A H1N1 related pneumonia and community-acquired pneumonia: differences in the evolution.** Rev. bras. ter. intensiva  [Internet]. 2013  June;  25( 2 ): 123-129. Available from: http:\/\/www.scielo.br\/scielo.php?script=sci_arttext&pid=S0103-507X2013000200010&lng=en.  https:\/\/doi.org\/10.5935\/0103-507X.20130023.\n6. J. Matthew Velkey. **Cell Injury, Death, Inflammation, and Repair**. Lecture notes. Duke University. Available at: https:\/\/slideplayer.com\/slide\/4382692\/\n","e285741d":"#### Gradient Boosting Classifier\n","cb27030f":"We also performed an analysis on the co-occurences of the aforementioned groups of tests by COVID status (positive or negative) and admission unit (ICU, etc.). Below we present the data. The values are on percentage of total records of the subset of patients. We've found that infected patients have done slightly more non-respiratory tests then COVID negative people. Comparing admission units, admitted patients underwent significantly more exams then elective ones.","a0f2399b":"## Acknowledgment\n\nWe would like to thanks the team from Einstein Data4u for the competition and selection of our work as relevant to the theme. We also thanks SIG Ci\u00eancia de Dados & Intelig\u00eancia Artificial em Sa\u00fade (CIDIAS) for the opportunity to present our work to a medical audience.","41a64969":"##### Backtest against Rhinovirus","38b215e7":"## Introduction\n\nWe analyse feature bias through severity of cases. 6 groups of tests were found using Principal Components Analysis. 3 of them are: Regular blood test, respiratory virus and bacterial tests and Influenza rapid tests). For these we fit models and compare the ones that favors precision and recall through a clinical perspective. Regular blood tests were found to be the most useful to detect coronavirus. We also backtest our best models agains patients infected with H1N1, Rhinovirus and Influenza B and found that our models capture SARS-CoV-2 patterns different than these flus.\n\nOur work is organized as follows:\n\n1. Data prep\n  1. Import and preparation\n  1. EDA\n1. Modelling strategy\n1. Prediction of confirmed COVID19\n  1. Regular blood Tests\n    1. Baseline\n    1. SVM\n    1. Gradient Boosting Classifier\n        1. Backtest against Influenza B\n        1. Backtest against H1N1\n        1. Backtest against Rhinovirus\n    1. Random Forest\n    1. AdaBoost (on Decision Trees)\n        1. Backtest against Influenza B\n        1. Backtest against H1N1\n        1. Backtest against Rhinovirus\n  1. Respiratory virus and bacteria Tests\n    1. Baseline\n    1. SVM\n    1. Gradient Boosting Classifier\n    1. Random Forest\n    1. AdaBoost (on Decision Trees)\n  1. Influenza \n    1. Baseline\n    1. SVM\n    1. Gradient Boosting Classifier\n    1. Random Forest\n    1. AdaBoost (on Decision Trees)\n1. Discussion of results\n1. Acknowledgment","36cb1d22":"# Taskforce to help diagnose COVID19\nKaggle competition: https:\/\/www.kaggle.com\/dataset\/e626783d4672f182e7870b1bbe75fae66bdfb232289da0a61f08c2ceb01cab01\/data\nTeam members:\n* [Jairo da Silva Freitas J\u00fanior](https:\/\/www.linkedin.com\/in\/jairofreitas), Computer Scientist from Federal University of ABC (Brazil) and data analytst at Ita\u00fa Unibanco (Fortune 500, NYSE and B3: ITUB)\n* [Christian Espinoza](https:\/\/www.linkedin.com\/in\/christianespinoz), Computer Scientist from University of S\u00e3o Caetano do Sul  (Brazil) and improver data analyst at Hospital Israelita Albert Einstein.","f9d741bc":"### EDA","834cf82e":"#### Baseline: Dummy classifiers\n\nSince this dataset is imbalanced, dummy classifiers get high accuracy, but low F1-Score (**0.92** and **0.48**, respectively).","37ed6d57":"#### AdaBoost (on Decision Trees)","8fc7ba17":"## Final thoughts on results","9f773885":"#### Gradient Boosting Classifier\n","5d4539ce":"#### Random Forest","5a951b45":"#### AdaBoost (on Decision Trees)","91c33eb4":"Given the high dispersion of patients undergoing each test, we also analysed the null values in the dataset. Figure 2 is based on Nasser Boan's kernel [2]. Unfortunately, he didn't report the interpretation of the pattern in the data, so we will do it by performing dimensionality reduction on the presence (or absence) of exams. For that we used the standart implementation of PCA from Scikit-learn.","c81626c3":"#### SVM","058961ce":"### Regular blood Tests\n\nThis group of tests is composed of the patient age quantile and 16 common blood tests. \nThe tests can be splitted into two categories:\n* Red blood cells (RBCs): Tests on concentration and morphology of cells responsible to transport oxygen in the blood.\n* * Red blood cells\n* * Hemoglobin\n* * Hematocrit\n* * Red blood cell distribution width (RDW)\n* * Mean corpuscular hemoglobin (MCH)\n* * Mean corpuscular volume (MCV)\n* * Mean corpuscular hemoglobin concentration\n* White blood cells (WBCs): Cells responsible for immunulogic body process (such as fighting a disease and stanching a wound).\n* * Leukocytes\n* * Lymphocytes\n* * Basophils\n* * Eosinophils\n* * Neutrophils\n* * Platelets\n* * Monocytes\n* * Mean platelet volume\n* * C Reactive Protein\n\nAll models tested greatly improved over the baseline, based on F1-Scores measures. We've found that the AdaBoost metalearning model over Decision Trees had the best recall on the positive COVID cases (82%) and a decent precision (42%). On the other hand, Gradient Boosting Classifier got the best precision on the COVID cases (57%) and a reasonable recall (49%). We also tested penalizing more the errors on the minority classes with Random Forest and SVM.\n\nThe Gradient Boosting most important features were  Leukocytes, \nMonocytes, Platelets, C reactive protein mg\/dL and Red blood cell distribution width (RDW). The first four features usually present abnorbal values when the body passing through an immunological process. The last one represents the variation in volume of the red blood cells and usually indicate other underlying conditions [4].\n\nTh AdaBoost most important features are C reactive protein, Neutrophils, Mean platelet volume, monocytes and Red blood cell distribution width (RDW). Medical expertise is needed to fully interpret this data. Our hypothesis is that:\n\n* Gradient Boosting give more importance to clearer signs of infection severity (leukocytes).\n\n* On the other hand, AdaBoost recall is higher because it's more sensitive to elements that show up early in an infection process (C reactive protein[5] and neutrophils[6]). Figure 6 illustrate the usual infection kinectics with respect to some white blood cells.\n\n<table>\n    <tr><center>Figure 7 -  Infection kinetics and white blood cells<\/center><\/tr>\n    <tr><td><center>(a) General [6]<\/center><\/td><td><center>(b) C Reactive Protein [5]<\/center><\/td><\/tr>\n    <tr>\n        <td>\n            <img src=\"https:\/\/slideplayer.com\/slide\/4382692\/14\/images\/84\/Sequence+of+Events+-+Infection.jpg\" alt=\"drawing\" width=\"400\"\/>\n        <\/td>\n        <td>\n            <img src=\"http:\/\/www.scielo.br\/img\/revistas\/rbti\/v25n2\/en_a10fig01.jpg\" alt=\"drawing\" width=\"400\"\/>\n        <\/td>\n    <\/tr>\n<\/table>\n\nWe've also found that the AdaBoost model have high accuracy on H1N1 (80%) and Rhinovirus (94%) patients, but low accuracy on Influenza B ones (54%). In contrast, Gradient Boost have high accuracy on all tests (the lowest performance on H1N1 with 93%). These result u","37b4bb25":"#### SVM","d7e3bf81":"### Influenza Rapid Tests\n\nThe influenza rapid tests group is composed of 2 tests (A and B Influenza rapid tests) and the patient age quantile. It has 820 samples. **The models fitted to it marginally outperformed the baseline**. Testing positive or not apparently doesn't help on diagnosing coronavirus.","88da8658":"From Figure 3 we observe that after the 6th component the variance explained grows very slowly. On Figure 4 we plot the most important features of the first 6 principal components (variance explained by these PCs: 94%). Later we interpret these PCs.","35d7ebca":"### Import","772ceee0":"We performed categorical to numerical conversion and removed  tests that were not tested on infected patients. Both data preparations are inspired by Ossamu's[1] EDA of this dataset. Different from him, we considered wordings like \"not_done\" and \"N\u00e3o Realizado\" as missing for further analysis of missing values. We also treated \"Ausentes\" as 0 and any other kind of crystal as 1 on \"Urine - Crystals\", because we believe that this is more intuitive for interpretation.","912108e9":"#### Random Forest","79d23622":"Coocurence matrix for test on elective patients:","de472db6":"##### Backtest against H1N1","b289a3c5":"## Modelling strategy","4d9bd5c6":"The Gradient Boosting Classifier is the best alternative we've got for high precision needs. We believe though that recall is preferred over precision given the efficacy of putting infected people in isolation.\n\nWe identified some possible bias in the data that must be taking into account when modelling it, specially that some tests are performed mostly on severe cases. We also were capable of spliting the dataset into 6 groups of frequently co-occuring medical exams in a unsupervised manner, which allowed for greater samples on training (less dropping of records due to null values). \n\nWe also showed that the blood tests are the only relevant exams found to greatly outperform a dummy baseline in predicting coranavirus. The unbalanaced nature of the data was explored and taken into account when evaluating the model performances. The accuracy of the models were tested against patients with 3 diseases which have similar symptoms to COVID-19 and the results suggested that they can differentiate SARS-CoV-2 from H1N1, Rhinovirus and Influenza B.\n\nFinally, **AdaBoost is our model of choice for isolation of suspicious cases**, since it  has a very high recall. As exemplified by the video below by Grant Sanderson, adopting strategies to quickly isolate vectors of a disease is the most effective (non-pharmacological) strategy.","d4f2061f":"### Respiratory virus and bacteria Tests\n\nThis group of tests is composed of the patient age quantile and 17 tests on common virus and bacterias that affect the respiratory system, such as H1N1 and influenza. **The models fitted to this subset of tests barely outperformed the baseline.** One curious case was the Random Forest algorithm that reached a 65% F1-Score on test, but greatly deviated from validation results (55%), so we invalidated the model. Investigatint the feature importances of this random forest we've found that 48% of the model was explained by patient age, which is far from reasonable.","cf51a1fb":"The interpretation of the first six principal components are:\n1. Respiratory viruses test (e.g.: Influenza, Rhinovirus)\n2. Regular blood test (red and white cells)\n3. Billirubin, enzymes, electrolytes<sup>1<\/sup> and gaseous analysis\n4. Same interpretation of 3 (medical expertise would help)\n5. Urine\n6. Unusual Bone marrow cells circulating in blood and segmented parts\n\n<sup>1<\/sup> We found Blann article on Nursing Times [3] useful to feel comfortable deciding to allocate electrolytes on PC 3 other than 2 (which is in accordance to the data).","85c1dc59":"The exploratory analysis indicated that:\n1. Most of the dataset is missing values\n2. It has 6 groups of tests (each group contains medical exams that usually occur together)\n3. The occurence of each group of tests and the co-occurrence between them is highly dependent on the severity of the case (especially admitted versus non-admitted patients).\n\nThis said, we have chosen to create models for each group of tests in order to prevent bias toward severe cases and data imputation. \n\n**Evaluation metrics**\n\nWe evaluated all of our models using F1-Score (the harmonic mean of precision and recall), given that the dataset is very unbalanced. The accuracy is also reported since it's more intuitive to a new entrant in data science. All results are compared against a dummy classifier.\n\n**Training, validation and test datasets**\n\nOnce selected the patients that underwent a group of tests, we split the dataset in training (70%) and test (30%). We stratified the sets by SARS Cov2 exam result and admission type\/unit. We use 5-fold cross validation on training.\n\n**Backtest agains H1N1, Rhinovirus and Influenza B**\n\nWe selected SARS-CoV-2 negative patients diagnosed with H1N1, Rhinovirus and Influenza B to backtest our best performing models agains other diseases with similar symptoms.\n","4ba11499":"##### Backtest against Influenza B","f6d91737":"#### Baseline: Dummy classifiers\n\nSince this dataset is imbalanced, dummy classifiers get high accuracy, but low F1-Score (**0.92** and **0.48**, respectively).","87f528e1":"The plot below is used in the discussion of AdaBoost results.","5cf477c3":"**We selected some patients diagnosed with other flus to backtest our models**. The question we want to answer is: Are we actually detecting a SARS-CoV-2 pattern or just a commom infectious process related to other diseases with similar symptoms? Figure 8 presents the quantity of patients without SARS-CoV-2 but diagnosed with 1 or more respiratory diseases.","b00934de":"We reordered Figure 2 rows and columns by the groups of exams. The result is shown in Figure 6. The aggregation of white points in the image illustrates the final result of PCA. Now we notice that most of the patients didn't underwent tests other then for COVID in the sample.","51f50ed9":"The discussion on this result uses the feature importance table below.","d37799df":"Coocurence matrix for test on COVID positive patients:","7a93260d":"We first analyze the frequency of each test in the dataset. The first plot in the figure below illustrate it (Figure 1 (a)). There's a high dispersion in the quantity of patients undergoing each test. So we investigated (Figure 1 (b)) the representativeness of patient admission unit for each medical exam. Usually, rarest tests are related to increased complexity of the medical facility. Also, we found on Figure 1 (c) that rarer tests are related to higher probability of the patient having coronavirus."}}