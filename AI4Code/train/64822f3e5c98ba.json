{"cell_type":{"c7e66c5e":"code","c66e50f9":"code","7596d930":"code","a5fdaba8":"code","89a66c02":"code","baee773d":"code","6d433f83":"code","3dac3876":"code","9b409a5a":"code","006f26e9":"code","a70cc759":"code","3efced9c":"code","4377c319":"code","b8d9e19d":"code","9d8f9294":"code","ee5500ba":"code","1deb4002":"code","c625eb47":"code","ea7fcea9":"code","356af6cb":"code","3274b99c":"code","7e2c8b36":"code","bdd3e441":"code","f1683837":"code","89beca11":"code","02ae147c":"code","785b7c31":"code","643c886e":"code","2afb1123":"code","5c2b5908":"code","3ed80a4b":"code","20fe4f3e":"markdown","5eb1f6dd":"markdown","d78cc92e":"markdown","df7be383":"markdown","eaab3123":"markdown","d6e9e30d":"markdown"},"source":{"c7e66c5e":"import os\nprint(os.listdir(\"..\/input\"))\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\n% matplotlib inline\nfrom PIL import Image\nimport cv2\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nimport random as rnd\nimport math","c66e50f9":"IMG_WIDTH = 32\nIMG_HEIGHT = 32\nIMG_CHANNELS = 1\nTRAIN_SIZE = 4000 \nTRAIN_PATH = '..\/input\/trainset\/'\nTEST_PATH = '..\/input\/testset\/'\nROI_PATH = \"..\/input\/roi\/\"","7596d930":"# Create useful helpers\n\ndef get_centers(dir_roi, resol=(2048, 2048)):\n    ''' This function scans through the directory of the ROI files, reads the\n        coordinates (in pixel) of the centers of all circular ROIs, then\n        transforms them into relative coordinates (assumming image size 1x1) '''  \n\n    img_id = []\n    cx_pxl = []\n    cy_pxl = []\n\n    HEIGHT, WIDTH = resol\n    \n    # Get center coordinates of all sample images\n    for dirpath, dirnames, files in os.walk(dir_roi):\n        sample_id = os.path.split(dirpath)[1].split('.')[0]\n        for file in files:\n            img_id.append(sample_id + file[:4])\n            cx_pxl.append(int(file[10:14]))\n            cy_pxl.append(int(file[5:9]))\n\n    df_roi = pd.DataFrame({'img_id': img_id,\n                           'cx_pxl': cx_pxl,\n                           'cy_pxl': cy_pxl},\n                           columns = ['img_id', 'cx_pxl', 'cy_pxl'])\n    df_roi['cx'] = df_roi.cx_pxl \/ float(WIDTH)\n    df_roi['cy'] = df_roi.cy_pxl \/ float(HEIGHT)\n            \n    return df_roi\n\n\ndef coord_transfm(df_roi_org, shifts=(359, 359), cropped_resol=(1330, 1330)):\n    shift_x, shift_y = shifts\n    HEIGHT, WIDTH = cropped_resol\n    df_roi = df_roi_org.copy()\n    df_roi.cx_pxl = df_roi.cx_pxl - shift_x\n    df_roi.cy_pxl = df_roi.cy_pxl - shift_y\n    df_roi.cx = df_roi.cx_pxl \/ float(WIDTH)\n    df_roi.cy = df_roi.cy_pxl \/ float(HEIGHT)\n    \n    return df_roi \n\n\ndef draw_roi(img_path, img_list, true_centers, pred_centers=None, \n             actual_R=1.5, actual_imgsize=16.38, current_resol=1330, \n             org_resol=2048, rows=1, cols=3, model_name=\"Model\"):\n    \n    resize_ratio = current_resol \/ org_resol\n    R = math.floor(current_resol * actual_R\/(actual_imgsize*resize_ratio))\n    \n    plt.figure(figsize=(8*cols, 8*rows))\n    \n    for i, img_id in enumerate(img_list):\n        plt.subplot(rows, cols, i+1)\n        img = cv2.imread(TRAIN_PATH + img_id + '.png')\n        cx = math.floor(true_centers[i, 0] * current_resol)\n        cy = math.floor(true_centers[i, 1] * current_resol)        \n        \n        if pred_centers is not None:\n            cx_pred = math.floor(pred_centers[i, 0] * current_resol) \n            cy_pred = math.floor(pred_centers[i, 1] * current_resol)\n            img_mod = cv2.circle(img, (cx_pred, cy_pred), R, (0,0,255), 3)  # Mark the predicted center in blue\n            img_mod = cv2.circle(img_mod, (cx_pred, cy_pred), round(R*0.05), (0,0,255), -1)  \n            img_mod = cv2.circle(img_mod, (cx, cy), R, (255,0,0), 2)  # Mark the true center in red\n            img_mod = cv2.circle(img_mod, (cx, cy), round(R*0.05), (255,0,0), -1)  \n\n        else:\n            img_mod = cv2.circle(img, (cx, cy), R, (255,0,0), 3)  # Mark the true center in red\n            img_mod = cv2.circle(img_mod, (cx, cy), round(R*0.05), (255,0,0), -1)  \n\n        plt.imshow(img_mod)\n    \n        if pred_centers is not None:\n            plt.title(\"Vitamin D Deficiency Point  \\n\" + model_name + \": {}\\nHuman: {}\"\n                      .format(str((cx_pred, cy_pred)),\n                              str((cx, cy))))\n        else:\n            plt.title(\"Vitamin D Deficiency Point: {}\".format(str((cx, cy))))   \n            \n\ndef mirror(df_imgs, flip_axis, img_height=IMG_HEIGHT, img_width=IMG_WIDTH):\n    \n    pxl_cols = [col for col in df_imgs.columns if 'pxl' in col]\n    num_imgs = df_imgs.shape[0]\n    img_size = IMG_HEIGHT * IMG_WIDTH\n    \n    mat_images = df_imgs[pxl_cols].values\n    mat_images = mat_images.reshape((num_imgs, IMG_HEIGHT, IMG_WIDTH))\n    df_imgs_flip = df_imgs.copy()\n    \n    assert 'h' in flip_axis or 'v' in flip_axis, \\\n           \"Flipping axis is not defined. Must be either 'horizontal' or 'vertical'.\"\n    \n    if 'h' in flip_axis:\n        flipping = 1\n        df_imgs_flip.img_id = df_imgs.img_id + 'hf'\n        df_imgs_flip.cy = 1.0 - df_imgs.cy  \n    elif 'v' in flip_axis:\n        flipping = 2\n        df_imgs_flip.img_id = df_imgs.img_id + 'vf'\n        df_imgs_flip.cx = 1.0 - df_imgs.cx    \n    \n    # Flip images around the specified axis    \n    mat_images_flip = np.flip(mat_images, flipping) \\\n                        .reshape((num_imgs, img_size))\n    df_imgs_flip[pxl_cols] = mat_images_flip\n    \n    return df_imgs_flip","a5fdaba8":"df_centers_org = get_centers(ROI_PATH).sort_values(by='img_id') \\\n                                     .reset_index(drop=True)\nprint(df_centers_org.head())\ndf_centers = coord_transfm(df_centers_org)\nprint(df_centers.head())","89a66c02":"images = pd.Series(sorted(os.listdir(TRAIN_PATH)))\nimg_ids = images.str.split('.').str[0]\nassert df_centers.img_id.equals(img_ids), \"Image lists don't match\"","baee773d":"\nimg_size = IMG_HEIGHT * IMG_WIDTH\nmat_images = np.zeros((TRAIN_SIZE, img_size))\ntrain_images = images.sample(TRAIN_SIZE, random_state=10)\ntrain_img_ids = train_images.str.split('.').str[0]\ndf_train = pd.DataFrame(mat_images, \n                        columns=['pxl' + str(i) for i in range(img_size)])\ndf_train.insert(0, 'img_id', train_img_ids.values)\ndf_train = pd.merge(df_train, df_centers[['img_id', 'cx', 'cy']], \n                    on='img_id', validate=\"1:1\")\nprint(df_train.head())\nprint(df_train.shape)","6d433f83":"df_train_hflip = mirror(df_train, 'h')\ndf_train_vflip = mirror(df_train, 'v')","3dac3876":"df_train = pd.concat([df_train, df_train_hflip, df_train_vflip],\n                     ignore_index=True)\nprint(\"New dataframe's shape: {}\".format(df_train.shape))\ndf_centers = df_train[['img_id', 'cx', 'cy']]","9b409a5a":"X = df_train.drop(columns=['img_id', 'cx', 'cy']) \\\n            .values.reshape((-1, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\nY = df_train[['cx', 'cy']].values\nIDs = df_train.img_id.values\nX \/= 255.0","006f26e9":"# Free RAM space\ndel df_train, df_train_hflip, df_train_vflip, mat_images","a70cc759":"from sklearn.model_selection import train_test_split\nX_train, X_val, Y_train, Y_val, IDs_train, IDs_val = train_test_split(X, Y, IDs, test_size=0.05, random_state=1)\nprint(\"Trainset shape: {}\".format(X_train.shape))\nprint(\"Validateset shape: {}\".format(X_val.shape))","3efced9c":"import math \nimport cv2\nselect_disp = df_centers.iloc[:TRAIN_SIZE].sample(n=3)\nimg_list = select_disp['img_id'].values\ntrue_centers = select_disp[['cx', 'cy']].values\ndraw_roi(TRAIN_PATH, img_list, true_centers)","4377c319":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\ncnn_model = Sequential()\n\ncnn_model.add(Conv2D(filters = 32, kernel_size = (5,5), \n                     padding = 'Same', activation ='relu', \n                     input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)))\n\ncnn_model.add(Conv2D(filters = 32, kernel_size = (5,5),\n                     padding = 'Same', activation ='relu'))\n\ncnn_model.add(MaxPool2D(pool_size=(2,2)))\n# cnn_model.add(Dropout(0.25))\n\ncnn_model.add(Conv2D(filters = 64, kernel_size = (3,3),\n                 padding = 'Same', activation ='relu'))\n\ncnn_model.add(Conv2D(filters = 64, kernel_size = (3,3),\n                     padding = 'Same', activation ='relu'))\n\ncnn_model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n# cnn_model.add(Dropout(0.25))\n\ncnn_model.add(Flatten())\ncnn_model.add(Dense(512, activation = \"relu\"))\ncnn_model.add(Dense(64, activation = \"relu\"))\n# cnn_model.add(Dropout(0.25))\ncnn_model.add(Dense(2))\n\ncnn_model.summary()","b8d9e19d":"def mean_dist(y_pred, y_true):\n    d = y_pred - y_true\n    return tf.reduce_mean(tf.norm(d, axis=1))","9d8f9294":"import tensorflow as tf\ncnn_model.compile(loss=mean_dist, optimizer='adam')\ncnn_model.fit(X_train, Y_train, batch_size=64, epochs=8)","ee5500ba":"cnn_scores_train = cnn_model.evaluate(X_train, Y_train)\nprint(\"Score on trainset: {}\".format(cnn_scores_train))\ncnn_scores_val = cnn_model.evaluate(X_val, Y_val)\nprint(\"Score on validate set: {}\".format(cnn_scores_val))","1deb4002":"cnn_pred = cnn_model.predict(X_val, verbose=True)\ncnn_results = pd.DataFrame(np.concatenate([cnn_pred, Y_val], axis=1), \n                          columns = ['cx_pred', 'cy_pred', 'cx', 'cy'])\ncnn_results.insert(0, 'img_id', IDs_val)\nprint(cnn_results.head())","c625eb47":"orig = [img_id for img_id in cnn_results.img_id \n        if 'f' not in img_id]\norig_imgs = cnn_results[cnn_results.img_id.isin(orig)]\nselt_imgs = orig_imgs.sample(n=6)\nimg_list = selt_imgs['img_id'].values\ntrue_centers = selt_imgs[['cx', 'cy']].values\npred_centers = selt_imgs[['cx_pred', 'cy_pred']].values\n\ndraw_roi(TRAIN_PATH, img_list, true_centers, \n         pred_centers, rows=2, cols=3, model_name=\"Simple CNN\")","ea7fcea9":"selt_dots = orig_imgs.sample(n=20)\nimg_list = selt_dots['img_id'].values\ntrue_centers = (selt_dots[['cx', 'cy']].values * 1330).astype(int)\npred_centers = (selt_dots[['cx_pred', 'cy_pred']].values * 1330).astype(int)\n\nplt.figure(figsize = (5, 5))\nplt.scatter(true_centers[:, 0], true_centers[:, 1], c='r', alpha=0.5, label='Human')\nplt.scatter(pred_centers[:, 0], pred_centers[:, 1], c='b', alpha=0.5, label='CNN model')\nplt.axis('equal')\nplt.legend()\nplt.title(\"20 Random Selected Images of Bones\")\nplt.show() ","356af6cb":"cnn_results.to_csv(\"CNN1.csv\")","3274b99c":"from keras import layers\nfrom keras.layers import Input, Add, Activation, ZeroPadding2D, BatchNormalization, \\\n                         AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\nfrom keras.models import Model\nfrom keras.initializers import glorot_uniform","7e2c8b36":"def identity_block(X, f, filters, stage, block):\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    F1, F2, F3 = filters\n    X_shortcut = X\n    X = Conv2D(filters = F1, kernel_size = (1,1), strides = (1,1), \n               padding = 'valid', name = conv_name_base + '2a', \n               kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n    X = Conv2D(filters = F2, kernel_size = (f,f), strides = (1,1),\n               padding = 'same', name = conv_name_base + '2b',\n               kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name = bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n    X = Conv2D(filters = F3, kernel_size = (1,1), strides = (1,1), \n               padding = 'valid', name = conv_name_base + '2c', \n               kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name = bn_name_base + '2c')(X)\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n    return X","bdd3e441":"def convolutional_block(X, f, filters, stage, block, s=2):\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    F1, F2, F3 = filters\n    X_shortcut = X\n    X = Conv2D(F1, (1,1), strides = (s,s), name = conv_name_base + '2a',\n               padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n    X = Conv2D(F2, (f,f), strides = (1,1), name = conv_name_base + '2b',\n               padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n    X = Conv2D(F3, (1,1), strides = (1,1), name = conv_name_base + '2c',\n               padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X) \n    X_shortcut = Conv2D(F3, (1,1), strides = (s,s), padding = 'valid',\n                        name = conv_name_base + '1',\n                        kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n    return X","f1683837":"def ResNet50(input_shape):\n    X_input = Input(input_shape)\n    X = ZeroPadding2D((1, 1))(X_input) # mod (3,3) -> (1,1)\n    X = Conv2D(64, (3, 3), strides=(1, 1), name='conv1', # mod (7,7) -> (3,3); (2,2) -> (1,1)\n               kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n    X = convolutional_block(X, f=3, filters=[64, 64, 256], \n                            stage=2, block='a', s=1)\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n    X = convolutional_block(X, f=3, filters=[128,128,512],\n                            stage=3, block='a', s=2) \n    X = identity_block(X, f=3, filters=[128,128,512], stage=3, block='b')\n    X = identity_block(X, f=3, filters=[128,128,512], stage=3, block='c')\n    X = identity_block(X, f=3, filters=[128,128,512], stage=3, block='d')\n    X = convolutional_block(X, f=3, filters=[256,256,1024],\n                            stage=4, block='a', s=2) \n    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block='b')\n    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block='c')\n    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block='d')\n    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block='e')\n    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block='f')\n    X = convolutional_block(X, f=3, filters=[512,512,2048],\n                            stage=5, block='a', s=2) \n    X = identity_block(X, f=3, filters=[512,512,2048], stage=5, block='b')\n    X = identity_block(X, f=3, filters=[512,512,2048], stage=5, block='c')\n    X = AveragePooling2D((2,2), name='avg_pool')(X)\n    X = Flatten()(X)\n    # X = Dense(1024, name='fc_1024', kernel_initializer=glorot_uniform(seed=0))(X)  # add an extra dense layer\n    # X = Dense(64, name='fc_64', kernel_initializer=glorot_uniform(seed=0))(X)  # add an extra dense layer\n    X = Dense(2, name='fc_outputs', kernel_initializer=glorot_uniform(seed=0))(X)\n    model = Model(inputs = X_input, outputs = X, name = 'Conv2')\n    return model","89beca11":"ResNet_model = ResNet50(input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\nResNet_model.summary()","02ae147c":"ResNet_model.compile(loss=mean_dist, optimizer='adam')\nResNet_model.fit(X_train, Y_train, batch_size=128, epochs=15)","785b7c31":"ResNet_scores_train = ResNet_model.evaluate(X_train, Y_train, batch_size=128)\nprint(\"Score on trainset: {}\".format(ResNet_scores_train))\nResNet_scores_val = ResNet_model.evaluate(X_val, Y_val)\nprint(\"Score on validate set: {}\".format(ResNet_scores_val))","643c886e":"ResNet_pred = ResNet_model.predict(X_val, verbose=True)\nResNet_results = pd.DataFrame(np.concatenate([ResNet_pred, Y_val], axis=1), \n                              columns = ['cx_pred', 'cy_pred', 'cx', 'cy'])\nResNet_results.insert(0, 'img_id', IDs_val)\nprint(ResNet_results.head())","2afb1123":"orig = [img_id for img_id in ResNet_results.img_id \n        if 'f' not in img_id]\norig_imgs = ResNet_results[ResNet_results.img_id.isin(orig)]\nselt_imgs = orig_imgs.sample(n=6)\nimg_list = selt_imgs['img_id'].values\ntrue_centers = selt_imgs[['cx', 'cy']].values\npred_centers = selt_imgs[['cx_pred', 'cy_pred']].values\n\ndraw_roi(TRAIN_PATH, img_list, true_centers, pred_centers, \n         rows=2, cols=3, model_name=\"ResNet50\")","5c2b5908":"selt_dots = orig_imgs.sample(n=20)\nimg_list = selt_dots['img_id'].values\ntrue_centers = (selt_dots[['cx', 'cy']].values * 1330).astype(int)\npred_centers = (selt_dots[['cx_pred', 'cy_pred']].values * 1330).astype(int)\n\nplt.figure(figsize = (5, 5))\nplt.scatter(true_centers[:, 0], true_centers[:, 1], c='r', alpha=0.5, label='Human')\nplt.scatter(pred_centers[:, 0], pred_centers[:, 1], c='b', alpha=0.5, label='CNN with Activations Func')\nplt.axis('equal')\nplt.legend()\nplt.title(\"20 randomly selected images\")\nplt.show() ","3ed80a4b":"# Save results\nResNet_results.to_csv(\"CNN2_results.csv\")","20fe4f3e":"Osteoporosis Detection using CNN and Keras by Mohsin\n1. Importing the libraries\n2. Training the set\n3. Creating a model\n4. Testing set by model COnv2D\n5. Validating\n6. Saving results to .csv\n7. Dataset CT Scan of Bones Joints\n8. Referring to the last work done\n8. Improving the Estimated TIme Arrival and Lessening the Loss\n9. Defining the region of interest of Vitamin D defficiency by preprocessing of the images\n10. Concluded the Results","5eb1f6dd":"### Data Loading","d78cc92e":"**Simple Convolutional Neural Network Model**","df7be383":"Preprocessing of Images","eaab3123":"**Convolutional Neural Network with Activation Functions**","d6e9e30d":"### Manual image preprocessing"}}