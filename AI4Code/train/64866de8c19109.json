{"cell_type":{"fc7ee9ad":"code","0f3ceddb":"code","af914b0a":"code","15f27a5b":"code","a1b1db93":"code","a703a23a":"code","370d45e1":"code","4bf0040d":"code","0a8a95b0":"code","57929804":"code","40c73d9e":"code","f8684b2b":"code","a29f41fc":"code","4e834f67":"code","df1bb7d9":"code","05bf0b19":"code","dc874dcb":"code","ca4a2799":"code","a8c9948f":"code","a80e516a":"code","a525fd8b":"code","2ae87188":"code","5fc74d5a":"code","c91692d0":"code","3a2de7cd":"code","441ee0e6":"code","0add88cc":"code","26f82791":"code","b54f2c21":"code","81d245c7":"code","bd525163":"code","8c86cdc0":"code","4ffd14c9":"code","73b199aa":"code","e545911e":"code","1ad534f1":"code","260182a4":"code","32154ad7":"code","19c7f2cc":"code","7754b86b":"code","fbe4f6f6":"code","99cc8203":"code","74f2e6a4":"code","f4c18655":"code","76bd038a":"code","a94a5fa3":"code","e9241caa":"markdown","c3f3351a":"markdown","6da984d2":"markdown","17a6561c":"markdown","d42f3bac":"markdown","892e630a":"markdown","71e6fd8c":"markdown","39570bfe":"markdown","b44ede77":"markdown","ca0238a0":"markdown","10c13bbc":"markdown","1ba43d43":"markdown","b7377534":"markdown","daad7503":"markdown","3c7f3e1b":"markdown","e5199a3e":"markdown"},"source":{"fc7ee9ad":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import scatter_matrix\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0f3ceddb":"covid19_india_df = pd.read_csv(\"\/kaggle\/input\/covid19-in-india\/covid_19_india.csv\")","af914b0a":"covid19_india_df.info()","15f27a5b":"covid19_india_df.count()","a1b1db93":"covid19_india_df.head()","a703a23a":"#covid19_india_df['ConfirmedIndianNational'] = covid19_india_df['ConfirmedIndianNational'].replace('-',0)\n#covid19_india_df['ConfirmedIndianNational'].unique()","370d45e1":"covid19_india_df = covid19_india_df.replace('-',0)","4bf0040d":"covid19_india_df.columns","0a8a95b0":"covid19_india_df.rename(columns = {\"State\/UnionTerritory\" : \"State_UnionTerritory\"}, inplace = True)","57929804":"covid19_india_df.shape\ndf_rows,df_col = covid19_india_df.shape\nprint(\"There are total %d records in the datset\" %(df_rows))\n","40c73d9e":"covid19_india_df.describe()","f8684b2b":"covid19_india_df.info()\ncovid19_india_df.describe(include = ['object'])\n","a29f41fc":"type(covid19_india_df.Sno)\n# Sno is of type series and we can perform sorting operation on the series datatype columns only.\ncovid19_india_df.Sno.sort_values(ascending = False)","4e834f67":"covid19_india_df[covid19_india_df['State_UnionTerritory'] == 'Kerala'].Confirmed.max()","df1bb7d9":"States_df = covid19_india_df.State_UnionTerritory.unique()\nStates_df\nprint(\"there are total %d states and UT\" %(len(States_df)))\nmax1 = 0\nfor states in States_df:\n    #print(covid19_india_df[covid19_india_df['State_UnionTerritory'] == states].ConfirmedIndianNational.max())\n    #print(states)\n    max1= covid19_india_df[covid19_india_df['State_UnionTerritory'] == states].Confirmed.max()\n    print(\"Maximum confirmed cases in %s are %d\" %(states, max1))\n    #print(\"Maximum confirmed cases are %d\" %(max1))\n \n#len(max1)\n#covid19_india_df[covid19_india_df.Confirmed.isin(max1)]\n\n    \n","05bf0b19":"%matplotlib inline\ncovid19_india_df.groupby('State_UnionTerritory').Confirmed.max().sort_values().plot(kind = 'bar', title = 'Total Confirmed Cases', legend = True, figsize = (20,10))","dc874dcb":"covid19_india_df.info()","ca4a2799":"covid19_india_df.Deaths.astype('float')\n\n#covid19_india_df.groupby('State_UnionTerritory').Deaths.agg(['min','max','mean','std'])","a8c9948f":"covid19_india_df['State_UnionTerritory'] = covid19_india_df['State_UnionTerritory'].str.replace('#','')\n\n#round(covid19_india_df[covid19_india_df['State_UnionTerritory'] == 'Dadar Nagar Haveli'].Confirmed.std(),2)","a80e516a":"import numpy as np\n#covid19_india_df[covid19_india_df.Confirmed == covid19_india_df[covid19_india_df['State_UnionTerritory'] == 'Punjab'].Confirmed.max()]\nstates_std = []\nstate_std = 0\nctr = 0\nprint(len(States_df))\nfor states in States_df:\n    #print(states)\n    state_std = round(covid19_india_df[covid19_india_df['State_UnionTerritory'] == states].Confirmed.std(),2)\n    ctr = ctr + 1\n    #if not state_std:\n     #   print(states,state_std)\n    states_std.append((states,state_std))\n#print(round(covid19_india_df[covid19_india_df['State_UnionTerritory'] == 'Punjab'].Confirmed.std()))\n#print(np.var(covid19_india_df[covid19_india_df['State_UnionTerritory'] == 'Punjab'].Confirmed))\n#states_std\nprint(len(states_std))\nprint(ctr)","a525fd8b":"states_std = np.array(states_std)","2ae87188":"states_std_df = pd.DataFrame(states_std, columns = ('States_UT','Standard_Deviation'))\n#states_std_df.rename(columns = {'0': 'States_UT','1' : 'Standard_Deviation'}, inplace= True)\nstates_std_df['Standard_Deviation'] = states_std_df['Standard_Deviation'].str.replace('nan','0.0')\n#states_std_df['Standard_Deviation'] = round(int(states_std_df['Standard_Deviation']))\n#type(states_std_df['Standard_Deviation'])\nprint(\"before datatype\")\n#states_std_df.dtypes\n#convert_dt = {'Standard_Deviation' : float }\n#states_std_df.astype(convert_dt)\nprint(\"After datatype\")\nstates_std_df.dtypes\nstates_std_df['Standard_Deviation'] = states_std_df['Standard_Deviation'].apply(pd.to_numeric)\n\n\n","5fc74d5a":"states_std_df.dtypes","c91692d0":"states_std_df.Standard_Deviation.sort_values().index\nstates_std_df.iloc[states_std_df.Standard_Deviation.sort_values().index]\n","3a2de7cd":"filenames","441ee0e6":"ICMR_testing_lab_df = pd.read_csv('\/kaggle\/input\/covid19-in-india\/ICMRTestingLabs.csv')","0add88cc":"ICMR_testing_lab_df.info()","26f82791":"ICMR_testing_lab_df.head()","b54f2c21":"%matplotlib inline\nICMR_testing_lab_df.groupby(['state','type']).lab.count().sort_values().plot(kind = 'bar', figsize=(50,20), fontsize = '30')\n#ICMR_testing_lab_df.groupby(['state']).type.count().plot(kind = 'bar', figsize=(50,20), fontsize = '20',stacked = True)","81d245c7":"state_testing_df = pd.read_csv(r'\/kaggle\/input\/covid19-in-india\/StatewiseTestingDetails.csv')","bd525163":"state_testing_df.head()","8c86cdc0":"state_testing_df.isnull().sum()","4ffd14c9":"state_testing_df.fillna(0,inplace = True)","73b199aa":"state_testing_df.isnull().sum()\n#Null Values have been removed from the datframe","e545911e":"punjab_data = state_testing_df.loc[state_testing_df.State == 'Punjab',:]","1ad534f1":"punjab_data.head()","260182a4":"import matplotlib.pyplot as plt\nx1 = punjab_data.Date\ny1 = punjab_data.TotalSamples\n\ny2 = punjab_data.Positive\n\nplt.figure(figsize = (30,10))\nplt.plot(x1,y1)\nplt.plot(x1,y2)\nplt.show()\n","32154ad7":"punjab_data.set_index('Date').head()","19c7f2cc":"\npunjab_data.sort_values(by = 'Date').head()","7754b86b":"l = 0\ndaily_samples = []\nfor index,row in punjab_data.sort_values(by = 'Date').iterrows():\n    #print(l)\n    #print('row.TotalSamples ' + str(row.TotalSamples) + '-----' + str(l))\n    l = int(row.TotalSamples) - l\n    #l = row.TotalSamples\n    daily_samples.append(l)\n    l = int(row.TotalSamples)\n#daily_samples","fbe4f6f6":"len(daily_samples)\ndaily_samples = pd.Series(daily_samples, index = punjab_data.index, name = 'DailySamples')\ndaily_samples.head()\n","99cc8203":"punjab_data.count()\npd.concat([punjab_data,daily_samples], axis = 1).head()","74f2e6a4":"ind = 0\ndaily_positive = []\ndaily_negative = []\nfor index,row in punjab_data.sort_values(by='Date').iterrows():\n    if ind == 0:\n        daily_positive.append(row.Positive)\n        daily_negative.append(row.Negative)\n    else:\n        daily_positive.append(row.Positive - punjab_data.loc[ind,'Positive'])\n        daily_negative.append(row.Negative - punjab_data.loc[ind,'Negative'])\n    ind = index\ndaily_positive = pd.Series(daily_positive,index = punjab_data.index, name = 'DailyPositive')\ndaily_negative = pd.Series(daily_negative,index = punjab_data.index, name = 'DailyNegative')\npunjab_data = pd.concat([punjab_data,daily_samples,daily_positive,daily_negative], axis = 1)","f4c18655":"punjab_data.tail()","76bd038a":"scatter_matrix(punjab_data[['DailySamples','DailyPositive','DailyNegative']])","a94a5fa3":"#punjab_data.head()\nfig, ax = plt.subplots(figsize = (20,10))\n#fig.figure(figsize = (30,10))\nprint(fig)\nfig = (500,400)\nprint(ax)\n#plt.legend(True)\n#ax = fig.add_axes([0,0,1,1])\nax.plot(punjab_data.Date,punjab_data.DailySamples,'b*')#,punjab_data.DailyPositive,punjab_data.DailyNegative))\nax.plot(punjab_data.Date,punjab_data.DailySamples,'b',label = 'Daily Samples')#,punjab_data.DailyPositive,punjab_data.DailyNegative))\nax.plot(punjab_data.Date,punjab_data.DailyPositive,'g-', label = 'Daily Positive')\nax.plot(punjab_data.Date,punjab_data.DailyPositive,'g*')\n#ax.plot(punjab_data.Date,punjab_data.DailyNegative,color = 'r', label = 'Daily Negative')\nax.plot(punjab_data.DailySamples.mean(),'r')#,punjab_data.DailyPositive,punjab_data.DailyNegative))\nax.legend()\nplt.title('Daily testing vs Daily positive', size = (30))\nplt.xlabel('Dates',size = (20))\nplt.ylabel('Daily tests', size= (20))\nprint(fig)\nplt.show()","e9241caa":"# Sorting the dataset","c3f3351a":"# Aggregate function in pandas\n","6da984d2":"# Lets Explore the ICMR testing lab csv","17a6561c":"**Cleaning the whole dataset whereever there is - replace it with 0**","d42f3bac":"# **df.shape**\n\nThis method will return the shape tuple of 2 where first value repersents the number of rows and 2nd value repersents the number of columns","892e630a":"# Lets look at the data and findout which all columns have null data.","71e6fd8c":"# Replacing # from the data of dataframe","39570bfe":"# **Describe method in the pandas**\n\nIn order to get quick overview of the data, we use thed esscribe method. this methods will perform the various statistics functions on the columns having values either in float or integer.","b44ede77":"# **Rename the State\/UnionTerritory column to State_UnionTerritory**\n\n* We can rename the column using the df.rename command. \n* Here the arguments are (columns = {'old_column_name' : 'new_column_name'}","ca0238a0":"# Data Cleaning\n**Lets clean the data covid19_india_df. Replacing -(hyphen) with 0(zero)**","10c13bbc":"# Attributes of df.describe() function\nNow in order to include the other columns as well we use additonal attributes of the describe function","1ba43d43":"**This dataset has details of all the lab along with their address and type**","b7377534":"# Creating a new datafrmae by performing some operations on the existing dataframe\n","daad7503":"# Lets explore the statewsie testing data","3c7f3e1b":"# Group by based on state_unionterritory","e5199a3e":"# Data Filtering from a dataset covid19_india_df\n\nSuppose we want only those rows where the confirmed cases are maximum"}}