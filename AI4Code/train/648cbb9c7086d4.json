{"cell_type":{"92340560":"code","9468f8cd":"code","1a7d44f1":"code","510eace6":"code","0678404a":"code","0c592f57":"code","0a24d3db":"code","0d9ed151":"code","37088e2f":"code","c937068d":"code","37f1f5af":"code","088d3b10":"code","7a71b24c":"code","5573055e":"code","6a7a5821":"code","0319452b":"code","f07d6ae8":"code","9c32566a":"code","b568bf3c":"code","b9f9b539":"code","5ee4d418":"code","26c1f090":"code","2a7239fa":"code","871270d3":"code","047c1f6e":"code","2110bf46":"code","4044a5bc":"code","796df25b":"code","5ef94445":"code","84a0e75f":"code","1d2d43fd":"code","dfb141a2":"code","a33b141e":"code","5694274f":"code","f23c135e":"code","3691ea24":"code","9c08da70":"code","ae8dd069":"code","bd9703b1":"code","16994299":"code","b3c90c7a":"markdown","6485d16e":"markdown","9ec4880b":"markdown","b45c3f59":"markdown","dfb74f0d":"markdown","4d1814f6":"markdown","67ac95db":"markdown","39062ac4":"markdown","2b9c8064":"markdown","95fdcad4":"markdown","adb8e934":"markdown","24837d26":"markdown","e5428a3d":"markdown","4df9439c":"markdown","24abf493":"markdown","483bae16":"markdown","f80d5255":"markdown","17930cb1":"markdown","96a7d686":"markdown","886cc11d":"markdown","a9fc936c":"markdown","17b034c5":"markdown","3d9202a9":"markdown","75e05fcf":"markdown","2c2d2999":"markdown","20197882":"markdown","4a3598fa":"markdown","162cc370":"markdown","ff453fc9":"markdown","d10e2a19":"markdown","9b791f70":"markdown","14718e90":"markdown","71f693d2":"markdown","d8e65b31":"markdown","8da36735":"markdown","56529866":"markdown","e6a96a33":"markdown","73a2318b":"markdown","f2451d0a":"markdown","687ec20f":"markdown"},"source":{"92340560":"# Data Processing\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os # system processing\n\n# Statistics\nimport pandas_profiling as pp # statistics report\nfrom statsmodels.formula.api import ols  # statistics\nimport statsmodels.api as sm # statistics\n\n# Data Visualization\nimport seaborn as sns # data visualization\nimport matplotlib.pyplot as plt # data visualization\nimport plotly.express as px # data visualization\nimport plotly.graph_objs as go # go object plot\n\n# Machine Learning\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_validate\nimport pickle \n\n# Permutation Importance\nimport eli5  # Permutation Importance\nfrom eli5.sklearn import PermutationImportance # Permutation Importance\n\n# Shap Value\nimport shap  # package used to calculate Shap values\n\nprint(\"Setup Complete\")","9468f8cd":"train_csv = '..\/input\/learn-together\/train.csv'\npred_csv = '..\/input\/learn-together\/test.csv'\ntrain_data = pd.read_csv (train_csv, index_col='Id')\npred_data = pd.read_csv (pred_csv, index_col='Id')\n\nprint(\"Files Preparation Completed\")","1a7d44f1":"print('**************************Train File Preliminary Investigation**************************')\nprint('1. Train File Shape:', train_data.shape)\nmissing_val_count_by_column = (train_data.isnull().sum())\nprint('2. Train File Missing Valu:', missing_val_count_by_column[missing_val_count_by_column > 0])\nprint(\"   Missing Values in Train File: {}\".format(train_data.isna().any().any()))\nprint('3. Train File Variables Information:')\nprint(train_data.info())\nprint('4. Train File Variables Unique Number:')\nprint(train_data.nunique())\nprint('                                                                                       ')\nprint('**************************Prediction File Preliminary Investigation**************************')\nprint('1. Prediction File Shape:', pred_data.shape)\nmissing_val_count_by_column = (pred_data.isnull().sum())\nprint('2. Prediction File Missing Value:', missing_val_count_by_column[missing_val_count_by_column > 0])\nprint(\"   Missing Values in Test File: {}\".format(pred_data.isna().any().any()))\nprint('3. Prediction File Variables Information:')\nprint(pred_data.info())\nprint('4. Prediction File Variables Unique Number:')\nprint(pred_data.nunique())","510eace6":"def datatype_check(data, type_list):\n    for type_name in type_list:\n        try:\n            temp = data[type_name]\n        except:\n            print('Some Issues in Data Type: {}!'.format(type_name))\n            pass\n    print('Data Type Check OK!')\n\nnumerical_data_list = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Horizontal_Distance_To_Fire_Points']\nsoil_type_list = ['Soil_Type{}'.format(idx) for idx in range(1, 41)]\nwilderness_area_list = ['Wilderness_Area{}'.format(idx) for idx in range(1, 5)]\nbinary_data_list = []\nbinary_data_list.extend(soil_type_list)\nbinary_data_list.extend(wilderness_area_list)\ncategorical_data_list = ['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']\n#drop_list = [\"Soil_Type7\", \"Soil_Type15\"]\noutput_list = ['Cover_Type']\n\nprint('**************************Numerical Data List**************************')\nprint(numerical_data_list)\ndatatype_check(train_data, numerical_data_list)\ndatatype_check(pred_data, numerical_data_list)\nprint('************************** Binary Data List **************************')\nprint(binary_data_list)\ndatatype_check(train_data, binary_data_list)\ndatatype_check(pred_data, binary_data_list)\nprint('**************************Categorical Data List**************************')\nprint(categorical_data_list)\ndatatype_check(train_data, categorical_data_list)\ndatatype_check(pred_data, categorical_data_list)\n#print('**************************  Drop Data List  **************************')\n#print(drop_list)\n#datatype_check(train_data, drop_list)\n#datatype_check(test_data, drop_list)\nprint('**************************  Output List  **************************')\nprint(output_list)\ndatatype_check(train_data, output_list)\n\nprint('Prelimanary Investigation Completed!')","0678404a":"print('Train File:')\ntrain_data.head().T","0c592f57":"print('Prediction File:')\npred_data.head().T","0a24d3db":"# Line Histogram Plot\ndef linehistogram_plot(data, type_list):\n    for type_name in type_list:\n        plt.figure() \n        sns.distplot(data[type_name], label=type_name)\n        plt.title('Distribution Plot for ' + type_name)\n        plt.ylabel('No of Instances, Mass Distribution')\n        plt.grid()\n\n# Bar Plot\ndef bar_plot(data, type_list):\n    for type_name in type_list:\n        plt.figure() \n        sns.barplot(data[type_name], label=type_name)\n        plt.title('Distribution Plot for ' + type_name)\n        plt.ylabel('No of instances')\n        plt.grid()\n        \n# Box Plot\ndef box_plot(data, type_list, target_list):\n    for type_name in type_list:\n        for target_name in target_list:\n            plt.figure()\n            #plt.subplot(121)\n            sns.boxplot(y= data[type_name], hue=None)\n            plt.ylabel('No of instances: ' + type_name)\n            plt.title('Box Plot for ' + type_name)\n            #plt.subplot(122)\n            plt.figure()\n            sns.catplot(data = data, x=target_name, y=type_name, kind=\"boxen\")\n            plt.ylabel('No of instances: ' + type_name)\n            plt.title('Box Plot (Versus Target Type) for ' + type_name)\n            plt.grid()\n\n# Scatter Plot\ndef pairscatter_plot(data, type_list, target_list):\n    for target_name in target_list:\n        #plt.figure()\n        #plt.title('Pair Scatter Plot Versus Target Type')\n        #pair_plot = sns.PairGrid(data= data, vars = type_list, hue= target_name)\n        #pair_plot = pair_plot.map_diag(sns.distplot, hist=False); #, bins = 10, edgecolor =  'k', color = 'darkred'\n        #pair_plot = pair_plot.map_lower(sns.scatterplot)\n        #pair_plot = pair_plot.map_upper(sns.kdeplot)\n        pair_plot = sns.pairplot(data= data, vars =type_list, hue= target_name, diag_kind = 'kde')\n        \n        plt.grid()\n\ndef scatter_plot(data, type_list, target_list):\n    for idx in range(0, len(type_list)-1):\n        type_name1 = type_list[idx]\n        for jdx in range(idx+1, len(type_list)):\n            type_name2 = type_list[jdx]\n            for target_name in target_list:\n                plt.figure()\n                sns.scatterplot(data = data, x=type_name1, y=type_name2,hue = target_name)\n                #sns.regplot(data = data, x=type_name1, y=type_name2,)\n                plt.title('Scatter Plot for ' + type_name1 + type_name2)\n                plt.grid()\n    \n# Count Plot\ndef count_plot(data, type_list, target_list):\n    for type_name in type_list:\n        for target_name in target_list:\n            plt.figure()\n            sns.countplot(x= type_name, hue=target_name, data=data)\n            #face_plt = sns.FacetGrid(data, col=target_name, height=4, aspect=.5)\n            #face_plt.map(sns.countplot, type_name)\n\n# Radar plot\ndef radar_plot(data, type_list, target_list):\n    for type_name in type_list:\n        for target_name in target_list:\n            crosstab_data = pd.crosstab(index=data[type_name],columns=data[target_name])\n            target_name_list = crosstab_data.columns\n            type_name_list = crosstab_data.index\n            cat = [target_name +' '+ str(a) for a in target_name_list]\n            \n            layout = go.Layout(\n                polar=dict(\n                    radialaxis=dict(\n                        visible=True,\n                        range=[0, 3000]\n                    )),\n                title=go.layout.Title(\n                    text=\"Radar Plot: \"+type_name+\" v.s. \"+target_name),\n                showlegend=True\n            )\n            fig = go.Figure(layout=layout)\n            for idx in range(0, len(type_name_list)):\n                values = list(crosstab_data.loc[idx].values)#\/(crosstab_data.loc[idx].sum())\n                print(type(values))\n                fig.add_trace(go.Scatterpolar(\n                    r=values,\n                    theta=cat,\n                    fill='toself',\n                    name=str(idx)\n                ))\n            fig.show()\n\n#Correlation Heatmap Plot\ndef correlation_heatmap(data, type_list):\n    plt.figure()\n    colormap = plt.cm.RdBu\n    num_size = len(type_list)\n    plt.figure(figsize=(num_size, num_size))\n    plt.title('Correlation of Numerical Variables: Linear Method', y=1.05, size=15)\n    sns_plot = sns.heatmap(data[type_list].astype(float).corr(), linewidths=0.1, vmax=1.0,\n                           square=True, cmap=colormap, linecolor='white', annot=True)\n    for method_type in [\"pearson\", \"kendall\", \"spearman\"]:\n        plt.figure()\n        colormap = plt.cm.RdBu\n        num_size = len(type_list)\n        plt.figure(figsize=(num_size, num_size))\n        plt.title('Correlation of Numerical Variables: {} Method'.format(method_type), y=1.05, size=15)\n        sns_plot = sns.heatmap(data[type_list].astype(float).corr(method=method_type), linewidths=0.1, vmax=1.0,\n                           square=True, cmap=colormap, linecolor='white', annot=True)\n        #sns_plot.figure.savefig(os.path.join(output_folder,filename+'_correlation_map.png'))\n\nprint(\"Function Read Completed\")","0d9ed151":"print('Train File:')\ntrain_data[numerical_data_list].describe().T","37088e2f":"print('Prediction File:')\npred_data[numerical_data_list].describe().T","c937068d":"print('Train File:')\nlinehistogram_plot(train_data, numerical_data_list)","37f1f5af":"print('Train File:')\nbox_plot(train_data, numerical_data_list, output_list)  ","088d3b10":"print('Train File:')\npairscatter_plot(train_data, numerical_data_list, output_list)\n#scatter_plot(train_data, numerical_data_list, output_list)    ","7a71b24c":"print('Train File:')\ncorrelation_heatmap(train_data, numerical_data_list)   ","5573055e":"def ANOVA_test(data, type_list):\n    for idx in range(0, len(type_list)-1):\n        for jdx in range(idx+1, len(type_list)):\n            type_name1 = type_list[idx]\n            type_name2 = type_list[jdx]\n            if type_name1 != type_name2:\n                mod = ols(type_name1 + '~' + type_name2, data=data).fit()\n                # do type 2 anova\n                aov_table = sm.stats.anova_lm(mod, typ=2)\n                print('ANOVA Table:'+type_name1+' v.s. ' + type_name2)\n                print('-'*100)\n                print(aov_table)\n                print(' '*100)\n\nprint('Train File:')\nANOVA_test(train_data, numerical_data_list)   ","6a7a5821":"print(\"Train File\")\nnumerical_train_report = pp.ProfileReport(train_data[numerical_data_list])\n#report.to_file(\"report.html\")\nnumerical_train_report","0319452b":"print(\"Train File:\")\ntrain_data[categorical_data_list].describe().T","f07d6ae8":"print(\"Test File:\")\npred_data[categorical_data_list].describe().T","9c32566a":"print('Train File:')\nbox_plot(train_data, categorical_data_list, output_list) ","b568bf3c":"print(\"Train File:\")\nlinehistogram_plot(train_data, categorical_data_list)","b9f9b539":"print('Train File:')\npairscatter_plot(train_data, categorical_data_list, output_list)","5ee4d418":"print('Train File:')\ncorrelation_heatmap(train_data, categorical_data_list)  ","26c1f090":"print(\"Train File\")\ncategorical_train_report = pp.ProfileReport(train_data[categorical_data_list])\n#report.to_file(\"report.html\")\ncategorical_train_report","2a7239fa":"print(\"Train File:\")\ntrain_data[binary_data_list].describe().T","871270d3":"print(\"Test File:\")\npred_data[binary_data_list].describe().T","047c1f6e":"print('Train File')\ncount_plot(train_data, binary_data_list, output_list)","2110bf46":"print(\"Train File:\")\nradar_plot(train_data, binary_data_list, output_list)","4044a5bc":"print(\"Train File\")\nbinary_train_report = pp.ProfileReport(train_data[binary_data_list])\n#report.to_file(\"report.html\")\nbinary_train_report","796df25b":"# Training Data Preparation\nX = train_data.drop(output_list, axis = 'columns')\ny = train_data[output_list[0]]\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, test_size= 0.33, random_state = 0)\n\n# Permutation Importance & SHAPE Value Test\nsmall_val_X = val_X.iloc[:150]\none_val_X = val_X.iloc[0,:]\nprint('Data Preparation Completed')","5ef94445":"# Random Forest Set\nRFModel = RandomForestClassifier(n_estimators=30, random_state=1)\nRFModel = RFModel.fit(train_X, train_y)\nprint(\"Training Completed\")","84a0e75f":"# Permutation Importance\nperm = PermutationImportance(RFModel, random_state=1).fit(val_X, val_y)\neli5.show_weights(perm, feature_names = val_X.columns.tolist(), top = 60)","1d2d43fd":"def shap_force_plot(shap_values, val_X, output_class_num):\n    for idx in range(0, output_class_num):\n        print(\"Type {}\".format(idx))\n        shap.initjs()\n        shap_display = shap.force_plot(explainer.expected_value[idx], shap_values[idx], val_X)\n        display(shap_display)\n\nprint(\"Function Create Completed\")","dfb141a2":"# SHAPE Value Force Plot\nexplainer = shap.TreeExplainer(RFModel)\nshap_values = explainer.shap_values(one_val_X)\n\nshap_force_plot(shap_values, one_val_X, 7)","a33b141e":"explainer = shap.TreeExplainer(RFModel)\nshap_values = explainer.shap_values(small_val_X)\n\n# Small SHAPE Value Force Plot\n#shap_force_plot(shap_values, small_val_X, 7)\n\n# Small SHAPE Value Summary Plot\nshap.summary_plot(shap_values, small_val_X)","5694274f":"candidate_features_list = ['Elevation', 'Aspect', 'Slope',\n                           'Horizontal_Distance_To_Roadways', 'Horizontal_Distance_To_Fire_Points', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n                           'Hillshade_Noon', 'Hillshade_9am', 'Hillshade_3pm',\n                           'Wilderness_Area1', 'Wilderness_Area3', 'Wilderness_Area4']\nprint(\"Load Completed\")","f23c135e":"# Data Preparation for Best Features\nX = train_data.drop(output_list, axis = 'columns')\ny = train_data[output_list[0]]\ntrain_X, val_X, train_y, val_y = train_test_split(X[candidate_features_list], y, test_size= 0.33, random_state = 0)\n\nprint(\"Data Preparation Completed\")","3691ea24":"train_X.head().T","9c08da70":"val_X.head().T","ae8dd069":"# Parameters Range Setting\n# Accuracy: 0.840\n# grid_n_estimator = [200, 400]\n# grid_criterion = ['gini', 'entropy']\n# grid_max_depth = [50]\n# grid_min_samples_split = [2, 5]\n# grid_min_samples_leaf = [1, 4]\n# grid_max_features = [7, 13]\n# grid_seed = [0]\ngrid_n_estimator = [200, 400]#[200, 400, 600, 800, 1000]  #[10] # Number of trees in random forest\ngrid_criterion = ['gini', 'entropy'] #['gini']\ngrid_max_depth = [50] #[50, 100]#[20, 40, 60, 80, 100] #[2] # Maximum number of levels in tree\ngrid_min_samples_split = [2, 5]#[2, 5, 10] # Minimum number of samples required to split a node\ngrid_min_samples_leaf = [1, 4]#[1, 2, 4] # Minimum number of samples required at each leaf node\n#grid_max_features = ['auto', 'sqrt'] # Number of features to consider at every split\ngrid_max_features = [7, 13] #[7, 9, 11, 13]\n#grid_bootstrap = [True, False] # Method of selecting samples for training each tree\ngrid_seed = [0]\n\n# Hyper Parameters\ngrid_param = [{\n                'n_estimators': grid_n_estimator,  # default=10\n                'criterion': grid_criterion,  # default=\u201dgini\u201d\n                'max_depth': grid_max_depth,  # default=None\n                'max_features': grid_max_features,\n                'min_samples_split': grid_min_samples_split,\n                'min_samples_leaf': grid_min_samples_leaf,\n                'oob_score': [True],\n                #'bootstrap': grid_bootstrap,\n                'random_state': grid_seed\n            }]\nprint('Setting Completed')","bd9703b1":"# Model Path\nmodel_file = \"..\/input\/RFOpt.sav\"\n\n# Fine training the model\nclf = RandomForestClassifier()\n#outer_fold_obj = StratifiedShuffleSplit(n_splits=10, random_state=0)\ninner_fold_obj = StratifiedShuffleSplit(n_splits=5, random_state=0)\nclf = GridSearchCV(estimator=clf, param_grid=grid_param, cv=inner_fold_obj)\nclf.fit(train_X, train_y)\n#best_search.grid_scores_, best_search.best_params_, best_search.best_score_\nprint(\"Best score: %0.3f\" % clf.best_score_)\n\n# Save Model \nwith open(model_file,mode='wb') as model_f:\n    pickle.dump(clf, model_f)\n#cv_results = cross_validate(best_search, train_X, train_y, cv=outer_fold_obj, return_train_score=True, return_estimator=True)\n#print(cv_results)\n\n#for est in cv_results['estimator']:\n#    with open(model_file,mode='wb') as model_f:\n#        pickle.dump(est, model_f)\n\nprint('Fine Tunning Completed')","16994299":"# Load Submission Format\nsample_submission = pd.read_csv(\"..\/input\/learn-together\/sample_submission.csv\", sep=',')\n\n# Load Model\nloaded_model = pickle.load(open(model_file, 'rb'))\n\n# Model Prediction\ny_pred = loaded_model.predict(pred_data[candidate_features_list])\n\n# Get the Submission File\nsubmission_id = sample_submission[\"Id\"]\nsubmission = pd.DataFrame({\n            \"Id\": submission_id,\n            \"Cover_Type\": y_pred\n        })\nsubmission.to_csv('submission.csv', index=False, float_format=\"%.0f\")\n\nprint(\"Submission Completed\")","b3c90c7a":"Last, we show the fundemental statistics summary in the numerical data type: ","6485d16e":"### Binary Data Type\nFirst, we show the binary data statistics discriptions:","9ec4880b":"Last, we show the fundemental statistics in categorical data type: ","b45c3f59":"Again, we can realize the interaction between two variables from the scatter and the heat map:","dfb74f0d":"# 6. Model Prediction","4d1814f6":"## SHAPE Value Analysis\n\nWe create the SHAPE plot function to draw the SHAPE value for each classification type. ","67ac95db":"From each type SHAPE value plot, we get the key matters for each types:\n- Type 0: the Horizontal_Distance_To_Fire_Points, the Elevation and the Wilderness_Area4\n- Type 1: the Wilderness_Area4, the Elevation and the Wilderness_Area1\n- Type 2: the Elevation and the Horizontal_Distance_To_Hydrology  \n- Type 3: the Horizontal_Distance_To_Hydrology, the Wilderness_Area4 and the Elevation\n- Type 4: the Wilderness_Area4, the Elevation and the Wilderness_Area1\n- Type 5: the Elevation and the Horizontal_Distance_To_Hydrology \n- Type 6: the Elevation, the Wilderness_Area4 and the Horizontal_Distance_To_Roadways","39062ac4":"# 5. Model Established\n\nFirst, we train the Random Forest Classifier model for default setting.","2b9c8064":" # Easy to Analysis with Data Science\n\nAuthor: CY Peng\n\nHistory Record\n- First Release: 2019\/9\/14\n- Second Release: 2019\/9\/20, Bug Fixed, Accuracy Promotion\n\n\nFor this project, we cover several part:\n  - Preparation\n    - Tool Liberary Usage\n    - Data Preparation\n  - Define the Problem\n  - Explore Data Analysis\n    - Preliminary Investigation\n    - Statistical Information\n    - Thinking: Data Leakage\n  - Feature Engineering\n  - Model Established\n    - Permutation Importance\n    - SHAPE Value Analysis\n    - Fine Tunning\n  - Model Prediction\n\n# 1. Preparation\n\n## Tool Liberary Usage\nFirst, we import the libraries for this project. According to the data science, there are five steps to analyze for this project:\n- Step 1: Define the Problem\n- Step 2: Explore Data Analysis, EDA: we use the numpy, pandas, seaborn and matplotlib liberaries to analyze the data.\n- Stpe 3: Feature Engineering: we use the numpy and the pandas to process the data\n- Step 4: Model Established: we use the sklearn to established the model\n- Step 5: Model Maintenance: this step, we use the model the predict the unknown data","95fdcad4":"From above figures, we identify that there are many imbalance data for binary data, escipecilly soil data. According to the statistics theroy, there are at least 5000 data of one data type to establish the good model. But there are seldom effective data for the binary data, which aren't same ratio data, only the Wilderness_Area1, the Wilderness_Area3 and the Wilderness_Area4 variables could possible reach these condition.\nLast, we show the summary fundemental statistics in binary data type: ","adb8e934":"We indicate the box plot of the categorical data type, and we know that the distribution of the variables from the line histogram plot:","24837d26":"For categorical data type, there are no effetive variables as features from statistics analysis. ","e5428a3d":"The Elevation feature has wide range impact on the output! Combine the statistics analysis, the permutation importance and the SHAPE value, we will select the Elevation, the Aspect, the Slope, the Horizontal_Distance_To_Roadways, the Horizontal_Distance_To_Fire_Points, the Horizontal_Distance_To_Hydrology, the Vertical_Distance_To_Hydrology, the Hillshade_Noon, the Hillshade_9am, the Hillshade_3pm, the Wilderness_Area1, the Wilderness_Area3 and the Wilderness_Area4 as the candidate features. We don't choose the soil type, becasue they are not balance data.","4df9439c":"# 2. Define Problem\n\nBased on the problem description, we summarize as following as descriptions:\n- Problem Target: Multi-Classifications\n- Train File: 15.1k data, 56 Variables, 1 Variable for Output Label\n- Test File: 566k data, 55 Variables\n\n# 3. Explore Data Analysis, EDA\n\n## Preliminary Investigation\n\nFirst, we need to know some simple information about the files:","24abf493":"Again, we check the data for the train and the test files:","483bae16":"Like statistics analysis, the Elevation variable is the most important matter. Again, the second and the third importance features are the Horizontal_Distance_To_Roadways and the Horizontal_Distance_To_Fire_Points.","f80d5255":"### Numerical Data Type\nFor numerical data type, we review the fundmental statistics of these data:","17930cb1":"Data Check:","96a7d686":"## Permutation Importance\n\nCreate a PermutationImportance object called perm to show the importances from Random Forest model. Fit it with the appropriate data and show the weights.","886cc11d":"Of the above investigation, there some tips for two files:\n- From 1., there are 55 variables, including 1 output variable and 1 serial number (index).\n- From 2., we know that there are no missing values in the files! So, don't using the encoder technology for the missing values.\n- From 3., all variables type are integer.\n- From 4., we know that:\n  * There are three data types:\n    * numerical data type: \n      * Elevation\n      * Aspect\n      * Slope\n      * Horizontal_Distance_To_Hydrology \n      * Vertical_Distance_To_Hydrology \n      * Horizontal_Distance_To_Roadways \n      * Horizontal_Distance_To_Fire_Points\n    * binary data type:\n      * Wilderness_Area: Rawah Wilderness Area, Neota Wilderness Area, Comanche Peak Wilderness Area, Cache la Poudre Wilderness Area\n      * Soil_Type: Soil 1 - Soil 40\n    * categorical data type:\n      * Hillshade_9am (0 to 255 index)\n      * Hillshade_Noon (0 to 255 index)\n      * Hillshade_3pm (0 to 255 index)\n      * Cover_Type (Output)\n\n  * there are not distinguishable with two types of the two files: \n    * Soil_Type7\n    * Soil_Type15\n    \n    We will reomve these rows.","a9fc936c":"Again, we can see the Elevation variable is the most important factor of this project. The other factors distribution are most overlap.\nHere, we show the numerical variables with correlation heatmap:","17b034c5":"For numerical data type, we will must select the Elevation, the Horizontal_Distance_To_Fire_Points and the Horizontal_Distance_To_Roadways as features. ","3d9202a9":"We look into the distribution of the binary data for the count plot and the radar plot:","75e05fcf":"Visualizing the data for the line distribution plot:","2c2d2999":"Model Established:","20197882":"## Statistical Information\nFurther, we look into the data by using the statistics method and visualization. We will analyze the data for the numerical data type, the categorical data type, and the binary data type. Visualization plot can help us to know the data distribution, the data relationship, the data composition and the data comparision. \n\n- Numerical Data Type: Analyze the one variable data distribution by using the box plot and the line histogram plot. We show the scatter plot for Two variable data interaction. Last, we display the heat map for the multivariables correlation.\n\n- Categorical Data Type: In the same technolgy with the numerical data anlaysis. \n\n- Binary Data Type: Analyze the binary data distribution by using the count plot and the radar plot.\n\nWe write the some plot function as following as codes:","4a3598fa":"### Categorial Data Type\nFirst, we show the categorical data statistics discriptions:","162cc370":"Of the above figures, the most important factor is the Elevation. We can easily to distinguish the target type from the different elevation group. The second and the third import impact variables are the Horizontal_Distance_To_Fire_Points and the Horizontal_Distance_To_Roadways.\nFuther, we can get the scatter plot from these numerical data: ","ff453fc9":"\nFrom the statistics, we can check the data from the the box plot:","d10e2a19":"## Thinking: Data Leakage","9b791f70":" ## Fine Tuning\n\nFirst, we need to prepare the data for training.","14718e90":"## Data Preparation\nAccording to the problem description, we use the 'Id' column as index.","71f693d2":"We use the best model to predict the unknown data to submit the prediction.","d8e65b31":"From above figures, we know that the categorical data relative to the Elevation variable less effect the result. On the other hand, relative to other variables, Hillshade 3pm and Hillshade 9pm are highly correlated.","8da36735":"From above the heatmap, we know that there are no any correlation between two numerical variables, we couldn't do the conbination for variables.\n\nOn the other hand, we have a idea about the two distribution similiarity by using the ANOVA test:","56529866":"Set the fine tunning parameters range:","e6a96a33":"If you have any questions or suggestions, please let me know, thank you. Enjoy it!","73a2318b":"For binary data type, we will must select the Wilderness_Area1, the Wilderness_Area3 and the Wilderness_Area4 as features. ","f2451d0a":"# 4. Feature Engineering\n\nFirst, we try to use all variables as featrues to train the Random Forest model, and use the permutation importance and the SHAPE value analysis technology to analyze the feature importance! Combine the statistics analysis and the result of the model analysis, we will choose the best features and the parameters adjustment range to fine tune the Random Forest model.\n\nWe use the 7:3 cross-validation train-test data to training the model:","687ec20f":"We use the one data to see the SHAPE value plot. "}}