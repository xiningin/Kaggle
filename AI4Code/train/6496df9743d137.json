{"cell_type":{"194fa888":"code","b321c3d6":"code","d1038914":"code","c3644fa0":"code","fbe25df9":"code","5bce551d":"code","287044a0":"code","543008cc":"code","b10dff77":"code","138d8883":"code","54f6eff1":"code","275ae8b0":"markdown","46053aa8":"markdown","a5abe4af":"markdown","1091e4c1":"markdown","1a6b35af":"markdown","152c6c7d":"markdown","73bc7409":"markdown"},"source":{"194fa888":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nimport math\nimport gc\nimport warnings\nimport os\nfrom glob import glob\nfrom PIL import Image\nimport cv2\nimport pydicom\nfrom IPython.display import display, Audio\nimport folium\n\nfrom sklearn.preprocessing import minmax_scale\n\nimport librosa\nfrom librosa.display import waveplot, specshow\nfrom librosa.feature import melspectrogram, chroma_cqt, mfcc, delta, spectral_bandwidth, spectral_centroid\nfrom librosa.beat import beat_track\n\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', 100)\n\n%matplotlib inline","b321c3d6":"MAIN_PATH = '..\/input\/birdsong-recognition\/'\n\nTRAIN_PATH = os.path.join(MAIN_PATH, 'train.csv')\nTEST_PATH = os.path.join(MAIN_PATH, 'test.csv')\nSUB_PATH = os.path.join(MAIN_PATH, 'sample_submission.csv')\n\nEXAM_TEST = os.path.join(MAIN_PATH, 'example_test_audio')\nTRAIN_AUDIO_PATH = os.path.join(MAIN_PATH, 'train_audio')\n\nSR = 32000","d1038914":"def normalize(x, axis=0):\n    return minmax_scale(x, axis=axis)\n\n\n\ndef display_feature(df, feature, top=10):\n    \n    plt.figure(figsize=(15,8))\n    sns.set_style('darkgrid')\n    ax = sns.countplot(y=feature, data=df, order=df[feature].value_counts().index[:top])\n\n    for p in ax.patches:\n        ax.annotate('{:.2f}%'.format(100*p.get_width()\/df.shape[0]), (p.get_x() + p.get_width() + 0.02, p.get_y() + p.get_height()\/2))\n\n    plt.title(f'Distribution of {feature}', size=25, color='b')\n    plt.show()\n    \n    \n    \ndef audio_map(df, audio_list, num_bird=5):\n    for i in range(num_bird):\n        rand_bird = random.choice(df['ebird_code'])\n        rand_df = df[df['ebird_code']==rand_bird].sample().reset_index(drop=True)\n        latitude = rand_df.loc[0, 'latitude']\n        longitude = rand_df.loc[0, 'longitude']\n        location = rand_df.loc[0, 'location']\n        \n        map_hooray = folium.Map(location=[latitude, longitude], zoom_start=10)\n        folium.Marker([latitude, longitude], popup=location).add_to(map_hooray)\n        \n        file = random.choice(rand_df['filename'])\n        print(f'{file}: {rand_bird} in{location}')\n        file_path = [i for i in audio_list if file in i][0]\n        display(Audio(data=file_path, autoplay=True))\n        display(map_hooray)\n        \n        \n        \ndef spectrum_wave(df, audio_list, num_bird=3):\n    num_ax = 8\n    for i in range(num_bird):\n        rand_bird = random.choice(df['ebird_code'])\n        rand_df = df[df['ebird_code']==rand_bird].sample().reset_index(drop=True)\n        file = random.choice(rand_df['filename'])\n        file_path = [i for i in audio_list if file in i][0]\n        y, sr = librosa.load(file_path, sr=SR, offset=0, duration=10)\n        \n        S = melspectrogram(y, sr=sr, n_mels=128)\n        log_s = librosa.power_to_db(S, ref=np.max)\n        \n        fig, ax = plt.subplots(num_ax, 1, figsize=(20, 7*num_ax))\n        \n        ax0 = ax[0].twinx()\n        waveplot(y, sr, color='yellowgreen', alpha=0.4, ax=ax0)\n        s0 = specshow(log_s, sr=sr, x_axis='time', y_axis='log', ax=ax[0])\n        ax[0].set_title('Mel', color='r', fontsize=15)\n        \n        \n        y_harmonic, y_percussive = librosa.effects.hpss(y)\n        s_harmonic   = melspectrogram(y_harmonic, sr=sr)\n        s_percussive = melspectrogram(y_percussive, sr=sr)\n        \n        log_sh = librosa.power_to_db(s_harmonic, ref=np.max)\n        log_sp = librosa.power_to_db(s_percussive, ref=np.max)\n        \n        ax1 = ax[1].twinx()\n        waveplot(y, sr, color='yellowgreen', alpha=0.4, ax=ax1)\n        specshow(log_sh, sr=sr, x_axis='time', y_axis='log', ax=ax[1])\n        ax[1].set_title('Harmonic', color='r', fontsize=15)\n        \n        ax2 = ax[2].twinx()\n        waveplot(y, sr, color='yellowgreen', alpha=0.4, ax=ax2)\n        specshow(log_sp, sr=sr, x_axis='time', y_axis='log', ax=ax[2])\n        ax[2].set_title('Percussive', color='r', fontsize=15)\n        \n        c = chroma_cqt(y_harmonic, sr=sr, bins_per_octave=36)\n        \n        specshow(c, sr=sr, x_axis='time', y_axis='log', ax=ax[3])\n        ax[3].set_title('Chromagram', color='r', fontsize=15)\n        \n        tempo, beats = beat_track(y_percussive, sr=sr)\n        \n        specshow(log_s, sr=sr, x_axis='time', y_axis='log', ax=ax[4])\n        ax[4].set_title('Beat track', color='r', fontsize=15)\n        ax[4].vlines(librosa.frames_to_time(beats), 1, 0.5 * sr,\n                     colors='w', linestyles='-', linewidth=2, alpha=0.5)\n        \n        mfcc_ = mfcc(S=log_s, n_mfcc=13)\n        delta_mffc = delta(mfcc_)\n        delta_mffc2 = delta(mfcc_, order=2)\n        \n        specshow(mfcc_, x_axis='time', y_axis='log', ax=ax[5])\n        ax[5].set_title('MFFC', color='r', fontsize=15)\n        \n        specshow(delta_mffc, x_axis='time', y_axis='log', ax=ax[6])\n        ax[6].set_title('Delta MFFC', color='r', fontsize=15)\n        \n        specshow(delta_mffc2, x_axis='time', y_axis='log', ax=ax[7])\n        ax[7].set_title('Delta MFFC2', color='r', fontsize=15)\n        \n        plt.suptitle(f'{file}: {rand_bird}', fontsize=20, color='b')\n        fig.tight_layout(rect=[0, 0.03, 1, 0.95])        \n        \n        \n        \ndef bandwidth(df, audio_list, num_bird=5, num_each_bird=3):\n    for i in range(num_bird):\n        rand_bird = random.choice(df['ebird_code'])\n        rand_df = df[df['ebird_code']==rand_bird].sample(num_each_bird).reset_index(drop=True)\n        fig, ax = plt.subplots(num_each_bird, 1, figsize=(20, 10*num_each_bird))\n        for row in range(len(rand_df)):\n            file = rand_df.loc[row, 'filename']\n            file_path = [i for i in audio_list if file in i][0]\n            y, sr = librosa.load(file_path, sr=SR, offset=0, duration=10)\n            spec_center = spectral_centroid(y, sr=sr)[0]\n            band2 = spectral_bandwidth(y, sr=sr, p=2)[0]\n            band3 = spectral_bandwidth(y, sr=sr, p=3)[0]\n            band4 = spectral_bandwidth(y, sr=sr, p=4)[0]\n#             spec_center = specshow(spec_center, sr=sr, x_axis='time', y_axis='log')\n\n            waveplot(y, sr, color='b', alpha=0.4, ax=ax[row])\n            ax0 = ax[row].plot(librosa.frames_to_time(range(len(spec_center))), normalize(spec_center), color='r')[0]\n            ax1 = ax[row].plot(librosa.frames_to_time(range(len(band2))), normalize(band2), color='g')[0]\n            ax2 = ax[row].plot(librosa.frames_to_time(range(len(band3))), normalize(band3), color='black')[0]\n            ax3 = ax[row].plot(librosa.frames_to_time(range(len(band4))), normalize(band4), color='y')[0]\n            fig.legend([ax0, ax1, ax2, ax3], ['center', 'band2', 'band3', 'band4'], fontsize=16)\n            ax[row].set_title(f'{rand_df.loc[row, \"filename\"]}', color='r', fontsize=15)\n            \n            ax[row].legend()\n                     \n        plt.suptitle(f'{rand_bird}', fontsize=20, color='b')\n        fig.tight_layout(rect=[0, 0.03, 1, 0.95])           \n        plt.show()        ","c3644fa0":"train_df = pd.read_csv(TRAIN_PATH, usecols=['ebird_code', 'recordist', 'location', 'file_type',\n                                            'date', 'filename', 'url', 'longitude', 'latitude'])\ntrain_df.head(10)","fbe25df9":"test_df = pd.read_csv(TEST_PATH)\ntest_df.tail()","5bce551d":"sub_df = pd.read_csv(SUB_PATH)\nsub_df.head()","287044a0":"train_mp3 = glob(f'{TRAIN_AUDIO_PATH}\/*\/*.*')\nprint(f'Number of file: {len(train_mp3)}')","543008cc":"display_feature(train_df, 'recordist', top=10)","b10dff77":"audio_map(train_df, train_mp3, num_bird=3)","138d8883":"%%time\n\nspectrum_wave(train_df, train_mp3)","54f6eff1":"bandwidth(train_df, train_mp3)","275ae8b0":"# Config","46053aa8":"# Read File","a5abe4af":"# Function","1091e4c1":"## Way + Mel + Harmonic + Percussive + Chromagram + Beat track + MFFC\nReference: https:\/\/medium.com\/@jonathan_hui\/speech-recognition-feature-extraction-mfcc-plp-5455f5a69dd9","1a6b35af":"# Some Analysis","152c6c7d":"## Spectral Bandwidth","73bc7409":"## Display Audio"}}