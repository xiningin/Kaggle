{"cell_type":{"4f6f5a02":"code","bbf01cc2":"code","897b1e9c":"code","b91c3fba":"code","61fff147":"code","085953a5":"code","ba000e00":"code","29350c3f":"code","69684bd5":"code","c0de9715":"code","376ab2ec":"code","8a218c6f":"code","b56879a1":"code","6e173ea6":"code","493fbbbc":"code","ea095148":"code","87b23b85":"code","0b935296":"code","4d2706fe":"code","5680058f":"code","f7e70a49":"code","1ee15bd6":"code","874697dd":"code","05c73d9b":"code","70c16f90":"code","070bfd5c":"code","b765103d":"code","d3ef0957":"code","9f53cd21":"code","af36079f":"code","57f51edf":"code","1a9d9c0d":"code","2bf755ab":"markdown","a00596f9":"markdown","d55ac37d":"markdown"},"source":{"4f6f5a02":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bbf01cc2":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split # Import train_test_split function\nfrom sklearn import metrics\n%matplotlib inline","897b1e9c":"#initializing the dataset\ntraindf=pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntestdf=pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntraindf.head()","b91c3fba":"testdf.head()","61fff147":"#number of rows and columns in the train dataset\ntraindf.shape","085953a5":"#number of rows and columns in the test dataset\ntestdf.shape","ba000e00":"#number of missing values in each column of train dataset\ntraindf.isnull().sum()","29350c3f":"#Datatypes of each column of the train dataset\ntraindf.dtypes","69684bd5":"#plotting the distribution of the values in column \"Age\"\nsns.distplot(traindf[\"Age\"])","c0de9715":"missing_values_count=traindf.isnull().sum()","376ab2ec":"# how many total missing values do we have in training dataset?\ntotal_cells = np.product(traindf.shape)\ntotal_missing = missing_values_count.sum()\n\n# percent of data that are missing\npercent_missing = (total_missing\/total_cells) * 100\nprint(\"%.4f\"%  percent_missing,\"% values of total values are missing.\")","8a218c6f":"#now checking missing values in test dataset\ntestdf.isnull().sum()","b56879a1":"#filling missing values of Age column with the mean of the column\ntraindf[\"Age\"].fillna(traindf[\"Age\"].mean(),inplace=True)\n#doing the same for test dataset\ntestdf[\"Age\"].fillna(traindf[\"Age\"].mean(),inplace=True)","6e173ea6":"#violinplot of the values in Survived and Embarked column to check how the categories \n#of Embarked is ditribution based on Survival Categories.\nsns.violinplot(y=\"Survived\",x=\"Embarked\",data=traindf)","493fbbbc":"traindf.dropna(axis=0,subset=[\"Embarked\"],inplace=True)\n#doing the same thing for test dataset\ntestdf.dropna(axis=0,subset=[\"Embarked\"],inplace=True)","ea095148":"missing_values_percentage_Cabin = missing_values_count.Cabin\/traindf.shape[0]*100\nprint(\"percentage of missing values in the Cabin columns is %.4f\"% missing_values_percentage_Cabin,\"%\")","87b23b85":"#as the percentage of missing values in the Cabin column is too high, we are dropping the column\ntraindf = traindf.drop(\"Cabin\",axis=1)\n#doing the same thing for test dataset\ntestdf = testdf.drop(\"Cabin\",axis=1)\nmissing_values_count=traindf.isnull().sum()\n#checking missing value counts again to reconfirm all the missing values are treated\nmissing_values_count","0b935296":"#filling the missing value in Fare column of test dataset with mean of the column\ntestdf[\"Fare\"].fillna(testdf[\"Fare\"].mean(),inplace=True)","4d2706fe":"# Import label encoder\nfrom sklearn import preprocessing\n \n# label_encoder object knows how to understand word labels.\nlabel_encoder = preprocessing.LabelEncoder()\n \n# Encode labels in column \"Ticket\" of both train and test dataset.\ntraindf[\"Ticket\"]= label_encoder.fit_transform(traindf[\"Ticket\"])\ntestdf[\"Ticket\"]= label_encoder.fit_transform(testdf[\"Ticket\"])","5680058f":"#dropping \"Name\" and \"PassengerId\" column\ntraindf.drop([\"Name\",\"PassengerId\"],axis=1,inplace=True)\n#doing the same thing for test dataset\ntestdf.drop([\"Name\",\"PassengerId\"],axis=1,inplace=True)\n#encoding remaining categorical features\ntraindf1 = pd.get_dummies(traindf)\n#doing the same thing for test dataset\ntestdf = pd.get_dummies(testdf)","f7e70a49":"#Plotting relationship among all the attributes\nsns.pairplot(traindf)","1ee15bd6":"#correlation matrix\ntraindf.corr()","874697dd":"#correlation heatmap\nsns.heatmap(traindf.corr(),annot=True)\n#features with higher correlation with survival will be more useful.","05c73d9b":"#preparing data for model training\nX = traindf1.drop([\"Survived\"],axis=1)\ny = traindf1[\"Survived\"]","70c16f90":"#creating train and test datasets\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\naccuracy = list()\n#fitting 1000 different decision trees and storing their accuracy scores in the list accuracy.\nfor k in range(1,101):\n    model = DecisionTreeClassifier(random_state=int(k))\n    model = model.fit(X_train,y_train)\n    y_pred = model.predict(X_test)\n    score = metrics.accuracy_score(y_test,y_pred)\n    accuracy.append(score)\n#printing the accuracies of different decision trees.\naccuracy","070bfd5c":"#plotting the accuracy scores for each random states\ndf=pd.DataFrame({\"States\":np.arange(1,101,1),\"Score\":accuracy})\nplt.figure(figsize=(10,8))\nsns.lineplot(x=\"States\",y=\"Score\",data=df)","b765103d":"#getting the random state with most accuracy\naccuracy.index(max(accuracy))+1","d3ef0957":"#re-running the model with 55 random state\nmodel = DecisionTreeClassifier(random_state=55)\nmodel = model.fit(X_train,y_train)\ny_pred = model.predict(X_test)\n#printing accuracy\nprint(\"Accuracy: \",metrics.accuracy_score(y_test, y_pred))\n\n#Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\nprint(\"\\nConfusion matrix : \\n\")\nprint(confusion_matrix(y_test, y_pred))\n\n#Classification Report\nfrom sklearn.metrics import classification_report\nprint(\"\\nClassification Report : \\n\")\nprint(classification_report(y_test, y_pred))","9f53cd21":"from sklearn.tree import export_graphviz\nimport graphviz\n\n#plotting the decision tree\n\ndata = export_graphviz(model,out_file=None,feature_names=list(X.columns),class_names=[\"Died\",\"Survived\"],   \n                         filled=True, rounded=True,  \n                         special_characters=True)\ngraph = graphviz.Source(data)\ngraph","af36079f":"#now predicting the values for the test data\ny_pred = model.predict(testdf)","57f51edf":"#storing the results alongside with Passenger Id's of each passenger of whom's survival are to be predicted.\ntestdf1 = pd.read_csv(\"..\/input\/titanic\/test.csv\")\nresultdf = pd.DataFrame(testdf1[\"PassengerId\"])\n#printing the result\nresultdf[\"Survived\"]=y_pred\nresultdf.reset_index(drop=True,inplace=True)","1a9d9c0d":"#saving the result in csv file\nresultdf.to_csv(\"Titanic_Prediction.csv\",index=False)\nresultdf","2bf755ab":"We can see the mode is at somewhere around 25 and the distribution is positively skewed.","a00596f9":"We can see from the violin plot the distribution is not exactly identical\nfor different categories of Embarked column and also for each of the Survival Classes, \nSo we should not drop the Column, we are going to remove the rows with NA values from the column.","d55ac37d":"Next, we are going to drop the \"Name\" and \"PassengerId\" column as it unqiue to each passenger and does not really have anything to do with predicting survival. Also, we are going to label encode the Ticket column(not using the one hot encoding for this column because one hot encoding will create a difference between total number of columns for train and test dataset, so we wouldn't be able to apply our model to the test dataset)."}}