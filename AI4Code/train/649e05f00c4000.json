{"cell_type":{"d3c2070d":"code","a000d287":"code","bc3fcb3b":"code","941f177b":"code","502f3a99":"code","90a65da0":"code","b79d62b1":"code","7b83e771":"code","3b6800bc":"code","e096d674":"markdown","818d75ae":"markdown","d3fd7a33":"markdown","5d136015":"markdown","f4e90a1e":"markdown","1118532a":"markdown","e53f3372":"markdown","4625d393":"markdown","8b905afe":"markdown","0899817f":"markdown","f128a2bc":"markdown"},"source":{"d3c2070d":"import numpy as np\nimport pandas as pd \nimport torch\nfrom torch import optim\nimport torch.nn as nn\nfrom PIL import Image\nimport os","a000d287":"from skimage import filters, color, morphology, io\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random\nimport skimage as si\n\ndf = pd.read_csv(\"..\/input\/english-premier-league-logo-detection-20k-images\/train.csv\")\n\nn1 = 3\nn2 = 5\nfig, axs = plt.subplots(n1, n2, figsize=(32, 16))\nfor i in range(n1):\n    for j in range(n2):\n        z = random.randint(0, len(df)-1)\n        pic = np.array(io.imread(df.loc[z][\"filepath\"], plugin='pil'))\n        shape = np.shape(pic)\n        axs[i, j].imshow(pic)\n        axs[i, j].set_title('%s x=%.f, y=%.f' % (df.loc[z][\"team_name\"], shape[0], shape[1]))","bc3fcb3b":"import numpy as np\n\nsample_df = df.sample(frac=0.01, ignore_index=True)\n\nN = len(sample_df)\nshape = np.zeros((2, N))\n\nfor i in range(N):    \n    tmp = np.shape(np.array(io.imread(sample_df.loc[i][\"filepath\"], as_gray=True, plugin='pil')))\n    shape[:, i] = [tmp[0], tmp[1]]\n\nfig, axs = plt.subplots(1, 2, figsize=(20, 5))\n\naxs[0].scatter(shape[0, :], shape[1, :])\naxs[0].plot(range(0, 1000), range(0, 1000), 'k')\naxs[0].set_ylabel('dim 1')\naxs[0].set_xlabel('dim 0')\naxs[0].grid()\naxs[0].set_title('Scatter of images shapes')\naxs[0].set_xlim([0, 1000])\naxs[0].set_ylim([0, 1000])\n\naxs[1].hist(shape[0, :]\/shape[1, :])\naxs[1].grid()\naxs[1].set_xlabel('Aspect Ratio')\naxs[1].set_ylabel('Frequency')\naxs[1].set_title('Histogram of aspect ration for images')\naxs[1].set_xlim([0, 2])\n\nprint(\"Average height \" + str(sum(shape[1, :]) \/ len(shape[1, :])))","941f177b":"from torch.utils.data import Dataset\n\nclass CustomDataset(Dataset):\n  def __init__(self, X, y, BatchSize, transform):\n    super().__init__()\n    self.BatchSize = BatchSize\n    self.y = y\n    self.X = X\n    self.transform = transform\n    \n  def num_of_batches(self):\n    \"\"\"\n    Detect the total number of batches\n    \"\"\"\n    return math.floor(len(self.list_IDs) \/ self.BatchSize)\n\n  def __getitem__(self,idx):\n    class_id = self.y[idx]\n    img = Image.open(self.X[idx])\n    img = img.convert(\"RGBA\").convert(\"RGB\")\n    img = self.transform(img)\n    return img, torch.tensor(int(class_id))\n\n  def __len__(self):\n    return len(self.X)","502f3a99":"from sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\n\n# Shuffle dataframe\ndf = df.sample(frac=1)\n\nX = df.iloc[:,0]\ny = df.iloc[:,2]\n\ntransform = transforms.Compose([\n                transforms.Resize([256,256]),\n                transforms.RandomRotation(20, fill=256),\n                transforms.ToTensor(),\n                transforms.RandomAffine(degrees=0, translate=(0.025, 0.025), fill=256),\n                transforms.Normalize([0.5], [0.5])\n            ])\n\ntest_transform = transforms.Compose([\n                transforms.Resize([256,256]),\n                transforms.ToTensor(),\n                transforms.Normalize((0.5,), (0.5,)),\n            ])\n\ntrain_ratio = 0.90\nvalidation_ratio = 0.05\ntest_ratio = 0.05\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1 - train_ratio, stratify = y, random_state = 0)\nX_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio\/(test_ratio + validation_ratio), random_state = 0)\n\ndataset_stages = ['train', 'val', 'test']\n\nbatch_size = 32\nimage_datasets = {'train' : CustomDataset(X_train.values, y_train.values, batch_size, transform), 'val' : CustomDataset(X_val.values, y_val.values, batch_size, test_transform), 'test' : CustomDataset(X_test.values, y_test.values, batch_size, test_transform)}\ndataloaders = {x: DataLoader(image_datasets[x], batch_size=image_datasets[x].BatchSize,\n                                            shuffle=True, num_workers=0)\n            for x in dataset_stages}\n\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}","90a65da0":"nparray = image_datasets['train'][2][0].cpu().numpy() \nimage = transforms.ToPILImage()(image_datasets['train'][2][0].cpu()).convert(\"RGB\")\ndisplay(image)","b79d62b1":"import time\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n    since = time.time()\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n            num_batches = 0\n            outputs = None\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                # Loading Bar\n                if (phase == 'train'):\n                    num_batches += 1\n                    percentage_complete = ((num_batches * batch_size) \/ (dataset_sizes[phase])) * 100\n                    percentage_complete = np.clip(percentage_complete, 0, 100)\n                    print(\"{:0.2f}\".format(percentage_complete), \"% complete\", end=\"\\r\")\n\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n                \n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    loss = criterion(outputs.float(), labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        # TODO: try removal\n                        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                \n                predicted = torch.max(outputs.data, 1)[1] \n                running_correct = (predicted == labels).sum()\n                running_corrects += running_correct\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            \n            epoch_acc = running_corrects \/ dataset_sizes[phase]\n            #epoch_acc = sum(epoch_acc) \/ len(epoch_acc)\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc.item()))\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    return model","7b83e771":"from torchvision import models\nfrom torch.optim import lr_scheduler\n\nmodel_ft = models.squeezenet1_1(pretrained=True)\nmodel_ft.num_classes = 20\nmodel_ft.classifier._modules[\"1\"] = nn.Conv2d(512, model_ft.num_classes, kernel_size=(1, 1))\nfor param in model_ft.parameters():\n    param.requires_grad = False\nfor param in model_ft.classifier.parameters():\n    param.requires_grad = True\n\ncriterion = nn.CrossEntropyLoss()\n\noptimizer_ft = optim.Adam(model_ft.parameters(), lr=0.01)\n\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n\nmodel_ft = train_model(model_ft.to(device), criterion, optimizer_ft, exp_lr_scheduler, 10)","3b6800bc":"from sklearn.metrics import accuracy_score \n\naccuracy_scores = []\n\nrunning_corrects = 0\noutputs = None\nfor inputs, labels in dataloaders['test']:\n    model_ft.eval()\n    \n    inputs = inputs.to(device)\n    labels = labels.to(device)\n\n    outputs = model_ft(inputs)\n    \n    predicted = torch.max(outputs.data, 1)[1] \n    running_correct = (predicted == labels).sum()\n    running_corrects += running_correct\n\naccuracy = running_corrects \/ dataset_sizes['test']\nprint(\"Accuracy: \" + str(accuracy.item()))","e096d674":"# Load Squeezenet and Train\n","818d75ae":"# Import Necessary Libraries","d3fd7a33":"# Run on Test Set","5d136015":"# Create a Training Function","f4e90a1e":"# Conclusion\n\nA test accuracy of 1.0 has been achieved. Showing that even a network as small as squeezenet is suitable for this task.","1118532a":"# Instantiate the Datasets\n\nWe will form them into torch dataloaders to make the data easier to work with. We are also going to put in a minor amount of image augmentation in the train dataset.","e53f3372":"# Investigate Images\n\nLet's take a look at what we are dealing with.","4625d393":"Interestingly in this dataset the images have already been augmented.\n\n# Look At the Image's Shapes","8b905afe":"# Create the Custom Dataset Class\n\nWe need this to be able to load the image and label into the model we will create. So we will create a custom dataset to handle this","0899817f":"# Introduction\n\nI intend to use Squeezenet 1.1 on the dataset in this notebook. There isn't a particular reason to do this beyond I would like to run it on the CPU exclusively and squeezenet is the sort of low parameter network that suits this. I also like seeing if the low parameter network can achieve much on a dataset, in case I come back to it. ","f128a2bc":"# Test image from dataset\nLet's check the dataset is working and is able to display an image satisfactorily. We can also see the effects the transforms are having."}}