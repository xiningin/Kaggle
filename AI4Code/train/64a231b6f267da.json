{"cell_type":{"0b6b0803":"code","c0deb38f":"code","3171b996":"code","1ee07d6e":"code","e5f03e22":"code","b4470869":"code","9b0ba5cf":"code","22f67b2a":"code","379e1b48":"code","624edba1":"code","cfbdf1f4":"code","1101dbd8":"code","578b7012":"code","b1a0fb20":"code","ddd22d37":"code","bab32587":"code","58aa9002":"code","fad4e80c":"code","eccf3caf":"code","f7a0a225":"code","b8f2967e":"code","4d56f939":"code","d3213633":"markdown","8167fa09":"markdown","d557940a":"markdown","2314662d":"markdown","f79bf765":"markdown","f799467e":"markdown","a86d0bb9":"markdown","1a1acd45":"markdown","568ca603":"markdown","810c7561":"markdown","3d707c04":"markdown","2330fdea":"markdown","16e9056d":"markdown","806db560":"markdown","8150a780":"markdown","2c4eba2c":"markdown","9554ba5e":"markdown","74ad306e":"markdown"},"source":{"0b6b0803":"import numpy as np\nimport pandas as pd\nimport os\nprint(os.listdir(\"..\/input\"))","c0deb38f":"# load data from csv files\ntrain_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/sample_submission.csv')\nprint(train_df.shape, test_df.shape)","3171b996":"train_df['has_cactus'].value_counts()","1ee07d6e":"import matplotlib.pyplot as plt\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\n\ntrain_path = '..\/input\/train\/train\/'\ntest_path = '..\/input\/test\/test\/'","e5f03e22":"# look at some of the pics from train_df with cactus\nhas_cactus = train_df[train_df['has_cactus']==1]\nplt.figure(figsize=(15,7))\nfor i in range(40):  \n    plt.subplot(4, 10, i+1)\n    plt.imshow(load_img(train_path+has_cactus.iloc[i]['id']))\n    plt.title(\"label=%d\" % has_cactus.iloc[i]['has_cactus'], y=1)\n    plt.axis('off')\nplt.subplots_adjust(wspace=0.3, hspace=-0.1)\nplt.show()","b4470869":"# look at some of the pics from train_df with no cactus\nno_cactus = train_df[train_df['has_cactus']==0]\nplt.figure(figsize=(15,7))\nfor i in range(40):  \n    plt.subplot(4, 10, i+1)\n    plt.imshow(load_img(train_path+no_cactus.iloc[i]['id']))\n    plt.title(\"label=%d\" % no_cactus.iloc[i]['has_cactus'], y=1)\n    plt.axis('off')\nplt.subplots_adjust(wspace=0.3, hspace=-0.1)\nplt.show()","9b0ba5cf":"def prep_cnn_data(df, n_x, n_c, path):\n    \"\"\"\n    This function loads the image jpg data into tensors\n    \"\"\"\n    # initialize tensors\n    tensors = np.zeros((df.shape[0], n_x, n_x, n_c))\n    # load image as arrays into tensors\n    for i in range(df.shape[0]):\n        pic = load_img(path+df.iloc[i]['id'])\n        pic_array = img_to_array(pic)\n        tensors[i,:] = pic_array\n    # standardize the values by dividing by 255\n    tensors = tensors \/ 255.\n    return tensors","22f67b2a":"# prepare the train data for CNN\ntrain_pic_array = prep_cnn_data(train_df, 32, 3, path='..\/input\/train\/train\/')\ntrain_Y = train_df['has_cactus'].values","379e1b48":"# prepare the test data for prediction later on\ntest_pic_array = prep_cnn_data(test_df, 32, 3, path='..\/input\/test\/test\/')","624edba1":"print(train_pic_array.shape, train_Y.shape)\nprint(test_pic_array.shape)","cfbdf1f4":"# use Keras data generator to augment the training set\nfrom keras_preprocessing.image import ImageDataGenerator\ndata_augment = ImageDataGenerator(zoom_range=0.1, \n                                  width_shift_range=0.1, height_shift_range=0.1,\n                                  horizontal_flip=True, vertical_flip=True)","1101dbd8":"# build the CNN from keras\nfrom keras import models\nfrom keras import layers\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, kernel_size=3, padding='same', activation='relu', input_shape=(32, 32, 3)))\nmodel.add(layers.Conv2D(32, kernel_size=3, padding='valid', activation='relu'))\nmodel.add(layers.MaxPooling2D(pool_size=(2,2), strides=2))\nmodel.add(layers.Dropout(rate=0.4))\nmodel.add(layers.Conv2D(64, kernel_size=5, padding='same', activation='relu'))\nmodel.add(layers.Conv2D(64, kernel_size=5, padding='valid', activation='relu'))\nmodel.add(layers.MaxPooling2D(pool_size=(2,2), strides=2))\nmodel.add(layers.Dropout(rate=0.4))\nmodel.add(layers.Conv2D(128, kernel_size=3, padding='same', activation='relu'))\nmodel.add(layers.Conv2D(128, kernel_size=3, padding='valid', activation='relu'))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dropout(rate=0.4))\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.summary()","578b7012":"# compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', \n              metrics=['accuracy'])","b1a0fb20":"# here I use 3500 examples from the training data\nX_dev = train_pic_array[:3500]\nrem_X_train = train_pic_array[3500:]\nprint(X_dev.shape, rem_X_train.shape)\n\nY_dev = train_Y[:3500]\nrem_Y_train = train_Y[3500:]\nprint(Y_dev.shape, rem_Y_train.shape)","ddd22d37":"# Train and validate the model\nepochs = 150\nbatch_size = 1024\nhistory = model.fit_generator(data_augment.flow(rem_X_train, rem_Y_train, batch_size=batch_size), \n                              epochs=epochs, steps_per_epoch=rem_X_train.shape[0]\/\/batch_size, \n                              validation_data=(X_dev, Y_dev))","bab32587":"# plot and visualise the training and validation losses\nloss = history.history['loss']\ndev_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\n\nfrom matplotlib import pyplot as plt\nplt.figure(figsize=(15,10))\nplt.plot(epochs, loss, 'bo', label='training loss')\nplt.plot(epochs, dev_loss, 'b', label='validation loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","58aa9002":"# do error analysis on the predictions for X_dev\npred_dev = model.predict(X_dev)\npred_dev = (pred_dev > 0.5).astype(int)","fad4e80c":"# look at those that were classified wrongly in X_dev\nresult = pd.DataFrame(train_Y[:3500], columns=['Y_dev'])\nresult['Y_pred'] = pred_dev\nresult['correct'] = result['Y_dev'] - result['Y_pred']\nerrors = result[result['correct'] != 0]\nerror_list = errors.index\nprint('Number of errors is ', len(errors))\nprint('The indices are ', error_list)","eccf3caf":"# plot the image of the wrong in predictions for X_dev\nplt.figure(figsize=(15,8))\nfor i in range(len(error_list)):\n    plt.subplot(4, 10, i+1)\n    plt.imshow(load_img(train_path+train_df.iloc[error_list[i]]['id']))\n    plt.title(\"true={}\\npredict={}\".format(train_Y[error_list[i]], \n                                           pred_dev[error_list[i]]), y=1)\n    plt.axis('off')\nplt.subplots_adjust(wspace=0.3, hspace=-0.1)\nplt.show()","f7a0a225":"# predict on test set\npredictions = model.predict(test_pic_array)\nprint(predictions.shape)","b8f2967e":"test_df['has_cactus'] = predictions\ntest_df.head()","4d56f939":"# generate submission file in csv format\ntest_df.to_csv('submission.csv', index=False)","d3213633":"#### Here are some images from the training data that are labelled negative, i.e. no cactus:","8167fa09":"#### Comparing the two sets of images, I see that it looks relatively easy for a person to label the images. Those images with cactus typically have line-like shapes in the images. So I expect that an accuracy of above 90% would be easily attained with a CNN.","d557940a":"# Predictions","2314662d":"# Prepare the data for use in CNN","f79bf765":"Started on 11 Jun 2019","f799467e":"# Examine the data","a86d0bb9":"* Set up a dev set to check the performance of the CNN","1a1acd45":"* Let's get a sense of the images labelled 'has_cactus' and those without cactus.\n* I use the image preprocessing functions available in Keras. Keras also has function to convert the jpg pixels into tensors for the purpose of applying neural network.","568ca603":"#### Following from working on [Digit Recognizer][1] and [Fashion MNIST][2] using CNN, I decided to try my hand at this [Aerial Cactus Identification][3] problem. The approach is similar except that in this case, we are working with color images instead of gray-scale images in the other two problems.\n[1]: https:\/\/www.kaggle.com\/rhodiumbeng\/digit-recognizer-convolutional-neural-network\n[2]: https:\/\/www.kaggle.com\/rhodiumbeng\/fashion-mnist-convolutional-neural-network\n[3]: https:\/\/www.kaggle.com\/c\/aerial-cactus-identification","810c7561":"# Create CNN Model","3d707c04":"* In the [Digit Recognizer][1] and [Fashion MNIST][2] problems, I found it useful to use Keras' ImageDataGenerator to augment the training data as the number of training examples were small. Here, I think data augmentation will come in handy as well as there are only 17,500 examples in the training set.\n[1]: https:\/\/www.kaggle.com\/rhodiumbeng\/digit-recognizer-convolutional-neural-network\n[2]: https:\/\/www.kaggle.com\/rhodiumbeng\/fashion-mnist-convolutional-neural-network","2330fdea":"#### Run the model on the train and validation data, and capture metrics history to visualise the performance of the model","16e9056d":"* After 100 epochs, the loss was small and the accuracy reached for the validation data is above 99%.","806db560":"# Introduction","8150a780":"* The images (jpg) for the training data and test data can be found in the train and test folders. The filename of the jpg image files is also used as the unique 'id' in the csv files. \n* 'train_csv' contains the training data ('id' and label 'has_cactus') and 'sample_submission.csv' contains the test data 'id'. ","2c4eba2c":"#### Here are some images from the training data that are labelled as positive, i.e. has cactus:","9554ba5e":"* These are those in the validation set that were classified incorrectly. Any obvious patterns? I can't tell.","74ad306e":"# Error Analysis"}}