{"cell_type":{"14f73985":"code","0ebdf3da":"code","468a6ae0":"code","52c1cf16":"code","bfdb8f64":"code","ebcf6458":"code","251d07bd":"code","940b1dee":"code","abf42f78":"code","1fa9d475":"markdown","1a04adc7":"markdown","3bc9812f":"markdown","5b1ef8a5":"markdown","c6bf16ba":"markdown","57031d16":"markdown","0f4418d6":"markdown","e57c9715":"markdown","68d063ea":"markdown"},"source":{"14f73985":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0ebdf3da":"import matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\n%matplotlib inline","468a6ae0":"x = -2 * np.random.rand(150, 2)","52c1cf16":"x1 = 1+3 * np.random.rand(50, 2)\nx2 = 10+2 * np.random.rand(50, 2)\nx[50:100, :] = x1\nx[100:150, :] = x2\nplt.scatter(x[:, 0], x[:, 1], s=50, c='b')\nplt.show()","bfdb8f64":"Kmean = KMeans(n_clusters=3)\nKmean.fit(x)\nprint(Kmean)","ebcf6458":"cluster_centers = Kmean.cluster_centers_\nprint(cluster_centers)","251d07bd":"plt.scatter(x[:, 0], x[:, 1], s=50, c='b')\nplt.scatter(cluster_centers[0, 0], cluster_centers[0, 1], s=200, c='red')\nplt.scatter(cluster_centers[1, 0], cluster_centers[1, 1], s=200, c='green')\nplt.scatter(cluster_centers[2, 0], cluster_centers[2, 1], s=200, c='yellow')\nplt.show()","940b1dee":"print(Kmean.labels_)","abf42f78":"sample_test = np.array([-12, -10])\nsample_test = sample_test.reshape(1, -1)\ntype = Kmean.predict(sample_test)\nprint(type)","1fa9d475":"Initialize vector x containing random values","1a04adc7":"Below imports KMeans model provided by Scikit-learn","3bc9812f":"Check whether a value belongs to which cluster.","5b1ef8a5":"Plot to visualize cluster centroids' distribution.","c6bf16ba":"Intialize KMeans model with no. of clusters and train with x.","57031d16":"Get cluster labels of the trained model.","0f4418d6":"Get cluster centroids.","e57c9715":"Initialize few more vectors containing random values within different ranges and combine them to x. Then plot its distribution.","68d063ea":"Here I implemented and tested the code provided by this article's -> https:\/\/towardsdatascience.com\/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1 author. I made few changes for testing and to improve my understanding."}}