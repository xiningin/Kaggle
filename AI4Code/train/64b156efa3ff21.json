{"cell_type":{"d097fde4":"code","f8114dfa":"code","accd8d81":"code","51a330ee":"code","1ef64fda":"code","43c4f08c":"code","3ea6edb6":"code","5baf437e":"code","e32eb5b3":"code","d5efc56c":"code","49471cba":"code","fcfff423":"code","f7b5a804":"code","df3af863":"code","90118f53":"code","8eea4009":"code","cfbdc31a":"code","983a3e2a":"code","be88a954":"code","b06d34d3":"code","14799031":"code","0be89de5":"code","e4cfde91":"code","1b46efda":"code","d04ef13e":"code","cec91caf":"code","1c26487d":"code","420ab62d":"code","111feeac":"code","70d30a7e":"code","16bf70a1":"code","efaee795":"code","204678ff":"code","0408ecb7":"markdown","dd0fbd35":"markdown","17ec47e2":"markdown","4f7e72e6":"markdown"},"source":{"d097fde4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f8114dfa":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","accd8d81":"import re\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.metrics import roc_curve, roc_auc_score\n\n\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier","51a330ee":"def preprecess(data):\n    data.Cabin.fillna(\"N\", inplace = True)\n    data.loc[data.Cabin.str[0] == \"A\", \"Cabin\"] = \"A\"\n    data.loc[data.Cabin.str[0] == \"B\", \"Cabin\"] = \"B\"\n    data.loc[data.Cabin.str[0] == \"C\", \"Cabin\"] = \"C\"\n    data.loc[data.Cabin.str[0] == \"D\", \"Cabin\"] = \"D\"\n    data.loc[data.Cabin.str[0] == \"E\", \"Cabin\"] = \"E\"\n    data.loc[data.Cabin.str[0] == \"F\", \"Cabin\"] = \"F\"\n    data.loc[data.Cabin.str[0] == \"G\", \"Cabin\"] = \"G\"\n    data.loc[data.Cabin.str[0] == \"T\", \"Cabin\"] = \"N\"\n    \n    data[\"Sex\"].replace(\"female\", 1, inplace=True)\n    data[\"Sex\"].replace(\"male\", 0, inplace=True)   \n    \n    data[\"Age\"].fillna(data[\"Age\"].median(),inplace=True)\n    data[\"Fare\"].fillna(data[\"Fare\"].median(),inplace=True)\n    \n    data.Pclass.replace(1,\"First\",inplace=True)\n    data.Pclass.replace(2,\"Second\",inplace=True)\n    data.Pclass.replace(3,\"Third\",inplace=True)\n    \n    data = pd.get_dummies(data=data, columns=[\"Cabin\",\"Embarked\",\"Pclass\"])\n    \n    return data\n    \ndef age_detection(value):\n    if value < 18.0:\n        return \"kid\"\n    elif value >= 18.0 and value <=45.0:\n        return \"adult\"\n    else:\n        return \"mature\"\n        \n    \ndef group_title(data):\n    data[\"Title\"] = data[\"Name\"].map(lambda x: x.split(\",\")[1].split(\".\")[0].strip(\" \"))\n    data['Title'].replace('Master', \"A\", inplace=True)\n    data['Title'].replace('Mr', \"B\", inplace=True)\n    data['Title'].replace(['Ms','Mlle', 'Miss'], \"C\", inplace=True)\n    data['Title'].replace(['Mme', 'Mrs'], \"D\", inplace=True)\n    data['Title'].replace(['Dona', 'Lady', 'the Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'the'], \"E\", inplace=True)\n    data = pd.get_dummies(data=data, columns=[\"Title\"])\n    return data \n\ndef outlier(data):\n    for column in [\"Age\", \"Fare\"]:\n        for sex in data.Sex.unique():\n            sex_data = data[data[\"Sex\"] == sex]\n            sex_column = sex_data[column]\n        \n            Q1 = np.percentile(sex_column,25)\n            Q3 = np.percentile(sex_column,75)\n            IQR = Q3 - Q1\n            STEP = 1.5 * IQR\n            MAX_BORDER = Q3 + STEP\n            MIN_BORDER = Q1 - STEP\n        \n            data.loc[(data[\"Sex\"] == sex) & (data[column] > MAX_BORDER), column] = MAX_BORDER\n            data.loc[(data[\"Sex\"] == sex) & (data[column] < MIN_BORDER), column] = MIN_BORDER       \n    return data\n\ndef scaler(data):\n    data[\"Age\"] = StandardScaler().fit_transform(data[[\"Age\"]])\n    data[\"Fare\"] = StandardScaler().fit_transform(data[[\"Fare\"]])\n    return data","1ef64fda":"train = outlier(train)\ntest = outlier(test)\ntrain[\"Age_Detection\"] = train[\"Age\"].apply(age_detection)\ntest[\"Age_Detection\"] = test[\"Age\"].apply(age_detection)\ntrain = pd.get_dummies(data = train, columns = [\"Age_Detection\"])\ntest = pd.get_dummies(data = test, columns = [\"Age_Detection\"])\ntrain = preprecess(train)\ntrain = group_title(train)\ntest = preprecess(test)\ntest = group_title(test)\ntrain = scaler(train)\ntest = scaler(test)\ntrain.drop([\"Name\",\"Ticket\"],axis = 1 ,inplace = True)\ntest.drop([\"Name\",\"Ticket\"],axis = 1 ,inplace = True)","43c4f08c":"train.drop(\"PassengerId\", axis = 1, inplace=True)","3ea6edb6":"y = train.Survived\nX = train.drop(\"Survived\", axis=1)","5baf437e":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 1845)","e32eb5b3":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","d5efc56c":"xgb_params = {\n    'n_estimators' : [100,300,500,700],\n    'subsample' : [0.6, 0.8, 1.0],\n    'max_depth' : [3,4,5,6],\n    'learning_rate' : [0.1, 0.01, 0.02, 0.05],\n    'min_samples_split' : [2,5,10]\n    \n}\n\n\nxgb = XGBClassifier()\n\nxgb_cv_model = GridSearchCV(xgb, xgb_params, cv = 10, n_jobs = -1, verbose = 2)","49471cba":"xgb_cv_model.fit(X_train, y_train)","fcfff423":"xgb_cv_model.best_params_","f7b5a804":"xgb = XGBClassifier(learning_rate = 0.1,\n                    max_depth = 5,\n                    n_estimators = 100,\n                    subsample = 0.8)\n","df3af863":"xgb_tuned = xgb.fit(X_train,y_train)","90118f53":"y_pred = xgb_tuned.predict(X_test)","8eea4009":"accuracy_score(y_test,y_pred)","cfbdc31a":"print(classification_report(y_test,y_pred))","983a3e2a":"xgb_roc_auc = roc_auc_score(y_test, xgb_tuned.predict(X_test))\nfpr, tpr, thresholds = roc_curve(y_test, xgb_tuned.predict_proba(X_test)[:,1])\n\nplt.figure()\nplt.plot(fpr, tpr, label = \"AUC (area = %0.2f)\"% xgb_roc_auc)\nplt.plot([0,1],[0,1], 'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC\")\nplt.legend(loc=\"lower right\", fontsize=16)\nplt.show()","be88a954":"lgbm_params = {\n    'n_estimators' : [100,300],\n    'subsample' : [0.6, 0.8, 1.0],\n    'max_depth' : [3,4,5,6],\n    'learning_rate' : [0.1, 0.01, 0.02, 0.05],\n    'min_child_samples' : [5,10,20]    \n}\n\n\nlgbm = LGBMClassifier()\n\nlgbm_cv_model = GridSearchCV(lgbm, lgbm_params, cv=10, n_jobs=-1, verbose = 2)","b06d34d3":"lgbm_cv_model.fit(X_train,y_train)","14799031":"lgbm_cv_model.best_params_","0be89de5":"lgbm = LGBMClassifier(learning_rate = 0.1,\n                    max_depth = 4,\n                    min_child_samples = 10,\n                    n_estimators = 100,\n                    subsample = 0.6)\n","e4cfde91":"lgbm_mode = lgbm.fit(X_train,y_train)","1b46efda":"y_pred = lgbm_mode.predict(X_test)","d04ef13e":"accuracy_score(y_test, y_pred)","cec91caf":"print(classification_report(y_test,y_pred))","1c26487d":"lgbm_roc_auc = roc_auc_score(y_test, lgbm_mode.predict(X_test))\nfpr, tpr, thresholds = roc_curve(y_test, lgbm_mode.predict_proba(X_test)[:,1])\n\nplt.figure()\nplt.plot(fpr, tpr, label = \"AUC (area = %0.2f)\"% lgbm_roc_auc)\nplt.plot([0,1],[0,1], 'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC\")\nplt.legend(loc=\"lower right\", fontsize=16)\nplt.show()","420ab62d":"test_id = test.PassengerId\ntest.drop(\"PassengerId\", axis=1, inplace=True)","111feeac":"xgb = XGBClassifier(learning_rate = 0.1,\n                    max_depth = 6,\n                    n_estimators = 100,\n                    subsample = 0.8)\n","70d30a7e":"xgb_model = xgb.fit(X,y)","16bf70a1":"test_pred = xgb_model.predict(test)","efaee795":"submission = pd.DataFrame({\"PassengerId\" : test_id, \"Survived\" : test_pred})","204678ff":"submission.to_csv(\"submission.csv\",index=False)","0408ecb7":"## Model","dd0fbd35":"### XGBOOST","17ec47e2":"## Test Prediction","4f7e72e6":"### LightGBM"}}