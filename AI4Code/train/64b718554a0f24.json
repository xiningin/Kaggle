{"cell_type":{"524cb2e9":"code","b7f6a900":"code","f3ec8496":"code","9794e04b":"code","291eade4":"code","ce3bd11b":"code","bf5a6c6d":"code","2d36bd6f":"code","4bf6abe0":"code","7f1a87a2":"code","a7f7bb66":"code","ad4b4500":"code","bdff067f":"markdown","6f81f3f0":"markdown","ff0f2b63":"markdown","ec6e3f67":"markdown","b0e94e59":"markdown","60b56cec":"markdown","3d735180":"markdown"},"source":{"524cb2e9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b7f6a900":"import pandas as pd\nimport numpy as np\n\nimport torch\nimport torchvision.datasets as data\nimport torchvision.transforms as transforms\nimport random\n\nfrom sklearn import preprocessing\n","f3ec8496":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nrandom.seed(777)\ntorch.manual_seed(777)\n\nif device == 'cuda':\n  torch.cuda.manual_seed_all(777)","9794e04b":"learning_rate = 1e-4\ntraining_epoches = 100\nbatch_size = 50\nScaler = preprocessing.StandardScaler()","291eade4":"train_data = pd.read_csv('train.csv')\ntest_data = pd.read_csv('test.csv')\n\ntrain_data.drop(['snowFall','deepSnowfall'], axis=1, inplace=True)\ntest_data.drop(['snowFall','deepSnowfall'], axis=1, inplace=True)\ntrain_data = train_data.fillna(0)\ntest_data = test_data.fillna(0)\n\nx_train = train_data.loc[:,'avgTemp':'fogDuration']\ny_train = train_data['trafficAccident']\n\nx_train = np.array(x_train)\ny_train = np.array(y_train)\n\nx_train = torch.FloatTensor(x_train)\ny_train = torch.FloatTensor(y_train)\n\nprint(x_train)\nprint(y_train)\n","ce3bd11b":"\ntrain_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n\ndata_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n                                          batch_size = batch_size,\n                                          shuffle = True,\n                                          drop_last=True)","bf5a6c6d":"linear1 = torch.nn.Linear(6,64, bias = True) # feature\nlinear2 = torch.nn.Linear(64,64, bias = True)\nlinear3 = torch.nn.Linear(64,32, bias = True)\nlinear4 = torch.nn.Linear(32,32, bias = True)\nlinear5 = torch.nn.Linear(32,32, bias = True)\nlinear6 = torch.nn.Linear(32,32, bias = True)\nlinear7 = torch.nn.Linear(32,16, bias = True)\nlinear8 = torch.nn.Linear(16,16, bias = True)\nlinear9 = torch.nn.Linear(16,8, bias = True)\nlinear10 = torch.nn.Linear(8,8, bias = True)\nlinear11 = torch.nn.Linear(8,4, bias = True)\nlinear12 = torch.nn.Linear(4,1, bias = True)\n\n\ntorch.nn.init.xavier_uniform_(linear1.weight)\ntorch.nn.init.xavier_uniform_(linear2.weight)\ntorch.nn.init.xavier_uniform_(linear3.weight)\ntorch.nn.init.xavier_uniform_(linear4.weight)\ntorch.nn.init.xavier_uniform_(linear5.weight)\ntorch.nn.init.xavier_uniform_(linear6.weight)\ntorch.nn.init.xavier_uniform_(linear7.weight)\ntorch.nn.init.xavier_uniform_(linear8.weight)\ntorch.nn.init.xavier_uniform_(linear9.weight)\ntorch.nn.init.xavier_uniform_(linear10.weight)\ntorch.nn.init.xavier_uniform_(linear11.weight)\ntorch.nn.init.xavier_uniform_(linear12.weight)\n\nmodel = torch.nn.Sequential(linear1,\n                            linear2,\n                            linear3,\n                            linear4,\n                            linear5,\n                            linear6,\n                            linear7,\n                            linear8,\n                            linear9,\n                            linear10,\n                            linear11,\n                            linear12\n                            ).to(device)\n","2d36bd6f":"loss = torch.nn.MSELoss().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","4bf6abe0":"total_batch = len(data_loader)\n\nfor epoch in range(training_epoches):\n  avg_cost = 0\n\n  for X, Y in data_loader:\n\n    X = X.to(device)\n    Y = Y.to(device)\n\n    optimizer.zero_grad()\n    hypothesis = model(X)\n    cost = loss(hypothesis, Y)\n    cost.backward()\n    optimizer.step()\n\n    avg_cost += cost \/ total_batch\n  \n  print('Epoch:','%04d' % (epoch+1), 'cost=', '{:.9f}'.format(avg_cost))\nprint('Learning finshed')","7f1a87a2":"\nwith torch.no_grad():\n  x_test = test_data.loc[:,'avgTemp':'fogDuration']\n  x_test = np.array(x_test)\n  #x_test = Scaler.transform(x_test)\n  x_test = torch.from_numpy(x_test).float()\n\n  prediction = model(x_test)\n  correct_prediction = prediction.cpu().numpy().reshape(-1,1)\n ","a7f7bb66":"\nsubmit = pd.read_csv('submit_sample.csv')\n\nfor i in range(len(correct_prediction)):\n  submit['Expected'][i] = correct_prediction[i].item()\n\nsubmit","ad4b4500":"submit.to_csv('submit.csv', mode='w', index = False)\n!kaggle competitions submit -c traffic-accident -f submit.csv -m \"Message\"","bdff067f":"\ub370\uc774\ud130 \ub2e4\uc6b4\ubc1b\uace0 \uc815\ub9ac\ud558\uae30 ","6f81f3f0":"\uc608\uce21\uac12\uc744 \uc81c\ucd9c \uc591\uc2dd\uc5d0 \ub123\uae30 ","ff0f2b63":"\ubaa8\ub4c8 \uc784\ud3ec\ud2b8","ec6e3f67":"\ubaa8\ub378 \ud559\uc2b5\ud558\uae30 ","b0e94e59":"layer\uc758 \uac1c\uc218\uc640 \uc740\ub2c9 \ub808\uc774\uc5b4\uc758 \uac12 \uc870\uc808\n\n> \uae30\uc874\uc5d0 \ubca0\uc774\uc2a4 \ub77c\uc778 \ucf54\ub4dc\ub294 5\uac1c\uc758 \uc740\ub2c9 \ub808\uc774\uc5b4\ub97c \uc0ac\uc6a9\ud558\ub294\ub370 \uc774\ub97c 12\uac1c\ub85c \uc99d\uac00 \uc2dc\ucf30\ub2e4.  \n\uadf8\ub9ac\uace0 \uadf8 \uc548\uc5d0 \ub4e4\uc5b4\uac00\ub294 \uac12\ub3c4 6-->4-->2-->1 \uc5d0\uc11c 6-->64-->32-->16-->8-->4-->1\ub85c \ubcc0\uacbd\ud574\uc11c \ubaa8\ub378\uc744 \uc7ac\uc124\uacc4\ud588\ub2e4. \n\n","60b56cec":"\ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\ub85c \uc608\uce21 \uac12 \uad6c\ud558\uae30 ","3d735180":"learning rate \uc758 \uac12\uc744 \uae30\uc874\uc758 \ubca0\uc774\uc2a4\ub77c\uc778 \ucf54\ub4dc\uc5d0\uc11c\ub294 0.01--> 1e-4\ub85c \ubc14\uafc8\ntraining epoches\ub97c \uc880 \ub354 \ud06c\uac8c \uc124\uacc4 62-->100"}}