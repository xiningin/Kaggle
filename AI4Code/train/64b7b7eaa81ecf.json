{"cell_type":{"2336eb73":"code","e59a296b":"code","7ae5b6c7":"code","89329a0e":"code","c83aa065":"code","0d69e730":"code","152eeb70":"code","e6902dc4":"code","d3f76733":"code","9f7ac3b9":"code","b878e92a":"code","7884d21c":"code","b7c80704":"code","889f8de2":"code","cd31efb1":"code","79d58d98":"code","68cffb36":"code","5d6ac13f":"code","1cd9e88b":"code","9a190765":"code","5ad01bff":"markdown","20531c6e":"markdown","11b16709":"markdown","04bf8294":"markdown"},"source":{"2336eb73":"\nimport tensorflow_datasets as tfds\nimport tensorflow as tf\nimport keras\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.utils import plot_model\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy as sp\nimport cv2","e59a296b":"train_data = tfds.load('cats_vs_dogs', split='train[:80%]', as_supervised=True)\nvalidation_data = tfds.load('cats_vs_dogs', split='train[80%:90%]', as_supervised=True)\ntest_data = tfds.load('cats_vs_dogs', split='train[-10%:]', as_supervised=True)","7ae5b6c7":"def augment_images(image, label):\n    image = tf.cast(image, tf.float32)\n    image = (image\/255)\n    image = tf.image.resize(image, (300, 300))\n    return image, label","89329a0e":"augmented_training_data = train_data.map(augment_images)\ntrain_batches = augmented_training_data.shuffle(1024).batch(32)","c83aa065":"model = Sequential()\nmodel.add(Conv2D(16, input_shape=(300, 300, 3), kernel_size=3, activation='relu', padding='same', name='conv1'))\nmodel.add(MaxPooling2D(pool_size=2, name='maxpool1'))\nmodel.add(Conv2D(32, kernel_size=3, activation='relu', padding='same', name='conv2'))\nmodel.add(MaxPooling2D(pool_size=2, name='maxpool2'))\nmodel.add(Conv2D(64, kernel_size=3, activation='relu', padding='same', name='conv3'))\nmodel.add(MaxPooling2D(pool_size=2, name='maxpool3'))\nmodel.add(Conv2D(128, kernel_size=3, activation='relu', padding='same', name='conv4'))\nmodel.add(GlobalAveragePooling2D(name='gap'))\nmodel.add(Dense(1, activation='sigmoid', name='output'))\nmodel.summary()\n","0d69e730":"model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.RMSprop(lr=0.001), metrics=['accuracy'])","152eeb70":"plot_model(model, show_layer_names=True, show_shapes=True)","e6902dc4":"# train the model\nmodel.fit(train_batches, epochs=25)","d3f76733":"model.save('CatsVsDogs.h5')","9f7ac3b9":"from IPython.display import FileLink","b878e92a":"# Download the model and upload to the input so we can use it in the future without having to retrain\nFileLink('CatsVsDogs.h5')","7884d21c":"# Load model\nmodel = tf.keras.models.load_model('CatsVsDogs.h5')","b7c80704":"gap_weights = model.get_layer('output').get_weights()[0]","889f8de2":"print(gap_weights.shape)","cd31efb1":"cam_model = Model(inputs=model.input, outputs=[model.get_layer('conv4').output, model.get_layer('output').output])\ncam_model.summary()\nplot_model(cam_model, show_shapes=True, show_layer_names=True)","79d58d98":"def show_cam(image_value, features, results):\n    '''\n    Displays the class activation map of an image\n    Args:\n        image_value (tensor) -- preprocessed ijnput image with size 300x300\n        features (array) -- features of the image, shape (1, 37, 37, 128)\n        results (array) -- output of the sigmoid layer (cat or dog)\n    '''\n    # Therte is only one image in teh bach so we index at 0\n    features_for_img = features[0]\n    prediction = results[0]\n    \n    # There is only one unit in the ouptut so we can get the weights connected to it\n    class_activation_weights = gap_weights[:, 0]\n    \n    # upsample to the image size\n    class_activation_features = sp.ndimage.zoom(features_for_img, (300\/37, 300\/37, 1), order=2)\n    \n    # compute the intensity of each feature in the CAM\n    cam_output = np.dot(class_activation_features, class_activation_weights)\n    \n    # visualize the results\n    print(f'sigmoid output: {results}')\n    print(f'prediction: {\"dog\" if round(results[0][0]) else \"cat\"}')\n    plt.figure(figsize=(8, 8))\n    plt.imshow(cam_output, cmap='jet', alpha=0.5)\n    plt.imshow(tf.squeeze(image_value), alpha=0.5)\n    plt.show()","68cffb36":"!wget -O cat1.jpg https:\/\/storage.googleapis.com\/laurencemoroney-blog.appspot.com\/MLColabImages\/cat1.jpg\n!wget -O cat2.jpg https:\/\/storage.googleapis.com\/laurencemoroney-blog.appspot.com\/MLColabImages\/cat2.jpg\n!wget -O catanddog.jpg https:\/\/storage.googleapis.com\/laurencemoroney-blog.appspot.com\/MLColabImages\/catanddog.jpg\n!wget -O dog1.jpg https:\/\/storage.googleapis.com\/laurencemoroney-blog.appspot.com\/MLColabImages\/dog1.jpg\n!wget -O dog2.jpg https:\/\/storage.googleapis.com\/laurencemoroney-blog.appspot.com\/MLColabImages\/dog2.jpg","5d6ac13f":"def convert_and_classify(image):\n    # Load the image\n    img = cv2.imread(image)\n    # Preprocess teh image before feeding it to the model\n    img = cv2.resize(img, (300, 300))\/255.0\n    tensor_image = np.expand_dims(img, axis=0)\n    features, results = cam_model.predict(tensor_image)\n    show_cam(tensor_image, features, results)","1cd9e88b":"convert_and_classify('cat1.jpg')\nconvert_and_classify('cat2.jpg')\nconvert_and_classify('catanddog.jpg')\nconvert_and_classify('dog1.jpg')\nconvert_and_classify('dog2.jpg')","9a190765":"augmented_test_data = test_data.map(augment_images)\ntest_batches = augmented_test_data.batch(1)\nfor img, lbl in test_batches.take(5):\n    print(f'ground truth: {\"dog\" if lbl else \"cat\"}')\n    features, results = cam_model.predict(img)\n    show_cam(img, features, results)","5ad01bff":"# Building the CAM model","20531c6e":"Learned from Coursera: Advanced Computer Vision with TensorFlow.","11b16709":"# Build The Classifier","04bf8294":"# Download and prepare the dataset\n"}}