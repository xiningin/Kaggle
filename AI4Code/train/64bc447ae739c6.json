{"cell_type":{"6ecdeec8":"code","795bacf8":"code","ee5e5f45":"code","a24cc6bb":"code","b6078bc4":"code","b1b85b70":"code","e57ba6e0":"code","f05b8ab0":"code","8b09a7d3":"code","07ea3848":"code","d3b13db4":"code","d4302153":"code","518bdd4e":"code","d2ed8f90":"code","8b7c2d2c":"code","ee5636a9":"code","024ac67d":"code","0c8642b6":"code","d2ca1eaa":"code","593af7ca":"code","ddc25e4f":"code","c2ae435f":"code","5d75e136":"code","0d3ad33b":"code","8d58d1ef":"code","b817767d":"code","82e46e14":"code","271dab2a":"code","e6443475":"code","9ee6e30b":"code","c87e1329":"code","f2c77f14":"code","ba972165":"code","d89f29d3":"code","25203575":"code","e6db0810":"code","9331003f":"code","414cd8c8":"code","a34b2ab0":"code","07f478b3":"code","434fc59e":"markdown","cd01180b":"markdown","8de1e95d":"markdown","524e0e3d":"markdown","9dfcd90f":"markdown","29866f79":"markdown","86203e75":"markdown","bb9c8350":"markdown","3943fc8b":"markdown","b6771309":"markdown","fe3f3c50":"markdown","354280d4":"markdown","9b64e2b3":"markdown","6fdd53f0":"markdown","2e6d5b4f":"markdown","d5b30386":"markdown","9f8ca13e":"markdown","c15d83f0":"markdown","b89c7353":"markdown","686506c6":"markdown","4e52a0a0":"markdown","f57f9c32":"markdown","6ea76a22":"markdown","273e154a":"markdown","e85e7abc":"markdown","b782888b":"markdown","3223f8b4":"markdown","f08ce345":"markdown","63dec88b":"markdown","b875b7ab":"markdown","73daff86":"markdown","4087e32a":"markdown","515ff093":"markdown","0506961f":"markdown","29bc4ce7":"markdown","a509f3f6":"markdown","47087b97":"markdown","a2a80bfe":"markdown","20306c89":"markdown","317dca39":"markdown","cf92e851":"markdown","b7ceefee":"markdown","6f0d632d":"markdown","409ed92d":"markdown","12614127":"markdown","bc26c235":"markdown","6818ec92":"markdown","e8ab8917":"markdown","6b934f94":"markdown","556792f2":"markdown","1c0322f2":"markdown","1f69c6e3":"markdown","640f57f4":"markdown","1de6de2e":"markdown"},"source":{"6ecdeec8":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","795bacf8":"from sklearn.preprocessing import StandardScaler,LabelEncoder\nfrom sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier,VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import StratifiedKFold,GridSearchCV,learning_curve,cross_val_score","ee5e5f45":"train=pd.read_csv('..\/input\/titanic\/train.csv')\ntest=pd.read_csv('..\/input\/titanic\/test.csv')\ndf=pd.concat([train,test],axis=0,ignore_index=True)\nprint(f'Train:{train.shape}\\nTest:{test.shape}\\nDf:{df.shape}')","a24cc6bb":"df.head()","b6078bc4":"#columns with missing values\ndf.isnull().sum()[df.isnull().sum()>0]","b1b85b70":"df.describe().T","e57ba6e0":"# only describing the categorical columns\ndf.describe(exclude='number')","f05b8ab0":"#Let's draw a heatmap of correlation between the features\nplt.figure(figsize=(12,7))\nsns.heatmap(df.drop('PassengerId',axis=1).corr(),annot=True,center=0)","8b09a7d3":"g=sns.FacetGrid(train,col='Survived').map(sns.distplot,'Age',hist=False,kde=True,rug=False,kde_kws={'shade':True})","07ea3848":"sns.catplot(x='Pclass',y='Survived',data=train,kind='bar')","d3b13db4":"sns.catplot(x='Sex',y='Survived',hue='Pclass',data=train,kind='bar')","d4302153":"sns.catplot(x=\"Embarked\", y=\"Survived\", data=train, kind=\"bar\")","518bdd4e":"df['Family_Size']=df['Parch']+df['SibSp']\ndf.groupby('Family_Size')['Survived'].mean()","d2ed8f90":"sns.catplot(x='Family_Size',y='Survived',data=df,kind='bar')","8b7c2d2c":"#converting the sex column into numerical column\ndf.Sex=df.Sex.map({'male':0,'female':1}).astype('int')","ee5636a9":"df['Title'] = df['Name']\n\nfor name_string in df['Name']:\n    df['Title'] = df['Name'].str.extract('([A-Za-z]+)\\.', expand=True)\n\nmapping = {'Mlle': 'Miss', 'Major': 'Mr', 'Col': 'Mr', 'Sir': 'Mr', 'Don': 'Mr', 'Mme': 'Miss',\n          'Jonkheer': 'Mr', 'Lady': 'Mrs', 'Capt': 'Mr', 'Countess': 'Mrs', 'Ms': 'Miss', 'Dona': 'Mrs'}\n\ndf.replace({'Title': mapping}, inplace=True)","024ac67d":"sns.barplot(x='Title',y='Survived',data=df.iloc[:len(train)])","0c8642b6":"df[df['Fare'].isnull()]","d2ca1eaa":"df['Fare'].fillna(df['Fare'].mean(), inplace=True)","593af7ca":"df['FareBin'] = pd.qcut(df['Fare'], 5)\n\nlabel = LabelEncoder()\ndf['FareBin_Code'] = label.fit_transform(df['FareBin'])\ndf.drop(['Fare'], 1, inplace=True)","ddc25e4f":"df['FareBin_Code'].value_counts()","c2ae435f":"embarked=pd.get_dummies(df['Embarked'],drop_first=True)\ndf=pd.concat([df,embarked],axis=1)","5d75e136":"#  def fix_age(cols):\n#     Age=cols[0]\n#     Pclass=cols[1]\n    \n#     if pd.isnull(Age):\n#         if Pclass==1:\n#             return 37 \n#         elif Pclass==2:\n#             return 29\n#         else:\n#             return 24\n#     else:\n#         return Age ","0d3ad33b":"# df['Age']=df[['Age','Pclass']].apply(fix_age,axis=1)","8d58d1ef":"# filling missing values in 'age' column\ntitles = ['Dr', 'Master', 'Miss', 'Mr', 'Mrs', 'Rev']\n\nfor title in titles:\n    age_to_impute = df.groupby('Title')['Age'].median()[titles.index(title)]\n    df.loc[(df['Age'].isnull()) & (df['Title'] == title), 'Age'] = age_to_impute","b817767d":"df['Age'].isnull().sum()","82e46e14":"df['AgeBin'] = pd.qcut(df['Age'], 4)\n\nlabel = LabelEncoder()\ndf['AgeBin_Code'] = label.fit_transform(df['AgeBin'])","271dab2a":"df.sample(2)","e6443475":"df['AgeBin_Code'].value_counts()","9ee6e30b":"df.loc[(df['Cabin'].isnull()),'Cabin_status'] = 0\ndf.loc[(df['Cabin'].notnull()),'Cabin_status']=1\ndf.Cabin_status.astype('int')","c87e1329":"sns.barplot(x='Cabin_status',y='Survived',data=df.iloc[:len(train)])","f2c77f14":"df.drop(['Name', 'PassengerId', 'SibSp', 'Parch', 'Ticket', 'Cabin','Embarked',\n                 'FareBin', 'AgeBin', 'Survived', 'Title', 'Age'], axis = 1, inplace = True)","ba972165":"df.sample(2)","d89f29d3":"X_train = df[:len(train)]\nX_test = df[len(train):]\n\ny_train = train['Survived']","25203575":"scaler = StandardScaler()\n\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","e6db0810":"kfold = StratifiedKFold(n_splits=8)","9331003f":"RFC = RandomForestClassifier()\n\nrf_param_grid = {\"max_depth\": [None],\n              \"max_features\": [3,\"sqrt\", \"log2\"],\n              \"min_samples_split\": [n for n in range(1, 9)],\n              \"min_samples_leaf\": [5, 7],\n              \"bootstrap\": [False, True],\n              \"n_estimators\" :[200, 500],\n              \"criterion\": [\"gini\", \"entropy\"]}\n\nrf_param_grid_best = {\"max_depth\": [None],\n              \"max_features\": [3],\n              \"min_samples_split\": [4],\n              \"min_samples_leaf\": [5],\n              \"bootstrap\": [False],\n              \"n_estimators\" :[200],\n              \"criterion\": [\"gini\"]}\n\ngs_rf = GridSearchCV(RFC, param_grid = rf_param_grid_best, cv=kfold, scoring=\"roc_auc\", n_jobs= 4, verbose = 1)\n\ngs_rf.fit(X_train, y_train)\n\nrf_best = gs_rf.best_estimator_\nRFC.fit(X_train, y_train)","414cd8c8":"print(f'RandomForest GridSearch best params: {gs_rf.best_params_}\\n')\nprint(f'RandomForest GridSearch best score: {gs_rf.best_score_}')\nprint(f'RandomForest score:                 {RFC.score(X_train,y_train)}')","a34b2ab0":"XGB = XGBClassifier()\n\nxgb_param_grid = {'learning_rate':[0.05, 0.1], \n                  'reg_lambda':[0.3, 0.5],\n                  'gamma': [0.8, 1],\n                  'subsample': [0.8, 1],\n                  'max_depth': [2, 3],\n                  'n_estimators': [200, 300]\n              }\n\nxgb_param_grid_best = {'learning_rate':[0.1], \n                  'reg_lambda':[0.3],\n                  'gamma': [1],\n                  'subsample': [0.8],\n                  'max_depth': [2],\n                  'n_estimators': [300]\n              }\n\ngs_xgb = GridSearchCV(XGB, param_grid = xgb_param_grid_best, cv=kfold, scoring=\"roc_auc\", n_jobs= 4, verbose = 1)\n\ngs_xgb.fit(X_train,y_train)\nXGB.fit(X_train, y_train)\n\nxgb_best = gs_xgb.best_estimator_\n\n\nprint(f'XGB GridSearch best params: {gs_xgb.best_params_}\\n')\nprint(f'XGB GridSearch best score: {gs_xgb.best_score_}')\nprint(f'XGB score:                 {XGB.score(X_train,y_train)}')","07f478b3":"results=pd.DataFrame({'PassengerId':test['PassengerId'], 'Survived':RFC.predict(X_test)})\nresults.to_csv(\"submission.csv\", header=True,index=False)\n\nprint(\"The submission file is ready, here's a sample of it!\")\nprint(results.sample(2))","434fc59e":"<a id=\"section1\"><\/a>\n## Importing the libraries\n\n### [Back To Table of Contents](#toc_section)","cd01180b":"<a id=\"section6\"><\/a>\n### Converting Sex column to numerical type\n","8de1e95d":"Here's how you can fill missing ages using the Pclass column as reference.","524e0e3d":"<a id=\"section10\"><\/a>\n### Filling and Encoding the Age feature\n","9dfcd90f":"Let's read the data , both train and test one and to make sure that they are in the same format we will for the time being concatinate them so that both have the same operations","29866f79":"After all the dropped columns , our data must be clean and not-so-long , let's see for ourselves","86203e75":"Now let us encode the age column into 4 parts. ","bb9c8350":"Let's see for missing values in the Fare column.","3943fc8b":"But wait what about the Cabin column , like you i also thought that with so many missing values , I should just drop it but i thought of something , made a column with people having cabin(entry with cabin !=Nan) and people not having a cabin (entry with cabin column = Nan) ,and it actually has a great effect on the survival chances.","b6771309":"<a id=\"section3\"><\/a>\n## Visualizing given dataset\n\n### [Back To Table of Contents](#toc_section)","fe3f3c50":"Now let's encode the Fare column into 5 categories.I am using LabelEncoder from sklearn here.","354280d4":"<a id=\"section13\"><\/a>\n# Modelling\n\nSince preprocessing is done we are ready for training our models. We start with loading packages and splitting our transformed data so we have 22 features and and 891 observations to train our estimators. Our test set has 418 observations to make predictions.\n\n### [Back To Table of Contents](#toc_section)","9b64e2b3":"<a id=\"section11\"><\/a>\n### Do not make this mistake !","6fdd53f0":"As there is only one missing value , we can easily fill it up by either mean or median of the column , I am using mean here.","2e6d5b4f":"What about the sex of a person , how does it affect a person's survival? Let's find out !","d5b30386":"Let's see how the encoded fare column looks.","9f8ca13e":"So finally , let's drop all the unnecessary columns.","c15d83f0":"So let's do it !","b89c7353":"Let's combine the Parch and SibSp feature to form a better Family_size feature ","686506c6":"<a id=\"sectionlst\"><\/a>\n#  Submission\n\n\n### [Back To Table of Contents](#toc_section)","4e52a0a0":"Now , we have to head towards the modelling and submision part , so let's split the data into it's initial train and test sets. ","f57f9c32":"<a id=\"section12\"><\/a>\n### Dropping the unnecessary features\n","6ea76a22":"The first thing we will do is see for any missing data in the dataset.","273e154a":"# <a id=\"top_section\"><\/a>\n\n<div align='center'><font size=\"6\" color=\"#000000\"><b>Titanic Survival Prediction : The beginner's way !<\/b><\/font><\/div>\n<hr>\n<div align='center'><font size=\"5\" color=\"#000000\">Introduction<\/font><\/div>\n<hr>\n\nWhen I started doing this analysis my main goal was getting experience. I'm still learning and trying to improve my skills, so there is a great chance that there will be some areas for improvement.\n<br><br>\nIn this notebook I will show you how a beginner (in this case ,me) approached the Titanic Survival prediction problem.I read a lot of notebooks of very experienced and helpful kagglers and watched some videos on youtube for better understanding. So without further ado , let's get this started!\n\n### Here are the things I will try to cover in this Notebook:\n\n- What is the survival rate for specific groups?\n- Is there any relation between given info of passengers and their survival?\n- Was women and children first policy in order?\n- Having higher social status in helped people getting in life boats?\n- The mustering order from captain was highly dependent on the class of the passengers, can we spot this  effect between pclass and the survival rates?\n- What are the effects of family size?\n\n- Can we predict if a passenger survived from the disaster with using machine learning techniques?\n\n### If you liked this kernel feel free to upvote and leave feedback, thanks!","e85e7abc":"<a id=\"toc_section\"><\/a>\n## Table of Contents\n* [Introduction](#top_section)\n* [Importing all the Required Libraries](#section1)\n* [Exploring the Data](#section2)\n    - [Visualizing given dataset](#section3)\n* [Building the Feature Engineering Machine](#section4)\n    - [Merging Parch and SibSp](#section5)\n    - [Converting Sex column to numerical type](#section6)\n    - [Extracting Title from Name](#section7)\n    - [Filling and Encoding the Fare feature](#section8)\n    - [Encoding the Embarked feature](#section9)\n    - [Filling and Encoding the Age feature](#section10)\n    - [Do not make this mistake !](#section11)\n    - [Dropping the unnecessary features](#section12)\n* [Modelling](#section13)\n* [Submission & Some Last Words](#sectionlst)\n","b782888b":"Now let's plot and analyze the age and survival correlation.","3223f8b4":"Now we will use the get_dummy method of pandas to encode the Embarked column.","f08ce345":"<a id=\"section4\"><\/a>\n## Building the Feature Engineering Machine\n\n### [Back To Table of Contents](#toc_section)\n","63dec88b":"Let's convert the Sex column from categorical to Numerical , will use the map function for this.","b875b7ab":"Now we are done with all the encoding and taking care of mising values stuff , let's drop the features that are not useful.","73daff86":"Mind taking a sneak peak in the dataset now ?","4087e32a":"Now , the time for taking care of the Age column is here, we have two options here either use Pclass or Title to help fill the missing age values , I first used the Pclass but , using the Title increased my score so here are both for you !","515ff093":"Let's make sure it's done !","0506961f":"Now let's see how the Family Size of a person affects his\/her chance of survival.","29bc4ce7":"Here's how you can fill missing ages using the Title column as reference.(this yield better results for me)","a509f3f6":"<a id=\"section9\"><\/a>\n### Encoding the Embarked feature\n","47087b97":"<img src=\"https:\/\/cloud.netlifyusercontent.com\/assets\/344dbf88-fdf9-42bb-adb4-46f01eedd629\/7543b6dd-a4db-46d7-9a46-9755c6399b0e\/puppy-thanks.jpg\" alt=\"Thank you!\" width=\"500\" height=\"600\">","a2a80bfe":"Let's see if the Title feature really is affecting the Survival chances or not!","20306c89":"We will take care of the missing data , but first we need to see how each feature is connected to one another and you'll see how it will help us to take care of the missing data as well as understand the data more clearly.","317dca39":"Now let's plot and analyse how the Passenger Class(Pclass in dataset) affects survival chances of a person.","cf92e851":"<a id=\"section2\"><\/a>\n## Exploring the data\n\n### [Back To Table of Contents](#toc_section)","b7ceefee":"<a id=\"section8\"><\/a>\n### Filling and Encoding the Fare feature\n","6f0d632d":"So , let me show you how the not so useful seeming Cabin is actually useful !","409ed92d":"Let us also import all the sklearn libraries we might need ","12614127":"Let's see the stats of our data now using the describe function (I just transposed it because i prefer it that way)","bc26c235":"As we can see from the heatmap , that the Survival is highly correlated to Patch,SibSp,Age,Sex,Fare and Pclass.","6818ec92":"Does the Embarked feature also affect the survival chances, there only one way to find out , let's see!","e8ab8917":"There is clearly alot of data missing in the age and cabin column , a few in embarked too , the one you see in survived is not really the missing data but the data we need to predict so don't worry about it.","6b934f94":"We have done a lot of operations lately , let's see how our data looks like now.","556792f2":"<a id=\"section7\"><\/a>\n### Extracting Title from Name\n","1c0322f2":"The Name feature is not really useful but we can use the Title of a person(such as Mr,Miss,etc) as a feature , so let's do it !","1f69c6e3":"# Some last words:\n\n### Thank you for reading! I'm still a beginner and want to improve myself in every way I can. So if you have any ideas to feedback please let me know in the comments section!\n\n\n<div align='center'><font size=\"5\" color=\"#000000\"><b>And again please vote if you liked this notebook so it can reach more people, Thanks!<\/b><\/font><\/div>","640f57f4":"<a id=\"section5\"><\/a>\n### Merging Parch and SibSp\n","1de6de2e":"Now let's see the stats of the categorical features"}}