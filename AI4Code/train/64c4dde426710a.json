{"cell_type":{"d95ce334":"code","41adca4d":"code","580b2969":"code","482d8581":"code","465316f6":"code","817916c3":"code","7b576255":"code","c70dbe4c":"code","9faed385":"code","6d1c3d77":"code","92f5c521":"code","a1d50ef1":"code","127f0e75":"code","f2b52ef2":"code","dda37292":"code","c3532985":"code","74cd32b0":"code","0277e995":"code","962fa0f3":"code","1eaa4082":"code","830e22e5":"code","5afe185f":"code","b34419ec":"code","ef563dad":"code","d9d73b01":"markdown"},"source":{"d95ce334":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\n# Any results you write to the current directory are saved as output.","41adca4d":" df = pd.read_csv('\/kaggle\/input\/heart-disease\/Heart Disease Prediction.csv')","580b2969":"df.head()","482d8581":"df.info()","465316f6":"df.describe()","817916c3":"plt.figure(figsize=(10,10))\nsns.heatmap(df.corr(), annot=True, fmt='.1f')\nplt.show()","7b576255":"#age analysis\ndf.age.value_counts()[:10]","c70dbe4c":"sns.barplot(x= df.age.value_counts()[:10].index, y= df.age.value_counts()[:10].values  )\nplt.xlabel('Age')\nplt.ylabel(\"Age counter\")\nplt.title(\"Age Analysis\")\nplt.show","9faed385":"df.target.value_counts()","6d1c3d77":"countNoDisease = len(df[df.target == 0])\ncountHaveDisease = len(df[df.target == 1])\nprint(\"Percentage of patients dont have heart disease: {:.2f}%\".format((countNoDisease\/(len(df.target)))*100))\nprint(\"Percentage of patients have heart disease: {:.2f}%\".format((countHaveDisease\/(len(df.target)))*100))","92f5c521":"countFemale= len(df[df.sex == 0])\ncountMale = len(df[df.sex == 1])\nprint(\"% of Female Patients: {:.2f}%\".format((countFemale\/(len(df.sex))*100)))\nprint(\"% of male Patients: {:.2f}%\".format((countMale\/(len(df.sex))*100)))","a1d50ef1":"young_ages = df[(df.age>=29)&(df.age<40)]\nmiddle_ages = df[(df.age>=40)&(df.age<55)]\nelderly_ages = df[(df.age>=55)]\nprint(\"young ages\", len(young_ages))\nprint(\"middle ages\", len(middle_ages))\nprint(\"elderly ages\", len(elderly_ages))","127f0e75":"colors = ['blue','green', 'red']\nexplode= [1,1,1]\nplt.figure(figsize= (8,8))\nplt.pie([len(young_ages), len(middle_ages), len(elderly_ages)], labels=['young ages', 'middle ages', 'elderly ages'])\nplt.show()","f2b52ef2":"#chest pain analysis\ndf.cp.value_counts()","dda37292":"df.target.unique()","c3532985":"sns.countplot(df.target)\nplt.xlabel('Target')\nplt.ylabel('Count')\nplt.title('Target 1 & 0')\nplt.show()","74cd32b0":"df.corr()","0277e995":"from sklearn.linear_model import LogisticRegression\nx_data = df.drop(['target'], axis = 1)\ny = df.target.values","962fa0f3":"x_train, x_test, y_train, y_test = train_test_split(x_data, y, test_size = 0.2, random_state= 0)","1eaa4082":"lr = LogisticRegression()\nlr.fit(x_train, y_train)\nprint('Test Accuracy {:.2f}%'.format(lr.score(x_test, y_test)*100))","830e22e5":"#KNN model\nfrom sklearn.neighbors import KNeighborsClassifier\nknn =  KNeighborsClassifier(n_neighbors = 3)\nknn.fit(x_train, y_train)\nprint(\"KNN accuracy: {:.2f}%\".format(knn.score(x_test, y_test)*100))","5afe185f":"# support vector\nfrom sklearn.svm import SVC\nsvm = SVC(random_state = 1)\nsvm.fit(x_train, y_train)\nprint(\"SVC accuracy: {:.2f}%\".format(svm.score(x_test, y_test)*100))","b34419ec":"# Naive Bayes\n\nfrom sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(x_train, y_train)\nprint(\"NB accuracy: {:.2f}%\".format(nb.score(x_test, y_test)*100))","ef563dad":"# Random forset\n\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators = 1000, random_state= 1)\nrf.fit(x_train, y_train)\nprint(\"Random Forest accuracy: {:.2f}%\".format(rf.score(x_test, y_test)*100))","d9d73b01":"About\nThis database contains 76 attributes, but all published experiments refer to using a subset of 14 of them. In particular, the Cleveland database is the only one that has been used by ML researchers to this date. The \"goal\" field refers to the presence of heart disease in the patient. It is integer valued from 0 (no presence) to 4.\n\n\nAttribute Information:\n\n> 1.age = age in years\n\n> 2.sex= (1 = male; 0 = female)\n\n> 3.cp = chest pain type\n\n> 4.trestbpsr = esting blood pressure (in mm Hg on admission to the hospital)\n\n> 5.chol = serum cholestoral in mg\/dl\n\n> 6.fbs = (fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false)\n\n> 7.restecg = resting electrocardiographic results\n\n> 8.thalach = maximum heart rate achieved\n\n> 9.exang = exercise induced angina (1 = yes; 0 = no)\n\n> 10.oldpeak = ST depression induced by exercise relative to rest\n\n> 11.slope = the slope of the peak exercise ST segment\n\n> 12.ca = number of major vessels (0-3) colored by flourosopy\n\n> 13.thal = 3 = normal; 6 = fixed defect; 7 = reversable defect\n\n> 14.target = 1 or 0\n\n"}}