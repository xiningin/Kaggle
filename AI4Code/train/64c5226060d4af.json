{"cell_type":{"52728a1c":"code","ba42e892":"code","5a0836f8":"code","df3a9243":"code","111a0ad3":"code","cb743aba":"code","f6ec7163":"code","f8b91f16":"markdown","b3bf5794":"markdown"},"source":{"52728a1c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.figure_factory as ff\nimport plotly.express as px","ba42e892":"b1 = pd.read_csv('..\/input\/blending-weighted-rank-average\/submission.csv')\nb2 = pd.read_csv('..\/input\/basic-ensemble-of-public-nb\/submission.csv')\nb3 = pd.read_csv('..\/input\/noob-stacking-0-85654\/LGBM_overfit.csv')\nb4 = pd.read_csv('..\/input\/tps-oct-21-eda-modeling\/submission.csv')\nb5 = pd.read_csv('..\/input\/tps-oct-2021-pca-and-kmeans-feature-eng\/submission.csv')\nb6 = pd.read_csv('..\/input\/tps-oct-joes-sandpit\/avg_submission.csv')","5a0836f8":"hist_data = [b1.target, b2.target, b3.target, b4.target, b5.target, b6.target]\ngroup_labels = ['b1','b2','b3','b4','b5','b6']\nfig = ff.create_distplot(hist_data, group_labels, bin_size=0.3, show_hist=False, show_rug=False)\nfig.show()","df3a9243":"data = np.corrcoef([b1.target,b2.target, b3.target, b4.target, b5.target, b6.target])\nfig=px.imshow(data,x=group_labels, y=group_labels)\n\nfig.show()","111a0ad3":"# Power is arbitrary - refer to blog post for more info to get a better power\nensemble = b1.copy()\nensemble.loc[:,'target'] = (b1**4 + b2**4 + b3**4 +b4**4+b5**4+b6**4)\/6","cb743aba":"ensemble.head(10)","f6ec7163":"ensemble.to_csv('submission.csv', index=False)","f8b91f16":"We are going to use Power Averaging technique,which is a form of ensembling to optimize for the AUC metric.\nHere's a detailed post on it - https:\/\/medium.com\/data-design\/reaching-the-depths-of-power-geometric-ensembling-when-targeting-the-auc-metric-2f356ea3250e. \n\nIt works best on highly correlated models.The high positive probabilities of the positively confident models remain positively confident. The non-high probabilities of any models are knocked down. \n\nThe formula is **Final Submission = (Submission1^Power + Submission2^Power + Submission3^Power + Submission4^Power) \/ 4**\n\nGo through this great notebook https:\/\/www.kaggle.com\/edrickkesuma\/in-depth-power-averaging-0-81848 for better understanding and implementation of power averaging.","b3bf5794":"This is my final submission for Tabular Playground Series-October. In this notebook I used Power averaging(more on this later ;-) for blending. I'm used some public notebooks by other competitors. Thanks for sharing these wonderful notebooks :-)."}}