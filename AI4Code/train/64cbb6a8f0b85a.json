{"cell_type":{"b4eae295":"code","814be633":"code","7b6af3ab":"code","9186501e":"code","fa958ab1":"code","4fbcbc43":"code","0a719651":"code","dacf669b":"code","1c2a5403":"code","aa33b939":"code","ded48ace":"code","d9966227":"code","fb987284":"code","4d5c64a2":"code","9fda9892":"code","fa0b7e15":"code","61a05633":"code","949a09f9":"code","2d8aa11d":"code","bd166d20":"code","d727c337":"code","a620a693":"code","e46c2771":"code","12252487":"code","7c0a2e5f":"code","481ea76b":"code","7e508be7":"code","7b73edf7":"code","2d9d0130":"code","8c79ceea":"code","260f7e75":"code","48549ec1":"code","d430807c":"code","c0aa8749":"code","65d048bc":"code","9c9303b2":"code","961f9f4f":"code","0883e622":"code","bc206210":"code","9af81b21":"code","7ebcd6a8":"code","98cba18f":"code","021d01b6":"code","8b438bef":"code","0988ba41":"code","7c8dd820":"code","cb2cdddf":"code","9c0b54b4":"code","cd55ca7b":"code","4b2526af":"code","dd1af47e":"code","51ef5453":"code","e38cae3f":"code","7466d4eb":"code","fa76e1ff":"code","6a69c5c7":"code","49bb2e8a":"code","a0eed20f":"code","13a5f495":"code","e3cfedb4":"code","c12c9b7a":"code","99865aa6":"code","f9be4d77":"code","30b46084":"code","7773297c":"code","ab63de9e":"code","f98f4157":"code","2a8e2e1d":"code","ad199ab9":"code","003070a1":"code","b2237444":"markdown","8f83dfda":"markdown","274960d9":"markdown","4af048d2":"markdown","a8e1a3d0":"markdown","179337e2":"markdown","cb97ba08":"markdown","69412d83":"markdown","e4c18fec":"markdown","ae2a0282":"markdown","2daed8e9":"markdown","fdb38c0d":"markdown","fe6cebbb":"markdown","9490e708":"markdown","1d3d20b9":"markdown","f2f1d184":"markdown","2d3b57d3":"markdown","6fd844bb":"markdown","15b0f48c":"markdown","212e8365":"markdown","f3aea1ec":"markdown","38c7819c":"markdown","d6d2bfaa":"markdown","089db57d":"markdown","a1b52449":"markdown","7b0b6ad3":"markdown","a1ece3ea":"markdown","f5c9e6b6":"markdown","78086965":"markdown","39f7c255":"markdown","1c05ff03":"markdown","24308155":"markdown","c07d1138":"markdown","3c06ee5c":"markdown","9561ce14":"markdown","3b3531a9":"markdown","72960e2d":"markdown","1bc04b99":"markdown","938c0093":"markdown","8d86db0e":"markdown","3f6a4b0a":"markdown","69046eb6":"markdown"},"source":{"b4eae295":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","814be633":"pd.set_option('display.max_columns', None)\ndf = pd.read_csv('..\/input\/aug-train\/aug_train.csv')\ndf_test = pd.read_csv('..\/input\/aug-test\/aug_test.csv')","7b6af3ab":"df.head()","9186501e":"df.size, df.shape, df_test.size, df_test.shape","fa958ab1":"df.size, df.shape","4fbcbc43":"plt.figure(figsize=(16,5))\nsns.heatmap(df.isnull())","0a719651":"df.isnull().sum().sort_values(ascending = False).to_frame()","dacf669b":"df_test.isnull().sum().sort_values(ascending = False).to_frame()","1c2a5403":"df['company_type'].value_counts(dropna= False)","aa33b939":"df['company_type'] = df['company_type'].fillna(df['company_type'].mode()[0])","ded48ace":"df_test['company_type'] = df_test['company_type'].fillna(df_test['company_type'].mode()[0])","d9966227":"df['company_size'].value_counts()","fb987284":"df['company_size'] = df['company_size'].fillna(method = 'ffill')","4d5c64a2":"df_test['company_size'] = df_test['company_size'].fillna(method = 'ffill')","9fda9892":"df['gender'].value_counts(dropna = False)","fa0b7e15":"df['gender'] = df['gender'].fillna(df['gender'].mode()[0])","61a05633":"df_test['gender'] = df_test['gender'].fillna(df_test['gender'].mode()[0])","949a09f9":"df['major_discipline'].value_counts(dropna=False)","2d8aa11d":"df['major_discipline'] = df['major_discipline'].fillna(df['major_discipline'].mode()[0])","bd166d20":"df_test['major_discipline'] = df_test['major_discipline'].fillna(df_test['major_discipline'].mode()[0])","d727c337":"df['education_level'].value_counts(dropna = False)","a620a693":"df['education_level'] = df['education_level'].fillna(df['education_level'].mode()[0])","e46c2771":"df_test['education_level'] = df_test['education_level'].fillna(df_test['education_level'].mode()[0])","12252487":"df['last_new_job'].value_counts(dropna=False)","7c0a2e5f":"df['last_new_job'] = df['last_new_job'].fillna(method = 'ffill')","481ea76b":"df_test['last_new_job'] = df_test['last_new_job'].fillna(method = 'ffill')","7e508be7":"df['enrolled_university'].value_counts(dropna=False)","7b73edf7":"df['enrolled_university'] = df['enrolled_university'].fillna(df['enrolled_university'].mode()[0])","2d9d0130":"df_test['enrolled_university'] = df_test['enrolled_university'].fillna(df_test['enrolled_university'].mode()[0])","8c79ceea":"df['experience'].value_counts(dropna=False)","260f7e75":"df['experience'] = df['experience'].fillna(method='ffill')","48549ec1":"df_test['experience'] = df_test['experience'].fillna(method='ffill')","d430807c":"df =  df.dropna(axis=0)","c0aa8749":"df['city'] = df['city'].str.split('_').str[1].astype('int')\ndf_test['city'] = df_test['city'].str.split('_').str[1].astype('int')","65d048bc":"plt.figure(figsize=(8,5))\nplot = sns.countplot(data = df, x = df['target'])\nfor p in plot.patches:\n    plot.annotate(p.get_height(), (p.get_x()+p.get_width()\/2, p.get_height()))\nplt.show()","9c9303b2":"plt.figure(figsize=(10,8))\ncorr = df.corr()\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)]=True\nsns.heatmap(corr, mask=mask, center=0, square=True, annot=True, linewidths=5)","961f9f4f":"fig = make_subplots()\nfig.add_trace(go.Pie(labels=df['gender'].value_counts().index, values=df['gender'].value_counts().values))","0883e622":"plot = pd.crosstab(df['gender'],df['target']).plot(kind = 'bar')\n\nfor p in plot.patches:\n    plot.annotate(p.get_height(), (p.get_x()+p.get_width()\/6, p.get_height()))","bc206210":"fig, ax = plt.subplots(1,1, figsize = (10,5))\n\nplot = sns.countplot(df['relevent_experience'])\nfor p in plot.patches:\n    plot.annotate(p.get_height(), (p.get_x()+p.get_width()\/2, p.get_height()))\n    \nplot1 = pd.crosstab(df['relevent_experience'], df['target']).plot(kind = 'bar', figsize = (10,5))\nfor p in plot1.patches:\n    plot1.annotate(p.get_height(), (p.get_x()+p.get_width()\/6, p.get_height()))","9af81b21":"fig, ax = plt.subplots(1,1, figsize = (10,5))\n\nplot = sns.countplot(df['enrolled_university'])\nfor p in plot.patches:\n    plot.annotate(p.get_height(), (p.get_x()+p.get_width()\/2, p.get_height()))\n    \nplot1 = round(pd.crosstab(df['enrolled_university'], df['target']).apply(lambda r:r\/r.sum(),axis = 1),2).plot(kind = 'bar', figsize = (10,5))\nfor p in plot1.patches:\n    plot1.annotate(p.get_height(), (p.get_x()+p.get_width()\/6, p.get_height()))","7ebcd6a8":"fig, ax = plt.subplots(1,1, figsize = (10,5))\n\nplot = sns.countplot(df['education_level'])\nfor p in plot.patches:\n    plot.annotate(p.get_height(), (p.get_x()+p.get_width()\/2, p.get_height()))\n    \nplot1 = round(pd.crosstab(df['education_level'], df['target']).apply(lambda r:r\/r.sum(),axis = 1),2).plot(kind = 'bar', figsize = (12,5))\nfor p in plot1.patches:\n    plot1.annotate(p.get_height(), (p.get_x()+p.get_width()\/6, p.get_height()))","98cba18f":"fig, ax = plt.subplots(1,1, figsize = (10,5))\n\nplot = sns.countplot(df['major_discipline'])\nfor p in plot.patches:\n    plot.annotate(p.get_height(), (p.get_x()+p.get_width()\/2, p.get_height()))\n    \nplot1 = round(pd.crosstab(df['major_discipline'], df['target']).apply(lambda r:r\/r.sum(),axis = 1),2).plot(kind = 'bar', figsize = (12,5))\nfor p in plot1.patches:\n    plot1.annotate(p.get_height(), (p.get_x()+p.get_width()\/6, p.get_height()))","021d01b6":"fig, ax = plt.subplots(1,1, figsize = (15,5))\n\nplot = sns.countplot(df['experience'])\nfor p in plot.patches:\n    plot.annotate(p.get_height(), (p.get_x()+p.get_width()\/5, p.get_height()))\n    \nplot1 = round(pd.crosstab(df['experience'], df['target']).apply(lambda r:r\/r.sum(),axis = 1),2).plot(kind = 'bar', figsize = (15,5))\nfor p in plot1.patches:\n    plot1.annotate(p.get_height(), (p.get_x()+p.get_width()\/6, p.get_height()))","8b438bef":"fig, ax = plt.subplots(1,1, figsize = (15,5))\n\nplot = sns.countplot(df['company_size'])\nfor p in plot.patches:\n    plot.annotate(p.get_height(), (p.get_x()+p.get_width()\/5, p.get_height()))\n    \nplot1 = round(pd.crosstab(df['company_size'], df['target']).apply(lambda r:r\/r.sum(),axis = 1),2).plot(kind = 'bar', figsize = (15,5))\nfor p in plot1.patches:\n    plot1.annotate(p.get_height(), (p.get_x()+p.get_width()\/6, p.get_height()))","0988ba41":"fig, ax = plt.subplots(1,1, figsize = (15,5))\n\nplot = sns.countplot(df['company_type'])\nfor p in plot.patches:\n    plot.annotate(p.get_height(), (p.get_x()+p.get_width()\/5, p.get_height()))\n    \nplot1 = round(pd.crosstab(df['company_type'], df['target']).apply(lambda r:r\/r.sum(),axis = 1),2).plot(kind = 'bar', figsize = (15,5))\nfor p in plot1.patches:\n    plot1.annotate(p.get_height(), (p.get_x()+p.get_width()\/6, p.get_height()))","7c8dd820":"fig, ax = plt.subplots(1,1, figsize = (15,5))\n\nplot = sns.countplot(df['last_new_job'])\nfor p in plot.patches:\n    plot.annotate(p.get_height(), (p.get_x()+p.get_width()\/5, p.get_height()))\n    \nplot1 = round(pd.crosstab(df['last_new_job'], df['target']).apply(lambda r:r\/r.sum(),axis = 1),2).plot(kind = 'bar', figsize = (15,5))\nfor p in plot1.patches:\n    plot1.annotate(p.get_height(), (p.get_x()+p.get_width()\/6, p.get_height()))","cb2cdddf":"pd.cut(df['training_hours'], bins = 4).value_counts()\nlabels = ['least', 'moderate', 'high', 'highest']\ncut_bins = [0,84.75,168.5,252.25,336]\ndf['training_hours'] = pd.cut(df['training_hours'], bins=cut_bins, labels=labels)\ndf_test['training_hours'] = pd.cut(df_test['training_hours'], bins = cut_bins, labels=labels)","9c0b54b4":"fig, ax = plt.subplots(1,1, figsize = (15,5))\n\nplot = sns.countplot(df['training_hours'])\nfor p in plot.patches:\n    plot.annotate(p.get_height(), (p.get_x()+p.get_width()\/5, p.get_height()))\n    \nplot1 = round(pd.crosstab(df['training_hours'], df['target']).apply(lambda r:r\/r.sum(),axis = 1),2).plot(kind = 'bar', figsize = (15,5))\nfor p in plot1.patches:\n    plot1.annotate(p.get_height(), (p.get_x()+p.get_width()\/6, p.get_height()))","cd55ca7b":"sns.pairplot(df, hue='target')","4b2526af":"cat_columns = list(df.select_dtypes(exclude=['int32','int64','float64']).dtypes.index)\ncat_columns","dd1af47e":"le = LabelEncoder()","51ef5453":"df['relevent_experience'] = le.fit_transform(df['relevent_experience'])\ndf['education_level'] = le.fit_transform(df['education_level'])\ndf['experience'] = le.fit_transform(df['experience'])\ndf['company_size'] = le.fit_transform(df['company_size'])\ndf['last_new_job'] = le.fit_transform(df['last_new_job'])\ndf['training_hours'] = le.fit_transform(df['training_hours'])","e38cae3f":"df_test['relevent_experience'] = le.fit_transform(df_test['relevent_experience'])\ndf_test['education_level'] = le.fit_transform(df_test['education_level'])\ndf_test['experience'] = le.fit_transform(df_test['experience'])\ndf_test['company_size'] = le.fit_transform(df_test['company_size'])\ndf_test['last_new_job'] = le.fit_transform(df_test['last_new_job'])\ndf_test['training_hours'] = le.fit_transform(df_test['training_hours'])","7466d4eb":"df.head()","fa76e1ff":"df_test.head()","6a69c5c7":"df = pd.get_dummies(df, columns=['gender','enrolled_university','major_discipline','company_type'], drop_first=True)\ndf_test = pd.get_dummies(df_test, columns=['gender','enrolled_university','major_discipline','company_type'], drop_first=True)","49bb2e8a":"df.head()","a0eed20f":"df_test.head()","13a5f495":"X = df.drop(['target'],axis = 1)\n\ny = df['target']","e3cfedb4":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","c12c9b7a":"dc = DecisionTreeClassifier()","99865aa6":"dc.fit(X_train,y_train)","f9be4d77":"y_pred_dc = dc.predict(X_test)\naccuracy_score(y_test,y_pred_dc)","30b46084":"rf = RandomForestClassifier()\n\nrf.fit(X_train,y_train)","7773297c":"y_pred_rf = rf.predict(X_test)\naccuracy_score(y_test,y_pred_rf)","ab63de9e":"from sklearn.metrics import classification_report, confusion_matrix  \nprint(confusion_matrix(y_test, y_pred_rf))  \nprint(classification_report(y_test, y_pred_rf))","f98f4157":"prediction = rf.predict(df_test)\nprediction","2a8e2e1d":"submit = pd.DataFrame()\nsubmit['enrollee_id'] = df_test['enrollee_id']\nsubmit['target'] = prediction","ad199ab9":"submit.head()","003070a1":"submit.to_csv('Submit.csv',index=False)","b2237444":"## Converting categorical variables using LabelEncoder and OneHotEncoding","8f83dfda":"## For company_type lets fill the missing values with Pvt Ltd as they are the most frequency occuring","274960d9":"## For company size as can be see if we use most frequent occuring character then it will create bias, which will lead to a bad model. So we will use ffill\n","4af048d2":"## We can filledup most of the missing values, in case of any (due to ffill), lets drop them","a8e1a3d0":"## From our dataset, we will be using label encoding for relevant_experience, education_level, experience, company_size, last_new_job, training_hours","179337e2":"#### Most employees with full time course are existing the company after completing the trainig when compared with others.","cb97ba08":"#### There is almost similar kind of distribution of employees exisiting the company after training with respect to company_size","69412d83":"## Attrition w.r.t company_size","e4c18fec":"#### people from the funded startups are least existing the company after training when compared with other types","ae2a0282":"## Decision Tree Classifier","2daed8e9":"## Attrition w.r.t company_type","fdb38c0d":"## Feature engineering","fe6cebbb":"## From the above we can see that male employees populaton is  highest, so we will use highest occuring i.e. male to fill in the missing values","9490e708":"## Attrition of gender in the organization after completing the training","1d3d20b9":"## Lets group training hours and analyze them accordingly","f2f1d184":"## Splitting the dataset\n","2d3b57d3":"## We will use ffill to fill in the missing values so as to not create any bias","6fd844bb":"#### There is almost similar kind of distribution of employees exisiting the company across educational_level\n","15b0f48c":"## Gender percentage in the organization","212e8365":"#### There is almost similar kind of distribution of employees exisiting the company after training with respect to major_discipline","f3aea1ec":"## Attrition w.r.t experience","38c7819c":"#### From the above plots we can notice that people with experience of 1 or less than 1 are mostly likely to exist the company post training","d6d2bfaa":"## Attrition with respect with enrolled_university after completing the training\n","089db57d":"## Attrition with respect to major discipline","a1b52449":"## Random Forest Classified","7b0b6ad3":"#### There is almost similar kind of distribution of employees exisiting the company after training with respect to major_discipline","a1ece3ea":"## Attrition with respect to relevant experience after completing the training","f5c9e6b6":"## Null value treatment","78086965":"## Converting remaining categorical variables into numeric","39f7c255":"## Lets Carry Out some Exploratory Data Analysis\n","1c05ff03":"## Capturing only the numbers fro  the city column","24308155":"## Again, as STEM is most occuring compared to other fields lets fillna in the missing values with STEM","c07d1138":"## By looking at the crosstab graph we can see that on an average more than 50% of the employees with no relevant experience are looking to move out","3c06ee5c":"## Attrition with respect to training_hours\n","9561ce14":"## Attrition with respect to educational backgroud after completing the training","3b3531a9":"## From the above two we can see that RandomForestClassifier is giving us better result with an accuray score  of 76%. We will use it to predict the test dataset","72960e2d":"## Filling the missing last_new_job using forward fill\n","1bc04b99":"#### people with high difference in the last and current job are least existing from the company while employees with no difference are highly leaving the company","938c0093":"## We will replace Null valus with most occuring category. So lets replace it with Graducate","8d86db0e":"## Checking the null values with heatmap\n","3f6a4b0a":"## Filling the dataset with the most occuring category i.e. no_enrollment","69046eb6":"## Attrition w.r.t to last_job"}}