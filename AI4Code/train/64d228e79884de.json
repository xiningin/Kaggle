{"cell_type":{"f48d0584":"code","197805bb":"code","42d14c25":"code","82a11c85":"code","8dbaba67":"code","eac46ff1":"code","7cc0698d":"code","db8b6348":"code","00b59ca0":"code","c79353c2":"code","2eb1e316":"code","7355d07b":"code","abbe03b4":"code","c0c75e1a":"code","563bf0fe":"code","fb3bfc2c":"code","aad82799":"code","08d6e077":"code","e0027996":"code","835007ed":"code","a82ec257":"code","d7f4f6f5":"code","35f1fb42":"code","bb706dbf":"markdown","e199d465":"markdown","dfc0dded":"markdown","b2f386e9":"markdown","226c825f":"markdown","8fe9524d":"markdown","4ab4d7ab":"markdown","a6499ce7":"markdown","761252dc":"markdown","b1ab94a8":"markdown","cbad0952":"markdown","da416054":"markdown","09f2c1ac":"markdown","75b9689e":"markdown","38cf72af":"markdown","41cf72ad":"markdown","4ad7623d":"markdown","c942fc4d":"markdown","41236188":"markdown","0cde1d87":"markdown","b2c2f5a0":"markdown","9ef83b49":"markdown","8231da77":"markdown","1a83bb4f":"markdown","75ae5881":"markdown","5fa831cf":"markdown","40ceece5":"markdown"},"source":{"f48d0584":"import matplotlib.pyplot as plt\nfrom PIL import Image\n\nimport numpy as np\nimport struct\nimport pandas as pd\nimport os\nimport random\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torchvision\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils","197805bb":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n# Noise shape for generator\nNOISE_SIZE = 128\nBATCH_SIZE = 56\nNUM_CLASSES = 10\nEMBEDDING_SIZE = 48\n# Image size and number of channels\nH, W, C = (28, 28, 1)\n\n# Setup TensorBoard\ntensor_board_writer = SummaryWriter('.\/logs\/')","42d14c25":"# Download Ngrok to tunnel the tensorboard port to an external port\n!wget https:\/\/bin.equinox.io\/c\/4VmDzA7iaHb\/ngrok-stable-linux-amd64.zip\n!unzip ngrok-stable-linux-amd64.zip\n\n# Run tensorboard as well as Ngrox (for tunneling as non-blocking processes)\nimport os\nimport multiprocessing\n\n\npool = multiprocessing.Pool(processes = 10)\nresults_of_processes = [pool.apply_async(os.system, args=(cmd, ), callback = None )\n                        for cmd in [\n                        f\"tensorboard --logdir .\/logs\/ --load_fast true --host 0.0.0.0 --port 6006 &\",\n                        \".\/ngrok http 6006 &\"\n                        ]]","82a11c85":"! curl -s http:\/\/localhost:4040\/api\/tunnels | python3 -c \\\n    \"import sys, json; print('Your link: ', json.load(sys.stdin)['tunnels'][0]['public_url'])\"","8dbaba67":"# Read train images\ndf = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')\n# Create np array from csv\ndf_as_np = np.asarray(df)\n# Wrap images and labels\nlabels_mnist, data = (\n    df_as_np[:, 0],                                                  # First row - labels\n    df_as_np[:, 1:].reshape(-1, H, W, C)                             # Other rows - images\n)\n# Read test images\ndf = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv')\n# Create np array from csv\ndf_as_np = np.asarray(df)\n# Wrap images and labels\ntest_labels_mnist, test_data = (\n    df_as_np[:, 0],                                                  # First row - labels\n    df_as_np[:, 1:].reshape(-1, H, W, C)                             # Other rows - images\n)\nprint('Train data: ', data.shape, labels_mnist.shape)\nprint('Test data: ', test_data.shape, test_labels_mnist.shape)","eac46ff1":"# Define class with super-class Dataset\n# We must implement two methods (getitem__ and __len__): \n#     __getitem__ - gives possibility to apply indexing for the instance of class FashionDataset\n#     __len__ - gives possibility to take size of overall dataset\n# This methods need in order to use DataLoader\nclass FashionDataset(Dataset):\n\n    def __init__(self, data, data_y, transform = None, H = 28, W = 28, C = 1):\n        self._data = np.asarray(data, dtype=np.float32).reshape(-1, H, W, C)\n        self._data_y = np.asarray(data_y, dtype=np.int64).reshape(-1)\n        self._transform = transform\n\n    def __getitem__(self, index):\n        single_data = self._data[index]\n        single_label = self._data_y[index]\n        if self._transform is not None:\n            single_data = self._transform(single_data)\n        return single_data, single_label\n    \n    def __len__(self):\n        return len(self._data)\n\n# Create instaince of data loader in order to load and create batches of data\n# Also we can specify number of workers in loader which can speed up process of \n# preparing data. We leave it as it is, with default value.\n# For more info refer to original docs.\ntrain_set = FashionDataset(\n    data, labels_mnist, transform=transforms.Compose(\n        # Transform data into Tensor and normalize data into range [-1, 1]\n        [transforms.ToTensor(), transforms.Normalize(128, 128)]\n    ),\n    H=H, W=W, C=C\n)\n# Create data loader\ntrain_loader = DataLoader(\n    train_set, batch_size=BATCH_SIZE, \n    shuffle=True, drop_last=True\n)","7cc0698d":"# Test loader\nbatch_d, _ = next(iter(train_loader))\ngrid = torchvision.utils.make_grid(batch_d, nrow=10)\n\nplt.figure(figsize=(15, 20))\ngrid_image = np.transpose(grid, (1, 2, 0)).numpy()\ngrid_image = (grid_image + 1.0) \/ 2.0 # [-1, 1] --> [0, 1]\nplt.imshow(grid_image)","db8b6348":"# custom weights initialization called on netG and netD\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        nn.init.normal_(m.weight.data, 1.0, 0.02)\n        nn.init.constant_(m.bias.data, 0)","00b59ca0":"class GeneratorNN(nn.Module):\n\n    def __init__(\n            self, noise_size: tuple, num_classes: int, embedding_size: int, \n            map_noise_to: int = 128, start_size: int = 7):\n        super(GeneratorNN, self).__init__()\n        self._start_size = start_size\n        self._embed_input = nn.Sequential(\n            nn.Embedding(num_classes, embedding_size),\n            nn.Linear(embedding_size, start_size * start_size),\n        ) # 7\n        \n        self._map_noise_to = map_noise_to\n        self._noise_input = nn.Sequential(\n            nn.Linear(noise_size, map_noise_to * start_size * start_size),\n            #nn.BatchNorm1d(512, momentum=0.8, track_running_stats=False),\n            nn.LeakyReLU(0.2, inplace=True),\n        ) # 7\n        self._model = nn.Sequential(\n            nn.ConvTranspose2d(map_noise_to + 1, 128, kernel_size=4, stride=2, padding=1), # 14\n            #nn.BatchNorm1d(128, momentum=0.8, track_running_stats=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.ConvTranspose2d(128, 128, kernel_size=4, stride=2, padding=1),  # 28\n            #nn.BatchNorm1d(128, momentum=0.8, track_running_stats=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Conv2d(128, 1, kernel_size=7, padding=3),\n            nn.Tanh()\n        )\n    \n    def forward(self, x, y):\n        n_batch = x.shape[0]\n        y = self._embed_input(y).view(n_batch, 1, self._start_size, self._start_size)\n        x = self._noise_input(x).view(n_batch, self._map_noise_to, self._start_size, self._start_size)\n        x = torch.cat([y, x], dim=1)\n        x = self._model(x)\n        return x","c79353c2":"# Generator\ngen_nn = GeneratorNN(noise_size=NOISE_SIZE, num_classes=NUM_CLASSES, embedding_size=EMBEDDING_SIZE)\ngen_nn.to(device=device)\n# Init weights of the model with certain initialization\ngen_nn.apply(weights_init)\n# Turn on training mode\ngen_nn.train()\n\n# Check generator\narr_x = np.random.randn(BATCH_SIZE, NOISE_SIZE).astype(np.float32)\narr_y = np.random.randint(low=0, high=NUM_CLASSES, size=(BATCH_SIZE)).astype(np.int64)\nres = gen_nn(torch.tensor(arr_x).to(device=device), torch.tensor(arr_y).to(device=device))\nprint(res.shape)\nplt.imshow( ((res + 1.0) \/ 2.0)[0].cpu().detach().numpy().transpose(1, 2, 0)[..., 0])","2eb1e316":"class DiscriminatorNN(nn.Module):\n\n    def __init__(self, H: int, W: int, C: int, num_classes: int, embedding_size: int):\n        super(DiscriminatorNN, self).__init__()\n        \n        self._h, self._w = H, W\n        self._embed_input = nn.Sequential(\n            nn.Embedding(num_classes, embedding_size),\n            nn.Linear(embedding_size, H * W )\n        )\n        \n        self._net = nn.Sequential(\n            nn.Conv2d(C + 1, 128, kernel_size=3, stride=2, padding=1), # 14\n            nn.ReLU(inplace=True),\n            \n            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),   # 7\n            nn.ReLU(inplace=True),\n            nn.Flatten(),\n            nn.Dropout(p=0.4),\n            nn.Linear(7 * 7 * 128, 1),\n            nn.Sigmoid(),\n        )\n    \n    def forward(self, x, y):\n        b = x.shape[0]\n        y = self._embed_input(y).view(b, 1, self._h, self._w)\n        x = torch.cat([y, x], dim=1)\n        return self._net(x)","7355d07b":"# Discriminator\ndisc_nn = DiscriminatorNN(H=H, W=W, C=C, num_classes=NUM_CLASSES, embedding_size=EMBEDDING_SIZE)\ndisc_nn.to(device=device)\n# Init weights of the model with certain initialization\ndisc_nn.apply(weights_init)\n# Turn on training mode\ndisc_nn.train()\n\n# Check discriminator on noise data\narr_x = np.random.randn(BATCH_SIZE, C, H, W).astype(np.float32)\narr_y = np.random.randint(low=0, high=NUM_CLASSES, size=(BATCH_SIZE)).astype(np.int64)\nres = disc_nn(torch.tensor(arr_x, device=device), torch.tensor(arr_y, device=device))\nprint(res.shape)\nres.cpu().detach().numpy()[:5]","abbe03b4":"class TrainGANController:\n    \n    def __init__(\n            self, disc_nn, gen_nn, \n            batch_size, num_classes, noise_size, \n            device = None, tensor_board_writer = None):\n        self._disc_nn = disc_nn\n        self._gen_nn = gen_nn\n        self._batch_size = batch_size\n        self._num_classes = num_classes\n        self._noise_size = noise_size\n\n        self._is_compiled = False\n        self._opt_disc = None\n        self._opt_gen = None\n        self._loss = None\n        self._device = device\n        \n        self._tensor_board_writer = tensor_board_writer\n        self._global_step = 0\n        self._global_step_images = 0\n    \n    def compile(\n            self, \n            lr_disc=2e-4, lr_gen=2e-4, \n            beta_params_disc=(0.5, 0.999), beta_params_gen=(0.5, 0.999)):\n        # Init opt\n        self._opt_disc = torch.optim.Adam(\n            self._disc_nn.parameters(), lr=lr_disc, betas=beta_params_disc\n        )\n        self._opt_gen = torch.optim.Adam(\n            self._gen_nn.parameters(), lr=lr_gen, betas=beta_params_gen\n        )\n        # Losses\n        self._loss = nn.BCELoss().to(device=self._device)\n        # Set flag, in order to start train\n        self._is_compiled = True\n    \n    def train_step_disc(self, real_data, labels, real_label=0.9, fake_label=0.0):\n        # Set real label equal to 0.9 in order to use \"Label smoothing\"\n        # Discriminator can produce better gradients, then this technique is used\n        # For more details about label smoothing you can find in the internet \n        \n        # For easy access\n        device = self._device\n        # Train step for discriminator\n        # Zero grads\n        self._disc_nn.zero_grad()\n        # Forward pass for real data\n        label = torch.full((self._batch_size,), real_label, dtype=torch.float, device=device)\n        fake = torch.full((self._batch_size,), fake_label, dtype=torch.float, device=device)\n        # Generate fake stuf\n        noise = torch.randn(self._batch_size, self._noise_size, device=device)\n        generated_imgs = self._gen_nn(noise, labels)\n        # Forward pass real batch through D\n        errD_real = self._loss(self._disc_nn(real_data, labels).view(-1), label)\n        # Forward pass fake batch through D\n        errD_fake = self._loss(self._disc_nn(generated_imgs.detach(), labels).view(-1), fake)\n        errD = (errD_fake + errD_real) \/ 2.0\n        errD.backward()\n        self._opt_disc.step()\n        return errD.cpu().detach().numpy()\n\n    def train_step_gen(self, fake_label=1.0):\n        # For easy access\n        device = self._device\n        # Train step for generator\n        # Zero grads\n        self._gen_nn.zero_grad()\n        # fake labels are real for generator cost\n        label = torch.full((self._batch_size,), fake_label, dtype=torch.float, device=device)\n        # Since we just updated D, perform another forward pass of all-fake batch through D\n        # Generate batch of latent vectors\n        noise = torch.randn(self._batch_size, self._noise_size, device=device)\n        # Take random num classes\n        labels_y = torch.randint(low=0, high=self._num_classes, size=(self._batch_size,), device=device)\n        # Generate fake image batch with G\n        generated_imgs = self._gen_nn(noise, labels_y)\n        # Calculate G's loss based on this output\n        errG = self._loss(self._disc_nn(generated_imgs, labels_y).view(-1), label)\n        # Calculate gradients for G\n        errG.backward()\n        # Update G\n        self._opt_gen.step()\n        return errG.cpu().detach().numpy()\n    \n    def _tb_flush(self):\n        if self._tensor_board_writer is None:\n            # I.e. tensor board is not used\n            return\n        self._tensor_board_writer.flush()\n    \n    def write_tb_info(self, disc_loss, gen_loss):\n        if self._tensor_board_writer is None:\n            # I.e. tensor board is not used\n            return\n        \n        self._tensor_board_writer.add_scalars(\n            'loss',\n            {\n                'generator loss': gen_loss,\n                'discriminator loss': disc_loss,\n            },\n            global_step=self._global_step\n        )\n        self._global_step += 1\n    \n    def generate_images(self, epoch: int, iteration: int, write_to_tb=True):\n        # Check generator\n        num_data = NUM_CLASSES * NUM_CLASSES\n        arr = np.random.randn(num_data, NOISE_SIZE).astype(np.float32)\n        labels_arr = np.asarray(\n            [min(x, NUM_CLASSES-1)  for _ in range(NUM_CLASSES) for x in range(NUM_CLASSES)],\n            dtype=np.int64\n        )\n        gen_nn.eval()\n        res = gen_nn(torch.tensor(arr).to(device=self._device), torch.tensor(labels_arr).to(device=self._device))\n        # Unnormed images and plot big figure\n        res = ((res + 1.0) \/ 2.0).cpu().detach().numpy().transpose(0, 2, 3, 1)\n        save_name=f'generate_ep{epoch}_it{iteration}.png'\n        visualise_sheets_of_images(\n            res, NUM_CLASSES, \"generated_digits\", \n            show_images=True, use_grey=True, save_name=save_name\n        )\n        if write_to_tb:\n            if self._tensor_board_writer is None:\n                # I.e. tensor board is not used\n                return\n            self._tensor_board_writer.add_image(\n                'generator result',\n                np.array(Image.open(save_name)),\n                global_step=self._global_step_images,\n                dataformats='HWC'\n            )\n            self._global_step_images += 1\n\n    def fit(self, data_gen, epoch: int, print_it: int = 400, img_generation_it: int = None):\n        if img_generation_it is None:\n            # I.e. at the end of epoch\n            img_generation_it = len(data_gen) - 1\n        \n        for i_e in range(epoch):\n            for ii_it, (single_data, single_label) in enumerate(data_gen):\n                single_data = single_data.to(device=self._device)\n                single_label = single_label.to(device=self._device)\n                # Train discriminator\n                err_d = self.train_step_disc(single_data, single_label)\n                # Train generator\n                err_g = self.train_step_gen()\n                # Write loss info\n                self.write_tb_info(err_d, err_g)\n                if ii_it != 0 and ii_it % img_generation_it == 0:\n                    # Generate imgs\n                    self.generate_images(epoch=epoch, iteration=ii_it)\n                \n                if ii_it % print_it == 0:\n                    self._tb_flush()\n                    # Print info\n                    print(\n                        f'Epoch: {str(i_e+1).zfill(2)}\/{str(epoch).zfill(2)} || ' \n                        f'Iterations: {str(ii_it).zfill(4)}\/{str(len(data_gen)).zfill(4)} || '\n                        f'Loss G: {str(np.round(err_g, 5)).zfill(2)} || '\n                        f'Loss D: {str(np.round(err_d, 5)).zfill(2)}'\n                    )","c0c75e1a":"def visualise_sheets_of_images(\n    images, num_classes, prefix_name, save_name='generated_img.png',\n    show_images=False, figsize=(12, 12),use_BGR2RGB=False,\n    use_grey=False):\n    \"\"\"\n    Plot sheets of images. Usually used for generated images from GANs.\n    Parameters\n    ----------\n    images : list or np.ndarray\n        List of images that should be plotted.\n    prefix_name : str\n        Prefix name for file with sheets of images.\n    unique_index : int\n        Unique number for name of file which consist of sheets of images,\n        usually this params used for showing at which epoch this result is.\n    show_images : bool\n        If true, sheets of images will be plotted.\n    subplot_size : tuple\n        Size of raw and columns. For more detail, see plt docs.\n    figsize : tuple\n        Size of figure. For more detail, see plt docs.\n    use_BGR2RGB : bool\n        If true, `images` will be converted into RGB format (if they have BGR format).\n    use_grey : bool\n        If true, `images` will be plotted as black-white images.\n    \n    \"\"\"\n    # plot images\n    fig = plt.figure(figsize=figsize)\n    for i in range(num_classes * num_classes):\n        # define subplot\n        plt.subplot(num_classes, num_classes, 1 + i)\n        plt.title(i % num_classes)\n        # turn off axis\n        plt.axis('off')\n        # plot raw pixel data\n        if use_BGR2RGB:\n            plt.imshow(cv2.cvtColor(images[i], cv2.COLOR_BGR2RGB))\n        elif use_grey:\n            plt.imshow(images[i], cmap='gray')\n        else:\n            plt.imshow(images[i])\n        plt.axis('off')\n\n    plt.tight_layout()\n    plt.savefig(save_name)\n    if show_images:\n        plt.show()\n\n    plt.close('all')","563bf0fe":"t_gan_c = TrainGANController(\n    disc_nn, gen_nn, BATCH_SIZE, \n    num_classes=NUM_CLASSES, noise_size=NOISE_SIZE, \n    device=device, tensor_board_writer=tensor_board_writer\n)\nt_gan_c.compile()","fb3bfc2c":"t_gan_c.fit(train_loader, epoch=20)","aad82799":"# Check generator\nnum_data = NUM_CLASSES * NUM_CLASSES\narr = np.random.randn(num_data, NOISE_SIZE).astype(np.float32)\nlabels_arr = np.asarray(\n    [min(x, NUM_CLASSES-1)  for _ in range(NUM_CLASSES) for x in range(NUM_CLASSES)],\n    dtype=np.int64\n)\ngen_nn.eval()\nres = gen_nn(torch.tensor(arr).to(device=device), torch.tensor(labels_arr).to(device=device))\n# Unnormed images and plot big figure\nres = ((res + 1.0) \/ 2.0).cpu().detach().numpy().transpose(0, 2, 3, 1)\nvisualise_sheets_of_images(res, NUM_CLASSES, \"generated_digits\", show_images=True, use_grey=True)","08d6e077":"from scipy.linalg import sqrtm\nfrom sklearn.utils import shuffle\nimport cv2\nfrom tqdm import tqdm\nfrom torchvision.models import inception_v3\n\n# Number of images taken and generated\n# In order to estimate generator with FID metric\nN_IMAGES = 10_000","e0027996":"def scale_images(images, new_shape):\n    \"\"\"\n    Scale an array of images to a new size\n    \n    Parameters\n    ----------\n    images : list\n        List of images. Each image have shape - (C, H_old, W_old)\n        Where:\n            C - color dimension of the image;\n            H_old - height of the image;\n            W_old - width of the image.\n    new_shape : list or tuple\n        (H, W), Height and Width of the result image\n    \n    Return\n    ------\n    list\n        List of images with shape equal to `new_shape`\n    \n    \"\"\"\n    images_list = list()\n    for image in images:\n        # resize with nearest neighbor interpolation\n        new_image = np.transpose(image, (1, 2, 0)) # (C, H, W) --> (H, W, C)\n        new_image = cv2.resize(new_image, new_shape, interpolation = cv2.INTER_NEAREST)\n        if len(new_image.shape) == 2 or new_image.shape[-1] == 1:\n            new_image = cv2.cvtColor(new_image, cv2.COLOR_GRAY2BGR)\n        new_image = np.transpose(new_image, (2, 0, 1)) # (H, W, C) --> (C, H, W)\n        # store\n        images_list.append(new_image)\n    return np.asarray(images_list)","835007ed":"def calculate_fid_batched(model_inception, images1, images2, batch_size=128):\n    assert len(images1) == len(images2)\n    n_batches = len(images1) \/\/ batch_size\n    preds1 = []\n    preds2 = []\n    for i in tqdm(range(n_batches)):\n        batch_img1 = images1[i*batch_size: (i+1)*batch_size]\n        batch_img2 = images2[i*batch_size: (i+1)*batch_size]\n        # Resize images\n        resized_b_img1 = scale_images(batch_img1, (299, 299))\n        resized_b_img2 = scale_images(batch_img2, (299, 299))\n        # Normalize images\n        resized_b_img1 -= np.array([0.485, 0.456, 0.406]).reshape(1, -1, 1, 1)\n        resized_b_img1 \/= np.array([0.229, 0.224, 0.225]).reshape(1, -1, 1, 1)\n        # Run though inception v3 and take prediction\n        act1 = model_inception(torch.tensor(resized_b_img1, device=device)).squeeze().cpu().detach().numpy()\n        act2 = model_inception(torch.tensor(resized_b_img2, device=device)).squeeze().cpu().detach().numpy()\n        preds1.append(act1)\n        preds2.append(act2)\n    act1 = np.concatenate(preds1, axis=0)\n    act2 = np.concatenate(preds2, axis=0)\n    \n    return act1, act2","a82ec257":"def calculate_fid(act1, act2):\n    # calculate mean and covariance statistics\n    mu1, sigma1 = act1.mean(axis=0), np.cov(act1, rowvar=False)\n    mu2, sigma2 = act2.mean(axis=0), np.cov(act2, rowvar=False)\n    # calculate sum squared difference between means\n    ssdiff = np.sum((mu1 - mu2)**2.0)\n    # calculate sqrt of product between cov\n    covmean = sqrtm(sigma1.dot(sigma2))\n    # check and correct imaginary numbers from sqrt\n    if np.iscomplexobj(covmean):\n        covmean = covmean.real\n    # calculate score\n    fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n    return fid","d7f4f6f5":"# prepare the inception v3 model\nmodel = inception_v3(pretrained=True)\nmodel.eval()\n# Remove certain layers from output\nlayer_names = []\nfor layer in list(model.children()):\n    if layer.__class__.__name__ not in ['InceptionAux', 'Linear', 'Dropout']:\n        layer_names.append(layer)\n# Create model without some layers\nmodel = nn.Sequential(*layer_names)\nmodel.eval()\nmodel.to(device=device)\n# Define two batches of images\n# First - real data\nimages1 = shuffle(test_data)[:N_IMAGES]\nimages1 = np.transpose(np.asarray(images1), (0, 3, 1, 2)).astype(np.float32)\n# Images1 in range [0, 255], normalize into [0, 1]\nimages1 \/= 255.0\nimages1 = torch.tensor(images1, device=device).cpu().detach().numpy()\nimages1_labels = np.asarray(shuffle(test_labels_mnist)[:N_IMAGES], dtype=np.int64)\n\nimages2_noise = torch.tensor(\n    np.random.randn(N_IMAGES, NOISE_SIZE).astype(np.float32),\n    device=device\n)\nimage2_labels = torch.tensor(\n    images1_labels, device=device\n)\ngen_nn.eval()\nimages2 = gen_nn(images2_noise, image2_labels).cpu().detach().numpy()\n# Generator generate images in range (-1, 1), normalize into [0, 1] range\nimages2 += 1.0\nimages2 \/= 2.0\nprint('Prepared', images1.shape, images2.shape)\n# Calculate FID with batch size\n# fid between images1 and images1\nact1, act2 = calculate_fid_batched(model, images1, images2)\nfid_same = calculate_fid(act1, act1)\nfid = calculate_fid(act1, act2)\n\n\nprint('FID (same): %.3f' % fid_same)\n# fid between images1 and images2\nprint('FID (different): %.3f' % fid)","35f1fb42":"torch.save(gen_nn.state_dict(), 'model.pth')","bb706dbf":"## Get link to TensorBaord\n### In most cases it starts as https:\/\/xxxx.ngrok.io\n### You can grabe it from print info below","e199d465":"## Now, let's load InceptionV3 and calculate FID","dfc0dded":"### Calculate FID with predictions from InceptioV3","b2f386e9":"# Define Models","226c825f":"## Collect predictions from InceptionV3\u00b6\n### Collect data using certain batch size in order to save memory","8fe9524d":"## Define some useful methods\n## Scale list of images into certain shape","4ab4d7ab":"# Define global constants","a6499ce7":"# Import libraries what we will use in this notebook","761252dc":"# Setup TensorBoard\n## Download Ngrog in order to open TensorBoard in your browser","b1ab94a8":"## Import libraries and define constants","cbad0952":"# Define image generator (data loader)","da416054":"## Define Discriminator model","09f2c1ac":"## Create instance of generator model and test it with noise","75b9689e":"# Read data from CSV file","38cf72af":"# Save model","41cf72ad":"# In this notebook:\n### We will train the Conditional GAN on the Fashion-MNIST dataset. \n### For the training we also will up TensorBoard where we can check intermediate results from generator and loss plots.\n### After training, we will evaluate final generator with FID Metric.\n\n## Some references:\n> #### Training of the Conditional GAN, for more details refer to paper: https:\/\/arxiv.org\/pdf\/1411.1784.pdf\n> #### FID Metric. Calculate how good final generator with FID metric, for more details refer to paper: https:\/\/arxiv.org\/abs\/1706.08500","4ad7623d":"### Define function in order to plot results from generator","c942fc4d":"# Training\n## Define class which controls training of GAN.\n## Main methods: \n> ### `fit` - function which start training of a GAN;\n> ### `compile` - Setup optimizers and losses. Must be called first before training.","41236188":"## In order to download final model - click link below.\n<h1><a href=\"model.pth\"> Download trained generator <\/a><\/h1>","0cde1d87":"## Start training\n### You can observe results from generator and loss values in the TensorBoard","b2c2f5a0":"## Test train loader. \n### Print batch of images","9ef83b49":"## Create instance and compile controller","8231da77":"## Define some utils for layers\/models","1a83bb4f":"# Calculate accuracy with FID metric","75ae5881":"## Define Generator model","5fa831cf":"## Create instance of discriminator model and test it with noise","40ceece5":"# Generate digits with trained model"}}