{"cell_type":{"275afdb1":"code","2946ac69":"code","717e9a35":"code","7f083612":"code","0b3c1152":"code","acbd93b2":"code","120953f2":"code","5ec460ad":"code","82c22887":"code","a4351382":"code","aaf26934":"code","e4a769be":"code","0351e4ec":"code","c6918c4e":"code","60bae39b":"code","0d4dd6a1":"code","2df8833e":"code","42e123b5":"code","d7c0974f":"code","3015ca2a":"code","78ff1ae1":"code","2f258389":"code","ce48e766":"code","9c0ceb79":"code","73537649":"code","8ebbaf99":"code","6e075298":"code","1220f974":"code","0eb11d20":"code","5a85c4b2":"code","6125e5ad":"code","ca25186b":"code","2c5f3fed":"code","3072ca61":"code","a375caa7":"markdown","20b12993":"markdown","e67613a1":"markdown","abb1051a":"markdown","08478c80":"markdown","c790ed99":"markdown","dcb2bed0":"markdown","95196282":"markdown","10290966":"markdown","5603de52":"markdown","2c7a8e7e":"markdown","77d1cb43":"markdown","cbf75106":"markdown"},"source":{"275afdb1":"import tensorflow as tf\nimport tensorflow_addons as tfa\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport PIL\n\n%matplotlib inline","2946ac69":"# text file to all_classes list\nall_classes = []\nfor item in open('\/kaggle\/input\/aicleaves-diseaseprivate-ds\/all_classes.txt').readlines():\n    all_classes.append(item[:-1])","717e9a35":"# submission file sample\nsubmission = pd.read_csv('\/kaggle\/input\/aicleaves-diseaseprivate-ds\/sample_submission.csv')\nsubmission.head(3)","7f083612":"X_test = np.load('\/kaggle\/input\/aicleaves-diseaseprivate-ds\/test-images.npy').astype('float32')\nX_train = np.load('\/kaggle\/input\/aicleaves-diseaseprivate-ds\/train-images.npy').astype('float32')\ny_train = np.load('\/kaggle\/input\/aicleaves-diseaseprivate-ds\/train-labels.npy').astype('float32')\n\nprint(\"Shapes of the Loaded numpy files are....\")\nprint(\"Test Images: \",X_test.shape)\nprint(\"Train_Images: \",X_train.shape)\nprint(\"Train Labels: \",y_train.shape)","0b3c1152":"# Y consists of indices for the classes which we\n# can get from all_classes list\nprint(y_train[:10])\nfor x in y_train[:10]:\n    print(all_classes[int(x)])","acbd93b2":"# Let's see whether the values in\n# X_train and X_test are normalized or not\n# taken mean on image level\n\nprint(X_train[1,:,:,1].mean())\nprint(X_test[1,:,:,1].mean())","120953f2":"def plot_image(image):\n    plt.imshow(image)\n    plt.show()","5ec460ad":"image = X_train[100]\nplot_image(image)","82c22887":"labels = pd.DataFrame(y_train)\nlabels.head(3)","a4351382":"labels.columns = ['Classes']\nlabels.Classes.value_counts()","aaf26934":"## SOME PARAMETERS TO SET\nBATCH_SIZE = 32\nBUFFER_SIZE = 200\nPREFETCH_SIZE = tf.data.experimental.AUTOTUNE","e4a769be":"partition = int(len(X_train)*0.9)\n\ntrain_data = X_train[:partition]\/255\ntrain_labels = y_train[:partition]\n\nvalid_data = X_train[partition:]\/255\nvalid_labels = y_train[partition:]\n\ntest_data = X_test\/255","0351e4ec":"train_dataset = tf.data.Dataset.from_tensor_slices((train_data,train_labels))\nvalid_dataset = tf.data.Dataset.from_tensor_slices((valid_data,valid_labels))\ntest_dataset = tf.data.Dataset.from_tensor_slices((test_data))","c6918c4e":"train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(PREFETCH_SIZE)\nvalid_dataset = valid_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(PREFETCH_SIZE)\ntest_dataset = test_dataset.batch(BATCH_SIZE)","60bae39b":"base_model = tf.keras.applications.DenseNet201(include_top=False,input_shape=(32,32,3))\nbase_model.trainable = False","0d4dd6a1":"inputs = tf.keras.layers.Input(shape=(32,32,3))\nx = base_model(inputs)\n'''\nx = tf.keras.layers.Conv2D(32,(3,3),padding = 'same',activation='relu')(inputs)\nx = tf.keras.layers.Conv2D(32,(3,3),padding = 'same',activation='relu')(x)\nx = tf.keras.layers.MaxPool2D((2,2))(x)\n\nx = tf.keras.layers.Conv2D(128,(3,3),padding='same',activation='relu')(x)\nx = tf.keras.layers.Conv2D(128,(3,3),padding='same',activation='relu')(x)\nx = tf.keras.layers.MaxPool2D((2,2))(x)\n\nx = tf.keras.layers.Conv2D(256,(3,3),padding='same',activation='relu')(x)\n'''\nx = tf.keras.layers.Flatten()(x)\nout = tf.keras.layers.Dense(len(all_classes))(x)\n\nmodel = tf.keras.Model(inputs=[inputs],outputs=[out],name='aic-leaves-cnn')","2df8833e":"inputs = tf.keras.layers.Input(shape=(32,32,3))\nx = tf.keras.layers.Conv2D(32,(3,3),padding = 'same',activation='relu')(inputs)\nx = tf.keras.layers.Conv2D(32,(3,3),padding = 'same',activation='relu')(x)\nx = tf.keras.layers.MaxPool2D((2,2))(x)\n\nx = tf.keras.layers.Conv2D(128,(3,3),padding='same',activation='relu')(x)\nx = tf.keras.layers.Conv2D(128,(3,3),padding='same',activation='relu')(x)\nx = tf.keras.layers.MaxPool2D((2,2))(x)\n\nx = tf.keras.layers.Conv2D(256,(3,3),padding='same',activation='relu')(x)\nx = tf.keras.layers.Flatten()(x)\nout = tf.keras.layers.Dense(len(all_classes))(x)\n\nmodel = tf.keras.Model(inputs=[inputs],outputs=[out],name='aic-leaves-cnn')","42e123b5":"model.summary()","d7c0974f":"optimizer = tf.keras.optimizers.Adam(lr=0.001,decay=1e-4)","3015ca2a":"model.compile(optimizer=optimizer,\n             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n             metrics=['sparse_categorical_accuracy'])","78ff1ae1":"history_wo_drop = model.fit(train_dataset,validation_data=valid_dataset,epochs=20,verbose=1)","2f258389":"history = history_wo_drop","ce48e766":"plt.figure()\nplt.plot(history.history['loss'],c='r')\nplt.plot(history.history['val_loss'],c='g')\nplt.legend()\nplt.show()","9c0ceb79":"plt.figure()\nplt.plot(history.history['accuracy'],c='r')\nplt.plot(history.history['val_accuracy'],c='g')\nplt.legend()\nplt.show()","73537649":"from sklearn.metrics import f1_score,accuracy_score","8ebbaf99":"model.evaluate(valid_dataset)","6e075298":"y_pred = model.predict(valid_data)\ny_labels = y_pred.argmax(1)","1220f974":"f1_score(valid_labels,y_labels,average='macro')","0eb11d20":"accuracy_score(valid_labels,y_labels)","5a85c4b2":"valid_labels,y_labels","6125e5ad":"min(train_labels)","ca25186b":"submission = model.predict(test_dataset)","2c5f3fed":"submission = np.argmax(submission,axis=1)\nsubmission.shape","3072ca61":"import pandas as pd\nsubmission = pd.DataFrame(submission)\nsubmission.to_csv('submission.csv',header=['class_index'],index=False)","a375caa7":"## You can participate in the challenge on AiCrowd for dataset. I m not aware about the policies and thus cannot public the data","20b12993":"## Import Libraries","e67613a1":"#### Yupp Blurry for human eyes! But Can our model do better??","abb1051a":"## Creating Model using Functional API","08478c80":"## EDA Part","c790ed99":"## Evaluate our Predictions","dcb2bed0":"# Before You Move Ahead...\nI apologize but when I started this, I was unaware that I will not be able to submit and thus this notebook does not sure solution however the f1_score as well as accuracy are pretty high on validation data","95196282":"# Run Below for CNN from Scratch Kinda","10290966":"## Read the Files\n\nI am currently using tensorflow for my notebooks as much as possible thus We will be using tf.data.Dataset for reading these tensors and applying batch and shuffling. \n\n\nWe are reading it as np.load to get familiar with shapes and format of the data we have.\n\nAlso we will not be touching our test data at all","5603de52":"## Submission Creation","2c7a8e7e":"## Displaying some images","77d1cb43":"## Run Below for Transfer Learning","cbf75106":"## Using tf.data.Dataset.from_tensor_slices for training input"}}