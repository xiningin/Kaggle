{"cell_type":{"9123053d":"code","47be4b91":"code","1f9be0b5":"code","308efbf1":"code","412eb0f2":"code","b1790570":"code","1801bf0c":"code","a023201a":"code","3eef030d":"code","773901cb":"code","1f4f51dc":"code","53d39df1":"code","43a0872e":"markdown","8da7608b":"markdown","ad37d2e9":"markdown","000a4c1b":"markdown","89d93c10":"markdown","191da91e":"markdown","1ef3c728":"markdown"},"source":{"9123053d":"import torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import SGD\nfrom torch.utils.data.dataset import Dataset\nfrom torchvision import transforms as T\nfrom torch.utils.data import DataLoader\nimport torch\nfrom torch import optim\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport shutil\nimport cv2\nfrom PIL import Image\nimport time\nimport tqdm\nfrom copy import deepcopy\nimport tarfile","47be4b91":"random_seed = 42\ntorch.backends.cudnn.enDatasetable = False\ntorch.manual_seed(random_seed)","1f9be0b5":"def copy(SHARE=0.1, path=\"classification_dataset\/train_\/\", moveto=\"classification_dataset\/test_\/\"):\n    \n    '''copy files from one directory to other one with size proportion '''\n\n    files = os.listdir(path) # find list of all files\n    random_list = np.random.choice(files, int(len(files) * SHARE), replace=False) # take random files\n    random_list.sort() # sort data\n    for f in random_list: # iterate and concat file path + file name\n        src = path + f\n        dst = moveto + f\n        shutil.move(src, dst) # move ramdom files to test directory from train\n    # check the num of files copied\n    number_files = len(os.listdir(moveto))\n    print(number_files)\n\n# RUN ONLY ONE TIME on your local machine and set paths before (create folders)\n# copy(SHARE=0.2)","308efbf1":"# prepare objects\ntrain_tar = '..\/input\/brazilian-coins-dataset-classification25k-images\/train_.tar.xz'\ntest_tar = '..\/input\/brazilian-coins-dataset-classification25k-images\/test_.tar.xz'\n\n# function to extarct \ndef read_tar_to_array(file):\n    '''Read tar file and convert jpg to array witj cv2.\n    From file name extarct labels and convert into array'''\n    # Source https:\/\/www.kaggle.com\/gbonesso\/deep-learning-cnn#Extract-images-and-labels-from-images-in-tar.gz-file\n    tar = tarfile.open(file, \"r:xz\")\n    # lists to store\n    image_list = []\n    label_list = []\n    # iterate over tar file\n    for tarinfo in tar:\n        tar.extract(tarinfo.name) # creare an object with tar info\n        if(tarinfo.name[-4:] == '.jpg'): # select only jpg files\n            image_list.append(Image.open(tarinfo.name).convert(\"RGB\"))\n#             image_list.append(np.array(cv2.imread(tarinfo.name, cv2.IMREAD_COLOR))) # transfrom with cv2 photo fils into arrays\n            label_list.append(tarinfo.name.split('_\/')[1]) # split lables from file names \n                              \n#         \"if(tarinfo.isdir()):\n#             os.rmdir(tarinfo.name) # check is name exist\n#         else:\n#             os.remove(tarinfo.name)\"\n    tar.close() #close tar\n    \n    labels = np.array([i.split('_', 1)[0] for i in label_list]) # slit one more time and covert to array \n    \n    return image_list, labels\n\n# convert tar arhive file into PIL obj, extract labels\ntest_img, test_labels = read_tar_to_array(test_tar)\ntrain_img, train_labels = read_tar_to_array(train_tar)\n\n# check the lenght of the train test files\nlen(test_img), len(test_labels), len(train_img), len(train_labels)","412eb0f2":"class BrazillianCoins(Dataset):\n    \n    def __init__(self, file):\n        \n        \"\"\" Data set class for images with tranforming, resizing and preparing them to feed CNN by Torch lib\"\"\"\n        \n        # tranform img. Could be 128 * 96 (as 460 to 380 pic size)\n        self.transforms = T.Compose([T.Resize((128, 128)), T.ToTensor(), T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) \n        self.file = file\n\n    def __getitem__(self, idx):\n        # dict for target\n#         class_dic = {'5':0, '10':1, '25':2, '50':3, '100':4} \n        # class selector\n#         target = class_dic[self.labels]\n        # apply transformations\n        filename = self.file[idx]\n        img = self.transforms(filename) \n        \n        return img\n\n    def __len__(self):\n        return len(self.file)","b1790570":"# set class instances of Pytorch tensors\ntest_tensor = BrazillianCoins(test_img)\ntrain_tensor = BrazillianCoins(train_img)","1801bf0c":"# check the lenght of the tensors\nlen(test_tensor), len(train_tensor)","a023201a":"(test_tensor[0][0]).size()","3eef030d":"# set your batch size\nbatch_size = 128\n\n# load train and test into Pytorch format (tensors)\ntrain_ = DataLoader(train_tensor, batch_size=batch_size, shuffle=True)\ntest_ = DataLoader(test_tensor, batch_size=batch_size, shuffle=True)\n\n# Create dict for selectors\nloaders = {'train' : train_, 'test': test_}\nsizes = {'train': len(train_tensor), 'test': len(test_tensor)}","773901cb":"class CNN(nn.Module):\n    \n    def __init__(self, kernels=[3, 3], poolings=[2, 2], channels=[3, 16, 32], \n               paddings=[2, 2], strides=[2, 2], linear_sizes=[32, 32]):\n        \"\"\"\n          Define your NN here.\n          Args:\n            kernels: default [3, 3]. \n              Defines kernel size for each of two convolutional layers.\n              Kernel's width equals its height.\n            poolings: default [2, 2].\n              Deifnes kernel size for each of two pooling layers.\n            channels: default [32, 64]. \n              Defines amount of output channels for each of two convolutional layers.\n            padding: default [1, 1]. \n              Defines padding size for each of two convolutional layers.\n            strides: default [2, 2]. \n              Defines stride size for each of two convolutional layers.\n            linear_sizes: default [32, 32]. \n              Defines layer size for each of fully-connected layers.\n        \"\"\"\n        super(CNN, self).__init__()\n        self.kernels = kernels\n        self.channels = channels\n        self.paddings = paddings\n        self.strides = strides\n        self.max_pooling = poolings\n        self.linear_sizes = linear_sizes\n        self.relu = F.relu\n\n        \"\"\" set CNN structure \"\"\"\n        # set firest 2d layers\n        self.layer_2d_0 = nn.Conv2d(in_channels=self.channels[0], out_channels=self.channels[1], \\\n                      kernel_size=self.kernels[0], stride=self.strides[0], padding=self.paddings[0])\n        # set max pooling\n        self.max_1 = nn.MaxPool2d(self.max_pooling[0])\n         # set firest 2d layers\n        self.layer_2d_1 = nn.Conv2d(in_channels=self.channels[1], out_channels=self.channels[2], \\\n                      kernel_size=self.kernels[1], stride=self.strides[1], padding=self.paddings[1])\n        # set max pooling\n        self.max_2 = nn.MaxPool2d(self.max_pooling[1])\n        # set linear layers \n        self.layer_1 = nn.Linear(in_features=2048, out_features=128, bias=True)\n        self.layer_2 = nn.Linear(in_features=128, out_features=5, bias=True)\n        # flatter layer\n        self.flatten = nn.Flatten(start_dim=1, end_dim=-1) # or we can use .view\n        self.dropout = nn.Dropout(0.5) \n\n        \"\"\" Workflow for hight and wigth and channels for img \n        m1 = 128 - 3 +1 +2 \/ 2 = 64 (64*64, 3 channel)\n        max_pool = 64\/2 = 32 (32*32, 16 channel)\n        m2 = 32 - 3 +1 +2 \/ 2 = (16*16, 32 channel)\n        max_pool = 16\/2 = 8\n        flattern = [8*8*32] = 2048 neurons\n        linear1 = [2048, 128] neurons, size pict\n        linear2 = [128, 5] classs\n        \"\"\"\n\n    def forward(self, X):\n        \"\"\"\n          Forward propagation of your NN.\n\n          Args:\n            X: imput data\n          Returns\n            outputs: nn's output (logits)\n        \"\"\"\n        # First convolution layer\n        X = self.max_1(self.relu(self.layer_2d_0(X)))\n        # second conv layer\n        X = self.max_2(self.relu(self.layer_2d_1(X)))\n        # flatter layer before linear layers\n        X = X.view(-1, 2048) # or flatter self.flatten(X)\n        # dropout\n        X = self.dropout(X)\n        # first linear layer\n        X = self.layer_1(X)\n        # dropout\n        X = self.dropout(X)\n        # second lineat layer\n        logits = self.layer_2(X)\n        # Softmax probs with logits\n        probs = F.softmax(logits, dim=1)\n        \n        return logits, probs ","1f4f51dc":"# params # l_nn.forward(data.reshape(4, -1))  # l_nn.forward(data.view(1024, -1)) the same\nmodel = CNN()\n\n# CUDA\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)","53d39df1":"# test with one image \n\ntest_img = test_tensor[0][0] # by index 0\ntest_img = test_img.unsqueeze(0)\n\nlogits, probs = model.forward(test_img)\ndisplay('Logits of the last linear layer {} \\n with probability {} of class'.format(logits, probs))","43a0872e":"### Class to prepare data for Pytorch.\n\nIt resize, normalize and convert images to tensors along with labels.","8da7608b":"### Function to divide on train and test set\n\nYou can run on your local machine to randomly split data set at prefered proportion. \n\nYou **do not need to** do it Kaggle!","ad37d2e9":"## Set the seed for Pytorch","000a4c1b":"## Load libraries","89d93c10":"## Task is classify what is shown on the photo - 5, 10, 25, 50 or 100 cent coin?\n\n### Plan \n1. Optional. Load all data on your comp, unzip in one directory. \nUse function to ramdomly split all files into two sub directories (train and test) with certain proportion on your local machine.\n2. Load tar data into Kaggle enviroment, convert it into numpy array, extract labels.\n3. Create class from *torch.utils.data.Dataset*.a\n3. Load you data with class.\n4. Build class of *CNN* and LNN.\n5. Train network with train dataset and validate on test one. We save model in training loop each *n* epochs.\n6. Plot results.\n\nUseful links:\n  * [Creating and loading your own dataset](https:\/\/pytorch.org\/tutorials\/beginner\/data_loading_tutorial.html)\n  * [Convolutional layer in Pytorch](https:\/\/pytorch.org\/docs\/stable\/nn.html#conv2d)\n","191da91e":"### Extract files from tar","1ef3c728":"# Build Convolutional Neural Network (CNN) and Linear Neural Network (LNN) from scratch for image classification in Brazilian coins dataset"}}