{"cell_type":{"18312565":"code","b363bd2b":"code","2292319d":"code","ba5fb988":"code","ccbefbe6":"code","44f27c95":"code","8824ac2a":"code","04eb5638":"code","aaec2cf4":"code","04ee397f":"code","d153aabf":"code","e6b3c31a":"code","f23cbabd":"code","fc0bf15b":"code","d39f18bf":"code","7fc73052":"code","f767dc3d":"code","d47acf3c":"code","332f8223":"code","56b324c5":"code","c6acefb0":"code","37a5ad8a":"code","1afe907e":"code","7325ffcf":"code","b38d51c1":"code","29046f72":"code","8c16140b":"code","ce37db73":"code","32cfbb7b":"code","8a5922fd":"code","fa144f76":"code","7cdff405":"code","532de28a":"code","2d9d80fa":"code","6d3b8032":"code","5b604874":"code","0075323e":"code","1fe3b193":"code","550e13bc":"code","e7d9f429":"code","86fb9615":"code","05ae9887":"code","ed27cc8d":"code","07e35ec2":"markdown","8b776fda":"markdown","707aa43e":"markdown","fe9966f2":"markdown","d80cc803":"markdown","3c8f2f25":"markdown","cbf5a1e8":"markdown","4c772379":"markdown","ed50ff17":"markdown","07f56006":"markdown","c8cce8c6":"markdown","1ff9c546":"markdown"},"source":{"18312565":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b363bd2b":"movies = pd.read_csv(\"\/kaggle\/input\/movielens-20m-dataset\/movie.csv\")\nratings = pd.read_csv(\"\/kaggle\/input\/movielens-20m-dataset\/rating.csv\")\ntags = pd.read_csv(\"\/kaggle\/input\/movielens-20m-dataset\/tag.csv\")","2292319d":"movies.head(2)","ba5fb988":"ratings.head(2)","ccbefbe6":"tags.head(2)","44f27c95":"movies['genres'] = movies['genres'].str.replace('|', ' ')","8824ac2a":"movies.head()","04eb5638":"len(movies['movieId'].unique())","aaec2cf4":"len(ratings['movieId'].unique())","04ee397f":"ratings.shape","d153aabf":"#limit ratings to user ratings that have rated more than 80 movies \n#Otherwise it becomes impossible to pivot the rating dataframe later for collaborative filtering\n\nratings_t = ratings.groupby('userId').filter(lambda x: len(x) > 80)\n\nratings_t","e6b3c31a":"ratings_t.shape","f23cbabd":"#list the movie titles that survive the filtering\nmovie_list_rating = ratings_t.movieId.unique().tolist()","fc0bf15b":"len(ratings_t.movieId.unique())\/len(movies.movieId.unique()) * 100","d39f18bf":"len(ratings_t.userId.unique())\/len(ratings.userId.unique()) * 100","7fc73052":"movies = movies[movies.movieId.isin(movie_list_rating)]","f767dc3d":"movies.shape","d47acf3c":"#map movie to id\nmapping_file = dict(zip(movies.title.tolist(), movies.movieId.tolist()))","332f8223":"tags.drop(['timestamp'], axis = 1, inplace = True)\nratings_t.drop(['timestamp'], axis = 1, inplace = True)","56b324c5":"mixed = pd.merge(movies, tags, on='movieId', how = 'left')\nmixed.head()","c6acefb0":"#create metadata from tags and genres\nmixed.fillna(\"\", inplace = True)\nmixed = pd.DataFrame(mixed.groupby('movieId')['tag'].apply(lambda x: \"%s\" % ' '.join(x)))","37a5ad8a":"Final = pd.merge(movies, mixed, on='movieId', how = 'left')\nFinal ['metadata'] = Final[['tag', 'genres']].apply(lambda x: ' '.join(x), axis = 1)","1afe907e":"Final.head()","7325ffcf":"Final.shape","b38d51c1":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf = TfidfVectorizer(stop_words= 'english')\ntfidf_matrix = tfidf.fit_transform(Final['metadata'])\ntfidf_df = pd.DataFrame(tfidf_matrix.toarray(), index = Final.index.tolist())","29046f72":"tfidf_df.shape","8c16140b":"#Now Compress with SVD\n\nfrom sklearn.decomposition import TruncatedSVD\nsvd = TruncatedSVD(n_components=150)\nlatent_matrix = svd.fit_transform(tfidf_df)","ce37db73":"#Plot this variance grapd to check how much information this 150 features give\n\nimport matplotlib.pyplot as plt\nexplained = svd.explained_variance_ratio_.cumsum()\nplt.plot(explained, '_', ms = 16, color = 'red')\nplt.xlabel('Singular value components', fontsize = 12)\nplt.ylabel('Cumulative percent of variance', fontsize = 12)\nplt.show()","32cfbb7b":"#number of latent dimensions to keep\nn= 150\nlatent_matrix_df = pd.DataFrame(latent_matrix[:, 0:n], index=Final.title.tolist())","8a5922fd":"#our content latent matrix\"\nlatent_matrix.shape","fa144f76":"ratings_t.head()","7cdff405":"ratings_t.shape","532de28a":"ratings_t = ratings_t.iloc[:1000000,:]","2d9d80fa":"ratings_t1 = pd.merge(movies[['movieId']], ratings_t, on='movieId', how = 'right')","6d3b8032":"ratings_t1.shape","5b604874":"from sklearn.neighbors import NearestNeighbors\nfrom scipy.sparse import csr_matrix","0075323e":"movies_users= ratings_t.pivot(index='movieId', columns='userId',values='rating').fillna(0)","1fe3b193":"movies_users.shape","550e13bc":"mat_movies_users=csr_matrix(movies_users.values)","e7d9f429":"model_knn= NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=20)","86fb9615":"model_knn.fit(mat_movies_users)","05ae9887":"from fuzzywuzzy import process","ed27cc8d":"def recommender(movie_name, data,model, n_recommendations ):\n    model.fit(data)\n    idx=process.extractOne(movie_name, movies['title'])[2]\n    print('Movie Selected: ',movies['title'][idx], 'Index: ',idx)\n    print('Searching for recommendations.....')\n    distances, indices=model.kneighbors(data[idx], n_neighbors=n_recommendations)\n    for i in indices:\n        print(movies['title'][i].where(i!=idx))\n    \nrecommender('Jumanji (1995)', mat_movies_users, model_knn,20)","07e35ec2":"# Create a content latent matrix from movie metadata","8b776fda":"# Merge the movies and the tags dataframe and create a metadata tag for each movie:","707aa43e":"**No worries: we still have 97% of the original movie titles in ratings dataframe**","fe9966f2":"# Reading the Data","d80cc803":"# Model Building","3c8f2f25":"# Creating a collaborative latent matrix from user ratings:","cbf5a1e8":"**The first 150 components explains over 50% of the variance**","4c772379":"# Make a Recommendation","ed50ff17":"**But we have only 44% of the users, So now lets filter the movies data frame[](http:\/\/)**","07f56006":"## TF-IDF vectors and truncated SVD:","c8cce8c6":"**ratings data has more than 1.5 milions row, we can't not use all and actually we don't need it, one millions sample is enough for we**\n\n ","1ff9c546":"# Data Preprocessing"}}