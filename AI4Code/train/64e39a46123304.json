{"cell_type":{"e4591dd7":"code","205244b0":"code","f08808da":"code","5d3e8dae":"code","18f07d9a":"code","1f078a10":"code","778c6da6":"code","67f69030":"code","b5274561":"code","62bf4cbe":"code","de1de740":"code","54565442":"code","9d5b2162":"code","8c36999d":"code","680fd187":"code","cb2a1bc1":"code","11f8a00c":"code","63c3aead":"code","2378ed5f":"code","9ff2ab85":"code","e0534d58":"code","78b67863":"code","cb5a8459":"code","fd66821c":"code","8a5ba525":"code","cd29428a":"code","448db558":"code","ce247f90":"code","33e2d020":"code","4bcf4a97":"code","2da0851b":"code","96ee1410":"code","d38dc63d":"code","a4c1059a":"code","da01f039":"code","0708feea":"code","ab9e4c8f":"code","353e931a":"code","0900a3e4":"code","b2b3db85":"code","2b1779d9":"code","75437ac5":"code","acc7876c":"code","6194f490":"code","abcf7c73":"code","b5da7046":"code","518ea637":"code","e3b6b9bf":"code","c4509089":"code","9c35ec1b":"code","fb21a0ee":"code","816ef8bc":"code","a6e8b182":"code","fcbfc72d":"code","6c48473b":"code","26cadb22":"code","eb380cd1":"code","62c58bbb":"code","666c918a":"code","35cd0f27":"code","53c94e8d":"code","8e23683a":"code","e76558e5":"code","6177cb5e":"code","beb45897":"code","24904c8c":"code","d8443f0b":"code","f7e33d32":"code","f57b7607":"code","d26322b4":"code","3c8c7d33":"code","2c5f6b8d":"code","12638338":"code","62f94526":"code","e7b1013d":"code","53301d79":"code","3aedd3ef":"code","c0561f0a":"code","a7b9c3fa":"code","c82c0393":"code","6655f252":"code","ef9cce73":"code","843f5b48":"code","3e58c720":"code","e0e3dabe":"code","8cde844d":"code","5afeba68":"code","ae170fb6":"code","33aec4a9":"code","0fbdd0fc":"code","21f8b13f":"code","781ba09c":"code","ba569b4c":"code","6ce04b97":"code","84cf809c":"code","ea9bd956":"code","70f03ccb":"code","31cb6b5f":"code","85318cd8":"code","b286eef2":"code","5ff2448d":"code","3a3297f7":"code","7341e59f":"code","0f89da30":"code","7fa9f2fe":"code","67a44726":"code","490ae0f6":"code","11dd3cd4":"code","12bfa67c":"code","1951803c":"code","8ff8c2bb":"code","436d4f26":"code","298be837":"code","4eab559d":"code","484b5bdb":"code","6ca0d3e6":"code","b2ccd73c":"code","159b4229":"code","cb35e303":"code","687ee7d0":"code","81e1cd4f":"code","66114aa2":"code","e918ecb2":"code","5292aef9":"code","85c02537":"code","24d6ac0a":"code","a63d8cd0":"code","9cdd3e34":"code","4a1471f0":"markdown","1282b977":"markdown","743c28da":"markdown","a0cdfbca":"markdown","0bf0a7af":"markdown","e2bbea40":"markdown","6086101f":"markdown","8a55cc9e":"markdown","837038ba":"markdown","f429637b":"markdown","0fd81233":"markdown","05c9bab2":"markdown","e686eb6c":"markdown","04af12a1":"markdown","ab7ac1a1":"markdown","82dc4b55":"markdown","2e4febba":"markdown","2925c356":"markdown","12fe6680":"markdown","7732fdaa":"markdown","79f12fdd":"markdown","f0798211":"markdown","ebdd9f43":"markdown","03d12bd6":"markdown","ae36a23b":"markdown","62680478":"markdown","eb74c1c0":"markdown","17991003":"markdown","b676c162":"markdown","7e4b91fa":"markdown","09fb13d5":"markdown","b34d3422":"markdown","23e07a80":"markdown","22d5bb88":"markdown","7c33c405":"markdown","95782a27":"markdown","61f654ca":"markdown","3bae3cf1":"markdown","74c2bc7e":"markdown","7b6fa941":"markdown","470fe9cd":"markdown","6af5feaa":"markdown"},"source":{"e4591dd7":"import numpy as np\nimport pandas as pd\n\nimport cv2\n\nimport scipy\nfrom scipy import ndimage\nfrom scipy.ndimage.filters import gaussian_filter\nfrom scipy.ndimage import zoom\nimport random\n\nfrom tqdm.auto import tqdm\ntqdm.pandas()\n\nfrom skimage.io import imread\nfrom skimage.transform import resize\nfrom keras.utils import Sequence\nimport math\n\nimport PIL\nfrom PIL import Image, ImageOps\nimport matplotlib.pylab as plt\n\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, GroupShuffleSplit # Used to use Kfold to train our model\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.layers import Dense, Flatten, Input\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, Activation\nfrom tensorflow.keras.layers import Conv3D, MaxPooling3D\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import backend as K # The backend give us access to tensorflow operations and allow us to create the Attention class\n#from tensorflow.keras.models import Sequential\nimport matplotlib.pylab as plt\n\nfrom tensorflow.keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n                             EarlyStopping, ReduceLROnPlateau,CSVLogger)\n                             \nfrom sklearn.model_selection import train_test_split\n","205244b0":"from keras.callbacks import Callback\nfrom keras import backend as K\n\nclass CyclicLR(Callback):\n    def __init__(\n            self,base_lr=0.001,\n            max_lr=0.006,step_size=2000.,\n            mode='triangular',gamma=1.,\n            scale_fn=None,scale_mode='cycle'):\n        \n        super(CyclicLR, self).__init__()\n\n        if mode not in ['triangular', 'triangular2','exp_range']:\n            raise KeyError(\"mode must be one of 'triangular', \"\n                           \"'triangular2', or 'exp_range'\")\n        self.base_lr = base_lr\n        self.max_lr = max_lr\n        self.step_size = step_size\n        self.mode = mode\n        self.gamma = gamma\n        if scale_fn is None:\n            if self.mode == 'triangular':\n                self.scale_fn = lambda x: 1.\n                self.scale_mode = 'cycle'\n            elif self.mode == 'triangular2':\n                self.scale_fn = lambda x: 1 \/ (2.**(x - 1))\n                self.scale_mode = 'cycle'\n            elif self.mode == 'exp_range':\n                self.scale_fn = lambda x: gamma ** x\n                self.scale_mode = 'iterations'\n        else:\n            self.scale_fn = scale_fn\n            self.scale_mode = scale_mode\n        self.clr_iterations = 0.\n        self.trn_iterations = 0.\n        self.history = {}\n\n        self._reset()\n\n    def _reset(self, new_base_lr=None, new_max_lr=None,\n               new_step_size=None):\n        if new_base_lr is not None:\n            self.base_lr = new_base_lr\n        if new_max_lr is not None:\n            self.max_lr = new_max_lr\n        if new_step_size is not None:\n            self.step_size = new_step_size\n        self.clr_iterations = 0.\n        \n    def clr(self):\n        cycle = np.floor(1 + self.clr_iterations \/ (2 * self.step_size))\n        x = np.abs(self.clr_iterations \/ self.step_size - 2 * cycle + 1)\n        if self.scale_mode == 'cycle':\n            return self.base_lr + (self.max_lr - self.base_lr) * \\\n                np.maximum(0, (1 - x)) * self.scale_fn(cycle)\n        else:\n            return self.base_lr + (self.max_lr - self.base_lr) * \\\n                np.maximum(0, (1 - x)) * self.scale_fn(self.clr_iterations)\n\n    def on_train_begin(self, logs={}):\n        logs = logs or {}\n\n        if self.clr_iterations == 0:\n            K.set_value(self.model.optimizer.lr, self.base_lr)\n        else:\n            K.set_value(self.model.optimizer.lr, self.clr())\n\n    def on_batch_end(self, epoch, logs=None):\n\n        logs = logs or {}\n        self.trn_iterations += 1\n        self.clr_iterations += 1\n        K.set_value(self.model.optimizer.lr, self.clr())\n\n        self.history.setdefault(\n            'lr', []).append(\n            K.get_value(\n                self.model.optimizer.lr))\n        self.history.setdefault('iterations', []).append(self.trn_iterations)\n\n        for k, v in logs.items():\n            self.history.setdefault(k, []).append(v)\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        logs['lr'] = K.get_value(self.model.optimizer.lr)","f08808da":"batch_size = 8\nepochs = 50\n#epochs = 3\n#epochs = 10\n\n#how many splits to do on the training data, or how many cross-validation rounds to use\n#N_SPLITS = 5\n\nN_SPLITS = 2\n#my_test_pct is a percentage of values left out of test\/validation data to compare the final model against known results\nmy_test_pct = 0.05\n\n#there are some different sizes of images in my rescaled dataset, so using some of those here\n#because the 3D arrays are quite large, they tend to take memory and this (192) was a size that did not cause out of memory errors\n#img_size = 192\nimg_size = 256\n#img_size = 512\nimg_depth = 30\n\n","5d3e8dae":"!ls \/kaggle\/input\/osic-pulmonary-fibrosispreprocessed","18f07d9a":"df_train_orig = pd.read_csv(\"\/kaggle\/input\/osic-pulmonary-fibrosis-progression\/train.csv\")\ndf_train = pd.read_csv(\"\/kaggle\/input\/osic-pulmonary-fibrosispreprocessed\/dataset\/df_train_scaled_continous_smoke.csv\").drop(\"Unnamed: 0\", axis=1)\ndf_train.head()","1f078a10":"df_train[\"SmokingStatus\"].unique()","778c6da6":"df_test = pd.read_csv(\"\/kaggle\/input\/osic-pulmonary-fibrosis-progression\/test.csv\")\ndf_test.head()","67f69030":"DATA_DIR = \"\/kaggle\/input\/osic-pulmonary-fibrosispreprocessed\/dataset\"","b5274561":"df_train[df_train[\"Patient\"] == \"ID00126637202218610655908\"]","62bf4cbe":"patient_ids = df_train[\"Patient\"].unique()\npatient_ids.shape","de1de740":"patient_id = \"ID00047637202184938901501\"\npatient_fvc = df_train[df_train[\"Patient\"] == patient_id]\npatient_fvc","54565442":"#this is the original data from kaggle competition, no preprocessing done\n!ls \/kaggle\/input\/osic-pulmonary-fibrosis-progression","9d5b2162":"df_train.head()","8c36999d":"patient_ids = df_train[\"Patient\"].unique()\ntraining_rows = []\npatient_count = 0\nfor patient_id in tqdm(patient_ids):\n    df_patient = df_train[df_train[\"Patient\"] == patient_id]\n    patient_row_count = 0\n    row = df_patient.iloc[0]\n    row_fvc = row[\"FVC\"]\n    patient_row_count += 1\n    training_row = {}\n    training_row[\"patient_id\"] = row[\"Patient\"]\n    training_row[\"base_week\"] = row[\"Weeks\"]\n    training_row[\"pct\"] = row[\"Percent\"]\n    training_row[\"age\"] = row[\"Age\"]\n    training_row[\"gender_female\"] = row[\"Sex_Female\"]\n    training_row[\"gender_male\"] = row[\"Sex_Male\"]\n    training_row[\"smoking_status\"] = row[\"SmokingStatus\"]\n    training_row[\"target_fvc\"] = row[\"fvc_raw\"]\n    training_rows.append(training_row)\n    patient_count += 1\nprint(f\"processed {patient_count} patients\")\n","680fd187":"df_test = pd.read_csv(f\"{DATA_DIR}\/df_test_scaled_continous_smoke.csv\")\ndf_test.head()","cb2a1bc1":"patient_ids = df_test[\"Patient\"].unique()\ntest_rows = []\npatient_count = 0\nfor patient_id in tqdm(patient_ids):\n    df_patient = df_test[df_test[\"Patient\"] == patient_id]\n    patient_row_count = 0\n    for idx, row in df_patient.iterrows():\n        row_fvc = row[\"FVC\"]\n        patient_row_count += 1\n        test_row = {}\n        test_row[\"patient_id\"] = row[\"Patient\"]\n        test_row[\"base_fvc\"] = row_fvc\n        test_row[\"base_week\"] = row[\"Weeks\"]\n        test_row[\"pct\"] = row[\"Percent\"]\n        test_row[\"age\"] = row[\"Age\"]\n        test_row[\"gender_female\"] = row[\"Sex_Female\"]\n        test_row[\"gender_male\"] = row[\"Sex_Male\"]\n        test_row[\"smoking_status\"] = row[\"SmokingStatus\"]\n        test_rows.append(test_row)\n    print(f\"created {patient_row_count} instances for patient {patient_id}\")\n    patient_count += 1\nprint(f\"processed {patient_count} patients\")\n    #break","11f8a00c":"len(test_rows)","63c3aead":"df_new_train = pd.DataFrame(training_rows)\ndf_new_train\n","2378ed5f":"df_new_train.columns","9ff2ab85":"df_train[df_train[\"Patient\"] == \"ID00007637202177411956430\"]","e0534d58":"#the only thing this kernel uses from the x_cols is actually the patient id, as that can be used to find the filename of the image.\n#some other kernels i publish use the other colums as well, which is why they are there\nx_cols = [col for col in df_new_train.columns if col != \"target_fvc\"]\ndf_x = df_new_train[x_cols]\ndf_y = df_new_train[\"target_fvc\"]\n","78b67863":"df_x.head()","cb5a8459":"df_y.head()","fd66821c":"def unison_shuffled_copies(a, b):\n    assert len(a) == len(b)\n    p = np.random.permutation(len(a))\n    new_a = a.iloc[p]\n    new_b = b.iloc[p]\n    return new_a, new_b","8a5ba525":"class MySequence3D(Sequence):\n\n    def __init__(self, x_set, y_set, batch_size, mode=\"train\", augment=True):\n        self.x, self.y = x_set, y_set\n        self.batch_size = batch_size\n        self.mode = mode\n        self.max_idx = math.ceil(len(x_set)\/batch_size)\n        self.augment = augment\n\n    def __len__(self):\n        #TODO: check is correct\n        return int(np.ceil(len(self.x) \/ float(self.batch_size)))\n\n    def __getitem__(self, idx):\n        idx2 = idx % self.max_idx\n        start = idx2 * self.batch_size\n        end = min(start + batch_size, len(self.x))\n        batch_x = self.x.iloc[start : end]\n        batch_y = self.y.iloc[start : end]\n        \n        next_batch_img = []\n        next_batch_num = []\n        for index, row in batch_x.iterrows():\n            #print(row)\n            #nums = [row[col] for col in dense_cols]\n            nums = []\n            nums = np.array(nums)\n            file_name = row[\"patient_id\"]\n            #file_path = row[\"path\"]\n            augmented = img_augment_3d(self.mode, self.x, file_name, self.augment)\n            next_batch_num.append(nums)\n            next_batch_img.append(augmented)\n        np_y = np.array(batch_y)\n        np_x_img = np.array(next_batch_img)\n        np_x_num = np.array(next_batch_num)\n        del next_batch_img\n        del next_batch_num\n        del batch_y\n        #print(f\"loaded shape: {np_x.shape}, batch={idx}\")\n#        result = [np_x_img, np_x_num], np_y\n        result = [np_x_img], np_y\n\n        #print(f\"shapes: {result[0].shape}, {result[1].shape}\")\n        return result\n\n    def on_epoch_end(self):\n        self.x, self.y = unison_shuffled_copies(self.x, self.y)","cd29428a":"#https:\/\/stackoverflow.com\/questions\/43922198\/how-to-rotate-a-3d-image-by-a-random-angle-in-python\ndef random_rotation_3d(img, min_angle, max_angle):\n    \"\"\" Randomly rotate an image by a random angle (-max_angle, max_angle).\n\n    Arguments:\n    max_angle: `float`. The maximum rotation angle.\n\n    Returns:\n    rotated 3D image\n    \"\"\"\n    if random.randint(1,100) > 30:\n        #with some chance, do not rotate at all\n        return img\n    img_rot = np.zeros(img.shape)\n    angle = random.uniform(min_angle, max_angle)\n    if random.randint(1,100) > 50:\n        #in half the cases, rotate left. in other half, rotate right.\n        angle *= -1\n        # Following lines would rotate on z and y axis as well, but not using them in this kernel\n#        # rotate along z-axis\n#        image2 = scipy.ndimage.interpolation.rotate(image1, angle, mode='nearest', axes=(0, 1), reshape=False)\n#        # rotate along y-axis\n#        image3 = scipy.ndimage.interpolation.rotate(image2, angle, mode='nearest', axes=(0, 2), reshape=False)\n\n    # rotate along x-axis\n    img_rot = scipy.ndimage.interpolation.rotate(img, angle, mode='nearest', axes=(1, 2), reshape=False)\n    return img_rot.reshape(img.shape)","448db558":"#https:\/\/stackoverflow.com\/questions\/29920114\/how-to-gauss-filter-blur-a-floating-point-numpy-array\ndef gaussian_blur_3d(img):\n    if random.randint(1,100) > 15:\n        return img\n    sigma = random.uniform(0.1,0.9)\n    blurred = gaussian_filter(img, sigma=sigma)\n    return blurred\n","ce247f90":"#https:\/\/stackoverflow.com\/questions\/7416170\/numpy-reverse-multidimensional-array\ndef x_flip(img):\n    if random.randint(1,100) > 50:\n        flipped = img[:, :, ::-1]\n    else:\n        flipped = img\n    return flipped","33e2d020":"def y_flip(img):\n    if random.randint(1,100) > 70:\n        flipped = img[:, ::-1, :]\n    else:\n        flipped = img\n    return flipped","4bcf4a97":"def x_shift(img, min_shift, max_shift):\n    if random.randint(1,100) > 30:\n        return img\n    shift_dir = 1\n    if random.randint(1,100) > 50:\n        shift_dir = -1\n    roll_amount = random.randint(min_shift, max_shift)\n    roll_amount *= shift_dir\n    img = np.roll(img, roll_amount, axis=2)\n    #z,y,x?\n    if shift_dir > 0:\n        img[:, :, 0:roll_amount] = 0\n    else:\n        img[:, :, roll_amount:] = 0\n#    print(img)\n    return img\n    ","2da0851b":"def y_shift(img, min_shift, max_shift):\n    if random.randint(1,100) > 30:\n        return img\n    shift_dir = 1\n    if random.randint(1,100) > 50:\n        shift_dir = -1\n    roll_amount = random.randint(min_shift, max_shift)\n    roll_amount *= shift_dir\n    img = np.roll(img, roll_amount, axis=1)\n    #z,y,x?\n    if shift_dir > 0:\n        img[:, 0:roll_amount, :] = 0\n    else:\n        img[:, roll_amount:, :] = 0\n#    print(img)\n    return img\n    ","96ee1410":"#https:\/\/stackoverflow.com\/questions\/37119071\/scipy-rotate-and-zoom-an-image-without-changing-its-dimensions\ndef zoom_xy(img, min_zoom, max_zoom):\n    if random.randint(1,100) > 20:\n        return img\n    zoom_factor = random.uniform(min_zoom, max_zoom)\n    h, w = img_size, img_size\n\n    # For multichannel images we don't want to apply the zoom factor to the RGB\n    # dimension, so instead we create a tuple of zoom factors, one per array\n    # dimension, with 1's for any trailing dimensions after the width and height.\n    zoom_tuple = (1, zoom_factor, zoom_factor)\n\n    # Zooming out\n    if zoom_factor < 1:\n\n        # Bounding box of the zoomed-out image within the output array\n        zh = int(np.round(h * zoom_factor))\n        zw = int(np.round(w * zoom_factor))\n        top = (h - zh) \/\/ 2\n        left = (w - zw) \/\/ 2\n\n        # Zero-padding\n        out = np.zeros_like(img)\n        zoomed_img = zoom(img, zoom_tuple, order=0)\n        #print(f\"zoomed shape: {zoomed_img.shape}\")\n        #print(f\"out shape:{out.shape}\")\n        #print(f\"w:{w},h:{h},l:{left},t:{top},zw:{zw}, zh:{zh}\")\n        out[:, top:top+zh, left:left+zw] = zoomed_img\n\n    # Zooming in\n    elif zoom_factor > 1:\n\n        # Bounding box of the zoomed-in region within the input array\n        zh = int(np.ceil(h \/ zoom_factor))\n        zw = int(np.ceil(w \/ zoom_factor))\n        top = (h - zh) \/\/ 2\n        left = (w - zw) \/\/ 2\n\n        #out_template = np.zeros_like(img)\n        out = zoom(img[:, top:top+zh, left:left+zw], zoom_tuple, order=0)\n        #print(f\"out shape:{out.shape}\")\n        #print(f\"w:{w},h:{h},l:{left},t:{top},zw:{zw}, zh:{zh}\")\n\n        # `out` might still be slightly larger than `img` due to rounding, so\n        # trim off any extra pixels at the edges\n        trim_top = ((out.shape[1] - h) \/\/ 2)\n        trim_left = ((out.shape[2] - w) \/\/ 2)\n        #print(f\"out shape before:{out.shape}\")\n        out = out[:, trim_top:trim_top+h, trim_left:trim_left+w]\n        #print(f\"out shape after:{out.shape}\")\n        #print(f\"w:{w},h:{h},l:{left},trimtop:{trim_top},trimleft:{trim_left}\")\n\n    # If zoom_factor == 1, just return the input array\n    else:\n        out = img\n    #print(out.shape)\n    return out","d38dc63d":"#https:\/\/stackoverflow.com\/questions\/37119071\/scipy-rotate-and-zoom-an-image-without-changing-its-dimensions\n#open cv does not seem to support 3d image resizing so cannot do that..\ndef cv2_zoom_xy(img, min_zoom, max_zoom):\n    if random.randint(1,100) > 20:\n        return img\n    zoom_factor = random.uniform(min_zoom, max_zoom)\n    zoom_factor = 2.0\n    print(f\"zf:{zoom_factor}\")\n    height, width = img_size, img_size\n    new_height, new_width = int(height * zoom_factor), int(width * zoom_factor)\n\n    ### Crop only the part that will remain in the result (more efficient)\n    # Centered bbox of the final desired size in resized (larger\/smaller) image coordinates\n    y1, x1 = max(0, new_height - height) \/\/ 2, max(0, new_width - width) \/\/ 2\n    y2, x2 = y1 + height, x1 + width\n    bbox = np.array([y1,x1,y2,x2])\n    # Map back to original image coordinates\n    bbox = (bbox \/ zoom_factor).astype(np.int)\n    y1, x1, y2, x2 = bbox\n    cropped_img = img[:, y1:y2, x1:x2]\n\n    # Handle padding when downscaling\n    resize_height, resize_width = min(new_height, height), min(new_width, width)\n    pad_height1, pad_width1 = (height - resize_height) \/\/ 2, (width - resize_width) \/\/2\n    pad_height2, pad_width2 = (height - resize_height) - pad_height1, (width - resize_width) - pad_width1\n    pad_spec = [(0,0), (pad_height1, pad_height2), (pad_width1, pad_width2)] + [(0,0)] * (img.ndim - 2)\n\n    result = cv2.resize(cropped_img, (img.shape[0], resize_width, resize_height))\n    result = np.pad(result, pad_spec, mode='constant')\n    assert result.shape[0] == height and result.shape[1] == width\n    return result","a4c1059a":"def img_augment_3d(df_name, df, patient_id, do_augment):\n    filename = f\"{DATA_DIR}\/scaled_png\/{df_name}_{img_depth}\/{patient_id}\/full_3d_{img_size}.npy\"\n    img = np.load(filename)\n    img = img \/ 255.0\n    if do_augment:\n        #give it 15% chance of not doing any augmentation\n        if random.randint(1,100) > 15:\n            #you can just comment all but one of below calls to just see effects of a single one later\n            #in which case, you might want to modify above if the > 0 to make it always true and see changes\n            img = gaussian_blur_3d(img)\n            img = x_flip(img)\n            img = y_flip(img)\n            img = random_rotation_3d(img, 1, 5)\n            img = x_shift(img, 5, 15)\n            img = y_shift(img, 5, 15)\n            img = zoom_xy(img, 0.9, 1.1)\n            #pass\n    return img\n","da01f039":"experiment_gen = MySequence3D(df_x, df_y, batch_size, augment=True)","0708feea":"for x in tqdm(range(10)):\n    batch = experiment_gen.__getitem__(0)","ab9e4c8f":"def plot_gen_batch(generator, idx):\n    # configure batch size and retrieve one batch of images\n    plt.clf() #clears matplotlib data and axes\n    #for batch in train_generator:\n    rows = (batch_size \/ 3)+1\n    plt.figure(figsize=[30,10*rows])\n    batch = generator.__getitem__(idx)\n    print(f\"showing {len(batch[0])} images\")\n    #have to use len(batch[0] here, as batch size can vary if it is the last part of the images (truncated to dataset length)\n    for x in range(0, len(batch[0][0])):\n    #    print(train_generator.filenames[x])\n    \n        plt.subplot(rows, 3, x+1)\n        #batch[0] is x, which is [imgs, nums]\n        #batch[0][0] is imgs\n        #so the following line just takes the first slice of each 3D image in the batch\n        img_2d_plane = batch[0][0][x][0]\n        plt.imshow(img_2d_plane, interpolation='nearest')\n\n        num = \"disabled\"\n        y = batch[1][x]\n        print(f\"num: {num}, y: {y}, img min: {img_2d_plane.min()} max: {img_2d_plane.max()}\")\n\n    plt.show()","353e931a":"#this gives length 2, since it is an array of (x,y) batch items\nlen(batch)","0900a3e4":"#with batch size 8 we get 8 images\nlen(batch[0][0])","b2b3db85":"#with img_depth=30 and img_size=192, we get 8 images in a batch, each of size depth(z)=30, height(y)=192, width(x)=192\nbatch[0][0].shape","2b1779d9":"plot_gen_batch(experiment_gen, 0)","75437ac5":"plot_gen_batch(experiment_gen, 0)","acc7876c":"del batch\ndel experiment_gen","6194f490":"h = img_size\nw = img_size\ninput_shape = (h, w, img_depth, 1) #the image has just one color channel\n\nfrom keras.layers.merge import add\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.regularizers import l2\nfrom keras import backend as K","abcf7c73":"def create_cnn_model():\n    img_input = Input(shape=(input_shape), name=\"img_input\")\n    cnn = Conv3D(32, kernel_size=(15), strides=(2), padding='same', activation='relu', kernel_initializer='he_uniform', name=\"conv_3d_1\")(img_input)\n    #cnn = Dropout(0.5)(cnn)\n    #strides=(1,1)?\n    #batchnorm seems to really wreck havoc on the results if added anywhere in the cnn\n    #cnn = BatchNormalization()(cnn)\n    #cnn = MaxPooling3D(pool_size=(2,2,2))(cnn) #strides=(2,2)?\n    #cnn = Dropout(0.6)(cnn)\n    cnn = Conv3D(32, kernel_size=(7), strides=(2), padding='same', activation='relu', kernel_initializer='he_uniform', name=\"conv_3d_2\")(img_input)\n    #cnn = Dropout(0.5)(cnn)\n    #strides=(1,1)?\n    #cnn = BatchNormalization()(cnn)\n    cnn = MaxPooling3D(pool_size=(2,2,2), strides=(2, 2, 2))(cnn) #strides=(2,2)?\n    #cnn = Dropout(0.45)(cnn)\n    cnn = Conv3D(64, kernel_size=(3), strides=(1), padding='same', activation='relu', kernel_initializer='he_uniform', name=\"conv_3d_3\")(cnn)\n    cnn = Conv3D(64, kernel_size=(3), strides=(2), padding='same', activation='relu', kernel_initializer='he_uniform', name=\"conv_3d_4\")(cnn)\n    #cnn = BatchNormalization()(cnn)\n    #cnn = MaxPooling3D(pool_size=(2,2,2), strides=(2, 2, 2))(cnn) #strides=(2,2)?\n    #cnn = Dropout(0.45)(cnn)\n    #cnn = Conv3D(128, kernel_size=(5), strides=(1), padding='same', activation='relu', kernel_initializer='he_uniform', name=\"conv_3d_5\")(cnn)\n    #cnn = Conv3D(128, kernel_size=(3), strides=(2), padding='same', activation='relu', kernel_initializer='he_uniform', name=\"conv_3d_6\")(cnn)\n    #cnn = BatchNormalization()(cnn)\n    cnn = MaxPooling3D(pool_size=(2,2,2), strides=(2, 2, 2))(cnn) #strides=(2,2)?\n    #cnn = Dropout(0.3)(cnn)\n    flatten = Flatten()(cnn)\n    final_cnn_dense = Dense(100, activation='relu')(flatten)\n    model = keras.Model(\n        inputs=[img_input],\n        outputs=[final_cnn_dense],\n    )\n    return model\n","b5da7046":"# model2 = create_cnn_model()\n# model2.summary()","518ea637":"#tried a few options, just rename the one to try as \"create_cnn_model\" and run the thing..\ndef create_cnn_model_small():\n    img_input = Input(shape=(input_shape), name=\"img_input\")\n    cnn = Conv3D(32, kernel_size=(5), strides=(2), padding='same', activation='relu', kernel_initializer='he_uniform', name=\"conv_3d_1\")(img_input)\n    cnn = MaxPooling3D(pool_size=(2,2,2), strides=(2))(cnn)\n    cnn = Conv3D(64, kernel_size=(3), strides=(2), padding='same', activation='relu', kernel_initializer='he_uniform', name=\"conv_3d_2\")(img_input)\n    cnn = MaxPooling3D(pool_size=(2,2,2), strides=(2, 2, 2))(cnn)\n    flatten = Flatten()(cnn)\n    final_cnn_dense = Dense(100, activation='relu')(flatten)\n    model = keras.Model(\n        inputs=[img_input],\n        outputs=[final_cnn_dense],\n    )\n    return model\n","e3b6b9bf":"def _bn_relu_conv3d(**conv_params):\n    \"\"\"Helper to build a  BN -> relu -> conv3d block.\"\"\"\n    filters = conv_params[\"filters\"]\n    kernel_size = conv_params[\"kernel_size\"]\n    strides = conv_params.setdefault(\"strides\", (1, 1, 1))\n    kernel_initializer = conv_params.setdefault(\"kernel_initializer\",\n                                                \"he_normal\")\n    padding = conv_params.setdefault(\"padding\", \"same\")\n    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\",\n                                                l2(1e-4))\n\n    def f(input):\n        activation = _bn_relu(input)\n        return Conv3D(filters=filters, kernel_size=kernel_size,\n                      strides=strides, kernel_initializer=kernel_initializer,\n                      padding=padding,\n                      kernel_regularizer=kernel_regularizer)(activation)\n    return f","c4509089":"# ResBlocks\n\nfrom keras.regularizers import l2\nkernel_regularizer=l2(1e-4)\n#CHANNEL_AXIS = 3\ndef resnet_3d():\n    img_input = Input(shape=(input_shape), name=\"img_input\")\n    \n    ## First layer\n    conv1 = Conv3D(filters=32, kernel_size=(5, 5, 5),\n                           strides=(2,2,2), padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=kernel_regularizer\n                           )(img_input)\n    #print(conv1.shape)\n    conv11 = Conv3D(filters=32, kernel_size=(5, 5, 5),\n                           strides=(1,1,1), padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=kernel_regularizer\n                           )(conv1)\n    \n    norm1 = BatchNormalization(axis=-1)(conv11)\n    relu1 = Activation(\"relu\")(norm1)\n    #print(relu1.shape)\n    residual1 = Conv3D(filters=32, kernel_size=(3, 3, 3),\n                           strides=(1,1,1), padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=kernel_regularizer\n                           )(relu1)\n    #print(residual1.shape)\n    resblock1 = add([conv1, residual1])\n    \n    conv2 = Conv3D(filters=64, kernel_size=(5, 5, 5),\n                           strides=(2,2,2), padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=kernel_regularizer\n                           )(resblock1)\n    \n    conv22 = Conv3D(filters=64, kernel_size=(5, 5, 5),\n                           strides=(1,1,1), padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=kernel_regularizer\n                           )(conv2)\n\n    \n    norm2 = BatchNormalization(axis=-1)(conv22)\n    relu2 = Activation(\"relu\")(norm2)\n    #print(relu1.shape)\n    residual2 = Conv3D(filters=64, kernel_size=(3, 3, 3),\n                           strides=(1,1,1), padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=kernel_regularizer\n                           )(relu2)\n    #print(residual1.shape)\n    resblock2 = add([conv2, residual2])\n    \n    \n    conv3 = Conv3D(filters=64, kernel_size=(3, 3, 3),\n                           strides=(2,2,2), padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=kernel_regularizer\n                           )(resblock2)\n    \n    conv33 = Conv3D(filters=128, kernel_size=(3, 3, 3),\n                           strides=(1,1,1), padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=kernel_regularizer\n                           )(conv3)\n\n    \n    norm3 = BatchNormalization(axis=-1)(conv3)\n    relu3 = Activation(\"relu\")(norm3)\n    #print(relu1.shape)\n    residual3 = Conv3D(filters=64, kernel_size=(3, 3, 3),\n                           strides=(1,1,1), padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=kernel_regularizer\n                           )(relu3)\n    #print(residual1.shape)\n    resblock3 = add([conv3, residual3])\n    \n    conv4 = Conv3D(filters=16, kernel_size=(3, 3, 3),\n                           strides=(2,2,2), padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=kernel_regularizer\n                           )(resblock3)\n    \n    conv44 = Conv3D(filters=16, kernel_size=(3, 3, 3),\n                           strides=(1,1,1), padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=kernel_regularizer\n                           )(conv4)\n\n    \n    norm4 = BatchNormalization(axis=-1)(conv44)\n    relu4 = Activation(\"relu\")(norm4)\n    #print(relu1.shape)\n    residual4 = Conv3D(filters=16, kernel_size=(3, 3, 3),\n                           strides=(1,1,1), padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=kernel_regularizer\n                           )(relu4)\n    #print(residual1.shape)\n    resblock4 = add([conv4, residual4])\n    \n    conv5 = Conv3D(filters=16, kernel_size=(3, 3, 3),\n                           strides=(2,2,1), padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=kernel_regularizer\n                           )(resblock4)\n    \n    \n#     #cnn = Conv3D(32, kernel_size=(5), strides=(2), padding='same', activation='relu', kernel_initializer='he_uniform', name=\"conv_3d_1\")(img_input)\n#     cnn = MaxPooling3D(pool_size=(2,2,2), strides=(2))(cnn)\n#     cnn = Conv3D(64, kernel_size=(3), strides=(2), padding='same', activation='relu', kernel_initializer='he_uniform', name=\"conv_3d_2\")(img_input)\n#     cnn = MaxPooling3D(pool_size=(2,2,2), strides=(2, 2, 2))(cnn)\n    flatten = Flatten()(conv5)\n    final_cnn_dense = Dense(512, activation='relu')(flatten)\n    model = keras.Model(\n        inputs=[img_input],\n        outputs=[final_cnn_dense],\n    )\n    return model\n\n\nmodel = resnet_3d()\n#model.summary()","9c35ec1b":"# model.summary()","fb21a0ee":"# model = resnet_3d()\n# model.summary()","816ef8bc":"input_shape","a6e8b182":"# import six\n# from math import ceil\n# from keras.models import Model\n# from keras.layers import (\n#     Input,\n#     Activation,\n#     Dense,\n#     Flatten\n# )\n# from keras.layers.convolutional import (\n#     Conv3D,\n#     AveragePooling3D,\n#     MaxPooling3D\n# )\n# from keras.layers.merge import add\n# from keras.layers.normalization import BatchNormalization\n# from keras.regularizers import l2\n# from keras import backend as K\n\n\n# def _bn_relu(input):\n#     \"\"\"Helper to build a BN -> relu block (by @raghakot).\"\"\"\n#     norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n#     return Activation(\"relu\")(norm)\n\n\n# def _conv_bn_relu3D(**conv_params):\n#     filters = conv_params[\"filters\"]\n#     kernel_size = conv_params[\"kernel_size\"]\n#     strides = conv_params.setdefault(\"strides\", (1, 1, 1))\n#     kernel_initializer = conv_params.setdefault(\n#         \"kernel_initializer\", \"he_normal\")\n#     padding = conv_params.setdefault(\"padding\", \"same\")\n#     kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\",\n#                                                 l2(1e-4))\n\n#     def f(input):\n#         conv = Conv3D(filters=filters, kernel_size=kernel_size,\n#                       strides=strides, kernel_initializer=kernel_initializer,\n#                       padding=padding,\n#                       kernel_regularizer=kernel_regularizer)(input)\n#         return _bn_relu(conv)\n\n#     return f\n\n\n# def _bn_relu_conv3d(**conv_params):\n#     \"\"\"Helper to build a  BN -> relu -> conv3d block.\"\"\"\n#     filters = conv_params[\"filters\"]\n#     kernel_size = conv_params[\"kernel_size\"]\n#     strides = conv_params.setdefault(\"strides\", (1, 1, 1))\n#     kernel_initializer = conv_params.setdefault(\"kernel_initializer\",\n#                                                 \"he_normal\")\n#     padding = conv_params.setdefault(\"padding\", \"same\")\n#     kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\",\n#                                                 l2(1e-4))\n\n#     def f(input):\n#         activation = _bn_relu(input)\n#         return Conv3D(filters=filters, kernel_size=kernel_size,\n#                       strides=strides, kernel_initializer=kernel_initializer,\n#                       padding=padding,\n#                       kernel_regularizer=kernel_regularizer)(activation)\n#     return f\n\n\n# def _shortcut3d(input, residual):\n#     \"\"\"3D shortcut to match input and residual and merges them with \"sum\".\"\"\"\n#     stride_dim1 = ceil(input.shape[DIM1_AXIS] \\\n#         \/ residual.shape[DIM1_AXIS])\n#     stride_dim2 = ceil(input.shape[DIM2_AXIS] \\\n#         \/ residual.shape[DIM2_AXIS])\n#     stride_dim3 = ceil(input.shape[DIM3_AXIS] \\\n#         \/ residual.shape[DIM3_AXIS])\n#     equal_channels = residual.shape[CHANNEL_AXIS] \\\n#         == input.shape[CHANNEL_AXIS]\n\n#     shortcut = input\n#     if stride_dim1 > 1 or stride_dim2 > 1 or stride_dim3 > 1 \\\n#             or not equal_channels:\n#         shortcut = Conv3D(\n#             filters=residual.shape[CHANNEL_AXIS],\n#             kernel_size=(1, 1, 1),\n#             strides=(stride_dim1, stride_dim2, stride_dim3),\n#             kernel_initializer=\"he_normal\", padding=\"valid\",\n#             kernel_regularizer=l2(1e-4)\n#             )(input)\n#     return add([shortcut, residual])\n\n\n# def _residual_block3d(block_function, filters, kernel_regularizer, repetitions,\n#                       is_first_layer=False):\n#     def f(input):\n#         for i in range(repetitions):\n#             strides = (1, 1, 1)\n#             if i == 0 and not is_first_layer:\n#                 strides = (2, 2, 2)\n#             input = block_function(filters=filters, strides=strides,\n#                                    kernel_regularizer=kernel_regularizer,\n#                                    is_first_block_of_first_layer=(\n#                                        is_first_layer and i == 0)\n#                                    )(input)\n#         return input\n\n#     return f\n\n\n# def basic_block(filters, strides=(1, 1, 1), kernel_regularizer=l2(1e-4),\n#                 is_first_block_of_first_layer=False):\n#     \"\"\"Basic 3 X 3 X 3 convolution blocks. Extended from raghakot's 2D impl.\"\"\"\n#     def f(input):\n#         if is_first_block_of_first_layer:\n#             # don't repeat bn->relu since we just did bn->relu->maxpool\n#             conv1 = Conv3D(filters=filters, kernel_size=(3, 3, 3),\n#                            strides=strides, padding=\"same\",\n#                            kernel_initializer=\"he_normal\",\n#                            kernel_regularizer=kernel_regularizer\n#                            )(input)\n#         else:\n#             conv1 = _bn_relu_conv3d(filters=filters,\n#                                     kernel_size=(3, 3, 3),\n#                                     strides=strides,\n#                                     kernel_regularizer=kernel_regularizer\n#                                     )(input)\n\n#         residual = _bn_relu_conv3d(filters=filters, kernel_size=(3, 3, 3),\n#                                    kernel_regularizer=kernel_regularizer\n#                                    )(conv1)\n#         return _shortcut3d(input, residual)\n\n#     return f\n\n\n# def bottleneck(filters, strides=(1, 1, 1), kernel_regularizer=l2(1e-4),\n#                is_first_block_of_first_layer=False):\n#     \"\"\"Basic 3 X 3 X 3 convolution blocks. Extended from raghakot's 2D impl.\"\"\"\n#     def f(input):\n#         if is_first_block_of_first_layer:\n#             # don't repeat bn->relu since we just did bn->relu->maxpool\n#             conv_1_1 = Conv3D(filters=filters, kernel_size=(1, 1, 1),\n#                               strides=strides, padding=\"same\",\n#                               kernel_initializer=\"he_normal\",\n#                               kernel_regularizer=kernel_regularizer\n#                               )(input)\n#         else:\n#             conv_1_1 = _bn_relu_conv3d(filters=filters, kernel_size=(1, 1, 1),\n#                                        strides=strides,\n#                                        kernel_regularizer=kernel_regularizer\n#                                        )(input)\n\n#         conv_3_3 = _bn_relu_conv3d(filters=filters, kernel_size=(3, 3, 3),\n#                                    kernel_regularizer=kernel_regularizer\n#                                    )(conv_1_1)\n#         residual = _bn_relu_conv3d(filters=filters * 4, kernel_size=(1, 1, 1),\n#                                    kernel_regularizer=kernel_regularizer\n#                                    )(conv_3_3)\n\n#         return _shortcut3d(input, residual)\n\n#     return f\n\n\n# def _handle_data_format():\n#     global DIM1_AXIS\n#     global DIM2_AXIS\n#     global DIM3_AXIS\n#     global CHANNEL_AXIS\n#     if K.image_data_format() == 'channels_last':\n#         DIM1_AXIS = 1\n#         DIM2_AXIS = 2\n#         DIM3_AXIS = 3\n#         CHANNEL_AXIS = 4\n#     else:\n#         CHANNEL_AXIS = 1\n#         DIM1_AXIS = 2\n#         DIM2_AXIS = 3\n#         DIM3_AXIS = 4\n\n\n# def _get_block(identifier):\n#     if isinstance(identifier, six.string_types):\n#         res = globals().get(identifier)\n#         if not res:\n#             raise ValueError('Invalid {}'.format(identifier))\n#         return res\n#     return identifier\n\n\n# class Resnet3DBuilder(object):\n#     \"\"\"ResNet3D.\"\"\"\n\n#     @staticmethod\n#     def build(input_shape, num_outputs, block_fn, repetitions, reg_factor):\n#         \"\"\"Instantiate a vanilla ResNet3D keras model.\n#         # Arguments\n#             input_shape: Tuple of input shape in the format\n#             (conv_dim1, conv_dim2, conv_dim3, channels) if dim_ordering='tf'\n#             (filter, conv_dim1, conv_dim2, conv_dim3) if dim_ordering='th'\n#             num_outputs: The number of outputs at the final softmax layer\n#             block_fn: Unit block to use {'basic_block', 'bottlenack_block'}\n#             repetitions: Repetitions of unit blocks\n#         # Returns\n#             model: a 3D ResNet model that takes a 5D tensor (volumetric images\n#             in batch) as input and returns a 1D vector (prediction) as output.\n#         \"\"\"\n#         _handle_data_format()\n#         if len(input_shape) != 4:\n#             raise ValueError(\"Input shape should be a tuple \"\n#                              \"(conv_dim1, conv_dim2, conv_dim3, channels) \"\n#                              \"for tensorflow as backend or \"\n#                              \"(channels, conv_dim1, conv_dim2, conv_dim3) \"\n#                              \"for theano as backend\")\n\n#         block_fn = _get_block(block_fn)\n#         input = Input(shape=input_shape)\n        \n        \n        \n#         # first conv\n#         conv1 = _conv_bn_relu3D(filters=64, kernel_size=(7, 7, 7),\n#                                 strides=(2, 2, 2),\n#                                 kernel_regularizer=l2(reg_factor)\n#                                 )(input)\n#         pool1 = MaxPooling3D(pool_size=(3, 3, 3), strides=(2, 2, 2),\n#                              padding=\"same\")(conv1)\n\n#         # repeat blocks\n#         block = pool1\n#         filters = 64\n#         for i, r in enumerate(repetitions):\n#             block = _residual_block3d(block_fn, filters=filters,\n#                                       kernel_regularizer=l2(reg_factor),\n#                                       repetitions=r, is_first_layer=(i == 0)\n#                                       )(block)\n#             filters *= 2\n\n#         # last activation\n#         block_output = _bn_relu(block)\n\n#         # average poll and classification\n#         pool2 = AveragePooling3D(pool_size=(block.shape[DIM1_AXIS],\n#                                             block.shape[DIM2_AXIS],\n#                                             block.shape[DIM3_AXIS]),\n#                                  strides=(1, 1, 1))(block_output)\n#         flatten1 = Flatten()(pool2)\n#         if num_outputs > 1:\n#             dense = Dense(units=num_outputs,\n#                           kernel_initializer=\"he_normal\",\n#                           activation=\"softmax\",\n#                           kernel_regularizer=l2(reg_factor))(flatten1)\n#         else:\n#             dense = Dense(units=num_outputs,\n#                           kernel_initializer=\"he_normal\",\n#                           activation=\"sigmoid\",\n#                           kernel_regularizer=l2(reg_factor))(flatten1)\n\n#         model = Model(inputs=input, outputs=dense)\n#         return model\n\n#     @staticmethod\n#     def build_resnet_18(input_shape, num_outputs, reg_factor=1e-4):\n#         \"\"\"Build resnet 18.\"\"\"\n#         return Resnet3DBuilder.build(input_shape, num_outputs, basic_block,\n#                                      [2, 2, 2, 2], reg_factor=reg_factor)\n\n#     @staticmethod\n#     def build_resnet_34(input_shape, num_outputs, reg_factor=1e-4):\n#         \"\"\"Build resnet 34.\"\"\"\n#         return Resnet3DBuilder.build(input_shape, num_outputs, basic_block,\n#                                      [3, 4, 6, 3], reg_factor=reg_factor)\n\n#     @staticmethod\n#     def build_resnet_50(input_shape, num_outputs, reg_factor=1e-4):\n#         \"\"\"Build resnet 50.\"\"\"\n#         return Resnet3DBuilder.build(input_shape, num_outputs, bottleneck,\n#                                      [3, 4, 6, 3], reg_factor=reg_factor)\n\n#     @staticmethod\n#     def build_resnet_101(input_shape, num_outputs, reg_factor=1e-4):\n#         \"\"\"Build resnet 101.\"\"\"\n#         return Resnet3DBuilder.build(input_shape, num_outputs, bottleneck,\n#                                      [3, 4, 23, 3], reg_factor=reg_factor)\n\n#     @staticmethod\n#     def build_resnet_152(input_shape, num_outputs, reg_factor=1e-4):\n#         \"\"\"Build resnet 152.\"\"\"\n#         return Resnet3DBuilder.build(input_shape, num_outputs, bottleneck,\n#                                      [3, 8, 36, 3], reg_factor=reg_factor)","fcbfc72d":"\n# from tensorflow.keras.optimizers import Adam\n# adam = tensorflow.keras.optimizers.Adam(lr=0.01)\n\n# #model = Resnet3DBuilder.build_resnet_34(input_shape, 1) ## Input dimensions and no. of outputs\n\n# model = resnet_3d()\n\n# model.compile(loss='mean_squared_error',\n#                   optimizer=adam,  #keras.optimizers.SGD(lr=0.01),\n#                   metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n# #model.fit(X_train, y_train, batch_size=32)","6c48473b":"C1, C2 = tf.constant(70, dtype='float32'), tf.constant(1000, dtype=\"float32\")\n\ndef score(y_true, y_pred):\n    tf.dtypes.cast(y_true, tf.float32)\n    tf.dtypes.cast(y_pred, tf.float32)\n    sigma = y_pred[:, 2] - y_pred[:, 0]\n    fvc_pred = y_pred[:, 1]\n    \n    #sigma_clip = sigma + C1\n    sigma_clip = tf.maximum(sigma, C1)\n    delta = tf.abs(y_true[:, 0] - fvc_pred)\n    delta = tf.minimum(delta, C2)\n    sq2 = tf.sqrt( tf.dtypes.cast(2, dtype=tf.float32) )\n    metric = (delta \/ sigma_clip)*sq2 + tf.math.log(sigma_clip* sq2)\n    return K.mean(metric)\n\ndef qloss(y_true, y_pred):\n    # Pinball loss for multiple quantiles\n    qs = [0.2, 0.50, 0.8]\n    q = tf.constant(np.array([qs]), dtype=tf.float32)\n    e = y_true - y_pred\n    v = tf.maximum(q*e, (q-1)*e)\n    return K.mean(v)\n\ndef mloss(_lambda):\n    def loss(y_true, y_pred):\n        return _lambda * qloss(y_true, y_pred) + (1 - _lambda)*score(y_true, y_pred)\n    return loss","26cadb22":"import tensorflow as tf\nimport tensorflow_addons as tfa\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.models as M","eb380cd1":"from tensorflow.keras.optimizers import Adam\n\n# q loss model\n\ndef create_model():\n#     cnn_model = create_cnn_model()\n\n    cnn_model = resnet_3d()\n    \n    x = Dropout(0.5)(cnn_model.output)\n    x = Dense(256, activation=\"relu\")(x)\n    x = Dropout(0.4)(x)\n    x = Dense(128, activation=\"relu\")(x)\n    x = Dropout(0.4)(x)\n    x = Dense(3, activation=\"linear\", name=\"final_dense\")(x)\n    \n    model = keras.Model(inputs=[cnn_model.input], outputs=x)\n    adam = tensorflow.keras.optimizers.Adam(lr=0.004)\n    \n    radam = tfa.optimizers.RectifiedAdam(lr=5e-3,total_steps=10000, warmup_proportion=0.1,min_lr=1e-5)\n    ranger = tfa.optimizers.Lookahead(radam, sync_period=6, slow_step_size=0.5)\n    \n    model.compile(loss=mloss(0.8), optimizer=\"adam\", metrics=[score])\n    \n    return model\n    \n    \n    #model = M.Model(z, preds, name=\"CNN\")\n    #model.compile(loss=qloss, optimizer=\"adam\", metrics=[score])\n#     model.compile(loss=mloss(0.75), optimizer=\"adam\", metrics=[score])\n    \n#    adam = tensorflow.keras.optimizers.Adam(lr=0.001)\n#    adam = tensorflow.keras.optimizers.Adam(lr=1e-2, decay=1e-2\/epochs)\n\n#     model.compile(loss='mean_squared_error',\n#                   optimizer=adam,  #keras.optimizers.SGD(lr=0.01),\n#                   #metrics=[score])\n#                   metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n    \n#     #model.compile(loss=qloss, optimizer=\"adam\", metrics=[score])\n#     model.compile(loss=mloss(0.8), \n#                   optimizer=tf.keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.01, amsgrad=False),\n#                   metrics=[score])\n    \n    \nm22 = create_model()\n\n#m22.summary()","62c58bbb":"# from tensorflow.keras.optimizers import Adam\n\n# # Normal model\n\n# def create_model():\n# #     cnn_model = create_cnn_model()\n\n#     cnn_model = resnet_3d()\n    \n#     x = Dropout(0.5)(cnn_model.output)\n#     x = Dense(256, activation=\"relu\")(x)\n#     x = Dropout(0.4)(x)\n#     x = Dense(128, activation=\"relu\")(x)\n#     x = Dropout(0.4)(x)\n    \n#     x = Dense(1, activation=\"linear\", name=\"final_dense\")(x)\n    \n#     model = keras.Model(inputs=[cnn_model.input], outputs=x)\n#     adam = tensorflow.keras.optimizers.Adam(lr=0.01)\n    \n# #    adam = tensorflow.keras.optimizers.Adam(lr=0.001)\n# #    adam = tensorflow.keras.optimizers.Adam(lr=1e-2, decay=1e-2\/epochs)\n\n#     model.compile(loss='mean_squared_error',\n#                   optimizer=adam,  #keras.optimizers.SGD(lr=0.01),\n#                   #metrics=[score])\n#                   metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n    \n# #     #model.compile(loss=qloss, optimizer=\"adam\", metrics=[score])\n# #     model.compile(loss=mloss(0.8), \n# #                   optimizer=tf.keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.01, amsgrad=False),\n# #                   metrics=[score])\n    \n#     return model\n","666c918a":"# from tensorflow.keras.optimizers import Adam\n\n# def create_model():\n#     model = Resnet3DBuilder.build_resnet_34(input_shape, 1) ## Input dimensions and no. of outputs\n#     adam = tensorflow.keras.optimizers.Adam(lr=0.001)\n    \n#     #adam = tensorflow.keras.optimizers.Adam(lr=0.01)\n#     #adam = tensorflow.keras.optimizers.Adam(lr=1e-2, decay=1e-2\/epochs)\n\n#     model.compile(loss='mean_squared_error',\n#                   optimizer=adam,  #keras.optimizers.SGD(lr=0.01),\n#                   metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n#     return model","35cd0f27":"\n\ndef create_callbacks(idx):\n    checkpoint = ModelCheckpoint(f'..\/working\/weights_best_{idx}.h5', monitor='val_loss', verbose=1, \n                                 save_best_only=True, mode='min', save_weights_only = True)\n    reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6,\n                                       verbose=1, mode='auto', epsilon=0.0001)\n    early = EarlyStopping(monitor=\"val_loss\", \n                          mode=\"min\", \n                          patience=22) #OK, patience is silly \/ too high for this number of epochs but whatever :)\n\n    csv_logger = CSVLogger(filename='..\/working\/training_log.csv',\n                           separator=',',\n                           append=True)\n    \n    clr = CyclicLR(base_lr=0.0005, max_lr=0.004,step_size=400., mode='triangular')\n    \n    \n    callbacks_list = [checkpoint, reduceLROnPlat, clr, csv_logger, early]\n    return callbacks_list\n\n\n    ","53c94e8d":"def fit_model(model, callbacks_list, df_x_train, df_y_train, df_x_val, df_y_val):\n    train_gen = MySequence3D(df_x_train, df_y_train, batch_size, augment=True)\n    valid_gen = MySequence3D(df_x_val, df_y_val, batch_size, augment=False)\n\n    #the total number of images we have:\n    train_size = df_x_train.shape[0]\n    #train_steps is how many steps per epoch Keras runs the genrator. One step is batch_size*images\n    train_steps = train_size\/batch_size\n    train_steps = int(train_steps)\n    #same for the validation set\n    valid_size = df_x_val.shape[0]\n    valid_steps = valid_size\/batch_size\n    valid_steps = int(valid_steps)\n\n    fit_history = model.fit_generator(\n            train_gen,\n            steps_per_epoch=train_steps,\n            epochs = epochs,\n            validation_data=valid_gen,\n            validation_steps=valid_steps,\n            callbacks=callbacks_list,\n        use_multiprocessing=True,\n        workers=2,\n        verbose = 1\n    )\n    return fit_history","8e23683a":"def make_predictions_dict(model, test_rows):\n    if isinstance(test_rows, pd.DataFrame):\n        test_rows = [row.to_dict() for (idx, row) in test_rows.iterrows()]\n    predictions = {}\n    predictions_qloss = {}\n    col_names = []\n    print(f\"predicting {test_rows}\")\n    for target_week in tqdm(range(-12,134)):\n        for idx, row in enumerate(test_rows):\n            row[\"target_week\"] = (target_week+12)\/(133+12)\n            patient_id = row[\"patient_id\"]\n            img = img_augment_3d(\"train\", None, patient_id, False)\n            img = np.array([img])\n            #print(img)\n            #print(img.shape)\n            pred = model.predict([img])\n            col_name = f\"{idx+1}_{target_week}\"\n            col_names.append(col_name)\n            predictions[col_name] = pred.flatten()[0]\n            predictions_qloss[col_name] = pred.flatten()\n            \n            #predictions[col_name] = pred.flatten()[0]\n            ##print(f\"target week: {row['target_week']}, pred: {pred}\")\n        \n    return predictions_qloss, predictions, col_names","e76558e5":"#preds_test","6177cb5e":"#pred_test","beb45897":"def make_predictions_my_test(model, test_rows):\n    test_rows = [row.to_dict() for (idx, row) in test_rows.iterrows()]\n    predictions = []\n    for idx, row in tqdm(enumerate(test_rows), total=len(test_rows)):\n        patient_id = row[\"patient_id\"]\n        img = img_augment_3d(\"train\", None, patient_id, False)\n        img = np.array([img])\n        pred = model.predict([img])\n        predictions.append(pred.flatten()[0])\n        #print(f\"target week: {row['target_week']}, pred: {pred}\")\n        \n    return predictions","24904c8c":"indices = np.arange(df_x.shape[0])\n#https:\/\/github.com\/scikit-learn\/scikit-learn\/issues\/9193\ntrain_indices, my_test_indices = next(GroupShuffleSplit(test_size=my_test_pct, random_state=8).split(indices, groups=df_x[\"patient_id\"]))\nmy_test_X = df_x.iloc[my_test_indices]\nmy_test_y = df_y.iloc[my_test_indices]\n\nfull_indices = indices\nindices = train_indices","d8443f0b":"\n#split the training data by patient id, so if patient has multiple rows we put them in the same group\nsplits = list(GroupKFold(n_splits=N_SPLITS).split(indices, groups=df_x.iloc[indices][\"patient_id\"]))\npreds_test = []\npreds_my_test = []\ncol_names = []\nfit_histories = []\npreds_test_q_loss = []\n\nfor idx, (train_idx, val_idx) in enumerate(splits):\n    if idx>0:\n        break\n    K.clear_session() # start Keras from clean state in each iteration\n    print(\"Beginning fold {}\".format(idx+1))\n    # use the indexes to extract the folds in the train and validation data\n    train_X, train_y, val_X, val_y = df_x.iloc[train_idx], df_y.iloc[train_idx], df_x.iloc[val_idx], df_y.iloc[val_idx]\n    # instantiate the model for this fold\n    model = create_model()\n    callbacks = create_callbacks(idx)\n    #train the model on this fold\n    history = fit_model(model, callbacks, train_X, train_y, val_X, val_y)\n    fit_histories.append(history)\n    # loads the best weights saved by the checkpoint\n    model.load_weights(f'weights_best_{idx}.h5')\n    predictions_qloss, pred_test, col_names = make_predictions_dict(model, test_rows)\n    preds_test_q_loss.append(predictions_qloss)\n    preds_test.append(pred_test)\n    pred_test = make_predictions_my_test(model, my_test_X)\n    preds_my_test.append(pred_test)\n    del model\n    del callbacks\n","f7e33d32":"# test_rows","f57b7607":"# make_predictions_dict(model, test_rows)","d26322b4":"my_test_X\n","3c8c7d33":"# def make_predictions_my_test(model, test_rows):\n#     test_rows = [row.to_dict() for (idx, row) in test_rows.iterrows()]\n#     predictions = []\n#     pred0 = []\n#     pred1 = []\n#     pred2 = []\n#     for idx, row in tqdm(enumerate(test_rows), total=len(test_rows)):\n#         patient_id = row[\"patient_id\"]\n#         img = img_augment_3d(\"train\", None, patient_id, False)\n#         img = np.array([img])\n#         pred = model.predict([img])\n        \n#         pred0.append(pred.flatten()[0])\n#         pred1.append(pred.flatten()[1])\n#         pred2.append(pred.flatten()[2])\n        \n#         predictions.append(pred.flatten()[0])\n#         #print(f\"target week: {row['target_week']}, pred: {pred}\")\n        \n#     return pred0, pred1, pred2, predictions","2c5f6b8d":"# pred0, pred1, pred2, predictions = make_predictions_my_test(model, my_test_X)","12638338":"\n# from sklearn.metrics import mean_absolute_error\n# sigma_opt = mean_absolute_error(my_test_y, pred1)\n# # unc = pred[:,2] - pred[:, 0]\n# # unc = pred2 - pred0\n# unc = []\n\n\n# zip_object = zip(pred2, pred0)\n\n# for list1_i, list2_i in zip_object:\n\n#     unc.append(list1_i-list2_i)\n    \n# sigma_mean = np.mean(unc)\n# #print(sigma_mean)\n# print(sigma_opt, sigma_mean)","62f94526":"len(predictions_qloss.keys())","e7b1013d":"# pred_test","53301d79":"model = create_model()\nmodel.summary()","3aedd3ef":"from keras.utils import plot_model\nplot_model(model)","c0561f0a":"def plot_loss_and_accuracy(fit_history, n=0):\n    plt.clf()\n    plt.plot(fit_history.history['rmse'][n:])\n    plt.plot(fit_history.history['val_rmse'][n:])\n    plt.title('model rmse')\n    plt.ylabel('rmse')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n    plt.clf()\n    #since the loss is just mse here, the graph is practically identical to RMSE (metric above). Save space and plot it just once..\n    # summarize history for loss\n    #plt.plot(fit_history.history['loss'][n:])\n    #plt.plot(fit_history.history['val_loss'][n:])\n    #plt.title('model loss')\n    #plt.ylabel('loss')\n    #plt.xlabel('epoch')\n    #plt.legend(['train', 'test'], loc='upper left')\n    plt.show()","a7b9c3fa":"# for idx, fit_history in enumerate(fit_histories):\n#     print(f\"fold {idx}\")\n#     plot_loss_and_accuracy(fit_history)","c82c0393":"# for idx, fit_history in enumerate(fit_histories):\n#     print(f\"fold {idx}\")\n#     plot_loss_and_accuracy(fit_history, 4)","6655f252":"len(preds_my_test[0])","ef9cce73":"preds_my_test_mean = np.mean(preds_my_test, axis=0)","843f5b48":"from sklearn.metrics import mean_squared_error\n\nmean_squared_error(my_test_y, preds_my_test_mean, squared=False)","3e58c720":"my_test_y","e0e3dabe":"df_mytest_predictions = pd.DataFrame()\nfor idx, mtp in enumerate(preds_my_test):\n    df_mytest_predictions[f\"{idx+1}\"] = mtp\n","8cde844d":"df_mytest_predictions.T","5afeba68":"df_mytest_predictions.T.describe()","ae170fb6":"df_mytest_predictions.T.describe().T.describe()","33aec4a9":"df_mytest_predictions_diff = pd.DataFrame()\nfor idx, mtp in enumerate(preds_my_test):\n    df_mytest_predictions_diff[f\"{idx+1}\"] = np.abs(np.array(mtp) - my_test_y.values)\n","0fbdd0fc":"df_mytest_predictions_diff.T","21f8b13f":"df_mytest_predictions_diff.T.describe()","781ba09c":"df_mytest_predictions_diff.T.describe().T.describe()","ba569b4c":"# predictions_qloss","6ce04b97":"pd.DataFrame(predictions_qloss)","84cf809c":"qloss_preds = pd.DataFrame(predictions_qloss)\n","ea9bd956":"index = qloss_preds.T.index.values.tolist()\nindex[0:5]","70f03ccb":"pe0 = []\npe1 = []\npe2 = []\n\nfor i in range(len(index)):\n    pe0.append(qloss_preds[index[i]][0])\n    pe1.append(qloss_preds[index[i]][1])\n    pe2.append(qloss_preds[index[i]][2])","31cb6b5f":"# pe1[0]","85318cd8":"len(pe0)","b286eef2":"\nfrom sklearn.metrics import mean_absolute_error\n# sigma_opt = mean_absolute_error(my_test_y, pred1)\n\n\n# unc = pred[:,2] - pred[:, 0]\n# unc = pred2 - pred0\nunc = []\n\n\nzip_object = zip(pe2, pe0)\n\nfor list1_i, list2_i in zip_object:\n\n    unc.append(list1_i-list2_i)\n    \nsigma_mean = np.mean(unc)\nprint(sigma_mean)\n#print(sigma_opt, sigma_mean)","5ff2448d":"import pandas as pd\nsample_sub = pd.read_csv('..\/input\/osic-pulmonary-fibrosis-progression\/sample_submission.csv')\nsample_sub","3a3297f7":"#cnt = 0\nindex = qloss_preds.T.index.values.tolist()\nfor i in range(len(index)):\n    \n    test_rows_index = int(index[i].split('_')[0]) - 1\n    patient_week_temp = test_rows[test_rows_index]['patient_id'] + '_' + index[i].split('_')[1]\n    for j in range(len(sample_sub)):\n        if sample_sub['Patient_Week'][j] == patient_week_temp:\n            sample_sub['FVC'][j] = pe1[i]\n            sample_sub['Confidence'][j] = pe2[i] - pe1[i]\n            \n            \n#             sample_sub['FVC'][j] = df_final['mean'][i]\n#             sample_sub['Confidence'][j] = df_final['std'][i]","7341e59f":"sample_sub","0f89da30":"sample_sub.to_csv('submission.csv', index=False)","7fa9f2fe":"index = qloss_preds.T.index.values.tolist()\nfor i in range(len(index)):\n    \n    test_rows_index = int(index[i].split('_')[0]) - 1\n    patient_week_temp = test_rows[test_rows_index]['patient_id'] + '_' + index[i].split('_')[1]\n    for j in range(len(sample_sub)):\n        if sample_sub['Patient_Week'][j] == patient_week_temp:\n            sample_sub['FVC'][j] = pe1[i]\n            val = pe2[i] - pe1[i]\n            if val > 480 and val < 660:\n                sample_sub['Confidence'][j] = val\/3\n            elif val > 660 and val < 1000:\n                sample_sub['Confidence'][j] = val\/4\n            elif val < 480 and val > 300:\n                sample_sub['Confidence'][j] = val\/2\n            elif val < 150:\n                sample_sub['Confidence'][j] = 160\n            elif val >1000:\n                sample_sub['Confidence'][j] = 250\n            else:\n                sample_sub['Confidence'][j] = val","67a44726":"sample_sub.to_csv('submission2.csv', index=False)","490ae0f6":"# preds_test","11dd3cd4":"# df_test_predictions = pd.DataFrame(preds_test)\n# df_test_predictions = df_test_predictions[col_names] #to get sorted order","12bfa67c":"# df_test_predictions","1951803c":"# import pandas as pd\n# sample_sub = pd.read_csv('..\/input\/osic-pulmonary-fibrosis-progression\/sample_submission.csv')\n# sample_sub","8ff8c2bb":"# df_final = df_test_predictions.copy()\n","436d4f26":"# df_test_predictions.describe()","298be837":"# df_final = df_test_predictions.describe().T","4eab559d":"# df_final","484b5bdb":"# index = df_final.index.values.tolist()\n# index[0:5]","6ca0d3e6":"# df_final['mean'][0]","b2ccd73c":"# sample_sub.head()","159b4229":"# index[0].split('_')","cb35e303":"# index[0].split('_')[1]","687ee7d0":"# test_rows[4]['patient_id']","81e1cd4f":"# cnt = 0\n# index = df_final.index.values.tolist()\n# index[0:5]\n# for i in range(len(df_final)):\n    \n#     test_rows_index = int(index[i].split('_')[0]) - 1\n#     patient_week_temp = test_rows[test_rows_index]['patient_id'] + '_' + index[i].split('_')[1]\n#     for j in range(len(sample_sub)):\n#         if sample_sub['Patient_Week'][j] == patient_week_temp:\n#             sample_sub['FVC'][j] = df_final['mean'][i]\n#             sample_sub['Confidence'][j] = df_final['std'][i]\n    ","66114aa2":"# cnt = 0\n# for i in range(len(df_final)):\n    \n#     test_rows_index = int(index[i].split('_')[0]) - 1\n#     patient_week_temp = test_rows[test_rows_index]['patient_id'] + '_' + index[i].split('_')[1]\n#     for j in range(len(sample_sub)):\n#         if sample_sub['Patient_Week'][j] == patient_week_temp:\n#             sample_sub['FVC'][j] = df_final['mean'][i]*3\n#             if df_final['std'][i]*3>300:\n#                 sample_sub['Confidence'][j] = 220\n#             else:\n#                 sample_sub['Confidence'][j] = df_final['std'][i]*3","e918ecb2":"# sample_sub","5292aef9":"# sample_sub.to_csv('submission.csv', index=False)","85c02537":"# patient_week_temp","24d6ac0a":"# descriptions = df_test_predictions.describe()","a63d8cd0":"# descriptions.max(axis=1)","9cdd3e34":"# descriptions.T.describe()","4a1471f0":"# Create the Model\n\nHere, I build the 3D CNN to play with. First basic config for image sizes etc:","1282b977":"## Plot Some Example Augmented Batches\n\nEvery time `__getitem__()` is called on the generator, it should produce differenct augmentations on the fly. So here we call it twice to see that it works as expected:","743c28da":"And our regular Keras callbacks to save the best model during training, lower training rate on plateuau, and stop a bit earlier if no gains:","a0cdfbca":"# Custom Keras Sequence Generator\n\nHere I define a Keras Sequence generator to build the augmented dataset on the fly.\n\nFirst, a small utility function to shuffle x and y at the end of each training epoch:","0bf0a7af":"Above shows the mean, str, etc over the 5 folds for all patients in the test set.\n\nBy using describe() on describe(), we can get aggregated statistics on the overall dataset (so mean over all patients means, etc):","e2bbea40":"## Create Train and Test Rows\n\nThis is just a little something I ended up with to format my data after playing with various approaches. Maybe not really necessary but it works for this kernel.. I really just need the patient ID for accessing the image in this kernel, the rest are just someting I used in other kernels.","6086101f":"## Function to Train the Model on Given Data\n\nThis function runs the training for a single fold with given data:","8a55cc9e":"### Gaussian Blur\n\nA helper to do a gaussian blur on a 3D array (of image pixels):","837038ba":"I have scaled the columns to range 0..1, except the column now named *target_fvc*. I use this column as the target variable to predict here. It is the same as the base fvc given for each patient. Just renamed target here, as it is the prediction target..","f429637b":"In this case I used a continous value for the smoking feature, although you can say it is categorical. But 0 for non-smoking, 1 for currently smoking, and 0.5 for used to smoke.","0fd81233":"# 3D Augmentation Helpers\n\nA number of functions to perform augmentations, one per function, on given 3D images. These mostly start with a random chance of whether it will be applied at all or not. Just to avoid applying all augmentations all the time. Then the augmentation itself.\n\n### Rotate\n\nFirst, a helper to rotage a given 3D image by a random angle between given min and max angle:","05c9bab2":"## Make Predictions\n\nMake predictions for the Kaggle test set, using target week numbers -12...133. This is just to see how the prediction runs here, did not use this for actual submission, since I made this kernel more to explore the CNN architecture. It does not use any time related data, or the tabular data, so its not really very good for the actual final prediction over all weeks. But keeping these here anyway.","e686eb6c":"So on average, when I ran this, we were off across all folds and patients by 566 units. The results on this posted version should be little bit different but not too much, due to randomness of the process. When the range of units is roughly about 2000-3000, I'd say thats a pretty bad result.","04af12a1":"### Horizontal Flip\n\nFlip an entire 3D array along x-axis:","ab7ac1a1":"# Predictions for Kaggle Test Set\n\nThis would be the test set Kaggle provices, and the one that would be providing the actual competition results if we submitted this. But not going there with these poor results. Lets play anyway.\n\nPartly my idea was to look at the differences above, and compare with these values to see if I could find some trend to apply. Of course not.","82dc4b55":"# Brief Overview of the Data\n\nThe preprocessed data is in a [dataset](https:\/\/www.kaggle.com\/donkeys\/osic-pulmonary-fibrosispreprocessed) I previously uploaded. This is where it mounts:","2e4febba":"### Shift Y-axis\n\nShift a 3D array on y-axis by random number of pixels between given min and max. Left or right, random choice of direction.","2925c356":"## Plot Training Losses per Fold","12fe6680":"## Visualizing Augmentations to See How They Work\n\nA helper to plot the 3D augmented images the above custom generator produces (for debugging\/testing):","7732fdaa":"Convert our test set predictions into a dataframe for easier manipulation:","79f12fdd":"# A Few Configuration Variables","f0798211":"# 3D ConvNet with 3D Augmentations\n\nThis is a kernel I was playing around with to see if a 3D convolutional network could produce useful features from scan images preprocessed to the same size using code as published in my previous [kernel](https:\/\/www.kaggle.com\/donkeys\/preprocessing-images-to-normalize-colors-and-sizes). To recap, this includes:\n\n- resizing all images to same size (width, height)\n- rescaling the z-axis of all 3D arrays to the same depth.\n- removing boundaries from images there present.\n\nSince there are not that many images to start with, I also added augmentations to the 3D images, according to my earlier [kernel](https:\/\/www.kaggle.com\/donkeys\/ct-slices-basic-eda):\n\n- 3D gaussian blur\n- 3D flips on x- and y-axis\n- 3D rotation on x-axis\n- 3D shift on x- and y-axis\n- 3D zoom on x- and y-axis\n\nThe 3D in the above list simply refers to applying the augmentations\/transformations on the whole z-axis of the 3D numpy array at once.\n\nOne point of this kernel was also to allow faster and separate iterations of trying to build a 3D CNN to use as part of other models (e.g., with the tabular dataset).\n\nThe accuracy of the model in this kernel is low, but it could provide some useful building blocks for other kernels to build on. Or maybe someone will spot some errors and let me know..","ebdd9f43":"Just a little cleanup as we are resource-wasting paranoid:","03d12bd6":"### The One Function to Bind them Together\n\nThe actual augmentation function that aggregates all of the above into one:","ae36a23b":"## Split into N Groups to Train N Models","62680478":"## Look at Custom Test Set Predictions vs Actual Values","eb74c1c0":"List of patients in the training set. This can be useful, for example, to make patient-grouped data-splits.","17991003":"### Shift X-axis\n\nShift a 3D array on x-axis by random number of pixels between given min and max. Left or right, random choice of direction.","b676c162":"## Smoke Test\n\nSometimes the custom sequence generator has issues when some combination of augmentations hits, so this allows testing it with various combinations to see if it crashes (since it loops the batch generator with augmentation, it could also be used as a performance test):","7e4b91fa":"### Failed Attempt at Zoom\n\nThis was an attempt at using CV2 library for zooming, keeping it here for posterity:","09fb13d5":"### Vertical Flip\n\nFlip an entire 3D array along y-axis (some images seem to be upside down as noted in my [previous kernel](https:\/\/www.kaggle.com\/donkeys\/ct-slices-basic-eda)):","b34d3422":"Above shows one row per fold (5 folds = 5 rows), where each column is the prediction difference vs actual value for a patient (0-8 patients, for a total of 9 patients in this test set).","23e07a80":"The above charts often have a few versions where the first few epochs have very high loss, and then these drop down significatnly. But because the start is high, variance in the later epochs is hard to spot in the chart. To avoid this, here we plot loss history starting at epoch 4 for all folds:\n    ","22d5bb88":"This creates the actual model for training folds:","7c33c405":"Predict also for my own test set that was put aside from the training data. So I can compare later how well\/bad it did with the final trained model (since training set has known target FVC values):","95782a27":"The actual `create_model()` function further below will call `create_cnn_model()` to create the CNN. This is because some other kernels I reused the model I build in this kernel and this allows me to combine them easier. I built this here separately since it allowed me to focus on the CNN only, and run it faster with a smaller dataset. To iterate model architectures faster and with less use of the limited GPU resources on Kaggle.","61f654ca":"Full loss history for all folds:","3bae3cf1":"## Training the Model","74c2bc7e":"Another alternative I tried, just for illustration:","7b6fa941":"## Check Diff per Patient in Test Set\n\nBy looking at how much the FVC predictions differ from the actual FVC value per patient, maybe we could identify some trends.\n\nLets see.","470fe9cd":"### Zoom\n\nZoom the 3D image by a random zoom factor (same for both axis) between given min and max on both x- and y-axis:","6af5feaa":"A custom Keras generator sequence to produce batches of 3D augmented images:"}}