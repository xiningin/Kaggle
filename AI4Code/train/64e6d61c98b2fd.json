{"cell_type":{"8ecaf563":"code","44899425":"code","0e441d3a":"code","b7cf1bdd":"code","5f3bbc2a":"code","038f3d6b":"code","3ce6ab27":"code","ca4fc063":"code","b82f21ca":"code","5e491977":"code","472c63bf":"code","a345ce39":"code","a5730465":"code","c2712d48":"code","9815de56":"code","8b67eece":"code","a3605fae":"code","8fa2838e":"code","3f26c1fe":"code","4b31b324":"code","9aaaab6b":"code","b1e65e6d":"markdown","4bc3c93a":"markdown","f8a2abd4":"markdown","a9961fd3":"markdown","7a75fdde":"markdown","da4bb6bb":"markdown","1e741353":"markdown","d3ec790a":"markdown","9df9c2bc":"markdown","af9566ec":"markdown","a1436e1a":"markdown","016bc01f":"markdown"},"source":{"8ecaf563":"import numpy as np\nimport pandas as pd","44899425":"data = pd.read_csv(\"..\/input\/room-occupancy-estimation-data-set\/Occupancy_Estimation.csv\")\nprint(data.shape)\ndata.head()","0e441d3a":"target = 'Room_Occupancy_Count'\ndata[target].hist(figsize=(10,5))","b7cf1bdd":"### we will select a few columns for now ###\ncols_to_use = ['S1_Temp', 'S2_Temp', 'S3_Temp', 'S4_Temp', 'S1_Light',\n       'S2_Light', 'S3_Light', 'S4_Light', 'S1_Sound', 'S2_Sound', 'S3_Sound',\n       'S4_Sound', 'S5_CO2','S6_PIR', 'S7_PIR',\n       'Room_Occupancy_Count']\n\ndata = data[cols_to_use]\nprint(data.shape)\ndata.head(1)","5f3bbc2a":"!pip install autoviz","038f3d6b":"%matplotlib inline","3ce6ab27":"from autoviz.AutoViz_Class import AutoViz_Class","ca4fc063":"AV = AutoViz_Class()\nfilename = \"\"\nsep = \",\"\ndft = AV.AutoViz(\n    filename,\n    sep=\",\",\n    depVar=target,\n    dfte=data,\n    header=0,\n    verbose=0,\n    lowess=False,\n    chart_format=\"png\",\n    max_rows_analyzed=150000,\n    max_cols_analyzed=5,\n    save_plot_dir=None\n)","b82f21ca":"features_to_use = dft.columns[:5].tolist()\nlen(features_to_use)","5e491977":"features_to_use","472c63bf":"from sklearn.model_selection import train_test_split\ntrain, test = train_test_split(data, test_size=0.2,shuffle=True)\nprint(train.shape, test.shape)","a345ce39":"## So make sure train and test have same target distribution\nprint(train[target].value_counts(1))\nprint(test[target].value_counts(1))","a5730465":"preds = cols_to_use[:-1]\npreds","c2712d48":"def normalization(df):\n  for i in df.columns:\n    upper_bound = df[i].max()\n    lower_bound = df[i].min()\n    df[i] = (df[i]-lower_bound)\/(upper_bound-lower_bound)\n  return df\n\nX_train = normalization(train[preds])\ny_train = train[target]\nX_test = normalization(test[preds])\ny_test = test[target]","9815de56":"import lightgbm as lgb\nlgbm = lgb.LGBMClassifier()\nlgbm","8b67eece":"lgbm.fit(X_train, y_train)\ny_pred_all = lgbm.predict(X_test)\ny_pred_all","a3605fae":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred_all))","8fa2838e":"X_train = normalization(train[features_to_use])\ny_train = train[target]\nX_test = normalization(test[features_to_use])\ny_test = test[target]","3f26c1fe":"lgbm = lgb.LGBMClassifier()\nlgbm","4b31b324":"lgbm.fit(X_train, y_train)\ny_pred_5 = lgbm.predict(X_test)\ny_pred_5","9aaaab6b":"print(classification_report(y_test, y_pred_5))","b1e65e6d":"## This notebook is derived from: https:\/\/www.kaggle.com\/egemenuurdalg\/room-occupany-prediction\n# Many thanks to Egemen! I have restricted this modified notebook to just 2 steps:\n\n1. [Data Visualization](#1)\n1. [Feature Selection and Comparing Results](#2)","4bc3c93a":"<a id='4'><\/a>\n# 4. Model Configuration and The Results","f8a2abd4":"# Let's use just 5 variables for building the same model and see what the results are","a9961fd3":"# Let's see what the classification report says about using all variables \n### We get almost 99% accuracy with a very simple LGBM model","7a75fdde":"<a id='1'><\/a>\n# 1. Analyzing the Data","da4bb6bb":"<a id='2'><\/a>\n# 2. Let's try to see if using these 5 features is better than building a model with all features","1e741353":"# Let's visualize the data using AutoViz ","d3ec790a":"# From this beautiful visualization of data we can realize the following:\n1. Just a handful of features are enough to build a very highly accurate model\n2. We asked AutoViz to select the top 5 features for us. The features selected by AutoViz were:\n* 'S1_Sound'\n* 'S1_Light'\n* 'S2_Light'\n* 'S3_Light'\n* 'S7_PIR'","9df9c2bc":"# We first need to look at this as a multi-class problem since room_occupany can take on 4 values","af9566ec":"<a id='3'><\/a>\n# 3. Data Preprocessing\n\nSo far we analyzed the data and we plot some graphs to understand it even further. Let's compare a model with all variables vs. using just a few variables from AutoViz","a1436e1a":"# So we get the same accuracy 99% with 5 features selected by AutoViz vs 99% for using all features. What did we learn from this notebook?\n1. You can use AutoViz for fast visualization\n1. You can use AutoViz for fast feature selection","016bc01f":"# Let's plot the results of AutoViz inline - we must instantiate matplotlib inline"}}