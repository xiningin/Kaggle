{"cell_type":{"ab101de1":"code","ff219345":"code","928d2d6a":"code","1224c941":"code","76a3b380":"code","c737e1fa":"code","d19b8174":"code","45c42f08":"code","817f93f0":"code","33ee50a3":"code","0cff9124":"code","e044a506":"code","239f5e23":"code","f95481ff":"code","5bcb6828":"code","1511be90":"code","cd4c5d0b":"code","bd09d09e":"code","d9fa8fc7":"code","d51858bc":"markdown","43609188":"markdown","d53f586d":"markdown","4b60a6a9":"markdown","189061a3":"markdown","04fbadc1":"markdown","39d7df8a":"markdown","0e52ba44":"markdown","b84ff9fe":"markdown","0d781295":"markdown","933ad5c9":"markdown","6e104a52":"markdown","59441db7":"markdown"},"source":{"ab101de1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.linear_model import LinearRegression \nfrom sklearn.metrics import r2_score,mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.ensemble import RandomForestRegressor\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ff219345":"df= pd.read_csv('\/kaggle\/input\/insurance\/insurance.csv')","928d2d6a":"df.head(10)","1224c941":"df.describe()","76a3b380":"df.info()","c737e1fa":"print('Number of rows and columns in the data set: ',df.shape)","d19b8174":"# Check for null count column wise\ndf.isnull().sum(axis=0)","45c42f08":"f= plt.figure(figsize=(12,4))\nax=f.add_subplot(121)\nsns.distplot(df['charges'],bins=50,color='r',ax=ax)\nax.set_title('Distribution of insurance charges')\n\nax=f.add_subplot(122)\nsns.distplot(np.log10(df['charges']),bins=40,color='b',ax=ax)\nax.set_title('Distribution of insurance charges in $log$ sacle')\nax.set_xscale('log')\nplt.show()\n","817f93f0":"plt.figure(figsize=(18,4))\nplt.subplot(131)\nsns.barplot(x='sex', y='charges', data=df)\nplt.subplot(132)\nsns.barplot(x='smoker', y='charges', data=df)\nplt.subplot(133)\nsns.barplot(x='region', y='charges', data=df)\nplt.show()","33ee50a3":"sns.pairplot(df,kind=\"reg\")","0cff9124":"\n#Plot a heatmap and look at the corelation\nsns.heatmap(df.corr(), cmap='coolwarm',annot=True)","e044a506":"# Let us map the variables with 2 levels to 0 and 1\ndf['sex']=df['sex'].map({'male':1, 'female':0})\ndf['smoker']=df['smoker'].map({'yes':1,'no':0})","239f5e23":"# Assigning dummy variables to remaining categorical variable- region\ndf = pd.get_dummies(df, columns=['region'], drop_first=True)\ndf.head()","f95481ff":"from sklearn.model_selection import train_test_split\nX = df.drop('charges',axis=1) # Independet variable\ny = df['charges'] # dependent variable\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,random_state=0)","5bcb6828":"lr = LinearRegression()\nlr.fit(X_train,y_train)","1511be90":"y_train_pred = lr.predict(X_train)\ny_test_pred = lr.predict(X_test)\nprint(lr.score(X_test,y_test))","cd4c5d0b":"X = df.drop(['charges','region_northwest','region_southeast','region_southwest'], axis = 1)\nY = df.charges\n\n\n\nquad = PolynomialFeatures (degree = 2)\nx_quad = quad.fit_transform(X)\n\nX_train,X_test,Y_train,Y_test = train_test_split(x_quad,Y, random_state = 0)\n\nplr = LinearRegression().fit(X_train,Y_train)\n\nY_train_pred = plr.predict(X_train)\nY_test_pred = plr.predict(X_test)\n\nprint(plr.score(X_test,Y_test))","bd09d09e":"forest = RandomForestRegressor(n_estimators = 100,\n                              criterion = 'mse',\n                              random_state = 1,\n                              n_jobs = -1)\nforest.fit(X_train,y_train)\nforest_train_pred = forest.predict(X_train)\nforest_test_pred = forest.predict(X_test)\n\nprint('MSE train data: %.3f, MSE test data: %.3f' % (\nmean_squared_error(y_train,forest_train_pred),\nmean_squared_error(y_test,forest_test_pred)))\nprint('R2 train data: %.3f, R2 test data: %.3f' % (\nr2_score(y_train,forest_train_pred),\nr2_score(y_test,forest_test_pred)))","d9fa8fc7":"plt.figure(figsize=(10,6))\n\nplt.scatter(forest_train_pred,forest_train_pred - y_train,\n          c = 'black', marker = 'o', s = 35, alpha = 0.5,\n          label = 'Train data')\nplt.scatter(forest_test_pred,forest_test_pred - y_test,\n          c = 'c', marker = 'o', s = 35, alpha = 0.7,\n          label = 'Test data')\nplt.xlabel('Predicted values')\nplt.ylabel('Tailings')\nplt.legend(loc = 'upper left')\nplt.hlines(y = 0, xmin = 0, xmax = 60000, lw = 2, color = 'red')\nplt.show()","d51858bc":"Now we have imported dataset. When we look at the shape of dataset it has return as (1338,7).So there are  m=1338  training exaple and  n=7  independent variable. The target variable here is charges and remaining six variables such as age, sex, bmi, children, smoker, region are independent variable.","43609188":"Before Starting:\nAs in other projects, your upvotes really mean a lot to me because it tells me that Kagglers are interested in the work I am proving to you guys. So I will appreciate if you could upvote this kernel if you enjoy the work I do. Looking to share some insights with Kagglers in the comment section. Also, if updates take longer than usual it is because of work at school nevertheless, I'll try to bring more interesting updates with regards to this project. Hope you enjoy the analysis!","d53f586d":"---Step4.Explore the Data (EDA)--\n\na.Visualizing the Charges data Target Variable by using distplot\n","4b60a6a9":"# Now lets try out with Random Forest","189061a3":"**Now lets add Polynmial Feature and look at the result**","04fbadc1":"**Still there is chances off improvement \nHope to You attain 100% accuracy next time **\nIn my opinian you go ahead with other regression algoritham available , with parameter tuning can acheive geat result","39d7df8a":"----Step3.Clean Dataset---","0e52ba44":"# **Part 2 - DISCOVER**\n----Step2.Load Dataset---->Check Head, info and describe ,  shape of dataset by query","b84ff9fe":"c.Visualizing Numerical data by using pairplot\n- age\n- bmi\n- children\n- charges","0d781295":"# Part 3 DEVELOP\n# **Train Test split**","933ad5c9":"b.Visualizing categorical data by using bar plot\n\n- sex\n- smoker\n- region","6e104a52":"# **Cost of Treatment of Patient Prediction Based on Medical Cost Personal Datasets**\n\n# **Part 1 - DEFINE**\n\n---Step1.Define the problem----->\nAccurately Predict the insurance costs, based on medical cost personal dataset","59441db7":"--Step5.Label Encoding for Catogorical data---\n\n**Label encoding** refers to transforming the word labels into numerical form so that the algorithms can understand how to operate on them.\n\n"}}