{"cell_type":{"7e7d8e18":"code","8483e2fd":"code","9066e913":"code","b6a4cfad":"code","f503140c":"code","af00fe58":"code","c7fe778a":"code","e7fa6a0e":"code","748cc0cd":"code","a35518db":"code","db0b9955":"code","1d5f618e":"code","795ec08a":"code","ec78c8fa":"code","668f059c":"markdown","2507c14b":"markdown","09cc82b2":"markdown","2e8d3bac":"markdown","92fbacd0":"markdown","52f6d255":"markdown","7010af84":"markdown","213ef7a5":"markdown","db6eb191":"markdown","12beadcd":"markdown","fc4ae7c9":"markdown","95e8c4a2":"markdown","141cb67d":"markdown"},"source":{"7e7d8e18":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# Data Visualization libraries import\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n# Code for importing files and libraries\nimport os\noutput_path = os.path.abspath('\/kaggle\/output')\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","8483e2fd":"#Read the file from the directory\ndf = pd.read_csv(\"\/kaggle\/input\/sars-outbreak-2003-complete-dataset\/sars_2003_complete_dataset_clean.csv\")","9066e913":"#Understanding the dataset in detail\ndf.info()","b6a4cfad":"#Changing the names of the columns\ndf= df.rename(columns={'Cumulative number of case(s)': 'Cumulative_Cases', 'Number of deaths': 'Death_Count', \n                      'Number recovered': 'Recovered_Count'})","f503140c":"#Converting Date feature first to the datetime feature\ndf.Date = df.Date.apply(pd.to_datetime)","af00fe58":"plt.figure(figsize = [10,5])\nplt.title('Distribution of Confirmed Cases vs Death for SARS 2003')\n\nsns.scatterplot(x = df['Cumulative_Cases'], y=df['Death_Count'])\n\nplt.xlabel('Cumulative number of cases')\nplt.ylabel(\"Deaths occured\")","c7fe778a":"plt.figure(figsize = [10,5])\nplt.title('Distribution of Confirmed Cases vs Death for SARS 2003')\n\nsns.scatterplot(x = df['Cumulative_Cases'], y=df['Death_Count'], hue = df['Recovered_Count'])\n\nplt.xlabel('Cumulative number of cases')\nplt.ylabel(\"Deaths occured\")","e7fa6a0e":"plt.figure(figsize = [10,5])\nplt.title('Regression Line Distribution of Confirmed Cases vs Death for SARS 2003')\n\nsns.regplot(x = df['Cumulative_Cases'], y=df['Death_Count'])\n\nplt.xlabel('Cumulative number of cases')\nplt.ylabel(\"Deaths occured\")","748cc0cd":"# Performing feature engineering and extracting details from Date feature. \n# Since the entire dataset is of year 2003, so we are not considering year. \n# Only, we are extracting month and date values.\n# It is important to convert the new feature into type int \n\ndf['Day_of_the_year'] = df.Date.dt.strftime(\"%d\").astype(int)\ndf['Week_of_the_year'] = df.Date.dt.strftime(\"%w\").astype(int)\ndf['Month_of_the_year'] = df.Date.dt.strftime(\"%m\").astype(int)\ndf.drop(['Date'], inplace = True, axis = 1)","a35518db":"obj_type_features = df.select_dtypes(include = \"object\").columns\nprint (obj_type_features)\nprint (df.Country) #Before Encoding","db0b9955":"# We only have one feature - Country. So, now let's use Label Encoding.\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\n#Now we will transform the data of feature Country\ndf.Country = le.fit_transform(df.Country)\n\n#Now print and check Country feature values after encoding\nprint (df.Country)","1d5f618e":"from sklearn.model_selection import train_test_split\n\n#Let us assume that we are predicting \nX = df.drop(['Death_Count'], axis = 1)\ny = df['Death_Count']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","795ec08a":"#import the model class from sklearn \n\nfrom sklearn.linear_model import LinearRegression\nreg = LinearRegression()\nreg.fit(X_train, y_train)\ny_pred = reg.predict(X_test)","ec78c8fa":"from sklearn import metrics\n\nprint (\"Mean Absolute Error (MAE) - Test data : \", metrics.mean_absolute_error(y_test, y_pred))\n\nprint (\"Mean Squared Error (MSE) - Test data : \", metrics.mean_squared_error(y_test, y_pred))\n\nprint (\"Root Mean Squared Error (RMSE) - Test data : \", np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n\nprint(\"Co-efficient of determination (R2 Score): \", metrics.r2_score(y_test, y_pred))\n","668f059c":"## Label Encoding\n\nHere, we will first find out all the features that are not of type numeric. Then, using Label Encoding class by sklearn we will convert the feature type to numeric. \n\nReason: To train a machine learning models we need all the data in numbers format (integer or float). Models don't understand text or any other data. We can use Label Encoding or One Hot Encoding for this.","2507c14b":"Graph 3: So,now we will plot the Regression Line for the above scatter plot.","09cc82b2":"## Best fit line\nLet us see a real world graphical representation of Linear Regression. For this we are using [SARS 2003 dataset](https:\/\/www.kaggle.com\/imdevskp\/sars-outbreak-2003-complete-dataset) provided by Kaggle. \n\nHere, we are showing the data in the form of a scatter plot where the relationship between x and y variables is shown. To get better understanding of the relationship, we draw a line called as - best fit line.\nIt is a line that is drawn through the scatter plot points. The idea of this line is to best fit all the points. \n\n![bestfitline.png](attachment:bestfitline.png)\n\n\n## Evaluation metrics:\n\n1. Mean Absolute Error (MAE):\nThe distance between any data point and the best fit line is called as prediction error. The absolute mean of it is called as Mean Absolute Error (MAE).\n\nValue range: 0 to \u221e\nBest value = 0.0 or we can also say that lower the value, better it is.\n\nFormula of it is:\n![mae%20formula.png](attachment:mae%20formula.png)\n\n2. Mean Squared Error (MSE):\n\nThe summation of suqare of all the distances between any data point and the best fit line divided by the total number of data points (mean) gives us a value called as Mean Squared Error.\n\nFormula of it is:\n![mse%20formula.png](attachment:mse%20formula.png)\n\nValue range: 0 to \u221e\nBest value = 0.0 or we can also say that lower the value, better it is.\n\n3. Root Mean Squared Error (RMSE):\nFor calculating RMSE, we do square root of MSE. \n\nValue range: 0 to \u221e\nBest value = 0.0 or we can also say that lower the value, better it is.\n\nFormula of it is:\n![rmse.png](attachment:rmse.png)\n\nIf MAE or MSE or RMSE value is 0 then it means that all the data points are on the best fit line. Higher the value means that the data points are away from the best fit line.\n\n4. R2 Score - Coefficient of Determination: \n\nR2 Score is defined as regression sum of squares divided by the total sum of squares.\n\nBest value = 1.0 or we can also say that more the value close to 1, better it is.\n\nLet's see the formula and then we will find all the parameters needed to calculate the value of R-square:\n\n![r2%20score.png](attachment:r2%20score.png)\n\nOR \n\n![r%20square.png](attachment:r%20square.png)\n\n![r2%20%20best%20fit%20line.png](attachment:r2%20%20best%20fit%20line.png)\n\nConsider the above example with one new line - horizontal added. So, now we can describe the formula components as - \n\na) SS (Res) = Regression sum of squares and it quantifies how far is the regression slope is from the horizontal (no relationship line) the sample mean or y\u00af.\n\nb) SS (Tot) = Regression total sum of squares and it quantifies how much the data points, yi, vary around their mean, y\u00af.","2e8d3bac":"## Hands-on coded solutiion\n\nHere, for implementing Linear Regression, training the data and evaluating it we will be using the SARS 2003 dataset. \n\nRead more about SARS here - [wiki](https:\/\/en.wikipedia.org\/wiki\/Severe_acute_respiratory_syndrome).\nThe following is code it.","92fbacd0":"## EDA\n\nTotal number of rows in 2538 where country wise data is given. \nTotal number of cases, deaths and recovered cases are given in the integer data type.\nDate and Country features are of object type. So, Date feature will be converted into datetime first and then to numeric value.\nAlso, Country feature is to be converted to numeric value using Encoding technoques.","52f6d255":"## Evaluating the Model\n\nHere, as described in the introduction we will calculate following metrics of evaluation for test data and see how well is our model performing.\n1. Mean Absolute Error (MAE)\n2. Mean Squared Error (MSE)\n3. Root Mean Squared Error (RMSE)\n4. Coefficient of determination (R2 score)","7010af84":"## Graphical understanding\n\nGraph 1:\nIf we plot a scatterplot of Cumulative cases against Deaths we can see that as the number of cases started increasing the death count also started increasing.","213ef7a5":"Graph 2:\nViewing the above graph with and evaluating the Recovered Feature, we can say that the number of recovered cases started increasing when the cumulative cases started increasing. We can also say that as the medical team took time to understand the disease and then in few weeks time they were able to recover many people from the disease.","db6eb191":"## Model Training","12beadcd":"## Feature Engineering","fc4ae7c9":"If you have liked this explanation then please upvote for it. Also, if you want me to make such explanation notebooks for any other model of your choice then comment it below.","95e8c4a2":"## What is Linear Regression?\nIt is a relationship between 2 variables x and y where \nx = input or independent variables\ny = output or dependent value\nThis relationship is in the form of a straight line that best tries to fit each variable.\n\nMathematically it can be defined as \ny = mx + c where x and y are as defined above, \nm = slope or coefficient of regression\nc = constant\n\nGeneral view of a straight line : y = mx + c\n\n![line%202.png](attachment:line%202.png)\n\n","141cb67d":"We can see that all the values are transformed into numeric values.\n\nNow, since there are no null values, all feature engineering is done, all object types are converted to the numeric type, we are good to start training out Linear Regression model.\n\nBut, before thath we need to divide the dataset into 2 parts: train and test dataset.\nIf we have 2 different dataset given in the problem statement then we may not split the data as mentioned above. "}}