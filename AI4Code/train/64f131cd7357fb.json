{"cell_type":{"fb3d1384":"code","f9e14f37":"code","577f1d68":"code","adae17a1":"code","6f316c04":"code","119f6452":"code","7b56bf9e":"code","52955b53":"code","ff26dc99":"code","6f4327fe":"code","b8488dc3":"code","f2987da6":"code","d6d8ccb7":"code","2d4f97c3":"code","4ab5a0c2":"code","0845c083":"code","b0788d02":"code","1cb2cebe":"code","c33e5f9a":"code","f1afa8ec":"code","738f36b8":"code","5c2fadd7":"code","bc7dee75":"code","ac755dc1":"markdown","29f01e33":"markdown","cb5fba3b":"markdown","91269017":"markdown","56481096":"markdown","f2cfe626":"markdown","cb3245cd":"markdown"},"source":{"fb3d1384":"import numpy as np \nimport random\nimport pandas as pd \nfrom pathlib import Path\nimport pytorch_lightning as pl\nfrom fastai.vision.all import *\nfrom fastai.torch_basics import *\nfrom fastai.data.all import *\nimport torch\ntorch.cuda.empty_cache()","f9e14f37":"if torch.cuda.is_available():  \n    device = \"cuda\" \nelse: \n    device = \"cpu\"\ndevice","577f1d68":"torch.cuda.get_device_name(0)","adae17a1":"def random_seed(seed_value, use_cuda):\n    np.random.seed(seed_value) \n    torch.manual_seed(seed_value) \n    random.seed(seed_value) \n    if use_cuda: \n        torch.cuda.manual_seed(seed_value)\n        torch.cuda.manual_seed_all(seed_value) \n        torch.backends.cudnn.deterministic = True  \n        torch.backends.cudnn.benchmark = False\nrandom_seed(123, True)","6f316c04":"train_path = Path('..\/input\/cassava-leaf-disease-classification\/train_images') \ntest_path = Path('..\/input\/cassava-leaf-disease-classification\/test_images')\nsub_csv = '..\/input\/cassava-leaf-disease-classification\/sample_submission.csv'\ntrain_csv = '..\/input\/cassava-leaf-disease-classification\/train.csv'","119f6452":"files = get_image_files(train_path.as_posix())\nlen(files)","7b56bf9e":"train_df = pd.read_csv(train_csv)\ntrain_df.head()","52955b53":"submission_df = pd.read_csv(sub_csv)\nsubmission_df.head()","ff26dc99":"dls = ImageDataLoaders.from_df(train_df, \n                               train_path.as_posix(),   \n                               bs=64,\n                               item_tfms=Resize(460), \n                               batch_tfms=aug_transforms(size=224)\n                             )","6f4327fe":"dls.show_batch()","b8488dc3":"# loss_func = LabelSmoothingCrossEntropy()\n# cbs = MixUp","f2987da6":"# learn = cnn_learner(dls, \n#                     resnet50, \n#                     loss_func=loss_func,\n#                     cbs=cbs,\n#                     metrics=accuracy,\n#                     device=device,\n#                     model_dir=\"\/kaggle\/working\/\"\n#                    ).to_native_fp16()","d6d8ccb7":"# learn.fine_tune(20, freeze_epochs=8)","2d4f97c3":"# learn = learn.to_native_fp32()","4ab5a0c2":"# learn.show_results()","0845c083":"# interp = Interpretation.from_learner(learn)","b0788d02":"# interp.plot_top_losses(9, figsize=(15,10))","1cb2cebe":"import os\nos.chdir(\"\/kaggle\/working\/\")\nPath(Path().cwd())","c33e5f9a":"# learn.export(Path(\"\/kaggle\/working\/cld_resnet_50_fp32.pth\").as_posix())","f1afa8ec":"deployed_path = \"..\/input\/pth-resnet50\/cld_resnet_50_fp32.pth\"\nlearn = load_learner(deployed_path)","738f36b8":"labels = []\nfiles = []\nfor file in list(test_path.glob(\"*.jpg\")):\n#     print(file.name)\n    files.append(file.name)\n    labels.append(str(learn.predict(file)[0]))","5c2fadd7":"submission = pd.DataFrame({\"image_id\": files, \"label\" : labels})\nsubmission","bc7dee75":"submission.to_csv(\"submission.csv\", index=False)","ac755dc1":"# If you find this notebook useful please **upvote**...!!!\n\n","29f01e33":"### load pretrained model","cb5fba3b":"# Please **upvote** and do suggest for improvements ","91269017":"### prepare data loader","56481096":"### total train images","f2cfe626":"### Import libraries","cb3245cd":"###  Create submission file"}}