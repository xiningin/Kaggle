{"cell_type":{"c2bd12e0":"code","c04c6f85":"code","fa487fab":"code","a51a9227":"code","b3f2ea03":"code","811e9f49":"code","51c03039":"code","53541860":"code","6ad3275c":"code","7f117d23":"code","499fea86":"code","b8ae9872":"code","09d7b22b":"code","13dc6910":"code","72aeeab0":"code","7505b6a1":"code","c2ab2114":"code","3e0ca72e":"code","cba09aab":"code","dc101f63":"code","148d4c7b":"code","36298b20":"code","6dd345fe":"code","bd7767c3":"code","d7e1d2c2":"code","dfbc589e":"code","14ebd8b2":"code","676c54d7":"code","8fda7cf8":"code","3727de1c":"code","7108bd7f":"code","d6281d27":"code","7a094031":"code","c9b904a9":"code","f00e18cf":"code","c5d8d848":"code","7715c006":"code","36124f66":"code","77cabb13":"code","540c270b":"code","6d485403":"code","dc2db183":"code","8b4879a0":"code","913217cc":"code","0fe2b38f":"code","d8f707f8":"code","c733b7b9":"code","21abc9f8":"code","82e601fd":"code","54b4b49c":"code","491da852":"code","2a3219ab":"code","c7d684a0":"code","337dc6ab":"code","f223c61a":"code","a5549bae":"code","4e263b54":"code","47561949":"code","1fd23401":"code","2272aa1e":"code","8575480d":"code","ce061946":"code","434fa3fa":"code","72664829":"markdown","6157316e":"markdown","0d3652b1":"markdown","f3024c87":"markdown","d95a7f54":"markdown","cd7a2568":"markdown","e63bb6ec":"markdown","ce424de6":"markdown","f4f4eab7":"markdown","e8bb26b8":"markdown","17d9adaf":"markdown","0e35b732":"markdown","d3630ff2":"markdown","23605510":"markdown","a6fb9f86":"markdown","892a0fa5":"markdown","2c486d32":"markdown","667d192e":"markdown"},"source":{"c2bd12e0":"import pandas as pd\nimport numpy as np","c04c6f85":"df= pd.read_csv('..\/input\/crv.csv')\ndf.head()","fa487fab":"df_train = df.loc[df['ORIGIN'] == 'train']","a51a9227":"df_test = df.loc[df['ORIGIN'] == 'test']","b3f2ea03":"df_train.shape","811e9f49":"df_test.shape","51c03039":"target_train = df['CARAVAN'].loc[df['ORIGIN'] == 'train']","53541860":"target_train.shape","6ad3275c":"target_test = df['CARAVAN'].loc[df['ORIGIN'] == 'test']","7f117d23":"target_test.shape","499fea86":"df.isnull().sum()","b8ae9872":"#since it is showing more columns we will check which column's isnull().sum() value is greater than zero\ndf_nulls = df.isnull().sum().to_frame('nulls')","09d7b22b":"df_nulls[df_nulls.nulls > 0]","13dc6910":"X_train = df_train.drop(['ORIGIN'], axis=1)","72aeeab0":"X_test = df_test.drop(['ORIGIN'], axis=1)","7505b6a1":"len(X_train)","c2ab2114":"len(X_test)","3e0ca72e":"y_train = target_train\ny_test = target_test","cba09aab":"X_train.nunique() \n\ncoltypes = (X_train.nunique() < 5)  \ncoltypes    # All True are cat and all False are num\n\n\ncat_cols = coltypes[coltypes==True].index.tolist()\nnum_cols = coltypes[coltypes==False].index.tolist()","dc101f63":"from sklearn.preprocessing import StandardScaler as ss\nfrom sklearn.preprocessing import OneHotEncoder as onehot\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import RandomForestClassifier as rf","148d4c7b":"ohe = onehot(sparse = False)","36298b20":"ohe.fit_transform(X_train[cat_cols])","6dd345fe":"SS= ss()\nSS.fit_transform(X_train[num_cols])","bd7767c3":"from sklearn.tree import DecisionTreeClassifier","d7e1d2c2":"dt = DecisionTreeClassifier()\ndt.fit(X_train,y_train)","dfbc589e":"dt.predict(X_test)","14ebd8b2":"score = dt.score(X_test, y_test)\nprint(score)","676c54d7":"df_train = df.loc[df['ORIGIN'] == 'train']\ndf_test = df.loc[df['ORIGIN'] == 'test']\ntarget_train = df['CARAVAN'].loc[df['ORIGIN'] == 'train']\ntarget_test = df['CARAVAN'].loc[df['ORIGIN'] == 'test']\nX_train = df_train.drop(['ORIGIN'], axis=1)\nX_test = df_test.drop(['ORIGIN'], axis=1)\ny_train = target_train\ny_test = target_test","8fda7cf8":"from sklearn.ensemble import RandomForestClassifier\nrf=RandomForestClassifier()\nrf.fit(X_train,y_train)","3727de1c":"yy=rf.predict(X_test)","7108bd7f":"score = rf.score(X_test, y_test)\nscore","d6281d27":"df_train = df.loc[df['ORIGIN'] == 'train']\ndf_test = df.loc[df['ORIGIN'] == 'test']\ntarget_train = df['CARAVAN'].loc[df['ORIGIN'] == 'train']\ntarget_test = df['CARAVAN'].loc[df['ORIGIN'] == 'test']\nX_train = df_train.drop(['ORIGIN'], axis=1)\nX_test = df_test.drop(['ORIGIN'], axis=1)\ny_train = target_train\ny_test = target_test","7a094031":"from sklearn.preprocessing import StandardScaler","c9b904a9":"ct= ColumnTransformer([('abc', StandardScaler(),num_cols) ], remainder = 'passthrough')","f00e18cf":"from sklearn.pipeline import make_pipeline\npipe = make_pipeline( ct, rf)","c5d8d848":"ct.fit(X_train,y_train)","7715c006":"pipe.fit(X_train,y_train)","36124f66":"yy = pipe.predict(X_test)","77cabb13":"np.sum(yy == y_test)\/len(y_test)","540c270b":"df_train = df.loc[df['ORIGIN'] == 'train']\ndf_test = df.loc[df['ORIGIN'] == 'test']\ntarget_train = df['CARAVAN'].loc[df['ORIGIN'] == 'train']\ntarget_test = df['CARAVAN'].loc[df['ORIGIN'] == 'test']\nX_train = df_train.drop(['ORIGIN'], axis=1)\nX_test = df_test.drop(['ORIGIN'], axis=1)\ny_train = target_train\ny_test = target_test","6d485403":"X_train.nunique() \n\ncoltypes = (X_train.nunique() < 5)  \ncoltypes   \n\n\ncat_cols = coltypes[coltypes==True].index.tolist()\nnum_cols = coltypes[coltypes==False].index.tolist()","dc2db183":"from sklearn.preprocessing import OneHotEncoder","8b4879a0":"ct= ColumnTransformer([('abc', StandardScaler(),num_cols),('cde', OneHotEncoder(handle_unknown='ignore'),cat_cols) ], remainder = 'passthrough')","913217cc":"ct.fit(X_train,y_train)","0fe2b38f":"from sklearn.ensemble import RandomForestClassifier as rf\npipe = Pipeline([ ('ct',ct), ('rf', rf() )])","d8f707f8":"y_train.shape","c733b7b9":"pipe.fit(X_train,y_train)","21abc9f8":"yy=pipe.predict(X_test)","82e601fd":"np.sum(yy == y_test)\/len(y_test)","54b4b49c":"from sklearn.metrics import confusion_matrix\ncm=confusion_matrix(y_test,yy)\ncm","491da852":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nplt.figure(figsize=(10,7))\nsn.heatmap(cm,annot=True)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')","2a3219ab":"from sklearn.model_selection import train_test_split\nX_train_c, X_test_c, y_train_c, y_test_c = train_test_split(df.drop(['ORIGIN','CARAVAN'],axis='columns'),df.CARAVAN, test_size=0.4)","c7d684a0":"X_train_c.nunique() \n\ncoltypes_c = (X_train_c.nunique() < 5)  \ncoltypes_c   ","337dc6ab":"cat_cols_c = coltypes_c[coltypes_c==True].index.tolist()\nnum_cols_c = coltypes_c[coltypes_c==False].index.tolist()","f223c61a":"ct_c= ColumnTransformer([('abc', StandardScaler(),num_cols_c),('cde', OneHotEncoder(handle_unknown='ignore'),cat_cols_c) ], remainder = 'passthrough')","a5549bae":"pipe_c = Pipeline([ ('ct',ct_c), ('rf', rf() )])","4e263b54":"ct_c.fit(X_train_c,y_train_c)","47561949":"pipe_c.fit(X_train_c,y_train_c)","1fd23401":"from sklearn.ensemble import RandomForestClassifier as rf\nX_test_c.isnull().sum()\nyy_c=pipe_c.predict(X_test_c)","2272aa1e":"np.sum(yy_c == y_test_c)\/len(y_test_c)","8575480d":"from sklearn.metrics import confusion_matrix\ncm_c=confusion_matrix(y_test_c,yy_c)\ncm_c","ce061946":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nplt.figure(figsize=(10,7))\nsn.heatmap(cm_c,annot=True)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')","434fa3fa":"from sklearn.metrics import mean_squared_error\nmean_squared_error(y_test_c, yy_c)","72664829":"### CHECK SCORE WITH RANDOM FOREST CLASSIFIER - without scaling","6157316e":"#### We will use confusion matrix to display the accuarcy of our prediction","0d3652b1":"### CHECK SCORE WITH DECISION TREE","f3024c87":"### With Std scaler alone it is showing 100% accuracy..!","d95a7f54":"# *********************************************** End ********************************************************","cd7a2568":"### CHECK SCORE USING PIPELINE METHOD WITH STD.SCALER and OneHotEncoder","e63bb6ec":"#### Let us check the Mean squared error:","ce424de6":"# **Caravan Insurance Challenge**","f4f4eab7":"**Check whether any column has NAN value**","e8bb26b8":"# CHECK SCORE USING PIPELINE METHOD - WITH STD.SCALER","17d9adaf":"### Using Train_test_split, we get around 93% Score !","0e35b732":"No Null data","d3630ff2":"# It is showing 100% matching with given bifurcation of 'Test' and 'Train' in the data itself.   So, let us check the result using train_test_split model with same 40% split..","23605510":"<font size=6 color=green><center>Conclusion<\/font><br>\n    <font size=4 color=red><center>Models used with respective scores<\/font><br>\n\n\n|  <font size=6> Data Split      | <font size=6> Model     | <font size=6> Scaler     |  <font size=6> Pipeline     |<font size=6> Score Approx|\n|:----:|:----:|:----:|:----:|:----:|\n|<font size=3> From Data itself |<font size=3> Decision Tree |<font size=3>SS + OHE |<font size=3> No |<font size=3> 100% |\n|<font size=3> From Data itself |<font size=3> Random Forest |<font size=3>No  |<font size=3> No |<font size=3> 100% |\n|<font size=3> From Data itself | <font size=3>Random Forest |<font size=3>SS only  |<font size=3> Yes |<font size=3> 100% |\n|<font size=3> From Data itself |<font size=3> Random Forest |<font size=3> SS + OHE |<font size=3> Yes |<font size=3> 100% |\n|<font size=5 color=red> Train_test_split |<font size=3> Random Forest |<font size=3>SS + OHE |<font size=3> yes |<font size=3> 93% |\n\n","a6fb9f86":"### With  Std scaler and Onehotencoder, it is showing 100% accuracy !!","892a0fa5":"### Confusion matrix to display the result","2c486d32":"### Since data has \"train\" and \"test\" bifurcation in ORIGIN column, we split train\/test data on the basis of Origin column's type","667d192e":"#### We will drop the ORIGIN column from both X_train and X_test"}}