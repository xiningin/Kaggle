{"cell_type":{"cd4b7e6e":"code","7f4f2d04":"code","2b06bfcf":"code","8315c0ae":"code","5712bfaf":"code","a6c01736":"code","6bf6f254":"code","943b64aa":"code","f60600db":"code","e4944abf":"code","72de97e5":"code","868d0e0d":"code","17e9263b":"code","adaa3ca1":"code","83ecd277":"code","404c76cf":"code","4729f3a0":"code","aea5250a":"code","c5b4fa28":"markdown","57e270d0":"markdown","3bb0ac15":"markdown","24d96905":"markdown","addc0f80":"markdown","478e406d":"markdown","6de33c9b":"markdown","6f3b5b31":"markdown"},"source":{"cd4b7e6e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7f4f2d04":"from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPool2D\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.utils import to_categorical\n\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","2b06bfcf":"np.random.seed(42)","8315c0ae":"def doSubmission(y_pred):\n    test_Id = np.arange(1, y_pred.size+1, dtype=np.int)\n    \n    pred_dict = {\"ImageId\": test_Id, \"Label\": y_pred}\n    df = pd.DataFrame(pred_dict)\n    df.to_csv(\"sample_submission.csv\", index=False, index_label=False)","5712bfaf":"df_train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","a6c01736":"y = df_train.label.to_numpy() # transforming into numpy array\n\nX = df_train.drop(columns=[\"label\"]).to_numpy(np.float64)\nX \/= 255.0 #normalizing to improve the model learning","6bf6f254":"X_totrain = X.reshape(X.shape[0], 28, 28, 1) #a complete data base to train the model for prediction","943b64aa":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\n\nX_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1)","f60600db":"y_cat = to_categorical(y, 10)\ny_train_cat = to_categorical(y_train, 10)\ny_test_cat = to_categorical(y_test, 10)","e4944abf":"test = df_test.to_numpy(np.float64)\ntest = test.reshape(test.shape[0], 28, 28, 1)\ntest \/= 255.0","72de97e5":"def convNeuralNetwork(filters=256, kernel_size=(3, 3), pool_size=(2, 2), units=128, dropout=0.2):\n    cnn = Sequential()\n    \n    cnn.add(Conv2D(filters=filters, kernel_size=kernel_size, strides=(1, 1), \n                   input_shape=(28, 28, 1), activation=\"relu\", padding=\"same\"))\n    cnn.add(MaxPool2D(pool_size=pool_size, padding=\"same\"))\n\n    cnn.add(Conv2D(filters=filters, kernel_size=kernel_size, strides=(1, 1),\n                   activation=\"relu\", padding=\"same\"))\n    cnn.add(MaxPool2D(pool_size=pool_size, padding=\"same\"))\n    \n    cnn.add(Flatten())\n            \n    cnn.add(Dense(units=units, activation=\"relu\"))\n    cnn.add(Dropout(dropout))\n            \n    cnn.add(Dense(units=units, activation=\"relu\"))\n    cnn.add(Dropout(dropout))\n            \n    cnn.add(Dense(units=10, activation=\"softmax\"))\n    \n    cnn.compile(optimizer=\"adamax\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    \n    return cnn","868d0e0d":"early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1, \n                               restore_best_weights=True)\n\ncnn = convNeuralNetwork(filters=2048, units=1024)\ncnn_hist = cnn.fit(X_train, y_train_cat, validation_data=(X_test, y_test_cat), \n                   epochs=50, batch_size=256, callbacks=[early_stopping])","17e9263b":"accuracy = cnn_hist.history[\"accuracy\"]\nval_accuracy = cnn_hist.history[\"val_accuracy\"]\n\nplt.plot(accuracy, \"o-\", label=\"Accuracy\")\nplt.plot(val_accuracy, \"o-\", label=\"Val Accuracy\")\n\nplt.legend(loc=\"best\")\nplt.grid()\nplt.show()","adaa3ca1":"loss = cnn_hist.history[\"loss\"]\nval_loss = cnn_hist.history[\"val_loss\"]\n\nplt.plot(loss, \"o-\", label=\"Loss\")\nplt.plot(val_loss, \"o-\", label=\"Val Loss\")\n\nplt.legend(loc=\"best\")\nplt.grid()\nplt.show()","83ecd277":"early_stopping = EarlyStopping(monitor=\"loss\", patience=10, restore_best_weights=True)\nmodel_checkpoint = ModelCheckpoint(filepath=\".\/\", monitor=\"loss\", verbose=1,\n                                   save_best_only=True, save_weights_only=True)\n\nmodel = convNeuralNetwork(filters=2048, units=1024)\nmodel_hist = model.fit(X_totrain, y_cat, batch_size=256, epochs=50, \n                       callbacks=[early_stopping, model_checkpoint])","404c76cf":"accuracy = model_hist.history[\"accuracy\"]\n\nplt.plot(accuracy, \"o-\", label=\"Accuracy\")\nplt.legend(loc=\"best\")\nplt.grid()\nplt.show()","4729f3a0":"accuracy = model_hist.history[\"loss\"]\n\nplt.plot(accuracy, \"o-\", label=\"Loss\")\nplt.legend(loc=\"best\")\nplt.grid()\nplt.show()","aea5250a":"y_pred = model.predict(test).argmax(1)\n\ndoSubmission(y_pred)","c5b4fa28":"## Importing\n---","57e270d0":"### Training","3bb0ac15":"### Model to Test\n\nIt's important to see if the model is not underfiting or overfiting","24d96905":"## Functions\n___","addc0f80":"Now it's time to separate into train and test database. ","478e406d":"## Building the Convolution Neural Network\n---","6de33c9b":"# Digit Recognizer using CNN\n---","6f3b5b31":"## Preprocessing\n---"}}