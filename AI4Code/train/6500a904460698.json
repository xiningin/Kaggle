{"cell_type":{"71b27da2":"code","df6c3375":"code","a2af2148":"code","e2ccaa03":"code","4f946ee7":"code","9b1fb718":"code","626ebbc1":"code","c689096f":"code","b2cb71c6":"code","34d05ee8":"code","ce4166c5":"code","047c8638":"code","ee7c35d9":"code","9ecee486":"code","985a7359":"code","1bfa2ea0":"code","c194ffd8":"code","ad65187b":"code","40d84938":"code","6507718a":"code","d8c798b0":"code","023bf76e":"code","d87b8839":"code","ded69e7c":"code","4875aac8":"code","f6ac1501":"code","1ae81452":"code","b139d469":"code","314f6b3b":"code","a8e19c2c":"code","2566bf7c":"code","980b05ae":"code","c628e375":"code","fde332e9":"code","161421e5":"code","6c855bf1":"code","f74bd795":"code","27fbc9db":"code","73bc83af":"code","d3aea232":"code","2a5f2ddd":"code","c39d81f8":"code","5e3a8655":"code","a5281f86":"code","e00206a6":"code","9eee9c7f":"code","72d27b75":"code","3a525dfc":"code","dc7b8b3b":"code","b27e9736":"code","75f9c2da":"code","4053f972":"code","d635b017":"code","4d99c0d7":"code","dd90d4c8":"code","b0569178":"code","7d70b5b6":"code","8e25986d":"code","f8204f17":"code","f5929cf6":"code","3ebab4f6":"code","88cace8c":"code","d2321e98":"code","eb68c19b":"code","aa8bd3bf":"code","095bc8b8":"code","d32fea78":"code","0b4f8477":"code","b570bb53":"code","940a1bc4":"code","4a436b1a":"code","7913573e":"code","333336ad":"code","ac342e48":"code","190a3281":"code","6a59bf68":"code","cd76af29":"markdown","885d01b0":"markdown","b3938dbb":"markdown","e794f51d":"markdown","163bb3e9":"markdown","ac8237ab":"markdown","af8cfbe0":"markdown","3944f429":"markdown","67eaa038":"markdown","e840a281":"markdown","56cd3995":"markdown","a22c05ed":"markdown","7dcbd7ab":"markdown","61649bf2":"markdown","08882869":"markdown"},"source":{"71b27da2":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\npd.pandas.set_option('display.max_rows',None)","df6c3375":"df=pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')","a2af2148":"df.head()","e2ccaa03":"features_na = [features for features in df.columns if df[features].isnull().sum()>1]\nfor feature in features_na:\n    print(feature,np.round(df[feature].isnull().mean(),4))","4f946ee7":"for feature in features_na:\n    dfnew = df.copy()\n    dfnew[feature] = np.where(dfnew[feature].isnull(),1,0 )\n\n    dfnew.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.title(feature)\n    plt.show()","9b1fb718":"numerical = [features for features in df.columns if df[features].dtypes != \"O\"]\nprint(len(numerical))\ndf[numerical].head()","626ebbc1":"year_variables = [features for features in numerical if 'Yr' in features or 'Year' in features]\nyear_variables","c689096f":"print('YrSold',df['YrSold'].unique())","b2cb71c6":"df.groupby('YrSold')['SalePrice'].median().plot()\nplt.title('YrSold')\nplt.show()","34d05ee8":"for year in year_variables:\n    if year != 'YrSold':\n        data = df.copy()\n        data[year] = data['YrSold'] - data[year]\n        plt.scatter(data[year],data['SalePrice'])\n        plt.xlabel(year)\n        plt.ylabel('SalePrice')\n        plt.title(feature+' SalePrice')\n        plt.show()","ce4166c5":"discrete_feature = [features for features in numerical if len(df[features].unique())<25 and (features not in year_variables + ['Id'])]\nprint(len(discrete_feature))","047c8638":"for i in discrete_feature:\n    data = df.copy()\n    \n    data.groupby(i)['SalePrice'].median().plot.bar()\n    plt.xlabel(i)\n    plt.ylabel('SalePrice')\n    plt.title('Saleprice vs '+i )\n    plt.show()","ee7c35d9":"cont_features = [features for features in numerical if features not in discrete_feature + year_variables + ['Id']]\nlen(cont_features)","9ecee486":"for i in cont_features:\n    data = df.copy()\n    if 0 in data[i].unique():\n        pass\n    else:\n        data[i] = np.log(data[i])\n        data['SalePrice'] = np.log(data['SalePrice'])\n        plt.scatter(data[i],data['SalePrice'])\n        plt.xlabel(i)\n        plt.ylabel('SalePrice')\n        plt.show()","985a7359":"for i in cont_features:\n    data = df.copy()\n    if 0 in data[i].unique():\n        pass\n    else:\n        data[i] = np.log(data[i])\n        data.boxplot(column = i)\n        plt.title(i)\n        plt.show()","1bfa2ea0":"categorical = [feature for feature in df.columns if df[feature].dtypes == 'O']\nprint(len(categorical))","c194ffd8":"for i in categorical:\n    print(\"Feature {} has {} unique values\".format(i,len(df[i].unique())))","ad65187b":"for i in categorical:\n    data = df.copy()\n    \n    data.groupby(i)['SalePrice'].median().plot.bar()\n    plt.xlabel(i)\n    plt.ylabel('SalePrice')\n    plt.show()","40d84938":"sns.heatmap(df.isnull(),yticklabels = False,cbar = False)","6507718a":"df.isnull().sum()","d8c798b0":"df['LotFrontage'] = df['LotFrontage'].fillna(df['LotFrontage'].mean())","023bf76e":"df['BsmtFinType1'].value_counts()","d87b8839":"df.drop('Alley',axis = 1,inplace = True)","ded69e7c":"df.shape","4875aac8":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler","f6ac1501":"data = df.copy()\ndata.drop('SalePrice',axis = 1)\nX_train, X_test, y_train, y_test = train_test_split(data,df['SalePrice'],test_size = 0.1)","1ae81452":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","b139d469":"categorical = [features for features in df.columns if df[features].dtypes == 'O'\\\n               and df[features].isnull().sum()>=1]\nfor i in categorical:\n    print(i,\"Percentage of missing values\",\"{:.2%}\".format(df[i].isnull().sum()\/df.shape[0]))","314f6b3b":"for i in categorical:\n    #data = dataset.copy()\n    df[i] = df[i].fillna('Missing')\nfor i in categorical:\n    print(i,\"Percentage of missing values\",\"{:.2%}\".format(df[i].isnull().sum()\/df.shape[0]))","a8e19c2c":"numerical = [features for features in df.columns if df[features].dtypes != 'O' \\\n             and df[features].isnull().sum()>1]\nfor i in numerical:\n    print(i,\"Percentage of missing values\",\"{:.2%}\".format(df[i].isnull().sum()\/df.shape[0]))","2566bf7c":"for i in numerical:\n    #data = dataset.copy()\n    m = df[i].median()\n    df[i+'NAN'] = np.where(df[i].isnull(),1,0)\n    df[i].fillna(m, inplace = True)\nfor i in numerical:\n    print(i,\"Percentage of missing values\",\"{:.2%}\".format(df[i].isnull().sum()\/df.shape[0]))","980b05ae":"year_variables = ['YearBuilt', 'YearRemodAdd', 'GarageYrBlt']\nfor i in year_variables:\n    df[i] = df['YrSold'] - df[i]","c628e375":"df[['YearBuilt','YearRemodAdd','GarageYrBlt']].head()","fde332e9":"num_features=['LotFrontage', 'LotArea', '1stFlrSF', 'GrLivArea', 'SalePrice']\n\nfor feature in num_features:\n    df[feature]=np.log(df[feature])","161421e5":"#extracting the categorical features\ncategorical_features = [features for features in df.columns if df[features].dtype == 'O']\nlen(categorical_features)","6c855bf1":"for feature in categorical_features:\n    temp = df.groupby(feature)['SalePrice'].count()\/len(df)\n    temp_df = temp[temp>0.01].index\n    df[feature] = np.where(df[feature].isin(df),df[feature],\\\n                                'Rare variable')","f74bd795":"for feature in categorical_features:\n    labels_ordered=df.groupby([feature])['SalePrice'].count().sort_values().index\n    labels_ordered={k:i for i,k in enumerate(labels_ordered,0)}\n    df[feature]=df[feature].map(labels_ordered)","27fbc9db":"df.shape","73bc83af":"df.drop(['GarageYrBltNAN','MasVnrAreaNAN'],axis=1,inplace=True)","d3aea232":"#Features, which we want to scale\nscale_features = [features for features in df.columns if features not in ['Id','SalePrice']]\nlen(scale_features)","2a5f2ddd":"test_df=pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","c39d81f8":"test_df.shape","5e3a8655":"sns.heatmap(test_df.isnull())","a5281f86":"test_df['MSZoning'] = test_df['MSZoning'].fillna(test_df['MSZoning'].mode()[0])","e00206a6":"null_features = [features for features in test_df.columns if test_df[features].\\\n                 isnull().sum()>1]\nfor features in null_features:\n    print(features,100*np.round(test_df[features].isnull().mean(),4),'% of missing values')","9eee9c7f":"null_cat_features = [features for features in test_df.columns if test_df[features].isnull().\\\n                     sum()>1\\\n                 and test_df[features].dtypes == 'O']\nfor features in null_cat_features:\n    print(features,100*np.round(test_df[features].isnull().mean(),4),'% of missing values')","72d27b75":"def replace_nan(dataset,features):\n    data = dataset.copy()\n    data[features] = data[features].fillna('Missing')\n    return data\ntest_df = replace_nan(test_df,null_cat_features)\nprint(test_df[null_cat_features].isnull().sum())","3a525dfc":"numerical_features = [features for features in test_df.columns if test_df[features].isnull().\\\n                      sum()>1 and test_df[features].dtypes != 'O']\nfor features in numerical_features:\n    print(features,100*np.round(test_df[features].isnull().mean(),4),' % of missing values')","dc7b8b3b":"for feature in numerical_features:\n    m = test_df[feature].median()\n    d = np.where(test_df[feature].isnull(),1,0)\n    test_df[feature+'na'] = d\n    test_df[feature].fillna(m,inplace = True)\ntest_df[numerical_features].isnull().sum()","b27e9736":"year_features = [feature for feature in test_df.columns if 'Year' in feature or \\\n                 'Yr' in feature]\nyear_features","75f9c2da":"year_features = ['YearBuilt', 'YearRemodAdd', 'GarageYrBlt']\nfor feature in year_features:\n    test_df[feature] = test_df['YrSold'] - test_df[feature]","4053f972":"test_df[['YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'YrSold']].head()","d635b017":"num_features=['LotFrontage', 'LotArea', '1stFlrSF', 'GrLivArea']\n\nfor feature in num_features:\n    test_df[feature]=np.log(test_df[feature])","4d99c0d7":"categorical_features=[feature for feature in test_df.columns if test_df[feature].dtype=='O']","dd90d4c8":"for feature in categorical_features:\n    temp = test_df.groupby(feature)[feature].count()\/len(test_df)\n    temp_df = temp[temp>0.01].index\n    test_df[feature] = np.where(test_df[feature].isin(temp_df),test_df[feature],\\\n                                'Rare variable')","b0569178":"for feature in categorical_features:\n    labels_ordered=test_df.groupby([feature])[feature].count().sort_values().index\n    labels_ordered={k:i for i,k in enumerate(labels_ordered,0)}\n    test_df[feature]=test_df[feature].map(labels_ordered)","7d70b5b6":"#Features, which we want to scale\nscale_features = [features for features in df.columns if features not in ['Id','SalePrice']]\nlen(scale_features)","8e25986d":"#Normalizing the data\nscaler = MinMaxScaler()\nscaler.fit(df[scale_features])","f8204f17":"#Concatenation of the scaled and not-scaled features\ndf = pd.concat([df[['Id','SalePrice']].reset_index(drop = True),\n                     pd.DataFrame(scaler.transform(df[scale_features]),\\\n                                  columns = scale_features)],axis = 1)","f5929cf6":"#saving the file\ndf.to_csv('X_train.csv', index = False)","3ebab4f6":"from sklearn.linear_model import Lasso\nfrom sklearn.feature_selection import SelectFromModel","88cace8c":"#Concatenation of the scaled and not-scaled features\ntest_df_new = pd.concat([test_df['Id'].reset_index(drop = True),\n                     pd.DataFrame(scaler.transform(test_df[scale_features]),\\\n                                  columns = scale_features)],axis = 1)","d2321e98":"#Retrieving dependent variable\ny = df['SalePrice']","eb68c19b":"#Retrieving features\nX = df.drop(['Id','SalePrice'],axis = 1)","aa8bd3bf":"#Fitting the Lasso Regression model\nselect = SelectFromModel(Lasso(alpha = 0.005, random_state = 0))\nselect.fit(X,y)","095bc8b8":"#Selected features\nselected_feat = X.columns[select.get_support()]","d32fea78":"print(\"Original features {}\".format(X.shape[1]))\nprint(\"Selected features {}\".format(len(selected_feat)))","0b4f8477":"#Taking dataset with only selected features\nX = X[selected_feat]","b570bb53":"X.shape","940a1bc4":"X_test = test_df_new.drop(['Id'],axis = 1)","4a436b1a":"X_test = test_df_new[selected_feat]","7913573e":"X_test.shape","333336ad":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor","ac342e48":"## Replace the missing value with the most common one\nfor column in X_test.columns:\n    X_test[column].fillna(X_test[column].mode()[0], inplace=True)","190a3281":"regr = RandomForestRegressor(random_state=0)\nregr.fit(X, y)\ny_test = np.exp(regr.predict(X_test))\ny_test_df = pd.DataFrame(y_test)\ny_test_df.columns = ['SalePrice']\ndf_output = pd.concat([test_df_new['Id'],y_test_df],\\\n                      axis=1)\ndf_output.to_csv('submission.csv',index=False)","6a59bf68":"regr = GradientBoostingRegressor(random_state=0)\nregr.fit(X, y)\ny_test = np.exp(regr.predict(X_test))\ny_test_df = pd.DataFrame(y_test)\ny_test_df.columns = ['SalePrice']\ndf_output = pd.concat([test_df_new['Id'],y_test_df],\\\n                      axis=1)\ndf_output.to_csv('submission.csv',index=False)","cd76af29":"# Feature Engineering","885d01b0":"## Feature Engineering","b3938dbb":"# Test dataset","e794f51d":"### Discrete variables","163bb3e9":"We are going to remove the categorical variables, that contribute to only 1% of the observations","ac8237ab":"# Creating the model","af8cfbe0":"## Outliers","3944f429":"## Numerical variables","67eaa038":"### Continuous Features","e840a281":"# Feature Scaling","56cd3995":"## Missing values","a22c05ed":"### Numerical","7dcbd7ab":"## Categorical variables","61649bf2":"## Rare Categorical Variables","08882869":"### Continuous features"}}