{"cell_type":{"0b3dd82c":"code","52bd09dc":"code","6378164c":"code","dd324d97":"code","d55376aa":"code","badfa50e":"code","be64bf80":"code","021c03fb":"code","7ec39392":"code","7343b15f":"code","837f6849":"code","24b840f3":"code","991e05c9":"code","9ed940e6":"code","d7611886":"code","193f2e33":"code","54cc7060":"code","7ed3498e":"code","6dfb575a":"code","7effa675":"code","1e3e5b08":"code","25833d98":"code","1d1d4d82":"code","62b4e920":"code","41f2a08f":"code","eedbbbf5":"code","dac5ed45":"code","0f3da87e":"code","1e75fe93":"code","0f9e6e67":"code","d62f5cb4":"code","dc44cfdf":"code","06d7067f":"code","0bee1963":"code","f57a9163":"code","2d9b57b0":"code","f1298600":"code","685256e4":"code","967f590e":"markdown","dd318a18":"markdown","572c5c55":"markdown","a7fee068":"markdown","de64215b":"markdown","3205d9df":"markdown","07b7c31a":"markdown","8bcb8312":"markdown"},"source":{"0b3dd82c":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.datasets import load_boston\nfrom sklearn.metrics import r2_score","52bd09dc":"boston = load_boston()\ndata = pd.DataFrame(data = boston.data, columns = boston.feature_names)\ndata","6378164c":"data['Price'] = boston.target\ndata","dd324d97":"Missing_value = data.isna().sum()\nMissing_value","d55376aa":"data.shape[0] - data.count()\n","badfa50e":"data.info()","be64bf80":"data.describe()","021c03fb":"plt.hist(data['Price'], bins = 50)","7ec39392":"var_ind = np.arange(0, 14)\nplot = plt.figure(figsize = (20, 10))\nplot.subplots_adjust(hspace = 0.5, wspace = 0.5)\nfor i in range(1, 15):\n    a = plot.add_subplot(4, 4, i)\n    a.hist(data.iloc[:, var_ind[i - 1]], alpha = 0.7, bins = 30)\n    a.title.set_text(data.columns[i - 1])","7343b15f":"cor_table = data.iloc[:, var_ind].corr(method = 'pearson')\ncor_table","837f6849":"from sklearn.model_selection import train_test_split\ntrain, test = train_test_split(data, test_size = 0.25, random_state = 123456)\nprint(f'The shape of train is: {train.shape}')\nprint(f'The shape of test is: {test.shape}')","24b840f3":"test","991e05c9":"X_train = train.iloc[:, :-1]\ny_train = train.iloc[:, -1]\nX_test = test.iloc[:, :-1]\ny_test = test.iloc[:, -1]\n\n\nprint(f'The shape of X_train is: {X_train.shape}')\nprint(f'The shape of y_train is: {y_train.shape}')\nprint(f'The shape of X_test is: {X_test.shape}')\nprint(f'The shape of y_test is: {y_test.shape}')","9ed940e6":"import statsmodels.formula.api as smf\nmodel1 = smf.ols(formula = 'np.log(Price) ~ CRIM + ZN + INDUS + CHAS + NOX + RM + AGE + DIS + RAD + TAX + PTRATIO + B + LSTAT', data = train)\nmodel1 = model1.fit()\nmodel1.summary()","d7611886":"y_pred_model1 = model1.predict(X_test)\ny_pred_model1 = np.exp(y_pred_model1)\nabs_err_model1 = np.abs(y_pred_model1 - y_test)\nnp.mean(abs_err_model1)","193f2e33":"#Absolute error mean, median, sd, IQR, max, min\nfrom scipy.stats import iqr\nmodel_comp = pd.DataFrame({'Mean of AbsErrors':    abs_err_model1.mean(),\n                           'Median of AbsErrors' : abs_err_model1.median(),\n                           'SD of AbsErrors' :     abs_err_model1.std(),\n                           'IQR of AbsErrors':     iqr(abs_err_model1),\n                           'Min of AbsErrors':     abs_err_model1.min(),\n                           'Max of AbsErrors':     abs_err_model1.max()}, index = ['Model1: Classical Regression'])\nmodel_comp","54cc7060":"y_pred = y_pred_model1\ny_test = y_test\nmodel = 'model1_ClassicalRegression'\n\nplt.figure(figsize=(15, 15), dpi = 150);\nplt.subplots_adjust(hspace = 0.25, wspace = 0.25);\n\nplt.subplots(figsize=(16,6));\nplt.scatter(x = y_test, y = y_pred, color = 'blue');\n#Add 45 degree line\nxp = np.linspace(y_test.min(), y_test.max(), 100)\nplt.plot(xp, xp, 'k', alpha = 0.9, linewidth = 2, color = 'red')\nplt.xlabel('Actual Value');\nplt.ylabel('Predicted Value');\n\nplt.title(f'{model}');\nplt.subplots(figsize=(17,6));\nprint(f'The r2-score is: {r2_score(y_pred, y_test)}')\nx_points = list(range(len(y_test)));\nplt.plot(x_points, y_test, label='y_real', color = 'blue');\nplt.plot(x_points, y_pred, label='y_predict', color = 'red');\nplt.legend();\nplt.title(f'{model}');\nplt.show();","7ed3498e":"abs_err = abs_err_model1\nname = 'abs_err_model1 Classical Reg'\n\nplt.figure(figsize=(15, 5), dpi = 200)\nplt.subplots_adjust(hspace = 0.25, wspace = 0.25)\n\n\nplt.subplot(121)\nplt.boxplot(abs_err);\nplt.title(f'boxplot of {name}');\nplt.grid()\n\nplt.subplot(122)\nsns.distplot(abs_err, kde = False);\nplt.title(f'Histogram of {name}');\n","6dfb575a":"logy_train = np.log(y_train)","7effa675":"lambda_grid = 10 ** np.linspace(-2, 5, 1000)\nlambda_grid","1e3e5b08":"from sklearn.linear_model import Ridge, RidgeCV\nridgecv = RidgeCV(alphas = lambda_grid, cv = 10, normalize = True)\nridgecv.fit(X_train, logy_train)\nridgecv.alpha_\n\n","25833d98":"model2 = Ridge(normalize = True, alpha = ridgecv.alpha_)\nmodel2.fit(X_train, logy_train)\ny_pred_model2 = model2.predict(X_test)\ny_pred_model2 = np.exp(y_pred_model2)\nabs_err_model2 = np.abs(y_test - y_pred_model2)\nnp.mean(abs_err_model2)","1d1d4d82":"model_comp = model_comp.append(pd.DataFrame({'Mean of AbsErrors':    abs_err_model2.mean(),\n                                             'Median of AbsErrors' : abs_err_model2.median(),\n                                             'SD of AbsErrors' :     abs_err_model2.std(),\n                                             'IQR of AbsErrors':     iqr(abs_err_model2),\n                                             'Min of AbsErrors':     abs_err_model2.min(),\n                                             'Max of AbsErrors':     abs_err_model2.max()}, index = ['Model2: Ridge']), \n                               ignore_index = False)\n\nmodel_comp","62b4e920":"y_pred = y_pred_model2\ny_test = y_test\nmodel = 'model2: Ridge Regression'\n\nplt.figure(figsize=(15, 15), dpi = 150);\nplt.subplots_adjust(hspace = 0.25, wspace = 0.25);\n\nplt.subplots(figsize=(16,6));\nplt.scatter(x = y_test, y = y_pred, color = 'blue');\n#Add 45 degree line\nxp = np.linspace(y_test.min(), y_test.max(), 100)\nplt.plot(xp, xp, 'k', alpha = 0.9, linewidth = 2, color = 'red')\nplt.xlabel('Actual Value');\nplt.ylabel('Predicted Value');\n\nplt.title(f'{model}');\nplt.subplots(figsize=(17,6));\nprint(f'The r2-score is: {r2_score(y_pred, y_test)}')\nx_points = list(range(len(y_test)));\nplt.plot(x_points, y_test, label='y_real', color = 'blue');\nplt.plot(x_points, y_pred, label='y_predict', color = 'red');\nplt.legend();\nplt.title(f'{model}');\nplt.show();","41f2a08f":"abs_err = abs_err_model2\nname = 'abs_err_model2 Ridge Reg'\n\nplt.figure(figsize=(15, 5), dpi = 200)\nplt.subplots_adjust(hspace = 0.25, wspace = 0.25)\n\n\nplt.subplot(121)\nplt.boxplot(abs_err);\nplt.title(f'boxplot of {name}');\nplt.grid()\n\nplt.subplot(122)\nsns.distplot(abs_err, kde = False);\nplt.title(f'Histogram of {name}');\n","eedbbbf5":"# {'min_samples_leaf': 5, 'max_depth': 6, 'ccp_alpha': 0.00018}","dac5ed45":"from sklearn.tree import DecisionTreeRegressor\nmodel3 = DecisionTreeRegressor(max_depth = 6, \n                               min_samples_leaf = 5, \n                               ccp_alpha = 0.00018)\nmodel3 = model3.fit(X_train, logy_train)\ny_pred_model3 = model3.predict(X_test)\ny_pred_model3 = np.exp(y_pred_model3)\nabs_err_model3 = np.abs(y_pred_model3 - y_test)\nnp.mean(abs_err_model3)","0f3da87e":"# # HyperParameter Tuning\n# from sklearn.model_selection import RandomizedSearchCV\n\n# max_depth = [3, 4, 5, 6, 7, 8, 9]\n# min_samples_leaf = [5, 7, 6, 8, 9, 4]\n# ccp_alpha = [0.0001, 0.001, 0.01, 0.1, 0.00025, 0.00018, 0.0007, 0.0054]\n# objective = ['reg:squarederror']\n\n# random_grid = {'max_depth': max_depth, \n#                'min_samples_leaf': min_samples_leaf, \n#                'ccp_alpha': ccp_alpha}\n\n# decision = RandomizedSearchCV(estimator = model3, param_distributions = random_grid, scoring = 'neg_mean_squared_error', n_iter = 10, cv = 8)\n# decision.fit(X_train, logy_train)\n# decision.best_params_\n","1e75fe93":"model_comp = model_comp.append(pd.DataFrame({'Mean of AbsErrors':    abs_err_model3.mean(),\n                                             'Median of AbsErrors' : abs_err_model3.median(),\n                                             'SD of AbsErrors' :     abs_err_model3.std(),\n                                             'IQR of AbsErrors':     iqr(abs_err_model3),\n                                             'Min of AbsErrors':     abs_err_model3.min(),\n                                             'Max of AbsErrors':     abs_err_model3.max()}, index = ['Model3: Tree']), \n                               ignore_index = False)\n\nmodel_comp","0f9e6e67":"y_pred = y_pred_model3\ny_test = y_test\nmodel = 'model 3 Tree'\n\nplt.figure(figsize=(15, 15), dpi = 150);\nplt.subplots_adjust(hspace = 0.25, wspace = 0.25);\n\nplt.subplots(figsize=(16,6));\nplt.scatter(x = y_test, y = y_pred, color = 'blue');\n#Add 45 degree line\nxp = np.linspace(y_test.min(), y_test.max(), 100)\nplt.plot(xp, xp, 'k', alpha = 0.9, linewidth = 2, color = 'red')\nplt.xlabel('Actual Value');\nplt.ylabel('Predicted Value');\n\nplt.title(f'{model}');\nplt.subplots(figsize=(17,6));\nprint(f'The r2-score is: {r2_score(y_pred, y_test)}')\nx_points = list(range(len(y_test)));\nplt.plot(x_points, y_test, label='y_real', color = 'blue');\nplt.plot(x_points, y_pred, label='y_predict', color = 'red');\nplt.legend();\nplt.grid()\nplt.title(f'{model}');\nplt.show();","d62f5cb4":"abs_err = abs_err_model3\nname = 'abs_err_model3_Decision Tree'\n\nplt.figure(figsize=(15, 5), dpi = 200)\nplt.subplots_adjust(hspace = 0.25, wspace = 0.25)\n\n\nplt.subplot(121)\nplt.boxplot(abs_err);\nplt.title(f'boxplot of {name}');\nplt.grid()\n\nplt.subplot(122)\nsns.distplot(abs_err, kde = False);\nplt.title(f'Histogram of {name}');\n","dc44cfdf":"from sklearn.ensemble import BaggingRegressor\nmodel4 = BaggingRegressor(n_estimators = 500)\nmodel4.fit(X_train, logy_train)\n\n\n","06d7067f":"y_pred_model4 = model4.predict(X_test)\ny_pred_model4 = np.exp(y_pred_model4)\nabs_err_model4 = np.abs(y_pred_model4 - y_test)\nnp.mean(abs_err_model4)","0bee1963":"model_comp = model_comp.append(pd.DataFrame({'Mean of AbsErrors':    abs_err_model4.mean(),\n                                             'Median of AbsErrors' : abs_err_model4.median(),\n                                             'SD of AbsErrors' :     abs_err_model4.std(),\n                                             'IQR of AbsErrors':     iqr(abs_err_model4),\n                                             'Min of AbsErrors':     abs_err_model4.min(),\n                                             'Max of AbsErrors':     abs_err_model4.max()}, index = ['Model4: Bagging']), \n                               ignore_index = False)\n\nmodel_comp","f57a9163":"y_pred = y_pred_model4\ny_test = y_test\nmodel = 'model 4 Bagging'\n\nplt.figure(figsize=(15, 15), dpi = 150);\nplt.subplots_adjust(hspace = 0.25, wspace = 0.25);\n\nplt.subplots(figsize=(16,6));\nplt.scatter(x = y_test, y = y_pred, color = 'blue');\n#Add 45 degree line\nxp = np.linspace(y_test.min(), y_test.max(), 100)\nplt.plot(xp, xp, 'k', alpha = 0.9, linewidth = 2, color = 'red')\nplt.xlabel('Actual Value');\nplt.ylabel('Predicted Value');\n\nplt.title(f'{model}');\nplt.subplots(figsize=(17,6));\nprint(f'The r2-score is: {r2_score(y_pred, y_test)}')\nx_points = list(range(len(y_test)));\nplt.plot(x_points, y_test, label='y_real', color = 'blue');\nplt.plot(x_points, y_pred, label='y_predict', color = 'red');\nplt.legend();\nplt.grid()\nplt.title(f'{model}');\nplt.show();","2d9b57b0":"abs_err = abs_err_model4\nname = 'abs_err_model4 Bagging'\n\nplt.figure(figsize=(15, 5), dpi = 200)\nplt.subplots_adjust(hspace = 0.25, wspace = 0.25)\n\n\nplt.subplot(121)\nplt.boxplot(abs_err);\nplt.title(f'boxplot of {name}');\nplt.grid()\n\nplt.subplot(122)\nsns.distplot(abs_err, kde = False);\nplt.title(f'Histogram of {name}');\n","f1298600":"from sklearn.ensemble import RandomForestRegressor\nmodel5 = RandomForestRegressor(n_estimators = 1220,\n                               oob_score = True, \n                               max_features = 'sqrt', \n                               max_depth = 33, \n                               min_samples_split = 2, \n                               min_samples_leaf = 1)\n\nmodel5.fit(X_train, logy_train)\ny_pred_model5 = model5.predict(X_test)\ny_pred_model5 = np.exp(y_pred_model5)\nabs_err_model5 = np.abs(y_pred_model5 - y_test)\nnp.mean(abs_err_model5)\n\n","685256e4":"# from sklearn.model_selection import RandomizedSearchCV\n# n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 40)]\n# max_features = ['auto', 'sqrt']\n# max_depth = [int(x) for x in np.linspace(5, 40, num = 6)]\n# min_samples_split = [2, 5, 10, 15, 20,25,30,35,40,100]\n# min_samples_leaf = [1, 2, 5, 10]\n\n# random_grid = {'n_estimators': n_estimators,\n#                'max_features': max_features,\n#                'max_depth': max_depth,\n#                'min_samples_split': min_samples_split,\n#                'min_samples_leaf': min_samples_leaf}\n\n# rf_random = RandomizedSearchCV(estimator = model5, \n#                                param_distributions = random_grid, \n#                                scoring='neg_mean_squared_error',\n#                                n_iter = 10, \n#                                cv = 5, \n#                                verbose=2, \n#                                random_state=42, \n#                                n_jobs = 1)\n\n# rf_random.fit(X_train, logy_train);\n# rf_random.best_params_","967f590e":"# Model1: Classic Regression","dd318a18":"# Model 2: Ridge Regression","572c5c55":"# Model 4: Bagging","a7fee068":"# Load Dataset","de64215b":"# Split data","3205d9df":"# Model 5: RandomForest Regression\n","07b7c31a":"![boston.png](attachment:2ad91c6a-8278-48dc-a187-84a6f4525021.png)","8bcb8312":"# Model 3: Decision Tree"}}