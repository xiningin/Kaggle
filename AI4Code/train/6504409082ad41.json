{"cell_type":{"f53dcbd1":"code","78317fb1":"code","307865ba":"code","a18de6c2":"code","567199f1":"code","4ef0e56e":"code","780a4496":"code","dd8e8c47":"code","87081da1":"code","2ea9c572":"code","31c835b4":"code","263ec3dc":"code","134d7d9e":"code","e45abdd6":"code","e15b254d":"code","a03a9113":"code","7c229a0c":"code","72607c11":"markdown","e3d36d7f":"markdown","08c9bb98":"markdown","79a0776d":"markdown","4866e124":"markdown","20e4e7c3":"markdown"},"source":{"f53dcbd1":"!pip install imageai","78317fb1":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport shutil\nfrom pathlib import Path\n\nfrom imageai.Detection import ObjectDetection\nfrom imageai.Detection.Custom import DetectionModelTrainer\nfrom imageai.Detection.Custom import CustomObjectDetection\n\nfrom PIL import Image\n\nimport albumentations as A\nimport cv2\n\nimport xml.etree.ElementTree as ET","307865ba":"train_path = '..\/input\/fruit-images-for-object-detection\/train_zip\/train\/'\ntest_path = '..\/input\/fruit-images-for-object-detection\/test_zip\/test\/'\n\nannots_train_path = sorted([i for i in Path(train_path).glob('*.xml')])\nimages_train_path = sorted([i for i in Path(train_path).glob('*.jpg')])\n\nannots_test_path = sorted([i for i in Path(test_path).glob('*.xml')])\nimages_test_path = sorted([i for i in Path(test_path).glob('*.xml')])\n\nn_imgs = len(images_train_path)\nprint(f'train - {n_imgs}, test -{len(images_test_path)}')","a18de6c2":"Image.open('..\/input\/fruit-images-for-object-detection\/train_zip\/train\/apple_31.jpg')","567199f1":"with open(annots_train_path[24], 'r') as f:\n    print(f.read())","4ef0e56e":"#\u0424\u0443\u043d\u043a\u0446\u0438\u044f  \u0438\u0441\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u044f \u043d\u0443\u043b\u0435\u0432\u044b\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 width \u0438 height \u0432 \u0430\u043d\u043d\u043e\u0442\u0430\u0446\u0438\u044f\u0445\ndef editXML(file):\n    \n    my_file = open(file, 'r')\n    string = my_file.read()\n    \n    width = string[string.find('<width>')+len('<width>') : string.find('<\/width>')]\n    height = string[string.find('<height>')+len('<height>') : string.find('<\/height>')]\n    \n    if width == '0' or height == '0':\n        \n        folder = string[string.find('<folder>')+len('<folder>') : string.find('<\/folder>')]\n        filename = string[string.find('<filename>')+len('<filename>') : string.find('<\/filename>')]\n        path_img = f'..\/input\/fruit-images-for-object-detection\/{folder}_zip\/{folder}\/{filename}'\n        \n        im = Image.open(path_img)\n        (width_im, height_im) = im.size\n\n        tree = ET.parse(file)\n        root = tree.getroot()\n\n        for elem in root.iter(\"width\"):\n            elem.text = str(width_im)\n\n        for elem in root.iter(\"height\"):\n            elem.text = str(height_im)\n\n        tree.write('newfile.xml')\n\n        return 'newfile.xml'\n    \n    else:\n        return file","780a4496":"# \u0424\u0443\u043d\u043a\u0446\u0438\u044f \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0438 \u0430\u043d\u043d\u043e\u0442\u0430\u0446\u0438\u0439\ndef augmentation_image_and_XML(file):\n\n    my_file = open(file, 'r')\n    string = my_file.read()\n\n    path_image = file.replace('annotations', 'images')\n    image = cv2.imread(path_image[:-3]+'jpg')\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n    bboxes = []\n    class_labels = []\n    \n    for item in string.split('<\/object>'):\n        if '<object>' in item:\n            bboxes.append([int(item[item.find('<xmin>')+len('<xmin>') : item.find('<\/xmin>')]),\n                           int(item[item.find('<ymin>')+len('<ymin>') : item.find('<\/ymin>')]),\n                           int(item[item.find('<xmax>')+len('<xmax>') : item.find('<\/xmax>')]),\n                           int(item[item.find('<ymax>')+len('<ymax>') : item.find('<\/ymax>')])])\n            class_labels.append(item[item.find('<name>')+len('<name>') : item.find('<\/name>')])\n\n    transform = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.2),\n    A.RandomBrightnessContrast(p=0.2),\n    A.ChannelDropout(channel_drop_range=(1, 1), fill_value=0, p=0.1),\n    ], bbox_params=A.BboxParams(format='pascal_voc', min_area=1024, min_visibility=0.1, label_fields=['class_labels']))\n    \n    for i in range(1, 5):\n        transformed = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n        transformed_image = transformed['image']\n        transformed_bboxes = transformed['bboxes']\n        transformed_class_labels = transformed['class_labels']\n\n        # \u0441\u043e\u0445\u0440\u0430\u043d\u0438\u0442\u044c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435\n        Image.fromarray(transformed_image).save(f'{path_image[:-4]}-{i}.jpg',quality=95)\n        \n        # \u0441\u043e\u0445\u0440\u0430\u043d\u0438\u0442\u044c \u0430\u043d\u043d\u043e\u0442\u0430\u0446\u0438\u044e \n        folder = string[string.find('<folder>')+len('<folder>') : string.find('<\/folder>')]\n        filename = string[string.find('<filename>')+len('<filename>') : string.find('<\/filename>')]\n        width = string[string.find('<width>')+len('<width>') : string.find('<\/width>')]\n        height = string[string.find('<height>')+len('<height>') : string.find('<\/height>')]\n        \n        annotation = ET.Element(\"annotation\")\n        ET.SubElement(annotation, \"folder\").text = folder\n        ET.SubElement(annotation, \"filename\").text = str(f'{filename[:-4]}-{i}.jpg')\n        ET.SubElement(annotation, \"path\").text = str(f'{path_image[:-4]}-{i}.jpg')\n        source = ET.SubElement(annotation, \"source\")\n        ET.SubElement(source, \"database\").text = \"Unknown\"\n        size = ET.SubElement(annotation, \"size\")\n        ET.SubElement(size, \"width\").text = str(width)\n        ET.SubElement(size, \"height\").text = str(height)\n        ET.SubElement(size, \"depth\").text = \"3\"\n        ET.SubElement(annotation, \"segmented\").text = \"0\"\n        for num, box in enumerate(transformed_bboxes):\n            object = ET.SubElement(annotation, \"object\")\n            ET.SubElement(object, \"name\").text = transformed_class_labels[num]\n            ET.SubElement(object, \"pose\").text = \"Unspecified\"\n            ET.SubElement(object, \"truncated\").text = \"0\"\n            ET.SubElement(object, \"difficult\").text = \"0\"\n            bndbox = ET.SubElement(object, \"bndbox\")\n            ET.SubElement(bndbox, \"xmin\").text = str(int(box[0])) \n            ET.SubElement(bndbox, \"ymin\").text = str(int(box[1]))\n            ET.SubElement(bndbox, \"xmax\").text = str(int(box[2]))\n            ET.SubElement(bndbox, \"ymax\").text = str(int(box[3]))\n\n        tree = ET.ElementTree(annotation)\n        tree.write(f'{file[:-4]}-{i}.xml')","dd8e8c47":"# \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u0439 \u0434\u043b\u044f \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435 \u043f\u0440\u0435\u0434\u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0430\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\nos.makedirs('imageai\/data\/train\/images', exist_ok=True)\nos.makedirs('imageai\/data\/train\/annotations', exist_ok=True)\n\nos.makedirs('imageai\/data\/validation\/images', exist_ok=True)\nos.makedirs('imageai\/data\/validation\/annotations', exist_ok=True)\n\nos.makedirs('imageai\/data\/test\/images', exist_ok=True)\nos.makedirs('imageai\/data\/test\/annotations', exist_ok=True)","87081da1":"# \u0444\u043e\u0440\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0441\u043f\u0438\u0441\u043a\u0430 \u043a\u043b\u0430\u0441\u0441\u043e\u0432\nset_classes = set()\nannots_path = annots_train_path + annots_test_path\n\nfor annot in annots_path:\n    with open(annot, 'r') as f:\n        string = f.read()\n        name = string[string.find('<name>')+6:string.find('<\/name>')]\n        set_classes.add(name)\n\nclasses = np.array(list(set_classes))\nprint(classes)","2ea9c572":"# \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0435 \u0438 \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435 \u043f\u0440\u0435\u0434\u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0430\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\nfor i, (annot_path, img_path) in enumerate(zip(annots_train_path, images_train_path)):   \n    if i > n_imgs:\n        break\n        \n    if i%5 == 0:\n        new_path = shutil.copy(img_path, 'imageai\/data\/validation\/images\/' + img_path.parts[-1])\n        # \u0440\u0435\u0434\u0430\u043a\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\n        annot_path_edit = editXML(annot_path)\n        annot_path_new = shutil.copy(annot_path_edit, 'imageai\/data\/validation\/annotations\/' + annot_path.parts[-1])\n        # \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\n        augmentation_image_and_XML(annot_path_new)\n    else:\n        shutil.copy(img_path, 'imageai\/data\/train\/images\/' + img_path.parts[-1])\n        # \u0440\u0435\u0434\u0430\u043a\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\n        annot_path_edit = editXML(annot_path)\n        annot_path_new = shutil.copy(annot_path_edit, 'imageai\/data\/train\/annotations\/' + annot_path.parts[-1])\n        # \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\n        augmentation_image_and_XML(annot_path_new)\n        \nfor i, (annot_test_path, img_test_path) in enumerate(zip(annots_test_path, images_test_path)):  \n    shutil.copy(img_test_path, 'imageai\/data\/test\/images\/' + img_test_path.parts[-1])\n    annot_test_path_new = editXML(annot_test_path)\n    shutil.copy(annot_test_path_new, 'imageai\/data\/test\/annotations\/' + annot_test_path.parts[-1])","31c835b4":"print(len(list(Path('imageai\/data\/train\/annotations\/').glob('*.xml'))))\nprint(len(list(Path('imageai\/data\/validation\/annotations\/').glob('*.xml'))))\nprint(len(list(Path('imageai\/data\/test\/annotations\/').glob('*.xml'))))","263ec3dc":"# \u0434\u0435\u0442\u0435\u043a\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u043e\u0431\u044a\u0435\u043a\u0442\u0430 \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u043d\u043e\u0439 YOLOv3 \u043c\u043e\u0434\u0435\u043b\u044c\u044e\ndetector = ObjectDetection()\ndetector.setModelTypeAsRetinaNet()\ndetector.setModelPath(\"..\/input\/gb-retinanet\/resnet50_coco_best_v2.1.0.h5\")\ndetector.loadModel()\ndetections = detector.detectObjectsFromImage(input_image='..\/input\/fruit-images-for-object-detection\/train_zip\/train\/apple_31.jpg',\n                                             output_image_path='detected.jpg',\n                                             minimum_percentage_probability=50)\n\nfor eachObject in detections:\n    print(eachObject[\"name\"] , \" : \", eachObject[\"percentage_probability\"], \" : \", eachObject[\"box_points\"] )\n    print(\"--------------------------------\")","134d7d9e":"Image.open('detected.jpg')","e45abdd6":"# \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u0441\u0432\u043e\u0435\u0439 \u043c\u043e\u0434\u0435\u043b\u0438\ntrainer = DetectionModelTrainer()\ntrainer.setModelTypeAsYOLOv3()\ntrainer.setDataDirectory(data_directory=\".\/imageai\/data\")\ntrainer.setTrainConfig(object_names_array=classes,\n                       batch_size=15,\n                       num_experiments=15,\n                       train_from_pretrained_model=\"..\/input\/gb-pretrainedyolov3h5\/pretrained-yolov3.h5\")\n\ntrainer.trainModel()","e15b254d":"files = sorted(os.listdir('imageai\/data\/models\/'))[-1]\n\ntrainer = DetectionModelTrainer()\ntrainer.setModelTypeAsYOLOv3()\ntrainer.setDataDirectory(data_directory=\".\/imageai\/data\/\")\nmetrics = trainer.evaluateModel(model_path=f\"imageai\/data\/models\/{files}\",\n                                json_path=\"imageai\/data\/json\/detection_config.json\",\n                                iou_threshold=0.2,\n                                object_threshold=0.3,\n                                nms_threshold=0.5)","a03a9113":"# \u0434\u0435\u0442\u0435\u043a\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u043e\u0431\u044a\u0435\u043a\u0442\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u043e\u0439 \u0441\u0432\u043e\u0435\u0439 \u043c\u043e\u0434\u0435\u043b\u044c\u044e\ndetector = CustomObjectDetection()\ndetector.setModelTypeAsYOLOv3()\ndetector.setModelPath(f\"imageai\/data\/models\/{files}\")\ndetector.setJsonPath(\"imageai\/data\/json\/detection_config.json\")\ndetector.loadModel()\ndetections = detector.detectObjectsFromImage(minimum_percentage_probability=50,\n                                             input_image=\"..\/input\/fruit-images-for-object-detection\/train_zip\/train\/apple_31.jpg\",\n                                             output_image_path=\"detected1.jpg\")\nfor detection in detections:\n    print(detection[\"name\"], \" : \", detection[\"percentage_probability\"], \" : \", detection[\"box_points\"])","7c229a0c":"Image.open('detected1.jpg')","72607c11":"# 1. \u0417\u043d\u0430\u043a\u043e\u043c\u0441\u0442\u0432\u043e \u0441 \u0434\u0430\u043d\u043d\u044b\u043c\u0438 <a class='anchor' id=1>","e3d36d7f":"# 4. \u0412\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438 <a class='anchor' id=4>","08c9bb98":"# 2. \u041f\u0440\u0435\u0434\u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 <a class='anchor' id=2>","79a0776d":"# 5. \u0412\u044b\u0432\u043e\u0434\u044b \u043f\u043e \u043f\u0440\u043e\u0435\u043a\u0442\u0443 <a class='anchor' id=5>\n    \n  \u0414\u043b\u044f \u0431\u043e\u043b\u0435\u0435 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0434\u0435\u0442\u0435\u043a\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u043d\u0430 \u0438\u043c\u0435\u044e\u0449\u0438\u0445\u0441\u044f \u0434\u0430\u043d\u043d\u044b\u0445 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e:  \n    - \u0443\u0432\u0435\u043b\u0438\u0447\u0438\u0442\u044c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u043d\u0430 \u043a\u0430\u0436\u0434\u044b\u0439 \u043e\u0431\u044a\u0435\u043a\u0442  \n    - \u0443\u0432\u0435\u043b\u0438\u0447\u0438\u0442\u044c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u044d\u043f\u043e\u0445 \u043f\u0440\u0438 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0438 \u043c\u043e\u0434\u0435\u043b\u0438","4866e124":"# \u041a\u0443\u0440\u0441\u043e\u0432\u043e\u0439 \u043f\u0440\u043e\u0435\u043a\u0442 \u043a\u0443\u0440\u0441\u0430 \"\u0412\u0432\u0435\u0434\u0435\u043d\u0438\u0435 \u0432 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u044b\u0435 \u0441\u0435\u0442\u0438\"\n\n**\u0417\u0430\u0434\u0430\u0447\u0430:** \n\n\u0422\u0440\u0435\u0431\u0443\u0435\u0442\u0441\u044f, \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0430\u043d\u0438\u0438 \u0438\u043c\u0435\u044e\u0449\u0438\u0445\u0441\u044f \u0434\u0430\u043d\u043d\u044b\u0445, \u043f\u0440\u043e\u0438\u0437\u0432\u0435\u0441\u0442\u0438 \u0434\u0435\u0442\u0435\u043a\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432.\n\n**\u041e\u043f\u0438\u0441\u0430\u043d\u0438\u0435 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a\u043e\u0432 \u0434\u0430\u043d\u043d\u044b\u0445:**  \nhttps:\/\/www.kaggle.com\/mbkinaci\/fruit-images-for-object-detection\n\ntrain_zip - \u0434\u0430\u043d\u043d\u044b\u0435 \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438: \u0441\u043e\u0441\u0442\u043e\u044f\u0442 \u0438\u0437 240 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0438 \u043e\u043f\u0438\u0441\u0430\u043d\u0438\u044f\u043c \u043a \u043d\u0438\u043c   \ntest_zip - \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435: \u0441\u043e\u0441\u0442\u043e\u044f\u0442 \u0438\u0437 60 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0438 \u043e\u043f\u0438\u0441\u0430\u043d\u0438\u044f\u043c \u043a \u043d\u0438\u043c\n\n**\u041f\u043b\u0430\u043d \u043f\u0440\u043e\u0435\u043a\u0442\u0430**\n- [1. \u0417\u043d\u0430\u043a\u043e\u043c\u0441\u0442\u0432\u043e \u0441 \u0434\u0430\u043d\u043d\u044b\u043c\u0438](#1)\n- [2. \u041f\u0440\u0435\u0434\u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445](#2)\n- [3. \u042d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u044b \u0441 \u043c\u043e\u0434\u0435\u043b\u044f\u043c\u0438](#3)\n- [4. \u0412\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438](#4)\n- [5. \u0412\u044b\u0432\u043e\u0434\u044b \u043f\u043e \u043f\u0440\u043e\u0435\u043a\u0442\u0443](#5)","20e4e7c3":"# 3. \u042d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u044b \u0441 \u043c\u043e\u0434\u0435\u043b\u044f\u043c\u0438 <a class='anchor' id=3>"}}