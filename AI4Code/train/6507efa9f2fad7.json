{"cell_type":{"a8957023":"code","9a0fddc8":"code","2914b484":"code","ad58778e":"code","6161a43b":"code","fe67eb16":"code","4505c553":"code","9d571b10":"code","2018c60d":"markdown"},"source":{"a8957023":"!nvidia-smi","9a0fddc8":"!pip install optuna","2914b484":"import pandas as pd\nimport numpy as np\nimport xgboost as xgb\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom tqdm import tqdm\nimport optuna\nimport gc\nxgb.__version__","ad58778e":"train = pd.read_csv('..\/input\/song-popularity-prediction\/train.csv')\ntest = pd.read_csv('..\/input\/song-popularity-prediction\/test.csv')\ncolumns = [col for col in train.columns.to_list() if col not in ['id','song_popularity']]\ndata=train[columns]\ntarget=train['song_popularity']","6161a43b":"def objective(trial):\n  train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.15,random_state=42)\n  params = {\n        'objective': trial.suggest_categorical('objective',['multi:softprob']), \n        'num_class': trial.suggest_categorical('num_class',[2]), \n        'tree_method': trial.suggest_categorical('tree_method',['gpu_hist']),  # 'gpu_hist','hist'\n        'lambda': trial.suggest_loguniform('lambda',1e-3,10.0),\n        'alpha': trial.suggest_loguniform('alpha',1e-3,10.0),\n        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.3,1.0),\n        'subsample': trial.suggest_uniform('subsample', 0.4, 1.0),\n        'learning_rate': trial.suggest_loguniform('learning_rate', 0.001,0.1),\n        'max_depth': trial.suggest_categorical('max_depth', [3,5,7,9,11,13,15,17,20]),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1,300),\n        'eval_metric': trial.suggest_categorical('eval_metric',['mlogloss']),\n  }\n  model = xgb.XGBClassifier(**params)\n  model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=300,verbose=False)\n  preds = model.predict(test_x)\n  roc = accuracy_score(test_y, preds)\n  return roc","fe67eb16":"study = optuna.create_study(direction='maximize',study_name='song-pop_trials_200')\nstudy.optimize(objective, n_trials=200)","4505c553":"study.best_value","9d571b10":"study.best_params","2018c60d":"## Abstract\n\n\n\n### **Methods**\n\n> - **Data split**:  85\/15 split.\n\n> - **Models**: 1x XGB\n\n> - **Evaluation**:Best params can later be used for training with K-folds.\n\n> - **Metrics**: ROC auc is the primary metrics.\n\n> - **Best Params**:{'objective': 'multi:softprob',<br>\n 'num_class': 2,<br>\n 'tree_method': 'gpu_hist',<br>\n 'lambda': 0.49893366156692504,<br>\n 'alpha': 3.9821650252493717,<br>\n 'colsample_bytree': 0.8818299156888831,<br>\n 'subsample': 0.8887490789718422,<br>\n 'learning_rate': 0.05070583068266845,<br>\n 'max_depth': 17,<br>\n 'min_child_weight': 146,<br>\n 'eval_metric': 'mlogloss'} \n\n\n\n### **End**\n\n>A LGBM and catboost and can also be tuned in a similar way.\n\n\n"}}