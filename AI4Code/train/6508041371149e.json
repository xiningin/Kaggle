{"cell_type":{"7a1c262c":"code","b227d691":"code","6842ef69":"code","52441f47":"code","aceb7734":"code","c5a5d57d":"code","0eb3b2cd":"code","3831806f":"code","1eea2b27":"code","5d4daaa5":"code","166c394a":"code","c0d97dae":"code","d50319d5":"code","2912393c":"code","4bf83a10":"code","95977e31":"code","fd6f89bb":"code","8c76acd2":"code","3c1f712f":"code","76dd21c9":"code","2fac43ae":"code","9f474686":"code","439dfb50":"code","7b4c7f76":"code","7331310b":"code","5a4abbd4":"code","96c70968":"code","c0145ca6":"code","0545c1a7":"code","3e1d23ad":"markdown","5be03690":"markdown","bc6d4ee0":"markdown","4cee5d62":"markdown","84207132":"markdown","42914538":"markdown","7659f3c4":"markdown","a9f3ec27":"markdown","c0819a62":"markdown","e69a33a9":"markdown","21b28c17":"markdown","a2011595":"markdown"},"source":{"7a1c262c":"!pip install git+https:\/\/github.com\/goolig\/dsClass.git","b227d691":"from sklearn.metrics import roc_curve, auc # model performance metrics\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom dsClass.path_helper import *\n","6842ef69":"#print(os.listdir('..\/input'))","52441f47":"data_path = get_file_path('frd_sample.csv')\ndf = pd.read_csv(data_path, delimiter=',')\ndf.dataframeName = 'frd_sample.csv'\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')","aceb7734":"df.head(5)","c5a5d57d":"df.info()","0eb3b2cd":"# step1 - encode target variable\n\nd = {\"F\":1, \"G\":0}\ndf[\"IS_FRAUD\"].replace(d, inplace=True)\n\ndf.head()","3831806f":"# now lets see how bayes works on a simple example of USER_COUNTRY column\n\ndf_exp = df[[\"EVENT_ID\", \"USER_COUNTRY\",\"IS_FRAUD\"]]\n\ndf_exp.head()","1eea2b27":"df_exp_train = df_exp.query(\"EVENT_ID <= 2200\")\ndf_exp_train.tail()","5d4daaa5":"df_exp_test  = df_exp.query(\"EVENT_ID  > 2200\")\ndf_exp_test.tail()","166c394a":"tot_frd = df_exp_train.loc[(df_exp_train.IS_FRAUD == 1)].shape[0] # total fraud\ntot_gen = df_exp_train.shape[0] - tot_frd\n\nprint([tot_frd,tot_gen])","c0d97dae":"countries = df[\"USER_COUNTRY\"].unique()\nprint(countries)","d50319d5":"# for each country we calculate likelihood of a transaction being fraudulent\n\np_f_ctry = {}\n\nfor country in countries:\n    df_ctry = df_exp_train.loc[(df_exp_train.USER_COUNTRY == country)]\n    df_ctry_frd = df_ctry.loc[(df_ctry.IS_FRAUD == 1)]\n    \n    ctry_frd = df_ctry_frd.shape[0]\n    ctry_gen = df_ctry.shape[0] - ctry_frd\n    \n    if ctry_gen == 0:\n        p_f_ctry[country] = 0\n    else:\n        p_f_ctry[country] = 1000*np.log ( (ctry_frd\/tot_frd) \/ (ctry_gen\/tot_gen) )\n    \nprint(p_f_ctry)","2912393c":"y_score = df_exp_test[\"USER_COUNTRY\"]\ny_score.replace(p_f_ctry, inplace=True)\n\ny_score.head()","4bf83a10":"y_test = df_exp_test[\"IS_FRAUD\"]\n\ny_test.head()\n","95977e31":"# Compute ROC curve and ROC area\n    \nfpr, tpr, _ = roc_curve(y_test, y_score)\nroc_auc = auc(fpr, tpr)\n\nplt.figure()\nlw = 1\nplt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='-')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","fd6f89bb":"# add code here","8c76acd2":"# Let's generate more features:\n\n# 1. USER_COUNTRY\/PAYEE_COUNTRY\n\ndf_temp = df.copy()\n\ndf_temp[\"USER_CTRY_PAYEE_CTRY\"] = df_temp[\"USER_COUNTRY\"].str.cat(df_temp[\"PAYEE_COUNTRY\"], sep=';')\n\ndf_temp.head()","3c1f712f":"# 2. USER_HITS\n\nusers = df_temp[\"USER_ID\"].unique()\n\nevt_val_dict = {}\nfor user in users:\n    df_loop = df_temp.loc[(df_temp.USER_ID == user)]\n    \n    hits = 1\n    for index, row in df_loop.iterrows():\n        evt_val_dict[row['EVENT_ID']] = hits\n        hits = hits + 1\n    \ndf_temp[\"USER_HITS\"] = df_temp[\"EVENT_ID\"].apply(evt_val_dict.get)\ndf_temp.tail()","76dd21c9":"print(df_temp.query(\"USER_ID == 'user21'\"))","2fac43ae":"# add code here","9f474686":"print(df_temp.query(\"USER_PAYEE== 'user647;payee2'\"))","439dfb50":"features = [\"CHANNEL\",\"ISP\",\"USER_COUNTRY\",\"PAYEE_COUNTRY\",\"USER_CTRY_PAYEE_CTRY\",\"USER_HITS\",\"USER_PAYEE_HITS\",\"IS_FRAUD\",\"EVENT_ID\"]\n\ndf2 = df_temp[features]\ndf2.head()","7b4c7f76":"df_exp_train = df2.query(\"EVENT_ID <= 2200\")\ndf_exp_test  = df2.query(\"EVENT_ID  > 2200\")\n\nfor feature in features:\n    \n    if feature == \"IS_FRAUD\" or feature == \"EVENT_ID\":\n        continue\n    \n    \n    unique_values = df2[feature].unique()\n    d = {}\n    \n    for val in unique_values:\n        df_feat = df_exp_train.loc[(df_exp_train[feature] == val)]\n        df_feat_frd = df_feat.loc[(df_feat.IS_FRAUD == 1)]\n\n        feat_frd = df_feat_frd.shape[0]\n        feat_gen = df_feat.shape[0] - feat_frd\n        \n        if feat_gen == 0:\n            d[val] = 0\n        else:\n            d[val] = 1000*np.log ( (feat_frd\/tot_frd) \/ (feat_gen\/tot_gen) )\n    \n    df_exp_test[feature].replace(d, inplace=True)\n    df_exp_train[feature].replace(d, inplace=True)\n\ndf_exp_test.tail()","7331310b":"# add code here","5a4abbd4":"df_exp_train.info()","96c70968":"# now we aggregate the contribution of different features into a single fraud likelihood\n\ndf_exp_train[\"SCORE\"] = 0.0\ndf_exp_test [\"SCORE\"] = 0.0\n\nfor feature in features:\n    \n    if feature == \"IS_FRAUD\" or feature == \"EVENT_ID\":\n        continue\n    \n    df_exp_train[\"SCORE\"] = df_exp_train[\"SCORE\"] + df_exp_train[feature]\n    df_exp_test [\"SCORE\"] = df_exp_test [\"SCORE\"] + df_exp_test [feature]\n    \ndf_exp_test.head()","c0145ca6":"y = df_exp_train[\"IS_FRAUD\"]\ny_score = df_exp_train[\"SCORE\"]\n\n# Compute ROC curve and ROC area\n    \nfpr, tpr, _ = roc_curve(y, y_score)\nroc_auc = auc(fpr, tpr)\n\nplt.figure()\nlw = 1\nplt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='-')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","0545c1a7":"# add code here","3e1d23ad":"--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n**Self-Assessment C**\n\nNote \"-inf\" values for some columns, why this is happening and how we can fix it?\n\n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------","5be03690":"There is 1 csv file in the current version of the dataset:\n","bc6d4ee0":"Q2","4cee5d62":"Q3","84207132":"Let's take a quick look at what the data looks like:","42914538":"--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n**Self-Assessment D**\n* Is NB classifier suggested above is a black-box or a white-box model. \n* Suggest and implement a method for feature importance calculation based on df_exp_train data. Plot the importance and discuss the results\n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------","7659f3c4":"--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n**Self-Assessment B**\n* Using both techniques shown above calculate USER_PAYEE_HITS - number of hits from USER_ID\/PAYEE_ID combination\n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------","a9f3ec27":"Q1","c0819a62":"Q4","e69a33a9":"Let's do some preprocessing:","21b28c17":"### Let's check 1st file: ..\/input\/frd_sample.csv","a2011595":"**Self-Assessment A**\n* Calculate a similar ROC\/AUC performance metric on training data and compare it with the above. Would you expect the AUC results to be better\/worse than for the testing set?"}}