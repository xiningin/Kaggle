{"cell_type":{"35a9f0ca":"code","3f44e0e2":"code","e0e90ca1":"code","75de0a62":"code","e00861cc":"code","6fe3ea97":"code","eb3b6b59":"code","9bc550ff":"code","722a026a":"code","bd8976f6":"code","084b944e":"code","6a168b69":"code","b929a530":"code","e681c142":"code","5346cda0":"code","f35e329d":"code","27dc5ffa":"code","2e67d08a":"code","8157d754":"code","f56b0881":"markdown","1429959e":"markdown","156c4ca3":"markdown","54690ace":"markdown","bf71d96c":"markdown","3891d24a":"markdown","342b6073":"markdown","b1739c6c":"markdown","3cae4afd":"markdown","990a24f0":"markdown","e79632a5":"markdown","8e2c8b66":"markdown","a6e5792d":"markdown","c433d56d":"markdown","700b7569":"markdown","636a7b7b":"markdown","48b566a1":"markdown","69892512":"markdown","ce3ef364":"markdown","4190e475":"markdown","2d629103":"markdown"},"source":{"35a9f0ca":"from PIL import ImageTk, Image  \nimage1 = Image.open(\"..\/input\/fashionnn\/Untitled11.png\")\nimage1","3f44e0e2":"# Part 1 :- Importing Keras library and its modules\n\nimport tensorflow as tf #  Importing tensorflow package as tf\nimport keras # Importing the keras library to build neural network\nimport numpy as np # Importing python library numpy,which is used for working with arrrays within the file\nimport pandas as pd # Import panadas as pd\nfrom tensorflow.keras.models import Sequential # Used for importing the sequential model of ANN\nfrom tensorflow.keras.optimizers import SGD # Importing Stochastic Gradient Descent\nfrom tensorflow.keras.layers import Activation,Dense # Importing distinct layers of ANN\nimport matplotlib.pyplot as plt\nimport warnings # Importing Warnings\nfrom sklearn.model_selection import train_test_split # Importing the train_test_split function to split the data into test, train and validation sets\nwarnings.filterwarnings('ignore') # Importing warnings as 'ignore' to avoid warnings\n","e0e90ca1":"# Part 2 :- Import the test and train sets of fashion mnist\ntrain_set = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')\ntest_set = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv')","75de0a62":"# Part 3 :- Split the images and labels sets from test and train data of fashion mnist\ntrain_images=train_set.drop(['label'],axis=1)\ntrain_label=train_set['label']\n\ntest_images=test_set.drop(['label'],axis=1)\ntest_label=test_set['label']","e00861cc":"labels={0:\"T-shirt\/top\",1:\"Trouser\",2:\"Pullover\",3:\"Dress\",4:\"Coat\",5:\"Sandal\",6:\"Shirt\",\n          7:\"Sneaker\",8:\"Bag\",9:\"Ankle boot\"}","6fe3ea97":"# Part 4 :- Spliting the dataset into train, test and validation sets\n# We are using the first 10,000 samples of our training data as our validation set\nval_data = train_images[:10000]\nval_labels = train_label[:10000]\n\n# Using the remainder of the original training data for actual training\npartial_train_data = train_images[10000:]\npartial_train_labels = train_label[10000:]","eb3b6b59":"# Part 5 :- Converting the image values to float\npartial_train_data = partial_train_data.astype('float32')# Parse numbers as floats in train set\ntest_data = test_images.astype('float32')# Parse numbers as floats in test set\nval_data= val_data.astype('float32')# Parse numbers as floats in validation set\n\n\n# Part 6 :- Performing Normalization of data by scaling\npartial_train_data = partial_train_data \/ 255 # Scale the pixel values of train data so they lie in the range of 0-1\nval_data = val_data \/ 255 # Scale the pixel values of validation data so they lie in the range of 0-1\ntest_data = test_images \/255 # Scale the pixel values of test data so they lie in the range of 0-1\nprint(\"Train set : \",partial_train_data.shape) # to print shape of train set\nprint(\"Test set : \" ,test_data.shape) # to print shape of test set\nprint(\"Validation set : \",val_data.shape) # to print shape of validation set\n\n# Part 7 :- Labels Encoded Categorically\nfrom tensorflow.keras.utils import to_categorical # to import to_categorical module, which helps one-hot encoding of labels\npartial_train_labels = to_categorical(partial_train_labels) # to do Categorical encoding of labels of train set\nval_labels = to_categorical(val_labels) # to do Categorical encoding of labels of validation set\ntest_labels = to_categorical(test_label) # to do Categorical encoding of labels of test set","9bc550ff":"print('Shape of images set in training data')\ntrain_images.shape","722a026a":"print('Shape of label set in training data')\ntrain_label.shape","bd8976f6":"print('Shape of images set in testing data')\ntest_images.shape","084b944e":"print('Shape of labels set in testing data')\ntest_label.shape","6a168b69":"import matplotlib.pyplot as plt\nplt.figure(figsize = (20,20))\nX = np.array(train_images)\nlenght=range(0,20)\nfor i in lenght:\n    plt.subplot(10,5,i+1)\n    plt.axis('off')\n    image = X[i].reshape(28,28)\n    plt.imshow(image, cmap='gist_yarg',interpolation=\"nearest\")\n    plt.title(labels[train_label[i]])\n","b929a530":"plt.figure(figsize = (20,20))\nX = np.array(test_images)\nlenght=range(0,20)\nfor i in lenght:\n    plt.subplot(10,5,i+1)\n    plt.axis('off')\n    image = X[i].reshape(28,28)\n    plt.imshow(image, cmap='gist_yarg',interpolation=\"nearest\")\n    plt.title(labels[test_label[i]])","e681c142":"# Part 8 :- Building the Neural Network Model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\nfrom tensorflow.keras.layers import Dense, Lambda # to import the dense and lambda layer from keras library\nfrom tensorflow.keras import initializers # to import initializers \nnetwork = Sequential() # it calls sequential function which helps in creating a linear stack of layers\nnetwork.add(Dense(132, activation='relu')) # each neuron uses \"relu\" as an activation function\nnetwork.add(Dense(60, activation='relu')) # each neuron uses \"relu\" as an activation function\nnetwork.add(Dense(60, activation='relu')) # each neuron uses \"relu\" as an activation function\nnetwork.add(Dense(60, activation='relu')) # each neuron uses \"relu\" as an activation function\nnetwork.add(Dense(60, activation='relu')) # each neuron uses \"relu\" as an activation function\nnetwork.add(Dense(60, activation='relu')) # an output neuron uses relu as an activation function\nnetwork.add(Dense(60, activation='relu')) # an output neuron uses relu as an activation function\nnetwork.add(Dense(60, activation='relu')) # an output neuron uses relu as an activation function\nnetwork.add(Dense(10, activation='softmax')) # each neuron uses \"softmax\" as an activation function\n# to create an executable program from the given code\nnetwork.compile(optimizer=\"Adam\",\n                loss=\"categorical_crossentropy\",\n                metrics=['accuracy'])\n# in order to train the neural network \nhistory = network.fit(partial_train_data, partial_train_labels, epochs=15, batch_size=128, validation_data=(val_data, val_labels),verbose=2)","5346cda0":"# Part 9 :- Calculating the accuracies of model on test data\ntest_loss, test_acc = network.evaluate(test_images, test_labels)\nprint(f\"Test accuracy : {test_acc:4.2f}\") ","f35e329d":"\n# Part 10 :- Plotting history of Training and Validation Loss per epoch\nfrom matplotlib import pyplot as plt\nplt.plot(history.history['val_loss'],color='#990000')\nplt.grid(b = True, color ='black', linestyle ='-', linewidth = 0.7, alpha = 1.0) # Adding x, y gridlines \nplt.title('Training and validation loss per epoch',fontsize=17,fontweight='bold') # For Title\nplt.ylabel('Loss value per epoch',fontsize=11) # Adding label on y-axis\nplt.xlabel('Number of epoch',fontsize=11) # Adding label on x-axis\nplt.show() # Used for visualizing the plot\n\nprint(\"******************************************************************************************************\")\n#  Part 11 :- Plotting history of Training and Validation Accuracy per epoch'\nplt.plot(history.history['val_accuracy'],color='#990000')\nplt.grid(b = True, color ='black', linestyle ='-', linewidth = 0.7, alpha = 1.0) # Adding x, y gridlines \nplt.title('Training and validation accuracy per epoch',fontsize=17,fontweight='bold')# For Title \nplt.ylabel('Accuracy value per epoch',fontsize=11) # Adding label on y-axis\nplt.xlabel('Number of epoch',fontsize=11) # Adding label on x-axis\nplt.show() # Used for visualizing the plot\n","27dc5ffa":"# predict classes\npredicted=network.predict_classes(test_images)\npredicted","2e67d08a":"# The classification report for the model:\nfrom sklearn.metrics import classification_report\nprint('-----CLASSIFICATION  REPORT IS------')\nprint(classification_report(test_label,predicted))         ","8157d754":"plt.figure(figsize = (20,20))\nX = np.array(test_images)\n\nfor i in range(0,50):\n    plt.subplot(10,5,i+1)\n    plt.axis('off')\n    image = X[i].reshape(28,28)\n    plt.imshow(image, cmap='gist_yarg',interpolation=\"nearest\")\n    plt.title(\"Predicted: {}, Actual: {}\".format(labels[predicted[i]],labels[test_label[i]]))","f56b0881":"## **a) Split test and train data into images and labels sets**","1429959e":"# ****Fashion MNIST Analysis****","156c4ca3":"## **b) Create a dictionary to name a class labels**","54690ace":"# ***Exploratory Data Analysis***","bf71d96c":"## **b) Evaluate the model**","3891d24a":"## **b) Import Fashion MNIST dataset**","342b6073":"## **c) Plot test images**","b1739c6c":"### **ii) Classification Report of the model**","3cae4afd":"# ***Create an Artificial Neural Network model***","990a24f0":"**Self created image using 3D paint**","e79632a5":"## **b) Plot the train images**","8e2c8b66":"## **d) Performing Data Normalization and categorically encoding the labels**","a6e5792d":"## **a) Build model**","c433d56d":"### **i)Plot the losses and accuracies per epoch**","700b7569":"## **c) Split the dataset into train, test and validation sets**","636a7b7b":"### **iii) Visualize the predicted classes**","48b566a1":"## **a) Import Keras Libraries**","69892512":"# ***Importing***","ce3ef364":"### `Analysis`-:  We got an accuracy of 91.10% on validation set and 85%accuracy on test data. Moreover, In \"Training and validation loss per epoch\" plot we can see that as the number of epochs increase, on average,validation loss decreases. However,with the \"Training and validation accuracy per epoch\" graph, we can analyze that value of accuracy is increasing continuously.","4190e475":"## **a) Print shapes of different sets**","2d629103":"# ***Data Pre-Processing***"}}