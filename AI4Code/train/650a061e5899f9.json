{"cell_type":{"11b8cb2c":"code","37edbc54":"code","7f22a077":"code","dc05db0b":"code","6077b782":"code","181685da":"code","cfe673d9":"code","4ed55e58":"code","92c13ce2":"code","c6dbc349":"code","69e9fba9":"code","624cbd78":"code","b067b589":"code","bb6eac39":"code","ff298a11":"code","36916a74":"code","283f122e":"code","ca3df3f2":"code","cb15564b":"code","97e1b358":"code","c36f4626":"code","e7eb427c":"code","e0f49090":"code","b4d14ee3":"code","f819814f":"code","751b43d2":"code","0918962c":"code","98785f57":"code","7b144632":"code","57ee2f78":"code","668f9c17":"code","b4660389":"code","bbfcefe3":"code","5478c29b":"code","f14a653b":"code","a6446c9d":"code","6e061fb0":"code","975e0251":"code","c14a0591":"code","f3194cb8":"code","8e58f467":"code","62c89ffa":"code","e349eca4":"code","9c1bad97":"code","f519392f":"code","9a99b3e0":"code","911d1b24":"code","18726ca8":"code","37139671":"code","ea853992":"code","c61f30aa":"code","528c3c2e":"code","f206552c":"code","dbd80ed7":"code","f38fef70":"code","ce659219":"code","9a63d3bf":"code","0a56ceb2":"code","3629dba7":"code","b19d8215":"code","b89bd70d":"code","6d6a681d":"code","f0825cc4":"code","19757162":"code","ec4216c1":"code","b251b6c9":"code","765f6bc1":"code","b3c690ff":"code","54e8ea44":"code","04183019":"code","6028a1f1":"code","eaddaa26":"code","a49e9dd7":"markdown","138999a7":"markdown","d92a9670":"markdown","fdc3cb01":"markdown","55107ea7":"markdown","b56ab2f7":"markdown","b3d60bbe":"markdown","76b1fcb9":"markdown","f1afd0f5":"markdown","ad0ca449":"markdown","352643dd":"markdown","4f77031f":"markdown","ff6084fd":"markdown","9d2164c4":"markdown","ae488fdd":"markdown"},"source":{"11b8cb2c":"# \u043f\u0440\u043e\u0432\u0435\u0440\u044f\u0435\u043c, \u0447\u0442\u043e \u0432\u0438\u0434\u0435\u043e\u043a\u0430\u0440\u0442\u0430 \u043f\u043e\u0434\u043a\u043b\u044e\u0447\u0435\u043d\u0430\n!nvidia-smi","37edbc54":"# \u041e\u0431\u043d\u043e\u0432\u043b\u0435\u043d\u0438\u0435 tensorflow\n#!pip install tensorflow --upgrade\n# \u0417\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u043e\u0431\u0432\u044f\u0437\u043a\u0443 \u043f\u043e\u0434 keras \u0434\u043b\u044f \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u043f\u0440\u043e\u0434\u0432\u0438\u043d\u0443\u0442\u044b\u0445 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438\n!pip install git+https:\/\/github.com\/mjkvaak\/ImageDataAugmentor","7f22a077":"# \u0438\u043c\u043f\u043e\u0440\u0442 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport zipfile\nimport csv\nimport sys\nimport os\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Model\n\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras.layers import *\n    \n# \u0441\u043b\u043e\u0438, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043d\u0430\u043c \u043f\u0440\u0438\u0433\u043e\u0434\u044f\u0442\u0441\u044f\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n\nimport PIL\nfrom PIL import ImageOps, ImageFilter\n#\u0443\u0432\u0435\u043b\u0438\u0447\u0438\u043c \u0434\u0435\u0444\u043e\u043b\u0442\u043d\u044b\u0439 \u0440\u0430\u0437\u043c\u0435\u0440 \u0433\u0440\u0430\u0444\u0438\u043a\u043e\u0432\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5\n#\u0433\u0440\u0430\u0444\u0438\u043a\u0438 \u0432 svg \u0432\u044b\u0433\u043b\u044f\u0434\u044f\u0442 \u0431\u043e\u043b\u0435\u0435 \u0447\u0435\u0442\u043a\u0438\u043c\u0438\n%config InlineBackend.figure_format = 'svg' \n%matplotlib inline\n\n# \u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0432\u0445\u043e\u0434\u043d\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 \u0438 \u0432\u0435\u0440\u0441\u0438\u0438 \nprint(os.listdir(\"..\/input\"))\nprint('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)\nprint('Tensorflow   :', tf.__version__)\nprint('Keras        :', tf.keras.__version__)","dc05db0b":"# \u0412 setup \u0432\u044b\u043d\u043e\u0441\u0438\u043c \u043e\u0441\u043d\u043e\u0432\u043d\u044b\u0435 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0438: \u0442\u0430\u043a \u0443\u0434\u043e\u0431\u043d\u0435\u0435 \u0438\u0445 \u043f\u0435\u0440\u0435\u0431\u0438\u0440\u0430\u0442\u044c \u0432 \u0434\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0435\u043c.\n\nRANDOM_SEED          = 42\nnp.random.seed(RANDOM_SEED)  \nPYTHONHASHSEED = 0\n\nEPOCHS               = 8  # \u044d\u043f\u043e\u0445 \u043d\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435\nBATCH_SIZE           = 32 # \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0435\u043c batch \u0435\u0441\u043b\u0438 \u0441\u0435\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u0430\u044f, \u0438\u043d\u0430\u0447\u0435 \u043d\u0435 \u043f\u043e\u043c\u0435\u0441\u0442\u0438\u0442\u0441\u044f \u0432 \u043f\u0430\u043c\u044f\u0442\u044c \u043d\u0430 GPU\nLR                   = 1e-3\nVAL_SPLIT            = 0.2 # \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0434\u0430\u043d\u043d\u044b\u0445 \u0432\u044b\u0434\u0435\u043b\u044f\u0435\u043c \u043d\u0430 \u0442\u0435\u0441\u0442 = 15%\n\nCLASS_NUM            = 10  # \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0432 \u043d\u0430\u0448\u0435\u0439 \u0437\u0430\u0434\u0430\u0447\u0435\nIMG_SIZE             = 224 # \u043a\u0430\u043a\u043e\u0433\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0430 \u043f\u043e\u0434\u0430\u0435\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0432 \u0441\u0435\u0442\u044c\nIMG_CHANNELS         = 3   # \u0443 RGB 3 \u043a\u0430\u043d\u0430\u043b\u0430\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\nDATA_PATH = '..\/input\/sf-dl-car-classification\/'\nPATH = \"..\/working\/car\/\" # \u0440\u0430\u0431\u043e\u0447\u0430\u044f \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u044f","6077b782":"train_df = pd.read_csv(DATA_PATH+\"train.csv\")\nsample_submission = pd.read_csv(DATA_PATH+\"sample-submission.csv\")\ntrain_df.head()","181685da":"# \u043f\u0435\u0440\u0432\u0438\u0447\u043d\u044b\u0439 \u043f\u0440\u043e\u0441\u043c\u043e\u0442\u0440 \u0441\u043e\u0441\u0442\u043e\u044f\u043d\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445\ntrain_df.info()","cfe673d9":"sample_submission.info()","4ed55e58":"# \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0439\ntrain_df['Category'].nunique()","92c13ce2":"# \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445\ntrain_df.Category.hist()","c6dbc349":"print('\u0420\u0430\u0441\u043f\u0430\u043a\u043e\u0432\u044b\u0432\u0430\u0435\u043c \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438')\nfor data_zip in ['train.zip', 'test.zip']:\n    with zipfile.ZipFile(DATA_PATH+data_zip,\"r\") as z:\n        z.extractall(PATH)\n        \nprint(os.listdir(PATH))","69e9fba9":"# \u0440\u0430\u0441\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043f\u0440\u0438\u043c\u0435\u0440\u044b \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0434\u043b\u044f \u043e\u0446\u0435\u043d\u043a\u0438 \u0438\u0445 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u0438 \u0440\u0430\u0437\u043c\u0435\u0440\u043e\u0432\nprint('\u041f\u0440\u0438\u043c\u0435\u0440 \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a (random sample)')\nplt.figure(figsize=(12,8))\n\nrandom_image = train_df.sample(n=9)\nrandom_image_paths = random_image['Id'].values\nrandom_image_cat = random_image['Category'].values\n\nfor index, path in enumerate(random_image_paths):\n    im = PIL.Image.open(PATH+f'train\/{random_image_cat[index]}\/{path}')\n    plt.subplot(3,3, index+1)\n    plt.imshow(im)\n    plt.title('Class: '+str(random_image_cat[index]))\n    plt.axis('off')\nplt.show()","624cbd78":"image = PIL.Image.open(PATH+'\/train\/5\/211385.jpg')\nimgplot = plt.imshow(image)\nplt.show()\nimage.size","b067b589":"from ImageDataAugmentor.image_data_augmentor import *\nimport albumentations","bb6eac39":"AUGMENTATIONS = albumentations.Compose([\n    albumentations.HorizontalFlip(p=0.5),\n    albumentations.Rotate(limit=30, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.5),\n    albumentations.OneOf([\n        albumentations.CenterCrop(height=224, width=200),\n        albumentations.CenterCrop(height=200, width=224),\n    ],p=0.5),\n    albumentations.OneOf([\n        albumentations.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n        albumentations.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n    ],p=0.5),\n    albumentations.GaussianBlur(p=0.05),\n    albumentations.HueSaturationValue(p=0.5),\n    albumentations.RGBShift(p=0.5),\n    albumentations.FancyPCA(alpha=0.1, always_apply=False, p=0.5),\n    albumentations.Resize(IMG_SIZE, IMG_SIZE)\n])","ff298a11":"\ntrain_datagen = ImageDataAugmentor(\n        rescale=1\/255,\n        augment = AUGMENTATIONS,\n        validation_split=VAL_SPLIT,\n        )\n        \ntest_datagen = ImageDataAugmentor(rescale=1\/255)","36916a74":"# \u0417\u0430\u0432\u0435\u0440\u043d\u0435\u043c \u043d\u0430\u0448\u0438 \u0434\u0430\u043d\u043d\u044b\u0435 \u0432 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440:\n\ntrain_generator = train_datagen.flow_from_directory(\n    PATH+'train\/',      \n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') \n\ntest_generator = train_datagen.flow_from_directory(\n    PATH+'train\/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') ","283f122e":"# \u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b\ntrain_generator.show_data(rows=3, cols=5)","ca3df3f2":"# \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u043c\u043e\u0434\u0435\u043b\u0438 efficientnet\n!pip install -q efficientnet","cb15564b":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport zipfile\nimport csv\nimport sys\nimport os\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Model\nimport efficientnet.tfkeras as efn\n\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras.layers import *\n    \n# \u0441\u043b\u043e\u0438, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043d\u0430\u043c \u043f\u0440\u0438\u0433\u043e\u0434\u044f\u0442\u0441\u044f\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold","97e1b358":"# \u0437\u0430\u0433\u0440\u0443\u0437\u0438\u043c \u0431\u0430\u0437\u043e\u0432\u0443\u044e \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u043d\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c\n#from tensorflow.keras.applications import EfficientNetB7","c36f4626":"# \u0432 \u0445\u043e\u0434\u0435 \u043f\u043e\u0434\u0431\u043e\u0440\u0430 \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u043e\u0432 \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u043d\u044b\u0445 \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \u043e\u0441\u0442\u0430\u043d\u043e\u0432\u0438\u043b\u0438\u0441\u044c \u043d\u0430 EfficientNetB...\n# \u043d\u0438\u0436\u0435 \u043f\u0440\u0438\u0432\u0435\u0434\u0435\u043d\u043d\u044b\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 \u043c\u0435\u043d\u0435\u0435 \u044d\u0444\u0444\u0435\u043a\u0442\u0438\u0432\u043d\u044b\u0435\n#base_model = Xception(weights='imagenet', \n#                      include_top=False, \n#                      input_shape = input_shape)\n\n#base_model = InceptionV3(weights='imagenet', \n#                         include_top=False, \n#                         input_shape = input_shape)","e7eb427c":"base_model = efn.EfficientNetB7(\n    weights='imagenet', include_top=False, input_shape=input_shape)","e0f49090":"#base_model.summary()","b4d14ee3":"# \u0414\u043b\u044f \u043d\u0430\u0447\u0430\u043b\u0430 \u0437\u0430\u043c\u043e\u0440\u043e\u0437\u0438\u043c \u0432\u0435\u0441\u0430 EfficientNetB7 \u0438 \u043e\u0431\u0443\u0447\u0438\u043c \u0442\u043e\u043b\u044c\u043a\u043e \"\u0433\u043e\u043b\u043e\u0432\u0443\". \n# \u0414\u0435\u043b\u0430\u0435\u043c \u044d\u0442\u043e \u0434\u043b\u044f \u0442\u043e\u0433\u043e, \u0447\u0442\u043e\u0431\u044b \u0445\u043e\u0440\u043e\u0448\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u043d\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u043d\u0430 Imagenet \u043d\u0435 \u0437\u0430\u0442\u0438\u0440\u0430\u043b\u0438\u0441\u044c \u0432 \u0441\u0430\u043c\u043e\u043c \u043d\u0430\u0447\u0430\u043b\u0435 \u043d\u0430\u0448\u0435\u0433\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f\nbase_model.trainable = False","f819814f":"import tensorflow.keras.models as M\nimport tensorflow.keras.layers as Layer","751b43d2":"model=M.Sequential()\nmodel.add(base_model)\nmodel.add(Layer.GlobalAveragePooling2D())\nmodel.add(Layer.Dense(256, \n                      activation='relu'))\nmodel.add(Layer.BatchNormalization())\nmodel.add(Layer.Dropout(0.25))\nmodel.add(Layer.Dense(CLASS_NUM, activation='softmax'))","0918962c":"model.summary()","98785f57":"# \u043f\u0440\u043e\u0432\u0435\u0440\u0438\u043c \u0441\u0442\u0430\u0442\u0443\u0441 \u0441\u043b\u043e\u0435\u0432\nfor layer in model.layers:\n    print(layer, layer.trainable)","7b144632":"model.compile(loss=\"categorical_crossentropy\",\n              optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","57ee2f78":"# \u0434\u043e\u0431\u0430\u0432\u0438\u043c \u043a\u043e\u043b\u0431\u044d\u043a \u0434\u043b\u044f \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438 \u0441 \u043b\u0443\u0447\u0448\u0438\u043c\u0438 \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u044f\u043c\u0438\ncheckpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\nearlystop = EarlyStopping(monitor='accuracy', patience=5, restore_best_weights=True)\ncallbacks_list = [checkpoint, earlystop]","668f9c17":"# \u041e\u0431\u0443\u0447\u0430\u0435\u043c\n\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples\/\/train_generator.batch_size,\n    validation_data = test_generator, \n    validation_steps = test_generator.samples\/\/test_generator.batch_size,\n    epochs = EPOCHS,\n    callbacks = callbacks_list\n    )","b4660389":"scores = model.evaluate(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","bbfcefe3":"# \u0441\u043e\u0445\u0440\u0430\u043d\u0438\u043c \u0438\u0442\u043e\u0433\u043e\u0432\u0443\u044e \u0441\u0435\u0442\u044c\nmodel.save('..\/working\/model1.hdf5')\n#model.load_weights('best_model.hdf5')","5478c29b":"# \u0432\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c\ndef plot_history(history):\n    plt.figure(figsize=(10,5))\n    #plt.style.use('dark_background')\n    acc = history.history['accuracy'] \n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    epochs = range(len(acc))\n\n    plt.plot(epochs, acc, 'b', label='Training acc')\n    plt.plot(epochs, val_acc, 'g', label='Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n\n    #plt.figure()\n    plt.figure(figsize=(10,5))\n    #plt.style.use('dark_background')\n    plt.plot(epochs, loss, 'b', label='Training loss')\n    plt.plot(epochs, val_loss, 'g', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n\n    plt.show()\n\nplot_history(history)","f14a653b":"# \u043f\u0440\u043e\u0432\u0435\u0440\u0438\u043c \u043a\u043e\u043b\u0438\u0447\u0435c\u0442\u0432\u043e \u0441\u043b\u043e\u0435\u0432 \u0432 \u0431\u0430\u0437\u043e\u0432\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u0438\nprint(\"Number of layers in the base model: \", len(base_model.layers))","a6446c9d":"base_model.trainable = True\n\nfine_tune_at = len(base_model.layers)\/\/2\n\n# \u043e\u0441\u0442\u0430\u043b\u044c\u043d\u044b\u0435 \u0441\u043b\u043e\u0438 \u0442\u0430\u043a\u0436\u0435 \u043f\u043e\u043a\u0430 \u0437\u0430\u043c\u043e\u0440\u043e\u0437\u0438\u043c \nfor layer in base_model.layers[:fine_tune_at]:\n  layer.trainable =  False","6e061fb0":"# \u043f\u0440\u043e\u0432\u0435\u0440\u0438\u043c \u043f\u043e \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0443 \u0441\u043b\u043e\u0435\u0432 \nlen(base_model.trainable_variables)","975e0251":"# \u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0438 \u0441\u0442\u0430\u0442\u0443\u0441\nfor layer in model.layers:\n    print(layer, layer.trainable)","c14a0591":"BATCH_SIZE = 16 # \u0443\u043c\u0435\u043d\u044c\u0448\u0438\u043c \u044d\u0442\u043e\u0442 \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u044c\nLR=0.0001 # \u043f\u043e\u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u0438\u0440\u0443\u0435\u043c \u0441 learning_rate\n\ntrain_generator = train_datagen.flow_from_directory(\n    PATH+'train\/',      \n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') \n\ntest_generator = train_datagen.flow_from_directory(\n    PATH+'train\/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') \n\nmodel.compile(loss=\"categorical_crossentropy\", \n              optimizer=optimizers.Adam(lr=LR), \n              metrics=[\"accuracy\"])","f3194cb8":"# \u0434\u043e\u0431\u0430\u0432\u0438\u043c \u043a\u043e\u043b\u0431\u044d\u043a \u0434\u043b\u044f \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438 \u0441 \u043b\u0443\u0447\u0448\u0438\u043c\u0438 \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u044f\u043c\u0438\ncheckpoint = ModelCheckpoint('best_model2.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\nearlystop = EarlyStopping(monitor='accuracy', patience=5, restore_best_weights=True)\ncallbacks_list = [checkpoint, earlystop]","8e58f467":"# \u041e\u0431\u0443\u0447\u0430\u0435\u043c\n\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples\/\/train_generator.batch_size,\n    validation_data = test_generator, \n    validation_steps = test_generator.samples\/\/test_generator.batch_size,\n    epochs = EPOCHS,\n    callbacks = callbacks_list\n    )","62c89ffa":"scores = model.evaluate(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","e349eca4":"# \u0421\u043e\u0445\u0440\u0430\u043d\u0438\u043c \u043c\u043e\u0434\u0435\u043b\u044c\nmodel.save('..\/working\/model2.hdf5')\nmodel.load_weights('best_model2.hdf5')","9c1bad97":"plot_history(history)","f519392f":"base_model.trainable = True","9a99b3e0":"BATCH_SIZE = 8 # \u0443\u043c\u0435\u043d\u044c\u0448\u0438\u043c \u044d\u0442\u043e\u0442 \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u044c\nLR=0.00001 # \u043f\u043e\u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u0438\u0440\u0443\u0435\u043c \u0441 learning_rate\ntrain_generator = train_datagen.flow_from_directory(\n    PATH+'train\/',      \n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') \n\ntest_generator = train_datagen.flow_from_directory(\n    PATH+'train\/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') ","911d1b24":"model.compile(loss=\"categorical_crossentropy\", \n              optimizer=optimizers.Adam(lr=LR), \n              metrics=[\"accuracy\"])","18726ca8":"# \u0434\u043e\u0431\u0430\u0432\u0438\u043c \u043a\u043e\u043b\u0431\u044d\u043a \u0434\u043b\u044f \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438 \u0441 \u043b\u0443\u0447\u0448\u0438\u043c\u0438 \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u044f\u043c\u0438\ncheckpoint = ModelCheckpoint('best_model_full.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\nearlystop = EarlyStopping(monitor='accuracy', patience=5, restore_best_weights=True)\ncallbacks_list = [checkpoint, earlystop]","37139671":"# \u041e\u0431\u0443\u0447\u0430\u0435\u043c\n\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples\/\/train_generator.batch_size,\n    validation_data = test_generator, \n    validation_steps = test_generator.samples\/\/test_generator.batch_size,\n    epochs = EPOCHS,\n    callbacks = callbacks_list\n    )","ea853992":"scores = model.evaluate(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","c61f30aa":"# \u0421\u043e\u0445\u0440\u0430\u043d\u0438\u043c \u043c\u043e\u0434\u0435\u043b\u044c\nmodel.save('..\/working\/model_full.hdf5')\nmodel.load_weights('best_model_full.hdf5')","528c3c2e":"plot_history(history)","f206552c":"# \u043f\u0440\u043e\u0432\u0435\u0434\u0435\u043c \u0435\u0449\u0435 \u043e\u0434\u0438\u043d \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442 \u0441 \u0434\u0440\u0443\u0433\u043e\u0439 \u0432\u0430\u0440\u0438\u0430\u0446\u0438\u0435\u0439 \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u043d\u043e\u0439 \u0441\u0435\u0442\u0438 ENB\n# \u0441 \u0446\u0435\u043b\u044c\u044e \u0434\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0435\u0433\u043e \u0430\u0441\u0441\u0430\u043c\u0431\u043b\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f\nbase_model_2 = efn.EfficientNetB3(\n    weights='imagenet', include_top=False, input_shape=input_shape)","dbd80ed7":"# \u043f\u043e\u0441\u0442\u0440\u043e\u0438\u043c \u0433\u043e\u043b\u043e\u0432\u0443 \u043d\u0430 \u0434\u0440\u0443\u0433\u0438\u0445 \u043f\u0440\u0438\u043d\u0446\u0438\u043f\u0430\u0445 \u0441\u043e\u0447\u0435\u0442\u0430\u043d\u0438\u044f \u0441\u043b\u043e\u0435\u0432\nmodel=M.Sequential()\nmodel.add(base_model_2)\nmodel.add(Layer.GlobalAveragePooling2D())\nmodel.add(Layer.BatchNormalization())\nmodel.add(Layer.Dropout(0.25))\nmodel.add(Layer.Dense(256, \n                      activation='relu'))\nmodel.add(Layer.BatchNormalization())\nmodel.add(Layer.Dense(CLASS_NUM, activation='softmax'))","f38fef70":"# \u043f\u0440\u0438\u043c\u0435\u043d\u0438\u043c \u0443\u043f\u0440\u0430\u0432\u043b\u044f\u0435\u043c\u044b\u0439 learning rate \u0432 \u044d\u0442\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u0438\nfrom tensorflow.keras.optimizers.schedules import *\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.Adam(learning_rate=ExponentialDecay(\n                  0.0009, decay_steps=100, decay_rate=0.9)),\n              metrics='accuracy')","ce659219":"# \u0434\u043e\u0431\u0430\u0432\u0438\u043c \u043a\u043e\u043b\u0431\u044d\u043a \u0434\u043b\u044f \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438 \u0441 \u043b\u0443\u0447\u0448\u0438\u043c\u0438 \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u044f\u043c\u0438\ncheckpoint = ModelCheckpoint('best_model_enb3.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\nearlystop = EarlyStopping(monitor='accuracy', patience=5, restore_best_weights=True)\ncallbacks_list = [checkpoint, earlystop]","9a63d3bf":"# \u043d\u0435\u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043d\u043e\u0432\u044b\u0435 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0438 \u0434\u043b\u044f \u043c\u043e\u0434\u0435\u043b\u0438 \u0441 \u0443\u0447\u0435\u0442\u043e\u043c \u0440\u0430\u043d\u0435\u0435 \u043f\u0440\u043e\u0432\u0435\u0434\u0435\u043d\u043d\u044b\u0445 \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u043e\u0432\nEPOCHS               = 4 # \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u044b \u043f\u043e\u043a\u0430\u0437\u0430\u043b\u0438, \u0447\u0442\u043e \u0442\u0430\u043a\u043e\u0433\u043e \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u044d\u043f\u043e\u0445 \u0431\u0443\u0434\u0435\u0442 \u0434\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u043e\nBATCH_SIZE           = 8 # \u043f\u0440\u0438 \u0431\u043e\u043b\u044c\u0448\u0435\u043c \u0447\u0438\u0441\u043b\u0435 \u043a\u043e\u043c\u043f \u043d\u0435 \u0441\u043f\u0440\u0430\u0432\u043b\u044f\u0435\u0442\u0441\u044f \nVAL_SPLIT            = 0.05 # \u0443\u0432\u0435\u043b\u0438\u0447\u0438\u043c \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0443\u044e \u0432\u044b\u0431\u043e\u0440\u043a\u0443 \u0437\u0430 \u0441\u0447\u0435\u0442 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u043e\u0439\nIMG_SIZE             = 520 # \u0443\u0432\u0435\u043b\u0438\u0447\u0438\u043c \u0440\u0430\u0437\u043c\u0435\u0440 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439","0a56ceb2":"# \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0438 \u0434\u043b\u044f \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438\nWIDTH_SHIFT_RANGE    = 0.1\nHEIGHT_SHIFT_RANGE   = 0.1\nHORIZONTAL_FLIP      = True\nVERTICAL_FLIP        = False\nROTATION_RANGE       = 10\nBRIGHTNES_RANGE      = (0.5, 1.5)\nRESCALE              = 1\nSHEAR_RANGE          = 0.2\nZOOM_RANGE           = 0.1\n","3629dba7":"SUB_PATH = DATA_PATH+'test_upload\/'\nsample_submission = pd.read_csv(DATA_PATH+'sample-submission.csv')","b19d8215":"# \u0442\u0430\u043a\u0436\u0435 \u0438\u0437\u043c\u0435\u043d\u0438\u043c \u043c\u043e\u0434\u0435\u043b\u044c \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 \u0438 \u0432\u043e\u043e\u0431\u0449\u0435 \u043f\u043e\u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u0442\u0438\u0440\u0443\u0435\u043c \u0441 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\u043c\u0438\ntrain_datagen = ImageDataGenerator(\n#     rescale=1\/255,\n    validation_split=VAL_SPLIT,\n    width_shift_range = WIDTH_SHIFT_RANGE,\n    height_shift_range = HEIGHT_SHIFT_RANGE,\n    horizontal_flip=HORIZONTAL_FLIP,\n    rotation_range=ROTATION_RANGE,\n    shear_range=SHEAR_RANGE,\n    brightness_range=BRIGHTNES_RANGE,\n    zoom_range=ZOOM_RANGE,\n    vertical_flip=VERTICAL_FLIP,\n)\n\nval_datagen = ImageDataGenerator(\n#     rescale=1\/255,\n    validation_split=VAL_SPLIT,\n)\n\nsub_datagen = ImageDataGenerator(\n#     rescale=1\/255,\n    width_shift_range=WIDTH_SHIFT_RANGE, \n    height_shift_range=HEIGHT_SHIFT_RANGE,\n    horizontal_flip=HORIZONTAL_FLIP\n)","b89bd70d":"train_generator = train_datagen.flow_from_directory(\n    PATH+'train\/',      \n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') \n\ntest_generator = train_datagen.flow_from_directory(\n    PATH+'train\/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') \n\nsub_generator = sub_datagen.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=PATH+'test_upload\/',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE\n)","6d6a681d":"history = model.fit(\n        train_generator,\n        steps_per_epoch = len(train_generator),\n        validation_data = test_generator, \n        validation_steps = len(test_generator),\n        epochs = EPOCHS,\n        callbacks = callbacks_list)","f0825cc4":"scores = model.evaluate(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","19757162":"# \u0421\u043e\u0445\u0440\u0430\u043d\u0438\u043c \u043c\u043e\u0434\u0435\u043b\u044c\nmodel.save('..\/working\/model_enb3.hdf5')\nmodel.load_weights('best_model_enb3.hdf5')","ec4216c1":"plot_history(history)","b251b6c9":"# \u0441\u0434\u0435\u043b\u0430\u0435\u043c \u0441\u0430\u0431\u043c\u0438\u0442\npredictions = model.predict(sub_generator, verbose=1).argmax(axis=1)\nsubmission = pd.DataFrame({\n    'Id': sub_generator.filenames,\n    'Category': predictions\n}, columns=['Id', 'Category'])\nsubmission.to_csv('submission.csv', index=False)","765f6bc1":"# \u0441\u0434\u0435\u043b\u0430\u0435\u043c \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0439 \u043e\u0434\u043d\u043e\u0439 \u0438 \u0442\u043e\u0439 \u0436\u0435 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438\n# \u0443\u0441\u0440\u0435\u0434\u043d\u0438\u043c \u044d\u0442\u0438 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f\n# \u0441\u043e\u0445\u0440\u0430\u043d\u0438\u043c \u0432 \u0441\u0430\u0431\u043c\u0438\u0442\nsub_generator.reset()\npredictions_tta = []\nfor _ in range(EPOCHS):\n    predictions_tta.append(model.predict(sub_generator, verbose=1))\n    sub_generator.reset()\npredictions_tta = np.mean(np.array(predictions_tta), axis=0).argmax(axis=1)\nsubmission_tta = pd.DataFrame({\n    'Id': sub_generator.filenames,\n    'Category': predictions_tta\n}, columns=['Id', 'Category'])\nsubmission_tta.to_csv('submission_tta.csv', index=False)","b3c690ff":"scores = model.evaluate(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","54e8ea44":"from tensorflow import keras\nfrom tensorflow.keras import *","04183019":"model_2 = keras.models.load_model('model_full.hdf5')","6028a1f1":"sub_generator.reset()\npredictions_tta_ansemble = []\nfor _ in range(EPOCHS):\n    predictions_tta_ansemble.append(0.8*model.predict(sub_generator, verbose=1) \\\n                                    + 0.2*model_2.predict(sub_generator, verbose=1))\n    sub_generator.reset()\npredictions_tta_ansemble = np.mean(np.array(predictions_tta_ansemble), axis=0).argmax(axis=1)\nsubmission_tta_ansemble = pd.DataFrame({\n    'Id': sub_generator.filenames,\n    'Category': predictions_tta_ansemble\n}, columns=['Id', 'Category'])\nsubmission_tta_ansemble.to_csv('submission_tta_ansemble.csv', index=False)","eaddaa26":"# \u0443\u0434\u0430\u043b\u0438\u043c \u043f\u0430\u043f\u043a\u0443 \u0441 \u0440\u0430\u0441\u043f\u0430\u043a\u043e\u0432\u0430\u043d\u043d\u044b\u043c\u0438 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0430\u043c\u0438\n#import shutil\n#shutil.rmtree(PATH)","a49e9dd7":"**\u0410\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f**","138999a7":"# \u041f\u0440\u043e\u0435\u043a\u0442 7. Ford vs Ferrari. \u0410\u0432\u0442\u043e\u0440 \u0411\u044b\u0447\u043a\u043e\u0432 \u0410\u043b\u0435\u043a\u0441\u0430\u043d\u0434\u0440","d92a9670":"**EDA \/ \u0410\u043d\u0430\u043b\u0438\u0437 \u0434\u0430\u043d\u043d\u044b\u0445**","fdc3cb01":"**\u0426\u0435\u043b\u044c: \u041e\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 \u0430\u0432\u0442\u043e \u043f\u043e \u0444\u043e\u0442\u043e. \u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u0438\u0442\u044c \u0438\u0441\u0445\u043e\u0434\u043d\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 \u0438 \u043f\u0440\u0435\u0434\u043b\u043e\u0436\u0438\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0441 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\u043c\u0438 \u043b\u0443\u0447\u0448\u0435 \u0431\u0435\u0439\u0437\u043b\u0430\u0439\u043d\u0430**","55107ea7":"**SETUP**","b56ab2f7":"**FIT**","b3d60bbe":"\u0412\u044b\u0432\u043e\u0434\u044b:\n- \u0414\u043b\u044f \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438 \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u044b \u0444\u043e\u0442\u043e\u0433\u0440\u0430\u0444\u0438\u0438 10 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0439 \u0430\u0432\u0442\u043e\n- \u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0438 \u0441\u0431\u0430\u043b\u0430\u043d\u0441\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b \u043f\u043e \u043a\u043e\u043b-\u0432\u0443 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439\n- \u0420\u0430\u0437\u043c\u0435\u0440\u044b \u0444\u043e\u0442\u043e\u0433\u0440\u0430\u0444\u0438\u0439 \u0440\u0430\u0437\u043b\u0438\u0447\u0430\u044e\u0442\u0441\u044f, \u043d\u043e \u0432 \u043e\u0441\u043d\u043e\u0432\u043d\u043e\u043c 640 \u043d\u0430 480\n- \u0412\u0441\u0435\u0433\u043e 22236 \u0444\u043e\u0442\u043e \u0432 \u0442\u043e\u043c \u0447\u0438\u0441\u043b\u0435:15561 \u0444\u043e\u0442\u043e \u0432 \u0442\u0440\u0435\u0439\u043d\u0435 \u0438 6675 \u0432 \u0442\u0435\u0441\u0442\u0435\n\n\u041a\u043e\u043b-\u0432\u043e \u0444\u043e\u0442\u043e \u0432 \u0442\u0440\u0435\u0439\u043d\u0435 \u043c\u043e\u0436\u0435\u0442 \u043d\u0435 \u0445\u0432\u0430\u0442\u0438\u0442\u044c \u0434\u043b\u044f \u0445\u043e\u0440\u043e\u0448\u0435\u0433\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u043e\u0439 \u0441\u0435\u0442\u0438, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u0431\u0443\u0434\u0435\u043c \u043f\u0440\u0438\u043c\u0435\u043d\u044f\u0442\u044c \u0440\u0430\u0437\u043b\u0438\u0447\u043d\u044b\u0435 \u0432\u0438\u0434\u044b \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 \u0434\u0430\u043d\u043d\u044b\u0445","76b1fcb9":"\u0412 \u0445\u043e\u0434\u0435 \u0440\u0430\u0431\u043e\u0442\u044b \u043f\u0440\u043e\u0432\u0435\u0434\u0435\u043d\u044b \u0432\u0441\u0435 \u0441\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u043d\u044b\u0435 \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u044b \u043f\u043e \u0443\u043b\u0443\u0447\u0448\u0435\u043d\u0438\u044e \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u0435\u0439 \u043c\u043e\u0434\u0435\u043b\u0438 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f. \u041f\u043e \u0441\u0443\u0442\u0438 \u0432 \u0434\u0430\u043d\u043d\u043e\u043c \u043f\u0440\u043e\u0435\u043a\u0442\u0435 \u0441\u043e\u0437\u0434\u0430\u043d\u044b \u0434\u0432\u0435 \u043d\u0435\u0437\u0430\u0432\u0438\u0441\u0438\u043c\u044b\u0435 \u043c\u043e\u0434\u0435\u043b\u0438. \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043b\u0438\u0441\u044c \u0434\u0432\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 - \u043a\u043b\u0430\u0441\u0441\u0438\u0447\u0435\u0441\u043a\u0430\u044f \u0432\u043e \u0432\u0442\u043e\u0440\u043e\u043c \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u0435 \u0438 \u0441 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u043e\u0439 albumentations \u0432 \u043f\u0435\u0440\u0432\u043e\u043c, \u0441 \u0440\u0430\u0437\u043b\u0438\u0447\u043d\u044b\u043c\u0438 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0430\u043c\u0438.\n\n\u042d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u0430\u043b\u044c\u043d\u044b\u043c \u043f\u0443\u0442\u0435\u043c \u0432\u044b\u0432\u0435\u0434\u0435\u043d\u043e,\u0447\u0442\u043e \u043d\u0430\u0438\u0431\u043e\u043b\u0435\u0435 \u044d\u0444\u0444\u0435\u043a\u0442\u0438\u0432\u043d\u043e\u0439 \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u043d\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u044c\u044e \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f EfficientNet \u043d\u0430\u0447\u0438\u043d\u0430\u044f \u0441 \u0432\u0435\u0440\u0441\u0438\u0438 3 \u0438 \u0432\u044b\u0448\u0435. \u041c\u043d\u043e\u0439 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043b\u0430\u0441\u044c \u0442\u0440\u0435\u0442\u044c\u044f \u0438 \u0441\u0435\u0434\u044c\u043c\u0430\u044f \u043c\u043e\u0434\u0435\u043b\u044c. \n\n\u0412 \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u0435 \u0441 \u0441\u0435\u0434\u044c\u043c\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u044c\u044e EfficientNet \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043b\u0438\u0441\u044c \u043c\u0435\u0442\u043e\u0434\u044b transfer learning \u0438 fine-tuning. \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043b\u0430\u0441\u044c \u0440\u0443\u0447\u043d\u0430\u044f \u0440\u0435\u0433\u0443\u043b\u0438\u0440\u043e\u0432\u043a\u0430 learning rate \u0438 batch.\n\n\u0412 \u0434\u0440\u0443\u0433\u043e\u043c \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u0435 \u043f\u0440\u0438\u043c\u0435\u043d\u044f\u043b\u0441\u044f \u043c\u0435\u0442\u043e\u0434 ExponentialDecay \u0434\u043b\u044f \u0440\u0435\u0433\u0443\u043b\u0438\u0440\u043e\u0432\u043a\u0438 learning rate.\n\n\u0412 \u043e\u0431\u043e\u0438\u0445 \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u0430\u0445 \u043f\u0440\u0438\u043c\u0435\u043d\u044f\u043b\u0438\u0441\u044c \u0444\u0443\u043d\u043a\u0446\u0438\u0438 callback. \u0422\u0430\u043a \u0436\u0435 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043b\u0430\u0441\u044c Batch Normalization \u0432 \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u0435 \u201c\u0433\u043e\u043b\u043e\u0432\u044b\u201d \u043c\u043e\u0434\u0435\u043b\u0438. \u0410\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u044b \"\u0433\u043e\u043b\u043e\u0432\" \u0441\u043e\u0437\u043d\u0430\u0442\u0435\u043b\u044c\u043d\u043e \u043f\u0440\u0438\u043c\u0435\u043d\u044f\u043b\u0438\u0441\u044c \u0440\u0430\u0437\u043d\u044b\u0435.\n\n\u041c\u043e\u0434\u0435\u043b\u0438 \u0438\u043c\u0435\u044e\u0442 \u043f\u0440\u0438\u043c\u0435\u0440\u043d\u043e \u043e\u0434\u0438\u043d\u0430\u043a\u043e\u0432\u0443\u044e \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c 95,92% \u0438 95,99%.\n\n\u041c\u043e\u0436\u043d\u043e \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u0432\u044b\u0432\u043e\u0434, \u0447\u0442\u043e \u043c\u043e\u0434\u0435\u043b\u044c \u0441 \u0441\u0435\u0434\u044c\u043c\u043e\u0439 \u0432\u0435\u0440\u0441\u0438\u0435\u0439 EfficientNetB7 (95,92%) \u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u043e \u043e\u0431\u0433\u043e\u043d\u0438\u0442 \u0442\u0440\u0435\u0442\u044c\u044e, \u0435\u0441\u043b\u0438 \u0438\u0437\u043c\u0435\u043d\u0438\u0442\u044c \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u044c image_size \u0441 224 \u0434\u043e 512.\n\n\u041a \u043c\u043e\u0434\u0435\u043b\u0438 EfficientNetB3, \u043f\u043e\u0441\u043a\u043e\u043b\u044c\u043a\u0443 \u043e\u043d\u0430 \u0438\u043c\u0435\u043b\u0430 \u0447\u0443\u0442\u044c \u043b\u0443\u0447\u0448\u0435\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435, \u043f\u0440\u0438\u043c\u0435\u043d\u044f\u043b\u0441\u044f \u043c\u0435\u0442\u043e\u0434 TTA (Test Time Augmentation), \u0447\u0442\u043e \u043f\u043e\u043c\u043e\u0433\u043b\u043e \u0443\u043b\u0443\u0447\u0448\u0438\u0442\u044c \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u044c \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438 \u0434\u043e 96,25%.\n\n\u0412 \u0438\u0442\u043e\u0433\u0435 \u043f\u0440\u0438\u043c\u0435\u043d\u0435\u043d \u043c\u0435\u0442\u043e\u0434 \u0430\u043d\u0441\u0430\u043c\u0431\u043b\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f. \u0418\u0442\u043e\u0433\u043e\u0432\u044b\u0439 \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u044c \u043d\u0430 \u0441\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u043d\u0438\u0438 \u0432 \u041a\u0435\u0433\u043b\u0435 0,96898.\n\nP\/S: \u0431\u044b\u043b\u043e \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u043b\u0435\u043d\u043e,\u0447\u0442\u043e \u043f\u0440\u0438 \u043e\u0431\u043d\u043e\u0432\u043b\u0435\u043d\u0438\u0438 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0438 tensorflow \u0434\u043e \u0441\u0430\u043c\u043e\u0439 \u043d\u043e\u0432\u043e\u0439 \u0432\u0435\u0440\u0441\u0438\u0438 2.6 \u043d\u0435 \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442 GPU \u043d\u0430 Kaggle, \u043f\u0440\u0438 \u044d\u0442\u043e\u043c \u043e\u0442\u0441\u0447\u0435\u0442 \u0432\u0440\u0435\u043c\u0435\u043d\u0438 \u0435\u0433\u043e \u0440\u0430\u0431\u043e\u0442\u044b \u0438\u0434\u0435\u0442, \u0438\u0437-\u0437\u0430 \u0447\u0435\u0433\u043e \u044f \u043f\u043e\u0442\u0435\u0440\u044f\u043b \u043e\u043a\u043e\u043b\u043e 10 \u0447\u0430\u0441\u043e\u0432 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f GPU. \u0422\u0430\u043a\u0436\u0435 \u043d\u0430\u0434\u043e \u0431\u044b\u0442\u044c \u0432\u043d\u0438\u043c\u0430\u0442\u0435\u043b\u044c\u043d\u0435\u0435 \u0441 \u043a\u043e\u043c\u0430\u043d\u0434\u043e\u0439 \"from tensorflow.keras.applications import EfficientNetB7\", \u043f\u0440\u0438 \u044d\u0442\u043e\u043c \u043c\u043e\u0434\u0435\u043b\u044c \u043e\u0431\u0443\u0447\u0430\u0435\u0442\u0441\u044f \u043d\u0435 \u043a\u043e\u0440\u0440\u0435\u043a\u0442\u043d\u043e \u0438 \u043d\u0435 \u043f\u043e\u0437\u0432\u043e\u043b\u044f\u0435\u0442 \u0434\u043e\u0441\u0442\u0438\u0447\u044c \u0445\u043e\u0440\u043e\u0448\u0438\u0445 \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u0435\u0439. \u041d\u0443\u0436\u043d\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0443\u0441\u0442\u0430\u0440\u0435\u0432\u0448\u0438\u0435 \u043c\u0435\u0442\u043e\u0434\u044b, \u0442\u0430\u043a\u0438\u0435 \u043a\u0430\u043a \"import efficientnet.tfkeras as efn\" (\u0441 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0438\u043c \u0432\u044b\u0432\u043e\u0434\u043e\u043c \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e \u044f \u043e\u0448\u0438\u0431\u0430\u044e\u0441\u044c, \u043d\u0435 \u0431\u044b\u043b\u043e \u0434\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u043e \u0432\u0440\u0435\u043c\u0435\u043d\u0438 \u0443\u0434\u043e\u0441\u0442\u043e\u0432\u0435\u0440\u0438\u0442\u044c\u0441\u044f \u0432 \u044d\u0442\u043e\u043c \u043d\u0430 100%).","f1afd0f5":"**Test Time Augmentation (TTA)**","ad0ca449":"**\u0412\u044b\u0432\u043e\u0434\u044b**","352643dd":"**\u041c\u043e\u0434\u0435\u043b\u044c ENB3**","4f77031f":"**\u0410\u043d\u0441\u0430\u043c\u0431\u043b\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435**","ff6084fd":"**FineTuning. \u0420\u0430\u0437\u043c\u043e\u0440\u043e\u0437\u0438\u043c \u0438 \u0434\u043e\u043e\u0431\u0443\u0447\u0438\u043c \u0432\u0441\u044e \u0441\u0435\u0442\u044c EfficientNetB7**","9d2164c4":"**FineTuning. \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043f\u043e\u043b\u043e\u0432\u0438\u043d\u044b \u0432\u0435\u0441\u043e\u0432**","ae488fdd":"**\u041f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438**"}}