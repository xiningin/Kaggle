{"cell_type":{"855b6e98":"code","d7e6750f":"code","8220e5fe":"code","a4ca52bd":"code","7f4a7f0c":"code","55aea1b6":"code","cb849c72":"code","d57ed760":"code","fd169bd2":"code","62a94066":"markdown","7f0bd974":"markdown","dc935912":"markdown","b297066c":"markdown","a79c8dee":"markdown","0f4beca7":"markdown"},"source":{"855b6e98":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d7e6750f":"import tensorflow as tf\n\n(x_train,y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")","8220e5fe":"print(\"--------------------\")\nprint(\"x_train: \" , x_train.shape)\nprint(\"--------------------\")\nprint(\"y_train: \" , y_train.shape)\nprint(\"--------------------\")\nprint(\"x_test: \" , x_test.shape)\nprint(\"--------------------\")\nprint(\"y_test: \" , y_test.shape)\nprint(\"--------------------\")\n","a4ca52bd":"import matplotlib.pyplot as plt\n\nsample_img = x_train[0]\n\nTRAINSIZE = x_train.shape[0]\n\nTESTSIZE = x_test.shape[0]\n\nIMGSIZE = sample_img.shape[1]\n\nplt.imshow(sample_img)\nprint(TRAINSIZE, TESTSIZE, IMGSIZE)","7f4a7f0c":"x_train = x_train.reshape(TRAINSIZE, IMGSIZE,IMGSIZE, 1)\nx_test = x_test.reshape(TESTSIZE, IMGSIZE, IMGSIZE, 1)\n\n#Rescale Data between 0-1\nx_train = tf.keras.utils.normalize(x_train, axis=1)\nx_test  = tf.keras.utils.normalize(x_test, axis=1)\n\n\n","55aea1b6":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n\nmodel = Sequential()\nINPUT_SHAPE = (IMGSIZE, IMGSIZE, 1)\n\n#First Layer\nmodel.add(Conv2D(28,kernel_size = (3,3), input_shape = INPUT_SHAPE))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Flatten())\n\n#Second Layer\nmodel.add(Dense(128, activation=\"relu\"))\nmodel.add(Dropout(0.2))\n\n#Output Layer\nmodel.add(Dense(10, activation = \"softmax\"))","cb849c72":"model.compile(optimizer = \"adam\",\n             loss =\"sparse_categorical_crossentropy\",\n             metrics = [\"accuracy\"])\n\nmodel.fit(x_train,y_train, epochs = 20)","d57ed760":"model.evaluate(x_test, y_test)","fd169bd2":"test_img = x_test[678]\ntest_img = test_img.reshape(1,28,28,1)\npredict_ = model.predict(test_img)[0]\n\nfor i in range(len(predict_)):\n    if(predict_[i] == max(predict_)):\n        print(\"The number written is: \", i)\n        \nplt.imshow(test_img.reshape(28,28), cmap='gray')","62a94066":"# Evaluating the model","7f0bd974":"# Dataset","dc935912":"# Building the Model","b297066c":"# Preparing the data for CNN\n\n### The keras cnn model requires the dataset to add an additional dimention that has a value equivalent to the number of channels. In this case, since our images are in greyscale, we will just add an additional dimention with a value of \"1\"\n","a79c8dee":"# Example of Prediction","0f4beca7":"# Data Summary"}}