{"cell_type":{"97a53f5a":"code","424cdba7":"code","a5a1ae3b":"code","16c43aaf":"code","96aaca63":"code","88f1e038":"code","395c0b04":"code","4f3ec4c5":"code","122f4efd":"code","b6a61b5c":"code","e8db491a":"code","66814455":"code","689a57ca":"code","10b4bf69":"markdown","0cb8ffe3":"markdown","98e11b38":"markdown","326c29d5":"markdown","dda4ded8":"markdown","e7f8b5a5":"markdown","e7e62a75":"markdown","2e953ed9":"markdown","82506c73":"markdown","101221bf":"markdown"},"source":{"97a53f5a":"!pip install deep_autoviml","424cdba7":"from deep_autoviml import deep_autoviml as deepauto\nimport pandas as pd\nimport datetime as dt","a5a1ae3b":"# main flow\nstart_time = dt.datetime.now()\nprint(\"Started at \", start_time)","16c43aaf":"trainfile = '\/kaggle\/input\/tabular-playground-series-dec-2021\/train.csv'\ntestfile = '\/kaggle\/input\/tabular-playground-series-dec-2021\/test.csv'\nsubfile = '\/kaggle\/input\/tabular-playground-series-dec-2021\/sample_submission.csv'\n\ntrain = pd.read_csv(trainfile)\ntest = pd.read_csv(testfile)\nsub = pd.read_csv(subfile)\nprint(train.shape, test.shape)\ntrain.head()","96aaca63":"#### Check the class counts. If any class is too small, just drop those classes\ntarget = 'Cover_Type'\ntrain[target].value_counts()","88f1e038":"print('rows dropped = ', train[((train[target] == 4) | (train[target] == 5))].shape)\ntrain = train[~((train[target] == 4) | (train[target] == 5))]\nprint(train.shape)","395c0b04":"# drop useless features with zero variance\nfeatures_to_drop = ['Soil_Type15', 'Soil_Type7']\ntrain = train.drop(features_to_drop, axis=1)\ntest = test.drop(features_to_drop, axis=1)","4f3ec4c5":"# drop Wildness_Area3\ntrain = train.drop(['Wilderness_Area3'], axis=1)\ntest = test.drop(['Wilderness_Area3'], axis=1)\n\n# additional feature engineering\ntrain['EHiElv'] = train['Horizontal_Distance_To_Roadways'] * train['Elevation']\ntest['EHiElv'] = test['Horizontal_Distance_To_Roadways'] * test['Elevation']\n\ntrain.loc[train[\"Hillshade_9am\"] < 0, \"Hillshade_9am\"] = 0\ntrain.loc[train[\"Hillshade_9am\"] > 255, \"Hillshade_9am\"] = 255\ntest.loc[test[\"Hillshade_9am\"] < 0, \"Hillshade_9am\"] = 0\ntest.loc[test[\"Hillshade_9am\"] > 255, \"Hillshade_9am\"] = 255\n\n# Summed features pointed out by @craigmthomas (https:\/\/www.kaggle.com\/c\/tabular-playground-series-dec-2021\/discussion\/292823)\nsoil_features = [x for x in train.columns if x.startswith(\"Soil_Type\")]\nwilderness_features = [x for x in train.columns if x.startswith(\"Wilderness_Area\")]\n\ntrain[\"soil_type_count\"] = train[soil_features].sum(axis=1)\ntest[\"soil_type_count\"] = test[soil_features].sum(axis=1)\n\ntrain[\"wilderness_area_count\"] = train[wilderness_features].sum(axis=1)\ntest[\"wilderness_area_count\"] = test[wilderness_features].sum(axis=1)","122f4efd":"project_name = \"deep_autoviml\"\nkeras_options = {'early_stopping': True}\nmodel_options = {}\nkeras_model_type = 'fast'  # new fast mode\n","b6a61b5c":"model, cat_vocab_dict = deepauto.fit(train, target, keras_model_type=keras_model_type,\n\t\tproject_name=project_name, keras_options=keras_options,  \n\t\tmodel_options=model_options, save_model_flag=True, use_my_model='',\n\t\tmodel_use_case='', verbose=0)","e8db491a":"#predict\npredictions = deepauto.predict(model, project_name, test_dataset=test,\n            keras_model_type=keras_model_type, cat_vocab_dict=cat_vocab_dict)","66814455":"# update submission with the predictions obtained\nprediction_class = predictions[1]\nsub['Cover_Type'] = prediction_class\n# submit predictions\nsub.to_csv(\"submission.csv\", index=False)","689a57ca":"print('We are done. That is all, folks!')\nfinish_time = dt.datetime.now()\nprint(\"Finished at \", finish_time)\nelapsed = finish_time - start_time\nprint(\"Elapsed time: \", elapsed)","10b4bf69":"# Summary\n\nOut of the box, with very limited training time, we achieved quite a good class categorization accuracy\n- **0.90615** for 'fast1' model type (with only 'Soil_Type15', 'Soil_Type7' features dropped, and without data preprocessing suggested in https:\/\/www.kaggle.com\/c\/tabular-playground-series-dec-2021\/discussion\/293373)\n- **0.82723** for 'fast1' model type and additional feature preprocessing ('Soil_Type15', 'Soil_Type7' features dropped, imputing outliers for Aspect, Hillshade_9am, Hillshade_Noon, and Hillshade_3pm)\n- **0.89217** for ('Soil_Type15', 'Soil_Type7' features dropped, EHiElv and EViElv features added)\n- **0.91313** for ('Soil_Type15', 'Soil_Type7' features dropped, EHiElv feature added)\n- **0.90490** for ('Soil_Type15', 'Soil_Type7' features dropped, EHiElv feature added, Aspect and Aspect2 feature manipulations)\n- **0.91323** for ('Soil_Type15', 'Soil_Type7' features dropped, 'EHiElv' feature added, and outlier smoothening for 'Hillshade_9am')\n- **0.91164** for ('Soil_Type15', 'Soil_Type7' features dropped, 'EHiElv' feature added, and outlier smoothening for 'Hillshade_9am' and 'Hillshade_Noon')\n- **0.90723** for ('Soil_Type15', 'Soil_Type7' features dropped, 'EHiElv' feature added, and outlier smoothening for 'Hillshade_9am' and 'Hillshade_3pm')\n- **0.90957** for ('Soil_Type15', 'Soil_Type7' features dropped, 'EHiElv' and 'Highwater' features added, and outlier smoothening for 'Hillshade_9am')\n- **0.89942** for ('Soil_Type15', 'Soil_Type7' features dropped, 'EHiElv' and 'EVDtH' features added, and outlier smoothening for 'Hillshade_9am')\n- **0.91190** for ('Soil_Type15', 'Soil_Type7' features dropped, 'EHiElv' and 'EHDtH' features added, and outlier smoothening for 'Hillshade_9am')\n- **0.90940** for ('Soil_Type15', 'Soil_Type7' features dropped, 'EHiElv' and 'Euclidean_Distance_to_Hydrolody' features added, and outlier smoothening for 'Hillshade_9am')\n- **0.86319** for ('Soil_Type15', 'Soil_Type7' features dropped, 'EHiElv' and 'Manhattan_Distance_to_Hydrolody' features added, and outlier smoothening for 'Hillshade_9am')\n- **0.91019** for ('Soil_Type15', 'Soil_Type7' features dropped, 'EHiElv' and 'Hydro_Fire_1' features added, and outlier smoothening for 'Hillshade_9am')\n- **0.89677** for ('Soil_Type15', 'Soil_Type7' features dropped, 'EHiElv' and 'Hydro_Fire_2' features added, and outlier smoothening for 'Hillshade_9am')\n- **0.90663** for ('Soil_Type15', 'Soil_Type7' features dropped, 'EHiElv' and 'Hydro_Road_1' features added, and outlier smoothening for 'Hillshade_9am')\n- **0.90780** for ('Soil_Type15', 'Soil_Type7' features dropped, 'EHiElv' and 'Hydro_Road_2' features added, and outlier smoothening for 'Hillshade_9am')\n- **0.91160** for ('Soil_Type15', 'Soil_Type7' features dropped, 'EHiElv' and 'Fire_Road_1' features added, and outlier smoothening for 'Hillshade_9am')\n- **0.91052** for ('Soil_Type15', 'Soil_Type7' features dropped, 'EHiElv' and 'Fire_Road_2' features added, and outlier smoothening for 'Hillshade_9am')\n- **0.91939** for ('Soil_Type15', 'Soil_Type7', and 'Wilderness_Area3' features dropped, 'EHiElv' feature added, and outlier smoothened for 'Hillshade_9am')\n- **0.91339** for ('Soil_Type15', 'Soil_Type7', and 'Wilderness_Area3' features dropped, 'EHiElv' and 'Hillshade_3pm_is_zero' features added, and outlier smoothened for 'Hillshade_9am')\n- **0.92358** for ('Soil_Type15', 'Soil_Type7', and 'Wilderness_Area3' features dropped, 'EHiElv' and 'soil_type_count' features added, and outlier smoothened for 'Hillshade_9am')\n- **0.92918** for ('Soil_Type15', 'Soil_Type7', and 'Wilderness_Area3' features dropped, 'EHiElv', 'soil_type_count', and 'wilderness_area_count' features added, and outlier smoothened for 'Hillshade_9am')\n- **0.91276** for ('Soil_Type15', 'Soil_Type7', and 'Wilderness_Area1' features dropped, 'EHiElv', 'soil_type_count', and 'wilderness_area_count' features added, and outlier smoothened for 'Hillshade_9am')\n\n\n\nAs we can see, the results are quite promising.\n\n**Business-class accuracy**. *'fast1'* model in basic setup scored at *90.6%* accuracy on the  test set out of the box, and it could be futher tuned to *92.92%* with a bit of additional feature engineering (see above). Such an accuracy is extremely good for the real-world ML classification projects (sometimes they are released even if 70% of accuracy is achieved, depending on the missclassification tall and impact for a particular business problem).\n\n**Speed of model training and time to market under affordable resource allocation**. Model training time was less than 30 min (both on Kaggle premise and a local laptop). There was no need to set up any expensive hardware or cloud-based clusters to train the model.\n\nSurely, such a result is still behind certain manually tuned models.\n\nHowever, it demontrates that **Deep AutoViML** can deliver the models of real-world quality without  spending too much time and resource on its setup and training (as we know, in business enviroments, delivering good-enough results at a very fast timeline is often better then delivering the result of exceptional quality under very long timeline).","0cb8ffe3":"# Introduction\n\nThis notebook is dedicated to demonstrate the potential of **Deep AutoViML** AutoMLproduct at automatic building the DL model for this contest as well as predicting for the competion contest.\n\n**Note:** We have to install **Deep AutoViML** into the notebook interactively since it is not the part of the default set of Python packages deployed to the Kaggle notebook docker image.","98e11b38":"After it, we are going to apply some additional feature engineering below","326c29d5":"Also, we detected **'Soil_Type15'** and **'Soil_Type7'** to be useless features. They only have one value for each and every record in the training set (that is, they have zero variance) so they would not be helpful in the model training.\n\nWe are going to remove these features from both the training and test sets.","dda4ded8":"# Deep AutoViML: Model training and predictions\n\nFirst of all, we are going to set up some metadata for the model.\n\n**Note:** The essential detail is we are going to use Google's deep-and-wide NN architecture (*keras_model_type = 'fast1'*) and training for 100 epoches with early stopping option, to find the right compromise between the  model accuracy and the training time. You can check out the documentation per https:\/\/github.com\/AutoViML\/deep_autoviml , **API** section, to see more on the available model types.","e7f8b5a5":"# Data Preprocessing\n\nFirst of all, we read the data in memory","e7e62a75":"As we can see, classes with the labels of **4** and **5** are quite rare in the training set. Therefore we will ignore them in the model training. To achieve it, we are going to drop the training observations with such class labels:","2e953ed9":"# Data Preprocessing and Feature Engineering\n\nWe are going to check the frequency of the target class labels in the training set","82506c73":"Now we are going to launch the model training (with possible option for the early stopping, fast2 model and relatively small number of epoches).","101221bf":"Now we are ready to predict the class labels on the training set as well as submit the predictions file into the competition."}}