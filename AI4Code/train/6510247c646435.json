{"cell_type":{"f2a7f7ca":"code","054ae866":"code","9750939e":"code","62a59aab":"code","1a99f9bd":"code","2d5b21df":"code","f22fceea":"code","a14e3b84":"markdown","13f95310":"markdown","364a90f4":"markdown","4b9d4ce5":"markdown","25042508":"markdown","f9994c07":"markdown","12b26a60":"markdown","67b84d0a":"markdown","7852461e":"markdown","5d9161bb":"markdown","1b9a4ae2":"markdown","9525ed1f":"markdown","196e22c2":"markdown","2103140f":"markdown"},"source":{"f2a7f7ca":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndf = pd.read_csv('..\/input\/titanic\/train.csv')\ndf= df.drop(['Name', 'PassengerId', 'Ticket','Embarked','Cabin'], axis=1)\ndf['Age'] = df['Age'].fillna(df['Age'].median())\n\nencoded= pd.get_dummies(df[['Sex']], drop_first=True)\ndf = pd.concat([df, encoded], axis=1)\ndf= df.drop(['Sex'], axis=1)\n\n\ny_train = df['Survived']\nX_train = df.drop('Survived', axis=1)\n\ndf1 = pd.read_csv('..\/input\/titanic\/test.csv')\ndf1= df1.drop(['Name', 'PassengerId', 'Ticket','Embarked','Cabin'], axis=1)\ndf1['Age'] = df1['Age'].fillna(df['Age'].median())\ndf1['Fare'] = df1['Fare'].fillna(df['Fare'].median())\n\nencoded1 = pd.get_dummies(df1[['Sex']], drop_first=True)\ndf1 = pd.concat([df1, encoded1], axis=1)\ndf1 = df1.drop(['Sex'], axis=1)\n\nX_test = df1","054ae866":"#splitting train data in 2 parts\n\nfrom sklearn.model_selection import train_test_split\nxtraining,xvalid,ytraining,yvalid = train_test_split(X_train,y_train,test_size=0.5)","9750939e":"#importing the packages\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nimport xgboost as xgb\n\n#specifying the initial learners\nmodel1 = RandomForestClassifier()\nmodel2 = LogisticRegression()\nmodel3 = xgb.XGBClassifier()\n\n#training the initial learners\nmodel1.fit(xtraining,ytraining)\nmodel2.fit(xtraining,ytraining)\nmodel3.fit(xtraining,ytraining)\n","62a59aab":"#making predictions for the validation data\npreds1 = model1.predict(xvalid)\npreds2 = model2.predict(xvalid)\npreds3 = model3.predict(xvalid)\n\n#making predictions for the test data\ntest_preds1 = model1.predict(X_test)\ntest_preds2 = model2.predict(X_test)\ntest_preds3 = model3.predict(X_test)\n","1a99f9bd":"#making a new dataset for training our final model by stacking the predictions on the validation data\ntrain_stack = np.column_stack((preds1,preds2,preds3))\n\n#making the final test set for our final model by stacking the predictions on the test data\ntest_stack = np.column_stack((test_preds1,test_preds2,test_preds3))","2d5b21df":"final_model = RandomForestClassifier()\n\n#training the final model on the stacked predictions\nfinal_model.fit(train_stack,yvalid)","f22fceea":"final_predictions = final_model.predict(test_stack)","a14e3b84":"# Stacking used for the Titanic competition","13f95310":"**Data Preprocessing**","364a90f4":"Stacking is a way to ensemble multiple classifications or regression model. There are many ways to ensemble models, the widely known techniques are Bagging or Boosting. Bagging allows multiple similar models with high variance which are averaged to decrease variance. Boosting builds multiple incremental models to decrease the bias, while keeping variance small.\n\nStacking is a different paradigm. The point of stacking is to explore a space of different models for the same problem. The idea is that you can attack a learning problem with different types of models which are capable to learn some part of the problem, but not the whole space of the problem. So, you can build multiple different learners and you use them to build an intermediate prediction, one prediction for each learned model. Then you add a new model which learns from the intermediate predictions for the same target.\n\nThis final model is said to be stacked on the top of the others, hence the name. Thus, you might improve your overall performance, and often you end up with a model which is better than any individual intermediate model.","4b9d4ce5":"This is a beginner's introduction to Ensembling Machine learning models using the technique of *Stacking*.","25042508":"The final model (meta model) will be created and trained on the predictions of the models on the validation data. We will choose a random forrest classifier for this task.","f9994c07":"The initial learners will now be used to make predictions on the validation data (which will be stacked together to form the training data for the final model) and to make predictions on the test data (which will be stacked together to form the test data for the final model).","12b26a60":"#  Stacking Ensemble Machine Learning Model","67b84d0a":"The initial learners will now be specified and trained on the training data.","7852461e":"The train data will now be split into two parts, which we will call training and validation.\nThe initial learners(model1,model2,model3) will be trained on the training data and tested on the validation data. The final learner(meta_model) will be trained on the predictions of the initial learners on the validation data and the corresponding target variable values.","5d9161bb":"# Building the Stacked Ensemble","1b9a4ae2":"We now have an X_train,y_train and an X_test.","9525ed1f":"![image.png](attachment:image.png)","196e22c2":"1. The predictions on the validation data will be stacked together to create the train set for the final model.\n2. The predictions on the test data will be stacked together to create the test set for the final model. ","2103140f":"This final model is now ready to be used to make predictions on the test data for the final results."}}