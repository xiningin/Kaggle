{"cell_type":{"2f2c08b8":"code","258fec96":"code","ba6b6097":"code","1cf8aa85":"code","a854f19a":"code","211fec4f":"code","66cf41a4":"code","c413b22f":"code","44802a82":"code","cb4a494f":"code","d7f60248":"code","7210aa8f":"code","6231a325":"code","a55bb455":"code","483891a1":"markdown","53ba210c":"markdown","13f03606":"markdown","a1aa95ae":"markdown","e6d57b0a":"markdown","bd37e993":"markdown","47741d27":"markdown","f1f1cb90":"markdown","17a32426":"markdown"},"source":{"2f2c08b8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","258fec96":"seed_data = pd.read_csv('\/kaggle\/input\/seed-from-uci\/Seed_Data.csv')","ba6b6097":"seed_data.shape","1cf8aa85":"# this is how the dataset looks \nseed_data","a854f19a":"feature = seed_data.columns","211fec4f":"print(feature)","66cf41a4":"feature.drop(['target'])  ","c413b22f":"from sklearn.preprocessing import StandardScaler\nx = seed_data.loc[:,feature].values\nx = StandardScaler().fit_transform(x)","44802a82":"from sklearn.decomposition import PCA\npca = PCA(n_components=3)\nseed_data_transform = pca.fit_transform(x)","cb4a494f":"principal_seed_data = pd.DataFrame(data = seed_data_transform, columns = ['principal component 1', 'principal component 2','principal component 3'])\nprincipal_seed_data.tail()","d7f60248":"print(pca.explained_variance_) ","7210aa8f":"print('Explained variation per principal compoents {}'.format(pca.explained_variance_ratio_))","6231a325":"import matplotlib.pyplot as plt\n%matplotlib notebook\n\nplt.figure()\nplt.figure(figsize=(10,10))\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=14)\nplt.xlabel('Principal Component - 1',fontsize=20)\nplt.ylabel('Principal Component - 2',fontsize=20)\nplt.title(\"Principal Component Analysis of SEED DATA  Dataset\",fontsize=20)\n# we had numerical data thus we did not write it in quotes. ['1','2'...]\ntargets = [0,1,2]\ncolors = ['r', 'g','b']\nfor target, colour in zip(targets,colors):\n    indicesToKeep = seed_data['target'] == target\n    plt.scatter(principal_seed_data.loc[indicesToKeep, 'principal component 1']\n               , principal_seed_data.loc[indicesToKeep, 'principal component 2'],\n                c = colour, s = 50)\n\nplt.legend(targets,prop={'size': 15})","a55bb455":"from mpl_toolkits.mplot3d import axes3d\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nY = ['r','g','b']\n\ntargets = [0,1,2]\ncolors = ['r', 'g','b']\nfor target, colour in zip(targets,colors):\n    indicesToKeep = seed_data['target'] == target\n    ax.scatter(principal_seed_data.loc[indicesToKeep, 'principal component 1']\n               , principal_seed_data.loc[indicesToKeep, 'principal component 2'],\n               principal_seed_data.loc[indicesToKeep, 'principal component 3'],\n               c = colour, s = 50)\n\n\nax.set_xlabel('principal component 1')\nax.set_ylabel('principal component 2')\nax.set_zlabel('principal component 3')\nfor angle in range(0, 360):\n    ax.view_init(30, angle)\n    plt.draw()\n\nplt.legend(targets,prop={'size': 15})","483891a1":"**Lets look at the shape  of the data set**","53ba210c":"**Loading the data into seed_data from the Seed_Data.csv**","13f03606":"# Hey guys hope you like the notebook. Please Comment and Upvote it also.\ud83d\ude4f","a1aa95ae":"**Lets extract the column heads form the data**","e6d57b0a":"**\nSo as to train the model we need to drop the col. target form the feature so that is can be used to fit_tranform PCA\n**","bd37e993":"**We can also make a 3D plot to show how 3 PCA's to show how those 3 components helped to cluster the information.**","47741d27":"**\nWe can see that the first there principal components can cover almost 90% of the data set.\nSo we need not select any other components\n**","f1f1cb90":"**Now we are going to preprocess the data and normalize it. **","17a32426":"**We can clusture them using 2 PCA as shown in the 2D plot. **"}}