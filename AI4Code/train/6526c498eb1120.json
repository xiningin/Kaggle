{"cell_type":{"7d8a4079":"code","1c9b064f":"code","ad0cb31d":"code","e1aab835":"code","e17daaa5":"code","8909c86d":"code","95dfe5a1":"code","bc494825":"code","7fb8f521":"code","069c65b3":"code","b3a80485":"code","8fc840e5":"code","9dbcb10a":"code","c31c89c5":"code","4a4a93b8":"code","beee3d4c":"code","b6b10dbc":"code","8d310e6c":"code","10a8cf66":"code","78b9a85f":"code","6db422c4":"code","bf430306":"code","81520583":"code","ba88d5f3":"code","a14ab357":"code","9be9f8ca":"code","a12c345f":"code","4cd59942":"markdown","4074dfbf":"markdown","e99cef46":"markdown","a7bd6527":"markdown","e6ad52e8":"markdown","1da1c16c":"markdown","855a0425":"markdown","7e8091e3":"markdown","8e574e7f":"markdown","c910af75":"markdown","9cb7344b":"markdown","41ceb4c5":"markdown","548ce89a":"markdown","879151e9":"markdown","db380ce1":"markdown","546d8060":"markdown","0979585c":"markdown","5b883532":"markdown","061fd3c4":"markdown","feebc2d7":"markdown","d2fe1d16":"markdown","bbdc6c8a":"markdown","7c1395c7":"markdown"},"source":{"7d8a4079":"# Import packages\nimport math\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import cross_val_score\nfrom xgboost import XGBRegressor\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.decomposition import PCA","1c9b064f":"# Save filepath for easier access\ngold_file_path = '..\/input\/gold-price-prediction-dataset\/FINAL_USO.csv'\n\n# Read the data with pandas and store it in a dataframe titled gold data\ndf = pd.read_csv(gold_file_path)\n\ny = df['Adj Close'] \n\n# We will start out by selecting features gold ETF features\ngold_features = ['Open','High', 'Low', 'Volume']\nX = df[gold_features]\nX.head()","ad0cb31d":"# There are no null values\ndf.isnull().values.any()","e1aab835":"# Define Model\ngold_model = LinearRegression()\n\n#Fit Model\ngold_model.fit(X, y)\n\nprint(\"Making predicitons for the first 5 entries\\n\")\nprint(X.head())\nprint(\"\\nThe predictions are:\\n\")\nprint(gold_model.predict(X.head()))\nprint(\"\\nThe actual values are:\\n\")\nprint(y.head())\n","e17daaa5":"predicted_adj_close = gold_model.predict(X.head())\nprint(mean_absolute_error(y.head(),predicted_adj_close))\n\npredicted_adj_close = gold_model.predict(X)\nprint(mean_absolute_error(y, predicted_adj_close))","8909c86d":"# Partition data into training and validation groups\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n# Define a new model for training set\ngold_model = LinearRegression()\n# Fit model\ngold_model.fit(train_X, train_y)\n\n#get predicted prices on validation data\nval_predictions = gold_model.predict(val_X)\nprint(mean_absolute_error(val_y,val_predictions))\n\n","95dfe5a1":"gold_model = LinearRegression()\n\n# Bundle preporcessing and modeling code in a pipeline\nmy_pipeline = Pipeline(steps=[('gold_model', gold_model)])\n# Preprocessing of training data, fit model\nmy_pipeline.fit(train_X, train_y)\n\n# Preprocessing of validation data, get predictions\npreds = my_pipeline.predict(val_X)\n\n# Evaluate the model\nmae_score = mean_absolute_error(val_y, preds)\nprint('MAE:', mae_score)\n\n# Display Model\nsns.regplot(x=val_y, y=preds, line_kws={\"color\":\"black\"})\n","bc494825":"# Multiply by -1 since sklearn calculates *negative* MAE\nscores = -1 * cross_val_score(my_pipeline, X, y,\n                              cv=10,\n                              scoring = 'neg_mean_absolute_error')\nprint(\"MAE scores:\\n\",scores,\"\\n\")\nprint(\"Average MAE score (across all ten folds):\")\nprint(scores.mean())\n\nrmse = math.sqrt(mean_squared_error(val_y,preds))\nprint(\"\\nRMSE is\",rmse)\n\nr2 = r2_score(val_y, preds)\nprint(\"\\nr2 score is\", r2)","7fb8f521":"my_model = XGBRegressor()\nmy_model.fit(train_X, train_y)\n\n# Make predictions using XGBoost model\npredictions = my_model.predict(val_X)\nprint(\"Mean Absolute Error: \",mean_absolute_error(predictions, val_y))","069c65b3":"my_model = XGBRegressor(n_estimators=1000,\n                        learning_rate=0.03,\n                        n_jobs=4)\nmy_model.fit(train_X, train_y,\n            early_stopping_rounds=5,\n            eval_set=[(val_X, val_y)],\n            verbose=False)\n\npredictions = my_model.predict(val_X)\nprint(\"Mean Absolute Error\",\n      mean_absolute_error(predictions,val_y))\n\nrmse = math.sqrt(mean_squared_error(val_y,predictions))\nprint(\"\\nRMSE is\", rmse)\n\nr2 = r2_score(val_y,predictions)\nprint(\"\\nr2 score is\", r2)\n\nsns.regplot(x=val_y, y=predictions, line_kws={\"color\": \"black\"})\n","b3a80485":"# Refresh on what all of the features look like\n# There are 79 predictor columns. I am not including Adj Close and Close of the 81 total.\n\nplt.style.use(\"seaborn-whitegrid\")\n\ndf.head()","8fc840e5":"# Create new ds with all predictor features. Take Adj Close as Y\n# Remove Close because it is too close to Adj Close\nX = df.copy()\ny = X.pop('Adj Close')\ndate = X.pop('Date')\nX.pop('Close')","9dbcb10a":"# Create mutual info scores\n\ndef make_mi_scores (X, y):\n    mi_scores = mutual_info_regression(X, y)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\nmi_scores = make_mi_scores(X, y)","c31c89c5":"def plot_mi_scores(scores):\n    scores = scores.sort_values(ascending=True)\n    width = np.arange(len(scores))\n    ticks = list(scores.index)\n    plt.barh(width, scores)\n    plt.yticks(width, ticks)\n    plt.title(\"Mutual Information Scores\")\n    \nplt.figure(dpi=100, figsize=(10,18))\nplot_mi_scores(mi_scores)\n    ","4a4a93b8":"daily_high = sns.regplot(x=\"High\", y=\"Adj Close\", data=df, line_kws={\"color\": \"black\"}).set(title=\"Gold's Daily High\")\n","beee3d4c":"daily_low = sns.regplot(x=\"Low\", y=\"Adj Close\", data=df, line_kws={\"color\": \"black\"}).set(title=\"Gold's Daily Low\")\n","b6b10dbc":"daily_close = sns.regplot(x=\"Open\", y=\"Adj Close\", data=df, line_kws={\"color\": \"black\"}).set(title=\"Gold's Daily Open\")","8d310e6c":"df[\"Daily_Change\"] = abs(X.High - X.Low)\n\n# Convert Date from string to datetime to give us yearly ticks on the X-axis\ndf['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')\n\n# Plot volatility\nsns.set(rc={\"figure.figsize\":(20, 4)})\ndaily_change = sns.lineplot(x=\"Date\", y=\"Daily_Change\", data=df).set(title=\"Gold's Daily Change\/Volatility\")","10a8cf66":"# Adjusted Close with Time Series\nsns.set(rc={\"figure.figsize\":(20, 4)})\ndaily_change = sns.lineplot(x=\"Date\", y=\"Adj Close\", data=df).set(title=\"Gold's Adjusted Daily Close Price\")","78b9a85f":"features = [\"High\", \"Low\", \"Open\", \"GDX_High\", \"GDX_Low\", \"GDX_Close\"]\n\nX = df.copy()\ny = X.pop('Adj Close')\ndate = X.pop('Date')\nX.pop('Close')\nX = X.loc[:, features]\n\n# Standardize the new df. PCA is sensitive to scale.\nX_scaled = (X - X.mean(axis=0)) \/ X.std(axis=0)","6db422c4":"# Create principal componenets\npca = PCA()\nX_pca = pca.fit_transform(X_scaled)\n\n# Convert to dataframe\ncomponent_names = [f\"PC{i+1}\" for i in range (X_pca.shape[1])]\nX_pca = pd.DataFrame(X_pca, columns=component_names)\n\nX_pca.head()","bf430306":"# Wrap the PCA loadings up in a dataframe\nloadings = pd.DataFrame(\n    pca.components_.T,       # Transpose the matrix of loadings\n    columns=component_names, # to turn columns into principal components\n    index = X.columns,       # and the rows are original features, so we can identify them\n)\nloadings","81520583":"def plot_variance(pca, width=8, dpi=100):\n    # Create figure\n    fig, axs = plt.subplots(1,2)\n    n = pca.n_components_\n    grid = np.arange(1, n + 1)\n    \n    # Explained variance\n    evr = pca.explained_variance_ratio_\n    axs[0].bar(grid, evr)\n    axs[0].set(\n        xlabel=\"Component\", title=\"% Cumulative Variance\", ylim=(0.0, 1.0)\n    )\n    # Cumulative Variance\n    cv = np.cumsum(evr)\n    axs[1].plot(np.r_[0, grid], np.r_[0,cv], \"o-\")\n    axs[1].set(\n        xlabel=\"Component\", title=\"%Cumulative Variance\", ylim=(0.0,1.0)\n    )\n    # Set up figure\n    fig.set(figwidth=8, dpi=100)\n    return axs\n\n# Look at the explained variance from PCA\nplot_variance(pca);","ba88d5f3":"# View MI Scores for the principal components\nmi_scores = make_mi_scores(X_pca, y)\nmi_scores","a14ab357":"# Partition the PCA dataframe into training and validation groups\ntrain_X, val_X, train_y, val_y = train_test_split(X_pca, y, random_state = 0)\n\ngold_model = LinearRegression()\n\n# Bundle preporcessing and modeling code in a pipeline\nmy_pipeline = Pipeline(steps=[('gold_model', gold_model)])\n# Preprocessing of training data, fit model\nmy_pipeline.fit(train_X, train_y)\n\n# Preprocessing of validation data, get predictions\npreds = my_pipeline.predict(val_X)\n\n# Evaluate the model\nmae_score = mean_absolute_error(val_y, preds)\nprint('MAE:', mae_score)\n\n# Display Model\nsns.set(rc={\"figure.figsize\":(6,6)})\nsns.regplot(x=val_y, y=preds, line_kws={\"color\":\"black\"}).set(title=\"Linear Regression with PCA\")\n","9be9f8ca":"# Multiply by -1 since sklearn calculates *negative* MAE\nscores = -1 * cross_val_score(my_pipeline, X_pca, y,\n                              cv=10,\n                              scoring = 'neg_mean_absolute_error')\nprint(\"MAE scores:\\n\",scores,\"\\n\")\nprint(\"Average MAE score (across all ten folds):\")\nprint(scores.mean())\nrmse = math.sqrt(mean_squared_error(val_y,preds))\nprint(\"\\nRMSE is\", rmse)\nr2 = r2_score(val_y,preds)\nprint(\"\\nr2 score is\", r2)","a12c345f":"results = [['Linear Regression', 0.221, 0.326, 0.999672],\n           ['Gradient Boosting (XGBoost)', 0.325, 0.490, 0.999259],\n           ['Linear Regression with PCA', 0.193, 0.275, 0.999766]]\nresults_df = pd.DataFrame(results, columns = ['Model Type', 'MAE', 'RMSE', 'r2'])\nresults_df","4cd59942":"# Create a Gradient Boosting Model","4074dfbf":"We can see that these three native features are very good predictors for the adjusted close price. However, what if we can create a new feature that can lend a little more insight into the price of gold. In the code below, we will create a feature called \"daily change\" by taking the price difference from open and close. Daily change is useless as a predictor on its own, but maybe we can apply it to time-series data to see any trends. Daily change is a way to track the volatility of gold prices.","e99cef46":"# Check to see if we have any missing values that we need to impute or remove.","a7bd6527":"This notebook creates and improves a linear regression model using gold and stock index prices from 2012 until 2019 --[https:\/\/www.kaggle.com\/sid321axn\/gold-price-prediction-dataset](http:\/\/) . The data has 81 features. The index consists of individual days. The target feature is \"adjusted close\". We are trying to predict what the closing price of gold will be given predictors of the gold market itself as well as other stock market indexes. The regular \"Close\" feature is also removed during model construction. That leaves 78 features to predict the adjusted close price of gold.\n\nI started out building a simple linear regression model with predictors I imagined would be good to start with: the daily high, daily low, daily open, and volume being traded. From there, I created a gradient boosting model and compared its performance with the linear regression model. In this case, the linear regression model had a better mean absolute error than gradient boosting, even when put through a 10-fold cross validation.\n\nThen, I went into feature engineering for a more detailed look of the data. I put 78 features through mutual information analysis. All of the predictors I used for the earlier linear regression and gradient boosting models were the highest performers, with the exception of volume. Next, I created a custom feature that measured daily volatility of gold prices. I compared this with the adjusted close price over time. What I found is that daily volatility was slightly correlated with adjusted close price.\n\nFinally, I continue feature engineering by using PCA to take the top six features with the highest mutual information to adjusted close and created six principal components. I used those six principal components in a new linear regression pipeline. This final model was the best performing of this notebook. See the bottom for the final results.\n\nThanks to *Manu Siddhartha* for the dataset! Check out his profile here. [https:\/\/www.kaggle.com\/sid321axn](http:\/\/)\n\nAll feedback is welcome!","e6ad52e8":"Just based on the first five predictions. We can see that gold_model fitted to the whole data set is able to predict the adjusted close value within a dollar. We will run the whole model through validation and get its mean absolute error.","1da1c16c":"# Model Validation","855a0425":"# Creating a Data Pipeline","7e8091e3":"We can already see PCA helped us improve the model's MAE by 0.20. Let's run the new pipeline through cross-validation to get a more accurate score.","8e574e7f":"# Run Model through Cross-Validation","c910af75":"# Create Linear Regression Model","9cb7344b":"#  Three Models Performance Results","41ceb4c5":"**Good news!** Running the PCA model through ten-fold cross validation gave us our best model performance across all metrics. The simple linear regression model came in second on all metrics as well. XGBoost came in last this time. Although there is slight variation in performance, all three of these models perform well because the top three features are so highly correlated with adjusted time. The dataset has many features, but it would not improve the model significantly by adding ones beyond the top six to a regression model.\n\nThanks for your time! \n\nAll feedback is welcome!","548ce89a":"Next we'll apply principal component analysis (PCA). PCA will be good to use with this dataset for two reasons. \n* The first is that PCA works well with numeric features. All of our features, with the exception of Date, are numeric features.\n* Many of our features are redundant and are closely related mutual information scores. A lot of them can be removed or combined to create principal components.\nWe already know that High, Low, and Open have the highest mutual information scores. We also know that those features alone produce a high-performing linear regression model. To experiment with something new. We will leave in the top six features, which means including the gold index(GDX) features.","879151e9":"We can see principal component 1 (PC1) is the most informative by far. A disparity is expected usually between PC1 and the remainders. However, this is a very high disparity. If we didn't look at our features through mutual information earlier. This would raise concern. However, we already know that the first three features are highly correlated with our target feature of adjusted close, so these results make sense.","db380ce1":"# Feature Engineering\nWe've built a model that can predict gold's daily adjusted close value with good accuracy. However, this dataset came with 79 predictor features. Obviously, the predictors I just used are most closely related to the adjusted close value. Now we will use feature engineering to determine what are highly correlated features and see if we can build a better model with them. We'll start by ranking features with **mutual information** and show which features rank the highest with seaborn.","546d8060":"# Partitioning Data\nSince we did not split up our data into train, test, and validation sets, the above model could be overfitted.","0979585c":"# Predicting Gold Prices with PCA and Linear Regression\n![gold-bar-4-different-sizes-pbr-3d-model-fbx-ma-blend.jpg](attachment:6ef5a7d9-8b04-45aa-8d13-902d522e5a23.jpg) ","5b883532":"We can see that gold prices have gotten less volatile since 2012. Around after mid-2017, gold seems to have become less volatile to the end of 2018. If we were to split up the data from 2012-2013 and 2017-2018 and run them through our linear regression model, we would get better performance from the 2017-2018 dataset because the prices have less daily variation than the 2012-2013 subset. The main takeaway here is that gold volatility has decreased overtime. However, the Adjusted Close has also gone down, as visualized below.","061fd3c4":"# New Data Pipeline with PCA\nNow that we can see how worthy each principal component is, we can better determine which ones we should add to our new pipeline. In this instance, we will include all prinicpal components in our new pipeline The goal is to beat an MAE of 0.221 after a 10-fold cross validation. ","feebc2d7":"No wonder our earlier models performed so well. We were already using the best predictors: High, Low, and Open. The predictor we used that has very low mutual information is Volume. In fact, Volume has a lower mutual information than other volumes for stock market indicies. Thanks to the graph above, we know to drop Volume as a predictor and perhaps add in higher ranking predictors such as GDX_High and GDX_Close. It seems that the volume and trend categories of predictors always have a lower MI score than any high, low, or open predictor.\n\nHigh, Low and Open are extremely correlated to the Adj Close value. Let's create simple regplots to magnify their relationships. You will see that as their mutual information rank gets lower, the less correlated that feature's regplot is with adjusted close.","d2fe1d16":"Construct a bar plot to show each feature's score.","bbdc6c8a":"In this instance, XGBoost has a MAE of 0.325 and an RMSE of 0.490. The linear regression model gave an average MAE of 0.221 after it was run through ten folds of cross validation and an RMSE of 0.326. The linear regression model is slightly superior to XGBoost when given these parameters and validation techniques.","7c1395c7":"This is much worse than our linear regression model. We will need to adjust some of our parameters to make sure we get the best result XGBoost can afford us. We will start by changing: \n1. The number of estimators - the number of times it will go through the modeling cycle.\n2. The early stopping round - the parameter we set to stop the model when our validation score stops improving.\n3. Learning rate - the parameter that means each model will help us less. The lower we set the learning rate, generally, the more accurate our predictions will be.\n4. n_jobs - we would change this to build our models faster. Ideally, you match this to the number of cores on your machine to shorten the amount of time the model is being fit."}}