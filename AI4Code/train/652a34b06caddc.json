{"cell_type":{"800fec05":"code","b99977b3":"code","80df1c2d":"code","25a14be5":"code","97c4af30":"code","4adace72":"code","1935c62a":"code","4084f7e2":"code","6960dc28":"code","c6e6c1f8":"code","a6c1c40b":"code","871ebe24":"code","ccd931a8":"code","31551514":"code","9a123f45":"code","9c724d1e":"code","cdd02b0c":"code","85654e5f":"code","2c60db81":"code","614f8456":"code","f15382fa":"code","dc9a15d7":"code","ce7d01b8":"code","889092f0":"code","d0dcee97":"code","ed8ad21f":"code","189033db":"code","720cfa7c":"code","94502167":"code","7c19c792":"markdown","1aaa7ad1":"markdown","ba7d3950":"markdown","6790876e":"markdown","a8e3c667":"markdown","ee2312b9":"markdown"},"source":{"800fec05":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.offline as py\nimport plotly.express as px\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b99977b3":"df = pd.read_csv('..\/input\/sex-offender-registry\/Sex_Offender_Registry.csv', encoding='utf8')\npd.set_option('display.max_columns', None)\ndf.head()","80df1c2d":"df.isnull().sum()","25a14be5":"#Codes by Pooja Jain https:\/\/www.kaggle.com\/jainpooja\/av-guided-hackathon-predict-youtube-likes\/notebook\n\ntext_cols = ['ALIASES', 'MARKINGS', 'TYPE']\n\nfrom wordcloud import WordCloud, STOPWORDS\n\nwc = WordCloud(stopwords = set(list(STOPWORDS) + ['|']), random_state = 42)\nfig, axes = plt.subplots(2, 2, figsize=(20, 12))\naxes = [ax for axes_row in axes for ax in axes_row]\n\nfor i, c in enumerate(text_cols):\n  op = wc.generate(str(df[c]))\n  _ = axes[i].imshow(op)\n  _ = axes[i].set_title(c.upper(), fontsize=24)\n  _ = axes[i].axis('off')\n\n_ = fig.delaxes(axes[3])","97c4af30":"# categorical features with missing values\ncategorical_nan = [feature for feature in df.columns if df[feature].isna().sum()>0 and df[feature].dtypes=='O']\nprint(categorical_nan)","4adace72":"# replacing missing values in categorical features\nfor feature in categorical_nan:\n    df[feature] = df[feature].fillna('None')","1935c62a":"df[categorical_nan].isna().sum()","4084f7e2":"from scipy import stats\n\n#Finding out the skew for each attribute\nskew=df.skew()\nprint(skew)\n# Removing the skew by using the boxcox transformations\ntransform=np.asarray(df[['X']].values)\ndf_transform = stats.boxcox(transform)[0]\n#Plotting a histogram to show the difference \nplt.hist(df['X'],bins=10) #original data\nplt.show()\nplt.hist(df_transform,bins=10) #corrected skew data\nplt.show()","6960dc28":"pd.set_option('display.width', 100)\npd.set_option('precision', 3)\ncorrelation=df.corr(method='spearman')\nprint(correlation)","c6e6c1f8":"# heatmap of the correlation \nplt.figure(figsize=(10,10))\nplt.title('Correlation heatmap')\nsns.heatmap(correlation,annot=True,vmin=-1,vmax=1,cmap=\"GnBu_r\",center=1)","a6c1c40b":"fig = plt.figure(figsize = (15,7))\ndf.groupby('LASTNAME')['SEXOFFENDERCODE'].agg(len).sort_values(ascending = False).head(20).plot(kind = 'bar')\nplt.xlabel('LASTNAME', fontsize = 20)\nplt.ylabel('SEXOFFENDERCODE', fontsize = 20)\nplt.title('20 Sex Offenders by Lastname and Code', fontsize = 30)","871ebe24":"# Analysing the relationship between energy and loudness\nfig=plt.subplots(figsize=(10,10))\nsns.regplot(x='X',y='Y',data=df,color='purple')","ccd931a8":"fig=plt.subplots(figsize=(10,10))\nplt.title('Dependence between X and Y')\nsns.regplot(x='X', y='Y',\n            ci=None, data=df)\nsns.kdeplot(df.X,df.Y)","31551514":"df.plot(kind='box', subplots=True)\nplt.gcf().set_size_inches(30,30)\nplt.show()","9a123f45":"import squarify as sq\n\nplt.figure(figsize=(14,8))\nsq.plot(sizes=df.QUADRANT.value_counts(), label=df[\"QUADRANT\"].unique(), alpha=.8 )\nplt.axis('off')\nplt.show()","9c724d1e":"from sklearn.preprocessing import LabelEncoder\n\n#fill in mean for floats\nfor c in df.columns:\n    if df[c].dtype=='float16' or  df[c].dtype=='float32' or  df[c].dtype=='float64':\n        df[c].fillna(df[c].mean())\n\n#fill in -999 for categoricals\ndf = df.fillna(-999)\n# Label Encoding\nfor f in df.columns:\n    if df[f].dtype=='object': \n        lbl = LabelEncoder()\n        lbl.fit(list(df[f].values))\n        df[f] = lbl.transform(list(df[f].values))\n        \nprint('Labelling done.')","cdd02b0c":"df = pd.get_dummies(df)","85654e5f":"import warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import MinMaxScaler,LabelEncoder\nfrom sklearn.model_selection import train_test_split,cross_val_score, KFold\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB, MultinomialNB,BernoulliNB\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, classification_report\n%matplotlib inline","2c60db81":"#Linear regression, first create test and train dataset\nx=df.loc[:,['X','OBJECTID','BLOCK_X','BLOCK_Y','HEIGHTNUM', 'WEIGHTNUM','PSA']].values\ny=df.loc[:,'Y'].values","614f8456":"# Creating a test and training dataset\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.30)","f15382fa":"# Linear regression\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)\nprint(regressor.intercept_)\nprint(regressor.coef_)","dc9a15d7":"#Displaying the difference between the actual and the predicted\ny_pred = regressor.predict(X_test)\ndf_output = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\nprint(df_output)","ce7d01b8":"#Checking the accuracy of Linear Regression\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","889092f0":"plt.figure(figsize=(10,10))\nplt.plot(y_pred,y_test,color='black',linestyle='dashed',marker='*',markerfacecolor='red',markersize=10)\nplt.title('Error analysis')\nplt.xlabel('Predicted values')\nplt.ylabel('Test values')","d0dcee97":"# Cross validation score\nx=df.loc[:,['X','OBJECTID']].values\ny=df.loc[:,'Y'].values\nregressor=LinearRegression()\nmse=cross_val_score(regressor,X_train,y_train,scoring='neg_mean_squared_error',cv=5)\nmse_mean=np.mean(mse)\nprint(mse_mean)\ndiff=metrics.mean_squared_error(y_test, y_pred)-abs(mse_mean)\nprint(diff)","ed8ad21f":"x=df.loc[:,['X']].values\ny=df.loc[:,'Y'].values","189033db":"x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,random_state = 1)\n\n#Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nsc.fit(x_train)\nx_train=sc.transform(x_train)\nx_test=sc.transform(x_test)","720cfa7c":"# KNN Classification\n# sorted(sklearn.neighbors.VALID_METRICS['brute'])\nknn = KNeighborsClassifier(n_neighbors = 17)\nknn.fit(x_train,y_train)\ny_pred=knn.predict(x_test)","94502167":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Be patient. Mar\u00edlia Prata, @mpwolke was Here.' )","7c19c792":"### <b><mark style=\"background-color: #9B59B6\"><font color=\"white\">Background on the National Sex Offenders Registry:<\/font><\/mark><\/b>\n\n\nThe Pam Lychner Sexual Offender Tracking and Identification Act of 1996 (Lychner Act).\n\nThe Jacob Wetterling Crimes Against Children and Sexual Violent Offender Registration Program (1994).\n\nMegan\u2019s Law (1996).\n\nhttps:\/\/www.fbi.gov\/scams-and-safety\/sex-offender-registry","1aaa7ad1":"Since I got ValueError: Unknown label type: 'continuous' I won't perform the rest of the script.","ba7d3950":"![](https:\/\/www.jeffersoncountysheriff.com\/wp-content\/uploads\/2019\/03\/sor.jpg)jeffersoncountysheriff.com","6790876e":"#Codes by Arpita Gupta https:\/\/www.kaggle.com\/arpita28\/analysis-of-spotify-trends","a8e3c667":"It's cool but I have no clue what that chart represents. It seems abstract art.","ee2312b9":"I don't know the meaning of X and Y, though the programm didn't return an error."}}