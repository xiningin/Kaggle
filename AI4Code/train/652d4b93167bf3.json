{"cell_type":{"a550aab6":"code","24baf4ea":"code","8cc9608b":"code","3aefcc12":"code","3b13adb2":"code","ef5041d8":"code","c2372f30":"code","e91ca735":"code","11a23877":"code","9f528216":"code","ffe4782d":"code","4c82695e":"code","f29fa4b1":"code","a70ad5cf":"code","d8b48d67":"code","a6e3459d":"code","726eeb3c":"code","ebd760c4":"code","f0b878f1":"code","68bc8161":"code","ddf82bea":"code","1f6ab03c":"code","3e5b3bb8":"code","2cf7adc1":"code","a78fac29":"code","881c1b13":"code","40951749":"code","612f6aff":"markdown","5ec2d515":"markdown","fe9b0ca3":"markdown","ae335ba9":"markdown","580bd9ba":"markdown","4e37e2ca":"markdown","21d6e1a3":"markdown","c339dac6":"markdown"},"source":{"a550aab6":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom matplotlib.image import imread\n\nfrom sklearn.metrics import classification_report,confusion_matrix\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPool2D\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\n\nimport warnings\nwarnings.filterwarnings('ignore')","24baf4ea":"%%time\nb_d=os.listdir('\/kaggle\/input\/wafermap\/WaferMap\/balanced')\nfor i in b_d:\n   print( i,len(os.listdir('\/kaggle\/input\/wafermap\/WaferMap\/balanced\/'+i)))\nprint(\"==================================================================\")\ntest_d=os.listdir('\/kaggle\/input\/wafertestdata\/B_Test')\nfor i in test_d:\n   print( i,len(os.listdir('\/kaggle\/input\/wafertestdata\/B_Test\/'+i)))","8cc9608b":"b_path='\/kaggle\/input\/wafermap\/WaferMap\/balanced\/'\nsample_wafer=[]\nfor i in b_d:\n    sample_wafer.append(b_path+i+'\/'+os.listdir(b_path+i+'\/')[0])\nsample_wafer\n   ","3aefcc12":"# plt.figure(figsize=(24,12))\nf, axarr = plt.subplots(3,3,figsize=(24,12))\nm=0\nfor i in range(3):\n    for j in range(3):\n        axarr[i,j].imshow(imread(sample_wafer[m]))\n        axarr[i,j].set_title(os.path.basename(sample_wafer[m])) \n        m+=1\n ","3b13adb2":"def dimension(path,dim1,dim2):\n    for image_filename in os.listdir(path): \n        image=imread(path+image_filename)\n        d1,d2,channels=image.shape\n        dim1.append(d1)\n        dim2.append(d2)\n#         print(channels)\n    return dim1,dim2\n\nloc_dim1=[]\nloc_dim2=[]\nloc_dim1,loc_dim2=dimension('\/kaggle\/input\/wafermap\/WaferMap\/balanced\/Loc\/',loc_dim1,loc_dim2)\n\nedgeRing_dim1=[]\nedgeRing_dim2=[]\nedgeRing_dim1,edgeRing_dim2=dimension('\/kaggle\/input\/wafermap\/WaferMap\/balanced\/Edge-ring\/',edgeRing_dim1,edgeRing_dim2)\n\nedgeLoc_dim1=[]\nedgeLoc_dim2=[]\nedgeLoc_dim1,edgeLoc_dim2=dimension('\/kaggle\/input\/wafermap\/WaferMap\/balanced\/Edge-loc\/',edgeLoc_dim1,edgeLoc_dim2)\n\ncenter_dim1=[]\ncenter_dim2=[]\ncenter_dim1,center_dim2=dimension('\/kaggle\/input\/wafermap\/WaferMap\/balanced\/Center\/',center_dim1,center_dim2)\n\nrandom_dim1=[]\nrandom_dim2=[]\nrandom_dim1,random_dim2=dimension('\/kaggle\/input\/wafermap\/WaferMap\/balanced\/Random\/',random_dim1,random_dim2)\n\nscratch_dim1=[]\nscratch_dim2=[]\nscratch_dim1,scratch_dim2=dimension('\/kaggle\/input\/wafermap\/WaferMap\/balanced\/Scratch\/',scratch_dim1,scratch_dim2)\n\nnearFull_dim1=[]\nnearFull_dim2=[]\nnearFull_dim1,nearFull_dim2=dimension('\/kaggle\/input\/wafermap\/WaferMap\/balanced\/Near-Full\/',nearFull_dim1,nearFull_dim2)\n\ndonut_dim1=[]\ndonut_dim2=[]\ndonut_dim1,donut_dim2=dimension('\/kaggle\/input\/wafermap\/WaferMap\/balanced\/Donut\/',donut_dim1,donut_dim2)\n\nnone_dim1=[]\nnone_dim2=[]\nnone_dim1,none_dim2=dimension('\/kaggle\/input\/wafermap\/WaferMap\/balanced\/None\/',donut_dim1,donut_dim2)\n    \n\n","ef5041d8":"np.mean(scratch_dim1)","c2372f30":"\n# img_gen=ImageDataGenerator()\n","e91ca735":"image_gen = ImageDataGenerator(rotation_range=20, # rotate the image 20 degrees\n                               width_shift_range=0.10, # Shift the pic width by a max of 5%\n                               height_shift_range=0.10, # Shift the pic height by a max of 5%\n                               rescale=1\/255, # Rescale the image by normalzing it.\n                               shear_range=0.1, # Shear means cutting away part of the image (max 10%)\n                               zoom_range=0.1, # Zoom in by 10% max\n                               horizontal_flip=True, # Allo horizontal flipping\n                               fill_mode='nearest' # Fill in missing pixels with the nearest filled value\n                              )","11a23877":"plt.imshow(imread(sample_wafer[4]))","9f528216":"plt.imshow(image_gen.random_transform(imread(sample_wafer[4])))","ffe4782d":"train_path='\/kaggle\/input\/wafermap\/WaferMap\/balanced'\ntest_path='\/kaggle\/input\/wafertestdata\/B_Test'\n# image_gen.flow_from_directory(train_path)\n# image_gen.flow_from_directory(test_path)","4c82695e":"batch_size = 16\nimg_shape=(64,65,4)","f29fa4b1":"model = Sequential()\n\n## FIRST SET OF LAYERS\n# CONVOLUTIONAL LAYER\n# POOLING LAYER\nmodel.add(Conv2D(filters=32, kernel_size=(4,4),input_shape=img_shape, activation='relu',))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\n## SECOND SET OF LAYERS\n# CONVOLUTIONAL LAYER\n# POOLING LAYER\nmodel.add(Conv2D(filters=32, kernel_size=(4,4),input_shape=img_shape, activation='relu',))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\n# model.add(Conv2D(filters=32, kernel_size=(4,4),input_shape=img_shape, activation='relu',))\n# model.add(MaxPool2D(pool_size=(2, 2)))\n\n\n# FLATTEN IMAGES FROM 64 by 65 to 4160 BEFORE FINAL LAYER\nmodel.add(Flatten())\n\n# 256 NEURONS IN DENSE HIDDEN LAYER (YOU CAN CHANGE THIS NUMBER OF NEURONS)\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.3))\n# model.add(Dense(128, activation='sigmoid'))\n# model.add(Dropout(0.5))\n# LAST LAYER IS THE CLASSIFIER, THUS 9 POSSIBLE CLASSES\nmodel.add(Dense(9, activation='softmax'))\n\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","a70ad5cf":"model.summary()","d8b48d67":"\nearly_stop = EarlyStopping(monitor='val_loss',patience=5)","a6e3459d":"train_image_gen = image_gen.flow_from_directory(train_path,\n                                               target_size=img_shape[:2],\n                                                color_mode='rgba',\n                                               batch_size=batch_size,\n                                               class_mode='categorical')","726eeb3c":"test_image_gen = image_gen.flow_from_directory(test_path,\n                                               target_size=img_shape[:2],\n                                                color_mode='rgba',\n                                               batch_size=batch_size,\n                                               class_mode='categorical',\n                                              shuffle=False)","ebd760c4":"test_image_gen.class_indices.keys()","f0b878f1":"train_image_gen.class_indices","68bc8161":"results = model.fit_generator(train_image_gen,epochs=50,\n                              validation_data=test_image_gen,\n                             callbacks=[early_stop])","ddf82bea":"target_names=['Center', 'Donut', 'Edge-loc', 'Edge-ring', 'Loc', 'Near-Full', 'None', 'Random', 'Scratch']\nY_pred=model.predict_generator(test_image_gen,855)\ny_pred=np.argmax(Y_pred,axis=1)\n","1f6ab03c":"con_matrix=confusion_matrix(test_image_gen.classes,y_pred)\nplt.figure(figsize=(12, 12))\nax = sns.heatmap(con_matrix, cmap=plt.cm.Greens, annot=True, square=True, xticklabels=target_names, yticklabels=target_names)\nax.set_ylabel('Actual', fontsize=20)\nax.set_xlabel('Predicted', fontsize=20)","3e5b3bb8":"report=classification_report(test_image_gen.classes,y_pred,target_names=target_names,output_dict=True)\npd.DataFrame(report).transpose()","2cf7adc1":"# model.save('to_deploy.h5')","a78fac29":"losses = pd.DataFrame(model.history.history)\nlosses.plot()","881c1b13":"from tensorflow.keras.preprocessing import image\n\nplt.imshow(imread(sample_wafer[6]))","40951749":"eval_image = image.load_img(sample_wafer[6],target_size=img_shape,color_mode='rgba')\neval_image = image.img_to_array(eval_image)\neval_image = np.expand_dims(eval_image, axis=0)\nl=model.predict(eval_image)\nkeys=list(test_image_gen.class_indices.keys())\nprint('wafer defect classifed as '+ str(keys[l.argmax()]))","612f6aff":"# Evaluation \n","5ec2d515":"# Plot sample wafer defects","fe9b0ca3":"## Model Summary\n","ae335ba9":"# Create Model","580bd9ba":"# Confusion and Classification metrics","4e37e2ca":"# Get the dimensions of the images to adjust the Input Shape\n","21d6e1a3":"# Train the model","c339dac6":"# Load the image Data"}}