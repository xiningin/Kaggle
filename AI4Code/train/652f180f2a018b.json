{"cell_type":{"aba5eea4":"code","761a9683":"code","fa862b7f":"code","a44051ee":"code","ea7d8ea9":"code","b32fe6c4":"code","359abacc":"code","3433e155":"code","75fede32":"code","37b3db92":"code","6ec06fa6":"code","9ccba97a":"code","25147054":"code","8a66a4ad":"code","dae37b07":"code","3261e234":"code","d031a088":"code","58093a66":"code","3746211b":"code","0256295b":"code","5720d642":"code","691634ab":"markdown","f01da135":"markdown","1b8c0f59":"markdown","0f9ef761":"markdown","ff58b371":"markdown","c5f1391d":"markdown","a62c0736":"markdown","a3e0bab9":"markdown","3cd38959":"markdown","53a970c6":"markdown","c926743d":"markdown","5e6cc4f8":"markdown","2f2cfa0a":"markdown","59a517f1":"markdown","a056fab7":"markdown","5a251b42":"markdown","7c6f96bc":"markdown","ee4ebc84":"markdown","a8e87383":"markdown","7d4319e5":"markdown"},"source":{"aba5eea4":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","761a9683":"df = pd.read_csv('..\/input\/KNN_Project_Data')","fa862b7f":"df.head() ","a44051ee":"# THIS IS GOING TO BE A VERY LARGE PLOT\nsns.pairplot(df,hue='TARGET CLASS',palette='coolwarm')","ea7d8ea9":"from sklearn.preprocessing import StandardScaler","b32fe6c4":"scaler = StandardScaler()","359abacc":"scaler.fit(df.drop('TARGET CLASS',axis=1))","3433e155":"scaled_features = scaler.transform(df.drop('TARGET CLASS',axis=1))","75fede32":"df_feat = pd.DataFrame(scaled_features,columns=df.columns[:-1])\ndf_feat.head()","37b3db92":"from sklearn.model_selection import train_test_split","6ec06fa6":"X_train, X_test, y_train, y_test = train_test_split(scaled_features,df['TARGET CLASS'],\n                                                    test_size=0.30)","9ccba97a":"from sklearn.neighbors import KNeighborsClassifier","25147054":"knn = KNeighborsClassifier(n_neighbors=1)","8a66a4ad":"knn.fit(X_train,y_train)","dae37b07":"pred = knn.predict(X_test)","3261e234":"from sklearn.metrics import classification_report,confusion_matrix","d031a088":"print(confusion_matrix(y_test,pred))","58093a66":"print(classification_report(y_test,pred))","3746211b":"error_rate = []\n\n# Will take some time\nfor i in range(1,40):\n    \n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))","0256295b":"plt.figure(figsize=(10,6))\nplt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='red', markersize=10)\nplt.title('Error Rate vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","5720d642":"# NOW WITH K=30\nknn = KNeighborsClassifier(n_neighbors=30)\n\nknn.fit(X_train,y_train)\npred = knn.predict(X_test)\n\nprint('WITH K=30')\nprint('\\n')\nprint(confusion_matrix(y_test,pred))\nprint('\\n')\nprint(classification_report(y_test,pred))","691634ab":"**Convert the scaled features to a dataframe and check the head of this dataframe to make sure the scaling worked.**","f01da135":"# Standardize the Variables\n\nTime to standardize the variables.\n\n** Import StandardScaler from Scikit learn.**","1b8c0f59":"# Train Test Split\n\n**Use train_test_split to split your data into a training set and a testing set.**","0f9ef761":"** Fit scaler to the features.**","ff58b371":"**Use the .transform() method to transform the features to a scaled version.**","c5f1391d":"**Create a KNN model instance with n_neighbors=1**","a62c0736":"**Use the predict method to predict values using your KNN model and X_test.**","a3e0bab9":"# Choosing a K Value\nLet's go ahead and use the elbow method to pick a good K Value!\n\n** Create a for loop that trains various KNN models with different k values, then keep track of the error_rate for each of these models with a list. Refer to the lecture if you are confused on this step.**","3cd38959":"# Great Job!","53a970c6":"# Predictions and Evaluations\nLet's evaluate our KNN model!","c926743d":"# K Nearest Neighbors Project\n##This is a project that are part of Data science course offered by Pierian Data. This shows the implemtation of content of the coursework.\n\n\nWelcome to the KNN Project! This will be a simple project very similar to the lecture, except you'll be given another data set. Go ahead and just follow the directions below.\n## Import Libraries\n**Import pandas,seaborn, and the usual libraries.**","5e6cc4f8":"**Now create the following plot using the information from your for loop.**","2f2cfa0a":"** Create a StandardScaler() object called scaler.**","59a517f1":"# EDA\n\nSince this data is artificial, we'll just do a large pairplot with seaborn.\n\n**Use seaborn on the dataframe to create a pairplot with the hue indicated by the TARGET CLASS column.**","a056fab7":"**Fit this KNN model to the training data.**","5a251b42":"## Retrain with new K Value\n\n**Retrain your model with the best K value (up to you to decide what you want) and re-do the classification report and the confusion matrix.**","7c6f96bc":"** Create a confusion matrix and classification report.**","ee4ebc84":"## Get the Data\n** Read the 'KNN_Project_Data csv file into a dataframe **","a8e87383":"# Using KNN\n\n**Import KNeighborsClassifier from scikit learn.**","7d4319e5":"**Check the head of the dataframe.**"}}