{"cell_type":{"1a2832be":"code","ce47b03c":"code","1d268fd2":"code","39055cec":"code","40570d1f":"code","03c883a2":"code","6a237181":"code","754dbc6b":"code","9c2fe346":"code","b13153a6":"code","f4cd233c":"code","caef2478":"code","33194af0":"code","a0b76d34":"code","83a6b8c9":"code","d8c6e19a":"code","8e40f229":"code","d942c2d2":"code","6bbb9da3":"code","a9650103":"code","17b42afd":"code","6035bc32":"code","07b156dd":"code","ac6594ad":"code","39c829b3":"code","5207ca4b":"code","985452a5":"code","a4df2d30":"code","e90d0e24":"code","a13ef3d4":"code","81973730":"code","3b46a9e5":"code","5394c460":"code","79cf6052":"code","f4f029e1":"code","466c3a15":"code","8fba026d":"code","d67842ee":"code","2a3951ff":"code","3d8d4b0b":"code","a028ec28":"code","3f2aaa42":"code","08b83d36":"code","5869d712":"code","b22370bd":"markdown","e865b7bc":"markdown","d472e0ff":"markdown","3c96c381":"markdown","ee289393":"markdown","571efc1c":"markdown","a1042cf2":"markdown"},"source":{"1a2832be":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ce47b03c":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","1d268fd2":"df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf1 = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","39055cec":"df.shape","40570d1f":"#let us get some insights\ndf.describe()","03c883a2":"# counts of the survivors\n# 0 --> Not Survived\n# 1 --> Survived\nsurvived = df['Survived'].value_counts()\nsurvived","6a237181":"#using sns to visualize the survivors\n\n\ngraph = sns.countplot(x='Survived', data=df, palette='Set1')\ni=0\nfor p in graph.patches:\n    height = p.get_height()\n    width = p.get_width()\n    graph.text(p.get_x()+width\/2, height, survived[i],ha='center')\n    i+=1\nplt.show()","754dbc6b":"# survivors based on different columns\ncolumns = ['Pclass', 'Sex', 'Embarked']\nf, axes = plt.subplots(1,3,figsize=(15,6))\ni=0\nfor column in columns:\n    sns.countplot(df[column], hue=df['Survived'], palette='Set1',ax=axes[i])\n    i+=1\nplt.tight_layout()","9c2fe346":"# survival rate by sex\ndf['Survived'].groupby(df['Sex']).mean()\n# it shows the proportion of passengers survived based on gender","b13153a6":"df.pivot_table('Survived', index='Sex', columns='Pclass')","f4cd233c":"f, axes = plt.subplots(1,2, figsize=(12,5))\nsns.barplot(x='Pclass', y='Survived', data=df, palette='summer', ax=axes[0])\nsns.barplot(x='Pclass', y='Survived', hue='Sex', data=df, palette='summer', ax=axes[1])\nplt.tight_layout()","caef2478":"dfy = df.Survived\n\ndf.drop(['PassengerId','Survived','Name','Ticket','Cabin'],axis=1,inplace=True)\ndf1.drop(['PassengerId','Name','Ticket','Cabin'],axis=1,inplace=True)","33194af0":"df.head()","a0b76d34":"df.isnull().sum()","83a6b8c9":"df1.isnull().sum()","d8c6e19a":"df1.head()","8e40f229":"df.describe()","d942c2d2":"df1.describe()","6bbb9da3":"df.Age.isnull().value_counts()","a9650103":"df.Age.fillna(df.Age.median(),inplace=True)","17b42afd":"df1.Age.fillna(df1.Age.median(),inplace=True)","6035bc32":"df.Embarked.fillna(df.Embarked.mode()[0],inplace=True)","07b156dd":"df1.Fare.fillna(df1.Fare.median(),inplace=True)","ac6594ad":"print(df.Age.isnull().value_counts())\nprint(df1.Age.isnull().value_counts())\nprint(df.Embarked.isnull().value_counts())\nprint(df1.Fare.isnull().value_counts())","39c829b3":"from sklearn.preprocessing import LabelEncoder","5207ca4b":"le = LabelEncoder()\n\nle.fit(df.Sex)\nSex_labeled = le.transform(df.Sex)\ndf['Sex_labeled'] = Sex_labeled\ndf.drop(['Sex'],axis=1,inplace=True)\n\nle.fit(df1.Sex)\nSex_labeled = le.transform(df1.Sex)\ndf1['Sex_labeled'] = Sex_labeled\ndf1.drop(['Sex'],axis=1,inplace=True)\n\nle.fit(df.Embarked)\nEmbarked_labeled = le.transform(df.Embarked)\ndf['Embarked_labeled'] = Embarked_labeled\ndf.drop(['Embarked'],axis=1,inplace=True)\n\nle.fit(df1.Embarked)\nEmbarked_labeled = le.transform(df1.Embarked)\ndf1['Embarked_labeled'] = Embarked_labeled\ndf1.drop(['Embarked'],axis=1,inplace=True)","985452a5":"df.head()","a4df2d30":"df1.head()","e90d0e24":"df.info()","a13ef3d4":"df1.info()","81973730":"x = np.array(df)\nx1 = np.array(df1)\ny = np.array(dfy)","3b46a9e5":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nx = scaler.fit_transform(x)\nx1 = scaler.fit_transform(x1)","5394c460":"from sklearn.model_selection import train_test_split","79cf6052":"x_train, x_test, y_train, y_test = train_test_split(df,dfy,test_size = 0.2)","f4f029e1":"print('shape of train and test set : ')\nprint('x_train : ',x_train.shape)\nprint('x_test : ',x_test.shape)\nprint('y_train : ',y_train.shape)\nprint('y_test : ',y_test.shape)","466c3a15":"def models(X_train, y_train):\n    \n    # Logistic Regression\n    from sklearn.linear_model import LogisticRegression\n    lr = LogisticRegression(random_state=420)\n    lr.fit(x_train, y_train)\n    \n    # KNN\n    from sklearn.neighbors import KNeighborsClassifier\n    knn = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n    knn.fit(x_train, y_train)\n    \n    # SVM (linear kernel)\n    from sklearn.svm import SVC\n    svc_lin = SVC(kernel='linear', random_state=420)\n    svc_lin.fit(x_train, y_train)\n    \n    # SVM (rbf kernel)\n    from sklearn.svm import SVC\n    svc_rbf = SVC(kernel='rbf', random_state=420)\n    svc_rbf.fit(x_train, y_train)\n    \n    # Gaussian Naive Bayes\n    from sklearn.naive_bayes import GaussianNB\n    gauss = GaussianNB()\n    gauss.fit(x_train, y_train)\n    \n    # Decision tree classifier\n    from sklearn.tree import DecisionTreeClassifier\n    dtc = DecisionTreeClassifier(criterion='entropy', random_state=420)\n    dtc.fit(x_train, y_train)\n    \n    # Random Forest Classifier\n    from sklearn.ensemble import RandomForestClassifier\n    rfc = RandomForestClassifier(n_estimators=20, criterion='entropy', random_state=420)\n    rfc.fit(x_train, y_train)\n    \n    # Printing training accuracy for each model\n    print('Training accuracy for logistic regression = ', lr.score(x_train, y_train))\n    print('Training accuracy for KNN = ', knn.score(x_train, y_train))\n    print('Training accuracy for SVC(Linear) = ', svc_lin.score(x_train, y_train))\n    print('Training accuracy for SVC(rbf) = ', svc_rbf.score(x_train, y_train))\n    print('Training accuracy for Gaussian Naive Bayes = ', gauss.score(x_train, y_train))\n    print('Training accuracy for Decision Tree Classifier = ', dtc.score(x_train, y_train))\n    print('Training accuracy for Random Forest Classifier = ', rfc.score(x_train, y_train))\n    \n    return lr, knn, svc_lin, svc_rbf, gauss, dtc, rfc","8fba026d":"model = models(x_train, y_train)","d67842ee":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","2a3951ff":"model = keras.Sequential()\nmodel.add(layers.Dense(15, activation=\"relu\", input_shape=(7,)))\nmodel.add(layers.Dense(8, activation=\"relu\")),\nmodel.add(layers.Dense(1,activation=\"sigmoid\"))\n\nmodel.summary()","3d8d4b0b":"model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[keras.metrics.AUC()])\n\nhistory= model.fit(df,dfy,batch_size=32,epochs=100,validation_data=(x_test,y_test))\n\nplt.figure()\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])","a028ec28":"y_pred_nn = model.predict_classes(df1)","3f2aaa42":"Survived = np.squeeze(y_pred_nn)","08b83d36":"PassengerId = np.arange(892,1310)\n\nans = pd.DataFrame(list(zip(PassengerId,Survived)),columns=['PassengerId','Survived'])\nans.head()","5869d712":"ans.to_csv(\"final_ans.csv\",index=False)","b22370bd":"Standardise the data","e865b7bc":"Filling up the nan values","d472e0ff":"Applying test train split and applying various machine learning algorithms to the data","3c96c381":"Encoding Categorical Dta","ee289393":"Visualizing survivors on the basis of different columns","571efc1c":"Survival rate on the basis of gender","a1042cf2":"Let us also solve using ANN "}}