{"cell_type":{"3482c6ca":"code","275f506e":"code","a220997a":"code","2da49af6":"code","04dc9a66":"code","f31d185b":"code","baae7797":"code","b6130150":"code","0456a0b0":"code","7318aeae":"code","4cdae139":"code","64e3b779":"code","b3caac9e":"code","1d1c860c":"code","dc294d7c":"code","58449f50":"code","9ed77e02":"code","876a3d87":"code","e9e75715":"code","7f9c6dcf":"code","9cc44cc1":"code","81b90f39":"markdown"},"source":{"3482c6ca":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n #   for filename in filenames:\n   #     print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","275f506e":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.applications.mobilenet import preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\n%matplotlib inline\nimport matplotlib.pyplot as plt","a220997a":"train_path = \"..\/input\/facespoof\/dataset_2\/dataset_2\/train\/\"\ntest_path = \"..\/input\/facespoof\/dataset_2\/dataset_2\/test\/\"\nIMG_SIZE = 224\nIMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)","2da49af6":"NUM_CLASSES = 2\nCHANNELS = 3\nIMAGE_RESIZE = 224\nPOOLING_AVERAGE = 'avg'\nDENSE_LAYER_ACTIVATION = 'softmax'\nOBJECTIVE_FUNCTION = 'categorical_crossentropy'\nLOSS_METRICS = ['accuracy']\nNUM_EPOCHS = 20\nEARLY_STOP_PATIENCE = 3\nSTEPS_PER_EPOCH_TRAINING = 100\nSTEPS_PER_EPOCH_VALIDATION = 100\nBATCH_SIZE_TRAINING =743\nBATCH_SIZE_VALIDATION = 185\nBATCH_SIZE_TESTING = 1","04dc9a66":"from tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense","f31d185b":"model = Sequential()\nmodel.add(MobileNetV2(include_top = False, pooling = POOLING_AVERAGE, weights = 'imagenet'))\nmodel.add(Dense(NUM_CLASSES, activation = DENSE_LAYER_ACTIVATION))\nmodel.layers[0].trainable = False","baae7797":"model.summary()","b6130150":"from tensorflow.python.keras import optimizers\nsgd = optimizers.SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\nmodel.compile(optimizer = sgd, loss = OBJECTIVE_FUNCTION, metrics = LOSS_METRICS)\nimage_size = IMAGE_RESIZE","0456a0b0":"from keras.applications.mobilenet import preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\nimage_size = IMAGE_RESIZE\ndata_generator = ImageDataGenerator(preprocessing_function=preprocess_input)","7318aeae":"\n\ntrain_generator = data_generator.flow_from_directory(\n        '..\/input\/facespoof\/dataset_2\/dataset_2\/train',\n        target_size=(image_size, image_size),\n        batch_size=BATCH_SIZE_TRAINING,\n        class_mode='categorical')\nprint(train_generator.class_indices)\n\nvalidation_generator = data_generator.flow_from_directory(\n        '..\/input\/facespoof\/dataset_2\/dataset_2\/train',\n        target_size=(image_size, image_size),\n        batch_size=BATCH_SIZE_VALIDATION,\n        class_mode='categorical') \n","4cdae139":"datagen = ImageDataGenerator(validation_split=0.2, rescale=1.\/255)\nTRAIN_DIR='..\/input\/facespoof\/dataset_2\/dataset_2\/train'\ntrain_generator = datagen.flow_from_directory(\n    TRAIN_DIR, \n    subset='training'\n)\nprint(train_generator.class_indices)\nval_generator = datagen.flow_from_directory(\n    TRAIN_DIR,\n    subset='validation'\n)\nprint(train_generator.class_indices)","64e3b779":"from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\ncb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = EARLY_STOP_PATIENCE)\ncb_checkpointer = ModelCheckpoint(filepath = '..\/working\/best.hdf5', monitor = 'val_loss', save_best_only = True, mode = 'auto')","b3caac9e":"\nfit_history = model.fit_generator(\n        train_generator,\n        steps_per_epoch=500,\n        epochs = 50,\n        validation_data=validation_generator,\n        validation_steps=STEPS_PER_EPOCH_VALIDATION,\n        callbacks=[cb_checkpointer, cb_early_stopper]\n)\nmodel.save(\"..\/working\/mn2.hdf5\")\nmodel.load_weights(\"..\/working\/best.hdf5\")","1d1c860c":"from IPython.display import FileLink\nFileLink(\"..\/working\/best.hdf5\")","dc294d7c":"plt.figure(1, figsize = (20,8)) \nplt.subplot(221)  \nplt.plot(fit_history.history['acc'])  \nplt.plot(fit_history.history['val_acc'])  \nplt.title('model accuracy')  \nplt.ylabel('accuracy')  \nplt.xlabel('epoch')  \nplt.legend(['train', 'valid']) \n    \nplt.subplot(222)  \nplt.plot(fit_history.history['loss'])  \nplt.plot(fit_history.history['val_loss'])  \nplt.title('model loss')  \nplt.ylabel('loss')  \nplt.xlabel('epoch')  \nplt.legend(['train', 'valid']) \nplt.show()","58449f50":"test_generator = data_generator.flow_from_directory(\n    directory = '..\/input\/facespoof\/dataset_2\/dataset_2\/test',\n    target_size = (image_size, image_size),\n    batch_size = BATCH_SIZE_TESTING,\n    class_mode = None,\n    shuffle = False,\n    seed = 123\n)","9ed77e02":"# Reset before each call to predict\n#test_generator.reset()\n\n#pred = model.predict_generator(test_generator, steps = len(test_generator), verbose = 1)\n\n#predicted_class_indices = np.argmax(pred, axis = 1)","876a3d87":"\"\"\"\"\nkk=[]\nkk1=predicted_class_indices*1\nfor aa in range(len(test_generator.filenames)):\n    if test_generator.filenames[aa][0:4]=='fake':\n        kk.append(0)\n    else:\n        kk.append(1)\nCC=0;\nCC1=0;\nCC2=0\nCC3=0;\nfor aa in range(len(test_generator.filenames)):\n    if kk1[aa]==kk[aa]==1:\n        CC=CC+1\n    if kk1[aa]==0 and kk[aa]==0:\n        CC1=CC1+1\n    if kk1[aa]==1 and kk[aa]==0:\n        CC2=CC2+1\n    if kk1[aa]==0 and kk[aa]==1:\n        CC3=CC3+1\nprint('accuracy is', (CC+CC1)\/124000)\nprint(CC,CC1,CC2,CC3)\n\"\"\"\"\"\"","e9e75715":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\n#import keras\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense\n#from keras.applications.mobilenet import preprocess_input\nfrom tensorflow.keras.applications.mobilenet import preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport tensorflow\nimport numpy as np\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import load_model","7f9c6dcf":"\nmodel1 = load_model(\"..\/working\/mn2.hdf5\")\n\nimg = image.load_img('..\/input\/facespoof\/dataset_2\/dataset_2\/test\/real\/1050.jpg')\n\nfrom timeit import default_timer as timer\nstart = timer()\n\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\npreds = model.predict(x)\npreds1=model.predict(x)\nprint(preds)\nprint(preds1)\nend = timer()\nprint(end - start, 'second')","9cc44cc1":"model1 = load_model('..\/working\/mn2.hdf5')","81b90f39":"**Parameters**"}}