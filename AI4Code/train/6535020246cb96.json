{"cell_type":{"b91609ad":"code","784c16f5":"code","d0a511c8":"code","d1884df1":"code","2896304b":"code","4d662bc4":"code","b1e50583":"code","abec837c":"code","82547bd1":"code","35bf9061":"code","6ac8266d":"code","4da8ec58":"code","3386a9c4":"code","a34b78af":"code","1f92ddc8":"code","ef20f28a":"code","87bfdfd7":"code","29851daf":"code","ea61e57b":"code","5a711353":"code","d7139820":"markdown","d960c9d5":"markdown","4845887e":"markdown","562aca7e":"markdown","e43e82c0":"markdown","9d7fb651":"markdown","ae46309b":"markdown","5f838dbc":"markdown","b4f469c2":"markdown","20f12ca6":"markdown","141c3f91":"markdown","4fae0072":"markdown","49f414f4":"markdown","55f89536":"markdown","f227962e":"markdown","0ce58e88":"markdown","b299196f":"markdown"},"source":{"b91609ad":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","784c16f5":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport cv2\nimport os\nfrom tqdm import tqdm\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Model,Sequential, Input, load_model\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D, GlobalAveragePooling2D\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom keras.applications import NASNetLarge","d0a511c8":"disease_types=['COVID', 'non-COVID']\ndata_dir = '\/kaggle\/input\/sarscov2-ctscan-dataset\/'\ntrain_dir = os.path.join(data_dir)","d1884df1":"train_data = []\nfor defects_id, sp in enumerate(disease_types):\n    for file in os.listdir(os.path.join(train_dir, sp)):\n        train_data.append(['{}\/{}'.format(sp, file), defects_id, sp])\n        \ntrain = pd.DataFrame(train_data, columns=['File', 'DiseaseID','Disease Type'])\ntrain.head()","2896304b":"\nSEED = 42\ntrain = train.sample(frac=1, random_state=SEED) \ntrain.index = np.arange(len(train)) # Reset indices\ntrain.head()","4d662bc4":"\nplt.hist(train['DiseaseID'])\nplt.title('Frequency Histogram of Species')\nplt.figure(figsize=(12, 12))\nplt.show()","b1e50583":"\ndef plot_defects(defect_types, rows, cols):\n    fig, ax = plt.subplots(rows, cols, figsize=(12, 12))\n    defect_files = train['File'][train['Disease Type'] == defect_types].values\n    n = 0\n    for i in range(rows):\n        for j in range(cols):\n            image_path = os.path.join(data_dir, defect_files[n])\n            ax[i, j].set_xticks([])\n            ax[i, j].set_yticks([])\n            ax[i, j].imshow(cv2.imread(image_path))\n            n += 1\n# Displays first n images of class from training set\nplot_defects('COVID', 5, 5)","abec837c":"\ndef plot_defects(defect_types, rows, cols):\n    fig, ax = plt.subplots(rows, cols, figsize=(12, 12))\n    defect_files = train['File'][train['Disease Type'] == defect_types].values\n    n = 0\n    for i in range(rows):\n        for j in range(cols):\n            image_path = os.path.join(data_dir, defect_files[n])\n            ax[i, j].set_xticks([])\n            ax[i, j].set_yticks([])\n            ax[i, j].imshow(cv2.imread(image_path))\n            n += 1\n# Displays first n images of class from training set\nplot_defects('non-COVID', 5, 5)","82547bd1":"IMAGE_SIZE = 64\ndef read_image(filepath):\n    return cv2.imread(os.path.join(data_dir, filepath)) # Loading a color image is the default flag\n# Resize image to target size\ndef resize_image(image, image_size):\n    return cv2.resize(image.copy(), image_size, interpolation=cv2.INTER_AREA)","35bf9061":"X_train = np.zeros((train.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3))\nfor i, file in tqdm(enumerate(train['File'].values)):\n    image = read_image(file)\n    if image is not None:\n        X_train[i] = resize_image(image, (IMAGE_SIZE, IMAGE_SIZE))\n# Normalize the data\nX_Train = X_train \/ 255.\nprint('Train Shape: {}'.format(X_Train.shape))","6ac8266d":"Y_train = train['DiseaseID'].values\nY_train = to_categorical(Y_train, num_classes=2)","4da8ec58":"BATCH_SIZE = 64\n\n# Split the train and validation sets \nX_train, X_val, Y_train, Y_val = train_test_split(X_Train, Y_train, test_size=0.2, random_state=SEED)","3386a9c4":"fig, ax = plt.subplots(1, 3, figsize=(15, 15))\nfor i in range(3):\n    ax[i].set_axis_off()\n    ax[i].imshow(X_train[i])\n    ax[i].set_title(disease_types[np.argmax(Y_train[i])])","a34b78af":"EPOCHS = 50\nSIZE=64\nN_ch=3","1f92ddc8":"def build_densenet():\n     densenet = ResNet50(weights='imagenet',include_top=False) \n\n    input = Input(shape=(SIZE, SIZE, N_ch))\n    x = Conv2D(3, (3, 3), padding='same')(input)\n    \n    x = densenet.output(x)\n    \n    x = GlobalAveragePooling2D()(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(256, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    \n    for layer in densenet.layers:\n     layer.trainable = False\n    \n    #MAIN CODE----------------------------------------\n#     x = Conv2D(3, (3, 3), padding='same')(input)\n    \n#     x = densenet(x)\n    \n#     x = GlobalAveragePooling2D()(x)\n#     x = BatchNormalization()(x)\n#     x = Dropout(0.5)(x)\n#     x = Dense(256, activation='relu')(x)\n#     x = BatchNormalization()(x)\n#     x = Dropout(0.5)(x)\n\n     #-----------------------------------------------\n    \n    \n    base_model = vgg.VGG16(weights='imagenet', \n                       include_top=False)\n    \n    last = base_model.get_layer('block3_pool').output\n    \n    x = GlobalAveragePooling2D()(last)\n    \n    \n\n\n    # multi output\n    output = Dense(2,activation = 'softmax', name='root')(x)\n \n\n    # model\n    model = Model(densenet.input,output)\n    \n    optimizer = Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=0.1, decay=0.0)\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n    model.summary()\n    \n    return model","ef20f28a":"model = build_densenet()\nannealer = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1, min_lr=1e-3)\ncheckpoint = ModelCheckpoint('model.h5', verbose=1, save_best_only=True)\n# Generates batches of image data with data augmentation\ndatagen = ImageDataGenerator(rotation_range=360, # Degree range for random rotations\n                        width_shift_range=0.2, # Range for random horizontal shifts\n                        height_shift_range=0.2, # Range for random vertical shifts\n                        zoom_range=0.2, # Range for random zoom\n                        horizontal_flip=True, # Randomly flip inputs horizontally\n                        vertical_flip=True) # Randomly flip inputs vertically\n\ndatagen.fit(X_train)\n# Fits the model on batches with real-time data augmentation\nhist = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=BATCH_SIZE),\n               steps_per_epoch=X_train.shape[0] \/\/ BATCH_SIZE,\n               epochs=EPOCHS,\n               verbose=2,\n               callbacks=[annealer, checkpoint],\n               validation_data=(X_val, Y_val))","87bfdfd7":"#model = load_model('..\/output\/kaggle\/working\/model.h5')\nfinal_loss, final_accuracy = model.evaluate(X_val, Y_val)\nprint('Final Loss: {}, Final Accuracy: {}'.format(final_loss, final_accuracy))","29851daf":"Y_pred = model.predict(X_val)\n\nY_pred = np.argmax(Y_pred, axis=1)\nY_true = np.argmax(Y_val, axis=1)\n\ncm = confusion_matrix(Y_true, Y_pred)\nplt.figure(figsize=(12, 12))\nax = sns.heatmap(cm, cmap=plt.cm.Greens, annot=True, square=True, xticklabels=disease_types, yticklabels=disease_types)\nax.set_ylabel('Actual', fontsize=40)\nax.set_xlabel('Predicted', fontsize=40)","ea61e57b":"# accuracy plot \nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\n# loss plot\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","5a711353":"from skimage import io\nfrom keras.preprocessing import image\n#path='imbalanced\/Scratch\/Scratch_400.jpg'\nimg = image.load_img('\/kaggle\/input\/sarscov2-ctscan-dataset\/SARS-Cov-2\/COVID\/Covid (1010).png', grayscale=False, target_size=(64, 64))\nshow_img=image.load_img('\/kaggle\/input\/sarscov2-ctscan-dataset\/SARS-Cov-2\/COVID\/Covid (1010).png', grayscale=False, target_size=(200, 200))\ndisease_class=['Covid-19','Non Covid-19']\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis = 0)\nx \/= 255\n\ncustom = model.predict(x)\nprint(custom[0])\n\nplt.imshow(show_img)\nplt.show()\n\na=custom[0]\nind=np.argmax(a)\n        \nprint('Prediction:',disease_class[ind])","d7139820":"## Image Read and Resize Function","d960c9d5":"## Data","4845887e":"## Plot a histogram","562aca7e":"## Prediction from Image","e43e82c0":"## Train Test Splitting","9d7fb651":"## If you like this notebook please upvote. Thanks","ae46309b":"## Accuracy and Loss Curve","5f838dbc":"## Display images of non-COVID","b4f469c2":"## Final Loss and Accuracy","20f12ca6":"## Training Images","141c3f91":"## Data Augmentation and Fitting Model ","4fae0072":"## Randomize the order of training set","49f414f4":"## DenseNet121 Model","55f89536":"## 64*64 training images","f227962e":"## Converting Labels to Categorical","0ce58e88":"## Confusion Matrix","b299196f":"## Display images of COVID"}}