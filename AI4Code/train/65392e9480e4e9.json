{"cell_type":{"19049963":"code","e430f024":"code","3d2e5072":"code","3b2e51e6":"code","aa7a6f6f":"code","8bc9bdd9":"code","c6061461":"code","be479a9e":"code","154c8370":"code","06193520":"code","9f78fb20":"code","7fedb920":"code","ba11e840":"code","551ef529":"code","9406c6a2":"markdown"},"source":{"19049963":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e430f024":"#data loading\ntest = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")\ntrain = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")","3d2e5072":"import keras\nfrom sklearn.model_selection import train_test_split\nimport time\nfrom keras.utils import to_categorical\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten,Conv2D, MaxPool2D, BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n","3b2e51e6":"train.shape","aa7a6f6f":"#train\nX = train.drop(\"label\",axis=1)\nX = X.values.reshape(-1,28,28,1)\n#You can use (train.shape[0],28,28,1) or (42000,28,28,1). All of them are same.\ny = to_categorical(train[\"label\"]) \n# Dataset include 10 different number so shape of y will be (42000,10)\n# Each column represents one number. The name of process is one - hot encoding.\nX.shape, y.shape","8bc9bdd9":"#test\ntest= test.values.reshape(-1,28,28,1)","c6061461":"#To scale\nX=X\/255\ntest = test\/255","be479a9e":"#train test split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.1, random_state = 1845)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","154c8370":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","06193520":"\n#Augmentation\ndatagen = ImageDataGenerator(\n                            rotation_range=40,\n                            zoom_range=0.2,\n                            width_shift_range=0.1,\n                            height_shift_range=0.1,\n                            horizontal_flip=True,\n                            vertical_flip=True\n                            )\n\ndatagen.fit(X_train)","9f78fb20":"#training model\n\n#Model\nbatch_size = 128\nnum_classes = 10\nepochs = 500\ncnn_mdl = Sequential()\n\ncnn_mdl.add(Conv2D(32, (3,3), strides = 1, padding = \"same\", activation = \"relu\", input_shape = (28,28,1)))\n\ncnn_mdl.add(BatchNormalization())\n\ncnn_mdl.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n\ncnn_mdl.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n\ncnn_mdl.add(Dropout(0.1))\n\ncnn_mdl.add(BatchNormalization())\n\ncnn_mdl.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n\ncnn_mdl.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n\ncnn_mdl.add(BatchNormalization())\n\ncnn_mdl.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n\ncnn_mdl.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n\ncnn_mdl.add(Dropout(0.2))\n\ncnn_mdl.add(BatchNormalization())\n\ncnn_mdl.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n\ncnn_mdl.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n\ncnn_mdl.add(Dropout(0.2))\n\ncnn_mdl.add(BatchNormalization())\n\ncnn_mdl.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n\n\ncnn_mdl.add(Flatten())\ncnn_mdl.add(Dense(128, activation = \"relu\"))\n\ncnn_mdl.add(Dense(num_classes, activation = \"softmax\"))\ncnn_mdl.compile(optimizer = \"rmsprop\" , loss = 'binary_crossentropy' , metrics = ['accuracy'])\ncnn_mdl.summary()","7fedb920":"datagen_train = datagen.flow(X_train,y_train, batch_size=32)\ndatagen_Validation = datagen.flow(X_test,y_test)","ba11e840":"cnn_mdl.fit(datagen_train,\n                      epochs = 50, \n                      validation_data=datagen_Validation,\n                      callbacks=[learning_rate_reduction])","551ef529":"#Prediction\npred_test = cnn_mdl.predict(test)\npred_test = np.argmax(pred_test, axis = 1)\n\n#Submission\nsubmissions = pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")\nsubmissions['Label'] = pred_test\nsubmissions.to_csv('submission.csv', index = False)","9406c6a2":"> ##### I will try to implement what I learned from udemy lessons. \nThank you [Merve Ayyuce Kiraz](https:\/\/www.udemy.com\/course\/derin-ogrenmeye-giris\/) for what I learned. "}}