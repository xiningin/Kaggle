{"cell_type":{"6097b720":"code","85edc68a":"code","30952ddd":"code","1b3ae60a":"code","cac7b463":"code","49ce8e1b":"code","0bb59015":"code","4850f884":"code","599203f1":"code","d0d7b5f3":"code","52b91a4e":"code","abf78a1c":"code","f63b8985":"code","09fa55bc":"code","ff2f3915":"code","b59a6693":"code","b99f0299":"code","8c6f7424":"code","f6268461":"code","256e9b3f":"code","1b8a9999":"code","76629ab1":"code","67b567c7":"code","96973d8b":"code","33e22e49":"code","071de3d1":"code","c5eb8f81":"code","90b59cce":"code","9f0b79a5":"code","95c70e7f":"code","1dbe591a":"code","c2394821":"code","49370598":"code","8decf0d8":"markdown"},"source":{"6097b720":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","85edc68a":"print(os.listdir(\"..\/input\/training\"))\nprint(os.listdir(\"..\/input\/test\"))","30952ddd":"train = pd.read_csv('..\/input\/training\/training.csv')","1b3ae60a":"train.head().T","cac7b463":"#train['Image'][0]\nprint('size of traning data {}'.format(len(train)))\nprint('Missing vlaue col ')\nprint(train.isnull().any().value_counts())\ntrain.isnull().sum().sort_values(ascending=False)","49ce8e1b":"#ffill which fills the place with value in the Forward index or Previous\/Back respectively.\n\ntrain.fillna(method='ffill',inplace=True)\n#check missig col\ntrain.isnull().any().value_counts()","0bb59015":"len(train)","4850f884":"# convert image col to int  also check NaN\nimage_list=[]\n\nfor i in train['Image']:\n    i=i.split(' ')\n    image_list.append(i)\nlen(image_list)\n\n","599203f1":"len(image_list[0])\n","d0d7b5f3":"#covert to arry\nimage_list = np.array(object=image_list,dtype=float)","52b91a4e":"images=image_list.reshape(-1,96,96,1)","abf78a1c":"plt.imshow(image_list.reshape(-1,96,96)[3010],cmap='gray')\n\n","f63b8985":"IMAGE_HEIGHT=96\nIMAGE_WIDTH=96\n#Ytrain.iloc[3010][Ytrain.iloc[3010].index[1]]\n#np.dtype(Ytrain.iloc[3010]['left_eye_center_y'])\ndef img_show(image_list,train):\n    fig,axes = plt.subplots(nrows=5,ncols=2,dpi=300,figsize=(12,12))\n\n    for row in range(5):\n        for col in range(1):\n            #random number  generator for diff image\n            j  =np.random.randint(0,len(train))\n            X = image_list.reshape(-1,96,96)[j]\n            Y = train\n\n            Y=Y.iloc[j]# location of Y\n            img = np.copy(X) #copy image\n            for i in range(0,30,2):\n            #print(Y[Y.index[i+1]])\n                   if 0 < Y[Y.index[i]] < IMAGE_WIDTH and  0 < Y[Y.index[i+1]] < IMAGE_HEIGHT:\n                    img[int(Y[Y.index[i+1]]),int(Y[Y.index[i]])] = 255\n            axes[row,col].imshow(img,cmap='gray')\n            axes[row,col+1].imshow(X,cmap='gray')\n            #remove axies\n            axes[row,col].axis('off')\n            axes[row,col+1].axis('off')\n\n    plt.tight_layout()\n","09fa55bc":"img_show(image_list,train.drop(labels='Image',axis=1))","ff2f3915":"y_train=train.drop(labels='Image',axis=1)\ny_train.shape","b59a6693":"X_train=images\nX_train.shape\n#lenght of tensor has 4 index","b99f0299":"X_train=X_train\/255\nX_train[1]","8c6f7424":"\nimport tensorflow as tf\nmodel= tf.keras.models.Sequential(\n    \n    layers=[\n        \n         #convolution 1st time\n        tf.keras.layers.Conv2D(filters=32,kernel_size=(3,3),activation=tf.nn.relu,input_shape=(96,96,1)),\n        tf.keras.layers.MaxPool2D(2,2),\n     \n         #convolution 2nd time\n        tf.keras.layers.Conv2D(filters=32,kernel_size=(3,3),activation=tf.nn.relu,input_shape=(96,96,1)),\n        tf.keras.layers.MaxPool2D(2,2),\n       \n         #convolution 2nd time\n        tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),activation=tf.nn.relu,input_shape=(96,96,1)),\n        tf.keras.layers.MaxPool2D(2,2),\n      \n        #input layer\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(units=526,activation='relu'),\n        tf.keras.layers.Dense(units=526,activation='relu'),\n        tf.keras.layers.Dropout(0.3),\n        \n\n        # number of keypoint\n        tf.keras.layers.Dense(units=30,activation='relu')\n    ]\n)","f6268461":"model.summary()","256e9b3f":"model.compile(optimizer='adam',\n             loss='mse',\n              metrics=['acc'])","1b8a9999":"hist=model.fit(x=X_train,y=y_train,batch_size=128,epochs=200,verbose=2,validation_split=0.2)\nhist","76629ab1":"from sklearn.metrics import r2_score\n\n","67b567c7":"y_pred =model.predict(X_train)\n\nscore = r2_score(y_train,y_pred)\nscore","96973d8b":"\nplt.figure(figsize=(20,10))\nloss=hist.history['loss']\nval_loss=hist.history['val_loss']\ny=np.arange(1,201)\nplt.plot(y,loss,'b',label='train')\nplt.plot(y,val_loss,'r',label='val')\nplt.xlabel('epoch')\nplt.ylabel('loss')\n\nplt.legend()\n\nplt.legend()","33e22e49":"test = pd.read_csv('..\/input\/test\/test.csv')","071de3d1":"y=np.arange(1,501)","c5eb8f81":"# convert image col to int  also check NaN\nimage_list=[]\n\nfor i in test['Image']:\n    i=i.split(' ')\n    image_list.append(i)\nlen(image_list)","90b59cce":"image_list=np.array(image_list,dtype=float)\nimages=image_list.reshape(-1,96,96,1)\nX_test =images\/255.0\n","9f0b79a5":"predicted_value =model.predict(X_test)","95c70e7f":"pv =pd.DataFrame(data=predicted_value)\nimg_show(image_list,pv)","1dbe591a":"pred = model.predict(X_test)\nlookid_data = pd.read_csv('..\/input\/IdLookupTable.csv')\nlookid_list = list(lookid_data['FeatureName'])\nimageID = list(lookid_data['ImageId']-1)\npre_list = list(pred)\nrowid = lookid_data['RowId']\nrowid=list(rowid)\nfeature = []\nfor f in list(lookid_data['FeatureName']):\n    feature.append(lookid_list.index(f))\npreded = []\nfor x,y in zip(imageID,feature):\n    preded.append(pre_list[x][y])\nrowid = pd.Series(rowid,name = 'RowId')\n\nloc = pd.Series(preded,name = 'Location')\n\nsubmission = pd.concat([rowid,loc],axis = 1)\nsubmission.to_csv('submision.csv',index = False)","c2394821":"df=pd.read_csv('submision.csv')","49370598":"df","8decf0d8":"**Overfitting** if: training loss << validation loss\n\n**Underfitting** if: training loss >> validation loss or Underfitting \u2013 Validation and training error high\n\n**Good fit** if training loss ~ validation loss(Validation error low, slightly higher than the training error)"}}