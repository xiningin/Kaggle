{"cell_type":{"f6579445":"code","86465616":"code","cb79586e":"code","df106ce3":"code","10688c4c":"code","c003091b":"code","e82ca5df":"code","f74c6d6b":"code","bccfdc3b":"code","aeccf158":"code","3a16215c":"code","25f927aa":"code","f8ebd479":"code","2586346e":"code","ce237068":"code","0f0c2200":"code","ab38ffad":"code","1f61d8ae":"code","11a4f67c":"markdown","2b0adc78":"markdown","c62b346d":"markdown","db67e937":"markdown","13b9f8f4":"markdown","738eeb69":"markdown","8c058ebd":"markdown","1924e25b":"markdown","f7a3e1d8":"markdown","00f001ed":"markdown","8df824a6":"markdown","bc55e233":"markdown","9fb2a60e":"markdown","4ae797a6":"markdown","61e8e068":"markdown","4fbaafad":"markdown","458c5991":"markdown","cedc5e5c":"markdown","d09ebc04":"markdown","09205341":"markdown","a429c645":"markdown","8ef0827d":"markdown","4f50381e":"markdown"},"source":{"f6579445":"import pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn import metrics\n","86465616":"\nflight_df = pd.read_csv('\/kaggle\/input\/flight-delays\/flights.csv')\nflight_df","cb79586e":"flight_df = pd.read_csv('\/kaggle\/input\/flight-delays\/flights.csv', low_memory=False)\nflight_df","df106ce3":"flight_df = flight_df[0:100000]\nflight_df.info()","10688c4c":"flight_df.value_counts('DIVERTED')","c003091b":"sns.jointplot(data = flight_df, x = \"SCHEDULED_ARRIVAL\", y = \"ARRIVAL_TIME\")","e82ca5df":"flight_df.corr()","f74c6d6b":"flight_df = flight_df.drop(['YEAR','FLIGHT_NUMBER','AIRLINE','DISTANCE','TAIL_NUMBER','TAXI_OUT', 'SCHEDULED_TIME','DEPARTURE_TIME','WHEELS_OFF','ELAPSED_TIME', 'AIR_TIME','WHEELS_ON','DAY_OF_WEEK','TAXI_IN','CANCELLATION_REASON'], axis=1)","bccfdc3b":"flight_df[flight_df.columns[1:]].corr()['ARRIVAL_DELAY'][:].sort_values(ascending=False)","aeccf158":"flight_df.isna().sum()","3a16215c":"flight_df = flight_df.fillna(flight_df.mean())\nflight_df.isna().sum()","25f927aa":"result = []\nfor row_value in flight_df['ARRIVAL_DELAY']:\n    if row_value > 15:\n        result.append(1)\n    else:\n        result.append(0) \n        \nflight_df['Result']  = result\nflight_df.tail(10)","f8ebd479":"flight_df['Result'].value_counts()","2586346e":"flight_df = flight_df.drop(['ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'ARRIVAL_TIME', 'ARRIVAL_DELAY'],axis=1)\n","ce237068":"flight_df = flight_df.values\n\n# X consists all independent varibles.\n# y consists dependent variable.\nX, y = flight_df[:,:-1], flight_df[:,-1]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state = 42)","0f0c2200":"scaled_features = StandardScaler().fit_transform(X_train, X_test)","ab38ffad":"clf = DecisionTreeClassifier()\nclf = clf.fit(X_train,y_train)","1f61d8ae":"pred = clf.predict_proba(X_test)\nauc_score = roc_auc_score(y_test, pred[:,1])\nauc_score","11a4f67c":"# Data Cleaning and Preprocessing\n\nAs we have already removed the least correlated variables, now let's find out the variable which ","2b0adc78":"Further for model training and testing purpose, let's split dataset with test size as 30%.","c62b346d":"# Model Prediction \nAUC score of Model","db67e937":"Let's find out number of flights delayed.","13b9f8f4":"From the above we can see that there are a number of unwwanted features (i.e not highly correlated).\n\nLet's drop these variables. \n- 'YEAR'\n- 'FLIGHT_NUMBER'\n- 'AIRLINE'\n- 'DISTANCE'\n- 'TAIL_NUMBER','TAXI_OUT'\n- 'SCHEDULED_TIME'\n- 'DEPARTURE_TIME'\n- 'WHEELS_OFF'\n- 'ELAPSED_TIME'\n- 'AIR_TIME'\n- 'WHEELS_ON'\n- 'DAY_OF_WEEK'\n- 'TAXI_IN'\n- 'CANCELLATION_REASON'","738eeb69":"Let's print the correlation of features with 'ARRIVAL_DELAY' and then we will find the feature which has the highest correlation with the 'ARRIVAL_DELAY'","8c058ebd":"Notice that the data types of all the above features is Numerical. In order to handle these missing values we will replace the 'Null' values with mean values.","1924e25b":"# Model Creation\n\nWe will consider only following features for Model Building.\n>'MONTH', 'DAY', 'SCHEDULED_DEPARTURE', 'DEPARTURE_DELAY', 'SCHEDULED_ARRIVAL', 'DIVERTED', 'CANCELLED', 'AIR_SYSTEM_DELAY','SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY','WEATHER_DELAY', 'Result'\n\nand dropping other variables.","f7a3e1d8":"In order to build a predictive machine learning classification model, we need one or more independent variables and one dependent variable. \nIn the dataset we donot have any independent variable which serves the purspose as the result if flight is delayed or not.\n\nSo, let's create a variable named 'Result' which takes the value 0 and 1. \n- '0' : flight not delayed and \n- '1' : flight delayed.\nThese values will be imputed by using the condition if 'ARRIVAL_DELAY' is greater than 15 then impute '1'(flight delayed) else '0'.","00f001ed":"## Data Collection","8df824a6":"Now, to further analyse the data we will take a sampple of 100000 rows.","bc55e233":"So, from the top 10,000 sample data set, we have 224 number of flights got diverted. Moving on!\n\n## EDA\nSome key points:\n- [Exploratory Data Analysis (EDA)](https:\/\/www.itl.nist.gov\/div898\/handbook\/eda\/section1\/eda11.htm) is an approach\/philosophy for data analysis that employs a variety of techniques (mostly graphical) to:\n    - maximize insight into a data set\n    - uncover underlying structure\n    - extract important variables\n    - detect outliers and anomalies\n    - test underlying assumptions\n    - develop parsimonious models\n    - determine optimal factor settings. \n    \n\n\nNow, let's analyse the dataset using pairplots, jointplots using Seaborn module. \n- [Seaborn](https:\/\/towardsdatascience.com\/data-visualization-using-seaborn-fc24db95a850) is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics.\n\n\nLet's plot the jointplot between 'SCHEDULED_ARRIVAL' and 'ARRIVAL_TIME'.","9fb2a60e":"## Importing Libraries\nLet's import some important libraries to start with. Further we will keep on adding other libraries as required.","4ae797a6":"Now, we will calculate correlation among the variables to see the strength of association\/relation between them.\n\n### More about [Correlation](https:\/\/medium.com\/analytics-vidhya\/what-is-correlation-4fe0c6fbed47).","61e8e068":"Let's read the data. Notice that file size is huge (approximately 565MB).","4fbaafad":"Let's find out the number of flights diverted in the sample data. We will find this using unique counts of 'DIVERTED' columns. There are two values in the diverted column. In Diverted column, value 0 indicates Not Diverted and value 1 indicates Diverted.","458c5991":"It can be seen that a total of 36,221 flights got delayed out of 100,000 samples that we have taken.","cedc5e5c":"DecisionTreeClassifier to model the dataset. ","d09ebc04":"Reference: [https:\/\/www.kaggle.com\/hrishikeshmalkar\/flight-delay-prediction](https:\/\/www.kaggle.com\/hrishikeshmalkar\/flight-delay-prediction)","09205341":"As it can be seen that feature 'DEPARTURE_DELAY' has the highest correlation with 'ARRIVAL_DELAY'.\n\nMoving on!","a429c645":"Now we will use StandardScaler() class to fit and transform","8ef0827d":"It shows a warning that datatypes used is of mixed type. To resolve this we will set the low_memory parameter as False.\n\nTo know more about this warning\/error, follow the link below.\n\n*StackOverflow: \"[StackOverflow: Pandas read_csv low_memory and dtype options](https:\/\/stackoverflow.com\/questions\/24251219\/pandas-read-csv-low-memory-and-dtype-options)\"*\n","4f50381e":"# Machine Learning, Winternship\n### Widhya.org\n**An Airline company is facing issues with the unability to predict FLight Delay. Due to this company is having a huge loss. The Company needs a machine learning engineer to build a model which accurately predicts the flight delay.**"}}