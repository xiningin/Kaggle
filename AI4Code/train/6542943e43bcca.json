{"cell_type":{"df35a48d":"code","499c653f":"code","00723acb":"code","3393156b":"code","7e8227e7":"code","b5ba7fc4":"code","f15a80be":"code","d6eb4031":"code","dbc3a63c":"code","3c8a940d":"code","2c92d4be":"code","3f7eb681":"code","aeca8639":"code","a8298054":"code","87037fb7":"code","8d3893af":"code","e20d4522":"code","e3ec26f4":"code","9cc87313":"code","21674038":"code","d6fc7b21":"code","901274ee":"code","77f6cfc4":"code","1a0e3ddb":"code","70b1995f":"code","26710e95":"code","5a2923fc":"code","a80b8603":"code","c89601c3":"code","b3d76f9a":"code","4e7c2aaf":"code","630eee80":"code","476602c1":"code","4e960006":"code","7b708f8b":"code","23ab53f8":"code","43fa7d8a":"code","688f1e66":"code","b0e2c7f9":"code","4839edc9":"code","6cbd48cf":"code","914a0644":"code","71721bd4":"code","3a334b20":"markdown","ed95851c":"markdown","13697f3a":"markdown","ba947320":"markdown","29e1c3ba":"markdown","1e775238":"markdown","c8f5b79b":"markdown","ce19ea4d":"markdown","a32a46ee":"markdown","8535d8ab":"markdown","afc771c6":"markdown","62ccf10a":"markdown","15d3bf64":"markdown","ec69296c":"markdown","c31e5738":"markdown","c6d133e3":"markdown","310cd2e5":"markdown","aa030f63":"markdown","6bda5026":"markdown","0fc82c00":"markdown","2414aa97":"markdown","2d3c13df":"markdown"},"source":{"df35a48d":"import numpy as np\nimport pandas as pd\n\nfrom IPython.display import display, display_html , HTML\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report, roc_curve\nfrom sklearn.model_selection import learning_curve, cross_val_score, GridSearchCV\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import RobustScaler,StandardScaler,MinMaxScaler\n\nimport warnings\nwarnings.filterwarnings('ignore')","499c653f":"characteristics = pd.read_csv('..\/input\/2019-database-of-road-traffic-injuries\/caracteristiques-2019.csv')\ncharacteristics.name = 'characteristics'\nplaces = pd.read_csv('..\/input\/2019-database-of-road-traffic-injuries\/lieux-2019.csv')\nplaces.name = 'places'\ndrivers = pd.read_csv('..\/input\/2019-database-of-road-traffic-injuries\/usagers-2019.csv')\ndrivers.name = 'drivers'\nvehicles = pd.read_csv('..\/input\/2019-database-of-road-traffic-injuries\/vehicules-2019.csv')\nvehicles.name = 'vehicles'\n\ndatasets = [characteristics,places,vehicles,drivers]\n\ncharacteristics = characteristics.set_index('Num_Acc')\nplaces = places.set_index('Num_Acc')\nvehicles = vehicles.set_index('id_vehicule')\ndrivers = drivers.set_index('id_vehicule')\n\npd.set_option('display.max_row',max(characteristics.shape[0],places.shape[0],drivers.shape[0],vehicles.shape[0]))\npd.set_option('display.max_column',max(characteristics.shape[1],places.shape[1],drivers.shape[1],vehicles.shape[1]))\n\nfor df in datasets:\n    print (\"The dataset\",df.name,\"has\",df.shape[0],\"rows and\",df.shape[1],\"columns\")","00723acb":"display(HTML('<h1>characteristics<\/h1>'))\ndisplay(characteristics.head())\ndisplay(HTML('<h1>vehicles<\/h1>'))\ndisplay(vehicles.head())\ndisplay(HTML('<h1>drivers<\/h1>'))\ndisplay(drivers.head())\ndisplay(HTML('<h1>places<\/h1>'))\ndisplay(places.head())","3393156b":"display(HTML('<h1><center>Missing values of the different tables (%)<\/center><\/h1>'))\n\na = pd.DataFrame(np.transpose(np.array((characteristics.columns,round(characteristics.isna().sum()\/characteristics.shape[0]*100,2)),dtype=object,)),columns=['features','missing_rate'])\nb = pd.DataFrame(np.transpose(np.array((vehicles.columns,round(vehicles.isna().sum()\/vehicles.shape[0]*100,2)),dtype=object,)),columns=['features','missing_rate'])\nc = pd.DataFrame(np.transpose(np.array((places.columns,round(places.isna().sum()\/places.shape[0]*100,2)),dtype=object,)),columns=['features','missing_rate'])\nd = pd.DataFrame(np.transpose(np.array((drivers.columns,round(drivers.isna().sum()\/drivers.shape[0]*100,2)),dtype=object,)),columns=['features','missing_rate'])\n\ndef highlight_greaterthan(x):\n    if x.missing_rate > 80:\n        return ['background-color: #FFCECE']*2\n    if x.missing_rate > 40:\n        return ['background-color: #FFE9CE']*2\n    if x.missing_rate > 5:\n        return ['background-color: #FFFECE']*2\n    else:\n        return ['background-color: #CEFFFC']*2\n    \na = a.style.apply(highlight_greaterthan, axis=1).set_table_styles([{\n    'selector': 'caption',\n    'props': [\n        ('color', '#585858'),\n        ('font-size', '30px')\n    ]\n}])\nb = b.style.apply(highlight_greaterthan, axis=1).set_table_styles([{\n    'selector': 'caption',\n    'props': [\n        ('color', '#585858'),\n        ('font-size', '30px')\n    ]\n}])\nc = c.style.apply(highlight_greaterthan, axis=1).set_table_styles([{\n    'selector': 'caption',\n    'props': [\n        ('color', '#585858'),\n        ('font-size', '30px')\n    ]\n}])\nd = d.style.apply(highlight_greaterthan, axis=1).set_table_styles([{\n    'selector': 'caption',\n    'props': [\n        ('color', '#585858'),\n        ('font-size', '30px')\n    ]\n}])\n\na_styler = a.set_table_attributes(\"style='display:inline'\").set_caption('characteristics')\nb_styler = b.set_table_attributes(\"style='display:inline'\").set_caption('vehicles')\nc_styler = c.set_table_attributes(\"style='display:inline'\").set_caption('places')\nd_styler = d.set_table_attributes(\"style='display:inline'\").set_caption('drivers')\n\nspace = \"\\xa0\" * 50\ndisplay_html(a_styler._repr_html_() + space + b_styler._repr_html_() + space + c_styler._repr_html_() + space + d_styler._repr_html_(), raw=True)\n\ndisplay(HTML('<h3><i>The values highlighted are the ones above a certain threshold of missing values<\/i><\/h3>'))\ndisplay(HTML('<h3><i>We will get rid of those for the rest of the notebook<\/i><\/h3>'))","7e8227e7":"characteristics_dtypes = pd.DataFrame(np.transpose(np.array((characteristics.columns,characteristics.dtypes),dtype=object,)),columns=['features','dtype'])\nvehicles_dtypes = pd.DataFrame(np.transpose(np.array((vehicles.columns,vehicles.dtypes),dtype=object,)),columns=['features','dtype'])\nplaces_dtypes = pd.DataFrame(np.transpose(np.array((places.columns,places.dtypes),dtype=object,)),columns=['features','dtype'])\ndrivers_dtypes = pd.DataFrame(np.transpose(np.array((drivers.columns,drivers.dtypes),dtype=object,)),columns=['features','dtype'])\n\n\ncharacteristics_dtypes = characteristics_dtypes.style.set_table_styles([{\n    'selector': 'caption',\n    'props': [\n        ('color', '#585858'),\n        ('font-size', '30px')\n    ]\n}])\nvehicles_dtypes = vehicles_dtypes.style.set_table_styles([{\n    'selector': 'caption',\n    'props': [\n        ('color', '#585858'),\n        ('font-size', '30px')\n    ]\n}])\nplaces_dtypes = places_dtypes.style.set_table_styles([{\n    'selector': 'caption',\n    'props': [\n        ('color', '#585858'),\n        ('font-size', '30px')\n    ]\n}])\ndrivers_dtypes = drivers_dtypes.style.set_table_styles([{\n    'selector': 'caption',\n    'props': [\n        ('color', '#585858'),\n        ('font-size', '30px')\n    ]\n}])\n\n\ncharacteristics_dtypes_styler = characteristics_dtypes.set_table_attributes(\"style='display:inline'\").set_caption('characteristics')\nvehicles_dtypes_styler = vehicles_dtypes.set_table_attributes(\"style='display:inline'\").set_caption('vehicles')\nplaces_dtypes_styler = places_dtypes.set_table_attributes(\"style='display:inline'\").set_caption('places')\ndrivers_dtypes_styler = drivers_dtypes.set_table_attributes(\"style='display:inline'\").set_caption('drivers')\nspace = \"\\xa0\" * 50\ndisplay_html(characteristics_dtypes_styler._repr_html_() + space + vehicles_dtypes_styler._repr_html_() + space + \n             places_dtypes_styler._repr_html_() + space + drivers_dtypes_styler._repr_html_(), raw=True)","b5ba7fc4":"for col in characteristics.select_dtypes(\"object\"):\n    print('\\n')\n    print('Number of values in \"',col,'\"', {characteristics[col].nunique()})\n    print(characteristics[col].unique())\n    print('\\n')\n    print('------------------------------------------------')","f15a80be":"sns.set(font_scale = 1.5)\nplt.figure(figsize=(10, 30))\nplt.title('Number of accidents in 2019 per Department')\nsns.countplot(y=characteristics['dep'])\nplt.xlabel(\"Number of accidents\")\nplt.ylabel(\"Department\")\nplt.show()","d6eb4031":"sns.set(font_scale = 1.5)\nfig, ax = plt.subplots(3,4, figsize=(30, 15))\ni=0\nfor col in characteristics.select_dtypes(include=['float64','int64']):\n    sns.distplot(characteristics[col],label=col,ax=ax[i\/\/4][i%4])\n    i=i+1\nfig.show()","dbc3a63c":"for col in vehicles.select_dtypes(\"object\"):\n    print('\\n')\n    print('Number of values in \"',col,'\"', {vehicles[col].nunique()})\n    print(vehicles[col].unique())\n    print('\\n')\n    print('------------------------------------------------')","3c8a940d":"sns.set(font_scale = 1.5)\nplt.figure(figsize=(10, 15))\nplt.title('Number of accidents in 2019 per number of occupants (by category)')\nsns.countplot(y=vehicles['num_veh'])\nplt.xlabel(\"Number of accidents\")\nplt.ylabel(\"Category\")\nplt.show()","2c92d4be":"sns.set(font_scale = 1.5)\nfig, ax = plt.subplots(3,3, figsize=(30, 10))\ni=0\nfor col in vehicles.select_dtypes(include=['float64','int64']):\n    sns.distplot(vehicles[col],label=col,ax=ax[i\/\/3][i%3])\n    i=i+1\nfig.show()","3f7eb681":"for col in places.select_dtypes(\"object\"):\n    print('\\n')\n    print('Number of values in \"',col,'\"', {places[col].nunique()})\n    print(places[col].unique())\n    print('\\n')\n    print('------------------------------------------------')","aeca8639":"sns.set(font_scale = 1.5)\nfig, ax = plt.subplots(3,5, figsize=(30, 15))\ni=0\nfor col in places.select_dtypes(include=['float64','int64']):\n    sns.distplot(places[col],label=col,ax=ax[i\/\/5][i%5])\n    i=i+1\nfig.show()","a8298054":"for col in drivers.select_dtypes(\"object\"):\n    print('\\n')\n    print('Number of values in \"',col,'\"', {drivers[col].nunique()})\n    print(drivers[col].unique())\n    print('\\n')\n    print('------------------------------------------------')","87037fb7":"sns.set(font_scale = 1.5)\nplt.figure(figsize=(10, 5))\nplt.title('Number of accidents in 2019 sorted by pedestrian accions')\nsns.countplot(y=drivers['actp'])\nplt.xlabel(\"Number of accidents\")\nplt.ylabel(\"Category\")\nplt.show()","8d3893af":"sns.set(font_scale = 1.5)\nfig, ax = plt.subplots(3,4, figsize=(30, 15))\ni=0\nfor col in drivers.select_dtypes(include=['float64','int64']):\n    sns.distplot(drivers[col],label=col,ax=ax[i\/\/4][i%4])\n    i=i+1\nfig.show()","e20d4522":"characteristics = pd.read_csv('..\/input\/2019-database-of-road-traffic-injuries\/caracteristiques-2019.csv')\ncharacteristics.name = 'characteristics'\nplaces = pd.read_csv('..\/input\/2019-database-of-road-traffic-injuries\/lieux-2019.csv')\nplaces.name = 'places'\ndrivers = pd.read_csv('..\/input\/2019-database-of-road-traffic-injuries\/usagers-2019.csv')\ndrivers.name = 'drivers'\nvehicles = pd.read_csv('..\/input\/2019-database-of-road-traffic-injuries\/vehicules-2019.csv')\nvehicles.name = 'vehicles'\n\ndatasets = [characteristics,places,vehicles,drivers]\n\n# Indexing the tables\ncharacteristics = characteristics.set_index('Num_Acc')\nplaces = places.set_index('Num_Acc')\nvehicles = vehicles.set_index('id_vehicule')\ndrivers = drivers.set_index('id_vehicule')\n\n# Dealing with features with too many NaNs \nvehicles = vehicles.drop('occutc',axis=1)\nplaces = places.drop(['v2','lartpc','larrout'],axis=1)\n\n# Dealing with features according to the EDA\ncharacteristics = characteristics.drop(['an','adr','com'],axis=1)\ncharacteristics['lat']=characteristics['lat']\/10000000\ncharacteristics['long']=characteristics['long']\/10000000\ncharacteristics = characteristics.drop('201900033874',axis=0)\n#characteristics = characteristics[characteristics['dep']!='2B'] # comment \/ uncomment\n#characteristics = characteristics[characteristics['dep']!='2A'] # comment \/ uncomment\n#characteristics = characteristics[(characteristics['dep'].astype(float)<100)] # comment \/ uncomment\n#places = places.loc[characteristics.index.values] # comment \/ uncomment\nplaces = places.drop('201900033874',axis=0) # comment \/ uncomment\nplaces = places.drop(['v1','vosp','pr','voie'],axis=1)\nvehicles = vehicles.drop('obs',axis=1)\ndrivers = drivers.drop(['secu3'],axis=1)\n\npd.set_option('display.max_row',max(characteristics.shape[0],places.shape[0],drivers.shape[0],vehicles.shape[0]))\npd.set_option('display.max_column',max(characteristics.shape[1],places.shape[1],drivers.shape[1],vehicles.shape[1]))\n\nfor df in datasets:\n    print (\"The dataset\",df.name,\"has\",df.shape[0],\"rows and\",df.shape[1],\"columns\")","e3ec26f4":"from sklearn.preprocessing import LabelEncoder\ndef encoding(df):\n    label = LabelEncoder()\n    for c in df.select_dtypes(\"object\"):\n        df[c]=df[c].astype(\"|S\")\n        df[c]=label.fit_transform(df[c])\n    return df\n\ndef imputation(df):\n    df = df.fillna(df.median())\n    df = df.dropna()\n    return df\n\ndef preprocessing(df):\n    df = encoding(df)\n    df = imputation(df) \n\n    return df","9cc87313":"characteristics = preprocessing(characteristics)\nvehicles = preprocessing(vehicles)\nplaces = preprocessing(places)\ndrivers = preprocessing(drivers)","21674038":"display(HTML('<h1>characteristics<\/h1>'))\ndisplay(characteristics.head())\ndisplay(HTML('<h1>vehicles<\/h1>'))\ndisplay(vehicles.head())\ndisplay(HTML('<h1>drivers<\/h1>'))\ndisplay(drivers.head())\ndisplay(HTML('<h1>places<\/h1>'))\ndisplay(places.head())","d6fc7b21":"lat = characteristics['lat']\nlon = characteristics['long']\ndep = characteristics['dep']\ncatr = places['catr'].map({1 : 'Highway',\n2 : 'National road',\n3 : 'Departmental road',\n4 : 'Communal roads',\n5 : 'Outside the public network',\n6 : 'Parking lot open to public traffic',\n7 : 'Urban metropolis roads',\n9 : 'other'})\nlum = characteristics['lum'].map({1 : 'Full day',\n2 : 'Twilight or dawn',\n3 : 'Night without public lighting',\n4 : 'Night with public lighting not on',\n5 : 'Night with public lighting on'})\natm = characteristics['atm'].map({1 : 'Normal',\n2 : 'Light rain',\n3 : 'Heavy rain',\n4 : 'Snow. hail',\n5 : 'Fog. smoke',\n6 : 'Strong wind. storm',\n7 : 'Dazzling weather',\n8 : 'Cloudy weather',\n9 : 'Other'})\ncol = characteristics['col'].map({1 : 'Two vehicles. frontal',\n2 : 'Two vehicles. from the rear',\n3 : 'Two vehicles. from the side',\n4 : 'Three vehicles and more. in a chain',\n5 : 'Three or more vehicles. multiple collisions',\n6 : 'Other collision 7. No collision'})\ncirc = places['circ'].map({1 : 'One way',\n2 : 'Bidirectional',\n3 : 'A separate carriageway',\n4 : 'With variable assignment channels'})\nprof = places['prof'].map({1 : 'Flat',\n2 : 'Slope',\n3 : 'hilltop',\n4 : 'Bottom of coast'})\nplan = places['plan'].map({1 : 'rectilinear part',\n2 : 'In a curve to the left',\n3 : 'In a curve to the right',\n4 : 'In \"S\"'})\nsurf = places['surf'].map({1 : 'Normal',\n2 : 'Wet',\n3 : 'Puddles',\n4 : 'Flooded',\n5 : 'Snowy',\n6 : 'Mud',\n7 : 'Icy',\n8 : 'Fat. oil',\n9 : 'Other'})\nvma = places['vma']","901274ee":"import plotly.express as px\nfig = px.scatter_mapbox(characteristics, \n                        lat=\"lat\", \n                        lon=\"long\", \n                        hover_name=catr, \n                        hover_data={'Light':lum,\n                                    'Atmosphere':atm,\n                                    'Collision':col,\n                                    'Regime':circ,\n                                    'Profile':prof,\n                                    'Layout':plan,\n                                    'Surface':surf,\n                                    'Speed':vma,\n                                    'long':False,\n                                    'lat':False}, \n                        zoom=4.9, \n                        height=800, \n                        width=800)\nfig.data[0]['marker'].update(color='red') #green\nfig.data[0]['marker'].update(size=3)\nfig.update_layout(mapbox_style=\"open-street-map\")\nfig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\nfig.show()","77f6cfc4":"df_acc = pd.concat([characteristics, places.reindex(characteristics.index)], axis=1)\ndf_veh = pd.concat([drivers, vehicles.reindex(drivers.index)], axis=1)\npd.set_option('display.max_row',40)\npd.set_option('display.max_column',40)\ndisplay(HTML('<h1>df_acc<\/h1>'))\ndisplay(df_acc.head())\ndisplay(HTML('<h1>df_veh<\/h1>'))\ndisplay(df_veh.head())","1a0e3ddb":"df_acc = df_acc.loc[:,~df_acc.columns.duplicated()] # Get rid of duplicates\ndf_veh = df_veh.loc[:,~df_veh.columns.duplicated()]\ndf_veh.reset_index(drop=True, inplace=True)\ndf_veh.index = df_veh['Num_Acc'].astype('str')\ndf_veh = df_veh.drop(['Num_Acc'],axis=1)\ndf = pd.concat([df_acc.reindex(df_veh.index),df_veh],axis=1)\ndf = preprocessing(df)","70b1995f":"pd.set_option('display.max_row',40)\npd.set_option('display.max_column',40)\ndisplay(HTML('<h1>df_acc<\/h1>'))\ndisplay(df_acc.head())\ndisplay(HTML('<h1>df_veh<\/h1>'))\ndisplay(df_veh.head())\ndisplay(HTML('<h1>Fully concatenated dataset : df<\/h1>'))\ndisplay(df.head())\nprint('\\n')\nprint(\"----------------------------------\")\ndisplay(HTML('<h3>Complete dataset shape :<\/h3>'))\ndisplay(df.shape)\nprint(\"----------------------------------\")","26710e95":"plt.figure(figsize=(15,6))\nsns.countplot(df['grav'].map({1:'Unharmed',\n                                  2:'Killed',\n                                  3:'Injured hospitalized',\n                                  4:'Slightly injured'\n                                }))\nplt.plot()","5a2923fc":"# Class count\ncount_class_4, count_class_1, count_class_3, count_class_2 = df['grav'].value_counts()\n\n# Divide by class\ndf_class_1 = df[df['grav'] == 1]\ndf_class_2 = df[df['grav'] == 2]\ndf_class_3 = df[df['grav'] == 3]\ndf_class_4 = df[df['grav'] == 4]\n\ndf_class_1_under = df_class_1.sample(count_class_2,random_state=42)\ndf_class_4_under = df_class_4.sample(count_class_2,random_state=42)\ndf_class_3_under = df_class_3.sample(count_class_2,random_state=42)\ndf_under = pd.concat([df_class_1_under, df_class_2, df_class_3_under, df_class_4_under], axis=0)\n\ndf_class_2_over = df_class_2.sample(count_class_1, replace=True, random_state=42)\ndf_class_3_over = df_class_3.sample(count_class_1, replace=True, random_state=42)\ndf_class_4_over = df_class_4.sample(count_class_1, replace=True, random_state=42)\ndf_over = pd.concat([df_class_1, df_class_2_over, df_class_3_over, df_class_4_over], axis=0)\n\nfig,axes = plt.subplots(1,2,figsize=(20,6),sharey=True)\nsns.countplot(ax=axes[0],x=df_under['grav'].map({1:'Unharmed',\n                                  2:'Killed',\n                                  3:'Injured hospitalized',\n                                  4:'Slightly injured'\n                                }))\naxes[0].set_title('Random Downsampling')\nsns.countplot(ax=axes[1],x=df_over['grav'].map({1:'Unharmed',\n                                  2:'Killed',\n                                  3:'Injured hospitalized',\n                                  4:'Slightly injured'\n                                }))\naxes[1].set_title('Random Oversampling')\nplt.plot()","a80b8603":"trainset, testset = train_test_split(df_over, test_size=0.15, random_state=42)\nfig, ax = plt.subplots(1,2, figsize=(18, 5))\nsns.countplot(x = 'grav' , data = trainset,ax=ax[0],palette=\"Accent\").set_title('TrainSet')\nsns.countplot(x = 'grav' , data = testset,ax=ax[1],palette=\"Accent\").set_title('TestSet')","c89601c3":"X_train = trainset.drop('grav',axis=1)\ny_train = trainset['grav']\nX_test = testset.drop('grav',axis=1)\ny_test = testset['grav']","b3d76f9a":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.decomposition import PCA","4e7c2aaf":"preprocessor = make_pipeline(StandardScaler())\n\nPCAPipeline = make_pipeline(preprocessor, PCA(n_components=3,random_state=0))\n\nRandomPipeline = make_pipeline(preprocessor,RandomForestClassifier(random_state=0))\nAdaPipeline = make_pipeline(preprocessor,AdaBoostClassifier(random_state=0))\nSVMPipeline = make_pipeline(preprocessor,SVC(random_state=0,probability=True))\nKNNPipeline = make_pipeline(preprocessor,KNeighborsClassifier())\nLRPipeline = make_pipeline(preprocessor,LogisticRegression(solver='sag'))","630eee80":"PCA_df = pd.DataFrame(PCAPipeline.fit_transform(df.drop('grav',axis=1)))\nPCA_df = pd.concat([PCA_df.reset_index(), df['grav'].map({1:'Unharmed',\n                                  2:'Killed',\n                                  3:'Injured hospitalized',\n                                  4:'Slightly injured'\n                                }).reset_index()], axis=1)\nPCA_df = PCA_df.drop(['index','Num_Acc'],axis=1)\nPCA_df.head()","476602c1":"figure1 = px.scatter_3d(PCA_df,\n        x=0, \n        y=1, \n        z=2, \n        color = 'grav',\n                       width=600, height=800)\nfigure1.update_traces(marker=dict(size=5,\n                                  line=dict(width=0.15,\n                                        color='black')),\n                      selector=dict(mode='markers'))\n\nfigure1.show()","4e960006":"dict_of_models = {'KNN': KNNPipeline,\n                  'RandomForest': RandomPipeline,\n                  'AdaBoost': AdaPipeline,\n                  #'SVM': SVMPipeline,\n                  'LR': LRPipeline}","7b708f8b":"def evaluation(model):\n    model.fit(X_train, y_train)\n    # calculating the predictions\n    y_pred = model.predict(X_test)\n    print('Accuracy = ', accuracy_score(y_test, y_pred))\n    print('-')\n    print(confusion_matrix(y_test,y_pred))\n    print('-')\n    print(classification_report(y_test,y_pred))\n    print('-')","23ab53f8":"for name, model in dict_of_models.items():\n    print('---------------------------------')\n    print(name)\n    evaluation(model)","43fa7d8a":"from sklearn.model_selection import RandomizedSearchCV\nRandomPipeline.get_params().keys()","688f1e66":"hyper_params = {\n    'randomforestclassifier__n_estimators':[10,100,150,250,400,600],\n    'randomforestclassifier__criterion':['gini','entropy'],\n    'randomforestclassifier__min_samples_split':[2,6,12],\n    'randomforestclassifier__min_samples_leaf':[1,4,6,10],\n    'randomforestclassifier__max_features':['auto','srqt','log2',int,float],\n    'randomforestclassifier__verbose':[0,1,2],\n    'randomforestclassifier__class_weight':['balanced','balanced_subsample'],\n    'randomforestclassifier__n_jobs':[-1],\n}","b0e2c7f9":"RF_grid = RandomizedSearchCV(RandomPipeline,hyper_params,scoring='accuracy',n_iter=40)\nRF_grid.fit(X_train,y_train)","4839edc9":"print(RF_grid.best_params_)","6cbd48cf":"best_forest = (RF_grid.best_estimator_)\nbest_forest.fit(X_train,y_train)\n# calculating the predictions\ny_pred = best_forest.predict(X_test)\n\nN, train_score, test_score = learning_curve(best_forest, X_train, y_train, \n                                           cv=4, scoring='accuracy', \n                                           train_sizes=np.linspace(0.1,1,10))","914a0644":"print('Accuracy = ', accuracy_score(y_test, y_pred))\nprint('-')\nprint(confusion_matrix(y_test,y_pred))\nprint('-')\nprint(classification_report(y_test,y_pred))\nprint('-')\n    \nplt.figure(figsize=(5,5))\nplt.plot(N, train_score.mean(axis=1), label='train score')\nplt.plot(N, test_score.mean(axis=1), label='validation score')\nplt.legend()\nplt.title('Accuracy')\nplt.show()","71721bd4":"from sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.multiclass import OneVsRestClassifier\n\n# Binarize the output\ny_train = label_binarize(y_train, classes=[1, 2, 3, 4])\ny_test = label_binarize(y_test, classes=[1, 2, 3, 4])\nn_classes = y_train.shape[1]\n\n# Learn to predict each class against the other\nclassifier = OneVsRestClassifier(best_forest)\n#y_score = classifier.fit(X_train, y_train).decision_function(X_test)\ny_score = classifier.fit(X_train, y_train).predict_proba(X_test)\n\n# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\n# # Plot of a ROC curve for a specific class\n# plt.figure()\n# plt.plot(fpr[2], tpr[2], label='ROC curve (area = %0.2f)' % roc_auc[2])\n# plt.plot([0, 1], [0, 1], 'k--')\n# plt.xlim([0.0, 1.0])\n# plt.ylim([0.0, 1.05])\n# plt.xlabel('False Positive Rate')\n# plt.ylabel('True Positive Rate')\n# plt.title('Receiver operating characteristic for class 2')\n# plt.legend(loc=\"lower right\")\n# plt.show()\n\n# Plot ROC curve\nplt.figure(figsize=(15,10))\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]))\nfor i in range(n_classes):\n    plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n                                   ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic to multi-class')\nplt.legend(loc=\"lower right\")\nplt.show()","3a334b20":"<h1><center>vehicles<\/center><\/h1>","ed95851c":"# Modelling","13697f3a":"# Target visualization","ba947320":"<h2>Comments<\/h2>\n<ul>\n    <li>We can notice on the first graph (accidents by department) that the number 75 skyrockets compared to the others<\/li>\n    <li>We can notice on the second graph that the feature \"an\" that corresponds to \"year\" has no variance (in fact the whole dataset is based only on the year 2019 so thats pretty much obvious). We will get rid of this feature in the future.<\/li>\n    <li>The two features \"lat\" and \"long\" corresponding to the Latitude and the Longitude of the accident are not scaled. There is a factor of 1e7 (to be changed)<\/li>\n<\/ul>","29e1c3ba":"<h1><center>drivers<\/center><\/h1>","1e775238":"# Display accidents on a map\n#### (Unzoom for oversea french lands)","c8f5b79b":"<h1><center>Visualizing datasets dtypes 1 by 1<\/center><\/h1>","ce19ea4d":"# Resampling (if needed)\n\nA widely adopted technique for dealing with highly unbalanced datasets is called resampling. It consists of removing samples from the majority class (under-sampling) and \/ or adding more examples from the minority class (over-sampling).\n\n![](https:\/\/raw.githubusercontent.com\/rafjaa\/machine_learning_fecib\/master\/src\/static\/img\/resampling.png)\n\nDespite the advantage of balancing classes, these techniques also have their weaknesses (there is no free lunch). The simplest implementation of over-sampling is to duplicate random records from the minority class, which can cause overfitting. In under-sampling, the simplest technique involves removing random records from the majority class, which can cause loss of information.\n\nLet's implement a basic example, which uses the <code>DataFrame.sample<\/code> method to get random samples each class.","a32a46ee":"# Concatenating datasets","8535d8ab":"# Cleaning data","afc771c6":"<h2>Comments<\/h2>\n<ul>\n    <li>We can notice that the feature \"V1\",\"vosp\",\"pr\" have a low variance<\/li>\n<\/ul>","62ccf10a":"# PCA Analysis","15d3bf64":"<h2>Comments<\/h2>\n<ul>\n    <li>We can notice that the feature \"secu3\" has a low variance<\/li>\n<\/ul>","ec69296c":"<h2>Comments<\/h2>\n<ul>\n    <li>We can notice that the feature \"obs\" has a low variance<\/li>\n<\/ul>","c31e5738":"<h1><center><mark>Expand the following markdown to read the features description<\/mark><\/center><\/h1>","c6d133e3":"# Training models\n## Models overview","310cd2e5":"# Using RandomForest","aa030f63":"# Breaking down EDA for a set of 4 datasets","6bda5026":"<h1><center>characteristics<\/center><\/h1>","0fc82c00":"# Summary\n    \n## characteristics\n- \"dep\" 75 skyrockets compared to the others\n- \"an\" that corresponds to \"year\" has no variance (in fact the whole dataset is based only on the year 2019 so thats pretty much obvious). We will get rid of this feature in the future.\n- The two features \"lat\" and \"long\" corresponding to the Latitude and the Longitude of the accident are not scaled. There is a factor of 1e7 (to be changed)\n\n## vehicles\n- \"obs\" has a low variance\n\n## places\n- \"V1\",\"vosp\",\"pr\" have a low variance\n\n## drivers\n- \"secu3\" has a low variance","2414aa97":"<h1><center>places<\/center><\/h1>","2d3c13df":"## Num_Acc\nIdentification number of the accident.\n\n## jour\nDay of the accident.\n\n## mois\nMonth of the accident.\n\n## an\nYear of accident.\n\n## hrmn\nHour and minutes of the accident.\nThis one is tricky, it correspond to a percentage of 24h (your turn to convert it into day time)\n\n## lum\n\tLight: lighting conditions in which the accident occurred:\n1. Full day\n2. Twilight or dawn\n3. Night without public lighting\n4. Night with public lighting not on\n5. Night with public lighting on\n\n## dep\nDepartment: Code INSEE (National Institute of Statistics and Economic Studies) of department (2A Corse-du-Sud. 2B Haute-Corse).\n\n## com\nMunicipality: The municipality number is a code given by INSEE. The code is made up of the code INSEE of the department followed by 3 digits.\n\n## agg\n\tLocation :\n1. Outside agglomeration\n2. In built-up areas\n\n## int\n\tIntersection:\n1. Excluding intersection\n2. Intersection in X\n3. T-intersection\n4. Y intersection\n5. Intersection with more than 4 branches\n6. Roundabout\n7. Place\n8. Level crossing\n9. Other intersection \n\n## atm\n\tAtmospheric conditions:\n-1. Not specified\n1. Normal\n2. Light rain\n3. Heavy rain\n4. Snow. hail\n5. Fog. smoke\n6. Strong wind. storm\n7. Dazzling weather\n8. Cloudy weather\n9. Other\n\n## col\n\tCollision type:\n-1. Not specified\n1. Two vehicles. frontal\n2. Two vehicles. from the rear\n3. Two vehicles. from the side\n4. Three vehicles and more. in a chain\n5. Three or more vehicles. multiple collisions\n6. Other collision 7. No collision\n\n## adr\nPostal address: variable entered for accidents occurring in built-up areas.\n\n## lat\nLatitude\n\n## Long\nLongitude \n\n## catr\n\tRoad category:\n1. Highway\n2. National road\n3. Departmental road\n4. Communal roads\n5. Outside the public network\n6. Parking lot open to public traffic\n7. Urban metropolis roads\n9. other\n\n## voie\nRoute number.\n\n## V1\nNumerical index of the road number (example: 2 bis, 3 ter etc.). \n\n## V2\nAlphanumeric road index letter.\n\n## circ\n\tTraffic regime:\n-1. Not specified\n1. One way\n2. Bidirectional\n3. A separate carriageway\n4. With variable assignment channels\n\n## nbv\nTotal number of traffic lanes.\n\n## vosp\n\tIndicates the existence of a reserved lane, regardless of whether or \n\tnot the accident took place on this way.\n-1. Not specified\n0. Not applicable\n1. Cycle path\n2. Cycle lane\n3. Reserved lane\n\n## prof\n\tLongitudinal profile describes the gradient of the road at the location of the accident:\n-1. Not specified\n1. Flat\n2. Slope\n3. hilltop\n4. Bottom of coast\n\n## pr\nNumber of the associated PR (number of the upstream terminal). \nThe value -1 means that the PR is not informed.\n\n## pr1\nDistance in meters from the PR (in relation to the upstream terminal). \nThe value -1 means that the PR is not informed.\n\n## plan\n\tPlan layout:\n-1. Not specified\n1. rectilinear part\n2. In a curve to the left\n3. In a curve to the right 4. In \"S\"\n\n## lartpc\nWidth of the central reservation (TPC) if it exists (in m).\n## larrout\nWidth of the roadway used for vehicular traffic \nis not included in the stopping strips emergency, TPC and parking spaces (in m).\n\n## surf\n\tSurface condition: \n-1. Not specified\n1. Normal\n2. Wet\n3. Puddles\n4. Flooded\n5. Snowy\n6. Mud\n7. Icy\n8. Fat. oil\n9. Other\n\n## infra\n\tDevelopment. Infrastructure:\n-1. Not specified\n0. None\n1. Underground. tunnel\n2. Bridge. flyover\n3. Exchanger or connection sling\n4. Railroad\n5. Crossroads\n6. Pedestrian zone\n7. Toll zone\n8. Site\n9. Others\n\n## situ\n\tSituation of the accident:\n-1. Not specified\n0. None\n1. On the road\n2. On emergency lane\n3. On the shoulder\n4. On the sidewalk\n5. On a cycle path\n6. On other special track\n8. Others\n\n## vma\nMaximum authorized speed at the scene and at the time of the accident. \n\n## vehicle_id\nUnique identifier of the vehicle used for each user occupying this \nvehicle (including pedestrians who are attached to the vehicles \nwhich collided with them). Numerical code.\n\n## Num_Veh\nIdentifier of the vehicle taken back for each of the users \noccupying this vehicle (including pedestrians who are attached to the \nvehicles which collided with them). Alphanumeric code. \n\n## senc\n\tFlow direction :\n-1. Not specified\n0. Unknown\n1. PK or PR or increasing postal address number\n2. PK or PR or decreasing postal address number\n3. Lack of reference\n\n## catv\n\tVehicle category:\n00. Not determinable\n01. Bicycle\n02. Moped &lt;50cm3\n03. Cart (Quadricycle with bodywork motor) (formerly \"cart or motor tricycle\")\n04. Reference not used since 2006 (registered scooter)\n05. Reference unused since 2006 (motorcycle)\n06. Reference unused since 2006 (sidecar)\n07. VL only\n08. Reference unused since 2006 (VL + caravan)\n09. Reference not used since 2006 (light vehicles + trailer)\n10. VU only 1.5T &lt;= PTAC &lt;= 3.5T with or without trailer (formerly VU only 1.5T &lt;= PTAC &lt;= 3.5T)\n11. Reference not used since 2006 (VU (10) + caravan)\n12. Reference not used since 2006 (VU (10) + trailer)\n13. PL only 3.5T <PTCA <= 7,5T \n14. PL only > 7.5T\n15. PL> 3,5T + trailer\n16. Road tractor only\n17. Road tractor + semi-trailer\n18. Reference not used since 2006 (public transport)\n19. Reference not used since 2006 (tram)\n20. Special gear\n21. Farm tractor\n30. Scooter <50 cm3\n31. Motorcycle> 50 cm3 and <= 125 cm3\n32. Scooter> 50 cm3 and <= 125 cm3\n33. Motorcycle> 125 cm3\n34. Scooter> 125 cm3\n35. Light quad <= 50 cm3 (Quadricycle without bodywork engine)\n36. Heavy quad> 50 cm3 (Quadricycle without bodywork engine)\n37. Bus\n38. Coach\n39. Train\n40. Tram\n41. 3WD <= 50 cm3\n42. 3WD> 50 cm3 <= 125 cm3\n43. 3WD> 125 cm3\n50. EDP with motor\n60. EDP without motor\n80. VAE\n99. Other vehicle \n\n## obs\n\tFixed obstacle struck:\n-1. Not specified\n0. Not applicable\n1. Parked vehicle\n2. Tree\n3. Metal slide\n4. Concrete slide\n5. Other slide\n6. Building, wall, bridge pier\n7. Vertical signage support or emergency call station\n8. Post\n9. Street furniture\n10. Parapet\n11. Island, refuge, upper terminal\n12. Sidewalk edge\n13. Ditch, embankment, rock face\n14. Other fixed obstacle on the road\n15. Other fixed obstacle on sidewalk or shoulder\n16. Clearance of the roadway without obstacle\n17. Nozzle. aqueduct head\n\n## obsm\n\tMovable obstacle struck:\n-1. Not specified\n0. None\n1. Pedestrian\n2. Vehicle\n4. Rail vehicle\n5. Domestic animal\n6. Wild animal\n9. Other \n\n## choc\nInitial shock point:\n-1. Not specified\n0. None\n1. Before\n2. Right front\n3. Front left\n4. Rear\n5. Right back\n6. Left rear\n7. Right side\n8. Left side\n9. Multiple shocks (rolls) \n\n## manv\n\tMain maneuver before the accident:\n-1. Not specified\n0. Unknown\n1. Without change of direction\n2. Same direction, same row\n3. Between 2 lines\n4. In reverse\n5. In the wrong way\n6. Crossing the central reservation\n7. In the bus lane, in the same direction\n8. In the bus lane, in the opposite direction\n9. By inserting\n10. By making a U-turn on the road\n\tChanging lane\n11. Left\n12. Right\n\tDeported\n13. Left\n14. Right\n\tTurning\n15. Left\n16. Right\n\tExceeding\n17. Left\n18. Right\n\tVarious\n19. Crossing the road\n20. Parking maneuver\n21. Avoidance maneuver\n22. Door opening\n23. Stopped (except parking)\n24. Parked (with occupants\n25. Traveling on sidewalk\n26. Other maneuvers \n\n## motor\n\tVehicle engine type:\n-1. Not specified\n0. Unknown\n1. Hydrocarbons\n2. Electric hybrid\n3. Electric\n4. Hydrogen\n5. Human\n6. Other \n\n## occutc\nNumber of occupants in public transport. \n\n## id_vehicule\nUnique identifier of the vehicle used for each user occupying this vehicle (including\npedestrians who are attached to the vehicles which collided with them). Numerical code. \n\n## Num_Veh\nIdentifier of the vehicle taken back for each of the users occupying this vehicle \n(including pedestrians who are attached to the vehicles which collided with \nthem). Alphanumeric code. \n\n## place\nUsed to locate the space occupied in the vehicle by the user at the time of the accident\nCheck on this link for the pattern : https:\/\/ibb.co\/NsTxbXP\n\n## catu\n\tUser category:\n1. Driver\n2. Passenger\n3. Pedestrian \n\n## grav\n\tSeverity of user injury, injured users are classified into three categories of\n\tvictims plus unharmed:\n1. Unharmed\n2. Killed\n3. Injured hospitalized\n4. Slightly injured \n\n## sexe\n\tDriver gender:\n1. Male\n2. Female\n\n## An_nais\nYear of birth of the driver\n\n## trajet\n\tReason for travel at the time of the accident:\n-1. Not specified\n0. Not specified\n1. Home. work\n2. Home. school\n3. Shopping. shopping\n4. Professional use\n5. Walk. leisure\n9. Other  \n\n\n\nSecurity equipment until 2018 was divided into 2 variables: existence and use.\nFrom 2019, this concerns use with up to 3 possible devices for the same user\n(especially for motorcyclists whose helmets and gloves are compulsory). \n\n\n## secu1\n\tThe character intelligence indicates the presence and use of safety equipment:\n-1. Not specified\n0. No equipment\n1. Belt\n12\n2. Helmet\n3. Children's device\n4. reflective vest\n5. Airbag (2WD \/ 3WD)\n6. Gloves (2WD \/ 3WD)\n7. Gloves + Airbag (2WD \/ 3WD)\n8. Not determinable\n9. Other\n\n## secu2\n\tThe character intelligence indicates the presence and use of safety equipment:\n-1. Not specified\n0. No equipment\n1. Belt\n2. Helmet\n3. Children's device\n4. reflective vest\n5. Airbag (2WD \/ 3WD)\n6. Gloves (2WD \/ 3WD)\n7. Gloves + Airbag (2WD \/ 3WD)\n8. Not determinable\n9. Other\n\n## secu3\n\tThe character intelligence indicates the presence and use of safety equipment:\n-1. Not specified\n0. No equipment\n1. Belt\n2. Helmet\n3. Children's device\n4. reflective vest\n5. Airbag (2WD \/ 3WD)\n6. Gloves (2WD \/ 3WD)\n7. Gloves + Airbag (2WD \/ 3WD)\n8. Not determinable\n9. Other\n\n## locp\n\tLocalisation du pi\u00e9ton :\n-1. Non renseign\u00e9\n0. Sans objet\nSur chauss\u00e9e :\n1. A + 50 m du passage pi\u00e9ton\n2. A. 50 m du passage pi\u00e9ton\n\tSur passage pi\u00e9ton :\n3. Sans signalisation lumineuse\n4. Avec signalisation lumineuse\n\tDivers :\n5. Sur trottoir\n6. Sur accotement\n7. Sur refuge ou BAU\n8. Sur contre all\u00e9e\n9. Inconnue \n\n## actp\n\tPedestrian action:\n-1. Not specified\n\tMoving\n0. Not specified or not applicable\n1. Direction of colliding vehicle\n2. Opposite direction of the vehicle\n\tVarious\n3. Crossing\n4. Masked\n5. Playing. running\n6. With animal\n9. Other\nA. Get on \/ off the vehicle\nB. Unknown \n\n## etatp\n\tThis variable is used to specify whether the injured pedestrian was alone or not:\n-1. Not specified\n1. Alone\n2. Accompanied\n3. In a group "}}