{"cell_type":{"322f91cf":"code","425b2842":"code","cfad4032":"code","2136e1d6":"code","800e83a2":"code","02ebde18":"code","ff02505c":"code","fd26f571":"code","ae4d4a2d":"code","1e1b2965":"code","fbd05ce7":"code","4538cec6":"code","3959afc3":"code","30370f99":"code","9fd6bef2":"code","388254f3":"code","58d7353b":"code","1d96537b":"code","22eff7f3":"code","7e38fa2d":"code","23547b90":"code","8c639012":"code","5f8160c8":"code","dbb47cce":"code","a49ef7ce":"code","e658f537":"code","6147c24a":"code","8d199a09":"code","713d8b8a":"code","324cead4":"code","e7863edd":"code","4de7cd3e":"code","a3d8d435":"code","a154201a":"code","b2ef7580":"code","178d6a7a":"code","4fbede88":"code","61f07a2a":"code","51cfa04d":"code","2a9d7430":"code","abbd4ae5":"code","acfffdfe":"code","a968f8b8":"code","0326d1bf":"code","2f90a4a7":"code","fbc008b6":"code","6472f7b7":"code","ed217585":"code","85e20000":"code","6b8e06ed":"code","e4428472":"code","83be847a":"code","651a5dc9":"code","5f5abe2d":"code","ae5925db":"code","1c29255e":"code","a76a1184":"code","8cde762f":"code","a1d20ff7":"code","640ed6d4":"code","75a88550":"code","fcb70d22":"code","794dc3d1":"markdown","597be1a6":"markdown","77917b3a":"markdown","0b01dd77":"markdown","4cac41f2":"markdown","56cc359f":"markdown","0edc9b6b":"markdown","1ad15fc8":"markdown","9d57d674":"markdown","0505e7b8":"markdown","256402da":"markdown","192b695e":"markdown","f473d668":"markdown","03866e19":"markdown","8bb76982":"markdown","bfa367f2":"markdown","250bc359":"markdown","f7afe83d":"markdown","9cd38a86":"markdown","d4af05b3":"markdown","3af3a46c":"markdown","6fe1b321":"markdown","87e3b73f":"markdown","d1618598":"markdown","4b1160b3":"markdown","cd8ac373":"markdown","70b92be9":"markdown","dfcc6e11":"markdown","dd008a7b":"markdown"},"source":{"322f91cf":"print('Hello My name is Bashir Abubakar and welcome to this exploration!')","425b2842":"# import necessary libraries\n# data cleaning and manipulation \nimport pandas as pd\nimport numpy as np\n\n# data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n!pip install chart_studio\n!pip install cufflinks\nfrom chart_studio.plotly import plot, iplot\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.figure_factory as ff\nimport cufflinks\ncufflinks.go_offline()\ncufflinks.set_config_file(world_readable=True, theme='pearl')\nimport plotly.graph_objs as go\nimport chart_studio.plotly as py\nimport plotly\nimport chart_studio\nchart_studio.tools.set_credentials_file(username='bashman18', api_key='\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022')\ninit_notebook_mode(connected=True)\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.tools as tls\nimport itertools\nimport time\n\n# machine learning\nfrom sklearn.preprocessing import StandardScaler\nimport sklearn.linear_model as skl_lm\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn import neighbors\nfrom sklearn.metrics import confusion_matrix, classification_report, precision_score\nfrom sklearn.model_selection import train_test_split\nimport statsmodels.api as sm\nfrom sklearn.feature_selection import RFE\nimport statsmodels.formula.api as smf\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, learning_curve, train_test_split\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix, roc_curve, precision_recall_curve, accuracy_score\n\n# initialize some package settings\nsns.set(style=\"whitegrid\", color_codes=True, font_scale=1.3)\n\n%matplotlib inline\n\nprint('All modules imported')","cfad4032":"# read in the data and check the first 10 rows\ndf = pd.read_csv('..\/input\/data.csv')\ndf.head(10)","2136e1d6":"# general summary of the dataframe\ndf.info()","800e83a2":"# check number of missing values\nnull_feat = pd.DataFrame(len(df['id']) - df.isnull().sum(), columns = ['Count'])\nnull_feat","02ebde18":"# remove the 'Unnamed: 32' column\ndf = df.drop('Unnamed: 32', axis=1)\n# Reassign target\ndf.diagnosis.replace(to_replace = dict(M = 1, B = 0), inplace = True)","ff02505c":"# check the data type of each column\ndf.dtypes","fd26f571":"# drop the id column as well and check the dataframe\ndf=df.drop(\"id\",axis=1)\ndf.head()","ae4d4a2d":"# assign our categorical variables to a dataframe\nM = df[(df['diagnosis'] != 0)]\nB = df[(df['diagnosis'] == 0)]","1e1b2965":"# check what the dataframe looks like\ndf.head()","fbd05ce7":"trace = go.Bar(x = (len(M), len(B)), y = ['malignant', 'benign'], orientation = 'h', opacity = 0.8, marker=dict(\n        color=[ 'gold', 'black'],\n        line=dict(color='#000000',width=1.0)))\n\nlayout = dict(title =  'Count of diagnosis variable')\n                    \nfig = dict(data = [trace], layout=layout)\npy.iplot(fig)\n\ntrace = go.Pie(labels = ['benign','malignant'], values = df['diagnosis'].value_counts(), \n               textfont=dict(size=15), opacity = 0.8,\n               marker=dict(colors=['black', 'gold'], \n                           line=dict(color='#000000', width=1.5)))\n\nlayout = dict(title =  'Distribution of diagnosis variable')\n           \nfig = dict(data = [trace], layout=layout)\npy.iplot(fig)","4538cec6":"benign, malignant = df['diagnosis'].value_counts()\nprint('Number of cells labeled Benign: ', benign)\nprint('Number of cells labeled Malignant : ', malignant)\nprint('')\nprint('% of cells labeled Benign', round(benign \/ len(df) * 100, 2), '%')\nprint('% of cells labeled Malignant', round(malignant \/ len(df) * 100, 2), '%')","3959afc3":"def plot_distribution(df_f, size_bin) :  \n    tmp1 = M[df_f]\n    tmp2 = B[df_f]\n    hist_data = [tmp1, tmp2]\n    \n    group_labels = ['malignant', 'benign']\n    colors = ['#FFD700', '#7EC0EE']\n\n    fig = ff.create_distplot(hist_data, group_labels, colors = colors, show_hist = True, bin_size = size_bin, curve_type='kde')\n    \n    fig['layout'].update(title = df_f)\n\n    py.iplot(fig, filename = 'Density plot')","30370f99":"plot_distribution('radius_mean', .5)","9fd6bef2":"plot_distribution('texture_mean', .5)","388254f3":"plot_distribution('perimeter_mean', 5)","58d7353b":"plot_distribution('area_mean', 10)\n#plot_distribution('smoothness_mean', .5)\n#plot_distribution('compactness_mean' .5)\n#plot_distribution('concavity_mean' .5)\n#plot_distribution('concave points_mean' .5)\n#plot_distribution('symmetry_mean' .5)\n#plot_distribution('fractal_dimension_mean' .5)","1d96537b":"#correlation\ncorrelation = df.corr()\n#tick labels\nmatrix_cols = correlation.columns.tolist()\n#convert to array\ncorr_array  = np.array(correlation)","22eff7f3":"trace = go.Heatmap(z = corr_array,\n                   x = matrix_cols,\n                   y = matrix_cols,\n                   xgap = 2,\n                   ygap = 2,\n                   colorscale='Viridis',\n                   colorbar   = dict() ,\n                  )\nlayout = go.Layout(dict(title = 'Correlation Matrix for variables',\n                        autosize = False,\n                        height  = 720,\n                        width   = 800,\n                        margin  = dict(r = 0 ,l = 210,\n                                       t = 25,b = 210,\n                                     ),\n                        yaxis   = dict(tickfont = dict(size = 9)),\n                        xaxis   = dict(tickfont = dict(size = 9)),\n                       )\n                  )\nfig = go.Figure(data = [trace],layout = layout)\npy.iplot(fig)","7e38fa2d":"def plot_ft1_ft2(ft1, ft2) :  \n    trace0 = go.Scatter(\n        x = M[ft1],\n        y = M[ft2],\n        name = 'malignant',\n        mode = 'markers', \n        marker = dict(color = '#FFD700',\n            line = dict(\n                width = 1)))\n\n    trace1 = go.Scatter(\n        x = B[ft1],\n        y = B[ft2],\n        name = 'benign',\n        mode = 'markers',\n        marker = dict(color = '#7EC0EE',\n            line = dict(\n                width = 1)))\n\n    layout = dict(title = ft1 +\" \"+\"vs\"+\" \"+ ft2,\n                  yaxis = dict(title = ft2,zeroline = False),\n                  xaxis = dict(title = ft1, zeroline = False)\n                 )\n\n    plots = [trace0, trace1]\n\n    fig = dict(data = plots, layout=layout)\n    py.iplot(fig)","23547b90":"plot_ft1_ft2('perimeter_mean','radius_worst')\nplot_ft1_ft2('area_mean','radius_worst')\nplot_ft1_ft2('texture_mean','texture_worst')\nplot_ft1_ft2('area_worst','radius_worst')","8c639012":"plot_ft1_ft2('smoothness_mean','texture_mean')\nplot_ft1_ft2('radius_mean','fractal_dimension_worst')\nplot_ft1_ft2('texture_mean','symmetry_mean')\nplot_ft1_ft2('texture_mean','symmetry_se')","5f8160c8":"plot_ft1_ft2('area_mean','fractal_dimension_mean')\nplot_ft1_ft2('radius_mean','fractal_dimension_mean')\nplot_ft1_ft2('area_mean','smoothness_se')\nplot_ft1_ft2('smoothness_se','perimeter_mean')","dbb47cce":"df.head()","a49ef7ce":"# define X, y functions for our model\nX=df.drop('diagnosis',axis=1)\nX.head()","e658f537":"y=df['diagnosis']\ny.head()","6147c24a":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)","8d199a09":"logReg = LogisticRegression(solver = 'lbfgs', max_iter=9000,multi_class = 'multinomial', random_state = 42)\n\nstart_time=time.time()\n\nlogReg.fit(X_train, y_train)\n\nend_time=time.time()\n\nprint(\"---%s seconds ---\" % (end_time - start_time))","713d8b8a":"y_pred = logReg.predict(X_test)","324cead4":"print(y_pred.shape)","e7863edd":"print(accuracy_score(y_test, y_pred))","4de7cd3e":"print(confusion_matrix(y_test, y_pred))","a3d8d435":"print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(logReg.score(X_train, y_train)))","a154201a":"X_train","b2ef7580":"X_test","178d6a7a":"y_pred[1:6]","4fbede88":"y_pred = [\"M\" if x < 0.5 else \"B\" for x in y_pred]","61f07a2a":"y_pred[1:6]","51cfa04d":"from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,roc_auc_score","2a9d7430":"# Validating the train on the model\ny_train_pred =logReg.predict(X_train)\ny_train_prob =logReg.predict_proba(X_train)[:,1]\n\nprint(\"Accuracy Score of train\", accuracy_score(y_train,y_train_pred))\nprint(\"AUC of the train \", roc_auc_score(y_train,y_train_prob))\nprint(\" confusion matrix \\n\" , confusion_matrix(y_train,y_train_pred))","abbd4ae5":"# Validating the test on the model\ny_test_pred=logReg.predict(X_test)\ny_test_prob=logReg.predict_proba(X_test)[:,1]\n\nprint(\"Accuracy Score of test\", accuracy_score(y_test,y_test_pred))\nprint(\"AUC od the test \", roc_auc_score(y_test,y_test_prob))\nprint(\" confusion matrix \\n\" , confusion_matrix(y_test,y_test_pred))","acfffdfe":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test,y_test_pred))","a968f8b8":"# read in the data and check the first 10 rows\ndataset = pd.read_csv('..\/input\/data.csv')\ndataset.head(10)","0326d1bf":"cols = ['id', \n        'Unnamed: 32']\ndataset = dataset.drop(cols, axis=1)\ndataset.head()","2f90a4a7":"# drop unncessary columns\ndataset=dataset.drop([\"perimeter_mean\",\"radius_mean\",\"compactness_mean\",\"concave points_mean\",\"radius_se\",\"perimeter_se\",\n                     \"radius_worst\",\"perimeter_worst\",\"compactness_worst\",\"concave points_worst\",\"compactness_se\",\n                     \"concave points_se\",\"texture_worst\",\"area_worst\"],axis=1)","fbc008b6":"X1=dataset.drop(\"diagnosis\",axis=1)\nX1.head()","6472f7b7":"y1=dataset['diagnosis']\ny1.head()","ed217585":"X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.3, random_state = 42)","85e20000":"logReg1 = LogisticRegression(solver = 'lbfgs', max_iter=9000,multi_class = 'multinomial', random_state = 42)\n\nstart_time=time.time()\n\nlogReg1.fit(X1_train, y1_train)\n\nend_time=time.time()\n\nprint(\"---%s seconds ---\" % (end_time - start_time))","6b8e06ed":"y1_pred = logReg1.predict(X1_test)","e4428472":"print(y1_pred.shape)","83be847a":"print(accuracy_score(y1_test, y1_pred))","651a5dc9":"print(confusion_matrix(y1_test, y1_pred))","5f5abe2d":"# Validating the train on the model\ny1_train_pred =logReg1.predict(X1_train)\ny1_train_prob =logReg1.predict_proba(X1_train)[:,1]\n\nprint(\"Accuracy Score of train\", accuracy_score(y1_train,y1_train_pred))\nprint(\"AUC of the train \", roc_auc_score(y1_train,y1_train_prob))\nprint(\" confusion matrix \\n\" , confusion_matrix(y1_train,y1_train_pred))","ae5925db":"# Validating the test on the model\ny1_test_pred=logReg1.predict(X1_test)\ny1_test_prob=logReg1.predict_proba(X1_test)[:,1]\n\nprint(\"Accuracy Score of test\", accuracy_score(y1_test,y1_test_pred))\nprint(\"AUC of the test \", roc_auc_score(y1_test,y1_test_prob))\nprint(\" confusion matrix \\n\" , confusion_matrix(y1_test,y1_test_pred))","1c29255e":"from sklearn.metrics import classification_report\n\nprint(classification_report(y1_test,y1_test_pred))","a76a1184":"new_df = pd.read_csv('..\/input\/data - Copy.csv')","8cde762f":"# drop unncessary columns\nnew_df=new_df.drop([\"perimeter_mean\",\"radius_mean\",\"compactness_mean\",\"concave points_mean\",\"radius_se\",\"perimeter_se\",\n                     \"radius_worst\",\"perimeter_worst\",\"compactness_worst\",\"concave points_worst\",\"compactness_se\",\n                     \"concave points_se\",\"texture_worst\",\"area_worst\",\"fractal_dimension_worst\",\"id\"],axis=1)","a1d20ff7":"new_df.diagnosis.replace(to_replace = dict(M = 1, B = 0), inplace = True)","640ed6d4":"new_df","75a88550":"prediction = logReg1.predict(new_df)","fcb70d22":"prediction","794dc3d1":"Now run the logistic regression and take a look at the results.","597be1a6":"The result is telling us that we have 106+60 correct predictions and 2+3 incorrect predictions.","77917b3a":"#### Uncorrelated features","0b01dd77":"### The Model\n---","4cac41f2":"Our model accurately predicts 97.0% of the test data with 16 features.","56cc359f":"### Positive correlated features","0edc9b6b":"We will generate a matrix similar to the one above, but this time displaying the correlations between the variables. Let's find out if our hypothesis about the multicollinearity has any statistical support.","1ad15fc8":"It's finally time to develop our model! We will start by first splitting our dataset into two parts; one as a training set for the model, and the other as a test set to validate the predictions that the model will make. If we omit this step, the model will be trained and tested on the same dataset, and it will underestimate the true error rate, a phenomenon known as overfitting. It is like writing an exam after taking a look at the questions and answers beforehand. We want to make sure that our model truly has predictive power and is able to accurately label unseen data. We will set the test size to 0.3; i.e., 70% of the data will be assigned to the training set, and the remaining 30% will be used as a test set. In order to obtain consistent results, we will set the random state parameter to a value of 40.","9d57d674":"# Test on unseen data","0505e7b8":"#### Logsitic Regression Model on ( 16 Features )","256402da":"<img src=\"https:\/\/content.linkedin.com\/content\/dam\/brand\/site\/img\/logo\/logo-tm.png\"\/>","192b695e":"Looking at the matrix, we can immediately verify the presence of multicollinearity between some of our variables. For instance, the radius_mean column has a correlation of 1 and 0.99 with perimeter_mean and area_mean columns, respectively. This is probably because the three columns essentially contain the same information, which is the physical size of the observation (the cell). Therefore we should only pick one of the three columns when we go into further analysis.","f473d668":"Lets check how the model performs on all features when we make predictions ","03866e19":"We have successfully developed a logistic regression model. This model can take some unlabeled data and effectively assign each observation a probability ranging from 0 to 1. This is the key feature of a logistic regression model. However, for us to evaluate whether the predictions are accurate, the predictions must be encoded so that each instance can be compared directly with the labels in the test data. In other words, instead of numbers between 0 or 1, the predictions should show \"M\" or \"B\", denoting malignant and benign respectively. In our model, a probability of 1 corresponds to the \"Benign\" class, whereas a probability of 0 corresponds to the \"Malignant\" class. Therefore, we can apply a threshhold value of 0.5 to our predictions, assigning all values closer to 0 a label of \"M\" and assigniing all values closer to 1 a label of \"B\".","8bb76982":"It looks like our data does not contain any missing values, except for our suspect column **Unnamed: 32**, which is full of missing values. Let's go ahead and remove this column entirely. After that, let's check for the data type of each column.","bfa367f2":"Our response variable, **diagnosis**, is categorical and has two classes,  'B' (Benign) and 'M' (Malignant). All explanatory variables are numerical, so we can skip data type conversion.\n\nLet's now take a closer look at our response variable, since it is the main focus of our analysis. We begin by checking out the distribution of its classes.","250bc359":"Out of the 569 observations, 357 (or 62.7%) have been labeled malignant, while the rest 212 (or 37.3%) have been labeled benign. Later when we develop a predictive model and test it on unseen data, we should expect to see a similar proportion of labels.\n\nAlthough our dataset has 30 columns excluding the **id** and the **diagnosis** columns, they are all in fact very closely related since they all contain information on the same 10 key attributes but only differ in terms of their perspectives (i.e., the mean, standard errors, and the mean of the three largest values denoted as \"worst\"). \n\nIn this sense, we could attempt to dig out some quick insights by analyzing the data in only one of the three perspectives. For instance, we could choose to check out the relationship between the 10 key attributes and the **diagnosis** variable by only choosing the \"mean\" columns.\n\nLet's quickly scan for any interesting patterns between our 10 \"mean\" columns and the response variable by generating a scatter plot matrix as shown below:","f7afe83d":"# Predicting Breast Cancer - Logistic Regression\n---\n**Bashir Abubakar**\n\n# Introduction\n\nThe contents of this notebook:\n1. **The Data** - *Exploratory Data Analysis*\n2. **The Variables** - *Feature Selection*\n3. **The Model** - *Building a Logistic Regression Model*\n4. **The Prediction** - *Making Predictions with the Model*\n\n**Let's explore the Breast Cancer dataset and develop a Logistic Regression model to predict classification of suspected cells to Benign or Malignant.**\n\n# Data\n---\n*Extracted from the popular [UCI ML repository](https:\/\/archive.ics.uci.edu\/ml\/datasets\/Breast+Cancer+Wisconsin+%28Diagnostic%29)*\n\n### Attribute Information:\n\n* **id** \n* **diagnosis**: M = malignant, B = benign\n\n*Columns 3 to 32* \n\nTen real-valued features are computed for each cell nucleus: \n\n* **radius**: distances from center to points on the perimeter \n* **texture**: standard deviation of gray-scale values\n* **perimeter** \n* **area** \n* **smoothness**: local variation in radius lengths \n* **compactness**: perimeter^2 \/ area - 1.0 \n* **concavity**: severity of concave portions of the contour\n* **concave points**: number of concave portions of the contour\n* **symmetry** \n* **fractal dimension**: \"coastline approximation\" - 1\n\nThe mean, standard error, and \"worst\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features.  For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius.\n\n---","9cd38a86":"This is the end of our exploration.","d4af05b3":"Now that we have split our data into appropriate sets, let's write the code to be used for the logistic regression.","3af3a46c":"#### Logistic Regression Model on all Features","6fe1b321":"# Let's Connect on LinkedIn!\nIf anybody would like to discuss any other projects or just have a chat about data science topics, I'll be more than happy to connect with you on **LinkedIn:**\nhttps:\/\/www.linkedin.com\/in\/bashir-abubakar-61935417b\/","87e3b73f":"Let's check the correlation between few features by pair","d1618598":"Our response variable 'diagnosis', is categorical and has two classes, 'B' (Benign) and 'M' (Malignant). All explanatory variables are numerical, so we can skip data type conversion.\n\nLet's now take a closer look at our response variable, since it is the main focus of our analysis. We begin by checking out the distribution of its classes.","4b1160b3":"Compute precision, recall, F-measure and support\n\nTo quote from Scikit Learn:\n\nThe precision is the ratio tp \/ (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier to not label a sample as positive if it is negative.\n\nThe recall is the ratio tp \/ (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n\nThe F-beta score can be interpreted as a weighted harmonic mean of the precision and recall, where an F-beta score reaches its best value at 1 and worst score at 0.\n\nThe F-beta score weights the recall more than the precision by a factor of beta. beta = 1.0 means recall and precision are equally important.\n\nThe support is the number of occurrences of each class in y_test. Our model accurately predicts 97.0% of the test data.","cd8ac373":"The last column, **Unnamed:32**, seems like it has a lot of missing values. Let's quickly check for any missing values for other columns as well.","70b92be9":"There are some interesting patterns visible. For instance, the almost perfectly linear patterns between the radius, perimeter and area attributes are hinting at the presence of multicollinearity between these variables. Another set of variables that possibly imply multicollinearity are the concavity, concave_points and compactness.","dfcc6e11":"We can confirm that probabilities closer to 0 have been labeled as \"M\", while the ones closer to 1 have been labeled as \"B\". Now we are able to evaluate the accuracy of our predictions by checking out the classification report and the confusion matrix.","dd008a7b":"Another place where multicollienartiy is apparent is between the \"mean\" columns and the \"worst\" column. For instance, the radius_mean column has a correlation of 0.97 with the radius_worst column. In fact, each of the 10 key attributes display very high (from 0.7 up to 0.97) correlations between its \"mean\" and \"worst\" columns. This is somewhat inevitable, because the \"worst\" columns are essentially just a subset of the \"mean\" columns; the \"worst\" columns are also the \"mean\" of some values (the three largest values among all observations). Therefore, I think we should discard the \"worst\" columns from our analysis and only focus on the \"mean\" columns when training our model."}}