{"cell_type":{"fd171bb0":"code","ff6b63d1":"code","d4d12973":"code","04bd5244":"code","38b665ce":"code","65e31f43":"code","286e8db6":"code","80847fdb":"code","b9523c3b":"code","52c0f2e1":"markdown","e6cc4cb2":"markdown","16213dbf":"markdown","8295fec6":"markdown","784f2144":"markdown","a003455a":"markdown","f9b36b51":"markdown","23e24e32":"markdown"},"source":{"fd171bb0":"%%time\n\nimport os\nimport logging\nimport sys\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import roc_auc_score\n\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingClassifier as HGBClassifier\nfrom sklearn.ensemble import VotingClassifier\n\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier","ff6b63d1":"%%time\n\nfolds_dir = \"..\/input\/tps-september-2021-skfolds\/\"\ndata_dir = \"..\/input\/tabular-playground-series-sep-2021\/\"\n\ndf_train = pd.read_csv(folds_dir + \"train_folds.csv\")\ndf_test = pd.read_csv(data_dir + \"test.csv\")\nsubmission = pd.read_csv(data_dir + \"sample_solution.csv\")\n\nfeatures = [col for col in df_test.columns if \"f\" in col]\ndf_test = df_test[features]\n\n# constants\nTARGET = \"claim\"","d4d12973":"%%time\n\ndef add_new_features(df):\n    # https:\/\/www.kaggle.com\/realtimshady\/single-simple-lightgbm\n    df[\"n_missing\"] = df[features].isna().sum(axis=1)\n    df[\"n_missing_std\"] = df.isna().std(axis=1).astype(\"float\")\n    df[\"abs_sum\"] = df[features].abs().sum(axis=1)\n    df[\"sem\"] = df[features].sem(axis=1)\n    df[\"std\"] = df[features].std(axis=1)\n    df[\"avg\"] = df[features].mean(axis=1)\n    df[\"max\"] = df[features].max(axis=1)\n    df[\"min\"] = df[features].min(axis=1)\n    \n    return df\n\ndf_train = add_new_features(df_train)\ndf_test = add_new_features(df_test)\n\nnew_features = [\"n_missing\", \"n_missing_std\", \"abs_sum\", \n             \"sem\", \"std\", \"avg\", \"max\", \"min\"]\n\nfeatures += new_features","04bd5244":"fill_value_dict = {\n    \"f1\": \"Mean\", \n    \"f2\": \"Median\", \n    \"f3\": \"Median\", \n    \"f4\": \"Median\", \n    \"f5\": \"Mode\", \n    \"f6\": \"Mean\", \n    \"f7\": \"Median\", \n    \"f8\": \"Median\", \n    \"f9\": \"Median\", \n    \"f10\": \"Median\", \n    \"f11\": \"Mean\", \n    \"f12\": \"Median\", \n    \"f13\": \"Mean\", \n    \"f14\": \"Median\", \n    \"f15\": \"Mean\", \n    \"f16\": \"Median\", \n    \"f17\": \"Median\", \n    \"f18\": \"Median\", \n    \"f19\": \"Median\", \n    \"f20\": \"Median\", \n    \"f21\": \"Median\", \n    \"f22\": \"Mean\", \n    \"f23\": \"Mode\", \n    \"f24\": \"Median\", \n    \"f25\": \"Median\", \n    \"f26\": \"Median\", \n    \"f27\": \"Median\", \n    \"f28\": \"Median\", \n    \"f29\": \"Mode\", \n    \"f30\": \"Median\", \n    \"f31\": \"Median\", \n    \"f32\": \"Median\", \n    \"f33\": \"Median\", \n    \"f34\": \"Mean\", \n    \"f35\": \"Median\", \n    \"f36\": \"Mean\", \n    \"f37\": \"Median\", \n    \"f38\": \"Median\", \n    \"f39\": \"Median\", \n    \"f40\": \"Mode\", \n    \"f41\": \"Median\", \n    \"f42\": \"Mode\", \n    \"f43\": \"Mean\", \n    \"f44\": \"Median\", \n    \"f45\": \"Median\", \n    \"f46\": \"Mean\", \n    \"f47\": \"Mode\", \n    \"f48\": \"Mean\", \n    \"f49\": \"Mode\", \n    \"f50\": \"Mode\", \n    \"f51\": \"Median\", \n    \"f52\": \"Median\", \n    \"f53\": \"Median\", \n    \"f54\": \"Mean\", \n    \"f55\": \"Mean\", \n    \"f56\": \"Mode\", \n    \"f57\": \"Mean\", \n    \"f58\": \"Median\", \n    \"f59\": \"Median\", \n    \"f60\": \"Median\", \n    \"f61\": \"Median\", \n    \"f62\": \"Median\", \n    \"f63\": \"Median\", \n    \"f64\": \"Median\", \n    \"f65\": \"Mode\", \n    \"f66\": \"Median\", \n    \"f67\": \"Median\", \n    \"f68\": \"Median\", \n    \"f69\": \"Mean\", \n    \"f70\": \"Mode\", \n    \"f71\": \"Median\", \n    \"f72\": \"Median\", \n    \"f73\": \"Median\", \n    \"f74\": \"Mode\", \n    \"f75\": \"Mode\", \n    \"f76\": \"Mean\", \n    \"f77\": \"Mode\", \n    \"f78\": \"Median\", \n    \"f79\": \"Mean\", \n    \"f80\": \"Median\", \n    \"f81\": \"Mode\", \n    \"f82\": \"Median\", \n    \"f83\": \"Mode\", \n    \"f84\": \"Median\", \n    \"f85\": \"Median\", \n    \"f86\": \"Median\", \n    \"f87\": \"Median\", \n    \"f88\": \"Median\", \n    \"f89\": \"Median\", \n    \"f90\": \"Mean\", \n    \"f91\": \"Mode\", \n    \"f92\": \"Median\", \n    \"f93\": \"Median\", \n    \"f94\": \"Median\", \n    \"f95\": \"Median\", \n    \"f96\": \"Median\", \n    \"f97\": \"Mean\", \n    \"f98\": \"Median\", \n    \"f99\": \"Median\", \n    \"f100\": \"Mode\", \n    \"f101\": \"Median\", \n    \"f102\": \"Median\", \n    \"f103\": \"Median\", \n    \"f104\": \"Median\", \n    \"f105\": \"Median\", \n    \"f106\": \"Median\", \n    \"f107\": \"Median\", \n    \"f108\": \"Median\", \n    \"f109\": \"Mode\", \n    \"f110\": \"Median\", \n    \"f111\": \"Median\", \n    \"f112\": \"Median\", \n    \"f113\": \"Mean\", \n    \"f114\": \"Median\", \n    \"f115\": \"Median\", \n    \"f116\": \"Mode\", \n    \"f117\": \"Median\", \n    \"f118\": \"Mean\"\n}\n\n\nfor col in tqdm(features):\n    if fill_value_dict.get(col)==\"Mean\":\n        fill_value = df_train[col].mean()\n    elif fill_value_dict.get(col)==\"Median\":\n        fill_value = df_train[col].median()\n    elif fill_value_dict.get(col)==\"Mode\":\n        fill_value = df_train[col].mode().iloc[0]\n    \n    df_train[col].fillna(fill_value, inplace=True)\n    df_test[col].fillna(fill_value, inplace=True)","38b665ce":"%%time\n\npipe = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"constant\", missing_values=np.nan)),\n    (\"scaler\", RobustScaler())\n])\n\ndf_train[features] = pipe.fit_transform(df_train[features])\ndf_test[features] = pipe.transform(df_test[features])","65e31f43":"lgb_params = {\n    \"metric\" : \"auc\",\n    \"max_depth\" : 3,\n    \"num_leaves\" : 7,\n    \"n_estimators\" : 5000,\n    \"colsample_bytree\" : 0.3,\n    \"subsample\" : 0.5,\n    \"random_state\" : 42,\n    \"reg_alpha\" : 18,\n    \"reg_lambda\" : 17,\n    \"learning_rate\" : 0.095,\n    \"objective\" : \"binary\"\n}\n\nxgb_params = {\n    \"eval_metric\" : \"auc\",\n    \"lambda\": 0.004562711234493688, \n    \"alpha\": 7.268146704546314, \n    \"colsample_bytree\": 0.6468987558386358, \n    \"colsample_bynode\": 0.29113878257290376, \n    \"colsample_bylevel\": 0.8915913499148167, \n    \"subsample\": 0.37130229826185135, \n    \"learning_rate\": 0.021671163563123198, \n    \"grow_policy\": \"lossguide\", \n    \"max_depth\": 18, \n    \"min_child_weight\": 215, \n    \"max_bin\": 272,\n    \"n_estimators\": 10000,\n    \"random_state\": 0,\n    \"use_label_encoder\": False,\n    \"objective\": \"binary:logistic\",\n    \"tree_method\": \"gpu_hist\",\n    # gpu\n    \"gpu_id\": 0,\n    \"predictor\": \"gpu_predictor\"\n}\n\ncb_params = {\n    \"random_state\": 42,\n    \"eval_metric\" : \"AUC\",\n    \"iterations\": 15585, \n    \"objective\": \"CrossEntropy\",\n    \"bootstrap_type\": \"Bernoulli\", \n    \"od_wait\": 1144, \n    \"learning_rate\": 0.023575206684596582, \n    \"reg_lambda\": 36.30433203563295, \n    \"random_strength\": 43.75597655616195, \n    \"depth\": 7, \n    \"min_data_in_leaf\": 11, \n    \"leaf_estimation_iterations\": 1, \n    \"subsample\": 0.8227911142845009,\n    \"verbose\" : 0,\n    # gpu\n    \"task_type\" : \"GPU\",\n    \"devices\" : \"0\",\n}\n\nhgb_params = {\n    \"random_state\": 666, \n    \"scoring\": \"roc_auc\",\n    \"max_iter\": 40000,\n    \"learning_rate\": 0.025,\n    \"validation_fraction\": 0.1,\n    \"early_stopping\": True,\n    \"max_depth\": 15, \n    \"max_leaf_nodes\": 17, \n    \"min_samples_leaf\": 12173,\n}","286e8db6":"def predict(df_train, df_test, folds=5):\n    test_preds = []\n    valid_preds = {}\n    scores = []\n    \n    models = [\n        (\"lgb\", LGBMClassifier(**lgb_params)),\n        (\"xgb\", XGBClassifier(**xgb_params)),\n        (\"cb\", CatBoostClassifier(**cb_params)),\n        (\"hgb\", HGBClassifier(**hgb_params))\n    ]\n    \n    weights = [0.5, 0.4, 0.4, 0.3]\n    \n    for fold in range(folds):\n        x_train = df_train[df_train.kfold != fold].reset_index(drop=True)\n        x_valid = df_train[df_train.kfold == fold].reset_index(drop=True)\n        x_test = df_test.copy()\n        \n        valid_ids = x_valid.id.values.tolist()\n\n        y_train = x_train[TARGET]\n        y_valid = x_valid[TARGET]\n\n        x_train = x_train[features]\n        x_valid = x_valid[features]\n\n        model = VotingClassifier(\n            estimators = models,\n            voting = \"soft\",\n            weights = weights,\n            n_jobs = -1\n        )\n        model.fit(x_train, y_train)\n        \n        valid_pred = model.predict_proba(x_valid)[:, 1]\n        test_pred = model.predict_proba(x_test)[:, 1]\n        \n        test_preds.append(test_pred)\n        valid_preds.update(dict(zip(valid_ids, valid_pred)))\n\n        score = roc_auc_score(y_valid, valid_pred)\n        print(f\"Fold {fold} | AUC: {score}\")\n        scores.append(score)\n    \n    test_preds = np.mean(np.column_stack(test_preds), axis=1)\n    valid_preds = pd.DataFrame.from_dict(valid_preds, orient=\"index\").reset_index()\n    \n    return test_preds, valid_preds, scores","80847fdb":"test_preds, valid_preds, scores = predict(df_train, df_test)\nprint(np.mean(scores), np.std(scores))","b9523c3b":"valid_preds.columns = [\"id\", \"vote_pred_2\"]\nvalid_preds.to_csv(\"vote_train_2.csv\", index=False)\n\ntest_preds_df = pd.DataFrame({\"id\": submission.id, \"vote_pred_2\": test_preds})\ntest_preds_df.to_csv(\"vote_test_2.csv\", index=False)\n\nsub = pd.DataFrame({\"id\": submission.id, \"claim\": test_preds})\nsub.to_csv(\"submission.csv\", index=False)","52c0f2e1":"## Model params","e6cc4cb2":"## Feature engineering","16213dbf":"## Predict","8295fec6":"## Import libraries","784f2144":"# TPS September 2021 - VotingClassifier Baseline","a003455a":"## Preprocessing","f9b36b51":"## Save","23e24e32":"## Load datasets"}}