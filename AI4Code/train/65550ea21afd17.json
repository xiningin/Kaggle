{"cell_type":{"7b9faa28":"code","0dfcf876":"code","5dcefda6":"code","0017a74f":"code","b093a09a":"code","040e032d":"code","cc6194b5":"markdown"},"source":{"7b9faa28":"import numpy as np\nimport pandas as pd\nimport os\n\nPATH = \"\/kaggle\/input\/applications-of-deep-learning-wustlfall-2021\/city\/\"\nPATH_TRAIN = os.path.join(PATH, \"train.csv\")\nPATH_TEST = os.path.join(PATH, \"test.csv\")","0dfcf876":"import sys\nimport tensorflow.keras\nimport pandas as pd\nimport sklearn as sk\nimport tensorflow as tf\n\nprint(f\"Tensor Flow Version: {tf.__version__}\")\nprint(f\"Keras Version: {tensorflow.keras.__version__}\")\nprint()\nprint(f\"Python {sys.version}\")\nprint(f\"Pandas {pd.__version__}\")\nprint(f\"Scikit-Learn {sk.__version__}\")\nprint(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\nprint(\"Built with CUDA:\", tf.test.is_built_with_cuda())\nprint(\"Built with GPU support:\", tf.test.is_built_with_gpu_support())","5dcefda6":"df_train = pd.read_csv(PATH_TRAIN)\ndf_test = pd.read_csv(PATH_TEST)\n\ndf_train['filename'] = df_train.id.astype(str) + \".jpg\"\ndf_test['filename'] = df_test.id.astype(str) + \".jpg\"\n\nfrom sklearn.model_selection import train_test_split\ndf_train_cut, df_validate_cut = train_test_split(df_train, test_size=0.1, random_state = 42)\nprint(f\"Training size: {len(df_train_cut)}\")\nprint(f\"Validate size: {len(df_validate_cut)}\")","0017a74f":"import tensorflow as tf\nimport keras_preprocessing\nfrom keras_preprocessing import image\nfrom keras_preprocessing.image import ImageDataGenerator\n\nWIDTH = 299\nHEIGHT = 299\n\ntraining_datagen = ImageDataGenerator(\n  rescale = 1.\/255,\n  horizontal_flip=True,\n  #vertical_flip=True,\n  fill_mode='nearest')\n\ntrain_generator = training_datagen.flow_from_dataframe(\n        dataframe=df_train_cut,\n        directory=PATH,\n        x_col=\"filename\",\n        y_col=\"sqft\",\n        target_size=(HEIGHT, WIDTH),\n        batch_size=32, # Keeping the training batch size small USUALLY increases performance\n        class_mode='raw')\n\nvalidation_datagen = ImageDataGenerator(rescale = 1.\/255)\n\nval_generator = validation_datagen.flow_from_dataframe(\n        dataframe=df_validate_cut,\n        directory=PATH,\n        x_col=\"filename\",\n        y_col=\"sqft\",\n        target_size=(HEIGHT, WIDTH),\n        batch_size=128, # Make the validation batch size as large as you have memory for\n        class_mode='raw')","b093a09a":"from tensorflow.keras.applications import InceptionResNetV2\nfrom tensorflow.keras.layers import Input\n\ninput_tensor = Input(shape=(HEIGHT, WIDTH, 3))\n\nbase_model = InceptionResNetV2(\n    include_top=False, weights=None, input_tensor=input_tensor,\n    input_shape=None)\n\n#base_model.summary()\n\n\n\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\n\nx=base_model.output\nx=GlobalAveragePooling2D()(x)\nx=Dense(2048,activation='relu')(x) \nx=Dense(2048,activation='relu')(x) \nmodel=Model(inputs=base_model.input,outputs=Dense(1)(x))\n\n#model.summary()\n\n\n\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.metrics import RootMeanSquaredError\n\n# Important, calculate a valid step size for the validation dataset\nSTEP_SIZE_VALID=val_generator.n\/\/val_generator.batch_size\n\nmodel.compile(loss = 'mean_squared_error', optimizer='adam', metrics=[RootMeanSquaredError(name=\"rmse\")])\nmonitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=50, verbose=1, mode='auto',\n        restore_best_weights=True)\n\nhistory = model.fit(train_generator, epochs=200, steps_per_epoch=250, \n                    validation_data = val_generator, callbacks=[monitor],\n                    verbose = 1, validation_steps=STEP_SIZE_VALID)\n\n\n\nsubmit_datagen = ImageDataGenerator(rescale = 1.\/255)\n\nsubmit_generator = submit_datagen.flow_from_dataframe(\n        dataframe=df_test,\n        directory=PATH,\n        x_col=\"filename\",\n        batch_size = 1,\n        shuffle = False,\n        target_size=(HEIGHT, WIDTH),\n        class_mode=None)\n\nsubmit_generator.reset()\npred = model.predict(submit_generator,steps=len(df_test))","040e032d":"df_submit = pd.DataFrame({\"id\":df_test['id'],'sqft':pred[:,0].flatten()})\ndf_submit.to_csv(\".\/kaggle\/working\/InceptionResNetV2_Epochs200_ImgSize299_2048.csv\",index = False)","cc6194b5":"# Kaggle Transfer Learning Code for the City Square Feed Kaggle In-Class Competition\n\nThis workbook is the best single model of 'We tried though' team. (Submission score: 465.56332)\nBut our best result was achieved by a 'manual' ensemble of our 8 best candidate models using MS Excel. (Submission score: 422.07944)\n\nIn this single model, we chose InceptionResNetv3, with parameters of the following.\n - Image Size: 299*299 (Model\u2019s Original Input Size)\n - Output Layer: 2048-2048-1 (ReLU)\n - Epochs: 200 (Early Stopped at 154)"}}