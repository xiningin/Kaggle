{"cell_type":{"ec11a033":"code","ce328a5e":"code","be737ead":"code","2b253174":"code","9ad6d556":"code","f349a451":"code","e75bb990":"code","e29c73dd":"code","a94ebfc9":"code","0d762d9b":"code","b9b560c2":"code","924fcb62":"code","53df1db6":"code","e8ecf94f":"code","d266f6aa":"code","eef0576d":"markdown","148a1518":"markdown","0b04afca":"markdown","7e70ed38":"markdown","e2874d6a":"markdown","a2ef68da":"markdown","750df648":"markdown","ea332025":"markdown","2bd2d494":"markdown"},"source":{"ec11a033":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ce328a5e":"train = pd.read_csv('\/kaggle\/input\/assignment-3-data\/train.csv')\nprint(train.shape)\ntest = pd.read_csv('\/kaggle\/input\/assignment-3-data\/eval.csv')","be737ead":"train.info()\ntrain = train.astype('float32')\ntest = test.astype('float32')","2b253174":"print(test.shape)\nprint(train.shape)","9ad6d556":"train.head(10)","f349a451":"td = test['id']\ntest.drop(['id', 'pubchem_id'], axis = 1, inplace = True)\ntrain.drop(['id', 'pubchem_id'], axis = 1, inplace = True)","e75bb990":"y = train['Eat']\nX = train.drop(columns = ['Eat'])\ny = np.array(y)\nX = np.array(X)\ntest = np.array(test)\n\n\nprint(y.shape)\nprint(X.shape)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 123)","e29c73dd":"test.shape","a94ebfc9":"print(X_train.shape)\nprint(y_train.shape)","0d762d9b":"model = tf.keras.Sequential([\n    tf.keras.layers.Dense(256, input_dim = 1275, activation = 'relu'),\n    tf.keras.layers.Dense(64, activation = 'relu'),\n    tf.keras.layers.Dense(8)\n])\n\nmodel.compile(optimizer = 'adam',\n              loss = 'mean_absolute_error',\n              metrics = ['accuracy'])\n\nmodel.fit(X_train, y_train, batch_size = 15, verbose = 1, validation_split = 0.2,epochs = 10)","b9b560c2":"scores = model.evaluate(X_test, y_test, batch_size=128)\nscoresdf = pd.DataFrame(scores, columns = ['CVS'])\nprint(scoresdf.describe())\nplt.hist(scoresdf['CVS'])","924fcb62":"my_guess = model.predict(test)","53df1db6":"my_guess1 = [i[7] for i in my_guess] \nmy_guess1","e8ecf94f":"submission = pd.DataFrame({'id':td, 'Eat': my_guess1})\nsubmission['id'] = submission['id'].astype(int)\nsubmission.to_csv('csv_to_submit.csv', index = False)\nprint('saved file: ' + filename)","d266f6aa":"print(submission.to_string())","eef0576d":"# Convert train\/test data to a single numeric type (float)","148a1518":"We looked at the shape and now we see the head to give a general view of our data","0b04afca":"# SEQUENTIAL MODEL","7e70ed38":"Lets get rid of the 2 ID columns as they arent necessary for the model to know or learn anything of use","e2874d6a":"Submission file created and printed","a2ef68da":"# Read CSV files","750df648":"Scores and distribution for the model","ea332025":"Split our training data to prepare it for our model\nWe need array format in order to directly fit it to the model","2bd2d494":"predict on test set"}}