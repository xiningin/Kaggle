{"cell_type":{"7f0703eb":"code","2e45e3d3":"code","ef744fd2":"code","cae99962":"code","5e88bcb0":"code","2ffb8d3a":"code","ed58fbdc":"code","7e631620":"code","4a1ad266":"code","1a70078d":"code","9c86710b":"code","9d30f83a":"code","7776864b":"code","e806ad04":"code","0220c01f":"code","3b1bf609":"code","3b9af64d":"code","7421fc2b":"code","c506a78a":"code","76358936":"code","fb6bd8fb":"code","9f900390":"code","2fc59f32":"code","e8ad8c99":"code","f30aa850":"code","614a9c8b":"code","3aa06cca":"code","04562c91":"code","82190771":"code","5fb40e3a":"code","6b243ded":"code","f7d232c6":"markdown","9098552a":"markdown","f902ed5f":"markdown","c754c861":"markdown","0453a3db":"markdown","3e1c46a6":"markdown","d3e493f0":"markdown","2ad692db":"markdown","e4e67d0a":"markdown","d75474d1":"markdown","f3f18c7b":"markdown","f40983ec":"markdown","dacdd46f":"markdown","c6c9ab27":"markdown"},"source":{"7f0703eb":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport gc\n# neural nets\nimport tensorflow as tf\nimport tensorflow.keras.models as M\nimport tensorflow.keras.layers as L\n# riiid\nimport riiideducation\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","2e45e3d3":"gc.collect()","ef744fd2":"INPUT_DIR = '\/kaggle\/input\/riiid-test-answer-prediction\/'\nTRAIN_FILE = os.path.join(INPUT_DIR,'train.csv')\nTEST_FILE = os.path.join(INPUT_DIR,'test.csv')\nQUES_FILE = os.path.join(INPUT_DIR,'questions.csv')\nLEC_FILE = os.path.join(INPUT_DIR,'lectures.csv')","cae99962":"tr = pd.read_csv(TRAIN_FILE,\n                   usecols=[1, 2, 3, 4, 7, 8, 9],\n                   dtype={'timestamp': 'int64',\n                          'user_id': 'int32',\n                          'content_id': 'int16',\n                          'content_type_id': 'int8',\n                          'answered_correctly':'int8',\n                          'prior_question_elapsed_time': 'float32',\n                          'prior_question_had_explanation': 'boolean'}\n                   )\n\ntr.head()","5e88bcb0":"def ds_to_pickle(ds, ds_file, pkl_file):\n    ds.to_pickle(pkl_file)\n    print(\"Saving to pkl file to save some space and time, take a look at some stats:\")\n    print(\"train.csv:\", os.stat(ds_file).st_size * 1e-6)\n    print(\"train.pkl:\", os.stat(pkl_file).st_size * 1e-6)\n    del ds\n    return pd.read_pickle('tr.pkl')\n    \n    ","2ffb8d3a":"tr = ds_to_pickle(tr, TRAIN_FILE, 'tr.pkl')","ed58fbdc":"tr.info()","7e631620":"total_num_users = tr.user_id.unique().size\nunique_user_ids = list(tr.user_id.unique())\nprint('Total num users:', total_num_users)\nprint('Sneak peek of the list of all unique user ids... \\\n        \\nMin:', min(unique_user_ids), '\\nMax:', max(unique_user_ids),\n        '\\nFirst 10 user IDs:', unique_user_ids[:10])","4a1ad266":"total_num_ques = tr.loc[tr.content_type_id==0].content_id.unique().size\nunique_ques = list(tr.loc[tr.content_type_id==0].content_id.unique())\nprint('Total num ques:',total_num_ques)\nprint('Sneak peek of unique ques:', '\\nMin:',min(unique_ques), '\\nMax:',max(unique_ques),\\\n       '\\nFirst 10 Ques:',unique_ques[:10])","1a70078d":"num_ques_per_user = pd.DataFrame({\"user_id\":list(tr.loc[tr.content_type_id==0].user_id.unique()), \\\n                                 \"num_ques_answered\":list(tr.loc[tr.content_type_id==0].user_id.value_counts())}, \n                                 )\nnum_ques_answered = num_ques_per_user.sort_values('num_ques_answered')['num_ques_answered'].\\\n                                                    to_frame(name='num_ques_answered')\n","9c86710b":"print(num_ques_answered.min(), num_ques_answered.max())","9d30f83a":"def remove_user_by_num_ques_ans(num_ques_ans_thresh=100, tr=None):\n    num_ques_ans_filtered = num_ques_answered.loc[num_ques_answered.num_ques_answered > num_ques_ans_thresh].\\\n                                            rename(columns=\\\n                                            {'num_ques_answered':'num_ques_answered_gt_'+str(num_ques_ans_thresh)})\n    num_ques_per_user_gt_thresh = num_ques_per_user.loc[num_ques_per_user.num_ques_answered > num_ques_ans_thresh].\\\n                                                rename(columns={'num_ques_answered':'num_ques_answered_gt'+str(num_ques_ans_thresh)})\n    new_tr = tr[tr['user_id'].isin(list(num_ques_per_user_gt_thresh['user_id']))]\n    print(new_tr)\n    return num_ques_per_user_gt_thresh, new_tr","7776864b":"num_ques_answered_gt_100, tr_user_ques_gt_100 = remove_user_by_num_ques_ans(100, tr=tr)","e806ad04":"new_num_rows = len(tr_user_ques_gt_100.index)\nold_num_rows = len(tr.index)\n\nprint('Old rows:', old_num_rows, '\\nNew rows:', new_num_rows, \\\n      '\\nReduced to:', new_num_rows*100\/old_num_rows,'% of original dataset size')\nprint('That\\'s a 70% reduction, YAY!')","0220c01f":"tr_user_ques_gt_100.to_pickle('tr_user_ans_gt_100_ques.pkl')","3b1bf609":"tr.info()","3b9af64d":"tr_user_ques_gt_100.info()","7421fc2b":"del tr","c506a78a":"tr = tr_user_ques_gt_100","76358936":"%%time\npiv1 = tr.loc[tr.answered_correctly!=-1].groupby(\"content_id\")[\"answered_correctly\"].mean().reset_index()\npiv1.columns = [\"content_id\", \"content_emb\"]\n\npiv3 = tr.loc[tr.answered_correctly!=-1].groupby(\"user_id\")[\"answered_correctly\"].mean().reset_index()\npiv3.columns = [\"user_id\", \"user_emb\"]","fb6bd8fb":"TIME_MEAN = tr.prior_question_elapsed_time.median()\nTIME_MIN = tr.prior_question_elapsed_time.min()\nTIME_MAX = tr.prior_question_elapsed_time.max()\nprint(TIME_MEAN,TIME_MAX, TIME_MIN)\nmap_prior = {True:1, False:0}","9f900390":"def preprocess(df):\n#     print('before merging:\\n',df[:10])\n    df = df.merge(piv1, how=\"left\", on=\"content_id\")\n#     print('merged piv1:\\n',df[:10])\n    df[\"content_emb\"] = df[\"content_emb\"].fillna(0.5)\n    df = df.merge(piv3, how=\"left\", on=\"user_id\")\n    df[\"user_emb\"] = df[\"user_emb\"].fillna(0.5)\n    df[\"prior_question_elapsed_time\"] = df[\"prior_question_elapsed_time\"].fillna(TIME_MEAN)\n    df[\"duration\"] = (df[\"prior_question_elapsed_time\"] - TIME_MIN) \/ (TIME_MAX - TIME_MIN)\n    df[\"prior_answer\"] = df[\"prior_question_had_explanation\"].map(map_prior)\n    df[\"prior_answer\"] = df[\"prior_answer\"].fillna(0.5)\n    return df","2fc59f32":"%%time\ntr_preprocessed = preprocess(tr)","e8ad8c99":"FE = [\"content_emb\",  \"user_emb\", \"duration\", \"prior_answer\"]\nTARGET = \"answered_correctly\"","f30aa850":"x = tr_preprocessed.loc[tr_preprocessed.answered_correctly!=-1, FE].values\ny = tr_preprocessed.loc[tr_preprocessed.answered_correctly!=-1, TARGET].values","614a9c8b":"# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)","3aa06cca":"# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","04562c91":"# instantiating the model in the strategy scope creates the model on the TPU\nwith tpu_strategy.scope():\n    def make_ann(n_in):\n        inp = L.Input(shape=(n_in,), name=\"inp\")\n        d1 = L.Dense(100, activation=\"relu\", name=\"d1\")(inp)\n        d2 = L.Dense(100, activation=\"relu\", name=\"d2\")(d1)\n        preds = L.Dense(1, activation=\"sigmoid\", name=\"preds\")(d2)\n\n        model = M.Model(inp, preds, name=\"ANN\")\n        model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n        return model\n","82190771":"net = make_ann(x.shape[1])\nprint(net.summary())","5fb40e3a":"net.fit(x, y, validation_split=0.2, batch_size=30_000, epochs=1)","6b243ded":"net.save('min_100_ques_50_epochs.h5')","f7d232c6":"## How many questions did each user answer?","9098552a":"# Reduce the Dataset by user_ids that answered very few questions","f902ed5f":"# Build and Train a Model","c754c861":"## Total number of Questions","0453a3db":"# Pre-process Dataset","3e1c46a6":"# Globals","d3e493f0":"## Convert to Pickle","2ad692db":"## Num Users","e4e67d0a":"# EDA","d75474d1":"## Training Set","f3f18c7b":"- We have number of questions answered by a user ranging from 1 to 17609\n  - take only user_id s that answered > 100 questions","f40983ec":"## Take off these Users from tr","dacdd46f":"# Garbage collect \n### Just run me every now and then to avoid overuse of resources!! ","c6c9ab27":"# Read Dataset"}}