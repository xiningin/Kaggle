{"cell_type":{"b81165f1":"code","e19b6514":"code","8a98ef02":"code","b44f7f5c":"code","dc214e03":"code","b247b8e7":"code","4f71a443":"code","95929185":"code","72314bd6":"code","d798f3cb":"code","e67dfe9a":"code","a496baaa":"code","1574f05c":"code","573c40cd":"code","910434ba":"code","106fba48":"code","a3caae3f":"code","bf217e1e":"code","af4e7707":"code","9bfcc3a4":"code","4b6efb0c":"code","ed0e15c5":"code","64cea5de":"code","a0558e77":"code","a3d48a39":"code","55554871":"code","39823549":"code","4d0e4c54":"code","41249377":"code","fd98731f":"code","cbf49b2d":"code","f7c2f675":"code","38068126":"code","bca10053":"code","1446c738":"code","749a425d":"code","5f2849fe":"code","767b330b":"code","5df38b4c":"code","6a511c4f":"code","a4c02120":"code","75a80451":"code","889aac13":"code","7d6f64c6":"code","f6a4e3ea":"code","c22c83b3":"code","4b542cbd":"code","576c27c0":"code","6c75d42a":"markdown","14d9e0cd":"markdown","f59d1bf3":"markdown","9381187e":"markdown","b1ef7b53":"markdown","6b09341a":"markdown","cad36a9a":"markdown","38317854":"markdown","a0033982":"markdown","9c8e7884":"markdown","67d17eab":"markdown","76d1a35b":"markdown","16dd63cc":"markdown","568c102f":"markdown","4973db3e":"markdown","bc75b0fc":"markdown","f76d7600":"markdown","5553caeb":"markdown","adcc7a34":"markdown","38f1a90c":"markdown","700dd8cf":"markdown","de2e89e0":"markdown","8c9bdf23":"markdown","3e943ecb":"markdown","ee6f84a4":"markdown","4d41ef8d":"markdown"},"source":{"b81165f1":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split,KFold,cross_val_score,GridSearchCV\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import f1_score, accuracy_score, confusion_matrix,classification_report,plot_confusion_matrix,plot_roc_curve,precision_score,roc_curve\nimport seaborn as sns\nfrom sklearn.utils import shuffle\nfrom pandas_profiling import ProfileReport\nfrom sklearn.linear_model import LogisticRegression, Perceptron, RidgeClassifier, SGDClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier \nfrom sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, VotingClassifier \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics","e19b6514":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","8a98ef02":"cd \/kaggle\/input\/encoding","b44f7f5c":"cd \/kaggle\/input\/disease-symptom-description-dataset","dc214e03":"df = pd.read_csv('dataset.csv')\ndf = shuffle(df,random_state=42)\ndf.head()","b247b8e7":"for col in df.columns:\n    \n    df[col] = df[col].str.replace('_',' ')\ndf.head()    ","4f71a443":"df.describe()","95929185":"null_checker = df.apply(lambda x: sum(x.isnull())).to_frame(name='count')\nprint(null_checker)","72314bd6":"plt.figure(figsize=(10,5))\nplt.plot(null_checker.index, null_checker['count'])\nplt.xticks(null_checker.index, null_checker.index, rotation=45,\nhorizontalalignment='right')\nplt.title('Before removing Null values')\nplt.xlabel('column names')\nplt.margins(0.1)\nplt.show()","d798f3cb":"cols = df.columns\ndata = df[cols].values.flatten()\n\ns = pd.Series(data)\ns = s.str.strip()\ns = s.values.reshape(df.shape)\n\ndf = pd.DataFrame(s, columns=df.columns)\ndf.head()","e67dfe9a":"df = df.fillna(0)\ndf.head()","a496baaa":"df1 = pd.read_csv('Symptom-severity.csv')\ndf1['Symptom'] = df1['Symptom'].str.replace('_',' ')\ndf1.head()","1574f05c":"df1['Symptom'].unique()","573c40cd":"vals = df.values\nsymptoms = df1['Symptom'].unique()\n\nfor i in range(len(symptoms)):\n    vals[vals == symptoms[i]] = df1[df1['Symptom'] == symptoms[i]]['weight'].values[0]\n    \nd = pd.DataFrame(vals, columns=cols)\nd.head()","910434ba":"d = d.replace('dischromic  patches', 0)\nd = d.replace('spotting  urination',0)\ndf = d.replace('foul smell of urine',0)\ndf.head(10)","106fba48":"null_checker = df.apply(lambda x: sum(x.isnull())).to_frame(name='count')\nprint(null_checker)","a3caae3f":"plt.figure(figsize=(10,5))\nplt.plot(null_checker.index, null_checker['count'])\nplt.xticks(null_checker.index, null_checker.index, rotation=45,\nhorizontalalignment='right')\nplt.title('After removing Null values')\nplt.xlabel('column names')\nplt.margins(0.01)\nplt.show()","bf217e1e":"print(\"Number of symptoms used to identify the disease \",len(df1['Symptom'].unique()))\nprint(\"Number of diseases that can be identified \",len(df['Disease'].unique()))","af4e7707":"new_df = pd.read_csv('\/kaggle\/input\/encoding\/newdf.csv')\nencoding = pd.read_csv('\/kaggle\/input\/encoding\/decryption.csv',index_col=0)\nnew_df.drop(labels=[\"132\",'74','0'],axis=1,inplace=True)\nrenameddf=new_df.rename(errors='raise',inplace=False,columns= {str(x):y for y,x in encoding.to_dict()['code'].items()})\nrenameddf\nplt.figure(figsize= (15,10))\nsns.heatmap(renameddf.corr(),cmap=\"PuBu\",annot=False)","9bfcc3a4":"# ProfileReport(df)","4b6efb0c":"df['Disease'].unique()","ed0e15c5":"data = df.iloc[:,1:].values\nlabels = df['Disease'].values","64cea5de":"x_train, x_test, y_train, y_test = train_test_split(data, labels, train_size = 0.8,random_state=42)\nprint(x_train.shape, x_test.shape, y_train.shape, y_test.shape)","a0558e77":"SVM_unhyperd= SVC()\nSVM_unhyperd.fit(x_train, y_train)","a3d48a39":"preds = SVM_unhyperd.predict(x_test)\nconf_mat = confusion_matrix(y_test, preds)\ndf_cm = pd.DataFrame(conf_mat, index=df['Disease'].unique(), columns=df['Disease'].unique())\nprint('F1-score% =', f1_score(y_test, preds, average='macro')*100, '|', 'Accuracy% =', accuracy_score(y_test, preds)*100,'|', 'Precision% =', precision_score(y_test, preds,average='macro')*100)","55554871":"sns.heatmap(df_cm)","39823549":"kfold = KFold(n_splits=10,shuffle=True,random_state=42)\nSVM_unhyperd_train =cross_val_score(SVM_unhyperd, x_train, y_train, cv=kfold, scoring='accuracy')\npd.DataFrame(SVM_unhyperd_train,columns=['Scores'])\nprint(\"Mean Accuracy: %.3f%%, Standard Deviation: (%.2f%%)\" % (SVM_unhyperd_train.mean()*100.0, SVM_unhyperd_train.std()*100.0))","4d0e4c54":"kfold = KFold(n_splits=10,shuffle=True,random_state=42)\nSVM_unhyperd_test =cross_val_score(SVM_unhyperd, x_test, y_test, cv=kfold, scoring='accuracy')\npd.DataFrame(SVM_unhyperd_test,columns=['Scores'])\nprint(\"Mean Accuracy: %.3f%%, Standard Deviation: (%.2f%%)\" % (SVM_unhyperd_test.mean()*100.0, SVM_unhyperd_test.std()*100.0))","41249377":"print(classification_report(y_test, preds))","fd98731f":"# param_grid = {'C': [0.2,0.4,0.6], 'gamma': [0.2,0.3,0.4,0],'kernel': ['linear','poly', 'sigmoid']}\n# grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\n# grid.fit(x_train,y_train)\n# print(grid.best_estimator_)\n# grid_predictions = grid.predict(x_test)\n# print(confusion_matrix(y_test,grid_predictions))\n# print(classification_report(y_test,grid_predictions))","cbf49b2d":"SVM_hyperd = SVC(C=0.02, gamma=0.3, kernel='poly')\nSVM_hyperd.fit(x_train, y_train)\npreds = SVM_hyperd.predict(x_test)\nconf_mat = confusion_matrix(y_test, preds)\ndf_cm = pd.DataFrame(conf_mat, index=df['Disease'].unique(), columns=df['Disease'].unique())\nprint('F1-score% =', f1_score(y_test, preds, average='macro')*100, '|', 'Accuracy% =', accuracy_score(y_test, preds)*100)\nsns.heatmap(df_cm)","f7c2f675":"kfold = KFold(n_splits=10,shuffle=True,random_state=42)\nSVM_hyperd_train =cross_val_score(SVM_hyperd, x_train, y_train, cv=kfold, scoring='accuracy')\npd.DataFrame(SVM_hyperd_train,columns=['Scores'])\nprint(\"Mean Accuracy: %.3f%%, Standard Deviation: (%.2f%%)\" % (SVM_hyperd_train.mean()*100.0, SVM_hyperd_train.std()*100.0))","38068126":"kfold = KFold(n_splits=10,shuffle=True,random_state=42)\nSVM_hyperd_test =cross_val_score(SVM_hyperd, x_test, y_test, cv=kfold, scoring='accuracy')\npd.DataFrame(SVM_hyperd_test,columns=['Scores'])\nprint(\"Mean Accuracy: %.3f%%, Standard Deviation: (%.2f%%)\" % (SVM_hyperd_test.mean()*100.0, SVM_hyperd_test.std()*100.0))","bca10053":"from sklearn.naive_bayes import GaussianNB\ngaussian = GaussianNB()\ngaussian.fit(x_train, y_train)\npreds=gaussian.predict(x_test)\nconf_mat = confusion_matrix(y_test, preds)\ndf_cm = pd.DataFrame(conf_mat, index=df['Disease'].unique(), columns=df['Disease'].unique())\nprint('F1-score% =', f1_score(y_test, preds, average='macro')*100, '|', 'Accuracy% =', accuracy_score(y_test, preds)*100)\nsns.heatmap(df_cm)","1446c738":"kfold = KFold(n_splits=10,shuffle=True,random_state=42)\ngaussian_train =cross_val_score(gaussian, x_train, y_train, cv=kfold, scoring='accuracy')\npd.DataFrame(gaussian_train,columns=['Scores'])\nprint(\"Mean Accuracy: %.3f%%, Standard Deviation: (%.2f%%)\" % (gaussian_train.mean()*100.0, gaussian_train.std()*100.0))","749a425d":"kfold = KFold(n_splits=10,shuffle=True,random_state=42)\ngaussian_test =cross_val_score(gaussian, x_test, y_test, cv=kfold, scoring='accuracy')\npd.DataFrame(gaussian_test,columns=['Scores'])\nprint(\"Mean Accuracy: %.3f%%, Standard Deviation: (%.2f%%)\" % (gaussian_test.mean()*100.0, gaussian_test.std()*100.0))","5f2849fe":"tree =DecisionTreeClassifier(criterion='gini',random_state=42,max_depth=13)\ntree.fit(x_train, y_train)\npreds=tree.predict(x_test)\nconf_mat = confusion_matrix(y_test, preds)\ndf_cm = pd.DataFrame(conf_mat, index=df['Disease'].unique(), columns=df['Disease'].unique())\nprint('F1-score% =', f1_score(y_test, preds, average='macro')*100, '|', 'Accuracy% =', accuracy_score(y_test, preds)*100)\nsns.heatmap(df_cm)","767b330b":"kfold = KFold(n_splits=10,shuffle=True,random_state=42)\nDS_train =cross_val_score(tree, x_train, y_train, cv=kfold, scoring='accuracy')\npd.DataFrame(DS_train,columns=['Scores'])\nprint(\"Mean Accuracy: %.3f%%, Standard Deviation: (%.2f%%)\" % (DS_train.mean()*100.0, DS_train.std()*100.0))","5df38b4c":"kfold = KFold(n_splits=10,shuffle=True,random_state=42)\nDS_test =cross_val_score(tree, x_test, y_test, cv=kfold, scoring='accuracy')\npd.DataFrame(DS_test,columns=['Scores'])\nprint(\"Mean Accuracy: %.3f%%, Standard Deviation: (%.2f%%)\" % (DS_test.mean()*100.0, DS_test.std()*100.0))","6a511c4f":"rfc=RandomForestClassifier(random_state=42)","a4c02120":"rnd_forest = RandomForestClassifier(random_state=42, max_features='sqrt', n_estimators= 500, max_depth=13)\nrnd_forest.fit(x_train,y_train)\npreds=rnd_forest.predict(x_test)\nconf_mat = confusion_matrix(y_test, preds)\ndf_cm = pd.DataFrame(conf_mat, index=df['Disease'].unique(), columns=df['Disease'].unique())\nprint('F1-score% =', f1_score(y_test, preds, average='macro')*100, '|', 'Accuracy% =', accuracy_score(y_test, preds)*100)\nsns.heatmap(df_cm)","75a80451":"kfold = KFold(n_splits=10,shuffle=True,random_state=42)\nrnd_forest_train =cross_val_score(rnd_forest, x_train, y_train, cv=kfold, scoring='accuracy')\npd.DataFrame(rnd_forest_train,columns=['Scores'])\nprint(\"Mean Accuracy: %.3f%%, Standard Deviation: (%.2f%%)\" % (rnd_forest_train.mean()*100.0, rnd_forest_train.std()*100.0))","889aac13":"kfold = KFold(n_splits=10,shuffle=True,random_state=42)\nrnd_forest_test =cross_val_score(rnd_forest, x_test, y_test, cv=kfold, scoring='accuracy')\npd.DataFrame(rnd_forest_test,columns=['Scores'])\nprint(\"Mean Accuracy: %.3f%%, Standard Deviation: (%.2f%%)\" % (rnd_forest_test.mean()*100.0, rnd_forest_test.std()*100.0))","7d6f64c6":"def predd(S1,S2,S3,S4,S5,S6,S7,S8,S9,S10,S11,S12,S13,S14,S15,S16,S17,x):\n    psymptoms = [S1,S2,S3,S4,S5,S6,S7,S8,S9,S10,S11,S12,S13,S14,S15,S16,S17]\n    print(psymptoms)\n    a = np.array(df1[\"Symptom\"])\n    b = np.array(df1[\"weight\"])\n    for j in range(len(psymptoms)):\n        for k in range(len(a)):\n            if psymptoms[j]==a[k]:\n                psymptoms[j]=b[k]\n\n    psy = [psymptoms]\n\n    pred2 = x.predict(psy)\n    print(\"The prediction is\",pred2[0])","f6a4e3ea":"sympList=df1[\"Symptom\"].to_list()\npredd(sympList[7],sympList[5],sympList[2],sympList[80],0,0,0,0,0,0,0,0,0,0,0,0,0,rnd_forest)","c22c83b3":"sympList=df1[\"Symptom\"].to_list()\npredd(sympList[8],sympList[1],sympList[2],sympList[80],0,0,0,0,0,0,0,0,0,0,0,0,0,SVM_hyperd)","4b542cbd":"sympList=df1[\"Symptom\"].to_list()\npredd(sympList[8],sympList[5],sympList[2],sympList[80],0,0,0,0,0,0,0,0,0,0,0,0,0,SVM_unhyperd)","576c27c0":"n_groups = 5\nalgorithms = ('Naive Bayes','Unhyperd SVM', 'Hyperd SVM','Decision Tree', 'Random Forest')\ntrain_accuracy = (gaussian_train.mean()*100.0, \n                 SVM_unhyperd_train.mean()*100.0,\n                 SVM_hyperd_train.mean()*100.0,\n                 DS_train.mean()*100.0,\n                 rnd_forest_train.mean()*100.0,\n                 )\n\n\ntest_accuracy = (gaussian_test.mean()*100.0, \n                 SVM_unhyperd_test.mean()*100.0,\n                 SVM_hyperd_test.mean()*100.0,\n                 DS_test.mean()*100.0,\n                 rnd_forest_test.mean()*100.0\n                )\n\nStandard_Deviation=(gaussian_test.std()*100.0, \n                 SVM_unhyperd_test.std()*100.0,\n                 SVM_hyperd_test.std()*100.0,\n                 DS_test.std()*100.0,     \n                 rnd_forest_test.std()*100.0\n                 \n                   )\n\n# create plot\nfig, ax = plt.subplots(figsize=(15, 10))\nindex = np.arange(n_groups)\nbar_width = 0.3\nopacity = 1\nrects1 = plt.bar(index, train_accuracy, bar_width, alpha = opacity, color='Cornflowerblue', label='Train')\nrects2 = plt.bar(index + bar_width, test_accuracy, bar_width, alpha = opacity, color='Teal', label='Test')\nrects3 = plt.bar(index + bar_width, Standard_Deviation, bar_width, alpha = opacity, color='red', label='Standard Deviation')\nplt.xlabel('Algorithm') # x axis label\nplt.ylabel('Accuracy (%)') # y axis label\nplt.ylim(0, 115)\nplt.title('Comparison of Algorithm Accuracies') # plot title\nplt.xticks(index + bar_width * 0.5, algorithms) # x axis data labels\nplt.legend(loc = 'upper right') # show legend\nfor index, data in enumerate(train_accuracy):\n    plt.text(x = index - 0.035, y = data + 1, s = round(data, 2), fontdict = dict(fontsize = 8))\nfor index, data in enumerate(test_accuracy):\n    plt.text(x = index + 0.25, y = data + 1, s = round(data, 2), fontdict = dict(fontsize = 8))\nfor index, data in enumerate(Standard_Deviation):\n    plt.text(x = index + 0.25, y = data + 1, s = round(data, 2), fontdict = dict(fontsize = 8))    ","6c75d42a":"\n**Initialize and train a Support vector classifier**","14d9e0cd":"# Hyperparameter tuning with GridSearchCV\n\nPerforming hyperparameter tuning in order to determine the optimal values for our given model.The performance of a model significantly depends on the value of hyperparameters. There is no way to know in advance the best values for hyperparameters so ideally, we need to try all possible values to know the optimal values. Doing this manually could take a considerable amount of time and resources and thus we used GridSearchCV to automate the tuning of hyperparameters.\n**Note:** The ouput of the Gridsearchcv is **SVC(C=0.02, gamma=0.3, kernel='poly')**","f59d1bf3":"**Encode symptoms in the data with the symptom rank**","9381187e":"# Naive Bayes Model","b1ef7b53":"### Select the features as symptoms column and label as Disease column\n\nExplination: A **feature** is an input; **label** is an output.\nA feature is one column of the data in your input set. For instance, if you're trying to predict the type of pet someone will choose, your input features might include age, home region, family income, etc. The label is the final choice, such as dog, fish, iguana, rock, etc.\n\nOnce you've trained your model, you will give it sets of new input containing those features; it will return the predicted \"label\" (pet type) for that person.","6b09341a":"**Get the names of diseases from data**","cad36a9a":"**Get overall list of symptoms**","38317854":"# Random Forest","a0033982":"# Decision Tree","9c8e7884":"# pandas report on dataset","67d17eab":"### Compare linear relationships between attributes using correlation coefficient","76d1a35b":"**Removing Hyphen from strings**","16dd63cc":"# Comparison between algorithms testing and training","568c102f":"## Using 10-Fold Cross Validation to estimate the performance of machine learning models\n\nThe procedure provides an estimate of the model performance on the dataset when making a prediction on data not used during training. It is less biased than some other techniques, such as a single train-test split for small- to modestly-sized dataset","4973db3e":"# Fucntion to manually test the models","bc75b0fc":"## Splitting the dataset to training (80%) and testing (20%)\n\nSeparating data into training and testing sets is an important part of evaluating data mining models. Typically, when you separate a data set into a training set and testing set, most of the data is used for training, and a smaller portion of the data is used for testing. By using similar data for training and testing, you can minimize the effects of data discrepancies and better understand the characteristics of the model.\nAfter a model has been processed by using the training set, we test the model by making predictions against the test set. Because the data in the testing set already contains known values for the attribute that you want to predict, it is easy to determine whether the model's guesses are correct.\n\n* Train Dataset: Used to fit the machine learning model.\n* Test Dataset: Used to evaluate the fit machine learning model.","f76d7600":"**Symptom severity rank**","5553caeb":"**Fill the NaN values with zero**","adcc7a34":"**Assign symptoms with no rank to zero**","38f1a90c":"**Remove the trailing space from the symptom columns**","700dd8cf":"**Plot the confusion matrix for 25 diseases**","de2e89e0":"**Check for null and NaN values**","8c9bdf23":"### Compute the F1 score, also known as balanced F-score or F-measure.\n\nThe F1 score can be interpreted as a weighted average of the precision and\nrecall, where an F1 score reaches its best value at 1 and worst score at 0.\nThe relative contribution of precision and recall to the F1 score are\nequal. The formula for the F1 score is\n\n    F1 = 2 * (precision * recall) \/ (precision + recall)","3e943ecb":"**Dataset characteristics**","ee6f84a4":"**Read and shuffle the dataset**","4d41ef8d":"**Check if entire columns have zero values so we can drop those values**"}}