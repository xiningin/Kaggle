{"cell_type":{"5c47244b":"code","f7d448fe":"code","0d2f97c1":"code","4a63b596":"code","e0000c28":"code","b5009bae":"code","42c26481":"code","78b5e8f2":"code","463c53a9":"markdown","35ceca40":"markdown","55941cd3":"markdown","62a0c58f":"markdown","8a77e6b3":"markdown"},"source":{"5c47244b":"package_paths = [\n    '..\/input\/pytorch-image-models\/pytorch-image-models-master', #'..\/input\/efficientnet-pytorch-07\/efficientnet_pytorch-0.7.0'\n    '..\/input\/image-fmix\/FMix-master'\n]\nimport sys; \n\nfor pth in package_paths:\n    sys.path.append(pth)\n    \nfrom fmix import sample_mask, make_low_freq_image, binarise_mask","f7d448fe":"from glob import glob\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold\nimport cv2\nfrom skimage import io\nimport torch\nfrom torch import nn\nimport os\nfrom datetime import datetime\nimport time\nimport random\nimport cv2\nimport torchvision\nfrom torchvision import transforms\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.nn.modules.loss import _WeightedLoss\nimport torch.nn.functional as F\n\nimport timm\n\nimport sklearn\nimport warnings\nimport joblib\nfrom sklearn.metrics import roc_auc_score, log_loss\nfrom sklearn import metrics\nimport warnings\nimport cv2\nimport pydicom\n#from efficientnet_pytorch import EfficientNet\nfrom scipy.ndimage.interpolation import zoom\nfrom torchvision.datasets import ImageFolder","0d2f97c1":"CFG = {\n    'fold_num': 5,\n    'seed': 719,\n    'model_arch': 'tf_efficientnet_b4_ns',\n    'img_size': 512,\n    'epochs': 10,\n    'train_bs': 16,\n    'valid_bs': 32,\n    'T_0': 10,\n    'lr': 1e-4,\n    'min_lr': 1e-6,\n    'weight_decay':1e-6,\n    'num_workers': 4,\n    'accum_iter': 2, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n    'verbose_step': 1,\n    'device': 'cuda:0'\n}","4a63b596":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \ndef get_img(path):\n    im_bgr = cv2.imread(path)\n    im_rgb = im_bgr[:, :, ::-1]\n    #print(im_rgb)\n    return im_rgb\n\nimg = get_img('..\/input\/cassava-leaf-disease-classification\/train_images\/1000015157.jpg')\nplt.imshow(img)\nplt.show()","e0000c28":"from albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n)\n\nfrom albumentations.pytorch import ToTensorV2\n\ndef get_valid_transforms():\n    return Compose([\n            CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n            Resize(CFG['img_size'], CFG['img_size']),\n            Normalize(mean=[0.430, 0.497, 0.314], std=[0.211, 0.217, 0.193], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.)","b5009bae":"class test_dataset(Dataset):\n    def __init__(self,transforms=None):\n        self.transforms = transforms\n        self.image_name = pd.read_csv('..\/input\/cassava-leaf-disease-classification\/sample_submission.csv')['image_id']\n    \n    \n    def __len__(self):\n        return len(self.image_name)\n    \n    \n    def __getitem__(self,index):\n        img_name = self.image_name[index]\n        img = get_img('..\/input\/cassava-leaf-disease-classification\/test_images\/{}'.format(img_name))\n        if self.transforms:\n            img = self.transforms(image=img)['image']\n        return index,img, img_name\n","42c26481":"class CassvaImgClassifier(nn.Module):\n    def __init__(self, model_arch, n_class, pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_arch, pretrained=pretrained)\n        n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(n_features, n_class)\n\n        '''self.model.classifier = nn.Sequential(\n            nn.Dropout(0.3),\n            #nn.Linear(n_features, hidden_size,bias=True), nn.ELU(),\n            nn.Linear(n_features, n_class, bias=True)\n            )'''\n        \n\n    def forward(self, x):\n        x = self.model(x)\n        return x","78b5e8f2":"if __name__ == '__main__':\n    # bulid test dataset and dataloader\n    test_transforms = get_valid_transforms()\n    test_ds = test_dataset(test_transforms)\n    test_dataloader = torch.utils.data.DataLoader(\n        test_ds, \n        batch_size=1,\n        num_workers=0,\n        shuffle=False,\n        pin_memory=False,\n    )\n    # bulid model and load model state\n    device = torch.device('cuda:0')\n    model = CassvaImgClassifier(model_arch=CFG['model_arch'],n_class=5).to(device)\n    model.load_state_dict(torch.load('..\/input\/pytorch-efficientnet-baseline-train-amp-aug\/tf_efficientnet_b4_ns_fold_4_4'))\n    submission = pd.DataFrame(columns=('image_id','label'))\n    for i, img ,img_name in test_dataloader:\n        model.eval()\n        img = img.to(device)\n        index = i.item()\n        label = torch.argmax(model(img)).item()\n        submission = submission.append([{'image_id':img_name[0],'label':label}],ignore_index=True)\n    submission.to_csv('submission.csv',index=False)","463c53a9":"# # Define Train\\Validation Image Augmentations","35ceca40":"> We could do stratified validation split in each fold to make each fold's train and validation set looks like the whole train set in target distributions.","55941cd3":"# Helper Functions","62a0c58f":"# Model","8a77e6b3":"# test dataset\n"}}