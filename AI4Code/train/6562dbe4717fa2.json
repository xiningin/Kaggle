{"cell_type":{"fb9258eb":"code","450f9bca":"code","7a2f1607":"code","fe9abad9":"code","9b1e5efa":"code","5ad87756":"code","1124a714":"code","e1dd6f71":"code","7eb72930":"code","e078495d":"code","48bf015c":"code","3d2ca498":"code","3e5ce581":"code","577592d7":"code","341b045b":"code","9529b675":"code","5200e920":"code","3b402fea":"code","68058390":"code","d9bc4af5":"code","829725ee":"markdown","cc275ad0":"markdown","7d77fd5b":"markdown","525c6060":"markdown","f125a50d":"markdown","9d999e57":"markdown","33f57921":"markdown","a9a7444e":"markdown","bf926c6d":"markdown","bedada86":"markdown","45750a94":"markdown"},"source":{"fb9258eb":"import glob\nimport numpy as np \nimport pandas as pd \n\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam, Adamax\n\n\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'","450f9bca":"#getting train and validation images path \nimage_paths=glob.glob('..\/input\/asian-vs-african-elephant-image-classification\/dataset\/train\/**\/*.jpg', recursive=True)\n#obtaining labels from the path\nimage_labels=pd.Series([x.split(\"\/\")[-2] for x in image_paths])\n\n#getting  test images path \nimage_paths_test=glob.glob('..\/input\/asian-vs-african-elephant-image-classification\/dataset\/test\/**\/*.jpg', recursive=True)\n#obtaining labels from the path\nimage_labels_test=pd.Series([x.split(\"\/\")[-2] for x in image_paths_test])","7a2f1607":"#creating dataframe from paths and labels\ndf=pd.DataFrame({\"Paths\":image_paths,\"Labels\":image_labels})\ndf_test=pd.DataFrame({\"Paths\":image_paths_test,\"Labels\":image_labels_test})","fe9abad9":"df.head()","9b1e5efa":"df.Labels.value_counts()","5ad87756":"print(\"Number of training and validation images:\",df.shape[0])\nprint(\"Number of testing images:\",df_test.shape[0])","1124a714":"df = df.sample(frac=1,random_state=4567).reset_index(drop = True)","e1dd6f71":"fig, axes = plt.subplots(2, 3, figsize=(12, 7), subplot_kw={'xticks': [], 'yticks': []})\nfor idx, ax in enumerate(axes.flat):    \n    ax.imshow(plt.imread(df[\"Paths\"].iloc[idx]))\n    ax.set_title(df[\"Labels\"].iloc[idx])\nplt.show()","7eb72930":"#It is useful to augment the data in order to avoid overfitting. It is also useful considering that there aren't a lot of images in both train and validation set.\ntrain_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.xception.preprocess_input, width_shift_range=0.1, \n                                   height_shift_range=0.1,zoom_range=0.2,brightness_range=[0.2,1.0],validation_split=0.1)\ntest_datagen=ImageDataGenerator(preprocessing_function=tf.keras.applications.xception.preprocess_input)","e078495d":"BATCH_SIZE=64\ntrain_images=train_datagen.flow_from_dataframe(dataframe=df,x_col='Paths',y_col='Labels',color_mode='rgb',class_mode='categorical',\n                                                target_size=(224, 224),batch_size=BATCH_SIZE,shuffle=True,seed=1234,subset='training')\n\nval_images=train_datagen.flow_from_dataframe(dataframe=df,x_col='Paths',y_col='Labels',color_mode='rgb',class_mode='categorical',\n                                                target_size=(224, 224),batch_size=BATCH_SIZE,shuffle=True,seed=1234,subset='validation')\n\ntest_images = test_datagen.flow_from_dataframe(dataframe=df_test,x_col='Paths',y_col='Labels',color_mode='rgb',class_mode='categorical',\n                                                target_size=(224, 224),batch_size=BATCH_SIZE,shuffle=False)","48bf015c":"inputs = tf.keras.layers.Input((224,224,3))\nbase_model=tf.keras.applications.xception.Xception(include_top=False, weights=\"imagenet\",input_shape=(224, 224,3), pooling='max') \nbase_model.trainable = False\nx=base_model(inputs)\nx = layers.Dense(256,activation='relu')(x) \nx=layers.Dropout(rate=.5)(x)  \noutput=layers.Dense(2, activation='softmax')(x)\nmodel=tf.keras.models.Model(inputs=inputs, outputs=output)","3d2ca498":"lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-3,decay_steps=10000,decay_rate=1e-6)\nmodel.compile(Adamax(learning_rate=lr_schedule), loss='categorical_crossentropy',metrics=['accuracy'])\nhistory = model.fit(train_images, validation_data=val_images, epochs=50)","3e5ce581":"plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title('Accuracy Plot')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"accuracy\")\nplt.legend()\nplt.show()","577592d7":"plt.plot(history.history[\"loss\"], label=\"train_loss\")\nplt.plot(history.history[\"val_loss\"], label=\"val_loss\")\nplt.title('Loss Plot')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss\")\nplt.legend()\nplt.show()","341b045b":"#predicts the test images and converts to labels \npred=model.predict(test_images)\npred = np.argmax(pred,axis=1)\npred=pred>0.5\ngt=[0 if x==\"African\" else 1 for x in df_test[\"Labels\"]]","9529b675":"from sklearn.metrics import classification_report, confusion_matrix\nprint(classification_report(gt,pred))","5200e920":"conf_matrix = confusion_matrix(gt, pred)\nsns.heatmap(conf_matrix,xticklabels = [\"African\",\"Asian\"], yticklabels = [\"African\",\"Asian\"],annot=True)\nplt.title('Confusion Matrix')\nplt.show()","3b402fea":"probs=pd.DataFrame({\"Probs\":model.predict(test_images)[:,0]})\n# dataframe that contain bad predictions\nbad_preds=df_test[gt!=pred].sample(frac=1,random_state=1234).reset_index(drop = True)\n# dataframe that contain good predictions\ngood_preds=df_test[gt==pred].sample(frac=1,random_state=1234).reset_index(drop = True)","68058390":"fig, axes = plt.subplots(5, 4, figsize=(25, 10), subplot_kw={'xticks': [], 'yticks': []})\nfor idx, ax in enumerate(axes.flat):    \n    ax.imshow(plt.imread(good_preds[\"Paths\"].iloc[idx]))\n    ax.set_title(good_preds[\"Labels\"].iloc[idx])\nplt.show()","d9bc4af5":"fig, axes = plt.subplots(5, 4, figsize=(25, 10), subplot_kw={'xticks': [], 'yticks': []})\nfor idx, ax in enumerate(axes.flat):    \n    ax.imshow(plt.imread(bad_preds[\"Paths\"].iloc[idx]))\n    ax.set_title(bad_preds[\"Labels\"].iloc[idx])\nplt.show()","829725ee":"# End of the notebook\nFrom the obtained results (both error\/accuracies plots and classification report) it's clear that the model converged to a good solution, hence proving that the choice to use a Transfer Learning approach was right!\n\n***Thank you for reading this notebook and please upvote if you appreciated the work!***","cc275ad0":"# Model definition","7d77fd5b":"Examples of images from the train set.","525c6060":"From the classification report and from the confusion matrix, it can be noticed that the neural net struggles to classify correctly a lot of asian elephants.","f125a50d":"And now we will plot some of the bad predictions.","9d999e57":"# Model evaluation","33f57921":"# Dataset details\n<ul>\n    <li>Number of classes: 2 (Asian elephant and African elephant )<\/li>\n    <li>Number of images: 1028<\/li>\n    <li>Image shape range: ( 100, 100) to (4992, 3328)<\/li>\n    <li>To increase complexity the train set contains less than 5% mislabeled images, while all images in the test set have the correct label.<\\li>\n<\/ul>","a9a7444e":"# Summary\nThe goal of this notebook is to apply an neural network approach in order to perform a binary image classification on the dataset \"Asian vs African Elephants\".\nThe chosen approach consists in the use of a pre-trained model through Transfer Learning: the neural network used in this work is Xception from the tensorflow library.\n\nFrom the obtained results, we can consider right the choices made.\n","bf926c6d":"# Generators definition","bedada86":"Let's plot some of the good predictions.","45750a94":"The class are balanced!"}}