{"cell_type":{"08589044":"code","5fa37660":"code","29da17d1":"code","b3d4a570":"code","a5ed603e":"code","0b640130":"code","71450c78":"code","214433b4":"code","c919c7cc":"code","0fccf82e":"code","284b2b5d":"code","5a1a3952":"code","171c5f3c":"code","5e7cd28a":"code","ecaf7cdf":"code","5c76d0e7":"code","378f4a36":"code","d2154c43":"markdown"},"source":{"08589044":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5fa37660":"train=pd.read_csv('..\/input\/titanic\/train.csv')","29da17d1":"train.describe","b3d4a570":"train.corr()","a5ed603e":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.countplot(x = 'SibSp', hue = \"Survived\", data = train)\nplt.legend(loc = \"upper right\", title = \"Survived ~ Sibsp\")","0b640130":"sns.distplot(train[train['Survived'] == 0].Fare, kde=False,rug=False)\nsns.distplot(train[train['Survived'] == 1].Fare,  kde=False,rug=False)","71450c78":"train.isnull().sum()","214433b4":"train.drop(['PassengerId','Name','Cabin','Ticket', ], axis=1, inplace=True)\ntrain[\"Age\"].fillna(train[\"Age\"].median(skipna=True), inplace=True)\ntrain[\"Embarked\"].fillna(train['Embarked'].value_counts().idxmax(), inplace=True)","c919c7cc":"train['Alone']=np.where((train[\"SibSp\"]+train[\"Parch\"])>0, 0, 1)\ntrain.drop(['SibSp', 'Parch'], axis=1, inplace=True)","0fccf82e":"pd.get_dummies(train['Sex'])","284b2b5d":"training = pd.get_dummies(train, columns=[\"Pclass\",\"Embarked\",\"Sex\"], drop_first=True)\ntraining","5a1a3952":"from sklearn.preprocessing import StandardScaler\ntrain_standard = StandardScaler()\ntrain_copied = training.copy()\ntrain_standard.fit(train_copied[['Age','Fare']])\ntrain_std = pd.DataFrame(train_standard.transform(train_copied[['Age','Fare']]))\ntrain_std","171c5f3c":"training[['Age','Fare'] ] = train_std\ntraining","5e7cd28a":"from sklearn.linear_model import LogisticRegression\ncols = [\"Age\",\"Fare\",\"Alone\",\"Pclass_2\",\"Pclass_2\",\"Embarked_Q\",\"Embarked_S\",\"Sex_male\"] \nX = training[cols]\ny = training['Survived']\n# Build a logreg and compute the feature importances\nmodel = LogisticRegression()\n# create the RFE model and select 8 attributes\nmodel.fit(X,y)\nfrom sklearn.metrics import accuracy_score\ntrain_predicted = model.predict(X)\naccuracy_score(train_predicted, y)","ecaf7cdf":"test = pd.read_csv('..\/input\/titanic\/test.csv')\ntest.isnull().sum()","5c76d0e7":"test.drop(['PassengerId','Name','Cabin','Ticket'], axis=1, inplace=True)\ntest[\"Age\"].fillna(28, inplace=True)\ntest[\"Embarked\"].fillna(test['Embarked'].value_counts().idxmax(), inplace=True)\ntest[\"Fare\"].fillna(train.Fare.median(), inplace=True)\ntest['Alone']=np.where((test[\"SibSp\"]+test[\"Parch\"])>0, 0, 1)\ntest.drop(['SibSp', 'Parch'], axis=1, inplace=True)\ntesting=pd.get_dummies(test, columns=[\"Pclass\",\"Embarked\",\"Sex\"], drop_first=True)\nprint(testing.dtypes)\ntest_copied = testing.copy()\ntest_std = train_standard.transform(test_copied[['Age','Fare']])\ntest_std\ntesting[['Age','Fare']] = test_std\ntesting\ncols = [\"Age\",\"Fare\",\"Alone\",\"Pclass_2\",\"Pclass_2\",\"Embarked_Q\",\"Embarked_S\",\"Sex_male\"] \nX_test=testing[cols]\nprint(X_test.dtypes)\ntest_predicted = model.predict(X_test)","378f4a36":"sub = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nsub['Survived'] = list(map(int, test_predicted))\nsub.to_csv('submission.csv', index=False)","d2154c43":"#\u7279\u5fb4\u91cf\u306e\u78ba\u8a8d"}}