{"cell_type":{"f93a9e6f":"code","462c287a":"code","7ad50135":"code","3bf518ee":"code","368bfe0a":"code","13b37d34":"code","c2b59d3d":"code","3a7d6c37":"code","04c39683":"code","7b39515c":"code","297e6e1b":"code","0e6d3f78":"code","3be00093":"code","f40a628a":"code","0da7d3e3":"code","88d01d15":"code","5c78b4c2":"code","c4ad0d49":"markdown","cfac39b3":"markdown","22e7328d":"markdown","e49c9724":"markdown"},"source":{"f93a9e6f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","462c287a":"import matplotlib.pyplot as plt\nimport seaborn as sns","7ad50135":"train=pd.read_csv('\/kaggle\/input\/dont-overfit-ii\/train.csv')\ntrain.head()","3bf518ee":"test=pd.read_csv('\/kaggle\/input\/dont-overfit-ii\/test.csv')\ntest.head()","368bfe0a":"sample=pd.read_csv('\/kaggle\/input\/dont-overfit-ii\/sample_submission.csv')\nsample.head()","13b37d34":"train.isnull().any().any()","c2b59d3d":"test.isnull().any().any()","3a7d6c37":"print('Distributions of first 28 columns')\nplt.figure(figsize=(26, 24))\nfor i, col in enumerate(list(train.columns)[2:30]):\n    plt.subplot(7, 4, i + 1)\n    plt.hist(train[col])\n    plt.title(col)\n","04c39683":"corrs = train.corr().abs().unstack().sort_values(kind=\"quicksort\").reset_index()\ncorrs = corrs[corrs['level_0'] != corrs['level_1']]\ncorrs.tail(30)","7b39515c":"X=train.drop(columns=['id','target'])\ny=train['target']\nx_test=test.drop(columns=['id'])","297e6e1b":"from sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression","0e6d3f78":"X_train, x_val, y_train, y_val = train_test_split(X, y, test_size = 0.25, random_state = 42)","3be00093":"logreg = LogisticRegression(solver='liblinear')\nlogreg.fit(X_train, y_train)\nacc_log = round(logreg.score(x_val,  y_val) * 100, 2)\nprint('Validation Accuracy =', acc_log)","f40a628a":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\n\nknn = KNeighborsClassifier(n_neighbors=30)\nknn.fit(X_train,y_train)\nscore = cross_val_score(knn, X_train, y_train, cv=20, scoring='roc_auc')\nprint('training score = ',score.max())","0da7d3e3":"from sklearn.svm import SVC\nsvm = SVC(C=100, kernel='linear', max_iter=100, gamma='auto', probability=True, random_state=0)\nsvm.fit(X_train, y_train)","88d01d15":"svm_pred = svm.predict_proba(x_test)[:, 1]\ndf_test = pd.read_csv('\/kaggle\/input\/dont-overfit-ii\/test.csv')\nsubmission= pd.DataFrame({'id':np.asarray(df_test.id), 'target':svm_pred})\nsubmission.to_csv(\"submission.csv\", index=False)","5c78b4c2":"submission","c4ad0d49":"**there is no highly correlated feature as the maximum correlated feature has correlation = 0.338**","cfac39b3":"**try svm**","22e7328d":"**try logistic regression model**","e49c9724":"**try knn model**"}}