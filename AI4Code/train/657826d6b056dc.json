{"cell_type":{"40fb3408":"code","3c7014e3":"markdown"},"source":{"40fb3408":"%%time\n\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport gc\n\ngc.enable()\n\n\n\nu = tf.constant(3*(np.random.random(9_000)-0.5), dtype = tf.float32)\nx = tf.constant(np.random.normal(size=9_000, scale=0.5), dtype = tf.float32)\nx_min = min(x)\nx_max = max(x)\n\nactivations = [tf.keras.activations.softplus, \n               tf.keras.activations.relu,\n               tf.keras.activations.sigmoid,\n               tf.keras.activations.selu,\n               # tf.keras.activations.gelu,\n               tf.keras.activations.tanh,\n               tf.keras.activations.exponential,\n               tf.keras.activations.elu,\n               tf.keras.activations.hard_sigmoid,\n               tf.keras.activations.softsign,\n               tf.keras.activations.swish,\n              ]\n\n\nfor a in activations:\n    y = a(x).numpy()\n    \n    fig, axs = plt.subplots(1,3, figsize=(16,3))\n    fig.suptitle(f\">>> >>>      {a.__name__}      >>> >>>\")\n    axs[0].set_title(f\"range: {x_min:.2f} - {x_max:.2f}      >>> >>>\")\n    sns.distplot(x,ax=axs[0])\n    axs[1].plot(x,y,\".\")\n    axs[1].axhline()\n    axs[1].axvline()\n    axs[2].set_title(f\">>> >>>      range: {min(y):.2f} - {max(y):.2f}\")\n    sns.distplot(y,ax=axs[2])\n    plt.tight_layout()\n    plt.show()\n    \n    y = a(u).numpy()\n    fig, axs = plt.subplots(1,3, figsize=(16,3))\n    fig.suptitle(f\">>> >>>      {a.__name__}      >>> >>>\")\n    axs[0].set_title(f\"range: {u.numpy().min():.2f} - {u.numpy().max():.2f}      >>> >>>\")\n    sns.distplot(u,ax=axs[0])\n    axs[1].plot(u,y,\".\")\n    axs[1].axhline()\n    axs[1].axvline()\n    axs[2].set_title(f\">>> >>>      range: {min(y):.2f} - {max(y):.2f}\")\n    sns.distplot(y,ax=axs[2])\n    plt.tight_layout()\n    plt.show()","3c7014e3":"# Activation Functions"}}