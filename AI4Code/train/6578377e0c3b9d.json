{"cell_type":{"e5fee665":"code","220fedcb":"code","d8467330":"code","f18f5e2c":"code","f5adccc4":"code","7b551c71":"code","8e96da45":"code","0210523e":"code","eeaf6174":"code","4bfca388":"code","4e078cbe":"code","ae27a57a":"code","a095a651":"code","15f41910":"code","6f85fe1b":"code","f666cc73":"code","87a0d59d":"code","a45c6881":"code","d9fdd3ab":"code","3ab6de19":"code","5160cf3c":"code","4bfe10f1":"markdown","14ee93a6":"markdown","0158beff":"markdown","a0c78ca6":"markdown","60bfa09a":"markdown","5bd33532":"markdown","efd93b2e":"markdown","f924d14c":"markdown","222dc54e":"markdown","b616b9b9":"markdown"},"source":{"e5fee665":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","220fedcb":"dataset = pd.read_csv('\/kaggle\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')","d8467330":"dataset.head()","f18f5e2c":"dataset.isnull().any()","f5adccc4":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfor feature in dataset.columns:\n    if feature == 'quality':\n        break\n    sns.boxplot('quality',feature, data = dataset)\n    plt.figure()\n    \n        \n    ","7b551c71":"corr = dataset.corr()\n\nfig, ax = plt.subplots(figsize=(10, 8))\n\nsns.heatmap(corr, cmap='coolwarm', annot=True, fmt=\".2f\")\n\n\n\n\nplt.show()","8e96da45":"dataset.drop(['pH','chlorides','free sulfur dioxide', 'residual sugar'], axis = 1, inplace = True)","0210523e":"dataset","eeaf6174":"sns.countplot(x = 'quality', data = dataset)","4bfca388":"bins = (2, 6.5, 8)\nlabels = ['bad', 'good']\ndataset['quality'] = pd.cut(x = dataset['quality'], bins = bins, labels = labels)","4e078cbe":"sns.countplot(x = 'quality', data = dataset)","ae27a57a":"from sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()\ndataset['quality'] = labelencoder.fit_transform(dataset['quality'])","a095a651":"X = dataset.drop('quality', axis = 1)\ny = dataset['quality']","15f41910":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 30)","6f85fe1b":"print(\"Shape of X_train: \",X_train.shape)\nprint(\"Shape of X_test: \", X_test.shape)\nprint(\"Shape of y_train: \",y_train.shape)\nprint(\"Shape of y_test\",y_test.shape)","f666cc73":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n","87a0d59d":"from sklearn.svm import SVC\nclassifier = SVC()\nfrom sklearn.model_selection import GridSearchCV\nparameters = [{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n              {'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\ngrid_search = GridSearchCV(estimator = classifier,\n                           param_grid = parameters,\n                           scoring = 'accuracy',\n                           cv = 10,\n                           n_jobs = -1)\ngrid_search = grid_search.fit(X_train, y_train)","a45c6881":"accuracy = grid_search.best_score_\naccuracy","d9fdd3ab":"grid_search.best_params_","3ab6de19":"classifier = SVC(kernel = 'rbf', gamma=0.7)\nclassifier.fit(X_train, y_train)","5160cf3c":"y_pred = classifier.predict(X_test)\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nfrom sklearn.metrics import accuracy_score\naccuracy=accuracy_score(y_test,y_pred)\naccuracy\n","4bfe10f1":"pH,free sulphur dioxide,chlorides and residual sugar are not of much use as they have very less impact on target quality.","14ee93a6":"# **LOAD THE DATASET**\n","0158beff":"Since few features have a lot of outliers a correlation matrix will give better insights on which features to remove and which ones to keep.","a0c78ca6":"Here quality is the target variable.","60bfa09a":"# EDA AND PREPROCESSING\n","5bd33532":"# IMPLEMENTING THE MODEL USING GridSearchCV","efd93b2e":"Lets have a check for null values:","f924d14c":"Train - Test Split","222dc54e":"Lets analyse the distribution of target variable.","b616b9b9":"We need to label encode this binary data."}}