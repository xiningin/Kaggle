{"cell_type":{"41c6432b":"code","bbaf18f4":"code","417f8b91":"code","e097d107":"code","4c388f58":"code","4fbf1340":"code","965b63fc":"code","940f78fe":"code","2d1f70e5":"code","f1d2d182":"code","75662c5a":"code","f49c1492":"code","cef66604":"code","8e21a69b":"code","01ad9f6d":"code","65cb188c":"code","8024a274":"code","7d647c1f":"code","26499ad8":"code","70ff1726":"code","eac0caa4":"code","2dedb7a9":"code","00ed34e2":"code","39a22506":"code","e59de364":"code","d63baaaf":"code","34aa6f21":"code","5ca98c29":"code","93614cfd":"code","0080d8c4":"code","f1cb978c":"code","8c664033":"code","8b21fe2b":"code","7bee97e9":"code","1913f543":"code","0c2e7a06":"code","9f9fdfc8":"code","15e11709":"code","208a3eaf":"code","a19c1cf5":"code","aecdc6b0":"code","1aacd6d9":"code","0211a4fc":"code","1065d4b3":"code","12e4c199":"code","09a5b042":"code","d2909249":"code","d2aa614f":"code","c454a8da":"code","182427fa":"markdown","2beb9d64":"markdown","8392cdb0":"markdown","e0b5571d":"markdown","36d827ef":"markdown","07656193":"markdown","b811dab1":"markdown","79becd58":"markdown","798b6e47":"markdown","ef7c13d2":"markdown","78e04a44":"markdown","2527947b":"markdown","e185608c":"markdown"},"source":{"41c6432b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bbaf18f4":"train= pd.read_csv('\/kaggle\/input\/analytics-vidhya-job-a-thon-may-2021\/train_s3TEQDk.csv')\ntrain.head()","417f8b91":"test= pd.read_csv('\/kaggle\/input\/analytics-vidhya-job-a-thon-may-2021\/test_mSzZ8RL.csv')\ntest.head()","e097d107":"print(train.shape)\nprint(test.shape)","4c388f58":"train.isna().sum()","4fbf1340":"test.isna().sum()","965b63fc":"#percentage of null values\n(train['Credit_Product'].isna().sum()\/train['Credit_Product'].count())","940f78fe":"(test['Credit_Product'].isna().sum()\/test['Credit_Product'].count())","2d1f70e5":"train.drop('ID', axis=1, inplace=True)\ntest.drop('ID', axis=1, inplace=True)","f1d2d182":"train.info()","75662c5a":"cat_cols= [col for col in train.columns if train[col].dtype=='object']\nnum_cols= [col for col in train.columns if train[col].dtype!='object']\nnum_cols.remove('Is_Lead')\nprint(cat_cols)\nprint(num_cols)","f49c1492":"plt.figure(figsize=(15,12))\ni=1\nfor col in cat_cols:\n    plt.subplot(3,2,i)\n    sns.countplot(train[col])\n    i+=1","cef66604":"plt.figure(figsize=(15,12))\ni=1\nfor col in num_cols:\n    plt.subplot(2,2,i)\n    sns.distplot(train[col])\n    i+=1","8e21a69b":"sns.pairplot(train, hue='Is_Lead')","01ad9f6d":"plt.figure(figsize=(10,8))\nsns.heatmap(train.corr(), annot=True)","65cb188c":"train['Credit_Product'].fillna('Yes', inplace=True)\ntest['Credit_Product'].fillna('Yes', inplace=True)\ntrain.info()","8024a274":"test.info()","7d647c1f":"trans= [col for col in cat_cols if col!='Region_Code']\ntrans","26499ad8":"train_dum= pd.get_dummies(train[trans], drop_first=True)\ntrain_dum.head()\n","70ff1726":"test_dum= pd.get_dummies(test[trans], drop_first=True)\ntest_dum.head()","eac0caa4":"train.drop(trans, axis=1,inplace=True)\ntrain.head()","2dedb7a9":"train= pd.concat([train, train_dum], axis=1)\ntrain.head()","00ed34e2":"test.drop(trans, axis=1, inplace=True)\ntest= pd.concat([test, test_dum], axis=1)\ntest.head()","39a22506":"from sklearn.preprocessing import LabelEncoder\n\nenc= LabelEncoder()\ntrain['Region_Code']= enc.fit_transform(train['Region_Code'])\ntest['Region_Code']= enc.transform(test['Region_Code'])\ntrain.head()","e59de364":"test.head()","d63baaaf":"train['Avg_Account_Balance']= np.log(train['Avg_Account_Balance'])\ntrain['Vintage']= np.log(train['Vintage'])\ntest['Avg_Account_Balance']= np.log(test['Avg_Account_Balance'])\ntest['Vintage']= np.log(test['Vintage'])","34aa6f21":"from sklearn.preprocessing import StandardScaler\nss= StandardScaler()\n\ntrain[['Vintage', 'Avg_Account_Balance', 'Age', 'Region_Code']]= ss.fit_transform(train[['Vintage', 'Avg_Account_Balance', 'Age', 'Region_Code']])\ntest[['Vintage', 'Avg_Account_Balance','Age', 'Region_Code']]= ss.transform(test[['Vintage', 'Avg_Account_Balance', 'Age', 'Region_Code']])\ntrain.head()","5ca98c29":"test.head()","93614cfd":"sns.distplot(train['Avg_Account_Balance'])","0080d8c4":"sns.distplot(test['Avg_Account_Balance'])","f1cb978c":"sns.distplot(train['Vintage'])","8c664033":"sns.distplot(test['Vintage'])","8b21fe2b":"from sklearn.model_selection import train_test_split\n\nX= train.drop('Is_Lead', axis=1)\ny= train['Is_Lead']\n\nX_train, X_test, y_train, y_test= train_test_split(X,y,test_size=0.2, stratify=y)","7bee97e9":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_auc_score, classification_report","1913f543":"lr = LogisticRegression()\n\nlr.fit(X_train, y_train)\ny_pred= lr.predict(X_test)\n\nprint(roc_auc_score(y_train, lr.predict(X_train)))\nprint(roc_auc_score(y_test, y_pred))","0c2e7a06":"rfc= RandomForestClassifier()\n\nrfc.fit(X_train, y_train)\ny_pred= rfc.predict(X_test)\n\nprint(roc_auc_score(y_train, rfc.predict(X_train)))\nprint(roc_auc_score(y_test, y_pred))","9f9fdfc8":"from sklearn.model_selection import RandomizedSearchCV\n\nparams= {'C':[0.001, 0.01, 0.1, 1],\n        'max_iter':[100,200,500]}\n\nrandom_lr= RandomizedSearchCV(lr, param_distributions= params, cv=5, scoring='roc_auc', random_state=42)\n","15e11709":"random_lr.fit(X_train,y_train)","208a3eaf":"best_lr= random_lr.best_estimator_\n\nbest_lr.fit(X_train, y_train)\ny_pred= best_lr.predict(X_test)\n\nprint(roc_auc_score(y_train, best_lr.predict(X_train)))\nprint(roc_auc_score(y_test, y_pred))","a19c1cf5":"# params= {'n_estimators':[50,100,200,500],\n#         'max_depth':[10, 100, 500],\n#         'min_weight_fraction_leaf':[0, 0.1, 0.01, 0.2]}\n\n# random_rfc= RandomizedSearchCV(rfc, param_distributions= params, cv=5, random_state=42, scoring='roc_auc')","aecdc6b0":"# random_rfc.fit(X_train,y_train)","1aacd6d9":"# random_rfc.best_estimator_\n#RandomForestClassifier(max_depth=100, min_weight_fraction_leaf=0.01,\n#                        n_estimators=500)","0211a4fc":"best_rfc= RandomForestClassifier(max_depth=100, min_weight_fraction_leaf=0.01,n_estimators=500)\n\nbest_rfc.fit(X_train, y_train)\ny_pred= best_rfc.predict(X_test)\n\nprint(roc_auc_score(y_train, best_rfc.predict(X_train)))\nprint(roc_auc_score(y_test, y_pred))","1065d4b3":"from sklearn.metrics import plot_roc_curve\n\nplot_roc_curve(best_rfc, X_train, y_train)\nplot_roc_curve(best_rfc, X_test, y_test)","12e4c199":"predictions= best_rfc.predict(test)","09a5b042":"predictions","d2909249":"test_data= pd.read_csv('\/kaggle\/input\/analytics-vidhya-job-a-thon-may-2021\/test_mSzZ8RL.csv')\n\nsub= pd.DataFrame(test_data['ID'])\nsub.head()","d2aa614f":"sub['Is_Lead']= predictions\nsub.tail()","c454a8da":"sub.to_csv('submission.csv', index=False)","182427fa":"**For the sake of computational simplicity, I use Logistic Regression and RandomForest only. SVM and other classifiers took a lot of time to train, so I decided to go with this here**","2beb9d64":"# Final Predictions on Test Set","8392cdb0":"# Null Values","e0b5571d":"# Feature Engineeing","36d827ef":"# Load Data","07656193":"# Exploratory Data Analysis","b811dab1":"# Upvote if you liked my Notebook :)","79becd58":"# Hyperparamter Tuning","798b6e47":"**Divinding columns into categorical and numerical for easier EDA**","ef7c13d2":"**We use log transformation because the data is skewed**","78e04a44":"**Insights:**\n**The data is skewed**\n","2527947b":"# ROC Curve","e185608c":"# Model Building"}}