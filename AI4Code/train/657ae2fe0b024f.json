{"cell_type":{"a4aa2ddb":"code","cd657d5f":"code","31cc9d28":"code","c06e72f3":"code","f4b1ce26":"code","14a91a26":"code","115b88ac":"code","db9e048c":"code","571ceb41":"code","9e2250de":"code","ec98ac54":"code","c6df48be":"code","ad7df5dc":"markdown"},"source":{"a4aa2ddb":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = (6,6)\n\n# from keras import backend as K\n# from keras.engine.topology import Layer\n# from keras import initializers, regularizers, constraints\n\n# from keras.layers import Dense, Input, LSTM, Bidirectional, Activation, Conv1D, GRU, TimeDistributed\n# from keras.layers import Dropout, Embedding, GlobalMaxPooling1D, MaxPooling1D, Add, Flatten, SpatialDropout1D\n# from keras.layers import GlobalAveragePooling1D, BatchNormalization, concatenate\n# from keras.layers import Reshape, merge, Concatenate, Lambda, Average\n# from keras.models import Sequential, Model, load_model\n# from keras.callbacks import ModelCheckpoint\n# from keras.initializers import Constant\n# from keras.layers.merge import add\n\nfrom keras.preprocessing import sequence\nfrom keras.preprocessing.text import Tokenizer, text_to_word_sequence\nfrom keras.utils import np_utils\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nimport os\nprint(os.listdir(\"..\/input\"))\n","cd657d5f":"# load data\n\n# df = pd.read_json('..\/input\/News_Category_Dataset_v2.json')\ndf = pd.read_json('..\/input\/News_Category_Dataset_v2.json', lines=True)\nprint(df.shape)\ndf.head()","31cc9d28":"cates = df.groupby('category')\nprint(\"total categories:\", cates.ngroups)\nprint(cates.size())","c06e72f3":"# as shown above, THE WORLDPOST and WORLDPOST should be the same category, so merge them.\n\ndf.category = df.category.map(lambda x: \"WORLDPOST\" if x == \"THE WORLDPOST\" else x)","f4b1ce26":"# using headlines and short_description as input X\n\ndf['text'] = df.headline + \" \" + df.short_description\n\n# tokenizing\n\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(df.text)\nX = tokenizer.texts_to_sequences(df.text)\ndf['words'] = X\n\n# delete some empty and short data\n\ndf['word_length'] = df.words.apply(lambda i: len(i))\ndf = df[df.word_length >= 6]\n\ndf.head()","14a91a26":"print(df.shape)","115b88ac":"df.word_length.describe()","db9e048c":" df['category'].value_counts()","571ceb41":"df = df.drop_duplicates(subset=\"text\")\nprint(df.shape)","9e2250de":"df.columns","ec98ac54":"df.head()","c6df48be":"df.drop([\"words\"],axis=1).to_csv(\"Huffpost_News_Category.csv.gz\",index=False,compression=\"gzip\")","ad7df5dc":"# prepare data"}}