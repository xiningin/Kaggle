{"cell_type":{"569a5ed2":"code","e22e8876":"code","1fe90e64":"code","cbc32d3f":"code","8e0b78be":"code","b4ff1b80":"code","77600176":"code","82f5f9de":"code","c883db23":"code","22111e23":"code","7c75129f":"code","a8afa397":"code","510bcf3e":"code","c05e65f3":"code","710e9461":"code","a5c35406":"code","e5274d87":"code","858ad0ac":"code","efca5f2a":"code","e3036f84":"code","4d80b1d7":"code","0635e4bf":"code","3d60aec8":"code","efa17761":"code","4062ee1e":"code","76eb28c8":"code","b5f049b5":"code","95b35c38":"markdown","c7565dc7":"markdown","543c5cf5":"markdown","b8a2fb5c":"markdown","a49991a9":"markdown","2f6ff24d":"markdown","aa60a2d0":"markdown"},"source":{"569a5ed2":"#Definition of library\n!pip install pykdtree\n!pip install kdtree\n\nimport os\nimport cv2\nimport csv\nimport argparse\nfrom scipy.io import loadmat\nimport csv\nimport math\nimport random\nfrom scipy.io import loadmat\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import Sequential\nfrom keras.models import load_model\nimport pandas as pd\nimport numpy as np\nimport keras.backend as K\nfrom pykdtree.kdtree import KDTree\nimport glob\nimport h5py\nfrom scipy.io import loadmat\nfrom tqdm import tqdm\nimport h5py\nimport scipy\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\n%matplotlib inline\n#from utils_gen import gen_density_map_gaussian\n\n","e22e8876":"\ndef gen_density_map(img, anno_points):\n   \n    density_map = np.zeros_like(img, dtype=np.float64)\n    h, w = density_map.shape\n    kernel_size = 15 # Gaussian kernel size\n    sigma = 4.0 # standard deviation\n\n    for point in anno_points:\n        # Center point coordinates of human head\n        x, y = min(w-1, abs(math.floor(point[0]))), min(h-1, abs(math.floor(point[1])))\n        # Upper left corner coordinates and lower right corner coordinates\n        x1, y1 = x-kernel_size \/\/ 2, y-kernel_size \/\/ 2\n        x2, y2 = x + kernel_size \/\/ 2 + 1, y + kernel_size \/\/ 2 + 1\n\n        out_of_bounds = False\n        dx1, dy1, dx2, dy2 = 0, 0, 0, 0 # Out of bounds offset\n        # The following four ifs are used to determine whether the x and y of the two top corners are out of bounds\n        if x1 <0:\n            dx1 = abs(x1)\n            x1 = 0\n            out_of_bounds = True\n        if y1 <0:\n            dy1 = abs(y1)\n            y1 = 0\n            out_of_bounds = True\n        if x2> w:\n            dx2 = x2-w\n            x2 = w\n            out_of_bounds = True\n        if y2> h:\n            dy2 = y2-h\n            y2 = h\n            out_of_bounds = True\n\n        if out_of_bounds:\n            # If it is out of bounds, adjust the size of the Gaussian kernel\n            kernel_h = kernel_size-dy1-dy2\n            kernel_w = kernel_size-dx1-dx2\n            # Generate a Gaussian kernel of size (kernel_h, kernel_w)\n            H = np.multiply(cv2.getGaussianKernel(kernel_h, sigma), (cv2.getGaussianKernel(kernel_w, sigma)).T)\n        else:\n            # Generate a Gaussian kernel of size (15, 15)\n            H = np.multiply(cv2.getGaussianKernel(kernel_size, sigma), (cv2.getGaussianKernel(kernel_size, sigma)).T)\n\n        density_map[y1:y2, x1:x2] += H\n    return density_map\n\n\nclass DataLoader(object):\n    def __init__(self, data_path, gt_path, shuffle=False, gt_downsample=False):\n     \n        self.data_path = data_path\n        self.gt_path = gt_path\n        self.shuffle = shuffle\n        self.gt_downsample = gt_downsample\n        self.data_files = [filename for filename in os.listdir(data_path)]\n        self.num_samples = len(self.data_files)\n        self.blob_list = []\n\n        for fname in self.data_files:\n            img = cv2.imread(os.path.join(self.data_path, fname), 0)\n            img = img.astype(np.float32, copy=False)\n            ht = img.shape[0]\n            wd = img.shape[1]\n            ht_1 = int((ht \/ 4) * 4)\n            wd_1 = int((wd \/ 4) * 4)\n            img = cv2.resize(img, (wd_1, ht_1))\n            img = img.reshape((img.shape[0], img.shape[1], 1))\n            den = pd.read_csv(os.path.join(self.gt_path, os.path.splitext(fname)[0] +'.csv'),\n                              header=None).values\n            den = den.astype(np.float32, copy=False)\n            if self.gt_downsample:\n                wd_1 = int(wd_1 \/ 4)\n                ht_1 = int(ht_1 \/ 4)\n            den = cv2.resize(den, (wd_1, ht_1))\n            den = den * ((wd * ht) \/ (wd_1 * ht_1))\n            den = den.reshape((den.shape[0], den.shape[1], 1))\n\n            blob = dict()\n            blob['data'] = img\n            blob['gt'] = den\n            blob['fname'] = fname\n            self.blob_list.append(blob)\n\n        if self.shuffle:\n            np.random.shuffle(self.blob_list)\n\n    def flow(self, batch_size=32):\n        loop_count = self.num_samples \/\/ batch_size\n        while True:\n            np.random.shuffle(self.blob_list)\n            for i in range(loop_count):\n                blobs = self.blob_list[i*batch_size: (i+1)*batch_size]\n                X_batch = np.array([blob['data'] for blob in blobs])\n                Y_batch = np.array([blob['gt'] for blob in blobs])\n                yield X_batch, Y_batch\n\n    def get_all(self):\n        X = np.array([blob['data'] for blob in self.blob_list])\n        Y = np.array([blob['gt'] for blob in self.blob_list])\n        return X, Y\n\n    def __iter__(self):\n        for blob in self.blob_list:\n            yield blob\n\ndef mae(y_true, y_pred):\n    return K.abs(K.sum(y_true) - K.sum(y_pred))\n\ndef mse(y_true, y_pred):\n    return (K.sum(y_true) - K.sum(y_pred)) * (K.sum(y_true) - K.sum(y_pred))\n","1fe90e64":"EPOCHS = 200\nTRAIN_BATCH_SIZE = 1\nVAL_BATCH_SIZE = 1\ndataset = 'A'\nMODEL_DIR = '.\/trained_models\/'\nTRAIN_PATH = '.\/data\/formatted_trainval_{0}\/shanghaitech_part_{0}_patches_9\/train'\nTRAIN_GT_PATH = '.\/data\/formatted_trainval_{0}\/shanghaitech_part_{0}_patches_9\/train_den'\nVAL_PATH = '.\/data\/formatted_trainval_{0}\/shanghaitech_part_{0}_patches_9\/val'\nVAL_GT_PATH = '.\/data\/formatted_trainval_{0}\/shanghaitech_part_{0}_patches_9\/val_den'\n\nTEST_PATH = '.\/data\/original\/shanghaitech\/part_{}_final\/test_data\/images\/'\nTEST_GT_PATH = '.\/data\/original\/shanghaitech\/part_{}_final\/test_data\/ground_truth_csv\/'\nHM_GT_PATH = '.\/heatmaps_gt'\n\npath = '..\/input\/shanghaitech\/part_A\/train_data\/images\/'\ngt_path = '..\/input\/shanghaitech\/part_A\/train_data\/ground_truth\/'\ngt_path_csv = '.\/ground_truth_csv\/'\n\nif not os.path.exists(gt_path_csv):\n    os.makedirs(gt_path_csv)\n#num image\nnum_images = 300\nx=''.join((gt_path,'GT_IMG_1', '.mat'))\nprint(x)","cbc32d3f":"\n\n\nnum_val = math.ceil(num_images * 0.1)  \nindices = list(range(1, num_images + 1))\nrandom.shuffle(indices)\n\nfor idx in range(num_images):\n\n\n    i = indices[idx]\n    if (idx+1) % 10 == 0:\n        print('Processing {}\/{} files'.format(idx+1, num_images))\n    \n    input_img_name = ''.join((path, 'IMG_', str(i), '.jpg'))\n    if os.path.isfile(input_img_name):\n\n      im = cv2.imread(input_img_name, 0)\n      \n      image_info = loadmat(''.join((gt_path, 'GT_IMG_', str(i), '.mat')))['image_info']\n      annPoints = image_info[0][0][0][0][0] - 1\n      \n      im_density = gen_density_map.gen_density_map(im, annPoints)\n\n      h, w = im.shape\n      wn2, hn2 = w \/ 8, h \/ 8  \n      wn2, hn2 = int(wn2 \/ 8) * 8, int(hn2 \/ 8) * 8  \n      \n      xmin, xmax = wn2, w - wn2\n      ymin, ymax = hn2, h - hn2\n      \n      for j in range(1, N + 1):\n          \n          x = math.floor((xmax - xmin) * random.random() + xmin)\n          y = math.floor((ymax - ymin) * random.random() + ymin)\n          \n          x1, y1 = x - wn2, y - hn2\n          x2, y2 = x + wn2, y + hn2\n          \n          im_sampled = im[y1:y2, x1:x2]\n          im_density_sampled = im_density[y1:y2, x1:x2]\n\n          \n          img_idx = ''.join((str(i), '_', str(j)))\n          path_img, path_den = (val_path_img, val_path_den) if (idx+1) < num_val else (train_path_img, train_path_den)\n          cv2.imwrite(''.join([path_img, img_idx, '.jpg']), im_sampled)\n          with open(''.join([path_den, img_idx, '.csv']), 'w', newline='') as fout:\n              writer = csv.writer(fout)\n              writer.writerows(im_density_sampled)\n\n          ","8e0b78be":"dataset = 'A'\nN = 9  \ndataset_name = ''.join(['shanghaitech_part_', dataset, '_patches_', str(N)])\npath = ''.join(['shanghaitech\/part_', dataset, '\/train_data\/images\/'])\noutput_path = 'data\/formatted_trainval_{}\/'.format(dataset)\ntrain_path_img = ''.join((output_path, dataset_name, '\/train\/'))\ntrain_path_den = ''.join((output_path, dataset_name, '\/train_den\/'))\nval_path_img = ''.join((output_path, dataset_name, '\/val\/'))\nval_path_den = ''.join((output_path, dataset_name, '\/val_den\/'))\ngt_path = ''.join(['shanghaitech\/part_', dataset, '\/train_data\/ground_truth\/'])\nprint(gt_path)\n\nfor i in [output_path, train_path_img, train_path_den, val_path_img, val_path_den]:\n    if not os.path.exists(i):\n        os.makedirs(i)","b4ff1b80":"import numpy as np\n\nseed =26\nrandom.seed(seed)\ndataset = 'A'\nN = 9  \ndataset_name = ''.join(['shanghaitech_part_', dataset, '_patches_', str(N)])\npath = '..\/input\/shanghaitech\/ShanghaiTech\/part_A\/train_data\/images\/'\noutput_path = 'data\/formatted_trainval_{}\/'.format(dataset)\ntrain_path_img = ''.join((output_path, dataset_name, '\/train\/'))\ntrain_path_den = ''.join((output_path, dataset_name, '\/train_den\/'))\nval_path_img = ''.join((output_path, dataset_name, '\/val\/'))\nval_path_den = ''.join((output_path, dataset_name, '\/val_den\/'))\ngt_path = '..\/input\/shanghaitech\/ShanghaiTech\/part_A\/train_data\/ground-truth\/'\nprint(gt_path)\n\nfor i in [output_path, train_path_img, train_path_den, val_path_img, val_path_den]:\n    if not os.path.exists(i):\n        os.makedirs(i)\n\nif dataset == 'A':\n    num_images = 300\nelse:\n    num_images = 400\n\nnum_val = math.ceil(num_images * 0.1) \nindices = list(range(1, num_images + 1))\nrandom.shuffle(indices)\n\nfor idx in range(num_images):\n\n  i = indices[idx]\n  if (idx+1) % 10 == 0:\n      print('Processing {}\/{} files'.format(idx+1, num_images))\n  \n  input_img_name = ''.join((path, 'IMG_', str(i), '.jpg'))\n  im = cv2.imread(input_img_name, 0)\n  \n  x11=''.join((gt_path, 'GT_IMG_', str(i), '.mat'))\n\n  image_info = loadmat(''.join((gt_path, 'GT_IMG_', str(i), '.mat')))['image_info']\n  annPoints = image_info[0][0][0][0][0] - 1\n\n  density_map = np.zeros_like(im, dtype=np.float64)\n  print(density_map.shape)\n  \n  im_density = gen_density_map(im, annPoints)\n  \n  h, w = im.shape\n  wn2, hn2 = w \/ 8, h \/ 8  \n  wn2, hn2 = int(wn2 \/ 8) * 8, int(hn2 \/ 8) * 8 \n  xmin, xmax = wn2, w - wn2\n  ymin, ymax = hn2, h - hn2\n  for j in range(1, N + 1):\n      x = math.floor((xmax - xmin) * random.random() + xmin)\n      y = math.floor((ymax - ymin) * random.random() + ymin)\n      x1, y1 = x - wn2, y - hn2\n      x2, y2 = x + wn2, y + hn2\n     \n      im_sampled = im[y1:y2, x1:x2]\n      im_density_sampled = im_density[y1:y2, x1:x2]\n     \n      img_idx = ''.join((str(i), '_', str(j)))\n      path_img, path_den = (val_path_img, val_path_den) if (idx+1) < num_val else (train_path_img, train_path_den)\n      cv2.imwrite(''.join([path_img, img_idx, '.jpg']), im_sampled)\n      with open(''.join([path_den, img_idx, '.csv']), 'w', newline='') as fout:\n          writer = csv.writer(fout)\n          writer.writerows(im_density_sampled)\n         \n","77600176":"                           #prepaire data for train\ntrain_path = '.\/data\/formatted_trainval_A\/shanghaitech_part_A_patches_9\/train'\ntrain_gt_path = '.\/data\/formatted_trainval_A\/shanghaitech_part_A_patches_9\/train_den'\nval_path = '.\/data\/formatted_trainval_A\/shanghaitech_part_A_patches_9\/val'\nval_gt_path = '.\/data\/formatted_trainval_A\/shanghaitech_part_A_patches_9\/val_den'\n\nprint('Loading data, wait a moment...')\ntrain_data_gen = DataLoader(train_path, train_gt_path, shuffle=True, gt_downsample=True)\nval_data_gen = DataLoader(val_path, val_gt_path, shuffle=False, gt_downsample=True)\n\nprint('done')","82f5f9de":"#explor data\nimport matplotlib.pyplot as plt\n\nct_gts = []\nxx=0\nfor blob in train_data_gen:\n    xx=xx+1\n    gt = blob['gt']\n    gt_count = np.sum(gt)\n    ct_gts.append(gt_count)\n\nlen(ct_gts)\n\nfig,ax = plt.subplots(figsize=(5,5))\nax.plot(range(2439),ct_gts,label='train')\nax.legend()\nax.set_xlabel('num image')\nax.set_ylabel('count people')\nct_gts2 = []\nxx=0\nfor blob2 in val_data_gen:\n    xx=xx+1\n    gt2 = blob2['gt']\n    gt_count2 = np.sum(gt2)\n    ct_gts2.append(gt_count2)\nfig2,ax2 = plt.subplots(figsize=(5,5))\nax2.plot(range(261),ct_gts2,label='val')\nax2.legend()\nax2.set_xlabel('num image')\nax2.set_ylabel('count people')\n","c883db23":"len(ct_gts2)","22111e23":"\n\nfrom keras.models import Model\nfrom keras.layers import Conv2D, MaxPooling2D, Input, Concatenate\n\n\ndef MCNN(input_shape=None):\n    inputs = Input(shape=input_shape)\n\n    # column 1\n    column_1 = Conv2D(16, (9, 9), padding='same', activation='relu')(inputs)\n    column_1 = MaxPooling2D(2)(column_1)\n    column_1 = (column_1)\n    column_1 = Conv2D(32, (7, 7), padding='same', activation='relu')(column_1)\n    column_1 = MaxPooling2D(2)(column_1)\n    column_1 = Conv2D(16, (7, 7), padding='same', activation='relu')(column_1)\n    column_1 = Conv2D(8, (7, 7), padding='same', activation='relu')(column_1)\n\n    # column 2\n    column_2 = Conv2D(20, (7, 7), padding='same', activation='relu')(inputs)\n    column_2 = MaxPooling2D(2)(column_2)\n    column_2 = (column_2)\n    column_2 = Conv2D(40, (5, 5), padding='same', activation='relu')(column_2)\n    column_2 = MaxPooling2D(2)(column_2)\n    column_2 = Conv2D(20, (5, 5), padding='same', activation='relu')(column_2)\n    column_2 = Conv2D(10, (5, 5), padding='same', activation='relu')(column_2)\n\n    # column 3\n    column_3 = Conv2D(24, (5, 5), padding='same', activation='relu')(inputs)\n    column_3 = MaxPooling2D(2)(column_3)\n    column_3 = (column_3)\n    column_3 = Conv2D(48, (3, 3), padding='same', activation='relu')(column_3)\n    column_3 = MaxPooling2D(2)(column_3)\n    column_3 = Conv2D(24, (3, 3), padding='same', activation='relu')(column_3)\n    column_3 = Conv2D(12, (3, 3), padding='same', activation='relu')(column_3)\n\n    # merge feature map of 3 columns in last dimension\n    merges = Concatenate(axis=-1)([column_1, column_2, column_3])\n    # density map\n    density_map = Conv2D(1, (1, 1), padding='same')(merges)\n\n    model = Model(inputs=inputs, outputs=density_map)\n    return model\n","7c75129f":"#new train\ninput_shape = (None, None, 1)\nmodel = MCNN(input_shape)\n\nadam = Adam(lr=1e-4)\nmodel.compile(loss='mse', optimizer=adam, metrics=[mae, mse])\n\n\ncheckpointer_best_train = ModelCheckpoint(\n    filepath='..\/input\/data11\/final_model3 .h5',\n    monitor='loss', verbose=1, save_best_only=True, mode='min'\n)\n\ncallback_list = [checkpointer_best_train]\n\n\nprint('done prepaire {} ...'.format(dataset))\nmodel.summary()\n\n","a8afa397":"# intialize wights  resume from last train(transfer learning)\n#model_path = '\/content\/drive\/MyDrive\/final_model153.h5'\nmodel_path = '..\/input\/data11\/final_model32.h5'\nmodel = load_model(model_path)\nadam = Adam(lr=0.00000001)\nmodel.compile(loss='mse', optimizer=adam, metrics=[mae, mse])\n\ncheckpointer_best_train = ModelCheckpoint(\n    filepath='.\/final_model3.h5',\n    monitor='loss', verbose=1, save_best_only=True, mode='min'\n)\ncallback_list = [checkpointer_best_train]\nmodel.summary()\nif not os.path.exists('models'):\n    os.makedirs('models')\n#plot_model(model, 'models\/{}.png')\nwith open('.\/models\/{}.json', 'w') as fout:\n    fout.write(model.to_json())\n","510bcf3e":"#start train 1\nprint (\"start train..........\")\n\nh=model.fit(train_data_gen.flow(1),\n                    steps_per_epoch=train_data_gen.num_samples \/\/ 1,\n                    validation_data=val_data_gen.flow(1),\n                    validation_steps=val_data_gen.num_samples \/\/ 1,\n                    epochs=30,\n                    callbacks=callback_list,\n                    verbose=1)","c05e65f3":"hist_df = pd.DataFrame(h.history) \n\n#  save history of accurcy to csv: \nhist_df = pd.DataFrame(h.history) \n#  save history of accurcy to csv: \nhist_csv_file = '.\/history3.csv'\nwith open(hist_csv_file, mode='a') as f:\n    hist_df.to_csv(f)","710e9461":"#read accurcy as plot\n\nimport pandas as pd\n\nf=pd.read_csv('..\/input\/data11\/history3.csv')  \n\nimport matplotlib.pyplot as plt\n\nplt.plot(f['mse'], label='MSE (training data)')\n\nplt.title('MSE')\nplt.ylabel('MSE value')\nplt.xlabel(' epoch')\nplt.show()","a5c35406":"plt.title('MAE')\nplt.ylabel('MAE value')\nplt.xlabel(' epoch')\nplt.plot(f['mae'])\nplt.show()","e5274d87":"#read accurcy as plot\nimport pandas as pd\nf=pd.read_csv('..\/input\/data11\/history3.csv')  \nimport matplotlib.pyplot as plt\nplt.plot(f['loss'], label='MSE (training data)')\nplt.title('loss fun')\nplt.ylabel('loss ')\nplt.xlabel(' epoch')\nplt.show()","858ad0ac":"#transfer learning\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nimport tensorflow as tf\n\n                                     #prepaire\ntrain_path = '.\/data\/formatted_trainval_A\/shanghaitech_part_A_patches_9\/train\/'\ntrain_gt_path = '.\/data\/formatted_trainval_A\/shanghaitech_part_A_patches_9\/train_den\/'\nval_path = '.\/data\/formatted_trainval_A\/shanghaitech_part_A_patches_9\/val\/'\nval_gt_path = '.\/data\/formatted_trainval_A\/shanghaitech_part_A_patches_9\/val_den\/'\ntrain_data_gen = DataLoader(train_path, train_gt_path, shuffle=True, gt_downsample=True)\nval_data_gen = DataLoader(val_path, val_gt_path, shuffle=False, gt_downsample=True)\n","efca5f2a":"#transfer learning\nmodel_path = 'final_model3.h5'\n\noutput_dir = 'test'\nheatmaps_dir ='test\/'  # directory to save heatmap\nresults_txt = 'test\/r\/ ' # file to save predicted results\nnumtest=10\ntest_path ='.\/data\/formatted_trainval_A\/shanghaitech_part_A_patches_9\/val'\ntest_gt_path ='.\/data\/formatted_trainval_A\/shanghaitech_part_A_patches_9\/val_den'\n# load test set\nprint('Loading data, wait a moment...')\ndata_loader = DataLoader(test_path, test_gt_path, shuffle=False, gt_downsample=True)","e3036f84":"                                            ##Test\nimport matplotlib.pyplot as plt\n\n#print('Loading data, wait a moment...')\n#data_loader = DataLoader(test_path, test_gt_path, shuffle=False, gt_downsample=True)\n# load model\n#model = load_model(model_path)\n# test\nprint('Testing Part_{} ...'.format(dataset))\nmae = 0.0\nmse = 0.0\nu=0\n\nct_preds = []\nct_gts = []\nxx=0\nfor blob in data_loader:\n    xx=xx+1\n    img = blob['data']\n    gt = blob['gt']\n    pred = model.predict(np.expand_dims(img, axis=0))\n    gt_count = np.sum(gt)\n    pred_count = np.sum(pred)\n    ct_preds.append(pred_count)\n    ct_gts.append(gt_count)\n\n  \n    mae += abs(gt_count - pred_count)\n    mse += ((gt_count - pred_count) * (gt_count - pred_count))\n    # create and save heatmap\n    pred = np.squeeze(pred)  # shape(1, h, w, 1) -> shape(h, w)\n\n    #save_heatmap(pred, blob, test_path, heatmaps_dir)#error\n    #print(test_path)\n    # save results\n    #print('<{}> {:.2f} -- {:.2f}\\n'.format(blob['fname'].split('.')[0], gt_count, pred_count))\n   # with open(results_txt, 'a') as f:\n        #line = '<{}> {:.2f} -- {:.2f}\\n'.format(blob['fname'].split('.')[0], gt_count, pred_count)\n        #f.write(line)\nplt.plot(ct_preds, 'r>')\nplt.plot(ct_gts, 'b+')\nplt.legend(['ct_preds', 'ct_gts'])\nplt.title('Pred vs GT')\nplt.show()\nerror = np.array(ct_preds) - np.array(ct_gts)\nplt.plot(error)\nplt.title('Pred - GT, mean = {}, MAE={}'.format(\n    str(round(np.mean(error), 3)),\n    str(round(np.mean(np.abs(error)), 3))\n))\nplt.show()\nidx_max_error = np.argsort(np.abs(error))[::-1]\n\nmae = mae \/ data_loader.num_samples\nmse = np.sqrt(mse \/ data_loader.num_samples)\nprint('MAE: %0.2f, MSE: %0.2f' % (mae, mse))\n#with open(results_txt, 'a') as f:\n   # f.write('MAE: %0.2f, MSE: %0.2f' % (mae, mse))\n\nprint('MAE: %0.2f, MSE: %0.2f' % (mae, mse))\n","4d80b1d7":"\n\ndef smallize_density_map(density_map, stride=1):\n    if stride > 1:\n        density_map_stride = np.zeros((np.asarray(density_map.shape).astype(int)\/\/stride).tolist(), dtype=np.float32)\n        for r in range(density_map_stride.shape[0]):\n            for c in range(density_map_stride.shape[1]):\n                density_map_stride[r, c] = np.sum(density_map[r*stride:(r+1)*stride, c*stride:(c+1)*stride])\n    else:\n        density_map_stride = density_map\n    return density_map_stride\n\n\ndef norm_by_imagenet(img):\n    if len(img.shape) == 3:\n        img = img \/ 255.0\n        img[:, :, 0] = (img[:, :, 0] - 0.485) \/ 0.229\n        img[:, :, 1] = (img[:, :, 1] - 0.456) \/ 0.224\n        img[:, :, 2] = (img[:, :, 2] - 0.406) \/ 0.225\n        return img\n    elif len(img.shape) == 4 or len(img.shape) == 1:\n        # In SHA, shape of images varies, so the array.shape is (N, ), that's the '== 1' case.\n        imgs = []\n        for im in img:\n            im = im \/ 255.0\n            im[:, :, 0] = (im[:, :, 0] - 0.485) \/ 0.229\n            im[:, :, 1] = (im[:, :, 1] - 0.456) \/ 0.224\n            im[:, :, 2] = (im[:, :, 2] - 0.406) \/ 0.225\n            imgs.append(im)\n        return np.array(imgs)\n    else:\n        print('Wrong shape of the input.')\n        return None\n\n\n\ndef image_preprocessing(x, y, flip_hor=False, brightness_shift=False):\n    xs, ys = [], []\n    for idx_pro in range(x.shape[0]):\n        x_, y_ = x[idx_pro], y[idx_pro]\n        # preprocessings -----\n        if flip_hor:\n            x_, y_ = flip_horizontally(x_, y_)\n        # preprocessings -----\n        x_ = norm_by_imagenet(x_)\n        xs.append(x_)\n        ys.append(y_)\n    xs, ys = np.array(xs), np.array(ys)\n    return xs, ys\n\n\ndef flip_horizontally(x, y):\n    to_flip = np.random.randint(0, 2)\n    if to_flip:\n        x, y = cv2.flip(x, 1), np.expand_dims(cv2.flip(np.squeeze(y), 1), axis=-1)\n        # Suppose shape of y is (123, 456, 1), after cv2.flip, shape of y would turn into (123, 456).\n    return x, y\n\n\ndef fix_singular_shape(img, unit_len=16):\n    \"\"\"\n    Some network like w-net has both N maxpooling layers and concatenate layers,\n    so if no fix for their shape as integeral times of 2 ** N, the shape will go into conflict.\n    \"\"\"\n    hei_dst, wid_dst = img.shape[0] + (unit_len - img.shape[0] % unit_len), img.shape[1] + (unit_len - img.shape[1] % unit_len)\n    if len(img.shape) == 3:\n        img = cv2.resize(img, (wid_dst, hei_dst), interpolation=cv2.INTER_LANCZOS4)\n    elif len(img.shape) == 2:\n        GT = int(round(np.sum(img)))\n        img = cv2.resize(img, (wid_dst, hei_dst), interpolation=cv2.INTER_LANCZOS4)\n        img = img \/ (np.sum(img) \/ GT)\n    return img\n\ndef gen_paths_img_dm(path_file_root='data\/paths_train_val_test', dataset='A'):\n    path_file_root_curr = os.path.join(path_file_root, 'paths_'+dataset)\n    img_paths = []\n    dm_paths = []\n    paths = os.listdir(path_file_root_curr)[:2]\n    for i in sorted([os.path.join(path_file_root_curr, p) for p in paths]):\n        with open(i, 'r') as fin:\n            img_paths.append(\n                sorted(\n                    [l.rstrip() for l in fin.readlines()],\n                    key=lambda x: int(x.split('_')[-1].split('.')[0]))\n            )\n        with open(i, 'r') as fin:\n            dm_paths.append(\n                sorted(\n                    [l.rstrip().replace('images', 'ground').replace('.jpg', '.h5') for l in fin.readlines()],\n                    key=lambda x: int(x.split('_')[-1].split('.')[0]))\n            )\n    return img_paths, dm_paths\n\n\ndef gen_var_from_paths(paths, stride=1, unit_len=16):\n    vars = []\n    format_suffix = paths[0].split('.')[-1]\n    if format_suffix == 'h5':\n        for ph in paths:\n            dm = h5py.File(ph, 'r')['density'].value.astype(np.float32)\n            if unit_len:\n                dm = fix_singular_shape(dm, unit_len=unit_len)\n            dm = smallize_density_map(dm, stride=stride)\n            vars.append(np.expand_dims(dm, axis=-1))\n    elif format_suffix == 'jpg':\n        for ph in paths:\n            raw = cv2.cvtColor(cv2.imread(ph), cv2.COLOR_BGR2RGB).astype(np.float32)\n            if unit_len:\n                raw = fix_singular_shape(raw, unit_len=unit_len)\n            vars.append(raw)\n        # vars = norm_by_imagenet(vars)\n    else:\n        print('Format suffix is wrong.')\n    return np.array(vars)\n\n\ndef gen_density_map_gaussian(im, points, sigma=4):\n    \"\"\"\n    func: generate the density map\n    \"\"\"\n    density_map = np.zeros(im.shape[:2], dtype=np.float32)\n    h, w = density_map.shape[:2]\n    num_gt = np.squeeze(points).shape[0]\n    if num_gt == 0:\n        return density_map\n    if sigma == 4:\n        # Adaptive sigma in CSRNet.\n        leafsize = 2048\n        tree = KDTree(points.copy(), leafsize=leafsize)\n        distances, _ = tree.query(points, k=4)\n    for idx_p, p in enumerate(points):\n        p = np.round(p).astype(int)\n        p[0], p[1] = min(h-1, p[1]), min(w-1, p[0])\n        gaussian_radius = sigma * 2 - 1\n        if sigma == 4:\n            # Adaptive sigma in CSRNet.\n            sigma = max(int(np.sum(distances[idx_p][1:4]) * 0.1), 1)\n            gaussian_radius = sigma * 3\n        gaussian_map = np.multiply(\n            cv2.getGaussianKernel(int(gaussian_radius*2+1), sigma),\n            cv2.getGaussianKernel(int(gaussian_radius*2+1), sigma).T\n        )\n        x_left, x_right, y_up, y_down = 0, gaussian_map.shape[1], 0, gaussian_map.shape[0]\n        # cut the gaussian kernel\n        if p[1] < gaussian_radius:\n            x_left = gaussian_radius - p[1]\n        if p[0] < gaussian_radius:\n            y_up = gaussian_radius - p[0]\n        if p[1] + gaussian_radius >= w:\n            x_right = gaussian_map.shape[1] - (gaussian_radius + p[1] - w) - 1\n        if p[0] + gaussian_radius >= h:\n            y_down = gaussian_map.shape[0] - (gaussian_radius + p[0] - h) - 1\n        gaussian_map = gaussian_map[y_up:y_down, x_left:x_right]\n        if np.sum(gaussian_map):\n            gaussian_map = gaussian_map \/ np.sum(gaussian_map)\n        density_map[\n            max(0, p[0]-gaussian_radius):min(h, p[0]+gaussian_radius+1),\n            max(0, p[1]-gaussian_radius):min(w, p[1]+gaussian_radius+1)\n        ] += gaussian_map\n    density_map = density_map \/ (np.sum(density_map \/ num_gt))\n    return density_map","0635e4bf":"\n#..\/input\/shanghaitech\/ShanghaiTech\/part_A\/test_data\/images\/IMG_1.jpg\nroot = '..\/input\/shanghaitech\/ShanghaiTech\/'\npart_A_train = os.path.join(root, 'part_A\/train_data', 'images')\npart_A_test = os.path.join(root, 'part_A\/test_data', 'images')\npart_B_train = os.path.join(root, 'part_B\/train_data', 'images')\npart_B_test = os.path.join(root, 'part_B\/test_data', 'images')\npath_sets_A = [part_A_train, part_A_test]\npath_sets_B = [part_B_train, part_B_test]\nimg_paths_A = []\nfor path in path_sets_A:\n    for img_path in glob.glob(os.path.join(path, '*.jpg')):\n        img_paths_A.append(img_path)\nprint(len(img_paths_A))\nimg_paths_B = []\nfor path in path_sets_B:\n    for img_path in glob.glob(os.path.join(path, '*.jpg')):\n        img_paths_B.append(img_path)\nprint(len(img_paths_B))","3d60aec8":"root = '.\/shanghaitech\/'\n\ndm_paths=[]\nimg_path1=[]\n\nfor dataset in ['A']:\n    img_paths = eval('img_paths_'+dataset)\n    for img_path in tqdm(img_paths_A):\n        img_ori = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n        pts = loadmat(img_path.replace('.jpg', '.mat').replace('images', 'ground-truth').replace('IMG_', 'GT_IMG_'))\n        img = cv2.imread(img_path)\n        sigma = 4  if 'part_A' in img_path else 15\n        k = np.zeros((img.shape[0], img.shape[1]))\n        gt = pts[\"image_info\"][0, 0][0, 0][0]\n        for i in range(len(gt)):\n            if int(gt[i][1]) < img.shape[0] and int(gt[i][0]) < img.shape[1]:\n                k[int(gt[i][1]), int(gt[i][0])] = 1\n\n        DM = gen_density_map_gaussian(k, gt, sigma=sigma)\n\n        file_path = img_path.replace('.jpg', '.h5').replace('images', 'ground').replace('..\/input\/shanghaitech\/ShanghaiTech\/part_A\/train_data\/ground\/', '.\/models').replace('..\/input\/shanghaitech\/ShanghaiTech\/part_A\/test_data\/ground\/', '.\/models')\n        dm_paths.append(file_path)\n        img_path1.append(img_path)\n        \n        with h5py.File(file_path, 'w') as hf:\n            hf['density'] = DM","efa17761":"# Show a sample\nimg_paths = ['..\/input\/shanghaitech\/ShanghaiTech\/part_A\/test_data\/images\/IMG_1.jpg',\n             '..\/input\/shanghaitech\/ShanghaiTech\/part_A\/test_data\/images\/IMG_101.jpg']\nfor img_path in img_paths:\n    img_ori = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n    pts = loadmat(img_path.replace('.jpg', '.mat').replace('images', 'ground-truth').replace('IMG_', 'GT_IMG_'))\n    img = cv2.imread(img_path)\n    \n    sigma = 4  if 'part_A' in img_path else 15\n    k = np.zeros((img.shape[0], img.shape[1]))\n    gt = pts[\"image_info\"][0, 0][0, 0][0]\n    for i in range(len(gt)):\n        if int(gt[i][1]) < img.shape[0] and int(gt[i][0]) < img.shape[1]:\n            k[int(gt[i][1]), int(gt[i][0])] = 1\n\n    DM = gen_density_map_gaussian(k, gt, sigma=sigma)\n    fg, (ax0, ax1) = plt.subplots(1, 2, figsize=(20, 4))\n    ax0.imshow(img_ori)\n    ax0.set_title(str(gt.shape[0]))\n    ax1.imshow(np.squeeze(DM), cmap=plt.cm.jet)\n    ax1.set_title('DM -- '+str(np.sum(DM)))\n    plt.show()","4062ee1e":"\n#important to perpair data\nimport os\nimport cv2\nimport time\nimport random\nimport shutil\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\nplt.ioff()\n\n\ntest_img_paths=img_path1\ntest_dm_paths=dm_paths\n# Settings\nnet = 'CSRNet'\ndataset = \"A\"\n# Generate paths of (train, test) x (img, dm)\n\n# Generate raw images(normalized by imagenet rgb) and density maps\ntest_x, test_y = gen_var_from_paths(test_img_paths[:], unit_len=None), gen_var_from_paths(test_dm_paths[:], stride=8, unit_len=None)\n\n\ntest_x = norm_by_imagenet(test_x)  # Normalization on raw images in test set, those of training set are in image_preprocessing below.\nprint('Test data size:', test_x.shape[0], test_y.shape[0], len(test_img_paths))\n#train_x, train_y = gen_var_from_paths(train_img_paths[:], unit_len=None), gen_var_from_paths(train_dm_paths[:], stride=8, unit_len=None)\n#print('Train data size:', train_x.shape[0], train_y.shape[0], len(train_img_paths))\n# Delete the directory for saving weights during last training.\nweights_dir = 'weights_' + dataset\nif os.path.exists(weights_dir):\n    shutil.rmtree(weights_dir)","76eb28c8":"\nct_preds = []\nct_gts = []\nfor i in range(len(test_x[:])):\n    if i % 100 == 0:\n        print('{}\/{}'.format(i, len(test_x)))\n    i += 0\n    test_x_display = np.squeeze(test_x[i])\n    test_y_display = np.squeeze(test_y[i])\n    path_test_display = test_img_paths[i]\n\n    img = test_x[i][:,:,0]\n\n    img = img.astype(np.float32, copy=False)\n    ht = img.shape[0]\n    wd = img.shape[1]\n    ht_1 = int((ht \/ 4) * 4)\n    wd_1 = int((wd \/ 4) * 4)\n    img = cv2.resize(img, (wd_1, ht_1))\n    img = img.reshape((img.shape[0], img.shape[1], 1))\n\n    #pred = model.predict(np.expand_dims(img, axis=0))\n\n    pred = np.squeeze(model.predict(np.expand_dims(img, axis=0)))\n\n    ct_pred = np.sum(pred)\n    ct_gt = round(np.sum(test_y_display))\n    ct_preds.append(ct_pred)\n    ct_gts.append(ct_gt)\nplt.plot(ct_preds, 'r>')\nplt.plot(ct_gts, 'b+')\nplt.legend(['ct_preds', 'ct_gts'])\nplt.title('Pred vs GT')\nplt.show()\nerror = np.array(ct_preds) - np.array(ct_gts)\nplt.plot(error)\nplt.title('Pred - GT, mean = {}, MAE={}'.format(\n    str(round(np.mean(error), 3)),\n    str(round(np.mean(np.abs(error)), 3))\n))\nplt.show()\nidx_max_error = np.argsort(np.abs(error))[::-1]\n","b5f049b5":"\n# Show rowndom samples\nfor worst_idx in range(50,55):\n    test_x_display = np.squeeze(test_x[worst_idx])\n    test_y_display = np.squeeze(test_y[worst_idx])\n    path_test_display = test_img_paths[worst_idx]\n    test_x_display = np.squeeze(test_x[worst_idx])\n    test_y_display = np.squeeze(test_y[worst_idx])\n    path_test_display = test_img_paths[worst_idx]\n\n    img = test_x[worst_idx][:,:,0]\n\n    img = img.astype(np.float32, copy=False)\n    ht = img.shape[0]\n    wd = img.shape[1]\n    ht_1 = int((ht \/ 4) * 4)\n    wd_1 = int((wd \/ 4) * 4)\n    img = cv2.resize(img, (wd_1, ht_1))\n    img = img.reshape((img.shape[0], img.shape[1], 1))\n\n    \n\n\n    pred = np.squeeze(model.predict(np.expand_dims(img, axis=0)))\n\n\n\n    fg, (ax_x_ori, ax_y, ax_pred) = plt.subplots(1, 3, figsize=(20, 4))\n    ax_x_ori.imshow(cv2.cvtColor(cv2.imread(path_test_display), cv2.COLOR_BGR2RGB))\n    ax_x_ori.set_title('Original Image')\n    ax_y.imshow(test_y_display, cmap=plt.cm.jet)\n    ax_y.set_title('Ground_truth: ' + str(np.sum(test_y_display)))\n    ax_pred.imshow(pred, cmap=plt.cm.jet)\n    ax_pred.set_title('Prediction: ' + str(np.sum(pred)))\n    plt.show()","95b35c38":"this class  gen_density_map \nGenerate density map matrix\nwhitch has  param img: 2d array, image array\nparam anno_points: 2d array, labeled human head coordinates, shape(nums,2) to return: 2d array\n\n\n\nclass DataLoader \nto data preperation \nparam data_path: image file path\nparam gt_path: ground truth path\nparam shuffle: bool, whether to shuffle the data\nparam gt_downsample: bool, whether to downsample\n","c7565dc7":"# start train \n","543c5cf5":"# intialize wights  resume from last train(transfer learning)\n","b8a2fb5c":"# new train\n ","a49991a9":"# **build modle MCNN**","2f6ff24d":"This notebook aims to develop a machine learning model for crowd number estimation from a single\nimage at random crowd density and arbitrary perspective. We have proposed a multi- column\nconvolutional neural network (MCNN) architecture to map Image of a crowd density map. MCNN\nallows the input image to be of any size or resolution. through the use of filters with receptive\nfields of different sizes, And also, regardless of the size of the people. Moreover, the true density\nmap is calculated precisely based on engineering adaptation kernels. We have collected and\nclassified a group of 300 images and created a data Augmentation of images, bringing the training\ndata to 2439 images and verification data of 261 images, we are conducting extensive trials to\nverify the effectiveness of the proposed model and method. In particular, with the proposed\nsimple MCNN model, our method It beats all existing styles. In addition to the experiments Show\nthat our model, once trained on it.\n show that our model, once trained on one dataset, can be readily transferred to a new dataset\n \n ![Picture1.png](attachment:Picture1.png)\n","aa60a2d0":"# read accurcy as plot\n"}}