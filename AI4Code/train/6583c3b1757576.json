{"cell_type":{"bd7952b0":"code","52a158f5":"code","a9113d83":"code","4270e537":"code","457e7e13":"code","5468805b":"code","feac82f6":"code","6a40d4c3":"code","0998a159":"code","866c5c33":"code","ff04cf95":"code","083d5be2":"code","fbab044b":"code","303c1636":"code","e538f7ff":"code","7d19c46a":"code","657f8365":"code","25ed0b68":"code","23fd4b63":"code","f3043637":"code","b057b605":"code","0dfb88aa":"code","e58423c6":"code","38d60e7e":"markdown","447a5de8":"markdown","6a72b5b0":"markdown","8d9093a6":"markdown","71c8909f":"markdown","b8c9b39d":"markdown","37e0ed9b":"markdown"},"source":{"bd7952b0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","52a158f5":"data = pd.read_csv(\"..\/input\/Pokemon.csv\")","a9113d83":"len(data)","4270e537":"data.head(9)","457e7e13":"data.columns","5468805b":"data['Type 2'].fillna(value='None',inplace=True)","feac82f6":"data.head(9)","6a40d4c3":"data['Type 1'].value_counts().plot.bar()","0998a159":"data['Type 2'].value_counts().plot.bar()","866c5c33":"data['Legendary'].value_counts().plot.bar()","ff04cf95":"from sklearn.model_selection import train_test_split\nlegendaryPokemon = data.loc[data['Legendary']==True]\nnormalPokemon = data.loc[data['Legendary']==False]\n# we will only use the pokemon battle stats + types to determine whether it is legendary or not \nlegendaryPokemon = legendaryPokemon[['Type 1','Type 2','Total','HP','Attack','Defense','Sp. Atk','Sp. Def','Speed','Legendary']]\nnormalPokemon = normalPokemon[['Type 1','Type 2','Total','HP','Attack','Defense','Sp. Atk','Sp. Def','Speed','Legendary']]\n\n# now we will randomly sample random non-legendary pokemon from the data set to balance our dataset\n\nsampledNormalPokemon = normalPokemon.sample(100)\n\n\nx = pd.concat([legendaryPokemon, sampledNormalPokemon])\nx = pd.get_dummies(x)\n# take last column as training labels and drop it from the training data\ny = x['Legendary']\nx = x.drop('Legendary', 1)","083d5be2":"testNormalPokemon = pd.get_dummies(normalPokemon)\ntestNormalPokemon.head()","fbab044b":"#Using the train_test_split to create train and test sets.\nX_train, X_test, y_train, y_test = train_test_split(x, y, random_state = 47, test_size = 0.30)","303c1636":"# now that we have split our train, test data. Let's increase the amount of Legendary pokemon in our training data, \n# by creating synthetic examples using the SMOTE algorithm\nfrom imblearn.over_sampling import SMOTE\n\n# sampling ration of 1.0 will equally balance the binary classes\nsm = SMOTE(random_state=15,sampling_strategy= 1.0)\nX_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n","e538f7ff":"\nX_train_res.shape","7d19c46a":"(y_train_res == True).sum()","657f8365":"from sklearn.ensemble import RandomForestClassifier # for random forest classifier\nmodel = RandomForestClassifier(n_estimators=100,max_depth=7)","25ed0b68":"#Training the random forest classifier. \nmodel.fit(X_train_res, y_train_res)\n","23fd4b63":"#Predicting labels on the test set.\ny_pred =  model.predict(X_test)","f3043637":"#Importing the accuracy metric from sklearn.metrics library\n\nfrom sklearn.metrics import accuracy_score\nprint('Accuracy Score on train data: ', accuracy_score(y_true=y_train_res, y_pred=model.predict(X_train_res)))\nprint('Accuracy Score on test data: ', accuracy_score(y_true=y_test, y_pred=y_pred))","b057b605":"# feature importance\nimportances = pd.DataFrame({'feature':X_train.columns,'importance':np.round(model.feature_importances_,3)})\nimportances = importances.sort_values('importance',ascending=False).set_index('feature')\nimportances.head(10)","0dfb88aa":"plot = importances.plot.pie(y='importance', figsize=(10, 10))","e58423c6":"import sklearn.tree \nimport graphviz \n\n# Extract single tree\nestimator = model.estimators_[4]\n\ndot_data = dot_data = sklearn.tree.export_graphviz(estimator, out_file=None, \n               feature_names=x.columns,  \n                class_names=['normal','legendary'] , filled=True, rounded=True,  special_characters=True)  \ngraph = graphviz.Source(dot_data) \n\ngraph","38d60e7e":"Damn! The legendary Pok\u00e9mon live up to their name of rarity with less than a 1\/8 of Pokemon holding that status.\n\nI wonder if any of the other features in the dataset can indicate whether a pokemon is legendary or not!\n\nLets use a decision tree to model this problem!\n* Decision tree learners create biased trees if some classes dominate. It is therefore recommended to balance the dataset prior to fitting with the decision tree.","447a5de8":"So we have 13 features (columns) in our data.\n\nWe can see that not all pokemon have dual types e.g. Charmander, so lets replace any NaN values in Type 2 column","6a72b5b0":"Let's check the data out, How many pokemon are in the dataset?","8d9093a6":"So we can see that having a second type is actually quite rare among all the 800 pokemon with almost 50% having no type at all.\n\nIn pokemon the Legendary pokemon, were always the coolest. Lets see how many there are?","71c8909f":"check the data to see the NaN have bits been updated","b8c9b39d":"Woaahhh so many water types!! we can see that there are not many primary flying types, hmm why dont we look at the type 2 count too!","37e0ed9b":"Nice! lets start doing some visualisation to understand our data\n\n1. How much of each primary type are there?\n\n(pandas.Series.value_counts returns object containing counts of unique values)"}}