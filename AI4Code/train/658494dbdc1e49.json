{"cell_type":{"3cb8eb37":"code","7fa901a7":"code","28e9c616":"code","5f0c0af9":"code","e61c0ecd":"code","0786a00e":"code","210ca5f5":"code","6e016be4":"code","b982a771":"code","5624af1c":"code","072f074d":"code","49cb8f79":"code","b7e4accf":"code","3f2eff4b":"code","ae766c03":"code","7dcaa2e1":"code","b28a6921":"code","e782d364":"code","fa1359e5":"code","48d9cdd8":"code","892c5c93":"code","6bb18d9d":"code","8ae31e98":"code","88d0a34a":"code","e734e099":"code","c5a93a8a":"code","e7de6888":"code","51d5b311":"code","9b3e79a9":"code","ee4e0822":"code","63d4f0f5":"code","f04c681f":"code","f21ad14d":"code","401f40f7":"code","4c2d997b":"code","7b07d808":"code","eeb0b604":"code","5c36479f":"code","70225104":"code","9ce13abd":"code","c2a4477d":"code","5b74b88d":"code","e2fb2723":"code","dd0d9748":"code","4199c436":"code","285eff21":"code","1c95e9fe":"code","b515442c":"code","866e74a4":"code","1a0913dd":"code","48b36807":"code","9f3bcf62":"markdown","5e722965":"markdown","51a5221d":"markdown","590a60c2":"markdown","b3443750":"markdown","d7fd1081":"markdown","16de6bc8":"markdown","6b4b9f49":"markdown","d8e9c5e0":"markdown","c7bd9f5f":"markdown","503bb47f":"markdown","cb1dc552":"markdown","081d535c":"markdown","d8021eb9":"markdown","96bd9e77":"markdown","7ce0c7d2":"markdown"},"source":{"3cb8eb37":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7fa901a7":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.metrics import classification_report \n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.neural_network import MLPClassifier","28e9c616":"# load the dataset\n\ndata = pd.read_csv('\/kaggle\/input\/iris\/Iris.csv')\ndata.head()","5f0c0af9":"data.shape","e61c0ecd":"data.info()","0786a00e":"data.describe()","210ca5f5":"# Histogram based on count of each label in the dataset\n\nplt.figure(figsize=(8,4))\nsns.countplot(x = data['Species'])\nplt.tight_layout()","6e016be4":"# Scatter plot based on dimension of Sepal and Petal\n\nfig, (ax0, ax1) = plt.subplots(1, 2, figsize=(16,8))\nsns.scatterplot(x = data['SepalLengthCm'], y = data['SepalWidthCm'], hue = data['Species'], ax=ax0)\nsns.scatterplot(x = data['PetalLengthCm'], y = data['PetalWidthCm'], hue = data['Species'], ax=ax1)\nplt.tight_layout()","b982a771":"# box plot of different features\n\nplt.figure(figsize=(8,8))\nsns.boxplot(data = data.drop('Id', axis=1));","5624af1c":"# abstraction of independent and dependent variables\n\nX, y = data.drop(['Id', 'Species'], axis=1), data['Species']\nprint(X.shape, y.shape)","072f074d":"# encoing categorical values\n\nenc = LabelEncoder()\ny = enc.fit_transform(y)","49cb8f79":"# splitting the dataset into training and testing sets\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)\nprint(y_train.shape, y_test.shape)","b7e4accf":"# feature scaling\n\nst = StandardScaler()\nX_train = st.fit_transform(X_train)\nX_test = st.transform(X_test)","3f2eff4b":"scores = pd.DataFrame(columns = ['Model','Training', 'Testing'])","ae766c03":"# finding the best parameters using grid search\n\nparam_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\ngrid = GridSearchCV(LogisticRegression(), param_grid = param_grid, cv=3).fit(X_train, y_train)\nprint('Score: {:.3f}'.format(grid.score(X_test, y_test)))\nprint('Best Estimator: {}'.format(grid.best_estimator_))","7dcaa2e1":"# visualization of effect of the parameter\n\nfig = plt.figure(figsize=(4, 4))\n\nparam = [0.001, 0.01, 0.1, 1, 10, 100]\nx = np.linspace(0,5,6)\n\nax = fig.add_axes([1,1,1.1,1.1])\nax.set_xticks(x)\nax.set_xticklabels(param)\n\ntest_score = np.array([])\ntrain_score = np.array([])\nfor i in param:\n    clf = LogisticRegression(C=i).fit(X_train, y_train)\n    train_score = np.append(train_score, clf.score(X_train, y_train))\n    test_score = np.append(test_score, clf.score(X_test, y_test))\n\nax.plot(x, train_score, label='Train Score')\nax.plot(x, test_score, label='Test Score')\nax.set_title('Logistic Regression')\nax.legend();","b28a6921":"# checking score of data across different folds using cross_val_score\n\ncvs = cross_val_score(LogisticRegression(C=100, max_iter=1000), X, y, cv=5)\nprint('Cross Validation Scores: {:.3f} {:.3f} {:.3f} {:.3f} {:.3f}'.format(*cvs))","e782d364":"# fitting the training set in the model and appending the scores to the DataFrame\n\nclf = LogisticRegression(C=100).fit(X_train, y_train)\n\ntraining_s = np.round(clf.score(X_train, y_train), 3)\ntesting_s = np.round(clf.score(X_test, y_test), 3)\n\nprint('Training Score: {}'.format(training_s))\nprint('Testing Score: {}'.format(testing_s))\n\nscores = scores.append({'Model':'LogisticRegression','Training':training_s,'Testing':testing_s}, ignore_index=True)","fa1359e5":"# classification report of the model\n\nprint(classification_report(y_test, clf.predict(X_test)))","48d9cdd8":"# fitting the training set in the model and appending the scores to the DataFrame\n\nclf = GaussianNB().fit(X_train, y_train)\n\ntraining_s = np.round(clf.score(X_train, y_train), 3)\ntesting_s = np.round(clf.score(X_test, y_test), 3)\n\nprint('Training Score: {}'.format(training_s))\nprint('Testing Score: {}'.format(testing_s))\n\nscores = scores.append({'Model':'GaussianNB','Training':training_s,'Testing':testing_s}, ignore_index=True)","892c5c93":"# classification report of the model\n\nprint(classification_report(y_test, clf.predict(X_test)))","6bb18d9d":"# finding the best parameters using grid search\n\nparam_grid = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\ngrid = GridSearchCV(KNeighborsClassifier(), param_grid = param_grid, cv=3).fit(X_train, y_train)\nprint('Score: {:.3f}'.format(grid.score(X_test, y_test)))\nprint('Best Estimator: {}'.format(grid.best_estimator_))","8ae31e98":"# visualization of effect of the parameter\n\nfig = plt.figure(figsize=(4, 4))\n\nparam = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\nx = np.linspace(0,9,10)\n\nax = fig.add_axes([1,1,1.1,1.1])\nax.set_xticks(x)\nax.set_xticklabels(param)\n\ntest_score = np.array([])\ntrain_score = np.array([])\nfor i in param:\n    clf = KNeighborsClassifier(n_neighbors=i).fit(X_train, y_train)\n    train_score = np.append(train_score, clf.score(X_train, y_train))\n    test_score = np.append(test_score, clf.score(X_test, y_test))\n\nax.plot(x, train_score, label='Train Score')\nax.plot(x, test_score, label='Test Score')\nax.set_title('K-Neighbors Classifier')\nax.legend();","88d0a34a":"# checking score of data across different folds using cross_val_score\n\ncvs = cross_val_score(KNeighborsClassifier(n_neighbors=7), X, y, cv=5)\nprint('Cross Validation Scores: {:.3f} {:.3f} {:.3f} {:.3f} {:.3f}'.format(*cvs))","e734e099":"# fitting the training set in the model and appending the scores to the DataFrame\n\nclf = KNeighborsClassifier(n_neighbors=7).fit(X_train, y_train)\n\ntraining_s = np.round(clf.score(X_train, y_train), 3)\ntesting_s = np.round(clf.score(X_test, y_test), 3)\n\nprint('Training Score: {}'.format(training_s))\nprint('Testing Score: {}'.format(testing_s))\n\nscores = scores.append({'Model':'KNeighborsClassifier','Training':training_s,'Testing':testing_s}, ignore_index=True)","c5a93a8a":"# classification report of the model\n\nprint(classification_report(y_test, clf.predict(X_test)))","e7de6888":"# finding the best parameters using grid search\n\nparam_grid = {'C': [0.01, 0.1, 1, 10, 100], 'gamma': [0.01, 0.1, 1, 10, 100], 'kernel':['linear', 'rbf', 'poly']}\ngrid = GridSearchCV(SVC(), param_grid = param_grid, cv=3).fit(X_train, y_train)\nprint('Score: {:.3f}'.format(grid.score(X_test, y_test)))\nprint('Best Estimator: {}'.format(grid.best_estimator_))","51d5b311":"# checking score of data across different folds using cross_val_score\n\ncvs = cross_val_score(SVC(C=1, gamma=0.01, kernel='linear'), X, y, cv=5)\nprint('Cross Validation Scores: {:.3f} {:.3f} {:.3f} {:.3f} {:.3f}'.format(*cvs))","9b3e79a9":"# fitting the training set in the model and appending the scores to the DataFrame\n\nclf = SVC(C=1, gamma=0.01, kernel='linear').fit(X_train, y_train)\n\ntraining_s = np.round(clf.score(X_train, y_train), 3)\ntesting_s = np.round(clf.score(X_test, y_test), 3)\n\nprint('Training Score: {}'.format(training_s))\nprint('Testing Score: {}'.format(testing_s))\n\nscores = scores.append({'Model':'SVC','Training':training_s,'Testing':testing_s}, ignore_index=True)","ee4e0822":"# classification report of the model\n\nprint(classification_report(y_test, clf.predict(X_test)))","63d4f0f5":"# finding the best parameters using grid search\n\nparam_grid = {'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\ngrid = GridSearchCV(DecisionTreeClassifier(), param_grid = param_grid, cv=3).fit(X_train, y_train)\nprint('Score: {:.3f}'.format(grid.score(X_test, y_test)))\nprint('Best Estimator: {}'.format(grid.best_estimator_))","f04c681f":"# visualization of effect of the parameter\n\nfig = plt.figure(figsize=(4, 4))\n\nparam = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\nx = np.linspace(0,9,10)\n\nax = fig.add_axes([1,1,1.1,1.1])\nax.set_xticks(x)\nax.set_xticklabels(param)\n\ntest_score = np.array([])\ntrain_score = np.array([])\nfor i in param:\n    clf = DecisionTreeClassifier(max_depth=i).fit(X_train, y_train)\n    train_score = np.append(train_score, clf.score(X_train, y_train))\n    test_score = np.append(test_score, clf.score(X_test, y_test))\n\nax.plot(x, train_score, label='Train Score')\nax.plot(x, test_score, label='Test Score')\nax.set_title('Decision Tree Classifier')\nax.legend();","f21ad14d":"# checking score of data across different folds using cross_val_score\n\ncvs = cross_val_score(DecisionTreeClassifier(max_depth=2), X, y, cv=5)\nprint('Cross Validation Scores: {:.3f} {:.3f} {:.3f} {:.3f} {:.3f}'.format(*cvs))","401f40f7":"# fitting the training set in the model and appending the scores to the DataFrame\n\nclf = DecisionTreeClassifier(max_depth=2).fit(X_train, y_train)\n\ntraining_s = np.round(clf.score(X_train, y_train), 3)\ntesting_s = np.round(clf.score(X_test, y_test), 3)\n\nprint('Training Score: {}'.format(training_s))\nprint('Testing Score: {}'.format(testing_s))\n\nscores = scores.append({'Model':'DecisionTreeClassifier','Training':training_s,'Testing':testing_s}, ignore_index=True)","4c2d997b":"# classification report of the model\n\nprint(classification_report(y_test, clf.predict(X_test)))","7b07d808":"# finding the best parameters using grid search\n\nparam_grid = {'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\ngrid = GridSearchCV(RandomForestClassifier(), param_grid = param_grid, cv=5).fit(X_train, y_train)\nprint('Score: {:.3f}'.format(grid.score(X_test, y_test)))\nprint('Best Estimator: {}'.format(grid.best_estimator_))","eeb0b604":"# visualization of effect of the parameter\n\nfig = plt.figure(figsize=(4, 4))\n\nparam = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\nx = np.linspace(0,9,10)\n\nax = fig.add_axes([1,1,1.1,1.1])\nax.set_xticks(x)\nax.set_xticklabels(param)\n\ntest_score = np.array([])\ntrain_score = np.array([])\nfor i in param:\n    clf = RandomForestClassifier(max_depth=i).fit(X_train, y_train)\n    train_score = np.append(train_score, clf.score(X_train, y_train))\n    test_score = np.append(test_score, clf.score(X_test, y_test))\n\nax.plot(x, train_score, label='Train Score')\nax.plot(x, test_score, label='Test Score')\nax.set_title('Random Forest Classifier')\nax.legend();","5c36479f":"# checking score of data across different folds using cross_val_score\n\ncvs = cross_val_score(RandomForestClassifier(max_depth=6), X, y, cv=5)\nprint('Cross Validation Scores: {:.3f} {:.3f} {:.3f} {:.3f} {:.3f}'.format(*cvs))","70225104":"# fitting the training set in the model and appending the scores to the DataFrame\n\nclf = RandomForestClassifier(max_depth=6).fit(X_train, y_train)\n\ntraining_s = np.round(clf.score(X_train, y_train), 3)\ntesting_s = np.round(clf.score(X_test, y_test), 3)\n\nprint('Training Score: {}'.format(training_s))\nprint('Testing Score: {}'.format(testing_s))\n\nscores = scores.append({'Model':'RandomForestClassifier','Training':training_s,'Testing':testing_s}, ignore_index=True)","9ce13abd":"# classification report of the model\n\nprint(classification_report(y_test, clf.predict(X_test)))","c2a4477d":"# finding the best parameters using grid search\n\nparam_grid = {'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\ngrid = GridSearchCV(GradientBoostingClassifier(), param_grid = param_grid, cv=4).fit(X_train, y_train)\nprint('Score: {:.3f}'.format(grid.score(X_test, y_test)))\nprint('Best Estimator: {}'.format(grid.best_estimator_))","5b74b88d":"# visualization of effect of the parameter\n\nfig = plt.figure(figsize=(4, 4))\n\nparam = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\nx = np.linspace(0,9,10)\n\nax = fig.add_axes([1,1,1.1,1.1])\nax.set_xticks(x)\nax.set_xticklabels(param)\n\ntest_score = np.array([])\ntrain_score = np.array([])\nfor i in param:\n    clf = GradientBoostingClassifier(max_depth=i).fit(X_train, y_train)\n    train_score = np.append(train_score, clf.score(X_train, y_train))\n    test_score = np.append(test_score, clf.score(X_test, y_test))\n\nax.plot(x, train_score, label='Train Score')\nax.plot(x, test_score, label='Test Score')\nax.set_title('Gradient Boosting Classifier')\nax.legend();","e2fb2723":"# checking score of data across different folds using cross_val_score\n\ncvs = cross_val_score(GradientBoostingClassifier(max_depth=2), X, y, cv=5)\nprint('Cross Validation Scores: {:.3f} {:.3f} {:.3f} {:.3f} {:.3f}'.format(*cvs))","dd0d9748":"# fitting the training set in the model and appending the scores to the DataFrame\n\nclf = GradientBoostingClassifier(max_depth=2).fit(X_train, y_train)\n\ntraining_s = np.round(clf.score(X_train, y_train), 3)\ntesting_s = np.round(clf.score(X_test, y_test), 3)\n\nprint('Training Score: {}'.format(training_s))\nprint('Testing Score: {}'.format(testing_s))\n\nscores = scores.append({'Model':'GradientBoostingClassifier','Training':training_s,'Testing':testing_s}, ignore_index=True)","4199c436":"# classification report of the model\n\nprint(classification_report(y_test, clf.predict(X_test)))","285eff21":"# finding the best parameters using grid search\n\nparam_grid = {'hidden_layer_sizes': [[5], [10], [5,5], [10,10]], 'alpha': [0.01, 0.1, 1, 10]}\ngrid = GridSearchCV(MLPClassifier(solver='lbfgs', max_iter=1000), param_grid = param_grid, cv=3).fit(X_train, y_train)\nprint('Score: {:.3f}'.format(grid.score(X_test, y_test)))\nprint('Best Estimator: {}'.format(grid.best_estimator_))","1c95e9fe":"# checking score of data across different folds using cross_val_score\n\ncvs = cross_val_score(MLPClassifier(alpha=1, hidden_layer_sizes=[10,10], max_iter=1000, solver='lbfgs'), X, y, cv=5)\nprint('Cross Validation Scores: {:.3f} {:.3f} {:.3f} {:.3f} {:.3f}'.format(*cvs))","b515442c":"# fitting the training set in the model and appending the scores to the DataFrame\n\nclf = MLPClassifier(alpha=1, hidden_layer_sizes=[10,10], max_iter=1000, solver='lbfgs').fit(X_train, y_train)\n\ntraining_s = np.round(clf.score(X_train, y_train), 3)\ntesting_s = np.round(clf.score(X_test, y_test), 3)\n\nprint('Training Score: {}'.format(training_s))\nprint('Testing Score: {}'.format(testing_s))\n\nscores = scores.append({'Model':'MLPClassifier','Training':training_s,'Testing':testing_s}, ignore_index=True)","866e74a4":"# classification report of the model\n\nprint(classification_report(y_test, clf.predict(X_test)))","1a0913dd":"# best to worst model performance\n\nscores = scores.reindex(scores.mean(axis=1).sort_values()[::-1].index)\nscores","48b36807":"# plot of respective models\n\nplt.figure(figsize=(8,8))\nplt.plot(scores['Model'], scores['Training'], label='Train Score')\nplt.plot(scores['Model'], scores['Testing'], label='Test Score')\nplt.tick_params(axis='x', rotation=45)","9f3bcf62":"# ML Modeling","5e722965":"# Importing Libraries","51a5221d":"## 2. Gaussian Naive Bayes","590a60c2":"# Conslusion","b3443750":"## 3. K-Neighbors Classifier","d7fd1081":"## 8. Multilayer Perceptron Classifier (Neural Networks)","16de6bc8":"## 6. Random Forest Classifier","6b4b9f49":"#### - We can observe that the RandomForestClassifier and GradientBoostingClassifier fits the data very well resulting in a good performance.\n#### - The LogisticRegression and MLPClassifier fits the data quite good as well but not as good as RandomForest and GradientBoosting\n#### - However, GaussianNBClassifier, KNeighborsClassifier, SVC and DecisionTreeClassifier does not fit the data equally as good.\n<br>\n\n### The best model to use for this dataset would be LogisticRegression if considering the time taken to train the model, and RandomForestClassifier\/GradientBoostingClassifier if complexity can be compromised for best results.","d8e9c5e0":"# Data Visualization","c7bd9f5f":"# Data Preprocessing","503bb47f":"# Loading and Analysing Dataset","cb1dc552":"# Performance Comparison","081d535c":"## 7. Gradient Boosting Classifier","d8021eb9":"## 1. Logistic Regression","96bd9e77":"## 5. Decision Tree Classifier","7ce0c7d2":"## 4. Support Vector Classifier"}}