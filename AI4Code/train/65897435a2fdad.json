{"cell_type":{"15d8cff8":"code","571cca48":"code","1288c9b3":"code","b95cfcf4":"code","b2f7bc01":"code","e6e19436":"code","22ae9fc2":"code","b3f32270":"code","bc309fed":"code","fefc30e5":"code","2a834967":"code","e7042ca3":"code","7485cf4a":"code","4b598734":"code","fcc185ed":"code","04bee713":"code","4ed9d050":"code","e7bd1e36":"code","d3f00c8b":"code","fda04735":"code","2a513e74":"code","c97053b2":"code","84b5cd3b":"code","b97a4a87":"code","9a8ee013":"markdown","91fea3f9":"markdown","7080deda":"markdown","73394dd7":"markdown","5c85c4ee":"markdown","624a64da":"markdown","fd49fd00":"markdown","a9c2cbf5":"markdown","859fc517":"markdown","4b7b72cc":"markdown","ecf80ba1":"markdown","2c3328a2":"markdown","bd97f174":"markdown","06271650":"markdown","65d3d24a":"markdown","bf3e55b6":"markdown","c48ff3ae":"markdown"},"source":{"15d8cff8":"pip install -U scikit-image==0.16.2","571cca48":"import os \nimport sys\nfrom tqdm import tqdm\nimport cv2\nimport numpy as np\nimport json\nimport skimage.draw\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport random\nfrom pathlib import Path\nfrom IPython.display import clear_output\n\nDATASET_DIR = '..\/input\/brain-tumor'\nROOT_DIR = Path('\/kaggle\/working')\n#-------- directory to save logs and trained model----\nMODEL_DIR = os.path.join(ROOT_DIR, 'logs')\nDEFAULT_LOGS_DIR = 'logs' ","1288c9b3":"!pip install tensorflow==1.14\nimport tensorflow as tf\nclear_output()","b95cfcf4":"tf.__version__","b2f7bc01":"!pip install keras==2.1.5\nclear_output()","e6e19436":"!pip install pycocotools\nclear_output()","22ae9fc2":"!git clone https:\/\/www.github.com\/matterport\/Mask_RCNN.git\n!rm -rf .git # to prevent an error when the kernel is committed\n!rm -rf images assets # to prevent displaying images at the bottom of a kernel\nclear_output()","b3f32270":"# Root directory of the project\nROOT_DIR = os.path.abspath('Mask_RCNN\/')\n# Import Mask RCNN\nsys.path.append(ROOT_DIR) \nfrom mrcnn.config import Config\nfrom mrcnn import utils\nfrom mrcnn.model import log\nimport mrcnn.model as modellib\nfrom mrcnn import visualize\n\nclear_output()","bc309fed":"sys.path.append(os.path.join(ROOT_DIR, 'samples\/coco\/'))\nimport coco\n\n# Local path to trained weights file\nCOCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n# Download COCO trained weights from Releases if needed\nif not os.path.exists(COCO_MODEL_PATH):\n    utils.download_trained_weights(COCO_MODEL_PATH)\nplt.rcParams['figure.facecolor'] = 'white'\n\nclear_output()","fefc30e5":"class TumorConfig(Config):\n    NAME = 'Brain_Tumor_Detector'\n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 1\n    NUM_CLASSES = 1 + 1 \n    DETECTION_MIN_CONFIDENCE = 0.9    \n    STEPS_PER_EPOCH = 80\n    LEARNING_RATE = 0.005    \nconfig = TumorConfig()\nconfig.display()","2a834967":"class BrainTumorDataset(utils.Dataset):\n    def load_brain_scan(self, dataset_dir, subset):\n        \"\"\"Load a subset of the FarmCow dataset.\n        dataset_dir: Root directory of the dataset.\n        subset: Subset to load: train or val\n        \"\"\"\n        # Add classes. We have only one class to add.\n        self.add_class(\"tumor\", 1, \"tumor\")\n\n        # Train or validation dataset?\n        assert subset in [\"Training\", \"Validation\", 'Test']\n        dataset_dir = os.path.join(dataset_dir, subset)\n\n        annotations = json.load(open(os.path.join(dataset_dir,'annotations_'+subset+'.json')))\n        annotations = list(annotations.values())  # don't need the dict keys\n\n        # The VIA tool saves images in the JSON even if they don't have any\n        # annotations. Skip unannotated images.\n        annotations = [a for a in annotations if a['regions']]\n\n        # Add images\n        for a in annotations:\n            # Get the x, y coordinaets of points of the polygons that make up\n            # the outline of each object instance. These are stores in the\n            # shape_attributes (see json format above)\n            # The if condition is needed to support VIA versions 1.x and 2.x.\n            if type(a['regions']) is dict:\n                polygons = [r['shape_attributes'] for r in a['regions'].values()]\n            else:\n                polygons = [r['shape_attributes'] for r in a['regions']]\n\n            # load_mask() needs the image size to convert polygons to masks.\n            # Unfortunately, VIA doesn't include it in JSON, so we must read\n            # the image. This is only managable since the dataset is tiny.\n            image_path = os.path.join(dataset_dir, a['filename'])\n            \n            image = skimage.io.imread(image_path)\n            height, width = image.shape[:2]\n\n            self.add_image(\n                \"tumor\",\n                image_id=a['filename'],  # use file name as a unique image id\n                path=image_path,\n                width=width, \n                height=height,\n                polygons=polygons\n            )\n\n    def load_mask(self, image_id):\n        \"\"\"Generate instance masks for an image.\n       Returns:\n        masks: A bool array of shape [height, width, instance count] with\n            one mask per instance.\n        class_ids: a 1D array of class IDs of the instance masks.\n        \"\"\"\n        # If not a farm_cow dataset image, delegate to parent class.\n        image_info = self.image_info[image_id]\n        if image_info[\"source\"] != \"tumor\":\n            return super(self.__class__, self).load_mask(image_id)\n\n        # Convert polygons to a bitmap mask of shape\n        # [height, width, instance_count]\n        info = self.image_info[image_id]\n        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n                        dtype=np.uint8)\n        for i, p in enumerate(info[\"polygons\"]):\n            # Get indexes of pixels inside the polygon and set them to 1\n            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n            mask[rr, cc, i] = 1\n\n        # Return mask, and array of class IDs of each instance. Since we have\n        # one class ID only, we return an array of 1s\n        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n\n    def image_reference(self, image_id):\n        \"\"\"Return the path of the image.\"\"\"\n        info = self.image_info[image_id]\n        if info[\"source\"] == \"tumor\":\n            return info[\"path\"]\n        else:\n            super(self.__class__, self).image_reference(image_id)","e7042ca3":"# Training dataset.\ndataset_train = BrainTumorDataset()\ndataset_train.load_brain_scan(DATASET_DIR, 'Training')\ndataset_train.prepare()\n\n# Validation dataset\ndataset_val = BrainTumorDataset()\ndataset_val.load_brain_scan(DATASET_DIR, 'Validation')\ndataset_val.prepare()\n\ndataset_test = BrainTumorDataset()\ndataset_test.load_brain_scan(DATASET_DIR, 'Test')\ndataset_test.prepare()","7485cf4a":"print(dataset_train.image_reference(6))\nimage = dataset_train.load_image(6)\nmask, class_ids = dataset_train.load_mask(6)\nvisualize.display_top_masks(image, mask, class_ids, dataset_train.class_names, limit=1)\n    ","4b598734":"print(dataset_train.image_reference(30))\nimage = dataset_train.load_image(30)\nmask, class_ids = dataset_train.load_mask(30)\nvisualize.display_top_masks(image, mask, class_ids, dataset_train.class_names, limit=1)","fcc185ed":"print(dataset_train.image_reference(40))\nimage = dataset_train.load_image(40)\nmask, class_ids = dataset_train.load_mask(40)\nvisualize.display_top_masks(image, mask, class_ids, dataset_train.class_names, limit=1)","04bee713":"#-------------- Create model object in training mode------------------------\nmodel = modellib.MaskRCNN(\n    mode='training', \n    config=config, \n    model_dir=DEFAULT_LOGS_DIR\n)\n#-------------- Load weights trained on MS-COCO ---------------------------\nmodel.load_weights(\n    COCO_MODEL_PATH, \n    by_name=True, \n    exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"]\n)","4ed9d050":"model.train(\n    dataset_train, dataset_val,\n    learning_rate=config.LEARNING_RATE,\n    epochs=7,\n    layers='heads'\n)","e7bd1e36":"def display_image(dataset, ind):\n    plt.figure(figsize=(5,5))\n    plt.imshow(dataset.load_image(ind))\n    plt.xticks([])\n    plt.yticks([])\n    plt.title('Original Image')\n    plt.show()\ndef get_ax(rows=1, cols=1, size=5):\n    \"\"\"Return a Matplotlib Axes array to be used in\n    all visualizations in the notebook. Provide a\n    central point to control graph sizes.\n    \n    Change the default size attribute to control the size\n    of rendered images\n    \"\"\"\n    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n    return ax\n\ndef predict_and_plot_differences(dataset, img_id):\n    original_image, image_meta, gt_class_id, gt_box, gt_mask =\\\n        modellib.load_image_gt(dataset, config, \n                               img_id, use_mini_mask=False)\n\n    results = model.detect([original_image], verbose=0)\n    r = results[0]\n\n    visualize.display_differences(\n        original_image,\n        gt_box, gt_class_id, gt_mask,\n        r['rois'], r['class_ids'], r['scores'], r['masks'],\n        class_names = ['tumor'], title=\"\", ax=get_ax(),\n        show_mask=True, show_box=True)","d3f00c8b":"# Recreate the model in inference mode\nmodel = modellib.MaskRCNN(\n    mode=\"inference\", \n    config=config,\n    model_dir=DEFAULT_LOGS_DIR\n)\n\n\nmodel_path = model.find_last()\n#model_path=\"..\/input\/mask-r-cnn-tumor-brain\/logs\/tumor_detector20210209T1932\/mask_rcnn_tumor_detector_0002.h5\"\n# Load trained weights\nprint(\"Loading weights from \", model_path)\nmodel.load_weights(model_path, by_name=True)","fda04735":"print(\"Sample 1\")\nind = 10\ndisplay_image(dataset_val, ind)\npredict_and_plot_differences(dataset_val, ind)\n","2a513e74":"print(\"Sample 2\")\nind = 16\ndisplay_image(dataset_val, ind)\npredict_and_plot_differences(dataset_val, ind)","c97053b2":"print(\"Sample 3\")\nind = 0\ndisplay_image(dataset_test, ind)\npredict_and_plot_differences(dataset_test, ind)","84b5cd3b":"print(\"Sample 4\")\nind = 2\ndisplay_image(dataset_test, ind)\npredict_and_plot_differences(dataset_test, ind)","b97a4a87":"print(\"Sample 5\")\nind = 3\ndisplay_image(dataset_test, ind)\npredict_and_plot_differences(dataset_test, ind)","9a8ee013":"# 4-Import COCO config","91fea3f9":"# 7-Build the Mask R-CNN Model Architecture\n","7080deda":"![download.png](attachment:download.png)","73394dd7":"# 5-Brain Tumor Dataset","5c85c4ee":"# 6-Visualizing Some Samples","624a64da":"# 11-Detect Tumors and Visualize the Results","fd49fd00":"## 2.3 Install pycocotools","a9c2cbf5":"# 8-Training","859fc517":"# 1-Import Libraries","4b7b72cc":"# 10-Inference","ecf80ba1":"# 9-Helper Functions\n","2c3328a2":"# 12- References\n1. https:\/\/www.kaggle.com\/ruslankl\/brain-tumor-detection-v2-0-mask-r-cnn\n","bd97f174":"# 2-Installing","06271650":"# 3-Download the Model Mask_RCNN ","65d3d24a":"# Brain Tumor Detection using Mask R-CNN ","bf3e55b6":"## 2.2 Install Keras version (2.1.5)","c48ff3ae":"## 2.1-Install the previous version of TensorFlow(1.14)"}}