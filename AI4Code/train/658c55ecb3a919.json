{"cell_type":{"da1d4357":"code","a4af03ae":"code","d85cc2da":"code","273c8368":"code","1cbfd7c0":"code","9d4718a8":"code","d1d5ccb7":"code","28a60b23":"code","fd689f06":"code","cbfb384a":"code","bba48281":"code","2dbc1904":"code","facb6e60":"code","4132f6e2":"code","fc70f65d":"code","5baebce1":"code","3468a646":"code","51dc901e":"code","0db692dd":"code","328b030f":"code","f3632caa":"code","f74ef478":"code","b88d9da6":"code","108ebf63":"code","32522f70":"code","5c346342":"markdown","1c0ebdd5":"markdown","42cc6253":"markdown","2cfb8c86":"markdown","fb06feea":"markdown","c071eea1":"markdown","2fecc6bf":"markdown"},"source":{"da1d4357":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras.layers import Embedding,Flatten,Dense,LSTM\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot\n\nimport regex as re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer","a4af03ae":"train_data=pd.read_csv('\/kaggle\/input\/fake-news\/train.csv')\ntrain_data.head()","d85cc2da":"train_data['label'].value_counts()","273c8368":"train_data.shape","1cbfd7c0":"train_data=train_data.dropna()\nprint(train_data.shape)","9d4718a8":"X=train_data.drop('label',axis=1)\nX.head()","d1d5ccb7":"y=train_data['label']","28a60b23":"test_data=pd.read_csv('\/kaggle\/input\/fake-news\/test.csv')\ntest_data.head()","fd689f06":"vocab_size=5000","cbfb384a":"messages=X.copy()\nmessages.reset_index(inplace=True)\nmessages.head()","bba48281":"ps=PorterStemmer()\ncorpus_train=[]\nfor i in range(len(messages)):\n    review=re.sub('[^a-zA-Z]',' ',messages['title'][i])\n    review=review.lower()\n    review=review.split()\n    review=[ps.stem(word) for word in review if word not in stopwords.words('english')]\n    review=' '.join(review)\n    corpus_train.append(review)","2dbc1904":"corpus_train[0:10]","facb6e60":"messages['title'][0:10]","4132f6e2":"one_hot_rep=[one_hot(words,vocab_size) for words in corpus_train]\none_hot_rep[0]","fc70f65d":"sent_length=20\nembedded_docs=pad_sequences(one_hot_rep,padding='pre',maxlen=sent_length)\nembedded_docs[0]","5baebce1":"embedded_features=40\n\nmodel=Sequential()\n\nmodel.add(Embedding(vocab_size,embedded_features,input_length=sent_length))\nmodel.add(LSTM(100))\nmodel.add(Dense(1,activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nmodel.summary()","3468a646":"X_final=np.asarray(embedded_docs)\ny_final=np.asarray(y)","51dc901e":"X_train,X_test,y_train,y_test=train_test_split(X_final,y_final,random_state=42)\nprint(X_train.shape,y_train.shape)\nprint(X_test.shape,y_test.shape)","0db692dd":"train_model=model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10)","328b030f":"plt.plot(train_model.history['accuracy'],'b',label='train_accuracy')\nplt.plot(train_model.history['val_accuracy'],'r',label='val_accuracy')\nplt.legend()","f3632caa":"def test(X):\n    X=X.fillna(0)\n    messages=X.copy()\n    messages.reset_index(inplace=True)\n    corpus=[]\n    for i in range(len(messages)):\n        reviews=re.sub('[^a-zA-Z]',' ',str(messages['title'][i]))\n        reviews=reviews.lower()\n        reviews=reviews.split()\n        reviews=[ps.stem(word) for word in reviews if word not in stopwords.words('english')]\n        reviews=' '.join(reviews)\n        corpus.append(reviews)\n    one_hot_rep=[one_hot(word,vocab_size)for word in corpus]\n    embedded_docs = pad_sequences(one_hot_rep, padding = 'pre', maxlen = sent_length)\n    X_final = np.array(embedded_docs)\n    \n    \n    return X_final","f74ef478":"test_data_new= test(test_data)\ntest_data_new[0]","b88d9da6":"pred=model.predict(test_data_new)\nprint(pred.shape)","108ebf63":"submission_data = pd.read_csv('\/kaggle\/input\/fake-news\/submit.csv')\nsubmission_data['label']=np.round(pred).astype('int')\nsubmission_data.head()","32522f70":"submission_data.to_csv('Submission.csv',index=False)","5c346342":"### RNN-Model","1c0ebdd5":"### Preparing data","42cc6253":"### Train the model","2cfb8c86":"### Reading data","fb06feea":"### Split train test data","c071eea1":"### Import required packages","2fecc6bf":"### Plotting accuracy"}}