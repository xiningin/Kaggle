{"cell_type":{"0b73f72d":"code","82ff0e9c":"code","36b5963e":"code","6bfc4af1":"code","7d1a652a":"code","94a6b00e":"code","77d15aa0":"code","a1bafc9f":"code","259409e5":"code","a093535c":"code","3a0d152a":"markdown","508608e3":"markdown","74e32fcb":"markdown","3cd15362":"markdown","c30fb192":"markdown","8717d5ce":"markdown","032ef05a":"markdown","f34e3a67":"markdown","c0ea0ffb":"markdown","6960c657":"markdown"},"source":{"0b73f72d":"# Importing libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.datasets import load_boston","82ff0e9c":"boston_dataset = load_boston()\ndataset = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\ndataset['MEDV'] = boston_dataset.target","36b5963e":"print(dataset.head())\nprint(dataset.describe())\nprint(dataset.info())\nprint(dataset.isnull().sum())","6bfc4af1":"sns.distplot(dataset['MEDV'])\nplt.show()","7d1a652a":"correlation_matrix = dataset.corr().round(2)\n# annot is True to print the values inside the square\nsns.heatmap(data=correlation_matrix, annot=True)\nplt.show()","94a6b00e":"plt.figure(figsize=(20, 5))\n\nfeatures = ['LSTAT', 'RM']\ntarget = dataset['MEDV']\n\nfor i, col in enumerate(features):\n    plt.subplot(1, len(features), i+1)\n    x = dataset[col]\n    y = target\n    plt.scatter(x , y, marker='o')\n    plt.title(col)\n    plt.xlabel(col)\n    plt.ylabel('MEDV')\nplt.show()\n","77d15aa0":"X = pd.DataFrame(np.c_[dataset['LSTAT'], dataset['RM']], columns=['LSTAT', 'RM'])\nY = dataset['MEDV']","a1bafc9f":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=5)\n\nfrom sklearn.linear_model import LinearRegression\nreg = LinearRegression()\nreg.fit(X_train, y_train)","259409e5":"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n# Model evaluation for training set\ny_train_predict = reg.predict(X_train)\nprint(\"Model evaluation for training set\")\nprint(\"\\n mean_squared_error = \", (mean_squared_error(y_train, y_train_predict)))\nprint(\"\\n root mean_squared_error = \", np.sqrt(mean_squared_error(y_train, y_train_predict)))\nprint(\"\\n mean_absolute_error = \", mean_absolute_error(y_train, y_train_predict))\nprint(\"\\n r2_score = \", r2_score(y_train, y_train_predict))","a093535c":"y_test_predict = reg.predict(X_test)\ndf = pd.DataFrame({'Actual': y_test, 'Predicted': y_test_predict})\nprint(df)\n(df.head(10)).plot(kind='bar')\nplt.show()\n\nprint(\"Model evaluation for test set\")\nprint(\"\\n mean_squared_error = \", (mean_squared_error(y_test, y_test_predict)))\nprint(\"\\n root mean_squared_error = \", np.sqrt(mean_squared_error(y_test, y_test_predict)))\nprint(\"\\n mean_absolute_error = \", mean_absolute_error(y_test, y_test_predict))\nprint(\"\\n r2_score = \", r2_score(y_test, y_test_predict))","3a0d152a":"# Creating the correlation matrix that measures the linear relationship b\/w the variables.","508608e3":"# **Checking distribution of target variable**","74e32fcb":"# Model Evaluation","3cd15362":"# **loading data set**","c30fb192":"> Observation -->\n* TO fit a linear regression model, we select those features which have a high correlation\n  with our target variable.(+ve or -ve)(RM, LSTAT)\n* An important point in selecting feature for a LR model is to check for multi-colinearity\n  The features RAD, TAX have a correlation of 0.91. These features pairs are strongly correlated\n  to each other. We should not select both these features together for training the model.\n  And same goes with DIS and AGE.  ","8717d5ce":"# **Analysing dataset**","032ef05a":"* Model evaluation for training set","f34e3a67":"> Based on the above observations we will choose RM and LSTAT as our features.\nUsing a scatter plot let's see how these features vary with MEDV. ","c0ea0ffb":"# Preparing data for taring the model","6960c657":"* Model evaluation for testing set"}}