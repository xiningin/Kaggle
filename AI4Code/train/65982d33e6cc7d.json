{"cell_type":{"aee0f2c6":"code","022088d8":"code","440b075c":"code","1a78d655":"code","de1bfd2d":"code","c0acb1c0":"code","75b89ce8":"code","4959b2a7":"code","5ae2edec":"code","67874462":"code","fe960c52":"code","18ce7b63":"code","76379261":"code","ad7a0540":"code","ff7ba3a9":"code","792e0c81":"code","6a5151b2":"code","167e66d0":"code","135c9257":"code","0b38e8de":"code","7349a10e":"code","0125a682":"code","231931d2":"code","31bd236c":"code","df1e5315":"code","e7e0c04b":"code","98be5373":"code","c57c2996":"code","171c8d0f":"code","fbf46732":"code","9922f10c":"code","6da45f7e":"code","4a8772da":"code","7809388c":"code","f3ce2054":"code","3bea88d0":"code","c4530aa9":"code","178b91f4":"code","d62c7375":"code","10a8e9ea":"code","415797e7":"code","f70ee836":"code","056eaaa5":"code","6f2d957e":"code","e2feb736":"code","db42c7c2":"code","84d98433":"markdown","2fe558a0":"markdown","f6b86e42":"markdown","cd479cda":"markdown","d381cf27":"markdown","dea9add6":"markdown","a3343130":"markdown","cd6fd76a":"markdown","4ab3f34e":"markdown","44501255":"markdown","db53fb07":"markdown","d44806c6":"markdown","3a841306":"markdown","f81f5aa0":"markdown","ed979d66":"markdown","84cbee92":"markdown","6b485809":"markdown","3a899d83":"markdown","43ee7efb":"markdown","6e20f316":"markdown","84a4c599":"markdown","8f79c645":"markdown","f0af5b6c":"markdown","63ab1b0b":"markdown","f47f5188":"markdown","034465d4":"markdown","4d3de28f":"markdown","62c9b63a":"markdown","859b2c62":"markdown","5420477f":"markdown","85a5a546":"markdown","436bd26e":"markdown","15269247":"markdown","7d0a0faf":"markdown","711d4e43":"markdown","f076f7fd":"markdown","5cc3c36b":"markdown","e090b74d":"markdown","b7474b3a":"markdown"},"source":{"aee0f2c6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","022088d8":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import GridSearchCV,RandomizedSearchCV\nfrom sklearn.preprocessing import OneHotEncoder,OrdinalEncoder,StandardScaler,MinMaxScaler,PowerTransformer,FunctionTransformer\nfrom sklearn.model_selection import train_test_split,cross_val_score\nfrom sklearn.metrics import confusion_matrix,classification_report,ConfusionMatrixDisplay\nfrom sklearn.linear_model import LogisticRegression,RidgeClassifier,LassoCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import accuracy_score, plot_confusion_matrix\n\n\nimport cufflinks as cf\nimport plotly.offline\ncf.go_offline()\ncf.set_config_file(offline=False, world_readable=True)\nimport plotly \nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.offline as py\nfrom plotly.offline import iplot\nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff\nimport warnings\nwarnings.filterwarnings(\"ignore\", category = FutureWarning)\n\n\nsns.set(style=\"darkgrid\")\n","440b075c":"#load the dataset\ndf=pd.read_csv(\"..\/input\/heart-failure-prediction\/heart.csv\")\ndf.head()","1a78d655":"#check the rows and columns number.\nprint(f\"number of rows:--> {df.shape[0]} and number of columns:--> {df.shape[1]}\")","de1bfd2d":"#chack the data information\ndf.info()","c0acb1c0":"#check for missing numbers\ndef checking_m(df):\n    null_v = df.isnull().sum().sort_values(ascending=False)\n    null_percent = (df.isnull().sum()\/df.isnull().count()).sort_values(ascending=False)\n    null_v = pd.concat([null_v, null_percent], axis=1, keys=['Missing_Number', 'Missing_Percent'])\n    return null_v\n\nchecking_m(df)","75b89ce8":"#check for dublicated rows\nprint(\"Numbers of duplicated rows :\",df.duplicated().sum())","4959b2a7":"#check data description\ndf.describe().T.style.bar(subset=['mean'], color='#205ff2').background_gradient(subset=['std'], cmap='Reds').background_gradient(subset=['50%'], cmap='coolwarm')","5ae2edec":"#check the correlation between terget and each of columns\ndf.corr()[\"HeartDisease\"]\n","67874462":"plt.figure(figsize=(20,10))\n\n#plot heat map\nsns.heatmap(df.corr(),annot=True,cmap=\"gist_heat\")","fe960c52":"#with the function we can select highly correlated  independent features \n#it will remove the first feature that is correlated with anything other feature \ndef correlation(df,threshold):\n    coll_corr=set() #set of all the names of correlated columns \n    corr_matrix=df.corr()\n    for i in range (len(corr_matrix.columns)):\n        for j in range(i):\n            if abs(corr_matrix.iloc[i,j])> threshold:\n                colname=corr_matrix.columns[i] #getting the name of columns\n                coll_corr.add(colname)\n    return coll_corr           ","18ce7b63":"#calling the fuction\ncorr_feature = correlation(df.iloc[:,:-1],0.85)\nlen(set(corr_feature))","76379261":"#get numerical and categorical col\n#getting the categorical and numerical columns from df\nnumeric_col=[col for col in df if df[col].dtype !=\"object\" ]\ncategorical_col=[col for col in df if df[col].dtype==\"object\" ]\nnumeric_col.remove(\"HeartDisease\")\nprint(\"Numerical col:\",numeric_col)\nprint(\"Categrical col:\",categorical_col)","ad7a0540":"df[numeric_col].iplot(kind='histogram',subplots=True)","ff7ba3a9":"df.head()","792e0c81":"fig = px.histogram(df, 'Age',             \n                   color=\"HeartDisease\",histfunc=\"count\",\n                   title=\"<b>Age vs HeartDisease<\/b>\")\n\nfig.show()","6a5151b2":"fig = px.histogram(df, x='Cholesterol',        \n                   color=\"HeartDisease\",\n                   title=\"<b>Cholesterol vsHeartDisease<\/b>\")\n\nfig.show()","167e66d0":"fig = px.histogram(df, 'RestingBP',             \n                   color=\"HeartDisease\",histfunc=\"count\",\n                   title=\"<b>RestingBP vs HeartDisease<\/b>\")\n\nfig.show()","135c9257":"pd.DataFrame(df['HeartDisease'].value_counts()).rename({\"HeartDisease\":\"Counts\"}, axis = 1).rename_axis(\"HeartDisease\")","0b38e8de":"fig = px.pie(df, names = \"HeartDisease\",\n             title = \"<b>Counts in HeartDisease<\/b>\",\n             hole = 0.4, template = \"plotly_dark\",\n            width=600,\n            height=400)\n\nfig.update_traces(textposition='inside',\n                  textinfo='percent+label',\n                  marker=dict(line=dict(color='#000000', width = 2)))\n\n\nfig.show()","7349a10e":"#Sex vs heart disease\ndf.groupby('Sex')['HeartDisease'].mean().sort_values(ascending=False)*100","0125a682":"fig = px.histogram(data_frame = df,\n             x = \"Sex\",\n             color=\"HeartDisease\", title=\"<b>Sex vs HeartDisease<\/b>\",\n             pattern_shape_sequence=['x'],template='plotly_dark', width=500,height=300)\n\nfig.show()","231931d2":"#ChestPainType vs Heart disease\ndf.groupby('ChestPainType')['HeartDisease'].mean().sort_values(ascending=False)*100","31bd236c":"fig = px.histogram(data_frame = df,\n             x = \"ChestPainType\",\n             color=\"HeartDisease\", title=\"<b>ChestPainType vs HeartDisease<\/b>\",\n             pattern_shape_sequence=[\"x\"],template='plotly_dark', width=500,height=300)\n\nfig.show()","df1e5315":"#RestingECG vs HeartDisease\ndf.groupby('RestingECG')['HeartDisease'].mean().sort_values(ascending=False)*100","e7e0c04b":"fig = px.histogram(data_frame = df,\n             x = \"RestingECG\",\n             color=\"HeartDisease\", title=\"<b>RestingECG vs HeartDisease<\/b>\",\n             pattern_shape_sequence=['x'],template='plotly_dark', width=500,height=300)\n\nfig.show()","98be5373":"#ExerciseAngina vs Heart disease\ndf.groupby('ExerciseAngina')['HeartDisease'].mean().sort_values(ascending=False)*100","c57c2996":"fig = px.histogram(data_frame = df,\n             x = \"ExerciseAngina\",\n             color=\"HeartDisease\", title=\"<b>ExerciseAngina vs HeartDisease<\/b>\",\n             pattern_shape_sequence=['x'],template='plotly_dark', width=500,height=300)\n\nfig.show()","171c8d0f":"#ST_Slope vs HeartDisease\ndf.groupby('ST_Slope')['HeartDisease'].mean().sort_values(ascending=False)*100","fbf46732":"fig = px.histogram(data_frame = df,\n             x = \"ST_Slope\",\n             color=\"HeartDisease\", title=\"<b>ST_Slope vs HeartDisease<\/b>\",\n             pattern_shape_sequence=['x'],template='plotly_dark', width=500,height=300)\n\nfig.show()","9922f10c":"# Get the features and terget columns\nX=df.iloc[:,0:-1]\ny=df.HeartDisease","6da45f7e":"#It is a good practise to split the data to avoiding the data leakage \n#train test split  \nx_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\nprint(\"X_train shape: \",x_train.shape)\nprint(\"X_test shape: \",x_test.shape)\nprint(\"Y_train shape: \",y_train.shape)\nprint(\"Y_test shape: \",y_test.shape)\n","4a8772da":"#let find the skewed col and fix them\n    \nskew_limit=0.75 # limit for skewed col\nskew_vals=x_train[numeric_col].drop('FastingBS', axis=1).skew()\nskew_col=skew_vals[abs(skew_vals)>skew_limit].sort_values(ascending =False)\n\n#graphically represent the skewed col\ni=1    \nprint(\"Columns names: \",skew_col.index)\nprint(\"\\n\")\nprint(\"skewed value:--->>\",skew_col)\nplt.figure(figsize=(40,60))\nfor col in skew_col.index:\n    plt.subplot(8,2,i)\n    sns.distplot(X[col],color=\"r\")\n    plt.xticks(fontsize=25)\n    plt.yticks(fontsize=25)\n    plt.xlabel(col,fontsize=25)\n    i=i+1\n        \n\nplt.show()","7809388c":"#fix the skewness using function transformer\npt=PowerTransformer(standardize=False)\n#ft=FunctionTransformer(func=np.log1p)\nskew=[\"Oldpeak\"]\nx_train[skew]=pt.fit_transform(x_train[skew])\nx_test[skew]=pt.transform(x_test[skew])","f3ce2054":"x_train.head()","3bea88d0":"#Encoding the categorical columns into numerical columns \nx_train=pd.get_dummies(x_train,columns=categorical_col,drop_first=True) #using pandas function\nx_test=pd.get_dummies(x_test,columns=categorical_col,drop_first=True)\nprint(\"shape:\",x_train.shape)\nprint()\nx_train.head()","c4530aa9":"# Using standard scaler\nsc=StandardScaler()\nx_train_scaled=sc.fit_transform(x_train)\nx_test_scaled=sc.transform(x_test)\n\nx_train = pd.DataFrame(x_train_scaled, columns = x_train.columns[:])\nx_test = pd.DataFrame(x_test_scaled, columns = x_test.columns[:])\nx_train.head()","178b91f4":"#this function used to evalute the models with features and terget.\ndef models_score(models, X_train, X_test, y_train, y_test):    \n    \n    scores = {}\n    \n    for name, model in models.items():\n        model.fit(X_train, y_train)\n        y_pred=model.predict(X_test) \n        scores[name] = model.score(X_test,y_test)\n        #printing the model name and accuracy !!!!!\n        print(\"Model name: \",model)\n        print(\"Accuracy :--->>\",accuracy_score(y_test,y_pred))\n        print()\n        print(classification_report(y_test,y_pred))\n        print(\"Confusion matrix:--->>\\n\",confusion_matrix(y_test,y_pred)) \n        print(\"\\n<<<<------------------------------------------------------------->>>>\\n\")\n           \n   \n    model_scores = pd.DataFrame(scores, index=['Score']).transpose()\n    model_scores = model_scores.sort_values('Score',ascending=False)\n    return model_scores\n    \n    \n   ","d62c7375":"#initialize the models \nmodels = {\"LogisticRegression\":LogisticRegression(solver=\"liblinear\"),\n          \"SVC\":SVC(C= 1.0,gamma= 0.05,kernel='rbf'),\n          \"DecisionTree\":DecisionTreeClassifier(criterion='gini',max_depth=5,max_features='auto',splitter='random'),\n          \"AdaBoost\":AdaBoostClassifier(algorithm='SAMME',learning_rate= 0.1,n_estimators=150),\n          \"GradiantBoost\":GradientBoostingClassifier(criterion='friedman_mse',learning_rate=0.05,loss='exponential',n_estimators=100),\n         \"RandomForest\":RandomForestClassifier(criterion='gini',n_estimators=50),\n         \"XgBoost\": XGBClassifier(learning_rate=0.1,n_estimators=50),\n         \"KNeighborsClassifier\":KNeighborsClassifier(n_neighbors=7)}","10a8e9ea":"#Calling the function\nmodel_scores = models_score(models, x_train, x_test, y_train, y_test)","415797e7":"model_scores","f70ee836":"model_scores = model_scores.reset_index().rename({\"index\":\"Algorithms\"}, axis = 1)\n\nmodel_scores.style.bar()","056eaaa5":"fig = px.bar(data_frame = model_scores,\n             x=\"Algorithms\",\n             y=\"Score\",\n             color=\"Algorithms\", title = \"<b>Models Score<\/b>\", template = 'plotly_dark')\n\nfig.update_layout(bargap=0.2)\n\nfig.show()","6f2d957e":"label = model_scores['Algorithms']\nvalue = model_scores['Score']\n\nfig = go.Figure(data=[go.Pie(labels = label, values = value, rotation = 90)])\n\nfig.update_traces(textposition='inside',\n                  textinfo='percent+label',\n                  marker=dict(line=dict(color='#000000', width = 1.5)))\n\nfig.update_layout(title_x=0.5,\n                  title_font=dict(size=20),\n                  uniformtext_minsize=15)\n\nfig.show()","e2feb736":"#knn\nknn=KNeighborsClassifier(n_neighbors=7)\nknn.fit(x_train,y_train)\nprint(\"Confusion matrix:------>>>>\\n\")\nplot_confusion_matrix(knn,\n                      x_test, y_test,\n                      cmap=\"cool\",\n                      display_labels = ['0', '1'])\nplt.grid(False)\nplt.show();","db42c7c2":"#Gradinat boosting classifier\ngbc=GradientBoostingClassifier(criterion='friedman_mse',learning_rate=0.05,loss='exponential',n_estimators=100)\ngbc.fit(x_train,y_train)\nprint(\"Confusion matrix:---------->>>\\n\")\nplot_confusion_matrix(gbc,\n                      x_test, y_test,\n                      cmap=\"cool\",\n                      display_labels = ['0', '1'])\nplt.grid(False)\nplt.show();","84d98433":"<a id=\"10\"><\/a>\n# <p style=\"background-color:#47b7ed;font-family:newtimeroman;color:#000000;font-size:120%;text-align:center;border-radius:20px 80px;\">\ud83d\udcca Visualize Model Score<\/p>","2fe558a0":"<b>No imbalanced classes in terget col ,great \ud83d\ude0e\ud83d\ude0e","f6b86e42":"<b> we got only 1 skewed columns ","cd479cda":"<b>we have no  missing values in our dataset .great!!!","d381cf27":"<a id=\"4\"><\/a>\n# <p style=\"background-color:#47b7ed;font-family:newtimeroman;color:#000000;font-size:120%;text-align:center;border-radius:20px 80px;\">\ud83d\udcc8 Statistical information of Dataframe<\/p>\n","dea9add6":"<a id=\"7.3\"><\/a>\n# <p style=\"background-color:#47b7ed;font-family:newtimeroman;color:#000000;font-size:120%;text-align:center;border-radius:20px 80px;\"> \ud83d\udc31\u200d\ud83c\udfcdEncoding the Categorical columns \ud83e\uddd0<\/p>\n","a3343130":"<a id=\"2\"><\/a>\n# <p style=\"background-color:#47b7ed;font-family:newtimeroman;color:#000000;font-size:120%;text-align:center;border-radius:20px 80px;\">\ud83d\udcdd Meta information about Dataframe<\/p>\n\u200b","cd6fd76a":"<a id=\"7.1\"><\/a>\n# <p style=\"background-color:#47b7ed;font-family:newtimeroman;color:#000000;font-size:120%;text-align:center;border-radius:20px 80px;\"> \ud83d\udc31\u200d\ud83c\udfcdTrain test split \ud83e\uddd0<\/p>\n","4ab3f34e":"<a id=\"6.1\"><\/a>\n# <p style=\"background-color:#47b7ed;font-family:newtimeroman;color:#000000;font-size:120%;text-align:center;border-radius:20px 80px;\">\ud83d\udc7b Numerical EDA<\/p>\n","44501255":"<b>exercise-induced angina with 'Yes' almost 2.4 times more likley have a heart disaese than exercise-induced angina with 'No' \ud83d\ude2f\ud83d\ude2f","db53fb07":"<a id=\"6\"><\/a>\n# <p style=\"background-color:#47b7ed;font-family:newtimeroman;color:#000000;font-size:120%;text-align:center;border-radius:20px 80px;\">\ud83d\udd25 EDA & Visualization<\/p>\n","d44806c6":"# <a id=\"1\"><\/a>\n# <p style=\"background-color:#47b7ed;font-family:newtimeroman;color:#000000;font-size:120%;text-align:center;border-radius:20px 80px;\">\ud83d\udce5 Importing libraries<\/p>\n","3a841306":"<b>we transform our Oldpeak col and fix the skewness \ud83d\ude0e","f81f5aa0":"<a id=\"6.2\"><\/a>\n# <p style=\"background-color:#47b7ed;font-family:newtimeroman;color:#000000;font-size:120%;text-align:center;border-radius:20px 80px;\">\ud83d\udc7b Terget EDA<\/p>\n","ed979d66":"<b> 50 to 65 age peoples are suffer in herat disease ","84cbee92":"<b>\ud83d\ude4b\u200d\u2642\ufe0f\ud83d\ude4b\u200d\u2640\ufe0f Hi all !!! we going to implement heart failure classification problem ,If you like this notebook then plz consider a upvote for me and if don't plz drop your advise or comment so that i improve my skill !!!!!!!!","6b485809":"<b> No highly correalted features or multicolinarity problems ,great !","3a899d83":"<a id=\"5\"><\/a>\n# <p style=\"background-color:#47b7ed;font-family:newtimeroman;color:#000000;font-size:120%;text-align:center;border-radius:20px 80px;\">\ud83c\udfb0 Visualize correlation of independent features and check multicolinarity problems<\/p>\n\n","43ee7efb":"<b>DATA DICTONARY:------>>>\n\n1 Age: Age of the patient [years]\n\n2 Sex: Sex of the patient [M: Male, F: Female]\n\n3 ChestPainType: [TA: Typical Angina, ATA: Atypical Angina, NAP: Non-Anginal \nPain, ASY: Asymptomatic]\n\n4 RestingBP: Resting blood pressure [mm Hg]\n\n5 Cholesterol: Serum cholesterol [mm\/dl]\n\n6 FastingBS: Fasting blood sugar [1: if FastingBS > 120 mg\/dl, 0: otherwise]\n\n7 RestingECG: Resting electrocardiogram results [Normal: Normal, ST: having ST-T wave abnormality (T wave inversions and\/or ST elevation or depression of > 0.05 mV), LVH: showing probable or definite left ventricular hypertrophy by Estes' criteria]\n\n8 MaxHR: Maximum heart rate achieved [Numeric value between 60 and 202]\n9 ExerciseAngina: Exercise-induced angina [Y: Yes, N: No]\n\n10 Oldpeak: ST [Numeric value measured in depression]\n\n11 ST_Slope: The slope of the peak exercise ST segment [Up: upsloping, Flat: flat, Down: downsloping]\n\n12 HeartDisease: Output class [1: heart disease, 0: Normal]\n\nReference: https:\/\/www.kaggle.com\/fedesoriano\/heart-failure-prediction","6e20f316":"<a id=\"7.2\"><\/a>\n# <p style=\"background-color:#47b7ed;font-family:newtimeroman;color:#000000;font-size:120%;text-align:center;border-radius:20px 80px;\"> \ud83d\udc31\u200d\ud83c\udfcdNormalized skewed col \ud83e\uddd0<\/p>\n","84a4c599":"<b>we noticed some skewed columns ,we fix it later !!!","8f79c645":"<a id=\"8\"><\/a>\n# <p style=\"background-color:#47b7ed;font-family:newtimeroman;color:#000000;font-size:120%;text-align:center;border-radius:20px 80px;\">\ud83e\udd16 Create & Train Model<\/p>\n","f0af5b6c":"<a id=\"11\"><\/a>\n# <p style=\"background-color:#47b7ed;font-family:newtimeroman;color:#000000;font-size:120%;text-align:center;border-radius:20px 80px;\"> \ud83c\udf08Confusion matrix of top two models<\/p>","63ab1b0b":"<a id='top'><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<p style=\"background-color:#47b7ed;font-family:newtimeroman;color:#000000;font-size:170%;text-align:center;border-radius:20px 80px;\">\ud83d\udccb TABLE OF CONTENTS<\/p>   ","f47f5188":"<b>Asymptomatic chest pain has almost 6 times more likely have a heart disease than person with ATA Atypical Angina chest pain","034465d4":"<a id=\"7\"><\/a>\n# <p style=\"background-color:#47b7ed;font-family:newtimeroman;color:#000000;font-size:120%;text-align:center;border-radius:20px 80px;\"> \ud83d\udc31\u200d\ud83c\udfcdFeature Engineering \ud83e\uddd0<\/p>\n","4d3de28f":"<a id=\"7.4\"><\/a>\n# <p style=\"background-color:#47b7ed;font-family:newtimeroman;color:#000000;font-size:120%;text-align:center;border-radius:20px 80px;\"> \ud83d\udc31\u200d\ud83c\udfcdScaling the features \ud83e\uddd0<\/p>\n","62c9b63a":"<b>no duplicated rows !!!","859b2c62":"<a id=\"9\"><\/a>\n# <p style=\"background-color:#47b7ed;font-family:newtimeroman;color:#000000;font-size:120%;text-align:center;border-radius:20px 80px;\">\ud83e\uddee Models Score<\/p>","5420477f":" <a id='top'><\/a>\n <div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h1 style=\"background-color:#47b7ed;font-family:newtimeroman;color:#000000;font-size:170%;text-align:center;border-radius:20px 80px;\">\ud83d\udccb Dataset information<\/h1>   ","85a5a546":"<a id=\"11\"><\/a>\n# <p style=\"background-color:#47b7ed;font-family:newtimeroman;color:#000000;font-size:120%;text-align:center;border-radius:20px 80px;\"> \ud83c\udf08Thank you \ud83c\udf83 Happy kaggling\ud83d\udc45\ud83d\udc45 <\/p>","436bd26e":"<a id=\"3\"><\/a>\n# <p style=\"background-color:#47b7ed;font-family:newtimeroman;color:#000000;font-size:120%;text-align:center;border-radius:20px 80px;\">\ud83d\udcdd Missing values and Duplicated rowa<\/p>\n\u200b","15269247":"<b> For our purpose we divided this part into 3 group:\n    \n1.Analysis the numerical col \ud83e\udd84\n       \n2.Anaysis the categorical col \ud83d\udc7e      \n3.Analysis the terget col  \ud83e\udd21","7d0a0faf":"<b>RestingECG: resting electrocardiogram results don't differ much.","711d4e43":"<a id=\"6.3\"><\/a>\n# <p style=\"background-color:#47b7ed;font-family:newtimeroman;color:#000000;font-size:120%;text-align:center;border-radius:20px 80px;\">\ud83d\udc7b Categorical EDA<\/p>\n","f076f7fd":"<b> Oh no ,male suffer in heart disease at 2 time more than woman \ud83d\ude16","5cc3c36b":"<b> we encode our categorical columns into numerical columns , great !!!!","e090b74d":"    \n* [1. Importing Libraries](#1)\n    \n* [2. Meta information of dataframe](#2)\n    \n* [3.Missing values and duplicated rows](#3)\n    \n* [4.Statistical information of Dataframe](#4) \n\n* [5.Visualize correlation of independent features and check multicolinarity problems](#5)\n    \n* [6. EDA & Visualization](#6)\n\n    * [6.1. Numerical EDA](#6.1)\n    \n    * [6.2. Terget EDA](#6.2)\n    \n    * [6.3. Categorical EDA](#6.3)\n        \n* [6. Preprocess data for Machine Learning](#6)\n    \n* [7. \ud83c\udfcdFeature Engineering](#7)\n\n    * [7.1.\ud83c\udfcdNormalized skewed col](#7.1)\n    \n    * [7.2.\ud83c\udfcdNormalized skewed col](#7.2)\n       \n    * [7.3. One-Hot Encoding](#7.3)\n       \n    * [7.4. Scaling Features](#7.4)\n    \n\n* [8. Create & Train Model](#8)\n\n* [9. Models Score](#9)\n\n* [10. Visualize Models Score](#10)\n\n* [11. Plot Confusion Matrix for best 2 models](#11)\n\n\n\n\n\n\n\n\n\n\n    ","b7474b3a":"<b>ST_Slope Up significantly less likely has heart disease than the other two segment."}}