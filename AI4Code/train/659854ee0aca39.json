{"cell_type":{"f57d1b1b":"code","dc6a104c":"code","1279231d":"code","22310184":"code","f891449b":"code","1eec0334":"code","92914cfe":"code","19cb2bb4":"code","d32c8b2f":"code","24a3d863":"code","bd3d3cf9":"code","ff2c5182":"code","28ff000a":"code","11082187":"code","a0d95ec5":"code","47689345":"code","3bdbdb84":"code","b909fcc5":"code","1c6021ca":"code","d120d76d":"code","c69a6a37":"code","af5acc3e":"code","ac4e0843":"code","db812205":"code","99411ea9":"code","91d5764d":"code","c014ae68":"code","8a69f1de":"code","3f721d0c":"code","7dff51f2":"code","2e258494":"markdown","a635ca0f":"markdown","438fd656":"markdown","ef44bad9":"markdown","2e29a98a":"markdown","ab56848b":"markdown","df25e5d8":"markdown","a1c62016":"markdown","56a3651c":"markdown"},"source":{"f57d1b1b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,Dropout,BatchNormalization\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dc6a104c":"filepath_train = '\/kaggle\/input\/sign-language-mnist\/sign_mnist_train\/sign_mnist_train.csv'\nfilepath_test = '\/kaggle\/input\/sign-language-mnist\/sign_mnist_test\/sign_mnist_test.csv'\n\ndef import_data(filepath):\n    \n    X = pd.read_csv(filepath).drop('label',axis= 1)\n    y = pd.read_csv(filepath).loc[:,'label']\n    \n    return (np.array(X), np.array(y))\n\nX_train,y_train = import_data(filepath_train)\nX_test,y_test = import_data(filepath_test)","1279231d":"y_train.shape","22310184":"X_test.shape","f891449b":"X_train.shape","1eec0334":"X_train.shape[0] ","92914cfe":"np.unique(y_train)","19cb2bb4":"#we want the labels ordered from 0 to 23 \n# since 9,25 is missing \nfor i in range(10,25,1):\n    y_train[y_train == i] = i-1\n    y_test[y_test == i] = i-1","d32c8b2f":"y_train.shape","24a3d863":"np.unique(y_train)","bd3d3cf9":"plt.figure(figsize = (30,15))\n\nplt.xticks(size=30)\nsns.countplot(y_train,linewidth = 3,edgecolor=sns.color_palette(\"Set2\"))\nplt.title('Partition of label in the train dataset', fontdict={'color' : 'Black' , 'fontsize' : 30})\n\nplt.show()","ff2c5182":"num_letters = {0 : 'A' , 1 : 'B', 2 : 'C' , 3 : 'D', 4: 'E' , 5 : 'F',\n                     6 : 'G' , 7 : 'H' , 8 : 'I' , 9 : 'K' , \n                     10 : 'L' , 11 :'M' , 12 : 'N' , 13 : 'O' , 14 : 'P',\n                     15 : 'Q' , 16 : 'R' , 17 : 'S' , 18 :'T' , 19 : 'U',\n                     20 : 'V' , 21 :'W' , 22 : 'X', 23 : 'Y'}","28ff000a":"L = 6\nW = 6 \nfig, axes = plt.subplots(L, W, figsize = (12,12))\naxes = axes.ravel()\n\nfor i in range(0, L * W):  \n    axes[i].imshow(X_test[i].reshape(28,28),cmap='gray')\n    axes[i].set_title(\"True Sign = \"+str(num_letters[y_test[i]]))\n    axes[i].axis('off')\nplt.subplots_adjust(wspace=0.5)","11082187":"print('Shape of X_train : {} , Shape of X_test : {}' .format(X_train.shape,X_test.shape))\nprint('Shape of y_train : {} , Shape of y_test : {}' .format(y_train.shape,y_test.shape))","a0d95ec5":"# since X_train[i] data is of shape (784,)  reshape image to 28,28\nX_train = X_train.reshape(X_train.shape[0],28,28,1)\nX_test = X_test.reshape(X_test.shape[0],28,28,1)\n\n\ny_train = tf.keras.utils.to_categorical(y_train)\ny_test = tf.keras.utils.to_categorical(y_test)\n\nX_train.shape","47689345":"# Normalize pixel values to be between 0 and 1\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(rescale=(1.\/255))","3bdbdb84":"model = Sequential()\nmodel.add(Conv2D(filters = 32,kernel_size = (3,3),activation = 'relu',input_shape = (28,28,1)))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(filters = 32,kernel_size = (3,3),activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D((2,2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters = 64,kernel_size = (3,3),activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D((2,2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters = 128,kernel_size = (3,3),activation = 'relu'))\nmodel.add(MaxPooling2D((2,2)))","b909fcc5":"model.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(24,activation='softmax')) \nmodel.summary()","1c6021ca":"X_train.shape","d120d76d":"model.compile(optimizer='adam' ,metrics = ['accuracy'],loss = 'categorical_crossentropy')\n\nhistory=model.fit_generator(datagen.flow(X_train, y_train),steps_per_epoch=21964\/\/128,epochs=50,validation_data=(X_test, y_test),validation_steps=5491\/\/128, use_multiprocessing=True)","c69a6a37":"loss, acc = model.evaluate(X_test, y_test)\nprint(\"model accuracy : {}%\".format(acc*100))","af5acc3e":"#Visualizing the training performance\nplt.figure(figsize=(12, 8))\n\nplt.subplot(2, 2, 1)\nplt.plot(history.history['loss'], label='Loss')\nplt.plot(history.history['val_loss'], label='val_Loss')\n\nplt.legend()\nplt.grid()\nplt.title('Loss evolution')\n\nplt.subplot(2, 2, 2)\nplt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label='val_accuracy')\nplt.legend()\nplt.grid()\nplt.title('Accuracy evolution')","ac4e0843":"# we are going to use data generator to train the CNN\ntrain_datagen = ImageDataGenerator(rescale=1.\/255 ,\n                                   rotation_range = 40,\n                                   horizontal_flip=True,\n                                   zoom_range=0.2,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   fill_mode = 'nearest')\nX_test = X_test\/255","db812205":"model = Sequential()\n\nmodel.add(Conv2D(filters = 256,kernel_size = (5,5),padding = 'same',activation = 'relu',input_shape = (28,28,1)))\nmodel.add(MaxPooling2D())\nmodel.add(Conv2D(filters = 128,kernel_size = (5,5),padding = 'same',activation = 'relu'))\nmodel.add(MaxPooling2D())\nmodel.add(Conv2D(filters = 64,kernel_size = (5,5),padding = 'same',activation = 'relu'))\nmodel.add(MaxPooling2D())\nmodel.add(Conv2D(filters = 32,kernel_size = (5,5),padding = 'same',activation = 'relu'))\n\n\nmodel.add(Flatten())\n\nmodel.add(Dense(units = 256,activation = 'relu'))\nmodel.add(Dense(units = 128,activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(24,activation = 'softmax'))\n\nmodel.summary()","99411ea9":"model.compile(optimizer='adam',metrics = ['accuracy'],loss = 'categorical_crossentropy')\nhistory = model.fit(train_datagen.flow(X_train,y_train,batch_size = 300),validation_data=(X_test,y_test),epochs = 50)","91d5764d":"#Visualizing the training performance\nplt.figure(figsize=(12, 8))\n\nplt.subplot(2, 2, 1)\nplt.plot(history.history['loss'], label='Loss')\nplt.plot(history.history['val_loss'], label='val_Loss')\n\nplt.legend()\nplt.grid()\nplt.title('Loss evolution')\n\nplt.subplot(2, 2, 2)\nplt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label='val_accuracy')\nplt.legend()\nplt.grid()\nplt.title('Accuracy evolution')","c014ae68":"loss, acc = model.evaluate(X_test, y_test)\nprint(\"model accuracy : {}%\".format(acc*100))","8a69f1de":"y_pred = model.predict(X_test)\n\ny_pred2 = np.array([np.argmax(y_pred[i]) for i in range(len(y_pred))])\ny_test2 = np.array([np.argmax(y_test[i]) for i in range(len(y_test))])","3f721d0c":"L = 6\nW = 2\nfig, axes = plt.subplots(L, W, figsize = (12,12))\naxes = axes.ravel()\n\nfor i in np.arange(0, L * W):  \n    axes[i].imshow(X_test[i],cmap='gray')\n    axes[i].set_title('True : {} , Predicted : {} with {} % of accuracy '.format(num_letters[y_test2[i]],\n                                                                            num_letters[y_pred2[i]],\n                                                                            round(y_pred[i][y_pred2[i]]*100,2)\n                                                                            ))\n    axes[i].axis('off')\nplt.subplots_adjust(wspace=0.5)","7dff51f2":"for indx, char in num_letters.items():\n    x, y = [] , []\n    for i in range(len(X_test)): \n        if y_test2[i] == indx :\n            x.append(X_test[i])\n            y.append(y_test[i])\n    x = np.array(x)\n    y = np.array(y)\n    print(\"number of images for {} : {}\".format(char,len(y)))\n    loss, acc = model.evaluate(x,y)\n    print(\"accuracy for {} : {} %\".format(char, acc*100))\n    print()\n                ","2e258494":"# Thank You !","a635ca0f":"# Preprocessing","438fd656":"# Prediction for each class","ef44bad9":"# Importing data","2e29a98a":"# Data Visualization","ab56848b":"## Architecture Referred from [Research Paper](http:\/\/link.springer.com.library.somaiya.edu\/chapter\/10.1007\/978-981-15-7961-5_6)","df25e5d8":"---\n## Name : Pathik Prashant Ghugare\n## Roll No : 1911014\n## Div : A\n## Topic : CNN model for American Sign Language Recognition\n---","a1c62016":"## Architecture Referred from [Kaggle](https:\/\/www.kaggle.com\/chemamasamuel\/cnn-for-beginner-tensorflow-keras-99-accuracy\/data)","56a3651c":"![image.png](attachment:9049ee21-5f0a-4de4-9f34-e139bd585622.png)"}}