{"cell_type":{"d7e6d893":"code","25036b2d":"code","2c7aee70":"code","24affe00":"code","67db5614":"code","519d2939":"code","8fded9d5":"code","605c7a3d":"code","cba8f549":"code","da57aca6":"code","188585d3":"code","4fa1837c":"code","2cd7622c":"code","66af82d8":"code","ea09db55":"code","e39cbf15":"code","16f48ab9":"code","1885408c":"code","01eb4559":"code","d7629362":"code","88bef231":"markdown","bae223ff":"markdown","9a6201ee":"markdown","3b540e29":"markdown"},"source":{"d7e6d893":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport cv2\nfrom skimage.io import imread\nfrom skimage.feature import greycomatrix, greycoprops\nfrom skimage.transform import resize\nfrom multiprocessing import Pool\nimport random\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport tqdm\nfrom sklearn.model_selection import train_test_split","25036b2d":"from keras.layers import *\nfrom keras.models import Model,Sequential\nimport keras.backend as K\nfrom keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\nfrom keras.optimizers import Adam\nimport tensorflow as tf\n","2c7aee70":"IMG_ROW=IMG_COL=32\nIMG_CHANNEL=3\nTRAIN_IMG_DIR='..\/input\/train\/images\/'\nTRAIN_MASK_DIR='..\/input\/train\/masks\/'\nimgidlist=os.listdir(TRAIN_IMG_DIR)\nmaskidlist=os.listdir(TRAIN_MASK_DIR)","24affe00":"train_img_list,valid_img_list,train_mask_list,valid_mask_list=train_test_split(imgidlist,maskidlist,\n                                                                             test_size=0.01)","67db5614":"def glcm_props(patch):\n    lf = []\n    props = ['dissimilarity', 'contrast', 'homogeneity', 'energy', 'correlation']\n\n    # left nearest neighbor\n    glcm = greycomatrix(patch, [1], [0], 256, symmetric=True, normed=True)\n    for f in props:\n        lf.append( greycoprops(glcm, f)[0,0] )\n\n    # upper nearest neighbor\n    glcm = greycomatrix(patch, [1], [np.pi\/2], 256, symmetric=True, normed=True)\n    for f in props:\n        lf.append( greycoprops(glcm, f)[0,0] )\n        \n    return lf\n\ndef patch_gen(img, PAD=4):\n    img1 = (img * 255).astype(np.uint8)\n\n    W = 101\n    imgx = np.zeros((101+PAD*2, 101+PAD*2), dtype=img1.dtype)\n    imgx[PAD:W+PAD,PAD:W+PAD] = img1\n    imgx[:PAD,  PAD:W+PAD] = img1[PAD:0:-1,:]\n    imgx[-PAD:, PAD:W+PAD] = img1[W-1:-PAD-1:-1,:]\n    imgx[:, :PAD ] = imgx[:, PAD*2:PAD:-1]\n    imgx[:, -PAD:] = imgx[:, W+PAD-1:-PAD*2-1:-1]\n\n    xx, yy = np.meshgrid(np.arange(0, W), np.arange(0, W))\n    xx, yy = xx.flatten() + PAD, yy.flatten() + PAD\n\n    for x, y in zip(xx, yy):\n        patch = imgx[y-PAD:y+PAD+1, x-PAD:x+PAD+1]\n        yield patch\n\ndef glcm_feature(img, verbose=False):\n    \n    W, NF, PAD = 101, 10, 4\n\n    if img.sum() == 0:\n        return np.zeros((W,W,NF), dtype=np.float32)\n    \n    l = []\n    with Pool(3) as pool:\n        for p in tqdm.tqdm(pool.imap(glcm_props, patch_gen(img, PAD)), total=W*W, disable=not verbose):\n            l.append(p)\n        \n    fimg = np.array(l, dtype=np.float32).reshape(101, 101, -1)\n    \n    return fimg\n","519d2939":"def read_image(imgpath):\n    img=imread(imgpath).astype(np.uint8)\n    img1=imread(imgpath)[...,0].astype(np.float32) \/ 255\n    return img,img1","8fded9d5":"def process_img(imgpath):\n    img,img_=read_image(imgpath)\n    fimg=glcm_feature(img_,verbose=0)\n    amin=np.amin(fimg,axis=(0,1))\n    amax=np.amax(fimg,axis=(0,1))\n    fimg=(fimg-amin)\/(amax-amin)\n    img1=np.power(fimg[...,4],3)\n    img2=np.power(fimg[...,9],3)\n    img1=resize(img1,(IMG_ROW,IMG_COL))\n    img2=resize(img2,(IMG_ROW,IMG_COL))\n    img1=transform_img(img1)\n    img2=transform_img(img2)\n    return img1,img2","605c7a3d":"def read_mask(maskpath):\n    mask=np.zeros((IMG_ROW,IMG_COL,1),\n                  dtype=np.bool)\n    mask_=imread(maskpath)\n    mask_=np.expand_dims(resize(mask_,(IMG_ROW,IMG_COL),\n                               mode='constant',preserve_range=True),\n                        axis=-1)\n    mask=np.maximum(mask,mask_)","cba8f549":"def transform_img(img):\n    img1=np.zeros((IMG_ROW,IMG_COL,IMG_CHANNEL))\n    for i in range(IMG_ROW):\n        for j in range(IMG_COL):\n            for k in range(IMG_CHANNEL):\n                img1[i][j][k]=img[i][j]\n    return img1","da57aca6":"def visual_glcm():\n    for i in range(10):\n        rndid=random.randint(0,len(imgidlist)-1)\n        img,img1=read_image(TRAIN_IMG_DIR+imgidlist[rndid])\n        mask,mask1=read_image(TRAIN_MASK_DIR+imgidlist[rndid])\n        _,(ax0,ax1,ax2,ax3)=plt.subplots(1,4,figsize=(6,2))\n        ax0.imshow(img)\n        ax1.imshow(mask)\n        fimg = glcm_feature(img1, verbose=0)\n        amin = np.amin(fimg, axis=(0,1))\n        amax = np.amax(fimg, axis=(0,1))\n        fimg = (fimg - amin) \/ (amax - amin)\n        fimg[...,4] = np.power(fimg[...,4], 3)\n        fimg[...,9] = np.power(fimg[...,9], 3)\n        img1=fimg[...,4]\n        img2=fimg[...,9]\n        img1=resize(img1,(IMG_ROW,IMG_COL))\n        img2=resize(img2,(IMG_ROW,IMG_COL))\n        img1=transform_img(img1)\n        img2=transform_img(img2)\n        print(img1.shape)\n        ax2.imshow(img1,cmap='seismic')\n        ax3.imshow(img2,cmap='seismic')","188585d3":"def train_gen(batch_size=128):\n    while(True):\n        imglist=np.zeros((batch_size,IMG_ROW,IMG_COL,IMG_CHANNEL))\n        masklist=np.zeros((batch_size,IMG_ROW,IMG_COL,1),dtype=np.bool)\n        for i in range(batch_size):\n            rnd_id=random.randint(0,len(train_img_list)-1)\n            imgpath=TRAIN_IMG_DIR+train_img_list[rnd_id]\n            maskpath=TRAIN_MASK_DIR+train_mask_list[rnd_id]\n            img1,img2=process_img(imgpath)\n            mask=read_mask(maskpath)\n            imglist[i]=img1\n            masklist[i]=mask\n        yield (imglist,masklist)\n        imglist=np.zeros((batch_size,IMG_ROW,IMG_COL,IMG_CHANNEL))\n        masklist=np.zeros((batch_size,IMG_ROW,IMG_COL,1),dtype=np.bool)","4fa1837c":"def valid_gen():\n    imglist=np.zeros((len(valid_img_list),IMG_ROW,IMG_COL,IMG_CHANNEL))\n    masklist=np.zeros((len(valid_img_list),IMG_ROW,IMG_COL,1),dtype=np.bool)\n    for i in range(len(valid_img_list)):\n        imgpath=TRAIN_IMG_DIR+valid_img_list[i]\n        maskpath=TRAIN_MASK_DIR+valid_mask_list[i]\n        img1,img2=process_img(imgpath)\n        mask=read_mask(maskpath)\n        imglist[i]=img1\n        masklist[i]=mask\n    return (imglist,masklist)","2cd7622c":"validdata=valid_gen()\n(validimglist,validmasklist)=validdata\nprint(validimglist.shape)\nprint(validmasklist.shape)","66af82d8":"visual_glcm()","ea09db55":"def double_conv_layer(x,size,dropout=0.0,batch_norm=True):\n    conv=Conv2D(size,(2,2),padding='same')(x)\n    if(batch_norm==True):\n        conv=BatchNormalization(axis=3)(conv)\n    conv=Activation('relu')(conv)\n    conv=Conv2D(size,(3,3),padding='same')(conv)\n    if(batch_norm==True):\n        conv=BatchNormalization(axis=3)(conv)\n    conv=Activation('relu')(conv)\n    if(dropout!=0.0):\n        conv=SpatialDropout(dropout)(conv)\n    return conv","e39cbf15":"def unet_model(filters):\n    inputs=Input((IMG_ROW,IMG_COL,IMG_CHANNEL))\n    conv1=double_conv_layer(inputs,filters)\n    p1=MaxPooling2D(pool_size=(2,2))(conv1)\n\n    conv2=double_conv_layer(p1,2*filters)\n    p2=MaxPooling2D(pool_size=(2,2))(conv2)\n\n    conv3=double_conv_layer(p2,4*filters)\n    p3=MaxPooling2D(pool_size=(2,2))(conv3)\n\n    conv4=double_conv_layer(p3,8*filters)\n    p4=MaxPooling2D(pool_size=(2,2))(conv4)\n\n    conv5=double_conv_layer(p4,32*filters)\n\n    up6=concatenate([UpSampling2D(size=(2,2))(conv5),conv4],axis=3)\n    conv6=double_conv_layer(up6,8*filters)\n\n    up7=concatenate([UpSampling2D(size=(2,2))(conv6),conv3],axis=3)\n    conv7=double_conv_layer(up7,4*filters)\n\n    up8=concatenate([UpSampling2D(size=(2,2))(conv7),conv2],axis=3)\n    conv8=double_conv_layer(up8,2*filters)\n\n    up9=concatenate([UpSampling2D(size=(2,2))(conv8),conv1],axis=3)\n    conv9=double_conv_layer(up9,filters,0)\n\n    convfinal=Conv2D(1,(1,1))(conv9)\n    convfinal=Activation('sigmoid')(convfinal)\n\n    model=Model(inputs,convfinal)\n    model.summary()\n    return model","16f48ab9":"model=unet_model(8)\n","1885408c":"def dice_coef(y_true,y_pred):\n    y_true_f=K.flatten(y_true)\n    y_pred_f=K.flatten(y_pred)\n    intersection=K.sum(y_true_f*y_pred_f)\n    return (2.0*intersection+1.0)\/(K.sum(y_true_f)+K.sum(y_pred_f)+1.0)\ndef dice_coef_loss(y_true,y_pred):\n    return -dice_coef(y_true,y_pred)\ndef mean_iou(y_true, y_pred):\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        y_pred_ = tf.to_int32(y_pred > t)\n        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n        K.get_session().run(tf.local_variables_initializer())\n        with tf.control_dependencies([up_opt]):\n            score = tf.identity(score)\n        prec.append(score)\n    return K.mean(K.stack(prec), axis=0)","01eb4559":"model.compile(Adam(lr=0.001),metrics=[mean_iou],loss=dice_coef_loss)","d7629362":"callbacks=[\n    ReduceLROnPlateau(monitor='val_loss',patience=3,min_lr=1e-9,verbose=1,mode='min'),\n    ModelCheckpoint('salt_model.h5',monitor='val_loss',save_best_only=True,verbose=1)\n]","88bef231":"history=model.fit_generator(train_gen(),steps_per_epoch=50,\n                            epochs=15,\n                            validation_data=validdata,\n                            callbacks=callbacks)","bae223ff":"plt.plot(history.history['mean_iou'])\nplt.plot(history.history['val_mean_iou'])\nplt.legend(['train','valid'])","9a6201ee":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['train','valid'])","3b540e29":"Reference:\nhttps:\/\/www.kaggle.com\/zeemeen\/glcm-texture-features\/notebook"}}