{"cell_type":{"1c525ff4":"code","93a7920a":"code","5e353f31":"code","ff289022":"code","3d5d6946":"code","fe439d40":"code","626c7a38":"code","a896e682":"code","a17829a6":"code","6fd44752":"code","e284d6bb":"code","5dd12b63":"code","fe7cb8cd":"code","d5104fd3":"code","ac817cc4":"code","dce4ec83":"code","0b4f1c8a":"code","2f760a01":"code","97a01547":"code","438cc5b9":"code","98f85b10":"code","de4441b5":"code","6fe5faa4":"code","c1fcca4a":"code","8c9d0f85":"code","b40a928b":"code","34c58449":"code","05d7cc2b":"code","57942ee7":"code","96f6e6d5":"code","9dfe9331":"code","9976d4bf":"code","bb9c038d":"markdown","9a12600d":"markdown","5a09ab73":"markdown"},"source":{"1c525ff4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","93a7920a":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","5e353f31":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","ff289022":"%matplotlib inline\nimport matplotlib.pyplot as plt","3d5d6946":"cols = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Ticket\", \"Name\", \"Fare\", \"Cabin\", \"Embarked\"]","fe439d40":"def survival_rate_plot(col, target, data):\n    counts = (data[[target, col]]\n                  .groupby([target, col])\n                  .size()\n                  .unstack(target)\n             )\n    group_counts = counts.sum(axis='columns')\n    props = counts.div(group_counts, axis='index')\n\n    ax = props.plot(kind=\"barh\", stacked=True)\n    ax.invert_yaxis()\n    ax.legend(\n      loc='center left', \n      bbox_to_anchor=(1.05, 0.5)\n    )","626c7a38":"cols_to_plot = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Embarked\"]\n\nfor col in (cols_to_plot):\n    survival_rate_plot(\n        col, 'Survived', train_data\n    )","a896e682":"import seaborn as sns\nplt.figure(figsize=(12,8))\nsns.heatmap(train_data.corr(), annot=True)","a17829a6":"for col in cols:\n  print(col+\" : \" + str(train_data[col].nunique()) + \" unique values\")\n  print(train_data[col].unique())\n  print()","6fd44752":"for col in cols:\n    print(col)\n    print(\"Train Data \" + str(train_data[col].isna().sum()))\n    print()\n    print(\"Test Data \" + str(train_data[col].isna().sum()))\n    print()\n    print(\"=====================\")","e284d6bb":"final_data = train_data.copy()\ntest = test_data.copy()","5dd12b63":"final_data['Cabin'] = final_data[\"Cabin\"].fillna(\"None\")\ntest_data['Cabin'] = test_data[\"Cabin\"].fillna(\"None\")\n\nfinal_data['Ticket'] = final_data[\"Ticket\"].fillna(\"None\")\ntest_data['Ticket'] = test_data[\"Ticket\"].fillna(\"None\")","fe7cb8cd":"numeric_cols = ['Age','Fare']\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nfor cols in numeric_cols:\n    final_data[cols] = imputer.fit_transform(train_data[cols].values.reshape(-1,1))[:,0]\n    test_data[cols] = imputer.fit_transform(test_data[cols].values.reshape(-1,1))[:,0]\n","d5104fd3":"object_cols = ['Embarked',\"Pclass\", \"Sex\",\"SibSp\", \"Parch\" ]\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\nfor cols in object_cols:\n    final_data[cols] = imputer.fit_transform(train_data[cols].values.reshape(-1,1))[:,0]\n    test_data[cols] = imputer.fit_transform(test_data[cols].values.reshape(-1,1))[:,0]","ac817cc4":"final_data['Cabin_Letter'] = final_data['Cabin'].apply(lambda x: str(x)[0])\ntest_data['Cabin_Letter'] = test_data['Cabin'].apply(lambda x: str(x)[0])","dce4ec83":"final_data['Ticket_Lett'] = final_data['Ticket'].apply(lambda x: str(x)[0])\ntest_data['Ticket_Lett'] = test_data['Ticket'].apply(lambda x: str(x)[0])","0b4f1c8a":"final_data['Cabin_Letter'].unique()","2f760a01":"final_data['Ticket_Lett'].unique()","97a01547":"# Encoding above ordinal data using OrdinalEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\n\nsub_categories =[\n    ['Male', \"Female\"], \n    [\"S\", \"C\", \"Q\"],\n    ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'N', 'T']\n]\n\ncategory = ['Sex', 'Embarked', 'Cabin_Letter']\n\nfor i in range(len(category)):\n    categories_poverty = pd.Categorical(final_data[category[i]], categories= sub_categories[i], ordered=True)\n    labels, unique = pd.factorize(categories_poverty, sort=True)\n    final_data[category[i]] = labels\n    \n    categories_poverty = pd.Categorical(test_data[category[i]], categories= sub_categories[i], ordered=True)\n    labels, unique = pd.factorize(categories_poverty, sort=True)\n    test_data[category[i]] = labels\n\n\nordinalencoder = OrdinalEncoder()\nfinal_data['Cabin'] = ordinalencoder.fit_transform(final_data[['Cabin']])\ntest_data['Cabin'] = ordinalencoder.fit_transform(test_data[['Cabin']])\n\nfinal_data['Ticket_Lett'] = ordinalencoder.fit_transform(final_data[['Ticket_Lett']])\ntest_data['Ticket_Lett'] = ordinalencoder.fit_transform(test_data[['Ticket_Lett']])\n\nfinal_data['Ticket'] = ordinalencoder.fit_transform(final_data[['Ticket']])\ntest_data['Ticket'] = ordinalencoder.fit_transform(test_data[['Ticket']])","438cc5b9":"final_data = final_data.drop(columns=['Name', 'PassengerId'])\ntest_data = test_data.drop(columns=['Name', 'PassengerId'])","98f85b10":"final_data.info()","de4441b5":"cols = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Cabin\", \"Embarked\"]\nfor col in cols:\n    print(col)\n    print(final_data[col].value_counts())\n    print()","6fe5faa4":"from sklearn.feature_selection import mutual_info_classif\n\n\ndef make_mi_scores(X, y):\n    X = X.copy()\n    for colname in X.select_dtypes([\"object\", \"category\"]):\n        X[colname], _ = X[colname].factorize()\n    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n    mi_scores = mutual_info_classif(X, y, discrete_features=discrete_features, random_state=0)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\n\ndef plot_mi_scores(scores):\n    scores = scores.sort_values(ascending=True)\n    width = np.arange(len(scores))\n    ticks = list(scores.index)\n    plt.barh(width, scores)\n    plt.yticks(width, ticks)\n    plt.title(\"Mutual Information Scores\")","c1fcca4a":"X = final_data.copy()\ny = X.pop(\"Survived\")\n\nmi_scores = make_mi_scores(X, y)\nmi_scores","8c9d0f85":"relations_aboard = ['Parch', 'SibSp']\nfinal_data[\"relations_aboard\"] = final_data[relations_aboard].sum(axis=1)\ntest_data[\"relations_aboard\"] = test_data[relations_aboard].sum(axis=1)\n\n","b40a928b":"final_data[\"Average_Fare_Pclass\"] = final_data.groupby(\"Pclass\")[\"Fare\"].transform(\"mean\")\ntest_data[\"Average_Fare_Pclass\"] = test_data.groupby(\"Pclass\")[\"Fare\"].transform(\"mean\")","34c58449":"y = final_data[\"Survived\"]\nfinal_data = final_data.drop(columns = 'Survived')","05d7cc2b":"final_data.info()","57942ee7":"test_data.info()","96f6e6d5":"test.info()","9dfe9331":"y","9976d4bf":"from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(final_data, y)\npredictions = model.predict(test_data)\n\noutput = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","bb9c038d":"# **Feature Engineering**","9a12600d":"# **Exploratory Data Analysis**","5a09ab73":"# **Data Pre-processing**"}}