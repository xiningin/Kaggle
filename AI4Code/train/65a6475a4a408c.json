{"cell_type":{"5079786c":"code","94b6eac1":"code","d8e71b74":"code","acd03f43":"code","cc2a8d58":"code","9a46ebfb":"code","6625a855":"code","0e31753e":"code","542866e5":"code","e2a37ef4":"code","c8421f8a":"code","440b6f4e":"markdown","be4e8a55":"markdown","63028929":"markdown","9d94ba61":"markdown","eb3997d7":"markdown"},"source":{"5079786c":"# Import necessary libraries\nfrom copy import deepcopy\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt","94b6eac1":"# Set three centers, the model should predict similar results\ncenter_1 = np.array([1,1])\ncenter_2 = np.array([5,5])\ncenter_3 = np.array([8,1])\n\n# Generate random data and center it to the three centers\ndata_1 = np.random.randn(200, 2) + center_1\ndata_2 = np.random.randn(200,2) + center_2\ndata_3 = np.random.randn(200,2) + center_3\n\ndata = np.concatenate((data_1, data_2, data_3), axis = 0)\n\nplt.scatter(data[:,0], data[:,1], s=7)","d8e71b74":"# Number of clusters\nk = 3\n# Number of training data\nn = data.shape[0]\n# Number of features in the data\nc = data.shape[1]\n\n# Generate random centers, here we use sigma and mean to ensure it represent the whole data\nmean = np.mean(data, axis = 0)\nstd = np.std(data, axis = 0)\ncenters = np.random.randn(k,c)*std + mean\n\n# Plot the data and the centers generated as random\nplt.scatter(data[:,0], data[:,1], s=7)\nplt.scatter(centers[:,0], centers[:,1], marker='*', c='g', s=150)","acd03f43":"centers_old = np.zeros(centers.shape) # to store old centers\ncenters_new = deepcopy(centers) # Store new centers\n\ndata.shape\nclusters = np.zeros(n)\ndistances = np.zeros((n,k))\n\nerror = np.linalg.norm(centers_new - centers_old)\n\n# When, after an update, the estimate of that center stays the same, exit loop\nwhile error != 0:\n    # Measure the distance to every center\n    for i in range(k):\n        distances[:,i] = np.linalg.norm(data - centers[i], axis=1)\n    # Assign all training data to closest center\n    clusters = np.argmin(distances, axis = 1)\n    \n    centers_old = deepcopy(centers_new)\n    # Calculate mean for every cluster and update the center\n    for i in range(k):\n        centers_new[i] = np.mean(data[clusters == i], axis=0)\n    error = np.linalg.norm(centers_new - centers_old)\ncenters_new    ","cc2a8d58":"# Plot the data and the centers generated as random\nplt.scatter(data[:,0], data[:,1], s=7)\nplt.scatter(centers_new[:,0], centers_new[:,1], marker='*', c='g', s=150)","9a46ebfb":"df = pd.read_csv(\"..\/input\/Iris.csv\") #load the dataset\ndf.drop('Id',axis=1,inplace=True) # Se elimina la columna no requerida","6625a855":"df.head()","0e31753e":"# Change categorical data to number 0-2\ndf[\"Species\"] = pd.Categorical(df[\"Species\"])\ndf[\"Species\"] = df[\"Species\"].cat.codes\n# Change dataframe to numpy matrix\ndata = df.values[:, 0:4]\ncategory = df.values[:, 4]","542866e5":"# Number of clusters\nk = 3\n# Number of training data\nn = data.shape[0]\n# Number of features in the data\nc = data.shape[1]\n\n# Generate random centers, here we use sigma and mean to ensure it represent the whole data\nmean = np.mean(data, axis = 0)\nstd = np.std(data, axis = 0)\ncenters = np.random.randn(k,c)*std + mean\n\n# Plot the data and the centers generated as random\ncolors=['orange', 'blue', 'green']\nfor i in range(n):\n    plt.scatter(data[i, 0], data[i,1], s=7, color = colors[int(category[i])])\nplt.scatter(centers[:,0], centers[:,1], marker='*', c='g', s=150)","e2a37ef4":"centers_old = np.zeros(centers.shape) # to store old centers\ncenters_new = deepcopy(centers) # Store new centers\n\ndata.shape\nclusters = np.zeros(n)\ndistances = np.zeros((n,k))\n\nerror = np.linalg.norm(centers_new - centers_old)\n\n# When, after an update, the estimate of that center stays the same, exit loop\nwhile error != 0:\n    # Measure the distance to every center\n    for i in range(k):\n        distances[:,i] = np.linalg.norm(data - centers[i], axis=1)\n    # Assign all training data to closest center\n    clusters = np.argmin(distances, axis = 1)\n    \n    centers_old = deepcopy(centers_new)\n    # Calculate mean for every cluster and update the center\n    for i in range(k):\n        centers_new[i] = np.mean(data[clusters == i], axis=0)\n    error = np.linalg.norm(centers_new - centers_old)\ncenters_new    ","c8421f8a":"# Plot the data and the centers generated as random\ncolors=['orange', 'blue', 'green']\nfor i in range(n):\n    plt.scatter(data[i, 0], data[i,1], s=7, color = colors[int(category[i])])\nplt.scatter(centers_new[:,0], centers_new[:,1], marker='*', c='g', s=150)","440b6f4e":"# Test on Iris Dataset","be4e8a55":"# K-Means Clustering\nThis work is based on Mubaris' great work (\nhttps:\/\/mubaris.com\/2017\/10\/01\/kmeans-clustering-in-python\/).\n\nA description of the algorithm can be found:\nhttps:\/\/github.com\/andrewxiechina\/DataScience\/blob\/master\/K-Means\/cs229-notes7a%202.pdf\n\n![](https:\/\/github.com\/andrewxiechina\/DataScience\/blob\/master\/K-Means\/k4XcapI.gif?raw=true)","63028929":"# Create K-Means Algorithm\nGenerate random data normally distributed around 3 centers, with a noise.","9d94ba61":"# Generate Random Data\nGenerate random data normally distributed around 3 centers, with a noise.","eb3997d7":"# hello there! prasad kevin here , i hope u enjoy this kernal"}}