{"cell_type":{"e69d2472":"code","cc686dbc":"code","7f6b1f16":"code","54a27b07":"code","aec3088b":"code","0fb9c0e4":"code","3bac2a02":"code","ccef34e5":"code","fd42ee02":"code","79f588ea":"code","feab0256":"code","e70e34b2":"code","47a83a99":"code","6983f0b9":"code","80b6be14":"code","53007782":"code","3b0bc08f":"code","86541669":"code","fd1e6ec9":"code","543f64f8":"code","c4dc27f6":"code","df53335c":"code","db247ab9":"code","51e9d9ba":"code","b836dd02":"code","f6c4e522":"code","bc22e5f9":"code","51e774be":"code","15a398ac":"code","d58b4bba":"code","ff990838":"code","a76a5839":"code","af453eea":"code","4d0bdbf1":"code","320b6ecf":"code","7fdce8f7":"code","c49141ae":"code","bbb63961":"code","b2b5450c":"code","873cc86f":"code","0062e0aa":"code","09774f2e":"code","5ff925ee":"code","be64ffb8":"code","ffd9dccb":"code","0e02a015":"code","711d0f98":"code","65d0e914":"code","10a6103a":"code","647584af":"code","49e3bcd1":"code","4df2e8a9":"code","c96cb9dd":"code","c9e9fcc6":"code","c6ec71e9":"code","3d027202":"code","beefddd0":"code","5777f2b5":"code","efa5ee6b":"code","5e019510":"code","e751d419":"code","63111726":"code","66ae909f":"code","43338b5a":"code","32834c12":"code","8e1d6c45":"code","be95e3c8":"code","b679fbee":"code","18c3fd40":"code","f7ed82f9":"code","ebbf56f2":"code","2258233d":"code","932aa2e1":"code","a0042c6d":"code","4a249745":"code","76b6638a":"code","182c0116":"code","3ae65275":"code","d048de65":"code","47a878b6":"code","5a468933":"code","43d4f23d":"code","1cdd08e5":"code","283a0ba3":"code","efc5b5f0":"code","85c0e2d9":"code","1dce2000":"code","8d84d92b":"code","d3fcfa2a":"code","6a44af69":"code","5e31e823":"code","b915259a":"code","0cc26aec":"code","a4534127":"code","5a0d7fe9":"code","8e3b33d8":"code","21b1d670":"code","390fcf00":"code","f7016794":"code","f4539c36":"code","09978cbe":"code","65af37b2":"code","23201f6f":"code","a6bba1ec":"code","260a31fd":"code","384f8540":"code","26527c1e":"code","fdbacca4":"code","ac1e301e":"code","b01ba9cf":"markdown","3a32f789":"markdown","0a747f70":"markdown","aca8c95b":"markdown","34eb5aa7":"markdown","e1f22d5d":"markdown","84468b14":"markdown","a62dea72":"markdown","8412a0a8":"markdown","36b02647":"markdown","1aef8188":"markdown","d9cab423":"markdown","ed5f180f":"markdown","be36a76b":"markdown","088cef02":"markdown","a230f045":"markdown","9935d34c":"markdown","ae698bec":"markdown","0f89b305":"markdown","b882d14a":"markdown","63ad654f":"markdown","39356792":"markdown","e55ed234":"markdown","35000a7f":"markdown","aae8bf52":"markdown","a771102e":"markdown","90c6e08c":"markdown","a46810a5":"markdown","8c192cdb":"markdown","d78df32d":"markdown","a1c59ebc":"markdown","385d965f":"markdown","43c14aaf":"markdown","314be021":"markdown","44ae59dd":"markdown","1454c9e1":"markdown","411eddf0":"markdown","f43f6f87":"markdown","e12d8cd5":"markdown","b9c9e19e":"markdown","38cfa35d":"markdown","628b5642":"markdown","fbf5e85d":"markdown","6d08e167":"markdown"},"source":{"e69d2472":"import pandas as pd\nimport numpy as np\nimport scipy\nimport re\nimport string\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport scikitplot as skplt\nfrom wordcloud import WordCloud\n\n\nfrom sklearn.model_selection import train_test_split as split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report, confusion_matrix, auc, roc_curve\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer \nfrom nltk.stem import PorterStemmer, LancasterStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\n\nfrom textblob import TextBlob\nimport warnings\nwarnings.filterwarnings('ignore') \n\nfrom IPython.display import Image\n\n%matplotlib inline","cc686dbc":"df = pd.read_csv(\"..\/input\/womens-ecommerce-clothing-reviews\/Womens Clothing E-Commerce Reviews.csv\", index_col=0)\nprint(df.shape)\ndf.head(3)","7f6b1f16":"df.groupby(['Rating', 'Recommended IND'])['Recommended IND'].count()","54a27b07":"df.loc[(df.Rating==5) & (df['Recommended IND']==0)]['Review Text'].iloc[1]","aec3088b":"text_df = df[['Title', 'Review Text', 'Recommended IND']]\ntext_df.head()","0fb9c0e4":"text_df['Review'] = text_df['Title'] + ' ' + text_df['Review Text']\ntext_df = text_df.drop(labels=['Title','Review Text'] , axis=1)\ntext_df.head()","3bac2a02":"text_df.Review.isna().sum()","ccef34e5":"text_df = text_df[~text_df.Review.isna()]\ntext_df = text_df.rename(columns={\"Recommended IND\": \"Recommended\"})\nprint(\"My data's shape is:\", text_df.shape)\ntext_df.head()","fd42ee02":"text_df['Recommended'].unique()","79f588ea":"text_df['Recommended'].value_counts(normalize=True)","feab0256":"text_df['Review_length'] = text_df['Review'].apply(len)\nprint(text_df.shape)\ntext_df.head()","e70e34b2":"text_df['Review_length'].describe()","47a83a99":"sns.set(rc={'figure.figsize':(11,5)})\nsns.distplot(text_df['Review_length'] ,hist=True, bins=100)","6983f0b9":"df_zero = text_df[text_df['Recommended']==0]\ndf_one = text_df[text_df['Recommended']==1]","80b6be14":"sns.distplot(df_zero[['Review_length']] ,hist=False)\nsns.distplot(df_one[['Review_length']], hist=False)","53007782":"def count_exclamation_mark(string_text):\n    count = 0\n    for char in string_text:\n        if char == '!':\n            count += 1\n    return count","3b0bc08f":"text_df['count_exc'] = text_df['Review'].apply(count_exclamation_mark)\ntext_df.head(5)","86541669":"text_df['count_exc'].describe(np.arange(0.2, 1.0, 0.2))","fd1e6ec9":"text_df['count_exc'].value_counts().sort_index().plot(kind='bar')","543f64f8":"text_df[text_df['count_exc']== 41].index","c4dc27f6":"text_df['Review'][3301]","df53335c":"text_df['Polarity'] = text_df['Review'].apply(lambda x: TextBlob(x).sentiment.polarity)\ntext_df.head(5)","db247ab9":"text_df['Polarity'].plot(kind='hist', bins=100)","51e9d9ba":"text_prep = text_df.copy()","b836dd02":"string.punctuation","f6c4e522":"def punctuation_removal(messy_str):\n    clean_list = [char for char in messy_str if char not in string.punctuation]\n    clean_str = ''.join(clean_list)\n    return clean_str","bc22e5f9":"text_prep['Review'] = text_prep['Review'].apply(punctuation_removal)\ntext_prep['Review'].head()","51e774be":"Image(url= \"http:\/\/josecarilloforum.com\/imgs\/longnounphrase_schematic-1B.png\", width=600, height=10)","15a398ac":"def adj_collector(review_string):\n    new_string=[]\n    review_string = word_tokenize(review_string)\n    tup_word = nltk.pos_tag(review_string)\n    for tup in tup_word:\n        if 'VB' in tup[1] or tup[1]=='JJ':  #Verbs and Adjectives\n            new_string.append(tup[0])  \n    return ' '.join(new_string)","d58b4bba":"text_prep['Review'] = text_prep['Review'].apply(adj_collector)\ntext_prep['Review'].head(7)","ff990838":"print(stopwords.words('english')[::12])","a76a5839":"stop = stopwords.words('english')\nstop.append(\"i'm\")","af453eea":"stop_words = []\n\nfor item in stop: \n    new_item = punctuation_removal(item)\n    stop_words.append(new_item) \nprint(stop_words[::12])","4d0bdbf1":"clothes_list =['dress', 'top','sweater','shirt',\n               'skirt','material', 'white', 'black',\n              'jeans', 'fabric', 'color','order', 'wear']","320b6ecf":"def stopwords_removal(messy_str):\n    messy_str = word_tokenize(messy_str)\n    return [word.lower() for word in messy_str \n            if word.lower() not in stop_words and word.lower() not in clothes_list ]","7fdce8f7":"text_prep['Review'] = text_prep['Review'].apply(stopwords_removal)\ntext_prep['Review'].head()","c49141ae":"print(text_prep['Review'][3301])\n\n#'Beautiful and unique. Love this top, just received it today.\n# \\nit is a very artistic interpretation for a casual top.\n# \\nthe blue is gorgeous!\n# \\nthe unique style of the peplm and the details on the front set this apart!\n# \\nruns a little shorter, but i feel the length enhances it;s beauty, and is appropriate for the overall design.\n# \\nlove !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\nordered my usual size and it fits perfectly.'","bbb63961":"print(text_prep['Review'][267]) ","b2b5450c":"def drop_numbers(list_text):\n    list_text_new = []\n    for i in list_text:\n        if not re.search('\\d', i):\n            list_text_new.append(i)\n    return ' '.join(list_text_new)","873cc86f":"text_prep['Review'] = text_prep['Review'].apply(drop_numbers)\ntext_prep['Review'].head()","0062e0aa":"print(text_prep['Review'][267]) ","09774f2e":"print(text_prep['Review'][2293])","5ff925ee":"porter = PorterStemmer()","be64ffb8":"text_prep['Review'] = text_prep['Review'].apply(lambda x: x.split())\ntext_prep['Review'].head()","ffd9dccb":"def stem_update(text_list):\n    text_list_new = []\n    for word in text_list:\n        word = porter.stem(word)\n        text_list_new.append(word) \n    return text_list_new","0e02a015":"text_prep['Review'] = text_prep['Review'].apply(stem_update)\ntext_prep['Review'].head()","711d0f98":"text_prep['Review'] = text_prep['Review'].apply(lambda x: ' '.join(x))\ntext_prep['Review'].head()","65d0e914":"print(text_prep['Review'][2293])","10a6103a":"pos_df = text_prep[text_prep.Recommended== 1]\nneg_df = text_prep[text_prep.Recommended== 0]\npos_df.head(3)","647584af":"pos_words =[]\nneg_words = []\n\nfor review in pos_df.Review:\n    pos_words.append(review) \npos_words = ' '.join(pos_words)\npos_words[:40]\n\nfor review in neg_df.Review:\n    neg_words.append(review)\nneg_words = ' '.join(neg_words)\nneg_words[:400]","49e3bcd1":"wordcloud = WordCloud().generate(pos_words)\n\nwordcloud = WordCloud(background_color=\"white\",max_words=len(pos_words),\\\n                      max_font_size=40, relative_scaling=.5, colormap='summer').generate(pos_words)\nplt.figure(figsize=(13,13))\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.show()","4df2e8a9":"wordcloud = WordCloud().generate(neg_words)\n\nwordcloud = WordCloud(background_color=\"white\",max_words=len(neg_words),\\\n                      max_font_size=40, relative_scaling=.5, colormap='gist_heat').generate(neg_words)\nplt.figure(figsize=(13,13))\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.show()","c96cb9dd":"text_prep['Review'].head()","c9e9fcc6":"def text_vectorizing_process(sentence_string):\n    return [word for word in sentence_string.split()]","c6ec71e9":"bow_transformer = CountVectorizer(text_vectorizing_process)","3d027202":"bow_transformer.fit(text_prep['Review'])","beefddd0":"print(text_prep['Review'].iloc[3])","5777f2b5":"example = bow_transformer.transform([text_prep['Review'].iloc[3]])\nprint(example)\n#3507=Love\n#4438=petit","efa5ee6b":"Reviews = bow_transformer.transform(text_prep['Review'])\nReviews","5e019510":"print('Shape of Sparse Matrix', Reviews.shape)\nprint('Amount of Non-Zero occurences:', Reviews.nnz)","e751d419":"tfidf_transformer = TfidfTransformer().fit(Reviews)\n\ntfidf_example = tfidf_transformer.transform(example)\nprint (tfidf_example)\n#3507=Love\n#4438=petit","63111726":"[i for i in bow_transformer.vocabulary_.items() if i[1]==3507]","66ae909f":"[i for i in bow_transformer.vocabulary_.items()][6:60:10]","43338b5a":"messages_tfidf = tfidf_transformer.transform(Reviews)\nmessages_tfidf.shape","32834c12":"print(messages_tfidf[:1]) \n#tuple(index_num, word_num), tfidf_proba","8e1d6c45":"messages_tfidf = messages_tfidf.toarray()\nmessages_tfidf = pd.DataFrame(messages_tfidf)\nprint(messages_tfidf.shape)\nmessages_tfidf.head()","be95e3c8":"df_all = pd.merge(text_prep.drop(columns='Review'),messages_tfidf, \n                  left_index=True, right_index=True )\ndf_all.head()","b679fbee":"X = df_all.drop('Recommended', axis=1)\ny = df_all.Recommended\n\nX.head()","18c3fd40":"X.shape","f7ed82f9":"X.describe()","ebbf56f2":"X_train, X_test, y_train, y_test = split(X,y, test_size=0.3, stratify=y, random_state=111)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","2258233d":"y_train.value_counts(normalize=True)","932aa2e1":"y_test.value_counts(normalize=True)","a0042c6d":"scaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","4a249745":"pd.DataFrame(X_train_scaled,columns= X_train.columns).describe()","76b6638a":"pca_transformer = PCA(n_components=2).fit(X_train_scaled)\nX_train_scaled_pca = pca_transformer.transform(X_train_scaled)\nX_test_scaled_pca = pca_transformer.transform(X_test_scaled)\nX_train_scaled_pca[:1]","182c0116":"plt.figure(figsize=(15,7))\nsns.scatterplot(x=X_train_scaled_pca[:, 0], \n                y=X_train_scaled_pca[:, 1], \n                hue=y_train, \n                sizes=100,\n                palette=\"inferno\") ","3ae65275":"X_train_scaled = scipy.sparse.csr_matrix(X_train_scaled)\nX_test_scaled = scipy.sparse.csr_matrix(X_test_scaled)\n\nX_train = scipy.sparse.csr_matrix(X_train.values)\nX_test = scipy.sparse.csr_matrix(X_test.values)\nX_test","d048de65":"def report(y_true, y_pred, labels):\n    cm = pd.DataFrame(confusion_matrix(y_true=y_true, y_pred=y_pred), \n                                        index=labels, columns=labels)\n    rep = classification_report(y_true=y_true, y_pred=y_pred)\n    return (f'Confusion Matrix:\\n{cm}\\n\\nClassification Report:\\n{rep}')","47a878b6":"svc_model = SVC(C=1.0, \n             kernel='linear',\n             class_weight='balanced', \n             probability=True,\n             random_state=111)\nsvc_model.fit(X_train_scaled, y_train)","5a468933":"test_predictions = svc_model.predict(X_test_scaled)\nprint(report(y_test, test_predictions, svc_model.classes_ ))","43d4f23d":"skplt.metrics.plot_roc(y_test, svc_model.predict_proba(X_test_scaled)) ","1cdd08e5":"lr_model = LogisticRegression(class_weight='balanced', \n                              random_state=111, \n                              solver='lbfgs',\n                              C=1.0)\n\ngs_lr_model = GridSearchCV(lr_model, \n                           param_grid={'C': [0.01, 0.1, 0.5, 1.0, 5.0]}, \n                           cv=5, \n                           scoring='roc_auc')\n\ngs_lr_model.fit(X_train_scaled, y_train)","283a0ba3":"gs_lr_model.best_params_","efc5b5f0":"test_predictions = gs_lr_model.predict(X_test_scaled)\nprint(report(y_test, test_predictions, gs_lr_model.classes_ ))","85c0e2d9":"skplt.metrics.plot_roc(y_test, gs_lr_model.predict_proba(X_test_scaled),\n                      title='ROC Curves - Logistic Regression') ","1dce2000":"dt = DecisionTreeClassifier(max_depth=5, class_weight='balanced', random_state=555)\n\nada_model = AdaBoostClassifier(base_estimator=dt, learning_rate=0.001, n_estimators=1000, random_state=222)\nada_model.fit(X_train ,y_train)","8d84d92b":"test_predictions = ada_model.predict(X_test)\nprint(report(y_test, test_predictions, ada_model.classes_ ))","d3fcfa2a":"skplt.metrics.plot_roc(y_test, ada_model.predict_proba(X_test), \n                       title='ROC Curves - AdaBoost') ","6a44af69":"rf_model = RandomForestClassifier(n_estimators=1000, max_depth=5, \n                                  class_weight='balanced', random_state=3)\nrf_model.fit(X_train, y_train)","5e31e823":"test_predictions = rf_model.predict(X_test)\nprint(report(y_test, test_predictions, rf_model.classes_ ))","b915259a":"skplt.metrics.plot_roc(y_test, rf_model.predict_proba(X_test), \n                       title='ROC Curves - Random Forest') ","0cc26aec":"my_list = list(zip(rf_model.feature_importances_ ,X.columns))\nmy_list.sort(key=lambda tup: tup[0],reverse=True)\nmy_list[:7]","a4534127":"bow_list = [i for i in bow_transformer.vocabulary_.items()]\n\nfor i in my_list:\n    for j in bow_list:\n        if i[1] == j[1] and i[0]> 0.005:\n            print(f'Importance: {i[0]:.4f}   Word num: {i[1]}   Word:  { j[0]}')","5a0d7fe9":"probs = rf_model.predict_proba(X_train)\nfpr, tpr, thresholds = metrics.roc_curve(y_train, probs[:,1])","8e3b33d8":"#Train\nplt.subplots(figsize=(10, 6))\nplt.plot(fpr, tpr, '-', label=\"ROC curve\")\nplt.plot(np.linspace(0,1,10), np.linspace(0,1,10), label=\"diagonal\")\nfor x, y, txt in zip(fpr[::100], tpr[::100], thresholds[::100]):\n    plt.annotate(np.round(txt,3), (x, y-0.03), fontsize='x-small')\nrnd_idx = 700\nplt.annotate('this point refers to the tpr and the fpr\\n at a probability threshold of {}'\\\n             .format(np.round(thresholds[rnd_idx], 4)), \n             xy=(fpr[rnd_idx], tpr[rnd_idx]), xytext=(fpr[rnd_idx]+0.2, tpr[rnd_idx]-0.25),\n             arrowprops=dict(facecolor='black', lw=2, arrowstyle='->',color='r'),)\nplt.legend(loc=\"upper left\")\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")","21b1d670":"probs = rf_model.predict_proba(X_test)\nfpr, tpr, thresholds = metrics.roc_curve(y_test, probs[:,1])","390fcf00":"#Test\nplt.subplots(figsize=(10, 6))\nplt.plot(fpr, tpr, '-', label=\"ROC curve\")\nplt.plot(np.linspace(0,1,10), np.linspace(0,1,10), label=\"diagonal\")\nfor x, y, txt in zip(fpr[::70], tpr[::70], thresholds[::70]):\n    plt.annotate(np.round(txt,4), (x, y-0.01))\n\nplt.legend(loc=\"upper left\")\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")","f7016794":"X_train = pd.DataFrame(X_train.toarray(), columns=X.columns)\nX_train.head()","f4539c36":"X_test = pd.DataFrame(X_test.toarray(), columns=X.columns)\nX_test.head()","09978cbe":"rf_model.classes_","65af37b2":"arr= rf_model.predict_proba(X_test)\nprint(arr)","23201f6f":"arr_list = arr.tolist()","a6bba1ec":"arr_list[1][1]","260a31fd":"proba_list = []\nfor i in arr_list:\n    proba_list.append(i[0])\nproba_list[:5]","384f8540":"X_test['Proba0'] = proba_list\nX_test.head()","26527c1e":"prediction_list = []\nfor i in X_test['Proba0']:\n    if i > 0.4998:\n        prediction_list.append(0)\n    else:\n        prediction_list.append(1)\nprediction_list[:5]","fdbacca4":"X_test['Predictions'] = prediction_list\nX_test.head()","ac1e301e":"print(report(y_test, X_test['Predictions'], rf_model.classes_))","b01ba9cf":"# TF-IDF","3a32f789":"### Random Forest - Threshold:","0a747f70":"* SVM - f1 micro score of 0.72\n* Logistic Regression - f1 micro score of 0.72\n* AdaBoost - f1 micro score of 0.75\n* Random Forest - f1 micro score of 0.76\n","aca8c95b":"### Stemming","34eb5aa7":"## Positive reviews","e1f22d5d":"### Stopwords:","84468b14":"#### The tagging of the target variable is inaccurate, but I'm about to use it as is.","a62dea72":"___","8412a0a8":"### Data Visualization (PCA)","36b02647":"Pay attention to the words: return, disappoint, small","1aef8188":"### Adding Features","d9cab423":"##### Text Length:","ed5f180f":"___","be36a76b":"Term Frequency\u2013Inverse Document Frequency","088cef02":"### Merging Sparse matrix with other features","a230f045":"##### Exclamation mark counter:","9935d34c":"Model Evaluation will be made by two metrics:\n1. <u> F1 micro score<\/u>  - which is the harmonic mean of precision and recall, and takes into account label imbalances.\n2. <u> AUC <\/u>- ROC is a probability curve and AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes.\n","ae698bec":"Polarity is the emotion expressed in the sentence. It can be positive, neagtive and neutral.\n\nThe polarity score is a float within the range [-1.0, 1.0]","0f89b305":"adding clothing stopwords:","b882d14a":"### Removing all numbers (weight, size etc.)","63ad654f":"### 4. Random Forest","39356792":"### 3. AdaBoost","e55ed234":"### 2. Logistic Regression","35000a7f":"# Text Features:","aae8bf52":"## Splitting the data","a771102e":"#### Mostly adjectives and verbs reflect the positiveness or negativeness of the reviews","90c6e08c":"Stopwords punctuation removal","a46810a5":"# Models","8c192cdb":"# Thank you! \n\nThe code below is for checking the f1 score of the chosen threshold:","d78df32d":"___","a1c59ebc":"#### The target is imbalanced","385d965f":"### 1. SVM","43c14aaf":"### Dropping null values","314be021":"# Womens Clothing E-Commerce Reviews - NLP","44ae59dd":"### Merging text features:","1454c9e1":"### Vectorizing - Bag of Words","411eddf0":"## Negative Reviews:","f43f6f87":"### Part of Speech filter:","e12d8cd5":"# Preprocessing - text features","b9c9e19e":"### Target Value - positive\\negative review","38cfa35d":"##### Text Polarity","628b5642":"### Dropping punctuation","fbf5e85d":"# WordCloud - Repetition of words","6d08e167":"### Scaler - MinMaxScaler"}}