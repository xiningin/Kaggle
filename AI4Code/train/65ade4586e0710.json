{"cell_type":{"197ecbb4":"code","b55d4fef":"code","ffae61df":"code","0f3695e8":"code","66fd6cfc":"code","5edc4ec7":"code","9ffddc37":"code","a800aef8":"code","3d6ea50d":"code","9114139c":"code","371e676f":"code","c8a3658f":"code","cea13aae":"markdown"},"source":{"197ecbb4":"import numpy as np, pandas as pd\nfrom glob import glob\nimport shutil, os\nimport pickle\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.decomposition import IncrementalPCA\nfrom tqdm.notebook import tqdm\nimport seaborn as sns\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport cv2","b55d4fef":"df = pd.read_csv(\"..\/input\/yolopred\/objectdetection.csv\",index_col=0)\ndf = df[df.Index==1].drop(\"Index\",axis=1).reset_index(drop=True)\ndf[\"xmin\"] = df[\"x\"] - df[\"w\"]\/2\ndf[\"xmax\"] = df[\"x\"] + df[\"w\"]\/2\ndf[\"ymin\"] = df[\"y\"] - df[\"h\"]\/2\ndf[\"ymax\"] = df[\"y\"] + df[\"h\"]\/2\ndf.loc[df.xmin<0,\"xmin\"] = 0\ndf.loc[df.ymin<0,\"ymin\"] = 0\ndf.loc[df.xmax>1,\"xmax\"] = 1.0\ndf.loc[df.ymax>1,\"ymax\"] = 1.0\ndf","ffae61df":"for index,row in df.sample(n=3).iterrows():\n    image = cv2.imread(f\"\/kaggle\/input\/petfinder-pawpularity-score\/train\/{row.Id}.jpg\")\n    h,w,_ = image.shape\n    xmin, ymin, xmax, ymax = int((row.xmin)*w), int((row.ymin)*h), int((row.xmax)*w), int((row.ymax)*h)\n    plt.imshow(image)\n    plt.show()\n    plt.imshow(image[ymin:ymax,xmin:xmax,:])\n    plt.show()","0f3695e8":"#PCA part\n\n#define dataset\nclass dataset(Dataset):\n    def __init__(self,df):\n        self.df = df\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = df.iloc[idx]\n        path = f\"\/kaggle\/input\/petfinder-pawpularity-score\/train\/{row.Id}.jpg\"\n        image = cv2.imread(path)\n        h,w,_ = image.shape\n        xmin, ymin, xmax, ymax = int((row.xmin)*w), int((row.ymin)*h), int((row.xmax)*w), int((row.ymax)*h)\n        cropimage = image[ymin:ymax,xmin:xmax,:]\n        image = cv2.resize(image,(224,224))\n        image = image.flatten()\n        \n        cropimage = cv2.resize(cropimage,(128,128))\n        cropimage = cropimage.flatten()\n        \n        return image, cropimage\n        \ndef get_loader(df):                   \n    datasets = dataset(df=df)\n    loader = torch.utils.data.DataLoader(datasets, batch_size=batchsize,shuffle=False, num_workers=2)\n    return loader\n\ndef make_model(df):\n    loader = get_loader(df)\n    transform = IncrementalPCA(n_components=PCAcomp, batch_size=batchsize)\n    transform_crop = IncrementalPCA(n_components=PCAcomp, batch_size=batchsize)\n    for idx,(image,cropimage) in enumerate(loader):\n        transform.partial_fit(image)\n        transform_crop.partial_fit(cropimage)\n        print(idx)\n        \n    \n    with open('model.pickle', mode='wb') as fp:\n        pickle.dump(transform, fp)\n    \n    with open('cropmodel.pickle', mode='wb') as fp:\n        pickle.dump(transform_crop, fp)\n    \n    return transform, transform_crop\n    \ndef data_transform(df,model,cropmodel):\n    loader = get_loader(df)\n    arr = np.empty((0,PCAcomp))\n    arr_crop = np.empty((0,PCAcomp))\n    labellist = []\n    for idx,(image, cropimage) in enumerate(loader):\n        com_img = model.transform(image)\n        com_img = cropmodel.transform(cropimage)\n        arr = np.append(arr,com_img,axis=0)\n        arr_crop = np.append(arr_crop,com_img,axis=0)\n        if idx%5==0:\n            print(idx)\n    return arr,arr_crop","66fd6cfc":"batchsize = 512\nPCAcomp = 30","5edc4ec7":"model,cmodel = make_model(df)","9ffddc37":"arr,arr_crop = data_transform(df,model,cmodel)","a800aef8":"croppcadf = pd.DataFrame(arr_crop)\ncroppcadf[\"Id\"] = df.Id.values\n\npcadf = pd.DataFrame(arr)\npcadf[\"Id\"] = df.Id.values","3d6ea50d":"display(croppcadf,pcadf)","9114139c":"pcadf = pd.merge(pcadf,croppcadf,on=[\"Id\"],suffixes=(\"\",\"_crop\"))\ndisplay(pcadf)","371e676f":"df = pd.merge(df,pcadf,on=[\"Id\"],suffixes=(\"\",\"\"))\ndisplay(df)","c8a3658f":"df.to_csv(\"train.csv\")","cea13aae":"# Crop test"}}