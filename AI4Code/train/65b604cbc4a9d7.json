{"cell_type":{"40b72373":"code","d444dd37":"code","7810b4e6":"code","da0a422b":"code","f5c42143":"code","283acd48":"code","714ebf01":"code","f8a9d33f":"code","e6c2d23a":"code","2223b4a3":"code","b99fd511":"code","fbbabb81":"code","a42ab876":"code","aa38b030":"code","dcb4c676":"code","82dfcec2":"code","364fb677":"code","9e4b42ae":"markdown","74837ad2":"markdown"},"source":{"40b72373":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n#!pip install pubg-python\n\nimport matplotlib  as plt\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","d444dd37":"df = pd.read_csv('\/kaggle\/input\/pubg-finish-placement-prediction\/train_V2.csv',nrows = 3000000)\n","7810b4e6":"# Thanks to https:\/\/www.kaggle.com\/gemartin\/load-data-reduce-memory-usage\n\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n#        else:\n#            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df","da0a422b":"df_train = reduce_mem_usage(df)\n","f5c42143":"df.shape","283acd48":"df.dropna(inplace=True)","714ebf01":"#f, ax = plt.subplots(figsize=(10, 8))\n#corr = df.corr()\n#sns.heatmap(corr,\n#           xticklabels=corr.columns.values,\n#           yticklabels=corr.columns.values)\n","f8a9d33f":"x = df.drop(['Id', 'groupId', 'matchId','matchType','winPlacePerc'],axis=1)\n\ny = df.winPlacePerc\n","e6c2d23a":"del df","2223b4a3":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import accuracy_score\nrandom_forest = RandomForestRegressor(random_state=42, n_jobs=-1,n_estimators = 50)\nrandom_forest.fit(x,y)","b99fd511":"#rf = RandomForestRegressor()\n#rf.fit(x,y)\n#names = x.columns\n\n#sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), \n#             reverse=True)","fbbabb81":"test =  pd.read_csv('\/kaggle\/input\/pubg-finish-placement-prediction\/test_V2.csv')\ntest.head(5)","a42ab876":"x_test = test.drop(['Id', 'groupId', 'matchId','matchType'],axis=1)\n","aa38b030":"y_pred = random_forest.predict(x_test)  # test the output by changing values \n","dcb4c676":"submission = pd.DataFrame({\"Id\":test['Id'], \"winPlacePerc\":y_pred})\n","82dfcec2":"submission.to_csv(\"submission_new.csv\", index=False)","364fb677":"print('CODE ENEDED')","9e4b42ae":"rs.fit(x,y)","74837ad2":"from sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import accuracy_score\n# Hyperparameter grid\nparam_grid = {\n    'n_estimators': np.linspace(10, 20).astype(int),\n    'max_depth': [None] + list(np.linspace(3, 20).astype(int)),\n    'max_features': ['auto', 'sqrt', None] + list(np.arange(0.5, 1, 0.1)),\n    'max_leaf_nodes': [None] + list(np.linspace(10, 50, 500).astype(int)),\n    'min_samples_split': [2, 5, 10],\n    'bootstrap': [True, False]\n}\n\n# Estimator for use in random search\nestimator = RandomForestRegressor(random_state = 42)\n\n# Create the random search model\nrs = RandomizedSearchCV(estimator, param_grid, n_jobs = -1, \n                        scoring = 'roc_auc', cv = 2, \n                        n_iter = 2, verbose = 1, random_state=42)\n\n# Fit \n"}}