{"cell_type":{"d535e456":"code","484199c4":"code","2720ca29":"code","48a904a0":"code","a6c83882":"code","a9a65bef":"code","c2f72af0":"code","9b7556b3":"code","5e75f5fb":"code","16119b86":"code","ed04753c":"code","bd36ae3a":"code","a75bc0f9":"code","80ffb34e":"code","57d31565":"code","c57df37e":"code","7ab59fd9":"code","53da63f6":"code","ef61c670":"code","9ee7a48e":"code","e9e5219e":"code","d28696f4":"code","490aea98":"code","a6e23d6e":"code","a38bde60":"code","252177a4":"code","3a593f63":"code","38b77936":"code","63e453da":"code","10571b76":"code","28867a86":"code","ae4cdf35":"code","4a4379f1":"code","d72ddcd0":"code","2dfe1b04":"code","55cf2cb0":"code","d55621d1":"code","e9bce585":"code","31df996f":"code","6f909965":"code","b3349353":"code","d82abfb7":"code","ca11c18f":"code","b8c08dfb":"code","91b07186":"code","88387303":"code","a6423ab0":"code","e5c83243":"code","9660c3a6":"code","ebb528a3":"code","03e666b9":"code","b20de460":"code","80992c28":"code","09002d2e":"code","b77d17fd":"code","5f60f1f6":"code","e2de2580":"code","8ed59de8":"code","2c768d99":"code","39ac1728":"code","539c24e8":"code","de27366b":"code","38634170":"code","4173489d":"code","ce193543":"code","b14f20ee":"code","23420784":"code","2e1ca58a":"code","bac3b1a0":"code","db9350ee":"code","414284b0":"code","504a3b42":"code","57405737":"code","fab11c4e":"code","d287b8a0":"code","a3b363ba":"code","75f5f954":"code","2f5c5551":"code","df31ebb3":"code","cbc7f23f":"code","fb94f745":"code","4ed01061":"code","88895d39":"code","1a452da0":"code","5a70b203":"code","9fa07aa0":"code","ebcbfdec":"code","9f1107c8":"code","2c646613":"code","b166df63":"code","4f423de8":"markdown","00557c3d":"markdown"},"source":{"d535e456":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style='darkgrid', palette='deep')\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nprint(os.listdir(\"..\/input\"))\n%matplotlib inline","484199c4":"df_raw = pd.read_csv(\"..\/input\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/test.csv\")","2720ca29":"df_raw.info()","48a904a0":"df_raw.head(5)","a6c83882":"df_test.head(5)","a9a65bef":"df_test.shape","c2f72af0":"df_user= df_test['PassengerId']","9b7556b3":"df_user = pd.DataFrame(df_user, columns=['PassengerId'])","5e75f5fb":"df_user.shape","16119b86":"df_raw.columns.values","ed04753c":"new_columns = ['passangerId','survival', 'class', 'name', 'sex', 'age', 'siblings\/spouses',\n               'parents\/children', 'ticket', 'fare', 'cabin', 'embarked']\nnew_columns_test = ['passangerId', 'class', 'name', 'sex', 'age', 'siblings\/spouses',\n               'parents\/children', 'ticket', 'fare', 'cabin', 'embarked']","bd36ae3a":"df = pd.DataFrame(df_raw.values, columns= new_columns )\ndf.info()","a75bc0f9":"df_test = pd.DataFrame(df_test.values, columns= new_columns_test )\ndf_test.info()","80ffb34e":"df.head()","57d31565":"df['family'] = df['siblings\/spouses'] + df['parents\/children'] + 1\ndf = df.drop(['siblings\/spouses','parents\/children'], axis=1)\ndf['embarked'].value_counts()\ndf['embarked'].replace(['S', 'C', 'Q'], \n  ['southampton', 'cherbourg', 'quennstone'], inplace= True )","c57df37e":"df_test['family'] = df_test['siblings\/spouses'] + df_test['parents\/children'] + 1\ndf_test = df_test.drop(['siblings\/spouses','parents\/children'], axis=1)\ndf_test['embarked'].value_counts()\ndf_test['embarked'].replace(['S', 'C', 'Q'], \n  ['southampton', 'cherbourg', 'quennstone'], inplace= True )","7ab59fd9":"df[['class', 'survival', 'age', 'fare', 'passangerId',\n    'family']] = df[['class',  'survival', 'age', 'fare','passangerId',\n    'family']].apply(pd.to_numeric)\n\ndf_test[['class', 'age', 'fare', 'passangerId',\n    'family']] = df_test[['class', 'age', 'fare','passangerId',\n    'family']].apply(pd.to_numeric)","53da63f6":"df.info()","ef61c670":"df_test.info()","9ee7a48e":"#Visualising Dataset\nbins = range(0,100,10)\n\ng = pd.crosstab(df.sex, df.survival).plot(kind='bar', figsize=(10,5))\nax = g.axes\nfor p in ax.patches:\n     ax.annotate(f\"{p.get_height() * 100 \/ df.shape[0]:.2f}%\", (p.get_x() + p.get_width() \/ 2., p.get_height()),\n         ha='center', va='center', fontsize=11, color='gray', rotation=0, xytext=(0, 10),\n         textcoords='offset points')  \nplt.grid(b=True, which='major', linestyle='--')\nplt.title('Survival Frequency for Genre')\nplt.legend(['Not Survived', 'Survived'])\nplt.xlabel('Genre')\nplt.ylabel('Quantity')\nplt.show()","e9e5219e":"g = df.groupby(pd.cut(df.age, bins))['age'].count().plot(kind='bar', figsize=(10,10))\nax = g.axes\nfor p in ax.patches:\n     ax.annotate(f\"{p.get_height() * 100 \/ df.shape[0]:.2f}%\", (p.get_x() + p.get_width() \/ 2., p.get_height()),\n         ha='center', va='center', fontsize=11, color='gray', rotation=0, xytext=(0, 10),\n         textcoords='offset points') \nplt.grid(b=True, which='major', linestyle='--')\nplt.title('Frequency of Age')\nplt.grid(b=True, which='major', linestyle='--')\nplt.xlabel('Age')\nplt.ylabel('Quantity')\nplt.show()","d28696f4":"g = pd.crosstab(pd.cut(df.age, bins), df.survival).plot(kind='bar', figsize=(10,10))\nax = g.axes\nfor p in ax.patches:\n     ax.annotate(f\"{p.get_height() * 100 \/ df.shape[0]:.2f}%\", (p.get_x() + p.get_width() \/ 2., p.get_height()),\n         ha='center', va='center', fontsize=11, color='gray', rotation=0, xytext=(0, 10),\n         textcoords='offset points') \nplt.grid(b=True, which='major', linestyle='--')\nplt.title('Survival Frequency for Age')\nplt.legend(['Not Survived', 'Survived'])\nplt.yticks(np.arange(0,250,50))\nplt.xlabel('Age')\nplt.ylabel('Quantity')\nplt.show()","490aea98":"age_notsurvival = (df.groupby(pd.cut(df.age, bins))['age'].count()\/ len(df[df.survival==0]))*100\nage_survival = (df.groupby(pd.cut(df.age, bins))['age'].count()\/ len(df[df.survival==1]))*100\nage_notsurvival.shape\nage_notsurvival.plot(kind='bar', figsize=(10,10))\nplt.grid(b=True, which='major', linestyle='--')\nplt.title('Percentage of Age for Passanger Not Survived')\nplt.yticks(np.arange(0,110,10))\nplt.xlabel('Age')\nplt.ylabel('Percentage')\nplt.show()","a6e23d6e":"age_survival.plot(kind='bar', figsize=(10,10))\nplt.grid(b=True, which='major', linestyle='--')\nplt.title('Percentage of Age for Passanger Survived')\nplt.yticks(np.arange(0,110,10))\nplt.xlabel('Age')\nplt.ylabel('Percentage')\nplt.show()","a38bde60":"fig, axes = plt.subplots(nrows=2, ncols=1, sharex=True, sharey=True, figsize=(10,10))\nplt.subplots_adjust(hspace=0)\nplt.suptitle('Age Frequency')\nax1 = sns.countplot(pd.cut(df.age, bins), data= df, \n                    color='darkblue', ax=axes[0], saturation=0.5)\nax2 = sns.countplot(pd.cut(df.age, bins)[df.survival==0], data=df , \n                    color='red', ax=axes[1], saturation=1, alpha=0.5)\nax2.set_xlabel('Age')\nax3 = sns.countplot(pd.cut(df.age, bins)[df.survival==1], data= df, \n                    color='darkblue', ax=ax2, saturation=1, alpha=0.5)\nax2.legend(['Have Not Survived', 'Have Survived'])","252177a4":"pd.crosstab(df['class'], df.survival).plot(kind='bar', figsize=(15,10))\nplt.grid(b=True, which= 'major', linestyle='--')\nplt.title('Survival Frequency for Class')\nplt.yticks(np.arange(0,600,50))\nplt.legend(['Not Survived', 'Survived'])\nplt.xlabel('class')\nplt.ylabel('Quantity')\nplt.show()","3a593f63":"pd.crosstab(df.embarked, df.survival).plot(kind='bar', figsize=(15,10))\nplt.grid(b=True, which='major', linestyle='--')\nplt.yticks(np.arange(0,700,50))\nplt.title('Survival Frequency for Embarked')\nplt.legend(['Not Survived', 'Survived'])\nplt.xlabel('Embarked')\nplt.ylabel('Quantity')\nplt.show()","38b77936":"sns.pairplot(data=df, hue='survival', vars=['age', 'fare', ])","63e453da":"sns.countplot(x='survival', data=df)","10571b76":"sns.heatmap(data= df.corr(),annot=True,cmap='viridis')","28867a86":"sns.distplot(df.age, bins=10)","ae4cdf35":"pd.crosstab(df.survival[df.embarked=='southampton'],df['class']).plot(kind='bar', figsize=(15,10))\nplt.title('Survival Frequency for Class \/ Embarked(Southampton)')\nplt.grid(b=True, which='Major', linestyle='--')\nplt.legend(['First Class', 'Second Class', 'Third Class'])\nplt.ylabel('Quatity')\nplt.xlabel('Survival')\nplt.show()","4a4379f1":"df.drop(['passangerId', 'survival'], axis=1).hist(figsize=(10,10))\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])","d72ddcd0":"## Correlation with independent Variable (Note: Models like RF are not linear like these)\ndf2 = df.drop(['passangerId', 'survival'], axis=1)\ndf2.corrwith(df.survival).plot.bar(\n        figsize = (10, 10), title = \"Correlation with Survival\", fontsize = 15,\n        rot = 45, grid = True)","2dfe1b04":"sns.set(style=\"white\")\n# Compute the correlation matrix\ncorr = df2.corr()\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(10, 10))\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","55cf2cb0":"## Pie Plots (Just for binary values)\ndf.columns\ndf2 = df[['class','survival','sex', 'embarked']]\nfig = plt.figure(figsize=(15, 12))\nplt.suptitle('Pie Chart Distributions', fontsize=20)\nfor i in range(1, df2.shape[1] + 1):\n    plt.subplot(6, 3, i)\n    f = plt.gca()\n    f.axes.get_yaxis().set_visible(False)\n    f.set_title(df2.columns.values[i - 1])\n   \n    values = df2.iloc[:, i - 1].value_counts(normalize = True).values\n    index = df2.iloc[:, i - 1].value_counts(normalize = True).index\n    plt.pie(values, labels = index, autopct='%1.1f%%')\n    plt.axis('equal')\nfig.tight_layout(rect=[0, 0.03, 1, 0.95])","d55621d1":"df.describe()   ","e9bce585":"df.survival.value_counts()","31df996f":"countNotsurvival = len(df[df.survival == 0])     \ncountSurvival = len(df[df.survival == 1]) \nprint('Percentage of Titanic not survived: {:.2f}%'.format((countNotsurvival\/len(df)) * 100)) \nprint('Percentage of Titanic survived: {:.2f}%'.format((countSurvival\/len(df)) * 100))","6f909965":"df.groupby(df['survival']).mean()","b3349353":"#Looking for Null Values\nsns.heatmap(df.isnull(), yticklabels=False, cbar=False, cmap='viridis')","d82abfb7":"#Looking for Null Values\nsns.heatmap(df_test.isnull(), yticklabels=False, cbar=False, cmap='viridis')","ca11c18f":"df.isnull().any()","b8c08dfb":"df_test.isnull().any()","91b07186":"df.isnull().sum()","88387303":"df_test.isnull().sum()","a6423ab0":"null_percentage = (df.isnull().sum()\/len(df) * 100)\nnull_percentage = pd.DataFrame(null_percentage, columns = ['Percentage Train Null Values (%)'])\nnull_percentage_test = (df_test.isnull().sum()\/len(df_test) * 100)\nnull_percentage_test = pd.DataFrame(null_percentage_test, columns = ['Percentage Test Null Values (%)'])","e5c83243":"print(null_percentage)\n","9660c3a6":"print(null_percentage_test)","ebb528a3":"#Define X and y\ndf.columns\nX_train = df.drop(['passangerId', 'survival', 'name', 'ticket', 'cabin',\n              'embarked'], axis=1)\ny_train = df['survival']\ndf_test = df_test.drop(['passangerId',  'name', 'ticket', 'cabin',\n              'embarked'], axis=1)","03e666b9":"y_train.head()","b20de460":"#Get Dummies\nX_train = pd.get_dummies(X_train)","80992c28":"df_test = pd.get_dummies(df_test)","09002d2e":"X_train.head(5)","b77d17fd":"df_test.head()","5f60f1f6":"#Avoiding Dummies Trap\nX_train.columns\nX_train = X_train.drop(['sex_male'], axis=1)\nX_train.isnull().sum()","e2de2580":"#Avoiding Dummies Trap\ndf_test.columns\ndf_test = df_test.drop(['sex_male'], axis=1)\ndf_test.isnull().sum()","8ed59de8":"#Taking care of Missing Values\nfrom sklearn.preprocessing import Imputer\nimputer = Imputer(missing_values='NaN', strategy='mean', axis=0)\nimputer = imputer.fit(X_train.iloc[:, 1:2])\nX_train.iloc[:, 1:2] = imputer.transform(X_train.iloc[:, 1:2])\nX_train.isnull().sum()","2c768d99":"#Taking care of Missing Values\nfrom sklearn.preprocessing import Imputer\nimputer = Imputer(missing_values='NaN', strategy='mean', axis=0)\nimputer = imputer.fit(df_test.iloc[:, 1:2])\ndf_test.iloc[:, 1:2] = imputer.transform(df_test.iloc[:, 1:2])\ndf_test.isnull().sum()","39ac1728":"df_test[df_test['class'] == 3]['fare'].mean()","539c24e8":"df_test[df_test.fare.isnull()] = df_test[df_test['class'] == 3]['fare'].mean()","de27366b":"df_test.isnull().sum()","38634170":"#Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc_x = StandardScaler()\nX_train = pd.DataFrame(sc_x.fit_transform(X_train), columns=X_train.columns.values)\ndf_test = pd.DataFrame(sc_x.transform(df_test), columns=df_test.columns.values)","4173489d":"X_train.head()","ce193543":"df_test.head()","b14f20ee":"X_test = df_test","23420784":"X_test.head()","2e1ca58a":"## Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nlr_classifier = LogisticRegression(random_state = 0, penalty = 'l1')\nlr_classifier.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = lr_classifier.predict(X_test)\nacc = round(lr_classifier.score(X_train, y_train) * 100, 2)\n\nresults = pd.DataFrame([['Logistic Regression (Lasso)', acc]],\n               columns = ['Model', 'Accuracy'])\nacc","bac3b1a0":"from sklearn.neighbors import KNeighborsClassifier\nkn_classifier = KNeighborsClassifier(n_neighbors=25, metric='minkowski', p= 2)\nkn_classifier.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = kn_classifier.predict(X_test)\nacc = round(kn_classifier.score(X_train, y_train) * 100, 2)\n\nmodel_results = pd.DataFrame([['K-Nearest Neighbors (minkowski)', acc]],\n               columns = ['Model', 'Accuracy'])\n\nresults = results.append(model_results, ignore_index = True)\nacc","db9350ee":"## SVM (Linear)\nfrom sklearn.svm import SVC\nsvc_linear_classifier = SVC(random_state = 0, kernel = 'linear', probability= True)\nsvc_linear_classifier.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = svc_linear_classifier.predict(X_test)\nacc = round(svc_linear_classifier.score(X_train, y_train) * 100, 2)\n\nmodel_results = pd.DataFrame([['SVM (Linear)', acc]],\n               columns = ['Model', 'Accuracy'])\n\nresults = results.append(model_results, ignore_index = True)\nacc","414284b0":"## SVM (rbf)\nfrom sklearn.svm import SVC\nsvc_rbf_classifier = SVC(random_state = 0, kernel = 'rbf', probability= True)\nsvc_rbf_classifier.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = svc_rbf_classifier.predict(X_test)\nacc = round(svc_rbf_classifier.score(X_train, y_train) * 100, 2)\n\nmodel_results = pd.DataFrame([['SVM (RBF)', acc]],\n               columns = ['Model', 'Accuracy'])\n\nresults = results.append(model_results, ignore_index = True)\nacc","504a3b42":"## Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\ngb_classifier = GaussianNB()\ngb_classifier.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = gb_classifier.predict(X_test)\nacc = round(gb_classifier.score(X_train, y_train) * 100, 2)\n\nmodel_results = pd.DataFrame([['Naive Bayes (Gaussian)', acc]],\n               columns = ['Model', 'Accuracy'])\n\nresults = results.append(model_results, ignore_index = True)\nacc","57405737":"## Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\ndt_classifier = DecisionTreeClassifier(criterion='entropy', random_state=0)\ndt_classifier.fit(X_train, y_train)\n\n#Predicting the best set result\ny_pred = dt_classifier.predict(X_test)\nacc = round(dt_classifier.score(X_train, y_train) * 100, 2)\n\nmodel_results = pd.DataFrame([['Decision Tree', acc]],\n               columns = ['Model', 'Accuracy'])\n\nresults = results.append(model_results, ignore_index = True)\nacc","fab11c4e":"## Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nrf_classifier = RandomForestClassifier(random_state = 0, n_estimators = 100,\n                                    criterion = 'gini')\nrf_classifier.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = rf_classifier.predict(X_test)\nacc = round(rf_classifier.score(X_train, y_train) * 100, 2)\n\nmodel_results = pd.DataFrame([['Random Forest gini (n=100)', acc]],\n               columns = ['Model', 'Accuracy'])\n\nresults = results.append(model_results, ignore_index = True)\nacc","d287b8a0":"## Ada Boosting\nfrom sklearn.ensemble import AdaBoostClassifier\nad_classifier = AdaBoostClassifier()\nad_classifier.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = ad_classifier.predict(X_test)\nacc = round(ad_classifier.score(X_train, y_train) * 100, 2)\n\nmodel_results = pd.DataFrame([['Ada Boosting', acc]],\n               columns = ['Model', 'Accuracy'])\n\nresults = results.append(model_results, ignore_index = True)\nacc","a3b363ba":"##Gradient Boosting\nfrom sklearn.ensemble import GradientBoostingClassifier\ngr_classifier = GradientBoostingClassifier()\ngr_classifier.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = gr_classifier.predict(X_test)\nacc = round(gr_classifier.score(X_train, y_train) * 100, 2)\n\nmodel_results = pd.DataFrame([['Gradient Boosting', acc]],\n               columns = ['Model', 'Accuracy'])\n\nresults = results.append(model_results, ignore_index = True)\nacc","75f5f954":"##Xg Boosting\nfrom xgboost import XGBClassifier\nxg_classifier = XGBClassifier()\nxg_classifier.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = xg_classifier.predict(X_test)\nacc = round(xg_classifier.score(X_train, y_train) * 100, 2)\n\nmodel_results = pd.DataFrame([['Xg Boosting', acc]],\n               columns = ['Model', 'Accuracy'])\n\nresults = results.append(model_results, ignore_index = True)\nacc","2f5c5551":"##Ensemble Voting Classifier\nfrom sklearn.ensemble import VotingClassifier\nvoting_classifier = VotingClassifier(estimators= [('lr', lr_classifier),\n                                                  ('kn', kn_classifier),\n                                                  ('svc_linear', svc_linear_classifier),\n                                                  ('svc_rbf', svc_rbf_classifier),\n                                                  ('gb', gb_classifier),\n                                                  ('dt', dt_classifier),\n                                                  ('rf', rf_classifier),\n                                                  ('ad', ad_classifier),\n                                                  ('gr', gr_classifier),\n                                                  ('xg', xg_classifier),],\nvoting='soft')","df31ebb3":"for clf in (lr_classifier,kn_classifier,svc_linear_classifier,svc_rbf_classifier,\n            gb_classifier, dt_classifier,rf_classifier, ad_classifier, gr_classifier, xg_classifier,\n            voting_classifier):\n    clf.fit(X_train,y_train)\n    y_pred = clf.predict(X_test)\n    print(clf.__class__.__name__, round(clf.score(X_train, y_train) * 100, 2))","cbc7f23f":"# Predicting Voting Test Set\ny_pred = voting_classifier.predict(X_test)\nacc = round(voting_classifier.score(X_train, y_train) * 100, 2)\n\nmodel_results = pd.DataFrame([['Ensemble Voting', acc]],\n               columns = ['Model', 'Accuracy'])\n\nresults = results.append(model_results, ignore_index = True)\nacc","fb94f745":"results","4ed01061":"#The Best Classifier\nprint('The best classifier is:')\nprint('{}'.format(results.sort_values(by='Accuracy',ascending=False).head(5)))","88895d39":"#Applying K-fold validation\nfrom sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator=gr_classifier, X=X_train, y=y_train,cv=10)\naccuracies.mean()\naccuracies.std()\nprint(\"Gradient Boosting Accuracy: %0.3f (+\/- %0.3f)\" % (accuracies.mean(), accuracies.std() * 2))","1a452da0":"X_test.shape","5a70b203":"df_user.shape\n","9fa07aa0":"y_pred.shape","ebcbfdec":"submission = pd.DataFrame({\n        \"PassengerId\": df_user[\"PassengerId\"],\n        \"Survived\": y_pred\n    })","9f1107c8":"submission.head()","2c646613":"submission.to_csv('titanic_submission.csv', index=False)","b166df63":"print(submission)","4f423de8":"# Model Building \n# Comparing Models","00557c3d":"I Have chose Gradient Boosting as the best classifier becouse Decision Tree and Random Forest can be overfitting."}}