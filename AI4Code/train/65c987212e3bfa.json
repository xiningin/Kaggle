{"cell_type":{"eea33e78":"code","b8005852":"code","f0324efd":"code","1fddfe40":"code","c572279c":"code","cce7bb7c":"code","29b08f3d":"code","f6119b3d":"code","1ee87fa1":"code","04b39aa5":"code","a3d1f8d6":"code","bf8dd25c":"code","e26179ad":"code","19d9fc4d":"code","c94fee1d":"code","82d65685":"code","a31629e5":"code","884fd218":"code","7ff9e0c8":"code","1c0047ab":"code","142b9420":"code","b0bf8341":"code","f8c8fced":"code","95fd4321":"code","4caac4c7":"code","c1339ad3":"code","d4ffd227":"code","30f03e5d":"markdown","5f1b827f":"markdown","addd6b74":"markdown","f7624548":"markdown","25a23998":"markdown","e920d44c":"markdown","07b99a18":"markdown","be0862e6":"markdown","3dbe7f8f":"markdown","af672c0b":"markdown","f13e3b66":"markdown"},"source":{"eea33e78":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.base import clone\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nimport missingno as msno\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline","b8005852":"df = pd.read_csv(\"..\/input\/widsdatathon2021\/TrainingWiDS2021.csv\")","f0324efd":"df.head().T","1fddfe40":"for col in df.columns:\n    print (col, '\\t\\t', df[col].unique()[:7])","c572279c":"df.nunique()","cce7bb7c":"class_distribution = df['diabetes_mellitus'].value_counts()\nplt.bar([str(k) for k in list(class_distribution.index)], list(class_distribution), color ='maroon',  \n        width = 0.5) ","29b08f3d":"msno.bar(df) ","f6119b3d":"total = df.isnull().sum().sort_values(ascending=False)\npercent = (df.isnull().sum()\/df.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(30)","1ee87fa1":"top_20 = missing_data.index[:20]\ntop_20_40 = missing_data.index[20:40]\ntop_40_60 = missing_data.index[40:60]\ntop_60_80 = missing_data.index[60:80]\ntop_80_100 = missing_data.index[80:100]\ntop_100_120 = missing_data.index[100:120]\ntop_120_140 = missing_data.index[120:140]\ntop_140_160 = missing_data.index[140:160]\ntop_160 = missing_data.index[160:]","04b39aa5":"msno.bar(df[top_20])\nmsno.heatmap(df[top_20]) ","a3d1f8d6":"msno.bar(df[top_20_40])\nmsno.heatmap(df[top_20_40]) ","bf8dd25c":"msno.bar(df[top_40_60])\nmsno.heatmap(df[top_40_60]) ","e26179ad":"msno.bar(df[top_60_80])\nmsno.heatmap(df[top_60_80]) ","19d9fc4d":"msno.bar(df[top_80_100]) \nmsno.heatmap(df[top_80_100]) ","c94fee1d":"msno.bar(df[top_100_120]) \nmsno.heatmap(df[top_100_120]) ","82d65685":"msno.bar(df[top_120_140]) \nmsno.heatmap(df[top_120_140]) ","a31629e5":"msno.bar(df[top_140_160]) \nmsno.heatmap(df[top_140_160]) ","884fd218":"msno.bar(df[top_160])","7ff9e0c8":"df['target_dummy'] = df['diabetes_mellitus'].apply(lambda x:{0:0, 1:np.nan}[x])","1c0047ab":"msno.bar(df[list(top_20)+['target_dummy']])\nmsno.heatmap(df[list(top_20)+['target_dummy']])","142b9420":"msno.bar(df[list(top_20_40)+['target_dummy']])\nmsno.heatmap(df[list(top_20_40)+['target_dummy']])","b0bf8341":"msno.bar(df[list(top_40_60)+['target_dummy']])\nmsno.heatmap(df[list(top_40_60)+['target_dummy']])","f8c8fced":"msno.bar(df[list(top_60_80)+['target_dummy']])\nmsno.heatmap(df[list(top_60_80)+['target_dummy']])","95fd4321":"msno.bar(df[list(top_80_100)+['target_dummy']])\nmsno.heatmap(df[list(top_80_100)+['target_dummy']])","4caac4c7":"msno.bar(df[list(top_100_120)+['target_dummy']])\nmsno.heatmap(df[list(top_100_120)+['target_dummy']])","c1339ad3":"msno.bar(df[list(top_120_140)+['target_dummy']])\nmsno.heatmap(df[list(top_120_140)+['target_dummy']])","d4ffd227":"msno.bar(df[list(top_140_160)+['target_dummy']])\nmsno.heatmap(df[list(top_140_160)+['target_dummy']])","30f03e5d":"Count of values available for each column","5f1b827f":"Too crowded ! Isn't it?","addd6b74":"Let's pick 20 columns at a time to understand available values and correlation of missing values.","f7624548":"# Missing Values\nIn this notebook we will focus on simple exploration with emphasis on missing value identification. We will delve into correlation among missing values i.e. if the values are missing because of unavailability of a group of similar values or is it because of some other reason like human entry error. We will also look into possible data leaks using the above method.","25a23998":"Let's arrange the columns by proportion of missing values","e920d44c":"### Heatmap plots\nHeatmap shows the correlation of missingness between every 2 columns.\nA value near -1 means if one variable appears then the other variable is very likely to be missing.\nA value near 0 means there is no dependence between the occurrence of missing values of two variables.\nA value near 1 means if one variable appears then the other variable is very likely to be present.","07b99a18":"![Business photo created by jcomp - www.freepik.com](https:\/\/www.freepik.com\/free-photo\/jigsaw-puzzle-with-missing-piece-missing-puzzle-pieces_5469654.htm#page=1&query=missing&position=2)","be0862e6":"### Class Imabalance","3dbe7f8f":"#### Correlation between missing values and Target Variable\nI am doing this in hope of a possible data leak. Validating if a lot of missing values in the columns correspond to a particular value in the target variable.\nLet's create a dummy column target_dummy and put nan instead of 1.","af672c0b":"**Unique Values**\n\nLet's look at some unique values of each column","f13e3b66":"### Missing Values"}}