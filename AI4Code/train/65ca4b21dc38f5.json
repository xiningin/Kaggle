{"cell_type":{"8de08909":"code","b4b8ff30":"code","482d1c34":"code","0b42887e":"code","dcdab209":"code","7cf955d9":"code","08584fbf":"code","653d0b51":"code","8f548edf":"code","0aabc8b9":"code","dc6af4cb":"code","fb354e58":"code","908df452":"code","207f72f5":"code","924075c6":"code","15c44478":"code","4caf4442":"code","3555dc9e":"code","ccfed509":"code","e59f0a1a":"code","64a91265":"code","84a3bd9c":"code","ca0d5cda":"code","480a2f6e":"code","5298ae02":"code","e3c8cc54":"code","8e971777":"code","9f4d9372":"code","2b2c3002":"code","17dd116e":"code","29d08045":"code","d5248777":"code","51564da2":"code","90b7fd39":"code","ae769870":"markdown","34f1ba7a":"markdown","88481f13":"markdown","31b39c79":"markdown","4d6a9d42":"markdown","79bcc9d6":"markdown","ad81bcea":"markdown","ee6ec86b":"markdown","77724148":"markdown","a30c38f4":"markdown","e4c58fb2":"markdown","46d309db":"markdown","b80be21d":"markdown","b703f5d1":"markdown","329cbcac":"markdown","6bba505a":"markdown","b52b7aea":"markdown","111b934f":"markdown","9f65fa90":"markdown","bb814d0b":"markdown","eaefb573":"markdown","03319ba7":"markdown","92f77d82":"markdown","6e04512d":"markdown","f249477d":"markdown","af64128b":"markdown","797c7509":"markdown","b4a17e94":"markdown","0e02b4be":"markdown","404bd548":"markdown","8eeaad6b":"markdown","20ecc925":"markdown","ce6a9e7a":"markdown","a9638fa2":"markdown","5e4503dd":"markdown","f98e152a":"markdown","7066307f":"markdown","22c8ed20":"markdown","1c7b51e1":"markdown","92d1a7e9":"markdown","704edc5c":"markdown","71590a42":"markdown","1805eba7":"markdown","49136b98":"markdown","076d7ce5":"markdown","96915b02":"markdown","d10ce141":"markdown","285effb2":"markdown","8364346e":"markdown","b0b5b8da":"markdown","796836f9":"markdown","87dad723":"markdown","eda286b0":"markdown","2f17e8d7":"markdown","3c29ab34":"markdown"},"source":{"8de08909":"# Importing the required files.\nfrom __future__ import print_function\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport sys\nimport pandas as pd\nimport string\nfrom time import time\nimport nltk\nfrom nltk.corpus import stopwords \nstops = set(stopwords.words(\"english\"))\nimport re\nfrom IPython.display import display # Allows the use of display() for DataFrames\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline\nRAN_STATE = 42 # Setting the random state","b4b8ff30":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","482d1c34":"# Read json data\ndata=pd.read_json('\/kaggle\/input\/amazon-electronics-reviews\/Electronics_5.json',lines=True,orient='columns')\ndata.head()","0b42887e":"# Remove duplicate reviews(if any)\nprint(\"The shape of the data set before removing duplicate reviews : {}\".format(data.shape))\ndata=data.drop_duplicates(subset=[\"reviewText\"], keep='first', inplace=False)\nprint(\"The shape of the data set after removing duplicate reviews : {}\".format(data.shape))","dcdab209":"def preprocess(x):\n    x = x.replace(\",000,000\", \" m\").replace(\",000\", \" k\").replace(\"\u2032\", \"'\").replace(\"\u2019\", \"'\")\\\n                           .replace(\"won't\", \" will not\").replace(\"cannot\", \" can not\").replace(\"can't\", \" can not\")\\\n                           .replace(\"n't\", \" not\").replace(\"what's\", \" what is\").replace(\"it's\", \" it is\")\\\n                           .replace(\"'ve\", \" have\").replace(\"'m\", \" am\").replace(\"'re\", \" are\")\\\n                           .replace(\"he's\", \" he is\").replace(\"she's\", \" she is\").replace(\"'s\", \" own\")\\\n                           .replace(\"%\", \" percent \").replace(\"\u20b9\", \" rupee \").replace(\"$\", \" dollar \")\\\n                           .replace(\"\u20ac\", \" euro \").replace(\"'ll\", \" will\").replace(\"how's\",\" how has\").replace(\"y'all\",\" you all\")\\\n                           .replace(\"o'clock\",\" of the clock\").replace(\"ne'er\",\" never\").replace(\"let's\",\" let us\")\\\n                           .replace(\"finna\",\" fixing to\").replace(\"gonna\",\" going to\").replace(\"gimme\",\" give me\").replace(\"gotta\",\" got to\").replace(\"'d\",\" would\")\\\n                           .replace(\"daresn't\",\" dare not\").replace(\"dasn't\",\" dare not\").replace(\"e'er\",\" ever\").replace(\"everyone's\",\" everyone is\")\\\n                           .replace(\"'cause'\",\" because\").replace(\"i'm\",\" i am\")\n    \n    x = re.sub(r\"([0-9]+)000000\", r\"\\1m\", x)\n    x = re.sub(r\"([0-9]+)000\", r\"\\1k\", x)\n    x=re.sub(r'((www\\.[^\\s]+)|(https?:\/\/[^\\s]+))',' ',x)\n    x=re.sub(r\"\\\\s*\\\\b(?=\\\\w*(\\\\w)\\\\1{2,})\\\\w*\\\\b\",' ',x)\n    x=re.sub(r'<.*?>',' ',x)\n    x=re.sub('[^a-zA-Z]',' ',x)\n    x=''.join([i for i in x if not i.isdigit()])\n    return x","7cf955d9":"# Import libraries\nfrom nltk.corpus import stopwords\nfrom textblob import TextBlob\nfrom textblob import Word\n\n# Lower casing and removing punctuations\ndata['reviewText'] = data['reviewText'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\ndata['reviewText'] = data['reviewText'].str.replace('[^\\w\\s]','')\n\n# Removing stopwords\n#stop = stopwords.words('english')\n#data['reviewText'] = data['reviewText'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\ndata['reviewText'] = data['reviewText'].apply(lambda x: preprocess(x))\n# Lemmatization\n\ndata['reviewText'] = data['reviewText'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\ndata.reviewText.head(5)","08584fbf":"data.head()","653d0b51":"#select the columns\ndf = data.iloc[:, [5,4,3]]\n\n#split numerator and denominator\ndf['helpful_numerator'] = df['helpful'].apply(lambda x: x[0])\ndf['helpful_denominator'] = df['helpful'].apply(lambda x: x[1])\n\n# delete un-needed helpful column\ndel df['helpful']\n\n#Check if we have any null values\nprint (df.isnull().sum())","8f548edf":"df.describe()","0aabc8b9":"# include reviews that have more than 20 helpfulness data point only\ndf1 = df[(df.helpful_denominator > 20)].copy()\ndf1.shape","dc6af4cb":"# transform Helpfulness into a binary variable with 0.5 ratio\nthreshold = 0.5\ndf1.loc[:, 'Helpful'] = np.where(df1.loc[:, 'helpful_numerator'] \\\n                                 \/ df1.loc[:, 'helpful_denominator'] > threshold, 1, 0)\ndf1.head(3)","fb354e58":"#Check the balance\nprint ('Count:')\ndisplay(df1.groupby('Helpful').count())","908df452":"df1","207f72f5":"from sklearn.feature_extraction.text import TfidfVectorizer\n# define the vectorizer\nvectorizer = TfidfVectorizer(min_df = 0.01)\n# fit the vectorizers to the data.\nfeatures = vectorizer.fit_transform(df1['reviewText'])\nfeatures","924075c6":"# split and shuffle data\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(features,df1['Helpful'], test_size=0.2, random_state=RAN_STATE)","15c44478":"from sklearn.metrics import roc_auc_score, roc_curve\n\ndef train_classifier(clf, X_train, y_train):\n    ''' Fits a classifier to the training data. '''\n    \n    # Start the clock, train the classifier, then stop the clock\n    start = time()\n    clf.fit(X_train, y_train)\n    end = time()\n    \n    # Print the results\n    print (\"Trained model in {:.4f} seconds\".format(end - start))\n\n    \ndef predict_labels(clf, features, target):\n    ''' Makes predictions using a fit classifier based on roc_auc score. '''\n    \n    # Start the clock, make predictions, then stop the clock\n    start = time()\n    probas = clf.predict_proba(features)\n    end = time()\n    \n    # Print and return results\n    print (\"Made predictions in {:.4f} seconds.\".format(end - start))\n    return roc_auc_score(target.values, probas[:,1].T)\n\n\ndef train_predict(clf, X_train, y_train, X_test, y_test):\n    ''' Train and predict using a classifer based on roc_auc score. '''\n    \n    # Indicate the classifier and the training set size\n    print (\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, X_train.shape[0]))\n    \n    # Train the classifier\n    train_classifier(clf, X_train, y_train)\n    \n    # Print the results of prediction for both training and testing\n    print (\"ROC_AUC score for training set: {:.4f}.\".format(predict_labels(clf, X_train, y_train)))\n    print (\"ROC_AUC score for test set: {:.4f}.\\n\".format(predict_labels(clf, X_test, y_test)))\n    \ndef clf_test_roc_score(clf, X_train, y_train, X_test, y_test):\n    clf.fit(X_train, y_train)\n    probas = probas =clf.predict_proba(X_test)\n    return roc_auc_score(y_test, probas[:,1].T)","4caf4442":"# Import the supervised learning models from sklearn\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\n\n\n# Initialize the models using a random state were applicable.\nclf_list = [GaussianNB(),  \n            LogisticRegression(random_state = RAN_STATE),\n            DecisionTreeClassifier(random_state = RAN_STATE)]\nx_tr = X_train.toarray()\nx_te = X_test.toarray()\n\n\n# Set up the training set sizes for 10000, 20000 and 40000 respectively.\ntrain_feature_list = [x_tr[0:10000],x_tr[0:20000],x_tr]\ntrain_target_list = [y_train[0:10000], y_train[0:20000], y_train]\n\n\n# Execute the 'train_predict' function for each of the classifiers and each training set size\nfor clf in clf_list:\n    for a, b in zip(train_feature_list, train_target_list):\n        train_predict(clf, a, b, x_te, y_test)","3555dc9e":"FIG_SIZE = (14,8)\n# Visualize all of the classifiers                                                               \nfor clf in clf_list:\n    x_graph = []\n    y_graph = []\n    for a, b in zip(train_feature_list, train_target_list):\n        y_graph.append(clf_test_roc_score(clf, a, b, x_te, y_test))\n        x_graph.append(len(a))\n    plt.scatter(x_graph,y_graph)\n    plt.plot(x_graph,y_graph, label = clf.__class__.__name__)\n\nplt.title('Comparison of Different Classifiers')\nplt.xlabel('Training Size')\nplt.ylabel('ROC_AUC score on test set')\nplt.legend(bbox_to_anchor=(1.6, 1.05))\nplt.figure(figsize=FIG_SIZE)             \nplt.show() ","ccfed509":"#add Score column to features\nimport scipy as scipy\n\noverall = np.array(list(df1.overall))\noverall = overall.reshape(features.shape[0], 1)\n\nfeatures = scipy.sparse.hstack((features,scipy.sparse.csr_matrix(overall)))\n\nfeatures = scipy.sparse.csr_matrix(features)\nfeatures\n","e59f0a1a":"X_train2, X_test2, y_train, y_test = train_test_split(features, df1['Helpful'], test_size=0.2, random_state=RAN_STATE)","64a91265":"from sklearn.model_selection import GridSearchCV,cross_validate,StratifiedKFold\n#make the grid search object\ngs2 = GridSearchCV(\n    estimator=LogisticRegression(),\n    param_grid={'C': [10**i for i in range(-5,5)], 'class_weight': [None, 'balanced']},\n    cv=StratifiedKFold(n_splits=5),\n    scoring='roc_auc'\n)\n\n#fit the grid search object to our new dataset\nprint ('Fitting grid search...')\ngs2.fit(X_train2, y_train)\nprint (\"Grid search fitted.\")","84a3bd9c":"#print the grid search scores.\ngs2.best_params_","ca0d5cda":"clf2 = gs2.best_estimator_\nprobas =clf2.predict_proba(X_test2)\n\n\n# ROC\/AUC score\nprint ('ROC_AUC Score:',roc_auc_score(y_test, probas[:,1].T))","480a2f6e":"\nclf = LogisticRegression()\nclf.fit(X_train,y_train)\nprobas = clf.predict_proba(X_test)\nclf2 = gs2.best_estimator_\nprobas2 =clf2.predict_proba(X_test2)\nplt.figure(figsize = FIG_SIZE)\n\n# plot graph to show roc_auc_score.\nplt.plot(roc_curve(y_test, probas[:,1])[0], roc_curve(y_test, probas[:,1])[1], label = 'TFIDF')\nplt.plot(roc_curve(y_test, probas2[:,1])[0], roc_curve(y_test, probas2[:,1])[1], label = 'TFIDF + overall')\nplt.title('ROC Curve for Helpful Rating')\nplt.grid()\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\n\nplt.legend(bbox_to_anchor=(1.0, .5))\nplt.figure(figsize=FIG_SIZE)\nplt.show()","5298ae02":"data.head()","e3c8cc54":"#select the columns\ndf2 = data.iloc[:, [5,4]]\ndf2.head(10)","8e971777":"def score_classify(x):\n    if x>3:\n        return 'Positive'\n    elif x<3:\n        return 'Negative'\n    else:\n        return 'Neutral'\ndf2['Overall_Sentiment']=df2.apply(lambda x: score_classify(x['overall']),axis=1)\ndf2","9f4d9372":"df2.Overall_Sentiment.value_counts()","2b2c3002":"df2.dropna(\n    axis=0,\n    how='any',\n    thresh=None,\n    subset=None,\n    inplace=True\n)\ndf2.Overall_Sentiment.value_counts()","17dd116e":"from textblob import TextBlob\n\nsentiment_score_list = []\nsentiment_label_list = []\n\nfor i in df2['reviewText'].values.tolist():\n    sentiment_text=TextBlob(i)\n    sentiment_score = sentiment_text.sentiment.polarity\n    #print(sentiment_score)\n\n    if sentiment_score > 0:\n        sentiment_score_list.append(sentiment_score)\n        sentiment_label_list.append('Positive')\n    elif sentiment_score < 0:\n        sentiment_score_list.append(sentiment_score)\n        sentiment_label_list.append('Negative')\n    else:\n        sentiment_score_list.append(sentiment_score)\n        sentiment_label_list.append('Neutral')\n    \ndf2['Review_Sentiment'] = sentiment_label_list\ndf2['sentiment score'] = sentiment_score_list\n\ndisplay(df2.head(10))","29d08045":"before=df2.shape[0]\ndf2 = df2[df2.Overall_Sentiment != 'Neutral']\ndf2 = df2[df2.Review_Sentiment != 'Neutral']\ndf2.head(10)\nafter=df2.shape[0]\n#EDA for finding how many neutral labels have been removed","d5248777":"print(\"The number of neutral labels have been removed : {}\".format(before-after))","51564da2":"comparison_column = np.where(df2[\"Overall_Sentiment\"] == df2[\"Review_Sentiment\"], True, False)\ndf2[\"result\"] = comparison_column\ndf2.head()","90b7fd39":"df2 = df2[df2.result != True]\nprint(df2.shape)\ndf2.head()","ae769870":"Here, we are going to select **reviewText** and **overall** score rating since we going to classify reviews based on these two features.","34f1ba7a":"# Problem Statement 1","88481f13":"Let's see the given data.","31b39c79":"Now, let's start with problem statements.","4d6a9d42":"Before we start with the problem statements, we have to do a little data preparation.\n\nFirst, let's import all required files.","79bcc9d6":"A Rough Overview\n--\nMarketing is an essential part of the business. Digital marketing was already in hype for the past few years but due to this pandemic, it has increased exponentially. Since a customer cannot physically check the product, he\/she has to depend on reviews of the given product. \n\nDespite this there are some people who do not give genuine review or give a sarcastic review.\n\nHere are some examples:\n\n<img src=\"https:\/\/imgur.com\/Dbxy4Ck.jpeg\" width=\"400px\">\n\n<img src=\"https:\/\/imgur.com\/QWuvHhN.jpeg\" width=\"400px\">\n\nHaving such reviews displayed in forums hurts Amazon\u2019s business since the major reason as stated above is that people are willing to buy consumer goods online without seeing the items themselves because they have access to other people's opinions of the item. ","ad81bcea":"Since we are having two problem statements, both of which require the same kind of preprocessing, we are going to preprocess before starting with the problem statements.\n\nPreprocessing before going to problem statements will save a lot of time since just to preprocess once, I required about an hour.","ee6ec86b":"In this project, we first predicted the helpfulness of review. In the second part, we found out about the genuinity of reviews.\n\nFor the second part, I have also made a web app using streamlit in which you can find out find if the review is genuine or not.\n\n**Click [here](https:\/\/share.streamlit.io\/letus21500\/amazon-electronic-reviews\/main\/amazon.py) to go to the web app.**\n\n**Github link is given [here](https:\/\/github.com\/letus21500\/Amazon-Electronic-Reviews).**\n\nI would like to thank [Rocky Jigtiani Sir](https:\/\/www.linkedin.com\/today\/author\/rocky-jagtiani-3b390649\/) for guiding me in this project. \n\nI would also like to thank my friend and project-partner [Chetan Gadge](https:\/\/www.linkedin.com\/in\/chetan-gadge-7b1090189\/) for helping me with this project.","77724148":"We can see that some reviews are of Neutral, sentiment based on star rating bit are Positive, based on the sentiment of review text.\n\nSuch reviews may be harmful to our model as they could be classified wrongly.\n\nSo we are removing all Neutral reviews.","a30c38f4":"A Rough Overview\n--\nMarketing is an essential part of the business. \nDigital marketing was already in hype for the past few years, but due to this pandemic, it has increased exponentially. \nSince a customer cannot physically check the product, he\/she has to depend on reviews of the given product. \n\nAmazon has a helpfulness rating system, that allows users to see top-rated reviews which can help a customer to make an informed decision. \n\nBut even if this helps, poor-quality reviews can still come on top of forums.\n\nHaving poor quality reviews displayed in forums hurts Amazon\u2019s business since the major reason as stated above is that people are willing to buy consumer goods online without seeing the items themselves because they have access to other people's opinions of the item. ","e4c58fb2":"We can see our optimized classifier is a LogisticRession with a 'C' parameter of 1 and a 'class_weight' = 'None'. This is the same as default, meaning our optimization step did not change the parameters of our model. Let's now find our ROC_AUC Score.","46d309db":"Now let's find out how many Neutral reviews we have removed.","b80be21d":"Here to get our output label **helpfulness**, we have to take the ratio of helpful_numerator to helpful_denominator. The result is compared with a threshold value(*we are taking threshold as 50%, but we can change it as per our requirement*).\n* If result > threshold ==> helpful = 1\n* if result < treshold ==> not helpful = 0","b703f5d1":"As we can see in the above ROC Curve, adding an overall score to TFIDF vectors would give us a higher Area Under Curve(AUC).","329cbcac":"It's a hassle to find each value. So let's just visualize the outputs for all models.","6bba505a":"Let's see the given data.","b52b7aea":"Based on data we thought of two problem statements:\n\n> Problem Statement 1: Prediction of Helpfulness from given data.\n\n> Problem Statement 2: Classification of genuine and fake\/sarcastic reviews.","111b934f":"# Problem Statement 2","9f65fa90":"Now, let's find the total number of all the fake reviews. \n\nAnd also see some as an example.","bb814d0b":"We will now import the dataset and extract data.\n\nThe dataset has been taken from [here](http:\/\/snap.stanford.edu\/data\/amazon\/productGraph\/categoryFiles\/) and doesn't belong to me.","eaefb573":"Wow! 90 % ROC_AUC Score. That means our model has been trained well.\n\nLet's now plot the graph to find the ROC Curve for Helpful Rating of both TFIDF and TFIDF along with the overall score. ","03319ba7":"Data Preparation\n--","92f77d82":"Hyper-parameters are parameters that are not directly learned within estimators. In scikit-learn, they are passed as arguments to the constructor of the estimator classes. Hyperparameter tuning helps us in optimizing our model.\nFor more information see [here](https:\/\/scikit-learn.org\/stable\/modules\/grid_search.html#grid-search).\n\nWe will now be applying Gridsearch and Cross-Validation techniques to optimize and hypertune our model.\n\n* **GridSearch:** Exhaustive search over specified parameter values for an estimator.\n\n* **Cross-Validation:** In the train-test split, we use only 20% for testing. The performance metric we get on that 20% test data may not be accurate. So Cross-Validation allows you to consume 100% of the data for training and testing both.\n \nFor more information see [here](https:\/\/scikit-learn.org\/stable\/modules\/classes.html#module-sklearn.model_selection)","6e04512d":"Here we can see that 1354351 reviews are Positive,190693 are Negative while 142125 are Neutral.\n\nBut it may also be possible that some data may be missing or null. \n\nSo let's drop null values if there are any. Then recheck the number of reviews.","f249477d":"Now let's do the count of data to get an idea about the distribution of helpfulness.","af64128b":"Here we are going to first convert reviews to lowercase. Then we are going to do preprocessing. And finally, go to lemmatization.\n\nHere we could also use stemming but I am going to use lemmatization.\n\n> **Stemming:** Stemming is a process of extracting a root word. For example, \u201cfish,\u201d \u201cfishes,\u201d and \u201cfishing\u201d are stemmed into fish.\n> \n> **Lemmatization:** Lemmatization is a process of extracting a root word by considering the vocabulary. For example, \u201cgood,\u201d \u201cbetter,\u201d or \u201cbest\u201d is lemmatized into good. The part of speech of a word is determined in lemmatization. It will return the dictionary form of a word, which must be valid while stemming just extracts the root word.\n\n*Lemmatization handles matching \u201ccar\u201d to \u201ccars\u201d along with matching \u201ccar\u201d to \u201cautomobile.\u201d*\n\n*Stemming handles matching \u201ccar\u201d to \u201ccars.\u201d*\n\nFor more info see [here](https:\/\/nlp.stanford.edu\/IR-book\/html\/htmledition\/stemming-and-lemmatization-1.html).","797c7509":"We will now read the data.\n\nThe dataset is a JSON file so we are using the read_json() function of Pandas. We have used *lines=True*  to read the file as a JSON object per line, else it will give an error.\n\nFor more information,see [here](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.read_json.html)","b4a17e94":"This project was done as the final project for the Advanced Machine Learning Course of [Suven Consultants](https:\/\/datascience.suvenconsultants.com\/) under the mentorship of [Mr. Rocky Jigtiani](https:\/\/www.linkedin.com\/today\/author\/rocky-jagtiani-3b390649\/).\n\nIn this course we, learned about various advance machine learning concepts like text classification,sentiment analysis,information retrieval,text summarization,speech recognition,text-to-speech,speech-to-text,next word prediction,languge translation and detection,etc.\n\nBased on these concepts and using data given [here](http:\/\/snap.stanford.edu\/data\/amazon\/productGraph\/categoryFiles\/), we were asked to create a project for completion of our course.\n\nI would like to thank Mr. Rocky Jagtiani Sir and my partner [Chetan Gadge](https:\/\/www.linkedin.com\/in\/chetan-gadge-7b1090189\/) for helping me with this project.\n","0e02b4be":"Sentiment analysis is a process in which we computationally analyze and identify opinions and judgments of a customer from a piece of text. You can understand if a piece of text is positive, negative, or neutral, based on their sentiment analysis.\n\nThere are various types of sentiment analysis, but we are using aspect-based sentiment analysis here.\n\nAspect-based sentiment analysis is generally for one or more aspects of a service or product. \n\nFor example, if a company that sells mobile phones uses this type of sentiment analysis, it could be for one aspect of mobile phones \u2013 like battery life, processor, USF storage, etc. \n\nSo they can understand how customers feel about specific attributes of the product. \n\nFor more information, see [here](https:\/\/www.upgrad.com\/blog\/types-of-sentiment-analysis\/).","404bd548":"We can now split the dataset and try to optimize our initial model.","8eeaad6b":"So we can see that there are no missing or null values.\n\nLet's now go for sentiment analysis of review text.","20ecc925":"Text Preprocessing\n--","ce6a9e7a":"We can implement aspect-based sentiment analysis in different ways. \n\nThe most famous is Sentiment Intensity Analyzer(commonly known as SIA) from vaderSentiment. \n\nBut I found that sentiment from Textblob gives better results than SIA here. So we have used the sentiment from Textblob.\n\nFor more information see [here](https:\/\/textblob.readthedocs.io\/en\/dev\/quickstart.html#sentiment-analysis).","a9638fa2":"Finally, we found all the reviews that are not genuine and that is a lot of reviews.","5e4503dd":"Conclusion:\n--\nThe importance of this problem statement is that we can easily find out if the given review is genuine or not. \nHere, we used review text and star rating from Amazon's Electronic Reviews that was given to the product by the reviewer. We used these features to classify if the given review is truly genuine or not.","f98e152a":"**Based on the above data we can say:**\n> Input Features : reviewText,overall\n\n> Output labels: helpfulness\n\n**Reason for selecting input features:** When we give any review, along with text(reviewText) of the review we also give a rating in stars(overall).\n\n**A brief explanation about the helpful column:** helpful column given above is a list containing two values---no of helpful ratings and the total no of ratings--- separated by a comma.\n\nWe are dividing the helpful column into two parts i.e. \n \n > helpful_numerator => contains no. of helpful rating.\n \n > helpful_denominator => contains total no. of ratings.\n\nand then we are deleting the helpful column.\n","7066307f":"Now, let's find out how the number of Positive, Negative, and Neutral reviews.","22c8ed20":"Problem Statement\n--\nThe problem addressed here is Amazon Reviews of poor quality that are there, at the top of forums despite the helpfulness rating system of Amazon. \nThis problem mainly arises due to the new reviews are directly placed on top of the forum which would give the community a chance to rate them.\n\nThe solution to this problem is to create a model using machine learning techniques that would pre-rate the helpfulness of a given customer review before they are posted on the top of the forum. \nThis way poor quality reviews would not be shown on top of forums.\n\nThe model will be trained on Amazon Reviews for Electronic Category to predict if a given review is helpful or not helpful.","1c7b51e1":"Conclusion:\n--\nThe important quality of this problem statement is the effect of introducing a new key feature to our model. Here, we mainly looked at the TFIDF features generated from Amazon's Electronic Reviews text and added the 'overall_rating' (star rating) that was given to the product by the reviewer. We used these features to predict how 'helpful' other users would find the review.","92d1a7e9":"Since we don't have a separate dataset for testing we are splitting data as 80% for training and 20% for testing.","704edc5c":"Wow! That is a lot of reviews.\n\nNow, let's classify reviews as true or false.\n\nThe true review would one in which the sentiment of star rating matches the sentiment of review text.\n\n If it does not match, then we could say that review is false.","71590a42":"Let's the best estimator for our model.","1805eba7":"Problem Statement\n--\nThe problem that is being addressed here is if Amazon Review is fake or not genuine. Sometimes some people give fake reviews on forums. This could harm the sale of the product if such a review came on top. \n\nBy fake review I mean which is given a 5-star rating but in review text, the person gives a negative review and since it is rated 5 stars, so chances are that review would come on top of the forum. \n\nThe possibility exists that such reviews be given by competitors to harm the sale of the product.\n\nThe solution to this problem is to create a model using machine learning techniques that would classify given customer reviews based on sentiment analysis before they are posted on the top of the forum. This way fake reviews would not be shown on top of forums.\n\nThe model will be trained on Amazon Reviews for Electronic Category to classify if a given review is genuine or not.","49136b98":"# Introduction","076d7ce5":"As we can see, our data did have duplicate reviews. Now let's go-to text preprocessing.","96915b02":"To make a baseline model for our project we are going to use the following algorithms :\n\n* **GaussianNB**: GaussianNB implements the Gaussian Naive Bayes algorithm for classification. In Gaussian Naive Bayes, continuous values associated with each feature are assumed to be distributed according to a Gaussian distribution. \nA Gaussian distribution is also called Normal distribution. When plotted, it gives a bell-shaped curve that is symmetric about the mean of the feature values.\n<img src=\"https:\/\/imgur.com\/nMRnwlL.png\" width=\"400px\">\n\n* **Logistic Regression**: Logistic regression, despite its name, is a linear model for classification rather than regression. Logistic regression is also known in the literature as logit regression, maximum-entropy classification (MaxEnt), or the log-linear classifier\n\n* **Decision tree**: DecisionTreeClassifier is a classifier capable of performing both binary and multi-class classification on a dataset. A Decision tree is a flowchart-like tree structure, where each internal node denotes a test on an attribute, each branch represents an outcome of the test, and each leaf node (terminal node) holds a class label.\n\nAll the algorithms used here are popular algorithms for classification. However, since we are doing binary classification, I think *Logistic Regression* would give better results than *Decision tree* or *Gaussian Naive Bayes*.\n\nFor more information, see [here](https:\/\/scikit-learn.org\/stable\/supervised_learning.html).","d10ce141":"Let's see some stats.","285effb2":"Now let's see the whole data since we are going to creating our model.","8364346e":"Now let's first classify score ratings as Positive, Negative, and Neutral.\n\n> * If the **score rating => 4 or 5**,we are taking it as **Positive**.\n>\n> * If the **score rating => 3**,we are taking it as **Neutral**.\n>\n> * And if the **score rating => 1 or 2**,we are taking it as **Negative**.\n\nThen we are saving the result in a column named **Overall_Sentiment**. This would tell us the sentiment of the review based on the star rating.","b0b5b8da":"Since our reviews may also contain duplicates, we are using the drop_duplicate() function to remove duplicates.\nFor more info,see [here](https:\/\/pandas.pydata.org\/docs\/reference\/api\/pandas.DataFrame.drop_duplicates.html).","796836f9":"Just as we thought Logistic Regression gives us the best accuracy. Its final score for the area under the ROC curve was 0.8704 and a sample size of ~40,000. Besides, it is the fastest. The training speed and prediction speed were 19.993s and 0.955s  for a sample size of 40,000. Since our model has to consider the accuracy and speed, the Logistic Regression algorithm represents the ideal model for us.\n\nNow, let's add values of scores to the review text and see if we can increase the accuracy of our model.","87dad723":"Since we have already prepared the data above. We are now directly applying TF-IDF Vectorizer to generate more features.\nTF-IDF is an acronym of Term Frequency Inverse Document Frequency. It is a statistical measure used to find how important a word is to document in a collection or corpus. It is generally used in text mining and information retrieval.\n\n> TF: Term Frequency, which measures how frequently a term occurs in a document. Since every document is different in length, it may possible that a term would appear much more times in long documents than shorter ones. Thus, the term frequency is often divided by the document length (aka. the total number of terms in the document) as a way of normalization:\n>  \n> TF(t) = (Number of times term t appears in a document) \/ (Total number of terms in the document).\n>  \n> IDF: Inverse Document Frequency, which measures how important a term is. While computing TF, all terms are considered equally important. However, it is known that certain terms, such as \"is\", \"of\", and \"that\", may appear a lot of times but have little importance. Thus we need to weigh down the frequent terms while scaling up the rare ones, by computing the following:\n>  \n> IDF(t) = log_e(Total number of documents \/ Number of documents with term t in it).\n\nTo get more information about TF-IDF see [here](http:\/\/www.tfidf.com\/).","eda286b0":"Since our problem is of binary classification(helpful or not helpful), we are using roc_auc_score to evaluate our model.\n\nThe roc_auc_score computes the area under the receiver operating characteristic (ROC) curve which is also denoted by AUC or AUROC. By computing the area under the roc curve, the curve information is summarized in one number.\n\nThis curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR). The area under the curve is used to give a score to the model.\n> If AUC = 0.5 => TPR = FPR, and the model is doing just random computations.\n>\n> If AUC= 1.0 => TPR = 100%,and it is an ideal model.\n\n* True Positive: the truth is positive, and the test predicts a positive. e.g. The person is sick, and the test accurately reports this.\n* False Positive: the truth is negative, but the test predicts a positive. e.g. The person is not sick, but the test inaccurately reports that they are. It is also called a Type I error in statistics.\n\nFor more information about roc_auc_score,see [here](https:\/\/scikit-learn.org\/stable\/modules\/model_evaluation.html#roc-metrics).\n","2f17e8d7":"Here, since our dataset is huge(about 1687169 records), we are taking only those records that have at least 20 ratings in total.","3c29ab34":"# Conclusion of Project"}}