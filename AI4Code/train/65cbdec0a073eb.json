{"cell_type":{"6da95470":"code","22e02ecb":"code","09be3d00":"code","d8405f94":"code","536c7f50":"code","68694316":"code","7cbe3812":"code","ad9e7f06":"code","97095346":"code","c6ad7826":"code","4f7da6e1":"code","6ebaa18f":"code","f3bb26d7":"code","0df907d5":"code","defac9d4":"code","a2d4d21d":"code","a5fe0321":"code","1cd6dc1c":"code","1587cfc1":"code","3a5cfdc7":"code","1118674d":"code","755e96d5":"code","1ceec6f4":"code","5f0f06cb":"code","801c4944":"code","62169672":"code","564704a5":"code","01f67b14":"code","aa901368":"code","24a78cf5":"code","34be64e4":"code","4a9ad79b":"code","715d449a":"code","7f1bafdb":"code","caf07bb0":"code","23f5a80f":"code","047e0632":"code","bb120190":"code","a4fc7fe7":"code","81d04ec4":"code","0573e0b6":"code","dfc16c2b":"code","dcdd905d":"code","aaf9c368":"code","68b7dff7":"code","1190b736":"code","606c608d":"code","4fd2f11b":"code","b22fda06":"code","d3320cf9":"code","c8fd41f4":"code","4749535e":"code","ec2f3821":"code","ba9bba99":"code","46997c82":"code","18982492":"code","8c0bf330":"markdown","bf1efed7":"markdown","609da01e":"markdown","4869cfcc":"markdown","909ffa55":"markdown","1174312b":"markdown","a970d0a3":"markdown","e70405c9":"markdown","dee16d3e":"markdown","21193a35":"markdown","eb3cdba8":"markdown","547560dd":"markdown","4117f79e":"markdown","626ab433":"markdown","191eec42":"markdown","a56014cd":"markdown","82838640":"markdown","9a091159":"markdown","f9113c23":"markdown","31132fa0":"markdown","514a6a44":"markdown","611b42a5":"markdown"},"source":{"6da95470":"! pip install contractions\n! pip install Unidecode\n! pip install word2number","22e02ecb":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nfrom tqdm.notebook import tqdm as note_book_tqdm\n\nimport contractions\nimport nltk\nfrom wordcloud import WordCloud, STOPWORDS\nfrom unidecode import unidecode\nfrom word2number import w2n\nimport re\n\nnote_book_tqdm.pandas(desc=\"progress: \")\n\nimport tensorflow as tf\nnltk.download('punkt')\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\nprint('TF', tf.__version__)","09be3d00":"plt.rcParams[\"font.size\"] = 16","d8405f94":"df_train = pd.read_csv('..\/input\/shopee-product-matching\/train.csv')","536c7f50":"print('shape', df_train.shape)\ndf_train.head()","68694316":"df_train.info()","7cbe3812":"label_mapper = dict(zip(df_train['label_group'].unique(), np.arange(len(df_train['label_group'].unique()))))\ndf_train['label_group'] = df_train['label_group'].map(label_mapper)","ad9e7f06":"df_train.head()","97095346":"label_groups = df_train['label_group'].value_counts(ascending=False)\nprint('Unique Item Count', len(label_groups))","c6ad7826":"plt.figure(figsize=(20,5))\nplt.plot(np.arange(len(label_groups)),label_groups.values)\nplt.ylabel('LabelGroup Item Count',size=14)\nplt.xlabel('Index of Unique Item',size=14)\nplt.title('Number of items per group',size=16)\nplt.show()","4f7da6e1":"def plot_random_images(images_count):\n    \n    plot_list = df_train['image'].sample(n=images_count).tolist()\n    size = np.sqrt(images_count)\n    if int(size)*int(size) < images_count:\n        size = int(size) + 1\n        \n    plt.figure(figsize=(20, 20))\n    \n    ind=0\n    for image_id in plot_list:\n        plt.subplot(size, size, ind + 1)\n        image = cv2.imread(f'..\/input\/shopee-product-matching\/train_images\/{image_id}', )\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        plt.imshow(image)\n        plt.title(image_id, fontsize=12)\n        plt.axis(\"off\")\n        ind+=1\n    plt.show()","6ebaa18f":"plot_random_images(15)","f3bb26d7":"def plot_group_images(group_id, df):\n    \n    plot_list = df[df['label_group'] == group_id]\n    plot_list = plot_list['image'].tolist()\n    images_count = len(plot_list)\n    size = np.sqrt(images_count)\n    if int(size)*int(size) < images_count:\n        size = int(size) + 1\n        \n    plt.figure(figsize=(20, 20))\n    \n    ind=0\n    for image_id in plot_list:\n        plt.subplot(size, size, ind + 1)\n        image = cv2.imread(f'..\/input\/shopee-product-matching\/train_images\/{image_id}', )\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        plt.imshow(image)\n        plt.title(image_id, fontsize=6)\n        plt.axis(\"off\")\n        ind+=1\n    plt.show()\n    \n    sample = df[df['label_group'] == group_id]\n    print(f'Total number of items in group {group_id}: {len(sample)}, number of unique titles: {sample.nunique()}')","0df907d5":"plt.figure(figsize=(20,5))\nplt.bar(label_groups.index.values[:50].astype('str'), label_groups.values[:50])\nplt.xticks(rotation = 45)\nplt.ylabel('Duplicate Count',size=14)\nplt.xlabel('Label Group',size=14)\nplt.title('Top 50 Duplicated Items',size=16)\nplt.show()","defac9d4":"plot_group_images(106, df_train)","a2d4d21d":"plot_group_images(48, df_train)","a5fe0321":"plot_group_images(307, df_train)","1cd6dc1c":"plot_group_images(979, df_train)","1587cfc1":"plot_group_images(252, df_train)","3a5cfdc7":"plot_group_images(283, df_train)","1118674d":"plot_group_images(714, df_train)","755e96d5":"def remove_duplicated_row(df, col_name):\n    df_removed = df_train.drop_duplicates([col_name])\n    print('Original data size', len(df))\n    print('Reamoved data size', len(df_removed))\n    removed_duplicated_label_groups = df_removed['label_group'].value_counts(ascending=False)\n    print('Original Unique Item Count', len(label_groups))\n    print('Reamoved Unique Item Count', len(removed_duplicated_label_groups))\n    \n    return df_removed","1ceec6f4":"df_removed_same_image = remove_duplicated_row(df_train, 'image')","5f0f06cb":"plot_group_images(979, df_removed_same_image)","801c4944":"df_removed_same_title = remove_duplicated_row(df_train, 'title')","62169672":"plot_group_images(979, df_removed_same_title)","564704a5":"df_removed_same_phash = remove_duplicated_row(df_train, 'image_phash')","01f67b14":"plot_group_images(979, df_removed_same_phash)","aa901368":"def dhash(image_name, hashSize=8):\n    \"\"\"calculation to create a numerical representation of the image.\"\"\"\n    image_path = f'..\/input\/shopee-product-matching\/train_images\/{image_name}'\n    image = cv2.imread(image_path, )\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    resized = cv2.resize(gray, (hashSize + 1, hashSize))\n    diff = resized[:, 1:] > resized[:, :-1]\n    return sum([2 ** i for (i, v) in enumerate(diff.flatten()) if v])","24a78cf5":"df_train.loc[:, 'dhash'] = df_train.image.progress_apply(dhash)","34be64e4":"df_removed_same_dhash = remove_duplicated_row(df_train, 'dhash')","4a9ad79b":"plot_group_images(979, df_removed_same_dhash)","715d449a":"def get_image_shape(image_name):\n    image_path = f'..\/input\/shopee-product-matching\/train_images\/{image_name}'\n    image = cv2.imread(image_path)\n    return image.shape","7f1bafdb":"df_train.loc[:, 'shape'] = df_train.image.progress_apply(get_image_shape)","caf07bb0":"df_train[['width', 'height', 'chanel']] = pd.DataFrame(df_train['shape'].tolist(), index=df_train.index)","23f5a80f":"df_train.head()","047e0632":"images_shape = df_train['shape'].value_counts(ascending=False)\nprint('image shape variations', len(images_shape))\nimages_shape.head(15)","bb120190":"plt.figure(figsize=(10,8))\nplt.scatter(df_train['width'], df_train['height'], alpha=0.3)\nplt.xlabel('image width')\nplt.ylabel('image height')\nplt.show()","a4fc7fe7":"df_train.loc[:, 'title_length'] = df_train.title.progress_apply(lambda x: len(x))","81d04ec4":"df_train.head()","0573e0b6":"title_length = df_train['title_length'].value_counts(ascending=False)\ntitle_length","dfc16c2b":"stop_words = set(stopwords.words('english'))\ndef text_preprocess(title):\n    # Convert Accented Characters\n    title = unidecode(title)\n    # Expand Contractions\n    title = contractions.fix(title)\n    # Lowercase all texts\n    title = title.lower()\n    # Remove special characters\n    title = re.sub(r\"[^a-zA-Z0-9]+\", ' ', title)\n    # title to word list\n    title = word_tokenize(title)\n    # Remove stopwords\n    title = [w for w in title if not w in stop_words]\n    title = ' '.join(title)\n\n\n    return title","dcdd905d":"df_train.loc[:, 'clean_title'] = df_train.title.progress_apply(text_preprocess)","aaf9c368":"df_train.loc[:, 'clean_title_length'] = df_train.clean_title.progress_apply(lambda x: len(x))","68b7dff7":"df_train.head()","1190b736":"clean_title_length = df_train['clean_title_length'].value_counts(ascending=False)\nclean_title_length.head()","606c608d":"fig = plt.figure(figsize=(20, 8))\nfig.suptitle(\"Difference in the number of characters between the original title and the clean title\")\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2)\nax1.set_xlabel('original title length')\nax1.set_ylabel('item count')\nax2.set_xlabel('clean title length')\nax2.set_ylabel('item count')\nax1.bar(clean_title_length.index, clean_title_length.values, width=1, color='b', alpha=0.5)\nax2.bar(title_length.index, title_length.values, width=1, color='r', alpha=0.5)\nplt.show()","4fd2f11b":"test = pd.read_csv('..\/input\/shopee-product-matching\/test.csv')","b22fda06":"check = test.groupby(['title']).count().reset_index()['title'].tolist()\na = []\nb = []\nfor item in check:\n    res = test[test['title']== item]['posting_id'].tolist()\n    ans = \"\"\n    for id_item in res:\n        ans = ans + str(id_item) + \" \"\n    for id_item in res:\n        a.append(id_item)\n        b.append(ans)","d3320cf9":"submission1 = pd.DataFrame()\nsubmission1['posting_id'] = a\nsubmission1['matches'] = b\nsubmission1","c8fd41f4":"check = test.groupby(['image_phash']).count().reset_index()['image_phash'].tolist()\na = []\nb = []\nfor item in check:\n    res = test[test['image_phash']== item]['posting_id'].tolist()\n    ans = \"\"\n    for id_item in res:\n        ans = ans + str(id_item) + \" \"\n    ans = ans[:-1]\n    for id_item in res:\n        a.append(id_item)\n        b.append(ans)","4749535e":"submission2 = pd.DataFrame()\nsubmission2['posting_id'] = a\nsubmission2['matches'] = b\nsubmission2","ec2f3821":"submission2 = pd.DataFrame()\nsubmission2['posting_id'] = a\nsubmission2['matches'] = b\nsubmission2","ba9bba99":"sub = pd.merge(submission1, submission2, on='posting_id', how='inner')\nsub['list'] = sub['matches_x'] + sub['matches_y']\nsub","46997c82":"final = []\nfor index, row in sub.iterrows():\n    res = list(set(row['list'].split(' ')))\n    ans = \"\"\n    for item in res:\n        ans = ans + str(item) + \" \"\n    ans = ans[:-1]\n    final.append(ans)\n    \nsubmission = pd.DataFrame()\nsubmission['posting_id'] = sub['posting_id']\nsubmission['matches'] = final\nsubmission","18982492":"submission.to_csv('submission.csv', index=False)","8c0bf330":"##### Memo\n- the number of data is different for each label group.","bf1efed7":"### Train Data info","609da01e":"#### Same Imgae name","4869cfcc":"### Remove Dupilicated Data","909ffa55":"## Data observation","1174312b":"#### plot random images","a970d0a3":"### Number of items per label group ","e70405c9":"## Setting","dee16d3e":"#### Same title","21193a35":"#### Same dhash","eb3cdba8":"### Distribution of title length","547560dd":"### label_group to index","4117f79e":"# Simple model for the same titles","626ab433":"### Distribution of image shapes","191eec42":"### Visualizing Images","a56014cd":"##### Memo\n- Most of the images are square in shape.\n- The most common size is 640\u2716\ufe0f640","82838640":"## Data Reading","9a091159":"#### Same image_phash","f9113c23":"#### plot group images","31132fa0":"### Train Data shape and sample rows","514a6a44":"##### Memo\n- there are several images that are exactly the same in the same group.","611b42a5":"### (TODO)Analyze the title column\n- wordcloud\n- preporocess\n- etc"}}