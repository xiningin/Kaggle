{"cell_type":{"372ca8e6":"code","be48755c":"code","461a1a55":"code","03b35ddb":"code","98d1503b":"code","373bc041":"code","84f5e3d4":"code","0cbd18fa":"code","b79c915b":"code","a8b373fa":"code","65679944":"code","4fe25188":"code","c2315c51":"code","5a7ef5a1":"code","6d17fb3f":"code","9d82d0f7":"code","0847795d":"code","91a18fc5":"code","503cc6b8":"code","2020de42":"code","96b21352":"code","8aae20d9":"code","7c46741a":"code","9b9b4b4a":"code","afc34eab":"code","cb9bac08":"code","fbb19966":"code","3b9d043d":"code","68bdfb58":"code","2c03b673":"code","39cc0220":"code","bc69157c":"code","c1b96658":"code","53a384a6":"markdown","e6aa588f":"markdown","396bc78f":"markdown","d83cf4a6":"markdown","8a5d059a":"markdown","d2c44e2f":"markdown","1143ed42":"markdown","b25ff919":"markdown","1cc45e9e":"markdown","6091d1bd":"markdown","e88c5078":"markdown","9449f35d":"markdown","50bf5df9":"markdown","3ae8b2de":"markdown","f56e8bee":"markdown","a21d5403":"markdown","2de2cd0a":"markdown","e3efc5d0":"markdown","1075222a":"markdown","b72f89df":"markdown","7a2b9b44":"markdown","d5e39cec":"markdown","ae45be41":"markdown","b03ac5be":"markdown","bfde592f":"markdown","8906230d":"markdown","b6b2ad43":"markdown","9935a7e4":"markdown","3495ec5e":"markdown","d93c500a":"markdown","32d0fa9d":"markdown","55e0e97b":"markdown","8d4146e9":"markdown","c18f793d":"markdown","764d0b92":"markdown","1687774f":"markdown","0803e6b2":"markdown","8196f98d":"markdown","9457cb17":"markdown","34511d55":"markdown","3ff61ff8":"markdown","0d6a0950":"markdown","a50a5bcb":"markdown","47be8f65":"markdown"},"source":{"372ca8e6":"#imports\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n% matplotlib inline\n\nimport os\ndata_path = os.path.join('..\/input','loan.csv')\n\nloan = pd.read_csv(data_path, low_memory=False)\n\n#for predictive analysis\nfrom sklearn.feature_selection import chi2\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier","be48755c":"print(loan.info())","461a1a55":"loan.head(5)","03b35ddb":"missing_val_count_by_column = (loan.isnull().sum())\ntotal_entries = len(loan)*len(loan.columns)\npercent_missing_entries = sum(missing_val_count_by_column)\/total_entries\npercent_missing_columns = len(missing_val_count_by_column[missing_val_count_by_column > 0.8*len(loan)])\/len(loan.columns)\n\nprint(\"Total missing entries:\")\nprint(sum(missing_val_count_by_column),'\\n')\nprint(\"Percentage of missing entries:\")\nprint(percent_missing_entries*100, '\\n')\nprint(\"Percentage of columns with more than 80 percent missing values:\")\nprint(percent_missing_columns*100, '\\n')\nprint(\"Columns with more than 80 percent missing values:\")\nprint(missing_val_count_by_column[missing_val_count_by_column > 0.8*len(loan)])","98d1503b":"loan['date_time'] = pd.to_datetime(loan['issue_d'])","373bc041":"plt.figure(figsize=(14,5))\n\nfor x in ['loan_amnt','funded_amnt','funded_amnt_inv']:\n    loan.groupby('date_time').mean()[x].plot(label=x)\n\nplt.title('Mean of Loan Amounts')\nplt.xlabel('Year')\nplt.ylabel('Dollars')\nplt.legend(loc='center left', bbox_to_anchor = (1,0.5))","84f5e3d4":"plt.figure(figsize=(14,5))\n\nloan.groupby('date_time').mean()['int_rate'].plot()\n\nplt.title('Mean of Interest Rate (%)')\nplt.xlabel('Year')\nplt.ylabel('%')","0cbd18fa":"plt.figure(figsize=(14,5))\n\nloan.groupby('date_time').std()['int_rate'].plot()\n\nplt.title('Standard Deviation of Interest Rate (%)')\nplt.xlabel('Year')\nplt.ylabel('%')","b79c915b":"plt.figure(figsize=(14,5))\n\nloan.groupby('date_time').median()['int_rate'].plot()\n\nplt.title('Median of Interest Rate (%)')\nplt.xlabel('Year')\nplt.ylabel('%')","a8b373fa":"loan['year'] = loan['date_time'].dt.year","65679944":"plt.figure(figsize=(12,5))\nloan.groupby('year').count()['loan_status'].plot()\nplt.xlabel('Year')\nplt.ylabel('Count')\nplt.title('Number of Loans')","4fe25188":"plt.figure(figsize=(15,8))\nsns.countplot(x='year',hue='loan_status',data=loan)\nplt.title('Loan Status')\nplt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))","c2315c51":"print('Count of Loan Status:')\nprint(loan['loan_status'].value_counts(), '\\n')\nprint('Proportion of Fully Paid Loans (amongst completed loans):')\nprint(loan['loan_status'].value_counts()['Fully Paid']\/np.sum([loan['loan_status'] != 'Current'])*100)","5a7ef5a1":"def fully_paid(x):\n    if x == 'Fully Paid':\n        return int(1)\n    else:\n        return int(0)","6d17fb3f":"completed_loan = loan.copy()\ncompleted_loan = completed_loan[completed_loan['loan_status'] != 'Current']\ncompleted_loan['fully_paid_dummy'] = completed_loan['loan_status'].apply(fully_paid)","9d82d0f7":"plt.figure(figsize=(15,8))\nsns.countplot(x='year',hue='grade',data=completed_loan,hue_order=['A','B','C','D','E','F','G'])\nplt.title('Grade')\nplt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))","0847795d":"print(completed_loan.groupby('grade')['fully_paid_dummy', 'int_rate'].mean())","91a18fc5":"print('Summary Stats for Annual Income (amongst completed loans):')\nprint(completed_loan.describe()['annual_inc'])","503cc6b8":"# Creating bins for income\n\np1 = np.nanpercentile(np.array(completed_loan['annual_inc']),25)\np2 = np.nanpercentile(np.array(completed_loan['annual_inc']),50)\np3 = np.nanpercentile(np.array(completed_loan['annual_inc']),75)\n\n\ndef income_bin(x):\n    if x <= p1:\n        return 'Low'\n    elif x <= p2:\n        return 'Middle_Low'\n    elif x <= p3:\n        return 'Middle_High'\n    else:\n        return 'High'","2020de42":"completed_loan['income_group'] = completed_loan['annual_inc'].apply(income_bin)","96b21352":"print(completed_loan.groupby(['income_group','home_ownership'])['fully_paid_dummy','int_rate'].mean().sort_values('fully_paid_dummy', ascending = False))","8aae20d9":"print(completed_loan.groupby('home_ownership')['fully_paid_dummy','int_rate'].mean().sort_values('int_rate', ascending = False))","7c46741a":"west = ['CA', 'OR', 'UT','WA', 'CO', 'NV', 'AK', 'MT', 'HI', 'WY', 'ID']\nsouth_west = ['AZ', 'TX', 'NM', 'OK']\nsouth_east = ['GA', 'NC', 'VA', 'FL', 'KY', 'SC', 'LA', 'AL', 'WV', 'DC', 'AR', 'DE', 'MS', 'TN' ]\nmid_west = ['IL', 'MO', 'MN', 'OH', 'WI', 'KS', 'MI', 'SD', 'IA', 'NE', 'IN', 'ND']\nnorth_east = ['CT', 'NY', 'PA', 'NJ', 'RI','MA', 'MD', 'VT', 'NH', 'ME']\n\ndef main_region(x):\n    if x in west:\n        return 'West'\n    elif x in south_west:\n        return 'South West'\n    elif x in south_east:\n        return 'South East'\n    elif x in mid_west:\n        return 'Mid West'\n    else:\n        return 'North East'","9b9b4b4a":"completed_loan['main_region'] = completed_loan['addr_state'].apply(main_region)","afc34eab":"print(completed_loan.groupby('main_region')['fully_paid_dummy', 'int_rate'].mean().sort_values('fully_paid_dummy',ascending = False))","cb9bac08":"print(completed_loan.groupby('purpose')['fully_paid_dummy', 'int_rate'].mean().sort_values('fully_paid_dummy',ascending = False))","fbb19966":"def get_int(x):\n    if x == '10+ years':\n        return int(10)\n    elif x == np.nan:\n        return np.nan\n    else: \n        tokens = x.split()\n        for s in tokens:\n            if s.isdigit():\n                return int(s)\n        ","3b9d043d":"completed_loan['emp_int'] = completed_loan['emp_length'].astype(str).apply(get_int)\n\nprint(completed_loan.groupby('purpose')['fully_paid_dummy', 'int_rate'].mean().sort_values('fully_paid_dummy',ascending = False))","68bdfb58":"# cleaning up data \n\ncompleted_loan['term int'] = completed_loan['term'].apply(get_int)\n\n\n# remove columns with more than 10% missing values\ncols_with_missing = [col for col in completed_loan.columns \n                                 if completed_loan[col].isnull().sum() > 0.1*len(completed_loan)]\n\nreduced_df = completed_loan.drop(cols_with_missing, axis = 1)\n\n# drop irrelevant columns\nreduced_df.drop(['term','emp_length','emp_title','zip_code', 'addr_state','earliest_cr_line',\n        'disbursement_method','year','date_time','total_rec_late_fee', 'policy_code','num_tl_120dpd_2m',\n                'last_pymnt_d','last_credit_pull_d','loan_status','issue_d','title'],axis=1,inplace=True)\n\n# encoded categorical variables\ndummies = pd.get_dummies(reduced_df.select_dtypes(include='object'),drop_first=True)\n\n\n# training data\ntrain = pd.concat([reduced_df.select_dtypes(exclude='object'), dummies], axis = 1).dropna(axis=0)","2c03b673":"x_train = train.drop('fully_paid_dummy', axis = 1)\n\ny = train['fully_paid_dummy']","39cc0220":"# Setup\nn_folds = 5\nskf = StratifiedKFold(n_splits=n_folds, random_state=1, shuffle=True)\ny_oof = y*0 \nfeat_impt = 0\nmodel = RandomForestClassifier(n_estimators=50,random_state=0)","bc69157c":"print(\"\\n Begin Setting up cv. Executing {} folds cross validation \\n\".format(n_folds))\nfor i, (train_index,test_index) in enumerate(skf.split(x_train,y)):\n        \n    y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n    X_train, X_valid = x_train.iloc[train_index], x_train.iloc[test_index]\n    print(\"\\n Starting: fold {}\".format(i+1))\n        \n    # fit model\n    model.fit(X_train,y_train)\n    \n    # predict\n    oof_pred = model.predict(X_valid)\n    print('Accuracy Score:',accuracy_score(y_valid,oof_pred), '\\n')\n    print('Classification Report:','\\n', classification_report(y_valid,oof_pred))\n    \n    # save\n    y_oof.iloc[test_index] = oof_pred\n    feat_impt += feat_impt + model.feature_importances_","c1b96658":"feat_impt = pd.DataFrame(feat_impt,index=x_train.columns)\nfeat_impt.columns = ['Feature Importance']\nplt.figure(figsize=(15,8))\nsns.barplot(x=feat_impt.sort_values(by='Feature Importance',ascending=False).head(10).index,\n            y=feat_impt.sort_values(by='Feature Importance',ascending=False)['Feature Importance'].head(10),\n            palette='viridis')\nplt.tight_layout()","53a384a6":"A decoupling of the interest rates is observed, where the middle-income group of borrowers with no home ownership had larger good loan outcomes but held higher interest rates. \n>It appears that home ownership seems to be a key variable in determining interest levels for a loan contract, and that is independent of probability of loan outcome.","e6aa588f":"## Possible Bias","396bc78f":"Using mean and standard deviation as aggregate measures, we will look at some loan-specific variables to identify patterns in the data over time. We shall focus on loan amounts and interest rates of loans as a starting point.","d83cf4a6":"There appears to be no discrepancies in the different regions across America to which loan have been made out to.","8a5d059a":"### **Interest Rate (of loans)**","d2c44e2f":"Because repeated cross-sectional data comprise of different loans issued to different borrowers over time, it should be used to analyse changes in the loans issued or borrowers over time. It cannot be used to look at individual change. For example, we can draw conclusions on how the overall composition of \u2018home_ownership\u2019 of the borrowers has changed over time but we cannot deduce how the \u2018home_ownership\u2019 for a given borrower has changed over time. To study the aggregate change over time, we can:\n* Construct panel at a more aggregated level\n* Use time-series aspects to compare the different groups of loans\/borrowers\n","1143ed42":"We also observe that a majority (70%) of the completed loans, those that are not \u2018current\u2019, are fully paid. \n\n> As such, there is an imbalance in loan status amongst the completed loans. ","b25ff919":"<h1 align=\"center\"> Predictive Analysis <\/h1> <br>","1cc45e9e":"The simplest option to handle missing values would be to remove columns or rows with missing values. A better option, however, would be to impute the missing values \u2013 using an aggregate measure or regression. A kernel on approaches to handle missing values can be found [here](https:\/\/www.kaggle.com\/alexisbcook\/missing-values).\n","6091d1bd":"### **Loan Amounts**","e88c5078":"## Data Structure\n\nThe loans issued are indexed in time order, and across time, different loans are issued to different individuals. In other words, we are dealing with a repeated cross-sectional data.","9449f35d":"### **Region**","50bf5df9":"<h1 align=\"center\"> Visual Inspection <\/h1> <br>","3ae8b2de":"## Loans Characteristics","f56e8bee":"### **Loan Status**","a21d5403":"<h1 align=\"center\"> Loan Status Analysis <\/h1> <br>","2de2cd0a":"## Causality vs Correlation","e3efc5d0":"Amongst the top 10 predictors identified through RFC to hold higher importance in capturing loan outcomes, 4 of them were recovery-related features. It is further intuitive to mention that debt-recovery only occurs when the loan contract has already gone \u2018bad\u2019. However, we are much more interested in identifying a \u2018bad\u2019 loan before it turns \u2018bad\u2019. \n> Thus, the features within our dataset might not hold strong form metrics in terms of predicting loan outcomes ex ante. \n","1075222a":"Key observations:\n* Overall, **mean loan amounts have increased across time**\n* **Large variations between 2007 and 2009:** average loan amount first doubled from 2007 to 2008 then dropped by half in mid-2008 before increasing from mid-2008 onwards. This \u2018unusual\u2019 behaviour could be attributed to the subprime mortgage which coincides with the timeframe. \n* **The three curves converge after 2011:** this could be inferred as an increase in investor confidence, where borrowers were more likely to have received entire loan amounts demanded after 2011 as compared to before. ","b72f89df":"We observe an exponential increase in the number of loan contracts made out between 2008 and 2015, followed by a gentler increase before picking up again from 2017 to 2019. This clearly means that the dataset we are dealing with is skewed to the later part of the timeframe. ","7a2b9b44":"<h1 align=\"center\"> A Primer on the LendingClub Loan Data <\/h1> <br>\n\nI hope this kernel will help you build a broader perspective in observation for deeper exploration. This kernel also serve as a means of reflection, and to receive feedback from readers.\n\n## Abstract\n\nLendingClub is a US peer-to-peer lending company, headquartered in San Francisco, California. The data we are dealing with is a matrix of approximately 2 million observations with 145 variables capturing information on LendingClub\u2019s issued loans from 2007 to 2019. \n\n## Motivation\n\nBefore we can perform any prediction or prescriptive modelling, we first try to read and understand the data with descriptive analysis. Descriptive analyses enable us to present the data in a more intuitive manner which allows for simpler interpretations. Specifically, descriptive analyses allow us to understand the distribution of the data or identify interesting patterns which may be relevant to our ultimate objective and aim we want to achieve with the data. \n\n","d5e39cec":"Observe that \"none\" has the highest mean interest rate despite having the 2nd highest rate of good loan.****","ae45be41":"Here we identify variables of interest to be the loan grade of the borrower, home ownership and income, region, and finally, purpose of loan. We will study possible correlation between loan status and the variables of interest. \n\n> Dummy variables were assigned to the samples of completed loans as (1) a 'Fully Paid' loans and (0) \u2018otherwise\u2019.","b03ac5be":"> Given that each loan already has an \u2018assigned grade\u2019, it appears that LendingClub already has in place some form of screening before approving a loan request. It is likely that the dataset only comprises of borrowers that have already passed an initial \u201cscreening\u201d by LC which introduces bias in the dataset. Thus, the use of dataset for deeper analyses would be more suited for monitoring approved loans \u2013 narrowing the scope of loans to monitor.","bfde592f":"## Aggregate Measures","8906230d":"As a control, we can plot the median of interest rate to check if there are extreme values which may have skewed the mean plot. In short, the median and mean plot appears to have similar shapes and scale.","b6b2ad43":"### **Feature Importance**","9935a7e4":"### **Employment Length**","3495ec5e":"It is also clear that purpose is correlated with the rate of a loan being fully paid. One surprising observation would be that educational loans are doing the worst. This could possibly be due to the fact that students usually do not command incomes.","d93c500a":"<h1 align=\"center\"> Descriptive Analysis <\/h1> <br>","32d0fa9d":"> *The growth in number of loan contracts could be attributed to the growth path of the firm. For example, LC issued an IPO later in 2014 and that could be ascribed to the sharp increase in number of loan contracts made out between 2012 to 2015, if there was a certain KPI attached to these numbers. *","55e0e97b":"The variables fitted produced an average accuracy score of 99.76%.","8d4146e9":"> A casual observer looking at a strong correlation between variables and the outcome of loan may be tempted to conclude that, for instance, educational loans are riskier because it is negatively correlated with the outcome of being a good loan. This, however, is an unwarranted conclusion because correlation is not a statement of causality. Because correlation only measures direction and magnitude of change between two variables, it could be the case where the two variables are directly unrelated but are affected by a third variable that links to one another. That being said, correlation is often helpful in the exploratory data analysis phase to help us identify variables of interests. ","c18f793d":"### **Number of Loans**","764d0b92":"Let's try to fit a predictive model to our data. As a baseline model, we won't be putting much emphasis on feature engineering and feature selection. ","1687774f":"Interest rate standard deviations have also been increasing overtime and this can be implied as an increase in the diversity of borrowers.","0803e6b2":"### **Grade**","8196f98d":"### **Income & Home Ownership**","9457cb17":"We understand that loan grades are formed based on a pre-assessment of the borrower, and as it turns out, borrowers with higher loan grading had the largest concentration of good outcomes. This implies that LendingClub\u2019s assigned loan grade to their respective borrowers have been internally consistent. Interest rates are also seen to be lower in contracts made out to higher grading borrowers.","34511d55":"## Missing Values\n\nMissing values are non-trivial as columns or rows with many missing values are usually biased and thus, may be not representative of the whole dataset. About 33% of the entries are missing while 27% of the columns have more than 80% of missing values.\n","3ff61ff8":"The mean of interest rate appears to follow a head and shoulders pattern with a upper bound of approximately 13 percent before 2011 followed by a peak of 15 percent in 2013 and then decrease from 2013 to 2016. One possible interpretation would be considering interest rate on loans to be a proxy for the \"price\" for loans. After all, interest rate is the cost of loan for borrowers. \n\n> It is likely that interest rates remained low during the subprime mortage crisis from 2007 to 2009 and started to increase from 2011 as the economy began to recover.","0d6a0950":"There is a large number of current loans dating back to 2014. In this sense, we are not able to identify the distribution of loan status since we do not know the outcome of these ongoing loans. \n\n> From 2007 to 2015, we can say with certain that the number of fully paid loans has increased during the period. However, we cannot extend this inference from 2015 onwards due to the sizable proportion of ongoing loans.\n\n","a50a5bcb":"### **Purpose**","47be8f65":"<h1 align=\"center\"> Final Words <\/h1> <br>"}}