{"cell_type":{"e23aff6f":"code","3490638b":"code","471e1e52":"code","e5b6a698":"code","28298ebf":"code","52fe77fe":"code","bcf9707a":"code","0fb3d21f":"code","643a5551":"code","df2b095b":"code","0fd38fe1":"code","0824237d":"code","dcc2605f":"code","f2b529be":"code","1cae6d19":"code","a71fe289":"code","11a4a0de":"code","88f84c7a":"code","1d43a688":"code","17618b0d":"code","c48ce2a2":"code","3de71abb":"code","80924935":"code","5765b941":"code","f92c84a3":"code","3b41c5e8":"markdown","3131d26c":"markdown"},"source":{"e23aff6f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3490638b":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline ","471e1e52":"#data\ntrain = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","e5b6a698":"#create duplicates\ntrain_data = train.copy()\ntest_data = test.copy()","28298ebf":"train_data.shape,test_data.shape","52fe77fe":"train_data.head()","bcf9707a":"target = train_data['label']\ntrain_data.drop('label',axis=1,inplace=True)","0fb3d21f":"target.value_counts()","643a5551":"sns.countplot(target);","df2b095b":"#import keras\nfrom keras import models\nfrom keras.layers import Conv2D,MaxPool2D,Dropout,Flatten,Dense,BatchNormalization","0fd38fe1":"model = models.Sequential()\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.1))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","0824237d":"model.summary()","dcc2605f":"X = train_data.to_numpy()\ny = target.to_numpy()\ntest_data = test_data.to_numpy()","f2b529be":"X = X.astype('float32')\ntest_data = test_data.astype('float32')\ny = y.astype('float32')","1cae6d19":"#normalizing\nX = X\/255\ntest_data = test_data\/255","a71fe289":"X = X.reshape(-1,28,28,1)\ntest_data = test_data.reshape(-1,28,28,1)","11a4a0de":"from keras.utils import to_categorical\ny = to_categorical(y)","88f84c7a":"model.compile(optimizer='Adam',\n           loss='categorical_crossentropy',\n           metrics=['accuracy'])","1d43a688":"model.fit(X, y, epochs=10, batch_size=32)","17618b0d":"from keras.preprocessing.image import ImageDataGenerator\ngenerator = ImageDataGenerator(\n        featurewise_center=False,\n        samplewise_center=False,\n        featurewise_std_normalization=False,\n        samplewise_std_normalization=False,\n        zca_whitening=False,\n        rotation_range=10,\n        zoom_range = 0.1, \n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        horizontal_flip=False,\n        vertical_flip=False)","c48ce2a2":"generator.fit(X)","3de71abb":"from keras.callbacks import ReduceLROnPlateau\nlearning_rate_decay = ReduceLROnPlateau(monitor='accuracy', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","80924935":"model.fit_generator(generator.flow(X,y, batch_size=32),\n                    epochs = 30,verbose = 2, steps_per_epoch=X.shape[0] \/\/ 32,callbacks=[learning_rate_decay])","5765b941":"ypreds = model.predict(test_data)\npreds = np.argmax(ypreds,axis = 1)","f92c84a3":"submit=pd.DataFrame()\nsubmit['ImageId']=range(1,28001)\nsubmit['Label']=preds\nsubmit.to_csv('submit.csv',index=False)","3b41c5e8":"without batch normalization layer i ended with public score:0.9955\nand\nwith batch normalization layer it is 0.9945","3131d26c":"Without data augmentation i obtained public score: 0.99128"}}