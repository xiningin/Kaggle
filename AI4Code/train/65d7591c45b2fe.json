{"cell_type":{"f04122f3":"code","decb15e3":"code","97e401f6":"code","a16053cf":"code","43504b73":"code","596f498f":"code","bf2a8d70":"code","bc5c9edd":"code","7419d068":"code","745ce5f5":"code","0aa14133":"code","4a40479a":"code","046f7b40":"code","03bc3828":"code","4dde8065":"code","56df454f":"code","2174505c":"code","ad5e8704":"code","6e376c5a":"code","fe984cc9":"code","f16353c1":"code","adf84f4e":"code","4e38cb0f":"code","097b7524":"code","188087d3":"code","dc10a77a":"code","da8dff34":"code","f170fdf7":"code","38b63121":"code","4875394d":"code","7a18a4af":"code","c5a5a811":"code","885c2fe6":"code","0661f9dd":"code","1ace1013":"code","512169df":"code","7a78fbbe":"code","3f74da6b":"code","0b2a65a8":"code","37754c7f":"code","8d414037":"code","47ee12fb":"code","b19c1427":"code","5fcb0fd3":"code","a26f0df9":"code","9fd388f0":"code","734f3194":"code","5bf7b022":"code","adf66b6c":"code","4eac414f":"code","536b1fa9":"code","20e61f44":"code","a77faf15":"code","c2bda738":"code","4fd2b3d7":"code","0750d373":"code","5bb24de8":"code","12810316":"code","a6ec070f":"code","b602f133":"code","33523901":"code","f41fbe18":"code","2d6945e6":"code","b916453e":"code","e5f28f3a":"code","3d0b7e3a":"code","e8e78cd7":"code","3c4ba3ea":"code","ffbe7a12":"code","73ee7794":"code","9a91a7a6":"code","bffb9c1a":"code","8128aedc":"code","b33d58b5":"code","ec7229a2":"code","5b73227f":"code","3e409567":"code","a081dedc":"code","1ad6b04e":"code","78731702":"code","2e5e1149":"code","bc8079fe":"code","ea1d17cf":"code","94113a4b":"markdown","50defac6":"markdown","f0268be1":"markdown"},"source":{"f04122f3":"import numpy as np # linear algebra\nimport pandas as pd \nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport matplotlib as mpl\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport matplotlib.colors as mcolors\n\nimport operator \nimport random\n\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Input, Dropout, Dense, Embedding, SpatialDropout1D, concatenate, BatchNormalization, Flatten\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.preprocessing import text, sequence\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.losses import mean_squared_error as mse_loss\n\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.optimizers import RMSprop, Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau","decb15e3":"data=pd.read_csv('https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_confirmed_global.csv')","97e401f6":"data.head()","a16053cf":"data.describe()","43504b73":"def reduce_mem_usage(df):\n    start_mem_usg = df.memory_usage().sum() \/ 1024**2 \n    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n    NAlist = [] # Keeps track of columns that have missing values filled in. \n    for col in df.columns:\n        if df[col].dtype != object:  # Exclude strings            \n            # Print current column type\n            print(\"******************************\")\n            print(\"Column: \",col)\n            print(\"dtype before: \",df[col].dtype)            \n            # make variables for Int, max and min\n            IsInt = False\n            mx = df[col].max()\n            mn = df[col].min()\n            print(\"min for this col: \",mn)\n            print(\"max for this col: \",mx)\n            # Integer does not support NA, therefore, NA needs to be filled\n            if not np.isfinite(df[col]).all(): \n                NAlist.append(col)\n                df[col].fillna(mn-1,inplace=True)  \n                   \n            # test if column can be converted to an integer\n            asint = df[col].fillna(0).astype(np.int64)\n            result = (df[col] - asint)\n            result = result.sum()\n            if result > -0.01 and result < 0.01:\n                IsInt = True            \n            # Make Integer\/unsigned Integer datatypes\n            if IsInt:\n                if mn >= 0:\n                    if mx < 255:\n                        df[col] = df[col].astype(np.uint8)\n                    elif mx < 65535:\n                        df[col] = df[col].astype(np.uint16)\n                    elif mx < 4294967295:\n                        df[col] = df[col].astype(np.uint32)\n                    else:\n                        df[col] = df[col].astype(np.uint64)\n                else:\n                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n                        df[col] = df[col].astype(np.int8)\n                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n                        df[col] = df[col].astype(np.int16)\n                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n                        df[col] = df[col].astype(np.int32)\n                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n                        df[col] = df[col].astype(np.int64)    \n            # Make float datatypes 32 bit\n            else:\n                df[col] = df[col].astype(np.float32)\n            \n            # Print new column type\n            print(\"dtype after: \",df[col].dtype)\n            print(\"******************************\")\n    # Print final result\n    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n    mem_usg = df.memory_usage().sum() \/ 1024**2 \n    print(\"Memory usage is: \",mem_usg,\" MB\")\n    print(\"This is \",100*mem_usg\/start_mem_usg,\"% of the initial size\")\n    return df, NAlist","596f498f":"train=data\nb=len(train)\nprint(\"total examples:\",b)\nfor col in train.columns:\n  a=train[col].isna().sum()\n  c=(a\/b)*100\n  print(col, \"has\", a ,\"NaN's with\",c,\"percentage\")","bf2a8d70":"fig, ax = plt.subplots(figsize=(50,25))\n# use a ranked correlation to catch nonlinearities\ncorr = train[[col for col in train.columns]].corr(method='spearman')\n_ = sns.heatmap(corr, annot=True,\n                xticklabels=corr.columns.values,\n                yticklabels=corr.columns.values)","bc5c9edd":"confirmed=data\ndates = confirmed.keys()\ndates","7419d068":"confirmed_df=data\ncols = confirmed_df.keys()\nconfirmed=data.loc[:, cols[4]:cols[-1]]\ndates = confirmed.keys()\n\nworld_cases = []\n\nchina_cases = [] \nitaly_cases = []\nus_cases = [] \nindia_cases= []\nspain_cases = [] \n\nfor i in dates:\n    confirmed_sum = confirmed[i].sum()\n   \n    world_cases.append(confirmed_sum)\n    \n\n    # case studies \n    china_cases.append(confirmed_df[confirmed_df['Country\/Region']=='China'][i].sum())\n    italy_cases.append(confirmed_df[confirmed_df['Country\/Region']=='Italy'][i].sum())\n    india_cases.append(confirmed_df[confirmed_df['Country\/Region']=='India'][i].sum())\n    us_cases.append(confirmed_df[confirmed_df['Country\/Region']=='US'][i].sum())\n    spain_cases.append(confirmed_df[confirmed_df['Country\/Region']=='Spain'][i].sum())","745ce5f5":"def daily_increase(data):\n    d = [] \n    for i in range(len(data)):\n        if i == 0:\n            d.append(data[0])\n        else:\n            d.append(data[i]-data[i-1])\n    return d \n\nworld_daily_increase = daily_increase(world_cases)\nchina_daily_increase = daily_increase(china_cases)\nitaly_daily_increase = daily_increase(italy_cases)\nus_daily_increase = daily_increase(us_cases)\nspain_daily_increase = daily_increase(spain_cases)\nindia_daily_increase = daily_increase(india_cases)","0aa14133":"days_since_1_22 = np.array([i for i in range(len(dates))]).reshape(-1, 1)\n","4a40479a":"days_in_future = 10\nfuture_forcast = np.array([i for i in range(len(dates)+days_in_future)]).reshape(-1, 1)\nadjusted_dates = future_forcast[:-10]","046f7b40":"type(world_cases)","03bc3828":"x = []\nfor sublist in adjusted_dates:\n    for item in sublist:\n        x.append(item)\n\n#x=adjusted_dates.tolist()\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=x, y=world_cases,mode='lines+markers',name='Confirmed cases'))\nfig.update_layout(title='Coronavirus Cases Over Time',xaxis_title=\"Days Since 1\/22\/2020\",\n    yaxis_title=\"Number of cases\",)\nfig.update_yaxes(nticks=20)\nfig.update_xaxes(nticks=36)\nfig.show()","4dde8065":"fig = go.Figure()\nfig.add_trace(go.Bar(y=world_daily_increase,name='Confirmed cases'))\nfig.update_layout(title='Coronavirus Cases Increasing Over Time',xaxis_title=\"Days Since 1\/22\/2020\",\n    yaxis_title=\"Number of cases\",)\nfig.update_yaxes(nticks=20)\nfig.update_xaxes(nticks=36)\nfig.show()","56df454f":"fig = go.Figure()\nfig.add_trace(go.Bar(y=china_daily_increase,name='Confirmed cases'))\nfig.update_layout(title='Coronavirus Cases Increasing Over Time in China',xaxis_title=\"Days Since 1\/22\/2020\",\n    yaxis_title=\"Number of cases\",)\nfig.update_yaxes(nticks=20)\nfig.update_xaxes(nticks=36)\nfig.show()","2174505c":"fig = go.Figure()\nfig.add_trace(go.Bar(y=italy_daily_increase,name='Confirmed cases'))\nfig.update_layout(title='Coronavirus Cases Increasing Over Time in Italy',xaxis_title=\"Days Since 1\/22\/2020\",\n    yaxis_title=\"Number of cases\",)\nfig.update_yaxes(nticks=20)\nfig.update_xaxes(nticks=36)\nfig.show()","ad5e8704":"fig = go.Figure()\nfig.add_trace(go.Bar(y=us_daily_increase,name='Confirmed cases'))\nfig.update_layout(title='Coronavirus Cases Increasing Over Time in US',xaxis_title=\"Days Since 1\/22\/2020\",\n    yaxis_title=\"Number of cases\",)\nfig.update_yaxes(nticks=20)\nfig.update_xaxes(nticks=36)\nfig.show()","6e376c5a":"fig = go.Figure()\nfig.add_trace(go.Bar(y=spain_daily_increase,name='Confirmed cases'))\nfig.update_layout(title='Coronavirus Cases Increasing Over Time in Spain',xaxis_title=\"Days Since 1\/22\/2020\",\n    yaxis_title=\"Number of cases\",)\nfig.update_yaxes(nticks=20)\nfig.update_xaxes(nticks=36)\nfig.show()","fe984cc9":"fig = go.Figure()\nfig.add_trace(go.Bar(y=india_daily_increase,name='Confirmed cases'))\nfig.update_layout(title='Coronavirus Cases Increasing Over Time in India',xaxis_title=\"Days Since 1\/22\/2020\",\n    yaxis_title=\"Number of cases\",)\nfig.update_yaxes(nticks=20)\nfig.update_xaxes(nticks=36)\nfig.show()","f16353c1":"#x=adjusted_dates.tolist()\nfig = go.Figure()\n\n\nfig.add_trace(go.Scatter(x=x, y=india_cases,mode='lines+markers',name=\"India's cases\"))\n\n\nfig.update_layout(title='Coronavirus Cases Over Time In India',xaxis_title=\"Days Since 1\/22\/2020\",\n    yaxis_title=\"Number of cases\",)\nfig.update_yaxes(nticks=20)\nfig.update_xaxes(nticks=36)\nfig.show()","adf84f4e":"#x=adjusted_dates.tolist()\nfig = go.Figure()\n\n#fig.add_trace(go.Scatter(x=x, y=world_cases,mode='lines+markers',name='Totla cases'))\nfig.add_trace(go.Scatter(x=x, y=china_cases,mode='lines+markers',name=\"China's cases\"))\nfig.add_trace(go.Scatter(x=x, y=india_cases,mode='lines+markers',name=\"India's cases\"))\nfig.add_trace(go.Scatter(x=x, y=us_cases,mode='lines+markers',name=\"USA's cases\"))\nfig.add_trace(go.Scatter(x=x, y=italy_cases,mode='lines+markers',name=\"Italy's cases\"))\nfig.add_trace(go.Scatter(x=x, y=spain_cases,mode='lines+markers',name=\"Spain's cases\"))\n\nfig.update_layout(title='Coronavirus Cases Over Time',xaxis_title=\"Days Since 1\/22\/2020\",\n    yaxis_title=\"Number of cases\",)\nfig.update_yaxes(nticks=20)\nfig.update_xaxes(nticks=36)\nfig.show()","4e38cb0f":"#x=adjusted_dates.tolist()\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(x=x, y=world_cases,mode='lines+markers',name='Total cases'))\nfig.add_trace(go.Scatter(x=x, y=china_cases,mode='lines+markers',name=\"China's cases\"))\nfig.add_trace(go.Scatter(x=x, y=india_cases,mode='lines+markers',name=\"India's cases\"))\nfig.add_trace(go.Scatter(x=x, y=us_cases,mode='lines+markers',name=\"USA's cases\"))\nfig.add_trace(go.Scatter(x=x, y=italy_cases,mode='lines+markers',name=\"Italy's cases\"))\nfig.add_trace(go.Scatter(x=x, y=spain_cases,mode='lines+markers',name=\"Spain's cases\"))\n\nfig.update_layout(title='Coronavirus Cases Over Time',xaxis_title=\"Days Since 1\/22\/2020\",\n    yaxis_title=\"Number of cases\",)\nfig.update_yaxes(nticks=20)\nfig.update_xaxes(nticks=36)\nfig.show()","097b7524":"unique_countries =  list(confirmed_df['Country\/Region'].unique())\ncountry_confirmed_cases = []\nlatest_confirmed = confirmed_df[dates[-1]]\nno_cases = []\nfor i in unique_countries:\n    cases = latest_confirmed[confirmed_df['Country\/Region']==i].sum()\n    if cases > 0:\n        country_confirmed_cases.append(cases)\n    else:\n        no_cases.append(i)\n        \nfor i in no_cases:\n    unique_countries.remove(i)\n    \n# sort countries by the number of confirmed cases\nunique_countries = [k for k, v in sorted(zip(unique_countries, country_confirmed_cases), key=operator.itemgetter(1), reverse=True)]\nfor i in range(len(unique_countries)):\n    country_confirmed_cases[i] = latest_confirmed[confirmed_df['Country\/Region']==unique_countries[i]].sum()","188087d3":"# number of cases per country\/region\nprint('Confirmed Cases by Countries\/Regions:')\nfor i in range(len(unique_countries)):\n    print(f'{unique_countries[i]}: {country_confirmed_cases[i]} cases')","dc10a77a":"visual_unique_countries = [] \nvisual_confirmed_cases = []\nothers = np.sum(country_confirmed_cases[10:])\n\nfor i in range(len(country_confirmed_cases[:10])):\n    visual_unique_countries.append(unique_countries[i])\n    visual_confirmed_cases.append(country_confirmed_cases[i])\n    \nvisual_unique_countries.append('Others')\nvisual_confirmed_cases.append(others)","da8dff34":"plt.figure(figsize=(16, 9))\nplt.barh(visual_unique_countries, visual_confirmed_cases)\nplt.title('# of Covid-19 Confirmed Cases in Countries\/Regions', size=20)\nplt.xticks(size=20)\nplt.yticks(size=20)\nplt.show()","f170fdf7":"full_table = confirmed_df.melt(id_vars=[\"Province\/State\", \"Country\/Region\", \"Lat\", \"Long\"], var_name=\"Date\", value_name=\"Confirmed\")\n\nfull_table['Date'] = pd.to_datetime(full_table['Date'])\nfull_table.head()","38b63121":"len(full_table)","4875394d":"full_table.head()","7a18a4af":"data=full_table.drop(['Lat','Long'],axis=1)","c5a5a811":"data['days']=(data['Date']-pd.to_datetime(\"2020-01-22\")).dt.days","885c2fe6":"data.tail()","0661f9dd":"data['Confirmed'].max()","1ace1013":"from sklearn.preprocessing import LabelEncoder\nle1 = LabelEncoder()\nle2 = LabelEncoder()","512169df":"categoricals=[\"Province\/State\", \t\"Country\/Region\"]\nnumericals=[\"days\"]","7a78fbbe":"data.fillna(value=\"no\",inplace=True)\ndata.tail()","3f74da6b":"data[\"Province\/State\"]=le1.fit_transform(data[\"Province\/State\"])\ndata[\"Country\/Region\"]=le2.fit_transform(data[\"Country\/Region\"])","0b2a65a8":"data.tail()","37754c7f":"from sklearn.preprocessing import StandardScaler\nscaler1 = StandardScaler()\nscaler2 = StandardScaler()","8d414037":"data[[\"Confirmed\"]]=scaler1.fit_transform(data[[\"Confirmed\"]].to_numpy())\n","47ee12fb":"data[[\"days\"]]=scaler2.fit_transform(data[[\"days\"]].to_numpy())","b19c1427":"data=data.drop(\"Date\",axis=1)\ndata.head()","5fcb0fd3":"data, NAlist = reduce_mem_usage(data)\ndata.head()","a26f0df9":"val=data[data.days>61]\ntrain=data[data.days<62]","9fd388f0":"train.head()","734f3194":"train.describe()","5bf7b022":"def model(dense_dim_1=16, dense_dim_2=8, dense_dim_3=8, dense_dim_4=4, \ndropout1=0.4, dropout2=0.3, dropout3=0.3, dropout4=0.4, lr=0.0005,pre_model=None):\n\n    #Inputs\n    state = Input(shape=[1], name=\"Province\/State\")\n    country = Input(shape=[1], name=\"Country\/Region\")\n    #conf = Input(shape=[1], name=\"Confirmed\")\n    days = Input(shape=[1], name=\"days\")\n    \n   \n    #Embeddings layers\n    emb_state = Embedding(77, 4)(state)\n    emb_country = Embedding(175, 4)(country)\n    \n\n    concat_emb = concatenate([\n           Flatten() (emb_state)\n         , Flatten() (emb_country)\n         \n    ])\n    \n    categ = Dropout(dropout1)(Dense(dense_dim_1,activation='relu') (concat_emb))\n    categ = BatchNormalization()(categ)\n    categ = Dropout(dropout2)(Dense(dense_dim_2,activation='relu') (categ))\n    \n    #main layer\n    main_l = concatenate([\n          categ\n        , days\n        \n    ])\n    \n    main_l = Dropout(dropout3)(Dense(dense_dim_3,activation='relu') (main_l))\n    main_l = BatchNormalization()(main_l)\n    main_l = Dropout(dropout4)(Dense(dense_dim_4,activation='relu') (main_l))\n    \n    #output\n    output = Dense(1) (main_l)\n\n    model = Model([ state,\n                    country, \n                    days], output)\n\n    model.compile(optimizer = Adam(lr=lr),\n                  loss= mse_loss,\n                  metrics=[root_mean_squared_error,\"accuracy\"])\n    return model\n\ndef root_mean_squared_error(y_true, y_pred):\n    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=0))","adf66b6c":"def get_keras_data(df, num_cols, cat_cols):\n    cols = num_cols + cat_cols\n    X = {col: np.array(df[col]) for col in cols}\n    return X","4eac414f":"Y_train=train.Confirmed\nX_train=train.drop('Confirmed',axis=1)\nY_valid=val.Confirmed\nX_valid=val.drop(\"Confirmed\",axis=1)","536b1fa9":"X_t = get_keras_data(X_train, numericals, categoricals)\nX_v = get_keras_data(X_valid, numericals, categoricals)","20e61f44":"keras_model=model(lr=0.001)","a77faf15":"early_stopping = EarlyStopping(patience=105, verbose=2)\nmodel_checkpoint = ModelCheckpoint(\"corona.hdf5\",\n                                       save_best_only=True, verbose=2, monitor='val_root_mean_squared_error', mode='min')\nhist = keras_model.fit(X_t, Y_train, batch_size=128, epochs=150,\n                             validation_split=0.1,\n                            callbacks=[early_stopping, model_checkpoint])","c2bda738":"plt.plot(hist.history['val_loss'])","4fd2b3d7":"plt.plot(hist.history['loss'])","0750d373":"Modl=load_model(\"corona.hdf5\",custom_objects={'root_mean_squared_error': root_mean_squared_error})","5bb24de8":"sub=pd.read_csv(\"\/kaggle\/input\/submission(1).csv\")\nsub=sub.melt(id_vars=[\"Province\/State\", \"Country\/Region\"], var_name=\"Date\", value_name=\"Confirmed\")\nsub['Date'] = pd.to_datetime(sub['Date'])\nsub.head()","12810316":"sub[\"Province\/State\"].fillna(value=\"no\",inplace=True)\n\nsub[\"Province\/State\"]=le1.transform(sub[\"Province\/State\"])\nsub[\"Country\/Region\"]=le2.transform(sub[\"Country\/Region\"])","a6ec070f":"sub['days']=(sub['Date']-pd.to_datetime(\"2020-01-22\")).dt.days","b602f133":"sub[[\"days\"]]=scaler2.transform(sub[[\"days\"]].to_numpy())","33523901":"sub.head()","f41fbe18":"len(sub)","2d6945e6":"for_prediction=get_keras_data(sub,numericals,categoricals)\n","b916453e":"result=Modl.predict(for_prediction, batch_size=1715)","e5f28f3a":"sub['Confirmed']=result","3d0b7e3a":"sub['Confirmed']=scaler1.inverse_transform(sub['Confirmed'])","e8e78cd7":"sub.head()","3c4ba3ea":"sub.Confirmed.max()","ffbe7a12":"sub.describe()\n","73ee7794":"sub['Confirmed']=(sub.Confirmed.astype(np.int64))","9a91a7a6":"sub=sub.drop(\"days\",axis=1)","bffb9c1a":"sub.head()","8128aedc":"pt=sub.set_index([\"Province\/State\", \"Country\/Region\", 'Date']).unstack('Date').reset_index()\npt.columns.name=None\npt.reset_index()","b33d58b5":"sub1=pd.read_csv('\/kaggle\/input\/submission(1).csv')","ec7229a2":"pt.columns=sub1.columns","5b73227f":"pt['Province\/State']=le1.inverse_transform(pt['Province\/State'])","3e409567":"pt['Country\/Region']=le2.inverse_transform(pt['Country\/Region'])","a081dedc":"pt['Province\/State'].value_counts()","1ad6b04e":"pt=pt.replace(\"no\",\"\")","78731702":"len(pt)","2e5e1149":"pt.head()","bc8079fe":"pt['Province\/State'].value_counts()","ea1d17cf":"pt.to_csv(\"submit.csv\")","94113a4b":"#Predictions","50defac6":"# Visualizations","f0268be1":"Dataset obtained from [here](https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_confirmed_global.csv)"}}