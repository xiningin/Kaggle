{"cell_type":{"b76554a4":"code","e44d324a":"code","ae3eb39b":"code","fca3a062":"code","9a82ba7a":"code","dc4033cd":"code","1bfa92ed":"code","e3ff8e96":"code","4bb5eb5d":"code","3297ce3c":"code","6e520a1a":"code","726a4747":"code","d186b35f":"code","68d9ccc1":"code","5bf71112":"code","194e1205":"code","b2a86052":"code","70bba44f":"code","6079f767":"code","a469040b":"code","b6408a26":"code","682b998d":"code","7bb3ab12":"code","ac0b3083":"code","ec0bd4e1":"markdown","ef401403":"markdown","622f49c2":"markdown","9c10ccc0":"markdown","585f1118":"markdown","f605a744":"markdown","cd53814d":"markdown"},"source":{"b76554a4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e44d324a":"import matplotlib.pyplot as plt\nfrom keras import preprocessing\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,Dropout,Dense,Flatten,Conv2DTranspose,BatchNormalization,LeakyReLU,Reshape\nimport tensorflow as tf","ae3eb39b":"train_data = pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_train.csv')\ntrain_data.head()","fca3a062":"X_train = train_data.drop('label',axis=1)\nX_train.head()","9a82ba7a":"X_train=X_train.values\nprint(X_train.shape)","dc4033cd":"X_train=X_train.reshape(-1,28,28,1)\nprint(X_train.shape)","1bfa92ed":"fig,axe=plt.subplots(2,2)\nidx = 0\nfor i in range(2):\n    for j in range(2):\n        axe[i,j].imshow(X_train[idx].reshape(28,28),cmap='gray')\n        idx+=1","e3ff8e96":"X_train =  X_train.astype('float32')","4bb5eb5d":"X_train = X_train\/255\nX_train = X_train*2 - 1.","3297ce3c":"print(X_train.max(),X_train.min())\n","6e520a1a":"generator = Sequential()\ngenerator.add(Dense(512,input_shape=[100]))\ngenerator.add(LeakyReLU(alpha=0.2))\ngenerator.add(BatchNormalization(momentum=0.8))\ngenerator.add(Dense(256))\ngenerator.add(LeakyReLU(alpha=0.2))\ngenerator.add(BatchNormalization(momentum=0.8))\ngenerator.add(Dense(128))\ngenerator.add(LeakyReLU(alpha=0.2))\ngenerator.add(BatchNormalization(momentum=0.8))\ngenerator.add(Dense(784))\ngenerator.add(Reshape([28,28,1]))","726a4747":"generator.summary()","d186b35f":"discriminator = Sequential()\ndiscriminator.add(Dense(1,input_shape=[28,28,1]))\ndiscriminator.add(Flatten())\ndiscriminator.add(Dense(256))\ndiscriminator.add(LeakyReLU(alpha=0.2))\ndiscriminator.add(Dropout(0.5))\ndiscriminator.add(Dense(128))\ndiscriminator.add(LeakyReLU(alpha=0.2))\ndiscriminator.add(Dropout(0.5))\ndiscriminator.add(Dense(64))\ndiscriminator.add(LeakyReLU(alpha=0.2))\ndiscriminator.add(Dropout(0.5))\ndiscriminator.add(Dense(1,activation='sigmoid'))","68d9ccc1":"discriminator.summary()","5bf71112":"GAN =Sequential([generator,discriminator])\ndiscriminator.compile(optimizer='adam',loss='binary_crossentropy')\ndiscriminator.trainable = False","194e1205":"GAN.compile(optimizer='adam',loss='binary_crossentropy')","b2a86052":"GAN.layers","70bba44f":"GAN.summary()","6079f767":"epochs = 30\nbatch_size = 100\nnoise_shape=100","a469040b":"with tf.device('\/gpu:0'):\n for epoch in range(epochs):\n    print(f\"Currently on Epoch {epoch+1}\")\n    \n    \n    for i in range(X_train.shape[0]\/\/batch_size):\n        \n        if (i+1)%50 == 0:\n            print(f\"\\tCurrently on batch number {i+1} of {X_train.shape[0]\/\/batch_size}\")\n            \n        noise=np.random.normal(size=[batch_size,noise_shape])\n       \n        gen_image = generator.predict_on_batch(noise)\n        \n        train_dataset = X_train[i*batch_size:(i+1)*batch_size]\n       \n        #training discriminator on real images\n        train_label=np.ones(shape=(batch_size,1))\n        discriminator.trainable = True\n        d_loss_real=discriminator.train_on_batch(train_dataset,train_label)\n        \n        #training discriminator on fake images\n        train_label=np.zeros(shape=(batch_size,1))\n        d_loss_fake=discriminator.train_on_batch(gen_image,train_label)\n        \n        \n        #training generator \n        noise=np.random.normal(size=[batch_size,noise_shape])\n        train_label=np.ones(shape=(batch_size,1))\n        discriminator.trainable = False\n        \n        d_g_loss_batch =GAN.train_on_batch(noise, train_label)\n        \n        \n        \n       \n    #plotting generated images at the start and then after every 10 epoch\n    if epoch % 10 == 0:\n        samples = 10\n        x_fake = generator.predict(np.random.normal(loc=0, scale=1, size=(samples, 100)))\n\n        for k in range(samples):\n            plt.subplot(2, 5, k+1)\n            plt.imshow(x_fake[k].reshape(28, 28), cmap='gray')\n            plt.xticks([])\n            plt.yticks([])\n\n        plt.tight_layout()\n        plt.show()\n\n        \n        \nprint('Training is complete')","b6408a26":"noise=np.random.normal(size=[10,noise_shape])\n\ngen_image = generator.predict(noise)","682b998d":"fig,axe=plt.subplots(2,5)\nfig.suptitle(\"Actual Images\")\nidx = 0\nfor i in range(2):\n    for j in range(5):\n        axe[i,j].imshow(X_train[idx].reshape(28,28),cmap='gray')\n        idx+=10","7bb3ab12":"plt.imshow(noise)\nplt.title('How the noise looks')","ac0b3083":"fig,axe=plt.subplots(2,5)\nfig.suptitle('Generated Images from Noise using GANs')\nidx=0\nfor i in range(2):\n    for j in range(5):\n         axe[i,j].imshow(gen_image[idx].reshape(28,28),cmap='gray')\n         idx+=1","ec0bd4e1":"# *Data preprocessing*","ef401403":"***GANS***","622f49c2":"**Generator**","9c10ccc0":"# **Model Building**","585f1118":"**Discriminator**","f605a744":"*Import data*","cd53814d":"# ***Training the model***"}}