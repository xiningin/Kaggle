{"cell_type":{"8f571954":"code","e61f66fa":"code","a9ab37b7":"code","d5f54ae2":"code","d9a1efb6":"code","e89bb91b":"code","eb5e0099":"code","33872734":"code","a679dc9a":"code","0c68e52f":"code","63e740ed":"code","5ac92cff":"code","9e4b8404":"code","f9cb4cae":"code","6742d975":"code","7ca3a08c":"code","4976e0a3":"code","d38ff4f0":"code","c9685c2b":"code","90372d97":"code","f59051c5":"code","56f9b081":"code","30864f31":"code","00c4da38":"code","388cdef8":"code","2c5cb51c":"code","2f3c3018":"code","44569890":"code","7af76e97":"code","2203097a":"code","79018bd5":"code","eb58781a":"code","eaf91220":"code","980ed0ad":"code","d545257e":"markdown","b3e32eec":"markdown","e315d762":"markdown","a54add4d":"markdown","e125585c":"markdown","ad2fa863":"markdown","04f5e110":"markdown","19584399":"markdown"},"source":{"8f571954":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","e61f66fa":"# read the csv file \npath = '..\/input\/admission-predict1\/Admission_Predict.csv'\nadmission_df = pd.read_csv(path)","a9ab37b7":"admission_df.head()","d5f54ae2":"# Let's drop the serial no.\nadmission_df.drop('Serial No.', axis = 1, inplace = True)","d9a1efb6":"# checking the null values\nadmission_df.isnull().sum()","e89bb91b":"# Check the dataframe information\nadmission_df.info()","eb5e0099":"# Statistical summary of the dataframe\nadmission_df.describe()","33872734":"# Grouping by University ranking \ndf_university = admission_df.groupby('University Rating').mean()\ndf_university.head()","a679dc9a":"admission_df.hist(bins = 30, figsize = (20,20), color ='r')","0c68e52f":"sns.pairplot(admission_df)\nplt.show()","63e740ed":"corr_matrix = admission_df.corr()\nplt.figure(figsize =(12,12))\nsns.heatmap(corr_matrix, annot = True)\nplt.show()\n  ","5ac92cff":"admission_df.columns","9e4b8404":"X = admission_df.drop(columns = ['Chance of Admit'])","f9cb4cae":"y = admission_df['Chance of Admit']","6742d975":"X = np.array(X)\ny = np.array(y)","7ca3a08c":"y = y.reshape(-1,1)","4976e0a3":"# scaling the data before training the model\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nscaler_x = StandardScaler()\nX = scaler_x.fit_transform(X)\n","d38ff4f0":"scaler_y = StandardScaler()\ny = scaler_y.fit_transform(y)","c9685c2b":"# spliting the data in to test and train sets\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)","90372d97":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, accuracy_score","f59051c5":"lm = LinearRegression()\nlm.fit(X_train, y_train)","56f9b081":"accuracy_lm = lm.score(X_test, y_test)\naccuracy_lm","30864f31":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Dense, Activation, Dropout\nfrom tensorflow.keras.optimizers import Adam\n","00c4da38":"ANN_model = keras.Sequential()\nANN_model.add(Dense(50, input_dim = 7))\nANN_model.add(Activation('relu'))\nANN_model.add(Dense(150))\nANN_model.add(Activation('relu'))\nANN_model.add(Dropout(0.5))\nANN_model.add(Dense(150))\nANN_model.add(Activation('relu'))\nANN_model.add(Dropout(0.5))\nANN_model.add(Dense(50))\nANN_model.add(Activation('linear'))\nANN_model.add(Dense(1))\nANN_model.compile(loss = 'mse', optimizer = 'adam')\nANN_model.summary()","388cdef8":"ANN_model.compile(optimizer='Adam', loss='mean_squared_error')","2c5cb51c":"epochs_hist = ANN_model.fit(X_train, y_train, epochs = 100, batch_size = 20, validation_split = 0.2)","2f3c3018":"result = ANN_model.evaluate(X_test, y_test)\naccuracy_ANN = 1 - result\nprint(\"Accuracy : {}\".format(accuracy_ANN))","44569890":"epochs_hist.history.keys()","7af76e97":"plt.plot(epochs_hist.history['loss'])\nplt.title('Model Loss Progress During Training')\nplt.xlabel('Epoch')\nplt.ylabel('Training Loss')\nplt.legend(['Training Loss'])","2203097a":"# Decision tree builds regression or classification models in the form of a tree structure. \n# Decision tree breaks down a dataset into smaller subsets while at the same time an associated decision tree is incrementally developed. \n# The final result is a tree with decision nodes and leaf nodes.\n# Great resource: https:\/\/www.saedsayad.com\/decision_tree_reg.htm\n\nfrom sklearn.tree import DecisionTreeRegressor\nDecisionTree_model = DecisionTreeRegressor()\nDecisionTree_model.fit(X_train, y_train)","79018bd5":"accuracy_DecisionTree = DecisionTree_model.score(X_test, y_test)\naccuracy_DecisionTree","eb58781a":"# Many decision Trees make up a random forest model which is an ensemble model. \n# Predictions made by each decision tree are averaged to get the prediction of random forest model.\n# A random forest regressor fits a number of classifying decision trees on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. \nfrom sklearn.ensemble import RandomForestRegressor\nRandomForest_model= RandomForestRegressor(n_estimators = 100, max_depth = 10)\nRandomForest_model.fit(X_train, y_train)","eaf91220":"accuracy_RandomForest = RandomForest_model.score(X_test, y_test)\naccuracy_RandomForest","980ed0ad":"y_predict = lm.predict(X_test)\nplt.plot(y_test, y_predict, '*')","d545257e":"# TRAINING AND EVALUATING A DECISION TREE AND RANDOM FOREST MODELS","b3e32eec":"# TRAINING AND TESTING DATASET","e315d762":"# EXPLORATORY DATA ANALYSIS","a54add4d":"# UNDERSTAND THE PROBLEM STATEMENT\n\n### In this project, I aim to build regression model to predict the chance of admission into a particular university based on the student's profile.\n\n### INPUT FEATURES\n* GRE Scores (out od 340)\n* TOEFL Scores(out of 120)\n* University Rating(out of 5)\n* Statement of purpose(SOP)\n* Letter of Recommendation (Strength out of 5)\n* Undergraduate GPA (out of 10)\n* Research Experience (either 0 or 1)","e125585c":"#  IMPORT LIBRARIES AND DATASET","ad2fa863":"# TRAIN AND EVALUATE AN ARTIFICIAL NEURAL NETWORK","04f5e110":"# DATA VISUALIZATION","19584399":"# TRAIN AND EVALUATE A LINEAR REGRESSION MODEL"}}