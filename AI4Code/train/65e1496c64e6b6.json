{"cell_type":{"2ca3ba9f":"code","f722f0d5":"code","23324709":"code","bf9f7628":"code","6da7e83d":"code","84d9a787":"code","f979797e":"code","36a72842":"code","8840df5e":"code","d703bcc8":"code","3e7aad43":"code","e6aa82bd":"code","ad9d220e":"code","1d6ebb10":"code","c7df8c58":"code","7b7715f1":"code","d407e5b0":"code","ee487b5f":"code","9cec07b8":"code","8fe57cd6":"code","83750aaf":"code","0e72934c":"code","79e1a900":"code","882942c7":"code","a6a8c5b3":"code","3e1a375e":"code","257b137a":"code","2c02a747":"code","fbec08f8":"markdown","6c6ee186":"markdown","f1de6a31":"markdown","25552cb9":"markdown","8fcc131e":"markdown","0fcd5807":"markdown"},"source":{"2ca3ba9f":"import numpy as np\nimport matplotlib.pyplot as plt\nimport cv2 as cv\nimport os\nimport sys\n","f722f0d5":"from tensorflow.keras.layers import Input, Dense, Activation, Concatenate,Dropout,ZeroPadding2D\nfrom tensorflow.keras.layers import Flatten, AveragePooling2D,MaxPooling2D, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model ,load_model\nfrom tensorflow.keras.layers import Conv2D,Dropout,Lambda,PReLU, LeakyReLU,BatchNormalization\nimport tensorflow as tf\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras import backend as k\nleaky_relu = LeakyReLU(alpha=0.01)\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.layers import add, Activation\n#from tensorflow.keras.applications import Inceptio\nfrom deepface.basemodels import Facenet,VGGFace","23324709":"#resnet = Facenet.InceptionResNetV2(dimension = 512)\nvgg = VGGFace.baseModel()\n#resnet.load_weights('..\/input\/facenet512\/facenet512_weights.h5')\n#vgg = VGGFace.loadModel()","bf9f7628":"vgg.load_weights('..\/input\/weightsss\/vgg_face_weights.h5')","6da7e83d":"size = 224\nshape = (size,size,3)","84d9a787":"cnt = 0\nfor lyer in vgg.layers:\n    if cnt>34:\n        lyer.trainable= True\n        lyer.activation= tf.keras.layers.Activation('tanh')\n    else:\n        lyer.trainable =False\n    cnt = cnt+1\nvgg_face = Model(inputs=vgg.layers[0].input, outputs=vgg.layers[-2].output)","f979797e":"#vggmod16.load_weights('..\/input\/faceweight\/facenet_weights.h5' , by_name = True, skip_mismatch = True)","36a72842":"\ndef create_model():\n    inputs = Input(shape)\n    #inputs = BatchNormalization(axis= -1)(inputs)\n    outputs = vgg_face(inputs)\n    x = Flatten()(outputs) \n    \n    model = Model(inputs,x)\n    print(vgg_face.summary())\n    return model","8840df5e":"extractor = create_model()","d703bcc8":"imgA = Input(shape=shape)\nimgB = Input(shape=shape)\nfeatA = extractor(imgA)\nfeatB = extractor(imgB)\n#comb = Concatenate()([featA,featB])","3e7aad43":"def euclidean_distance(vectors):\n    (featA, featB) = vectors\n    sum_squared = k.sum(k.square(featA - featB), axis=1, keepdims=True)\n    return k.sqrt(k.maximum(sum_squared, k.epsilon()))\n\n\ndistance = Lambda(euclidean_distance)([featA, featB])\nprint(distance)\noutputs = Dense(1, activation=\"sigmoid\", name = 'ddd')(distance)\nmodel = Model(inputs=[imgA, imgB], outputs=outputs)\nmodel.summary()","e6aa82bd":"def resz3(h,w,img):\n    hz = np.zeros((h,w,3))\n    for i in range(3):\n        \n        hz[:,:,i] = cv.resize(img[:,:,i],(w,h))\n    \n    return hz","ad9d220e":"datadir = '..\/input\/facesdata\/original_hp'\nclasses = [i for i in os.listdir(datadir)]\nclasses = classes[:35]\ntraining=[]\nfor clas in classes:\n    Path=os.path.join(datadir,clas)\n    label=classes.index(clas)\n    for img in (os.listdir(Path)):\n        imgarray= cv.imread(os.path.join(Path,img))\n        newimg =  resz3(size,size,imgarray)\n        #newimg=cv.resize(imgarray,(160,160))\n        training.append([newimg,label])\nimport random    \nrandom.shuffle(training)\nx=[]\ny=[]\nfor fea,labl in training:\n    x.append(fea)\n    y.append(labl)\nx=np.array(x)\ny=np.array(y)\n#y = tf.one_hot(y,2)\nprint(x.shape)","1d6ebb10":"def preprocess_pairs(images, labels,classes):\n    targets = [j for j in range(len(classes))]\n    label_indices = {}\n    for label in targets:\n        label_indices.setdefault(label,[index for index, curr_label in enumerate(labels) if label == curr_label])\n        #list comprehension\n    \n    pimages = []\n    plabels = []\n    for i, image in enumerate(images):\n        pos_indices = label_indices.get(labels[i])\n        pos_image = images[np.random.choice(pos_indices)]\n        pimages.append((image, pos_image))\n        plabels.append(1)\n\n        neg_indices = np.where(labels != labels[i])\n        neg_image = images[np.random.choice(neg_indices[0])]\n        pimages.append((image, neg_image))\n        plabels.append(0)\n    return np.array(pimages), np.array(plabels)","c7df8c58":"pairs , labels = preprocess_pairs(x,y,classes)\nlen(pairs)\n","7b7715f1":"(sys.getsizeof(pairs)\/1024)\/1024","d407e5b0":"show = 150\nimg1,img2 = pairs[show]","ee487b5f":"print(labels[show])\nplt.imshow((img1.astype(np.uint8)))\nplt.show()\nplt.imshow((img2.astype(np.uint8)))\nplt.show()","9cec07b8":"import pickle","8fe57cd6":"from tensorflow.keras.callbacks import TensorBoard,EarlyStopping\nimport datetime\nlogg = \"logs3\"\ntfcallback = TensorBoard(log_dir=logg)\n#ly = EarlyStopping(monitor = 'train_loss',patience = 3) to","83750aaf":"model.compile(loss=\"binary_crossentropy\", optimizer= Adam(0.001), metrics=[\"accuracy\"])","0e72934c":"\nmodel.fit([pairs[:, 0], pairs[:, 1]], labels[:],validation_split=0.2,batch_size = 32,\n          epochs=80,verbose=2)","79e1a900":"keyss = model.history.history\nnn = len(keyss['loss'])","882942c7":"\nplt.plot(np.arange(nn),keyss['loss'],color='green',label='loss')\nplt.legend()\nplt.plot(np.arange(nn),keyss['val_loss'],color='black',label = 'val_loss')\nplt.legend()\nplt.plot(np.arange(nn),keyss['accuracy'],color='red',label = 'accurcy')\nplt.legend()\nplt.plot(np.arange(nn),keyss['val_accuracy'],color='purple',label = 'val_accu')\nplt.legend()\nplt.xlim(0,80)\nplt.ylim(0,1)\nplt.show()\n\n","a6a8c5b3":"def findCosineDistance(source_representation, test_representation):\n    a = np.matmul(np.transpose(source_representation), test_representation)\n    b = np.sum(np.multiply(source_representation, source_representation))\n    c = np.sum(np.multiply(test_representation, test_representation))\n    return 1 - (a \/ (np.sqrt(b) * np.sqrt(c)))\ndef l2_normalize(xx):\n    return xx \/ np.sqrt(np.sum(np.multiply(xx, xx)))\ndef findEuclideanDistance(source_representation, test_representation):\n    if type(source_representation) == list:\n        source_representation = np.array(source_representation)\n\n    if type(test_representation) == list:\n        test_representation = np.array(test_representation)\n\n    euclidean_distance = source_representation - test_representation\n    euclidean_distance = np.sum(np.multiply(euclidean_distance, euclidean_distance))\n    euclidean_distance = np.sqrt(euclidean_distance)\n    return euclidean_distance","3e1a375e":"from scipy import spatial\ndatadir = '..\/input\/databaseimg\/imagesdb'\nclasses = [i for i in os.listdir(datadir)]\ndb = []\nfor clas in classes:\n    path = os.path.join(datadir,clas)\n    for img in os.listdir(path):\n        img2= cv.imread(os.path.join(path,img))\n        img2 = resz3(224,224,img2)\n        #newimg=cv.resize(imgarray,(160,160))\n        db.append(np.array(img2))\nprint(classes)\nPath = '..\/input\/databasetest\/test_images_for_classification'\n    \nfor img in (os.listdir(Path)):\n    \n    imgarray= cv.imread(os.path.join(Path,img))\n    imgsc =  resz3(size,size,imgarray)\n    plt.imshow((imgsc.astype(np.uint8)))\n    plt.show()\n    imgsc = imgsc.reshape(-1,size,size,3,1)\n    f1 = extractor.predict(imgsc)\n    #f1 = l2_normalize(f1)\n    #newimg=cv.resize(imgarray,(160,160))\n    dist = []\n    for imgref in db:\n        \n        imgref = resz3(size,size,imgref)\n        #plt.imshow((imgref.astype(np.uint8)))\n        #plt.show()\n        f2 = extractor.predict(imgref.reshape(-1,size,size,3,1))\n        dis = spatial.distance.cosine(f1,f2)\n        #f2 = l2_normalize(f2)\n        #sum_squared = k.sum(k.square(f1 - f2), axis=1)\n        #dis = k.sqrt(k.maximum(sum_squared,k.epsilon()))\n        \n        dist.append(dis)\n    print(np.round(dist,3))\n    \n        \n  \n    print(classes[np.argmin(dist)])\n        \n        \n        \n    ","257b137a":"from tensorflow.keras.utils import plot_model\nplot_model(extractor,'hii.png') ","2c02a747":"extractor.save('.\/mod2')","fbec08f8":"file2 = open('pairspkl','rb')\npairs = pickle.load(file2)\nfile2.close()","6c6ee186":"vggmod16 = vgg16.VGG16(include_top = False, weights = '..\/input\/vggfacenotop\/rcmalli_vggface_tf_notop_vgg16.h5',input_shape =shape)","f1de6a31":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(\n    featurewise_center=False, samplewise_center=False,\n    featurewise_std_normalization=False, samplewise_std_normalization=False,\n    zca_whitening=False, zca_epsilon=1e-06, rotation_range=(0,25), width_shift_range=0.2,\n    height_shift_range=(0,0.2), brightness_range= (0,0.2), shear_range=(0.0,0.2), zoom_range=(0,0.2),\n    channel_shift_range=(0,0.1), fill_mode='nearest')","25552cb9":"<a href=\".\/mod2\/variables\/variables.data-00000-of-00001\"> Download File <\/a>","8fcc131e":"## ","0fcd5807":"file1 = open('.\/labelss','rb')\nlabels = pickle.load(file1)\nfile1.close()\n#fiel2  = open('')"}}