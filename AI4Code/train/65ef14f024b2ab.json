{"cell_type":{"2b8a5ad3":"code","73fbbbd4":"code","082b3663":"code","e228ed22":"code","2e5d363f":"code","759f2065":"code","8f569198":"code","8e3c0647":"code","4cdf69fe":"code","fa7f872d":"code","225b85de":"code","9c85a8b4":"code","78e1a76d":"code","b75c9b7c":"code","c55ebdd3":"code","01b4e318":"code","17ea61b8":"code","abe1139a":"code","cc105184":"code","02a51895":"code","24e6d9fb":"code","f6f20ec8":"code","fe9124cf":"markdown","1310c544":"markdown","6557660d":"markdown","0e586015":"markdown","291f337c":"markdown","7315a524":"markdown","b41f2494":"markdown","88e9d6ac":"markdown","7de5b849":"markdown","c3a6db04":"markdown","0e0b52f8":"markdown","952ade78":"markdown","dde40f16":"markdown","f1950ffd":"markdown","e089e3dc":"markdown","aaa5bd5d":"markdown","0e344747":"markdown","85833ce8":"markdown","5f978446":"markdown","ef5c8afe":"markdown","b6685f2d":"markdown","e7bf7086":"markdown","4e480808":"markdown","a58ed4e9":"markdown","16d016e0":"markdown","b3f89617":"markdown","23e5dc9e":"markdown","54d1e6dd":"markdown","273add86":"markdown"},"source":{"2b8a5ad3":"import pandas as pd\nimport numpy as np\nimport gc, warnings\nwarnings.filterwarnings('ignore')","73fbbbd4":"sale_train = pd.read_csv('..\/input\/sales_train.csv')","082b3663":"print(\"----------Top-5- Record----------\")\nprint(sale_train.head(5))\nprint(\"-----------Information-----------\")\nprint(sale_train.info())\nprint(\"-----------Data Types-----------\")\nprint(sale_train.dtypes)\nprint(\"----------Missing value-----------\")\nprint(sale_train.isnull().sum())\nprint(\"----------Null value-----------\")\nprint(sale_train.isna().sum())\nprint(\"----------Shape of Data----------\")\nprint(sale_train.shape)","e228ed22":"print('Number of duplicates:', len(sale_train[sale_train.duplicated()]))","2e5d363f":"def downcast_dtypes(df):\n    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n    int_cols = [c for c in df if df[c].dtype in [\"int64\", \"int32\"]]\n    df[float_cols] = df[float_cols].astype(np.float32)\n    df[int_cols] = df[int_cols].astype(np.int16)\n    return df\n\nsale_train = downcast_dtypes(sale_train)\nprint(sale_train.info())","759f2065":"sales_by_item_id = sale_train.pivot_table(index=['item_id'],values=['item_cnt_day'], \n                                        columns='date_block_num', aggfunc=np.sum, fill_value=0).reset_index()\nsales_by_item_id.columns = sales_by_item_id.columns.droplevel().map(str)\nsales_by_item_id = sales_by_item_id.reset_index(drop=True).rename_axis(None, axis=1)\nsales_by_item_id.columns.values[0] = 'item_id'","8f569198":"sales_by_item_id.sum()[1:].plot(legend=True, label=\"Monthly sum\")","8e3c0647":"sales_by_item_id.mean()[1:].plot(legend=True, label=\"Monthly mean\")","4cdf69fe":"outdated_items = sales_by_item_id[sales_by_item_id.loc[:,'27':].sum(axis=1)==0]\nprint('Outdated items:', len(outdated_items))","fa7f872d":"test = pd.read_csv('..\/input\/test.csv')\nprint('Outdated items in test set:', len(test[test['item_id'].isin(outdated_items['item_id'])]))","225b85de":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10,4))\nplt.xlim(-100, 3000)\nsns.boxplot(x=sale_train['item_cnt_day'])\nprint('Sale volume outliers:',sale_train['item_id'][sale_train['item_cnt_day']>500].unique())\n\nplt.figure(figsize=(10,4))\nplt.xlim(sale_train['item_price'].min(), sale_train['item_price'].max())\nsns.boxplot(x=sale_train['item_price'])\nprint('Item price outliers:',sale_train['item_id'][sale_train['item_price']>50000].unique())","9c85a8b4":"sales_by_shop_id = sale_train.pivot_table(index=['shop_id'],values=['item_cnt_day'], \n                                        columns='date_block_num', aggfunc=np.sum, fill_value=0).reset_index()\nsales_by_shop_id.columns = sales_by_shop_id.columns.droplevel().map(str)\nsales_by_shop_id = sales_by_shop_id.reset_index(drop=True).rename_axis(None, axis=1)\nsales_by_shop_id.columns.values[0] = 'shop_id'\n\nfor i in range(6,34):\n    print('Not exists in month',i,sales_by_shop_id['shop_id'][sales_by_shop_id.loc[:,'0':str(i)].sum(axis=1)==0].unique())\n\nfor i in range(6,28):\n    print('Shop is outdated for month',i,sales_by_shop_id['shop_id'][sales_by_shop_id.loc[:,str(i):].sum(axis=1)==0].unique())\n","78e1a76d":"print('Recently opened shop items:', len(test[test['shop_id']==36]))","b75c9b7c":"shops = pd.read_csv('..\/input\/shops.csv')\nshops.head()","c55ebdd3":"shops['shop_name'] = shops['shop_name'].apply(lambda x: x.lower()).str.replace('[^\\w\\s]', '').str.replace('\\d+','').str.strip()\nshops['shop_city'] = shops['shop_name'].str.partition(' ')[0]\nshops['shop_type'] = shops['shop_name'].apply(lambda x: '\u043c\u0442\u0440\u0446' if '\u043c\u0442\u0440\u0446' in x else '\u0442\u0440\u0446' if '\u0442\u0440\u0446' in x else '\u0442\u0440\u043a' if '\u0442\u0440\u043a' in x else '\u0442\u0446' if '\u0442\u0446' in x else '\u0442\u043a' if '\u0442\u043a' in x else 'NO_DATA')\nshops.head()","01b4e318":"items = pd.read_csv('..\/input\/items.csv')\nitems.head()","17ea61b8":"# Ugly code to show the idea\nfrom collections import Counter\nfrom operator import itemgetter\nitems['name_1'], items['name_2'] = items['item_name'].str.split('[', 1).str\nitems['name_1'], items['name_3'] = items['item_name'].str.split('(', 1).str\n\nitems['name_2'] = items['name_2'].str.replace('[^A-Za-z0-9\u0410-\u042f\u0430-\u044f]+', ' ').str.lower()\nitems['name_3'] = items['name_3'].str.replace('[^A-Za-z0-9\u0410-\u042f\u0430-\u044f]+', ' ').str.lower()\nitems = items.fillna('0')\n\nresult_1 = Counter(' '.join(items['name_2'].values.tolist()).split(' ')).items()\nresult_1 = sorted(result_1, key=itemgetter(1))\nresult_1 = pd.DataFrame(result_1, columns=['feature', 'count'])\nresult_1 = result_1[(result_1['feature'].str.len() > 1) & (result_1['count'] > 200)]\n\nresult_2 = Counter(' '.join(items['name_3'].values.tolist()).split(\" \")).items()\nresult_2 = sorted(result_2, key=itemgetter(1))\nresult_2 = pd.DataFrame(result_2, columns=['feature', 'count'])\nresult_2 = result_2[(result_2['feature'].str.len() > 1) & (result_2['count'] > 200)]\n\nresult = pd.concat([result_1, result_2])\nresult = result.drop_duplicates(subset=['feature'])\n\nprint('Most common aditional features:', result)","abe1139a":"print('Unique item names:', len(items['item_name'].unique()))","cc105184":"import re\ndef name_correction(x):\n    x = x.lower()\n    x = x.partition('[')[0]\n    x = x.partition('(')[0]\n    x = re.sub('[^A-Za-z0-9\u0410-\u042f\u0430-\u044f]+', ' ', x)\n    x = x.replace('  ', ' ')\n    x = x.strip()\n    return x\n\nitems['item_name'] = items['item_name'].apply(lambda x: name_correction(x))\nitems.head()","02a51895":"print('Unique item names after correction:', len(items['item_name'].unique()))","24e6d9fb":"categories = pd.read_csv('..\/input\/item_categories.csv')\ncategories.head()","f6f20ec8":"test = pd.read_csv('..\/input\/test.csv')\ngood_sales = test.merge(sale_train, on=['item_id','shop_id'], how='left').dropna()\ngood_pairs = test[test['ID'].isin(good_sales['ID'])]\nno_data_items = test[~(test['item_id'].isin(sale_train['item_id']))]\n\nprint('1. Number of good pairs:', len(good_pairs))\nprint('2. No Data Items:', len(no_data_items))\nprint('3. Only Item_id Info:', len(test)-len(no_data_items)-len(good_pairs))\n  ","fe9124cf":"With a close look we can find out that some shops have duplicated id\/name - probably it changed location (within commercial center), or it has a different type (isle sale point), but I decided to merge it.\n* 11 => 10\n* 1  => 58\n* 0  => 57\n* 40 => 39\n\nI converted train shop_id to shop_id that is in the test set","1310c544":"## 1.7 Category info\n* * *\nThe structure here is\n### Section name - subsection\nwe can split it and have two features from one","6557660d":"### Possible shop_id features\n1. Lags (shop_id\/shp_cnt_mth)\n2. Opening month (possible  opening sales)\n3. Closed Month (possible stock elimination)","0e586015":"We have duplicated rows, but I don't think that it is a mistake.\n\nIt could be different sales methods or client type, etc.\n\nYou can remove it, but I really don't believe that 6 rows of 3m can make the difference.","291f337c":"### Outliers by price and sales volume\nWe will get rid of them later\n\n#### please see lovely kernel made by Denis Larionov (I stole few graphs from there)\n* https:\/\/www.kaggle.com\/dlarionov\/feature-engineering-xgboost","7315a524":"## 1.2 shop_id\n* * *\n### Lets now group train data by shop_id.\nWe can see new shops - probably there will be a sales spike (opening event for example).\nApparently closed shops (ill call it \"outdated shops\")  - no sales for last 6 months.","b41f2494":"#### Is it feature? Yes. We need to apply different prediction approach for each type of items in the test set.\n####  For example - \"No Data Items\" - it is more likely classification task.","88e9d6ac":"### Possible item_id features:\n1. Lags\n2. Release date\n3. Last month sale\n4. Days on sale\n5. Neighbors (items with id 1000 and 1001 could be somehow similar - genre, type, release date)","7de5b849":" ## Load train data\n * * *","c3a6db04":"# Overview\nWhat is this kernel about?\n* No predictions to make \n* No features to create\n\nWe will load competition data and look closer on it. We will try to understand what we have in our hands and how we can work with it.\n* * *","0e0b52f8":"## 1.8 Test Set\n* * *\nThe key to my success was the analysis of Test test data.\n\nWe have three groups of items:\n1. Item\/shop pairs that are in train\n2. Items without any data\n3. Items that are in train","952ade78":"## 1.6 Item info\n* * *\nLet's see what we can get from this file.","dde40f16":"We can enconde \"features\" that many items have.\n\nThe structure is always the same\n### Item name [category feature] (additional feature)\nwe can split it, and \"one hot encode it.\"","f1950ffd":"## 1.4 Dates\n* * *\n### Possible Date features:\n1. Weekends and holidays sales (to correct monthly sales)\n2. Number of days in the month (to correct monthly sales)\n3. Month number (for seasonal items)","e089e3dc":"### Let's see how many products are outdated (no sales for the last 6 months)\n12391 of 21807 is a huge number. Probably we can set 0 for all that items and do not make any model prediction.","aaa5bd5d":"### Simple graph\nWhat this graph is telling us. Basically nothing.)) I only see that train data has many old products (degradation line) and many 1c products are seasonal and probably release date depended.\n\n#### I'm not very good with graphs and presentations - there are better data representation examples:\n* https:\/\/www.kaggle.com\/dimitreoliveira\/model-stacking-feature-engineering-and-eda\n* https:\/\/www.kaggle.com\/jagangupta\/time-series-basics-exploring-traditional-ts","0e344747":"### How many outdated items in test set?\n6888 - not much but we have such items","85833ce8":"### Next part will be about data aggregation and feature preparation.\n## To be continued...","5f978446":"### Item name correction\nFor our basic \"name feature\" it is enough to find identical items (not similar but identical),","ef5c8afe":"## 1.1 Item_id\n* * *\n### Lets group data by item_id and date_block_num and look closer on it.\n","b6685f2d":"## 1.3 Price\n* * *\n### Possible Price features:\n1. Price category (1$\/10$\/20$\/ etc.) - obviously (or not obviously),  items with smaller price have greater volumes\n2. Discount and Discount duration\n3. Price lag (shows discount)\n4. Price correction (rubl\/usd pair)\n5. Shop Revenue","e7bf7086":"### Possible Category features\n1. Section\n2. Main Category name\n3. Main SubCategory name \n4. Secondary SubCategory name\n","4e480808":"### Possible Shop features:\n1. Shop City\n2. Shop Type","a58ed4e9":"In our test set we have 5100 sales in really new shop and no \"outdated shops\" but anyway it is good feature for future.","16d016e0":"I can advise downcasting your DataFrame. It will save you some memory, and believe me you will need all memory possible.\n\nIn our case from 134.4+ MB, we went to 61.6+ MB\n\nNot a great deal right now but such approach works with bigger DF also.\n\n#### please see this two links for more tips (I stole that downcast basic snippet from anqitu)))\n* https:\/\/www.kaggle.com\/anqitu\/feature-engineer-and-model-ensemble-top-10\n* https:\/\/www.kaggle.com\/yuliagm\/how-to-work-with-big-datasets-on-16g-ram-dask","b3f89617":"### Possible Item features:\n1. Item name\n2. Encoded aditional feature ","23e5dc9e":"We can view basic DafaFrame information. \n\nAs you can see, we do not have broken and nan data that is good.","54d1e6dd":"## 1.5 Shop info\n* * *\nThe structure of the shop information is evident.\n### Shop City | Shop type | Shop name","273add86":"### But I did manual feature extraction here to have four features.\nSection \/ Main Category name \/ Main SubCategory name \/ Secondary SubCategory name\n#### \u0410\u043a\u0441\u0435\u0441\u0441\u0443\u0430\u0440\u044b \/ PS2\t\/ PS \/ 2"}}