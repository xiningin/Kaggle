{"cell_type":{"a723787a":"code","d3aeafc2":"code","ddc4f6c4":"code","52674b72":"code","c4e3f5df":"code","c43bb729":"code","c0396e59":"code","b716b292":"code","80cbc27f":"code","e53e5268":"code","995cdf8c":"code","c7e4ab52":"code","2b8d195a":"code","e097ffaf":"code","fad4df60":"code","fb3f3b9a":"code","e950ea27":"code","d11d84b0":"code","3b4dea63":"code","f937925b":"markdown","310d539f":"markdown","72b312e9":"markdown","ea052c62":"markdown","5bdef65b":"markdown","ac5629fb":"markdown","e904043f":"markdown","6f5c6e15":"markdown","1fb8ba63":"markdown","58fb3dde":"markdown","bb7524e8":"markdown","411569d0":"markdown","43df0505":"markdown","23f6d7aa":"markdown","4d7771c7":"markdown","93ff7c98":"markdown","300862f5":"markdown"},"source":{"a723787a":"import os\nimport numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook\nimport pandas as pd\nfrom numba import njit\nimport gc","d3aeafc2":"@njit\ndef entropy_fast(vec, bins):\n    h = np.histogram(vec, bins=bins)[0] + 1E-15\n    h = h \/ np.sum(h)\n    return -np.sum(h * np.log(h))","ddc4f6c4":"def replace_peaks(X, win=1000, threshold=500):\n    np.random.seed(0)\n    \n    for idx in range(X.shape[0]):\n        max_idx = np.argmax(np.abs(X[idx]))\n        \n        while np.abs(X[idx,max_idx]) > threshold:\n            temp_win = win + np.random.randint(-500, 501)\n            X[idx,max_idx] = 0.5 * (X[idx, np.maximum(0, max_idx-temp_win)] + X[idx, np.minimum(X[idx].shape[0] - 1, max_idx+temp_win)])\n            max_idx = np.argmax(np.abs(X[idx]))","52674b72":"%%time\ndf = pd.read_csv(os.path.join('..','input','train.csv'), dtype={'acoustic_data': np.int16, 'time_to_failure': np.float32})","c4e3f5df":"n_samples = 150000\nn_segments = int(np.floor(df.shape[0] \/ n_samples))","c43bb729":"X = np.zeros((n_segments, n_samples))\ny = np.zeros(n_segments)\n\nfor seg_id in range(n_segments):\n    seg = df.iloc[seg_id*n_samples:seg_id*n_samples+n_samples]\n    X[seg_id] = seg['acoustic_data'].values\n    y[seg_id] = seg['time_to_failure'].values[-1]\n\ndel df\ngc.collect();","c0396e59":"replace_peaks(X)","b716b292":"ent = np.zeros(X.shape[0])\n\nn=2000\nent_temp = np.zeros(n)\ncv = KFold(n, shuffle=False)\n\nfor idx in tqdm_notebook(range(X.shape[0])):\n    for idx2, (train_idx, test_idx) in enumerate(cv.split(X[idx])):\n        ent_temp[idx2] = entropy_fast(X[idx,test_idx], 300)\n    \n    ent[idx] = np.mean(ent_temp)","80cbc27f":"plt.figure(figsize=(15,5))\nplt.plot(ent)\nplt.xlabel('time')\nplt.ylabel('entropy');","e53e5268":"feature = np.clip(ent, a_min=2.37, a_max=2.66)\n\nmodel = LinearRegression(n_jobs=-1)\nmodel.fit(feature.reshape(-1,1), y.reshape(-1,1))\nfeature = model.predict(feature.reshape(-1,1))\n\nprint('MAE: ', mean_absolute_error(feature, y))","995cdf8c":"plt.figure(figsize=(15,5))\nplt.plot(feature,'r')\nplt.plot(y,'k')\nplt.ylabel('TTF')\nplt.xlabel('time')\nplt.grid()","c7e4ab52":"### Load testing data","2b8d195a":"submission = pd.read_csv(os.path.join('..','input','sample_submission.csv'), index_col='seg_id')","e097ffaf":"n_test_segments = submission.shape[0]\n\nX_test = np.zeros((n_test_segments, n_samples))\n\nfor seg_idx, seg_id in enumerate(tqdm_notebook(submission.index)):\n    seg = pd.read_csv(os.path.join('..','input','test', seg_id + '.csv'))\n    X_test[seg_idx] = seg['acoustic_data'].values","fad4df60":"replace_peaks(X_test)","fb3f3b9a":"ent = np.zeros(X_test.shape[0])\n\nn=2000\nent_temp = np.zeros(n)\ncv = KFold(n, shuffle=False)\n\nfor idx in tqdm_notebook(range(X_test.shape[0])):\n    for idx2, (train_idx, test_idx) in enumerate(cv.split(X_test[idx])):\n        ent_temp[idx2] = entropy_fast(X_test[idx,test_idx], 300)\n    \n    ent[idx] = np.mean(ent_temp)\n\ntest_feature = np.clip(ent, a_min=2.37, a_max=2.66)","e950ea27":"test_set_TTF_peaks = [11, 11, 11, 8, 11, 16, 9, 11, 16]\ntest_set_TTF_mean_peak = np.mean(test_set_TTF_peaks)\nscaling_factor = test_set_TTF_mean_peak \/ np.max(feature)","d11d84b0":"predictions = scaling_factor * model.predict(test_feature.reshape(-1,1)).flatten()","3b4dea63":"submission.time_to_failure = predictions\nsubmission.to_csv('submission.csv',index=True)","f937925b":"Split the segment into _n_ parts. Calculate the entropy on each part and take the mean to reduce noise.","310d539f":"Replaces peaks above the absolute value of a threshold with the average of nearby peaks.","72b312e9":"#### This kernel demonstrates the ability to achieve a high score (private leaderboard: 2.33037; 9th place) in the LANL Earthquake Prediction competition with only _one_ well-crafted feature and information from the test set data leak. This kernel was inspired by my [Three Keys to This Competition](https:\/\/www.kaggle.com\/c\/LANL-Earthquake-Prediction\/discussion\/94355) discussion topic.","ea052c62":"### Create submission","5bdef65b":"### Replace peaks","ac5629fb":"Plot the entropy.","e904043f":"# One Feature, No ML, Gold Medal Range","6f5c6e15":"### Take advantage of test data set leak","1fb8ba63":"`numba`tized version of information entropy. This is faster than the version in `scipy`.","58fb3dde":"### Define a few functions","bb7524e8":"Do some clipping and linearly transform the feature to best match the TTF. The optimal values for clipping were determined through some iterative hand tuning (not shown here) to arrive at an MAE of 2.112. Some people may say that linear regression is machine learning. However, I would claim that with one variable, it's a simple univariate linear transformation. ","411569d0":"### Load training data","43df0505":"Multiply predictions by the ratio of the mean peak TTF values in the test set to the peak TTF value in the predictions from the one entropy feature","23f6d7aa":"### Create information entropy feature","4d7771c7":"### Replace peaks and compute entropy feature for testing data.","93ff7c98":"View the feature and TTF together.","300862f5":"The peaks of the TTF in the test set were determined from the figures in [this discussion post](https:\/\/www.kaggle.com\/c\/LANL-Earthquake-Prediction\/discussion\/94086)."}}