{"cell_type":{"f55b0a63":"code","3a9e7098":"code","f54c4088":"code","097f96c1":"code","aec3b594":"code","a30af449":"code","b24c19bf":"code","f5499113":"code","91b9260d":"code","d54d6bbc":"code","a55e30a1":"code","03bebc7f":"code","ab58a8bd":"code","190ee3da":"code","10251a55":"code","a8d0ba07":"code","92dba239":"code","b2cd7ca4":"code","0fceae77":"code","535f186e":"code","399cd20e":"code","e989cae1":"markdown"},"source":{"f55b0a63":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nsns.set(rc={'figure.figsize':(14,8)}, font_scale=.9)\n","3a9e7098":"df = pd.read_csv('\/kaggle\/input\/covid19-symptoms-checker\/Cleaned-Data.csv')\ndisplay(df)","f54c4088":"indicators = ['Fever', 'Tiredness', 'Dry-Cough',  'Difficulty-in-Breathing', 'Sore-Throat', 'Pains', 'Nasal-Congestion',\n              'Runny-Nose', 'Diarrhea', 'Age_0-9', 'Age_10-19', 'Age_20-24', 'Age_25-59', 'Age_60+', 'Gender_Male',\n              'Gender_Female', 'Gender_Transgender']\ntarget_columns = ['Severity_None']\nindicators2 = ['Fever', 'Tiredness', 'Dry-Cough',  'Difficulty-in-Breathing', 'Sore-Throat', 'Pains', 'Nasal-Congestion',\n              'Runny-Nose', 'Diarrhea', 'Age_0-9', 'Age_10-19', 'Age_20-24', 'Age_25-59', 'Age_60+', 'Gender_Male',\n              'Gender_Female', 'Gender_Transgender', 'Severity_None']\nfeatures = df[indicators]\ntargets = df[target_columns]\ndisplay(features.head(), targets.head())","097f96c1":"# condition = []\n# cond_dict = {\n#     0: \"Mild\",\n#     1: \"Moderate\",\n#     2: \"Severe\"\n# }\n# for i in targets.values:\n#     idx = np.where(i == 1)[0][0]\n#     condition.append(cond_dict[idx])\n# targets['Condition'] = condition\nsns.set(rc={'figure.figsize':(12,8)}, font_scale=.9)\ntargets = targets.rename(columns={'Severity_None':'Non_Severe'})\nsns.countplot(targets['Non_Severe'])\nplt.title(\"Severity Data Distribution\")\nplt.show()\nsns.set(rc={'figure.figsize':(12,8)}, font_scale=.9)\n","aec3b594":"temp = []\nfor i in indicators:\n    temp.append(sum(features[i].values))\ntemp_df = pd.DataFrame({\"Indicator\":indicators, \"Occurence_Count\":temp})\nsns.barplot(data = temp_df, y=\"Indicator\", x=\"Occurence_Count\")","a30af449":"plt.pie(data=temp_df, x=\"Occurence_Count\", labels=temp_df[\"Indicator\"])\nplt.show()","b24c19bf":"def get_symptom_count(the_list):\n    return sum(the_list.values)\nfeatures['Total_Symptom'] = features[indicators].apply(get_symptom_count, axis=1)\nfeats = df[indicators2]\nfeats['Total_Symptom'] = feats[indicators].apply(get_symptom_count, axis=1)","f5499113":"sns.countplot(data=feats, x='Total_Symptom', hue='Severity_None')\nplt.xlabel(\"Total symptom occurence on someone\")\nplt.show()","91b9260d":"data = features\ndata['Non_Severe'] = targets['Non_Severe'].values\ndata","d54d6bbc":"data_for_corr = data.drop(labels=\"Total_Symptom\", axis=1)\n# data_for_corr['Condition'] = data_for_corr['Condition'].apply(make_condition_grade)\ncorrmat = data_for_corr.corr()\nk = 22\ncols = corrmat.nlargest(k, 'Non_Severe')['Non_Severe'].index\ncm = np.corrcoef(data_for_corr[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","a55e30a1":"from sklearn.decomposition import PCA\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\n\n\nk_fold = KFold(n_splits=10, shuffle=True, random_state=0)","03bebc7f":"x = data.drop(['Non_Severe', 'Total_Symptom'], axis=1)\nx = PCA(n_components = 3).fit_transform(x)\ny = data['Non_Severe']\nx_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42, test_size=.3)","ab58a8bd":"rfc = RandomForestClassifier()\nrfc.fit(x_train, y_train)\nrfc.score(x_test, y_test)","190ee3da":"lr = LogisticRegression()\nlr.fit(x_train, y_train)\nlr.score(x_test, y_test)","10251a55":"DTC = DecisionTreeClassifier()\nDTC.fit(x_train, y_train)\nDTC.score(x_test, y_test)","a8d0ba07":"params = {\n    \"max_depth\":[15,20,25], \n    \"n_estimators\":[27,30,33],\n    \"criterion\":[\"gini\", \"entropy\"],\n}\n\nrfc = RandomForestClassifier()\n\nrf_reg = GridSearchCV(rfc, params, cv = 10, n_jobs =10)\nrf_reg.fit(x_train, y_train)\nprint(rf_reg.best_estimator_)","92dba239":"rfc_tune = RandomForestClassifier(max_depth=15, n_estimators=27)\nrfc_tune.fit(x_train, y_train)\nscore = cross_val_score(rfc,x_test,y_test,cv = k_fold,n_jobs=1,scoring=\"accuracy\")\nprint(score.mean())","b2cd7ca4":"params={\n    \"penalty\":['l1', 'l2', 'elasticnet', 'none'],\n    \"solver\":['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n}\nlr = LogisticRegression()\nlr_reg = GridSearchCV(lr, params, cv=10, n_jobs=10)\nlr_reg.fit(x_train, y_train)\nprint(lr_reg.best_estimator_)","0fceae77":"lr_tune = LogisticRegression(penalty='l1', solver='liblinear')\nlr_tune.fit(x_train, y_train)\nscore = cross_val_score(lr_tune, x_test, y_test, cv=k_fold, n_jobs=1, scoring=\"accuracy\")\nprint(score.mean())","535f186e":"params = {\n    \"criterion\":[\"gini\", \"entropy\"],\n    \"max_depth\":[15,20,25], \n}\ndtc = DecisionTreeClassifier()\ndtc_reg = GridSearchCV(dtc, params, cv=10, n_jobs=10)\ndtc_reg.fit(x_train, y_train)\nprint(dtc_reg.best_estimator_)","399cd20e":"dtc_tune = DecisionTreeClassifier(max_depth=15)\ndtc_tune.fit(x_train, y_train)\nscore = cross_val_score(dtc_tune, x_test, y_test, cv=k_fold, n_jobs=1, scoring=\"accuracy\")\nprint(score.mean())","e989cae1":"# Modelling"}}