{"cell_type":{"7bcb431b":"code","d1733c4d":"code","de75a4a7":"code","5d26bab9":"code","777076a6":"code","ef02c339":"code","2536254b":"code","da49c761":"code","309cebee":"code","5e15acc0":"code","bf35ae01":"code","822477bb":"code","927c4280":"code","db1846ba":"code","50498106":"code","112473d6":"code","5199c113":"code","0dadb943":"code","f09d6d16":"code","94fc4c08":"code","8d3bc200":"code","2378dae2":"code","b2f44879":"code","41fbca53":"code","8b527b8c":"code","7682a931":"code","a5eb70a4":"code","cc9dce37":"code","2c8d76ca":"code","54402dbd":"code","09050fb6":"code","3aa940a9":"code","ae594e39":"code","2dd65094":"code","6eed1ff5":"code","0f0029e1":"code","0d4ecd61":"code","d8bb5ddd":"code","ba56fc51":"code","66c94408":"code","705d5b22":"code","aa16dfaa":"code","cc1c872e":"code","da2c0b39":"code","66900d62":"code","1985eaa3":"code","19cd1a36":"code","2b14602d":"code","951e80d4":"code","af68310d":"code","0a2d86b1":"code","4aca7d07":"code","130aa03c":"code","743e8312":"code","c13234a3":"code","8236ab5e":"code","f3595786":"code","3f96aa18":"code","98a6acd3":"code","142fc1cf":"code","17272949":"code","bd0d320d":"code","fe7b3dca":"code","a0375692":"code","f51970e7":"code","6985ec08":"code","e21bc5fa":"code","b1c3789c":"code","3053f5e2":"code","200bab76":"code","69043041":"code","fc8108d0":"code","a6c16e4e":"code","2c645e2f":"code","3887d1d1":"code","469210b2":"code","c71c1db3":"code","0a96cc5b":"code","59141bb7":"code","ca1d07b6":"code","4afefdc7":"code","79d74ec8":"code","00947498":"code","04f274da":"code","a1faf3b0":"code","470269c3":"code","1f11de67":"code","328b3aa9":"code","7daf4c91":"code","f122e255":"code","0a097e02":"code","159948ba":"code","6ffa1190":"code","132aeccb":"code","0583e499":"code","e78b7a62":"code","c00f5e68":"code","a9fb1d87":"code","9c21636b":"code","de1c721f":"code","bdb14c58":"code","acce5aad":"code","6b228f34":"code","edd41613":"code","7cfa0722":"code","e9f48597":"code","5163897a":"code","1043117c":"code","fe2a51f7":"code","360a2a9c":"code","c07e8af3":"code","9157fe1e":"code","96f6e4f1":"code","68a20d38":"code","27467aff":"code","4e66af48":"code","0390a2d0":"code","8a246710":"code","f9bcb44d":"markdown","5e4c062b":"markdown","2375b9ee":"markdown","c1a2fb27":"markdown","95302796":"markdown","1c1a2eee":"markdown","edc308b6":"markdown","dd2e11c5":"markdown","bb85bbc4":"markdown","466f7230":"markdown","4cfde844":"markdown","aa861a77":"markdown","df8d23aa":"markdown","f9d2f2e9":"markdown","66250531":"markdown","3ee4ec0a":"markdown","0c4320cb":"markdown","334e31f5":"markdown","955a23a8":"markdown","45d5f17d":"markdown","d5a88da5":"markdown","06f0ecbf":"markdown","3bdf68ed":"markdown","6f10c24b":"markdown","a95b0a10":"markdown","1d053b47":"markdown","add1bc8a":"markdown","94ad2326":"markdown","ca6e07d9":"markdown","5fcffb38":"markdown","5fa9f543":"markdown","7103aa15":"markdown","618f61bb":"markdown","948c07ef":"markdown","8f5b85b0":"markdown","e4e16d22":"markdown","e3649aff":"markdown","0fb730fc":"markdown","33f56859":"markdown","2ee9e33c":"markdown","d380c8aa":"markdown","cdf101d6":"markdown","19f6aeeb":"markdown","0cc96fbf":"markdown","ee4d2aeb":"markdown","9a3f4d20":"markdown","96a56ba3":"markdown","18dbcda2":"markdown","70a9d221":"markdown","b5b5b5eb":"markdown","1ad55ec9":"markdown","f15b2520":"markdown","92570cc6":"markdown","1f9ca497":"markdown","b9ee651d":"markdown","7727391e":"markdown","14beb824":"markdown","ab21a09b":"markdown","68f0d25b":"markdown","6b0486d1":"markdown","32ff98ec":"markdown","1d979fcb":"markdown","d941bc5d":"markdown","c3a76c60":"markdown"},"source":{"7bcb431b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d1733c4d":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()","de75a4a7":"train_df=pd.read_csv('..\/input\/titanic\/train.csv')","5d26bab9":"train_df['Target']=train_df['Survived'].astype(int)\ntrain_df['Survived']=train_df['Survived'].map({1:'Yes',0:'No'})\ntrain_df.head()","777076a6":"train_df.info()","ef02c339":"sns.kdeplot(train_df['Age'],shade=True)","2536254b":"sns.boxplot('Age',data=train_df)","da49c761":"train_df['Age'].describe()","309cebee":"train_df['Age'].median()","5e15acc0":"train_df['Age'].fillna(train_df['Age'].median(),inplace=True)","bf35ae01":"train_df['Age'].isna().any()","822477bb":"bins=np.arange(0,90,10) - 0.5\nplt.figure(figsize=(10,8))\nplt.hist(train_df['Age'],bins=bins)\nplt.xticks(rotation=90)","927c4280":"def child(passenger):\n    age,sex=passenger\n    if age<16:\n        return 'child'\n    else:\n        return sex","db1846ba":"train_df['Person']=train_df[['Age','Sex']].apply(child,axis=1)","50498106":"train_df['Person'].value_counts()","112473d6":"fig1=sns.FacetGrid(train_df,hue='Sex',aspect=2,height=6)\nfig1.map(sns.kdeplot,'Age',shade=True)\nfig1.add_legend()\n\n","5199c113":"fig2=sns.FacetGrid(train_df,hue='Person',aspect=2,height=8)\nfig2.map(sns.kdeplot,'Age',shade=True)\nfig2.add_legend()\n\n","0dadb943":"sns.catplot('Person',data=train_df,kind='count',hue='Survived',aspect=2,height=6)","f09d6d16":"sns.lmplot('Age','Target',data=train_df,aspect=2,height=6)","94fc4c08":"train_df['Embarked'].unique()","8d3bc200":"train_df['Embarked'].value_counts()","2378dae2":"train_df['Embarked'].isnull().value_counts()","b2f44879":"train_df['Embarked'].replace(np.nan,'S',inplace=True)","41fbca53":"train_df['Embarked'].isnull().any()","8b527b8c":"sns.catplot('Embarked',data=train_df,kind='count',aspect=2,height=6)","7682a931":"ax=sns.catplot('Embarked',data=train_df,kind='count',hue='Survived',aspect=2,height=6)\nax.set_xticklabels(['Southampton','Charlton','Queenstown'])","a5eb70a4":"deck=train_df['Cabin']","cc9dce37":"deck.isna().value_counts()","2c8d76ca":"deck=deck.dropna()","54402dbd":"levels=[]\nfor level in deck:\n    levels.append(level[0])\n    ","09050fb6":"cabin_df=pd.DataFrame(levels,columns=['Cabin level'])","3aa940a9":"cabin_df.head()","ae594e39":"cabin_df['Cabin level'].value_counts().sort_values(ascending=False)","2dd65094":"sns.catplot('Cabin level',data=cabin_df,kind='count',aspect=2,height=6,palette='summer_d')","6eed1ff5":"train_temp=train_df.copy()\ntrain_temp.isna().any()","0f0029e1":"train_temp=train_temp.dropna(axis=0)\ntrain_temp.reset_index(inplace=True,drop=True)","0d4ecd61":"train_temp['Level']=cabin_df['Cabin level']","d8bb5ddd":"sns.catplot('Level',kind='count',hue='Person',aspect=2,height=6,data=train_temp)","ba56fc51":"sns.catplot('Level',kind='count',hue='Survived',aspect=2,height=6,data=train_temp)","66c94408":"sns.factorplot('Survived',\n               data=train_temp,\n               kind='count',col='Level',\n               col_wrap=4,height=4,aspect=1)","705d5b22":"train_df['Pclass'].value_counts()","aa16dfaa":"sns.catplot('Pclass',data=train_df, kind='count')","cc1c872e":"sns.catplot('Pclass',data=train_df,kind='count',hue='Survived',aspect=2,height=6,palette='winter')","da2c0b39":"sns.lmplot('Age','Target',data=train_df,aspect=2,height=6,hue='Pclass')","66900d62":"\nsns.catplot('Pclass','Target',data=train_df,hue='Person',kind='point',aspect=2,height=6)\n","1985eaa3":"train_df['SibSp'].value_counts()","19cd1a36":"sns.catplot('SibSp',data=train_df,kind='count')","2b14602d":"sns.catplot('SibSp',data=train_df,kind='count',hue='Target',aspect=2,height=6)","951e80d4":"sns.lmplot('SibSp','Target',data=train_df)","af68310d":"train_df['Sex'].value_counts()","0a2d86b1":"sns.catplot('Sex',data=train_df,kind='count',hue='Survived')","4aca7d07":"sns.lmplot('Age','Target',data=train_df,hue='Sex',aspect=2,height=6)","130aa03c":"train_df['Parch'].unique()","743e8312":"train_df['Parch'].value_counts()","c13234a3":"sns.catplot('Parch',data=train_df,kind='count')","8236ab5e":"sns.catplot('Parch',data=train_df,kind='count',hue='Survived')","f3595786":"train_df['Total relatives']=train_df['Parch']+train_df['SibSp']","3f96aa18":"ax=sns.catplot('Total relatives','Target',kind='point',data=train_df,aspect=2,height=6)\nax.set_ylabels('Survival probability')","98a6acd3":"correlations=train_df.corr()\nplt.figure(figsize=(10,8))\nsns.heatmap(correlations,annot=True,cmap='summer')","142fc1cf":"train_mod=train_df.copy()","17272949":"train_mod.columns.isna()","bd0d320d":"train_mod.drop(['PassengerId','Survived','Sex','Name','Ticket','Cabin','Parch','SibSp'],axis=1,inplace=True)","fe7b3dca":"train_mod.head()","a0375692":"train_mod['Person']=train_mod['Person'].map({'male':1,'female':2,'child':3})\ntrain_mod.head()","f51970e7":"temp=pd.get_dummies(train_mod['Embarked'])","6985ec08":"train_mod=train_mod.merge(temp,on=train_mod.index)\ntrain_mod.head()","e21bc5fa":"train_mod.drop(['key_0','Embarked'],axis=1,inplace=True)\ntrain_mod.head()","b1c3789c":"train_mod.loc[train_mod['Age']<=16,'Age band']=0\ntrain_mod.loc[(train_mod['Age']>16) & (train_mod['Age']<33),'Age band']=1\ntrain_mod.loc[(train_mod['Age']>32) & (train_mod['Age']<49),'Age band']=2\ntrain_mod.loc[(train_mod['Age']>48) & (train_mod['Age']<65),'Age band']=3\ntrain_mod.loc[train_mod['Age']>64,'Age band']=4\ntrain_mod.head()","3053f5e2":"plt.figure(figsize=(10,8))\nplt.boxplot(train_df['Fare'])\nplt.ylabel('Fare value')\n\n","200bab76":"plt.figure(figsize=(10,7))\nsns.kdeplot(train_mod['Fare'],shade=True)","69043041":"train_mod.loc[(train_mod['Fare']<51),'Fare band']=1\ntrain_mod.loc[(train_mod['Fare']>50)&(train_mod['Fare']<101),'Fare band']=2\ntrain_mod.loc[(train_mod['Fare']>100)&(train_mod['Fare']<201),'Fare band']=3\ntrain_mod.loc[(train_mod['Fare']>200),'Fare band']=4\ntrain_mod.head()","fc8108d0":"train_mod.drop('Fare',axis=1,inplace=True)","a6c16e4e":"target_df=pd.DataFrame(columns=['Target'])\ntarget_df['Target']=train_mod['Target']","2c645e2f":"target_df['Target'].value_counts()","3887d1d1":"train_mod.drop('Target',axis=1,inplace=True)","469210b2":"train_mod.head()","c71c1db3":"from sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test=train_test_split(train_mod,target_df,test_size=0.2,shuffle=True,random_state=365)\n\n","0a96cc5b":"from sklearn.neighbors import KNeighborsClassifier\n\nknn=KNeighborsClassifier(n_neighbors=6)\nknn.fit(X_train,y_train)","59141bb7":"y_knn_pred=knn.predict(X_test)\nprint('Score with KNN on test dataset:{}'.format(np.round(knn.score(X_test,y_test) *100,2)))\nprint('Score with KNN on train dataset:{}'.format(np.round(knn.score(X_train,y_train) *100,2)))","ca1d07b6":"from sklearn.metrics import confusion_matrix\ncnf_knn=confusion_matrix(y_knn_pred,y_test)\nsns.heatmap(cnf_knn,annot=True,cmap='winter')","4afefdc7":"from sklearn.linear_model import LogisticRegression\nreg_log=LogisticRegression()\nreg_log.fit(X_train,y_train)","79d74ec8":"y_log_pred=reg_log.predict(X_test)\nprint('Score with Logistic regression on test dataset:{}'.format(np.round(reg_log.score(X_test,y_test) *100,2)))\nprint('Score with Logistic regression on train dataset:{}'.format(np.round(reg_log.score(X_train,y_train) *100,2)))","00947498":"cnf_reg=confusion_matrix(y_test,y_log_pred)\nsns.heatmap(cnf_reg,annot=True,cmap='gnuplot')","04f274da":"y_lr=reg_log.fit(X_train,y_train).decision_function(X_test)\nfrom sklearn.metrics import roc_curve,auc,precision_recall_curve\n\nfpr,tpr,_=roc_curve(y_test,y_lr)\nplt.plot(fpr,tpr,color='indianred')\nplt.plot([0,1],[0,1],linestyle='--')\nauc_reg=auc(fpr,tpr).round(2)\nplt.title('ROC curve with AUC={}'.format(auc_reg))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')","a1faf3b0":"precision,recall,threshold=precision_recall_curve(y_test,y_lr)\nclosest_zero=np.argmin(np.abs(threshold))\nclosest_zero_p=precision[closest_zero]\nclosest_zero_r = recall[closest_zero]\nplt.plot(precision,recall)\nplt.plot(closest_zero_p, closest_zero_r, 'o', markersize = 12, fillstyle = 'none', c='r', mew=3)\nplt.title('Precision-Recall curve with Logistic Regression')\nplt.xlabel('Precision')\nplt.ylabel('Recall')","470269c3":"from sklearn.svm import SVC\nsvc=SVC(gamma=1e-07,C=1e9)\nsvc.fit(X_train,y_train)","1f11de67":"y_svc_pred=svc.predict(X_test)\nprint('Score with SVC on test dataset:{}'.format(np.round(svc.score(X_test,y_test) *100,2)))\nprint('Score with SVC on train dataset:{}'.format(np.round(svc.score(X_train,y_train) *100,2)))","328b3aa9":"cnf_reg=confusion_matrix(y_test,y_svc_pred)\nsns.heatmap(cnf_reg,annot=True,cmap='summer',fmt='g')","7daf4c91":"y_svc=svc.fit(X_train,y_train).decision_function(X_test)\nfpr,tpr,_=roc_curve(y_test,y_svc)\nplt.plot(fpr,tpr,color='indianred')\nplt.plot([0,1],[0,1],linestyle='--')\nauc_reg=auc(fpr,tpr).round(2)\nplt.title('ROC curve with AUC={}'.format(auc_reg))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\n\n","f122e255":"precision,recall,threshold=precision_recall_curve(y_test,y_svc)\nclosest_zero=np.argmin(np.abs(threshold))\nclosest_zero_p=precision[closest_zero]\nclosest_zero_r = recall[closest_zero]\nplt.plot(precision,recall)\nplt.plot(closest_zero_p, closest_zero_r, 'o', markersize = 12, fillstyle = 'none', c='r', mew=3)\nplt.title('Precision-Recall curve with SVC')\nplt.xlabel('Precision')\nplt.ylabel('Recall')","0a097e02":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV","159948ba":"rfc=RandomForestClassifier()\nparam_grid={'n_estimators':[5,7,9,10], 'max_depth':[5,7,9,10]}\ngrid_search=GridSearchCV(rfc,param_grid,scoring='roc_auc')","6ffa1190":"X_train.drop('Age',axis=1,inplace=True)\nX_train.head()","132aeccb":"grid_result=grid_search.fit(X_train,y_train)","0583e499":"grid_result.best_params_","e78b7a62":"grid_result.best_score_","c00f5e68":"X_test.drop('Age',axis=1,inplace=True)","a9fb1d87":"\ny_rfc_pred=grid_result.predict(X_test)\nprint('Score with RFC on test dataset:{}'.format(np.round(grid_result.score(X_test,y_test) *100,2)))\nprint('Score with RFC on train dataset:{}'.format(np.round(grid_result.score(X_train,y_train) *100,2)))","9c21636b":"cnf_rfc=confusion_matrix(y_test,y_rfc_pred)\nsns.heatmap(cnf_rfc,annot=True,fmt='g')","de1c721f":"from sklearn.model_selection import cross_val_score\nrfc_opt=RandomForestClassifier(max_depth=5,n_estimators=9)","bdb14c58":"score_cv=cross_val_score(rfc_opt,X_train,y_train,cv=5,scoring='accuracy')","acce5aad":"cv_df=pd.DataFrame(columns=['Cross validated score'])\ncv_scores=np.round(score_cv*100,2)","6b228f34":"cv_df['Cross validated score']=cv_scores\ncv_df.index=cv_df.index + 1\ncv_df","edd41613":"print('Cross validated mean score: {}'.format(cv_scores.mean()))\nprint('Cross validated score standard deviation: {}'.format(np.round(cv_scores.std(),2)))","7cfa0722":"test_df=pd.read_csv('..\/input\/titanic\/test.csv')\ntest_df.head()","e9f48597":"\ntest_df.drop(['Name','Cabin','Ticket'],axis=1,inplace=True)\ntrain_df.head()","5163897a":"test_df['Total relatives']=test_df['SibSp']+test_df['Parch']\ntest_df.drop(['SibSp','Parch'],axis=1,inplace=True)\nembarks=pd.get_dummies(test_df['Embarked'])\ntest_df=test_df.merge(embarks,on=test_df.index)\ntest_df.drop(['key_0','Embarked'],axis=1,inplace=True)\ntest_df.head()","1043117c":"test_df['Person']=test_df[['Age','Sex']].apply(child,axis=1)\ntest_df.head()","fe2a51f7":"test_df['Person']=test_df['Person'].map({'male':1,'female':2,'child':3})\ntest_df['Age']=test_df['Age'].fillna(test_df['Age'].median())\ntest_df.loc[test_df['Age']<=16,'Age band']=0\ntest_df.loc[(test_df['Age']>16) & (test_df['Age']<33),'Age band']=1\ntest_df.loc[(test_df['Age']>32) & (test_df['Age']<49),'Age band']=2\ntest_df.loc[(test_df['Age']>48) & (test_df['Age']<65),'Age band']=3\ntest_df.loc[test_df['Age']>64,'Age band']=4\ntest_df.head()","360a2a9c":"test_df['Fare']=test_df['Fare'].fillna(test_df['Fare'].median())\ntest_df.isna().any()","c07e8af3":"test_df.loc[(test_df['Fare']<51),'Fare band']=1\ntest_df.loc[(test_df['Fare']>50)&(test_df['Fare']<101),'Fare band']=2\ntest_df.loc[(test_df['Fare']>100)&(test_df['Fare']<201),'Fare band']=3\ntest_df.loc[(test_df['Fare']>200),'Fare band']=4\ntest_df.head()","9157fe1e":"test_df.drop(['Sex','Age','Fare'],axis=1,inplace=True)\ntest_df.head()","96f6e4f1":"train_mod.head()","68a20d38":"test_df[train_mod.columns].head()","27467aff":"rfc_opt.fit(X_train,y_train)","4e66af48":"y_final_predictions=rfc_opt.predict(test_df[train_mod.columns])\nfinal_predictions_df=pd.DataFrame(columns=['PassengerId','Survived'])\nfinal_predictions_df['PassengerId']=test_df['PassengerId']\nfinal_predictions_df['Survived']=y_final_predictions","0390a2d0":"final_predictions_df.isna().any()","8a246710":"final_predictions_df","f9bcb44d":"## 9. Data Wrangling\n\nWe have visualised all the features in the previous sections. Now, we shall make changes to the dataframe to keep only the relevant features. We may modify or drop features such that it shall give us a good model prediction.","5e4c062b":"It could be said that 1st class passengers could have got a preferential treatment during evacuation process as a result of which, more 1st class passengers survived than ones that didn't. In 2nd class passengers, the survivors and deaths were nearly the same. \n\nAs expected, the 3rd class passengers must have been evacuated in the end and hence, couldn't be saved. It could also be due to the fact that the population of 3rd class passengers were highest. Hence, evacuating the passengers couldn't be completed due to the paucity of time.\n\n\nTo get a better understanding of the survival trend, let us make a lm plot to see the relation between age and survival with a hue of passenger class.","2375b9ee":"As we can see from the abpve graph, if there are 0-3 relatives, chances of survival is high. However, anything more than that leads to a drop in survival rate. Hence, we can consider the number of relatives to be an important factor.","c1a2fb27":"Let us visualise the data of each field so that we can understand how to deal with the NaN values.","95302796":"# B) Testing phase","1c1a2eee":"Most of the female passengers survived the accident as compared to males. This indicates that female passengers were evacuated first and hence, they survived. Let us check this with another plot.","edc308b6":"## We shall perform the same data wrangling and preprocessing which we have performed on the training dataset for the model to predict accurately.","dd2e11c5":"The above data shows that 3rd class passengers were maximum followed by 1st and 2nd class passengers. Let us check if Pclass has any correlation with survival.","bb85bbc4":"## 8. Checking correlation of the various features\n\nLet us check the correlation of the various features with each other using a heatmap.","466f7230":"From the available data, we have maximum passengers from level C followed by B.","4cfde844":"For adult males and females, the age distribution is extremely similar. Let us now compare it with the children.","aa861a77":"# Checking for NaN values in our dataframe","df8d23aa":"To streamline the effect of age, we group the ages as follows:\n* Ages<=16 : 0\n* Ages <=32 & >16 : 1\n* Ages <=48 & >32 : 2\n* Ages <=64 & >48 : 3\n* Ages >64 : 4\n\n\n\n\n","f9d2f2e9":"# K-Fold cross validation","66250531":"###  SVC","3ee4ec0a":"## 6. Sex","0c4320cb":"## Random Forest","334e31f5":"The above dataframe contains all the passengers who have been predicted to either survive or die the titanic disaster using the RFC.\n\n# The End","955a23a8":"Let us encode the person column as :\n\n1: Male\n\n2: Female\n\n3: Child","45d5f17d":"The above plot clearly indicates that with age, female passengers actually had a higher probability of survival.\n\nThis indicates that aged women were evacuated first and then the middle age and young ones.\n\nFor males, it was the opposite. Younger males had higher chance of survival.","d5a88da5":"## 7. Parents\/ Children","06f0ecbf":"Let us check if gender has any role to play in survival.","3bdf68ed":"Let us check if gender or being a child plays a role in survival from the ship.","6f10c24b":"The above plot proves our hypothesis that survival chances reduce as number of family members increase.","a95b0a10":"The only categorical data we have in the above data is the Embarked column. Let us one-hot encode the Embarked column.","1d053b47":"## 3. Cabin","add1bc8a":"As we can see, the test data is now preprocessed and can be used for machine learning.","94ad2326":"Hence, the standard deviation is at an appreciated low value. This means our cross validation scores are nearly similar for each fold. ","ca6e07d9":"Both the area under curve score and precision-recall curve are very close to logistic regression curves. Hence, their performances are very identical.","5fcffb38":"## 5. Siblings and spouses\n\nLet us check if having any siblings and spouses aboard had any relation to survival.","5fa9f543":"### KNN","7103aa15":"Let us visualise the data of the embarking stations.","618f61bb":"### Logistic Regression","948c07ef":"## We can finalise that we shall be using random forest classifier on our final test dataset.","8f5b85b0":"As we can see, ages between 20-30 is the highest followed by 30-40.\n\nLet us make another age group for children. Ages lower than 16 will be considered as a child. This way, we can segregate the children from the list of passengers.","e4e16d22":"Here, we can see that for children, max survivors were from 2nd class. For males, 3rd class survivors were higher than 2nd class. This is interesting to note as it was unexpected.","e3649aff":"# Machine Learning","0fb730fc":"From the above data, it can be seen that maximum passengers embarked in Southampton followed by Charlton and Queenstown. Let us now check the number of survivors from each of the embarking stations.","33f56859":"As we can see, with increase in age, probability of survival decreases. This could be due to the fact that older people found it more difficult to act quickly during the evacuation time as compared to the young and middle aged passengers.\n\n","2ee9e33c":"## Applying machine learning to the test dataframe","d380c8aa":"## 1. Age","cdf101d6":"Let us take a look at the fare paid by the customers.","19f6aeeb":"As we can see, there are two passengers whose embarking station isn't mantioned. As max passengers embarked at Southampton, we can make a brute assumption that these 2 passengers may have embarked at Southhampton. Let us replace NaN with S.","0cc96fbf":"Let us check the age distribution of all adults and children.","ee4d2aeb":"From the above boxplot, it is seen that the median fare is around 14 pounds while the high prices could go as high as 500 plus pounds. Hence, we need to divide these fares into fare bands. This will help take care of the non linear distribution of the fare and the presence of so many outliers.","9a3f4d20":"This particular feature is extremely problematic due to very high number of missing data. It'll be very difficult to fill null values with any cabin data. It is impossible to try to model this particular data. Hence, it will be wise to simply delete this feature. Inputting a feature with high missing values may induce high bias in our model. Never the less, let us check the correlation with surivival for the data we have.","96a56ba3":"From above data, we can say that maximum number of female adults survived the accident. Most male passengers died. For children, just above 50 percent survived while the rest could not.\n\nThe reason could be that most female passengers alongiwith their children were evacuated first from the ship. Males were probably evacuated in the end and hence, could not make it.\n\nLet us now see how age played at important role in survival.","18dbcda2":"## 4. Passenger class\n\nLet us visualise the data for passenger class.","70a9d221":"Hence, an optimum precision vs recall will be about 0.83 and 0.65 respectively","b5b5b5eb":"Hence, all missing values of Age has been taken care of. Let us now plot a histogram to check which age groups are maximum in the Titanic passengers.","1ad55ec9":"Let us check if having any parents or children played any important role in survival of the passengers.","f15b2520":"As we can see, Random forest classifier with max_depth=5 and n_estimators=9 gives the best train scores followed by Decision tree. Hence, tree based models have perfored better.\nLet us now perform a K-cross fold validation to prevent any overfitting issues.","92570cc6":"We can drop columns such as *PassengerID,Survived, Name,Sex,SibSp,Parch,Cabin and Ticket*","1f9ca497":"As it can be observed, the probability of survival from the same age group on class 1 was higher than class 3. Hence, it can be said that Passenger Class definitely has a good correlation to survival and will be an important feature of our dataset.\n\nLet us check how the survival of children, male and female adults vary.","b9ee651d":"Let us perform a 5 fold cross validation.","7727391e":"## 2. Embarked","14beb824":"As expected, many passengers who did not have to worry about any children survived. There are about 50% survivors amongst parents with 1 and 2 children aboard.\n\nDuring the data wrangling process, we can combine the Parch and SibSp columns as with relatives and without relatives to simplify the dataframe and prevent much data leakage. This process is shown below.","ab21a09b":"As is expected, many of the single passengers survived. This could be due to the fact that weren't reqiured to wait for any of the family members to deboard the ship and could be far easily be vacated. Fair number of people with one family member survived since it is realtively easier to find one family member instead of multiple family members.\n\nHence, it can be said that as family members increases, survival reduced.\nLet us check this hypothesis through a lmplot.","68f0d25b":"* S stands for Southampton.\n* C stands for Charlton.\n* Q stands for Queenstown.\n\n","6b0486d1":"As it can be seen, maximum number of passengers were actually alone. About 209 passengers had either a spouse or a sibling along with them.\n\nLet us now check if this feature realates to survival.\n\n","32ff98ec":"# Data Visualisation","1d979fcb":"The above data is now preprocessed and can be used for Machine Learning.","d941bc5d":"Hence, from the above, we can understand that the level location did have a significant impact on whether the person survived. Higher levels such as level A,B, C and D had good number of survivors. The lower decks had much fewer survivors. However, we can't add it to the model since maximum entries have missing entries. ","c3a76c60":"The division of fares maybe done as follows:\n\n* 0-50: 1 (General class)\n* 50-100: 2 (Economy class)\n* 100-200: 3 (Semi-premium)\n* 200+ : 4 (Premium)\n\n"}}