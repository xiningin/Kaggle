{"cell_type":{"edc40d0b":"code","e8477a86":"code","70c63496":"code","80490481":"code","b025cf2a":"code","e3a4af49":"code","d2f0f99c":"code","58709758":"code","5c69af74":"code","a26368f7":"code","5ff830f2":"code","40f6c5eb":"code","de7f5a3f":"code","aefcf2d1":"code","adbfb955":"code","800204e7":"code","45be6dda":"code","f9528e33":"code","bc53967a":"code","9147cd77":"code","1669f324":"code","605b438a":"code","f5d8e23d":"markdown","b8ea7171":"markdown","3aff2c85":"markdown","3f8e936e":"markdown","f230f03e":"markdown","87ca212e":"markdown","aa6ff01c":"markdown","5b49df5e":"markdown","acb971b6":"markdown","4813ffb4":"markdown","a1c4ef56":"markdown","d6026e9e":"markdown","0ee8942f":"markdown","4bffcf79":"markdown","1aad5454":"markdown","5734712a":"markdown","28de4666":"markdown","7afe93fd":"markdown","69b4c71a":"markdown","62e44089":"markdown","3ae201a2":"markdown","6f5444e3":"markdown"},"source":{"edc40d0b":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport seaborn as sb\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import FuncFormatter\nfrom pathlib import Path\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom keras.models import Sequential\nfrom keras.layers import Activation, Dense, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom keras.applications.resnet import preprocess_input\nfrom keras_preprocessing.image import ImageDataGenerator","e8477a86":"# print all columns\npd.set_option('display.max_columns', None)\n\n# inhibit graphics card runs out of memory\ngpu_devices = tf.config.experimental.list_physical_devices('GPU')\nfor device in gpu_devices:\n    tf.config.experimental.set_memory_growth(device, True)","70c63496":"def load_data(path: str):\n    dir = Path(path)\n    # list of all filepathes\n    filepaths = list(dir.glob(r'**\/*.png'))\n    # list of labels extracted from last foldername of filepath\n    labels = list(map(lambda l: os.path.split(os.path.split(l)[0])[1], filepaths))\n    # series of string filepathes\n    filepaths = pd.Series(filepaths, name='FilePaths').astype(str)\n    # series of string labels\n    labels = pd.Series(labels, name='Labels').astype(str)\n    # merge series to dataframe df\n    df = pd.merge(filepaths, labels, right_index=True, left_index=True)\n    # filter folders with GT (Ground Truth) at the end\n    df = df[df['Labels'].apply(lambda l: l[-2:] != 'GT')]\n    # Resampling complete rows and reset the index\n    return df.sample(frac=1).reset_index(drop=True)\n\ndf = load_data('..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset')","80490481":"df.head(3)","b025cf2a":"df.info()","e3a4af49":"def plot_images_per_label(df, label, cols: int, size: tuple):\n    fig, axs = plt.subplots(nrows=1, ncols=cols, figsize=size)\n\n    cntMax = cols\n    cntCur = 0\n    for index, row in df.iterrows():\n        if(row['Labels'] == label and cntCur < cntMax):\n            axs[cntCur].imshow(plt.imread(df.FilePaths[index]))\n            axs[cntCur].set_title(df.Labels[index])\n\n            cntCur += 1\n        else:\n            if(cntCur >= cntMax):\n                break\n    \n    plt.tight_layout()\n    plt.show()\n\n\n# unique labels\nlabels = sorted(df['Labels'].unique())\n# loop through labels\nfor label in labels:\n    plot_images_per_label(df, label, 3, (12,9))","d2f0f99c":"print(f\"Rows: {df.shape[0]}\\nColumns: {df.shape[1]} \")","58709758":"df['Labels'].value_counts(ascending=True)","5c69af74":"# stratisfied train and test (10%) datasets\nX_train, X_test = train_test_split(df, test_size=0.1, stratify=df['Labels'])\n# stratisfied train and val (20%) datasets\nX_train, X_val = train_test_split(X_train, test_size=0.2, stratify=X_train['Labels'])\n\nprint('Train Data: ', X_train.shape)\nprint('Val Data: ', X_val.shape)\nprint('Test Data: ', X_test.shape)\n\n# ordered count of rows per unique label\nX_train['Labels'].value_counts(ascending=True)","a26368f7":"# number of samples\/images per iteration\nBATCH_SIZE = 32\n# input image size\nIMG_SIZE = (224, 224)\n# count of epchos\nEPOCHS = 30\n\n# image preprocessing\ntrain_data_gen = ImageDataGenerator(shear_range=0.2,\n                                  zoom_range=0.2,\n                                  horizontal_flip=True,\n                                  preprocessing_function=preprocess_input)\n\ntest_data_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\nX_train = train_data_gen.flow_from_dataframe(dataframe=X_train,\n                                          x_col='FilePaths',\n                                          y_col='Labels',\n                                          target_size=IMG_SIZE,\n                                          color_mode='rgb',\n                                          class_mode='categorical',\n                                          batch_size=BATCH_SIZE,\n                                          seed=42)\n\nX_val = train_data_gen.flow_from_dataframe(dataframe=X_val,\n                                          x_col='FilePaths',\n                                          y_col='Labels',\n                                          target_size=IMG_SIZE,\n                                          color_mode='rgb',\n                                          class_mode='categorical',\n                                          batch_size=BATCH_SIZE,\n                                          seed=42)\n\nX_test = test_data_gen.flow_from_dataframe(dataframe=X_test,\n                                          x_col='FilePaths',\n                                          y_col='Labels',\n                                          target_size=IMG_SIZE,\n                                          color_mode='rgb',\n                                          class_mode='categorical',\n                                          batch_size=BATCH_SIZE,\n                                          shuffle=False, # necessary for confusion matrix\n                                          seed=42)\n","5ff830f2":"fit, ax = plt.subplots(nrows=2, ncols=3, figsize=(13,7))\n\nfor i, a in enumerate(ax.flat):\n    img, label = X_train.next()\n    a.imshow(img[0],)\n    a.set_title(label[0])\n\nplt.tight_layout()\nplt.show()","40f6c5eb":"model = Sequential()\n# scale image size to 0..1\nmodel.add(tf.keras.layers.experimental.preprocessing.Rescaling(1.\/255))\n\n# 1. Conv2D layer\nmodel.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', input_shape=(224, 224, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\n\n# 2. Conv2D layer\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\n\n# 3. Conv2D layer\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\n\n# scale to 1 dimensional input for NN\nmodel.add(Flatten())\n\n# hidden fully connected layer\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\n\n# inhibit overfitting\nmodel.add(Dropout(0.2))\n\n# output fully connected layer\nmodel.add(Dense(9))\nmodel.add(Activation('softmax'))\n\n# compile model\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","de7f5a3f":"# stop training when accuracy has stopped improving \n# cb = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=3)\n# hst = model.fit(X_train, validation_data=X_val, epochs=EPOCHS, callbacks=cb)\n# train model \nhst = model.fit(X_train, validation_data=X_val, epochs=EPOCHS)","aefcf2d1":"model.save_weights('model1',save_format='tf', overwrite=True)","adbfb955":"# model.load_weights('model1')","800204e7":"model.summary()","45be6dda":"accuracy = hst.history['accuracy']\nloss = hst.history['loss']\nval_loss = hst.history['val_loss']\nval_accuracy = hst.history['val_accuracy']\n\nplt.figure(figsize=(17, 12))\nplt.subplot(2, 2, 1)\nplt.plot(range(EPOCHS), accuracy, label='Training Accuracy')\nplt.plot(range(EPOCHS), val_accuracy, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Accuracy : Training vs. Validation ')\n\nplt.subplot(2, 2, 2)\nplt.plot(range(EPOCHS), loss, label='Training Loss')\nplt.plot(range(EPOCHS), val_loss, label='Validation Loss')\nplt.title('Loss : Training vs. Validation ')\nplt.legend(loc='upper right')\nplt.show()","f9528e33":"res = model.evaluate(X_test)","bc53967a":"# accuracy\nprint(f'Train Accuracy: {hst.history[\"accuracy\"][-1:][0] * 100:.2f}')\nprint(f'Val Accuracy: {hst.history[\"val_accuracy\"][-1:][0] * 100:.2f}')\nprint(f'Test Accuracy: {res[1] * 100:.2f}')\n# loss\nprint(f'Train Loss: {hst.history[\"loss\"][-1:][0] * 100:.2f}')\nprint(f'Val Loss: {hst.history[\"val_loss\"][-1:][0] * 100:.2f}')\nprint(f'Test Loss: {res[0] * 100:.2f}')","9147cd77":"# predicted labels\nY_pred = model.predict(X_test)\nprint(\"Y_pred\", Y_pred.shape)\n# rounded labels\ny_pred = np.argmax(Y_pred, axis=1)\nprint(\"y_pred\", y_pred.size)","1669f324":"# true labels\ny_true = X_test.classes\nprint(\"y_pred\", len(y_pred))\n# label classes\nclass_labels = list(X_test.class_indices.keys())\nprint(\"labels\", len(class_labels))","605b438a":"# compare with true labels\ncfm = confusion_matrix(y_pred, y_true, normalize='true')\n\n# plot size\nfig, ax = plt.subplots(figsize=(18,18))\n# print confusion matrix\ns = sb.heatmap(cfm,\n                annot=True,\n                cmap=['#ff0000', '#09AA00'],\n                center=0.8,\n                fmt='.1%',\n                linewidths=.5,\n                cbar_kws={'format': FuncFormatter(lambda x, pos: '{:.0%}'.format(x))}, #'label': 'Percentage' \n                linecolor='white',\n                ax=ax)\n# set labels\ns.set(xlabel='Predict', ylabel='True')\ns.set(title='Confusion Matrix')\ns.set(xticklabels=class_labels, yticklabels=class_labels)","f5d8e23d":"### Save the model","b8ea7171":"### Preprocess images","3aff2c85":"### Count of rows and cols from the dataset","3f8e936e":"### Print first rows","f230f03e":"### Print a short summary of the dataset","87ca212e":"### Calc y_pred","aa6ff01c":"### Load the model","5b49df5e":"### Training vs. Validation","acb971b6":"### Print model summary ","4813ffb4":"### Settings","a1c4ef56":"### Split the dataset into Train-, Val- and Test datasets","d6026e9e":"### Accuracies and results","0ee8942f":"### Print confusion matrix","4bffcf79":"### Import modules","1aad5454":"### Plot images after preprocessing","5734712a":"### Create and compile CNN model","28de4666":"### Load data","7afe93fd":"### Test model","69b4c71a":"### Plot 3 images per label ","62e44089":"### Ordered count of rows per unique label","3ae201a2":"### Train model","6f5444e3":"### Calc y_true"}}