{"cell_type":{"17d1315b":"code","6a5ac2d1":"code","34f33602":"code","f5e07b43":"code","d73cc8d1":"code","ed62926e":"code","03d0e3af":"code","b1e9d60d":"code","41b03fda":"code","c53160cb":"code","1df3138d":"code","8967bce4":"code","9b38c0f0":"code","84fbdea9":"code","3acc1ac3":"code","f56924c8":"code","dc832cf3":"code","e1714c0b":"code","3f03b113":"code","a15ef5ba":"code","0def823a":"code","e69b8203":"code","119871ad":"code","faf5bbfd":"code","3c250a15":"code","a5812d80":"code","78f410a4":"code","46d5ee68":"code","5c44783c":"code","7cb25e08":"code","f091f493":"code","9ba9abf4":"code","adde9683":"code","42e9d7e0":"code","4e3008f3":"code","bceb8a33":"code","e634f28d":"code","8f8bbe09":"code","6c704e63":"code","a0e44706":"code","6b135eb8":"code","9ed93ea6":"code","1ff58d6b":"code","57a62f76":"code","b2f31194":"code","aae40d9a":"code","93d63477":"code","c3ba7c68":"code","f753ea35":"code","36ed1496":"code","ae571ff9":"code","7ae41d4d":"code","2fa50a49":"code","787ae902":"code","d84d4c64":"code","d140e8b6":"code","ed8043f4":"code","58d07cfe":"code","0de7ace2":"code","83764a69":"code","503330ae":"code","ac0cf718":"code","b1207728":"code","4f30c1c6":"code","89bd4aef":"code","df9d2089":"code","ecf06099":"code","6df839c0":"code","3ba8e8bb":"code","1cbb5ec2":"code","3db6832d":"code","1ba46b94":"code","095a4869":"code","e617b657":"code","140648a2":"code","39d4a3c9":"code","657e8077":"code","d47b692b":"code","7976e264":"code","7943b36d":"code","5abbaaf9":"code","d617ca29":"code","7fe6ef50":"code","c1f995e4":"code","8edb3ce2":"code","73aa5a2d":"markdown","41d77a66":"markdown","d8102396":"markdown","9b34582d":"markdown","f3968f78":"markdown","0c2702e8":"markdown","786c008a":"markdown","88bbf39b":"markdown","4a111421":"markdown","238e2401":"markdown","3e249385":"markdown","3f1687b5":"markdown","1a580c2f":"markdown","f7a07e60":"markdown","092d7ec9":"markdown","7e603354":"markdown","812ea125":"markdown","59f09925":"markdown","c6031af9":"markdown","c1d5ee54":"markdown","d36f416a":"markdown","0f9eb9f2":"markdown","1bda2bed":"markdown","5b7a8922":"markdown","2f98976b":"markdown"},"source":{"17d1315b":"#load the packages\nimport numpy as np\nimport pandas as pd\nimport os\n#visualization imports\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n#consistent sized plots\nfrom pylab import rcParams\nrcParams['figure.figsize']=12,5\nrcParams['axes.labelsize']=12\nrcParams['xtick.labelsize']=12\nrcParams['ytick.labelsize']=12\n#display all columns \npd.options.display.max_columns = None\n#handle unwanted warnings\nimport warnings\nwarnings.filterwarnings(action='ignore',category=DeprecationWarning)\nwarnings.filterwarnings(action='ignore',category=FutureWarning)","6a5ac2d1":"#load the data\ntrain = pd.read_csv('\/kaggle\/input\/machinehack-music-genre-hackathon\/train.csv',delimiter=',',encoding='IBM862',engine='python')\ntest = pd.read_csv('\/kaggle\/input\/machinehack-music-genre-hackathon\/test.csv',delimiter=',',encoding='IBM862',engine='python')","34f33602":"#view the top rows\ntrain.head()","f5e07b43":"#check for duplicates \nlen(train[train.duplicated()==True])","d73cc8d1":"#trim artist name and track name of leading white spaces and convert to lower case\ntrain['Artist Name'] = train['Artist Name'].str.strip()\ntest['Artist Name'] =  test['Artist Name'].str.strip()\n\ntrain['Track Name'] = train['Track Name'].str.strip()\ntest['Track Name'] =  test['Track Name'].str.strip()\n\ntrain['Artist Name'] = train['Artist Name'].str.lower()\ntest['Artist Name'] =  test['Artist Name'].str.lower()\n\ntrain['Track Name'] = train['Track Name'].str.lower()\ntest['Track Name'] =  test['Track Name'].str.lower()","ed62926e":"#check the info \ntrain.info()","03d0e3af":"#check the basic stats\ntrain.describe().transpose()","b1e9d60d":"#check the various classes \/ labels\ntrain['Class'].unique()","41b03fda":"#check the number of different class types\ntrain['Class'].value_counts().sort_values(ascending=False)","c53160cb":"#plot of the Class \/ Music Genre count\nplt.figure(figsize=(14,4))\nsns.countplot(y=train['Class'])\nplt.title('Distribution of the Music Genre')\nplt.ylabel('Genres')\nplt.xlabel('Count of Genres')\nplt.grid()\nplt.show()","1df3138d":"#import train test split and create the X features and y labels \nfrom sklearn.model_selection import train_test_split\nX = train.drop('Class',axis=1)\ny = train[['Class']]\ntest_size = 0.1\nseed = 41\n\n#split the dataset\nX_train,X_dev,y_train,y_dev = train_test_split(X,y,test_size=test_size,random_state=seed,stratify=train['Class'],shuffle=True)","8967bce4":"#check top rows of X_train\nX_train.head(2)","9b38c0f0":"y_train.head(2)","84fbdea9":"#check the correlation map\nsns.heatmap(X_train.corr())\nplt.show()","3acc1ac3":"#check for the null values\nsns.heatmap(X_train.isna(),yticklabels=False,cbar=False)\nplt.title('Visualize Features with Null Values')\nplt.show()\n","f56924c8":"#check the top 10 artists in the dataset \nX_train['Artist Name'].value_counts().sort_values(ascending=False)[:10]","dc832cf3":"#check the unique track names in the dataset\nX_train['Track Name'].nunique()","e1714c0b":"len(X_train)","3f03b113":"#list down the track names in the descending order of their frequency\nX_train['Track Name'].value_counts().sort_values(ascending=False)","a15ef5ba":"#check one of the repeated tracks\nX_train[X_train['Track Name']=='runaway']","0def823a":"#check another of repeated tracks to spot any new observation .. \nX_train[X_train['Track Name']=='dreams']","e69b8203":"#get rid of the absolute duplicate records from the dataset \nindices_duplicated_xtrain = X_train[X_train.duplicated(keep='first')==True].index\nindices_duplicated_xdev = X_dev[X_dev.duplicated(keep='first')==True].index","119871ad":"warnings.filterwarnings(action='ignore')\n\n#drop the duplicates\nX_train.drop_duplicates(keep='first',inplace=True)\nX_dev.drop_duplicates(keep='first',inplace=True)","faf5bbfd":"indices_retain_xtrain = X_train.index\nindices_retain_xdev = X_dev.index","3c250a15":"indices_retain_xtrain","a5812d80":"#remove the corresponding labels from y_train and y_dev\ny_train = y_train.loc[indices_retain_xtrain]\ny_dev = y_dev.loc[indices_retain_xdev]","78f410a4":"#check the length of the X_train and y_train --> one way to confirm \nlen(X_train), len(y_train)","46d5ee68":"#check the match in indices --> first few indices, a more robust algo can also be written\nprint(X_train.index[:10])\nprint(y_train.index[:10])","5c44783c":"X_train.head()","7cb25e08":"X_train['Track Name'].value_counts().sort_values(ascending=False)","f091f493":"X_train[X_train['Track Name']=='Runaway']","9ba9abf4":"plt.figure(figsize=(12,5))\nplt.hist(X_train['duration_in min\/ms'],bins=50)\nplt.title('Duration of the music')\nplt.grid()\nplt.show()","adde9683":"def duration_min(duration):\n    '''This function will convert the millisecond duration music in minutes'''\n    if duration > 1000: #1000 is a safe lower limit\n        duration = duration \/ 60000\n    return duration","42e9d7e0":"#convert the duration in minutes\nX_train['duration_in min\/ms'] = X_train['duration_in min\/ms'].apply(duration_min)","4e3008f3":"#convert the duration in minutes in the dev set\nX_dev['duration_in min\/ms'] = X_dev['duration_in min\/ms'].apply(duration_min)","bceb8a33":"X_train.head(2)","e634f28d":"#apply the changes in the test dataset\ntest['duration_in min\/ms'] = test['duration_in min\/ms'].apply(duration_min)","8f8bbe09":"plt.figure(figsize=(12,5))\nplt.hist(X_train['duration_in min\/ms'],bins=50)\nplt.title('Duration of the music in minutes')\nplt.grid()\nplt.show()","6c704e63":"#select only the numerical features\nnumerical_features =  X_train.select_dtypes(exclude='object')","a0e44706":"#create histogram of all the numerical features \nnumerical_features.hist(bins=50, figsize=(20,15))\nplt.show()","6b135eb8":"categorical_features = X_train.select_dtypes(include='object').columns.tolist()","9ed93ea6":"categorical_features","1ff58d6b":"X_train['mode'].value_counts()","57a62f76":"X_train.info()","b2f31194":"#check how many similar track names still appear\nX_train['Track Name'].value_counts().sort_values(ascending=False)","aae40d9a":"X_train['Artist Name'].nunique()","93d63477":"#label encode the categorical features\nfrom sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\ntrain_cat_features = ['Artist Name']\nfor col in train_cat_features:\n    encoder.fit(list(X_train[col].values) + list(X_dev[col].values) + list(test[col].values))\n    X_train[col] = encoder.transform(list(X_train[col].values))\n    X_dev[col] =   encoder.transform(list(X_dev[col].values))\n    test[col] =    encoder.transform(list(test[col].values))","c3ba7c68":"X_train.head(3)","f753ea35":"X_dev.head(3)","36ed1496":"test.head(2)","ae571ff9":"X_train.columns","7ae41d4d":"numeric_columns = ['Popularity', 'danceability', 'energy',\n       'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n       'instrumentalness', 'liveness', 'valence', 'tempo',\n       'duration_in min\/ms', 'time_signature']","2fa50a49":"from sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer","787ae902":"#carve out only the numerical features \nX_train_num = X_train[numeric_columns]\nX_dev_num = X_dev[numeric_columns]\ntest_num = test[numeric_columns]","d84d4c64":"#impute the values in the numerical features\nimputer = IterativeImputer()\ntrain_imputed = imputer.fit_transform(X_train_num)\nX_train_num = pd.DataFrame(data=train_imputed,columns=numeric_columns)","d140e8b6":"#apply the impute transform on the dev and the test set\ndev_imputed = imputer.transform(X_dev_num)\ntest_imputed = imputer.transform(test_num)\n\nX_dev_num = pd.DataFrame(data=dev_imputed,columns=numeric_columns)\ntest_num = pd.DataFrame(data=test_imputed,columns=numeric_columns)","ed8043f4":"X_train.drop(numeric_columns,axis=1,inplace=True)\nX_dev.drop(numeric_columns,axis=1,inplace=True)\ntest.drop(numeric_columns,axis=1,inplace=True)","58d07cfe":"X_train","0de7ace2":"#add the imputed columns\nfor feature in numeric_columns:\n    X_train[feature] = X_train_num[feature].values\n    X_dev[feature] = X_dev_num[feature].values\n    test[feature] = test_num[feature].values    ","83764a69":"X_train.head()","503330ae":"X_train.isna().sum().sum()","ac0cf718":"X_dev.isna().sum().sum()","b1207728":"test.isna().sum().sum()","4f30c1c6":"import string\n#remove the special characters \/ punctuations from the track name\nX_train['Track Name'] = X_train['Track Name'].str.replace('[{}]'.format(string.punctuation),'')","89bd4aef":"X_dev['Track Name'] = X_dev['Track Name'].str.replace('[{}]'.format(string.punctuation),'')\ntest['Track Name'] = test['Track Name'].str.replace('[{}]'.format(string.punctuation),'')","df9d2089":"#remove all the digits\nX_train['Track Name'] = X_train['Track Name'].str.replace(r'[\\d]*','',regex=True)\nX_dev['Track Name'] = X_dev['Track Name'].str.replace(r'[\\d]*','',regex=True)\ntest['Track Name'] = test['Track Name'].str.replace(r'[\\d]*','',regex=True)","ecf06099":"X_train.head()","6df839c0":"from nltk.corpus import stopwords\nstop_words = stopwords.words('english')","3ba8e8bb":"from nltk.tokenize import word_tokenize\ndef rem_stopword(text):\n    '''function to remove the stopwords from a text column of a dataframe'''\n    words = ' '.join([word for word in word_tokenize(text) if word not in stop_words])\n    return words","1cbb5ec2":"X_train['Track Name'] = X_train['Track Name'].apply(rem_stopword)","3db6832d":"X_dev['Track Name'] = X_dev['Track Name'].apply(rem_stopword)\ntest['Track Name'] = test['Track Name'].apply(rem_stopword)","1ba46b94":"X_train.head(3)","095a4869":"#!pip install --upgrade tensorflow_hub\nimport tensorflow_hub as hub\n#download the model\nembed = hub.load(\"https:\/\/tfhub.dev\/google\/universal-sentence-encoder-large\/5\")","e617b657":"#generate embeddings\nembeddings = embed(X_train['Track Name'])\n#create list from np arrays\nuse= np.array(embeddings).tolist()\n#add lists as dataframe column\nX_train['Track Name Embeddings'] = use\n#check dataframe\nX_train.head(2)","140648a2":"#generate embeddings\nembeddings = embed(X_dev['Track Name'])\n#create list from np arrays\nuse= np.array(embeddings).tolist()\n#add lists as dataframe column\nX_dev['Track Name Embeddings'] = use\n#check dataframe\nX_dev.head(2)","39d4a3c9":"#generate embeddings\nembeddings = embed(test['Track Name'])\n#create list from np arrays\nuse= np.array(embeddings).tolist()\n#add lists as dataframe column\ntest['Track Name Embeddings'] = use\n#check dataframe\ntest.head(2)","657e8077":"#install this package\n!pip install texthero","d47b692b":"#load texthero\nimport texthero as hero","7976e264":"X_train['tsneuse'] = hero.tsne(X_train['Track Name Embeddings'])","7943b36d":"X_train.head(2)","5abbaaf9":"#create scatter plot of uni. sent. enc.\nhero.scatterplot(X_train, col='tsneuse',title=\"Track Name on 2-Dimension Embedding using Universal Sentence Encoder\",color='Popularity')","d617ca29":"#perform dimensionality reduction using t-SNE on the dev and the test set \nX_dev['tsneuse'] = hero.tsne(X_dev['Track Name Embeddings'])\ntest['tsneuse'] = hero.tsne(test['Track Name Embeddings'])","7fe6ef50":"X_train['tsneuse'].dtype","c1f995e4":"X_train.info()","8edb3ce2":"X_train.head(3)","73aa5a2d":"<a name='3-3'><\/a>\n## _Handle the text field Track Name_\n\n- _Clean the text_ \n- _Apply Universal Sentence Encoder Large to generate the embeddings_","41d77a66":"<a name='3-3-1'><\/a>\n### _Clean the Text_","d8102396":"<a name='3-3-2'><\/a>\n## _Generate embeddings using tensorflow hub universal sentence encoder_\nReference:https:\/\/towardsdatascience.com\/how-to-vectorize-text-in-dataframes-for-nlp-tasks-3-simple-techniques-82925a5600db","9b34582d":"- _There are 17,996 observations in the dataset_\n- _Features \"key\" and \"intrumentalness\" have missing values_\n- _Artist Name and Track Name are the only string features. Remaining all the features are of numerical type_","f3968f78":"_The duration is either in minutes or in milliseconds and hence the histogram is so highly skewed. It would be better to convert them to a single unit measure in minutes_","0c2702e8":"- _There is correlation between some of the features. Example loudness, energy and acouticness are highly correlated_\n- _Similarly danceability and valence is also correlated_\n\nUsing a dimensionality reduction technique would help to reduce the features before feeding into the model.","786c008a":"<b> _Before proceeding further, lets split the dataset into train and dev set. While we would explore the train set, the dev set would be used to validate the model performance and generalization_ <\/b>","88bbf39b":"<a name='4'><\/a>\n## _Conclusion_\n-  Vectorizing text data can be done via Word2Vec, Doc2Vec model using gensim libraries, Bag of Words\/Tf-IDF approach as well. In this notebook, the approach using google's universal senetence encoder is demonstrated. Check https:\/\/tfhub.dev\/google\/universal-sentence-encoder-large\/5\n- texthero is a convenient package. Check for more information here https:\/\/texthero.org\/\n\n- This notebook is inspired from the article https:\/\/towardsdatascience.com\/how-to-vectorize-text-in-dataframes-for-nlp-tasks-3-simple-techniques-82925a5600db","4a111421":"<a name='2-2'><\/a>\n## _Harmonizing Duration Feature_","238e2401":"_The number of unique tracks is lesser than the total number of rows in the X_train. There are either duplicate tracks or two artist seem to have a similar track name_","3e249385":"<a name='1'><\/a>\n## _Import Libraries_","3f1687b5":"_The same artist name and same track name could result due to date merging from different apps where the music is listed. It is unlikely that the same artist may have the same track name. One possibility is if the same track is listed again with a different musical background. For example it is very common to spot unplugged version, altered version with higher beats, remix etc. These differences can be noiticed with the other features of the dataset like energy, danceability, valence, loudness and acousticness. A musician would be better positioned to spot the differences_","1a580c2f":"<a name='3'><\/a>\n## _Data Preparation_\n***","f7a07e60":"<a name='3-2'><\/a>\n## _Handling the missing values using Iterative Imputer_","092d7ec9":"## Table of Contents\n\n- [1 - Import Libraries and Load Data](#1)\n- [2 - Basic Exploratory Data Analysis](#2)\n    - [2.1 - An ingisht into Spotting Duplicate Records](#2-1)\n    - [2.2 - Harmonizing the Duration Feature Values](#2-2)\n    \n- [3 - Data Preparation](#3)\n    - [3.1 - Handling Missing Values using Iterative Imputer](#3-1)\n    - [3.2 - Label Encode the Artist Name](#3-2)\n    - [3.3 - Handling Text Data in Track Name](#3-3)\n        - [3.3.1 - Clean the Text Data](#3-3-1)\n        - [3.3.2 - Generate Embeddings using Tensorflow Universal Sentence Encoder](#3-3-2)\n        - [3.3.3 - t-SNE Non Linear Dimensionality Reduction using texthero package](#3-3-3)\n        - [3.3.4 - Visualizing the Embeddings on 2Dimensions](#3-3-4)\n- [ 4 - Conclusion](#4)\n","7e603354":"<a name='3-3-4'><\/a>\n## _Visualize Embeddings_","812ea125":"<a name='3-1'><\/a>\n## _Label Encode the Artist Name_\n_Test dataset contains artist names not in the train dataset and hence the below approach is a workaround. This is not the preferred way to label encode when launching model into production. In real scenario we may not even know what the test data is going to contain. Handling of this scenario is beyond the scope of this notebook_ ","59f09925":"<a name='2-1'><\/a>\n## _An insight into spotting the Duplicate records_","c6031af9":"_This is an imbalanced dataset. For model training, it would be appropriate to split based on stratification on the Class label_","c1d5ee54":"## _Load the Data_","d36f416a":"- _There are clear duplicate records in the dataset. Observe the row index 15513 and 9102_\n- _The same track name is repeated for different artists as well.One way to handle such instance would be to combine the artist name and the track name together_","0f9eb9f2":"<a name='3-3-3'><\/a>\n## _t-SNE Non Linear Dimensionality Reduction using texthero_","1bda2bed":"<a name='2'><\/a>\n## _Basic Exploratory Data Analysis_","5b7a8922":"# _Music Genre - EDA and Text Vectorization using Universal Sentence Encoder_\n\n## _Overview_\nMusic has been an important part of our lives since time immemorial. Every artist has a signature, making music a subjective art. We have scales\/metrics to measure the quality of music. But, is it possible to train a machine learning model to predict the genre and quality of the music?\n\nCurrently, many music aggregator applications rely on machine learning to power their recommendation engine, and curate playlists. MachineHack is challenging data scientists and machine learning practitioners to build a highly scalable ML model for a music aggregator app (Company ABC) to accurately predict the genre of songs in the dataset.\n\nAbout Dataset:\n\nTraining dataset: 17,996 rows with 17 columns \n\nColumn details: artist name; track name; popularity; \u2018danceability\u2019; energy; key; loudness; mode; \u2018speechiness\u2019; \u2018acousticness\u2019; \u2018instrumentalness\u2019; liveness; valence; tempo; duration in milliseconds and time_signature. \n\nTarget Variable: 'Class\u2019 such as Rock, Indie, Alt, Pop, Metal, HipHop, Alt_Music, Blues, Acoustic\/Folk, Instrumental, Country, Bollywood, \n\nTest dataset: 7,713 rows with 16 columns \n\nDataset is taken from https:\/\/machinehack.com\/hackathons\/music_genre_classification_weekend_hackathon_edition_2_the_last_hacker_standing\/data","2f98976b":"_According to this there are no duplicates. We would test this out more when the dataset is analyzed separately without the class labels. Key question is whether the same music can land up in different genres based on the values of the other features like energy, danceability. Perhaps yes, if it is an unplugged version or a remix version_"}}