{"cell_type":{"3e50cfe6":"code","d67afdde":"code","ec4380ff":"code","a1c01a00":"code","acab30ef":"code","e4914e90":"code","4d8d4bce":"code","283b1729":"code","c9d24f18":"code","bf99b475":"code","b55ade1d":"code","d0bbd948":"code","6be6bfd1":"code","b275b7ec":"code","396f0c6b":"code","06c9aca7":"code","e92ad531":"code","81369a33":"code","e412965b":"code","56e1f702":"code","24111cc8":"code","29f207fb":"code","64a754ab":"code","c704eb77":"code","3615d606":"code","2ed35511":"code","6870ec8b":"code","f7c4bfb2":"code","60c8d325":"code","f9f907bf":"code","68928556":"code","c36e5c2e":"code","df3f15da":"code","519b0fe5":"code","c76802bb":"code","b5c2fb5b":"code","15570b25":"code","7e4637dc":"code","1fb3c6d6":"code","1178816a":"code","c92b0322":"code","90a78eb5":"code","a8a52443":"code","957c41e2":"code","96463999":"code","c46aa1dd":"code","6adcf538":"code","c17d4c0c":"code","060568d0":"code","b8369160":"code","eaafb545":"code","97873e1d":"code","5c61076a":"code","827dd844":"code","7225b7f6":"markdown","d05acc45":"markdown","d3fe5e32":"markdown","bfde0101":"markdown","a9a49adf":"markdown","198fe042":"markdown","f563b8be":"markdown","7f5ca1a5":"markdown","ae5c1a3d":"markdown","eeb8f93a":"markdown","b9a497db":"markdown","8ce020d0":"markdown","5424e6c6":"markdown","779c3520":"markdown","d5081291":"markdown","9658c96f":"markdown","ffef7a6c":"markdown","1ea56dd2":"markdown","91df2d11":"markdown","8bdbb748":"markdown","2b93a460":"markdown","bc31468f":"markdown","e7bd8f68":"markdown","09309f45":"markdown","15552506":"markdown","cb7037bd":"markdown","496c36e8":"markdown","2d430ec7":"markdown","8a315700":"markdown","87c2415d":"markdown","670df3b8":"markdown","502440f7":"markdown","37ffc58f":"markdown","b3b88a8a":"markdown","02676db7":"markdown","92083dcf":"markdown","142f6a3d":"markdown"},"source":{"3e50cfe6":"import pandas as pd, numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sns \nimport warnings \nwarnings.filterwarnings('ignore')","d67afdde":"data = pd.read_csv('..\/input\/wine-quality-classification\/wine_quality_classification.csv', engine='python')","ec4380ff":"data.head()","a1c01a00":"data.info()","acab30ef":"data.isnull().sum()","e4914e90":"data['quality'] = data['quality'].replace({'good' : 1, 'bad' : 0})","4d8d4bce":"data.describe()","283b1729":"data.quantile(np.linspace(0.90,1,12))","c9d24f18":"x_vars = data.columns[data.columns != 'quality']\nfig,ax = plt.subplots(len(x_vars))\nfig.set_figheight(24)\nfig.set_figwidth(12)\nfor num,i in enumerate(x_vars) : \n    ax[num].set_title(i)\n    ax[num].set_xlabel('')\n    sns.boxplot(data[i],ax=ax[num])","bf99b475":"# removing outliers : \nx_vars = data.columns[data.columns != 'quality']\nfor i in x_vars :\n    q1 = data[i].quantile(0.25)\n    q3 = data[i].quantile(0.75)\n    upper_extreme = data[i].quantile(0.75) + 1.5*(q3-q1) # q3-q1 is IQR\n    lower_extreme = data[i].quantile(0.75) - 1.5*(q3-q1)\n    mask =  (data[i] > lower_extreme) & (data[i] < upper_extreme)  # sans outliers\n    outliers = data[mask].index\n    data.drop(index=outliers)\n","b55ade1d":"from sklearn.model_selection import train_test_split\ny = data.pop('quality')\nX = data\n","d0bbd948":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=100)","6be6bfd1":"# In our case, all the independent variables are continuous\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train[X_train.columns] = scaler.fit_transform(X_train[X_train.columns])\n\n# Scaling test set for later use\nX_test[X_train.columns] = scaler.transform(X_test[X_train.columns])","b275b7ec":"plt.figure(figsize=[20,10])\nsns.heatmap(X_train.corr(),annot=True)\nplt.title('Visualizing Correlations')\nplt.show()","396f0c6b":"import statsmodels.api as sm","06c9aca7":"# Logistic Regression Model \nlogm1 = sm.GLM(y_train, sm.add_constant(X_train),family=sm.families.Binomial())\nlogm1.fit().summary()","e92ad531":"from sklearn.linear_model import LogisticRegression\nlogReg = LogisticRegression()","81369a33":"from sklearn.feature_selection import RFE \nrfe = RFE(logReg,10)\nrfe = rfe.fit(X_train,y_train)","e412965b":"## RFE results\nrfe_results = list(zip(X_train.columns,rfe.support_,rfe.ranking_))\nsorted(rfe_results,key=lambda x : (x[2]))","56e1f702":"X_train.drop(columns=['pH'],inplace=True)\nX_test.drop(columns=['pH'],inplace=True)\n","24111cc8":"X_train.columns = X_train.columns[X_train.columns !='pH']\nlogm1 = sm.GLM(y_train, sm.add_constant(X_train),family=sm.families.Binomial())\nlogm1.fit().summary()","29f207fb":"X = X_train.loc[:,X_train.columns != 'free sulfur dioxide']\nlogm2 = sm.GLM(y_train, sm.add_constant(X),family=sm.families.Binomial())\nlogm2.fit().summary()","64a754ab":"X = X.loc[:,X.columns != 'free sulfur dioxide']\nlogm3 = sm.GLM(y_train, sm.add_constant(X),family=sm.families.Binomial())\nlogm3.fit().summary()","c704eb77":"X = X.loc[:,X.columns != 'density']\nlogm4 = sm.GLM(y_train, sm.add_constant(X),family=sm.families.Binomial())\nlogm4.fit().summary()","3615d606":"X = X.loc[:,X.columns != 'chlorides']\nlogm5 = sm.GLM(y_train, sm.add_constant(X),family=sm.families.Binomial())\nlogm5.fit().summary()","2ed35511":"X = X.loc[:,X.columns != 'residual sugar']\nlogm6 = sm.GLM(y_train, sm.add_constant(X),family=sm.families.Binomial())\nlogm6.fit().summary()","6870ec8b":"from statsmodels.stats.outliers_influence import variance_inflation_factor\ndef vif(X) : \n    df = sm.add_constant(X)\n    vif = [variance_inflation_factor(df.values,i) for i in range(df.shape[1])]\n    vif_frame = pd.DataFrame({'vif' : vif[0:]},index = df.columns).reset_index()\n    print(vif_frame.sort_values(by='vif',ascending=False))","f7c4bfb2":"vif(X)","60c8d325":"print('Selected columns :' , X.columns)","f9f907bf":"logm_final = sm.GLM(y_train, sm.add_constant(X_train[X.columns]),family=sm.families.Binomial())\nres = logm_final.fit()\nres.summary()","68928556":"selected_vars = X.columns\ny_train_pred = res.predict(sm.add_constant(X_train[X.columns]))","c36e5c2e":"print(y_train_pred.head())","df3f15da":"predictions = pd.DataFrame({'Quality' : y_train.values,'class_probability' : y_train_pred.values.reshape(-1)}, index=X_train.index)\nprint(predictions.head())","519b0fe5":"predictions['Predicted_Quality'] = predictions['class_probability'].apply(lambda x : 1 if x > 0.5 else 0)\nprint(predictions.head())","c76802bb":"from sklearn import metrics","b5c2fb5b":"confusion = metrics.confusion_matrix(predictions['Quality'],predictions['Predicted_Quality'])\nprint(confusion)","15570b25":"# Accuracy of the model\nprint(metrics.accuracy_score(predictions['Quality'],predictions['Predicted_Quality']))","7e4637dc":"TP = confusion[1,1]\nTN = confusion[0,0]\nFP = confusion[0,1]\nFN = confusion[1,0]","1fb3c6d6":"#### Metrics\nimport math\ndef model_metrics(TP,TN,FP,FN) : \n    print('Accuracy :' , round((TP + TN)\/float(TP+TN+FP+FN),3))\n    print('Misclassification Rate \/ Error Rate :', round((FP + FN)\/float(TP+TN+FP+FN),3))\n    print('Sensitivity \/ True Positive Rate \/ Recall :', round(TP\/float(FN + TP),3))\n    sensitivity = round(TP\/float(FN + TP),3)\n    print('Specificity \/ True Negative Rate : ', round(TN\/float(TN + FP),3))\n    specificity = round(TN\/float(TN + FP),3)\n    print('False Positive Rate :',round(FP\/float(TN + FP),3))\n    print('Precision \/ Positive Predictive Value :', round(TP\/float(TP + FP),3))\n    precision = round(TP\/float(TP + FP),3)\n    print('Prevalance :',round((FN + TP)\/float(TP+TN+FP+FN),3))\n    print('Negative Predictive Value', round(TN\/float(TN + FN),3))\n    print('Likelihood Ratio : Sensitivity \/ 1-Specificity :', round(sensitivity\/float(1-specificity) ,3))\n    print('F1-score :', round(2*precision*sensitivity\/(precision + sensitivity),3))","1178816a":"model_metrics(TP,TN,FP,FN)","c92b0322":"print(predictions.head())","90a78eb5":"# generating predictions for cutoffs between 0 and 1\ncutoffs = pd.DataFrame()\nfor i in np.arange(0,1,0.1) : \n    cutoffs[i] = predictions['class_probability'].map(lambda x : 1 if x > i else 0)","a8a52443":"tpr = []\nfpr = []\nfor column in cutoffs.columns : \n    confusion = metrics.confusion_matrix(predictions['Quality'],cutoffs[column])\n    TP = confusion[1,1] # true positive \n    TN = confusion[0,0] # true negatives\n    FP = confusion[0,1] # false positives\n    FN = confusion[1,0] # false negatives\n    tpr.append(TP\/float(TP + FN))\n    fpr.append(FP\/float(FP + TN))\nplt.title('ROC curve')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nsns.scatterplot(fpr,tpr);\n\n","957c41e2":"sensitivity = []\nspecificity = []\naccuracy = []\ncoffs = []\nfor column in cutoffs.columns : \n    confusion = metrics.confusion_matrix(predictions['Quality'],cutoffs[column])\n    TP = confusion[1,1] # true positive \n    TN = confusion[0,0] # true negatives\n    FP = confusion[0,1] # false positives\n    FN = confusion[1,0] # false negatives\n    sensitivity.append(TP\/float(TP + FN))\n    specificity.append(1 - FP\/float(FP + TN))\n    accuracy.append((TP + TN)\/(TP + TN + FP + FN))\nfig,ax = plt.subplots()\nax.set_xlabel('Cutoffs')\nax.plot(cutoffs.columns,sensitivity,label='sensitivity')\nax.plot(cutoffs.columns,specificity,label='specificity')\nax.plot(cutoffs.columns,accuracy,label='accuracy')\nax.legend(('sensitivity','specificity','accuracy'))\nplt.show()","96463999":"predictions['Final_Predictions'] = predictions['Predicted_Quality'].map(lambda x : 1 if x > 0.5 else 0)","c46aa1dd":"confusion_final = metrics.confusion_matrix(predictions['Quality'],predictions['Final_Predictions'])\nTP = confusion_final[1,1]\nTN = confusion_final[0,0]\nFP = confusion_final[0,1]\nFN = confusion_final[1,0]","6adcf538":"#### Metrics\nmodel_metrics(TP,TN,FP,FN)","c17d4c0c":"precision = [] # positive predictive power - TP \/ TP + FP\nrecall = []   ## same as sensitivity\n\nfor column in cutoffs.columns : \n    confusion = metrics.confusion_matrix(predictions['Quality'],cutoffs[column])\n    TP = confusion[1,1] # true positive \n    TN = confusion[0,0] # true negatives\n    FP = confusion[0,1] # false positives\n    FN = confusion[1,0] # false negatives\n    precision.append(TP\/float(TP + FP))\n    recall.append(TP\/float(FN + TP))\n\nfig,ax = plt.subplots()\nax.set_xlabel('Cutoffs')\nax.plot(cutoffs.columns,precision,label='precision')\nax.plot(cutoffs.columns,recall,label='recall')\nax.legend(('precision','recall'))\nplt.show()","060568d0":"# using sklearn utilities \nfrom sklearn.metrics import precision_score, recall_score\nprint('Precision',precision_score(predictions['Quality'],predictions['Predicted_Quality']))\nprint('Recall', recall_score(predictions['Quality'],predictions['Predicted_Quality']))","b8369160":"print(X_test[X.columns].head())","eaafb545":"test_predictions = pd.DataFrame()\nX_test_ = X_test[X.columns]\ntest_predictions['Class_Probabilities'] = res.predict(sm.add_constant(X_test_))","97873e1d":"test_predictions['Original'] = y_test\ntest_predictions.index = y_test.index","5c61076a":"# Predictions are made using 0.5 as the threshold\ntest_predictions['Predicted'] = test_predictions['Class_Probabilities'].map(lambda x : 1 if x > 0.5 else 0)","827dd844":"#### Metrics\nTN,FP,FN,TP = metrics.confusion_matrix(test_predictions['Original'],test_predictions['Predicted']).reshape(-1)\nmodel_metrics(TP,TN,FP,FN)\n    ","7225b7f6":"- RFE results show that ```pH``` can be dropped. ","d05acc45":"### Model Building ","d3fe5e32":"### Model 5 \n- dropping ```chlorides``` because of high p-value","bfde0101":"High Correlations : \n- Fixed acidity vs pH : -0.69\n- Fixed acidity vs density : 0.69\n- fixed acidity vs citric acid : 0.67 \n- Volatile acidity vs citric acid : -0.53\n- citric acid vs pH : -0.54\n- density vs alcohol : -0.51 ","a9a49adf":"### Feature Selection using RFE ","198fe042":"- As we can see, there's no multi collinearity since VIF < 5","f563b8be":"### Metrics beyond Simple Accuracy","7f5ca1a5":"### Scaling Continuous Variables","ae5c1a3d":"* There are outlier in ```fixed acidity```, ```volatile acidity```, ```citric acid```, ```residual sugar```, ```chlorides```, ```free sulfur dioxide```, ```total sulfur dioxide```, ```pH```, ```sulphates```, ```alcohol```","eeb8f93a":"### Checking for Outliers","b9a497db":"### Classification Threshold\n- Let us assume that any probability < 0.5 is Bad and >0.5 is Good","8ce020d0":"- The above result could be interpreted in the following manner \n- a\\[i,j\\] is the no of times class j was predicted when actual was class i \n- So TN : 390, FP : 130, FN : 147, TP : 452 \n\n|Predicted >   |  0 |  1 |\n|---|---|---|\n| Actual  |   |   |\n|  0 | TN = 390  | FP =130  |\n| 1  | FN =147  | TP = 452  |\n\n0 : bad, 1 : good\n","5424e6c6":"### Making Predictions on Train Set","779c3520":"### Optimum Cut Off ","d5081291":"#### Confusion Matrix","9658c96f":"### Correlations","ffef7a6c":"### Visualizing Independent Variables","1ea56dd2":"### Summary Statistics","91df2d11":"### Simple Metrics","8bdbb748":"### Checking Multi-Collinearity","2b93a460":"### Wine Quality vs Predicted Probability","bc31468f":"### Replacing ```quality``` levels with 0,1","e7bd8f68":"### ROC curve","09309f45":"### Importing Data","15552506":"#### Model 2\n- Dropping ```free sulfur dioxide``` because of high p-value","cb7037bd":"### Model 6 \n-- Dropping ```residual sugar``` because of high p-value","496c36e8":"```quality``` is our target variable. It has two levels - good & bad. No null or missing values. All the other variables are continuous variables. ","2d430ec7":"# Wine Quality Prediction\nClassification using Logistic Regression  \n### Data Set\nThis Data set contains the information related to red wine , Various factors affecting the quality. This data set was prepossessed and downloaded from the UCI Machine Learning Repository. This data set was simple, cleaned, practice data set for classification modelling. Source of this Dataset: https:\/\/archive.ics.uci.edu\/ml\/datasets\/wine+quality\n\nAttribute Information:  \nInput variables (based on physicochemical tests):  \n1. - fixed acidity  \n2.  - volatile acidity  \n3.  - citric acid   \n4.  - residual sugar   \n5.  - chlorides   \n6.  - free sulfur dioxide   \n7.  - total sulfur dioxide  \n8.  - density   \n9.  - pH  \n10.  - sulphates   \n11.  - alcohol  \nOutput variable (based on sensory data):    \n12.  - quality ('good' and 'bad' based on score >5 and <5)  \n\n### Analysis Summary\nThis analysis focuses on finding attributes that significantly affect wine quality classification and training a predictive model to classify wine quality into ```good``` and ```bad``` based on attributes. Analysis is pivoted on the variable ```quality```(target variable). Exploratory data analysis steps like removing null values, observing summary statistics, visualizing the variables, removing oultiers, checking for correlations are carried out.   \n  \nFollowing significant correlations are observed. \n- Fixed acidity vs pH : -0.69\n- Fixed acidity vs density : 0.69\n- fixed acidity vs citric acid : 0.67 \n- Volatile acidity vs citric acid : -0.53\n- citric acid vs pH : -0.54\n- density vs alcohol : -0.51   \n\n\nA 70-30 split is done to divide dataset into test and train sets.  \n10 variables are selected using automated RFE. Further, manual selection is carried out using p-value method. \nModels are build on train data using ```statsmodels.api``` package. \nFinal Model is build on the following variables.   \n```citric acid```,```fixed acidity```,```volatile acidity```,```alcohol```,```sulphates```,```total sulfur dioxide```  \nVariance inflation factor is calculated for all final selection of variables. VIF < 5. No significant Multicollinearity observed. \n   \n\nROC, Precision-Recall \/ Sensitivity - Specificity curves have been plotted. The optimum threshold for classification seems to be 0.5   \n  \n**Model metrics on train data at classification threshold of 0.5 :**   \n* Accuracy : 0.752\n* Misclassification Rate \/ Error Rate : 0.248\n* Sensitivity \/ True Positive Rate \/ Recall : 0.755\n* Specificity \/ True Negative Rate :  0.75\n* False Positive Rate : 0.25\n* Precision \/ Positive Predictive Value : 0.777\n* Prevalance : 0.535\n* Negative Predictive Value 0.726\n* Likelihood Ratio : Sensitivity \/ 1-Specificity : 3.02\n* F1-score : 0.766\n\n**Model metrics on test data at classification threshold of 0.5 :**   \n* Accuracy : 0.746\n* Misclassification Rate \/ Error Rate : 0.254\n* Sensitivity \/ True Positive Rate \/ Recall : 0.797\n* Specificity \/ True Negative Rate :  0.688\n* False Positive Rate : 0.312\n* Precision \/ Positive Predictive Value : 0.745\n* Prevalance : 0.533\n* Negative Predictive Value 0.748\n* Likelihood Ratio : Sensitivity \/ 1-Specificity : 2.554\n* F1-score : 0.77\n\n\n ","8a315700":"### Model 3\n- dropping ```free sulfur dioxide``` because of high p-value","87c2415d":"### Model 4 \n- Dropping ```density``` because of high p-value","670df3b8":"- All the p-values are very low. So the variable which remain have statistically significant relationships. ","502440f7":"### Test Train Split","37ffc58f":"- From the above plot, 0.5 seems like the optimum Threshold for classification","b3b88a8a":"### Final Model ","02676db7":"### Precision and Recall ","92083dcf":"### Assessing Model\n#### Model 1","142f6a3d":"### Predictions on Test set"}}