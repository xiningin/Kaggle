{"cell_type":{"59e74135":"code","c3cad5c2":"code","49b2775e":"code","720703da":"code","7f408634":"code","9aede663":"code","fe118f05":"code","22a11248":"code","bde02d53":"code","e3dd9ae2":"code","ea5f9a3e":"code","8a449969":"code","0e01d183":"code","29546539":"code","f165a377":"code","09cd846b":"code","0c465f46":"code","6b393c4b":"code","b7d73a80":"code","3ba73b6d":"code","cc60bd3d":"code","97bcc956":"code","97667454":"code","94df47b8":"code","7c7eaf2c":"code","559ad1e5":"code","1c7d325d":"code","5de9edc2":"code","16f5e96b":"code","edd20e6c":"code","47e6b140":"code","0b997cd0":"code","57160ec7":"code","2c856c5f":"code","84d5b89f":"code","c81a8afe":"code","950aef5b":"code","e55923f2":"markdown","000a46c8":"markdown","2a2fb251":"markdown","284519c8":"markdown","92da71d4":"markdown","65f096c4":"markdown","d2ced6ec":"markdown","c8c273a3":"markdown","a2bac3a9":"markdown","4d63d58c":"markdown","4c45e913":"markdown","8b7be9d0":"markdown","cb12d161":"markdown","a15d2854":"markdown","a3083ffe":"markdown"},"source":{"59e74135":"%env JOBLIB_TEMP_FOLDER=\/tmp","c3cad5c2":"!conda install -c conda-forge gdcm -y","49b2775e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport scipy.ndimage\nfrom skimage import measure, morphology\nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection\nfrom sklearn.cluster import KMeans\nimport shutil\nimport cv2\nimport pydicom\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import (MultipleLocator, FormatStrFormatter,\n                               AutoMinorLocator)\nimport seaborn as sns\nfrom IPython.display import HTML\nimport gdcm\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n'''\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n'''\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","720703da":"def set_options():\n    pd.set_option('display.max_columns', 100)\n    pd.set_option('display.max_colwidth', None)\n    pd.set_option('display.max_rows', 1000)","7f408634":"set_options()","9aede663":"TRAIN_PATH = '..\/input\/osic-pulmonary-fibrosis-progression\/train.csv'\nTRAIN_IMG_PATH = '..\/input\/osic-pulmonary-fibrosis-progression\/train'\nTEST_PATH = '..\/input\/osic-pulmonary-fibrosis-progression\/test.csv'\nTEST_IMG_PATH = '..\/input\/osic-pulmonary-fibrosis-progression\/test'\nSUBMISSION_PATH = '..\/input\/osic-pulmonary-fibrosis-progression\/sample_submission.csv'","fe118f05":"'''Load data'''\ntrain = pd.read_csv(TRAIN_PATH)\ntest = pd.read_csv(TEST_PATH)","22a11248":"# Duplicates on basis of patient and weeks\ntrain[train.duplicated(['Patient','Weeks'], keep=False)]","bde02d53":"# Remove duplicates\ntrain = train.drop_duplicates()","e3dd9ae2":"train.head()","ea5f9a3e":"HTML('<iframe width=\"600\" height=\"400\" src=\"https:\/\/www.youtube.com\/embed\/KZld-5W99cI\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen><\/iframe>')","8a449969":"## In this dataset ImagePosition is not available so we will sort the slices on InstanceNumber.\ndef load_slices(path):\n    filenames = os.listdir(path)\n    slices = [pydicom.dcmread(f'{path}\/{file}') for file in filenames]\n    slices.sort(key = lambda x: int(x.InstanceNumber), reverse=True)\n    return slices","0e01d183":"scans = load_slices(f'{TRAIN_IMG_PATH}\/ID00007637202177411956430')\nscans[0]","29546539":"# Rescale intercept, (0028|1052), and rescale slope (0028|1053) are DICOM tags that specify the linear \n# transformation from pixels in their stored on disk representation to their in memory representation.\n# Whenever the values stored in each voxel have to be scaled to different units, \n# Dicom makes use of a scale factor using two fields into the header \n# defining the slope and the intercept of the linear transformation to be used to \n# convert pixel values to real world values.\n\ndef get_pixels_hu(slices):\n    image = np.stack([s.pixel_array for s in slices])\n    # Convert to int16 (from sometimes int16), \n    # should be possible as values should always be low enough (<32k)\n    image = image.astype(np.int16)\n\n    # Set outside-of-scan pixels to 0\n    # The intercept is usually -1024, so air is approximately 0\n    image[image <= -1000] = 0\n    \n    # Convert to Hounsfield units (HU)\n    for slice_number in range(len(slices)):\n        \n        intercept = slices[slice_number].RescaleIntercept\n        slope = slices[slice_number].RescaleSlope\n        \n        if slope != 1:\n            image[slice_number] = slope * image[slice_number].astype(np.float64)\n            image[slice_number] = image[slice_number].astype(np.int16)\n            \n        image[slice_number] += np.int16(intercept)\n    \n    return np.array(image, dtype=np.int16)","f165a377":"def apply_window(hu_image, center, width):\n    hu_image = hu_image.copy()\n    min_value = center - width \/\/ 2\n    max_value = center + width \/\/ 2\n    hu_image[hu_image < min_value] = min_value\n    hu_image[hu_image > max_value] = max_value\n    return hu_image","09cd846b":"train.loc[0]['Patient']","0c465f46":"fig,ax = plt.subplots(1,2,figsize=(20,5))\nexample = train.loc[0]['Patient']\nscans = load_slices(f'{TRAIN_IMG_PATH}\/{example}')\nrescaled_images=get_pixels_hu(scans)\nimages = [scan.pixel_array for scan in scans]\nfor i in range(10):\n    sns.distplot(images[i].flatten(), ax=ax[0])\n    sns.distplot(rescaled_images[i].flatten(), ax=ax[1])\nax[0].set_title(\"Raw pixel array distributions for 10 examples\")\nax[1].set_title(\"HU unit distributions for 10 examples\")","6b393c4b":"def get_dicom_raw(dicom):\n    return ({attr:getattr(dicom, attr) for attr in dir(dicom) if attr[0].isupper() and attr not in ['PixelData']})","b7d73a80":"%%time\n# Get dicom metadata\n# Image features like lung volume are implementation from a detailed discussion \"Domain expert's insight\" by Dr. Konya.\n# https:\/\/www.kaggle.com\/c\/osic-pulmonary-fibrosis-progression\/discussion\/165727\n\ndef get_dicom_metadata(df):\n    patients = df.Patient.unique()\n    dicom_metadata = []\n    for patient in patients:\n        path = f'{TRAIN_IMG_PATH}\/{patient}'\n        img_list = os.listdir(path)\n        for img in img_list:\n            image = pydicom.dcmread(f'{path}\/{img}')\n            record = get_dicom_raw(image)\n            raw = image.pixel_array\n            pixelspacing_r, pixelspacing_c = image.PixelSpacing[0], image.PixelSpacing[1]\n            row_distance = pixelspacing_r * image.Rows\n            col_distance = pixelspacing_c * image.Columns\n            record.update({'raw_min':raw.min(),\n                        'raw_max':raw.max(),\n                        'raw_mean':raw.mean(),\n                        'raw_std':raw.std(),\n                        'raw_diff':raw.max()-raw.min(),\n                        'pixel_spacing_area':pixelspacing_r * pixelspacing_c,\n                        'img_area':image.Rows * image.Columns,\n                        'pixel_row_distance':row_distance,\n                        'pixel_col_distance':col_distance,\n                        'slice_area_cm2':(0.1 * row_distance) * (0.1 * col_distance),\n                        'slice_vol_cm3':(0.1 * image.SliceThickness) * (0.1 * row_distance) * (0.1 * col_distance),\n                        'patient_img_path':f'{path}\/{img}'})\n\n            dicom_metadata.append(record)\n            \n    metadata_df = pd.DataFrame(dicom_metadata)\n    metadata_df.to_pickle('metadata_df.pkl')\n    return metadata_df","3ba73b6d":"%%time\nmetadata_df = get_dicom_metadata(train.copy())\nmetadata_df.head()","cc60bd3d":"plt.tight_layout()\nfig, ax = plt.subplots(2, 2, figsize=(20,10))\nsns.distplot(metadata_df.pixel_row_distance, ax=ax[0,0], color='green')\nsns.distplot(metadata_df.pixel_col_distance, ax=ax[0,1], color='blue')\nsns.distplot(metadata_df.slice_area_cm2, ax=ax[1,0], color='pink')\nsns.distplot(metadata_df.slice_vol_cm3, ax=ax[1,1], color='magenta')\nax[0,0].set_title(\"Pixel Rows Distance\")\nax[0,0].set_xlabel(\"Pixel Rows\")\nax[0,1].set_title(\"Pixel Column Distance\")\nax[0,1].set_xlabel(\"Pixel Columns\")\nax[1,0].set_title(\"CT-slice area in $cm^{2}$\")\nax[1,0].set_xlabel(\"Area in $cm^{2}$\")\nax[1,1].set_title(\"CT-slice volume in $cm^{3}$\")\nax[1,1].set_xlabel(\"Volume in $cm^{3}$\")","97bcc956":"# It is clearly visible that area and volume of lungs vary a lot. Let's show images with maximum volume and minimum volume.\nhighest_vol_patients = list(metadata_df[metadata_df.slice_vol_cm3 == max(metadata_df.slice_vol_cm3)]['PatientID'])\nlowest_vol_patients = list(metadata_df[metadata_df.slice_vol_cm3 == min(metadata_df.slice_vol_cm3)]['PatientID'])\n# Load scans for highest and lowest volume lung patients\nmax_vol_scans = load_slices(f\"{TRAIN_IMG_PATH}\/{highest_vol_patients[0]}\")\nmin_vol_scans = load_slices(f\"{TRAIN_IMG_PATH}\/{lowest_vol_patients[0]}\")\n# Convert to HU\nmax_vol_hu_imgs = get_pixels_hu(max_vol_scans)\nmin_vol_hu_imgs = get_pixels_hu(min_vol_scans)\n# Apply windowing]\n# We can try with different window width and levels.\nmax_vol_window_img = apply_window(max_vol_hu_imgs[20], -600, 1200)\nmin_vol_window_img = apply_window(min_vol_hu_imgs[18], -600, 1200)\nfig, ax = plt.subplots(1, 2, figsize=(20, 10))\nax[0].imshow(max_vol_window_img, cmap=\"YlGnBu\")\nax[0].set_title(\"CT with large volume\")\nax[1].imshow(min_vol_window_img, cmap=\"YlGnBu\")\nax[1].set_title(\"CT with small volume\")","97667454":"metadata_df.SliceThickness.unique()","94df47b8":"# Lets see thickness for slices before thinking about resampling.\npatient1 = train.Patient.unique()[0]\npatient2 = train.Patient.unique()[5]\nscans1 = load_slices(f\"{TRAIN_IMG_PATH}\/{patient1}\")\nscans2 = load_slices(f\"{TRAIN_IMG_PATH}\/{patient2}\")\nprint(f\"{scans1[0].SliceThickness}, {scans1[0].PixelSpacing}\")\nprint(f\"{scans2[0].SliceThickness}, {scans2[0].PixelSpacing}\")\n","7c7eaf2c":"patient1_hu_scans = get_pixels_hu(scans1)\npatient2_hu_scans = get_pixels_hu(scans2)","559ad1e5":"def resample(image, scan, new_spacing=[1,1,1]):\n    # Determine current pixel spacing\n    spacing = np.array([scan[0].SliceThickness] + list(scan[0].PixelSpacing), dtype=np.float32)\n    resize_factor = spacing \/ new_spacing\n    new_real_shape = image.shape * resize_factor\n    new_shape = np.round(new_real_shape)\n    real_resize_factor = new_shape \/ image.shape\n    new_spacing = spacing \/ real_resize_factor\n    image = scipy.ndimage.interpolation.zoom(image, real_resize_factor)\n    return image, new_spacing","1c7d325d":"image1, rounded_new_spacing1 = resample(patient1_hu_scans, scans1, [1,1,1])\nimage2, rounded_new_spacing2 = resample(patient2_hu_scans, scans2, [1,1,1])\nprint(f\"Original shape : {patient2_hu_scans.shape}\")\nprint(f\"Shape after resampling : {image2.shape}\")","5de9edc2":"def plot_3d(image,threshold=800):\n    \n    # Position the scan upright, \n    # so the head of the patient would be at the top facing the   \n    # camera\n    p = image.transpose(2,1,0)\n    \n    verts, faces, _, _ = measure.marching_cubes_lewiner(p, threshold)\n    fig = plt.figure(figsize=(10, 10))\n    ax = fig.add_subplot(111, projection='3d')\n    # Fancy indexing: `verts[faces]` to generate a collection of    \n    # triangles\n    mesh = Poly3DCollection(verts[faces], alpha=0.70)\n    face_color = [0.45, 0.45, 0.75]\n    mesh.set_facecolor(face_color)\n    ax.add_collection3d(mesh)\n    ax.set_xlim(0, p.shape[0])\n    ax.set_ylim(0, p.shape[1])\n    ax.set_zlim(0, p.shape[2])\n    plt.show()","16f5e96b":"plot_3d(image1)","edd20e6c":"plot_3d(patient1_hu_scans)","47e6b140":"#Standardize the pixel values\ndef make_lungmask(img, display=False):\n    row_size= img.shape[0]\n    col_size = img.shape[1]\n    mean = np.mean(img)\n    std = np.std(img)\n    img = img-mean\n    img = img\/std\n    \n    # Find the average pixel value near the lungs\n    # to renormalize washed out images\n    middle = img[int(col_size\/5):int(col_size\/5*4),int(row_size\/5):int(row_size\/5*4)] \n    mean = np.mean(middle)  \n    max = np.max(img)\n    min = np.min(img)\n    # To improve threshold finding, I'm moving the \n    # underflow and overflow on the pixel spectrum\n    img[img==max]=mean\n    img[img==min]=mean\n    \n    # Using Kmeans to separate foreground (soft tissue \/ bone) and background (lung\/air)\n    #\n    kmeans = KMeans(n_clusters=2).fit(np.reshape(middle,[np.prod(middle.shape),1]))\n    centers = sorted(kmeans.cluster_centers_.flatten())\n    threshold = np.mean(centers)\n    \n    # Threshold the image and the output will be a binary image. Morphology workes either on binary or gray images.\n    thresh_img = np.where(img<threshold,1.0,0.0)\n    \n    # First erode away the finer elements, then dilate to include some of the pixels surrounding the lung.  \n    # We don't want to accidentally clip the lung.\n\n    eroded = morphology.erosion(thresh_img,np.ones([3,3]))\n    dilation = morphology.dilation(eroded,np.ones([8,8]))\n\n    labels = measure.label(dilation) # Different labels are displayed in different colors\n    label_vals = np.unique(labels)\n    regions = measure.regionprops(labels)\n    good_labels = []\n    for prop in regions:\n        B = prop.bbox\n        if B[2]-B[0]<row_size\/10*9 and B[3]-B[1]<col_size\/10*9 and B[0]>row_size\/5 and B[2]<col_size\/5*4:\n            good_labels.append(prop.label)\n    mask = np.ndarray([row_size,col_size],dtype=np.int8)\n    mask[:] = 0\n\n    #  After just the lungs are left, we do another large dilation\n    #  in order to fill in and out the lung mask \n    for N in good_labels:\n        mask = mask + np.where(labels==N,1,0)\n    mask = morphology.dilation(mask,np.ones([10,10])) # one last dilation\n\n    if (display):\n        fig, ax = plt.subplots(3, 2, figsize=[12, 12])\n        ax[0, 0].set_title(\"Original\")\n        ax[0, 0].imshow(img, cmap='gray')\n        ax[0, 0].axis('off')\n        ax[0, 1].set_title(\"Threshold\")\n        ax[0, 1].imshow(thresh_img, cmap='gray')\n        ax[0, 1].axis('off')\n        ax[1, 0].set_title(\"After Erosion and Dilation\")\n        ax[1, 0].imshow(dilation, cmap='gray')\n        ax[1, 0].axis('off')\n        ax[1, 1].set_title(\"Color Labels\")\n        ax[1, 1].imshow(labels)\n        ax[1, 1].axis('off')\n        ax[2, 0].set_title(\"Final Mask\")\n        ax[2, 0].imshow(mask, cmap='gray')\n        ax[2, 0].axis('off')\n        ax[2, 1].set_title(\"Apply Mask on Original\")\n        ax[2, 1].imshow(mask*img, cmap='gray')\n        ax[2, 1].axis('off')\n        \n        plt.show()\n    return mask*img","0b997cd0":"make_lungmask(image1[14], True)","57160ec7":"def get_rows_cols(size):\n    cols = 6\n    rows = size \/\/ cols\n    if (int(size%cols) != 0):\n        rows = rows+1\n    return rows,cols","2c856c5f":"def plot_stack(stack, start_with=10, show_every=3):\n    size = (len(stack) - (start_with - 1))\/\/show_every\n    rows, cols = get_rows_cols(size)\n    plt.tight_layout()\n    fig,ax = plt.subplots(rows,cols,figsize=[12,12])\n    for i in range(size-1):\n        ind = start_with + i*show_every\n        ax[int(i\/cols),int(i % cols)].set_title('slice %d' % ind)\n        ax[int(i\/cols),int(i % cols)].imshow(stack[ind],cmap='gray')\n        ax[int(i\/cols),int(i % cols)].axis('off')\n    plt.show()","84d5b89f":"plot_stack(patient1_hu_scans, start_with=0, show_every=1)","c81a8afe":"masked_lung = []\n\nfor img in image1:\n    masked_lung.append(make_lungmask(img))\n    \nplot_stack(masked_lung, start_with=0, show_every=1)","950aef5b":"# Code for running processing on the whole data all together. Outcome of the code will \n\n# be .npz file for all patients. .npz files can be loaded using np.load() function for further use.\n# If you want to store images in .png files remove the comments from below code and comment out code mentioned below.\n'''\npath = \".\/segmented-images\"\nif not shutil.os.path.isdir(path):\n    shutil.os.mkdir(path)\n\npatients = train.Patient.unique()[0:10]\nfor patient in patients:\n    #if not shutil.os.path.isdir(path + \"\/\" + patient):\n    #    shutil.os.mkdir(path + \"\/\" + patient)\n    scans = load_slices(f'{TRAIN_IMG_PATH}\/{patient}')\n    hu_imgs = get_pixels_hu(scans)\n    rescaled_images, spacing = resample(hu_imgs, scans,[1,1,1])\n\n    masked_lung = []\n    for img_number in range(len(rescaled_images)):\n        window_img = apply_window(rescaled_images[img_number], -600, 1200)\n        masked_img = make_lungmask(window_img)\n        masked_lung.append(masked_img)\n        #cv2.imwrite(f'{path}\/{patient}\/{img_number + 1}.png', masked_img)\n    # Comment the below line if images required to store in .png format.\n    np.savez(f'{path}\/{patient}',masked_lung)\n    #plot_stack(masked_lung, start_with=0, show_every=1)\n'''","e55923f2":"<a id=\"hounsfield\"><\/a>\n# Conversion to Hounsfield Units\nThe Hounsfield scale is a quantitative scale for describing radiodensity in medical CT scan and provides an accurate density for the type of tissue. Plain x-rays which only displays 5 densities (i.e. air\/fat\/soft tissue\/bone\/metal), CT displays a huge range of densities ranging from air (black) to bone (white). On the Hounsfield scale, water represented by 0 value, air is represented by a value of \u22121000 (black on the grey scale) and bone between +700 (cancellous bone) to +3000 (dense bone) (white on the grey scale). As bones are much denser than surrounding soft tissues, they show up very clearly in CT images. Raw pixel values of images gets convereted into Hounsfield Units because the spectral composition of the x-rays depends on the measurement settings like acquisition parameters and tube voltage. By normalizing to values of water and air (water has HU 0 and air -1000) the images of different measurements are becoming comparable.\nRead more about Hounsfield units on [Hounsfield Scale](https:\/\/www.sciencedirect.com\/topics\/medicine-and-dentistry\/hounsfield-scale)\n\n![image.png](attachment:image.png)","000a46c8":"<a id=\"segmentation\"><\/a>\n# Segmentation\n\nSegmentation is most important part of medical image processing as it extracts region of interest. Segmentation defines narrowly what algorithm want to look at, so definitely CNN will perform better on segmented images rather than on whole chest image.\nSegmentation is done by many ways and clustering is most common among all. Clustering has several techniques such as K-means clustering, hierarchical clustering, divisive clustering, and mean shift clustering. Moreover, due to the irregular and fuzzy borders in most of the medical images, fuzzy set and neutrosophic set theories become important in the segmentation process to handle uncertainty in the medical images. Read more about medical image segmentation [here.](https:\/\/www.sciencedirect.com\/topics\/engineering\/medical-image-segmentation)\nAfter clustering images are morphed using erosion(contraction) and dialation(expansion) to remove unwanted border areas and label different reasons separately. So the steps goes as:\n1. Normalization of image.\n2. Clustering for separating lung with everything else.\n3. Threshold image.\n4. Morphology - Erosion followed by dialation.\n5. Label different regions and define regions with different colors.\n6. Create lung mask.\n7. Apply mask on original image and get final masked image.","2a2fb251":"<a id=\"metadata\"><\/a>\n# Storing metadata in dataframe\nEvery DICOM image has lot of metadata as we saw earlier for one scan. Lets put this metadata in dataframe for easy access. ","284519c8":"Below methods we consider eveything below -1000 as air. ","92da71d4":"<a id=\"coordinate-system\"><\/a>\n# Coordinate Systems in medical imaging\n\nCoordinate system is used for identifying the location of a point. Three types coordinate systems commonly used in imaging applications: the world, anatomical and the medical image coordinate system.\n\nWe will talk about Anatomical coordinate system. This system has three planes and **dataset we will be using is on Axial Plane.**\n\n* Axial plane -  The axial plane is actually when you place point of view above the patient and look down. Depending on the region of the 3D medical image you will observe different anatomical structures. For a 3D total body scan, if you had a control-bar over this 2D view you would start from a 2D slice of the head, and by increasing you would end up in the legs. Let\u2019s practically call this view the \u201cdrone plane\u201d or \u201ctop-view\u201d. Slices near to head is known as superior and towards feet is known as inferior. Below is axial plane of lungs CT Scans.\n\n* Sagittal plane - Basically, this is a side view. Instead of looking from above the patient, now we look from the side. The side can be either\u00a0right\u00a0or\u00a0left.\u00a0Which side and direction is the positive one, depends on the coordinate system.\n\n* Coronal plane \u2013 In this point of view is either in front of eyes(anterior plane) or back of the patient(posterior plane)","65f096c4":"<a id=\"about-data\"><\/a>\n# About data\nMedical dataset containing lungs CT scans of patients diagnosed with pulmonary fibrosis a disorder with no known cause and no known cure, created by scarring of the lungs. Prognosis of the troubling disease becomes frightening for the patients because outcomes can range from long-term stability to rapid deterioration, but doctors aren\u2019t easily able to tell where an individual may fall on that spectrum. This is where data science can help in predicting the detoriating condition of the patients. Detailed description about data is found [here.](https:\/\/www.kaggle.com\/c\/osic-pulmonary-fibrosis-progression\/data)","d2ced6ec":"<a id=\"histogram-analysis\"><\/a>\n# Histogram Analysis\nLets plot histogram for image pixels after converting to HU and raw pixel values. After converting to HU we can see there is lot of air(-1000) in the scan. Some fat and muscle is also seen.","c8c273a3":"References:\n1. [Medical Coordinate System](https:\/\/theaisummer.com\/medical-image-coordinates\/)\n2. [Managing DICOM Images](https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC3354356\/)\n3. [All about radiology - Radiopedia.org](https:\/\/radiopaedia.org\/)\n4. [Domain expert's insight](https:\/\/www.kaggle.com\/c\/osic-pulmonary-fibrosis-progression\/discussion\/165727)\n5. [Intrinsic dependencies of CT radiomic features on voxel size and number of gray levels](https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC5462462\/)\n6. [Hounsfield Scale](https:\/\/www.sciencedirect.com\/topics\/medicine-and-dentistry\/hounsfield-scale)\n7. [Determining effective window width and center using different windowing techniques](https:\/\/www.researchgate.net\/publication\/272179277_Determining_effective_window_width_and_center_using_different_windowing_techniques_for_radio_therapy_images)\n8. [Resampling](https:\/\/www.dl-c.com\/Temp\/downloads\/Whitepapers\/Resampling.pdf)\n9. [Marching cubes](http:\/\/www.cs.carleton.edu\/cs_comps\/0405\/shape\/marching_cubes.html)\n10. [Image Segmentation](https:\/\/www.sciencedirect.com\/topics\/engineering\/medical-image-segmentation)\n11. [Morphological Filtering](https:\/\/scikit-image.org\/docs\/dev\/auto_examples\/applications\/plot_morphology.html)\n12. [DICOM Processing Segmentation Visualization in Python](https:\/\/www.raddq.com\/dicom-processing-segmentation-visualization-in-python\/)\n13. [Data Science Bowl 2017 - Preprocessing Tutorial by Guido Zuidhof](https:\/\/www.kaggle.com\/gzuidhof\/full-preprocessing-tutorial)\n14. [Pulmonary DICOM Preprocessing](https:\/\/www.kaggle.com\/allunia\/pulmonary-dicom-preprocessing)\n","a2bac3a9":"<a id=\"windowing\"><\/a>\n# Windowing\nWindowing is the process in which the grayscale of a particular image can be adjusted. Windowing uses two values window width and window level for getting a right\/interested window. The window width is the range of the grayscale that can be displayed. The center of grayscale range is referred to as the window level.Window width controls contrast and window level controls brightness. That is why windowing also known as grey-level mapping, contrast stretching, histogram modification or contrast enhancement. A large window width means there is a long grayscale and the transition black to white will take longer and vice versa for smaller window width. An example to better explain:\nWW of 100 HU could mean the grayscale only ranges from 0HU to +100 HU, with a WL of +50 HU.\nFor Lungs window width is 1500 and window level is -600, so grayscale ranges from 150HU to -1350HU.\nMore about windowing can be read [here.](https:\/\/radiopaedia.org\/articles\/windowing-ct?lang=us)\nHow to get window width and level is explained briefly in [this](https:\/\/www.researchgate.net\/publication\/272179277_Determining_effective_window_width_and_center_using_different_windowing_techniques_for_radio_therapy_images) article.","4d63d58c":"Video for better understanding about DICOM images.","4c45e913":"Table of Contents\n* [Coordinate System For Medical Imaging](#coordinate-system)\n* [About data](#about-data)\n* [What is DICOM?](#dicom)\n* [Conversion to Hounsfield Units](#hounsfield)\n* [Windowing](#windowing)\n* [Histogram Analysis](#histogram-analysis)\n* [Storing metadata in dataframe](#metadata)\n* [Voxel Size and Volume](#voxel-size)\n* [Resampling](#resample)\n* [3D Plotting](#3d-plot)\n* [Segmentation](#segmentation)","8b7be9d0":"<a id=\"dicom\"><\/a>\n# What is DICOM?\n\nA DICOM image file is an outcome of the Digital Imaging and Communications in Medicine standard and represented as .dcm. Because of its ease of integration and continuous evolution this communication standard has over the years achieved a nearly universal level of acceptance among vendors of radiological equipment.DICOM differs from other image formats because it groups information into datasets. DICOM file consist of header and image data collectively in one file. We will see later how these group of information looks like and interpreted.\nDetailed information about DICOM can be read [here.](https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC3354356\/)","cb12d161":"<a id=\"3d-plot\"><\/a>\n# 3D Plotting","a15d2854":"<a id=\"voxel-size\"><\/a>\n# Voxel Size and Volume\nVolume of scans vary highly. Does it mean that lungs of images having more voxel volume are bigger than others? NO certainly not. Let's understand what is voxel? Voxel is 3D pixel having pixel spacing shows distance travelled by a pixel in x and y coordinates and slice thickness as z coordinate. Voxel we can imagine like a cuboid. So if pixel spacing(size) is more than definitely volume of image will be more. Lets plot variance of area, volume and pixel spacing to have an idea about number of images having large volumes. ","a3083ffe":"<a id=\"resample\"><\/a>\n# Resampling\nVoxel size resampling is an appropriate preprocessing step for image data sets acquired with variable voxel sizes in order to obtain more reproducible CT features. We found that some of radiomics features were voxel size and gray level discretization dependent. The introduction of normalizing factors in their definitions greatly reduced or removed these dependencies. In computed tomography, voxel size in a region of interest depends on both pixel dimensions (x-y plane) and slice thickness (z-axis), assuming slice thickness equals interslice distance. Any change in these two parameters changes CT image resolution or voxel size. A minimally curation step may be to resample image sets so that all have the same voxel size. In this paper, voxel size resampling was investigated as a way to minimize the variability in feature values due to differing voxel sizes.\n\nVoxel intensities within a region of interest (ROI) are typically resampled into a limited number of discrete values or bin sizes before calculating feature values. Different studies have used different gray level resampling before extracting texture features. Later normalization is also done to improve robustness of these features.\n"}}