{"cell_type":{"9fdc0a9c":"code","dc8b5500":"code","d2378e24":"code","ddb294d1":"code","ef989637":"code","24281a6e":"code","ef310b90":"code","0c4fe618":"code","eb1f702c":"code","fe4c388c":"code","7f8e8ac5":"code","6a5fdc3b":"code","5e1d9987":"code","34752be2":"code","cdf46537":"code","cdf91b0f":"code","2a38d863":"code","edf8bf6a":"code","69bece82":"code","71bf8fdb":"code","a20430d9":"code","89fe1be5":"code","68815b19":"code","c1228cf3":"code","dff06c28":"code","ece2e2f1":"code","4de4fbb8":"code","0af1c202":"code","0ef61f0d":"code","47492729":"code","5aa068c3":"code","3f83339b":"code","fd01ca65":"code","5cdb180b":"code","ba6d960f":"code","e8fa0fa4":"code","ca3bddea":"code","4a29b49f":"code","f6304edf":"code","c7b8f203":"code","458d5fb8":"code","cee815b6":"code","cbe3b387":"code","3933a006":"code","df68cc87":"code","37ffa850":"code","71080bc3":"code","c7a41043":"markdown","8e999a91":"markdown","262fa54b":"markdown","287748b9":"markdown","33ae2dec":"markdown","d9c11f27":"markdown","b25fe7cf":"markdown","de187f58":"markdown","d33e4d8e":"markdown"},"source":{"9fdc0a9c":"#importing libraries \nimport numpy\n# for handling arrays more efficiently\nimport pandas as pd\n# for getting data,dataframes and much more\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# for visualization\n%matplotlib inline","dc8b5500":"# Getting data\ndf = pd.read_csv(\"..\/input\/case-study\/202004-divvy-tripdata.csv\")","d2378e24":"# Checking Dataset\ndf.sample(10)","ddb294d1":"# Getting an overview\ndf.describe()","ef989637":"# Checking for null values \ndf[df.end_station_id.isnull()]","24281a6e":"# Dropping values with null value\ndf2=df.dropna()","ef310b90":"# Reviewing again to check count is same for all\ndf2.describe()","0c4fe618":"# Re-checking null values\ndf2.isnull().sum()","eb1f702c":"# Checking dataset\ndf2.head()","fe4c388c":"# Understanding datatypes and column info\ndf2.info()","7f8e8ac5":"# Checking for duplicates\ndf2.duplicated().sum()","6a5fdc3b":"# Checking for most used start stations\ndf2.start_station_name.value_counts().head(10).to_frame()","5e1d9987":"# Checking for most used end stations\ndf2.end_station_name.value_counts().head(10).to_frame()","34752be2":"# Grouping Start Station ID and Station Name and checking other variables\ndf2.groupby([\"start_station_name\",\"start_station_id\"]).count().nlargest(10,\"end_station_name\")","cdf46537":"# Grouping End Station ID and Station Name and checking other variables\ndf2.groupby([\"end_station_name\",\"end_station_id\"]).count().nlargest(10,\"start_station_name\")","cdf91b0f":"#Visualizing Annual Members Vs Casual Members Countplot\nsns.set(style=\"darkgrid\")\nsplot = sns.countplot(df2[\"member_casual\"])\n# For annotation\nfor p in splot.patches:\n    splot.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() \/ 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')","2a38d863":"# Checking rideable types \ndf2.rideable_type.value_counts()","edf8bf6a":"df2.columns","69bece82":"# Top Start Stations with Annual membership holders\ndf2[df2[\"member_casual\"]==\"member\"][\"start_station_name\"].value_counts().head(10)","71bf8fdb":"# Top End Stations with Annual membership holders\ndf2[df2[\"member_casual\"]==\"member\"][\"end_station_name\"].value_counts().head(10)","a20430d9":"# Top Start Stations with Casual membership holders\n# so that we can target marketing in this station more to attract more Annual users\ndf2[df2[\"member_casual\"]==\"casual\"][\"start_station_name\"].value_counts().head(10)","89fe1be5":"# Top End Stations with Casual membership holders\n# so that we can target marketing in this station more to attract more Annual users\ndf2[df2[\"member_casual\"]==\"casual\"][\"end_station_name\"].value_counts().head(10)","68815b19":"#To convert col into datetime format to use datetime's functionalities\ndf2[\"started_at\"]=pd.to_datetime(df2[\"started_at\"])\ndf2[\"ended_at\"]=pd.to_datetime(df2[\"ended_at\"])\ndf2.info()","c1228cf3":"# import datetime as dt\ndf2[\"date\"] = df2[\"started_at\"].apply(lambda x : x.date())","dff06c28":"# Checking for missing dates, if any\ndiff = pd.date_range(\"2020-04-01\",\"2020-04-30\").difference(df2[\"date\"])","ece2e2f1":"# No dates are missing\ndiff","4de4fbb8":"df2.head(2)","0af1c202":"# Some started dates are higher than others that's why its showing error\n# we will check this out later \ndf2[df2[\"started_at\"]>df2[\"ended_at\"]].head(5)","0ef61f0d":"# Creating new feature  from dates col to know day of the week\ndf2[\"Day_of_week\"]=df2[\"started_at\"].apply(lambda x : x.dayofweek)","47492729":"# Mapping numbers to day of week\ndf2[\"Day_of_week\"]=df2[\"Day_of_week\"].map({0:\"Monday\",1:\"Tuesday\",2:\"Wednesday\",3:\"Thursday\",4:\"Friday\",5:\"Saturday\",6:\"Sunday\"})","5aa068c3":"# Checking changes\ndf2.head(2)","3f83339b":"# Checking most number of rides vs day of week for both type of customers\ndf2.groupby([\"member_casual\",\"Day_of_week\"]).count()[\"ride_id\"].sort_values()","fd01ca65":"#Visuals no. of rides vs day of weeks\nplt.figure(figsize=(16,8))\nsns.set(style=\"darkgrid\")\nsplot2 = sns.countplot(df2[\"Day_of_week\"],order=df2[\"Day_of_week\"].value_counts().index,hue=df2[\"member_casual\"])\nfor p in splot2.patches:\n    splot2.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() \/ 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')","5cdb180b":"# Coverting latitudes and longitudes to distance\nfrom math import sin, cos, sqrt, atan2, radians\n\ndfrange = df2.shape[0]\ndist=[]\nR=6373.0\nfor i in range(0,int(dfrange)):\n    lat1 = radians(df2[\"start_lat\"].iloc[i])\n    lon1 = radians(df2[\"start_lng\"].iloc[i])\n    lat2 = radians(df2[\"end_lat\"].iloc[i])\n    lon2 = radians(df2[\"end_lng\"].iloc[i])\n    dlon = lon2 - lon1\n    dlat = lat2 - lat1\n    a = sin(dlat \/ 2)**2 + cos(lat1) * cos(lat2) * sin(dlon \/ 2)**2\n    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n    d=R*c\n    dist.append(format(d,\".2f\"))\n","ba6d960f":"# New feature\ndf2[\"travel_distance\"]=dist","e8fa0fa4":"df2","ca3bddea":"# Coming back to issue of start date and end dates, and doing swap \nli=[]\nend=[]\ndfrange = df2.shape[0]\nfor i in range(0,int(dfrange)):\n    if df2[\"started_at\"].iloc[i]>df2[\"ended_at\"].iloc[i]:\n        li.append(df2[\"ended_at\"].iloc[i])\n        end.append(df2[\"started_at\"].iloc[i])\n    else:\n        li.append(df2[\"started_at\"].iloc[i])\n        end.append(df2[\"ended_at\"].iloc[i])\n    ","4a29b49f":"# Assigning new cols\ndf2[\"new_start_time\"]=li\ndf2[\"new_end_time\"]=end","f6304edf":"# Checking dataset\ndf2.head(5)","c7b8f203":"# Taking into consider and updating column to remove errors\ndf2[\"travel_time\"]=df2[\"new_end_time\"]-df2[\"new_start_time\"]","458d5fb8":"# Checking\ndf2[df2[\"new_start_time\"]>df2[\"new_end_time\"]]","cee815b6":"# Checking max travel distance\ndf2[\"travel_distance\"].max()","cbe3b387":"# Distance col to float rather than object\ndf2[\"travel_distance\"]=df2[\"travel_distance\"].map(float)","3933a006":"# Checking avg travel distance per member vs casual \ndf2.groupby(\"member_casual\").mean()[\"travel_distance\"]","df68cc87":"# Checking distance vs day of week\ndf2.groupby([\"member_casual\",\"Day_of_week\"]).mean()[\"travel_distance\"]","37ffa850":"plt.figure(figsize=(18,9))\nsplot3=sns.barplot(df2[\"Day_of_week\"],df2[\"travel_distance\"], hue=df2[\"member_casual\"])\nfor p in splot3.patches:\n    splot3.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() \/ 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')","71080bc3":"#df2.to_csv(\"Updated_Dataset.csv\")","c7a41043":"### Importing Libraries","8e999a91":"Dataset by Motivate International Inc.","262fa54b":"### Conclusion","287748b9":"**In this Case Study**\n\n* We first imported required libraries like numpy,pandas,matplotlib,seaborn,etc\n* Then we cleaned Dataset and analyzed by \n1. Dropping null values as they were small in numbers \n2. Swapped start date and end date for rows with start date more than end date\n3. Checked for duplicates and missing dates\n4. Creted new day of week column, extracted date and travel time by subtracting start and end date\n5. With latitudes and longitudes we found distance by using formula\n6. Analyzed top 10 stations for start and end points\n7. Analyzed same with respect to member categories\n8. Found that for casual rider Sunday and Saturday, and for annual member Sunday and Thursday are peak days\n9. And analyzed various other relations like distance and avg distance w.r.t.o. members and dates\/dayofweeks\n10. Visualized some and rest visuals can be seen on my Tableau Public profile below\n\n###### Tableau Public Profile :  <https:\/\/public.tableau.com\/app\/profile\/harpreet.singh6784>\n\n\n\n","33ae2dec":"### Analyzing Dataset","d9c11f27":"### Importing Dataset","b25fe7cf":"# Case Study - How Does a Bike-Share Navigate Speedy Success?\n","de187f58":"### Cleaning Dataset","d33e4d8e":"**Thanks!!!**"}}