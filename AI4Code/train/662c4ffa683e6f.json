{"cell_type":{"14ff0937":"code","a2d23652":"code","2f04e9bf":"code","87d9f473":"code","54553946":"code","52574a22":"code","1a2b58ee":"code","abb3ed63":"code","98e4ab87":"code","ab87ab91":"code","a9376734":"code","7e4e488c":"code","6b1fa4dd":"code","ed408099":"code","8b41f23e":"code","a5c1ef50":"code","81565017":"code","5ccd1767":"code","4d155fc6":"code","04107997":"code","b753450b":"code","fd0b2d15":"code","90b3dbdd":"code","6b6d6b46":"code","1fe75ec5":"code","314fe42c":"code","d3d55902":"code","3bb329c4":"markdown","15db549d":"markdown","8ebf98d1":"markdown","14b156ac":"markdown","855b5f01":"markdown","164ad55c":"markdown","4beae028":"markdown"},"source":{"14ff0937":"import numpy as np\nimport pandas as pd\nimport plotly.express as px\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\n\nfrom tensorflow_addons.metrics import RSquare","a2d23652":"data = pd.read_csv('..\/input\/food-choices\/food_coded.csv')","2f04e9bf":"data","87d9f473":"data.isna().sum()","54553946":"data[(data.isna().sum()[data.isna().sum() >= 10]).index]","52574a22":"data = data.drop('type_sports', axis=1)","1a2b58ee":"numeric_nulls = [column for column in data.columns if data.dtypes[column] != 'object' and data.isna().sum()[column] != 0]","abb3ed63":"for column in numeric_nulls:\n    data[column] = data[column].fillna(data[column].mean())","98e4ab87":"{column: list(data[column].unique()) for column in data.columns if data.isna().sum()[column] > 0}","ab87ab91":"data['GPA'] = data['GPA'].replace('Personal ', np.NaN)\ndata['GPA'] = data['GPA'].replace('Unknown', np.NaN)\ndata['GPA'] = data['GPA'].replace('3.79 bitch', '3.79')\n\ndata['GPA'] = data['GPA'].astype(np.float)\n\ndata['GPA'] = data['GPA'].fillna(data['GPA'].mean())","a9376734":"nonnumeric_nulls = [column for column in data.columns if data.dtypes[column] == 'object' and data.isna().sum()[column] != 0]\nnonnumeric_nulls.remove('weight')\n\ndata = data.drop(nonnumeric_nulls, axis=1)","7e4e488c":"data","6b1fa4dd":"data.isna().sum()","ed408099":"data['weight'].unique()","8b41f23e":"data['weight'] = data['weight'].replace('Not sure, 240', '240')\ndata['weight'] = data['weight'].replace('144 lbs', '144')\ndata['weight'] = data['weight'].replace(\"I'm not answering this. \", np.NaN)\n\ndata = data.dropna(axis=0).reset_index(drop=True)","a5c1ef50":"data.isna().sum().sum()","81565017":"data = data.astype(np.float)","5ccd1767":"data","4d155fc6":"y = data.loc[:, 'weight']\nX = data.drop('weight', axis=1)","04107997":"scaler = StandardScaler()\n\nX = scaler.fit_transform(X)","b753450b":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=22)","fd0b2d15":"X.shape","90b3dbdd":"inputs = tf.keras.Input(shape=(48,))\nx = tf.keras.layers.Dense(256, activation='relu')(inputs)\nx = tf.keras.layers.Dense(512, activation='relu')(x)\nx = tf.keras.layers.Dense(512, activation='relu')(x)\nx = tf.keras.layers.Dense(256, activation='relu')(x)\noutputs = tf.keras.layers.Dense(1, activation='linear')(x)\n\nmodel = tf.keras.Model(inputs, outputs)\n\n\nmodel.compile(\n    optimizer='adam',\n    loss='mse'\n)\n\n\nbatch_size = 32\nepochs = 200\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    validation_split=0.2,\n    batch_size=batch_size,\n    epochs=epochs\n)","6b6d6b46":"fig = px.line(\n    history.history,\n    y=['loss', 'val_loss'],\n    labels={'x': \"Epoch\", 'y': \"Loss\"},\n    title=\"Loss Over Time\"\n)\n\nfig.show()","1fe75ec5":"y_preds = np.squeeze(model.predict(X_test))","314fe42c":"rsquare = RSquare()\n\nrsquare.update_state(y_test, y_preds)","d3d55902":"print(\"R^2 Score:\", rsquare.result().numpy())","3bb329c4":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/ddzaEUN375k","15db549d":"## Splitting and Scaling","8ebf98d1":"# Results","14b156ac":"# Getting Started","855b5f01":"# Training","164ad55c":"# Preprocessing","4beae028":"# Task for Today  \n\n***\n\n## Predicting Weight From Food Choices  \n\nGiven *data about different people's food preferences*, let's try to predict the **weight** of a given person.  \n  \nWe will use a TensorFlow ANN to make our predictions."}}