{"cell_type":{"df0d79d5":"code","9b957f02":"code","b30da547":"code","714af1dd":"code","d525e3d9":"code","49ada493":"code","6b401979":"code","d058bbd8":"code","b303e2b3":"code","0fb3189a":"code","bc769adc":"code","b741a780":"code","2bedcfbd":"code","84ebf6b4":"code","d273611d":"code","f808d2d2":"code","9a3e3ed4":"code","6b2bef56":"code","3b587ec3":"code","dde7b006":"code","adc240cd":"code","2cd79772":"code","090f1d22":"code","2f397885":"code","ea3083a1":"code","f64561bb":"code","06c10d52":"code","e9c501bf":"code","ca5a3635":"code","92c06d70":"code","c5a11f0d":"code","5f61f7ea":"code","62533759":"code","bde93e5e":"code","0e406a1a":"code","5b4789f8":"markdown","3257fd11":"markdown","2ceba31d":"markdown","0f261083":"markdown","c1e4b6ae":"markdown","1919cd25":"markdown","4498ba0f":"markdown","191225e5":"markdown","8c9283a4":"markdown","6394dc1e":"markdown","4c432ec3":"markdown","861e304c":"markdown"},"source":{"df0d79d5":"#import the necessary libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n%matplotlib inline","9b957f02":"#reading the files\ntrain = pd.read_csv('..\/input\/Admission_Predict_Ver1.1.csv')\n","b30da547":"#viewing the data\ntrain.head()","714af1dd":"#taking a look at all the columns in the data\ntrain.columns.values","d525e3d9":"sns.pairplot(train)","49ada493":"y = train['Chance of Admit '] #target variable\nz = train['Research'] #extract it for later preprocessing as this only has boolean values\nX = train.drop(columns=['Serial No.','Chance of Admit ','Research']) #drop the columns\nprint(X.head())\ncolumns = X.columns.values\nprint(columns)","6b401979":"X.corr()","d058bbd8":"#Preprocessing data to get better results\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_new = scaler.fit_transform(X)\nX_new ","b303e2b3":"X_new = pd.DataFrame(data=X_new,columns=['GRE_Score','TOEFL_Score','University_Rating','SOP','LOR','CGPA'])\nX_new.head()","0fb3189a":"X_new['Research'] = z\nX_new['Chances_of_admit'] = y","bc769adc":"#importing more libraries to check the assumptions of Linear Regression\nimport statsmodels.formula.api as smf\nimport statsmodels.stats.api as sms\nfrom scipy import stats\nfrom statsmodels.compat import lzip","b741a780":"model = smf.ols(\"Chances_of_admit~GRE_Score+TOEFL_Score+SOP+LOR+CGPA+Research+University_Rating\", data= X_new).fit()\n    \nmodel.summary()","2bedcfbd":"pred_val = model.fittedvalues.copy()\ntrue_val = y.values.copy()\nresidual = true_val - pred_val","84ebf6b4":"fig, ax = plt.subplots(figsize=(6,2.5))\n_ = ax.scatter(residual, pred_val)","d273611d":"stats.probplot(model.resid, plot= plt)\nplt.title(\"Model Residuals Probability Plot\")","f808d2d2":"#another measure of the degree of normal distribution of the residuals\nstats.kstest(model.resid, 'norm')","9a3e3ed4":"\nname = ['Lagrange multiplier statistic', 'p-value', \n        'f-value', 'f p-value']\ntest = sms.het_breuschpagan(model.resid, model.model.exog)\nlzip(name, test)","6b2bef56":"from sklearn.linear_model import LinearRegression\nX_new = X_new.drop(columns=['Chances_of_admit'])\nX_new['Research'] = z\nreg = LinearRegression().fit(X_new, y)\nreg.score(X_new, y)","3b587ec3":"#dropping GRE Score\nX_new_drop= X_new.drop(columns=['GRE_Score'])\nreg = LinearRegression().fit(X_new_drop, y)\nreg.score(X_new_drop, y)","dde7b006":"#dropping TOEFL Score\nX_new_drop= X_new.drop(columns=['TOEFL_Score'])\nreg = LinearRegression().fit(X_new_drop, y)\nreg.score(X_new_drop, y)","adc240cd":"#dropping University Rating\nX_new_drop= X_new.drop(columns=['University_Rating'])\nreg = LinearRegression().fit(X_new_drop, y)\nreg.score(X_new_drop, y)","2cd79772":"#dropping CGPA\nX_new_drop= X_new.drop(columns=['CGPA'])\nreg = LinearRegression().fit(X_new_drop, y)\nreg.score(X_new_drop, y)","090f1d22":"#dropping Research\nX_new_drop= X_new.drop(columns=['Research'])\nreg = LinearRegression().fit(X_new_drop, y)\nreg.score(X_new_drop, y)","2f397885":"#dropping University Rating\nX_new_drop= X_new.drop(columns=['University_Rating'])\nreg = LinearRegression().fit(X_new_drop, y)\nreg.score(X_new_drop, y)","ea3083a1":"#dropping LOR\nX_new_drop= X_new.drop(columns=['LOR'])\nreg = LinearRegression().fit(X_new_drop, y)\nreg.score(X_new_drop, y)","f64561bb":"#dropping SOP\nX_new_drop= X_new.drop(columns=['SOP'])\nreg = LinearRegression().fit(X_new_drop, y)\nreg.score(X_new_drop, y)","06c10d52":"test = pd.read_csv('..\/input\/Admission_Predict.csv')\ntest.head()","e9c501bf":"test.columns.values","ca5a3635":"y_act = test['Chance of Admit ']\nX_test = test.drop(columns=[\"Serial No.\",'Chance of Admit '])","92c06d70":"scaler = StandardScaler()\nz = X_test['Research']\nX_test = X_test.drop(columns=[\"Research\"])\nX_test_new = scaler.fit_transform(X_test)\nX_test_new","c5a11f0d":"X_test_new = pd.DataFrame(data=X_test_new,columns=['GRE_Score','TOEFL_Score','University_Rating','SOP','LOR','CGPA'])\nX_test_new.head()","5f61f7ea":"X_test_new['Research'] = z\nX_test_new.head()","62533759":"reg = LinearRegression().fit(X_new, y)\nreg.score(X_new, y)","bde93e5e":"y_pred = reg.predict(X_test_new)","0e406a1a":"#evaluating the metrics\nfrom sklearn import metrics\nprint(metrics.mean_absolute_error(y_act,y_pred))\nprint(metrics.mean_squared_error(y_act,y_pred))\nprint(np.sqrt(metrics.mean_squared_error(y_act,y_pred)))","5b4789f8":"It is evident that GRE Score is highly correlated with TOEFL score and CGPA. This does not satisfy Linear Regression's assumption. This could be a reason why the model might not perform too well. You can use Principal Component Analysis to solve the multicollinearity issue. ","3257fd11":"As is seen, the evaluation metrics is good enough. The model can do better if we satisfy all the assumptions of Linear Regression. ","2ceba31d":"Since this plot is so concentrated at one point, it indicates that residuals are not normally distributed. To test this further we can use the below plot.","0f261083":"Clearly, the feature that has most impact on the target is CGPA. ","c1e4b6ae":"Assumptions of Linear Regression are not independent of each other. So this could also be because of other assumptions being violated. ","1919cd25":"Homoscedasticity\u2013This assumption states that the variance of error terms are similar across the values of the independent variables. To test this condition we use the Breusch\u2013Pagan test. If the p-value is less than 0.05, this condition is violated. ","4498ba0f":"Now, let's see how our model does on unseen data. ","191225e5":"The above method gives an extensive summary of the Ordinary Least Squares Regression.  ","8c9283a4":"Homoscedacity is violated as well. Nevertheless, we'll be applying the Linear Regression model on this dataset and seeing the results. This dataset is pretty clean and the features have a linear relationship with the target as well. Hence, Linear Regression should give good enough results. ","6394dc1e":"Through this dataset, I have attempted to study Linear Regression. Graduate Admissions dataset consists of various features like GRE Score, TOEFL Score, CGPA, etc and the target variable is Chances of Admit. This project involves data visualization and building a linear regression model. ","4c432ec3":"Take a look the Chance of Admit row at the bottom. It is evident that the target value is linearly dependent on the features. ","861e304c":"Let's try to see the effect that individual features have on this score when dropped one at a time. "}}