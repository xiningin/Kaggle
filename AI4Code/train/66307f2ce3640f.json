{"cell_type":{"2a3191df":"code","f482cfda":"code","936d97a9":"code","1819f8cf":"code","5d88d3c4":"code","c52deb03":"code","19ce1cc8":"code","dd27ecb8":"code","6dc1f68e":"code","3bdd2b00":"code","d024e806":"code","8426d33b":"code","9b028834":"code","95c4d60f":"code","e248cf0a":"code","5939438b":"code","ed6f70dd":"code","24263114":"code","260893d3":"code","be102e36":"code","d5c5b3d4":"code","6d2f6944":"code","07ece9df":"code","486bc203":"code","0c179fb3":"code","81bb1b98":"code","b4025d72":"code","81243567":"code","49b0871d":"code","dccc08f6":"code","46d09a72":"code","d185288f":"code","7dad2bf0":"code","c91853c3":"code","f0b27c57":"code","7350d76b":"code","3df0a2ad":"code","82ed4e15":"code","6100b64e":"code","1f5282fa":"code","b8d2e3a5":"code","1055265e":"code","b3372ad2":"code","6a9a7abd":"code","686d065e":"code","d5da2a72":"code","58f1b8dc":"code","6c47df52":"code","b738e796":"code","a2445c01":"code","a6082cf2":"code","31488a62":"code","8f4f1909":"code","c5dd6778":"code","359dd7eb":"code","667048df":"code","89765cba":"code","5bebbf70":"code","184ca803":"code","de0ea9f9":"code","fd05f044":"code","25fa3afc":"code","de58f436":"code","668ea768":"code","8e559b22":"code","d59bb178":"code","2defef83":"code","6cf604ec":"code","5eb1385b":"code","87d2a5e7":"code","b63e744d":"code","39118d05":"markdown","3dc049c2":"markdown","c5255adb":"markdown","615ca071":"markdown","491cce25":"markdown","b3c139a6":"markdown","2d57f915":"markdown","5bf29d18":"markdown","92ca9972":"markdown","57cfbc4b":"markdown","2153d907":"markdown","b336ae87":"markdown","61afc7a9":"markdown","05247711":"markdown","a8759a6c":"markdown","ff8fcdaf":"markdown","30c6f9ac":"markdown","11ad80ef":"markdown","98776b7c":"markdown","c3b7c6c1":"markdown","c6587b7f":"markdown","933497c1":"markdown","96a19448":"markdown","20d189de":"markdown","426df9aa":"markdown","41a50e95":"markdown","391abd54":"markdown","4c1648a8":"markdown","6a64c40b":"markdown","0b1dffe4":"markdown","3598a5be":"markdown","32879537":"markdown","88d96166":"markdown","2e87859c":"markdown","8e93c4da":"markdown","5083ba85":"markdown","5645299b":"markdown","2f37ebc3":"markdown","e3e957c1":"markdown","3e11e578":"markdown","e875e508":"markdown","20538033":"markdown","aaebef70":"markdown","3ea1f93a":"markdown"},"source":{"2a3191df":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f482cfda":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\npd.pandas.set_option('display.max_columns', None)\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\nfrom sklearn.linear_model import Lasso\nfrom sklearn.feature_selection import SelectFromModel\npd.pandas.set_option('display.max_columns', None)\nimport matplotlib.pyplot as plt\nfrom fbprophet import Prophet\nimport plotly.express as px\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import metrics\nfrom sklearn.model_selection import ParameterGrid\nfrom tqdm import tqdm\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.decomposition import PCA","936d97a9":"path = \"..\/input\/covid19-global-forecasting-week-5\/train.csv\"\npath2 = \"..\/input\/covid19-global-forecasting-week-5\/test.csv\"\npath3=\"..\/input\/covid19-useful-features-by-country\/Countries_usefulFeatures.csv\"\npath4=\"..\/input\/covid19-global-forecasting-week-5\/submission.csv\"\n","1819f8cf":"df_train = pd.read_csv(path,encoding = 'unicode_escape')\ndf_test = pd.read_csv(path2,encoding = 'unicode_escape')\ndf_count_feat=pd.read_csv(path3,encoding = 'unicode_escape')\ndf_sub=pd.read_csv(path4,encoding = 'unicode_escape')","5d88d3c4":"df_train.head()","c52deb03":"df_train.info()","19ce1cc8":"#missing data\ntotal = df_train.isnull().sum().sort_values(ascending=False)\npercent = (df_train.isnull().sum()\/df_train.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data","dd27ecb8":"df_train.describe()","6dc1f68e":"df_train.drop(df_train[df_train.TargetValue < 0].index, inplace=True)","3bdd2b00":"country_wise=df_train[df_train['Province_State'].isnull()]\ncountry_wise=country_wise[country_wise['Target']=='ConfirmedCases']\ncountry_wise=country_wise.groupby('Country_Region')['TargetValue'].sum().reset_index()\ncountry_wise=country_wise.rename(columns={\"Country_Region\":\"Country_Region\",\"TargetValue\":\"ConfimedCases\"})\ncountry_wise","d024e806":"def plot_map(df, col, pal):\n    df = df[df[col]>0]\n    fig = px.choropleth(df, locations=\"Country_Region\", locationmode='country names', \n                  color=col, hover_name=\"Country_Region\", \n                  title=col, hover_data=[col], color_continuous_scale=pal)\n#     fig.update_layout(coloraxis_showscale=False)\n    fig.show()","8426d33b":"plot_map(country_wise, 'ConfimedCases', 'matter')","9b028834":"def plot_hbar(df, col, n, hover_data=[]):\n    fig = px.bar(df.sort_values(col).tail(n), \n                 x=col, y=\"Country_Region\", color='Country_Region',  \n                 text=col, orientation='h', width=700, hover_data=hover_data,\n                 color_discrete_sequence = px.colors.qualitative.Dark2)\n    fig.update_layout(title=col, xaxis_title=\"\", yaxis_title=\"\", \n                      yaxis_categoryorder = 'total ascending',\n                      uniformtext_minsize=8, uniformtext_mode='hide')\n    fig.show()","95c4d60f":"plot_hbar(country_wise, 'ConfimedCases', 15)","e248cf0a":"df_Us=df_train[df_train['Country_Region']=='US']\ndf_Us=df_Us[df_Us['Target']=='ConfirmedCases']\ndf_Us=df_Us[df_Us['Province_State'].isnull()]\ndf_plot=df_Us.rename(columns={\"Date\":\"Date\",\"TargetValue\": \"US_TotalCase\"})\ndf_plot=df_plot[[\"Date\",\"US_TotalCase\"]]\ndf_Br=df_train[df_train['Country_Region']=='Brazil']\ndf_Br=df_Br[df_Br['Target']=='ConfirmedCases']\ndf_Br=df_Br.rename(columns={\"Date\":\"Date\",\"TargetValue\": \"Brazil_TotalCase\"})\ndf_Br=df_Br[[\"Date\",\"Brazil_TotalCase\"]]\ndf_Rus=df_train[df_train['Country_Region']=='Russia']\ndf_Rus=df_Rus[df_Rus['Target']=='ConfirmedCases']\ndf_Rus=df_Rus.rename(columns={\"Date\":\"Date\",\"TargetValue\": \"Russia_TotalCase\"})\ndf_Rus=df_Rus[[\"Date\",\"Russia_TotalCase\"]]","5939438b":"df_plot=df_plot.merge(df_Br,on='Date').merge(df_Rus,on='Date')\ndf_plot","ed6f70dd":"temp = df_plot.groupby('Date')['Russia_TotalCase','Brazil_TotalCase','US_TotalCase'].sum().reset_index()\ntemp = temp.melt(id_vars=\"Date\", value_vars=['Russia_TotalCase','Brazil_TotalCase','US_TotalCase'],\n                 var_name='Case', value_name='Count')\ntemp.head()\n\nfig = px.area(temp, x=\"Date\", y=\"Count\", color='Case', height=600, width=700,\n             title='Cases over time', color_discrete_sequence = [\"blue\", \"green\", \"red\"])\nfig.update_layout(xaxis_rangeslider_visible=True)\nfig.show()","24263114":"df_train2=df_train.merge(df_count_feat[['Country_Region','Tourism','Latitude','Longtitude','Mean_Age','Lockdown_Date','Lockdown_Type']], on='Country_Region', how='inner', sort=False)\ndf_train2.head()","260893d3":"def confatal(df):\n    df_Confirmed_Cases=df[df[\"Target\"]==\"ConfirmedCases\"]\n    df_Confirmed_Cases=df_Confirmed_Cases.rename(columns={\"TargetValue\": \"ConfirmedCases\"})\n    df_Confirmed_Cases=df_Confirmed_Cases.drop(['Target'], axis=1)\n    df_Fatalities=df[df[\"Target\"]==\"Fatalities\"]\n    df_Fatalities=df_Fatalities.rename(columns={\"TargetValue\": \"Fatalities\"})\n    df_Fatalities=df_Fatalities.drop(['Target'], axis=1)\n    df=pd.merge(df_Confirmed_Cases,df_Fatalities[['Date','County','Province_State','Country_Region','Fatalities']],on=['Date','County','Province_State','Country_Region'], how='inner')\n    df=df[['Id','County','Province_State','Country_Region','Population','Weight','Date','ConfirmedCases','Fatalities','Tourism','Latitude','Longtitude','Mean_Age','Lockdown_Date','Lockdown_Type']]\n    return df","be102e36":"df_confat=confatal(df_train2)\ndf_confat.head()","d5c5b3d4":"from sklearn.preprocessing import OrdinalEncoder\n\ndef create_date_features(df):\n    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n    df['Year']=df.Date.dt.year\n    df['Month']=df.Date.dt.month\n    df['Day']=df['Date'].dt.strftime('%d')\n    df['Day_number_of_week'] = df.Date.dt.weekday\n    return df","6d2f6944":"create_date_features(df_confat)","07ece9df":"def getdayofweek(dow):\n    if (dow == 0):\n        return \"Monday\"\n    elif(dow == 1):\n        return \"Tuesday\"\n    elif(dow ==2):\n        return \"Wednesday\"\n    elif(dow == 3):\n        return \"Thursday\"\n    elif(dow ==4):\n        return \"Friday\"\n    elif(dow == 5):\n        return \"Saturday\"\n    elif(dow ==6):\n        return \"Sunday\"","486bc203":"df_confat['Dayofweek'] = df_confat.Day_number_of_week.apply(getdayofweek)","0c179fb3":"df_Us=df_train[df_train['Country_Region']=='US']\ndf_Us=df_Us[df_Us['Target']=='ConfirmedCases']","81bb1b98":"df_Us=df_Us[df_Us['Province_State'].isnull()]\ndf_Us","b4025d72":"plt.figure(figsize=(20, 10))\nsns.lineplot(data=df_Us[df_Us['Date']<\"2020-05-01\"], x=\"Date\", y=\"TargetValue\")\nplt.xticks(rotation=90);","81243567":"Train_us=df_Us[df_Us[\"Date\"]<\"2020-05-12\"]\nTest_us=df_Us[df_Us[\"Date\"]>=\"2020-05-12\"]","49b0871d":"Train_us=Train_us[[\"Date\",\"TargetValue\"]]\nTest_us=Test_us[[\"Date\",\"TargetValue\"]]\nTrain_us=Train_us.rename(columns={\"Date\":\"ds\",\"TargetValue\":\"y\"})\nTest_us=Test_us.rename(columns={\"Date\":\"ds\",\"TargetValue\":\"y\"})","dccc08f6":"model=Prophet(growth='linear',changepoint_prior_scale=60)\nmodel.fit(Train_us)\nforecast = model.predict(Test_us)\nfig = model.plot_components(forecast)","46d09a72":"plot = model.plot(forecast)","d185288f":"Test_us['yhat']=forecast['yhat'].values\nTest_us","7dad2bf0":"plt.figure(figsize=(20, 8))\nplt.plot(Test_us['ds'], Test_us['y'], 'b-', label = 'Actual')\nplt.plot(Test_us['ds'], Test_us['yhat'], 'r--', label = 'Prediction')\nplt.xlabel('Date',rotation=90); plt.ylabel('Sales'); plt.title('Actual vs Prediction')\nplt.xticks(rotation=90)\nplt.legend();","c91853c3":"Test_us['diff']=(Test_us.y-Test_us.yhat).abs()\nacc_ts=(1-(Test_us['diff'].sum()\/Test_us['y'].sum()))*100\nacc_ts","f0b27c57":"MAE_ts=metrics.mean_absolute_error(Test_us['y'], Test_us['yhat'])\nMSE_ts=metrics.mean_squared_error(Test_us['y'], Test_us['yhat'])\nRMSE_ts=np.sqrt(metrics.mean_squared_error(Test_us['y'], Test_us['yhat']))\nprint('MAE:', MAE_ts)\nprint('MSE:', MSE_ts)\nprint('RMSE:', RMSE_ts)","7350d76b":"params_grid = {'seasonality_mode':('multiplicative','additive'),\n               'changepoint_prior_scale':[0.5,1.2,2.5],\n              'seasonality_prior_scale':[0.5,1.2,2.5]\n              }\ngrid = ParameterGrid(params_grid)","3df0a2ad":"model_parameters = pd.DataFrame(columns = ['Acc','Parameters'])\nfor p in tqdm(grid):\n    \n    Train=Train_us.copy()\n    Valid=Test_us[['ds','y']]\n            \n    m =Prophet(changepoint_prior_scale = p['changepoint_prior_scale'],\n               seasonality_prior_scale = p['seasonality_prior_scale'],\n               seasonality_mode = p['seasonality_mode'],\n               interval_width=0.95)\n            \n    m.fit(Train_us)\n            \n            \n    forecast = m.predict(Valid[['ds']])\n    forecast = forecast.astype({\"ds\": object})\n    Valid=Valid.merge(forecast[['ds', 'yhat']],'inner',['ds'])\n    \n    #performance metric\n    Valid['diff']=(Valid.y-Valid.yhat).abs()\n    acc=(1-((Valid['diff'].sum()\/Valid['y'].sum())))*100\n    \n    model_parameters = model_parameters.append({'Acc':acc,'Parameters':p},ignore_index=True)\n            \nparameters = model_parameters.sort_values(by=['Acc'],ascending=False)\nparameters = parameters.reset_index(drop=True)\n        \nbest_parameters=parameters['Parameters'][0]","82ed4e15":"best_parameters","6100b64e":"m = Prophet(\n        growth=\"linear\",\n        seasonality_mode=best_parameters['seasonality_mode'],\n        changepoint_prior_scale=best_parameters['changepoint_prior_scale'],\n        seasonality_prior_scale=best_parameters['seasonality_prior_scale']\n        )\nm.fit(Train_us)\nforecast=m.predict(Test_us)","1f5282fa":"fig = m.plot_components(forecast)","b8d2e3a5":"plot = m.plot(forecast)","1055265e":"Test_us['yhat']=forecast['yhat'].values\nplt.figure(figsize=(20, 8))\nplt.plot(Test_us['ds'], Test_us['y'], 'b-', label = 'Actual')\nplt.plot(Test_us['ds'], Test_us['yhat'], 'r--', label = 'Prediction')\nplt.xlabel('Date',rotation=90); plt.ylabel('Sales'); plt.title('Actual vs Prediction')\nplt.xticks(rotation=90)\nplt.legend();","b3372ad2":"Test_us['diff']=(Test_us.y-Test_us.yhat).abs()\nacc_ts2=(1-(Test_us['diff'].sum()\/Test_us['y'].sum()))*100\nacc_ts2","6a9a7abd":"MAE_ts2=metrics.mean_absolute_error(Test_us['y'], Test_us['yhat'])\nMSE_ts2=metrics.mean_squared_error(Test_us['y'], Test_us['yhat'])\nRMSE_ts2=np.sqrt(metrics.mean_squared_error(Test_us['y'], Test_us['yhat']))\nprint('MAE:', MAE_ts2)\nprint('MSE:', MSE_ts2)\nprint('RMSE:', RMSE_ts2)","686d065e":"reg_us=create_date_features(df_Us)","d5da2a72":"reg_us['Dayofweek'] = reg_us.Day_number_of_week.apply(getdayofweek)","58f1b8dc":"reg_us=pd.get_dummies(reg_us,columns=['Dayofweek'])\nreg_us.head()","6c47df52":"Train_reg_us=reg_us[reg_us[\"Date\"]<\"2020-05-12\"]\nTest_reg_us=reg_us[reg_us[\"Date\"]>=\"2020-05-12\"]","b738e796":"x_train_reg_us=Train_reg_us[['Month','Dayofweek_Monday','Dayofweek_Tuesday','Dayofweek_Wednesday','Dayofweek_Thursday','Dayofweek_Friday','Dayofweek_Saturday','Dayofweek_Sunday']]\ny_train_reg_us=Train_reg_us[['TargetValue']]","a2445c01":"x_test_reg_us=Test_reg_us[['Month','Dayofweek_Monday','Dayofweek_Tuesday','Dayofweek_Wednesday','Dayofweek_Thursday','Dayofweek_Friday','Dayofweek_Saturday','Dayofweek_Sunday']]\ny_test_reg_us=Test_reg_us[['TargetValue']]","a6082cf2":"rf_us = RandomForestRegressor(n_estimators=100)\nrf_us.fit(x_train_reg_us,y_train_reg_us)\npred_rf = rf_us.predict(x_test_reg_us)","31488a62":"y_test_reg_us['diff']=(y_test_reg_us.TargetValue-pred_rf).abs()\nacc_rf=(1-(y_test_reg_us['diff'].sum()\/y_test_reg_us['TargetValue'].sum()))*100\nacc_rf","8f4f1909":"MAE_rf=metrics.mean_absolute_error(y_test_reg_us.TargetValue, pred_rf)\nMSE_rf=metrics.mean_squared_error(y_test_reg_us.TargetValue, pred_rf)\nRMSE_rf=np.sqrt(metrics.mean_squared_error(y_test_reg_us.TargetValue, pred_rf))\nprint('MAE:', MAE_rf)\nprint('MSE:', MSE_rf)\nprint('RMSE:', RMSE_rf)","c5dd6778":"param_grid = { \n        \"n_estimators\"      : [10,20,300,100,200,500],\n        \"max_features\"      : [\"auto\", \"sqrt\", \"log2\"],\n        \"min_samples_split\" : [2,4,6,8],\n        \"bootstrap\": [True, False],\n            }\ngrid = ParameterGrid(param_grid)","359dd7eb":"model_parameters = pd.DataFrame(columns = ['Acc','Parameters'])\nfor p in tqdm(grid):\n    \n    X_Train=x_train_reg_us.copy()\n    Y_Train=y_train_reg_us.copy()\n    X_Valid=x_test_reg_us.copy()\n    Y_Valid=y_test_reg_us.copy()\n    m = RandomForestRegressor(n_estimators = p['n_estimators'],\n               max_features = p['max_features'],\n               min_samples_split = p['min_samples_split'],\n               bootstrap=p['bootstrap'])\n    \n    \n    \n    m.fit(X_Train,Y_Train)\n    pred_rf2 = m.predict(X_Valid)\n            \n    Y_Valid['yhat']=pred_rf2\n    \n    #performance metric\n    Y_Valid['diff']=(Y_Valid.TargetValue-Y_Valid.yhat).abs()\n    acc=(1-((Y_Valid['diff'].sum()\/Y_Valid['TargetValue'].sum())))*100\n    \n    model_parameters = model_parameters.append({'Acc':acc,'Parameters':p},ignore_index=True)\n            \nparameters = model_parameters.sort_values(by=['Acc'],ascending=False)\nparameters = parameters.reset_index(drop=True)\n        \nbest_parameters=parameters['Parameters'][0]","667048df":"best_parameters","89765cba":"m = RandomForestRegressor(\n        bootstrap=best_parameters['bootstrap'],\n        max_features=best_parameters['max_features'],\n        min_samples_split=best_parameters['min_samples_split'],\n        n_estimators=best_parameters['n_estimators']\n        )\nm.fit(x_train_reg_us,y_train_reg_us)\npred_rf2 = m.predict(x_test_reg_us)","5bebbf70":"y_test_reg_us['diff']=(y_test_reg_us.TargetValue-pred_rf2).abs()\nacc_rf2=(1-(y_test_reg_us['diff'].sum()\/y_test_reg_us['TargetValue'].sum()))*100\nacc_rf2","184ca803":"MAE_rf2=metrics.mean_absolute_error(y_test_reg_us.TargetValue, pred_rf2)\nMSE_rf2=metrics.mean_squared_error(y_test_reg_us.TargetValue, pred_rf2)\nRMSE_rf2=np.sqrt(metrics.mean_squared_error(y_test_reg_us.TargetValue, pred_rf2))\nprint('MAE:', MAE_rf2)\nprint('MSE:', MSE_rf2)\nprint('RMSE:', RMSE_rf2)","de0ea9f9":"xgb_us = XGBRegressor(n_estimators=100)\nxgb_us.fit(x_train_reg_us,y_train_reg_us)\nxgb_pred = xgb_us.predict(x_test_reg_us)","fd05f044":"y_test_reg_us['diff']=(y_test_reg_us.TargetValue-xgb_pred).abs()\nacc_xg=(1-(y_test_reg_us['diff'].sum()\/y_test_reg_us['TargetValue'].sum()))*100\nacc_xg","25fa3afc":"MAE_xgb=metrics.mean_absolute_error(y_test_reg_us.TargetValue, xgb_pred)\nMSE_xgb=metrics.mean_squared_error(y_test_reg_us.TargetValue, xgb_pred)\nRMSE_xgb=np.sqrt(metrics.mean_squared_error(y_test_reg_us.TargetValue, xgb_pred))\nprint('MAE:', MAE_xgb)\nprint('MSE:', MSE_xgb)\nprint('RMSE:', RMSE_xgb)","de58f436":"param_grid = { \n            'nthread':[4], #when use hyperthread, xgboost may become slower,\n            'learning_rate': [.03, 0.05, .07], #so called `eta` value\n            'max_depth': [5, 6, 7],\n            'min_child_weight': [1,4],\n            'subsample': [0.7],\n            'colsample_bytree': [0.7],\n            'n_estimators': [100,200,500]\n            }\ngrid = ParameterGrid(param_grid)","668ea768":"model_parameters = pd.DataFrame(columns = ['Acc','Parameters'])\nfor p in tqdm(grid):\n    \n    X_Train=x_train_reg_us.copy()\n    Y_Train=y_train_reg_us.copy()\n    X_Valid=x_test_reg_us.copy()\n    Y_Valid=y_test_reg_us.copy()\n    m = XGBRegressor(nthread = p['nthread'],\n               learning_rate = p['learning_rate'],\n               max_depth=p['max_depth'],\n               min_child_weight = p['min_child_weight'],\n               subsample = p['subsample'],\n               colsample_bytree=p['colsample_bytree'],\n               n_estimators=p['n_estimators']             )\n    \n    \n    \n    m.fit(X_Train,Y_Train)\n    pred_xg2 = m.predict(X_Valid)\n            \n    Y_Valid['yhat']=pred_xg2\n    \n    #performance metric\n    Y_Valid['diff']=(Y_Valid.TargetValue-Y_Valid.yhat).abs()\n    acc=(1-((Y_Valid['diff'].sum()\/Y_Valid['TargetValue'].sum())))*100\n    \n    model_parameters = model_parameters.append({'Acc':acc,'Parameters':p},ignore_index=True)\n            \nparameters = model_parameters.sort_values(by=['Acc'],ascending=False)\nparameters = parameters.reset_index(drop=True)\n        \nbest_parameters=parameters['Parameters'][0]","8e559b22":"best_parameters","d59bb178":"m = XGBRegressor(\n        nthread=best_parameters['nthread'],\n        learning_rate=best_parameters['learning_rate'],\n        max_depth=best_parameters['max_depth'],\n        min_child_weight=best_parameters['min_child_weight'],\n        subsample=best_parameters['subsample'],\n        colsample_bytree=best_parameters['colsample_bytree'],\n        n_estimators=best_parameters['n_estimators']\n        )\nm.fit(x_train_reg_us,y_train_reg_us)\npred_xg2 = m.predict(x_test_reg_us)","2defef83":"y_test_reg_us['diff']=(y_test_reg_us.TargetValue-pred_xg2).abs()\nacc_xg2=(1-(y_test_reg_us['diff'].sum()\/y_test_reg_us['TargetValue'].sum()))*100\nacc_xg2","6cf604ec":"MAE_xgb2=metrics.mean_absolute_error(y_test_reg_us.TargetValue, pred_xg2)\nMSE_xgb2=metrics.mean_squared_error(y_test_reg_us.TargetValue, pred_xg2)\nRMSE_xgb2=np.sqrt(metrics.mean_squared_error(y_test_reg_us.TargetValue, pred_xg2))\nprint('MAE:', MAE_xgb2)\nprint('MSE:', MSE_xgb2)\nprint('RMSE:', RMSE_xgb2)","5eb1385b":"df_performance = {'Model':['Prophet','Prophet','Random Forest','Random Forest','XGBoost','XGBoost'],\n        'Parameters':['Default','Best','Default','Best','Default','Best'],\n        'Accuracy':[acc_ts,acc_ts2,acc_rf,acc_rf2,acc_xg,acc_xg2],\n        'MAE': [MAE_ts,MAE_ts2, MAE_rf,MAE_rf2,MAE_xgb,MAE_xgb2],\n        'MSE': ['{:f}'.format(MSE_ts),'{:f}'.format(MSE_ts2),'{:f}'.format(MSE_rf),'{:f}'.format(MSE_rf2),'{:f}'.format(MSE_xgb),'{:f}'.format(MSE_xgb2)], \n        'RMSE': ['{:f}'.format(RMSE_ts),'{:f}'.format(RMSE_ts2),'{:f}'.format(RMSE_rf),'{:f}'.format(RMSE_rf2),'{:f}'.format(RMSE_xgb),'{:f}'.format(RMSE_xgb2)]}\npd.DataFrame.from_dict(df_performance)","87d2a5e7":"fig, ax = plt.subplots(figsize=(9,4))\na=sns.barplot(data=df_performance,x=\"Model\", y=\"Accuracy\",hue = 'Parameters')\na.set_title(\"Model Performance\",fontsize=15)\nplt.xlabel('Model')\nplt.ylabel('Accuracy')\nplt.legend(loc='upper left')\nplt.ylim(60, 92)\nplt.show()","b63e744d":"fig, ax = plt.subplots(figsize=(9,4))\na=sns.barplot(data=df_performance,x=\"Model\", y=\"MAE\",hue = 'Parameters')\na.set_title(\"Model Performance\",fontsize=15)\nplt.xlabel('Model')\nplt.ylabel('Mean Absolute Error')\nplt.ylim(500, 4500)\nplt.legend(loc='upper left')\nplt.show()","39118d05":"**We create datetime features to use in the model..**","3dc049c2":"### According to Map and the graph below, we can say that the number of cases is mostly in the US and then in Brazil..","c5255adb":"Since we are asked to predict the cases after May of 12, we split our observations from this point as Train-Test. Train data set includes 110 observations, test data set 30 observations.","615ca071":"Accuracy is better with the best parameters","491cce25":"## Map","b3c139a6":"### Parameter Tuning for XGBOOST Regressor","2d57f915":"**We drop the negatif values**","5bf29d18":"<a id=\"Feature_Engineering\"><\/a>\n# 3. Feature Engineering","92ca9972":"**Creating Date Features**","57cfbc4b":"## Top 20 Countries","2153d907":"**One hot encoding for Dayofweek Feature**\n<br>We use one hot encoding to transform categorical variables (Day0fweek) to use in our model","b336ae87":"### Creating ConfirmedCases and Fatalities variables for some calculation","61afc7a9":"I use MAE, MSE, RMSE performance metric, because it is easy to explain. Prediction differs 3378 case from the actual.. It is not bad, because there are around 20000, 25000 case in US in a day..","05247711":"Accuracy is %84 for the prophet model with default parameters.. We should try to do parameter tuning to increase accuracy..","a8759a6c":"<a id=\"Second_Model\"><\/a>\n>## 4.2 US Confimed Case Forecasting with Random Forest Reggressor","ff8fcdaf":"### Transformation of datetime features","30c6f9ac":"![](http:\/\/)Accuracy is %83.42 for RandomForest Regressor model with default parameters.. We should try to do parameter tuning to increase accuracy..","11ad80ef":"<a id=\"First_Model\"><\/a>\n>## 4.1 Time Series for US - with Prophet\nI use Prophet for time series because it provides intuitive parameters which are easy to tune..","98776b7c":"<a id=\"Introduction\"><\/a>\n# 1. Introduction\n\nKaggle describes this competition as [follows](https:\/\/www.kaggle.com\/c\/covid19-global-forecasting-week-5\/overview)\n\n**The Challenge**\n<br>Kaggle is launching a companion COVID-19 forecasting challenges to help answer a subset of the NASEM\/WHO questions. While the challenge involves developing quantile estimates intervals for confirmed cases and fatalities between May 12 and June 7 by region, the primary goal isn't only to produce accurate forecasts. It\u2019s also to identify factors that appear to impact the transmission rate of COVID-19.","c3b7c6c1":"**Below We see that TargetValue variable has negatif values at some point. But the number of cases must be at least 0..**","c6587b7f":"## The Story of COVID-19\n#### The COVID-19 pandemic is the defining global health crisis of our time and the greatest global humanitarian challenge the world has faced since World War II. The virus has spread widely, and the number of cases is rising daily as governments work to slow its spread. India has moved quickly, implementing a proactive, nationwide, lockdown, with the goal of flattening the curve and using the time to plan and resource responses adequately.","933497c1":"## Importing Libraries","96a19448":"![alt text](https:\/\/kesk.org.tr\/wp-content\/uploads\/2020\/04\/covid.png)","20d189de":"**Splitting Data - Train and Test**\n<br> We will try to predict the cases after 2020-05-12, we are spliting the dataset from here..","426df9aa":"# Table of Contents\n\n* [1. Introduction](#Introduction)\n* [2. Data Analysis](#Data_Analysis)\n* [3. Feature Engineering](#Feature_Engineering)\n* [4. Model Building](#Model_Building)\n    * [4.1. First Model](#First_Model)\n    * [4.2. Second Model](#Second_Model)\n    * [4.3. Third Model](#Third_Model)\n* [5. Model Comparing](#Model_Comparing)","41a50e95":"We see trend and weekly seasonality for train dataset..","391abd54":"XGBOOST Regressor Fit with GridSearch Parameters for cv data","4c1648a8":"When we look at the Actual-Prediction chart, we see that the model can catch the change-points, but the difference between the actual and the prediction increased after May.","6a64c40b":"We fit the model with best parameters..","0b1dffe4":"**Creating day of week variable from Date**","3598a5be":"### Parameter Tuning for RandomForest Regressor","32879537":"<a id=\"Data_Analysis\"><\/a>\n# 2. Data_Analysis","88d96166":"<a id=\"Model_Building\"><\/a>\n# 4. Model Building","2e87859c":"Accuracy is better with the best parameters","8e93c4da":"### When we look at the graph below, we see the top 3 country's behaviours. After May, the cases in US and Brazil increase while those in Russia decrease.","5083ba85":"Accuracy is better with the best parameters","5645299b":"<a id=\"Model_Comparing\"><\/a>\n## 5. Model Comparison for Confirmed Cases for US","2f37ebc3":"## Importing Data","e3e957c1":"**We merge the 3 countries with the highest number of cases in a single table..**","3e11e578":"### Creating Datetime Feautures","e875e508":"<a id=\"Third_Model\"><\/a>\n>## 4.3 US Confimed Case Forecasting with  XGBOOST Reggressor","20538033":"**Below We see that County and Province_State variable have null values..**","aaebef70":"Accuracy is %83 for XGBOOST Regressor model with default parameters.. We should try to do parameter tuning to increase accuracy..","3ea1f93a":"### Parameter Tuning for Prophet"}}