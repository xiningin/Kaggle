{"cell_type":{"4246ee2d":"code","6c1f37ec":"code","1d62a3be":"code","af1959e8":"code","bbe58602":"code","5abf15d2":"code","93ec3834":"code","04b014dc":"code","759f2615":"code","72b72f4a":"code","a394d8b0":"code","e28fc7bd":"code","0f68e226":"code","f622e031":"code","119030e9":"code","8c458837":"code","0b60e13d":"code","e7cd81e5":"code","d9fd83eb":"code","21a42c2e":"code","b9251993":"code","374c5a49":"code","6b4341ad":"code","834fd59b":"code","f01b4f11":"code","fdf27c80":"code","5a7b81b8":"code","a761425d":"code","b7b7127c":"code","92a28a09":"code","048fbbae":"code","3662a80e":"code","ae0532dd":"code","da2f312f":"code","c9c87c32":"code","217facb5":"code","c27780ec":"code","0d2a7b51":"code","1aebcfc5":"markdown","5c4a11c0":"markdown","ec288d5c":"markdown","35a5baf6":"markdown","13a14c86":"markdown","465ca29b":"markdown","e0437994":"markdown","b3363e01":"markdown","0e57db6b":"markdown","f6eea428":"markdown","1e49ee5c":"markdown","88ec4123":"markdown","976b4d4c":"markdown","67ba043a":"markdown","4e8e7a08":"markdown","d0286846":"markdown","e24b845a":"markdown","61126c8d":"markdown","dbcb29d1":"markdown","3e344590":"markdown","77911fbb":"markdown","195eeebb":"markdown","c36d1296":"markdown"},"source":{"4246ee2d":"import warnings  \nwarnings.filterwarnings('ignore')","6c1f37ec":"# Installing DVC\n! pip install dvc ","1d62a3be":"# Checking out DVC installation\n! dvc -h\n","af1959e8":"! mkdir get-started && cd get-started","bbe58602":"from pathlib import Path\nimport os\n\na = Path.cwd() \/ \"get-started\"\nos.chdir(a)","5abf15d2":"# Initialising git in our folder\n! git init","93ec3834":"# Run DVC initialization in a repository directory to create the DVC meta files and directories\n! dvc init","04b014dc":"# configuring git for user account\n! git config --global user.name \"kuranbenoy\" #Replace with your github username\n! git config --global user.email \"kurian.bkk@gmail.com\" #Replace with your email id\n# commit the initialised git files\n! git commit -m \"initialize DVC\"","759f2615":"! dvc remote add -d myremote \/tmp\/dvc-storage","72b72f4a":" ! git commit .dvc\/config -m \"initialize DVC local remote\"","a394d8b0":"# Download the data\n! mkdir data\/\n!  dvc get https:\/\/github.com\/iterative\/dataset-registry \\\n        get-started\/data.xml -o data\/data.xml","e28fc7bd":"# add file(directory) to DVC\n! dvc add data\/data.xml","0f68e226":"# add DVC files to git and update gitignore\n! git add data\/.gitignore data\/data.xml.dvc\n! git commit -m \"add source data to DVC\"","f622e031":"#  push them from your repository to the default remote storage*:\n! dvc push","119030e9":"! rm -f data\/data.xml","8c458837":"# Now your data returns back to repositary\n! dvc pull","0b60e13d":"# incase just to retrieve single dataset or file\n! dvc pull data\/data.xml.dvc","e7cd81e5":"# run these commands to get the sample code:\n! wget wget https:\/\/code.dvc.org\/get-started\/code.zip\n! unzip code.zip\n! rm -f code.zip","d9fd83eb":"# Create a pipeline to create  folder data\/prepared with files train.tsv and test.tsv\n! dvc run -f prepare.dvc \\\n          -d src\/prepare.py -d data\/data.xml \\\n          -o data\/prepared \\\n          python src\/prepare.py data\/data.xml","21a42c2e":"!  git add data\/.gitignore prepare.dvc\n!  git commit -m \"add data preparation stage\"","b9251993":"! dvc push","374c5a49":"# Lets create a second stage (after prepare.dvc, created in the previous chapter) to perform feature extraction\n! dvc run -f featurize.dvc \\\n          -d src\/featurization.py -d data\/prepared\/ \\\n          -o data\/features \\\n           python src\/featurization.py data\/prepared data\/features","6b4341ad":"# A third stage for training the model\n! dvc run -f train.dvc \\\n          -d src\/train.py -d data\/features \\\n          -o model.pkl \\\n          python src\/train.py data\/features model.pkl","834fd59b":"%%bash\ngit add data\/.gitignore .gitignore featurize.dvc train.dvc\ngit commit -m \"add featurization and train steps to the pipeline\"\ndvc push\n","f01b4f11":"! dvc pipeline show --ascii train.dvc ","fdf27c80":"! dvc run -f evaluate.dvc \\\n          -d src\/evaluate.py -d model.pkl -d data\/features \\\n          -M auc.metric \\\n          python src\/evaluate.py model.pkl \\\n                 data\/features auc.metric","5a7b81b8":"%%bash\ngit add evaluate.dvc auc.metric\ngit commit -m \"add evaluation step to the pipeline\"","a761425d":"! dvc push","b7b7127c":"# Tag as a checkpoint to cpmpare further experiments\n! git tag -a \"baseline-experiment\" -m \"baseline\"","92a28a09":"%%writefile src\/featurization.py\nimport os\nimport sys\nimport errno\nimport pandas as pd\nimport numpy as np\nimport scipy.sparse as sparse\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\n\ntry:\n    import cPickle as pickle\nexcept ImportError:\n    import pickle\n\nnp.set_printoptions(suppress=True)\n\nif len(sys.argv) != 3 and len(sys.argv) != 5:\n    sys.stderr.write('Arguments error. Usage:\\n')\n    sys.stderr.write('\\tpython featurization.py data-dir-path features-dir-path\\n')\n    sys.exit(1)\n\ntrain_input = os.path.join(sys.argv[1], 'train.tsv')\ntest_input = os.path.join(sys.argv[1], 'test.tsv')\ntrain_output = os.path.join(sys.argv[2], 'train.pkl')\ntest_output = os.path.join(sys.argv[2], 'test.pkl')\n\ntry:\n    reload(sys)\n    sys.setdefaultencoding('utf-8')\nexcept NameError:\n    pass\n\n\ndef mkdir_p(path):\n    try:\n        os.makedirs(path)\n    except OSError as exc:  # Python >2.5\n        if exc.errno == errno.EEXIST and os.path.isdir(path):\n            pass\n        else:\n            raise\n\n\ndef get_df(data):\n    df = pd.read_csv(\n        data,\n        encoding='utf-8',\n        header=None,\n        delimiter='\\t',\n        names=['id', 'label', 'text']\n    )\n    sys.stderr.write('The input data frame {} size is {}\\n'.format(data, df.shape))\n    return df\n\n\ndef save_matrix(df, matrix, output):\n    id_matrix = sparse.csr_matrix(df.id.astype(np.int64)).T\n    label_matrix = sparse.csr_matrix(df.label.astype(np.int64)).T\n\n    result = sparse.hstack([id_matrix, label_matrix, matrix], format='csr')\n\n    msg = 'The output matrix {} size is {} and data type is {}\\n'\n    sys.stderr.write(msg.format(output, result.shape, result.dtype))\n\n    with open(output, 'wb') as fd:\n        pickle.dump(result, fd, pickle.HIGHEST_PROTOCOL)\n    pass\n\n\nmkdir_p(sys.argv[2])\n\n# Generate train feature matrix\ndf_train = get_df(train_input)\ntrain_words = np.array(df_train.text.str.lower().values.astype('U'))\n\nbag_of_words = CountVectorizer(stop_words='english',\n                               max_features=5000,\n                              ngram_range=(1, 2),)\nbag_of_words.fit(train_words)\ntrain_words_binary_matrix = bag_of_words.transform(train_words)\ntfidf = TfidfTransformer(smooth_idf=False)\ntfidf.fit(train_words_binary_matrix)\ntrain_words_tfidf_matrix = tfidf.transform(train_words_binary_matrix)\n\nsave_matrix(df_train, train_words_tfidf_matrix, train_output)\n\n# Generate test feature matrix\ndf_test = get_df(test_input)\ntest_words = np.array(df_test.text.str.lower().values.astype('U'))\ntest_words_binary_matrix = bag_of_words.transform(test_words)\ntest_words_tfidf_matrix = tfidf.transform(test_words_binary_matrix)\n\nsave_matrix(df_test, test_words_tfidf_matrix, test_output)\n\n","048fbbae":"# Using DVC Repro here \n! dvc repro train.dvc\n","3662a80e":"! git commit -a -m \"bigram model\"","ae0532dd":"! git checkout baseline-experiment\n! dvc checkout","da2f312f":"%%bash\ngit checkout master\ndvc checkout\ndvc repro evaluate.dvc","c9c87c32":"%%bash\ngit commit -a -m \"evaluate bigram model\"\ngit tag -a \"bigram-experiment\" -m \"bigrams\"","217facb5":"! dvc metrics show -T","c27780ec":"! git checkout baseline-experiment train.dvc\n! dvc checkout train.dvc","0d2a7b51":"! git checkout baseline-experiment\n! dvc checkout","1aebcfc5":"References\n----------\n\n- https:\/\/dvc.org\/doc\/get-started\n- https:\/\/medium.com\/qonto-engineering\/using-dvc-to-create-an-efficient-version-control-system-for-data-projects-96efd94355fe","5c4a11c0":"## Metrics\n\nThe last stage we would like to add to our pipeline is its the evaluation. Data science is a metric-driven R&D-like process and `dvc metrics` along with DVC metric \nfiles provide a framework to capture and compare experiments performance.\n","ec288d5c":"> Please, refer to the [dvc metrics](https:\/\/dvc.org\/doc\/commands-reference\/metrics) command documentation to see more available options and details.","35a5baf6":"`evaluate.py` calculates AUC value using the test data set. It reads features from the `features\/test.pkl` file and produces a DVC metric file - `auc.metric`. It is a special DVC output file type, in this case it's just a plain text file with a single number inside.","13a14c86":"## Initialising NLP Project","465ca29b":"## Configuring DVC remotes\n\n\nA DVC remote is used to share your ML models and datasets with others. The various types of remotes DVC currently supports is:\nhttps:\/\/dvc.org\/doc\/get-started\/configure\n- `local` - Local directory\n- `s3` - Amazon Simple Storage Service\n- `gs` - Google Cloud Storage\n- `azure` - Azure Blob Storage\n- `ssh` - Secure Shell\n- `hdfs` - The Hadoop Distributed File System\n- `http` - Support for HTTP and HTTPS protocolbucks\n\n> Note we are using remote as a local directory as storage. **It's usually recommended to use Cloud storage services as DVC remote.**\n\n[More information](https:\/\/dvc.org\/doc\/get-started\/configure)","e0437994":"## Get older Data files\n\nThe answer is the `dvc checkout` command, and we already touched briefly the process of switching between different data versions in the Experiments step of this get started guide.","b3363e01":"## Downloading files\n\n","0e57db6b":"Stages are run using dvc run [command] and options among which we use:\n\n- d for dependency: specify an input file\n- o for output: specify an output file ignored by git and tracked by dvc\n- M for metric: specify an output file tracked by git\n- f for file: specify the name of the dvc file.\n- command: a bash command, mostly a python script invocation","f6eea428":"[more information](https:\/\/dvc.org\/doc\/get-started\/add-files)","1e49ee5c":"## fin.","88ec4123":"## Compare Expermiments\n\nDVC makes it easy to iterate on your project using Git commits with tags or Git branches. It provides a way to try different ideas, keep track of them, \nswitch back and forth. To find the best performing experiment or track the progress, a special metric output type is supported in \nDVC (described in one of the previous steps).","976b4d4c":"## Retrieving Data\n\nNow since we pushed our data, we are going to do the opposite of push ie `pull` similar to git analogy.\nAn easy way to test it is by removing currently downloaded data.","67ba043a":"Having installed the `src\/prepare.py` script in your repo, the following command\ntransforms it into a reproducible\n[stage](https:\/\/dvc.org\/doc\/user-guide\/dvc-files-and-directories) for the ML pipeline we're\nbuilding (described in detail [in the documentation](https:\/\/dvc.org\/doc\/get-started\/example-pipeline)).","4e8e7a08":"## Conncting with code\n\nFor providing full Machine Learning reproducibility. It is important to connect code with Datasets which are being reproducible by\nusing commands like `dvc add\/push\/pull`.\n\n","d0286846":"We are going to play with an actual Machine Learning scenario. It explores the NLP problem of predicting tags for a given StackOverflow\nquestion. For example, we want one classifier which can predict a post that is about the Python language by tagging it python.\n\nThis kernel has been made adopting [DVC get-Started tutorial](https:\/\/dvc.org\/doc\/get-started\/agenda) and full credit goes to DVC team for making that.\nA github repo for get-starter tutorial can be found [here](https:\/\/github.com\/iterative\/example-get-started).","e24b845a":"## Installing DVC\n\nInstalling DVC is very easy. There are mainly three recommended ways:\n- pip\n- OS-specific package managers\n- HomeBrew(for apple users)\n\n\nWe are going to install with `pip- Python package manger`. For other installation\nmethods checkout [here](https:\/\/dvc.org\/doc\/get-started\/install)","61126c8d":"We are modifying our feature extraction of our files. Inorder to use `bigrams`. We are increasing no of features and n_gram_range in our file `src\/featurization.py`.","dbcb29d1":"## Experiments\n\nData science process is inherently iterative and R&D like - data scientist may try many different approaches, different hyper-parameter values and \"fail\" \nmany times before the required level of a metric is achieved.","3e344590":"## Introduction to Data Version Control\n\n\n\nIn this kernel we are planning to introduce about Data Version Control which one of best open source tools available in the market for [Machine Learning\nModels and Dataset Versioning](https:\/\/dvc.org\/doc\/use-cases\/data-and-model-files-versioning) and [other amazing features](https:\/\/dvc.org\/features).\n\n![dvc.png](attachment:dvc.png)\n\n<br>\n<br>","77911fbb":"## Pipeline\n\nUsing `dvc run` multiple times, and specifying outputs of a command (stage) as dependencies in another one, we can describe a sequence of commands that gets to a desired result.\nThis is what we call a data pipeline or computational graph.\n\n","195eeebb":"## Pipelines Visualisation","c36d1296":"## Reproduce\n\nWe described our first pipeline. Basically, we created a number of DVC-file. Each file describes a single stage we need to run (a pipeline) towards a final result.\nEach depends on some data (either source data files or some intermediate results from another DVC-file file) and code files."}}