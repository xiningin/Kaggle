{"cell_type":{"242643cf":"code","3d4f8c4f":"code","da81d855":"code","10bbdaf0":"code","024d32a7":"code","46697fca":"code","c4f76fcd":"code","462f84e3":"code","7d20f373":"code","f26becd3":"code","6f8b6abf":"markdown","20d18a72":"markdown","167a0c87":"markdown","04e82be5":"markdown","0ccc6fb4":"markdown"},"source":{"242643cf":"!pip install '\/kaggle\/input\/mmdetectionv2140\/pycocotools-2.0.2\/pycocotools-2.0.2' --no-deps\n!pip install '\/kaggle\/input\/mmdetectionv2140\/mmpycocotools-12.0.3\/mmpycocotools-12.0.3' --no-deps","3d4f8c4f":"import sklearn\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport json\nimport glob\nimport pycocotools\nfrom pycocotools import mask\nimport random\nimport cv2\nimport re\nimport ast","da81d855":"train_df = pd.read_csv('..\/input\/tensorflow-great-barrier-reef\/train.csv')","10bbdaf0":"train_df","024d32a7":"output_json_dict = {\n    \"images\": [],\n    \"annotations\": [],\n    \"categories\": []\n}\ncategory_dict = {\"id\": 1, \"name\": \"starfish\", \"supercategory\": \"none\"}\noutput_json_dict[\"categories\"].append(category_dict)","46697fca":"annot_id = 0","c4f76fcd":"def get_boxes(row):\n    \"\"\"Return the bboxes for a given row as a 3D matrix \"\"\"\n    #if len(row['annotations']) == 0:\n    #    row['annotations'] = [{'x': -1, 'y': -1, 'width': -1, 'height': -1}]\n    return pd.DataFrame(row['annotations'], columns=['x', 'y', 'width', 'height']).astype(float).values","462f84e3":"for f in train_df.itertuples():\n    img_path = '..\/input\/tensorflow-great-barrier-reef\/train_images\/video_' + str(f[1]) + '\/' + f[5].split('-')[1] + '.jpg'\n    img = cv2.imread(img_path)\n    height, width, channels = img.shape\n\n    img_info = {\n        \"id\": f[0],\n        \"width\": width,\n        \"height\": height,\n        \"file_name\": img_path\n    }\n    output_json_dict[\"images\"].append(img_info)\n    if f[6] != '[]':\n#         print(train_df.iloc[f[0]]['annotations'])\n        bbox_list = ast.literal_eval(f[6])\n        for bbox in bbox_list:\n#             bbox = ast.literal_eval(bbox)\n            if bbox['height'] + bbox['y'] > 720:\n                bbox['height'] = 720 - bbox['y']\n            annot = {\n                \"category_id\": 1,\n                \"bbox\": [bbox['x'], bbox['y'], bbox['width'], bbox['height']],\n                \"id\": annot_id,\n                \"image_id\": f[0],\n                \"area\": bbox['width'] * bbox['height'],\n                \"segmentation\": [],\n                \"iscrowd\": 0\n            }\n            output_json_dict[\"annotations\"].append(annot)\n            annot_id += 1","7d20f373":"output_json_dict['annotations'][0]","f26becd3":"with open('train_dataset.json', 'w') as f:\n    output_json = json.dumps(output_json_dict)\n    f.write(output_json)","6f8b6abf":"# **Import Libraries**","20d18a72":"# **References**","167a0c87":"# **Create Coco Json File**","04e82be5":"https:\/\/www.kaggle.com\/julian3833\/reef-starter-torch-fasterrcnn-train-lb-0-361\n\nhttps:\/\/www.kaggle.com\/rhythmcam\/ast-basic-string-expression\n\nhttps:\/\/www.kaggle.com\/vexxingbanana\/sartorius-coco-dataset-notebook","0ccc6fb4":"# **Install Pycocotools**"}}