{"cell_type":{"906e5917":"code","3c410d8b":"code","2e10b2df":"code","97db0f42":"code","0d7c39a7":"code","5f4b3fa9":"code","b4dfd980":"markdown","733e637b":"markdown","f152e225":"markdown","14b541f2":"markdown","45f7e7fe":"markdown","d80643f6":"markdown","99948e82":"markdown","03d018bb":"markdown"},"source":{"906e5917":"# Import the pandas package\nimport pandas as pd","3c410d8b":"# Read the CSV File stored in your file destination\n# Remember to download the csv file and replace the file location in order to read in your csv\ndf = pd.read_csv('..\/input\/train.csv')","2e10b2df":"# Run and test the functions here:\ndf.head()\n\n","97db0f42":"# Run and test the functions here:\ndf.isnull().sum()\n\n","0d7c39a7":"# Run and test the functions here:\ndf['Age']\n\n","5f4b3fa9":"# Run and test the functions here:\ndf[df['Age'] < 2]\n","b4dfd980":"# 6. Combining Datasets\n***\n\n### Objective\n\nHere are some common functions that allows you to combine multiple datasets easily!\n\n### Functions\n\n- **df1.append(df2)** \u2014 add the rows in df1 to the end of df2 (columns should be identical)\n- **df.concat([df1, df2],axis=1)**\u200a\u2014\u200aadd the columns in df1 to the end of df2 (rows should be identical)\n- **df1.join(df2,on=col1,how='inner')**\u200a\u2014\u200aSQL-style join the columns in df1 with the columns on df2 where the rows for colhave identical values. how can be equal to one of: 'left', 'right', 'outer', 'inner'\n","733e637b":"# Let's Connect!\n***\n## This is still a work in progress!\n\nIf anybody would like to discuss any other projects or just have a chat about data science topics, I'll be more than happy to connect with you on:\n\n**LinkedIn**: https:\/\/www.linkedin.com\/in\/randylaosat\/\n\n**My Website**: http:\/\/claoudml.co","f152e225":"# 4. Selecting \/ Subsetting Data\n***\n\n### Summary\n\nPandas is great for selecting certain columns or rows within your DataFrame. Let's see the various ways we can do this!\n\n\n### Functions\n\n\n- **df[['col_name1','col_name2','col_name3']]** \u2014 Creates a new DataFrame by extracting certain column names\n- **df['col_name1']** \u2014 Creates a new DataFrame that selects a single column name\n- **df['col_name1'].unique()** \u2014 Creates an arraylist containing the unique values of a column \n\n### Select by Loc \n**How it works:** loc works on labels in the index.\n- **df.loc[ :, 'col_name1':'col_name2']** \u2014 Creates a new DataFrame that only includes columms 1-3\n\n### Select by iLoc\n**How it works:** iloc works on the positions in the index (so it only takes integers).\n\n- **df.iloc[ :, [1,2,3]]** \u2014 Creates a new DataFrame that only includes columns 1-3\n","14b541f2":"# 3. Manipulating \/ Cleaning Data\n***\n<img src=\"https:\/\/i.imgur.com\/bhKeU4P.gif\"\/>\n\n### Objective\n\nClean up on column 5! When your data is dirty, your job as a Data Scientist is to clean it up! \n\nSome common tasks are to understand every feature you're working with, identify errors, missing values, and corrupt records. \n\nCleaning the data involves you to throw away, replace, and\/or fill missing values\/errors\n\n\n### Functions\n- **df.isnull().sum()** \u2014 Used to display the total amount of missing values in your columns\n- **df.columns** \u2014 Displays a list of your column names\n- **df.columns = ['col_name1','col_name2','col_name3']** \u2014 Allows you to replace your columns with a new name\n- **df.rename(columns={'old_name1':'new_name1', 'old_name2':'new_name2'})** \u2014 Allows you to rename certain columns directly\n- **df.fillna(x)** \u2014 Repalces every null value in your table with x (could be a string value or numeric value)\n","45f7e7fe":"# 2. Summarizing Data (Statistics)\n***\n### Objective\n\nYou cannot do anything as a data scientist without even having any data! So now you've loaded your dataset and now you want to examine it. What headers and values does your data frame have? How big is my data set? What summary can be displayed? Some really handy Pandas functions can help you solve these problems!\n\nThese functions are the most common tools used when trying to summarize your data\n\n### Functions\n\n- **df.head(n)** \u2014 Returns the first n rows of your DataFrame. Having a blank argument will display the first 5 by default\n- **df.tail(n)** \u2014 Returns the last n rows of your DataFrame. Having a blank argument will display the last 5 by default\n- **df.shape()** \u2014 Displays the number of rows and columns in your DataFrame\n- **df.describe()** \u2014 Dispalys a statistical summary for numerical columns\n- **df.describe(include=['object'])** \u2014  Displays a statistical summary for all object (string) columns\n- **df.describe(include='all')**  \u2014  Displays a statistical summary for all columns\n- **df.mean()** \u2014 Returns the mean of all columns\n- **df.median()** \u2014 Returns the median of all columns\n- **df.std()** \u2014 Returns the standard deviation of all columns\n- **df.max()** \u2014 Returns the highest value in each column\n- **df.min()** \u2014 Returns the lowest value in each column\n- **df.dtypes** - Returns the data types of each colulmn\n","d80643f6":"# Final Note\n***\n\nThese are the very basic Pandas commands but I hope you can see how powerful Pandas can be for data analysis. \n\nThis post is just the tip of the iceberg\u200a\u2014\u200aafter all, entire books can be (and have been) written about data analysis with Pandas. \n\nI also hope this notebook made you feel like taking a dataset and **PLAYING** around with it using Pandas! :)\n\n<img src=\"http:\/\/img1.liveinternet.ru\/images\/attach\/c\/3\/76\/786\/76786793_pandaDONE.gif\"\/>\n","99948e82":"# Reference Guide: Teach Me How To Pandas\n***\n<img src=\"https:\/\/s-media-cache-ak0.pinimg.com\/originals\/7e\/cc\/a7\/7ecca73c35701df2708c43d0c9f40ada.png\"\/>\n<img src=\"https:\/\/a.disquscdn.com\/get?url=https%3A%2F%2Fmedia.giphy.com%2Fmedia%2FIU5ApmC4e6wEw%2Fgiphy.gif&key=yOhwdV8VW_y07hJuhGmfZQ\"\/>\n\n# Background\n***\n\n### \"Hey, can you teach me how to Pandas?\" \n\nSay no more friends! Today we're going to learn the Pandas library. Pandas stands for \u201cPython Data Analysis Library\u201d. According to the Wikipedia page on Pandas, \u201cthe name is derived from the term \u201cpanel data\u201d, an econometrics term for multidimensional structured data sets.\u201d \n\n### Why Pandas\n\nPandas is one of the most powerful data manipulation tools out there but when a data scientist can leverage the power of indexing to his advantage, it makes pandas the best data manipulation tool out there!\n\n- Pandas is a game changer when analyzing data with Python\n- It's a python module that makes data science easy and effective\n- It's one of the most preferred and widely used tools in data manipulation if not **THE** most used one\n- Pandas is an open source package and is **FREE** to use\n\n### DataFrame Basics\n\n*Dataframe* is a main object in Pandas. What\u2019s cool about Pandas is that it takes data (like a CSV or JSON file, or a SQL database) and creates a Python object with **rows** and **columns**. It is used to reprsent data with rows and columns (tabular or excel spreadsheet like data). \n\n\n*Reference*: https:\/\/towardsdatascience.com\/a-quick-introduction-to-the-pandas-python-library-f1b678f34673\n\n# Pandas Main Concepts & Exercises\n***\n\n<img src=\"https:\/\/data.whicdn.com\/images\/109402725\/original.gif\"\/>\n\n## 6 Parts of Pandas\n1. Importing Data and Reading Data\n2. Summarizing Data (Statistics)  \n3. Manipulating Data \/ Cleaning Data\n4. Selecting Data \/ Subsetting Data\n5. Grouping and Filtering Data\n6. Combining Datasets\n\n<img src=\"https:\/\/pbs.twimg.com\/media\/C65MaMpVwAA3v0A.jpg\"\/>\n\n\n# 1. Importing Data and Reading Data\n***\n\n### Summary\n\nDon't make things complicated. This is literally a two step process! \n\nYou import the Pandas library and then you use it's **read_csv()** function to read your files :-)\n\n**Note:** We'll be working with the Titanic Dataset\n","03d018bb":"# 5. Grouping and Filtering Data\n***\n\n### Objective\n\nGrouping and Filtering plays an important role in data manipulation. Luckily, the Pandas library provides you really simple, but powerful, functions that allows you to do just that. Here's the main functions that you should be comfortable with:\n\n### Filtering\n\nYou can use different conditions to filter columns. For example, df[df[year] > 1984] would give you only the column year is greater than 1984. You can use & (and) or | (or) to add different conditions to your filtering. These is also called boolean filtering.\n\n- **df[df['col_name1'] == 'value']** \u2014 Select a value from this list and create a new DataFrame that only matches the condition\n- **df.loc[df['col_name1' > 10] , ['col_name1','col_name2','col_name3']]** \u2014 Select columns 1-3 from the DataFrame that meets the condition\n\n### Sorting\n\n- **df.sort_values('col_name1')** \u2014 Sorts the values in a certain column in ascending order\n- **df.sort_values('col_name1', ascending=False)** \u2014 Sorts the values in a certain column in descending order\n\n### Grouping\nGrouping involves splitting the data into groups based on some criteria, applying a function to each group independently and combining the results into a data structure.\n\n- **df.groupby('col_name1')** \u2014 Returns a groupby object for values from one column\n- **df.groupby(['col_name1' , 'col_name2'])** \u2014 Returns a groupby object for values from multiple columns\n"}}