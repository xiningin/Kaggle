{"cell_type":{"ebdd2f07":"code","3b7f216c":"code","dbaafb97":"code","ff5532e0":"code","c70db7e9":"code","7cbd17e1":"code","1f8532e8":"code","a6fb0b78":"code","ade6c78d":"code","ec4bd510":"code","f27a929f":"code","97dfe91f":"code","d6942546":"code","1079c8d9":"code","2c060630":"code","0d7dbd31":"markdown","19bc1755":"markdown","1aa7b629":"markdown","32c4e814":"markdown","32a67b31":"markdown","b55f33db":"markdown","658746e1":"markdown","928123b5":"markdown","e2326f82":"markdown","580b03e7":"markdown"},"source":{"ebdd2f07":"from sklearn.datasets import load_breast_cancer\nimport numpy as np","3b7f216c":"bc = load_breast_cancer()\n\ndata = bc.data\ntarget = bc.target","dbaafb97":"print(\"Formato dos dados (linhas x colunas) => \", data.shape)\nprint(\"Labels do problema => \", np.unique(target))","ff5532e0":"from sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score","c70db7e9":"# separando os dados em treino e teste\nX_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=42)","7cbd17e1":"knn = KNeighborsClassifier(n_neighbors=8)\nknn.fit(X_train, y_train)","1f8532e8":"probas = knn.predict_proba(X_test)\nprint(probas)","a6fb0b78":"probas[:,1]","ade6c78d":"from sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\n\nfpr, tpr, thresholds = roc_curve(y_test, probas[:,1])\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize = (10, 5))\n\nplt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Aleat\u00f3rio')\nplt.plot(fpr, tpr, lw=1, label='ROC (area = %0.2f)' % roc_auc)\nplt.plot(fpr, tpr, 'ro', label='Thresholds')\n\nplt.xlim([-0.05, 1.05])\nplt.ylim([-0.05, 1.05])\nplt.xlabel('Falsos Positivos', fontsize = 15)\nplt.ylabel('Positivos Verdadeiros', fontsize = 15)\nplt.title('ROC do KNN', fontsize = 20)\nplt.legend(loc=\"lower right\", prop={'size': 15})\nplt.show()\n","ec4bd510":"for tp, fp, t in zip(tpr, fpr, thresholds):\n    print('tp = %.2f, fp = %.2f, t=%.2f' % (tp, fp, t))","f27a929f":"from statsmodels.stats.contingency_tables import mcnemar","97dfe91f":"def build_contingence_table(Y, Y_pred_1, Y_pred_2):\n    y1_and_y2 = 0\n    y1_and_not_y2 = 0\n    y2_and_not_y1 = 0\n    not_y1_and_not_y2 = 0\n    for y, y1, y2 in zip(Y, Y_pred_1, Y_pred_2):\n        if y == y1 == y2:\n            y1_and_y2 += 1\n        elif y != y1 and y != y2:\n            not_y1_and_not_y2 += 1\n        elif y == y1 and y != y2:\n            y1_and_not_y2 += 1\n        elif y != y1 and y == y2:\n            y2_and_not_y1 += 1\n            \n    contingency_table = [[y1_and_y2, y1_and_not_y2], \n                         [y2_and_not_y1, not_y1_and_not_y2]]\n    \n    return contingency_table","d6942546":"knn2 = KNeighborsClassifier(n_neighbors=2)\nknn2.fit(X_train, y_train)\n\nknn3 = KNeighborsClassifier(n_neighbors=3)\nknn3.fit(X_train, y_train)\n\ny_pred2 = knn2.predict(X_test)\ny_pred3 = knn3.predict(X_test)","1079c8d9":"contingence_table = build_contingence_table(y_test, y_pred2, y_pred3)\n\nimport pprint\n\npprint.pprint(contingence_table)","2c060630":"result = mcnemar(contingence_table)\n    \n    \nif result.pvalue >= 0.001:\n    print('statistic=%.3f, p-value=%.3f' % (result.statistic, result.pvalue))\nelse:\n    print('statistic=%.3f, p-value=%.3e' % (result.statistic, result.pvalue))\n\n# interpretando o p-value\nalpha = 0.05\nif result.pvalue > alpha:\n    print('Mesma propor\u00e7\u00e3o de erros (falhou em rejeitar H0)')\nelse:\n    print('Propor\u00e7\u00f5es de erros diferentes (rejeitou H0)')","0d7dbd31":"(1) Plote o ROC do resultado para k=3 e k=10","19bc1755":"Vamos criar uma divis\u00e3o dos dados em treino e teste para analisar nosso m\u00e9todo de classifica\u00e7\u00e3o atrav\u00e9s de algumas m\u00e9tricas. Para isso, considere a divis\u00e3o de 33% para teste e o m\u00e9todo de classifica\u00e7\u00e3o k-NN.","1aa7b629":"**Curva ROC (Receiving Operating Characteristic)**\n\nUm modelo classificador bin\u00e1rio geralmente retorna o n\u00edvel de confian\u00e7a que o resultado retornado realmente seja de uma determinada classe - variando de 0 a 1,0. Mas a partir de qual n\u00edvel de confian\u00e7a pode-se obter o melhor resultado do classificador? Devemos simplesmente considerar que se o n\u00edvel de confian\u00e7a for > 0.50 ent\u00e3o a classe \u00e9 1, sen\u00e3o a classe \u00e9 0?\n\nNa curva ROC plotamos as taxas de verdadeiros positivos e falsos positivos para cada threshold utilizado. A \u00e1rea sob a curva (Area Under de Curve - AUC) fornece uma boa avalia\u00e7\u00e3o sobre a performance do modelo, mesmo que se utilize outros thresholds.","32c4e814":"# Exerc\u00edcios","32a67b31":"***Teste Estat\u00edstico de McNemmar***\n\nEste teste permite verificar se dois modelos possuem a mesma propor\u00e7\u00e3o de erros.\n\nTemos nossa hip\u00f3tese nula H0: dois modelos possuem a mesma propor\u00e7\u00e3o de erros.\n\n- Se essa hip\u00f3tese for rejeitada, temos que os dois modelos apresentam propor\u00e7\u00f5es de erro diferentes, logo eles s\u00e3o estatisticamente diferentes (o melhor \u00e9 o que apresentar melhores resultados, de acordo com outras m\u00e9tricas)\n- Se falharmos em rejeitar essa hip\u00f3tese, ent\u00e3o n\u00e3o \u00e9 poss\u00edvel afirmar que os modelos tem resultados diferentes.\n\nPrimeiro precisamos montar a matriz de conting\u00eancia.","b55f33db":"As m\u00e9tricas de desempenho auxiliam a entender como um determinado algoritmo de aprendizado de m\u00e1quina se comporta ao identificar padr\u00f5es de um conjunto de dados. Nem sempre identificar apenas a acur\u00e1cia em um problema \u00e9 suficiente. Muitas vezes \u00e9 necess\u00e1rio identificar se a classe cr\u00edtica de um problema (quando houver) est\u00e1 sendo considerada na escolha de um modelo.\n\n**Reflex\u00e3o:**\n\nVamos supor que voc\u00ea trabalha em uma grande empresa de an\u00e1lise de imagens m\u00e9dicas. O seu projeto atual \u00e9 identificar a ocorr\u00eancia de les\u00f5es no globo ocular, devido a diabetes.\n\nO que ser\u00e1 mais desastroso?\n\n* Acusar que um paciente ir\u00e1 precisar do parecer de um m\u00e9dico especialista, quando na verdade a sa\u00fade ocular do paciente est\u00e1 bem.\n* Acusar que um paciente j\u00e1 com a presen\u00e7a de les\u00f5es est\u00e1 sem problemas, e libera-lo. Ser\u00e1 que na pr\u00f3xima consulta as les\u00f5es j\u00e1 n\u00e3o estar\u00e3o muito mais avan\u00e7adas e dif\u00edceis de serem tratadas?","658746e1":"# Curva ROC e Teste Estat\u00edstico de McNemmar","928123b5":"(2) Use o teste de McNemmar e responda: Comparando todos os modelos treinados com k=2 at\u00e9 k=10, quais pares de modelos apresentam resultados estatisticamente diferentes?","e2326f82":"Ap\u00f3s o treinamento, as m\u00e9tricas de desempenho s\u00e3o obtidas ao analisar amostra por amostra a rela\u00e7\u00e3o entre a label conhecida (y_train ou y_test) e a label predita (y_pred) pelo m\u00e9todo de classifica\u00e7\u00e3o. Para identificar a acur\u00e1cia, basta encontrar a rela\u00e7\u00e3o de r\u00f3tulos corretamente predizidos.","580b03e7":"Utilizando o conjunto de dados de c\u00e3ncer de mama, o objetivo deste notebook \u00e9 avaliar as m\u00e9tricas de desempenho, utilizando a Curva ROC (Receiving Operating Characteristic). Considere os mesmos passos iniciais executados no notebook anterior."}}