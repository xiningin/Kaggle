{"cell_type":{"461e4b9f":"code","c1d0e5fe":"code","7a20da3d":"code","6f0a12cf":"code","c270e794":"code","dc704d79":"code","9326627d":"code","f3af9d0c":"code","1c1515bb":"code","58c18d1f":"code","8f414bac":"code","4ff5482e":"code","e450359d":"code","7745e91e":"code","b2861fc1":"code","25e26d71":"code","a33d244c":"code","890fcb0a":"code","8da5181e":"code","6b1a4f31":"code","70ef519a":"code","419e09b4":"markdown","b51cb7ee":"markdown","8c070a7f":"markdown","3955f12f":"markdown","7bf51d61":"markdown","dfef03bc":"markdown","76d5557d":"markdown","c22cfaf9":"markdown","93242526":"markdown","0355b34b":"markdown","6f92678a":"markdown","e853fd26":"markdown","a09a550f":"markdown","0f6fb746":"markdown","dd620d8b":"markdown","187d3c25":"markdown","ab84b566":"markdown","d7708783":"markdown","6b6b0f2b":"markdown","823231c4":"markdown","eadc0170":"markdown","b745b102":"markdown","44bfd996":"markdown","2712e35d":"markdown","86f17dfd":"markdown","6929def9":"markdown","666f4413":"markdown"},"source":{"461e4b9f":"import warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport pandas as pd\nimport cv2\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim import Adam\nfrom torchvision import transforms\nimport torch.nn.functional as F\n\nfrom sklearn.model_selection import train_test_split","c1d0e5fe":"PATH = '..\/input\/digit-recognizer\/'\nTRAIN_PATH = PATH + 'train.csv'\nTEST_PATH = PATH + 'test.csv'","7a20da3d":"train_df = pd.read_csv(TRAIN_PATH)\ntest_df = pd.read_csv(TEST_PATH)\n\ndisplay(train_df.head())\ndisplay(test_df.head())","6f0a12cf":"train_pixels = train_df[train_df.columns[1:]].values\ntest_pixels = test_df[test_df.columns[:]].values\ntrain_labels = train_df['label'].values\nprint('Shape of sample data before Reshaping : ',train_pixels[0].shape)\n\n\n\"\"\" Converting vector of shape 784 to matrix of shape 28*28 \"\"\"\ntrain_images = np.array([x.reshape(28,28) for x in train_pixels])\ntest_images = np.array([y.reshape(28,28) for y in test_pixels])\n\nprint('Shape of sample data after Reshaping : ',np.shape(train_images[0]))\n","c270e794":"def display_images():\n    rows, col = 2, 5\n    #rows, col = 2, 2\n    fig = plt.figure(figsize=(15,7))\n    for index in range(10):\n        ax = fig.add_subplot(rows, col, index+1)\n        ax.imshow(train_images[index])\n        ax.set_title(train_labels[index])\n        ax.axis('off')\n        \n    plt.show()\n    \ndisplay_images()","dc704d79":"px.bar(pd.Series(train_labels).value_counts().reset_index(name='Digit'))","9326627d":"train_images, test_images, train_labels, test_labels = train_test_split(train_images, train_labels,\n                                                                       test_size=0.2, stratify = train_labels, random_state=101)\nprint('Distribution of Numbers in Train Sample')\nprint(pd.Series(train_labels).value_counts())\n\nprint(\"\")\nprint('Distribution of Numbers in Test Sample')\nprint(pd.Series(test_labels).value_counts())","f3af9d0c":"class CreateDataset(Dataset):\n    def __init__(self, X, y, transform=None):\n        self.X = X\n        self.y = y\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, idx):\n        inp = self.X[idx].astype(np.float32)\n        out = self.y[idx]\n        \n        if self.transform:\n            inp = self.transform(inp)\n        \n        return inp,out","1c1515bb":"t = transforms.Compose([transforms.ToTensor(),\n                                transforms.Normalize((0.1307), (0.3081))])\n\ntrain_dataset = CreateDataset(train_images, train_labels, transform=t)\ntrain_loader = DataLoader(train_dataset, shuffle=True , batch_size=100) ## num_workers\n\ntest_dataset = CreateDataset(test_images, test_labels, transform=t)\ntest_loader = DataLoader(test_dataset, shuffle=True , batch_size=100)","58c18d1f":"class Net(nn.Module):\n    def __init__(self, num_classes=10):\n        super(Net, self).__init__()\n        # Inchannel = 1, for B&W images, 3 for RGB, out_channels is of our choice\n        self.conv1 = nn.Conv2d(in_channels=1,out_channels=32,kernel_size=3) \n        # Out channel from above is used as in channel in below conv layer\n        self.conv2 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3)\n        \n        self.pool = nn.MaxPool2d(2,2)\n        self.relu = nn.ReLU()\n        \n        self.fc1 = nn.Linear(1600, 100)\n        self.fc2 = nn.Linear(100, 10)\n        #self.drop = nn.Dropout2d()\n        #self.softmax = nn.Softmax(dim=1)\n        \n    def forward(self, x):\n        x = self.relu(self.pool(self.conv1(x)))\n        x = self.relu(self.pool(self.conv2(x)))\n        \n        x = x.view(100,-1)\n        x = self.relu(self.fc1(x))\n        #x = self.drop(x)\n        x = self.fc2(x)\n        return F.log_softmax(x)\n                ","8f414bac":"EPOCHS = 15\nnet = Net()\ncriterion = nn.CrossEntropyLoss()\noptimizer = Adam(net.parameters(), lr=0.001)        ","4ff5482e":"for epoch in range(EPOCHS):\n    net.train()\n    for data in train_loader:\n        # Get inputs\n        X_train, y_train = data\n        # Zero the parameter gradients\n        optimizer.zero_grad()\n        \n        #Forward + backward + optimize\n        y_pred = net(X_train)\n        y_pred = y_pred.squeeze(0)\n\n        train_loss = criterion(y_pred, y_train)\n        train_loss.backward()\n        optimizer.step()\n    print(f\"Epoch :{epoch+1}, Train Loss = {train_loss.item()}\")","e450359d":"correct, total = 0, 0\n\npred_probabs = []\npred_y = []\ntest_y = []\ntest_x = []\nnet.eval()\n\nfor data in test_loader:\n    X_test, y_test = data\n    output = net(X_test)\n    _, predicted = torch.max(output.data,1)\n    total += y_test.size(0)\n    correct += (predicted == y_test).sum().item()\n    \n    pred_probabs.append(output)\n    test_x.append(X_test)\n    pred_y.append(predicted)\n    test_y.append(y_test)\n\nprint('Test Accuracy : ',100*correct\/total)\n","7745e91e":"pred_y = np.array([x.cpu().detach().numpy() for x in pred_y])\n\ntest_y = np.array([x.cpu().detach().numpy() for x in test_y])\n\ntest_x = np.array([x.cpu().detach().numpy() for x in test_x])\n\npred_probabs = np.array([x.cpu().detach().numpy() for x in pred_probabs])\n\n\n'''Reshaping the arrays as they are present in batch format'''\npred_y = pred_y.reshape(-1)\ntest_y = test_y.reshape(-1)\ntest_x = test_x.reshape(8400,28,28)\npred_probabs = pred_probabs.reshape(8400,10)","b2861fc1":"pred_df = pd.DataFrame(zip(pred_y, test_y), columns=['Test','Pred'])","25e26d71":"def display_images():\n    rows, col = 4, 5\n    #rows, col = 2, 2\n    fig = plt.figure(figsize=(15,7))\n    for index in range(20):\n        ax = fig.add_subplot(rows, col, index+1)\n        ax.imshow(test_x[index])\n        ax.set_title(pred_y[index])\n        ax.axis('off')\n        \n    plt.show()\n    \ndisplay_images()","a33d244c":"_ = plt.figure(figsize=(10,5))\n_ = sns.lineplot(data=pred_df, x='Test', y='Pred')","890fcb0a":"pred_df[pred_df['Test'] != pred_df['Pred']]","8da5181e":"df = pd.DataFrame(pred_df[pred_df['Test'] != pred_df['Pred']]['Test'].value_counts().reset_index())\ndf.columns = ['Number','Wrong Prediction Count']\ndisplay(df)\npx.bar(pred_df[pred_df['Test'] != pred_df['Pred']]['Test'].value_counts())","6b1a4f31":"# Output Probabilities of First Four samples\n# Exp is used as the pred_prob was an output of log_softmax, \n# hence reversing\/ using anti log \nnp.round(np.exp(pred_probabs[:4]), decimals=4)","70ef519a":"plt.figure(figsize=(14,20))\n\n\nfor i in range(4):\n    plt.subplot(4,2,2*i+1)\n    plt.imshow(test_x[i+10])\n    plt.title(\"\") \n    plt.xlabel(\"\") \n    plt.ylabel(\"\") \n    plt.xticks([]) \n    plt.yticks([])\n\n    plt.subplot(4,2,2*i+2)\n    sns.barplot(x=[0,1,2,3,4,5,6,7,8,9],y=np.round(np.exp(pred_probabs[i+10]), decimals=4)) \n    plt.title(\"Pred Proba\", fontsize=16) \n    plt.xlabel(\"Number\", fontsize=16) \n    plt.ylabel(\"Prob\", fontsize=16) \n    plt.xticks(fontsize=14)\n\nplt.subplots_adjust(hspace = 0.6, wspace = 0.1)\n\nplt.show()","419e09b4":"<center> We have used stratified Sampling strategy on labels, <br>Numbers are evenly distributed in bot Training and Test samples","b51cb7ee":"<center><h3> Creating Training & Test Samples","8c070a7f":"<center><h3> Creating Datasets(Tensors) for PyTorch<\/h3><\/center>\n<br>\n    <ol>\n    <li>We will be transforming our individual input sample before sending for training.\n        <ul>\n            <li> Normalizing pixels- We have only one Channel(B&W), so we will use normalize Height and Width using (value),(value)\n                Incase of RGB(3 channels), our normalizing values would be (r_heig,g_heigh,b_heigh),(r_width,g_width,b_width)\n         <li>  To_Tensor - This will convert the images to Tesnor Values and will a new dimension to value. Shape - (1,28,28)     \n        <\/ul>\n        <li> Batching - In the Data_loader library we will use batch size of 100 samples to be passed so that the weigths are updated for 100 sample at the same time\n            After Batching, the input tensor size would be (100,1,28,28)\n            100 is the batch size, 1 is the number of channels(Black & white)\n            28*28 is the height and widht of each image\n    <\/ol>\n    \n    One mental anchor we have when feeding tensors into convolutional is that the first dimension is always batch size (N).\n    It\u2019s important to know how PyTorch expects its tensors to be shaped\u2014 because you might be perfectly satisfied that your 28 x 28 pixel image shows up as a tensor of torch.Size([28, 28]). \n    Whereas PyTorch on the other hand, thinks you want it to be looking at your 28 batches of 28 feature vectors. \n    \n    >>> torch.Size([16, 3, 28, 28])\n    # 4d: [batch_size, channels, height, width]\n    # use for nn.Conv2d() input.\n    \n    So, if you wanted to load a grey scale, 28 x 28 pixel image into a Conv2d network layer, \n    find the layer type in the example above. \n    Since it wants a 4d tensor, and you already have a 2d tensor with height and width, just add batch_size, and channels to pad out the extra dimensions, like so: [1, 1, 28, 28].","3955f12f":"<center><h3> Converting Tensor(GPU) data into Numpy Arrays ","7bf51d61":"<center><h3> Predicted Softmax Probabilities","dfef03bc":"<center> <h3>Test Labels vs Predicted Labels","76d5557d":"<center><h2>Importing Libraries<\/h2><\/center>","c22cfaf9":"<center><h3> Distribution of Numbers that were predicted wrong\n    <\/h3><\/center>\n   <center> Number VS Count of wrong predictions","93242526":"<center><h3>Creating Network<\/center>","0355b34b":"<center><h2>Loading Data<\/h2><\/center>","6f92678a":"    x.cpu() will do nothing at all if your Tensor is \n    already on the cpu and otherwise create a new Tensor on the cpu with the same content as x.\n\n    y = x.detach() breaks the graph between x and y. \n    But y will actually be a view into x and share memory with it.","e853fd26":"<center><h3>Function to Display Images & Labels<\/center>","a09a550f":"<center><h3> Samples that were predicted wrongly","0f6fb746":"<center>Reading Train & Test csv files<\/center>","dd620d8b":"<center><h3> Plotting Predicted outputs","187d3c25":"<center><h3>Distribution of Numbers in the Dataset<center>","ab84b566":"<center> <h3>Evaluation","d7708783":"    Use view() to change your tensor\u2019s dimensions.\n    image = image.view(batch_size, -1)\n    You supply your batch_size as the first number, and then \u201c-1\u201d basically tells Pytorch, \n    \u201cyou figure out this other number for me\u2026 please.\u201d \n    Your tensor will now feed properly into any linear layer\n\nsoftmax:\nexp(x_i) \/ exp(x).sum()\n\nlog_softmax:\nlog( exp(x_i) \/ exp(x).sum() )","6b6b0f2b":"<center> <h3> Some Parameters, loss, optimizer","823231c4":"<h1 style=\"font-family:verdana;\"> <center>\ud83d\udcda Introduction \ud83d\udcda<\/center> <\/h1>\n\n***\n![image.png](attachment:image.png)\n<br>\n<br>\n\n<div class=\"alert alert-block alert-info\" style=\"font-size:15px; font-family:verdana; line-height: 1.4em;\">\n    <center>\n        <span style=\"color:crimson;\">\ud83d\udcccClassification of Numbers(MNIST)<\/span> \n       <br> \n  \n\n\n<br>\n \nIn this kernel, we will visualize the MNIST dataset using Matplotlib and Plotly. This is a classic Machine Learning Problem, I will demonstrate how this problem can be approached using PyTorch Library. \n    <\/center> \n<\/div>\n\n***","eadc0170":"<center><h3>Merging pixel columns & Reshaping to 2D Matrix<\/h3><\/center>","b745b102":"The accuracy (98%) is so high that the test and pred labels form a straight line at 45 degrees","44bfd996":"<center>\nWe have almost even distribution of all the numbers, <br>the samples are sufficient for Spliting data into Train & Test samples","2712e35d":"The Probabilities of above samples are one, which means that our model was not confused even a littled for above samples","86f17dfd":"<center><h3> Training Model","6929def9":"<center> Defining Paths <\/center>","666f4413":"![image.png](attachment:image.png)"}}