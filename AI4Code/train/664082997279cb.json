{"cell_type":{"fef060bf":"code","8e3fb8ab":"code","942ba0d7":"code","12166dbe":"code","8bf36e69":"code","8c7067e2":"code","8a4aa88e":"code","08e102b2":"code","5431593d":"code","6c0f7229":"code","431c28c7":"code","e0e8648f":"code","7182a387":"code","d8f37595":"code","1895f595":"code","41e8dc42":"code","233ceee3":"code","accf0e66":"code","3ed2096a":"code","7a79c73e":"code","465e777c":"code","841a6263":"code","ec3e5766":"code","b3317d2c":"code","a1d7538a":"code","604443d0":"code","1a1f6f5a":"code","9ef0d584":"code","1bce29a0":"code","fb3cad93":"code","f9c59bb3":"code","d00f281b":"code","671ae5b4":"code","42217b76":"code","52430712":"code","f662bf46":"code","0daa8b0f":"code","55d7a911":"code","e1ffe441":"code","be86cba9":"code","37c503e5":"code","84019dd5":"code","1ad7fcaf":"code","ec82e0fa":"code","598591d5":"code","29e2c33d":"code","3a929743":"code","2ce6ce3c":"code","a66c6651":"code","ea2972d5":"code","9756ead7":"code","e69dafaf":"code","5f81c399":"code","b6e02b2c":"code","e093d92c":"code","9c8ccf7f":"code","fc74236c":"code","2dbeb8a5":"code","bfeeb0ca":"code","814e6647":"code","b0ee7ac4":"code","0840fdc2":"code","496f83f7":"code","88093a82":"code","7839b920":"code","f341d24d":"markdown","28fa44d9":"markdown","66606664":"markdown","af6137bf":"markdown","e2ed7185":"markdown","d4cf6aed":"markdown","8377fca9":"markdown","b7cf598d":"markdown","7ec11c6a":"markdown"},"source":{"fef060bf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n        \n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8e3fb8ab":"'''\nThe Objective - deeply analyze dataset, by experimenting a verity of ML models and technics\n--- Main Tasks ---\n\n1. Cleaning and organizing the data\n2. Get initial understanding of relations in the data \n3. Clustering \u2013 for categorizing data, set \u201cstrong\u201d features\n4. Regression \u2013 seeking the best model to determine \u201cselling price\u201d  \n\n\n'''","942ba0d7":"import pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn import metrics\nfrom sklearn.cluster import KMeans\nfrom sklearn.cluster import AgglomerativeClustering\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.cluster import MeanShift\nfrom sklearn.cluster import Birch\nfrom sklearn.cluster import AffinityPropagation\nfrom sklearn.cluster import MiniBatchKMeans\n\nimport warnings\n#warnings.filterwarnings(\"ignore\")","12166dbe":"import os\nos.getcwd()","8bf36e69":"df=pd.read_csv('..\/input\/vehicle-dataset-from-cardekho\/Car details v3.csv').drop('torque',axis = 1 ).dropna(how = 'all')\ndf.drop_duplicates(subset = ['name','year','selling_price', 'km_driven', 'seller_type','mileage'], keep = 'first')\ndf.sample(4)","8c7067e2":"df.owner.unique()\n# sum(df.owner.str.contains('First | Second | third', case = False))\ndf['owner'].replace({'First Owner': 1,'Second Owner':2, 'Third Owner':3,'Fourth & Above Owner':4, 'Test Drive Car':6}, inplace = True)\ndf.owner.unique()","8a4aa88e":"import datetime as dt\ndt.datetime.today().year\ndf['car_age'] = dt.datetime.today().year - df.year \ndf['car_age']\ndf.drop('year', axis = 1 ) ","08e102b2":"df.shape","5431593d":"df.info()","6c0f7229":"df['max_power'] = df['max_power'].str.strip('bhp')\n\ndf['max_power'] = df['max_power'].str.replace(\" \", \"\")\n# \ndf['max_power'].sort_values(ascending = False).head()#.astype('float64')\ndf['max_power'] = pd.to_numeric(df['max_power'],errors='coerce')","431c28c7":"df['engine'] = df['engine'].str.replace(\"CC\", \"\")\ndf['engine'] = pd.to_numeric(df['engine'], errors= 'coerce')\ndf['mileage'] = df['mileage'].str.replace(\"kmpl\", \"\")\ndf['mileage'] = pd.to_numeric(df['mileage'], errors= 'coerce')\ndf['mileage'].sample(5)","e0e8648f":"# name to brand\ndf['brand'] = df.name.str.split(' ').str[0]\ndf.drop(['year','name'], axis =1, inplace = True)","7182a387":"df.dropna(inplace = True)\n# df.isnull().any()\ndf.isnull().sum()","d8f37595":"# Shuffling the data\ndf.sample(frac = 1).reset_index(drop = True)","1895f595":"df.describe()","41e8dc42":"import seaborn as sns\nfig, ax = plt.subplots(figsize = (10,5))\nsns.heatmap(df.corr(), annot = True )","233ceee3":"plt.boxplot(df[['max_power','car_age', 'engine']])\ndf[['max_power','car_age', 'engine']].describe()","accf0e66":"fig, ax  = plt.subplots(figsize = (10,5)) \nplt.scatter(df.selling_price, df.max_power)\nplt.ylabel('Max Power')\nplt.xlabel('Selling Price')","3ed2096a":"df.seller_type.unique()","7a79c73e":"from sklearn import preprocessing as pre\ndf.transmission = pre.LabelEncoder().fit_transform(df.transmission)\ndf.fuel = pre.LabelEncoder().fit_transform(df.fuel)\ndf.fuel.unique()","465e777c":"# better nameing\ndf_temp = pd.get_dummies(df.seller_type)\ndf_temp.iloc[:,0:2]","841a6263":"print(df_temp.iloc[:,0:2].shape  , df.shape)\ndf  = pd.concat([df,df_temp.iloc[:,0:2]], axis = 1)\ndf.shape","ec3e5766":"del df_temp\ndf.drop(['seller_type'],axis = 1, inplace= True)","b3317d2c":"df.columns","a1d7538a":"df  = pd.get_dummies(df, columns= ['brand'])\ndf.shape","604443d0":"from sklearn.metrics import silhouette_score\nmodel = KMeans(n_clusters=3,max_iter=1000, algorithm = 'full', tol=0.0001 ).fit(df)\nmodel.labels_","1a1f6f5a":"# The silhouette_score gives the average value for all the samples.\n# This gives a perspective into the density and separation of the formed\n# clusters\nsilhouette_avg = silhouette_score(df,model.labels_)\nprint(\"For n_clusters =\", model.n_clusters,\n      \"The average silhouette_score is :\", silhouette_avg)","9ef0d584":"df_num_only = df.iloc[:,np.r_[0:2,5:9]]\ndf_full_feature = df\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\ndf_std = sc.fit_transform(df_full_feature)\ndf_std_num = sc.fit_transform(df_num_only)\nprint('std values , all features ')\nprint(df_std)\nprint('\\n std values , only numeric features ')\nprint(df_std_num)","1bce29a0":"from sklearn.model_selection import ParameterGrid\nbest_score = -1\nn_Kmeans =list(range(3,11,1))\nn_Kmeans","fb3cad93":"best_score = -1\nbest_no_Kmeans = 0\ninter_no = 0\nfor i in n_Kmeans:\n    for j in [200, 1000, 100000]:\n        model = KMeans(n_clusters=i,max_iter= j , algorithm = 'full', tol=0.00001 ).fit(df_std_num)\n        silhouette_avg = silhouette_score(df_std_num,model.labels_)\n        print(\"For n_clusters =\", model.n_clusters,'inter_no: ',model.max_iter,\"The average silhouette_score is :\", silhouette_avg)\n        if silhouette_avg > best_score:\n            best_score =  silhouette_avg\n            best_no_Kmeans = model.n_clusters\n            inter_no = model.max_iter","f9c59bb3":"print(\"Best n_clusters =\", best_no_Kmeans,'Max_iter: ',model.max_iter,\" | Best silhouette_score is :\", best_score)","d00f281b":"model = KMeans(n_clusters =  best_no_Kmeans ,max_iter=1000).fit(df)\nKMeans_results = model.labels_","671ae5b4":"len(KMeans_results)","42217b76":"### eps = the min distance for the clustering internals \n### min samples - min samples for a cluster \n### all others will consider outliers and will reduced from the model\neps_values =np.arange(2,4,1)\nmin_samples =  list(range(9,11,1))","52430712":"print(eps_values)\nmin_samples","f662bf46":"best_score = -1\nbest_eps = 0\nbest_min_samples = 0\nfor i in eps_values:\n    for j in min_samples:\n        model = DBSCAN(eps=i, min_samples=j).fit(df_std_num)\n        model.labels_\n        print(i, model.labels_)\n        silhouette_avg = silhouette_score(df_std_num,model.labels_)\n        print(\"For eps = \", i,'For min_val= ',j ,\"The average silhouette_score is :\", silhouette_avg)\n        if silhouette_avg > best_score:\n            best_score =  silhouette_avg\n            best_eps = i\n            best_min_samples = j","0daa8b0f":"silhouette_avg = silhouette_score(df_std_num,model.labels_)","55d7a911":"silhouette_avg","e1ffe441":"len(model.labels_)","be86cba9":"set(model.labels_)","37c503e5":"list(model.labels_).count(-1)","84019dd5":"print(\"Best eps =\", best_eps,\" | Best min_sample :\", best_min_samples,'No. of clusters: ', len(set(model.labels_)),\" | Best silhouette_score is :\", best_score)\nbest_eps","1ad7fcaf":"model = DBSCAN(eps=best_eps, min_samples=best_min_samples).fit(df_std_num)\nDBSCAN_results = model.labels_","ec82e0fa":"len(set(DBSCAN_results))","598591d5":"from sklearn.cluster import estimate_bandwidth\nestimate_bandwidth(df)","29e2c33d":"model = MeanShift(bandwidth=estimate_bandwidth(df)).fit(df)\nmodel.labels_","3a929743":"silhouette_score = silhouette_score(df, model.labels_)\nsilhouette_score","2ce6ce3c":"print('silhouette_score: ' , silhouette_score, ' | No. of clusters: ', len(set(model.labels_)))\nlen(set(model.labels_))","a66c6651":"from sklearn.cluster import MeanShift\nfrom sklearn.cluster import estimate_bandwidth\nmodel = MeanShift(bandwidth=estimate_bandwidth(df_std_num)).fit(df_std_num)","ea2972d5":"from sklearn.metrics import silhouette_score\nsilhouette_score = silhouette_score(df_std_num, model.labels_)\nsilhouette_score","9756ead7":"MeanShift_results = model.labels_","e69dafaf":"print('silhouette_score: ' , silhouette_score, ' | No. of clusters: ', len(set(model.labels_)))","5f81c399":"set(model.labels_)","b6e02b2c":"n_clusters =np.arange(3,10,1)\nn_clusters","e093d92c":"from sklearn.metrics import silhouette_score\nfrom sklearn.cluster import Birch\nbest_score = -1\nbest_no_clusters = 0\nfor i in n_clusters:\n    model = Birch(n_clusters= i, threshold= 0.3).fit(df_std_num)\n    print(i, model.labels_)\n    silhouette_avg = silhouette_score(df_std_num,model.labels_)\n    print(\"For n_clusters =\", model.n_clusters,\"The average silhouette_score is :\", silhouette_avg)\n    if silhouette_avg > best_score:\n        best_score =  silhouette_avg\n        best_no_clusters = model.n_clusters","9c8ccf7f":"set(model.labels_)\n","fc74236c":"silhouette_score(df_std,model.labels_)","2dbeb8a5":"print('Best No. of clusters: ', best_no_clusters,\" | Best silhouette_score is :\", best_score)","bfeeb0ca":"model = Birch(n_clusters= best_no_clusters, threshold= 0.3).fit(df_std_num)\nBirch_results = model.labels_\nlen(Birch_results)","814e6647":"set(model.labels_)","b0ee7ac4":"#export base table\ndf.to_csv('Car_processed.csv', index= False)","0840fdc2":"df_cl = df.copy()","496f83f7":"df_cl['Birch'] = Birch_results\n#df_cl['MeanShift'] = MeanShift_results\n# df_cl['DBSCAN'] = DBSCAN_results\n#df_cl['KMeans'] = KMeans_results\n\ndf_cl","88093a82":"df_cl.pivot_table(columns= 'owner', index= 'Birch', values = 'selling_price', aggfunc='mean')","7839b920":"#export table with Clusters assigned\ndf_cl.to_csv('Car_processed_cl.csv', index= False)","f341d24d":"### K-mean - Basic","28fa44d9":"### One-Hot Encoding","66606664":"#### DBSCAN clusterring","af6137bf":"### Categorial data into no.\n","e2ed7185":"# Exit Script","d4cf6aed":"#### K-mean","8377fca9":"#### Birch clustering","b7cf598d":"#### MeanShift clustering\n","7ec11c6a":"### Hyper Tuning - the clustering models"}}