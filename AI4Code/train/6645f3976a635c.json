{"cell_type":{"26c970ef":"code","7c953b9b":"code","0abb3e8e":"code","ec1e1257":"code","4df379ff":"code","89fc5882":"code","85a45e7f":"code","ee26ded4":"code","4dde75b5":"code","56e5ae33":"code","9123e8ca":"code","b064984c":"code","b34959d7":"code","1cf2f8cf":"code","df3b2eb3":"code","52f9ffe7":"code","8bc33c26":"code","c219bc2b":"code","459ec2a7":"code","ee7c2971":"code","1e08214d":"code","516c8106":"code","604834d6":"code","d313bcb9":"code","1fff5b12":"code","8e1f75af":"code","366e4c2f":"code","3e8149f2":"code","ce3f6de1":"code","7c6583d1":"code","4f991159":"markdown","f6db9f8d":"markdown","ce0e06b0":"markdown","0228d2b2":"markdown"},"source":{"26c970ef":"# Data preparation\nimport pandas as pd\n\ndf = pd.read_csv('..\/input\/sms-spam-collection-dataset\/spam.csv', encoding='latin1')\ndf.tail(2)","7c953b9b":"df = df[['v1', 'v2']]\ndf.rename({'v1': 'target', 'v2': 'text'}, axis='columns', inplace=True)\ndf","0abb3e8e":"X = df[['text']]\ny = df[['target']]\nX.tail(5)","ec1e1257":"y.tail(5)","4df379ff":"# Check null data\nprint(df.isnull().sum())","89fc5882":"import matplotlib.pyplot as plt\n\n# Check whether this data is imbalanced or not\nplt.figure(figsize=(20, 10))\ndf['target'].value_counts().plot(kind='bar')\nplt.title('Ham versus Spam ratio')\nplt.show()\n\ndf.groupby('target').count().style.background_gradient(cmap='Blues')","85a45e7f":"# stopwords\nfrom tensorflow.keras.preprocessing.text import Tokenizer\n\ntk = Tokenizer()\ntk.fit_on_texts(X.text)\n\ntotal_count = len(tk.word_index)\nrare_count = 0\n\nfor k, v in tk.word_counts.items():\n    if (v < 2):\n        rare_count = rare_count + 1\n\nprint('total number of words : ', total_count, \n      'number of sparse words : ', rare_count)","ee26ded4":"tk = Tokenizer(num_words=total_count-rare_count+1)\ntk.fit_on_texts(X.text) \nX_data = tk.texts_to_sequences(X.text) \nX_data[0][:5]","4dde75b5":"# Vocabularay\n\nsent = [None] * 5\nfor k, v in tk.word_index.items():\n    if v == 50:\n        sent[0] = k\n    if v == 469:\n        sent[1] = k\n    if v == 841:\n        sent[2] = k\n    if v == 751:\n        sent[3] = k\n    if v == 657:\n        sent[4] = k\nprint(sent)","56e5ae33":"# Frequency top5 in spam\nX_spam = df[df['target'] == 'spam']['text']\ntk2 = Tokenizer()\ntk2.fit_on_texts(X_spam)\nsequences = tk2.texts_to_sequences(X_spam)\nrank5 = sorted(tk2.word_counts.items(), key=lambda item: item[1], reverse=True)[:5]\n\nprint('spam Top 5')\nfor i, (w, f) in enumerate(rank5):\n    print('{}\uc704 : '.format(i+1) + w, f)","9123e8ca":"# Frequency top5 in ham\nX_ham = df[df['target'] == 'ham']['text']\ntk2 = Tokenizer()\ntk2.fit_on_texts(X_ham)\nsequences = tk2.texts_to_sequences(X_ham)\nrank5 = sorted(tk2.word_counts.items(), key=lambda item: item[1], reverse=True)[:5]\n\nprint('ham Top 5')\nfor i, (w, f) in enumerate(rank5):\n    print('{}\uc704 : '.format(i+1) + w, f)","b064984c":"import numpy as np\nimport seaborn as sns\n\n# visualization\nmail_length = [len(x) for x in X_data] # \uc911\ubcf5\uc774 \uc880 \ub9ce\uc74c\n\nprint('max : ', np.max(mail_length))\nprint('mean : ', np.mean(mail_length))\nprint('-' * 100)\n\nplt.figure(figsize=(10, 6))\nsns.distplot(mail_length, bins=50)\nplt.title('Distribution')\nplt.xlabel('Word count')\nplt.show()","b34959d7":"# last preparation\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n\nX = pd.DataFrame(pad_sequences(X_data, maxlen=183))\ny.target = y.target.factorize()[0]\ny","1cf2f8cf":"from sklearn.model_selection import train_test_split\n\ntrain_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.25, random_state=0)","df3b2eb3":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import SimpleRNN, Embedding, Dense\n\n\nmodel = Sequential()\nmodel.add(Embedding(total_count, 32))\nmodel.add(SimpleRNN(32))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel.summary()","52f9ffe7":"print('embedding : ', 8920 * 32)\nprint('simple_rnn : ', (32 * 32) + (32 * 32) + 32)\nprint('dense : ', 32 * 1 + 1)","8bc33c26":"epochs = 10\nhistory = model.fit(train_X, train_y, epochs=epochs, validation_split=0.2, batch_size=64, verbose=0)","c219bc2b":"def plot_curve():\n    f, axs = plt.subplots(1, 2, figsize=(10, 5))\n    axs[0].plot(history.history['loss'], label='loss')\n    axs[0].plot(history.history['val_loss'], label='val_loss')\n    axs[0].legend()\n    axs[0].set_title('Loss Curve')\n    axs[1].plot(history.history['accuracy'], label='accuracy')\n    axs[1].plot(history.history['val_accuracy'], label='val_accuracy')\n    axs[1].legend()\n    axs[1].set_title('Accuracy Curve')\n    plt.show()\nplot_curve()","459ec2a7":"model = Sequential()\nmodel.add(Embedding(total_count, 32))\nmodel.add(SimpleRNN(32))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n\nepochs = 3\nhistory = model.fit(train_X, train_y, epochs=epochs, validation_split=0.2, batch_size=64)","ee7c2971":"from sklearn.metrics import classification_report, accuracy_score\n\nmus = model.predict(test_X)\ny_pred = [np.where(mu >= 0.5, 1, 0) for mu in mus]\nprint(classification_report(test_y, y_pred))\nprint('-' * 100)\nprint('\uc815\ud655\ub3c4 : ', accuracy_score(test_y, y_pred))","1e08214d":"train_X.shape, train_y.shape","516c8106":"from sklearn.decomposition import PCA \n\npca = PCA(n_components=2)\nX_2d = pca.fit_transform(train_X)\nX_2d = pd.DataFrame(X_2d, columns=['x', 'y'])\n\n\ndf_2d = pd.concat([X_2d, train_y.reset_index(drop=True)], axis=1)\n\nmask0 = df_2d['target'] == 0\nmask0 = df_2d['target'] == 1\n\nplt.figure(figsize=(10, 5))\nsns.scatterplot(x='x', y='y', data=df_2d, hue='target', s=12)\nplt.title('ham + spam')\nplt.show()","604834d6":"plt.figure(figsize=(10, 5))\ndf_2d.groupby('target').size().plot(kind='bar')\nplt.show()","d313bcb9":"from imblearn.over_sampling import *\nfrom tensorflow.keras.regularizers import l2\n\n# try oversampling\nblcd_X, blcd_y = SMOTE(random_state=0).fit_resample(train_X, train_y)\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import SimpleRNN, Embedding, Dense\n\nmodel = Sequential()\nmodel.add(Embedding(total_count, 32))\nmodel.add(SimpleRNN(32))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n\nepochs = 10\nhistory = model.fit(blcd_X, blcd_y, epochs=epochs, validation_split=0.2, batch_size=64)\n\nplot_curve()","1fff5b12":"from sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\nX_2d = pca.fit_transform(blcd_X)\nX_2d = pd.DataFrame(X_2d, columns=['x', 'y'])\n\ndf_2d = pd.concat([X_2d, blcd_y.reset_index(drop=True)], axis=1)\n\nplt.figure(figsize=(10, 5))\nsns.scatterplot(x='x', y='y', data=df_2d, hue='target', alpha=0.8)\nplt.title('ham + spam')\nplt.show()","8e1f75af":"plt.figure(figsize=(10, 5))\ndf_2d.groupby('target').size().plot(kind='bar')\nplt.show()","366e4c2f":"mus = model.predict(test_X)\ny_pred = [np.where(mu >= 0.5, 1, 0) for mu in mus]\nprint(classification_report(test_y, y_pred))\n# Check recall rate","3e8149f2":"text = '''\nHow are you doing today? I am Mr. Fong pau teck a staff of a reputable financial institution here in Malaysia.\nAn investment was placed under my management. I need your assistance in investing the fund in your country into a good business.\nIf you are interested reply back, so I can forward you with more details.\n'''\n\ndef predict_spam(text):\n    from math import ceil\n    seq = pd.DataFrame(tk.texts_to_sequences(text)[:183]).fillna(value=0).T\n    prob = model.predict(seq)\n    (result, belief) = ('spam', prob) if prob >= 0.5 else ('ham', 1-prob)\n    \n    print('Belief {}% - {}.'.format(round(float(belief), 2) * 100, result))","ce3f6de1":"predict_spam(text)","7c6583d1":"text = '''\nYour business should be accepting Credit Cards from your customers!\nIncrease your sales by 30, 40 even 50 percent by accepting Credit Cards\n'''\n\npredict_spam(text)","4f991159":"This notebook is made for a light practice in **computational-linguistics class**. Feel free to use! \nI'd also appreciate any comment, feedback, and question :D","f6db9f8d":"### EDA","ce0e06b0":"### Machine Learning","0228d2b2":"### Imbalanced data"}}