{"cell_type":{"c7f4a0c7":"code","b3d407cb":"code","efb9385b":"code","da903301":"code","20aef3ff":"code","9db44432":"code","67e80ff5":"code","1c4dd2f2":"code","cf48388b":"code","2f71aa4e":"code","b04d462f":"code","60f1b194":"code","111600a5":"code","d937d545":"code","65737d82":"code","3722dddf":"code","7953b76b":"code","dd950324":"code","6f548321":"code","bf776ccc":"code","508f1cd4":"code","4b65dc23":"code","a7459a46":"code","9afd4174":"code","44392f75":"code","590fe680":"code","19888541":"code","6bee4c8f":"code","624cbfe4":"code","cb73f2dd":"code","08c82618":"code","2886719f":"code","df66bc65":"code","b2986e2a":"code","80257211":"code","5c9db6f2":"code","91968264":"code","dafa8711":"code","560a2589":"code","f7a82e02":"code","22f22156":"code","6ff84d02":"code","fc5d6d66":"code","52f46d2f":"code","17728d3d":"code","8369a120":"code","0700e4b8":"code","680d95e1":"code","ad7e9bf4":"code","48f7dcae":"code","b8842731":"code","d09a4cb3":"code","e825da08":"code","07d5fc9e":"code","b53fe265":"code","3a1789b9":"code","9a1b3ed3":"code","3deaa8f5":"code","edc05068":"code","865c9f53":"code","ec181e70":"code","78d8f28b":"code","f3fe5c7c":"code","4787632c":"code","d7fa6d96":"code","7318573e":"code","3038959f":"code","c8f73dcb":"code","a9100162":"code","786e596a":"code","a09265cd":"code","3039cfa6":"code","ac969855":"code","dfd20e2c":"code","3ce373e5":"code","f4c4c83f":"code","d0f043e2":"code","1cccfe7a":"code","cd41c596":"code","fac2f00a":"code","c617cd5b":"code","a22e17b9":"code","8a158033":"code","3edd0d09":"code","3ac1faaa":"code","87834e04":"code","b6aedaaf":"code","20a64a17":"code","b377ad8f":"code","e2735485":"code","aa7910ce":"code","0a4c562c":"code","8bb3a1ce":"code","15a6976b":"code","9bce5402":"code","f360d04a":"code","b064259d":"markdown","843500d8":"markdown","83880510":"markdown","d6b2206d":"markdown","a622abd2":"markdown","c11476bc":"markdown","7e76ab64":"markdown","e23f9fe1":"markdown","6514c90d":"markdown","7c563782":"markdown","9dfe080b":"markdown","52b84405":"markdown","0444c5c2":"markdown","6ae54218":"markdown","b5a7fd77":"markdown","d132f9d4":"markdown","dfd05c43":"markdown","8ea96004":"markdown","a0b03fee":"markdown","7426b227":"markdown","ea828f62":"markdown","75e78b32":"markdown","dc36eb2e":"markdown","265a7ad2":"markdown","dd1b55b8":"markdown","16f73d13":"markdown","90ee3493":"markdown"},"source":{"c7f4a0c7":"# Importing the required Libraries\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom datetime import datetime\nfrom matplotlib import pyplot\n\nfrom sklearn.feature_selection import SelectKBest,f_classif  # Feature Engineering\nfrom sklearn.model_selection import train_test_split  # Splitting the dataset into training & testing\n\n# Regression & Classification Models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\n\n\n#Metrics\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score,f1_score,recall_score,precision_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score","b3d407cb":"# Loading the Dataset.\n\ndf_train=pd.read_csv('..\/input\/carinsurance\/carInsurance_train.csv')","efb9385b":"df_train.head()","da903301":"df_train.info()","20aef3ff":"# There are missing values in the fields -> \"Job\", \"Education\", \"Communication\" & \"Outcome\".\n# Let's check the percentage of missing values in them.\n\nprint(\"Missing values (Count):-\")\nprint(\"\\n\")\nprint(df_train.isnull().sum())\nprint(\"\\n\")\nprint(\"Missing values (Percentage (%)):-\")\nprint(\"\\n\")\nprint((df_train.isnull().sum()\/len(df_train))*100)","9db44432":"# Analyzing the Categorical values in the Missing value fields.\n\nprint(\"Job Field ->\")\nprint(df_train.Job.value_counts())\nprint(\"\\n\")\nprint(\"Education Field ->\")\nprint(df_train.Education.value_counts())\nprint(\"\\n\")\nprint(\"Communication Field ->\")\nprint(df_train.Communication.value_counts())","67e80ff5":"# Let's determine the most commonly occuring values in the fields -> \"Job\", \"Education\" & \"Communication\".\n\nprint(\"Job Field\")\nprint(df_train.Job.mode())\nprint(\"\\n\")\nprint(\"Education Field\")\nprint(df_train.Education.mode())\nprint(\"\\n\")\nprint(\"Communication Field\")\nprint(df_train.Communication.mode())","1c4dd2f2":"# Let's fill the missing values with their respective modes.\n\nfor i in [\"Job\",\"Education\",\"Communication\"]:\n    df_train[i]=df_train[i].fillna(df_train[i].mode()[0])","cf48388b":"# As 76% of the data is missing in \"Outcome\" field, it's better to drop the column.\n\ndf_train.drop('Outcome',axis=1,inplace=True)","2f71aa4e":"# Converting the type of \"CallStart\" & \"CallEnd\" to Datetime.\n\ndf_train[['CallStart','CallEnd']]=df_train[['CallStart','CallEnd']].astype('datetime64[ns]')","b04d462f":"# Calculating the total Call Duration\n\ndf_train['Call_Duration']=df_train['CallEnd']-df_train['CallStart']\n\n# Extracting the time & converting it to seconds\n\ndf_train['Call_Duration']=df_train['Call_Duration'].dt.components['minutes']*60 + df_train['Call_Duration'].dt.components['seconds']\ndf_train['Call_Duration'].head()","60f1b194":"df_train.head()","111600a5":"# Adding a column with Age Ranges.\n\ndef agerange(age):\n    if age >= 18 and age <= 20:\n        return \"18-20\"\n    elif age >= 21 and age <= 30:\n        return \"21-30\"\n    elif age >= 31 and age <= 40:\n        return \"31-40\"\n    elif age >= 41 and age <= 50:\n        return \"41-50\"\n    elif age >= 51 and age <= 60:\n        return \"51-60\"\n    elif age >= 61 and age <= 70:\n        return \"61-70\"\n    elif age >= 71 and age <= 80:\n        return \"71-80\"\n    elif age >=81 and age <= 90:\n        return \"81-90\"\n    elif age > 90:\n        return \"Above 90\"","d937d545":"df_train['Age Range']=df_train['Age'].apply(agerange)","65737d82":"# Let's analyze the Age of the Customers w.r.t Jobs\n\nAgeRange_crosstab=pd.crosstab(index=df_train['Age Range'],columns=df_train['Job'])\nAgeRange_crosstab","3722dddf":"# Plotting the above values.\n\nAgeRange_crosstab.plot(kind='bar',stacked=False,figsize=(20,6))\nplt.xticks(rotation = 0)\nplt.xlabel('Age Ranges',fontsize=16)\nplt.ylabel('Job',fontsize=16)\nplt.title('Analyzing Age w.r.t Job',fontsize=18)\nplt.legend(title='Job',title_fontsize=15,prop={\"size\":12})","7953b76b":"# Let's check the age dependancy w.r.t Car Insurance Opting Decisions\n\nAge_crosstab=pd.crosstab(index=df_train['Age Range'],columns=df_train['CarInsurance'])\nAge_crosstab['Percentage Enrolled']=round(Age_crosstab[1]\/(Age_crosstab[0]+Age_crosstab[1])*100,2)\nAge_crosstab","dd950324":"# Plotting the above values.\n\nAge_crosstab.drop(['Percentage Enrolled'], axis=1).plot(kind='bar',stacked=False,figsize=(20,6))\nplt.xticks(rotation = 0,fontsize=12)\nplt.xlabel('Age Ranges',fontsize=16)\nplt.ylabel('Car Insurance',fontsize=16)\nplt.title('Car Insurance policy Decisions w.r.t Age',fontsize=18)\nplt.legend(['Rejected','Accepted'],title='Car Insurance',title_fontsize=15,prop={\"size\":12})","6f548321":"# Let's check the Job dependancy w.r.t Car Insurance Opting Decisions\n\nJob_crosstab=pd.crosstab(df_train['Job'],df_train['CarInsurance'],colnames=['Car Insurance'])\nJob_crosstab['Percentage Enrolled']=round(Job_crosstab[1]\/(Job_crosstab[0]+Job_crosstab[1])*100,2)\nJob_crosstab","bf776ccc":"# Plotting the above values.\n\nJob_crosstab.drop(['Percentage Enrolled'], axis=1).plot(kind='bar',stacked=False,figsize=(20,6))\nplt.xticks(rotation = 0,fontsize=12)\nplt.xlabel('Jobs',fontsize=16)\nplt.ylabel('Car Insurance',fontsize=16)\nplt.title('Car Insurance Policy Decisions w.r.t Job',fontsize=18)\nplt.legend(['Rejected','Accepted'],title='Car Insurance',title_fontsize=15,prop={\"size\":12})","508f1cd4":"# Let's check the dependancy of marital status on Car Insurance Opting Decisions\n\nMarital_crosstab=pd.crosstab(df_train['Marital'],df_train['CarInsurance'],colnames=['Car Insurance'])\nMarital_crosstab['Percentage Enrolled']=round(Marital_crosstab[1]\/(Marital_crosstab[0]+Marital_crosstab[1])*100,2)\nMarital_crosstab","4b65dc23":"# Plotting the above values.\n\nMarital_crosstab.drop(['Percentage Enrolled'], axis=1).plot(kind='bar',stacked=False,figsize=(20,6))\nplt.xticks(rotation = 0,fontsize=12)\nplt.xlabel('Marital Status',fontsize=16)\nplt.ylabel('Car Insurance',fontsize=16)\nplt.title('Car Insurance Policy Decisions w.r.t Marital Status',fontsize=18)\nplt.legend(['Rejected','Accepted'],title='Car Insurance',title_fontsize=15,prop={\"size\":12})","a7459a46":"# Let's check the dependancy of Education on Car Insurance Opting Decisions\n\nEducation_crosstab=pd.crosstab(df_train['Education'],df_train['CarInsurance'],colnames=['Car Insurance'])\nEducation_crosstab['Percentage Enrolled']=round(Education_crosstab[1]\/(Education_crosstab[0]+Education_crosstab[1])*100,2)\nEducation_crosstab","9afd4174":"# Plotting the above values.\n\nEducation_crosstab.drop(['Percentage Enrolled'], axis=1).plot(kind='bar',stacked=False,figsize=(20,6))\nplt.xticks(rotation = 0,fontsize=12)\nplt.xlabel('Education',fontsize=16)\nplt.ylabel('Car Insurance',fontsize=16)\nplt.title('Car Insurance Policy Decisions w.r.t Education',fontsize=18)\nplt.legend(['Rejected','Accepted'],title='Car Insurance',title_fontsize=15,prop={\"size\":12})","44392f75":"# Let's check the dependancy of House-Hold Insurance on Car Insurance Opting Decisions\n\nHHInsurance_crosstab=pd.crosstab(df_train['HHInsurance'],df_train['CarInsurance'],colnames=['Car Insurance'])\nHHInsurance_crosstab['Percentage Enrolled']=round(HHInsurance_crosstab[1]\/(HHInsurance_crosstab[0]+HHInsurance_crosstab[1])*100,2)\nHHInsurance_crosstab","590fe680":"# Plotting the above values.\n\nHHInsurance_crosstab.drop(['Percentage Enrolled'], axis=1).plot(kind='bar',stacked=False,figsize=(20,6))\nplt.xticks(rotation = 0,fontsize=12)\nplt.xlabel('House-Hold Insurance',fontsize=16)\nplt.ylabel('Car Insurance',fontsize=16)\nplt.title('Car Insurance Policy Decisions w.r.t House-Hold Insurance',fontsize=18)\nplt.legend(['Rejected','Accepted','Percentage Accepted'],title='Car Insurance',title_fontsize=15,prop={\"size\":12})","19888541":"# Let's check the dependancy of Loan defaulting on Car Insurance Opting Decisions\n\nDefault_crosstab=pd.crosstab(df_train['Default'],df_train['CarInsurance'],colnames=['Car Insurance'])\nDefault_crosstab['Percentage Enrolled']=round(Default_crosstab[1]\/(Default_crosstab[0]+Default_crosstab[1])*100,2)\nDefault_crosstab","6bee4c8f":"# Plotting the above values.\n\nDefault_crosstab.drop(['Percentage Enrolled'], axis=1).plot(kind='bar',stacked=False,figsize=(20,6))\nplt.xticks(rotation = 0,fontsize=12)\nplt.xlabel('Default',fontsize=16)\nplt.ylabel('Car Insurance',fontsize=16)\nplt.title('Car Insurance Policy Decisions w.r.t Loan Defaulting',fontsize=18)\nplt.legend(['Rejected','Accepted'],title='Car Insurance',title_fontsize=15,prop={\"size\":12})","624cbfe4":"# Let's check the dependancy of Car Loan on Car Insurance Opting Decisions\n\nCarLoan_crosstab=pd.crosstab(df_train['CarLoan'],df_train['CarInsurance'],colnames=['Car Insurance'])\nCarLoan_crosstab['Percentage Enrolled']=round(CarLoan_crosstab[1]\/(CarLoan_crosstab[0]+CarLoan_crosstab[1])*100,2)\nCarLoan_crosstab","cb73f2dd":"# Plotting the above values.\n\nCarLoan_crosstab.drop(['Percentage Enrolled'], axis=1).plot(kind='bar',stacked=False,figsize=(20,6))\nplt.xticks(rotation = 0,fontsize=12)\nplt.xlabel('Car Loan',fontsize=16)\nplt.ylabel('Car Insurance',fontsize=16)\nplt.title('Car Insurance Policy Decisions w.r.t Car Loan',fontsize=18)\nplt.legend(['Rejected','Accepted'],title='Car Insurance',title_fontsize=15,prop={\"size\":12})","08c82618":"# Let's check the dependancy of the Mode of Communication on Car Insurance Opting Decisions\n\nCommunication_crosstab=pd.crosstab(df_train['Communication'],df_train['CarInsurance'],colnames=['Car Insurance'])\nCommunication_crosstab['Percentage Enrolled']=round(Communication_crosstab[1]\/(Communication_crosstab[0]+Communication_crosstab[1])*100,2)\nCommunication_crosstab","2886719f":"# Plotting the above values.\n\nCommunication_crosstab.drop(['Percentage Enrolled'], axis=1).plot(kind='bar',stacked=False,figsize=(20,6))\nplt.xticks(rotation = 0,fontsize=12)\nplt.xlabel('Communication',fontsize=16)\nplt.ylabel('Car Insurance',fontsize=16)\nplt.title('Car Insurance Policy Decisions w.r.t Communication',fontsize=18)\nplt.legend(['Rejected','Accepted'],title='Car Insurance',title_fontsize=15,prop={\"size\":12})","df66bc65":"# Let's check the dependancy of the Contact Month on Car Insurance Opting Decisions\n\nLastContactMonth_crosstab=pd.crosstab(df_train['LastContactMonth'],df_train['CarInsurance'],colnames=['Car Insurance'])\nLastContactMonth_crosstab['Percentage Enrolled']=round(LastContactMonth_crosstab[1]\/(LastContactMonth_crosstab[0]+\n                                                                                     LastContactMonth_crosstab[1])*100,2)\nLastContactMonth_crosstab","b2986e2a":"# Plotting the above values.\n\nLastContactMonth_crosstab.drop(['Percentage Enrolled'], axis=1).plot(kind='bar',stacked=False,figsize=(20,6))\nplt.xticks(rotation = 0,fontsize=12)\nplt.xlabel('Last Contact Month',fontsize=16)\nplt.ylabel('Car Insurance',fontsize=16)\nplt.title('Car Insurance Policy Decisions w.r.t Last Contact Month',fontsize=18)\nplt.legend(['Rejected','Accepted'],title='Car Insurance',title_fontsize=15,prop={\"size\":12})","80257211":"# Let's define a new column containing the categorical values of the days of a month.\n\ndef Day_Categories(day):\n    if(day >= 1 and day <= 11):\n        return \"Month Starting\"\n    elif(day >= 12 and day <= 21):\n        return \"Middle of the Month\"\n    elif(day >= 22 and day <= 31):\n        return \"Month Ending\"","5c9db6f2":"df_train['Day_Categories']=df_train['LastContactDay'].apply(Day_Categories)","91968264":"# Let's check the dependancy of Last Contacted Day on Car Insurance Opting Decisions\n\nLastContactDay_crosstab=pd.crosstab(df_train['Day_Categories'],df_train['CarInsurance'],colnames=['Car Insurance'])\nLastContactDay_crosstab['Percentage Enrolled']=round(LastContactDay_crosstab[1]\/(LastContactDay_crosstab[0]+\n                                                                                     LastContactDay_crosstab[1])*100,2)\nLastContactDay_crosstab","dafa8711":"# Plotting the above values.\n\nLastContactDay_crosstab.drop(['Percentage Enrolled'], axis=1).plot(kind='bar',stacked=False,figsize=(20,6))\nplt.xticks(rotation = 0,fontsize=12)\nplt.xlabel('Last Contact Day',fontsize=16)\nplt.ylabel('Car Insurance',fontsize=16)\nplt.title('Car Insurance Policy Decisions w.r.t Last Contact Day',fontsize=18)\nplt.legend(['Rejected','Accepted'],title='Car Insurance',title_fontsize=15,prop={\"size\":12})","560a2589":"df_train.NoOfContacts.value_counts()","f7a82e02":"# Let's categorize the No of times the bank has contacted the customers regarding the Insurance policy.\n\ndef update_contacts(contact):\n    if(contact == 1):\n        return \"Contacted once\"\n    elif(contact > 1 and contact <= 10):\n        return \"Contacted More than once\"\n    elif(contact > 10 and contact <= 20):\n        return \"Contacted more than 10 times\"\n    elif(contact > 20 and contact <= 30):\n        return \"Contacted more than 20\"\n    elif(contact > 30):\n        return \"Contacted more than 30 times\"","22f22156":"df_train['NoOfContacts_Category']=df_train['NoOfContacts'].apply(update_contacts)","6ff84d02":"df_train.NoOfContacts_Category.value_counts()","fc5d6d66":"# Dependancy of No of contacts by the bank on Car Insurance Opting Decisions\n\nNoOfContacts_Category_crosstab=pd.crosstab(df_train['NoOfContacts_Category'],df_train['CarInsurance'],colnames=['Car Insurance'])\nNoOfContacts_Category_crosstab['Percentage Enrolled']=round(NoOfContacts_Category_crosstab[1]\/(NoOfContacts_Category_crosstab[0]+\n                                                                                     NoOfContacts_Category_crosstab[1])*100,2)\nNoOfContacts_Category_crosstab","52f46d2f":"# Plotting the above values.\n\nNoOfContacts_Category_crosstab.drop(['Percentage Enrolled'], axis=1).plot(kind='bar',stacked=False,figsize=(20,6))\nplt.xticks(rotation = 90,fontsize=12)\nplt.xlabel('No of Contacts made',fontsize=16)\nplt.ylabel('Car Insurance',fontsize=16)\nplt.title('Car Insurance Policy Decisions w.r.t Contacts made',fontsize=18)\nplt.legend(['Rejected','Accepted'],title='Car Insurance',title_fontsize=15,prop={\"size\":12})","17728d3d":"# Converting \"Call Duration\" to minutes.\n\ndf_train['Call_Duration']=df_train['Call_Duration'].apply(lambda x: round(x\/60),2)\ndf_train['Call_Duration'].head()","8369a120":"# Dependancy of Call Duration on Car Insurance Opting Decisions\n\nCall_Duration_crosstab=pd.crosstab(df_train['Call_Duration'],df_train['CarInsurance'],colnames=['Car Insurance'],\n                                   rownames=['Call Duration (in minutes)'])\nCall_Duration_crosstab['Percentage Enrolled']=round(Call_Duration_crosstab[1]\/(Call_Duration_crosstab[0]+ Call_Duration_crosstab[1])*100,2)\nCall_Duration_crosstab","0700e4b8":"# Plotting the above values.\n\nCall_Duration_crosstab.drop(['Percentage Enrolled'], axis=1).plot(kind='bar',stacked=False,figsize=(20,6))\nplt.xticks(rotation = 0,fontsize=12)\nplt.xlabel('Call Duration (in minutes)',fontsize=16)\nplt.ylabel('Car Insurance',fontsize=16)\nplt.title('Car Insurance Policy Decisions w.r.t Call Duration',fontsize=18)\nplt.legend(['Rejected','Accepted'],title='Car Insurance',title_fontsize=15,prop={\"size\":12})","680d95e1":"# Let's categorize the Call durations for better understanding according to the mean duration.\n\nmean=df_train.Call_Duration.mean()\nmean\n\ndef update_duration(call):\n    if(call < mean):\n        return \"Less than Mean Duration\"\n    elif(call > mean):\n        return \"More than Mean Duration\"","ad7e9bf4":"df_train['Call_Duration_Mean']=df_train['Call_Duration'].apply(update_duration)","48f7dcae":"# Dependancy of Mean Call Duration on Car Insurance Opting Decisions\n\nMean_Call_Duration_crosstab=pd.crosstab(df_train['Call_Duration_Mean'],df_train['CarInsurance'],colnames=['Car Insurance'],\n                                   rownames=['Call Duration (in minutes)'])\nMean_Call_Duration_crosstab['Percentage Enrolled']=round(Mean_Call_Duration_crosstab[1]\/(Mean_Call_Duration_crosstab[0]+ Mean_Call_Duration_crosstab[1])*100,2)\nMean_Call_Duration_crosstab","b8842731":"# Plotting the above values.\n\nMean_Call_Duration_crosstab.drop(['Percentage Enrolled'], axis=1).plot(kind='bar',stacked=False,figsize=(20,6))\nplt.xticks(rotation = 0,fontsize=12)\nplt.xlabel('Call Duration (in minutes)',fontsize=16)\nplt.ylabel('Car Insurance',fontsize=16)\nplt.title('Car Insurance Policy Decisions w.r.t Mean Call Duration',fontsize=18)\nplt.legend(['Rejected','Accepted'],title='Car Insurance',title_fontsize=15,prop={\"size\":12})","d09a4cb3":"df_train.head()","e825da08":"plt.figure(figsize=(21,7))\nres=sns.heatmap(df_train.corr(),annot=True)\nres.set_xticklabels (res.get_xmajorticklabels (), fontsize = 12,rotation=45)\nres.set_yticklabels (res.get_xmajorticklabels (), fontsize = 12)","07d5fc9e":"# Let's drop the columns \"Id\", \"CallStart\" & \"CallEnd\".\n\ndf_train.drop(['Id','CallStart','CallEnd'],axis=1,inplace=True)","b53fe265":"# Let's convert all the categorical valued features into numerical values by using get_dummies method in pandas. \n\ndf_train=pd.get_dummies(data=df_train,columns=['Job','Marital','Education','Communication','LastContactMonth','NoOfContacts_Category',\n                                      'Call_Duration_Mean','Day_Categories','Age Range','Call_Duration_Mean'],drop_first=True)","3a1789b9":"# Removing all the duplicate columns if any.\n\ndf_train = df_train.loc[:,~df_train.columns.duplicated()]","9a1b3ed3":"# evaluating the important features for consideration using SelectKBest method.\n\nX_temp=df_train.drop(['CarInsurance','NoOfContacts_Category_Contacted more than 10 times','NoOfContacts_Category_Contacted more than 20',\n               'NoOfContacts_Category_Contacted more than 30 times','NoOfContacts_Category_Contacted once',\n                'Call_Duration_Mean_More than Mean Duration','Day_Categories_Month Ending','Day_Categories_Month Starting',\n               'Age Range_21-30','Age Range_31-40','Age Range_41-50','Age Range_51-60','Age Range_61-70','Age Range_71-80',\n               'Age Range_81-90','Age Range_Above 90'],axis=1)","3deaa8f5":"X_temp.columns","edc05068":"y_temp=df_train['CarInsurance']","865c9f53":"# As there are -ve values present in the data, we need to use \"f_classif\" scoring function.\n# Let's select top 35 features.\n\nBest_Params=SelectKBest(score_func=f_classif, k=35)\nBest_Params.fit(X_temp,y_temp)","ec181e70":"df_scores=pd.DataFrame(Best_Params.scores_)                    # Feature Scores\ndf_columns=pd.DataFrame(X_temp.columns)                        # Feature Names\ndf_score_evaluation=pd.concat([df_scores,df_columns],axis=1)   # Concatinating both the dataframes\ndf_score_evaluation.columns=['Scores','Features']              # Renaming the columns\nprint(df_score_evaluation.nlargest(35,'Scores'))               # Sorting Scores in Descending order","78d8f28b":"X_temp.columns.sort_values()","f3fe5c7c":"import copy\nX_new=copy.deepcopy(X_temp)\nX_new.head()","4787632c":"y_new=copy.deepcopy(y_temp)","d7fa6d96":"# Let's split the data into Training & Test sets.\n\nX_train,X_test,y_train,y_test=train_test_split(X_new,y_new,test_size=0.20,random_state=42)\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","7318573e":"# LOGISTIC REGRESSION MODEL\n\nlr_model=LogisticRegression()\n\n# Hyper-parameter tuning\nsolvers = ['newton-cg', 'lbfgs', 'liblinear']\npenalty = ['l2']\nlr_c = [100, 10, 1.0, 0.1, 0.01]\n\nlr_grid = dict(solver=solvers,penalty=penalty,C=lr_c)\n\n# cross-validation using Repeated Stratified K-fold method.\nlr_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\n# Grid Search CV method loops through the different hyper parameters determining the optimal values.\nlr_grid_search = GridSearchCV(estimator=lr_model, param_grid=lr_grid, n_jobs=-1, cv=lr_cv, scoring='accuracy',error_score=0)\n\n# Fitting the Model to the Dataset.\nlr_grid_result=lr_grid_search.fit(X_train,y_train)\n\n# returns the best hyper parameters.\nlr_grid_result.best_params_","3038959f":"# Making predictions using our model.\nlr_grid_predictions=lr_grid_result.predict(X_test)","c8f73dcb":"# Model Metrics\n\nprint(\"LOGISTIC REGRESSION Model Performance Metrics:\")\nprint(classification_report(y_test,lr_grid_predictions))\n\nprint(\"CONFUSION MATRIX :\")\nprint(confusion_matrix(y_test,lr_grid_predictions))\nprint(\"\\n\")\n\nplt.figure(figsize=(12,6))\npyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill Classifier') # Let's define a no skill (Dummy) Classifier for reference.\n\nfpr, tpr, _ = roc_curve(y_test,lr_grid_predictions)             # passing the target labels & Model Predictions to the roc_curve method. \n\npyplot.plot(fpr, tpr, marker='.', label='Logistic Regression')  # Plotting the obtained results.\n\nns_probs = [0 for _ in range(len(y_test))]       # generating predictions from the no skill (Dummy) classifier for reference.\n\n# Calculating Area under Curve for the No Skill & the trained Model.\nns_auc = roc_auc_score(y_test, ns_probs)             \nlr_auc = roc_auc_score(y_test, lr_grid_predictions)\n\nprint('NO SKILL CLASSIFIER: ROC AUC=%.3f' % (ns_auc))\nprint('LOGISTIC REGRESSION: ROC AUC=%.3f' % (lr_auc))\n\npyplot.xlabel('False Positive Rate',fontsize=16)\npyplot.ylabel('True Positive Rate',fontsize=16)\npyplot.title(\"ROC Curve\",fontsize=18)\npyplot.legend(prop={'size':12})\npyplot.show()","a9100162":"rc_model=RidgeClassifier()\n\nalpha = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n\nrc_grid = dict(alpha=alpha)\n\nrc_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\nrc_grid_search = GridSearchCV(estimator=rc_model, param_grid=rc_grid, n_jobs=-1, cv=rc_cv, scoring='accuracy',error_score=0)\n\nrc_grid_result=rc_grid_search.fit(X_train,y_train)\n\nrc_grid_result.best_params_","786e596a":"rc_grid_predictions=rc_grid_result.predict(X_test)","a09265cd":"print(\"RIDGE CLASSIFIER Model Performance Metrics:\")\nprint(classification_report(y_test,rc_grid_predictions))\n\nprint(\"CONFUSION MATRIX :\")\nprint(confusion_matrix(y_test,rc_grid_predictions))\nprint(\"\\n\")\n\nplt.figure(figsize=(12,6))\npyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill Classifier') # Let's define a no skill (Dummy) Classifier for reference.\n\nfpr, tpr, _ = roc_curve(y_test,rc_grid_predictions)             # passing the target labels & Model Predictions to the roc_curve method. \n\npyplot.plot(fpr, tpr, marker='.', label='RIDGE CLASSIFIER')  # Plotting the obtained results.\n\nns_probs = [0 for _ in range(len(y_test))]       # generating predictions from the no skill (Dummy) classifier for reference.\n\n# Calculating Area under Curve for the No Skill & the trained Model.\nns_auc = roc_auc_score(y_test, ns_probs)             \nrc_auc = roc_auc_score(y_test, rc_grid_predictions)\n\nprint('NO SKILL CLASSIFIER: ROC AUC=%.3f' % (ns_auc))\nprint('RIDGE CLASSIFIER: ROC AUC=%.3f' % (rc_auc))\n\npyplot.xlabel('False Positive Rate',fontsize=16)\npyplot.ylabel('True Positive Rate',fontsize=16)\npyplot.title(\"ROC Curve\",fontsize=18)\npyplot.legend(prop={'size':12})\npyplot.show()","3039cfa6":"dtc_model=DecisionTreeClassifier()\n\ndtc_grid = { 'criterion':['gini','entropy'],'max_depth': np.arange(1, 10),'min_samples_split':range(1,10),'min_samples_leaf':range(1,5)}\n\ndtc_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\ndtc_grid_search = GridSearchCV(estimator=dtc_model, param_grid=dtc_grid, n_jobs=-1, cv=dtc_cv, scoring='accuracy',error_score=0)\n\ndtc_grid_result=dtc_grid_search.fit(X_train,y_train) \n\ndtc_grid_result.best_params_","ac969855":"dtc_grid_predictions=dtc_grid_result.predict(X_test)","dfd20e2c":"print(\"DECISION TREE CLASSIFIER Model Performance Metrics:\")\nprint(classification_report(y_test,dtc_grid_predictions))\n\nprint(\"CONFUSION MATRIX :\")\nprint(confusion_matrix(y_test,dtc_grid_predictions))\nprint(\"\\n\")\n\nplt.figure(figsize=(12,6))\npyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill Classifier') # Let's define a no skill (Dummy) Classifier for reference.\n\nfpr, tpr, _ = roc_curve(y_test,dtc_grid_predictions)             # passing the target labels & Model Predictions to the roc_curve method. \n\npyplot.plot(fpr, tpr, marker='.', label='DECISION TREE CLASSIFIER')  # Plotting the obtained results.\n\nns_probs = [0 for _ in range(len(y_test))]       # generating predictions from the no skill (Dummy) classifier for reference.\n\n# Calculating Area under Curve for the No Skill & the trained Model.\nns_auc = roc_auc_score(y_test, ns_probs)             \ndtc_auc = roc_auc_score(y_test, dtc_grid_predictions)\n\nprint('NO SKILL CLASSIFIER: ROC AUC=%.3f' % (ns_auc))\nprint('DECISION TREE CLASSIFIER: ROC AUC=%.3f' % (dtc_auc))\n\npyplot.xlabel('False Positive Rate',fontsize=16)\npyplot.ylabel('True Positive Rate',fontsize=16)\npyplot.title(\"ROC Curve\",fontsize=18)\npyplot.legend(prop={'size':12})\npyplot.show()","3ce373e5":"bc_model=BaggingClassifier()\n\nbc_n_estimators = [1000]\n\nbc_grid = dict(n_estimators=bc_n_estimators)\n\nbc_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\nbc_grid_search = GridSearchCV(estimator=bc_model, param_grid=bc_grid, n_jobs=-1, cv=bc_cv, scoring='accuracy',error_score=0)\n\nbc_grid_result=bc_grid_search.fit(X_train,y_train)\n\nbc_grid_result.best_params_","f4c4c83f":"bc_grid_predictions=bc_grid_result.predict(X_test)","d0f043e2":"print(\"BAGGING CLASSIFIER Model Performance Metrics:\")\nprint(classification_report(y_test,bc_grid_predictions))\n\nprint(\"CONFUSION MATRIX :\")\nprint(confusion_matrix(y_test,bc_grid_predictions))\nprint(\"\\n\")\n\nplt.figure(figsize=(12,6))\npyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill Classifier') # Let's define a no skill (Dummy) Classifier for reference.\n\nfpr, tpr, _ = roc_curve(y_test,bc_grid_predictions)             # passing the target labels & Model Predictions to the roc_curve method. \n\npyplot.plot(fpr, tpr, marker='.', label='BAGGING CLASSIFIER')  # Plotting the obtained results.\n\nns_probs = [0 for _ in range(len(y_test))]       # generating predictions from the no skill (Dummy) classifier for reference.\n\n# Calculating Area under Curve for the No Skill & the trained Model.\nns_auc = roc_auc_score(y_test, ns_probs)             \nbc_auc = roc_auc_score(y_test, bc_grid_predictions)\n\nprint('NO SKILL CLASSIFIER: ROC AUC=%.3f' % (ns_auc))\nprint('BAGGING CLASSIFIER: ROC AUC=%.3f' % (bc_auc))\n\npyplot.xlabel('False Positive Rate',fontsize=16)\npyplot.ylabel('True Positive Rate',fontsize=16)\npyplot.title(\"ROC Curve\",fontsize=18)\npyplot.legend(prop={'size':12})\npyplot.show()","1cccfe7a":"knc_model=KNeighborsClassifier()\n\nn_neighbors = range(1, 21)\nweights = ['uniform', 'distance']\nmetric = ['euclidean', 'manhattan', 'minkowski']\n\nknc_grid = dict(n_neighbors=n_neighbors,weights=weights,metric=metric)\n\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\nknc_grid_search = GridSearchCV(estimator=knc_model, param_grid=knc_grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n\nknc_grid_result=knc_grid_search.fit(X_train,y_train)\n\nknc_grid_result.best_params_","cd41c596":"knc_grid_predictions=knc_grid_result.predict(X_test)","fac2f00a":"print(\"K-NEIGHBOURS CLASSIFIER Model Performance Metrics:\")\nprint(classification_report(y_test,knc_grid_predictions))\n\nprint(\"CONFUSION MATRIX :\")\nprint(confusion_matrix(y_test,knc_grid_predictions))\nprint(\"\\n\")\n\nplt.figure(figsize=(12,6))\npyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill Classifier') # Let's define a no skill (Dummy) Classifier for reference.\n\nfpr, tpr, _ = roc_curve(y_test,knc_grid_predictions)             # passing the target labels & Model Predictions to the roc_curve method. \n\npyplot.plot(fpr, tpr, marker='.', label='K-NEIGHBOURS CLASSIFIER')  # Plotting the obtained results.\n\nns_probs = [0 for _ in range(len(y_test))]       # generating predictions from the no skill (Dummy) classifier for reference.\n\n# Calculating Area under Curve for the No Skill & the trained Model.\nns_auc = roc_auc_score(y_test, ns_probs)             \nknc_auc = roc_auc_score(y_test, knc_grid_predictions)\n\nprint('NO SKILL CLASSIFIER: ROC AUC=%.3f' % (ns_auc))\nprint('K-NEIGHBOURS CLASSIFIER: ROC AUC=%.3f' % (knc_auc))\n\npyplot.xlabel('False Positive Rate',fontsize=16)\npyplot.ylabel('True Positive Rate',fontsize=16)\npyplot.title(\"ROC Curve\",fontsize=18)\npyplot.legend(prop={'size':12})\npyplot.show()","c617cd5b":"rfc_model=RandomForestClassifier()\n\nmax_features = ['sqrt', 'log2']\n\nrfc_n_estimators = [1000]\n\nrfc_grid = dict(n_estimators=rfc_n_estimators,max_features=max_features)\n\nrfc_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\nrfc_grid_search = GridSearchCV(estimator=rfc_model, param_grid=rfc_grid, n_jobs=-1, cv=rfc_cv, scoring='accuracy',error_score=0)\n\nrfc_grid_result=rfc_grid_search.fit(X_train,y_train)\n\nrfc_grid_result.best_params_","a22e17b9":"rfc_grid_predictions=rfc_grid_result.predict(X_test)","8a158033":"print(\"RANDOM FOREST CLASSIFIER Model Performance Metrics:\")\nprint(classification_report(y_test,rfc_grid_predictions))\n\nprint(\"CONFUSION MATRIX :\")\nprint(confusion_matrix(y_test,rfc_grid_predictions))\nprint(\"\\n\")\n\nplt.figure(figsize=(12,6))\npyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill Classifier') # Let's define a no skill (Dummy) Classifier for reference.\n\nfpr, tpr, _ = roc_curve(y_test,rfc_grid_predictions)             # passing the target labels & Model Predictions to the roc_curve method. \n\npyplot.plot(fpr, tpr, marker='.', label='RANDOM FOREST CLASSIFIER')  # Plotting the obtained results.\n\nns_probs = [0 for _ in range(len(y_test))]       # generating predictions from the no skill (Dummy) classifier for reference.\n\n# Calculating Area under Curve for the No Skill & the trained Model.\nns_auc = roc_auc_score(y_test, ns_probs)             \nrfc_auc = roc_auc_score(y_test, rfc_grid_predictions)\n\nprint('NO SKILL CLASSIFIER: ROC AUC=%.3f' % (ns_auc))\nprint('RANDOM FOREST CLASSIFIER: ROC AUC=%.3f' % (rfc_auc))\n\npyplot.xlabel('False Positive Rate',fontsize=16)\npyplot.ylabel('True Positive Rate',fontsize=16)\npyplot.title(\"ROC Curve\",fontsize=18)\npyplot.legend(prop={'size':12})\npyplot.show()","3edd0d09":"svc_model=SVC()\n\n#kernel = ['poly', 'rbf', 'sigmoid']\n#C = [50, 10, 1.0, 0.1, 0.01]\n\nkernel=['rbf']\nC=[1000]\ngamma = ['scale']\n\nsvc_grid = dict(kernel=kernel,C=C,gamma=gamma)\n\nsvc_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\nsvc_grid_search = GridSearchCV(estimator=svc_model, param_grid=svc_grid, n_jobs=-1, cv=svc_cv, scoring='accuracy',error_score=0)\n\nsvc_grid_result=svc_grid_search.fit(X_train,y_train)\n\nsvc_grid_result.best_params_","3ac1faaa":"svc_grid_predictions=svc_grid_result.predict(X_test)","87834e04":"print(\"SVM CLASSIFIER Model Performance Metrics:\")\nprint(classification_report(y_test,svc_grid_predictions))\n\nprint(\"CONFUSION MATRIX :\")\nprint(confusion_matrix(y_test,svc_grid_predictions))\nprint(\"\\n\")\n\nplt.figure(figsize=(12,6))\npyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill Classifier') # Let's define a no skill (Dummy) Classifier for reference.\n\nfpr, tpr, _ = roc_curve(y_test,svc_grid_predictions)             # passing the target labels & Model Predictions to the roc_curve method. \n\npyplot.plot(fpr, tpr, marker='.', label='SVM CLASSIFIER')  # Plotting the obtained results.\n\nns_probs = [0 for _ in range(len(y_test))]       # generating predictions from the no skill (Dummy) classifier for reference.\n\n# Calculating Area under Curve for the No Skill & the trained Model.\nns_auc = roc_auc_score(y_test, ns_probs)             \nsvc_auc = roc_auc_score(y_test, svc_grid_predictions)\n\nprint('NO SKILL CLASSIFIER: ROC AUC=%.3f' % (ns_auc))\nprint('SVM CLASSIFIER: ROC AUC=%.3f' % (svc_auc))\n\npyplot.xlabel('False Positive Rate',fontsize=16)\npyplot.ylabel('True Positive Rate',fontsize=16)\npyplot.title(\"ROC Curve\",fontsize=18)\npyplot.legend(prop={'size':12})\npyplot.show()","b6aedaaf":"gnb_model=GaussianNB()\n\ngnb_grid = {'var_smoothing': np.logspace(0,-9, num=100)}\n\ngnb_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\ngnb_grid_search = GridSearchCV(estimator=gnb_model, param_grid=gnb_grid, n_jobs=-1, cv=gnb_cv, scoring='accuracy',error_score=0)\n\ngnb_grid_result=gnb_grid_search.fit(X_train,y_train)\n\ngnb_grid_result.best_params_","20a64a17":"gnb_grid_predictions=gnb_grid_result.predict(X_test)","b377ad8f":"print(\"GAUSSIANNB Model Performance Metrics:\")\nprint(classification_report(y_test,gnb_grid_predictions))\n\nprint(\"CONFUSION MATRIX :\")\nprint(confusion_matrix(y_test,gnb_grid_predictions))\nprint(\"\\n\")\n\nplt.figure(figsize=(12,6))\npyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill Classifier') # Let's define a no skill (Dummy) Classifier for reference.\n\nfpr, tpr, _ = roc_curve(y_test,gnb_grid_predictions)             # passing the target labels & Model Predictions to the roc_curve method. \n\npyplot.plot(fpr, tpr, marker='.', label='GAUSSIANNB CLASSIFIER')  # Plotting the obtained results.\n\nns_probs = [0 for _ in range(len(y_test))]       # generating predictions from the no skill (Dummy) classifier for reference.\n\n# Calculating Area under Curve for the No Skill & the trained Model.\nns_auc = roc_auc_score(y_test, ns_probs)             \ngnb_auc = roc_auc_score(y_test, gnb_grid_predictions)\n\nprint('NO SKILL CLASSIFIER: ROC AUC=%.3f' % (ns_auc))\nprint('GAUSSIANNB CLASSIFIER: ROC AUC=%.3f' % (gnb_auc))\n\npyplot.xlabel('False Positive Rate',fontsize=16)\npyplot.ylabel('True Positive Rate',fontsize=16)\npyplot.title(\"ROC Curve\",fontsize=18)\npyplot.legend(prop={'size':12})\npyplot.show()","e2735485":"gbc_model=GradientBoostingClassifier()\n\n#n_estimators = [10, 100, 1000]\n#gbc_n_estimators = [0.001, 0.01, 0.1]\n#gbc_subsample = [0.5, 0.7, 1.0]\n#gbc_max_depth = [3, 7, 9]\n#gbc_learning_rate = [0.0001, 0.001, 0.01, 0.1]\n\ngbc_n_estimators = [1000]\ngbc_learning_rate = [0.01]\ngbc_subsample = [0.5]\ngbc_max_depth = [7]\n\ngbc_grid = dict(learning_rate=gbc_learning_rate, n_estimators=gbc_n_estimators, subsample=gbc_subsample, max_depth=gbc_max_depth)\n\ngbc_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\ngbc_grid_search = GridSearchCV(estimator=gbc_model, param_grid=gbc_grid, n_jobs=-1, cv=gbc_cv, scoring='accuracy',error_score=0)\n\ngbc_grid_result=gbc_grid_search.fit(X_train,y_train)\n\ngbc_grid_result.best_params_","aa7910ce":"gbc_grid_predictions=gbc_grid_result.predict(X_test)","0a4c562c":"print(\"GRADIENT BOOSTING Model Performance Metrics:\")\nprint(classification_report(y_test,gbc_grid_predictions))\n\nprint(\"CONFUSION MATRIX :\")\nprint(confusion_matrix(y_test,gbc_grid_predictions))\nprint(\"\\n\")\n\nplt.figure(figsize=(12,6))\npyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill Classifier') # Let's define a no skill (Dummy) Classifier for reference.\n\nfpr, tpr, _ = roc_curve(y_test,gbc_grid_predictions)             # passing the target labels & Model Predictions to the roc_curve method. \n\npyplot.plot(fpr, tpr, marker='.', label='GRADIENT BOOSTING MODEL')  # Plotting the obtained results.\n\nns_probs = [0 for _ in range(len(y_test))]       # generating predictions from the no skill (Dummy) classifier for reference.\n\n# Calculating Area under Curve for the No Skill & the trained Model.\nns_auc = roc_auc_score(y_test, ns_probs)             \ngbc_auc = roc_auc_score(y_test, gbc_grid_predictions)\n\nprint('NO SKILL CLASSIFIER: ROC AUC=%.3f' % (ns_auc))\nprint('GRADIENT BOOSTING MODEL: ROC AUC=%.3f' % (gbc_auc))\n\npyplot.xlabel('False Positive Rate',fontsize=16)\npyplot.ylabel('True Positive Rate',fontsize=16)\npyplot.title(\"ROC Curve\",fontsize=18)\npyplot.legend(prop={'size':12})\npyplot.show()","8bb3a1ce":"xgbc_model=XGBClassifier()\n\n#n_estimators = [10,100,1000]\n#xgbc_learning_rate = [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n#xgbc_subsample = [0.3,0.4,0.5,.6,0.7,0.8,0.9]\n#xgbc_max_depth = [3, 4, 5, 6, 7, 8, 9]\n#colsample_bytree = [0.5,0.6,0.7,0.8,0.9],\n#xgbc_min_child_weight = [1, 2, 3, 4]\n\nxgbc_n_estimators = [1000]\nxgbc_learning_rate = [0.01]\nxgbc_subsample = [0.7]\nxgbc_max_depth = [8]\nxgbc_min_child_weight = [1]\n\ngrid = dict(n_estimators=xgbc_n_estimators,learning_rate=xgbc_learning_rate,subsample=xgbc_subsample,max_depth=xgbc_max_depth,\nmin_child_weight=xgbc_min_child_weight)\n\nxgbc_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\nxgbc_grid_search = GridSearchCV(estimator=xgbc_model, param_grid=grid, n_jobs=-1, cv=xgbc_cv, scoring='accuracy',error_score=0)\n\nxgbc_grid_result=xgbc_grid_search.fit(X_train,y_train)\n\nxgbc_grid_result.best_params_","15a6976b":"xgbc_grid_predictions=xgbc_grid_result.predict(X_test)","9bce5402":"print(\"EXTREME GRADIENT BOOSTING Model Performance Metrics:\")\n#print(classification_report(y_test,xgbc_grid_predictions,output_dict=True))\nprint(classification_report(y_test,xgbc_grid_predictions))\n\nprint(\"CONFUSION MATRIX :\")\nprint(confusion_matrix(y_test,xgbc_grid_predictions))\nprint(\"\\n\")\n\nplt.figure(figsize=(12,6))\npyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill Classifier') # Let's define a no skill (Dummy) Classifier for reference.\n\nfpr, tpr, _ = roc_curve(y_test,xgbc_grid_predictions)             # passing the target labels & Model Predictions to the roc_curve method. \n\npyplot.plot(fpr, tpr, marker='.', label='EXTREME GRADIENT BOOSTING MODEL')  # Plotting the obtained results.\n\nns_probs = [0 for _ in range(len(y_test))]       # generating predictions from the no skill (Dummy) classifier for reference.\n\n# Calculating Area under Curve for the No Skill & the trained Model.\nns_auc = roc_auc_score(y_test, ns_probs)             \nxgbc_auc = roc_auc_score(y_test, xgbc_grid_predictions)\n\nprint('NO SKILL CLASSIFIER: ROC AUC=%.3f' % (ns_auc))\nprint('EXTREME GRADIENT BOOSTING MODEL: ROC AUC=%.3f' % (xgbc_auc))\n\npyplot.xlabel('False Positive Rate',fontsize=16)\npyplot.ylabel('True Positive Rate',fontsize=16)\npyplot.title(\"ROC Curve\",fontsize=18)\npyplot.legend(prop={'size':12})\npyplot.show()","f360d04a":"# Model Names\nModel_Names=['LOGISTIC REGRESSION', 'RIDGE CLASSIFIER', 'DECISION TREE', 'BAGGING CLASSIFIER', 'K-NEIGHBOURS CLASSIFIER', 'RANDOM FOREST',\n            'SVM CLASSIFIER', 'GAUSSIANNB CLASSIFIER', 'GRADIENT BOOSTING', 'EXTREME GRADIENT BOOSTING']\n\n# DataFrame Index values\nIndex=['Accuracy','Precision','Recall','F1 Score','AUC Score']\n\n# Model Prediction values\nModel_Predictions=[lr_grid_predictions,rc_grid_predictions,dtc_grid_predictions,bc_grid_predictions,knc_grid_predictions,\n                   rfc_grid_predictions,svc_grid_predictions,gnb_grid_predictions,gbc_grid_predictions,xgbc_grid_predictions]\n\n# Model Metrics methods\nmodel_metrics=[accuracy_score,precision_score,recall_score,f1_score,roc_auc_score]\n\n# DataFrame Initialisation\nModel_Metrics_Comparison=pd.DataFrame(columns=Model_Names,index=Index)\n\n# Let's fill the dataframe with the model metrics values of all the trained models above.\nfor index,metric in zip(range(0,5),model_metrics):\n    for model_name,model_prediction in zip(Model_Names,Model_Predictions):\n        Model_Metrics_Comparison[model_name].values[index]=metric(y_test,model_prediction)*100\n\n# Metric values in Percentage (%).\nModel_Metrics_Comparison","b064259d":"# Model Training","843500d8":"* 1 person who hasen't received the call has enrolled themselves in the policy.\n* It can be observed that longer the call duration, more customers have enrolled themselves in the policy.\n* It may be that during longer calls with the customers, the bank officials may have gotten more time to convince the customers for \n  their enrollment.","83880510":"* About 40% of the Non-Defaulters have enrolled in the policy & 14 Defaulters have also enrolled themselves in the policy.","d6b2206d":"# Handling the Missing Values","a622abd2":"Dropping all the columns created for the purpose of visualization in the above cell along with the target label column \"CarInsurance\".","c11476bc":"* About 42% of them without a car loan have enrolled in the policy.\n* So, it's likely that more people without a car loan (about 41%) may enroll in the policy.","7e76ab64":"Highest percentage of missing data (76%) is in the \"Outcome\" field.\nLet's handle the Missing values.","e23f9fe1":"* When contacted just once, almost 46% of them have enrolled in the policy.\n* So, there's a better chance of getting the people into enrolling themselves by contacting & convincing them once or more than once in       some cases.\n* So, higher the bank tries to contact the people, they're more likely to not opt the policy.","6514c90d":"* People having secondary level of education are the highest enrollers. But, there are more rejectors than enrollers.","7c563782":"****Let's Analyze the Data****","9dfe080b":"* Almost all customers have been employed from the age of 21.\n* The oldest customers are above 90 yrs & both of them are retired.\n* Most of the Customers are in blue-collar or management Jobs & some are in technician & admin Jobs.","52b84405":"* There is a correlation of 0.5 b\/w \"DaysPassed\" & PrevAttempts.\n* There is a correlationof 0.48 b\/w \"CarInsurance\" & \"Call_Duration\".","0444c5c2":"# Data Visualization","6ae54218":"* More People who have been contacted during the months of \"March\", \"April\", \"September\", \"October\" & \"December\" have enrolled in the policy than compared with the other months. ","b5a7fd77":"# Data Preparation","d132f9d4":"# Feature Engineering","dfd05c43":"* When the call duration b\/w the customers & bank is greater than the mean call duration, more customers have enrolled themselves in the policy","8ea96004":"* Majority of the people who've Enrolled for the car insurance are in their 30s & also Majority of the rejectors are also in their 30s.\n* But Most of the people who've Enrolled range from 21 to 60 yrs of age maybe due to job securities.","a0b03fee":"* From the above dataframe, we can see that \"Extreme Gradient Boosting Classifier\" has an accuracy of 84.3% which is the highest among all\n  the trained models & also \"Random Forest Classifier\" has an accuracy of 84.1%.\n\n* As we cannot always depend only on the accuracy of models, we also need to consider other metrics such as \"Precision\", \"Recall\" & \n  \"F1 Score\" for optimal results.\n  \n* When a model has high values for both precision & recall, then it can be told that, that model is performing well.\n\n*  So in this case, out of any of the following models i.e., (\"BAGGING CLASSIFIER\", \"RANDOM FOREST CLASSIFIER\", \"GRADIENT BOOSTING\" & \n   \"EXTREME GRADIENT BOOSTING\"), we can get good results as all 4 models are having almost same Precision & Recall values.\n   \n* In the case of \"F1 Score\", as it is the weighted average of both precision & Recall Metrics, it can be more useful than Accuracy most of   the time.\n* We can also observe from the AUC Scores that, the Models \"EXTREME GRADIENT BOOSTING\", \"GRADIENT BOOSTING\" & \"RANDOM FOREST CLASSIFIER\" have good Area under Curve values.\n\n* Moving ahead, I'll try to improve the model performances and Metric results.","7426b227":"* Most of the people who've enrolled for the insurance are working in management or Technician jobs.\n* Surprisingly, unemployed members Enrolled for the insurance are more than the ones who have rejected it.","ea828f62":"**Let's Display all the Model Metrics in a dataframe for easier analysis**","75e78b32":"* Almost 40% of them who have been contacted through a cellular device have enrolled in the policy.\n* So, the probability of getting the people enrolled in the policy by contacting them through a cellular device is high.","dc36eb2e":"* More people have enrolled in the policy during the Starting & ending days of the month than compared with the middle of the month.","265a7ad2":"* Most of them having a House-Hold Insurance (1380 Customers) have rejected the car Insurance.","dd1b55b8":"**If you like my Kernel, Please Upvote. Please feel free to provide suggestions in the comments which helps me to improve myself. Thank you :)**","16f73d13":"* people who are single have enrolled for the insurance more than the divorced ones & married people are the highest group to have enrolled in it.","90ee3493":"# Visualization, EDA and Model Metrics Comparison for Car Insurance Cold Calls"}}