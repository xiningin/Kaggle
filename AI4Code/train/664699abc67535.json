{"cell_type":{"73ba9d2e":"code","f5b1d38d":"code","bcb0fea2":"code","04ac9f77":"code","a55443fd":"code","5cc7df75":"code","371ad3fc":"code","d847f34f":"code","bfc5b4f5":"code","ed5208ae":"code","721bdd21":"code","988b2263":"code","17aef5ca":"code","54674870":"code","d76b4175":"code","859efc74":"code","2e385496":"code","a27d0553":"code","157e2b5f":"code","e76dc363":"code","5bf6d8a7":"code","6f5a4e16":"code","a42766c5":"code","9bcb1661":"markdown","4ab591b9":"markdown","52636ddc":"markdown","1314e6cd":"markdown","17f60d23":"markdown","1d502a8f":"markdown","0c71443a":"markdown","4a56ac32":"markdown","1c6a766b":"markdown","98d56f8a":"markdown","ba71c62d":"markdown","bd983305":"markdown","9f2bbc9c":"markdown","d9ebdfe7":"markdown"},"source":{"73ba9d2e":"import matplotlib.pyplot as plt\nimport numpy as np\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport seaborn as sns\n\nfrom sklearn.metrics import roc_auc_score\n \nimport cv2\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, sampler, TensorDataset, random_split\nfrom torch.optim import lr_scheduler\nfrom torchvision import datasets, transforms, models\nfrom torch import utils\n\nimport  time, copy, glob, torchvision, torch, os, json, re\nfrom collections import Counter, OrderedDict\n\nfrom PIL import Image\nfrom sklearn.metrics import classification_report\n\n\nplt.rcParams['figure.figsize']=(20,10)\npy.init_notebook_mode(connected=False)\n%matplotlib inline\nprint(os.listdir('..\/input'))","f5b1d38d":"ROOT_DIR = '..\/input\/virtual-hack\/car_data\/car_data'\nTRAIN_DIR = '..\/input\/virtual-hack\/car_data\/car_data\/train'\nTEST_DIR = '..\/input\/virtual-hack\/car_data\/car_data\/test'\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nNUM_CLASSES = 196","bcb0fea2":"train_transforms = transforms.Compose([\n    transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n    transforms.RandomRotation(degrees=15),\n    transforms.RandomHorizontalFlip(),\n    transforms.CenterCrop(size=224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])])\n\nvalid_transforms = transforms.Compose([transforms.CenterCrop(size=224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])])\n\ndataset = datasets.ImageFolder(TRAIN_DIR, train_transforms)\ntest_dataset = datasets.ImageFolder(TEST_DIR, valid_transforms)","04ac9f77":"size = len(dataset)\nval_split = 0.2\ntrainset, valset = random_split(dataset, [size - int(size * val_split), int(size * val_split)])\n\ntrain_loader = DataLoader(trainset, batch_size=64, shuffle=True)\nval_loader = DataLoader(valset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)","a55443fd":"def imshow(img):\n    inverse_transform = transforms.Compose([\n      transforms.Normalize(mean = [ 0., 0., 0. ],\n                           std = [ 1\/0.229, 1\/0.224, 1\/0.225 ]),\n      transforms.Normalize(mean = [ -0.485, -0.456, -0.406 ],\n                           std = [ 1., 1., 1. ]),\n      ])\n\n    unnormalized_img = inverse_transform(img)\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n  \n\ndef visualize(): \n    dataiter = iter(train_loader)\n    images, labels = dataiter.next()\n\n    classes = dataset.classes\n    imshow(torchvision.utils.make_grid(images[:4]))\n    for j in range(4):\n        print(\"label: {},  name: {}\".format(labels[j].item(),\n                                        classes[labels[j]]))\nvisualize()","5cc7df75":"def create_model():\n    model = models.densenet121(pretrained=True)\n\n    for param in model.parameters():\n        param.requires_grad = False\n\n    n_inputs = model.classifier.in_features\n    model.classifier = nn.Sequential(\n                    nn.Linear(n_inputs, NUM_CLASSES),\n                    nn.LogSoftmax(dim=1))\n    # Move model to the device specified above\n\n    model.to(device)\n    return model","371ad3fc":"model = create_model()","d847f34f":"def get_count_per_class():\n    train_labels_count = [0]*NUM_CLASSES\n    for ind, dir in enumerate(os.listdir(TRAIN_DIR)):\n        path, dirs, files = next(os.walk(os.path.join(TRAIN_DIR, dir)))\n        file_count = len(files)\n        train_labels_count[ind] = file_count\n    return train_labels_count\n\ndef create_class_weights():\n    dataset_size = len(trainset)\n    labels_count = get_count_per_class()\n    class_weights = [1-(float(labels_count[class_id])\/dataset_size) for class_id in range(NUM_CLASSES)]\n  \n    return class_weights","bfc5b4f5":"weight=torch.FloatTensor(create_class_weights()).to(device)\ncriterion = nn.NLLLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)","ed5208ae":"dataset_sizes = {'train': len(trainset), 'valid': len(valset), 'test': len(test_dataset)}","721bdd21":"def train_model(dataloaders, model, criterion, optimizer, scheduler, num_epochs=5):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    losses = {'train': [], 'valid':[]}\n    acc = {'train': [], 'valid': []}\n  \n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch + 1, num_epochs))\n        print('-' * 10)\n\n    # Each epoch has a training and validation phase\n        for phase in ['train', 'valid']:\n            if phase == 'train':\n                scheduler.step()\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n            # forward\n            # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                    running_loss += loss.item() * inputs.size(0)\n                    running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n            losses[phase].append(epoch_loss)\n            acc[phase].append(epoch_acc)\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                      phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'valid' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n      time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","988b2263":"def save(model, path):\n    torch.save(model, path)\n\ndef load(path):\n    return torch.load(path)","17aef5ca":"model = load('..\/input\/model-saved\/car_classification_densenet_17e.pt')\ndataloaders = {'train': train_loader, 'valid': val_loader}\n# model = train_model(dataloaders, model, criterion, optimizer, exp_lr_scheduler, num_epochs=5)\n# save(model, \".\/car_classification_densenet_22e.pt\")","54674870":"confusion_matrix = torch.zeros(NUM_CLASSES, NUM_CLASSES)\n\nwith torch.no_grad():\n    accuracy = 0\n    pred_labels = []\n    pred_img_ids = []\n    true_labels = []\n    for i, (inputs, labels) in enumerate(test_loader):\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        outputs = model(inputs)\n        _, preds = torch.max(outputs, 1)\n        running_acc = torch.sum(preds == labels.data)\n        accuracy += running_acc\n        pred_labels.append(preds)\n        true_labels.append(labels)\n        \n        for t, p in zip(labels.view(-1), preds.view(-1)):\n            confusion_matrix[t.long(), p.long()] += 1\n        \n    for dir in os.listdir(TEST_DIR):\n        for file in os.listdir(os.path.join(TEST_DIR, dir)):\n            img_id = os.path.splitext(file)[0]\n            pred_img_ids.append(img_id)\n            \n    print('Accuracy =====>>', accuracy.item()\/len(test_dataset))","d76b4175":"sns.set(font_scale=1.4)#for label size\nsns.heatmap(confusion_matrix[:10, :10], annot=True,annot_kws={\"size\": 16})# font size","859efc74":"pred_labels_expanded = []\nfor l in pred_labels:\n    for l1 in l:\n        pred_labels_expanded.append(l1.item())\n\ntrue_labels_expanded = []\nfor l in true_labels:\n    for l1 in l:\n        true_labels_expanded.append(l1.item())\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelBinarizer\n\ndef multiclass_roc_auc_score(truth, pred, average=\"macro\"):\n\n    lb = LabelBinarizer()\n    lb.fit(truth)\n\n    truth = lb.transform(truth)\n    pred = lb.transform(pred)\n\n    return roc_auc_score(truth, pred, average=average)\n\nprint(\"ROC AUC SCORE: =========>\", multiclass_roc_auc_score(true_labels_expanded, pred_labels_expanded))","2e385496":"import pandas as pd\nsub_sample = pd.read_csv('..\/input\/virtual-hack\/sampleSubmission.csv')\nsub_sample.head()","a27d0553":"id_label_dict = {}\nfor id, label in zip(pred_img_ids, pred_labels_expanded):\n    id_label_dict[id] = label","157e2b5f":"od = OrderedDict(sorted(id_label_dict.items()))","e76dc363":"my_submission = pd.DataFrame()","5bf6d8a7":"my_submission['Id'] = od.keys()\nmy_submission['Predicted'] = od.values()","6f5a4e16":"my_submission.head()","a42766c5":"my_submission.to_csv('my_submission.csv', index=False)","9bcb1661":"## Step 8: Predicting Labels for the Test Images","4ab591b9":"## Step 2: Creating the Datasets and Defining DataLoaders","52636ddc":"# Note: I am busy this weekend so I don't have the time to write very clean code, I'll try to make it as clean as possible if I get enough time","1314e6cd":"## Step 10: Calculating the AUC Score","17f60d23":"## Step 7: Training the Model","1d502a8f":"## Step 3: Visualizing the Dataset","0c71443a":"## Summary of the Model:\n    - Model Used: Densenet 121 Pretrained\n    - Loss: NLLLoss\n    - Optimizer: Adam\n    - Learning Rate: 0.1 till 17 epochs, then 0.001\n    - Epochs Trained: 22\n    - Although this kernel won't show the training loss as I've trained the model on Colab and imported in Kaggle","4a56ac32":"## Step 4: Defining the Model","1c6a766b":"### Step 5: Defining the Loss Function using weights according to the class","98d56f8a":"## Step 11: Creating the Predictions CSV","ba71c62d":"## Step 1: Importing the Libraries","bd983305":"## Step 6: Defining the Train Function","9f2bbc9c":"## Step 9: Visualizing the Confusion Matrix","d9ebdfe7":"### Save and Load Functions"}}