{"cell_type":{"584c0b86":"code","aaf26681":"code","db194593":"code","34844cfc":"code","d6f60cab":"code","05609008":"code","892b4eae":"code","d7eb53f8":"code","b83c267e":"code","5e4b2c77":"code","189ceac5":"code","4f203d75":"code","2d73646c":"code","18271ac9":"code","7793f501":"code","ed2eb340":"code","e9da756a":"code","803a6742":"code","d9adb381":"code","74668251":"code","0a18bf13":"code","36b357e2":"code","5edec1fa":"code","954702f1":"code","e378eec9":"code","71cb6771":"code","c7ea5798":"code","23ac34e2":"code","ac75ca8a":"code","5f7fd53d":"code","f9003c55":"code","39efc3b5":"code","329a1859":"code","21edf308":"code","9ed2ea5d":"code","8b972125":"code","b1796bd0":"code","4e214f34":"code","56ea1af4":"code","b65f73b5":"markdown","7ca476e7":"markdown","b80b0db9":"markdown","6d0d8342":"markdown","1c3bf969":"markdown","b78e5232":"markdown","ef784d73":"markdown","107f6a78":"markdown","9f581c6f":"markdown","9c15ada7":"markdown","8dddc478":"markdown","14209a88":"markdown","2d799c52":"markdown","882173ad":"markdown","d6efddf6":"markdown"},"source":{"584c0b86":"import numpy as np # linear algebra\nimport pandas as pd\npd.set_option(\"display.max_rows\", 101)\nimport os\nprint(os.listdir(\"..\/input\"))\nimport cv2\nimport json\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.rcParams[\"font.size\"] = 15\nimport seaborn as sns\nfrom collections import Counter\nfrom PIL import Image\nimport math\nimport seaborn as sns","aaf26681":"input_dir = \"..\/input\/\"","db194593":"def classid2label(class_id):\n    category, *attribute = class_id.split(\"_\")\n    return category, attribute","34844cfc":"def print_dict(dictionary, name_dict):\n    print(\"{}{}{}{}{}\".format(\"rank\".ljust(5), \"id\".center(8), \"name\".center(40), \"amount\".rjust(10), \"ratio(%)\".rjust(10)))\n    all_num = sum(dictionary.values())\n    for i, (key, val) in enumerate(sorted(dictionary.items(), key=lambda x: -x[1])):\n        print(\"{:<5}{:^8}{:^40}{:>10}{:>10.3%}\".format(i+1, key, name_dict[key], val, val\/all_num))","d6f60cab":"def print_img_with_labels(img_name, labels, category_name_dict, attribute_name_dict, ax):\n    img = np.asarray(Image.open(input_dir + \"train\/\" + img_name))\n    label_interval = (img.shape[0] * 0.9) \/ len(labels)\n    ax.imshow(img)\n    for num, attribute_id in enumerate(labels):\n        x_pos = img.shape[1] * 1.1\n        y_pos = (img.shape[0] * 0.9) \/ len(labels) * (num + 2) + (img.shape[0] * 0.1)\n        if(num == 0):\n            ax.text(x_pos, y_pos-label_interval*2, \"category\", fontsize=12)\n            ax.text(x_pos, y_pos-label_interval, category_name_dict[attribute_id], fontsize=12)\n            if(len(labels) > 1):\n                ax.text(x_pos, y_pos, \"attribute\", fontsize=12)\n        else:\n            ax.text(x_pos, y_pos, attribute_name_dict[attribute_id], fontsize=12)","05609008":"def print_img(img_name, ax):\n    img_df = train_df[train_df.ImageId == img_name]\n    labels = list(set(img_df[\"ClassId\"].values))\n    print_img_with_labels(img_name, labels, category_name_dict, attribute_name_dict, ax)","892b4eae":"def json2df(data):\n    df = pd.DataFrame()\n    for index, el in enumerate(data):\n        for key, val in el.items():\n            df.loc[index, key] = val\n    return df","d7eb53f8":"train_df = pd.read_csv(input_dir + \"train.csv\")","b83c267e":"train_df.head()","5e4b2c77":"with open(input_dir + \"label_descriptions.json\") as f:\n    label_description = json.load(f)","189ceac5":"print(\"this dataset info\")\nprint(json.dumps(label_description[\"info\"], indent=2))","4f203d75":"category_df = json2df(label_description[\"categories\"])\ncategory_df[\"id\"] = category_df[\"id\"].astype(int)\ncategory_df[\"level\"] = category_df[\"level\"].astype(int)\nattribute_df = json2df(label_description[\"attributes\"])\nattribute_df[\"id\"] = attribute_df[\"id\"].astype(int)\nattribute_df[\"level\"] = attribute_df[\"level\"].astype(int)","2d73646c":"print(\"Category Labels\")\ncategory_df","18271ac9":"print(\"Attribute Labels\")\nattribute_df","7793f501":"print(\"We have {} categories, and {} attributes.\".format(len(label_description['categories']), len(label_description['attributes'])))\nprint(\"Each label\u3000have ID, name, supercategory, and level.\")","ed2eb340":"train_df.head(10)","e9da756a":"image_label_num_df = train_df.groupby(\"ImageId\")[\"ClassId\"].count()","803a6742":"fig, ax = plt.subplots(figsize=(25, 7))\nx = image_label_num_df.value_counts().index.values\ny = image_label_num_df.value_counts().values\nz = zip(x, y)\nz = sorted(z)\nx, y = zip(*z)\nindex = 0\nx_list = []\ny_list = []\nfor i in range(1, max(x)+1):\n    if(i not in x):\n        x_list.append(i)\n        y_list.append(0)\n    else:\n        x_list.append(i)\n        y_list.append(y[index])\n        index += 1\nfor i, j in zip(x_list, y_list):\n    ax.text(i-1, j, j, ha=\"center\", va=\"bottom\", fontsize=13)\nsns.barplot(x=x_list, y=y_list, ax=ax)\nax.set_xticks(list(range(0, len(x_list), 5)))\nax.set_xticklabels(list(range(1, len(x_list), 5)))\nax.set_title(\"the number of labels per image\")\nax.set_xlabel(\"the number of labels\")\nax.set_ylabel(\"amout\");","d9adb381":"counter_category = Counter()\ncounter_attribute = Counter()\nfor class_id in train_df[\"ClassId\"]:\n    category, attribute = classid2label(class_id)\n    counter_category.update([category])\n    counter_attribute.update(attribute)","74668251":"len(counter_category)","0a18bf13":"len(counter_attribute)","36b357e2":"category_name_dict = {}\nfor i in label_description[\"categories\"]:\n    category_name_dict[str(i[\"id\"])] = i[\"name\"]\nattribute_name_dict = {}\nfor i in label_description[\"attributes\"]:\n    attribute_name_dict[str(i[\"id\"])] = i[\"name\"]","5edec1fa":"print(\"Category label frequency\")\nprint_dict(counter_category, category_name_dict)","954702f1":"print(\"Attribute label frequency\")\nprint_dict(counter_attribute, attribute_name_dict)","e378eec9":"train_df.ClassId.max()","71cb6771":"attribute_num_dict = {}\nnone_key = str(len(counter_attribute))\nk = list(map(str, range(len(counter_attribute) + 1)))\nv = [0] * (len(counter_attribute) + 1)\nzipped = zip(k, v)\ninit_dict = dict(zipped)\nfor class_id in train_df[\"ClassId\"].values:\n    category, attributes = classid2label(class_id)\n    if category not in attribute_num_dict.keys():\n        attribute_num_dict[category] = init_dict.copy()\n    if attributes == []:\n        attribute_num_dict[category][none_key] += 1\n        continue\n    for attribute in attributes:\n        attribute_num_dict[category][attribute] += 1","c7ea5798":"fig, ax = plt.subplots(math.ceil(len(counter_category)\/2), 2,\\\n                       figsize=(8*2, 6*math.ceil(len(counter_category)\/2)), sharey=True)\nfor index, key in enumerate(sorted(map(int, attribute_num_dict.keys()))):\n    x = list(map(int, attribute_num_dict[str(key)].keys()))\n    total = sum(attribute_num_dict[str(key)].values())\n    y = list(map(lambda x: x \/ total, attribute_num_dict[str(key)].values()))\n    sns.barplot(x, y, ax=ax[index\/\/2, index%2])\n    ax[index\/\/2, index%2].set_title(\"category:{}({})\".format(key, category_name_dict[str(key)]))\n    ax[index\/\/2, index%2].set_xticks(list(range(0, int(none_key), 5)))\n    ax[index\/\/2, index%2].set_xticklabels(list(range(0, int(none_key), 5)))\nprint(\"the ratio of attribute per category(x=92 means no attribute)\")","23ac34e2":"print(\"The number of training image is {}.\".format(len(os.listdir(\"..\/input\/train\/\"))))\nprint(\"The number of test image is {}.\".format(len(os.listdir(\"..\/input\/test\/\"))))","ac75ca8a":"image_shape_df = train_df.groupby(\"ImageId\")[\"Height\", \"Width\"].first()","5f7fd53d":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\nax1.hist(image_shape_df.Height, bins=100)\nax1.set_title(\"Height distribution\")\nax2.hist(image_shape_df.Width, bins=100)\nax2.set_title(\"Width distribution\");","f9003c55":"img_name = image_shape_df.Height.idxmin()\nheight, width = image_shape_df.loc[img_name, :]\nprint(\"Minimam height image is {},\\n(H, W) = ({}, {})\".format(img_name, height, width))\nfig, ax = plt.subplots()\nprint_img(img_name, ax)","39efc3b5":"img_name = image_shape_df.Height.idxmax()\nheight, width = image_shape_df.loc[img_name, :]\nprint(\"Maximum height image is {},\\n(H, W) = ({}, {})\".format(img_name, height, width))\nfig, ax = plt.subplots()\nprint_img(img_name, ax)","329a1859":"img_name = image_shape_df.Width.idxmin()\nheight, width = image_shape_df.loc[img_name, :]\nprint(\"Minimam width image is {},\\n(H, W) = ({}, {})\".format(img_name, height, width))\nfig, ax = plt.subplots()\nprint_img(img_name, ax)","21edf308":"img_name = image_shape_df.Width.idxmax()\nheight, width = image_shape_df.loc[img_name, :]\nprint(\"Maximum width image is {},\\n(H, W) = ({}, {})\".format(img_name, height, width))\nfig, ax = plt.subplots()\nprint_img(img_name, ax)","9ed2ea5d":"pallete =  [\n    'Pastel1', 'Pastel2', 'Paired', 'Accent', 'Dark2',\n    'Set1', 'Set2', 'Set3', 'tab10', 'tab20', 'tab20b', 'tab20c']\n\n\ndef make_mask_img(segment_df):\n    category_num = len(counter_category)\n    seg_width = segment_df.at[0, \"Width\"]\n    seg_height = segment_df.at[0, \"Height\"]\n    seg_img = np.full(seg_width*seg_height, category_num-1, dtype=np.uint8)\n    for encoded_pixels, class_id in zip(segment_df[\"EncodedPixels\"].values, segment_df[\"ClassId\"].values):\n        pixel_list = list(map(int, encoded_pixels.split(\" \")))\n        for i in range(0, len(pixel_list), 2):\n            start_index = pixel_list[i] - 1\n            index_len = pixel_list[i+1] - 1\n            seg_img[start_index:start_index+index_len] =\\\n                int(int(class_id.split(\"_\")[0]) \/ (category_num-1) * 255)\n    seg_img = seg_img.reshape((seg_height, seg_width), order='F')\n    return seg_img\n\n\ndef train_generator(df, batch_size):\n    img_ind_num = df.groupby(\"ImageId\")[\"ClassId\"].count()\n    index = df.index.values[0]\n    trn_images = []\n    seg_images = []\n    for i, (img_name, ind_num) in enumerate(img_ind_num.items()):\n        img = cv2.imread(\"..\/input\/train\/\" + img_name)\n        segment_df = (df.loc[index:index+ind_num-1, :]).reset_index(drop=True)\n        index += ind_num\n        if segment_df[\"ImageId\"].nunique() != 1:\n            raise Exception(\"Index Range Error\")\n        seg_img = make_mask_img(segment_df)\n        \n        # HWC -> CHW\n        img = img.transpose((2, 0, 1))\n        \n        trn_images.append(img)\n        seg_images.append(seg_img)\n        if((i+1) % batch_size == 0):\n            return trn_images, seg_images","8b972125":"def cv2plt(img, isColor=True):\n    original_img = img\n    original_img = original_img.transpose(1, 2, 0)\n    original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n    return original_img","b1796bd0":"original, segmented = train_generator(train_df, 6)\nfig, ax = plt.subplots(3, 2, figsize=(16, 18))\nfor i, (img, seg) in enumerate(zip(original, segmented)):\n    ax[i\/\/2, i%2].imshow(cv2plt(img))\n    seg[seg == 45] = 255\n    ax[i\/\/2, i%2].imshow(seg, cmap='tab20_r', alpha=0.6)\n    ax[i\/\/2, i%2].set_title(\"Sample {}\".format(i))","4e214f34":"sample_df = pd.read_csv(input_dir + \"sample_submission.csv\")","56ea1af4":"sample_df.head(20)","b65f73b5":"* label_descriptions.json  \nA file giving the apparel categories and fine-grained attributes descriptions.","7ca476e7":"Wow!  \nMany category don't have any attribute.  ","b80b0db9":"# Check Image data\nLet's check the number of image!","6d0d8342":"# check Text Data\n* train.csv  \nTraining annotations, contains images with both segmented apparel categories and fine-grained attributes; and images with segmented apparel categories only.\n\n    * `ImageID` : the unique Id of an image\n    * `EncodedPixels` : masks in **run-length encoded format** (please refer to [evaluation page](https:\/\/www.kaggle.com\/c\/imaterialist-fashion-2019-FGVC6\/overview\/evaluation) for details).  \n        * `run-length encoded format` : In summary, '1 3 10 5' implies pixels 1,2,3,10,11,12,13,14 are to be included in the mask.  \n        (The pixels are one-indexed and numbered from top to bottom, then left to right: 1 is pixel (1,1), 2 is pixel (2,1), etc.)\n    * `ClassId` : the class id for this mask. We concatenate both category and attributes (if any) together.","1c3bf969":"Next, let's show segmented images.  ","b78e5232":"Let's check image size!","ef784d73":"# Sample Submission","107f6a78":"Most image have about 1-17 labels.  \nBut some image have too many labels about over 20.  \nMax label in a image is 74!  ","9f581c6f":"# Let's segment a variety of clothing types!\n# import modules and define utils","9c15ada7":"We have 46 categories, and 92 attributes.  \nEach label have ID, name, supercategory, and level.  \nI do not know what **level** represents.  \n\nLet's check the number of labels in each images and look some images!  ","8dddc478":"# Thank you for watching!\nPlease tell me if i make a mistake.  \nI hope this kernel will help.  \n","14209a88":"A image have some ClassID.  \nNext, check the label description.  \nAfter that, let's check the number of labels in each images and look some images.  ","2d799c52":"All kinds of label is in the train dataset.  ","882173ad":"I have to pay enough attention to `ClassId`.  \n`ClassId` is represented\u3000by concatenated both category and attributes (if any) together.  \nSo, we need to predict category and attribute (if any).  \nAll `ClassId` have one category and 0 or more attributes.  \n\n9_9_20_43_61_91 means `category: 9`, `attributes: 9, 20, 43, 61, and 91`  \nyou can see this information in competition [Overview\/Evaluation\/ClassId](https:\/\/www.kaggle.com\/c\/imaterialist-fashion-2019-FGVC6\/overview\/evaluation).  \n\nLet's check the ratio of attribute per category.  ","d6efddf6":"Category of 17% in training set is `sleeve`.  \nLeast category is `leg warmer`(112\/0.034%).But 112 images, not too few.  \nAttribute of 15% in training set is `symmetrical`.  \nLeast attribute is `burnout`(3\/0.004%). OMG....only 3  "}}