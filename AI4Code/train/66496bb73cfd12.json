{"cell_type":{"7d1f80f5":"code","cf3baf19":"code","29d86e55":"code","6a60d2d4":"code","2ccfdab1":"code","e499128f":"code","647a4384":"code","77007435":"code","6b1c4d27":"code","72d7f8d9":"code","9c23ccd8":"code","c994f309":"code","dc80b37d":"code","502282a0":"code","aa307779":"code","d681ba54":"code","e6606882":"code","54ef10ad":"code","1a849ea1":"code","958a0ba1":"code","36dc5cf3":"code","75027a7b":"code","a7ec9070":"code","edcbbe01":"code","73af0df4":"code","522f9a35":"code","529ad8ac":"code","ea2ca2da":"code","aa4fe2c0":"code","8f1b2a27":"code","7a04f260":"code","6f1f5d4d":"markdown","28b44784":"markdown","5701eee9":"markdown","344db735":"markdown","e10e4a0a":"markdown","022f48cb":"markdown","9bcae2a6":"markdown","0afee764":"markdown","de5aee34":"markdown","adbfe4fa":"markdown","650609c7":"markdown","0ae3f386":"markdown","c02d6134":"markdown"},"source":{"7d1f80f5":"# AdamW(lr=1e-3) CosineLR(epoch=40, min=1e-7) CE loss\n# iaa.Cutout(0.7) 320x512\n# 1 outputs with dropout + 1 output without dropout","cf3baf19":"!nvidia-smi","29d86e55":"USE_COLAB, TRAIN_MODE, USE_TPU = 0, 1, 0\nversion_name = 'v16'\nnetwork_name = 'efficientnet_b4'  # \u7528\u4f5c\u4fdd\u5b58\u6a21\u578b\u65f6\u7684\u540d\u5b57","6a60d2d4":"if USE_TPU:\n    !curl https:\/\/raw.githubusercontent.com\/pytorch\/xla\/master\/contrib\/scripts\/env-setup.py -o pytorch-xla-env-setup.py\n    !python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev\n\n    import torch_xla\n    import torch_xla.core.xla_model as xm\n    import torch_xla.distributed.data_parallel as dp\n    import torch_xla.distributed.parallel_loader as pl\n    import torch_xla.distributed.xla_multiprocessing as xmp","2ccfdab1":"import os, shutil, sys, time, gc\nimport copy, multiprocessing, functools\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm as tqdmauto\nfrom PIL import Image\nfrom collections import OrderedDict\n\nimport math, cv2, sklearn\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.utils import model_zoo\nfrom torch.utils.data import Dataset, DataLoader, RandomSampler\nfrom sklearn.model_selection import StratifiedKFold\n\nif not USE_COLAB:\n    print(os.listdir('..\/input\/'))\n    # PATH = '..\/input\/plant-pathology-2020-images-just-resize\/'\n    PATH = '..\/input\/plant-pathology-image-processing\/'\n    SAVE_PATH = '.\/'  # \u6a21\u578b\u8981\u4fdd\u5b58\u5230\u7684\u8def\u5f84\n    MODEL_PATH = '..\/input\/plant-pathology-pytorch-gpu-model\/'\n    !git clone -q https:\/\/github.com\/welkin-feng\/ComputerVision.git\n    sys.path.append('.\/ComputerVision\/')\n    !git clone -q https:\/\/github.com\/rwightman\/pytorch-image-models.git\n    sys.path.append('.\/pytorch-image-models\/')\n    # sys.path.append('..\/input\/cvmodels\/')\n    # sys.path.append('..\/input\/pytorch-image-models\/')\n    # # for training\n    # if TRAIN_MODE:\n    #     !git clone -q https:\/\/github.com\/welkin-feng\/ComputerVision.git\n    #     sys.path.append('.\/ComputerVision\/')\n    #     !git clone -q https:\/\/github.com\/rwightman\/pytorch-image-models.git\n    #     sys.path.append('.\/pytorch-image-models\/')\n\nelse:\n    from google.colab import drive\n\n    drive.mount('\/content\/drive', force_remount=True)\n    PATH = '.\/drive\/My Drive\/Competition\/plant-pathology-2020\/plant-pathology-2020\/'\n    SAVE_PATH = f\".\/drive\/My Drive\/Competition\/plant-pathology-2020\/{version_name}_{network_name}\/\"\n    MODEL_PATH = SAVE_PATH\n    if not os.path.isdir(SAVE_PATH):\n        os.mkdir(SAVE_PATH)\n    !git clone -q https:\/\/github.com\/welkin-feng\/ComputerVision.git\n    sys.path.append('.\/ComputerVision\/')\n    !git clone -q https:\/\/github.com\/rwightman\/pytorch-image-models.git\n    sys.path.append('.\/pytorch-image-models\/')\n\nprint(\"PATH: \", os.listdir(PATH))\nprint(\"SAVE_PATH: \", os.listdir(SAVE_PATH))\nif os.path.isdir(MODEL_PATH):\n    # \u5982\u679c\u8bad\u7ec3\u4e2d\u65ad\u4e86\u5c31\u4ece\u8fd9\u91cc\u91cd\u65b0\u8bfb\u53d6\u6a21\u578b\n    print('MODEL_PATH: ', os.listdir(MODEL_PATH))\n\n# Gets the GPU if there is one, otherwise the cpu\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(DEVICE)\nrandom_seed = 644\nprint(f'random_state: {random_seed}')","e499128f":"def seed_everything(seed):\n    \"\"\"\n    Seeds basic parameters for reproductibility of results\n    \n    Arguments:\n        seed {int} -- Number of the seed\n    \"\"\"\n    # random.seed(seed)\n    # os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nif USE_TPU:\n    seed_everything(random_seed)","647a4384":"network_name = network_name\nversion_name = version_name\nDEVICE = DEVICE\nPATH = PATH\nSAVE_PATH = SAVE_PATH\nMODEL_PATH = MODEL_PATH\n\nIMAGE_FILE_NAME = ['train_images_320x512.npy', 'test_images_320x512.npy']\nIMG_SHAPE = (1365, 2048, 3)\nINPUT_IMG_SHAPE = (320, 512, 3)\nRGB_MEAN = np.array([0.40379888, 0.5128721, 0.31294255])\nRGB_STD = np.array([0.20503741, 0.18957737, 0.1883159])\n\n# train_transforms = {\n#     'mix_prob': 0.0, 'mixup_prob': 0.2, 'cutmix_prob': 0.35, 'fmix_prob': 0, \n#     'grid_prob': 0.2, 'erase_prob': 0, 'cutout_prob': 0, \n#     'cutout_ratio': (0.1, 0.5), 'cut_size': int(INPUT_IMG_SHAPE[0] * 0.7), # (0.1, 0.3), \n#     'brightness': (0.7, 1.1), 'noise_prob': 0, 'blur_prob': 0, 'drop_prob': 0, 'elastic_prob': 0,\n#     'hflip_prob': 0.1, 'vflip_prob': 0, 'scale': (0.8, 1.1), \n#     'shear': (-10, 10), 'translate_percent': (-0.15, 0.15), 'rotate': (-20, 20)\n# }\n\nn_fold = 5\n# just use one fold\nfold = (0, 1, 2, 3, 4)\nBATCH_SIZE = 16 if not USE_TPU else 64\nTEST_BATCH_SIZE = 1\naccumulation_steps = 1\nloss_weights = (1, 1)\n\nlearning_rate = 1e-3\nlr_ratio = np.sqrt(0.1)\nreduce_lr_metric = ['loss', 'score', 'both'][0]\npatience = 5\nwarm_up_steps = 1\nwarm_up_lr_factor = 0.1\nnum_classes = 4\n\nn_epochs = 50\ntrain_epochs = 50\nresume = False\npretrained = not resume","77007435":"df_train = pd.read_csv(PATH + 'train.csv')\ndf_train['class'] = np.argmax(df_train.iloc[:, 1:].values, axis=1)\n\nskf = StratifiedKFold(n_fold, shuffle = True, random_state = 644)\nfor i_fold, (train_idx, val_idx) in enumerate(skf.split(df_train, df_train['class'].values)):\n    df_train.loc[val_idx, 'fold'] = i_fold\ndf_train['fold'] = df_train['fold'].astype(int)\n\ndf_test = pd.read_csv(PATH + 'test.csv')\nsubmission = pd.read_csv(PATH + 'sample_submission.csv')","6b1c4d27":"for i_fold in range(5):\n    train_idx, valid_idx = np.where((df_train['fold'] != i_fold))[0], np.where((df_train['fold'] == i_fold))[0]\n    train_class = df_train['class'].iloc[train_idx].values.tolist()\n    val_class = df_train['class'].iloc[valid_idx].values.tolist()\n    train_class_count = {i:train_class.count(i) for i in range(4)}\n    val_class_count = {i:val_class.count(i) for i in range(4)}\n    print(f\"i_fold {i_fold} train_class count {train_class_count} val_class_count {val_class_count}\")","72d7f8d9":"class PlantPathologyDataset(Dataset):\n    def __init__(self, csv, idx, mode, transform = None, data = None):\n        self.csv = csv.reset_index(drop = True)\n        self.data = data\n        self.filepath_format = PATH + 'images\/{}.jpg'\n        self.idx = np.asarray(idx).astype('int')\n        self.mode = mode\n        self.transform = transform\n\n    def __len__(self):\n        return self.idx.shape[0]\n\n    def __getitem__(self, index):\n        index = self.idx[index]\n        if self.data is not None:\n            image = self.data[index]\n        else:\n            img_name = self.csv['image_id'].iloc[index]\n            image = cv2.imread(self.filepath_format.format(img_name))\n            if image.shape != IMG_SHAPE:\n                image = cv2.rotate(image, rotateCode = cv2.ROTATE_90_CLOCKWISE)\n        if image.shape != INPUT_IMG_SHAPE:\n            image = cv2.resize(image, INPUT_IMG_SHAPE[1::-1], interpolation = cv2.INTER_AREA)\n\n        image = image.astype('uint8')  \n        image_origin = image.copy().astype('float32')\n        image = self.transform(image).astype('float32') if self.transform is not None else image.astype('float32')\n        image, image_origin =  np.rollaxis(image, 2, 0) \/ 255, np.rollaxis(image_origin, 2, 0) \/ 255\n\n        if self.mode == 'test':\n            return torch.tensor(image)\n        else:\n            label = self.csv.iloc[index, 1:5].values.astype('float32') # len = 4\n            return torch.tensor(image), torch.tensor(image_origin), torch.tensor(label)\n\ndef get_train_val_dataloader(i_fold, transforms_train, transforms_val):\n    train_idx, valid_idx = np.where((df_train['fold'] != i_fold))[0], np.where((df_train['fold'] == i_fold))[0]\n    train_data = np.load(PATH + IMAGE_FILE_NAME[0]) if os.path.isfile(PATH + IMAGE_FILE_NAME[0]) else None\n    dataset_train = PlantPathologyDataset(df_train, train_idx, 'train', transform=transforms_train, data = train_data)\n    dataset_valid = PlantPathologyDataset(df_train, valid_idx, 'val', transform=transforms_val, data = train_data)\n    batch_size, train_sampler, drop_last = BATCH_SIZE, RandomSampler(dataset_train), False\n    if USE_TPU and xm.xrt_world_size() > 1:\n        batch_size, drop_last = BATCH_SIZE \/\/ xm.xrt_world_size(), True\n        train_sampler = torch.utils.data.distributed.DistributedSampler(\n            dataset_train, num_replicas=xm.xrt_world_size(), rank=xm.get_ordinal(), shuffle=True\n        )\n    train_loader = DataLoader(dataset_train, batch_size, sampler = train_sampler, drop_last = drop_last, num_workers=4)\n    val_loader = DataLoader(dataset_valid, TEST_BATCH_SIZE, num_workers=4, pin_memory = True)\n\n    return train_loader, val_loader\n\ndef get_test_dataloader():\n    test_data = np.load(PATH + IMAGE_FILE_NAME[1]) if os.path.isfile(PATH + IMAGE_FILE_NAME[1]) else None\n    dataset_test = PlantPathologyDataset(df_test, np.arange(len(df_test)), 'test', data = test_data)\n    test_loader = DataLoader(dataset_test, TEST_BATCH_SIZE, sampler=None, num_workers=4)\n\n    return test_loader","9c23ccd8":"from cvmodels.augment.grid_mask import GridMaskBatch\nfrom cvmodels.augment.fmix import sample_mask\n\ndef rand_bbox(img_shape, lam):\n    H, W = img_shape\n    cut_rat = np.sqrt(1. - lam)  # (1. - lam)\n    cut_w, cut_h = int(W * cut_rat), int(H * cut_rat)\n    # cx, cy = int(W * (np.random.randn()\/8+0.5)), int(H * (np.random.randn()\/8+0.5))\n    cx, cy = np.random.randint(cut_w \/\/ 4, W - cut_w \/\/ 4), np.random.randint(cut_h \/\/ 4, H - cut_h \/\/ 4)\n\n    bbx1 = np.clip(cx - cut_w \/\/ 2, 0, W)\n    bby1 = np.clip(cy - cut_h \/\/ 2, 0, H)\n    bbx2 = np.clip(cx + cut_w \/\/ 2, 0, W)\n    bby2 = np.clip(cy + cut_h \/\/ 2, 0, H)\n    return bbx1, bby1, bbx2, bby2\n\nclass MixupBatch(object):\n    def __init__(self, mixup_prob, mixup_alpha, **kwargs):\n        self.prob = mixup_prob\n        self.alpha = mixup_alpha\n\n    def set_prob(self, epoch, max_epoch):\n        self.prob = min(1., epoch \/ max_epoch)\n\n    def __call__(self, ori_img_batch, img_batch, label_batch):\n        ''' \n        ori_img_batch: torch Tensor [N, C, H, W]\n        img_batch: torch Tensor [N, C, H, W]\n        label_batch: List[Tensor[N, cls]]\n        '''\n        label_batch_mix, lam = None, 1\n        if self.alpha <= 0 or np.random.rand() > self.prob:\n            return img_batch, label_batch, label_batch_mix, lam\n\n        batch_size = ori_img_batch.shape[0]\n        # lam = np.random.beta(self.alpha, self.alpha)\n        lam = np.random.beta(self.alpha, self.alpha, batch_size)\n        lam = np.maximum(1 - lam, lam)\n        lam = torch.from_numpy(lam).view(batch_size, 1, 1, 1).to(ori_img_batch)\n        shuffled_idx = torch.randperm(batch_size)\n        ori_img_batch = lam * ori_img_batch + (1 - lam) * ori_img_batch[shuffled_idx]\n        label_batch_mix = [label[shuffled_idx] for label in label_batch]\n        # label_batch = [lam * label + (1 - lam) * label[shuffled_idx] for label in label_batch]\n\n        return ori_img_batch, label_batch, label_batch_mix, lam\n\nclass CutmixBatch(object):\n    def __init__(self, cutmix_prob, cutmix_alpha, **kwargs):\n        self.prob = cutmix_prob\n        self.alpha = cutmix_alpha\n\n    def set_prob(self, epoch, max_epoch):\n        self.prob = min(1., epoch \/ max_epoch)\n\n    def __call__(self, ori_img_batch, img_batch, label_batch):\n        ''' \n        ori_img_batch: torch Tensor [N, C, H, W]\n        img_batch: torch Tensor [N, C, H, W]\n        label_batch: List[Tensor[N, cls]]\n        '''\n        label_batch_mix, lam = None, 1\n        if self.alpha <= 0 or np.random.rand() > self.prob:\n            return img_batch, label_batch, label_batch_mix, lam\n\n        batch_size = ori_img_batch.shape[0]\n        # lam = np.random.beta(self.alpha, self.alpha)\n        lam = np.random.beta(self.alpha, self.alpha, batch_size)\n        lam = np.maximum(1 - lam, lam)\n        lam = torch.from_numpy(lam).view(batch_size, 1, 1, 1).to(ori_img_batch)\n        shuffled_idx = torch.randperm(batch_size)\n        y = ori_img_batch[shuffled_idx].clone().detach()\n        label_batch_mix = [label[shuffled_idx] for label in label_batch]\n        # label_batch = [lam * label + (1 - lam) * label[shuffled_idx] for label in label_batch]\n        for i in range(batch_size):\n            bbx1, bby1, bbx2, bby2 = rand_bbox(ori_img_batch.shape[-2:], lam[i])\n            ori_img_batch[i, :, bby1:bby2, bbx1:bbx2] = y[i, :, bby1:bby2, bbx1:bbx2]\n            lam[i] = 1 - (bbx2 - bbx1) * (bby2 - bby1) \/ np.prod(ori_img_batch.shape[-2:])\n\n        return ori_img_batch, label_batch, label_batch_mix, lam\n\nclass FMixBatch(object):\n    def __init__(self, fmix_prob, fmix_alpha=1, decay_power=3, max_soft=0.0, reformulate=False):\n        self.prob = fmix_prob\n        self.alpha = fmix_alpha\n        self.decay_power = decay_power\n        self.max_soft = max_soft\n        self.reformulate = reformulate\n\n    def set_prob(self, epoch, max_epoch):\n        self.prob = min(1., epoch \/ max_epoch)\n\n    def __call__(self, ori_img_batch, img_batch, label_batch):\n        ''' \n        ori_img_batch: torch Tensor [N, C, H, W]\n        img_batch: torch Tensor [N, C, H, W]\n        label_batch: List[Tensor[N, cls]]\n        '''\n        label_batch_mix, lam = None, 1\n        if np.random.rand() > self.prob:\n            return img_batch, label_batch, label_batch_mix, lam\n\n        size = ori_img_batch.shape[-2:]\n        lam, mask = sample_mask(self.alpha, self.decay_power, size, self.max_soft, self.reformulate)\n        mask = torch.from_numpy(mask).to(ori_img_batch)\n        shuffled_idx = torch.randperm(ori_img_batch.size(0))\n        ori_img_batch = mask * ori_img_batch + (1 - mask) * ori_img_batch[shuffled_idx]\n        label_batch_mix = [label[shuffled_idx] for label in label_batch]\n        # label_batch = [lam * label + (1 - lam) * label[shuffled_idx] for label in label_batch]\n\n        return ori_img_batch, label_batch, label_batch_mix, lam\n\nclass MixBatch(object):\n    def __init__(self, transforms_dict = None, img_mean = np.zeros(1), img_std = np.ones(1), mixup_alpha = 0.4, cutmix_alpha = 1.0, **kwargs):\n        transforms_dict = transforms_dict or {}\n        self.mix_prob = transforms_dict.get('mix_prob', 0)\n        probs = [transforms_dict.get('mixup_prob', 0), transforms_dict.get('cutmix_prob', 0),\n                 transforms_dict.get('fmix_prob', 0), transforms_dict.get('grid_prob', 0)]\n        self.probs = np.cumsum(probs)\n        cutout_ratio = transforms_dict.get('cutout_ratio', (0.05, 0.25))\n\n        self.mixup = MixupBatch(mixup_prob = 1, mixup_alpha = mixup_alpha)\n        self.cutmix = CutmixBatch(cutmix_prob = 1, cutmix_alpha = cutmix_alpha)\n        self.fmix = FMixBatch(fmix_prob = 1, fmix_alpha=1, decay_power=3, max_soft=0.0, reformulate=False)\n        self.gridmask = [GridMaskBatch(num_grid = (3, 6), rotate = 15, mode = 0, prob = 1.),\n                         GridMaskBatch(num_grid = (3, 6), rotate = 15, mode = 1, prob = 1.),\n                         GridMaskBatch(num_grid = (3, 6), rotate = 15, mode = 2, prob = 1.),]\n\n    def set_prob(self, epoch, max_epoch = 15):\n        self.mixup.set_prob(epoch, max_epoch)\n        self.cutmix.set_prob(epoch, max_epoch)\n        self.fmix.set_prob(epoch, max_epoch)\n        for gridmask in self.gridmask:\n            gridmask.set_prob(epoch, max_epoch)\n\n    def __call__(self, ori_img_batch, img_batch, label_batch):\n        label_batch_mix, lam = None, 1\n        if np.random.rand() < self.mix_prob:\n            r = np.random.rand()\n            if r < self.probs[0]:\n                return self.mixup(ori_img_batch, img_batch, label_batch)\n            elif r < self.probs[1]:\n                return self.cutmix(ori_img_batch, img_batch, label_batch)\n            elif r < self.probs[2]:\n                return self.fmix(ori_img_batch, img_batch, label_batch)\n            elif r < self.probs[3]:\n                img_batch = np.random.choice(self.gridmask)(ori_img_batch, img_batch)\n\n        return img_batch, label_batch, label_batch_mix, lam","c994f309":"transforms_train, transforms_val = None, None\nif TRAIN_MODE:\n    !pip install --upgrade -q albumentations\n    !pip install --upgrade -q imgaug\n\n    import imgaug.augmenters as iaa\n    import albumentations\n    from torchvision.transforms import transforms\n    \n    transforms_train = transforms.Compose([\n        lambda image: iaa.Sequential([\n            # iaa.Sometimes(0.08, iaa.Rot90([1, 3])),\n            iaa.Fliplr(0.5),\n            iaa.Flipud(0.5),\n        ])(image=image),\n        lambda image: albumentations.OneOf([\n            albumentations.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, p=1),\n            # albumentations.RandomResizedCrop(INPUT_IMG_SHAPE[0], INPUT_IMG_SHAPE[1], scale=(0.9, 1.1), p=1),\n        ])(image=image)['image'],\n        # lambda image: iaa.SomeOf((3, 6),[\n        #     iaa.Multiply((0.8, 1.2), per_channel = 0.5),\n        #     iaa.LinearContrast((0.8, 1.2), per_channel = 0.5), \n        #     iaa.AddToHueAndSaturation(value_hue = (-10, 10), value_saturation = (-10, 10),per_channel=True), \n        #     iaa.Sometimes(0.5, iaa.AdditiveGaussianNoise(loc=0, scale=(0.01*255, 0.1*255), per_channel=True)),\n        #     iaa.Sometimes(0.5, iaa.OneOf([iaa.GaussianBlur(sigma = (0.1, 0.5)),\n        #                                   iaa.AverageBlur(k = (2, 5))])),\n        #     iaa.Sometimes(0.3, iaa.Dropout((0.01, 0.1), per_channel=0.5)),\n        # ], random_order = True)(image=image),\n        lambda image: iaa.Sequential([\n            iaa.Sometimes(0.7, iaa.Cutout(nb_iterations=1, size=(0.6, 0.7), fill_mode=\"constant\", cval=0))\n        ])(image=image),\n    ])\n\n    # transforms_train = transforms.Compose([\n    #     lambda image: iaa.Sequential([\n    #         iaa.Sometimes(0.7, iaa.Cutout(nb_iterations=1, size=(0.6, 0.7), fill_mode=\"constant\", cval=0))\n    #     ])(image=image),\n    # ])\n\nmix = None","dc80b37d":"df_show = df_train.iloc[:100]\ndata = np.load(PATH + IMAGE_FILE_NAME[0]) if os.path.isfile(PATH + IMAGE_FILE_NAME[0]) else None\ndataset_show = PlantPathologyDataset(df_show, list(range(df_show.shape[0])), 'train', transform=transforms_train, data = data)\n\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 15, 10\nfor i in range(1):\n    f, axarr = plt.subplots(1,5)\n    for p in range(5):\n        idx = np.random.randint(0, len(dataset_show))\n        t0 = time.time()\n        img, img_org, label = dataset_show[idx]\n        # print(f\"{time.time()-t0:.4f}\")\n        axarr[p].imshow(img.transpose(0, 1).transpose(1,2).squeeze())\n        axarr[p].set_title(idx)","502282a0":"from timm.models.layers import Mish as MishJit, Swish as SwishJit\n\nclass RGBNorm(nn.Module):\n    IMAGENET_MEAN = torch.tensor((0.485, 0.456, 0.406)).view(1, 3, 1, 1)\n    IMAGENET_STD = torch.tensor((0.229, 0.224, 0.225)).view(1, 3, 1, 1)\n\n    def __init__(self, **kwargs):\n        super().__init__()\n        self.register_buffer('rgb_mean', torch.tensor(RGB_MEAN).view(1,3,1,1))\n        self.register_buffer('rgb_std', torch.tensor(RGB_STD).view(1,3,1,1))\n\n    def forward(self, x):\n        _, C, _, _ = x.shape\n        if C == 1:\n            x = x.repeat((1, 3, 1, 1))\n        x = (x - self.rgb_mean.to(x)) \/ self.rgb_std.to(x)\n        return x\n\nclass Mish(nn.Module):\n    def __init__(self, *args, **kwagrs):\n        super(Mish, self).__init__()\n\n    def forward(self,x):\n        return x.mul(F.softplus(x).tanh())\n\ndef gem(x, kernel_size, stride = None, p = 3, eps = 1e-6):\n    return F.avg_pool2d(x.clamp(min=eps).pow(p), kernel_size, stride).pow(1.\/p)\n\nclass ArcMarginProduct(nn.Module):\n    def __init__(self, in_features, out_features):\n        super().__init__()\n        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        stdv = 1. \/ math.sqrt(self.weight.size(1))\n        self.weight.data.uniform_(-stdv, stdv)\n\n    def forward(self, features):\n        cosine = F.linear(F.normalize(features), F.normalize(self.weight))\n        return cosine\n\nclass Classifier(nn.Module):\n    \"\"\"\n    backbone should output feature maps with [N, out_channel, H, W] shape,\n    backbone should have attribute `out_channel`\n    \"\"\"\n    def __init__(self, backbone, num_classes, **kwargs):\n        super().__init__()\n        self.norm = RGBNorm()\n        self.backbone = backbone\n        self.gfc = nn.Sequential(*[nn.AdaptiveAvgPool2d(1),\n                                   nn.Flatten(),\n                                   nn.Linear(backbone.out_channel, 2048),\n                                   Mish()])\n        self.dropouts = nn.ModuleList([nn.Dropout(0.5) for _ in range(5)])\n        self.metric_classify = ArcMarginProduct(2048, num_classes)\n        self.cls_head = nn.Linear(2048, num_classes)\n\n\n    def forward(self, x):\n        x = self.norm(x)\n        x = self.backbone(x)\n        x = self.gfc(x)\n        \n        for i, dropout in enumerate(self.dropouts):\n            if i == 0:\n                out = self.cls_head(dropout(x))\n            else:\n                out += self.cls_head(dropout(x))\n        out \/= len(self.dropouts)\n        metric_output = self.metric_classify(x)\n\n        return out, metric_output\n\ndef load_pretrained_model(model, model_path = '', url = '', skip = (), conversion = ()):\n    import os\n    if os.path.isfile(model_path):\n        state_dict = torch.load(model_path, map_location = 'cpu')\n        if not USE_TPU or xm.is_master_ordinal():\n            print('=> loading pretrained model {}'.format(model_path))\n    elif url != '':\n        import torch.utils.model_zoo as model_zoo\n        state_dict = model_zoo.load_url(url, progress = False, map_location = 'cpu')\n        if not USE_TPU or xm.is_master_ordinal():\n            print('=> loading pretrained model {}'.format(url))\n    else:\n        return\n\n    conversion = np.array(conversion).reshape(-1, 2) if len(conversion) else []\n    model_dict = model.state_dict()\n    pretrained_state_dict = {}\n    for ks in state_dict.keys():\n        if ks in model_dict.keys() and all(s not in ks for s in skip):\n            km = ks\n            for _km, _ks in conversion:\n                if ks == _ks:\n                    km = _km\n                    break\n            pretrained_state_dict[km] = state_dict[ks]\n    if not USE_TPU or xm.is_master_ordinal():\n        print(f\"=> loading pretrained model weight length {len(pretrained_state_dict)} \/ total_state_dict {len(state_dict)} \/ total_model_dict {len(model_dict)}\")\n    model_dict.update(pretrained_state_dict)\n    model.load_state_dict(model_dict, strict = False)","aa307779":"from cvmodels.models.efficientnet import EfficientNet\nfrom timm.models.efficientnet import _gen_efficientnet\n\ndef efficientnet_b4(pretrained = False, **kwargs):\n    if not USE_TPU or xm.is_master_ordinal():\n        print('=> create `efficientnet_b4`')\n    backbone = EfficientNet.from_name('efficientnet-b4')\n    backbone._fc = None\n    backbone.out_channel = backbone.out_channels\n    # backbone_kwargs = {'bn_eps': 1e-3, 'pad_type': 'same'}\n    # backbone = _gen_efficientnet(\n    #     'tf_efficientnet_b1', channel_multiplier=1.4, depth_multiplier=1.8, pretrained=pretrained, **backbone_kwargs)\n    # backbone.out_channel = backbone.num_features\n    backbone.forward = backbone.forward_features\n    if pretrained:\n        pretrained_file_name = ''  # 'efficientnet-b1-f1951068.pth'\n        url = 'https:\/\/github.com\/lukemelas\/EfficientNet-PyTorch\/releases\/download\/1.0\/efficientnet-b4-6ed6700e.pth'\n        load_pretrained_model(backbone, model_path = MODEL_PATH + pretrained_file_name, url = url,\n                              skip = ('.num_batches_tracked', '_fc.', ))\n    model = Classifier(backbone, num_classes)\n    return model","d681ba54":"from cvmodels.models.resnet_modified import Bottleneck, ResNet\n\ndef seresnext50_32x4d(pretrained = False, **kwargs):\n    if not USE_TPU or xm.is_master_ordinal():\n        print('=> create `seresnext50_32x4d`')\n    backbone_kwargs = dict(cardinality = 32, base_width = 4, act_layer = Mish, block_args = dict(attn_layer = 'se'))\n    backbone = ResNet(Bottleneck, [3, 4, 6, 3], in_chans = 3, **backbone_kwargs)\n    backbone.fc = None\n    backbone.out_channel, backbone.forward = backbone.num_features, backbone.forward_features\n    if pretrained:\n        pretrained_file_name = 'gluon_seresnext50_32x4d-90cf2d6e.pth'\n        url = 'https:\/\/github.com\/rwightman\/pytorch-pretrained-gluonresnet\/releases\/download\/v0.1\/gluon_seresnext50_32x4d-90cf2d6e.pth'\n        load_pretrained_model(backbone, model_path = MODEL_PATH + pretrained_file_name, url = url,\n                              skip = ('.num_batches_tracked',))\n    model = Classifier(backbone, num_classes)\n    return model","e6606882":"def cross_entropy(preds, trues, class_weights = 1.0, reduction = 'mean', **kwargs):\n    class_weights = torch.tensor(class_weights).to(preds) \n    ce_loss = -torch.sum(class_weights * trues * F.log_softmax(preds, dim = 1), dim = 1)\n    if reduction == 'mean':\n        return ce_loss.mean()\n    elif reduction == 'sum':\n        return ce_loss.sum()\n    elif reduction == 'none':\n        return ce_loss\n\ndef focol_loss(preds, trues, gamma = 2, class_weights = 1, reduction = 'mean', **kwargs):\n    ce_loss = cross_entropy(preds, trues, class_weights=class_weights, reduction = 'none')\n    alpha = torch.sum(trues * (1 - F.softmax(preds, dim = 1)) ** gamma, dim = 1)\n    pos_loss = alpha * ce_loss\n    # neg_loss = -torch.sum((trues == 0) * (1 - alpha) * probs ** gamma * torch.log(1 - probs), dim = 1)\n    if reduction == 'mean':\n        return pos_loss.mean()\n    elif reduction == 'sum':\n        return pos_loss.sum()\n    elif reduction == 'none':\n        return pos_loss\n\ndef ohem_loss(preds, trues, ohem_rate = 1, class_weights = 1, reduction = 'mean', **kwargs):\n    ohem_rate = max(0, min(1, ohem_rate))\n    ce_loss = cross_entropy(preds, trues, class_weights, reduction = 'none')\n    loss = torch.topk(ce_loss, int(ohem_rate * ce_loss.size(0)))[0] if 0 <= ohem_rate < 1 else ce_loss\n    if reduction == 'mean':\n        return torch.mean(loss)\n    elif reduction == 'sum':\n        return torch.sum(loss)\n    elif reduction == 'none':\n        return loss\n\nclass ArcFaceLoss(nn.Module):\n    def __init__(self, s=30.0, m=0.5, reduction='mean'):\n        super().__init__()\n        self.reduction = reduction\n        self.s = s\n        self.cos_m = math.cos(m)             #  0.87758\n        self.sin_m = math.sin(m)             #  0.47943\n        self.th = math.cos(math.pi - m)      # -0.87758\n        self.mm = math.sin(math.pi - m) * m  #  0.23971\n\n    def forward(self, logits, labels):\n        logits = logits.float()  # float16 to float32 (if used float16)\n        cosine = logits\n        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))  # equals to **2\n        phi = cosine * self.cos_m - sine * self.sin_m\n        phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n\n        output = (labels * phi) + ((1.0 - labels) * cosine)\n        output *= self.s\n        loss = cross_entropy(output, labels, reduction = self.reduction)\n        return loss \/ 2\n\ndef criterion(logits, metric_logits, trues, is_val = False, lam = 1, **kwargs):\n    assert len(trues) == len(logits) == len(metric_logits)\n    weights = loss_weights\n    class_weights = (1, 4, 1, 1)\n    if not is_val:\n        loss_0 = cross_entropy(logits, trues.float(), class_weights=class_weights, reduction='mean') * lam\n        loss_metric = ArcFaceLoss(reduction='mean')(metric_logits, trues.float()) * lam\n        loss = (loss_0 * weights[0] + loss_metric * weights[1]) \/ sum(weights)\n    else:\n        loss_0 = cross_entropy(logits, trues.float(), class_weights=class_weights, reduction='sum') * lam\n        loss_metric = ArcFaceLoss(reduction='sum')(metric_logits, trues.float()) * lam \n        loss = (loss_0 * weights[0] + loss_metric * weights[1]) \/ sum(weights)\n\n    return loss, (loss_0.detach(), loss_metric.detach())","54ef10ad":"from sklearn.metrics import roc_auc_score\n\ndef get_score(submission, solution):\n    roc_score = roc_auc_score(solution, submission)\n    predictions = np.argmax(submission, axis = 1)\n    trues = np.argmax(solution, axis = 1)\n    hard_idx = np.where(np.max(submission, axis = 1) <= 0.9)[0]\n    easy_idx = np.where(np.max(submission, axis = 1) > 0.9)[0]\n    score = np.mean(predictions == trues)\n    hard_score = np.mean(predictions[hard_idx] == trues[hard_idx]) if len(hard_idx) else 0\n    easy_score = np.mean(predictions[easy_idx] == trues[easy_idx]) if len(easy_idx) else 0\n\n    return roc_score, score, hard_score, easy_score\n\ndef get_each_score(submission, solution):\n    predictions = np.argmax(submission, axis = 1)\n    trues = np.argmax(solution, axis = 1)\n    roc_scores, scores, hard_scores, easy_scores = [0] * num_classes, [0] * num_classes, [0] * num_classes, [0] * num_classes\n    for i in range(num_classes):            \n        roc_scores[i] = roc_auc_score(solution.T[i], submission.T[i])\n        pred, true = predictions[trues==i], trues[trues==i]\n        hard_idx = np.where(submission[trues==i][:, i] <= 0.9)[0]\n        easy_idx = np.where(submission[trues==i][:, i] > 0.9)[0]\n        scores[i] = np.mean(pred == true)\n        hard_scores[i] = np.mean(pred[hard_idx] == true[hard_idx]) if len(hard_idx) else 0\n        easy_scores[i] = np.mean(pred[easy_idx] == true[easy_idx]) if len(easy_idx) else 0\n    roc_score, score, hard_score, easy_score = get_score(submission, solution)\n    roc_scores.insert(0, roc_score)\n    scores.insert(0, score)\n    hard_scores.insert(0, hard_score)\n    easy_scores.insert(0, easy_score)\n    return roc_scores, scores, hard_scores, easy_scores\n\ndef show_running_time(text):\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kw):\n            t0 = time.time()\n            res = func(*args, **kw)\n            print(f\"{text} time: {time.time()-t0:.1f} s\")\n            return res\n        return wrapper\n    return decorator\n            \ndef clear_cache(func):\n    @functools.wraps(func)\n    def wrapper(*args, **kw):\n        torch.cuda.empty_cache()\n        gc.collect()\n        return func(*args, **kw)\n    return wrapper\n\n@show_running_time('train')\n@clear_cache\ndef train_epoch(model, loader, device, optimizer, verbose = False):\n    model.train()\n    train_loss = []\n    optimizer.zero_grad()\n    acc_steps = accumulation_steps\n    steps = len(loader) \/\/ acc_steps * acc_steps # if not USE_TPU else None\n    progress_bar = tqdmauto(loader) if (not USE_TPU or xm.is_master_ordinal()) and verbose else None\n    for batch_idx, (img_batch, origin_img_batch, label_batch) in enumerate(loader):\n        ### mixup & cutmix & cutout\n        label_batch_mix, lam = None, 1\n        if mix is not None:\n            img_batch, label_batch, label_batch_mix, lam = mix(img_batch, origin_img_batch, label_batch)  # process from origin\n        img_batch, label_batch = img_batch.to(device), label_batch.to(device)\n        label_batch_mix = None if label_batch_mix is None else label_batch_mix.to(device)\n        lam = lam.to(device) if isinstance(lam, torch.Tensor) else lam\n        if steps is not None and batch_idx >= steps:\n            acc_steps = 1\n        logits, metric_logits = model(img_batch)\n        loss, _ = criterion(logits, metric_logits, label_batch, is_val = False, lam = lam)\n        if label_batch_mix is not None:\n            loss_mix = criterion(logits, metric_logits, label_batch_mix, is_val = False, lam = 1 - lam)\n            loss = loss + loss_mix\n        loss = loss \/ acc_steps\n        loss.backward()\n        if (batch_idx + 1) % acc_steps == 0:\n            if USE_TPU:\n                xm.optimizer_step(optimizer, barrier = True)\n            else:\n                optimizer.step()\n            optimizer.zero_grad()\n\n        loss_np = loss.detach().cpu().item() * acc_steps\n        train_loss.append(loss_np)\n        if (not USE_TPU or xm.is_master_ordinal()) and verbose and (batch_idx <= 10 or (batch_idx - 10) % verbose_step == 0):\n            progress_bar.set_postfix_str(f\"loss: {loss_np:.4f}, smooth_loss: {np.mean(train_loss[-20:]):.4f}\")\n            progress_bar.update(1 if batch_idx <= 10 else 30)\n\n    return np.asarray(train_loss).mean()\n\n# @show_running_time('val')\n@clear_cache\ndef val_epoch(model, loader, device):\n    model.eval()\n    val_loss, val_loss1, val_loss2 = 0, 0, 0\n    preds, metric_preds, trues = [], [], []\n\n    with torch.no_grad():\n        for img_batch, origin_img_batch, label_batch in loader:\n            img_batch, label_batch = img_batch.to(device), label_batch.to(device)\n\n            logits, metric_logits = model(img_batch)\n            loss, (loss1, loss2) = criterion(logits, metric_logits, label_batch, is_val = True)\n\n            val_loss += loss.detach().cpu().item()\n            val_loss1 += loss1.detach().cpu().item()\n            val_loss2 += loss2.detach().cpu().item()\n            preds.append(F.softmax(logits, dim = 1).cpu().numpy())\n            metric_preds.append(metric_logits.cpu().numpy())\n            trues.append(label_batch.cpu().numpy())\n\n    preds = np.concatenate(preds)\n    metric_preds = np.concatenate(metric_preds)\n    trues = np.concatenate(trues)\n    scores1 = get_each_score(preds, trues)\n    scores2 = get_each_score(metric_preds, trues)\n    val_result = (val_loss \/ len(trues), val_loss1 \/ len(trues), val_loss2 \/ len(trues), preds, metric_preds, trues, scores1, scores2)\n    return val_result","1a849ea1":"def resume_model(model, optimizer = None, lr_scheduler = None, resume_file_path = '', device = 'cpu'):\n    other_param = {}\n    history, last_epoch, best_val_loss, best_val_score = None, None, None, None\n    if os.path.isfile(resume_file_path):\n        checkpoint = torch.load(resume_file_path, map_location = device)\n        model.load_state_dict(checkpoint.pop('state_dict'), strict = False)\n        print(f\"load model success!  last_epoch: {checkpoint['last_epoch']}, file_path: {resume_file_path}\")\n        if optimizer is not None and lr_scheduler is not None:\n            optimizer.load_state_dict(checkpoint['optimizer'])\n            lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n            print(f\"lr: {optimizer.state_dict()['param_groups'][0]['lr']:.2e}\")\n        checkpoint.pop('optimizer', None)\n        checkpoint.pop('lr_scheduler', None)\n        other_param.update(checkpoint)\n        print(f\"cur_val_score: {other_param['cur_val_score']:.4f}, cur_val_loss: {other_param['cur_val_loss']:.4f}\\n\" +\n              f\"best_val_score: {other_param['best_val_score']:.4f}, best_val_loss: {other_param['best_val_loss']:.4f}\\n\" +\n              f\"best_epoch: {other_param['best_epoch']}, best_score_epoch: {other_param['best_score_epoch']}\\n\")\n    return model, optimizer, lr_scheduler, other_param","958a0ba1":"model_class = efficientnet_b4\n# model_class = seresnext50_32x4d","36dc5cf3":"@clear_cache\ndef train(i_fold, verbose = False):\n    device = DEVICE if not USE_TPU else xm.xla_device()\n    devices = [device] if not USE_TPU else [device]\n    lr = learning_rate if not USE_TPU else learning_rate * max(len(devices), xm.xrt_world_size())\n    batch_size = BATCH_SIZE if not USE_TPU else BATCH_SIZE \/\/ max(len(devices), xm.xrt_world_size())\n    filename = f\"{version_name}_{network_name}_fold_{i_fold}.pth\"\n    log_name = f\"log_{version_name}_{network_name}_fold_{i_fold}.txt\"\n\n    train_loader, val_loader = get_train_val_dataloader(i_fold, transforms_train, transforms_val)\n\n    model = model_class(pretrained).to(device)\n    optimizer = torch.optim.AdamW(model.parameters(), lr)\n    # optimizer = torch.optim.SGD(model.parameters(), lr,momentum=0.9, weight_decay=1e-5)\n    # if use_amp:\n    #     model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\")\n    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs, eta_min = 1e-6)\n\n    train_param = {}\n    if resume:\n        if SAVE_PATH != MODEL_PATH and os.path.isfile(MODEL_PATH + log_name):\n            shutil.copy(MODEL_PATH + log_name, SAVE_PATH + log_name)\n        model, optimizer, lr_scheduler, train_param = \\\n            resume_model(model, optimizer, lr_scheduler, MODEL_PATH + filename, device)\n    last_epoch = train_param.get('last_epoch', -1)\n    best_val_loss, best_val_score = train_param.get('best_val_loss', 2**20), train_param.get('best_val_score', 0)\n    best_epoch, best_score_epoch = train_param.get('best_epoch', -1), train_param.get('best_score_epoch', -1)\n    history = train_param.get('history', pd.DataFrame())\n\n    def save_model(model, optimizer, lr_scheduler, is_best = False, is_best_score = False):\n        model_state = {'state_dict': model.state_dict(),\n                       'last_epoch': last_epoch, 'history': history, 'i_fold': i_fold,\n                       'cur_val_loss': val_loss, 'cur_val_score': val_score,\n                       'best_val_loss': best_val_loss, 'best_val_score': best_val_score,\n                       'best_epoch': best_epoch, 'best_score_epoch': best_score_epoch,\n                       'optimizer': optimizer.state_dict(), 'lr_scheduler': lr_scheduler.state_dict()}\n        model_path = SAVE_PATH + f\"{version_name}_{network_name}_fold_{i_fold}.pth\"\n\n        if not USE_TPU:\n            torch.save(model_state, model_path)\n        elif xm.is_master_ordinal():\n            xm.save(model_state, model_path)\n        else:\n            return\n        if is_best:\n            best_model_path = SAVE_PATH + f\"{version_name}_{network_name}_fold_{i_fold}_best.pth\"\n            shutil.copy(model_path, best_model_path)\n        if is_best_score:\n            best_model_path = SAVE_PATH + f\"{version_name}_{network_name}_fold_{i_fold}_best_score.pth\"\n            shutil.copy(model_path, best_model_path)\n\n    def show_attributes():\n        attr = (f\"train_set count: {len(train_loader.dataset)} val_set count: {len(val_loader.dataset)}\\n\" +\n                f\"save_path: {SAVE_PATH}\\n\" + f\"batch_size: {batch_size}, accumulation_steps: {accumulation_steps}\\n\" +\n                f\"current lr: {optimizer.param_groups[0]['lr']:.2e}, reduce_lr_metric: {reduce_lr_metric}\\n\" +\n                f\"best_val_score: {best_val_score:.5f}, best_val_loss: {best_val_loss:.5f}\\n\" +\n                f\"best_epoch: {best_epoch}, best_score_epoch: {best_score_epoch}\\n\" +\n                f\"last_epoch: {last_epoch}, train_epochs: {train_epochs}, n_epochs: {n_epochs}\\n\")\n        if hasattr(lr_scheduler, 'num_bad_epochs'):\n            attr += f\"num_bad_epochs: {lr_scheduler.num_bad_epochs}, min_lr: {lr_scheduler.min_lrs[0]:.2e}, patience: {lr_scheduler.patience}\\n\"\n        print('\\n' + attr + '\\n')\n        return attr\n\n    try:\n        if not USE_TPU or xm.is_master_ordinal():\n            attr = show_attributes()\n        if (not USE_TPU or xm.is_master_ordinal()) and (not resume or not os.path.isfile(SAVE_PATH + log_name)):\n            content = (f\"\\nTraining fold {i_fold}\\nfilename: {filename}\\ntrain_data: {IMAGE_FILE_NAME[0]}\\n\" + \n                       f\"train_img_size: {INPUT_IMG_SHAPE}\\nbatch_size: {batch_size}\\naccumulation_steps: {accumulation_steps}\\nn_epochs: {n_epochs}\\n\"+\n                       f\"model_class: {model_class.__name__}\\noptimizer: {optimizer}\\nlr_scheduler: {lr_scheduler}\\n\")\n            content += '\\n\\n' + f\"{time.ctime()} Training start\\n\"\n            print(content)\n            with open(SAVE_PATH + log_name, 'a') as appender:\n                appender.write(content)\n        for epoch in range(last_epoch + 1, train_epochs):\n            cur_lr = optimizer.param_groups[0]['lr']\n            train_loss = train_epoch(model, train_loader, device, optimizer, verbose)\n            val_result = val_epoch(model, val_loader, device)\n            val_loss, val_loss1, val_loss2, preds, metric_preds, trues, scores1, scores2 = val_result\n\n            last_epoch, val_score = epoch, scores1[1][0]\n            is_best_loss, is_best_score = val_loss < best_val_loss, val_score > best_val_score\n            is_best = (is_best_loss or reduce_lr_metric is 'score') and (is_best_score or reduce_lr_metric is 'loss')\n            best_val_loss, best_val_score = min(val_loss, best_val_loss), max(val_score, best_val_score)\n            lr_scheduler.step()\n\n            content =( f\"{time.ctime()} Epoch {epoch}, lr: {cur_lr:.2e}, \" +\n                    f\"train loss: {train_loss:.5f}, val loss: {val_loss:.5f}, val loss1: {val_loss1:.4f}, val loss2: {val_loss2:.4f}, \" + \n                    f\"roc_score1: {scores1[0][0]:.4f}, roc_score2: {scores2[0][0]:.4f}, \" +\n                    f\"score1: {scores1[1][0]:.4f}, hard_score1: {scores1[2][0]:.4f}, easy_score1: {scores1[3][0]:.4f}, \" + \n                    f\"score2: {scores2[1][0]:.4f}, hard_score2: {scores2[2][0]:.4f}, easy_score2: {scores2[3][0]:.4f}\")\n            if is_best:\n                best_epoch, content = epoch, content + \"  => best metric\"\n            if is_best_score:\n                best_score_epoch, content = epoch, content + \"  => best score\"\n\n            if not USE_TPU or xm.is_master_ordinal():\n                print(content)\n                with open(SAVE_PATH + log_name, 'a') as appender:\n                    appender.write(content + '\\n')\n                _h = pd.DataFrame({'train_loss': [train_loss], 'val_loss': [val_loss], \n                                   'roc_score1': [scores1[0][0]], 'roc_score2': [scores2[0][0]],\n                                   'score1': [scores1[1][0]], 'score2': [scores2[1][0]]})\n                history = history.append(_h, ignore_index = True)\n                save_model(model, optimizer, lr_scheduler, is_best, is_best_score)\n                history.to_csv(SAVE_PATH + f\"history_{version_name}_fold_{i_fold}.csv\")\n\n        content = (f\"\\nbest_val_score: {best_val_score:.5f}, best_val_loss: {best_val_loss:.5f}\\n\" +\n                   f\"best_epoch: {best_epoch}, best_score_epoch: {best_score_epoch}\\n\")\n        with open(SAVE_PATH + log_name, 'a') as appender:\n            appender.write(content + '\\n')\n    finally:\n        torch.cuda.empty_cache()\n        gc.collect()\n        if not USE_TPU or xm.is_master_ordinal():\n            show_attributes()","75027a7b":"if TRAIN_MODE:\n    if DEVICE == torch.device('cuda'):\n        torch.backends.cudnn.benchmark = True\n        print('cudnn.benchmark = True')\n    if USE_TPU:\n        torch.set_default_tensor_type('torch.FloatTensor')\n    for i_fold in fold:\n        # seed_everything(random_seed)\n        train(i_fold, verbose = False)","a7ec9070":"def visualize_training_history(history, start_loc = 0):\n    history = history.loc[start_loc:]\n    plt.figure(figsize=(15,10))\n    plt.subplot(311)\n    train_loss = history['train_loss'].dropna()\n    plt.plot(train_loss.index, train_loss, label = 'train_loss')\n    plt.legend()\n\n    plt.subplot(312)\n    val_loss = history['val_loss'].dropna()\n    plt.plot(val_loss.index, val_loss, label = 'val_loss')\n    # plt.scatter(val_loss.index, val_loss)\n    plt.legend()\n\n    plt.subplot(313)\n    val_score = history['score1'].dropna()\n    plt.plot(val_score.index, val_score, label = 'score1')\n    val_score = history['score2'].dropna()\n    plt.plot(val_score.index, val_score, label = 'score2')\n    # plt.scatter(val_score.index, val_score)\n    plt.legend()\n    plt.show()","edcbbe01":"for i_fold in range(n_fold):\n    if os.path.isfile(SAVE_PATH + f\"history_{version_name}_fold_{i_fold}.csv\"):\n        history_file = SAVE_PATH + f\"history_{version_name}_fold_{i_fold}.csv\"\n    elif os.path.isfile(MODEL_PATH + f\"history_{version_name}_fold_{i_fold}.csv\"):\n        history_file = MODEL_PATH + f\"history_{version_name}_fold_{i_fold}.csv\"\n    else:\n        continue\n    print(f\"show {history_file}\")\n    history = pd.read_csv(history_file)\n    visualize_training_history(history, start_loc = 2)","73af0df4":"def get_models(model_files, model_class):\n    device = DEVICE if not USE_TPU else xm.xla_device()\n    models = []\n    params = []\n    for model_f in model_files:\n        if os.path.isfile(SAVE_PATH + model_f):\n            resume_file_path = SAVE_PATH + model_f\n        elif os.path.isfile(MODEL_PATH + model_f):\n            resume_file_path = MODEL_PATH + model_f\n        else:\n            continue\n        model = model_class()\n        model, _, _, other_params = resume_model(model, resume_file_path = resume_file_path, device = 'cpu')\n        model = model.to(device)\n        model.eval()\n        other_params['sub_mode'] = ''\n        if 'best.' in model_f:\n            other_params['sub_mode'] = '_best'\n        elif 'best_score.' in model_f:\n            other_params['sub_mode'] = '_best_score'\n        models.append(model)\n        params.append(other_params)\n    return models, params\n\n@show_running_time('test')\ndef predict(model, loader):\n    device = DEVICE if not USE_TPU else xm.xla_device()\n    model.eval()\n    preds, metric_preds = [], []\n\n    with torch.no_grad():\n        for img_batch in loader:\n            img_batch = img_batch.to(device)\n            logits, metric_logits = model(img_batch)\n            preds.append(F.softmax(logits, dim = 1).cpu().numpy())\n            metric_preds.append(metric_logits.cpu().numpy())\n\n    preds = np.concatenate(preds)\n    metric_preds = np.concatenate(metric_preds)\n\n    return preds, metric_preds","522f9a35":"def show_each_score(folds, model_files):\n    device = DEVICE if not USE_TPU else xm.xla_device()\n    models, params = get_models(model_files, model_class)\n    cv = np.mean([p['cur_val_score'] for p in params])\n    for i_fold, model, p in zip(folds, models, params):\n        _, val_loader = get_train_val_dataloader(i_fold, transforms_train, transforms_val)\n        val_result = val_epoch(model, val_loader, device)\n        val_loss, val_loss1, val_loss2, preds, metric_preds, trues, scores1, scores2 = val_result\n        print(f\"\\nFold {i_fold}, last_epoch: {p['last_epoch']}\\nval loss: {val_loss:.5f}, val loss1: {val_loss1:.4f}, val loss2: {val_loss2:.4f}\")\n        for i in range(5):\n            print(f\"{i}, roc_score1: {scores1[0][i]:.4f}, roc_score2: {scores2[0][i]:.4f}, \" +\n                    f\"score1: {scores1[1][i]:.4f}, hard_score1: {scores1[2][i]:.4f}, easy_score1: {scores1[3][i]:.4f}, \" + \n                    f\"score2: {scores2[1][i]:.4f}, hard_score2: {scores2[2][i]:.4f}, easy_score2: {scores2[3][i]:.4f}\")","529ad8ac":"model_files = [\n    f\"{version_name}_{network_name}_fold_{0}_best.pth\",\n    f\"{version_name}_{network_name}_fold_{1}_best.pth\",\n    f\"{version_name}_{network_name}_fold_{2}_best.pth\",\n    f\"{version_name}_{network_name}_fold_{3}_best.pth\",\n    f\"{version_name}_{network_name}_fold_{4}_best.pth\",\n]\nshow_each_score((0,1,2,3,4), model_files)","ea2ca2da":"@clear_cache\ndef predict_and_submission(test_loader, model_files):\n    submission1 = submission.copy()\n    submission2 = submission.copy()\n    n_fold_preds, n_fold_metric_preds = [], []\n\n    models, params = get_models(model_files, model_class)\n\n    cv = np.mean([p['cur_val_score'] for p in params])\n    sub_name = '_'.join([f\"{p['i_fold']}_{p['last_epoch']+1}ep{p['sub_mode']}\" for p in params])\n    submission_name1 = f\"{version_name}_{network_name}_{len(model_files)}_fold_submission1_cv{cv:.4f}_ifold_{sub_name}.csv\"\n    submission_name2 = f\"{version_name}_{network_name}_{len(model_files)}_fold_submission2_ifold_{sub_name}.csv\"\n    \n    with open(SAVE_PATH + f'log_{version_name}_{network_name}_submission.txt', 'a') as appender:\n        content = (f\"\\n{time.ctime()}, submission file: {submission_name1}\\n\" +\n                   f\"test_data: {IMAGE_FILE_NAME[0]}\\ntest_img_size: {INPUT_IMG_SHAPE}\\nfrom models:\\n\")\n        for s, p in zip(model_files, params):\n            content += s + f\", i_fold: {p['i_fold']}, train_epochs: {p['last_epoch']+1}ep, cur_val_score: {p['cur_val_score']:.5f}, cur_val_loss: {p['cur_val_loss']:.4f}, best_val_score: {p['best_val_score']:.5f}, best_val_loss: {p['best_val_loss']:.4f}\\n\"\n        print(content)\n        appender.write(content + '\\n\\n')\n\n    for model in models:\n        preds, metric_preds = predict(model, test_loader)\n        n_fold_preds.append(preds)\n        n_fold_metric_preds.append(metric_preds)\n\n    # dup_ids = submission[submission['image_id'].isin(['Test_1407', 'Test_829'])].index.values\n    preds = np.stack(n_fold_preds).mean(axis = 0)\n    submission1.iloc[:, 1:] = preds\n    # submission1.iloc[dup_ids, 1:5] = df_train[df_train['image_id'].isin(['Train_1703', 'Train_1505'])].iloc[:, 1:5].values\n    submission1.to_csv(SAVE_PATH + submission_name1, index=False)\n\n    # metric_preds = np.stack(n_fold_metric_preds).mean(axis = 0)\n    # submission2.iloc[:, 1:] = metric_preds\n    # submission2.iloc[dup_ids, 1:5] = df_train[df_train['image_id'].isin(['Train_1703', 'Train_1505'])].iloc[:, 1:5].values\n    # submission2.to_csv(SAVE_PATH + submission_name2, index=False)\n\n    # submission_name1 = f\"{version_name}_{network_name}_{len(model_files)}_fold_submission1_{sub_name}_max.csv\"\n    # submission_name2 = f\"{version_name}_{network_name}_{len(model_files)}_fold_submission2_{sub_name}_max.csv\"\n    # max_preds = np.stack(n_fold_preds).max(axis = 0)\n    # preds = np.stack(n_fold_preds).min(axis = 0)\n    # preds[np.arange(len(preds)), np.argmax(max_preds, axis=1)] = np.max(max_preds, axis=1)\n    # submission1.iloc[:, 1:] = preds\n    # submission1.iloc[dup_ids, 1:5] = df_train[df_train['image_id'].isin(['Train_1703', 'Train_1505'])].iloc[:, 1:5].values\n    # submission1.to_csv(SAVE_PATH + submission_name1, index=False)\n\n    # max_metric_preds = np.stack(n_fold_metric_preds).max(axis = 0)\n    # metric_preds = np.stack(n_fold_metric_preds).min(axis = 0)\n    # metric_preds[np.arange(len(metric_preds)), np.argmax(max_metric_preds, axis=1)] = np.max(max_metric_preds, axis=1)\n    # submission2.iloc[:, 1:] = metric_preds\n    # submission2.iloc[dup_ids, 1:5] = df_train[df_train['image_id'].isin(['Train_1703', 'Train_1505'])].iloc[:, 1:5].values    # submission1.to_csv(SAVE_PATH + f\"{version_name}_{network_name}_{len(model_files)}_fold_submission1_max.csv\", index=False)\n    # submission2.to_csv(SAVE_PATH + f\"{version_name}_{network_name}_{len(model_files)}_fold_submission2_max.csv\", index=False)\n    display(submission1.tail(5))","aa4fe2c0":"df_test = pd.read_csv(PATH + 'test.csv')\nsubmission = pd.read_csv(PATH + 'sample_submission.csv')\n\ntest_loader = get_test_dataloader()\n\nmodel_files = [\n    f\"{version_name}_{network_name}_fold_{0}_best.pth\",\n    f\"{version_name}_{network_name}_fold_{1}_best.pth\",\n    f\"{version_name}_{network_name}_fold_{2}_best.pth\",\n    f\"{version_name}_{network_name}_fold_{3}_best.pth\",\n    f\"{version_name}_{network_name}_fold_{4}_best.pth\",\n]\npredict_and_submission(test_loader, model_files)","8f1b2a27":"model_files = [\n    f\"{version_name}_{network_name}_fold_{0}.pth\",\n    f\"{version_name}_{network_name}_fold_{1}.pth\",\n    f\"{version_name}_{network_name}_fold_{2}.pth\",\n    f\"{version_name}_{network_name}_fold_{3}.pth\",\n    f\"{version_name}_{network_name}_fold_{4}.pth\",\n]\npredict_and_submission(test_loader, model_files)","7a04f260":"if os.path.isdir('.\/ComputerVision\/'):\n    shutil.rmtree('.\/ComputerVision\/')\nif os.path.isdir('.\/pytorch-image-models\/'):\n    shutil.rmtree('.\/pytorch-image-models\/')\nfor file in os.listdir('.\/'):\n    if any([(s in file) for s in ('torch-xla', 'torch-nightly', 'torchvision-nightly')]):\n        os.remove('.\/' + file)","6f1f5d4d":"## SEResNeXt50 32x4d","28b44784":"# Config","5701eee9":"# Model","344db735":"# Training with P100 GPU\n\nModel: EfficientNet b4\n\ninput size 320x512 (.npy files are generated by https:\/\/www.kaggle.com\/welkinfeng\/plant-pathology-generate-npy-data)\n\n**using P100 GPU: train time: 60s \/ epoch, test time: 50s**\n\n**using single core TPU (320x320 input size): train time: 3-6mins for the first epoch, 60s for rest epoch, test time: 50s** (https:\/\/www.kaggle.com\/welkinfeng\/plant-pathology-pytorch-tpu-efficientnet-b4)\n\nv3: 5 fold LB 0.968\n\nv7: use weighted CE loss","e10e4a0a":"# Train & Validate","022f48cb":"# Transform","9bcae2a6":"# Visualize training curve","0afee764":"## EfficientNet","de5aee34":"# Dataset","adbfe4fa":"# Test & Submission","650609c7":"\u8bfb\u53d6 df_train & df_test","0ae3f386":"# Train Loop","c02d6134":"# Loss Function"}}