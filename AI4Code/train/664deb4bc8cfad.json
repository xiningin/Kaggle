{"cell_type":{"a82b7824":"code","31c48258":"code","8bb595d2":"code","8864fc8c":"code","c3083dc9":"code","55be9702":"code","b22b8710":"code","a60cc2c7":"code","d2733d55":"code","a2a7f7f8":"code","b1cd6957":"code","0a4eaeea":"code","95a2ec5f":"code","81977c80":"markdown","c149e606":"markdown","25ccaaba":"markdown","1ebc64cf":"markdown"},"source":{"a82b7824":"sample = 'This movie sucks'\nfixed_size = 1024\n\nprint(sample.split())\n\nfeatures = [(hash(f)%fixed_size, 1) for f in sample.split()]\n\n# list of tuples in form (feature_index, feature_value)\nprint(features)","31c48258":"!unzip \/kaggle\/input\/word2vec-nlp-tutorial\/labeledTrainData.tsv.zip\n!unzip \/kaggle\/input\/word2vec-nlp-tutorial\/unlabeledTrainData.tsv.zip\n!unzip \/kaggle\/input\/word2vec-nlp-tutorial\/testData.tsv.zip","8bb595d2":"PATH = '\/kaggle\/working\/'","8864fc8c":"import re\nimport random\nfrom math import exp, log\nfrom datetime import datetime\nfrom operator import itemgetter # \ud0a4\uac00 \uc544\ub2cc \uac12\uc73c\ub85c max, min \uac12\uc744 \uad6c\ud560 \ub54c \uc0ac\uc6a9","c3083dc9":"def clean(s):\n    return \" \".join(re.findall(r'\\w+', s, flags=re.UNICODE)).lower()","55be9702":"def get_data_tsv(loc_dataset, opts):\n    for e, line in enumerate(open(loc_dataset, 'rb')):\n        if e > 0:\n            r = line.decode('utf-8').strip().split('\\t')\n            id = r[0]\n            \n            if opts['clean']:\n                try:\n                    r[2] = clean(r[2])\n                except:\n                    r[1] = clean(r[1])\n            \n            if len(r) == 3:\n                features = [(hash(f)%opts['D'], 1) for f in r[2].split()]\n                label = int(r[1])\n            else:\n                features = [(hash(f)%opts['D'], 1) for f in r[1].split()]\n                label = 1\n            \n            if opts['2grams']:\n                for i in range(len(features)-1):\n                    features.append(\n                        (hash(str(features[i][0])+str(features[i+1][0]))%opts['D'], 1))\n            yield label, id, features","b22b8710":"def dot_product(features, weights):\n    dotp = 0\n    for f in features:\n        dotp += weights[f[0]]*f[1]\n    return dotp","a60cc2c7":"def train_tron(loc_dataset, opts):\n    start = datetime.now()\n    print('\\nPass\\t\\tErrors\\t\\tAverage\\t\\tNr. Samples\\tSince Start')\n    \n    # \uac00\uc911\uce58 \ucd08\uae30\ud654\n    if opts['random_init']:\n        random.seed(3003)\n        weight = [random.random()] * opts['D']\n    else:\n        weights = [0.] * opts['D']\n    \n    # Running training passes\n    # \ud559\uc2b5 \uc2e4\ud589\n    for pass_nr in range(opts['n_passes']):\n        error_counter = 0\n        for e, (label, id, features) in enumerate( \\\n            get_data_tsv(loc_dataset, opts)):\n            \n            # \ud37c\uc149\ud2b8\ub860\uc740 \uc9c0\ub3c4\ud559\uc2b5 \ubd84\ub958\uae30\uc758 \uc77c\uc885\n            # \uc774\uc804 \uac12\uc5d0 \ub300\ud55c \ud559\uc2b5\uc73c\ub85c \uc608\uce21\n            # \ub0b4\uc801(dotproduct) \uac12\uc774 \uc784\uacc4 \uac12\ubcf4\ub2e4 \ub192\uac70\ub098 \ub0ae\uc740\uc9c0\uc5d0 \ub530\ub77c\n            # \ucd08\uacfc\ud558\uba74 1\uc744 \uc608\uce21\ud558\uace0 \ubbf8\ub9cc\uc774\uba74 0\uc744 \uc608\uce21\ud55c\ub2e4.\n            dp = dot_product(features, weights) > 0.5\n            \n            # \ub2e4\uc74c perceptron\uc740 \uc0d8\ud50c\uc758 \ub808\uc774\ube14\uc744 \ubcf8\ub2e4.\n            # \uc2e4\uc81c \ub808\uc774\ube14 \ub370\uc774\ud130\uc5d0\uc11c \uc704 \ud37c\uc149\ud2b8\ub860\uc73c\ub85c \uad6c\ud55c dp \uac12\uc744 \ube7c\uc900\ub2e4.\n            # \uc608\uce21\uc774 \uc815\ud655\ud558\ub2e4\uba74 error \uac12\uc740 0\uc774\uba70, \uac00\uc911\uce58\ub9cc \ub0a8\uaca8\ub454\ub2e4.\n            # \uc608\uce21\uc774 \ud2c0\ub9b0 \uacbd\uc6b0 error\uac12\uc740 1 \ub610\ub294 -1\uc774\uace0 \ub2e4\uc74c\uacfc \uac19\uc774 \uac00\uc911\uce58\ub97c \uc5c5\ub370\uc774\ud2b8 \ud55c\ub2e4.\n            # weights[feature_index] += learning_rate * error * feature_value\n            \n            error = label - dp\n            \n            # \uc608\uce21\uc774 \ud2c0\ub9b0 \uacbd\uc6b0 \ud37c\uc149\ud2b8\ub860\uc740 \ub2e4\uc74c\uacfc \uac19\uc774 \uac00\uc911\uce58\ub97c \uc5c5\ub370\uc774\ud2b8 \ud55c\ub2e4.\n            if error != 0:\n                error_counter += 1\n                # updating the weights\n                for index, value in features:\n                    weights[index] += opts['learning_rate'] * error * log(1.+value)\n        \n        # Reporting stuff\n        print('%s\\t\\t%s\\t\\t%s\\t\\t%s\\t\\t%s' % (\\\n                pass_nr+1,\n                error_counter,\n                round(1 - error_counter \/ float(e+1), 5),\n                e+1, datetime.now()-start))\n        \n        # Oh heh, we have overfit :)\n        if error_counter == 0 or error_counter < opts['errors_satisfied']:\n            print('%s erros found during training, halting' % error_counter)\n            break\n    return weights","d2733d55":"def test_tron(loc_dataset,weights,opts):\n    \"\"\"\n        output:\n                preds: list, a list with\n                [id,prediction,dotproduct,0-1normalized dotproduct]\n    \"\"\"\n    start = datetime.now()\n    print(\"\\nTesting online\\nErrors\\t\\tAverage\\t\\tNr. Samples\\tSince Start\")\n    preds = []\n    error_counter = 0\n    for e, (label, id, features) in enumerate( \\\n        get_data_tsv(loc_dataset,opts) ):\n\n        dotp = dot_product(features, weights)\n        # \ub0b4\uc801\uc774 0.5\ubcf4\ub2e4 \ud06c\ub2e4\uba74 \uae0d\uc815\uc73c\ub85c \uc608\uce21\ud55c\ub2e4.\n        dp = dotp > 0.5\n        if dp > 0.5: # we predict positive class\n            preds.append( [id, 1, dotp ] )\n        else:\n            preds.append( [id, 0, dotp ] )\n        \n        # get_data_tsv\uc5d0\uc11c \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc758 \ub808\uc774\ube14\uc744 1\ub85c \ucd08\uae30\ud654 \ud574\uc8fc\uc5c8\uc74c\n        if label - dp != 0:\n            error_counter += 1\n\n    print(\"%s\\t\\t%s\\t\\t%s\\t\\t%s\" % (\n        error_counter,\n        round(1 - error_counter \/float(e+1),5),\n        e+1,\n        datetime.now()-start))\n\n    # normalizing dotproducts between 0 and 1 \n    # \ub0b4\uc801\uc744 \uad6c\ud574 0\uacfc 1\ub85c \uc77c\ubc18\ud654 \ud55c\ub2e4.\n    # TODO: proper probability (bounded sigmoid?), \n    # online normalization\n    max_dotp = max(preds,key=itemgetter(2))[2]\n    min_dotp = min(preds,key=itemgetter(2))[2]\n    for p in preds:\n        # appending normalized to predictions\n        # \uc815\uaddc\ud654 \ub41c \uac12\uc744 \ub9c8\uc9c0\ub9c9\uc5d0 \ucd94\uac00\ud574 \uc900\ub2e4.\n        # (\ud53c\ucc98\uc640 \uac00\uc911\uce58\uc5d0 \ub300\ud55c \ub0b4\uc801\uac12 - \ucd5c\uc18c \ub0b4\uc801\uac12) \/ \ucd5c\ub300 \ub0b4\uc801\uac12 - \ucd5c\uc18c \ub0b4\uc801\uac12\n        # \uc774 \uac12\uc774 \uce90\uae00\uc5d0\uc11c 0.95\uc758 AUC\ub97c \uc5bb\uc744 \uc218 \uc788\ub294 \uac12\uc774\ub2e4.\n        p.append((p[2]-min_dotp)\/float(max_dotp-min_dotp)) \n        \n    #Reporting stuff\n    print(\"Done testing in %s\"%str(datetime.now()-start))\n    return preds","a2a7f7f8":"#Setting options\nopts = {}\nopts[\"D\"] = 2 ** 25\nopts[\"learning_rate\"] = 0.1\nopts[\"n_passes\"] = 80 # Maximum number of passes to run before halting\nopts[\"errors_satisfied\"] = 0 # Halt when training errors < errors_satisfied\nopts[\"random_init\"] = False # set random weights, else set all 0\nopts[\"clean\"] = True # clean the text a little\nopts[\"2grams\"] = True # add 2grams\n\n#training and saving model into weights\n%time \nweights = train_tron(PATH+\"labeledTrainData.tsv\",opts)","b1cd6957":"# testing and saving predictions into preds\n%time \npreds = test_tron(PATH+\"testData.tsv\",weights,opts)","0a4eaeea":"preds[:10]","95a2ec5f":"# \uce90\uae00 \uc810\uc218 \uc81c\ucd9c\uc744 \uc704\ud55c \uc11c\ube0c\ubbf8\uc158 \ud30c\uc77c\uc744 \uc791\uc131\ud55c\ub2e4.\nwith open(\"submit_perceptron.csv\",\"wb\") as outfile:\n    outfile.write('\"id\",\"sentiment\"\\n'.encode('utf-8'))\n    for p in sorted(preds):\n        outfile.write(\"{},{}\\n\".format(p[0],p[3]).encode('utf-8'))","81977c80":"## \ud504\ub85c\uadf8\ub808\uc2dc\ube0c \uac80\uc99d \uc190\uc2e4\n\ud55c \ubc88\uc5d0 \ud558\ub098\uc529 \ud45c\ubcf8\uc744 \ud559\uc2b5\ud558\uba74 \uc810\uc2e0\uc801\uc73c\ub85c train loss\uac00 \ub41c\ub2e4. \ubaa8\ub378\uc774 \ud0c0\uac9f\uc744 \ubcf4\uc9c0\uc54a\uace0 \uccab \uc0d8\ud50c\uc744 \ubcf4\uace0 \uc608\uce21\uc744 \ud55c\ub2e4. \uadf8\ub7f0 \ub2e4\uc74c \uc608\uce21\uc744 \ub300\uc0c1 \ub808\uc774\ube14\uacfc \ube44\uad50\ud558\uc5ec \uc624\ub958\uc728\uc744 \uacc4\uc0b0\ud55c\ub2e4. \uc624\ub958\uc728\uc774 \ub0ae\uc73c\uba74 \uc88b\uc740 \ubaa8\ub378\uc5d0 \uac00\uae5d\ub2e4.","c149e606":"## Data extract","25ccaaba":"## Online Learning Perceptro in Python\n\ud30c\uc774\uc36c\uc73c\ub85c \ud45c\uc900 \ub77c\uc774\ube0c\ub7ec\ub9ac\ub97c \uc0ac\uc6a9\ud574\uc11c \uc704\uc758 \ud37c\uc149\ud2b8\ub860 \uc54c\uace0\ub9ac\uc998\uc744 \uad6c\ud604\ud588\uae30 \ub54c\ubb38\uc5d0 \uc2a4\ud06c\ub9bd\ud2b8\uac00 PyPy\uc5d0\uc11c \uc2e4\ud589\ub418\uace0 3-4\ubc30\uc758 \uc18d\ub3c4\ud5a5\uc0c1\uc774 \uc788\ub2e4. \uc5ec\uae30\uc5d0 \uc0ac\uc6a9\ub41c \uc54c\uace0\ub9ac\uc998\uc740 Kaggle \ud3ec\ub7fc\uc5d0\uc11c \ucc98\uc74c \ubc1c\uacac \ub41c tinrtgu\uc758 \uc628\ub77c\uc778 \ub85c\uc9c0\uc2a4\ud2f1 \ud68c\uadc0 \uc2a4\ud06c\ub9bd\ud2b8\uc5d0\uc11c \ud070 \uc601\uac10\uc744 \uc5bb\uc5c8\ub2e4\uace0 \ud55c\ub2e4.\n\n\ub2e4\uc74c \uacbd\uc9c4\ub300\ud68c\uc5d0\uc11c Vowpal Wabbit\uc744 \ud1b5\ud55c \ud574\uc2dc\ud2b8\ub9ad\uc744 \uc0ac\uc6a9\ud558\uc600\uace0 \ucf54\ub4dc\uac00 \uacf5\uac1c\ub418\uc5b4 \uc788\ub2e4.\n\nDisplay Advertising Challenge - Kaggle, Beat the benchmark with less then 200MB of memory.\n\ucf54\ub4dc : https:\/\/kaggle2.blob.core.windows.net\/forum-message-attachments\/53646\/1539\/fast_solution.py","1ebc64cf":"## \ud574\uc2f1 \ud2b8\ub9ad\n\ubca1\ud130\ud654 \ud574\uc2f1\ud2b8\ub9ad\uc740 Vowpal Wabbit(John Langford)\uc5d0\uc11c \uc2dc\uc791\ub418\uc5c8\ub2e4. \uc774 \ud2b8\ub9ad\uc740 \ud37c\uc149\ud2b8\ub860\uc73c\ub85c \ub4e4\uc5b4\uc624\ub294 \uc5f0\uacb0 \uc218\ub97c \uace0\uc815 \ub41c \ud06c\uae30\ub85c \uc124\uc815\ud55c\ub2e4. \uace0\uc815 \ub41c \ud06c\uae30\ubcf4\ub2e4 \ub0ae\uc740 \uc22b\uc790\ub85c \ubaa8\ub4e0 \uc6d0\uc2dc \ud53c\ucc98\ub97c \ud574\uc2f1\ud55c\ub2e4. Vowpal Wabbit\uc740 \ubaa8\ub4e0 \ub370\uc774\ud130\ub97c \uba54\ubaa8\ub9ac\ub85c \uc77d\uc5b4\ub4e4\uc774\uc9c0 \uc54a\uace0 \ubaa8\ub378\uc744 \ud6c8\ub828\uc2dc\ud0ac \uc218 \uc788\ub294 \ube60\ub978 \uba38\uc2e0\ub7ec\ub2dd \ub77c\uc774\ube0c\ub7ec\ub9ac\ub2e4."}}