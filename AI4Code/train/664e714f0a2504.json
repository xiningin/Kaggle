{"cell_type":{"44a9e0b6":"code","0e87b74f":"code","121f400d":"code","36bcebe8":"code","8d8dcde8":"code","1578d46a":"code","ef198ced":"code","e8b48aaa":"code","15abb0b3":"code","35b2afca":"code","d0cb1b44":"code","cb2ef535":"code","db308129":"code","4fb4ac18":"code","3ad2cf7c":"code","1cee1c14":"code","af04a54f":"code","a01926fd":"code","a1164233":"code","e1abb485":"code","18e8ec90":"code","f5379338":"code","52ec709e":"code","7cd52749":"code","f61fa8c3":"code","f19ce0e7":"code","d94d0f28":"code","2b757c6f":"code","4c28fef2":"code","3f03f29f":"code","06604da3":"code","f0b29b70":"code","fa0a6ca5":"code","ccb3a7fa":"code","9b4d7ffd":"code","853c6750":"code","9f6c5434":"code","3eeb05ea":"markdown","cb14d7b3":"markdown","8b5509ab":"markdown","030827c8":"markdown","7501ea59":"markdown","4b5a2fbf":"markdown","b9b47ed9":"markdown","6e8e4100":"markdown","966223fd":"markdown","a7bdd8f7":"markdown","5fe05514":"markdown","52248e51":"markdown","3c882ddf":"markdown","69371b67":"markdown","3405515d":"markdown","40d6eefc":"markdown"},"source":{"44a9e0b6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nsns.set()\nimport numpy as np # linear algebra\n # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import  Input, Conv2D, MaxPooling2D,GlobalMaxPooling2D, Flatten, Dense, GlobalAveragePooling2D, Activation, MaxPool2D, AvgPool2D, Dropout, Conv1D, MaxPooling1D\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\nfrom tensorflow.keras.applications import DenseNet121, VGG19, ResNet50\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom IPython.display import display, Image\nimport matplotlib.pyplot as mpimg\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.utils import shuffle\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0e87b74f":"train_df = pd.read_csv('..\/input\/coronahack-chest-xraydataset\/Chest_xray_Corona_Metadata.csv')","121f400d":"train_df.head(5)","36bcebe8":"missing_vals = train_df.isnull().sum()\nmissing_vals.plot(kind = 'bar')","8d8dcde8":"train_df.dropna(how = 'all')\ntrain_df.isnull().sum()","1578d46a":"train_data = train_df[train_df['Dataset_type'] == 'TRAIN']\ntest_data = train_df[train_df['Dataset_type'] == 'TEST']\nassert train_data.shape[0] + test_data.shape[0] == train_df.shape[0]\nprint(f\"Shape of train data : {train_data.shape}\")\nprint(f\"Shape of test data : {test_data.shape}\")\ntest_data.sample(10)","ef198ced":"train_fill = train_data.fillna('unknown')\ntest_fill = test_data.fillna('unknown')\ndisplay(train_fill.head(5))","e8b48aaa":"# Count plot for 3 attributes with unknown variable addition\ntargets = ['Label', 'Label_2_Virus_category', 'Label_1_Virus_category']\nfig, ax = plt.subplots(2,2, figsize=(20, 10))\nsns.countplot(x=targets[0], data=train_fill, ax=ax[0, 0])\nsns.countplot(x=targets[1], data=train_fill, ax=ax[0, 1])\nsns.countplot(x=targets[2], data=train_fill, ax=ax[1, 0])\nplt.show()","15abb0b3":"test_img_dir = '\/kaggle\/input\/coronahack-chest-xraydataset\/Coronahack-Chest-XRay-Dataset\/Coronahack-Chest-XRay-Dataset\/test'\ntrain_img_dir = '\/kaggle\/input\/coronahack-chest-xraydataset\/Coronahack-Chest-XRay-Dataset\/Coronahack-Chest-XRay-Dataset\/train'\n\nassert os.path.isdir(test_img_dir) == True\nassert os.path.isdir(train_img_dir) == True\n\nsample_train_images = list(os.walk(train_img_dir))[0][2][:8]\nsample_train_images = list(map(lambda x: os.path.join(train_img_dir, x), sample_train_images))\n\nsample_test_images = list(os.walk(test_img_dir))[0][2][:8]\nsample_test_images = list(map(lambda x: os.path.join(test_img_dir, x), sample_test_images))","35b2afca":"from PIL import Image\nplt.figure(figsize = (17,17))\nfor iterator, filename in enumerate(sample_train_images):\n    image = Image.open(filename)\n    plt.subplot(4,2,iterator+1)\n    plt.imshow(image)\n\nplt.tight_layout()","d0cb1b44":"plt.figure(figsize = (17,17))\nfor iterator, filename in enumerate(sample_test_images):\n    image = Image.open(filename)\n    plt.subplot(4,2,iterator+1)\n    plt.imshow(image)\n\nplt.tight_layout()","cb2ef535":"fig, ax = plt.subplots(4, 2, figsize=(17, 17))\n\n\ncovid_path = train_data[train_data['Label_2_Virus_category']=='COVID-19']['X_ray_image_name'].values\n\nsample_covid_path = covid_path[:4]\nsample_covid_path = list(map(lambda x: os.path.join(train_img_dir, x), sample_covid_path))\n\nfor row, file in enumerate(sample_covid_path):\n    image = plt.imread(file)\n    ax[row, 0].imshow(image)\n    ax[row, 1].hist(image.ravel(), 256, [0,256])\n    ax[row, 0].axis('off')\n    if row == 0:\n        ax[row, 0].set_title('Images')\n        ax[row, 1].set_title('Histograms')\nfig.suptitle('Label 2 Virus Category = COVID-19', size=16)\nplt.show()","db308129":"fig, ax = plt.subplots(4, 2, figsize=(17, 17))\n\n\nnormal_path = train_data[train_data['Label']=='Normal']['X_ray_image_name'].values\n\nsample_normal_path = normal_path[:4]\nsample_normal_path = list(map(lambda x: os.path.join(train_img_dir, x), sample_normal_path))\n\nfor row, file in enumerate(sample_normal_path):\n    image = plt.imread(file)\n    ax[row, 0].imshow(image)\n    ax[row, 1].hist(image.ravel(), 256, [0,256])\n    ax[row, 0].axis('off')\n    if row == 0:\n        ax[row, 0].set_title('Images')\n        ax[row, 1].set_title('Histograms')\nfig.suptitle('Label = NORMAL', size=16)\nplt.show()","4fb4ac18":"final_train_data = train_data[(train_data['Label'] == 'Normal') | \n                              ((train_data['Label'] == 'Pnemonia') & (train_data['Label_2_Virus_category'] == 'COVID-19'))]\n\n\n# Create a target attribute where value = positive if 'Pnemonia + COVID-19' or value = negative if 'Normal'\nfinal_train_data['target'] = ['negative' if holder == 'Normal' else 'positive' for holder in final_train_data['Label']]\n\nfinal_train_data = shuffle(final_train_data, random_state=1)\n\nfinal_validation_data = final_train_data.iloc[1000:, :]\nfinal_train_data = final_train_data.iloc[:1000, :]\n\nprint(f\"Final train data shape : {final_train_data.shape}\")\nfinal_train_data.sample(10)","3ad2cf7c":"train_image_generator = ImageDataGenerator(\n    rescale=1.\/255,\n    validation_split = 0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n)\n\ntrain_generator = train_image_generator.flow_from_dataframe(\n    dataframe=final_train_data,\n    directory=train_img_dir,\n    x_col='X_ray_image_name',\n    y_col='target',\n    target_size=(224, 224),\n    batch_size=16,\n    seed=2020,\n    shuffle=True,\n    class_mode='binary'\n)\n\nvalidation_generator = train_image_generator.flow_from_dataframe(\n    dataframe=final_validation_data,\n    directory=train_img_dir,\n    x_col='X_ray_image_name',\n    y_col='target',\n    target_size=(224, 224),\n    batch_size=16,\n    seed=2020,\n    shuffle=True,\n    class_mode='binary'\n)\n","1cee1c14":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape= (224,224,3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n\nmodel.add(Conv2D(64,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(Conv2D(250,(3,3)))\nmodel.add(Dropout(0.5))\nmodel.add(Activation(\"relu\"))\n  \nmodel.add(Conv2D(128,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(AvgPool2D(2,2))\nmodel.add(Conv2D(64,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(AvgPool2D(2,2))\n\nmodel.add(Conv2D(256,(2,2)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPool2D(2,2))\n    \nmodel.add(Flatten())\nmodel.add(Dense(32))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))\nmodel.add(Activation(\"sigmoid\"))","af04a54f":"model.summary()","a01926fd":"callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)","a1164233":"BATCH_SIZE = 16\nEPOCHS = 30","e1abb485":"model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\nhistory = model.fit(train_generator,\n                              steps_per_epoch = train_generator.samples \/\/BATCH_SIZE,\n                              validation_data=validation_generator,\n                              epochs=EPOCHS,\n                              validation_steps= validation_generator.samples \/\/BATCH_SIZE,\n                              callbacks = [callbacks]\n                                     )","18e8ec90":"plt.figure(figsize=(17,17))\nplt.subplot(2, 2, 1)\nplt.plot(history.history['loss'], label='Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend()\nplt.title('Training - Loss Function')\n\nplt.subplot(2, 2, 2)\nplt.plot(history.history['accuracy'], label='Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend()\nplt.title('Train - Accuracy')\n\nplt.legend()\nplt.title('Metrics estimations')\n","f5379338":"mob_model = Sequential()\nmob_model.add(tf.keras.applications.MobileNetV2(include_top=False, pooling = 'avg', weights='imagenet',input_shape=(224, 224, 3), classes=2))\nmob_model.add(Dense(32, activation='relu'))\nmob_model.add(Dense(1, activation='sigmoid'))\nmob_model.layers[0].trainable = False\nmob_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","52ec709e":"mob_history = mob_model.fit_generator(train_generator,\n                              steps_per_epoch = len(train_generator),\n                              validation_data=validation_generator,\n                              epochs=20,\n                              validation_steps=len(validation_generator),\n                              callbacks = [callbacks]\n                                     )","7cd52749":"plt.figure(figsize=(17,17))\n\nplt.subplot(2, 1, 2)\nplt.plot(mob_history.history['loss'], label='Loss')\nplt.plot(mob_history.history['loss'], label='Validation Loss')\n\nplt.legend()\nplt.title('Training - Loss Function')\n\nplt.subplot(2, 1, 2)\nplt.plot(mob_history.history['accuracy'], label='Accuracy')\nplt.plot(mob_history.history['val_accuracy'], label='Validation Accuracy')\n\n\nplt.legend()\nplt.title('Train - Accuracy')","f61fa8c3":"label = validation_generator.classes\nprint('Cases summary of the models : \\n{}'.format(label))","f19ce0e7":"pred= model.predict(validation_generator)\npredicted_class_indices=np.argmax(pred,axis=1)\nlabels = (validation_generator.class_indices)\nlabels2 = dict((v,k) for k,v in labels.items())\npredictions = [labels2[k] for k in predicted_class_indices]","d94d0f28":"labels","2b757c6f":"print('CNN Model Predictions : \\n{}'.format(predictions))","4c28fef2":"from sklearn.metrics import confusion_matrix, classification_report\n\ncf_matrix = confusion_matrix(predicted_class_indices,label)\ncf_matrix","3f03f29f":"exp_series = pd.Series(label)\npred_series = pd.Series(predicted_class_indices)\npd.crosstab(exp_series, pred_series, rownames=['Actual'], colnames=['Predicted'],margins=True)","06604da3":"import seaborn as sns\n\nmatrix_index = [\"Negative\", \"Positive\"]\n# Negative - no COVID\n\n\npreds = model.predict(validation_generator)\nclasspreds = np.argmax(preds, axis=1) # predicted classes \n#y_testclass = np.argmax(valida, axis=1) # true classes\n\ncm = confusion_matrix(predicted_class_indices,label)\nprint(classification_report(predicted_class_indices,label, target_names=matrix_index))\n\n# Get percentage value for each element of the matrix\ncm_sum = np.sum(cm, axis=1, keepdims=True)\ncm_perc = cm \/ cm_sum.astype(float) * 100\nannot = np.empty_like(cm).astype(str)\nnrows, ncols = cm.shape\nfor i in range(nrows):\n    for j in range(ncols):\n        c = cm[i, j]\n        p = cm_perc[i, j]\n        if i == j:\n            s = cm_sum[i]\n            annot[i, j] = '%.1f%%\\n%d\/%d' % (p, c, s)\n        elif c == 0:\n            annot[i, j] = ''\n        else:\n            annot[i, j] = '%.1f%%\\n%d' % (p, c)\n\n\n# Display confusion matrix \ndf_cm = pd.DataFrame(cm, index = matrix_index, columns = matrix_index)\ndf_cm.index.name = 'Actual'\ndf_cm.columns.name = 'Predicted'\nfig, ax = plt.subplots(figsize=(10,7))\nsns.heatmap(df_cm, annot=annot, fmt='')","f0b29b70":"pred= mob_model.predict(validation_generator)\npredicted_class_indices=np.argmax(pred,axis=1)\nlabels = (validation_generator.class_indices)\nlabels2 = dict((v,k) for k,v in labels.items())\npredictions = [labels2[k] for k in predicted_class_indices]","fa0a6ca5":"labels","ccb3a7fa":"print('MobileNet Model Predictions : \\n{}'.format(predictions))","9b4d7ffd":"cf_matrix = confusion_matrix(predicted_class_indices,label)\ncf_matrix","853c6750":"exp_series = pd.Series(label)\npred_series = pd.Series(predicted_class_indices)\npd.crosstab(exp_series, pred_series, rownames=['Actual'], colnames=['Predicted'],margins=True)","9f6c5434":"matrix_index = [\"Negative\", \"Positive\" ]\n# Negative - no COVID\n\npreds = mob_model.predict(validation_generator)\nclasspreds = np.argmax(preds, axis=1) # predicted classes \n#y_testclass = np.argmax(valida, axis=1) # true classes\n\ncm = confusion_matrix(predicted_class_indices,label)\nprint(classification_report(predicted_class_indices,label, target_names=matrix_index))\n\n# Get percentage value for each element of the matrix\ncm_sum = np.sum(cm, axis=1, keepdims=True)\ncm_perc = cm \/ cm_sum.astype(float) * 100\nannot = np.empty_like(cm).astype(str)\nnrows, ncols = cm.shape\nfor i in range(nrows):\n    for j in range(ncols):\n        c = cm[i, j]\n        p = cm_perc[i, j]\n        if i == j:\n            s = cm_sum[i]\n            annot[i, j] = '%.1f%%\\n%d\/%d' % (p, c, s)\n        elif c == 0:\n            annot[i, j] = ''\n        else:\n            annot[i, j] = '%.1f%%\\n%d' % (p, c)\n\n\n# Display confusion matrix \ndf_cm = pd.DataFrame(cm, index = matrix_index, columns = matrix_index)\ndf_cm.index.name = 'Actual'\ndf_cm.columns.name = 'Predicted'\nfig, ax = plt.subplots(figsize=(10,7))\nsns.heatmap(df_cm, annot=annot, fmt='')","3eeb05ea":"# 6. Model Development","cb14d7b3":"Let's fill the missing values with 'unknown'","8b5509ab":"# Plots to estimate loss and accuracy","030827c8":"# 6.1 Convolutional Neural Network","7501ea59":"# MobileNet predictions","4b5a2fbf":"**Normal Histogram images**","b9b47ed9":"# 2. Missing Values","6e8e4100":"# 4. Display Images","966223fd":"Displaying test images","a7bdd8f7":"# 3. Visualization of Unknown Data","5fe05514":"# CNN predictions","52248e51":"# Load the libraries","3c882ddf":"# 4.1 Histogram analysis of Images","69371b67":"# MobileNetV2","3405515d":"# 5. Image Augmentation","40d6eefc":"**For COVID-19 cases**"}}