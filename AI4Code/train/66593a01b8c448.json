{"cell_type":{"bd9a462c":"code","61c52982":"code","bbb7c89d":"code","fb3672d9":"code","b088a9cc":"code","02b86407":"code","7c5c34e7":"code","366c3c64":"code","bf6f5ab0":"code","222ae821":"code","1d25599d":"markdown","e239f463":"markdown","0b1d3160":"markdown","7f6b1262":"markdown"},"source":{"bd9a462c":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as Optim\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import confusion_matrix\nimport pandas as pd\nimport numpy as np\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","61c52982":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Hyper parametros\nnum_epochs = 20\nbatch_size = 30\nlearning_rate = 0.001\n\n# Clases de elementros\nclasses = ('T-shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')","bbb7c89d":"# FashionMNIST: 60000 imagenes 28x28 en blanco y negro en 10 clases\ntransform = transforms.Compose(\n    [transforms.ToTensor(),\n    transforms.Normalize(0.5, 0.5)])","fb3672d9":"train_dataset = torchvision.datasets.FashionMNIST(root='.\/data', train=True, download=True, transform=transform)\n\ntest_dataset = torchvision.datasets.FashionMNIST(root='.\/data', train=False, download=True, transform=transform)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","b088a9cc":"examples = iter(train_loader)\nsamples, labels = examples.next()\nprint(samples.shape, labels.shape)","02b86407":"for i in range(6):\n    plt.subplot(2,3,i+1)\n    plt.imshow(samples[i][0], cmap='gray')\nplt.show()","7c5c34e7":"# Implementar red neuronal convolucional\nclass ConvNet(nn.Module):\n\n    def __init__(self):\n        super(ConvNet, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=5, stride=1, padding=0) \n        self.norm1 = nn.LayerNorm([8, 24, 24])\n        self.conv2 = nn.Conv2d(in_channels=8, out_channels=32, kernel_size=5, stride=1, padding=2)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.norm2 = nn.LayerNorm([32, 12, 12])\n        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n        self.conv5 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(in_features=32*6*6, out_features=512)\n        self.fc2 = nn.Linear(in_features=512, out_features=512)\n        self.fc3 = nn.Linear(in_features=512, out_features=10)\n\n    def forward(self, x):\n        x = self.norm1(F.relu(self.conv1(x))) #  -> n, 8, 24, 24\n        x = self.norm2(self.pool(F.relu(self.conv2(x)))) # -> n, 32, 12, 12\n        x = self.conv3(x) # -> n, 64, 12, 12\n        x = self.conv4(x) # -> n, 64, 12, 12\n        x = self.pool(self.conv5(x))  # -> n, 32, 6, 6\n        x = x.view(-1, 32*6*6) # -> 1152\n        x = F.relu(self.fc1(x)) # -> 512\n        x = F.relu(self.fc2(x)) # -> 512\n        x = self.fc3(x) # -> 10\n        return x","366c3c64":"# Loop de entrenamiento\nmodel = ConvNet().to(device)\ncriterion = nn.CrossEntropyLoss()\n#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\noptimizer = Optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-7)\nAccuracy_in_training = []\nTraining_Losses= []\n\nn_total_steps = len(train_loader)\nfor epoch in range(num_epochs):\n    TrainingAccuracy = 0\n    TrainingLoss = 0\n    for i, (images, labels) in enumerate(train_loader):\n        # Forma original: [bacht_size, 1, 28, 28] = bacht_size, 1, 784\n        # Input layer: 1 input channel, 6 output channels, 3 kernel size\n        images = images.to(device)\n        labels = labels.to(device)\n\n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        _, prediction = torch.max(outputs, 1)\n        n_samples = labels.size(0)\n        n_correct = (prediction == labels).sum().item()\n        Accuracy = 100*n_correct\/n_samples\n        TrainingAccuracy += Accuracy\n        TrainingLoss += loss.item()\n\n        if (i+1) % 2000 == 0:\n            TrainingAccuracy \/= len(train_loader)\n            TrainingLoss \/= len(train_loader)\n            Accuracy_in_training.append(TrainingAccuracy)\n            Training_Losses.append(TrainingLoss)  \n            print(f'Epoch [{epoch+1}\/{num_epochs}], Step [{i+1}\/{n_total_steps}], Loss: {TrainingLoss:.4f}, Accuracy: {TrainingAccuracy:.2f}%')\n    \n\nprint('Entrenamiento finalizado')\nPATH = '.\/cnn.pth'\ntorch.save(model.state_dict(), PATH)","bf6f5ab0":"plt.plot(Training_Losses, label='Training Loss')\nplt.ylabel('Loss')\nplt.title('Training Loss')\nplt.show()\n\nplt.plot(Accuracy_in_training, label='Training Accuracy')\nplt.ylabel('Accuracy')\nplt.title('Training Accuracy')\nplt.show()","222ae821":"#Pruebas del set de pruebas\nwith torch.no_grad():\n    n_correct = 0\n    n_samples = 0\n    n_class_correct = [0 for i in range(10)]\n    n_class_samples = [0 for i in range(10)]\n    Accuracy_in_test = []\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = model(images)\n        # max returns (value ,index)\n        _, predicted = torch.max(outputs, 1)\n        n_samples += labels.size(0)\n        n_correct += (predicted == labels).sum().item()\n        acc = 100.0 * n_correct \/ n_samples\n        Accuracy_in_test.append(acc)\n        \n        for i in range(10):\n            label = labels[i]\n            pred = predicted[i]\n            if (label == pred):\n                n_class_correct[label] += 1\n            n_class_samples[label] += 1\n\n    \n    print(f'Accuracy of the network: {acc} %')\n    network_acc = acc\n    accuracy_per_class = []\n    for i in range(10):\n        acc = 100.0 * n_class_correct[i] \/ n_class_samples[i]\n        accuracy_per_class.append(acc)\n        print(f'Accuracy of {classes[i]}: {acc:.2f} %')\n    \n    plt.bar(classes, accuracy_per_class)\n    plt.title('Precisi\u00f3n por clase')\n    plt.xticks(classes, rotation='vertical')\n    plt.show()\n\n    plt.barh(['Training','Testing'],[TrainingAccuracy,network_acc])\n    plt.xticks([0,10,20,30,40,50,60,70,80,90,100])\n    plt.title('Precisi\u00f3n de la red')\n    plt.show()\n\n","1d25599d":"# Modelo CNN\nLa arquitectura del modelo elegida fue una versi\u00f3n simplificada de AlexNet que consta de cinco capas convolucionales, las dos primeras con un kernel de 5x5 con 8 y 32 filtros; a ambas capas se les aplico otra capa de normalizaci\u00f3n y a la segunda capa se le aplic\u00f3 un max pooling de 2x2 con stride 2. Las siguientes 3 capas convolucionales son id\u00e9nticas, con un kernel de 3x3, stride 1 y padding 1. \n\nSe procedi\u00f3 con dos capas ocultas id\u00e9nticas de 512 neuronas y con una capa de salida de 10 neuronas que corresponden a cada uno de los tipos de elementos en el set de entrenamiento y validaci\u00f3n. La funci\u00f3n de activaci\u00f3n utilizada para todas las capas es la funci\u00f3n ReLu.\n ","e239f463":"# Preprocesamiento de datos\n\nLos datos de entrada del modelo se obtuvieron directamente desde la libreria Torchvision, que posee el repositorio de los datos FashionMNIST para evitar cargar el dataset de un archivo .csv y hacer mas facil de ejecutar el codigo. Una vez descargado el dataset se procede con la normalizacion de los datos para distribuir los valores entre (-1,1). Se estableci\u00f3 un batch size de 30.","0b1d3160":"# Resultado del modelo\n\nEl mejor resultado obtenido con este modelo es de un 95.66% de accuracy en el set de entrenamiento y un 91.06 % de accuracy en el set de validaci\u00f3n. El tiempo de ejecuci\u00f3n fue de 12 minutos para el entrenamiento del modelo. El resultado del LeaderBoard en Kaggle fue de \u2026","7f6b1262":"# Entrenamiento del modelo\n\nEl algoritmo de optimizaci\u00f3n utilizado es Adam, ya que implementa los algoritmos de Momentum y RMSProp para lograr un entrenamiento m\u00e1s eficiente y con menos ruido. El batch size utilizado es de 30 elementos, con un n\u00famero de Epoch de 20 y un learning rate igual a 0.001. La funci\u00f3n de Loss utilizada es Cross Entropy Loss."}}