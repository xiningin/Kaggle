{"cell_type":{"713b3e6c":"code","449a1af8":"code","5d202fd9":"code","401f7b71":"code","bb53fdfe":"code","f57abc27":"code","9e8bc260":"code","b8e960f5":"code","92e4718e":"code","ccae3f67":"code","7461a1fd":"code","0961d735":"code","6a3b1c83":"code","01a454f2":"code","fd785c26":"code","d29acfca":"code","4c5afd54":"code","d081c60a":"code","6264a8ce":"code","448ab5a8":"code","ed48d49d":"code","60985ac0":"code","68213f14":"code","1cfdd79e":"code","4a2c444c":"code","1a75102c":"code","8d5df2fe":"markdown","98a585ea":"markdown","3f61fe05":"markdown","d43f7183":"markdown","3d34082d":"markdown","791f96df":"markdown","ec65e1aa":"markdown","09375429":"markdown","20fd8523":"markdown","c373c1a5":"markdown","ddbed58e":"markdown","5dd3734e":"markdown"},"source":{"713b3e6c":"# library with nice formating\n!pip install rich","449a1af8":"# exporti train\nfrom tqdm.notebook import tqdm","5d202fd9":"# default_exp resnet\nimport os\n\nif os.environ.get('KAGGLE_KERNEL_RUN_TYPE', 'Localhost') == 'Losthost':\n    from nbdev import *","401f7b71":"# exporti train\nimport rich\n\nfrom collections import OrderedDict","bb53fdfe":"# exporti\nimport numpy as np\nimport pandas as pd","f57abc27":"# exporti\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim","9e8bc260":"# exporti train\nfrom torch.utils.data import dataset, dataloader, random_split\n\nfrom torchvision.datasets import CIFAR10\nfrom torchvision.transforms import ToTensor, Lambda, Compose","b8e960f5":"# exporti train\ndataset = CIFAR10(root=\"\/kaggle\/working\/data\/\",\n                        download=True,\n                        train=True, transform=ToTensor())\ntest_dataset = CIFAR10(root=\"\/kaggle\/working\/data\/\",\n                       download=True, train=False,\n                       transform=ToTensor())\n\n# create train, valid datasets\nvalid_size = int(dataset.data.shape[0]*0.1)\ntrain_size = dataset.data.shape[0] - valid_size\n\ntrain_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])","92e4718e":"# exporti train\nconfig = OrderedDict()\nconfig['batch_size'] = 128","ccae3f67":"# exporti train\ntrain_dataloader = dataloader.DataLoader(train_dataset, batch_size=config['batch_size'])\nvalid_dataloader = dataloader.DataLoader(valid_dataset, batch_size=config['batch_size'])\ntest_dataloader = dataloader.DataLoader(test_dataset, batch_size=config['batch_size'])","7461a1fd":"# hide\nfor x, y in train_dataloader:\n    rich.print(x.max(), x.min())\n    rich.print(y)\n    break","0961d735":"# export\nclass ResNetBlock(nn.Module):\n    \n    def __init__(self, in_channels: int = 32, num_filters: int = 64):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels=in_channels,\n                               out_channels=num_filters,\n                               kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(num_filters)\n        self.relu1 = nn.ReLU()\n        self.conv2 = nn.Conv2d(in_channels=num_filters,\n                               out_channels=num_filters, \n                               kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(num_filters)\n        self.relu2 = nn.ReLU()\n    \n    def forward(self, x):\n        z = self.conv1(x)\n        z = self.relu1(z)\n        z = self.bn1(z)\n        z = self.conv2(z)\n        y = self.relu2(z + x)\n        return self.bn2(y)","6a3b1c83":"rblock = ResNetBlock(in_channels=64)\nx = torch.randint(0, 100, size=(128, 64, 32, 32), dtype=torch.float32)\ny = rblock(x)\nassert x.shape == y.shape","01a454f2":"# export\nclass ResNetChangeBlock(nn.Module):\n    \n    def __init__(self, in_channels: int = 32, num_filters: int = 64):\n        super().__init__()\n        self.in_channels = in_channels\n        self.out_channels = num_filters\n        self.conv1 = nn.Conv2d(in_channels=in_channels,\n                               out_channels=num_filters,\n                               stride=2,\n                               kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(num_filters)\n        self.relu1 = nn.ReLU()\n        self.conv2 = nn.Conv2d(in_channels=num_filters,\n                               out_channels=num_filters, \n                               kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(num_filters)\n        self.relu2 = nn.ReLU()\n    \n    def forward(self, x):\n        n, c, w, h = x.shape\n        z = self.conv1(x)\n        z = self.relu1(z)\n        z = self.bn1(z)\n        z = self.conv2(z)\n        self.zero_identity = nn.Parameter(\n            torch.zeros(n, self.out_channels-self.in_channels,\n                        int(w\/\/2), int(h\/\/2)),\n            requires_grad=False\n        )\n        x_expand = F.pad(x[:, :, :int(w\/\/2), :int(h\/\/2)], pad=(\n            0, 0, 0, 0, self.out_channels-self.in_channels, 0, 0, 0))\n        y = self.relu2(z + x_expand)\n        return self.bn2(y)","fd785c26":"x = torch.ones([128, 16, 16, 16])\ny = torch.ones([128, 32, 16, 16])\nz = F.pad(x, (0, 0, 0, 0, 16, 0, 0, 0))\nassert z.shape == y.shape","d29acfca":"rblock2 = ResNetChangeBlock(in_channels=64, num_filters=128)\nx = torch.randint(0, 100, size=(128, 64, 32, 32), dtype=torch.float32)\ny = rblock2(x)\nassert y.shape == (128, 128, 16, 16)","4c5afd54":"# export\nclass ResNet(nn.Module):\n    \n    def __init__(self, n: int = 3, num_classes: int = 10):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16,\n                               kernel_size=3, padding=1)\n        self.resblock1_list = nn.ModuleList([\n            ResNetBlock(in_channels=16, num_filters=16) for _ in range(n)\n        ])\n        self.resblock2_list = nn.ModuleList([\n                ResNetChangeBlock(in_channels=16, num_filters=32)\n            ] + [\n            ResNetBlock(in_channels=32, num_filters=32) for _ in range(n-1)\n        ])\n        self.resblock3_list = nn.ModuleList([\n            ResNetChangeBlock(in_channels=32, num_filters=64)\n        ] + [\n            ResNetBlock(in_channels=64, num_filters=64) for _ in range(n-1)\n        ])\n        self.linear1 = nn.Linear(in_features=64,\n                                 out_features=num_classes)\n        \n    def forward(self, x):\n        x = self.conv1(x)\n        for layer1 in self.resblock1_list:\n            x = layer1(x)\n        for layer2 in self.resblock2_list:\n            x = layer2(x)\n        for layer3 in self.resblock3_list:\n            x = layer3(x)\n        x = torch.mean(x, dim=[2, 3])\n        x = self.linear1(x)\n        return x","d081c60a":"n = 3\nnum_classes = 10\nbatch_size = 128\nres_net = ResNet(n=n, num_classes=num_classes)\nx = torch.randint(0, 100, size=(batch_size, 3, 32, 32), dtype=torch.float32)\ny = res_net(x)\nassert y.shape == (batch_size, num_classes)","6264a8ce":"# exporti train\nconfig['device'] = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"device: {config['device']}\")\n\n# define the network\nconfig['n'] = 3\nnum_classes = 10\nres_net = ResNet(n=config['n'], num_classes=num_classes)\nres_net = res_net.to(config['device'])\n\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(params=res_net.parameters())","448ab5a8":"rich.print(res_net)","ed48d49d":"# exporti train\ndef train_fn(model: nn.Module, \n             train_dataloader: dataloader.DataLoader,\n             loss_fn, optimizer, epoch: int, device: str):\n    \n    model.train()\n    \n    for batch_index, (X, y) in tqdm(enumerate(train_dataloader),\n                                    total=len(train_dataloader.dataset.indices)\/\/config['batch_size']):\n        \n        X_data, y_data = X.to(device), y.to(device)\n        y_pred = model(X_data)\n        loss = loss_fn(y_pred, y_data)\n        \n        # backprop\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    loss = loss.item()\n    accu = torch.argmax(y_pred, dim=-1) == y_data\n    accu = sum(accu)\/len(accu)\n    accu = accu.item()\n    print(\"loss=\"+str(loss), end=' ')\n    print(\"accu=\"+str(accu), end=' ')\n","60985ac0":"# exporti train\ndef test_fn(model: nn.Module,\n            test_dataloader: dataloader.DataLoader,\n            epoch: int, device: str, dataset: str):\n    \n    loss = 0\n    results = []\n    model.eval()\n    with torch.no_grad():\n        for batch_index, (X, y) in tqdm(enumerate(test_dataloader)):\n            X_data, y_data = X.to(device), y.to(device)\n            y_pred = model(X_data)\n            loss += loss_fn(y_pred, y_data).item()\n            results.extend(torch.argmax(y_pred, dim=-1) == y_data)\n    \n    test_accu = sum(results)\/len(results)\n    test_accu = test_accu.item()\n    test_loss = loss\/len(results)\n    print(dataset + \"_loss: \" + str(test_loss), end=' ')\n    print(dataset + \"_accu: \" + str(test_accu), end=' ')\n    return False","68213f14":"# exporti train\n\nconfig['num_epochs'] = 25\n\nfor epoch in tqdm(range(config['num_epochs'])):\n    print(\"epoch: \" + str(epoch), end=' ')\n    train_fn(res_net, train_dataloader, loss_fn, optimizer, epoch, config['device'])\n    test_fn(res_net, valid_dataloader, epoch, config['device'], dataset=\"valid\")    \n    print()","1cfdd79e":"# exporti predict\ndef predict_fn(model, test_dataloader, device):\n\n    y_pred_list = []\n    with torch.no_grad():\n        for batch_index, (X, y) in enumerate(test_dataloader):\n            X_data, y_data = X.to(device), y.to(device)\n            y_pred = model(X_data)\n            y_pred_list.append(y_pred)\n    return torch.cat(y_pred_list)","4a2c444c":"# exporti train\ntest_fn(res_net, test_dataloader, epoch, config['device'], dataset=\"test\")","1a75102c":"# exporti train\ntorch.save(res_net.state_dict(), \"resnet_cifar10_n3_network.pth\")","8d5df2fe":"### Test and Save the network","98a585ea":"Check that `ResNetChangeBlock` has half receptor field","3f61fe05":"### Define Train and Eval loop","d43f7183":"Check the padding operation works as intended, the pad dimensions are left-to-right last-to-first dimension","3d34082d":"### Train and Track the Model","791f96df":"`ResNet` with variable `6n+2` number of layers and skip connections `2n` skip connections, Similar to CIFAR10 network from the [resnet paper](https:\/\/arxiv.org\/abs\/1512.03385#).","ec65e1aa":"### ResNet Block","09375429":"### Imports and Notebook setup","20fd8523":"Check `ResNet` has last dimension as `num_classes`","c373c1a5":"Check that `ResNetBlock` has same input and output sizes","ddbed58e":"`ResNetChangeBlock` implements the ResNet with skip connections when the input and output have different shape","5dd3734e":"### Conclusion and Future work"}}