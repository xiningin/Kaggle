{"cell_type":{"ceebdc4d":"code","79ebaa2e":"code","25ef0613":"code","24b9ddd8":"code","02bc5d61":"code","7b164fb8":"code","b4c550d1":"code","b547a71b":"code","1d31e685":"code","095d6888":"code","6ea49dbc":"code","cf316675":"code","d07044d9":"code","d33414f4":"code","9e4d22f3":"code","d0e3495b":"code","a55d4430":"code","eee7d7d9":"code","62257282":"markdown","22e96f8e":"markdown","27dfa82f":"markdown","dc39f05b":"markdown","4d29f1ec":"markdown","2f41ff9d":"markdown","b2abdbaf":"markdown","f948c3c5":"markdown","59c6949c":"markdown","1117e547":"markdown","c1ce6069":"markdown"},"source":{"ceebdc4d":"import os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\n%matplotlib inline","79ebaa2e":"my_data_dir = r'\/kaggle\/input\/01-eda-and-image-augmentatio-v2\/output\/'","25ef0613":"os.listdir(my_data_dir) ","24b9ddd8":"# check for any corrupted images from image augmentation steps and delete them\n# code obtained from https:\/\/stackoverflow.com\/questions\/67505710\/pil-unidentifiedimageerror-cannot-identify-image-file-io-bytesio-object\nimport PIL\nfrom pathlib import Path\nfrom PIL import UnidentifiedImageError\n\npath = Path(my_data_dir).rglob(\"*.jpg\")\nfor img_p in path:\n    try:\n        img = PIL.Image.open(img_p)\n    except PIL.UnidentifiedImageError:\n        print(img_p) ","02bc5d61":"#Making another copies of input data to be able to fit the generator in modelling stage \n#Kaggle notebook doesn't allow to fit the read-only files from input folder\nfrom distutils.dir_util import copy_tree\ncopy_dir = r'\/kaggle\/working\/working_images\/'\ncopy_tree(my_data_dir, copy_dir, verbose = 2)\nfrom IPython.display import clear_output\nclear_output(wait=True)\nprint(\"finished\")","7b164fb8":"#Confirming number of images to ensure that the images have been loaded properly\nsplitted_dir = copy_dir\nprint(\"Training folder : \")\ncategory = []\nnumber_images_train = []\nfor cat in os.listdir(splitted_dir + 'train'):\n    print(\"Number of \" + cat + \" images : \" + str(len(os.listdir(splitted_dir+'train' + '\/'+cat))))\n    category.append(cat)\n    number_images_train.append(len(os.listdir(splitted_dir + 'train' + '\/'+cat)))    \nprint(\"Total Number of Images : \" + str(np.sum(number_images_train)))\n\nprint(\"\\n\\nTesting folder : \")\ncategory = []\nnumber_images_test = []\nfor cat in os.listdir(splitted_dir + 'test'):\n    print(\"Number of \" + cat + \" images : \" + str(len(os.listdir(splitted_dir+'test' + '\/'+cat))))\n    category.append(cat)\n    number_images_test.append(len(os.listdir(splitted_dir + 'test' + '\/'+cat)))    \nprint(\"Total Number of Images : \" + str(np.sum(number_images_test)))\n\nprint(\"\\n\\nValidation folder : \")\ncategory = []\nnumber_images_valid = []\nfor cat in os.listdir(splitted_dir + 'train'):\n    print(\"Number of \" + cat + \" images : \" + str(len(os.listdir(splitted_dir+'val' + '\/'+cat))))\n    category.append(cat)\n    number_images_valid.append(len(os.listdir(splitted_dir + 'val' + '\/'+cat)))    \nprint(\"Total Number of Images : \" + str(np.sum(number_images_valid)))","b4c550d1":"plt.figure(figsize=(20,10))\nplt.subplot(1,3,1)\nplt.pie(number_images_train, labels=category, autopct='%.0f%%')\nplt.title(f'Train - {sum(number_images_train)} files')\nplt.subplot(1,3,2)\nplt.pie(number_images_test, labels=category, autopct='%.0f%%')\nplt.title(f'Test - {sum(number_images_test)} files')\nplt.subplot(1,3,3)\nplt.pie(number_images_valid, labels=category, autopct='%.0f%%')\nplt.title(f'Valid - {sum(number_images_valid)} files')\nplt.show()","b547a71b":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# instance and adjust the options\ntrain_datagen = ImageDataGenerator(\n    rescale = 1\/255, # normalize the values\n)\n\ntest_datagen = ImageDataGenerator(\n    rescale = 1\/255, # normalize the values\n)\n\nvalid_datagen = ImageDataGenerator(\n    rescale = 1\/255, # normalize the values\n)","1d31e685":"import tensorflow as tf\nfrom tensorflow import keras\n\n# set the random seed\nseed = 1234\ntf.random.set_seed(seed)\nnp.random.seed(seed)\n\n# define train\/test\/valid path\ntrain_path = splitted_dir+'train\/'\ntest_path =  splitted_dir+'test\/'\nvalid_path =  splitted_dir+'val\/'","095d6888":"image_size = 600\ntrain_gen = train_datagen.flow_from_directory(\n    train_path, \n    batch_size = 1,\n    class_mode = 'categorical',\n    target_size = (image_size, image_size), \n    shuffle = True,\n    seed = seed,\n#    save_to_dir=train_path\n)\n\n# test\ntest_gen = test_datagen.flow_from_directory(\n    test_path,\n    batch_size = 1,\n    class_mode = 'categorical', \n    target_size = (image_size, image_size), \n    shuffle = True,\n    seed = seed,\n#    save_to_dir=test_path\n)\n\n# validation\nvalid_gen = test_datagen.flow_from_directory(\n    valid_path, \n    batch_size = 1,\n    class_mode = 'categorical',\n    target_size = (image_size, image_size), \n    shuffle = True,\n    seed = seed,\n#    save_to_dir=valid_path\n)","6ea49dbc":"from tensorflow.keras import Sequential, layers\nnum_classes = len(category)\nmodel = Sequential([\n    layers.InputLayer(input_shape=[image_size, image_size, 3]),\n    layers.Conv2D(filters=16, kernel_size=3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(32, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(64, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Flatten(),    \n    layers.Dense(256, activation='relu'),\n    layers.Dropout(0.3),     \n    layers.Dense(256, activation='relu'),\n    layers.Dropout(0.3),    \n    layers.Dense(num_classes, activation='softmax')\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel.summary()","cf316675":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stopping = EarlyStopping(\n    min_delta=0.005, \n    patience=2, \n    restore_best_weights=True\n)\n\nfrom PIL import ImageFile\n# ask PIL to be tolerant of files that are truncated (missing some file from the block) by changing a setting.\n# if that option isn't enabled training will trow an error\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nhistory = model.fit(\n    train_gen,\n    validation_data = test_gen,\n    epochs = 25,\n    callbacks = [early_stopping]\n)","d07044d9":"model.save('CNN_baseline_model3.hdf5')","d33414f4":"# saved_model_dir = r'\/kaggle\/input\/daan570-final-project-cnn\/CNN_baseline_model.hdf5'\n# os.listdir(r'\/kaggle\/input\/daan570-final-project-cnn\/')","9e4d22f3":"from tensorflow.keras.models import load_model\n# model = load_model(saved_model_dir)\nmodel.summary()","d0e3495b":"plt.figure(figsize=(15, 10))\n\n# plot the loss function\nplt.subplot(1,2,1)\nplt.plot(history.history['loss'], label='train')\nplt.plot(history.history['val_loss'], label='test')\nplt.title('Loss Function')\nplt.grid(True)\nplt.legend()\n\n# and the accuracy\nplt.subplot(1,2,2)\nplt.plot(history.history['accuracy'], label='train')\nplt.plot(history.history['val_accuracy'], label='test')\nplt.grid(True)\nplt.title('Accuracy')\nplt.legend()\n\nplt.show()","a55d4430":"results = model.evaluate(test_gen, batch_size=1)\nprint(\"test loss, test acc:\", results)","eee7d7d9":"results = model.evaluate(valid_gen, batch_size=1)\nprint(\"valid loss, valid acc:\", results)","62257282":"It looks like we can achieve around 89% accuracy of the testing dataset.  Let's see the performance on the validation data.","22e96f8e":"#Result from CNN model fitting","27dfa82f":"This is the 2nd notebook of total 5 notebooks in this series listed as following:\n1. EDA and image augmentation note books >> https:\/\/www.kaggle.com\/suradechk\/01-eda-and-image-augmentation-v2\n2. Setting up a baseline model using CNN >> https:\/\/www.kaggle.com\/suradechk\/02-baseline-model-using-cnn-v2\n3. Keypoint generation using movenet >> https:\/\/www.kaggle.com\/suradechk\/03-keypoint-movenet-v2\n4. Classification keypoint output using classical ML >> https:\/\/www.kaggle.com\/suradechk\/04-classification-using-keypoints-output-v2\n5. Classification keypoint output using ANN >> https:\/\/www.kaggle.com\/suradechk\/05-classification-using-ann-v2","dc39f05b":"# 2. Check whether there is any corrupted images.","4d29f1ec":"# DAAN570 - Final Project - RSI Prevention by Yoga - Modelling notebook\n<br>Team: 11: Suradech Kongkiatpaiboon and Burq Latif\nCourse: DAAN 570 \u2013 Deep Learning (Fall, 2021) - Penn State World Campus\n\n> Problem statement : Repetitive stress injury is extremely prevalent for anyone who works at the same spot for a long length of time, especially with the development of COVID-19 and the increase in work from home trend. We've identified certain flaws in traditional RSI prevention software on the market, and we've noted that yoga's popularity is growing by the day. The reason for this is the numerous physical, mental, and spiritual advantages that yoga may provide. Many people are following this trend and practice yoga without the help of a professional. However, doing yoga incorrectly or without adequate instruction can lead to serious health problems such as strokes and nerve damage. As a result, adhering to appropriate yoga poses is a vital consideration.\nIn this work, we present a method for identifying the user's postures and providing visual guidance to the user. In order to be more engaging with the user, this procedure is done in real-time and utilizes the traditional webcam on the laptop\/desktop to run the application.\n\nKeywords : Yoga, posture, classification, movenet, keypoint\n\nData Collection:\nWe took some images from open source yoga posture dataset from three following sites and applied basic data cleaning manually (e.g. remove corrupted images, remove misclassified yoga posture images).\n1. Open source dataset from https:\/\/www.kaggle.com\/general\/192938\n2. 3D synthetic dataset from https:\/\/laurencemoroney.com\/2021\/08\/23\/yogapose-dataset.html\n3. Yoga-82 dataset from https:\/\/sites.google.com\/view\/yoga-82\/home","2f41ff9d":"# 1. Obtain the images from 01 EDA and Image augmentation notebook\nhttps:\/\/www.kaggle.com\/suradechk\/01-eda-and-image-augmentation\/notebook","b2abdbaf":"It looks like we have a good train\/test\/valid split now.","f948c3c5":"Let's start with building a simple CNN model.","59c6949c":"# 3. Building our first baseline CNN model","1117e547":"There are no corrupted images found so far, so we proceed with the next steps.","c1ce6069":"# 4. Model fitting"}}