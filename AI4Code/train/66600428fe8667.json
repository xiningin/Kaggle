{"cell_type":{"17845e91":"code","a75d859e":"code","c59b0bc2":"code","d6c5fa35":"code","2ecc7b37":"code","9e2aea3d":"code","3466ce37":"code","7b9c4b1f":"code","e4914845":"code","9708292b":"code","7929e500":"code","52fe2bbd":"code","b1b64ef4":"code","031298e0":"code","3b5064d1":"code","85b9be0e":"code","6fdcb053":"code","b26b43b1":"code","1ec39606":"code","f36a61c9":"code","58608465":"code","ba5efcf9":"code","582dcb33":"code","48c20639":"code","b382571b":"code","9f44f175":"code","6a9a6aa6":"code","c22a56d8":"code","9d55f20d":"code","b76de0b7":"code","9b65f327":"code","ed261512":"code","dfe67268":"code","97274941":"code","872aba94":"markdown","09bf6f78":"markdown","2d52c4e2":"markdown","6e51091f":"markdown","3d8f634c":"markdown","30c88727":"markdown","72f4fcb1":"markdown","0431a83f":"markdown","6cb22e59":"markdown","a02e2987":"markdown","99ba1697":"markdown","dbb6b950":"markdown","23a27b5b":"markdown","5a975a0b":"markdown","0f270d92":"markdown","42e3e9d1":"markdown"},"source":{"17845e91":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a75d859e":"from __future__ import print_function\nimport lime\nimport sklearn\nimport numpy as np\nimport sklearn\nimport sklearn.ensemble\nimport sklearn.metrics\n","c59b0bc2":"from sklearn.datasets import fetch_20newsgroups\ncategories = ['rec.autos', 'sci.med']\nnewsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\nnewsgroups_test = fetch_20newsgroups(subset='test', categories=categories)\nclass_names = ['autos', 'med']","d6c5fa35":"newsgroups_train.data[9:10]","2ecc7b37":"type(newsgroups_train.data)","9e2aea3d":"type(newsgroups_train.target)","3466ce37":"newsgroups_train.target[:10]","7b9c4b1f":"vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(lowercase=False)\ntrain_vectors = vectorizer.fit_transform(newsgroups_train.data)\ntest_vectors = vectorizer.transform(newsgroups_test.data)","e4914845":"type(vectorizer)","9708292b":"rf = sklearn.ensemble.RandomForestClassifier(n_estimators=500)\nrf.fit(train_vectors, newsgroups_train.target)","7929e500":"pred = rf.predict(test_vectors)\nsklearn.metrics.f1_score(newsgroups_test.target, pred, average='binary')","52fe2bbd":"pred[:10]","b1b64ef4":"from lime import lime_text\nfrom sklearn.pipeline import make_pipeline\nc = make_pipeline(vectorizer, rf)","031298e0":"type(newsgroups_test.data)","3b5064d1":"newsgroups_test.data[0]","85b9be0e":"newsgroups_test.target[0]","6fdcb053":"type(newsgroups_test.target)","b26b43b1":"print(c.predict_proba([newsgroups_test.data[0]]))","1ec39606":"from lime.lime_text import LimeTextExplainer\nexplainer = LimeTextExplainer(class_names=class_names)","f36a61c9":"idx = 0\nexp = explainer.explain_instance(newsgroups_test.data[idx], c.predict_proba, num_features=6)\nprint('Document id: %d' % idx)\nprint('Probability(med) =', c.predict_proba([newsgroups_test.data[idx]])[0,1])\nprint('True class: %s' % class_names[newsgroups_test.target[idx]])","58608465":"exp.as_list()","ba5efcf9":"print('Original prediction:', rf.predict_proba(test_vectors[idx])[0,1])\ntmp = test_vectors[idx].copy()\ntmp[0,vectorizer.vocabulary_['doctor']] = 0\ntmp[0,vectorizer.vocabulary_['is']] = 0\nprint('Prediction removing some features:', rf.predict_proba(tmp)[0,1])\nprint('Difference:', rf.predict_proba(tmp)[0,1] - rf.predict_proba(test_vectors[idx])[0,1])","582dcb33":"%matplotlib inline\nfig = exp.as_pyplot_figure()","48c20639":"exp.show_in_notebook(text=False)","b382571b":"exp.save_to_file('\/tmp\/oi.html')","9f44f175":"exp.show_in_notebook(text=True)","6a9a6aa6":"print(c.predict_proba([newsgroups_test.data[1]]))\nfrom lime.lime_text import LimeTextExplainer\nexplainer = LimeTextExplainer(class_names=class_names)","c22a56d8":"idx = 1\nexp = explainer.explain_instance(newsgroups_test.data[idx], c.predict_proba, num_features=6)\nprint('Document id: %d' % idx)\nprint('Probability(med) =', c.predict_proba([newsgroups_test.data[idx]])[0,1])\nprint('True class: %s' % class_names[newsgroups_test.target[idx]])","9d55f20d":"exp.as_list()","b76de0b7":"print('Original prediction:', rf.predict_proba(test_vectors[idx])[0,1])\ntmp = test_vectors[idx].copy()\ntmp[0,vectorizer.vocabulary_['of']] = 0\ntmp[0,vectorizer.vocabulary_['subject']] = 0\nprint('Prediction removing some features:', rf.predict_proba(tmp)[0,1])\nprint('Difference:', rf.predict_proba(tmp)[0,1] - rf.predict_proba(test_vectors[idx])[0,1])","9b65f327":"%matplotlib inline\nfig = exp.as_pyplot_figure()","ed261512":"exp.show_in_notebook(text=False)","dfe67268":"exp.save_to_file('\/tmp\/oi1.html')","97274941":"exp.show_in_notebook(text=True)","872aba94":"These weighted features are a linear model, which approximates the behaviour of the random forest classifier in the vicinity of the test example. Roughly, if we remove 'doctor' and 'is' from the document , the prediction should move towards the opposite class (autos) by about 0.07 (the sum of the weights for both features). Let's see if this is the case.","09bf6f78":"SO this is a basic kernal describing how to use the LIME , further i have used this concept to build two kernals, in very detailed manner.\n\n1. In this kernal i have used Logistic Regression Classifier to predict the class of comment (toxic or non-toxic)[kernal](https:\/\/www.kaggle.com\/bavalpreet26\/explainable-ai-lime)\n\n2. In this 2nd kernal i have used Support Vector Classifier with same pipeline to predict the class of comment (toxic or non-toxic)[kernal2](https:\/\/www.kaggle.com\/bavalpreet26\/explainable-ai-lime-svc)","2d52c4e2":"![](https:\/\/miro.medium.com\/max\/4552\/1*XN9NNL_Q3EcctTELM3CoNA.png)","6e51091f":"Pretty close!\nThe words that explain the model around this document seem somewhat related like 'doctor' and 'medical'.And from remaining 'is' and 'of' are kinda stopwords whereas 'effects' or 'information' i think not much to do with or somehow very less related to medical\n","3d8f634c":"# Why Explainable AI is so Important?\n\nExplainable AI (XAI) refers to methods and techniques in the application of artificial intelligence technology (AI) such that the results of the solution can be understood by human beings. It contrasts with the concept of the \"black box\" in machine learning where even their designers cannot explain why the AI arrived at a specific decision.","30c88727":"### Visualizing explanations","72f4fcb1":"### Explaining predictions using lime","0431a83f":"Now we create an explainer object. We pass the class_names a an argument for prettier display.","6cb22e59":"We then generate an explanation with at most 6 features for an arbitrary document in the test set.","a02e2987":"Lime explainers assume that classifiers act on raw text, but sklearn classifiers act on vectorized representation of texts. For this purpose, we use sklearn's pipeline, and implements predict_proba on raw_text lists.","99ba1697":"so we get higher prob for med class and low for autos","dbb6b950":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcTz0dmBOdIz5VNjYqkK4kwK4467a0AR3Iro8YxzHF8IxjSyvsFY&usqp=CAU)","23a27b5b":"SO this is a basic kernal describing how to use the LIME , further i have used this concept to build two kernals, in very detailed manner.\n\n1. In this kernal i have used Logistic Regression Classifier to predict the class of comment (toxic or non-toxic)[kernal](https:\/\/www.kaggle.com\/bavalpreet26\/explainable-ai-lime)\n\n2. In this 2nd kernal i have used Support Vector Classifier with same pipeline to predict the class of comment (toxic or non-toxic)[kernal2](https:\/\/www.kaggle.com\/bavalpreet26\/explainable-ai-lime-svc)","5a975a0b":"Now, let's say we want to use random forests for classification. It's usually hard to understand what random forests are doing, especially with many trees.","0f270d92":"we will now use tf\/idf vectorizer","42e3e9d1":"The classifier got this example right (it predicted med).\nThe explanation is presented below as a list of weighted features."}}