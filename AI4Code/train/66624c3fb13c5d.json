{"cell_type":{"1f2e4c7b":"code","502ab62f":"code","f58cb58e":"code","6c19b7cf":"code","27107d94":"code","66e840bb":"code","e8f88b6c":"code","13abc3cc":"code","00d83009":"code","15933f9c":"code","495bf0de":"code","c43696ad":"code","ff458503":"code","75a88bdd":"code","ca8815de":"code","a10a664c":"code","e88d873d":"code","b490507d":"code","596488d4":"code","b19f24bc":"markdown","5ad1478d":"markdown","b8cec9aa":"markdown","406847e5":"markdown","07701a44":"markdown","81f8da7f":"markdown"},"source":{"1f2e4c7b":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","502ab62f":"iris_df = pd.read_csv('..\/input\/iris\/Iris.csv')\niris_df.head()","f58cb58e":"iris_df.shape","6c19b7cf":"iris_df = pd.get_dummies(iris_df, columns=['Species'])\niris_df.head()","27107d94":"X = iris_df.values[:, 1:5]\ny = iris_df.values[:, 5:8]","66e840bb":"def normalize(array):\n    arr_min = array.min(axis=(0, 1))\n    arr_max = array.max(axis=(0, 1))\n    return (array - arr_min) \/ (arr_max - arr_min)","e8f88b6c":"X = normalize(X)","13abc3cc":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)","00d83009":"from keras.models import Sequential \nfrom keras.layers import Dense \nfrom keras.optimizers import Adam ","15933f9c":"def create_network():\n    model = Sequential()\n    model.add(Dense(7, input_shape=(4,), activation='relu')) \n    model.add(Dense(8, activation='relu')) \n    model.add(Dense(5, activation='relu'))\n    model.add(Dense(3, activation='softmax')) #3 classes need 3 nodes at output layer\n        \n    model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy']) \n    return model","495bf0de":"model = create_network()","c43696ad":"results = model.fit(X_train,y_train, epochs=10, batch_size=8, validation_data=(X_test, y_test))","ff458503":"plt.figure(figsize=(5, 5))\nplt.title(\"Learning curve\")\nplt.plot(results.history[\"loss\"], label=\"loss\")\nplt.plot(results.history[\"val_loss\"], label=\"val_loss\")\nplt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"log_loss\")\nplt.legend();","75a88bdd":"model.predict(X_test[:5])","ca8815de":"y_test[:5]","a10a664c":"import keras.backend as K","e88d873d":"weight, biases = model.layers[0].get_weights()","b490507d":"weight","596488d4":"biases","b19f24bc":"normalize dataset between (0, 1) before training","5ad1478d":"# Build NN with Keras","b8cec9aa":"One-hot labels by get_dummies() method","406847e5":"# A Simple Neural Network working on Iris flower dataset","07701a44":"# Load dataset","81f8da7f":"This is results of prediction on 5 samples and the below is real labels"}}