{"cell_type":{"a9d1406f":"code","2ab1d924":"code","dccb07ee":"code","6f3673c2":"code","eefca484":"code","cf8ef9f5":"code","de36ad96":"code","c33f53df":"code","636e4c25":"code","bfa32236":"code","d54b262f":"code","84c0d7fe":"code","48ecd34c":"code","3910285f":"code","7cd20dfe":"code","51dd50aa":"code","053e70c6":"code","68587f3a":"code","b80ac4d9":"code","9c275f67":"code","04822da2":"code","652bc1a7":"code","ed2933b9":"code","a4b99f86":"code","8149239d":"code","839bb008":"code","25d04158":"code","6e5ea599":"code","a0a0405d":"code","1116626a":"code","ba07e159":"code","81f66573":"code","82e109c8":"code","cb35bdb4":"code","0bfd52b5":"code","e0e315bb":"code","80bee3b1":"code","edb1dcec":"code","e68e5df8":"code","79125974":"code","92bca37a":"code","137105b0":"code","4f1af172":"code","abaeec0d":"code","95909b87":"code","9607b6cb":"code","4c4996c0":"markdown","f617f536":"markdown","bd72e648":"markdown","add3cace":"markdown","af844c43":"markdown","b8d0f6f6":"markdown","bab22235":"markdown","51dddbf1":"markdown","e0003688":"markdown","a1a576a3":"markdown","6a03c724":"markdown","64a61f0a":"markdown","ce5234cd":"markdown","dd195932":"markdown","55772148":"markdown","ec8c030a":"markdown","09810b1b":"markdown","01af82f9":"markdown","6657b9dd":"markdown","3a848437":"markdown","ffff2970":"markdown","e84b100d":"markdown","2a3005c5":"markdown"},"source":{"a9d1406f":"import warnings\nwarnings.filterwarnings('ignore', category=DeprecationWarning)","2ab1d924":"import pandas as pd","dccb07ee":"review_data = pd.read_csv('..\/input\/topic-analysis-of-review-data\/K8 Reviews v0.2.csv').drop('sentiment',axis=1)\nreview_data.head()","6f3673c2":"review_data.shape\n\n# We have 14K reviews ","eefca484":"review_data.isnull().sum()\n\n# Since our data has no null values will be skip this step","cf8ef9f5":"review_data['clean_review'] = review_data['review'].apply(lambda x: str(x).lower())\nreview_data.head()","de36ad96":"review_data['clean_review'] = review_data['clean_review'].str.replace(r'[^a-zA-Z\\s]', ' ',regex=True) \nreview_data.head()","c33f53df":"review_data['clean_review'] = review_data['clean_review'].str.replace(r'\\s{2,}', ' ',regex=True)\nreview_data.head()","636e4c25":"import nltk\nfrom nltk.tokenize import word_tokenize\nnltk.download('punkt')","bfa32236":"review_data['clean_review'] = review_data['clean_review'].apply(lambda x: word_tokenize(x))\nreview_data.head()","d54b262f":"!pip install stopwords","84c0d7fe":"from nltk.corpus import stopwords\nnltk.download('stopwords')","48ecd34c":"review_data['clean_review'] = review_data['clean_review'].apply\\\n(lambda x:[word for word in x if word not in stopwords.words(\"english\") and len(word) > 3 and word.isalpha()])\nreview_data.head()","3910285f":"review_data = review_data[review_data['clean_review'].map(lambda x: len(x)) > 1].reset_index(drop=True)\n# Keeping records with more than single words","7cd20dfe":"from nltk.stem import WordNetLemmatizer\nnltk.download('wordnet')","51dd50aa":"review_data['clean_review'] = review_data['clean_review'].apply\\\n(lambda x: [WordNetLemmatizer().lemmatize(word) for word in x])\nreview_data.head()","053e70c6":"nltk.download('averaged_perceptron_tagger')","68587f3a":"review_data['clean_review'] = review_data['clean_review'].apply\\\n(lambda x: [word for word in x if nltk.pos_tag([word])[0][1] == 'NN'])","b80ac4d9":"review_data = review_data[review_data['clean_review'].map(lambda x: len(x)) > 1].reset_index(drop=True)\n# Keeping records with more than single words","9c275f67":"review_data.head()","04822da2":"!pip install gensim","652bc1a7":"import gensim\nfrom gensim import corpora","ed2933b9":"dictionary = corpora.Dictionary(review_data['clean_review'])\nprint(dictionary)\n\n# We have 6724 unique tokens","a4b99f86":"doc_term_matrix = review_data['clean_review'].apply(lambda x: dictionary.doc2bow(x))\ndoc_term_matrix[:10]\n\n# Each tokenized words has been assigned index value and thier count in corpus","8149239d":"from IPython.display import clear_output","839bb008":"Lda = gensim.models.ldamodel.LdaModel\nldamodel = Lda(corpus=doc_term_matrix, num_topics=12, id2word=dictionary, passes=10,random_state=45)\nclear_output()\n\n# corpus requires document term matrix\n# num_topics is used to define number of topics to create from corpus\n# id2word requires mapping of words\n# passes is used to define number of iterations","25d04158":"ldamodel.print_topics()\n\n# We have printed all 12 topics and their keywords generated by LDA","6e5ea599":"!pip install pyLDAvis # To visualize lda model","a0a0405d":"import pyLDAvis\nimport pyLDAvis.gensim\n\npyLDAvis.enable_notebook()\nvis = pyLDAvis.gensim.prepare(ldamodel,doc_term_matrix,dictionary)\nvis","1116626a":"from gensim.models.coherencemodel import CoherenceModel\ncoherence_model_lda = CoherenceModel(model=ldamodel,texts=review_data['clean_review'],\\\n                                     dictionary=dictionary , coherence='c_v')\nprint('\\nCoherence Score: ', coherence_model_lda.get_coherence())\n\n# Compute Coherence Score\n","ba07e159":"# Computing coherence score for different size of topic\n\ndef calculate_topic_cv(ldamodel,texts,dictionary,topic_range):\n  cv_score =[]\n  topic_num = []\n  for i in range(2,topic_range):\n    topic_num.append(i)\n    Lda = gensim.models.ldamodel.LdaModel\n    ldamodel = Lda(doc_term_matrix, num_topics=i, id2word=dictionary, passes=10,random_state=45)\n    cv_score.append(CoherenceModel(model=ldamodel,texts=texts,\\\n                                   dictionary=dictionary , coherence='c_v').get_coherence())\n    clear_output()\n  return topic_num,cv_score","81f66573":"topic_num,cv_score = calculate_topic_cv(ldamodel,review_data['clean_review'],dictionary,15)","82e109c8":"pd.DataFrame(zip(topic_num,cv_score),columns=['Topic','Coherence_Score']).set_index\\\n('Topic').sort_values('Coherence_Score',ascending=False)","cb35bdb4":"import matplotlib.pyplot as plt\n\nplt.plot(topic_num,cv_score,color='green', marker='o', linestyle='dashed')\nplt.xticks(range(2,15))\nplt.xlabel('Number of topics')\nplt.ylabel('Coherence score')\nplt.show()","0bfd52b5":"# Creating LDA model with number of topics as 6\n\nLda = gensim.models.ldamodel.LdaModel\nldamodel = Lda(doc_term_matrix, num_topics=6, id2word=dictionary, passes=10,random_state=45)\nclear_output()\nprint(CoherenceModel(model=ldamodel,texts=review_data['clean_review'],\\\n                     dictionary=dictionary , coherence='c_v').get_coherence())","e0e315bb":"ldamodel.print_topics()","80bee3b1":"pyLDAvis.gensim.prepare(ldamodel,doc_term_matrix,dictionary)","edb1dcec":"review_data.head()","e68e5df8":"topic_lookup_data = pd.DataFrame((ldamodel.print_topics()),columns=['Topic_Number','Top_Keywords'])\ntopic_lookup_data['Topic_Name'] = ['Camera, Sound','Mixed issues','Heating issue','turbo charger','Connectivity','Battery']\ntopic_lookup_data = topic_lookup_data[['Topic_Number','Topic_Name','Top_Keywords']]\ntopic_lookup_data['Top_Keywords'] = topic_lookup_data.Top_Keywords.str\\\n.replace(r'[^a-z]',' ',regex=True).apply(lambda x: x.split())\ntopic_lookup_data.style.set_properties(subset=['Top_Keywords'], **{'width': '300px'})","79125974":"for index,sent in enumerate(ldamodel[doc_term_matrix]):\n  topic_num =[]\n  topic_details = sorted(sent,key=lambda x: x[1], reverse=True)[:2] # Getting top 2 topics in descending order\n  topic_num.append(topic_details[0][0]) # Appending top topic\n  if len(topic_details) > 1:\n    if topic_details[1][1] > 0.35: # Appending second topic only if it has more than 35% influence on current row\n      topic_num.append(topic_details[1][0])\n  review_data.loc[index,'Topic_Number'] = ','.join(str(x) for x in sorted(topic_num))","92bca37a":"for index,topic_num in enumerate(review_data.Topic_Number):\n  topic_name_list=[]\n  for single_topic_num in topic_num.split(','):\n    single_topic_num=int(single_topic_num)\n    topic_name_list.append(topic_lookup_data.loc\\\n                           [topic_lookup_data.Topic_Number == single_topic_num,'Topic_Name'][single_topic_num]) \n  # Extracting topic names from lookup table\n  review_data.loc[index,'Topic_Name'] =' & '.join(topic_name_list)","137105b0":"review_data.head()","4f1af172":"import seaborn as sns","abaeec0d":"plt.figure(figsize=(12,6))\nax = sns.barplot(x=review_data.Topic_Name.value_counts()[:6].index,y=review_data.Topic_Name.value_counts()[:6].values)\nfor p in ax.patches:\n    ax.annotate(p.get_height(), (p.get_x() + p.get_width() \/ 2., p.get_height()+50),ha = 'center', va = 'center')\nplt.xlabel('Topic Names',size=15)\nplt.ylabel('Count of topics',size=15)\nplt.title('Most talked topics in reviews',size=15)\nplt.show()\n","95909b87":"plt.figure(figsize=(12,6))\nax = sns.barplot(x=review_data.Topic_Name.value_counts()[6:].index,y=review_data.Topic_Name.value_counts()[6:].values)\nfor p in ax.patches:\n    ax.annotate(p.get_height(), (p.get_x() + p.get_width() \/ 2., p.get_height()+5),ha = 'center', va = 'center')\nplt.xlabel('Topic Names combined',size=15)\nplt.ylabel('Count of combined topics',size=15)\nplt.title('Most talked combined topics in reviews',size=15)\nplt.xticks(rotation=45)\nplt.show()\n","9607b6cb":"review_data.loc[review_data.Topic_Number.str.contains('5'),['review','Topic_Name']].head(10)\\\n.style.set_properties(subset=['review'], **{'width': '300px'})","4c4996c0":"## Visualization","f617f536":"From above graph we can say that most of customers had issues with Battery of mobile","bd72e648":"## 9. Document Term Matrix","add3cace":"Since, some topics in above graph are overlapping each other we will try to find optimal number of topics.","af844c43":"## 2. Converting to LOWER case","b8d0f6f6":"## 7. LEMMATIZATION","bab22235":"# Conclusion\n\n1. We can combine topic number 2 (Heating issue),3 (turbo charger), 5(Battery)\n2. If lenovo company improve their turbo charger that is causing heating issues in battery their mobile will be more appreciated by users.\n3. We can try to use other POS tags to improve our model.","51dddbf1":"## we will be going with number of topic 6 as with 8 topics there will be many overlaps .","e0003688":"From above graph we can say that most of customers had combined issues with,\n\n1.  Heating issue & Battery\n2.  Camera, Sound & Battery\n3.  turbo charger & Battery","a1a576a3":"## 1. Replacing\/Dropping NULL values","6a03c724":"<img src='https:\/\/drive.google.com\/uc?export=view&id=1If5liRr07PO--0r2E60l_2H6XdW6wiEs' height=250>\n\nIn this notebook, we will clean reviews of customer for a mobile brand and apply LDA model and extract relevant information from it.","64a61f0a":"## Visualizing LDA model topics","ce5234cd":"## Extracting reviews of 5 topic(review of battery)","dd195932":"# Data Pre-Processing","55772148":"# LDA","ec8c030a":"## 4. REMOVING WHITE SPACE","09810b1b":"## 5. WORD TOKENIZATION","01af82f9":"## 3. REMOVE NON-ALPHA DATA(DIGITS,PUNCTUATIONS,DIACRITICS)","6657b9dd":"## Creating new columns and inserting topic numbers and names","3a848437":"## 8. Extracting only NOUN","ffff2970":"## 6. REMOVE UNNECESSARY WORDS","e84b100d":"# References\n\n\n\n1.   https:\/\/towardsdatascience.com\/the-complete-guide-for-topics-extraction-in-python-a6aaa6cedbbc\n2.   https:\/\/github.com\/rsreetech\/LDATopicModelling\/blob\/main\/LDADemo.ipynb\n3.   https:\/\/stackoverflow.com\/questions\/62419353\/select-texts-by-topic-lda\n\n","2a3005c5":"## Creating a lookup table for topics"}}