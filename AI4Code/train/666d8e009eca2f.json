{"cell_type":{"e9e807bb":"code","971358f8":"code","078e9e2d":"code","a105c4f2":"code","8186186d":"code","2cc29be9":"code","9d216bb0":"code","8a170648":"code","edd179d8":"code","e160be3d":"code","383a53ca":"code","f25c3918":"code","df181f62":"code","9369bddd":"code","f572fbe4":"code","41302c76":"code","314369e5":"code","4ccc3290":"code","624dea97":"code","cedf7709":"code","89c60034":"code","4e3759d9":"code","2d0cdbd5":"code","3a2fb330":"code","af183061":"code","8e16afbc":"code","74273555":"code","ed4b6fe6":"code","83cd69b6":"code","3adae996":"code","6d82e1d5":"code","966ccb45":"code","9b2c0414":"code","5faecc4c":"code","f343af7d":"code","d1c9159a":"code","57bcc722":"code","5653fb11":"code","cc9407d8":"code","825e6b5e":"code","242077a1":"code","72031a2e":"code","6da18fcb":"code","d53b8bc6":"code","ddcd9c74":"code","c4538c19":"code","80442b17":"code","146cfdea":"code","835d43e3":"code","97a6d498":"code","46de089d":"code","94d68e8d":"code","be91663d":"code","1aced8da":"code","586801c0":"code","7894cfd4":"code","9acd932a":"code","b4b7b605":"code","85d4891f":"code","e4d1767a":"code","1fa164e5":"code","68522037":"code","01e1a1f7":"code","d55582a9":"code","f6c3b5b9":"code","dff5b1ba":"code","c2709a1f":"code","50b949d7":"code","05c2cc59":"code","65f8d47b":"code","9dca995c":"code","1d1d9ffc":"code","b94f9fbc":"code","a5e157c9":"code","5206871b":"code","192ae7cf":"code","e248c00e":"code","8c27ecad":"code","e3c9d845":"code","de2f03f5":"code","6807f98a":"code","3dd091fb":"code","6d370a35":"code","bda1aabd":"code","5da900a5":"code","08996ea9":"code","8c2fedbf":"code","b5888af5":"code","5ae6cdb5":"code","2c099c0a":"code","2928a579":"code","630ea433":"code","b79ef1df":"code","dd9ac45d":"code","9775b0c4":"code","a1953221":"code","76081c03":"code","dc816332":"code","9f54cdf5":"code","4cafe6af":"code","5beaec91":"code","66c504ba":"code","f5d5e45e":"code","8d7ad34e":"code","0088d1e2":"code","62a94314":"code","fff9b96a":"code","187718c2":"code","35467773":"code","08939787":"code","b8af39c1":"code","2da094b1":"code","ebbe91d4":"code","24951f7e":"code","8e30f40e":"code","a18285fb":"code","9f69e37f":"code","31a02a08":"code","c3a66631":"code","9473542c":"code","ee38eae4":"code","d2c94d77":"code","674b6217":"code","e79e9cb9":"code","c439e595":"code","24018ba9":"code","38f68b39":"code","31f01c7f":"code","962e3d91":"code","a8b22b0f":"code","06087d4e":"code","0319ddc7":"code","d20ab212":"code","312209c4":"code","5e9ba28a":"code","007ff8ef":"code","7cec2a21":"code","15970cb8":"code","f94d9336":"code","4f5bf8a3":"code","ff690771":"code","0eeca745":"code","483cb4a6":"code","bb9cec4a":"code","2d1ee759":"code","488209e6":"code","257ccc02":"code","dfb28815":"code","3575566d":"code","730929c8":"code","ea94c3da":"code","17c800fe":"code","7eec6193":"code","3a429795":"code","e3284116":"code","a7db352f":"code","ace09eb7":"code","ce8bd91c":"code","216f1d9d":"code","82297075":"code","fb6def6c":"code","4f478ad8":"code","0abd1b02":"code","9861635a":"code","744ad632":"code","09f1a9a9":"code","e380349e":"code","8a3aa0d5":"code","8f68af3f":"code","186a32f5":"code","94749d2f":"code","44fda64a":"code","8cb9cde5":"code","73a87ea2":"code","a48d90c1":"code","9e4e1365":"code","c4f4ca9b":"code","95912d8c":"code","4c6966e0":"code","a0f4b4f3":"code","9206d391":"code","af9dd05b":"code","a971fead":"code","8387ae53":"code","303a636b":"code","2667cd45":"code","fd06fd31":"code","327a2cb1":"code","70b62b72":"code","be825730":"code","3f332481":"code","0e24410c":"code","14759e67":"code","d63b3973":"code","4a117906":"code","eeb0ee71":"code","85658ad4":"code","a184b695":"code","40b138cd":"code","51a7d005":"code","87b013e2":"code","5869be1c":"code","a81ff73d":"code","b16e3747":"code","db65ee2a":"code","d3be7968":"code","d6bd55fb":"code","69b510e3":"code","4b5ccdca":"code","4bcc71b2":"code","4b1b79a2":"code","0edcdf2d":"code","e63f36a1":"code","878d2ef8":"code","7aace582":"code","8c827c21":"code","c73dec78":"code","cf92b25f":"code","e0ddc645":"code","661a532b":"code","a1619ea2":"code","8c3f0af0":"code","9ed0be29":"code","86324404":"code","db28f9ac":"code","fc2c1ba0":"code","6ea89a43":"code","accca09a":"code","f6a035f9":"code","75746619":"code","50fe161c":"code","c8c9f73b":"code","8f9d2ff6":"code","0a05deb7":"code","d5f6b0e3":"code","14f9f215":"code","a0b4d790":"code","ca88708d":"code","356aa4b3":"code","ebbd8137":"code","f3698801":"code","eeb11ca3":"code","77508b13":"code","e630ddee":"code","747c8feb":"code","5768564b":"code","716b6523":"code","2845e93e":"code","5b249c23":"code","7f83be5e":"code","d122f9b3":"code","fb30b98a":"code","d495f2d9":"code","f2ec4138":"code","8b6a5278":"code","a1763cf4":"code","22ca0663":"code","83bd67bf":"code","a9a237a5":"code","eb1ad9ce":"code","5398ff1f":"code","ca04d775":"code","5932152e":"code","a7a14204":"code","43f16aa4":"markdown","d2c7ca37":"markdown","01480f95":"markdown","f53b2898":"markdown","834d25e9":"markdown","d166d117":"markdown","b9a94928":"markdown","4b713b95":"markdown","68396832":"markdown","c292d31f":"markdown","c9ab8845":"markdown","a5a56686":"markdown","5c7932fb":"markdown","a678bc6c":"markdown","b0680a90":"markdown","ecc3897f":"markdown","540d0f74":"markdown","434134f7":"markdown","4ab94524":"markdown","0633ae35":"markdown","e562c1e7":"markdown","33e449e5":"markdown","ae581c30":"markdown","64c6ed55":"markdown","75114615":"markdown","26278af7":"markdown","f07c6712":"markdown","40731eef":"markdown","2c5d7fa5":"markdown","f8630ebf":"markdown","2bc9c0de":"markdown","f2b7fad8":"markdown","a73e6cbd":"markdown","467430ef":"markdown","cd45f513":"markdown","2a0bd32c":"markdown","b15ac172":"markdown","656d029f":"markdown","adbcb56a":"markdown","ca3bc557":"markdown","062d2f3f":"markdown","a357b859":"markdown","5d599140":"markdown","3280904d":"markdown","39e1f690":"markdown","ec72a903":"markdown","4fbdbbf8":"markdown","454dafd1":"markdown","17c33c76":"markdown","d51c25b9":"markdown","0f2c8701":"markdown","100e8f29":"markdown","c24ad31f":"markdown","277275c4":"markdown","8f61e913":"markdown","13c28ca0":"markdown","1c38f13d":"markdown","a8a25da3":"markdown","051b24ca":"markdown","6e47d9dd":"markdown","2b31da9f":"markdown","6bb6a017":"markdown","ee839d83":"markdown","42bbd6f1":"markdown","ae03aef7":"markdown","a10665b4":"markdown","9c522766":"markdown","55657b39":"markdown","0bd5d915":"markdown","bcc8cd30":"markdown","dfbf397e":"markdown","746831e6":"markdown","3ee398a2":"markdown"},"source":{"e9e807bb":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","971358f8":"import pandas as pd\nimport numpy as np\nimport pickle","078e9e2d":"filename = \"heart.csv\"","a105c4f2":"# handles datetime and most edge cases and file issues the best way\ndf = pd.read_csv(r'\/kaggle\/input\/heart-disease-uci\/heart.csv')","8186186d":"df","2cc29be9":"# for first five rows\ndf.head()","9d216bb0":"df3 = np.loadtxt(r'\/kaggle\/input\/heart-disease-uci\/heart.csv', delimiter=\",\", skiprows=1)","8a170648":"df3","edd179d8":"# we use genfromtxt here\ndf4 = np.genfromtxt(r'\/kaggle\/input\/heart-disease-uci\/heart.csv', delimiter=\",\", dtype=None, names=True, encoding='utf-8-sig')","e160be3d":"print(df4)\nprint(df4.dtype)","383a53ca":"file = r'\/kaggle\/input\/heart-disease-uci\/heart.csv'","f25c3918":"open(file)","df181f62":"def load_file(file):\n    with open(file, encoding='utf-8-sig') as f:\n        data, cols = [], []\n        for i, line in enumerate(f.read().splitlines()):\n            if i == 0:\n                cols += line.split(\",\")\n            else:\n                df = pd.DataFrame(df4, columns=cols)\n    return df\nload_file(file).head()","9369bddd":"# convert file to pickle if it isnt already\nimport pickle\nfile_name='df_file.pkl'\nf = open(file_name,'wb')\npickle.dump(df,f)\nf.close()","f572fbe4":"dfp = pd.read_pickle('df_file.pkl')\ndfp","41302c76":"objects = []\nwith (open(r'df_file.pkl', \"rb\")) as openfile:\n    while True:\n        try:\n            objects.append(pickle.load(openfile))\n        except EOFError:\n            break","314369e5":"df1 = pd.read_csv(r'\/kaggle\/input\/heart-disease-uci\/heart.csv')","4ccc3290":"import numpy as np\nimport pandas as pd\n\ndata = df1.to_numpy()","624dea97":"data","cedf7709":"df1.head()","89c60034":"# modify numpy data\ndata[0,0] = 100\ndata","4e3759d9":"# create a new dataframe using numpy through an existing one\ndf2 = df1[[\"age\", \"sex\", \"cp\"]]\ndata2 = df2.to_numpy()\ndata2[0,0] = 100\ndf2","2d0cdbd5":"# if you dont wanna tamper with the original data, then you make a copy of the numpy array version\ndf2 = df1[[\"age\", \"sex\", \"cp\"]]\ndata2 = df2.to_numpy().copy()\ndata2[0,0] = 100\ndf2","3a2fb330":"# get the mean of age column\nprint(df1['age'].mean())","af183061":" # we can also call it as a numpy and get the mean\nprint(df1['age'].to_numpy().mean())","8e16afbc":"# get a quanitle using pandas as numpy cant suport that\nprint(df1['age'].quantile(0.5))","74273555":"# we can use NUMPYs fpr reshaping as pandas cant support it\nprint(df1['age'].to_numpy().reshape((3,-1)))","ed4b6fe6":"import pandas as pd\nimport numpy as np","83cd69b6":"# we can use random to generate any Values and even rows and columns\ndata = np.random.random(size = (5,3))\ndata","3adae996":"# we also can create a calean Dataframe with Pandas\n# it minimum requires three columns to start \ndf = pd.DataFrame(data=data,columns=['A','B','c'] )","6d82e1d5":"df","966ccb45":"datacrush = pd.DataFrame(data={'A':[1,2,3], 'B':['Ammar', 'Amu', 'Ammy']})","9b2c0414":"datacrush","5faecc4c":"# we can also create a structure array using numpy extensions but for strings we have to specify \n# string limits\ndtype = [('A', np.int), ('B', (np.str,20))]","f343af7d":"dtype","d1c9159a":"# we now have to structure it using np.array\ndata = np.array([(1,'SAM'), (2,'ANS'), (3,'DAS')], dtype=dtype)","57bcc722":"print(data)","5653fb11":"print(data.dtype)","cc9407d8":"# now to further encode it in a DataFrame\ndf = pd.DataFrame(data)","825e6b5e":"df","242077a1":"# we can verify that\ndata = [{'A':1, 'B': 'SAM'}, {'A':2, 'B': 'ANS'}, {'A': 3, 'B': 'DAS'}]\ndata","72031a2e":"df = pd.DataFrame(data)","6da18fcb":"df","d53b8bc6":"# WE USE THE RANDOM FUNCTION FOR VALUES, AND DECIDE ON THE COLUMNS\ndf = pd.DataFrame(np.random.random(size=(100000,4)), columns=['A', 'B', 'C', 'D'])\ndf.head()","ddcd9c74":"df.to_csv(\"save.csv\",index=False, float_format=\"%0.4f\")","c4538c19":"df","80442b17":"df.to_pickle(\"save.pkl\")","146cfdea":"df","835d43e3":"# use df.to_ and then press 'tab' on your keyboard to see the number of options you can convert your df to\n# you have to install certain formats using 'pip install nameofformat-format'\n# hdf, which is heirarchal data format, is used for big data","97a6d498":" # https:\/\/jupyter-contrib-nbextensions.readthedocs.io\/en\/latest\/nbextensions\/execute_time\/readme.html \n    # all extentions for Jupyter notebook execution times","46de089d":"# WE USE THIS COMMAND TO CHECK ALL NOTEBOOK ACTICITY ON WINDOWS DIRECTORY\n%ls","94d68e8d":"df = pd.read_csv(r'\/kaggle\/input\/astronauts-who-are-been-to-space\/cosmonauts.csv')","be91663d":"# the first 2 rows\ndf.head(2)","1aced8da":"# the last 2 rows\ndf.tail(2)","586801c0":"# to show any three random rows from the dataframe, we can add replace to stop any duplicate rows from being shown\ndf.sample(3, replace=True)","7894cfd4":"# complete file summary\ndf.info()","9acd932a":"# to show the statistical summary of the file\ndf.describe()","b4b7b605":"# to show the total rows and columns\ndf.shape","85d4891f":"# to see al correlations between all files\ndf.corr()","e4d1767a":"# to calculate the connt of each number variable repaeated in the column\ndf['birth'].value_counts()","1fa164e5":"# to show the max values in all columns\ndf.max()","68522037":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \n\ndf = pd.read_csv(r'\/kaggle\/input\/heart-disease-uci\/heart.csv')","01e1a1f7":"df.head()","d55582a9":"# we use groupby method to group the data we want together to visualize and give it a file name and not the name \n# of the intial file\nchest_pain = df.groupby(by='cp').median()","f6c3b5b9":"# thus shown in the above code we are displaying the median of the cp file and its connections with all other values\n# in the reaming dataset\nchest_pain","dff5b1ba":"# normally we need to declare both x and y, when making a bar plot, it since cp is the only fact in this file,\n# it automatically recognises it as the base value x, we add the semi colon in the end to make it look cleaner \nchest_pain.plot.bar(y='age');","c2709a1f":"# if we wanna plot cp against allgiven values in the table\nchest_pain.plot.bar();","50b949d7":"# making a barplot with a more insightful view, with selected columns\nfig, ax = plt.subplots()\nax.bar(chest_pain['ca'],chest_pain['age'], label='age')\nax.set_xlabel('ca')\nax.legend();","05c2cc59":"# IF YOU WANNA USE A FUNCTION METHOD TO MAKE BARPLOT ACCORDING TO YOUR SPECIFICATIONS\nfig, ax = plt.subplots()\nax.bar(chest_pain['ca'],chest_pain['age'], label='age',\n       edgecolor='k', color=['red','blue','green','black'])\nax.set_xlabel('ca')\nax.set_xticks(chest_pain['ca']);","65f8d47b":"# USING BARPLOT WITH SEABORN LIBRARY,it also shows errors calulcated throughits error bars here \nimport seaborn as sns\nax = sns.barplot('cp', 'age', errcolor='w', capsize=0.1, data=df)","9dca995c":"# create a basic scatterplot\ndf.plot.scatter('age','cp');","1d1d9ffc":"# create a function for an advanced scatterplot with markers\nfig, ax = plt.subplots()\nax.scatter(df['age'],df['fbs'], marker='^',\n          s=60, c=df['age'], edgecolors='k',alpha=0.5)\nax.set_xlabel('age')\nax.set_ylabel('fbs');","b94f9fbc":"# create a heatbased scatterplot using seaborn library\nsns.scatterplot('age','fbs', hue='age', s =30, edgecolor='none', data=df);","a5e157c9":"# using groupby method\nages = df.groupby('age').median().reset_index()\nages.head()","5206871b":"ages.plot.line('age', ['trestbps', 'ca'])","192ae7cf":"# create a function for an advanced line plot \nfig,ax = plt.subplots()\nax.plot(ages['cp'], ages['trestbps'],ls=':',lw=0.7)\nax.set_xlabel('cp')\nax.set_ylabel('trestbps');","e248c00e":"# plotting methods\ndf = pd.read_csv(r'\/kaggle\/input\/heart-disease-uci\/heart.csv')\n# the first 2 rows\ndf.head(2)","8c27ecad":"# how to create 2 comparable plots at the same time\nfig, axes = plt.subplots(ncols=2)\ndf.plot.scatter(x='chol', y='thalach', ax=axes[0])\ndf.plot.scatter(x='chol', y='oldpeak', ax=axes[1])\nfig.tight_layout","e3c9d845":"# saving the first figure of scatter plot above\nfig2 = axes[0].get_figure()","de2f03f5":"# you can save accroding to your image specifications, this isjust a sample\nfig2.savefig('plots.png', bbox_inches='tight', transparent=True)","6807f98a":"# you can use this advanced function to create an entire plot using seaborn with multiple x bases\n# you can change the colour according to your needs to in the parenthesis after context\nwith plt.style.context(\"dark_background\"):\n    fig, axes =plt.subplots(ncols=3, sharey=True,\n                            gridspec_kw={'width_ratios':[2,1,1], 'wspace':0})\n    y ='age'\n    xs =['chol','trestbps','thalach']\n    for x, ax in zip(xs, axes):\n        ax.scatter(df[x],df[y])\n        ax.set_xlabel(x)\n        axes[0].set_ylabel(y)","3dd091fb":"# default\nwith plt.style.context(\"default\"):\n    fig, axes =plt.subplots(ncols=3, sharey=True,\n                            gridspec_kw={'width_ratios':[2,1,1], 'wspace':0})\n    y ='age'\n    xs =['chol','trestbps','thalach']\n    for x, ax in zip(xs, axes):\n        ax.scatter(df[x],df[y])\n        ax.set_xlabel(x)\n        axes[0].set_ylabel(y)","6d370a35":"# seaborn\nwith plt.style.context(\"seaborn\"):\n    fig, axes =plt.subplots(ncols=3, sharey=True,\n                            gridspec_kw={'width_ratios':[2,1,1], 'wspace':0})\n    y ='age'\n    xs =['chol','trestbps','thalach']\n    for x, ax in zip(xs, axes):\n        ax.scatter(df[x],df[y])\n        ax.set_xlabel(x)\n        axes[0].set_ylabel(y)","bda1aabd":"# you can save the images according  your specs as well\nwith plt.style.context(\"seaborn\"):\n    fig, axes =plt.subplots(ncols=3, sharey=True,\n                            gridspec_kw={'width_ratios':[2,1,1], 'wspace':0})\n    y ='age'\n    xs =['chol','trestbps','thalach']\n    for x, ax in zip(xs, axes):\n        ax.scatter(df[x],df[y])\n        ax.set_xlabel(x)\n        axes[0].set_ylabel(y)\n        # here\n        fig.savefig('output.pdf', dpi=100,bbox_inches='tight')","5da900a5":"fig.savefig('output.pdf')","08996ea9":"# histogramfor age, with 30 int conversions\ndf.age.plot.hist(bins=30);","8c2fedbf":"# a function to create two histogram and concatenate them into one \nfig, ax = plt.subplots()\nax.hist(df.trestbps, bins=20, histtype='step', label='trestbps')\nax.hist(df.thalach, bins=20, histtype='stepfilled', label='thalach', alpha=0.3, edgecolor='w')\nax.legend()","b5888af5":"df[['trestbps', 'thalach']].describe()","5ae6cdb5":"# plotthe boxplot\ndf[['trestbps', 'thalach']].plot.box();","2c099c0a":"# plot it in number refrence\nplt.boxplot(df[[\"trestbps\", \"thalach\"]].to_numpy());","2928a579":"# plot the boxplot using seaborn lib\nsns.boxplot(data=df[[\"trestbps\", \"thalach\"]]);","630ea433":"# create a boxplot with groupby method, as we can show how number ofnullvaluesmay change with changing \n# values\ndf.groupby('cp').boxplot(column=\"trestbps\", sharex=True,layout=(1,4), grid=False)\nplt.tight_layout();","b79ef1df":"fig, ax = plt.subplots()\nax.violinplot(df[['trestbps', 'thalach']].to_numpy());","dd9ac45d":"# extra illustration features\nfig, ax = plt.subplots()\nax.violinplot(df[['trestbps', 'thalach']].to_numpy(), bw_method=0.2);","9775b0c4":"# using violin with seaborn\nsns.violinplot(df[['trestbps', 'thalach']].to_numpy(),inner='quartile', bw_method=0.2);","a1953221":"# using this plot with seaborn library \nsns.swarmplot(data=df[['trestbps', 'thalach']], size=1);","76081c03":"sns.swarmplot(data=df[['trestbps', 'thalach']]);","dc816332":"# uaing both violinplots and swarmplots with seabornlib\nsns.violinplot(data=df[['trestbps', 'thalach']], inner=None);\nsns.swarmplot(data=df[['trestbps', 'thalach']]);","9f54cdf5":" df = pd.read_csv(r'\/kaggle\/input\/meteorite-landings\/meteorite-landings.csv')","4cafe6af":"df.head()","5beaec91":"# always check df.info to decide which columns shouldbe droppedor not\ndf.info()","66c504ba":"df =df.dropna(subset = ['reclat', 'reclat'])\ndf = df[df.reclong < 300]","f5d5e45e":"# 2d Histogram (staple)","8d7ad34e":"plt.hist2d(df.reclong,df.reclat,bins=200, vmax=4)\nplt.colorbar();","0088d1e2":"# Hexbin, ;is for showing nothing but the diagram and its implicit details.\ndf.plot.hexbin(x='reclong', y='reclat', vmax=2, gridsize=100, linewidth=0.25);","62a94314":"# Contour plots, using broader shapes to show data(ca be used for resource location by geologists)\nspacing = np.linspace(0,10,200)\nx, y = np.meshgrid(spacing, spacing)\nz = (np.sin(x) + np.cos(y) + 2 * np.arcsinh(x * y))**2\nplt.contour(x,y,z, levels=20)\nplt.colorbar();","fff9b96a":"# if you wanna make it more detailed\nc = plt.contour(x,y,z,levels=20)\nplt.clabel(c,inline='True', fmt='%0.1f')\nplt.colorbar();","187718c2":"# if you wanna filll labels\nc = plt.contourf(x,y,z,levels=20)\nplt.colorbar();","35467773":"# if you wanna edit the colors and info visuals\nplt.contourf(x,y,z, levels=10)\nc =  plt.contour(x, y, z, levels=10, colors=\"black\")\nplt.clabel(c, inline=True, fmt=\"%0.1f\");","08939787":"#  KDE\n# also known as rejection sampling \n# its used to bruteforce any sample from any surface, but is slow in running\nn = 50000\nxs, ys = np.random.uniform(0, 10, n), np.random.uniform(0, 10, n)\nzs = (np.sin(xs) + np.cos(ys) * np.arcsinh(xs * ys))**2\nzs \/= zs.max()\npassed = np.random.uniform(0,10,n) < 25\nxs, ys = xs[passed], ys[passed]\nplt.scatter(xs,ys, s=1,alpha=0.2);\n# we use the points here to reconstruct the points in the counterf plot","b8af39c1":"# lets now construct a KDE plot using the data programmng above with SNS\nsns.kdeplot(xs,ys);","2da094b1":"# make it more visible by carving it out by 20%\nsns.kdeplot(xs,ys, bw=0.2);","ebbe91d4":"# Joint Plots\n# Swap out the interior and marginal plots to your needs\n# used with seaborn\nsns.jointplot(data=df, x='reclong', y='reclat');","24951f7e":"# edit it frther according to your interests \nsns.jointplot(data=df, x='reclong', y='reclat', kind='hex',\n              gridsize=100, vmax=3, linewidth=0, marginal_kws = {'bins': 100});","8e30f40e":"# merge joint plots with KDE data wrangling\nsns.jointplot(x=xs, y= ys, kind='kde')","a18285fb":"# add extra features\nsns.jointplot(x=xs, y= ys, kind='hex', gridsize=20, cmap='magma');","9f69e37f":"# how to make so many plots at once using pairplot from seaborn\nsns.pairplot(data=df[['reclat','reclong', 'mass']]);","31a02a08":"# using tables in python for styling \nimport pandas as pd\nimport numpy as np\ndf = pd.DataFrame(np.random.normal(size=(6,6)), columns=[x for x in 'ABCDEF'])\ndf","c3a66631":"# function to highlight values\ndef neg_red(x):\n    return f\"color: {'red' if x < 0 else 'white'}\"\ndf.style.applymap(neg_red)","9473542c":"def gold_max(xs):\n    m = xs.to_numpy().max()\n    color = {True: \"background-color: #c78f2e\", False: \"\"} \n    is_max = (xs == m).replace(color)\n    return is_max\ndf.style.apply(gold_max, axis=None)","ee38eae4":"# when we use rainbowe, as purple here represents hwo more negative tha vlaues are and lighter \n# rep how more positive the values are\ndf.style.background_gradient(cmap='rainbow')","d2c94d77":"# abs is used to rank values in ascending order\ndf.abs().style.bar(align='left', width=100)","674b6217":"# when you choose the how the heading row should look \nhead ={'selector': 'th', 'props': [('text-align', 'centre')]}\ndf.style.set_table_styles([head]).bar(align='mid', color=['red','blue'],vmin=-3,vmax=3)","e79e9cb9":"# after ww\ndf.style.bar(align='mid', color=['red','blue'],vmin=-3,vmax=3)","c439e595":"# apply gold color on the bar graph\ndf.style.bar(align='mid', width=50).apply(gold_max,axis=None).applymap(neg_red)","24018ba9":"# we import the main libraries here\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns \nimport numpy as np\nfrom sklearn import manifold","38f68b39":"# you can also set your columns  after loading and reading the file\ndf = pd.read_csv(r\"\/kaggle\/input\/heart-disease-uci\/heart.csv\")\ntarget = df['target'].to_numpy()\ndf = df[['age','sex','cp','trestbps','chol','thalach']]\ndf.head()","31f01c7f":"# Visualizing all needed columns \npd.plotting.scatter_matrix(df);","962e3d91":"df.corr()","a8b22b0f":"# using heatmap from seaborn library to further color the visual corr\nsns.heatmap(df.corr(), annot=True, fmt='0.2f', square=True);","06087d4e":"np.random.seed(0)\nn = 2000\nt = np.linspace(0, 20, n)\nx = t * np.sin(t) + 0.2*np.random.normal(size=n)\ny = t * np.cos(t) + 0.2*np.random.normal(size=n)\nz = np.log(t+1) * np.sin(np.sqrt(t)) + 0.1 * np.random.normal(size=n)\na = np.log(t+1) * np.cos(np.sqrt(t)) + 0.1 * np.random.normal(size=n)\n\ndf2 = pd.DataFrame({'x': x, 'y': y, 'z': z, 'a':a})\ndata = df2.to_numpy()","0319ddc7":"pd.plotting.scatter_matrix(df2);","d20ab212":"# 3D diagram\nfrom mpl_toolkits.mplot3d import Axes3D\nfig = plt.figure()\nax = fig.add_subplot(projection='3d')\nax.scatter(x,y,z, c=t, s=3+a);","312209c4":"methods = [\n    (\"LLE\", manifold.LocallyLinearEmbedding(n_neighbors=20,method='standard')),\n    (\"LTSA\", manifold.LocallyLinearEmbedding(n_neighbors=20,method='ltsa')),\n    (\"Hessian LLE\", manifold.LocallyLinearEmbedding(n_neighbors=20,method='hessian')),\n    (\"Modified LLE\", manifold.LocallyLinearEmbedding(n_neighbors=20,method='modified')),\n    (\"Isomap\",manifold.Isomap()),\n    (\"MDS\",manifold.MDS(n_init=1)),\n    (\"SE\",manifold.SpectralEmbedding()),\n    (\"t-SNE\",manifold.TSNE()),\n]\nfig, axes =plt.subplots(nrows=2,ncols=4)\nfor (name,method), ax in zip(methods, axes.flatten()):\n     print(f\"Running{name}\")\n     g = method.fit_transform(data)\n     ax.scatter(g[:,0],g[:,1],c=t)\n     ax.set_title(name)\n     ax.set_xticklabels([])\n     ax.set_yticklabels([])","5e9ba28a":"# we mnake some changes to the plot here \nfig, axes =plt.subplots(nrows=2,ncols=4)\nfor (name,method), ax in zip(methods, axes.flatten()):\n     print(f\"Running{name}\")\n     try: \n        g = method.fit_transform(df.to_numpy())\n        ax.scatter(g[:,0],g[:,1],c=target)\n     except Exception:\n        print(f\"Method{name} failed\")\n     ax.set_title(name)\n     ax.set_xticklabels([])\n     ax.set_yticklabels([])","007ff8ef":"import pandas as pd\ndf =pd.read_csv(r'\/kaggle\/input\/ab-nyc-2019csv\/AB_NYC_2019.csv')","7cec2a21":"df.head(3)","15970cb8":"# create a highlight view frame for id \ndf2 = df.set_index('id')","f94d9336":"df2.head(3)","4f5bf8a3":"# lets check which id meets at which column, always use barckets for calling internal values, paRENTHESIS IS FOR CALLING\n# FUNCTIONS and printing values\ndf2.neighbourhood[2595]","ff690771":"df2.minimum_nights[2539]","0eeca745":"# we can use groupby to view and analyze certain columns\\\ndf3 = df2.groupby('host_name')\ndf3","483cb4a6":"# we can also use it to describe certain columns relationships to other columns\ndf3 = df2.groupby('host_name').mean()\ndf3.reset_index()","bb9cec4a":"df3.sort_index(ascending=False)","2d1ee759":"# You cqn also sort values \ndf.sort_values([\"latitude\", \"longitude\"])\ndf.head(3)","488209e6":"# how to get unique values in a column\ndf.neighbourhood_group.unique()","257ccc02":"df.neighbourhood_group.value_counts()","dfb28815":"# its not advisable to use inplace=True cause it creates copies\ndf.sort_values(['neighbourhood_group','host_name'],ascending=[False,True],inplace=True)","3575566d":"dfp = df.sort_values(['price'], ascending=False)","730929c8":"# we use double brackets when using multiple parametres\ndfp[['id', 'host_name', 'price']].head(5)","ea94c3da":"# create anew columns to check the average of prices\ndfp['price_rank'] = dfp.price.rank(method='average', ascending=False)","17c800fe":"dfp.head(5)","7eec6193":"import numpy as np \nimport pandas as pd\ndf =pd.read_csv(r'\/kaggle\/input\/ab-nyc-2019csv\/AB_NYC_2019.csv')","3a429795":"df.dtypes","e3284116":"df.host_name","a7db352f":"# FILTERING OUT COLUMNS\ndf[[\"host_name\",\"neighbourhood_group\"]]","ace09eb7":"# FILTER COLUMNS BY A CERTAIN PROPERTY\ndf[df.host_name == 'Taz']","ce8bd91c":"df.host_name =='Taz'","216f1d9d":"(df.host_name =='Taz').sum()","82297075":"# set it in a diff file\nmask = df.host_name =='Taz'\ndf[mask].head(2)","fb6def6c":"# lets create a rows showing consistent review from the given data\n# whenever we want to do anything numerical wityh the \nreviews_consistent = df[(df.number_of_reviews > 3) | (df.number_of_reviews > 50)]\nreviews_consistent.head(5)","4f478ad8":"reviews_consistent0 = df[(df.number_of_reviews < 10)]\nreviews_consistent.head(5)","0abd1b02":"# estabilish logic\nmask = np.logical_or((df.number_of_reviews > 3), (df.number_of_reviews > 50))\ndf[mask].head(2)","9861635a":"# set it to one of 2\ndf[~mask].head(2)","744ad632":"# use loc condtion to represent brackets on a filtered basis or filter values\ndf.loc[mask,['name','host_name']]","09f1a9a9":"df.loc[mask, :].head()","e380349e":"# check all first rows\ndf.iloc[0, :]","8a3aa0d5":"# check the first value in the second column\ndf.iloc[0,1]","8f68af3f":"# set the index and check the value of the first row in all columns\ndf2 = df.set_index('id')\ndf2.iloc[0,:]","186a32f5":"# check values of the second to fifth rows from 7th columns and onwards\ndf.iloc[1:4,7:]","94749d2f":"# check ranges between a certain column\ndf.loc[df.price.between(100,200), \"price\"].head()","44fda64a":"# check the rows with these values\n# for isin function which only recognises string va;lues you have to put [] in the paranthesis\ndf.loc[df.price.isin([100,200]), \"price\"].head()","8cb9cde5":"pd.show_versions()","73a87ea2":"# check the presence of a value\ndf  == \"John\"","a48d90c1":"# check value in a filtered form in each column\n(df  == \"John\").any()","9e4e1365":"# copy file\ndf_new = df.copy()","c4f4ca9b":"df_new['name'][0] = 'TESTING'\ndf_new.head(1)","95912d8c":"df_new[df_new.host_name == 'John']['name'] = 'Oh no'\ndf_new.head(1)","4c6966e0":"import pandas as pd\nimport numpy as np\n\ndf = pd.read_csv(r'\/kaggle\/input\/ab-nyc-2019csv\/AB_NYC_2019.csv')","a0f4b4f3":"df.head(2)","9206d391":"df.info()","af9dd05b":"df.dropna().info()","a971fead":"# we drop the column here using this method\ndf.dropna(subset=[\"last_review\"]).info()\ndf.dropna(axis=1).info()","8387ae53":"# we place the column back using this method\ndf.dropna(subset=[\"last_review\"]).info()","303a636b":"# we use this method to fill the data by using either forward filling or backward filling \ndf.fillna(0)","2667cd45":"# we replace values in the entire data frame \ndf.replace('John','Jono').head(1)","fd06fd31":"# replace values in a particular column \ndf.host_name.replace('John','Jono',limit=1)[0]","327a2cb1":"# replace multiple values at once \n# we have to use {} when being specific about certain values from certain columns when replacing them especially strings\ndf.replace({'John' : 'Jono', 'Brooklyn' : 'Brooky'}).head(1)","70b62b72":"import matplotlib.pyplot as plt\nplt.hist(df.price);","be825730":"# you capply a log function to see rates of exponential increase\nplt.hist(df.price, log=True);","3f332481":"# see a quartile range on the graph\nplt.hist(df.price.clip(upper=1000));","0e24410c":"# create a coptyto show a LOC condition as you dont want the original data affected by it\ndf4 = df.copy()","14759e67":"# we reomove outliers here \ndf4.loc[df4.price > 1000, 'price'] = 1000\nplt.hist(df2.price);","d63b3973":"import pandas as pd\ndf = df =pd.read_csv(r'\/kaggle\/input\/astronauts-who-are-been-to-space\/cosmonauts.csv')\ndf.head(1)","4a117906":"birthdate = pd.to_datetime(df['birth'])\nbirthdate","eeb0ee71":"# check just the year\nbirthdate.dt.year","85658ad4":"# how to change something specific from the column and showing it\n# zarya = pd.to_datetime(\"1998-11-20\")\n# df[\"age_at_zarya\"] = (zarya - birthdate).astype('datetime64')\n# df.head(3)","a184b695":"# update the data context of a column in a new column\ndf['birth_0'] = birthdate\ndf.head(3)","40b138cd":"# categoricals \ndf['personLabel'].unique()","51a7d005":"df['personLabel'].dtype","87b013e2":"# converting to category \ndf['personLabel'] = df['personLabel'].astype('category')\ndf['personLabel'].dtype","5869be1c":"df.head(1)","a81ff73d":"# you have to do 2 conversions at once if one conversion does not work \n# df.age_at_zarya.astype(\"str\").astype(\"float\").astype(\"int\")","b16e3747":"# drop a row by its its number\ndf.drop(3)","db65ee2a":"# drop multiple columns \n# df2.drop(columns=['Year','Group']).head()","d3be7968":"# we add rows\ndf2.append({\"Name\":\"Samuel Hilton\", \"Year\": 2010, \"Group\": 20.0}, ignore_index=True)","d6bd55fb":"# another filtered way to test before actaully doing it \ndf_sis = pd.DataFrame({\"Name\": [\"Al Hinton\"], \"Year\": [2010], \"Group\": [20.0]})\ndf_sis","69b510e3":"# add the df_sis file into df2\ndf2.append(df_sis, ignore_index=True)","4b5ccdca":"# if you want to sort it\n#df2.sort_values(by=['Group'])","4bcc71b2":"# Adding columns \ndf2['Col1'] = \"Whoa\"\ndf2","4b1b79a2":"df2.assign(some_col=\"someval\")","0edcdf2d":"# How to insert values\n#df2.insert(1,\"FirstName\", df.Name.str.split(\"\", 1,expand=True)[0])\n#df2.head()","e63f36a1":"# organize rows in a close up view by column \n#df3 = df.set_index(\"Name\")\n#df3.head()","878d2ef8":"# We transpose the data of each column using filename.T\ndf3.T","7aace582":"import pandas as pd\nimport numpy as np \n# create data using random function\ndata = np.round(np.random.normal(size=(4,3)),2)\ndf = pd.DataFrame(data, columns=['A','B','C'])\ndf.head()","8c827c21":"# using apply and lamda to add 1 to all values of a df file\ndf.apply(lambda x: 1 + np.abs(x))","c73dec78":"# viewing the original column of A using apply method\ndf.A.apply(np.abs)","cf92b25f":"# this function wont work\n#def double_if_positive(x):\n #   if x > 0:\n  #      return 2 *x\n   # return x\n# df.apply(double_if_positive)","e0ddc645":"# this function works to double each value in all rows in each columns\ndef double_if_positive(x):\n    x[x > 0] *= 2\n    return x\ndf.apply(double_if_positive)","661a532b":"df","a1619ea2":"# create copy of function use\n\ndef double_if_positive(x):\n    x = x.copy()\n    x[x > 0] *= 2\n    return x\n# raw by default is false but if we want to use more methods from numpy and pandas then we set it as True\ndf.apply(double_if_positive, raw=True)","8c3f0af0":"series = pd.Series([\"Steve\", \"Alex\", \"Jess\", \"Marks\"])","9ed0be29":"series.map({\"Steve\" : \"Stephen\"})","86324404":"# USING LAMBDA TO Map all null values\nseries.map(lambda s: f\"i am {s}\")","db28f9ac":"# display\ndisplay(df,df.abs())","fc2c1ba0":"series = pd.Series([\"Obi-Wan Kenobi\", \"Luke Sky Walker\", \"Han Solo\", \"Leia Organa\"])","6ea89a43":"# splitting a string variable\n\"Luke SkyWalker\".split()","accca09a":"# split all strings in the file\nseries.str.split()","f6a035f9":"# find out the loccation of a value in a column \nseries.str.contains(\"Luke Sky Walker\")","75746619":"# Use Upper string split(split in Capital letters)\nseries.str.upper().str.split()","50fe161c":"# User Defined Functions \ndata2 =np.random.normal(10,2,size=(10000,2))","c8c9f73b":"df2 = pd.DataFrame(data2,columns=[\"x\",\"y\"])","8f9d2ff6":"# create a hypothesis function\nhypot = (df2.x**2 + df2.y**2)**0.5\nprint(hypot[0])","0a05deb7":"# create a user defined function for hypothesis \ndef hypot(x,y):\n    return np.sqrt(x**2 + y**2)\n\nh1 = []\nfor index, (x,y) in df2.iterrows():\n    h1.append(hypot(x,y))\nprint(h1[0])","d5f6b0e3":"# the most simple way to create user defined function for a hypothesis\n#def hyp3(x,y):\n    #return np.sqrt(x**2, y**2)\n#h3 = hyp3(df2.x,df2.y)\n#print(h3[0])","14f9f215":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt","a0b4d790":"# first 5 columns\ndf.head(5)","ca88708d":"# check all info \ndf.info();","356aa4b3":"# adjust a data set \n#df = pd.read_csv(r'C:\\Users\\muham\\Downloads\\train.csv',low_memory=False, parse_dates=['Date'])","ebbd8137":"# group by in a new file var\n#dfx = df.groupby(\"Store\")\n#dfx","f3698801":"# check all corressponding values of Store column\n#df.groupby(by=\"Store\").sum()","eeb11ca3":"# sample data to show grouping\narrays = [['Falcon', 'Falcon', 'Parrot', 'Parrot'],['Captive', 'Wild', 'Captive', 'Wild']]","77508b13":"index = pd.MultiIndex.from_arrays(arrays, names=('Animal', 'Type'))","e630ddee":"df1 = pd.DataFrame({'Max Speed': [390., 350., 30., 20.]}, index=index)","747c8feb":"# SHOW MEAN OF A COLUMN USING GROUPING\ndf1.groupby(level=0).mean()","5768564b":"df1.mean()","716b6523":"#store_avg = dfx.mean()\n#store_avg.head(5)","2845e93e":"# reset the index\n#store_avg = store_avg.reset_index()","5b249c23":"# make a scatter plot(it will only work when you reset the index in order to recognise store as a variable)\n#store_avg.plot.scatter(\"Store\", \"Sales\",s=3, title='Avg sale per store')","7f83be5e":"# show the mean of multiple columns to each corresponding row in a variable\n#store_day = df.groupby([\"Store\",\"DayOfWeek\"], as_index=False).mean()\n#store_day.head()","d122f9b3":"# using a function to generate a visual\n#for store in df.Store.unique()[:5]:\n    #df_temp = store_day[store_day.Store == store]\n    #plt.plot(df_temp.DayOfWeek, df_temp.Sales, label=f\"Store {store}\")\n#plt.xlabel(\"day of week\")\n#plt.xlabel(\"avg Sales\")\n#plt.legend();","fb30b98a":"#df.groupby('Sales').mean()","d495f2d9":"#df.Sales.describe()","f2ec4138":"# create bins\nbins = [0, 2000,4000, 6000, 8000, 10000, 50000]","8b6a5278":"# using pd.cut to merge the bins with Sales\n#cuts = pd.cut(df.Sales, bins, include_lowest=True)\n#df['SalesGroup'] = cuts\n#df.head()","a1763cf4":"# check all corresponding values of Store and Sales to DayOfWeek\n#df.groupby(['Store','Sales']).DayOfWeek.value_counts()","22ca0663":"# Do it in a neater version with all null values filled\n#df.groupby(['Store','Sales']).DayOfWeek.value_counts().unstack(fill_value=0)","83bd67bf":"# group 3 columns together\n#df.groupby(['Store','Sales','DayOfWeek']).count()","a9a237a5":"# measure their count against sales\n#df.groupby(['Store','SalesGroup','DayOfWeek']).Sales.count()","eb1ad9ce":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt","5398ff1f":"#plt.hist(dfo.Sales);","ca04d775":"# lets create a new copy file\n#df = dfo[dfo.Open == 1].copy()\n#plt.hist(df.Sales)\n#print(df.shape)","5932152e":"# show valye layers for better data driven insights\n#mask = np.random.choice(10, df.shape[0]) == 0\n#df[\"newSales\"] = df.Sales.copy()\n#df.loc[mask, \"newSales\"] = np.nan\n\n# compare the levels of corrupted values in refrence to the original value\n#plt.hist(df.Sales, label='Original', histtype='step')\n#plt.hist(df.newSales.fillna(0), label='corrupted', histtype='step')\n#plt.legend(), plt.xlabel('Sales');","a7a14204":"# lets fill it now using mean instead using a transform function \n#test_fix = df.newSales.transform(lambda x: x.fillna(x.mean()))\n#plt.hist(test_fix, bins=100);","43f16aa4":"thus verfied","d2c7ca37":"# Intelligent Imputation","01480f95":" This proves to be very inaccurate and so many stores have variances in amount of sales amnd is seasonal \n and we need to take those factors into consideration here","f53b2898":"# SCATTER PLOTS","834d25e9":"for completely weird file structures","d166d117":"# Dealing with NaNs","b9a94928":"# Basic Data Manipulation","4b713b95":"# Vectorised functions \nHighly present in pandas and Numpy ","68396832":"# Violin Plots","c292d31f":"currently not widely used in pandas","c9ab8845":"# Thresholding","a5a56686":"Indexing, Slicing, Ordering, Filtering, Replacing and cleaning","5c7932fb":"# using numpy loadtxt and genfromtxt","a678bc6c":" Histogram\n the most common method of distributions","b0680a90":"# Filtering Based on Index","ecc3897f":"# Grouping\ncode syntax, imputation and aggregation options ","540d0f74":"Line Plots","434134f7":"So we can see it can symbolise the bandwidth of a value","4ab94524":"# Correlation Matrix\nshows the correlation of all columns","0633ae35":"Lets assume here some computer malfunction has ruined 10% of our data","e562c1e7":"# Creating DataFrames","33e449e5":"# Sorting \n# to sort values according to the needs of analysis and programming","ae581c30":"# Pickle ","64c6ed55":"# Multiple Groups\n","75114615":"Show mean,interquartile, quartiles and outliers","26278af7":" it fails without additional arguments, thus its only as smarts as we tell it to be and is only meant to load data saved using np.savetxt","f07c6712":"# Continuous grouping ","40731eef":"# With the help of a Udemy course (Data manip with Pandas)","2c5d7fa5":"INDEXING LABELLING AND ORDERING","f8630ebf":"Pandas has a numpy core, extra structures and tools but you sometime have to strip it away","2bc9c0de":"# Higher Dimension Visualizations","f2b7fad8":"# 2D Distributions ","a73e6cbd":"# Basics- Removing and Adding Data\nUsing explicit sorting order rather than lexical order and huge speed improvements if you group on categories \nInformation be Utilised by other libraries pandas interfaces with.","467430ef":"# Visualising 1D Distributions","cd45f513":"# Slicing and Filtering \ntwo of the most common data frames ","2a0bd32c":"# best method as know is pd.read_csv","b15ac172":"# I want to work with Rows\/Columns but i have columns\/Rows","656d029f":"# Scatter Max","adbcb56a":"# Replacing and Thresholding","ca3bc557":"# Basics: Apply, Map and vectorised Functions","062d2f3f":"# MAPS \nsimilar to apply but operates on Series & Uses Dictionary based inputs rather than an array of values","a357b859":"# Modifying types of columns\n# common for time series, categoricals or converting strings to numerics\n#Also useful for timeseries","5d599140":"# another way to do it\nplt.hist(df.age, bins=30);","3280904d":"Pickles have a bit of danger  such as encoding changes, use industry standard like hd5 and dont use this if youre working with data frames and dont forget pandas has their own implementation of pickle such df.to_pickle and df.read_pickle. and suports compression\n","39e1f690":"# Inspecting Data ","ec72a903":"# BoxPlots","4fbdbbf8":"introduction to super basic  plots","454dafd1":"# Adding Rows","17c33c76":"# Visualizing the Data ","d51c25b9":"Bar plot","0f2c8701":"# Provided Mask Helpers","100e8f29":"They are fancy plots for presentations but less concise than other plots","c24ad31f":"# Ranking\nlike sorting but with collission detection","277275c4":"notice the change in column values now of [0,0, which means 0 row and 0 column ","8f61e913":"# Bee Swarm Plots","13c28ca0":"# Numeric String Conversion","1c38f13d":"csV IS THE BEST DATAFRAME TO USE IN PYTHON PROGRAMMING","a8a25da3":"# We will Visualize ND Data here","051b24ca":" # Saving and Serialising","6e47d9dd":"# more complicated methods like a 4-dimensional spiral","2b31da9f":"# Apply\nused to execute an arbitrary function again an entire dataframe \nApplies to a vectories fashion","6bb6a017":"# Manual Loading","ee839d83":"# Manifold Learning\nit follows sklearn algorithms","42bbd6f1":"Grouping - Imputation\nUsing groupby to smartly fill missing values","ae03aef7":"# views vs Copy","a10665b4":" SO we can say that Pandas is good for quick plots while matplotlib is verbose but has more control and good formore descriptive insights","9c522766":"# Visualizing 2D Data","55657b39":"# NUMPY VS PANDAS ","0bd5d915":"# Pandas vs Matplotlib","bcc8cd30":"# Indexing \nFinding a unique value from a list of values\nBasically the primary key such as id","dfbf397e":"its been added in row 357","746831e6":"Libraries like sklearn have programmed algorithms for finding higher dimension data and relating it with lower dimension levels, something human minds are still not capable of doing at once","3ee398a2":" 2D Histogram, CounterpLot, KDE"}}