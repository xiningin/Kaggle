{"cell_type":{"f9ca9ebc":"code","0c0f2ce2":"code","673295f9":"code","8c2dc843":"code","cdfb962f":"code","04d33346":"code","dc9af9a1":"code","1ca65ecf":"code","5dc35aac":"code","6ddb55b0":"code","9b30c756":"code","4e19d39c":"code","2c00cdd6":"code","361f5d66":"code","8b22b044":"code","398cdacb":"code","fda2d3a2":"code","16e7ed9e":"markdown","e2466973":"markdown","21c94b32":"markdown","5f950132":"markdown","b0a77644":"markdown","48012f4e":"markdown","94e3eacd":"markdown","e7c4566b":"markdown","cb4a8a49":"markdown","7d13b0ce":"markdown","06246c18":"markdown","696cc9f4":"markdown","e3cc8e2e":"markdown","13263197":"markdown","6e717a3c":"markdown","30c4daba":"markdown","3cd3b8af":"markdown","d87f3262":"markdown","0be238fc":"markdown","271eb0f9":"markdown","171318bf":"markdown","25b0e307":"markdown"},"source":{"f9ca9ebc":"import pandas as pd\nimport pylab as pl\nimport numpy as np\nimport scipy.optimize as opt\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline \nimport matplotlib.pyplot as plt","0c0f2ce2":"#Click here and press Shift+Enter\n!wget -O cell_samples.csv https:\/\/s3-api.us-geo.objectstorage.softlayer.net\/cf-courses-data\/CognitiveClass\/ML0101ENv3\/labs\/cell_samples.csv","673295f9":"cell_df = pd.read_csv(\"cell_samples.csv\")\ncell_df.head()","8c2dc843":"#refer the DataSlicing and Mathplotlib Notebooks for details about ploting and slicing the data\nax = cell_df[cell_df['Class'] == 4][0:50].plot(kind='scatter', x='Clump', y='UnifSize', color='DarkBlue', label='malignant');\ncell_df[cell_df['Class'] == 2][0:50].plot(kind='scatter', x='Clump', y='UnifSize', color='Yellow', label='benign', ax=ax);\nplt.show()","cdfb962f":"cell_df.dtypes","04d33346":"cell_df = cell_df[pd.to_numeric(cell_df['BareNuc'], errors='coerce').notnull()]\ncell_df['BareNuc'] = cell_df['BareNuc'].astype('int')\ncell_df.dtypes","dc9af9a1":"feature_df = cell_df[['Clump', 'UnifSize', 'UnifShape', 'MargAdh', 'SingEpiSize', 'BareNuc', 'BlandChrom', 'NormNucl', 'Mit']]\nX = np.asarray(feature_df)\nX[0:5]","1ca65ecf":"cell_df['Class'] = cell_df['Class'].astype('int')\ny = np.asarray(cell_df['Class'])\ny [0:5]","5dc35aac":"X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)","6ddb55b0":"from sklearn import svm\nclf = svm.SVC(kernel='rbf')\nclf.fit(X_train, y_train) ","9b30c756":"yhat = clf.predict(X_test)\nyhat [0:5]","4e19d39c":"from sklearn.metrics import classification_report, confusion_matrix\nimport itertools","2c00cdd6":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","361f5d66":"# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, yhat, labels=[2,4])\nnp.set_printoptions(precision=2)\n\nprint (classification_report(y_test, yhat))\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['Benign(2)','Malignant(4)'],normalize= False,  title='Confusion matrix')","8b22b044":"from sklearn.metrics import f1_score\nf1_score(y_test, yhat, average='weighted') ","398cdacb":"from sklearn.metrics import jaccard_similarity_score\njaccard_similarity_score(y_test, yhat)","fda2d3a2":"# write your code here\n","16e7ed9e":"The ID field contains the patient identifiers. The characteristics of the cell samples from each patient are contained in fields Clump to Mit. The values are graded from 1 to 10, with 1 being the closest to benign.\n\nThe Class field contains the diagnosis, as confirmed by separate medical procedures, as to whether the samples are benign (value = 2) or malignant (value = 4).\n\nLets look at the distribution of the classes based on Clump thickness and Uniformity of cell size:","e2466973":"We want the model to predict the value of Class (that is, benign (=2) or malignant (=4)). As this field can have one of only two possible values, we need to change its measurement level to reflect this.","21c94b32":"## Train\/Test dataset","5f950132":"<h1>Table of contents<\/h1>\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n    <ol>\n        <li><a href=\"#load_dataset\">Load the Cancer data<\/a><\/li>\n        <li><a href=\"#modeling\">Modeling<\/a><\/li>\n        <li><a href=\"#evaluation\">Evaluation<\/a><\/li>\n        <li><a href=\"#practice\">Practice<\/a><\/li>\n    <\/ol>\n<\/div>\n<br>\n<hr>","b0a77644":"<h2 id=\"evaluation\">Evaluation<\/h2>","48012f4e":"You can refer <a href=\"https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.to_numeric.html\">Pandas Documentation <\/a> of to_numeric for more details.  \n\n* pandas.to_numeric(arg, errors='raise', downcast=None)\n\n* Convert argument to a numeric type.\n\nThe default return dtype is float64 or int64 depending on the data supplied. Use the downcast parameter to obtain other dtypes.\n\n   Parameters\n\n1. args : Scalar, list, tuple, 1-d array, or Series\n2. errors : {\u2018ignore\u2019, \u2018raise\u2019, \u2018coerce\u2019}, default \u2018raise\u2019\n            If \u2018raise\u2019, then invalid parsing will raise an exception.\n            If \u2018coerce\u2019, then invalid parsing will be set as NaN.\n            If \u2018ignore\u2019, then invalid parsing will return the input.\n        downcast{\u2018integer\u2019, \u2018signed\u2019, \u2018unsigned\u2019, \u2018float\u2019}, default None\n\nIf not None, and if the data has been successfully cast to a numerical dtype (or if the data was numeric to begin with), downcast that resulting data to the smallest numerical dtype possible according to the following rules:\n\n  \u2018integer\u2019 or \u2018signed\u2019: smallest signed int dtype (min.: np.int8)\n\n  \u2018unsigned\u2019: smallest unsigned int dtype (min.: np.uint8)\n\n  \u2018float\u2019: smallest float dtype (min.: np.float32)\n","94e3eacd":"Okay, we split our dataset into train and test set:","e7c4566b":"After being fitted, the model can then be used to predict new values:","cb4a8a49":"You can also easily use the __f1_score__ from sklearn library:","7d13b0ce":"In this notebook, you will use SVM (Support Vector Machines) to build and train a model using human cell records, and classify cells to whether the samples are benign or malignant.\n\nAs we discussed in the class SVM is to map data to a high-dimensional feature space so that data points can be categorized, even when the data are not otherwise linearly separable. A separator between the categories is found, then the data is transformed in such a way that the separator could be drawn as a hyperplane. Following this, characteristics of new data can be used to predict the group to which a new record should belong.","06246c18":"It looks like the __BareNuc__ column includes some values that are not numerical. We can drop those rows: ","696cc9f4":"<h2>Thanks for completing this lesson!<\/h2>\n<h4>Author:  Santosh Bothe <\/a><\/h4>\n<hr>\n\n<p>Copyright &copy; 2020 ML Class IEDC Shirur.","e3cc8e2e":"Double-click __here__ for the solution.\n\n<!-- Your answer is below:\n    \nclf2 = svm.SVC(kernel='linear')\nclf2.fit(X_train, y_train) \nyhat2 = clf2.predict(X_test)\nprint(\"Avg F1-score: %.4f\" % f1_score(y_test, yhat2, average='weighted'))\nprint(\"Jaccard score: %.4f\" % jaccard_similarity_score(y_test, yhat2))\n\n-->","13263197":"### Load Data From CSV File  ","6e717a3c":"\n<h1 align=center><font size=\"5\"> Machine Learning (IT):  Sem V <\/font><\/h1>\n<h1 align=center><font size=\"5\"> SVM (Support Vector Machines)<\/font><\/h1>\n","30c4daba":"Lets first look at columns data types:","3cd3b8af":"<h2 id=\"load_dataset\">Load the Cancer data<\/h2>\nThe example is based on a dataset that is publicly available from the UCI Machine Learning Repository (Asuncion and Newman, 2007)[http:\/\/mlearn.ics.uci.edu\/MLRepository.html]. The dataset consists of several hundred human cell sample records, each of which contains the values of a set of cell characteristics. The fields in each record are:\n\n|Field name|Description|\n|--- |--- |\n|ID|Clump ID|\n|Clump|Clump thickness|\n|UnifSize|Uniformity of cell size|\n|UnifShape|Uniformity of cell shape|\n|MargAdh|Marginal adhesion|\n|SingEpiSize|Single epithelial cell size|\n|BareNuc|Bare nuclei|\n|BlandChrom|Bland chromatin|\n|NormNucl|Normal nucleoli|\n|Mit|Mitoses|\n|Class|Benign or malignant|\n\n<br>\n<br>\n\nFor the purposes of this example, we're using a dataset that has a relatively small number of predictors in each record. To download the data, we will use `!wget` (We studied it in last Lab) to download it from IBM Object Storage.  \n","d87f3262":"<h2 id=\"modeling\">Modeling (SVM with Scikit-learn)<\/h2>","0be238fc":"<h2 id=\"practice\">Practice<\/h2>\nCan you rebuild the model, but this time with a __linear__ kernel? You can use __kernel='linear'__ option, when you define the svm. How the accuracy changes with the new kernel function?","271eb0f9":"## Data pre-processing and selection","171318bf":"The SVM algorithm offers a choice of kernel functions for performing its processing. Basically, mapping data into a higher dimensional space is called kernelling. The mathematical function used for the transformation is known as the\u00a0kernel\u00a0function, and can be of different types, such as:\n\n    1.Linear\n    2.Polynomial\n    3.Radial basis function (RBF)\n    4.Sigmoid\nEach of these functions has its characteristics, its pros and cons, and its equation, but as there's no easy way of knowing which function performs best with any given dataset, we usually choose different functions in turn and compare the results. Let's just use the default, RBF (Radial Basis Function) for this lab.","25b0e307":"Lets try jaccard index for accuracy:"}}