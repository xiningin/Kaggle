{"cell_type":{"c2517bd4":"code","854658c1":"code","d9896232":"code","0da16fc6":"code","6740f45c":"code","9a54b7dc":"code","c8373e5c":"code","4741f1a0":"code","2011c720":"code","a9f458c7":"code","32934087":"code","5201bd7e":"code","a27bc6e8":"markdown","72c733f3":"markdown","6bf0d059":"markdown","4ac207de":"markdown"},"source":{"c2517bd4":"!pip install textract","854658c1":"import textract","d9896232":"!pip install wget\nimport wget\ndef fetch_pdf(link):\n    wget.download(link)\n    return link.split('\/')[-1]","0da16fc6":"!pip install bs4\n!pip install urllib3","6740f45c":"import bs4 as bs\nimport urllib.request\ndef get_links():\n    links=[]\n    source = urllib.request.urlopen('https:\/\/www.google.com\/covid19\/mobility\/')\n    print(f'Fetching links from {source}')\n    soup = bs.BeautifulSoup(source,'lxml')\n    print(soup.title)\n    for anchors in soup.find_all('a',class_=\"download-link\"):\n        links.append(anchors.get('href'))\n    print(f'Successfully retrieved links')\n    return links","9a54b7dc":"import os\ndef delete_pdf(pdf):\n    os.remove(pdf)\n    print(f'removed:{pdf}')","c8373e5c":"def extract_text(pdf):\n    text = textract.process(pdf)\n    print(f'Extracting text from {pdf}')\n    paras=text.decode().split('\\n\\n')\n    country=paras[1][0:paras[1].find('March')].strip()\n    retail_val=paras[7]\n    grocery_val=paras[10]\n    park_val=paras[13]\n    transit_val=paras[43]\n    work_val=paras[46]\n    resi_val=paras[49]\n    res=[country,retail_val,grocery_val,park_val,transit_val,work_val,resi_val]\n    return res","4741f1a0":"import csv","2011c720":"def write_results_to_csv(res,csv_file):\n    with open(csv_file,'a',newline='') as file:\n        writer=csv.writer(file)\n        writer.writerow(res)\n    print(f'wrote {res} to {csv_file}')","a9f458c7":"csv_file='mobility_google.csv'\n!rm {csv_file}\nres=['Country','Retail & recreation','Grocery & pharmacy', 'Parks', 'Transit stations', 'Workplaces', 'Residential']\nwrite_results_to_csv(res,csv_file)","32934087":"links=get_links()\nfor link in links:\n    pdf=fetch_pdf(link)\n    print(f'Link fetched. File:{pdf}')\n    res=extract_text(pdf)\n    write_results_to_csv(res,csv_file)\n    delete_pdf(pdf)","5201bd7e":"!cat mobility_google.csv","a27bc6e8":"[https:\/\/www.google.com\/covid19\/mobility\/](https:\/\/www.google.com\/covid19\/mobility\/) has Mobility results for March 2020. However they are stored in the form of PDFs. With no access to consumable dataset, this was a perfect opportunity to convert the PDFs into CSVs.\n\nI use Python library _textract_ to extract information from the pdf.","72c733f3":"**Beautiful Soup**, another Python library, allows users to parse data [scrape] from URLs.\n\nAlternative - `Scrapy`\/`Requests`","6bf0d059":"## [COVID 19 Mobility](https:\/\/www.google.com\/covid19\/mobility\/)\n\nCOVID-19 has impacted the mobility of human civilization. Using Google Maps, one can get a fair bit of understanding abotu the trends in mobility across the globe. Thanks to Google and thanks to the users who have turn the location sharing on.","4ac207de":"Values retrieved from the PDF\n* Retail & recreation\n* Grocery & pharmacy\n* Parks\n* Transit stations\n* Workplaces\n* Residential"}}