{"cell_type":{"9daa5773":"code","6897a106":"code","6a7f286d":"code","a6994fdb":"code","cc7b93d9":"code","b3b8fccd":"code","4382f5ca":"code","2159bbc8":"code","ca78ce1e":"code","8c4f60df":"code","1f3afee9":"code","a532604f":"code","9d7ed43e":"code","8819e6ec":"code","17e7bb2c":"code","0eb07fc6":"code","8149d13f":"code","31f8a68d":"code","273ee53f":"code","45ded9cc":"code","ee71923d":"code","736cc1bc":"code","3493ede8":"code","1a4fd622":"code","9a25a3b5":"code","8b9f9ee7":"code","b7132b0f":"code","5f260ddd":"code","0f508885":"code","b5114cb2":"code","9709e6da":"code","88f81dc7":"code","15739d31":"code","42dcffe4":"code","7cd54ef2":"code","fd440880":"markdown","1a9fd0c6":"markdown","f0c8ee34":"markdown","5fcabfa4":"markdown","ad85bc73":"markdown","848dc329":"markdown","e2b85cc8":"markdown","c4e7b2d6":"markdown","72a4d217":"markdown","040c4284":"markdown","9496b31a":"markdown","337975da":"markdown","f6032ff4":"markdown","503fb84d":"markdown","b5c5f72d":"markdown","5c436446":"markdown","6e465c30":"markdown","19326972":"markdown","ad3d9568":"markdown","684573e0":"markdown","bd49dbb6":"markdown","1190fbc7":"markdown","f998cea1":"markdown","9e1718c7":"markdown"},"source":{"9daa5773":"#\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#\nfrom imblearn.over_sampling import SMOTE \nfrom imblearn.under_sampling import RandomUnderSampler\n#\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import  precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import RocCurveDisplay\nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import plot_roc_curve,roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\n\n#\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression","6897a106":"#---------- configs\npd.set_option('max_rows',100)\npd.set_option('max_columns',100)","6a7f286d":"### loading data\ndf_train = pd.read_csv(r\"..\/input\/pima-indians-diabetes-database\/diabetes.csv\")\ndf_train.info()","a6994fdb":"df_copy = df_train.copy()","cc7b93d9":"sns.countplot(data = df_copy,x='Outcome')\nplt.title('Diabetes Class 0 , 1 Count')\nplt.show()","b3b8fccd":"numerical_columns = list(df_copy.select_dtypes(exclude=['object']).columns)\n\ndef plot_numerical_histogram(df,x_cols=[],rows = 2,cell_size = 4):\n    size = len(x_cols)\n    cols = size \/\/ rows\n    fig,axes = plt.subplots(rows,cols,figsize=(cols * cell_size, rows * cell_size))\n    fig.suptitle(\"Variable Histogram\")\n    for i,axe in enumerate(axes.flatten()):\n        if(i < size):\n            sns.histplot(df[x_cols[i]],ax=axe,alpha=0.4)\n            median = df[x_cols[i]].median()\n            axe.set_title(x_cols[i] + f' ,Median : {median:0.1f}')\n            axe.axvline(median, color ='red',lw=2, alpha = 0.55)\n        else:\n            print('subplots > n of columns, change n of rows')\n            break \n    plt.tight_layout()\n    plt.show()\nplot_numerical_histogram(df_copy,numerical_columns,rows=2)","4382f5ca":"plt.figure(figsize=(10,8))\nsns.heatmap(df_copy.corr(),annot=True,square=True,linewidths=1,cmap='mako',cbar=True)\nplt.show()","2159bbc8":"sns.scatterplot(data=df_copy,x='Insulin',y='Glucose',hue='Outcome',palette='Set1',alpha=0.5,x_jitter=0.2,y_jitter=0.3)\nplt.title('Insuline and Glucose')\nplt.show()","ca78ce1e":"sns.scatterplot(data=df_copy,x='BMI',y='SkinThickness',hue='Outcome',palette='Set1',alpha=0.5)\nplt.title('SkinThickness and BMI')\nplt.show()","8c4f60df":"sns.boxenplot(data=df_copy,y='Age',x='Pregnancies')\nplt.title('Pregnancies and Age')\nplt.show()","1f3afee9":"# split for processing by train information\ntrain,test = train_test_split(df_copy, test_size = 0.2,stratify=df_copy['Outcome'], random_state=47)","a532604f":"def encode_data_series(df_prep,df_original,col_name,from_vals,to_vals):\n    df_prep[col_name] = df_original[col_name].replace(from_vals,to_vals,inplace=False)","9d7ed43e":"train_copy = train.copy()\ntest_copy = test.copy()","8819e6ec":"incorrect_cols = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin','BMI']\n \nencode_data_series(train_copy,train,incorrect_cols,[0],[np.nan])\nencode_data_series(test_copy,test,incorrect_cols,[0],[np.nan])","17e7bb2c":"train_copy.isna().sum()","0eb07fc6":"low_missing = ['Glucose','BloodPressure','BMI']\n\nfor na_col in low_missing:\n    encode_data_series(train_copy,train_copy,[na_col],[np.nan],train[na_col].median())\n    encode_data_series(test_copy,test_copy,[na_col],[np.nan],train[na_col].median())","8149d13f":"train_copy.isna().sum()","31f8a68d":"from sklearn.impute import KNNImputer\nkimputer = KNNImputer(n_neighbors=10)\nkimputer.fit(train_copy) \ntrain_imp = kimputer.transform(train_copy)\ntest_imp = kimputer.transform(test_copy)","273ee53f":"train_impA = pd.DataFrame(train_imp,columns = train_copy.columns)\ntest_impA = pd.DataFrame(test_imp,columns = test_copy.columns)","45ded9cc":"sns.scatterplot(data=train_impA,x='BMI',y='SkinThickness',hue='Outcome',palette='Set1',alpha=0.5)\nplt.title('SkinThickness and BMI')\nplt.show()","ee71923d":"sns.scatterplot(data=train_impA,x='Insulin',y='Glucose',hue='Outcome',palette='Set1',alpha=0.5,x_jitter=0.2,y_jitter=0.3)\nplt.title('Insuline and Glucose')\nplt.show()","736cc1bc":"from scipy.stats import skew\n#-- skewed data\ntrain_impA_skewed = train_impA.copy()\ntest_impA_skewed = test_impA.copy()\n\nskewed_feats = train_impA.apply(lambda x: skew(x.dropna())) #compute skewness\nskewed_feats = skewed_feats[skewed_feats > 0.75]\nskewed_feats = skewed_feats.index\n\nprint('Skewed Features : ' ,list(skewed_feats))\ntrain_impA_skewed[skewed_feats] = np.log1p(train_impA[skewed_feats])\ntest_impA_skewed[skewed_feats] = np.log1p(test_impA[skewed_feats])","3493ede8":"from sklearn.preprocessing import StandardScaler\ns_scaler = StandardScaler()\n\ntraintoscale = train_impA_skewed.drop('Outcome',axis=1).copy()\ntesttoscale = test_impA_skewed.drop('Outcome',axis=1).copy()\n\ns_scaler.fit(traintoscale)\ntrain_scaled = s_scaler.transform(traintoscale)\ntest_scaled = s_scaler.transform(testtoscale)\n\ntrain_ready = pd.DataFrame(train_scaled,columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n       'BMI', 'DiabetesPedigreeFunction', 'Age'])\ntest_ready = pd.DataFrame(test_scaled,columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n       'BMI', 'DiabetesPedigreeFunction', 'Age'])\n\ntrain_ready['Outcome'] = train_impA['Outcome']\ntest_ready['Outcome'] = test_impA['Outcome']","1a4fd622":"#some distributions after fixing skewness and standardization\nplot_numerical_histogram(train_ready,skewed_feats,rows=2)","9a25a3b5":"df_corr = train_ready.corr()\ndf_sorted_corr = df_corr['Outcome'].abs().sort_values(ascending=False)[1:]\ncorrelation_threshold =  0.2 \nhigh_corr_cols = df_sorted_corr[df_sorted_corr > correlation_threshold].index.tolist()","8b9f9ee7":"print('Sorted Features by Pearson Correlation','\\n')\nprint(df_sorted_corr)","b7132b0f":"#-- raw data with imbalanced class\n\n# X_train = train_ready[high_corr_cols]\n# y_train = train_ready['Outcome']\n\n#-- balancing class distribution in training data only before training\nover_smote = SMOTE(sampling_strategy=0.9) # oversampling didn't bring greater results \nunder_smote = RandomUnderSampler(sampling_strategy=0.6,random_state=47) #~minimizing the imbalance abit.\n\nX_train, y_train = under_smote.fit_resample(train_ready[high_corr_cols],train_ready['Outcome'])\n\nX_test = test_ready[high_corr_cols]\ny_test = test_ready['Outcome']","5f260ddd":"#original value counts\ntrain_ready['Outcome'].value_counts()","0f508885":"#after smote undersampling\ny_train.value_counts()","b5114cb2":"knn_clf = KNeighborsClassifier()\n\nparam_grid = {'n_neighbors' : [i for i in range(1,20) if i%2==0]\n              ,'weights':['uniform','distance']}\n\nknn_gcv = GridSearchCV(knn_clf,param_grid,cv=5,scoring='roc_auc')\nknn_gcv_fit = knn_gcv.fit(X_train, y_train)\n\nprint('best estimator : ',knn_gcv_fit.best_estimator_)\nprint('best score : ',knn_gcv_fit.best_score_)","9709e6da":"y_eval = knn_gcv_fit.best_estimator_.predict(X_test)\nprint(classification_report(y_test, y_eval))\n\nplot_roc_curve(knn_gcv_fit.best_estimator_,X_test,y_test)\nplt.title('ROC')\nplt.show()","88f81dc7":"svc_clf = SVC(class_weight='balanced',random_state=42)\n\nparam_grid = {'kernel':['poly', 'rbf'],'degree':[1,2],'C' : np.arange(1,10,1)}\n\nsvc_gcv = GridSearchCV(svc_clf,param_grid,cv=5,scoring='roc_auc')\nsvc_gcv_fit = svc_gcv.fit(X_train, y_train)\n\nprint('best estimator : ',svc_gcv_fit.best_estimator_)\nprint('best score : ',svc_gcv_fit.best_score_)","15739d31":"y_eval = svc_gcv_fit.best_estimator_.predict(X_test)\nprint(classification_report(y_test, y_eval))\n\nplot_roc_curve(svc_gcv_fit.best_estimator_,X_test,y_test)\nplt.title('ROC')\nplt.show()","42dcffe4":"log_clf = LogisticRegression(class_weight='balanced',random_state=42)\n\nparam_grid = {'C' :  np.arange(0.01,0.3,0.01)}\n\nlog_gcv = GridSearchCV(log_clf,param_grid,cv=5,scoring='roc_auc')\nlog_gcv_fit = log_gcv.fit(X_train, y_train)\n\nprint('best estimator : ',log_gcv_fit.best_estimator_)\nprint('best score : ',log_gcv_fit.best_score_)\n","7cd54ef2":"y_eval = log_gcv_fit.best_estimator_.predict(X_test)\nprint(classification_report(y_test, y_eval))\n\nplot_roc_curve(log_gcv_fit.best_estimator_,X_test,y_test)\nplt.title('ROC')\nplt.show()","fd440880":"---\n#### KNN Classifier","1a9fd0c6":"* Get Correlated Variables","f0c8ee34":"* room for improvement like : \n    * Handling outliers.\n    * Feature engineering.\n    * Interaction between predictors.\n    * clustering for uncovering structure in the data.. and much more i may revisit in the future.","5fcabfa4":"---\n## 3. <a name=\"3\">Data Processing<\/a>\n(<a href=\"#0\">Go to top<\/a>)","ad85bc73":"* we have to deal with the incorrect data -zeros-\n* data skewness.\n* data scaling.","848dc329":"### Imports","e2b85cc8":"---\n#### Logisitic Regression","c4e7b2d6":"* outcome is not balanced","72a4d217":"### Data fields\n\n* Pregnancies : Number of times pregnant\n* Glucose : Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n* BloodPressure : Diastolic blood pressure (mm Hg)\n* SkinThickness : Triceps skin fold thickness (mm)\n* Insulin : 2-Hour serum insulin (mu U\/ml)\n* BMI : Body mass index (weight in kg\/(height in m)^2)\n* DiabetesPedigreeFunction : Diabetes pedigree function\n* Age : Age (years)\n* Outcome : Class variable (0 or 1) 268 of 768 are 1, the others are 0","040c4284":"---\n## 1. <a name=\"1\">Problem Statement<\/a>\n(<a href=\"#0\">Go to top<\/a>)\n* Can you build a machine learning model to accurately predict whether or not the patients in the dataset have diabetes or not?","9496b31a":"* for low percentage of missing data i will fill by median","337975da":"---\n#### Univariate Exploration","f6032ff4":"---\n#### Bivariate Exploration","503fb84d":"* some notes \n    * 0 glucose level , 0 blood pressure ,0 BMI , 0 Insulin , 0 SkinThickness\n* skin thickness : Its thickness gives information about the fat reserves of the body. ~\n    * ref : https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC5083983\/\n    * reflects the fat , maybe correlated to bmi \n    * ranges for women according to the ref , ~[10-60]\n* most of the distributions are right skewed.","b5c5f72d":"--- \n## 6. <a name=\"6\">Improvements<\/a>\n(<a href=\"#0\">Go to top<\/a>)","5c436446":"* No missing values ! , all datatypes are numeric lets check the data","6e465c30":"* lets visualize some of the results","19326972":"1. <a href=\"#1\">Problem Statement<\/a>\n2. <a href=\"#2\">Data Exploration<\/a>\n3. <a href=\"#3\">Data Processing<\/a>\n4. <a href=\"#4\">Feature selection<\/a>\n5. <a href=\"#5\">Model Training<\/a>\n6. <a href=\"#6\">Improvements<\/a>","ad3d9568":"--- \n## 5. <a name=\"5\">Model Training<\/a>\n(<a href=\"#0\">Go to top<\/a>)","684573e0":"---\n#### SVC","bd49dbb6":"* notable correlations:\n    * Pregnancies and Age\n    * Glucose and Insulin\n    * Skin Thickness and Insulin , BMI\n    ","1190fbc7":"## <a name=\"0\">Practice Classification using SVM, Logistic Regression and KNN<\/a>","f998cea1":"---\n## 2. <a name=\"2\">Data Exploration<\/a>\n(<a href=\"#0\">Go to top<\/a>)","9e1718c7":"--- \n## 4. <a name=\"4\">Feature selection<\/a>\n(<a href=\"#0\">Go to top<\/a>)"}}