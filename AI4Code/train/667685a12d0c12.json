{"cell_type":{"3fe120e9":"code","9e18c824":"code","3df337f9":"code","6c3b37be":"code","e69b789d":"code","4ec0d0f9":"code","fdf0df7b":"code","7ac5cfa1":"code","e0718584":"code","55b622e0":"code","7de286df":"code","72955974":"code","3a89bbf0":"markdown","ac36d80a":"markdown","fd5d2d69":"markdown","fe5fbceb":"markdown","95e81d4d":"markdown","ea4e9300":"markdown","9af19c34":"markdown","32bde6ec":"markdown","e79ca50e":"markdown","5ca71f4c":"markdown","53301374":"markdown","5f693673":"markdown","05fd0e7e":"markdown","3fbf1449":"markdown"},"source":{"3fe120e9":"import pandas as pd\nimport numpy as np\nimport string\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nfrom sklearn import datasets\n\nimport requests\nfrom bs4 import BeautifulSoup\n\nfrom wordcloud import WordCloud, STOPWORDS \nimport networkx as nx\n\nSEED = 2020\nnp.random.seed(SEED)","9e18c824":"# Let's generate random data using numpy's random module\ndf = pd.DataFrame(dict(time=pd.date_range('2020-06-24',periods=100),\n                       stock_price=abs(np.random.randn(100).cumsum())))\n\nfig, ax = plt.subplots(figsize=(20,8))\nsns.lineplot(x='time',y='stock_price',data=df, ax=ax)\nplt.title('Stock Market Data',fontsize=15)","3df337f9":"# Let's generate Data related to the sales of mobile phones\nsales = np.random.choice(['Apple','Samsung','Oneplus','Oppo','Vivo','Nokia'],5000)\n\nfig, ax = plt.subplots(figsize=(20,8))\nsns.countplot(x=sales,ax=ax)\nplt.title('Total Number of Mobile Phones sold',fontsize=15)\nplt.xlabel('Brand')","6c3b37be":"# Let's generate random data for this\ncases = pd.Series(np.random.choice(['Maharashtra','Delhi','Gujarat','Madhya Pradesh','Kerala'],p=[0.5,0.2,0.15,0.1,0.05],size=5000))\n\nfig, ax = plt.subplots(figsize=(20,8))\nax = plt.pie(labels=cases.value_counts().index.values,x=cases.value_counts().values,startangle=90)\nplt.title('Distribution of Corona Virus Cases in Several States',fontsize=15)","e69b789d":"age = np.random.randint(0,100,size=5000)\n\nfig, ax = plt.subplots(figsize=(20,8))\nsns.distplot(age,kde=False,ax=ax)\nplt.title('Distribution of Age of the patients',fontsize=15)\nplt.xlabel('Age')","4ec0d0f9":"weight, height = datasets.make_regression(n_samples=500,n_features=1,noise=5)\n\n# Some preprocessing to give it some realistic touch\nweight = abs(weight)\nheight = abs(height)\nweight \/= np.max(weight)\nheight \/= np.max(height)\nweight = weight*97 + 3\nheight = height*6 + 1\n\n\nfig, ax = plt.subplots(figsize=(20,8))\nsns.scatterplot(weight.reshape([-1,]),height.reshape([-1,]),ax=ax)\nplt.title('Height vs Weight',fontsize=15)\nplt.xlabel('Weight in kgs')\nplt.ylabel('Height in feets')","fdf0df7b":"x = np.random.rand(5000)\n\nfig, ax = plt.subplots(figsize=(20,8))\nsns.kdeplot(x,shade=True,ax=ax)\nplt.title('Kernel Density Estimation of x',fontsize=15)\nplt.xlabel('x')","7ac5cfa1":"# Let's generate random data for this\ncustomers = np.random.choice(['John','Peter','Arjun','Mukesh','Rohit'],5000)\nspendings = np.random.randint(1,100000,5000)\n\n# Putting outliers in the data\nspendings[np.random.choice(list(range(5000)),replace=False,size=20)] = np.random.choice(list(range(100000,200000)),size=20)\n\nfig, ax = plt.subplots(figsize=(10,10))\nsns.boxplot(customers,spendings,ax=ax)\nplt.title('Distribution of Spendings of customers',fontsize=15)\nplt.xlabel('Customers')\nplt.ylabel('Spendings ')","e0718584":"url = 'https:\/\/www.forbes.com\/sites\/cognitiveworld\/2019\/07\/23\/understanding-explainable-ai\/#763dbbc87c9e'\nresponse = requests.get(url)\nsoup = BeautifulSoup(response.text, 'html.parser')\n\ntextdata = []\nfor p in soup.find_all('span'):\n    textdata += p.text.split(\" \")\n    \nstopwords = set(STOPWORDS)\n\ntextdata = list(map(lambda x: x.lower(),textdata))","55b622e0":"wordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10, max_words=50).generate(\" \".join(textdata))\n\nfig, ax = plt.subplots(figsize=(15, 8))\nax.imshow(wordcloud, interpolation='bilinear',aspect='auto')\nax.axis(\"off\")\nplt.show()","7de286df":"# Declaring Graph\nG = nx.Graph()\n\n# Using lower case alphabets as nodes\nnodes = list(string.ascii_lowercase)\n\n# Adding nodes \nG.add_nodes_from(nodes)\n\n# Adding edges randomly\nfor i in range(50):\n    edge = np.random.choice(nodes,2,replace=False)\n    G.add_edge(*edge)\n\nplt.figure(figsize=(25,25))\n\noptions = {\n    'edge_color': '#FFDEA2',\n    'width': 1,\n    'with_labels': True,\n    'font_weight': 'regular',\n}\n\nnx.draw(G,node_size=[700 for node in G], **options)\nax = plt.gca()\nplt.show()","72955974":"# Let's generate random data\ndf = pd.DataFrame(data=np.random.normal(size=(500,10)),columns=list(string.ascii_uppercase[:10]))\n\n# Correlation matrix\nmat = df.corr()\n\n# Mask for the lower triangle\nmask = np.triu(np.ones_like(mat, dtype=np.bool))\n\nfig, ax = plt.subplots(figsize=(10,8))\nsns.heatmap(mat,mask=mask,ax=ax)\nplt.title('Correlation Matrix',fontsize=15)","3a89bbf0":"### 2.1 Line Plot\n\n---\n\n**Line plots** are useful when we want to **visualize change in one variable** with the value of other variable. **Ex** Stock Market index etc.  \n  \nHere we will generate **Stock Market** data to use it as an example for the **Line Plot.**","ac36d80a":"### 2.9 Network Diagrams\n\n---\n\n**Network Diagrams** are used to visualize **graph** based data like **social media.** Where we can visualize links between **users**. Network can be **directed** or **undirected**, **weighted** or **unweighted**. \n\nHere we will use **randomly generated graph** for this.","fd5d2d69":"Visualizing and making sense of data is crucial for interpretable machine learning as models stand for data and knowing its contents is vital for setting a baseline expectation for how models behave and what they create. Exploratory analysis is not a new concept. For long, data visualization has been a major tool for gleaning meaningful information from data. A few such techniques can help to find the important characteristics and relevant manifestations of data. This can point us to what is potentially influential for the decision-making capacity of a model, which could be easily understood by humans.\n\nResearchers opine in agreement that our most powerful sense is vision. We take in about 80-85% information through our eyes. This goes a notch up when understanding and interpreting data or when identifying connections between variables running into hundreds or thousands to sort and assign their respective values of significance. Using advanced analysis and visualizations that are easy to understand can be effective in discerning significant relationships. Applications of data visualization can be useful in almost all knowledge spheres. Multi-disciplinary scientists make use of computer techniques for modelling complicated outcomes and visualizing developments not seen in a direct manner. Examples of such cases are weather conditions, medical diagnoses or mathematical problems.\n\nData visualization presents a set of tools and techniques to understand data in a better way. Some of the basic techniques use the plots that are explained in this notebook.","fe5fbceb":"### 2.3 Pie and Donut Charts\n\n---\n\n**Pie and Donut Charts** are useful when we want to visualize **distribution** of a **categorical variable** as a whole. Using these charts it will be easy to analyze the distribution as compared to barplots.\n\nWe will take **Distribution of Corona Virus Cases** in several states as an example for this.","95e81d4d":"### 2.7 Box and Whisker Plot\n\n---\n\n**Box and Whisker Plots** are used to visualize distributions involving **Categorical variables.** It is used to see if there are any **outliers** in the distributions or not. This kind of plot shows the **three quartile values(25,50,75)** of the distribution along with **maximum** and **minimum** values. The \u201c**whiskers**\u201d extend to points that lie within 1.5 IQRs of the lower and upper quartile, and then observations that fall outside this range are displayed independently.\n\nHere we will use **Credit card spendings** of 5 people.","ea4e9300":"### 2.10 Correlation Matrices\n\n---\n\n**Correlation Matrices** is used to visualize **correlation coefficient** between variables. This gives insights about the relationship between the variables.\n\nHere we will use **randomly generated** data.","9af19c34":"## 1. Importing necessary libraries","32bde6ec":"### 2.6 Kernel Density Estimation\n\n---\n\nThe major drawback of histogram is that it is highly dependent on **bin-size** and if the bin size is not set properly than we could miss some important information. To overcome this problem we have **Kernel Density Estimation Plot**  which could be used to visualize the **distribution** of **continuous** variable as well as we can use it to visualize **probability distribution** of a variable.\n\nWe will use *randomly generated data* for this.","e79ca50e":"### 2.4 Histogram Plot\n\n---\n\n**Histogram** is used to visualize **distribution** of a **numerical** variable using **bins** in the range of the variable and **height** of that bin indicates the **number of data point** that fall into that **bin**.  \n**Quality** of the visualization highly depends on the choice of the **bin-size**. It should not be too high or too low.\n\nWe will use **Age Distribution of patients affected by Corona Virus** as an example of this.","5ca71f4c":"## Data Explainability: Exploratory Analysis and Visualization\n\n![](https:\/\/media.giphy.com\/media\/HUplkVCPY7jTW\/giphy.gif)\n \n ---","53301374":"## 2. Various Plots","5f693673":"### 2.2 Bar Chart\n\n---\n\n**Bar Charts** are used when we want to visualize **number of observations** in each category. They are similar to histograms but for categorical variables.\n\nHere we will generate some categorical values randomly to see a use case of **Bar charts**.","05fd0e7e":"### 2.5 Scatter Plot\n\n---\n\n**Scatter Plot** is used to visualize relationship between **two variables** and each point in the plot represents one observation.\nIt is mostly used when both of the variables are **numeric** in nature. We can find how one variable is related to the other variable. For example we can find if there is a linear relationship or not etc.\n\nWe will use **Weight & Height** data for this.\n\n*As the data is generated randomly there could be non-realistic nature in the data*","3fbf1449":"### 2.8 Word Clouds\n\n---\n\n**Word Cloud** is used to visualize **text data** like **words**, **tags** etc. When working with **unstructured data** like **text files**, word-cloud is useful to visualize **frequently** occuring words.\n\nHere we will use **Text Data of a wikipedia page** to generate a word-cloud. "}}