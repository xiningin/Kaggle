{"cell_type":{"75fc1975":"code","44229786":"code","3217bdf5":"code","c234a747":"code","8c794456":"code","6983c285":"code","1f1c865c":"code","35089679":"code","de32921b":"code","2a52cd8e":"code","3544aa83":"code","b781f4a1":"code","fadc7a2d":"code","037d2158":"code","4fad2f28":"code","1ceaed42":"code","c20fbbc3":"code","cfb49b8c":"code","f15d1b39":"code","a151ca4f":"code","b2ca1edd":"code","ed715d57":"code","7bb55cf9":"code","3df02832":"code","b12fc543":"code","0da882d5":"code","0960a917":"code","2ee465fc":"code","d6101230":"code","ab89951b":"code","4372f970":"code","dde69346":"code","279219f0":"code","e4f21d51":"code","7ecb64e2":"code","91224138":"code","bd58a9d2":"code","626fc293":"code","f5c972b8":"code","f76fbc97":"code","e3668dae":"code","c907e264":"code","615489d7":"code","72045c6c":"code","d2928b48":"code","4e1aec18":"code","9164ad59":"code","44716910":"code","a125d997":"code","b5babff1":"code","6b3c7b36":"code","247b19e4":"code","3f0299b0":"code","9a802c76":"code","88a3e4a5":"markdown","6c0e96d6":"markdown","1a19b3c5":"markdown","3e41ccfc":"markdown","ef77f169":"markdown","08a0a5ac":"markdown","9cc07414":"markdown","bf4ce952":"markdown","a2240f56":"markdown","bc89f297":"markdown","d48eb93b":"markdown","53ced245":"markdown","9fab7a4e":"markdown","4392b8b6":"markdown","90cb2a8c":"markdown","0ab39686":"markdown","50ce3dc5":"markdown","f30b3ca9":"markdown","f4c1a173":"markdown","52a0a248":"markdown","f44adf3e":"markdown","f2963bf8":"markdown","3b409e86":"markdown","3704c011":"markdown","e6c19903":"markdown","605c4fc0":"markdown","62ec61b4":"markdown","afad02c6":"markdown","bfe2b766":"markdown","84770bc4":"markdown","0a826ddb":"markdown","6eceaa81":"markdown","9ce998aa":"markdown","400698cc":"markdown"},"source":{"75fc1975":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = (10, 10)\nimport seaborn as sns\nplt.style.use(\"fivethirtyeight\")\n%matplotlib inline\n\nfrom plotly import tools\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nos.listdir('..\/input')","44229786":"df = pd.read_csv(\"..\/input\/train.csv\")\ndf.sample(5)","3217bdf5":"df.info()","c234a747":"null_sum = pd.DataFrame(df.isnull().sum(), columns=['Sum'])\nnull_percent = pd.DataFrame((df.isnull().sum()\/df.shape[0])*100, columns=['Percent'])\ntotal = pd.concat([null_sum, null_percent], axis=1)\ntotal.sort_values(['Sum', 'Percent'], ascending=False)","8c794456":"''' Droping Cabin column and filling Age column null values with mean '''\ndf.drop('Cabin', axis=1, inplace=True)\ndf[\"Age\"] = df[\"Age\"].fillna(value=df.Age.mean())","6983c285":"def pie_plot(cnts, colors, title):\n    labels = cnts.index\n    values = cnts.values\n    \n    trace = go.Pie(labels=labels,\n                   values=values,\n                   title=title,\n                   textinfo='value',\n                   hoverinfo='label+percent',\n                   hole=.4,\n                   textposition='inside',\n                   marker=dict(colors=colors,\n                               line=dict(color='#000000', width=2)\n                              )\n                  )\n    layout = go.Layout(hovermode='closest')\n    fig = go.Figure(data=[trace], layout=layout)\n    return py.iplot(fig)","1f1c865c":"pie_plot(df['Embarked'].value_counts(), colors=['yellow','orange', 'cyan'], title='Embarked')","35089679":"''' Filling null values with most common value '''\ndf[\"Embarked\"] = df[\"Embarked\"].fillna(\"S\")","de32921b":"pie_plot(df['Survived'].value_counts(), colors=['gold','cyan'], title='Survived?')","2a52cd8e":"plt.figure(figsize=(10,10))\nplt.style.use('ggplot')\nsns.countplot(df['Survived'], hue=df['Sex'], palette='plasma')\nplt.title(\"Survived vs Sex\")\nplt.show()","3544aa83":"plt.figure(figsize=(10,10))\nsns.countplot(x='Survived', hue='Pclass', data=df, palette='inferno')\nplt.title('Survived vs Pclass')\nplt.show()","b781f4a1":"plt.figure(figsize=(15,10))\nplt.subplot(1,2,1)\nsns.boxplot(x=\"Pclass\", y=\"Age\", data=df)\nplt.title('Pclass vs Age')\n\nplt.subplot(1,2,2)\nsns.boxplot(x=\"Survived\", y=\"Fare\", data=df)\nplt.title('Survived vs Fare')\n\nplt.subplots_adjust(wspace=0.4, hspace=0.4)\nplt.show()\n\nplt.figure(figsize=(15, 8))\nsns.boxplot(x='Survived', y='Age', data=df);","fadc7a2d":"pd.DataFrame(df.corr()['Survived'].sort_values(ascending=False))","037d2158":"plt.figure(figsize=(10,10), dpi=100)\nsns.heatmap(df.corr(), annot=True, cmap='coolwarm');","4fad2f28":"''' Extracting prefix from names '''\ndf[\"Title\"] = df[\"Name\"].str.extract(\"([A-Za-z]+)\\.\", expand=False)\ndf[\"Title\"].unique()","1ceaed42":"''' Correcting spelling mistakes in prefixes and naming rarely used prefixes with Rare'''\ndf[\"Title\"] = df[\"Title\"].replace([\"Don\", \"Rev\", \"Dr\", \"Major\", \"Lady\", \n                                         \"Sir\", \"Col\", \"Capt\", \"Countess\", \"Jonkheer\"], \"Rare\")\n\ndf[\"Title\"] = df[\"Title\"].replace(\"Mlle\", \"Mrs\")\ndf[\"Title\"] = df[\"Title\"].replace(\"Ms\", \"Miss\")\ndf[\"Title\"] = df[\"Title\"].replace(\"Mme\", \"Mrs\")\n\ndf[[\"Title\", \"Survived\"]].groupby(\"Title\", as_index=False).mean()","c20fbbc3":"'''Mapping male as 1 and Female as 0'''\ndf[\"Sex\"] = df[\"Sex\"].map({\"male\": 1, \"female\":0})","cfb49b8c":"'''Bining the values of Fare'''\ndf[\"Fareband\"] = pd.qcut(df[\"Fare\"], 4)\ndf[[\"Fareband\", \"Survived\"]].groupby(\"Fareband\", as_index=False).mean().sort_values(by=\"Fareband\", ascending=True)","f15d1b39":"df.loc[df[\"Fare\"] <= 7.91, \"Fare\"] = 0\ndf.loc[(df[\"Fare\"] > 7.91) & (df[\"Fare\"] <= 14.454), \"Fare\"] = 1\ndf.loc[(df[\"Fare\"] > 14.454) & (df[\"Fare\"] <= 31.0), \"Fare\"] = 2\ndf.loc[df[\"Fare\"] > 31.0, \"Fare\"] = 3\ndf[\"Fare\"] = df[\"Fare\"].astype(\"int\")","a151ca4f":"'''Bining the values of Age'''\ndf[\"Ageband\"] = pd.cut(df[\"Age\"], 4)\ndf[[\"Ageband\", \"Survived\"]].groupby(\"Ageband\", as_index=False).mean().sort_values(by=\"Ageband\", ascending=True)","b2ca1edd":"df.loc[df[\"Age\"] <= 20.315, \"Age\"] = 0\ndf.loc[(df[\"Age\"] > 20.315) & (df[\"Age\"] <= 40.21), \"Age\"] = 1\ndf.loc[(df[\"Age\"] > 40.21) & (df[\"Age\"] <= 60.105), \"Age\"] = 2\ndf.loc[(df[\"Age\"] > 60.105) & (df[\"Age\"] <= 80.0), \"Age\"] = 3\ndf[\"Age\"] = df[\"Age\"].astype(\"int\")","ed715d57":"'''Creating isAlone Feature to see if the person is alone or not'''\ndf[\"isAlone\"] = df[\"SibSp\"] + df[\"Parch\"] + 1\ndf[\"isAlone\"].loc[df[\"isAlone\"] > 1] = 0\ndf[\"isAlone\"].loc[df[\"isAlone\"] == 1] = 1","7bb55cf9":"def horizontal_bar_chart(cnt_srs, color):\n    trace = go.Bar(\n        y = cnt_srs.index[::-1],\n        x = cnt_srs.values[::-1],\n        showlegend = False,\n        orientation = 'h',\n        marker = dict(\n            color = color,\n        ),\n    )\n    return trace\n\ncnt_srs = df.groupby('Title')[\"Survived\"].agg(['count', 'mean'])\ncnt_srs.columns = [\"count\", \"mean\"]\ncnt_srs = cnt_srs.sort_values(by=\"count\", ascending=False)\ntrace_1 = horizontal_bar_chart(cnt_srs[\"count\"].head(10), 'rgba(50, 171, 96, 0.6)')\ntrace_2 = horizontal_bar_chart(cnt_srs[\"mean\"].head(10), 'rgba(50, 171, 96, 0.6)')\n\n\ncnt_srs = df.groupby('Age')[\"Survived\"].agg(['count', 'mean'])\ncnt_srs.columns = [\"count\", \"mean\"]\ncnt_srs = cnt_srs.sort_values(by=\"count\", ascending=False)\ntrace_3 = horizontal_bar_chart(cnt_srs[\"count\"].head(10), 'rgba(71, 58, 131, 0.6)')\ntrace_4 = horizontal_bar_chart(cnt_srs[\"mean\"].head(10), 'rgba(71, 58, 131, 0.6)')\n\n\ncnt_srs = df.groupby('Fare')[\"Survived\"].agg(['count', 'mean'])\ncnt_srs.columns = [\"count\", \"mean\"]\ncnt_srs = cnt_srs.sort_values(by=\"count\", ascending=False)\ntrace_5 = horizontal_bar_chart(cnt_srs[\"count\"].head(10), 'rgba(246, 78, 139, 0.6)')\ntrace_6 = horizontal_bar_chart(cnt_srs[\"mean\"].head(10), 'rgba(246, 78, 139, 0.6)')\n\n\nfig = tools.make_subplots(3, 2, vertical_spacing=0.04,\n                         subplot_titles=[\"Count-Title\", \"Mean-Title\",\n                                         \"Count-Ageband\", \"Mean-Ageband\",\n                                         \"Count-Fareband\", \"Mean-Fareband\"])\n\nfig.append_trace(trace_1, 1, 1)\nfig.append_trace(trace_2, 1, 2)\nfig.append_trace(trace_3, 2, 1)\nfig.append_trace(trace_4, 2, 2)\nfig.append_trace(trace_5, 3, 1)\nfig.append_trace(trace_6, 3, 2)\n\nfig['layout'].update(height=1200, width=1200, paper_bgcolor='rgb(233, 233, 233)', title=\"Survived by Columns\")\npy.iplot(fig, filename=\"survived-by-cols\")","3df02832":"df['Survived'].value_counts()","b12fc543":"plt.figure(figsize=(10,10))\nsns.countplot(df['Survived'], palette='Set1');","0da882d5":"df.drop(['PassengerId', 'Ageband', 'Fareband', 'Name', 'Ticket'], axis=1, inplace=True)","0960a917":"'''One Hot Encoding'''\nobjects = df.select_dtypes(include=['object'])\nobjects = pd.get_dummies(objects, drop_first=True)\ndf.drop(df.select_dtypes(include=['object']), axis=1, inplace=True)\ndf = pd.concat([df, objects], axis=1)\ndf.head()","2ee465fc":"X = df.drop('Survived', axis=1)\ny = df[\"Survived\"]","d6101230":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nimport eli5\nfrom eli5.sklearn import PermutationImportance\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import cross_val_score, cross_val_predict, KFold\nfrom sklearn import svm\nfrom sklearn.utils import resample\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC","ab89951b":"df_train, df_test, Y_train, Y_test = train_test_split(X, y , test_size=0.2, random_state=101)","4372f970":"'''OverSampling'''\nX = pd.concat([df_train, Y_train], axis=1)\n\nnot_survived = X[X.Survived==0]\nsurvived = X[X.Survived==1]\n\nover_sampled = resample(survived, \n                        replace=True, # Samples with replacement\n                        n_samples=len(not_survived), # Number of samples\n                        random_state=27)\n\nover_sampled = pd.concat([not_survived, over_sampled])\n\nover_sampled.Survived.value_counts()","dde69346":"plt.figure(figsize=(8,8))\nsns.countplot(over_sampled['Survived'], palette='Set2');","279219f0":"over_train = over_sampled.drop('Survived', axis=1)\ny_over_train = over_sampled['Survived']\n\nlg = LogisticRegression()\nlg.fit(over_train, y_over_train)\nlg_pred = lg.predict(df_test)\nprint('OverSampling Accuracy:', metrics.accuracy_score(Y_test, lg_pred))","e4f21d51":"'''UnderSampling'''\n\nunder_sampled = resample(not_survived,\n                         replace=False, # sample without replacement\n                         n_samples=len(survived), # Number of Samples\n                         random_state=27\n                        )\nunder_sampled = pd.concat([survived, under_sampled])\n\nunder_sampled.Survived.value_counts()","7ecb64e2":"plt.figure(figsize=(8,8))\nsns.countplot(under_sampled['Survived'], palette='Set1');","91224138":"X_train = under_sampled.drop('Survived', axis=1)\ny_train = under_sampled['Survived']\n\nlg = LogisticRegression()\nlg.fit(X_train, y_train)\nlg_pred = lg.predict(df_test)\nprint('UnderSampling Accuracy:', metrics.accuracy_score(Y_test, lg_pred))","bd58a9d2":"X = df.drop('Survived', axis=1)\ny = df[\"Survived\"]\n\nsmote = SMOTE(ratio='minority')\nX_sm, y_sm = smote.fit_sample(X, y)","626fc293":"x_train, x_test, y_train, y_test = train_test_split(X_sm, y_sm , test_size=0.2, random_state=101)","f5c972b8":"lg = LogisticRegression()\nlg.fit(x_train, y_train)\nlg_pred = lg.predict(x_test)\nprint('SMOTE Accuracy:', metrics.accuracy_score(y_test, lg_pred))","f76fbc97":"x_train = over_train\ny_train = y_over_train\nx_test = df_test\ny_test = Y_test","e3668dae":"folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)\n\nparams = {\"C\": [0.01, 0.1, 1, 10, 100, 1000]}\n\nlr = LogisticRegression()\n\ngs_Log = GridSearchCV(lr, param_grid=params, cv=folds, n_jobs=-1, scoring='accuracy', return_train_score=True, \n                      verbose=1)\n\ngs_Log.fit(x_train, y_train)","c907e264":"gs_Log.best_params_","615489d7":"gs_results = pd.DataFrame(gs_Log.cv_results_)\ngs_results","72045c6c":"plt.plot(gs_results['param_C'], gs_results['mean_test_score'])\nplt.plot(gs_results['param_C'], gs_results['mean_train_score'])\nplt.legend([\"Test Score\", \"Train Score\"], loc=\"lower right\")\nplt.xscale(\"log\")","d2928b48":"svc = SVC()\n\n'''Finding right params'''\nparams = {\"C\": [0.01, 0.1, 1, 10, 100],\n          \"gamma\": [1e-1, 1e-2, 1e-3, 1e-4],\n          \"kernel\" : [\"linear\", \"rbf\", \"sigmoid\", \"poly\"]}\n\nsvc_gs = GridSearchCV(svc, param_grid=params, cv=folds, scoring=\"accuracy\", n_jobs=-1, return_train_score=True, \n                      verbose=1)\n\nsvc_gs.fit(x_train, y_train)","4e1aec18":"svc_gs.best_params_","9164ad59":"svc_results = pd.DataFrame(svc_gs.cv_results_)\nsvc_results.head()","44716910":"svc_results['param_C'] = svc_results['param_C'].astype('int')\n\nfig, ax = plt.subplots(2,2, figsize=(12,10))\ngamma_01 = svc_results.loc[(svc_results['param_gamma'] == 0.1) & (svc_results['param_kernel'] == 'rbf')]\nsns.lineplot(gamma_01['param_C'], gamma_01['mean_test_score'], ax=ax[0,0])\nsns.lineplot(gamma_01['param_C'], gamma_01['mean_train_score'], ax=ax[0,0])\nax[0,0].set_title(\"Gamma=0.1\")\nax[0,0].set_ylim([0.50, 1.0])\nax[0,0].set_xscale(\"log\")\nax[0,0].legend([\"Test Score\", \"Train Score\"], loc=\"lower right\")\n\n\ngamma_01 = svc_results.loc[(svc_results['param_gamma'] == 0.01) & (svc_results['param_kernel'] == 'rbf')]\nax[0,1].plot(gamma_01['param_C'], gamma_01['mean_test_score'])\nax[0,1].plot(gamma_01['param_C'], gamma_01['mean_train_score'])\nax[0,1].set_title(\"Gamma=0.01\")\nax[0,1].set_ylim([0.50, 1.0])\nax[0,1].set_xscale(\"log\")\nax[0,1].legend([\"Test Score\", \"Train Score\"], loc=\"lower right\")\n\n\ngamma_01 = svc_results.loc[(svc_results['param_gamma'] == 0.001) & (svc_results['param_kernel'] == 'rbf')]\nax[1,0].plot(gamma_01['param_C'], gamma_01['mean_test_score'])\nax[1,0].plot(gamma_01['param_C'], gamma_01['mean_train_score'])\nax[1,0].set_title(\"Gamma=0.001\")\nax[1,0].set_ylim([0.50, 1.0])\nax[1,0].set_xscale(\"log\")\nax[1,0].legend([\"Test Score\", \"Train Score\"], loc=\"lower right\")\n\n\ngamma_01 = svc_results.loc[(svc_results['param_gamma'] == 0.0001) & (svc_results['param_kernel'] == 'rbf')]\nax[1,1].plot(gamma_01['param_C'], gamma_01['mean_test_score'])\nax[1,1].plot(gamma_01['param_C'], gamma_01['mean_train_score'])\nax[1,1].set_title(\"Gamma=0.0001\")\nax[1,1].set_ylim([0.50, 1.0])\nax[1,1].set_xscale(\"log\")\nax[1,1].legend([\"Test Score\", \"Train Score\"], loc=\"lower right\")\n\nplt.tight_layout()","a125d997":"final_svc = SVC(C=1, gamma=0.1, kernel=\"rbf\")\nfinal_svc.fit(x_train, y_train)","b5babff1":"'''Feature Importance'''\nperm = PermutationImportance(final_svc, random_state=1).fit(x_train, y_train)\neli5.show_weights(perm, feature_names=x_train.columns.tolist())","6b3c7b36":"kfold = KFold(5, random_state=10)\naccuracy = []\n\nclassifiers=['Linear Svm','Radial Svm','Logistic Regression','KNN','Decision Tree','Naive Bayes','Random Forest']\n\nmodels=[svm.SVC(kernel='linear'),svm.SVC(kernel='rbf'),LogisticRegression(C=1),\n        KNeighborsClassifier(n_neighbors=9),DecisionTreeClassifier(),GaussianNB(),\n        RandomForestClassifier(n_estimators=100)]\n\nfor model in models:\n    cv_result = cross_val_score(model, X, y, cv=kfold, scoring=\"accuracy\")\n    accuracy.append(cv_result.mean())\nnew_models_df = pd.DataFrame({\"CV Mean\": accuracy}, index=classifiers)\nnew_models_df","247b19e4":"import shap \nrf = RandomForestClassifier(n_estimators=1000, max_depth=2)\nrf.fit(x_train, y_train)","3f0299b0":"exp = shap.TreeExplainer(rf, x_train)\nshap_values = exp.shap_values(x_test)\n\nshap.summary_plot(shap_values[1], x_test)","9a802c76":"shap.initjs()\nshap.force_plot(exp.expected_value[0], shap_values[0], x_test)","88a3e4a5":"# Imbalanced ?","6c0e96d6":"# Exploring relations","1a19b3c5":"# Preprocessing","3e41ccfc":"<img src=\"https:\/\/raw.githubusercontent.com\/rafjaa\/machine_learning_fecib\/master\/src\/static\/img\/smote.png\" width='800'>","ef77f169":"SMOTE (Synthetic Minority Oversampling TEchnique) consists of synthesizing elements for the minority class, based on those that already exist. It works randomly picking a point from the minority class and computing the k-nearest neighbors for this point. The synthetic points are added between the chosen point and its neighbors.","08a0a5ac":"# Feature Engineering","9cc07414":"# Which class survived the most?","bf4ce952":"<img src = \"https:\/\/raw.githubusercontent.com\/rafjaa\/machine_learning_fecib\/master\/src\/static\/img\/resampling.png\" width='800'>","a2240f56":">* Higher Age passengers are mostly in First Class\n>* As First Class Passengers have survived the most there is a direct relation with Fare\n>* Higher Age passengers survived the most which is because most higher age passengers travelled in first class and most first class passengers Survived","bc89f297":"# Logistic Regression","d48eb93b":"# Who Survived?","53ced245":"# Different Algorithms","9fab7a4e":"# SMOTE","4392b8b6":">* PassengerId: type should be integers \n>* Survived: Survived or Not \n>* Pclass: Class of Travel\n>* Name: Name of Passenger\n>* Sex: Gender\n>* Age: Age of Passengers\n>* SibSp: Number of Sibling\/Spouse aboard\n>* Parch: Number of Parent\/Child aboard\n>* Ticket: Ticket number\n>* Fare: Fare for ticket\n>* Cabin: Cabin Number\n>* Embarked: The port in which a passenger has embarked. C - Cherbourg, S - Southampton, Q = Queenstown","90cb2a8c":">* target column is imbalanced\n>* We have handled this later with resampling","0ab39686":">* Count and Mean Survived by title, ageband, fareband","50ce3dc5":"* OverSampling gives the best result so we will be using oversampled data","f30b3ca9":">* Most passengers got on board from Southampton","f4c1a173":">* Cabin and Age columns has most null values","52a0a248":"<img src='https:\/\/cdn.radiofrance.fr\/s3\/cruiser-production\/2018\/10\/bfca8681-cbe1-4396-b725-b3bf51e6e68e\/870x489_titanic_uppa_photoshot_maxnewsfr040608.jpg' width='800'>","f44adf3e":">* Fare, Parch are quite correlated with survived","f2963bf8":">* 38.4% of people Survived","3b409e86":">* Radial SVM gives the best score","3704c011":"# SVM","e6c19903":"# Data Description","605c4fc0":">* First Class Passengers Survived the most","62ec61b4":"* Undersampling\n>* Some samples of majority class are removed till it becomes equal to the samples of minority class\n\n* Oversampling\n>* Copies of monority class samples are made till it becomes equal to the samples of majority class","afad02c6":"# Features Impact","bfe2b766":"# How many people Survived?","84770bc4":">* Females Survived the most","0a826ddb":"# Resampling","6eceaa81":"# Reference:-\n\n>* https:\/\/www.kaggle.com\/shahules\/tackling-class-imbalance","9ce998aa":"# Who Survived more Male or Female?","400698cc":"# UpVote if this was helpful\n>* I would be updating it more "}}