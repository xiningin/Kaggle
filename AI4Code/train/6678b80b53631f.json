{"cell_type":{"1a4b4d0d":"code","f2ae6122":"code","2b51188c":"code","728a316d":"code","f66e43e9":"code","ca395058":"code","8026f092":"code","85d7a33d":"code","3973dce3":"code","48857b97":"code","12defa98":"code","63edb0a4":"code","900785d6":"code","09b05050":"code","416733e9":"code","9d810fa3":"code","32a3283b":"code","783e867c":"code","08d88971":"code","8b3c689e":"code","e59e2e34":"code","398a8b94":"code","0feadf9d":"code","0976cd65":"code","89a9beac":"code","e663a2ee":"code","1c975406":"code","6300fad6":"code","d1ea9ef4":"code","605ea3c1":"code","fffce2ea":"code","555de082":"markdown","aba1fd7c":"markdown","cddb9f62":"markdown","2d5bca38":"markdown","967efbe9":"markdown","480a0e62":"markdown","16f4655e":"markdown","40682687":"markdown","ebd2b828":"markdown","ba797d70":"markdown","f4e60266":"markdown","55163743":"markdown","39011205":"markdown","e5d04efb":"markdown","100ff583":"markdown","4627070c":"markdown","d527d836":"markdown"},"source":{"1a4b4d0d":"%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom scipy.stats import norm\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler","f2ae6122":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\n\ndef con(X,test):\n    combined = pd.concat([X,test], axis=0,ignore_index=True)\n    return combined\ndef dropper(data, columns):\n    for set_ in data:\n        set_.drop(columns, axis=1, inplace=True)","2b51188c":"con(train,test).info()","728a316d":"y = train.SalePrice\nX = train.drop(['Id','SalePrice'],axis=1)\nID = test.Id\ntest.drop('Id', axis=1, inplace=True)","f66e43e9":"X","ca395058":"test","8026f092":"combined = con(X,test)","85d7a33d":"null = combined.isnull().sum().sort_values(ascending=False)\nnull = null[null != 0]\npercent = null\/len(combined)\npd.concat([null,percent],axis=1,keys=['Nulls','Percent'])","3973dce3":"for col in ['GarageYrBlt','MasVnrArea','BsmtHalfBath','BsmtFullBath','BsmtFinSF1','TotalBsmtSF','BsmtUnfSF','GarageCars','BsmtFinSF2','GarageArea']:\n    median = combined[col].median()\n    combined[col].fillna(median, inplace=True)","48857b97":"from sklearn.impute import SimpleImputer\nnone_imp = SimpleImputer(strategy='constant',fill_value='None')\nnom_imp = SimpleImputer(strategy='most_frequent')\n\nnone_cols = ['FireplaceQu','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','GarageFinish','GarageQual','GarageCond','GarageType',]\nnom_cols = ['Functional','KitchenQual','MasVnrType','Electrical','Utilities','MSZoning','Exterior1st','Exterior2nd','SaleType']\n\ncombined[none_cols] = none_imp.fit_transform(combined[none_cols])\ncombined[nom_cols] = nom_imp.fit_transform(combined[nom_cols])","12defa98":"# Binary\ncol = ['PoolQC','Fence','Alley','MiscFeature']\ncombined[col] = combined[col].fillna(0)\nfor col in ['PoolQC','Fence','Alley','MiscFeature']:\n    combined.loc[combined[col] != 0,col] = 1\ncombined[col] = combined[col].astype(int)","63edb0a4":"# Object -> dummy \ndummies = pd.get_dummies(combined.select_dtypes(object))\ncombined= pd.concat([combined,dummies],axis=1)\ncombined.drop(combined.select_dtypes(object).columns,axis=1,inplace=True)","900785d6":"# Knn for LotFrontage\nfrom sklearn.neighbors import KNeighborsRegressor\nknn = KNeighborsRegressor(weights='distance')\n\nLF = combined['LotFrontage'].copy().dropna()\ncombined2 = combined.drop('LotFrontage',axis=1).iloc[LF.index]\nknn.fit(combined2, LF);\n\nLF_test = combined[combined.LotFrontage.isnull()==True].drop('LotFrontage',axis=1)\npredict = knn.predict(LF_test)\ncombined.loc[combined.LotFrontage.isnull() == True, 'LotFrontage'] = predict","09b05050":"combined.info()","416733e9":"cols = combined.var()[combined.var() > 2].astype(int).index\ndata = combined[cols]\ndata.hist(figsize=(20,15))\nplt.show()","9d810fa3":"# PowerTransformer only works if the data set has non-zero entries\nfrom sklearn.preprocessing import QuantileTransformer\ncombined[cols] = QuantileTransformer(output_distribution='normal').fit_transform(combined[cols])","32a3283b":"combined[cols].hist(figsize=(20,15))\nplt.show()","783e867c":"# SalePrice\nplt.figure(figsize=(10,5))\nsns.distplot(y,fit=norm)\nplt.show()","08d88971":"y = np.log(y)\n\nplt.figure(figsize=(10,5))\nsns.distplot(y,fit=norm)\nplt.show()","8b3c689e":"# combined = StandardScaler().fit_transform(combined)\nX = combined[:1460]\ntest = combined[1460:]","e59e2e34":"from sklearn.linear_model import LinearRegression\nregressor = LinearRegression().fit(X, y)\n\nfrom sklearn.metrics import r2_score\nprint(r2_score(regressor.predict(X), y))","398a8b94":"plt.scatter(range(0,1460),sorted(regressor.predict(X)))\nplt.scatter(range(0,1460),sorted(y),c='red',alpha = 0.05)\nplt.show()","0feadf9d":"from sklearn.ensemble import RandomForestRegressor # robust and can measure feature importance\nfrom sklearn.model_selection import cross_val_score\n\nrf_reg = RandomForestRegressor(random_state=1, n_jobs=-1)","0976cd65":"def evaluation(model,X,y):\n    scores = cross_val_score(model, X, y, scoring = 'neg_mean_squared_error', cv=10)\n    rmse_scores = np.sqrt(-scores)\n    print('Mean',rmse_scores.mean())\n    print('Std Dev',rmse_scores.std())","89a9beac":"evaluation(rf_reg,X,y)","e663a2ee":"from sklearn.model_selection import GridSearchCV\nparam_grid = [\n    {'n_estimators':[10,100,200], 'max_features':[10,100,150,200],'min_samples_split':[2,4,6,8]},\n]\nforest_reg = RandomForestRegressor(random_state=1)\ngrid_search = GridSearchCV(forest_reg, param_grid, cv=10,\n                         scoring = 'neg_mean_squared_error',\n                         return_train_score = True)","1c975406":"grid_search.fit(X, y)\ngrid_search.best_params_","6300fad6":"evaluation(grid_search.best_estimator_,X,y)","d1ea9ef4":"rf = grid_search.best_estimator_\nrf.fit(X,y)\nrf_pred = np.exp(rf.predict(test))","605ea3c1":"%%time\nfrom sklearn.ensemble import AdaBoostRegressor\nbase_estimator = grid_search.best_estimator_\n\nada_reg = AdaBoostRegressor(\n        n_estimators = 100, learning_rate = 1,\n        base_estimator = base_estimator,random_state=1)\nada_reg.fit(X,y)\nevaluation(ada_reg,X,y)","fffce2ea":"predict = np.exp(ada_reg.predict(test))\npredict = pd.DataFrame(predict,columns=['SalePrice'])\nfile = pd.concat([ID,predict],axis=1)\nfile.to_csv('ada.csv', index = False)","555de082":"# 1. Introduction\nThis project seeks to create a reliable predictive model of house prices using housing data collected from Ames, Iowa.  \nAnyone reading this, I'm going to assume you know the basics and avoid adding in needless explanation.","aba1fd7c":"## Cross-Validation","cddb9f62":"### Imports","2d5bca38":"## Remember to apply np.exp() to your predictions so that they're in the right scale for submission.","967efbe9":"# Submission","480a0e62":"# 2. Null and Data Transformation","16f4655e":"### Linearity check","40682687":"## Observations\n* **There are 80 features in the training set.** With the very last feature, **SalePrice** being our target. \n* **2919 entries in each feature** with some features missing data.\n* **Lots of categorical features** if we look in the data description text file. We can easily convert those later.","ebd2b828":"Combine X and test and then split them again when training our models. This is to avoid having to apply transformations twice.","ba797d70":"## Nulls","f4e60266":"# GridSearch","55163743":"# AdaBoosting","39011205":"https:\/\/scikit-learn.org\/stable\/auto_examples\/preprocessing\/plot_map_data_to_normal.html","e5d04efb":"# Normalizing\/Standardizing Data","100ff583":"# Model Training","4627070c":"### Train Test Split","d527d836":"PoolQC, MiscFeature, Alley, and Fence have 80% of their entries as nulls but the data literature explains away most of them. \n\n**Data Description Null Explanation:**\n* **MasVnrType\/Area** No masonry\n* **Bsmt...** No basement\n* **PoolQC, Fence, Alley, and MiscFeature** No pool, fence, alley access, or miscellaneous feature\n* **FireplaceQU** No fireplace\n* **Garage...** No garage   \n\nSo the data for almost all of these features aren't actually missing.  \n* Considering how most (80%-99%) of the homes don't contain a pool, miscfeature, alley access, or a fence, we'll transform these columns into binary columns: 0 for doesn't have and 1 for has\n* Impute the above features' NaNs with the string 'None'\n* Impute the rest with their medians."}}