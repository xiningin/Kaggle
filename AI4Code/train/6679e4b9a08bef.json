{"cell_type":{"9e32161f":"code","b6f16f25":"code","9e7f9387":"code","108017f5":"code","7d656373":"code","1d63f8a4":"code","008713ca":"code","6b898f14":"code","34576180":"code","100eed3f":"code","c437c504":"code","e55df4b9":"code","a0f708c1":"code","55f067d4":"code","c8cd642c":"code","ed98db13":"code","b07627a8":"code","029be8f8":"code","672d1cda":"code","cbc4802b":"code","22e2f052":"code","1d4d8705":"code","9276acd2":"code","e0e62a75":"code","c82d871f":"code","d0fadb15":"code","44d4d95e":"code","3b5608a1":"code","380d9f2b":"code","8dcb4f38":"code","c83eb02c":"code","b2dd4530":"code","8a92b2e0":"code","abe28a9c":"code","e9354fbb":"code","2f57dcc5":"code","c5807319":"code","ace9040c":"code","153a349b":"code","73fc0ccf":"code","14f06fb8":"code","3d99b93b":"code","c71203f8":"code","9fd0cee1":"code","9467a263":"code","55af05f6":"code","c75c0c99":"code","c076d402":"code","ee2535c3":"code","e38e749f":"code","41f2139b":"code","31f0fd82":"code","6a1ffcd6":"code","3672d843":"code","62fdafdf":"code","ea19252d":"code","0d3cade4":"code","dd2ad3f5":"code","e856cecb":"code","09df7963":"code","aa56955d":"code","543b6b74":"code","b37279d8":"code","75aa1247":"code","b5356e1c":"code","552176a6":"code","b19c4332":"code","10088b3f":"code","0ed6bf94":"code","2644d774":"code","58a1c2de":"code","97297011":"code","7b5b72f2":"code","6053bed3":"code","9b7afc36":"code","9b03cc85":"code","8e9061a6":"code","0db8e3f5":"markdown","046fb5df":"markdown","4d705492":"markdown","f7a0ed5c":"markdown","da92e5a5":"markdown","285b8be4":"markdown","d54a645e":"markdown","e89a415c":"markdown","5dc554b1":"markdown","7e4cdc47":"markdown","991b5c9c":"markdown","37960645":"markdown","4cf55b2d":"markdown","cc8d24af":"markdown","be0a3b5d":"markdown","b23f9d8d":"markdown"},"source":{"9e32161f":"!pip install wordcloud","b6f16f25":"# Import libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud\nimport nltk\nfrom nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport re\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import confusion_matrix, f1_score, roc_auc_score, roc_curve\nimport warnings\nwarnings.filterwarnings(\"ignore\")","9e7f9387":"# Download the stopwords\nnltk.download('stopwords')","108017f5":"# Read the data (.csv) file\ndata = pd.read_csv(\"..\/input\/luxury-apparel-data\/Luxury_Products_Apparel_Data.csv\")\ndata.head()","7d656373":"# Checking the Unnames: 0\ndata['Unnamed: 0'].value_counts()","1d63f8a4":"# Drop the column\ndata.drop('Unnamed: 0', axis=1, inplace=True)","008713ca":"data.head()","6b898f14":"# plot the frequency of each Category in the data\nplt.style.use('seaborn')\ndata['Category'].value_counts().sort_values().plot(kind='barh')\nplt.xlabel(\"Category\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Category Counts\")\nplt.show()","34576180":"# Plot the SubCategory Counts\nplt.style.use('seaborn')\nplt.figure(figsize=(12,12))\ndata['SubCategory'].value_counts().sort_values().plot(kind='barh')\nplt.xlabel(\"SubCategory\")\nplt.ylabel(\"Frequency\")\nplt.title(\"SubCategory Counts\")\nplt.show()","100eed3f":"def clean_text_data(data):\n\n  # Stopwords\n  stp_words = stopwords.words('english')\n\n  # Create the final string\n  final_string = \"\"\n  for word in data.values:\n    final_string += word\n\n  # Clean the text and remove the stopwords\n  clean_text = []\n  for word in final_string.split():\n    if word not in stp_words:\n      clean_text.append(word)\n\n  # Join the clean text\n  clean_string = \" \".join(clean_text)\n\n  return re.sub(r'[^\\w]', ' ', clean_string)\n\n# Extract the clean string from Product Name and Description\nclean_product_name = clean_text_data(data['ProductName'])\nclean_description_name = clean_text_data(data['Description'])","c437c504":"# PLot the most occurring words in the Product Name\nstp_words = stopwords.words('english')\nplt.figure(figsize=(12,12))\nwordcloud = WordCloud(width = 800, height = 800, background_color ='white', stopwords = stp_words, min_font_size = 10).generate(clean_product_name)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","e55df4b9":"# PLot the most occurring words in the Description\nplt.figure(figsize=(12,12))\nwordcloud = WordCloud(width = 800, height = 800, background_color ='white', stopwords = stp_words, min_font_size = 10).generate(clean_description_name)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","a0f708c1":"# Subcategories across Categories\ndata.groupby('Category').count()['SubCategory'].sort_values().plot(kind='bar')\nplt.ylabel(\"Counts\")\nplt.title(\"SubCategory counts across Category\")\nplt.show()","55f067d4":"# Copy the dataset\ndata_copy = data.copy()","c8cd642c":"# Predicting Loafers and not Loafers\ndef SubCat_binarizer(x):\n\n  '''\n  if x is not Loafers encode other categories as Not Loafers\n  '''\n  if x != 'Loafers':\n    x = 'Not Loafers'\n\n  return x\n\n# Apply the function on the copy dataset\ndata_copy['Target'] = data_copy['SubCategory'].apply(lambda x : SubCat_binarizer(x))","ed98db13":"data_copy.drop(['SubCategory'], axis=1, inplace=True)","b07627a8":"data_copy.head()","029be8f8":"# Visualise the distribution of Target variable\nlabels = data_copy['Target'].value_counts().index\nplt.pie(data_copy['Target'].value_counts(), labels=labels, explode=(0.0, 0.4), autopct=\"%1.1f%%\", shadow=True)\nplt.title(\"Target Percentage Distribution\")\nplt.tight_layout()\nplt.show()","672d1cda":"# Encode the Target and Category\nle = LabelEncoder()\ndata_copy['Category'] = data_copy['Category'].astype('str')\ndata_copy['Category'] = le.fit_transform(data_copy['Category'])","cbc4802b":"# Encode the Target\nencode_target = {'Not Loafers' : 0, 'Loafers' : 1}\ndata_copy['Target'] = data_copy['Target'].apply(lambda x : encode_target[x])","22e2f052":"# create a function to tokenize the data\ndef preprocess_data(data):\n  \n  # 1. Tokenization\n  tk = RegexpTokenizer('\\s+', gaps = True)\n  text_data = [] # List for storing the tokenized data\n  for values in data.values:\n    tokenized_data = tk.tokenize(values) # Tokenize the news\n    text_data.append(tokenized_data) # append the tokenized data\n\n  # 2. Stopword Removal\n\n  # Extract the stopwords\n  sw = stopwords.words('english')\n  clean_data = [] # List for storing the clean text\n  # Remove the stopwords using stopwords\n  for data in text_data:\n    clean_text = [words.lower() for words in data if words.lower() not in sw]\n    clean_data.append(clean_text) # Appned the clean_text in the clean_data list\n  \n  # 3. Stemming\n\n  # Create a stemmer object\n  ps = PorterStemmer()\n  stemmed_data = [] # List for storing the stemmed data\n  for data in clean_data:\n    stemmed_text = [ps.stem(words) for words in data] # Stem the words\n    stemmed_data.append(stemmed_text) # Append the stemmed text\n  \n\n  # 4. tfidf vectorizer --> Term Frequency Inverse Document Frequency\n\n  '''TF-IDF stands for Term Frequency Inverse Document Frequency of records. \n     It can be defined as the calculation of how relevant a word in a series or corpus is to a text. \n     The meaning increases proportionally to the number of times in the text a word appears but is compensated \n     by the word frequency in the corpus (data-set).'''\n\n  '''Term Frequency: In document d, the frequency represents the number of instances of a given word t. \n     Therefore, we can see that it becomes more relevant when a word appears in the text, which is rational. \n     Since the ordering of terms is not significant, we can use a vector to describe the text in the bag of term models. \n     For each specific term in the paper, there is an entry with the value being the term frequency.'''\n\n     # tf(t,d) = count of t in d \/ number of words in d\n\n  '''Document Frequency: This tests the meaning of the text, which is very similar to TF, in the whole corpus collection. \n     The only difference is that in document d, TF is the frequency counter for a term t, while df is the number of occurrences \n     in the document set N of the term t. In other words, the number of papers in which the word is present is DF.'''\n\n     # df(t) = occurrence of t in documents\n\n  '''Inverse Document Frequency: Mainly, it tests how relevant the word is. \n     The key aim of the search is to locate the appropriate records that fit the demand. \n     Since tf considers all terms equally significant, it is therefore not only possible to use the term frequencies \n     to measure the weight of the term in the paper. First, find the document frequency of a term t by counting the \n     number of documents containing the term.'''\n\n  ''' df(t) = N(t)\n      where\n      df(t) = Document frequency of a term t\n      N(t) = Number of documents containing the term t'''\n\n      # Take the log, idf(t) = log(N\/ df(t))\n      # tf-idf(t, d) = tf(t, d) * idf(t)\n  \n  # Flatten the stemmed data\n\n  updated_data = []\n  for data in stemmed_data:\n    updated_data.append(\" \".join(data))\n\n  # TFID Vector object\n  tfidf = TfidfVectorizer()\n  tfidf_matrix = tfidf.fit_transform(updated_data)\n\n  return tfidf_matrix","1d4d8705":"# Preprocess the above function\ntext_data = (data_copy['Description'] + data_copy['ProductName'])\ntfidf_matrix = preprocess_data(text_data).toarray()","9276acd2":"# Prepare the final set\nfinal_train = np.concatenate((data_copy['Category'].values.reshape(-1,1), tfidf_matrix), axis=1)\ntarget = data_copy['Target']","e0e62a75":"# Split the data\nX_train, X_test, y_train, y_test = train_test_split(final_train, target, test_size=0.2, random_state=42)","c82d871f":"# Plot the confusion matrix\ndef plot_confusion_matrix(model, model_name, X_test=X_test, y_test=y_test):\n  predictions = model.predict(X_test)\n  cnf_matrix = confusion_matrix(y_test, predictions)\n  sns.heatmap(cnf_matrix, annot=True, cbar=False, fmt='.2f', cmap='Blues')\n  plt.xlabel(\"Predicted Label\")\n  plt.ylabel(\"Actual Label\")\n  plt.title(\"{} Confusion Matrix\".format(model_name))\n  plt.show()","d0fadb15":"def print_f1_score(model, model_name, X_test=X_test, y_test=y_test):\n\n  # Make Predicitons\n  predcitions_2 = model.predict(X_test)\n\n  # Print the f1 score\n  f1 = f1_score(y_test, predcitions_2)\n  print(\"F1 score for the  {} model : {:.4f}\".format(model_name, f1))\n  return f1","44d4d95e":"# 1. KNN\nknn = KNeighborsClassifier()\nknn.fit(X_train, y_train)","3b5608a1":"knn_f1 = print_f1_score(knn, 'KNN')","380d9f2b":"# plot the confusion matrix\nplot_confusion_matrix(model=knn, model_name='KNN')","8dcb4f38":"# 2. Naive Bayes\nmnb = MultinomialNB()\nmnb.fit(X_train, y_train)\n\n# Print the f1 score\nnb_f1 = print_f1_score(model = mnb, model_name='Naive Bayes')","c83eb02c":"# Plot the confusion matrix\nplot_confusion_matrix(model=mnb, model_name='Naive Bayes')","b2dd4530":"# 3. Logistic Regression\nlr_clf = LogisticRegression()\nlr_clf.fit(X_train, y_train)","8a92b2e0":"# print the f1 score\nlr_f1 = print_f1_score(model=lr_clf, model_name='Logistic Regression')","abe28a9c":"# Plot the confusion matrix\nplot_confusion_matrix(model=lr_clf, model_name=\"Logistic Regression\")","e9354fbb":"# 4. SVM\nsvm_clf = SVC(probability=True)\nsvm_clf.fit(X_train, y_train)","2f57dcc5":"# Print the f1 score\nsvm_f1 = print_f1_score(model=svm_clf, model_name='SVM')","c5807319":"# Plot the Confusion Matrix\nplot_confusion_matrix(model=svm_clf, model_name='SVM')","ace9040c":"# 5. Decision Tree\ndt_clf = DecisionTreeClassifier()\ndt_clf.fit(X_train, y_train)","153a349b":"# Print the f1 score\ndt_f1 = print_f1_score(model=dt_clf, model_name='Decision Tree')","73fc0ccf":"# Plot the Confusion Matrix\nplot_confusion_matrix(model=dt_clf, model_name='Decision Tree')","14f06fb8":"# 6. Random Forest\nrf_clf = RandomForestClassifier()\nrf_clf.fit(X_train, y_train)","3d99b93b":"# Print the f1 score\nrf_f1 = print_f1_score(model=rf_clf, model_name='Random Forest')","c71203f8":"# Plot the confusion matrix\nplot_confusion_matrix(model=rf_clf, model_name='Random Forest')","9fd0cee1":"# 7. XGBoost\nxgb = XGBClassifier()\nxgb.fit(X_train, y_train)\n\n# Print the f1 score\nxgb_f1 = print_f1_score(model=xgb, model_name='XGBoost')","9467a263":"# plot the confusion matrix\nplot_confusion_matrix(model=xgb, model_name='XGBoost')","55af05f6":"# 8. Light GBM\nlgbm_clf = LGBMClassifier()\nlgbm_clf.fit(X_train, y_train)\n\n# print the f1 score\nlgbm_f1 = print_f1_score(model=lgbm_clf, model_name='LightGBM')","c75c0c99":"# plot the confusion matrix\nplot_confusion_matrix(model=lgbm_clf, model_name='LightGBM')","c076d402":"# Compare the models\ncombine_f1 = np.array([[knn_f1], [nb_f1], [lr_f1], [svm_f1], [dt_f1], [rf_f1], [xgb_f1], [lgbm_f1]])\ncombine_f1_df = pd.DataFrame(combine_f1, \n                             index=['KNN','Naive Bayes','Logistic Regression', 'SVM', 'Decision Tree', 'Random Forest', 'XGBoost', 'LightGBM'], \n                             columns=[\"F1 Score\"]).sort_values(by='F1 Score', ascending=False)\ncombine_f1_df","ee2535c3":"# plot the results\ncombine_f1_df.plot(kind='bar')\nplt.xlabel(\"ML Models\")\nplt.show()","e38e749f":"print(\"F1 Score of Decision Tree model on the train set {:.4f}\".format(f1_score(y_train, dt_clf.predict(X_train))))","41f2139b":"data.head()\n\n# Extract the text data\ntext_data_2  = (data['SubCategory'].astype('str') + data['ProductName'] + data['Description'])\ntrain_data_2 = preprocess_data(text_data_2).toarray()\n\n# Target \nle = LabelEncoder()\ntarget_2 = le.fit_transform(data['Category'].astype('str'))","31f0fd82":"plt.figure(figsize=(12,8))\nlabels = data['Category'].value_counts().index\nplt.pie(data['Category'].value_counts(), labels=labels, autopct=\"%1.1f%%\")\nplt.title(\"Category Distribution\")\nplt.show()","6a1ffcd6":"# Function to compute Micro\/Macro F1 score\ndef print_micro_macro_f1(model, model_name, X_test=X_test, y_test=y_test):\n\n  # make predictions\n  predictions = model.predict(X_test)\n  \n  # 1. Compute f1 macro\n  f1_macro = f1_score(y_test, predictions, average='macro')\n\n  # 2. Compute the f1 micro \n  f1_micro = f1_score(y_test, predictions, average='micro')\n\n  print(\"F1 Micro for the {} : {:.3f}\".format(model_name, f1_micro))\n  print(\"F1 Macro for the {} : {:.3f}\".format(model_name, f1_macro))\n\n  return f1_macro, f1_micro","3672d843":"# Split the data\nX_train, X_test, y_train, y_test = train_test_split(train_data_2, target_2, test_size=0.2, random_state=42)","62fdafdf":"# 1. KNN\nknn_2 = KNeighborsClassifier()\nknn_2.fit(X_train, y_train)","ea19252d":"# Print the F1 Score Macro\/Micro\nknn_f1_macro, knn_f1_micro = print_micro_macro_f1(knn_2, 'KNN', X_test=X_test, y_test=y_test)","0d3cade4":"# Plot the Confusion Matrix\nplot_confusion_matrix(model=knn_2, model_name='KNN', X_test=X_test, y_test=y_test)","dd2ad3f5":"# 2. Naive Bayes\nmnb_2 = MultinomialNB()\nmnb_2.fit(X_train, y_train)","e856cecb":"# Print the f1 score\nmnb_f1_macro, mnb_f1_micro = print_micro_macro_f1(model=mnb_2, model_name='Naive Bayes', X_test=X_test, y_test=y_test)","09df7963":"# Plot the Confusion Matrix\nplot_confusion_matrix(model=mnb_2, model_name='Naive Bayes', X_test=X_test, y_test=y_test)","aa56955d":"# 3. Logistic Regression\nlr_clf = LogisticRegression()\nlr_clf.fit(X_train, y_train)","543b6b74":"# Print the f1 score\nlr_f1_macro, lr_f1_micro = print_micro_macro_f1(model=lr_clf, model_name='Logistic Regression', X_test=X_test, y_test=y_test)","b37279d8":"# Plot the confusion matrix\nplot_confusion_matrix(model=lr_clf, model_name=\"Logistic Regression\", X_test=X_test, y_test=y_test)","75aa1247":"# 4. SVM\nsvm_clf = SVC(probability=True)\nsvm_clf.fit(X_train, y_train)","b5356e1c":"# Print the f1 score\nsvm_f1_macro, svm_f1_micro = print_micro_macro_f1(model=svm_clf, model_name='SVM', X_test=X_test, y_test=y_test)","552176a6":"# Plot the confusion matrix\nplot_confusion_matrix(model=svm_clf, model_name='SVM', X_test=X_test, y_test=y_test)","b19c4332":"# 5. Decision Tree\ndt_clf = DecisionTreeClassifier()\ndt_clf.fit(X_train, y_train)","10088b3f":"# Print the f1 score\ndt_f1_macro, dt_f1_micro = print_micro_macro_f1(model=dt_clf, model_name='Decision Tree', X_test=X_test, y_test=y_test)","0ed6bf94":"# Plot the confusion matrix\nplot_confusion_matrix(model=dt_clf, model_name='Decision Tree', X_test=X_test, y_test=y_test)","2644d774":"# 6. Random Forest\nrf_clf = RandomForestClassifier()\nrf_clf.fit(X_train, y_train)","58a1c2de":"# Print the f1 score\nrf_f1_macro, rf_f1_micro = print_micro_macro_f1(model=rf_clf, model_name='RandomForest', X_test=X_test, y_test=y_test)","97297011":"# Plot the confusion matri\nplot_confusion_matrix(model=rf_clf, model_name='Random Forest', X_test=X_test, y_test=y_test)","7b5b72f2":"# 7. XGBoost\nxgb = XGBClassifier()\nxgb.fit(X_train, y_train)\n\n# Print the f1 score\nxgb_f1_macro, xgb_f1_micro = print_micro_macro_f1(model=xgb, model_name='XGBoost', X_test=X_test, y_test=y_test)","6053bed3":"# Plot the confusion matrix\nplot_confusion_matrix(model=xgb, model_name='XGBoost', X_test=X_test, y_test=y_test)","9b7afc36":"# 8. Light GBM\nlgbm_clf = LGBMClassifier()\nlgbm_clf.fit(X_train, y_train)\n\n# print the f1 score\nlgbm_f1_macro, lgbm_f1_micro = print_micro_macro_f1(model=lgbm_clf, model_name='LightGBM', X_test=X_test, y_test=y_test)","9b03cc85":"# Plot confusion matrix\nplot_confusion_matrix(model=lgbm_clf, model_name='LightGBM', X_test=X_test, y_test=y_test)","8e9061a6":"# Compare the models\nresults = np.array([[knn_f1_macro, knn_f1_micro], \n                    [mnb_f1_macro, mnb_f1_micro], \n                    [lr_f1_macro, lr_f1_micro], \n                    [svm_f1_macro, svm_f1_micro], \n                    [dt_f1_macro, dt_f1_micro],\n                    [rf_f1_macro, rf_f1_micro],\n                    [xgb_f1_macro, xgb_f1_micro], \n                    [lgbm_f1_macro, lgbm_f1_micro]])\n\nresults_df = pd.DataFrame(results, \n                          index=['KNN', \n                                  'Naive Bayes', \n                                  'Logistic Regression', \n                                  'SVM', \n                                  'Decision Tree', \n                                  'Random Forest', \n                                  'XGBoost', \n                                  'LightGBM'], \n                          columns=['Macro_F1', \n                                    'Micro_F1']).sort_values(by='Micro_F1', ascending=False)\nresults_df","0db8e3f5":"<span style=\"font-family:cursive;\"> **Each value has one count.**","046fb5df":"<span style=\"font-family:cursive;\"> AT LAST, BEFORE LEAVING PLEASE DO UPVOTE MY WORK IF YOU LIKE IT :)","4d705492":"<span style=\"font-family:cursive;\"> **a. If we wanted to predict one particular subcategory (say, Loafers or Watches) using the\ninformation available, how would we proceed?**\n\n<span style=\"font-family:cursive;\"> **Ans.** If we want to predict only one category, then we can proceed by converting the problem into a Binary Classification problem. Let's assume we want to predict Loafers then, we will create a target variable where we will rename all subcategories other than 'Loafers' as 'Not Loafers'. Thus, making it a binary classification problem where we predict the subcategory(Loafer\/Not Loafer) of the object given it's name and description. The implementation of the above approach is shown below.","f7a0ed5c":"<span style=\"font-family:cursive;\"> **Decision Tree maximises the True Positives and True Negatives while minimising the False Positives and False Negatives at the same time as compared to all the other models. It also maximises the F1 Score. Hence, Decision Tree seem to perform best for the given problem.**","da92e5a5":"# <span style=\"font-family:cursive;\"> Classification Tasks","285b8be4":"<span style=\"font-family:cursive;\">**The model seem to generalise on both the train and the test data.**","d54a645e":"# <span style=\"font-family:cursive;\"> Data Analysis","e89a415c":"<span style=\"font-family:cursive;\"> **Since, the class distribution is imbalanced, accuracy score would not be a good metric to measure the performance of the model. Further, depending upon the business requirements we can reduce the number of False Negatives or the number of False positives. But at this stage, I am not aware of the priorities of the business. Hence, optimising Precision\/Recall would not be a good option too. Rather we can try to optimise both by using F1 Score as a metric.**","5dc554b1":" # <span style=\"font-family:cursive;\"> Initial insights around the data","7e4cdc47":"<span style=\"font-family:cursive;\"> **The data contains an Unnamed: 0, will do a simple value counts to check whether the column holds some information or is it just an identifier.**","991b5c9c":"<span style=\"font-family:cursive;\"> **Decision Tree maximizes the F1 Score for the test set. Checking it's performance on the train set to check whether the results are generalized or not.**","37960645":"<span style=\"font-family:cursive;\"> **Imbalanced distribution of classes.**","4cf55b2d":"<span style=\"font-family:cursive;\"> ***I have tried to prepare the notebook in a Q&A format. I start by generating insights from the data, then moving to a Binary Classification problem then generalizing it into a MultiClass Classification problem. It's an exhaustive notebook. I have tried to explain various concepts like TFIDF Vectorisation etc. in this notebook as well. If you are beginner at NLP problems, it should be a decent guide for you. Please do upvote my work if you like it. Happy Learning :)*** ","cc8d24af":"<span style=\"font-family:cursive;\"> **b. Would this change if we wanted to find only categories?**\n\n<span style=\"font-family:cursive;\"> **Ans:** In case of finding only Categories, the problem will be converted into a Multi-class classification, where there are more than 2 classes. The implementation of the same is shown below. Another, difference between the 2 approaches would be the choice of metric, in the previous case f1_score with average = 'binary' was selected. However, in this case the average for the f1_score could be either \"micro\" or \"macro\".\n\n<span style=\"font-family:cursive;\"> **c. Would we need to make any considerations with respect to the distribution of subcategories?**\n\n<span style=\"font-family:cursive;\"> **Ans:** Yes, earlier we had Binary Classification problem, but in this case Multiclass Classification problem.","be0a3b5d":"# <span style=\"font-family:cursive;\"> Data Preprocessing","b23f9d8d":"<span style=\"font-family:cursive;\"> **3. How can we know whether our chosen algorithm(s) has\/have worked as intended, and\nhow do we quantify its degree of effectiveness?**\n\n**Ans :** To measure the performance of the algorithm(s) following can be done:\n    \n\n1. Immediate way to measure the algorithm is to chose the right performance metric, in this case possible choice of performance metrics can be F-Beta score or Precision\/Recall(depending upon the business requirements).\n \n2. Long term way to measure the algorithm's performance is to deploy the model and monitor it's performance, if the model is giving the desired results for a suffecient period of time then the algorithm has worked as intended, else, it can be said that there is a need for improvement.\n"}}