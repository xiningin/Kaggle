{"cell_type":{"afd44d7e":"code","0790a0e9":"code","cef09a9a":"code","6363a486":"code","9328a5e0":"code","3a2a1f5f":"code","081bf034":"code","f24531a3":"code","843f0e03":"code","808097fe":"code","b7276317":"code","b967319d":"code","06d23622":"code","e02767ca":"code","a9a2da93":"code","777ec3a4":"code","0889cdb5":"code","6d3d7840":"code","f9e1a014":"code","c1f99366":"code","f9c75c46":"code","13ec59d4":"code","47703b35":"code","f806a8fb":"code","2b9717ac":"code","1aef3cde":"code","61fae2c0":"code","dd66390a":"code","941a8a15":"code","30672264":"code","05386d75":"code","f66ea4f5":"code","e8102ea4":"code","48af4102":"code","a5ae0780":"code","fab2927c":"code","eb4ff9cf":"code","c39440e2":"code","5e1e4c33":"code","9f3e4bef":"code","0beaa573":"code","99118cb8":"code","212fbc10":"code","ce010e2b":"markdown"},"source":{"afd44d7e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0790a0e9":"import numpy as np\nfrom sklearn.datasets import load_iris\nfrom sklearn.linear_model import Perceptron\n\niris = load_iris()\nX = iris.data[:, (2, 3)]  # petal length, petal width\ny = (iris.target == 0).astype(np.int)  # Iris setosa?\n\nper_clf = Perceptron()\nper_clf.fit(X, y)\n\ny_pred = per_clf.predict([[2, 0.5]])","cef09a9a":"import tensorflow as tf\nfrom tensorflow import keras","6363a486":"tf.__version__","9328a5e0":"keras.__version__","3a2a1f5f":"fashion_mnist = keras.datasets.fashion_mnist\n(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()","081bf034":"X_train_full.shape","f24531a3":"X_train_full.dtype","843f0e03":"X_valid, X_train = X_train_full[:5000] \/ 255.0, X_train_full[5000:] \/ 255.0\ny_valid, y_train = y_train_full[:5000], y_train_full[5000:]\nX_test = X_test\/255.0","808097fe":"class_names = [\"T-shirt\/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]","b7276317":"class_names[y_train[0]]","b967319d":"model = keras.models.Sequential()\nmodel.add(keras.layers.Flatten(input_shape=[28, 28]))\nmodel.add(keras.layers.Dense(300, activation=\"relu\"))\nmodel.add(keras.layers.Dense(100, activation=\"relu\"))\nmodel.add(keras.layers.Dense(10, activation=\"softmax\"))","06d23622":"model.summary()","e02767ca":"model.layers","a9a2da93":"hidden1 = model.layers[1]","777ec3a4":"hidden1.name","0889cdb5":"weights, biases = hidden1.get_weights()\nweights","6d3d7840":"weights.shape","f9e1a014":"biases","c1f99366":"biases.shape","f9c75c46":"model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\")","13ec59d4":"history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))","47703b35":"import pandas as pd\nimport matplotlib.pyplot as plt\n\npd.DataFrame(history.history).plot(figsize=(8, 5))\nplt.grid(True)\nplt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\nplt.show()","f806a8fb":"model.evaluate(X_test, y_test)","2b9717ac":"X_new = X_test[:3]\ny_proba = model.predict(X_new)\ny_proba.round(2)","1aef3cde":"y_pred = model.predict_classes(X_new)\ny_pred","61fae2c0":"import numpy as np\n\nnp.array(class_names)[y_pred]","dd66390a":"y_new = y_test[:3]\ny_new ","941a8a15":"from sklearn.datasets import fetch_california_housing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nhousing = fetch_california_housing()\n\nX_train_full, X_test, y_train_full, y_test = train_test_split(\n    housing.data, housing.target)\nX_train, X_valid, y_train, y_valid = train_test_split(\n    X_train_full, y_train_full)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_valid = scaler.transform(X_valid)\nX_test = scaler.transform(X_test)","30672264":"from tensorflow import keras\n\nmodel = keras.models.Sequential([\n    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n    keras.layers.Dense(1)\n])\nmodel.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\nhistory = model.fit(X_train, y_train, epochs=20,\n                    validation_data=(X_valid, y_valid))\nmse_test = model.evaluate(X_test, y_test)\nX_new = X_test[:3] # pretend these are new instances\ny_pred = model.predict(X_new)","05386d75":"from sklearn.datasets import fetch_california_housing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nhousing = fetch_california_housing()\n\nX_train_full, X_test, y_train_full, y_test = train_test_split(\n    housing.data, housing.target)\nX_train, X_valid, y_train, y_valid = train_test_split(\n    X_train_full, y_train_full)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_valid = scaler.transform(X_valid)\nX_test = scaler.transform(X_test)","f66ea4f5":"input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\ninput_B = keras.layers.Input(shape=[6], name=\"deep_input\")\nhidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\nhidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\nconcat = keras.layers.concatenate([input_A, hidden2])\noutput = keras.layers.Dense(1, name=\"output\")(concat)\nmodel = keras.Model(inputs=[input_A, input_B], outputs=[output])","e8102ea4":"model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n\nX_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\nX_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\nX_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\nX_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n\nhistory = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n                    validation_data=((X_valid_A, X_valid_B), y_valid))\nmse_test = model.evaluate((X_test_A, X_test_B), y_test)\ny_pred = model.predict((X_new_A, X_new_B))\n","48af4102":"output = keras.layers.Dense(1, name=\"main_output\")(concat)\naux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\nmodel = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])\nmodel.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=\"sgd\")","a5ae0780":"history = model.fit(\n    [X_train_A, X_train_B], [y_train, y_train], epochs=20,\n    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))\n","fab2927c":"total_loss, main_loss, aux_loss = model.evaluate(\n    [X_test_A, X_test_B], [y_test, y_test])\n","eb4ff9cf":"y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])","c39440e2":"class WideAndDeepModel(keras.Model):\n    def __init__(self, units=30, activation=\"relu\", **kwargs):\n        super().__init__(**kwargs) # handles standard args (e.g., name)\n        self.hidden1 = keras.layers.Dense(units, activation=activation)\n        self.hidden2 = keras.layers.Dense(units, activation=activation)\n        self.main_output = keras.layers.Dense(1)\n        self.aux_output = keras.layers.Dense(1)\n\n    def call(self, inputs):\n        input_A, input_B = inputs\n        hidden1 = self.hidden1(input_B)\n        hidden2 = self.hidden2(hidden1)\n        concat = keras.layers.concatenate([input_A, hidden2])\n        main_output = self.main_output(concat)\n        aux_output = self.aux_output(hidden2)\n        return main_output, aux_output\n\nmodel = WideAndDeepModel()","5e1e4c33":"def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n    model = keras.models.Sequential()\n    model.add(keras.layers.InputLayer(input_shape=input_shape))\n    for layer in range(n_hidden):\n        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n    model.add(keras.layers.Dense(1))\n    optimizer = keras.optimizers.SGD(lr=learning_rate)\n    model.compile(loss=\"mse\", optimizer=optimizer)\n    return model","9f3e4bef":"keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)","0beaa573":"keras_reg.fit(X_train, y_train, epochs=100,\n              validation_data=(X_valid, y_valid),\n              callbacks=[keras.callbacks.EarlyStopping(patience=10)])\nmse_test = keras_reg.score(X_test, y_test)\ny_pred = keras_reg.predict(X_new)","99118cb8":"from scipy.stats import reciprocal\nfrom sklearn.model_selection import RandomizedSearchCV\n\nparam_distribs = {\n    \"n_hidden\": [0, 1, 2, 3],\n    \"n_neurons\": np.arange(1, 100),\n    \"learning_rate\": reciprocal(3e-4, 3e-2),\n}\n\nrnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\nrnd_search_cv.fit(X_train, y_train, epochs=100,\n                  validation_data=(X_valid, y_valid),\n                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])","212fbc10":"rnd_search_cv.best_params_","ce010e2b":"THIS NOTEBOOK FOLLOS CHAPTER 10 OF HANDS-ON MACHINE LEARNING WITH SCIKIT-LEARN, KERAS, AND TENSORFLOW."}}