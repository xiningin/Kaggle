{"cell_type":{"87c8df4c":"code","de3e83d9":"code","7b995686":"code","f8bb3f64":"code","4ca8c40b":"code","745e5599":"code","1529b235":"code","934ec752":"code","9564f4b9":"code","87c608f3":"code","bcc33cf7":"code","78afa851":"code","6d99b581":"code","d12c371d":"code","7dc235ba":"code","49b84073":"code","5d362627":"code","12244dab":"code","3f1f947e":"markdown","8fd9df2d":"markdown","04a078d7":"markdown","b781a439":"markdown","626f9212":"markdown","2b44b437":"markdown","2c9e9d17":"markdown","f792a67c":"markdown","1d32fbd5":"markdown","6906157b":"markdown","0bab20f3":"markdown","a7751e4c":"markdown","e862d8fd":"markdown","bd7a12f3":"markdown","5a7ecbd2":"markdown","e838a75b":"markdown","534271f5":"markdown","a1914d23":"markdown","71c73f78":"markdown","c7b94943":"markdown"},"source":{"87c8df4c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nimport glob\nimport math\nimport random\nimport time\nimport datetime\nfrom collections import defaultdict\nfrom tqdm import tqdm, tqdm_notebook\n\nimport xml.etree.ElementTree as ET \n\nimport cv2\n\nprint(os.listdir(\"..\/input\"))","de3e83d9":"image_width = 64\nimage_height = 64\nimage_channels = 3\nimage_sample_size = 10000\nimage_output_dir = '..\/output_images\/'\nimage_input_dir = '..\/input\/all-dogs\/all-dogs\/'\nimage_ann_dir = \"..\/input\/annotation\/Annotation\/\"","7b995686":"dog_breed_dict = {}\nfor annotation in os.listdir(image_ann_dir):\n    annotations = annotation.split('-')\n    dog_breed_dict[annotations[0]] = annotations[1]","f8bb3f64":"print(dog_breed_dict['n02097658'])","4ca8c40b":"def get_input_image_dict(image_input_dir, labels_dict):\n    image_sample_dict = defaultdict(list)\n    for image in os.listdir(image_input_dir):\n        filename = image.split('.')\n        label_code = filename[0].split('_')[0]\n        breed_name = labels_dict[label_code]\n        #print('Code: {}, Breed: {}'.format(label_code, breed_name))\n        if image is not None:\n            image_sample_dict[breed_name].append(image)\n    \n    print('Created label dictionary for input images.')\n    return image_sample_dict","745e5599":"image_sample_dict = get_input_image_dict(image_input_dir, dog_breed_dict)","1529b235":"def plot_class_distributions(image_sample_dict, title=''):\n    class_lengths = []\n    labels = []\n    total_images = 0\n    \n    print('Total amount of dog breeds: ', len(image_sample_dict))\n    \n    for label, _ in image_sample_dict.items():\n        total_images += len(image_sample_dict[label])\n        class_lengths.append(len(image_sample_dict[label]))\n        labels.append(label)\n        \n    print('Total amount of input images: ', total_images)\n        \n    plt.figure(figsize = (10,30))\n    plt.barh(range(len(class_lengths)), class_lengths)\n    plt.yticks(range(len(labels)), labels)\n    plt.title(title)\n    plt.ylabel('Dog Breed')\n    plt.xlabel('Sample size')\n    plt.show()\n    \n    return total_images","934ec752":"total_images = plot_class_distributions(image_sample_dict)","9564f4b9":"def read_image(src):\n    img = cv2.imread(src)\n    if img is None:\n        raise FileNotFoundError\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return img","87c608f3":"def plot_images(directory, image_sample_dict, examples=25, disp_labels=True): \n  \n    if not math.sqrt(examples).is_integer():\n        print('Please select a valid number of examples.')\n        return\n    \n    imgs = []\n    classes = []\n    for i in range(examples):\n        rnd_class, _ = random.choice(list(image_sample_dict.items()))\n        #print(rnd_class)\n        rnd_idx = np.random.randint(0, len(image_sample_dict[rnd_class]))\n        filename = image_sample_dict[rnd_class][rnd_idx]\n        img = read_image(os.path.join(directory, filename))\n        imgs.append(img)\n        classes.append(rnd_class)\n    \n    \n    fig, axes = plt.subplots(round(math.sqrt(examples)), round(math.sqrt(examples)),figsize=(15,15),\n    subplot_kw = {'xticks':[], 'yticks':[]},\n    gridspec_kw = dict(hspace=0.3, wspace=0.1))\n    \n    for i, ax in enumerate(axes.flat):\n        if disp_labels == True:\n            ax.title.set_text(classes[i])\n        ax.imshow(imgs[i])","bcc33cf7":"plot_images(image_input_dir, image_sample_dict)","78afa851":"plot_images(image_input_dir, image_sample_dict, examples=36, disp_labels=True)","6d99b581":"def load_cropped_images(dog_breed_dict=dog_breed_dict, image_ann_dir=image_ann_dir, sample_size=25000, \n                        image_width=image_width, image_height=image_height, image_channels=image_channels):\n    curIdx = 0\n    breeds = []\n    dog_images_np = np.zeros((sample_size,image_width,image_height,image_channels))\n    for breed_folder in os.listdir(image_ann_dir):\n        for dog_ann in tqdm(os.listdir(image_ann_dir + breed_folder)):\n            try:\n                img = read_image(os.path.join(image_input_dir, dog_ann + '.jpg'))\n            except FileNotFoundError:\n                continue\n                \n            tree = ET.parse(os.path.join(image_ann_dir + breed_folder, dog_ann))\n            root = tree.getroot()\n            \n            size = root.find('size')\n            width = int(size.find('width').text)\n            height = int(size.find('height').text)\n            objects = root.findall('object')\n            for o in objects:\n                bndbox = o.find('bndbox') \n                \n                xmin = int(bndbox.find('xmin').text)\n                ymin = int(bndbox.find('ymin').text)\n                xmax = int(bndbox.find('xmax').text)\n                ymax = int(bndbox.find('ymax').text)\n                \n                xmin = max(0, xmin - 4)        # 4 : margin\n                xmax = min(width, xmax + 4)\n                ymin = max(0, ymin - 4)\n                ymax = min(height, ymax + 4)\n\n                w = np.min((xmax - xmin, ymax - ymin))\n                w = min(w, width, height)                     # available w\n\n                if w > xmax - xmin:\n                    xmin = min(max(0, xmin - int((w - (xmax - xmin))\/2)), width - w)\n                    xmax = xmin + w\n                if w > ymax - ymin:\n                    ymin = min(max(0, ymin - int((w - (ymax - ymin))\/2)), height - w)\n                    ymax = ymin + w\n                \n                img_cropped = img[ymin:ymin+w, xmin:xmin+w, :]      # [h,w,c]\n                # Interpolation method\n                if xmax - xmin > image_width:\n                    interpolation = cv2.INTER_AREA          # shrink\n                else:\n                    interpolation = cv2.INTER_CUBIC         # expansion\n                    \n                img_cropped = cv2.resize(img_cropped, (image_width, image_height), \n                                         interpolation=interpolation)  # resize\n                    \n                dog_images_np[curIdx,:,:,:] = np.asarray(img_cropped)\n                dog_breed_name = dog_breed_dict[dog_ann.split('_')[0]]\n                breeds.append(dog_breed_name)\n                curIdx += 1\n                \n    dog_images_np = dog_images_np \/ 255.  # change the pixel range to [-1, 1]\n    return dog_images_np, breeds","d12c371d":"start_time = time.time()\ndog_images_np, breeds = load_cropped_images()\nest_time = round(time.time() - start_time)\nprint(\"Feature loading time: {}.\".format(str(datetime.timedelta(seconds=est_time))))","7dc235ba":"def plot_features(features, labels, image_width=image_width, image_height=image_height, \n                image_channels=image_channels,\n                examples=25, disp_labels=True): \n  \n    if not math.sqrt(examples).is_integer():\n        print('Please select a valid number of examples.')\n        return\n    \n    imgs = []\n    classes = []\n    for i in range(examples):\n        rnd_idx = np.random.randint(0, len(labels))\n        imgs.append(features[rnd_idx, :, :, :])\n        classes.append(labels[rnd_idx])\n    \n    \n    fig, axes = plt.subplots(round(math.sqrt(examples)), round(math.sqrt(examples)),figsize=(15,15),\n    subplot_kw = {'xticks':[], 'yticks':[]},\n    gridspec_kw = dict(hspace=0.3, wspace=0.01))\n    \n    for i, ax in enumerate(axes.flat):\n        if disp_labels == True:\n            ax.title.set_text(classes[i])\n        ax.imshow(imgs[i])","49b84073":"print('Loaded features shape: ', dog_images_np.shape)\nprint('Loaded labels: ', len(breeds))","5d362627":"print('Plotting cropped images by specified coordinates..')\nplot_features(dog_images_np, breeds, examples=16, disp_labels=True)","12244dab":"plt.imshow(dog_images_np[3])","3f1f947e":"1. Xml parsing and cropping to specified bounding box - (https:\/\/www.kaggle.com\/paulorzp\/show-annotations-and-breeds)\n\n2. Also thanks to K.Amano for his cropping method with interpolation - (https:\/\/www.kaggle.com\/amanooo\/wgan-gp-keras)","8fd9df2d":"## Visualizing the images","04a078d7":"## Storing the dog breed type in a dictionary by mapping it to its code in the annotations","b781a439":"## Cropping the images according to the annotations","626f9212":"The total dog images seem to be 20579 with 22125 separately cropped dogs.","2b44b437":"We can see quite a few images with more than one dog present in the samples.","2c9e9d17":"The following helper-function will allow to create another similar dictionary but for all of the input images. Since each dog breed can be found multiple times in the dataset, the value part here will be stored as a list.","f792a67c":"## Plotting the class distributions of the input images by dog breed","1d32fbd5":"## Importing libraries","6906157b":"## Setting some constants according to the rules","0bab20f3":"After we have gathered the features and their labels, we can easily plot them once again to confirm that they have been cropped correctly and that there aren't multiple dogs in a single image.","a7751e4c":"Here I've created the dictionary ```dog_breed_dict```, which will map each breed code to its original name.","e862d8fd":"The following preprocessing function is used to create the actual features for the future model. The ```dog_images_np``` are first initialized with zeros with a fixed sample size of 25000 images. Each image from the dataset is read and information about the image objects is gathered from the <b>xml<\/b> file representing each image. \n\nAfter gathering the information on the coordinates, the input image is either cropped, shrunk or expanded, depending on the position of the object and finally, is stored to the array of features. I will also scale the input pixel values of the features to the range [-1, 1], due to the fact the future model will probably be using a <b> tanh <\/b>activation function.","bd7a12f3":"## References","5a7ecbd2":"This notebook is basically my attempt to introduce myself to the dataset a little bit by getting the full dog image dataset and the label (annotation) for every image. This in turn will allow me to analyze the class distributions for each dog breed, as well plot the dog images.\n\nFinally, since there are images with multiple dogs in them, I will attempt to separate each dog (with cropping) using the provided annotations that contain the coordinates of each object.","e838a75b":"Using the previously created ```image_sample_dict``` we can plot a matrix of images to see what the dogs look like, along with their actual breed name.","534271f5":"After we have this information, we can do some EDA. Firstly, we can print the total amount of dog breeds in the dataset and we can also count the total input images using the created ```image_sample_dict```. Secondly, we can plot the class distributions of each breed.","a1914d23":"There are people present in a few samples as well.","71c73f78":"## Creating another dictionary (of lists), in order to map each input filename to a specific dog breed","c7b94943":"Using the <b>OpenCV<\/b> imaging library, we can load each image and create an example set of features."}}