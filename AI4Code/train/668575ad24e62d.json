{"cell_type":{"40da453c":"code","c1873556":"code","98aa8b13":"code","f317de24":"code","8bb9ea93":"code","667c125a":"code","47201978":"code","537121cf":"code","5e441af8":"code","8b848480":"code","64327d39":"code","02314885":"code","41bcb121":"code","ce19135b":"code","3bedb613":"code","882d7d7e":"markdown","b2861549":"markdown"},"source":{"40da453c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c1873556":"import warnings \nwarnings.filterwarnings(\"ignore\")\nimport matplotlib.pyplot as plt\nimport os \nimport plotly_express as px\nfrom sklearn import feature_extraction,linear_model,model_selection,preprocessing\n\nimport matplotlib.patches as mpatches\n","98aa8b13":"train_df=pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')\ntest_df=pd.read_csv('\/kaggle\/input\/nlp-getting-started\/test.csv')","f317de24":"train_df[train_df[\"target\"]==0][\"text\"].values[1]","8bb9ea93":"train_df[train_df[\"target\"]==1][\"text\"].values[1]","667c125a":"count_vectorizer=feature_extraction.text.CountVectorizer()\n\n#let's count the words in first 5 tweets \nexample_train_vectors=count_vectorizer.fit_transform(train_df[\"text\"][0:5])","47201978":"print(example_train_vectors[0].todense().shape)\nprint(example_train_vectors[0].todense())","537121cf":"#vector for all the tweets\ntrain_Vectors=count_vectorizer.fit_transform(train_df[\"text\"])\ntest_vectors=count_vectorizer.transform(test_df[\"text\"])","5e441af8":"clf=linear_model.RidgeClassifier()","8b848480":"scores=model_selection.cross_val_score(clf,train_Vectors,train_df[\"target\"],cv=3,scoring=\"f1\")\nscores","64327d39":"clf.fit(train_Vectors,train_df[\"target\"])","02314885":"sample_submission=pd.read_csv('\/kaggle\/input\/nlp-getting-started\/sample_submission.csv')","41bcb121":"sample_submission[\"target\"]=clf.predict(test_vectors)","ce19135b":"sample_submission.head()","3bedb613":"sample_submission.to_csv(\"submission.csv\",index=False)","882d7d7e":"**The above data tells us ** that there are 54 unique words in the first five tweets and all the 1s represents the tokens that do exists in first tweet. ","b2861549":"The simplest way to determine if the tweet is about real disaster or not, is to look at the words. \nin order t odo that we are using 'scikit-learn's CountVectorizer to count the words in each tweet and turn them into data our model can process. "}}