{"cell_type":{"568a8083":"code","6719c021":"code","d0cd76b7":"code","1258da97":"code","5f8364e5":"code","b6f33a1c":"code","20b35c7d":"code","b908a8ba":"code","74a930a3":"code","59e0e937":"code","5f69cf84":"code","e9bf1bd5":"code","782b6844":"code","9bb579de":"code","83267f47":"code","36fc2378":"code","cfd59597":"code","e26a001d":"code","9c1ab3d3":"code","0d7ebf99":"code","ec8b04e5":"code","b2b2a775":"code","7dad399a":"code","459246e8":"code","8d6dd213":"code","8cc36612":"code","d5668f00":"code","3c418217":"code","f2e961f0":"code","aab4b184":"code","3fcb2773":"code","a6e134d0":"code","33778033":"code","b6741505":"code","44931af5":"code","fa25bf70":"code","5d0ad32e":"code","dfaa4b20":"code","e964ae2a":"code","19ed1e26":"code","29776fe3":"code","5e83c718":"code","6a1eb806":"code","eff6d8aa":"code","e164e266":"code","aeadcf6b":"code","1474f99d":"code","967725c5":"code","13e47233":"code","a3f25e6a":"code","06ad7eea":"code","3da3e59b":"code","6acdb392":"code","02bd4b75":"code","891ba37c":"code","9269747e":"code","1d6f776f":"code","3baaed66":"code","46fb25e5":"code","eeb76e29":"code","76bc5ba7":"code","64d0bbce":"code","b267d1fd":"code","7ddd664f":"markdown","ed1184a8":"markdown","7fa8528b":"markdown","2adad07e":"markdown","2982d241":"markdown","bc07e979":"markdown","7a2fce1d":"markdown","22aeb69b":"markdown","c01770cf":"markdown","91c79035":"markdown","34ae2e2c":"markdown","c02eb75b":"markdown","1843e25e":"markdown","29380467":"markdown","c0140800":"markdown","0d78f548":"markdown","9d2f9486":"markdown","bd04271a":"markdown","a37f0376":"markdown","7a763a60":"markdown","89a415e8":"markdown","c39306c5":"markdown","e0d0b669":"markdown","a03c65b7":"markdown","5e8dfed3":"markdown","be000b60":"markdown","fa6e9484":"markdown","dbf4c5df":"markdown","8ea3f4f2":"markdown","b2abda74":"markdown","c67e3957":"markdown","e80b1c26":"markdown","66cdbd2c":"markdown","69573870":"markdown","6e1dabba":"markdown","fed1e28c":"markdown","acf0ae5b":"markdown","bc789db6":"markdown","aea03b3a":"markdown","5d940b29":"markdown","647ab8ff":"markdown","f16b439d":"markdown","b463a311":"markdown","2ec3952c":"markdown","d12f092d":"markdown","cc66be13":"markdown"},"source":{"568a8083":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6719c021":"ss = pd.read_csv(\"\/kaggle\/input\/churn-for-bank-customers\/churn.csv\")\ndf = ss.copy()\ndf.head()","d0cd76b7":"df.columns","1258da97":"df.info()","5f8364e5":"df.isnull().any()","b6f33a1c":"df.drop([\"RowNumber\",\"CustomerId\",\"Surname\"], axis = 1 , inplace = True)\ndf.columns","20b35c7d":"cat_list = [\"Geography\",\"Gender\",\"Tenure\",\"NumOfProducts\",\"HasCrCard\",\"IsActiveMember\",\"Exited\"]","b908a8ba":"def category(variable):\n    print(df[variable].value_counts())\n    \n    sns.countplot(df[variable])\n    plt.show()","74a930a3":"for i in cat_list:\n    category(i)","59e0e937":"num_list = [\"CreditScore\",\"Age\",\"Balance\",\"EstimatedSalary\"]","5f69cf84":"def numeric(variable):\n    \n    plt.hist(df[variable], bins = 20, color = \"green\")\n    plt.xlabel(variable)\n    plt.ylabel(\"Frequency\")\n    plt.title(\"{} variable distribution\".format(variable))\n    plt.show()","e9bf1bd5":"for i in num_list:\n    numeric(i)","782b6844":"cat_effect = [\"Geography\",\"Gender\",\"Tenure\",\"NumOfProducts\",\"HasCrCard\",\"IsActiveMember\"]","9bb579de":"def kategorik_etki(variable):\n    \n    print(\"{} effect of variable on customer churn : \\n\".format(variable))\n    print(df.groupby(variable)[\"Exited\"].mean())\n    \n    sns.countplot(y = variable, hue = \"Exited\" , data = df)\n    plt.show()","83267f47":"for i in cat_effect:\n    kategorik_etki(i)","36fc2378":"list_ol = [\"CreditScore\",\"Age\",\"Tenure\",\"Balance\",\"NumOfProducts\",\"EstimatedSalary\"]","cfd59597":"def outlier_show(variable):\n    \n    sns.boxplot(df[variable])\n    plt.show()","e26a001d":"for i in list_ol:\n    outlier_show(i)","9c1ab3d3":"  def outlier(df_ol, degiskenler):\n    \n    aykiri_indexler = []\n    \n    for i in degiskenler:\n        \n        Q1 = df_ol[i].quantile(0.25)\n        Q3 = df_ol[i].quantile(0.75)\n\n\n        IQR = Q3 - Q1\n\n        alt_sinir = Q1 - 1.5*IQR\n        ust_sinir = Q3 + 1.5*IQR\n\n        toplam_filtre = ((df_ol[i] < alt_sinir) | (df_ol[i] > ust_sinir))\n\n        aykiri_gozlemler = df_ol[i][toplam_filtre]\n        aykiri_index = aykiri_gozlemler.index\n        \n        aykiri_indexler.extend(aykiri_index)\n        \n    aykiri_indexler = Counter(aykiri_indexler)\n    \n    ortak_indexler = [i for i, v in aykiri_indexler.items() if v > 0]\n    \n    return ortak_indexler","0d7ebf99":"ortak_indexler = outlier(df, [\"CreditScore\",\"Age\",\"Tenure\",\"Balance\",\"NumOfProducts\",\"EstimatedSalary\"])","ec8b04e5":"df.loc[ortak_indexler]","b2b2a775":"df.shape","7dad399a":"df = df.drop(ortak_indexler, axis = 0).reset_index(drop = True)","459246e8":"df.shape","8d6dd213":"list_corr = [\"CreditScore\",\"Age\",\"Tenure\",\"Balance\",\"NumOfProducts\",\"EstimatedSalary\",\"Exited\"]\nsns.heatmap(df[list_corr].corr(), annot = True, linecolor = \"black\", lw = 0.5, fmt= '.2f') ","8cc36612":"sns.lineplot(x = \"Age\", y = \"Exited\", data = df);","d5668f00":"df.groupby(df[\"Exited\"])[\"Age\"].mean()","3c418217":"(sns.FacetGrid(df, hue = \"Exited\", height = 5).map(sns.kdeplot, \"Balance\", shade= True).add_legend());","f2e961f0":"df.groupby(df[\"Exited\"])[\"Balance\"].mean()","aab4b184":"(sns.FacetGrid(df, col = \"Exited\", row = \"NumOfProducts\", height = 5).map(plt.hist, \"Balance\",bins =10).add_legend());","3fcb2773":"df.groupby([\"NumOfProducts\",\"Exited\"])[\"Balance\"].mean()","a6e134d0":"df[\"NumOfProducts\"] = df[\"NumOfProducts\"].astype(\"category\")\ndf[\"HasCrCard\"] = df[\"HasCrCard\"].astype(\"category\")\ndf[\"IsActiveMember\"] = df[\"IsActiveMember\"].astype(\"category\")\n\ndf = pd.get_dummies(df, columns = [\"Geography\"])\ndf = pd.get_dummies(df, columns = [\"Gender\"])\ndf = pd.get_dummies(df, columns = [\"NumOfProducts\"])\ndf = pd.get_dummies(df, columns = [\"HasCrCard\"])\ndf = pd.get_dummies(df, columns = [\"IsActiveMember\"])","33778033":"df.head()","b6741505":"df.drop([\"Tenure\"], axis = 1 , inplace = True)","44931af5":"x_df = df.drop([\"Exited\"], axis=1)\ny = df[\"Exited\"]\n\nx = (x_df - np.min(x_df)) \/ (np.max(x_df)-np.min(x_df)).values\nx.head()","fa25bf70":"x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.20, random_state = 42)","5d0ad32e":"loj = LogisticRegression(solver = \"liblinear\")\nloj.fit(x_train,y_train)\nloj","dfaa4b20":"loj.intercept_","e964ae2a":"loj.coef_","19ed1e26":"print(\"Test accurarcy {}\".format(loj.score(x_test,y_test)))","29776fe3":"y_pred = loj.predict(x_test)\ny_true = y_test\n\ncm =confusion_matrix(y_true,y_pred)\n\nf, ax = plt.subplots(figsize = (5,5))\nsns.heatmap(cm,annot=True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()","5e83c718":"cross_val_score(loj, x_test, y_test, cv = 10).mean()","6a1eb806":"knn = KNeighborsClassifier()\nknn_model = knn.fit(x_train,y_train)\nknn_model","eff6d8aa":"y_pred = knn_model.predict(x_test)","e164e266":"accuracy_score(y_test,y_pred)","aeadcf6b":"knn_params = {\"n_neighbors\": np.arange(1,50)}","1474f99d":"knn = KNeighborsClassifier()\nknn_cv = GridSearchCV(knn, knn_params, cv=10)\nknn_cv.fit(x_train, y_train)","967725c5":"print(\"The best parameters: \" + str(knn_cv.best_params_))","13e47233":"knn = KNeighborsClassifier(7)\nknn_model = knn.fit(x_train, y_train)","a3f25e6a":"y_pred = knn_model.predict(x_test)","06ad7eea":"accuracy_score(y_test, y_pred)","3da3e59b":"y_true = y_test\n\ncm =confusion_matrix(y_true,y_pred)\n\nf, ax = plt.subplots(figsize = (5,5))\nsns.heatmap(cm,annot=True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()","6acdb392":"rf_model = RandomForestClassifier().fit(x_train, y_train)","02bd4b75":"y_pred = rf_model.predict(x_test)\naccuracy_score(y_test, y_pred)","891ba37c":"rf_params = {\"max_depth\": [2,5,8,10],\n            \"max_features\": [2,5,8],\n            \"n_estimators\": [10,500,1000],\n            \"min_samples_split\": [2,5,10]}","9269747e":"rf_model = RandomForestClassifier()\n\nrf_cv_model = GridSearchCV(rf_model, \n                           rf_params, \n                           cv = 10, \n                           n_jobs = -1, \n                           verbose = 2) ","1d6f776f":"rf_cv_model.fit(x_train, y_train)","3baaed66":"print(\"The best parameters: \" + str(rf_cv_model.best_params_))","46fb25e5":"rf_tuned = RandomForestClassifier(max_depth = 10, \n                                  max_features = 5, \n                                  min_samples_split = 5,\n                                  n_estimators = 1000)\n\nrf_tuned.fit(x_train, y_train)","eeb76e29":"y_pred = rf_tuned.predict(x_test)\naccuracy_score(y_test, y_pred)","76bc5ba7":"y_true = y_test\n\ncm =confusion_matrix(y_true,y_pred)\n\nf, ax = plt.subplots(figsize = (5,5))\nsns.heatmap(cm,annot=True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()","64d0bbce":"models = [\n    knn_model,\n    loj,\n    rf_tuned,\n     \n        ]\n\n\nfor model in models:\n    names = model.__class__.__name__\n    y_pred = model.predict(x_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    print(\"-\"*28)\n    print(names + \":\" )\n    print(\"Accuracy: {:.4%}\".format(accuracy))","b267d1fd":"logistic_roc_auc = roc_auc_score(y_test, loj.predict(x_test))\nfpr, tpr, thresholds = roc_curve(y_test, loj.predict_proba(x_test)[:,1])\nknn_roc_auc = roc_auc_score(y_test, knn_model.predict(x_test))\nknn_fpr, knn_tpr, knn_thresholds = roc_curve(y_test, knn_model.predict_proba(x_test)[:,1])\nrf_roc_auc = roc_auc_score(y_test, rf_tuned.predict(x_test))\nrf_fpr, rf_tpr, rf_thresholds = roc_curve(y_test, rf_tuned.predict_proba(x_test)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logistic_roc_auc)\nplt.plot(knn_fpr, knn_tpr, label='KNN (area = %0.2f)' % knn_roc_auc)\nplt.plot(rf_fpr, rf_tpr, label='Random Forest (area = %0.2f)' % rf_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()","7ddd664f":"* We deleted outlier observations from the data set.","ed1184a8":"<a id = \"6\"><\/a><br>\n## The Effect of Categorical Variables on the Dependent Variable\n* We have collected our categorical variables in the list named \"cat_effect\" that we will examine with dependent variables.\n* Then we created a function called categorical_effect, and we navigate through our list with the for loop and call our function.","7fa8528b":"* Coefficients of the inputs of the independent variables (the values a, b, c in the equation, of course, we have 16 arguments, not 3)","2adad07e":"<a id = \"26\"><\/a><br>\n# Comparison of Models","2982d241":"# Churn for Bank Customers\n\n## What is our problem?\n* Our problem with the data set is whether the bank will lose its customers.\n* While solving this problem, we need to understand our data set well and ask ourselves the right questions while analyzing the data set.\n\n### The story of the data set\n* We have 14 variables and 10000 observations.\n* The variable exited is our target variable, the other variables are our independent variables.\n* We have 11 continuous variables and 3 categorical variables.\n* Binary Classification problem.\n\n### Features\n* RowNumber : It corresponds to the record (line) number and has no effect on the output.\n* CustomerId : Contains random numbers, no effect on our target variable.\n* Surname : Customer's last name, it has no effect on our problem.\n* CreditScore : Refers to the credit score.\n* Geography : Refers to the country. (France, Germany, Spain)\n* Gender : Refers to gender. (Femal or Male)\n* Age : Refers to the age of the customer.\n* Tenure : It refers to the number of years that the customer is a customer of the bank.\n* Balance : Person's account balance.\n* NumOfProducts : Refers to the number of products a customer has purchased through a bank.\n* HasCrCard : Indicates whether the customer has a credit card.(0 or 1)\n* IsActiveMember : It expresses whether the customer is active in using banks.(0 or 1)\n* EstimatedSalary : Estimated salary of the customer.\n* Exited : Whether the customer has left the bank.(1 left 0 remainder)","bc07e979":"<a id = \"4\"><\/a><br>\n## Analysis of Categorical Variables\n* I am collecting our categorical variables in the \"cat_list\" list.\n* Then I create a function rather than create and analyze a chart one by one.\n* Then I go through the list with the for loop and call the function.","7a2fce1d":"<a id = \"24\"><\/a><br>\n### Model & Prediction","22aeb69b":"* Yes, as we said while analyzing the correlation matrix, as the age of the customer increases, the customer losing rate increases.\n* Average age of customers who did not leave the bank ==> 36\n* Average age of customers leaving the bank ==> 43","c01770cf":"<a id = \"12\"><\/a><br>\n## NumOfProducts-Balance-Exited","91c79035":"<a id = \"8\"><\/a><br>\n# Correlation Matrix","34ae2e2c":"* There are 1 or more outliers in 432 observations.","c02eb75b":"* Constant value (the \"e\" value in the equation).","1843e25e":"<a id = \"25\"><\/a><br>\n### Model Tuning","29380467":"<a id = \"5\"><\/a><br>\n## Analysis of Numerical Variables\n* I am collecting our continuous variables in the \"num_list\" list.\n* Then I create a function rather than create and analyze a chart one by one.\n* Then I go through the list with the for loop and call the function.","c0140800":"<a id = \"3\"><\/a><br>\n# Data visualization","0d78f548":"<a id = \"16\"><\/a><br>\n# Modeling\n* Logistic Regression\n* KNN\n* Random Forest","9d2f9486":"* While examining the relationships between variables, we realized that the Tenure variable has no effect on our target variable. We will delete the Tenure variable so that it does not mislead our model.","bd04271a":"* Average loss of customers is highest in Germany.\n* Female customers left the bank more often.\n* We cannot draw an exact conclusion from the Tenure variable. The distributions are close.\n* It is observed that customers who buy more than 2 products have a high rate of loss, but let's not forget that our data is unstable. All of the customers (60 people) who bought 4 products left the bank.\n* Customer churn rate with or without credit cards was close, but the data in our HasCrCard variable was unstable.\n* Customers who do not actively use the bank leave the bank more.","a37f0376":"* Age has the strongest relation with Exited (0.35). Here we can make the following comment: As the age of the customer increases, the rate of losing the customer increases. (Positive strong relationship)\n* Exited and Balance variable have a relatively strong relationship (0.12).\n* Exited and the variable NumOfProducts have a moderately strong relationship (-0.11). They have a strong negative relationship.","7a763a60":"<a id = \"23\"><\/a><br>\n## Random Forest","89a415e8":"<a id = \"13\"><\/a><br>\n# Feature Engineering\n* We will split Geography, Gender, NumOfProducts, HasCrCard and IsActiveMember variables into variables according to the values they get for our model. We will briefly implement the dummies process.","c39306c5":"<a id = \"7\"><\/a><br>\n# Outliers\n* We used the boxplot graph to see the outliers.","e0d0b669":"<a id = \"17\"><\/a><br>\n## Logistic Regression\n* y = ax1 + bx2 + cx3 + e ===> y is the output of our dependent variable, x is the input of our independent variables (a, b, and c are the input coefficients of our independent variables), and e is our constant.","a03c65b7":"* The variables Credit Score, Age, Num Products have outlier observations.\n* We create a function to detect outliers and keep the indexes of these values in a list.","5e8dfed3":"# Thank You for Reading\n### If you like it please you can vote :)\n![spongebob.jpg](attachment:spongebob.jpg)","be000b60":"<a id = \"2\"><\/a><br>\n# Import data and let's simply examine the data set","fa6e9484":"<a id = \"9\"><\/a><br>\n# The Effect of Numerical Variables on The Dependent Variable","dbf4c5df":"# INTRODUCTION\n1. [Import Libraries](#1)\n2. [Import data and let's simply examine the data set](#2)\n3. [Data visualization](#3)\n    * [Analysis of Categorical Variables](#4)\n    * [Analysis of Numerical Variables](#5)\n    * [The Effect of Categorical Variables on the Dependent Variable](#6)\n4. [Outliers](#7)\n5. [Correlation Matrix](#8)\n6. [The Effect of Numerical Variables on The Dependent Variable](#9)\n    * [Age-Exited](#10)\n    * [Balance-Exited](#11)\n    * [NumOfProducts-Balance-Exited](#12)\n7. [Feature Engineering](#13)\n8. [Feature Scaling](#14)\n9. [Train-Test Split](#15)\n10. [Modeling](#16)\n    * [Logistic Regression](#17)\n        * [Model & Prediction](#18)\n        * [Model Tuning](#19)\n    * [KNN](#20)\n        * [Model & Prediction](#21)\n        * [Model Tuning](#22)\n    * [Random Forest](#23)\n        * [Model & Prediction](#24)\n        * [Model Tuning](#25)\n11. [Comparison of Models](#26)\n","8ea3f4f2":"<a id = \"21\"><\/a><br>\n### Model & Prediction","b2abda74":"#### The variables that would not affect our problem in our data set were removed from the data set.","c67e3957":"<a id = \"1\"><\/a><br>\n# Import Libraries","e80b1c26":"<a id = \"18\"><\/a><br>\n### Model & Prediction","66cdbd2c":"* Customers mainly live in France, the number of customers living in Germany and Spain is very close.\n* Customers' gender is predominantly male but their numbers are close to each other, so we can say that it is a balanced variable.\n* We have understood that customers have generally been customers of the bank for 1 to 9 years.\n* Customers generally bought 1 and 2 products, there is a serious decrease in the number of customers who bought more than 2 products. An unbalanced distribution.\n* Customers usually hold credit cards. There is an unbalanced distribution.\n* Customers use the bank more actively, but there is a balanced distribution.\n* Customers generally did not leave the bank. There is an unbalanced distribution.","69573870":"* When the success of the models was examined, KNN algorithm achieved low success compared to Logistic Regression and Random Forest algorithms.\n* We obtained the best success score from the Random Forest algorithm.","6e1dabba":"<a id = \"11\"><\/a><br>\n## Balance-Exited","fed1e28c":"* We deleted the value 4 in the NumOfProducts variable in the process of deleting outliers.","acf0ae5b":"<a id = \"22\"><\/a><br>\n### Model tuning\n* We will find the optimum hyperparameter values.","bc789db6":"<a id = \"14\"><\/a><br>\n# Feature Scaling\n* Since the variables in our data set are unstable, we applied the normalization method.","aea03b3a":"<a id = \"10\"><\/a><br>\n## Age-Exited","5d940b29":"<a id = \"15\"><\/a><br>\n# Train-Test Split","647ab8ff":"* Credit Score variable is skewed to the left.\n* The age variable is skewed to the right.\n* Since the ratio of the balance variable is too much, it is added to the left.\n* EstimatedSalary variable displayed a normal distribution.","f16b439d":"* There is no missing value in the data set.","b463a311":"<a id = \"20\"><\/a><br>\n## KNN","2ec3952c":"* Since the value in the account balance of the customers is too much 0, we may not be able to make an accurate analysis, but we can say the following comments, when the customer's account balance is 0, usually customers have not left the bank and customers with account balances between 50000 and 200000 usually leave the bank.\n* Average account balance of customers who cannot leave the bank ==> 72,870\n* Average account balance of customers leaving the bank ==> 90,902\n* But here, the high number of customers with 0 account balance makes our variable unbalanced.","d12f092d":"#### We have 14 variables and 10000 observations in the dataset, also;\n* We have 3 String variables. (Surname, Geography, Gender)\n* We have 11 numerical variables. (RowNumber, CustomerId, CreditScore, Age, Tenure, Balance, NumOfProducts, HasCrCard, IsActiveMember, EstimatedSalary, Exited)","cc66be13":"<a id = \"19\"><\/a><br>\n### Model Tuning\n* I apply cross validation to prevent overfitting."}}