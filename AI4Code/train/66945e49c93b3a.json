{"cell_type":{"40262d29":"code","1cbb08b1":"code","bf6e3de4":"code","6555b91e":"code","23b5d1cb":"code","5bf6fd5b":"code","096328be":"code","b68f8db5":"code","5e2217d7":"code","ea5fdb21":"code","80409af8":"code","f7ccf4df":"code","0f1c1e72":"code","bae71251":"code","b46221aa":"code","8953b8b4":"code","163d140e":"code","db18503f":"code","150b6025":"code","c933e0cd":"code","6a65f198":"code","5d8a09c4":"code","17d8e283":"code","f69a4d0e":"code","1b4872fc":"code","8c67713a":"code","1234e893":"code","6beebc90":"code","548f565b":"code","d2955bfe":"code","ecf23645":"code","9659937d":"code","e1b54146":"code","0080faed":"code","389c3a22":"code","5f953f01":"code","ede346f1":"code","802041a1":"code","0afa1e8a":"code","a283193a":"code","36b5939b":"markdown","eef9dd51":"markdown","a465f056":"markdown","0ad21517":"markdown","faf58f2c":"markdown","6e85f4c5":"markdown","61c7e8da":"markdown","a0c25bf3":"markdown","f9f45b99":"markdown","6e69b1a7":"markdown","63150c71":"markdown"},"source":{"40262d29":"# NumPy\u306e\u8aad\u307f\u8fbc\u307f\nimport numpy as np\n# Pandas\u306e\u8aad\u307f\u8fbc\u307f\nimport pandas as pd \n# OS\u30e2\u30b8\u30e5\u30fc\u30eb:\u30d7\u30ed\u30b0\u30e9\u30e0\u306e\u4e2d\u3067OS\u306e\u6642\u9593\u3092\u5229\u7528\u3057\u305f\u308a\u3001\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u30a2\u30af\u30bb\u30b9\u3057\u3066\u30d5\u30a1\u30a4\u30eb\u306e\u4f5c\u6210\/\u7de8\u96c6\/\u524a\u9664\u306a\u3069\u304c\u3067\u304d\u308b\nimport os\n# OpenCV:\u753b\u50cf\u3092\u51e6\u7406\u3059\u308b\u306e\u306b\u5fc5\u8981\u306a\u69d8\u3005\u306a\u6a5f\u80fd\u3092\u63d0\u4f9b\u3059\u308b\u30e9\u30a4\u30d6\u30e9\u30ea\nimport cv2\n# matplotlib:NumPy\u306e\u305f\u3081\u306e\u30b0\u30e9\u30d5\u63cf\u753b\u30d1\u30c3\u30b1\u30fc\u30b8\n# pyplot:\u307b\u3057\u3044\u30d7\u30ed\u30c3\u30c8\u3092\u4f5c\u308b\u305f\u3081\u306b\u6697\u9ed9\u7684\u304b\u3064\u81ea\u52d5\u7684\u306b\u56f3\u5f62\u3084\u8ef8\u3092\u4f5c\u6210\u3059\u308b\u30e2\u30b8\u30e5\u30fc\u30eb\nfrom matplotlib import pyplot as plt\n# TPU\u306e\u5834\u5408\u3001\u30c7\u30fc\u30bf\u306fGoogle Cloud Storage\u306e\u307f\u30a2\u30af\u30bb\u30b9\u3067\u304d\u308b\u305f\u3081\u3001\u4f7f\u7528\nfrom kaggle_datasets import KaggleDatasets\n\n# tensorflow:\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u4e3b\u306a\u30e9\u30a4\u30d6\u30e9\u30ea\n# keras:\u5358\u4f53\u3067\u306f\u4f7f\u3046\u3053\u3068\u306e\u3067\u304d\u306a\u3044\u30e9\u30a4\u30d6\u30e9\u30ea\u3002tensorflow\u304c\u5fc5\u8981\nimport tensorflow as tf\n# Sequential:\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u3092\u7c21\u7565\u5316\u3059\u308b\u30e2\u30c7\u30eb\u306e\u4e00\u3064\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers as L\nfrom tensorflow.keras.utils import to_categorical\n\n# train_test_split:train\u30c7\u30fc\u30bf\u3068test\u30c7\u30fc\u30bf\u306b\u5206\u3051\u308b\u30e2\u30b8\u30e5\u30fc\u30eb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn import metrics\n\n%matplotlib inline","1cbb08b1":"# \n# TPU\u306e\u521d\u671f\u5316\n# \n# \u4f8b\u5916\u51e6\u7406\u306etry\ntry:\n#     TPU\u306e\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u60c5\u5831\u3092\u7372\u5f97\u3002TPU\u304c\u5229\u7528\u3067\u304d\u306a\u3044\u74b0\u5883\u3067\u306f\u30a8\u30e9\u30fc\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n#     TPU\u5229\u7528\u53ef\u80fd\u5316\u306e\u78ba\u8a8d\n    print('Running on TPU:', tpu.master())\n# \u4e0a\u8a18\u3067\u30a8\u30e9\u30fc\uff08\u4f8b\u5916\uff09\u304c\u51fa\u305f\u5834\u5408\u306e\u51e6\u7406\nexcept ValueError:\n    tpu = None\n\n# tpu\u304c\u5229\u7528\u3067\u304d\u308b\u5834\u5408\uff08Accelerator TPU\uff09\n# \u4e0a\u8a18\u3067None\u3067\u306a\u3044\u3068\u304d\nif tpu:\n#   \u30ea\u30e2\u30fc\u30c8\u30af\u30e9\u30b9\u30bf\u306b\u63a5\u7d9a\u3057\u3066TPU\u3092\u521d\u671f\u5316\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n#   \u30c7\u30fc\u30bf\u306e\u4e26\u5217\u51e6\u7406\u3092\u4f7f\u7528\u3057\u3066\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3092\u5206\u6563\u3059\u308b\n#   TPU\u3067\u4e26\u5217\u51e6\u7406\u306e\u65b9\u6cd5\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n# TPU\u306a\u3057\u306e\u3068\u304d\uff08Accelerator None\uff09\nelse:\n    strategy = tf.distribute.get_strategy()\n\n# \u4e26\u5217\u51e6\u7406\u306e\u30ec\u30d9\u30eb\u306b\u95a2\u3059\u308b\u6c7a\u5b9a\u3092AUTO\u3067\u884c\u3046\nAUTO = tf.data.experimental.AUTOTUNE\n# TPU\u306fGCS(Google Cloud Storage)\u306b\u306e\u307f\u30a2\u30af\u30bb\u30b9\u3067\u304d\u308b\u3002\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()\n\n# \u30df\u30cb\u30d0\u30c3\u30c1\u52fe\u914d\u964d\u4e0b\u6cd5\u3092\u884c\u3046\u969b\u3001\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u5e7e\u3064\u304b\u306e\u30b5\u30d6\u30bb\u30c3\u30c8\u306b\u5206\u3051\u308b\n# \u30b5\u30d6\u30bb\u30c3\u30c8\u306e\u52fe\u914d\u306e\u5e73\u5747\u3067\u91cd\u307f\u3092\u66f4\u65b0\u3059\u308b\n# \u305d\u306e\u30b5\u30d6\u30bb\u30c3\u30c8\u306e\u5927\u304d\u3055\u3092Batch Size\u3068\u547c\u3076\n# strategy.num_replicas_in_sync\u306fstrategy\u306e\u5206\u5272\u3057\u305fTPU\u30ec\u30d7\u30ea\u30ab\u306e\u6570\u3092\u8868\u3059\u3002\n# TPU\u304c\u4f7f\u7528\u53ef\u80fd\u306a\u5834\u5408\u3001\u30ec\u30d7\u30ea\u30ab\u6570\u306f8\u3067\u3042\u308b\u304b\u30898\u500d\u3057\u305f\u6570\u3092\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u3068\u3059\u308b\u3002\n# TPU\u4f7f\u7528\u4e0d\u53ef\u306e\u6642\u3001\u30ec\u30d7\u30ea\u30ab\u6570\u306f1\u3068\u306a\u308a\u3001\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u306f8\nBATCH_SIZE = 8 * strategy.num_replicas_in_sync\nIMG_SIZE = 768\n\nprint('Batch size:', BATCH_SIZE)","bf6e3de4":"train = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/test.csv')\nsub = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/sample_submission.csv')\n\nprint(train.head())\n\n# GCS\u3067image\u306e\u30d1\u30b9\u6307\u5b9a\ntrain_path = train.image_id.apply(lambda x: f'{GCS_DS_PATH}\/images\/{x}.jpg').values\ntest_path = test.image_id.apply(lambda x: f'{GCS_DS_PATH}\/images\/{x}.jpg').values\n# train\u306eimage_id\u3092\u524a\u9664\u3057\u3001array\u306b\ntrain_label = train.loc[:, 'healthy':].values\n\n# train_path, valid_path, train_label, valid_label = train_test_split(train_path, train_label,\n#                                                                     test_size=0.1, stratify=train_label)","6555b91e":"# weight\u3092\u304b\u3051\u308b\u3068\u5168\u30c7\u30fc\u30bf\u6570\u306e1\/4\u306b\u306a\u308b\n# n_samples[1821] \/ (n_classes[4] * np.bincount(y)[healthy:516\/multi:91\/rust:622\/scab:592])\nclass_weight = compute_class_weight('balanced', np.unique(np.argmax(train_label, axis=1)), np.argmax(train_label, axis=1))\n# barplot\u306e\u4f5c\u6210\nplt.bar(range(4), class_weight)","23b5d1cb":"# 2\u00d72\u3067\u8868\u793a\nfig, ax = plt.subplots(2, 2)\n# \u30b5\u30f3\u30d7\u30eb\u8aad\u307f\u8fbc\u307f\nimg = cv2.imread('\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/Train_0.jpg')\nimg1 = cv2.imread('\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/Train_1.jpg')\nimg2 = cv2.imread('\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/Train_2.jpg')\nimg3 = cv2.imread('\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/Train_3.jpg')\n# \u5834\u6240\u6307\u5b9a\u3057\u305f\u66f8\u304d\u51fa\u3057\nax[0, 0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\nax[0, 1].imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\nax[1, 0].imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\nax[1, 1].imshow(cv2.cvtColor(img3, cv2.COLOR_BGR2RGB))","5bf6fd5b":"# \u30c7\u30b3\u30fc\u30c9\u306e\u5b9a\u7fa9\ndef decode_image(filename, label=None, image_size=(IMG_SIZE, IMG_SIZE)):\n#     \u751f\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u307f\n    bits = tf.io.read_file(filename)\n#     \u753b\u50cf\u306e\u30c6\u30f3\u30bd\u30eb\u306b\u30c7\u30b3\u30fc\u30c9\n    image = tf.image.decode_jpeg(bits, channels=3)\n#     0-255\u306eRGB\u30920-1\u306b\u3059\u308bnormalize\n    image = tf.cast(image, tf.float32) \/ 255.0\n#     1365\u00d72048\u306e\u753b\u50cf\u3092\u3001768\u00d7768\u306b\u3059\u308b\n    image = tf.image.resize(image, image_size)\n    \n#     \u6761\u4ef6\u5f0f\u306e\u610f\u5473\u306f\u308f\u304b\u308a\u307e\u305b\u3093\u304c\u5909\u63db\u3057\u305fimage\u3092return\n    if label is None:\n        return image\n    else:\n        return image, label\n\n# augment\u306e\u5b9a\u7fa9\ndef data_augment(image, label=None):\n#     \u30e9\u30f3\u30c0\u30e0\u306b\u6c34\u5e73\u65b9\u5411\u306b\u53cd\u8ee2\n    image = tf.image.random_flip_left_right(image)\n#     \u30e9\u30f3\u30c0\u30e0\u306b\u5782\u76f4\u65b9\u5411\u306b\u53cd\u8ee2\n    image = tf.image.random_flip_up_down(image)\n    \n#     image\u3092return\n    if label is None:\n        return image\n    else:\n        return image, label","096328be":"# \u6559\u5e2b\u30c7\u30fc\u30bf\u3092\u30c7\u30b3\u30fc\u30c9\ntrain_dataset = (\n#     TFR\u5f62\u5f0f\u3067\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u66f8\u304d\u3059\u308b\n    tf.data.TFRecordDataset\n#     \u914d\u5217\u3092\u30b9\u30e9\u30a4\u30b9\u3057\u3066\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u69cb\u7bc9\u3059\u308b\n    .from_tensor_slices((train_path, train_label))\n#     \u30c7\u30fc\u30bf\u5909\u63db\uff08\u30c7\u30b3\u30fc\u30c9\uff09\u3092\u4e26\u5217\u5316\u3057\u3066\u884c\u3046\n    .map(decode_image, num_parallel_calls=AUTO)\n#     \u30c7\u30fc\u30bf\u5909\u63db\uff08\u5897\u5e45\uff09\u3092\u4e26\u5217\u5316\u3059\u308b\n    .map(data_augment, num_parallel_calls=AUTO)\n#     \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u30e1\u30e2\u30ea\u304b\u30ed\u30fc\u30ab\u30b9\u30b9\u30c8\u30ec\u30fc\u30b8\u306b\u30ad\u30e3\u30c3\u30b7\u30e5\u3067\u304d\u308b\n    .cache()\n#     \u7e70\u308a\u8fd4\u3057\u3002shuffle\u306e\u524d\u306b\u3042\u308c\u3070EPOCH\u306e\u5883\u754c\u3092\u8d8a\u3048\u3066\u8981\u7d20\u304c\u30b7\u30e3\u30c3\u30d5\u30eb\u3055\u308c\u306a\u3044\n    .repeat()\n#     \u30b7\u30e3\u30c3\u30d5\u30eb\u30d0\u30c3\u30d5\u30a1\u306e\u30b5\u30a4\u30ba\u306f\u5927\u304d\u3044\u307b\u3069\u5b8c\u5168\u306b\u30b7\u30e3\u30c3\u30d5\u30eb\u3055\u308c\u308b\u3002\u203b\u30e9\u30f3\u30c0\u30e0\u8981\u7d20\n    .shuffle(1024)\n#     \u30d0\u30c3\u30c1\u5316\n    .batch(BATCH_SIZE)\n#     CPU\u3068TPU\u3067\u305d\u308c\u305e\u308c\u4e26\u5217\u306b\u51e6\u7406\u3092\u5b9f\u884c\n    .prefetch(AUTO)\n)\n\n# valid_dataset = (\n#     tf.data.TFRecordDataset\n#     .from_tensor_slices((valid_path, valid_label))\n#     .map(decode_image, num_parallel_calls=AUTO)\n#     .map(data_augment, num_parallel_calls=AUTO)\n#     .cache()\n#     .batch(BATCH_SIZE)\n#     .prefetch(AUTO)\n# )\n\n# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u30c7\u30b3\u30fc\u30c9\ntest_dataset = (\n    tf.data.TFRecordDataset\n    .from_tensor_slices(test_path)\n    .map(decode_image, num_parallel_calls=AUTO)\n    .map(data_augment, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n)","b68f8db5":"EPOCHS = 40\nLR_START = 0.0001\nLR_MAX = 0.00005 * strategy.num_replicas_in_sync\nLR_MIN = 0.0001\nLR_RAMPUP_EPOCHS = 10\nLR_SUSTAIN_EPOCHS = 4\nLR_EXP_DECAY = .8\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) \/ LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n    return lr\n\nlr = tf.keras.callbacks.LearningRateScheduler(lrfn)\n\ny = [lrfn(x) for x in range(EPOCHS)]\nplt.plot(y)","5e2217d7":"# EfficientNet\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n!pip install -q efficientnet","ea5fdb21":"# # EfficientNetB7\u306e\u8aad\u307f\u8fbc\u307f\n# from efficientnet.tfkeras import EfficientNetB7\n\n# # model\u306e\u4f5c\u6210\u306fstrategy.scope\u4e0b\u3067\u884c\u3046\n# with strategy.scope():\n# #     \u5168\u7d50\u5408\u5c64\u3092\u542b\u3081\u306a\u3044\/noisy-student\u3067self training\/average pooling\/\u753b\u50cf\u30b5\u30a4\u30ba\u3068RGB\n#     efn7 = EfficientNetB7(include_top=False, weights='noisy-student', pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n# #     Sequential\u30e2\u30c7\u30eb\u3092\u4f5c\u6210\u3001\u5f8c\u308d\u306b\u5c64\u3092\u8ffd\u52a0\n#     model_efn7 = Sequential()\n# #     EfficientNet\u5c64\u3092Model\u306b\u8ffd\u52a0\n#     model_efn7.add(efn7)\n# #     \u3053\u3061\u3089\u3067\u5168\u7d50\u5408\u5c64\u3092\u8ffd\u52a0\u30014\u5024\u5206\u985e\u3001\u5206\u985e\u554f\u984c\u306e\u305f\u3081\u6d3b\u6027\u5316\u95a2\u6570\u306fsoftmax\n#     model_efn7.add(L.Dense(4, activation='softmax'))\n# #     model\u304c\u3069\u306e\u3088\u3046\u306b\u5b66\u7fd2\u3059\u308b\u304b\u3092\u6c7a\u3081\u308b\n# #     \u6700\u9069\u5316\u95a2\u6570adam\/\u640d\u5931\u95a2\u6570\u306f\u591a\u30af\u30e9\u30b9\u5206\u985e\u306e\u305f\u3081\u30af\u30ed\u30b9\u30a8\u30f3\u30c8\u30ed\u30d4\u30fc\/\u8a55\u4fa1\u95a2\u6570\u306f\u6b63\u89e3\u7387\uff08\u5b66\u7fd2\u306b\u306f\u5f71\u97ff\u3057\u306a\u3044\uff09\n#     model_efn7.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_efn7.summary())","80409af8":"# from efficientnet.tfkeras import EfficientNetB6\n\n# with strategy.scope():\n#     efn6 = EfficientNetB6(include_top=False, weights='noisy-student', pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_efn6 = Sequential()\n#     model_efn6.add(efn6)\n#     model_efn6.add(L.Dense(4, activation='softmax'))\n#     model_efn6.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_efn6.summary())","f7ccf4df":"# from efficientnet.tfkeras import EfficientNetB5\n\n# with strategy.scope():\n#     efn5 = EfficientNetB5(include_top=False, weights='noisy-student', pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_efn5 = Sequential()\n#     model_efn5.add(efn5)\n#     model_efn5.add(L.Dense(4, activation='softmax'))\n#     model_efn5.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_efn5.summary())","0f1c1e72":"# from efficientnet.tfkeras import EfficientNetB4\n\n# with strategy.scope():\n#     efn4 = EfficientNetB4(include_top=False, weights='noisy-student', pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_efn4 = Sequential()\n#     model_efn4.add(efn4)\n#     model_efn4.add(L.Dense(4, activation='softmax'))\n#     model_efn4.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_efn4.summary())","bae71251":"from efficientnet.tfkeras import EfficientNetB3\n\nwith strategy.scope():\n    efn3 = EfficientNetB3(include_top=False, weights='noisy-student', pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n    model_efn3 = Sequential()\n    model_efn3.add(efn3)\n    model_efn3.add(L.Dense(4, activation='softmax'))\n    model_efn3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    print(model_efn3.summary())","b46221aa":"from efficientnet.tfkeras import EfficientNetB2\n\nwith strategy.scope():\n    efn2 = EfficientNetB2(include_top=False, weights='noisy-student', pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n    model_efn2 = Sequential()\n    model_efn2.add(efn2)\n    model_efn2.add(L.Dense(4, activation='softmax'))\n    model_efn2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    print(model_efn2.summary())","8953b8b4":"from efficientnet.tfkeras import EfficientNetB1\n\nwith strategy.scope():\n    efn1 = EfficientNetB1(include_top=False, weights='noisy-student', pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n    model_efn1 = Sequential()\n    model_efn1.add(efn1)\n    model_efn1.add(L.Dense(4, activation='softmax'))\n    model_efn1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    print(model_efn1.summary())","163d140e":"# from tensorflow.keras.applications import DenseNet121\n\n# with strategy.scope():\n#     dnn121 = DenseNet121(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_dnn121 = Sequential()\n#     model_dnn121.add(dnn121)\n#     model_dnn121.add(L.GlobalAveragePooling2D())\n#     model_dnn121.add(L.Dense(4, activation='softmax'))\n#     model_dnn121.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_dnn121.summary())","db18503f":"# from tensorflow.keras.applications import DenseNet169\n\n# with strategy.scope():\n#     dnn169 = DenseNet169(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_dnn169 = Sequential()\n#     model_dnn169.add(dnn169)\n#     model_dnn169.add(L.GlobalAveragePooling2D())\n#     model_dnn169.add(L.Dense(4, activation='softmax'))\n#     model_dnn169.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_dnn169.summary())","150b6025":"# from tensorflow.keras.applications import DenseNet201\n\n# with strategy.scope():\n#     dnn201 = DenseNet201(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_dnn201 = Sequential()\n#     model_dnn201.add(dnn201)\n#     model_dnn201.add(L.GlobalAveragePooling2D())\n#     model_dnn201.add(L.Dense(4, activation='softmax'))\n#     model_dnn201.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_dnn201.summary())","c933e0cd":"# # Epoch\u7d42\u4e86\u5f8c\u306e\u5404\u6570\u5024\u3092\u76e3\u8996\u3057\u3066\u6761\u4ef6\u304c\u63c3\u3063\u305f\u5834\u5408\u30e2\u30c7\u30eb\u3092\u4fdd\u5b58\u3059\u308b\n# # \u91cd\u307f\u306e\u30d5\u30a1\u30a4\u30eb\u540d\/\u76e3\u8996\u3059\u308b\u5024\/\u5224\u5b9a\u7d50\u679c\u304b\u3089\u4fdd\u5b58\u3092\u6c7a\u5b9a\/\u30e2\u30c7\u30eb\u306e\u91cd\u307f\u3092\u4fdd\u5b58\n# mc_efn7 = tf.keras.callbacks.ModelCheckpoint('weights_efn7.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# # \u8a13\u7df4\u306e\u5c65\u6b74\u306e\u53ef\u8996\u5316\n# history = model_efn7.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_efn7], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","6a65f198":"# mc_efn6 = tf.keras.callbacks.ModelCheckpoint('weights_efn6.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_efn6.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_efn6], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","5d8a09c4":"# mc_efn5 = tf.keras.callbacks.ModelCheckpoint('weights_efn5.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_efn5.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_efn5], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","17d8e283":"# mc_efn4 = tf.keras.callbacks.ModelCheckpoint('weights_efn4.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_efn4.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_efn4], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","f69a4d0e":"mc_efn3 = tf.keras.callbacks.ModelCheckpoint('weights_efn3.h5', monitor='loss', save_best_only=True, save_weights_only=True)\nhistory = model_efn3.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_efn3], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","1b4872fc":"mc_efn2 = tf.keras.callbacks.ModelCheckpoint('weights_efn2.h5', monitor='loss', save_best_only=True, save_weights_only=True)\nhistory = model_efn2.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_efn2], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","8c67713a":"mc_efn1 = tf.keras.callbacks.ModelCheckpoint('weights_efn1.h5', monitor='loss', save_best_only=True, save_weights_only=True)\nhistory = model_efn1.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_efn1], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","1234e893":"# mc_dnn121 = tf.keras.callbacks.ModelCheckpoint('weights_dnn121.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_dnn121.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_dnn121], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","6beebc90":"# mc_dnn169 = tf.keras.callbacks.ModelCheckpoint('weights_dnn169.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_dnn169.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_dnn169], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","548f565b":"# mc_dnn201 = tf.keras.callbacks.ModelCheckpoint('weights_dnn201.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_dnn201.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_dnn201], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","d2955bfe":"with strategy.scope():\n#     \u3042\u3089\u304b\u3058\u3081\u4fdd\u5b58\u3057\u3066\u304a\u3044\u305fweight\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u30ed\u30fc\u30c9\n#     model_efn7.load_weights('weights_efn7.h5')\n#     model_efn6.load_weights('weights_efn6.h5')\n#     model_efn5.load_weights('weights_efn5.h5')\n#     model_efn4.load_weights('weights_efn4.h5')\n    model_efn3.load_weights('weights_efn3.h5')\n    model_efn2.load_weights('weights_efn2.h5')\n    model_efn1.load_weights('weights_efn1.h5')\n#     model_dnn121.load_weights('weights_dnn121.h5')\n#     model_dnn169.load_weights('weights_dnn169.h5')\n#     model_dnn201.load_weights('weights_dnn201.h5')\n# valid_prob = model.predict(valid_dataset, verbose=1)\n# print(metrics.classification_report(np.argmax(valid_label, axis=1), np.argmax(valid_prob, axis=1)))\n# print(metrics.confusion_matrix(np.argmax(valid_label, axis=1), np.argmax(valid_prob, axis=1)))","ecf23645":"# # test\u30c7\u30fc\u30bf\u3067\u306e\u4e88\u6e2c\/log\u306e\u51fa\u529bverbose\n# probs_efn7 = model_efn7.predict(test_dataset, verbose=1)\n# # probs\u306e\u5024\u3092sumple_submission\u306e\u5217healthy,multiple_diseases,rust,scab\u306b\u3042\u3066\u306f\u3081\n# sub_efn7 = sub\n# sub_efn7.loc[:, 'healthy':] = probs_efn7\n# # CSV\u30d5\u30a1\u30a4\u30eb\u306b\u66f8\u304d\u51fa\u3057\n# sub_efn7.to_csv('submission_efn7.csv', index=False)\n# # \u8868\u793a\n# sub_efn7.head()","9659937d":"# probs_efn6 = model_efn6.predict(test_dataset, verbose=1)\n# sub_efn6 = sub\n# sub_efn6.loc[:, 'healthy':] = probs_efn6\n# sub_efn6.to_csv('submission_efn6.csv', index=False)\n# sub_efn6.head()","e1b54146":"# probs_efn5 = model_efn5.predict(test_dataset, verbose=1)\n# sub_efn5 = sub\n# sub_efn5.loc[:, 'healthy':] = probs_efn5\n# sub_efn5.to_csv('submission_efn5.csv', index=False)\n# sub_efn5.head()","0080faed":"# probs_efn4 = model_efn4.predict(test_dataset, verbose=1)\n# sub_efn4 = sub\n# sub_efn4.loc[:, 'healthy':] = probs_efn4\n# sub_efn4.to_csv('submission_efn4.csv', index=False)\n# sub_efn4.head()","389c3a22":"probs_efn3 = model_efn3.predict(test_dataset, verbose=1)\nsub_efn3 = sub\nsub_efn3.loc[:, 'healthy':] = probs_efn3\nsub_efn3.to_csv('submission_efn3.csv', index=False)\nsub_efn3.head()","5f953f01":"probs_efn2 = model_efn2.predict(test_dataset, verbose=1)\nsub_efn2 = sub\nsub_efn2.loc[:, 'healthy':] = probs_efn2\nsub_efn2.to_csv('submission_efn2.csv', index=False)\nsub_efn2.head()","ede346f1":"probs_efn1 = model_efn1.predict(test_dataset, verbose=1)\nsub_efn1 = sub\nsub_efn1.loc[:, 'healthy':] = probs_efn1\nsub_efn1.to_csv('submission_efn1.csv', index=False)\nsub_efn1.head()","802041a1":"# probs_dnn121 = model_dnn121.predict(test_dataset, verbose=1)\n# sub_dnn121 = sub\n# sub_dnn121.loc[:, 'healthy':] = probs_dnn121\n# sub_dnn121.to_csv('submission_dnn121.csv', index=False)\n# sub_dnn121.head()","0afa1e8a":"# probs_dnn169 = model_dnn169.predict(test_dataset, verbose=1)\n# sub_dnn169 = sub\n# sub_dnn169.loc[:, 'healthy':] = probs_dnn169\n# sub_dnn169.to_csv('submission_dnn169.csv', index=False)\n# sub_dnn169.head()","a283193a":"# probs_dnn201 = model_dnn201.predict(test_dataset, verbose=1)\n# sub_dnn201 = sub\n# sub_dnn201.loc[:, 'healthy':] = probs_dnn201\n# sub_dnn201.to_csv('submission_dnn201.csv', index=False)\n# sub_dnn201.head()","36b5939b":"# Decode images","eef9dd51":"# Import Libraries","a465f056":"# Predict","0ad21517":"# Define the parameters","faf58f2c":"# EfficientNet B7-B1","6e85f4c5":"# TPU setup","61c7e8da":"# Get class weights","a0c25bf3":"# Model","f9f45b99":"# Get train and test data","6e69b1a7":"# DenseNet 121\/169\/201","63150c71":"# Lets see some images"}}