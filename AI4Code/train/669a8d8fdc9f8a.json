{"cell_type":{"27840381":"code","1dead91a":"code","727c79ca":"code","1964c044":"code","d24b6f90":"code","0d1f063c":"code","8734b306":"code","7c2715e7":"code","8c591e0b":"code","8bf17e12":"code","477eeef7":"code","5ef7e5c0":"code","b3bd1ab3":"code","ce695e5a":"markdown","5f9dbaeb":"markdown","272b2c1f":"markdown","7df0a28a":"markdown","fbd723ef":"markdown","ec48c5cb":"markdown","95acebd3":"markdown","19fcdbf7":"markdown","3c6621d9":"markdown","4539ac41":"markdown","5ceabe0d":"markdown"},"source":{"27840381":"from pathlib import Path\nfrom skimage.io import imread\nfrom skimage.transform import resize\nfrom skimage.color import rgb2gray\nfrom os import listdir\nfrom random import randint\nfrom sklearn.model_selection import train_test_split\nfrom time import time\nfrom copy import deepcopy\nfrom torch import nn\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt","1dead91a":"def load_dir(dir):\n    images = []\n    masks = []\n    for subdir in listdir(dir):\n        for file in listdir(f\"{dir}\/{subdir}\"):\n            if file.endswith(\".png\") and \"mask\" not in file:\n                image = imread(f\"{dir}\/{subdir}\/{file}\")\n                image = resize(image, output_shape=(128, 128))\n                image = rgb2gray(image)\n                \n                filename = file.split(\".\")[0]\n                files_list = list(Path(f\"{dir}\/{subdir}\").rglob(f\"{filename}*\"))\n                masks_list = [f for f in files_list if \"mask\" in str(f)]\n\n                if len(masks_list) == 1:\n                        mask_file = masks_list[0]\n                        mask = imread(f\"{mask_file}\")\n                        mask = resize(mask, output_shape=(128, 128))\n                        mask = rgb2gray(mask)\n                                                \n                        images.append(image)\n                        masks.append(mask)\n                        \n                else:\n                    continue\n\n                \n    return np.array(images), np.array(masks)\n   ","727c79ca":"path = Path.cwd().parent\ndata_path = path \/ 'input' \/ 'breast-ultrasound-images-dataset' \/ 'Dataset_BUSI_with_GT'\nimages, masks = load_dir(data_path)\nprint(f\"Images shape: {images.shape}\",\n      f\"Masks shape: {masks.shape}\\n\")","1964c044":"def flip(images, labels, axis):\n    flipped_images = np.flip(images, axis)\n    flipped_labels = np.flip(labels, axis)\n    return flipped_images, flipped_labels\n\ndef augmentation(images, labels):\n    # Data augmentation (flip_horizontal)\n    flipped_y_images, flipped_y_labels = flip(images, labels, axis=2)\n\n    # Concatenate arrays\n    images = np.concatenate([images, flipped_y_images])\n    labels = np.concatenate([labels, flipped_y_labels])\n\n    # Data augmentation (flip_horizontal)\n    flipped_x_images, flipped_x_labels = flip(images, labels, axis=1)\n\n    # Concatenate arrays\n    images = np.concatenate([images, flipped_x_images])\n    labels = np.concatenate([labels, flipped_x_labels])\n\n\n    return images, labels\n\nimages, masks = augmentation(images, masks)\nprint(f\"Images shape: {images.shape}\",\n      f\"Masks shape: {masks.shape}\\n\")","d24b6f90":"f, axis = plt.subplots(nrows=4, ncols=2, constrained_layout=True, figsize=(10, 10))\nfor i in range(4):\n    rand = randint(0, images.shape[0]-1)\n    axis[i, 0].imshow(images[rand], cmap=\"gray\")\n    axis[i, 1].imshow(masks[rand], cmap=\"gray\")\nplt.show()","0d1f063c":"images = np.expand_dims(images, axis=3)\nmasks = np.expand_dims(masks, axis=3)\n\n\nx_train, x_val, y_train, y_val = train_test_split(images, masks,\n                                                  test_size= 0.1,\n                                                  shuffle=True,\n                                                  random_state=2021)\n\nx_test, x_val, y_test, y_val = train_test_split(x_val, y_val,\n                                                test_size=0.5,\n                                                shuffle=True,\n                                                random_state=2021)\n\nprint(f\"Train arrays shape: {x_train.shape}, {y_train.shape}\")\nprint(f\"Test arrays shape: {x_test.shape}, {y_test.shape}\")\nprint(f\"Validation arrays shape: {x_val.shape}, {y_val.shape}\")","8734b306":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nimages_format = torch.float32\nmasks_format = torch.float32\n\n# Free memory\ndel images, masks\n\n# Convert Numpy arrays to Torch tensors\ntrain_inputs = torch.from_numpy(x_train).to(images_format).to(device)\ntrain_outputs = torch.from_numpy(y_train).to(masks_format).to(device)\ndel x_train, y_train\n\nval_inputs = torch.from_numpy(x_val).to(images_format).to(device)\nval_outputs = torch.from_numpy(y_val).to(masks_format).to(device)\ndel x_val, y_val\n\ntest_inputs = torch.from_numpy(x_test).to(images_format).to(device)\ntest_outputs = torch.from_numpy(y_test).to(masks_format).to(device)\ndel x_test, y_test\n\ntrain_inputs = train_inputs.permute(0, 3, 1, 2)\nval_inputs = val_inputs.permute(0, 3, 1, 2)\ntest_inputs = test_inputs.permute(0, 3, 1, 2)\n\ntrain_outputs = train_outputs.permute(0, 3, 1, 2)\nval_outputs = val_outputs.permute(0, 3, 1, 2)\ntest_outputs = test_outputs.permute(0, 3, 1, 2)\n\n\n\n# Verify datasets shapes\nprint(f\"Train tensor shape: {train_inputs.shape}, {train_outputs.shape}\")\nprint(f\"Test tensor shape: {test_inputs.shape}, {test_outputs.shape}\")\nprint(f\"Validation tensor shape: {val_inputs.shape}, {val_outputs.shape}\")","7c2715e7":"class double_conv(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super(double_conv, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        x = self.conv(x)\n        return x\n\n\nclass up(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super(up, self).__init__()\n        self.up_scale = nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2)\n\n    def forward(self, x1, x2):\n        x2 = self.up_scale(x2)\n\n        diffY = x1.size()[2] - x2.size()[2]\n        diffX = x1.size()[3] - x2.size()[3]\n\n        x2 = F.pad(x2, [diffX \/\/ 2, diffX - diffX \/\/ 2,\n                        diffY \/\/ 2, diffY - diffY \/\/ 2])\n        x = torch.cat([x2, x1], dim=1)\n        return x\n\n\nclass down_layer(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super(down_layer, self).__init__()\n        self.pool = nn.AvgPool2d(2, stride=2, padding=0)\n        self.conv = double_conv(in_ch, out_ch)\n\n    def forward(self, x):\n        x = self.conv(self.pool(x))\n        return x\n\n\nclass up_layer(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super(up_layer, self).__init__()\n        self.up = up(in_ch, out_ch)\n        self.conv = double_conv(in_ch, out_ch)\n\n    def forward(self, x1, x2):\n        a = self.up(x1, x2)\n        x = self.conv(a)\n        return x\n\n\nclass UNet(nn.Module):\n    def __init__(self):\n        super(UNet, self).__init__()\n        self.conv1 = double_conv(1, 8)\n        self.down1 = down_layer(8, 16)\n        self.down2 = down_layer(16, 32)\n        self.down3 = down_layer(32, 64)\n        self.down4 = down_layer(64, 128)\n        self.down5 = down_layer(128, 256)\n        self.down6 = down_layer(256, 512)\n        self.down7 = down_layer(512, 1024)\n        \n        self.up1 = up_layer(1024, 512)\n        self.up2 = up_layer(512, 256)\n        self.up3 = up_layer(256, 128)\n        self.up4 = up_layer(128, 64)\n        self.up5 = up_layer(64, 32)\n        self.up6 = up_layer(32, 16)\n        self.up7 = up_layer(16, 8)\n        self.last_conv = nn.Conv2d(8, 1, 1)\n        self.dilute = nn.Conv2d(1, 1, 1)\n\n\n    def forward(self, x):\n        x1 = self.conv1(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4)\n        x6 = self.down5(x5)\n        x7 = self.down6(x6)\n        x8 = self.down7(x7)\n        \n        x1_up = self.up1(x7, x8)\n        x2_up = self.up2(x6, x1_up)\n        x3_up = self.up3(x5, x2_up)\n        x4_up = self.up4(x4, x3_up)\n        x5_up = self.up5(x3, x4_up)\n        x6_up = self.up6(x2, x5_up)\n        x7_up = self.up7(x1, x6_up)\n    \n        output = self.last_conv(x7_up)\n        output = self.dilute(output)\n        output = torch.sigmoid(output)\n        return output","8c591e0b":"class DiceLoss(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(DiceLoss, self).__init__()\n\n    def forward(self, inputs, targets, smooth=1):    \n        \n        #flatten label and prediction tensors\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n        \n        intersection = (inputs * targets).sum()                            \n        dice = (2.*intersection + smooth)\/(inputs.sum() + targets.sum() + smooth)  \n        \n        return 1 - dice\n\n    \nnet = UNet().to(device)\noptim = torch.optim.Adam(net.parameters(), lr=1.0E-3)\ncriterion = DiceLoss()","8bf17e12":"best_loss = np.inf\nepochs = 200\npatience = 5\nbatch_size = 20\ntrain_losses = []\nval_losses = []\nachieved_epochs = []\ntotal_train = train_inputs.size()[0]\ntotal_val = val_inputs.size()[0]\nprint(\"Train loop:\\n\")\n\nt0 = time()\nfor epoch in range(epochs):\n    net.train()\n    train_loss = 0\n    val_loss = 0\n    achieved_epochs.append(epoch)\n    train_permutation = torch.randperm(total_train)\n    val_permutation = torch.randperm(total_val)\n\n    for i in range(0, total_train, batch_size):\n        optim.zero_grad()\n        indices = train_permutation[i:i+batch_size]\n        batch_x, batch_y = train_inputs[indices], train_outputs[indices]\n        outputs = net(batch_x)\n        loss = criterion(outputs, batch_y)\n        loss.backward()\n        optim.step()\n        train_loss += loss\n    train_loss = train_loss.cpu().detach() \/ total_train\n    train_losses.append(train_loss)\n\n    for j in range(0, total_val, batch_size):\n        net.eval()\n        indices = val_permutation[j:j+batch_size]\n        batch_x, batch_y = val_inputs[indices], val_outputs[indices]\n        outputs = net(batch_x)\n        loss = criterion(outputs, batch_y)\n        \n        val_loss += loss\n    val_loss = val_loss.cpu().detach() \/ total_val\n    val_losses.append(val_loss)\n\n    if val_loss < best_loss:\n        best_loss = val_loss\n        cost_patience = patience\n        state_dict = deepcopy(net.state_dict())\n        print(f\"\\tEpoch: {epoch+1}\/{epochs}, \",\n              f\"Train Loss: {train_loss:.3g}, \",\n              f\"Val Loss: {val_loss:.3g}\")\n\n    else:\n        cost_patience -= 1\n        if cost_patience < 0:\n            print(f\"\\nEarly stopping after {patience} epochs of no improvements\")\n            break\n\n        else:\n            print(f\"\\tEpoch: {epoch+1}\/{epochs}, \",\n                  f\"Train Loss: {train_loss:.3g}, \",\n                  f\"Val Loss: {val_loss:.3g} - No improvement\",\n                  f\"-> Remaining patience: {cost_patience}\")\n\ntf = time()\nprint(f\"\\nTrain finished successfully in {tf-t0:.3g}s\")","477eeef7":"f, ax = plt.subplots()\nax.plot(achieved_epochs, train_losses, label='train')\nax.plot(achieved_epochs, val_losses, label='validation')\nax.set_title('model loss')\nax.set_ylabel('loss')\nax.set_xlabel('epoch')\nno_improvement_line = achieved_epochs[-1] - patience\nax.axvline(x=no_improvement_line, color='r')\nax.legend(loc='upper center', frameon=False)\nplt.show()","5ef7e5c0":"torch.save(state_dict, \".\/checkpoint.pth\")\nprint(\"\\nCheckpoint saved successfully :)\")","b3bd1ab3":"predictions = net(test_inputs).cpu().detach().numpy()\nimages = test_inputs.cpu().detach().numpy()\nmasks = test_outputs.cpu().detach().numpy()\n\nf, axis = plt.subplots(nrows=4, ncols=3, constrained_layout=True, figsize=(10, 10))\nfor i in range(4):\n    rand = randint(0, images.shape[0]-1)\n    axis[i, 0].imshow(images[rand][0], cmap=\"gray\")\n    axis[i, 0].set_title(\"image\")\n    axis[i, 1].imshow(masks[rand][0], cmap=\"gray\")\n    axis[i, 1].set_title(\"target\")\n    axis[i, 2].imshow(predictions[rand][0], cmap=\"gray\")\n    axis[i, 2].set_title(\"pred\")\n\nplt.show()","ce695e5a":"## Split Dataset","5f9dbaeb":"## Initialize Model","272b2c1f":"## Librairies","7df0a28a":"## Predictions","fbd723ef":"## Transfer Data to GPU","ec48c5cb":"## Load Data","95acebd3":"# Semantic segmentation","19fcdbf7":"## Network","3c6621d9":"## Trainning","4539ac41":"## Data augmentation","5ceabe0d":"## Data visualization"}}