{"cell_type":{"4c160770":"code","f70f54ed":"code","0377b63c":"code","7e033a51":"code","25928c5c":"code","655cb4bc":"code","911fb71e":"code","237d7683":"code","6d813130":"code","b38f7029":"code","3a4f03b6":"code","fb558f68":"code","ddc6d5de":"code","9786bb88":"code","4927de3f":"code","c6d2ed63":"code","f8aefb36":"code","e4652372":"code","27c8f9ff":"code","d91f45fc":"code","b0c6e9f1":"code","a899abc7":"code","512d0133":"code","144aefb4":"markdown","07be539c":"markdown"},"source":{"4c160770":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f70f54ed":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import RobustScaler , StandardScaler\n","0377b63c":"df_train=pd.read_csv('..\/input\/song-popularity-prediction\/train.csv')\ndf_train","7e033a51":"df_test=pd.read_csv('..\/input\/song-popularity-prediction\/test.csv')\ndf_test","25928c5c":"df_test.info()","655cb4bc":"cols=df_unified.columns\nnan_cols=[]\nfor column in cols:\n    if df_train[column].isnull().sum()!=0:\n        nan_cols.append(column)","911fb71e":"for column in nan_cols:\n    df_train[column]=df_train[column].fillna(df_train[column].median())\n    df_test[column]=df_test[column].fillna(df_train[column].median())","237d7683":"plt.figure(figsize=(100,120))\ni=1;\nfor column in cols:\n    plt.subplot(5,3,i)\n    sns.boxplot(df_train[column],data=df_unified)\n    plt.title(column)\n    i=i+1","6d813130":"\n# q3=np.quantile(df_unified['energy'],0.75)\n# q1=np.quantile(df_unified['energy'],0.25)\n# iqr=q3-q1\n# upper_limit=q3+1.5*iqr\n# lower_limit=q1-1.5*iqr\n# ctr=0\n\n# for i in range(df_unified.shape[0]):\n#     if (df_unified['energy'].values)[i]>upper_limit:\n        \n#         (df_unified['energy'].values)[i]=upper_limit\n\n#     elif (df_unified['energy'].values)[i]<lower_limit:\n        \n#         (df_unified['energy'].values)[i]=lower_limit\n#     else:\n        \n#         (df_unified['energy'].values)[i]=(df_unified['energy'].values)[i]\n","b38f7029":"\n# q3=np.quantile(df_unified['acousticness'],0.75)\n# q1=np.quantile(df_unified['acousticness'],0.25)\n# iqr=q3-q1\n# upper_limit=q3+1.5*iqr\n# lower_limit=q1-1.5*iqr\n\n# for i in range(df_unified.shape[0]):\n#     if (df_unified['acousticness'].values)[i]>upper_limit:\n#         (df_unified['acousticness'].values)[i]=upper_limit\n#     elif (df_unified['acousticness'].values)[i]<lower_limit:\n#         (df_unified['acousticness'].values)[i]=lower_limit\n#     else:\n#         (df_unified['acousticness'].values)[i]=(df_unified['acousticness'].values)[i]\n","3a4f03b6":"# #Selecting numerical columns and scaling them\n# num_cols = list(df_unified.select_dtypes('float64').columns)\n# from sklearn.preprocessing import StandardScaler\n# for column in num_cols:\n#     sc = StandardScaler()\n#     df_unified[column]=sc.fit_transform(df_unified[column].values.reshape(-1,1))","fb558f68":"from sklearn.preprocessing import PowerTransformer\nskew_cols=['acousticness','instrumentalness','loudness','speechiness']\nfor column in skew_cols:\n    pt = PowerTransformer(method='yeo-johnson')\n    df_train[column]=pt.fit_transform(df_train[column].values.reshape(-1,1))","ddc6d5de":"df_train['song_popularity'].value_counts()","9786bb88":"from sklearn.model_selection import KFold\n#insert the kfold columns\ndf_train['fold'] = -1\n\n#distributing the data\nkfold = KFold(n_splits = 5,shuffle=True,random_state = 42)\nfor fold, (tr_i,va_i) in enumerate(kfold.split(X=df_train)):\n    df_train.loc[va_i,'fold'] = fold","4927de3f":"features = [f for f in df_train.columns if f not in(\"id\",\"fold\",\"song_popularity\")]\ndf_test = df_test[features]","c6d2ed63":"import lightgbm as lgb","f8aefb36":"    params_lgb = {\n    \"task\": \"train\",\n    \"boosting_type\": \"gbdt\",\n    \"objective\": \"binary\",\n    'subsample': 0.95312,\n    'learning_rate': 0.001635,\n    \"max_depth\": 3,\n    \"feature_fraction\": 0.2256038826485174,\n    \"bagging_fraction\": 0.7705303688019942,\n    \"min_child_samples\": 290,\n    \"reg_alpha\": 14.68267919457715,\n    \"reg_lambda\": 66.156,\n    \"max_bin\": 772,\n    \"min_data_per_group\": 177,\n    \"bagging_freq\": 1,\n    \"cat_smooth\": 96,\n    \"cat_l2\": 17,\n    \"verbosity\": -1,\n    'random_state':42,\n    'n_estimators':5000,\n    'colsample_bytree':0.1107\n    }\n    \n#     lgb_train = lgb.Dataset(x_train, y_train)\n#     lgb_val = lgb.Dataset(x_test, y_test)\n    \n#     model = lgb.train(params=params_lgb,\n#                       train_set=lgb_train,\n#                       valid_sets=lgb_val,\n#                       early_stopping_rounds=300,\n#                       verbose_eval=False)\n    ","e4652372":"final_pred = []\n\n\nfor fold in range(5):\n    train = df_train[df_train[\"fold\"] != fold].reset_index(drop = True)\n    test = df_train[df_train[\"fold\"] == fold].reset_index(drop = True)\n    x_final_test = df_test.copy()\n    \n    y_train = train[\"song_popularity\"]\n    y_test = test[\"song_popularity\"]\n    \n    rl = RobustScaler()\n    x_train = rl.fit_transform(train[features])\n    x_test = rl.transform(test[features])\n    x_final_test = rl.transform(x_final_test[features])\n    \n#     pt = PowerTransformer(method='yeo-johnson')\n#     x_train =pt.fit_transform(train[skew_cols])\n#     x_test = pt.transform(test[skew_cols])\n#     x_final_test = rl.transform(x_final_test[skew_cols])\n    \n    \n    lgb_train = lgb.Dataset(x_train, y_train)\n    lgb_test = lgb.Dataset(x_test, y_test)\n    \n    model = lgb.train(params = params_lgb,\n                     train_set = lgb_train,\n                     valid_sets = lgb_test,\n                     early_stopping_rounds = 300,\n                     verbose_eval = False)\n    \n    pred = model.predict(x_test, num_iteration=model.best_iteration)\n    acc = roc_auc_score(y_test, pred)\n    print(\"Fold {} ROC {}\".format(fold + 1, acc))\n    test_pred = model.predict(x_final_test, num_iteration=model.best_iteration)\n    final_pred.append(test_pred)\nprint(\"\\n\")","27c8f9ff":"preds = np.mean(np.stack(final_pred), axis = 0)","d91f45fc":"df_sub = pd.read_csv('..\/input\/song-popularity-prediction\/sample_submission.csv')","b0c6e9f1":"df_test['song_popularity'] = -1\ndf_test['song_popularity']= preds\ndf_test['id']=0\ndf_test['id'] = df_sub['id']\ndf_sub1 = df_test[['id','song_popularity']]\ndf_sub1","a899abc7":"# def binarizer(x):\n#     if x<0.5:\n#         return 0\n#     else:\n#         return 1\n# df_sub['song_popularity']=df_sub['song_popularity'].apply(binarizer)","512d0133":"df_sub1.to_csv('28_jan_folds.csv',index=False)","144aefb4":"# Preprocessing+EDA","07be539c":"# MODELLING"}}