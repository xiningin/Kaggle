{"cell_type":{"109bb34f":"code","87fd0588":"code","0b18392d":"code","b1847d85":"code","c122f06b":"code","7d2e894f":"code","5ec1abf0":"code","bb47dd5a":"code","5a30bd1e":"code","bb639400":"code","c8072b5b":"code","9397a926":"code","26c6fb67":"code","0ab1c994":"markdown","926afad5":"markdown","33284e13":"markdown","f13baf96":"markdown","ed08c596":"markdown","7e247211":"markdown","34f95acd":"markdown"},"source":{"109bb34f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","87fd0588":"data_train = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_train.csv\")\ndata_test=pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_test.csv\")\n\nprint(data_train.head())\n","0b18392d":"print(data_test.head())","b1847d85":"X_train_data = data_train.drop(\"label\",axis=1)\nY_train_data=data_train[\"label\"]\n\n\nX_test_data =data_test.drop(\"label\",axis=1)\nY_test_data = data_test[\"label\"]\n","c122f06b":"X_train_data= np.array(X_train_data)\nX_test_data= np.array(X_test_data)\n\n\nprint(\"X_train shape: \",X_train_data.shape)\nprint(\"X_test shape: \",X_test_data.shape)\n","7d2e894f":"X_test_data=X_test_data\/255.0\nX_train_data=X_train_data\/255.0","5ec1abf0":"X_train_data= X_train_data.reshape(-1, 28,28,1)\nX_test_data= X_test_data.reshape(-1, 28,28,1)\n","bb47dd5a":"from keras.utils import to_categorical\nY_train_data=to_categorical(Y_train_data,num_classes=len(set(Y_train_data)))\nY_test_data =to_categorical(Y_test_data,num_classes=len(set(Y_test_data)))","5a30bd1e":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\n\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu', input_shape = (28,28,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.20))\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Conv2D(filters = 16, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(10, activation = \"softmax\"))\nmodel.compile(optimizer = (\"Adam\") , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n","bb639400":"from sklearn.model_selection import train_test_split\nX_train, X_val, Y_train, Y_val = train_test_split(X_train_data, Y_train_data, test_size = 0.2, random_state=2)\n\nprint(\"x_train shape\",X_train.shape)\nprint(\"x_test shape\",X_val.shape)\nprint(\"y_train shape\",Y_train.shape)\nprint(\"y_test shape\",Y_val.shape)","c8072b5b":"epochs = 40 \nbatch_size = 128\n\nhistory= model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_val, Y_val))","9397a926":"score = model.evaluate(X_test_data, Y_test_data, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","26c6fb67":"import matplotlib.pyplot as plt\naccuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(accuracy))\nplt.plot(epochs, accuracy, 'g', label='Training accuracy')\nplt.plot(epochs, val_accuracy, 'r', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'g', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","0ab1c994":"# Converting Our Data to Numpy Array","926afad5":"# Reshape","33284e13":"# Read Data","f13baf96":"# Catogoricalizing The Y Variables","ed08c596":"# Model Create","7e247211":"# Normalization","34f95acd":"#  Splitting Test and Train Data Into X and Y"}}