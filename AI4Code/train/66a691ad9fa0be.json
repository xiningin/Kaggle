{"cell_type":{"5917d0d9":"code","d041ecd9":"code","2383522d":"code","79b01c32":"code","76079451":"code","94afd883":"code","db784973":"code","28281b90":"code","dd5d1a76":"code","98e913f3":"markdown","d6d6f484":"markdown","fbfb206b":"markdown","12d59a66":"markdown","104bd16d":"markdown","b00e6436":"markdown","eb3a96ca":"markdown","9e7eaea4":"markdown","353f9509":"markdown"},"source":{"5917d0d9":"# Global variables for testing changes to this notebook quickly\nTRAIN_SIZE = 300000\nNUM_FOLDS = 6\nRANDOM_SEED = 0","d041ecd9":"# Install Tensorflow Decision Forests\n!pip3 install -q tensorflow_decision_forests","2383522d":"# Essentials\nimport numpy as np\nimport pandas as pd\nimport warnings\nimport time\nimport gc\nimport os\n\n# Hide warnings\nwarnings.filterwarnings('ignore')\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n\n# Model selection and evaluation\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\n# Tensorflow\nimport tensorflow as tf\nimport tensorflow_decision_forests as tfdf\ntf.random.set_seed(RANDOM_SEED)","79b01c32":"def load_data(num_samples):\n    train = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/train.csv')\n    train, valid = train_test_split(\n        train, \n        train_size = num_samples,\n        random_state = RANDOM_SEED,\n        stratify = train['claim']\n    )\n    return train\n\ndef downcast(input_df):\n    data = input_df.copy()\n    for col, dtype in data.dtypes.iteritems():\n        if dtype.name.startswith('int'):\n            data[col] = pd.to_numeric(data[col], downcast ='integer')\n        elif dtype.name.startswith('float'):\n            data[col] = pd.to_numeric(data[col], downcast ='float')\n    return data","76079451":"%%time\n\n# Load subset of training data\ntrain = load_data(TRAIN_SIZE)\ntest = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/test.csv')\nsubmission = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv')\n\n# Drop irrel columns\ntrain.drop('id', axis = 'columns', inplace = True)\ntest.drop('id', axis = 'columns', inplace = True)\n\n# Create NaN features, get number of rows\ntrain[\"nan_count\"] = train.isnull().sum(axis=1)\ntest[\"nan_count\"] = test.isnull().sum(axis=1)\n\n# Downcast training and test data\ntrain = downcast(train)\ntest = downcast(test)\ngc.collect()\n\n# Get relevant features, load sample submission\nfeatures = [x for x in train.columns if x not in ['id','claim']]","94afd883":"def score_gradient_boosting():\n\n    # Vectors to store predictions\/scores\n    X_test = test[features].to_numpy()\n    test_preds = np.zeros((test.shape[0],))\n    oof_preds = np.zeros((train.shape[0],))\n    scores = np.zeros(NUM_FOLDS)\n    \n    # Stratified k-fold cross-validation\n    skf = StratifiedKFold(n_splits = NUM_FOLDS, shuffle = True, random_state = RANDOM_SEED)\n    for fold, (train_idx, valid_idx) in enumerate(skf.split(train, train[\"claim\"])):\n       \n        # Training and Validation Sets\n        start = time.time()\n        X_train = train[features].iloc[train_idx].to_numpy()\n        X_valid = train[features].iloc[valid_idx].to_numpy()\n        y_train = train[\"claim\"].iloc[train_idx].to_numpy()\n        y_valid = train[\"claim\"].iloc[valid_idx].to_numpy()\n        \n        # Define and train model\n        model = tfdf.keras.GradientBoostedTreesModel(verbose = 0)\n        model.compile(metrics=[tf.metrics.AUC()])\n        model.fit(X_train, y_train, verbose = 0)\n        \n        # Get predictions\n        valid_preds = model.predict(X_valid)[:,0]\n        test_preds += model.predict(X_test)[:,0] \/ NUM_FOLDS\n        oof_preds[valid_idx] = valid_preds\n        scores[fold] = roc_auc_score(y_valid, valid_preds)\n        end = time.time()\n        print(f'Fold {fold} AUC: {round(scores[fold], 6)} in {round((end-start) \/ 60, 2)} minutes')\n    \n    print(\"\\nAverage AUC:\", round(scores.mean(), 6))\n    print(\"Worst AUC:\", round(scores.min(), 6))\n    \n\n    return scores.mean(), test_preds, oof_preds","db784973":"def score_random_forest():\n\n    # Vectors to store predictions\/scores\n    X_test = test[features].to_numpy()\n    test_preds = np.zeros((test.shape[0],))\n    oof_preds = np.zeros((train.shape[0],))\n    scores = np.zeros(NUM_FOLDS)\n    \n    # Stratified k-fold cross-validation\n    skf = StratifiedKFold(n_splits = NUM_FOLDS, shuffle = True, random_state = RANDOM_SEED)\n    for fold, (train_idx, valid_idx) in enumerate(skf.split(train, train[\"claim\"])):\n       \n        # Training and Validation Sets\n        start = time.time()\n        X_train = train[features].iloc[train_idx].to_numpy()\n        X_valid = train[features].iloc[valid_idx].to_numpy()\n        y_train = train[\"claim\"].iloc[train_idx].to_numpy()\n        y_valid = train[\"claim\"].iloc[valid_idx].to_numpy()\n        \n        # Define and train model\n        model = tfdf.keras.RandomForestModel(verbose = 0)\n        model.compile(metrics=[tf.metrics.AUC()])\n        model.fit(X_train, y_train, verbose = 0)\n        \n        # Get predictions\n        valid_preds = model.predict(X_valid)[:,0]\n        test_preds += model.predict(X_test)[:,0] \/ NUM_FOLDS\n        oof_preds[valid_idx] = valid_preds\n        scores[fold] = roc_auc_score(y_valid, valid_preds)\n        end = time.time()\n        print(f'Fold {fold} AUC: {round(scores[fold], 6)} in {round((end-start) \/ 60, 2)} minutes')\n    \n    print(\"\\nAverage AUC:\", round(scores.mean(), 6))\n    print(\"Worst AUC:\", round(scores.min(), 6))\n\n    return scores.mean(), test_preds, oof_preds","28281b90":"gbdt_score, gbdt_preds, gbdt_oof = score_gradient_boosting()\n\nsubmission['claim'] = gbdt_preds\nsubmission.to_csv('gbtree_submission.csv', index=False)","dd5d1a76":"rf_score, rf_preds, rf_oof = score_random_forest()\n\nsubmission['claim'] = rf_preds\nsubmission.to_csv('randomforest_submission.csv', index=False)","98e913f3":"## 1. Gradient Boosted Trees","d6d6f484":"## Imports","fbfb206b":"## 2. Random Forest","12d59a66":"## 2. Random Forest","104bd16d":"# TensorFlow Decision Forests\n\nIn this notebook we will use the relatively new TensorFlow [Decision Forests](https:\/\/www.tensorflow.org\/decision_forests) library.  We get baselines for the [Gradient Boosted Trees](https:\/\/www.tensorflow.org\/decision_forests\/api_docs\/python\/tfdf\/keras\/GradientBoostedTreesModel) and [Random Forest](https:\/\/www.tensorflow.org\/decision_forests\/api_docs\/python\/tfdf\/keras\/RandomForestModel) models. We mostly use default settings except for the following:\n\n* We create a feature `nan_count` which is the sum of NAs in each row, based on [this discussion](https:\/\/www.kaggle.com\/c\/tabular-playground-series-sep-2021\/discussion\/270206).\n* For the Gradient Boosted Trees model, we set a high value for `num_trees` and enable early stopping to avoid overfitting on each fold.\n\n**Note:** This library doesn't support many optimizations at this time and will take a couple hours to run.","b00e6436":"# Training","eb3a96ca":"# Models\n\nFunctions for training a model and generating predictions on the test data","9e7eaea4":"## Load Data","353f9509":"## 1. Gradient Boosted Trees"}}