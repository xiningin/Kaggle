{"cell_type":{"3c5a24a4":"code","5e78b853":"code","3470c048":"code","6ab668c8":"code","c67f5606":"code","4bfc4bd4":"code","ca79b9e1":"code","3140ff0b":"code","4bd9bdbc":"code","64cde765":"code","d094afa4":"code","435aa0b7":"code","c4cd010f":"code","98cbad21":"code","29cc1389":"code","2d41290d":"code","72c39313":"code","65f7698a":"code","3cd46cb9":"code","528d2f2a":"code","e0105524":"code","5808c432":"code","b5e7acd7":"code","fe934aa7":"code","9f14108f":"code","5674cde5":"code","504155bb":"code","fe835ff2":"code","21928bf9":"code","02e85e26":"code","05b47d2e":"code","48e2671a":"code","b41f9e87":"code","ebcc4d5d":"code","65c203e3":"code","180d4765":"code","17e2f58f":"code","ad47f682":"code","8a28fd46":"code","75de434c":"code","f1ea13d6":"code","52b3cedc":"code","78844956":"code","678de3f3":"code","6389b8b4":"code","16a1fcae":"code","dcfdd73a":"code","3d97789b":"code","489ca53f":"code","855337b0":"code","cdc86353":"code","1949308c":"code","64dc23ed":"code","7a671d55":"code","76e61273":"code","9a52256d":"code","7f343a6c":"code","ae48b3f8":"code","93e74149":"code","a123dae7":"code","2ceaaeeb":"markdown","b2b11468":"markdown","fe7dfab8":"markdown","9c7d266c":"markdown","90d6cc84":"markdown","888f0db9":"markdown","1c1bd1f6":"markdown","1d1ad3af":"markdown","4a7703c8":"markdown","ab084358":"markdown","2c60b860":"markdown","6041d6e1":"markdown","57af99cc":"markdown","08ddf110":"markdown","21ace25d":"markdown","b36e9003":"markdown","5d28d921":"markdown","05548f57":"markdown","73b7bf1e":"markdown","4220455e":"markdown","fd61087d":"markdown","38d9bcb4":"markdown","c80aebce":"markdown","1ed353a2":"markdown","3e1d098a":"markdown","4fb7a1ec":"markdown","0654d8de":"markdown","223e97d9":"markdown","7b088917":"markdown","555320f6":"markdown","21d37df3":"markdown","7603c0d7":"markdown","8c4f407e":"markdown","9a54ae34":"markdown","08b7905f":"markdown","092e92b3":"markdown","f1546f77":"markdown","6e7d447c":"markdown","f310b3df":"markdown","2b800bca":"markdown","17c2c6b9":"markdown","65b4760a":"markdown","75dd6018":"markdown"},"source":{"3c5a24a4":"import matplotlib.pyplot as plt\nimport random\nimport itertools \nimport seaborn as sns\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","5e78b853":"sns.set_palette(\"icefire\")","3470c048":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\nseed_everything()","6ab668c8":"raw_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\nraw_data","c67f5606":"plt.figure(figsize = (8,4))\nsns.countplot(data = raw_data, x = 'Survived')","4bfc4bd4":"c1_index = raw_data[raw_data['Survived'] == 1].index\nc1_subsample = raw_data.loc[c1_index]\nc0_subsample = raw_data[raw_data['Survived'] == 0].sample(n = len(c1_subsample))\n\nbalanced_data = c0_subsample.append(c1_subsample, ignore_index = True).sample(frac = 1)\nbalanced_data = raw_data","ca79b9e1":"plt.figure(figsize = (8,4))\nsns.countplot(data = balanced_data, x = 'Survived')","3140ff0b":"plt.figure(figsize = (8,4))\nsns.countplot(data = balanced_data, x = 'Survived', hue = 'Pclass')","4bd9bdbc":"print(\"PClass \\t p_survive \\t N\")\nfor pclass in range(1,4):\n    selection = balanced_data[balanced_data['Pclass'] == pclass]\n    n = len(selection)\n    p = selection['Survived'].value_counts(normalize = True)[1]\n    print(\"{} \\t {:.5} \\t {}\".format(pclass, p, n))\n\n","64cde765":"plt.figure(figsize = (8,4))\nsns.countplot(data = balanced_data, x = 'Survived', hue = 'Sex')","d094afa4":"print(\"Sex \\t p_survive \\t N\")\nfor gender in ['female', 'male']:\n    selection = balanced_data[balanced_data['Sex'] == gender]\n    n = len(selection)\n    p = selection['Survived'].value_counts(normalize = True)[1]\n    print(\"{} \\t {:.5} \\t {}\".format(gender, p, n))","435aa0b7":"plt.figure(figsize = (8,8))\nsns.boxplot(data = balanced_data, x = 'Survived', y = 'Age')","c4cd010f":"pd.cut(balanced_data['Age'],5)","98cbad21":"def get_age_range(age):\n    if age < 16:\n        return 0\n    elif age < 32:\n        return 1\n    elif age < 48:\n        return 2\n    elif age < 64:\n        return 3\n    else:\n        return 4\n    \nbalanced_data['Age_range'] = balanced_data['Age'].apply(get_age_range)\n\nplt.figure(figsize = (8,4))\nsns.countplot(data = balanced_data, x = 'Survived', hue = 'Age_range')","29cc1389":"print(\"Age \\t p_survive \\t N\")\nage_range_names = [\"0-16\", \"16-32\", \"32-48\", \"48-64\", \"64+\"]\nfor i in range(0,5):\n    selection = balanced_data[balanced_data['Age_range'] == i]\n    n = len(selection)\n    p = selection['Survived'].value_counts(normalize = True)[1]\n    print(\"{} \\t {:.5} \\t {}\".format(age_range_names[i], p, n))","2d41290d":"plt.figure(figsize = (8,4))\nsns.histplot(data = balanced_data, x = 'SibSp')","72c39313":"balanced_data['SibSp_range'] = balanced_data['SibSp'].apply(lambda x: 0 if x == 0 else 1)\n\nplt.figure(figsize = (8,4))\nsns.countplot(data = balanced_data, x = 'Survived', hue = 'SibSp_range')","65f7698a":"print(\"SibSp \\t p_survive \\t N\")\n\nfor i in range(2):\n    selection = balanced_data[balanced_data['SibSp_range'] == i]\n    n = len(selection)\n    p = selection['Survived'].value_counts(normalize = True)[1]\n    print(\"{} \\t {:.5} \\t {}\".format(i, p, n))","3cd46cb9":"balanced_data['Parch'].value_counts()","528d2f2a":"plt.figure(figsize = (8,4))\nsns.histplot(balanced_data['Parch'])","e0105524":"balanced_data['Parch_range'] = balanced_data['Parch'].apply(lambda x: 0 if x == 0 else 1)\n\nplt.figure(figsize = (8,4))\nsns.countplot(data = balanced_data, x = 'Survived', hue = 'Parch_range')","5808c432":"plt.figure(figsize = (8,8))\nsns.boxplot(data = balanced_data, x = 'Survived', y = 'Fare')","b5e7acd7":"plt.figure(figsize = (8,4))\nsns.histplot(balanced_data['Fare'], bins = 15)","fe934aa7":"pd.qcut(balanced_data['Fare'], 5)","9f14108f":"def fare_range(n):\n    if n < 7.896:\n        return 1\n    elif n < 12.475:\n        return 2\n    elif n < 25.858:\n        return 3\n    elif n < 52.0:\n        return 4\n    else:\n        return 5\n        \nbalanced_data['Fare_range'] = balanced_data['Fare'].apply(fare_range)\n\nplt.figure(figsize = (8,4))\nsns.countplot(data = balanced_data, x = 'Survived', hue = 'Fare_range')","5674cde5":"balanced_data","504155bb":"print(\"Fare \\t p_survive \\t N\")\nfare_range_names = [\"0-8\", \"8-12\", \"12-25\", \"25-52\", \"52+\"]\nfor i in range(1,6):\n    selection = balanced_data[balanced_data['Fare_range'] == i]\n    n = len(selection)\n    p = selection['Survived'].value_counts(normalize = True)[1]\n    print(\"{} \\t {:.5} \\t {}\".format(fare_range_names[i-1], p, n))","fe835ff2":"def to_int(text):\n    try:\n        return int(text)\n    except:\n        return 0\n\nbalanced_data['Cabin'].fillna(\"Z\").apply(lambda x: to_int(x[1:]) if len(x) > 1 else 0).value_counts()","21928bf9":"def get_cabin_letter(cabin):\n    try:\n        return cabin[0]\n    except:\n        return 0\nbalanced_data['Cabin_letter'] = balanced_data['Cabin'].apply(get_cabin_letter).replace({'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'T':8})","02e85e26":"plt.figure(figsize = (12,6))\nsns.countplot(data = balanced_data, x = 'Survived', hue = 'Cabin_letter')","05b47d2e":"print(\"Letter \\t p_survive \\t N\")\nfor i in range(8):\n    selection = balanced_data[balanced_data['Cabin_letter'] == i]\n    n = len(selection)\n    p = selection['Survived'].value_counts(normalize = True)[1]\n    print(\"{} \\t {:.5} \\t {}\".format(i, p, n))","48e2671a":"balanced_data['Has_cabin'] = (~balanced_data['Cabin'].isnull()).apply(int)\nplt.figure(figsize = (8,4))\nsns.countplot(data = balanced_data, x = 'Survived', hue = 'Has_cabin')","b41f9e87":"print(\"Cabin? \\t p_survive \\t N\")\nfor i in range(2):\n    selection = balanced_data[balanced_data['Has_cabin'] == i]\n    n = len(selection)\n    p = selection['Survived'].value_counts(normalize = True)[1]\n    print(\"{} \\t {:.5} \\t {}\".format(i, p, n))","ebcc4d5d":"plt.figure(figsize = (8,4))\nsns.countplot(data = balanced_data, x = 'Embarked')","65c203e3":"plt.figure(figsize = (8,4))\nsns.countplot(data = balanced_data, x = 'Survived', hue = 'Embarked')","180d4765":"balanced_data['Name']","17e2f58f":"wordlist = \"\"\nfor i in range(len(balanced_data)):\n    wordlist = wordlist + balanced_data.iloc[i]['Name'] + \" \"\n    \nwordlist = ''.join(e for e in wordlist if not (e in [',', ')', '(', '.']))\n    \nwordlist = wordlist.split()\n\nwordfreq = {}\n\nfor w in wordlist:\n    wordfreq[w] = wordlist.count(w)\n\nwordfreq = {k: v for k, v in sorted(wordfreq.items(), key=lambda item: item[1], reverse= True)}\n\ntitles_data = pd.DataFrame()\ntitles_data['Name'] = wordfreq.keys()\ntitles_data['Freq'] = wordfreq.values()\ntitles_data.head(10)","ad47f682":"def get_title_index(name):\n    if name.find('Mrs') >= 0:\n        return 4\n    elif name.find('Miss') >= 0:\n        return 3\n    elif name.find('Mr') >= 0:\n        return 1\n    elif name.find('Master') >= 0:\n        return 2\n    else:\n        return 0\n\nbalanced_data['Title'] = balanced_data['Name'].apply(get_title_index)","8a28fd46":"plt.figure(figsize = (8,4))\nsns.countplot(data = balanced_data, x = 'Survived', hue = 'Title')","75de434c":"print(\"Title \\t p_survive \\t N\")\ntitles = ['None', 'Mr', 'Master', 'Miss', 'Mrs']\nfor i in range(5):\n    selection = balanced_data[balanced_data['Title'] == i]\n    n = len(selection)\n    p = selection['Survived'].value_counts(normalize = True)[1]\n    print(\"{} \\t {:.5} \\t {}\".format(titles[i], p, n))","f1ea13d6":"balanced_data.isnull().sum()","52b3cedc":"balanced_data['Age'].describe()","78844956":"plt.figure(figsize = (8,4))\nsns.histplot(balanced_data['Age'])","678de3f3":"def solve_missing_values(data_):\n    data = data_.copy()\n    \n    data['Age'] = data['Age'].fillna(data['Age'].mean())\n\n    try:\n        data = data.drop(['Cabin'], axis = 1)\n    except KeyError:\n        pass\n\n    data['Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0])\n        \n    return data\n\nbalanced_data = solve_missing_values(balanced_data)","6389b8b4":"balanced_data['Age_range'] = balanced_data['Age'].apply(get_age_range)","16a1fcae":"balanced_data['Is_alone'] = (balanced_data['Parch_range'] == 0 & (balanced_data['SibSp_range'] == 0)).apply(int)\nbalanced_data['SibSp+Parch'] = balanced_data['SibSp'] + balanced_data['Parch']\nbalanced_data['Is_child'] = (balanced_data['Age_range'] == 0).apply(int)","dcfdd73a":"try:\n    target = balanced_data['Survived']\n    balanced_data = balanced_data.drop(['Survived','PassengerId', 'Name', 'Ticket', 'SibSp', 'Parch', 'Fare', 'Age'], axis = 1)\nexcept KeyError:\n    pass","3d97789b":"balanced_data['Sex'] = balanced_data['Sex'].replace({\"female\": 0, \"male\": 1})\nbalanced_data['Embarked'] = balanced_data['Embarked'].replace({\"Q\": 0, \"C\": 1, \"S\": 2})\nbalanced_data","489ca53f":"from sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.model_selection import KFold, cross_validate, ShuffleSplit\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\n\ncv_split = ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 42 )\n\nrf = ('rf', RandomForestClassifier())\nsvc = ('svc', SVC(probability= True))\nknn = ('knn', KNeighborsClassifier())\n\nscores = pd.DataFrame()\n\nmodels = [RandomForestClassifier(random_state = 42), KNeighborsClassifier(), SVC(), VotingClassifier(estimators=[rf, svc, knn], voting='soft')]\n\nfor model in models:\n    cv_results = cross_validate(model, balanced_data, target, cv  = cv_split, scoring = 'roc_auc')\n    scores = scores.append({'model': model.__class__.__name__, 'score(ROC_AUC)': np.mean(cv_results['test_score'])}, ignore_index = True)\nscores","855337b0":"from sklearn.feature_selection import RFECV\n\nrfe_selector = RFECV(RandomForestClassifier(random_state = 42), scoring = 'roc_auc', cv = cv_split)\nrfe_selector.fit(balanced_data, target)","cdc86353":"selected_features = balanced_data.columns[rfe_selector.get_support()].values\nprint(\"Selected features:\")\nprint(selected_features)","1949308c":"scores = pd.DataFrame()\n\nmodels = [RandomForestClassifier(random_state = 42), KNeighborsClassifier(), SVC(), VotingClassifier(estimators=[rf, svc, knn], voting='soft')]\n\nfor model in models:\n    cv_results = cross_validate(model, balanced_data[selected_features], target, cv  = cv_split, scoring = 'roc_auc')\n    scores = scores.append({'model': model.__class__.__name__, 'score(ROC_AUC)': np.mean(cv_results['test_score'])}, ignore_index = True)\nscores","64dc23ed":"rf = RandomForestClassifier(random_state = 42)\nrf.get_params()","7a671d55":"cv_results = cross_validate(rf, balanced_data[selected_features], target, cv  = cv_split, scoring = 'roc_auc')\nprint(\"Baseline - test scoring (ROC_AUC): {}\".format(cv_results['test_score'].mean()))","76e61273":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = {'criterion': ['gini', 'entropy'],\n              'n_estimators': [50, 100, 200, 300],\n              'max_depth': [None, 2,4,8],\n              'random_state': [42]}\n\nparams_search = GridSearchCV(RandomForestClassifier(random_state = 42), param_grid = param_grid, scoring = 'roc_auc', cv = cv_split)\nparams_search.fit(balanced_data[selected_features], target)\nprint(\"Tuned parameters + features selected  - test score (ROC_AUC): {}\".format(params_search.cv_results_['mean_test_score'][params_search.best_index_]))","9a52256d":"print(\"Best parameters:\")\nparams_search.best_params_","7f343a6c":"def data_pipeline(data_):    \n    data = data_.copy()\n    \n    data['Embarked'] = data['Embarked'].fillna(balanced_data['Embarked'].dropna().mode()[0])\n    \n    data['Age'] = data['Age'].fillna(29)    \n    \n    data['Age_range'] = data['Age'].apply(get_age_range)\n\n    data['SibSp_range'] = data['SibSp'].apply(lambda x: 0 if x == 0 else 1)\n\n    data['Parch_range'] = data['Parch'].apply(lambda x: 0 if x == 0 else 1)\n\n    data['Fare_range'] = data['Fare'].apply(fare_range)\n    \n    data['Sex'] = data['Sex'].replace({\"female\": 0, \"male\": 1})\n    \n    data['Embarked'] = data['Embarked'].replace({\"Q\": 0, \"C\": 1, \"S\": 2})\n    \n    data['Has_cabin'] = (~data['Cabin'].isnull()).apply(int)\n    \n    data['Cabin_letter'] = data['Cabin'].apply(get_cabin_letter).replace({'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'T':8})\n    \n    data['Title'] = data['Name'].apply(get_title_index)\n    \n    data['Is_alone'] = (data['Parch_range'] == 0 & (data['SibSp_range'] == 0)).apply(int)\n    \n    data['SibSp+Parch'] = data['SibSp'] + data['Parch']\n    \n    data['Is_child'] = (data['Age_range'] == 0).apply(int)\n    \n    \n    try:\n        data = data.drop(['PassengerId', 'Name', 'Ticket', 'SibSp', 'Parch', 'Fare', 'Age', 'Cabin'], axis = 1)\n\n    except KeyError:\n        pass\n    \n    return data","ae48b3f8":"test_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\nsample_submission = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')","93e74149":"RF = RandomForestClassifier(criterion = 'entropy', max_depth = 4, n_estimators = 50, random_state = 42)\n\nRF.fit(balanced_data[selected_features], target)\n\npred = RF.predict(data_pipeline(test_data)[selected_features])","a123dae7":"sample_submission['Survived'] = pred\nsample_submission.to_csv('submission.csv', index=False)\nsample_submission","2ceaaeeb":"## Preparing submission","b2b11468":"## Preprocessing the data","fe7dfab8":"## Conclusion and Next Steps\n\nOur prediction performance is quite satisfactory we managed to score 77% accuracy on the leaderboard and 81% on cross-validation. We still can explore different methods for tuning hyperparameters and select features to further improve the model performance.\n","9c7d266c":"## Dealing with missing values","90d6cc84":"### Survivability X  Embarked","888f0db9":"The new balanced dataset has 684 rows.","1c1bd1f6":"## Random Forest\n","1d1ad3af":"Now we'll analyze the \"Class\" variable against the target variable. Does the passenger class influence it survivability?","4a7703c8":"### Survivability X Sibsp\n\nHere we will explore the Sibsp variable. Does having siblings or spouses aboard affect the passenger survivability? ","ab084358":"### Survivability X Class","2c60b860":"## The \"Name\" variable","6041d6e1":"## Creating a baseline model","57af99cc":"### Survivability X Parch","08ddf110":"Observing the histogram we can conclude that the best strategy for this analyzis is to transform this variable into a binary (have\/not have) attribute simply because the dataset doesn't have enough samples of passengers with more than 1 SibSp they are mostly like outliers.","21ace25d":"### Survivability X Fare","b36e9003":"Analyzing the Sex variable.","5d28d921":"Looking to the graph we can see that the passenger class does matter alot for it survivebality.\n\nA third class passenger had only 33% chance of surviving the crash, while a first class passenger had a considerable greater 73%.","05548f57":"### Making the submission","73b7bf1e":"## Feature selection","4220455e":"The age range does not seem very promising. \n\nKids (0 - 16 yrs) had advantage on surviving the crash with 70% chance of making it.","fd61087d":"### Mapping text into numeric","38d9bcb4":"### Defining cross validation model","c80aebce":"## Adding some new features","1ed353a2":"## Loading packages","3e1d098a":"### Creating data pipeline function","4fb7a1ec":"### Predicting with RF","0654d8de":"### Target class balance","223e97d9":"##  Hyperparameters tunning","7b088917":"In this section we will explore the dataset and relations between the columns and the target variable. Exploration is an important part of  any data science project as it can provide meaningful insights about the analyzed data.","555320f6":"We choose to fill the age column with the average value of the atribute for two reasons:\n\n1. According to the distribution of the variable the age has a high density around the mean value.\n\n2. According to the previous analysis the passengers within the Age_range of the mean (16-35 yrs) has about equal chances of either surviving or dying the crash, which means that the age by itself will not influence the predictions for those individuals. ","21d37df3":"### Survivability X Cabin","7603c0d7":"### Survivability X Age","8c4f407e":"Since classification is the proposed task we need to keep the dataset balanced in terms of target variable so it won't drive our models into biased results.","9a54ae34":"Passengers without any siblings\/spouses had lower survivability when compared to people traveling with their SibSP. \n\n45% vs 58%","08b7905f":"### Loading test (submission) dataset","092e92b3":"# Titanic survival challenge\n\nIn this notebook we will explore the Titanic survival challenge and try make predictions with Machine Learning models.\n\n*\"This is the legendary Titanic ML competition \u2013 the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\"*","f1546f77":"### Survivability X Sex","6e7d447c":"### Dropping cols that won't be used","f310b3df":"According to the data men got a hard time during the crash with a little 27% chance of survive agaisnt women's 82%.\n\n**Women and kids first...**","2b800bca":"Our original dataset has 891 columns (which is quite few) and 12 columns.\n\n\nPassengerId, Name and Ticket probably will not be very useful leaving us with 8 attribute + 1 target columns.","17c2c6b9":"## Data Exploration","65b4760a":"The Cabin column has alot of null values there is no efficient way of fixing it, so we'll drop it.\n\nWe'll be filling the Embarked col with the most frequent value, which is pretty acceptable.\n\nFor the Age column we'll have to find a fair way of filling it.\n\n","75dd6018":"For this analysis we will create a new column called Age_range. We'll use ranges to convert the numeric Age variable into categorical (object)."}}