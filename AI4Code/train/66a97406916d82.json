{"cell_type":{"f99f71e5":"code","4d9e8e2b":"code","1a85bca9":"code","e08f8027":"code","e5c384c1":"code","a9ffea09":"code","2684ea49":"code","54fdd272":"code","c9ed4b3e":"code","fbf0665a":"code","44ea0a66":"code","9d44ebcd":"code","4cbfba1b":"code","f78fb6fd":"code","2c7ed1c2":"code","1a72a8f9":"code","96f4adfc":"code","2e97555d":"code","3f4c13f7":"code","2a18ab23":"code","c6ae3613":"code","19ed49c6":"code","3cd3f362":"code","cbbfa8ca":"code","33e3ccb4":"code","586b466f":"code","9dfec35c":"code","0289e353":"code","5236282e":"markdown","fa150cc7":"markdown","de8a7620":"markdown","1a34bb71":"markdown","c7b8ed1f":"markdown","02c916a2":"markdown","54e6dc02":"markdown","171f2244":"markdown","82197b94":"markdown","3e34e56d":"markdown","39f2c416":"markdown"},"source":{"f99f71e5":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport glob\nfrom tqdm.notebook import tqdm\nimport gc","4d9e8e2b":"df_train = pd.read_csv('..\/input\/optiver-realized-volatility-prediction\/train.csv')\ndf_train.head()","1a85bca9":"# reading test.csv\n\ndf_test = pd.read_csv('..\/input\/optiver-realized-volatility-prediction\/test.csv')\ndf_test.head()","e08f8027":"submission = pd.read_csv('..\/input\/optiver-realized-volatility-prediction\/sample_submission.csv')\nsubmission.head()","e5c384c1":"def WAP1(df):\n    WAP = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * \n           df['bid_size1'])\/(df['bid_size1'] + df['ask_size1'])\n    return WAP\n\ndef WAP2(df):\n    wap = (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * \n           df['bid_size2'])\/(df['bid_size2'] + df['ask_size2'])\n    return wap\n\ndef log_return(WAP):\n    return np.log(WAP).diff() \n\ndef realized_volatility(log_r):\n    return np.sqrt((log_r**2).sum())","a9ffea09":"def read_data(path):\n    trade = pd.read_parquet(path)\n    return trade\n\n\ndef consol_book_df(path):\n\n    #read stock pq file\n    df = read_data(path)\n    \n    #add stock-id column\n    df['stock_id'] = int(path.split(\"=\")[1]) #extract stock id by removing directory\n    \n    # Caulculating WAP\n    df['WAP1'] = WAP1(df)\n    df['WAP2'] = WAP2(df)\n    \n    #calculating log return\n    df['book_log_ret1'] = df.groupby('time_id')['WAP1'].apply(log_return).fillna(0)\n    df['book_log_ret2'] = df.groupby('time_id')['WAP2'].apply(log_return).fillna(0)\n    \n    #calculating spread\n    # As explained in the dataset description the difference between bid value and ask value i.e. spread is correlated to volatile nature of stock\n    # the bigger the spread the higher volatile stock will be\n    \n    df['price_spread1'] = (df['ask_price1'] - df['bid_price1']) \/ ((df['ask_price1'] + df['bid_price1']) \/ 2)\n    df['price_spread2'] = (df['ask_price2'] - df['bid_price2']) \/ ((df['ask_price2'] + df['bid_price2']) \/ 2)\n    df['bid_spread'] = df['bid_price1'] - df['bid_price2']\n    df['ask_spread'] = df['ask_price1'] - df['ask_price2']\n    df[\"bid_ask_spread\"] = abs(df['bid_spread'] - df['ask_spread'])\n    df['bid_ask_price_ratio1'] = df['bid_price1'] \/ df['ask_price1']\n    df['bid_ask_price_ratio2'] = df['bid_price2'] \/ df['ask_price2']\n    \n    df['total_volume'] = (df['ask_size1'] + df['ask_size2']) + (df['bid_size1'] + df['bid_size2'])\n    df['volume_imbalance'] = abs((df['ask_size1'] + df['ask_size2']) - (df['bid_size1'] + df['bid_size2']))\n    \n    #Book features\n    \n    '''the features that will be returned from book_data are:\n        1.Realized volatiltiy1:calculated from WAP1\n        2.Realized volatility2: calculated from WAP2\n        3.Price_spread1: The spread betwwen ask_price1 and bid_price1\n        4.Price_spread2: The spread betwwen ask_price2 and bid_price2\n        5.Bid_spread: The spread between the two bidding prices\n        6.Ask_spread: The spread between the two ask prices\n    '''\n    final_book = df.groupby(['stock_id', 'time_id']).agg(\n                                              real_vol_1 =('book_log_ret1', realized_volatility),\n                                              real_vol_2 = ('book_log_ret2', realized_volatility),\n                                              price_spread1 =('price_spread1', 'mean'),\n                                              price_spread2 =('price_spread2', 'mean'),\n                                              bid_spread =('bid_spread', 'mean'),\n                                              ask_spread =('ask_spread', 'mean'),\n                                              bid_ask_price_ratio1 =('bid_ask_price_ratio1', 'mean'),\n                                              bid_ask_price_ratio2 =('bid_ask_price_ratio2', 'mean'),\n                                              total_volume =('total_volume', 'sum'),\n                                              volume_imbalance =('volume_imbalance', 'mean'),\n    \n        \n                                              \n                                              ).reset_index()\n    return final_book\n\n\n\n# consol_trade_df works on trade_train data\n#It return realized volatility calculated from the price column of trada data\n\ndef consol_trade_df(path):\n    \n    #read stock pq file\n    df = read_data(path)\n    \n    #add stock-id column\n    df['stock_id'] = int(path.split(\"=\")[1])  #extract stock id by removing directory\n    \n    #trade log return from fixed price in trade book\n    df['trade_log_ret'] = df.groupby('time_id')['price'].apply(log_return).fillna(0)\n\n    \n    #Trade features\n    final_trade = df.groupby(['time_id', 'stock_id']).agg(\n                                                     real_vol_trade=('trade_log_ret', realized_volatility)).reset_index()\n\n    return final_trade","2684ea49":"# Function to combine and get features from train file, book_train file and trade_train file\n\ndef create_dataSet(df, book_paths, trade_paths):\n    final_df = pd.DataFrame()\n    for book_path, trade_path in tqdm(zip(book_paths, trade_paths)):\n        book = consol_book_df(book_path)\n        trade = consol_trade_df(trade_path)\n        merged_df = (pd.merge(book, trade, on=['stock_id', 'time_id'], how='left')\n                     .merge(df, on=['stock_id', 'time_id'], how='left'))\n        final_df = pd.concat([final_df, merged_df])\n        gc.collect()\n    return final_df","54fdd272":"#reading data_path for each stock\norder_book_training = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/book_train.parquet\/*')\ntrade_training = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/trade_train.parquet\/*')\ntrain_df = pd.read_csv('..\/input\/optiver-realized-volatility-prediction\/train.csv')\n\n\n# passing the file_path for each stock to create_dataSet function\ntrain_set = create_dataSet(train_df, order_book_training, trade_training)","c9ed4b3e":"train_set.head()","fbf0665a":"train_set.describe()","44ea0a66":"#checking null values in the dataset\ntrain_set.isnull().sum()","9d44ebcd":"# handling null values\n\n# real_vol_trade contains 19 null values\n# So removing those 19 rows from the dataframe\n\ntrain_set_final = train_set.replace([np.inf,-np.inf],np.nan).dropna()\ntrain_set_final[train_set_final.isnull().any(axis=1)]\ntrain_set_final","4cbfba1b":"train_set_final.describe()","f78fb6fd":"train_set_final.head()","2c7ed1c2":"#Correlation between target variable and other features\n\ntrain_set_final.corr()['target']","1a72a8f9":"fig, ax = plt.subplots(figsize=(15,15))\nsns.heatmap(train_set_final.corr(),annot=True,ax=ax)","96f4adfc":"sns.scatterplot(x=train_set_final['bid_ask_price_ratio1'],y=train_set_final['target'])","2e97555d":"sns.scatterplot(x=train_set_final['bid_ask_price_ratio2'],y=train_set_final['target'])","3f4c13f7":"sns.scatterplot(x=train_set_final['total_volume'],y=train_set_final['target'])","2a18ab23":"sns.scatterplot(x=train_set_final['volume_imbalance'],y=train_set_final['target'])","c6ae3613":"# Plottting Real_vol1_1 with target\nsns.scatterplot(x=train_set_final['real_vol_1'],y=train_set_final['target'])","19ed49c6":"# Plottting Real_vol1_2 with target\nsns.scatterplot(x=train_set_final['real_vol_2'],y=train_set_final['target'])","3cd3f362":"# Plottting Real_vol1_target with target\nsns.scatterplot(x=train_set_final['real_vol_trade'],y=train_set_final['target'])","cbbfa8ca":"# Plottting price_spread1 with target\nsns.scatterplot(x=train_set_final['price_spread1'],y=train_set_final['target'])","33e3ccb4":"# Plottting price_spread1 with target\nsns.scatterplot(x=train_set_final['price_spread2'],y=train_set_final['target'])","586b466f":"# Plottting bid_spread with target\n\nsns.scatterplot(x=train_set_final['bid_spread'],y=train_set_final['target'])","9dfec35c":"## Plottting ask_spread with target\nsns.scatterplot(x=train_set_final['ask_spread'],y=train_set_final['target'])","0289e353":"from sklearn.metrics import r2_score\ndef rmspe_R_squared(y_true, y_pred):\n    return  ((np.sqrt(np.mean(np.square((y_true - y_pred) \/ y_true)))),r2_score(y_true, y_pred))","5236282e":"The test file copntains three columns\n\n1 stock_id: Id of the stock\n\n2 time_id: Id of the time\n\n3 row_id: combined stock_id and time_id with a hypen(-)","fa150cc7":"From above plots we can see that all the features are correlated with the target variable.\nAll fwatures are positively correlated except the ask_apread.Ask_spread is negatively correlated with target value","de8a7620":"For EDA on the the dataset refer to:\nhttps:\/\/www.kaggle.com\/ravinderkotwal\/optiver-volatility-prediction-eda2\n\nHere I will be working on features","1a34bb71":"**Functions for reading data**","c7b8ed1f":"**Plotting target vs other features**","02c916a2":"Lets take look at how to submit the test results","54e6dc02":"Predicted value is evluated by two metrics:\n\n    RMSPE:Root Mean Square Percentage Error\n    \n    R quared","171f2244":"First lets look into **train.csv and test.csv**","82197b94":"**Functions for calculating realized volatility**\n\nTo undestand below functions and why they are used refer to notebook mentioned in the first cell.\n\n\n**To calculate realized volatility we go through the following precudure:**\n\n\n\nCalculate **Weighted Averaged price(WAP)** from the **bid price** and **ask price** and **their size**. WAP is a fixed price.\n\n    \n**\ud835\udc4a\ud835\udc34\ud835\udc43** =( \ud835\udc35\ud835\udc56\ud835\udc51\ud835\udc43\ud835\udc5f\ud835\udc56\ud835\udc50\ud835\udc521 \u2217 \ud835\udc34\ud835\udc60\ud835\udc58\ud835\udc46\ud835\udc56\ud835\udc67\ud835\udc521 + \ud835\udc34\ud835\udc60\ud835\udc58\ud835\udc43\ud835\udc5f\ud835\udc56\ud835\udc50\ud835\udc521 \u2217 \ud835\udc35\ud835\udc56\ud835\udc51\ud835\udc46\ud835\udc56\ud835\udc67\ud835\udc521) \/( \ud835\udc35\ud835\udc56\ud835\udc51\ud835\udc46\ud835\udc56\ud835\udc67\ud835\udc521 + \ud835\udc34\ud835\udc60\ud835\udc58\ud835\udc46\ud835\udc56\ud835\udc67\ud835\udc521 )\n      \n    \n Similary using above formula we can calculate **WAP2 for bid_prce2, ask_price2 and their sizes.**\n    \n\n Then we calculate the **log return value of the WAP**\n    \n $\\huge r_{t-1, t} = \\log \\left( \\frac{S_{t-1}}{S_{t1}} \\right)$    \n \n where St is the fixed price at time t.In book_train the calculated WAP is the fixed price.\n        \n        \n        \n Then we calculate the **realized volatility using log return value **\n \n  \n $\\huge \\sigma = \\sqrt{\\sum_{t}r_{t-1, t}^2}$   \n \n \n\n       \n\n","3e34e56d":"Train file has three columns.\n\n1.stock_id: Id of the stock\n\n2.time_id: Id of the time bucket\n\n3.target: Realized volatility of the next 10 minute window under the same stock_id\/time_id\n\nTarget value is given for different time_id for various stocks","39f2c416":"So while submisson we will use two columns\n\nOne is the row_id from the test file\n\nAnd the other is the target value we have predicted for that row_id i.e. stock_id-time_id(stock_id at particular time_id)"}}