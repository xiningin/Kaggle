{"cell_type":{"e78e498e":"code","5108feea":"code","48ba9fa6":"code","681eafe1":"code","bf657536":"code","89d191a6":"code","61e9cb7a":"code","2fbe1cc9":"code","e92c4a5c":"code","56d7e677":"code","05177027":"markdown","6bf5fcf0":"markdown"},"source":{"e78e498e":"#Imports\n#!pip install scikit-learn==0.21.2\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\npd.set_option('max_columns', None, \"max_rows\", None)\nfrom numpy.random import seed\nseed(1002)\ntf.random.set_seed(1002)","5108feea":"#Declare Global variables \ntrain_path = \"..\/input\/titanic\/train.csv\"\ntest_path = \"..\/input\/titanic\/test.csv\"\nmapping = {'Col': 'Other',\n           'Major': 'Other',\n           'Ms': 'Miss',\n           'Mlle': 'Miss',\n           'Sir': 'Royal',\n           'Jonkheer': 'Royal',\n           'Countess': 'Royal',\n           'Lady': 'Royal',\n           'Capt': 'Other',\n           'Dona': 'Royal',\n           'Mme': 'Mrs',\n           'Don': 'Royal',\n           'Dr': 'Other',\n           'Rev' : 'Other'}\ncontinuous = ['Age', 'Fare', 'Parch', 'SibSp', 'Family_Size', \"Family_Survival\"]","48ba9fa6":"def prepare_data(train_path,test_path):\n    train = pd.read_csv(train_path)\n    test = pd.read_csv(test_path)\n    df = pd.concat([train, test], axis = 0, sort = False)\n    df[\"Title\"] = df[\"Name\"].str.extract(r\"([a-zA-Z]+)\\.\", expand = True)\n    df.replace({\"Title\": mapping}, inplace = True)\n    title_ages = dict(df.groupby('Title')['Age'].median())\n    df[\"age_med\"] = df[\"Title\"].apply(lambda a : title_ages[a])\n    df[\"Age\"].fillna(df[\"age_med\"], inplace = True)\n    #df[\"Pclass_rel\"] = df[\"Pclass\"]\n    submit = df[pd.isnull(df[\"Survived\"])][[\"PassengerId\",\"Survived\"]]\n    df[\"Fare\"].fillna(df[\"Fare\"][df[\"Pclass\"] == 3].median(), inplace = True)\n    df['Family_Size'] = df['Parch'] + df['SibSp'] + 1\n    df.loc[:,'FsizeD'] = 'Alone'\n    df.loc[(df['Family_Size'] > 1),'FsizeD'] = 'Small'\n    df.loc[(df['Family_Size'] > 4),'FsizeD'] = 'Big'\n    # Family Survival (https:\/\/www.kaggle.com\/konstantinmasich\/titanic-0-82-0-83)\n    df['Last_Name'] = df['Name'].apply(lambda x: str.split(x, \",\")[0])\n    DEFAULT_SURVIVAL_VALUE = 0.5\n    df['Family_Survival'] = DEFAULT_SURVIVAL_VALUE\n    for grp, grp_df in df[['Survived','Name', 'Last_Name', 'Fare', 'Ticket', 'PassengerId', \n                           'SibSp', 'Parch', 'Age', 'Cabin']].groupby(['Last_Name', 'Fare']):\n        if (len(grp_df) != 1):\n            # A Family group is found.\n            for ind, row in grp_df.iterrows():\n                smax = grp_df.drop(ind)['Survived'].max()\n                smin = grp_df.drop(ind)['Survived'].min()\n                passID = row['PassengerId']\n                if (smax == 1.0):\n                    df.loc[df['PassengerId'] == passID, 'Family_Survival'] = 1\n                elif (smin == 0.0):\n                    df.loc[df['PassengerId'] == passID, 'Family_Survival'] = 0\n    for _, grp_df in df.groupby('Ticket'):\n        if (len(grp_df) != 1):\n            for ind, row in grp_df.iterrows():\n                if (row['Family_Survival'] == 0) | (row['Family_Survival']== 0.5):\n                    smax = grp_df.drop(ind)['Survived'].max()\n                    smin = grp_df.drop(ind)['Survived'].min()\n                    passID = row['PassengerId']\n                    if (smax == 1.0):\n                        df.loc[df['PassengerId'] == passID, 'Family_Survival'] = 1\n                    elif (smin == 0.0):\n                        df.loc[df['PassengerId'] == passID, 'Family_Survival'] = 0\n    df['Embarked'].fillna(method='backfill', inplace=True)\n    df['Sex'] = df['Sex'].astype('category').cat.codes\n    df.drop(['Cabin', 'Name', 'Ticket', 'PassengerId', 'age_med', 'Last_Name'], axis=1, inplace=True)\n    df = pd.get_dummies(df, columns = [\"Embarked\", \"Pclass\", \"Title\", \"FsizeD\"])\n    scaler = StandardScaler()\n    for var in continuous:\n        df[var] = scaler.fit_transform(df[var].astype('float64').values.reshape(-1, 1))\n    x_train = df[pd.notnull(df[\"Survived\"])].drop(\"Survived\",axis = 1)\n    y_train = df[pd.notnull(df[\"Survived\"])][\"Survived\"].astype(int)\n    x_test = df[pd.isnull(df[\"Survived\"])].drop(\"Survived\",axis = 1)\n    return x_train, y_train, x_test, submit","681eafe1":"x_train, y_train, x_test, submit = prepare_data(train_path, test_path)","bf657536":"layers = [[8],[16],[8,4],[16,8],[24,16,8],[24,8]]\nactivation = [\"relu\",\"linear\",\"tanh\"]\noptimizer = [\"SGD\",\"RMSprop\",\"Adam\"]\ndropout = [0.0,0.2]\nbatch_size = [32,64,128]\nepochs = [50,75]\nparam_grid = dict(batch_size = batch_size, \n                  epochs = epochs,\n                  lyr = layers,\n                  act = activation,\n                  opt = optimizer, \n                  dr = dropout)","89d191a6":"def create_model(lyr = [13,8], act = \"relu\", opt = \"adam\", dr = 0.2):\n    model = Sequential()\n    model.add(Dense(lyr[0], input_dim = 22, activation = act))\n    model.add(Dropout(dr))\n    for i in lyr[1:]:\n        model.add(Dense(i, activation = act))\n    model.add(Dense(1, activation = \"sigmoid\"))\n    model.compile(loss = \"binary_crossentropy\", optimizer = opt, metrics = [\"accuracy\"])\n    return model","61e9cb7a":"def search():\n  model = KerasClassifier(build_fn = create_model, verbose = 1)\n  grid = GridSearchCV(estimator = model, param_grid = param_grid, n_jobs = -1, cv = 2, verbose=2)\n  grid_result = grid.fit(x_train, y_train)\n  return grid_result","2fbe1cc9":"estimator = KerasClassifier(build_fn = create_model, epochs = 100, batch_size = 10, verbose = 0)\nkfold = StratifiedKFold(n_splits = 5, random_state = 42, shuffle = False)\nresults = cross_val_score(estimator, x_train, y_train, cv = kfold)\nprint(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))","e92c4a5c":"estimator.fit(x_train, y_train, epochs = 100, batch_size = 10)","56d7e677":"submit[\"Survived\"] = estimator.predict(x_test)\nsubmit[\"Survived\"] = [int(np.round(x,0)) for x in submit[\"Survived\"]]\nsubmit.to_csv('predictions.csv', index=False)\nsubmit.head()","05177027":"**Now that we have done all this,**\n<br>\n<br>all we have to now do is just:\n<br>call the search method and store the result.\n<br>use the result to see the best parameter\n<br>\n<br>**BUT**\n<br>\n<br>The current kernal in kaggle uses the scikit-learn version 0.23.0\n<br>This version of Scikit-learn has got a bug in the GridSearchCV\n<br>and the only way to fix this is to roll back on a more stable release where \n<br>GridSearchCV is working ( I choose v0.21.2)\n<br>\n<br>**BUT**\n<br>\n<br>To roll to this version, i need to use conda inside of kaggle and that thing is also bugged out rn\n<br>\n<br>So it has become a rabbit hole of tryint to fix GridSearchCV -> Scikit-learn -> Conda installs\n<br>where I have already spent so many hours into\n<br>\n<br>**THEREFORE**\n<br>\n<br>I ran the GridSearchCV locally and stored its results in a dataframe\n<br>\n<br>Below are the output of codes that I ran locally:\n<br>\n> ```#codes to be run if GridSearchCV() is running properly\n> search_result = search()\n> view = pd.DataFrame(search_result.cv_results_)\n> view.to_csv('gridsearch_cv_results.csv', index=False)\n> search_result.best_params_```\n> \n---\n> search_result = search()\n<br>\n```Fitting 2 folds for each of 648 candidates, totalling 1296 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  37 tasks        | elapsed:   41.0s\n[Parallel(n_jobs=-1)]: Done 158 tasks        | elapsed:  3.0min\n[Parallel(n_jobs=-1)]: Done 361 tasks        | elapsed:  5.8min\n[Parallel(n_jobs=-1)]: Done 644 tasks        | elapsed: 10.5min\n[Parallel(n_jobs=-1)]: Done 1009 tasks       | elapsed: 16.3min\n[Parallel(n_jobs=-1)]: Done 1296 out of 1296 | elapsed: 20.1min finished```\n\n> search_result\n<br>\n```GridSearchCV(cv=2, error_score='raise-deprecating',\n             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f79f41f2550>,\n             iid='warn', n_jobs=-1,\n             param_grid={'act': ['relu', 'linear', 'tanh'],\n                         'batch_size': [32, 64, 128], 'dr': [0.0, 0.2],\n                         'epochs': [50, 75],\n                         'lyr': [[8], [16], [8, 4], [16, 8], [24, 16, 8],\n                                 [24, 8]],\n                         'opt': ['SGD', 'RMSprop', 'Adam']},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring=None, verbose=2)```\n\n> search_result.best_params_\n<br>\n```{'act': 'tanh',\n 'batch_size': 32,\n 'dr': 0.0,\n 'epochs': 75,\n 'lyr': [16, 8],\n 'opt': 'RMSprop'}```\n\n---\n\n**Some different samples of batch size and their co-responding acc**\n<br>batch 32 : 85.07%\n<br>batch 16 : 85.41%\n<br>batch 1 : 85.63%\n<br>other \n<br>#Results: 84.06% (1.45%) <13,8,1>\n<br>#Results: 84.29% (1.87%) <13,8,1> with dr 0.2\n<br>#Results: 84.40% (1.72%) <13,8,1> with dr 0.2 epochs = 100 (choosen)\n<br>#Results: 84.17% (0.90%) <9,9,5> with dr 0.2 epochs = 100\n\n---","6bf5fcf0":"The Ultimate oneliner\n\n---\n```submit[\"Survived\"] = [int(np.round(best_nn.predict(x_test.loc[x].to_numpy().reshape(1,18)),0)) for x in range(0,submit[\"Survived\"].size)]```\n\n---"}}