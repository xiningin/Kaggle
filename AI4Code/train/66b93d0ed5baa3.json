{"cell_type":{"88b8a047":"code","f02a9a70":"code","2636296d":"code","ec98e495":"code","d1d303bd":"code","6aaded1d":"code","4a56bf25":"code","e8719524":"code","991537cc":"code","c3acc893":"code","5207e090":"code","1fcfd643":"code","2fec017b":"code","bddcce3e":"code","3246bafe":"code","cafad3dc":"code","4535776f":"code","58731e3b":"code","90dbb071":"code","b37409a6":"code","f0b1fdb4":"code","2733905a":"markdown","90670f3a":"markdown","a97f09be":"markdown","f079816f":"markdown","fcf030bf":"markdown","4eb05429":"markdown","e3896b26":"markdown","2e1ab64b":"markdown","68416f34":"markdown"},"source":{"88b8a047":"from keras.models import Sequential\nfrom keras.layers import Conv2D, Activation,Dropout\nfrom keras.models import Model,load_model\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.core import Flatten, Dense\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom keras.engine.topology import Layer\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import backend as K\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.datasets import load_files\nimport itertools\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport cv2\nimport matplotlib.pyplot as plt\nimport itertools\n%matplotlib inline","f02a9a70":"train_dir = '\/kaggle\/input\/waste-classification-data\/dataset\/DATASET\/TRAIN'\ntest_dir = '\/kaggle\/input\/waste-classification-data\/dataset\/DATASET\/TEST'\n\ndef load_dataset(path):\n    data = load_files(path) #load all files from the path\n    files = np.array(data['filenames']) #get the file  \n    targets = np.array(data['target'])#get the the classification labels as integer index\n    target_labels = np.array(data['target_names'])#get the the classification labels \n    return files,targets,target_labels\n    \nx_train, y_train,target_labels = load_dataset(train_dir)\nx_test, y_test,_ = load_dataset(test_dir)\n\nprint('Training set size : ' , x_train.shape[0])\nprint('Testing set size : ', x_test.shape[0])","2636296d":"x_train,x_validate,y_train,y_validate = train_test_split(x_train,y_train,test_size = 0.2,random_state = 1)","ec98e495":"print (\"x_train shape: \" + str(x_train.shape))\nprint (\"x_train shape: \" + str(y_train.shape))\nprint (\"x_validate shape: \" + str(x_validate.shape))\nprint (\"y_validate shape: \" + str(y_validate.shape))\nprint (\"x_test shape: \" + str(x_test.shape))\nprint (\"y_test shape: \" + str(y_test.shape))","d1d303bd":"def convert_image_to_array(files):\n    width, height, channels = 100, 100, 3\n    images_as_array = np.empty((files.shape[0], width, height, channels), dtype=np.uint8) #define train and test data shape\n    for idx,file in enumerate(files):\n        img = cv2.imread(file) \n        res = cv2.resize(img, dsize=(width, height), interpolation=cv2.INTER_CUBIC) #As images have different size, resizing all images to have same shape of image array\n        images_as_array[idx] = res\n    return images_as_array\n\nx_train = np.array(convert_image_to_array(x_train))\nprint('Training set shape : ',x_train.shape)\n\nx_valid = np.array(convert_image_to_array(x_validate))\nprint('Validation set shape : ',x_valid.shape)\n\nx_test = np.array(convert_image_to_array(x_test))\nprint('Test set shape : ',x_test.shape)","6aaded1d":"x_train = x_train.astype('float32')\/255\nx_valid = x_valid.astype('float32')\/255\nx_test = x_test.astype('float32')\/255\ny_train = y_train.reshape(y_train.shape[0],1)\ny_test = y_test.reshape(y_test.shape[0],1)\ny_validate = y_validate.reshape(y_validate.shape[0],1)","4a56bf25":"plt.figure(figsize=(20,20))\nclasses = ['R','O']\nfor i in range(1,26):\n    index = np.random.randint(x_train.shape[0])\n    plt.subplot(5, 5, i)\n    plt.imshow(np.squeeze(x_train[index]), cmap='cool')\n    plt.title(classes[int(y_train[index])])\n    plt.tight_layout()\nplt.show()","e8719524":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\ndatagen.fit(x_train)","991537cc":"model = Sequential()\nmodel.add(Conv2D(32,kernel_size=(3, 3),kernel_initializer='he_normal',activation='relu',input_shape=(100,100,3),name = 'conv0'))\nmodel.add(Conv2D(32, kernel_size=(3, 3),activation='relu', name = 'conv1'))\nmodel.add(BatchNormalization(name='bn0'))\nmodel.add(MaxPooling2D(pool_size=(2, 2),name = 'maxpool0'))\nmodel.add(Dropout(0.2,name='dropout0'))\n\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu',name = 'conv2'))\nmodel.add(Conv2D(64, kernel_size=(3, 3),activation='relu', name = 'conv3'))\nmodel.add(BatchNormalization(name='bn1'))\nmodel.add(MaxPooling2D(pool_size=(2, 2),name = 'maxpool1'))\nmodel.add(Dropout(0.2,name='dropout1'))\n\nmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu',name = 'conv4'))\nmodel.add(Conv2D(128, kernel_size=(3, 3),activation='relu',name = 'conv5'))\nmodel.add(BatchNormalization(name='bn2'))\nmodel.add(MaxPooling2D(pool_size=(2, 2),name = 'maxpool2'))\nmodel.add(Dropout(0.3,name='dropout2'))\n\nmodel.add(Conv2D(256, kernel_size=(3, 3), activation='relu',name = 'conv6'))\nmodel.add(Conv2D(256, kernel_size=(3, 3),activation='relu',name = 'conv7'))\nmodel.add(BatchNormalization(name='bn3'))\nmodel.add(MaxPooling2D(pool_size=(2, 2),name = 'maxpool3'))\nmodel.add(Dropout(0.3,name='dropout3'))\n\nmodel.add(Flatten(name='fc'))\nmodel.add(Dense(512, activation='relu',name = 'Dense0'))\nmodel.add(Dense(256, activation='relu',name = 'Dense1'))\nmodel.add(Dense(128, activation='relu',name = 'Dense2'))\nmodel.add(Dropout(0.3,name='dropout4'))\nmodel.add(Dense(2, activation='softmax',name = 'Dense3'))\n\nmodel.compile(loss=\"sparse_categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])","c3acc893":"checkpoint = ModelCheckpoint(filepath = 'cnn.hdf5', verbose = 1, save_best_only = True)","5207e090":"earlystop = EarlyStopping(monitor = 'val_loss', # value being monitored for improvement\n                          min_delta = 0, #Abs value and is the min change required before we stop\n                          patience = 15, #Number of epochs we wait before stopping \n                          verbose = 1,\n                          restore_best_weights = True) #keeps the best weigths once stopped","1fcfd643":"ReduceLR = ReduceLROnPlateau(patience=3, verbose=1)","2fec017b":"callbacks = [earlystop, checkpoint, ReduceLR]","bddcce3e":"history = model.fit_generator(datagen.flow(x_train, y_train, batch_size= 32), epochs = 80, verbose=1,callbacks = callbacks,validation_data=(x_valid,y_validate))","3246bafe":"import pickle\n\npickle_out = open(\"Trained_cnn_history.pickle\",\"wb\")\npickle.dump(history.history, pickle_out)\npickle_out.close()","cafad3dc":"pickle_in = open(\"Trained_cnn_history.pickle\",\"rb\")\nsaved_history = pickle.load(pickle_in)\nprint(saved_history)","4535776f":"import matplotlib.pyplot as plt\n\n# Plot training & validation accuracy values\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validate'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validate'], loc='upper left')\nplt.show()","58731e3b":"model = load_model('cnn.hdf5')\nmodel.load_weights('cnn.hdf5')","90dbb071":"score = model.evaluate(x_test,y_test,verbose=0)\nprint('Test Loss :',score[0])\nprint('Test Accuracy :',score[1])","b37409a6":"#get the predictions for the test data\npredicted_classes = model.predict_classes(x_test)","f0b1fdb4":"confusion_mtx = confusion_matrix(y_test, predicted_classes) \n\nplt.imshow(confusion_mtx, interpolation='nearest', cmap=plt.cm.Blues)\nplt.title('confusion_matrix')\nplt.colorbar()\ntick_marks = np.arange(2)\nplt.xticks(tick_marks, ['R','O'], rotation=90)\nplt.yticks(tick_marks, ['R','O'])\n#Following is to mention the predicated numbers in the plot and highligh the numbers the most predicted number for particular label\nthresh = confusion_mtx.max() \/ 2.\nfor i, j in itertools.product(range(confusion_mtx.shape[0]), range(confusion_mtx.shape[1])):\n    plt.text(j, i, confusion_mtx[i, j],\n    horizontalalignment=\"center\",\n    color=\"white\" if confusion_mtx[i, j] > thresh else \"black\")\n\nplt.tight_layout()\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","2733905a":"Load the saved history:","90670f3a":"Save the model when the lowest loss is achieved during epochs training iterations.","a97f09be":"Let's save the history file","f079816f":"Let's plot the confusion matrix","fcf030bf":"We need to convert jpg file to numpy array to feed to the CNN.<br>\nOpencv library is used to perform this task.","4eb05429":"Also stop the training the model if the loss is not decreasing with epochs training iterations","e3896b26":"Reduce the learning rate if improvemnt is not seen for 'patience' number of epochs.This helps to have a smooth learning curve.","2e1ab64b":"In this case data is not available in form of csv files.<br>\nIt is in form of image files grouped based on the classes as a folder name.","68416f34":"Wide range of items are available to classify whether it can be recycle or not.<br>\nIt is difficult to achieve good accuracy with a CNN created from scratch and this dataset.<br>\nHere transfer learning is performs better than a CNN from scratch but still I want to try it out.<br>\nThe following CNN architecture is inspired from VGG architecture. But it is not as bulky as VGG.<br>\nHere adding additional convolution layers to have a better accuracy."}}