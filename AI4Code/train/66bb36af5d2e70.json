{"cell_type":{"6cdfa697":"code","572d6a78":"code","2e935f5a":"code","52fd3560":"code","8dd42772":"code","b7fbbd34":"code","0a73e6c0":"code","6a618dcc":"markdown","373afb5e":"markdown","96c8a102":"markdown","aeb66868":"markdown","622f512a":"markdown","2c2fa3f9":"markdown","9d50e031":"markdown","5a9145ca":"markdown"},"source":{"6cdfa697":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\n\nimport os\nprint(os.listdir(\"..\/input\"))","572d6a78":"iris_data = pd.read_csv(\"..\/input\/Iris.csv\");\niris_data.head()","2e935f5a":"iris_data.info()","52fd3560":"iris_data['Species'].value_counts()","8dd42772":"sns.pairplot(iris_data.drop(['Id'],axis=1), hue = 'Species')","b7fbbd34":"#Classification Preparation\nfrom sklearn.model_selection import train_test_split\n\nX = iris_data.drop(['Species','Id'],axis=1)\ny = iris_data['Species']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,shuffle=True, random_state=100, test_size=0.5)","0a73e6c0":"from sklearn import metrics\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nmodelKNN = KNeighborsClassifier(n_neighbors=5)\nmodelDT = DecisionTreeClassifier(random_state=0, max_depth=2)\n\nmodelKNN.fit(X_train,y_train)\nmodelDT.fit(X_train,y_train)\n\npredictedKNN = modelKNN.predict(X_test)\npredictedDT = modelDT.predict(X_test)\n\nprint(\"Accuracy with K-Nearest Neighbors:\",metrics.accuracy_score(y_test,predictedKNN))\nprint(\"Accuracy with Decision Tree:\",metrics.accuracy_score(y_test,predictedDT))","6a618dcc":"I want to know how many class in this dataset and how much data on this class.","373afb5e":"## Classification","96c8a102":"## Preparation","aeb66868":"I want to check the missing data on this dataset but I don't found any missing data.","622f512a":"This dataset is well distributed because I can see the data is not mixed and well distributed and there should be no need to use complicated algorithms.","2c2fa3f9":"For this prediction, I will use Simple Algorithm of KNN and Decision Tree with default parameter and the result is 96% from KNN with 5 neighbors and 94.7% from Decision Tree with maximum depth 2. From this experiment we can see KNN algorithm is better than Decision Tree for Iris classification.","9d50e031":"## Visualize","5a9145ca":"I will use simple visualization using pairplot on seaborn and I will see how the data spread from this dataset."}}