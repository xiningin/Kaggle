{"cell_type":{"7bc3b1bf":"code","3c6973e8":"code","e2a6356f":"code","c5c3853b":"code","3f386bd8":"code","798dff2f":"code","adc79ed3":"code","d879b074":"code","ac902c4d":"code","73360c1e":"code","2f9bf1a7":"code","7e42d2ce":"code","eaec0e0c":"code","9b94a9d8":"code","31d9bf74":"code","766f51ff":"code","2a69caab":"code","13a073f1":"code","87c3f424":"code","2198bb78":"code","6adcf179":"code","0c82924d":"code","6e1cccdd":"code","9b062e17":"code","df78b303":"code","1570cae4":"code","00040efa":"code","115cb8d3":"code","f6f9ddc6":"code","85dfce71":"code","ce4c4ae0":"code","25eeedd9":"code","846f3c30":"code","757b8fe8":"code","999b615d":"code","cf244a4a":"code","80597ee3":"code","edde29da":"code","b79161c4":"markdown","87139e38":"markdown","06b67010":"markdown","190c8e86":"markdown","ab545f7d":"markdown","ee0e6060":"markdown","ee7ff471":"markdown","6477a9cc":"markdown","7de15ab2":"markdown","d2ce4b2b":"markdown","2581fd44":"markdown","9c5a5a0c":"markdown","4c62a9a5":"markdown","89b96901":"markdown"},"source":{"7bc3b1bf":"import cv2\nimport numpy as np\nfrom glob import glob\nfrom tqdm import tqdm\nimport pandas as pd\nimport seaborn as sns; sns.set()\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nfrom sklearn.model_selection import train_test_split\n\nimport os\nprint(os.listdir(\"..\/input\"))\nprint(os.listdir())","3c6973e8":"seed = 42\nversion=117\nnp.random.seed(seed)\ndf = pd.read_csv('..\/input\/train.csv')\ndf[['ImageId', 'ClassId']] = df['ImageId_ClassId'].str.split('_', expand=True)\ndf['path'] = '..\/input\/train_images\/' + df['ImageId']\n\n# Dataframe containing only defects\nedf = df[df['EncodedPixels'].notnull()]\nedf.head()","e2a6356f":"def get_binary_mask(encoded_pixels, input_shape=(256, 1600)):\n    # run length encoding (rle)\n    height, width = input_shape[:2]\n    mask= np.zeros(width*height).astype(np.uint8)\n    array = np.asarray([int(x) for x in encoded_pixels.split()])\n    \n    starts = array[0::2]\n    lengths = array[1::2]\n\n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n    return mask.reshape(width, height).T\n\ndef mask_to_image(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef plot_img(path, pixels=None, title=None, figsize=(10, 10)):\n    base_img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    if pixels is not None:\n        mask = get_binary_mask(pixels, (256, 1600))\n        base_img[mask==1] = 255\n    fig = plt.figure(figsize=figsize)\n    plt.title(title)\n    plt.imshow(base_img, cmap='gray'); plt.show()\n    return base_img","c5c3853b":"# Visualize images with their masks\nfor sample in edf.sample(5).itertuples(index=False):\n    _ = plot_img(sample.path, sample.EncodedPixels, title=sample.ImageId_ClassId)","3f386bd8":"# How many defects per image\nedf.groupby(['ImageId']).agg({'ClassId': 'count'})['ClassId'].value_counts().plot(kind='bar')","798dff2f":"# How many defects by classId\nedf['ClassId'].value_counts().plot(kind='bar')","adc79ed3":"!mkdir augmented_img\nprint(os.listdir('.'))","d879b074":"def upsample(ids, edf):\n    if ids in ['1', '4']:\n        edf2 = edf[edf['ClassId'] == ids].sample(200, random_state=seed)\n    else:\n        edf2 = edf[edf['ClassId'] == ids]\n    \n    def hflip(img):\n        # Horizontal flip\n        return np.flip(img, 0)\n\n    def vflip(img):\n        # Vertical flip\n        return np.flip(img, 1)\n\n    augmented_dict = {'EncodedPixels': [], 'ImageId': [], 'ClassId': [], 'path': [], 'ImageId_ClassId': []}\n\n    def update_dict(adict, pixels, image, cid, path):\n        adict['EncodedPixels'].append(pixels)\n        adict['ImageId'].append(image)\n        adict['ClassId'].append(cid)\n        adict['path'].append(path)\n        adict['ImageId_ClassId'].append(image + '_' + cid)\n        return augmented_dict\n\n    for img2 in edf2.itertuples(index=False):\n        img = cv2.imread(img2.path, cv2.IMREAD_GRAYSCALE)\n        mask = get_binary_mask(img2.EncodedPixels)\n\n        himg = hflip(img)\n        hmask = mask_to_image(hflip(mask))\n        vimg = vflip(img)\n        vmask = mask_to_image(vflip(mask))\n\n        himg_path = 'augmented_img\/h' + img2.ImageId.replace('jpg', 'png')\n        vimg_path = 'augmented_img\/v' + img2.ImageId.replace('jpg', 'png')\n\n        augmented_dict = update_dict(augmented_dict, hmask, 'h'+img2.ImageId, img2.ClassId, path=himg_path)\n        augmented_dict = update_dict(augmented_dict, vmask, 'v'+img2.ImageId, img2.ClassId, path=vimg_path)\n\n        cv2.imwrite(f'{himg_path}', himg)\n        cv2.imwrite(f'{vimg_path}', vimg)\n\n    edf = pd.concat([edf, pd.DataFrame(augmented_dict)])\n    return edf\n\nedf = upsample('2', edf).reset_index(drop=True)","ac902c4d":"# Add masks to the dataframe\nedf.loc[:, 'mask'] = edf['EncodedPixels'].map(get_binary_mask)\n\n# Get a count of the number of pixels in each mask\nedf.loc[:, 'pixel_count'] = edf['mask'].map(lambda x: x.ravel().sum())\nedf.head()","73360c1e":"edf.groupby(['ClassId']).agg({'pixel_count': 'sum'}).plot.pie(subplots=True, figsize=(5, 10))","2f9bf1a7":"# Get largest defect size\nlargest = edf.loc[edf['pixel_count'].idxmax()]\n# Get smallest defect size\nsmallest = edf.loc[edf['pixel_count'].idxmin()]","7e42d2ce":"smask = plot_img(smallest['path'], smallest['EncodedPixels'], figsize=(15,10), title=smallest['ImageId_ClassId'])\nprint(f'Smallest mask: {smask[smask == 255].shape}')","eaec0e0c":"lmask = plot_img(largest['path'], largest['EncodedPixels'], figsize=(15,10), title=largest['ImageId_ClassId'])","9b94a9d8":"mask = smallest\nkernel = np.ones((3, 3),np.uint8)\nso_mask = mask_to_image(cv2.morphologyEx(mask['mask'], cv2.MORPH_OPEN, kernel))\nnew_img = plot_img(mask['path'], so_mask, figsize=(15,10), title=mask['ImageId_ClassId'])","31d9bf74":"img1 = new_img[210:230, 1090:1120]\nprint(img1[img1 == 255].shape)\nplt.imshow(img1); plt.show()","766f51ff":"edf.groupby(['ClassId']).agg({'pixel_count': 'describe'})","2a69caab":"plabel = edf['pixel_count'].sum()\ntotal_pixels = 256 * 1600 * edf.shape[0]\nprint(f'Positive label: {plabel}, total pixels: {total_pixels} positive_pct: {plabel \/ total_pixels}')","13a073f1":"def balance_df(df, sample=None):\n    if sample:\n        ndf = pd.DataFrame()\n        for i in ['1', '2', '3', '4']:\n            tdf = df[df['ClassId'] == i].sample(sample, random_state=seed)\n            ndf = pd.concat([ndf, tdf])\n        return ndf\n    else:\n        minor_edf = df[df['ClassId'].isin(['1', '2', '4'])]\n        sampled_df = df[df['ClassId'] == '3'].sample(replace=False, n=5000, random_state=seed)\n        \n        return pd.concat([minor_edf, sampled_df])\n\n# Some models can preform better when the distribution for ClassIds are about the same\n# However I am not doing that here, it's an option\ntdf = balance_df(edf).reset_index(drop=True)\ntdf['ClassId'].value_counts()","87c3f424":"train, valid = train_test_split(tdf.index, test_size=0.15, random_state=seed)\nprint('train:{}\\tvalid:{}\\ttdf:{}\\tdf:{}'.format(train.shape, valid.shape, tdf.shape, edf.shape))\nprint(tdf.loc[train]['ClassId'].value_counts())\nprint(tdf.loc[valid]['ClassId'].value_counts())","2198bb78":"#https:\/\/github.com\/qubvel\/segmentation_models\n! pip install segmentation-models","6adcf179":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport keras\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras import applications\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.losses import binary_crossentropy\nfrom keras.regularizers import l2, l1\nfrom keras.layers import GaussianNoise\nfrom keras import optimizers\nfrom keras.initializers import he_normal, glorot_uniform\nfrom keras import initializers\nfrom keras.models import Sequential, Model, load_model, Input\nfrom keras.layers import Dropout, Flatten, Dense, Conv2D, Add, BatchNormalization, Activation, MaxPooling2D, Layer, InputSpec, Conv2DTranspose, UpSampling2D, concatenate, GlobalAveragePooling2D, ZeroPadding2D\nfrom keras.layers.core import SpatialDropout2D, Activation\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping, ReduceLROnPlateau","0c82924d":"img_height, img_width = 256, 1600\nbatch = 256\nBATCH_SIZE = 5\nEPOCHS = 15\nN_CLASS = 4\n\nstrided = True\nLEARNING_RATE = 1e-5","6e1cccdd":"def dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1-dice_coef(y_true, y_pred)\n\ndef tversky_loss(y_true, y_pred, beta=0.75):\n    numerator = tf.reduce_sum(y_true * y_pred, axis=-1)\n    denominator = y_true * y_pred + beta * (1 - y_true) * y_pred + (1 - beta) * y_true * (1 - y_pred)\n    return 1 - (numerator + 1) \/ (tf.reduce_sum(denominator, axis=-1) + 1)\n\ndef binary_dice_coef_loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) + dice_coef_loss(y_true, y_pred)\n\ndef binary_tversky_loss(y_true, y_pred):\n    return tversky_loss(y_true, y_pred) + binary_crossentropy(y_true, y_pred)\n\ndef img_to_dataframe(img, depth=4):\n    df = pd.DataFrame({i: img[..., i].ravel() for i in range(depth)})\n    return df","9b062e17":"gamma = 2\ninverse_gamma = 1.0 \/ gamma\nlook_up_table = np.array([((i\/255.0) ** inverse_gamma) * 255.0 for i in np.arange(0,256,1)]).astype(\"uint8\")\nclahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n\ndef contrast_enhancement(img):\n    img = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n    img[:,:,0] = clahe.apply(img[:,:,0])\n    img = cv2.cvtColor(img, cv2.COLOR_YUV2RGB)\n    return img\n\ndef gamma_correction(img):\n    return cv2.LUT(img.astype('uint8'), look_up_table)","df78b303":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, df, mode='fit', batch_size=BATCH_SIZE, n_channels=1, reshape=None, n_classes=4, shuffle=True, strided=True):\n        self.batch_size = batch_size\n        self.df = df\n        self.mode = mode\n        self.list_IDs = list_IDs\n        self.reshape = reshape\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.strided = strided\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(np.floor(len(self.list_IDs) \/ self.batch_size))\n\n    def __getitem__(self, index):\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n        X = self.__generate_X(list_IDs_batch)\n        \n        # Pass a sliding window through the image to create 256 x 256\n        if self.strided:\n            Xn = []\n            for jj in X:\n                for i in range(0, 224 * 7, 224):\n                    nm = jj[:, i:i+batch]\n                    Xn.append(nm)\n            X = np.array(Xn)\n        \n        if self.mode == 'fit':\n            y = self.__generate_y(list_IDs_batch)\n            \n            # Pass a sliding window through the mask to create 256 x 256\n            if self.strided:\n                yn = []\n                for jj in y:\n                    for i in range(0, 224 * 7, 224):\n                        nm = jj[:, i:i+batch]\n                        yn.append(nm)\n                y = np.array(yn)            \n            return X, y\n        else:\n            return X\n\n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n    \n    def __generate_X(self, list_IDs_batch):\n        # Initialization\n        X = np.zeros((self.batch_size, *self.reshape, self.n_channels))\n        \n        for i, ID in enumerate(list_IDs_batch):\n            path = self.df['path'].iloc[ID]\n            img = self.__load_grayscale(path)\n            X[i, :] = img\n\n        return X\n    \n    def __generate_y(self, list_IDs_batch):\n        \n        y = np.zeros((self.batch_size, *self.reshape, self.n_classes), dtype=int)\n        \n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            image_df = self.df[self.df['ImageId'] == im_name][['ClassId', 'EncodedPixels']]\n            \n            masks = np.zeros((*self.reshape, 4))\n            for cid, pixel in image_df.itertuples(index=False):\n                masks[:, :, int(cid) - 1] = get_binary_mask(pixel)\n            y[i, :] = masks\n\n        return y\n    \n    def __load_grayscale(self, img_path):\n        img = cv2.imread(img_path)\n        img = contrast_enhancement(img)\n        img = gamma_correction(img)\n        img = img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) \/ 255.0\n        img = np.expand_dims(img, axis=-1)\n\n        return img\n","1570cae4":"salt = int(str(datetime.now().timestamp())[-1])\n\nsample=tdf.sample(1, random_state=seed+salt).index[0]\nprint(f'sample:{sample} seed:{seed} salt:{salt}')\ntrain_sample = [sample]\nX=0; Y=0;\ntrain_generator = DataGenerator(train_sample, df=tdf, reshape=(img_height, img_width), strided=strided, batch_size=1, shuffle=False, n_channels=1)\n\nfor x, y in train_generator:\n    X=x; \n    Y=y;\n    break\nprint(f'x: {X.shape}\\ty: {Y.shape}')","00040efa":"fi = plt.figure(figsize=(20,20))\nprint('ORIGINAL IMAGE')\nplt.imshow(cv2.imread(tdf.loc[sample]['path'], cv2.IMREAD_GRAYSCALE), cmap='gray')","115cb8d3":"print('BASE IMAGE WITH MASK')\nbase = plot_img(tdf.loc[sample]['path'], tdf.loc[sample]['EncodedPixels'], title=tdf.loc[sample]['ImageId'], figsize=(20, 15))","f6f9ddc6":"img = cv2.imread(tdf.loc[sample]['path'])\nfig = plt.figure(figsize=(20, 20))\nrow=1; col=7;\nprint('BASE IMAGE STRIDES')\nfor idx, i in enumerate(range(0, 224 * 7, 224)):\n    fig.add_subplot(row, col, idx+1)\n    nm = img[:, i:i+batch]\n    plt.imshow(nm)","85dfce71":"fig = plt.figure(figsize=(20, 20))\nrow=1; col=7;\nprint('GENERATED IMAGE STRIDES')\nif X.shape[-1] == 1:\n    Xr = np.repeat(X, repeats=3, axis=-1)\nelse:\n    Xr = X\nfor idx, i in enumerate(Xr):\n    fig.add_subplot(row, col, idx+1)\n    plt.imshow(i)","ce4c4ae0":"mask = get_binary_mask(tdf.loc[train_sample]['EncodedPixels'].values[0], input_shape=(256, 1600))\nfig = plt.figure(figsize=(20, 20))\nrow=1; col=7;\nprint('BASE MASK STRIDED')\nfor idx, i in enumerate(range(0, 224 * 7, 224)):\n    fig.add_subplot(row, col, idx+1)\n    nm = mask[:, i:i+batch]\n    plt.imshow(nm)","25eeedd9":"fig = plt.figure(figsize=(20, 20))\nrow=1; col=7;\nchannel = int(tdf.loc[train_sample]['ClassId'])-1\nYr = np.repeat(np.expand_dims(Y[..., channel], axis=-1), repeats=3, axis=-1)\nprint('GENERATED MASK STRIDED')\nfor idx, i in enumerate(Yr):\n    fig.add_subplot(row, col, idx+1)\n    plt.imshow(i * 255)","846f3c30":"from segmentation_models import Unet\nkeras.backend.set_image_data_format('channels_last')\n\nmodel = Unet('resnet34', input_shape=(256, 256, 1), classes=4, activation='sigmoid', encoder_weights=None)\nmodel.compile(optimizer=Adam(LEARNING_RATE), loss=binary_tversky_loss, metrics=[dice_coef])\nmodel.summary()","757b8fe8":"model_path = f'UNet_ResNet34_{LEARNING_RATE}_{EPOCHS}_{version}.h5'\n\ntrain_generator = DataGenerator(train, df=tdf, reshape=(img_height, 1600), strided=strided, n_channels=1)\nval_generator = DataGenerator(valid, df=tdf, reshape=(img_height, 1600), strided=strided, n_channels=1)\n\ncallbacks = [\n    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=1e-10, verbose=1),\n    ModelCheckpoint(model_path, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto')\n]\nhistory = model.fit_generator(train_generator, validation_data=val_generator, callbacks=callbacks, use_multiprocessing=False, epochs=EPOCHS)","999b615d":"hdf = pd.DataFrame(history.history)\nhdf.to_csv('v{}_history.df'.format(version), index=False)\nhdf[['loss', 'val_loss']].plot(grid=True, figsize=(15, 3), title='Loss Graphs')\nhdf[['dice_coef', 'val_dice_coef']].plot(grid=True, figsize=(15, 3), title='Val Graphs')","cf244a4a":"model = load_model(model_path, custom_objects={'dice_coef': dice_coef, 'dice_coef_loss': dice_coef_loss, 'binary_tversky_loss': binary_tversky_loss})","80597ee3":"def test_model(model, img, df):\n    test_df = df[df['ImageId'] == img]\n    \n    if test_df.shape[0] == 1:\n        test_df = test_df.iloc[0]\n    else:\n        test_df = test_df.iloc[1]\n    \n    img = cv2.imread(test_df['path'], cv2.IMREAD_GRAYSCALE)\n    \n    pred = np.zeros((256, 1600, 4))\n    for i in range(0, 224*7, 224):\n        nm = img[:, i:i+batch]\n        batch_pred = model.predict(np.expand_dims(np.expand_dims(nm, axis=-1), axis=0))[0]\n        pred[:, i:i+batch, :] = np.maximum(pred[:, i:i+batch, :], batch_pred)\n\n    pred = np.where(pred > 0.4, 1, 0)\n        \n    y_true = get_binary_mask(test_df['EncodedPixels'], (256, 1600))\n    final_mask = mask_to_image(pred[..., int(test_df['ClassId']) - 1])\n    \n    plot_img(test_df['path'], test_df['EncodedPixels'], title='true_' + test_df['ImageId_ClassId'])\n    plot_img(test_df['path'], final_mask, title='pred_' + test_df['ImageId_ClassId'])\n    \ntest_img = tdf.sample(10)['ImageId'].tolist()\nfor i in test_img: test_model(model, i, tdf)","edde29da":"!rm -rf augmented_img","b79161c4":"# Severstal Steel Defects\n\nSteel is one of the most important creations of man kind, without it we would have much of our infrasstrucuter. Although steel is a very efficient componenent to most structures it has it's faults. This competition aim to build a model to find those faults so they can be addressed.\n\nIn this kernel I use UNet_ResNet34 on 256x256 images. The original images are not resized but broken into batches of 256x256 with a 224 sliding window.\nThis approach offers \"better\" training as the inputs are much smaller but at the cost of more work in the pot processing phase.","87139e38":"The distribution of the defect classIds","06b67010":"Remove images that were created; kaggle has a 500 files max","190c8e86":"Creating the model","ab545f7d":"The code below was taken from another author but I can't find it at the moment\nThe idea is to give the network more to work with by modifying the contrast in the input image","ee0e6060":"Validation Datagenerator was implemented correctly","ee7ff471":"Very few of the pixels actually contain defects\nThe positive pixel count makes it clear that removing flase positives (FP) will be key to a successful model","6477a9cc":"Defect size distribution by classId","7de15ab2":"Investigate edge cases, images with the largest and smallest masks","d2ce4b2b":"Loss functions","2581fd44":"It suprising that ClassId 3 contains the smallest mask and is the most common, I was thinking ClassId 2 would contain the smallest mask","9c5a5a0c":"From the above it's abvious that ID 2 is greatly under represented, we can upsample by copying the same images or using some data augmentation.\nThe code below upsamples classId 2 by taking vertical and horizontal flips\n","4c62a9a5":"Methods for converting the rle to numpy arrays and the reverse as well as plotting the images","89b96901":"Test the model"}}