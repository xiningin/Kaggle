{"cell_type":{"db681d87":"code","e982ec46":"code","28d12a0e":"code","6bd90172":"code","d8f1e23c":"code","7f9ecdf9":"code","dcdfdc64":"code","36577a64":"code","d72eaad0":"code","58ee0d29":"code","37969e0c":"code","4632674e":"code","f3b0242d":"code","0d8807a3":"code","4f9997a6":"code","528d09a4":"code","e6d606e6":"code","8f5ade2d":"code","367ebb54":"code","c3a98c77":"code","151214d0":"code","7ead4864":"code","1d8ededd":"code","ba4c1bad":"code","0ab8ce8c":"code","c8e728ef":"code","9f46d816":"code","090e5766":"code","4d55282d":"code","aa7d8b8b":"code","227b03a4":"markdown","88448177":"markdown","2d3a9dea":"markdown","b57bdd23":"markdown","b41a721d":"markdown","56287823":"markdown","5566e118":"markdown"},"source":{"db681d87":"# Importing Libraries\n\n# Provides OS realted functions\nimport os \n\n# For Image Manipulation\nfrom skimage.data import imread\nfrom skimage.morphology import label\n\n# For Data Manipulation and Analysis\nimport pandas as pd\nimport numpy as np\n\n# Deep Learning Library\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\n\n# Other utilities\nimport random\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split","e982ec46":"# Directories Paths\ninput_dir = '..\/input\/'\ntrain_dir = '..\/input\/train_v2\/'\ntest_dir = '..\/input\/test_v2\/'","28d12a0e":"# Reading Training Data\ntrain_df = pd.read_csv(input_dir+'train_ship_segmentations_v2.csv')\n\ntrain_df.head()","6bd90172":"train_df.shape","d8f1e23c":"# Removing Bug Images\ntrain_df = train_df[train_df['ImageId'] != '6384c3e78.jpg']","7f9ecdf9":"train_df.shape","dcdfdc64":"# Removing 10000 non-ship Images\ndef area_isnull(x):\n    if x == x:\n        return 0\n    else:\n        return 1","36577a64":"train_df['isnan'] = train_df['EncodedPixels'].apply(area_isnull)","d72eaad0":"train_df = train_df.sort_values('isnan', ascending=False)\ntrain_df = train_df.iloc[100000:]","58ee0d29":"train_df['isnan'].value_counts()","37969e0c":"# Helper Functions\ndef rle_to_mask(rle_list, SHAPE):\n    tmp_flat = np.zeros(SHAPE[0]*SHAPE[1])\n    if len(rle_list) == 1:\n        mask = np.reshape(tmp_flat, SHAPE).T\n    else:\n        strt = rle_list[::2]\n        length = rle_list[1::2]\n        for i,v in zip(strt,length):\n            tmp_flat[(int(i)-1):(int(i)-1)+int(v)] = 255\n        mask = np.reshape(tmp_flat, SHAPE).T\n    return mask","4632674e":"def calc_area_for_rle(rle_str):\n    rle_list = [int(x) if x.isdigit() else x for x in str(rle_str).split()]\n    if len(rle_list) == 1:\n        return 0\n    else:\n        area = np.sum(rle_list[1::2])\n        return area","f3b0242d":"train_df['area'] = train_df[\"EncodedPixels\"].apply(calc_area_for_rle)","0d8807a3":"train_df_isship = train_df[train_df['area'] > 0]","4f9997a6":"train_df_isship.shape","528d09a4":"train_df_smallarea = train_df_isship['area'][train_df_isship['area'] < 10]","e6d606e6":"train_df_smallarea.shape","8f5ade2d":"train_df_smallarea.shape[0]\/train_df_isship.shape[0]","367ebb54":"train_gp = train_df.groupby('ImageId').sum()\ntrain_gp = train_gp.reset_index()","c3a98c77":"train_gp.head()","151214d0":"def calc_class(area):\n    area = area \/ (768*768)\n    if area == 0:\n        return 0\n    elif area < 0.005:\n        return 1\n    elif area < 0.015:\n        return 2\n    elif area < 0.025:\n        return 3\n    elif area < 0.035:\n        return 4\n    elif area < 0.045:\n        return 5\n    else:\n        return 6","7ead4864":"train_gp['class'] = train_gp['area'].apply(calc_class)","1d8ededd":"train_gp['class'].value_counts()","ba4c1bad":"train, val = train_test_split(train_gp, test_size=0.01, stratify=train_gp['class'].tolist())","0ab8ce8c":"train_isship_list = train['ImageId'][train['isnan']==0].tolist()\ntrain_isship_list = random.sample(train_isship_list, len(train_isship_list))\ntrain_nanship_list = train['ImageId'][train['isnan']==1].tolist()\ntrain_nanship_list = random.sample(train_nanship_list, len(train_nanship_list))\n","c8e728ef":"# data generator\n\ndef mygenerator(isship_list, nanship_list, batch_size, cap_num):\n    train_img_names_nanship = isship_list[:cap_num]\n    train_img_names_isship = nanship_list[:cap_num]\n    k = 0\n    while True:\n        if k+batch_size\/\/2 >= cap_num:\n            k = 0\n        batch_img_names_nan = train_img_names_nanship[k:k+batch_size\/\/2]\n        batch_img_names_is = train_img_names_isship[k:k+batch_size\/\/2]\n        batch_img = []\n        batch_mask = []\n        for name in batch_img_names_nan:\n            tmp_img = imread(train_dir + name)\n            batch_img.append(tmp_img)\n            mask_list = train_df['EncodedPixels'][train_df['ImageId'] == name].tolist()\n            one_mask = np.zeros((768, 768, 1))\n            for item in mask_list:\n                rle_list = str(item).split()\n                tmp_mask = rle_to_mask(rle_list, (768, 768))\n                one_mask[:,:,0] += tmp_mask\n            batch_mask.append(one_mask)\n        for name in batch_img_names_is:\n            tmp_img = imread(train_dir + name)\n            batch_img.append(tmp_img)\n            mask_list = train_df['EncodedPixels'][train_df['ImageId'] == name].tolist()\n            one_mask = np.zeros((768, 768, 1))\n            for item in mask_list:\n                rle_list = str(item).split()\n                tmp_mask = rle_to_mask(rle_list, (768, 768))\n                one_mask[:,:,0] += tmp_mask\n            batch_mask.append(one_mask)\n        img = np.stack(batch_img, axis=0)\n        mask = np.stack(batch_mask, axis=0)\n        img = img \/ 255.0\n        mask = mask \/ 255.0\n        k += batch_size\/\/2\n        yield img, mask\n","9f46d816":"BATCH_SIZE = 2\nCAP_NUM = min(len(train_isship_list),len(train_nanship_list))\ndatagen = mygenerator(train_isship_list, train_nanship_list, batch_size=BATCH_SIZE, cap_num=CAP_NUM)","090e5766":"inputs = Input(shape=(768,768,3))\nconv0 = Conv2D(8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\nconv0 = BatchNormalization()(conv0)\nconv0 = Conv2D(8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv0)\nconv0 = BatchNormalization()(conv0)\n\ncomp0 = AveragePooling2D((6,6))(conv0)\nconv1 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(comp0)\nconv1 = BatchNormalization()(conv1)\nconv1 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\nconv1 = BatchNormalization()(conv1)\nconv1 = Dropout(0.4)(conv1)\n\npool1 = MaxPooling2D(pool_size=(2,2))(conv1)\nconv2 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\nconv2 = BatchNormalization()(conv2)\nconv2 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\nconv2 = BatchNormalization()(conv2)\nconv2 = Dropout(0.4)(conv2)\n\npool2 = MaxPooling2D(pool_size=(2,2))(conv2)\nconv3 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\nconv3 = BatchNormalization()(conv3)\nconv3 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\nconv3 = BatchNormalization()(conv3)\nconv3 = Dropout(0.4)(conv3)\n\npool3 = MaxPooling2D(pool_size=(2,2))(conv3)\nconv4 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\nconv4 = BatchNormalization()(conv4)\nconv4 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\nconv4 = BatchNormalization()(conv4)\nconv4 = Dropout(0.4)(conv4)\n\npool4 = MaxPooling2D(pool_size=(2,2))(conv4)\nconv5 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\nconv5 = BatchNormalization()(conv5)\nconv5 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\nconv5 = BatchNormalization()(conv5)\n\nupcv6 = UpSampling2D(size=(2,2))(conv5)\nupcv6 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(upcv6)\nupcv6 = BatchNormalization()(upcv6)\nmrge6 = concatenate([conv4, upcv6], axis=3)\nconv6 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(mrge6)\nconv6 = BatchNormalization()(conv6)\nconv6 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\nconv6 = BatchNormalization()(conv6)\n\nupcv7 = UpSampling2D(size=(2,2))(conv6)\nupcv7 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(upcv7)\nupcv7 = BatchNormalization()(upcv7)\nmrge7 = concatenate([conv3, upcv7], axis=3)\nconv7 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(mrge7)\nconv7 = BatchNormalization()(conv7)\nconv7 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\nconv7 = BatchNormalization()(conv7)\n\nupcv8 = UpSampling2D(size=(2,2))(conv7)\nupcv8 = Conv2D(32, 2, activation='relu', padding='same', kernel_initializer='he_normal')(upcv8)\nupcv8 = BatchNormalization()(upcv8)\nmrge8 = concatenate([conv2, upcv8], axis=3)\nconv8 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(mrge8)\nconv8 = BatchNormalization()(conv8)\nconv8 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\nconv8 = BatchNormalization()(conv8)\n\nupcv9 = UpSampling2D(size=(2,2))(conv8)\nupcv9 = Conv2D(16, 2, activation='relu', padding='same', kernel_initializer='he_normal')(upcv9)\nupcv9 = BatchNormalization()(upcv9)\nmrge9 = concatenate([conv1, upcv9], axis=3)\nconv9 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(mrge9)\nconv9 = BatchNormalization()(conv9)\nconv9 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\nconv9 = BatchNormalization()(conv9)\n\ndcmp10 = UpSampling2D((6,6), interpolation='bilinear')(conv9)\nmrge10 = concatenate([dcmp10, conv0], axis=3)\nconv10 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(mrge10)\nconv10 = BatchNormalization()(conv10)\nconv10 = Conv2D(8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv10)\nconv10 = BatchNormalization()(conv10)\nconv11 = Conv2D(1, 1, activation='sigmoid')(conv10)\n\nmodel = Model(inputs=inputs, outputs=conv11)\n","4d55282d":"model.compile(optimizer='adam', loss='binary_crossentropy')","aa7d8b8b":"history = model.fit_generator(datagen, steps_per_epoch = 500, epochs = 10)","227b03a4":"These are some helper functions that will help in calculating the ship area and will group them by imageId","88448177":"# Airbus Ship Detection","2d3a9dea":"Splitting data into train and validation set","b57bdd23":"Creat","b41a721d":"In this kernel, we will create a model that will help us detect ships in a sattelite image. Our task is to locate the ships in the image and put an aligned bounding box around them. Ships can differ in size and some images may not even have ships.","56287823":"**train_ship_segmentation_v2.csv**: This file contains the [Run Length Encoded](https:\/\/en.wikipedia.org\/wiki\/Run-length_encoding) Masks of ships in the image.","5566e118":"Now we will set the class for ship area"}}