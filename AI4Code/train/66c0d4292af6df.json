{"cell_type":{"26b26471":"code","754f4613":"code","6beecaff":"code","9d0c38a5":"code","6d54bc8f":"code","9752250a":"code","92807a74":"code","4f5c4085":"code","50e5946a":"code","29356022":"code","4c3234b7":"code","d1c88126":"code","0f6175a3":"code","b7f95335":"code","f1d50a4b":"code","f07e0ac9":"code","7d8cc2ff":"code","ee53a355":"code","7cbd04ec":"code","1a176574":"code","e602a440":"code","5aadf85d":"code","013fe9e8":"code","6f665806":"code","c1014aae":"code","72860813":"code","3e313370":"code","2bffc6e3":"code","ab0f49eb":"code","4cc667f3":"code","48d928f2":"code","8738f617":"code","bfd43f93":"code","0633392c":"code","8cbe293a":"code","9ac68e10":"code","93b45217":"code","3418224e":"code","e644fc63":"code","ee13a3aa":"code","0a94e1df":"code","5388682a":"code","e7408db4":"code","d9807d48":"code","c6f85df6":"code","2ca39e6c":"code","647b3b3b":"code","ba93ffe8":"code","46058b0d":"code","24efb0dd":"code","23abb8e6":"code","c6af5c99":"code","7562fd1e":"code","9c702d19":"code","c12f0243":"code","f4a8dba0":"code","952d8bd1":"code","f92b685e":"code","76b7c60c":"code","6117e72d":"code","2717c5c7":"code","771570ea":"code","9a71e2ca":"code","d68d434f":"code","3296a35f":"code","392e80a3":"code","9ff5c93c":"code","701e0340":"code","e44ccd88":"code","3891ea02":"code","607b2509":"code","7eed6029":"code","ec670e3f":"code","f97423c8":"code","c3861522":"code","ed66e4b8":"code","dafa4be8":"code","766f6edc":"markdown","52554f53":"markdown","91a0e019":"markdown","b4fd06f3":"markdown","1d886255":"markdown","1e27255e":"markdown","4d992d05":"markdown","861b2417":"markdown","efc3b8d5":"markdown"},"source":{"26b26471":"import pandas as pd\nimport tensorflow\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D,AveragePooling2D, Flatten, Dense, Dropout, Activation , Concatenate, Input , BatchNormalization\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras import activations\n\n%matplotlib inline","754f4613":"# load data\ndf_train = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')\ndf_test = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv')","6beecaff":"df_train.head()","9d0c38a5":"df_train.label.value_counts()","6d54bc8f":"df_test.head()","9752250a":"df_test.label.value_counts()","92807a74":"df_train.columns","4f5c4085":"# split our data into features & target\ntrainX = df_train.drop('label', axis=1).values\ntrainy = df_train['label'].values.reshape(-1,1)\n\ntestX = df_test.drop('label', axis=1).values\ntesty = df_test['label'].values.reshape(-1,1)","50e5946a":"trainX[:5]","29356022":"trainy[:5]","4c3234b7":"# summarize loaded dataset\nprint('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\nprint('Test: X=%s, y=%s' % (testX.shape , testy.shape))","d1c88126":"# plot first few images\nfor i in range(9):\n    img = trainX[i].reshape(28,28)\n    # define subplot\n    plt.subplot(330 + 1 + i)\n    # plot raw pixel data\n    plt.imshow(img)\n    \n# show the figure\nplt.show()","0f6175a3":"# reshape dataset to have a single channel\ntrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\ntestX = testX.reshape((testX.shape[0], 28, 28, 1))\n# one hot encode target values\ntrainy = to_categorical(trainy)\ntesty = to_categorical(testy)","b7f95335":"# convert from integers to floats\ntrainX = trainX.astype('float32')\ntestX = testX.astype('float32')\n# normalize to range 0-1\ntrainX = trainX \/ 255.0\ntestX = testX \/ 255.0","f1d50a4b":"print(trainX.shape)","f07e0ac9":"datagen = ImageDataGenerator(\n        validation_split = 0.2,\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=True)  # randomly flip images","7d8cc2ff":"batch_size = 128\nTraining_data = datagen.flow(trainX,\n                             y=trainy,\n                            batch_size = batch_size,\n                            subset = 'training')\n\nValidation_data = datagen.flow(trainX,\n                             y=trainy,\n                            batch_size = batch_size,\n                            subset = 'validation')","ee53a355":"es = EarlyStopping(monitor='val_loss',\n                   mode='auto',\n                   verbose=1,\n                   patience=7)\n\nlrr= ReduceLROnPlateau(monitor='val_loss',\n                       factor=0.1, \n                       patience=5, \n                       min_lr=1e-10)","7cbd04ec":"input_model = Input((trainX.shape[1],trainX.shape[2],trainX.shape[3]),name = 'input_layer')\n\nmodel1 = Conv2D(32,(5,5), activation='relu',name = 'Conv1_5')(input_model)\nmodel1 = BatchNormalization(name = 'Bnorm1')(model1)\nmodel1 = Conv2D(32,(5,5), activation='relu', padding='same',name= 'Conv2_5')(model1)\nmodel1 = BatchNormalization(name = 'Bnorm2')(model1)\nmodel1 = MaxPooling2D((2, 2),name = 'MaxPool1')(model1)\nmodel1 = Conv2D(64,(3,3), activation='relu' ,padding='same',name = 'Conv3_3')(model1)\nmodel1 = BatchNormalization(name = 'Bnorm3')(model1)\nmodel1 = Conv2D(64,(3,3), activation='relu' ,padding='same',name = 'Conv4_3')(model1)\nmodel1 = BatchNormalization(name = 'Bnorm4')(model1)\nmodel1 = AveragePooling2D((2, 2),name = 'AvgPool1')(model1)\nmodel1 = Conv2D(128,(1,1), activation='relu' ,padding='valid',name = 'Conv5_1')(model1)\nmodel1 = BatchNormalization(name = 'Bnorm5')(model1)\n########################################################\nmodel1 = Flatten(name = 'Flatten')(model1)\n########################################################\nmodel1 = Dense(units = 128, activation = 'relu')(model1)\nmodel1 = Dropout(rate = 0.2)(model1)\nmodel1 = BatchNormalization()(model1)\nmodel1 = Dense(units = 20, activation = 'relu')(model1)\nmodel1 = BatchNormalization()(model1)\nmodel1 = Dense(units = 15, activation = 'relu')(model1)\nmodel1 = BatchNormalization()(model1)\noutput = Dense(units = 10, activation = 'softmax' , name='preds')(model1)\n\nmodel = Model(inputs= [input_model], outputs=[output])\nmodel.summary()","1a176574":"plot_model(model, show_shapes=True)","e602a440":"sgd = SGD(lr=0.001, momentum=0.9)\nmodel.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])","5aadf85d":"history = model.fit(Training_data, \n                              epochs= 50,\n                              validation_data= Validation_data,\n                              verbose=1,\n                              callbacks=[es , lrr])","013fe9e8":"model.save_weights(\"MNIST_weights.h5\")","6f665806":"val_loss = history.history['val_loss']\nloss = history.history['loss']\n\nplt.plot(val_loss)\nplt.plot(loss)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['Val error','Train error'], loc='upper right')\nplt.savefig('plot_error.png')\nplt.show()","c1014aae":"val_accuracy = history.history['val_accuracy']\naccuracy = history.history['accuracy']\n\nplt.plot(val_accuracy)\nplt.plot(accuracy)\nplt.xlabel('Epochs')\nplt.ylabel('accuracy')\nplt.legend(['Val accuracy','Train accuracy'], loc='upper right')\nplt.savefig( 'plot_accuracy.png')\nplt.show()","72860813":"input_model = Input((trainX.shape[1],trainX.shape[2],trainX.shape[3]),name = 'input_layer')\n\nmodel1 = Conv2D(32,(5,5), activation='tanh',name = 'Conv1_5')(input_model)\nmodel1 = BatchNormalization(name = 'Bnorm1')(model1)\nmodel1 = Conv2D(32,(5,5), activation='tanh', padding='same',name= 'Conv2_5')(model1)\nmodel1 = BatchNormalization(name = 'Bnorm2')(model1)\nmodel1 = MaxPooling2D((2, 2),name = 'MaxPool1')(model1)\nmodel1 = Conv2D(64,(3,3), activation='tanh' ,padding='same',name = 'Conv3_3')(model1)\nmodel1 = BatchNormalization(name = 'Bnorm3')(model1)\nmodel1 = Conv2D(64,(3,3), activation='tanh' ,padding='same',name = 'Conv4_3')(model1)\nmodel1 = BatchNormalization(name = 'Bnorm4')(model1)\nmodel1 = AveragePooling2D((2, 2),name = 'AvgPool1')(model1)\nmodel1 = Conv2D(128,(1,1), activation='tanh' ,padding='valid',name = 'Conv5_1')(model1)\nmodel1 = BatchNormalization(name = 'Bnorm5')(model1)\n########################################################\nmodel1 = Flatten(name = 'Flatten')(model1)\n########################################################\nmodel1 = Dense(units = 128, activation = 'relu')(model1)\nmodel1 = Dropout(rate = 0.2)(model1)\nmodel1 = BatchNormalization()(model1)\nmodel1 = Dense(units = 20, activation = 'relu')(model1)\nmodel1 = BatchNormalization()(model1)\nmodel1 = Dense(units = 15, activation = 'relu')(model1)\nmodel1 = BatchNormalization()(model1)\noutput = Dense(units = 10, activation = 'softmax' , name='preds')(model1)\n\nmodel = Model(inputs= [input_model], outputs=[output])\nmodel.summary()","3e313370":"sgd = SGD(lr=0.001, momentum=0.9)\nmodel.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])","2bffc6e3":"history = model.fit(Training_data, \n                              epochs= 50,\n                              validation_data= Validation_data,\n                              verbose=1,\n                              callbacks=[es , lrr])","ab0f49eb":"val_loss = history.history['val_loss']\nloss = history.history['loss']\n\nplt.plot(val_loss)\nplt.plot(loss)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['Val error','Train error'], loc='upper right')\nplt.savefig('plot_error.png')\nplt.show()","4cc667f3":"val_accuracy = history.history['val_accuracy']\naccuracy = history.history['accuracy']\n\nplt.plot(val_accuracy)\nplt.plot(accuracy)\nplt.xlabel('Epochs')\nplt.ylabel('accuracy')\nplt.legend(['Val accuracy','Train accuracy'], loc='upper right')\nplt.savefig( 'plot_accuracy.png')\nplt.show()","48d928f2":"input_model = Input((trainX.shape[1],trainX.shape[2],trainX.shape[3]),name = 'input_layer')\n\nmodel1 = Conv2D(32,(5,5), activation='tanh',name = 'Conv1_5')(input_model)\nmodel1 = BatchNormalization(name = 'Bnorm1')(model1)\nmodel1 = Conv2D(32,(4,4), activation='tanh', padding='same',name= 'Conv2_5')(model1)\nmodel1 = BatchNormalization(name = 'Bnorm2')(model1)\nmodel1 = MaxPooling2D((2, 2),name = 'MaxPool1')(model1)\nmodel1 = Conv2D(64,(3,3), activation='tanh' ,padding='same',name = 'Conv3_3')(model1)\nmodel1 = BatchNormalization(name = 'Bnorm3')(model1)\nmodel1 = AveragePooling2D((2, 2),name = 'MaxPool1')(model1)\nmodel1 = Conv2D(128,(2,2), activation='tanh' ,padding='same',name = 'Conv4_3')(model1)\nmodel1 = BatchNormalization(name = 'Bnorm4')(model1)\n########################################################\nmodel1 = Flatten(name = 'Flatten')(model1)\n########################################################\nmodel1 = Dense(units = 128, activation = 'relu')(model1)\nmodel1 = Dropout(rate = 0.2)(model1)\nmodel1 = BatchNormalization()(model1)\nmodel1 = Dense(units = 20, activation = 'relu')(model1)\nmodel1 = BatchNormalization()(model1)\nmodel1 = Dense(units = 15, activation = 'relu')(model1)\nmodel1 = BatchNormalization()(model1)\noutput = Dense(units = 10, activation = 'softmax' , name='preds')(model1)\n\nmodel = Model(inputs= [input_model], outputs=[output])\nmodel.summary()","8738f617":"history = model.fit(Training_data, \n                              epochs= 50,\n                              validation_data= Validation_data,\n                              verbose=1,\n                              callbacks=[es , lrr])","bfd43f93":"val_loss = history.history['val_loss']\nloss = history.history['loss']\n\nplt.plot(val_loss)\nplt.plot(loss)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['Val error','Train error'], loc='upper right')\nplt.savefig('plot_error.png')\nplt.show()","0633392c":"val_accuracy = history.history['val_accuracy']\naccuracy = history.history['accuracy']\n\nplt.plot(val_accuracy)\nplt.plot(accuracy)\nplt.xlabel('Epochs')\nplt.ylabel('accuracy')\nplt.legend(['Val accuracy','Train accuracy'], loc='upper right')\nplt.savefig( 'plot_accuracy.png')\nplt.show()","8cbe293a":"input_model = Input((trainX.shape[1],trainX.shape[2],trainX.shape[3]),name = 'input_layer')\n\nmodel1 = Conv2D(32,(5,5), activation='relu',name = 'Conv1_5')(input_model)\nmodel1 = BatchNormalization(name = 'Bnorm1')(model1)\nmodel1 = Conv2D(32,(5,5), activation='relu', padding='same',name= 'Conv2_5')(model1)\nmodel1 = BatchNormalization(name = 'Bnorm2')(model1)\nmodel1 = MaxPooling2D((2, 2),name = 'MaxPool1')(model1)\nmodel1 = Conv2D(64,(3,3), activation='relu' ,padding='same',name = 'Conv3_3')(model1)\nmodel1 = BatchNormalization(name = 'Bnorm3')(model1)\nmodel1 = Conv2D(64,(3,3), activation='relu' ,padding='same',name = 'Conv4_3')(model1)\nmodel1 = BatchNormalization(name = 'Bnorm4')(model1)\n########################################################\nmodel1 = Flatten(name = 'Flatten')(model1)\n########################################################\nmodel1 = Dense(units = 128, activation = 'relu')(model1)\nmodel1 = Dropout(rate = 0.2)(model1)\nmodel1 = BatchNormalization()(model1)\nmodel1 = Dense(units = 20, activation = 'relu')(model1)\nmodel1 = BatchNormalization()(model1)\nmodel1 = Dense(units = 15, activation = 'relu')(model1)\nmodel1 = BatchNormalization()(model1)\noutput = Dense(units = 10, activation = 'softmax' , name='preds')(model1)\n\nmodel = Model(inputs= [input_model], outputs=[output])\nmodel.summary()","9ac68e10":"sgd = SGD(lr=0.001, momentum=0.9)\nmodel.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])","93b45217":"history = model.fit(Training_data, \n                              epochs= 50,\n                              validation_data= Validation_data,\n                              verbose=1,\n                              callbacks=[es , lrr])","3418224e":"val_loss = history.history['val_loss']\nloss = history.history['loss']\n\nplt.plot(val_loss)\nplt.plot(loss)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['Val error','Train error'], loc='upper right')\nplt.savefig('plot_error.png')\nplt.show()","e644fc63":"val_accuracy = history.history['val_accuracy']\naccuracy = history.history['accuracy']\n\nplt.plot(val_accuracy)\nplt.plot(accuracy)\nplt.xlabel('Epochs')\nplt.ylabel('accuracy')\nplt.legend(['Val accuracy','Train accuracy'], loc='upper right')\nplt.savefig( 'plot_accuracy.png')\nplt.show()","ee13a3aa":"img = trainX[1]\nprint(img.shape)\nimg = img.reshape(28,28)\nprint(img.shape)\nplt.imshow(img)","0a94e1df":"layer_names = []\nfor layer in model.layers[1:14]:\n    layer_names.append(layer.name) # Names of the layers, so you can have them as part of your plot\n\nlayer_names","5388682a":"for n_layer in range(1,13):\n    model_layer = Model(inputs=model.inputs, outputs=model.layers[n_layer].output)\n    feature_maps = model_layer.predict(trainX[1].reshape(1,28,28,1))\n    print('layer : {} , feature map shape : {}'.format(model.layers[n_layer].name,feature_maps.shape))\n    \n    n_row = int(feature_maps.shape[-1]\/8)\n    n_col = 8\n    print('nrow : {} , ncol : {}'.format(n_row,n_col))\n    plt.figure(figsize=(20,15))\n    # plot all maps in an shape\/8 * 8 squares\n    ix = 1\n    for _ in range(n_row):\n        for _ in range(n_col):\n            # specify subplot and turn of axis\n            ax = plt.subplot(n_row, n_col, ix)\n            ax.set_xticks([])\n            ax.set_yticks([])\n            # plot filter channel in grayscale\n            plt.imshow(feature_maps[0, :, :, ix-1], cmap='gray')\n            ix += 1\n    # show the figure\n    plt.show()","e7408db4":"trainX[0][0][0:5]","d9807d48":"trainX_N = 1.0 - trainX","c6f85df6":"img = trainX_N[1]\nprint(img.shape)\nimg = img.reshape(28,28)\nprint(img.shape)\nplt.imshow(img,cmap=plt.get_cmap('gray'))","2ca39e6c":"batch_size = 128\nTraining_data_N = datagen.flow(trainX_N,\n                             y=trainy,\n                            batch_size = batch_size,\n                            subset = 'training')\n\nValidation_data_N = datagen.flow(trainX_N,\n                             y=trainy,\n                            batch_size = batch_size,\n                            subset = 'validation')","647b3b3b":"input_model = Input((trainX_N.shape[1],trainX_N.shape[2],trainX_N.shape[3]),name = 'input_layer')\n\n\nmodel1 = Conv2D(32,(5,5), activation='relu',name = 'Conv1_5')(input_model)\nmodel1 = BatchNormalization(name = 'Bnorm1')(model1)\nmodel1 = Conv2D(32,(5,5), activation='relu', padding='same',name= 'Conv2_5')(model1)\nmodel1 = BatchNormalization(name = 'Bnorm2')(model1)\nmodel1 = MaxPooling2D((2, 2),name = 'MaxPool1')(model1)\nmodel1 = Conv2D(64,(3,3), activation='relu' ,padding='same',name = 'Conv3_3')(model1)\nmodel1 = BatchNormalization(name = 'Bnorm3')(model1)\nmodel1 = Conv2D(64,(3,3), activation='relu' ,padding='same',name = 'Conv4_3')(model1)\nmodel1 = BatchNormalization(name = 'Bnorm4')(model1)\nmodel1 = AveragePooling2D((2, 2),name = 'AvgPool1')(model1)\nmodel1 = Conv2D(128,(1,1), activation='relu' ,padding='valid',name = 'Conv5_1')(model1)\nmodel1 = BatchNormalization(name = 'Bnorm5')(model1)\n########################################################\nmodel1 = Flatten(name = 'Flatten')(model1)\n########################################################\nmodel1 = Dense(units = 32, activation = 'relu')(model1)\nmodel1 = Dropout(rate = 0.2)(model1)\nmodel1 = BatchNormalization()(model1)\nmodel1 = Dense(units = 20, activation = 'relu')(model1)\nmodel1 = BatchNormalization()(model1)\nmodel1 = Dense(units = 15, activation = 'relu')(model1)\nmodel1 = BatchNormalization()(model1)\noutput = Dense(units = 10, activation = 'softmax' , name='preds')(model1)\n\nmodel = Model(inputs= [input_model], outputs=[output])\nmodel.summary()","ba93ffe8":"sgd = SGD(lr=0.01, momentum=0.9)\nmodel.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])","46058b0d":"history = model.fit_generator(Training_data_N, \n                              epochs= 50,\n                              validation_data= Validation_data_N,\n                              verbose=1,\n                              callbacks=[es , lrr])","24efb0dd":"val_loss = history.history['val_loss']\nloss = history.history['loss']\n\nplt.plot(val_loss)\nplt.plot(loss)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['Val error','Train error'], loc='upper right')\nplt.savefig('plot_error.png')\nplt.show()","23abb8e6":"layer_names = []\nfor layer in model.layers[1:14]:\n    layer_names.append(layer.name) # Names of the layers, so you can have them as part of your plot\n\nlayer_names","c6af5c99":"for n_layer in range(1,13):\n    model_layer = Model(inputs=model.inputs, outputs=model.layers[n_layer].output)\n    feature_maps = model_layer.predict(trainX[1].reshape(1,28,28,1))\n    print('layer : {} , feature map shape : {}'.format(model.layers[n_layer].name,feature_maps.shape))\n    \n    n_row = int(feature_maps.shape[-1]\/8)\n    n_col = 8\n    print('nrow : {} , ncol : {}'.format(n_row,n_col))\n    plt.figure(figsize=(20,15))\n    # plot all maps in an shape\/8 * 8 squares\n    ix = 1\n    for _ in range(n_row):\n        for _ in range(n_col):\n            # specify subplot and turn of axis\n            ax = plt.subplot(n_row, n_col, ix)\n            ax.set_xticks([])\n            ax.set_yticks([])\n            # plot filter channel in grayscale\n            plt.imshow(feature_maps[0, :, :, ix-1], cmap='gray')\n            ix += 1\n    # show the figure\n    plt.show()","7562fd1e":"# # https:\/\/keras.io\/examples\/vision\/grad_cam\/","9c702d19":"last_conv_layer_name = \"Bnorm5\"\n\nclassifier_layer_names = []\nfor layer in model.layers[13:]:\n    classifier_layer_names.append(layer.name) # Names of the layers, so you can have them as part of your plot\n\nclassifier_layer_names","c12f0243":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Display\nfrom IPython.display import Image\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm","f4a8dba0":"def make_gradcam_heatmap(img_array, model, last_conv_layer_name, classifier_layer_names):\n    # First, we create a model that maps the input image to the activations\n    # of the last conv layer\n    last_conv_layer = model.get_layer(last_conv_layer_name)\n    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n\n    # Second, we create a model that maps the activations of the last conv\n    # layer to the final class predictions\n    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n    x = classifier_input\n    for layer_name in classifier_layer_names:\n        x = model.get_layer(layer_name)(x)\n    classifier_model = keras.Model(classifier_input, x)\n\n    # Then, we compute the gradient of the top predicted class for our input image\n    # with respect to the activations of the last conv layer\n    with tf.GradientTape() as tape:\n        # Compute activations of the last conv layer and make the tape watch it\n        last_conv_layer_output = last_conv_layer_model(img_array)\n        tape.watch(last_conv_layer_output)\n        # Compute class predictions\n        preds = classifier_model(last_conv_layer_output)\n        top_pred_index = tf.argmax(preds[0])\n        top_class_channel = preds[:, top_pred_index]\n\n    # This is the gradient of the top predicted class with regard to\n    # the output feature map of the last conv layer\n    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n\n    # This is a vector where each entry is the mean intensity of the gradient\n    # over a specific feature map channel\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    # We multiply each channel in the feature map array\n    # by \"how important this channel is\" with regard to the top predicted class\n    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n    pooled_grads = pooled_grads.numpy()\n    for i in range(pooled_grads.shape[-1]):\n        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n\n    # The channel-wise mean of the resulting feature map\n    # is our heatmap of class activation\n    heatmap = np.mean(last_conv_layer_output, axis=-1)\n\n    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n    heatmap = np.maximum(heatmap, 0) \/ np.max(heatmap)\n    return heatmap","952d8bd1":"# Print what the top predicted class is\npreds = model.predict(trainX[100].reshape(1,28,28,1))\n# Generate class activation heatmap\nheatmap = make_gradcam_heatmap(trainX[1].reshape(1,28,28,1), model, last_conv_layer_name, classifier_layer_names)\n# Display heatmap\nplt.imshow(img.reshape(28,28))\nplt.matshow(heatmap)\nplt.show()","f92b685e":"# We load the original image\nimg = trainX[100].reshape(28,28,1)\n\n# We rescale heatmap to a range 0-255\nheatmap = np.uint8(255 * heatmap)\n\n# We use jet colormap to colorize heatmap\njet = cm.get_cmap(\"jet\")\n\n# We use RGB values of the colormap\njet_colors = jet(np.arange(256))[:, :1]\njet_heatmap = jet_colors[heatmap]\n\n# We create an image with RGB colorized heatmap\njet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\njet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\njet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n\n# Superimpose the heatmap on original image\nprint(jet_heatmap.shape)\nsuperimposed_img = jet_heatmap * 0.4 + img\nsuperimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n\nplt.imshow(superimposed_img)\nplt.show()","76b7c60c":"# Print what the top predicted class is\npreds = model.predict(trainX[1000].reshape(1,28,28,1))\n# Generate class activation heatmap\nheatmap = make_gradcam_heatmap(trainX[1].reshape(1,28,28,1), model, last_conv_layer_name, classifier_layer_names)\n# Display heatmap\nplt.imshow(img.reshape(28,28))\nplt.matshow(heatmap)\nplt.show()","6117e72d":"# We load the original image\nimg = trainX[1000].reshape(28,28,1)\n\n# We rescale heatmap to a range 0-255\nheatmap = np.uint8(255 * heatmap)\n\n# We use jet colormap to colorize heatmap\njet = cm.get_cmap(\"jet\")\n\n# We use RGB values of the colormap\njet_colors = jet(np.arange(256))[:, :1]\njet_heatmap = jet_colors[heatmap]\n\n# We create an image with RGB colorized heatmap\njet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\njet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\njet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n\n# Superimpose the heatmap on original image\nprint(jet_heatmap.shape)\nsuperimposed_img = jet_heatmap * 0.4 + img\nsuperimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n\nplt.imshow(superimposed_img)\nplt.show()","2717c5c7":"input_model1 = Input((trainX.shape[1],trainX.shape[2],trainX.shape[3]),name = 'input1_layer')\ninput_model2 = Input((trainX.shape[1],trainX.shape[2],trainX.shape[3]),name = 'input2_layer')\n\n#######################################################\n#model1 CNN\nmodel1 = Conv2D(32,(5,5), activation='relu',name = 'Conv1_1_5')(input_model1)\nmodel1 = BatchNormalization(name = 'Bnorm1_1')(model1)\nmodel1 = Conv2D(32,(5,5), activation='relu', padding='same',name= 'Conv1_2_5')(model1)\nmodel1 = BatchNormalization(name = 'Bnorm1_2')(model1)\nmodel1 = MaxPooling2D((2, 2),name = 'MaxPool1')(model1)\nmodel1 = Conv2D(64,(3,3), activation='relu' ,padding='same',name = 'Conv1_3_3')(model1)\nmodel1 = BatchNormalization(name = 'Bnorm1_3')(model1)\nmodel1 = Conv2D(64,(3,3), activation='relu' ,padding='valid',name = 'Conv1_4_3')(model1)\nmodel1 = BatchNormalization(name = 'Bnorm1_4')(model1)\nmodel1 = AveragePooling2D((2, 2),name = 'AvgPool1_1')(model1)\nmodel1 = Conv2D(128,(1,1), activation='relu' ,padding='valid',name = 'Conv1_5_1')(model1)\nmodel1 = BatchNormalization(name = 'Bnorm1_5')(model1)\nmodel1 = MaxPooling2D((2, 2),name = 'MaxPool1_2')(model1)\nmodel1 = Flatten(name = 'Flatten1')(model1)\n#######################################################\n#model2 CNN\nmodel2 = Conv2D(32,(5,5), activation='tanh',name = 'Conv2_1_5')(input_model2)\nmodel2 = BatchNormalization(name = 'Bnorm2_1')(model2)\nmodel2 = Conv2D(32,(4,4), activation='tanh', padding='same',name= 'Conv2_2_5')(model2)\nmodel2 = BatchNormalization(name = 'Bnorm2_2')(model2)\nmodel2 = MaxPooling2D((2, 2),name = 'MaxPool2_1')(model2)\nmodel2 = Conv2D(64,(3,3), activation='tanh' ,padding='same',name = 'Conv2_3_3')(model2)\nmodel2 = BatchNormalization(name = 'Bnorm2_3')(model2)\nmodel2 = Conv2D(64,(2,2), activation='tanh' ,padding='valid',name = 'Conv2_4_3')(model2)\nmodel2 = BatchNormalization(name = 'Bnorm2_4')(model2)\nmodel2 = AveragePooling2D((2, 2),name = 'AvgPool2_1')(model2)\nmodel2 = Conv2D(128,(1,1), activation='tanh' ,padding='valid',name = 'Conv2_5_1')(model2)\nmodel2 = BatchNormalization(name = 'Bnorm2_5')(model2)\nmodel2 = MaxPooling2D((2, 2),name = 'MaxPool2_2')(model2)\nmodel2 = Flatten(name = 'Flatten2')(model2)\n#######################################################\nmerged = Concatenate()([model1, model2])\n# neural network\nmerged = Dense(units = 128, activation = 'relu')(merged)\nmerged = Dropout(rate = 0.2)(merged)\nmerged = BatchNormalization()(merged)\nmerged = Dense(units = 20, activation = 'relu')(merged)\nmerged = BatchNormalization()(merged)\nmerged = Dense(units = 15, activation = 'relu')(merged)\nmerged = BatchNormalization()(merged)\noutput = Dense(units = 10, activation = 'softmax')(merged)\n\nmodel = Model(inputs= [input_model1,input_model2], outputs=[output])\nmodel.summary()","771570ea":"plot_model(model, show_shapes=True)","9a71e2ca":"sgd = SGD(lr=0.01, momentum=0.9)\nmodel.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])","d68d434f":"history = model.fit(x = [trainX,trainX], y = trainy,\n                              batch_size = 128,\n                              epochs= 50,\n                              validation_split = 0.2,\n                              verbose=1,\n                              callbacks=[es])","3296a35f":"val_loss = history.history['val_loss']\nloss = history.history['loss']\n\nplt.plot(val_loss)\nplt.plot(loss)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['Val error','Train error'], loc='upper right')\nplt.savefig('plot_error.png')\nplt.show()","392e80a3":"val_accuracy = history.history['val_accuracy']\naccuracy = history.history['accuracy']\n\nplt.plot(val_accuracy)\nplt.plot(accuracy)\nplt.xlabel('Epochs')\nplt.ylabel('accuracy')\nplt.legend(['Val accuracy','Train accuracy'], loc='upper right')\nplt.savefig( 'plot_accuracy.png')\nplt.show()","9ff5c93c":"from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n\ndef change_size(image):\n    img = array_to_img(image, scale=False) #returns PIL Image\n    img = img.resize((32, 32))\n    img = img.convert(mode='RGB') #makes 3 channels\n    arr = img_to_array(img) #convert back to array\n    return arr.astype(np.float64)\n\ntrainX = [change_size(img) for img in trainX]\ntrainX = np.array(trainX)\ntrainX.shape","701e0340":"import keras\nfrom keras.applications import VGG19\n#Build the model\n\n#'The first base model used is VGG19. The pretrained weights from the imagenet challenge are used'\nbase_model_1 = VGG19(include_top=False,weights='imagenet',input_shape=(32,32,3),classes=10)","e44ccd88":"from keras.models import Sequential\n#Lets add the final layers to these base models where the actual classification is done in the dense layers\n\nmodel_1= Sequential()\nmodel_1.add(base_model_1) #Adds the base model (in this case vgg19 to model_1)\nmodel_1.add(Flatten()) \n#Since the output before the flatten layer is \n#a matrix we have to use this function to get a vector of \n#the form nX1 to feed it into the fully connected layers\n\nmodel_1.summary()","3891ea02":"#Add the Dense layers along with activation and batch normalization\nmodel_1.add(Dense(512,activation=('relu'),name = 'Descider',input_dim=512))\nmodel_1.add(Dropout(.3))\nmodel_1.add(Dense(64,activation=('relu')))\nmodel_1.add(Dropout(.2))\nmodel_1.add(Dense(10,activation=('softmax'))) #This is the classification layer","607b2509":"#Check final model summary\nmodel_1.summary()","7eed6029":"for layer in model_1.layers[0].layers:\n    print(layer.name)\n    if layer.name == 'block5_pool':\n         break\n    layer.trainable=False","ec670e3f":"#Check final model summary\nmodel_1.summary()","f97423c8":"sgd = SGD(lr=0.00001, momentum=0.9)\nmodel_1.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])","c3861522":"history = model_1.fit(trainX, trainy , batch_size= 128,\n                              epochs= 50,validation_split = 0.2,\n                              verbose=1,\n                              callbacks=[es])","ed66e4b8":"val_loss = history.history['val_loss']\nloss = history.history['loss']\n\nplt.plot(val_loss)\nplt.plot(loss)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['Val error','Train error'], loc='upper right')\nplt.savefig('plot_error.png')\nplt.show()","dafa4be8":"val_accuracy = history.history['val_accuracy']\naccuracy = history.history['accuracy']\n\nplt.plot(val_accuracy)\nplt.plot(accuracy)\nplt.xlabel('Epochs')\nplt.ylabel('accuracy')\nplt.legend(['Val accuracy','Train accuracy'], loc='upper right')\nplt.savefig( 'plot_accuracy.png')\nplt.show()","766f6edc":"# transfer learning","52554f53":"# CNN with Relu activation","91a0e019":"# output of CNN layers","b4fd06f3":"# Multi Input","1d886255":"# Grad-CAM class activation visualization","1e27255e":"# make image negative","4d992d05":"# CNN with Tanh activation","861b2417":"# change depth of CNN","efc3b8d5":"# change model depth"}}