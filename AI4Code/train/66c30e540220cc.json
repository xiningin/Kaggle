{"cell_type":{"fe60a172":"code","270e9dfc":"code","3c61a22f":"code","c2e92218":"code","d5f6a520":"code","b90d534c":"code","76c84d90":"code","926b8bd6":"code","0308f00b":"code","5eb11547":"code","cba55cef":"code","3539b840":"code","feb21428":"code","9c5f2d89":"code","6cf6d2b6":"code","0820cb6d":"markdown","87e4083c":"markdown","fb8fa1a2":"markdown","7fa52f15":"markdown","4cb3090e":"markdown","f2a09ac2":"markdown","f1557b45":"markdown","f6a39535":"markdown"},"source":{"fe60a172":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","270e9dfc":"train_raw = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/train.csv\")\ntest_raw = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/test.csv\")\nsubmission_raw = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/sample_submission.csv\")","3c61a22f":"import hashlib\n\nimport spacy\nimport sklearn\nfrom sklearn.svm import SVC\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import f1_score","c2e92218":"nlp = spacy.load('en')","d5f6a520":"# remove stopwords,punct\n# remove duplicate tweet\ntexts = []\nlabels = []\ntexts_md5 = set()\nfor target, doc in zip(train_raw.target, nlp.pipe(train_raw.text)):\n    tokens = [token.lemma_ for token in doc if token.is_stop is False and token.is_punct is False and token.is_space is False]\n    temp_text = ' '.join(tokens)\n    # remove duplicate\n    md5 = hashlib.md5()\n    md5.update(temp_text.encode('utf-8'))\n    text_md5 = md5.hexdigest()\n    if text_md5 not in texts_md5:\n        texts.append(temp_text)\n        labels.append(target)\n        texts_md5.add(text_md5)","b90d534c":"tests = []\nfor doc in nlp.pipe(test_raw.text):\n    tokens = [token.lemma_ for token in doc if token.is_stop is False and token.is_punct is False and token.is_space is False]\n    tests.append(' '.join(tokens))","76c84d90":"tf_idf = TfidfVectorizer(max_features=10000).fit(texts)\ntrain = tf_idf.transform(texts)\ntest = tf_idf.transform(tests)","926b8bd6":"X_train, X_test, y_train, y_test = train_test_split(train, labels, test_size=0.3)","0308f00b":"param_grid = {\n    \"gamma\" : [0.001,0.01,1,10,100],\n    \"C\":[0.001,0.01,1,10,100],\n    'kernel' : ['poly', \"linear\", 'sigmoid', 'rbf']\n}","5eb11547":"svc = SVC()\ngrid_searcher = GridSearchCV(svc, param_grid, cv=5, scoring='f1')\ngrid_searcher.fit(X_train, y_train)\ngrid_searcher.best_params_","cba55cef":"best_params= {'C': 1, 'gamma': 0.001, 'kernel': 'linear'}\nsvc = SVC(**best_params)\nscores = cross_val_score(svc,X_train, y_train, cv=5, scoring='f1')\nprint(scores)\nprint(sum(scores)\/len(scores))","3539b840":"val_texts = [\"A happy day!\", 'An earthquake happened!']\nval_data = tf_idf.transform(val_texts)\nsvc.fit(X_train, y_train)\nprint(svc.predict(val_data))","feb21428":"y_hat = svc.predict(test)","9c5f2d89":"submission = pd.DataFrame({\n    'id': test_raw.id,\n    'target':y_hat\n})","6cf6d2b6":"submission.to_csv(\"my_submission_linear.csv\", index=False)","0820cb6d":"# 1. load data","87e4083c":"**apply best params, and use cross_val_score find average f1**","fb8fa1a2":"# 4. train models","7fa52f15":"# **Submission**","4cb3090e":"# GridSearchCV\n**best_params:Linear, f1:0.757**","f2a09ac2":"# 3. preprocess data ","f1557b45":"# SVM","f6a39535":"# 2. import libraries and initial"}}