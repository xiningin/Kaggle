{"cell_type":{"1cefc982":"code","c8b24104":"code","d9436bcd":"code","57e702e0":"code","d0825583":"code","342481a0":"code","4d47a492":"code","deaef659":"code","f6d970a5":"code","177c834d":"code","8a3f6904":"code","fc9ea93b":"code","d5fc643f":"code","6e795ae8":"code","7ac15758":"code","33369a86":"code","f4e9bcbd":"code","d17f5244":"code","bcaeb888":"code","8f01908e":"code","b7437ee0":"code","584fa5f8":"code","4343b55a":"code","733eb8ac":"code","98b63ba3":"code","e02a9ef4":"code","719d899d":"code","ebbb3b9b":"code","582ec262":"code","2b4e1c18":"code","b2ad1708":"code","8c7569a6":"code","98178ef4":"code","01c9aa6e":"code","ffae959e":"code","37d4f4fc":"markdown","247c70f1":"markdown","43df1ba2":"markdown","cbe661a2":"markdown","3e24a9bf":"markdown","9baf2adf":"markdown","bfa1054d":"markdown","7e00e614":"markdown","d297abab":"markdown","73cb4bc1":"markdown","91d984e2":"markdown","4edbf4fa":"markdown","10a504d2":"markdown","2f3c04e4":"markdown","dcbd5906":"markdown","9ec7393d":"markdown","aca297f1":"markdown","656b5a28":"markdown","305ae9eb":"markdown","4cf1d086":"markdown","5c991cd6":"markdown","c80337de":"markdown","ea2057e2":"markdown","7923541b":"markdown","49c65da3":"markdown","9036eac8":"markdown"},"source":{"1cefc982":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c8b24104":"import matplotlib.pyplot as plt\nimport seaborn as sns\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n","d9436bcd":"\ndf=pd.read_csv('\/kaggle\/input\/new-york-city-airbnb-open-data\/AB_NYC_2019.csv')\n#Lets take a look at some of the entries.\ndf.head()\n","57e702e0":"df.describe(), df.info()","d0825583":"df.isnull().sum()","342481a0":"#Removing the columns which don't have affect on price.\ndf.drop(['id','host_name','last_review'], axis = 1,inplace=True) \n\ndf.reviews_per_month.fillna(value=0,inplace=True)","4d47a492":"plt.figure(figsize=(16, 6))\nsns.barplot(df.neighbourhood_group,df.price,hue=df.room_type,ci=None)","deaef659":"plt.figure(figsize=(16, 6))\nsns.countplot(df.neighbourhood_group,hue=df.room_type)","f6d970a5":"df.drop('price', axis=1).corrwith(df.price).plot.barh(figsize=(10, 8), \n                                                        title='Correlation with Response Variable',\n                                                        fontsize=15)","177c834d":"plt.figure(figsize = (15, 10))\nplt.style.use('seaborn-white')\nax=plt.subplot(221)\nplt.boxplot(df['number_of_reviews'])\nax.set_title('Numer of Reviews')\nax=plt.subplot(222)\nplt.boxplot(df['price'])\nax.set_title('Price')\nax=plt.subplot(223)\nplt.boxplot(df['availability_365'])\nax.set_title('availability_365')\nax=plt.subplot(224)\nplt.boxplot(df['reviews_per_month'])\nax.set_title('reviews_per_month')","8a3f6904":"Q1 = df['price'].quantile(0.25)\nQ3 = df['price'].quantile(0.75)\nIQR = Q3 - Q1    #IQR is interquartile range. \n\noultier_remover = (df['price'] >= Q1 - 1.5 * IQR) & (df['price'] <= Q3 + 1.5 *IQR)\ndf=df.loc[oultier_remover]\n\nQ1 = df['number_of_reviews'].quantile(0.25)\nQ3 = df['number_of_reviews'].quantile(0.75)\nIQR = Q3 - Q1    #IQR is interquartile range. \n\noultier_remover = (df['number_of_reviews'] >= Q1 - 1.5 * IQR) & (df['number_of_reviews'] <= Q3 + 1.5 *IQR)\nairbnb2=df.loc[oultier_remover]\n\n\nQ1 = df['reviews_per_month'].quantile(0.25)\nQ3 = df['reviews_per_month'].quantile(0.75)\nIQR = Q3 - Q1    #IQR is interquartile range. \n\noultier_remover = (df['reviews_per_month'] >= Q1 - 1.5 * IQR) & (df['reviews_per_month'] <= Q3 + 1.5 *IQR)\nairbnb_new=df.loc[oultier_remover]","fc9ea93b":"#extract the host_ids having high number of entries in the dataset.\nhost_with_most_listings=df.host_id.value_counts().head(13)\n\n#extract the most popular neighbourhoods.\nmost_popular_neighbourhoods=df.neighbourhood.value_counts().head(13)","d5fc643f":"most_popular_neighbourhoods,host_with_most_listings","6e795ae8":"plt.figure(figsize=(16, 6))\nhost_with_most_listings.plot(kind='bar')","7ac15758":"plt.figure(figsize=(16, 6))\nmost_popular_neighbourhoods.plot(kind='bar')","33369a86":"most_popular_neighbourhoods_df=df.loc[df.neighbourhood.isin(['Williamsburg','Bedford-Stuyvesant',   \n'Harlem',                \n'Bushwick',              \n'Upper West Side',       \n'Hell\\'s Kitchen',        \n'East Village',      \n'Upper East Side',       \n'Crown Heights',     \n'Midtown',               \n'East Harlem',           \n'Greenpoint',            \n'Chelsea' ])]","f4e9bcbd":"# host_with_most_listings_df=df.loc[df.host_id.isin([ '219517861',    \n#  '107434423',    \n#  '30283594',     \n#  '137358866',    \n#  '12243051',      \n#  '16098958',      \n#  '61391963',      \n#  '22541573',      \n#  '200380610',     \n#  '7503643',       \n# '1475015',       \n#  '120762452',     \n#  '2856748' ])]","d17f5244":"plt.figure(figsize=(20, 6))\nsns.catplot(x='neighbourhood', hue='neighbourhood_group', col='room_type', data=most_popular_neighbourhoods_df, kind='count').set_xticklabels(rotation=90)","bcaeb888":"plt.figure(figsize=(15, 6))\nsns.scatterplot(x=df.neighbourhood_group,y=df.number_of_reviews,ci=False)","8f01908e":"plt.figure(figsize=(15, 6))\nsns.barplot(x=df.neighbourhood_group,y=df.calculated_host_listings_count,ci=False)","b7437ee0":"#Now lets take the name column and get some insights.\nkeywords=[]\n#the basic motto is to get the individual tokens out of the dataframe column\nfor name in df.name:\n    keywords.append(name)\ndef split_keywords(name):\n    spl=str(name).split()\n    return spl\nkeywords_filtered=[]\nfor x in keywords:\n    for word in split_keywords(x):\n        word=word.lower()\n        keywords_filtered.append(word)\n#These are some of the words that I have removed after working on data.\nkeywords_filtered=[word for word in keywords_filtered if not word in ['in','of','the','to','1','2','3','and','with','&']]","584fa5f8":"from collections import Counter\n#Get the list of most frequent words.\nfreq_keywords=Counter(keywords_filtered).most_common()\n","4343b55a":"freq_keywords_df=pd.DataFrame(freq_keywords)\nfreq_keywords_df.rename(columns={0:'Words', 1:'Count'}, inplace=True)","733eb8ac":"plt.figure(figsize=(15, 6))\n#plotting the top ten\nsns.barplot(x='Words',y='Count',data=freq_keywords_df[0:10])","98b63ba3":"plt.figure(figsize=(15, 6))\nsns.barplot(x=df.neighbourhood_group,y=df.availability_365,hue=df.room_type,ci=False)","e02a9ef4":"plt.figure(figsize=(15, 6))\nsns.scatterplot(x=df.longitude,y=df.latitude,hue=df.neighbourhood_group)","719d899d":"plt.figure(figsize=(15, 6))\nsns.scatterplot(x=df.longitude,y=df.latitude,hue=df.room_type)","ebbb3b9b":"df.info()","582ec262":"#Applying one hot encoding for categorical variables using get_dummies.\ndummy_neighbourhood=pd.get_dummies(df['neighbourhood_group'], prefix='dummy')\ndummy_roomtype=pd.get_dummies(df['room_type'], prefix='dummy')\ndf_new = pd.concat([df,dummy_neighbourhood,dummy_roomtype],axis=1)\n#Removing the columns which are not helpful in predicting new prices.\ndf_new.drop(['neighbourhood_group','room_type','neighbourhood','name','longitude','latitude','host_id'],axis=1, inplace=True)\ndf_new","2b4e1c18":"#Seperating the predictor and target variables.\ny=df_new['price']\nX=df_new.drop(['price'],axis=1)","b2ad1708":"from sklearn import preprocessing\n#Only standardize the numerical colums and not the dummy variables.\nX_scaled=preprocessing.scale(X.iloc[:,0:5])\nX_scaled = pd.DataFrame(X_scaled, index=X.iloc[:,0:5].index, columns=X.iloc[:,0:5].columns)\nX.drop(X.iloc[:,0:5],axis=1,inplace=True)\nX=pd.concat([X_scaled,X],axis=1)","8c7569a6":"from sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\nregressor = RandomForestRegressor(n_estimators = 50, random_state = 0) \n# As there is only option to calculate negative MAE.So lets make it positive.  \nscores =  -1 * cross_val_score(regressor, X, y,\n                              cv=5,\n                              scoring='neg_mean_absolute_error')\n\nprint(\"MAE scores:\\n\", scores)\nprint(\"Average MAE score (across experiments):\",scores.mean())","98178ef4":"#split the dataset.\nfrom sklearn.model_selection import train_test_split\ntrain_X,test_X,train_y,test_y=train_test_split(X,y,random_state=1)","01c9aa6e":"#Result using Random Forest Regressor\nfrom sklearn.metrics import mean_absolute_error\nmodel = RandomForestRegressor(n_estimators=100, random_state=0)\nmodel.fit(train_X, train_y)\npreds = model.predict(test_X)\nmean_absolute_error(test_y, preds)","ffae959e":"#Result using XGBoost.\nfrom xgboost import XGBRegressor\n\nmodel = XGBRegressor(n_estimators=1000, learning_rate=0.05, n_jobs=4)\nmodel.fit(train_X, train_y, \n             early_stopping_rounds=5, \n             eval_set=[(test_X, test_y)], \n             verbose=False)\npredictions = model.predict(test_X)\nprint(\"Mean Absolute Error: \" + str(mean_absolute_error(predictions, test_y)))","37d4f4fc":"# 1. Import the dataset.","247c70f1":"The above plot tells that:\n1. Manhattan has the most entries in data. ","43df1ba2":"Kernels that I have referred from:\n1. Belong Anywhere-NY Airbnb price prediction [here](https:\/\/www.kaggle.com\/benroshan\/belong-anywhere-ny-airbnb-price-prediction\/notebook)\n2. Data Exploration on NYC Airbnb [here](https:\/\/www.kaggle.com\/dgomonov\/data-exploration-on-nyc-airbnb)\n","cbe661a2":"So, the score decreased by a bit to 34.69.\nI am still working on it to reduce more and will update the kernel if anything interesting comes up.","3e24a9bf":"Lets get info about the different features present and their properties.","9baf2adf":"The above plot describes the pearson coefficients of the features(numerical) with price variable.Not much to infer as the values for the coefficient is not upto mark(>0.5).","bfa1054d":"The above plot shows that :\n1. The entries for private and Entire home are much more than shared rooms.","7e00e614":"The score is coming out to be 38.37. I have tried many things but wasn't able to get any lower.Feel free to comment if you find anything new and interesting.","d297abab":"# Handling Missing Data","73cb4bc1":"The below idea is taken from this [kernel](https:\/\/www.kaggle.com\/dgomonov\/data-exploration-on-nyc-airbnb)","91d984e2":"The above count plot concludes:\n1. Staten Island and Bronx have the least number of entries in the listings.\n2. Shared rooms are less available in the listings.\n3. Manhattan and Brooklyn neighbourhoods have far more entries in the listings.\n\nI will infer from this plot that Brooklyn and Manhattan are towns(IT or Industrial areas) where people come for jobs thats why the renting properties are more there. \n","4edbf4fa":"In the dataset, there are 5 categorical and 9 numerical features","10a504d2":"# Cross Validation","2f3c04e4":"These plots concludes:\n1. Confirms the above inference that Manhattan and Brooklyn are most popular.\n2. It alse tells which neighbourhood falls in which neighbourhood_group(Can be helpful for someone coming first time to the country :) )","dcbd5906":"The above plot concludes that:\n1. If number_of_reviews is taken as the number of people who have stayed and provided there reviews then Queens , Manhattan and Brooklyn are the most preferred places.\n\n","9ec7393d":"The above plots conclude:\n1. All of the above except *availability_365* have outliers.","aca297f1":"This plot concludes:\n1. Some hosts have more number of entries w.r.t to others and the host_id with most number of entries has 327 entries. ","656b5a28":"# Handling Outliers\n\nOutliers are the absurd values that can occur in the data due to errors during data collection or sometime can also be indicators of interesting trends. Have a look at [this](http:\/\/towardsdatascience.com\/ways-to-detect-and-remove-the-outliers-404d16608dba) post to know more about outliers and how to detect and remove them.","305ae9eb":"# Baseline Model.\n\n1. Preprocessing data","4cf1d086":"The above plot  infers taht:\n1. No fancy words are used.\n2. Words like 'room' , 'bedroom' ,'private' are most frequent.\nPersonal Opinion:\nAs the description are simple and not contain much of the adjectives so, it shows that the number of tenants are much more than the number of hosts (i.e they dont have to exaggerate)  ","5c991cd6":"I am newbie at machine learning.This is my first kernel on EDA. There are some personal insights that I have provided after working on the data.This is a basic approach (So any first timer who is yet to write his first kernel can take a look and clear his\/her doubts) So if anybody finds the points contradicting feel free to comment. \n\n\nThe Basic sequence of steps that I followed:\n1. Finding and handling missing data.\n2. Handling outliers.\n3. Visualising the dataset for EDA.\n4. A baseline prediction model.","c80337de":"This plot concludes that:\n1. Williamsburg  and Bedford-Stuyvesant are the most popular neighbourhood of all.","ea2057e2":"The above bar plot concludes:\n1. Manhattan is the most expensive neighbourhood_group\n2. The price of entire home\/apt is more than any other room type.\n3. Bronx is the cheapest.","7923541b":"I have dropped the *last_review* column as it contains dates and 20% of the values are missing.\nI have also filled the NaN values of *reviews_per_month* with 0, which will also not affect the  *number_of_reviews* column.","49c65da3":"The above plot concludes:\n1. Staten Island properties remain unoccupied as they are available most of the days.\n2. Manhattan properties are most occupied.","9036eac8":"The above plot just decibes the demogrphic view of the entries in the data and also provides a clear view of the neighbourhood_groups."}}