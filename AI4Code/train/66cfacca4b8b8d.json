{"cell_type":{"03072191":"code","5c887030":"code","fc567e78":"code","43127a86":"code","4a9d83a2":"code","5a741da3":"code","54dffd42":"code","6d321415":"code","ff7373d9":"code","93d200d8":"code","185611e6":"code","50d65faf":"markdown","bacb8752":"markdown","0159ac15":"markdown","286f581b":"markdown","5910f9e6":"markdown","df7b0359":"markdown","1e0d7a7e":"markdown","41eccdf6":"markdown","0e7f3c24":"markdown","a1ed6d43":"markdown"},"source":{"03072191":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom pandas_profiling import ProfileReport\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.svm import SVC\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nplt.style.use('ggplot')","5c887030":"df = pd.read_csv(\"\/kaggle\/input\/heart-disease-uci\/heart.csv\")\ndf.index.rename('id', inplace = True)\ndf.drop_duplicates(inplace = True)\n\n#Encode (cp 0 to 3)(slope 0 to 2)(thal 0 to 3)\ndf = pd.get_dummies(df, columns=['cp', 'slope', 'thal'], drop_first=True)\n\ndf.sample(10)","fc567e78":"#Amount of Missing Data\npercent_missing = df.isnull().sum() * 100 \/ len(df)\nmissing_value_df = pd.DataFrame({'column_name': df.columns,\n                                 'percent_missing': percent_missing})\nmissing_value_df","43127a86":"#Split Train and Test Data\nx = df.drop(columns = \"target\")\ny = df[\"target\"]\nx_train,x_test,y_train,y_test=train_test_split(x, y, test_size=0.25,random_state= 37)","4a9d83a2":"#Standardize Data\nSS = StandardScaler()\nx_train = SS.fit_transform(x_train)\nx_test = SS.transform(x_test)","5a741da3":"# Create Neural Network\nmodel = Sequential()\n\n#Add Two layers(18 input and 2 output) - Sigmoid for last layer because it's binary classification\nmodel.add(Dense(16, input_dim=18, activation=\"relu\"))\nmodel.add(Dense(12, activation=\"relu\"))\nmodel.add(Dense(1, activation=\"sigmoid\"))","54dffd42":"#Create Dictionary for Store history of each Optimizer\nhistory = {}","6d321415":"#Compile with SGD Optimizer\nmodel.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['accuracy'])\nhistory[\"SGD\"] = model.fit(x_train, y_train, epochs=25, batch_size=32)","ff7373d9":"#Compile with RMSprop Optimizer\nmodel.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\nhistory[\"RMSprop\"] = model.fit(x_train, y_train, epochs=25, batch_size=32)","93d200d8":"plt.plot(history['SGD'].history['accuracy'])\nplt.plot(history['RMSprop'].history['accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['SGD', 'RMSprop'], loc='upper left')\nplt.show()","185611e6":"plt.plot(history['SGD'].history['loss']) \nplt.plot(history['RMSprop'].history['loss']) \nplt.title('Model loss') \nplt.ylabel('Loss') \nplt.xlabel('Epoch') \nplt.legend(['SGD', 'RMSprop'], loc='upper left') \nplt.show()","50d65faf":"# Data Scaling","bacb8752":"# Split data to Train and Test","0159ac15":"## RMSprop\n","286f581b":"### Acuaracy","5910f9e6":"# Build Base Neural Network","df7b0359":"## SGD","1e0d7a7e":"## Compare different Optimizers","41eccdf6":"### Loss","0e7f3c24":"# Compile with Different Optimizers","a1ed6d43":"# Data Preprocessing"}}