{"cell_type":{"63f9363d":"code","87a83196":"code","6dff5267":"code","06951dcb":"code","9312afb8":"code","e3c85353":"code","969adafa":"code","579840ad":"code","e628e611":"code","373d0f08":"code","6d4a401e":"code","4e6921f0":"code","e5577152":"code","446f98f7":"code","70c2004c":"code","266e2b2e":"code","906afb5d":"code","af3b2389":"code","1f8dab60":"code","06710f41":"code","f2bfd4b7":"code","a59309ff":"code","f673883e":"code","bcd5eb56":"code","8a766fb6":"code","971b4653":"code","63a42304":"code","9e971115":"code","c1926c81":"code","4ef03a9d":"code","e71d1680":"code","2e590ce2":"code","2bab4279":"code","b28b2e32":"code","73fe8b13":"code","0eab23aa":"code","ffa38040":"code","fdc3c564":"code","9cea5365":"code","a9f50494":"code","9f7fa873":"code","4da1e5b2":"markdown","3aee8036":"markdown","2e16f89a":"markdown","94ff10e9":"markdown","2e960d67":"markdown","f947619c":"markdown","66257f18":"markdown","f1b47bdc":"markdown","6c0ffce8":"markdown","6a4cbed8":"markdown","176031fa":"markdown"},"source":{"63f9363d":"pip install google-colab","87a83196":"import cv2           # extra\u00e7\u00e3o dos pixels;\nimport numpy as np\nimport os\nimport zipfile\nfrom google.colab.patches import cv2_imshow\nimport tensorflow as tf\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","6dff5267":"path = '..\/input\/neural-networks-homer-and-bart-classification\/homer_bart_1'","06951dcb":"directory = '..\/input\/neural-networks-homer-and-bart-classification\/homer_bart_1'\nfiles = [os.path.join(directory, f) for f in sorted(os.listdir(directory))]","9312afb8":"arquivos = [os.path.join(directory, f) for f in sorted(os.listdir(directory))]  ","e3c85353":"export = 'mouth,pants,shoes,shirt,shorts,sneakers,class\\n'  ","969adafa":"export","579840ad":"show_images = False\ncharacteristics = []","e628e611":"100 * 200","373d0f08":"(2000 \/ 20000) * 100","6d4a401e":"for path_image in files:\n  \n  try:\n    original_image = cv2.imread(path_image)\n    (H, W) = original_image.shape[:2]\n  except:\n    continue\n\n  altered_image = original_image.copy()\n  image_features = []\n  image_name = os.path.basename(os.path.normpath(path_image))\n  mouth = pants = shoes = 0\n  shirt = shorts = sneakers = 0\n\n  if image_name.startswith('b'): \n    classe = 0\n  else:\n    classe = 1\n\n  for height in range(0, H):\n    for width in range(0, W):\n      \n      blue = altered_image.item(height, width, 0)\n      green = altered_image.item(height, width, 1)\n      red = altered_image.item(height, width, 2)\n\n      if (blue >= 95 and blue <= 140 and green >= 160 and green <= 185 and red >= 175 and red <= 205):\n        altered_image[height, width] = [0, 255, 255]\n        mouth += 1\n\n\n      if (blue >= 150 and blue <= 180 and green >= 98 and green <= 120 and red >= 0 and red <= 90):\n        altered_image[height, width] = [0, 255, 255]\n        pants += 1\n\n\n      if height > (H \/ 2):\n        if (blue >= 25 and blue <= 45 and green >= 25 and green <= 45 and red >= 25 and red <= 45):\n          altered_image[height, width] = [0, 255, 255]\n          shoes += 1\n\n\n      if (blue >= 11 and blue <= 50 and green >= 85 and green <= 105 and red >= 240 and red <= 255):\n        altered_image[height, width] = [0, 255, 128]\n        shirt += 1\n\n\n      if (blue >= 125 and blue <= 170 and green >= 0 and green <= 12 and red >= 0 and red <= 20):\n        altered_image[height, width] = [0, 255, 128]\n        shorts += 1\n\n\n      if height > (H \/ 2):\n        if (blue >= 125 and blue <= 170 and green >= 0 and green <= 12 and red >= 0 and red <= 20):\n          altered_image[height, width] = [0, 255, 128]\n          sneakers += 1\n\n  boca = round((mouth \/ (H * W)) * 100, 9)\n  calca = round((pants \/ (H * W)) * 100, 9)\n  sapato = round((shoes \/ (H * W)) * 100, 9)\n  camisa = round((shirt \/ (H * W)) * 100, 9)\n  calcao = round((shorts \/ (H * W)) * 100, 9)\n  tenis = round((sneakers \/ (H * W)) * 100, 9)\n\n  image_features.append(mouth)\n  image_features.append(pants)\n  image_features.append(shoes)\n  image_features.append(shirt)\n  image_features.append(shorts)\n  image_features.append(sneakers)\n  image_features.append(classe)\n\n  characteristics.append(image_features)\n\n    \n  f = (\",\".join([str(item) for item in image_features]))\n  export += f + '\\n'\n\n  if show_images == True:\n    altered_image = cv2.cvtColor(altered_image, cv2.COLOR_BGR2RGB)\n    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n    figura, im = plt.subplots(1, 2)\n    im[0].imshow(original_image)\n    im[0].axis('off')\n    im[1].imshow(altered_image)\n    im[1].axis('off')\n    plt.show()\n\n\n  #cv2_imshow(original_image)\n  #print(H, W)\n  #print(image_name)","4e6921f0":"export","e5577152":"with open('features.csv', 'w') as file:\n  for linha in export:\n    file.write(linha)\nfile.closed","446f98f7":"dataset = pd.read_csv('features.csv', error_bad_lines = False)","70c2004c":"X = dataset.iloc[:, 0:6].values   \nX","266e2b2e":"y = dataset.iloc[:, 6].values  \ny","906afb5d":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)","af3b2389":"X_train.shape, y_train.shape","1f8dab60":"X_test.shape, y_test.shape","06710f41":"(6 + 2) \/ 2","f2bfd4b7":"network = tf.keras.Sequential()\nnetwork.add(tf.keras.layers.Dense(input_shape = (6,), units = 4, activation='relu'))\nnetwork.add(tf.keras.layers.Dense(units=4, activation='relu'))\nnetwork.add(tf.keras.layers.Dense(units=4, activation='relu'))\nnetwork.add(tf.keras.layers.Dense(units = 1, activation='sigmoid'))","a59309ff":"network.summary()","f673883e":"network.compile(optimizer='Adam', loss='binary_crossentropy', metrics = ['accuracy'])","bcd5eb56":"historic = network.fit(X_train, y_train, epochs = 80)","8a766fb6":"historic.history.keys()","971b4653":"plt.plot(historic.history['loss']);","63a42304":"plt.plot(historic.history['accuracy']);","9e971115":"X_test.shape","c1926c81":"forecasts = network(X_test)\nforecasts","4ef03a9d":"forecasts = forecasts > 0.5\nforecasts","e71d1680":"y_test","2e590ce2":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test, forecasts)","2bab4279":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, forecasts)\ncm","b28b2e32":"sns.heatmap(cm, annot=True);","73fe8b13":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, forecasts))","0eab23aa":"network.summary()","ffa38040":"image_test = X_test[1]\nimage_test","fdc3c564":"image_test.shape","9cea5365":"image_test = image_test.reshape(1,-1)\nimage_test.shape","a9f50494":"network.predict(image_test)[0][0]","9f7fa873":"if network.predict(image_test)[0][0] < 0.5:\n  print('Bart')\nelse:\n  print('Homer')","4da1e5b2":"## Neural network evaluation","3aee8036":"## Construction and training of the neural network","2e16f89a":"## Upload and rate a single image","94ff10e9":"## Extraction of pixels from images","2e960d67":"## Training and testing bases","f947619c":"\n\n\n**THIS IS ANOTHER ALGORITHM WE CAN USE TO MAKE RATINGS THROUGH FEATURE EXTRACTION**","66257f18":"## Import from libraries","f1b47bdc":"## Feature Extractor","6c0ffce8":"# **If you find this notebook useful, support with an upvote** \ud83d\udc4d\u00b6","6a4cbed8":"https:\/\/www.kaggle.com\/juniorbueno\/neural-networks-simpsons-image-classification","176031fa":"**The case study with the extraction of features has a much better result than just with neural networks.**"}}