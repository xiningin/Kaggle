{"cell_type":{"fdf66da0":"code","eed67bfa":"code","f693b591":"code","d6f315bd":"code","9f381e72":"code","f78c091b":"code","04b67b65":"code","136a9794":"code","1bf47a94":"code","532ec6d7":"code","a175fe19":"code","001636ef":"code","b10a74e1":"code","cfcab7b3":"code","a8034218":"code","2a4dd571":"code","9116a128":"code","f97564a8":"code","08ce7f79":"code","33a18bf2":"code","8e2eb948":"code","22d39e51":"code","dabc75aa":"code","4996ae7c":"markdown","3a2ba5e7":"markdown","8794f325":"markdown","5b988442":"markdown","e95cfeb9":"markdown","365baaea":"markdown","83faeb3a":"markdown","09f9e32c":"markdown","fc06adee":"markdown","1bd09f5b":"markdown","3c7e3bf4":"markdown"},"source":{"fdf66da0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        pass\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","eed67bfa":"\nimport tensorflow as tf\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator","f693b591":"train_data = ImageDataGenerator(rescale = 1.\/255,shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)","d6f315bd":"training_set = train_data.flow_from_directory('..\/input\/cat-and-dog\/training_set\/training_set', batch_size = 64, target_size = (64,64), class_mode = 'binary')","9f381e72":"test_data = ImageDataGenerator(rescale = 1.\/255)\n","f78c091b":"#defining testing set\ntesting_set = test_data.flow_from_directory('..\/input\/cat-and-dog\/test_set\/test_set', batch_size = 64, target_size = (64,64), class_mode = 'binary')","04b67b65":"\ncnn = tf.keras.models.Sequential()","136a9794":"cnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3, input_shape = [64,64,3],activation = 'relu'))","1bf47a94":"cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))","532ec6d7":"#adding 2nd Convolutional layer\ncnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3, activation = 'relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))","a175fe19":"#adding 3rd Convolutional layer\ncnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3, activation = 'relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))","001636ef":"#the input of step 4 is an flattened array,\ncnn.add(tf.keras.layers.Flatten())","b10a74e1":"#forming an ann with 128 input neurons\ncnn.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))","cfcab7b3":"#adding ouput layer of the ann\ncnn.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))","a8034218":"#compiling the CNN\ncnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","2a4dd571":"#training the model\ncnn.fit(x = training_set, validation_data = testing_set, epochs = 25)","9116a128":"cnn.save('catdog_cnn_model.h5')\n","f97564a8":"from keras.models import load_model \nclassifier = load_model('catdog_cnn_model.h5')","08ce7f79":"import numpy as np\nfrom keras.preprocessing import image\ntraining_set.class_indices","33a18bf2":"image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/cats\/cat.4014.jpg')\n","8e2eb948":"#importing images\ntest_img = image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/cats\/cat.4014.jpg',target_size = (64,64))\n#converting image to array\ntest_img = image.img_to_array(test_img)\ntest_img = np.expand_dims(test_img,axis = 0)\nresult = classifier.predict(test_img)\nif result[0][0] >= 0.5:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'\nprint(prediction)","22d39e51":"image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/dogs\/dog.4014.jpg')\n","dabc75aa":"#importing images\ntest_img = image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/dogs\/dog.4014.jpg',target_size = (64,64))\n#converting image to array\ntest_img = image.img_to_array(test_img)\ntest_img = np.expand_dims(test_img,axis = 0)\nresult = classifier.predict(test_img)\nif result[0][0] >= 0.5:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'\nprint(prediction)","4996ae7c":"# defining the CNN as a sequence of layers.","3a2ba5e7":"0 MEANS CATS AND 1 MEANS DOGS\n","8794f325":"STEP - 2) APPLYING MAX POOLING\n\n","5b988442":"IT'S A CAT","e95cfeb9":"# 4 steps of cnn\n1. CONVOLUTION\n2. POOLING\n3. FLATTENING\n4. FULL CONNECTION","365baaea":"STEP - 1) ADDING CONVOLUTIONAL LAYER\n","83faeb3a":"STEP -3 ) FLATTENING\n\n","09f9e32c":"STEP - 4 ) FULL CONNECTION\n\n","fc06adee":"## PREDICTING VALUES\n","1bd09f5b":"IT'S A DOG","3c7e3bf4":"# IMPORTING LIBRARIES"}}