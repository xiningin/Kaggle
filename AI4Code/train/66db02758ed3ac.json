{"cell_type":{"02e9b73a":"code","3bbaac78":"code","549be6a3":"code","58f31699":"code","dc693de6":"code","5622c9e9":"code","02331863":"code","b874a222":"code","a16782ee":"code","48c67238":"code","57082841":"code","2638c956":"code","1da9ca57":"code","f12b2254":"code","460b534a":"code","9045c866":"code","5146cd52":"code","200aa808":"code","498d9d28":"code","f1887718":"code","d1dba79b":"code","1ceb7985":"code","ea6a051a":"markdown","299aab2d":"markdown","caa55b09":"markdown","51fd14af":"markdown","729738d9":"markdown"},"source":{"02e9b73a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3bbaac78":"!pip install texthero","549be6a3":"import texthero\nhelp(texthero)","58f31699":"import pandas as pd\ndf=pd.read_csv(\"\/kaggle\/input\/emotions-in-text\/Emotion_final.csv\")","dc693de6":"df.head()","5622c9e9":"series=pd.Series(df['Text'])\nseries","02331863":"##removing digits from the series of text\nimport texthero as hero\nhero.remove_digits(series)","b874a222":"##removing punctuations from the series\nhero.remove_punctuation(series)","a16782ee":"## Remove Brackets\nhero.remove_brackets(series)","48c67238":"hero.remove_diacritics(series)","57082841":"##removing white spaces\nhero.remove_whitespace(series)","2638c956":"\n###  removing Stopwords\nhero.remove_stopwords(series)","1da9ca57":"hero.clean(series)","f12b2254":"df.shape","460b534a":"df1=df.head(50)","9045c866":"df1.head(10)","5146cd52":"df1['pca'] = (\n   df1['Text']\n   .pipe(hero.clean)\n   .pipe(hero.tfidf)###vectorizing\n   .pipe(hero.pca)\n)\n","200aa808":"df1.head()","498d9d28":"df1['tfidf'] = (\n    df1['Text']\n    .pipe(hero.clean)\n    .pipe(hero.tfidf)\n)\n### Kmeans\n\ndf1['kmeans_labels'] = (\n    df1['tfidf']\n    .pipe(hero.kmeans, n_clusters=5)\n    .astype(str)\n)\n\ndf1['pca'] = df1['tfidf'].pipe(hero.pca)","f1887718":"df1.head()","d1dba79b":"import seaborn as sns","1ceb7985":"sns.scatterplot(data=df1, x=\"kmeans_labels\", y=\"Emotion\")","ea6a051a":"here we can see the principle components","299aab2d":"# installing texthero","caa55b09":"# so this wrapups this notebook,hope it had given some information about TEXTHERO library.please do upvote by nootbook if it is useful","51fd14af":"# **TextHero**\nUnder the hoods, Texthero makes use of multiple NLP and machine learning toolkits such as Gensim, NLTK, SpaCy and scikit-learn. You don't need to install them all separately, pip will take care of that.\n\nTexthero include tools for:\n\n* **Preprocess text data**: it offers both out-of-the-box solutions but it's also flexible for custom-solutions.\n\n* **Natural Language Processing**: keyphrases and keywords extraction, and named entity recognition.\n\n* **Text representation**: TF-IDF, term frequency, and custom word-embeddings (wip)\n\n* **Vector space analysis**: clustering (K-means, Meanshift, DBSAN and Hierarchical), topic modelling (wip) and interpretation.\n\n* **Text visualization**: vector space visualization, place localization on maps (wip).\n\n\nSupported representation algorithms:\n\n* Term frequency (count)\n* Term frequency-inverse document frequency (tfidf)\n\n\nSupported clustering algorithms:\n\n* K-means (kmeans)\n* Density-Based Spatial Clustering of Applications with Noise (dbscan)\n* Meanshift (meanshift)\n\n\nSupported dimensionality reduction algorithms:\n\n* Principal component analysis (pca)\n* t-distributed stochastic neighbor embedding (tsne)\n* Non-negative matrix factorization (nmf)","729738d9":"so the above mentioned preprocessing steps can be done in only one step.That is the magic of texthero library :)"}}