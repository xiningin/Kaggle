{"cell_type":{"71d305bc":"code","f773e196":"code","be000124":"code","a86e9256":"code","daaacd7d":"code","d5338813":"code","02f3cd27":"code","cf091793":"code","093f6aef":"code","e149ec69":"code","f8cb019f":"code","f4b550bb":"code","d43a1197":"code","5f9d3fc0":"code","cc93dd9f":"code","b27e56b0":"code","3292782c":"code","db31f62b":"code","b0deacd5":"code","e40a8807":"code","c1cc82b8":"code","0277488d":"code","aac01556":"code","903957ec":"code","8e0f9db2":"code","ccfa7df0":"code","569fe3e4":"code","5666e987":"code","cf3b8d3f":"code","df948c48":"code","43299706":"code","915d23f9":"code","e0cd0aff":"code","deb4ed80":"code","ac72e67c":"code","f17efef8":"code","1407a7fe":"code","2c06ed35":"code","a0059099":"code","55b5acb6":"code","4d38bad0":"code","2300e4d5":"code","f9f6e7ac":"code","16774da7":"code","91c428db":"code","fe6fbda7":"code","9db3e04c":"code","ffba0993":"code","55610b95":"code","baeb7dbf":"code","2fa26f69":"code","cd6ad582":"code","60630ef2":"code","ea2ddb64":"code","9b28ded9":"code","b3d8c055":"code","8214219f":"code","866e967f":"code","77d68cfd":"code","f329a2b3":"code","7ca9da70":"code","e076297e":"code","6f01fe5e":"code","0ec3342a":"code","978dcad4":"code","3beb05b8":"code","fe70d0e5":"code","f195bcc5":"code","9c5fa62c":"code","f81240cc":"code","439298f4":"code","9258ace7":"code","fd68b4d9":"code","e05a98b1":"code","b5d0dbd3":"code","0b5af2c2":"code","37d01c02":"code","f46eb20b":"code","6937faf3":"code","d220b855":"code","4de09c1c":"code","848b8f75":"code","e257b003":"code","6761f7b8":"code","3480f902":"code","3b415aba":"code","1189d55b":"code","dfc047e1":"code","710aab1f":"code","8611797f":"markdown","32345947":"markdown","b4bf4076":"markdown","2413d3f1":"markdown","49d0f203":"markdown","42f44f2a":"markdown","ad3795d5":"markdown","0b32cdcf":"markdown","3434c245":"markdown","22fcdd4c":"markdown","e21ab0f8":"markdown","36773688":"markdown","1d624992":"markdown","3aaa9a05":"markdown","4d7b7908":"markdown","9ed7c7a1":"markdown","62c1e590":"markdown","7567c4a0":"markdown","78df73b2":"markdown","dc7e476e":"markdown","914890a1":"markdown","c76ba4b1":"markdown","93b78562":"markdown","4767e79a":"markdown","7fedecb0":"markdown","7fa81e0a":"markdown","19d28d97":"markdown","61ea9010":"markdown","5aca72b4":"markdown","0df8b47d":"markdown","f7262d53":"markdown","6d538b82":"markdown","33f65973":"markdown","62770f42":"markdown","17fb13f5":"markdown","b38de33d":"markdown","bf1fa211":"markdown","958882de":"markdown","4696d65e":"markdown","078fa12b":"markdown","369f0f86":"markdown","b765a8fc":"markdown","319df750":"markdown","2a74c763":"markdown","f8257c33":"markdown","ab8c2036":"markdown","93db2be9":"markdown","81463f1f":"markdown","e9b78a35":"markdown","c4b7459e":"markdown","4da65414":"markdown","87833250":"markdown","a839b410":"markdown"},"source":{"71d305bc":"import numpy as np # linear algebra\nimport pandas as pd # data processing, csv file,I\/O(e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-whitegrid')\n\nimport seaborn as sns\n\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname,_, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n#Any results you write to the current directory are saved as output  ","f773e196":"train_df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_PassengerId = test_df[\"PassengerId\"]","be000124":"train_df.columns","a86e9256":"train_df.head()","daaacd7d":"train_df.describe().T","d5338813":"train_df.info()","02f3cd27":"def bar_plot(variable):\n    \"\"\"\n        input: variable ex:\"Sex\"\n        output: barplot & value count\n    \n    \"\"\"\n   #get feature \n    var = train_df[variable]\n    \n    #count number of categorical variable(value\/sample)\n    varValue = var.value_counts()\n    \n    # visualization\n    plt.figure(figsize = (9,3))\n    plt.bar(varValue.index, varValue)\n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel(\"Frequency\")\n    plt.title(variable)\n    plt.show()\n    print(\"{}: \\n {}\".format(variable, varValue))","cf091793":"categories1 = [\"Survived\", \"Sex\", \"Pclass\", \"Embarked\", \"SibSp\", \"Parch\"]\nfor category in categories1:\n    bar_plot(category)\n","093f6aef":"categories2 = [\"Cabin\", \"Name\", \"Ticket\"]\nfor category in categories2:\n    print(\"{} \\n\".format(train_df[category].value_counts()))","e149ec69":"def plot_hist(variable):\n    plt.figure(figsize = (9,3))\n    plt.hist(train_df[variable], bins = 50)\n    plt.xlabel(variable)\n    plt.ylabel(\"Frequency\")\n    plt.title(\"{} distribution with hist\".format(variable))\n    plt.show()","f8cb019f":"numericVar = [\"Fare\", \"Age\", \"PassengerId\"]\nfor n in numericVar:\n    plot_hist(n)","f4b550bb":"# Pclass vs. Survived\ntrain_df[[\"Pclass\", \"Survived\"]].groupby([\"Pclass\"], as_index = False).mean().sort_values(by=\"Survived\",ascending = False)","d43a1197":"# Sex vs. Survived\ntrain_df[[\"Sex\", \"Survived\"]].groupby([\"Sex\"], as_index = False).mean().sort_values(by=\"Survived\",ascending = False)","5f9d3fc0":"# SibSp vs. Survived\ntrain_df[[\"SibSp\", \"Survived\"]].groupby([\"SibSp\"], as_index = False).mean().sort_values(by=\"Survived\",ascending = False)","cc93dd9f":"# Parch vs. Survived\ntrain_df[[\"Parch\", \"Survived\"]].groupby([\"Parch\"], as_index = False).mean().sort_values(by=\"Survived\",ascending = False)","b27e56b0":"def detect_outliers(df, features):\n    outlier_indices = []\n    \n    for c in features:\n        \n    # 1st Quartile\n        Q1 = np.percentile(df[c], 25)\n    \n    # 3rd Quartile\n        Q3 = np.percentile(df[c], 75)\n        \n    # IQR = 3rdQuartile - 1stQuartile\n        IQR = Q3 - Q1\n    \n    #Outlier Step \n        outlier_step = IQR * 1.5\n    \n    #detect outlier and their indices\n        outlier_list_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 + outlier_step )].index\n    \n    #store indices\n        outlier_indices.extend(outlier_list_col)\n    \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2) #if an observation has the outliers more than 2,then that observation will extract the dataset.\n    \n    return multiple_outliers","3292782c":"train_df.loc[detect_outliers(train_df, [\"Age\", \"SibSp\", \"Parch\", \"Fare\"])]","db31f62b":"#drop outliers\ntrain_df = train_df.drop(detect_outliers(train_df, [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]), axis = 0).reset_index(drop = True)\n","b0deacd5":"train_df_len = len(train_df)\ntrain_df = pd.concat([train_df, test_df], axis = 0).reset_index(drop = True)\n","e40a8807":"train_df.head()","c1cc82b8":"train_df.columns[train_df.isnull().any()]\n# it shows which columns have a null value","0277488d":"train_df.isnull().sum()","aac01556":"train_df[train_df[\"Embarked\"].isnull()]","903957ec":"train_df.boxplot(column=\"Fare\", by=\"Embarked\")\n\nplt.show()\n","8e0f9db2":"train_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"C\")\ntrain_df[train_df[\"Embarked\"].isnull()]","ccfa7df0":"train_df[train_df[\"Fare\"].isnull()]","569fe3e4":"train_df[\"Fare\"] = train_df[\"Fare\"].fillna(np.mean(train_df[train_df[\"Pclass\"]==3][\"Fare\"]))","5666e987":"train_df[train_df[\"Fare\"].isnull()]","cf3b8d3f":"list1 = [\"SibSp\", \"Parch\", \"Age\", \"Fare\", \"Survived\"]\nsns.heatmap(train_df[list1].corr(), annot = True, fmt = \".2f\")\nplt.show()","df948c48":"g = sns.factorplot(x = \"SibSp\", y = \"Survived\", data = train_df, kind = \"bar\", size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","43299706":"g = sns.factorplot(x = \"Parch\", y = \"Survived\", data = train_df, kind = \"bar\", size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","915d23f9":"g = sns.factorplot(x = \"Pclass\", y = \"Survived\", data = train_df, kind = \"bar\", size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","e0cd0aff":"g = sns.FacetGrid(train_df, col = \"Survived\")\ng.map(sns.distplot, \"Age\", bins = 25)\nplt.show()","deb4ed80":"g = sns.FacetGrid(train_df, col = \"Survived\", row = \"Pclass\", size = 3)\ng.map(plt.hist, \"Age\", bins = 25)\ng.add_legend()\nplt.show()","ac72e67c":"g = sns.FacetGrid(train_df, row = \"Embarked\", size = 2)\ng.map(sns.pointplot, \"Pclass\",\"Survived\",\"Sex\")\ng.add_legend()\nplt.show()","f17efef8":"g = sns.FacetGrid(train_df, row = \"Embarked\", col = \"Survived\", size = 2.5)\ng.map(sns.barplot, \"Sex\", \"Fare\")\ng.add_legend()\nplt.show()","1407a7fe":"train_df[train_df[\"Age\"].isnull()]","2c06ed35":"sns.factorplot(x = \"Sex\", y = \"Age\", data = train_df, kind = \"box\")\nplt.show()","a0059099":"sns.factorplot(x = \"Sex\", y = \"Age\", hue = \"Pclass\",data = train_df, kind = \"box\")\nplt.show()","55b5acb6":"sns.factorplot(x = \"Parch\", y = \"Age\", data = train_df, kind = \"box\")\nsns.factorplot(x = \"SibSp\", y = \"Age\", data = train_df, kind = \"box\")\nplt.show()","4d38bad0":"train_df[\"Sex\"] = [1 if i == \"male\" else 0 for i in train_df[\"Sex\"]]","2300e4d5":"train_df[\"Sex\"].head()","f9f6e7ac":"sns.heatmap(train_df[[\"Age\",\"Sex\",\"SibSp\",\"Parch\",\"Pclass\"]].corr(), annot = True)\nplt.show()","16774da7":"# we write a code block for the age values which have the null\n\nindex_nan_age = list(train_df[\"Age\"][train_df[\"Age\"].isnull()].index)\nfor i in index_nan_age:\n    age_pred = train_df[\"Age\"][((train_df[\"SibSp\"] == train_df.iloc[i][\"SibSp\"]) &(train_df[\"Parch\"] == train_df.iloc[i][\"Parch\"])& (train_df[\"Pclass\"] == train_df.iloc[i][\"Pclass\"]))].median()\n    age_med = train_df[\"Age\"].median()\n    if not np.isnan(age_pred):\n        train_df[\"Age\"].iloc[i] = age_pred\n    else:\n        train_df[\"Age\"].iloc[i] = age_med","91c428db":"train_df[train_df[\"Age\"].isnull()]","fe6fbda7":"train_df[\"Name\"].head(10)","9db3e04c":"name = train_df[\"Name\"]\ntrain_df[\"Title\"] = [i.split(\".\")[0].split(\",\")[-1].strip() for i in name]","ffba0993":"train_df[\"Title\"].head(10)","55610b95":"sns.countplot(x=\"Title\", data = train_df)\nplt.xticks(rotation = 60)\nplt.show()","baeb7dbf":"# convert to categorical\ntrain_df[\"Title\"] = train_df[\"Title\"].replace([\"Lady\",\"the Countess\",\"Capt\",\"Col\",\"Don\",\"Dr\",\"Major\",\"Rev\",\"Sir\",\"Jonkheer\",\"Dona\"],\"other\")\ntrain_df[\"Title\"] = [0 if i == \"Master\" else 1 if i == \"Miss\" or i == \"Ms\" or i == \"Mlle\" or i == \"Mrs\" else 2 if i == \"Mr\" else 3 for i in train_df[\"Title\"]]\ntrain_df[\"Title\"].head(20)","2fa26f69":"sns.countplot(x=\"Title\", data = train_df)\nplt.xticks(rotation = 60)\nplt.show()","cd6ad582":"g = sns.factorplot(x = \"Title\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_xticklabels([\"Master\",\"Mrs\",\"Mr\",\"Other\"])\ng.set_ylabels(\"Survival Probability\")\nplt.show()","60630ef2":"train_df.drop(labels = [\"Name\"], axis = 1, inplace = True)","ea2ddb64":"train_df.head()","9b28ded9":"train_df = pd.get_dummies(train_df,columns=[\"Title\"])\ntrain_df.head()","b3d8c055":"train_df.head()","8214219f":"# we used +1 for the person herself\ntrain_df[\"Fsize\"] = train_df[\"SibSp\"] + train_df[\"Parch\"] + 1","866e967f":"train_df.head()","77d68cfd":"g = sns.factorplot(x = \"Fsize\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_ylabels(\"Survival\")\nplt.show()","f329a2b3":"train_df[\"family_size\"] = [1 if i < 5 else 0 for i in train_df[\"Fsize\"]]","7ca9da70":"train_df.head(10)","e076297e":"sns.countplot(x = \"family_size\", data = train_df)\nplt.show()","6f01fe5e":"g = sns.factorplot(x = \"family_size\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_ylabels(\"Survival\")\nplt.show()","0ec3342a":"train_df = pd.get_dummies(train_df, columns= [\"family_size\"])\ntrain_df.head()","978dcad4":"train_df[\"Embarked\"].head()","3beb05b8":"sns.countplot(x = \"Embarked\", data = train_df)\nplt.show()","fe70d0e5":"train_df = pd.get_dummies(train_df, columns=[\"Embarked\"])\ntrain_df.head()","f195bcc5":"train_df[\"Ticket\"].head(20)","9c5fa62c":"a = \"A\/5. 2151\"\na.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0]","f81240cc":"tickets = []\nfor i in list(train_df.Ticket):\n    if not i.isdigit():\n        tickets.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0])\n    else:\n        tickets.append(\"x\")\ntrain_df[\"Ticket\"] = tickets","439298f4":"train_df[\"Ticket\"].head(20)","9258ace7":"train_df.head()","fd68b4d9":"train_df = pd.get_dummies(train_df, columns= [\"Ticket\"], prefix = \"T\")\ntrain_df.head(10)","e05a98b1":"sns.countplot(x = \"Pclass\", data = train_df)\nplt.show()","b5d0dbd3":"train_df[\"Pclass\"] = train_df[\"Pclass\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df, columns= [\"Pclass\"])\ntrain_df.head()","0b5af2c2":"train_df[\"Sex\"] = train_df[\"Sex\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df, columns=[\"Sex\"])\ntrain_df.head()","37d01c02":"train_df.drop(labels = [\"PassengerId\", \"Cabin\"], axis = 1, inplace = True)","f46eb20b":"train_df.columns","6937faf3":"from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","d220b855":"train_df_len\n# This is the value before the merge was made.","4de09c1c":"test = train_df[train_df_len:]\ntest.drop(labels = [\"Survived\"],axis = 1, inplace = True)","848b8f75":"test.head()","e257b003":"train = train_df[:train_df_len]\nX_train = train.drop(labels = \"Survived\", axis = 1)\ny_train = train[\"Survived\"]\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.33, random_state = 42)\nprint(\"X_train\",len(X_train))\nprint(\"X_test\",len(X_test))\nprint(\"y_train\",len(y_train))\nprint(\"y_test\",len(y_test))\nprint(\"test\",len(test))","6761f7b8":"logreg = LogisticRegression(solver='liblinear')\nlogreg.fit(X_train, y_train)\nacc_log_train = round(logreg.score(X_train, y_train)*100,2) \nacc_log_test = round(logreg.score(X_test,y_test)*100,2)\nprint(\"Training Accuracy: % {}\".format(acc_log_train))\nprint(\"Testing Accuracy: % {}\".format(acc_log_test))","3480f902":"random_state = 42\nclassifier = [DecisionTreeClassifier(random_state = random_state),\n             SVC(random_state = random_state),\n             RandomForestClassifier(random_state = random_state),\n             LogisticRegression(random_state = random_state),\n             KNeighborsClassifier()]\n\ndt_param_grid = {\"min_samples_split\" : range(10,500,20),\n                \"max_depth\": range(1,20,2)}\n\nsvc_param_grid = {\"kernel\" : [\"rbf\"],\n                 \"gamma\": [0.001, 0.01, 0.1, 1],\n                 \"C\": [1,10,50,100,200,300,1000]}\n\nrf_param_grid = {\"max_features\": [1,3,10],\n                \"min_samples_split\":[2,3,10],\n                \"min_samples_leaf\":[1,3,10],\n                \"bootstrap\":[False],\n                \"n_estimators\":[100,300],\n                \"criterion\":[\"gini\"]}\n\nlogreg_param_grid = {\"C\":np.logspace(-3,3,7),\n                    \"penalty\": [\"l1\",\"l2\"]}\n\nknn_param_grid = {\"n_neighbors\": np.linspace(1,19,10, dtype = int).tolist(),\n                 \"weights\": [\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\"]}\nclassifier_param = [dt_param_grid,\n                   svc_param_grid,\n                   rf_param_grid,\n                   logreg_param_grid,\n                   knn_param_grid]","3b415aba":"cv_result = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i], param_grid=classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1,verbose = 1)\n    clf.fit(X_train,y_train)\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print(cv_result[i])","1189d55b":"cv_results = pd.DataFrame({\"Cross Validation Means\":cv_result, \"ML Models\":[\"DecisionTreeClassifier\", \"SVM\",\"RandomForestClassifier\",\n             \"LogisticRegression\",\n             \"KNeighborsClassifier\"]})\n\ng = sns.barplot(\"Cross Validation Means\", \"ML Models\", data = cv_results)\ng.set_xlabel(\"Mean Accuracy\")\ng.set_title(\"Cross Validation Scores\")","dfc047e1":"votingC = VotingClassifier(estimators = [(\"dt\",best_estimators[0]),\n                                        (\"rfc\",best_estimators[2]),\n                                        ],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_train, y_train)\nprint(accuracy_score(votingC.predict(X_test),y_test))","710aab1f":"test_survived = pd.Series(votingC.predict(test), name = \"Survived\").astype(int)\nresults = pd.concat([test_PassengerId, test_survived],axis = 1)\nresults.to_csv(\"submission.csv\", index = False)","8611797f":"<a id = '6'><\/a><br>\n## 3. Basic Data Analysis\n\nHere, we try to understand if there is a relationship between each of the below features and the \"survived\" feature.\n\n* Pclass - Survived\n* Sex - Survived\n* SibSp - Survived\n* Parch - Survived","32345947":"<a id=\"18\"><\/a><br>\n###  Embarked -- Sex -- Pclass -- Survived","b4bf4076":"<a id = '3'><\/a><br>\n### Univariate Variable Analysis\n* **Categorical Variable:** Name, Sex, Ticket, Cabin, Embarked, Survived,Pclass,Sibsp, Parch\n* **Numerical Variable:** Age, Fare, PassengerId","2413d3f1":"* Pclass is important feature for our model training.","49d0f203":"* Having a lot of SibSp have less chance to survive\n* If SibSp == 0 or 1 or 2, passenger has more chance to survive\n* We can consider a new feature describing these categories","42f44f2a":"<a id=\"32\"><\/a><br>\n### Hyperparameter Tuning -- Grid Search -- Cross Validation","ad3795d5":"* age <= 10 has a high survival rate,\n* oldest passengers (80) survived,\n* large number of 20 years old did not survive,\n* most passengers are in 15-35 age range,\n* use age feature in training\n* use age distribution for missing value of age","0b32cdcf":"* Sex is not informative for age prediction, age distribution seems to be same.","3434c245":"<a id=\"22\"><\/a><br>\n###  Name -- Title","22fcdd4c":"<a id=\"15\"><\/a><br>\n###  Pclass -- Survived","e21ab0f8":"<a id=\"28\"><\/a><br>\n### Drop Passenger ID and Cabin","36773688":"<a id=\"12\"><\/a><br>\n###  Correlation Between SibSp -- Parch -- Age -- Fare -- Survived","1d624992":"<a id=\"24\"><\/a><br>\n###  Embarked","3aaa9a05":"<a id='2'><\/a><br>\n## 2. Variable Description\n\n1. **PassengerId:** unique id number to each passenger\n2. **Survived:** passenger survive(1) or died(0)\n3. **Pclass:** passenger class\n4. **Name:** name\n5. **Sex:** gender of passenger\n6. **Age:** age of passenger\n7. **SibSp**: number of siblings\/spouses\n8. **Parch:** -->PARent\/CHildren: number of parents\/children\n9. **Ticket:** ticket number\n10. **Fare:** amount of money spent on ticket\n11. **Cabin:** cabin category\n12. **Embarked:** port where passenger embarked(C= Cherbourg, Q= Queenstown, S= Southampton)","4d7b7908":"<a id=\"11\"><\/a><br>\n## 6. Visualization","9ed7c7a1":"Fare feature seems to have a correlation with survived feature(0.26).","62c1e590":">* Female passengers have much better survival rate than males.\n>* Male passengers have better survival rate in pclass 3 in C.\n>* Embarked and sex will be used in training.","7567c4a0":"<a id=\"33\"><\/a><br>\n### Ensemble Modeling","78df73b2":"* Age is not correlated with sex but it is correlated with parch, sibsp and pclass.","dc7e476e":"<a id=\"27\"><\/a><br>\n###  Sex","914890a1":"<a id=\"16\"><\/a><br>\n###  Age -- Survived","c76ba4b1":"<a id=\"30\"><\/a><br>\n### Train - Test Split","93b78562":"We will compare 5 ml classifier and evaluate mean accuracy of each of them by stratified cross validation.\n\n> * Decision Tree\n> * SVM\n> * Random Forest\n> * KNN\n> * Logistic Regression","4767e79a":"<a id=\"13\"><\/a><br>\n###  SibSp -- Survived","7fedecb0":"# Introduction\n\nThe sinking of Titanic is one of the most notorious shipwrecks in the history. In 1912, during her voyage, the Titanic sank after colliding with iceberg, killing 1502 out of 2224 passengers and crew.\n\n<font color = 'blue'>\nContent:\n\n1. [Load and Check Data](#1)\n2. [Variable Description](#2)\n   \n * [Univariate Variable Analysis](#3)\n  * [Categorical Variable Analysis](#4)\n  * [Numerical Variable Analysis](#5)\n\n3. [Basic Data Analysis](#6)\n4. [Outlier Detection](#7)\n5. [Missing Value](#8)\n    \n * [Find Missing Value](#9)\n * [Fill Missing Value](#10)\n \n6. [Visualization](#11)\n\n * [Correlation Between SibSp -- Parch -- Age -- Fare -- Survived](#12)\n * [SibSp -- Survived](#13)\n * [Parch -- Survived](#14)\n * [Pclass -- Survived](#15)\n * [Age -- Survived](#16)\n * [Pclass -- Survived -- Age](#17)\n * [Embarked -- Sex -- Pclass -- Survived](#18)\n * [Embarked -- Sex -- Fare -- Survived](#19)\n * [Fill Missing: Age Feature](#20)\n\n7. [Feature Engineering](#21)\n\n * [Name -- Title](#22)\n * [Family Size](#23)\n * [Embarked](#24)\n * [Ticket](#25)\n * [Pclass](#26)\n * [Sex](#27)\n * [Drop Passenger ID and Cabin](#28)\n   \n8. [Modeling](#29)\n    \n * [Train - Test Split](#30)\n * [Simple Logistic Regression](#31)\n * [Hyperparameter Tuning -- Grid Search -- Cross Validation](#32)\n * [Ensemble Modeling](#33)\n * [Prediction and Submission](#34)\n    ","7fa81e0a":"<a id=\"19\"><\/a><br>\n###  Embarked -- Sex -- Fare -- Survived","19d28d97":"<a id=\"14\"><\/a><br>\n###  Parch -- Survived","61ea9010":"<p>According to this result, there doesn't exist an age of 256 passengers, cabin info of 1007 passengers, the fare of 1 passenger, and embarked info of 2 passengers. Also having missing values of 418 survived passengers is due to the test dataset does not have the survived info.<\/p>","5aca72b4":"* **float64(2):** Age, Fare\n* **int64(5):** PassengerId, Survived, Pclass, Sibsp,Parch\n* **object(5):** Name, Sex, Ticket, Cabin, Embarked","0df8b47d":"* SibSp and parch can be used for new feature extraction with threshold = 3\n* Small families have more chance to survive\n* There is std in surival of passenger with Parch = 3","f7262d53":"<a id = \"8\"><\/a><br>\n## 5. Missing Value\n\n* Find Missing Value\n* Fill Missing Value\n\nFirst, we need to find the missing data by combining the training dataset and the test dataset. Because if we don't do this, it will cause an error when it sees the missing values in the test data set while applying our model.","6d538b82":"<a id=\"20\"><\/a><br>\n###  Fill Missing: Age Feature","33f65973":"<a id=\"26\"><\/a><br>\n###  Pclass","62770f42":"<a id=\"34\"><\/a><br>\n### Prediction and Submission","17fb13f5":"* 1st class passengers are older than 2nd, and 2nd is older than 3rd class.","b38de33d":"> We can not see the sex feature in the heatmap. Because sex feature does not have numerical data. We need to convert it to numerical data.","bf1fa211":"> We joined test and train data by finding missing value in section 5. Now we will extract the test dataset from train dataset.","958882de":"<a id=\"21\"><\/a><br>\n##  7. Feature Engineering","4696d65e":"<a id = \"10\"><\/a><br>\n### Fill Missing Value\n<br>\n\n*  Embarked has 2 missing value\n*  Fare has only 1\n","078fa12b":"<a id = '1'><\/a><br>\n## 1. Load and Check Data","369f0f86":"<a id = \"9\"><\/a><br>\n### Find Missing Value","b765a8fc":"<a id=\"31\"><\/a><br>\n### Simple Logistic Regression","319df750":"Embarked is null with a \"fare\" value of 80.\n\nWhen the \"Boxplot\" is examined, we see that there are no values with this value from the Q and S class. When the boxplot is examined, we can clearly see that the fare value of the C class can be 80. So we will fill these null values as C.","2a74c763":"<a id = '5'><\/a><br>\n####  Numerical Variable","f8257c33":"* Passsengers who pay higher fare have better survival. Fare can be used as categorical for training.","ab8c2036":"<a id = '7'><\/a><br>\n## 4. Outlier Detection\n\nThe sample that distorts the data in the dataset we have is called an outlier.","93db2be9":"> Whether people survive or not may have changed according to their titles. Here we will examine it.","81463f1f":"<a id=\"25\"><\/a><br>\n###  Ticket","e9b78a35":"<a id=\"17\"><\/a><br>\n###  Pclass -- Survived -- Age","c4b7459e":"<a id = '4'><\/a><br>\n####   Categorical Variable","4da65414":"* Small familes have more chance to survive than large families.","87833250":"<a id=\"29\"><\/a><br>\n## 8. Modeling","a839b410":"<a id=\"23\"><\/a><br>\n###  Family Size"}}