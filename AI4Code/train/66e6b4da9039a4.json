{"cell_type":{"5dc3ad0e":"code","c16e86e2":"code","5424759c":"code","69d725ae":"code","51606f7d":"code","999b9ee3":"code","390ded98":"code","27ad6086":"code","c8c22557":"code","156e0474":"code","e07765f9":"code","1a1b5ce4":"code","89f8ccbd":"code","eb4ecf1d":"code","9ed9de13":"code","7873c83c":"code","356d31d4":"code","5a9dc158":"code","a35fa0ef":"code","78284f95":"code","f52d30a3":"code","19b70dac":"code","d7655d4b":"markdown","4941ebd4":"markdown","f5549ecb":"markdown","1e54b5f2":"markdown","c5f497aa":"markdown","af50c911":"markdown","f58def9e":"markdown","2893125f":"markdown","a806d6e7":"markdown","823a6199":"markdown","07066ab7":"markdown"},"source":{"5dc3ad0e":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport nltk\nimport string\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nimport warnings\nwarnings.filterwarnings('ignore')\n","c16e86e2":"data= pd.read_csv('..\/input\/sms-spam-collection-dataset\/spam.csv',delimiter=',',encoding='latin-1')","5424759c":"data.head() #First five row","69d725ae":"data.shape","51606f7d":"data.isna().sum()","999b9ee3":"data.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'],axis=1,inplace=True)\ndata = data.rename(columns={'v1':'Labels','v2':'Message'}) ","390ded98":"data.info()","27ad6086":"sns.countplot(data.Labels)\nplt.title('No. of ham and spam messages')\nprint('{:0.2f}% of the ham massages'.format(100*(data.Labels.value_counts()[0])\/len(data)))\nprint('{:0.2f}% of the spam massages'.format(100*(data.Labels.value_counts()[1])\/len(data)))\n","c8c22557":"pd.set_option('display.max_colwidth',2000)","156e0474":"data['message_len']=data['Message'].apply(len)","e07765f9":"data.describe()","1a1b5ce4":"data.loc[data['message_len'].max()][1]","89f8ccbd":"data['Text'] = data['Message'].map(lambda word :''.join([w for w in word if not w in string.punctuation]))\ndata['Text'] = data['Text'].map(lambda text : word_tokenize(text.lower()))\nstopword = set(stopwords.words('english'))\ndata['Text'] = data['Text'].map(lambda token : [w for w in token if not w in stopword])","eb4ecf1d":"data.head()","9ed9de13":"from nltk.stem import SnowballStemmer\nstemmer = SnowballStemmer(\"english\")\ndata['Text'] = data['Text'].map(lambda text : [stemmer.stem(w)for w in text])","7873c83c":"data['Text'] = data['Text'].map(lambda text : ' '.join(text))","356d31d4":"data.head()","5a9dc158":"from sklearn.feature_extraction.text import TfidfVectorizer\nx = data['Text']\ny = data['Labels']","a35fa0ef":"tfidf = TfidfVectorizer()\ntfidf_dtm = tfidf.fit_transform(x)\ntfidf_data=pd.DataFrame(tfidf_dtm.toarray())\ntfidf_data.head()","78284f95":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(tfidf_data,y,test_size=0.2)","f52d30a3":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score\nnb = MultinomialNB(alpha=0.2)\nnb.fit(x_train,y_train)\npred = nb.predict(x_test)\naccuracy_score(pred,y_test)","19b70dac":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nlr = LogisticRegression()\nlr.fit(x_train,y_train)\npred = lr.predict(x_test)\naccuracy_score(pred,y_test)","d7655d4b":"Let's calculate the percentage of ham and spam messages","4941ebd4":"After all that stems each word.Stemming is the process of reducing inflected words to their word stem, base or root form generally a written word form. Here, i am using 'SnowballStemmer'(this means that it replaces a word with the root of that word, for example \"tasted\" or \"tasting\" would become \"taste\").","f5549ecb":"Naive bayes gives the best result.","1e54b5f2":"Now define our text precessing function,comman preprocessing includes removing punctuation and stopwords (i.e. \"and\" \"or\" these words are not giving useful meaning). Also the characters are changed to lower case ","c5f497aa":"Lets convert our clean text into a representation that a machine learning model can understand. I'll use the Tfifd for this","af50c911":"# First import of required lybraries","f58def9e":"As the preview of data shows there are three useless columns, we need to delete these columns and Rename the columns v1 and v2 to 'Labels' and 'Message'","2893125f":"Let's read the data from csv file","a806d6e7":"Let's split our features into train and test test","823a6199":"86% of data consists of ham message","07066ab7":"Import machine model and make functions to fit our classifiers and make predictions"}}