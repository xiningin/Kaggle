{"cell_type":{"982c14a8":"code","9010402a":"code","0b249524":"code","f1373839":"code","d0f3479e":"code","c120917c":"code","d4bdf048":"code","db7faea7":"code","612dafae":"code","9d8b5e67":"code","26ce5ed7":"code","7fba7901":"code","e4b4ba93":"code","728b40d2":"code","b8587d58":"code","5ecc981d":"code","578f0fbf":"code","2a33907c":"code","28dd8b4b":"code","c7f80c77":"code","55dfff62":"code","2cff758f":"code","d05edfea":"code","6fa9b772":"code","10daf59d":"code","d682b2a0":"code","bcd13913":"code","5b59fad6":"code","6444808c":"code","5a107fe4":"code","a59524ea":"code","7cbac2f7":"code","b65eb05c":"code","5fa3e0ff":"code","e578e784":"code","ae950d8f":"code","688f64d6":"code","9d12ceb6":"code","b040da62":"code","d1fa1332":"code","3cb4657d":"code","18d4a157":"code","3205f5ce":"code","209ad356":"code","d983845e":"code","e594d698":"code","a35cfcb0":"code","fed09b90":"code","0f19fe7c":"code","07aeb2bf":"code","f96785f9":"code","3da6a7cd":"code","4ea72dac":"code","b534af7b":"code","ca83f810":"code","b5264189":"code","0d26d970":"code","bd2769d3":"code","82e3c97e":"code","9f5039af":"code","4c1ecc95":"code","4dd83120":"code","1c288d85":"code","2c87f206":"code","0eb082fe":"code","7a8b2078":"code","47dfd251":"code","c24ed92f":"code","8a4f0c75":"markdown","2b7f92d9":"markdown","867230b1":"markdown","bdba969e":"markdown","12d5a75a":"markdown","d438fd5a":"markdown","a32051bb":"markdown","8e219d1e":"markdown","d0bd9c91":"markdown","47a04d72":"markdown","08475580":"markdown","ed239791":"markdown","c3a7923b":"markdown","2ad6948c":"markdown","554e5260":"markdown","713babbe":"markdown","b92e0c4d":"markdown","470cb4ba":"markdown","2599473d":"markdown","bda63a7a":"markdown","902540c6":"markdown","e06f24e3":"markdown","4ee4d97b":"markdown","c471d6f8":"markdown","3d39c08f":"markdown","064f3012":"markdown","e4fd9307":"markdown","f99bb62c":"markdown","dbb9e2cd":"markdown","c566ae76":"markdown","98d15ed0":"markdown","c1ea1f7a":"markdown","1b0016bc":"markdown","5a175c9a":"markdown","37e01bb8":"markdown","d57db72b":"markdown","a8bd40cc":"markdown","b5c6f552":"markdown","5a8ab6e6":"markdown","6e152a63":"markdown","0b35602f":"markdown","a63b3c34":"markdown","2f6bf0d7":"markdown","46f0fcdf":"markdown","7b357b2e":"markdown","0a60fc42":"markdown","ee1c7b2f":"markdown","9e946512":"markdown","bbf018fc":"markdown","26424e84":"markdown","019dc630":"markdown","eee4659e":"markdown"},"source":{"982c14a8":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\nsns.color_palette(\"crest\", as_cmap=True)\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","9010402a":"data = pd.read_csv(\"..\/input\/buildingenergycleaned\/building-energy-cleaned.csv\")\ndata.head()","0b249524":"data.info()","f1373839":"data.describe()","d0f3479e":"data[(data.GFAPerBuilding == np.inf) | (data.GFAPerFloor == np.inf)].head()","c120917c":"data['GFAPerBuilding'] = np.where(((data.GFAPerBuilding == np.inf) & (data.NumberofBuildings == 0)),0, data.GFAPerBuilding)\ndata['GFAPerFloor'] = np.where(((data.GFAPerFloor == np.inf) & (data.NumberofFloors == 0)),0, data.GFAPerFloor)","d4bdf048":"font_title = {'family': 'serif',\n              'color':  '#1d479b',\n              'weight': 'bold',\n              'size': 18,\n             }\n\nfig = plt.figure(figsize=(12,8))\nsns.scatterplot(data = data, x='PropertyGFATotal', y='SiteEnergyUse(kBtu)', hue='BuildingType')\nplt.title(f\"Consommations d'\u00e9nergie par surface totale au sol et par type de b\u00e2timent\\n\", \n          fontdict=font_title, fontsize=16)\nplt.show()","db7faea7":"data[data['SiteEnergyUse(kBtu)']>8*10**8]","612dafae":"data = data[data['SiteEnergyUse(kBtu)']<8*10**8]","9d8b5e67":"identification_features = ['OSEBuildingID', 'PropertyName', 'Address', 'ZipCode']\ndata_identification = data[identification_features]\ndata.drop(identification_features, axis=1, inplace = True)","26ce5ed7":"data_filter = data.drop(['SteamUse(kBtu)','Electricity(kBtu)',\n                         'NaturalGas(kBtu)'], axis=1)","7fba7901":"numerical_features = data_filter.select_dtypes(include=['int64','float64'])\ncategorical_features = data_filter.select_dtypes(exclude=['int64','float64']) ","e4b4ba93":"categorical_features.nunique()","728b40d2":"categorical_features = categorical_features.drop(['State','YearsENERGYSTARCertified'], axis=1)","b8587d58":"list(numerical_features.columns)","5ecc981d":"energystar_score = numerical_features['ENERGYSTARScore']\nnumerical_features = numerical_features.drop(['ENERGYSTARScore','DataYear'], axis=1)","578f0fbf":"data_filter = pd.concat([categorical_features, numerical_features], axis=1)","2a33907c":"from sklearn.preprocessing import StandardScaler, OrdinalEncoder, RobustScaler\nfrom category_encoders.target_encoder import TargetEncoder\nfrom sklearn.compose import ColumnTransformer\n\ntarget_features = ['BuildingType','PrimaryPropertyType','Neighborhood','LargestPropertyUseType']\ntarget_transformer = TargetEncoder()\n\nnumeric_features = ['harvesine_distance','NumberofBuildings','NumberofFloors',\n                    'PropertyGFATotal','BuildingAge','TotalUseTypeNumber',\n                    'GFABuildingRate','GFAParkingRate','GFAPerBuilding','GFAPerFloor']\nnumeric_transformer = RobustScaler(unit_variance=True)\n\npreprocessor = ColumnTransformer(transformers=[\n    ('target', target_transformer, target_features),\n    ('numeric', numeric_transformer, numeric_features)\n])","28dd8b4b":"import warnings\ndef get_feature_names(column_transformer):\n    \"\"\"Get feature names from all transformers.\n    Returns\n    -------\n    feature_names : list of strings\n        Names of the features produced by transform.\n        \n    ------\n    Code from :\n        https:\/\/johaupt.github.io\/\n    \"\"\"\n    # Remove the internal helper function\n    #check_is_fitted(column_transformer)\n    \n    # Turn loopkup into function for better handling with pipeline later\n    def get_names(trans):\n        # >> Original get_feature_names() method\n        if trans == 'drop' or (\n                hasattr(column, '__len__') and not len(column)):\n            return []\n        if trans == 'passthrough':\n            if hasattr(column_transformer, '_df_columns'):\n                if ((not isinstance(column, slice))\n                        and all(isinstance(col, str) for col in column)):\n                    return column\n                else:\n                    return column_transformer._df_columns[column]\n            else:\n                indices = np.arange(column_transformer._n_features)\n                return ['x%d' % i for i in indices[column]]\n        if not hasattr(trans, 'get_feature_names'):\n        # >>> Change: Return input column names if no method avaiable\n            # Turn error into a warning\n            warnings.warn(\"Transformer %s (type %s) does not \"\n                                 \"provide get_feature_names. \"\n                                 \"Will return input column names if available\"\n                                 % (str(name), type(trans).__name__))\n            # For transformers without a get_features_names method, use the input\n            # names to the column transformer\n            if column is None:\n                return []\n            else:\n                return [f for f in column]\n\n        return [f for f in trans.get_feature_names()]\n    \n    ### Start of processing\n    feature_names = []\n    \n    l_transformers = list(column_transformer._iter(fitted=True))\n    \n    \n    for name, trans, column, _ in l_transformers: \n        feature_names.extend(get_names(trans))\n    \n    return feature_names","c7f80c77":"from sklearn.model_selection import train_test_split\n\nX = data_filter.drop(['TotalGHGEmissions','SiteEnergyUse(kBtu)'], axis=1)\nY = data_filter[['TotalGHGEmissions','SiteEnergyUse(kBtu)']]\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n\nprint(\"Entrainement: {} lignes,\\nTest: {} lignes.\\n\".format(X_train.shape[0],\n                                                            X_test.shape[0]))","55dfff62":"from sklearn.preprocessing import FunctionTransformer\n\nlogtransformer = FunctionTransformer(np.log, inverse_func = np.exp, check_inverse = True)\nY_log = logtransformer.transform(Y)\n\nfig, axes = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=False, figsize=(20,8))\nsns.histplot(data=Y, x='TotalGHGEmissions', stat=\"density\", ax=axes[0])\naxes[0].set_title(\"Donn\u00e9es initiales\", color='#2cb7b0')\nsns.histplot(data=Y_log, x='TotalGHGEmissions', stat=\"density\", ax=axes[1])\naxes[1].set_title(\"Application du logarithme\", color='#2cb7b0')\nplt.suptitle(\"Distribution des emissions de CO2 avec changement d'\u00e9chelle\", fontdict=font_title, fontsize=22)\nplt.show()","2cff758f":"from sklearn.compose import TransformedTargetRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import set_config\nset_config(display='diagram')\n\n\nparam_mlr = {\"regressor__fit_intercept\": [True, False],\n             \"regressor__normalize\": [True, False]}\n\nmlr_grid_cv = Pipeline([\n    ('preprocessor', preprocessor),\n    ('grid_search_mlr', GridSearchCV(\n                            TransformedTargetRegressor(\n                                regressor=LinearRegression(), \n                                func=np.log, \n                                inverse_func=np.exp),\n                            param_grid=param_mlr,\n                            cv=5,\n                            scoring=('r2','neg_mean_absolute_error'),\n                            return_train_score = True,\n                            refit='neg_mean_absolute_error',\n                            n_jobs = -1))])","d05edfea":"#Retour des meilleurs scores NMAE et R2\n#Stockage du dataframe de resultats du mod\u00e8le\ndef model_scores(pip,step):\n    df_results = pd.DataFrame.from_dict(pip.named_steps[step].cv_results_) \\\n                    .sort_values('rank_test_neg_mean_absolute_error')\n    best_nmae = pip.named_steps[step].best_score_\n    best_r2 = np.mean(df_results[df_results.rank_test_r2 == 1]['mean_test_r2'])\n    best_params = pip.named_steps[step].best_params_\n    training_time = round((np.mean(df_results.mean_fit_time)*X_train.shape[0]),2)\n    print(\"Meilleur score MAE : {}\\nMeilleur Score R2 : {}\\nMeilleurs param\u00e8tres : {}\\nTemps moyen d'entrainement : {}s\"\\\n         .format(round(best_nmae,3), round(best_r2,3), best_params, training_time))\n    return df_results","6fa9b772":"#Entrainement sur les 2 variables \u00e0 expliquer :\nGHG_mlr_model = mlr_grid_cv.fit(X_train, Y_train['TotalGHGEmissions'])\nGHG_mlr_results = model_scores(GHG_mlr_model, 'grid_search_mlr')","10daf59d":"SEU_mlr_model = mlr_grid_cv.fit(X_train, Y_train['SiteEnergyUse(kBtu)'])\nSEU_mlr_results = model_scores(SEU_mlr_model, 'grid_search_mlr')","d682b2a0":"GHG_mlr_results","bcd13913":"SEU_mlr_model","5b59fad6":"from sklearn.linear_model import ElasticNet\n\nparam_eNet = {\"regressor__max_iter\": [10, 100, 1000],\n              \"regressor__alpha\": np.logspace(-4, 0, num=5),\n              \"regressor__l1_ratio\": np.arange(0.0, 1.1, 0.1)}\n\neNet_grid_cv = Pipeline([\n    ('preprocessor', preprocessor),\n    ('grid_search_enet', GridSearchCV(\n                            TransformedTargetRegressor(\n                                regressor=ElasticNet(), \n                                func=np.log, \n                                inverse_func=np.exp),\n                            param_grid=param_eNet,\n                            cv=5,\n                            scoring=('r2','neg_mean_absolute_error'),\n                            return_train_score = True,\n                            refit='neg_mean_absolute_error',\n                            n_jobs = -1))])","6444808c":"GHG_eNet_model = eNet_grid_cv.fit(X_train, Y_train['TotalGHGEmissions'])\nGHG_eNet_results = model_scores(GHG_eNet_model, 'grid_search_enet')","5a107fe4":"SEU_eNet_model = eNet_grid_cv.fit(X_train, Y_train['SiteEnergyUse(kBtu)'])\nSEU_eNet_results = model_scores(SEU_eNet_model, 'grid_search_enet')","a59524ea":"from sklearn.svm import LinearSVR\n\nparam_svr = {'regressor__C' : np.logspace(-4, 0, 5),\n             'regressor__epsilon' : [0, 0.01, 0.1, 0.5, 1, 2],\n             'regressor__loss' : [\"epsilon_insensitive\",\"squared_epsilon_insensitive\"],\n             'regressor__max_iter': [10, 100, 1000]}\n\nsvr_grid_cv = Pipeline([\n    ('preprocessor', preprocessor),\n    ('grid_search_svr', GridSearchCV(\n                            TransformedTargetRegressor(\n                                regressor=LinearSVR(), \n                                func=np.log, \n                                inverse_func=np.exp),\n                            param_grid=param_svr,\n                            cv=5,\n                            scoring=('r2','neg_mean_absolute_error'),\n                            refit='neg_mean_absolute_error',\n                            return_train_score = True,\n                            n_jobs = -1))])","7cbac2f7":"GHG_svr_model = svr_grid_cv.fit(X_train, Y_train['TotalGHGEmissions'])\nGHG_svr_results = model_scores(GHG_svr_model, 'grid_search_svr')","b65eb05c":"SEU_svr_model = svr_grid_cv.fit(X_train, Y_train['SiteEnergyUse(kBtu)'])\nSEU_svr_results = model_scores(SEU_svr_model, 'grid_search_svr')","5fa3e0ff":"from sklearn.ensemble import RandomForestRegressor\n\nparam_rfr = {'regressor__max_features' : ['sqrt', 'log2'],\n             'regressor__max_depth': [5, 15, 25, 50],\n             'regressor__min_samples_split': [2, 5, 10],\n             'regressor__bootstrap' : [True, False],\n             'regressor__min_samples_leaf': [1,2,5,10]}\n\nrfr_grid_cv = Pipeline([\n    ('preprocessor', preprocessor),\n    ('grid_search_rfr', GridSearchCV(\n                            TransformedTargetRegressor(\n                                regressor=RandomForestRegressor(), \n                                func=np.log, \n                                inverse_func=np.exp),\n                            param_grid=param_rfr,\n                            cv=5,\n                            scoring=('r2','neg_mean_absolute_error'),\n                            refit='neg_mean_absolute_error',\n                            return_train_score = True,\n                            n_jobs = -1))])","e578e784":"GHG_rfr_model = rfr_grid_cv.fit(X_train, Y_train['TotalGHGEmissions'])\nGHG_rfr_results = model_scores(GHG_rfr_model, 'grid_search_rfr')","ae950d8f":"SEU_rfr_model = rfr_grid_cv.fit(X_train, Y_train['SiteEnergyUse(kBtu)'])\nSEU_rfr_results = model_scores(SEU_rfr_model, 'grid_search_rfr')","688f64d6":"import xgboost as xgb\nfrom sklearn.model_selection import RandomizedSearchCV\n\nparam_xgb = {'regressor__learning_rate' : [0.001, 0.01, 0.1, 0.2, 0,3],\n             'regressor__gamma': [0, 0.25, 0.5, 1.0],\n             'regressor__max_depth': [6, 10, 15, 20],\n             'regressor__min_child_weight' : [0.5, 1.0, 3.0, 5.0, 7.0, 10.0],\n             'regressor__n_estimators': [25, 50, 100, 500, 1000]}\n\nxgb_grid_cv = Pipeline([\n    ('preprocessor', preprocessor),\n    ('grid_search_xgb', RandomizedSearchCV(\n                            TransformedTargetRegressor(\n                                regressor=xgb.XGBRegressor(tree_method='gpu_hist'), \n                                func=np.log, \n                                inverse_func=np.exp),\n                            param_distributions=param_xgb,\n                            n_iter=20,\n                            cv=5,\n                            scoring=('r2','neg_mean_absolute_error'),\n                            refit='neg_mean_absolute_error',\n                            return_train_score = True,\n                            n_jobs = -1))])","9d12ceb6":"GHG_xgb_model = xgb_grid_cv.fit(X_train, Y_train['TotalGHGEmissions'])\nGHG_xgb_results = model_scores(GHG_xgb_model, 'grid_search_xgb')","b040da62":"SEU_xgb_model = xgb_grid_cv.fit(X_train, Y_train['SiteEnergyUse(kBtu)'])\nSEU_xgb_results = model_scores(SEU_xgb_model, 'grid_search_xgb')","d1fa1332":"metrics = ['mean_fit_time', 'mean_score_time',\n           'mean_test_neg_mean_absolute_error',\n           'mean_train_neg_mean_absolute_error']\nGHG_compare_metrics = pd.concat([pd.DataFrame(GHG_rfr_results[metrics].mean(), columns=['RandomForest']),\n           pd.DataFrame(GHG_xgb_results[metrics].mean(), columns=['XGBoost']),\n           pd.DataFrame(GHG_svr_results[metrics].mean(), columns=['LinearSVR']),\n           pd.DataFrame(GHG_eNet_results[metrics].mean(), columns=['ElasticNet']),\n           pd.DataFrame(GHG_mlr_results[metrics].mean(), columns=['LinearRegression'])\n          ], axis=1)\nGHG_final_metrics_compare = pd.DataFrame(columns=metrics, \n                                     index=['RandomForest','XGBoost',\n                                            'LinearSVR','ElasticNet',\n                                            'LinearRegression'])\nfor m in metrics:\n    GHG_final_metrics_compare[m] = GHG_compare_metrics.loc[m]","3cb4657d":"GHG_final_metrics_compare","18d4a157":"#On \u00e9limine le mod\u00e8le SVR de cette repr\u00e9sentation car hors normes\nGHG_final_metrics_compare = GHG_final_metrics_compare[GHG_final_metrics_compare.index != 'LinearSVR']\nx = np.arange(len(GHG_final_metrics_compare.index))\nwidth = 0.35\n\nfig, ax = plt.subplots(1,2,figsize=(20,8), sharey=False, sharex=False)\n\nscores1 = ax[0].bar(x - width\/2, -1*GHG_final_metrics_compare['mean_test_neg_mean_absolute_error'], width, label='Test')\nscores2 = ax[0].bar(x + width\/2, -1*GHG_final_metrics_compare['mean_train_neg_mean_absolute_error'], width, label='Train')\nax[0].set_ylabel('Mean Absolute Error')\nax[0].set_title('Comparaison des scores par mod\u00e8le')\nax[0].set_xticks(x)\nax[0].set_xticklabels(GHG_final_metrics_compare.index)\nax[0].legend()\nax[0].bar_label(scores1, padding=3)\nax[0].bar_label(scores2, padding=3)\n\ntimes1 = ax[1].bar(x - width\/2, GHG_final_metrics_compare['mean_score_time'], width, label='Predict')\ntimes2 = ax[1].bar(x + width\/2, GHG_final_metrics_compare['mean_fit_time'], width, label='Fit')\nax[1].set_ylabel('Temps(s)')\nax[1].set_title(\"Comparaison des temps d'entrainement et pr\u00e9diction\")\nax[1].set_xticks(x)\nax[1].set_xticklabels(GHG_final_metrics_compare.index)\nax[1].legend()\nax[1].bar_label(times1, padding=3, fmt='%.3f')\nax[1].bar_label(times2, padding=3, fmt='%.3f')\n\nplt.suptitle(\"Mod\u00e9lisations sur la variable TotalGHGEmissions\", fontdict=font_title, fontsize=22)\nfig.tight_layout()\n\nplt.show()","3205f5ce":"#Fonction d'affichage des scores de GridSearch pour chacun des param\u00e8tres\ndef plot_search_results(grid, title): \n       \n    ## R\u00e9sultats de la GridSearch\n    results = grid.cv_results_\n    means_test = results['mean_test_neg_mean_absolute_error']\n    stds_test = results['std_test_neg_mean_absolute_error']\n    means_train = results['mean_train_neg_mean_absolute_error']\n    stds_train = results['std_train_neg_mean_absolute_error']\n\n    ## Index de valeurs par hyper-param\u00e8tre\n    masks=[]\n    masks_names= list(grid.best_params_.keys())\n    for p_k, p_v in grid.best_params_.items():\n        masks.append(list(results['param_'+p_k].data==p_v))\n\n    params=grid.param_grid\n\n    \n    ## Plot des r\u00e9sultats\n    fig, ax = plt.subplots(1,len(params),sharex='none', sharey='all',figsize=(20,5))\n    fig.suptitle('Scores par param\u00e8tres pour la variable {}'.format(title), \n                 fontdict=font_title, fontsize=22)\n    fig.text(0.04, 0.5, 'NEG MEAN ABSOLUTE ERROR SCORE', va='center', rotation='vertical')\n    pram_preformace_in_best = {}\n    for i, p in enumerate(masks_names):\n        m = np.stack(masks[:i] + masks[i+1:])\n        pram_preformace_in_best\n        best_parms_mask = m.all(axis=0)\n        best_index = np.where(best_parms_mask)[0]\n        x = np.array(params[p])\n        y_1 = np.array(means_test[best_index])\n        e_1 = np.array(stds_test[best_index])\n        y_2 = np.array(means_train[best_index])\n        e_2 = np.array(stds_train[best_index])\n        ax[i].errorbar(x, y_1, e_1, linestyle='--', marker='o', label='test', color=\"#2cb7b0\")\n        ax[i].errorbar(x, y_2, e_2, linestyle='--', marker='o', label='train', color=\"#337da4\")\n        ax[i].set_xlabel(p.upper())\n\n    plt.legend()\n    plt.show()\n    \n    print(\"\\nRappel des meilleurs param\u00e8tres :\\n{}\".format(grid.best_params_))","209ad356":"plot_search_results(GHG_rfr_model.named_steps['grid_search_rfr'], title=\"TotalGHGEmissions\")","d983845e":"feature_importance = GHG_rfr_model.named_steps['grid_search_rfr'].best_estimator_.regressor_.feature_importances_ \nfeatures_names = get_feature_names(GHG_rfr_model.named_steps['preprocessor'])\nstd = np.std([\n    tree.feature_importances_ for tree in GHG_rfr_model.named_steps['grid_search_rfr'].best_estimator_.regressor_], axis=0)\ndf_feature_importance = pd.Series(feature_importance, index=features_names)\n\nfig, ax = plt.subplots(figsize=(12,8))\ndf_feature_importance.plot.bar(yerr=std, ax=ax)\nax.set_title(\"Feature importances du mod\u00e8le RandomForestRegressor sur les \u00e9missions de CO2\", fontdict=font_title)\nax.set_ylabel(\"Diminution moyenne des impuret\u00e9s\")\nfig.tight_layout()","e594d698":"SEU_compare_metrics = pd.concat([pd.DataFrame(SEU_rfr_results[metrics].mean(), columns=['RandomForest']),\n           pd.DataFrame(SEU_xgb_results[metrics].mean(), columns=['XGBoost']),\n           pd.DataFrame(SEU_svr_results[metrics].mean(), columns=['LinearSVR']),\n           pd.DataFrame(SEU_eNet_results[metrics].mean(), columns=['ElasticNet']),\n           pd.DataFrame(SEU_mlr_results[metrics].mean(), columns=['LinearRegression'])\n          ], axis=1)\nSEU_final_metrics_compare = pd.DataFrame(columns=metrics, \n                                     index=['RandomForest','XGBoost',\n                                            'LinearSVR','ElasticNet',\n                                            'LinearRegression'])\nfor m in metrics:\n    SEU_final_metrics_compare[m] = SEU_compare_metrics.loc[m]\nSEU_compare_metrics","a35cfcb0":"SEU_final_metrics_compare = SEU_final_metrics_compare[SEU_final_metrics_compare.index != 'LinearRegression']\nx = np.arange(len(SEU_final_metrics_compare.index))\nwidth = 0.35\n\nfig, ax = plt.subplots(1,2,figsize=(20,8), sharey=False, sharex=False)\n\nscores1 = ax[0].bar(x - width\/2, -1*SEU_final_metrics_compare['mean_test_neg_mean_absolute_error'], width, label='Test')\nscores2 = ax[0].bar(x + width\/2, -1*SEU_final_metrics_compare['mean_train_neg_mean_absolute_error'], width, label='Train')\nax[0].set_ylabel('Mean Absolute Error')\nax[0].set_title('Comparaison des scores par mod\u00e8le')\nax[0].set_xticks(x)\nax[0].set_xticklabels(SEU_final_metrics_compare.index)\nax[0].legend()\nax[0].bar_label(scores1, padding=3)\nax[0].bar_label(scores2, padding=3)\n\ntimes1 = ax[1].bar(x - width\/2, SEU_final_metrics_compare['mean_score_time'], width, label='Predict')\ntimes2 = ax[1].bar(x + width\/2, SEU_final_metrics_compare['mean_fit_time'], width, label='Fit')\nax[1].set_ylabel('Temps(s)')\nax[1].set_title(\"Comparaison des temps d'entrainement et pr\u00e9diction\")\nax[1].set_xticks(x)\nax[1].set_xticklabels(SEU_final_metrics_compare.index)\nax[1].legend()\nax[1].bar_label(times1, padding=3, fmt='%.3f')\nax[1].bar_label(times2, padding=3, fmt='%.3f')\n\nplt.suptitle(\"Mod\u00e9lisations sur la variable SiteEnergyUse\", fontdict=font_title, fontsize=22)\nfig.tight_layout()\n\nplt.show()","fed09b90":"plot_search_results(SEU_rfr_model.named_steps['grid_search_rfr'], title=\"SiteEnergyUse(kBtu)\")","0f19fe7c":"feature_importance = SEU_rfr_model.named_steps['grid_search_rfr'].best_estimator_.regressor_.feature_importances_ \nfeatures_names = get_feature_names(SEU_rfr_model.named_steps['preprocessor'])\nstd = np.std([\n    tree.feature_importances_ for tree in SEU_rfr_model.named_steps['grid_search_rfr'].best_estimator_.regressor_], axis=0)\ndf_feature_importance = pd.Series(feature_importance, index=features_names)\n\nfig, ax = plt.subplots(figsize=(12,8))\ndf_feature_importance.plot.bar(yerr=std, ax=ax)\nax.set_title(\"Feature importances du mod\u00e8le RandomForestRegressor sur la consommation d'\u00e9nergie\")\nax.set_ylabel(\"Diminution moyenne des impuret\u00e9s\")\nfig.tight_layout()","07aeb2bf":"def metrics_model(y_true, y_pred):\n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    diff = y_true - y_pred\n    mae = np.mean(abs(diff))\n    r2 = 1-(sum(diff**2)\/sum((y_true-np.mean(y_true))**2))\n    dict_metrics = {\"M\u00e9trique\":[\"MAE\", \"R\u00b2\"], \"R\u00e9sultats\":[mae, r2]}\n    df_metrics = pd.DataFrame(dict_metrics)\n    return df_metrics","f96785f9":"def plot_pred_true(y_true, y_pred, color=None, title=None):\n    X_plot = [y_true.min(), y_true.max()]\n    fig = plt.figure(figsize=(12,8))\n    plt.scatter(y_true, y_pred, color=color, alpha=.6)\n    plt.plot(X_plot, X_plot, color='r')\n    plt.xlabel(\"Valeurs r\u00e9\u00e9lles\")\n    plt.ylabel(\"Valeurs pr\u00e9dites\")\n    plt.title(\"Valeurs pr\u00e9dites VS valeurs r\u00e9\u00e9lles | Variable {}\".format(title), \n              fontdict=font_title, fontsize=18)\n    plt.show()","3da6a7cd":"#Mod\u00e8le avec les meilleurs param\u00e8tres pour les \u00e9missions de CO2\n\nimport time\nstart_time = time.time()\n\nGHG_pred = GHG_rfr_model.predict(X_test)\n\nprint(\"Temps d'execution de l'agorithme : {:.2} s.\".format((time.time() - start_time)))","4ea72dac":"#Calcul des m\u00e9triques pour les \u00e9missions de CO2\nGHGmetrics = metrics_model(Y_test['TotalGHGEmissions'],GHG_pred)\nGHGmetrics","b534af7b":"#Affichage des valeurs pr\u00e9dites vs valeurs r\u00e9\u00e9lles pour \u00e9missions de CO2\nplot_pred_true(Y_test['TotalGHGEmissions'],GHG_pred, color=\"#9C3E2D\", title=\"TotalGHGEmissions\")","ca83f810":"GHG_test_results = GHG_rfr_results[['split0_test_neg_mean_absolute_error',\n                'split1_test_neg_mean_absolute_error',\n                'split2_test_neg_mean_absolute_error',\n                'split3_test_neg_mean_absolute_error',\n                'split4_test_neg_mean_absolute_error',\n                ]][GHG_rfr_results['rank_test_neg_mean_absolute_error']==1].values\nGHG_train_results = GHG_rfr_results[['split0_train_neg_mean_absolute_error',\n                'split1_train_neg_mean_absolute_error',\n                'split2_train_neg_mean_absolute_error',\n                'split3_train_neg_mean_absolute_error',\n                'split4_train_neg_mean_absolute_error',\n                ]][GHG_rfr_results['rank_test_neg_mean_absolute_error']==1].values","b5264189":"x = np.arange(0,5,1)\nfig, ax = plt.subplots(1,2, figsize=(20,8), sharey=False, sharex=False)\nax[0].plot(range(0,5), GHG_test_results.reshape(-1))\nax[0].set_xticks(x)\nax[0].set_xticklabels([\"Split\"+str(n) for n in range(0,5)])\nax[0].set_ylabel('Neg Mean Absolute Error')\nax[0].set_title('Scores de test')\n\nax[1].plot(range(0,5), GHG_train_results.reshape(-1), color='b')\nax[1].set_xticks(x)\nax[1].set_xticklabels([\"Split\"+str(n) for n in range(0,5)])\nax[1].set_title('Scores de train')\n\nplt.suptitle(\"Evolution des scores \u00e0 travers les Splits de Cross-validation\", fontdict=font_title, fontsize=22)\nfig.tight_layout()\n\nplt.show()","0d26d970":"start_time = time.time()\n\nSEU_pred = SEU_rfr_model.predict(X_test)\n\nprint(\"Temps d'execution de l'agorithme : {:.2} s.\".format((time.time() - start_time)))","bd2769d3":"#Calcul des m\u00e9triques pour les \u00e9missions de CO2\nSEUmetrics = metrics_model(Y_test['SiteEnergyUse(kBtu)'],SEU_pred)\nSEUmetrics","82e3c97e":"#Affichage des valeurs pr\u00e9dites vs valeurs r\u00e9\u00e9lles pour \u00e9missions de CO2\nplot_pred_true(Y_test['SiteEnergyUse(kBtu)'],SEU_pred, color=\"#6D9C0E\", title=\"SiteEnergyUse(kBtu)\")","9f5039af":"final_SEU_test = pd.concat([X_test,Y_test],axis=1)\nfinal_SEU_test['SEU_pred'] = SEU_pred\ncompare_final_SEU_test = final_SEU_test = final_SEU_test.groupby(by='BuildingType').mean()","4c1ecc95":"x = np.arange(len(compare_final_SEU_test.index))\nwidth = 0.35\n\nfig, ax = plt.subplots(figsize=(20,8), sharey=False, sharex=False)\n\nscores1 = ax.bar(x - width\/2, compare_final_SEU_test['SiteEnergyUse(kBtu)'], width, label='SiteEnergyUse(kBtu)')\nscores2 = ax.bar(x + width\/2, compare_final_SEU_test['SEU_pred'], width, label='Pr\u00e9dictions')\nax.set_ylabel('(kBtu)')\nax.set_xticks(x)\nax.set_xticklabels(compare_final_SEU_test.index)\nax.legend()\nax.bar_label(scores1, padding=3)\nax.bar_label(scores2, padding=3)\n\nplt.suptitle(\"Ecarts de pr\u00e9dictions sur la variable SiteEnergyUse(kBtu) par type de b\u00e2timent\", fontdict=font_title, fontsize=22)\nfig.tight_layout()\n\nplt.show()","4dd83120":"#Ajout de la variable \u00e0 nos variables X\nX['energystar_score'] = energystar_score\n#Ajout de la variable dans les variables num\u00e9rique du preprocessor\nnumeric_features.append('energystar_score')","1c288d85":"#Filtrage des donn\u00e9es ayant un Energy Star Score renseign\u00e9\nX = X[X['energystar_score'].isnull()==False]\nY = Y[Y.index.isin(list(X.index))]","2c87f206":"fig, axes = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=False, figsize=(20,8))\nsns.histplot(data=X, x='energystar_score', stat=\"density\", ax=axes[0])\naxes[0].set_title(\"Distribution\", color='#2cb7b0')\nsns.scatterplot(data=pd.concat([X,Y], axis=1), y='TotalGHGEmissions', x='energystar_score', ax=axes[1])\naxes[1].set_title(\"ENERGY STAR score en fonction de TotalGHGEmissions\", color='#2cb7b0')\nplt.suptitle(\"Analyse de la variable ENERGY STAR Score\", fontdict=font_title, fontsize=22)\nplt.show()","0eb082fe":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n\nprint(\"Entrainement: {} lignes,\\nTest: {} lignes.\\n\".format(X_train.shape[0],\n                                                            X_test.shape[0]))","7a8b2078":"rfr_grid_cv_eStar = Pipeline([\n    ('preprocessor', preprocessor),\n    ('grid_search_rfr_eStar', GridSearchCV(\n                            TransformedTargetRegressor(\n                                regressor=RandomForestRegressor(), \n                                func=np.log, \n                                inverse_func=np.exp),\n                            param_grid=param_rfr,\n                            cv=5,\n                            scoring=('r2','neg_mean_absolute_error'),\n                            refit='neg_mean_absolute_error',\n                            n_jobs = -1))])\n\nGHG_rfr_model_eStar = rfr_grid_cv_eStar.fit(X_train, Y_train['TotalGHGEmissions'])\nGHG_rfr_results_eStar = model_scores(GHG_rfr_model_eStar, 'grid_search_rfr_eStar')","47dfd251":"GHG_pred_star = GHG_rfr_model_eStar.predict(X_test)\n#Calcul des m\u00e9triques pour les \u00e9missions de CO2\nGHGmetricsES = metrics_model(Y_test['TotalGHGEmissions'],GHG_pred_star)\nGHGmetrics = GHGmetrics.rename(columns={\"R\u00e9sultats\" : \"Sans ENERGY STAR\"})\nGHGmetrics['Avec ENERGY STAR'] = GHGmetricsES['R\u00e9sultats']\nGHGmetrics","c24ed92f":"#Affichage des valeurs pr\u00e9dites vs valeurs r\u00e9\u00e9lles pour \u00e9missions de CO2\nplot_pred_true(Y_test['TotalGHGEmissions'],GHG_pred_star, color=\"#9C3E2D\", title=\"TotalGHGEmissions\")","8a4f0c75":"# <font color=\"#1d479b\">Sommaire<\/font>\n1. [Preprocessing](#section_1)     \n    1.1. [Encodage et standardisation](#section_1_1)     \n    1.2. [Pr\u00e9paration des jeux d'entrainement et de test](#section_1_2)     \n2. [Mod\u00e8le Baseline : R\u00e9gression lin\u00e9aire multivari\u00e9e](#section_2)     \n3. [Mod\u00e8le lin\u00e9aires : ElasticNet et SVR](#section_3)     \n    3.1. [Mod\u00e8le ElasticNet](#section_3_1)     \n    3.2. [Mod\u00e8le Support Vector Regression (SVR)](#section_3_2)     \n4. [Mod\u00e8le non-lin\u00e9aires : XGBoost et RandomForestRegressor](#section_4)     \n    4.1. [Mod\u00e8le RandomForestRegressor](#section_4_1)     \n    4.2. [Mod\u00e8le XGBoost *(eXtreme Gradient Boosting)*](#section_4_2)          \n5. [S\u00e9lection des meilleurs mod\u00e8les](#section_5)     \n    5.1. [Mod\u00e8le de pr\u00e9diction des \u00e9missions de CO2](#section_5_1)     \n    5.2. [Mod\u00e8le de pr\u00e9diction des consommations d'\u00e9nergie](#section_5_2)     \n6. [Test des mod\u00e8les s\u00e9lectionn\u00e9s](#section_6)    \n    6.1. [Pr\u00e9diction des \u00e9missions de CO2](#section_6_1)     \n    6.2. [Pr\u00e9diction des consommation d'\u00e9nergie](#section_6_2)     \n7. [Influence du score ENERGY STAR](#section_7)","2b7f92d9":"Regardons maintenant les donn\u00e9es num\u00e9riques :","867230b1":"## <font color=\"#337da4\" id=\"section_7\">7. Influence du score ENERGY STAR<\/font>\n\nLe score **ENERGY STAR** fournit un aper\u00e7u complet de la performance \u00e9nerg\u00e9tique d'un b\u00e2timent, en tenant compte des actifs physiques, des op\u00e9rations et du comportement des occupants du b\u00e2timent. Il est exprim\u00e9 sur une \u00e9chelle de 1 \u00e0 100 facile \u00e0 comprendre : **plus le score est \u00e9lev\u00e9, meilleure est la performance \u00e9nerg\u00e9tique du b\u00e2timent**.\n\nCe score permet de r\u00e9aliser plusieurs actions :\n- \u00c9valuer les donn\u00e9es \u00e9nerg\u00e9tiques r\u00e9elles factur\u00e9es,  \n- Normaliser pour l'activit\u00e9 commerciale *(heures, travailleurs, climat)*, \n- Comparer les b\u00e2timents \u00e0 la population nationale, \n- Indiquer le niveau de performance \u00e9nerg\u00e9tique.\n\nNous allons donc \u00e9valuer si ce score \u00e0 un impact significatif sur les performances de notre mod\u00e9lisation.","bdba969e":"<details>\n<summary><font color=\"blue\"><b>Explication du mod\u00e8le :<\/b><\/font><\/summary>\n\nLa r\u00e9gression lin\u00e9aire est un mod\u00e8le simple tente de minimiser la somme des erreurs au carr\u00e9. \nL'erreur dans ce cas est la diff\u00e9rence entre la donn\u00e9e r\u00e9elle et sa valeur pr\u00e9dite. \nPour produire un mod\u00e8le plus pr\u00e9cis de donn\u00e9es complexes, nous pouvons ajouter un <b>terme de p\u00e9nalit\u00e9 \u00e0 l'\u00e9quation OLS<\/b>.\nUne p\u00e9nalit\u00e9 ajoute un <b>biais<\/b> sur certaines valeurs. \n\nCelles-ci sont appel\u00e9es <b>r\u00e9gularisation L1 <em>(r\u00e9gression Lasso)<\/em><\/b> et <b>r\u00e9gression L2 <em>(r\u00e9gression Ridge)<\/em><\/b>. Le meilleur mod\u00e8le que nous pouvons esp\u00e9rer proposer minimise \u00e0 la fois le biais et la variance.\n\n<h5>R\u00e9gression Ridge<\/h5>\nLa r\u00e9gression Ridge utilise une r\u00e9gularisation L2 qui ajoute la p\u00e9nalit\u00e9 suivante \u00e0 l'\u00e9quation OLS : $\\large + \\lambda \\sum_{j=0}^{p} w^0_j$\n\nLe terme L2 est \u00e9gal au carr\u00e9 de la magnitude des coefficients. Dans ce cas, si lambda ($\\lambda$) est \u00e9gal \u00e0 z\u00e9ro, l'\u00e9quation est l'OLS de base mais si elle est sup\u00e9rieure \u00e0 z\u00e9ro, nous ajoutons une contrainte aux coefficients. <b>La r\u00e9gression Ridge diminue la complexit\u00e9 d'un mod\u00e8le mais ne r\u00e9duit pas le nombre de variables, elle r\u00e9duit simplement leur effet<\/b>.\n    \n<h5>R\u00e9gression Lasso<\/h5>\nLa r\u00e9gression Lasso utilise le terme de p\u00e9nalit\u00e9 L1 et repr\u00e9sente le Least Absolute Shrinkage et l'op\u00e9rateur de s\u00e9lection. La p\u00e9nalit\u00e9 appliqu\u00e9e est \u00e9gale \u00e0 la valeur absolue de la magnitude des coefficients : $\\large + \\lambda \\sum_{j=0}^{p} |w_j|$\n    \n    <b>L'application de ce terme peut \u00e9liminer compl\u00e8tement certaines variables<\/b> et donner un sous-ensemble de pr\u00e9dicteurs qui aident \u00e0 att\u00e9nuer la multi-colin\u00e9arit\u00e9 et la complexit\u00e9 du mod\u00e8le.\n    \n<h5>Elastic Net<\/h5>\nElastic Net incorpore des p\u00e9nalit\u00e9s de r\u00e9gularisation L1 et L2 :\n$$\\large \\frac{\\sum^{n}_{i=1}(y_i - x^i_j \\hat{\\beta})^2}{2n} + \\lambda \\left( \\frac{1 - \\alpha}{2} \\sum^{m}_{j=1} \\hat{\\beta}^2_j + \\alpha \\sum^{m}_{j=1} |\\hat{\\beta}_j| \\right) $$\n    \nEn plus de d\u00e9finir et de choisir une valeur lambda, ElasticNet permet \u00e9galement d'ajuster le param\u00e8tre alpha o\u00f9 $\\large \\alpha = 0$ correspond \u00e0 Ridge et $\\large \\alpha = 1$ \u00e0 Lasso. On peut donc choisir une valeur alpha entre 0 et 1 pour optimiser ElasticNet <em>(cela r\u00e9duira certains coefficients et en mettra d'autres \u00e0 0 pour une s\u00e9lection parcimonieuse)<\/em>.\n<\/details>\n","12d5a75a":"Un b\u00e2timent de type campus est tr\u00e8s sup\u00e9rieur aux autres donn\u00e9es. Il ne s'agit sans doute pas d'une valeur ab\u00e9rrante mais d'une **valeur atypique** qui est tr\u00e8s isol\u00e9e. Nous allons ici la supprimer de nos donn\u00e9es sources.","d438fd5a":"## <font color=\"#337da4\" id=\"section_1\">1. Preprocessing<\/font>","a32051bb":"Pour les consommations d'\u00e9nergie, la surface de la propri\u00e9t\u00e9 \u00e0 ici \u00e9galement une importance bien sup\u00e9rieure aux autres variables.\n\n## <font color=\"#337da4\" id=\"section_6\">6. Test des mod\u00e8les s\u00e9lectionn\u00e9s<\/font>\n\nNous allons \u00e0 pr\u00e9sent tester les mod\u00e8les s\u00e9lectionn\u00e9s sur nos donn\u00e9es test et v\u00e9rifier leurs performances.\n\n### <font color=\"#2cb7b0\" id=\"section_6_1\">6.1. Pr\u00e9diction des \u00e9missions de CO2<\/font>","8e219d1e":"La date de relev\u00e9 ne nous sera pas utile ici, nous la supprimerons du jeu de donn\u00e9es. `ENERGYSTARScore` est insuffisement compl\u00e9t\u00e9. Nous allons l'\u00e9carter du dataset mais nous la conservons pour **v\u00e9rifier ensuite si cette variable a un impact sur la qualit\u00e9 de pr\u00e9diction**.","d0bd9c91":"Apr\u00e8s avoir test\u00e9 les premiers param\u00e8tres, nous avons \u00e0 pr\u00e9sent d\u00e9fini notre **mod\u00e8le pour la pr\u00e9diction des \u00e9missions de CO2**. Regardons \u00e0 pr\u00e9sent l'importance des variables dans notre mod\u00e8le de for\u00eats al\u00e9atoires :","47a04d72":"Sur ce mod\u00e8le **SVR lin\u00e9aire, les m\u00e9triques sont encore l\u00e9g\u00e9rement am\u00e9lior\u00e9es** pour les 2 variables \u00e0 pr\u00e9dire compar\u00e9es au mod\u00e8le ElasticNet.\n\nNous allons \u00e0 pr\u00e9sent nous pencher sur des mod\u00e8les non-lin\u00e9aires.\n\n## <font color=\"#337da4\" id=\"section_4\">4. Mod\u00e8le non-lin\u00e9aires : XGBoost et RandomForestRegressor<\/font>","08475580":"Les valeurs pr\u00e9dites sont tr\u00e8s \u00e9loign\u00e9es de la premi\u00e8re bissectrice. En effet, **le transformer log() \/ exp() de notre variable Y emplifie les erreurs lors de la transformation inverse**.\n\nNous allons regarder les scores obtenus sur les diff\u00e9rents splits de la Cross-validation pour v\u00e9rifier les \u00e9carts :","ed239791":"### <font color=\"#2cb7b0\" id=\"section_5_1\">5.1. Mod\u00e8le de pr\u00e9diction des \u00e9missions de CO2<\/font>","c3a7923b":"Nous allons **regrouper les donn\u00e9es d'identification des b\u00e2timents** afin qu'elles ne perturbent pas nos mod\u00e9lisations mais restent utilisables.","2ad6948c":"### <font color=\"#2cb7b0\" id=\"section_1_1\">1.1. Encodage et standardisation<\/font>","554e5260":"## <font color=\"#337da4\" id=\"section_2\">2. Mod\u00e8le Baseline : R\u00e9gression lin\u00e9aire multivari\u00e9e<\/font>\n\nA pr\u00e9sent, nous allons cr\u00e9er un mod\u00e8le baseline pour \u00e9valuer les performances de nos futurs mod\u00e8les et v\u00e9rifier qu'ils am\u00e9liore les pr\u00e9dictions. Pour cette baseline, nous utiliserons une **r\u00e9gression lin\u00e9aire multivari\u00e9e**.","713babbe":"Tous les r\u00e9sultats des GridSearchCV sont stock\u00e9s dans un DataFrame pour chaque variable \u00e0 pr\u00e9dire :","b92e0c4d":"Comme nous l'avons remarqu\u00e9 dans le [Notebook de nettoyage](https:\/\/www.kaggle.com\/michaelfumery\/seattle-building-energy-cleaning), les Campus sont tr\u00e8s consommateurs en energie. Nous allons v\u00e9rifier la distribution des consommations en fonction des surfaces totales au sol par cat\u00e9gorie de b\u00e2timent. D'\u00e9ventuels valeurs hors-normes pourraient poser des probl\u00e8mes pour les mod\u00e9lisations :","470cb4ba":"Les surfaces (GFA) de la propri\u00e9t\u00e9 et le type d'utilisation principale ont un poids plus important dans les d\u00e9cisions de notre mod\u00e8le. En revanche, le type de b\u00e2timent a un impact tr\u00e8s limit\u00e9. On remarque \u00e9galement que l'age du batiment ou encore son emplacement g\u00e9ographique n'ont pas un impact tr\u00e8s important non plus.\n\n### <font color=\"#2cb7b0\" id=\"section_5_2\">5.2. Mod\u00e8le de pr\u00e9diction des consommations d'\u00e9nergie<\/font>\n\nCette fois encore, nous allons **comparer les m\u00e9triques obtenues sur les diff\u00e9rents mod\u00e8les** :","2599473d":"On utilise ici le meilleur mod\u00e8le calcul\u00e9 sur la variable `TotalGHGEmissions` en incluant l'ENERGY STAR Score :","bda63a7a":"Ici encore, le m\u00eame probl\u00e8me que pour la variable TotalGHG se pose. Le mod\u00e8le est performant en entrainement mais ne parveint pas \u00e0 g\u00e9n\u00e9raliser sur le jeu de test.\n\nNous allons regarder les **\u00e9carts de pr\u00e9diction en fonction du type de b\u00e2timent** pour v\u00e9rifier si des \u00e9carts sont plus importants dans certaines cat\u00e9gories :","902540c6":"et les scores pour la variable `SiteEnergyUse(kBtu)` :","e06f24e3":"Nous allons calculer 2 principales m\u00e9triques pour \u00e9valuer nos mod\u00e8les :\n- **MAE** : Mean Absolute Error.\n- **R\u00b2** : Coeficient de d\u00e9termination, carr\u00e9 du coefiscient de corr\u00e9lation lin\u00e9aire.","4ee4d97b":"Nous allons s\u00e9parer les donn\u00e9es num\u00e9riques et les donn\u00e9es cat\u00e9gorielles de notre dataset :","c471d6f8":"![banniere_small.jpg](attachment:8f523117-9a7d-4c29-89df-52846d97129f.jpg)","3d39c08f":"Pour les donn\u00e9es cat\u00e9gorielles, nous allons devoir encoder les valeurs. Nous allons donc supprimer les variables qui n'apporteront rien \u00e0 notre mod\u00e8le *(les constantes par exemple)* et s\u00e9parer les variables pouvant \u00eatre encod\u00e9es en OneHot des autres.","064f3012":"Les donn\u00e9es num\u00e9riques doivent \u00eatre standardis\u00e9es pour entrer dans nos mod\u00e8les de pr\u00e9diction. Nous r\u00e9aliserons un **centrage-r\u00e9duction** via la m\u00e9thode `StandardScaler` de Scikit-Learn.","e4fd9307":"L'\u00e9cart est tr\u00e8s important sur la cat\u00e9gorie \"Campus\" qui est faiblement repr\u00e9sent\u00e9e dans le jeu de donn\u00e9es mais qui pr\u00e9sente les plus grandes consommations.","f99bb62c":"# <font color=\"#1d479b\">Contexte<\/font>\n\nPour atteindre l'objectif de **ville neutre en \u00e9missions de carbone en 2050**, la ville de **Seattle** s\u2019int\u00e9resse de pr\u00e8s aux \u00e9missions des b\u00e2timents non destin\u00e9s \u00e0 l\u2019habitation.\n\nDes relev\u00e9s minutieux ont \u00e9t\u00e9 effectu\u00e9s en 2015 et en 2016. Cependant, ces relev\u00e9s sont co\u00fbteux \u00e0 obtenir, et \u00e0 partir de ceux d\u00e9j\u00e0 r\u00e9alis\u00e9s, nous devons tenter de pr\u00e9dire les \u00e9missions de CO2 et la consommation totale d\u2019\u00e9nergie de b\u00e2timents pour lesquels elles n\u2019ont pas encore \u00e9t\u00e9 mesur\u00e9es.\n\n<hr width=\"50%\" align=\"center\"\/>\n\nLa premi\u00e8re partie nous a permis de r\u00e9aliser un nettoyage des fichiers et une courte analyse exploratoire *([Seattle building energy cleaning - Kaggle Notebook](https:\/\/www.kaggle.com\/michaelfumery\/seattle-building-energy-cleaning))*.      \nDans cette seconde partie, nous allons r\u00e9aliser les diverses **mod\u00e9lisations gr\u00e2ce \u00e0 des approches lin\u00e9aires et non-lin\u00e9aire afin de pr\u00e9dire les \u00e9missions de CO2 et les consommations d'\u00e9nergie des b\u00e2timents**.","dbb9e2cd":"#### Pr\u00e9paration du Preprocessor","c566ae76":"On affiche les **scores de la GridSearch avec validation crois\u00e9e** pour la variable `TotalGHGEmissions` :","98d15ed0":"### <font color=\"#2cb7b0\" id=\"section_4_2\">4.2. Mod\u00e8le XGBoost *(eXtreme Gradient Boosting)*<\/font>\n\n<details>\n<summary><font color=\"blue\"><b>Explication du mod\u00e8le :<\/b><\/font><\/summary>\n<h5>XGBoost<\/h5>\nComme son nom l'indique, ce mod\u00e8le est un algorithme de gradient boosting. Ce boosting consiste \u00e0 assembler plusieurs algorithmes ayant une performance peu \u00e9lev\u00e9e pour en cr\u00e9er un beaucoup plus efficace.\n\nDans le cadre de la r\u00e9gression, les variables \u00e0 pr\u00e9dire vont \u00eatre estim\u00e9es avec un premier mod\u00e8le, puis les r\u00e9sidus de ce mod\u00e8le deviendront les variables cible du second mod\u00e8le, et ainsi de suite.\n    \nPour pouvoir pr\u00e9dire un output en fonction d\u2019un input dont on ne connait pas la variable cible, il faut pr\u00e9dire le r\u00e9sidu de chaque mod\u00e8le et ensuite en faire la somme.\n    \nPour l'agorithme XGBoost, r\u00e9alis\u00e9 une GridSearch en \"brute\", en testant toutes les combinaisons est tr\u00e8s long et tr\u00e8s couteux en temps de calcul. Pour palier \u00e0 ce probl\u00e8me, nous allons ici utiliser une grille de recherche al\u00e9atoire.\n<\/details>","c1ea1f7a":"### <font color=\"#2cb7b0\" id=\"section_1_2\">1.2. Pr\u00e9paration des jeux d'entrainement et de test<\/font>\n\nAfin de **tester notre meilleur mod\u00e8le** sur des donn\u00e9es \"inconnues\", nous allons mettre de c\u00f4t\u00e9 une partie des donn\u00e9es initiales qui ne seront pas inclusent dans les mod\u00e8les interm\u00e9diaires. Nous allons donc spliter nos donn\u00e9es pour obtenir un jeu d'entrainement et un jeu de test *(20% des donn\u00e9es)*","1b0016bc":"On remarque ici que le score ENERGY STAR ne semble pas avoir de corr\u00e9lation importante avec les \u00e9missions de CO2. La distribution ne suit pas de loi normale et la majorit\u00e9 des batiments a un score sup\u00e9rieur \u00e0 50 *(de bonne qualit\u00e9 voir de tr\u00e8s bonne qualit\u00e9)*.","5a175c9a":"Comme nous l'avons vu dans l'analyse exploratoire, un mod\u00e8le simple de **r\u00e9gression lin\u00e9aire multivari\u00e9** ne pourrait pas r\u00e9pondre totalement \u00e0 notre probl\u00e8me de pr\u00e9diction. Nous allons donc utiliser ce premier mod\u00e8le comme baseline et tester les m\u00e9triques principales : **R\u00b2** et **MAE**.","37e01bb8":"Le mod\u00e8le XGBoost non-lin\u00e9aire a des niveaux de performances de pr\u00e9diction sur les 2 variables quasi similaire au mod\u00e8le RandomForestRegressor mais nous avons d\u00fb utiliser le GPU pour acc\u00e9lerer le temps de calcul.\n\n## <font color=\"#337da4\" id=\"section_5\">5. S\u00e9lection des meilleurs mod\u00e8les<\/font>\n\nSur les 4 mod\u00e8les test\u00e9s,les mod\u00e8les lin\u00e9aires retournent de moins bonnes m\u00e9triques en g\u00e9n\u00e9ral. Si nous prenons en consid\u00e9ration le score MAE, qui aura du sens sur les mod\u00e8les lin\u00e9aires et non-lin\u00e9aires, **les algorithmes XGBoost et RandomForestRegressor offrent des performances \u00e0 peu pr\u00e8s similaires pour la qualit\u00e9 des pr\u00e9dictions** mais les temps de calculs sont meilleurs sur le mod\u00e8le RandomForestRegressor.\n\nNous allons donc regarder de plus pr\u00e8s les r\u00e9sultats obtenus sur nos 2 variables \u00e0 pr\u00e9dire avec les diff\u00e9rents mod\u00e8les :","d57db72b":"Pour toutes ces variables, nous utiliserons la m\u00e9thode *TagetEncoder* de la librairie Category_Encoders que nous int\u00e9grerons dans un pipeline Sklearn.     \nCet encodeur r\u00e9alise 2 principales \u00e9tapes :\n1. Groupe les donn\u00e9es par chaque cat\u00e9gorie et compte de nombre d'occurrences de chaque cible.\n2. Calcul de la probabilit\u00e9 que chaque cible se produise pour chaque groupe sp\u00e9cifique.","a8bd40cc":"On voit ici que les scores des diff\u00e9rents splits de cross-validation, pour les meilleurs param\u00e8tres obtenus, \u00e9voluent correctement lors de l'entrainement et des test, tout en restant dans la m\u00eame \u00e9chelle.\n\nLes \u00e9carts et mauvais r\u00e9sultats obtenus d\u00e9pendent donc du faible nombre de donn\u00e9es qui impactent le Train_Test_Split initial. Le mod\u00e8le est correctement entrain\u00e9 mais n'obtient pas de bon r\u00e9sultats sur le jeu de test *(pas d'overfiting constat\u00e9 dans les entrainements)*.","b5c6f552":"### <font color=\"#2cb7b0\" id=\"section_4_1\">4.1. Mod\u00e8le RandomForestRegressor<\/font>\n\n<details>\n<summary><font color=\"blue\"><b>Explication du mod\u00e8le :<\/b><\/font><\/summary>\n<h5>Random Forest<\/h5>\nLes \"for\u00eats al\u00e9atoires\" sont des algorithmes qui se basent sur l'assemblage d'arbre de d\u00e9cision ind\u00e9pendants.\n\nChaque arbre traitant seulement une partie du probl\u00e8me gr\u00e2ce \u00e0 un double tirage al\u00e9atoire :\n<ul>\n    <li>Un tirage avec remplacement sur les individus : C'est le <b>tree bagging<\/b><\/li>\n    <li>Un tirage al\u00e9atoire sur les variables : le <b>feature sampling<\/b><\/li>\n<\/ul>\n\nAu final, tous ces arbres de d\u00e9cisions ind\u00e9pendants sont assembl\u00e9s. La pr\u00e9diction faite par le random forest pour des donn\u00e9es inconnues est alors la moyenne de tous les arbres dans le cas de la r\u00e9gression.\n<\/details>","5a8ab6e6":"Dans cette description, on remarque des donn\u00e9es avec des **valeurs infinies** *(16 entr\u00e9es)*. Nous allons regarder de plus pr\u00eat ces donn\u00e9es et les corriger :","6e152a63":"Pour la variable SiteEnergyUse, le mod\u00e8le RandomForest offre \u00e0 nouveau les meilleurs scores MAE et les meilleurs temps d'entrainement et de pr\u00e9diction. **<font color=\"green\">Nous allons donc s\u00e9l\u00e9ctionner le mod\u00e8le RandomForestRegressor pour pr\u00e9dire la variable SiteEnergyUse<\/font>**.\n\nRegardons maintenant l'impact des hyperparam\u00e8tres de la Grille de recherche :","0b35602f":"### <font color=\"#2cb7b0\" id=\"section_3_2\">3.2. Mod\u00e8le Support Vector Regression (SVR)<\/font>\n\n<details>\n<summary><font color=\"blue\"><b>Explication du mod\u00e8le :<\/b><\/font><\/summary>\n<h5>Les machines \u00e0 vecteur de support<\/h5>\nDans le cas de donn\u00e9es lin\u00e9airement s\u00e9parables, il existe g\u00e9n\u00e9ralement une infinit\u00e9 d'hyperplans s\u00e9parateurs qui classifient correctement les donn\u00e9es. Pour formaliser lequel parmi ces multiples hyperplans nous convient le mieux, nous allons d\u00e9finir la <b>marge d'un hyperplan<\/b> s\u00e9parateur $\\mathcal{H}$ comme deux fois la distance de $\\mathcal{H}$ au point du jeu de donn\u00e9es qui en est le plus proche.\n    \nDans la plupart des cas, les donn\u00e9es ne sont pas lin\u00e9airement s\u00e9parables. Il va donc falloir accepter de faire des erreurs, autrement dit que certains points de notre jeu d'entra\u00eenement se retrouvent du mauvais c\u00f4t\u00e9 de la fronti\u00e8re de la zone d'ind\u00e9cision.\n![svm_6.png](attachment:ee1799ec-2438-4908-a56b-92ecc77d7cee.png)\n    \nPlus la marge est grande, plus nous somme susceptibles d'avoir d'erreurs. Nous allons donc devoir <b>minimiser la marge et l'erreur simultan\u00e9ment<\/b> :\n\n$$\\large arg \\, {\\underset{w \\in \\mathbb{R}^{p}, b \\in \\mathbb{R}}{min}} \\frac{1}{2} ||w||^2_2 + C \\text{ erreur}$$\n\nL'hyperparam\u00e8tre $\\large C$ sert \u00e0 quantifier l'importance relative du terme d'erreur et du terme de marge.\n\nIl s'agit donc bien d'une <b>r\u00e9gularisation \u21132<\/b>, et le coefficient $\\large C$ vaut $\\large \\frac{1}{2\\lambda}$ par rapport \u00e0 ce que nous avons pu \u00e9crire pour la r\u00e9gression Ridge.\n    \n<b>Les SVM peuvent aussi \u00eatre utilis\u00e9es pour des probl\u00e8mes de r\u00e9gression <em>(SVR)<\/em><\/b> et on cherche toujours \u00e0 minimiser $\\large ||w||^2_2$ \n<\/details>","a63b3c34":"Suite \u00e0 cette premi\u00e8re mod\u00e9lisation par ElasticNet, **les m\u00e9triques ne se sont que l\u00e9g\u00e9rement am\u00e9lior\u00e9es pour les pr\u00e9dictions de la consommation d'\u00e9nergie et des \u00e9missions de CO2**. Nous allons \u00e0 pr\u00e9sent tester un second mod\u00e8le lin\u00e9aire : SVR.","2f6bf0d7":"En passant les donn\u00e9es \u00e0 l'\u00e9chelle logarithmique, nous obtenons une distribution normale des donn\u00e9es \u00e0 pr\u00e9dire. Nous allons donc appliquer cette transformation dans notre pipeline gr\u00e2ce \u00e0 la fonction `TransformedTargetRegressor` de la librairie Sklearn.\n\nLa fonction inverse (exp) sera donc pass\u00e9e dans les pr\u00e9dictions.","46f0fcdf":"Concernant nos variables \u00e0 pr\u00e9dire, nous allons regarder l'**impact du passage \u00e0 l'\u00e9chelle logarithmique sur les distribution** :","7b357b2e":"Nous avons \u00e0 pr\u00e9sent nos m\u00e9triques de d\u00e9part obtenues avec notre mod\u00e8le de r\u00e9gression lin\u00e9aire multivari\u00e9 servant de baseline. Nous allons r\u00e9aliser nos premi\u00e8res mod\u00e9lisations en utilisant des mod\u00e8les lin\u00e9aires.","0a60fc42":"Avec la projection graphique ci-dessus, on constate que le mod\u00e8le RandomForestRegressor offre le meilleur compromis score \/ temps. Il est en effet meilleur en terme de score MAE et \u00e9galement bien plus rapide que le mod\u00e8le XGBoost.\n\n**<font color=\"green\">Le mod\u00e8le retenu pour la mod\u00e9lisation de la variable TotalGHGEmissions est donc le mod\u00e8le RandomForestRegressor<\/font>**. Nous allons \u00e0 pr\u00e9sent visualiser l'impact des hyperparam\u00e8tres de la GridSearch :","ee1c7b2f":"Le but de notre programme est de supprimer les relev\u00e9s couteux pour les ann\u00e9es \u00e0 venir. **Nous allons donc exclure toutes les donn\u00e9es de rel\u00e8ve de notre dataset**.","9e946512":"### <font color=\"#2cb7b0\" id=\"section_6_2\">6.2. Pr\u00e9diction des consommations d'\u00e9nergie<\/font>","bbf018fc":"**Les m\u00e9triques sur le jeu de donn\u00e9es de test sont tr\u00e8s d\u00e9grad\u00e9es comparativement aux m\u00e9triques obtenues avec la GridSearch** avec le mod\u00e8le de RandomForestRegressor. Nous allons v\u00e9rifier la distribution des valaurs pr\u00e9dites en fonction des valeurs r\u00e9\u00e9lles :","26424e84":"Regardons la distribution de cette variable ainsi que sa relation avec les \u00e9missions de CO2 :","019dc630":"## <font color=\"#337da4\" id=\"section_3\">3. Mod\u00e8le lin\u00e9aires : ElasticNet et SVR<\/font>\n\n### <font color=\"#2cb7b0\" id=\"section_3_1\">3.1. Mod\u00e8le ElasticNet<\/font>","eee4659e":"Les valeurs pr\u00e9dites sont en effet beaucoup plus reserr\u00e9es sur la premi\u00e8re bissectrice et **les m\u00e9triques se sont am\u00e9lior\u00e9es gr\u00e2ce \u00e0 la prise en compte de l'ENERGY STAR Score**. \n\nEn revanche, cette variable est encore **peu renseign\u00e9e et le jeu de donn\u00e9es comporte peu d'entr\u00e9es**. Il est donc difficile de savoir si cette am\u00e9lioration est **r\u00e9\u00e9llement significative**. Il faut \u00e9galement prendre en compte le b\u00e9n\u00e9fice vis \u00e0 vis du co\u00fbt de cet ENERGY STAR Score."}}