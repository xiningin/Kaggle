{"cell_type":{"45f220f9":"code","2885e29a":"code","9dbdbaf3":"code","42ed7044":"code","e3259fd1":"code","ecf7f82e":"code","8ef9aa38":"code","a1129fa8":"code","e0141ce5":"code","db34ebc1":"code","38965092":"code","ff4fc7b6":"code","48fb9ac1":"code","e3e04bd3":"code","e6319ed9":"code","c04f378a":"code","a31289ee":"code","ee4b94bc":"code","b393301a":"code","07b1223a":"code","144f40f2":"code","320ad264":"code","0495dff7":"code","800f25fe":"code","ed1e516a":"code","af2bb58a":"code","0acb3ca0":"code","9e7fe14b":"code","7aa6eb7d":"code","c521846d":"code","fec758d2":"code","5c1f5043":"code","f9bfe01d":"code","66e1d344":"code","dc0a0e9b":"code","f11de66d":"code","f7641d83":"code","107e7cec":"code","dc862163":"code","d4bbe43f":"code","c339d745":"code","98689160":"code","3749cb30":"code","e6e238ae":"code","d18bae26":"code","7dd6f632":"markdown","060d6f23":"markdown","1824550f":"markdown","d486453c":"markdown","add6e7ef":"markdown","6836b1ee":"markdown","5fa79585":"markdown","008abed2":"markdown"},"source":{"45f220f9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport pandas as pd \nimport numpy as np                     # For mathematical calculations \nimport seaborn as sns                  # For data visualization \nimport matplotlib.pyplot as plt        # For plotting graphs \n%matplotlib inline \nimport warnings \n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","2885e29a":"DATA_DIR = r'..\/input'  # set for local environment!\nTEST_DIR = r'..\/input\/test'  # set for local environment!","9dbdbaf3":"train = pd.read_csv(os.path.join(DATA_DIR, 'train_sAmple.csv'), \n                    dtype={'acoustic_data': np.int16, 'time_to_failure': np.float32})\nprint(train.shape)\nprint('ok')\n","42ed7044":"test = pd.read_csv(os.path.join(DATA_DIR, 'test_SamPle.csv'), \n                    dtype={'acoustic_data': np.int16, 'time_to_failure': np.float32})\nprint(test.shape)\nprint('ok')","e3259fd1":"train.columns","ecf7f82e":"test.columns","8ef9aa38":"train.dtypes","a1129fa8":"train['Loan_Status'].value_counts()\n","e0141ce5":"train['Loan_Status'].value_counts(normalize=True)","db34ebc1":"train['Loan_Status'].value_counts().plot.bar()","38965092":"plt.figure(1) \nplt.subplot(221) \ntrain['Gender'].value_counts(normalize=True).plot.bar(figsize=(10,6), title= 'Gender') \nplt.subplot(222) \ntrain['Married'].value_counts(normalize=True).plot.bar(title= 'Married') \nplt.subplot(223) \ntrain['Self_Employed'].value_counts(normalize=True).plot.bar(title= 'Self_Employed') \nplt.subplot(224) \ntrain['Credit_History'].value_counts(normalize=True).plot.bar(title= 'Credit_History') \n\nplt.show()\n","ff4fc7b6":"plt.figure(1) \nplt.subplot(131)\ntrain['Dependents'].value_counts(normalize=True).plot.bar(figsize=(20,8), title= 'Dependents') \nplt.subplot(132)\ntrain['Education'].value_counts(normalize=True).plot.bar(title= 'Education') \nplt.subplot(133) \ntrain['Property_Area'].value_counts(normalize=True).plot.bar(title= 'Property_Area') \nplt.show()","48fb9ac1":"df=train.dropna() \nsns.distplot(df['ApplicantIncome'], rug=True, rug_kws={\"color\": \"b\"}); \n","e3e04bd3":"sns.distplot(df['CoapplicantIncome'],rug=True, rug_kws={\"color\": \"b\"} )\n","e6319ed9":"    plt.figure(2) \n    plt.subplot(121)\n    train['ApplicantIncome'].plot.box(figsize=(16,5), title= 'Applicant - Income')\n\n    plt.subplot(122) \n    train['CoapplicantIncome'].plot.box(figsize=(16,5), title= 'Coapplicant - Income') \n\n    plt.show()","c04f378a":"train.boxplot(column='ApplicantIncome', by = 'Education') \nplt.suptitle(\"\")","a31289ee":"# distribution of LoanAmount variable.\nplt.figure(1) \nplt.subplot(121) \ndf=train.dropna() \n\nsns.distplot(df['LoanAmount']); \n\nplt.subplot(122) \ntrain['LoanAmount'].plot.box(figsize=(16,5)) \n\nplt.show()","ee4b94bc":"Gender=pd.crosstab(train['Gender'],train['Loan_Status']) \nGender.div(Gender.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))\n","b393301a":"Married=pd.crosstab(train['Married'],train['Loan_Status']) \nDependents=pd.crosstab(train['Dependents'],train['Loan_Status']) \nEducation=pd.crosstab(train['Education'],train['Loan_Status']) \nSelf_Employed=pd.crosstab(train['Self_Employed'],train['Loan_Status']) \n\nMarried.div(Married.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4)) \nplt.show() \n\nDependents.div(Dependents.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True) \nplt.show()\n\nEducation.div(Education.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4)) \nplt.show() \n\nSelf_Employed.div(Self_Employed.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4)) \nplt.show()","07b1223a":"Credit_History=pd.crosstab(train['Credit_History'],train['Loan_Status']) \nProperty_Area=pd.crosstab(train['Property_Area'],train['Loan_Status']) \n\nCredit_History.div(Credit_History.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4)) \nplt.show() \n\nProperty_Area.div(Property_Area.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True) \nplt.show()","144f40f2":"#Mean Income ---\ntrain.groupby('Loan_Status')['ApplicantIncome'].mean().plot.bar()","320ad264":"bins=[0,2500,4000,6000,81000] \ngroup=['Low','Average','High', 'Very high'] \n\ntrain['Income_bin']=pd.cut(df['ApplicantIncome'],bins,labels=group)\n\nIncome_bin=pd.crosstab(train['Income_bin'],train['Loan_Status']) \nIncome_bin.div(Income_bin.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True) \nplt.xlabel('ApplicantIncome') \n\nP = plt.ylabel('Percentage')","0495dff7":"bins=[0,1000,3000,42000] \ngroup=['Low','Average','High'] \n\ntrain['Coapplicant_Income_bin']=pd.cut(df['CoapplicantIncome'],bins,labels=group)\n\nCoapplicant_Income_bin=pd.crosstab(train['Coapplicant_Income_bin'],train['Loan_Status']) \nCoapplicant_Income_bin.div(Coapplicant_Income_bin.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True) \nplt.xlabel('CoapplicantIncome') \nP = plt.ylabel('Percentage')","800f25fe":"train['Total_Income']=train['ApplicantIncome']+train['CoapplicantIncome']\nbins=[0,2500,4000,6000,81000] \ngroup=['Low','Average','High', 'Very high'] \ntrain['Total_Income_bin']=pd.cut(train['Total_Income'],bins,labels=group)\nTotal_Income_bin=pd.crosstab(train['Total_Income_bin'],train['Loan_Status']) \nTotal_Income_bin.div(Total_Income_bin.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True) \nplt.xlabel('Total_Income') \n\nP = plt.ylabel('Percentage')","ed1e516a":"bins=[0,100,200,500,700] \ngroup=['Low','Average','High','Very High']\n\ntrain['LoanAmount_bin']=pd.cut(df['LoanAmount'],bins,labels=group)\nLoanAmount_bin=pd.crosstab(train['LoanAmount_bin'],train['Loan_Status']) \n\nLoanAmount_bin.div(LoanAmount_bin.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True) \nplt.xlabel('LoanAmount') \nP = plt.ylabel('Percentage')","af2bb58a":"train=train.drop(['Income_bin', 'Coapplicant_Income_bin', 'LoanAmount_bin', 'Total_Income_bin', 'Total_Income'], axis=1)\n\ntrain['Dependents'].replace('3+', 3,inplace=True) \ntest['Dependents'].replace('3+', 3,inplace=True) \ntrain['Loan_Status'].replace('N', 0,inplace=True) \ntrain['Loan_Status'].replace('Y', 1,inplace=True)","0acb3ca0":"matrix = train.corr() \nf, ax = plt.subplots(figsize=(9, 6)) \nsns.heatmap(matrix, vmax=1.5, square=True, cmap=\"BuPu\");","9e7fe14b":"train.isnull().sum()","7aa6eb7d":"train['Gender'].fillna(train['Gender'].mode()[0], inplace=True) \ntrain['Married'].fillna(train['Married'].mode()[0], inplace=True) \ntrain['Dependents'].fillna(train['Dependents'].mode()[0], inplace=True) \ntrain['Self_Employed'].fillna(train['Self_Employed'].mode()[0], inplace=True) \ntrain['Credit_History'].fillna(train['Credit_History'].mode()[0], inplace=True)","c521846d":"train.isnull().sum()","fec758d2":"train['Loan_Amount_Term'].value_counts()\ntrain['Loan_Amount_Term'].fillna(train['Loan_Amount_Term'].mode()[0], inplace=True)\ntrain['LoanAmount'].fillna(train['LoanAmount'].median(), inplace=True)\ntrain.isnull().sum()","5c1f5043":"test['Gender'].fillna(train['Gender'].mode()[0], inplace=True) \ntest['Dependents'].fillna(train['Dependents'].mode()[0], inplace=True) \ntest['Self_Employed'].fillna(train['Self_Employed'].mode()[0], inplace=True) \ntest['Credit_History'].fillna(train['Credit_History'].mode()[0], inplace=True) \ntest['Loan_Amount_Term'].fillna(train['Loan_Amount_Term'].mode()[0], inplace=True) \ntest['LoanAmount'].fillna(train['LoanAmount'].median(), inplace=True)","f9bfe01d":"train['LoanAmount_log'] = np.log(train['LoanAmount']) \ntrain['LoanAmount_log'].hist(bins=20) ","66e1d344":"test['LoanAmount_log'] = np.log(test['LoanAmount'])\ntest['LoanAmount_log'].hist(bins=20)","dc0a0e9b":"train=train.drop('Loan_ID',axis=1) \ntest=test.drop('Loan_ID',axis=1)","f11de66d":"X = train.drop('Loan_Status',1) \ny = train.Loan_Status","f7641d83":"X=pd.get_dummies(X) \ntrain=pd.get_dummies(train) \ntest=pd.get_dummies(test)","107e7cec":"from sklearn.model_selection import train_test_split\nx_train, x_cv, y_train, y_cv = train_test_split(X,y, test_size =0.3)","dc862163":"from sklearn.linear_model import LogisticRegression \nfrom sklearn.metrics import accuracy_score\nmodel = LogisticRegression() \nmodel.fit(x_train, y_train)\nLogisticRegression(C=1.0, class_weight=None, dual=False, \n                   fit_intercept=True,intercept_scaling=1, max_iter=100, multi_class='ovr', \n                   n_jobs=1,penalty='l2', random_state=1, solver='liblinear', tol=0.0001,         \n                   verbose=0, warm_start=False)","d4bbe43f":"#Let\u2019s predict the Loan_Status for validation set and calculate its accuracy.\n\npred_cv = model.predict(x_cv)\naccuracy_score(y_cv,pred_cv)","c339d745":"pred_test = model.predict(test)","98689160":"submission = pd.read_csv(os.path.join(DATA_DIR, 'sample_submission_S7jWYrJ.csv'), \n                    dtype={'acoustic_data': np.int16, 'time_to_failure': np.float32})\nprint(submission.shape)\nprint('ok')","3749cb30":"submission['Loan_Status']=pred_test \nsubmission['Loan_ID']=test['Loan_ID']\n","e6e238ae":"submission['Loan_Status'].replace(0, 'N',inplace=True) \nsubmission['Loan_Status'].replace(1, 'Y',inplace=True)","d18bae26":"pd.DataFrame(submission, columns=['Loan_ID','Loan_Status']).to_csv('Final_submission.csv')","7dd6f632":"Proportion of married applicants is higher for the approved loans. Distribution of applicants with 1 or 3+ dependents is similar across both the categories of Loan_Status. There is nothing significant we can infer from Self_Employed vs Loan_Status plot.","060d6f23":"Here the y-axis represents the mean applicant income. We don\u2019t see any change in the mean income. So, let\u2019s make bins for the applicant income variable based on the values in it and analyze the corresponding loan status for each bin.","1824550f":"it shows that if coapplicant\u2019s income is less the chances of loan approval are high. But this does not look right. The possible reason behind this may be that most of the applicants don\u2019t have any coapplicant so the coapplicant income for such applicants is 0 and hence the loan approval is not dependent on it. ","d486453c":"Most of the applicants don\u2019t have any dependents. Around 80% of the applicants are Graduate. Most of the applicants are from Semiurban area.","add6e7ef":"We see that the most correlated variables are (ApplicantIncome - LoanAmount) and (Credit_History - Loan_Status). LoanAmount is also correlated with CoapplicantIncome.","6836b1ee":"80% applicants in the dataset are male. Around 65% of the applicants in the dataset are married. Around 15% applicants in the dataset are self employed. Around 85% applicants have repaid their debts.","5fa79585":"**** ---- Outlier Treatment","008abed2":"Applicants with high income should have more chances of loan approval. Applicants who have repaid their previous debts should have higher chances of loan approval. Loan approval should also depend on the loan amount. If the loan amount is less, chances of loan approval should be high. Lesser the amount to be paid monthly to repay the loan, higher the chances of loan approval."}}