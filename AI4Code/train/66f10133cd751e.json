{"cell_type":{"296edfc2":"code","178dd1bf":"code","3c51e7f7":"code","8a3819e6":"code","1a22bb93":"code","6fcbb490":"code","d21e679d":"code","ba3dff66":"code","6f5457f1":"code","6ffa222f":"code","efb5f05e":"code","5d4f0a80":"code","2e3bed3a":"code","f4735ab4":"code","af26653e":"code","bdb52f82":"code","b636a2a2":"code","a6322194":"markdown","acbfc4f1":"markdown","2c6ce4b2":"markdown","0538cb21":"markdown","b587d874":"markdown","04020c51":"markdown","cffada28":"markdown","d8524678":"markdown","143a8fc9":"markdown","9074fafb":"markdown","1744e282":"markdown","a90ad56b":"markdown","c4bd9a33":"markdown","af9f7527":"markdown"},"source":{"296edfc2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","178dd1bf":"import pandas as pd\nimport numpy as np\nimport random\nimport math\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPool2D, BatchNormalization\nfrom keras.layers import Convolution2D, MaxPooling2D\nfrom keras.utils.np_utils import to_categorical\n\nimport seaborn as sns\nfrom matplotlib import pyplot as plt","3c51e7f7":"# numpy random number geneartor seed\n# for reproducibility\nnp.random.seed(123)\n\n# set plot rc parameters\n# jtplot.style(grid=False)\nplt.rcParams['figure.facecolor'] = 'white'\nplt.rcParams['axes.facecolor'] = '#232323'\n#plt.rcParams['axes.edgecolor'] = '#FFFFFF'\nplt.rcParams['figure.figsize'] = 10, 7\nplt.rcParams['legend.loc'] = 'best'\nplt.rcParams['legend.framealpha'] = 0.2\nplt.rcParams['text.color'] = '#666666'\nplt.rcParams['axes.labelcolor'] = '#666666'\nplt.rcParams['axes.labelsize'] = 14\nplt.rcParams['axes.titlesize'] = 16\nplt.rcParams['xtick.color'] = '#666666'\nplt.rcParams['xtick.labelsize'] = 14\nplt.rcParams['ytick.color'] = '#666666'\nplt.rcParams['ytick.labelsize'] = 14\n\n# plt.rcParams['font.size'] = 16\n\nsns.color_palette('dark')\n%matplotlib inline","8a3819e6":"dftrain = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ndftest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\ndftrain.head()","1a22bb93":"dftrain.shape, dftest.shape","6fcbb490":"# plot histogram of digits\nfig = plt.figure(figsize=[10,7])\nsns.countplot(dftrain['label'], color=sns.xkcd_rgb['greenish cyan'])\nplt.title('Histogram of digits')\nplt.show()","d21e679d":"# generate random list of indices of data point\nlist_idx = [random.randint(0,1000) for a in range(10)]\n# plot randomly chosen data points\nfig, axs = plt.subplots(5,2, figsize=[25,25])\naxs = axs.flatten()\nfor i in range(0,10,2):\n    # get x and y values from image\n    y = dftrain.iloc[list_idx[i]]['label']\n    x = dftrain.iloc[list_idx[i]][1:].values\n    # plot flattened image (1D)\n    axs[i].plot(x)\n    axs[i].set_xlabel('#pixel')\n    axs[i].set_ylabel('intensity')\n    # axs[i].set_title(str(y))\n    # plot 2D image\n    axs[i+1].imshow(x.reshape(28,28))\n    axs[i+1].set_title('image of number' + str(y))\n    \nplt.show()","ba3dff66":"# split data into train and test set\nXtrain, Xcv, Ytrain, Ycv = train_test_split(dftrain.values[:,1:], dftrain.values[:,0], random_state=16, test_size=0.2)","6f5457f1":"# one hot encode label matrix\ndef ohe_y(y):\n    return to_categorical(y, 10)\n\n# pre-process image pixel\ndef pre_process_x(x):\n    # reshape array as 28X28 matrix\n    out_x = x.reshape(-1, 28, 28, 1)\n    # normalize \n    out_x = out_x.astype('float32')\n    out_x \/= 255\n    return out_x\n\nXtrain = pre_process_x(Xtrain)\nXcv = pre_process_x(Xcv)\nXtest = pre_process_x(dftest.values)\nYtrain= ohe_y(Ytrain)\nYcv = ohe_y(Ycv)","6ffa222f":"# print meta data\nprint('Xtrain shape\\t\\t', Xtrain.shape, '\\n',\n     'Xcv shape\\t\\t', Xcv.shape, '\\n',\n     'Xtest shape\\t\\t', Xtest.shape, '\\n',\n     'Ytrain shape\\t\\t', Ytrain.shape, '\\n',\n     'Ycv shape\\t\\t', Ycv.shape, '\\n')","efb5f05e":"# initiate sequential model\nmodel = Sequential()\n# add convolutional layer\n# 16 sliding windows each of 3X3 size\n# default step is 1X1\nmodel.add(Conv2D(filters = 16,\n                 kernel_size = (3, 3),\n                 activation='relu',\n                 input_shape = (28, 28,1)))\n# let's print shape of output of first layer\nprint('shape of output of first convolution layer\\t\\t', model.output_shape, '\\n\\n')\n# add batch normalization to normalize output of the layer\nmodel.add(BatchNormalization())\n# add another convolutional layer\nmodel.add(Conv2D(filters = 16,\n                 kernel_size = (3, 3),\n                 activation='relu'))\n# let's print shape of output of second layer\nprint('shape of output of secon convolution layer\\t\\t', model.output_shape, '\\n\\n')\n# batchnormalize\nmodel.add(BatchNormalization())\n# add maxpooling layer\n# this layer picks max value for every 2X2 window\nmodel.add(MaxPool2D(pool_size=(2,2)))\n# let's print shape of output of maxpool layer\nprint('shape of output of first maxpool layer\\t\\t', model.output_shape, '\\n\\n')\n# add dropout layer\n# it acts as a regularizer\nmodel.add(Dropout(0.25))\n# repeat above sequence once more\nmodel.add(Conv2D(filters = 32,\n                 kernel_size = (3, 3),\n                 activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 32,\n                 kernel_size = (3, 3),\n                 activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n# now we'll add two dense layer\n# just like layer of ANN\nprint('shape of output before flattening data\\t\\t', model.output_shape, '\\n\\n')\nmodel.add(Flatten())\nprint('shape of output after flattening data\\t\\t', model.output_shape, '\\n\\n')\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(128, activation='relu'))\n# let's print shape of output of dense layers\nprint('shape of output of dense layers\\t\\t', model.output_shape, '\\n\\n')\nmodel.add(Dropout(0.5))\n# finally add a softmax layer which will predict probability of each class\nmodel.add(Dense(10, activation='softmax'))\n# print model summary\nmodel.summary()\n\n# compile model\nmodel.compile(loss='categorical_crossentropy',\n             optimizer='adam',\n             metrics=['accuracy'])","5d4f0a80":"# train model\nmodel_out = model.fit(Xtrain,\n                      Ytrain,\n                     batch_size=128,\n                     epochs=40,\n                     validation_data=(Xcv[:500], Ycv[:500]))","2e3bed3a":"# evaluate model performance\nloss, acc = model.evaluate(Xcv, Ycv, verbose=0)\n# Print loss and accuracy of model\nloss, acc","f4735ab4":"# plot model accuracy and error with respect to each epoch\nfig, axs = plt.subplots(1,2, figsize=[15,7])\naxs.flatten()\n# plot accuracy\naxs[0].plot(model_out.history['accuracy'], sns.xkcd_rgb['greenish cyan'], label='training')\naxs[0].plot(model_out.history['val_accuracy'], sns.xkcd_rgb['red pink'], label='cross validation')\naxs[0].set_ylabel('accuracy')\naxs[0].set_xlabel('epoch')\naxs[0].legend(loc='best')\n# plot loss\naxs[1].plot(model_out.history['loss'], sns.xkcd_rgb['greenish cyan'], label='training')\naxs[1].plot(model_out.history['val_loss'], sns.xkcd_rgb['red pink'], label='cross validation')\naxs[1].set_ylabel('loss')\naxs[1].set_xlabel('epoch')\naxs[1].legend(loc='best')\nplt.show()","af26653e":"# plot confusion matrix\ndef plot_confusion_matrix(model, Xtrain, Xtest, Ytrain, Ytest):\n    \n    # get predicted values\n    Ytrain_pred = model.predict(Xtrain)\n    Ytest_pred = model.predict(Xtest)\n    \n    # flatten ypredicted and ytrue\n    Ytrain = np.argmax(Ytrain, axis=1)\n    Ytest = np.argmax(Ytest, axis=1)\n    Ytrain_pred = np.argmax(Ytrain_pred, axis=1)\n    Ytest_pred = np.argmax(Ytest_pred, axis=1)\n\n    # confusion matrix\n    fig, axs = plt.subplots(1,2,\n                            figsize=[15,8])\n    axs = axs.flatten()\n    \n    axs[0].set_title('Training data')\n    # axs[0].set_xlabel('Predicted label')\n    # axs[0].set_ylabel('True label')\n    axs[1].set_title('Test data')\n    # axs[1].set_xlabel('Predicted label')\n    # axs[1].set_ylabel('True label')\n    \n    fig.text(0.3, 0.1, 'Predicted label', ha='center', fontsize=14)\n    fig.text(0.72, 0.1, 'Predicted label', ha='center', fontsize=14)\n    fig.text(0.08, 0.5, 'True label', va='center', rotation='vertical', fontsize=14)\n    fig.text(0.5, 0.5, 'True label', va='center', rotation='vertical', fontsize=14)\n    \n    sns.heatmap(confusion_matrix(Ytrain,Ytrain_pred),\n                    annot=True,\n                    xticklabels=list(range(10)),\n                    yticklabels=list(range(10)),\n                    fmt=\"d\",\n                    cmap='coolwarm',\n                    square=True,\n                    cbar=False,\n                    ax=axs[0])\n    \n    sns.heatmap(confusion_matrix(Ytest,Ytest_pred),\n                    annot=True,\n                    xticklabels=list(range(10)),\n                    yticklabels=list(range(10)),\n                    fmt=\"d\",\n                    cmap='coolwarm',\n                    square=True,\n                    cbar=False,\n                    ax=axs[1])\n    plt.show()\n    \n    return\n\nplot_confusion_matrix(model,Xtrain,Xcv,Ytrain,Ycv)","bdb52f82":"# get prediction of test data\nYtest = model.predict(Xtest)\nYtest = np.argmax(Ytest,axis=1)\n# get id column\nids = list(range(1,dftest.shape[0]+1))\n# put that in pandas data frame\nsubmission = pd.DataFrame({'ImageId':ids, 'Label':Ytest})\nsubmission.head()","b636a2a2":"# save submission file\nsubmission.to_csv('submission.csv')","a6322194":"Our data is in csv file, first row is name of columns, first column is label of image. each image is 28X28, 784 pixels each.","acbfc4f1":"## Import libraries","2c6ce4b2":"### Plot model statistics","0538cb21":"I'm using four convolutional layer each followed by a batch normalization, you can reduce the number of batch-normalization layer. There is no hard and fast rule about how many layers to use and what dimensions to use. You have to choose a model architecture either by experimenting (tuning hyperparameters) or learn from others to find out what works best.\n\nEach convolutional layer uses a sliding window to perform convolution operation on image matrix. It used to identify certain features in image like edges, curves etc. I'm using 16 such windows in each convolution layer. each window will have different parameters it will generate different output.\n\nI'm not using any padding because there is not much information to gain about numbers from edges of the images, so we can skip it.\n\nfollowing is the code for my model architecture","b587d874":"## Load data","04020c51":"# Digit identification on MNIST data","cffada28":"## Train model","d8524678":"# refereces\n\n*  [gettting started with keras](https:\/\/elitedatascience.com\/keras-tutorial-deep-learning-in-python)\n*  [Deeplearning course kaggle](https:\/\/www.kaggle.com\/dansbecker\/deep-learning-from-scratch)\n*  [best submission](https:\/\/www.kaggle.com\/toregil\/welcome-to-deep-learning-cnn-99)\n*  [tuning CNN parameters](https:\/\/www.kaggle.com\/cdeotte\/how-to-choose-cnn-architecture-mnist)","143a8fc9":"## EDA","9074fafb":"## Define Model architecture","1744e282":"### data prepration","a90ad56b":"### model evaluation","c4bd9a33":"## Data pre-processing","af9f7527":"### split data"}}