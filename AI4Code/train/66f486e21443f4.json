{"cell_type":{"d235c3fc":"code","b405f8fa":"code","ad970be5":"code","5bb8422c":"code","2bbb54b9":"code","c6469028":"code","e8a8aedb":"code","07a6c9ee":"code","ea4d2c01":"code","8b5fc991":"code","95f3f6d4":"code","4c448bfa":"code","160db490":"code","c94d1547":"markdown","8e6df1b5":"markdown","17830497":"markdown","239110b6":"markdown","fb2b3cbe":"markdown","0700a4c5":"markdown","4e3d0f35":"markdown","9debdf6a":"markdown","4e4db90b":"markdown"},"source":{"d235c3fc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b405f8fa":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras.layers import Conv2D,Dropout,MaxPooling2D,Dense,Flatten\nfrom keras.models import Sequential\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import np_utils\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping","ad970be5":"data=pd.read_csv('..\/input\/digit-recognizer\/train.csv')\nprint('data information:',data.info())\nimages=[]\nfor l in range(len(data)):\n    images.append(np.array(data.iloc[l,1:]).reshape(28,28))\nplt.imshow(images[10],cmap='gray')\nplt.show()","5bb8422c":"target=data['label']\noh_y=np_utils.to_categorical(target)\nx=np.array(images).reshape(-1,28,28,1)\nxtrain,xtets,ytrain,ytest=train_test_split(x,oh_y,test_size=0.25,random_state=123)\ntarget.value_counts()","2bbb54b9":"from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\n\ndef cnn_model(n_input_filters=16,kernel=2,n_layer=2,n_hidden_filters=8,activation='relu',optimizer='adam',dropout=0.2,n_dense=2,\n             n_dense_layer=2):\n    model=Sequential()\n    model.add(Conv2D(n_input_filters,(kernel,kernel),activation=activation,input_shape=(28,28,1),padding='same'))\n    model.add(MaxPooling2D(2,2))\n    for i in range(n_layer):\n        model.add(Conv2D(n_hidden_filters,(kernel,kernel),activation=activation))\n        model.add(MaxPooling2D(2,2))\n \n    model.add(Flatten())\n    for j in range(n_dense_layer):\n        \n        model.add(Dense(n_dense,activation=activation))\n        model.add(Dropout(dropout))\n    model.add(Dense(10,activation='sigmoid'))\n    model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer=optimizer)\n    return model\ncnn=KerasClassifier(build_fn=cnn_model,epochs=5,batch_size=8)\nparams=dict(optimizer=['adam','sgd'],n_input_filters=[16,32,64],kernel=[2,3],\n           n_layer=[2,3,4],n_hidden_filters=[16,32,64],activation=['tanh','relu'],\n           epochs=[3],batch_size=[32,64],dropout=[0.3,0.5],n_dense=[64,128,32],\n             n_dense_layer=[2,3])\ntuned_model=RandomizedSearchCV(cnn,param_distributions=params,cv=3)","c6469028":"tuned_model.fit(xtrain,ytrain)","e8a8aedb":"checkpoint=ModelCheckpoint('bestmodel.hdf5',save_best_only=True,monitor='val_loss')\nearlystopping=EarlyStopping(monitor='val_loss',patience=5)\nmodel=Sequential()\nmodel.add(Conv2D(32,kernel_size=(3,3),activation ='tanh',input_shape=(28,28,1),padding='same'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Conv2D(64,(3,3),activation='tanh'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Conv2D(64,(3,3),activation='tanh'))\nmodel.add(Flatten())\nmodel.add(Dense(64,activation='sigmoid'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(64,activation='sigmoid'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(64,activation='sigmoid'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(10,activation='sigmoid'))\nmodel.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\nfinal_model=model.fit(xtrain,ytrain,batch_size=64,epochs=100,validation_split=0.2,callbacks=[earlystopping,checkpoint])","07a6c9ee":"model.evaluate(xtets,ytest)","ea4d2c01":"plt.plot(final_model.history['val_loss'],label='validation error')\nplt.plot(final_model.history['loss'],label='train error')\nplt.title('learning crves')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend()\nplt.show()","8b5fc991":"model.load_weights('.\/bestmodel.hdf5')\ntest_data=pd.read_csv('..\/input\/digit-recognizer\/test.csv')\ntest_pictures=[]\nfor j in range(len(test_data)):\n    test_pictures.append(np.array(test_data.iloc[j,:]).reshape(28,28))\ntest=np.array(test_pictures).reshape(-1,28,28,1)\nprediction=model.predict(test)\nbinary_output=np.round(prediction)\n","95f3f6d4":"predicted_labels=[]\nfor t in range(len(binary_output)):\n    number_list=list(binary_output[t])\n    max_value = max(number_list)\n    max_index = number_list.index(max_value)\n    predicted_labels.append(max_index)\n","4c448bfa":"images=[i for i in range(1,len(test_data)+1)]\nsubmission=pd.DataFrame({'ImageId':images,'Label':predicted_labels})","160db490":"submission.reset_index(drop=True,inplace=True)\nsubmission.to_csv('sample_submission.csv')","c94d1547":"**bulding final model according to tuned hyperparameters**","8e6df1b5":"**one-hot encoding & splitting data to test and train sets**","17830497":"**importing necessary libreries**","239110b6":"**predicting with best model**","fb2b3cbe":"**training model**","0700a4c5":"**tuning hyperparameters of convolutional neural network(CNN) using from RandomizedSearchCV**","4e3d0f35":"**learning curves**","9debdf6a":"**evaluating model**","4e4db90b":"**importing and inspecting data**"}}