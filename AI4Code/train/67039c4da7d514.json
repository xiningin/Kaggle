{"cell_type":{"3987d103":"code","53501691":"code","7980bb88":"code","7edbaf05":"code","93c8c63b":"code","1e2709bd":"code","266c706c":"code","f8b6ce45":"code","24101c2b":"code","c29df116":"code","c5719496":"code","e88f433b":"code","24b0ed9e":"code","7248ad82":"code","58c1f478":"code","4c9daa35":"code","3d27216b":"code","9c61f2d5":"code","187ea639":"code","04d31133":"code","d391d0d0":"code","ad770cf0":"code","b82e8259":"code","494405ea":"code","9bb8ad3f":"code","d850625a":"code","a7247485":"code","059f2d36":"code","421c95d1":"code","d0e7ee50":"code","b639c39c":"code","3d3175d1":"code","9d342a6e":"code","7ff64f81":"code","2f2b209e":"code","77454b4a":"code","11ea26ae":"code","ece6f4d9":"markdown","9fb837ef":"markdown","ed4544ff":"markdown","8b6aebf5":"markdown","50042960":"markdown","d4679929":"markdown","23228e90":"markdown","4cb672b8":"markdown","25b40d51":"markdown","768e0b4a":"markdown","707ee836":"markdown","c0a70ced":"markdown","89acacf0":"markdown","9dfea54d":"markdown","6f8c604d":"markdown","1dc41a17":"markdown","3897cd43":"markdown","8acf651f":"markdown","139d6cc5":"markdown","cd332165":"markdown","c01b3645":"markdown","714cebda":"markdown","67d5a884":"markdown","63e0bdcf":"markdown","651f6f98":"markdown","0150bc21":"markdown","a6c91654":"markdown","f78643da":"markdown","51780345":"markdown","348e19a8":"markdown","2c9659cc":"markdown","afbf5393":"markdown","06d6772d":"markdown","c0410bf8":"markdown","77353b85":"markdown","ea8e5335":"markdown","da1af567":"markdown","800e82b6":"markdown"},"source":{"3987d103":"# Importando as bibliotecas principais utilizadas\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","53501691":"features_ = pd.read_csv('..\/input\/walmart-recruiting-store-sales-forecasting\/features.csv.zip')\ntrain = pd.read_csv('..\/input\/walmart-recruiting-store-sales-forecasting\/train.csv.zip')\nstores = pd.read_csv('..\/input\/walmart-recruiting-store-sales-forecasting\/stores.csv')\ntest = pd.read_csv('..\/input\/walmart-recruiting-store-sales-forecasting\/test.csv.zip')\nsample_submission = pd.read_csv('..\/input\/walmart-recruiting-store-sales-forecasting\/sampleSubmission.csv.zip')","7980bb88":"walmart = pd.read_csv('..\/input\/walmart-sales\/walmart_sales.csv')\nwalmart.head()","7edbaf05":"# n\u00famero dos de departamentos\nwalmart_store = np.sort(walmart.Store.unique())\nwalmart_store","93c8c63b":"dept_qtd = list()\n\nfor idx, store in enumerate(walmart_store): \n   dept_qtd.append(walmart[walmart.Store == store].Dept.unique().size)\n\nc = plt.bar(walmart_store, dept_qtd)\nplt.ylabel('Number of departamets')\nplt.xlabel('Store')\nplt.xticks(range(1,46,2))\nplt.grid(True)\nplt.show()","1e2709bd":"walmart[walmart.Store == 1].groupby('Dept')['Date'].count().plot.bar(figsize=(15,5))","266c706c":"walmart[walmart.Store == 45].groupby('Dept')['Date'].count().plot.bar(figsize=(15,5))","f8b6ce45":"walmart_store1_2010_02_2016 = walmart[(walmart.Store == 1) & (walmart.Date == '2010-12-31')]\nwalmart_store1_2010_02_2016.head()","24101c2b":"walmart_store1_2010_02_2016.nunique()","c29df116":"walmart.info()","c5719496":"walmart_markdown = walmart.loc[:, 'MarkDown1':'MarkDown5']\n\nprint('Procentagem de nulos')\n\nfor markdown in walmart_markdown.columns:\n  md = walmart_markdown[markdown]\n  print(markdown, ':', md.isna().sum() \/ md.size * 100)","e88f433b":"walmart.isna().sum()","24b0ed9e":"walmart_treated = walmart.fillna(0)\nwalmart_treated.isna().sum()","7248ad82":"walmart_treated['Date'] = pd.to_datetime(walmart_treated.Date)","58c1f478":"walmart_treated[['Date']].info()","4c9daa35":"walmart_treated = walmart_treated.sort_values(by='Date')","3d27216b":"walmart_treated.Date.dt.isocalendar()","9c61f2d5":"walmart_treated['week'] = walmart_treated.Date.dt.isocalendar().week\nwalmart_treated['year'] = walmart_treated.Date.dt.isocalendar().year\n\nwalmart_treated.drop('Date', axis=1, inplace=True)","187ea639":"walmart_treated.head(2)","04d31133":"walmart_treated.tail(2)","d391d0d0":"walmart_treated = pd.get_dummies(walmart_treated)\nwalmart_treated.head(2)","ad770cf0":"X = walmart_treated.drop('Weekly_Sales', axis=1)\ny = walmart_treated['Weekly_Sales']\n\nprint(X.shape)\nprint(y.shape)","b82e8259":"from sklearn.model_selection import train_test_split\n\nX_training, X_test, y_training, y_test = train_test_split(X, y, \n                                                          test_size = 0.25, \n                                                          shuffle = False)\n\nprint(\"Train set X\", X_training.shape)\nprint(\"Train set y\", y_training.shape)\nprint(\"Test set X\", X_test.shape)\nprint(\"Test set y\", y_test.shape)","494405ea":"X_train, X_val, y_train, y_val = train_test_split(X, y, \n                                                          test_size = 0.33, \n                                                          shuffle = False)\n\nprint(\"Train set X\", X_train.shape)\nprint(\"Train set y\", y_train.shape)\nprint(\"Validation set X\", X_val.shape)\nprint(\"Validation set y\", y_val.shape)","9bb8ad3f":"from sklearn.model_selection import TimeSeriesSplit\n\ncv = TimeSeriesSplit(n_splits=10)","d850625a":"# Importando as bibliotecas que vamos utilizar no modelo\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.datasets import make_regression\nfrom sklearn.metrics import mean_absolute_error, r2_score\nfrom sklearn.model_selection import GridSearchCV","a7247485":"SEED = 42","059f2d36":"# seta melhor op\u00e7\u00e3o baseada nos hiperpar\u00e2metros\n# utiliza as melhores op\u00e7\u00f5es de hiperpar\u00e2metros encontrados\n\n#rf_model_cv_gs.set_params(n_estimators = grid_search.best_params_['n_estimators'],\n#                          max_features = grid_search.best_params_['max_features'],\n#                          min_samples_split = grid_search.best_params_['min_samples_split'],\n#                          )\nrf_model_cv_gs = RandomForestRegressor(random_state=SEED, n_jobs=-1)\n\nrf_model_cv_gs.set_params(n_estimators = 50,\n                          max_features = 14,\n                          min_samples_split = 4,\n                          )\n\n# treina modelo com todos os dados de treino dispon\u00edveis e com os melhores hiperpar\u00e2metros encontrados\nrf_model_cv_gs.fit(X_training, y_training)","421c95d1":"# prevendo os valores no dataset de teste\ny_pred_test = rf_model_cv_gs.predict(X_test)","d0e7ee50":"print(\"Score on validation set: {:.3f}\".format(rf_model_cv_gs.score(X_test, y_test)))\nprint(\"Mean absolute error (MAE): {:.3f}\".format(mean_absolute_error(y_test, y_pred_test)))\nprint(\"R\u00b2 Score: {:.3f}\".format(r2_score(y_test, y_pred_test)))","b639c39c":"# Desenhando o gr\u00e1fico de valores previstos por valores reais\nplt.figure(figsize=(18,8))\nplt.title('Walmart weakly sales - Predicted vs Real',fontsize=20)\n\ndf = pd.DataFrame({'real':y_test,'RF':y_pred_test})\ndf = df.reset_index(drop=True)\n\n\nplt.plot(df.iloc[-100:])\nplt.legend(['Real weekly sales','RF Predicted weekly sales'],fontsize=20)\nplt.ylabel('Weekly sales',fontsize=20)\nplt.xlabel('Samples ordered by date',fontsize=20)\nplt.show()","3d3175d1":"features = X.columns\nimportances = rf_model_cv_gs.feature_importances_\nindices = np.argsort(importances)\n\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel('Relative Importance')\nplt.show()","9d342a6e":"feat_sto = features_.merge(stores, how='inner', on='Store')\n\nfeat_sto['Date'] = pd.to_datetime(feat_sto['Date'])\nfeat_sto['Week'] = feat_sto.Date.dt.isocalendar().week\nfeat_sto['Year'] = feat_sto.Date.dt.isocalendar().year\n\nfeat_sto.head()","7ff64f81":"test['Date'] = pd.to_datetime(test['Date'])\n\ntest_detail = test.merge(feat_sto, \n                           how='inner',\n                           on=['Store','Date','IsHoliday']).sort_values(by=['Store',\n                                                                            'Dept',\n                                                                            'Date']).reset_index(drop=True)\n\ntest_detail.fillna(0, inplace=True)\ntest_detail.drop('Date', axis=1, inplace=True)\n\ntest_detail.head()","2f2b209e":"test_final = pd.get_dummies(test_detail)\ntest_final.head()","77454b4a":"test_predict = rf_model_cv_gs.predict(test_final)","11ea26ae":"sample_submission['Weekly_Sales'] = test_predict\nsample_submission.to_csv('submission.csv',index=False)","ece6f4d9":"* Split que n\u00e3o embaralhe os dados (`shuffle = False`)\n* Expanding Windows para a valida\u00e7\u00e3o cruzada (se n\u00e3o demorar uma eternidae, pois temos mais de 282 mil registros)","9fb837ef":"##### Departamentos por loja\n* O n\u00famero de departamentos \u00e9 diferente de uma loja para outra: a maioria tem entre 70 e 80 departamentos, mas algumas t\u00eam cerca de 60. \n","ed4544ff":"##### Convers\u00f5es pertinentes (Data as datetime)\n","8b6aebf5":"No grafico acima, para as 100 \u00faltmas amostras do dataset de teste, podemos ver como os valores previstos pelo modelo (em larajna) se comprortam em rela\u00e7\u00e3o as valores reais (em azul).","50042960":"#### Vari\u00e1veis dummy","d4679929":"Um dos grandes desafios das empresas \u00e9 a previs\u00e3o de vendas. Um bom modelo de previs\u00e3o das vendas da empresa permite um melhor planejamento de gastos das empresas e da produ\u00e7\u00e3o, permite uma estima\u00e7\u00e3o de lucros e at\u00e9 mesmo auxilia a empresa a determinar metas, avaliar o seu desempenho e ter uma melhor vis\u00e3o de futuro, ajudando na atra\u00e7\u00e3o de poss\u00edveis investidores.\n\nEsse notebook cont\u00e9m o exerc\u00edcio pr\u00e1tico da aula de s\u00e9ries temporais. O *dataset* que utilizaremos e foi disponibilizado na pasta de dados da aula vem originalmente de um desafio de recrutamento do Walmart - que pode ser acessado [aqui](https:\/\/www.kaggle.com\/c\/walmart-recruiting-store-sales-forecasting\/data). Ele cont\u00e9m vendas an\u00f4nimas por departamento para 45 lojas Walmart, bem como vari\u00e1veis de apoio.\n\nAssim, o exerc\u00edcio proposto aqui \u00e9 de **prever as vendas semanais das lojas da Walmart**. Para isso, sugerimos voc\u00ea utilizar o modelo de machine learning *Random Forest* que vimos na aula, mas voc\u00ea pode tamb\u00e9m experimentar outros modelos que aprendemos.\n\nAp\u00f3s todo o conhecimento que voc\u00ea adquiriu ao longo da trilha, voc\u00ea j\u00e1 est\u00e1 preparado para fazer um projeto sozinho. Assim, diferentemente dos outros exerc\u00edcios, deixaremos o desafio para voc\u00ea estruturar o seu pr\u00f3prio c\u00f3digo e modelo. Caso tenha dificuldade ou n\u00e3o saiba por onde come\u00e7ar, te recomendamos consultar os exemplos feitos ao longo das aulas para aplicar no exerc\u00edcio, e sinta-se livre para mandar suas d\u00favidas no grupo.\n\nBom, agora \u00e9 com voc\u00ea!","23228e90":"A contagem de vendas semanais \u00e9 fechada sempre na sexta-feira (5\u00ba dia \u00fatil da semana). Portanto, o dia das datas n\u00e3o nos traz informa\u00e7\u00e3o \u00fatil. Cabe manter no dataset somentre o ano e a semana de cada registro.","4cb672b8":"Em todas as features de promo\u00e7\u00e3o, h\u00e1 mais de 60% de registros nulos. \n\nConforme consta na descri\u00e7\u00e3o do dataset do Kaggle, os registros s\u00f3 est\u00e3o dispon\u00edveis a partir de Nov 2011 e n\u00e3o n\u00e3o est\u00e3o dispon\u00edveis para todas as lojas a todo momento.","25b40d51":"#### Explora\u00e7\u00e3o dos dados","768e0b4a":"#### Limpeza dos dados","707ee836":"#### GridSearch","c0a70ced":"## Exerc\u00edcio 2: Separa\u00e7\u00e3o dos conjuntos de treino e teste","89acacf0":"## Submission","9dfea54d":"Claramente estamos com overfit, pois, ao utilizar diferentes dados para valida\u00e7\u00e3o, obtivemos um resultado consideravelmente pior: $R^2$ caiu de 0.945 para 0.915.\n\nPortanto, cabe uma investiga\u00e7\u00e3o dos melhores hiperpar\u00e2metros com o GridSearch.","6f8c604d":"Os registros v\u00e3o de 05\/fev\/2010 at\u00e9 01\/nov\/2012, com frequ\u00eancia semanal. Como uma datetime n\u00e3o diz muita coisa para o modelo, devemos converter a Date para algum formato \u00fatil.","1dc41a17":"#### Hiperpar\u00e2metros padr\u00e3o","3897cd43":"#### Cross Validation: Expanding Windows","8acf651f":"##### Quantidade de amostras por departamento e loja\n* Em uma mesma loja, os departamentos tem n\u00fameros de amostras bem diferentes: enquanto alguns departamentos tem mais de 100 amostras, outros tem apenas 3.\n* Em um mesmo departamento de lojas diferentes, tamb\u00e9m n\u00e3o h\u00e1 uma regularidade no n\u00famero de amostras: o departamento 96 da loja 1 tem cerca de 80, enquanto o mesmo departamento da loja 45 tem exatas 2 amostras. ","139d6cc5":"Como temos uma vari\u00e1vel categ\u00f3rica multiclasse, a Type, devemos criar vari\u00e1veis dummy para cada categoria, visando utiliz\u00e1-las no Random Forest.","cd332165":"<a href=\"https:\/\/colab.research.google.com\/github\/wesleydecezere\/programa_ds_fc\/blob\/master\/Entrega%206%20-%20S%C3%A9ries%20Temporais\/Series_Temporais_Exercicio.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>","c01b3645":"\n\n##### Ordena\u00e7\u00e3o temporal das amostras (data como \u00edndice)","714cebda":"### Cria\u00e7\u00e3o de features\n\n","67d5a884":"##### Caracter\u00edsticas iguais nos departamentos\n\nEm uma mesma data, todos os departamentos de uma mesma loja apresentam as mesmas caracter\u00edsticas (inclusive as de promo\u00e7\u00e3o, MarkDown1-5).\n","63e0bdcf":"A vari\u00e1vel `Date` \u00e9 do tipo `object`. Portanto, cabe convert\u00ea-la para `datetime`","651f6f98":"Anteriormente, na valida\u00e7\u00e3o cruzada com os melhores hiperpar\u00e2metros do GridSearch, obtivemos $R^2$ m\u00e9dio de 0,993 e 0,919 nos sets de treino e valida\u00e7\u00e3o, respectivamente. Estes valores formam um pouco melhores que os obtidos com os hiperpar\u00e2metros padr\u00e3o.\n\nAgora, para o dataset de treino, conseguimos resultados muito bons: $R^2$ de 0,965 e MAE de 2056,159, a qual tinha ficado em 2420.472 para o modelo com hiperpar\u00e2metros padr\u00e3o e sem valida\u00e7\u00e3o cruzada.","0150bc21":"## Exerc\u00edcio 1: Pr\u00e9-processamento de dados e cria\u00e7\u00e3o de Features\n\n","a6c91654":"## Exerc\u00edcio 3: Constru\u00e7\u00e3o do modelo e an\u00e1lise dos resultados","f78643da":"#### Informa\u00e7\u00e3o temporal","51780345":"Na sequ\u00eancia, fazemos o split de treino e teste, sem embaralhar as amostras.","348e19a8":"Portanto, dado uma data qualquer, nenhuma das caracter\u00edsticas dispon\u00edveis influencia realmente o n\u00famero de vendas semanais entre os departamentos de uma mesma loja. Nesta data, essas caracter\u00edsticas podem influenciar somentes o volume de vendas entre lojas diferentes, mas n\u00e3o necessariamente. \n\nIsso me leva a pensar que nenhuma das caracter\u00edsticas \u00e9 boa para auxiliar na previs\u00e3o de vendas semanais entre os departamentos de uma mesma loja. Algumas podem ser \u00fateis, contudo, para avaliar as vendas entre departamentos de lojas diferentes.","2c9659cc":"Ap\u00f3s alguns longos GridSearch, constata-se que os melhores hiperpar\u00e2metros s\u00e3o:\n* `n_estimators`: 50\n* `max_depth`: None\n* `min_samples_split`: 4\n* `min_samples_leaf`: 1 \n* `max_features`: 14\n\nPor isso, vamos treinar o modelo com a combina\u00e7\u00e3o encontrada.\n","afbf5393":"##### Tratamento de nulos","06d6772d":"#### Resultados","c0410bf8":"# <center>S\u00e9ries temporais - Exerc\u00edcio<\/center>\n___","77353b85":"No gr\u00e1fico de feature importance, percebemos que a vari\u00e1vel Dept teve uma import\u00e2ncia ligeiramente maior, enquanto a Size teve import\u00e2ncia ligeiramente menor, em rela\u00e7\u00e3o ao modelo com hiperpar\u00e2metros padr\u00e3o. Mesmo assim, ambas ainda foram as vari\u00e1veis mais importantes para a decis\u00e3o.","ea8e5335":"Por fim, definimos uma Expanding Windows para utiliza\u00e7\u00e3o na valida\u00e7\u00e3o cruzada.","da1af567":"Primeiramente, temos que separar o target das features.","800e82b6":"Valor padr\u00e3o dos hiperpar\u00e2metros selecionados\n* `n_estimators`: 100\n* `max_depth`: None\n* `min_samples_split`: 2\n* `min_samples_leaf`: 1 \n* `max_features`: 'auto'"}}