{"cell_type":{"70b8c2ed":"code","4515d5ee":"code","3ab4c204":"code","4497d88b":"code","e6e33872":"code","22c868aa":"code","a081a140":"code","b7393b04":"code","4ff0a487":"code","80b2d844":"code","e46d986d":"code","1343e7f9":"code","1a1519b0":"code","de1093f0":"code","103d660a":"code","38be465e":"code","5d4e24a8":"code","afa3d25a":"code","53a61a4d":"code","44a0bdbe":"code","713dc876":"code","34f2b85d":"code","7c204813":"code","076cbeb7":"code","576b5440":"code","ce767b99":"code","91ce758f":"code","8961669b":"code","0279b803":"code","d91c9a94":"code","e7721416":"markdown","782ff667":"markdown","de0165d4":"markdown","e2685d8e":"markdown","fdf62754":"markdown","ae605d1b":"markdown","f9fc6e18":"markdown","319299ae":"markdown","29d721f8":"markdown","a759040d":"markdown","273f6725":"markdown","f70e443c":"markdown","5e30e7e3":"markdown","87c192da":"markdown","150ccc2b":"markdown","53560abf":"markdown","577f2a92":"markdown","96b44a0f":"markdown","60a2de7c":"markdown","79d88027":"markdown","1d21e460":"markdown","98d1edee":"markdown","b64f1229":"markdown","3008e0bc":"markdown","96e218c8":"markdown","26352e2c":"markdown","ef98ddf6":"markdown","40a0f1af":"markdown","21edac1f":"markdown"},"source":{"70b8c2ed":"!pip install evalml","4515d5ee":"import evalml\nfrom evalml.pipelines import BinaryClassificationPipeline\n\nX,y = evalml.demos.load_breast_cancer()\n\npipeline = BinaryClassificationPipeline([\"Simple Imputer\", \"Random Forest Classifier\"])\npipeline.fit(X,y)\n\nprint(pipeline.score(X,y, objectives = ['log loss binary']))","3ab4c204":"pipeline.feature_importance","4497d88b":"pipeline.graph_feature_importance()","e6e33872":"from evalml.model_understanding import calculate_permutation_importance\ncalculate_permutation_importance(pipeline, X, y, \"log loss binary\")","22c868aa":"from evalml.model_understanding import graph_permutation_importance\ngraph_permutation_importance(pipeline, X, y, 'log loss binary')","a081a140":"from evalml.model_understanding.graphs import partial_dependence\npartial_dependence(pipeline, X, features='mean radius')","b7393b04":"from evalml.model_understanding.graphs import graph_partial_dependence\ngraph_partial_dependence(pipeline, X, features='mean radius')","4ff0a487":"X_fraud, y_fraud = evalml.demos.load_fraud(100, verbose=False)\nX_fraud.ww.init(logical_types={\"provider\": \"Categorical\", 'region': \"Categorical\"})\nfraud_pipeline = BinaryClassificationPipeline([\"DateTime Featurization Component\",\"One Hot Encoder\", \"Random Forest Classifier\"])\nfraud_pipeline.fit(X_fraud, y_fraud)\n\ngraph_partial_dependence(fraud_pipeline, X_fraud, features='provider')","80b2d844":"partial_dependence(pipeline, X, features=('worst perimeter', 'worst radius'), grid_resolution=10)","e46d986d":"graph_partial_dependence(pipeline, X, features=('worst perimeter', 'worst radius'), grid_resolution=10)\n","1343e7f9":"from evalml.model_understanding.graphs import confusion_matrix\ny_pred = pipeline.predict(X)\nconfusion_matrix(y, y_pred)","1a1519b0":"from evalml.model_understanding.graphs import graph_confusion_matrix\ny_pred = pipeline.predict(X)\ngraph_confusion_matrix(y, y_pred)\n","de1093f0":"from evalml.model_understanding.graphs import graph_precision_recall_curve\n# get the predicted probabilities associated with the \"true\" label\nimport woodwork as ww\ny_encoded = y.ww.map({'benign': 0, 'malignant': 1})\ny_pred_proba = pipeline.predict_proba(X)[\"malignant\"]\ngraph_precision_recall_curve(y_encoded, y_pred_proba)","103d660a":"from evalml.model_understanding.graphs import graph_roc_curve\n# get the predicted probabilities associated with the \"malignant\" label\ny_pred_proba = pipeline.predict_proba(X)[\"malignant\"]\ngraph_roc_curve(y_encoded, y_pred_proba)","38be465e":"from evalml.model_understanding.graphs import graph_roc_curve\n# get the predicted probabilities associated with the \"malignant\" label\ny_pred_proba = pipeline.predict_proba(X)[\"malignant\"]\ngraph_roc_curve(y_encoded, y_pred_proba)","5d4e24a8":"from evalml.pipelines import MulticlassClassificationPipeline\nX_multi, y_multi = evalml.demos.load_wine()\n\npipeline_multi = MulticlassClassificationPipeline(['Simple Imputer', 'Random Forest Classifier'])\npipeline_multi.fit(X_multi, y_multi)\n\ny_pred_proba = pipeline_multi.predict_proba(X_multi)\ngraph_roc_curve(y_multi, y_pred_proba)","afa3d25a":"from evalml.model_understanding.graphs import binary_objective_vs_threshold\nbinary_objective_vs_threshold(pipeline, X, y, 'f1', steps=100)","53a61a4d":"from evalml.model_understanding.graphs import graph_binary_objective_vs_threshold\ngraph_binary_objective_vs_threshold(pipeline, X, y, 'f1', steps=100)","44a0bdbe":"from evalml.model_understanding.graphs import graph_prediction_vs_actual\nfrom evalml.pipelines import RegressionPipeline\n\nX_regress, y_regress = evalml.demos.load_diabetes()\nX_train, X_test, y_train, y_test = evalml.preprocessing.split_data(X_regress, y_regress, problem_type='regression')\n\npipeline_regress = RegressionPipeline(['One Hot Encoder', 'Linear Regressor'])\npipeline_regress.fit(X_train, y_train)\n\ny_pred = pipeline_regress.predict(X_test)\ngraph_prediction_vs_actual(y_test, y_pred, outlier_threshold=50)","713dc876":"pipeline_dt = BinaryClassificationPipeline(['Simple Imputer', 'Decision Tree Classifier'])\npipeline_dt.fit(X, y)","34f2b85d":"from evalml.model_understanding.graphs import visualize_decision_tree\n\nvisualize_decision_tree(pipeline_dt.estimator, max_depth=2, rotate=False, filled=True, filepath=None)","7c204813":"from evalml.model_understanding.prediction_explanations import explain_predictions\n\ntable = explain_predictions(pipeline=pipeline, input_features=X, y=None, indices_to_explain=[3],\n                           top_k_features=6, include_shap_values=True)\nprint(table)","076cbeb7":"from evalml.model_understanding.prediction_explanations import explain_predictions\n\nreport = explain_predictions(pipeline=pipeline, input_features=X, y=y, indices_to_explain=[0, 4, 9], include_shap_values=True,\n                            output_format='text')\nprint(report)","576b5440":"from evalml.model_understanding.prediction_explanations import explain_predictions_best_worst\n\nreport = explain_predictions_best_worst(pipeline=pipeline, input_features=X, y_true=y,\n                                        include_shap_values=True, top_k_features=6, num_to_explain=2)\n\nprint(report)","ce767b99":"import numpy as np\n\ndef hinge_loss(y_true, y_pred_proba):\n\n    probabilities = np.clip(y_pred_proba.iloc[:, 1], 0.001, 0.999)\n    y_true[y_true == 0] = -1\n\n    return np.clip(1 - y_true * np.log(probabilities \/ (1 - probabilities)), a_min=0, a_max=None)\n\nreport = explain_predictions_best_worst(pipeline=pipeline, input_features=X, y_true=y,\n                                        include_shap_values=True, num_to_explain=5, metric=hinge_loss)\n\nprint(report)","91ce758f":"import json\nsingle_prediction_report = explain_predictions(pipeline=pipeline, input_features=X, indices_to_explain=[3],\n                                              y=y, top_k_features=6, include_shap_values=True,\n                                              output_format=\"dict\")\nprint(json.dumps(single_prediction_report, indent=2))\n","8961669b":"single_prediction_report = explain_predictions(pipeline=pipeline, input_features=X, indices_to_explain=[3],\n                                              y=y, top_k_features=6, include_shap_values=True,\n                                              output_format=\"dataframe\")\nsingle_prediction_report","0279b803":"report = explain_predictions_best_worst(pipeline=pipeline, input_features=X, y_true=y,\n                                        num_to_explain=1, top_k_features=6,\n                                        include_shap_values=True, output_format=\"dict\")\nprint(json.dumps(report, indent=2))","d91c9a94":"report = explain_predictions_best_worst(pipeline=pipeline, input_features=X, y_true=y,\n                                        num_to_explain=1, top_k_features=6,\n                                        include_shap_values=True, output_format=\"dataframe\")\nreport","e7721416":"# Graphing Utilities\nFirst, let\u2019s train a pipeline on some data.","782ff667":"# Permutation Importance\nWe can also compute and plot [the permutation importanc](http:\/\/scikit-learn.org\/stable\/modules\/permutation_importance.html)e of the pipeline.","de0165d4":"# Explaining Best and Worst Predictions\nWhen debugging machine learning models, it is often useful to analyze the best and worst predictions the model made. [The explain_predictions_best_worst function](https:\/\/evalml.alteryx.com\/en\/stable\/generated\/evalml.model_understanding.prediction_explanations.explain_predictions_best_worst.html) can help us with this.\n\nThis function will display the output of [explain_predictions](https:\/\/evalml.alteryx.com\/en\/stable\/generated\/evalml.model_understanding.prediction_explanations.explain_predictions.html) for the best 2 and worst 2 predictions. By default, the best and worst predictions are determined by the absolute error for regression problems and cross entropy for classification problems.\n\nWe can specify our own ranking function by passing in a function to the metric parameter. This function will be called on y_true and y_pred. By convention, lower scores are better.\n\nAt the top of each table, we can see the predicted probabilities, target value, error, and row index for that prediction. For a regression problem, we would see the predicted value instead of predicted probabilities.","e2685d8e":"#### The ROC curve can also be generated for multiclass classification problems. For multiclass problems, the graph will show a one-vs-many ROC curve for each class","fdf62754":"The interpretation of the table is the same for regression problems - but the SHAP value now corresponds to the change in the estimated value of the dependent variable rather than a change in probability. For multiclass classification problems, a table will be output for each possible class.\n\nBelow is an example of how you would explain three predictions with explain_predictions.","ae605d1b":"### Now let\u2019s train a decision tree on some data.\n\n","f9fc6e18":"# Welcome to this Notebook Tutorial for EvalML\/Model Understanding: \n# This Notebook Contains:\n* Graphing Utilities\n* Feature Importance\n* Permutation Importance\n* Partial Dependence Plots\n* Confusion Matrix\n* Precision-Recall Curve\n* ROC Curve\n* Binary Objective Score vs. Threshold Graph\n* Predicted Vs Actual Values Graph for Regression Problems\n* Tree Visualization\n* Explaining Predictions\n* Explaining Best and Worst Predictions\n* Changing Output Formats\n* Single prediction as a dictionary\n* Single prediction as a dataframe\n* Best and worst predictions as a dictionary\n* Best and worst predictions as a dataframe","319299ae":"# Model Understanding\nSimply examining a model\u2019s performance metrics is not enough to select a model and promote it for use in a production setting. While developing an ML algorithm, it is important to understand how the model behaves on the data, to examine the key factors influencing its predictions and to consider where it may be deficient. Determination of what \u201csuccess\u201d may mean for an ML project depends first and foremost on the user\u2019s domain expertise.\n\nEvalML includes a variety of tools for understanding models, from graphing utilities to methods for explaining predictions.","29d721f8":"[Some binary classification objectives](https:\/\/evalml.alteryx.com\/en\/stable\/user_guide\/objectives.html) (objectives that have score_needs_proba set to False) are sensitive to a decision threshold. For those objectives, we can obtain and graph the scores for thresholds from zero to one, calculated at evenly-spaced intervals determined by steps.","a759040d":"# Tree Visualization\n### We can visualize the structure of the Decision Tree that was fit to that data, and save it if necessary.","273f6725":"# Precision-Recall Curve\nFor binary classification, we can view the precision-recall curve of the pipeline.","f70e443c":"# Binary Objective Score vs. Threshold Graph","5e30e7e3":"# Confusion Matrix\nFor binary or multiclass classification, we can view a confusion matrix of the classifier\u2019s predictions. In the DataFrame output of confusion_matrix(), the column header represents the predicted labels while row header represents the actual labels.","87c192da":"# Changing Output Formats","150ccc2b":"* We can also create a bar plot of the feature importances","53560abf":"We use a custom metric ([hinge loss](https:\/\/en.wikipedia.org\/wiki\/Hinge_loss)) for selecting the best and worst predictions. See this example:\n","577f2a92":"# Best and worst predictions as a dictionary\n","96b44a0f":"Instead of getting the prediction explanations as text, you can get the report as a python dictionary or pandas dataframe. All you have to do is pass output_format=\"dict\" or output_format=\"dataframe\" to either explain_prediction, explain_predictions, or explain_predictions_best_worst.","60a2de7c":"# Best and worst predictions as a dataframe\n","79d88027":"### I hope you enjoy reading my notebook\n* Reference: [EvalML](https:\/\/github.com\/alteryx\/evalml) is an AutoML library which builds, optimizes, and evaluates machine learning pipelines using domain-specific objective functions.","1d21e460":"### You can also compute the partial dependence for a categorical feature. We will demonstrate this on the fraud dataset.","98d1edee":"# ROC Curve\n* For binary and multiclass classification, we can view the Receiver Operating Characteristic (ROC) curve of the pipeline.","b64f1229":"# Explaining Predictions\nWe can explain why the model made certain predictions with the [explain_predictions](https:\/\/evalml.alteryx.com\/en\/stable\/generated\/evalml.model_understanding.prediction_explanations.explain_predictions.html) function. This will use the [Shapley Additive Explanations (SHAP)](https:\/\/github.com\/slundberg\/shap) algorithm to identify the top features that explain the predicted value.\n\nThis function can explain both classification and regression models - all you need to do is provide the pipeline, the input features, and a list of rows corresponding to the indices of the input features you want to explain. The function will return a table that you can print summarizing the top 3 most positive and negative contributing features to the predicted value.\n\nIn the example below, we explain the prediction for the third data point in the data set. We see that the worst concave points feature increased the estimated probability that the tumor is malignant by 20% while the worst radius feature decreased the probability the tumor is malignant by 5%.","3008e0bc":"# Predicted Vs Actual Values Graph for Regression Problems\nWe can also create a scatterplot comparing predicted vs actual values for regression problems. We can specify an outlier_threshold to color values differently if the absolute difference between the actual and predicted values are outside of a given threshold.","96e218c8":"##### Two-way partial dependence plots are also possible and invoke the same API.\n\n","26352e2c":"# Feature Importance\nWe can get the importance associated with each feature of the resulting pipeline","ef98ddf6":"# Single prediction as a dictionary\n","40a0f1af":"# Partial Dependence Plots\n* We can calculate the one-way [partial dependence plots](http:\/\/christophm.github.io\/interpretable-ml-book\/pdp.html) for a feature.","21edac1f":"# Single prediction as a dataframe\n"}}