{"cell_type":{"fd2518d4":"code","34de927a":"code","bed3bdc9":"code","b4c097ea":"code","3d90bf3c":"code","128a7f3f":"code","b9e6162e":"code","ef3ac63d":"code","1071d640":"code","7efdd3c5":"code","d1b0a2f9":"code","2b4c873e":"code","8d296aec":"code","edca2687":"code","a2495551":"code","2d6afef1":"code","75062114":"code","b1c35670":"code","e55e506e":"code","f1b4ab7a":"code","a331fb77":"code","5b4a1e7c":"markdown"},"source":{"fd2518d4":"import numpy as np\nimport librosa as lb\nimport librosa.display as lbd\nimport soundfile as sf\nfrom  soundfile import SoundFile\nimport pandas as pd\nfrom  IPython.display import Audio\nfrom pathlib import Path\n\nfrom matplotlib import pyplot as plt\n\nfrom tqdm.notebook import tqdm\nimport joblib, json\n\nfrom  sklearn.model_selection  import StratifiedKFold","34de927a":"PART_ID = 0 # The start index in the below list, by changing it you will compute mels on another subset\nPART_INDEXES = [0,15718, 31436, 47154, 62874] # The train_set is splitted into 4 subsets","bed3bdc9":"SR = 32_000\nDURATION = 7 \nSEED = 666\n\nDATA_ROOT = Path(\"..\/input\/birdclef-2021\")\nTRAIN_AUDIO_ROOT = Path(\"..\/input\/birdclef-2021\/train_short_audio\")\nTRAIN_AUDIO_IMAGES_SAVE_ROOT = Path(\"audio_images\") # Where to save the mels images\nTRAIN_AUDIO_IMAGES_SAVE_ROOT.mkdir(exist_ok=True, parents=True)","b4c097ea":"def get_audio_info(filepath):\n    \"\"\"Get some properties from  an audio file\"\"\"\n    with SoundFile(filepath) as f:\n        sr = f.samplerate\n        frames = f.frames\n        duration = float(frames)\/sr\n    return {\"frames\": frames, \"sr\": sr, \"duration\": duration}","3d90bf3c":"PART_ID+1","128a7f3f":"import os","b9e6162e":"def make_df(n_splits=5, seed=SEED, nrows=None):\n    \n    df = pd.read_csv(DATA_ROOT\/\"train_metadata.csv\", nrows=nrows)\n\n    LABEL_IDS = {label: label_id for label_id,label in enumerate(sorted(df[\"primary_label\"].unique()))}\n    \n    df = df.iloc[0:15718]\n\n    df[\"label_id\"] = df[\"primary_label\"].map(LABEL_IDS)\n\n    df[\"filepath\"] =[str(TRAIN_AUDIO_ROOT\/primary_label\/filename) for primary_label,filename in zip(df.primary_label, df.filename) ]\n\n    pool = joblib.Parallel(4)\n    mapper = joblib.delayed(get_audio_info)\n    tasks = [mapper(filepath) for filepath in df.filepath]\n\n    df = pd.concat([df, pd.DataFrame(pool(tqdm(tasks)))], axis=1, sort=False)\n    \n    skf = StratifiedKFold(n_splits=n_splits, random_state=seed, shuffle=True)\n    splits = skf.split(np.arange(len(df)), y=df.label_id.values)\n    df[\"fold\"] = -1\n\n    for fold, (train_set, val_set) in enumerate(splits):\n        \n        df.loc[df.index[val_set], \"fold\"] = fold\n\n    return LABEL_IDS, df","ef3ac63d":"_,df2 = make_df(nrows=None)","1071d640":"df=pd.read_csv(\"..\/input\/train-meta-2\/gandfaatgaya.csv\")\ndf=df[0:15718]","7efdd3c5":"df2['Cluster_point']=df['Cluster_point']\ndf=df2\npath1='..\/input\/240255-noise-signal\/noise1'\npath2='..\/input\/3060-signal-noise\/noise1'\npath3='..\/input\/120135signalandnoise\/noise1'\npath4='..\/input\/135150signalandnoise\/noise1'\npath5='..\/input\/150180-signal-and-noise\/noise1'\npath6='..\/input\/180210-signal-and-noise\/noise1'\npath7='..\/input\/210240signalandnoise\/noise1'\npath8='..\/input\/255270noisesignal\/noise1'\npath9='..\/input\/270300-signal-and-noise\/noise1'\npath10='..\/input\/300330-signal-and-noise\/noise1'\npath11='..\/input\/360397signalandnoise\/noise1'\npath12='..\/input\/6090-signal-and-noise\/noise1'\npath13='..\/input\/90120-signal-noise\/noise1'\npath14='..\/input\/signals-and-noise-part-1\/noise1'\npath15='..\/input\/330345signalandnoise\/noise1'\npath16='..\/input\/345360signalandnoise\/noise1'\n\nnoise=[]\n\npaths=[path1,path2,path3,path4,path5,path6,path7,path8,path9,path10,path11,path12,path13,path14,path15,path16]\n\nfor j in range(len(df)):\n    c=0\n    for path in paths:\n        for i in os.listdir(path):\n            #print(df['primary_label'][j])\n            if(df['primary_label'][j]==i):\n                #print(os.listdir(path+'\/'+i))\n                for x in os.listdir(path+'\/'+i):\n                    if(df['filename'][j][:-4]==x[:-4]):\n                        noise.append(path+'\/'+i+'\/'+x)\n                        #print('ok2')\n                        c=1\n                        break\n            if(c==1):\n                break\n        if(c==1):\n            break\n\ndf['noise filepath'] = noise\n\nnoise_cluster=[]\nfor i in df['Cluster_point'].unique():\n    noise_cluster.append(df['noise filepath'][np.where(df['Cluster_point']==i)[0]])\n\nnoise_cluster_final=[]\nfor i in df['Cluster_point']:\n    noise_cluster_final.append(noise_cluster[i])\n    \ndf['final_noise']=noise_cluster_final","d1b0a2f9":"len(noise)","2b4c873e":"df.head()","8d296aec":"class MelSpecComputer:\n    def __init__(self, sr, n_mels, fmin, fmax, **kwargs):\n        self.sr = sr\n        self.n_mels = n_mels\n        self.fmin = fmin\n        self.fmax = fmax\n        kwargs[\"n_fft\"] = kwargs.get(\"n_fft\", self.sr\/\/10)\n        kwargs[\"hop_length\"] = kwargs.get(\"hop_length\", self.sr\/\/(10*4))\n        self.kwargs = kwargs\n\n    def __call__(self, y):\n\n        melspec = lb.feature.melspectrogram(\n            y, sr=self.sr, n_mels=self.n_mels, fmin=self.fmin, fmax=self.fmax, **self.kwargs,\n        )\n\n        melspec = lb.power_to_db(melspec).astype(np.float32)\n        return melspec","edca2687":"def mono_to_color(X, eps=1e-6, mean=None, std=None):\n    mean = mean or X.mean()\n    std = std or X.std()\n    X = (X - mean) \/ (std + eps)\n    \n    _min, _max = X.min(), X.max()\n\n    if (_max - _min) > eps:\n        V = np.clip(X, _min, _max)\n        V = 255 * (V - _min) \/ (_max - _min)\n        V = V.astype(np.uint8)\n    else:\n        V = np.zeros_like(X, dtype=np.uint8)\n\n    return V\n\ndef crop_or_pad(y, length, is_train=True, start=None):\n    if len(y) < length:\n        y = np.concatenate([y, np.zeros(length - len(y))])\n        \n        n_repeats = length \/\/ len(y)\n        epsilon = length % len(y)\n        \n        y = np.concatenate([y]*n_repeats + [y[:epsilon]])\n        \n    elif len(y) > length:\n        if not is_train:\n            start = start or 0\n        else:\n            start = start or np.random.randint(len(y) - length)\n\n        y = y[start:start + length]\n\n    return y","a2495551":"class AudioToImage:\n    def __init__(self, sr=SR, n_mels=128, fmin=0, fmax=None, duration=DURATION, step=None, res_type=\"kaiser_fast\", resample=True):\n\n        self.sr = sr\n        self.n_mels = n_mels\n        self.fmin = fmin\n        self.fmax = fmax or self.sr\/\/2\n\n        self.duration = duration\n        self.audio_length = self.duration*self.sr\n        self.step = step or self.audio_length\n        \n        self.res_type = res_type\n        self.resample = resample\n\n        self.mel_spec_computer = MelSpecComputer(sr=self.sr, n_mels=self.n_mels, fmin=self.fmin,\n                                                 fmax=self.fmax)\n        \n    def audio_to_image(self, audio,row):\n        \n        audio=add_noise(audio,row.final_noise)\n        melspec = self.mel_spec_computer(audio)\n        #melspec=signal_noise_ratio(melspec)\n        image = mono_to_color(melspec)\n#         image = normalize(image, mean=None, std=None)\n        return image\n\n    def __call__(self, row, save=True):\n#       max_audio_duration = 10*self.duration\n#       init_audio_length = max_audio_duration*row.sr\n        \n#       start = 0 if row.duration <  max_audio_duration else np.random.randint(row.frames - init_audio_length)\n    \n      audio, orig_sr = sf.read(row.filepath, dtype=\"float32\")\n      #audio,_=signal_noise_split(audio)\n      if self.resample and orig_sr != self.sr:\n        audio = lb.resample(audio, orig_sr, self.sr, res_type=self.res_type)\n        \n      audios = [audio[i:i+self.audio_length] for i in range(0, max(1, len(audio) - self.audio_length + 1), self.step)]\n      audios[-1] = crop_or_pad(audios[-1] , length=self.audio_length)\n      images = [self.audio_to_image(audio,row) for audio in audios]\n      images = np.stack(images)\n        \n      if save:\n        path = TRAIN_AUDIO_IMAGES_SAVE_ROOT\/f\"{row.primary_label}\/{row.filename}.npy\"\n        path.parent.mkdir(exist_ok=True, parents=True)\n        np.save(str(path), images)\n      else:\n        return  row.filename, images","2d6afef1":"import os","75062114":"dur_frame = 7\nlen_frame = dur_frame * SR\nn_frame = len_frame \/\/ 512 + 1\nimport cv2","b1c35670":"from librosa.core import spectrum\nfrom scipy.ndimage.morphology import binary_dilation, binary_erosion\ndef signal_noise_split(audio):\n    S, _ = spectrum._spectrogram(y=audio, power=1.0, n_fft=2048, hop_length=512, win_length=2048)\n\n    col_median = np.median(S, axis=0, keepdims=True)\n    row_median = np.median(S, axis=1, keepdims=True)\n    S[S < row_median * 3] = 0.0\n    S[S < col_median * 3] = 0.0\n    S[S > 0] = 1\n\n    S = binary_erosion(S, structure=np.ones((4, 4)))\n    S = binary_dilation(S, structure=np.ones((4, 4)))\n\n    indicator = S.any(axis=0)\n    indicator = binary_dilation(indicator, structure=np.ones(4), iterations=2)\n\n    mask = np.repeat(indicator, 512)\n    mask = binary_dilation(mask, structure=np.ones(2048 - 512), origin=-(2048 -512)\/\/2)\n    mask = mask[:len(audio)]\n    signal = audio[mask]\n    noise = audio[~mask]\n    return signal,noise\ndef add_noise(signal,i,n=4):\n    \n    p_noise = np.random.uniform(0, 1, n)\n    i_noise = np.where(p_noise > 0.5)[0]\n    alpha_noise = np.random.uniform(0, 0.5, n)\n    path_noise = np.random.choice(i, n)\n    for i in i_noise:\n        noise, _ = lb.load(path_noise[i], sr=SR, mono=True, duration=7*32000, res_type='kaiser_fast')\n        len_noise = len(noise)\n        \n        i_start = 0\n        if len_noise < len_frame:\n            i_start = np.random.randint(len_frame - len_noise)\n        print(signal[i_start: i_start + len_noise].shape)\n        print(alpha_noise[i].shape)\n        print(noise.shape)\n        signal[i_start: i_start + len_noise] += noise[:signal[i_start: i_start + len_noise].shape[0]] * alpha_noise[i]\n    return signal\ndef signal_noise_ratio(spec):\n      spec = spec.copy()\n\n      col_median = np.median(spec, axis=0, keepdims=True)\n      row_median = np.median(spec, axis=1, keepdims=True)\n\n      spec[spec < row_median * 1.25] = 0.0\n      spec[spec < col_median * 1.15] = 0.0\n      spec[spec > 0] = 1.0\n\n      spec = cv2.medianBlur(spec, 3)\n      spec = cv2.morphologyEx(spec, cv2.MORPH_CLOSE, np.ones((3, 3), np.float32))\n\n      spec_sum = spec.sum()\n      try:\n          snr = spec_sum \/ (spec.shape[0] * spec.shape[1] * spec.shape[2])\n      except:\n          snr = spec_sum \/ (spec.shape[0] * spec.shape[1])\n\n      return snr","e55e506e":"def get_audios_as_images(df):\n    pool = joblib.Parallel(2)\n    \n    converter = AudioToImage(step=int(DURATION*0.666*SR))\n    mapper = joblib.delayed(converter)\n    tasks = [mapper(row) for row in df.itertuples(False)]\n    \n    pool(tqdm(tasks))","f1b4ab7a":"int(DURATION)","a331fb77":"get_audios_as_images(df)","5b4a1e7c":"![tcs_1x](https:\/\/user-images.githubusercontent.com\/50532530\/121583499-f6fcfe80-ca4d-11eb-875f-c79d63fca3b5.jpeg)"}}