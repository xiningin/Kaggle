{"cell_type":{"9bbfb70f":"code","8da75a70":"code","ee36aeb4":"code","9f3b7e09":"code","756e94ba":"code","29337832":"code","3735e5f1":"code","89ee4ef1":"code","8ccc7afd":"code","795676f8":"code","c4973fa9":"code","96a32968":"code","5163619d":"code","5b972df2":"code","93f04718":"code","c94a817a":"code","d96eeddb":"code","632227af":"code","63a8d90e":"code","7db6bbec":"code","ce948e28":"code","be901702":"markdown","47ae5f37":"markdown","ab9b0502":"markdown","c95a855f":"markdown"},"source":{"9bbfb70f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport missingno\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import accuracy_score, log_loss, roc_auc_score, auc\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import roc_curve\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom scipy.stats import boxcox\nimport warnings\nimport wandb\nimport math\nfrom imblearn.combine import SMOTETomek\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nwarnings.filterwarnings(\"ignore\")\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8da75a70":"df = pd.read_csv(\"..\/input\/song-popularity-prediction\/train.csv\")\ndf.head()","ee36aeb4":"df.info()","9f3b7e09":"df.shape","756e94ba":"df.isna().sum()","29337832":"fig = px.bar(y=df.isna().sum().values, x= df.columns, color = df.columns, \n       hover_name = (df.isna().sum().values \/ df.shape[0] * 100),\n      title= \"Count and % of null values in each column\")\nfig.update_traces(showlegend=False)\nfig.show()","3735e5f1":"cols = list(df.columns)[1:]\ncols.remove(\"audio_mode\")\ncols.remove(\"song_popularity\")","89ee4ef1":"\"\"\"f, axs = plt.subplots(4,3, figsize=(20,20))\nk = 0\nfor i in range(4):\n    for j in range(3):\n        sns.histplot(ax = axs[i,j],data = df, x= cols[k], hue = 'song_popularity', \n                    stat = \"density\", kde = True)\n        k+=1\"\"\"","8ccc7afd":"g = sns.FacetGrid(df, col=\"song_popularity\", hue = \"audio_mode\",palette = \"rocket\")\ng.map(sns.scatterplot, \"liveness\", \"danceability\", alpha=.7)\ng.add_legend()","795676f8":"\"\"\"g = sns.PairGrid(df, vars=cols[:5], hue=\"song_popularity\", palette = \"Set2\")\ng.map_diag(sns.histplot)\ng.map_offdiag(sns.scatterplot)\ng.add_legend()\"\"\"","c4973fa9":"plt.figure(figsize=(20,20))\nsns.heatmap(df.corr(), annot = True)","96a32968":"px.bar(y = df.skew(axis = 0).values, x = df.columns, title = \"Visualizing skewness for each column\")","5163619d":"#wandb.login()","5b972df2":"import math\nsweep_config = {\n    \"method\": \"bayes\", # try grid or random\n    \"metric\": {\n      \"name\": \"roc_auc_score\",\n      \"goal\": \"maximize\"   \n    },\n    \"parameters\": {\n        \"booster\": {\n            \"values\": [\"gbtree\"]\n        },\n        \"max_depth\": {\n            \"values\": [2, 3, 4, 5, 6, 7, 8, 9]\n        },\n        \"learning_rate\": {\n            \"values\": [0.01, 0.05, 0.1, 0.02, 0.001, 0.005, 0.2]\n        },\n        \"subsample\": {\n            \"distribution\": \"uniform\",\n            \"min\": 0.3,\n            \"max\": 0.9,\n        },\n        \"n_estimators\": {\n            \"values\": [2500, 3000, 5000, 10000,15000, 20000]\n        },\n        \"reg_lambda\": {\n            \"distribution\": \"uniform\",\n            \"min\": 0,\n            \"max\": 50,\n            \n        },\n        \"reg_alpha\": {\n            \"distribution\": \"uniform\",\n            \"min\": 0,\n            \"max\": 50,\n            \n        },\n        \"colsample_bytree\":{\n            \"distribution\": \"uniform\",\n            \"min\": 0.2,\n            \"max\": 0.8,\n            \n        },\n        \"colsample_bylevel\":{\n            \"distribution\": \"uniform\",\n            \"min\": 0.2,\n            \"max\": 0.8,\n        \n        }\n        \n    }\n}\n#sweep_id = wandb.sweep(sweep_config, project=\"SPP-XGBoost2-sweeps\")","93f04718":"pipeline = Pipeline([\n    (\"impute\", IterativeImputer()),\n    (\"scale\", RobustScaler())\n])\nX = df.drop([\"song_popularity\", \"id\"], axis=1)\nx = pipeline.fit_transform(X)\ny = df[\"song_popularity\"]\ny.shape","c94a817a":"\ndef train():\n    config_defaults = {\n    \"booster\": \"gbtree\",\n    \"max_depth\": 9,\n    \"learning_rate\": 0.1,\n    \"subsample\": 1,\n    \"seed\": 117,\n    \"test_size\": 0.2,\n    }\n\n    wandb.init(config=config_defaults)  # defaults are over-ridden during the sweep\n    config = wandb.config\n\n    # load data and split into predictors and targets\n    \n    # split data into train and test sets\n    X_train, X_test, y_train, y_test = train_test_split(x, y,\n                                                      test_size=config.test_size,\n                                                      random_state=config.seed)\n    os = SMOTETomek(1)\n    X_train,y_train = os.fit_resample(X_train,y_train)\n    # fit model on train\n    model = XGBRegressor(booster=config.booster, max_depth=config.max_depth,\n                        learning_rate=config.learning_rate, subsample=config.subsample, \n                        gpu_id = 0, eval_metric=\"logloss\")\n    model.fit(X_train, y_train, eval_set=[(X_test,y_test)], \n              early_stopping_rounds=300, verbose=False)\n\n    # make predictions on test\n    predictions = model.predict(X_test)\n    \n    # evaluate predictions\n    logloss = log_loss(y_test, predictions)\n    rocauc_score = roc_auc_score(y_test, predictions)\n    print(\"Roc AUC score: \", rocauc_score)\n    wandb.log({\"roc_auc_score\": rocauc_score})\n    wandb.log({\"logloss\": logloss})\n","d96eeddb":"#wandb.agent(sweep_id, train, count=50)","632227af":"test_df = pd.read_csv(\"..\/input\/song-popularity-prediction\/test.csv\")\nxt = test_df.drop([\"id\"], axis=1)\ncols = xt.columns\nx = pd.DataFrame(columns = cols, data=pipeline.fit_transform(X))\nxt = pd.DataFrame(columns = cols, data=pipeline.fit_transform(xt))","63a8d90e":"##Obtained from WandB Sweeps\nparams = {'max_depth': 5,\n 'n_estimators': 15000,\n 'learning_rate': 0.1,\n 'subsample': 0.54,\n 'colsample_bytree': 0.7238,\n 'colsample_bylevel': 0.6279,\n #'min_child_weight': 0.281257758038499,\n 'reg_lambda': 24.285,\n 'reg_alpha': 29.734,}","7db6bbec":"SKfolds = StratifiedKFold(n_splits=10, shuffle = True,random_state = 10)\nvalid_preds,test_preds,scores = [],[],[]\nfor fold, (idx_train, idx_valid) in enumerate(SKfolds.split(x, y)):\n    x_train, y_train = x.iloc[idx_train], y.iloc[idx_train]\n    x_valid, y_valid = x.iloc[idx_valid], y.iloc[idx_valid]\n    os = SMOTETomek(1)\n    x_train,y_train = os.fit_resample(x_train,y_train)\n    model = XGBRegressor(**params, booster= 'gbtree',\n                        eval_metric = 'auc',\n                        random_state=fold, \n                        use_label_encoder=False)\n    \n    model.fit(x_train,y_train,\n            eval_set=[(x_valid,y_valid)],\n            early_stopping_rounds=300,\n            verbose=False)\n    \n    valid_pred = model.predict(x_valid)\n    valid_preds.append(valid_pred)\n\n    fpr, tpr, _ = roc_curve(y_valid, valid_pred)\n    score = auc(fpr, tpr)\n    scores.append(score)\n    \n    print(f\"Fold: {fold} Score: {score}\")\n    print('--'*25)\n    \n    test_pred = model.predict(xt)\n    test_preds.append(test_pred)\n    \nprint(f\"Final Validation Score : {np.mean(scores)}\")","ce948e28":"submission = pd.read_csv('..\/input\/song-popularity-prediction\/sample_submission.csv')\npredictions = np.mean(np.column_stack(test_preds),axis=1)\nsubmission['song_popularity'] = predictions\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()\n","be901702":"## Check Null values","47ae5f37":"**The distribution plots shows that the data in these columns is highly skewed.**","ab9b0502":"## Plotting column distributions and correlation matrix","c95a855f":"**Both scatter plots and correlation matrix shows there is little to no correlation between columns**  \nSkewness and missing values needs to be fixed to make this data usable for a model."}}