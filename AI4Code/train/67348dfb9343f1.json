{"cell_type":{"02924fbf":"code","f7235ab6":"code","170606d2":"code","23caecc5":"code","be489de1":"code","fc2fe9b8":"code","fb962602":"code","a5b67ed1":"code","699fc8f2":"code","2a1b4a70":"code","41c22b4e":"code","c0d5beb0":"code","d0d95b15":"code","ba061229":"code","ecb41d8e":"code","5459a976":"code","96daf126":"code","4e13f877":"code","bb13c76e":"code","d028d2d0":"code","cdd4cbf4":"code","9047276a":"code","960d6b7a":"code","d4ce9612":"code","14efd6c8":"code","a69956b6":"markdown","5cae7fee":"markdown","9239be75":"markdown","4ccb91dc":"markdown","6e7bb97e":"markdown","479d179f":"markdown","e529121b":"markdown","f852679f":"markdown","5b0eab22":"markdown","b878400d":"markdown","2aa660ca":"markdown","70798378":"markdown","91a31fed":"markdown","b8bd1412":"markdown","a7e38f38":"markdown"},"source":{"02924fbf":"import matplotlib.pyplot as plt\nimport numpy as np\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport pandas as pd\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import  ElasticNet, Lasso, LinearRegression, Ridge\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import GridSearchCV, KFold, train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\n\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\n\nimport time\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","f7235ab6":"house_price_raw = pd.read_csv('\/kaggle\/input\/house-price-tehran-iran\/housePrice.csv')\nprint(f\"Shape of dataset: {house_price_raw.shape}\")\nhouse_price_raw.head()","170606d2":"house_price_raw.info()","23caecc5":"house_price = house_price_raw.copy()\nhouse_price['Area'] = pd.to_numeric(house_price['Area'], errors='coerce')\nhouse_price.dropna(inplace = True)\nhouse_price.reset_index(drop = True, inplace = True)\nprint(f\"Shape of dataset after drop NaN values: {house_price.shape}\")\nprint(f\"Number of rows that deleted: {len(house_price_raw) - len(house_price)}\")","be489de1":"house_price_df = house_price.drop(columns = ['Price(USD)'])\nboolean_features = ['Parking','Warehouse','Elevator']\nhouse_price_df[boolean_features] = house_price_df[boolean_features].astype('int64')\n\nhouse_price_df.head()","fc2fe9b8":"print(f\"Skewness of features:\\n{house_price_df.skew()}\")","fb962602":"plt.figure(figsize = (16,8))\n\nplt.subplot(2,1,1)\nsns.boxplot(x = house_price_df['Area'])\n\nplt.subplot(2,1,2)\nsns.boxplot(x = house_price_df['Price'])","a5b67ed1":"def lower_upper(x):\n    Q1 = np.percentile(x, 25)\n    Q3 = np.percentile(x, 75)\n    IQR = Q3 - Q1\n    lower = Q1 - 1.5 * IQR\n    upper = Q3 + 1.5 * IQR\n    \n    return lower, upper\n\nlower_area, upper_area = lower_upper(house_price_df['Area'])\nlower_price, upper_price = lower_upper(house_price_df['Price'])\n\nprint(f\"Lower limit for area: {lower_area:0.2f}\")\nprint(f\"Upper limit for area: {upper_area:0.2f}\")\nprint(f\"Lower limit for price: {lower_price:,}\")\nprint(f\"Upper limit for price: {upper_price:,}\")","699fc8f2":"area_outliers = np.where(house_price_df['Area'] > upper_area)\nprice_outliers = np.where(house_price_df['Price'] > upper_price)\ntotal_outliers = np.union1d(area_outliers, price_outliers)\n\nprint(f\"Number of area outliers: {len(house_price_df.iloc[area_outliers])}\")\nprint(f\"Number of price outliers: {len(house_price_df.iloc[price_outliers])}\")\nprint(f\"Number of outliers: {len(house_price_df.iloc[total_outliers])}\")","2a1b4a70":"house_price = house_price_df.copy()\nhouse_price.drop(total_outliers, inplace = True)\nhouse_price.reset_index(drop = True, inplace = True)\nprint(f\"Shape of new dataset: {house_price.shape}\")","41c22b4e":"plt.figure(figsize = (16,8))\n\nplt.subplot(2,1,1)\nsns.boxplot(x = house_price['Area'])\n\nplt.subplot(2,1,2)\nsns.boxplot(x = house_price['Price'])","c0d5beb0":"print(f\"Skewness of features after drop outliers:\\n{house_price.skew()}\")","d0d95b15":"sns.pairplot(house_price, corner = True)","ba061229":"addres_dummy = pd.get_dummies(house_price['Address'])\nhouse_price_final = house_price.merge(addres_dummy, left_index = True, right_index = True)\nhouse_price_final.drop(columns = 'Address', inplace = True)\nhouse_price_final.head(3)","ecb41d8e":"X = house_price_final.drop(columns = 'Price')\ny = house_price_final['Price']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\nprint(f\"shape of x train: {X_train.shape}\")\nprint(f\"shape of y train: {y_train.shape}\")\nprint(f\"shape of x test: {X_test.shape}\")\nprint(f\"shape of y train: {y_test.shape}\")","5459a976":"def parameter_finder (model, parameters):\n    \n    start = time.time()\n    \n    grid = GridSearchCV(model, \n                        param_grid = parameters, \n                        refit = True, \n                        cv = KFold(shuffle = True, random_state = 1), \n                        n_jobs = -1)\n    grid_fit = grid.fit(X_train, y_train)\n    y_pred = grid_fit.predict(X_test)\n    \n    train_score = round(grid_fit.score(X_train, y_train), 4) \n    test_score = round(grid_fit.score(X_test, y_test), 4)\n    RMSE = round(np.sqrt(mean_squared_error(y_test, y_pred)))\n    \n    model_name = str(model).split('(')[0]\n    \n    end = time.time()\n    \n    print(f\"The best parameters for {model_name} model is: {grid_fit.best_params_}\")\n    print(\"--\" * 10)\n    print(f\"The coefficient of determination (R2 score) in the training set is {train_score:0.2%} for {model_name} model.\")\n    print(f\"The coefficient of determination (R2 score) in the testing set is {test_score:0.2%} for {model_name} model.\")\n    print(f\"RMSE is {RMSE:,} for {model_name} model.\")\n    print(\"--\" * 10)\n    print(f\"Runtime of the program is: {end - start:0.2f}\")\n    \n       \n    return train_score, test_score, RMSE","96daf126":"lr = LinearRegression(n_jobs = -1)\n\nlr_train_score, lr_test_score, lr_RMSE = parameter_finder(lr, {})","4e13f877":"ridge = Ridge(random_state = 1) # Linear least squares with l2 regularization.\nparam_ridge = {'alpha': [0.001, 0.01, 0.1, 1, 10]}\n\nridge_train_score, ridge_test_score, ridge_RMSE = parameter_finder(ridge, param_ridge)","bb13c76e":"lasso = Lasso(random_state = 1) # Linear Model trained with L1 prior as regularizer.\nparam_lasso = {'alpha': [0.001, 0.01, 0.1, 1, 10]}\n\nlasso_train_score, lasso_test_score, lasso_RMSE = parameter_finder(lasso, param_lasso)","d028d2d0":"eln = ElasticNet(random_state = 1) # Linear regression with combined L1 and L2 priors as regularizer.\nparam_eln = {'alpha': [0.001, 0.01, 0.1, 1, 10],\n            'l1_ratio': [0.3, 0.4, 0.5, 0.6, 0.7]}\n\neln_train_score, eln_test_score, eln_RMSE = parameter_finder(eln, param_eln)","cdd4cbf4":"dtr = DecisionTreeRegressor(random_state = 1)\nparam_dtr = {'min_samples_split': [2, 3, 4, 5],\n            'min_samples_leaf': [1, 2, 3]}\n\ndtr_train_score, dtr_test_score, dtr_RMSE = parameter_finder(dtr, param_dtr)","9047276a":"rfr = RandomForestRegressor(random_state = 1, n_jobs = -1)\nparam_rfr = {'min_samples_split': [2, 3, 4, 5],\n            'min_samples_leaf': [1, 2, 3]}\n\nrfr_train_score, rfr_test_score, rfr_RMSE = parameter_finder(rfr, param_rfr)","960d6b7a":"knr = KNeighborsRegressor(n_jobs = -1)\nparam_knr = {'n_neighbors': [5, 10, 15, 20],\n            'weights': ['uniform', 'distance']}\n\nknr_train_score, knr_test_score, knr_RMSE = parameter_finder(knr, param_knr)","d4ce9612":"models_score = pd.DataFrame({'Training score': [lr_train_score, ridge_train_score, lasso_train_score, eln_train_score, dtr_train_score, rfr_train_score, knr_train_score],\n                             'Testing score': [lr_test_score, ridge_test_score, lasso_test_score, eln_test_score, dtr_test_score, rfr_test_score, knr_test_score],\n                             'RMSE': [lr_RMSE, ridge_RMSE, lasso_RMSE, eln_RMSE, dtr_RMSE, rfr_RMSE, knr_RMSE]},\n                             index = ['LinearRegression', 'Ridge', 'Lasso','ElasticNet', 'DecisionTreeRegressor', 'RandomForestRegressor', 'KNeighborsRegressor'])\n\nmodels_score","14efd6c8":"fig, ax = plt.subplots(figsize=(20,10))\n\nsns.set(style='white')\n\nax.set_title(\"Camparison\", fontsize = 20)\n\nax = sns.barplot(x = list(models_score.index), y = models_score['RMSE']\/1000000000, alpha = 0.7, palette='Greens_r')\n\nax.set_ylabel(\"RMSE\\n(billion tomans)\", fontsize = 20)\n\nsec_ax = ax.twinx()\n\nsec_ax = sns.lineplot(x = list(models_score.index), y = models_score['Training score'], linewidth = 3, color = 'blue')\nsec_ax = sns.scatterplot(x = list(models_score.index), y = models_score['Training score'], s = 200)\n\nsec_ax = sns.lineplot(x = list(models_score.index), y = models_score['Testing score'], linewidth = 3, color = 'red')\nsec_ax = sns.scatterplot(x = list(models_score.index), y = models_score['Testing score'], s = 200)\n\nsec_ax.set_ylabel(\"R2 scores\", fontsize = 20)\n\nsec_ax.legend(labels = ['Training score', 'Testing score'], fontsize = 20)\n\n\nsns.despine(offset = 10)\n\nplt.show()","a69956b6":"# References <a id = \"6\"><\/a> ","5cae7fee":"# Conclusions <a id = \"5\"><\/a> ","9239be75":"<figure>\n    <figcaption>Cost Function for Lasso regression<\/figcaption>\n    <img src='https:\/\/miro.medium.com\/max\/618\/1*MzVvLRrsHNX6txA27U9k-Q.png' \/>\n<\/figure>","4ccb91dc":"Several machine learning algorithms make the assumption that the data follow a normal (or Gaussian) distribution. This is easy to check with the skewness value, which explains the extent to which the data is normally distributed. Ideally, the skewness value should be between -1 and +1, and any major deviation from this range indicates the presence of extreme values.(<a href = 'https:\/\/www.pluralsight.com\/guides\/cleaning-up-data-from-outliers#:~:text=Several%20machine%20learning,of%20extreme%20values.'> Cleaning up Data from Outliers on Pluralsight<\/a>)","6e7bb97e":"# Table of content:\n1. [Import Libraries](#1)\n2. [Reading Dataset](#2)\n3. [Data Pre-processing](#3)\n4. [Modeling](#4)\n5. [Conclusions](#5)\n6. [References](#6)","479d179f":"<figure>\n    <figcaption>Cost Function for Ridge regression<\/figcaption>\n    <img src='https:\/\/miro.medium.com\/max\/495\/1*v6EnnH1WkXJ01YLcK--qhA.png' \/>\n<\/figure>","e529121b":"# Import Libraries <a id = \"1\"><\/a> ","f852679f":"<figure>\n    <figcaption>Cost Function for linear regression<\/figcaption>\n    <img src='https:\/\/miro.medium.com\/max\/495\/1*v6EnnH1WkXJ01YLcK--qhA.png' \/>\n<\/figure>","5b0eab22":"<figure>\n    <figcaption>Cost Function for ElasticNet<\/figcaption>\n    <img src='https:\/\/miro.medium.com\/max\/700\/1*5qda942X54E4i9exXF3XmQ.png' \/>\n<\/figure>","b878400d":"<figure>\n    <figcaption>Ordinary regression compares to the Lasso, the Ridge and the Elastic Net Regressors<\/figcaption>\n    <img src='https:\/\/miro.medium.com\/max\/1400\/1*nrWncnoJ4V_BkzEf1pd4MA.png' \/>\n<\/figure>","2aa660ca":"<a href = \"https:\/\/towardsdatascience.com\/from-linear-regression-to-ridge-regression-the-lasso-and-the-elastic-net-4eaecaf5f7e6\">From Linear Regression to Ridge Regression, the Lasso, and the Elastic Net<\/a>","70798378":"# Modeling <a id = \"4\"><\/a> ","91a31fed":"As can be seen from the plot above, **linear regression** has the lowest RMSE and the highest R2 score in the test data.","b8bd1412":"# Reading Dataset <a id = \"2\"><\/a> \n<a href = 'https:\/\/www.kaggle.com\/mokar2001\/house-price-tehran-iran'>Link to the dataset in Kaggle.<\/a>\n- Area: Area in square meters\n- Room: Number of bedrooms\n- Parking: Has Parking or not\n- Warehouse: Has warehouse or not\n- Elevator: Has elevator or not\n- Address: The region where the house is placed.\n- Price: Price in Toman\n- Price(USD): Price in USD","a7e38f38":"# Data Pre-processing <a id = \"3\"><\/a> "}}