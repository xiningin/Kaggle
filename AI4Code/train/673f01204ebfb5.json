{"cell_type":{"1aadd7ce":"code","627def3e":"code","93fd22e3":"code","8b140b3b":"code","4eea88be":"code","da619bfb":"code","10f79d9a":"code","2b0984f4":"code","38e9796d":"code","91e3defe":"code","cd4109d4":"code","b38ced70":"code","2d0ed072":"code","bb04ed34":"code","92883bce":"code","e0ae7eb1":"code","1a757f10":"code","95c66ff5":"code","fed1b724":"code","2c89d2d4":"code","f3ce3533":"code","8068b1d3":"code","6cdc2acc":"code","1ba31743":"code","1e2eb5a0":"code","524e3609":"code","85c16488":"code","e16924cf":"code","4ff3b70e":"code","a6aac094":"code","09e1e737":"code","5cc82737":"code","9d0434ca":"code","e9c6b0cd":"code","fafd886d":"code","1512cac0":"code","016f9f88":"code","ae30265d":"code","d2a2ff44":"code","bc0ec5dd":"code","9f832610":"code","956b0e14":"code","7d6946c0":"markdown","5c674ecb":"markdown","222d3929":"markdown","f0fa5663":"markdown","1bdf64c7":"markdown","7ca87967":"markdown","2e60dfe1":"markdown","b11edee7":"markdown","74803845":"markdown","423959b7":"markdown","9d2c52fa":"markdown","c86932a6":"markdown"},"source":{"1aadd7ce":"#importing required Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nimport time\nimport seaborn as sns\nimport os\n\n#pytorch imports\nimport torch\nimport torchvision\nfrom torch.utils.data import DataLoader, Dataset, random_split\nimport torchvision.transforms as transforms\nfrom PIL import Image","627def3e":"train_data_directory = \"..\/input\/train\/train\"\ntest_data_directory = \"..\/input\/test\/test\"","93fd22e3":"#reading the train.csv file for basic data analysis\ntrain_csv_df = pd.read_csv(\"..\/input\/train.csv\")\ntrain_csv_df.head()","8b140b3b":"#dataset dimensions\ntrain_csv_df.shape","4eea88be":"#checking for missing values in the dataset\ntrain_csv_df.isna().sum()","da619bfb":"#checking the distribution of classes\ntrain_csv_df.has_cactus.value_counts()","10f79d9a":"#distribution of classes using seaborn plot\nplt.style.use(\"seaborn\")\ntrain_csv_df.has_cactus.value_counts().plot(kind = \"barh\")\nplt.ylabel(\"Classes\")\nplt.xlabel(\"Number of catus in each class\")\nplt.show()","2b0984f4":"#reading the test data set csv\ntest_data_df = pd.read_csv(\"..\/input\/sample_submission.csv\")","38e9796d":"test_data_df.head()","91e3defe":"#number of images in test data\ntest_data_df.shape","cd4109d4":"from sklearn.model_selection import train_test_split","b38ced70":"#split the train data csv into two parts using stratified sampling\ntrain_df, validation_df = train_test_split(train_csv_df, stratify=train_csv_df.has_cactus, test_size=0.2)","2d0ed072":"#shape of train data\ntrain_df.shape","bb04ed34":"#shape of validation data\nvalidation_df.shape","92883bce":"class AerialCatcusClassification(Dataset):\n    def __init__(self,file_data,root_dir,transform=None):\n        self.transform = transform\n        self.file_data = file_data.values\n        self.data_root = root_dir \n            \n    def __len__(self):\n        return len(self.file_data)\n    \n    def __getitem__(self, index):\n        img_name, label = self.file_data[index]\n        img_data = self.pil_loader(os.path.join(self.data_root, img_name))\n        #applying transforms if any specified\n        if self.transform:\n            img_data = self.transform(img_data)\n        return img_data, label\n          \n    def pil_loader(self,path):\n        #funtion to read the image and convet to RGB\n        with open(path, 'rb') as f:\n            img = Image.open(f)\n            return img.convert('RGB')","e0ae7eb1":"#read the train and validation data images\ntrain_data = AerialCatcusClassification(file_data=train_df, root_dir=train_data_directory, transform = transforms.Compose([transforms.ToTensor()]))\nvalidation_data = AerialCatcusClassification(file_data=validation_df, root_dir=train_data_directory, transform = transforms.Compose([transforms.ToTensor()]))\n\n#read the test data\ntest_data = AerialCatcusClassification(file_data=test_data_df, root_dir=test_data_directory,transform = transforms.Compose([transforms.ToTensor()]))","1a757f10":"#create a train and validation data loader\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=5, shuffle=True)\nvalidation_loader = torch.utils.data.DataLoader(validation_data, batch_size=5, shuffle=True)","95c66ff5":"#custom function to display images\n\ndef imshow(img, title):\n    \n    #convert image from tensor to numpy for visualization\n    npimg = img.numpy()\n    #define the size of a figure\n    plt.figure(figsize = (20, 20))\n    plt.axis(\"off\")\n    \n    #interchaging the image sizes - transposing\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.title(title, fontsize=15)\n    plt.show()","fed1b724":"#function to get images and feed into our custom function 'imshow'\n\ndef show_batch_images(dataloader):\n    \n    #getting the images\n    images, labels = next(iter(dataloader))\n    #make a grid from those images\n    img = torchvision.utils.make_grid(images)\n    \n    #call our custom function\n    imshow(img, title = [str(x.item()) for x in labels])","2c89d2d4":"#visualize the training data\n\nfor i in range(4):\n    show_batch_images(train_loader)","f3ce3533":"transform_train = transforms.Compose([\n    #cropping and resizing the image to 224*224\n    transforms.Resize(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(30),\n    #convert image to tensor\n    transforms.ToTensor(),\n    #normalizing the input mean = 0.5 and std = 0.5 for three channels (R,G,B)\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\n#define the same operations to test data\ntransform_test = transforms.Compose([\n    transforms.Resize(224),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])","8068b1d3":"#read the train and validation data images\ntrain_data = AerialCatcusClassification(file_data=train_df, root_dir=train_data_directory, transform = transform_train)\nvalidation_data = AerialCatcusClassification(file_data=validation_df, root_dir=train_data_directory, transform = transform_train)\n\n#read the test data\ntest_data = AerialCatcusClassification(file_data=test_data_df, root_dir=test_data_directory,transform = transform_test)","6cdc2acc":"#create a train and validation data loader\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=10, shuffle=True)\nvalidation_loader = torch.utils.data.DataLoader(validation_data, batch_size=10, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=10, shuffle=False)","1ba31743":"import torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import models\nimport copy","1e2eb5a0":"#number of classes in the data\nnum_classes = 2\ntraining_batchsize = 10","524e3609":"#create a data iterator\n\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\n\n#shape of images bunch\nprint(images.shape)\n\n#shape of first image in a group of 4\nprint(images[1].shape)\n\n#class label for first image\nprint(labels)","85c16488":"#checking for available gpu\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","e16924cf":"#download the vgg19 model pretrained on imagenet data\nvgg = models.vgg19_bn(pretrained = True)","4ff3b70e":"#number of trainable parameters in vgg19 - before freezing\nprint(\"Number of trainable parameters: \", sum(p.numel() for p in vgg.parameters() if p.requires_grad))","a6aac094":"#Let's print the names of the layer stacks for our model\nfor name, child in vgg.named_children():\n    print(name)","09e1e737":"#freeze all the weights\nfor param in vgg.parameters():\n    param.requires_grad = False","5cc82737":"#number of features in final fc layer\nfinal_in_features = vgg.classifier[6].in_features\n\n#editing the final fc layer\nvgg.classifier[6] = nn.Linear(final_in_features, num_classes)","9d0434ca":"#checking the size of trainable layesr\nfor param in vgg.parameters():\n    if param.requires_grad:\n        print(param.shape)","e9c6b0cd":"#define the loss function and optimizer for back prop\ncriterion = nn.CrossEntropyLoss()\nvgg = vgg.to(device) #push to gpu\n\n#pass only the trainable parameters into optimizer\noptimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, vgg.parameters()), lr=0.0001, amsgrad=True, weight_decay=1e-4)","fafd886d":"#custom function to evaluate the model\n\ndef evaluation(dataloader, model):\n    total, correct = 0, 0\n    for data in dataloader:\n        inputs, labels = data\n        #pushing the data to gpu if present else cpu\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        _, pred = torch.max(outputs.data, 1)\n        total += labels.size(0)\n\n        #number of correct predictions\n        correct += (pred == labels).sum().item()\n\n    return 100 * correct\/total","1512cac0":"def train_model(model, criterion, optimizer, num_epochs=25):\n    \n    since = time.time()\n    train_acc, validation_acc = [], []\n    best_loss = 1000\n    best_model_wts = copy.deepcopy(model.state_dict())\n\n    #define the number of iterations\n    n_iter = np.ceil(len(train_loader.dataset)\/training_batchsize)\n\n    #iterate or epochs\n    for epoch in range(num_epochs):\n        running_trainloss = 0.0\n\n        #iterate through all the batches to complete one pass\n        for i, data in enumerate(train_loader, 0):\n            inputs, labels = data\n            #push to gpu\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            #set gradients to zero\n            optimizer.zero_grad()\n\n            #run the model\n            outputs = model(inputs)\n\n            #calculate loss\n            loss = criterion(outputs, labels)\n            \n            #backpropagate the gradients\n            loss.backward()\n            optimizer.step()\n\n            #total trainingloss\n            running_trainloss += loss.item()\n\n            #clear memory\n            del inputs, labels, outputs\n            torch.cuda.empty_cache()\n\n        else:\n            running_trainloss = running_trainloss \/ len(train_loader.dataset)\n\n            #doing inference\n            validation_accuracy = 0\n            training_accuracy = 0\n            \n            model.eval()\n            with torch.no_grad():\n                validation_accuracy = evaluation(validation_loader, model)\n                training_accuracy = evaluation(train_loader, model)\n                \n            if running_trainloss < best_loss:\n                best_loss = running_trainloss\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n            model.train()\n\n            print(\"Epoch: {}\/{}.. \".format(epoch+1, num_epochs), \"Training Loss: {:.3f}.. \".format(running_trainloss),\n                  \"Training Accuracy % : {:.3f}.. \".format(training_accuracy),\n                  \"Validation Accuracy % : {:.3f}..\".format(validation_accuracy))\n\n            train_acc.append(training_accuracy)\n            validation_acc.append(validation_accuracy)\n    \n    time_elapsed = time.time() - since        \n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best training loss: {:4f}'.format(best_loss))\n    \n    #saving the best model\n    torch.save(model.state_dict(best_model_wts),\"saved.pth\")\n    print(\"best model saved\")\n    \n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    \n    return model, train_acc, validation_acc","016f9f88":"#train the model\nbest_model, train_acc, validation_acc = train_model(vgg, criterion, optimizer_ft,120)","ae30265d":"#plot the accuracy\nplt.plot(train_acc, label='Training Accuracy')\nplt.plot(validation_acc, label='Validation Accuracy')\nplt.legend(frameon=False)\nplt.show()","d2a2ff44":"#compute the validation accuracy using best model\nvalidation_acc_bestmodel = evaluation(validation_loader, best_model)\nprint(\"validation accuracy %: \", validation_acc_bestmodel)","bc0ec5dd":"#create a iterator\n\ndataiter = iter(test_loader)\nimages, labels = dataiter.next()\n\n#shape of images bunch\nprint(images.shape)\n\n#shape of first image in a group of 4\nprint(images[1].shape)\n\n#class label for first image\nprint(labels[1])","9f832610":"#custom function for prediction\ndef testdata_sumission(dataloader, model):\n    since = time.time()\n    predict = []\n    \n    model.eval()  # Set model to evaluate mode\n    # Iterate over data.\n    for data in dataloader:\n        # get the inputs\n        inputs, labels = data\n\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        # forward pass\n        outputs = model(inputs)\n        _, pred = torch.max(outputs.data, 1)\n        \n        pred = pred.cpu().numpy()\n        #print(pred)\n        for i in pred:\n            predict.append(i)\n      \n    time_elapsed = time.time() - since\n    print('Run complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n\n    return predict","956b0e14":"#appending the predicted values\ntest_data_df['has_cactus'] = testdata_sumission(test_loader, best_model)\n\n#saving the submission file\ntest_data_df.to_csv('submission.csv', index= False)","7d6946c0":"## Loading Data","5c674ecb":"# Make Final Submission","222d3929":"# Train the Model","f0fa5663":"* The main aim of the competition is to create an algorithm that can identify a specific type of cactus in aerial imagery.\n* This dataset contains a large number of 32 x 32 thumbnail images containing aerial photos of a columnar cactus (Neobuxbaumia tetetzo). Kaggle has resized the images from the original dataset to make them uniform in size","1bdf64c7":"## More Transformations\n\n### Data Augmentation\n\nA common strategy for training neural networks is to introduce randomness in the input data itself. For example, you can randomly rotate, mirror, scale, and\/or crop your images during training. This will help your network generalize as it's seeing the same images but in different locations, with different sizes, in different orientations, etc.\n\nTo randomly rotate, scale and crop, then flip your images you would define your transforms like this:\n\n```python\ntrain_transforms = transforms.Compose([transforms.RandomRotation(30),\n                                       transforms.RandomResizedCrop(224),\n                                       transforms.RandomHorizontalFlip(),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize([0.5, 0.5, 0.5], \n```\n\nYou'll also typically want to normalize images with `transforms.Normalize`. You pass in a list of means and list of standard deviations, then the color channels are normalized like so\n\n```input[channel] = (input[channel] - mean[channel]) \/ std[channel]```\n\nSubtracting `mean` centers the data around zero and dividing by `std` squishes the values to be between -1 and 1. Normalizing helps keep the network work weights near zero which in turn makes backpropagation more stable. Without normalization, networks will tend to fail to learn.\n\nYou can find a list of all [the available transforms here](http:\/\/pytorch.org\/docs\/0.3.0\/torchvision\/transforms.html). When you're testing however, you'll want to use images that aren't altered (except you'll need to normalize the same way). So, for validation\/test images, you'll typically just resize and crop.\n","7ca87967":"# Modeling\n* Pretrained VGG Net trained on Imagenet dataset","2e60dfe1":"# Visualization Data","b11edee7":"# Exploratory Data Analysis","74803845":"# Imbalance Dataset","423959b7":"# Creating a Custom Data Loader Class\n* For converting the dataset to torchvision dataset format.\nhttps:\/\/pytorch.org\/tutorials\/beginner\/data_loading_tutorial.html","9d2c52fa":"# Classification of Catcus","c86932a6":"### Declaring the directory variables"}}