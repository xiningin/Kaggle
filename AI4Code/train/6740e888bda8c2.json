{"cell_type":{"66e23304":"code","89aa802d":"code","2b6a4de1":"code","3aa3abf6":"code","a2364177":"code","c63cc0f5":"code","f62bd2ba":"code","81726284":"code","53f8753a":"code","ce9ff0ed":"code","8eb55066":"code","19afb8a0":"code","bff67773":"code","1accce06":"code","498ebc75":"code","7cc22e67":"code","4e6c292f":"code","357bb6b1":"markdown","8d8ed872":"markdown","131844fb":"markdown","56662375":"markdown","70fe0970":"markdown","316e6d1b":"markdown","2d92022b":"markdown","4036ce43":"markdown","d2589e66":"markdown","95e7ac7a":"markdown","aa1a28e1":"markdown","6a224808":"markdown","0b4d8624":"markdown","e741467b":"markdown","beba2745":"markdown","e3619347":"markdown"},"source":{"66e23304":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt ","89aa802d":"breast_data = pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')\nbreast_data.head()","2b6a4de1":"breast_data = breast_data.drop(['id', 'Unnamed: 32'], axis  = 1)\nbreast_data.head()","3aa3abf6":"breast_data.describe()","a2364177":"breast_data['diagnosis'] = np.where((breast_data['diagnosis'] == 'M'), 1, 0)\nbreast_data.head()","c63cc0f5":"breast_data['diagnosis'].unique()","f62bd2ba":"cancer_M = breast_data[breast_data['diagnosis']==1]\ncancer_B = breast_data[breast_data['diagnosis']==0]","81726284":"features_mean=list(breast_data.columns[1:11])\nfig, axes = plt.subplots(nrows=5, ncols=2, figsize=(10,13))\naxes = axes.ravel()\nfor idx,ax in enumerate(axes):\n    ax.figure\n    ax.hist([cancer_M[features_mean[idx]],cancer_B[features_mean[idx]]], bins = 50, alpha=0.8, stacked=True, label=['M','B'], color=['red','blue'])\n    ax.legend(loc='upper right')\n    ax.set_title(features_mean[idx])\nplt.tight_layout()\nplt.show()","53f8753a":"from sklearn.model_selection import train_test_split, KFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score","ce9ff0ed":"train, test = train_test_split(breast_data, test_size = 0.2, random_state = 0)","8eb55066":"def classification_model(model, train, test, features, target):\n    model.fit(train[features], np.ravel(train[target]))\n    pred = model.predict(test[features])\n  \n    accuracy = accuracy_score(pred ,test[target])\n    print(\"Accuracy : %s\" % \"{0:.3%}\".format(accuracy))","19afb8a0":"features = ['radius_mean']\ntarget = ['diagnosis']\n\nmodel_logistic = LogisticRegression()\nclassification_model(model_logistic, train, test, features, target)","bff67773":"features = ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean','concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']\ntarget = ['diagnosis']\n\nmodel_logistic_2 = LogisticRegression()\nclassification_model(model_logistic_2 , train, test, features, target)","1accce06":"features = ['radius_mean', 'perimeter_mean', 'area_mean', 'compactness_mean','concave points_mean', 'concavity_mean']\ntarget = ['diagnosis']\n\nmodel_random = RandomForestClassifier(random_state=0)\nclassification_model(model_random, train, test, features, target)","498ebc75":"features = ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n                 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']\n\nmodel_random_2 = RandomForestClassifier(random_state=0)\nclassification_model(model_random_2, train, test, features, target)","7cc22e67":"imp_features = pd.Series(model_random_2.feature_importances_, index=features).sort_values(ascending=False)\nimp_features","4e6c292f":"features = imp_features.index[:7]\ntarget = ['diagnosis']\n\nmodel_random_3 = RandomForestClassifier(random_state=0)\nclassification_model(model_random_3, train, test, features, target)","357bb6b1":"### Take a look at these plots before reading the next part.\nAs you may have noticed, Red colour corresponds to Malignant and Blue to Benign. There are features that can differentiate and classify whether it is M or B easily whereas as features which might not help us classify properly.\n\n#### Features that can help us:\n    1] radius_mean\n    2] perimeter_mean\n    3] area_mean\n    4] compactness_mean\n    5] concavity_mean\n    6] concave points_mean\n#### Features that might not be as useful:\n    1] texture_mean\n    2] smoothness_mean\n    3] symmetry_mean\n    4] fractal_dimension_mean","8d8ed872":"## Breast Cancer Prediction\n#### In this notebook, we will try classify and predict whether it is a Malignant(M) or a Benign(B) based on the features we provide to the model.","131844fb":"#### Random Forest Classifier has a attribute called 'feature_importances_'. It tells us which feature are important in making the decision i.e. in this case M or B.","56662375":"#### Uses all the mean valued features:","70fe0970":"## Splitting dataset into two viz. training set and testing set.","316e6d1b":"## Now we will split the data for visualization purpose.","2d92022b":"## Importing the libraries.","4036ce43":"### Function that takes type of model, training set, testing set, features & target as arguments and prints Accuracy.","d2589e66":"## Models based on Logistic Regression\n#### Uses only one feature:","95e7ac7a":"## Models based on Random Forest Classifier \n#### Uses features that we shortlisted by observing the plots above:","aa1a28e1":"#### Model based on Random Forest Classifier (uses all the mean valued features):","6a224808":"## Let's load the data and explore it.","0b4d8624":"### Now we will only use top 7 features according to feature_importances_ attribute.","e741467b":"### Now our dataset has only numerical values.","beba2745":"### Changing M and B in diagnosis column to 1 and 0 respectively.","e3619347":"### Deleting unneccesary columns."}}