{"cell_type":{"fe206da5":"code","c8e67355":"code","3d6368d0":"code","ac4dd9f8":"code","82c19d67":"code","c9c72a0a":"code","1eb6385d":"code","959785ad":"code","c8c6d977":"code","85cc0475":"code","7d492bda":"code","cda31399":"code","fd6dc4f5":"code","dafe39d5":"code","4bac3873":"code","e1542237":"code","a42f4a7f":"code","95ac5947":"code","3e97b71c":"code","51c15325":"code","034290ce":"code","7a203e22":"code","709f5f88":"code","b28d2d97":"code","7cd8d2c2":"code","a9e8dcd3":"code","aae1c5d7":"code","627ce2ef":"code","b09aadd0":"code","fba96977":"code","fec15308":"code","e74f273e":"code","8ba5fe51":"code","7a93fb85":"code","90cbd8d9":"code","434a2f4a":"code","86d97a9e":"code","f1398ca8":"code","2f5f1dfd":"code","cf2221f3":"code","97df867a":"code","865ac063":"code","a6925e50":"code","75de5102":"code","e2f72c67":"code","590e3fa2":"code","7ba033be":"code","cb333788":"code","1065acb8":"code","ff3863e2":"code","e0253cb0":"code","20e754a6":"code","5edc7e83":"code","93039a49":"code","61fd2578":"code","d0d03521":"code","371a01ea":"code","4f66b6d3":"code","ae1a06f6":"code","c6811c59":"code","a409b8cd":"code","ccb996ef":"code","784d9b8c":"code","a6206bc8":"markdown","5392a342":"markdown","22ca2052":"markdown","daaddfe6":"markdown"},"source":{"fe206da5":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\npd.options.display.max_columns = None\npd.options.display.max_rows = None\nfrom sklearn.preprocessing import LabelEncoder\n\n \n# to suppress the notation 'e'    \npd.options.display.float_format = '{:.6f}'.format\nfrom sklearn.model_selection import train_test_split\nimport statsmodels\nimport statsmodels.api as sm\nimport statsmodels.stats.api as sms\nimport statsmodels.formula.api as smf\nfrom statsmodels.graphics.gofplots import qqplot\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nimport statsmodels.tsa.api as smt\nfrom scipy import stats\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.preprocessing import StandardScaler\n\nimport pip as pip\npip.main(['install', 'mlxtend'])\nfrom mlxtend.feature_selection import SequentialFeatureSelector as SFS\nfrom sklearn.feature_selection import RFE\n\nfrom sklearn.linear_model import LinearRegression\n\nfrom sklearn.model_selection import LeaveOneOut\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import SGDRegressor\n\n# import function for ridge regression\nfrom sklearn.linear_model import Ridge\n\n# import function for lasso regression\nfrom sklearn.linear_model import Lasso\n\n# import function for elastic net regression\nfrom sklearn.linear_model import ElasticNet\n\n# import function to perform GridSearchCV\nfrom sklearn.model_selection import GridSearchCV","c8e67355":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3d6368d0":"data = pd.read_csv('..\/input\/flight-take-off-data-jfk-airport\/M1_final.csv')\ndata.head()","ac4dd9f8":"data.shape","82c19d67":"data.info()","c9c72a0a":"df_cat = data.select_dtypes(include=np.object)\ndf_num = data.select_dtypes(include=np.number)\nprint('categorical : ', df_cat.columns)\nprint('numerical : ', df_num.columns)","1eb6385d":"plt.rcParams['figure.figsize'] = [12,12]\ndf_num.hist()\nplt.show()","959785ad":"#skewness and kurtosis","c8c6d977":"j = []\nskew = []\nkurtosis = []\nfor i in df_num.columns[3:]:\n    j.append(i)\n    skew.append(data[i].skew())\n    kurtosis.append(data[i].kurt())\nskew_kurtosis = pd.DataFrame({'column name': j, 'skew':skew, 'kurtosis':kurtosis})\nskew_kurtosis","85cc0475":"k = 1\nplt.figure(figsize = (30,30))\nfor i in df_num.columns[3:]:\n    plt.subplot(5,3,k)\n    sns.distplot(data[i])\n    k+=1","7d492bda":"plt.figure(figsize = (20,15))\nsns.heatmap(data.corr(), annot = True)\nplt.show()","cda31399":"data.isnull().sum()","fd6dc4f5":"#we find missing values in Wind","dafe39d5":"data.describe().T","4bac3873":"for i in data.columns:\n    print(i)\n    print('---------')\n    print(data[i].value_counts())\n    print('+++')","e1542237":"data[data.isnull().any(axis=1)]","a42f4a7f":"data['Wind'].groupby((data['DEST']=='FLL')).value_counts()","95ac5947":"data['Wind'].groupby((data['DEST']=='PWM')).value_counts()","3e97b71c":"data['Wind'].value_counts()","51c15325":"data['Wind'].replace(np.nan, 'W', inplace = True)","034290ce":"data.isnull().sum()","7a203e22":"# null values treated","709f5f88":"k = 1\nplt.figure(figsize =(20,20))\nfor i in df_num.columns[3:]:\n    if(data[i].dtypes != 'object'):\n        plt.subplot(4,4,k)\n        sns.boxplot(x=data[i])\n        k+=1","b28d2d97":"sns.boxplot(x= 'DAY_OF_WEEK', y='TAXI_OUT', data = data)","7cd8d2c2":"Q3= data['DEP_DELAY'].quantile(0.75)\nQ1= data['DEP_DELAY'].quantile(0.25)\nIQR= Q3-Q1\nUL= Q3 + (1.5)*IQR\nLL= Q1 - (1.5)*IQR\ndf= data[ (data['DEP_DELAY']>=LL) & (data['DEP_DELAY']<=UL) ]","a9e8dcd3":"df.shape","aae1c5d7":"k = 1\nplt.figure(figsize =(20,20))\nfor i in df.columns[3:]:\n    if(df[i].dtypes != 'object'):\n        plt.subplot(5,3,k)\n        sns.boxplot(x=df[i])\n        k+=1","627ce2ef":"data.head()","b09aadd0":"label_encoder = LabelEncoder()\n\ndata['OP_UNIQUE_CARRIER'] = label_encoder.fit_transform(data['OP_UNIQUE_CARRIER'].astype(str))\ndata['DEST'] = label_encoder.fit_transform(data['DEST'].astype(str))\ndata['Wind'] = label_encoder.fit_transform(data['Wind'].astype(str))\ndata['Condition'] = label_encoder.fit_transform(data['Condition'].astype(str))\ndata.head()","fba96977":"data.drop(\"TAIL_NUM\",axis=1,inplace=True)\nprint(data.shape)","fec15308":"data['Dew Point'] = data['Dew Point'].astype(int)","e74f273e":"data.info()","8ba5fe51":"X = data.drop('TAXI_OUT',1)\nY = data['TAXI_OUT']","7a93fb85":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.1, random_state=1)\nprint(X_train.shape, X_test.shape ,Y_train.shape ,Y_test.shape)","90cbd8d9":"#OLS model","434a2f4a":"Xc = sm.add_constant(X)\nmodel_v1 = sm.OLS(Y,Xc).fit()\nmodel_v1.summary()","86d97a9e":"model_v1.resid.skew()  # Normality of Residuals\n\n# Checking assumptions\n #  Use original data (To Build the Model)","f1398ca8":"sns.distplot(model_v1.resid)","2f5f1dfd":"#Linear Regression","cf2221f3":"linear_regression = LinearRegression()\nlinear_regression.fit(X_train.values,Y_train.values)\nrmse = (mean_squared_error(Y_test,linear_regression.predict(X_test))**0.5)\nprint(rmse)","97df867a":"#Ridge Regression","865ac063":"ridge_regression = Ridge(alpha=0.05,normalize=True)\nridge_regression.fit(X_train,Y_train)\nrmse2 = (mean_squared_error(Y_test,ridge_regression.predict(X_test))**0.5)\nprint(rmse2)","a6925e50":"#Lasso Regression","75de5102":"lasso_regression = Lasso(alpha=1,max_iter=1000,tol=.01)\nlasso_regression.fit(X_train,Y_train)\nrmse3=(mean_squared_error(Y_test,lasso_regression.predict(X_test))**0.5)\nprint(rmse3)","e2f72c67":"label_encoder = LabelEncoder()\n\ndf['OP_UNIQUE_CARRIER'] = label_encoder.fit_transform(df['OP_UNIQUE_CARRIER'].astype(str))\ndf['DEST'] = label_encoder.fit_transform(df['DEST'].astype(str))\ndf['Wind'] = label_encoder.fit_transform(df['Wind'].astype(str))\ndf['Condition'] = label_encoder.fit_transform(df['Condition'].astype(str))\ndf.head()","590e3fa2":"df.drop(\"TAIL_NUM\",axis=1,inplace=True)\nprint(df.shape)","7ba033be":"df['Dew Point'] = df['Dew Point'].astype(int)","cb333788":"df.info()","1065acb8":"X = df.drop('TAXI_OUT',1)\nY = df['TAXI_OUT']","ff3863e2":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.1, random_state=1)\nprint(X_train.shape, X_test.shape ,Y_train.shape ,Y_test.shape)","e0253cb0":"#OLS model","20e754a6":"Xc = sm.add_constant(X)\nmodel_v1 = sm.OLS(Y,Xc).fit()\nmodel_v1.summary()","5edc7e83":"model_v1.resid.skew()  # Normality of Residuals\n\n# Checking assumptions\n #  Use original data (To Build the Model)","93039a49":"sns.distplot(model_v1.resid)","61fd2578":"#Linear Regression","d0d03521":"linear_regression = LinearRegression()\nlinear_regression.fit(X_train.values,Y_train.values)\nrmse_af = (mean_squared_error(Y_test,linear_regression.predict(X_test))**0.5)\nprint(rmse_af)","371a01ea":"#Ridge Regression","4f66b6d3":"ridge_regression = Ridge(alpha=0.05,normalize=True)\nridge_regression.fit(X_train,Y_train)\nrmse2_af = (mean_squared_error(Y_test,ridge_regression.predict(X_test))**0.5)\nprint(rmse2_af)","ae1a06f6":"#Lasso Regression","c6811c59":"lasso_regression = Lasso(alpha=1,max_iter=1000,tol=.01)\nlasso_regression.fit(X_train,Y_train)\nrmse3_af=(mean_squared_error(Y_test,lasso_regression.predict(X_test))**0.5)\nprint(rmse3_af)","a409b8cd":"models = pd.DataFrame({\n'Model': ['Linear Regression','Ridge Regression',\n              'Lasso Regression'],\n    'rmse_before_outlier treatment': [rmse,rmse2,\n              rmse3],\n    'rmse_after_outlier treatment': [rmse_af,rmse2_af,\n              rmse3_af]})\nmodels","ccb996ef":"Model = np.array(['Linear Regression','Ridge Regression','Lasso Regression'])\nrmse_before_outlier_treatment = np.array([rmse,rmse2,rmse3])\nrmse_after_outlier_treatment = np.array([rmse_af,rmse2_af,rmse3_af])\nplt.plot(Model,rmse_before_outlier_treatment)\nplt.plot(Model,rmse_after_outlier_treatment)\nplt.legend([\"rmse_before_outlier_treatment\",\"rmse_after_outlier_treatment\"])\nplt.xlabel(\"ML Models\")\nplt.ylabel(\"RMSE\")\nplt.show()","784d9b8c":"models.to_csv(\"models.csv\",index = False)","a6206bc8":"# EDA process\n","5392a342":"#### After outliers treatment","22ca2052":"#### Outlier Treatment","daaddfe6":"#### Model with dataset with outliers"}}