{"cell_type":{"19db06fc":"code","c9a60f51":"code","664151f0":"code","585bf84c":"code","5d979b36":"code","e25bd94a":"code","7f2427ae":"code","37362a58":"code","84381379":"code","b88ef8e9":"code","fd1f2fdd":"code","e568aee0":"code","5bc262f2":"code","1df9c01f":"code","610bd195":"code","25e3755a":"code","9fd4e7b8":"code","5c6bf136":"code","cef2fcf5":"code","da3241e1":"code","60fd2bde":"code","e7265b08":"code","8195c3bd":"code","206d0146":"code","5b772858":"code","79ade6b7":"code","363defab":"code","44c005db":"code","caa982e8":"code","92e75311":"code","9f402afd":"markdown","6c9498c6":"markdown","eaa59c7c":"markdown","ed18f46d":"markdown","b37b6f26":"markdown","bf9c57b7":"markdown","73230ad1":"markdown","2feb3da7":"markdown"},"source":{"19db06fc":"import torch\nimport torchvision\nfrom torchvision.transforms import ToTensor, Normalize, Compose\nfrom torchvision.datasets import MNIST","c9a60f51":"mnist = MNIST(root='data',\n              train=True,\n              download = True,\n              transform = Compose([ToTensor(), Normalize(mean=(0.5,), std=(0.5,))]))","664151f0":"img, label = mnist[0]\nprint('Label: ', label)\nprint(img[:,10:15, 10:15])\ntorch.min(img), torch.max(img)","585bf84c":"def denorm(x):\n    out = (x+1)\/2\n    return out.clamp(0,1)","5d979b36":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nimg_norm = denorm(img)\nplt.imshow(img_norm[0], cmap='gray')\nprint('Label:', label)","e25bd94a":"from torch.utils.data import DataLoader\n\nbatch_size = 100\ndata_loader = DataLoader(mnist, batch_size, shuffle = True)","7f2427ae":"for img_batch, label_batch in data_loader:\n    print('first batch')\n    print(img_batch.shape)\n    plt.imshow(img_batch[0][0], cmap='gray')\n    print(label_batch)\n    break","37362a58":"#Device Configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","84381379":"device","b88ef8e9":"image_size = 784\nhidden_size = 256","fd1f2fdd":"import torch.nn as nn\n\nD = nn.Sequential(\n    nn.Linear(image_size, hidden_size),\n    nn.LeakyReLU(0.2),\n    nn.Linear(hidden_size, hidden_size),\n    nn.LeakyReLU(0.2),\n    nn.Linear(hidden_size, 1),\n    nn.Sigmoid())","e568aee0":"D.to(device)","5bc262f2":"latent_size = 64","1df9c01f":"G =  nn.Sequential(\n     nn.Linear(latent_size, hidden_size),\n     nn.ReLU(),\n     nn.Linear(hidden_size, hidden_size),\n     nn.ReLU(),\n     nn.Linear(hidden_size, image_size),\n     nn.Tanh())","610bd195":"y = G(torch.randn(2, latent_size))\ngen_imgs = denorm(y.reshape((-1,28,28)).detach())","25e3755a":"plt.imshow(gen_imgs[0], cmap='gray')","9fd4e7b8":"plt.imshow(gen_imgs[1], cmap='gray')","5c6bf136":"G.to(device);","cef2fcf5":"criterion = nn.BCELoss()\nd_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002)\ng_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002)","da3241e1":"def reset_grad():\n    d_optimizer.zero_grad()\n    g_optimizer.zero_grad()\n    \ndef train_discriminator(images):\n    #Create a labels which are later used as input for the BCE loss\n    real_labels = torch.ones(batch_size, 1).to(device)\n    fake_labels = torch.zeros(batch_size, 1).to(device)\n    \n    #Loss for real images\n    outputs = D(images)\n    d_loss_real = criterion(outputs, real_labels)\n    real_score = outputs\n    \n    #Loss for fake images\n    z = torch.randn(batch_size, latent_size).to(device)\n    fake_images = G(z)\n    outputs = D(fake_images)\n    d_loss_fake = criterion(outputs, fake_labels)\n    fake_score = outputs\n    \n    #Combine Losses\n    d_loss = d_loss_real + d_loss_fake\n    #Reset gradients\n    reset_grad()\n    #Compute gradients\n    d_loss.backward()\n    #Adjust the parameters using backprop\n    d_optimizer.step()\n    \n    return d_loss, real_score, fake_score","60fd2bde":"z = torch.randn(batch_size, latent_size).to(device)\nfake_images = G(z)\nD(fake_images)","e7265b08":"def train_generator():\n    #Generate fake images and calculate loss\n    z = torch.randn(batch_size, latent_size).to(device)\n    fake_images = G(z)\n    labels = torch.ones(batch_size, 1).to(device)\n    g_loss = criterion(D(fake_images), labels)\n    \n    #Backdrop and optimize\n    reset_grad()\n    g_loss.backward()\n    g_optimizer.step()\n    return g_loss, fake_images","8195c3bd":"import os \nsample_dir = 'samples'\nif not os.path.exists(sample_dir):\n    os.makedirs(sample_dir)","206d0146":"from IPython.display import Image\nfrom torchvision.utils import save_image\n\n#Save some real images\nfor images, _ in data_loader:\n    images = images.reshape(images.size(0), 1, 28, 28)\n    save_image(denorm(images), os.path.join(sample_dir, 'real_images.png'), nrow=10)\n    break\n    \nImage(os.path.join(sample_dir, 'real_images.png'))","5b772858":"sample_vectors = torch.randn(batch_size, latent_size).to(device)\n\ndef save_fake_images(index):\n    fake_images = G(sample_vectors)\n    fake_images = fake_images.reshape(fake_images.size(0), 1, 28, 28)\n    fake_fname  = 'fake_images-{0:0=4d}.png'.format(index)\n    print('Saving', fake_fname)\n    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=10)\n    \n#Before training \nsave_fake_images(0)\nImage(os.path.join(sample_dir, 'fake_images-0000.png'))","79ade6b7":"%%time\n\nnum_epochs = 500\ntotal_step = len(data_loader)\nd_losses, g_losses, real_scores, fake_scores = [], [], [], []\n\n\nfor epoch in range(num_epochs):\n    for i, (images, _) in enumerate(data_loader):\n        #Load a batch & transform to vectors \n        images = images.reshape(batch_size, -1).to(device)\n        \n        #Train the discriminator and generator\n        d_loss, real_score, fake_score = train_discriminator(images)\n        g_loss, fake_images = train_generator()\n        \n        #Inspect the losses\n        if (i+1) % 200 == 0:\n            d_losses.append(d_loss.item())\n            g_losses.append(g_loss.item())\n            real_scores.append(real_score.mean().item())\n            fake_scores.append(fake_score.mean().item())\n            print('Epoch [{}\/{}], Step [{}\/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}'\n                  .format(epoch, num_epochs, i+1, total_step, d_loss.item(), g_loss.item(),\n                         real_score.mean().item(), fake_score.mean().item()))\n    \n    #Samples and save images\n    save_fake_images(epoch+1)                  ","363defab":"#Save the model checkpoints\ntorch.save(G.state_dict(), 'G.ckpt')\ntorch.save(D.state_dict(), 'D.ckpt')","44c005db":"import cv2\nimport os\n\nfrom IPython.display import FileLink\n\nvid_fname = 'gans_training.avi'\n\nfiles = [os.path.join(sample_dir, f) for f in os.listdir(sample_dir) if 'fake_images' in f]\nfiles.sort()\n\nout = cv2.VideoWriter(vid_fname, cv2.VideoWriter_fourcc(*'MP4V'), 8, (302, 302))\n[out.write(cv2.imread(fname)) for fname in files]\nout.release()\nFileLink('gans_training.avi')","caa982e8":"plt.plot(d_losses, '_')\nplt.plot(g_losses, '_')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend(['Discriminator', 'Generator'])\nplt.title('Losses')","92e75311":"plt.plot(real_scores, '_')\nplt.plot(fake_scores, '_')\nplt.xlabel('epoch')\nplt.ylabel('score')\nplt.legend(['Real Score', 'Fake Score'])\nplt.title('Scores')","9f402afd":"# Discriminator Training","6c9498c6":"# Training the Model","eaa59c7c":"# Generator Network","ed18f46d":"# Visualizing Losses and Scores","b37b6f26":"# Convert the images to Video","bf9c57b7":"# Generator Training","73230ad1":"# Discriminator Network","2feb3da7":"# Load the Data"}}