{"cell_type":{"7ff41af8":"code","4bffc76c":"code","ed76d1b3":"code","dee95e1c":"code","2fe91dd0":"code","a0ae2140":"code","77fe1b61":"code","2d41cf41":"code","22d81faa":"code","278d477d":"code","b2ea4088":"code","06b7c6b6":"code","b7f0d955":"code","97610f12":"code","029e7e59":"code","82de888c":"code","77f004c7":"code","041b4218":"code","0997fc17":"code","9a4511ea":"code","a9abfda3":"markdown","ea2d02b9":"markdown","e0d8f104":"markdown","d7bb59e9":"markdown","cf53ddf3":"markdown","683ea25c":"markdown","32d188bf":"markdown","9956fa4e":"markdown","529387c7":"markdown","ad600d9c":"markdown","e7ca83a4":"markdown","40995aa5":"markdown","551d5f6d":"markdown","51bad72c":"markdown","1bebea64":"markdown","700c791e":"markdown","6d567466":"markdown","ef46b612":"markdown","93c6cfd1":"markdown","f921e687":"markdown","873717de":"markdown","490cca82":"markdown","03156042":"markdown","75b8f3cd":"markdown","0f90cc10":"markdown","af610888":"markdown","197f1b53":"markdown","5366b1fc":"markdown","02da7b27":"markdown","c87570c3":"markdown","4d53a70d":"markdown","7e3f297d":"markdown","bcaa8acc":"markdown","79d49eda":"markdown","929332a8":"markdown","295161e7":"markdown","d03fcb2b":"markdown","772fb727":"markdown","8193ccd7":"markdown"},"source":{"7ff41af8":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\nimport tqdm\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom bayes_opt import BayesianOptimization\n\nimport time\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom skopt import BayesSearchCV\n!pip install MulticoreTSNE\nfrom MulticoreTSNE import MulticoreTSNE as TSNE\nfrom sklearn.manifold import TSNE\nimport plotly.express as px\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nrandom_state = 42\nnp.random.seed(random_state)\n\ndf_train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/digit-recognizer\/sample_submission.csv')","4bffc76c":"print('Train data Info : ' )\ndf_train.info()\n\nprint('\\nTest data Info : ')\ndf_test.info()\n\nprint('\\nThere is ' + str(df_train.isnull().sum().sum()) + ' missing values in Train data')\nprint('\\nThere is ' + str(df_test.isnull().sum().sum()) + ' missing values in Train data')\n\nprint('\\nTrain first 5 rows')\ndisplay(df_train.head())\n\nprint('\\nTest first 5 rows')\ndf_train.head()","ed76d1b3":"labels = sorted(df_train['label'].unique())\nfig = plt.figure(figsize = [20,20])\ni = 1\nfor l in labels :\n    for data in df_train[df_train['label'] == l].sample(n=10, random_state=random_state).values :\n        plt.subplot(10, 10, i)\n        label = data[0]\n        pixels = data[1:]\n        pixels = np.array(pixels, dtype='uint8')\n\n        pixels = pixels.reshape((28, 28))\n\n        plt.title('Label is {label}'.format(label=label))\n        plt.imshow(pixels, cmap='gray', aspect='auto')\n        i = i+ 1\nplt.tight_layout()\nplt.show()","dee95e1c":"plt.figure(figsize=(25, 15))\nj = 1\nfor i in range(10) :\n    plt.subplot(10,4,j)\n    j +=1\n    plt.imshow(df_train[df_train['label'] == i].sample(1).drop(labels = [\"label\"],axis = 1).values.reshape(28, 28), cmap='gray', interpolation='none')\n    plt.title(\"Digit: {}\".format(i))\n    plt.subplot(10,4,j)\n    j +=1\n    pd.DataFrame(df_train[df_train['label'] == i].sample(1).drop(labels = [\"label\"],axis = 1).values.reshape(28, 28)).sum(axis = 1).plot.area(title = 'Univariation of Horizontal Pixels')\n    plt.subplot(10,4,j)\n    j +=1\n    pd.DataFrame(df_train[df_train['label'] == i].sample(1).drop(labels = [\"label\"],axis = 1).values.reshape(28, 28)).sum(axis = 0).plot.area(title = 'Univariation of Vertical Pixels')\n    plt.subplot(10,4,j)\n    j +=1\n    plt.hist(df_train[df_train['label'] == i].sample(1).drop(labels = [\"label\"],axis = 1))\n    plt.title(\"Pixel Value Distribution\")\nplt.tight_layout()\n","2fe91dd0":"ax = sns.barplot(x=\"index\", y=\"label\", data=df_train.label.value_counts().to_frame().sort_index().reset_index())\nax.set(xlabel='Count', ylabel='Degits')","a0ae2140":"# X_train = df_train.drop(labels = [\"label\"],axis = 1)\n# Y_train = df_train[\"label\"]\n# Y_train = to_categorical(Y_train, num_classes = 10)\n# X_train \/= 255\n\n# X_embedded = TSNE(n_components=3, n_jobs=1).fit_transform(X_train)\n# tsne_plot = pd.DataFrame(X_embedded)\n# tsne_plot.columns = ['tsne_axe1','tsne_axe2','tsne_axe3']\n# tsne_plot['digits'] = df_train[\"label\"].astype('str')\n# fig = px.scatter_3d(tsne_plot, x='tsne_axe1', y='tsne_axe2', z='tsne_axe3',\n#               color='digits',  size_max=18)\n# fig.show()","77fe1b61":"X_train = df_train.drop(labels = [\"label\"],axis = 1)\nY_train = df_train[\"label\"]\nY_train = to_categorical(Y_train, num_classes = 10)\n\nX_train = X_train.values.reshape(X_train.shape[0], 28, 28, 1)\nX_test = df_test.values.reshape(df_test.shape[0], 28, 28, 1)\n\ndatagen = ImageDataGenerator(rotation_range=10,\n                             zoom_range = 0.1,\n                             width_shift_range=0.1,\n                             height_shift_range=0.1)\n\ndict_ = {}\nbatchs = datagen.flow(X_train, Y_train, batch_size=1)\nfor i in range(784) :\n    indx = 'pixel' + str(i)\n    dict_[indx] = []\ndict_['label'] = []\nk = 0\ncounter = 0\nfor x_batch, y_batch in tqdm.tqdm(datagen.flow(X_train, Y_train, batch_size=1)):\n    for i in range(28):\n        for j in range (28):         \n            indx = 'pixel' + str(k)\n            dict_[indx].append(float(x_batch[0][i][j][0]))\n            k = k+1\n    dict_['label'].append(np.where(y_batch[0] == 1.)[0].item(0))\n    k = 0\n    counter += 1\n    if counter > 10**5:\n        break\n\ndf_train = pd.DataFrame.from_dict(dict_)\ndel dict_","2d41cf41":"labels = sorted(df_train['label'].unique())\nfig = plt.figure(figsize = [20,20])\ni = 1\nfor l in labels :\n    for data in df_train[df_train['label'] == l].sample(n=10, random_state=random_state).values :\n        plt.subplot(10, 10, i)\n        label = data[0]\n        pixels = data[1:]\n        pixels = np.array(pixels, dtype='uint8')\n\n        pixels = pixels.reshape((28, 28))\n\n        plt.title('Label is {label}'.format(label=label))\n        plt.imshow(pixels, cmap='gray', aspect='auto')\n        i = i+ 1\nplt.tight_layout()\nplt.show()","22d81faa":"ax = sns.barplot(x=\"index\", y=\"label\", data=df_train.label.value_counts().to_frame().sort_index().reset_index())\nax.set(xlabel='Count', ylabel='Degits')","278d477d":"X_train = df_train.drop(labels = [\"label\"],axis = 1)\nY_train = df_train[\"label\"]\nY_train = to_categorical(Y_train, num_classes = 10)\n\nX_train \/= 255\n\nX_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.1, random_state=random_state)","b2ea4088":"batch_size = [256, 512]\nepochs = [10, 20]\noptimizer = ['RMSprop', 'Adam']\nneurons = [512, 1024]\n\ndef create_model(neurons=neurons, epochs=epochs, optimizer=optimizer, batch_size=batch_size):\n    model = Sequential()\n    model.add(Dense(neurons, input_dim=784, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(neurons, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(10, activation='softmax'))\n\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n\n    return model\n\nmodel_BayesianOptimization = KerasClassifier(build_fn=create_model, verbose=0)\nmodel_GridSearch = KerasClassifier(build_fn=create_model, verbose=0)\nmodel_RandomSearch = KerasClassifier(build_fn=create_model, verbose=0)\n\nparam_opt = dict(batch_size=batch_size, epochs=epochs, neurons=neurons, optimizer = optimizer)","06b7c6b6":"grid = GridSearchCV(estimator=model_GridSearch, param_grid=param_opt, n_jobs=1, cv=3, verbose = 0)\ngrid_result = grid.fit(X_train, Y_train)\n#it took 80.5min","b7f0d955":"print('according to gridsearch the best parameters are : ')\nprint('batch_size : ' + str(grid_result.best_params_['batch_size']))\nprint('epochs : ' + str(grid_result.best_params_['epochs']))\nprint('neurons : ' + str(grid_result.best_params_['neurons']))\nprint('optimizer : ' + str(grid_result.best_params_['optimizer']))","97610f12":"batch_size = grid_result.best_params_['batch_size']\nepochs = grid_result.best_params_['epochs']\nneurons = grid_result.best_params_['neurons']\noptimizer = grid_result.best_params_['optimizer']\n\n\nmodel = Sequential()\nmodel.add(Dense(neurons, input_dim=784, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(neurons, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n\nmodel.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, Y_test), verbose = 0)\n\npredictions = model.predict_classes(df_test\/255)\nsubmission['Label'] = pd.DataFrame(predictions)[0].values\nsubmission.to_csv('submission_grid_search.csv', index=False) ","029e7e59":"random = RandomizedSearchCV(estimator=model_RandomSearch, param_distributions=param_opt, n_jobs=1, cv=3, verbose = 1, n_iter = 5)\n\nrandom_result = random.fit(X_train, Y_train)","82de888c":"print('according to randomsearch the best parameters are : ')\nprint('batch_size : ' + str(random_result.best_params_['batch_size']))\nprint('epochs : ' + str(random_result.best_params_['epochs']))\nprint('neurons : ' + str(random_result.best_params_['neurons']))\nprint('optimizer : ' + str(random_result.best_params_['optimizer']))","77f004c7":"batch_size = random_result.best_params_['batch_size']\nepochs = random_result.best_params_['epochs']\nneurons = random_result.best_params_['neurons']\noptimizer = random_result.best_params_['optimizer']\n\n\nmodel = Sequential()\nmodel.add(Dense(neurons, input_dim=784, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(neurons, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n\nmodel.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, Y_test), verbose = 2)\n\npredictions = model.predict_classes(df_test\/255)\nsubmission['Label'] = pd.DataFrame(predictions)[0].values\nsubmission.to_csv('submission_Random_Search.csv', index=False) ","041b4218":"bayesian = BayesSearchCV(\n     model_BayesianOptimization,\n     param_opt,\n     n_iter=32,\n     random_state=random_state,\n     cv=3,\n     verbose = 0, n_jobs=1\n )\n\nbayesian_result = bayesian.fit(X_train, Y_train)","0997fc17":"print('according to BayesianOptimization the best parameters are : ')\nprint('batch_size : ' + str(bayesian_result.best_params_['batch_size']))\nprint('epochs : ' + str(bayesian_result.best_params_['epochs']))\nprint('neurons : ' + str(bayesian_result.best_params_['neurons']))\nprint('optimizer : ' + str(bayesian_result.best_params_['optimizer']))","9a4511ea":"batch_size = bayesian_result.best_params_['batch_size']\nepochs = bayesian_result.best_params_['epochs']\nneurons = bayesian_result.best_params_['neurons']\noptimizer = bayesian_result.best_params_['optimizer']\n\n\nmodel = Sequential()\nmodel.add(Dense(neurons, input_dim=784, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(neurons, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n\nmodel.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, Y_test), verbose = 2)\n\npredictions = model.predict_classes(df_test\/255)\nsubmission['Label'] = pd.DataFrame(predictions)[0].values\nsubmission.to_csv('submission_Bayesian_Optimization.csv', index=False) ","a9abfda3":"## Let's cleanly prepare our vacation photos <a id=\"5.1\"><\/a>","ea2d02b9":"Let's build our neural network with these parameters and see how it works","e0d8f104":"## Let's look at the pixel distribution of each picture <a id=\"4.2\"><\/a>\n","d7bb59e9":"# Hyperparameter Optimization <a id=\"5\"><\/a>\n","cf53ddf3":"The dynamic hyperparameters that we have to find :\n\n* Batch size is the size of the batch of images that the model will see before he updates his weights and biases so that he minimizes categorical crossentropy. the size of the batch defines the speed and stability of the network. I have chosen the values 256 and 512, it is preferable to choose a multiple of 2.\n\n* The epoch is the number of times that the network goes around all the training data. If the epoch number is too large, this can lead to overfitting.\n\n<img src=\"https:\/\/i.postimg.cc\/8PqF3Wh9\/optimiser2.png\" align=\"right\" width=\"300\" height=\"200\">\n* The optimizer is the algorithm which will modify the weights and biases of the network to reach the minimum of the error function, in other words it reduces the error and it is the engine of learning, I chose the two most popular: Adam and RMSprop, both do the same work, that is to say they find the minimum of the error function but their particularity is that they accelerate the step to reach the minimum in the goal that learning does not take much time and also that the network is not trapped in a shallow minimum which is the local minimum. The difference between Adam and RMSpro and that Adam uses the principle of RMSprop and he adds another accelerator called the momentum.\n<BR CLEAR=\u201dleft\u201d \/>\n\n* Finally the number of neurons of each layer which define the degree of freedom of the network, if the number is too high that can cause an overfitting and if it is small it generates an underfitting. I took 512 and 1024 which is high but we have generated 100,000 images to teach this network and for it to model well it must be quite large.\n\n* Why did I take 4 hyper parameters to optimize and 2 examples of each? Because it's already a lot, you'll see how long it will take when I run the optimizers. If you have ultra powerful GPUs test all hyperparameters. have fun =).\n\n\n","683ea25c":"Around 4000 of each digit, it's balanced.","32d188bf":"## Bay\u00e9sien Optimisation <a id=\"5.4\"><\/a>","9956fa4e":"# First look of the Data <a id=\"3\"><\/a>","529387c7":"We can clearly distinguish digits facing or shifted towards one of the edges.","ad600d9c":"The hyperparameters that I fixed :\n* Neural network layer numbers I chose 2 hidden layers and an output layer. the higher the number of layers, the higher the network has a degree of freedom, if we choose more layers than necessary we fall into overfitting. and the opposite leads to underfitting.\n\n* The activation functions of each layer, I chose re-read for the hidden layers and softmax for the output.why reread, honestly I don't know and few people can explain this, it's just that there is a guy who was inspired by biomimetism who tried and it worked well. Softmax because this function exaggerates the differences between the 1 and the 0 of the output layer, as we have 10 output neurons and each one corresponds to a digit (0 to 9) the neuron with the highest score wins and represents the prediction, and softmax is perfect for that because it increases the value above 0.5 and decreases the value below 0.5.\n\n<img src=\"https:\/\/i.postimg.cc\/ryjCvhmb\/dropout.jpg\" align=\"right\" width=\"200\" height=\"100\">\n\n* The dropout eliminates a percentage of neurons at random from each layer at each iteration which reduces the degree of freedom of the network and it works quite well against overfitting.\n\n<BR CLEAR=\u201dleft\u201d \/>\n\n* The error function is categorical crossentropy, it is a function that calculates the difference between the predicted output and the real output, it gives us how wrong our model is, the objective of learning is to minimize this function as much as possible using the optimization algorithm. It calculates this distance by multiplying the elements of the hot encoded vector of the real output by the predicted output.\n\n<img src=\"https:\/\/i.postimg.cc\/5yKzjRQ2\/loss.png\" width=\"400\" height=\"200\">\n\n* The metric that calculates the performance of the model is the accuracy which is simply (the digits predict correctly) \/ (all the digits).","e7ca83a4":"## How many elements of each digit do we have ? <a id=\"4.3\"><\/a>","40995aa5":"We have 42,000 learning inputs and 28,000 test inputs, making a total of 70,000 images.\n\nThe first column of our data is \"label\" it contains the digit represented by the line, it goes from 0 to 9.\n\nthe labels are present on the training data only, it is up to us to predict the label of the test data.\n\nThe rest of the columns (pixel0 to pixel783) contain the gray shade of each pixel which constitutes the image, the resolution of the images is 28 x 28 which is flattened in a vector of 784 boxes represented by these columns.\n\nThe shade of gray goes from 0 to 255, 0 is white and 255 is black and between them it is shades of gray.","551d5f6d":"## Let's Prepare these Digits <a id=\"4.5\"><\/a>","51bad72c":"<img src=\"https:\/\/i.postimg.cc\/c1P44Wr8\/data-gen.png\" align=\"right\" width=\"600\" height=\"500\">\n\nTo diversify our images I decided to make use of the ImageDataGenerator functionality of the Keras library which allows to apply various modifications to a basic image batch.\nI chose a zoom in or out of 1%, a left or right rotation of 10 degrees and a shift in length or width of 10%.\n\nI did this by reconstructing the 28 x 28 images from the 784 pixel vectors, then I injected these images into the ImageDataGenerator function, mentioning the modifications it should apply, I generated 100,000 images with the 42000 basic and finally I restored the state of origin of the data by flattening these resulting images.\n\nThe objective of this increase and diversification of data is to create a greater generalization of training data and that gives them more possibility of containing examples of real life. the more the training data is divided, the less chance that the algorithm will fall into overfitting.\n\n<BR CLEAR=\u201dleft\u201d \/>","1bebea64":"Grid search is a way to find the best hyper parameters by evaluating all possible combinations of these.\n\nAs we have 4 hyper parameters with 2 possibility of each, that makes 2 x 2 x 2 x 2 = 16 possible combinations, and as we evaluate the model in cross validation with 3 folds that makes 16 x 3 = 48 fits of the network and that is huge it will take a considerable time.\n\nIf each fit is done in 2 minutes, everything ends in 1 hour and 36 minutes\n\nIf we had chosen 3 possibilities for the 4 hyperparameters it will make 81 possible combination and 243 fit with a CV of 3 folds and it will take more than 8 hours.\n\nwe can deduce that the number of hyperparameters and the number of possibilities for each hyper parameter will make expenentially increase the execution time. this event is called the curse of dimensionality.\n\nThe adventures of grid search is that it is reliable and it tests all the possibilities that it gives.\n\nInconvenience due to curse of dimensionality it will take a lot of time if we want to experiment with a lot of variables and also grid search only experiences the values we give it and it does not experiment with the values between those we give it.","700c791e":"Submission scored 0.98342 in public LB","6d567466":"<img src=\"https:\/\/i.postimg.cc\/gJkb4Srp\/deeplearning-meme-1.jpg\" width=\"700\" height=\"500\">","ef46b612":"Let's build our neural network with these parameters and see how it works","93c6cfd1":"<img src=\"https:\/\/i.postimg.cc\/R0dj37dD\/tsne.png\" align=\"right\" width=\"400\" height=\"300\">\n\nThis is a 3D representation of the 784 pixels, this resizing is done using TSNE (t-distributed stochastic neighbor embedding).\nTo simplify, TSNE projects the points in the final dimension (here it is 3 dimensions) then it brings together or removes these points by calculating their similarity.\n<a href=\"https:\/\/www.youtube.com\/watch?v=NEaUSP4YerM\">Check this<\/a>\n\nIn this 3D space, there are 9 clusters of dots of different colors, each cluster represents a digit. so we can deduce that the digits are similar to each other. However, we can clearly see that some points are not in the clusters where they are supposed to be. these points are digits that are written in a way that they look like other digits.\n\nthose will cause a problem.\n\n<BR CLEAR=\u201dleft\u201d \/>","f921e687":"## Grid Search <a id=\"5.2\"><\/a>","873717de":"## Let's see this in 3D space <a id=\"4.4\"><\/a>\n","490cca82":"Random Search looks like grid search but without testing all possible combinations, we chose only a limited number of combinations drawn randomly without discount and we evaluated our model with what we have drawn.\n\nIn our case we take 5 possible combinations randomly and we test the model. So among 16 possibilities we will take only 5 with 5\/16 of chance that among these 5 picks we will fall on the best combination.\n\nThe advantage of randomsearch is that it doesn't take much time.\n\nThe inconvenient is that we are not sure to come across the best hyper parameters.\n\n<img src=\"https:\/\/i.postimg.cc\/ZKv51rjX\/grid-and-randon-search.png\" width=\"700\" height=\"500\">","03156042":"# Contents\n\n* [<font size=4>Introduction<\/font>](#1)\n* [<font size=4>Import Libraries and read Data<\/font>](#2)\n* [<font size=4>First look of the Data<\/font>](#3)\n* [<font size=4>Let's explore the mess<\/font>](#4)\n *     [Let's look at some of those damn pictures](#4.1)\n *     [Let's look at the pixel distribution of each picture](#4.2)\n *     [How many elements of each digit do we have ?](#4.3)\n *     [Let's see this in 3D space](#4.4)\n *     [Let's Prepare these Digits](#4.5)\n* [<font size=4>Hyperparameter Optimization<\/font>](#5)\n *     [Let's cleanly prepare our vacation photos](#5.1)\n *     [Grid Search](#5.2)\n *     [Random Search](#5.3)\n *     [Bay\u00e9sien Optimisation](#5.4)\n* [<font size=4>Conclusion<\/font>](#6)","75b8f3cd":"We are creating our first neural network which we will optimize.\n\nThis neural network contains hyperparameters which i fixed at the start and others which remain dynamic which we must optimize and find the right combination which allows to have optimal performances.\n\nWhy did I fix some and not others ? it is for lack of time and computing power, even if Kaggle puts at our disposal GPUs and TPUs which considerably boost the learning speed but it remains too long = \/\n\nFor these reasons i chose only some hyper parameters to optimize and fix others.\n\nThose that i fixed are supposed to be the most optimal according to other studies so they will not be able to cannibalize the performances.","0f90cc10":"## Random Search <a id=\"5.3\"><\/a>","af610888":"It scored 0.98114 it can be better or worst when i commit this note book maybe the hyperparameters will change.","197f1b53":"## Introduction <a id=\"1\"><\/a>\n\nThis notebook provides an overview on building a simple sequential Neural Network using Tensorflow Keras API and then finding the best hyperparameters to increase its accuracy using different approaches by evaluating their reliability and the time it takes them to get there.\n\nThe first part of the notebook is an exploratory analysis that we will use for this experiment.\n\nThereafter, we will do Data engineering to favor the diversity of our Dataset.\n\nFinally the most important part is the optimization of the parameters of the network in order to increase its performance.\n\nI do this experiment after having completed the theoretical courses provided by <a href=\"https:\/\/www.coursera.org\/specializations\/deep-learning\">deeplearnong.ai<\/a> i recommend to everyone and also the excellent conference of  <a href=\"https:\/\/www.youtube.com\/watch?v=BtAVBeLuigI&t=6823s\">Martin G\u00f6rner<\/a> if you speak French =)","5366b1fc":"<img src=\"https:\/\/i.postimg.cc\/rppLNZDk\/Cross-validation.png\" align=\"bottom\" width=\"800\" height=\"400\">\n\nNow we will split our 100k images into 2 groups.\n\nThe first group which will contain 90% of the images will serve to train our neural network and find the best hyperparameters of our network and the second group which will contain only 10% of the images that the network has not seen during training which will be used to evaluate the neural network at the end.\n\nI normalized the pixel value between 0 and 1 instead of 0 and 254 because neural networks feel uneasy with this data interval.\n\nI also apply the one hot encoding on the digital labels\nex: 2 -> [0,0,1,0,0,0,0,0,0,0,0]\n\n<BR CLEAR=\u201dtopum\u201d \/>","02da7b27":"# Import Libraries and read Data <a id=\"2\"><\/a>","c87570c3":"The balancing of the digits remained the same.","4d53a70d":"the network prediction with the hyperparameters found by the bayesian optimization made the highest score.\n\n0.98685 sur la Public LB","7e3f297d":"Bayesian optimization works by constructing a posterior distribution of functions (gaussian process) that best describes the function you want to optimize. As the number of observations grows, the posterior distribution improves, and the algorithm becomes more certain of which regions in parameter space are worth exploring and which are not, as seen in the picture below.\n\n<img src=\"https:\/\/i.postimg.cc\/kgtRF0k6\/bo-example-22.jpg\" width=\"700\" height=\"500\">\n\n\nAs you iterate over and over, the algorithm balances its needs of exploration and exploitation taking into account what it knows about the target function. At each step a Gaussian Process is fitted to the known samples (points previously explored), and the posterior distribution, combined with a exploration strategy (such as UCB (Upper Confidence Bound), or EI (Expected Improvement)), are used to determine the next point that should be explored (see the gif below).\n\n<img src=\"https:\/\/i.postimg.cc\/bJYvMWFR\/bayesian-optimization.gif\" width=\"700\" height=\"500\">\n\nThis process is designed to minimize the number of steps required to find a combination of parameters that are close to the optimal combination. To do so, this method uses a proxy optimization problem (finding the maximum of the acquisition function) that, albeit still a hard problem, is cheaper (in the computational sense) and common tools can be employed. Therefore Bayesian Optimization is most adequate for situations where sampling the function to be optimized is a very expensive endeavor. See the references for a proper discussion of this method.\n\n<a href=\"https:\/\/github.com\/fmfn\/BayesianOptimization\">Referance<\/a>","bcaa8acc":"# Conclusion <a id=\"6\"><\/a>","79d49eda":"# Let's explore the mess <a id=\"4\"><\/a>","929332a8":"* The choice of hyperparameters is crucial to considerably increase the precision of a neural network and in general of other algorithms.\n\n* GridSearch is great, but it takes a long time.\n\n* Randomsearch takes less time but it does not provide the best hyperparameters.\n\n* Bayesian Optimization takes a long time but it guarantees the best hyperparameters.\n\n* The greater the number of hyper parameters, the higher the time required to find the best ones, as is the number of choices for each hyper parameter.","295161e7":"## Let's look at some of those damn pictures <a id=\"4.1\"><\/a>","d03fcb2b":"These are small images in which we can easily distinguish a digit between 0 and 9 written with hands and sometimes with feet, our algorithm will have a hard time predicting them.","772fb727":"<img src=\"https:\/\/i.postimg.cc\/Fs2mmVCb\/nnmeme3.png\" align=\"right\" width=\"300\" height=\"200\">\n\nI apply this exercise to recognize handwritten digits presented on photos of 28 x 28 pixels but we can apply this methodology very well for other problems. wait, i will even say, it is recomendable to apply this methodology for other problems with input data which are neither images or videos because a convolutional neural network (CNN) which I do not use here performs far better than a standard neural network.\n\nA trivial sequential neural network can have good results if we choose the right configuration and combine it with other neural networks or other algorithms.\n\nEnough talking leave room for the most important ! \n\n<BR CLEAR=\u201dleft\u201d \/>","8193ccd7":"On the far left we have the digit in question to draw at random.\n\nIn the middle we have Univariation of Horizontal Pixels and Univariation of Vertical Pixels which are respectively the sum of the pixel values of the horizontal axis and the vertical axis of the left image.\n\nWe notice that the variation is different between the images, for example the zero is symmetrical and the sum of the pixels of the two axes is practically identical. the same for the one and eight.\n\nOn the other hand the three is asynmetric what makes that the sum of the pixels of each axis is not homogeneous. the same for the rest of the digits.\n\nThis can be good news because there is a simple way of distinguishing between zero, one and eight and the rest of the digits, if they are well written of course.\n\nOn the far right we have the distribution of the 255 shades of gray in the image on the left.\n\nWe notice that the white pixels (value 0) is very present and which are followed by far by the black pixels (value 255).\n\nthis means that the gray pixels are present mainly in the borders between the black pixels and the white pixels and they are few."}}