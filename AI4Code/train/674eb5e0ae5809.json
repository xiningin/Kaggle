{"cell_type":{"8b72f271":"code","f97b7eb4":"code","0916c3c1":"code","88721497":"code","aa924277":"code","87a64936":"code","1dc66449":"code","4906eecb":"code","a3b9c385":"code","a3e39537":"code","9508aadb":"code","214f0314":"code","78e43bfa":"code","4f39b3e5":"code","1280e6be":"code","812a56c8":"code","8ff32337":"code","ad508c6c":"code","8760e24a":"markdown","f3278e56":"markdown","a742e660":"markdown","f49d7261":"markdown","10635071":"markdown","37896164":"markdown","2b6f64c5":"markdown","9087dfd8":"markdown","997593e3":"markdown","dbb2308d":"markdown","e976e568":"markdown","57cec142":"markdown"},"source":{"8b72f271":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom keras.datasets import fashion_mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.optimizers import Adam\n# from keras.layers.normalization import BatchNormalization\nfrom keras.utils import np_utils\nfrom keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\nfrom keras.layers.advanced_activations import LeakyReLU \nfrom keras.preprocessing.image import ImageDataGenerator\nnp.random.seed(25)","f97b7eb4":"(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\nprint(\"X_train original shape\", X_train.shape)\nprint(\"y_train original shape\", y_train.shape)\nprint(\"X_test original shape\", X_test.shape)\nprint(\"y_test original shape\", y_test.shape)","0916c3c1":"plt.imshow(X_train[10],cmap='gray')","88721497":"y_train[10]","aa924277":"(unique, counts) = np.unique(y_train, return_counts=True)\nprint(unique, counts)\ng = sns.countplot(y_train)","87a64936":"x_test=X_test","1dc66449":"X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\n\nX_train\/=255\nX_test\/=255\n\nX_train.shape","4906eecb":"number_of_classes = 10\n\nY_train = np_utils.to_categorical(y_train, number_of_classes)\nY_test = np_utils.to_categorical(y_test, number_of_classes)\n\ny_train[0], Y_train[0]","a3b9c385":"model = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","a3e39537":"model.summary()","9508aadb":"model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])","214f0314":"history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=25, batch_size = 64, verbose=1)","78e43bfa":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","4f39b3e5":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","1280e6be":"from sklearn.metrics import confusion_matrix\nY_pred = model.predict(X_test)\ny_pred = np.argmax(Y_pred, axis=1)\nmatrix = confusion_matrix(y_test, y_pred)","812a56c8":"matrix","8ff32337":"from sklearn.metrics import classification_report\ntarget = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]\nreport = classification_report(y_test, y_pred, target_names = target)","ad508c6c":"report","8760e24a":"# Training model","f3278e56":"# Confusion matrix","a742e660":"# Reshaping and normalization","f49d7261":"# Training and validation accuracy","10635071":"# Classification report","37896164":"# Adding layers to the model","2b6f64c5":"# Viewing dataset","9087dfd8":"# Compiling the model","997593e3":"# Training and validation loss","dbb2308d":"# Label Encoding","e976e568":"# Loading dataset","57cec142":"# Importing libraries"}}