{"cell_type":{"5e4b2b55":"code","9dff77aa":"code","09a550e0":"code","e7c5c23a":"code","4f94d448":"code","64f75706":"code","a8d11519":"code","ebc31eb4":"code","03a5eba7":"code","76a5c69a":"code","a187cfc8":"code","3807e7ee":"code","c83008ca":"code","f916cdca":"code","84a5a8d8":"code","88889c4e":"code","01d80be1":"code","04d27ebb":"code","0cc8d9d9":"code","afd31ae0":"code","f3800595":"code","475495e8":"code","dfffc730":"code","429b9390":"code","ac7253c3":"code","58fbb476":"code","a0f2c533":"code","865df924":"code","a674b6ba":"code","08182819":"code","66f54193":"code","901935a2":"code","0e4ff476":"code","78dce497":"code","dc8bfa9c":"code","b75395c7":"markdown"},"source":{"5e4b2b55":"import numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import PowerTransformer","9dff77aa":"df=pd.read_csv('\/kaggle\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')\ndf.head()","09a550e0":"fig=px.histogram( data_frame=df,\n            x=df['quality'],\n            color=df['quality'])\nfig.show()","e7c5c23a":"df.info()","4f94d448":"df.duplicated().sum()","64f75706":"df=df.drop_duplicates(keep='first')","a8d11519":"df.duplicated().sum()","ebc31eb4":"df['quality'].value_counts()","03a5eba7":"df.corr()['quality']","76a5c69a":"x=df.iloc[:,:-1]\ny=df.iloc[:,-1]\ny=[1 if i>=7 else 0 for i in y]","a187cfc8":"y=pd.DataFrame(y)","3807e7ee":"y.value_counts()","c83008ca":"\ni=1\nplt.figure(figsize=(50,90))\n\nfor col in x.columns:\n    plt.subplot(11,2,i)\n    sns.histplot(x[col])\n    plt.xticks(fontsize=25)\n    plt.yticks(fontsize=25)\n    plt.xlabel(col,fontsize=25)\n    plt.ylabel(\"count\",fontsize=25)\n    i=i+1\nplt.show()","f916cdca":"x","84a5a8d8":"y","88889c4e":"print(x.shape,y.shape)\nprint(y.value_counts())","01d80be1":"from imblearn.over_sampling import SMOTE \n\nsmote=SMOTE()\nx,y=smote.fit_resample(x,y)","04d27ebb":"print(y.value_counts())","0cc8d9d9":"print(x.shape,y.shape)\n#y=y.value\ny=y.reshape(2350,)\nprint(y.shape)","afd31ae0":"i=1\nplt.figure(figsize=(50,90))\n\nfor col in x.columns:\n    plt.subplot(11,2,i)\n    sns.histplot(x[col])\n    plt.xticks(fontsize=25)\n    plt.yticks(fontsize=25)\n    plt.xlabel(col,fontsize=25)\n    plt.ylabel(\"count\",fontsize=25)\n    i=i+1\nplt.show()","f3800595":"def check_skewness(x):\n    \n    skew_limit=0.75\n    skew_value=df[x.columns].skew()\n    skew_cols=skew_value[abs(skew_value)>skew_limit]\n    #print(skew_cols)\n    cols=skew_cols.index\n    return cols\n    \nskewed_col=check_skewness(x)\nprint(skewed_col)\n\npt=PowerTransformer(standardize=False)\nx[skewed_col]=pt.fit_transform(x[skewed_col])\n\n\n\n","475495e8":"x[skewed_col].skew()","dfffc730":"i=1\nplt.figure(figsize=(50,90))\nfor col in x.columns:\n    plt.subplot(11,2,i)\n    sns.distplot(x[col])\n    plt.xticks(fontsize=25)\n    plt.yticks(fontsize=25)\n    plt.xlabel(col,fontsize=25)\n    plt.ylabel(\"count\",fontsize=25)\n    i=i+1\nplt.show()","429b9390":"x.duplicated().sum()","ac7253c3":"from sklearn.model_selection import train_test_split\n\nxtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=1)\n\nprint(xtrain.shape)\nprint(ytrain.shape)\nprint(xtest.shape)\nprint(ytest.shape)","58fbb476":"from sklearn.preprocessing import StandardScaler\n\nsc=StandardScaler()\nxtrain=sc.fit_transform(xtrain)\nxtest=sc.transform(xtest)","a0f2c533":"def evaluate(model):\n    model.fit(xtrain,ytrain)\n    accuracy=model.score(xtest,ytest)\n    \n    print('model name ',model)\n    print('accuracy ',accuracy)\n    ","865df924":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\nlr=LogisticRegression()\nsvm=SVC()\ndt=DecisionTreeClassifier(max_depth=6)\nrf=RandomForestClassifier(max_samples=0.9)\nknn=KNeighborsClassifier(n_neighbors=5)\n\nmodels=[lr,svm,dt,rf,knn]\n\nfor model in models:\n    evaluate(model)","a674b6ba":"from sklearn.model_selection import GridSearchCV\nsvm2=SVC()\ngrid={\n    'C': [0.1, 1, 10, 100, 1000],\n    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n    'gamma': [1, 0.1, 0.01, 0.001, 0.0001]\n    \n}","08182819":"svm_grid=GridSearchCV(estimator=svm2,param_grid=grid,cv=3,n_jobs=-1)\nsvm_grid.fit(xtrain,ytrain)","66f54193":"svm_grid.best_params_","901935a2":"svm_grid.score(xtrain,ytrain)","0e4ff476":"svm_grid.score(xtest,ytest)","78dce497":"from sklearn.metrics import confusion_matrix\ny_pred = svm_grid.predict(xtest)\nconf_matrix = confusion_matrix(ytest, y_pred)\nsns.heatmap(conf_matrix, annot = True, fmt='g')","dc8bfa9c":"from sklearn.metrics import classification_report\nprint(classification_report(ytest, y_pred))","b75395c7":"### We can see after using SMOTE we have no duplicates that means now we can safely proceed "}}