{"cell_type":{"2e0b5ec3":"code","2cd8909a":"code","c0bbb04a":"code","5c1a5efd":"code","4216e13c":"code","8ab8a4aa":"code","ea9167e7":"code","adf1d43b":"code","16288578":"code","cdf8da78":"code","3ece8778":"code","f551f3be":"code","5be52903":"code","4e84f246":"code","f625947a":"code","e6dcb71d":"code","52e2ae8e":"code","49d04901":"code","15d5c657":"code","f9e9640d":"code","21432961":"code","73a5bbb5":"code","1e94b567":"code","cebef10e":"code","91a93397":"code","3e5166b9":"code","24908bb7":"code","60298eff":"code","e4ef8f01":"code","12ff3078":"code","3ed1c8d9":"code","b669c934":"code","95fe095a":"code","18418569":"code","c29b96ca":"code","dcabfb10":"code","de40afea":"code","e126c05a":"code","ea55787b":"code","65037b46":"code","1acf3d39":"code","9e51c287":"code","1e1c9b7e":"code","86798952":"code","ea268545":"code","411e0f24":"code","4bff3e65":"code","fd136dd5":"code","1458b033":"code","1d3b8175":"code","f0a4718d":"code","db1f6e08":"code","de40f8ee":"code","784b767e":"code","8cefd13b":"code","ccaed074":"code","d8fd62e2":"code","f5c2230d":"code","28dd5e47":"code","7b0051e2":"code","f73e0c80":"code","12c72b62":"code","4a10364d":"code","af263a26":"code","6d8d9cf3":"code","91578616":"code","ffc21d44":"code","1cfeabe7":"code","55765126":"code","6f935df8":"code","1cc0fe38":"code","ef0b5ce2":"code","52819539":"code","095bcbc5":"code","21ff2754":"code","b5392d88":"code","89fe7f08":"code","f5b75c8d":"code","045cf60f":"code","d8a66aed":"code","1b00f66c":"code","7b70ec51":"code","d944e6c5":"code","b11ca895":"code","e3e6233d":"code","34a53ffe":"code","443f5ee3":"code","1cdebf6a":"code","8f16a440":"code","5f47cd08":"code","1fc6f562":"code","bfcaad69":"code","dac4fa60":"code","2627e26b":"code","408214e1":"markdown","ab4f9899":"markdown","abdf6f50":"markdown","ceef71ef":"markdown","4617ea14":"markdown","4806e9e2":"markdown","189f8783":"markdown","1f58b1dd":"markdown","f8698c03":"markdown","6b1729c6":"markdown","d5444051":"markdown","46393f5d":"markdown","7056ba21":"markdown","0418f123":"markdown","73f6fb57":"markdown","48712de3":"markdown","c3adb51f":"markdown","9737fc27":"markdown","5e5493d4":"markdown","da323992":"markdown","6aeedda3":"markdown","1b321d1e":"markdown","3056e8fd":"markdown","a0d693f4":"markdown","34d90c7b":"markdown","ac6948a8":"markdown","107de2b7":"markdown","f3a5af44":"markdown","e1dd9269":"markdown","608ee4f8":"markdown","234171ab":"markdown","5c006427":"markdown","5407b4c6":"markdown","4664c107":"markdown","aae63f11":"markdown","2bbd7300":"markdown","d713cef9":"markdown","7fcbfe1e":"markdown","ea70ca95":"markdown"},"source":{"2e0b5ec3":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n%matplotlib inline","2cd8909a":"import plotly as py\nimport cufflinks as cf","c0bbb04a":"from plotly.offline import iplot","5c1a5efd":"py.offline.init_notebook_mode(connected=True)\ncf.go_offline()","4216e13c":"df = pd.read_csv('..\/input\/womens-ecommerce-clothing-reviews\/Womens Clothing E-Commerce Reviews.csv', index_col=0)\ndf.head()","8ab8a4aa":"df.drop(labels=['Clothing ID', 'Title'], axis=1, inplace=True)\ndf.head()","ea9167e7":"#Checking null values\ndf.isnull().sum()","adf1d43b":"#Dropping null values\ndf.dropna(subset=['Review Text','Division Name'], inplace= True)","16288578":"df.isnull().sum()","cdf8da78":"contractions = { \n\"ain't\": \"am not\",\n\"aren't\": \"are not\",\n\"can't\": \"cannot\",\n\"can't've\": \"cannot have\",\n\"'cause\": \"because\",\n\"could've\": \"could have\",\n\"couldn't\": \"could not\",\n\"couldn't've\": \"could not have\",\n\"didn't\": \"did not\",\n\"doesn't\": \"does not\",\n\"don't\": \"do not\",\n\"hadn't\": \"had not\",\n\"hadn't've\": \"had not have\",\n\"hasn't\": \"has not\",\n\"haven't\": \"have not\",\n\"he'd\": \"he would\",\n\"he'd've\": \"he would have\",\n\"he'll\": \"he will\",\n\"he'll've\": \"he will have\",\n\"he's\": \"he is\",\n\"how'd\": \"how did\",\n\"how'd'y\": \"how do you\",\n\"how'll\": \"how will\",\n\"how's\": \"how does\",\n\"i'd\": \"i would\",\n\"i'd've\": \"i would have\",\n\"i'll\": \"i will\",\n\"i'll've\": \"i will have\",\n\"i'm\": \"i am\",\n\"i've\": \"i have\",\n\"isn't\": \"is not\",\n\"it'd\": \"it would\",\n\"it'd've\": \"it would have\",\n\"it'll\": \"it will\",\n\"it'll've\": \"it will have\",\n\"it's\": \"it is\",\n\"let's\": \"let us\",\n\"ma'am\": \"madam\",\n\"mayn't\": \"may not\",\n\"might've\": \"might have\",\n\"mightn't\": \"might not\",\n\"mightn't've\": \"might not have\",\n\"must've\": \"must have\",\n\"mustn't\": \"must not\",\n\"mustn't've\": \"must not have\",\n\"needn't\": \"need not\",\n\"needn't've\": \"need not have\",\n\"o'clock\": \"of the clock\",\n\"oughtn't\": \"ought not\",\n\"oughtn't've\": \"ought not have\",\n\"shan't\": \"shall not\",\n\"sha'n't\": \"shall not\",\n\"shan't've\": \"shall not have\",\n\"she'd\": \"she would\",\n\"she'd've\": \"she would have\",\n\"she'll\": \"she will\",\n\"she'll've\": \"she will have\",\n\"she's\": \"she is\",\n\"should've\": \"should have\",\n\"shouldn't\": \"should not\",\n\"shouldn't've\": \"should not have\",\n\"so've\": \"so have\",\n\"so's\": \"so is\",\n\"that'd\": \"that would\",\n\"that'd've\": \"that would have\",\n\"that's\": \"that is\",\n\"there'd\": \"there would\",\n\"there'd've\": \"there would have\",\n\"there's\": \"there is\",\n\"they'd\": \"they would\",\n\"they'd've\": \"they would have\",\n\"they'll\": \"they will\",\n\"they'll've\": \"they will have\",\n\"they're\": \"they are\",\n\"they've\": \"they have\",\n\"to've\": \"to have\",\n\"wasn't\": \"was not\",\n\" u \": \" you \",\n\" ur \": \" your \",\n\" n \": \" and \"}","3ece8778":"# Creating a lamda function to convert contraction form into expanded form\ndef cont_to_exp(x):\n    if type(x) is str:\n        x= x.replace('\\\\','')\n        for key in contractions:\n            value = contractions[key]\n            x= x.replace(key, value)\n        return x\n    else:\n        return x ","f551f3be":"# Testing the function\nx= \"I don't know what date is today, I am 5'8\\\"\"","5be52903":"print(cont_to_exp(x))","4e84f246":"# Applying the function to the text data.\n\ndf['Review Text'] = df['Review Text'].apply(lambda x: cont_to_exp(x))","f625947a":"df.head()","e6dcb71d":"# Printing first 1000 characters as there is exeed in amount of Input\/Output data rate.\nprint(''.join(df['Review Text'].tolist())[:1000])","52e2ae8e":"from textblob import TextBlob","49d04901":"df.head()","15d5c657":"# Calculating the sentiment polarity of the text\ndf['polarity'] = df['Review Text'].apply(lambda x: TextBlob(x).sentiment.polarity)","f9e9640d":"# Calculating the total number of characters\ndf['review_len'] = df['Review Text'].apply(lambda x: len(x))","21432961":"# Calculating the total number of words present in each review text\ndf['review_count'] = df['Review Text'].apply(lambda x: len(x.split()))","73a5bbb5":"# Creating a function for avg word length in each of the reviews\ndef get_avg_word_len(x):\n    words = x.split()\n    word_len = 0\n    for word in words:\n        word_len = word_len + len(word)\n    return word_len\/len(words)","1e94b567":"# Calculating avg word length in each review\ndf['avg_word_len'] = df['Review Text'].apply(lambda x : get_avg_word_len(x))","cebef10e":"df.head()","91a93397":"df.head()","3e5166b9":"df['polarity'].iplot(kind='hist', color='red', bins =50, xTitle ='Polarity', yTitle= 'Count', title ='Sentiment Polarity Distribution')","24908bb7":"df['Rating'].iplot(kind='hist', xTitle='Rating', yTitle='Count', title='Review Rating Distribution')","60298eff":"df['Age'].iplot(kind='hist', bins = 40, xTitle='Age', yTitle='Count', title='Reviewers Age Distribution')","e4ef8f01":"df['review_len'].iplot(kind ='hist', xTitle='Review Length', yTitle='Count', title='Review Text Length Distribution')","12ff3078":"df['review_count'].iplot(kind ='hist', xTitle='Word Count', yTitle='Count', title='Word Count Distrbution')","3ed1c8d9":"df['avg_word_len'].iplot(kind ='hist', xTitle='Avg Word Len', yTitle='Count', title='Review Text Avg Word Length Distrbution')","b669c934":"df.head()","95fe095a":"df['Department Name'].value_counts()","18418569":"df['Department Name'].value_counts().iplot(kind='bar', xTitle='Department Name', yTitle='Count', \n                                          title='Bar Chart of Department Name')","c29b96ca":"df['Division Name'].value_counts().iplot(kind='bar', xTitle='Division Name', yTitle='Count', \n                                          title='Bar Chart of Division Name')","dcabfb10":"df['Class Name'].value_counts().iplot(kind='bar', xTitle='Class Name', yTitle='Count', \n                                          title='Bar Chart of Class Name')","de40afea":"from sklearn.feature_extraction.text import CountVectorizer","e126c05a":"# Creating a function with the help of an example\nx = ['this is the list list this this this']","ea55787b":"vec = CountVectorizer().fit(x) # Creating a vectorizer object\nbow = vec.transform(x) # Encode the document\nsum_words = bow.sum(axis = 0)# Counts the sum of each words\nword_freq = [(word, sum_words[0, idx])for word, idx in vec.vocabulary_.items()] # Creating word frequency\nword_freq = sorted(word_freq, key = lambda x:x[1], reverse = True)# Sorting word frequency in descending order\nword_freq","65037b46":"def get_top_n_words(x,n):\n    vec = CountVectorizer().fit(x) # Creating a vectorizer object\n    bow = vec.transform(x) # Encode the bag of word\n    sum_words = bow.sum(axis = 0)# Counts the sum of each words\n    word_freq = [(word, sum_words[0, idx])for word, idx in vec.vocabulary_.items()] # Creating word frequency\n    word_freq = sorted(word_freq, key = lambda x:x[1], reverse = True)# Sorting word frequency in descending order\n    return word_freq[:n]","1acf3d39":"get_top_n_words(x,3)","9e51c287":"# Using the fucntion to get top 20 words from our Review Text column.\nwords = get_top_n_words(df['Review Text'], 20)\nwords","1e1c9b7e":"# Creating a new dataframe for unigram\ndf1 = pd.DataFrame(words, columns =['Unigram', 'Frequency'])\ndf1 = df1.set_index('Unigram')\ndf1","86798952":"df1.iplot(kind='bar', xTitle='Unigram', yTitle='Frequency', title='Top 20 Unigram words')","ea268545":"def get_top_n_words(x,n):\n    vec = CountVectorizer(ngram_range=(2, 2)).fit(x) # Creating a vectorizer object\n    bow = vec.transform(x) # Encode the bag of word\n    sum_words = bow.sum(axis = 0)# Counts the sum of each words\n    word_freq = [(word, sum_words[0, idx])for word, idx in vec.vocabulary_.items()] # Creating word frequency\n    word_freq = sorted(word_freq, key = lambda x:x[1], reverse = True)# Sorting word frequency in descending order\n    return word_freq[:n]","411e0f24":"get_top_n_words(x,3)","4bff3e65":"# Using the fucntion to get top 20 words from our Review Text column.\nwords = get_top_n_words(df['Review Text'], 20)\nwords","fd136dd5":"# Creating a new dataframe for unigram\ndf1 = pd.DataFrame(words, columns =['Bigram', 'Frequency'])\ndf1 = df1.set_index('Bigram')\ndf1","1458b033":"df1.iplot(kind='bar', xTitle='Bigram', yTitle='Frequency', title='Top 20 Bigram words')","1d3b8175":"def get_top_n_words(x,n):\n    vec = CountVectorizer(ngram_range=(3, 3)).fit(x) # Creating a vectorizer object\n    bow = vec.transform(x) # Encode the bag of word\n    sum_words = bow.sum(axis = 0)# Counts the sum of each words\n    word_freq = [(word, sum_words[0, idx])for word, idx in vec.vocabulary_.items()] # Creating word frequency\n    word_freq = sorted(word_freq, key = lambda x:x[1], reverse = True)# Sorting word frequency in descending order\n    return word_freq[:n]","f0a4718d":"get_top_n_words(x,3)","db1f6e08":"# Using the fucntion to get top 20 words from our Review Text column.\nwords = get_top_n_words(df['Review Text'], 20)\nwords","de40f8ee":"# Creating a new dataframe for unigram\ndf1 = pd.DataFrame(words, columns =['Trigram', 'Frequency'])\ndf1 = df1.set_index('Trigram')\ndf1","784b767e":"df1.iplot(kind='bar', xTitle='Trigram', yTitle='Frequency', title='Top 20 Trigram words')","8cefd13b":"def get_top_n_words(x,n):\n    vec = CountVectorizer(ngram_range=(1, 1), stop_words='english').fit(x) # Creating a vectorizer object\n    bow = vec.transform(x) # Encode the bag of word\n    sum_words = bow.sum(axis = 0)# Counts the sum of each words\n    word_freq = [(word, sum_words[0, idx])for word, idx in vec.vocabulary_.items()] # Creating word frequency\n    word_freq = sorted(word_freq, key = lambda x:x[1], reverse = True)# Sorting word frequency in descending order\n    return word_freq[:n]","ccaed074":"get_top_n_words(x,3)","d8fd62e2":"# Using the fucntion to get top 20 words from our Review Text column.\nwords = get_top_n_words(df['Review Text'], 20)\nwords","f5c2230d":"# Creating a new dataframe for unigram\ndf1 = pd.DataFrame(words, columns =['Unigram', 'Frequency'])\ndf1 = df1.set_index('Unigram')\ndf1","28dd5e47":"df1.iplot(kind='bar', xTitle='Unigram', yTitle='Frequency', title='Top 20 Unigram words')","7b0051e2":"def get_top_n_words(x,n):\n    vec = CountVectorizer(ngram_range=(2, 2), stop_words='english').fit(x) # Creating a vectorizer object\n    bow = vec.transform(x) # Encode the bag of word\n    sum_words = bow.sum(axis = 0)# Counts the sum of each words\n    word_freq = [(word, sum_words[0, idx])for word, idx in vec.vocabulary_.items()] # Creating word frequency\n    word_freq = sorted(word_freq, key = lambda x:x[1], reverse = True)# Sorting word frequency in descending order\n    return word_freq[:n]","f73e0c80":"get_top_n_words(x,3)","12c72b62":"# Using the fucntion to get top 20 words from our Review Text column.\nwords = get_top_n_words(df['Review Text'], 20)\nwords","4a10364d":"# Creating a new dataframe for unigram\ndf1 = pd.DataFrame(words, columns =['Bigram', 'Frequency'])\ndf1 = df1.set_index('Bigram')\ndf1","af263a26":"df1.iplot(kind='bar', xTitle='Bigram', yTitle='Frequency', title='Top 20 Bigram words')","6d8d9cf3":"def get_top_n_words(x,n):\n    vec = CountVectorizer(ngram_range=(3, 3), stop_words='english').fit(x) # Creating a vectorizer object\n    bow = vec.transform(x) # Encode the bag of word\n    sum_words = bow.sum(axis = 0)# Counts the sum of each words\n    word_freq = [(word, sum_words[0, idx])for word, idx in vec.vocabulary_.items()] # Creating word frequency\n    word_freq = sorted(word_freq, key = lambda x:x[1], reverse = True)# Sorting word frequency in descending order\n    return word_freq[:n]","91578616":"# Using the fucntion to get top 20 words from our Review Text column.\nwords = get_top_n_words(df['Review Text'], 20)\nwords","ffc21d44":"# Creating a new dataframe for unigram\ndf1 = pd.DataFrame(words, columns =['Unigram', 'Frequency'])\ndf1 = df1.set_index('Unigram')\ndf1","1cfeabe7":"df1.iplot(kind='bar', xTitle='Trigram', yTitle='Frequency', title='Top 20 Trigram words')","55765126":"import nltk","6f935df8":"nltk.download('punkt')\nnltk.download('averaged_perceptron_tagger')\nnltk.download('tagset')","1cc0fe38":"# Converting dataframe into a string\nblob = TextBlob(str(df['Review Text']))\nblob","ef0b5ce2":"# Representation of tags\nprint(nltk.help.upenn_tagset())","52819539":"blob.tags","095bcbc5":"# Creating a dataframe for Part of Speech\npos_df = pd.DataFrame(blob.tags, columns=['words', 'pos'])\npos_df","21ff2754":"# Count of each Part of Speech\npos_df = pos_df['pos'].value_counts()\npos_df","b5392d88":"pos_df.iplot(kind='bar')","89fe7f08":"sns.pairplot(df)","f5b75c8d":"# Polarity of Division Name.\nsns.catplot(x='Division Name', y='polarity', data=df)","045cf60f":"sns.catplot(x='Division Name', y='polarity', data=df, kind='box')","d8a66aed":"# Polarity of Department Name \nsns.catplot(x='Department Name', y='polarity', data=df)","1b00f66c":"sns.catplot(x='Department Name', y='polarity', data=df, kind='box')","7b70ec51":"sns.catplot(x='Division Name', y='review_len', data=df, kind='box')","d944e6c5":"sns.catplot(x='Department Name', y='review_len', data=df, kind='box')","b11ca895":"import plotly.express as px\nimport plotly.graph_objects as go","e3e6233d":"x1 = df[df['Recommended IND']==1]['polarity']\nx1","34a53ffe":"x0 = df[df['Recommended IND']==0]['polarity']\nx0","443f5ee3":"trace0 = go.Histogram(x= x0, name ='Not Recommended', opacity=0.7)\ntrace1 = go.Histogram(x= x1, name='Recommended', opacity=0.7)","1cdebf6a":"data = [trace0, trace1]\nlayout = go.Layout(barmode='overlay', title='Distribution of Sentiment Polarity of Reviews Based on the Recommendation')\nfig = go.Figure(data=data, layout=layout)\nfig.show()","8f16a440":"x1 = df[df['Recommended IND']==1]['Rating']\nx1","5f47cd08":"x0 = df[df['Recommended IND']==0]['Rating']\nx0","1fc6f562":"trace0 = go.Histogram(x= x0, name ='Not Recommended', opacity=0.7)\ntrace1 = go.Histogram(x= x1, name='Recommended', opacity=0.7)","bfcaad69":"data = [trace0, trace1]\nlayout = go.Layout(barmode='overlay', title='Distribution of Reviews Rating Based on the Recommendation')\nfig = go.Figure(data=data, layout=layout)\nfig.show()","dac4fa60":"sns.jointplot(x='polarity', y='review_len', data = df, kind='kde')","2627e26b":"sns.jointplot(x='polarity', y='Age', data = df, kind='kde')","408214e1":"* Histogram is rightly skewed towards 1 that means most of the reviews are positive.\n* Most of the reviews have the polarity between 0.125 and 0.325 that means most of the customers are satisfied.\n* There are some polarity below zero that means the reviews are negative.","ab4f9899":"### Distribution of Review Text length and Word length","abdf6f50":"## Distribution of Unigram, Bigram and Trigram without Stop words","ceef71ef":"# EDA on Text Data","4617ea14":"* If the polarity is near to +1 then it is a positive review.\n* If the polarity is near to -1 then it is a negative review.\n* If the polarity is close to 0 then it is a neutral review.","4806e9e2":"* Average word length of a review text has maximum of 4 character.\n* There are average word length more than 7 and 8 it might be some long character word or a spelling mistake.","189f8783":"### Text Cleaning","1f58b1dd":"### Unigram","f8698c03":"* Most of the ratings are around 4 and 5 that means customers are positively satisfied.\n* Rating at 3 suggest that the reviews is neutral.\n* Rating at 1 and 2 suggest that the reviews are negative.","6b1729c6":"### Bigram","d5444051":"### Distribution of Department, Division, and Class.","46393f5d":"### Distribution of Top 20 Part of Speech POS tags","7056ba21":"* Maximum reviewers age lies between 35 and 39.\n* Most of the reviewers age is between 30 and 45.","0418f123":"* NN represents Noun. Review text contains max count of noun words.\n* DT represents determiner(such as 'this', 'all'). Determiner has the second most count in the review text.","73f6fb57":"### Trigram","48712de3":"### **Please Upvote if you like the kernel.**","c3adb51f":"### Data Import","9737fc27":"* There is positive correlation between polarity and avg word length, which means as the avg word increases the sentiment of the text also becomes positive.\n* There is also positive correlation between positive feedback count and polarity which means as the positive feedback count is more there is a positive polarity.\n","5e5493d4":"* Jackets, Trend and Dresses has larger review length as compared to Tops and Intimate Departments.","da323992":"* In natural language processing n-gram is a contiguous sequence of n items generated from a given sample of text where the       items can be characters or words and n can be any numbers like 1,2,3, etc.\n\n* Unigrams or 1-grams:\n  To generate 1-grams we pass the value of n=1 in ngrams function of NLTK.\n  \n* Bigrams or 2-grams:\n  For generating 2-grams we pass the value of n=2 in ngrams function of NLTK.\n  \n* Trigrams or 3-grams:\n  In case of 3-grams, we pass the value of n=3 in ngrams function of NLTK.","6aeedda3":"* Median of the Division Name has polarity at 0.25 that means most of the reviews are positive.","1b321d1e":"### Bigram","3056e8fd":"### Bivariate Analysis","a0d693f4":"### Distribution of Sentiment Polarity of Reviews Based on the Recommendation","34d90c7b":"### Distribution of Sentiment Polarity","ac6948a8":"### Distribution of Ratings Based on Recommendation","107de2b7":"* Tops department has maximum reviews.\n* Trend department has minimum reviews.\n* Tops, Bottoms, Dresses together consist the max part of reviews.","f3a5af44":"* Max reviews have the word count between 94 and 103.\n* Other reviews have the word count in the range between 20 and 66.","e1dd9269":"* Max reviews are 500 characters in length.\n* Count is constant between 100 and 300 review length.","608ee4f8":"* Most of the reviews is concentrated at age 35.\n* Polarity of the reviews at age 35 is around 0.25.","234171ab":"### Trigram","5c006427":"* Length of the reviews is heighest at polarity 0.25.\n* Length of the reviews keeps on increasing between polarity 0 to 0.25. After 0.25 polarity the review length keeps on           decreasing.","5407b4c6":"### Feature Engineering","4664c107":"## Women's E-Commerce Clothing reviews","aae63f11":"### Unigram","2bbd7300":"* General Petite and General Division Name has almost similar review length.\n* Initmates has the minimum review length.","d713cef9":"* General Division Name has maximum polarity and also has many negative polarity counts.\n* Initmates has minimum polarity and also has very few negative polarity counts.","7fcbfe1e":"### Distribution  of Reviews Rating and Reviewers Age","ea70ca95":"### Distribution of Unigram, Bigram and Trigram"}}