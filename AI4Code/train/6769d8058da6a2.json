{"cell_type":{"a295cc7d":"code","7cb64394":"code","53c052f3":"code","cae7b78a":"code","7c8e6fc5":"code","46989aa5":"code","4b59f6af":"code","2f21885a":"code","b4823a22":"code","f32c3b9e":"code","7e7a637d":"code","d4ad5f08":"code","4be10056":"code","cb178926":"code","aba3e8ed":"code","723ed6e0":"code","f87ec3ef":"code","75771565":"code","14e76c65":"code","c196d9ce":"code","09176f5f":"code","a931af83":"code","992dbcb8":"code","d70b37da":"code","4a8b73a4":"code","d9318c8d":"code","af2aa09f":"code","1b4c524a":"code","a75b5e89":"code","6a433e0d":"code","bbcdb7e4":"code","e750203e":"code","b130f344":"markdown","9b273450":"markdown","bac11887":"markdown","84dc639b":"markdown","a9e6fbc3":"markdown","0118ea69":"markdown","9aea6514":"markdown","9cef7ff0":"markdown","e2cefac1":"markdown","30512955":"markdown","2fcead33":"markdown","f35d9db8":"markdown","5bdf1713":"markdown","69533148":"markdown","d04cbdb2":"markdown","6868d7c0":"markdown","25c695d4":"markdown","1d6d2023":"markdown","44c984d1":"markdown","8cb22770":"markdown","e71f4266":"markdown","272bbeb6":"markdown","d8ae6156":"markdown","24116b79":"markdown","3cc54373":"markdown","ce189ee5":"markdown","0f4f739a":"markdown","e9ce590e":"markdown"},"source":{"a295cc7d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set()\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","7cb64394":"df=pd.read_csv('..\/input\/titanic\/train.csv',na_values={'Cabin':0},index_col='PassengerId')\ndf.head()","53c052f3":"df.info()","cae7b78a":"df.describe()","7c8e6fc5":"sns.countplot(x='Survived', data=df)","46989aa5":"df.groupby(['Survived','Sex'])['Survived'].count()","4b59f6af":"sns.catplot(x='Sex', col='Survived', kind='count', data=df)","2f21885a":"pd.crosstab(df['Pclass'], df['Survived'], margins=True).style.background_gradient(cmap='autumn_r')","b4823a22":"print(\"% of survivals in\") \nprint(\"Pclass=1 : \", df['Survived'][df['Pclass'] == 1].sum()\/df[df['Pclass'] == 1]['Survived'].count())\nprint(\"Pclass=2 : \", df['Survived'][df['Pclass'] == 2].sum()\/df[df['Pclass'] == 2]['Survived'].count())\nprint(\"Pclass=3 : \", df['Survived'][df['Pclass'] == 3].sum()\/df[df['Pclass'] == 3]['Survived'].count())","f32c3b9e":"pd.crosstab([df['Sex'], df['Survived']], df['Pclass'], margins=True).style.background_gradient(cmap='autumn_r')","7e7a637d":"df = pd.read_csv('..\/input\/titanic\/train.csv',na_values={'Cabin':0})\ndf_test = pd.read_csv('..\/input\/titanic\/test.csv',na_values={'Cabin':0})\ndf_apply = df.copy()","d4ad5f08":"df_apply_x = pd.get_dummies(df_apply, columns=['Sex', 'Embarked', 'Pclass'], drop_first=True)\ndf_apply_x = df_apply_x.drop(['PassengerId','Name','Ticket','Cabin'],axis=1)\ndf_apply_y = df_apply['Survived']\n\ndf_test = pd.get_dummies(df_test, columns=['Sex', 'Embarked', 'Pclass'], drop_first=True)\nsubmission = pd.DataFrame()\nsubmission['PassengerId'] = df_test['PassengerId']\ndf_test = df_test.drop(['PassengerId','Name','Ticket','Cabin'],axis=1)","4be10056":"df_apply_x.head()","cb178926":"df_apply_y.head()","aba3e8ed":"median=df_apply_x['Age'].median()\ndf_apply_x['Age'].fillna(median,inplace=True)\n#df_apply_x['Cabin'][df_apply_x['Cabin']!=1]=0\ndf_apply_x.head()","723ed6e0":"median_test=df_test['Age'].median()\ndf_test['Age'].fillna(median,inplace=True)\n#df_apply_x['Cabin'][df_apply_x['Cabin']!=1]=0\ndf_test.head()","f87ec3ef":"df_apply_x.dropna(inplace=True)\ndf_apply_x.head()","75771565":"df_apply_x.info()","14e76c65":"df_test.info()","c196d9ce":"corr = df_apply_x.corr()\n\nf,ax = plt.subplots(figsize=(9,6))\nsns.heatmap(corr, annot = True, linewidths=1.5 , fmt = '.2f',ax=ax)\nplt.show()","09176f5f":"df_apply_x.fillna(df_apply_x.mean(), inplace=True)\ndf_apply_x = df_apply_x.drop(['Survived'],axis=1)\nX=df_apply_x.values\nY=df_apply_y.values","a931af83":"#from sklearn.model_selection import train_test_split\n#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 1)\nX_train = X\nY_train = Y","992dbcb8":"#print(X_train)\nprint(len(X_train))\n#print(X_test)\n#print(len(X_test))","d70b37da":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)","4a8b73a4":"# for df_test_ml\ndf_test.fillna(df_test.mean(), inplace=True)\n# scaler.fit(df_test_ml)\nscaled_features = sc.transform(df_test)\nX_test = pd.DataFrame(scaled_features, columns=df_test.columns)","d9318c8d":"from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier_KNN = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nclassifier_KNN.fit(X_train, Y_train)","af2aa09f":"Y_pred_KNN = classifier_KNN.predict(X_test)\n#print(confusion_matrix(Y_test, Y_pred_KNN))\n#print(classification_report(Y_test, Y_pred_KNN))\n#print(\"Accuracy: \",accuracy_score(Y_test, Y_pred_KNN)*100, \"%\")","1b4c524a":"from sklearn.linear_model import LogisticRegression\nclassifier_LR = LogisticRegression()\nclassifier_LR.fit(X_train,Y_train)\nY_pred_LR = classifier_LR.predict(X_test)\nprint(confusion_matrix(Y_test, Y_pred_LR))\nprint(classification_report(Y_test, Y_pred_LR))\nprint(\"Accuracy: \",accuracy_score(Y_test, Y_pred_LR)*100 ,\"%\")","a75b5e89":"from sklearn.naive_bayes import GaussianNB\nclassifier_GNB = GaussianNB()\nclassifier_GNB.fit(X_train,Y_train)\nY_pred_GNB = classifier_GNB.predict(X_test)\nprint(confusion_matrix(Y_test,Y_pred_GNB ))\nprint(classification_report(Y_test, Y_pred_GNB))\nprint(\"Accuracy: \",accuracy_score(Y_test, Y_pred_GNB)*100,\" %\")","6a433e0d":"from sklearn.tree import DecisionTreeClassifier\nclassifier_DT= DecisionTreeClassifier()\nclassifier_DT.fit(X_train,Y_train)\nY_pred_DT = classifier_DT.predict(X_test)\nprint(classification_report(Y_test,Y_pred_DT))\nprint(accuracy_score(Y_test, Y_pred_DT))","bbcdb7e4":"from sklearn.ensemble import RandomForestClassifier\nclassifier_RF = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nclassifier_RF.fit(X_train, Y_train)\nY_pred_RF = classifier_RF.predict(X_test)\nprint(classification_report(Y_test,Y_pred_RF))\nprint(\"Accuracy: \",accuracy_score(Y_test, Y_pred_RF)*100, \" %\")","e750203e":"from sklearn.svm import SVC\nclassifier_SVC = SVC(gamma = 0.01, C = 100)#, probability=True)\nclassifier_SVC.fit(X_train, Y_train)\nY_pred_SVC = classifier_SVC.predict(X_test)\n#print(classification_report(Y_test,Y_pred_SVC))\n#print(\"Accuracy: \",accuracy_score(Y_test, Y_pred_SVC)*100, \" %\")\nsubmission['Survived'] = Y_pred_SVC\nsubmission.to_csv('submission.csv',index=False)","b130f344":"Splitting the data into test and training set","9b273450":"##                          **This is my first Kaggle Notebook.**\n**This notebook explores the basic use of Pandas for data analysis and cleaning and scikit-learn for using ML algorithms for this Classifcation problem.**","bac11887":"**Converting data frames into arrays, since our sklearn library ML models takes input in the form of arrays**","84dc639b":"#### Data Cleaning","a9e6fbc3":"**Descision Tree**","0118ea69":"**Is the inference true that Females had Higher Survival Rate in this Incident??\n   Let us see, If yes? Can you come up with a reason justifying this??**","9aea6514":"**Survived and Fare are positively correlated, Survived and Sex_male negatively correlated.\nAlso, Survived and Pclass_3 negatively correlated.\nIf you need to Brush up about what Correlation and Covariance are, just go to StatQuest Youtube Channel, that Guy is just Awesome. BAM!!!**","9cef7ff0":"**Correlation Matrix**","e2cefac1":"**SVM**","30512955":"References:\n\n* Udemy: Machine Learning A to Z: Hands-on Python & R, Team Data Science\n* Krish Naik: Exploratory Data Analysis","2fcead33":"**Gaussian Naive Bayes**","f35d9db8":"#### Let us begin with Exploratory Data Analysis","5bdf1713":"#### Loading the Dataset.","69533148":"**What will you find in this notebook:**\n1. Exploratory Data Analysis on Titanic Dataset.\n    * Understanding the Data\n2. Data Preprocessing.\n    * Handling missing values\n    * Converting categorical features to numerical\n    * Splitting Data to train and test data for ML algorithm\n3. Scikit-learn basic ML algorithms.\n    * implement different Classifiers from the sklearn library like Logistic regression, Gaussian naive Bayes, KNN, Decision tree, Random forest, SVM\n4. Comparison of Model performances.\n    * using performance metrics like confusion_matrix, accuracy_score. ","d04cbdb2":"**Training KNN  model**","6868d7c0":"**Random forest**","25c695d4":"**You got the guess right. The Survival Rate of those people is higher who had tickets of Higher class(i.e. class 1 > class 2, etc.), the reason is again understandable. Maybe the people having tickets of higher class were rich and able to make an escape first by offering money to rescuers.**","1d6d2023":"* **There are 891 entries**\n* **Columns like Age,Cabin has missing values**\n* **Columns like Name, Sex, Cabin, etc has Categorical Data** ","44c984d1":"Removed Label column from X.","8cb22770":"**The reason might be that at the time of disaster, people give preferences to save Women and Children first**","e71f4266":"**Scikit-learn basic ML algorithms**\n* KNN\n* Logistic Regression\n* Naive Bayes\n* SVM\n* Descicon Tree\n* Random Forest","272bbeb6":"**Out of the two labels(survived, or Died) . Let us check how many survived, how many died according to our Data?**","d8ae6156":"**Training Logistic Regression Model**","24116b79":"#### If you find this useful in helping you learn some new things, please upvote and let's begin...","3cc54373":"**Replacing the NaN values in Age column by median of this column and NaN values in cabin by 0.**","ce189ee5":"#### Importing Libraries","0f4f739a":"**Can you come up with a guess of Survival rate with respect to Passenger Class???\n  Let's just see it.**","e9ce590e":"**Thank You!!!**"}}