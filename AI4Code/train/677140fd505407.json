{"cell_type":{"82563e72":"code","d2ff191d":"code","9a61b53c":"code","e83e83ca":"code","865dafe6":"code","f9d30aa1":"code","cdea4e9e":"code","4703d6b6":"code","846414dd":"code","48d7557b":"code","c8d5b878":"code","ec8bff17":"code","2140c248":"code","af621ba0":"code","58c3afb6":"code","e4d94061":"code","6bc0b1b7":"code","1a14be78":"code","7741daf9":"code","447ba03b":"code","ecb60211":"code","2e218da2":"code","24de23bb":"code","535c734f":"code","38a07eca":"code","55069337":"code","d21c73fd":"code","beb34f97":"code","d2bd803c":"code","c2a615d7":"code","0f641f71":"code","520d4a45":"code","d6090c27":"code","4fc1aec1":"markdown","bbaded03":"markdown","85ec22ab":"markdown","519d1aae":"markdown","c2382df0":"markdown","12beca1e":"markdown","94810e9b":"markdown","716caaee":"markdown","a7de0a3f":"markdown","e3593d0e":"markdown","1a81471a":"markdown","29664b61":"markdown","4690fd31":"markdown","150da6d7":"markdown","12e79685":"markdown","b55e935f":"markdown","5a6dcb3a":"markdown","ba125486":"markdown","7ac75028":"markdown","07977386":"markdown","225b2c46":"markdown","4e2015e2":"markdown","978bdfc5":"markdown","006189fd":"markdown","d94d150c":"markdown","59f663a1":"markdown","7b89c6fa":"markdown","94884dcb":"markdown","58fb5b6b":"markdown","54d79dbc":"markdown","13ae34d8":"markdown","e40db1d8":"markdown","66231b43":"markdown","e21f5d2d":"markdown","bb93aebf":"markdown","1badc331":"markdown"},"source":{"82563e72":"# Importing numpy, pandas and Series + DataFrame:\nimport numpy as np\nimport pandas as pd\nfrom pandas import Series, DataFrame\n\n# Imports for plotly:\nimport plotly.graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\n# Imports for plotting:\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\n%matplotlib inline","d2ff191d":"# Importing and loading the iris dataset\niris = pd.read_csv('..\/input\/Iris.csv')","9a61b53c":"# Show first 5 rows of dataset:\nheader = ff.create_table(iris.head())\n\nheader.show()","e83e83ca":"# Check unique values for Species:\nprint(iris['Species'].unique())","865dafe6":"# Function to describe variables\ndef desc(df):\n    d = pd.DataFrame(df.dtypes,columns=['Data_Types'])\n    d = d.reset_index()\n    d['Columns'] = d['index']\n    d = d[['Columns','Data_Types']]\n    d['Missing'] = df.isnull().sum().values    \n    d['Uniques'] = df.nunique().values\n    return d\n\n\ndescr = ff.create_table(desc(iris))\n\ndescr.show()","f9d30aa1":"# Distritution of Species:\n\ns_df = pd.DataFrame(iris.groupby(['Species'])['Species'].count())\n\ndata=go.Bar(x = s_df.index\n           , y = s_df.Species\n           ,  marker=dict( color=['#0e9aa7', '#f6cd61', '#fe8a71'])\n           )\n\n\n\nlayout = go.Layout(title = 'Distribution of Iris Species'\n                   , xaxis = dict(title = 'Species')\n                   , yaxis = dict(title = 'Volume')\n                  )\n\nfig = go.Figure(data,layout)\nfig.show()","cdea4e9e":"# Create a dataset for each of the species:\nsetosa = iris[iris.Species == 'Iris-setosa']\nversicolor = iris[iris.Species == 'Iris-versicolor']\nvirginica = iris[iris.Species == 'Iris-virginica']\n\n# Histogram data for Sepal Length\nhist_data  = [setosa.SepalLengthCm, versicolor.SepalLengthCm, virginica.SepalLengthCm]\n\ngroup_labels = ['setosa', 'versicolor', 'virginica']\ncolors = ['#0e9aa7', '#f6cd61', '#fe8a71']\n\n# Create distplot with curve_type set to 'normal'\nfig = ff.create_distplot(hist_data, group_labels, colors=colors,\n                         bin_size=.1, show_rug=False)\n# Add title\nfig.update_layout(title_text='Histogram for Sepal Length'\n                  , xaxis = dict(title = 'lenght (cm)')\n                  , yaxis = dict(title = 'count')\n                 )\n\n\nfig.show()","4703d6b6":"# Histogram data for Sepal Width\n\nhist_data  = [setosa.SepalWidthCm, versicolor.SepalWidthCm, virginica.SepalWidthCm]\n\ngroup_labels = ['setosa', 'versicolor', 'virginica']\ncolors = ['#0e9aa7', '#f6cd61', '#fe8a71']\n\n# Create distplot with curve_type set to 'normal'\nfig = ff.create_distplot(hist_data, group_labels, colors=colors,\n                         bin_size=.1, show_rug=False)\n# Add title\nfig.update_layout(title_text='Histogram for Sepal Width'\n                  , xaxis = dict(title = 'width (cm)')\n                  , yaxis = dict(title = 'count')\n                 )\n\nfig.show()\n","846414dd":"# Histogram data for Petal Length\n\nhist_data  = [setosa.PetalLengthCm, versicolor.PetalLengthCm, virginica.PetalLengthCm]\n\ngroup_labels = ['setosa', 'versicolor', 'virginica']\ncolors = ['#0e9aa7', '#f6cd61', '#fe8a71']\n\n# Create distplot with curve_type set to 'normal'\nfig = ff.create_distplot(hist_data, group_labels, colors=colors,\n                         bin_size=.1, show_rug=False)\n# Add title\nfig.update_layout(title_text='Histogram for Petal Length'\n                  , xaxis = dict(title = 'lenght (cm)')\n                  , yaxis = dict(title = 'count')\n                 )\n\nfig.show()","48d7557b":"# Histogram data for Petal Width\n\nhist_data  = [setosa.PetalWidthCm, versicolor.PetalWidthCm, virginica.PetalWidthCm]\n\ngroup_labels = ['setosa', 'versicolor', 'virginica']\ncolors = ['#0e9aa7', '#f6cd61', '#fe8a71']\n\n# Create distplot with curve_type set to 'normal'\nfig = ff.create_distplot(hist_data, group_labels, colors=colors,\n                         bin_size=.1, show_rug=False)\n# Add title\nfig.update_layout(title_text='Histogram for Petal Width'\n                  , xaxis = dict(title = 'width (cm)')\n                  , yaxis = dict(title = 'count')\n                 )\n\nfig.show()\n","c8d5b878":"# Scattergraph for Iris Sepal (length vs width):\n\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(\n      x=setosa.SepalLengthCm\n    , y=setosa.SepalWidthCm\n    , name='setosa'\n    , mode='markers'\n    , marker_color='#0e9aa7'\n))\n\nfig.add_trace(go.Scatter(\n      x=versicolor.SepalLengthCm\n    , y=versicolor.SepalWidthCm\n    , name='versicolor'\n    , mode='markers'\n    , marker_color='#f6cd61'\n))\n\nfig.add_trace(go.Scatter(\n      x=virginica.SepalLengthCm\n    , y=virginica.SepalWidthCm\n    , name='virginica'\n    , mode='markers'\n    , marker_color='#fe8a71'\n))\n\n# Set options common to all traces with fig.update_traces\nfig.update_traces(mode='markers'\n                 # , marker_line_width=2\n                  , marker_size=10)\n\nfig.update_layout(title='Iris Sepal (length vs width)'\n                  , xaxis = dict(title = 'length (cm)')\n                  , yaxis = dict(title = 'width (cm)')\n                 )\n\n\nfig.show()","ec8bff17":"# Scattergraph for Iris Petal (length vs width):\n\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(\n      x=setosa.PetalLengthCm\n    , y=setosa.PetalWidthCm\n    , name='setosa'\n    , mode='markers'\n    , marker_color='#0e9aa7'\n))\n\nfig.add_trace(go.Scatter(\n      x=versicolor.PetalLengthCm\n    , y=versicolor.PetalWidthCm\n    , name='versicolor'\n    , mode='markers'\n    , marker_color='#f6cd61'\n))\n\nfig.add_trace(go.Scatter(\n      x=virginica.PetalLengthCm\n    , y=virginica.PetalWidthCm\n    , name='virginica'\n    , mode='markers'\n    , marker_color='#fe8a71'\n))\n\n# Set options common to all traces with fig.update_traces\nfig.update_traces(mode='markers'\n                 # , marker_line_width=2\n                  , marker_size=10)\n\nfig.update_layout(title='Iris Petal (length vs width)'\n                  , xaxis = dict(title = 'length (cm)')\n                  , yaxis = dict(title = 'width (cm)')\n                 )\n\n\nfig.show()","2140c248":"# Plotting the features of our dataset (this gives us density graphs and scatter plots): \n\ncolumns = list(iris.columns)[1:] # remove id column\n\nsns.set(style=\"ticks\")\nsns.pairplot(iris[columns]\n             , hue='Species'\n             , palette=['#0e9aa7', '#f6cd61', '#fe8a71']\n             , diag_kind = 'kde'\n             , height = 2.8)\nplt.show()","af621ba0":"# Box plot for Sepal Length:\n\nfig = go.Figure()\nfig.add_trace(go.Box(y=setosa.SepalLengthCm, name='setosa', marker_color='#0e9aa7'))\nfig.add_trace(go.Box(y=virginica.SepalLengthCm, name='virginica', marker_color='#fe8a71'))\nfig.add_trace(go.Box(y=versicolor.SepalLengthCm, name = 'versicolor',  marker_color='#f6cd61'))\n\nfig.update_layout(title='Sepal Length'\n                  , xaxis = dict(title = 'species')\n                  , yaxis = dict(title = 'length (cm)')\n                 )\n\nfig.show()","58c3afb6":"# Box plot for Sepal Width:\n\nfig = go.Figure()\nfig.add_trace(go.Box(y=setosa.SepalWidthCm, name='setosa', marker_color='#0e9aa7'))\nfig.add_trace(go.Box(y=virginica.SepalWidthCm, name='virginica', marker_color='#fe8a71'))\nfig.add_trace(go.Box(y=versicolor.SepalWidthCm, name = 'versicolor',  marker_color='#f6cd61'))\n\nfig.update_layout(title='Sepal Width'\n                  , xaxis = dict(title = 'species')\n                  , yaxis = dict(title = 'length (cm)')\n                 )\n\nfig.show()","e4d94061":"# Box plot for Petal Length:\n\nfig = go.Figure()\nfig.add_trace(go.Box(y=setosa.PetalLengthCm, name='setosa', marker_color='#0e9aa7'))\nfig.add_trace(go.Box(y=virginica.PetalLengthCm, name='virginica', marker_color='#fe8a71'))\nfig.add_trace(go.Box(y=versicolor.PetalLengthCm, name = 'versicolor',  marker_color='#f6cd61'))\n\nfig.update_layout(title='Petal Length'\n                  , xaxis = dict(title = 'species')\n                  , yaxis = dict(title = 'length (cm)')\n                 )\n\nfig.show()","6bc0b1b7":"# Box plot for Petal Width:\n\nfig = go.Figure()\nfig.add_trace(go.Box(y=setosa.PetalWidthCm, name='setosa', marker_color='#0e9aa7'))\nfig.add_trace(go.Box(y=virginica.PetalWidthCm, name='virginica', marker_color='#fe8a71'))\nfig.add_trace(go.Box(y=versicolor.PetalWidthCm, name = 'versicolor',  marker_color='#f6cd61'))\n\nfig.update_layout(title='Sepal Width'\n                  , xaxis = dict(title = 'species')\n                  , yaxis = dict(title = 'length (cm)')\n                 )\n\nfig.show()","1a14be78":"# Create Parallel Coordinates:\n\ndef spc_id(i):    \n    if i == 'Iris-setosa':\n        return 1\n    elif i == 'Iris-versicolor':\n        return 2\n    else:\n        return 3\n\niris['species_id'] = iris['Species'].apply(spc_id)\niris = iris.drop('Id', axis = 1)\n\n\nfig = px.parallel_coordinates(iris\n                              , color='species_id'\n                              , labels={'species_id':'Species'\n                                        ,'SepalWidthCm':'Sepal Width'\n                                        ,'SepalLengthCm':'Sepal Length'\n                                        ,'PetalWidthCm':'Petal Width'\n                                        ,'PetalLengthCm':'Petal Length'}\n                              , color_continuous_scale = ['#0e9aa7', '#f6cd61', '#fe8a71']\n                              , color_continuous_midpoint=2                           \n                             )\nfig.show()","7741daf9":"from sklearn.model_selection import train_test_split","447ba03b":"# Defining target set y, and a training set X:\ny = iris.Species\nX = iris.drop(['Species','species_id'], axis = 1)\n\n# Split data into train and test part:\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 101)","ecb60211":"# The most important parameter of k-Nearest Neighbors classifier is the number of neighbors, which we will set to 17:\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 17)","2e218da2":"# Fitting the data with knn model:\nknn.fit(X_train, y_train)","24de23bb":"# Using the predict method on KNN to predict values for X_test:\ny_pred = knn.predict(X_test)","535c734f":"print('Test set score {:.2f}'.format(knn.score(X_test,y_test)))","38a07eca":"# Importing classification_method and confusion_matrix:\nfrom sklearn.metrics import classification_report, confusion_matrix","55069337":"# Printing out classification report:\nprint(classification_report(y_test,y_pred))","d21c73fd":"z = confusion_matrix(y_test, y_pred)\n\nx = ['setosa', 'versicolor', 'virginica']\ny = ['setosa', 'versicolor', 'virginica']\n\n# change each element of z to type string for annotations\nz_text = [[str(y) for y in x] for x in z]\n\n# set up figure \nfig = ff.create_annotated_heatmap(z, x=x, y=y, annotation_text=z_text, colorscale='Portland')\n\n# add title\nfig.update_layout(title_text='<i><b>Confusion matrix<\/b><\/i>',\n                  #xaxis = dict(title='x'),\n                  #yaxis = dict(title='x')\n                 )\n\n# add custom xaxis title\nfig.add_annotation(dict(font=dict(color=\"black\",size=14),\n                        x=0.5,\n                        y=-0.15,\n                        showarrow=False,\n                        text=\"Predicted value\",\n                        xref=\"paper\",\n                        yref=\"paper\"))\n\n# add custom yaxis title\nfig.add_annotation(dict(font=dict(color=\"black\",size=14),\n                        x=-0.35,\n                        y=0.5,\n                        showarrow=False,\n                        text=\"Real value\",\n                        textangle=-90,\n                        xref=\"paper\",\n                        yref=\"paper\"))\n\n# adjust margins to make room for yaxis title\nfig.update_layout(margin=dict(t=50, l=200))\n\n# add colorbar\nfig['data'][0]['showscale'] = True\nfig.show()","beb34f97":"# Creating a for loop that trains various KNN models with different K values:\n# Keeping a track of the error_rate for each of these models with a list\nerror_rate = []\n\nfor i in range(1,50,2):\n    \n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))","d2bd803c":"# Line graph for k vs. error rate:\n\nx = list(range(1,50,2))\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=x\n                         , y=error_rate\n                         , mode='lines'\n                         , name='Error Rate line'\n                        )\n             )\n\nfig.add_trace(go.Scatter(x=x\n                         , y=error_rate\n                         , mode='markers'\n                         , name='Error Rate point'\n                        )\n             )\n\nfig.update_layout(title='Line graph for K value vs. Error Rate'\n                  , xaxis_title='K'\n                  , yaxis_title='Error Rate'\n                 )\n\nfig.show()","c2a615d7":"# Using brute force to find best value for K:\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\n\ncv_scores = []\nneighbors = list(np.arange(1,50,2))\nfor n in neighbors:\n    knn = KNeighborsClassifier(n_neighbors = n,algorithm = 'brute')    \n    cross_val = cross_val_score(knn,X_train,y_train,cv = 5 , scoring = 'accuracy')\n    cv_scores.append(cross_val.mean())\n    \nerror = [1-x for x in cv_scores]\noptimal_n = neighbors[ error.index(min(error)) ]\nknn_optimal = KNeighborsClassifier(n_neighbors = optimal_n,algorithm = 'brute')\nknn_optimal.fit(X_train,y_train)\npred = knn_optimal.predict(X_test)\nacc = accuracy_score(y_test,pred)*100\n\nprint(\"The accuracy for optimal K = {0} using brute is {1}\".format(optimal_n,acc))","0f641f71":"# NOW WITH K=5\nknn = KNeighborsClassifier(n_neighbors=5)\n\nknn.fit(X_train,y_train)\npred = knn.predict(X_test)\n\nprint('WITH K=5')\nprint('\\n')\n\nprint(classification_report(y_test,pred))","520d4a45":"# Graph for Decision Boundaries\n\nfrom matplotlib.colors import ListedColormap\nfrom sklearn import neighbors, datasets\n\nn_neighbors = 5\n\n# prepare data\nX=iris.values[:, :2]\ny=iris.species_id\nh = .02\n\n# Create color maps\ncmap_light = ListedColormap(['#0e9aa7', '#f6cd61', '#fe8a71'])\ncmap_bold = ListedColormap(['#154360', '#7D6608', '#900C3F'])\n\n# we create an instance of Neighbours Classifier and fit the data.\nclf = neighbors.KNeighborsClassifier(n_neighbors, weights='distance')\nclf.fit(X, y)\n\n# calculate min, max and limits\nx_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\ny_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\nnp.arange(y_min, y_max, h))\n\n# predict class using data and kNN classifier\nZ = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n\n# Put the result into a color plot\nZ = Z.reshape(xx.shape)\nplt.figure(figsize=(12,7))\nplt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n\n# Plot also the training points\nplt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\n\nplt.title(\"3-Class classification (k = %i)\" % (n_neighbors))\nplt.xlabel('Sepal length')\nplt.ylabel('Sepal width')\n\nplt.show()\n","d6090c27":"z = confusion_matrix(y_test, pred)\n\nx = ['setosa', 'versicolor', 'virginica']\ny = ['setosa', 'versicolor', 'virginica']\n\n# change each element of z to type string for annotations\nz_text = [[str(y) for y in x] for x in z]\n\n# set up figure \nfig = ff.create_annotated_heatmap(z, x=x, y=y, annotation_text=z_text, colorscale='Portland')\n\n# add title\nfig.update_layout(title_text='<i><b>Confusion matrix<\/b><\/i>',\n                  #xaxis = dict(title='x'),\n                  #yaxis = dict(title='x')\n                 )\n\n# add custom xaxis title\nfig.add_annotation(dict(font=dict(color=\"black\",size=14),\n                        x=0.5,\n                        y=-0.15,\n                        showarrow=False,\n                        text=\"Predicted value\",\n                        xref=\"paper\",\n                        yref=\"paper\"))\n\n# add custom yaxis title\nfig.add_annotation(dict(font=dict(color=\"black\",size=14),\n                        x=-0.35,\n                        y=0.5,\n                        showarrow=False,\n                        text=\"Real value\",\n                        textangle=-90,\n                        xref=\"paper\",\n                        yref=\"paper\"))\n\n# adjust margins to make room for yaxis title\nfig.update_layout(margin=dict(t=50, l=200))\n\n# add colorbar\nfig['data'][0]['showscale'] = True\nfig.show()","4fc1aec1":"### Building the model: K-Nearest Neighbors","bbaded03":"**Decision Boundaries**\n\nThe decision boundaries, are shown on the graph below.","85ec22ab":"**Retrain and print classification report**","519d1aae":"### Scatter Plots","c2382df0":"For creating Scatterplot Matrix, we used seaborn visualisation instead od plotly. The colours for species are consistent throuhout this project.","12beca1e":"<img src='https:\/\/images.fineartamerica.com\/images\/artworkimages\/mediumlarge\/3\/spanish-iris-illustration-1827-r1-botany.jpg' width=450 align='center'\/>","94810e9b":"### Retraining the Model with new K-value\n ","716caaee":"Please find below box plots for Sepal and Petal dimensions: ","a7de0a3f":"As we mentioned previously color is consistent for species throuhgout the notebook. To make it easy to read the species key is as follows:\n - 1 setosa\n - 2 versicolor\n - 3 virginica","e3593d0e":"We will now evaluate our model by using classification report and confusion matrix:","1a81471a":"There are three iris species in this dataset: setosa, versicolor and virginica. The dataset consists of 6 columns called: Id, SepalLengthCm, SepalWidthCm, PetalLengthCM, PetalWidthCm and Species.\n\nEach row represents one sample (iris flower), four columns for Sepal&Petal represent measuremnets. Species columns specifie what iris class. Id column is not needed and we can drop it. ","29664b61":"## Importing libraries","4690fd31":"The iris dataset contains 50 samples (rows) for each of the species. Dataset is perfectly balanced :)","150da6d7":"## Loading the Data","12e79685":"## Training and testing data","b55e935f":"# Classifying Iris Species","5a6dcb3a":"**Confusion matrix**","ba125486":"### Scatterplot Matrix","7ac75028":"Let's have a look at model performance when using different values of k by using Error Rate.","07977386":"In this section we will plot data specifically for Sepal(length&width) and Petal(length&width). We can find all scatter plot combinations on Scatterplot Metrics visualisation.","225b2c46":"**Confusion matrix**","4e2015e2":"### Box Plots","978bdfc5":"The botanist wants to use existing data for iris species to classify ireses she finds. In this project we will be using a simple classification algorithm called K-Nearest Neighbor. ","006189fd":"### Model Improvement  - choosing the best K-value\n","d94d150c":"Let's assume that a hobby botanist is interested in distinguishing the species of some iris flowers that she has found. She has collected some measurements associated with each iris: the length and width of the petals and the length and width of the sepals, all measured in centimetres. <br>\n<br>\nShe also has the measurements of some irises that have been previously identified by an expert botanist as belonging to the species setosa, versicolor, or virginica. For these measurements, she can be certain of which species each iris belongs to. Let's assume that these are the only species our hobby botanist will encounter in the wild. <br>\n<br>\nAttribute Information: <br>\n\n1. sepal length in cm <br>\n2. sepal width in cm <br>\n3. petal length in cm <br>\n4. petal width in cm <br>\n5. class: <br>\n-- Iris Setosa <br>\n-- Iris Versicolour <br>\n-- Iris Virginica <br>","59f663a1":"In the following section we will use Exploratory Data Analysis (EDA) to find out more about iris dataset via data visualisation. It's a good practice to get to know your data before applying machine learning algorithms. ","7b89c6fa":"As we can see above, the model performs deffirently for different values of k. But the question is, how to select the right value of K? \n\nFirst at all we will use odd value for K. The reason for this is that it can happen that for K=4 we have two points from class 1 and two points from class 2. What should we do in this case to go for class 1 or class 2? Since we have 3 species (target classes) we will also avoid multiples of 3 as K values.\n\nIf K value is too low, it will cause overfitting and value too high will underfit.","94884dcb":"### Evaluating the model ","58fb5b6b":"For performing machine learning we split data into to parts: test and train. Test size represents 20% of the whole iris dataset. ","54d79dbc":"We can see that we can clearly distinguish setosa species according to it's petal parameters. Virginica and versicolor parameters are overlaping.","13ae34d8":"Optimal value for K = 5.","e40db1d8":"### Parallel Coordinates","66231b43":"### Histograms","e21f5d2d":"## Exploratory Data Analysis (EDA) ","bb93aebf":"**Classification report**","1badc331":"We can see from the table above, that we have no missing values, and that the lenght of dataset is 150 rows\/samples."}}