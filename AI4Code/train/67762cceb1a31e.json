{"cell_type":{"fd77a8d9":"code","7f08f7f4":"code","161782a5":"code","7635c7c1":"code","8bceb0ba":"code","e5d508d4":"code","ec3effdf":"code","4a661b74":"code","78feb24a":"code","e422c306":"code","401d8f1e":"code","4ec56563":"code","753b71cd":"code","5f1e903a":"code","4acae7c2":"code","c08adcfd":"code","7d778e2e":"code","badc501a":"code","fd57428c":"code","9d8ce095":"code","4f278006":"code","e0b2e4dd":"code","8e58b4fb":"code","105da67d":"code","596e3261":"code","fa8dbb04":"code","adec2f1b":"code","76c0c425":"code","98d09fbd":"code","86ee4025":"code","7a41992d":"code","f67378d5":"code","b618150c":"code","345b7936":"code","b6b51c81":"code","b004dcf3":"code","a5cc1ce0":"code","b8661c1f":"code","6b08cf29":"code","ee219e8c":"code","a3234f69":"code","33ea1300":"code","daceeb2b":"code","0b99285a":"code","fef7feb7":"code","29e03c93":"code","0dc11541":"code","df7cbfcc":"code","7fd8635a":"code","62a7653b":"code","bcb635e0":"code","5018f91f":"code","0617a1ce":"code","8a927f50":"code","7976defb":"code","48169557":"code","155a392d":"code","be5dff15":"code","7a59013e":"code","c9fd2bbb":"code","e194bce0":"code","1941280e":"code","2c07008b":"code","a72f18ab":"code","af720ad8":"code","913101c5":"code","5efd915f":"code","af39f30e":"code","85d62427":"code","d3a16938":"code","572954b3":"code","5b1625f2":"code","e83c001d":"code","e22674b0":"code","b63be8c8":"code","ec8ba176":"code","a03e684f":"code","1d6ac9ef":"code","434ac435":"markdown","146fd670":"markdown","8b56e7c2":"markdown","d9ba1666":"markdown","2a3e50bb":"markdown","638c30a7":"markdown","729b6d8f":"markdown","768175d2":"markdown","8541d969":"markdown","80eaec5c":"markdown","e78d768d":"markdown","96208478":"markdown","152e264c":"markdown","35a01e6b":"markdown","7eb77e0c":"markdown","ececa3db":"markdown","f464d4d4":"markdown","27484748":"markdown","38b46112":"markdown","de8b3402":"markdown","3c099c48":"markdown","43fbcac8":"markdown","b6a29e7e":"markdown","fde92a04":"markdown","c3d460fb":"markdown","d6d3d5b5":"markdown"},"source":{"fd77a8d9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport os\nimport json\nimport ast\nimport numpy as np\nimport pandas as pd\nfrom pandas.io.json import json_normalize\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\n\n%matplotlib inline\n\nfrom plotly import tools\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport seaborn as sns\nplt.rcParams['axes.grid'] = True\n\nfrom sklearn import model_selection, preprocessing, metrics\nimport lightgbm as lgb\n\nnp.random.seed(seed=45)\n\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","7f08f7f4":"!ls ..\/input\/","161782a5":"def load_df(csv_path='..\/input\/train_v2.csv',nrows=None):\n    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n    \n    df = pd.read_csv(csv_path, \n                     converters={column: json.loads for column in JSON_COLUMNS}, \n                     dtype={'fullVisitorId': 'str'},\n                     nrows=nrows)\n    print('nrows: %d',nrows)\n    \n    for column in JSON_COLUMNS:\n        column_as_df = json_normalize(df[column])\n        column_as_df.columns = [f\"{column}_{subcolumn}\" for subcolumn in column_as_df.columns]\n        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n    print(f\"Loaded {os.path.basename(csv_path)}. Shape: {df.shape}\")\n    return df","7635c7c1":"%%time\ntrain_df = load_df(nrows=3*pow(10,5))\n#test_df = load_df(\"..\/input\/test.csv\")","8bceb0ba":"train_df.shape","e5d508d4":"train_df.sample(n=5)","ec3effdf":"train_df.drop_duplicates(inplace=True)\ntrain_df.shape","4a661b74":"missing_df = (train_df.isna().sum()\/train_df.shape[0])*100\nmissing_df = missing_df.loc[missing_df.values > 20]\nmissing_df","78feb24a":"ratio_of_conversion = train_df['totals_transactionRevenue'].notnull().sum()\/train_df.shape[0]\nprint('Only %f percent of visits are converted into revenue' % (ratio_of_conversion*100))","e422c306":"train_df.customDimensions.sample(n=10)","401d8f1e":"train_df.drop(columns='customDimensions', inplace=True)","4ec56563":"train_df.head()","753b71cd":"train_df.hits.sample(n=1, random_state=42).values","5f1e903a":"hits_dict = ast.literal_eval(train_df.hits.sample(n=1, random_state=42).values[0])[0]\ndisplay(hits_dict)","4acae7c2":"train_df.drop(columns='hits', inplace=True)","c08adcfd":"train_df.sample(n=5)","7d778e2e":"# Fill the NA values with 'nan' for tracking the nan values in groupby functions\ntrain_df.fillna('nan',inplace=True)","badc501a":"# remove the missing columns we got\n#train_df = train_df.drop(columns=missing_df.index)","fd57428c":"# Find columns with only one unique value and drop them\nconstant_columns = [ c for c in train_df.columns if train_df[c].nunique(dropna=False)==1]\ndisplay(constant_columns)\ntrain_df.drop(columns=constant_columns, inplace=True)","9d8ce095":"train_df.head()","4f278006":"train_df.dtypes","e0b2e4dd":"train_df.totals_bounces.describe()","8e58b4fb":"train_df['totals_bounces'] = train_df.totals_bounces.apply(lambda x: 0 if x=='nan' else x)\ntrain_df['totals_bounces'] = train_df['totals_bounces'].astype('int16')","105da67d":"train_df.totals_hits.describe()","596e3261":"train_df.totals_pageviews.describe()","fa8dbb04":"train_df.totals_sessionQualityDim.describe()","adec2f1b":"# If a new visit is nan it can be 1 but then it becomes only one value, so we can drop this column\ndisplay(train_df['totals_newVisits'].unique())\ntrain_df.drop(columns='totals_newVisits', inplace=True)","76c0c425":"# I find it safe to put 0 for nan values because those could be bots that visits the website\ndisplay(train_df['totals_timeOnSite'].describe())\nprint('Top 5 most common values for totals_timeOnSite: ')\ndisplay(train_df.groupby('totals_timeOnSite').size().sort_values(ascending=False)[:5])\ntrain_df['totals_timeOnSite'] = train_df.totals_timeOnSite.apply(lambda x: 0 if x=='nan' else x)\ntrain_df['totals_timeOnSite'] = train_df['totals_timeOnSite'].astype('int64')","98d09fbd":"# A minimum hit in a visit can be 1 and 1 is also the mode number\ntrain_df['totals_hits'] = train_df.totals_hits.apply(lambda x: 1 if x=='nan' else x)\ntrain_df['totals_hits'] = train_df['totals_hits'].astype('int64')\n# minimum pageview can be 1 for a visit and mode is also 1\ntrain_df['totals_pageviews'] = train_df.totals_pageviews.apply(lambda x: 1 if x=='nan' else x)\ntrain_df['totals_pageviews'] = train_df['totals_pageviews'].astype('int64')\n# sessionQuality represents a score between 1-100 that shows how close is the user to the conversion to a transaction in the website\ntrain_df['totals_sessionQualityDim'] = train_df.totals_sessionQualityDim.apply(lambda x: 1 if x=='nan' else x)\ntrain_df['totals_sessionQualityDim'] = train_df['totals_sessionQualityDim'].astype('int16')\n# When transaction variables are 'nan' we considered them transaction has not been made by the user, so 0 is the appropriate number\ntrain_df['totals_totalTransactionRevenue'] = train_df.totals_totalTransactionRevenue.apply(lambda x: 0 if x=='nan' else x)\ntrain_df['totals_totalTransactionRevenue'] = train_df['totals_totalTransactionRevenue'].astype('int64')\ntrain_df['totals_transactionRevenue'] = train_df.totals_transactionRevenue.apply(lambda x: 0 if x=='nan' else x)\ntrain_df['totals_transactionRevenue'] = train_df['totals_transactionRevenue'].astype('int64')\ntrain_df['totals_transactions'] = train_df.totals_transactions.apply(lambda x: 0 if x=='nan' else x)\ntrain_df['totals_transactions'] = train_df['totals_transactions'].astype('int64')","86ee4025":"# We can set 'nan' to None which represents a direct connection to website, not through google adWords then convert it to a category variable\n# as per its stated https:\/\/support.google.com\/analytics\/answer\/3437719?hl=en\ndisplay(train_df['trafficSource_adwordsClickInfo.adNetworkType'].unique())\ntrain_df['trafficSource_adwordsClickInfo.adNetworkType'] = train_df['trafficSource_adwordsClickInfo.adNetworkType'].apply(lambda x: 'None' if x=='nan' else x)\n# rename the column for easy reference\ntrain_df.rename(columns={'trafficSource_adwordsClickInfo.adNetworkType':'trafficSource_adwords_adNetworkType'}, inplace=True)","7a41992d":"# Fix the adContent variable, by converting 'nan' to None since user visits website without going through an ad campaign\ndisplay(train_df['trafficSource_adContent'].describe())\nadContent_series = train_df.groupby('trafficSource_adContent').size().sort_values(ascending=False)\nmost_common_sources = adContent_series[adContent_series.cumsum() < train_df.shape[0]*0.95].index\ntrain_df.trafficSource_adContent = train_df.trafficSource_adContent.apply(lambda x: x if x in most_common_sources else 'others')\ntrain_df.trafficSource_adContent.describe()\ntrain_df.drop(columns='trafficSource_adContent', inplace=True)","f67378d5":"# trafficSource_adwordsClickInfo.gclId represents google click ID, we can drop it as it is not related with revenue generation and it is not\n# easily interpreted by humans\ndisplay(train_df['trafficSource_adwordsClickInfo.gclId'].unique())\ntrain_df.drop(columns='trafficSource_adwordsClickInfo.gclId', inplace=True)","b618150c":"# trafficSource_adwordsClickInfo.isVideoAd shows whether the user is coming from a video ad\ndisplay(train_df['trafficSource_adwordsClickInfo.isVideoAd'].unique())","345b7936":"# converting the name of the column for convenience and convert 'nan' to Unknown\ntrain_df.rename(columns={'trafficSource_adwordsClickInfo.isVideoAd':'trafficSource_adwords_isVideoAd'}, inplace=True)\ntrain_df['trafficSource_adwords_isVideoAd'] = train_df.trafficSource_adwords_isVideoAd.apply(lambda x: 'Unknown' if x=='nan' else x)","b6b51c81":"# This column is an ordinal variable, we will replace 'nan' with -1\ndisplay(train_df['trafficSource_adwordsClickInfo.page'].unique())\ntrain_df.rename(columns={'trafficSource_adwordsClickInfo.page':'trafficSource_adwordsClickInfo_page'}, inplace=True)\ntrain_df['trafficSource_adwordsClickInfo_page'] = train_df.trafficSource_adwords_isVideoAd.apply(lambda x: 'Not given' if x=='nan' else x)","b004dcf3":"train_df.drop(columns=['trafficSource_adwordsClickInfo.slot','trafficSource_campaignCode'], inplace=True)","a5cc1ce0":"# too many unique keywords exist and 95% is missing -> dropping the column\ndisplay(train_df['trafficSource_keyword'].describe())\ntrain_df.drop(columns='trafficSource_keyword',inplace=True)","b8661c1f":"# since there are too many unique values and more than 60% of the data is missing, I am removing this column\ndisplay(train_df['trafficSource_referralPath'].unique())\ndisplay(train_df['trafficSource_referralPath'].describe())\ntrain_df.drop(columns='trafficSource_referralPath',inplace=True)","6b08cf29":"# there are too many unique values for a categorical variable we need to decrease this number by making a histogram of most common sources\ndisplay(train_df['trafficSource_source'].describe())","ee219e8c":"sources_series = (train_df.groupby('trafficSource_source').size().sort_values()\/train_df.shape[0])*100\n\ntrace1 = go.Bar(\n            x=sources_series.values,\n            y=sources_series.index,\n            marker = dict(color = 'rgba(100, 155, 15, 1.0)'),\n            orientation = 'h',\n            name='percentage'\n)\n\n\nlayout = go.Layout(title='% representation of each unique trafficSource category',\n                   height=3000,\n                   width=1000,\n                   margin = dict(l=300,r=100,t=140, b=80),\n                   xaxis=dict(title='categories'),\n                   yaxis=dict(title='percentage')\n)\n\nfig = go.Figure(data=[trace1], layout=layout)\npy.iplot(fig, filename='Revenue generation with pageviews')","a3234f69":"# By analysis of the above plot, categories covering 95% of all sessions considered enough for representation\nmost_common_sources = sources_series[sources_series.cumsum() < train_df.shape[0]*0.98].index\ntrain_df.trafficSource_source = train_df.trafficSource_source.apply(lambda x: x if x in most_common_sources else 'others')\ntrain_df.trafficSource_source.describe()","33ea1300":"\ndisplay(train_df.trafficSource_isTrueDirect.unique())\ntrain_df.trafficSource_isTrueDirect = train_df.trafficSource_isTrueDirect.apply(lambda x: 'Unknown' if x == 'nan' else x)","daceeb2b":"cities_series = (train_df.groupby('geoNetwork_city').size().sort_values()\/train_df.shape[0])*100\n\ntrace1 = go.Bar(\n            x=cities_series.values,\n            y=cities_series.index,\n            marker = dict(color = 'rgba(100, 175, 115, 1.0)'),\n            orientation = 'h',\n            name='percentage'\n)\n\n\nlayout = go.Layout(title='% representation of each unique trafficSource category',\n                   height=3000,\n                   width=1000,\n                   margin = dict(l=300,r=100,t=140, b=80),\n                   xaxis=dict(title='categories'),\n                   yaxis=dict(title='percentage')\n)\n\nfig = go.Figure(data=[trace1], layout=layout)\npy.iplot(fig, filename='Revenue generation with pageviews')","0b99285a":"cities_series = train_df.groupby('geoNetwork_city').size().sort_values(ascending=False)\nmost_common_cities = cities_series[cities_series.cumsum() < train_df.shape[0]*0.80].index\ntrain_df.geoNetwork_city = train_df.geoNetwork_city.apply(lambda x: x if x in most_common_cities else 'others')\ndisplay(train_df['geoNetwork_city'].nunique())","fef7feb7":"# Nominal variables\ntrain_df['channelGrouping'] = train_df['channelGrouping'].astype('category')\ntrain_df['device_browser'] = train_df['device_browser'].astype('category')\ntrain_df['device_deviceCategory'] = train_df['device_deviceCategory'].astype('category')\ntrain_df['device_operatingSystem'] = train_df['device_operatingSystem'].astype('category')\ntrain_df['geoNetwork_city'] = train_df['geoNetwork_city'].astype('category')\ntrain_df['geoNetwork_continent'] = train_df['geoNetwork_continent'].astype('category')\ntrain_df['geoNetwork_metro'] = train_df['geoNetwork_metro'].astype('category')\ntrain_df['geoNetwork_region'] = train_df['geoNetwork_region'].astype('category')\ntrain_df['geoNetwork_subContinent'] = train_df['geoNetwork_subContinent'].astype('category')\ntrain_df['trafficSource_medium'] = train_df['trafficSource_medium'].astype('category')\ntrain_df['trafficSource_adwords_adNetworkType'] = train_df['trafficSource_adwords_adNetworkType'].astype('category')\ntrain_df['trafficSource_adwords_isVideoAd'] = train_df['trafficSource_adwords_isVideoAd'].astype('category')\ntrain_df['trafficSource_source'] = train_df['trafficSource_source'].astype('category')\ntrain_df['trafficSource_isTrueDirect'] = train_df['trafficSource_isTrueDirect'].astype('category')","29e03c93":"train_df.sample(n=5)","0dc11541":"# fix the date format\nimport datetime\n# convert string formatted date to datetime object\ntrain_df['date'] = train_df['date'].apply(lambda x: datetime.date(int(str(x)[:4]), int(str(x)[4:6]), int(str(x)[6:])))\n# we still use to_datetime so that pandas can know it is Datetime\ntrain_df['date'] = pd.to_datetime(train_df['date'],yearfirst=True)","df7cbfcc":"# set an index column\n#train_df.set_index(['fullVisitorId', 'visitId'], inplace=True)\n#train_df.reset_index(inplace=True)","7fd8635a":"train_df.sample(n=5)","62a7653b":"train_df.rename(columns={'device_browser': 'browser', 'device_deviceCategory':'deviceCategory', 'device_isMobile':'isMobile',\n                        'device_operatingSystem': 'operatingSystem', 'geoNetwork_city':'city', 'geoNetwork_continent': 'continent',\n                        'geoNetwork_country':'country', 'geoNetwork_metro':'metro', 'geoNetwork_networkDomain':'networkDomain',\n                        'geoNetwork_region':'region', 'totals_bounces':'bounces', 'totals_hits':'hits', 'totals_pageviews':'pageviews',\n                        'totals_sessionQualityDim':'sessionQuality', 'totals_timeOnSite':'timeOnSite', 'totals_totalTransactionRevenue':'totalTransactionRevenue',\n                        'totals_transactionRevenue':'transactionRevenue', 'totals_transactions':'transactions', 'trafficSource_adwords_adNetworkType':'adwords_adNetworkType',\n                        'trafficSource_adwords_isVideoAd':'adwords_isVideoAd', 'trafficSource_adwordsClickInfo_page': 'adwords_pageNumber'}, inplace=True)","bcb635e0":"train_df.head()","5018f91f":"train_df[\"transactionRevenue\"] = train_df[\"transactionRevenue\"].astype(\"float\")\ngdf = train_df.groupby([\"fullVisitorId\"])[\"transactionRevenue\"].sum().reset_index()\ndisplay(gdf.sample(5))\nplt.figure(figsize= (8,6))\nplt.scatter(range(gdf.shape[0]), np.sort(np.log1p(gdf[\"transactionRevenue\"].values)))\nplt.xlabel('index', fontsize=12)\nplt.ylabel('TransactionRevenue', fontsize=12)\nplt.show()","0617a1ce":"nzi = pd.notnull(train_df[\"transactionRevenue\"]).sum()\nnzr = (gdf[\"transactionRevenue\"]>0).sum()\nprint(\"Number of instances in train set with non-zero revenue : \", nzi, \" and ratio is : \", nzi \/ train_df.shape[0])\nprint(\"Number of unique customers with non-zero revenue : \", nzr, \"and the ratio is : \", nzr \/ gdf.shape[0])","8a927f50":"# According to \ntrain_df['transactionRevenue'].describe()","7976defb":"plt.figure(figsize=(12,6))\n# I tried to scale the transactionRevenue variable to be able to get a distribution of transactions' values. \n# I will not use this as a label as it squeezes the distribution\n# Why divide by 10**6 check: https:\/\/support.google.com\/analytics\/answer\/3437719?hl=en\ny = train_df['transactionRevenue']\/10**6\nmask = (y>0) & (y < 1000)\nrevenue_df = y[mask]\n\n\nn, bins, patches = plt.hist(revenue_df.values, 100, facecolor='b', alpha=0.75)\nplt.xticks(rotation='horizontal')\nplt.xlabel('Transaction revenue', fontsize=12)\nplt.ylabel('Number of Transactions', fontsize=12)\nplt.show()","48169557":"mask = (y > 1000)\ntotal_revenue_1000 = y[mask].sum()\ntotal_revenue = y.sum()\n\ndata_dict = {'Number of transactions over 1000 USD revenues': mask.sum(),\n             'Percent total revenue' : [np.round(total_revenue_1000\/total_revenue*100,2)]}\ntail_df = pd.DataFrame(data=data_dict)\ntail_df","155a392d":"def scatter_plot(cnt_srs, color, name):\n    trace = go.Scatter(\n        x=cnt_srs.index[::-1],\n        y=cnt_srs.values[::-1],\n        showlegend=False,\n        marker=dict(\n            color=color,\n        ),\n        name = name\n    )\n    return trace\n\n\ntrans_per_day = train_df.groupby('date')['transactionRevenue'].agg(['sum','count'])\ntrans_per_day.columns = [\"revenue\", \"session count\"]\ntrans_per_day = trans_per_day.sort_index()\n\n\nnon_zero_trans = train_df[train_df['transactionRevenue']>0]\nnon_zero_trans_per_day = non_zero_trans.groupby('date')['transactionRevenue'].agg(['count'])\nnon_zero_trans_per_day.columns = [\"count of non-zero revenue\"]\nnon_zero_trans_per_day = non_zero_trans_per_day.sort_index()\n\n\ntrace1 = scatter_plot(trans_per_day[\"revenue\"]\/10**6, 'red','Session count')\ntrace2 = scatter_plot(trans_per_day[\"session count\"], 'blue','Session count')\ntrace3 = scatter_plot(non_zero_trans_per_day[\"count of non-zero revenue\"], 'green','Session count')\n\nfig = tools.make_subplots(rows=3, cols=1, vertical_spacing=0.08, horizontal_spacing=0.08,\n                          subplot_titles=[\"Date - Revenue\", \"Date - Session count\", \"Date - Non-zero revenue\"])\nfig.append_trace(trace1, 1, 1)\nfig.append_trace(trace2, 2, 1)\nfig.append_trace(trace3, 3, 1)\nfig['layout'].update(height=1000, width=1000,title=\"Date Plots\")\nfig['layout']['xaxis1'].update(title='dates')\nfig['layout']['xaxis2'].update(title='dates')\nfig['layout']['xaxis3'].update(title='dates')\n\npy.iplot(fig, filename='date-plots')","be5dff15":"# Check date has any NaNs\ntrain_df['date'].isnull().any()","7a59013e":"# First convert date to weekdays\ntrain_df['weekday'] = train_df['date'].dt.day_name()\ntrain_df['weekday'].unique()","c9fd2bbb":"session_df = train_df.groupby('weekday')['fullVisitorId'].nunique()\nrevenue_df = train_df.groupby('weekday')['transactionRevenue'].sum()\/10**6\n\n\nplt.figure(figsize=(12,4))\n#plot the transaction distribution by month\nsns.barplot(session_df.index, session_df.values, alpha=0.8, color=color[2])\nplt.xticks(rotation='vertical')\nplt.xlabel('Weekday of sessions', fontsize=12)\nplt.ylabel('Number of sessions', fontsize=12)\nplt.show()\n\nplt.figure(figsize=(12,4))\nsns.barplot(revenue_df.index, revenue_df.values, alpha=0.8, color=color[6])\nplt.xticks(rotation='vertical')\nplt.xlabel('Weekday of sessions', fontsize=12)\nplt.ylabel('Total Revenue', fontsize=12)\nplt.show()\n","e194bce0":"# First convert date to Months\ntrain_df['month'] = train_df['date'].dt.month_name()\ntrain_df['month'].unique()","1941280e":"session_df = train_df.groupby('month')['fullVisitorId'].nunique()\nrevenue_df = train_df.groupby('month')['transactionRevenue'].sum()\/10**6\n\n\nplt.figure(figsize=(12,4))\n#plot the transaction distribution by month\nsns.barplot(session_df.index, session_df.values, alpha=0.8, color=color[1])\nplt.xticks(rotation='vertical')\nplt.xlabel('Month of sessions', fontsize=12)\nplt.ylabel('Number of sessions', fontsize=12)\nplt.show()\n\nplt.figure(figsize=(12,4))\nsns.barplot(revenue_df.index, revenue_df.values, alpha=0.8, color=color[3])\nplt.xticks(rotation='vertical')\nplt.xlabel('Month of sessions', fontsize=12)\nplt.ylabel('Total Revenue', fontsize=12)\nplt.show()","2c07008b":"#First check if theres any null for channelGrouping\ntrain_df['channelGrouping'].isnull().any()","a72f18ab":"session_df = train_df.groupby('channelGrouping')['fullVisitorId'].nunique()\nsession_df.sort_values(ascending=False, inplace=True)\n\nrevenue_df = train_df.groupby('channelGrouping')['transactionRevenue'].sum()\/10**6\n\nplt.figure(figsize=(12,4))\n#plot the transaction distribution by month\nsns.barplot(session_df.index, session_df.values, alpha=0.8, color='dodgerblue')\nplt.xticks(rotation='horizontal')\nplt.xlabel('Channel Groupings', fontsize=12)\nplt.ylabel('Number of sessions', fontsize=12)\nplt.show()\n\nplt.figure(figsize=(12,4))\n#plot the transaction distribution by month\nsns.barplot(revenue_df.index, revenue_df.values, alpha=0.8, color='yellowgreen')\nplt.xticks(rotation='horizontal')\nplt.xlabel('Channel Groupings', fontsize=12)\nplt.ylabel('Total Revenue', fontsize=12)\nplt.show()","af720ad8":"session_df = train_df.groupby('deviceCategory')['fullVisitorId'].nunique()\nrevenue_df = train_df.groupby('deviceCategory')['transactionRevenue'].sum()\/10**6\n\n\ndata1 = go.Bar(\n            x=session_df.values,\n            y=session_df.index,\n            orientation = 'h',\n            marker = dict(color = 'rgba(246, 78, 139, 1.0)'),\n            name='session count'\n)\n\ndata2 = go.Bar(\n            x=revenue_df.values,\n            y=revenue_df.index,\n            orientation = 'h',\n            name='revenue(in dollars)'\n)\n\nfig = tools.make_subplots(rows=1, cols=2)\nfig['layout'].update(height=400, width=800, title='Session and Revenue generation per device segment')\nfig['layout']['xaxis1'].update(title='Session Count')\nfig['layout']['xaxis2'].update(title='Revenue (in USD)')\n\nfig.append_trace(data1, 1, 1)\nfig.append_trace(data2, 1, 2)\npy.iplot(fig, filename='simple-subplot-with-annotations')","913101c5":"session_df = train_df.groupby('operatingSystem')['fullVisitorId'].nunique()\nrevenue_df = train_df.groupby('operatingSystem')['transactionRevenue'].sum()\/10**6\n\n# sort and pick top 7\nsession_df = session_df[session_df.index != \"(not set)\"]\nsession_df = session_df.sort_values(ascending=False)[:7]\ndisplay(session_df.index.values)\n\nrevenue_df = revenue_df[revenue_df.index != \"(not set)\"]\nrevenue_df = revenue_df.sort_values(ascending=False)[:7]\n\n\ndata1 = go.Bar(\n            x=session_df.values,\n            y=session_df.index,\n            orientation = 'h',\n            marker = dict(color = 'rgba(246, 78, 25, 1.0)'),\n            name='session count'\n)\n\ndata2 = go.Bar(\n            x=revenue_df.values,\n            y=revenue_df.index,\n            orientation = 'h',\n            marker = dict(color = 'rgba(115, 20, 139, 1.0)'),\n            name='revenue'\n)\n\nfig = tools.make_subplots(rows=1, cols=2)\nfig['layout'].update(height=400, width=800, title='Session and Revenue generation per OS')\nfig['layout']['xaxis1'].update(title='Session Count')\nfig['layout']['xaxis2'].update(title='Total Revenue (in USD)')\n\nfig.append_trace(data1, 1, 1)\nfig.append_trace(data2, 1, 2)\npy.iplot(fig, filename='Session and Revenue generation per OS')\n\n","5efd915f":"browser_df = train_df.groupby('browser')['fullVisitorId'].nunique()\nbrowser_df = browser_df.sort_values(ascending=False)[:15]\n\nbrowser_revenue_df = train_df.groupby('browser')['transactionRevenue'].sum()\/10**6\nbrowser_revenue_df = browser_revenue_df.sort_values(ascending=False)[:15]\n\ndata1 = go.Bar(\n            x=browser_df.values,\n            y=browser_df.index,\n            orientation = 'h',\n            marker = dict(color = 'rgba(225, 55, 25, 1.0)'),\n            name='session count'\n)\n\ndata2 = go.Bar(\n            x=browser_revenue_df.values,\n            y=browser_revenue_df.index,\n            orientation = 'h',\n            marker = dict(color = 'rgba(200, 20, 139, 1.0)'),\n            name='revenue'\n)\n\nfig = tools.make_subplots(rows=1, cols=2)\nfig['layout'].update(height=800, width=1000, title='Session and Revenue generation per Browser')\nfig['layout']['xaxis1'].update(title='Session Count')\nfig['layout']['xaxis2'].update(title='Total Revenue (in USD)')\n\nfig.append_trace(data1, 1, 1)\nfig.append_trace(data2, 1, 2)\npy.iplot(fig, filename='Session and Revenue generation per OS')\n","af39f30e":"revenue_df = train_df.groupby('pageviews')['transactionRevenue'].sum()\/10**6\nrevenue_df = revenue_df.sort_values(ascending=False)\n\ndata1 = go.Bar(\n            x=revenue_df.index,\n            y=revenue_df.values,\n            marker = dict(color = 'rgba(225, 55, 25, 1.0)'),\n            name='revenue'\n)\n\nlayout = go.Layout(title='Revenue generation with pageviews',\n                   height=400,\n                   width=800,\n                   xaxis=dict(title='Pageviews'),\n                   yaxis=dict(title='Revenue (in USD)')\n)\n\nfig = go.Figure(data=[data1], layout=layout)\npy.iplot(fig, filename='Revenue generation with pageviews')","85d62427":"train_df.head()","d3a16938":"top_k_countries = 20\ncountry_df = train_df.groupby('country')['fullVisitorId'].nunique()\ncountry_df = country_df.sort_values(ascending=False)[:top_k_countries]\ncountry_revenue_df = train_df.groupby('country')['transactionRevenue'].sum()\/10**6\ncountry_revenue_df = country_revenue_df.sort_values(ascending=False)[:top_k_countries]\n\ntrace1 = go.Bar(\n            x=country_df.values,\n            y=country_df.index,\n            marker = dict(color = 'rgba(55, 55, 125, 1.0)'),\n            orientation = 'h',\n            name='session count'\n)\n\ntrace2 = go.Bar(\n            x=country_revenue_df.values,\n            y=country_revenue_df.index,\n            marker = dict(color = 'rgba(55, 155, 25, 1.0)'),\n            orientation = 'h',\n            name='revenue'\n)\n\nfig = tools.make_subplots(rows=1, cols=2)\nfig['layout'].update(height=800, width=1000, title='Session and Revenue generation per Country')\nfig['layout']['margin'].update(l=120,r=10,t=140, b=80 )\nfig['layout']['xaxis1'].update(title='Session Count')\nfig['layout']['xaxis2'].update(title='Total Revenue (in USD)')\n\nfig.append_trace(trace1, 1, 1)\nfig.append_trace(trace2, 1, 2)\npy.iplot(fig, filename='Session and Revenue generation per Country')","572954b3":"train_df.transactions.describe()","5b1625f2":"session_quality_hist = train_df[['sessionQuality','transactionRevenue']]\nsession_quality_hist = session_quality_hist[session_quality_hist['transactionRevenue'] > 0].sessionQuality.value_counts()\nsession_quality_df = train_df.groupby('sessionQuality').size()\nsession_quality_df = session_quality_df.sort_values(ascending=False)\nsession_quality_revenue_df = train_df.groupby('sessionQuality')['transactionRevenue'].sum()\/10**6\nsession_quality_revenue_df = session_quality_revenue_df.sort_values(ascending=False)\n\ntrace1 = go.Bar(\n            x=session_quality_hist.index,\n            y=session_quality_hist.values,\n            marker = dict(color = 'rgba(55, 72, 155, 1.0)'),\n            name='session count'\n)\n\ntrace0 = go.Bar(\n            x=session_quality_df.index,\n            y=session_quality_df.values,\n            marker = dict(color = 'rgba(155, 55, 125, 1.0)'),\n            name='session count'\n)\n\ntrace2 = go.Bar(\n            x=session_quality_revenue_df.index,\n            y=session_quality_revenue_df.values,\n            marker = dict(color = 'rgba(55, 100, 25, 1.0)'),\n            name='revenue'\n)\n\nfig = tools.make_subplots(rows=3, cols=1)\nfig['layout'].update(height=1000, width=1500, title='Session and Revenue generation with SessionQuality')\nfig['layout']['margin'].update(l=120,r=250,t=140, b=80 )\nfig['layout']['yaxis2'].update(title='Non-zero revenue session count')\nfig['layout']['xaxis1'].update(title='SessionQuality (1-100)')\nfig['layout']['yaxis1'].update(title='Total Sessions')\nfig['layout']['xaxis2'].update(title='SessionQuality (1-100)')\nfig['layout']['yaxis3'].update(title='Total Revenue (in USD)')\nfig['layout']['xaxis3'].update(title='SessionQuality (1-100)')\n\nfig.append_trace(trace0, 1, 1)\nfig.append_trace(trace1, 2, 1)\nfig.append_trace(trace2, 3, 1)\npy.iplot(fig, filename='Session and Revenue generation with SessionQuality')\n\n","e83c001d":"time_spend_df = train_df.groupby('timeOnSite')['transactionRevenue'].sum()\/10**6\ntime_spend_df = time_spend_df.sort_values(ascending = False)\nsorted_times = train_df['timeOnSite']\n\ntrace1 = go.Bar(\n            x=time_spend_df.index,\n            y=time_spend_df.values,\n            marker = dict(color = 'rgba(175, 55, 25, 1.0)'),\n            name='revenue'\n)\n\ntrace2= go.Histogram(\n            histnorm='percent',\n            marker = dict(color = 'rgba(100, 155, 25, 0.7)'),\n            x = sorted_times.values,\n            xbins=dict(\n                start=0,\n                end=3000,\n                size=30\n            ),\n            name='percentage of sessions'\n)\n        \n\nfig = tools.make_subplots(rows=2, cols=1)\nfig['layout'].update(height=1000, width=1500, title='Session and Revenue generation with timeOnSite')\nfig['layout']['margin'].update(l=120,r=250,t=140, b=80 )\nfig['layout']['yaxis1'].update(title='Revenue (USD)')\nfig['layout']['xaxis1'].update(title='Time spent on site (in secs)')\nfig['layout']['yaxis2'].update(title='Percentage of Sessions (in %)')\nfig['layout']['xaxis2'].update(title='Time spent on site (in secs)')\n\nfig.append_trace(trace1, 1, 1)\nfig.append_trace(trace2, 2, 1)\npy.iplot(fig, filename='Session and Revenue generation with SessionQuality')\n\n","e22674b0":"train_df.head()","b63be8c8":"video_ads_df = train_df.groupby('adwords_isVideoAd')['transactionRevenue'].sum()\/10**6\n\n# realize that most of the videoAd column is unknown \/ we may get rid of this column doesn't provide useful information\ndisplay(train_df.adwords_isVideoAd.describe())\n\ntrace1 = go.Bar(\n            x=video_ads_df.values,\n            y=video_ads_df.index,\n            marker = dict(color = 'rgba(175, 155, 25, 1.0)'),\n            orientation='h',\n            name='Revenue'\n)\n\n\nlayout = go.Layout(title='Revenue generation with video ads',\n                   height=400,\n                   width=800,\n                   xaxis=dict(title='Revenue (in USD)'),\n                   yaxis=dict(title='IsVideoAd')\n)\n\nfig = go.Figure(data=[trace1], layout=layout)\npy.iplot(fig, filename='Revenue generation with pageviews')","ec8ba176":"region_df = train_df.groupby('visitNumber')['transactionRevenue'].sum()\/10**6\n\n\ntrace1 = go.Bar(\n            x=region_df.index,\n            y=region_df.values,\n            marker = dict(color = 'rgba(200, 55, 25, 1.0)'),\n            name='revenue'\n)\n\ntrace2= go.Histogram(\n            histnorm='percent',\n            marker = dict(color = 'rgba(100, 155, 215, 0.7)'),\n            x = train_df['visitNumber'].values,\n            xbins=dict(\n                start=0,\n                end=1000,\n                size=2\n            ),\n            name='percentage of sessions'\n)\n        \n\nfig = tools.make_subplots(rows=2, cols=1)\nfig['layout'].update(height=1000, width=1000, title='Session percentages and Revenue generation with VisitCounts')\nfig['layout']['margin'].update(l=120,r=25,t=140, b=80 )\nfig['layout']['yaxis1'].update(title='Revenue (USD)')\nfig['layout']['xaxis1'].update(title='visit count to the site')\nfig['layout']['yaxis2'].update(title='Percentage of Sessions (in %)')\nfig['layout']['xaxis2'].update(title='visit count to the site')\n\nfig.append_trace(trace1, 1, 1)\nfig.append_trace(trace2, 2, 1)\npy.iplot(fig, filename='Session and Revenue generation with VisitCounts')","a03e684f":"# calculating number of sessions, non-zero revenue count and mean revenue from each geolocation and domain\n\ndef horizontal_bar_chart(series, color, name):\n    trace = go.Bar(\n        y=series.index,\n        x=series.values,\n        showlegend=False,\n        orientation = 'h',\n        marker=dict(\n            color=color,\n        ),\n        name = name\n    )\n    return trace\n\n\nnz_revenue_mask = train_df['transactionRevenue'] > 0\ncontinent_srs = train_df.groupby('continent')['transactionRevenue'].agg(['size','mean'])\ncontinent_srs.columns = ['number of sessions', 'mean revenue']\ncontinent_srs.sort_values(by='number of sessions', ascending=False, inplace=True)\ncontinent_nz_revenue_srs = train_df[nz_revenue_mask].groupby('continent')['transactionRevenue'].size()\ncontinent_nz_revenue_srs.sort_values(ascending=False, inplace=True)\n\nsubContinent_srs = train_df.groupby('geoNetwork_subContinent')['transactionRevenue'].agg(['size','mean'])\nsubContinent_srs.columns = ['number of sessions', 'mean revenue']\nsubContinent_srs.sort_values(by='number of sessions', ascending=False, inplace=True)\nsubContinent_nz_revenue = train_df[nz_revenue_mask].groupby('geoNetwork_subContinent')['transactionRevenue'].size()\nsubContinent_nz_revenue.sort_values(ascending=False, inplace=True)\n\nnetworkDomain_srs = train_df.groupby('networkDomain')['transactionRevenue'].agg(['size','mean'])\nnetworkDomain_srs.columns = ['number of sessions', 'mean revenue']\nnetworkDomain_srs.sort_values(by='number of sessions', ascending=False, inplace=True)\nnetworkDomain_nz_revenue_srs = train_df.loc[nz_revenue_mask].groupby('networkDomain')['transactionRevenue'].size()\nnetworkDomain_nz_revenue_srs.sort_values(ascending=False, inplace=True)\n\n\n\ntrace1 = horizontal_bar_chart(continent_srs[\"number of sessions\"].head(10), 'rgba(50, 171, 96, 0.6)',name='count')\ntrace2 = horizontal_bar_chart((continent_srs[\"mean revenue\"]\/10**6).head(10), 'rgba(50, 171, 96, 0.6)','revenue')\ntrace3 = horizontal_bar_chart(continent_nz_revenue_srs, 'rgba(50, 171, 96, 0.6)','count')\n\n\ntrace4 = horizontal_bar_chart(subContinent_srs[\"number of sessions\"], 'rgba(71, 58, 131, 0.8)','count')\ntrace5 = horizontal_bar_chart(subContinent_srs[\"mean revenue\"]\/10**6, 'rgba(71, 58, 131, 0.8)','revenue')\ntrace6 = horizontal_bar_chart(subContinent_nz_revenue.head(10), 'rgba(71, 58, 131, 0.8)','count')\n\ntrace7 = horizontal_bar_chart(networkDomain_srs[\"number of sessions\"].head(10), 'rgba(246, 78, 139, 0.6)','count')\ntrace8 = horizontal_bar_chart((networkDomain_srs[\"mean revenue\"]\/10**6).head(10), 'rgba(246, 78, 139, 0.6)','revenue')\ntrace9 = horizontal_bar_chart(networkDomain_nz_revenue_srs.head(10), 'rgba(246, 78, 139, 0.6)','count')\n\nfig = tools.make_subplots(rows=3, cols=3, vertical_spacing=0.04, \n                          subplot_titles=[\"Continent - Count\", \"Continent - Mean Revenue\", \"Continent - Non-zero Revenue Count\",\n                                          \"Subcontinent - Count\",  \"Subcontinent - Mean Revenue\", \"Subcontinent - Non-zero Revenue Count\", \n                                          \"NetworkDomain - Count\", \"NetworkDomain - Mean Revenue\", \"NetworkDomain - Non-zero Revenue Count\"])\n\nfig.append_trace(trace1, 1, 1)\nfig.append_trace(trace2, 1, 2)\nfig.append_trace(trace3, 1, 3)\nfig.append_trace(trace4, 2, 1)\nfig.append_trace(trace5, 2, 2)\nfig.append_trace(trace6, 2, 3)\nfig.append_trace(trace7, 3, 1)\nfig.append_trace(trace8, 3, 2)\nfig.append_trace(trace9, 3, 3)\n\nfig['layout'].update(height=1200, width=1500, paper_bgcolor='rgb(233,233,233)',title=\"Geolocation and NetworkDomain Plots\")\nfig['layout']['margin'].update(l=100,r=25,t=75, b=80)\npy.iplot(fig, filename='geolocation-plots')","1d6ac9ef":"pageviews_srs = train_df.groupby('pageviews')['transactionRevenue'].agg(['size','mean'])\npageviews_srs.columns = ['number of sessions','mean revenue']\npageviews_srs.sort_values(by='number of sessions', inplace=True,ascending=False)\npageviews_non_zero_revenue_srs = train_df[nz_revenue_mask].groupby('pageviews')['transactionRevenue'].size()\npageviews_non_zero_revenue_srs.sort_values(inplace=True, ascending=False)\n\n\nhits_srs = train_df.groupby('hits')['transactionRevenue'].agg(['size','mean'])\nhits_srs.columns = ['number of sessions','mean revenue']\nhits_srs.sort_values(by='number of sessions', inplace=True, ascending=False)\nhits_non_zero_revenue_srs = train_df[nz_revenue_mask].groupby('hits')['transactionRevenue'].size()\nhits_non_zero_revenue_srs.sort_values(inplace=True, ascending=False)\n\n\ntrace1 = horizontal_bar_chart(pageviews_srs[\"number of sessions\"].head(50), 'rgba(50, 171, 96, 0.6)',name='count')\ntrace2 = horizontal_bar_chart((pageviews_srs[\"mean revenue\"]\/10**6).head(50), 'rgba(50, 171, 96, 0.6)','dollars')\ntrace3 = horizontal_bar_chart(pageviews_non_zero_revenue_srs.head(50), 'rgba(50, 171, 96, 0.6)','count')\n\n\ntrace4 = horizontal_bar_chart(hits_srs[\"number of sessions\"].head(50), 'rgba(71, 58, 131, 0.8)','count')\ntrace5 = horizontal_bar_chart((hits_srs[\"mean revenue\"]\/10**6).head(50), 'rgba(71, 58, 131, 0.8)','dollars')\ntrace6 = horizontal_bar_chart(hits_non_zero_revenue_srs.head(50), 'rgba(71, 58, 131, 0.8)','count')\n\n\n\nfig = tools.make_subplots(rows=2, cols=3, vertical_spacing=0.04, \n                          subplot_titles=[\"Pageviews - Count\", \"Pageviews - Mean Revenue\", \"Pageviews - Non-zero Revenue Count\",\n                                          \"Hits - Count\",  \"Hits - Mean Revenue\", \"Hits - Non-zero Revenue Count\"])\n\nfig.append_trace(trace1, 1, 1)\nfig.append_trace(trace2, 1, 2)\nfig.append_trace(trace3, 1, 3)\nfig.append_trace(trace4, 2, 1)\nfig.append_trace(trace5, 2, 2)\nfig.append_trace(trace6, 2, 3)\n\nfig['layout'].update(height=1200, width=1500, paper_bgcolor='rgb(233,233,233)',title=\"Geolocation and NetworkDomain Plots\")\nfig['layout']['margin'].update(l=100,r=25,t=75, b=80)\npy.iplot(fig, filename='geolocation-plots')\n","434ac435":"__Analyze the customDimensions and hits columns__   \nBecause they look weird and still contain some information in json format","146fd670":"__Visualize the target variable - `transactionRevenue`__  \nAs you can see below, our target variable distribution is highly skewed. On top of that only very few customers 1% made successful purchase on the website","8b56e7c2":"__Checking out for duplicate rows__","d9ba1666":"We see that transactionRevenue distribution is highly skewed towards smaller values.","2a3e50bb":"### Analyzing ``channelGrouping``, ``source`` and ``medium`` variables :","638c30a7":"**Since important knowledge about hits and social referrals already exist in the current table under totals and trafficSource variables , we can drop hits column as well**","729b6d8f":"__Finding the conversion rate to revenue__  \nHere we see the reason why we have so many NaN rows in transaction columns","768175d2":"** Normalizing the column names **","8541d969":"**We see that most of trafficSource columns are filled with NaN, we will inspect more about before making a decision about dropping them. We also see that our target variable (transactions) include a lot of missing columns with NaNs. This could be because only very few of the customers made an actual purchase from the website. We will try to clarify the reason of this in the later analysis stages.**","80eaec5c":"**Since we have this information already exists in the table in geoNetwork variables, we will drop this column**","e78d768d":"**Data type conversion to suitable types**","96208478":"**Summary**:  \nWe see that both number of sessions and revenue generated are effected from the day of the week. This points out that we should use ``weekday`` as a categorical variable in the modelling","152e264c":"**Since there is no true value exists for isVideoAd, we will convert 'nan' values to Unknown and will let statistics decide**","35a01e6b":"Changing format to get a proper view","7eb77e0c":"### Channel grouping:\nChannels define how users come to the website. Channel groupings are groupings of these channels\/sources. The groups are defined by the ``Medium`` and ``Source`` or ``Social Source Referral``.  \n* **Source: ** The source of the traffic, such as a search engine or a domain (linkedin.com)  \n* **Medium: ** General category of the source. For organic search -> organic, cost-per-click paid search -> cpc, web referral -> referral","ececa3db":"** Analyzing the `hits` column**","f464d4d4":"### Browser stats: \nThe first plot displays top-15 browser statistics with most number of sessions and second plot shows the same statistics for the  most revenue making browsers. For both plots, we see that most revenue and users are coming from Chrome browser. Safari has a lot of sessions however, doesn't generate revenue as much. Firefox has a good balance between number of sessions and revenues. Other browsers barely generate any significant revenue.","27484748":"### Operating Systems: \nHere I will plot the relation of variable ``operatingSystem``. I plot the number of unique sessions per operating system category and revenue generated per  operating system.\n","38b46112":"**Analyzing transactionRevenue variable**","de8b3402":"**Summary**:  \nAs we can see here, most of the transactions are very small. However, there are only 54 transactions that create 22.7% percent of all revenue. This means that our revenues are heavily right skewed. Whereas most of the transactions are very small in value. We must try to predict at the tail locations to ensure minimum loss.","3c099c48":"**Summary**:  \nAs we see here, even though ``referral`` create only the 4th most sessions, it create the greatest revenue. Furthermore, when we look at the ``Social``, we see that social creates the second most traffic to the website, however revenue conversion of the ``Social`` almost non-existent.","43fbcac8":"__Counting NaN columns for later inspection__","b6a29e7e":"### Geolocation information analysis","fde92a04":"#### Observing the sessions and revenues by Month of the year","c3d460fb":"#### Observing sessions and revenues by workday of the week","d6d3d5b5":"### Pageviews relation to Revenue:  \nAs you can see below, there is an skewed normal distribution around 20 - 30 pageviews for revenue generation. As pageviews increase, it doesn't show immediate relation to revenue increase. One thing to realize from this plot is that when pageviews are low ( < 10 pageviews ) the revenue generation is also low. So the maximum revenue generated concentrates around 15-30 pageviews. "}}