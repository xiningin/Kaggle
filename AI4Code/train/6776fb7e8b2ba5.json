{"cell_type":{"d3265e70":"code","6c5c9915":"code","61020b60":"code","6366ced0":"code","c84789c2":"code","0630e69c":"code","9735d1a8":"code","55320b08":"code","3e368091":"code","7fe34fc9":"code","e7889dd9":"code","3307fb46":"code","32c04b32":"code","8712072c":"markdown","ad26728e":"markdown","ca5b3dd6":"markdown"},"source":{"d3265e70":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use('bmh')\nimport os\nimport cv2\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import models\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2","6c5c9915":"OUTPUT_DIR = '.\/'\nimage_size = 256\nbatch_size = 32","61020b60":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\ndevice","6366ced0":"model = torch.load('..\/input\/cassava-balanced-ce-model\/sgd_balanced_ce_aug.pt')","c84789c2":"class CassavaDataset(Dataset):\n    def __init__(self, data_dir, ids, labels, transform=None):\n        self.data_dir = data_dir\n        self.ids = ids\n        self.labels = labels\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.ids)\n    \n    def __getitem__(self, idx):\n        image = cv2.imread(os.path.join(self.data_dir, self.ids[idx]))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.transform:\n            image = self.transform(image=image)['image']\n        \n        label = self.labels[idx]    \n        \n        return (image, label)","0630e69c":"transform = A.Compose([\n    A.RandomResizedCrop(image_size, image_size),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.25),\n    A.Transpose(p=0.25),\n    A.RandomBrightnessContrast(\n                brightness_limit=(-0.1,0.1), \n                contrast_limit=(-0.1, 0.1), \n                p=0.5),\n    A.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, \n                p=1.0),\n    ToTensorV2(p=1.0)\n])","9735d1a8":"test_df = pd.read_csv('..\/input\/cassava-leaf-disease-classification\/sample_submission.csv')\ntest_dir = '..\/input\/cassava-leaf-disease-classification\/test_images'\nids = test_df['image_id'].values\nlabels = test_df['label'].values\ntest_df","55320b08":"test_dataset = CassavaDataset(test_dir, ids, labels, transform=transform)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)","3e368091":"softmax = nn.Softmax(dim = 1)","7fe34fc9":"num_inferences = 10\ninferences = []\n\nfor i in range(num_inferences): \n    inf = []\n    model.eval()\n    with torch.no_grad(): \n        for data in test_loader:\n            inputs, labels = data\n            inputs = inputs.to(device)\n            outputs = softmax(model(inputs))\n            outputs = outputs.cpu().numpy()\n            inf += list(outputs)\n    inferences.append(np.array(inf))","e7889dd9":"preds = np.zeros((inferences[0].shape))\nfor inf in inferences:\n    preds += inf\npreds = preds \/ num_inferences\npreds = list(np.argmax(preds, axis=1))","3307fb46":"test_df['label'] = preds\ntest_df.to_csv(OUTPUT_DIR+'submission.csv', index=False)","32c04b32":"pd.read_csv(OUTPUT_DIR+'submission.csv')","8712072c":"### Inference with TTA","ad26728e":"### Get Data","ca5b3dd6":"### Load Model"}}