{"cell_type":{"f5a0293c":"code","9a706677":"code","b5bbf5fa":"code","99c86f2c":"code","fe2cd63d":"code","a54b8d3c":"code","2372d3a3":"code","6d006aa1":"code","61d78b65":"code","d5230caf":"code","2d67e3b6":"code","0d89676e":"code","d204704c":"code","c2c4b529":"code","b20d26d4":"code","8f32363c":"code","d32f6752":"markdown","84921f8a":"markdown","982e4849":"markdown","becabece":"markdown","6122045b":"markdown","3465c1eb":"markdown","1949c14a":"markdown","de8959b4":"markdown"},"source":{"f5a0293c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import svm\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9a706677":"train = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/test.csv')","b5bbf5fa":"train.head()","99c86f2c":"train.describe()","fe2cd63d":"missing_cols = ['keyword', 'location']\nplt.subplot(121)\nplt.bar(train[missing_cols].isnull().sum().index, train[missing_cols].isnull().sum().values)\nplt.title('Training Dataset')\n\nplt.subplot(122)\nplt.bar(test[missing_cols].isnull().sum().index, test[missing_cols].isnull().sum().values)\nplt.title('Testing Dataset')","a54b8d3c":"train[train['target'] == 0]['text'].values","2372d3a3":"vectorizer = CountVectorizer()\ntrain_vec = vectorizer.fit_transform(train['text'])\ntest_vec = vectorizer.transform(test['text'])","6d006aa1":"nsamp = train_vec.shape[0]\nIperm = np.random.permutation(nsamp)\n\nxtr = train_vec[Iperm[:], :]\nytr = train['target']\nytr = ytr[Iperm[:]]","61d78b65":"clf = svm.SVC(C=2.6, verbose=10)","d5230caf":"scores_perm = cross_val_score(clf, xtr, ytr, cv=3, scoring=\"f1\")\nscores = cross_val_score(clf, train_vec, train['target'], cv=3, scoring=\"f1\")","2d67e3b6":"print('Scores without permutation',scores)\nprint('Scores with permutation',scores_perm)","0d89676e":"clf.fit(xtr, ytr)","d204704c":"sample_submission = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/sample_submission.csv')","c2c4b529":"pred = clf.predict(test_vec)\nsample_submission['target'] = pred","b20d26d4":"sample_submission.head()","8f32363c":"sample_submission.to_csv(\"submission.csv\", index=False)","d32f6752":"## 1. Loading Data\nUse pd.read_csv() to load data from .csv files","84921f8a":"## 7. Prediction","982e4849":"## 2. Missing Value","becabece":"## 4. Permutation","6122045b":"## 5. SVM model\nImplement [SVM classifier](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.svm.SVC.html) to classify text.","3465c1eb":"## 6. Fit model","1949c14a":"## O. Reference\n\n[1]. [NLP Getting Started Tutorial](https:\/\/www.kaggle.com\/philculliton\/nlp-getting-started-tutorial)\n\n[2]. [NLP with Disaster Tweets - EDA, Cleaning and BERT](https:\/\/www.kaggle.com\/gunesevitan\/nlp-with-disaster-tweets-eda-cleaning-and-bert#5.-Mislabeled-Samples)\n\nThis is a SVM version of [1] and I used random permutation to improve the model performance.\nFor EDA part, [2] did excellent job on it.","de8959b4":"## 3. Vector Converting\nConvert text to a vector using [sklearn.feature_extraction.text.CountVectorizer](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.feature_extraction.text.CountVectorizer.html)"}}