{"cell_type":{"6cc24807":"code","6eec7ae0":"code","dc68f16b":"code","6a4c4821":"code","4818e373":"code","c65136fe":"code","f1cc7ec9":"code","df26f277":"code","06bfc10d":"code","124bcf38":"code","4a2fc30d":"code","08d819d9":"code","846b40b6":"code","18cc8cc4":"code","dc8ce13b":"code","d8af21d1":"code","5bba7400":"code","7d2ce00b":"code","011d6f71":"code","3448cebb":"code","652d21b5":"code","134002be":"code","e383b09d":"code","bebcf378":"code","3736e2f7":"code","4b215e88":"code","787add52":"code","4739c383":"code","f0b0cab0":"code","b8694ed6":"code","c74f7f96":"code","de4ff4f2":"code","84d56ca6":"code","09462273":"code","7f803b9a":"code","a3e9c00a":"code","f053b274":"code","2ecb04b2":"code","6366ba7e":"code","9a038da3":"code","ac8d68b6":"code","93b55092":"code","fd324437":"code","0a442436":"code","f0264623":"code","a6ca52c7":"code","da03cc43":"code","0fa0420f":"code","7c1bc02f":"code","9117a0fd":"code","fd577e0f":"code","076e936d":"code","f4c28ee1":"code","a98bed65":"code","76965364":"code","1294e13f":"code","23017758":"code","ea90ba66":"code","6a1e1ccb":"code","b8c1e3bf":"code","f31ea40f":"code","01886629":"code","5f08061a":"code","ea184028":"code","bf4b2790":"code","01f0d81c":"markdown","9014803b":"markdown","3039cf68":"markdown","1df64922":"markdown","338fa92a":"markdown","e0a66af6":"markdown","0815942d":"markdown","18b8ed12":"markdown","577bb08c":"markdown","320c1c30":"markdown","1a4e2c1c":"markdown","a9e1afb9":"markdown","ce4928be":"markdown","ac1452f0":"markdown"},"source":{"6cc24807":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport matplotlib.image as mpimg\nfrom imblearn.over_sampling import SMOTE\nfrom random import randint, random\nimport random\nfrom distutils.dir_util import copy_tree, remove_tree\nfrom PIL import Image\n\n#from distutils.dir_util import copy_tree, remove_tree\n#from sklearn.metrics import f1_score\n#from sklearn.metrics import matthews_corrcoef as MCC\n#from sklearn.metrics import balanced_accuracy_score as BAS\n#from sklearn.metrics import classification_report, confusion_matrix\n\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.regularizers import l1, l2\nfrom tensorflow.keras.optimizers import RMSprop, Adam, SGD\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import BatchNormalization, Conv2D, Conv3D, Dense, Dropout, Flatten, InputLayer, Lambda, MaxPool2D, MaxPooling3D, LSTM\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n#, MultiGPUModelCheckpoint\nfrom tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n#from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n#from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\nfrom tensorflow.keras.utils import plot_model\n#, multi_gpu_model\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport tensorflow_addons as tfa\n#SeparableConv2D, BatchNormalization, MaxPool2D\n\n\nprint(\"TensorFlow Version:\", tf.__version__)","6eec7ae0":"size_ResNet50 = (224,224,3)\nsize_VGG19 = (224,224,3)\nsize_IncpV3 = (299,299,3)","dc68f16b":"BATCH_size = 16\n#OPT = Adam(learning_rate=0.005,\n#           beta_2=0.989,\n#           epsilon=1e-07,\n#           amsgrad=False,\n#           name=\"Adam\",\n#            ) #Adam, SGD, RMSprop, \n#OPT = RMSprop(learning_rate=0.0001)\n\n# OPT = Adam() More details below!!!!\n\n    \nLOSS_func = tf.keras.losses.CategoricalCrossentropy() # \n\nEPOCHS = 60 #100\n\nMETRICS = [\n      #tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n      tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\"),\n      tf.keras.metrics.Precision(name='precision'),\n      tf.keras.metrics.Recall(name='recall'),  \n      tf.keras.metrics.AUC(name='auc'),\n      tf.keras.metrics.SpecificityAtSensitivity(0.5, num_thresholds=300,\n                                             name=None, dtype=None),\n      tfa.metrics.F1Score(num_classes=4)\n]\nweight_decay = 0.0002","6a4c4821":"#base_dir = \"\/kaggle\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/\"\n#root_dir = \".\/\"\ntest_dir = \"\/kaggle\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/test\/\"\ntrain_dir = \"\/kaggle\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/train\/\"\nwork_dir = \".\/dataset\/\"\n\nif os.path.exists(work_dir):\n    remove_tree(work_dir)\n    \n\nos.mkdir(work_dir)\ncopy_tree(train_dir, work_dir)\ncopy_tree(test_dir, work_dir)\nprint(\"Working Directory Contents:\", os.listdir(work_dir))","4818e373":"WORK_DIR = '.\/dataset\/'\n\nCLASSES = [ 'NonDemented',\n            'VeryMildDemented',\n            'MildDemented',\n            'ModerateDemented']\n\nIMG_SIZE = 174\nIMAGE_SIZE = [IMG_SIZE, IMG_SIZE]\nDIM = (IMG_SIZE, IMG_SIZE)","c65136fe":"#Performing Image Augmentation to have more data samples\n\n\nZOOM = [.98, 1.02]\nBRIGHT_RANGE = [0.8, 1.2]\nHORZ_FLIP = True\nFILL_MODE = \"constant\"\nDATA_FORMAT = \"channels_last\"\nROT_RANGE = 5\nW_SHIFT_RANGE = 0.15\nH_SHIFT_RANGE = 0.15\nSHEAR_RANGE = 0.25\n\nwork_dr = ImageDataGenerator(rescale = 1.\/255,\n                             brightness_range=BRIGHT_RANGE,\n                             zoom_range=ZOOM,\n                             data_format=DATA_FORMAT,\n                             fill_mode=FILL_MODE,\n                             horizontal_flip=HORZ_FLIP,\n                             rotation_range=ROT_RANGE,\n                             width_shift_range=W_SHIFT_RANGE,\n                             height_shift_range=H_SHIFT_RANGE,\n                             shear_range=SHEAR_RANGE)\n\ntrain_data_gen = work_dr.flow_from_directory(directory=WORK_DIR,\n                                             target_size=DIM,\n                                             batch_size=6500,\n                                             shuffle=False)\n\n\n                                   ","f1cc7ec9":"#Performing Image Augmentation to have more data samples \n#(LESS SAMPLE VERSION)\nZOOM = [.99, 1.01]\nBRIGHT_RANGE = [0.8, 1.2]\nHORZ_FLIP = True\nFILL_MODE = \"constant\"\nDATA_FORMAT = \"channels_last\"\n\nwork_dr = ImageDataGenerator(\n                             rescale = 1.\/255,\n                             brightness_range=BRIGHT_RANGE,\n                             zoom_range=ZOOM,\n                             data_format=DATA_FORMAT, \n                             fill_mode=FILL_MODE,\n                             horizontal_flip=HORZ_FLIP\n                            )\n\n\ntrain_data_gen = work_dr.flow_from_directory(directory=WORK_DIR, target_size=DIM, batch_size=6500, shuffle=False)","df26f277":"def show_images(generator,y_pred=None):\n    \"\"\"\n    Input: An image generator,predicted labels (optional)\n    Output: Displays a grid of 9 images with lables\n    \"\"\"\n    \n    # get image lables\n    labels =dict(zip([0,1,2,3], CLASSES))\n    \n    # get a batch of images\n    x,y = generator.next()\n    \n    # display a grid of 9 images\n    plt.figure(figsize=(10, 10))\n    if y_pred is None:\n        for i in range(9):\n            ax = plt.subplot(3, 3, i + 1)\n            idx = randint(0, 6400)\n            plt.imshow(x[idx])\n            plt.axis(\"off\")\n            plt.title(\"Class:{}\".format(labels[np.argmax(y[idx])]))\n                                                     \n    else:\n        for i in range(9):\n            ax = plt.subplot(3, 3, i + 1)\n            plt.imshow(x[i])\n            plt.axis(\"off\")\n            plt.title(\"Actual:{} \\nPredicted:{}\".format(labels[np.argmax(y[i])],labels[y_pred[i]]))\n    \n# Display Train Images\nshow_images(train_data_gen)","06bfc10d":"plt.figure(figsize=(20,20))\ntest_folder=\"..\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/test\/MildDemented\" \nfor i in range(5):\n    file = random.choice(os.listdir(test_folder))\n    image_path= os.path.join(test_folder, file)\n    img=mpimg.imread(image_path)\n    ax=plt.subplot(1,5,i+1)\n    ax.title.set_text(file)\n    plt.imshow(img)","124bcf38":"plt.figure(figsize=(20,20))\ntest_folder=\"..\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/test\/ModerateDemented\" \nfor i in range(5):\n    file = random.choice(os.listdir(test_folder))\n    image_path= os.path.join(test_folder, file)\n    img=mpimg.imread(image_path)\n    ax=plt.subplot(1,5,i+1)\n    ax.title.set_text(file)\n    plt.imshow(img)","4a2fc30d":"plt.figure(figsize=(20,20))\ntest_folder=\"..\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/test\/NonDemented\" \nfor i in range(5):\n    file = random.choice(os.listdir(test_folder))\n    image_path= os.path.join(test_folder, file)\n    img=mpimg.imread(image_path)\n    ax=plt.subplot(1,5,i+1)\n    ax.title.set_text(file)\n    plt.imshow(img)","08d819d9":"plt.figure(figsize=(20,20))\ntest_folder=\"..\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/test\/VeryMildDemented\" \nfor i in range(5):\n    file = random.choice(os.listdir(test_folder))\n    image_path= os.path.join(test_folder, file)\n    img=mpimg.imread(image_path)\n    ax=plt.subplot(1,5,i+1)\n    ax.title.set_text(file)\n    plt.imshow(img)","846b40b6":"#img = cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)","18cc8cc4":"#Retrieving the data from the ImageDataGenerator iterator\n\ntrain_data, train_labels = train_data_gen.next()","dc8ce13b":"#Getting to know the dimensions of our dataset\n\nprint(train_data.shape, train_labels.shape)","d8af21d1":"#Performing over-sampling of the data, since the classes are imbalanced\n\nsm = SMOTE(random_state=42)\n\ntrain_data, train_labels = sm.fit_resample(train_data.reshape(-1, IMG_SIZE * IMG_SIZE * 3), train_labels)\n\ntrain_data = train_data.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n\nprint(train_data.shape, train_labels.shape)","5bba7400":"#Splitting the data into train, test, and validation sets\n\ntrain_data, test_data, train_labels, test_labels = train_test_split(\n                                        train_data, train_labels,\n                                        test_size = 0.22, random_state=42, stratify=train_labels\n                                        )\n\ntrain_data, val_data, train_labels, val_labels = train_test_split(\n                                        train_data, train_labels, \n                                        test_size = 0.22, random_state=42, stratify=train_labels\n                                        )","7d2ce00b":"base_model = VGG19(input_shape=(IMG_SIZE, IMG_SIZE, 3),\n                   include_top=False, weights=\"imagenet\")\n#size_VGG19","011d6f71":"#base_model = InceptionV3(input_shape=size_IncpV3, include_top=False, weights='imagenet')\n\n#base_model = ResNet50(input_shape=size_ResNet50, include_top=False, weights='imagenet')","3448cebb":"#Freezing the top layers (pre-trained model)\nfor each_layer in base_model.layers:\n    each_layer.trainable = False","652d21b5":"plot_model(base_model) ","134002be":"base_model.summary()","e383b09d":"base_model2 = VGG16(input_shape=(IMG_SIZE, IMG_SIZE, 3),\n                   include_top=False, weights=\"imagenet\")\n#size_VGG19","bebcf378":"#Freezing the top layers (pre-trained model)\nfor each_layer in base_model2.layers:\n    each_layer.trainable = False","3736e2f7":"plot_model(base_model2) ","4b215e88":"base_model2.summary()","787add52":"STEPS_PER_EPOCH = int( np.ceil(train_data.shape[0] \/ BATCH_size))\n\nlr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(1e-4, decay_steps=STEPS_PER_EPOCH*1000, decay_rate=1, staircase=False) #lr = 0.0002\n\nOPT = Adam(lr_schedule) ","4739c383":"# Building Model (v3)\n\nmodel = Sequential()\n\n#model.add(Lambda(lambda image: tf.image.resize(image, input_size)))\nmodel.add(base_model)\n\nmodel.add(Flatten())\n\n\"\"\"\nmodel.add(Dense(256, activation='relu', kernel_regularizer=l2(weight_decay), \n                kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.1))\n\nmodel.add(Dense(256, activation='relu', kernel_regularizer=l2(weight_decay), \n                kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.1))\n\nmodel.add(Dense(256, activation='relu', kernel_regularizer=l2(weight_decay),\n                kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.1))\n\"\"\"\n\"\"\"\nmodel.add(Dense(256, activation='relu', kernel_regularizer=l2(weight_decay),\n                kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\n\nmodel.add(Dense(128, activation='relu', kernel_regularizer=l2(weight_decay),\n                kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\n\n\nmodel.add(Dense(1024, activation='relu', kernel_regularizer=l2(weight_decay),\n                kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))    #512\n\"\"\"\n\n\n\nmodel.add(Dense(512, activation='relu', kernel_regularizer=l2(weight_decay)))\n                #,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n\nmodel.add(Dense(256, activation='relu', kernel_regularizer=l2(weight_decay)))\n                #,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))      #128\n\n        #model.add(Lambda(lambda x: tf.abs(x)))\n        #model.add(LSTM(256))\n        #model.add(LSTM(128))\n\nmodel.add(Dense(4, activation='softmax'))","f0b0cab0":"commonInput = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n","b8694ed6":"# Building Model (v4)\n\nmodel1 = Sequential()\n\n#model.add(Lambda(lambda image: tf.image.resize(image, input_size)))\nmodel1.add(base_model)\n\n\n\n\n\nmodel2 = Sequential()\n\n#model.add(Lambda(lambda image: tf.image.resize(image, input_size)))\n#model.add(base_model)\n\n#input_shape=(IMG_SIZE,IMG_SIZE,3)\n\n#model2.add(commonInput)\n\n\n    \n\nmodel2.add(Conv2D(64, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\nmodel2.add(Conv2D(64, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\nmodel2.add(BatchNormalization())\nmodel2.add(MaxPool2D((2,2)))\nmodel2.add(Dropout(0.3))\nmodel2.add(Conv2D(128, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\nmodel2.add(Conv2D(128, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\nmodel2.add(BatchNormalization())\nmodel2.add(MaxPool2D((2,2)))\nmodel2.add(Dropout(0.3))\n    \n    \nmodel2.add(Conv2D(256, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\nmodel2.add(Conv2D(256, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\nmodel2.add(Conv2D(256, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\nmodel2.add(Conv2D(256, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\nmodel2.add(BatchNormalization())\nmodel2.add(MaxPool2D((2,2)))\nmodel2.add(Dropout(0.3))    \n    \nmodel2.add(Conv2D(512, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\nmodel2.add(Conv2D(512, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\nmodel2.add(Conv2D(512, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\nmodel2.add(Conv2D(512, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\nmodel2.add(BatchNormalization())\nmodel2.add(MaxPool2D((2,2)))\nmodel2.add(Dropout(0.3))    \n    \nmodel2.add(Conv2D(512, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\nmodel2.add(Conv2D(512, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\nmodel2.add(Conv2D(512, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\nmodel2.add(Conv2D(512, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\nmodel2.add(BatchNormalization())\nmodel2.add(MaxPool2D((2,2)))\nmodel2.add(Dropout(0.3))    \n\n\"\"\"\nmodel.add(Dense(256, activation='relu', kernel_regularizer=l2(weight_decay), \n                kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.1))\n\nmodel.add(Dense(256, activation='relu', kernel_regularizer=l2(weight_decay), \n                kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.1))\n\nmodel.add(Dense(256, activation='relu', kernel_regularizer=l2(weight_decay),\n                kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.1))\n\"\"\"\n\"\"\"\nmodel.add(Dense(256, activation='relu', kernel_regularizer=l2(weight_decay),\n                kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\n\nmodel.add(Dense(128, activation='relu', kernel_regularizer=l2(weight_decay),\n                kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\n\n\nmodel.add(Dense(1024, activation='relu', kernel_regularizer=l2(weight_decay),\n                kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))    #512\n\"\"\"\n\n\n\nfrom keras.layers import *\n\nout1, out2 = model1(commonInput), model2(commonInput)    #model1(commonInput) \n\nmerged_model = Add()([out1, out2])\n#merged_model = tf.keras.layers.Concatenate()([base_model.output, model2.output])\n\n\n#merged_model = Concatenate()([out1, out2])\n\nmerged_model = Flatten()(merged_model)\n\nmerged_model = Dense(1024, activation='relu', kernel_regularizer=l2(weight_decay))(merged_model)\n                #,kernel_initializer='he_uniform'))\nmerged_model = BatchNormalization()(merged_model)\nmerged_model = Dropout(0.5)(merged_model)      #128\n\n        #model.add(Lambda(lambda x: tf.abs(x)))\n        #model.add(LSTM(256))\n        #model.add(LSTM(128))\n\nmerged_model = Dense(4, activation='softmax')(merged_model)\n\n\n\nfrom keras.models import Model\n#,model2.input\nmodel = Model(commonInput, merged_model)\n\n\n","c74f7f96":"#from keras.applications import VGG16\n#Load the VGG model\n\n#Camera Model\n#vgg_conv_C = VGG16(weights='imagenet', include_top=False, input_shape=(227, 227, 3))\n\n#Depth Model\n#vgg_conv_D = VGG16(weights='imagenet', include_top=False, input_shape= (227, 227, 3))\n#for layer in vgg_conv_D.layers[:-4]:\n#    layer.trainable = False \n#for layer in vgg_conv_C.layers[:-4]:\n#    layer.trainable = False \n\n#mergedModel = tf.keras.layers.Concatenate()([base_model.output, base_model2.output])\n#mergedModel = Dense(units = 1024, activation='relu')(mergedModel)\n#mergedModel = BatchNormalization()(mergedModel)\n#mergedModel = Dropout(0.5)(mergedModel)\n#mergedModel = Dense(units = 4,activation = 'softmax')(mergedModel)\n#fused_model = Model([base_model.input, base_model.input], mergedModel)    ","de4ff4f2":"#Normal CNN model (Without Transfer Learning or Siamese Network)\n\"\"\"\ndef my_model():\n    model = Sequential()\n\n    model.add(tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3)))\n\n    model.add(Conv2D(64, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\n    model.add(Conv2D(64, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D((2,2)))\n    model.add(Dropout(0.3))\n    model.add(Conv2D(128, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\n    model.add(Conv2D(128, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D((2,2)))\n    model.add(Dropout(0.3))\n\n\n    model.add(Conv2D(256, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\n    model.add(Conv2D(256, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\n    model.add(Conv2D(256, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\n    model.add(Conv2D(256, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D((2,2)))\n    model.add(Dropout(0.3))    \n\n    model.add(Conv2D(512, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\n    model.add(Conv2D(512, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\n    model.add(Conv2D(512, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\n    model.add(Conv2D(512, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D((2,2)))\n    model.add(Dropout(0.3))    \n\n    model.add(Conv2D(512, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\n    model.add(Conv2D(512, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\n    model.add(Conv2D(512, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\n    model.add(Conv2D(512, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D((2,2)))\n    model.add(Dropout(0.3))    \n\n\n    model.add(Flatten())\n    model.add(Dense(512, activation='relu', kernel_regularizer=l2(weight_decay)))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n\n    model.add(Dense(128, activation='relu', kernel_regularizer=l2(weight_decay)))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n\n    model.add(Dense(64, activation='relu', kernel_regularizer=l2(weight_decay)))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n\n    model.add(Dense(4, activation='softmax'))\n    \n    return model\n\"\"\"","84d56ca6":"def conv_block(filters, act='relu'):\n    \"\"\"Defining a Convolutional NN block for a Sequential CNN model. \"\"\"\n    \n    block = Sequential()\n    block.add(Conv2D(filters, 3, activation=act, padding='same'))\n    block.add(Conv2D(filters, 3, activation=act, padding='same'))\n    block.add(BatchNormalization())\n    block.add(MaxPool2D())\n    \n    return block\n\n\ndef conv_block2(filters, act='relu'):\n    \"\"\"Defining a Convolutional NN block for a Sequential CNN model. \"\"\"\n    \n    block = Sequential()\n    block.add(Conv2D(filters, 3, activation=act, padding='same'))\n    block.add(Conv2D(filters, 3, activation=act, padding='same'))\n    block.add(Conv2D(filters, 3, activation=act, padding='same'))\n    block.add(Conv2D(filters, 3, activation=act, padding='same'))\n    block.add(BatchNormalization())\n    block.add(MaxPool2D())\n    \n    return block","09462273":"def dense_block(units, dropout_rate, act='relu'):\n    \"\"\"Defining a Dense NN block for a Sequential CNN model. \"\"\"\n    \n    block = Sequential()\n    block.add(Dense(units, activation=act))\n    block.add(BatchNormalization())\n    block.add(Dropout(dropout_rate))\n    \n    return block","7f803b9a":"def construct_model(act='relu'):\n    \"\"\"Constructing a Sequential CNN architecture for performing the classification task. \"\"\"\n    \n    model = Sequential([\n        tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3)),\n        Conv2D(64, 3, activation=act, padding='same'),\n        Conv2D(64, 3, activation=act, padding='same'),\n        BatchNormalization(),\n        MaxPool2D(),\n        Dropout(0.3),\n        \n        conv_block(128),\n        #conv_block(128),\n        Dropout(0.3),\n        \n        conv_block2(256),\n        Dropout(0.3),\n        \n        conv_block2(512),\n        Dropout(0.3),\n        \n        conv_block2(512),\n        Dropout(0.3),\n        \n        Flatten(),\n        dense_block(512, 0.7),\n        dense_block(128, 0.5),\n        dense_block(64, 0.3),\n        Dense(4, activation='softmax')        \n    ], name = \"cnn_model\")\n\n    return model","a3e9c00a":"def construct_model2_VGG19(act='relu'):\n    \"\"\"Convolutional Neural Network - Pre-trained model (VGG19)\"\"\"\n    \n    model = Sequential([\n        base_model,\n        \n        Flatten(),\n        dense_block(512, 0.7),\n        dense_block(128, 0.5),\n        dense_block(64, 0.3),\n        Dense(4, activation='softmax')        \n    ], name = \"cnn_model\")\n\n    return model","f053b274":"def construct_model3_VGG16(act='relu'):\n    \"\"\"Convolutional Neural Network - Pre-trained model (VGG16)\"\"\"\n    \n    model = Sequential([\n        base_model2,\n        \n        Flatten(),\n        dense_block(512, 0.7),\n        dense_block(128, 0.5),\n        dense_block(64, 0.3),\n        Dense(4, activation='softmax')        \n    ], name = \"cnn_model\")\n\n    return model","2ecb04b2":"\ndef constr_model(act='relu'): #REFERENCE\n    \"\"\"Convolutional Neural Network\"\"\"\n    \n    model = Sequential([\n        tf.keras.Input(shape=(*IMAGE_SIZE, 3)),\n        Conv2D(32, 3, activation=act, padding='same'),\n        Conv2D(32, 3, activation=act, padding='same'),\n        MaxPool2D(),\n        conv_block(32),\n        conv_block(64),\n        conv_block(128),\n        Dropout(0.2),\n        conv_block(256),\n        Dropout(0.2),\n        Flatten(),\n        dense_block(512, 0.7),\n        dense_block(128, 0.5),\n        dense_block(64, 0.3),\n        Dense(4, activation='softmax')        \n    ], name = \"cnn_model\")\n\n    return model","6366ba7e":"def constr_model2(act='relu'):\n    \"\"\"Convolutional Neural Network - Preferred version - VGG19 based (No transfer learning)\"\"\"   \n    \n    model = Sequential([\n        tf.keras.Input(shape=(*IMAGE_SIZE, 3)),\n        \n        Conv2D(64, 3, activation=act, padding='same'),\n        Conv2D(64, 3, activation=act, padding='same'),\n        BatchNormalization(),\n        MaxPool2D(),\n        \n        #conv_block(32),\n        #conv_block(64),\n        conv_block(128),\n        Dropout(0.5),\n        \n        conv_block2(256),\n        Dropout(0.5),\n        \n        conv_block2(512),\n        Dropout(0.5),\n        \n        conv_block2(512),\n        Dropout(0.5),\n        \n        Flatten(),\n        #dense_block(512, 0.7),\n        dense_block(128, 0.5),\n        dense_block(64, 0.3),\n        Dense(4, activation='softmax')        \n    ], name = \"cnn_model\")\n\n    return model","9a038da3":"model = constr_model2()","ac8d68b6":"model = construct_model2_VGG19()","93b55092":"plot_model(model)","fd324437":"model.summary()","0a442436":"class MyCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if logs.get('val_acc') > 0.99:\n            print(\"\\nReached accuracy threshold! Terminating training.\")\n            self.model.stop_training = True\n            ","f0264623":"checkpoint = ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5', verbose=1)\n\n#Callbacks\nmy_callbacks = [checkpoint]\n                #EarlyStopping(monitor='val_categorical_accuracy',\n                 #                        patience=2)]\n                #MyCallback()] #EarlyStopping(),","a6ca52c7":"model.compile(optimizer=OPT, loss=LOSS_func, metrics=METRICS)","da03cc43":"history = model.fit(train_data, train_labels, validation_data=(val_data, val_labels),\n                    callbacks=my_callbacks, epochs=EPOCHS) #, steps_per_epoch = STEPS_PER_EPOCH)","0fa0420f":"#model = unknown","7c1bc02f":"scores = model.evaluate(test_data, test_labels, verbose=2)","9117a0fd":"for c in scores:\n    print(c)","fd577e0f":"print(f\"Val_Loss: {scores[0]}\\nAccuracy: {scores[1]}\\nPrecision: {scores[2]}\\nRecall: {scores[3]}\\nAUC: {scores[4]}\\nSpecificity at Sensitivity: {scores[5]}\")\nprint(f\"\\n\\nF1 scores:\\nNon Demented: {scores[6][0]}\\nVery Mild Demented: {scores[6][1]}\\nMild Demented: {scores[6][2]}\\nModerate Demented: {scores[6][3]}\\n\")","076e936d":"\"\"\"\n[ 'NonDemented','VeryMildDemented','MildDemented','ModerateDemented']\n\"\"\"","f4c28ee1":"pip install visualkeras","a98bed65":"import visualkeras\nfrom PIL import ImageFont\n\n\nvisualkeras.layered_view(base_model)","76965364":"visualkeras.layered_view(base_model, scale_xy=10, scale_z=10, max_z=1000)","1294e13f":"#FONT = ImageFont.truetype(\"arial.ttf\", 32)\nvisualkeras.layered_view(model)","23017758":"frame = pd.DataFrame(history.history)\n\nframe.plot(figsize=(12,8))\nplt.grid(True)\nplt.show()","ea90ba66":"acc_plot = frame.plot(y='categorical_accuracy', title='Accuracy vs Epochs')\nacc_plot.set(xlabel='Epochs', ylabel='Accuracy')","6a1e1ccb":"loss_plot = frame.plot(y='loss', title='Loss vs Epochs')\nloss_plot.set(xlabel='Epochs', ylabel='Loss')","b8c1e3bf":"num_test_images = test_data.shape[0]\n\nrandom_inx = np.random.choice(num_test_images, 4)\nrandom_test_images = test_data[random_inx, ...]\nrandom_test_labels = test_labels[random_inx, ...]\n\npredictions = model.predict(random_test_images)\n\nfig, axes = plt.subplots(4, 2, figsize=(16, 12))\nfig.subplots_adjust(hspace=0.4, wspace=-0.2)\n\nfor i, (prediction, image, label) in enumerate(zip(predictions, random_test_images, random_test_labels)):\n    axes[i, 0].imshow(np.squeeze(image))\n    axes[i, 0].get_xaxis().set_visible(False)\n    axes[i, 0].get_yaxis().set_visible(False)\n    axes[i, 0].text(10., -1.5, f'Class {label}')\n    axes[i, 1].bar(np.arange(len(prediction)), prediction)\n    axes[i, 1].set_xticks(np.arange(len(prediction)))\n    axes[i, 1].set_title(f\"Categorical distribution. Model prediction: {np.argmax(prediction)}\")\n    \nplt.show()","f31ea40f":"\ncount_class_0, count_class_1 = train_data.target.value_counts()\n# Divide by class\ndf_class_0 = train_data[train_data['target'] == 0]\ndf_class_1 = train_data[train_data['target'] == 1]\ndf_class_0_under = df_class_0.sample(count_class_1)\ndf_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)\nprint('Random under-sampling:')\nprint(df_test_under.target.value_counts())\ndf_test_under.target.value_counts().plot(kind='bar', title='Count (target)',color = ['#1F77B4', '#FF7F0E']);","01886629":"pip install storm-tuner","5f08061a":"from storm_tuner import Tuner","ea184028":"class MyTuner(Tuner):\n    def run_trial(self, trial, *args):\n            hp = trial.hyperparameters\n            model = build_model(hp)\n            X_train, y_train, X_test, y_test = args[0], args[1], args[2], args[3]\n\n            batch_size = hp.values['batch_size']\n            score = custom_score_function(train_data,\n                                          train_labels,\n                                          test_data,\n                                          test_labels,\n                                          model=model,\n                                          batch_size=BATCH_size,\n                                         )\n            self.score_trial(trial, score)","bf4b2790":"tuner = MyTuner(project_dir='Saved:\/',\n                build_fn=model,\n                objective_direction='min',\n                init_random=5,\n                max_iters=10,\n                randomize_axis_factor=0.5,\n                overwrite=True)\n#Calling Tuner\ntuner.search(X_train, y_train, X_test, y_test)","01f0d81c":"### Moderate Demented","9014803b":"### Mild Demented","3039cf68":"## Data Exploration","1df64922":"## Plot training history","338fa92a":"### Non-Demented","e0a66af6":"## My model","0815942d":"## Performance ","18b8ed12":"### Very Mild Demented","577bb08c":"## Directories and Hyperparameters","320c1c30":"## Training\n","1a4e2c1c":"## Transfer Learning","a9e1afb9":"### Bar prediction","ce4928be":"### Training history","ac1452f0":"## Data Splitting"}}