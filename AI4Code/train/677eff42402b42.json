{"cell_type":{"c5b926b5":"code","e6c359ea":"code","3437460f":"code","b32f9dc2":"code","678bd9e3":"code","3737f27b":"code","a208c5e2":"code","d9d5b681":"code","dbeb9985":"code","d37eab35":"code","5ae39c18":"code","61b913bf":"code","2fc9c1b5":"code","62a09aae":"code","b5d7ae93":"code","da8fdfcb":"code","e11c9222":"code","16830795":"code","4e7d4469":"code","33978144":"code","5511b62e":"code","3855f8e0":"code","678d5a43":"code","84b6be3c":"code","68f6a02e":"code","2044399c":"code","5f022bb5":"code","08c26bcd":"code","347407c1":"code","b615e42f":"code","16fc5bea":"code","06c0ad6e":"markdown","75e7ef68":"markdown","105fa3d2":"markdown","8149d4a9":"markdown","5136d050":"markdown","84f6b4ae":"markdown"},"source":{"c5b926b5":"import torch\nimport random\nfrom PIL import Image\nimport numpy as np\nfrom numpy import int64\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import fetch_openml\nimport matplotlib.pyplot as plt\n#from google.colab import files\n#from google.colab import drive\n!pip gdown\nimport os\nimport glob\nrandom.seed(0)\nnp.random.seed(0)\ntorch.manual_seed(0)\ntorch.cuda.manual_seed(0)\ntorch.backends.cudnn.deterministic = True","e6c359ea":"#\u041e\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043c\u0435\u0442\u0440\u0438\u043a \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u0440\u0430\u0431\u043e\u0442\u044b \u0441\u044b\u0442\u0435\u043c\u044b - \u043f\u043e\u043b\u043d\u043e\u0442\u0430, \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c, F-\u043c\u0435\u0440\u0430\nfrom keras import backend as K\ndef recall_m(y_true, y_pred):#\u041f\u043e\u043b\u043d\u043e\u0442\u0430\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives \/ (possible_positives + K.epsilon())\n    return recall\n\ndef precision_m(y_true, y_pred):#\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    return precision\n\ndef f1_m(y_true, y_pred):#F1-\u043c\u0435\u0440\u0430\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)\/(precision+recall+K.epsilon()))","3437460f":"drive.mount('\/gdrive')\nroot = '\/gdrive\/My Drive\/'","b32f9dc2":"data_root = '\/gdrive\/My Drive\/GPO\/'\ntest_path = \"\/gdrive\/My Drive\/GPO\/test\/tags\/\"\ntrain_img_path = \"\/gdrive\/My Drive\/GPO\/train\/tags\/\"\ntrain_mask_path = \"\/gdrive\/My Drive\/GPO\/train\/price_card_mask\/\" #\ntest_mask_path = \"\/gdrive\/My Drive\/GPO\/test\/price_card_masks\/\" #\ntrain_dir = 'tags'\nmask_dir = 'price_card_mask'\ntest_dir = 'test'","678bd9e3":"import torchvision\nfrom torchvision import transforms, models","3737f27b":"train_files = glob.glob(\"\/gdrive\/My Drive\/GPO\/train\/tags\/*.jpg\")\ntest_files = glob.glob(\"gdrive\/My Drive\/GPO\/test\/*.jpg\")\nmask_files = glob.glob(\"gdrive\/My Drive\/GPO\/train\/price_card_mask\/*.tif\")","a208c5e2":"from sklearn.utils import class_weight\n\n#x - \u0446\u0435\u043d\u043d\u0438\u043a\u0438, \u0443 - \u043c\u0430\u0441\u043a\u0438\n\nx1 = []\nx2 = []\ny1 = []\ny2 = []\ni=0\nj=0\nz=0\ng=0\nfor fl1 in os.listdir(train_img_path):\n    img = Image.open(train_img_path + fl1)\n    x1.append(img)\nfor fl2 in os.listdir(train_mask_path):\n    mask = Image.open(train_mask_path + fl2)\n    gray1 = mask.convert('L')\n    mask = gray1.point(lambda x: 0 if x<128 else 255, '1')\n    y1.append(mask)\nfor fl3 in os.listdir(test_path):\n    test_img = Image.open(test_path + fl3)\n    x2.append(test_img)\nfor fl4 in os.listdir(test_mask_path):\n    test_mask = Image.open(test_mask_path + fl4)\n    gray2 = test_mask.convert('L')\n    test_mask = gray2.point(lambda x: 0 if x<128 else 255, '1')\n    y2.append(test_mask)\n\nX_train = torch.Tensor()\nX_train_list = []\nfor i in x1:\n    x_train = torch.from_numpy(np.asarray(i))  #256 256 3\n    x_train = x_train.reshape(1, 3, 256, 256)\n    X_train = torch.cat((X_train, x_train), dim = 0)\n\nY_train = torch.Tensor()\nY_train_list = []\nfor j in y1:\n    #y_train = torch.from_numpy(np.asarray(j)) #256 256 2\n    #y_train = torch.squeeze(y_train)\/255  #0-255\n    #y_train = y_train.reshape(1, 256, 256)\n    #Y_train = torch.cat((Y_train, y_train), dim = 0)\n\n    y_train = torch.from_numpy(np.asarray(j))\n    y_train = y_train.reshape(1, 1, 256, 256)\n    Y_train = torch.cat((Y_train, y_train), dim = 0)\n    \n\nX_test = torch.Tensor()\nX_test_list = []\nfor z in x2:\n    x_test = torch.from_numpy(np.asarray(z))\n    x_test = x_test.reshape(1, 3, 256, 256)\n    X_test = torch.cat((X_test, x_test), dim = 0)\n\nY_test = torch.Tensor()\nY_test_list = []\nfor g in y2:\n    #y_test = torch.from_numpy(np.asarray(g))\n    #y_test = torch.squeeze(y_test)\/255\n    #y_test = y_test.reshape(1, 256, 256)\n    #Y_test = torch.cat((Y_test, y_test), dim = 0)\n\n    y_test = torch.from_numpy(np.asarray(g))\n    y_test = y_test.reshape(1, 1, 256, 256)\n    Y_test = torch.cat((Y_test, y_test), dim = 0)\n\n\n#(trainX, testX, trainY, testY) = train_test_split(X_train, X_test, test_size=40, random_state=10, stratify=X_test)\n(trainX, testX, trainY, testY) = train_test_split(np.transpose(X_train), np.transpose(X_test), test_size=40, random_state=10)\n\n\n#class_weight = class_weight.compute_class_weight('balanced',np.unique(trainY),trainY)\n#class_weight = {i : class_weight[i] for i in range(2)}","d9d5b681":"# Based on https:\/\/github.com\/divamgupta\/image-segmentation-keras\/blob\/master\/keras_segmentation\/models\/unet.py#L19\nclass UNetMini(torch.nn.Module):\n\n    def __init__(self, num_classes):\n        super(UNetMini, self).__init__()\n\n        # Use padding 1 to mimic `padding='same'` in keras,\n        # use this visualization tool https:\/\/ezyang.github.io\/convolution-visualizer\/index.html\n        self.block1 = torch.nn.Sequential(\n            torch.nn.Conv2d(3, 32, kernel_size=3, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.Dropout2d(0.2),\n            torch.nn.Conv2d(32, 32, kernel_size=3, padding=1),\n            torch.nn.ReLU(),\n        )\n        self.pool1 = torch.nn.MaxPool2d((2, 2))\n\n        self.block2 = torch.nn.Sequential(\n            torch.nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.Dropout2d(0.2),\n            torch.nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            torch.nn.ReLU(),\n        )\n        self.pool2 = torch.nn.MaxPool2d((2, 2))\n\n        self.block3 = torch.nn.Sequential(\n            torch.nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.Dropout2d(0.2),\n            torch.nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            torch.nn.ReLU()\n        )\n\n        self.up1 = torch.nn.UpsamplingNearest2d(scale_factor=2)\n        self.block4 = torch.nn.Sequential(\n            torch.nn.Conv2d(192, 64, kernel_size=3, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.Dropout2d(0.2),\n            torch.nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            torch.nn.ReLU()\n        )\n\n        self.up2 = torch.nn.UpsamplingNearest2d(scale_factor=2)\n        self.block5 = torch.nn.Sequential(\n            torch.nn.Conv2d(96, 32, kernel_size=3, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.Dropout2d(0.2),\n            torch.nn.Conv2d(32, 32, kernel_size=3, padding=1),\n            torch.nn.ReLU()\n        )\n\n        self.conv2d = torch.nn.Conv2d(32, num_classes, kernel_size=1)\n\n        #self.fc1 = torch.nn.Linear(num_classes, num_classes)\n        #self.fc2 = torch.nn.Linear(num_classes, 2)\n\n        weights = [0.1, 1.0]\n        class_weights = torch.FloatTensor(weights)\n        self.criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n\n    def forward(self, x):\n        out1 = self.block1(x)\n        out_pool1 = self.pool1(out1)\n\n        out2 = self.block2(out_pool1)\n        out_pool2 = self.pool1(out2)\n\n        out3 = self.block3(out_pool2)\n\n        out_up1 = self.up1(out3)\n        # return out_up1\n        out4 = torch.cat((out_up1, out2), dim=1)\n        out4 = self.block4(out4)\n\n        out_up2 = self.up2(out4)\n        out5 = torch.cat((out_up2, out1), dim=1)\n        out5 = self.block5(out5)\n\n        out = self.conv2d(out5)\n\n        #out = self.fc1(x)\n        #out = self.fc2(x)\n\n        return out\nfrom torchsummary import summary\nprice_net = UNetMini(2) \n#summary(price_net, input_size=(3, 256, 256))","dbeb9985":"#price_net=torch.load('\/gdrive\/My Drive\/GPO\/price_net_full_2_5.pth')\nprice_net.load_state_dict(torch.load('\/gdrive\/My Drive\/GPO\/unet.pt'), strict=False)","d37eab35":"price_net.requires_grad_ = False\n#price_net.fc1.weight.requires_grad = True\n#price_net.fc1.bias.requires_grad = True\n#price_net.fc2.weight.requires_grad = True\n#price_net.fc2.bias.requires_grad = True\nprice_net.conv2d.weight.requires_grad = True\nprice_net.conv2d.bias.requires_grad = True","5ae39c18":"loss = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(price_net.parameters(), lr=0.0001)\n#optimizer = torch.optim.SGD(price_net.parameters(), lr=0.0001, momentum = 0.9)\n#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)","61b913bf":"batch_size =  10\n\ntest_accuracy_history = []\ntest_loss_history = []\nrecall_history = []\nprec_history = []\nf1_history = []\n\nfor epoch in range(17):\n    order = np.random.permutation(len(X_train))\n    for start_index in range(0, len(X_train), batch_size):\n        optimizer.zero_grad()\n        \n        batch_indexes = order[start_index:start_index+batch_size]\n        \n        x_batch = X_train[batch_indexes]\n        y_batch = Y_train[batch_indexes]\n\n        #logits, _ = price_net(x_batch)\n        #loss_value = criterion(logits, y_batch)\n\n        #scheduler.step()\n        preds = price_net.forward(x_batch) \n        #loss_value = price_net.criterion(preds, torch.tensor((y_batch), dtype=torch.long))\n        loss_value = price_net.criterion(preds, torch.tensor(torch.squeeze(y_batch)\/255, dtype=torch.long))\n        loss_value.backward()\n        \n        optimizer.step()\n\n        \n   \n    if epoch % 4 == 0:\n        #i=int(epoch\/4)\n        test_preds = price_net.forward(X_test)\n        #print(Y_train.shape)\n        #test_loss_history.append(loss(test_preds, torch.tensor(torch.squeeze(Y_test)\/255, dtype=torch.long)))\n        #test_loss_history.append(loss(test_preds, torch.tensor(Y_test, dtype=torch.long)))\n\n        #test_logits, _ = price_net(X_test)\n        #test_loss_value = price_net.criterion(test_preds, torch.tensor((Y_test), dtype=torch.long))\n        test_loss_value = price_net.criterion(test_preds, torch.tensor(torch.squeeze(Y_test)\/255, dtype=torch.long))\n        test_loss_history.append(test_loss_value)\n\n        #accuracy = (test_preds.argmax(dim=1) == Y_test).float().mean()\n        accuracy = (test_preds.argmax(dim=1) == Y_test).float().mean()\n        #recall = recall_m(Y_test, test_preds.argmax(dim=1))\n        recall = recall_m(Y_test, test_preds.detach().numpy())\n        recall_history.append(recall)\n        #print(Y_test.shape)\n        #prec = precision_m(Y_test, np.asarray(test_preds.argmax(dim=1)).astype(int64))\n        prec = precision_m(Y_test, test_preds.detach().numpy())\n        prec_history.append(prec)\n        f1 = f1_m(Y_test, test_preds.detach().numpy())\n        f1_history.append(f1)\n        test_accuracy_history.append(accuracy)\n\n        \n        print(epoch, loss, accuracy, flush=True)\n        #print(np.asarray(test_preds.argmax(dim=1) == Y_test))\n        print(recall)\n        print(prec)\n        print(f1)\n        print('-----------------------')","2fc9c1b5":"torch.save(price_net, '\/gdrive\/My Drive\/GPO\/price_net_full_2_5.pth')","62a09aae":"torch.save(price_net.state_dict(), '\/gdrive\/My Drive\/GPO\/price_net.pth')","b5d7ae93":"plt.imshow(y_batch[0])","da8fdfcb":"#test_preds.shape\n\n#test_preds1 = torch.squeeze(test_preds)*255\n#test_preds1 = test_preds.reshape(20,1,256,256)\n#test_preds1.shape\n#test_preds1 = test_preds[:,:1,:,:]\nconv = torch.nn.Conv2d(2,1, kernel_size = 1)\ntest_preds1 = conv(test_preds)\n#test_preds1 = torch.squeeze(test_preds)*255","e11c9222":"#test_preds.shape\n\n#test_preds1 = torch.squeeze(test_preds)*255\n#test_preds1 = test_preds.reshape(20,1,256,256)\n#test_preds1.shape\n#test_preds1 = test_preds[:,:1,:,:]\nconv = torch.nn.Conv2d(2,1, kernel_size = 1)\ntest_preds1 = conv(test_preds)\n#test_preds1 = torch.squeeze(test_preds)*255","16830795":"test_preds2 = torch.squeeze(test_preds)*255\ntest_preds2 = test_preds.reshape(20,1,256,256)\ntest_preds2.shape","4e7d4469":"def plot_sample(X, y, preds, ix=None):\n    \"\"\"Function to plot the results\"\"\"\n    if ix is None:\n        ix = random.randint(0, len(X))\n\n    has_mask = y[ix].max() > 0\n\n    fig, ax = plt.subplots(1, 3, figsize=(20, 10))\n    ax[0].imshow(X[ix, ..., 0], cmap='seismic')\n    if has_mask:\n        ax[0].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n    ax[0].set_title('price tag')\n\n    ax[1].imshow(y[ix].squeeze())\n    ax[1].set_title('mask')\n\n    ax[2].imshow(preds[ix].detach().numpy().squeeze(), vmin=0, vmax=1)\n    if has_mask:\n        ax[2].contour(y[ix].detach().numpy().squeeze(), colors='k', levels=[0.5])\n    ax[2].set_title('Predicted')","33978144":"#test_preds3 = price_net(X_test)","5511b62e":"#test_preds3 = torch.squeeze(test_preds3)*255\n#test_preds3 = test_preds3.reshape(20,1,256,256)\n#test_preds3.shape","3855f8e0":"plot_sample(X_test, Y_test, test_preds2)","678d5a43":"#plt.plot(test_accuracy_history)\n#plt.plot(test_loss_history);","84b6be3c":"#Git_Unet = torch.hub.load('mateuszbuda\/brain-segmentation-pytorch', 'unet',\n#    in_channels=3, out_channels=1, init_features=32, pretrained=True)","68f6a02e":"#Git_Unet = torch.load('\/gdrive\/My Drive\/GPO\/unet.pt')","2044399c":"#Git_Unet.requires_grad = False","5f022bb5":"#weights = [0.1, 1.0]\n#class_weights = torch.FloatTensor(weights)\n#self.criterion = torch.nn.CrossEntropyLoss(weight=class_weights)","08c26bcd":"#test_preds4 = Git_Unet(X_test)","347407c1":"#ResNet = models.segmentation.fcn_resnet50(pretrained=True, progress=True, num_classes=21, aux_loss=None)\n#ResNet.requires_grad = False","b615e42f":"#test_preds5 = ResNet(X_test)","16fc5bea":"#Test_preds5 = torch.tensor(test_preds5)\n#Test_preds5 = torch.squeeze(Test_preds5)*255\n#Test_preds5 = Test_preds5.reshape(20,1,256,256)\n#Test_preds5.shape","06c0ad6e":"Metrics","75e7ef68":"Data set","105fa3d2":"Price_net resaults","8149d4a9":"Price_net learning","5136d050":"ResNet50","84f6b4ae":"UNet transfer"}}