{"cell_type":{"1835e609":"code","508c1738":"code","9eeaeed0":"code","e30fb0c4":"code","30c621da":"code","4e6e14e5":"code","5f3b942a":"code","5906f3e9":"code","40a7fcf5":"code","218ee7c6":"code","a5b83a9f":"code","afdfdf42":"code","f8c9f81a":"code","e0b5f416":"code","dab4535b":"code","1abfbc87":"code","14391f7e":"code","aa6a0ff0":"code","63f5af9c":"code","2005ee46":"code","66e13ff0":"code","e9bb8735":"code","ee3a776a":"code","20a6fa4e":"code","2320c03a":"code","0b661e33":"code","55ed4292":"code","c54b8597":"markdown","08b95e3b":"markdown","a4860eb4":"markdown","2719cdf1":"markdown","0abe4e38":"markdown","7aeb9f6d":"markdown","09300769":"markdown","25bbff0c":"markdown","1abd0f09":"markdown","91710a9f":"markdown","9799664c":"markdown","8620d977":"markdown","c32ffcc4":"markdown","e0def171":"markdown","b464bc1d":"markdown"},"source":{"1835e609":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras.models import Sequential\nfrom keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Bidirectional,Flatten, LSTM, Dense, Lambda, Activation, BatchNormalization, Dropout\nfrom keras.optimizers import Adam","508c1738":"def getUnreadableCount(df):\n    return (df['IDENTITY'] == 'UNREADABLE').sum();\n\ndef getLowercaseCount(df):\n    return (df['IDENTITY'].str.islower()).sum();\n\ndef getDigitCount(df):\n    return (df['IDENTITY'].str.isdigit()).sum();\n  \ndef removeUnreadableEntries(df):\n    is_unreadable = df['IDENTITY'] != 'UNREADABLE';\n    df = df[is_unreadable];\n    return df;\n\ndef removeDigitEntries(df):\n    is_digit = df['IDENTITY'].str.isdigit();\n    df = df[is_digit];\n    return df;\n\ndef cleanDataSet(df):\n    empty_count = df.isnull().sum().sum();      # 565 for train, 78 for validation\n    if(empty_count):\n        df.dropna(inplace=True);\n    unreadable_count = getUnreadableCount(df);  # 102 for train, 12 for validation\n    if(unreadable_count):\n        df = removeUnreadableEntries(df);\n    digit_count = getDigitCount(df);            # 0 for train, 0 for validation\n    if(digit_count):\n        df = removeDigitEntries(df);\n    lowercase_count = getLowercaseCount(df);    # 13 for train, 2 for validation\n    if(lowercase_count):\n        # Names in the pictures are all uppercase, we have to make our data uppercase\n        df.loc[:, 'IDENTITY'] = df['IDENTITY'].apply(lambda x: x.upper());\n    notpicture_count = df[~df[\"FILENAME\"].str.endswith('.jpg')].sum().sum().astype(int);\n    if(notpicture_count):                       # 0 for train, 0 for validation\n         df = df[df[\"FILENAME\"].str.contains('.jpg')];\n    return df;\n\ndef num_to_char(num): \n    label = \"\"\n    for ch in num:\n        if ch == -1:\n            break\n        label+=alphabet_characters[ch]        \n    return label\n\ndef ctc_loss_function(args):  \n    y_pred, y_true, input_length, label_length = args\n    return tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)","9eeaeed0":"train_size = 50000\nvalid_size= 10000\nalphabet_characters = u\"ABCDEFGHIJKLMNOPQRSTUVWXYZ-' \"\nnum_of_characters = len(alphabet_characters) + 1\nnum_of_timestamps = 64","e30fb0c4":"training_written_df = pd.read_csv('\/kaggle\/input\/handwriting-recognition\/written_name_train_v2.csv')\nvalidation_written_df = pd.read_csv('\/kaggle\/input\/handwriting-recognition\/written_name_validation_v2.csv')","30c621da":"training_written_df = cleanDataSet(training_written_df);\nvalidation_written_df = cleanDataSet(validation_written_df);\n    \n# To make sure our indices are one behind the other\ntraining_written_df.reset_index(inplace = True, drop=True)\nvalidation_written_df.reset_index(inplace = True, drop=True) ","4e6e14e5":"i = 128;\nimg_dir = '\/kaggle\/input\/handwriting-recognition\/train_v2\/train\/'+training_written_df.loc[i, 'FILENAME']\nimage = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\nnew_img = cv2.resize(image, (128, 64))\nplt.imshow(new_img, cmap = 'gray')\nplt.show()","5f3b942a":"i = 128;\nimg_dir = '\/kaggle\/input\/handwriting-recognition\/train_v2\/train\/'+training_written_df.loc[i, 'FILENAME']\nimage = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\nnew_img = cv2.resize(image, (256, 32))\nplt.imshow(new_img, cmap = 'gray')\nplt.show()","5906f3e9":"valid_x = []\nfor i in range(valid_size):\n    img_dir = '\/kaggle\/input\/handwriting-recognition\/validation_v2\/validation\/'+validation_written_df.loc[i, 'FILENAME']   \n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (256, 32));\n    image = tf.keras.utils.normalize(image, axis = 1)\n    image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n    valid_x.append(image)\n    \ntrain_x = []\nfor j in range(train_size):\n    img_dir = '\/kaggle\/input\/handwriting-recognition\/train_v2\/train\/'+training_written_df.loc[j, 'FILENAME']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (256, 32));\n    image = tf.keras.utils.normalize(image, axis = 1)\n    image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n    train_x.append(image)\n","40a7fcf5":"valid_x = np.array(valid_x).reshape(-1, 256, 32, 1)\ntrain_x = np.array(train_x).reshape(-1, 256, 32, 1)\n\nstr_len = training_written_df[\"IDENTITY\"].str.len().max()\n","218ee7c6":"train_y = np.ones([train_size, str_len]) * -1\n\ntrain_label_len = np.zeros([train_size, 1])\ntrain_input_len = np.ones([train_size, 1]) * (num_of_timestamps-2)\ntrain_output = np.zeros([train_size])\n\nvalid_y = np.ones([valid_size, str_len]) * -1\n\nvalid_label_len = np.zeros([valid_size, 1])\nvalid_input_len = np.ones([valid_size, 1]) * (num_of_timestamps-2)\nvalid_output = np.zeros([valid_size])","a5b83a9f":"for i in range(train_size):\n    label = []\n    for ch in training_written_df['IDENTITY'][i]:\n        label.append(alphabet_characters.index(ch))\n    arr = np.array(label)\n    train_y[i, 0:len(training_written_df.loc[i, 'IDENTITY'])] = arr;\n    train_label_len[i] = len(training_written_df.loc[i, 'IDENTITY'])\n\n\nfor i in range(valid_size):\n    label = []\n    for ch in validation_written_df['IDENTITY'][i]:\n        label.append(alphabet_characters.index(ch))\n    arr = np.array(label)\n    valid_y[i, 0:len(validation_written_df.loc[i, 'IDENTITY'])] = arr;\n    valid_label_len[i] = len(validation_written_df.loc[i, 'IDENTITY'])\n","afdfdf42":"model_seq = Sequential()\n\nmodel_seq.add(Conv2D(32, (3, 3), padding='same', input_shape=(256, 32, 1)))\nmodel_seq.add(Activation('relu'))\nmodel_seq.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_seq.add(BatchNormalization())\n\nmodel_seq.add(Conv2D(64, (3, 3), padding='same'))\nmodel_seq.add(Activation('relu'))\nmodel_seq.add(MaxPooling2D(pool_size=(1, 2)))\nmodel_seq.add(Dropout(0.3))\nmodel_seq.add(BatchNormalization())\n\nmodel_seq.add(Flatten())\nmodel_seq.add(Dropout(0.3))\n\nmodel_seq.add(Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1'))\nmodel_seq.add(Activation('relu'))\nmodel_seq.add(Dropout(0.2))\n\nmodel_seq.add(Dense(34))\nmodel_seq.add(Activation('relu'))\nmodel_seq.add(Dropout(0.2))\nmodel_seq.add(Activation('softmax'))\n\ninput_data = Input(shape=(256, 32, 1), name='input')\ny_pred_seq = model_seq(input_data)","f8c9f81a":"optimizer = 'adam'\nmodel_seq.compile(loss=tf.keras.losses.MeanAbsoluteError(), optimizer=optimizer, metrics=['accuracy'])\n\nmodel_seq.summary()","e0b5f416":"early_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_loss\", patience=5, restore_best_weights=True\n)\nmy_callbacks = [\n    tf.keras.callbacks.EarlyStopping(patience=10)\n]","dab4535b":"seq_history = model_seq.fit(train_x, train_y, validation_data=(valid_x, valid_y), epochs=30, batch_size=64, callbacks=my_callbacks)","1abfbc87":"input_data = Input(shape=(256, 32, 1))\n\ncnn_layer = Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal')(input_data)  \ncnn_layer = BatchNormalization()(cnn_layer)\ncnn_layer = Activation('relu')(cnn_layer)\ncnn_layer = MaxPooling2D(pool_size=(2, 2))(cnn_layer)\n    \ncnn_layer = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal')(cnn_layer)\ncnn_layer = BatchNormalization()(cnn_layer)\ncnn_layer = Activation('relu')(cnn_layer)\ncnn_layer = MaxPooling2D(pool_size=(1, 2))(cnn_layer)\ncnn_layer = Dropout(0.3)(cnn_layer)\n    \ncnn_layer = Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal')(cnn_layer)\ncnn_layer = BatchNormalization()(cnn_layer)\ncnn_layer = Activation('relu')(cnn_layer)\ncnn_layer = MaxPooling2D(pool_size=(1, 1))(cnn_layer)\ncnn_layer = Dropout(0.3)(cnn_layer)\n\ncnn_layer = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal')(cnn_layer)\ncnn_layer = BatchNormalization()(cnn_layer)\ncnn_layer = Activation('relu')(cnn_layer)\ncnn_layer = MaxPooling2D(pool_size=(2, 2))(cnn_layer)\ncnn_layer = Dropout(0.3)(cnn_layer)\n    \n# CNN to RNN\nreshaped_layer = Reshape(target_shape=((64, 1024)))(cnn_layer)\ndense_layer = Dense(64, activation='relu', kernel_initializer='he_normal')(reshaped_layer)\n    \n## RNN\nrnn_layer = Bidirectional(LSTM(256, return_sequences=True))(dense_layer)\nrnn_layer = Bidirectional(LSTM(256, return_sequences=True))(rnn_layer)\n    \n## OUTPUT\nfinal_dense_layer = Dense(num_of_characters, kernel_initializer='he_normal')(rnn_layer)\ny_pred = Activation('softmax')(final_dense_layer)\n\nmodel = Model(inputs=input_data, outputs=y_pred)\nmodel.summary()","14391f7e":"early_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_loss\", patience=5, restore_best_weights=True\n)\nmy_callbacks = [\n    tf.keras.callbacks.EarlyStopping(patience=10)\n]","aa6a0ff0":"true_labels = Input(shape=[str_len], dtype='float32')\ninput_length = Input(shape=[1], dtype='int64')\nlabel_length = Input(shape=[1], dtype='int64')\n\nctc_loss = Lambda(ctc_loss_function, output_shape=(1,), name='ctc_loss')([y_pred, true_labels, input_length, label_length])\nmodel_final = Model(inputs=[input_data, true_labels, input_length, label_length], outputs=ctc_loss)","63f5af9c":"model_final.compile(loss={'ctc_loss' : lambda y_true, y_pred: y_pred}, optimizer=Adam(lr = 0.0001))","2005ee46":"history = model_final.fit(x=[train_x, train_y, train_input_len, train_label_len], y=train_output, \n                validation_data=([valid_x, valid_y, valid_input_len, valid_label_len], valid_output),\n                epochs=30, batch_size=64, callbacks=my_callbacks)","66e13ff0":"loss_train = np.array(history.history['loss'])\nloss_val = np.array(history.history['val_loss'])\nepochs = range(1,31)\nplt.plot(epochs, loss_train, 'g', label='Training loss')\nplt.plot(epochs, loss_val, 'b', label='validation loss')\nplt.title('Training and Validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","e9bb8735":"def decode_batch_predictions(pred):\n    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n    # Use greedy search. For complex tasks, you can use beam search\n    results = tf.keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]\n\n    output_text = []\n    for i in range(valid_size):\n        output_text.append(num_to_char(K.get_value(results[i])))\n    return output_text\n","ee3a776a":"model_valid_prediction = model.predict(valid_x)\ndecoded_valid_prediction = decode_batch_predictions(model_valid_prediction)","20a6fa4e":"valid_true_labels = validation_written_df.loc[0:valid_size, 'IDENTITY']\ncorrect = 0\n\nfor i in range(valid_size):\n    pr = decoded_valid_prediction[i]\n    tr = valid_true_labels[i]\n    \n    if pr == tr :\n        correct += 1 \n    \nprint('Correct words in validation predicted: %.2f%%' %(correct*100\/valid_size))","2320c03a":"test_written_df = pd.read_csv('\/kaggle\/input\/handwriting-recognition\/written_name_test_v2.csv')\ntest_size = 10000\ntest_written_df = cleanDataSet(test_written_df);\n    \n# To make sure our indices are one behind the other\ntest_written_df.reset_index(inplace = True, drop=True)\n\ntest_x = []\nfor i in range(valid_size):\n    img_dir = '\/kaggle\/input\/handwriting-recognition\/test_v2\/test\/'+test_written_df.loc[i, 'FILENAME']   \n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (256, 32));\n    image = tf.keras.utils.normalize(image, axis = 1)\n    image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n    test_x.append(image)\n    \ntest_x = np.array(test_x).reshape(-1, 256, 32, 1)\ntest_y = np.ones([test_size, str_len]) * -1\n\nfor i in range(test_size):\n    label_num = []\n    for ch in test_written_df['IDENTITY'][i]:\n        label_num.append(alphabet_characters.index(ch))\n    arr = np.array(label_num)\n    test_y[i, 0:len(test_written_df.loc[i, 'IDENTITY'])] = arr;","0b661e33":"model_test_prediction = model.predict(test_x)\ndecoded_test_prediction = decode_batch_predictions(model_test_prediction)\n\ntest_labels = test_written_df.loc[0:test_size, 'IDENTITY']\ncorrect = 0\n\nfor i in range(test_size):\n    pr = decoded_test_prediction[i]\n    tr = test_labels[i]\n    \n    if pr == tr :\n        correct += 1 \n    \nprint('Correct words in test predicted: %.2f%%' %(correct*100\/test_size))\n","55ed4292":"for i in range(5,14):\n    img_dir = '\/kaggle\/input\/handwriting-recognition\/test_v2\/test\/'+test_written_df.loc[i, 'FILENAME']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    plt.imshow(image, cmap='gray')\n    image = cv2.resize(image, (256, 32));\n    image = tf.keras.utils.normalize(image, axis = 1)\n    image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n    prediction = model.predict(image.reshape(1, 256, 32, 1))\n    decoded_label = K.get_value(K.ctc_decode(prediction, input_length=np.ones(prediction.shape[0])*prediction.shape[1],greedy=True)[0][0])\n    plt.title(num_to_char(decoded_label[0]))\n    plt.show()","c54b8597":"# Loading the training and validation written names","08b95e3b":"# RCNN Model","a4860eb4":"Calculation of ctc loss function","2719cdf1":" # Data cleaning","0abe4e38":"Compiling the model","7aeb9f6d":"# CNN Model","09300769":"# Random image reconstruction, with the predicted labels","25bbff0c":"# Data preparation","1abd0f09":"Compiling of model","91710a9f":"# Loading, cleaning and prediction on the test set (10 000 examples)[](http:\/\/)","9799664c":"# Example of picture after resizing to 128x64 and 256x32 ","8620d977":"# Using the decoding function from Keras (Example for reading Captchas)","c32ffcc4":"Training of model","e0def171":"# Label preparation\n","b464bc1d":"Early stopping function"}}