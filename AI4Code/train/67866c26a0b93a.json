{"cell_type":{"4b5180b1":"code","71c48e72":"code","52f26cef":"code","9976bed0":"code","eed39627":"code","2c139200":"code","16f80f0c":"code","97f0274b":"markdown","7189b01c":"markdown","834dfecb":"markdown","f7879924":"markdown","cd6838c6":"markdown","e560893f":"markdown","1d73f56d":"markdown"},"source":{"4b5180b1":"# Familiar imports\nimport numpy as np\nimport pandas as pd\n\n# For ordinal encoding categorical variables, splitting data\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.model_selection import train_test_split\n\n# For training XGBBooster\nfrom xgboost import XGBRegressor\n\nfrom sklearn.metrics import mean_squared_error\n","71c48e72":"# Load the training data\ntrain = pd.read_csv(\"..\/input\/30-days-of-ml\/train.csv\", index_col=0)\ntest = pd.read_csv(\"..\/input\/30-days-of-ml\/test.csv\", index_col=0)\n\n# Preview the data\ntrain.head()","52f26cef":"# Separate target from features\ny = train['target']\nfeatures = train.drop(['target'], axis=1)\n\n# Preview features\nfeatures.head()","9976bed0":"# List of categorical columns\nobject_cols = [col for col in features.columns if 'cat' in col]\n\n# ordinal-encode categorical columns\nX = features.copy()\nX_test = test.copy()\nordinal_encoder = OrdinalEncoder()\nX[object_cols] = ordinal_encoder.fit_transform(features[object_cols])\nX_test[object_cols] = ordinal_encoder.transform(test[object_cols])\n\n# Preview the ordinal-encoded features\nX.head()","eed39627":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=0)","2c139200":"# Define the model \nxgb_params = {'n_estimators':5000,'learning_rate': 0.1,\n             'tree_method':'gpu_hist', 'n_jobs': 4,\n             'max_depth': 3, 'min_child_weight':5}\nmodel = XGBRegressor(**xgb_params)\nmodel.fit(X_train, y_train,\n             early_stopping_rounds=100, \n             eval_set=[(X_train,y_train),(X_valid, y_valid)],\n             eval_metric = \"rmse\",\n             verbose=False)\npreds_valid = model.predict(X_valid)\nprint(\"RMSE:\" ,mean_squared_error(y_valid, preds_valid, squared=False))","16f80f0c":"# Use the model to generate predictions\npredictions = model.predict(X_test)\n\n# Save the predictions to a CSV file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'target': predictions})\noutput.to_csv('submission.csv', index=False)","97f0274b":"**[30 Days of ML competition](https:\/\/www.kaggle.com\/c\/30-days-of-ml\/overview)**!  \n\n\n\n# Step 1: Import helpful libraries\n\nWe begin by importing the libraries we'll need.","7189b01c":"In the code cell above, we set `squared=False` to get the root mean squared error (RMSE) on the validation data.\n\n# Step 5: Submit to the competition\n\nWe'll begin by using the trained model to generate predictions, which we'll save to a CSV file.","834dfecb":"# Step 4: Train a model\n\nNow that the data is prepared, the next step is to train a model.  \n\n In the code cell below, we fit a random forest model to the data.","f7879924":"# Step 2: Load the data\n\nNext, we'll load the training and test data.  \n\nWe set `index_col=0` in the code cell below to use the `id` column to index the DataFrame.  (*If you're not sure how this works, try temporarily removing `index_col=0` and see how it changes the result.*)","cd6838c6":"The next code cell separates the target (which we assign to `y`) from the training features (which we assign to `features`).","e560893f":"Next, we break off a validation set from the training data.","1d73f56d":"# Step 3: Prepare the data\n\nNext, we'll need to handle the categorical columns (`cat0`, `cat1`, ... `cat9`).  "}}