{"cell_type":{"765258f3":"code","bd4613ba":"code","1a26dfd8":"code","f9fea4b1":"code","9fad25f6":"code","c382d42d":"code","3150d558":"code","a491dc9b":"code","5ff5d310":"code","22f27de8":"code","ee35232e":"code","28e07344":"code","2d9fc00f":"code","9fdeca04":"markdown","291c9868":"markdown","562f4b27":"markdown","d2162358":"markdown","1cc9ebe6":"markdown","d782f525":"markdown","d38c7292":"markdown"},"source":{"765258f3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bd4613ba":"# Import libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential, layers","1a26dfd8":"train_loc='..\/input\/chest-xray-pneumonia\/chest_xray\/train'\ntest_loc= '..\/input\/chest-xray-pneumonia\/chest_xray\/test'\nval_loc='..\/input\/chest-xray-pneumonia\/chest_xray\/val'\n\n","f9fea4b1":"input_height=128\ninput_width=128\nbatch_size=32","9fad25f6":"train_ds=tf.keras.preprocessing.image_dataset_from_directory(train_loc, \n                                                             color_mode='grayscale', \n                                                             image_size=(input_height, input_width), \n                                                             batch_size=batch_size)\n\ntest_ds=tf.keras.preprocessing.image_dataset_from_directory(test_loc, \n                                                             color_mode='grayscale', \n                                                             image_size=(input_height, input_width), \n                                                             batch_size=batch_size)\n\nval_ds=tf.keras.preprocessing.image_dataset_from_directory(val_loc, \n                                                             color_mode='grayscale', \n                                                             image_size=(input_height, input_width), \n                                                             batch_size=batch_size)","c382d42d":"train_ds.take(1)","3150d558":"train_ds.class_names","a491dc9b":"plt.figure(figsize=(10,10))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        \n        plt.subplot(3, 3, i+1)\n        plt.imshow(np.squeeze(images[i].numpy().astype('uint8')))\n        plt.title(train_ds.class_names[labels[i]])\n        plt.axis('off')\n","5ff5d310":"AUTOTUNE = tf.data.experimental.AUTOTUNE\n\ntrain_ds=train_ds.cache().prefetch(buffer_size=AUTOTUNE)\ntest_ds=test_ds.cache().prefetch(buffer_size=AUTOTUNE)\nval_ds=val_ds.cache().prefetch(buffer_size=AUTOTUNE)","22f27de8":"model=Sequential()\nmodel.add(layers.experimental.preprocessing.Rescaling(1.\/255))\n\nmodel.add(layers.Conv2D(32,3, activation='relu'))\nmodel.add(layers.MaxPooling2D())\n\nmodel.add(layers.Conv2D(32,3, activation='relu'))\nmodel.add(layers.MaxPooling2D())\n\nmodel.add(layers.Conv2D(32,3, activation='relu'))\nmodel.add(layers.MaxPooling2D())\n\nmodel.add(layers.Flatten())\n\nmodel.add(layers.Dense(128, activation='relu'))\n\nmodel.add(layers.Dense(2, activation='sigmoid'))\n\n","ee35232e":"model.compile(optimizer='adam', loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])","28e07344":"model.fit(train_ds, validation_data=val_ds, epochs=10)","2d9fc00f":"model.evaluate(test_ds)","9fdeca04":"Shape of the 1st batch","291c9868":"#### Path of each dataset","562f4b27":"#### Preprocessing images of train, test and validation set","d2162358":"Let's cache and prefetch the data for fast learning","1cc9ebe6":"#### Setting input image dimensions","d782f525":"Let's visualize some of the images in 1st batch","d38c7292":"### Let's setup the model now"}}