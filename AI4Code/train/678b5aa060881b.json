{"cell_type":{"55584eb1":"code","7d3674fc":"code","53f4328e":"code","34a8ac01":"code","edda9b78":"code","056695e1":"code","6a5b43db":"code","b29e51af":"code","fc8b31c6":"code","fe4fce42":"code","a356fb21":"code","dbfc2c41":"code","ca3d68d9":"code","07ed4ec1":"code","7aec1c68":"code","e0d1ee14":"code","aa4ed802":"code","f896eba2":"code","53209ffb":"code","c1a633de":"code","e53bf033":"code","1ee5da7a":"code","e94e6f82":"code","834c8f31":"code","92894652":"code","1c2d950e":"code","debba615":"code","fdad9bda":"code","33a6be3b":"code","39e4f723":"code","b2775c9b":"code","74061762":"code","0ed9a5b0":"code","0639bd7f":"code","7807c729":"code","eb08cee6":"code","35688d3d":"code","1775f97a":"markdown","97bcc0e1":"markdown","a1c1192d":"markdown","91d26de3":"markdown","52b0a2b6":"markdown","f10dd344":"markdown","0cd65d3a":"markdown","13eb63ea":"markdown","762db9ab":"markdown","3e24e624":"markdown","0328bdc3":"markdown","c98650ac":"markdown","4f878f96":"markdown","d110ea43":"markdown"},"source":{"55584eb1":"## Starter code from Kaggle\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n","7d3674fc":"## imports from zero2gans \nimport os\nimport torch\nimport torchvision\nimport tarfile\nimport torch.nn as nn\nimport numpy as np\nimport torch.nn.functional as F\nfrom torchvision.datasets.utils import download_url\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as tt\nfrom torch.utils.data import random_split\nfrom torchvision.utils import make_grid\nimport matplotlib.pyplot as plt\n%matplotlib inline","53f4328e":"project_name = 'cats-and-dogs'","34a8ac01":"# Look into the data directory\ndata_dir = '\/kaggle\/input\/cat-and-dog'\nprint(os.listdir(data_dir))\nclasses = os.listdir(data_dir + \"\/test_set\/test_set\")\nprint(classes)","edda9b78":"classes = os.listdir(data_dir + '\/training_set\/training_set')\nprint(classes)","056695e1":"# transformation\nstats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\ntrain_transform = tt.Compose([tt.Resize(64),\n                              tt.RandomCrop(64, padding=4, padding_mode='reflect'),\n                              tt.RandomHorizontalFlip(),\n                              tt.ToTensor(),\n                              tt.Normalize(*stats, inplace=True)])\n\n#normalizing the validation image size before transforming to tensor\nvalid_transform = tt.Compose([tt.Resize(64),\n                              tt.CenterCrop(64),\n                              tt.ToTensor(),\n                              tt.Normalize(*stats)])","6a5b43db":"# Pytorch datasets\ntrain_ds = ImageFolder(data_dir+'\/training_set\/training_set', valid_transform)\nvalid_ds = ImageFolder(data_dir+'\/test_set\/test_set' ,train_transform)","b29e51af":"torch.manual_seed(17)\ntest_size = 500\nval_size = len(valid_ds) - test_size\nval_ds, test_ds = random_split(valid_ds, [val_size, test_size])","fc8b31c6":"len(train_ds)","fe4fce42":"len(val_ds)","a356fb21":"len(test_ds)","dbfc2c41":"batch_size = 64\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)\nvalid_dl = DataLoader(val_ds, batch_size*2, num_workers=3, pin_memory=True)\ntest_dl = DataLoader(test_ds, batch_size*2, num_workers=3, pin_memory=True)","ca3d68d9":"def show_batch(dl):\n    for images, labels in dl:\n        print('images.shape:', images.shape)\n        print('example label:', classes[labels[0]])\n        fig, ax = plt.subplots(figsize=(12, 12))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(images[:batch_size], nrow=16).permute(1, 2, 0))\n        break","07ed4ec1":"print('Example training data:')\nshow_batch(train_dl)","7aec1c68":"print('Example validation data:')\nshow_batch(valid_dl)","e0d1ee14":"print('Example test data:')\nshow_batch(test_dl)","aa4ed802":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","f896eba2":"device = get_default_device()\ndevice","53209ffb":"# wrap classic data loaders into a device loader (GPU, if available)\ntrain_dl = DeviceDataLoader(train_dl, device)\nvalid_dl = DeviceDataLoader(valid_dl, device)\ntest_dl = DeviceDataLoader(test_dl, device)","c1a633de":"def plot_losses(history):\n    losses = [x['val_loss'] for x in history]\n    plt.plot(losses, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.title('Loss vs. No. of epochs');\n\ndef plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');","e53bf033":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))\n\ndef evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        for batch in train_loader:\n            loss = model.training_step(batch)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))","1ee5da7a":"input_size = 3*64*64\noutput_size = 2 #only 2 output classes. 'cats' and 'dogs'","e94e6f82":"class CatsAndDogsModel(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 128 x 32 x 32\n\n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 256 x 16 x 16\n\n            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 512 x 8 x 8\n\n            nn.Flatten(), \n            nn.Linear(512*8*8, 1024),\n            nn.ReLU(),\n            nn.Linear(1024, 512),\n            nn.ReLU(),\n            nn.Linear(512, 2))\n        \n    def forward(self, xb):\n        return self.network(xb)","834c8f31":"model = to_device(CatsAndDogsModel(), device)","92894652":"history = [evaluate(model, valid_dl)]\nhistory","1c2d950e":"num_epochs = 10\nopt_func = torch.optim.Adam\nlr = 3e-4","debba615":"history += fit(num_epochs, lr, model, train_dl, valid_dl, opt_func)","fdad9bda":"history += fit(10, 0.001, model, train_dl, valid_dl, opt_func)","33a6be3b":"history += fit(5, 0.0001, model, train_dl, valid_dl , opt_func)","39e4f723":"plot_losses(history)","b2775c9b":"plot_accuracies(history)","74061762":"test_res = evaluate(model, test_dl)\ntest_res","0ed9a5b0":"# arch = \"3 layer feed forward (128,64,10) on gpu\"\n# lrs = [10e-4, 10e-6, 10e-7]\n# epochs = [4, 3, 3]\ntorch.save(model.state_dict(), 'cat-and-dog.pth')","0639bd7f":"!pip install jovian --upgrade --quiet","7807c729":"import jovian","eb08cee6":"jovian.commit(project=project_name, environment=None)","35688d3d":"# log hyper parameters\njovian.reset()\njovian.log_hyperparams({\n    'num_epochs': num_epochs,\n    'opt_func': opt_func.__name__,\n    'batch_size': batch_size,\n    'lr': lr,\n})\njovian.log_metrics(test_loss=test_res['val_loss'], test_acc=test_res['val_acc'])\njovian.commit(project=project_name, outputs=['cat-and-dog.pth'], environment=None)","1775f97a":"first, we'll see the initial history. We expect that in the first iteration, a random model should be right about 50% of the time (given only 2 options)","97bcc0e1":"## Setting up the Pipeline\nLet's use the Image Classification pipeline from our CIFAR10 feedforward network:","a1c1192d":"## Training the Model\nVery much like the CIFAR10 traing we have done, we'll set the size of our in- and outputs.\nWe have to experiment with the batch sizes, because the images are a lot bigger than the CIFAR10 images.","91d26de3":"Check device compatibility","52b0a2b6":"## Setting up the GPU Support\nFor the first set of training (linear regression only), we are not going to use the GPU.","f10dd344":"So, after our training is done, we can evaluate how it worked out:","0cd65d3a":"# Classifying Cats and Dogs\n\nusing the kaggle cats-and-dogs dataset","13eb63ea":"## Preparing the Data","762db9ab":"so, let's see how many images we got to work with:","3e24e624":"As expected, we can now move on to use our fit function to train the model a bit more.","0328bdc3":"Next, we'll transform the data into a format, that is a uniform tensor.\nThe stats used for Normalize() are the same used for ResNet, and will make a transfer of pre trained ResNet Data easier to compare","c98650ac":"## Commit & to Jovian","4f878f96":"Helpers for plotting","d110ea43":"## Set Hyperparameters"}}