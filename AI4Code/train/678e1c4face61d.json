{"cell_type":{"d9eca93e":"code","352677d9":"code","5b9e694b":"code","1398974a":"code","6660d3eb":"code","6f6eb493":"code","7f6e5942":"code","84c1aad1":"code","4e345248":"code","5ef0221a":"code","6abe5e0f":"code","401ad01c":"code","81d52ffc":"code","03dabfc0":"code","2358ea10":"code","48baddb2":"code","36962cca":"code","417ee546":"code","21546c97":"code","1035609f":"code","b70fdc05":"code","90aabf6b":"code","0178de79":"code","9c008d43":"code","5a57995d":"code","6a0fac4e":"code","b16f9840":"code","387609c5":"code","8f7edaad":"code","35ce9b12":"code","772c8d14":"code","b64fadae":"code","d3a7443a":"code","27408130":"code","ce52ae1b":"code","c3642dab":"code","484989a7":"code","afb65fce":"code","d2c459e0":"code","3de11dd8":"code","09a2b086":"code","28500f13":"code","7a53191d":"code","acdc68fe":"code","3be5048a":"code","f09e83da":"code","d1c96206":"code","bd9f2bae":"code","a59df8a3":"markdown","4a80500f":"markdown","3ee9f76f":"markdown","b4816f13":"markdown","27f13484":"markdown","1d28f878":"markdown","92c4308b":"markdown","b14229cd":"markdown","a8f5bb84":"markdown","16c8c2f3":"markdown","e7f1ce14":"markdown","5e3578cf":"markdown","363beb23":"markdown","82eef4d5":"markdown","b7873026":"markdown"},"source":{"d9eca93e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","352677d9":"# linear algebra\nimport numpy as np  \n\n# data processing\nimport pandas as pd  \n\n# data visualising\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\n# data preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# model building\nfrom sklearn.linear_model import LogisticRegression # Logistic Regression\nfrom sklearn.naive_bayes import GaussianNB # Naive Bayes\nfrom sklearn.svm import SVC # Support Vector Machine\nfrom sklearn.ensemble import RandomForestClassifier # Random Forest\nfrom sklearn.tree import DecisionTreeClassifier # Decision Tree\n\n# model evaluation\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\n# k-fold cross validation\nfrom sklearn.model_selection import cross_val_score","5b9e694b":"dataset = pd.read_csv('\/kaggle\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')","1398974a":"dataset.head()","6660d3eb":"dataset.tail()","6f6eb493":"dataset.columns","7f6e5942":"dataset.info()","84c1aad1":"plt.figure(figsize=(20,12))\nplt.suptitle('Continuous Features', fontsize=20)\nfor i in range(0, dataset[['age', 'creatinine_phosphokinase', 'ejection_fraction', 'platelets', 'serum_creatinine', 'serum_sodium', 'time']].shape[1]):\n    plt.subplot(3, 3, i+1)\n\n    sns.distplot(dataset[['age', 'creatinine_phosphokinase', 'ejection_fraction', 'platelets', 'serum_creatinine', 'serum_sodium', 'time']].iloc[:, i])","4e345248":"plt.figure(figsize=(20,12))\nplt.suptitle('Categorical Features', fontsize=20)\nfor i in range(0, dataset[['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking']].shape[1]):\n    plt.subplot(3, 3, i+1)\n\n    sns.countplot(dataset[['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking']].iloc[:, i], hue=dataset['DEATH_EVENT'])","5ef0221a":"plt.figure(figsize=(12,8))\nsns.heatmap(dataset.drop(columns=['DEATH_EVENT']).corr(), annot=True)\nplt.show()","6abe5e0f":"dataset.drop(columns=['DEATH_EVENT']).corrwith(dataset['DEATH_EVENT'])","401ad01c":"plt.figure(figsize=(12,8))\ndataset.drop(columns=['DEATH_EVENT']).corrwith(dataset['DEATH_EVENT']).plot.bar(title = 'Correlations with the response variable', rot = 45, grid = True, color = 'orange')\nplt.show()","81d52ffc":"# Finding the features having correlation more than 0.1 or less than -0.1\ncolumns = dataset.drop(columns=['DEATH_EVENT']).columns[np.array(abs(dataset.drop(columns=['DEATH_EVENT']).corrwith(dataset['DEATH_EVENT']).array) > 0.1)]\nprint(columns)","03dabfc0":"# Rejecting the features with weak correlations\nX = dataset[columns]\ny = dataset['DEATH_EVENT']","2358ea10":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","48baddb2":"sc = StandardScaler()\nX_train = pd.DataFrame(sc.fit_transform(X_train))\nX_test = pd.DataFrame(sc.transform(X_test))","36962cca":"classifier_lr = LogisticRegression(random_state=0)\nclassifier_lr.fit(X_train, y_train)\ny_pred_lr = classifier_lr.predict(X_test)","417ee546":"sns.heatmap(confusion_matrix(y_test, y_pred_lr), annot=True)\nplt.show()","21546c97":"accuracy_score(y_test, y_pred_lr)","1035609f":"model = []\nmodel_accuracy = []","b70fdc05":"model.append('Logistic Regression')\nmodel_accuracy.append(accuracy_score(y_test, y_pred_lr))","90aabf6b":"classifier_nb = GaussianNB()\nclassifier_nb.fit(X_train, y_train)\ny_pred_nb = classifier_nb.predict(X_test)","0178de79":"sns.heatmap(confusion_matrix(y_test, y_pred_nb), annot=True)\nplt.show()","9c008d43":"accuracy_score(y_test, y_pred_nb)","5a57995d":"model.append('Naive Bayes')\nmodel_accuracy.append(accuracy_score(y_test, y_pred_nb))","6a0fac4e":"classifier_svm_l = SVC(random_state = 0, kernel='linear')\nclassifier_svm_l.fit(X_train, y_train)\ny_pred_svm_l = classifier_svm_l.predict(X_test)","b16f9840":"sns.heatmap(confusion_matrix(y_test, y_pred_svm_l), annot=True)\nplt.show()","387609c5":"accuracy_score(y_test, y_pred_svm_l)","8f7edaad":"model.append('SVM Linear')\nmodel_accuracy.append(accuracy_score(y_test, y_pred_svm_l))","35ce9b12":"classifier_svm_rbf = SVC(random_state = 0, kernel='rbf')\nclassifier_svm_rbf.fit(X_train, y_train)\ny_pred_svm_rbf = classifier_svm_rbf.predict(X_test)","772c8d14":"sns.heatmap(confusion_matrix(y_test, y_pred_svm_rbf), annot=True)\nplt.show()","b64fadae":"accuracy_score(y_test, y_pred_svm_rbf)","d3a7443a":"model.append('SVM rbf')\nmodel_accuracy.append(accuracy_score(y_test, y_pred_svm_rbf))","27408130":"classifier_rf = RandomForestClassifier(criterion='entropy', n_jobs=10, random_state=10)\nclassifier_rf.fit(X_train, y_train)\ny_pred_rf = classifier_rf.predict(X_test)","ce52ae1b":"sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True)\nplt.show()","c3642dab":"accuracy_score(y_test, y_pred_rf)","484989a7":"model.append('Random Forest')\nmodel_accuracy.append(accuracy_score(y_test, y_pred_rf))","afb65fce":"classifier_dt = DecisionTreeClassifier(criterion = 'entropy', random_state=0)\nclassifier_dt.fit(X_train, y_train)\ny_pred_dt = classifier_dt.predict(X_test)","d2c459e0":"sns.heatmap(confusion_matrix(y_test, y_pred_dt), annot=True)\nplt.show()","3de11dd8":"accuracy_score(y_test, y_pred_dt)","09a2b086":"model.append('Decision Tree')\nmodel_accuracy.append(accuracy_score(y_test, y_pred_dt))","28500f13":"# Printing the models alongside their accuracies\nprint(np.concatenate((np.array(model).reshape(len(model),1), np.array(model_accuracy).reshape(len(model),1)), axis=1))","7a53191d":"plt.figure(figsize=(9,6))\nsns.barplot(model, model_accuracy)\nplt.show()","acdc68fe":"# Calculating K Fold Cross Validation scores for the models\naccuracies_lr = cross_val_score(estimator = classifier_lr, X = X_train, y = y_train, cv = 10)\naccuracies_nb = cross_val_score(estimator = classifier_nb, X = X_train, y = y_train, cv = 10)\naccuracies_svm_l = cross_val_score(estimator = classifier_svm_l, X = X_train, y = y_train, cv = 10)\naccuracies_svm_rbf = cross_val_score(estimator = classifier_svm_rbf, X = X_train, y = y_train, cv = 10)\naccuracies_rf = cross_val_score(estimator = classifier_rf, X = X_train, y = y_train, cv = 10)\naccuracies_dt = cross_val_score(estimator = classifier_dt, X = X_train, y = y_train, cv = 10)","3be5048a":"kfold_acc_mean = [np.mean(accuracies_lr), np.mean(accuracies_nb), np.mean(accuracies_svm_l), np.mean(accuracies_svm_rbf), np.mean(accuracies_rf), np.mean(accuracies_dt)]","f09e83da":"kfold_acc_std = [np.std(accuracies_lr), np.std(accuracies_nb), np.std(accuracies_svm_l), np.std(accuracies_svm_rbf), np.std(accuracies_rf), np.std(accuracies_dt)]","d1c96206":"KFold = pd.DataFrame({'Model': model, 'KFold accuracies mean': kfold_acc_mean, 'KFold accuracies std': kfold_acc_std})\nprint(KFold)","bd9f2bae":"plt.figure(figsize=(9,6))\nsns.barplot(model, kfold_acc_mean)\nplt.show()","a59df8a3":"# Data Preprocessing","4a80500f":"# SVM Model (RBF Kernel)","3ee9f76f":"# Data Visualisation","b4816f13":"# K-Fold Cross Validation","27f13484":"# Decision Tree Model","1d28f878":"<p>Hi, I'm going to apply and compare 6 supervised machine learning classification models on the given dataset to predict if the patient deceased during the follow-up period.<\/p>\n\n<ol>\n<li>Logistic Regression<\/li>\n<li>Naive Bayes<\/li>\n<li>SVM (Linear Kernel)<\/li>\n<li>SVM (RBF Kernel)<\/li>\n<li>Random Forest<\/li>\n<li>Decision Tree<\/li>\n<\/ol>","92c4308b":"# SVM Model (Linear Kernel)","b14229cd":"# Correlations between Features","a8f5bb84":"# Importing Dataset","16c8c2f3":"# Logistic Regression Model","e7f1ce14":"# Naive Bayes Model","5e3578cf":"# Correlations of features with Response Variable","363beb23":"# Comparing the Models","82eef4d5":"# Importing Libraries","b7873026":"# Random Forest Model"}}