{"cell_type":{"26332c71":"code","a2935d62":"code","d7390f65":"code","95be49cb":"code","932d0f4c":"code","a94bf340":"code","95183529":"code","f0e21931":"code","b499d870":"code","70492bd5":"code","7970cbdf":"code","64307518":"code","1d55d185":"code","b055383c":"code","b5bc3d7b":"code","ceecd60d":"code","74c3e365":"code","862c7ba3":"code","a6ee5c97":"code","57b56a64":"code","1f6ce88f":"code","5f1a05f3":"code","1a9d67b9":"code","ed128dff":"code","31745beb":"code","9d8a88b5":"code","523b28c2":"code","5611c8d6":"code","f8a22a74":"code","43c91ae4":"code","9a7316b2":"markdown","17faa05b":"markdown","05c0e0b4":"markdown","aa1bda70":"markdown","bb2c3587":"markdown","b3491688":"markdown","9c29e5b9":"markdown","1726a572":"markdown","cdf41f5e":"markdown","4289851c":"markdown","e6a7f8e7":"markdown","e3c5ec91":"markdown"},"source":{"26332c71":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","a2935d62":"pd.__version__","d7390f65":"# read datasets, force object data type to preserve number formatting\ntrain = pd.read_csv('..\/input\/train.csv', dtype=object)\ntrain.shape","95be49cb":"test = pd.read_csv('..\/input\/test.csv', dtype=object)\ntest.shape","932d0f4c":"# the most common values have a single significant figure for target\ntrain.target.value_counts()","a94bf340":"# remove ID and target columns, examine population of remaining values\n# note there are two formats for zero, some values do not have a trailing \".0\"\ntrain.iloc[:,2:].stack().value_counts()","95183529":"# remove ID column, examine population of values\n# test data has high precision values not present in train\ntest.iloc[:,1:].stack().value_counts()","f0e21931":"# flatten dataframe into a series\ntrain_series = pd.Series(train.iloc[:,2:].astype(np.float64).values.flatten())","b499d870":"train_series.shape","70492bd5":"# how many nonzero values?\ntrain_series[train_series>0].shape[0]","7970cbdf":"# how sparse is the train dataset? 3.1%\ntrain_series[train_series>0].shape[0]\/train_series.shape[0]","64307518":"test_series = pd.Series(test.iloc[:,1:].astype(np.float64).values.flatten())","1d55d185":"test_series.shape","b055383c":"# how sparse is the test dataset? 1.4%, significantly less than train\ntest_series[test_series>0].shape[0]\/test_series.shape[0]","b5bc3d7b":"# clean up to fit this notebook into Kaggle's 17 GB limit\ndel train_series\ndel test_series","ceecd60d":"# some test dataset statistics, look at nonzero values only\ntrain_stats = train.ID.to_frame()\ntrain_stats['count']  = train.iloc[:,2:].astype(np.float64).replace(0.0, np.nan).count(axis=1)\ntrain_stats['unique'] = train.iloc[:,2:].astype(np.float64).replace(0.0, np.nan).nunique(axis=1)","74c3e365":"# some test dataset statistics, look at nonzero values only\ntest_stats = test.ID.to_frame()\ntest_stats['count']  = test.iloc[:,1:].astype(np.float64).replace(0.0, np.nan).count(axis=1)\ntest_stats['unique'] = test.iloc[:,1:].astype(np.float64).replace(0.0, np.nan).nunique(axis=1)","862c7ba3":"# there are unusual clusters, a series of points with a negative slope, not seen in the test dataset\ntrain_stats.plot.scatter(x='count', y='unique', figsize=(12,10), alpha=0.3)","a6ee5c97":"# examine the lower left more closely, there are more of these clusters\ntrain_stats[train_stats['count']<900].plot.scatter(x='count', y='unique', figsize=(12,10), alpha=0.3)","57b56a64":"test_stats.plot.scatter(x='count', y='unique', figsize=(12,10), alpha=0.3)","1f6ce88f":"# this cluster stands out in the test dataset\ntest_stats[test_stats['count'] == test_stats['unique']].plot.scatter(x='count', y='unique', alpha=0.3)","5f1a05f3":"# how many 'customers' are in this count=unique set? \ntest_stats[test_stats['count'] == test_stats['unique']].count()['ID']","1a9d67b9":"# how many 'customers' are not in this count=unique set? \ntest_stats[test_stats['count'] != test_stats['unique']].count()['ID']","ed128dff":"# test the sparsity of the values in this count=unique set\ntest_series = pd.Series(test.iloc[:,1:].astype(np.float64).values.flatten())","31745beb":"test[test.ID.isin(test_stats[test_stats['count'] == test_stats['unique']]['ID'])].shape","9d8a88b5":"test_series_count_unique = pd.Series(test[test.ID.isin(test_stats[test_stats['count'] == test_stats['unique']]['ID'])].iloc[:,1:].astype(np.float64).values.flatten())","523b28c2":"# this count=unique set is very sparse, 0.70%\ntest_series_count_unique[test_series_count_unique>0].shape[0]\/test_series_count_unique.shape[0]","5611c8d6":"test[test.ID.isin(test_stats[test_stats['count'] != test_stats['unique']]['ID'])].shape","f8a22a74":"test_series_count_not_unique = pd.Series(test[test.ID.isin(test_stats[test_stats['count'] != test_stats['unique']]['ID'])].iloc[:,1:].astype(np.float64).values.flatten())","43c91ae4":"# this count!=unique set less sparse, closer to the 3.1% of the train dataset\ntest_series_count_not_unique[test_series_count_not_unique>0].shape[0]\/test_series_count_not_unique.shape[0]","9a7316b2":"Finally, let's test if the sparsity of this unusual count=unique set is similar to the training dataset sparsity.","17faa05b":"Visualizing the count of unique values vs the count of nonzero values for each row reveals structural differences between the two datasets. The train dataset has clusters that show an interesting negative slope. The test dataset has a large number of rows (56%) that have a unique property, the unique values per row equal the nonzero count of values, not present in the test dataset.","05c0e0b4":" There is a significant sparcity difference between test and train, 1.4% vs 3.1%.","aa1bda70":"### Examine Sparsity of Test and Train Datasets","bb2c3587":"The count=unique subset of the test dataset represents 56% of total test rows and has very low sparsity, 0.70%. The remaining rows have a sparsity of 2.3%, much closer to the 3.1% seen in the train dataset. ","b3491688":"The test and train dataset values have significant differences in the populations of number formats. Train data has many numbers that are rounded to a few significant figures, and some are rounded to exactly two decimal places. Test data has a large block of rows with high decimal precision, not seen in the train dataset.","9c29e5b9":"### Exploring Sparsity in the Test Dataset","1726a572":"### Visualizing Dataset Count vs Unique Differences","cdf41f5e":"### Examine Numeric Format","4289851c":"A visual inspection of the test and train dataset values reveals structure in the number formats. Many numbers are rounded to a few significant figures, and some are rounded to exactly two decimal places. In the test set there is a large block of rows with high decimal precision, not seen in the train dataset.\n<p>\nStatistical analysis reveals further structure around the relative proportion of unique values. Plotting the count of nonzero values vs the number of unique nonzero values reveals interesting structure in both the test and train datasets that are unique to each and not present in the other.\n<p>\nFinally, there is a significant difference in how sparse the test and train datasets are. Also, within the test dataset, there is a significant difference in sparsity between rows that have all unique values vs rows that do not.  For test, the rows with all unique values have a sparsity of 0.70%, and represent 56% of the data. The remaining test data has a sparsity of 2.3%, much closer to the 3.1% sparsity of the train data.","e6a7f8e7":"## Visualization of Statistical Differences Between Test and Train Datasets","e3c5ec91":"The datasets are obviously sparse, but are they equally sparse?"}}