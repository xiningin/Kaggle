{"cell_type":{"206d7ff6":"code","b7958188":"code","0327b227":"code","d4f4c116":"code","b9e79e66":"code","d613d710":"code","3d5ab0a1":"code","8da24b57":"code","0c602e18":"code","9b7d49e9":"code","8f1ef0a1":"code","5e717569":"code","0841e237":"code","d681202a":"code","5a6200d7":"code","5fa754dd":"code","1f9fe4c2":"code","277702cc":"code","6818aec4":"code","6567d974":"code","7a9dcd51":"markdown","2b43a393":"markdown","6c7fd8a0":"markdown","fb826393":"markdown","fb7c93cf":"markdown","55105d18":"markdown","b405ecf5":"markdown","0668744c":"markdown","ba92a867":"markdown","d4cfa0b7":"markdown","d49579b9":"markdown","325956a9":"markdown","a9f6f1f1":"markdown","04f3ecb5":"markdown","59c7f19e":"markdown","cc0f5bf1":"markdown","caf5d119":"markdown","27ffbf6a":"markdown","8600d0e3":"markdown","1da6ff43":"markdown","0ffbc363":"markdown"},"source":{"206d7ff6":"import numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","b7958188":"import cv2\nimport inspect\nfrom keras import Sequential, applications\nfrom keras.callbacks import Callback, EarlyStopping\nfrom keras.layers import Flatten, Dense\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom math import ceil\nimport matplotlib.pyplot as plt\nimport random\nfrom timeit import default_timer as timer\nfrom tqdm import tqdm","0327b227":"# \ub9c8\uc2a4\ud06c \ucc29\uc6a9\ub41c \uc0ac\uc9c4\ub4e4\uc758 \ub514\ub809\ud1a0\ub9ac \ubaa8\uc74c\nwith_mask_dirs = ['..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train\/WithMask', \n                  '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Validation\/WithMask',\n                  '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test\/WithMask',\n                  '..\/input\/covid-face-mask-detection-dataset\/New Masks Dataset\/Train\/Mask',\n                  '..\/input\/covid-face-mask-detection-dataset\/New Masks Dataset\/Validation\/Mask',\n                  '..\/input\/covid-face-mask-detection-dataset\/New Masks Dataset\/Test\/Mask']\n# \ub9c8\uc2a4\ud06c \ubbf8\ucc29\uc6a9\ub41c \uc0ac\uc9c4\ub4e4\uc758 \ub514\ub809\ud1a0\ub9ac \ubaa8\uc74c\nwithout_mask_dirs = ['..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train\/WithoutMask',\n                     '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Validation\/WithoutMask',\n                     '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test\/WithoutMask',\n                     '..\/input\/covid-face-mask-detection-dataset\/New Masks Dataset\/Train\/Non Mask',\n                     '..\/input\/covid-face-mask-detection-dataset\/New Masks Dataset\/Validation\/Non Mask',\n                     '..\/input\/covid-face-mask-detection-dataset\/New Masks Dataset\/Test\/Non Mask']\n\n# \uc0ac\uc9c4\ub4e4\uc758 \ub514\ub809\ud1a0\ub9ac\uc640 \ud0c0\uac9f \uac12\uc744 dataframe\uc73c\ub85c \ubb36\uc74c\ndef folder_to_df(dirs, labels):\n    file_list = []\n    num_folders = len(dirs)\n    for count, folder in enumerate(dirs, start=1):\n        for file in sorted(os.listdir(folder)):\n            if count < num_folders \/ 2:\n                file_list.append((folder + '\/' + file, labels[0]))\n            else:\n                file_list.append((folder + '\/' + file, labels[1]))\n    return pd.DataFrame(file_list, columns=['filename', 'class'])\n\nlabels = ['With Mask', 'Without Mask'] # \ud0c0\uac9f \uac12: \ub9c8\uc2a4\ud06c \ucc29\uc6a9, \ub9c8\uc2a4\ud06c \ubbf8\ucc29\uc6a9\nall_mask_df = folder_to_df(with_mask_dirs + without_mask_dirs, labels) # \ubaa8\ub4e0 \uc0ac\uc9c4\ub4e4\uc758 \ub514\ub809\ud1a0\ub9ac\ub97c dataframe\uc73c\ub85c \ud569\uce68\n\nshuffled_mask_df = all_mask_df.sample(frac=1) # \uace0\ub978 \uc120\ud0dd\uc744 \uc704\ud574 \ub370\uc774\ud130 \uc804\uccb4\uc758 \uc21c\uc11c\ub97c \uc11e\uc74c\n\ntrain_df, val_df, test_df = np.split(shuffled_mask_df, \n                                     [int(0.8*len(shuffled_mask_df)), int(0.9*len(shuffled_mask_df))]) # \ub370\uc774\ud130\ub97c 80:10:10\uc758 \ube44\uc728\ub85c train, validation, test \ubd84\ud560\n\n# train, validation, test \uc138\ud2b8 \ud655\uc778\nprint('total dataset : {}\\ntraining set  : {}\\nvalidation set: {}\\ntest set      : {}'.format(all_mask_df.shape, train_df.shape, val_df.shape, test_df.shape))\ndisplay(train_df.head(5), val_df.head(5), test_df.head(5))","d4f4c116":"train_datagen = ImageDataGenerator(rotation_range=10, # \uae30\uc6b8\uc5b4\uc9c4 \uc5bc\uad74\n                                   zoom_range=0.1, # \ud655\ub300\ub41c \uc5bc\uad74\n                                   horizontal_flip=True, # \uc88c\uc6b0 \ubc18\uc804\ub41c \uc5bc\uad74\n                                   rescale=1.0\/255) # 255\uac1c\uc758 RGB values\uc5d0 \ub9de\ucdb0\uc11c \ucd95\uc18c\n\nval_test_datagen = ImageDataGenerator(rescale=1.0\/255) # validation","b9e79e66":"VAL_BATCH_SIZE = 128\nBATCH_SIZE = VAL_BATCH_SIZE * 8\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=train_df,\n    target_size=(128,128), # \ucd5c\ub300 \uc785\ub825 \uc774\ubbf8\uc9c0 \ud06c\uae30\uc5d0 \ub9de\ucda4\n    class_mode='binary',\n    batch_size=BATCH_SIZE) # \ucd9c\ub825 \uac12 2\uac00\uc9c0: \ub9c8\uc2a4\ud06c \ucc29\uc6a9, \ub9c8\uc2a4\ud06c \ubbf8\ucc29\uc6a9\nval_generator = val_test_datagen.flow_from_dataframe(\n    dataframe=val_df,\n    target_size=(128,128),\n    class_mode='binary',\n    batch_size=VAL_BATCH_SIZE)\ntest_generator = val_test_datagen.flow_from_dataframe(\n    dataframe=test_df,\n    target_size=(128,128),\n    class_mode='binary',\n    batch_size=VAL_BATCH_SIZE)","d613d710":"def show_img_samples(dirs, num, label):\n    folder = random.choice(dirs) # randomly choose folder\n    images = random.sample(os.listdir(folder), num) # randomly choose img\n    \n    plt.figure(figsize=(20, 10))\n    for i in range(num):\n        plt.subplot(num \/\/ 5 + 1, 5, i + 1)\n        img = cv2.cvtColor(cv2.imread(folder + '\/' + images[i]), cv2.COLOR_BGR2RGB)\n        plt.subplots_adjust(hspace=0.001)\n        plt.xlabel(label)\n        plt.imshow(img)\n    plt.show()","3d5ab0a1":"show_img_samples(with_mask_dirs, 5, 'With Mask')\nshow_img_samples(without_mask_dirs, 5, 'Without Mask')","8da24b57":"class TimingCallback(Callback):\n    def __init__(self, logs={}):\n        self.logs=[]\n    def on_epoch_begin(self, epoch, logs={}):\n        self.starttime = timer()\n    def on_epoch_end(self, epoch, logs={}):\n        self.logs.append(timer()-self.starttime)\n\ntiming_callback = TimingCallback()","0c602e18":"# Keras Applications\uc5d0 \uc788\ub294 \ubaa8\ub378\ub4e4\uc744 \ubd88\ub7ec\uc634\nmodel_dictionary = {m[0]:m[1] for m in inspect.getmembers(applications, inspect.isfunction)}\nfor key in model_dictionary:\n    print(key)\n\n# \ubaa8\ub378\ub4e4\uc758 \uc131\ub2a5 \uae30\ub85d\nmodel_benchmarks = {'model_name': [], 'num_model_params': [], 'val_loss': [], 'val_accuracy': [], 'avg_train_time': []}\n\nfor model_name, model in tqdm(model_dictionary.items()):\n    # NASNet \ubaa8\ub378\ub4e4\uc740 \ubaa8\ub378\uc5d0 \ub9de\ub294 input_shape\ub97c \uc0ac\uc6a9\ud574\uc57c\ud568\n    if 'NASNetLarge' in model_name:\n        input_shape=(331,331,3)\n    elif 'NASNetMobile' in model_name:\n        input_shape=(224,224,3)\n    # \uc774\uc678\uc758 \ubaa8\ub378\ub4e4\uc740 \uc774\ubbf8\uc9c0 \ucd5c\ub300 \ud06c\uae30\uc778 128x128\uc73c\ub85c \uc124\uc815\n    else:\n        input_shape=(128,128,3)\n\n    # \ubca0\uc774\uc2a4 \ubaa8\ub378 \uc124\uc815\n    pre_trained_model = model(\n        include_top=False, \n        pooling='avg', \n        input_shape=input_shape)\n    pre_trained_model.trainable = False\n    \n    # \uc804\uc774\ud559\uc2b5 \ubaa8\ub378 \uc124\uc815\n    clf_model = Sequential([\n        pre_trained_model,\n        Flatten(),\n        Dense(1, activation='sigmoid')])\n    clf_model.compile(\n        optimizer='adam',\n        loss='binary_crossentropy',\n        metrics=['accuracy'])\n    \n    # \ubaa8\ub378 \ud6c8\ub828\n    history = clf_model.fit(\n        train_generator,\n        epochs=3, # \ub9ce\uc740 \ubaa8\ub378\ub4e4\uc744 \ube44\uad50\ud574\uc57c\ud558\ubbc0\ub85c epoch\ub97c 3\uc73c\ub85c \uc124\uc815\n        callbacks=[timing_callback],\n        validation_data=val_generator)\n    \n    # \ubaa8\ub378 \uc131\ub2a5 \ube44\uad50\ub97c \uc704\ud55c \uac12\ub4e4\uc744 \uae30\ub85d\n    model_benchmarks['model_name'].append(model_name)\n    model_benchmarks['num_model_params'].append(pre_trained_model.count_params())\n    model_benchmarks['val_loss'].append(history.history['val_loss'][-1])\n    model_benchmarks['val_accuracy'].append(history.history['val_accuracy'][-1])\n    model_benchmarks['avg_train_time'].append(sum(timing_callback.logs)\/3)","9b7d49e9":"benchmark_df = pd.DataFrame(model_benchmarks)\n\nbenchmark_df.to_csv('pretrained_model_benchmarks.csv')\n\nbm_params_df = benchmark_df.sort_values('num_model_params')\nbm_params_df.head(10)","8f1ef0a1":"pretrained_base = applications.DenseNet121(\n    include_top=False, # 128x128\uc758 \uc774\ubbf8\uc9c0 \ud06c\uae30\ub97c \ub9de\ucd94\uae30 \uc704\ud574 False\ub85c \uc124\uc815\n    input_shape=(128,128,3), # \uc774\ubbf8\uc9c0 \ud06c\uae30\uc640 RGB \uac12 \uac2f\uc218\n    pooling='avg') \npretrained_base.trainable = False\n\nmodel = Sequential([\n    pretrained_base,\n    Flatten(),\n    Dense(1, activation='sigmoid')])\n\nmodel.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['accuracy'])","5e717569":"early_stopping = EarlyStopping(\n    monitor='val_loss', \n    min_delta=0,\n    patience=10, # 10\ubc88\uc758 epoch \ub3d9\uc548 val_loss\uc774 \ub354 \uc774\uc0c1 \uc904\uc5b4\ub4e4\uc9c0 \uc54a\uc744 \ub54c \ud6c8\ub828\uc744 \uba48\ucda4\n    verbose=1,\n    mode='min',\n    restore_best_weights=True)","0841e237":"EPOCHS = 100\n\nhistory = model.fit(\n    train_generator,\n    epochs=EPOCHS,\n    callbacks=[early_stopping],\n    validation_data=val_generator)","d681202a":"history_df = pd.DataFrame(history.history)\nhistory_df\nhistory_df.loc[:, ['loss', 'val_loss']].plot();\nhistory_df.loc[:, ['accuracy', 'val_accuracy']].plot();\nprint(\"Minimum validation loss: {}\".format(history_df['val_loss'].min()))\nprint(\"Maximum validation accuracy: {}\".format(history_df['val_accuracy'].max()))","5a6200d7":"model.evaluate(test_generator)","5fa754dd":"model.save('DenseNet121.h5')","1f9fe4c2":"def predict_rand_sample(num, label):\n    plt.figure(figsize=(20,10))\n    img_dirs = test_df.loc[test_df['class'] == label].sample(num).values[:, 0] # \uc0ac\uc9c4\ub4e4\uc744 \uc784\uc758\ub85c \uc120\ud0dd\n    for i in range(num):\n        plt.subplot(num \/\/ 5 + 1, 5, i + 1)\n        \n        img = cv2.cvtColor(cv2.imread(img_dirs[i]), cv2.COLOR_BGR2RGB)\n        processed_img = cv2.resize(img,(128,128))\n        processed_img = np.reshape(processed_img,[1,128,128,3])\n        processed_img = processed_img\/255.0\n\n        prediction = model.predict(processed_img)[0][0] # \uc0ac\uc9c4\uc758 \uacb0\uacfc\uac12 \uc5d0\uce21\n        if prediction < 0.5:\n            plt.xlabel('With Mask')\n        else:\n            plt.xlabel('Without Mask')\n        plt.imshow(img)\n    plt.show","277702cc":"predict_rand_sample(5, 'With Mask')\npredict_rand_sample(5, 'Without Mask')","6818aec4":"def predict_samples(label):\n    folder = '..\/input\/mask-or-no-mask-private-dataset\/' + label\n    images = os.listdir(folder)\n    num = len(images)\n    \n    plt.figure(figsize=(20,10))\n    for i in range(num):\n        plt.subplot(num \/\/ (num \/\/ 2) + 1, 5, i + 1)\n        img = cv2.cvtColor(cv2.imread(folder + '\/' + images[i]), cv2.COLOR_BGR2RGB)\n        plt.xlabel(label)\n        plt.imshow(img)\n    plt.show()","6567d974":"predict_samples('With Mask')\npredict_samples('Without Mask')","7a9dcd51":"# Examine Images\n* \ub370\uc774\ud130\uc14b\uc5d0 \uc788\ub294 \uc774\ubbf8\uc9c0\ub4e4\uc744 \uc784\uc758\ub85c \ud655\uc778\ud574\ubd05\ub2c8\ub2e4.","2b43a393":"### Generate Image Batches\n* Train, validation, test \uc138\ud2b8 \uac01\uac01\uc758 image data generator\ub97c \ub370\uc774\ud130 \uacbd\ub85c\uc5d0 \ub9de\ucdb0\uc11c \uc124\uc815\ud574\uc90d\ub2c8\ub2e4.","6c7fd8a0":"* \ubaa8\ub378 \ud06c\uae30\uac00 \ube44\uad50\uc801 \uc791\uc73c\uba74\uc11c \uc190\uc2e4\uac12\uacfc \uc815\ud655\ub3c4\uac00 \ub192\uace0 \ud6c8\ub828\uc774 \ube60\ub978 \uc218\uce58\ub4e4\uc744 \ubcf4\uc5ec\uc900 **DenseNet121**\uc744 \ubca0\uc774\uc2a4 \ubaa8\ub378\ub85c \uc120\ud0dd\ud569\ub2c8\ub2e4.\n\n# Create Model\n* DenseNet121\uc744 \uae30\ubc18\uc73c\ub85c \ud55c \uc804\uc774\ud559\uc2b5 \ubaa8\ub378\uc744 \ub9cc\ub4ed\ub2c8\ub2e4. ","fb826393":"# Train Model\n* Epoch \ud69f\uc218\ub97c \ucd5c\ub300 100\ubc88\uc73c\ub85c \uc124\uc815\ud558\uc5ec\uc11c \ubaa8\ub378\uc744 \ud6c8\ub828\uc2dc\ud0b5\ub2c8\ub2e4.","fb7c93cf":"## With\/Without Masks\n* \ub9c8\uc2a4\ud06c \ucc29\uc6a9\ud55c\/\ubbf8\ucc29\uc6a9\ud55c \uc774\ubbf8\uc9c0\ub4e4\uc744 \ud655\uc778\ud569\ub2c8\ub2e4.","55105d18":"# Model Predictions\n* \ud559\uc2b5\ub41c \ubaa8\ub378\ub85c \ub2e4\ub978 \uc0ac\uc9c4\ub4e4 \uc18d \uc778\ubb3c\ub4e4\uc774 \ub9c8\uc2a4\ud06c\ub97c \ucc29\uc6a9\ud588\ub294\uc9c0\ub294 \uc608\uce21\ud569\ub2c8\ub2e4.","b405ecf5":"## Compare Pretrained Models\n* \uac01 \ubaa8\ub378\ub4e4\uc744 \ube44\uad50\ud569\ub2c8\ub2e4.\n* \ucd9c\ub825\uac12\uc774 2\uac00\uc9c0(\ub9c8\uc2a4\ud06c \ucc29\uc6a9, \ub9c8\uc2a4\ud06c \ubbf8\ucc29\uc6a9)\uc774\ubbc0\ub85c *loss='binary_crossentropy'*, \uadf8\ub9ac\uace0 *activation='sigmoid'*\uc73c\ub85c \uc124\uc815\ud569\ub2c8\ub2e4.\n* \uc5ec\ub7ec\uac1c\uc758 \ubaa8\ub378\ub4e4\uc758 \uc804\ubc18\uc801\uc778 \uc131\ub2a5\uc744 \uac04\ub2e8\ud788 \ube44\uad50\ud558\ub294 \ubaa9\uc801\uc774\ubbc0\ub85c \ud6c8\ub828 \uc2dc\uac04\uc744 \ub2e8\ucd95\uc2dc\ud0a4\uae30 \uc704\ud574 *epoch=3*\uc73c\ub85c \uc124\uc815\ud569\ub2c8\ub2e4.","0668744c":"* 100\ubc88\uc758 epoch \uc911 \uac80\uc99d \uc190\uc2e4\uac12\uc774 \uac00\uc7a5 \ub0ae\uc558\ub358 96\ubc88\uc9f8\uc758 \ubaa8\ub378 weight \uac12\ub4e4\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\n## Check Model Performance\n* \ud559\uc2b5\ub41c \ubaa8\ub378\uc758 \uc190\uc2e4\uac12\uacfc \uc815\ud655\ub3c4\ub97c \ucc28\ud2b8\ub85c \ud655\uc778\ud569\ub2c8\ub2e4.","ba92a867":"* \uc774\ubbf8 \ub9ce\uc774 \ud559\uc2b5\uc774 \ub41c \ubca0\uc774\uc2a4 \ubaa8\ub378(DenseNet121)\uc744 \uae30\ubc18\uc73c\ub85c \ud558\uc5ec\uc11c \ucd08\ubc18\ubd80\ud130 \uc190\uc2e4\uac12\uacfc \uc815\ud655\ub3c4\uac00 \uc88b\uac8c \ub098\uc628 \uac83\uc73c\ub85c \ubcf4\uc785\ub2c8\ub2e4.\n* \uc774\ud6c4\uc5d0\ub294 \ud6c8\ub828\uac12\uacfc \uac80\uc99d\uac12\uc758 \ucc28\uc774\uac00 \uac70\uc758 \ubbf8\ubbf8\ud588\uc2b5\ub2c8\ub2e4.\n\n## Evaluate Model\n* Test \uc138\ud2b8\ub85c \ubd84\ud560\ud574\ub193\uc740 \ub370\uc774\ud130\ub85c \ubaa8\ub378\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4.","d4cfa0b7":"## Private Images Predictions\n* \uac1c\uc778 \uc0ac\uc9c4\ub4e4\ub3c4 \ud559\uc2b5\ub41c \ubaa8\ub378\ub85c \ub9c8\uc2a4\ud06c \ucc29\uc6a9 \uc5ec\ubd80\ub97c \uc608\uce21\ud574\ubd05\ub2c8\ub2e4.","d49579b9":"# Data Preparation\n## Train-Validation-Test Split\n* Kaggle\uc5d0 \uacf5\uac1c\ub41c \ub370\uc774\ud130\uc14b 3\uac00\uc9c0\ub97c \ud569\uccd0\uc11c \uc774 \ubaa8\ub378\uc758 \ub370\uc774\ud130\uc14b\uc744 \uc900\ube44\ud569\ub2c8\ub2e4. \n* Train-validation-test split\uc744 \uc704\ud574\uc11c \ubaa8\ub4e0 \ub370\uc774\ud130 \uacbd\ub85c\ub4e4\uc744 \ud569\uce5c \ub2e4\uc74c\uc5d0 *80:10:10*\uc758 \ube44\uc728\ub85c \ubd84\ud560\ud569\ub2c8\ub2e4.\n* \ub610\ud55c \uace0\ub978 \ubd84\ud560\uc744 \uc704\ud574 \uc804\uccb4 \ub370\uc774\ud130\uc14b\uc744 \uc11e\uc5b4\ub193\uc2b5\ub2c8\ub2e4.","325956a9":"# Transfer Learning\n## Determine Best Pre-trained Base Model\n* \uc774 \ubaa9\uc801\uc758 \uc804\uc774\ud559\uc2b5\uc5d0 \uc801\uc6a9\uc2dc\ud0a4\uae30 \uac00\uc7a5 \uc801\ud569\ud55c \ud6c8\ub828\ub41c \ubaa8\ub378 \uc120\ud0dd\ud569\ub2c8\ub2e4.\n* Keras Applications\uc5d0 \uc788\ub294 \ubaa8\ub378\ub4e4\uc744 \uc9e7\uac8c \ud6c8\ub828\uc2dc\ucf1c\uc11c \uac01\uac01\uc758 \uc131\ub2a5 \uc218\uce58\ub4e4\uc744 (\ub9e4\uac1c\ubcc0\uc218, \uac80\uc99d \uc190\uc2e4, \uac80\uc99d \uc815\ud655\ub3c4, \ud6c8\ub828 \uc2dc\uac04) \ube44\uad50\ud574\uc11c \uc120\ud0dd\ud569\ub2c8\ub2e4.\n\n### Timing Callback\n* \ubaa8\ub378\uc758 \ud3c9\uade0 \ud6c8\ub828\uc2dc\uac04\uc744 \uae30\ub85d\ud558\uae30 \uc704\ud55c **Callback**\ub97c \ub9cc\ub4ed\ub2c8\ub2e4.","a9f6f1f1":"* \uc190\uc2e4\uac12: 0.0332, \uc815\ud655\ub3c4: 0.9898\uc73c\ub85c \uc608\uce21\ub960\uc774 \uc88b\uc544\ubcf4\uc785\ub2c8\ub2e4.\n\n## Save Model\n* \ud559\uc2b5\ub41c \ubaa8\ub378\uc744 \uc7ac\uc0ac\uc6a9 \ud560 \uc218 \uc788\uac8c \uc800\uc7a5\ud574\ub193\uc2b5\ub2c8\ub2e4.","04f3ecb5":"# Import Modules","59c7f19e":"### With\/Without Mask Predictions\n* \ub9c8\uc2a4\ud06c \ucc29\uc6a9\/\ubbf8\ucc29\uc6a9\ud55c \uac1c\uc778 \uc0ac\uc9c4\ub4e4\uc758 \uacb0\uacfc\uac12\uc744 \uc608\uce21\ud569\ub2c8\ub2e4.","cc0f5bf1":"### With Mask Predictions\n* \ub9c8\uc2a4\ud06c \ucc29\uc6a9\/\ubbf8\ucc29\uc6a9\ud55c \uc0ac\uc9c4\ub4e4\uc758 \uacb0\uacfc\uac12\uc744 \uc608\uce21\ud569\ub2c8\ub2e4.","caf5d119":"### Early Stopping\n* \ubaa8\ub378 \ud559\uc2b5\uc744 \uac80\uc99d \uc190\uc2e4\uac12\uc774 \ub354 \uc774\uc0c1 \uc904\uc5b4\ub4e4\uc9c0 \uc54a\uc744 \ub54c\uae4c\uc9c0 \ud6c8\ub828\uc744 \uc2dc\ud0a4\uae30 \uc704\ud574 **EarlyStopping**\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.","27ffbf6a":"## Benchmark Results\n* \uac01 \ubaa8\ub378\uc758 \uc131\ub2a5 \uc218\uce58\ub4e4\uc744 \ud655\uc778\ud558\uace0 \ube44\uad50\ud569\ub2c8\ub2e4.","8600d0e3":"# Mask or No Mask? \/ \ub9c8\uc2a4\ud06c \ucc29\uc6a9 \ubd84\ub958 \ubaa8\ub378\n### by Yehoon (Luke) Joo \/ \uc8fc\uc608\ud6c8\n\ucf54\ub85c\ub098\uac00 \ub354 \uc2ec\ud574\uc9c0\uace0 \uc788\ub294 \uc694\uc998 \uc2dc\ubbfc\ub4e4\uc758 \ub9c8\uc2a4\ud06c \ucc29\uc6a9 \uc5ec\ubd80\ub97c \ud655\uc778\ud558\ub294 \uc77c\uc774 \ud544\uc218\uac00 \ub418\uc5c8\uc2b5\ub2c8\ub2e4. Kaggle\uc5d0 \uae30\uc7ac\ub41c \ub9c8\uc2a4\ud06c \uacf5\uac1c \ub370\uc774\ud130\uc14b\uacfc \uc804\uc774\ud559\uc2b5\uc744 \ud65c\uc6a9\ud558\uc5ec \ub9c8\uc2a4\ud06c \ucc29\uc6a9 \uc5ec\ubd80\ub97c \ubd84\ubcc4\ud574\uc8fc\ub294 \ub525 \ub7ec\ub2dd \ubaa8\ub378\uc744 \uac1c\ubc1c\ud55c \ub178\ud2b8\ubd81\uc744 \uc791\uc131\ud558\uc600\uc2b5\ub2c8\ub2e4.\n# Read Datasets","1da6ff43":"* \uae30\ub300\ud55c\ud55c \uacb0\uacfc\uac12\ub4e4\uc774 \uc798 \ub098\uc654\uc2b5\ub2c8\ub2e4.\n\n# Conclusion\n\uc804\uc774\ud559\uc2b5\ub41c \ub525 \ub7ec\ub2dd \ubaa8\ub378\ub85c \uc0ac\uc9c4 \uc18d \uc778\ubb3c\uc758 \ub9c8\uc2a4\ud06c \ucc29\uc6a9 \uc5ec\ubd80\ub97c \ud655\uc778\ud558\ub294 \uac83\uc774 \uac00\ub2a5\ud588\uc2b5\ub2c8\ub2e4. \ub354 \ud5a5\uc0c1\ub41c \ud559\uc2b5\uc744 \uc704\ud574\uc11c\ub294 \ud6c8\ub828 \ub370\uc774\ud130\uc640 \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130 \uc0ac\uc9c4\ub4e4\uc5d0\uc11c \uc5bc\uad74\ub4e4\ub9cc\uc744 \uc798\ub77c\ub0b4\uc11c \uc801\uc6a9\ud558\uba74 \ub354 \uc88b\uc740 \uc131\ub2a5\uc744 \uc774\ub04c\uc5b4\ub0bc \uc218 \uc788\uc744 \uac83\uc73c\ub85c \ubcf4\uc785\ub2c8\ub2e4. \ub610\ud55c \ubaa8\ub378\uc744 \uad6c\ucd95\ud558\uba74\uc11c \ub9c8\uc2a4\ud06c\ub97c \uadc0\uc5d0 \uac78\uc5c8\uc9c0\ub9cc \uc785\uc744 \uac00\ub9ac\uc9c0 \uc54a\uc740 \uc0ac\ub78c\ub4e4\uc744 \ubd84\ub958\ud574\ub0b4\ub294 \uc791\uc5c5\ub3c4 \uac00\ub2a5\ud558\uba74 \uc88b\uc744 \uac83 \uac19\ub2e4\ub294 \uc0dd\uac01\uc774 \ub4e4\uc5c8\uc2b5\ub2c8\ub2e4.","0ffbc363":"## Data Augmentation\n* \ud6c8\ub828 \ub370\uc774\ud130\uc758 \uacfc\uc801\ud569\uc744 \ubc29\uc9c0\ud558\uae30 \uc704\ud574 \ub370\uc774\ud130 \uc99d\uac15\uc744 \uc801\uc6a9\ud569\ub2c8\ub2e4.\n* \uc774\ub97c \uc704\ud574\uc11c **Image Data Generator**\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n* \uc608\uce21\uc744 \ud560 \ub54c \uc2e4\uc81c \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud558\ub294 \uac83\uc774 \uc911\uc694\ud558\uae30\uc5d0 \ud6c8\ub828 \ub370\uc774\ud130\uc5d0\ub9cc \uc99d\uac15\uc744 \uc801\uc6a9\ud569\ub2c8\ub2e4."}}