{"cell_type":{"ebc4db89":"code","cea0f498":"code","638b464b":"code","5c8f803b":"code","65b0eea2":"code","345cbb03":"code","c2c72553":"markdown","7876b664":"markdown","ca7c5985":"markdown","b1bf8c8a":"markdown","4fbc8037":"markdown"},"source":{"ebc4db89":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestRegressor\n\ntrain = pd.read_csv('..\/input\/train.csv', index_col='id')\ntest = pd.read_csv('..\/input\/test.csv', index_col='id')\n\nstructures = pd.read_csv('..\/input\/structures.csv')\n\ndef map_atom_info(df, atom_idx):\n    df = pd.merge(df, structures, how = 'left',\n                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],\n                  right_on = ['molecule_name',  'atom_index'])\n    \n    df = df.drop('atom_index', axis=1)\n    df = df.rename(columns={'atom': f'atom_{atom_idx}',\n                            'x': f'x_{atom_idx}',\n                            'y': f'y_{atom_idx}',\n                            'z': f'z_{atom_idx}'})\n    return df\n\ntrain = map_atom_info(train, 0)\ntrain = map_atom_info(train, 1)\n\ntest = map_atom_info(test, 0)\ntest = map_atom_info(test, 1)","cea0f498":"%%time\n# Engineer a single feature: distance vector between atoms\n#  (there's ways to speed this up!)\n\ndef dist(row):\n    return ( (row['x_1'] - row['x_0'])**2 +\n             (row['y_1'] - row['y_0'])**2 +\n             (row['z_1'] - row['z_0'])**2 ) ** 0.5\n\ntrain['dist'] = train.apply(lambda x: dist(x), axis=1)\ntest['dist'] = test.apply(lambda x: dist(x), axis=1)","638b464b":"train_p_0 = train[['x_0', 'y_0', 'z_0']].values\ntrain_p_1 = train[['x_1', 'y_1', 'z_1']].values\ntest_p_0 = test[['x_0', 'y_0', 'z_0']].values\ntest_p_1 = test[['x_1', 'y_1', 'z_1']].values\n\ntr_a_min_b = train_p_0 - train_p_1\nte_a_min_b = test_p_0 - test_p_1","5c8f803b":"%%time\n# This block is SPPED UP\ntrain['dist_speedup'] = np.linalg.norm(tr_a_min_b, axis=1)\ntest['dist_speedup'] = np.linalg.norm(te_a_min_b, axis=1)","65b0eea2":"%%time\n# This block is SPED UP a little more\n# np.sqrt(np.einsum('ij,ij->i', a_min_b, a_min_b))\ntrain['dist_speedup_einsum'] = np.sqrt(np.einsum('ij,ij->i', tr_a_min_b, tr_a_min_b))\ntest['dist_speedup_einsum'] = np.sqrt(np.einsum('ij,ij->i', te_a_min_b, te_a_min_b))","345cbb03":"train.head()","c2c72553":"### Using np.linalg.norm","7876b664":"# Calculate distance","ca7c5985":"### Using np.einsum","b1bf8c8a":"*not that we need to, but....\n*\n### It seems we can go even faster with [numpy.einsum](https:\/\/docs.scipy.org\/doc\/numpy\/reference\/generated\/numpy.einsum.html)....\nfrom:\n> CPU times: user 140 ms, sys: 84 ms, total: 224 ms <br\/>\n> Wall time: 220 ms\n\nto:\n> CPU times: user 108 ms, sys: 4 ms, total: 112 ms <br\/>\n> Wall time: 107 ms\n\n---------------------------------------------------------------------\n\n\n**borrowing from** [chanran's kernel](https:\/\/www.kaggle.com\/seriousran\/just-speed-up-calculate-distance-from-benchmark)\n\n---------------------------------------------------------------------\nIn [Atomic Distance Benchmark](https:\/\/www.kaggle.com\/inversion\/atomic-distance-benchmark\/output) kernel by [inversion](https:\/\/www.kaggle.com\/inversion), <br\/> I found '#(there's ways to speed this up!)'.\nI tried to find the faster way to calculate distance and share it. <br\/>\nLet's research FASTER :)\n\nFrom\n> CPU times: user 7min 19s, sys: 9.25 s, total: 7min 28s <br\/>\n> Wall time: 7min 28s\n\nTo\n> CPU times: user 412 ms, sys: 828 ms, total: 1.24 s <br\/>\n> Wall time: 1.23 s","4fbc8037":"### Verify the Results"}}