{"cell_type":{"b4bd4686":"code","fc88ca32":"code","5b3c713f":"code","d88bc929":"code","8e5c10ad":"code","9f6f0f56":"code","ba89f755":"code","eb54a70e":"code","1e257290":"code","13c7e591":"code","41c7c1b7":"code","963e016b":"markdown"},"source":{"b4bd4686":"# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.ensemble import RandomForestRegressor\nimport pandas as pd \nimport matplotlib.pyplot as plt\n\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n#loading dataset\ntrain_iop_path='\/kaggle\/input\/new-york-city-taxi-fare-prediction\/train.csv'\ntest_iop_path='\/kaggle\/input\/new-york-city-taxi-fare-prediction\/test.csv'\ndataset_train=pd.read_csv(train_iop_path, nrows=1000000, index_col='key')\ndataset_test=pd.read_csv(test_iop_path, nrows=1000000, index_col='key')\n","fc88ca32":"\nprint(\"dataset_test old size\", len(dataset_test))\n\ndataset_test = dataset_test[dataset_test.dropoff_longitude != 0]\nprint(\"new size\", len(dataset_test))\ndataset_test.head(50)","5b3c713f":"print(\"old size\", len(dataset_train))\n\ndataset_train = dataset_train[dataset_train.dropoff_longitude != 0]\nprint(\"new size\", len(dataset_train))","d88bc929":"from datetime import datetime as dt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\ndef preparedataset(datasetname):\n    datasetname['pickup_year']=0\n    datasetname['pickup_month']=0\n    datasetname['pickup_day']=0\n    datasetname['pickup_hour']=0\n  #  datasetname['pickup_minute']=0\n #   datasetname['pickup_second']=0\n    datasetname['dis'] =0\n    datasetname['x_dis']=0\n    datasetname['y_dis']=0\n    \n    datasetname.head()\n#print(datetime.strptime(df['pickup_datetime'][0].replace(\"UTC\",''),\"%Y-%m-%d %H:%M:%S \"))\n\n    for k in range(len(datasetname.index)):\n        datetime=dt.strptime(datasetname['pickup_datetime'][k].replace(\"UTC\",''),\"%Y-%m-%d %H:%M:%S \")\n        datasetname['pickup_year'][k]=datetime.year\n        datasetname['pickup_month'][k]=datetime.month\n        datasetname['pickup_day'][k]=datetime.day\n        datasetname['pickup_hour'][k]=datetime.hour\n      # datasetname['pickup_minute'][k]=datetime.minute\n      # datasetname['pickup_second'][k]=datetime.second\n        \n    datasetname['x_dis'] = (datasetname['dropoff_longitude'] - datasetname['pickup_longitude'])  \n    datasetname['y_dis'] = (datasetname['dropoff_latitude'] - datasetname['pickup_latitude']) \n    datasetname['dis'] = ((datasetname['dropoff_longitude'] - datasetname['pickup_longitude'])**2 + (datasetname['dropoff_latitude']-datasetname['pickup_latitude'])**2)**.5 \n    datasetname=datasetname.drop(['pickup_datetime'],axis=1)\n    datasetname=datasetname.drop(['pickup_longitude'],axis=1)\n    datasetname=datasetname.drop(['dropoff_latitude'],axis=1)\n    datasetname=datasetname.drop(['dropoff_longitude'],axis=1)\n    datasetname=datasetname.drop(['pickup_latitude'],axis=1)\n\n    return datasetname\n\n\n","8e5c10ad":"df=preparedataset(dataset_train)\ndf.head(50)\n","9f6f0f56":"df.to_csv('train_preprocessed.csv')","ba89f755":"test_df=preparedataset(dataset_test)\ntest_df.head(50)","eb54a70e":"test_df.to_csv('test_preprocessed.csv')","1e257290":"#spliting the dataset \nfrom sklearn.model_selection import train_test_split\ny = df.fare_amount\nX=df.drop('fare_amount',axis=1)\nX_train, X_valid, y_train, y_valid = train_test_split(X, y)","13c7e591":"#applying XCbossting \nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error\nresult={}\nbest_istemator=0\nbest_learing_rate=0\nbest_mae=100000000000\nfor lr in [X \/ 100 for X in range(10,50, 5)]:\n    for ns in range(200,701,50):\n        #print(\"n_estimators\",ns)\n        #print(\"learning_rate\",lr)\n        my_model = XGBRegressor(n_estimators=ns, learning_rate=lr,n_jobs=4)\n        my_model.fit(X_train, y_train)\n\n        predictions = my_model.predict(X_valid)\n\n        mae=mean_absolute_error(predictions, y_valid)\n        if(mae < best_mae):\n            best_mae=mae\n            best_istemator=ns\n            best_learing_rate=lr\n            print(\"better found\")\n            print(ns , lr, mae)\n        result[(ns,lr)]=mae\nmy_model_2 = XGBRegressor(n_estimators=best_istemator, learning_rate=best_learing_rate, n_jobs=4)\nmy_model_2.fit(X_train,y_train)\npredictions_2 = my_model_2.predict(X_valid)\nmae_2 = mean_absolute_error( y_valid, predictions_2) \n# Uncomment to print MAE\nprint(\"best_istemator:\" , best_istemator)\nprint(\"best_learing_rate:\" , best_learing_rate)\nprint(\"Mean Absolute Error:\" , mae_2)\n","41c7c1b7":"from xgboost import XGBRegressor\nmy_model_2 = XGBRegressor(n_estimators=700, learning_rate=0.2, n_jobs=4)\nmy_model_2.fit(X_train,y_train)\n\ntest_preds = my_model_2.predict(test_df)\n\noutput = pd.DataFrame({'key': test_df.index,\n                      'fare_amount': test_preds})\noutput.to_csv('submission.csv', index=False)","963e016b":"best paramter so far 700 0.2 1.8986893455852212\n"}}