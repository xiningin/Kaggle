{"cell_type":{"f2d87760":"code","cea105c9":"code","8e0bcc10":"code","a87b3e86":"code","e16daf56":"code","67f1c542":"code","c819aecc":"code","20d9a1b3":"code","4f078b2a":"code","2d8dcfa7":"code","f423d8cf":"code","6c42b74b":"code","3c1d6758":"code","2c9583fd":"code","76a8e457":"code","db02db63":"code","c102381f":"code","35934a36":"code","9f87c91a":"code","392e0582":"code","58dea0ee":"code","66863118":"code","e0efb869":"code","c34beda7":"code","e467d34f":"code","c88e7ae7":"code","6d93bcb3":"code","179733cd":"code","c3289511":"code","83e40c15":"code","3884c0c8":"code","5249700c":"code","878070d6":"code","0a1f66a2":"code","0349edfa":"code","7ac17f27":"code","726f40ed":"code","46106c60":"code","5990e372":"code","b35e525a":"code","f741348f":"code","44f8f7ff":"code","069d26a1":"code","62296428":"code","22165ac0":"code","344caa97":"code","c6475fb7":"markdown","5205462e":"markdown"},"source":{"f2d87760":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","cea105c9":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nfrom fastai.collab import *\nfrom fastai.tabular import *","8e0bcc10":"ratings = pd.read_csv('..\/input\/ratings.csv',names=['UserId','MovieId','Rating','TimeStamp'],header=0)\nratings.columns=['userId','movieId','rating','timestamp']\nratings.head()","a87b3e86":"# Load a movie metadata dataset\nmovies = pd.read_csv('..\/input\/movies.csv',low_memory=False)\nmovies.columns=['movieId','title','genres']\nmovies.head()","e16daf56":"movies_with_names = pd.merge(ratings,movies,how='inner', on='movieId')\nmovies_with_names.shape","67f1c542":"movies_with_names.head(10)","c819aecc":"import matplotlib.pyplot as plt\n\ndata_rating = ratings.rating.value_counts().sort_index(ascending=False)","20d9a1b3":"x = [5,4.5,4,3.5,3,2.5,2,1.5,1,0.5]\ns=['{:.1f} %'.format(val) for val in (data_rating.values \/ ratings.shape[0] * 100)]\nplt.figure(figsize=(8,6))\nplt.bar(data_rating.index,data_rating.values)\nfor i in range(10):\n    plt.text(x[i],data_rating.values[i],s=s[i])\nplt.title('Distribution Of {} Movie Lens-Ratings'.format(ratings.shape[0]))\nplt.xlabel('Rating')\nplt.ylabel('Count')\nplt.grid(which='minor', axis='y')\nplt.show()","4f078b2a":"\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nfrom fastai.collab import *","2d8dcfa7":"data = CollabDataBunch.from_df(ratings, seed=42, valid_pct=0.1, user_name='userId', item_name='movieId', rating_name='rating')\ndata.show_batch","f423d8cf":"ratings.rating.min(), ratings.rating.max()","6c42b74b":"MODELS_PATH = '\/kaggle\/working\/models\/'\nPATH='..\/input\/'\n\n%mkdir -p {MODELS_PATH}","3c1d6758":"learn = collab_learner(data, n_factors=40, y_range=(0.5, 5), wd=1e-1, model_dir=MODELS_PATH, path=PATH)","2c9583fd":"print(learn.summary())","76a8e457":"learn.lr_find()\nlearn.recorder.plot()","db02db63":"learn.fit_one_cycle(10, 1e-01)","c102381f":"learn.save('goodmovies-2')","35934a36":"# load in EmbeddingDotBias model\nlearn = collab_learner(data, n_factors=40, y_range=(1, 5), wd=1e-1, model_dir=MODELS_PATH, path=PATH)\nlearn.load('goodmovies-2');","9f87c91a":"# get top movies\ng = ratings.groupby('movieId').count()\ntop_movies = g.sort_values('rating',ascending=False).reset_index().drop('userId',axis=1).drop('timestamp',axis=1)[:3000]\n# top_movies = top_movies.astype(str)\ntop_movies[:10]","392e0582":" top_movies = top_movies.astype(int)","58dea0ee":"top_movies.dtypes","66863118":"top_movies_with_names = pd.merge(top_movies,movies,how='inner',on='movieId')\ntop_movies_with_names.shape","e0efb869":"top_movies_with_names.head(10)","c34beda7":"top_movies_with_names.tail(10)","e467d34f":"top_movies = top_movies.astype(str)","c88e7ae7":"top_movies_with_name = np.array(top_movies_with_names['title'])","6d93bcb3":"top_movies_idx = g.sort_values('rating',ascending=False).index.values[:3000]\ntop_movies_idx = top_movies_idx.astype(str)\n","179733cd":"learn.model","c3289511":"data.show_batch()","83e40c15":"movie_bias = learn.bias(top_movies_idx, is_item=True)\nmovie_bias.shape","3884c0c8":"mean_ratings = ratings.groupby('movieId')['rating'].mean()\nmovie_ratings = [(b, top_movies_with_name[i], mean_ratings.loc[int(tb)]) for i, (tb, b) in enumerate(zip(top_movies_idx, movie_bias))]","5249700c":"item0 = lambda o:o[0]\nsorted(movie_ratings, key=item0)[:15]","878070d6":"sorted(movie_ratings, key=item0, reverse=True)[:15]","0a1f66a2":"movie_w = learn.weight(top_movies_idx, is_item=True)\nmovie_w.shape","0349edfa":"movie_pca = movie_w.pca(3)\nmovie_pca.shape","7ac17f27":"fac0,fac1,fac2 = movie_pca.t()\nmovie_comp = [(f, i) for f,i in zip(fac0, top_movies_with_name)]","726f40ed":"sorted(movie_comp, key=itemgetter(0), reverse=True)[:10]","46106c60":"sorted(movie_comp, key=itemgetter(0) )[:10]","5990e372":"movie_comp = [(f, i) for f,i in zip(fac1, top_movies_with_name)]\nsorted(movie_comp, key=itemgetter(0), reverse=True)[:10]","b35e525a":"sorted(movie_comp, key=itemgetter(0))[:10]","f741348f":"idxs = np.random.choice(len(top_movies_with_name), 50, replace=False)\nidxs = list(range(50))\nX = fac0[idxs]\nY = fac2[idxs]\nplt.figure(figsize=(15,15))\nplt.scatter(X, Y)\nfor i, x, y in zip(top_movies_with_name[idxs], X, Y):\n    plt.text(x,y,i, color=np.random.rand(3)*0.7, fontsize=11)\nplt.show()","44f8f7ff":"# Shuffle DataFrame\ndf_filterd = ratings.drop('timestamp', axis=1).sample(frac=1).reset_index(drop=True)\n\n# Testingsize\nn = 80000\nn1 = 20000\n# Split train- & testset\ndf_train = df_filterd[:-n]\ndf_test = df_filterd[-n1:]","069d26a1":"# Create a user-movie matrix with empty values\ndf_p = df_filterd.pivot_table(index='userId', columns='movieId', values='rating')\nprint('Shape User-Movie-Matrix:\\t{}'.format(df_p.shape))\ndf_p.sample(3)","62296428":"from sklearn.metrics import mean_squared_error\n# To create deep learning models\nfrom keras.layers import Input, Embedding, Reshape, Dot, Concatenate, Dense, Dropout\nfrom keras.models import Model","22165ac0":"# Create user- & movie-id mapping\nuser_id_mapping = {id:i for i, id in enumerate(ratings['userId'].unique())}\nmovie_id_mapping = {id:i for i, id in enumerate(ratings['movieId'].unique())}\n\n\n# Create correctly mapped train- & testset\ntrain_user_data = df_train['userId'].map(user_id_mapping)\ntrain_movie_data = df_train['movieId'].map(movie_id_mapping)\n\ntest_user_data = df_test['userId'].map(user_id_mapping)\ntest_movie_data = df_test['movieId'].map(movie_id_mapping)\n\n\n# Get input variable-sizes\nusers = len(user_id_mapping)\nmovies = len(movie_id_mapping)\nembedding_size = 10\n\n\n##### Create model\n# Set input layers\nuser_id_input = Input(shape=[1], name='User')\nmovie_id_input = Input(shape=[1], name='Movie')\n\n# Create embedding layers for users and movies\nuser_embedding = Embedding(output_dim=embedding_size, \n                           input_dim=users,\n                           input_length=1, \n                           name='user_embedding')(user_id_input)\nmovie_embedding = Embedding(output_dim=embedding_size, \n                            input_dim=movies,\n                            input_length=1, \n                            name='item_embedding')(movie_id_input)\n\n# Reshape the embedding layers\nuser_vector = Reshape([embedding_size])(user_embedding)\nmovie_vector = Reshape([embedding_size])(movie_embedding)\n\n# Compute dot-product of reshaped embedding layers as prediction\ny = Dot(1, normalize=False)([user_vector, movie_vector])\n\n# Setup model\nmodel = Model(inputs=[user_id_input, movie_id_input], outputs=y)\nmodel.compile(loss='mse', optimizer='adam')\n\n\n# Fit model\nmodel.fit([train_user_data, train_movie_data],\n          df_train['rating'],\n          batch_size=256, \n          epochs=4,\n          validation_split=0.1,\n          shuffle=True)\n\n# Test model\ny_pred = model.predict([test_user_data, test_movie_data])\ny_true = df_test['rating'].values\n\n#  Compute RMSE\nrmse = np.sqrt(mean_squared_error(y_pred=y_pred, y_true=y_true))\nprint('\\n\\nTesting Result With Keras Matrix-Factorization: {:.4f} RMSE'.format(rmse))","344caa97":"# Create user- & movie-id mapping\nuser_id_mapping = {id:i for i, id in enumerate(ratings['userId'].unique())}\nmovie_id_mapping = {id:i for i, id in enumerate(ratings['movieId'].unique())}\n\n\n# Create correctly mapped train- & testset\ntrain_user_data = df_train['userId'].map(user_id_mapping)\ntrain_movie_data = df_train['movieId'].map(movie_id_mapping)\n\ntest_user_data = df_test['userId'].map(user_id_mapping)\ntest_movie_data = df_test['movieId'].map(movie_id_mapping)\n\n\n# Get input variable-sizes\nusers = len(user_id_mapping)\nmovies = len(movie_id_mapping)\nembedding_size = 10\n\n\n##### Create model\n# Set input layers\nuser_id_input = Input(shape=[1], name='User')\nmovie_id_input = Input(shape=[1], name='Movie')\n\n# Create embedding layers for users and movies\nuser_embedding = Embedding(output_dim=embedding_size, \n                           input_dim=users,\n                           input_length=1, \n                           name='user_embedding')(user_id_input)\nmovie_embedding = Embedding(output_dim=embedding_size, \n                            input_dim=movies,\n                            input_length=1, \n                            name='item_embedding')(movie_id_input)\n\n# Reshape the embedding layers\nuser_vector = Reshape([embedding_size])(user_embedding)\nmovie_vector = Reshape([embedding_size])(movie_embedding)\n\n# Compute dot-product of reshaped embedding layers as prediction\ny = Dot(1, normalize=False)([user_vector, movie_vector])\n\n# Setup model\nmodel = Model(inputs=[user_id_input, movie_id_input], outputs=y)\nmodel.compile(loss='mse', optimizer='adam')\n\n\n# Fit model\nmodel.fit([train_user_data, train_movie_data],\n          df_train['rating'],\n          batch_size=256, \n          epochs=10,\n          validation_split=0.1,\n          shuffle=True)\n\n# Test model\ny_pred = model.predict([test_user_data, test_movie_data])\ny_true = df_test['rating'].values\n\n#  Compute RMSE\nrmse = np.sqrt(mean_squared_error(y_pred=y_pred, y_true=y_true))\nprint('\\n\\nTesting Result With Keras Matrix-Factorization: {:.4f} RMSE'.format(rmse))","c6475fb7":" # Matrix Factorisation With Keras And Gradient Descent \n","5205462e":"# Movie Bias"}}