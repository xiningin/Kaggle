{"cell_type":{"6576de50":"code","466d8da2":"code","53be5165":"code","25ca57ab":"code","57d7e35f":"code","80089c8e":"code","97e048cd":"code","3cb624d8":"code","5ce27b08":"code","fc2e02e8":"code","38c5c744":"code","dd557638":"code","c598df73":"code","b8a089d7":"code","a8d5c79f":"code","99136051":"code","51e6346a":"code","ab143d4b":"code","30f57f47":"code","0925b4f3":"code","b8e2362e":"code","f7f6c382":"code","191eb5be":"code","c48b677d":"code","aef72098":"code","1863a5eb":"code","85595682":"code","d6c2b8df":"code","6130564e":"code","b9bf7a6d":"code","698341f0":"code","4bb5899a":"code","baebac7d":"code","8fd39439":"code","41dea85b":"code","d2f98b5f":"code","2e64f59c":"markdown","979e3c28":"markdown","6725943d":"markdown","f05ec397":"markdown","591f7500":"markdown","dbe7309f":"markdown"},"source":{"6576de50":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport gc,os,re\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","466d8da2":"def load_data():\n    train = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/train.csv')\n    test  = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/test.csv')\n    submission = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/sample_submission.csv')\n    return train,test,submission","53be5165":"train,_,_ = load_data()\ntrain.head(1)","25ca57ab":"train['target'].value_counts()","57d7e35f":"cat_features=[]\n\nfor c in train.columns:\n    if train[c].dtype=='object':\n        cat_features.append(c)\nprint(cat_features)","80089c8e":"train_encoded = pd.get_dummies(train,columns=cat_features,drop_first=True)\ntrain_encoded","97e048cd":"from sklearn.feature_selection import mutual_info_classif\n\ndef make_mi_scores(X, y):\n    X = X.copy()\n    for colname in X.select_dtypes([\"object\", \"category\"]):\n        X[colname], _ = X[colname].factorize()\n    # All discrete features should now have integer dtypes\n    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n    mi_scores = mutual_info_classif(X, y, discrete_features=discrete_features, random_state=0)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\ntrain_data = train_encoded.copy()\ntrain_data.drop([\"id\"],axis=1,inplace=True)\ny=train_data.pop('target')\nX=train_data\nscores = make_mi_scores(X,y)\nscores","3cb624d8":"def plot_mi_scores(scores):\n    scores = scores.sort_values(ascending=True)\n    width = np.arange(len(scores))\n    ticks = list(scores.index)\n    color = np.array([\"C0\"] * scores.shape[0])\n    # Color red for probes\n    idx = [i for i, col in enumerate(scores.index)\n           if col.startswith(\"PROBE\")]\n    color[idx] = \"C3\"\n    # Create plot\n    plt.figure(figsize=(50,50))\n    plt.barh(width, scores, color=color)\n    plt.yticks(width, ticks)\n    plt.title(\"Mutual Information Scores\\n\")\n    \nplot_mi_scores(scores)","5ce27b08":"print(\"selected features:\",len(scores[scores>0.01]))","fc2e02e8":"select_features = list(scores[scores>0.01].index)\nprint(\"selected important festures:\\n\",select_features)","38c5c744":"train2 = train_encoded[select_features]\nX= train2\ny=train.pop('target')","dd557638":"from sklearn.model_selection import train_test_split\n\ntrain_x,test_x,train_y,test_y = train_test_split(X,y,train_size=0.8)\nprint(train_x.shape,train_y.shape)","c598df73":"print(test_x.shape,test_y.shape)","b8a089d7":"gc.collect()","a8d5c79f":"%%time\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nmodel1 = RandomForestClassifier()\nmodel1.fit(train_x,train_y)","99136051":"from sklearn.metrics import accuracy_score\n\nprint(\"Random Forest Model Accuracy\",round(accuracy_score(test_y,model1.predict(test_x)),5))","51e6346a":"from sklearn.metrics import confusion_matrix\nprint(confusion_matrix(test_y,model1.predict(test_x)))","ab143d4b":"gc.collect()","30f57f47":"!pip install catboost -q\nfrom catboost import CatBoostClassifier, Pool, cv","0925b4f3":"%%time\n\nmodel2 = CatBoostClassifier(custom_loss=['Accuracy'],logging_level='Silent')\nmodel2.fit(train_x,train_y,eval_set=(test_x,test_y),logging_level='Verbose',plot=True)","b8e2362e":"cv_params = model2.get_params()\ncv_params.update({'loss_function': 'Logloss'})\n\ncv_data = cv(Pool(X, y),cv_params,plot=True)","f7f6c382":"print('Best validation accuracy score: {:.2f}\u00b1{:.2f} on step {}'.format(\n    np.max(cv_data['test-Accuracy-mean']),\n    cv_data['test-Accuracy-std'][np.argmax(cv_data['test-Accuracy-mean'])],\n    np.argmax(cv_data['test-Accuracy-mean'])\n))","191eb5be":"print('Precise validation accuracy score: {}'.format(np.max(cv_data['test-Accuracy-mean'])))","c48b677d":"print(confusion_matrix(test_y,model2.predict(test_x)))","aef72098":"print(\"Catboost Model Accuracy\",round(accuracy_score(test_y,model2.predict(test_x)),5))","1863a5eb":"gc.collect()","85595682":"%%time\n\n!pip install hyperopt -q","d6c2b8df":"import hyperopt\n\ndef hyperopt_objective(params):\n    model = CatBoostClassifier(\n        l2_leaf_reg=int(params['l2_leaf_reg']),\n        learning_rate=params['learning_rate'],\n        iterations=1000,\n        eval_metric='Accuracy',\n        random_seed=41,\n        verbose=False,\n        loss_function='Logloss',\n    )\n    \n    cv_data = cv(\n        Pool(X, y),\n        model.get_params()\n    )\n    best_accuracy = np.max(cv_data['test-Accuracy-mean'])\n    \n    return 1 - best_accuracy # as hyperopt minimises","6130564e":"from numpy.random import RandomState\n\nparams_space = {\n    'l2_leaf_reg': hyperopt.hp.qloguniform('l2_leaf_reg', 0, 2, 1),\n    'learning_rate': hyperopt.hp.uniform('learning_rate', 1e-3, 5e-1),\n}\n\ntrials = hyperopt.Trials()\n\nbest = hyperopt.fmin(\n    hyperopt_objective,\n    space=params_space,\n    algo=hyperopt.tpe.suggest,\n    max_evals=3,\n    trials=trials,\n    rstate=RandomState(123)\n)\n\nprint(best)","b9bf7a6d":"best = {'l2_leaf_reg': 3.0, 'learning_rate': 0.16129990013229004}\n\nmodel = CatBoostClassifier(\n    l2_leaf_reg=int(best['l2_leaf_reg']),\n    learning_rate=best['learning_rate'],\n    iterations=500,\n    eval_metric='Accuracy',\n    random_seed=42,\n    verbose=True,\n    loss_function='Logloss',\n)\n\ncv_data = cv(Pool(X, y), model.get_params())","698341f0":"print('Precise validation accuracy score: {}'.format(np.max(cv_data['test-Accuracy-mean'])))","4bb5899a":"model.fit(X, y)","baebac7d":"_,test,_ = load_data()\ntest.head(2)","8fd39439":"test_encoded = pd.get_dummies(test,columns=cat_features,drop_first=True)\ntest_encoded.head(2)","41dea85b":"_,_,submission = load_data()\nsubmission['target'] = model2.predict(test_encoded[select_features])\nsubmission.to_csv('submission.csv', index=False)","d2f98b5f":"_,_,submission = load_data()\nsubmission['target'] = model.predict(test_encoded[select_features])\nsubmission.to_csv('submission.csv', index=False)","2e64f59c":"### catboost without tuning hyper parameters","979e3c28":"### catboost with tuning hyper parameters","6725943d":"### Hyper Parameter Tuning","f05ec397":"best = {'l2_leaf_reg': 3.0, 'learning_rate': 0.16129990013229004}","591f7500":"### Baseline model - Random Forest Classifier","dbe7309f":"### CatBoost Classifier"}}