{"cell_type":{"25410ff6":"code","5ff0f396":"code","c9b77a2e":"code","a3f32531":"code","c33b7e9a":"code","b63318d2":"code","4fd6c35c":"code","be273942":"code","e0977dc8":"code","fad0ae37":"code","1c57b0bf":"code","00f509f0":"markdown","eda76e17":"markdown","45a4bca0":"markdown","f4911c6a":"markdown","fbf53cd1":"markdown","342386e9":"markdown"},"source":{"25410ff6":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier,AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, f1_score\nimport warnings\nwarnings.filterwarnings(action='ignore')","5ff0f396":"data=pd.read_csv(r'..\/input\/rice-type-classification\/riceClassification.csv')\nprint (data.head())\nprint (data.isna().sum())\nprint(data.info())\nprint (data['Class'].unique())","c9b77a2e":"print (data['Class'].value_counts())","a3f32531":"def trim(df, column):\n    df=df.copy()\n    sample_list=[]\n    balance=list(df[column].value_counts())\n    min_samples=np.min(balance) # least samples in any class\n    print ('the minimum number of samples in any class is ', min_samples)\n    min_size = 0\n    groups=df.groupby(column)\n    for label in df[column].unique():                 \n        group=groups.get_group(label)\n        sample_count=len(group)    \n        if sample_count> min_samples :\n            samples=group.sample(min_samples, replace=False, weights=None, random_state=123, axis=0).reset_index(drop=True)\n            sample_list.append(samples)\n        elif sample_count>= min_size:\n            sample_list.append(group)\n    df=pd.concat(sample_list, axis=0).reset_index(drop=True)\n    return df ","c33b7e9a":"def preprocess(df):\n    df=df.copy()\n    df=df.drop(['id'], axis=1)\n    # balance the data set by having samples in each class equal to smallest samples for any class\n    df=trim(df, 'Class')\n    print (df['Class'].value_counts())\n    # partition into target y and data x\n    y=df['Class']\n    X=df.drop(['Class'], axis=1)\n    #split into train and test sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, shuffle=True, random_state=1)\n    # scale the X data    \n    scaler = StandardScaler()\n    scaler.fit(X_train) # fit only on train data\n    X_train = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)\n    X_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)\n    \n    return X_train, X_test, y_train, y_test\n    \n","b63318d2":"X_train, X_test, y_train, y_test=preprocess(data)\nprint ('X_train length: ', len(X_train), '  X_test length: ', len(X_test))","4fd6c35c":"X_train","be273942":"print (y_train.value_counts())","e0977dc8":"models = {\n    \"Logistic Regression\": LogisticRegression(),\n    \"      Decision Tree\": DecisionTreeClassifier(),\n    \"     Neural Network\": MLPClassifier(),\n    \"      Random Forest\": RandomForestClassifier(),\n    \"  Gradient Boosting\": GradientBoostingClassifier(),\n    \" AdaBoostClassifier\": AdaBoostClassifier(),\n    \"KNeighborsClassifier\": KNeighborsClassifier()\n}\n\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    print(name + \" trained.\")","fad0ae37":"for name, model in models.items():\n    y_pred = model.predict(X_test)\n    acc = accuracy_score(y_test, y_pred)\n    print(name + \" Accuracy: {:.2f}%\".format(acc * 100))","1c57b0bf":"for name, model in models.items():\n    y_pred = model.predict(X_test)\n    f1 = f1_score(y_test, y_pred, pos_label=1)\n    print(name + \" F1-Score: {:.5f}\".format(f1))","00f509f0":"### let's look at the dataset balance","eda76e17":"### dataset is not balanced. define a function that finds the minimum number of samples in any class\n### then sets all classes to have that number of samples","45a4bca0":"### Training result by model","f4911c6a":"### read in the csv file","fbf53cd1":"### Training","342386e9":"### there are no missing values to deal with- create a function to process the data frame"}}