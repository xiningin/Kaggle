{"cell_type":{"5a423091":"code","360ae7bc":"code","c6a0de76":"code","2f3e359d":"code","af12bdb0":"code","93f51739":"code","94315602":"code","a1fbabf7":"code","b51717c1":"code","da3b96d4":"code","49dc7693":"code","1ca3e431":"code","faf3b06d":"code","dcf474f5":"code","3450ca86":"code","5dc58974":"code","13565f26":"code","84cbc64b":"code","872e8e62":"code","6975357a":"code","6216702e":"code","b48aec3e":"code","62e896db":"code","0fba544e":"code","10cbda13":"code","1de8aaec":"code","e333736a":"code","2530a85e":"code","3a42b36c":"code","8740c9cc":"code","6ee3ea0a":"code","0705930e":"code","da6d0f8f":"code","80a389ae":"code","38d6234f":"code","c2b22209":"code","4bf41030":"markdown","51954574":"markdown","2881f1e5":"markdown","9f1712eb":"markdown","7c463b48":"markdown","fd5d262b":"markdown","21e98682":"markdown","1a5aa8ef":"markdown","e289efce":"markdown","a6a6f0bd":"markdown","257e7cc1":"markdown","60afef53":"markdown","05948f25":"markdown","a34b3ff8":"markdown","07852d11":"markdown","847cbeae":"markdown","b02982a7":"markdown","5ecf7091":"markdown","ccdb5895":"markdown","a34ce142":"markdown","c3cc1bfa":"markdown","e798905f":"markdown","c8a325c4":"markdown","b9d84cc0":"markdown","479cce78":"markdown","9f20072b":"markdown","e568ab00":"markdown"},"source":{"5a423091":"# Import necessary libraries\nimport math\nimport pickle\nimport os\nimport pandas as pd\nimport folium \nimport numpy as np\nimport matplotlib\nmatplotlib.use('nbagg')\nimport matplotlib.pylab as plt\nimport seaborn as sns\nfrom matplotlib import rcParams\nimport plotly as py\nimport cufflinks\nfrom plotly.subplots import make_subplots\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom tqdm import tqdm_notebook as tqdm\nimport warnings\nimport tensorflow as tf\nfrom numpy import array\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.layers import BatchNormalization\nfrom dateutil.relativedelta import relativedelta\nimport datetime\nwarnings.filterwarnings(\"ignore\")\n","360ae7bc":"# Reading COVID-19 Raw data\ntrain = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-3\/train.csv\")\n#covid_master=pd.read_csv('covid_19_data.csv')\nsubmission = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-3\/submission.csv\")\n#covid_open=pd.read_csv('COVID19_open_line_list.csv')\ntest = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-3\/test.csv\")\n#train = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-1\/train.csv\")","c6a0de76":"train.isna().sum()","2f3e359d":"# We will fill the missing states with a value 'NoState'\ntrain=train.fillna('NoState')\ntest=test.fillna('NoState')\n# changing the data type\ntrain=train.rename(columns={'ConfirmedCases':'Confirmed','Fatalities':'Deaths','Country_Region':'Country\/Region',\n                     'Province_State':'Province\/State','Date':'ObservationDate'})\nnum_cols=['Confirmed', 'Deaths']\nfor col in num_cols:\n    temp=[int(i) for i in train[col]]\n    train[col]=temp \ntrain.head(2)","af12bdb0":"# Creating list of all regions of all counntries\nunique_regions=train['Country\/Region'].unique()\nstates_per_regions=[]\nfor reg in tqdm(unique_regions):\n    states_per_regions.append(train[train['Country\/Region']==reg]['Province\/State'].unique()) \nprint('No of unique regions:',len(unique_regions))    ","93f51739":"# function to create training data for LSTM\n# We will take last 7 days Cases as input and 8th day's case as output\ndef create_train_dataset(target,n_steps,train,pivot_date):\n    train = train.query(\"ObservationDate<\"+pivot_date)\n    x=[]\n    y=[]\n    for k in tqdm(range(len(unique_regions))):\n        for state in states_per_regions[k]:\n            #print(unique_regions[k],state)\n            temp=train[(train['Country\/Region']==unique_regions[k]) &(train['Province\/State']==state)]\n            sequence=list(temp[target])\n            for i in range(len(sequence)):\n                end_ix = i + n_steps\n                if end_ix > len(sequence)-1:\n                    break\n                seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n                if(seq_y!=0):\n                    x.append(seq_x)   \n                    y.append(seq_y)\n    return array(x),array(y)    \n\ndef create_countrywise_newly_added_train_dataset(target,n_steps,train,pivot_date):\n    train = train.query(\"ObservationDate<\"+pivot_date)\n    x=[]\n    y=[]\n    for k in tqdm(range(len(unique_regions))):\n            #print(unique_regions[k],state)\n        temp=train[(train['Country\/Region']==unique_regions[k])]\n        sequence=list(temp[target])\n        for i in range(len(sequence)):\n            end_ix = i + n_steps\n            if end_ix > len(sequence)-1:\n                break\n            seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n            if(seq_y!=0):\n                x.append(seq_x)   \n                y.append(seq_y)\n    return array(x),array(y)  ","94315602":"# function to create test dataset\n# our supervised probem is now given last 7 days data predict the no of cases for 8th day\n# target : 'Confirmed'\/'Deaths'\ndef create_test_dataset(target,n_steps,train,pivot_date):\n    train = train.query(\"ObservationDate<\"+pivot_date)\n    x=[]\n    regs=[]\n    for k in tqdm(range(len(unique_regions))):\n        for state in states_per_regions[k]:\n            #regs.append((unique_regions[k],state))\n            temp=train[(train['Country\/Region']==unique_regions[k]) &(train['Province\/State']==state)]\n            sequence=temp[target]\n            #print(sequence[len(sequence)-n_steps:len(sequence)+1])\n            x.append(sequence[len(sequence)-n_steps:len(sequence)+1])\n            regs.append((unique_regions[k],state))      \n    return array(x),regs\n\ndef create_countrywise_newly_added_test_dataset(target,n_steps,train,pivot_date):\n    train = train.query(\"ObservationDate<\"+pivot_date)\n    x=[]\n    regs=[]\n    for k in tqdm(range(len(unique_regions))):\n        temp=train[(train['Country\/Region']==unique_regions[k])]\n        sequence=temp[target]\n        #print(sequence[len(sequence)-n_steps:len(sequence)+1])\n        x.append(sequence[len(sequence)-n_steps:len(sequence)+1])\n        regs.append(unique_regions[k])      \n    return array(x),regs\n","a1fbabf7":"def get_newly_added(world_data_):\n    world_data_=world_data_.sort_values(['Country\/Region','ObservationDate'])\n    temp=[0*i for i in range(len(world_data_))]\n    world_data_['New Confirmed']=temp\n    world_data_['New Death']=temp\n    for i in tqdm(range(1,len(world_data_))):\n        if(world_data_['Country\/Region'].iloc[i]==world_data_['Country\/Region'].iloc[i-1]):\n            if(world_data_['Deaths'].iloc[i]<world_data_['Deaths'].iloc[i-1]):\n                world_data_['Deaths'].iloc[i]=world_data_['Deaths'].iloc[i-1]\n            if(world_data_['Confirmed'].iloc[i]<world_data_['Confirmed'].iloc[i-1]):\n                world_data_['Confirmed'].iloc[i]=world_data_['Confirmed'].iloc[i-1]     \n            world_data_['New Confirmed'].iloc[i]=world_data_['Confirmed'].iloc[i]-world_data_['Confirmed'].iloc[i-1]\n            world_data_['New Death'].iloc[i]=world_data_['Deaths'].iloc[i]-world_data_['Deaths'].iloc[i-1]\n        else:\n            world_data_['New Confirmed'].iloc[i]=world_data_['Confirmed'].iloc[i]\n            world_data_['New Death'].iloc[i]=world_data_['Deaths'].iloc[i]\n    return world_data_","b51717c1":"# Countrywise timeseries data with Newly added Incident Each Day\ncovid_timeseries = train.groupby(['ObservationDate','Country\/Region','Province\/State'])['Confirmed', 'Deaths'].sum()\ncovid_timeseries=covid_timeseries.reset_index().sort_values('ObservationDate')\ncovid_timeseries=get_newly_added(covid_timeseries)\ncovid_timeseries[covid_timeseries['Country\/Region']=='India'].tail()","da3b96d4":"# Maintain the date format for pivot_date and forcast_start_date\n# Pivot_date : data of date less than the given date will be used for training\n# Forcast_start_date : Date from which forcasting will be started\nn_steps=7\npivot_date=\"'2020-04-02'\"\nforcast_start_date='2020-04-02'\nprint('Preparing datasets with Cumulative Confirmed Incidents..')\nX_c,y_c=create_train_dataset('Confirmed',n_steps,train,pivot_date)\nprint('Preparing datasets with Newly Confirmed Incidents..')\nX_nc,y_nc=create_train_dataset('New Confirmed',n_steps,covid_timeseries,pivot_date)\ntest_confirmed,regs= create_test_dataset('Confirmed',n_steps,train,pivot_date)\ntest_nc,reg_nc=create_test_dataset('New Confirmed',n_steps,covid_timeseries,pivot_date)\nprint('Preparing datasets with Deaths Incidents..')\nX_d,y_d=create_train_dataset('Deaths',n_steps,train,pivot_date)\ntest_deaths,regs= create_test_dataset('Deaths',n_steps,train,pivot_date)\nprint('Datasets prepared sucessfully.')","49dc7693":"# Split the train data in to train and val data\n\nX_train_c, X_val_c, y_train_c, y_val_c = train_test_split(X_c, y_c, test_size=0.30, random_state=42)\nX_train_d, X_val_d, y_train_d, y_val_d = train_test_split(X_d, y_d, test_size=0.30, random_state=42)\n\nX_train_nc, X_val_nc, y_train_nc, y_val_nc = train_test_split(X_c, y_c, test_size=0.30, random_state=42)\n","1ca3e431":"# Reshapping the Confirmed data for LSTM\nX_train_c = X_train_c.reshape((X_train_c.shape[0], 1, X_train_c.shape[1]))\nX_val_c= X_val_c.reshape(( X_val_c.shape[0], 1,  X_val_c.shape[1]))\nX_train_nc = X_train_nc.reshape((X_train_nc.shape[0], 1, X_train_nc.shape[1]))\nX_val_nc= X_val_nc.reshape(( X_val_nc.shape[0], 1,  X_val_nc.shape[1]))\nX_test_c= test_confirmed.reshape(( test_confirmed.shape[0], 1, test_confirmed.shape[1]))\nX_test_nc= test_nc.reshape(( test_nc.shape[0], 1, test_nc.shape[1]))\nprint(X_train_c.shape, y_train_c.shape, X_val_c.shape, y_val_c.shape,X_test_c.shape,X_test_nc.shape)","faf3b06d":"# Reshapping the donfirmed data for LSTM\nX_train_d = X_train_d.reshape((X_train_d.shape[0], 1, X_train_d.shape[1]))\nX_val_d= X_val_d.reshape(( X_val_d.shape[0], 1,  X_val_d.shape[1]))\nX_test_d= test_deaths.reshape(( test_deaths.shape[0], 1, test_deaths.shape[1]))\nprint(X_train_d.shape, y_train_d.shape, X_val_d.shape, y_val_d.shape,X_test_d.shape)","dcf474f5":"print(X_train_c[100])\nprint(X_train_d[1])","3450ca86":"# Initializing model components\nepochs = 10\nbatch_size = 32\nn_hidden = 32\ntimesteps = X_train_c.shape[1]\ninput_dim = X_train_c.shape[2]\nn_features=1\n\nprint(timesteps)\nprint(input_dim)\nprint(len(X_train_c))","5dc58974":"# Stacked LSTM Model\nmodel_c = Sequential()\nmodel_c.add(LSTM(50, activation='relu', input_shape=(n_features,n_steps),return_sequences=True))\nmodel_c.add(LSTM(150, activation='relu'))\nmodel_c.add(Dense(1,activation='relu'))\nmodel_c.summary()","13565f26":"# Compiling the model\nmodel_c.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredLogarithmicError())\ncallbacks = [ReduceLROnPlateau(monitor='val_loss', patience=5, verbose=1, factor=0.6),\n             EarlyStopping(monitor='val_loss', patience=20),\n             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n# fit the model\nhist=model_c.fit(X_train_c,y_train_c, epochs=epochs, batch_size=batch_size, validation_data=(X_val_c, y_val_c), verbose=2, \n               shuffle=True,callbacks=callbacks)\n","84cbc64b":"plt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('Epoch vs Loss for Confirmed Cases')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='best')\nplt.show()","872e8e62":"# Stadked LSTM Model\nmodel_d = Sequential()\nmodel_d.add(LSTM(50, activation='relu', input_shape=(n_features,n_steps),return_sequences=True))\nmodel_d.add(LSTM(50, activation='relu'))\nmodel_d.add(Dense(1))\nmodel_d.summary()","6975357a":"# Compiling the model\nmodel_d.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredLogarithmicError())\ncallbacks = [ReduceLROnPlateau(monitor='val_loss', patience=5, verbose=1, factor=0.6),\n             EarlyStopping(monitor='val_loss', patience=20),\n             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n# fit the model\nhist=model_d.fit(X_train_d,y_train_d, epochs=epochs, batch_size=batch_size, validation_data=(X_val_d, y_val_d), verbose=2, \n               shuffle=True,callbacks=callbacks)\n","6216702e":"plt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('Epoch vs Loss for Deathh Cases')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='best')\nplt.show()","b48aec3e":"# Stadked LSTM Model\nmodel_nc = Sequential()\nmodel_nc.add(LSTM(50, activation='relu', input_shape=(n_features,n_steps),return_sequences=True))\nmodel_nc.add(LSTM(50, activation='relu'))\nmodel_nc.add(Dense(1))\nmodel_nc.summary()\nmodel_nc.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredLogarithmicError())\ncallbacks = [ReduceLROnPlateau(monitor='val_loss', patience=5, verbose=1, factor=0.6),\n             EarlyStopping(monitor='val_loss', patience=20),\n             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n# fit the model\nhist=model_nc.fit(X_train_nc,y_train_nc, epochs=epochs, batch_size=batch_size, validation_data=(X_val_nc, y_val_nc), verbose=2, \n               shuffle=True,callbacks=callbacks)","62e896db":"import math\ndef pred(model,data):\n    y_pred=model.predict(data)\n    #y_pred=[math.ceil(i) for i in y_pred]\n    return y_pred","0fba544e":"# Utility method for Forcasting\n# model - trained model on Confirmed\/Deaths data\n# start_date - Starting date of forcasting\n# num_days - Number of days for which forcasting is required\ndef forcast(model,data,start_date,num_days):\n    res_=dict()\n    for i in range(len(data)):\n        res_[i]=[]\n    y_pred=pred(model,data)\n    dates=[]\n    date1 = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n    for j in range(1,num_days+1):\n        for i in range(len(data)):\n            cur_window=list(data[i][0][1:n_steps+1])\n            #print(j,i,cur_window[-1])\n            res_[i].append(cur_window[-1])\n            cur_window.append(y_pred[i])\n            data[i][0]=cur_window\n        y_pred=pred(model,data)\n        dates.append(date1.strftime(\"%Y-%m-%d\"))\n        date1+=relativedelta(days=1)\n    res=pd.DataFrame(pd.DataFrame(pd.DataFrame(res_).values.T)) \n    res.columns=dates\n    res['Country\/State']=regs\n    return res\n\ndef forcast_(model,data,start_date,num_days):\n    res_=[]\n    for i in list(data['Country\/Region']):\n        res_.append(i)\n    y_pred=pred(model,data)\n    dates=[]\n    date1 = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n    for j in range(1,num_days+1):\n        for i in range(len(data)):\n            cur_window=list(data[i][0][1:n_steps+1])\n            #print(j,i,cur_window[-1])\n            res_[i].append(cur_window[-1])\n            cur_window.append(y_pred[i])\n            data[i][0]=cur_window\n        y_pred=pred(model,data)\n        dates.append(date1.strftime(\"%Y-%m-%d\"))\n        date1+=relativedelta(days=1)\n    res=pd.DataFrame(pd.DataFrame(pd.DataFrame(res_).values.T)) \n    res.columns=dates\n    res['Country\/State']=res_\n    return res\n        ","10cbda13":"# Utility method for submission\ndef prepare_submission(res_c,res_d,res_nc,test,pivot_date):\n    test=test.query(\"Date>=\"+pivot_date)\n    index=dict()\n    for i in range(len(res_c)):\n        index[res_c.iloc[i]['Country\/State']]=i\n    pred_c=[]\n    pred_d=[]\n    pred_nc=[]\n    for i in tqdm(range(len(test))):\n        if((test.iloc[i]['Country_Region'],test.iloc[i]['Province_State']) in index):\n            loc=index[(test.iloc[i]['Country_Region'],test.iloc[i]['Province_State'])]\n            #print(res.iloc[loc][test.iloc[i]['Date']])\n            pred_c.append(res_c.iloc[loc][test.iloc[i]['Date']])     \n            pred_d.append(res_d.iloc[loc][test.iloc[i]['Date']]) \n            pred_nc.append(res_nc.iloc[loc][test.iloc[i]['Date']]) \n    test['ConfirmedCases']=pred_c\n    test['Fatalities']=pred_d\n    test['New Confirmed']=pred_nc\n    res_regional=test\n    res=test.drop(columns=['Province_State','Country_Region','Date','New Confirmed'])\n    return res,res_regional ","1de8aaec":"# Call only when forcast and submission data are available\ndef get_countrywise_forcast_(target,country_name,state_name,num_days):\n    temp=covid_timeseries[(covid_timeseries['Country\/Region']==country_name)&(covid_timeseries['Province\/State']==state_name)].query(\"ObservationDate>=\"+pivot_date)\n    x_truth=temp.ObservationDate\n    y_truth=temp[target]\n    pred_=res_regional[(res_regional['Country_Region']==country_name) & ((res_regional['Province_State']==state_name))]\n    x_pred=pred_.Date[0:num_days]\n    y_pred=pred_[target][0:num_days]\n    return list(x_truth),list(y_truth),list(x_pred),list(y_pred)","e333736a":"# Call only when forcast and submission data are available\ndef get_countrywise_forcast(country_name,state_name,num_days):\n    temp=train[(train['Country\/Region']==country_name)&(train['Province\/State']==state_name)].query(\"ObservationDate>=\"+pivot_date)\n    x_truth=temp.ObservationDate\n    y_truth=temp.Confirmed\n    pred_=res_regional[(res_regional['Country_Region']==country_name) & ((res_regional['Province_State']==state_name))]\n    x_pred=pred_.Date[0:num_days]\n    y_pred=pred_.ConfirmedCases[0:num_days]\n    return list(x_truth),list(y_truth),list(x_pred),list(y_pred)","2530a85e":"# Call only when forcast and submission data are available\ndef get_countrywise_forcast_Deaths(country_name,state_name,num_days):\n    temp=train[(train['Country\/Region']==country_name)&(train['Province\/State']==state_name)].query(\"ObservationDate>=\"+pivot_date)\n    x_truth=temp.ObservationDate\n    y_truth=temp.Deaths\n    pred_=res_regional[(res_regional['Country_Region']==country_name) & ((res_regional['Province_State']==state_name))]\n    x_pred=pred_.Date[0:num_days]\n    y_pred=pred_.Fatalities[0:num_days]\n    return list(x_truth),list(y_truth),list(x_pred),list(y_pred)","3a42b36c":"# Utility Method to convert newly added prediction to cumulative [Not Accurate]\ndef get_cumulative_confirmed_cases(world_data_):\n    world_data_=world_data_.sort_values(['Country_Region','Date'])\n    temp=[0*i for i in range(len(world_data_))]\n    world_data_['Cumulative Confirmed']=world_data_['New Confirmed']\n    for i in tqdm(range(1,len(world_data_))):\n        if(world_data_['Country_Region'].iloc[i]!=world_data_['Country_Region'].iloc[i-1]):\n            world_data_['Cumulative Confirmed'].iloc[i]=world_data_['ConfirmedCases'].iloc[i]\n    for i in tqdm(range(1,len(world_data_))):    \n        if(world_data_['Country_Region'].iloc[i]==world_data_['Country_Region'].iloc[i-1]):\n            world_data_['Cumulative Confirmed'].iloc[i]=world_data_['Cumulative Confirmed'].iloc[i]+world_data_['Cumulative Confirmed'].iloc[i-1]\n    return world_data_","8740c9cc":"# num_days = Num of days for which Forcasting is required\n#forcast_start_date='2020-04-01'\n\nres_confirmed=forcast(model_c,X_test_c,forcast_start_date,num_days=50)\nres_deaths=forcast(model_d,X_test_d,forcast_start_date,num_days=50)\nres_new_confirmed=forcast(model_nc,X_test_nc,forcast_start_date,num_days=50)","6ee3ea0a":"# res_regional contains submission data along with extra columns\nsub,res_regional=prepare_submission(res_confirmed,res_deaths,res_new_confirmed,test,pivot_date)\nsub.to_csv('submission.csv',index=None)\nsub.head()","0705930e":"x_truth_Ge,y_truth_Ge,x_pred_Ge,y_pred_Ge=get_countrywise_forcast_('New Confirmed','Germany','NoState',15)\nx_truth_In,y_truth_In,x_pred_In,y_pred_In=get_countrywise_forcast_('New Confirmed','India','NoState',15)\nx_truth_Sp,y_truth_Sp,x_pred_Sp,y_pred_Sp=get_countrywise_forcast_('New Confirmed','Spain','NoState',15)\nx_truth_It,y_truth_It,x_pred_It,y_pred_It=get_countrywise_forcast_('New Confirmed','Italy','NoState',15)","da6d0f8f":"x_truth_Ge,y_truth_Ge,x_pred_Ge,y_pred_Ge=get_countrywise_forcast('Germany','NoState',15)\nx_truth_In,y_truth_In,x_pred_In,y_pred_In=get_countrywise_forcast('India','NoState',15)\nx_truth_Sp,y_truth_Sp,x_pred_Sp,y_pred_Sp=get_countrywise_forcast('Spain','NoState',15)\nx_truth_It,y_truth_It,x_pred_It,y_pred_It=get_countrywise_forcast('Italy','NoState',15)","80a389ae":"fig = make_subplots(rows=2, cols=2)\nfig.update_layout(template='plotly_dark')\nfig.add_trace(go.Scatter(x=x_truth_In, \n                         y=y_truth_In,\n                         mode='lines+markers',\n                         name='Actual_India',\n                         line=dict(color='#CCFFCC', width=3)),1,1)\nfig.add_trace(go.Scatter(x=x_pred_In, \n                         y=y_pred_In,\n                         mode='lines+markers',\n                         name='Predicted_India',\n                         line=dict(color='red', width=1)),1,1)\n\nfig.add_trace(go.Scatter(x=x_truth_Sp, \n                         y=y_truth_Sp,\n                         mode='lines+markers',\n                         name='Actual_Spain',\n                         line=dict(color='yellow', width=3)),1,2)\nfig.add_trace(go.Scatter(x=x_pred_Sp, \n                         y=y_pred_Sp,\n                         mode='lines+markers',\n                         name='Predicted_Spain',\n                         line=dict(color='red', width=1)),1,2)\n\nfig.add_trace(go.Scatter(x=x_truth_Ge, \n                         y=y_truth_Ge,\n                         mode='lines+markers',\n                         name='Actual_Germany',\n                         line=dict(color='#E5CCFF', width=3)),2,1)\nfig.add_trace(go.Scatter(x=x_pred_Ge, \n                         y=y_pred_Ge,\n                         mode='lines+markers',\n                         name='Predicted_Germany',\n                         line=dict(color='red', width=1)),2,1)\n\n\nfig.add_trace(go.Scatter(x=x_truth_It, \n                         y=y_truth_It,\n                         mode='lines+markers',\n                         name='Actual-Italy',\n                         line=dict(color='#33FFFF', width=3)),2,2)\nfig.add_trace(go.Scatter(x=x_pred_It, \n                         y=y_pred_It,\n                         mode='lines+markers',\n                         name='Predicted_Italy',\n                         line=dict(color='red', width=1)),2,2)\n\nfig.update_layout(template='plotly_dark',\n                  title = 'COVID-19 Confirmed Cases prediction in India\/Spain\/Germany\/Italy(27th March - 9th April)',\n                  annotations=[\n    ]\n                 )","38d6234f":"x_truth_Ge,y_truth_Ge,x_pred_Ge,y_pred_Ge=get_countrywise_forcast_Deaths('Germany','NoState',15)\nx_truth_In,y_truth_In,x_pred_In,y_pred_In=get_countrywise_forcast_Deaths('India','NoState',15)\nx_truth_Sp,y_truth_Sp,x_pred_Sp,y_pred_Sp=get_countrywise_forcast_Deaths('Spain','NoState',15)\nx_truth_It,y_truth_It,x_pred_It,y_pred_It=get_countrywise_forcast_Deaths('Italy','NoState',15)","c2b22209":"fig = make_subplots(rows=2, cols=2)\nfig.update_layout(template='plotly_dark')\nfig.add_trace(go.Scatter(x=x_truth_In, \n                         y=y_truth_In,\n                         mode='lines+markers',\n                         name='Actual_India',\n                         line=dict(color='#CCFFCC', width=3)),1,1)\nfig.add_trace(go.Scatter(x=x_pred_In, \n                         y=y_pred_In,\n                         mode='lines+markers',\n                         name='Predicted_India',\n                         line=dict(color='red', width=1)),1,1)\n\nfig.add_trace(go.Scatter(x=x_truth_Sp, \n                         y=y_truth_Sp,\n                         mode='lines+markers',\n                         name='Actual_Spain',\n                         line=dict(color='yellow', width=3)),1,2)\nfig.add_trace(go.Scatter(x=x_pred_Sp, \n                         y=y_pred_Sp,\n                         mode='lines+markers',\n                         name='Predicted_Spain',\n                         line=dict(color='red', width=1)),1,2)\n\nfig.add_trace(go.Scatter(x=x_truth_Ge, \n                         y=y_truth_Ge,\n                         mode='lines+markers',\n                         name='Actual_Germany',\n                         line=dict(color='#E5CCFF', width=3)),2,1)\nfig.add_trace(go.Scatter(x=x_pred_Ge, \n                         y=y_pred_Ge,\n                         mode='lines+markers',\n                         name='Predicted_Germany',\n                         line=dict(color='red', width=1)),2,1)\n\n\nfig.add_trace(go.Scatter(x=x_truth_It, \n                         y=y_truth_It,\n                         mode='lines+markers',\n                         name='Actual-Italy',\n                         line=dict(color='#33FFFF', width=3)),2,2)\nfig.add_trace(go.Scatter(x=x_pred_It, \n                         y=y_pred_It,\n                         mode='lines+markers',\n                         name='Predicted_Italy',\n                         line=dict(color='red', width=1)),2,2)\n\nfig.update_layout(template='plotly_dark',\n                  title = 'COVID-19 Death Cases prediction in India\/Spain\/Germany\/Italy(27th March - 9th April)',\n                  annotations=[\n    ]\n                 )","4bf41030":"[kaggle Top 8%]Please visit this notebook in case you want to check performance of Tree Based Models(DecisionTree\/XGBoost) \nhttps:\/\/www.kaggle.com\/arpandas65\/covid-19-week3-forecasting-decisiontree-xgboost","51954574":"# STAY HOME, STAY SAFE !\nIf you found these notebook useful, your unpove will encourage me to improve more. Thank You ","2881f1e5":"### Specialities of this Notebook\n\n- The 'forcast' method will give a projection of n number of days where n is user input\n- Check the model performance with ground truth from India\/Spain\/Italy\/Germany\n- The forcast is a rolling projectio, for N+1 days forcast it takes N-7 to Nth days data as input\n- Covid_Countrywise: Which gives calculation of countrywise how many new cases are getting added\n- Flexibility to use a pivot date for training\/testing, you can start training\/prediction from any date of choice","9f1712eb":"## Forcasting","7c463b48":"### Reshapping the data","fd5d262b":"## Preparing the Model","21e98682":"### Model for Death Cases","1a5aa8ef":"## Submission","e289efce":"## Data Preprocessing","a6a6f0bd":"## Importing Necessary Libraries","257e7cc1":"## Model to predict Newly Confirmed Cases","60afef53":"### Visulizing the Prediction","05948f25":"Please visit the following notebook for a detailed regional and timeseries Exploratory Data Analysis\nhttps:\/\/www.kaggle.com\/arpandas65\/covid-19-regional-and-time-series-data-analysis?scriptVersionId=31484857","a34b3ff8":"### Model for Confirmed cases","07852d11":"### A Brief Description\nCoronavirus disease 2019 (COVID-19) is an infectious disease caused by severe acute respiratory syndrome coronavirus 2 (SARS coronavirus 2, or SARS-CoV-2),a virus closely related to the SARS virus.The disease was discovered and named during the 2019\u201320 coronavirus outbreak.Those affected may develop a fever, dry cough, fatigue, and shortness of breath. A sore throat,runny nose or sneezing is less common. While the majority of cases result in mild symptoms,some can progress to pneumonia and multi-organ failure.","847cbeae":"### What is our problem statement?\nGiven historical data We need to predict the Number of Confirmed and Death cases. The task at hand is very sensitive at nature but can help us with better readyness with a picture of what can come next \n\nTo train our model,We will take past 7 days data as Input and Predict the Number of cases on day 8th.","b02982a7":"### Spliting the data","5ecf7091":"### Stacked LSTM ","ccdb5895":"## Cleaning Data","a34ce142":"Let's prepare a list of all states of each region\/country","c3cc1bfa":"## Reading Data","e798905f":"### Exploratory Data Analysis and Visualization","c8a325c4":"# COVID-19 Projection using LSTM","b9d84cc0":"## Utilities for Prediction and Submission","479cce78":"### Countrywise Forcast","9f20072b":"We will convert the prepared data set in to a supervised Regression problem. We will take last 7 days data as input and 8th day's data as output. Now our problem statement will be:\n\n<b>Given last 7 days data and population information predict the No of confirmed and Death cases on 8th day<\/b>","e568ab00":"### What is LSTM?\nLSTMS are a special kind of RNN(Recurrent Neural Network),capable of learning long-term dependencies from Context. Generaly They perform well on sequential data. LSTMs are widely used in Timeseries analysis.\n\nVisit : https:\/\/towardsdatascience.com\/rnn-simplified-a-beginners-guide-cf3ae1a8895b to learn more on RNNs\n"}}