{"cell_type":{"71220040":"code","3284cfad":"code","a53f1d56":"code","4afaef50":"code","4a50161d":"code","5adb9e07":"code","ded77b68":"code","786cdd1f":"code","f7c5b3be":"code","4c553209":"code","c18f4d72":"code","64646890":"code","144afa78":"code","3117956b":"code","62bd1dab":"code","a42c6d77":"code","3cff420e":"code","296a2aaf":"code","df1c2a1d":"code","30fd448d":"code","d4c49c3d":"code","527dbd33":"code","34c93c7b":"code","d553e5cd":"code","4553344c":"code","5f2a0c75":"code","fe4890b0":"code","fbe6d909":"code","71b3d56a":"code","613d772b":"markdown","7476d416":"markdown","f7c6082e":"markdown","c03bb7dd":"markdown","58124c40":"markdown","e8ee626a":"markdown","3c79cd63":"markdown","b63a3191":"markdown","6b2c2d9b":"markdown","22f1a6c9":"markdown","0ad692d7":"markdown","3a32135d":"markdown","391644c9":"markdown","731f9f3b":"markdown","def6d90d":"markdown","b52c65bf":"markdown","fdd4fb09":"markdown","bd47a83b":"markdown","28259583":"markdown","58393378":"markdown","8f4af9d8":"markdown","cd9b694d":"markdown","742ba70a":"markdown","c6830b8d":"markdown"},"source":{"71220040":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3284cfad":"df=pd.read_csv('..\/input\/water-potability\/water_potability.csv')","a53f1d56":"df.head()","4afaef50":"(df.isnull().sum()\/len(df)*100).sort_values(ascending=False).round(2)","4a50161d":"fig,ax=plt.subplots(figsize=(9,9))\nsns.heatmap(df.corr(),annot=True)","5adb9e07":"df_sul=df[['Sulfate','Organic_carbon','Chloramines']]","ded77b68":"df_sul=df_sul.dropna()","786cdd1f":"from sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\nscled=scaler.fit_transform(df_sul.drop('Sulfate',axis=1))","f7c5b3be":"from sklearn.model_selection import train_test_split\nx_tr,x_te,y_tr,y_te=train_test_split(scled,df_sul['Sulfate'],random_state=42,test_size=0.3)","4c553209":"from sklearn.svm import SVR\nsvr=SVR()","c18f4d72":"from sklearn.model_selection import GridSearchCV\nparam_grid={'kernel':['linear', 'poly', 'rbf', 'sigmoid'],'degree':[1,2],'gamma':['scale','auto'],'C':[1.2,1.3,1.4,1.7]}\ngs=GridSearchCV(svr,param_grid=param_grid,n_jobs=-1,cv=3,verbose=3)","64646890":"gs.fit(x_tr,y_tr)\nsul_pr=gs.predict(x_te)","144afa78":"sulfatee=gs.predict(scaler.fit_transform(df[['Organic_carbon','Chloramines']]))","3117956b":"df['sulfatee']=sulfatee","62bd1dab":"df.drop('Sulfate',axis=1,inplace=True)","a42c6d77":"tr_df=df[['Chloramines','Conductivity','Potability','Trihalomethanes']]\ntr_df=tr_df.dropna()\ntr_sc=scaler.fit_transform(tr_df.drop('Trihalomethanes',axis=1))\ntr_tr,tr_te,ytr_tr,yte_te=train_test_split(tr_sc,tr_df['Trihalomethanes'],random_state=42,test_size=0.3)\ngs.fit(tr_tr,ytr_tr)","3cff420e":"trr=gs.predict(scaler.fit_transform(df[['Chloramines','Conductivity','Potability']]))","296a2aaf":"df['trr']=trr\ndf.drop('Trihalomethanes',axis=1,inplace=True)","df1c2a1d":"ph_df=df[['ph','Hardness','sulfatee','Conductivity','Organic_carbon','trr']]\nph_df.dropna(inplace=True)\nph_sc=scaler.fit_transform(ph_df.drop('ph',axis=1))\nx_tr,x_te,y_tr,y_te=train_test_split(ph_sc,ph_df['ph'],random_state=42,test_size=0.3)\ngs.fit(x_tr,y_tr)\nphh=gs.predict(df[['Hardness','sulfatee','Conductivity','Organic_carbon','trr']])\ndf['phh']=phh\ndf.drop('ph',axis=1,inplace=True)","30fd448d":"df.head()","d4c49c3d":"(df.isnull().sum()\/len(df)*100).round(2)","527dbd33":"from sklearn.svm import SVC\nsvc=SVC()\nparam_grid={'C':[1.2,1.5,2.2,3.5,3.2,4.1],'kernel':['linear', 'poly', 'rbf', 'sigmoid'],'degree':[1,2,4,8,10],'gamma':['scale','auto']}\ngridsearch=GridSearchCV(svc,param_grid=param_grid,n_jobs=-1,verbose=4,cv=3)","34c93c7b":"scaled_x=scaler.fit_transform(df.drop('Potability',axis=1))","d553e5cd":"x_tr,x_te,y_tr,y_te=train_test_split(scaled_x,df['Potability'],random_state=42,test_size=0.3)","4553344c":"x_tr.shape,y_tr.shape","5f2a0c75":"gridsearch.fit(x_tr,y_tr)","fe4890b0":"gridsearch.best_params_","fbe6d909":"predicted_y=gridsearch.predict(x_te)\nfrom sklearn.metrics import confusion_matrix\nprint(confusion_matrix(y_te,predicted_y))","71b3d56a":"from sklearn.metrics import accuracy_score\naccuracy_score(y_te,predicted_y)","613d772b":"### Fitting and predicting the data in Grid-search ","7476d416":"### Dropping null values","f7c6082e":"### Predicting the values with best model","c03bb7dd":"# Checking the percentage of null values","58124c40":"### Fitting The data","e8ee626a":"### Scaling features","3c79cd63":"### dropping the old column","b63a3191":"### Co-relation map to understand the data better","6b2c2d9b":"### Final data-set","22f1a6c9":"### Splitting the data","0ad692d7":"### Scaling the dataset","3a32135d":"### For tuning the hyper-parameters","391644c9":"### Building a model to predict the Potability","731f9f3b":"## Approach used to fill null values:\n1. **Identify the column with null values**\n2. **Build Co-relation chart**\n3. **Form a new data-set with one column of missing values and other positive co-related values filled data**\n4. **Drop null values and Apply ML model and hyper-parameter tuning to find the best predicted value**\n5. **Repeat the steps 3-4 till all the columns are filled**","def6d90d":"### Adding new column in dataframe","b52c65bf":"### 100% Accuracy achieved","fdd4fb09":"### Splitting the final Data-set","bd47a83b":"### Importing the model to predict the values for missing column","28259583":"### Predicting values for missing ph column","58393378":"### Adding the data in df and dropping the old data","8f4af9d8":"### Fitting data for next column","cd9b694d":"### Predicting the values","742ba70a":"### Testing the accuracy","c6830b8d":"### Getting the column ready to be predicted"}}