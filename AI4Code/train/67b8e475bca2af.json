{"cell_type":{"9a0a8ba3":"code","1d807406":"code","717caae5":"code","7bae3af6":"code","4715d6f3":"code","abe924d2":"code","3d117e29":"code","07c44f94":"code","e681a8c2":"code","a9c465d4":"code","3b9f89d0":"code","0cf0e2b7":"code","1e0c705f":"code","b163c8f0":"code","1f7c7454":"code","a0a45562":"code","90d979ba":"code","0db107e2":"code","93c7c8e8":"code","a527a47d":"code","9144c95e":"markdown"},"source":{"9a0a8ba3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","1d807406":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport cv2\nimport os\nfrom tqdm import tqdm\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Model,Sequential, Input, load_model\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D, GlobalAveragePooling2D\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom keras.applications import DenseNet121","717caae5":"defect_types = ['Center','Donut','Edge-loc','Edge-ring','Loc','Random','Scratch','Near-Full','None']\ndata_dir = '..\/input\/wafermap\/WaferMap\/balanced\/'\ntrain_dir = os.path.join(data_dir)\n#test_dir = os.path.join(data_dir, 'test')","7bae3af6":"train_data = []\nfor defects_id, sp in enumerate(defect_types):\n    for file in os.listdir(os.path.join(train_dir, sp)):\n        train_data.append(['{}\/{}'.format(sp, file), defects_id, sp])\n        \ntrain = pd.DataFrame(train_data, columns=['File', 'DefectsId','Defect Type'])\ntrain.head()","4715d6f3":"# Randomize the order of training set\nSEED = 42\ntrain = train.sample(frac=1, random_state=SEED) \ntrain.index = np.arange(len(train)) # Reset indices\ntrain.head()","abe924d2":"# Plot a histogram\nplt.hist(train['DefectsId'])\nplt.title('Frequency Histogram of Species')\nplt.figure(figsize=(12, 12))\nplt.show()","3d117e29":"# Display images for different species\ndef plot_defects(defect_types, rows, cols):\n    fig, ax = plt.subplots(rows, cols, figsize=(12, 12))\n    defect_files = train['File'][train['Defect Type'] == defect_types].values\n    n = 0\n    for i in range(rows):\n        for j in range(cols):\n            image_path = os.path.join(data_dir, defect_files[n])\n            ax[i, j].set_xticks([])\n            ax[i, j].set_yticks([])\n            ax[i, j].imshow(cv2.imread(image_path))\n            n += 1\n# Displays first n images of class from training set\nplot_defects('Scratch', 5, 5)","07c44f94":"IMAGE_SIZE = 64\n\ndef read_image(filepath):\n    return cv2.imread(os.path.join(data_dir, filepath)) # Loading a color image is the default flag\n# Resize image to target size\ndef resize_image(image, image_size):\n    return cv2.resize(image.copy(), image_size, interpolation=cv2.INTER_AREA)","e681a8c2":"X_train = np.zeros((train.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3))\nfor i, file in tqdm(enumerate(train['File'].values)):\n    image = read_image(file)\n    X_train[i] = resize_image(image, (IMAGE_SIZE, IMAGE_SIZE))\n# Normalize the data\nX_train = X_train \/ 255.\nprint('Train Shape: {}'.format(X_train.shape))","a9c465d4":"Y_train = train['DefectsId'].values\nY_train = to_categorical(Y_train, num_classes=9)","3b9f89d0":"BATCH_SIZE = 64\n\n# Split the train and validation sets \nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=SEED)","0cf0e2b7":"fig, ax = plt.subplots(1, 4, figsize=(15, 15))\nfor i in range(4):\n    ax[i].set_axis_off()\n    ax[i].imshow(X_train[i])\n    ax[i].set_title(defect_types[np.argmax(Y_train[i])])","1e0c705f":"#def construct_model():\n    #model = Sequential()\n    \n    #model.add(Conv2D(filters=32, kernel_size=(5, 5), padding='SAME', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n                #activation='relu'))\n    #model.add(BatchNormalization()) # Normalize the activations of the previous layer at each batch\n    #model.add(Conv2D(filters=32, kernel_size=(5, 5), padding='SAME', activation='relu'))\n    #model.add(BatchNormalization())\n    #model.add(MaxPool2D(pool_size=(2, 2)))\n\n    #model.add(Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation='relu'))\n    #model.add(BatchNormalization())\n    #model.add(Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation='relu'))\n    #model.add(BatchNormalization())\n    #model.add(MaxPool2D(pool_size=(2, 2)))\n\n    #model.add(Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu'))\n    #model.add(BatchNormalization())\n    #model.add(Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu'))\n    #model.add(BatchNormalization())\n    #model.add(MaxPool2D(pool_size=(2, 2)))\n\n    #model.add(Flatten()) # Flatten the input\n    #model.add(Dense(64, activation='relu'))\n    #model.add(Dropout(0.2))\n    #model.add(Dense(9, activation='softmax'))\n    # Configure the learning process\n    # The loss function is the objective that the model will try to minimize\n    # For any classification problem, use accuracy metric\n    #optimizer = Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=0.1, decay=0.0)\n    #model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n    \n    #model.summary()\n    #return model","b163c8f0":"EPOCHS = 50\nSIZE=64\nN_ch=3","1f7c7454":"def build_densenet():\n    densenet = DenseNet121(weights='imagenet', include_top=False)\n\n    input = Input(shape=(SIZE, SIZE, N_ch))\n    x = Conv2D(3, (3, 3), padding='same')(input)\n    \n    x = densenet(x)\n    \n    x = GlobalAveragePooling2D()(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(256, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n\n    # multi output\n    output = Dense(9,activation = 'softmax', name='root')(x)\n \n\n    # model\n    model = Model(input,output)\n    \n    optimizer = Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=0.1, decay=0.0)\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n    model.summary()\n    \n    return model","a0a45562":"model = build_densenet()\nannealer = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1, min_lr=1e-3)\ncheckpoint = ModelCheckpoint('model.h5', verbose=1, save_best_only=True)\n# Generates batches of image data with data augmentation\ndatagen = ImageDataGenerator(rotation_range=360, # Degree range for random rotations\n                        width_shift_range=0.2, # Range for random horizontal shifts\n                        height_shift_range=0.2, # Range for random vertical shifts\n                        zoom_range=0.2, # Range for random zoom\n                        horizontal_flip=True, # Randomly flip inputs horizontally\n                        vertical_flip=True) # Randomly flip inputs vertically\n\ndatagen.fit(X_train)\n# Fits the model on batches with real-time data augmentation\nhist = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=BATCH_SIZE),\n               steps_per_epoch=X_train.shape[0] \/\/ BATCH_SIZE,\n               epochs=EPOCHS,\n               verbose=2,\n               callbacks=[annealer, checkpoint],\n               validation_data=(X_val, Y_val))\n","90d979ba":"#model = load_model('..\/output\/kaggle\/working\/model.h5')\nfinal_loss, final_accuracy = model.evaluate(X_val, Y_val)\nprint('Final Loss: {}, Final Accuracy: {}'.format(final_loss, final_accuracy))","0db107e2":"Y_pred = model.predict(X_val)\n\nY_pred = np.argmax(Y_pred, axis=1)\nY_true = np.argmax(Y_val, axis=1)\n\ncm = confusion_matrix(Y_true, Y_pred)\nplt.figure(figsize=(12, 12))\nax = sns.heatmap(cm, cmap=plt.cm.Greens, annot=True, square=True, xticklabels=defect_types, yticklabels=defect_types)\nax.set_ylabel('Actual', fontsize=40)\nax.set_xlabel('Predicted', fontsize=40)","93c7c8e8":"# accuracy plot \nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\n# loss plot\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","a527a47d":"from skimage import io\nfrom keras.preprocessing import image\n#path='imbalanced\/Scratch\/Scratch_400.jpg'\nimg = image.load_img('..\/input\/wafermap\/WaferMap\/test\/wafermapdefects.jpg', grayscale=False, target_size=(64, 64))\nshow_img=image.load_img('..\/input\/wafermap\/WaferMap\/test\/wafermapdefects.jpg', grayscale=False, target_size=(200, 200))\ndefect_class = ['Center','Donut','Edge-Loc','Edge-Ring','Loc','Random','Scratch','Near-Full','None']\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis = 0)\n\nx \/= 255\n\ncustom = model.predict(x)\nprint(custom[0])\n\n\nx = np.array(x, 'float32')\n#x = x.reshape([64, 64]);\n\n#plt.gray()\nplt.imshow(show_img)\nplt.show()\n\na=custom[0]\nmax_num=max(a);\nfor i in range(0,len(a)):\n    if a[i]==max_num:\n        ind=i\n        break\n        \nprint('Prediction:',defect_class[ind])","9144c95e":"### Testing By External Images"}}