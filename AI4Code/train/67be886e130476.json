{"cell_type":{"6b37d5ff":"code","8682e967":"code","127c1467":"code","e724e4ad":"code","a3c49211":"code","4dd130fd":"code","a718d26b":"code","5ce5d347":"code","3ffe43bb":"code","d92f238a":"code","ce8d26f3":"code","83850121":"code","e50ba41c":"code","cd4a91c0":"code","22cb9f99":"code","a06fca1a":"code","ec4246d4":"code","7dd1eae0":"code","fb48f3d4":"code","aca874a7":"markdown","0a1f89d9":"markdown","1e1405f9":"markdown"},"source":{"6b37d5ff":"import numpy as np\nimport pandas as pd\n# from catboost import Pool, CatBoostRegressor\nfrom sklearn.preprocessing import OrdinalEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor","8682e967":"# Load the training data\ntrain = pd.read_csv(\"..\/input\/30-days-of-ml\/train.csv\", index_col=0)\ntest = pd.read_csv(\"..\/input\/30-days-of-ml\/test.csv\", index_col=0)\n\n# Preview the data\ntrain.head()","127c1467":"#Target \ny = train['target']\nf = train.drop(['target'],axis = 1)","e724e4ad":"y.head()","a3c49211":"f.head()","4dd130fd":"#Choosing categorical columns\n# cat_col = [c for c in features.columns if 'cat' in c]\ncat_col = [c for c in f.columns if f[c].dtype =='object']\nprint(cat_col)\n#numerical columns\nnum_col = [c for c in f.columns if f[c].dtype in ['int64','float64']]\nprint(num_col)\n\n#cmbined categoricals and numericals\nall_col = cat_col + num_col\nX = f[all_col].copy()\nX_test = test[all_col].copy()\n","a718d26b":"# Define column transfermer for standardizing num_col and encoding cat_col\npreprocessor = ColumnTransformer(\n    [\n        ('num',StandardScaler(),num_col),\n        ('cat',OrdinalEncoder(),cat_col)\n    ])","5ce5d347":"#Train test split\nX_t,X_v,y_t,y_v = train_test_split(X,y, train_size = 0.8,test_size = 0.2 ,random_state =10)","3ffe43bb":"# rep_value = [5,10,20,30,40,50,60,70,80,90,95]\n# all_value={}\n# for n in rep_value:\n#     #Define Model\n#     model = XGBRegressor(\n#         n_estimators = 2500,\n#         max_debth = 8,#5,\n#         learning_rate = 0.05,#0.12,\n#         n_jobs = 10, #10,\n#         random_state = 10, #30,\n#         colsample_bytree = 0.1,#0.85,\n#         subsample = 0.6,#0.9,\n#         booster='gbtree',\n#         reg_lambda= 95,#30,\n#         reg_alpha=30,\n# #         gamma = n\n#     )\n\n#     #Define Pipeline\n#     pipe = Pipeline(steps = [('preprocessor',preprocessor),('model',model)])\n\n#     pipe[0].fit(X_t)\n\n#     fit_param = {\"model__eval_set\":[(pipe[0].transform(X_v),y_v)],\n#                                     \"model__early_stopping_rounds\":7}\n#     pipe.fit(X_t,y_t,**fit_param)\n#     predict_value = pipe.predict(X_v)\n#     all_value[n]=mean_squared_error(predict_value,y_v)\n#     print(\"Mean Square Error:\", mean_squared_error(predict_value,y_v))","d92f238a":"# for i in range(10,100,10):\n#     print(i)\n# all_value\n#Value test and output for subsample:\n# {0.1: 0.5297349242784952,\n#  0.2: 0.5272713080584766,\n#  0.3: 0.5247034898856802,\n#  0.4: 0.5225528749291577,\n#  0.5: 0.5219788365857486,\n#  0.6: 0.5219465330099143, #minimum\n#  0.7: 0.5232120403949474,\n#  0.8: 0.5216207075369675,\n#  0.9: 0.5208703054904071,\n#  0.95: 0.5215806802983007}\n\n# reg_alpha output :\n# {10: 0.521451141359662,\n#  20: 0.5213062351263095,\n#  30: 0.5204483047237963,\n#  40: 0.5211341396053314,\n#  50: 0.5207986117757092,\n#  60: 0.5210576140423934,\n#  70: 0.5208585932909453,\n#  80: 0.5200745866426433,\n#  90: 0.5201540870755343,\n#  95: 0.5200671543919076} #minimum\n#Reg_lambda output:\n# {10: 0.5198266115775522,\n#  20: 0.5197696244228401,\n#  30: 0.519031572013811,\n#  40: 0.5192072590851861,\n#  50: 0.5190830268169911,\n#  60: 0.5195764462768282,\n#  70: 0.5198627127896706,\n#  80: 0.5204061975468359,\n#  90: 0.5207461820607538,\n#  95: 0.5211952352655078}\n","ce8d26f3":"# {0.02: 0.5244700476255569,\n#  0.05: 0.5237069908393156,\n#  0.07: 0.5239774205922112,\n#  0.08: 0.5241931153016941,\n#  0.1: 0.5245118802581357,\n#  0.15: 0.5255665612682926,\n#  0.2: 0.5271434809834863,\n#  0.25: 0.5272137744609866,\n#  0.3: 0.5287256428846243}","83850121":" model = XGBRegressor(\n        n_estimators = 2500,\n        max_debth = 8,#5,\n        learning_rate = 0.05,#0.12,\n        n_jobs = 10, #10,\n        random_state = 10, #30,\n        colsample_bytree = 0.1,#0.85,\n        subsample = 0.6,#0.9,\n        booster='gbtree',\n        reg_lambda= 95,#30,\n        reg_alpha=30,\n#         gamma = n\n    )\n\n#Define Pipeline\npipe = Pipeline(steps = [('preprocessor',preprocessor),('model',model)])\n\npipe[0].fit(X_t)\n\nfit_param = {\"model__eval_set\":[(pipe[0].transform(X_v),y_v)],\n                                \"model__early_stopping_rounds\":7}\npipe.fit(X_t,y_t,**fit_param)\npredict_value = pipe.predict(X_v)\n# all_value[n]=mean_squared_error(predict_value,y_v)\nprint(\"Mean Square Error:\", mean_squared_error(predict_value,y_v))","e50ba41c":"# #Define Pipeline\n# pipe = Pipeline(steps = [('preprocessor',preprocessor),('model',model)])","cd4a91c0":"\n# pipe[0].fit(X_t)\n\n# fit_param = {\"model__eval_set\":[(pipe[0].transform(X_v),y_v)],\n#                                 \"model__early_stopping_rounds\":7}","22cb9f99":"pipe.fit(X_t,y_t,**fit_param)\npredict_value = pipe.predict(X_v)\nprint(\"Mean Square Error:\", mean_squared_error(predict_value,y_v))","a06fca1a":"predict_test = pipe.predict(X_test)\npredict_test","ec4246d4":"# print(\"Mean Square Error:\", mean_squared_error(predict_test,y_v))\n# submission.target = predict_test\n# X_test\n# X_t\n# ,X_v,y_t,y_v","7dd1eae0":"output = pd.DataFrame({'id': X_test.index,\n                       'target': predict_test})\noutput.to_csv('submission.csv', index=False)","fb48f3d4":"output","aca874a7":"# CatBoost Regressor","0a1f89d9":"## The Data","1e1405f9":"### Choose categorical features."}}