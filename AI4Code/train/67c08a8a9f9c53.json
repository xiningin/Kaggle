{"cell_type":{"6941c6ed":"code","093c8ab4":"code","3fe6e305":"code","20ca4fc0":"code","9e0a0427":"code","27cb521c":"code","a4f45950":"code","456867ab":"code","648ceaab":"code","8f097443":"code","4b086fa2":"code","905fa28b":"code","7d6da16e":"code","b63a038b":"code","4aea6cba":"code","86363796":"code","16750a62":"code","e3ea6adc":"code","54132a5f":"code","19bdcb0e":"code","b82bf08c":"code","78a319ac":"code","8ae5d846":"code","db0f1f9e":"code","187e68c5":"code","43d5d83d":"code","a5d61bd6":"code","7d891e05":"code","82d17af4":"code","db16d41a":"code","abf14ded":"code","553a338d":"markdown","89442906":"markdown","433ffaf4":"markdown","a7772dad":"markdown","cc2c9f0c":"markdown","acd3067e":"markdown","aecc1a70":"markdown","5395ad0c":"markdown","dfb9a641":"markdown","7829380f":"markdown","31a1e15f":"markdown","d059efe0":"markdown","5f416edd":"markdown","cc838481":"markdown","9670182d":"markdown","90d2264d":"markdown","0857a6ef":"markdown","57885073":"markdown","6d77d667":"markdown","3114c1ee":"markdown","70e22409":"markdown","cf3d893a":"markdown","f2d9e63a":"markdown","04e24383":"markdown","e9b072a0":"markdown","de4dfd4e":"markdown","05925b4d":"markdown","5f96ef3a":"markdown","2d1725af":"markdown","e6767b3a":"markdown","6053329e":"markdown","414d2ca9":"markdown","a40d0dfb":"markdown","02064f3a":"markdown","7f1f38d3":"markdown","9476c7d9":"markdown","c07b240f":"markdown","77b1ea8d":"markdown","f43e71b8":"markdown","1fa29455":"markdown","14ff92e8":"markdown","b7da9789":"markdown","853cc16c":"markdown","65eca5e0":"markdown","540e287f":"markdown","07eddad2":"markdown","8e91d7ef":"markdown","48e7578e":"markdown","35e9eb82":"markdown","cf7ec52b":"markdown","2156dad5":"markdown","ce78cba0":"markdown","45aecc78":"markdown","5d49dfba":"markdown","538eff23":"markdown","e2885b44":"markdown","ce836b2e":"markdown"},"source":{"6941c6ed":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","093c8ab4":"# import libraries\n\nimport pandas as pd #working with dataframes\n%matplotlib inline\nimport matplotlib.pyplot as plt #plotting\nimport seaborn as sns #plotting\nfrom sklearn.preprocessing import StandardScaler, RobustScaler #scale data\nfrom sklearn.model_selection import train_test_split #for splitting data\nfrom imblearn.under_sampling import RandomUnderSampler #for undersampling \nfrom imblearn.over_sampling import RandomOverSampler #for oversampling\nfrom imblearn.over_sampling import SMOTE #for smote\nfrom imblearn.under_sampling import NearMiss  #near miss undersampling\nfrom sklearn import tree # for decision tree\n#for roc\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import classification_report # classification report: precision, recall\nfrom sklearn.linear_model import LogisticRegression #linear regression\nfrom sklearn.svm import SVC #svc\nfrom sklearn.neighbors import KNeighborsClassifier #knn\nfrom sklearn.ensemble import RandomForestClassifier #random forest\nimport xgboost as xgb #XGBoost","3fe6e305":"#load the data\ndt=pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")\ndt.head()","20ca4fc0":"#to check for basic summary of the data\ndt.describe().apply(lambda s: s.apply(lambda x: format(x, 'f')))","9e0a0427":"#check for missinf values\ndt.isnull()\n#check if we have any missing values\nprint(dt.isnull().values.any())\n#check numver of total missing values\nprint(dt.isnull().sum())","27cb521c":"print(dt['Class'].value_counts())\n# proportion\nprint(dt['Class'].value_counts(normalize=True))","a4f45950":"#plot\ncolors = [\"#E43F5A\", \"#1B1B2F\"]\n\nsns.countplot('Class', data=dt, palette=colors)\nplt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)')","456867ab":"\n# fig=plt.figure()\n\namount_val = dt['Amount'].values\ntime_val = dt['Time'].values\n\n# plt.subplot(2,1,1)\nsns.distplot(amount_val, color='r')\nplt.title('Distribution of Transaction Amount', fontsize=14)\nplt.xlim([min(amount_val), max(amount_val)])\n\n\nplt.show()\n\n","648ceaab":"\n# plt.subplot(2,1,2)\nsns.distplot(time_val,color='b')\nplt.title('Distribution of Transaction Time', fontsize=14)\nplt.xlim([min(time_val), max(time_val)])\n\nplt.show()","8f097443":"plt.xticks([0,1])\nsns.scatterplot(dt['Class'].values, dt['Amount'].values)\nplt.title(\"class vs Amount\")\nplt.xlabel(\"Class\")\nplt.ylabel(\"Amount\")\nplt.show()","4b086fa2":"# Compute the correlation matrix\ncorr = dt.corr()\n\n# Set up the matplotlib figure\nfig = plt.figure(figsize = (12, 9)) \n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, vmax=.9, center=0, square=True)","905fa28b":"#drop the time column\n\ndt=dt.drop(\"Time\",axis=1)\n#can also be done by reassigning dt as dt.iloc(:,2:)\ndt.head()","7d6da16e":"#convering class in categories\ndt[\"Class\"] = dt[\"Class\"].astype('category')\ndt[\"Class\"] = dt[\"Class\"].cat.rename_categories({0: 'Not_Fraud', 1: 'Fraud'})\ndt[\"Class\"]","b63a038b":"scaler = RobustScaler().fit(dt.iloc[:,:-1])\n\nscaler.transform(dt.iloc[:,:-1])\ndt.head()","4aea6cba":"#split\nx=dt.iloc[:,:-1]\ny=dt.iloc[:,-1]\nxTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.2, random_state = 0)\n","86363796":"#check proportion of class\n\nprint(yTrain.value_counts())\nprint(yTest.value_counts())\n# proportion\nprint(yTrain.value_counts(normalize=True))\nprint(yTest.value_counts(normalize=True))","16750a62":"rus = RandomUnderSampler(sampling_strategy='auto',random_state=9650)\nX_res, y_res = rus.fit_resample(xTrain, yTrain)\n# print(X_res.value_counts())\nprint(y_res.value_counts())\n# y_res.head()\nprint(X_res.shape)\nprint(y_res.shape)","e3ea6adc":"ros = RandomOverSampler(sampling_strategy='auto',random_state=9650)\nX_ros, y_ros = ros.fit_resample(xTrain, yTrain)\nprint(y_ros.value_counts())\nprint(X_ros.shape)\nprint(y_ros.shape)","54132a5f":"sm = SMOTE(sampling_strategy='auto',random_state=9650)\nX_sm, y_sm = sm.fit_resample(xTrain, yTrain)\nprint(y_sm.value_counts())\nprint(X_sm.shape)\nprint(y_sm.shape)","19bdcb0e":"nr = NearMiss(sampling_strategy='auto')\nX_nr, y_nr = nr.fit_resample(xTrain, yTrain)\nprint(y_nr.value_counts())\nprint(X_nr.shape)\nprint(y_nr.shape)","b82bf08c":"#function to plot ROC\ndef roc_plot(fpr,tpr):\n    plt.plot(fpr, tpr, color='red', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.legend()\n    plt.show()\ndef test_auc_roc_classification_score(clf):\n    probs = clf.predict_proba(xTest)\n    probs = probs[:, 1]\n    auc = roc_auc_score(yTest, probs)    \n    print('AUC: %.2f' % auc)\n    fpr, tpr, thresholds = roc_curve(yTest,probs, pos_label='Not_Fraud')\n    roc_plot(fpr,tpr)\n    predicted=clf.predict(xTest)\n    report = classification_report(yTest, predicted)\n    print(report)\n    return auc","78a319ac":"clf = tree.DecisionTreeClassifier()\n#for original training dataset\nclf = clf.fit(xTrain, yTrain)\n\ntest_auc_roc_classification_score(clf)","8ae5d846":"clf_under = tree.DecisionTreeClassifier()\nclf_under = clf_under.fit(X_res, y_res)\ntest_auc_roc_classification_score(clf_under)","db0f1f9e":"clf_o = tree.DecisionTreeClassifier()\nclf_o = clf.fit(X_res, y_res)\ntest_auc_roc_classification_score(clf_o)","187e68c5":"clf_sm = tree.DecisionTreeClassifier()\nclf_sm = clf.fit(X_sm, y_sm)\ntest_auc_roc_classification_score(clf_sm)","43d5d83d":"clf_nr = tree.DecisionTreeClassifier()\nclf_nr = clf.fit(X_nr, y_nr)\nauc_nm=test_auc_roc_classification_score(clf_nr)","a5d61bd6":"reg = LogisticRegression(random_state=0, solver='lbfgs', max_iter=1000, multi_class='ovr').fit(X_ros, y_ros)\nauc_reg=test_auc_roc_classification_score(reg)","7d891e05":"knn_clf = KNeighborsClassifier().fit(X_ros, y_ros)\nauc_knn=test_auc_roc_classification_score(knn_clf)","82d17af4":"rf_clf = RandomForestClassifier().fit(X_ros, y_ros)\nauc_rf=test_auc_roc_classification_score(rf_clf)","db16d41a":"xgb_clf = xgb.XGBClassifier(max_depth=3, n_estimator=300, learning_rate=0.05).fit(X_ros, y_ros)\nauc_xgb=test_auc_roc_classification_score(xgb_clf)","abf14ded":"# print(auc_reg)\nm=max(auc_xgb, auc_reg, auc_knn, auc_rf)\nif(m==auc_xgb):\n    print(\"XGBoost performs the best\")\nelif(m==auc_reg):\n    print(\"Logistic Regresion performs the best\")\nelif(m==auc_rf):\n    print(\"Random Forest performs the best\")\nelse:\n    print(\"KNN performs the best\")","553a338d":"### On NearMiss dataset","89442906":"Shows no significant correlation between the features.","433ffaf4":"Different versions of the training set as per sampling technique\n* Undersampling\n* Oversampling\n* SMOTE\n* Near-Miss\n","a7772dad":"## Count the value of the target class","cc2c9f0c":"## XGBoost","acd3067e":"We observe that the dataset is clearly imbalanced.","aecc1a70":"RobustScaler transforms the feature vector by subtracting the median and then dividing by the interquartile range (75% value \u2014 25% value).It reduces the effects of outliers, relative.\n","5395ad0c":"When it comes to a classification problem, we can count on an AUC - ROC Curve.\n\n**AUC - ROC curve** is a performance measurement for classification problem at various thresholds settings. ROC is a probability curve and AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s and 1s as 1s. The ROC curve is plotted with TPR against the FPR where TPR is on y-axis and FPR is on the x-axis. Where:\n* TPR (True Positive Rate) or Recall or Sensitivity= TP\/(TP+FN)\n* Specificity= TN\/(TN+FP)\n* FPR= 1-Specificity= FP\/(TN+FP)\n\nAn excellent model has AUC near to the 1 which means it has good measure of separability. A poor model has AUC near to the 0 which means it has worst measure of separability. In fact it means it is reciprocating the result. It is predicting 0s as 1s and 1s as 0s. And when AUC is 0.5, it means model has no class separation capacity whatsoever.\n","dfb9a641":"## Check proportion of values in the target class","7829380f":"## CART - Decision Trees Classification","31a1e15f":"## Check Summary of data","d059efe0":"## Plot graph for the count","5f416edd":"## Random Forest","cc838481":"In this case, recall is important than precision.","9670182d":"# Near-miss Algorithm","90d2264d":"Applying the same understanding, we know that Recall shall be the model metric we use to select our best model when there is a high cost associated with False Negative.\n\nIn fraud detection or sick patient detection. If a fraudulent transaction (Actual Positive) is predicted as non-fraudulent (Predicted Negative), the consequence can be very bad for the bank.","0857a6ef":"Categoricals are a pandas data type corresponding to categorical variables in statistics. A categorical variable takes on a limited, and usually fixed, number of possible values (categories; levels in R).","57885073":"Machine Learning algorithms tend to produce unsatisfactory classifiers when faced with imbalanced datasets. For any imbalanced data set, if the event to be predicted belongs to the minority class and the event rate is less than 5%, it is usually referred to as a rare event. Dealing with imbalanced datasets entails strategies such as improving classification algorithms or balancing classes in the training data (data preprocessing) before providing the data as input to the machine learning algorithm. The later technique is preferred as it has wider application.\nThe main objective of balancing classes is to either increasing the frequency of the minority class or decreasing the frequency of the majority class. This is done in order to obtain approximately the same number of instances for both the classes. ","6d77d667":"# Over-Sampling","3114c1ee":"It is a step of Data Pre Processing which is applied to independent variables or features of data. It helps to normalise the data within a particular range. Sometimes, it also helps in speeding up the calculations in an algorithm.\n MinMaxScaler, RobustScaler, StandardScaler, and Normalizer are scikit-learn methods to preprocess data for machine learning.","70e22409":"# Data preparation","cf3d893a":"## Split the data into test and train data","f2d9e63a":"# SMOTE","04e24383":"### On over-sampled data","e9b072a0":"## Drop the time column","de4dfd4e":"## Load the data","05925b4d":"## Plot graphs to see behaviour of time and amount","5f96ef3a":"## KNN","2d1725af":"# Modelling","e6767b3a":"Random Undersampling aims to balance class distribution by randomly eliminating majority class examples.  This is done until the majority and minority class instances are balanced out.","6053329e":"# Dealing with imbalance!","414d2ca9":"**Synthetic Minority Over-sampling TEchnique** for imbalanced data is followed to avoid overfitting which occurs when exact replicas of minority instances are added to the main dataset. A subset of data is taken from the minority class as an example and then new synthetic similar instances are created. These synthetic instances are then added to the original dataset. ","a40d0dfb":"### On original Training set ","02064f3a":"# Data Exploration","7f1f38d3":"## Check performance of differently sampled data","9476c7d9":"### On SMOTE","c07b240f":"This graph shaws that the frauds have more variance in terms of amount wrt non-fraud transactions.","77b1ea8d":"We drop the time column since it doesn't actually have any relation with the tractions being fraudulent or non fraudulent(They are jut chronological timestamps)\n","f43e71b8":"It is evident from the values of mean that the data has been normalised with respect to mean ","1fa29455":"### On under-sampled data","14ff92e8":"## Check for missing values","b7da9789":"## Logistic Regression","853cc16c":"Precision is a good measure to determine, when the costs of False Positive is high.","65eca5e0":"## Scale the data","540e287f":"Over-Sampling increases the number of instances in the minority class by randomly replicating them in order to present a higher representation of the minority class in the sample.","07eddad2":"#### Since over-sampled shows best results, we choose it to further test other models","8e91d7ef":"# Importing the libraries","48e7578e":"### Common function to plot ROC and find auc, plot roc and classification report","35e9eb82":"This doesn't give any significant insight","cf7ec52b":"We evaluate the model performance on test data by finding the roc auc score\nWe will now apply various sampling techniques to the data and see the performance on the test set.\n","2156dad5":"NearMiss is an under-sampling technique. Instead of resampling the Minority class, using a distance, this will make the majority class equal to minority class.","ce78cba0":"Before starting first we check how CART performs with imbalanced data. We use the ROC as a parameter to gauge model performance on the test set.","45aecc78":"# Under- Sampling","5d49dfba":"# Testing different models","538eff23":"## Convert the Class column into Categories","e2885b44":"## Correlation- Heatmap","ce836b2e":"There are no missing values."}}