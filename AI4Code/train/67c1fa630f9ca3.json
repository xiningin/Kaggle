{"cell_type":{"76a57015":"code","bfb77d3a":"code","5c6622be":"code","d27407d8":"code","c4886caf":"code","1a7e278c":"code","ad104768":"code","b04018ba":"code","a5fa4c5c":"code","8847d356":"code","0f71d098":"code","bb84b912":"code","66a63460":"code","f1f28386":"code","77c44cc5":"code","a2207d1a":"code","491eec5f":"code","5eb7d5b4":"code","aa56b09c":"code","19508da5":"code","e787afc0":"code","65826348":"code","ad169d3b":"code","54a5294d":"code","dc65a766":"code","8ed65ebd":"code","c92f0c93":"code","e98c78ee":"code","c396e4b6":"code","162a5f38":"code","e0ec648e":"code","4d44ba43":"code","0a55781e":"code","e63f3d35":"code","f471ca40":"code","dc6f2623":"code","e29ef9f3":"code","f5dd329d":"code","73bbd09d":"code","0d7ec693":"code","9a172658":"code","d0564d34":"code","af7fb02c":"code","9fdd7030":"code","6ba980a8":"code","4ac4c411":"code","78a56512":"code","5890ad5f":"code","7feab233":"code","37e24194":"code","03fe6e9e":"code","8deec6c2":"code","0006c337":"code","3226349b":"code","1ee4f452":"code","fa05f986":"code","4ea93aed":"code","c80b3b93":"code","636759ff":"code","07efb139":"code","43899f36":"code","aa8469ba":"code","f31c9c50":"code","a8e1c99a":"code","8ae43b9c":"code","d7743366":"code","5fc09925":"code","1ff7323f":"code","bdafa66c":"code","81aeeba1":"code","1e9cb594":"code","6feddbe6":"code","64d559dc":"code","ef7f0c6a":"code","4bc9b944":"code","b429a4a7":"code","a9b2e8a5":"code","f0e390ab":"code","ed859b93":"code","36871f03":"code","de083243":"code","76b9dc20":"code","024d9288":"code","f768a3c6":"code","a69f8235":"code","54342c2d":"code","b4e33c45":"code","d93b41b2":"code","6cfa3d31":"code","87dc557a":"code","dbd6e55e":"code","90c559f3":"code","94d86bc6":"code","a16c0167":"code","ba296f18":"code","19fd468b":"markdown","41d3e6e2":"markdown","cd889ed4":"markdown","190d8afb":"markdown","72a64699":"markdown","3f6dbb0d":"markdown","72b19c00":"markdown","1c6ec7e5":"markdown","f1f36bce":"markdown","40c67b27":"markdown","fdfb9849":"markdown","90102bad":"markdown","7e7c8298":"markdown","920dcfce":"markdown","9a75d66e":"markdown","6b1ea15f":"markdown","93e8b7b9":"markdown","f277430c":"markdown","e4f75c66":"markdown","733da6a8":"markdown","37542836":"markdown","588b4480":"markdown","e812b74f":"markdown","74dbd8b9":"markdown","f7a053a5":"markdown","29cd68f6":"markdown","8dd5c89d":"markdown","91743460":"markdown","45dbe383":"markdown","ec914742":"markdown","c2cfa47f":"markdown","0a493f99":"markdown","3552bbfc":"markdown","036fc73f":"markdown","db0e33af":"markdown","0d7d95d8":"markdown","96481a06":"markdown","4b4e2c97":"markdown","978f6502":"markdown","90e9d209":"markdown","59b3c063":"markdown","927859d7":"markdown","01571131":"markdown","e50f9f1c":"markdown","818ba7c0":"markdown","14c3008c":"markdown","b9e18f04":"markdown","1d684716":"markdown","5f754ce8":"markdown","db59f6ff":"markdown","e79127df":"markdown","531051dd":"markdown","c474a36f":"markdown","b4fac35c":"markdown","24231d60":"markdown","f27ed96d":"markdown","d580fcdd":"markdown","e731e63a":"markdown","c4371b06":"markdown","3b6d079b":"markdown","a1c676dd":"markdown","73dea6e3":"markdown","d1e262f5":"markdown","a5c2d904":"markdown","e926b781":"markdown","8f645307":"markdown","43c40238":"markdown","9f7efd0e":"markdown","09d17b4f":"markdown","980055d8":"markdown","38339a19":"markdown","3ae5e340":"markdown","6bef7cce":"markdown","e1258475":"markdown","8c0d712f":"markdown","072f4bf2":"markdown","3a75c077":"markdown","b9dfe2eb":"markdown","27eafdae":"markdown","aafcade5":"markdown","4f6fed15":"markdown","68e59a14":"markdown","2d7c7670":"markdown","55e9e0b2":"markdown","78a126c8":"markdown","6e9c6735":"markdown"},"source":{"76a57015":"!pip3 install comet_ml\n# Setting up experiments\nfrom comet_ml import Experiment\n\n# Linking to Comet\nexperiment = Experiment(api_key='tvx43aEjuXWoGnkxiQOaNjXD7',\n                       project_name='classification-predict',\n                       workspace='en2-jhb')","bfb77d3a":"# Data wrangling libraries\nimport pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport re\n\n# Data visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# NLP libraries\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import TweetTokenizer\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom spacy import load\nfrom textblob import TextBlob\n\n# Download NLTK Dependencies\n# nltk.download('stopwords')\n# nltk.download('vader_lexicon')\n\n# Load spacy\n# nlp = load('en_core_web_sm')\n\n# Feature Preprocessing\nfrom sklearn.utils import resample\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.pipeline import Pipeline\n\n# Models\nfrom sklearn.linear_model import LogisticRegression,LinearRegression, RidgeCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier,StackingClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\n\n# Evaluating Model Performance\nfrom sklearn.metrics import f1_score, recall_score, precision_score\n\n# Storing Models and Vectorizers\nimport pickle\n\n# Settings\nsns.set_style('whitegrid')\n%matplotlib inline","5c6622be":"# load the datasets\ntrain_data = pd.read_csv('..\/input\/climate-change-belief-analysis\/train.csv')\ntest_data = pd.read_csv('..\/input\/climate-change-belief-analysis\/test.csv')\nsample_data = pd.read_csv('..\/input\/climate-change-belief-analysis\/sample_submission.csv')\n\n# check the number of rows and columns of the data\nprint (f\"There are {train_data.shape[0]} rows and {train_data.shape[1]} columns in the training set.\")\nprint (f\"There are {test_data.shape[0]} rows and {test_data.shape[1]} columns in the test set.\")","d27407d8":"train_data.head(3)","c4886caf":"train_data.info()","1a7e278c":"# here is an example tweet selected randomly\ntweet = train_data.loc[771, 'message']\ntweet","ad104768":"count = 0\nfor i,s,m,tid in train_data.itertuples():\n    if type(m)==str:\n        if str(m).isspace():\n            count += 1\n\nprint (f\"There are {train_data['message'].isnull().sum()} missing values and {count} empty strings in the training set.\")","b04018ba":"# create dictionary of target number with their actual string\ntarget_map = {-1:'Anti', 0:'Neutral', 1:'Pro', 2:'News'}\n# create 'target' column\ntrain_data['target'] = train_data['sentiment'].map(target_map)","a5fa4c5c":"# Function to convert data types\ndef typeConvert(df):\n    \"\"\"\n    Return converted data-types of selected columns from dataframe.\n    \n    Parameters\n    ----------\n        df (DataFrame): input dataframe.\n        \n    Returns\n    -------\n        clean_df (DataFrame): output dataframe with new converted data types.\n        \n    Examples\n    --------\n    >>> traun_data.dtypes\n            \n            sentiment     int64\n            message      object\n            tweetid       int64\n            target       object\n            dtype: object\n            \n    >>> typeConvert(train_data).dtypes\n        \n            sentiment    category\n            message        object\n            tweetid         int16\n            target         object\n            dtype: object\n    \"\"\"\n    \n    if 'sentiment' in df.columns:\n        # convert 'sentiment' to category as data type\n        df['sentiment'] = df['sentiment'].astype('category')\n    # convert 'tweetid' to int16 as data type\n    df['tweetid'] = df['tweetid'].astype('int16')\n    # return new converted data type\n    return df\n\n# train_data = typeConvert(train_data)","8847d356":"# Function to extract urls\ndef findURLs(tweet):\n    \"\"\"\n    Return a string of an url from a tweet.\n    \n    Parameters\n    ----------\n        tweet (str): tweet containing an url.\n        \n    Returns\n    -------\n        extractedUrl(str): an url from a tweet.\n        \n    Examples\n    --------\n    >>> findURLs(\"This is my kaggle link, https:\/\/www.kaggle.com\/touch-hd\")\n        \n        \"https:\/\/www.kaggle.com\/touch-hd\"\n        \n    \"\"\"\n    # create string to extract an url\n    pattern = r'ht[t]?[p]?[s]?:\/\/(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n    # extract an url\n    extractedUrl = \" \".join(re.findall(pattern,tweet))\n    # return a string of an url\n    return extractedUrl\n\n# example implementation\nfindURLs(tweet)","0f71d098":"# finally implement the function in the train dataset\ntrain_data['urls'] = train_data['message'].map(findURLs)","bb84b912":"#Function to replace an url\ndef strip_url(df):\n    \"\"\"\n     Return removal of all urls from the DataFrame raw message and replaces them with \"urlweb\".\n    \n    Parameters\n    ----------\n        df (DataFrame): input dataframe.\n        \n    Returns\n    -------\n        clean_df (DataFrame): output dataframe with an \"urlweb\" string replacement to each url from raw message.\n        \n    Example\n    --------\n    >>> train_data[0]\n    \n        |index|sentiment|message|tweetid\n        |0    |-1       |https..|13442\n        \n    >>> strip_url(train_data[0])\n        \n        |index|sentiment|message|tweetid\n        |0    |-1       |urlweb |13442\n    \"\"\"\n    # copy the original DataFrame\n    clean_df = df.copy()\n    # create string to remove an url\n    pattern_url = r'http[s]?:\/\/(?:[A-Za-z]|[0-9]|[$-@.&+]|[!*(),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n    # create new string\n    subs_url = r'urlweb'\n    # replace an url with 'urlweb' string\n    clean_df['message'] = clean_df['message'].replace(to_replace = pattern_url, value = subs_url, regex = True)\n    return clean_df\n\n# transforming dataframe\ntrain_data = strip_url(train_data)","66a63460":"# show an example of a tweet\ntweet = train_data['message'][771]\ntweet","f1f28386":"# Function to extract twitter handles\ndef findHandles(tweet):\n    \"\"\"\n    Return a list of all handles from a tweet.\n     \n    Parameters\n    ----------\n         tweet (str): tweet containing handles.\n         \n    Returns\n    -------\n         handles (list): list of all handles.\n         \n    Examples\n    --------\n    >>> findHandles(\"hi @SenBernieSanders, you will beat @realDonaldTrump\")\n    \n        ['@SenBernieSanders','@realDonaldTrump']\n    \"\"\"\n    # create an empty list\n    handles = list()\n    for token in tweet.split():\n        if token.startswith('@'):\n            handles.append(token) # or .replace('@', '')\n    # return twitter handles from the tweet\n    return handles\n\n# example implementation\nfindHandles(tweet)","77c44cc5":"# finally implement the function across the training data\ntrain_data['handles'] = train_data['message'].map(findHandles)","a2207d1a":"# Function to extract hash-tags\ndef findHashTags(tweet):\n    \"\"\"\n     Return a list of all hashtags from a tweet.\n     \n     Parameters\n     ----------\n        tweet (str): text containing hashtags\n        \n     Returns\n     -------\n        hash_tags (list): list of all hashtags\n        \n     Examples\n     --------\n     >>> findHashTags(\"Oil is killing the world renewables and EVS are the \n                                way the go! #EVs #GlobalWarming #Fossilfuels\")\n                                \n         ['#EVs', '#GlobalWarming', '#Fossilfuels']\n     \"\"\"\n    # create an empty list\n    hash_tags = list()\n    for token in tweet.split():\n        if token.startswith('#'):\n            hash_tags.append(token)\n    # return hash-tags from the tweet\n    return hash_tags\n\n# example implementation\nfindHashTags(tweet)","491eec5f":"# finally implement the function across the training data\ntrain_data['hash_tags'] = train_data['message'].map(findHashTags)","5eb7d5b4":"train_data.head(3)","aa56b09c":"train_data.info()","19508da5":"# for interest sake we print out the example tweet again\ntweet","e787afc0":"# Function to remove punctuation\ndef removePunctuation(tweet):\n    \"\"\"\n    Return the removal of punctuation and other uncommon characters in the tweet.\n    \n    Parameters\n    ----------\n        tweet (str): string containing punctuation to be removed.\n        \n    Returns\n    -------\n        clean_tweet (str): string without punctuation.\n        \n    Examples\n    --------\n    >>> removePunctuation(\"Hey! Check out this story: urlweb. He doesn't seem impressed. :)\")\n            \n        \"Hey Check out this story urlweb He doesn't seem impressed\"\n    \"\"\"    \n    # first remove line spaces\n    clean_tweet = tweet.replace('\\n', ' ')\n    \n    # substitute digits within text with an empty strring\n    clean_tweet = re.sub('\\w*\\d\\w*', ' ', clean_tweet)\n    \n    # remove punctuation\n    # some of the character removed here were determined by visually inspecting the text\n    clean_tweet = re.sub(r'[:;.,_()\/\\{}\"?\\!&\u00ac\u00a6\u00e3\u00c3\u00e2\u00c2\u00a2\\d]', '', clean_tweet) \n    \n    # return cleaner tweet\n    return clean_tweet\n\n# example implementation\ntweet = removePunctuation(tweet)\ntweet","65826348":"# finally implement the function across the training data\ntrain_data['tweets'] = train_data['message'].map(removePunctuation)","ad169d3b":"# Function to generate tweet tokenization\ndef tweetTokenizer(tweet):\n    \"\"\"\n    This method tokenizes and strips handles from twitter data.\n    \n    Parameters\n    ----------\n        tweet (str): string to be tokenized.\n    Returns\n    -------\n        tokenized_tweet (list): list of tokens in tweet.\n    Examples\n    --------\n    >>> tweetTokenizer(\"Read @swrightwestoz's latest on climate change insurance amp lending \n                                       featuring APRA speech and @CentrePolicyDev work urlweb\")\n    \n        ['read',\n        'latest',\n        'on',\n        'climate',\n        'change',\n        'insurance',\n        'amp',\n        'lending',\n        'featuring',\n        'apra',\n        'speech',\n        'and',\n        'work',\n        'urlweb']\n    \"\"\"\n    tokenizer = TweetTokenizer(preserve_case = False, strip_handles = True)\n    tokenized_tweet = tokenizer.tokenize(tweet)\n    return tokenized_tweet\n\n# example implementation\ntokenized_tweet = tweetTokenizer(tweet)\ntokenized_tweet","54a5294d":"# finally implement the function across the training data\ntrain_data['tweets'] = train_data['tweets'].map(tweetTokenizer)","dc65a766":"# Function to remove stop words\ndef removeStopWords(tokenized_tweet):\n    \"\"\"\n    This method removes stop words and punctuation relics.\n    \n    Parameters\n    ----------\n        tokenized_tweet (list): list of tokens to be cleaned.\n        \n    Returns\n    -------\n        clean_tweet (list): list of tokens without stopwords.\n        \n    Examples\n    --------\n    >>> removeStopWords(['read',\n                        'latest',\n                        'on',\n                        'climate',\n                        'change',\n                        'insurance',\n                        'amp',\n                        'lending',\n                        'featuring',\n                        'apra',\n                        'speech',\n                        'and',\n                        'work',\n                        'urlweb'])\n                        \n        ['read',\n        'latest',\n        'on',\n        'climate',\n        'change',\n        'insurance',\n        'amp',\n        'lending',\n        'featuring',\n        'apra',\n        'speech',\n        'and',\n        'work',\n        'urlweb']\n    \"\"\"\n    # initialising an empty list as container for the cleaned tweet\n    clean_tweet = list()\n    # iterating through all words in a list\n    for token in tokenized_tweet:\n        # checking if current word is not a stopword # also checking if the current word is a hash_tag # also checking if the current word has more than one character\n        if token not in stopwords.words('english') + ['amp','rt'] and token.startswith('#') == False and len(token) > 1:\n            clean_tweet.append(token)            \n    # return the cleaner tweet\n    return clean_tweet\n\n# example implementation\nclean_tweet = removeStopWords(tokenized_tweet)\nclean_tweet","8ed65ebd":"# finally implement the function across the training data\ntrain_data['tweets'] = train_data['tweets'].map(removeStopWords)","c92f0c93":"# Function to generate tweet lemmatization\ndef lemmatizeTweet(tweet):\n    \"\"\"\n    Return tweet lemmatizer.\n    \n    Parameters\n    ----------\n        tweet (list): tokens to be lemmatized.\n        \n    Returns\n    -------\n        lemmatized_tweet (list): lemmatized list of tokens.\n        \n    Examples\n    --------\n    >>> lemmatizeTweet(['read',\n                        'latest',\n                        'on',\n                        'climate',\n                        'change',\n                        'insurance',\n                        'amp',\n                        'lending',\n                        'featuring',\n                        'apra',\n                        'speech',\n                        'and',\n                        'work',\n                        'urlweb'])\n                        \n        ['read',\n        'latest',\n        'climate',\n        'change',\n        'insurance',\n        'lending',\n        'featuring',\n        'apra',\n        'speech',\n        'work',\n        'urlweb']\n    \"\"\"\n    lemmatized_tweet = list()\n    lmtzr = WordNetLemmatizer()\n    for token in tweet:\n        lemmatized_tweet.append(lmtzr.lemmatize(token))\n    return lemmatized_tweet\n\n# example implementation\nlemmatized_tweet = lemmatizeTweet(clean_tweet)\nlemmatized_tweet","e98c78ee":"# finally implement the function across the training data\ntrain_data['tweets'] = train_data['tweets'].map(lemmatizeTweet)","c396e4b6":"# check the dataframe\ntrain_data.head(3)","162a5f38":"# Function to generate vocabulary\ndef getVocab(df):\n    \"\"\"\n    Return a list of vocabulary from 'tweets' column in dataframe.\n    \n    Parameters\n    ----------\n        df (DataFrame): input dataframe.\n        \n    Returns\n    -------\n        vocab (list): list of all words that occur atleast once in the tweets.\n        \n    Examples\n    --------\n    >>> df['tweets']\n     \n    0   ['terror', 'major']\n    1   ['yes', 'taken']\n    \n    >>> getVocab(df['tweets'])\n        \n        ['terror',\n         'major',\n         'yes',\n         'taken']\n    \"\"\"\n    # create an empty list\n    vocab = list()\n    for tweet in df:\n        for token in tweet:\n            vocab.append(token)\n    # return giant list of vocab\n    return vocab","e0ec648e":"#  example implementation\nvocab = getVocab(df = train_data['tweets'])","4d44ba43":"# check length and count unique words\nlen(vocab), pd.Series(vocab).nunique()","0a55781e":"word_frequency_dict = {}\nfor label in train_data['target'].unique():\n    data = train_data[train_data['target'] == label]\n    class_vocab = getVocab(data['tweets'])\n    length_of_vocab = len(class_vocab)\n    ordered_class_words = Counter(class_vocab).most_common()\n    ordered_class_words_freq = list()\n    for paired_tuple in ordered_class_words:\n        word, count = paired_tuple\n        word_frequency = round((count \/ length_of_vocab) * 100, 3)\n        ordered_class_words_freq.append((word, word_frequency))\n        word_frequency_dict[label] = ordered_class_words_freq\n        \nword_frequency_dict['Anti'][-5:]","e63f3d35":"fig, axes = plt.subplots(1, 4, figsize = (16, 5))\nfor i, label in enumerate(train_data['target'].unique()):\n    data = pd.DataFrame(word_frequency_dict[label])[1]\n    g = sns.distplot(data, ax = axes[i])\n    g.set_title(label)\n    g.set_xlabel('Percentage (%)')\n    if label == 'Pro':\n        g.set_ylabel('Frequency')\n    g.set_xlim(0, 1) # comment this\n    g.set_ylim(0, 1) # comment this","f471ca40":"frequency_threshold = 0.01\nclass_words = {}\nfor label, value in word_frequency_dict.items():\n    words = list()\n    for paired_tuple in value:\n        word, freq = paired_tuple\n        if freq > frequency_threshold:\n            words.append(word)\n    class_words[label] = words\n    \nclass_words['News'][:5]","dc6f2623":"pro_spec_words = list(set(class_words['Pro']) - set(class_words['Neutral']).union(set(class_words['Anti'])).union(set(class_words['News'])))\nneutral_spec_words = list(set(class_words['Neutral']) - set(class_words['Pro']).union(set(class_words['Anti'])).union(set(class_words['News'])))\nanti_spec_words = list(set(class_words['Anti']) - set(class_words['Pro']).union(set(class_words['Neutral'])).union(set(class_words['News'])))\nnews_spec_words = list(set(class_words['News']) - set(class_words['Pro']).union(set(class_words['Neutral'])).union(set(class_words['Anti'])))\n\nlabel_specific_words = dict(\n    Pro = pro_spec_words, Neutral = neutral_spec_words, Anti = anti_spec_words, News = news_spec_words\n    )\nlabel_specific_words['Pro'][:5]","e29ef9f3":"print(f\" Pro: {len(pro_spec_words):{10}} \\n Neutral: {len(neutral_spec_words):{6}} \\n Anti: {len(anti_spec_words):{8}} \\n News: {len(news_spec_words):{9}}\")","f5dd329d":"class_specific_words = pro_spec_words + neutral_spec_words + anti_spec_words + news_spec_words\nclass_specific_words[:5], len(class_specific_words)","73bbd09d":"# example implementation\nordered_words = Counter(vocab).most_common()\nordered_words[:5]","0d7ec693":"# Note, we set default n = 5000\n# function to generate the top N of words\ndef topNWords(ordered_words, n = 5000):\n    \"\"\"\n    \n    \n    Parameters\n    ----------\n        ordered_words (): input dataframe.\n        n (int):\n        \n    Returns\n    -------\n        most_common (list): list of all words that occur atleast once in the tweets.\n        \n    Examples\n    --------\n        \n    \"\"\"\n    most_common = list()\n    for word in ordered_words[:n]:\n        most_common.append(word[0])\n    return most_common\n\n# implementing the function\ntop_n_words = topNWords(ordered_words)\ntop_n_words[:5]","9a172658":"with open(\"topnwords.txt\", \"w\") as output:\n    output.write(str(top_n_words))","d0564d34":"# show the count of uniques\npd.Series(top_n_words).nunique()","af7fb02c":"tweet","9fdd7030":"def removeInfrequentWords(tweet, include):\n    \"\"\"\n    This function goes through the words in a tweet,\n    determines if there are any words that are not in\n    the top n words and removes them from the tweet\n    and return the filtered tweet.\n    \n    Parameters\n    ----------\n        tweet (list): list tokens to be flitered.\n        top_n_words (int): number of tweets to keep.\n        \n    Returns\n    -------\n        filt_tweet (list): list of top n words.\n        \n    Examples\n    --------\n    >>> bag_of_words = [('change', 12634),\n                        ('climate', 12609),\n                        ('rt', 9720),\n                        ('urlweb', 9656),\n                        ('global', 3773)]\n                        \n    >>> removeInfrequentWords(['rt', 'climate', 'change', 'equation', 'screenshots', 'urlweb'],2)\n    \n        ['change', 'climate']    \n    \"\"\"\n    \n    filt_tweet = list()\n    for token in tweet:\n        if token in include:\n            filt_tweet.append(token)\n    return filt_tweet","6ba980a8":"# finally implement the function across the training data\ntrain_data['tweets_clean'] = train_data['tweets'].map(lambda tweet: removeInfrequentWords(tweet, include = top_n_words + class_specific_words))","4ac4c411":"all_vocab = list()\nfor tweet in train_data['tweets_clean']:\n    for token in tweet:\n        all_vocab.append(token)\npd.Series(all_vocab).nunique()","78a56512":"train_data.head(2)","5890ad5f":"very_common_words = topNWords(ordered_words, n = 20)\nvery_common_words[:5]","7feab233":"def removeCommonWords(tweet):\n    \"\"\"\n    This method removes the most common words from a list of given words.\n    \n    Parameters\n    ----------\n        tweet (list): list of words to be cleaned.\n        \n    Returns\n    -------\n        filt_tweet (list): list of cleaned words.\n        \n    Examples\n    --------\n    >>> very_common_words = ['change', 'climate', 'rt', 'urlweb', 'global']\n    \n    >>> removeCommonWords(['rt', 'climate', 'change', 'equation', 'screenshots', 'urlweb'])\n        \n        ['equation']\n    \"\"\"\n    filt_tweet = list()\n    for token in tweet:\n        if token not in very_common_words:\n            filt_tweet.append(token)\n    return filt_tweet\n\n# example implementation\n# print(filtered_tweet)\n# print(removeCommonWords(filtered_tweet))","37e24194":"# finally implement the function across the training data\ntrain_data['tweets_clean'] = train_data['tweets_clean'].map(removeCommonWords)","03fe6e9e":"train_data.head(3)","8deec6c2":"def lengthOfTweet(tweet):\n    \"\"\"\n    Return the length of each tweet in the dataframe.\n    \n    Parameters\n    ----------\n        tweet (list): list of a tweet.\n        \n    Returns\n    -------\n        length (int): length of each tweet.\n    \n    \"\"\"\n    length = len(tweet)\n    return length\n\n# example implementation\nlengthOfTweet(tweet)","0006c337":"# implement the function across the dataset and save the results in a column\ntrain_data['len_of_tweet'] = train_data['tweets_clean'].map(lengthOfTweet)\n\n# plot a distribution of the tweet lengths\nsns.distplot(train_data['len_of_tweet'])\nplt.show()","3226349b":"len(train_data[train_data['len_of_tweet'] == 0])","1ee4f452":"# plotting counter-plots\nsns.countplot(data = train_data, x = 'target', palette = {'Pro':'#CCCC00', 'News':'teal', 'Neutral':'teal', 'Anti':'teal'})\nplt.title('Count of Sentiments\\n')\nplt.xlabel('\\nSentiment')\nplt.ylabel('Count\\n')\nplt.show()","fa05f986":"tweet = train_data.loc[0, 'tweets_clean']\ntweet","4ea93aed":"# function for generating word cloud\ndef plotWordCloud(data, label, text_col = 'tweets_clean'):\n    \"\"\"\n    the plot of the most common use of words that appear bigger than words that\n    appear infrequent in a text document by each sentiment\n    \n    Parameters\n    ----------\n        data (DataFrame): input of dataframe\n        label (int): sentiment variable from dataframe\n        \n    Returns\n    -------\n        fig (matplotlib.figure.Figure): Final plot to be displayed\n    \n    \"\"\"\n    words = list()\n    for tweet in data[text_col]:\n        for token in tweet:\n            words.append(token)\n    words = ' '.join(words)\n\n    from wordcloud import WordCloud\n    wordcloud = WordCloud(contour_width=3, contour_color='steelblue').generate(words)\n\n    # Display the generated image:\n    fig = plt.figure(figsize = (10, 6))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.title(label, fontsize = 30)\n    plt.axis(\"off\")\n    plt.margins(x=0, y=0)\n    plt.show()","c80b3b93":"# plotting word cloud for 'Pro' as target\ndata = train_data[train_data['target'] == 'Pro']\nplotWordCloud(data, label = 'Sentiment = Pro')","636759ff":"# plotting word cloud for 'Anti' as target\ndata = train_data[train_data['target'] == 'Anti']\nplotWordCloud(data, label = 'Target = Anti')","07efb139":"# plotting word cloud for 'Neutral' as target\ndata = train_data[train_data['target'] == 'Neutral']\nplotWordCloud(data, label = 'Target = Neutral')","43899f36":"# plotting word cloud for 'News' as target\ndata = train_data[train_data['target'] == 'News']\nplotWordCloud(data, label = 'Target = News')","aa8469ba":"def getPolarityScores(tweet):\n    \"\"\"\n    return the polarity score of each tweet in the dataset\n    \n    Parameters\n    ----------\n        tweet (list): list of a tweet\n    Returns\n    -------\n        scores (dict): dictionary of polarity scores\n    \n    \"\"\"\n    tweet = ' '.join(tweet)\n    # analyse the sentiment\n    sid = SentimentIntensityAnalyzer()\n    # get polarity score of each data\n    scores = sid.polarity_scores(tweet) \n    # return the polarity scores\n    return scores\n\n\n# example implementation\nprint(tweet)\ngetPolarityScores(tweet)","f31c9c50":"# implement the function across the dataset\nnltk_scores = dict(compound = list(), negative = list(), neutral = list(), positive = list())\nfor tweet in train_data['tweets_clean']:\n    output = getPolarityScores(tweet)\n    nltk_scores['compound'].append(output['compound'])\n    nltk_scores['negative'].append(output['neg'])\n    nltk_scores['neutral'].append(output['neu'])\n    nltk_scores['positive'].append(output['pos'])\n    \n# concatenate the output from above into the main dataset\nif 'compound' in train_data.columns:\n    \n    # drop the columns if this has been executed before\n    train_data.drop(['compound', 'negative', 'neutral', 'positive'], axis = 1, inplace = True)\n    \n    # concatenate a DataFrame version of the nltk_scores dictionary\n    train_data = pd.concat([train_data, pd.DataFrame(nltk_scores)], axis = 1)\nelse:\n    # concatenate directly if this is the first execution\n    train_data = pd.concat([train_data, pd.DataFrame(nltk_scores)], axis = 1)","a8e1c99a":"train_data.head(3)","8ae43b9c":"sentiment_scores = [TextBlob(' '.join(tweet)).sentiment for tweet in train_data['tweets_clean']]\n\n# Add output to dataframe\npol = list()\nsubj = list()\nfor scores in sentiment_scores:\n    pol.append(scores.polarity)\n    subj.append(scores.subjectivity)\n\ntrain_data['polarity'] = pol\ntrain_data['subjectivity'] = subj","d7743366":"train_data.head(2)","5fc09925":"# summary statistics\ntrain_data[['compound', 'polarity', 'subjectivity']].describe()","1ff7323f":"# plotting violin-plots\nfig, axes = plt.subplots(1, 3, figsize = (18, 5))\nfor i, column in enumerate(['compound', 'polarity', 'subjectivity']):\n    g = sns.violinplot(data = train_data, x = 'target', y = column, ax = axes[i], palette = {'Pro':'#CCCC00', 'News':'teal', 'Neutral':'teal', 'Anti':'teal'})\n    g.set_title(column)\n    if column == \"compound\":\n        g.set_ylabel('Scores')\n    else:\n        g.set_ylabel(' ')\n    g.set_xlabel(' ')","bdafa66c":"data = train_data.groupby('target')[['negative', 'positive', 'neutral', 'compound', 'polarity', 'subjectivity']].mean().reset_index()\ndata","81aeeba1":"# function for generating scatter-plot\ndef plotScatter(x, y, df, title):\n    \"\"\"\n    display the scatter plot\n    \n    Parameters\n    ----------\n        x (str): variable string from dataframe\n        y (str): variable string from dataframe\n        df (DataFrame): input of dataframe\n        \n    Returns\n    -------\n        g (plot): display a scatter plot with points of each labelled sentiments\n    \n    \"\"\"\n    fig = plt.figure(figsize = (8, 5))\n    g = sns.scatterplot(data = df, x = x, y = y, hue = 'target', legend = False, palette = {'Pro':'#CCCC00', 'News':'teal', 'Neutral':'teal', 'Anti':'teal'})\n    g.set_title(title, fontsize = 20)\n    \n    # add annotations one by one with a loop\n    for line in range(0,data.shape[0]):\n        g.text(data[x][line], data[y][line], data['target'][line], \n                horizontalalignment='left', size='large', color='black')\n    \n    return g","1e9cb594":"# plotting scatter-plot\nplotScatter(x = 'compound', y = 'polarity', df = data, title = 'Compound Vs Polarity\\n')\nplt.xlabel('\\nCompound Score')\nplt.ylabel('Polarity\\n')\nplt.show()","6feddbe6":"# plotting scatter-plot\nfig = plt.figure(figsize = (8, 5))\ng = sns.scatterplot(data = train_data, x = 'subjectivity', y = 'polarity', color = 'teal', hue = 'target', alpha = 1\/3)\ng.arrow(0, 0.1, 0.99, 1, fc = 'black', ec = '#CCCC00')\ng.arrow(0, 0.1, 0.99, -1, fc = 'black', ec = '#CCCC00')\nplt.title('Subjectiviy vs Polarity\\n')\nplt.xlabel('\\nSubjectivity')\nplt.ylabel('Polarity')\nplt.show()","64d559dc":"number_of_handles_per_tweet = train_data['handles'].map(lengthOfTweet)\nfig = plt.figure(figsize = (8, 5))\nnumber_of_handles_per_tweet.value_counts().plot(kind = 'barh', color = 'teal')\nplt.title('Number of Handles in tweets\\n ', fontsize = 16)","ef7f0c6a":"# plotting word cloud for 'News' as target\ndata = train_data[train_data['target'] == 'Pro']\nplotWordCloud(data, label = 'Handles \\n Pro \\n', text_col = 'handles')","4bc9b944":"# plotting word cloud for 'News' as target\ndata = train_data[train_data['target'] == 'Anti']\nplotWordCloud(data, label = 'Handles \\n Anti \\n', text_col = 'handles')","b429a4a7":"# plotting word cloud for 'News' as target\ndata = train_data[train_data['target'] == 'Neutral']\nplotWordCloud(data, label = 'Handles \\n Neutral \\n', text_col = 'handles')","a9b2e8a5":"# plotting word cloud for 'News' as target\ndata = train_data[train_data['target'] == 'News']\nplotWordCloud(data, label = 'Handles \\n News \\n', text_col = 'handles')","f0e390ab":"#plotting word cloud\nlower = -0.15\ninterval = 0.3\ndata = train_data[(train_data['compound'] < lower+interval) & (train_data['compound'] > lower)]\nplotWordCloud(data, label = f'Neutral where: {lower} < Compound < {lower+interval}')","ed859b93":"number_of_handles_per_tweet = train_data['hash_tags'].map(lengthOfTweet)\nfig = plt.figure(figsize = (8, 5))\nnumber_of_handles_per_tweet.value_counts().plot(kind = 'barh', color = 'teal')\nplt.title('Number of HashTags in tweets\\n ', fontsize = 16)","36871f03":"# plotting word cloud\nlower = -0.8\ndata = train_data[train_data['compound'] < lower]\nplotWordCloud(data, label = f'compound < {lower}')","de083243":"# plotting word cloud\nupper = 0.6\nsent = 0\ndata = train_data[(train_data['sentiment']==sent)&(train_data['compound'] > upper)]\nplotWordCloud(data, label = f'compound > {upper}')","76b9dc20":"# Setting the random_state to reproduce the same results\nrs = 42\n\n#Creating data subsets\npos = train_data[train_data['sentiment']==1]\nneg = train_data[train_data['sentiment']==-1]\nneu = train_data[train_data['sentiment']==0]\nnews = train_data[train_data['sentiment']==2]\n\n# Class size\nfrac = 100\nsize = int(len(pos)* frac\/100)\n\n# Resampling\nneg_upsampled = resample(neg,\n\n                          replace=True, # sample with replacement (need to duplicate observations)\n                          n_samples=size, # match number in half of majority class\n                          random_state=rs) # reproducible results\n\nnews_upsampled = resample(news,\n                          replace=True, # sample with replacement (need to duplicate observations)\n                          n_samples=size, # match number in half of majority class\n                          random_state=rs) # reproducible results\n\nneu_upsampled = resample(neu,\n                          replace=True, # sample with replacement (need to duplicate observations)\n                          n_samples=size, # match number in half of majority class\n                          random_state=rs) # reproducible results\n\npos_downsampled = resample(pos,\n                          replace=False, # sample without replacement (no need to duplicate observations)\n                          n_samples=size, # match number in half of majority class\n                          random_state=rs) # reproducible results\n\nsampled = pd.concat([neg_upsampled, news_upsampled, neu_upsampled, pos_downsampled])\n\n# Display new class counts\n\nsns.countplot(data = train_data, x = 'target', palette = 'gray')\nsns.countplot(data = sampled, x = 'target', palette = \"Blues\", alpha=0.5)\nplt.title('Count of Sentiments\\n')\nplt.xlabel('\\nSentiment')\nplt.ylabel('Count\\n')\nplt.show()","024d9288":"#consider also using 'compound' column\nX = sampled['tweets_clean'].apply(lambda x:' '.join(x))\ny = sampled['sentiment']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=rs)","f768a3c6":"def best_classifier(param_search,vectoriser, cv_folds=2):\n\n    \"\"\"\n    Return a dataframe including, and ranking, the weighted f1 scores\n    of the classifiers (from input), using the best parameters \n    (from GridSearch performed on input parameters) after being run through\n    a pipeline with the input vectoriser.\n\n    Creates a dictionary in the form:\n    {'name of classifier':'classifier with best parameters'}\n\n    Parameters:\n    param_search -- a list of tuples, in the form\n                  [(name of classifier,classifier,param_grid)]\n    vectoriser -- word vectoriser\n    \"\"\"\n\n  # Creates empty dictionary to store classifier with best parameters\n    class_dict = {}\n  # New list to append information from classifer gridsearch\n    results = []\n\n  # Gridsearching each classifier in provided list\n    for i in param_search:\n        pipe = Pipeline([('vectorizer', vectoriser),\n                         ('classifier', i[1])])\n    \n        grid = GridSearchCV(pipe,i[2],scoring='f1_weighted',n_jobs=-1, cv=cv_folds)\n        grid.fit(X_train,y_train)\n\n  # Making prediction on test set data using classifier fitted with best parameters\n        y_pred = grid.best_estimator_.predict(X_test)\n  \n  # Appending tuple of information gained from grid search to results list\n        results.append([i[0],f1_score(y_test,y_pred, average='weighted'),\n                        grid.best_params_])\n        \n# Converting name string for naming file\n        key = i[0].lower().replace(' ','_')\n  # Adding classifier, loaded with best parameters, to dictionary   \n        class_dict[key] = [grid.best_estimator_,\n                            f1_score(y_test,y_pred, average='weighted')]\n\n  # Creating dataframe to display sorted f1_scores\n    results = pd.DataFrame(results, columns=['classifier','f1_score',\n                                         'best_params'])\n    results.set_index(['classifier'], inplace=True)\n    results = results.sort_values('f1_score', ascending=False)\n    return class_dict, results","a69f8235":"# Instantiate a vectorizer\nvectoriser = TfidfVectorizer()\n\n# Name all of the classifiers\nnames = ['Logistic Regression',\n         'Nearest Neighbors',\n         'AdaBoost',\n         'Naive Bayes',\n         'Decision Tree', \n         'Support Vector'\n        ]\n\n# Instatiate the classifiers\nclassifiers = [LogisticRegression(),\n               KNeighborsClassifier(),\n               AdaBoostClassifier(),\n               MultinomialNB(),\n               DecisionTreeClassifier(),\n               SVC()\n               ]\n\n# List model parameters\nparams = [{'classifier__C':[0.001, 0.01, 0.1, 1, 10],\n           'classifier__solver':['liblinear','sag','saga','lbfgs'],\n           'classifier__max_iter':[500, 1000]},\n          {'classifier__n_neighbors':[1, 5, 10],\n           'classifier__weights':['uniform','distance'],\n           'classifier__algorithm':['auto', 'brute']},\n          {'classifier__n_estimators':[50, 100, 500, 1000],\n           'classifier__algorithm':['SAMME','SAMME.R']},\n          {'classifier__alpha':[0.01,0.5,1],\n           'classifier__fit_prior':[True, False]},\n          {'classifier__criterion':[\"gini\", \"entropy\"],\n           'classifier__splitter':['best','random']},\n          {'classifier__C':[0.1, 1, 10],\n           'classifier__kernel':['poly', 'rbf', 'sigmoid'],\n           'classifier__gamma':[0.1, 1]}\n         ]","54342c2d":"class_dict, results = best_classifier(zip(names,classifiers,params),vectoriser)\nresults","b4e33c45":"# Sort dictiionary by weighted f1_score and convert to list\nsub_comet = sorted(class_dict.items(), key=lambda x:x[1][1], reverse=True)\n\n# Select 3 best performing pipelines\nmodels = []\nfor terms in sub_comet[:3]:\n    models.append((terms[0],terms[1][0]['classifier']))\n\n    \n    \n# Initialise meta learner\nmeta_learner_reg = DecisionTreeClassifier()\n\n# Initialise stacking classifier\ns_reg = StackingClassifier(estimators=models, \n                          final_estimator=meta_learner_reg\n                          )\n\n# Train stacking classifier\ns_reg.fit(vectoriser.fit_transform(X_train), y_train)\n\n# Stacking classifier prediction and performance\nstack_y_pred = s_reg.predict(vectoriser.transform(X_test))\nf1_score(y_test,stack_y_pred, average='weighted')","d93b41b2":"class_dict['stacking_regressor'] = [Pipeline(steps=[('vectorizer', vectoriser),\n                                                    ('classifier', s_reg)]),\n                                   f1_score(y_test,stack_y_pred, average='weighted')]","6cfa3d31":"\n# Submit the parameters and metrics of the best performing model\n\n# Submitting all experiments' metrics and parameters to comet\n\nfor name, ppl in class_dict.items():\n    y_pred = ppl[0].predict(X_test)\n    f1 = f1_score(y_test,y_pred, average='weighted')\n    precision = precision_score(y_test, y_pred, average='weighted')\n    recall = recall_score(y_test, y_pred, average='weighted')\n    \n# Storing metrics\n    metrics = {'f1':f1,\n               'recall':recall,\n               'precision':precision}\n    \n# Storing paramerters\n    params = {\"random_state\":rs,\n              \"model_type\":name,\n              \"param_grid\":ppl[0].get_params()}  \n    \n    experiment.log_metrics(metrics)\n    experiment.log_parameters(params)\n    \n    \nexperiment.end()\nexperiment.display()","87dc557a":"for name, classifier in class_dict.items():\n# Saving models with best parametres for use in streamlit app\n    model_save_path = f\"{name}.pkl\"\n    with open(model_save_path, 'wb') as file:\n        pickle.dump(classifier[0],file)","dbd6e55e":"test_data = test_data.copy()\ntest_data = typeConvert(test_data[['message', 'tweetid']])\ntest_data = strip_url(test_data)\ntest_data['tweets'] = test_data['message'].map(removePunctuation)\ntest_data['tweets'] = test_data['tweets'].map(tweetTokenizer)\ntest_data['tweets'] = test_data['tweets'].map(removeStopWords)\ntest_data['tweets'] = test_data['tweets'].map(lemmatizeTweet)\ntest_data['tweets_clean'] = test_data['tweets'].map(lambda tweet: removeInfrequentWords(tweet, include = top_n_words + class_specific_words))\ntest_data['tweets_clean'] = test_data['tweets_clean'].map(removeCommonWords)\n\ntest_data.head()","90c559f3":"X_sub = test_data['tweets_clean'].apply(lambda x:' '.join(x))\n\nsub_classifier = sorted(class_dict.items(), key=lambda x:x[1][1], reverse=True)\nsub_classifier = sub_classifier[0]\nsub_classifier = sub_classifier[1][0]\n\nsample_data['sentiment'] = sub_classifier.predict(X_sub)\nsample_data.set_index('tweetid', inplace=True)\n\nsample_data.to_csv('submission.csv')\n\nsample_data.head()","94d86bc6":"# Install required libraries\n!pip install --upgrade pip\n!pip install kaggle --upgrade","a16c0167":"%mkdir --parents \/root\/.kaggle\/\n%cp \/kaggle\/input\/kaggle-token\/kaggle.json   \/root\/.kaggle\/\n!chmod 600 \/root\/.kaggle\/kaggle.json","ba296f18":"!kaggle competitions submit -c climate-change-belief-analysis -f submission.csv -m \"new submission\"","19fd468b":"### Text analysis\nNow we dig a little bit further into the data through use of visualisations and other statistical techniques.","41d3e6e2":"Similarly, we write another function that extracts hashtags from the tweet.","cd889ed4":"Now tokenize the tweet using NLTK's TweetTokenizer class. This class was designed specifically for twitter data. As such in addition to allowing us to lower case the tokenized tweets it also allows us to removed handles by setting the argument strip_handles to True. Remember we can remove these because we have them stored in a separate column anyway. See example implementation for the expected output.","190d8afb":"## Data Definitions <a class=\"anchor\" id=\"fourth-bullet\"><\/a>\n[back to top](#contents-bullet)\n\n### Description\nThe collection of this data was funded by a Canada Foundation for Innovation JELF Grant to Chris Bauch, University of Waterloo.\n\nThis dataset aggregates tweets pertaining to climate change collected between Apr 27, 2015 and Feb 21, 2018. In total, 43943 tweets were annotated. Each tweet is labelled independently by 3 reviewers. This dataset only contains tweets that all 3 reviewers agreed on (the rest were discarded).\n\n### Data types\n\n**Categorical**\n- *sentiment*: (Target) Sentiment of tweet labeled `-1`,`0`,`1`, and`2` representing `'Anti'`,`'Neutral'`,`'Pro'`, and`'News'` respectively.\n\n**Numeric**\n- *tweetid*:  Unique tweet id\n\n**Unstructured**\n - *message*: Tweet body used for training\n\n","72a64699":"Note that single character words such as \"s\" and \"'\" will also need to be removed. We do that in the following task.","3f6dbb0d":"Here we write a user function that finds url like strings in the tweets and extracts them.","72b19c00":"This group seems to talk about \"penguins\", \"clubs\". They share words like \"right\", \"year\", \"know\" with the other sentiment groups. They dont really talk about much. Lets see the news articles","1c6ec7e5":"### Contributors\n\n- Ebrahim Noormahomed - Supervisor\n- Zanele Gwamanda\n- Stanley Machuene Kobo\n- Rirhandzu Mahlaule\n- Kgaogelo Mamadi\n- Bulelani Nkosi\n- Titus Ndondo\n","f1f36bce":"[back to top](#contents-bullet)","40c67b27":"Generally, this group speaks words like \"die\", \"fight\", \"husband\", \"help\" etc. Maybe they are scared they will die. They intend to \"fight\" climate change. Note that they also talk about elections and presidents, maybe they want to be careful when voting for presidents and vote for the candidate that has intentions to fight climate change. See, we can already assume the kinds of statements this group makes just by looking at a wordcloud. They also talk abount \"science\", \"action\", maybe they are encouraging that leaders such as presidents should take action. Now let us take a look at the \"Anti\" group, the non-believers.","fdfb9849":"**task: plot wordclouds for the different sentiment classes**\nA word cloud is essentially a clouds of words. Words that are common will appear bigger than words that appear infrequently in a text document. Lets just go ahead and implement the technique, it will get clear after an illustration. In the code cell below we utilise a python library \"wordclod\" to generate the words clouds.","90102bad":"### Train Test Split","7e7c8298":"###### task: get TextBlob polarity and subjectivity scores\nAs mentioined above, textblob will give us a unique set of scores for measuring subjectivity. It also provides what the call polarity scores, that measure sentiments similar to the way NLTK's compound does, although these may differ. See the example below for how textblob works. First we convert a string of text into a blob. The resukting blob has certain attributes and methods it can perform. One of the is computing sentiment scores for subjectivity and polarity by simply averaging the individual sentiment of the words i a string of text. For example \"I love the juice\" below is said to be a subjective statement. It also ranks high on polarity, it is a positive statement after all.","920dcfce":"### Saving Models as .pkl Files","9a75d66e":"News articles are generally about politics and current events - Not surprising. Donald Trump is likely mentioned for his anti-climate change beliefs. Scott Pruitt is mentioned as he is the administrator of the Environmental Protection Agency and has been tearing down Obama-era environmental protection policies. China is likely mentioned the most as the largest contributor to greenhouse gas emmisions.","6b1ea15f":"[back to top](#contents-bullet)","93e8b7b9":"To identify infrequently occuring words, we start of by ordering the words in our vocabulary by frequency, similar to the way we orderd them in the previous task per class. Luckily we already have a giant list with our vocabulary from an earlier task. So we utilise a python package known as Collections (already imported above). The package has a useful function \"Counter\". Takes as input a list of words, counts their occurance and returns an object with a method \"most_common\" that returns tuple pairs that display as below (for the 5 most common words).","f277430c":"For example, displayed above are the first 5 words extracted from the tuple pairs relating to the \"News\" sentiment group and meet the criteria of occuring more than 0.05% in the News tweets. Next we want to get words that are specific to each class by utilising sets. So we get a set of, for example, Pro words and subtract from that set a union set of the other 3 classes. See code cell below.","e4f75c66":"###### task: visualise wordclouds of hashtags by class","733da6a8":"###### task: get NLTK Polarity scores\nIn the code cell below we define a function that gets compound scores from a given text. Note the the text should be in tokenized form (list of words) rather than in raw form.","37542836":"The result of the above operation is 2 additional columns in our dataframe (polarity and subjectivity). At this point we are done. We can go ahead and utilise visualisations to analyse tweet sentiments.","588b4480":"Next we want to concatenate the class specific words and store them for later use.","e812b74f":"For example, displayed above are the top 5 most common words in the \"Anti\" sentiment group. Next we want to extract the words, the first value in the paired tuples displayed above, but we dont need all of them, some occur way too infrequently. The figure below shows the distribution of the frequencies. Most of them occur with frequencies close to zero percent. In the figure we've limited both the x and the y axis to show the relevant pasrts of the plot, see the code cell below. You can comment out the set_lim menthods to see the entire axis.","74dbd8b9":"In order to execute our best_classifier function, we must create the following variables to feed into the function","f7a053a5":"Next we need a function that goes through the words in a tweet, determines if there are any words that are not in the top n words and removes them from the tweet and return the filtered tweet. Note that this operation should exclude the 762 class specific words determined above. See below.","29cd68f6":"Looks like this group also talks about \"science\". They also talk about Obama. It is possible that they are critiquing Obama's views about climate change. Since the data was collected between 2015 and 2018, it is likely that the former president and presidential candidates would be most mentioned in the dataset. Interestingly, and something that is to be expected, this group seeems to use words like \"scam\", \"fake\" and \"hoax\". They just don't believe in climate change and seem to be taken in by conspiracy theories. How about the neutral group. Lets see that wordcloud.","8dd5c89d":"###### check if tweets have hashtags","91743460":"## Exploratory Data Analysis <a class=\"anchor\" id=\"eigth-bullet\"><\/a>\n[back to top](#contents-bullet)","45dbe383":"Here we remove the stop words. Note that the list of stopwords provided by NLTK can be extended simply by concatenating a list of the additional words. Here we added the word \"amp\". More words can be added but this will suffice for now.","ec914742":"Looks like there is a number of tweets whose length reduces to zero. How many are they?","c2cfa47f":"Now we write a function that removes these frequent words in our tweets.","0a493f99":"###### task: analyse summary statistics\nWe'll start off by generating some summary statistics for the new columns we just introduced. See the output displayed below. Compound scores seem to range from -0.96 (minimum) to 0.93 (maximum) suggesting that there are tweets that tend to be highly negative while some tend to be highly positive. The average is -0.05, suggesting that tweet relating to climate change generally tend to contain negativity. Remember polarity captures similar sentiment to compound, also has a wide range (-1 to +1), the mean score however is 0.024, slightly higher that the average compound. Overall however, we expect these will have a high correlation. Subjectivity on the other hand, has a range from 0.26 to 1. The lower this value the more factual the tweet, we expect News tweets will display this characteristic as they report factual information about climate change. The other groups however, particularly the Anti and Pro will probably be very subjective in their statements. We're yet to find out through visualisations.","3552bbfc":"It makes sense to first investigate if there are any words that occur exclusively in one class. Such words, if they occur sufficiently, can be used to immediately distinguish between the classes. The code cell below attempts do that operation. The frequency computations are done per class and stored in a dictionary using a for loop operation.","036fc73f":"## Loading Data <a class=\"anchor\" id=\"third-bullet\"><\/a>\n[back to top](#contents-bullet)\n\n#### Load the training dataset and inspecting the dataset.","db0e33af":"### Processsing Test Data","0d7d95d8":"Here we utilise a looping method to go through each of the tweets and extract the words and append them to a list. So the output \"vocab\" is a giant list with all words that occur atleast once in the tweets","96481a06":"Implement the function across the dataset. Save the filtered tweets in a separate column and keep the original for reference.","4b4e2c97":"Lastly, we do lemmatization. We utilise NLTK's WordNet Lemmatizer class.","978f6502":"### Compound and Polarity\n\nNow looking at the above visual, it is clear that most of the data lies in the same range, ragardless of class. See for example the frist panel, most of the tweets will lie in the zero range of compound scores regardless of whether they are Pro, News or Neutral. The only exception is perhaps the Anti class, the belly in the zero range is smaller and the data is distributed across the range although not evenly. Polarity also displays a similar pattern, much worse. An important aspect of violinplots are the white dots we see in the middle of the bellies. That is the median value of the scores in that class. See that the median scores are relatively the same for both compound and polarity scores. Finally, looking at the colours of the visuals. The coloring is intentinal. If we are to extract insights about how people perceive climate change and whether or not they believe it is real, having sample data on belief we know for sure believe in climate cahnge is a good starting point. Thats why the Pro group is colored differently from the rest. The task now becomes one of figuring out how significantly different is the sample data of the other groups from that of the Pro group. Based on these violin plots for compound and polarity we can't tell. Lets look at subjectivity, the third panel of the figure.\n\n### Subjectivity\n\nLooking at subjectivity, the belly curve dont really tell anything. But look at the white dots (median), its slightly higher for the Pro and the Anti group. Note that these are people with strong opinions about climate change, very surprising that they are so subjective. News tweets as per our hypothesis earlier they are lower on subjectivity, and so are the Neutral group tweets. Perhaps now we have something to go on. But then again, how significant are these differences, can we possibly quantify that difference. In a later section we'll attempt testing a hypothesis based on t-tests on the mean values of the different classes.","90e9d209":"### To Comet","59b3c063":"# Feature engineering <a class=\"anchor\" id=\"sixth-bullet\"><\/a>\n[back to top](#contents-bullet)\n\nThis section is dedicated to further cleaning the tweets and formating them in such a way that they can be fed into a machine learning model. The first step in that regard is to remove punctuation and other characters that introduce noise to the tweets such as brackets, curly braces, question marks etc. Next we implement tokenization. This is a common technique in text analytics that takes a sentence or text and transforms it into a list of words instead. Text data formatted this way can then be fed into machine learning model using a Bag of Words (BOC) approach. More will be explained on what BOC is all about in the predictive modelling section later. The next step will then be to remove stop words. These are words such as (and, is, I, am etc) that do not necessarily provide any information about sentiments because they occur too frequently in language. Lastly we will lemmatize the words. Lemmatization is the process of reducing words to their root form for example the root form of falling is \"fall\". This has the advantage of reducing the number of unique words in the text data's vocabulary and most importantly it allows the machine learning models we build later to learn generalised patterns by identifying \"falling\" and \"fall\" as the same word rather than two different words. In the following tasks we write functions that implement the above outlined preprocessing.","927859d7":"##### task: visualise sentiment scores in a 2 dimensional space\nIn this task we take the average scores for each group and visualise them in two dimensional spaces. The idea is to visusally inspect how different the scores for Anti, News and Neutral are from the Pro class. This should give us a rough idea of how people perceive climate change relative to the believers. The following code cell utilises the groupby method to get the averages.","01571131":"The result is the addiitional columns in our dataset. Lets go ahead and get subjectivity scores from TextBlob before we go on to visualise the scores.","e50f9f1c":"## Data Cleaning <a class=\"anchor\" id=\"fifth-bullet\"><\/a>\nIn this section we do further cleaning of the tweets. Tweets often have urls, hashtags and handles that we may want to remove from the tweets if we are to properly analyse the tweets and get insights. However, in certain cases we may also want to do further analysis such tweet attributes. So instead of completely throwing them away, we'll just create new columns in our dataframe to store them. The following tasks are meant to acieve that purpose. First we do a quick check of any missing tweets or tweets with empty strings.","818ba7c0":"Having done all this preprocessing in the tweets we've added an extra column \"tweets\" to the dataset. These tweets have been removed of punctuation, tokenized (thus they are in list of words format), removed of stopwords and lemmatized. Ofcoarse we did not see lemmatization in action because our example tweet didn't particularly have words with lemmas. We just trust the process.","14c3008c":"The total number of words is 159465 while 13882 are unique. This means our BOW sparse matrix would consist of 13883 columns. The number of rows would be equal to the number of tweets we have in the data. This is a big matrix. In practice it is common to remove infrequently occuring words, a process that can be viewed as doing feature selection of some sort. In the following task we attempt to do just that.","b9e18f04":"Looking at the axis, however, we will choose a threshold frequency for a word to be kept. We choose 0.02 for now.","1d684716":"###### task: investigate the length of tweets\nHere we will check the length of each tweet in the dataset. We want to root out those that are left with no words at all after the filtering we did in previous tasks. The function below computes the length of tweets.","5f754ce8":"Yet another approach to trim those words down is to remove very frequently occuring words. The idea behind this approach is that very frequent words tend to occur similarly across all classes of the target, sometimes so much that they do not really provide any information that can help with classification. Care needs to be taken however, as this may sometimes remove important text information. As such, for now, we'll only remove the 20 most common words. Below we utilise our previous function that takes as input the list of ordered words, and returns the n very common words. n is equal to 20 this time.","db59f6ff":"Letsgo ahead and implement the function across the dataset. The result is 4 extra columns {negative, neutral, positive and compound). Our interest is mainly in the compound score as it summarises the other three.","e79127df":"After all this is done we've introduced three more columns in our training dataset. One for urls, another for handles and another for hashtags. In the next section, as we do more data cleaning, these tweet attributes can be removed and we will be comfortable with that because we've already stored them separately.","531051dd":"#### map the target to actual labels\nThe target is provided as the numbers -1, 0, 1, and 2. We want to map these to their actual string for example \"Anti\" for -1. The rest map as follows: 0:'Neutral', 1:'Pro', 2:'News'","c474a36f":"###### task: investigate if tweets have atleast one handle","b4fac35c":"After extracting the urls there are two things we may do. We may remove them completely from the tweets. Another option, that we think is more plausible is to replace them with the string \"urlweb\". This will result in all tweet that have a url of any sort containing this value. This will minimise the loss of data we may incur by completely discarding them. Below we write a user function that does just that.","24231d60":"### Predictions on Test Set","f27ed96d":"### Sentiment analysis\nNow we'll ask several more questions about the data. In Natural Language Processing its common to analyse the sentiment of textual data. Sentiment analysis is the automated process that uses AI to analyze data and classify opinions as positive, neutral or negative. Opinions can also be ranked based on how subjective they are. I hope you already see how this may be applicable to the dataset we have been working with. In this sub-section of EDA we intend to analyse the sentiment of our tweets. First we'll we'll implement an algorithm that assigns sentiment scores based of how negative they are or how positive they are. The NLTK library provides such functionality. It generates what they call compound scores that are computed as a linear combination of individual scores for positivity, negativity and neutrality. The higher the compound score the more positive a statement is and vise versa. See the following task for implementation details. As mentioned above opinions can also be ranked based on how subjective they are. We'll then utilise TextBlob, another python NLP package built ontop of NLTK. This package will allow us to easily get sentiment scores for how subjective a certain tweet is. Lets proceed.","d580fcdd":"The function below takes as input a single tweet and removes punctuation and other uncommon characters in the tweet. See example implementation below and how the punctuation has been removed. ","e731e63a":"Now lets plot a wordcloud for the Pro group. Remember these are tweets that indicate the sentiment of people who believe in climate change. The wordcloud therefore aims to show the words commonly used by those believers. See below.","c4371b06":"#### Experiments\n!pip install comet_ml\n\n#### Dependencies\n- *!pip install textblob*\n- *!pip install wordcloud*\n- *!pip install twython","3b6d079b":"See example of a randomly selected tweet with a url below.","a1c676dd":"Unfortunately our randomly selected tweet does not have any hashtags. Lets just go ahead and implement the fucntion across the training data.","73dea6e3":"After inspecting the data, the following is noted:\n1. There does not appear to be any missing data - This will be confirmed later\n2. Sentiment is `int64` although it is a categorical data type\n3. Int64 is an inefficient int size for the size of the numbers stored. `int16` will be far more memory efficient","d1e262f5":"Its only 122 of them, of the more than 15000. Tempting to just drop them and focus on the others. However, this approach has a really high likelyhood of overfitting. I mean the entire process of selecting words almost arbitrarily like this. As such we will treat the paramenter n as a variable parameter and fit a classifier on a cross validation scheme. Note that this will be done later. For now we will do Exploratory Data Analysis, a process that may reveal even more insights about the data\/tweets and how they can be utilised to answer some of the question surrounding beief in climate change.","a5c2d904":"Not surprisingly the words climate and change occur with highest frequency. The tweets are about climate change after all. Anyway, our intention is to keek the top n words, where n is the number of words we want to keep. Below we write a function that iterate through the paired tuples displayed above and returns a list of top n words. Function argument is n.","e926b781":"For example, above displayed are 5 of the words that are specific to the Pro sentiment group. The number of unique words as found in the tweets are displayed below.","8f645307":"## Modelling  <a class=\"anchor\" id=\"ninth-bullet\"><\/a>\n[back to top](#contents-bullet)\n\n### Dealing with data imbalances\n\nAs we saw in our EDA, the dataset is imbalanced as more than 50% of the observations belong to the `Pro`class and the fewest observations belonging to the `Anti` class. Although the dataset is representative of the the population, it is not usefull for modelling as our model will perform well on the `Pro` class but poorly for the `Anti` class. We have chose to resample our dataset to 50% of the `Pro` class. This will cause worse performance on the `Pro` subset as we will lose 4000 observations, however we may see an improvement in the classes with fewer observations","43c40238":"Next we use a list comprehension to get the sentiment scores, see the cell below.","9f7efd0e":"# Climate Change Belief Classification\n\n## Contents: <a class=\"anchor\" id=\"contents-bullet\"><\/a>\n- [Introduction](#first-bullet)\n- [Imports](#second-bullet)\n- [Loading Data](#third-bullet)\n- [Data Definitions](#fourth-bullet)\n- [Data Cleaning](#fifth-bullet)\n- [Feature Engineering](#sixth-bullet)\n- [Text Selection](#seventh-bullet)\n- [Exploratory Data Analysis](#eigth-bullet)\n- [Modelling](#ninth-bullet)\n- [Conclusion](#tenth-bullet)","09d17b4f":"[back to top](#contents-bullet)","980055d8":"Looking at the above plot, we see that the data is distributed unevenly across the sentiments. Generally most tweets fall under the Pro class indicating that the general sentiment is that people do believe in human caused climate change. The second most common class is the News class. Note that this is not really a sentiment class but just news articles relating to climate change. The Neutral class consists of a set of tweets whose sentiment indicates that they neither believe nor disbelieve in human caused climate change. Lastly, the Anti class consists of tweeters who make it clear that they do not belive in human caused climate change. In the sample of tweets provided, these are the minority of the population.","38339a19":"Next we take the unique words and count them.","3ae5e340":"Write a function to convert the data types","6bef7cce":"## Text Selection - Part 1 <a class=\"anchor\" id=\"seventh-bullet\"><\/a>\n[back to top](#contents-bullet)\n\nUsually the Data Science will include a section of feature selection. In Natural Language Processing however, we don't immediately have features. For example in the provided dataset has a single column whose entries are tweets. How do we get features? One such approach is the BOW model. Bag of Words is literally a Bag of Words. The Bag can be thought of as the `list` object in Python and the contents of that Bag\/list are the words. The way this BOW is transformed to a set of features that are machine learning ready is as follows: \n1. All unique words in all tweets are extracted and mapped in a dataframe as column names. The whole sample of tweets remains as rows. \n2. For each row\/tweet and for each column name\/word we count the number of occurances of the word in the tweet and assign that as a value in the corresponding cell.\n\nSo a BOW creates as many columns as there unique words in the tweets combined, resulting in a sparse matrix (a matrix with many zero values because words generally occur infrequently in text).","e1258475":"To identify infrequently occuring words, we start of by ordering the words in our vocabulary by frequency. Luckily we already have a giant list with our vocabulary from the previous task. So we untilise a python package known as Collections (already imported above). The package has a useful function \"Counter\". Takes as input a list of words, counts their occurance and returns an object with a method \"most_common\" that returns tuple pairs that display as below (for the 5 most common words).","8c0d712f":"## Introduction <a class=\"anchor\" id=\"first-bullet\"><\/a>\n\n### Context\nMany companies are built around lessening one\u2019s environmental impact or carbon footprint. They offer products and services that are environmentally friendly and sustainable, in line with their values and ideals. They would like to determine how people perceive climate change and whether or not they believe it is a real threat. This would add to their market research efforts in gauging how their product\/service may be received.\n\n### Problem statement \nWith this context, EDSA is challenging you during the Classification Sprint with the task of creating a Machine Learning model that is able to classify whether or not a person believes in climate change, based on their novel tweet data.\n\nProviding an accurate and robust solution to this task gives companies access to a broad base of consumer sentiment, spanning multiple demographic and geographic categories - thus increasing their insights and informing future marketing strategies.\n\n### Objective\n- __Competition:__ [Climate Change Belief Analysis](https:\/\/www.kaggle.com\/c\/climate-change-belief-analysis)\n- __Determine:__ How the public perceives climate change and wheter or not they believe it is a threat\n- __Classify:__ Individuals by belief in climate change based on novel tweet data\n- __Evaluation:__ Weighted F1-Score\n- __Kernel Workflow:__ Data -> Features(EDA) -> Comparison(EDA) -> Model\n\n### Evaluation Metric\n\n**weighted f1-score**\n\nThe traditional f1-score is the harmonic mean between precision and recall:\n<img src=\"https:\/\/wikimedia.org\/api\/rest_v1\/media\/math\/render\/svg\/3607c634303f2fd8b69ca4f9d97a491c45083cc5\"\n     \/>\n\nThe F1 Scores are calculated for each label (`2`, `1`, `0`, `-1`) and then their average is weighted by support - being the number of true instances for each label. In other words, the f1-score for each label is weighted based on it's proportion of TN and TP in the  sample.\n\nJust like the f1-score, the weighted f1 score will be a number between 0 and 1 where perfect precision and recall occurs at 1.","072f4bf2":"#### investigate missingness and empty strings","3a75c077":"### Tweet handles and Hashtags\nEarlier we retrieved and stored tweet handles and hashtags and stored them in columns of their own for later use. In this section we take the opportunity to revisit them. We'll start of with the handles.","b9dfe2eb":"###### task: visualise the distribution of the score by label\nAlthough the sunmaries in the previous task tell a little story about the data, it does not give us the opprotunity to learn about hos sentiment is distributed across the different classes in our data. Now we want to ask questions such as \"Do News tweets tend to be more subjective than tweets by the other groups\"? for example. To do this we utilise seaborn's violin plots. Violinplots attempt to show how data is distributed by having fat bellies were more data lies and by thinning in the range where there is little data. An illustration will certainly make this clear. See below.","27eafdae":"We'll start off by plotting compound versus polarity in a two dimensional space. We then indicate where in that space each class would lie based on their computed average values of sentiment. Looking at the figure, it is clear that the News tweets tend to perceive climate change almost similar to the way the Pro group does. The Anti group is a little further. The Neutral group is furthest. An additional finding is that, in a spectrum that goes from negative to positive, both Pro and News fall somewhere inbetween. With the Anti group being the most negative and the Neutral group being the most positive.","aafcade5":"## Conclusion <a class=\"anchor\" id=\"tenth-bullet\"><\/a>","4f6fed15":"Again, we write a user function that find twitter handles and treats them the same way urls were treated above.","68e59a14":"We already determined that the Pro and the Anti groups tend to be more subjective than the other groups. Now what is the relationship between subjectivity and polarity. We sort of hypothesized earlier that Pro and Anti are the groups with strong opinions but does this really mean they are more subjective. Below we visualise a scatterplot of polarity and subjectivity. See how when subjectivity is low, the range of polarity scores is thin around zero. As we move along the subjectivity axis, this range widens more and more. If we assume that polarity is efficient at capturing sentiment, the range around zero would be a collection of neutral tweets, perhaps News and the Neutral group with low subjectivity. Pro and Anti would then lie higher in the subjectivity scale where the range of polarity is much wider. So yes, it seems there a some relationship between polarity and subjectivity. The more positive or negative a statement is, the more subjective and the less factual.","2d7c7670":"### Submitting directly to Competition","55e9e0b2":"## Imports <a class=\"anchor\" id=\"second-bullet\"><\/a>\n[back to top](#contents-bullet)","78a126c8":"### Cross-Validation\n\nIn order to choose a model we need to determine which is the besst classifier for the job. To do this, the function below will:\n1. Cross validate the models - Default folds = 2\n2. Build a pipeline\n2. Fit and tune the model hyperparameters\n3. Return a dataframe containing the pipeline, models and results","6e9c6735":"Note that almost all of the words in the tweet are removed. This should raise further concern. What if there are tweets that are left woth no words at all after this filtering? Lets do more investigation. First implement the function across the dataset."}}