{"cell_type":{"f5a8459a":"code","728045c5":"code","c62b8332":"code","8aaf2f60":"code","17da368f":"code","83f38bf4":"code","ba595646":"code","ae48195f":"code","429c2daa":"code","ffd74d1e":"code","9b1d7f67":"code","2044b491":"code","355ecd53":"code","c46ee6f3":"code","64bea51d":"code","88b456cd":"code","adf2738d":"code","b4bc4694":"code","11593110":"code","00aa4271":"code","d92978fe":"code","ae624399":"code","a9ccc2ac":"code","808978b6":"code","636d9c63":"code","b602888a":"code","188c3455":"code","dda98da3":"code","00caf3a9":"code","a64ed514":"code","8ad2abf0":"code","df1cc73e":"code","108628a5":"code","d4e107ac":"code","86d82899":"code","c1a7bec0":"code","c28519ad":"code","07d430d6":"code","9453b0cf":"code","e0018252":"code","262bb988":"markdown"},"source":{"f5a8459a":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","728045c5":"#Todas las librer\u00edas utilizadas en alg\u00fan momento de la programaci\u00f3n\nimport numpy as np\nimport pandas as pd\nimport xgboost as xgb\nfrom scipy import stats\nfrom xgboost.sklearn import XGBClassifier\nfrom scipy.stats import uniform, randint\nfrom sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\nfrom sklearn.metrics import explained_variance_score\nfrom sklearn.metrics import confusion_matrix, roc_auc_score\nfrom sklearn.metrics import mean_squared_error\nimport seaborn as sns\nimport matplotlib.pylab as pl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport shap\nimport matplotlib.pyplot as plt\nshap.initjs()\n%matplotlib inline\n\nnp.random.seed(3)\n\nfrom mpl_toolkits.mplot3d import Axes3D\nimport folium\nfrom folium.plugins import HeatMap","c62b8332":"#Importaci\u00f3n de la base de datos\nhouses_file_path = '\/kaggle\/input\/houses-mad\/houses_Madrid_GPS.csv'\nhouses_data = pd.read_csv(houses_file_path)\n\nhouses_data.columns\n","8aaf2f60":"#Estructura de los datos\nhouses_data.shape","17da368f":"#Eliminar filas que tengan variables vac\u00edas\nhouses_data = houses_data.dropna(axis=0)\n#Como queda la estructura de los datos\nhouses_data.shape","83f38bf4":"#Histogr\u00e1mas de las variables\nhouses_data.hist(figsize = (18,16))","ba595646":"#Histograma\/nomalidad de la variable objetivo buy_price\nfrom scipy.stats import norm\nsns.distplot(houses_data['buy_price'], fit=norm);\nfig = plt.figure()\n","ae48195f":"#Valores de simetr\u00eda y curtosis antes de tratar\nprint(\"Skewness: %f\" % houses_data['buy_price'].skew())\nprint(\"Kurtosis: %f\" % houses_data['buy_price'].kurt())","429c2daa":"#Matriz de correlaciones\ncorrmat = houses_data.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(20,20))\ng=sns.heatmap(houses_data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")\n","ffd74d1e":"#Algunos scatter de las variables para representar la correlaci\u00f3n\nfrom matplotlib import pyplot\npyplot.scatter(houses_data[\"sq_mt_built\"], houses_data[\"buy_price\"])\npyplot.show()\npyplot.scatter(houses_data[\"n_bathrooms\"], houses_data[\"buy_price\"])\npyplot.show() \npyplot.scatter(houses_data[\"n_rooms\"], houses_data[\"buy_price\"])\npyplot.show()\npyplot.scatter(houses_data[\"n_rooms\"], houses_data[\"buy_price\"])\npyplot.show()\npyplot.scatter(houses_data[\"n_bathrooms\"], houses_data[\"buy_price\"])\npyplot.show()\npyplot.scatter(houses_data[\"latitude\"], houses_data[\"buy_price\"])\npyplot.show()","9b1d7f67":"#Gr\u00e1fica de caja para ver valores extremos (los c\u00edrculos negros)\nplt.boxplot(houses_data[\"buy_price\"])\nplt.show()","2044b491":"#El percentil 90 de las X\nQ90 = houses_data.quantile(0.90)\n\n\nprint(Q90)","355ecd53":"#Un resumen de las estad\u00edsticas m\u00e1s importantes\nhouses_data.describe()","c46ee6f3":"#Limpeza de valores extremos\nprint(\"Antes de quitar extremos: (17756, 14)\")\nindex = houses_data[(houses_data['buy_price'] >= 1200000)|(houses_data['buy_price'] <= 70000)].index\nhouses_data.drop(index, inplace=True)\nprint(\"Despues de quitar extremos: \" ,houses_data.shape)\n\n","64bea51d":"#C\u00f3mo quedan despu\u00e9s de quitar los valores extremos\nhouses_data.describe()","88b456cd":"#Histogr\u00e1ma de variable objetivo mucho m\u00e1s aceptable\nfrom scipy.stats import norm\nsns.distplot(houses_data['buy_price'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(houses_data['buy_price'], plot=plt)","adf2738d":"#Nuevos valores de asimetr\u00eda y curtosis m\u00e1s aceptables tras eliminar valores extremos\nprint(\"Skewness: %f\" % houses_data['buy_price'].skew())\nprint(\"Kurtosis: %f\" % houses_data['buy_price'].kurt())","b4bc4694":"#Nuevos histogramas de las variables tras quitar valores extremos\nhouses_data.hist(figsize = (18,16))","11593110":"#Nueva matriz de correlaciones\ncorrmat = houses_data.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(20,20))\ng=sns.heatmap(houses_data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","00aa4271":"#Representaci\u00f3n de los diferentes distritos del dataset\nfig, ax = plt.subplots(figsize=(12,6))\nax.scatter(houses_data['longitude'], houses_data['latitude'])\nax.set_xlabel('Longitud')\nax.set_ylabel('Latitud')\nplt.show()","d92978fe":"#Representaci\u00f3n en un mapa de calor sobre la ciudad de Madrid de los inputs del modelo\n\n# Encuentra la fila que tiene la casa m\u00e1s cara\nmaxpr=houses_data.loc[houses_data['buy_price'].idxmax()]\n\n#Define la funci\u00f3n para dibujar el mapa\ndef generateBaseMap(default_location=[40.4280, -3.675], default_zoom_start=9.4):\n    base_map = folium.Map(location=default_location, control_scale=True, zoom_start=default_zoom_start)\n    return base_map\n\nhouses_data_copy = houses_data.copy()\nhouses_data_copy['count'] = 1\nbasemap = generateBaseMap()\n# A\u00f1ade un mapa tipo 'cartodbpositron'\nfolium.TileLayer('cartodbpositron').add_to(basemap)\ns=folium.FeatureGroup(name='icon').add_to(basemap)\n# A\u00f1ade un marcador que indica el lugar de la casa m\u00e1s cara\nfolium.Marker([maxpr['latitude'], maxpr['longitude']],popup='Highest Price: $'+str(format(maxpr['buy_price'],'.0f')),\n              icon=folium.Icon(color='green')).add_to(s)\n# A\u00f1ade el mapa de temperatura\nHeatMap(data=houses_data_copy[['latitude','longitude','count']].groupby(['latitude','longitude']).sum().reset_index().values.tolist(),\n        radius=12,max_zoom=13,name='Heat Map').add_to(basemap)\nfolium.LayerControl(collapsed=False).add_to(basemap)\nbasemap","ae624399":"#Selecci\u00f3n de las variables dependiente e indepependiente\ny = houses_data.buy_price\nhouses_features = ['sq_mt_built', 'n_rooms', 'n_bathrooms','latitude', 'longitude','floor',\n                   'is_renewal_needed', 'is_new_development', 'has_lift', 'is_exterior', 'has_parking']\nX = houses_data[houses_features]","a9ccc2ac":"#Implementaci\u00f3n de algoritmo de \u00e1rboles de decisi\u00f3n XGBoost\n\ndata_dmatrix = xgb.DMatrix(data=X,label=y)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n\n\nxg_reg = xgb.XGBRegressor(objective ='reg:linear',\n                          eta = 0.3,\n                          min_child_weight = 1,\n                          gamma = 0.1018506246381371,\n                          colsample_bytree = 0.8629698417369874, \n                          learning_rate = 0.06164827794908118, \n                          max_depth = 5, \n                          alpha = 8.072986901537691, \n                          n_estimators = 127,\n                          subsample= 0.6873761748867334)\nxg_reg.fit(X_train,y_train)\npreds = xg_reg.predict(X_test)\nrmse = np.sqrt(mean_squared_error(y_test, preds))\nprint(\"RMSE: %f\" % (rmse))\nprint(explained_variance_score(preds,y_test))","808978b6":"#Representaci\u00f3n de un ejemplo de \u00e1rbol de decisi\u00f3n del modelo\nfrom xgboost import plot_tree\nplot_tree(xg_reg)\nfig = plt.gcf()\nfig.set_size_inches(100, 70)\n","636d9c63":"\n#Media de las predicciones\nimport statistics\nstatistics.mean(preds)","b602888a":"#C\u00e1lculo de los valores de Shapley, mediante la variable C se puede elegir que fila de la base de datos se quiere explicar\n\nC = 58\nexplainer = shap.TreeExplainer(xg_reg)\nshap_values = explainer.shap_values(X_test)\n\n\n\n","188c3455":"#Force plot de la fila C\nshap.force_plot(explainer.expected_value, shap_values[C,:], X_test.iloc[C,:])","dda98da3":"#Imprime el Precio original de la vivienda C y sus atributos\nprint (\"Precio: \" ,y_test.iloc[C], \"\\n\" \n      ,X_test.iloc[C,:])","00caf3a9":"#Media de las variables a interpretar\nX_test.mean()","a64ed514":"X_importance = X_test","8ad2abf0":"#Summary plots\n\nshap.summary_plot(shap_values, X_test)\n\nshap.summary_plot(shap_values, X_importance, plot_type='bar')","df1cc73e":"#C\u00e1lculo de los valores Shapley promedio por variable\nshap_sum = np.abs(shap_values).mean(axis=0)\nimportance_df = pd.DataFrame([X_importance.columns.tolist(), shap_sum.tolist()]).T\nimportance_df.columns = ['column_name', 'shap_importance']\nimportance_df = importance_df.sort_values('shap_importance', ascending=False)\nimportance_df","108628a5":"#Dependence plot\nshap.dependence_plot('sq_mt_built', shap_values, X_test, interaction_index=\"sq_mt_built\")","d4e107ac":"#Otro summary plot\nX_interaction = X_importance.iloc[:2500,:]\n\nshap_interaction_values = shap.TreeExplainer(xg_reg).shap_interaction_values(X_interaction)\n\nshap.summary_plot(shap_interaction_values, X_interaction, plot_type=\"compact_dot\")","86d82899":"#Agregado de force plot, se pueden cambiar los ejes y si se desliza el cursero por los valores de Shapley los muestra\nshap.force_plot(explainer.expected_value, shap_values, X_test)","c1a7bec0":"#otro tipo de force plot\nshap.waterfall_plot(explainer.expected_value, shap_values[C,:], feature_names=X.columns.values, max_display=5, show=True)","c28519ad":"#Gr\u00e1fico de la importacia de las variables nativo de XGBoost (para comparar)\nxgb.plot_importance(xg_reg)","07d430d6":"#Se declara la variable que reporte los mejores par\u00e1meetros para el modelo XGBoost\ndef report_best_scores(results, n_top=3):\n    for i in range(1, n_top + 1):\n        candidates = np.flatnonzero(results['rank_test_score'] == i)\n        for candidate in candidates:\n            print(\"Model with rank: {0}\".format(i))\n            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n                  results['mean_test_score'][candidate],\n                  results['std_test_score'][candidate]))\n            print(\"Parameters: {0}\".format(results['params'][candidate]))\n            print(\"\")","9453b0cf":"def display_scores(scores):\n    print(\"Scores: {0}\\nMean: {1:.3f}\\nStd: {2:.3f}\".format(scores, np.mean(scores), np.std(scores)))","e0018252":"#El c\u00f3digo de abajo est\u00e1 desactivado porque busca los valores \u00f3ptimos de los par\u00e1metros \n#repitiendo el c\u00e1lculo del modelo, cambiando los par\u00e1metros en cada iteraci\u00f3n\n#tarda mucho tiempo","262bb988":"xgb_model = xgb.XGBRegressor()\n\nparams = {\n    \"eta\" : uniform(0.1, 0.5),\n    \"alpha\" : uniform(1, 15),\n    \"colsample_bytree\": uniform(0.7, 0.3),\n    \"gamma\": uniform(0, 0.5),\n    \"learning_rate\": uniform(0.03, 0.3), # default 0.1 \n    \"max_depth\": randint(2, 6), # default 3\n    \"n_estimators\": randint(100, 150), # default 100\n    \"subsample\": uniform(0.6, 0.4)\n}\n\nsearch = RandomizedSearchCV(xgb_model, param_distributions=params, random_state=42, n_iter=180, cv=2, verbose=1, n_jobs=1, return_train_score=True)\n\nsearch.fit(X_test, y_test)\n\nreport_best_scores(search.cv_results_, 1)"}}