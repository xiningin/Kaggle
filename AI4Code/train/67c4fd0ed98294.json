{"cell_type":{"7e095959":"code","1baca153":"code","1567e066":"code","8f9ff2d8":"code","0eafee7a":"code","36e26bda":"code","8697c418":"code","5b1b5af4":"code","8f5038d2":"code","7695e8f7":"code","19017990":"code","02c1ff24":"code","6b67b0bb":"code","f61cb827":"code","03a97c3b":"code","96b1a79f":"code","880e4885":"code","0057b392":"code","8dafd696":"code","9d21c85a":"code","36d8e991":"code","e264d090":"code","1c1cc8b8":"code","7425f822":"code","901df470":"code","ac8f2df5":"code","3ad81ff1":"code","f0c76c55":"code","93a88613":"code","12cde8ce":"code","91cfae0f":"code","177646fe":"code","e372df6a":"code","be7cf65c":"code","703cb783":"code","aa8b12d3":"code","16b11ca6":"markdown","79f87dce":"markdown","e3f5430b":"markdown","48f92119":"markdown","c7f58dd4":"markdown","7f790134":"markdown","c6b6565a":"markdown","54e770f1":"markdown","d1aad3bd":"markdown","3da1259e":"markdown","7f534b02":"markdown","39450559":"markdown","812a6857":"markdown","3c7aa4dc":"markdown","2c481736":"markdown","1ec4ab00":"markdown","2a424d2a":"markdown"},"source":{"7e095959":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1baca153":"#import required libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\n%matplotlib inline","1567e066":"train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","8f9ff2d8":"train.shape","0eafee7a":"test.shape","36e26bda":"train.describe()","8697c418":"train.info()","5b1b5af4":"#TRAIN DATA\n#find missing values count for each column\nmissingData= train.isnull().sum().sort_values(ascending = False)\nmissingData.head(20)","8f5038d2":"high_null_cols = [features for features in train.columns if train[features].isnull().sum()>730]\ntrain.drop(high_null_cols,axis = 1,inplace = True )\ntest.drop(high_null_cols,axis = 1,inplace = True )","7695e8f7":"#Find numeric datatype columns whose values are missing\nnum_columns = [feature for feature in train.columns if train[feature].dtypes != 'O' and train[feature].isnull().sum()>0]\nfor col in num_columns:\n    train[col]=train[col].fillna(train[col].mean())","19017990":"#Find object datatype columns whose values are missing\nobj_columns = [feature for feature in train.columns if train[feature].dtypes == 'O' and train[feature].isnull().sum()>0]\nfor col in obj_columns:\n    train[col]=train[col].fillna(train[col].mode()[0])\nobj_columns","02c1ff24":"train.isnull().sum().sort_values(ascending = False)","6b67b0bb":"#TestData\n#Find numeric datatype columns whose values are missing in testdata\nnum_columns_test = [feature for feature in test.columns if test[feature].dtypes != 'O' and test[feature].isnull().sum()>0]\nfor colTest in num_columns_test:\n    test[colTest]=test[colTest].fillna(test[colTest].mean())","f61cb827":"#Find object datatype columns whose values are missing in testdata\nobj_columns_test = [feature for feature in test.columns if test[feature].dtypes == 'O' and test[feature].isnull().sum()>0]\nfor colTest in obj_columns_test:\n    test[colTest]=test[colTest].fillna(test[colTest].mode()[0])","03a97c3b":"test.isnull().sum()","96b1a79f":"#check how saleprice is distributed \nsns.distplot(train['SalePrice'])","880e4885":"#lets find how features are correlated with salePrice.\nplt.subplots(figsize=(16,8))\nsns.heatmap(train.corr())","0057b392":"comat = train.corr()\ncomat['SalePrice'].sort_values(ascending = False)","8dafd696":"sns.scatterplot(train['GrLivArea'],train['SalePrice'])","9d21c85a":"sns.boxplot(train['OverallQual'],train['SalePrice'])","36d8e991":"#remove Id from both train & test data,and also remove price data and assign it to a varaiable.\ny= train['SalePrice']\ntrainID =train['Id'] \ntestID = test['Id']\n\ntrain.drop(['Id','SalePrice'],axis = 1, inplace= True)\ntest.drop(['Id'],axis = 1, inplace = True)","e264d090":"#Train_data\nnumeric_cols_train =[feature for feature in train.columns if train[feature].dtypes != 'O']\nscaler = StandardScaler()\ntrain[numeric_cols_train] = scaler.fit_transform(train[numeric_cols_train])","1c1cc8b8":"#Test_data\nnumeric_cols_test =[feature for feature in test.columns if test[feature].dtypes != 'O']\nscaler = StandardScaler()\ntest[numeric_cols_test] = scaler.fit_transform(test[numeric_cols_test])","7425f822":"#select object datatype columns data of train\ntrain_nums = train.select_dtypes(exclude='object')\ntrain_objects = train.select_dtypes(include='object')\n\n\n#select object datatype columns data of test\ntest_nums = test.select_dtypes(exclude='object')\ntest_objs = test.select_dtypes(include='object')\n\n\n#\nobjects = pd.concat([train_objects,test_objs])\nobjects.shape","901df470":"#Now apply one-hot encoding for these features\nobjects_final = pd.get_dummies(objects)","ac8f2df5":"#Now add train data objects to numeric objects\nX = pd.concat([train_nums,objects_final.iloc[:1460]],axis=1)\nX.shape","3ad81ff1":"#Now add test data objects to its numeric objects\ntest_data = pd.concat([test_nums,objects_final.iloc[1460:]],axis=1)\ntest_data.shape","f0c76c55":"#split the train & validation for train data\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)","93a88613":"#Decision regression model\nDTR_model = DecisionTreeRegressor(random_state=1)\nDTR_model.fit(train_X, train_y)","12cde8ce":"# Make validation predictions and calculate Root mean square error\nval_predictions = DTR_model.predict(val_X)\nrmse_DTR = sqrt(mean_squared_error(val_y, val_predictions))\nprint(\"RMSE for Decision Tree: {:,.0f}\".format(rmse_DTR))","91cfae0f":"#RandomForestRegressor Model\nRFR_model = RandomForestRegressor(random_state=1)\nRFR_model.fit(X,y)","177646fe":"# Make validation predictions and calculate Root mean square error\nval_predictions = RFR_model.predict(val_X)\nrmse_RFR = sqrt(mean_squared_error(val_y, val_predictions))\nprint(\"RMSE for Decision Tree: {:,.0f}\".format(rmse_RFR))\n","e372df6a":"test_predict_data = RFR_model.predict(test_data)","be7cf65c":"output = pd.DataFrame({'Id': testID ,\n                       'SalePrice': test_predict_data})\n","703cb783":"output.head(20)","aa8b12d3":"output.to_csv('submission.csv', index=False)","16b11ca6":"From Correlation matrix we can say OverallQual,Grlivarea are good predictors for Saleprice","79f87dce":"# Import Datasets","e3f5430b":"# One Hot-encoding for object features","48f92119":"There is a positive skew. so it is not normally distributed.","c7f58dd4":"Here we can see the saleprice value increases as the Overallqual value increases. Hence it is a good predictor.","7f790134":"# Exploratory Data Analysis","c6b6565a":"1.3 for features of object datatype, replace missing values with the mode of it.","54e770f1":"As model improvisation is more in RandomForrestRegressor, we go with this model.","d1aad3bd":"# Model development","3da1259e":"Do same for test data missing values","7f534b02":"No missing values are present in train data","39450559":"1.2 for features of numerical datatype, replace missing values with the mean of it.","812a6857":"Now check any missing values are present","3c7aa4dc":"Data normalisation","2c481736":"1.1 Remove 50% of data missing columns as they wont have much impact on house price prediction","1ec4ab00":"# 1.Handle missing data","2a424d2a":"Here we can see outliers present when GrlivArea> 4000 and SalePrice<  300000"}}