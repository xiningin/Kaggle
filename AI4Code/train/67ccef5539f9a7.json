{"cell_type":{"28cf445c":"code","b81ba694":"code","71bd5750":"code","e560880c":"code","00760a83":"code","9490072e":"code","6d6ac10e":"code","00eeff5a":"code","9cfaf4e1":"code","8d122c60":"code","22a1c6c7":"code","ca007d70":"code","6556bdef":"code","0937d079":"code","8271e6fb":"code","ee102241":"code","bea1be38":"code","e5a86b7d":"code","58a65aac":"code","c1c5178d":"code","ddcca4a7":"code","162edaeb":"code","e1e07ba2":"code","5e0857f9":"code","91a80faa":"code","9872bce3":"code","dea674f2":"code","d998c965":"code","c7a269dd":"code","3f38342d":"code","b6c55e29":"code","1305885e":"code","d5b74183":"code","4ff12b97":"code","fdff9c3f":"code","6cb992bc":"code","76020250":"code","b7dba6b0":"code","4db906f7":"markdown","7a5eb5ba":"markdown","472cba6c":"markdown","f93fef9a":"markdown","42dd64df":"markdown","fa97b236":"markdown","0fc6e801":"markdown","60764054":"markdown","1606958c":"markdown","13ab5f89":"markdown","994ef8a3":"markdown"},"source":{"28cf445c":"import warnings\nwarnings.filterwarnings('ignore')","b81ba694":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nimport cv2, os","71bd5750":"train_dir = '..\/input\/asl_alphabet_train\/asl_alphabet_train\/'\ntrain_folders = os.listdir(train_dir)\ntest_dir = '..\/input\/asl_alphabet_test\/asl_alphabet_test\/'\ntest_files = os.listdir(test_dir)","e560880c":"x_train, y_train = [], []\nfor folder in train_folders:\n    files = os.listdir(train_dir + folder)\n    print('Reading images from ' + train_dir + folder + '\/ ...')\n    for file in files[:1000]:\n        img = cv2.imread(train_dir + folder + '\/' + file)\n        img = cv2.resize(img, (227, 227))\n        x_train.append(img)\n        y_train.append(folder)","00760a83":"len(x_train), x_train[0].shape","9490072e":"len(y_train)","6d6ac10e":"x_test, y_test = [], []\nfor file in test_files:\n    img = cv2.imread(test_dir + file)\n    img = cv2.resize(img, (227, 227))\n    x_test.append(img)\n    y_test.append(file.split('_')[0])","00eeff5a":"len(x_test), x_test[0].shape","9cfaf4e1":"len(y_test)","8d122c60":"# LabelEncoding\ny_test_encoded = np.array(list(range(len(y_test))))\ny_train_encoded = np.array([y_test.index(i) if i != 'del' else 29 for i in y_train])","22a1c6c7":"y_test_encoded = np.eye(30)[y_test_encoded]\ny_train_encoded = np.eye(30)[y_train_encoded]","ca007d70":"y_train_encoded.shape, y_test_encoded.shape","6556bdef":"def next_batch(batch_size, data, labels):\n    idx = np.arange(0, len(data))\n    np.random.shuffle(idx)\n    idx = idx[: batch_size]\n    data_shuffle = [data[i] for i in idx]\n    labels_shuffle = [labels[i] for i in idx]\n    return np.asarray(data_shuffle), np.asarray(labels_shuffle)","0937d079":"def display_images(data, title, display_label = True):\n    x, y = data\n    fig, axes = plt.subplots(2, 6, figsize = (18, 5))\n    fig.subplots_adjust(hspace = 0.5, wspace = 0.5)\n    fig.suptitle(title, fontsize = 18)\n    for i, ax in enumerate(axes.flat):\n        ax.imshow(x[i])\n        if display_label:\n            ax.set_xlabel(y[i])\n        ax.set_xticks([])\n        ax.set_yticks([])\n    plt.show()","8271e6fb":"display_images(next_batch(12, x_train, y_train), 'Training Images')","ee102241":"display_images(next_batch(12, x_test, y_test), 'Test Images')","bea1be38":"# Training Hyperparameters\nlearning_rate = 0.001\nepochs = 5000\nbatch_size = 128\ndisplay_step = 200","e5a86b7d":"height = 227\nwidth = 227\nn_channels = 3\nn_classes = 30","58a65aac":"X = tf.placeholder(tf.float32, shape = [None, height, width, n_channels])\nY = tf.placeholder(tf.float32, shape = [None, n_classes])","c1c5178d":"weights = {\n    # Convolutional Layer 1: 11x11 filters, 3 input channels, 96 output channels\n    'w1' : tf.Variable(tf.random_normal([11, 11, 3, 96])), \n    # Convolutional Layer 2: 5x5 filters, 96 input channels, 256 output channels\n    'w2' : tf.Variable(tf.random_normal([5, 5, 96, 256])),\n    # Convolutional Layer 3: 3x3 filters, 256 input channels, 384 output channels\n    'w3' : tf.Variable(tf.random_normal([3, 3, 256, 384])),\n    # Convolutional Layer 4: 3x3 filters, 384 input channels, 384 output channels\n    'w4' : tf.Variable(tf.random_normal([3, 3, 384, 384])),\n    # Convolutional Layer 5: 3x3 filters, 384 input channels, 256 output channels\n    'w5' : tf.Variable(tf.random_normal([3, 3, 384, 256])),\n    # Fully Connected Layer 1: 9216 input channels, 4096 output channels\n    'w6' : tf.Variable(tf.random_normal([9216, 4096])),\n    # Fully Connected Layer 2: 4096 input channels, 4096 output channels\n    'w7' : tf.Variable(tf.random_normal([4096, 4096])),\n    # Fully Connected Layer 3: 4096 input channels, 30(number of classes) output channels\n    'w8' : tf.Variable(tf.random_normal([4096, n_classes]))\n}","ddcca4a7":"biases = {\n    'b1' : tf.Variable(tf.random_normal([96])),\n    'b2' : tf.Variable(tf.random_normal([256])),\n    'b3' : tf.Variable(tf.random_normal([384])),\n    'b4' : tf.Variable(tf.random_normal([384])),\n    'b5' : tf.Variable(tf.random_normal([256])),\n    'b6' : tf.Variable(tf.random_normal([4096])),\n    'b7' : tf.Variable(tf.random_normal([4096])),\n    'b8' : tf.Variable(tf.random_normal([n_classes]))\n}","162edaeb":"# Wrapper function for creating a Convolutional Layer\ndef conv2d(x, W, b, strides = 1, padding = 'SAME'):\n    x = tf.nn.conv2d(x, W, strides = [1, strides, strides, 1], padding = padding)\n    x = tf.nn.bias_add(x, b)\n    return tf.nn.relu(x)","e1e07ba2":"# Wrapper function for creating a Pooling Layer\ndef maxpool2d(x, k = 2, padding = 'VALID'):\n    return tf.nn.max_pool(x, ksize = [1, k, k, 1], strides = [1, k, k, 1], padding = padding)","5e0857f9":"def alexnet(x, w, b):\n    x = tf.reshape(x, shape = [-1, 227, 227, 3])\n    \n    # Layer 1\n    conv1 = conv2d(x, w['w1'], b['b1'], strides = 4, padding = 'VALID') # Convolution\n    conv1 = maxpool2d(conv1) # Pooling\n    \n    # Layer 2\n    conv2 = conv2d(conv1, w['w2'], b['b2']) # Convolution\n    conv2 = maxpool2d(conv2) # Pooling\n    \n    # Layer 3\n    conv3 = conv2d(conv2, w['w3'], b['b3']) # Convolution\n    \n    # Layer 4\n    conv4 = conv2d(conv3, w['w4'], b['b4']) # Convolution\n    \n    # Layer 5\n    conv5 = conv2d(conv4, w['w5'], b['b5']) # Convolution\n    conv5 = maxpool2d(conv5) # Pooling\n    \n    # Layer 6\n    fc1 = tf.reshape(conv5, [-1, weights['w6'].get_shape().as_list()[0]]) # Channel Reshape\n    fc1 = tf.add(tf.matmul(fc1, w['w6']), b['b6']) # Linear Function\n    fc1 = tf.nn.relu(fc1) # Activation Function\n    \n    # Layer 7\n    fc2 = tf.add(tf.matmul(fc1, w['w7']), b['b7']) # Linear Function\n    fc2 = tf.nn.relu(fc2) # Activation Function\n    \n    # Layer 8\n    out = tf.add(tf.matmul(fc2, w['w8']), b['b8']) # Linear Function\n    \n    return out","91a80faa":"logits = alexnet(X, weights, biases) # Forward Propagation","9872bce3":"# Cost Function\nloss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = Y))\n# Optimizer\noptimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n# Training Operation\ntrain_op = optimizer.minimize(loss_op)","dea674f2":"correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))","d998c965":"init = tf.global_variables_initializer()","c7a269dd":"with tf.Session() as sess:\n    # Running Initializer\n    sess.run(init)\n    cost_hist, acc_hist = [], []\n    for epoch in range(1, epochs + 1):\n        _x, _y = next_batch(batch_size, x_train, y_train_encoded)\n        # Running Optimizer\n        sess.run(train_op, feed_dict = { X : _x, Y : _y })\n        if epoch % display_step == 0:\n            # Calculating Loss and Accuracy on the current Epoch\n            loss, acc = sess.run([loss_op, accuracy], feed_dict = { X : _x, Y : _y })\n            loss = loss\n            cost_hist.append(loss)\n            acc_hist.append(acc)\n            print('Epoch ' + str(epoch) + ', Cost: ' + str(loss) + ', Accuracy: ' + str(acc * 100) + ' %')\n    W = sess.run(weights)\n    B = sess.run(biases)\n    print('-' * 70)\n    print('\\nOptimization Finished\\n')","3f38342d":"plt.plot(list(range(len(cost_hist))), cost_hist)\nplt.title(\"Change in cost\")\nplt.xlabel('Epoch')\nplt.ylabel('Cost')\nplt.show()","b6c55e29":"plt.plot(list(range(len(acc_hist))), acc_hist)\nplt.title(\"Change in accuracy\")\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.show()","1305885e":"for key in weights.keys():\n    weights[key] = tf.Variable(W[key])\n    np.save(key, W[key])","d5b74183":"for key in biases.keys():\n    biases[key] = tf.Variable(B[key])\n    np.save(key, B[key])","4ff12b97":"logits = alexnet(X, weights, biases)\ncorrect_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\ninit = tf.global_variables_initializer()","fdff9c3f":"with tf.Session() as sess:\n    acc = []\n    sess.run(init)\n    for i in range(100, 29001, 100):\n        acc.append(sess.run(accuracy, feed_dict = { X : x_train[i - 100 : i], Y : y_train_encoded[i - 100 : i] }))\nprint('Accuracy on Training Data: ' + str(sum(acc) * 100 \/ len(acc)) + '%')","6cb992bc":"with tf.Session() as sess:\n    sess.run(init)\n    y_pred = sess.run(logits, feed_dict = { X : x_test })\n    acc = sess.run(accuracy, feed_dict = { X : x_test, Y : y_test_encoded }) * 100\nprint('Accuracy on Test Data: ' + str(acc) + '%')","76020250":"y_pred = [y_test[list(i).index(max(list(i)))] for i in y_pred]","b7dba6b0":"display_images(next_batch(12, x_test, y_pred), 'Predictions')","4db906f7":"## Data Visualization","7a5eb5ba":"AlexNet is the name of a convolutional neural network, invented by **Alex Krizhevsky**, **Ilya Sutskever** and **Geoffrey Hinton**. AlexNet has had a large impact on the field of machine learning, specifically in the application of deep learning to machine vision. As of 2018 it has been cited over 25,000 times.\n\nAlexNet competed in the [ImageNet Large Scale Visual Recognition Challenge](https:\/\/en.wikipedia.org\/wiki\/ImageNet#ImageNet_Challenge) in 2012. The network achieved a top-5 error of 15.3%, more than 10.8 percentage points lower than that of the runner up. The original paper's primary result was that the depth of the model was essential for its high performance, which was computationally expensive, but made feasible due to the utilization of GPUs during training.\n\nAlexNet contained eight layers; the first five were convolutional layers, and the last three were fully connected layers. It used the non-saturating `ReLU` activation function, which showed improved training performance over `tanh` and `sigmoid`.\n\n![](https:\/\/github.com\/Koderunners\/Convolutional-Neural-Networks\/blob\/master\/Images\/Alexnet.png)\n\n\nThe current implementation has been made using Tensorflow which utilizes 6 GB of Nvidia Tesla K80 GPU provided in Kaggle Kernels. This kernel was written by [Soumik Rakshit](https:\/\/www.kaggle.com\/soumikrakshit) and [Sohom Dey](https:\/\/www.kaggle.com\/sohom17d).","472cba6c":"## Data Preprocessing","f93fef9a":"## Training the Alexnet","42dd64df":"## Read Dataset","fa97b236":"## Importing Libraries","0fc6e801":"## Saving Optimized Parameters","60764054":"## Visualizing Predictions","1606958c":"## Alexnet Model","13ab5f89":"## Checking Accuracy","994ef8a3":"# Alexnet Architecture"}}