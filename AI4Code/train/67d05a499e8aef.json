{"cell_type":{"c22a80a4":"code","e4dc7fbc":"code","50a3b609":"code","d232d27c":"code","e0fddba3":"code","43673e85":"code","ba058860":"code","dd651817":"code","d1c52321":"code","38288c99":"markdown","0a452574":"markdown","1d568945":"markdown","98ce9ae7":"markdown","3954721f":"markdown","1d7703ce":"markdown","a461e353":"markdown","3ecfbac2":"markdown"},"source":{"c22a80a4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport sys\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nsys.path.append('\/kaggle\/input\/enron-project\/')\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e4dc7fbc":"import pickle\noriginal = \"\/kaggle\/input\/harshmi\/final_project_dataset.pkl\"\ndestination = \"modified_final_project_dataset.pkl\"\n\ncontent = ''\noutsize = 0\nwith open(original, 'rb') as infile:\n    content = infile.read()\nwith open(destination, 'wb') as output:\n    for line in content.splitlines():\n        outsize += len(line) + 1\n        output.write(line + str.encode('\\n'))","50a3b609":"def featureFormat( dictionary, features, remove_NaN=True, remove_all_zeroes=True, remove_any_zeroes=False, sort_keys = False):\n    return_list = []\n    if isinstance(sort_keys, str):\n        import pickle\n        keys = pickle.load(open(sort_keys, \"rb\"))\n    elif sort_keys:\n        keys = sorted(dictionary.keys())\n    else:\n        keys = dictionary.keys()\n\n    for key in keys:\n        tmp_list = []\n        for feature in features:\n            try:\n                dictionary[key][feature]\n            except KeyError:\n                print (\"error: key \", feature, \" not present\")\n                return\n            value = dictionary[key][feature]\n            if value==\"NaN\" and remove_NaN:\n                value = 0\n            tmp_list.append( float(value) )\n\n        # Logic for deciding whether or not to add the data point.\n        append = True\n        # exclude 'poi' class as criteria.\n        if features[0] == 'poi':\n            test_list = tmp_list[1:]\n        else:\n            test_list = tmp_list\n        ### if all features are zero and you want to remove\n        ### data points that are all zero, do that here\n        if remove_all_zeroes:\n            append = False\n            for item in test_list:\n                if item != 0 and item != \"NaN\":\n                    append = True\n                    break\n        ### if any features for a given data point are zero\n        ### and you want to remove data points with any zeroes,\n        ### handle that here\n        if remove_any_zeroes:\n            if 0 in test_list or \"NaN\" in test_list:\n                append = False\n        ### Append the data point if flagged for addition.\n        if append:\n            return_list.append( np.array(tmp_list) )\n\n    return np.array(return_list)\n\ndef targetFeatureSplit( data ):\n    target = []\n    features = []\n    for item in data:\n        target.append( item[0] )\n        features.append( item[1:] )\n\n    return target, features","d232d27c":"#Plots for Various Features\nenron_data = pickle.load(open(\"modified_final_project_dataset.pkl\", 'rb') )\nenron_data.pop('TOTAL')\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfig,a=plt.subplots(2,2,squeeze=False,figsize=(10,10))\n#Plotting Graphs for Various Factors\nx1=featureFormat(enron_data,[\"poi\",\"salary\",\"deferral_payments\"])\nfor y in range(len(x1)):\n    if x1[y][0]==True:\n        a[0][0].scatter(x1[y][1],x1[y][2],color='g')\n    else:\n        a[0][0].scatter(x1[y][1],x1[y][2],color='y')\nx2=featureFormat(enron_data,[\"poi\",\"total_payments\",\"loan_advances\"])\nfor z in range(len(x2)):\n    if x2[z][0]==True:\n        a[0][1].scatter(x2[z][1],x2[z][2],color='g')\n    else:\n        a[0][1].scatter(x2[z][1],x2[z][2],color='y')\nx3=featureFormat(enron_data,[\"poi\",\"total_stock_value\",\"exercised_stock_options\"])\nfor z in range(len(x3)):\n    if x3[z][0]==True:\n        a[1][0].scatter(x3[z][1],x3[z][2],color='g')\n    else:\n        a[1][0].scatter(x3[z][1],x3[z][2],color='y')\nx4=featureFormat(enron_data,[\"poi\",\"salary\",\"loan_advances\",\"deferral_payments\"])\nfor z in range(len(x4)):\n    if x4[z][0]==True:\n        a[1][1].scatter(x4[z][1],x4[z][2],color='g')\n    else:\n        a[1][1].scatter(x4[z][1],x4[z][2],color='y')\nplt.show()","e0fddba3":"#Introducing New Features\ndef dict_to_list(key,normalizer):\n    new_list=[]\n\n    for i in enron_data:\n        if enron_data[i][key]==\"NaN\" or enron_data[i][normalizer]==\"NaN\":\n            new_list.append(0.)\n        elif enron_data[i][key]>=0:\n            new_list.append(float(enron_data[i][key])\/float(enron_data[i][normalizer]))\n    return new_list\n\nfraction_from_poi_email=dict_to_list(\"from_poi_to_this_person\",\"to_messages\")\nfraction_to_poi_email=dict_to_list(\"from_this_person_to_poi\",\"from_messages\")\nj = 0\nfor i in enron_data:\n    enron_data[i][\"fraction_from_poi_email\"]=fraction_from_poi_email[j]\n    enron_data[i][\"fraction_to_poi_email\"]=fraction_to_poi_email[j]\n    j+=1","43673e85":"from sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn import metrics\nfrom sklearn import tree\nfeature_list = ['poi','shared_receipt_with_poi','fraction_from_poi_email','fraction_to_poi_email',\"deferral_payments\"]\nu = featureFormat(enron_data, feature_list)\nlabels, features = targetFeatureSplit(u)\nX_train, X_test, Y_train, Y_test = train_test_split(features, labels,test_size=0.2,random_state=42)\n#Accuracy Score is less by DecisionTree as compared to SVM\n#clf = tree.DecisionTreeRegressor()\n#clf.fit(X_train,Y_train)\n#print(accuracy_score(Y_test, clf.predict(X_test)))\n\n#Training the Algorithm using SVM\nfrom sklearn.svm import SVC\nsvmClassifier=SVC(kernel=\"rbf\",gamma=\"auto\")\nsvmClassifier.fit(X_train,Y_train)\nprint(accuracy_score(Y_test, svmClassifier.predict(X_test)))","ba058860":"#Evaluation using Confusing Matrix\ncm = metrics.confusion_matrix(Y_test,svmClassifier.predict(X_test))\nimport seaborn as sn\nsn.heatmap(cm, annot=True,  fmt='.2f', xticklabels = [\"Yes\", \"No\"] , yticklabels = [\"Yes\", \"No\"],)\nplt.ylabel('True label',fontsize=12)\nplt.xlabel('Predicted label',fontsize=12)\nplt.show()","dd651817":"#Classification Report\nprint(metrics.classification_report(Y_test,svmClassifier.predict(X_test),digits=2))","d1c52321":"pickle.dump(svmClassifier, open(\"my_classifier.pkl\", \"wb\") )\npickle.dump(enron_data, open(\"my_dataset.pkl\", \"wb\") )\npickle.dump(feature_list, open(\"my_feature_list.pkl\", \"wb\") )","38288c99":"# Converting New line characters in unix","0a452574":"# Classification Report","1d568945":"# Outputting the Data as Pickle File","98ce9ae7":"# Evaluation using Confusion Matrix","3954721f":"# Introducing New Features","1d7703ce":"# Training and Testing the ALGORITHM Using Different Model","a461e353":"# Defining Feature Format and Target list","3ecfbac2":"# Scatter Plot for Various Feature Lists "}}