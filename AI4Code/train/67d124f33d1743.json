{"cell_type":{"d3ba2788":"code","584ab618":"code","9809b50d":"code","5ae72fa9":"code","cfa617c1":"code","0ea4135e":"code","fb46081a":"code","4c8e1a7e":"code","503bacba":"code","cee68253":"code","d759dade":"code","546cfbb0":"code","32cb912a":"code","1e831ead":"code","d5377fd3":"markdown","8395da7f":"markdown","dbfea7f3":"markdown","b2223944":"markdown","f5e052d6":"markdown","be26958a":"markdown","49d16799":"markdown"},"source":{"d3ba2788":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression","584ab618":"data = pd.read_csv('..\/input\/employee-attrition-data\/MFG10YearTerminationData.csv')","9809b50d":"data","5ae72fa9":"data.info()","cfa617c1":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Drop unnecessary columns\n    df = df.drop(['EmployeeID', 'gender_short'], axis=1)\n    \n    # Drop all columns not available before termination\n    df = df.drop(['terminationdate_key', 'length_of_service', 'termreason_desc', 'termtype_desc'], axis=1)\n    \n    # Split df into X and y\n    y = df['STATUS']\n    X = df.drop('STATUS', axis=1)\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)\n    \n    return X_train, X_test, y_train, y_test","0ea4135e":"X_train, X_test, y_train, y_test = preprocess_inputs(data)","fb46081a":"X_train","4c8e1a7e":"# Let's build a transformer for date columns that will extract the year, month, and day features\nclass DateTransformer:\n    \n    def fit(self, X, y):\n        return self\n    \n    def transform(self, X):\n        for column in X.columns:\n            X[column] = pd.to_datetime(X[column])\n            X[column + '_year'] = X[column].apply(lambda x: x.year)\n            X[column + '_month'] = X[column].apply(lambda x: x.month)\n            X[column + '_day'] = X[column].apply(lambda x: x.day)\n            X = X.drop(column, axis=1)\n        return X","503bacba":"# Classify features by type\nbinary_features = [\n    'gender_full',\n    'BUSINESS_UNIT'\n]\nnominal_features = [\n    'city_name',\n    'department_name',\n    'job_title'\n]\ndate_features = [\n    'recorddate_key',\n    'birthdate_key',\n    'orighiredate_key'\n]\n\n# Construct transformers to handle each type of feature\nbinary_transformer = Pipeline(steps=[\n    ('ordinal', OrdinalEncoder(categories='auto'))\n])\nnominal_transformer = Pipeline(steps=[\n    ('nominal', OneHotEncoder())\n])\ndate_transformer = Pipeline(steps=[\n    ('date', DateTransformer())\n])","cee68253":"# Build a preprocessing transformer with ColumnTransformer\npreprocessor = ColumnTransformer(transformers=[\n    ('binary', binary_transformer, binary_features),\n    ('nominal', nominal_transformer, nominal_features),\n    ('date', date_transformer, date_features)\n], sparse_threshold=0)","d759dade":"# Build the final pipeline\nmodel = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('scaler', StandardScaler()),\n    ('classifier', LogisticRegression())\n])","546cfbb0":"model.fit(X_train, y_train)","32cb912a":"acc = model.score(X_test, y_test)\n\nprint(\"Test Accuracy: {:.2f}%\".format(acc * 100))","1e831ead":"sample_input = pd.DataFrame(pd.Series({\n      'recorddate_key': '6\/1\/2006',\n       'birthdate_key': '6\/28\/1944',\n    'orighiredate_key': '1\/3\/1993',\n                 'age': 65,\n           'city_name': 'Fort St John',\n     'department_name': 'Dairy',\n           'job_title': 'Dairy Person',\n          'store_name': 12,\n         'gender_full': 'Female',\n         'STATUS_YEAR': 2006,\n       'BUSINESS_UNIT': 'STORES'\n})).T\n\nprediction = model.predict(sample_input)\nprint(\"Model Prediction:\", prediction)","d5377fd3":"# Task for Today  \n\n***\n\n## Employee Attrition Prediction  \n\nGiven *data about employees at a company*, let's try to predict whether a given employee will **leave** the company.\n\nWe will use a logistic regression model to make our predictions.","8395da7f":"# Results","dbfea7f3":"# Building Pipeline","b2223944":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/Ci7pju1gNUY","f5e052d6":"# Training","be26958a":"# Initial Preprocessing","49d16799":"# Getting Started"}}