{"cell_type":{"65c90435":"code","883676f7":"code","e53c4f9e":"code","346ee7e3":"code","7c60e15f":"code","9d7fbfbe":"code","0698a2e8":"code","bb8b3b34":"code","7e78105e":"code","35abedc9":"code","12f24102":"code","d8c58a43":"code","f93667ed":"code","3b4dda61":"code","1651b6d4":"code","89d665f0":"code","1a314bbd":"markdown","18172241":"markdown","e008e83c":"markdown","78f08bfe":"markdown","b984a60b":"markdown"},"source":{"65c90435":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","883676f7":"# Familiar imports\nimport numpy as np\nimport pandas as pd\n\n# For ordinal encoding categorical variables, splitting data\nfrom sklearn.preprocessing import OrdinalEncoder,LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\n# For training random forest model\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\n# Pytorch Libraries\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader,TensorDataset\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor, Lambda, Compose\nimport matplotlib.pyplot as plt","e53c4f9e":"# Load the training data\ntrain = pd.read_csv(\"..\/input\/30-days-of-ml\/train.csv\", index_col=0)\ntest = pd.read_csv(\"..\/input\/30-days-of-ml\/test.csv\", index_col=0)\n\n# Preview the data\ntrain.head()\n\n# Separate target from features\ny = train[['target']]\nfeatures = train.drop(['target'], axis=1)\n\n# Preview features\nfeatures.head()\ny.shape","346ee7e3":"# List of categorical columns\nobject_cols = [col for col in features.columns if 'cat' in col]\n\n# ordinal-encode categorical columns\nX = features.copy()\nX_test = test.copy()\nordinal_encoder = OrdinalEncoder()\nX[object_cols] = ordinal_encoder.fit_transform(features[object_cols])\nX_test[object_cols] = ordinal_encoder.transform(test[object_cols])\n\n# Preview the ordinal-encoded features\nX.head()\n# X_test.values","7c60e15f":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=0)","9d7fbfbe":"batch_size = 500\n\n#Change to numpy arraay. \nX_train=X_train.values\ny_train=y_train.values\n\nX_valid=X_valid.values\ny_valid=y_valid.values\n\nX_test=X_test.values\n\nX_train=torch.FloatTensor(X_train)\ny_train=torch.FloatTensor(y_train)\ntrain_datasets = TensorDataset(X_train, y_train)\n\nX_valid=torch.FloatTensor(X_valid)\ny_valid=torch.FloatTensor(y_valid)\nvalid_datasets = TensorDataset(X_valid, y_valid)\n\nX_test=torch.FloatTensor(X_test)\n# Create data loaders.\ntrain_dataloader = DataLoader(train_datasets, batch_size=batch_size)\n\nvalid_dataloader = DataLoader(valid_datasets, batch_size=batch_size)\n\ntest_dataloader = DataLoader(X_test, batch_size=10000)\n","0698a2e8":"# Get cpu or gpu device for training.\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Using {} device\".format(device))\n\n# Define model\nclass NeuralNetwork(nn.Module):\n    def __init__(self):\n        super(NeuralNetwork, self).__init__()\n        self.fc1 = nn.Linear(24, 512)\n        self.fc2 = nn.Linear(512, 1024)\n        self.bn = nn.BatchNorm1d(1024)\n        self.fc3 = nn.Linear(1024, 128)\n        self.fc4 = nn.Linear(128, 8)\n        self.fc5 = nn.Linear(8, 1)\n        self.dropout = nn.Dropout(0.25)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.fc2(x)\n        x = self.dropout(x)\n        x = self.bn(x)\n        x = self.fc3(x)\n        x = self.fc4(x)\n        x = self.fc5(x)\n        return x\n\nmodel = NeuralNetwork().to(device)\nprint(model)","bb8b3b34":"loss_fn = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0005)","7e78105e":"def train(train_dataloader, model, loss_fn, optimizer):\n    size = len(train_dataloader.dataset)\n    model.train()\n    for batch, (X, y) in enumerate(train_dataloader):\n        X, y = X.to(device), y.to(device)\n\n        # Compute prediction error\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if batch % 100 == 0:\n            los, current = loss.item(), batch * len(X)\n            print(f\"loss: {los:>5f} ,loss: {loss.data:>5f} [{current:>5d}\/{size:>5d}]\")","35abedc9":"def testfn(valid_dataloader, model, loss_fn):\n    size = len(valid_dataloader.dataset)\n    num_batches = len(valid_dataloader)\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for X, y in valid_dataloader:\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n    test_loss \/= num_batches\n    print(f\"Test Error: \\n Avg loss: {test_loss:>8f} \\n\")","12f24102":"epochs = 35\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train(train_dataloader, model, loss_fn, optimizer)\n    testfn(valid_dataloader, model, loss_fn)\nprint(\"Done!\")","d8c58a43":"with torch.no_grad():\n    Xd = X_test.to(device)\n    predicted = model(Xd).cpu()","f93667ed":"predicted.unique()","3b4dda61":"predictions=predicted.data.numpy().flatten()","1651b6d4":"predictions.shape,test.index.shape","89d665f0":"# Save the predictions to a CSV file\noutput = pd.DataFrame({'Id': test.index,\n                       'target': predictions})\noutput.to_csv('submission.csv', index=False)","1a314bbd":"## Creating Models","18172241":"## Step 1: Importing helpful libraries","e008e83c":"## Step 3: Prepare the data","78f08bfe":"## Step 4 :prepare for torch","b984a60b":"## Step 2 : Load the data"}}