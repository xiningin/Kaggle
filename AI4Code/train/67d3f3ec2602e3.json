{"cell_type":{"8215d82d":"code","d3372693":"code","95217cc0":"code","353e07b4":"code","0195bb84":"code","1b0e123e":"code","b51896fe":"code","50d07531":"code","916f06bb":"code","542f497a":"code","eccb5308":"code","7e0b7528":"code","5f0d3018":"code","73e5bc9e":"code","c254a078":"code","eb993e01":"code","5560cabb":"code","ed6c03a9":"code","8acc7b97":"code","1a7eb4ef":"code","93476a9f":"code","3bcbda30":"code","27accdd5":"code","d32003c4":"code","dacb28fe":"code","866f198f":"code","d8a449ef":"markdown","a5f84ee4":"markdown","20b44dda":"markdown","99f2bdca":"markdown"},"source":{"8215d82d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","d3372693":"import numpy as np\nimport pandas as pd\n# read data\ntrain_data = pd.read_csv(\"..\/input\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/test.csv\")\nprint(\"Load data sucessfully!\")","95217cc0":"print(\"Begin Data Processing\")\n# understand data\nprint(train_data.head())\nprint(test_data.head())","353e07b4":"# convert pd to np\ntrain_data = train_data.values\ntest_data = test_data.values\nprint(train_data.shape)\nprint(test_data.shape)","0195bb84":"# split to X,y,  and norm X\nX_train = train_data[:,1:].reshape(-1,1,28,28)\/255\ny_train = train_data[:,0:1]","1b0e123e":"# # one-hot encoder\n# from sklearn.preprocessing import OneHotEncoder\n# #https:\/\/machinelearningmastery.com\/how-to-one-hot-encode-sequence-data-in-python\/\n# onehot_encoder = OneHotEncoder(sparse=False)\n# y_train = onehot_encoder.fit_transform(y_train)","b51896fe":"# split to train valid\nfrom sklearn.model_selection import train_test_split\n#https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.train_test_split.html\nX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train,\n                                                      test_size=0.2, random_state=2019)","50d07531":"print(X_train.shape)\nprint(X_valid.shape)\nprint(y_train.shape)\nprint(y_valid.shape)\nprint(\"Data Processing Successful!\")","916f06bb":"# #https:\/\/pytorch.org\/tutorials\/beginner\/transfer_learning_tutorial.html\n# # Data augmentation and normalization for training\n# # Just normalization for validation\n# data_transforms = {\n#     'train': transforms.Compose([\n#         transforms.RandomResizedCrop(224),\n#         transforms.RandomHorizontalFlip(),\n#         transforms.ToTensor(),\n#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n#     ]),\n#     'val': transforms.Compose([\n#         transforms.Resize(256),\n#         transforms.CenterCrop(224),\n#         transforms.ToTensor(),\n#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n#     ]),\n# }\n\n# data_dir = 'data\/hymenoptera_data'\n# image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n#                                           data_transforms[x])\n#                   for x in ['train', 'val']}\n# dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n#                                              shuffle=True, num_workers=4)\n#               for x in ['train', 'val']}\n# dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n# class_names = image_datasets['train'].classes\n\n# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","542f497a":"# model parameters\nX_channel = 1\nfilter1, kernel1, padding1, max_pooling1 = 16, 3, 1, 2\nfilter2, kernel2, padding2, max_pooling2 = 32, 3, 1, 2\nfilter3, kernel3, padding3, max_pooling3 = 64, 3, 1, 2\ndense0, dense1, dense2, dense3 = 64*3*3, 120, 64, 10","eccb5308":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n#https:\/\/pytorch.org\/tutorials\/beginner\/blitz\/neural_networks_tutorial.html\nclass Net(nn.Module):\n\n    def __init__(self):\n        super(Net, self).__init__()\n        # convolution layers\n        self.conv1 = nn.Conv2d(X_channel, filter1, kernel1, padding=padding1) \n        self.conv2 = nn.Conv2d(filter1, filter2, kernel2, padding=padding2) \n        self.conv3 = nn.Conv2d(filter2, filter3, kernel3, padding=padding3) \n        \n        # fully connect\n        self.fc1 = nn.Linear(dense0, dense1)\n        self.fc2 = nn.Linear(dense1, dense2)\n        self.fc3 = nn.Linear(dense2, dense3)\n        \n    def forward(self, X):\n        X = F.max_pool2d(F.relu(self.conv1(X)), max_pooling1)\n        X = F.max_pool2d(F.relu(self.conv2(X)), max_pooling2)\n        X = F.max_pool2d(F.relu(self.conv3(X)), max_pooling3)\n        X = X.view(-1,dense0)\n        X = F.relu(self.fc1(X))\n        X = F.relu(self.fc2(X))\n        X = self.fc3(X)\n        return X\n\nnet = Net()\nprint(net)","7e0b7528":"# set train parameters\n# https:\/\/github.com\/zergtant\/pytorch-handbook\/blob\/master\/chapter3\/3.2-mnist.ipynb\nbatch_size = 512 #\u5927\u6982\u9700\u89812G\u7684\u663e\u5b58\nEPOCH = 200 # \u603b\u5171\u8bad\u7ec3\u6279\u6b21\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n# \u8ba9torch\u5224\u65ad\u662f\u5426\u4f7f\u7528GPU\uff0c\u5efa\u8bae\u4f7f\u7528GPU\u73af\u5883\uff0c\u56e0\u4e3a\u4f1a\u5feb\u5f88\u591a\nprint(device)","5f0d3018":"import torch.utils.data","73e5bc9e":"# Pytorch train and test sets\n#https:\/\/www.kaggle.com\/kanncaa1\/pytorch-tutorial-for-deep-learning-lovers\/notebook\ntrain = torch.utils.data.TensorDataset(torch.from_numpy(X_train).float(),\n                                       torch.from_numpy(y_train).long())\n# https:\/\/blog.csdn.net\/baidu_36639782\/article\/details\/86641866\nvalid = torch.utils.data.TensorDataset(torch.from_numpy(X_valid).float(),\n                                      torch.from_numpy(y_valid).long())\n\n# data loader\ntrain_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = True)\nvalid_loader = torch.utils.data.DataLoader(valid, batch_size = batch_size, shuffle = False)","c254a078":"def train(model, device, train_loader, optimizer, criterion):\n    model.train()#\u628amodule\u8bbe\u6210training\u6a21\u5f0f\uff0c\u5bf9Dropout\u548cBatchNorm\u6709\u5f71\u54cd\n#     best_model_wts = copy.deepcopy(model.state_dict())\n#     best_acc = 0.0\n    running_loss = 0.0\n    running_corrects = 0            \n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        #https:\/\/stackoverflow.com\/questions\/49206550\/ ...\n        #...   pytorch-error-multi-target-not-supported-in-crossentropyloss\n        preds = torch.argmax(output, 1)\n        loss = criterion(output, target.squeeze_())\n        loss.backward()\n        optimizer.step()\n        # statistics\n        running_loss += loss.item() * data.size(0)\n        running_corrects += torch.sum(preds == target)\n    epoch_loss = running_loss \/ len(X_train)\n    epoch_acc = running_corrects.double() \/ len(X_train)\n    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\"Training\", epoch_loss, epoch_acc))","eb993e01":"def valid(model, device, test_loader, criterion):\n    model.eval()#\u628amodule\u8bbe\u7f6e\u4e3a\u8bc4\u4f30\u6a21\u5f0f\uff0c\u53ea\u5bf9Dropout\u548cBatchNorm\u6a21\u5757\u6709\u5f71\u54cd\n#     best_model_wts = copy.deepcopy(model.state_dict())\n#     best_acc = 0.0\n    running_loss = 0.0\n    running_corrects = 0     \n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            preds = torch.argmax(output, 1)\n            loss = criterion(output, target.squeeze_())\n            running_loss += loss.item() * data.size(0)\n            running_corrects += torch.sum(preds == target)\n    epoch_loss = running_loss \/ len(X_valid)\n    epoch_acc = running_corrects.double() \/ len(X_valid)\n    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\"valid\", epoch_loss, epoch_acc))\n    return epoch_acc","5560cabb":"import torch.optim as optim\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(net.parameters())\nmodel = net.to(device)\nimport time,copy\nsince = time.time()\nbest_model_wts = copy.deepcopy(model.state_dict())\nbest_acc = 0.0\n\nfor epoch in range(1, EPOCH + 1):\n\n    print('Epoch {}\/{}:'.format(epoch, EPOCH))\n    print('-' * 10)\n    train(model, device, train_loader, optimizer, criterion)\n    epoch_acc = valid(model, device, valid_loader, criterion)\n    if best_acc<epoch_acc:\n        best_acc = epoch_acc\n        best_model_wts = copy.deepcopy(model.state_dict())\n    else:\n        print(\"best acc is {:.4f}\".format(best_acc))\ntime_elapsed = time.time() - since\nprint('Training complete in {:.0f}m {:.0f}s'.format(\n    time_elapsed \/\/ 60, time_elapsed % 60))\nprint('Best val Acc: {:4f}'.format(best_acc))","ed6c03a9":"model.load_state_dict(best_model_wts)","8acc7b97":"X_test = test_data.reshape(-1,1,28,28)\/255\ntest = torch.utils.data.TensorDataset(torch.from_numpy(X_test).float())\n\n# data loader\ntest_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = False)","1a7eb4ef":"def test(model, device, test_loader, criterion):\n    model.eval()#\u628amodule\u8bbe\u7f6e\u4e3a\u8bc4\u4f30\u6a21\u5f0f\uff0c\u53ea\u5bf9Dropout\u548cBatchNorm\u6a21\u5757\u6709\u5f71\u54cd\n#     best_model_wts = copy.deepcopy(model.state_dict())\n#     best_acc = 0.0\n    ans = []\n    with torch.no_grad():\n        for data in test_loader:\n            data = data[0].to(device)\n            output = model(data)\n            preds = torch.argmax(output, 1)\n            ans.append(preds)\n    return ans","93476a9f":"Ans = test(model, device, test_loader, criterion)","3bcbda30":"Ans = torch.cat(Ans).cpu().numpy()","27accdd5":"Ans","d32003c4":"res = pd.read_csv(\"..\/input\/sample_submission.csv\")","dacb28fe":"res[\"Label\"] = Ans","866f198f":"res.to_csv(\"res.csv\",index=False)","d8a449ef":"# Section 4: predict testing data","a5f84ee4":"# Section 3: build trainer","20b44dda":"# Section 2: build CNN model","99f2bdca":"# section 1: Data Preprocessing"}}