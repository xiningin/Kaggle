{"cell_type":{"b4f249fe":"code","4429a882":"code","392e86c3":"code","a5e28123":"code","7ce0f8ac":"code","ff5a58b4":"code","cc3b5d20":"code","ccd01a42":"code","127f2cad":"code","2af76cf5":"code","f5267c3a":"code","498fae83":"code","1992a360":"code","664ef846":"code","4134076d":"code","80e7531d":"code","00543205":"code","642ff766":"code","11b569f6":"code","1d72ab92":"code","3159cac5":"code","46e294b1":"code","0ce290c5":"code","7d5d941d":"code","11e1934c":"code","72394fb0":"code","569ab4ae":"code","8f7b65b0":"code","fd4d7355":"code","6a2ca17d":"code","5baee492":"code","36b76d44":"code","21ae9523":"markdown","733a81dd":"markdown","63b0c92d":"markdown","33c9cc4c":"markdown","678d9bec":"markdown","69037ee1":"markdown","f859877a":"markdown"},"source":{"b4f249fe":"# This code works till numpy version 1.19.5\n# Please look for a solution if you want it to work wwith numpy version 1.20\nimport pandas as pd\nimport tensorflow as tf","4429a882":"df = pd.read_csv('..\/input\/fake-news\/train.csv')","392e86c3":"df.head()","a5e28123":"#check if the gpu is accessible here or not\ntf.test.is_gpu_available(cuda_only=True) ","7ce0f8ac":"# checking for nan values\ndf.isnull().sum()","ff5a58b4":"# dropping the nan values\ndf.dropna()","cc3b5d20":"#Storing the dependent variables\nX = df.drop([\"label\"],1)","ccd01a42":"# Storing the independent variable\ny= df[\"label\"]","127f2cad":"X.shape, y.shape","2af76cf5":"from tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout","f5267c3a":"# Now we set the vocabulary size\nvoc_size = 5000","498fae83":"messages=X.copy()\nmessages['title'][1]","1992a360":"# We are resetting indexes here because of the dropped nan values above\nmessages.reset_index(inplace=True)","664ef846":"import nltk\n# re = regular expression\nimport re\n# stopwords is used so as to remove the not so important words\nfrom nltk.corpus import stopwords","4134076d":"nltk.download('stopwords')","80e7531d":"\nfrom nltk.stem.porter import PorterStemmer\nps = PorterStemmer()\ncorpus = []\nfor i in range(0, len(messages)):\n    print(i)\n#     substituting everything with a blank space\n    review = re.sub('[^a-zA-Z]', ' ', str(messages['title'][i]))\n    review = review.lower()\n    review = review.split()\n    \n    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n    review = ' '.join(review)\n    corpus.append(review)","00543205":"corpus","642ff766":"onehot_repr=[one_hot(words,voc_size)for words in corpus] \nonehot_repr","11b569f6":"sent_length=20\nembedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\nprint(embedded_docs)","1d72ab92":"embedded_docs[0]","3159cac5":"embedded_docs","46e294b1":"## Now we start creating the model for it\nembedding_vector_features=40\nmodel=Sequential()\nmodel.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n# model.add(Dropout(0.3))\nmodel.add(LSTM(100))\n# model.add(Dropout(0.3))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n","0ce290c5":"print(model.summary())","7d5d941d":"len(embedded_docs),y.shape","11e1934c":"import numpy as np\nX_final=np.array(embedded_docs)\ny_final=np.array(y)","72394fb0":"X_final.shape,y_final.shape","569ab4ae":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=42)","8f7b65b0":"### Finally Training\nmodel.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=64)","fd4d7355":"from tensorflow.keras.layers import Dropout\n# setting seed to not get different values every time\nimport tensorflow\ntensorflow.random.set_seed(42)\n## Creating model\nembedding_vector_features=40\nmodel=Sequential()\nmodel.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\nmodel.add(Dropout(0.3))\nmodel.add(LSTM(100))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","6a2ca17d":"y_pred=model.predict_classes(X_test)","5baee492":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test,y_pred)","36b76d44":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test,y_pred)","21ae9523":"# Model Training","733a81dd":"# Embedding Representation","63b0c92d":"# Performance Metrics And Accuracy","33c9cc4c":"# Dataset Preprocessing and cleaning","678d9bec":"# OneHot Representation","69037ee1":"# Model Creation","f859877a":"# Adding Dropout"}}