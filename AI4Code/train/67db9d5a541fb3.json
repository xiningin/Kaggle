{"cell_type":{"e0211e44":"code","dc2d72a5":"code","bba09453":"code","ad5f6f77":"code","d0f71a45":"code","e5fde856":"code","cfec90ea":"code","5949672f":"code","814c4157":"code","f399936f":"code","a0b49e90":"code","fa132602":"code","832d7b8a":"code","9a3882b7":"code","d2d9b76f":"code","42115973":"code","d9d45642":"code","91dfda33":"code","61af9a5b":"code","714d9678":"code","3ba5eb6b":"code","ca0d118f":"code","7e5fd904":"code","7f1e7bd7":"code","acc7804e":"code","30067182":"code","2d6ec868":"code","874254f4":"code","315b0b5f":"code","4786c7ef":"code","9abc6e00":"code","65940051":"code","40364684":"code","2b1e10f0":"code","0bcfcbe7":"code","10ae898b":"code","c8c5075e":"code","99685a03":"code","523f56bb":"code","2f00a899":"code","c36fef68":"code","542dd284":"code","d2182858":"code","425c034a":"code","8eab13a2":"code","9acc13ba":"code","4abede4c":"code","506dcf73":"code","3d008579":"code","b7d55c1d":"code","ca904b25":"code","7428034d":"code","901b9c8d":"code","ee880340":"code","f0c13eec":"markdown","5be84a54":"markdown","7df8e1f7":"markdown","ec50877f":"markdown","bd053673":"markdown","91ea0666":"markdown","ed06bd53":"markdown","feff9c81":"markdown","852f249e":"markdown","73e35b7e":"markdown","db3cbf7b":"markdown","7bc1129d":"markdown","3efd8338":"markdown","9487d376":"markdown","74d9b24f":"markdown","bc56c5e7":"markdown","65b0ea9d":"markdown","622d93df":"markdown","320781e1":"markdown","23e5df3d":"markdown","d34f7673":"markdown","7e940d57":"markdown","1a2591c3":"markdown","32281883":"markdown","5d3af0ef":"markdown","0037ddf0":"markdown","3a98ebc2":"markdown","9715cc08":"markdown"},"source":{"e0211e44":"import numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n\n# ML classifier\nfrom sklearn.tree import DecisionTreeClassifier\nimport sklearn.model_selection as ms\nfrom sklearn.ensemble import RandomForestClassifier\n\n# scaling\nfrom sklearn.preprocessing import StandardScaler\n\n# Data imputation\n!pip install imbalanced-learn\nfrom imblearn.over_sampling import SMOTE \n\n# pipe\nfrom sklearn.pipeline import Pipeline\n\n# ML classifier model Evaluation\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\n\nplt.style.use('fivethirtyeight')\n\n# plotly offline\nfrom plotly.offline import download_plotlyjs,init_notebook_mode\ninit_notebook_mode(connected=True)\n\n","dc2d72a5":"train = pd.read_csv('..\/input\/hr-analytics-job-change-of-data-scientists\/aug_train.csv')\ntest = pd.read_csv('..\/input\/hr-analytics-job-change-of-data-scientists\/aug_test.csv')","bba09453":"train.head()","ad5f6f77":"train.info()","d0f71a45":"# checking for duplicates\n\nsim = train.duplicated() \nsim.sum()","e5fde856":"# Missing value\nmissing_value = 100 * train.isnull().sum()\/len(train)\nmissing_value = missing_value.reset_index()\nmissing_value.columns = ['variables','missing values in percentage']\n\n#import plotly.io as pio\n#pio.templates.default = \"none\"\n\n\n# heatmap\nfig = px.imshow(train.isnull().T,template='ggplot2')\nfig.update_layout(title='Missing values in data set')\nfig.show()\n\n# barplot\nfig = px.bar(missing_value, y='missing values in percentage',x='variables',title='Missing values % in each column',\n             template='ggplot2');\nfig.show()\n","cfec90ea":"# city\n\nplot_city = train['city'].value_counts()[0:50].reset_index()\nplot_city.columns = ['City','Count']\n\npx.bar(plot_city,x='City',y='Count',template='gridon',title='City',color='Count')","5949672f":"# CDI distribution\nplt.figure(figsize=(10,6))\nsns.distplot(train['city_development_index'],bins=15,color='#FF5733');\nplt.title('city_development_index distribution');","814c4157":"plot_cdi =train['city_development_index'].value_counts().reset_index()[0:50] \nplot_cdi.columns = ['cdi','Count']\nplot_cdi['cdi'] = plot_cdi['cdi'].astype('str')\npx.bar(plot_cdi,y=\"Count\", x=\"cdi\",color='Count',title='City development index')\n","f399936f":"plot_cdi =train['city_development_index'].value_counts().reset_index()[0:50] \nplot_cdi.columns = ['cdi','Count']\npx.scatter(plot_cdi,x=\"Count\", y=\"cdi\",color='Count',size=\"Count\",title='City development index',template='plotly_dark')","a0b49e90":"plot_gender = train['relevent_experience'].value_counts().reset_index()\nplot_gender.columns = ['gender','count']\n\npx.pie(plot_gender,values='count',names='gender',template='ggplot2',title='Gender')","fa132602":"plot_gender = train['relevent_experience'].value_counts().reset_index()\nplot_gender.columns = ['relevent_experience','count']\n\npx.pie(plot_gender,values='count',names='relevent_experience',title='relevent_experience')\n    ","832d7b8a":"plot_gender = train['enrolled_university'].value_counts().reset_index()\nplot_gender.columns = ['enrolled_university','count']\n\npx.pie(plot_gender,values='count',names='enrolled_university',template='simple_white',title='enrolled_university')","9a3882b7":"plot_gender = train['education_level'].value_counts().reset_index()\nplot_gender.columns = ['education_level','count']\n\npx.pie(plot_gender,values='count',names='education_level',template='ggplot2',title='education_level')","d2d9b76f":"plot_gender = train['major_discipline'].value_counts().reset_index()\nplot_gender.columns = ['major_discipline','count']\n\npx.pie(plot_gender,values='count',names='major_discipline',template='plotly',title='Major discipline')","42115973":"plot_gender = train['company_size'].value_counts().reset_index()\nplot_gender.columns = ['company_size','count']\n\npx.pie(plot_gender,values='count',names='company_size',template='plotly_white',title='company_size is determined by no. of people employees')","d9d45642":"train_mice = train.copy()","91dfda33":"# step 1 visual check for to ensure null vales are not represented with other values like -999, -1, ?,-111\n\nfor feature in train_mice.columns:\n    print('*******','Column name:',feature,'*******')\n    print(train_mice[feature].unique())\n    print('***********-end-***********')\n    print(' ')","61af9a5b":"# ******* Column name: enrolled_university *******\ntrain_mice['enrolled_university'] = train_mice['enrolled_university'].map({'no_enrollment':int(0),'Full time course':int(1) ,'Part time course':int(-1)})","714d9678":"# ******* Column name: education_level *******\ntrain_mice['education_level'] = train_mice['education_level'].map({'Graduate':int(0),'Masters':int(1) ,'High School':int(-1),\n                                                                   'Phd':int(2),'Primary School':int(3)})","3ba5eb6b":"# ******* Column name: gender *******\ntrain_mice['gender'] = train_mice['gender'].map({'Female':int(0),'Male':int(1) ,'Other':int(-1)})","ca0d118f":"# ******* Column name: experience *******\n\ntrain_mice['experience'] = train_mice['experience'].map({'>20':int(20), '15':int(15),  '5':int(5), '<1':int(-1), '11':int(11), \n                                               '13':int(13), '7':int(7), '17':int(17),\n                                               '2':int(7), '16':int(16), '1':int(1), '4':int(4), '10':int(10),\n                                               '14':int(14), '18':int(18),'19':int(19), '12':int(12), '3':int(3), \n                                               '6':int(6), '9':int(9), '8':int(8), '20':int(20)})","7e5fd904":"# ******* Column name: company_size *******\n\ntrain_mice['company_size'] = train_mice['company_size'].map({'50-99':int(0), '<10':int(-1), '10000+':int(1), '5000-9999':int(2), \n                                                   '1000-4999':int(3), '10\/49':int(4), '100-500':int(5),'500-999':int(6)})","7f1e7bd7":"# ******* Column name: company_type *******\n\ntrain_mice['company_type'] = train_mice['company_type'].map({'Pvt Ltd':int(0), 'Funded Startup':int(-1), 'Early Stage Startup':int(2), 'Other':int(3),'Public Sector':int(4), 'NGO':int(5)})","acc7804e":"# ******* Column name: last_new_job *******\n\ntrain_mice['last_new_job'] = train_mice['last_new_job'].map({'1':int(-1), '>4':int(0), 'never':int(1), '4':int(4), '3':int(3), '2':int(2)})","30067182":"train_mice['major_discipline'] = train_mice['major_discipline'].map({'STEM':int(-1) ,'Business Degree':int(0), 'Arts':int(1) ,'Humanities':int(2) ,'No Major':int(3) ,'Other':int(4)})","2d6ec868":"# Multivariate imputation by chained equations (MICE)\n\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\nmice_imputer = IterativeImputer()","874254f4":"#  filling null values with MICE for train set\n\ntrain_mice['gender'] = mice_imputer.fit_transform(train_mice[['gender']])\ntrain_mice['gender'] = round(train_mice['gender'])\n\ntrain_mice['education_level'] = mice_imputer.fit_transform(train_mice[['education_level']])\ntrain_mice['education_level'] = round(train_mice['education_level'])\n\ntrain_mice['enrolled_university']= mice_imputer.fit_transform(train_mice[['enrolled_university']])\ntrain_mice['enrolled_university'] = round(train_mice['enrolled_university'])\n\ntrain_mice['experience']= mice_imputer.fit_transform(train_mice[['experience']])\ntrain_mice['experience'] = round(train_mice['experience'])\n\ntrain_mice['company_size']= mice_imputer.fit_transform(train_mice[['company_size']])\ntrain_mice['company_size'] = round(train_mice['company_size'])\n\ntrain_mice['company_type']= mice_imputer.fit_transform(train_mice[['company_type']])\ntrain_mice['company_type'] = round(train_mice['company_type'])\n\ntrain_mice['last_new_job']= mice_imputer.fit_transform(train_mice[['last_new_job']])\ntrain_mice['last_new_job'] = round(train_mice['last_new_job'])\n\ntrain_mice['major_discipline']= mice_imputer.fit_transform(train_mice[['major_discipline']])\ntrain_mice['major_discipline'] = round(train_mice['major_discipline'])","315b0b5f":"# these two independent variable does have any null values so just converting to categorical\n\ntrain_mice['city'] = pd.Categorical(train_mice['city']).codes\ntrain_mice['relevent_experience'] = pd.Categorical(train_mice['relevent_experience']).codes\n","4786c7ef":"# null values check\n\ntrain_mice.isnull().sum()","9abc6e00":"# imputation  for test set\n\ntest['enrolled_university'] = test['enrolled_university'].map({'no_enrollment':int(0),'Full time course':int(1) ,'Part time course':int(-1)})\n# ******* Column name: gender *******\ntest['gender'] = test['gender'].map({'Female':int(0),'Male':int(1) ,'Other':int(-1)})\n# ******* Column name: experience *******\n\ntest['experience'] = test['experience'].map({'>20':int(20), '15':int(15),  '5':int(5), '<1':int(-1), '11':int(11), \n                                               '13':int(13), '7':int(7), '17':int(17),\n                                               '2':int(7), '16':int(16), '1':int(1), '4':int(4), '10':int(10),\n                                               '14':int(14), '18':int(18),'19':int(19), '12':int(12), '3':int(3), \n                                               '6':int(6), '9':int(9), '8':int(8), '20':int(20)})\n# ******* Column name: company_size *******\n\ntest['company_size'] = test['company_size'].map({'50-99':int(0), '<10':int(-1), '10000+':int(1), '5000-9999':int(2), \n                                                   '1000-4999':int(3), '10\/49':int(4), '100-500':int(5),'500-999':int(6)})\n# ******* Column name: company_type *******\n\ntest['company_type'] = test['company_type'].map({'Pvt Ltd':int(0), 'Funded Startup':int(-1), 'Early Stage Startup':int(2), 'Other':int(3),'Public Sector':int(4), 'NGO':int(5)})\n\n# ******* Column name: last_new_job *******\n\ntest['last_new_job'] = test['last_new_job'].map({'1':int(-1), '>4':int(0), 'never':int(1), '4':int(4), '3':int(3), '2':int(2)})\n\ntest['major_discipline'] = test['major_discipline'].map({'STEM':int(-1) ,'Business Degree':int(0), 'Arts':int(1) ,'Humanities':int(2) ,'No Major':int(3) ,'Other':int(4)})\n\n# ******* Column name: education_level *******\ntest['education_level'] = test['education_level'].map({'Graduate':int(0),'Masters':int(1) ,'High School':int(-1),\n                                                                   'Phd':int(2),'Primary School':int(3)})","65940051":"# these two independent variable does have any null values so just converting to categorical\n\ntest['city'] = pd.Categorical(test['city']).codes\ntest['relevent_experience'] = pd.Categorical(test['relevent_experience']).codes","40364684":"#  filling null values with MICE for train set\n\ntest['gender'] = mice_imputer.fit_transform(test[['gender']])\ntest['gender'] = round(test['gender'])\n\ntest['education_level'] = mice_imputer.fit_transform(test[['education_level']])\ntest['education_level'] = round(test['education_level'])\n\ntest['enrolled_university']= mice_imputer.fit_transform(test[['enrolled_university']])\ntest['enrolled_university'] = round(test['enrolled_university'])\n\ntest['experience']= mice_imputer.fit_transform(test[['experience']])\ntest['experience'] = round(test['experience'])\n\ntest['company_size']= mice_imputer.fit_transform(test[['company_size']])\ntest['company_size'] = round(test['company_size'])\n\ntest['company_type']= mice_imputer.fit_transform(test[['company_type']])\ntest['company_type'] = round(test['company_type'])\n\ntest['last_new_job']= mice_imputer.fit_transform(test[['last_new_job']])\ntest['last_new_job'] = round(test['last_new_job'])\n\ntest['major_discipline']= mice_imputer.fit_transform(test[['major_discipline']])\ntest['major_discipline'] = round(test['major_discipline'])","2b1e10f0":"# data split\n\nX_train = train_mice[['city', 'city_development_index', 'gender',\n       'relevent_experience', 'enrolled_university', 'education_level',\n       'major_discipline', 'experience', 'company_size', 'company_type',\n       'last_new_job', 'training_hours']]\n\n\ntrain_labels = train_mice['target']","0bcfcbe7":"X_test =test[[ 'city', 'city_development_index', 'gender',\n       'relevent_experience', 'enrolled_university', 'education_level',\n       'major_discipline', 'experience', 'company_size', 'company_type',\n       'last_new_job', 'training_hours']]","10ae898b":"# test labels loaded from file\n\ntest_labels = np.load('..\/input\/job-change-dataset-answer\/jobchange_test_target_values.npy')","c8c5075e":"rf_pipe = Pipeline(steps =[ ('std_scale',StandardScaler()), (\"RF\",RandomForestClassifier(random_state=0,max_depth= 10, max_features= 5,min_samples_leaf= 30, min_samples_split= 100, n_estimators= 500))])\nrf_pipe.fit(X_train,train_labels)\n\ndt_pipe = Pipeline(steps =[ ('_std_scale',StandardScaler()), (\"DT\",DecisionTreeClassifier(criterion='gini',max_features=10, max_depth=10, min_samples_leaf=15, min_samples_split=100,random_state=0)) ])\ndt_pipe.fit(X_train,train_labels)","99685a03":"# fit random forest model\nrf_pipe.fit(X_train,train_labels)","523f56bb":"# fit decision Tree model\ndt_pipe.fit(X_train,train_labels)\n","2f00a899":"feature_importances = pd.Series(rf_pipe.steps[1][1].feature_importances_, index=X_train.columns);\nfeature_importances.nlargest(15).plot(kind='barh');\nplt.title('Random forest feature_importances');","c36fef68":"rf_train_predict = rf_pipe.predict(X_train)\nrf_test_predict = rf_pipe.predict(X_test)\n\ndt_train_predict = dt_pipe.predict(X_train)\ndt_test_predict = dt_pipe.predict(X_test)","542dd284":"print('Random Forest classification_report on test_set')\nprint(' ')\nprint(classification_report(test_labels, rf_test_predict))","d2182858":"print('Random Forest classification_report on train_set')\nprint(' ')\nprint(classification_report(train_labels, rf_train_predict))\n","425c034a":"print('Decision Tree classification_report on test_set')\nprint(' ')\nprint(classification_report(test_labels, dt_test_predict))","8eab13a2":"print('Decision Tree classification_report on train_set')\nprint(' ')\nprint(classification_report(train_labels, dt_train_predict))","9acc13ba":"# probability for DT\nrf_probs_train = rf_pipe.predict_proba(X_train)\nrf_probs_train = rf_probs_train[:, 1]\n\nrf_probs_test = rf_pipe.predict_proba(X_test)\nrf_probs_test = rf_probs_test[:, 1]\n\n# probability for DT\ndt_probs_train = dt_pipe.predict_proba(X_train)\ndt_probs_train = dt_probs_train[:, 1]\n\ndt_probs_test = dt_pipe.predict_proba(X_test)\ndt_probs_test = dt_probs_test[:, 1]","4abede4c":"auc_RF_train = roc_auc_score(train_labels, rf_probs_train)\nauc_RF_test = roc_auc_score(test_labels, rf_probs_test)\n\nauc_dt_train = roc_auc_score(train_labels, dt_probs_train)\nauc_dt_test = roc_auc_score(test_labels, dt_probs_test)\n\nprint('Random forest auc on train set',auc_RF_train)\nprint('Random forest auc on test set',auc_RF_test)\nprint(' ')\nprint('Decision tree auc on train set',auc_dt_train)\nprint('Decision tree auc on test set',auc_dt_test)","506dcf73":"plt.style.use('seaborn-whitegrid')\nfpr_train, tpr_train, thresholds_train = roc_curve(train_labels, rf_probs_train)\nfpr_test, tpr_test, thresholds_test = roc_curve(test_labels, rf_probs_test)\n\nfig, (ax1, ax2) = plt.subplots(1, 2,figsize=(12,4))\n\nax1.plot([0, 1], [0, 1], linestyle='--');\nax1.plot(fpr_train, tpr_train, marker='.');\nax1.set_title('ROC_Curve for random forest on train');\n\nax2.plot([0, 1], [0, 1], linestyle='--');\nax2.plot(fpr_test, tpr_test, marker='.');\nax2.set_title('ROC_Curve for random forest on test set');","3d008579":"# plot the roc curve for the random forest model\n\nplt.style.use('seaborn-whitegrid')\n\n\nfpr_test_dt, tpr_test_dt, thresholds_test_dt = roc_curve(test_labels, dt_probs_test)\nfpr_train_dt, tpr_train_dt, thresholds_train_dt = roc_curve(train_labels,dt_probs_train)\n\n\nfig, (ax1, ax2) = plt.subplots(1, 2,figsize=(12,4))\n\nax1.plot([0, 1], [0, 1], linestyle='--');\nax1.plot(fpr_train_dt, tpr_train_dt, marker='.');\nax1.set_title('ROC_Curve for Decision tree on test set');\n\nax2.plot([0, 1], [0, 1], linestyle='--');\nax2.plot(fpr_test_dt, tpr_test_dt, marker='.');\nax2.set_title('ROC_Curve for Decision tree on test set');","b7d55c1d":"predict = rf_pipe.predict_proba(X_test)\npredict = predict[:, 1]","ca904b25":"# Create a  DataFrame\n\nsubmission = pd.DataFrame({'enrollee_id':test['enrollee_id'],'target':predict})","7428034d":"submission.head(10)","901b9c8d":"print('Decision tree auc on train set',auc_dt_train)\nprint('Decision tree auc on test data',auc_dt_train)\n\nprint(' ')\nprint('Random forest auc on train set',auc_RF_train)\nprint('Random forest auc on test data',auc_RF_test)\n\n","ee880340":"submission.to_csv('submission.csv',index=False)","f0c13eec":"# <span style=\"font-family: Arial;font-size:1.2em;color:#3E82F7\">Random forest and Decision Tree","5be84a54":"<span style=\"font-family: Arial;font-size:1.2em;color:#333333\"> Feature importance shows us which are the independent variable are given importance and that chosen for a split of the decision trees","7df8e1f7":"## <span style=\"font-family: Arial;font-size:1.2em;color:#333333\">vi. Education level","ec50877f":"### Thanks!\n\n## upvote if you like it and feel free to post any suggestions.","bd053673":"# <span style=\"font-family: Arial;font-size:1.2em;color:#3E82F7\">Null values imputation for test data\n","91ea0666":"## <span style=\"font-family: Arial;font-size:1.2em;color:#3E82F7\">Data import","ed06bd53":"# <span style=\"font-family: Arial;font-size:1.2em;color:#3E82F7\">Area under the curve AUC\n    \n","feff9c81":"# <span style=\"font-family: Arial;font-size:1.2em;color:#3E82F7\"> HR Analytics: Attrition prediction","852f249e":"# <span style=\"font-family: Arial;font-size:1.2em;color:#3E82F7\">Exploratory data analysis","73e35b7e":"## <span style=\"font-family: Arial;font-size:1.2em;color:#333333\">viii. Company size is determined by no. of people employees","db3cbf7b":"<span style=\"font-family: Arial;font-size:1.2em;color:#333333\">The CDI cuts across the different clusters identified in the Urban Indicator Framework as it is based on five sub indices namely, infrastructure, waste, health, education and city product.\nIt has separate sub-indices for Infrastructure, Waste Management, Health, Education, and City Product, which are averaged to form the CDI.\nThis formulation of the index by and large uses the same formulae as in UNDP Human Development Report (1999), for the Health, Education and City Product sub-indices.\n    \n","7bc1129d":"### <span style=\"font-family: Arial;font-size:1.3em;color:#3E82F7\">Encode the value with map ordinal (rank order) and nominal (non-rank order)\n    \n#### <span style=\"font-family: Arial;font-size:1.3em;color:#333333\"> from the data set we can observe that there are ordinal (rank order) and nominal (non-rank order) independent variables \n* <span style=\"font-family: Arial;font-size:1.2em;color:#333333\">Some of the independent variables have the rank order like  education level, company size last new job and experience\n* <span style=\"font-family: Arial;font-size:1.2em;color:#333333\">Some of the independent variables do not have the rank order like gender, company type, relevant experience, enrolled university, major discipline, city and enrolled university\n    \n* <span style=\"font-family: Arial;font-size:1.2em;color:#333333\">So with that logic, we map and encode the independent variables","3efd8338":"# <span style=\"font-family: Arial;font-size:1.2em;color:#3E82F7\">Feature importances","9487d376":"> # <span style=\"font-family: Arial;font-size:1.2em;color:#3E82F7\">ROC Reciever Operating Characteristic   \n* <span style=\"font-family: Arial;font-size:1.2em;color:#333333\">You may be wondering where the name \"Reciever Operating Characteristic\" came from. ROC analysis is part of a field called \"Signal Dectection Theory\" developed during World War II for the analysis of radar images\n    \n[READ This](http:\/\/gim.unmc.edu\/dxtests\/roc3.htm)","74d9b24f":"## <span style=\"font-family: Arial;font-size:1.2em;color:#3E82F7\">RF and DT model Evaluation","bc56c5e7":"# <span style=\"font-family: Arial;font-size:1.2em;color:#3E82F7\">Null values imputation","65b0ea9d":"## <span style=\"font-family: Arial;font-size:1.2em;color:#333333\">vii. Major discipline","622d93df":"## <span style=\"font-family: Arial;font-size:1.2em;color:#333333\">iii. Gender","320781e1":"## <span style=\"font-family: Arial;font-size:1.2em;color:#333333\">iv. Relevent Experience","23e5df3d":"# <span style=\"font-family: Arial;font-size:1.2em;color:#3E82F7\">Multivariate imputation by chained equations (MICE)","d34f7673":"## <span style=\"font-family: Arial;font-size:1.2em;color:#333333\">v. Enrolled University","7e940d57":"## <span style=\"font-family: Arial;font-size:1.2em;color:#333333\">i. City","1a2591c3":"# <span style=\"font-family: Arial;font-size:1.2em;color:#3E82F7\"> Index\n* [packages](#packages)\n* [Missing values](#Missing-values)\n* [Exploratory data analysis](#Exploratory-data-analysis)\n* [Null values imputation](#Null-values-imputation)\n* [Multivariate imputation by chained equations (MICE)](#Multivariate-imputation-by-chained-equations-(MICE))\n* [Random forest and Decision Tree](#Random-forest-and-Decision-Tree)\n* [Feature importances](#Feature-importances)\n* [Area under the curve AUC](#Area-under-the-curve-AUC)\n* [ROC Reciever Operating Characteristic](#ROC-Reciever-Operating-Characteristic)","32281883":"* <span style=\"font-family: Arial;font-size:1.2em;color:#333333\">Some of the independent variables have null value off that company type and the company size has the more than 30% of values are missing either we can do mode imputation  or we can (MICE) Multivariate imputation by chained equations\n    \n","5d3af0ef":"# <span style=\"font-family: Arial;font-size:1.2em;color:#3E82F7\">Missing values","0037ddf0":"# <span style=\"font-family: Arial;font-size:1.2em;color:#3E82F7\">Packages","3a98ebc2":"<span style=\"font-family: Arial;font-size:1.2em;color:#333333\">MICE is a multiple imputation method used to replace missing data values in a data set under certain assumptions about the data missingness mechanism (e.g., the data are missing at random, the data are missing completely at random)","9715cc08":"## <span style=\"font-family: Arial;font-size:1.2em;color:#333333\">ii. City development index"}}