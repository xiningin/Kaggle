{"cell_type":{"47bf9fc9":"code","e5100bb2":"code","97272d18":"code","4b46bb3d":"code","2451c699":"code","2b99f25e":"code","23c3b235":"code","debebec6":"code","6eaacb13":"code","5d599f48":"code","eeaf86d1":"code","c23e32a6":"code","6bd7cc97":"markdown","2314dbe6":"markdown","2cce1fc8":"markdown","77a3eaa9":"markdown","8a93e6de":"markdown","8abf52bb":"markdown","116d4b49":"markdown","d7ccf1af":"markdown","245c2f02":"markdown","49c1703c":"markdown","a1d14331":"markdown"},"source":{"47bf9fc9":"# Run these if OpenCV doesn't load\n\nimport sys\n# sys.path.append('\/Library\/Frameworks\/Python.framework\/Versions\/3.6\/lib\/python3.6\/site-packages\/cv2\/')","e5100bb2":"import cv2\nimport numpy as np\nimport math\nimport matplotlib.pyplot as plt\n%matplotlib inline ","97272d18":"# Here, we define some colours\nSCALAR_BLACK = (0.0,0.0,0.0)\nSCALAR_WHITE = (255.0,255.0,255.0)\nSCALAR_YELLOW = (0.0,255.0,255.0)\nSCALAR_GREEN = (0.0,255.0,0.0)\nSCALAR_RED = (0.0,0.0,255.0)\nSCALAR_CYAN = (255.0,255.0,0.0)","4b46bb3d":"# function to plot n images using subplots\ndef plot_image(images, captions=None, cmap=None ):\n    f, axes = plt.subplots(1, len(images), sharey=True)\n    f.set_figwidth(15)\n    for ax,image,caption in zip(axes, images, captions):\n        ax.imshow(image, cmap)\n        ax.set_title(caption)","2451c699":"SHOW_DEBUG_STEPS  = True\n\n# Reading video \ncap = cv2.VideoCapture('..\/input\/video-analysis\/AundhBridge.mp4')\n\n# if video is not present, show error\nif not(cap.isOpened()):\n    print(\"Error reading file\")\n\n# Check if you are able to capture the video    \nret, fFrame  = cap.read()\n\n# Capturing 2 consecutive frames and making a copy of those frame. Perform all operations on the copy frame. \nret, fFrame1 = cap.read()\nret, fFrame2 = cap.read()\nimg1 = fFrame1.copy()\nimg2 = fFrame2.copy()\n\nif(SHOW_DEBUG_STEPS):\n    print ('img1 height' + str(img1.shape[0]))\n    print ('img1 width' + str(img1.shape[1]))\n    print ('img2 height' + str(img2.shape[0]))\n    print ('img2 width' + str(img2.shape[1]))\n\n# Convert the colour images to greyscale in order to enable fast processing    \nimg1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\nimg2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n\n#plotting\nplot_image([img1, img2], cmap='gray', captions=[\"First frame\", \"Second frame\"])","2b99f25e":"# Add some Gaussian Blur\nimg1 = cv2.GaussianBlur(img1,(5,5),0)\nimg2 = cv2.GaussianBlur(img2,(5,5),0)\n\n#plotting\nplot_image([img1, img2], cmap='gray', captions=[\"GaussianBlur first frame\", \"GaussianBlur second frame\"])","23c3b235":"# This imgDiff variable is the difference between consecutive frames, which is equivalent to detecting movement\nimgDiff = cv2.absdiff(img1, img2) \n\n# Thresholding the image that is obtained after taking difference. Pixel value below 30 will be set as 0(black) and above as 255(white)\nret,imgThresh = cv2.threshold(imgDiff,30.0,255.0,cv2.THRESH_BINARY)\nht = np.size(imgThresh,0)\nwd = np.size(imgThresh,1)\nplot_image([imgDiff, imgThresh], cmap='gray', captions = [\"Difference between 2 frames\", \"Difference between 2 frames after threshold\"])","debebec6":"# Now, we define structuring elements\n\nstrucEle3x3 = cv2.getStructuringElement(cv2.MORPH_RECT,(3,3))\nstrucEle5x5 = cv2.getStructuringElement(cv2.MORPH_RECT,(5,5))\nstrucEle7x7 = cv2.getStructuringElement(cv2.MORPH_RECT,(7,7))        \nstrucEle15x15 = cv2.getStructuringElement(cv2.MORPH_RECT,(15,15))\n\nplot_image([strucEle3x3, strucEle5x5, strucEle7x7, strucEle15x15], cmap='gray', captions = [\"strucEle3x3\", \"strucEle5x5\", \"strucEle7x7\", \"strucEle15x15\"])\n","6eaacb13":"for i in range(2):\n    imgThresh = cv2.dilate(imgThresh,strucEle5x5,iterations = 2)\n    imgThresh = cv2.erode(imgThresh,strucEle5x5,iterations = 1)\n\n    imgThreshCopy = imgThresh.copy()\n    if(SHOW_DEBUG_STEPS):        \n        print ('imgThreshCopy height' + str(imgThreshCopy.shape[0]))\n        print ('imgThreshCopy width' + str(imgThreshCopy.shape[1]))\n        \nplt.imshow(imgThresh, cmap = 'gray')    \nplt.show()","5d599f48":"def drawAndShowContours(wd,ht,contours,strImgName):\n    global SCALAR_WHITE\n    global SHOW_DEBUG_STEPS\n    \n    # Defining a blank frame. Since it is initialised with zeros, it will be black. Will add all the coutours in this image.\n    blank_image = np.zeros((ht,wd,3), np.uint8)\n    #cv2.drawContours(blank_image,contours,10,SCALAR_WHITE,-1)\n    \n    # Adding all possible contour to the blank frame. Contour is white \n    cv2.drawContours(blank_image,contours,-1,SCALAR_WHITE,-1)\n    \n    \n    # For better clarity, lets just view countour 9\n    blank_image_contour_9 = np.zeros((ht,wd,3), np.uint8)\n    \n    # Let's just add contour 9 to the blank image and view it\n    cv2.drawContours(blank_image_contour_9,contours,8,SCALAR_WHITE,-1)\n    \n    # Plotting\n    plot_image([blank_image, blank_image_contour_9], cmap='gray', captions = [\"All possible contours\", \"Only the 9th contour\"])\n\n        \n    return blank_image","eeaf86d1":"# Now, we move on to the contour mapping portion    \n        \ncontours, hierarchy = cv2.findContours(imgThreshCopy,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\nim2 = drawAndShowContours(wd,ht,contours,'imgContours')\n\n# Printing all the coutours in the image.\nif(SHOW_DEBUG_STEPS):\n    print ('contours.shape: ' + str(len(contours)))","c23e32a6":"# Next, we define hulls.\n# Hulls are contours with the \"convexHull\" function from cv2\n\nhulls = contours # does it work?\nfor i in range(len(contours)):\n    hulls[i] = cv2.convexHull(contours[i])\n\n# Then we draw the contours    \nim3 = drawAndShowContours(wd,ht,hulls,'imgConvexHulls')","6bd7cc97":"Next, we define variables that will be used through the duration of the code","2314dbe6":"### Capturing movement in video\n**Two consecutive frames are required to capture the movement**. If there is movement in vehicle, there will be small change in pixel value in the current frame compared to the previous frame. The change implies movement. Let's capture the first 2 frames now.","2cce1fc8":"# Pre-processing notebook","77a3eaa9":"### Dilation and erosion in image \nDilation and erosion in the image with the filter size of structuring elements.","8a93e6de":"Function to draw the image","8abf52bb":"In this notebook, we will pre-process the frames. For better visualisation, we will just capture 2 frames and visualise all the steps. The steps are:\n1. Capture 2 consecutive frames. \n2. Find difference between the frames to capture the motion.\n3. Use GaussianBlur, thresholding, dilation and erosion to pre-process the frames.\n4. Image segmentation using contours. Extract the vehicles during this method.\n5. Convert contours to hulls. ","116d4b49":"## Hulls\nHulls are contours with the \"convexHull\".","d7ccf1af":"### Adding gaussion blur for smoothening","245c2f02":"First, we import the necessary libraries","49c1703c":"### Find the movement in video\nIf vehicle is moving, there will be **slight change** in pixel value in the next frame compared to previous frame. We then threshold the image. This will be useful further for preprocessing. Pixel value below 30 will be set as 0(black) and above as 255(white)\n\nThresholding: https:\/\/docs.opencv.org\/3.0-beta\/doc\/py_tutorials\/py_imgproc\/py_thresholding\/py_thresholding.html","a1d14331":"## Extracting contours\nTill now, you have a binary image. Next, we will segment the image and find all possible contours(possible vehicles). The shape of the contours will tell us the number of contours that has been identified. Define *drawAndShowContours()* function to plot the contours. You will see that the threshold image above and the countour image will look alike. So, additionally, we also plot a particular '9th' countour for further clarity. "}}