{"cell_type":{"918e6190":"code","1ecb5ec9":"code","c37784f4":"code","09a03781":"code","0b69806f":"code","2edf505a":"code","c314dbaf":"code","5cddf9ec":"code","84affcbc":"code","7b1f6fd1":"code","a483549b":"code","b3829cf7":"code","d8f3209f":"code","66192908":"code","5405fb96":"code","2e6aae5c":"code","253ea76c":"code","07db17af":"code","86bae0b4":"code","2bfecf97":"code","6fd3b9a2":"code","2cdebb80":"code","f0db2da3":"code","f9140a10":"markdown"},"source":{"918e6190":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1ecb5ec9":"import re\nimport nltk\nfrom nltk.corpus import stopwords\nimport seaborn as sns\nimport matplotlib.pyplot as plt \nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.metrics import accuracy_score","c37784f4":"data = pd.read_csv(\"\/kaggle\/input\/stockmarket-sentiment-dataset\/stock_data.csv\")","09a03781":"data.head()","0b69806f":"#Remove punctuation , Special characters from text coloum\n\ncleanText = []\nstop_words = set(stopwords.words('english'))\nfor text in data[\"Text\"]:\n    text = re.sub(\"[^A-z-a-z]\",\" \",text)\n    text = text.lower()\n    word_token = nltk.word_tokenize(text)\n    removedStopword = [word for word in word_token if word not in stop_words]\n    text_lemma = nltk.WordNetLemmatizer()\n    word = [text_lemma.lemmatize(word) for word in removedStopword]\n    text = \" \".join(word)\n    cleanText.append(text)\n","2edf505a":"print(stop_words)","c314dbaf":"cleanText[0:5]","5cddf9ec":"len(cleanText)","84affcbc":"data[\"cleanText\"]=cleanText","7b1f6fd1":"data.head(5)","a483549b":"data.drop(\"Text\",axis = 1,inplace=True)","b3829cf7":"data.head(5)","d8f3209f":"#check data is balanced or unbalacnced \ndata[\"Sentiment\"].value_counts()","66192908":"sns.set_style(\"darkgrid\")\nsns.countplot(data.Sentiment)","5405fb96":"X = data[\"cleanText\"]\ny = data[\"Sentiment\"]","2e6aae5c":"print(X.shape)\nprint(y.shape)","253ea76c":"#Now split the data in train and test \nfrom sklearn.model_selection import train_test_split\nfeatures_train, features_test, result_train, result_test = train_test_split(X, y, test_size = 0.3,random_state = 618)","07db17af":"# printing the shape of train and test data\nprint(\"features_train shape: \",features_train.shape)\nprint(\"features_test shape : \" ,features_test.shape)\nprint(\"result_train shape  : \"  ,result_train.shape) \nprint(\"result_test shape   : \"   ,result_test.shape)","86bae0b4":"# creating CountVectorizer object and MultinomialNB model (navi base model will work efficiently for text classification)\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer,TfidfVectorizer\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.naive_bayes import MultinomialNB\ncv= CountVectorizer()\nmodel = MultinomialNB()\ntfidf_transformer = TfidfTransformer()\nfor i in range(1,900):\n    features_train, features_test, result_train, result_test = train_test_split(X, y, test_size = 0.3,random_state = i)\n    features_train = cv.fit_transform(features_train)\n    #tfidf_transformer = tfidf_transformer.fit_transform(features_train)\n    model = model.fit(features_train,result_train)\n    features_test = cv.transform(features_test)\n    modelPredict = model.predict(features_test)\n    accuracy_test = accuracy_score(result_test, modelPredict)\n    if accuracy_test >=0.80:\n        print(accuracy_test,i)\n\n","2bfecf97":"\naccuracy_test","6fd3b9a2":"cm = confusion_matrix(result_test, modelPredict)\nprint(\"Confusion Matrix: \\n \\n\", cm)","2cdebb80":"from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix\nprint('Classification Report: \\n')\nprint(classification_report(result_test, accuracy_test))","f0db2da3":"plot_confusion_matrix(clf, features_test, result_test)  \nplt.show()","f9140a10":"as we see above setiment having two lable postive i.e +1 and negative i.e -1.\nPostive sentiment having more than Negative sentiment and data is little bit unbalanced."}}