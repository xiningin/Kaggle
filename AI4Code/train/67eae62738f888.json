{"cell_type":{"e9bcdc4e":"code","5e254ae1":"code","cc73fb5f":"code","fca76159":"code","e313a34f":"code","06084dcf":"code","cde1624c":"code","d484af05":"code","7f387911":"code","b4513b9c":"code","177d2a32":"code","dda5b835":"code","a811606d":"code","fff841ca":"code","74053be4":"code","6befad63":"code","2cba8396":"code","4bf68088":"code","59e4ad18":"code","9712ed6b":"code","4cba1c08":"code","5b16d436":"code","d34254b5":"code","ca8b763c":"code","5235b1b0":"code","3633e237":"code","c5f1439b":"code","89f9e7c7":"code","412e066d":"code","95233174":"code","4ca6f60a":"code","a15f1207":"code","6f8e69f8":"code","affeb998":"markdown","e3eb56ba":"markdown","f8ac6559":"markdown","dafa56e3":"markdown","2ada75e1":"markdown","f9a91b0a":"markdown","78132da1":"markdown","58704436":"markdown","8dc8dc00":"markdown"},"source":{"e9bcdc4e":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\nimport datetime\nfrom kaggle.competitions import nflrush\nimport tqdm\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nimport keras\n\nfrom tqdm import tqdm_notebook\nimport warnings\nwarnings.filterwarnings('ignore')\n\nsns.set_style('darkgrid')\nmpl.rcParams['figure.figsize'] = [15,10]","5e254ae1":"train = pd.read_csv('..\/input\/nfl-big-data-bowl-2020\/train.csv', dtype={'WindSpeed': 'object'})\n# train = train[:2200]\nprint(train.shape)\ntrain.head()","cc73fb5f":"#https:\/\/www.kaggle.com\/rooshroosh\/fork-of-neural-networks-different-architecture\ndef strtoseconds(txt):\n    txt = txt.split(':')\n    ans = int(txt[0])*60 + int(txt[1]) + int(txt[2])\/60\n    return ans\n\ndef strtofloat(x):\n    try:\n        return float(x)\n    except:\n        return -1\n\ndef map_weather(txt):\n    ans = 1\n    if pd.isna(txt):\n        return 0\n    if 'partly' in txt:\n        ans*=0.5\n    if 'climate controlled' in txt or 'indoor' in txt:\n        return ans*3\n    if 'sunny' in txt or 'sun' in txt:\n        return ans*2\n    if 'clear' in txt:\n        return ans\n    if 'cloudy' in txt:\n        return -ans\n    if 'rain' in txt or 'rainy' in txt:\n        return -2*ans\n    if 'snow' in txt:\n        return -3*ans\n    return 0\n\ndef OffensePersonnelSplit(x):\n    dic = {'DB' : 0, 'DL' : 0, 'LB' : 0, 'OL' : 0, 'QB' : 0, 'RB' : 0, 'TE' : 0, 'WR' : 0}\n    for xx in x.split(\",\"):\n        xxs = xx.split(\" \")\n        dic[xxs[-1]] = int(xxs[-2])\n    return dic\n\ndef DefensePersonnelSplit(x):\n    dic = {'DB' : 0, 'DL' : 0, 'LB' : 0, 'OL' : 0}\n    for xx in x.split(\",\"):\n        xxs = xx.split(\" \")\n        dic[xxs[-1]] = int(xxs[-2])\n    return dic\n\ndef orientation_to_cat(x):\n    x = np.clip(x, 0, 360 - 1)\n    try:\n        return str(int(x\/15))\n    except:\n        return \"nan\"","fca76159":"def preprocess(train):\n    ## GameClock\n    train['GameClock_sec'] = train['GameClock'].apply(strtoseconds)\n    train[\"GameClock_minute\"] = train[\"GameClock\"].apply(lambda x : x.split(\":\")[0]).astype(\"object\")\n\n    ## Height\n    train['PlayerHeight_dense'] = train['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n\n    ## Time\n    train['TimeHandoff'] = train['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n    train['TimeSnap'] = train['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n\n    train['TimeDelta'] = train.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n    train['PlayerBirthDate'] = train['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m\/%d\/%Y\"))\n\n    ## Age\n    seconds_in_year = 60*60*24*365.25\n    train['PlayerAge'] = train.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()\/seconds_in_year, axis=1)\n    train[\"PlayerAge_ob\"] = train['PlayerAge'].astype(np.int).astype(\"object\")\n\n    ## WindSpeed\n    train['WindSpeed_ob'] = train['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n    train['WindSpeed_ob'] = train['WindSpeed_ob'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))\/2 if not pd.isna(x) and '-' in x else x)\n    train['WindSpeed_ob'] = train['WindSpeed_ob'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))\/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n    train['WindSpeed_dense'] = train['WindSpeed_ob'].apply(strtofloat)\n\n    ## Weather\n    train['GameWeather_process'] = train['GameWeather'].str.lower()\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: \"indoor\" if not pd.isna(x) and \"indoor\" in x else x)\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n    train['GameWeather_dense'] = train['GameWeather_process'].apply(map_weather)\n\n    ## Rusher\n    train['IsRusher'] = (train['NflId'] == train['NflIdRusher'])\n    train['IsRusher_ob'] = (train['NflId'] == train['NflIdRusher']).astype(\"object\")\n    temp = train[train[\"IsRusher\"]][[\"Team\", \"PlayId\"]].rename(columns={\"Team\":\"RusherTeam\"})\n    train = train.merge(temp, on = \"PlayId\")\n    train[\"IsRusherTeam\"] = train[\"Team\"] == train[\"RusherTeam\"]\n\n    ## dense -> categorical\n    train[\"Quarter_ob\"] = train[\"Quarter\"].astype(\"object\")\n    train[\"Down_ob\"] = train[\"Down\"].astype(\"object\")\n    train[\"JerseyNumber_ob\"] = train[\"JerseyNumber\"].astype(\"object\")\n    train[\"YardLine_ob\"] = train[\"YardLine\"].astype(\"object\")\n    # train[\"DefendersInTheBox_ob\"] = train[\"DefendersInTheBox\"].astype(\"object\")\n    # train[\"Week_ob\"] = train[\"Week\"].astype(\"object\")\n    # train[\"TimeDelta_ob\"] = train[\"TimeDelta\"].astype(\"object\")\n\n\n    ## Orientation and Dir\n    train[\"Orientation_ob\"] = train[\"Orientation\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n    train[\"Dir_ob\"] = train[\"Dir\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n\n    train[\"Orientation_sin\"] = train[\"Orientation\"].apply(lambda x : np.sin(x\/360 * 2 * np.pi))\n    train[\"Orientation_cos\"] = train[\"Orientation\"].apply(lambda x : np.cos(x\/360 * 2 * np.pi))\n    train[\"Dir_sin\"] = train[\"Dir\"].apply(lambda x : np.sin(x\/360 * 2 * np.pi))\n    train[\"Dir_cos\"] = train[\"Dir\"].apply(lambda x : np.cos(x\/360 * 2 * np.pi))\n\n    ## diff Score\n    train[\"diffScoreBeforePlay\"] = train[\"HomeScoreBeforePlay\"] - train[\"VisitorScoreBeforePlay\"]\n    train[\"diffScoreBeforePlay_binary_ob\"] = (train[\"HomeScoreBeforePlay\"] > train[\"VisitorScoreBeforePlay\"]).astype(\"object\")\n\n    ## Turf\n    Turf = {'Field Turf':'Artificial', 'A-Turf Titan':'Artificial', 'Grass':'Natural', 'UBU Sports Speed S5-M':'Artificial', 'Artificial':'Artificial', 'DD GrassMaster':'Artificial', 'Natural Grass':'Natural', 'UBU Speed Series-S5-M':'Artificial', 'FieldTurf':'Artificial', 'FieldTurf 360':'Artificial', 'Natural grass':'Natural', 'grass':'Natural', 'Natural':'Natural', 'Artifical':'Artificial', 'FieldTurf360':'Artificial', 'Naturall Grass':'Natural', 'Field turf':'Artificial', 'SISGrass':'Artificial', 'Twenty-Four\/Seven Turf':'Artificial', 'natural grass':'Natural'} \n    train['Turf'] = train['Turf'].map(Turf)\n\n    ## OffensePersonnel\n    temp = train[\"OffensePersonnel\"].iloc[np.arange(0, len(train), 22)].apply(lambda x : pd.Series(OffensePersonnelSplit(x)))\n    temp.columns = [\"Offense\" + c for c in temp.columns]\n    temp[\"PlayId\"] = train[\"PlayId\"].iloc[np.arange(0, len(train), 22)]\n    train = train.merge(temp, on = \"PlayId\")\n\n    ## DefensePersonnel\n    temp = train[\"DefensePersonnel\"].iloc[np.arange(0, len(train), 22)].apply(lambda x : pd.Series(DefensePersonnelSplit(x)))\n    temp.columns = [\"Defense\" + c for c in temp.columns]\n    temp[\"PlayId\"] = train[\"PlayId\"].iloc[np.arange(0, len(train), 22)]\n    train = train.merge(temp, on = \"PlayId\")\n\n    ## sort\n#     train = train.sort_values(by = ['X']).sort_values(by = ['Dis']).sort_values(by=['PlayId', 'Team', 'IsRusher']).reset_index(drop = True)\n    train = train.sort_values(by = ['X']).sort_values(by = ['Dis']).sort_values(by=['PlayId', 'IsRusherTeam', 'IsRusher']).reset_index(drop = True)\n    return train","e313a34f":"%%time\ntrain = preprocess(train)","06084dcf":"## DisplayName remove Outlier\nv = train[\"DisplayName\"].value_counts()\nmissing_values = list(v[v < 5].index)\ntrain[\"DisplayName\"] = train[\"DisplayName\"].where(~train[\"DisplayName\"].isin(missing_values), \"nan\")\n\n## PlayerCollegeName remove Outlier\nv = train[\"PlayerCollegeName\"].value_counts()\nmissing_values = list(v[v < 10].index)\ntrain[\"PlayerCollegeName\"] = train[\"PlayerCollegeName\"].where(~train[\"PlayerCollegeName\"].isin(missing_values), \"nan\")","cde1624c":"pd.to_pickle(train, \"train.pkl\")","d484af05":"def drop(train):\n    drop_cols = [\"GameId\", \"GameWeather\", \"NflId\", \"Season\", \"NflIdRusher\"] \n    drop_cols += ['TimeHandoff', 'TimeSnap', 'PlayerBirthDate']\n    drop_cols += [\"Orientation\", \"Dir\", 'WindSpeed', \"GameClock\"]\n    # drop_cols += [\"DefensePersonnel\",\"OffensePersonnel\"]\n    train = train.drop(drop_cols, axis = 1)\n    return train","7f387911":"train = drop(train)","b4513b9c":"un_use_features = ['G_HomeTeamAbbr',\n 'G_PossessionTeam',\n 'G_RusherTeam',\n 'G_StadiumType',\n 'G_diffScoreBeforePlay_binary_ob',\n 'P_DefenseDB',\n 'P_DefenseDL',\n 'P_DefenseLB',\n 'P_DefenseOL',\n 'P_GameWeather_dense',\n 'P_IsRusher',\n 'P_IsRusherTeam',\n 'P_OffenseDB',\n 'P_OffenseDL',\n 'P_OffenseLB',\n 'P_OffenseOL',\n 'P_OffenseQB',\n 'P_OffenseTE',\n 'P_OffenseWR',\n 'P_PlayerAge_ob',\n 'P_Quarter',\n 'P_Week']\n\nun_use_features += ['G_Down_ob',\n 'G_FieldPosition',\n 'G_OffenseRB',\n 'G_TimeDelta',\n 'G_VisitorTeamAbbr',\n 'G_WindDirection',\n 'P_GameClock_sec',\n 'P_HomeScoreBeforePlay',\n 'P_Humidity',\n 'P_Orientation_ob',\n 'P_PlayerHeight',\n 'P_Temperature',\n 'P_VisitorScoreBeforePlay',\n 'P_WindSpeed_dense',\n 'P_diffScoreBeforePlay']\n\n## delete prefix\nun_use_features = [c[2:] for c in un_use_features]\ntrain = train.drop(un_use_features, axis = 1)","177d2a32":"cat_features = []\ndense_features = []\nfor col in train.columns:\n    if train[col].dtype =='object':\n        cat_features.append(col)\n        print(\"*cat*\", col, len(train[col].unique()))\n    else:\n        dense_features.append(col)\n        print(\"!dense!\", col, len(train[col].unique()))\ndense_features.remove(\"PlayId\")\ndense_features.remove(\"Yards\")","dda5b835":"train_cat = train[cat_features]\ncategories = []\nmost_appear_each_categories = {}\nfor col in tqdm_notebook(train_cat.columns):\n    train_cat.loc[:,col] = train_cat[col].fillna(\"nan\")\n    train_cat.loc[:,col] = col + \"__\" + train_cat[col].astype(str)\n    most_appear_each_categories[col] = list(train_cat[col].value_counts().index)[0]\n    categories.append(train_cat[col].unique())\ncategories = np.hstack(categories)\nprint(len(categories))","a811606d":"le = LabelEncoder()\nle.fit(categories)\nfor col in tqdm_notebook(train_cat.columns):\n    train_cat.loc[:, col] = le.transform(train_cat[col])\nnum_classes = len(le.classes_)","fff841ca":"train_dense = train[dense_features]\nsss = {}\nmedians = {}\nfor col in tqdm_notebook(train_dense.columns):\n    print(col)\n    medians[col] = np.nanmedian(train_dense[col])\n    train_dense.loc[:, col] = train_dense[col].fillna(medians[col])\n    ss = StandardScaler()\n    train_dense.loc[:, col] = ss.fit_transform(train_dense[col].values[:,None])\n    sss[col] = ss","74053be4":"eps = 1e-8\n## dense features for play\ndense_game_features = train_dense.columns[train_dense[:22].std() <= eps]\n## dense features for each player\ndense_player_features = train_dense.columns[train_dense[:22].std() > eps]\n## categorical features for play\ncat_game_features = train_cat.columns[train_cat[:22].std() <= eps]\n## categorical features for each player\ncat_player_features = train_cat.columns[train_cat[:22].std() > eps]","6befad63":"dense_game_feature_names = [\"G_\" + cc for cc in dense_game_features]\ndense_player_feature_names = list(np.hstack([[\"P_\" + c for c in dense_player_features] for k in range(22)]))\ncat_game_feature_names = [\"G_\" + cc for cc in cat_game_features]\ncat_player_feature_names = list(np.hstack([[\"P_\" + c for c in cat_player_features] for k in range(22)]))","2cba8396":"train_dense_game = train_dense[dense_game_features].iloc[np.arange(0, len(train), 22)].reset_index(drop = True).values\n## rusher player feature is included in train_dense_players, so skip this.\n# train_dense_game = np.hstack([train_dense_game, train_dense[dense_player_features][train_dense[\"IsRusher\"] > 0]]) ## with rusher player feature\n\ntrain_dense_players = [train_dense[dense_player_features].iloc[np.arange(k, len(train), 22)].reset_index(drop = True) for k in range(22)]\ntrain_dense_players = np.stack([t.values for t in train_dense_players]).transpose(1, 0, 2)\n\ntrain_cat_game = train_cat[cat_game_features].iloc[np.arange(0, len(train), 22)].reset_index(drop = True).values\n# train_cat_game = np.hstack([train_cat_game, train_cat[cat_player_features][train_dense[\"IsRusher\"] > 0]]) ## with rusher player feature\n\ntrain_cat_players = [train_cat[cat_player_features].iloc[np.arange(k, len(train), 22)].reset_index(drop = True) for k in range(22)]\ntrain_cat_players = np.stack([t.values for t in train_cat_players]).transpose(1, 0, 2)","4bf68088":"def return_step(x):\n    temp = np.zeros(199)\n    temp[x + 99:] = 1\n    return temp\n\ntrain_y_raw = train[\"Yards\"].iloc[np.arange(0, len(train), 22)].reset_index(drop = True)\ntrain_y = np.vstack(train_y_raw.apply(return_step).values)","59e4ad18":"train_dense_game.shape, train_dense_players.shape, train_cat_game.shape, train_cat_players.shape, train_y.shape","9712ed6b":"## concat all features\ntrain_dense_players = np.reshape(train_dense_players, (len(train_dense_players), -1))\ntrain_dense = np.hstack([train_dense_players, train_dense_game])\n\ntrain_cat_players = np.reshape(train_cat_players, (len(train_cat_players), -1))\ntrain_cat = np.hstack([train_cat_players, train_cat_game])\n\ntrain_x = np.hstack([train_dense, train_cat])","4cba1c08":"from lightgbm import LGBMClassifier\nclass MultiLGBMClassifier():\n    def __init__(self, resolution, params):\n        ## smoothing size\n        self.resolution = resolution\n        ## initiarize models\n        self.models = [LGBMClassifier(**params) for _ in range(resolution)]\n        \n    def fit(self, x, y):\n        self.classes_list = []\n        for k in tqdm_notebook(range(self.resolution)):\n            ## train each model\n            self.models[k].fit(x, (y + k) \/\/ self.resolution)\n            ## (0,1,2,3,4,5,6,7,8,9) -> (0,0,0,0,0,1,1,1,1,1) -> (0,5)\n            classes = np.sort(list(set((y + k) \/\/ self.resolution))) * self.resolution - k\n            classes = np.append(classes, 999)\n            self.classes_list.append(classes)\n            \n    def predict(self, x):\n        pred199_list = []\n        for k in range(self.resolution):\n            preds = self.models[k].predict_proba(x)\n            classes = self.classes_list[k]\n            pred199s = self.get_pred199(preds, classes)\n            pred199_list.append(pred199s)\n        self.pred199_list = pred199_list\n        pred199_ens = np.mean(np.stack(pred199_list), axis = 0)\n        return pred199_ens\n    \n    def _get_pred199(self, p, classes):\n        ## categorical prediction -> predicted distribution whose length is 199\n        pred199 = np.zeros(199)\n        for k in range(len(p)):\n            pred199[classes[k] + 99 : classes[k+1] + 99] = p[k]\n        return pred199\n\n    def get_pred199(self, preds, classes):\n        pred199s = []\n        for p in preds:\n            pred199 = np.cumsum(self._get_pred199(p, classes))\n            pred199 = pred199\/np.max(pred199)\n            pred199s.append(pred199)\n        return np.vstack(pred199s)","5b16d436":"params = {'lambda_l1': 0.001, 'lambda_l2': 0.001,\n 'num_leaves': 40, 'feature_fraction': 0.4,\n 'subsample': 0.4, 'min_child_samples': 10,\n 'learning_rate': 0.01,\n 'num_iterations': 700, 'random_state': 42}","d34254b5":"from sklearn.model_selection import train_test_split, KFold\nlosses = []\nmodels = []\nfor k in range(1):\n    kfold = KFold(5, random_state = 42 + k, shuffle = True)\n    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(train_y)):\n        print(\"-----------\")\n        print(\"-----------\")\n        model = MultiLGBMClassifier(resolution = 5, params = params)\n        model.fit(train_x[tr_inds], train_y_raw.values[tr_inds])\n        preds = model.predict(train_x[val_inds])\n        loss = np.mean((train_y[val_inds] - preds) ** 2)\n        models.append(model)\n        print(k_fold, loss)\n        losses.append(loss)\nprint(\"-------\")\nprint(losses)\nprint(np.mean(losses))","ca8b763c":"print(losses)\nprint(np.mean(losses))","5235b1b0":"feature_importances = 0\nnum_model = 0\nfor model in models:\n    for m in model.models:\n        feature_importances += m.booster_.feature_importance(\"gain\")\n        num_model += 1\n\nfeature_importances \/= num_model","3633e237":"feature_names = dense_player_feature_names + dense_game_feature_names + cat_game_feature_names + cat_player_feature_names\nfeature_importance_df = pd.DataFrame(np.vstack([feature_importances, feature_names]).T, columns = [\"importance\", \"name\"])\nfeature_importance_df[\"importance\"] = feature_importance_df[\"importance\"].astype(np.float32)\nfeature_importance_df = feature_importance_df.groupby(\"name\").agg(\"mean\").reset_index()","c5f1439b":"plt.figure(figsize = (8, 18))\nsns.barplot(data = feature_importance_df.sort_values(by = \"importance\", ascending = False).head(50), x = \"importance\", y = \"name\")\nplt.show()","89f9e7c7":"plt.figure(figsize = (8, 18))\nsns.barplot(data = feature_importance_df.sort_values(by = \"importance\", ascending = False).tail(50), x = \"importance\", y = \"name\")\nplt.show()","412e066d":"## bad features\nlist(feature_importance_df[feature_importance_df[\"importance\"] < np.quantile(feature_importance_df[\"importance\"], 0.3)][\"name\"])","95233174":"def make_pred(test, sample, env, model):\n    test = preprocess(test)\n    test = drop(test)\n    test = test.drop(un_use_features, axis = 1)\n    \n    ### categorical\n    test_cat = test[cat_features]\n    for col in (test_cat.columns):\n        test_cat.loc[:,col] = test_cat[col].fillna(\"nan\")\n        test_cat.loc[:,col] = col + \"__\" + test_cat[col].astype(str)\n        isnan = ~test_cat.loc[:,col].isin(categories)\n        if np.sum(isnan) > 0:\n#             print(\"------\")\n#             print(\"test have unseen label : col\")\n            if not ((col + \"__nan\") in categories):\n#                 print(\"not nan in train : \", col)\n                test_cat.loc[isnan,col] = most_appear_each_categories[col]\n            else:\n#                 print(\"nan seen in train : \", col)\n                test_cat.loc[isnan,col] = col + \"__nan\"\n    for col in (test_cat.columns):\n        test_cat.loc[:, col] = le.transform(test_cat[col])\n\n    ### dense\n    test_dense = test[dense_features]\n    for col in (test_dense.columns):\n        test_dense.loc[:, col] = test_dense[col].fillna(medians[col])\n        test_dense.loc[:, col] = sss[col].transform(test_dense[col].values[:,None])\n\n    ### divide\n    test_dense_players = [test_dense[dense_player_features].iloc[np.arange(k, len(test), 22)].reset_index(drop = True) for k in range(22)]\n    test_dense_players = np.stack([t.values for t in test_dense_players]).transpose(1,0, 2)\n\n    test_dense_game = test_dense[dense_game_features].iloc[np.arange(0, len(test), 22)].reset_index(drop = True).values\n#     test_dense_game = np.hstack([test_dense_game, test_dense[dense_player_features][test_dense[\"IsRusher\"] > 0]])\n    \n    test_cat_players = [test_cat[cat_player_features].iloc[np.arange(k, len(test), 22)].reset_index(drop = True) for k in range(22)]\n    test_cat_players = np.stack([t.values for t in test_cat_players]).transpose(1,0, 2)\n\n    test_cat_game = test_cat[cat_game_features].iloc[np.arange(0, len(test), 22)].reset_index(drop = True).values\n#     test_cat_game = np.hstack([test_cat_game, test_cat[cat_player_features][test_dense[\"IsRusher\"] > 0]])\n\n    test_dense_players = np.reshape(test_dense_players, (len(test_dense_players), -1))\n    test_dense = np.hstack([test_dense_players, test_dense_game])\n    test_cat_players = np.reshape(test_cat_players, (len(test_cat_players), -1))\n    test_cat = np.hstack([test_cat_players, test_cat_game])\n    test_x = np.hstack([test_dense, test_cat])\n\n    test_inp = test_x\n    \n    ## pred\n    pred = 0\n    for model in models:\n        _pred = model.predict(test_inp)\n        pred += _pred\n    pred \/= len(models)\n    pred = np.clip(pred, 0, 1)\n    env.predict(pd.DataFrame(data=pred,columns=sample.columns))\n    return pred","4ca6f60a":"env = nflrush.make_env()\npreds = []\nfor test, sample in tqdm_notebook(env.iter_test()):\n    pred = make_pred(test, sample, env, models)\n    preds.append(pred)\nenv.write_submission_file()","a15f1207":"preds = np.vstack(preds)\n## check whether prediction is submittable\nprint(np.mean(np.diff(preds, axis = 1) >= 0) == 1.0)\nprint(np.mean(preds > 1) == 0)","6f8e69f8":"print(losses)\nprint(np.mean(losses))","affeb998":"## Dense","e3eb56ba":"I simply replace my neural network model with lgbm model from https:\/\/www.kaggle.com\/mrkmakr\/neural-network-with-mae-objective-0-01385\n\nSome feature engineerings (standerize, categorical version of numeric feature) used in this kernel are not suitable to lgbm.\n\nI just use almost the same features used in the above kernel","f8ac6559":"## Prediction","dafa56e3":"### v12 : fix bug\n### v11 : drop more features based on feature importances\n### v10 : drop some features based on feature importances\n### v9 : add feature importance plot\n### v8 : add comments\n### v7 : 0.01387","2ada75e1":"## Feature engineering","f9a91b0a":"In this kernel, I use the multiple LGBMClassifiers.\n\nTarget Yard of lgbm is smoothened and fed to LGBMClassifier. \n\n- For example, (1,2,3,4,5) -> label 1, (6,7,8,9,10) -> label 2, etc...\n\nAnd I slide the smoothing window and train each LGBMClassifier.\n\n- For example, \n- First model : (1,2,3,4,5) -> label 1, (6,7,8,9,10) -> label 2, etc...\n- Second model : (2,3,4,5,6) -> label 1, (7,8,9,10,11) -> label 2, etc...\n- Third model : (3,4,5,6,7) -> label 1, (8,9,10,11,12) -> label 2, etc...\n- etc...\n\nFinaly I calculate the ensemble of predictions of these multiple LGBMClassifiers.","78132da1":"## Divide features into groups","58704436":"## Model","8dc8dc00":"## categorical"}}