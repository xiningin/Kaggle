{"cell_type":{"18a8366a":"code","e591192b":"code","f29c085d":"code","4d3910c9":"code","bc24f429":"code","33e3c6ff":"code","1d312539":"code","42a13c12":"code","514ae5c1":"code","396b6037":"code","e2ed9b69":"code","f3dd8c5f":"code","c0bfecc9":"code","e561f2d0":"markdown","48ae4636":"markdown","42b1c781":"markdown","07e2db45":"markdown","aba021ce":"markdown"},"source":{"18a8366a":"from keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical \n\n\ntrain_data=pd.read_csv('\/kaggle\/input\/av-healthcare-analytics-ii\/healthcare\/train_data.csv')\ntest_data=pd.read_csv('\/kaggle\/input\/av-healthcare-analytics-ii\/healthcare\/test_data.csv')","e591192b":"#  view the dataset's categories at-a-glance\ntrain_data.info()\n# test_data.info()","f29c085d":"#more details if necessary\nprint(train_data.shape)\nprint(test_data.shape)\nprint(train_data.head())\nprint(train_data.dtypes.value_counts())\nprint(train_data.describe(include='int').T)\nprint(train_data.describe(include='float').T)\nprint(train_data.describe(include='object').T)","4d3910c9":"## All Data Visualization code together for convenience\n\n# visualize Length of Stay intervals only\nplt.figure(figsize = (15,10))\nsns.countplot(y = 'Stay', data = train_data, palette = 'Set3')\nplt.xlabel('Admissions', size = 25)\nplt.ylabel('Length of Stay (in days)', size = 25)\nplt.title('Number of Admissions per Length of Stay(n = {})'.format(len(train_data)))\nplt.show()\n\n# visualize distribution of LOS by age cohort\nlos_indices = train_data.Stay.value_counts().index[:11]\nage_indices = train_data.Age.value_counts().index[:10]\ncross_data = train_data[train_data.Stay.isin(los_indices)& (train_data.Age.isin(age_indices))]\nplt.figure()\ncross_table = pd.crosstab(columns= cross_data.Stay, index = cross_data.Age) \ncross_table.plot.bar(figsize = (10,10), title=\"Stay Lengths per Age cohort\")\nplt.xlabel('Age cohorts', size = 20)\nplt.ylabel('Admissions', size = 20)\nplt.show()\n\n# visualize admissions by departments\nplt.figure(figsize=(15, 10))\nsns.countplot(x = train_data.Department)\nplt.title(\"Admission Counts for Departments in the Dataset\")\nplt.ylabel('Admission counts', size = 20)\nplt.xlabel('Departments', size = 20)\n\n# visualize admissions by illness severity\nf, (vis1, vis2) = plt.subplots(1,2, figsize = (14,6))\n\n# +++++++++\nsns.countplot(x= train_data[\"Severity of Illness\"], ax = vis1, palette = 'Set1')\nvis1.set_title(\"\"\"Distribution of Severity of Illness in training dataset\n(n = {})\"\"\".format(len(train_data)))\nvis1.set_ylabel(\"Total Admissions\")\n\n# ++++++++++\nillness = train_data.groupby([\"Severity of Illness\", \"Stay\"]).size()\nillness = (illness\/illness.groupby(level=1).sum()).reset_index()\n# ++++++++++++++++++\n\nsns.lineplot(x = 'Stay', y = 0, hue = \"Severity of Illness\", data = illness, ax = vis2, palette = 'Set2')\nvis2.set_title(\"\"\"Proportion of Length of Stay to Severity of Illness\n(n = {})\"\"\".format(len(train_data)))\nvis2.set_ylabel(\"Percent of Admissions\")\n\nplt.tight_layout()\nplt.show()\n\n\n# correlation matrix\ncorr_matrix = train_data.corr()\nplt.figure(figsize=(20,10))\nsns.heatmap(corr_matrix,vmax=.4, square=True,annot=True)","bc24f429":"# remove null values\ntrain_data = train_data.dropna()\ntest_data = test_data.dropna()\n# case ids will never help with predicting,so this category is removed;\ntrain_data = train_data.drop(['case_id'], axis = 1)\ntest_data = test_data.drop(['case_id'], axis = 1)\n\n# folds in repeated patient ids instances  into N number of visits \ntrain_data['Visits'] = train_data.groupby(['patientid'])['patientid'].transform('count')\ntrain_data = train_data.drop(['patientid'], axis=1) \n\ntest_data['Visits'] = test_data.groupby(['patientid'])['patientid'].transform('count')\ntest_data = test_data.drop(['patientid'], axis=1) \n\n# normalize some of the data in columns with high amount of unique values\n# academic honesty: inspired by example by JAKE TURICCHI on Kaggle --> see code section for this kaggle dataset\nthreshold = 0.05\nhospital_codes = train_data['Hospital_code'].value_counts(normalize = True)\nhospital_codes_below_threshold = hospital_codes.where(hospital_codes < threshold).dropna().index.values\ntrain_data['Hospital_code']= np.where(train_data['Hospital_code'].isin(hospital_codes_below_threshold), '0',  train_data['Hospital_code'])\n\ncity_code_patients = train_data['City_Code_Patient'].value_counts(normalize = True)\npatient_codes_below_threshold = city_code_patients.where(city_code_patients < threshold).dropna().index.values\ntrain_data['City_Code_Patient']= np.where(train_data['City_Code_Patient'].isin(patient_codes_below_threshold), '0',  train_data['City_Code_Patient'])","33e3c6ff":"# prepare columns to ease the encoding of categorical values\ntarget=['Hospital_code', 'City_Code_Hospital',\n        'City_Code_Patient', 'Severity of Illness',\n        'Hospital_type_code', 'Hospital_region_code', \n        'Department', 'Type of Admission', 'Bed Grade',\n        'Ward_Facility_Code',  'Ward_Type', 'Age'] \n\n# only train data has Stay column\ntrain_data['Stay'] = train_data['Stay'].astype('category')\ntrain_data[target] = train_data[target].astype('category')\ntest_data[target] = test_data[target].astype('category')\n\n\n# integer encoding step\ndef integer_encode_columns(dataframe, column_list):\n    encoder = LabelEncoder()\n    df = dataframe.copy()\n    for column in column_list:\n        col_name = column + '_lbl'\n        df[col_name] = encoder.fit_transform(df[column])\n    \n    df = df.drop(column_list, axis = 1)\n    df = df.reset_index(drop = True)\n    return df\n\n\nencode_targets = ['Hospital_code','Hospital_type_code','City_Code_Hospital', \n                  'Hospital_region_code','Department','Ward_Type','Ward_Facility_Code',\n                  'City_Code_Patient', 'City_Code_Hospital', 'Type of Admission', \n                  'Severity of Illness', 'Age', 'Stay', 'Bed Grade']\nencoded_df = integer_encode_columns(train_data, encode_targets)\n\n# binary encode Stay to turn prediction of LOS into a Binary Classification of Short (0-10 days) or Long (More than 10 days)\ndef binary_encode_column(dataframe, column, inplace = True):\n    if inplace:\n        dataframe.loc[dataframe[column]!= 0] = 1\n        dataframe = dataframe.reset_index(drop = True)\n        return\n    else:\n        df = dataframe.copy()\n        df.loc[df[column]!= 0]= 1\n        df = df.reset_index(drop = True)\n        return df\n    \nbinary_encode_column(encoded_df, 'Stay_lbl')\n\n# use pd.set_option('max_columns', None) in console to allow for viewing of all columns\n## rename most columns back to their original names before the _lbl suffix, or to a name following uniform naming convention\nencoded_df.rename(columns = {'Hospital_code_lbl':'Hospital_code', \n                             'Hospital_type_code_lbl':'Hospital_type_code',\n                             'City_Code_Hospital_lbl':'City_Code_Hospital',\n                            'Hospital_region_code_lbl':'Hospital_region_code',\n                            'Department_lbl': 'Department',\n                             'Ward_Type_lbl': 'Ward_Type',\n                            'Ward_Facility_Code_lbl': 'Ward_Facility_Code', \n                            'City_Code_Patient_lbl': 'City_Code_Patient',\n                            'City_Code_Hospital_lbl': 'City_Code_Hospital',\n                            'Type of Admission_lbl': 'Admission_Type',\n                            'Severity of Illness_lbl': 'Illness_Severity',\n                            'Age_lbl': 'Age', 'Stay_lbl': 'Stay', \n                            'Bed Grade_lbl': 'Bed_Grade'}, inplace = True)","1d312539":"numpy_train_data = encoded_df.to_numpy()\nnumpy_train_labels =  encoded_df.values\nprint(type(train_data))\nprint(type(numpy_train_data))\nprint(type(numpy_train_labels))\nprint(numpy_train_data.shape)\nprint(numpy_train_labels.shape)","42a13c12":"input_features = [\"Illness_Severity\", \"Age\", \"Admission_Type\",\n                  \"Hospital_code\", \"Department\", \"Visitors with Patient\"]\n\n# y = independent variable, X = dependent variable(s)\ny_feature = \"Stay\"\nX_train = encoded_df.loc[:, input_features + [y_feature]]\n#X_train = train_data.loc[:, input_features + [y_feature]]\n\nordered_categories = input_features[0:2]\nunordered_categories = input_features[2:-1]\nnum = [input_features[-1]]\n\n\n","514ae5c1":"def prepare_dataset():\n\n    # Convert categorical variables to indices\n    X_trn = None\n    m = MinMaxScaler()\n\n    for column in X_train.columns:\n        #print(column)\n        if column in unordered_categories or column in ordered_categories or column == y_feature:\n            _ = pd.factorize(X_train[column], sort=True)[0]\n            if column in unordered_categories:\n                _ = to_categorical(_, num_classes=X_train[column].unique().size)\n            elif column in ordered_categories:\n                _ = _\/np.max(_)\n        else:\n            #print(column)\n            _ = m.fit_transform(X_train[column].values.reshape(-1,1))[:, 0]\n\n        try:\n            print(\"Xtrn: \", X_trn.shape) \n        except:\n            pass\n        print(\"_: \",_.shape)\n        \n        try:\n            if len(_.shape) == 1:\n                    print(\"1D\")\n                    X_trn = np.hstack((X_trn, _.reshape(-1,1)))\n            else:\n                X_trn = np.hstack((X_trn, _))  \n        except Exception as e:\n            print(\"Error: We are up a creek without a paddle or Cheetohs\")\n            if len(_.shape) == 1:\n                    print(\"1D\")\n                    X_trn = _.reshape(-1,1)\n            else:\n                X_trn = _\n\n    X_trn = X_trn\n    y_trn = X_trn[:, -1]\n#     print(y_trn)\n    X_trn = X_trn[:, :-1]\n#     print(X_trn)\n\n    # adding Visitors Number ^ 2 to add another feature\n    #X_trn = np.vstack((X_trn.T, m.fit_transform(((X_train[\"Visitors with Patient\"]**2).values).reshape(-1,1))[:, 0])).T\n    #print(X_trn.shape)\n    \n    y_trn = to_categorical(y_trn, num_classes=train_data.Stay.unique().size)\n#     print(y_trn)\n    X_trn, X_val, y_trn, y_val = train_test_split(X_trn, y_trn, test_size=0.3)\n    \n    return X_trn, X_val, y_trn, y_val","396b6037":"X_train, X_test, y_train,y_test  = prepare_dataset()\nprint(X_train)\n","e2ed9b69":"# define model to tackle this single-label, binary classification problem\nmodel = Sequential()\nmodel.add(Dense(128, input_dim = X_train.shape[1] , activation = 'relu'))\nmodel.add(Dense(128, activation = 'relu'))\nmodel.add(Dense(128, activation = 'relu'))\nmodel.add(Dense(128, activation = 'relu'))\nmodel.add(Dense(11, activation='softmax'))\n\nmodel.summary()\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n\n","f3dd8c5f":"\nX_train=np.asarray(X_train).astype(np.int)\ny_train=np.asarray(y_train).astype(np.int)\nmodel.fit(X_train,y_train,validation_split = 0.2, batch_size = 225, epochs = 5, shuffle = True, verbose = 2)\n\n# _, accuracy = model_base.evaluate(x_train, y_test, verbose=0)\n# print('Accuracy: %.2f' % (accuracy*100))\n# monitor = EarlyStopping(monitor = '??', min_delta = ?)\n# checkpointer = ModelCheckPoint(filepath = 'DIR', verbose = 0, save_best_only= True)","c0bfecc9":"print('Accuracy: %.2f' % (accuracy*100))","e561f2d0":"# **Data Cleaning**","48ae4636":"# **Training the Neural Network**","42b1c781":"# **Encoding**","07e2db45":"# **Data Exploration**","aba021ce":"# *Predicting Length of Stay at a Hospital*\n\n"}}