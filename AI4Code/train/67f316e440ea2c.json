{"cell_type":{"fef637b4":"code","f168fc15":"code","6b7547f7":"code","e1641e51":"code","bf95276e":"code","7a0b8ac7":"code","f7eea4f0":"markdown","68315444":"markdown"},"source":{"fef637b4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","f168fc15":"\n#importing various libraries to use\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\n#read the data\ndata_train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndata_test = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\n\n#separate train from target\ny = data_train.SalePrice\nX = data_train.drop(['SalePrice'], axis = 1)\n\n#divide data into train test split\nX_train_full, X_valid_full, y_train_full, y_valid_full = train_test_split(\n                                                        X,y,test_size = 0.2, random_state = 0)\n\n#select numerical cols\nnumerical_cols = [cname for cname in X_train_full.columns if\n                 X_train_full[cname].dtype in ['int64','float64']]\n\n#selecting the low cardinality values\ncategorical_cols = [cname for cname in X_train_full.columns if\n                   X_train_full[cname].nunique()<10 and X_train_full[cname].dtype == 'object']\n\nmy_cols = numerical_cols + categorical_cols\nX_train = X_train_full[my_cols].copy()\nX_valid = X_valid_full[my_cols].copy()\nX_train.head()\n","6b7547f7":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\n\n#preprocessing for numerical data\nnumerical_transformer = SimpleImputer(strategy='constant')\n\n#preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer',SimpleImputer(strategy='most_frequent')),\n    ('onehot',OneHotEncoder(handle_unknown = 'ignore'))\n])\n\n#Bundle preprocessing for numerical data and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num',numerical_transformer,numerical_cols),\n        ('cat',categorical_transformer,categorical_cols)\n    ])","e1641e51":"from xgboost import XGBRegressor\nmodel = XGBRegressor(n_estimators = 250, random_state = 0)\n\nfrom sklearn.metrics import mean_absolute_error\n\n#bundle preprocessing and model code\nmy_pipeline = Pipeline(steps=[('preprocessor',preprocessor),\n                             ('model',model)])\n\n#fit the model\nmy_pipeline.fit(X_train,y_train_full)\n\n#predicting validation data\npreds_val = my_pipeline.predict(X_valid)\n\n#score error\nscore = mean_absolute_error(y_valid_full,preds_val)\nprint('MAE:',score)","bf95276e":"#preprocessing test data and fit\nfinal_pred = my_pipeline.predict(data_test)\n","7a0b8ac7":"#saving to the output\noutput = pd.DataFrame({'Id':data_test.Id,\n                     'SalePrice':final_pred})\noutput.to_csv('submission.csv',index=False)","f7eea4f0":"#defining the XGBRegressor model in this","68315444":"# Defining preprocessing steps using pipelines"}}