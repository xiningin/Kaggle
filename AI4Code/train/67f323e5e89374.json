{"cell_type":{"6263f7aa":"code","d549ee25":"code","f3f33948":"code","6fa9b3f3":"code","e720fc2d":"code","9cdffbeb":"code","4f63281c":"code","4d4de15a":"code","34f04ffc":"code","56511b51":"code","e34b0a01":"code","ec5ee48d":"code","6caa4736":"markdown","3064ceb4":"markdown","b13590de":"markdown","4aecd55a":"markdown","aa8f663e":"markdown","4def0655":"markdown","079b2a65":"markdown","d664b18b":"markdown","68ec482a":"markdown","75f074c6":"markdown","21793d50":"markdown","057c70e3":"markdown","9244bb97":"markdown","e280ed92":"markdown","bba1a686":"markdown","8dcd3d4d":"markdown","c3b9e9a3":"markdown","97ad984b":"markdown","a962a755":"markdown","1ea648a1":"markdown","f0e1d51e":"markdown","836626c0":"markdown","6c8af62e":"markdown","965aef17":"markdown","eef93d57":"markdown","4acc669d":"markdown","a75abd97":"markdown","f6788725":"markdown"},"source":{"6263f7aa":"!pip install pytorch-lightning\n!pip install -U 'git+https:\/\/github.com\/cocodataset\/cocoapi.git#subdirectory=PythonAPI'\n!pip install git+git:\/\/github.com\/lgvaz\/mantisshrimp.git","d549ee25":"from mantisshrimp.imports import *\nfrom mantisshrimp import *\nimport pandas as pd\nimport albumentations as A","f3f33948":"source = Path('..\/input\/global-wheat-detection\/')\ndf = pd.read_csv(source \/ \"train.csv\")\ndf.head()","6fa9b3f3":"class WheatParser(DefaultImageInfoParser, FasterRCNNParser):\n    def __init__(self, df, source):\n        self.df = df\n        self.source = source\n        self.imageid_map = IDMap()\n\n    def __iter__(self):\n        yield from self.df.itertuples()\n\n    def __len__(self):\n        return len(self.df)\n\n    def imageid(self, o) -> int:\n        return self.imageid_map[o.image_id]\n\n    def filepath(self, o) -> Union[str, Path]:\n        return self.source \/ f\"{o.image_id}.jpg\"\n\n    def height(self, o) -> int:\n        return o.height\n\n    def width(self, o) -> int:\n        return o.width\n\n    def label(self, o) -> int:\n        return 1\n\n    def bbox(self, o) -> BBox:\n        return BBox.from_xywh(*np.fromstring(o.bbox[1:-1], sep=\",\"))","e720fc2d":"data_splitter = RandomSplitter([.8, .2])\nparser = WheatParser(df, source \/ \"train\")\ntrain_rs, valid_rs = parser.parse(data_splitter)","9cdffbeb":"show_record(train_rs[0], label=False)","4f63281c":"train_tfm = AlbuTransform([A.Flip()])","4d4de15a":"train_ds = Dataset(train_rs, train_tfm)\nvalid_ds = Dataset(valid_rs)","34f04ffc":"class WheatModel(MantisFasterRCNN):\n    def configure_optimizers(self):\n        opt = SGD(self.parameters(), 1e-3, momentum=0.9)\n        return opt","56511b51":"model = WheatModel(2)","e34b0a01":"train_dl = model.dataloader(train_ds, shuffle=True, batch_size=4, num_workers=2)\nvalid_dl = model.dataloader(valid_ds, batch_size=4, num_workers=2)","ec5ee48d":"trainer = Trainer(max_epochs=1, gpus=1)\ntrainer.fit(model, train_dl, valid_dl)","6caa4736":"For creating a `Dataset` we just need need to pass the parsed records from the previous step and optionally a transform.","3064ceb4":"At first glance, we can make the following assumptions:  \n* Multiple rows with the same object_id, width, height  \n* A different bbox for each row  \n* source doesn't seem relevant right now  ","b13590de":"## Transforms and Datasets","4aecd55a":"Let's take a look at one record.","aa8f663e":"Mantisshrimp is agnostic to the transform library you want to use. We provide default support for [albumentations](https:\/\/github.com\/albumentations-team\/albumentations) but if you want to use another library you just need to inherit and override all abstract methods of `Transform`.","4def0655":"When creating a `Parser` we inherit from smaller building blocks that provides the functionallity we want:  \n* `DefaultImageInfoParser`: Will parse standard fields for image information, e.g. `filepath`, `height`, `width`  \n* `FasterRCNNParser`: Since we only need to predict bboxes we will use a `FasterRCNN` model, this will parse all the requirements for using such a model.  ","079b2a65":"<div class=\"alert alert-info\">\n    \n**Note:**\n\nIf you are using an IDE there is a little bit of magic than can happen. Once you created defined your class you can right click on it and select the option _\"implement abstract methods\"_, this will automatically populate your class with all the methods you need to override. \n\nIf you are using a notebook, or your IDE does not support that, check the documentation to know what methods you should override.\n\n<\/div>","d664b18b":"Another difference from lightning is that all mantis models have a `dataloader` method that returns a customized `DataLoader` for each model.","68ec482a":"The first step is to understand the data. In this task we were given a `.csv` file with annotations, let's take a look at that.","75f074c6":"## Model","21793d50":"## DataLoader","057c70e3":"Defining the `__init__` is completely up to you, normally we have to pass our data (the `df` in our case) and the folder where our images are contained (`source` in our case).","9244bb97":"\n<div class=\"alert alert-warning\">\n    \n**Important:**  \n    \nBe sure to return the correct type on all overriden methods!\n    \n<\/div>","e280ed92":"We create the model passing how many classes we have.  \n\nIn our case we have two: `wheat` and `background`.","bba1a686":"## Parser","8dcd3d4d":"We then override `__iter__`, telling our parser how to iterate over our data. In our case we call `df.itertuples` to iterate over all `df` rows.\n\n`__len__` is not obligatory but will help visualizing the progress when parsing.","c3b9e9a3":"For simplicity, let's use a single transform on the train data and no transforms on the validation data.","97ad984b":"## Train","a962a755":"And finally we override all the other methods, they all receive a single argument `o`, which is the object returned by `__iter__`.","1ea648a1":"Once we know what our data provides we can create our custom `Parser`.  ","f0e1d51e":"<div class=\"alert alert-info\">\n    \n**Note:**  \n\nReplace `source` with your own path for the dataset directory.\n    \n<\/div>","836626c0":"We can also specify exactly what fields we would like to parse, in fact, the parsers we are currently using are just helper classes that groups a collection of individual parsers.  \nWe are going to see how to use individual parsers in a future tutorial.","6c8af62e":"That's it! Trainer for train! \ud83d\ude80 \ud83d\ude80 \ud83d\ude80","965aef17":"If you are not familiar with lightning, be sure to check their excelent [documentation](https:\/\/pytorch-lightning.readthedocs.io\/en\/stable\/).","eef93d57":"Everything from now is almost pure lightning, the only big difference is that instead of inheriting from `LightningModule` we inherit from the specialized `MantisFasterRCNN`, this will automatically create the model architecture and download the pre-trained model weights.","4acc669d":"Now we just need to decide how to split our data and `Parser.parse`!","a75abd97":"# Wheat","f6788725":"Now [pytorch-lightning](https:\/\/github.com\/PytorchLightning\/pytorch-lightning) enters the picture.  "}}