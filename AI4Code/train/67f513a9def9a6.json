{"cell_type":{"d7c67a51":"code","b3a3bd04":"code","71dc94eb":"code","a85ca788":"code","37dbc983":"code","acf66a6b":"code","bbfa4f81":"code","0c5ba2fc":"code","5755b886":"code","fcdfa99a":"code","ef576c37":"code","5004a82c":"code","20d8708d":"code","f90e39ee":"code","42bcdb04":"code","43ababa6":"code","256282f3":"code","78b61d1f":"code","462d6002":"code","4255a046":"code","806bdd32":"code","e7302387":"code","c03a9880":"code","302f51fb":"code","88ccf6d1":"code","caf0b1ae":"code","9a823ca2":"code","098b49d7":"code","8e881bc1":"code","9ed861aa":"code","debd9009":"code","5e8f4c37":"code","c9468a4b":"code","e48c89b6":"markdown","c685ea99":"markdown","5a93791b":"markdown","7d1aa74c":"markdown","ffc30eda":"markdown","5c3cf6a2":"markdown","8597395e":"markdown","e45ff1b9":"markdown","60af3e00":"markdown","7314c45e":"markdown","dd606b96":"markdown","abfc4bb0":"markdown"},"source":{"d7c67a51":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport seaborn as sns\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.feature_selection import SelectKBest, f_regression\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.svm import SVR\nfrom sklearn.preprocessing import MinMaxScaler,StandardScaler,LabelEncoder\nimport statsmodels.api as sm\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max.columns', None)","b3a3bd04":"df = pd.read_csv('..\/input\/factorys-salary\/Factory_Salary.csv')\ndf.head()","71dc94eb":"df.shape","a85ca788":"df.info()","37dbc983":"df.isnull().sum()","acf66a6b":"df.describe()","bbfa4f81":"df['Date'] = pd.to_datetime(df['Date'], format = '%Y\/%m\/%d')\ndf['Month'] = pd.DatetimeIndex(df['Date']).month\ndf = df.drop('Date', axis = 1)\ndf.head()","0c5ba2fc":"f, ax = plt.subplots(figsize=(10,8))\ncorr = df.corr()\nsns.heatmap(corr, annot=True, mask=np.zeros_like(corr, dtype=np.bool),\n           cmap = sns.diverging_palette(240, 10, as_cmap = True), \n           square = True, ax = ax)","5755b886":"df.corr()[\"Salary\"].sort_values()","fcdfa99a":"print(df['Profession'].unique())\nprint('-----')\nprint(df['Equipment'].unique())\nprint('-----')\nprint(df['Rank'].unique())","ef576c37":"fig, axes = plt.subplots(nrows = 5, ncols = 1, figsize =(5, 20))\nsns.boxplot(y = 'Month', data = df, ax=axes[0])\nsns.boxplot(y = 'Insalubrity', data = df, ax=axes[1])\nsns.boxplot(y = 'Size_Production', data = df, ax=axes[2])\nsns.boxplot(y = 'Rank', data = df, ax=axes[3])\nsns.boxplot(y = 'Salary', data = df, ax=axes[4])","5004a82c":"def remove_outliers(data):\n    arr=[]\n    #print(max(list(data)))\n    q1=np.percentile(data,25)\n    q3=np.percentile(data,75)\n    iqr=q3-q1\n    mi=q1-(1.5*iqr)\n    ma=q3+(1.5*iqr)\n    #print(mi,ma)\n    for i in list(data):\n        if i<mi:\n            i=mi\n            arr.append(i)\n        elif i>ma:\n            i=ma\n            arr.append(i)\n        else:\n            arr.append(i)\n    #print(max(arr))\n    return arr","20d8708d":"df['Salary'] = remove_outliers(df['Salary'])\nsns.boxplot(y = 'Salary', data = df)","f90e39ee":"fig, axes = plt.subplots(nrows = 2, ncols = 2, figsize =(12, 10))\nsns.barplot(y = 'Salary', x = 'Month', data = df, ax=axes[0][0])\nsns.barplot(y = 'Salary', x = 'Insalubrity', data = df, ax=axes[0][1])\nsns.barplot(y = 'Salary', x = 'Size_Production', data = df, ax=axes[1][0])\nsns.barplot(y = 'Salary', x = 'Rank', data = df, ax=axes[1][1])","42bcdb04":"fig, axes = plt.subplots(nrows = 7, ncols = 1, figsize =(10, 30))\nsns.barplot(y = 'Profession', x = 'Salary', data = df, ax=axes[0])\nsns.barplot(y = 'Equipment', x = 'Salary', data = df, ax=axes[1])\nsns.barplot(x = 'Month', y = 'Size_Production', data = df, ax=axes[2])\nsns.barplot(y = 'Salary', x = 'Month', data = df, ax=axes[3])\nsns.barplot(y = 'Size_Production', x = 'Insalubrity', data = df, ax = axes [4])\nsns.barplot(x = 'Insalubrity', y = 'Profession', data = df, ax = axes [5])\nsns.barplot(x = 'Insalubrity', y = 'Equipment', data = df, ax = axes [6])","43ababa6":"le = LabelEncoder()\ndf['Profession'] = le.fit_transform(df['Profession'])\ndf['Equipment'] = le.fit_transform(df['Equipment'])\ndf = df.drop('Month', axis = 1)\ndf.head()","256282f3":"f, ax = plt.subplots(figsize=(10,8))\ncorr = df.corr()\nsns.heatmap(corr, annot=True, mask=np.zeros_like(corr, dtype=np.bool),\n           cmap = sns.diverging_palette(240, 10, as_cmap = True), \n           square = True, ax = ax)","78b61d1f":"df.corr()['Salary'].sort_values()","462d6002":"std = StandardScaler()\ndf_std = std.fit_transform(df)\ndf_std = pd.DataFrame(df_std, columns = df.columns)","4255a046":"X = df_std.drop('Salary', axis = 1)\ny = df_std.Salary","806bdd32":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 42)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","e7302387":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","c03a9880":"regressor = sm.OLS(y_train, X_train).fit()\nprint(regressor.summary())\n\nX_train_dropped = X_train.copy()","302f51fb":"while True:\n    if max(regressor.pvalues) > 0.05:\n        drop_variable = regressor.pvalues[regressor.pvalues == max(regressor.pvalues)]\n        print(\"Dropping \" + drop_variable.index[0] + \" and running regression again because pvalue is: \" + str(drop_variable[0]))\n        X_train_dropped = X_train_dropped.drop(columns = [drop_variable.index[0]])\n        regressor = sm.OLS(y_train, X_train_dropped).fit()\n    else:\n        print(\"All p values less than 0.05\")\n        break","88ccf6d1":"print(regressor.summary())","caf0b1ae":"X_train_dropped.shape","9a823ca2":"column_names = df.drop(columns = ['Salary']).columns\n\nno_of_features = []\nr_squared_train = []\nr_squared_test = []\n\n#look at X_train.shape\nfor k in range(1, 6):\n    selector = SelectKBest(f_regression, k = k)\n    X_train_transformed = selector.fit_transform(X_train, y_train)\n    X_test_transformed = selector.transform(X_test)\n    regressor = LinearRegression()\n    regressor.fit(X_train_transformed, y_train)\n    no_of_features.append(k)\n    r_squared_train.append(regressor.score(X_train_transformed, y_train))\n    r_squared_test.append(regressor.score(X_test_transformed, y_test))\n    \nsns.lineplot(x = no_of_features, y = r_squared_train, legend = 'full')\nsns.lineplot(x = no_of_features, y = r_squared_test, legend = 'full')","098b49d7":"selector = SelectKBest(f_regression, k = 3)\nX_train_transformed = selector.fit_transform(X_train, y_train)\nX_test_transformed = selector.transform(X_test)\ncolumn_names[selector.get_support()]","8e881bc1":"def regression_model(model):\n    \"\"\"\n    Will fit the regression model passed and will return the regressor object and the score\n    \"\"\"\n    regressor = model\n    regressor.fit(X_train_transformed, y_train)\n    score = regressor.score(X_test_transformed, y_test)\n    return regressor, score","9ed861aa":"model_performance = pd.DataFrame(columns = [\"Features\", \"Model\", \"Score\"])\n\nmodels_to_evaluate = [LinearRegression(), Ridge(), Lasso(), SVR(), RandomForestRegressor(), MLPRegressor()]\n\nfor model in models_to_evaluate:\n    regressor, score = regression_model(model)\n    model_performance = model_performance.append({\"Features\": \"Linear\",\"Model\": model, \"Score\": round(score, 2)}, ignore_index=True)\n\nmodel_performance.sort_values(by = 'Score', ascending = False)","debd9009":"poly = PolynomialFeatures()\nX_train_transformed_poly = poly.fit_transform(X_train)\nX_test_transformed_poly = poly.transform(X_test)\n\nprint(X_train_transformed_poly.shape)\n\nno_of_features = []\nr_squared = []\n\n#look at shape\nfor k in range(1, 21):\n    selector = SelectKBest(f_regression, k = k)\n    X_train_transformed = selector.fit_transform(X_train_transformed_poly, y_train)\n    regressor = LinearRegression()\n    regressor.fit(X_train_transformed, y_train)\n    no_of_features.append(k)\n    r_squared.append(regressor.score(X_train_transformed, y_train))\n    \nsns.lineplot(x = no_of_features, y = r_squared)","5e8f4c37":"selector = SelectKBest(f_regression, k = 11)\nX_train_transformed = selector.fit_transform(X_train_transformed_poly, y_train)\nX_test_transformed = selector.transform(X_test_transformed_poly)","c9468a4b":"models_to_evaluate = [LinearRegression(), Ridge(), Lasso(), SVR(), RandomForestRegressor(), MLPRegressor()]\n\nfor model in models_to_evaluate:\n    regressor, score = regression_model(model)\n    model_performance = model_performance.append({\"Features\": \"Polynomial\",\"Model\": model, \"Score\": round(score,2)}, ignore_index=True)\n\nmodel_performance.sort_values(by = 'Score', ascending = False)","e48c89b6":"### Check multicollinearity","c685ea99":"## Barplot","5a93791b":"# Import Libs","7d1aa74c":"# Modeling","ffc30eda":"1. Salary increases in some months. Hypothesis: Perhaps this is due to the volume of production\n2. For 18 and 22 points of harm, they pay the most - this is logical. Which is not logical: for the harmfulness of 11 points, they pay the least, i.e. pay more for work where there is no harm. Hypothesis: perhaps this was due to the discharge and volume of production, which fell on a certain category of harmfulness\n3. The larger the volume of products, the more they pay - everything is logical\n4. The higher the rank, the more they pay - everything is logical here too","5c3cf6a2":"# EDA \n\n## Boxplot","8597395e":"### Check and delete feature with high p-value","e45ff1b9":"# Thanks for watching!\n\n# If you liked my fork then upvoted or write your opinion\u00b6\n\n","60af3e00":"### Transformation to datetime and select months","7314c45e":"# Data preprocessing","dd606b96":"### We see outliers in Salary. Just delete it","abfc4bb0":"1. We see that the Profession and Equipment charts are almost the same.\n2. Month does not affect Salary, hypothesis # 1 is confirmed. So we can delete this variable."}}