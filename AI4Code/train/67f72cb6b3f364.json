{"cell_type":{"5c743f59":"code","7a1df2a6":"code","4c19e1c2":"code","4a36f91d":"code","8ec20964":"code","adeb1dfc":"code","4bd022eb":"code","bd13fee9":"code","e90a975d":"code","4127e437":"code","b02ac198":"code","147dfaa5":"code","864eaf17":"code","73478dad":"code","5a27c1e5":"code","3351ce24":"code","cb96844c":"code","e130efae":"code","23453197":"code","2fa0e5ce":"code","1cfbf7ca":"code","60210824":"code","bb4c350b":"markdown","b4237e36":"markdown","7efe284e":"markdown","25c0f3ef":"markdown","8edfbcf0":"markdown","46c3f4b1":"markdown","5bf92c27":"markdown","99e985f5":"markdown","9c36e300":"markdown","65994325":"markdown","a2a3845a":"markdown","39cd4be7":"markdown","af1678b2":"markdown"},"source":{"5c743f59":"#pytorch utility imports\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision.utils import make_grid\n\n#neural net imports\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable","7a1df2a6":"#import external libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport os\nimport math\n%matplotlib inline","4c19e1c2":"print(torch.cuda.is_available())\nprint(torch.backends.cudnn.enabled)\n\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nprint(device)","4a36f91d":"! ls ..\/input\/","8ec20964":"input_folder_path = \"..\/input\/\"\ntrain_df = pd.read_csv(input_folder_path+\"train.csv\")\ntest_df = pd.read_csv(input_folder_path+\"test.csv\")","adeb1dfc":"train_labels = train_df['label'].values\ntrain_images = (train_df.iloc[:,1:].values).astype('float32')\ntest_images = (test_df.iloc[:,:].values).astype('float32')\n\n#Training and Validation Split\ntrain_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels,\n                                                                     stratify=train_labels, random_state=123,\n                                                                     test_size=0.20)","4bd022eb":"train_images = train_images.reshape(train_images.shape[0], 28, 28)\nval_images = val_images.reshape(val_images.shape[0], 28, 28)\ntest_images = test_images.reshape(test_images.shape[0], 28, 28)","bd13fee9":"#train samples\nfor i in range(6, 9):\n    plt.subplot(330 + (i+1))\n    plt.imshow(train_images[i].squeeze(), cmap=plt.get_cmap('gray'))\n    plt.title(train_labels[i])","e90a975d":"#test samples\nfor i in range(6, 9):\n    plt.subplot(330 + (i+1))\n    plt.imshow(test_images[i].squeeze(), cmap=plt.get_cmap('gray'))","4127e437":"#train\ntrain_images_tensor = torch.tensor(train_images)\/255.0\ntrain_labels_tensor = torch.tensor(train_labels)\ntrain_tensor = TensorDataset(train_images_tensor, train_labels_tensor)\n\n#val\nval_images_tensor = torch.tensor(val_images)\/255.0\nval_labels_tensor = torch.tensor(val_labels)\nval_tensor = TensorDataset(val_images_tensor, val_labels_tensor)\n\n#test\ntest_images_tensor = torch.tensor(test_images)\/255.0","b02ac198":"train_loader = DataLoader(train_tensor, batch_size=16, num_workers=2, shuffle=True)\nval_loader = DataLoader(val_tensor, batch_size=16, num_workers=2, shuffle=True)\ntest_loader = DataLoader(test_images_tensor, batch_size=16, num_workers=2, shuffle=False)","147dfaa5":"for batch_idx, (data, target) in enumerate(train_loader):\n    img_grid = make_grid(data[0:8,].unsqueeze(1), nrow=8)\n    img_target_labels = target[0:8,].numpy()\n    break\n    \nplt.imshow(img_grid.numpy().transpose((1,2,0)))\nplt.rcParams['figure.figsize'] = (10, 2)\nplt.title(img_target_labels, size=16)\nplt.show()","864eaf17":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        \n        self.conv_block = nn.Sequential(\n            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2) \n        )\n        \n        self.linear_block = nn.Sequential(\n            nn.Dropout(p=0.5),\n            nn.Linear(128*7*7, 128),\n            nn.BatchNorm1d(128),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(128, 64),\n            nn.BatchNorm1d(64),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(64, 10)\n        )\n        \n    def forward(self, x):\n        x = self.conv_block(x)\n        x = x.view(x.size(0), -1)\n        x = self.linear_block(x)\n        \n        return x","73478dad":"conv_model = Net()\nconv_model","5a27c1e5":"optimizer = optim.Adam(params=conv_model.parameters(), lr=0.003)\ncriterion = nn.CrossEntropyLoss()\n\nexp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\nif torch.cuda.is_available():\n    conv_model = conv_model.cuda()\n    criterion = criterion.cuda()","3351ce24":"def train_model(num_epoch):\n    conv_model.train()\n    exp_lr_scheduler.step()\n    \n    for batch_idx, (data, target) in enumerate(train_loader):\n        data = data.unsqueeze(1)\n        data, target = data, target\n        \n        if torch.cuda.is_available():\n            data = data.cuda()\n            target = target.cuda()\n            \n        optimizer.zero_grad()\n        output = conv_model(data)\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n        \n        if (batch_idx + 1)% 100 == 0:\n            print('Train Epoch: {} [{}\/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                num_epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n                100. * (batch_idx + 1) \/ len(train_loader), loss.data[0]))\n            \ndef evaluate(data_loader):\n    conv_model.eval()\n    loss = 0\n    correct = 0\n    \n    for data, target in data_loader:\n        data = data.unsqueeze(1)\n        data, target = data, target\n        \n        if torch.cuda.is_available():\n            data = data.cuda()\n            target = target.cuda()\n        \n        output = conv_model(data)\n        \n        loss += F.cross_entropy(output, target, size_average=False).data[0]\n\n        pred = output.data.max(1, keepdim=True)[1]\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n        \n    loss \/= len(data_loader.dataset)\n        \n    print('\\nAverage Val Loss: {:.4f}, Val Accuracy: {}\/{} ({:.3f}%)\\n'.format(\n        loss, correct, len(data_loader.dataset),\n        100. * correct \/ len(data_loader.dataset)))","cb96844c":"num_epochs = 25\n\nfor n in range(num_epochs):\n    train_model(n)\n    evaluate(val_loader)","e130efae":"def make_predictions(data_loader):\n    conv_model.eval()\n    test_preds = torch.LongTensor()\n    \n    for i, data in enumerate(data_loader):\n        data = data.unsqueeze(1)\n        \n        if torch.cuda.is_available():\n            data = data.cuda()\n            \n        output = conv_model(data)\n        \n        preds = output.cpu().data.max(1, keepdim=True)[1]\n        test_preds = torch.cat((test_preds, preds), dim=0)\n        \n    return test_preds","23453197":"test_set_preds = make_predictions(test_loader)","2fa0e5ce":"submission_df = pd.read_csv(\"..\/input\/sample_submission.csv\")","1cfbf7ca":"submission_df['Label'] = test_set_preds.numpy().squeeze()\nsubmission_df.head()","60210824":"submission_df.to_csv('submission.csv', index=False)","bb4c350b":"#### Separate into labels and training images and reshape the images","b4237e36":"#### Define the CNN Model","7efe284e":"#### Read inputs","25c0f3ef":"#### Training the Model","8edfbcf0":"#### Load images into the data generator","46c3f4b1":"#### Plot some images to see samples","5bf92c27":"#### Plot some sample images using the data generator","99e985f5":"#### Imports","9c36e300":"Check for CUDA","65994325":"#### Define the optimizer and loss functions","a2a3845a":"#### Make predictions on the test set","39cd4be7":"#### Prepare Submissions","af1678b2":"#### Convert images to tensors\nNormalize the images too"}}