{"cell_type":{"1a5165fa":"code","8decc326":"code","6203e1ac":"code","717fbef0":"code","8a1401ad":"code","c0e240c6":"code","de989d2f":"code","9ae749c5":"code","f9902a24":"code","2e37e900":"code","b58b9e26":"code","4c21963e":"code","e64148f1":"code","5f30212f":"code","8caaec04":"code","393d6676":"code","3a51aebb":"code","3b0c92f8":"code","e11e42c5":"code","d03c5e77":"code","3c4890bf":"code","61b7023b":"markdown","130597db":"markdown","cc29e872":"markdown","c6e543a2":"markdown","47e543e0":"markdown","940ddb62":"markdown","6273eaab":"markdown","da098738":"markdown"},"source":{"1a5165fa":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\nimport seaborn as sns\n\nimport random","8decc326":"import tensorflow as tf\n\nfrom sklearn.model_selection import train_test_split\n\n\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom keras.layers.advanced_activations import LeakyReLU","6203e1ac":"path = \"..\/input\/\"\ntrain = pd.read_csv(path + \"train.csv\")\ntest = pd.read_csv(path + \"test.csv\")\nsample_submission = pd.read_csv(path + \"sample_submission.csv\")","717fbef0":"# plot a random sample image file\nnum = random.randint(0, len(train))\n\nlabel_sample, image = train.iloc[num,0], train.iloc[num,1:]\nshape = int(np.sqrt(784))\nplt.imshow(image.values.reshape(shape, shape))\nprint(\"The image should show: {}\".format(label_sample))","8a1401ad":"train.isnull().values.sum()","c0e240c6":"y_train = train.label\nx_train = train.drop(['label'], axis=1)","de989d2f":"x_train = (x_train \/ 255) - 0.5\ntest = (test \/ 255) - 0.5","9ae749c5":"sns.countplot(y_train)","f9902a24":"# reshape x_train and x_test to 3D image\nx_train = x_train.values.reshape(-1, 28, 28, 1)\ntest = test.values.reshape(-1, 28, 28, 1)","2e37e900":"x_part, x_val, y_part, y_val = train_test_split(\n    x_train, y_train, random_state=42)","b58b9e26":"# to_categorical for y_part and y_val\ny_part_oh = to_categorical(y_part, 10)\ny_val_oh = to_categorical(y_val, 10)","4c21963e":"def make_model():\n    # Feed-forward network \n    model = Sequential()\n\n    # CNN layers\n    # First two CNN layers with maxpooling and dropout\n    model.add(Conv2D(16, (3, 3), \n                     padding='same',\n                     input_shape=(28, 28, 1)))\n    model.add(LeakyReLU(0.1))\n    model.add(Conv2D(32, (3, 3), padding='same'))\n    model.add(LeakyReLU(0.1))\n    model.add(MaxPooling2D())\n    model.add(Dropout(0.25))\n    \n    #2nd two CNN layers with maxpooling and dropout\n    model.add(Conv2D(32, (3, 3), padding='same'))\n    model.add(LeakyReLU(0.1))\n    model.add(Conv2D(64, (3, 3), padding='same'))\n    model.add(LeakyReLU(0.1))\n    model.add(MaxPooling2D())\n    model.add(Dropout(0.25))\n    \n    # FC layers with dropout\n    model.add(Flatten())\n    model.add(Dense(256))\n    model.add(LeakyReLU(0.1))\n    model.add(Dropout(0.5))\n    \n    # FC Layers\n    model.add(Dense(10, activation='softmax'))\n    \n    return model","e64148f1":"s = tf.keras.backend.clear_session()\nmodel = make_model()\nmodel.summary()","5f30212f":"#Optimizer\n\nmodel.compile(\n    loss='categorical_crossentropy', # this is our cross-entropy\n    optimizer='adam',\n    metrics=['accuracy']  # report accuracy during training\n)","8caaec04":"# Training with model\nepochs=40\nmodel_log = model.fit(\n    x_part, \n    y_part_oh,\n    batch_size=32, \n    epochs=epochs,\n    validation_data=(x_val, y_val_oh),\n    verbose=10,\n)","393d6676":"plt.figure()\n# Accuracy Plot\nplt.subplot(2,1,1)\nplt.plot(model_log.history['acc'])\nplt.plot(model_log.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='lower right')\n\n# Loss Function Plot\nplt.subplot(2,1,2)\nplt.plot(model_log.history['loss'])\nplt.plot(model_log.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.tight_layout()","3a51aebb":"# Confusion Matrix\ny_pred_val = model.predict_proba(x_val)\ny_pred_classes = np.argmax(y_pred_val, axis=1)\ny_pred_max_probas = np.max(y_pred_val, axis=1)\n\ndigit_classes = [i for i in range(10)]","3b0c92f8":"# confusion matrix and accuracy\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\nplt.figure(figsize=(7, 6))\nplt.title('Confusion matrix', fontsize=16)\nplt.imshow(confusion_matrix(y_val, y_pred_classes))\nplt.xticks(np.arange(10), digit_classes, rotation=45, fontsize=12)\nplt.yticks(np.arange(10), digit_classes, fontsize=12)\nplt.colorbar()\nplt.show()\nprint(\"Test accuracy:\", accuracy_score(y_val, y_pred_classes))","e11e42c5":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=10, # 15 degree rotation\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n)\n\ndatagen.fit(x_part)\nmodel.fit_generator(datagen.flow(x_part, y_part_oh, batch_size=32),\n                    steps_per_epoch=len(x_train) \/ 32, epochs=epochs)","d03c5e77":"test_pred = model.predict(test)\ntest_result = np.argmax(test_pred, axis=1)\ntest_result = pd.Series(test_result,name=\"Label\")","3c4890bf":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),test_result],axis = 1)\nsubmission.to_csv(\"submission.csv\",index=False)","61b7023b":"Let's see how many digits are in the training set.","130597db":"# Accuracy Plot and Confusion Matrix","cc29e872":"# Data Augmentation\n\nTo improve the accuracy score, we can preprocess the image with image augmentation such as rotation, zoom-in and slice, etc\n\nhttps:\/\/keras.io\/preprocessing\/image\/","c6e543a2":"Split train and validation data.\nConvert labels to categorical matrix","47e543e0":"CNN for MNIST digits classification based on AlexNet (5 CONV layers and 3 FC layers)","940ddb62":"As shown int the above training set. The pixels in the image are in the range from 0 to 255. We should normalize it for CNN","6273eaab":"# Submission","da098738":"# EDA Phase"}}