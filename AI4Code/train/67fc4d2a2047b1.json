{"cell_type":{"f5a9a3ba":"code","6d8b9471":"code","500e0c69":"code","e1329e07":"code","6b0339e2":"code","a3e01534":"code","c7a715ed":"code","c9d81127":"code","379bf4c7":"code","3e0b3577":"code","4ac298ff":"code","a2123bd8":"code","32f861e5":"code","4783a065":"code","85dd0142":"code","c8b8f297":"code","9f59b6e3":"code","632081d3":"code","16e2471d":"code","4d1c7723":"code","00db609d":"code","44aafc2b":"code","1cfffddc":"code","ada2ada4":"code","d3ad59bd":"code","ca22c2d4":"code","68322f78":"code","0a7517ed":"code","3503c137":"code","ddf2d52b":"code","f847cd45":"code","e56ca91b":"code","1e223868":"code","98110483":"code","e585b6db":"code","f0e29b5d":"code","c6b017c7":"code","27bfb2df":"code","2e502152":"code","97423c6b":"code","26453207":"code","a0d608bd":"code","a12485cd":"code","4a88dde4":"code","b011210b":"code","34c249af":"code","ed837200":"code","35d593c2":"code","3a615d5d":"code","c2623490":"code","52efd103":"code","a43ab298":"code","3602efdc":"code","e2350612":"code","9925eb7a":"code","58cd0c3a":"code","5965b507":"code","8c83714b":"code","15c2149a":"code","7f5c9226":"code","981df0f1":"code","26ab02aa":"code","60035509":"code","62989fd5":"code","ca504069":"code","bc63ad08":"code","c710f2a4":"code","472091dd":"code","c6c6d921":"code","1df47a9a":"code","6827daab":"code","e3dc11da":"code","bc5fc7b0":"code","2fa8d0d5":"code","3849bd10":"code","2436a054":"code","f2489f34":"code","ea79252a":"code","37355a78":"code","56e8100d":"code","7205018a":"code","199eb495":"code","3128b542":"code","fe3dd728":"code","561e2694":"code","872f4ef8":"code","a312119f":"code","dbcde788":"code","e9883638":"code","f783facb":"code","f3b78d59":"code","d3027863":"code","6a78f54d":"code","2db0e5b3":"code","c02b4665":"code","a98d74d8":"code","bf958ba6":"code","77628dfb":"code","042217a3":"code","56944c61":"code","1776c5a1":"code","dea533e4":"code","95e1b184":"code","faa6f380":"code","1a102c18":"code","a3a0402d":"code","6a771cda":"code","9882a61c":"code","db1fbe34":"code","c4cbed78":"code","d6b317ec":"code","90909778":"code","3c30f9a6":"code","cf13fbb4":"code","f7e33336":"code","cf5d1c99":"code","51cc874a":"code","4f6abb81":"code","d920cf90":"code","a66c4464":"code","4116f49d":"code","d125587b":"code","2e1b3c62":"code","128886b2":"code","486c090a":"code","aad5a26c":"code","7856c6e0":"code","fd0668cd":"code","eaa14c3b":"code","bd172b4f":"code","955b2942":"code","e1c01f26":"code","94fd505a":"code","35280955":"code","9c6cbb30":"code","b68c8f32":"code","93b3df9e":"code","133a1267":"code","aa8a02a4":"code","7544de3c":"code","c95979f6":"code","8e8f186f":"code","44fbdffc":"code","772e5c3d":"code","a42b7240":"code","db28379d":"code","a10a64b1":"code","0cc49cf6":"code","ebe4d13c":"code","f595a0bc":"code","f3e38e17":"code","45c22896":"code","0a28211a":"code","3d399f2e":"code","7ed31b11":"code","051cd201":"code","6863239a":"code","b8ed374a":"code","c5f2822f":"code","47eef509":"code","7357ca7e":"code","8cc0964e":"code","0f1105c9":"code","73456439":"code","d8a924f0":"code","4227f482":"code","1f6d7175":"code","3b2e09ef":"code","c28dcbbf":"code","8ee86950":"code","4a8b99cf":"code","1da9fcba":"code","70af003c":"code","992b6359":"code","14d0f853":"code","a71f7897":"code","a1cab93e":"code","cfd8bfd3":"code","c6008749":"code","b5ff74b6":"code","414183ed":"code","62ac2bed":"code","0c2793aa":"code","ec9d5e4c":"code","52686688":"code","4048897f":"code","1e1736cf":"code","932e6753":"code","fb353324":"code","dd9ea00d":"code","fb0624c2":"code","2248acb5":"code","6649b3d1":"code","41857acd":"code","9e2191d0":"code","40130c93":"code","f45666ca":"code","c3b91c63":"code","92f95dfc":"code","0092f070":"code","58dc2163":"code","5302b12a":"code","52526107":"code","d4e06da3":"code","8ab914a8":"code","9d4245a4":"code","a420844a":"code","061b37b1":"code","e878c6c7":"code","42d5b119":"code","a15a14bc":"code","d32e86f6":"code","cf4540bd":"code","fdda6bce":"code","cd4e12c5":"code","935aabb3":"code","6496b82d":"code","6acfc887":"code","846229f7":"code","5aa0f99e":"code","c2e900a5":"code","d7e794fa":"code","1aa92d40":"code","a87dedf7":"code","89226cc0":"code","84da1322":"code","51e713d7":"code","3ce8a2cf":"code","b3c1cc4c":"code","c3e37b34":"code","74edc3ff":"code","070ee0dd":"code","0b889cda":"code","125f8111":"code","565c2872":"code","42dd735e":"code","ed635407":"code","13ce66dc":"code","a0544e5f":"code","24e946b0":"code","dfc9a0f8":"code","48f767b8":"code","b79dbe83":"code","cc07ea45":"code","9f2a9938":"code","ee5262d0":"code","bf5a62d9":"code","f49724a0":"code","dbb355a7":"code","48f09864":"code","cdfbb4d8":"code","f252a3bc":"code","34e4c676":"code","dd2cc08d":"code","0c10b8ca":"code","8900b0a1":"code","762624cc":"code","c8cd7c39":"code","22c1557d":"code","0e5bd1d7":"code","f6a8d15c":"code","17c1e166":"code","2e706d75":"code","6db8abb0":"code","b5067570":"code","7c13cd14":"code","5e593577":"code","5542d245":"code","25bea395":"code","53515dfe":"code","59830240":"code","5608e2ef":"code","dea10fb7":"code","1c92057a":"code","b23c1f42":"code","cb840383":"code","45d10b22":"code","fbaadb41":"code","3777a6e5":"code","2f52cc36":"code","63f83476":"code","e783bf24":"code","b34f6d6e":"code","ae18d837":"code","68142b00":"code","f791945e":"code","41e2448c":"code","c4a54e33":"code","f8bf66f8":"code","81d9f025":"code","3862e17d":"code","06ded229":"code","08233102":"code","8405406e":"code","654f67a9":"code","174ed99b":"code","16c8a6c7":"code","5357effb":"code","579db9fa":"code","2b510768":"code","39339074":"code","70507a13":"code","f63186df":"code","7047d3bb":"code","3bb0cba1":"code","a060e0a4":"code","ecab13c7":"code","986aaf74":"code","793538de":"code","e6268b28":"code","b1a2eb9e":"code","9a3eedec":"code","9fa9c229":"code","b3412ec5":"code","6da01afd":"code","4add277c":"code","bd5a2c69":"code","d3305617":"code","354ed681":"code","421d9be4":"code","51fd9a69":"code","e35727bc":"code","149aecd6":"code","fd266710":"code","2ee9030b":"code","1b3ef81e":"code","6db1b324":"code","bd6f2a96":"code","5e421e34":"code","3cbd6b9f":"code","69aab91a":"code","8aba210d":"code","eb601bc2":"code","03fbcee9":"code","211f487e":"code","7d1aadbc":"code","d4dfbea9":"code","81086434":"code","b511c2cd":"code","4064a724":"code","5b796111":"code","dd3bd12e":"code","6fafe1ad":"code","4248083e":"code","8d18c1e2":"code","680449ec":"code","ab4581fa":"code","35fa8ae7":"code","bcfbe573":"code","b2fcdc3f":"code","952fbbf0":"code","bd6e7c6b":"code","01a0971d":"code","941b07ca":"code","5558d99a":"code","441ab464":"code","fd8a0f1b":"code","068c6297":"code","a989c2b0":"code","b45dc67c":"code","865336f7":"code","97f33ed6":"code","3660b03d":"code","b9dc5be4":"code","6dad6629":"code","7edf960d":"code","d9e74940":"code","9c7536b3":"code","7675497b":"code","1d57b503":"code","5d655ca6":"code","621bd6d6":"code","293d6a16":"code","f0e53ea4":"code","e73cdc4b":"code","5b9847a6":"code","c8890dfc":"code","747d8586":"code","63a7225a":"code","70cb051d":"code","54c5d8a5":"code","3ae16aff":"code","a18315dd":"code","de1ab0d8":"code","749944ec":"code","3af53f5f":"code","c526f32b":"code","f6ddd320":"code","cc5d6cda":"code","c4c28c2d":"code","44dbfb63":"code","b0d20d0f":"code","a2fd96d5":"code","5d6afad8":"code","079a3a8e":"code","31930fdd":"code","5266371e":"code","7985a2f9":"code","183457d7":"code","fd03e4d5":"code","5fd77c7c":"code","301f37f2":"code","00748873":"code","a165c6fd":"code","be4dd8eb":"code","fabb62d0":"code","4727bce4":"code","9015ea52":"code","2257a76a":"code","ef1adaa0":"code","34627a3c":"code","ba19f692":"code","3df99657":"code","aa3b84e6":"code","8b197aea":"code","cca9e113":"code","9abfb65b":"code","9ab085e3":"code","6b2400a0":"code","2c574cae":"code","ec12fee3":"code","3fd0b063":"code","38b63804":"code","0ecc541b":"code","e885402a":"code","45a95fcc":"code","009b216d":"code","d38eba47":"code","8fb66022":"code","4e5af936":"code","644912ee":"code","21e01505":"code","1acfcba5":"code","6cc5dd90":"code","0d7fe974":"code","ecfe3a40":"code","0d383c34":"code","1d05c15d":"code","f54a462a":"code","4b9baf6e":"code","0e4b7060":"code","4583c6ab":"code","a3fe1393":"code","848b826a":"code","dff7dc9b":"code","71cb9d3d":"code","6c280156":"code","37f29ae7":"code","0dc8e13d":"code","18cb2cb8":"code","9291f635":"code","5e4755f1":"code","4007bcea":"code","e2dc7182":"code","079a55f9":"code","303c08ab":"code","c6b39708":"code","d9fcb5fa":"code","37206e22":"code","9f181610":"code","1347f043":"code","e20f5a6f":"code","5c93cbc4":"code","094c97ad":"code","19307aaf":"code","8b9c82f5":"code","e0ca6b4e":"code","9cf1e44b":"code","95fcacc9":"code","01ce7921":"code","dbd1caf9":"code","99489a0f":"code","bb3ed67e":"code","fc2f8c97":"code","dbc58fa5":"code","5a131d99":"code","4ca120ac":"code","4fb3ed48":"code","7a1afc9b":"code","38876be9":"code","85dad6e7":"code","203072b8":"code","442cd8db":"code","aefa0443":"code","5d477196":"code","b2d1459d":"code","d305e799":"code","ad25dfaf":"code","041c95a5":"code","4cbd21bd":"code","25fc86f8":"code","32c9155c":"code","e388c8eb":"code","720eb092":"code","a3a14643":"code","e93cc138":"code","cfb7e4f3":"code","4512e3db":"code","2040eba2":"code","f44b4248":"code","1388d0d8":"code","0c90a3ed":"code","24e28c74":"code","dabe43e0":"code","1663b3fc":"code","4f3d834c":"code","26ec5ce1":"code","103a5211":"code","18449c58":"code","2b70457a":"code","22432187":"code","388043d3":"code","a424f076":"code","21dc9a68":"code","342af663":"code","3e9b3109":"code","f110b441":"code","225e2c04":"code","9b932748":"code","5592c373":"code","edf17e32":"code","a5ff361c":"code","0164b8ed":"code","82fa191c":"code","ba81d2b1":"code","4279deb4":"code","573a038e":"code","7251ae0c":"code","320a7a3b":"code","2ee09550":"code","c3e60c4c":"code","82bc70a9":"code","688e410b":"code","d9c3a8d9":"code","8895199b":"code","215493f0":"code","458d4be1":"code","0f83841b":"code","ae9d4e75":"code","40bf7729":"code","27b8c994":"code","7f74a222":"code","ed06558e":"code","08253592":"code","3db4fd24":"code","0357e8f7":"code","dddca995":"code","518f7b7c":"code","d0034ddd":"code","8bb4347d":"code","3104ce9f":"code","3fa22497":"code","23066e79":"code","8eec121b":"code","02c29771":"code","fabd2908":"code","a8143d78":"code","b08ca32c":"code","34a3d05d":"code","2eaf57c8":"code","67e33a25":"code","a0c5af9b":"code","7f660f21":"code","9f43ee70":"code","cd386cc4":"code","7daaba91":"code","3a5128df":"code","a022c08a":"code","74ef2229":"code","4238ef58":"code","cbc3e515":"code","78ac01b8":"code","c05101f1":"code","09f5ce9d":"code","331aaf7f":"code","ec0edf8f":"code","03f3384e":"code","75e29b8a":"code","d3c1e5f8":"code","a34caff4":"code","6aa9dfc3":"code","cdb2801c":"code","65ff2861":"code","08266e81":"code","9cf974cb":"code","843c74a2":"code","fcb46227":"code","d374218a":"code","6108c256":"code","3eba198e":"code","a8cbc240":"code","3e30117b":"code","1c06f748":"code","3cb179bb":"code","922ea61c":"code","f310a7af":"code","72f79129":"code","cbce20b3":"code","3a74bd8c":"code","a3ef8c3c":"code","afb2b842":"code","bbd92b5e":"code","5ddd81b9":"code","248e3b6c":"code","a9430cd1":"code","9bbaa86b":"code","d5dbe1ac":"code","144679dc":"code","c595926f":"code","4166745f":"code","060bde75":"code","268832f0":"code","ff9493e0":"code","0058898d":"code","be4c1911":"code","18012ce7":"code","9ad1cc1a":"code","4d31ab71":"code","7c5bafeb":"code","b20f042b":"code","6c1352d6":"code","0b50681d":"code","98db82e2":"code","a6256cce":"code","79e06c7b":"code","7224a4da":"code","23e8e039":"code","8404c267":"code","f1536c4a":"code","5cf8605a":"code","0394054a":"code","d2ba3bc6":"code","0a904417":"code","0b17bc83":"code","eaeaee04":"code","77563d6b":"code","269cdf32":"code","b94e040d":"code","693ee30d":"code","6a1ca789":"code","32ec59ad":"code","4794e7ac":"code","d15087c3":"code","80dbb990":"code","9e3c80b2":"code","e38c8752":"code","b76d2b52":"code","1dd3aff8":"code","500c283f":"code","f7d0cd09":"code","bdc503b7":"code","5b616cf6":"code","21fb9052":"code","d1b47c67":"code","31d12197":"code","d988b7ed":"code","a41beef4":"code","26c73eab":"code","97d011e1":"code","968c57a8":"code","21ec4b8f":"code","2dfe6b45":"code","8012856b":"code","65cfbe8b":"code","7f994ce5":"code","295c4e73":"code","1f24661c":"code","23ba442e":"code","088bac90":"code","ff472ec8":"code","cf7acf16":"code","29db1a15":"code","12409cd4":"code","d0aefa88":"code","01a52bd7":"code","1b2d4732":"code","228ad5fb":"code","4677c169":"code","1ba6c4f8":"code","f1479d21":"code","c5766c35":"code","5a9480c3":"code","e828d8d6":"code","d707d4ef":"code","55d7a1ee":"code","5eadd803":"code","a3df9848":"code","3af900f1":"code","3f5ec81a":"code","187514a7":"code","1f1a33b8":"code","1fa7af8d":"code","6aff6b3d":"code","e427e3c8":"code","eda9e779":"code","642373b6":"code","bcd42fe0":"code","cf38d3ee":"code","1e506fa2":"code","995231fe":"code","cdec1341":"code","4a130d14":"code","2e0ea09e":"code","f670b9af":"code","f7639628":"code","6549b880":"code","671fffd1":"code","55d63d98":"code","64b7d934":"code","a318bde2":"code","6860ed65":"code","c0f63b5c":"code","0973edeb":"code","2fd7404e":"code","178f5716":"code","2a63619d":"code","eb84a95b":"code","3fab7847":"code","bb480827":"code","dc041f6a":"code","60078c42":"code","0e1fec8c":"code","f48e850e":"code","48abf578":"code","e3b5a893":"code","a42fd0ad":"code","bf7c38d6":"code","53a9d418":"code","66ff0c9d":"code","588727f8":"code","a1985ea4":"code","84105923":"code","db24ac7c":"code","ca5f38cf":"code","f43ae0e4":"code","e84f3bf7":"code","63a83947":"code","b678785d":"code","5486c0ce":"code","060e8688":"code","9c0ca45e":"code","033c0b29":"code","e1da6f40":"code","19ec4ddf":"code","bc14f526":"code","7585aba1":"code","7a094d54":"code","7c0f8638":"code","52ae11f4":"code","28ab4afa":"code","a4d7cc11":"code","e56cc878":"code","a6fd9463":"code","7024a3e1":"code","35384ffb":"code","6aa4bee4":"code","1e32e623":"code","7adfc10b":"code","88487a0b":"code","08665ba0":"code","030b5e6a":"code","891756a7":"code","5702c692":"code","4363b454":"code","60a68f5e":"code","874291e9":"code","2d0f4988":"code","52acc27f":"code","36a4c174":"code","8b2598c8":"code","8f954616":"code","ce0b762e":"code","5a7f02c6":"code","4ab39325":"code","d0648583":"code","34dcff4c":"code","5dc39f99":"code","b3fda12d":"code","fb9306c4":"code","a2e80e3f":"code","69b433c3":"code","b5291917":"code","cd6ef52b":"code","9ff8e31c":"code","09518315":"code","d1f2a54d":"code","e0d1ed40":"code","32240f28":"code","fad7b131":"code","7b54841d":"code","f6ebeae5":"code","1edecb6c":"code","591fbf4e":"code","adbab8a8":"code","be38a059":"code","3e3735ce":"code","c7763e01":"code","3af60e54":"code","62b73731":"code","dd0db4e7":"code","ae38a469":"code","0e0345a1":"code","383bceea":"code","1fdbd0cf":"code","9efa4f76":"code","a35558fa":"code","17493a0f":"code","6eb524ae":"code","55530808":"code","b6188b2a":"markdown","4341e679":"markdown","9d04d6fb":"markdown","842ad86d":"markdown","052b0ebd":"markdown","cd2326a0":"markdown","ee627b1b":"markdown","535e29dd":"markdown","a9028d01":"markdown","43034ecb":"markdown","86ef6b55":"markdown","e7e4e5cc":"markdown","d8534246":"markdown","49c0ac55":"markdown","ae4807e4":"markdown","4daf7537":"markdown","610cfdd2":"markdown","7e1c64b7":"markdown","68c4d958":"markdown","34e8ff63":"markdown","b871ef48":"markdown","7c03b97a":"markdown","6343e765":"markdown","0b9d2631":"markdown","2c8f9c77":"markdown","fd8ba9d1":"markdown","c38a0342":"markdown","b3481fa5":"markdown","6ed14888":"markdown","448fe2b2":"markdown","b2a654eb":"markdown","50baac85":"markdown","d1bcc068":"markdown","805a8a13":"markdown","0e48ccfe":"markdown","16be0fed":"markdown","a7da05c8":"markdown","e48e4dbf":"markdown","aa70e003":"markdown","d965812a":"markdown","91d02e64":"markdown","8f5d773a":"markdown","04e39060":"markdown","b9d9c30d":"markdown","51e9c6a9":"markdown","59f9627b":"markdown","138bbe05":"markdown","734f84b2":"markdown","d1d6249c":"markdown","e1997a36":"markdown","3298a297":"markdown","ee5e9f97":"markdown","dff1bb6a":"markdown","1901f834":"markdown","8ba6c2d5":"markdown","b2405361":"markdown","105fa84b":"markdown","1851e1a6":"markdown","1d0fdbc8":"markdown","683c15c9":"markdown","cbf59f25":"markdown","f9164472":"markdown","2de7af0a":"markdown","c4400ea1":"markdown","3283dd0d":"markdown","d6cdec94":"markdown","76eb8cd7":"markdown","74bfe0f4":"markdown","aa9146d1":"markdown","1f690411":"markdown","a90e1c76":"markdown","862dc9b2":"markdown","fb1ccdb9":"markdown","97a422d7":"markdown","1b9df470":"markdown","a347c34d":"markdown","38ebe7bc":"markdown","6fa8d0fd":"markdown","7561ecd5":"markdown","127cc71c":"markdown","a8c77786":"markdown","d99c01f0":"markdown","cbdf61cd":"markdown","6a5a6a15":"markdown","7b8b2fab":"markdown","e8b59d5c":"markdown","98b0948d":"markdown","c62e6455":"markdown","b98f193e":"markdown","9d18b2fd":"markdown","d901185f":"markdown","94e13d81":"markdown","e0a37587":"markdown","6ab9c145":"markdown","ad38ab46":"markdown","3afe448b":"markdown","f8b0b3da":"markdown","30372504":"markdown","bd40aafa":"markdown","6b2f0c01":"markdown","46f2b5b0":"markdown","aaa55ae3":"markdown","3723c105":"markdown","4a99d24d":"markdown","53a5307c":"markdown","0a510c1d":"markdown","874e7999":"markdown","ef230d82":"markdown","1d695b05":"markdown","8bd50762":"markdown","752653ec":"markdown","32740fe8":"markdown","bfcfcf0d":"markdown","5ed54e14":"markdown","e7a242c9":"markdown","ec906c4c":"markdown","66c343ea":"markdown","11511ad3":"markdown","518926bf":"markdown","f91026d0":"markdown","a781f6cb":"markdown","8e2287f6":"markdown","3f50a568":"markdown","7cb201e9":"markdown","efcb324d":"markdown","291b4be4":"markdown","b68bdae0":"markdown"},"source":{"f5a9a3ba":"import warnings\nwarnings.filterwarnings('ignore')\n\n#importing the libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\npd.set_option('display.float_format', '{:0.3f}'.format)","6d8b9471":"# Set ipython's max row display\npd.set_option('display.max_row', 500)\n\n# Set iPython's max column width to 100\npd.set_option('display.max_columns', 100)","500e0c69":"# Read the file\nconsumer = pd.read_csv('..\/input\/eleckartdata\/ConsumerElectronics.csv')","e1329e07":"# Take a look at the first 5 rows\nconsumer.head()","6b0339e2":"# Get info about the dataset\nconsumer.info()","a3e01534":"# Let's take a look at the statistical info of the dataset\nconsumer.describe(percentiles = [0.25, 0.5, 0.75, 0.90, 0.99, 0.999])","c7a715ed":"consumer.columns","c9d81127":"consumer.replace(r'^\\s+$', np.nan, regex=True, inplace = True)\nconsumer.replace('\\\\N', np.nan, inplace = True)","379bf4c7":"# let's check the null percentage for each column\nround(100*(consumer.isnull().sum()\/len(consumer.index)), 2)","3e0b3577":"#removing null valued GMV\nconsumer = consumer.loc[~(consumer.gmv.isnull())]","4ac298ff":"# let's check the null percentage for each column again\nround(100*(consumer.isnull().sum()\/len(consumer.index)), 2)","a2123bd8":"# Let's drop the rows that have product analytic vertical as null.\nconsumer = consumer[~pd.isnull(consumer.product_analytic_vertical)]","32f861e5":"# Let's now check the product_analytic_super_category unique values\nconsumer.product_analytic_super_category.unique()","4783a065":"consumer.drop('product_analytic_super_category',1, inplace = True)","85dd0142":"consumer.product_analytic_category.unique()","c8b8f297":"consumer.product_analytic_sub_category.unique()","9f59b6e3":"#The three product sub categories for the MMM are - camera accessory, home audio and gaming accessory.\n#Removing the rows with other sub categories\n\nconsumer = consumer.loc[(consumer.product_analytic_sub_category=='CameraAccessory') |\n                       (consumer.product_analytic_sub_category=='GamingAccessory')|\n                       (consumer.product_analytic_sub_category=='HomeAudio')]","632081d3":"consumer.product_analytic_vertical.unique()","16e2471d":"#Let's convert the data type of GMV\n\nconsumer['gmv'] = pd.to_numeric(consumer['gmv'])","4d1c7723":"#Checking the minimum and maximum values of GMV\nprint(consumer.gmv.min())\nprint(consumer.gmv.max())","00db609d":"consumer[consumer.duplicated(['fsn_id','order_date','order_id','order_item_id',\n                              'gmv','cust_id','pincode',\n                              'product_analytic_category','product_analytic_sub_category',\n                             'product_analytic_vertical'])]\n#consumer.loc[consumer.duplicated()]","44aafc2b":"len(consumer[consumer.duplicated(['fsn_id','order_date','order_id','order_item_id',\n                              'gmv','cust_id','pincode',\n                              'product_analytic_category','product_analytic_sub_category',\n                             'product_analytic_vertical'])])","1cfffddc":"#Removing duplicated values\nconsumer = consumer[~consumer.duplicated(['fsn_id','order_date','order_id','order_item_id',\n                              'gmv','cust_id','pincode',\n                              'product_analytic_category','product_analytic_sub_category',\n                             'product_analytic_vertical'])]","ada2ada4":"consumer.loc[consumer.duplicated()]","d3ad59bd":"#Checking nulls in gmv value\nconsumer.gmv.isnull().sum()","ca22c2d4":"consumer.shape","68322f78":"# The columns deliverybdays and deliverycdays are populated with \\N, which is incorrect.\n# Let's replace them with null.\nprint(consumer.deliverybdays.value_counts().head())\nprint(consumer.deliverycdays.value_counts().head())","0a7517ed":"print(consumer.deliverybdays.isnull().sum()\/len(consumer))\nprint(consumer.deliverycdays.isnull().sum()\/len(consumer))","3503c137":"# We can drop delivercdays and deliverybdays column as it has 79% null values.\nconsumer.drop(['deliverybdays', 'deliverycdays'],1, inplace = True)","ddf2d52b":"# Befor dealing with null values, let's first correct the data type of order_date\nconsumer['order_date'] = pd.to_datetime(consumer['order_date'])","f847cd45":"# We now need to check if the dates are not outside July 2015 and June 2016.\nconsumer.loc[(consumer.order_date < '2015-07-01') | (consumer.order_date >= '2016-07-01')]","e56ca91b":"consumer = consumer.loc[(consumer.order_date >= '2015-07-01')]\nconsumer = consumer.loc[(consumer.order_date < '2016-07-01')]","1e223868":"#Changing the name of the column s1_fact.order_payment_type\nconsumer.rename(columns={'s1_fact.order_payment_type':'order_payment_type'}, inplace=True)","98110483":"consumer.order_payment_type.value_counts()","e585b6db":"#Converting the datatype\nconsumer['pincode'] = pd.to_numeric(consumer['pincode'])","f0e29b5d":"#Let's see the values of pincode field\nconsumer.pincode.min()","c6b017c7":"consumer.pincode.isnull().sum()","27bfb2df":"# Before handling null values, there are negative values for pincode which we need to handle.\n# Let's make all the negative values as positive.\nconsumer.pincode = consumer.pincode.abs()","2e502152":"# Let's now check the frequency of pincodes to decide whether we can impute the missing pincodes with the highest frequency one.\nconsumer.pincode.value_counts()","97423c6b":"#pincode and cust_id doesn't seem to be of any use","26453207":"consumer.drop(['cust_id','pincode'], axis = 1, inplace = True)","a0d608bd":"consumer[(consumer.product_mrp == 0)].head()","a12485cd":"len(consumer[(consumer.product_mrp == 0)])","4a88dde4":"#Removing values with 0 MRP, since that is not possible at all\nconsumer = consumer.loc[~(consumer.product_mrp==0)]","b011210b":"consumer['gmv_per_unit'] = consumer.gmv\/consumer.units","34c249af":"#Replacing the values of MRP with GMV per unit where the values of GMV\/unit is greater than MRP\nconsumer['product_mrp'].loc[consumer.gmv_per_unit>consumer.product_mrp] = consumer['gmv_per_unit']","ed837200":"consumer.loc[consumer.gmv_per_unit>consumer.product_mrp]","35d593c2":"consumer.drop(['gmv_per_unit'],1,inplace=True)","3a615d5d":"consumer.shape","c2623490":"plt.figure(figsize=(20,8))\n\nplt.subplot(1,2,1)\nsns.boxplot(y=consumer.sla, palette=(\"cubehelix\"))\n\nplt.subplot(1,2,2)\nsns.boxplot(y=consumer.product_procurement_sla, palette=(\"cubehelix\"))","52efd103":"plt.figure(figsize=(20,8))\n\nplt.subplot(1,2,1)\nsns.distplot(consumer.sla)\n\nplt.subplot(1,2,2)\nsns.distplot(consumer.product_procurement_sla)","a43ab298":"consumer.sla.describe(percentiles=[0.0,0.25,0.5,0.75,0.9,0.95,0.99,1.0])","3602efdc":"consumer.product_procurement_sla.describe(percentiles=[0.0,0.25,0.5,0.75,0.9,0.95,0.99,1.0])","e2350612":"#Converting negative values to the positive\nlen(consumer.loc[consumer.product_procurement_sla<0])","9925eb7a":"consumer.product_procurement_sla = abs(consumer.product_procurement_sla)","58cd0c3a":"consumer.sla.std()","5965b507":"#Taking three sigma values for outliers treatment\nprint(consumer.sla.mean()+(3*(consumer.sla.std())))\nprint(consumer.sla.mean()-(3*(consumer.sla.std())))","8c83714b":"consumer.product_procurement_sla.std()","15c2149a":"#Taking three sigma values for outliers treatment\nprint(consumer.product_procurement_sla.mean()+(3*(consumer.product_procurement_sla.std())))\nprint(consumer.product_procurement_sla.mean()-(3*(consumer.product_procurement_sla.std())))","7f5c9226":"# Capping the values at three sigma value\nlen(consumer[consumer.sla > 14])","981df0f1":"# Let's cap the SLAs.\nconsumer.loc[consumer.sla > 14,'sla'] = 14","26ab02aa":"# Similarly, the min value of product procurement sla is 0 and the max value is 15. However, three sigma value is 7. \nprint(len(consumer[consumer.product_procurement_sla > 7]))","60035509":"# Let's cap the product procuremtn SLAs.\nconsumer.loc[consumer.product_procurement_sla > 7,'product_procurement_sla'] = 7","62989fd5":"consumer.shape","ca504069":"consumer.loc[consumer.duplicated()]","bc63ad08":"len(consumer[consumer.duplicated(['order_id','order_item_id'])])","c710f2a4":"consumer = consumer[~consumer.duplicated(['order_id','order_item_id'])]","472091dd":"consumer.describe()","c6c6d921":"plt.figure(figsize=(20,8))\n\nplt.subplot(1,2,1)\nsns.distplot(consumer.gmv)\n\nplt.subplot(1,2,2)\nsns.distplot(consumer.product_mrp)\n\nplt.show()","1df47a9a":"#2. gmv (Gross Merchendising Value - The cost price at which the item is sold multiplied by number of units)\n\n# Let's derive listing price, which is nothing but gmv\/units\n\nconsumer['listing_price'] = round((consumer.gmv\/consumer.units),2)","6827daab":"#Let's check if there are any rows with listing price > MRP\n\nlen(consumer.loc[consumer.listing_price>consumer.product_mrp])","e3dc11da":"# Let's now calculate the discount %, which is nothing but (mrp-list price)\/mrp\nconsumer['discount'] = round(((consumer.product_mrp - consumer.listing_price)\/(consumer.product_mrp)),2)","bc5fc7b0":"consumer['discount'].describe()","2fa8d0d5":"consumer['Order_Item_Value'] = consumer['product_mrp'] * consumer['units']","3849bd10":"# We can create the week number\nconsumer['week'] = np.where(consumer.Year == 2015, (consumer.order_date.dt.week - pd.to_datetime('2015-07-01').week + 1), consumer.order_date.dt.week+27)\n\n# Dates like 2016-01-01 will be 53rd week as per ISO standard, hence the week value would be 53+27=80.\n# We can make those values as week 27\nconsumer.week.values[(consumer.Year == 2016) & (consumer.week == 80)] = 27","2436a054":"### Prepaid = '1' or COD = '0'\nconsumer['order_payment_type'] = np.where(consumer['order_payment_type'] == \"Prepaid\",1,0)","f2489f34":"### Creating Calendar for the period\ncalendar = pd.DataFrame(pd.date_range('2015-07-01','2016-06-30').tolist(), columns = ['Date'])\n### Mapping week in the calendar\ncalendar['week'] = calendar.Date.dt.week\n### Jan 2016 should be week 54 ,not week 1.\ncalendar['week'] = np.where((calendar['week'] <= 26) & (calendar.Date.dt.year == 2016), calendar['week']+53, calendar['week'])\n","ea79252a":"### Special Sales List\n\nspecial_sales_list = [\"2015-07-18\",\"2015-07-19\",\"2015-08-15\",\"2015-08-16\",\"2015-08-17\",\"2015-08-28\",\"2015-08-29\",\n                      \"2015-08-30\",\"2015-10-15\",\"2015-10-16\",\"2015-10-17\",\"2015-11-07\",\"2015-11-08\",\"2015-11-09\",\n                      \"2015-11-10\",\"2015-11-11\",\"2015-11-12\",\"2015-11-13\",\"2015-11-14\",\"2015-12-25\",\"2015-12-26\",\n                      \"2015-12-27\",\"2015-12-28\",\"2015-12-29\",\"2015-12-30\",\"2015-12-31\",\"2016-01-01\",\"2016-01-02\",\n                      \"2016-01-03\",\"2016-01-20\",\"2016-01-21\",\"2016-01-22\",\"2016-02-01\",\"2016-02-02\",\"2016-02-14\",\n                      \"2016-02-15\",\"2016-02-20\",\"2016-02-21\",\"2016-03-07\",\"2016-03-08\",\"2016-03-09\",\"2016-05-25\",\n                      \"2016-05-26\",\"2016-05-27\"]\n\nss_list = pd.DataFrame(special_sales_list,columns = ['Date'])\nss_list['Date'] = pd.to_datetime(ss_list['Date'])\nss_list['Special_sales'] = True","37355a78":"calendar = calendar.merge(ss_list, 'left')\ncalendar.fillna(False, inplace = True)","56e8100d":"calendar['Special_sales'] = calendar['Special_sales'].astype(int)","7205018a":"calendar.head()","199eb495":"calendar['Payday'] = ((calendar['Date'].dt.day == 1) | (calendar['Date'].dt.day == 15)).astype(int)","3128b542":"### Ontario Climate data of year 2015-2016 \nontario_climate_2015 = pd.DataFrame(pd.read_csv('..\/input\/eleckartdata\/ONTARIO-2015.csv',encoding=\"ISO-8859-1\",skiprows=24))\nontario_climate_2016 = pd.DataFrame(pd.read_csv('..\/input\/eleckartdata\/ONTARIO-2016.csv',encoding=\"ISO-8859-1\",skiprows=24))","fe3dd728":"### Merge Calendar with dataset on week\n\nontario_climate = ontario_climate_2015.append(ontario_climate_2016)\nontario_climate = ontario_climate.reset_index()\nontario_climate.head()","561e2694":"### Checking for any nan values\n\nround((ontario_climate.isnull().sum()\/len(ontario_climate.index))*100,2)","872f4ef8":"### Dropping columns we do not require in the analysis.\nontario_climate.drop(['index','Data Quality','Max Temp Flag','Min Temp Flag','Mean Temp Flag',\n                      'Heat Deg Days Flag','Cool Deg Days Flag','Total Rain Flag','Total Snow Flag',\n                      'Total Precip Flag','Snow on Grnd Flag','Dir of Max Gust (10s deg)','Dir of Max Gust Flag',\n                      'Spd of Max Gust (km\/h)','Spd of Max Gust Flag'], axis = 1, inplace = True)","a312119f":"ontario_climate.columns = ['Date','Year','Month','Day','max_temp_C','min_temp_C','mean_temp_C','heat_deg_days','cool_deg_days','total_rain_mm','total_snow_cm','total_precip_mm','snow_on_grnd_cm']","dbcde788":"ontario_climate['Date'] = ontario_climate['Date'].apply(pd.to_datetime)","e9883638":"### Keeping Climate data from July 15 to June 16\n\nontario_climate=ontario_climate[(ontario_climate['Month'] >= 7) & (ontario_climate['Year'] == 2015) \n                               |(ontario_climate['Month'] <= 6) & (ontario_climate['Year'] == 2016)]","f783facb":"### Mapping week in the Climate data\nontario_climate['week'] = ontario_climate.Date.dt.week\n\n### Jan 2016 should be week 54 ,not week 1.\nontario_climate['week'] = np.where((ontario_climate['week'] <= 26) & (ontario_climate['Year'] == 2016), ontario_climate['week']+53, ontario_climate['week'])\n\nontario_climate = ontario_climate.reset_index()\nontario_climate.drop('index',axis=1,inplace=True)\nontario_climate.head()","f3b78d59":"### Checking for any nan values\n\nround((ontario_climate.isnull().sum()\/len(ontario_climate.index))*100,2)","d3027863":"### Replacing Nan with mean value\nontario_climate['max_temp_C'] = ontario_climate['max_temp_C'].fillna(ontario_climate['max_temp_C'].mean())\nontario_climate['min_temp_C'] = ontario_climate['min_temp_C'].fillna(ontario_climate['min_temp_C'].mean())\nontario_climate['mean_temp_C'] = ontario_climate['mean_temp_C'].fillna(ontario_climate['mean_temp_C'].mean())\nontario_climate['heat_deg_days'] = ontario_climate['heat_deg_days'].fillna(ontario_climate['heat_deg_days'].mean())\nontario_climate['cool_deg_days'] = ontario_climate['cool_deg_days'].fillna(ontario_climate['cool_deg_days'].mean())\nontario_climate['total_rain_mm'] = ontario_climate['total_rain_mm'].fillna(ontario_climate['total_rain_mm'].mean())\nontario_climate['total_snow_cm'] = ontario_climate['total_snow_cm'].fillna(ontario_climate['total_snow_cm'].mean())\nontario_climate['total_precip_mm'] = ontario_climate['total_precip_mm'].fillna(ontario_climate['total_precip_mm'].mean())\nontario_climate['snow_on_grnd_cm'] = ontario_climate['snow_on_grnd_cm'].fillna(ontario_climate['snow_on_grnd_cm'].mean())\n","6a78f54d":"ontario_climate.head()","2db0e5b3":"nps_score = pd.read_excel(\"..\/input\/eleckartdata\/Media data and other information.xlsx\", sheet_name='Monthly NPS Score', skiprows=1)","c02b4665":"### Transforming NPS and Stock_index\nnps_score = nps_score.T.reset_index(drop=True)\nnps_score.columns = ['NPS','Stock_Index']\nnps_score = nps_score.drop(nps_score.index[[0]]).reset_index(drop=True)","a98d74d8":"### Adding Month and Year\nnps_score['Month'] = pd.Series([7,8,9,10,11,12,1,2,3,4,5,6])\nnps_score['Year'] = pd.Series([2015,2015,2015,2015,2015,2015,2016,2016,2016,2016,2016,2016])","bf958ba6":"nps_score['NPS'] = nps_score['NPS'].astype(float)\nnps_score['Stock_Index'] = nps_score['Stock_Index'].astype(float)","77628dfb":"nps_score.head()","042217a3":"calendar = calendar.merge(ontario_climate, 'left')","56944c61":"calendar = calendar.merge(nps_score, 'left')","1776c5a1":"# We can create the week number\ncalendar['week'] = np.where(calendar.Date.dt.year == 2015, (calendar.Date.dt.week - pd.to_datetime('2015-07-01').week + 1), calendar.Date.dt.week+27)\n\n# Dates like 2016-01-01 will be 53rd week as per ISO standard, hence the week value would be 53+27=80.\n# We can make those values as week 27\ncalendar.week.values[(calendar.Date.dt.year == 2016) & (calendar.week == 80)] = 27","dea533e4":"calendar.head()","95e1b184":"calendar = pd.DataFrame(calendar.groupby('week').agg({'NPS':'mean','Stock_Index':'mean',\n                                                             'Special_sales':'mean','Payday':'mean',\n                                                             'max_temp_C':'mean','min_temp_C':'mean',\n                                                             'mean_temp_C':'mean','heat_deg_days':'mean',\n                                                             'cool_deg_days':'mean','total_rain_mm':'mean',\n                                                             'total_snow_cm':'mean','total_precip_mm':'mean',\n                                                             'snow_on_grnd_cm':'mean'}))","faa6f380":"calendar.reset_index(inplace = True)","1a102c18":"calendar.head()","a3a0402d":"### Marketing Investment Data\nmarketing = pd.read_excel(\"..\/input\/eleckartdata\/Media data and other information.xlsx\", sheet_name='Media Investment', skipfooter = 4, skiprows=2)","6a771cda":"marketing.drop('Unnamed: 0', axis = 1, inplace = True)\nmarketing.replace(np.nan,0,inplace = True)\nmarketing['Date'] = pd.to_datetime(marketing[['Year', 'Month']].assign(DAY=1))\nmarketing.set_index('Date', inplace = True)\nmarketing","9882a61c":"### Renaming the columns\n\nmarketing.columns = ['Year','Month','Total_Investment','TV','Digital','Sponsorship','Content_marketing',\n                     'Online_marketing','Affiliates','SEM','Radio','Other']","db1fbe34":"### convert to datetimeindex\nmarketing.index = pd.to_datetime(marketing.index)","c4cbed78":"marketing","d6b317ec":"### add new next month for correct resample\nidx = marketing.index[-1] + pd.offsets.MonthBegin(1)\nidx","90909778":"marketing = marketing.append(marketing.iloc[[-1]].rename({marketing.index[-1]: idx}))\nmarketing","3c30f9a6":"#Resampling the data on weekly frequency\nmarketing = marketing.resample('W').ffill().iloc[:-1]\nmarketing","cf13fbb4":"### divide by size of months\nmarketing['Total_Investment'] \/= marketing.resample('MS')['Total_Investment'].transform('size')\nmarketing['TV'] \/= marketing.resample('MS')['TV'].transform('size')\nmarketing['Digital'] \/= marketing.resample('MS')['Digital'].transform('size')\nmarketing['Sponsorship'] \/= marketing.resample('MS')['Sponsorship'].transform('size')\nmarketing['Content_marketing'] \/= marketing.resample('MS')['Content_marketing'].transform('size')\nmarketing['Online_marketing'] \/= marketing.resample('MS')['Online_marketing'].transform('size')\nmarketing['Affiliates'] \/= marketing.resample('MS')['Affiliates'].transform('size')\nmarketing['SEM'] \/= marketing.resample('MS')['SEM'].transform('size')\nmarketing['Radio'] \/= marketing.resample('MS')['Radio'].transform('size')\nmarketing['Other'] \/= marketing.resample('MS')['Other'].transform('size')","f7e33336":"marketing.head()","cf5d1c99":"marketing.reset_index(inplace = True)\n\n###  Mapping week in the marketing\n\nmarketing['Date'] = pd.to_datetime(marketing['Date'])\n# We can create the week number\nmarketing['week'] = np.where(marketing.Date.dt.year == 2015, (marketing.Date.dt.week - pd.to_datetime('2015-07-01').week + 1), marketing.Date.dt.week+27)\n\nmarketing.week.values[(marketing.Date.dt.year == 2016) & (marketing.week == 80)] = 27\nmarketing.sort_values('week', inplace = True)","51cc874a":"marketing.head()","4f6abb81":"def adstocked_advertising(adstock_rate=0.5, advertising = marketing):\n    \n    adstocked_advertising = []\n    for i in range(len(advertising)):\n        if i == 0: \n            adstocked_advertising.append(advertising.iloc[i])\n        else:\n            adstocked_advertising.append(advertising.iloc[i] + adstock_rate * advertising.iloc[i-1])            \n    return adstocked_advertising\n   ","d920cf90":"adstock = pd.DataFrame()","a66c4464":"adstock['TV_ads'] = adstocked_advertising(adstock_rate=0.5, advertising = marketing['TV'])\n\nadstock['Digital_ads'] = adstocked_advertising(adstock_rate=0.5, advertising = marketing['Digital'])\n\nadstock['Sponsorship_ads'] = adstocked_advertising(adstock_rate=0.5, advertising = marketing['Sponsorship'])\n\nadstock['Content_marketing_ads'] = adstocked_advertising(adstock_rate=0.5, advertising = marketing['Content_marketing'])\n\nadstock['Online_marketing_ads'] = adstocked_advertising(adstock_rate=0.5, advertising = marketing['Online_marketing'])\n\nadstock['Affiliates_ads'] = adstocked_advertising(adstock_rate=0.5, advertising = marketing['Affiliates'])\n\nadstock['SEM_ads'] = adstocked_advertising(adstock_rate=0.5, advertising = marketing['SEM'])\n\nadstock['Radio_ads'] = adstocked_advertising(adstock_rate=0.5, advertising = marketing['Radio'])\n\nadstock['Other_ads'] = adstocked_advertising(adstock_rate=0.5, advertising = marketing['Other'])","4116f49d":"adstock.head()","d125587b":"marketing = pd.concat([marketing,adstock] ,axis=1)","2e1b3c62":"marketing.head()","128886b2":"# The premium-ness of the product depends on the MRP. Higher the MRP, more premium is the product.\n# Let's check the percentiles of MRP in the dataset.\n\nconsumer.product_mrp.describe(percentiles=[0.25,0.5,0.75,0.8,0.9,0.95,0.99])","486c090a":"# Let's assume that products with MRP greater than 90 percentile to be premium products.\n# Create a dataframe with mrp, number of units sold and gmv against each product vertical to analyse better.\nprod_cat = pd.DataFrame(pd.pivot_table(consumer, values = ['units','product_mrp', 'gmv'], index = ['product_analytic_vertical'], \n               aggfunc={'units':np.sum, 'product_mrp':np.mean, 'gmv':np.sum}).to_records())","aad5a26c":"# Marking products with MRP greater than 90th percentile with 1 and rest with 0\nprod_cat['premium_product'] = np.where((prod_cat.product_mrp>consumer.product_mrp.quantile(0.9)),1,0)","7856c6e0":"prod_cat.loc[prod_cat.premium_product==1]","fd0668cd":"plt.figure(figsize=(15,5))\nsns.barplot(x = prod_cat.product_analytic_vertical, y=prod_cat.gmv, hue=prod_cat.premium_product)\nplt.xticks(rotation=90)\nplt.show()","eaa14c3b":"consumer = consumer.merge(prod_cat[['product_analytic_vertical', 'premium_product']] , left_on='product_analytic_vertical', \n            right_on='product_analytic_vertical',\n                   how = 'inner')","bd172b4f":"sales = consumer.copy()","955b2942":"consumer.drop(['product_analytic_vertical'],1,inplace=True)","e1c01f26":"consumer.head()","94fd505a":"camera_df = consumer[consumer['product_analytic_sub_category'] == 'CameraAccessory']","35280955":"###  Removing outliers is important as\n###  1. There may be some garbage value.\n###  2. Bulk orders can skew the analysis","9c6cbb30":"### Outlier Analysis\nfig, axs = plt.subplots(1,3, figsize = (20,4))\nplt1 = sns.boxplot(camera_df['gmv'], ax = axs[0])\nplt2 = sns.boxplot(camera_df['units'], ax = axs[2])\nplt4 = sns.boxplot(camera_df['product_mrp'], ax = axs[1])\nplt.tight_layout()","b68c8f32":"### Treating outliers\n### Outlier treatment for gmv & product_mrp\nQ1 = camera_df.gmv.quantile(0.25)\nQ3 = camera_df.gmv.quantile(0.75)\nIQR = Q3 - Q1\ncamera_df = camera_df[(camera_df.gmv >= Q1 - 1.5*IQR) & (camera_df.gmv <= Q3 + 1.5*IQR)]\nQ1 = camera_df.product_mrp.quantile(0.25)\nQ3 = camera_df.product_mrp.quantile(0.75)\nIQR = Q3 - Q1\ncamera_df = camera_df[(camera_df.product_mrp >= Q1 - 1.5*IQR) & (camera_df.product_mrp <= Q3 + 1.5*IQR)]","93b3df9e":"### Outlier Analysis\nfig, axs = plt.subplots(1,3, figsize = (20,4))\nplt1 = sns.boxplot(camera_df['gmv'], ax = axs[0])\nplt2 = sns.boxplot(camera_df['units'], ax = axs[2])\nplt4 = sns.boxplot(camera_df['product_mrp'], ax = axs[1])\nplt.tight_layout()","133a1267":"camera_df.columns","aa8a02a4":"camera_df.head()","7544de3c":"### Aggregating dataset on weekly level\n\nca_week = pd.DataFrame(camera_df.groupby('week').agg({'gmv':'sum','listing_price':'mean',\n                                                             'product_mrp':'mean','discount':'mean',\n                                                             'sla':'mean','product_procurement_sla':'mean',\n                                                             'fsn_id':pd.Series.nunique,'order_item_id':pd.Series.nunique,\n                                                             'order_id': pd.Series.nunique,\n                                                             'order_payment_type':'sum',\n                                                            'premium_product':'sum'}))\n\nca_week.reset_index( inplace = True)","c95979f6":"ca_week.head()","8e8f186f":"### Sum of GMV \/ No of unique Orders\n\nca_week['AOV'] = ca_week['gmv']\/ca_week['order_id']","44fbdffc":"ca_week['online_order_perc'] = ca_week['order_payment_type']*100\/ca_week['order_item_id']","772e5c3d":"ca_week.week.unique()","a42b7240":"calendar.week.unique()","db28379d":"ca_week['week'] = ca_week['week'].astype(int)\ncalendar['week'] = calendar['week'].astype(int)","a10a64b1":"ca_week = ca_week.merge(marketing, how = 'left', on = 'week')","0cc49cf6":"ca_week = ca_week.merge(calendar, how = 'left', on = 'week')","ebe4d13c":"ca_week.head()","f595a0bc":"ca_week_viz = ca_week.round(2)","f3e38e17":"sns.distplot(ca_week_viz['gmv'],kde=True)","45c22896":"plt.figure(figsize=(15, 5))\nsns.barplot(ca_week_viz['week'],ca_week_viz['gmv'])","0a28211a":"ca_week_viz.columns","3d399f2e":"fig, axs = plt.subplots(2,4,figsize=(16,8))\n\nplt1 = sns.scatterplot(x = 'Total_Investment', y = 'gmv', data = ca_week_viz, ax = axs[0,0])\n\nplt2 = sns.scatterplot(x = 'TV', y = 'gmv', data = ca_week_viz, ax = axs[0,1])\n\nplt3 = sns.scatterplot(x = 'Digital', y = 'gmv', data = ca_week_viz, ax = axs[0,2])\n\nplt4 = sns.scatterplot(x = 'Sponsorship', y = 'gmv', data = ca_week_viz, ax = axs[0,3])\n\nplt5 = sns.scatterplot(x = 'Content_marketing', y = 'gmv', data = ca_week_viz, ax = axs[1,0])\n\nplt6 = sns.scatterplot(x = 'Online_marketing', y = 'gmv', data = ca_week_viz, ax = axs[1,1])\n\nplt7 = sns.scatterplot(x = 'Affiliates', y = 'gmv', data = ca_week_viz, ax = axs[1,2])\n\nplt8 = sns.scatterplot(x = 'SEM', y = 'gmv', data = ca_week_viz, ax = axs[1,3])\n\nplt.tight_layout()","7ed31b11":"plt.figure(figsize=(20, 5))\nsns.barplot(x= ca_week_viz['week'], y =ca_week_viz['gmv'], hue = ca_week_viz['Special_sales'], dodge = False)\nplt.show()","051cd201":"plt.figure(figsize=(20, 5))\nsns.barplot(x= ca_week_viz['week'], y =ca_week_viz['gmv'], hue = pd.cut(ca_week_viz['discount'],3), dodge = False)\nplt.show()","6863239a":"### ca_week\n\n### Moving Average for listing_price and discount\n\n### ca_week = ca_week.sort_values('order_date')\n\nca_week[['MA2_LP','MA2_Discount']] = ca_week[['listing_price','discount']].rolling(window=2,min_periods=1).mean()\nca_week[['MA3_LP','MA3_Discount']] = ca_week[['listing_price','discount']].rolling(window=3,min_periods=1).mean()\nca_week[['MA4_LP','MA4_Discount']] = ca_week[['listing_price','discount']].rolling(window=4,min_periods=1).mean()\n\n### Reference listed price Inflation \n\nca_week['MA2_listed_price'] = (ca_week['listing_price']-ca_week['MA2_LP'])\/ca_week['MA2_LP']\nca_week['MA3_listed_price'] = (ca_week['listing_price']-ca_week['MA3_LP'])\/ca_week['MA3_LP']\nca_week['MA4_listed_price'] = (ca_week['listing_price']-ca_week['MA4_LP'])\/ca_week['MA4_LP']\n\n### Reference discount Inflation\n\nca_week['MA2_discount_offer'] = (ca_week['discount']-ca_week['MA2_Discount'])\/ca_week['MA2_Discount']\nca_week['MA3_discount_offer'] = (ca_week['discount']-ca_week['MA3_Discount'])\/ca_week['MA3_Discount']\nca_week['MA4_discount_offer'] = (ca_week['discount']-ca_week['MA4_Discount'])\/ca_week['MA4_Discount']\n\n\nca_week.drop(['MA2_LP','MA3_LP','MA4_LP','MA2_Discount','MA3_Discount','MA4_Discount'], axis = 1, inplace = True)  \nca_week.head()\n\n","b8ed374a":"# ### To identify multicollinearity between variable\nplt.figure(figsize=(20,20))\nsns.heatmap(ca_week.corr(),annot = True, cmap=\"YlGnBu\")\nplt.show()","c5f2822f":"### Highly Correlated Columns should be dropped\n\nca_week.drop(['TV', 'Digital', 'Sponsorship', 'Content_marketing','Online_marketing', 'Affiliates', 'SEM','Radio',\n              'Other'], axis = 1, inplace = True)","47eef509":"plt.figure(figsize=(25,20))\nsns.heatmap(ca_week.corr(), cmap=\"coolwarm\", annot=True)\nplt.show()","7357ca7e":"ca_week.drop(['Affiliates_ads','SEM_ads','Digital_ads','Radio_ads','Other_ads','mean_temp_C','min_temp_C',\n              'order_id','order_item_id','total_precip_mm','Total_Investment','MA3_discount_offer',\n               'MA3_listed_price','AOV','max_temp_C','MA2_listed_price','MA4_discount_offer'],1,inplace=True)","8cc0964e":"#Successfully removed more than 90% correlation","0f1105c9":"### Lag of listed_price, discount_offer, NPS, Special_sales\n\nca_week['lag_1_listed_price'] = ca_week['listing_price'].shift(-1).fillna(0)\nca_week['lag_2_listed_price'] = ca_week['listing_price'].shift(-2).fillna(0)\nca_week['lag_3_listed_price'] = ca_week['listing_price'].shift(-3).fillna(0)\n\nca_week['lag_1_discount'] = ca_week['discount'].shift(-1).fillna(0)\nca_week['lag_2_discount'] = ca_week['discount'].shift(-2).fillna(0)\nca_week['lag_3_discount'] = ca_week['discount'].shift(-3).fillna(0)\n\nca_week['lag_1_Stock_Index'] = ca_week['Stock_Index'].shift(-1).fillna(0)\nca_week['lag_2_Stock_Index'] = ca_week['Stock_Index'].shift(-2).fillna(0)\nca_week['lag_3_Stock_Index'] = ca_week['Stock_Index'].shift(-3).fillna(0)\n\nca_week['lag_1_Special_sales'] = ca_week['Special_sales'].shift(-1).fillna(0)\nca_week['lag_2_Special_sales'] = ca_week['Special_sales'].shift(-2).fillna(0)\nca_week['lag_3_Special_sales'] = ca_week['Special_sales'].shift(-3).fillna(0)\n\nca_week['lag_1_Payday'] = ca_week['Payday'].shift(-1).fillna(0)\nca_week['lag_2_Payday'] = ca_week['Payday'].shift(-2).fillna(0)\nca_week['lag_3_Payday'] = ca_week['Payday'].shift(-3).fillna(0)\n\nca_week['lag_1_NPS'] = ca_week['NPS'].shift(-1).fillna(0)\nca_week['lag_2_NPS'] = ca_week['NPS'].shift(-2).fillna(0)\nca_week['lag_3_NPS'] = ca_week['NPS'].shift(-3).fillna(0)","73456439":"ca_week.head()","d8a924f0":"gaming_accessory = consumer[consumer['product_analytic_sub_category'] == 'GamingAccessory']","4227f482":"###  Removing outliers is important as\n###  1. There may be some garbage value.\n###  2. Bulk orders can skew the analysis","1f6d7175":"### Outlier Analysis\nfig, axs = plt.subplots(1,3, figsize = (20,4))\nplt1 = sns.boxplot(gaming_accessory['gmv'], ax = axs[0])\nplt2 = sns.boxplot(gaming_accessory['units'], ax = axs[2])\nplt4 = sns.boxplot(gaming_accessory['product_mrp'], ax = axs[1])\nplt.tight_layout()","3b2e09ef":"### Treating outliers\n### Outlier treatment for gmv & product_mrp\nQ1 = gaming_accessory.gmv.quantile(0.25)\nQ3 = gaming_accessory.gmv.quantile(0.75)\nIQR = Q3 - Q1\ngaming_accessory = gaming_accessory[(gaming_accessory.gmv >= Q1 - 1.5*IQR) & (gaming_accessory.gmv <= Q3 + 1.5*IQR)]\nQ1 = gaming_accessory.product_mrp.quantile(0.25)\nQ3 = gaming_accessory.product_mrp.quantile(0.75)\nIQR = Q3 - Q1\ngaming_accessory = gaming_accessory[(gaming_accessory.product_mrp >= Q1 - 1.5*IQR) & (gaming_accessory.product_mrp <= Q3 + 1.5*IQR)]","c28dcbbf":"### Outlier Analysis\nfig, axs = plt.subplots(1,3, figsize = (20,4))\nplt1 = sns.boxplot(gaming_accessory['gmv'], ax = axs[0])\nplt2 = sns.boxplot(gaming_accessory['units'], ax = axs[2])\nplt4 = sns.boxplot(gaming_accessory['product_mrp'], ax = axs[1])\nplt.tight_layout()","8ee86950":"gaming_accessory.columns","4a8b99cf":"### Aggregating dataset on weekly level\n\nga_week = pd.DataFrame(gaming_accessory.groupby('week').agg({'gmv':'sum','listing_price':'mean',\n                                                             'product_mrp':'mean','discount':'mean',\n                                                             'sla':'mean','product_procurement_sla':'mean',\n                                                             'fsn_id':pd.Series.nunique,'order_item_id':pd.Series.nunique,\n                                                             'order_id': pd.Series.nunique,\n                                                             'order_payment_type':'sum'}))\n\nga_week.reset_index( inplace = True)","1da9fcba":"ga_week.head()","70af003c":"### Sum of GMV \/ No of unique Orders\n\nga_week['AOV'] = ga_week['gmv']\/ga_week['order_id']","992b6359":"ga_week['online_order_perc'] = ga_week['order_payment_type']*100\/ga_week['order_item_id']","14d0f853":"ga_week.head()","a71f7897":"ga_week = ga_week.merge(marketing, how = 'left', on = 'week')","a1cab93e":"ga_week = ga_week.merge(calendar, how = 'left', on = 'week')","cfd8bfd3":"ga_week.head()","c6008749":"ga_week_viz = ga_week.round(2)","b5ff74b6":"sns.distplot(ga_week_viz['gmv'],kde=True)","414183ed":"plt.figure(figsize=(15, 5))\nsns.barplot(ga_week_viz['week'],ga_week_viz['gmv'])","62ac2bed":"ga_week_viz.columns","0c2793aa":"fig, axs = plt.subplots(2,4,figsize=(16,8))\n\nplt1 = sns.scatterplot(x = 'Total_Investment', y = 'gmv', data = ga_week_viz, ax = axs[0,0])\n\nplt2 = sns.scatterplot(x = 'TV', y = 'gmv', data = ga_week_viz, ax = axs[0,1])\n\nplt3 = sns.scatterplot(x = 'Digital', y = 'gmv', data = ga_week_viz, ax = axs[0,2])\n\nplt4 = sns.scatterplot(x = 'Sponsorship', y = 'gmv', data = ga_week_viz, ax = axs[0,3])\n\nplt5 = sns.scatterplot(x = 'Content_marketing', y = 'gmv', data = ga_week_viz, ax = axs[1,0])\n\nplt6 = sns.scatterplot(x = 'Online_marketing', y = 'gmv', data = ga_week_viz, ax = axs[1,1])\n\nplt7 = sns.scatterplot(x = 'Affiliates', y = 'gmv', data = ga_week_viz, ax = axs[1,2])\n\nplt8 = sns.scatterplot(x = 'SEM', y = 'gmv', data = ga_week_viz, ax = axs[1,3])\n\nplt.tight_layout()","ec9d5e4c":"plt.figure(figsize=(20, 5))\nsns.barplot(x= ga_week_viz['week'], y =ga_week_viz['gmv'], hue = ga_week_viz['Special_sales'], dodge = False)\nplt.show()","52686688":"plt.figure(figsize=(20, 5))\nsns.barplot(x= ga_week_viz['week'], y =ga_week_viz['gmv'], hue = pd.cut(ga_week_viz['discount'],3), dodge = False)\nplt.show()","4048897f":"### ga_week\n\n### Moving Average for listed_price and discount_offer\n\n### ga_week = ga_week.sort_values('order_date')\n\nga_week[['MA2_LP','MA2_Discount']] = ga_week[['listing_price','discount']].rolling(window=2,min_periods=1).mean()\nga_week[['MA3_LP','MA3_Discount']] = ga_week[['listing_price','discount']].rolling(window=3,min_periods=1).mean()\nga_week[['MA4_LP','MA4_Discount']] = ga_week[['listing_price','discount']].rolling(window=4,min_periods=1).mean()\n\n### Reference listed price Inflation \n\nga_week['MA2_listed_price'] = (ga_week['listing_price']-ga_week['MA2_LP'])\/ga_week['MA2_LP']\nga_week['MA3_listed_price'] = (ga_week['listing_price']-ga_week['MA3_LP'])\/ga_week['MA3_LP']\nga_week['MA4_listed_price'] = (ga_week['listing_price']-ga_week['MA4_LP'])\/ga_week['MA4_LP']\n\n### Reference discount Inflation\n\nga_week['MA2_discount'] = (ga_week['discount']-ga_week['MA2_Discount'])\/ga_week['MA2_Discount']\nga_week['MA3_discount'] = (ga_week['discount']-ga_week['MA3_Discount'])\/ga_week['MA3_Discount']\nga_week['MA4_discount'] = (ga_week['discount']-ga_week['MA4_Discount'])\/ga_week['MA4_Discount']\n\n\nga_week.drop(['MA2_LP','MA3_LP','MA4_LP','MA2_Discount','MA3_Discount','MA4_Discount'], axis = 1, inplace = True)  \nga_week\n\n","1e1736cf":"plt.figure(figsize=(25,20))\n\n### Heatmap\nsns.heatmap(ga_week.corr(), cmap=\"coolwarm\", annot=True)\nplt.show()","932e6753":"\nga_week.drop(['TV', 'Digital', 'Sponsorship', 'Content_marketing','Online_marketing', 'Affiliates', 'SEM','Radio',\n              'Other','Affiliates_ads','SEM_ads','Digital_ads','Radio_ads','Other_ads','mean_temp_C','min_temp_C',\n              'order_id','order_item_id','total_precip_mm','Total_Investment','MA3_discount',\n              'MA3_listed_price','AOV','MA4_listed_price'], axis = 1, inplace = True)","fb353324":"ga_week.drop(['max_temp_C'], axis = 1, inplace = True)","dd9ea00d":"###  Successfully removed more than 90% highly correlated variables from dataset.\n","fb0624c2":"### Lag of listed_price, discount_offer, NPS, Special_sales\n\nga_week['lag_1_listed_price'] = ga_week['listing_price'].shift(-1).fillna(0)\nga_week['lag_2_listed_price'] = ga_week['listing_price'].shift(-2).fillna(0)\nga_week['lag_3_listed_price'] = ga_week['listing_price'].shift(-3).fillna(0)\n\nga_week['lag_1_discount_offer'] = ga_week['discount'].shift(-1).fillna(0)\nga_week['lag_2_discount_offer'] = ga_week['discount'].shift(-2).fillna(0)\nga_week['lag_3_discount_offer'] = ga_week['discount'].shift(-3).fillna(0)\n\nga_week['lag_1_NPS'] = ga_week['NPS'].shift(-1).fillna(0)\nga_week['lag_2_NPS'] = ga_week['NPS'].shift(-2).fillna(0)\nga_week['lag_3_NPS'] = ga_week['NPS'].shift(-3).fillna(0)\n\nga_week['lag_1_Stock_Index'] = ga_week['Stock_Index'].shift(-1).fillna(0)\nga_week['lag_2_Stock_Index'] = ga_week['Stock_Index'].shift(-2).fillna(0)\nga_week['lag_3_Stock_Index'] = ga_week['Stock_Index'].shift(-3).fillna(0)\n\nga_week['lag_1_Special_sales'] = ga_week['Special_sales'].shift(-1).fillna(0)\nga_week['lag_2_Special_sales'] = ga_week['Special_sales'].shift(-2).fillna(0)\nga_week['lag_3_Special_sales'] = ga_week['Special_sales'].shift(-3).fillna(0)\n\nga_week['lag_1_Payday'] = ga_week['Payday'].shift(-1).fillna(0)\nga_week['lag_2_Payday'] = ga_week['Payday'].shift(-2).fillna(0)\nga_week['lag_3_Payday'] = ga_week['Payday'].shift(-3).fillna(0)\n","2248acb5":"ga_week.head()","6649b3d1":"home_audio = consumer[consumer['product_analytic_sub_category'] == 'HomeAudio']","41857acd":"###  Removing outliers is important as\n###  1. There may be some garbage value.\n###  2. Bulk orders can skew the analysis","9e2191d0":"### Outlier Analysis\nfig, axs = plt.subplots(1,3, figsize = (20,4))\nplt1 = sns.boxplot(home_audio['gmv'], ax = axs[0])\nplt2 = sns.boxplot(home_audio['units'], ax = axs[2])\nplt4 = sns.boxplot(home_audio['product_mrp'], ax = axs[1])\nplt.tight_layout()","40130c93":"### Treating outliers\n### Outlier treatment for gmv & product_mrp\nQ1 = home_audio.gmv.quantile(0.25)\nQ3 = home_audio.gmv.quantile(0.75)\nIQR = Q3 - Q1\nhome_audio = home_audio[(home_audio.gmv >= Q1 - 1.5*IQR) & (home_audio.gmv <= Q3 + 1.5*IQR)]\nQ1 = home_audio.product_mrp.quantile(0.25)\nQ3 = home_audio.product_mrp.quantile(0.75)\nIQR = Q3 - Q1\nhome_audio = home_audio[(home_audio.product_mrp >= Q1 - 1.5*IQR) & (home_audio.product_mrp <= Q3 + 1.5*IQR)]","f45666ca":"### Outlier Analysis\nfig, axs = plt.subplots(1,3, figsize = (20,4))\nplt1 = sns.boxplot(home_audio['gmv'], ax = axs[0])\nplt2 = sns.boxplot(home_audio['units'], ax = axs[2])\nplt4 = sns.boxplot(home_audio['product_mrp'], ax = axs[1])\nplt.tight_layout()","c3b91c63":"home_audio.columns","92f95dfc":"### Aggregating dataset on weekly level\n\nha_week = pd.DataFrame(home_audio.groupby('week').agg({'gmv':'sum','listing_price':'mean',\n                                                             'product_mrp':'mean','discount':'mean',\n                                                             'sla':'mean','product_procurement_sla':'mean',\n                                                             'fsn_id':pd.Series.nunique,'order_item_id':pd.Series.nunique,\n                                                             'order_id': pd.Series.nunique,\n                                                             'order_payment_type':'sum'}))\n\nha_week.reset_index( inplace = True)","0092f070":"ha_week.head()","58dc2163":"### Sum of GMV \/ No of unique Orders\n\nha_week['AOV'] = ha_week['gmv']\/ha_week['order_id']","5302b12a":"ha_week['online_order_perc'] = ha_week['order_payment_type']*100\/ha_week['order_item_id']","52526107":"ha_week.head()","d4e06da3":"ha_week = ha_week.merge(marketing, how = 'left', on = 'week')","8ab914a8":"ha_week = ha_week.merge(calendar, how = 'left', on = 'week')","9d4245a4":"ha_week.head()","a420844a":"ha_week_viz = ha_week.round(2)","061b37b1":"sns.distplot(ha_week_viz['gmv'],kde=True)","e878c6c7":"plt.figure(figsize=(15, 5))\nsns.barplot(ha_week_viz['week'],ha_week_viz['gmv'])","42d5b119":"ha_week_viz.columns","a15a14bc":"fig, axs = plt.subplots(2,4,figsize=(16,8))\n\nplt1 = sns.scatterplot(x = 'Total_Investment', y = 'gmv', data = ha_week_viz, ax = axs[0,0])\n\nplt2 = sns.scatterplot(x = 'TV', y = 'gmv', data = ha_week_viz, ax = axs[0,1])\n\nplt3 = sns.scatterplot(x = 'Digital', y = 'gmv', data = ha_week_viz, ax = axs[0,2])\n\nplt4 = sns.scatterplot(x = 'Sponsorship', y = 'gmv', data = ha_week_viz, ax = axs[0,3])\n\nplt5 = sns.scatterplot(x = 'Content_marketing', y = 'gmv', data = ha_week_viz, ax = axs[1,0])\n\nplt6 = sns.scatterplot(x = 'Online_marketing', y = 'gmv', data = ha_week_viz, ax = axs[1,1])\n\nplt7 = sns.scatterplot(x = 'Affiliates', y = 'gmv', data = ha_week_viz, ax = axs[1,2])\n\nplt8 = sns.scatterplot(x = 'SEM', y = 'gmv', data = ha_week_viz, ax = axs[1,3])\n\nplt.tight_layout()","d32e86f6":"plt.figure(figsize=(20, 5))\nsns.barplot(x= ha_week_viz['week'], y =ha_week_viz['gmv'], hue = ha_week_viz['Special_sales'], dodge = False)\nplt.show()","cf4540bd":"plt.figure(figsize=(20, 5))\nsns.barplot(x= ha_week_viz['week'], y =ha_week_viz['gmv'], hue = pd.cut(ha_week_viz['discount'],3), dodge = False)\nplt.show()","fdda6bce":"### ha_week\n\n### Moving Average for listed_price and discount_offer\n\n### ha_week = ha_week.sort_values('order_date')\n\nha_week[['MA2_LP','MA2_Discount']] = ha_week[['listing_price','discount']].rolling(window=2,min_periods=1).mean()\nha_week[['MA3_LP','MA3_Discount']] = ha_week[['listing_price','discount']].rolling(window=3,min_periods=1).mean()\nha_week[['MA4_LP','MA4_Discount']] = ha_week[['listing_price','discount']].rolling(window=4,min_periods=1).mean()\n\n### Reference listed price Inflation \n\nha_week['MA2_listed_price'] = (ha_week['listing_price']-ha_week['MA2_LP'])\/ha_week['MA2_LP']\nha_week['MA3_listed_price'] = (ha_week['listing_price']-ha_week['MA3_LP'])\/ha_week['MA3_LP']\nha_week['MA4_listed_price'] = (ha_week['listing_price']-ha_week['MA4_LP'])\/ha_week['MA4_LP']\n\n### Reference discount Inflation\n\nha_week['MA2_discount'] = (ha_week['discount']-ha_week['MA2_Discount'])\/ha_week['MA2_Discount']\nha_week['MA3_discount'] = (ha_week['discount']-ha_week['MA3_Discount'])\/ha_week['MA3_Discount']\nha_week['MA4_discount'] = (ha_week['discount']-ha_week['MA4_Discount'])\/ha_week['MA4_Discount']\n\n\nha_week.drop(['MA2_LP','MA3_LP','MA4_LP','MA2_Discount','MA3_Discount','MA4_Discount'], axis = 1, inplace = True)  \nha_week\n\n","cd4e12c5":"plt.figure(figsize=(25,20))\n\n### Heatmap\nsns.heatmap(ha_week.corr(), cmap=\"coolwarm\", annot=True)\nplt.show()","935aabb3":"ha_week.drop(['TV', 'Digital', 'Sponsorship', 'Content_marketing','Online_marketing', 'Affiliates', 'SEM','Radio',\n              'Other','Affiliates_ads','SEM_ads','Digital_ads','Radio_ads','Other_ads','mean_temp_C','min_temp_C',\n              'order_id','order_item_id','total_precip_mm','Total_Investment','MA3_discount',\n              'MA3_listed_price','AOV'], axis = 1, inplace = True)","6496b82d":"ha_week.drop(['max_temp_C'], axis = 1, inplace = True)","6acfc887":"###  Successfully removed more than 90% highly correlated variables from dataset.","846229f7":"### Lag of listed_price, discount_offer, NPS, Special_sales\n\nha_week['lag_1_listed_price'] = ha_week['listing_price'].shift(-1).fillna(0)\nha_week['lag_2_listed_price'] = ha_week['listing_price'].shift(-2).fillna(0)\nha_week['lag_3_listed_price'] = ha_week['listing_price'].shift(-3).fillna(0)\n\nha_week['lag_1_discount_offer'] = ha_week['discount'].shift(-1).fillna(0)\nha_week['lag_2_discount_offer'] = ha_week['discount'].shift(-2).fillna(0)\nha_week['lag_3_discount_offer'] = ha_week['discount'].shift(-3).fillna(0)\n\nha_week['lag_1_NPS'] = ha_week['NPS'].shift(-1).fillna(0)\nha_week['lag_2_NPS'] = ha_week['NPS'].shift(-2).fillna(0)\nha_week['lag_3_NPS'] = ha_week['NPS'].shift(-3).fillna(0)\n\nha_week['lag_1_Stock_Index'] = ha_week['Stock_Index'].shift(-1).fillna(0)\nha_week['lag_2_Stock_Index'] = ha_week['Stock_Index'].shift(-2).fillna(0)\nha_week['lag_3_Stock_Index'] = ha_week['Stock_Index'].shift(-3).fillna(0)\n\nha_week['lag_1_Special_sales'] = ha_week['Special_sales'].shift(-1).fillna(0)\nha_week['lag_2_Special_sales'] = ha_week['Special_sales'].shift(-2).fillna(0)\nha_week['lag_3_Special_sales'] = ha_week['Special_sales'].shift(-3).fillna(0)\n\nha_week['lag_1_Payday'] = ha_week['Payday'].shift(-1).fillna(0)\nha_week['lag_2_Payday'] = ha_week['Payday'].shift(-2).fillna(0)\nha_week['lag_3_Payday'] = ha_week['Payday'].shift(-3).fillna(0)\n","5aa0f99e":"ha_week.head(10)","c2e900a5":"###  Importing RFE and LinearRegression\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression","d7e794fa":"ca_week.columns","1aa92d40":"camera_lm = ca_week[['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA4_listed_price',\n       'MA2_discount_offer','premium_product']]\n                            \n    \ncamera_lm.head()","a87dedf7":"### Checking NaN\n\ncamera_lm.isnull().sum()","89226cc0":"camera_lm.fillna(0, inplace = True)","84da1322":"from sklearn.model_selection import train_test_split\n\n\nnp.random.seed(0)\ndf_train, df_test = train_test_split(camera_lm, train_size = 0.7, test_size = 0.3, random_state = 100)","51e713d7":"### Import the StandardScaler()\n# from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n### Create a scaling object\n# scaler = StandardScaler()\nscaler = MinMaxScaler()\n\n\n### Create a list of the variables that you need to scale\nvarlist = ['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA4_listed_price',\n       'MA2_discount_offer','premium_product']\n                                      \n\n### Scale these variables using 'fit_transform'\ndf_train[varlist] = scaler.fit_transform(df_train[varlist])","3ce8a2cf":"df_train.head()","b3c1cc4c":"### Split the train dataset into X and y\nfrom sklearn.model_selection import train_test_split\nX_train = df_train.drop('gmv',axis=1)\ny_train = df_train['gmv']\n","c3e37b34":"#RFE\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","74edc3ff":"lm = LinearRegression()\nlm.fit(X_train,y_train)\nrfe = RFE(lm, 10)\nrfe = rfe.fit(X_train, y_train)","070ee0dd":"list(zip(X_train.columns,rfe.support_,rfe.ranking_))","0b889cda":"X_train.columns[rfe.support_]","125f8111":"X_train_rfe = X_train[X_train.columns[rfe.support_]]\nX_train_rfe.head()","565c2872":"def build_model(X,y):\n    X = sm.add_constant(X) #Adding the constant\n    lm = sm.OLS(y,X).fit() # fitting the model\n    print(lm.summary()) # model summary\n    return X\n    \ndef checkVIF(X):\n    vif = pd.DataFrame()\n    vif['Features'] = X.columns\n    vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n    vif['VIF'] = round(vif['VIF'], 2)\n    vif = vif.sort_values(by = \"VIF\", ascending = False)\n    return(vif)","42dd735e":"X_train_new = build_model(X_train_rfe,y_train)","ed635407":"checkVIF(X_train_new)","13ce66dc":"X_train_new = X_train_rfe.drop([\"discount\"], axis = 1)","a0544e5f":"X_train_new = build_model(X_train_new,y_train)","24e946b0":"checkVIF(X_train_new)","dfc9a0f8":"X_train_new = X_train_new.drop([\"heat_deg_days\"], axis = 1)","48f767b8":"X_train_new = build_model(X_train_new,y_train)","b79dbe83":"X_train_new = X_train_new.drop([\"snow_on_grnd_cm\"], axis = 1)","cc07ea45":"X_train_new = build_model(X_train_new,y_train)","9f2a9938":"checkVIF(X_train_new)","ee5262d0":"X_train_new = X_train_new.drop([\"sla\"], axis = 1)","bf5a62d9":"X_train_new = build_model(X_train_new,y_train)","f49724a0":"checkVIF(X_train_new)","dbb355a7":"X_train_new = X_train_new.drop([\"MA2_discount_offer\"], axis = 1)","48f09864":"X_train_new = build_model(X_train_new,y_train)","cdfbb4d8":"checkVIF(X_train_new)","f252a3bc":"X_train_new = X_train_new.drop([\"product_procurement_sla\"], axis = 1)","34e4c676":"X_train_new = build_model(X_train_new,y_train)","dd2cc08d":"checkVIF(X_train_new)","0c10b8ca":"X_train_new = X_train_new.drop([\"MA4_listed_price\"], axis = 1)","8900b0a1":"X_train_new = build_model(X_train_new,y_train)","762624cc":"checkVIF(X_train_new)","c8cd7c39":"lm = sm.OLS(y_train,X_train_new).fit()\ny_train_price = lm.predict(X_train_new)","22c1557d":"# Plot the histogram of the error terms\nfig = plt.figure()\nsns.distplot((y_train - y_train_price), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20)                  # Plot heading \nplt.xlabel('Errors', fontsize = 18)   ","0e5bd1d7":"#Scaling the test set\nnum_vars = ['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA4_listed_price',\n       'MA2_discount_offer','premium_product']\ndf_test[num_vars] = scaler.fit_transform(df_test[num_vars])\n","f6a8d15c":"#Dividing into X and y\ny_test = df_test.pop('gmv')\nX_test = df_test","17c1e166":"# Now let's use our model to make predictions.\nX_train_new = X_train_new.drop('const',axis=1)\n# Creating X_test_new dataframe by dropping variables from X_test\nX_test_new = X_test[X_train_new.columns]\n\n# Adding a constant variable \nX_test_new = sm.add_constant(X_test_new)","2e706d75":"# Making predictions\ny_pred = lm.predict(X_test_new)","6db8abb0":"from sklearn.metrics import r2_score \nr2_score(y_test, y_pred)","b5067570":"#EVALUATION OF THE MODEL\n# Plotting y_test and y_pred to understand the spread.\nfig = plt.figure()\nplt.scatter(y_test,y_pred)\nfig.suptitle('y_test vs y_pred', fontsize=20)              # Plot heading \nplt.xlabel('y_test', fontsize=18)                          # X-label\nplt.ylabel('y_pred', fontsize=16)   ","7c13cd14":"print(lm.summary())","5e593577":"###  Importing RFE and LinearRegression\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression","5542d245":"ca_week.columns","25bea395":"camera_lm = ca_week[['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA4_listed_price',\n       'MA2_discount_offer']]\n                            \n    \ncamera_lm.head()","53515dfe":"### Checking NaN\ncamera_lm.isnull().sum()","59830240":"camera_lm.fillna(0, inplace = True)","5608e2ef":"### Import the StandardScaler()\n# from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n### Create a scaling object\n# scaler = StandardScaler()\nscaler = MinMaxScaler()\n\n\n### Create a list of the variables that you need to scale\nvarlist = ['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA4_listed_price',\n       'MA2_discount_offer']\n                                      \n\n### Scale these variables using 'fit_transform'\ncamera_lm[varlist] = scaler.fit_transform(camera_lm[varlist])","dea10fb7":"camera_lm.head()","1c92057a":"### Split the train dataset into X and y\nfrom sklearn.model_selection import train_test_split\nx = camera_lm.drop('gmv',axis=1)\ny = camera_lm['gmv']\n\ncamera_train_lm = camera_lm","b23c1f42":"print(\"x dataset: \",x.shape)\nprint(\"y dataset: \",y.shape)","cb840383":"###  Instantiate\nlm = LinearRegression()\n\n###  Fit a line\nlm.fit(x,y)\n","45d10b22":"###  Coefficient values\n\ncoef = pd.DataFrame(x.columns)\ncoef['Coefficient'] = pd.Series(lm.coef_)\ncoef\n","fbaadb41":"col = x.columns\ncol","3777a6e5":"import statsmodels.api as sm  \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score","2f52cc36":"def stepwise_selection(x, y,\n                       initial_list=[ 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA4_listed_price',\n       'MA2_discount_offer'],\n                       threshold_in=0.01,threshold_out = 0.05, verbose=True):\n    \n    included = list(initial_list)\n    while True:\n        changed=False\n        ###forward step\n        excluded = list(set(x.columns)-set(included))\n        new_pval = pd.Series(index=excluded)\n        for new_column in excluded:\n            model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included+[new_column]]))).fit()\n            new_pval[new_column] = model.pvalues[new_column]\n        best_pval = new_pval.min()\n        if best_pval < threshold_in:\n            best_feature = new_pval.argmin()\n            included.append(best_feature)\n            changed=True\n            if verbose:\n                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n                \n                \n        ###backward step\n        model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included]))).fit()\n        ###use all coefs except intercept\n        pvalues = model.pvalues.iloc[1:]\n        worst_pval = pvalues.max() ###null if pvalues is empty\n        if worst_pval > threshold_out:\n            changed=True\n            worst_feature = pvalues.argmax()\n            included.remove(worst_feature)\n            if verbose:\n                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n        if not changed:\n            break\n    return included\n","63f83476":"import statsmodels.api as sm  \n\nfinal_features = stepwise_selection(x, y)\n\nprint(\"\\n\",\"final_selected_features:\",final_features)","e783bf24":"###  Import statsmodels\nimport statsmodels.api as sm  \n\n###  Subsetting training data for 15 selected columns\nx_rfe1 = x[final_features]\n\nx_rfe1 = sm.add_constant(x_rfe1)\n\n###  Fitting the model with selected variables\nlm1 = sm.OLS(y, x_rfe1).fit() \n\nprint(lm1.params)","b34f6d6e":"print(lm1.summary())","ae18d837":"###  Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","68142b00":"features = list(x_rfe1.columns)\nfeatures.remove('const')\nfeatures","f791945e":"###  Model Evaluation on testing data\nx_2 = x[features]\n\n\n###  Predicition with selected features on the test data\ny_pred = lm1.predict(sm.add_constant(x_2))\n","41e2448c":"###  Mean square error (MSE)\n\nmse = np.mean((y_pred - y)**2)\nmse","c4a54e33":"###  Coefficient values\n\ncoef = pd.DataFrame(x_rfe1.columns)\ncoef['Coefficient'] = pd.Series(lm.coef_)\ncoef\n","f8bf66f8":"### Mean Square Error \n###  Using K-Fold Cross validation evaluating on selected dataset\n\n# lm = LinearRegression()\nfold = KFold(10,shuffle = True, random_state = 100)\n\ncv_scores = -cross_val_score(lm,x[features],y,cv=fold,scoring='neg_mean_squared_error')\n\nprint(\"Neg. of MSE:\",cv_scores,\"\\n\")\nprint(\"Mean of 5 KFold CV - MSE:\",cv_scores.mean())","81d9f025":"def elasticity(model,x):\n    \n    features_df = pd.DataFrame(model.params)\n    features_df = features_df.rename(columns={0:'coef'})\n    \n    features_df['imp_feature'] = model.params.index\n    features_df = features_df[features_df.imp_feature != 'const'][['imp_feature','coef']]\n    features_df.index = range(len(features_df))\n#    features\n\n    elasticity_list = list()\n    \n    for i in range(len(features_df)):\n        elasticity_list.append(((features_df.coef[i] * np.mean(x[features_df.imp_feature[i]])) \/ np.mean(x['gmv'])))\n\n    features_df['elasticity'] = np.round(elasticity_list,3)\n    \n    sns.barplot(x='elasticity',y='imp_feature',data=features_df)\n    plt.show()\n    \n    return features_df\n    ","3862e17d":"elasticity(lm1,camera_train_lm)","06ded229":"# Plotting y and y_pred to understand the spread\n\nfig = plt.figure()\nplt.scatter(y, y_pred)\nfig.suptitle('y vs y_pred', fontsize = 20)              # Plot heading \nplt.xlabel('y', fontsize = 18)                          # X-label\nplt.ylabel('y_pred', fontsize = 16)  ","08233102":"# Figure size\nplt.figure(figsize=(8,5))\n\n# Heatmap\nsns.heatmap(camera_train_lm[features].corr(), cmap=\"YlGnBu\", annot=True)\nplt.show()","8405406e":"ca_week.columns","654f67a9":"camera_mm = ca_week[['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA4_listed_price',\n       'MA2_discount_offer']]         \n\ncamera_mm.head()\n","174ed99b":"### Applying Log \ncamera_mm=np.log(camera_mm)\n\ncamera_mm = camera_mm.fillna(0)\ncamera_mm = camera_mm.replace([np.inf, -np.inf], 0)","16c8a6c7":"camera_mm.head()","5357effb":"###  Import the StandardScaler()\n# from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n###  Create a scaling object\n# scaler = StandardScaler()\nscaler = MinMaxScaler()\n\n###  Create a list of the variables that you need to scale\nvarlist = ['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA4_listed_price',\n       'MA2_discount_offer']      \n\n\n\n### Scale these variables using 'fit_transform'\ncamera_mm[varlist] = scaler.fit_transform(camera_mm[varlist])","579db9fa":"camera_mm.head()","2b510768":"### Split the train dataset into X and y\nfrom sklearn.model_selection import train_test_split\n\nx = camera_mm.drop('gmv',axis=1)\ny = camera_mm['gmv']\n\ncamera_train_mm = camera_mm","39339074":"print(\"X = Independent variable & Y = Target variable\")\nprint(x.shape,y.shape)\n","70507a13":"### Instantiate\nmm = LinearRegression()\n\n### Fit a line\nmm.fit(x,y)\n","f63186df":"### Coefficient values\n\ncoef = pd.DataFrame(x.columns)\ncoef['Coefficient'] = pd.Series(mm.coef_)\ncoef\n","7047d3bb":"col = x.columns\ncol","3bb0cba1":"import statsmodels.api as sm  \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score","a060e0a4":"def stepwise_selection(x, y,\n                       initial_list=['discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA4_listed_price',\n       'MA2_discount_offer'],\n                       threshold_in=0.01,threshold_out = 0.05, verbose=True):\n    \n    included = list(initial_list)\n    while True:\n        changed=False\n        ###forward step\n        excluded = list(set(x.columns)-set(included))\n        new_pval = pd.Series(index=excluded)\n        for new_column in excluded:\n            model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included+[new_column]]))).fit()\n            new_pval[new_column] = model.pvalues[new_column]\n        best_pval = new_pval.min()\n        if best_pval < threshold_in:\n            best_feature = new_pval.argmin()\n            included.append(best_feature)\n            changed=True\n            if verbose:\n                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n                \n                \n        ###backward step\n        model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included]))).fit()\n        ###use all coefs except intercept\n        pvalues = model.pvalues.iloc[1:]\n        worst_pval = pvalues.max() ###null if pvalues is empty\n        if worst_pval > threshold_out:\n            changed=True\n            worst_feature = pvalues.argmax()\n            included.remove(worst_feature)\n            if verbose:\n                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n        if not changed:\n            break\n    return included\n","ecab13c7":"import statsmodels.api as sm  \n\nfinal_features = stepwise_selection(x, y)\n\nprint(\"\\n\",\"final_selected_features:\",final_features)","986aaf74":"### Import statsmodels\nimport statsmodels.api as sm  \n\n### Subsetting training data for 15 selected columns\nx_rfe1 = x[final_features]\n\nx_rfe1 = sm.add_constant(x_rfe1)\n\n\n### Fitting the model with selected variables\nmm1 = sm.OLS(y, x_rfe1).fit() \n\nprint(mm1.params)","793538de":"print(mm1.summary())","e6268b28":"x_rfe1.drop('TV_ads',1,inplace=True)\n\nx_rfe1 = sm.add_constant(x_rfe1)\n\n\n### Fitting the model with selected variables\nmm1 = sm.OLS(y, x_rfe1).fit() \n\nprint(mm1.params)","b1a2eb9e":"print(mm1.summary())","9a3eedec":"### Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","9fa9c229":"features = list(x_rfe1.columns)\nfeatures.remove('const')\nfeatures","b3412ec5":"### Model Evaluation on testing data\nx_2 = x[features]\n\n\n### Predicition with selected features on the test data\ny_pred = mm1.predict(sm.add_constant(x_2))\n","6da01afd":"### Mean square error (MSE)\nmse = np.mean((y_pred - y)**2)\nmse","4add277c":"### Coefficient values\n\ncoef = pd.DataFrame(x_rfe1.columns)\ncoef['Coefficient'] = pd.Series(mm.coef_)\ncoef\n","bd5a2c69":"### Mean Square Error \n###  Using K-Fold Cross validation evaluating on selected dataset\n\n# lm = LinearRegression()\nfold = KFold(10,shuffle = True, random_state = 100)\n\ncv_scores = -cross_val_score(mm,x[features],y,cv=fold,scoring='neg_mean_squared_error')\n\nprint(\"Neg. of MSE:\",cv_scores,\"\\n\")\nprint(\"Mean of 5 KFold CV - MSE:\",cv_scores.mean())","d3305617":"def elasticity(model,x):\n    \n    features_df = pd.DataFrame(model.params)\n    features_df = features_df.rename(columns={0:'coef'})\n    \n    features_df['imp_feature'] = model.params.index\n    features_df = features_df[features_df.imp_feature != 'const'][['imp_feature','coef']]\n    features_df.index = range(len(features_df))\n#     features\n\n    elasticity_list = list()\n    \n    for i in range(len(features_df)):\n        elasticity_list.append(((features_df.coef[i] * np.mean(x[features_df.imp_feature[i]])) \/ np.mean(x['gmv'])))\n\n    features_df['elasticity'] = np.round(elasticity_list,3)\n    \n    sns.barplot(x='elasticity',y='imp_feature',data=features_df)\n    plt.show()\n    \n    return features_df\n    ","354ed681":"elasticity(mm1,camera_train_mm)","421d9be4":"# Plotting y and y_pred to understand the spread\n\nfig = plt.figure()\nplt.scatter(y, y_pred)\nfig.suptitle('y vs y_pred', fontsize = 20)              # Plot heading \nplt.xlabel('y', fontsize = 18)                          # X-label\nplt.ylabel('y_pred', fontsize = 16)  ","51fd9a69":"ca_week.columns","e35727bc":"camera_km = ca_week[['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA4_listed_price',\n       'MA2_discount_offer']]           \n\n\ncamera_km.head()\n","149aecd6":"camera_km['lag_1_gmv'] = camera_km['gmv'].shift(-1)","fd266710":"### Checking NaN\n\ncamera_km.isnull().sum()","2ee9030b":"camera_km = camera_km.fillna(0)","1b3ef81e":"camera_km.head()","6db1b324":"###  Import the StandardScaler()\n# from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n### Create a scaling object\n# scaler = StandardScaler()\nscaler = MinMaxScaler()\n\n### Create a list of the variables that you need to scale\nvarlist = ['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA4_listed_price',\n       'MA2_discount_offer','lag_1_gmv']\n\n### Scale these variables using 'fit_transform'\ncamera_km[varlist] = scaler.fit_transform(camera_km[varlist])","bd6f2a96":"camera_km.head()","5e421e34":"### Split the train dataset into X and y\nfrom sklearn.model_selection import train_test_split\nx = camera_km.drop('gmv',axis=1)\ny = camera_km['gmv']\n\ncamera_train_km = camera_km","3cbd6b9f":"print(\"X = Independent variable & Y = Target variable\")\nprint(x.shape,y.shape)","69aab91a":"###  Instantiate\nkm = LinearRegression()\n\n###  Fit a line\nkm.fit(x,y)\n","8aba210d":"###  Coefficient values\n\ncoef = pd.DataFrame(x.columns)\ncoef['Coefficient'] = pd.Series(km.coef_)\ncoef\n","eb601bc2":"col = x.columns\ncol","03fbcee9":"import statsmodels.api as sm  \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score","211f487e":"def stepwise_selection(x, y,\n                       initial_list=['discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA4_listed_price',\n       'MA2_discount_offer', 'lag_1_gmv'],\n                       threshold_in=0.01,threshold_out = 0.05, verbose=True):\n    \n    included = list(initial_list)\n    while True:\n        changed=False\n        ### forward step\n        excluded = list(set(x.columns)-set(included))\n        new_pval = pd.Series(index=excluded)\n        for new_column in excluded:\n            model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included+[new_column]]))).fit()\n            new_pval[new_column] = model.pvalues[new_column]\n        best_pval = new_pval.min()\n        if best_pval < threshold_in:\n            best_feature = new_pval.argmin()\n            included.append(best_feature)\n            changed=True\n            if verbose:\n                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n                \n                \n        ###backward step\n        model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included]))).fit()\n        ###use all coefs except intercept\n        pvalues = model.pvalues.iloc[1:]\n        worst_pval = pvalues.max() ###null if pvalues is empty\n        if worst_pval > threshold_out:\n            changed=True\n            worst_feature = pvalues.argmax()\n            included.remove(worst_feature)\n            if verbose:\n                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n        if not changed:\n            break\n    return included\n","7d1aadbc":"import statsmodels.api as sm  \n\nfinal_features = stepwise_selection(x, y)\n\nprint(\"\\n\",\"final_selected_features:\",final_features)","d4dfbea9":"### Import statsmodels\nimport statsmodels.api as sm  \n\n### Subsetting training data for 15 selected columns\nx_rfe1 = x[final_features]\n\nx_rfe1 = sm.add_constant(x_rfe1)\n\n### Fitting the model with selected variables\nkm1 = sm.OLS(y, x_rfe1).fit() \n\nprint(km1.params)","81086434":"print(km1.summary())","b511c2cd":"### Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","4064a724":"features = list(x_rfe1.columns)\nfeatures.remove('const')\nfeatures","5b796111":"### Model Evaluation on testing data\nx_2 = x[features]\n\n\n### Predicition with selected features on the test data\ny_pred = km1.predict(sm.add_constant(x_2))\n","dd3bd12e":"### Mean square error (MSE)\nmse = np.mean((y_pred - y)**2)\nmse","6fafe1ad":"### Coefficient values\n\ncoef = pd.DataFrame(x_rfe1.columns)\ncoef['Coefficient'] = pd.Series(km.coef_)\ncoef\n","4248083e":"### Using K-Fold Cross validation evaluating on whole dataset\n\n# lm = LinearRegression()\nfold = KFold(10,shuffle = True, random_state = 100)\n\ncv_scores = -cross_val_score(km,x[features],y,cv=fold,scoring='neg_mean_squared_error')\n\nprint(\"Neg. of MSE:\",cv_scores,\"\\n\")\nprint(\"Mean of 5 KFold CV - MSE:\",cv_scores.mean())","8d18c1e2":"def elasticity(model,x):\n    \n    features_df = pd.DataFrame(model.params)\n    features_df = features_df.rename(columns={0:'coef'})\n    \n    features_df['imp_feature'] = model.params.index\n    features_df = features_df[features_df.imp_feature != 'const'][['imp_feature','coef']]\n    features_df.index = range(len(features_df))\n#      features\n\n    elasticity_list = list()\n    \n    for i in range(len(features_df)):\n        elasticity_list.append(((features_df.coef[i] * np.mean(x[features_df.imp_feature[i]])) \/ np.mean(x['gmv'])))\n\n    features_df['elasticity'] = np.round(elasticity_list,3)\n    \n    sns.barplot(x='elasticity',y='imp_feature',data=features_df)\n    plt.show()\n    \n    return features_df\n    ","680449ec":"elasticity(km1,camera_train_km)","ab4581fa":"# Plotting y and y_pred to understand the spread\n\nfig = plt.figure()\nplt.scatter(y, y_pred)\nfig.suptitle('y vs y_pred', fontsize = 20)              # Plot heading \nplt.xlabel('y', fontsize = 18)                          # X-label\nplt.ylabel('y_pred', fontsize = 16)  ","35fa8ae7":"# Figure size\nplt.figure(figsize=(8,5))\n\n# Heatmap\nsns.heatmap(camera_train_km[features].corr(), cmap=\"YlGnBu\", annot=True)\nplt.show()","bcfbe573":"ca_week.columns","b2fcdc3f":"camera_dlm = ca_week[['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday','heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm',  'MA4_listed_price',\n       'MA2_discount_offer', 'lag_1_listed_price','lag_1_discount',\n       'lag_2_discount','lag_3_discount','lag_2_NPS','lag_3_NPS','lag_1_Stock_Index',\n       'lag_2_Stock_Index','lag_3_Stock_Index','lag_1_Special_sales','lag_2_Special_sales','lag_3_Special_sales',\n       'lag_1_Payday','lag_2_Payday','lag_3_Payday']]           \n\n\ncamera_dlm.head()\n","952fbbf0":"camera_dlm['lag_1_gmv'] = camera_dlm['gmv'].shift(-1)\ncamera_dlm['lag_2_gmv'] = camera_dlm['gmv'].shift(-2)\ncamera_dlm['lag_3_gmv'] = camera_dlm['gmv'].shift(-3)\n","bd6e7c6b":"### Checking NaN\n\ncamera_dlm.isnull().sum()","01a0971d":"camera_dlm = camera_dlm.fillna(0)","941b07ca":"camera_dlm.head()","5558d99a":"camera_dlm.columns","441ab464":"###  Import the StandardScaler()\n# from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n###  Create a scaling object\n# scaler = StandardScaler()\nscaler = MinMaxScaler()\n\n\n###  Create a list of the variables that you need to scale\nvarlist = ['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday','heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm',  'MA4_listed_price',\n       'MA2_discount_offer', 'lag_1_listed_price','lag_1_discount',\n       'lag_2_discount','lag_3_discount','lag_2_NPS','lag_3_NPS','lag_1_Stock_Index',\n       'lag_2_Stock_Index','lag_3_Stock_Index','lag_1_Special_sales','lag_2_Special_sales','lag_3_Special_sales',\n       'lag_1_Payday','lag_2_Payday','lag_3_Payday']\n\n\n###  Scale these variables using 'fit_transform'\ncamera_dlm[varlist] = scaler.fit_transform(camera_dlm[varlist])","fd8a0f1b":"camera_dlm.head()","068c6297":"###  Split the train dataset into X and y\nfrom sklearn.model_selection import train_test_split\nx = camera_dlm.drop('gmv',axis=1)\ny = camera_dlm['gmv']\n\ncamera_train_dlm = camera_dlm","a989c2b0":"print(\"X = Independent variable & Y = Target variable\")\nprint(x.shape,y.shape)","b45dc67c":"###  Instantiate\ndlm = LinearRegression()\n\n###  Fit a line\ndlm.fit(x,y)\n","865336f7":"###  Coefficient values\n\ncoef = pd.DataFrame(x.columns)\ncoef['Coefficient'] = pd.Series(dlm.coef_)\ncoef\n","97f33ed6":"col = x.columns\ncol","3660b03d":"import statsmodels.api as sm  \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score","b9dc5be4":"def stepwise_selection(x, y,\n                       initial_list=['discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday','heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm',  'MA4_listed_price',\n       'MA2_discount_offer', 'lag_1_listed_price','lag_1_discount',\n       'lag_2_discount','lag_3_discount','lag_2_NPS','lag_3_NPS','lag_1_Stock_Index',\n       'lag_2_Stock_Index','lag_3_Stock_Index','lag_1_Special_sales','lag_2_Special_sales','lag_3_Special_sales',\n       'lag_1_Payday','lag_2_Payday','lag_3_Payday'],\n                     threshold_in=0.01,threshold_out = 0.05, verbose=True):\n    \n    included = list(initial_list)\n    while True:\n        changed=False\n        ###  forward step\n        excluded = list(set(x.columns)-set(included))\n        new_pval = pd.Series(index=excluded)\n        for new_column in excluded:\n            model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included+[new_column]]))).fit()\n            new_pval[new_column] = model.pvalues[new_column]\n        best_pval = new_pval.min()\n        if best_pval < threshold_in:\n            best_feature = new_pval.argmin()\n            included.append(best_feature)\n            changed=True\n            if verbose:\n                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n                \n                \n        ###  backward step\n        model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included]))).fit()\n        ###  use all coefs except intercept\n        pvalues = model.pvalues.iloc[1:]\n        worst_pval = pvalues.max() ###  null if pvalues is empty\n        if worst_pval > threshold_out:\n            changed=True\n            worst_feature = pvalues.argmax()\n            included.remove(worst_feature)\n            if verbose:\n                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n        if not changed:\n            break\n    return included\n","6dad6629":"import statsmodels.api as sm  \n\nfinal_features = stepwise_selection(x, y)\n\nprint(\"\\n\",\"final_selected_features:\",final_features)","7edf960d":"###  Import statsmodels\nimport statsmodels.api as sm  \n\n###  Subsetting training data for 15 selected columns\nx_rfe1 = x[final_features]\n\nx_rfe1 = sm.add_constant(x_rfe1)\n\n###  Fitting the model with selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit() \n\nprint(dlm1.params)","d9e74940":"print(dlm1.summary())","9c7536b3":"###  Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","7675497b":"x_rfe1.drop('discount', axis = 1, inplace = True)","1d57b503":"### 2","5d655ca6":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","621bd6d6":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","293d6a16":"x_rfe1.drop('product_procurement_sla', axis = 1, inplace = True)\n","f0e53ea4":"### 3","e73cdc4b":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","5b9847a6":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","c8890dfc":"x_rfe1.drop('lag_1_listed_price', axis = 1, inplace = True)\n","747d8586":"### 4","63a7225a":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","70cb051d":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","54c5d8a5":"features = list(x_rfe1.columns)\nfeatures.remove('const')\nfeatures","3ae16aff":"###  Model Evaluation on testing data\nx_2 = x[features]\n\n###  Predicition with selected features on the test data\ny_pred = dlm1.predict(sm.add_constant(x_2))","a18315dd":"###  Mean square error (MSE)\nmse = np.mean((y_pred - y)**2)\nmse\n","de1ab0d8":"###  Coefficient values\n\ncoef = pd.DataFrame(x_rfe1.columns)\ncoef['Coefficient'] = pd.Series(dlm.coef_)\ncoef\n","749944ec":"###  Using K-Fold Cross validation evaluating on whole dataset\n\n# lm = LinearRegression()\nfold = KFold(10,shuffle = True, random_state = 100)\n\ncv_scores = -cross_val_score(dlm,x[features],y,cv=fold,scoring='neg_mean_squared_error')\n\nprint(\"Neg. of MSE:\",cv_scores,\"\\n\")\nprint(\"Mean of 5 KFold CV - MSE:\",cv_scores.mean())","3af53f5f":"def elasticity(model,x):\n    \n    features_df = pd.DataFrame(model.params)\n    features_df = features_df.rename(columns={0:'coef'})\n    \n    features_df['imp_feature'] = model.params.index\n    features_df = features_df[features_df.imp_feature != 'const'][['imp_feature','coef']]\n    features_df.index = range(len(features_df))\n#      features\n\n    elasticity_list = list()\n    \n    for i in range(len(features_df)):\n        elasticity_list.append(((features_df.coef[i] * np.mean(x[features_df.imp_feature[i]])) \/ np.mean(x['gmv'])))\n\n    features_df['elasticity'] = np.round(elasticity_list,3)\n    \n    sns.barplot(x='elasticity',y='imp_feature',data=features_df)\n    plt.show()\n    \n    return features_df\n    ","c526f32b":"elasticity(dlm1,camera_train_dlm)","f6ddd320":"# Plotting y and y_pred to understand the spread\n\nfig = plt.figure()\nplt.scatter(y, y_pred)\nfig.suptitle('y vs y_pred', fontsize = 20)              # Plot heading \nplt.xlabel('y', fontsize = 18)                          # X-label\nplt.ylabel('y_pred', fontsize = 16)  ","cc5d6cda":"# Figure size\nplt.figure(figsize=(8,5))\n\n# Heatmap\nsns.heatmap(camera_train_dlm[features].corr(), cmap=\"YlGnBu\", annot=True)\nplt.show()","c4c28c2d":"ca_week.columns","44dbfb63":"camera_dlmm = ca_week[['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday','heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm',  'MA4_listed_price',\n       'MA2_discount_offer', 'lag_1_listed_price','lag_1_discount',\n       'lag_2_discount','lag_3_discount','lag_2_NPS','lag_3_NPS','lag_1_Stock_Index',\n       'lag_2_Stock_Index','lag_3_Stock_Index','lag_1_Special_sales','lag_2_Special_sales','lag_3_Special_sales',\n       'lag_1_Payday','lag_2_Payday','lag_3_Payday']]           \n\n\ncamera_dlmm.head()\n","b0d20d0f":"camera_dlmm['lag_1_gmv'] = camera_dlmm['gmv'].shift(-1)\ncamera_dlmm['lag_2_gmv'] = camera_dlmm['gmv'].shift(-2)\ncamera_dlmm['lag_3_gmv'] = camera_dlmm['gmv'].shift(-3)\n","a2fd96d5":"### Checking NaN\n\ncamera_dlmm.isnull().sum()","5d6afad8":"camera_dlmm = camera_dlmm.fillna(0)","079a3a8e":"### Applying Log \ncamera_dlmm=np.log(camera_dlmm)\n\ncamera_dlmm = camera_dlmm.fillna(0)\ncamera_dlmm = camera_dlmm.replace([np.inf, -np.inf], 0)","31930fdd":"camera_dlmm.head()","5266371e":"camera_dlmm.columns","7985a2f9":"###  Import the StandardScaler()\n# from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n###  Create a scaling object\n# scaler = StandardScaler()\nscaler = MinMaxScaler()\n\n\n###  Create a list of the variables that you need to scale\nvarlist = ['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday','heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm',  'MA4_listed_price',\n       'MA2_discount_offer', 'lag_1_listed_price','lag_1_discount',\n       'lag_2_discount','lag_3_discount','lag_2_NPS','lag_3_NPS','lag_1_Stock_Index',\n       'lag_2_Stock_Index','lag_3_Stock_Index','lag_1_Special_sales','lag_2_Special_sales','lag_3_Special_sales',\n       'lag_1_Payday','lag_2_Payday','lag_3_Payday']\n\n\n###  Scale these variables using 'fit_transform'\ncamera_dlmm[varlist] = scaler.fit_transform(camera_dlmm[varlist])\n","183457d7":"camera_dlmm.head()","fd03e4d5":"###  Split the train dataset into X and y\nfrom sklearn.model_selection import train_test_split\nx = camera_dlmm.drop('gmv',axis=1)\ny = camera_dlmm['gmv']\n\ncamera_train_dlmm = camera_dlmm","5fd77c7c":"print(\"X = Independent variable & Y = Target variable\")\nprint(x.shape,y.shape)","301f37f2":"###  Instantiate\ndlm = LinearRegression()\n\n###  Fit a line\ndlm.fit(x,y)\n","00748873":"###  Coefficient values\n\ncoef = pd.DataFrame(x.columns)\ncoef['Coefficient'] = pd.Series(dlm.coef_)\ncoef\n","a165c6fd":"col = x.columns\ncol","be4dd8eb":"import statsmodels.api as sm  \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score","fabb62d0":"def stepwise_selection(x, y,\n                       initial_list=['discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday','heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm',  'MA4_listed_price',\n       'MA2_discount_offer', 'lag_1_listed_price','lag_1_discount',\n       'lag_2_discount','lag_3_discount','lag_2_NPS','lag_3_NPS','lag_1_Stock_Index',\n       'lag_2_Stock_Index','lag_3_Stock_Index','lag_1_Special_sales','lag_2_Special_sales','lag_3_Special_sales',\n       'lag_1_Payday','lag_2_Payday','lag_3_Payday'],\n                     threshold_in=0.01,threshold_out = 0.05, verbose=True):\n    \n    included = list(initial_list)\n    while True:\n        changed=False\n        ###  forward step\n        excluded = list(set(x.columns)-set(included))\n        new_pval = pd.Series(index=excluded)\n        for new_column in excluded:\n            model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included+[new_column]]))).fit()\n            new_pval[new_column] = model.pvalues[new_column]\n        best_pval = new_pval.min()\n        if best_pval < threshold_in:\n            best_feature = new_pval.argmin()\n            included.append(best_feature)\n            changed=True\n            if verbose:\n                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n                \n                \n        ###  backward step\n        model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included]))).fit()\n        ###  use all coefs except intercept\n        pvalues = model.pvalues.iloc[1:]\n        worst_pval = pvalues.max() ###  null if pvalues is empty\n        if worst_pval > threshold_out:\n            changed=True\n            worst_feature = pvalues.argmax()\n            included.remove(worst_feature)\n            if verbose:\n                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n        if not changed:\n            break\n    return included\n","4727bce4":"import statsmodels.api as sm  \n\nfinal_features = stepwise_selection(x, y)\n\nprint(\"\\n\",\"final_selected_features:\",final_features)","9015ea52":"###  Import statsmodels\nimport statsmodels.api as sm  \n\n###  Subsetting training data for 15 selected columns\nx_rfe1 = x[final_features]\n\nx_rfe1 = sm.add_constant(x_rfe1)\n\n###  Fitting the model with selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit() \n\nprint(dlm1.params)","2257a76a":"print(dlm1.summary())","ef1adaa0":"###  Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","34627a3c":"x_rfe1.drop('lag_1_gmv', axis = 1, inplace = True)","ba19f692":"### 2","3df99657":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","aa3b84e6":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","8b197aea":"x_rfe1.drop('lag_2_discount', axis = 1, inplace = True)\n","cca9e113":"### 3","9abfb65b":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","9ab085e3":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","6b2400a0":"x_rfe1.drop('Special_sales', axis = 1, inplace = True)\n","2c574cae":"### 4","ec12fee3":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","3fd0b063":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","38b63804":"x_rfe1.drop('lag_1_listed_price', axis = 1, inplace = True)\n","0ecc541b":"### 5","e885402a":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","45a95fcc":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","009b216d":"x_rfe1.drop('lag_1_discount', axis = 1, inplace = True)\n","d38eba47":"### 6","8fb66022":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","4e5af936":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","644912ee":"x_rfe1.drop('lag_2_gmv', axis = 1, inplace = True)\n","21e01505":"### 7","1acfcba5":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","6cc5dd90":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","0d7fe974":"x_rfe1.drop('lag_2_NPS', axis = 1, inplace = True)\n","ecfe3a40":"### 8","0d383c34":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","1d05c15d":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","f54a462a":"x_rfe1.drop('sla', axis = 1, inplace = True)\n","4b9baf6e":"### 9","0e4b7060":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","4583c6ab":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","a3fe1393":"features = list(x_rfe1.columns)\nfeatures.remove('const')\nfeatures","848b826a":"###  Model Evaluation on testing data\nx_2 = x[features]\n\n###  Predicition with selected features on the test data\ny_pred = dlm1.predict(sm.add_constant(x_2))","dff7dc9b":"###  Mean square error (MSE)\nmse = np.mean((y_pred - y)**2)\nmse\n","71cb9d3d":"###  Coefficient values\n\ncoef = pd.DataFrame(x_rfe1.columns)\ncoef['Coefficient'] = pd.Series(dlm.coef_)\ncoef\n","6c280156":"###  Using K-Fold Cross validation evaluating on whole dataset\n\n# lm = LinearRegression()\nfold = KFold(10,shuffle = True, random_state = 100)\n\ncv_scores = -cross_val_score(dlm,x[features],y,cv=fold,scoring='neg_mean_squared_error')\n\nprint(\"Neg. of MSE:\",cv_scores,\"\\n\")\nprint(\"Mean of 5 KFold CV - MSE:\",cv_scores.mean())","37f29ae7":"def elasticity(model,x):\n    \n    features_df = pd.DataFrame(model.params)\n    features_df = features_df.rename(columns={0:'coef'})\n    \n    features_df['imp_feature'] = model.params.index\n    features_df = features_df[features_df.imp_feature != 'const'][['imp_feature','coef']]\n    features_df.index = range(len(features_df))\n#      features\n\n    elasticity_list = list()\n    \n    for i in range(len(features_df)):\n        elasticity_list.append(((features_df.coef[i] * np.mean(x[features_df.imp_feature[i]])) \/ np.mean(x['gmv'])))\n\n    features_df['elasticity'] = np.round(elasticity_list,3)\n    \n    sns.barplot(x='elasticity',y='imp_feature',data=features_df)\n    plt.show()\n    \n    return features_df\n    ","0dc8e13d":"elasticity(dlm1,camera_train_dlm)","18cb2cb8":"# Plotting y and y_pred to understand the spread\n\nfig = plt.figure()\nplt.scatter(y, y_pred)\nfig.suptitle('y vs y_pred', fontsize = 20)              # Plot heading \nplt.xlabel('y', fontsize = 18)                          # X-label\nplt.ylabel('y_pred', fontsize = 16)  ","9291f635":"# Figure size\nplt.figure(figsize=(8,5))\n\n# Heatmap\nsns.heatmap(camera_train_dlm[features].corr(), cmap=\"YlGnBu\", annot=True)\nplt.show()","5e4755f1":"###  Importing RFE and LinearRegression\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression","4007bcea":"ga_week.columns","e2dc7182":"gaming_lm = ga_week[['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price']]\n                            \n    \ngaming_lm.head()","079a55f9":"### Checking NaN\ngaming_lm.isnull().sum()","303c08ab":"gaming_lm.fillna(0, inplace = True)","c6b39708":"### Import the StandardScaler()\n# from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n### Create a scaling object\n# scaler = StandardScaler()\nscaler = MinMaxScaler()\n\n\n### Create a list of the variables that you need to scale\nvarlist = ['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price']\n                                      \n\n### Scale these variables using 'fit_transform'\ngaming_lm[varlist] = scaler.fit_transform(gaming_lm[varlist])","d9fcb5fa":"gaming_lm.head()","37206e22":"### Split the train dataset into X and y\nfrom sklearn.model_selection import train_test_split\nx = gaming_lm.drop('gmv',axis=1)\ny = gaming_lm['gmv']\n\ngaming_train_lm = gaming_lm","9f181610":"print(\"x dataset: \",x.shape)\nprint(\"y dataset: \",y.shape)","1347f043":"###  Instantiate\nlm = LinearRegression()\n\n###  Fit a line\nlm.fit(x,y)\n","e20f5a6f":"###  Coefficient values\n\ncoef = pd.DataFrame(x.columns)\ncoef['Coefficient'] = pd.Series(lm.coef_)\ncoef\n","5c93cbc4":"col = x.columns\ncol","094c97ad":"import statsmodels.api as sm  \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score","19307aaf":"def stepwise_selection(x, y,\n                       initial_list=['discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price'],\n                       threshold_in=0.01,threshold_out = 0.05, verbose=True):\n    \n    included = list(initial_list)\n    while True:\n        changed=False\n        ###forward step\n        excluded = list(set(x.columns)-set(included))\n        new_pval = pd.Series(index=excluded)\n        for new_column in excluded:\n            model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included+[new_column]]))).fit()\n            new_pval[new_column] = model.pvalues[new_column]\n        best_pval = new_pval.min()\n        if best_pval < threshold_in:\n            best_feature = new_pval.argmin()\n            included.append(best_feature)\n            changed=True\n            if verbose:\n                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n                \n                \n        ###backward step\n        model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included]))).fit()\n        ###use all coefs except intercept\n        pvalues = model.pvalues.iloc[1:]\n        worst_pval = pvalues.max() ###null if pvalues is empty\n        if worst_pval > threshold_out:\n            changed=True\n            worst_feature = pvalues.argmax()\n            included.remove(worst_feature)\n            if verbose:\n                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n        if not changed:\n            break\n    return included\n","8b9c82f5":"import statsmodels.api as sm  \n\nfinal_features = stepwise_selection(x, y)\n\nprint(\"\\n\",\"final_selected_features:\",final_features)","e0ca6b4e":"###  Import statsmodels\nimport statsmodels.api as sm  \n\n###  Subsetting training data for 15 selected columns\nx_rfe1 = x[final_features]\n\nx_rfe1 = sm.add_constant(x_rfe1)\n\n###  Fitting the model with selected variables\nlm1 = sm.OLS(y, x_rfe1).fit() \n\nprint(lm1.params)","9cf1e44b":"print(lm1.summary())","95fcacc9":"###  Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","01ce7921":"features = list(x_rfe1.columns)\nfeatures.remove('const')\nfeatures","dbd1caf9":"###  Model Evaluation on testing data\nx_2 = x[features]\n\n\n###  Predicition with selected features on the test data\ny_pred = lm1.predict(sm.add_constant(x_2))\n","99489a0f":"###  Mean square error (MSE)\n\nmse = np.mean((y_pred - y)**2)\nmse","bb3ed67e":"###  Coefficient values\n\ncoef = pd.DataFrame(x_rfe1.columns)\ncoef['Coefficient'] = pd.Series(lm.coef_)\ncoef\n","fc2f8c97":"### Mean Square Error \n###  Using K-Fold Cross validation evaluating on selected dataset\n\n# lm = LinearRegression()\nfold = KFold(10,shuffle = True, random_state = 100)\n\ncv_scores = -cross_val_score(lm,x[features],y,cv=fold,scoring='neg_mean_squared_error')\n\nprint(\"Neg. of MSE:\",cv_scores,\"\\n\")\nprint(\"Mean of 5 KFold CV - MSE:\",cv_scores.mean())","dbc58fa5":"def elasticity(model,x):\n    \n    features_df = pd.DataFrame(model.params)\n    features_df = features_df.rename(columns={0:'coef'})\n    \n    features_df['imp_feature'] = model.params.index\n    features_df = features_df[features_df.imp_feature != 'const'][['imp_feature','coef']]\n    features_df.index = range(len(features_df))\n#    features\n\n    elasticity_list = list()\n    \n    for i in range(len(features_df)):\n        elasticity_list.append(((features_df.coef[i] * np.mean(x[features_df.imp_feature[i]])) \/ np.mean(x['gmv'])))\n\n    features_df['elasticity'] = np.round(elasticity_list,3)\n    \n    sns.barplot(x='elasticity',y='imp_feature',data=features_df)\n    plt.show()\n    \n    return features_df\n    ","5a131d99":"elasticity(lm1,gaming_train_lm)","4ca120ac":"# Plotting y and y_pred to understand the spread\n\nfig = plt.figure()\nplt.scatter(y, y_pred)\nfig.suptitle('y vs y_pred', fontsize = 20)              # Plot heading \nplt.xlabel('y', fontsize = 18)                          # X-label\nplt.ylabel('y_pred', fontsize = 16)  ","4fb3ed48":"# Figure size\nplt.figure(figsize=(8,5))\n\n# Heatmap\nsns.heatmap(gaming_train_lm[features].corr(), cmap=\"YlGnBu\", annot=True)\nplt.show()","7a1afc9b":"ga_week.columns","38876be9":"gaming_mm = ga_week[['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price']]         \n\ngaming_mm.head()\n","85dad6e7":"### Applying Log \ngaming_mm=np.log(gaming_mm)\n\ngaming_mm = gaming_mm.fillna(0)\ngaming_mm = gaming_mm.replace([np.inf, -np.inf], 0)","203072b8":"gaming_mm.head()","442cd8db":"###  Import the StandardScaler()\n# from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n###  Create a scaling object\n# scaler = StandardScaler()\nscaler = MinMaxScaler()\n\n###  Create a list of the variables that you need to scale\nvarlist = ['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price']      \n\n\n\n### Scale these variables using 'fit_transform'\ngaming_mm[varlist] = scaler.fit_transform(gaming_mm[varlist])","aefa0443":"gaming_mm.head()","5d477196":"### Split the train dataset into X and y\nfrom sklearn.model_selection import train_test_split\n\nx = gaming_mm.drop('gmv',axis=1)\ny = gaming_mm['gmv']\n\ngaming_train_mm = gaming_mm","b2d1459d":"print(\"X = Independent variable & Y = Target variable\")\nprint(x.shape,y.shape)\n","d305e799":"### Instantiate\nmm = LinearRegression()\n\n### Fit a line\nmm.fit(x,y)\n","ad25dfaf":"### Coefficient values\n\ncoef = pd.DataFrame(x.columns)\ncoef['Coefficient'] = pd.Series(mm.coef_)\ncoef\n","041c95a5":"col = x.columns\ncol","4cbd21bd":"import statsmodels.api as sm  \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score","25fc86f8":"def stepwise_selection(x, y,\n                       initial_list=['discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price'],\n                       threshold_in=0.01,threshold_out = 0.05, verbose=True):\n    \n    included = list(initial_list)\n    while True:\n        changed=False\n        ###forward step\n        excluded = list(set(x.columns)-set(included))\n        new_pval = pd.Series(index=excluded)\n        for new_column in excluded:\n            model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included+[new_column]]))).fit()\n            new_pval[new_column] = model.pvalues[new_column]\n        best_pval = new_pval.min()\n        if best_pval < threshold_in:\n            best_feature = new_pval.argmin()\n            included.append(best_feature)\n            changed=True\n            if verbose:\n                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n                \n                \n        ###backward step\n        model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included]))).fit()\n        ###use all coefs except intercept\n        pvalues = model.pvalues.iloc[1:]\n        worst_pval = pvalues.max() ###null if pvalues is empty\n        if worst_pval > threshold_out:\n            changed=True\n            worst_feature = pvalues.argmax()\n            included.remove(worst_feature)\n            if verbose:\n                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n        if not changed:\n            break\n    return included\n","32c9155c":"import statsmodels.api as sm  \n\nfinal_features = stepwise_selection(x, y)\n\nprint(\"\\n\",\"final_selected_features:\",final_features)","e388c8eb":"### Import statsmodels\nimport statsmodels.api as sm  \n\n### Subsetting training data for 15 selected columns\nx_rfe1 = x[final_features]\n\nx_rfe1 = sm.add_constant(x_rfe1)\n\n\n### Fitting the model with selected variables\nmm1 = sm.OLS(y, x_rfe1).fit() \n\nprint(mm1.params)","720eb092":"print(mm1.summary())","a3a14643":"### Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","e93cc138":"x_rfe1.drop('order_payment_type', axis = 1, inplace = True)","cfb7e4f3":"### 2","4512e3db":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\nmm1 = sm.OLS(y, x_rfe1).fit()   \nprint(mm1.summary())","2040eba2":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","f44b4248":"x_rfe1.drop('snow_on_grnd_cm', axis = 1, inplace = True)\n","1388d0d8":"### 3","0c90a3ed":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\nmm1 = sm.OLS(y, x_rfe1).fit()   \nprint(mm1.summary())","24e28c74":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","dabe43e0":"features = list(x_rfe1.columns)\nfeatures.remove('const')\nfeatures","1663b3fc":"### Model Evaluation on testing data\nx_2 = x[features]\n\n\n### Predicition with selected features on the test data\ny_pred = mm1.predict(sm.add_constant(x_2))\n","4f3d834c":"### Mean square error (MSE)\nmse = np.mean((y_pred - y)**2)\nmse","26ec5ce1":"### Coefficient values\n\ncoef = pd.DataFrame(x_rfe1.columns)\ncoef['Coefficient'] = pd.Series(mm.coef_)\ncoef\n","103a5211":"### Mean Square Error \n###  Using K-Fold Cross validation evaluating on selected dataset\n\n# lm = LinearRegression()\nfold = KFold(10,shuffle = True, random_state = 100)\n\ncv_scores = -cross_val_score(mm,x[features],y,cv=fold,scoring='neg_mean_squared_error')\n\nprint(\"Neg. of MSE:\",cv_scores,\"\\n\")\nprint(\"Mean of 5 KFold CV - MSE:\",cv_scores.mean())","18449c58":"def elasticity(model,x):\n    \n    features_df = pd.DataFrame(model.params)\n    features_df = features_df.rename(columns={0:'coef'})\n    \n    features_df['imp_feature'] = model.params.index\n    features_df = features_df[features_df.imp_feature != 'const'][['imp_feature','coef']]\n    features_df.index = range(len(features_df))\n#     features\n\n    elasticity_list = list()\n    \n    for i in range(len(features_df)):\n        elasticity_list.append(((features_df.coef[i] * np.mean(x[features_df.imp_feature[i]])) \/ np.mean(x['gmv'])))\n\n    features_df['elasticity'] = np.round(elasticity_list,3)\n    \n    sns.barplot(x='elasticity',y='imp_feature',data=features_df)\n    plt.show()\n    \n    return features_df\n    ","2b70457a":"elasticity(mm1,gaming_train_mm)","22432187":"# Plotting y and y_pred to understand the spread\n\nfig = plt.figure()\nplt.scatter(y, y_pred)\nfig.suptitle('y vs y_pred', fontsize = 20)              # Plot heading \nplt.xlabel('y', fontsize = 18)                          # X-label\nplt.ylabel('y_pred', fontsize = 16)  ","388043d3":"# Figure size\nplt.figure(figsize=(8,5))\n\n# Heatmap\nsns.heatmap(gaming_train_mm[features].corr(), cmap=\"YlGnBu\", annot=True)\nplt.show()","a424f076":"ga_week.columns","21dc9a68":"gaming_km = ga_week[['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price']]           \n\n\ngaming_km.head()\n","342af663":"gaming_km['lag_1_gmv'] = gaming_km['gmv'].shift(-1)","3e9b3109":"### Checking NaN\n\ngaming_km.isnull().sum()","f110b441":"gaming_km = gaming_km.fillna(0)","225e2c04":"gaming_km.head()","9b932748":"###  Import the StandardScaler()\n# from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n### Create a scaling object\n# scaler = StandardScaler()\nscaler = MinMaxScaler()\n\n### Create a list of the variables that you need to scale\nvarlist = ['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price','lag_1_gmv']\n\n### Scale these variables using 'fit_transform'\ngaming_km[varlist] = scaler.fit_transform(gaming_km[varlist])","5592c373":"gaming_km.head()","edf17e32":"### Split the train dataset into X and y\nfrom sklearn.model_selection import train_test_split\nx = gaming_km.drop('gmv',axis=1)\ny = gaming_km['gmv']\n\ngaming_train_km = gaming_km","a5ff361c":"print(\"X = Independent variable & Y = Target variable\")\nprint(x.shape,y.shape)","0164b8ed":"###  Instantiate\nkm = LinearRegression()\n\n###  Fit a line\nkm.fit(x,y)\n","82fa191c":"###  Coefficient values\n\ncoef = pd.DataFrame(x.columns)\ncoef['Coefficient'] = pd.Series(km.coef_)\ncoef\n","ba81d2b1":"col = x.columns\ncol","4279deb4":"import statsmodels.api as sm  \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score","573a038e":"def stepwise_selection(x, y,\n                       initial_list=['discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price', 'lag_1_gmv'],\n                       threshold_in=0.01,threshold_out = 0.05, verbose=True):\n    \n    included = list(initial_list)\n    while True:\n        changed=False\n        ### forward step\n        excluded = list(set(x.columns)-set(included))\n        new_pval = pd.Series(index=excluded)\n        for new_column in excluded:\n            model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included+[new_column]]))).fit()\n            new_pval[new_column] = model.pvalues[new_column]\n        best_pval = new_pval.min()\n        if best_pval < threshold_in:\n            best_feature = new_pval.argmin()\n            included.append(best_feature)\n            changed=True\n            if verbose:\n                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n                \n                \n        ###backward step\n        model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included]))).fit()\n        ###use all coefs except intercept\n        pvalues = model.pvalues.iloc[1:]\n        worst_pval = pvalues.max() ###null if pvalues is empty\n        if worst_pval > threshold_out:\n            changed=True\n            worst_feature = pvalues.argmax()\n            included.remove(worst_feature)\n            if verbose:\n                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n        if not changed:\n            break\n    return included\n","7251ae0c":"import statsmodels.api as sm  \n\nfinal_features = stepwise_selection(x, y)\n\nprint(\"\\n\",\"final_selected_features:\",final_features)","320a7a3b":"### Import statsmodels\nimport statsmodels.api as sm  \n\n### Subsetting training data for 15 selected columns\nx_rfe1 = x[final_features]\n\nx_rfe1 = sm.add_constant(x_rfe1)\n\n### Fitting the model with selected variables\nkm1 = sm.OLS(y, x_rfe1).fit() \n\nprint(km1.params)","2ee09550":"print(km1.summary())","c3e60c4c":"### Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","82bc70a9":"features = list(x_rfe1.columns)\nfeatures.remove('const')\nfeatures","688e410b":"### Model Evaluation on testing data\nx_2 = x[features]\n\n\n### Predicition with selected features on the test data\ny_pred = km1.predict(sm.add_constant(x_2))\n","d9c3a8d9":"### Mean square error (MSE)\nmse = np.mean((y_pred - y)**2)\nmse","8895199b":"### Coefficient values\n\ncoef = pd.DataFrame(x_rfe1.columns)\ncoef['Coefficient'] = pd.Series(km.coef_)\ncoef\n","215493f0":"### Using K-Fold Cross validation evaluating on whole dataset\n\n# lm = LinearRegression()\nfold = KFold(10,shuffle = True, random_state = 100)\n\ncv_scores = -cross_val_score(km,x[features],y,cv=fold,scoring='neg_mean_squared_error')\n\nprint(\"Neg. of MSE:\",cv_scores,\"\\n\")\nprint(\"Mean of 5 KFold CV - MSE:\",cv_scores.mean())","458d4be1":"def elasticity(model,x):\n    \n    features_df = pd.DataFrame(model.params)\n    features_df = features_df.rename(columns={0:'coef'})\n    \n    features_df['imp_feature'] = model.params.index\n    features_df = features_df[features_df.imp_feature != 'const'][['imp_feature','coef']]\n    features_df.index = range(len(features_df))\n#      features\n\n    elasticity_list = list()\n    \n    for i in range(len(features_df)):\n        elasticity_list.append(((features_df.coef[i] * np.mean(x[features_df.imp_feature[i]])) \/ np.mean(x['gmv'])))\n\n    features_df['elasticity'] = np.round(elasticity_list,3)\n    \n    sns.barplot(x='elasticity',y='imp_feature',data=features_df)\n    plt.show()\n    \n    return features_df\n    ","0f83841b":"elasticity(km1,gaming_train_km)","ae9d4e75":"# Plotting y and y_pred to understand the spread\n\nfig = plt.figure()\nplt.scatter(y, y_pred)\nfig.suptitle('y vs y_pred', fontsize = 20)              # Plot heading \nplt.xlabel('y', fontsize = 18)                          # X-label\nplt.ylabel('y_pred', fontsize = 16)  ","40bf7729":"# Figure size\nplt.figure(figsize=(8,5))\n\n# Heatmap\nsns.heatmap(gaming_train_km[features].corr(), cmap=\"YlGnBu\", annot=True)\nplt.show()","27b8c994":"gaming_dlm = ga_week[['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price','lag_1_listed_price','lag_1_discount_offer',\n       'lag_2_discount_offer','lag_3_discount_offer','lag_2_NPS','lag_3_NPS','lag_1_Stock_Index',\n       'lag_2_Stock_Index','lag_3_Stock_Index','lag_1_Special_sales','lag_2_Special_sales','lag_3_Special_sales',\n       'lag_1_Payday','lag_2_Payday','lag_3_Payday']]           \n\n\ngaming_dlm.head()\n","7f74a222":"gaming_dlm['lag_1_gmv'] = gaming_dlm['gmv'].shift(-1)\ngaming_dlm['lag_2_gmv'] = gaming_dlm['gmv'].shift(-2)\ngaming_dlm['lag_3_gmv'] = gaming_dlm['gmv'].shift(-3)\n","ed06558e":"### Checking NaN\n\n# gaming_dlm.isnull().sum()","08253592":"gaming_dlm = gaming_dlm.fillna(0)","3db4fd24":"gaming_dlm.head()","0357e8f7":"gaming_dlm.columns","dddca995":"###  Import the StandardScaler()\n# from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n###  Create a scaling object\n# scaler = StandardScaler()\nscaler = MinMaxScaler()\n\n\n###  Create a list of the variables that you need to scale\nvarlist = ['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price','lag_1_listed_price','lag_1_discount_offer',\n       'lag_2_discount_offer','lag_3_discount_offer','lag_2_NPS','lag_3_NPS','lag_1_Stock_Index',\n       'lag_2_Stock_Index','lag_3_Stock_Index','lag_1_Special_sales','lag_2_Special_sales','lag_3_Special_sales',\n       'lag_1_Payday','lag_2_Payday','lag_3_Payday']\n\n\n###  Scale these variables using 'fit_transform'\ngaming_dlm[varlist] = scaler.fit_transform(gaming_dlm[varlist])","518f7b7c":"gaming_dlm.head()","d0034ddd":"###  Split the train dataset into X and y\nfrom sklearn.model_selection import train_test_split\nx = gaming_dlm.drop('gmv',axis=1)\ny = gaming_dlm['gmv']\n\ngaming_train_dlm = gaming_dlm","8bb4347d":"print(\"X = Independent variable & Y = Target variable\")\nprint(x.shape,y.shape)","3104ce9f":"###  Instantiate\ndlm = LinearRegression()\n\n###  Fit a line\ndlm.fit(x,y)\n","3fa22497":"###  Coefficient values\n\ncoef = pd.DataFrame(x.columns)\ncoef['Coefficient'] = pd.Series(dlm.coef_)\ncoef\n","23066e79":"col = x.columns\ncol","8eec121b":"import statsmodels.api as sm  \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score","02c29771":"def stepwise_selection(x, y,\n                       initial_list=['discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price','lag_1_listed_price','lag_1_discount_offer',\n       'lag_2_discount_offer','lag_3_discount_offer','lag_2_NPS','lag_3_NPS','lag_1_Stock_Index',\n       'lag_2_Stock_Index','lag_3_Stock_Index','lag_1_Special_sales','lag_2_Special_sales','lag_3_Special_sales',\n       'lag_1_Payday','lag_2_Payday','lag_3_Payday'],\n                     threshold_in=0.01,threshold_out = 0.05, verbose=True):\n    \n    included = list(initial_list)\n    while True:\n        changed=False\n        ###  forward step\n        excluded = list(set(x.columns)-set(included))\n        new_pval = pd.Series(index=excluded)\n        for new_column in excluded:\n            model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included+[new_column]]))).fit()\n            new_pval[new_column] = model.pvalues[new_column]\n        best_pval = new_pval.min()\n        if best_pval < threshold_in:\n            best_feature = new_pval.argmin()\n            included.append(best_feature)\n            changed=True\n            if verbose:\n                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n                \n                \n        ###  backward step\n        model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included]))).fit()\n        ###  use all coefs except intercept\n        pvalues = model.pvalues.iloc[1:]\n        worst_pval = pvalues.max() ###  null if pvalues is empty\n        if worst_pval > threshold_out:\n            changed=True\n            worst_feature = pvalues.argmax()\n            included.remove(worst_feature)\n            if verbose:\n                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n        if not changed:\n            break\n    return included\n","fabd2908":"import statsmodels.api as sm  \n\nfinal_features = stepwise_selection(x, y)\n\nprint(\"\\n\",\"final_selected_features:\",final_features)","a8143d78":"###  Import statsmodels\nimport statsmodels.api as sm  \n\n###  Subsetting training data for 15 selected columns\nx_rfe1 = x[final_features]\n\nx_rfe1 = sm.add_constant(x_rfe1)\n\n###  Fitting the model with selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit() \n\nprint(dlm1.params)","b08ca32c":"print(dlm1.summary())","34a3d05d":"###  Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","2eaf57c8":"x_rfe1.drop('lag_3_Stock_Index', axis = 1, inplace = True)","67e33a25":"### 2","a0c5af9b":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","7f660f21":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","9f43ee70":"x_rfe1.drop('lag_3_NPS', axis = 1, inplace = True)\n","cd386cc4":"### 3","7daaba91":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","3a5128df":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","a022c08a":"x_rfe1.drop('sla', axis = 1, inplace = True)\n","74ef2229":"### 4","4238ef58":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","cbc3e515":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","78ac01b8":"features = list(x_rfe1.columns)\nfeatures.remove('const')\nfeatures","c05101f1":"###  Model Evaluation on testing data\nx_2 = x[features]\n\n###  Predicition with selected features on the test data\ny_pred = dlm1.predict(sm.add_constant(x_2))","09f5ce9d":"###  Mean square error (MSE)\nmse = np.mean((y_pred - y)**2)\nmse\n","331aaf7f":"###  Coefficient values\n\ncoef = pd.DataFrame(x_rfe1.columns)\ncoef['Coefficient'] = pd.Series(dlm.coef_)\ncoef\n","ec0edf8f":"###  Using K-Fold Cross validation evaluating on whole dataset\n\n# lm = LinearRegression()\nfold = KFold(10,shuffle = True, random_state = 100)\n\ncv_scores = -cross_val_score(dlm,x[features],y,cv=fold,scoring='neg_mean_squared_error')\n\nprint(\"Neg. of MSE:\",cv_scores,\"\\n\")\nprint(\"Mean of 5 KFold CV - MSE:\",cv_scores.mean())","03f3384e":"def elasticity(model,x):\n    \n    features_df = pd.DataFrame(model.params)\n    features_df = features_df.rename(columns={0:'coef'})\n    \n    features_df['imp_feature'] = model.params.index\n    features_df = features_df[features_df.imp_feature != 'const'][['imp_feature','coef']]\n    features_df.index = range(len(features_df))\n#      features\n\n    elasticity_list = list()\n    \n    for i in range(len(features_df)):\n        elasticity_list.append(((features_df.coef[i] * np.mean(x[features_df.imp_feature[i]])) \/ np.mean(x['gmv'])))\n\n    features_df['elasticity'] = np.round(elasticity_list,3)\n    \n    sns.barplot(x='elasticity',y='imp_feature',data=features_df)\n    plt.show()\n    \n    return features_df\n    ","75e29b8a":"elasticity(dlm1,gaming_train_dlm)","d3c1e5f8":"# Plotting y and y_pred to understand the spread\n\nfig = plt.figure()\nplt.scatter(y, y_pred)\nfig.suptitle('y vs y_pred', fontsize = 20)              # Plot heading \nplt.xlabel('y', fontsize = 18)                          # X-label\nplt.ylabel('y_pred', fontsize = 16)  ","a34caff4":"# Figure size\nplt.figure(figsize=(8,5))\n\n# Heatmap\nsns.heatmap(gaming_train_dlm[features].corr(), cmap=\"YlGnBu\", annot=True)\nplt.show()","6aa9dfc3":"gaming_dlmm = ga_week[['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price','lag_1_listed_price','lag_1_discount_offer',\n       'lag_2_discount_offer','lag_3_discount_offer','lag_2_NPS','lag_3_NPS','lag_1_Stock_Index',\n       'lag_2_Stock_Index','lag_3_Stock_Index','lag_1_Special_sales','lag_2_Special_sales','lag_3_Special_sales',\n       'lag_1_Payday','lag_2_Payday','lag_3_Payday']]           \n\n\ngaming_dlmm.head()\n","cdb2801c":"gaming_dlmm['lag_1_gmv'] = gaming_dlmm['gmv'].shift(-1)\ngaming_dlmm['lag_2_gmv'] = gaming_dlmm['gmv'].shift(-2)\ngaming_dlmm['lag_3_gmv'] = gaming_dlmm['gmv'].shift(-3)\n","65ff2861":"### Checking NaN\n\ngaming_dlmm.isnull().sum()","08266e81":"gaming_dlmm = gaming_dlmm.fillna(0)","9cf974cb":"### Applying Log \ngaming_dlmm=np.log(gaming_dlmm)\n\ngaming_dlmm = gaming_dlmm.fillna(0)\ngaming_dlmm = gaming_dlmm.replace([np.inf, -np.inf], 0)","843c74a2":"gaming_dlmm.head()","fcb46227":"gaming_dlmm.columns","d374218a":"###  Import the StandardScaler()\n# from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n###  Create a scaling object\n# scaler = StandardScaler()\nscaler = MinMaxScaler()\n\n\n###  Create a list of the variables that you need to scale\nvarlist = ['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price','lag_1_listed_price','lag_1_discount_offer',\n       'lag_2_discount_offer','lag_3_discount_offer','lag_2_NPS','lag_3_NPS','lag_1_Stock_Index',\n       'lag_2_Stock_Index','lag_3_Stock_Index','lag_1_Special_sales','lag_2_Special_sales','lag_3_Special_sales',\n       'lag_1_Payday','lag_2_Payday','lag_3_Payday']\n\n\n###  Scale these variables using 'fit_transform'\ngaming_dlmm[varlist] = scaler.fit_transform(gaming_dlmm[varlist])\n","6108c256":"gaming_dlmm.head()","3eba198e":"###  Split the train dataset into X and y\nfrom sklearn.model_selection import train_test_split\nx = gaming_dlmm.drop('gmv',axis=1)\ny = gaming_dlmm['gmv']\n\ngaming_train_dlmm = gaming_dlmm","a8cbc240":"print(\"X = Independent variable & Y = Target variable\")\nprint(x.shape,y.shape)","3e30117b":"###  Instantiate\ndlm = LinearRegression()\n\n###  Fit a line\ndlm.fit(x,y)\n","1c06f748":"###  Coefficient values\n\ncoef = pd.DataFrame(x.columns)\ncoef['Coefficient'] = pd.Series(dlm.coef_)\ncoef\n","3cb179bb":"col = x.columns\ncol","922ea61c":"import statsmodels.api as sm  \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score","f310a7af":"def stepwise_selection(x, y,\n                       initial_list=['discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price','lag_1_listed_price','lag_1_discount_offer',\n       'lag_2_discount_offer','lag_3_discount_offer','lag_2_NPS','lag_3_NPS','lag_1_Stock_Index',\n       'lag_2_Stock_Index','lag_3_Stock_Index','lag_1_Special_sales','lag_2_Special_sales','lag_3_Special_sales',\n       'lag_1_Payday','lag_2_Payday','lag_3_Payday'],\n                     threshold_in=0.01,threshold_out = 0.05, verbose=True):\n    \n    included = list(initial_list)\n    while True:\n        changed=False\n        ###  forward step\n        excluded = list(set(x.columns)-set(included))\n        new_pval = pd.Series(index=excluded)\n        for new_column in excluded:\n            model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included+[new_column]]))).fit()\n            new_pval[new_column] = model.pvalues[new_column]\n        best_pval = new_pval.min()\n        if best_pval < threshold_in:\n            best_feature = new_pval.argmin()\n            included.append(best_feature)\n            changed=True\n            if verbose:\n                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n                \n                \n        ###  backward step\n        model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included]))).fit()\n        ###  use all coefs except intercept\n        pvalues = model.pvalues.iloc[1:]\n        worst_pval = pvalues.max() ###  null if pvalues is empty\n        if worst_pval > threshold_out:\n            changed=True\n            worst_feature = pvalues.argmax()\n            included.remove(worst_feature)\n            if verbose:\n                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n        if not changed:\n            break\n    return included\n","72f79129":"import statsmodels.api as sm  \n\nfinal_features = stepwise_selection(x, y)\n\nprint(\"\\n\",\"final_selected_features:\",final_features)","cbce20b3":"###  Import statsmodels\nimport statsmodels.api as sm  \n\n###  Subsetting training data for 15 selected columns\nx_rfe1 = x[final_features]\n\nx_rfe1 = sm.add_constant(x_rfe1)\n\n###  Fitting the model with selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit() \n\nprint(dlm1.params)","3a74bd8c":"print(dlm1.summary())","a3ef8c3c":"###  Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","afb2b842":"x_rfe1.drop('lag_3_Stock_Index', axis = 1, inplace = True)","bbd92b5e":"### 2","5ddd81b9":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","248e3b6c":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","a9430cd1":"x_rfe1.drop('lag_3_discount_offer', axis = 1, inplace = True)\n","9bbaa86b":"### 3","d5dbe1ac":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","144679dc":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","c595926f":"x_rfe1.drop('lag_2_NPS', axis = 1, inplace = True)\n","4166745f":"### 4","060bde75":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","268832f0":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","ff9493e0":"x_rfe1.drop('lag_2_discount_offer', axis = 1, inplace = True)\n","0058898d":"### 5","be4c1911":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","18012ce7":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","9ad1cc1a":"x_rfe1.drop('Online_marketing_ads', axis = 1, inplace = True)\n","4d31ab71":"### 6","7c5bafeb":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","b20f042b":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","6c1352d6":"x_rfe1.drop('lag_1_listed_price', axis = 1, inplace = True)\n","0b50681d":"### 7","98db82e2":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","a6256cce":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","79e06c7b":"x_rfe1.drop('lag_1_discount_offer', axis = 1, inplace = True)\n","7224a4da":"### 8","23e8e039":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","8404c267":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","f1536c4a":"x_rfe1.drop('lag_3_NPS', axis = 1, inplace = True)\n","5cf8605a":"### 9","0394054a":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","d2ba3bc6":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","0a904417":"x_rfe1.drop('Stock_Index', axis = 1, inplace = True)\n","0b17bc83":"### 10","eaeaee04":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","77563d6b":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","269cdf32":"x_rfe1.drop('order_payment_type', axis = 1, inplace = True)\n","b94e040d":"### 11","693ee30d":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","6a1ca789":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","32ec59ad":"x_rfe1.drop('lag_1_gmv', axis = 1, inplace = True)\n","4794e7ac":"### 12","d15087c3":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","80dbb990":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","9e3c80b2":"x_rfe1.drop('lag_1_Stock_Index', axis = 1, inplace = True)\n","e38c8752":"### 13","b76d2b52":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","1dd3aff8":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","500c283f":"x_rfe1.drop('TV_ads', axis = 1, inplace = True)\n","f7d0cd09":"### 14","bdc503b7":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","5b616cf6":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","21fb9052":"features = list(x_rfe1.columns)\nfeatures.remove('const')\nfeatures","d1b47c67":"###  Model Evaluation on testing data\nx_2 = x[features]\n\n###  Predicition with selected features on the test data\ny_pred = dlm1.predict(sm.add_constant(x_2))","31d12197":"###  Mean square error (MSE)\nmse = np.mean((y_pred - y)**2)\nmse\n","d988b7ed":"###  Coefficient values\n\ncoef = pd.DataFrame(x_rfe1.columns)\ncoef['Coefficient'] = pd.Series(dlm.coef_)\ncoef\n","a41beef4":"###  Using K-Fold Cross validation evaluating on whole dataset\n\n# lm = LinearRegression()\nfold = KFold(10,shuffle = True, random_state = 100)\n\ncv_scores = -cross_val_score(dlm,x[features],y,cv=fold,scoring='neg_mean_squared_error')\n\nprint(\"Neg. of MSE:\",cv_scores,\"\\n\")\nprint(\"Mean of 5 KFold CV - MSE:\",cv_scores.mean())","26c73eab":"def elasticity(model,x):\n    \n    features_df = pd.DataFrame(model.params)\n    features_df = features_df.rename(columns={0:'coef'})\n    \n    features_df['imp_feature'] = model.params.index\n    features_df = features_df[features_df.imp_feature != 'const'][['imp_feature','coef']]\n    features_df.index = range(len(features_df))\n#      features\n\n    elasticity_list = list()\n    \n    for i in range(len(features_df)):\n        elasticity_list.append(((features_df.coef[i] * np.mean(x[features_df.imp_feature[i]])) \/ np.mean(x['gmv'])))\n\n    features_df['elasticity'] = np.round(elasticity_list,3)\n    \n    sns.barplot(x='elasticity',y='imp_feature',data=features_df)\n    plt.show()\n    \n    return features_df\n    ","97d011e1":"elasticity(dlm1,gaming_train_dlm)","968c57a8":"# Plotting y and y_pred to understand the spread\n\nfig = plt.figure()\nplt.scatter(y, y_pred)\nfig.suptitle('y vs y_pred', fontsize = 20)              # Plot heading \nplt.xlabel('y', fontsize = 18)                          # X-label\nplt.ylabel('y_pred', fontsize = 16)  ","21ec4b8f":"# Figure size\nplt.figure(figsize=(8,5))\n\n# Heatmap\nsns.heatmap(gaming_train_dlm[features].corr(), cmap=\"YlGnBu\", annot=True)\nplt.show()","2dfe6b45":"###  Importing RFE and LinearRegression\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression","8012856b":"ha_week.columns","65cfbe8b":"home_lm = ha_week[['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price', 'MA4_listed_price']]\n                            \n    \nhome_lm.head()","7f994ce5":"### Checking NaN\n\nhome_lm.isnull().sum()","295c4e73":"home_lm.fillna(0, inplace = True)","1f24661c":"### Import the StandardScaler()\n# from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n### Create a scaling object\n# scaler = StandardScaler()\nscaler = MinMaxScaler()\n\n\n### Create a list of the variables that you need to scale\nvarlist = ['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price', 'MA4_listed_price']\n                                      \n\n### Scale these variables using 'fit_transform'\nhome_lm[varlist] = scaler.fit_transform(home_lm[varlist])","23ba442e":"home_lm.head()","088bac90":"### Split the train dataset into X and y\nfrom sklearn.model_selection import train_test_split\nx = home_lm.drop('gmv',axis=1)\ny = home_lm['gmv']\n\nhome_train_lm = home_lm","ff472ec8":"print(\"x dataset: \",x.shape)\nprint(\"y dataset: \",y.shape)","cf7acf16":"###  Instantiate\nlm = LinearRegression()\n\n###  Fit a line\nlm.fit(x,y)\n","29db1a15":"###  Coefficient values\n\ncoef = pd.DataFrame(x.columns)\ncoef['Coefficient'] = pd.Series(lm.coef_)\ncoef\n","12409cd4":"col = x.columns\ncol","d0aefa88":"import statsmodels.api as sm  \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score","01a52bd7":"def stepwise_selection(x, y,\n                       initial_list=['discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price', 'MA4_listed_price'],\n                       threshold_in=0.01,threshold_out = 0.05, verbose=True):\n    \n    included = list(initial_list)\n    while True:\n        changed=False\n        ###forward step\n        excluded = list(set(x.columns)-set(included))\n        new_pval = pd.Series(index=excluded)\n        for new_column in excluded:\n            model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included+[new_column]]))).fit()\n            new_pval[new_column] = model.pvalues[new_column]\n        best_pval = new_pval.min()\n        if best_pval < threshold_in:\n            best_feature = new_pval.argmin()\n            included.append(best_feature)\n            changed=True\n            if verbose:\n                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n                \n                \n        ###backward step\n        model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included]))).fit()\n        ###use all coefs except intercept\n        pvalues = model.pvalues.iloc[1:]\n        worst_pval = pvalues.max() ###null if pvalues is empty\n        if worst_pval > threshold_out:\n            changed=True\n            worst_feature = pvalues.argmax()\n            included.remove(worst_feature)\n            if verbose:\n                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n        if not changed:\n            break\n    return included\n","1b2d4732":"import statsmodels.api as sm  \n\nfinal_features = stepwise_selection(x, y)\n\nprint(\"\\n\",\"final_selected_features:\",final_features)","228ad5fb":"### Import statsmodels\nimport statsmodels.api as sm  \n\n### Subsetting training data for 15 selected columns\nx_rfe1 = x[final_features]\n\nx_rfe1 = sm.add_constant(x_rfe1)\n\n### Fitting the model with selected variables\nlm1 = sm.OLS(y, x_rfe1).fit() \n\nprint(lm1.params)","4677c169":"print(lm1.summary())","1ba6c4f8":"###  Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","f1479d21":"features = list(x_rfe1.columns)\nfeatures.remove('const')\nfeatures","c5766c35":"###  Model Evaluation on testing data\nx_2 = x[features]\n\n###  Predicition with selected features on the test data\ny_pred = lm1.predict(sm.add_constant(x_2))\n","5a9480c3":"###  Mean square error (MSE)\n\nmse = np.mean((y_pred - y)**2)\nmse","e828d8d6":"###  Coefficient values\n\ncoef = pd.DataFrame(x_rfe1.columns)\ncoef['Coefficient'] = pd.Series(lm.coef_)\ncoef","d707d4ef":"### Mean Square Error \n###  Using K-Fold Cross validation evaluating on selected dataset\n\n# lm = LinearRegression()\nfold = KFold(10,shuffle = True, random_state = 100)\n\ncv_scores = -cross_val_score(lm,x[features],y,cv=fold,scoring='neg_mean_squared_error')\n\nprint(\"Neg. of MSE:\",cv_scores,\"\\n\")\nprint(\"Mean of 5 KFold CV - MSE:\",cv_scores.mean())","55d7a1ee":"def elasticity(model,x):\n    \n    features_df = pd.DataFrame(model.params)\n    features_df = features_df.rename(columns={0:'coef'})\n    \n    features_df['imp_feature'] = model.params.index\n    features_df = features_df[features_df.imp_feature != 'const'][['imp_feature','coef']]\n    features_df.index = range(len(features_df))\n#    features\n\n    elasticity_list = list()\n    \n    for i in range(len(features_df)):\n        elasticity_list.append(((features_df.coef[i] * np.mean(x[features_df.imp_feature[i]])) \/ np.mean(x['gmv'])))\n\n    features_df['elasticity'] = np.round(elasticity_list,3)\n    \n    sns.barplot(x='elasticity',y='imp_feature',data=features_df)\n    plt.show()\n    \n    return features_df\n    ","5eadd803":"elasticity(lm1,home_train_lm)","a3df9848":"# Plotting y and y_pred to understand the spread\n\nfig = plt.figure()\nplt.scatter(y, y_pred)\nfig.suptitle('y vs y_pred', fontsize = 20)              # Plot heading \nplt.xlabel('y', fontsize = 18)                          # X-label\nplt.ylabel('y_pred', fontsize = 16)  ","3af900f1":"# Figure size\nplt.figure(figsize=(8,5))\n\n# Heatmap\nsns.heatmap(home_train_lm[features].corr(), cmap=\"YlGnBu\", annot=True)\nplt.show()","3f5ec81a":"ha_week.columns","187514a7":"home_mm = ha_week[['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price', 'MA4_listed_price']]         \n\nhome_mm.head()\n","1f1a33b8":"### Applying Log \nhome_mm=np.log(home_mm)\n\nhome_mm = home_mm.fillna(0)\nhome_mm = home_mm.replace([np.inf, -np.inf], 0)","1fa7af8d":"home_mm.head()","6aff6b3d":"###  Import the StandardScaler()\n# from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n###  Create a scaling object\n# scaler = StandardScaler()\nscaler = MinMaxScaler()\n\n###  Create a list of the variables that you need to scale\nvarlist = ['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price', 'MA4_listed_price']      \n\n\n\n### Scale these variables using 'fit_transform'\nhome_mm[varlist] = scaler.fit_transform(home_mm[varlist])","e427e3c8":"home_mm.head()","eda9e779":"### Split the train dataset into X and y\nfrom sklearn.model_selection import train_test_split\n\nx = home_mm.drop('gmv',axis=1)\ny = home_mm['gmv']\n\nhome_train_mm = home_mm","642373b6":"print(\"X = Independent variable & Y = Target variable\")\nprint(x.shape,y.shape)\n","bcd42fe0":"### Instantiate\nmm = LinearRegression()\n\n### Fit a line\nmm.fit(x,y)\n","cf38d3ee":"### Coefficient values\n\ncoef = pd.DataFrame(x.columns)\ncoef['Coefficient'] = pd.Series(mm.coef_)\ncoef\n","1e506fa2":"col = x.columns\ncol","995231fe":"import statsmodels.api as sm  \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score","cdec1341":"def stepwise_selection(x, y,\n                       initial_list=['discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price', 'MA4_listed_price'],\n                       threshold_in=0.01,threshold_out = 0.05, verbose=True):\n    \n    included = list(initial_list)\n    while True:\n        changed=False\n        ###forward step\n        excluded = list(set(x.columns)-set(included))\n        new_pval = pd.Series(index=excluded)\n        for new_column in excluded:\n            model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included+[new_column]]))).fit()\n            new_pval[new_column] = model.pvalues[new_column]\n        best_pval = new_pval.min()\n        if best_pval < threshold_in:\n            best_feature = new_pval.argmin()\n            included.append(best_feature)\n            changed=True\n            if verbose:\n                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n                \n                \n        ###backward step\n        model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included]))).fit()\n        ###use all coefs except intercept\n        pvalues = model.pvalues.iloc[1:]\n        worst_pval = pvalues.max() ###null if pvalues is empty\n        if worst_pval > threshold_out:\n            changed=True\n            worst_feature = pvalues.argmax()\n            included.remove(worst_feature)\n            if verbose:\n                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n        if not changed:\n            break\n    return included\n","4a130d14":"import statsmodels.api as sm  \n\nfinal_features = stepwise_selection(x, y)\n\nprint(\"\\n\",\"final_selected_features:\",final_features)","2e0ea09e":"### Import statsmodels\nimport statsmodels.api as sm  \n\n### Subsetting training data for 15 selected columns\nx_rfe1 = x[final_features]\n\nx_rfe1 = sm.add_constant(x_rfe1)\n\n\n### Fitting the model with selected variables\nmm1 = sm.OLS(y, x_rfe1).fit() \n\nprint(mm1.params)","f670b9af":"print(mm1.summary())","f7639628":"### Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","6549b880":"features = list(x_rfe1.columns)\nfeatures.remove('const')\nfeatures","671fffd1":"### Model Evaluation on testing data\nx_2 = x[features]\n\n\n### Predicition with selected features on the test data\ny_pred = mm1.predict(sm.add_constant(x_2))\n","55d63d98":"### Mean square error (MSE)\nmse = np.mean((y_pred - y)**2)\nmse","64b7d934":"### Coefficient values\n\ncoef = pd.DataFrame(x_rfe1.columns)\ncoef['Coefficient'] = pd.Series(mm.coef_)\ncoef\n","a318bde2":"### Mean Square Error \n###  Using K-Fold Cross validation evaluating on selected dataset\n\n# lm = LinearRegression()\nfold = KFold(10,shuffle = True, random_state = 100)\n\ncv_scores = -cross_val_score(mm,x[features],y,cv=fold,scoring='neg_mean_squared_error')\n\nprint(\"Neg. of MSE:\",cv_scores,\"\\n\")\nprint(\"Mean of 5 KFold CV - MSE:\",cv_scores.mean())","6860ed65":"def elasticity(model,x):\n    \n    features_df = pd.DataFrame(model.params)\n    features_df = features_df.rename(columns={0:'coef'})\n    \n    features_df['imp_feature'] = model.params.index\n    features_df = features_df[features_df.imp_feature != 'const'][['imp_feature','coef']]\n    features_df.index = range(len(features_df))\n#     features\n\n    elasticity_list = list()\n    \n    for i in range(len(features_df)):\n        elasticity_list.append(((features_df.coef[i] * np.mean(x[features_df.imp_feature[i]])) \/ np.mean(x['gmv'])))\n\n    features_df['elasticity'] = np.round(elasticity_list,3)\n    \n    sns.barplot(x='elasticity',y='imp_feature',data=features_df)\n    plt.show()\n    \n    return features_df\n    ","c0f63b5c":"elasticity(mm1,home_train_mm)","0973edeb":"# Plotting y and y_pred to understand the spread\n\nfig = plt.figure()\nplt.scatter(y, y_pred)\nfig.suptitle('y vs y_pred', fontsize = 20)              # Plot heading \nplt.xlabel('y', fontsize = 18)                          # X-label\nplt.ylabel('y_pred', fontsize = 16)  ","2fd7404e":"# Figure size\nplt.figure(figsize=(8,5))\n\n# Heatmap\nsns.heatmap(home_train_mm[features].corr(), cmap=\"YlGnBu\", annot=True)\nplt.show()","178f5716":"ha_week.columns","2a63619d":"home_km = ha_week[['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price', 'MA4_listed_price']]           \n\n\nhome_km.head()\n","eb84a95b":"home_km['lag_1_gmv'] = home_km['gmv'].shift(-1)","3fab7847":"### Checking NaN\n\nhome_km.isnull().sum()","bb480827":"home_km = home_km.fillna(0)","dc041f6a":"home_km.head()","60078c42":"###  Import the StandardScaler()\n# from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n### Create a scaling object\n# scaler = StandardScaler()\nscaler = MinMaxScaler()\n\n### Create a list of the variables that you need to scale\nvarlist = ['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price', 'MA4_listed_price','lag_1_gmv']\n\n### Scale these variables using 'fit_transform'\nhome_km[varlist] = scaler.fit_transform(home_km[varlist])","0e1fec8c":"home_km.head()","f48e850e":"### Split the train dataset into X and y\nfrom sklearn.model_selection import train_test_split\nx = home_km.drop('gmv',axis=1)\ny = home_km['gmv']\n\nhome_train_km = home_km","48abf578":"print(\"X = Independent variable & Y = Target variable\")\nprint(x.shape,y.shape)","e3b5a893":"###  Instantiate\nkm = LinearRegression()\n\n###  Fit a line\nkm.fit(x,y)\n","a42fd0ad":"###  Coefficient values\n\ncoef = pd.DataFrame(x.columns)\ncoef['Coefficient'] = pd.Series(km.coef_)\ncoef\n","bf7c38d6":"col = x.columns\ncol","53a9d418":"import statsmodels.api as sm  \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score","66ff0c9d":"def stepwise_selection(x, y,\n                       initial_list=['discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price', 'MA4_listed_price', 'lag_1_gmv'],\n                       threshold_in=0.01,threshold_out = 0.05, verbose=True):\n    \n    included = list(initial_list)\n    while True:\n        changed=False\n        ### forward step\n        excluded = list(set(x.columns)-set(included))\n        new_pval = pd.Series(index=excluded)\n        for new_column in excluded:\n            model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included+[new_column]]))).fit()\n            new_pval[new_column] = model.pvalues[new_column]\n        best_pval = new_pval.min()\n        if best_pval < threshold_in:\n            best_feature = new_pval.argmin()\n            included.append(best_feature)\n            changed=True\n            if verbose:\n                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n                \n                \n        ###backward step\n        model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included]))).fit()\n        ###use all coefs except intercept\n        pvalues = model.pvalues.iloc[1:]\n        worst_pval = pvalues.max() ###null if pvalues is empty\n        if worst_pval > threshold_out:\n            changed=True\n            worst_feature = pvalues.argmax()\n            included.remove(worst_feature)\n            if verbose:\n                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n        if not changed:\n            break\n    return included\n","588727f8":"import statsmodels.api as sm  \n\nfinal_features = stepwise_selection(x, y)\n\nprint(\"\\n\",\"final_selected_features:\",final_features)","a1985ea4":"### Import statsmodels\nimport statsmodels.api as sm  \n\n### Subsetting training data for 15 selected columns\nx_rfe1 = x[final_features]\n\nx_rfe1 = sm.add_constant(x_rfe1)\n\n### Fitting the model with selected variables\nkm1 = sm.OLS(y, x_rfe1).fit() \n\nprint(km1.params)","84105923":"print(km1.summary())","db24ac7c":"### Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","ca5f38cf":"features = list(x_rfe1.columns)\nfeatures.remove('const')\nfeatures","f43ae0e4":"### Model Evaluation on testing data\nx_2 = x[features]\n\n\n### Predicition with selected features on the test data\ny_pred = km1.predict(sm.add_constant(x_2))\n","e84f3bf7":"### Mean square error (MSE)\nmse = np.mean((y_pred - y)**2)\nmse","63a83947":"### Coefficient values\n\ncoef = pd.DataFrame(x_rfe1.columns)\ncoef['Coefficient'] = pd.Series(km.coef_)\ncoef\n","b678785d":"### Using K-Fold Cross validation evaluating on whole dataset\n\n# lm = LinearRegression()\nfold = KFold(10,shuffle = True, random_state = 100)\n\ncv_scores = -cross_val_score(km,x[features],y,cv=fold,scoring='neg_mean_squared_error')\n\nprint(\"Neg. of MSE:\",cv_scores,\"\\n\")\nprint(\"Mean of 5 KFold CV - MSE:\",cv_scores.mean())","5486c0ce":"def elasticity(model,x):\n    \n    features_df = pd.DataFrame(model.params)\n    features_df = features_df.rename(columns={0:'coef'})\n    \n    features_df['imp_feature'] = model.params.index\n    features_df = features_df[features_df.imp_feature != 'const'][['imp_feature','coef']]\n    features_df.index = range(len(features_df))\n#      features\n\n    elasticity_list = list()\n    \n    for i in range(len(features_df)):\n        elasticity_list.append(((features_df.coef[i] * np.mean(x[features_df.imp_feature[i]])) \/ np.mean(x['gmv'])))\n\n    features_df['elasticity'] = np.round(elasticity_list,3)\n    \n    sns.barplot(x='elasticity',y='imp_feature',data=features_df)\n    plt.show()\n    \n    return features_df\n    ","060e8688":"elasticity(km1,home_train_km)","9c0ca45e":"# Plotting y and y_pred to understand the spread\n\nfig = plt.figure()\nplt.scatter(y, y_pred)\nfig.suptitle('y vs y_pred', fontsize = 20)              # Plot heading \nplt.xlabel('y', fontsize = 18)                          # X-label\nplt.ylabel('y_pred', fontsize = 16)  ","033c0b29":"# Figure size\nplt.figure(figsize=(8,5))\n\n# Heatmap\nsns.heatmap(home_train_km[features].corr(), cmap=\"YlGnBu\", annot=True)\nplt.show()","e1da6f40":"home_dlm = ha_week[['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price', 'MA4_listed_price','lag_1_listed_price','lag_1_discount_offer',\n       'lag_2_discount_offer','lag_3_discount_offer','lag_2_NPS','lag_3_NPS','lag_1_Stock_Index',\n       'lag_2_Stock_Index','lag_3_Stock_Index','lag_1_Special_sales','lag_2_Special_sales','lag_3_Special_sales',\n       'lag_1_Payday','lag_2_Payday','lag_3_Payday']]           \n\n\nhome_dlm.head()\n","19ec4ddf":"home_dlm['lag_1_gmv'] = home_dlm['gmv'].shift(-1)\nhome_dlm['lag_2_gmv'] = home_dlm['gmv'].shift(-2)\nhome_dlm['lag_3_gmv'] = home_dlm['gmv'].shift(-3)\n","bc14f526":"### Checking NaN\n\nhome_dlm.isnull().sum()","7585aba1":"home_dlm = home_dlm.fillna(0)","7a094d54":"home_dlm.head()","7c0f8638":"###  Import the StandardScaler()\n# from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n###  Create a scaling object\n# scaler = StandardScaler()\nscaler = MinMaxScaler()\n\n\n###  Create a list of the variables that you need to scale\nvarlist = ['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price', 'MA4_listed_price','lag_1_listed_price','lag_1_discount_offer',\n       'lag_2_discount_offer','lag_3_discount_offer','lag_2_NPS','lag_3_NPS','lag_1_Stock_Index',\n       'lag_2_Stock_Index','lag_3_Stock_Index','lag_1_Special_sales','lag_2_Special_sales','lag_3_Special_sales',\n       'lag_1_Payday','lag_2_Payday','lag_3_Payday']\n\n\n###  Scale these variables using 'fit_transform'\nhome_dlm[varlist] = scaler.fit_transform(home_dlm[varlist])","52ae11f4":"home_dlm.head()","28ab4afa":"###  Split the train dataset into X and y\nfrom sklearn.model_selection import train_test_split\nx = home_dlm.drop('gmv',axis=1)\ny = home_dlm['gmv']\n\nhome_train_dlm = home_dlm","a4d7cc11":"print(\"X = Independent variable & Y = Target variable\")\nprint(x.shape,y.shape)","e56cc878":"###  Instantiate\ndlm = LinearRegression()\n\n###  Fit a line\ndlm.fit(x,y)\n","a6fd9463":"###  Coefficient values\n\ncoef = pd.DataFrame(x.columns)\ncoef['Coefficient'] = pd.Series(dlm.coef_)\ncoef\n","7024a3e1":"col = x.columns\ncol","35384ffb":"import statsmodels.api as sm  \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score","6aa4bee4":"def stepwise_selection(x, y,\n                       initial_list=['discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price', 'MA4_listed_price','lag_1_listed_price','lag_1_discount_offer',\n       'lag_2_discount_offer','lag_3_discount_offer','lag_2_NPS','lag_3_NPS','lag_1_Stock_Index',\n       'lag_2_Stock_Index','lag_3_Stock_Index','lag_1_Special_sales','lag_2_Special_sales','lag_3_Special_sales',\n       'lag_1_Payday','lag_2_Payday','lag_3_Payday'],\n                     threshold_in=0.01,threshold_out = 0.05, verbose=True):\n    \n    included = list(initial_list)\n    while True:\n        changed=False\n        ###  forward step\n        excluded = list(set(x.columns)-set(included))\n        new_pval = pd.Series(index=excluded)\n        for new_column in excluded:\n            model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included+[new_column]]))).fit()\n            new_pval[new_column] = model.pvalues[new_column]\n        best_pval = new_pval.min()\n        if best_pval < threshold_in:\n            best_feature = new_pval.argmin()\n            included.append(best_feature)\n            changed=True\n            if verbose:\n                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n                \n                \n        ###  backward step\n        model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included]))).fit()\n        ###  use all coefs except intercept\n        pvalues = model.pvalues.iloc[1:]\n        worst_pval = pvalues.max() ###  null if pvalues is empty\n        if worst_pval > threshold_out:\n            changed=True\n            worst_feature = pvalues.argmax()\n            included.remove(worst_feature)\n            if verbose:\n                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n        if not changed:\n            break\n    return included\n","1e32e623":"import statsmodels.api as sm  \n\nfinal_features = stepwise_selection(x, y)\n\nprint(\"\\n\",\"final_selected_features:\",final_features)","7adfc10b":"###  Import statsmodels\nimport statsmodels.api as sm  \n\n###  Subsetting training data for 15 selected columns\nx_rfe1 = x[final_features]\n\nx_rfe1 = sm.add_constant(x_rfe1)\n\n###  Fitting the model with selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit() \n\nprint(dlm1.params)","88487a0b":"print(dlm1.summary())","08665ba0":"###  Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","030b5e6a":"x_rfe1.drop('sla', axis = 1, inplace = True)\n","891756a7":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","5702c692":"x_rfe1.drop('lag_1_discount_offer', axis = 1, inplace = True)","4363b454":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","60a68f5e":"x_rfe1.drop('product_procurement_sla', axis = 1, inplace = True)","874291e9":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlm1.summary())","2d0f4988":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","52acc27f":"features = list(x_rfe1.columns)\nfeatures.remove('const')\nfeatures","36a4c174":"###  Model Evaluation on testing data\nx_2 = x[features]\n\n###  Predicition with selected features on the test data\ny_pred = dlm1.predict(sm.add_constant(x_2))","8b2598c8":"###  Mean square error (MSE)\nmse = np.mean((y_pred - y)**2)\nmse\n","8f954616":"###  Coefficient values\n\ncoef = pd.DataFrame(x_rfe1.columns)\ncoef['Coefficient'] = pd.Series(dlm.coef_)\ncoef\n","ce0b762e":"###  Using K-Fold Cross validation evaluating on whole dataset\n\n# lm = LinearRegression()\nfold = KFold(10,shuffle = True, random_state = 100)\n\ncv_scores = -cross_val_score(dlm,x[features],y,cv=fold,scoring='neg_mean_squared_error')\n\nprint(\"Neg. of MSE:\",cv_scores,\"\\n\")\nprint(\"Mean of 5 KFold CV - MSE:\",cv_scores.mean())","5a7f02c6":"def elasticity(model,x):\n    \n    features_df = pd.DataFrame(model.params)\n    features_df = features_df.rename(columns={0:'coef'})\n    \n    features_df['imp_feature'] = model.params.index\n    features_df = features_df[features_df.imp_feature != 'const'][['imp_feature','coef']]\n    features_df.index = range(len(features_df))\n#      features\n\n    elasticity_list = list()\n    \n    for i in range(len(features_df)):\n        elasticity_list.append(((features_df.coef[i] * np.mean(x[features_df.imp_feature[i]])) \/ np.mean(x['gmv'])))\n\n    features_df['elasticity'] = np.round(elasticity_list,3)\n    \n    sns.barplot(x='elasticity',y='imp_feature',data=features_df)\n    plt.show()\n    \n    return features_df\n    ","4ab39325":"elasticity(dlm1,home_train_dlm)","d0648583":"# Plotting y and y_pred to understand the spread\n\nfig = plt.figure()\nplt.scatter(y, y_pred)\nfig.suptitle('y vs y_pred', fontsize = 20)              # Plot heading \nplt.xlabel('y', fontsize = 18)                          # X-label\nplt.ylabel('y_pred', fontsize = 16)  ","34dcff4c":"# Figure size\nplt.figure(figsize=(8,5))\n\n# Heatmap\nsns.heatmap(home_train_dlm[features].corr(), cmap=\"YlGnBu\", annot=True)\nplt.show()","5dc39f99":"home_dlmm = ha_week[['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price', 'MA4_listed_price','lag_1_listed_price','lag_1_discount_offer',\n       'lag_2_discount_offer','lag_3_discount_offer','lag_2_NPS','lag_3_NPS','lag_1_Stock_Index',\n       'lag_2_Stock_Index','lag_3_Stock_Index','lag_1_Special_sales','lag_2_Special_sales','lag_3_Special_sales',\n       'lag_1_Payday','lag_2_Payday','lag_3_Payday']]           \n\n\nhome_dlmm.head()\n","b3fda12d":"home_dlmm['lag_1_gmv'] = home_dlmm['gmv'].shift(-1)\nhome_dlmm['lag_2_gmv'] = home_dlmm['gmv'].shift(-2)\nhome_dlmm['lag_3_gmv'] = home_dlmm['gmv'].shift(-3)\n","fb9306c4":"### Checking NaN\n\nhome_dlmm.isnull().sum()","a2e80e3f":"home_dlmm = home_dlmm.fillna(0)","69b433c3":"### Applying Log \nhome_dlmm=np.log(home_dlmm)\n\nhome_dlmm = home_dlmm.fillna(0)\nhome_dlmm = home_dlmm.replace([np.inf, -np.inf], 0)","b5291917":"home_dlmm.head()","cd6ef52b":"###  Import the StandardScaler()\n# from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n###  Create a scaling object\n# scaler = StandardScaler()\nscaler = MinMaxScaler()\n\n\n###  Create a list of the variables that you need to scale\nvarlist = ['gmv', 'discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price', 'MA4_listed_price','lag_1_listed_price','lag_1_discount_offer',\n       'lag_2_discount_offer','lag_3_discount_offer','lag_2_NPS','lag_3_NPS','lag_1_Stock_Index',\n       'lag_2_Stock_Index','lag_3_Stock_Index','lag_1_Special_sales','lag_2_Special_sales','lag_3_Special_sales',\n       'lag_1_Payday','lag_2_Payday','lag_3_Payday']\n\n\n###  Scale these variables using 'fit_transform'\nhome_dlmm[varlist] = scaler.fit_transform(home_dlmm[varlist])","9ff8e31c":"home_dlmm.head()","09518315":"###  Split the train dataset into X and y\nfrom sklearn.model_selection import train_test_split\nx = home_dlmm.drop('gmv',axis=1)\ny = home_dlmm['gmv']\n\nhome_train_dlmm = home_dlmm","d1f2a54d":"print(\"X = Independent variable & Y = Target variable\")\nprint(x.shape,y.shape)","e0d1ed40":"###  Instantiate\ndlmm = LinearRegression()\n\n###  Fit a line\ndlmm.fit(x,y)\n","32240f28":"###  Coefficient values\n\ncoef = pd.DataFrame(x.columns)\ncoef['Coefficient'] = pd.Series(dlmm.coef_)\ncoef\n","fad7b131":"col = x.columns\ncol","7b54841d":"import statsmodels.api as sm  \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score","f6ebeae5":"def stepwise_selection(x, y,\n                       initial_list=['discount', 'sla','product_procurement_sla', 'order_payment_type',\n       'online_order_perc', 'TV_ads','Sponsorship_ads', 'Content_marketing_ads', 'Online_marketing_ads',\n       'NPS', 'Stock_Index', 'Special_sales', 'Payday', 'heat_deg_days', 'cool_deg_days', \n       'total_rain_mm', 'total_snow_cm','snow_on_grnd_cm', 'MA2_listed_price', 'MA4_listed_price','lag_1_listed_price','lag_1_discount_offer',\n       'lag_2_discount_offer','lag_3_discount_offer','lag_2_NPS','lag_3_NPS','lag_1_Stock_Index',\n       'lag_2_Stock_Index','lag_3_Stock_Index','lag_1_Special_sales','lag_2_Special_sales','lag_3_Special_sales',\n       'lag_1_Payday','lag_2_Payday','lag_3_Payday'],\n                     threshold_in=0.01,threshold_out = 0.05, verbose=True):\n    \n    included = list(initial_list)\n    while True:\n        changed=False\n        ###  forward step\n        excluded = list(set(x.columns)-set(included))\n        new_pval = pd.Series(index=excluded)\n        for new_column in excluded:\n            model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included+[new_column]]))).fit()\n            new_pval[new_column] = model.pvalues[new_column]\n        best_pval = new_pval.min()\n        if best_pval < threshold_in:\n            best_feature = new_pval.argmin()\n            included.append(best_feature)\n            changed=True\n            if verbose:\n                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n                \n                \n        ###  backward step\n        model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included]))).fit()\n        ###  use all coefs except intercept\n        pvalues = model.pvalues.iloc[1:]\n        worst_pval = pvalues.max() ###  null if pvalues is empty\n        if worst_pval > threshold_out:\n            changed=True\n            worst_feature = pvalues.argmax()\n            included.remove(worst_feature)\n            if verbose:\n                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n        if not changed:\n            break\n    return included\n","1edecb6c":"import statsmodels.api as sm  \n\nfinal_features = stepwise_selection(x, y)\n\nprint(\"\\n\",\"final_selected_features:\",final_features)","591fbf4e":"###  Import statsmodels\nimport statsmodels.api as sm  \n\n###  Subsetting training data for 15 selected columns\nx_rfe1 = x[final_features]\n\nx_rfe1 = sm.add_constant(x_rfe1)\n\n###  Fitting the model with selected variables\ndlmm1 = sm.OLS(y, x_rfe1).fit() \n\nprint(dlmm1.params)","adbab8a8":"print(dlmm1.summary())","be38a059":"###  Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","3e3735ce":"x_rfe1.drop('lag_2_Stock_Index', axis = 1, inplace = True)\n","c7763e01":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlmm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlmm1.summary())","3af60e54":"x_rfe1.drop('lag_2_NPS', axis = 1, inplace = True)","62b73731":"# Refitting with final selected variables\nx_rfe1 = sm.add_constant(x_rfe1)\n\n# Fitting the model with final selected variables\ndlmm1 = sm.OLS(y, x_rfe1).fit()   \nprint(dlmm1.summary())","dd0db4e7":"###  Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\n\nvif['Features'] = x_rfe1.columns\nvif['VIF'] = [variance_inflation_factor(x_rfe1.values, i) for i in range(x_rfe1.shape[1])]\n\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","ae38a469":"features = list(x_rfe1.columns)\nfeatures.remove('const')\nfeatures","0e0345a1":"###  Model Evaluation on testing data\nx_2 = x[features]\n\n###  Predicition with selected features on the test data\ny_pred = dlmm1.predict(sm.add_constant(x_2))","383bceea":"###  Mean square error (MSE)\nmse = np.mean((y_pred - y)**2)\nmse\n","1fdbd0cf":"###  Coefficient values\n\ncoef = pd.DataFrame(x_rfe1.columns)\ncoef['Coefficient'] = pd.Series(dlmm.coef_)\ncoef\n","9efa4f76":"###  Using K-Fold Cross validation evaluating on whole dataset\n\n# lm = LinearRegression()\nfold = KFold(10,shuffle = True, random_state = 100)\n\ncv_scores = -cross_val_score(dlm,x[features],y,cv=fold,scoring='neg_mean_squared_error')\n\nprint(\"Neg. of MSE:\",cv_scores,\"\\n\")\nprint(\"Mean of 5 KFold CV - MSE:\",cv_scores.mean())","a35558fa":"def elasticity(model,x):\n    \n    features_df = pd.DataFrame(model.params)\n    features_df = features_df.rename(columns={0:'coef'})\n    \n    features_df['imp_feature'] = model.params.index\n    features_df = features_df[features_df.imp_feature != 'const'][['imp_feature','coef']]\n    features_df.index = range(len(features_df))\n#      features\n\n    elasticity_list = list()\n    \n    for i in range(len(features_df)):\n        elasticity_list.append(((features_df.coef[i] * np.mean(x[features_df.imp_feature[i]])) \/ np.mean(x['gmv'])))\n\n    features_df['elasticity'] = np.round(elasticity_list,3)\n    \n    sns.barplot(x='elasticity',y='imp_feature',data=features_df)\n    plt.show()\n    \n    return features_df\n    ","17493a0f":"elasticity(dlmm1,home_train_dlm)","6eb524ae":"# Plotting y and y_pred to understand the spread\n\nfig = plt.figure()\nplt.scatter(y, y_pred)\nfig.suptitle('y vs y_pred', fontsize = 20)              # Plot heading \nplt.xlabel('y', fontsize = 18)                          # X-label\nplt.ylabel('y_pred', fontsize = 16)  ","55530808":"# Figure size\nplt.figure(figsize=(8,5))\n\n# Heatmap\nsns.heatmap(home_train_dlm[features].corr(), cmap=\"YlGnBu\", annot=True)\nplt.show()","b6188b2a":"#### Adstock","4341e679":"#### Gaming Accessory - Moving Average","9d04d6fb":"### Distributed + Multiplicated Model","842ad86d":"### Distributed Lag Model","052b0ebd":"#### Model Building - Stepwise selection for feature selection","cd2326a0":"#### MODEL 4","ee627b1b":"#### Listed Price","535e29dd":"#### 5. s1_fact.order_payment_type","a9028d01":"#### Heatmap to see multicollinearity","43034ecb":"### Exploratory Data Analysis","86ef6b55":"Marketing KPI","e7e4e5cc":"### Seasonality and Trend related KPI","d8534246":"## 3. Home Audio Sub Category","49c0ac55":"# 5. Modeling - Camera Accessory","ae4807e4":"#### MODEL 1","4daf7537":"#### Model Building - Stepwise selection for feature selection","610cfdd2":"#### Model Building - Stepwise selection for feature selection","7e1c64b7":"Marketing KPI","68c4d958":"### Exploratory Data Analysis","34e8ff63":"### Distributed + Multiplicative Lag Model","b871ef48":"#### MODEL 7","7c03b97a":"### Pricing KPI","6343e765":"#### 8. sla and product_procurement_sla","0b9d2631":"#### Duplicates removal","2c8f9c77":"### Mapping KPI on Calendar","fd8ba9d1":"#### Total Price","c38a0342":"#### MODEL 8","b3481fa5":"#### Model Building - Stepwise selection for feature selection","6ed14888":"GMV and Dicount weekly","448fe2b2":"#### Climate Data","b2a654eb":"#### Model Building - Stepwise selection for feature selection","50baac85":"#### Residual Analysis of Model","d1bcc068":"### 2. Multiplicative Model","805a8a13":"#### Dicount","0e48ccfe":"#### Home Audio - Moving Average","16be0fed":"#### Mapping marketing and adstock","a7da05c8":"- There are no null values in the dataset!\n- Columns like order_date, gmv, deliverybdays, deliverycdays, pincode have incorrect data types and need to be changed.","e48e4dbf":"### Kyock Model","aa70e003":"#### Model Building - Stepwise selection for feature selection","d965812a":"#### 7. product_mrp","91d02e64":"# 7. Modeling - Home Audio","8f5d773a":"### 1. Linear Model","04e39060":"### Advertisement Related KPI","b9d9c30d":"Marketing KPI","51e9c6a9":"#### Special Sale","59f9627b":"# 4. Aggregation","138bbe05":"GMV and Holiday weekly","734f84b2":"#### Model Building - Stepwise selection for feature selection","d1d6249c":"#### Evaluation of test via comparison of y_pred and y_test","e1997a36":"#### Model Building - Stepwise selection for feature selection","3298a297":"#### MODEL 6","ee5e9f97":"Target Variable","dff1bb6a":"#### Building model using statsmodel, for the detailed statistics","1901f834":"#### Model Building - Stepwise selection for feature selection","8ba6c2d5":"#### Gaming Accessory - Lag Variable Functions","b2405361":"Error terms seem to be approximately normally distributed, so the assumption on the linear modeling seems to be fulfilled.","105fa84b":"#### Payment type","1851e1a6":"gmv (Gross Merchendising Value - The cost price at which the item is sold multiplied by number of units) - Value at 0.0 seems odd. \n\nAssumption : It could be because of any promotional offers, hence not deleting them\n","1d0fdbc8":"#### Univariate Analysis","683c15c9":"## 1. Camera Sub Category","cbf59f25":"GMV and Holiday weekly","f9164472":"#### Camera Accessory -  Lag Variable Functions","2de7af0a":"#### Camera Accessory - Moving Average","c4400ea1":"### Product assortment and quality related KPI","3283dd0d":"#### Univariate Analysis","d6cdec94":"### 3. Kyock Model","76eb8cd7":"#### Home Audio - Lag Variable Functions","74bfe0f4":"Target Variable","aa9146d1":"#### 6. pincode, custid","1f690411":"#### Bivariate Analysis","a90e1c76":"# 6. Modeling - Gaming Accessory","862dc9b2":"#### Model Building - Stepwise selection for feature selection","fb1ccdb9":"# 2. Data Cleaning And Preparation","97a422d7":"### Linear Model","1b9df470":"#### 2. gmv","a347c34d":"#### Univariate Analysis","38ebe7bc":"### Linear Model","6fa8d0fd":"### 5. Distributed Lag + Multiplicative Model","7561ecd5":"#### MODEL 5","127cc71c":"- Clearly, Teleconverter, SoundMixer, SlingBox, MotionController, KaraokePlayer, DJController are premium products. All other products are mass products.\n- Let's visualise how the premium products contribute towards the GMV.","a8c77786":"### Kyock Model","d99c01f0":"#### MODEL 2","cbdf61cd":"#### 4. order_date","6a5a6a15":"#### Bivariate Analysis","7b8b2fab":"GMV and Holiday weekly","e8b59d5c":"GMV and Holiday weekly","98b0948d":"#### Heatmap to see multicollinearity","c62e6455":"#### Model Building - Stepwise selection for feature selection","b98f193e":"#### Model Building - Stepwise selection for feature selection","9d18b2fd":"ElecKart is an e-commerce firm based out of Ontario, Canada specialising in electronic products. Over the last one year, they had spent a significant amount of money on marketing. Occasionally, they had also offered big-ticket promotions (similar to the Big Billion Day). They are about to create a marketing budget for the next year, which includes spending on commercials, online campaigns, and pricing & promotion strategies. The CFO feels that the money spent over the last 12 months on marketing was not sufficiently impactful, and, that they can either cut on the budget or reallocate it optimally across marketing levers to improve the revenue response.\n\n \n\nImagine that you are a part of the marketing team working on budget optimisation. You need to develop a market mix model to observe the actual impact of different marketing variables over the last year. Using your understanding of the model, you have to recommend the optimal budget allocation for different marketing levers for the next year.","d901185f":"Looks like a duplicated order. Let's check for duplicates","94e13d81":"#### Payday","e0a37587":"### 1.1 Linear Model - Stepwise Selection for feature selection","6ab9c145":"#### Model Building - Stepwise selection for feature selection","ad38ab46":"- All the numeric columns are almost normally distributed!\n- We need to cap the SLAs to max and min values.","3afe448b":"#### Bivariate Analysis","f8b0b3da":"### Discount and Promotion related KPI","30372504":"- We can clearly see that, maximum revenue is generated through mass producs like HomeAudioSpeaker, Lens, GamingPad, etc and not premium products that contibute quite less towards revenue.\n- The company hence should focus more on mass products than premium products.","bd40aafa":"### Distributed Lag Model","6b2f0c01":"### 4. Distributed Lag Model","46f2b5b0":"### Multiplicative Model","aaa55ae3":"## 2. Gaming Sub Category","3723c105":"#### 3. deliverybdays and deliverycdays","4a99d24d":"#### Evaluation of the model using Statistics","53a5307c":"- Clearly, there can't be two orders with the same combination of order id and order item id that were ordered at the same timestamp.\n- We can hence, drop the duplicates.","0a510c1d":"# 3. Feature Engineering and KPI","874e7999":"#### Calendar","ef230d82":"- There is only one value for this column. Hence, we can remove the column.","1d695b05":"Target Variable","8bd50762":"#### Model Building - Stepwise selection for feature selection","752653ec":"Clearly COD is preferred more than Prepaid order payment type.","32740fe8":"#### Net Promoters Score & Stock_Index","bfcfcf0d":"#### Model Building - Stepwise selection for feature selection","5ed54e14":"#### 1. product_analytic_super_category, product_analytic_category, product_analytic_sub_category, product_analytic_vertical","e7a242c9":"#### Marketing ","ec906c4c":"### Mapping Week into the Data","66c343ea":"### Multiplicative Model","11511ad3":"- There is 608 records that lie outside the range. Let's delete those rows.","518926bf":"#### Camera Accessory - Data Profiling to see multicollinearity and variable distributions","f91026d0":"### Other KPI","a781f6cb":"#### Prediction and Evaluation","8e2287f6":"GMV and discount weekly","3f50a568":"### Exploratory Data Analysis","7cb201e9":"# 1. Data Reading And Understanding","efcb324d":"### Product premium-ness","291b4be4":"#### MODEL 3","b68bdae0":"# Problem Statement"}}