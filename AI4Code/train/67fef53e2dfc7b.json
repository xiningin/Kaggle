{"cell_type":{"81e5932a":"code","e9ef2e88":"code","5aba7bb9":"code","1bcffff1":"code","ba2e78d0":"code","c46e52ae":"code","025a30f3":"code","7bbc2654":"code","0c200926":"code","9884233a":"code","9711184f":"code","4c0a4506":"code","28da0c7b":"code","39e98083":"code","19f1f016":"code","0b61f760":"code","133b7cea":"code","c350f6e5":"code","2d26b622":"code","36e1f515":"code","d82a96dc":"code","e36276ce":"code","6ecad0c3":"code","545edefa":"code","331cabc8":"code","5cf57ad6":"code","630c779b":"code","ba00841d":"code","0ab1282a":"code","ae05def6":"code","7e17d9dd":"code","ef253bed":"code","9532754b":"code","577015ae":"code","d5e88547":"code","e6e101fc":"code","d8718a3e":"code","330ddf11":"code","00e0b78d":"code","6531f55b":"markdown","24bc4538":"markdown","e1c69d1a":"markdown","e2dfd498":"markdown","dcfb9791":"markdown","d8393259":"markdown","33f3258a":"markdown","abbfdcc7":"markdown","dcd5cdff":"markdown","52a97eb1":"markdown","5de29f9a":"markdown","3b2e2ef1":"markdown","d402a74a":"markdown","608344f4":"markdown","22c42a04":"markdown","b451f79c":"markdown","632b6c59":"markdown","75d424c6":"markdown","04b8ee6e":"markdown","3a72cf9b":"markdown"},"source":{"81e5932a":"# Importing Libraries\nimport torch                       # pytorch\nimport torch.nn as nn              # pytorch for neural network\nimport numpy as np                 # for algebric functions\nimport matplotlib.pyplot as plt    # to plot graph\n\n# torch vision package\nimport torchvision                 # for handling image & has CNN architecture","e9ef2e88":"trainset = torchvision.datasets.CIFAR10(train=True,download=True,root= \".\/data\",\n                                     transform= torchvision.transforms.ToTensor())\n#transform --> transform the data during creation (ToTensor())\n#download  --> to download to local file\n#root      --> data storage place\n#train     --> means training data from training set \ntype(trainset)","5aba7bb9":"#class labels [there are 10 lables]\n#this is the order of lable of this dataset\nclasses = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship',' truck' )","1bcffff1":"#loading the dataset --> DataLoader class (torch.utils.data.DataLoader)\ntrainloader = torch.utils.data.DataLoader(trainset)\ntype(trainloader)","ba2e78d0":"data_iter = iter(trainloader)\ntype(data_iter)","c46e52ae":"#Access the data --> next() method\nimages,labels = data_iter.next()\nprint(images.shape)","025a30f3":"print(labels)\nprint(labels.item())\nprint(classes[labels.item()])","7bbc2654":"#Specifying batch_size, Shuffle & load data in paralell using multiprocessing workers\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size = 4, shuffle = True)\n\ndata_iter = iter(trainloader)\nimages,labels = data_iter.next()","0c200926":"print(images.shape)","9884233a":"print(labels)\nprint([i.item() for i in labels])\nprint([classes[i.item()] for i in labels])","9711184f":"img_data = images[0]\nimg_data.shape","4c0a4506":"# tensor image shape format must be like [32,32,3] not like [3,32,32]. so we need to convert it.\n#we can't do this in tensor. so, we are going to use numpy\n\nnp_image = img_data.numpy()                      #converting tensor --> numpy\nnp_image = np.transpose(np_image, (1,2,0))         #transform\nprint(np_image.shape)","28da0c7b":"#plotting the image\nplt.figure(figsize = (2,2))\nplt.imshow(np_image)\nprint(classes[labels[0].item()])\nplt.show()","39e98083":"# creating function to view image\ndef image_show(image_data):\n  np_image = image_data.numpy()\n  np_image = np.transpose(np_image, (1,2,0))\n  plt.figure(figsize = (2,2))\n  plt.imshow(np_image)\n  plt.show()","19f1f016":"print(classes[labels[2].item()])\nimage_show(images[2])","0b61f760":"class FirstNN(nn.Module):\n  def __init__(self):\n    super(FirstNN,self).__init__()\n    self.conv1 = nn.Conv2d(3,10,3)  #(no. of input channels, number of output channels, kernel size)\n    # kernel size --> 3 = (3,3)\n\n  def forward(self,x):\n    return self.conv1(x)","133b7cea":"cnn = FirstNN()\nout = cnn(images)\nprint(out.shape)","c350f6e5":"#image after convolution\nsample = out[0,0,:,:]\nprint(sample.shape)\nplt.figure(figsize = (2,2))\nplt.imshow(sample.detach().numpy())\nplt.show()","2d26b622":"#2nd filter\nsample = out[0,1,:,:]\nplt.figure(figsize = (2,2))\nplt.imshow(sample.detach().numpy())\nplt.show()","36e1f515":"#Padding & Stride\n#By Default: Padding = (0,0) & Stride = (1,1)\n\nclass FirstCNN(nn.Module):\n  def __init__(self):\n    super(FirstCNN,self).__init__()\n    self.conv1 = nn.Conv2d(3,10,3, padding = (1,1) )  # Padding = 1,1\n    # kernel size --> 3 = (3,3)\n  \n  def forward(self,x):\n    y = self.conv1(x)\n    return y","d82a96dc":"cnn = FirstNN()\nout = cnn(images)\nprint(out.shape)","e36276ce":"#Stride = 1\n\nclass FirstCNN(nn.Module):\n    def __init__(self):\n        super(FirstCNN,self).__init__()\n        self.conv1 = nn.Conv2d(3,10,3, padding = (1,1), stride = (1,1) )  # Stride = 1,1\n        # kernel size --> 3 = (3,3)\n\n    def forward(self,x):\n        y = self.conv1(x)\n        return y\n\n  \ncnn = FirstCNN()\nout = cnn(images)\nout.shape","6ecad0c3":"#Stride = 2\n\nclass FirstCNN(nn.Module):\n    def __init__(self):\n        super(FirstCNN,self).__init__()\n        self.conv1 = nn.Conv2d(3,10,3, padding = (1,1), stride = (2,2) )  # Stride = 2,2\n        # kernel size --> 3 = (3,3)\n\n    def forward(self,x):\n        y = self.conv1(x)\n        return y\n\n  \ncnn = FirstCNN()\nout = cnn(images)\nout.shape","545edefa":"#Stride = 2 without padding\n\nclass FirstCNN(nn.Module):\n    def __init__(self):\n        super(FirstCNN,self).__init__()\n        self.conv1 = nn.Conv2d(3,10,3, stride = (2,2) )  # Stride = 2,2\n        # kernel size --> 3 = (3,3)\n\n    def forward(self,x):\n        y = self.conv1(x)\n        return y\n\n  \ncnn = FirstCNN()\nout = cnn(images)\nout.shape","331cabc8":"class DeepCNN(nn.Module):\n  def __init__(self):\n    super(DeepCNN,self).__init__()\n    self.model = nn.Sequential(nn.Conv2d(3,10,3),\n                               nn.Conv2d(10,5,3))\n  def forward(self,x):\n    return self.model(x)","5cf57ad6":"deep = DeepCNN()\nout = deep(images)\nprint(out.shape)\n\nsample = out[0,1,:,:]\nplt.figure(figsize = (2,2))\nplt.imshow(sample.detach().numpy())\nplt.show()","630c779b":"#Mean Pool or Avg pool\nclass avg_pool(nn.Module):\n    def __init__(self):\n        super(avg_pool,self).__init__()\n        self.model = nn.Sequential(nn.Conv2d(3,10,3),\n                                  nn.Conv2d(10,5,3),\n                                  nn.AvgPool2d(2, stride = 2)) # Kernel size, Stride\n        #Stride = 2 --> (2,2)\n\n    def forward(self,x):\n        y = self.model(x)\n        return y","ba00841d":"avg = avg_pool()\nout = avg(images)\nprint(out.shape)\n\nsample = out[0,1,:,:]\nplt.figure(figsize = (2,2))\nplt.imshow(sample.detach().numpy())\nplt.show()","0ab1282a":"#Max Pool\nclass max_pool(nn.Module):\n    def __init__(self):\n        super(max_pool,self).__init__()\n        self.model = nn.Sequential(nn.Conv2d(3,10,3),\n                                  nn.Conv2d(10,5,3),\n                                  nn.MaxPool2d(2, stride = 2)) # Kernel size, Stride\n        #Stride = 2 --> (2,2)\n\n    def forward(self,x):\n        y = self.model(x)\n        return y","ae05def6":"max_p = max_pool()\nout = max_p(images)\nprint(out.shape)\n\nsample = out[0,1,:,:]\nplt.figure(figsize = (2,2))\nplt.imshow(sample.detach().numpy())\nplt.show()","7e17d9dd":"class LeNET(nn.Module):\n    def __init__(self):\n        super(LeNET,self).__init__()\n        self.conv_model = nn.Sequential(nn.Conv2d(in_channels=3,out_channels=6,kernel_size=5),   # (N,3,32,32) --> (N,6,28,28) \n                                        nn.Tanh(),                                               # TanH --> Activation Function\n                                        nn.AvgPool2d(kernel_size=2,stride=2),                    # (N,6,28,28) --> (N,6,14,14)\n                                        nn.Conv2d(6,16,5),nn.Tanh(),                             # (N,6,14,14) --> (N,16,10,10)\n                                        nn.AvgPool2d(2,stride=2))                                # (N,16,10,10) --> (N,16,5,5)\n\n        #Dense Layer\n        self.dense_layer = nn.Sequential(nn.Linear(in_features=400,out_features=120),           #16*5*5 = 400 as input\n                                         nn.Tanh(),\n                                         nn.Linear(120,84),\n                                         nn.Tanh(),\n                                     nn.Linear(84,10))\n    def forward(self,x):\n        y = self.conv_model(x)\n        #flatten the result from Conv model\n        y = torch.flatten(y,1) # 1 --> dimension (N,16,5,5)\n        y = self.dense_layer(y)\n        return y","ef253bed":"#understanding of torch.flattern\nx = torch.randn(6,50,50)\nprint(\"Starts from index 0  :\",torch.flatten(x).shape)\nprint(\"Starts from index 1  :\",torch.flatten(x,1).shape)\nprint(\"Starts from index 2  :\",torch.flatten(x,2).shape)","9532754b":"batch = 4\ntrainset = torchvision.datasets.CIFAR10(root = '.\/data', train = True, download = True, transform = torchvision.transforms.ToTensor())\ntrainloader1 = torch.utils.data.DataLoader(trainset, batch_size = batch, shuffle = True)\ndata_iter = iter(trainloader1)\nimages,labels = data_iter.next()\nprint(\"Shape of input  :\",images.shape)\nnet = LeNET() \nout = net(images)\nprint(\"Shape of Output :\",out.shape)","577015ae":"# max value\nprint(torch.max(out))\n# max value across each dimension, parameter --> 1\nprint(torch.max(out,dim=1))\nmax_val, preds = torch.max(out,dim=1)","d5e88547":"print(preds)\nprint(labels)\n(preds==labels).sum().item()","e6e101fc":"#define batch size\nbatch = 256\n\n#create new train & test data with new batch size\ntrainset = torchvision.datasets.CIFAR10(root = '.\/data', train = True, download = True, transform = torchvision.transforms.ToTensor())\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size = batch, shuffle = True)\n\ntestset = torchvision.datasets.CIFAR10(root = '.\/data', train = False, download = True, transform = torchvision.transforms.ToTensor())\ntestloader = torch.utils.data.DataLoader(testset, batch_size = batch, shuffle = False)\n#Setting the testloader with shuffle as False to measure test accuracy","d8718a3e":"net = LeNET() \n# defining Loss function\nloss_func = nn.CrossEntropyLoss()\n# defining optimizer\noptimizer = torch.optim.Adam(net.parameters()) ","330ddf11":"def model_eval(dataloader):\n    total = 0\n    correct = 0\n      for data in dataloader:\n        images, lables = data\n        out = net(images)\n        max_val, preds = torch.max(out,dim=1)\n        #accuracy = (correctly predicted class \/ total testing class) \u00d7 100%\n        total += lables.shape[0]                   # class value \n        correct += (preds == lables).sum().item()  # to summ correct in the batch then sum all of it\n        accuracy = (100 * correct)\/total\n  \n  return accuracy ","00e0b78d":"epoch = 25\n\nfor i in range(epoch):\n\n      for data in trainloader:\n        image_data , labels = data\n        optimizer.zero_grad() \n        out = net(image_data) #image_data --> input data\n\n    train_acc = model_eval(trainloader) \n    test_acc  = model_eval(testloader)\n\n  print(\"Epoch :\",i,\" Test Accuracy : \",test_acc,\" Train Accuracy : \",train_acc)","6531f55b":"### Intuition of Convolution:\n\nInput = 4,3,32,32\n\n    1st Convolution Layer --> Kernel = 3,3 & output channels = 10\n\n    Default padding = 0, Stride = 1\n\n    output, as a Result of 1st Convolution : 4,10,30,30\n\n---\n\n    2nd Convolution Layer --> Kernel = (3,3) & output channels = 5\n\n    Default padding = 0, Stride = 1\n\n    output, as a Result of 2nd Convolution :  4,5,28,28","24bc4538":"Shape is reduced into half","e1c69d1a":"# CNN with Tensor","e2dfd498":"# First Convolution Layer","dcfb9791":"# PyTorch\nPyTorch is the premier open-source deep learning framework developed and maintained by Facebook.\n\nAt its core, PyTorch is a mathematical library that allows you to perform efficient computation and automatic differentiation on graph-based models. Achieving this directly is challenging, although thankfully, the modern PyTorch API provides classes and idioms that allow you to easily develop a suite of deep learning models.\n\n1. [PyTorch Tutorial - 1 (Basic)](https:\/\/www.kaggle.com\/anandsubbu007\/pytorch-basics-tutorial-1)\n2. [PyTorch Tutorial - 2 (Autograd)](https:\/\/www.kaggle.com\/anandsubbu007\/pytorch-autograd-tutorial-2)\n3. [PyTorch Tutorial - 3 (Deep Neural Network)](https:\/\/www.kaggle.com\/anandsubbu007\/deep-nn-pytorch-tutorial-3)\n4. [PyTorch Tutorial - 3 (CNN-CIFAR10)](https:\/\/www.kaggle.com\/anandsubbu007\/cnn-cifar10-pytorch-tutorial-4)","d8393259":"## Sample ","33f3258a":"(4,3,32,32) -->\n\n4 - Batch Size(no. of images loaded), \n\n3 - channels in input,\n\n32,32 - shape of individual image ","abbfdcc7":"Shape is reduced to 30,30 from 32,32","dcd5cdff":"# Downloading data ","52a97eb1":"(1,3,32,32)\n\n1 - Batch Size, \n\n3 - channels in input,\n\n32,32 - shape of individual image ","5de29f9a":"## DataLoader","3b2e2ef1":"### With & without Padding & stride","d402a74a":"# Data Visualization","608344f4":"# Deep Convolution Networks","22c42a04":"## Complete LeNet","b451f79c":"No change in shape","632b6c59":"(4,10,30,30) \n\n    4             --> number of images (batch size)\n\n    10            --> Channels in output\n\n    (30,30)       --> Resultant image Size\n\n    **Default:**\n    Padding = (0,0), Stride  = (1,1)\n","75d424c6":"## Importing Data","04b8ee6e":"## CNN Layer\n\n[N,3,32,32]  N --> Batch Size\n\n      (N,3,32,32)    -->   (N,6,28,28)   -->   (N,6,14,14)   -->   (N,16,10,10)  -->  (N,16,5,5)\n     1st Conv Layer         Avg. Pool         2nd Conv Layer         Avg. Pool        Dense Layer\n      \n      kernel = 5           kernel = 2          kernel = 5          kernel = 2\n      stride = 1           stride = 2                              stride = 2\n\nResult of flattening --> (N,16*5*5) = (N,400) # N refers to number of images loaded in a batch\n\nDense Layer 1: 120 Neurons\n\nDense Layer 2: 84 Neurons\n\nDense Layer 3: 10 Neurons","3a72cf9b":"<a href=\"https:\/\/colab.research.google.com\/github\/anandsubbu007\/Pytorch-Tutorial-Beginner\/blob\/master\/4.CNN_CIFAR10_Part-1.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>"}}