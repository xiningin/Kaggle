{"cell_type":{"e7002ad4":"code","8a6643fe":"code","9b5a252f":"code","f1bb3722":"code","c081aa17":"code","8c986715":"code","173c6929":"code","d2d793cb":"code","8ec63622":"code","709b4fac":"code","e75643d2":"code","52ed9390":"markdown"},"source":{"e7002ad4":"import numpy as np\nimport matplotlib.pyplot as plt\nimport random\nimport os\nimport time\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nimport numpy as np \nimport pandas as pd","8a6643fe":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim","9b5a252f":"def get_classes():\n    return sorted(os.listdir('..\/input\/fruits-360_dataset\/fruits-360\/Training'))\n    \nclasses = get_classes()\nprint(classes)\n","f1bb3722":"img_size = 100\nimg_sc = int(((img_size-2)\/4)-1)","c081aa17":"class Conv(nn.Module):\n    def __init__(self, layer1_neurons, layer2_neurons):\n        super(Conv, self).__init__()\n        \n        self.layer1_neurons = layer1_neurons\n        self.layer2_neurons = layer2_neurons\n        \n        self.pool = nn.MaxPool2d(2, 2)\n        \n        self.img_sc_param = (img_sc**2)*20\n        \n        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 100, kernel_size = 3)\n        self.conv2 = nn.Conv2d(in_channels = 100, out_channels = 20, kernel_size = 3)\n        \n        self.lin1 = nn.Linear(self.img_sc_param, self.layer1_neurons)\n        self.lin2 = nn.Linear(self.layer1_neurons, self.layer2_neurons)\n        self.lin3 = nn.Linear(self.layer2_neurons, 118)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = F.relu(x)\n        x = self.pool(x)\n\n        x = self.conv2(x)\n        x = F.relu(x)\n        x = self.pool(x)\n        \n        x = x.view(-1, self.img_sc_param)\n        \n        x = self.lin1(x)\n        x = F.relu(x)\n        \n        x = self.lin2(x)\n        x = F.relu(x)\n        \n        x = self.lin3(x)\n        \n        return x\n\ndef train(conv, loader, epochs):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(conv.parameters(), lr = 0.01, momentum = 0.9)\n    \n    for epoch in range(epochs):\n        r_loss = 0.0\n        for i, data in enumerate(loader, 0):\n            inputs, labels = data\n\n            optimizer.zero_grad()\n\n            outputs = conv(inputs.cuda())\n            loss = criterion(outputs, labels.cuda())\n            loss.backward()\n            optimizer.step()\n\n            r_loss += loss.item()\n            \n            every_n = 700\n            if i % every_n == every_n - 1:\n                print('[%d, %5d] loss: %.3f' %\n                      (epoch + 1, i + 1, r_loss \/ every_n))\n                r_loss = 0.0\n\ndef test(conv, test_loader):\n    #print(len(test_loader))\n    dataiter = iter(test_loader)\n    classes = get_classes()\n    \n    #print(len(dataiter))\n    \n    for i in range(10000):\n        images, labels = dataiter.next()\n        #print(labels)\n        if i % 1000==0:\n            outputs = conv(images.cuda())\n            _, predicteds = torch.max(outputs, 1)\n            predicted = classes[predicteds[0]]\n            groundtruth = classes[labels[0]]\n            \n            #print(i,\"-\",predicteds[0])\n            print(i)\n            print(\"Prediction: {}\".format(predicted))\n            print(\"Real: {}\".format(groundtruth))\n        \n\ndef get_predictions(conv, data_loader):\n    y_true = []\n    y_pred = []\n    \n    for data in data_loader:\n        images, labels = data\n        images = images.cuda()\n        labels = labels.cuda()\n        \n        outputs = conv(images)\n        _, predicted = torch.max(outputs.data, 1)\n        y_true += labels.tolist()\n        y_pred += predicted.tolist()\n    \n    return [y_true, y_pred]\n\n\ndef validate(conv, test_loader):\n    y_true, y_pred = get_predictions(conv, test_loader)\n    \n    correct = (np.array(y_true) == np.array(y_pred)).sum()\n    total = len(y_true)\n    validation = correct \/ total\n    \n    return validation\n\ndef get_metrics(conv, test_loader):\n    y_true, y_pred = get_predictions(conv, test_loader)\n    \n    classes = get_classes()\n\n    y_true = [classes[a] for a in y_true]\n    y_pred = [classes[a] for a in y_pred]\n    \n    classification = classification_report(y_true, y_pred, labels = classes, target_names = classes)\n    \n    confusion = confusion_matrix(y_true, y_pred, labels = classes)\n    \n    return [classification, confusion]\n","8c986715":"conv = Conv(3000, 300)\n\nconv.cuda()","173c6929":"transform = transforms.Compose([\n    transforms.Resize(size = (img_size, img_size)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=(0,0,0), std=(1,1,1))\n])\n\ntrain_data = torchvision.datasets.ImageFolder('..\/input\/fruits-360_dataset\/fruits-360\/Training', transform = transform)\ntest_data = torchvision.datasets.ImageFolder('..\/input\/fruits-360_dataset\/fruits-360\/Test', transform = transform)","d2d793cb":"train_data_split, validation_data_split = torch.utils.data.random_split(train_data, [int(len(train_data)*0.4), len(train_data)-int(len(train_data)*0.4)])\n\ntrain_loader = torch.utils.data.DataLoader(train_data_split, 10, shuffle=True, num_workers = 2)\nvalidation_loader = torch.utils.data.DataLoader(validation_data_split, 1, shuffle=True, num_workers = 2)\ntest_loader = torch.utils.data.DataLoader(test_data, 1, shuffle=True, num_workers = 2)\n","8ec63622":"print(\"Train\")\ntrain(conv, train_loader, 5)\n\nprint('Validation')\nconv_validation = validate(conv, validation_loader)\n\nprint('Validation score')\nprint(conv_validation)","709b4fac":"print(\"Test\")\ntest(conv, test_loader)","e75643d2":"classification, confusion = get_metrics(conv, test_loader)\nprint()\nprint('classification report:')\nprint(classification)\n\nprint()\nprint('confusion report:')\nprint(confusion)","52ed9390":"**\u041f\u043e\u0434\u0433\u043e\u0442\u0430\u0432\u043b\u0438\u0432\u0430\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435**"}}