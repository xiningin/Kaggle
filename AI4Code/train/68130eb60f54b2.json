{"cell_type":{"f0b96378":"code","047ba633":"code","82505094":"code","adf8bac8":"code","8cf536b7":"code","f06f4b21":"code","fe8e5a92":"code","0ac1c31c":"code","b45331e8":"code","9c3d7829":"code","ef3353d7":"code","14ac0f3f":"code","e6931e9e":"code","afdb85a0":"code","1e00b06b":"code","0fb250ad":"code","788774d9":"code","518fb602":"code","a97fc3f1":"code","05a071dc":"code","57a40dea":"code","6662eaf6":"code","1775d071":"code","06b1f3c4":"markdown","6e887f77":"markdown","6437530f":"markdown","0a8f8e24":"markdown","1d45d4bc":"markdown","7ddf7445":"markdown","0e0111c4":"markdown","f5ff4536":"markdown","de35cd5e":"markdown","38547c58":"markdown","c76e8a8e":"markdown","eb1c86ac":"markdown","7d0e28aa":"markdown","7e4edbfa":"markdown","29f844a6":"markdown","e4062fd1":"markdown","8a6e042f":"markdown","83e3f74e":"markdown","34910326":"markdown"},"source":{"f0b96378":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","047ba633":"import pandas, numpy\nimport matplotlib.pyplot as plt\nimport seaborn as sn\n%matplotlib inline","82505094":"df = pd.read_csv(\"..\/input\/employees-evaluation-for-promotion\/employee_promotion.csv\")\ndf.head(20)","adf8bac8":"#finding na values\nprint(df.isna().sum())","8cf536b7":"df[\"education\"].fillna(\"no_degree\", inplace=True)","f06f4b21":"df[\"previous_year_rating\"].fillna(df[\"previous_year_rating\"].median(), inplace=True)\ndf[\"avg_training_score\"].fillna(df[\"avg_training_score\"].median(), inplace=True)","fe8e5a92":"df.isna().sum()","0ac1c31c":"columns = [\"department\", \"education\", \"gender\", \"recruitment_channel\", \"no_of_trainings\", \"age\",\n          \"previous_year_rating\", \"length_of_service\", \"awards_won\", \"avg_training_score\"]\nfor i in columns:\n    plt.figure(figsize=(14, 5.5))\n    sn.countplot(x=df[i])\n    plt.show()","b45331e8":"for i in columns:\n    plt.figure(figsize=(14, 5.5))\n    sn.histplot(x=df[i], hue=df[\"is_promoted\"], multiple=\"stack\")\n    plt.show()","9c3d7829":"for i in columns:\n    plt.figure(figsize=(14, 5.5))\n    sn.barplot(x=df[i], y=df[\"is_promoted\"])\n    plt.show()","ef3353d7":"# Splitting target and features\n\nX = df.drop([\"employee_id\"], axis=\"columns\")\ny = X.pop(\"is_promoted\")\nfor colname in X.select_dtypes(\"object\"):\n    X[colname], _ = X[colname].factorize()\ndiscrete_features = X.dtypes == int","14ac0f3f":"# Defining function make_mi_scores\nfrom sklearn.feature_selection import mutual_info_classif\n\ndef make_mi_scores(X, y, discrete_features):\n    mi_scores = mutual_info_classif(X, y, discrete_features=discrete_features)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\nmi_scores = make_mi_scores(X, y, discrete_features)","e6931e9e":"mi_scores\ndf.columns","afdb85a0":"# plotting mi_scores\ndef plot_mi_scores(scores):\n    scores = scores.sort_values(ascending=True)\n    width = np.arange(len(scores))\n    ticks = list(scores.index)\n    plt.barh(width, scores, color=\"#000080\")\n    plt.yticks(width, ticks)\n    plt.title(\"Mutual Information Scores\")","1e00b06b":"plot_mi_scores(mi_scores)","0fb250ad":"xprep = X[[\"avg_training_score\", \"previous_year_rating\", \"awards_won\", \"department\", \"gender\"]]\nyprep = y","788774d9":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score","518fb602":"from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV","a97fc3f1":"model = RandomForestClassifier()","05a071dc":"gcv = GridSearchCV(model, \n    {'random_state':[0, 1, 2, 42, 10, 20, 15], 'n_estimators':[10, 20, 30, 50, 70,100]})\ngcv.fit(xprep, yprep)\nprint(gcv.best_params_, gcv.best_score_)","57a40dea":"X_train, X_test, y_train, y_test = train_test_split(xprep, yprep, test_size=0.20)","6662eaf6":"rf = RandomForestClassifier(random_state=10, n_estimators=70)\nrf.fit(X_train, y_train)","1775d071":"print(\"Score : \",rf.score(X_test, y_test).round(decimals=2))","06b1f3c4":"# Parameter Tuning","6e887f77":"*We can see that {'n_estimators': 70, 'random_state': 10} parameters score well*","6437530f":"> Loading data","0a8f8e24":"***Our final score is 0.94***","1d45d4bc":"> Making Necessary imports","7ddf7445":"**I used many algorithms but RandomForest performs well\nIt scores 0.9388 accuracy**","0e0111c4":"# Scoring our dataset","f5ff4536":"# Data Visualization","de35cd5e":"**2.Plotting with respect to target variable** ","38547c58":"**Handling null values**","c76e8a8e":"# Model selection","eb1c86ac":"# Mutual info","7d0e28aa":"**1.Distribution of data**","7e4edbfa":"*We can fill education with \"no_degree\" as a person has null in education will have no degrees*","29f844a6":"We'll now move to the next section","e4062fd1":"# Exploratory Data Analysis","8a6e042f":"**3. Barchart**","83e3f74e":"**We can see that features avg_training_score, previous_year_rating, awards_won, region, etc., have more scores**","34910326":"*We can fill previous_year_rating and avg_training_score with median*"}}