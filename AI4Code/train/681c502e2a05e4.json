{"cell_type":{"ebee283d":"code","97c52abe":"code","84893236":"code","179adef6":"code","0ac29cb9":"code","d908264f":"code","3c044990":"code","a4858914":"code","df7320ed":"code","b6098a29":"code","f40874a9":"code","190da8c6":"code","e107f644":"code","7f98b751":"code","1b6d9450":"code","1c696707":"code","e3eae863":"code","03847f2b":"code","1577125b":"code","35578fed":"code","666f3a70":"code","0873ce75":"code","ed0965f5":"code","a2abc24e":"code","c57a74dc":"code","86d2e7b6":"code","861ea59e":"code","015a8d38":"code","0c52af7c":"code","6b14d000":"code","0d2fa432":"code","91a8e572":"code","032e3cae":"code","4e96afca":"code","7e7ff3ae":"code","bcaa824d":"code","f64542fa":"code","0492d3b9":"code","25c249de":"code","0273c1c4":"code","238bd44c":"code","dde467f3":"code","a8d22d35":"code","7bbf5897":"code","4a80f6c0":"code","a2f69fb9":"code","6ece7f8c":"code","07d0d409":"code","e9355b47":"code","259f6619":"code","b4db7857":"code","6a815e66":"code","b45623f0":"code","6454188f":"code","74e2f987":"code","cbaeb670":"code","fd3a943f":"code","7b0b9f31":"code","2a9ec2aa":"code","ca0a6c6f":"code","2d8d72a2":"code","6ddb7830":"code","a31a7630":"code","e68859f2":"code","36a29e2e":"code","513c5ab4":"markdown","010f87c2":"markdown","19874718":"markdown","c9abb09e":"markdown","c4c52970":"markdown","33f53e67":"markdown","123e30c8":"markdown"},"source":{"ebee283d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom scipy.sparse import vstack\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n","97c52abe":"from nltk.corpus import LazyCorpusLoader, CategorizedPlaintextCorpusReader","84893236":"# Listing the first 5 documents's ID and categories\n!head -n 5 '\/kaggle\/input\/reuters\/reuters\/reuters\/cats.txt'","179adef6":"# https:\/\/www.kaggle.com\/alvations\/testing-1000-files-datasets-from-nltk\nreuters = LazyCorpusLoader('reuters', CategorizedPlaintextCorpusReader, \n                           '(training|test).*', cat_file='cats.txt', encoding='ISO-8859-2',\n                          nltk_data_subdir='\/kaggle\/input\/reuters\/reuters\/reuters\/')\n# https:\/\/miguelmalvarez.com\/2015\/03\/20\/classifying-reuters-21578-collection-with-python-representing-the-data\/\nreuters.words()","0ac29cb9":"# See how many categories are there? \nnum_of_cat = len(reuters.categories())\nprint('Number of categories: ' + str(num_of_cat) + ' categories')\nreuters.categories()   # List all available categories.","d908264f":"reuters.fileids(\"jobs\")[:5]","3c044990":"reuters.words(reuters.fileids(\"jobs\")[0])","a4858914":"# List the raw text of the first 5 articles. \nfor i in range(5):\n    print('Article #' + str(i+1))\n    print(reuters.raw(reuters.fileids(\"jobs\")[i]))\n    ","df7320ed":"reuters.categories(reuters.fileids(\"jobs\")[:20])","b6098a29":"# File IDs\nreuters.fileids()[:5]","f40874a9":"train_docs = list(filter(lambda doc: doc.startswith(\"train\"),\n                        reuters.fileids()));","190da8c6":"print('Number of docs in the test set: ' + str(len(train_docs)))\ntrain_docs[:5]","e107f644":"test_docs = list(filter(lambda doc: doc.startswith(\"test\"),\n                        reuters.fileids()));","7f98b751":"print('Number of docs in the test set: ' + str(len(test_docs)))\ntest_docs[:5]","1b6d9450":"train_documents, train_categories = zip(*[(reuters.raw(i), reuters.categories(i)) for i in reuters.fileids() if i.startswith('training\/')])\ntest_documents, test_categories = zip(*[(reuters.raw(i), reuters.categories(i)) for i in reuters.fileids() if i.startswith('test\/')])\n\n# All documents in The Reuters dataset\nwhole_docs, whole_cats = zip(*[(reuters.raw(i), reuters.categories(i)) for i in reuters.fileids() if True])","1c696707":"whole_cats[:5]","e3eae863":"train_documents[0]","03847f2b":"train_categories[:20]","1577125b":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer(stop_words = 'english')\n\nvectorised_train_documents = vectorizer.fit_transform(train_documents)\nvectorised_test_documents = vectorizer.transform(test_documents)\n\nvectorizer2 = TfidfVectorizer(stop_words = 'english')\nvec_whole_docs = vectorizer2.fit_transform(whole_docs)","35578fed":"vectorised_train_documents","666f3a70":"vec_whole_docs","0873ce75":"from sklearn.preprocessing import MultiLabelBinarizer\n\nmlb = MultiLabelBinarizer()\ntrain_labels = mlb.fit_transform(train_categories)\ntest_labels = mlb.transform(test_categories)\n\n# For the whole dataset\nmlb2 = MultiLabelBinarizer()\nwhole_labels = mlb2.fit_transform(whole_cats)","ed0965f5":"train_labels.shape","a2abc24e":"whole_labels.shape   # Training docs = 7769 docs. ","c57a74dc":"# Create the whole dataset from training-only vectorized matrix. \nprint('X stuff: ')\nprint(vectorised_train_documents.shape)\nprint(vectorised_test_documents.shape)\nprint(type(vectorised_train_documents))\nX = vstack([vectorised_train_documents, vectorised_test_documents])\nprint(X.shape)\n\nprint('Label stuff: ')\nprint(train_labels.shape)\nprint(test_labels.shape)\ny = np.concatenate((train_labels, test_labels))\ny.shape","86d2e7b6":"# https:\/\/towardsdatascience.com\/multi-class-text-classification-with-sklearn-and-nltk-in-python-a-software-engineering-use-case-779d4a28ba5\nfrom sklearn.ensemble import RandomForestClassifier\nclf_random = RandomForestClassifier()\n# random_clf.fit(X, y)\n\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import LinearSVC\n\nclf_svm = OneVsRestClassifier(LinearSVC())\n# clf_svm.fit(vec_whole_docs, whole_labels)\n\nfrom sklearn.neural_network import MLPClassifier\nclf_mlp1 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(1,), random_state=1)\nclf_mlp2 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(2,), random_state=1)\nclf_mlp3 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(3,), random_state=1)\n# clf_mlp.fit(vec_whole_docs, whole_labels)","861ea59e":"# Setup \nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import recall_score\n# scoring = ['precision_samples', 'recall_samples', 'f1_samples']\n# scoring = ['precision_macro', 'recall_macro', 'f1_macro']       # No class imbalance consideration\nscoring = ['precision_micro', 'recall_micro', 'f1_micro']\ncv = 3","015a8d38":"scores = cross_validate(clf_random, X, y, cv=cv, scoring=scoring)\n\n# Whole dataset (begin before vectorization)\nscores_whole = cross_validate(clf_random, vec_whole_docs, whole_labels, cv=cv, scoring=scoring)","0c52af7c":"# print the report \nscores","6b14d000":"scores_whole","0d2fa432":"# SVM \nscores_svm = cross_validate(clf_svm, vec_whole_docs, whole_labels, cv=cv, scoring=scoring)","91a8e572":"scores_svm","032e3cae":"# MLP\nscores_mlp1 = cross_validate(clf_mlp1, vec_whole_docs, whole_labels, cv=cv, scoring=scoring)\nscores_mlp2 = cross_validate(clf_mlp2, vec_whole_docs, whole_labels, cv=cv, scoring=scoring)\nscores_mlp3 = cross_validate(clf_mlp3, vec_whole_docs, whole_labels, cv=cv, scoring=scoring)","4e96afca":"scores_mlp1","7e7ff3ae":"scores_mlp2","bcaa824d":"scores_mlp3","f64542fa":"from sklearn.model_selection import learning_curve\n\ntrain_sizes, train_scores, valid_scores = learning_curve(clf_mlp3, vec_whole_docs, whole_labels, train_sizes=[2000, 3000, 7000], cv=5)","0492d3b9":"train_scores","25c249de":"valid_scores","0273c1c4":"import pandas as pd\nimport numpy as np\nimport gzip\n\n# Read the JSON file. \ndef parse(path):\n    g = open(path, 'rb')\n    for l in g:\n        yield eval(l)\n\ndef getDF(path):\n    i = 0\n    data = {}\n    for d in parse(path):\n        data[i] = d\n        i += 1\n    return pd.DataFrame.from_dict(data, orient='index')\n\nDATASET_NAME = '..\/input\/appsforandroid\/reviews_Apps_for_Android_5.json'\ndf = getDF(DATASET_NAME)\n","238bd44c":"df.head(30)","dde467f3":"df.dropna(inplace=True)\ndf[df['overall'] != 3]\ndf['Positivity'] = np.where(df['overall'] > 3, 1, 0)\ndf['intRating'] = df['overall'].astype(int)\ndf.head(20)","a8d22d35":"# X_train, X_test, y_train, y_test = train_test_split(df['Text'], df['Positivity'], random_state = 0)\n\n# from sklearn.preprocessing import MultiLabelBinarizer\n# mlb = MultiLabelBinarizer()\n\napps_X = df['reviewText']\napps_y = pd.get_dummies(df['Positivity'])\napps_X","7bbf5897":"apps_y[:3]","4a80f6c0":"# TF-IDF Vectorization\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nvect = TfidfVectorizer(stop_words = 'english')\nvect_bigram = TfidfVectorizer(stop_words = 'english', ngram_range = (1,2))\napps_X_vec = vect.fit_transform(apps_X)\napps_X_vec_bigram = vect_bigram.fit_transform(apps_X)\nprint(len(vect.get_feature_names()))\nprint(len(vect_bigram.get_feature_names()))","a2f69fb9":"apps_X_vec.shape","6ece7f8c":"apps_y.shape","07d0d409":"apps_y_multi = pd.get_dummies(df['overall'])\napps_y_multi","e9355b47":"# Models\nfrom sklearn.linear_model import LogisticRegression\nm_lr = LogisticRegression()\n# m_lr.fit(apps_X_vec, df['Positivity'])\n\nfrom sklearn.ensemble import RandomForestClassifier\nm_random = RandomForestClassifier()\n# m_random.fit(apps_X_vec, df['Positivity'])\n\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import LinearSVC\nm_svm = OneVsRestClassifier(LinearSVC())","259f6619":"# Cross validation\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import recall_score\n# scoring = ['precision_samples', 'recall_samples', 'f1_samples']\n# scoring = ['precision_macro', 'recall_macro', 'f1_macro']\nscoring = ['precision_micro', 'recall_micro', 'f1_micro']\ncv = 3\n\napps_scores = cross_validate(m_lr, apps_X_vec, df['Positivity'], cv=cv, scoring=scoring)\napps_scores_bigram = cross_validate(m_lr, apps_X_vec_bigram, df['Positivity'], cv=cv, scoring=scoring)","b4db7857":"apps_scores","6a815e66":"apps_scores_bigram","b45623f0":"apps_scores_multi = cross_validate(m_lr, apps_X_vec, df['overall'], cv=cv, scoring=scoring)\napps_scores_bigram_multi = cross_validate(m_lr, apps_X_vec_bigram, df['overall'], cv=cv, scoring=scoring)","6454188f":"apps_scores_multi","74e2f987":"apps_scores_bigram_multi","cbaeb670":"# Random forest CV\n# apps_scores_random = cross_validate(m_random, apps_X_vec, df['Positivity'], cv=cv, scoring=scoring)   # Too long training time\n# apps_scores_random","fd3a943f":"# SVM CV (RandomForest takes too much time to train with this dataset)\napps_scores_svm = cross_validate(m_svm, apps_X_vec, df['Positivity'], cv=cv, scoring=scoring)","7b0b9f31":"apps_scores_svm","2a9ec2aa":"apps_scores_svm_bigram = cross_validate(m_svm, apps_X_vec_bigram, df['Positivity'], cv=cv, scoring=scoring)   # Too long training time","ca0a6c6f":"apps_scores_svm_bigram","2d8d72a2":"# SVM Multiclass Unigram \napps_scores_svm_multi = cross_validate(m_svm, apps_X_vec, df['intRating'], cv=cv, scoring=scoring)","6ddb7830":"apps_scores_svm_multi","a31a7630":"# SVM Multiclass Bigram \napps_scores_svm_bigram = cross_validate(m_svm, apps_X_vec_bigram, df['intRating'], cv=cv, scoring=scoring)  ","e68859f2":"apps_scores_svm_bigram","36a29e2e":"# What if we calculate using \"macro\"? \nscoring = ['precision_macro', 'recall_macro', 'f1_macro']\n# scoring = ['precision_micro', 'recall_micro', 'f1_micro']\napps_scores_svm_bigram = cross_validate(m_svm, apps_X_vec_bigram, df['Positivity'], cv=cv, scoring=scoring)\napps_scores_svm_bigram","513c5ab4":"# Evaluation\n- Precision \n- Recall \n- F1 Score","010f87c2":"![](http:\/\/)## Look at the learning curve","19874718":"# Apps for Android\nReference: https:\/\/towardsdatascience.com\/scikit-learn-for-text-analysis-of-amazon-fine-food-reviews-ea3b232c2c1b","c9abb09e":"# Model\n- Random Forest Classifier\n- SVM\n- Multi-layer perceptron","c4c52970":"Thank you to :  \nhttps:\/\/www.kaggle.com\/alvations\/testing-1000-files-datasets-from-nltk  \nhttps:\/\/miguelmalvarez.com\/2015\/03\/20\/classifying-reuters-21578-collection-with-python-representing-the-data\/  \nhttps:\/\/www.kaggle.com\/harshildarji\/reuters-onevsrestclassifier  \nhttps:\/\/towardsdatascience.com\/multi-class-text-classification-with-sklearn-and-nltk-in-python-a-software-engineering-use-case-779d4a28ba5","33f53e67":"# Explore the TF-IDF matrix extracted by Scikit Learn","123e30c8":"# Explore the Reuter dataset "}}