{"cell_type":{"58fe8df6":"code","e65776f6":"code","981d1889":"code","406f1d1a":"code","a53a3ed8":"code","f1d057ce":"code","13bb6f4f":"code","087620f7":"code","c2bd7542":"code","d4a89f05":"code","38512935":"code","08d9d079":"code","9593ac62":"code","ff52fec3":"code","8ca91b07":"code","66172917":"markdown","14880c60":"markdown","d9b09437":"markdown","fb05e6da":"markdown","2e0f138d":"markdown","8477509b":"markdown","124d907c":"markdown","5734db35":"markdown","720d3916":"markdown","c9b7aac6":"markdown","25ae78c1":"markdown","c7020dc8":"markdown","27063f71":"markdown","e5a2ab5f":"markdown","0fdf7fdf":"markdown","9d8a66b9":"markdown"},"source":{"58fe8df6":"import keras\nimport keras.models as M\nimport keras.layers as L\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport os\nfrom keras.datasets.cifar10 import load_data\nimport matplotlib.pyplot as plt\nfrom PIL import Image","e65776f6":"def import_data():\n    (X,_),(_,_)=load_data()\n    X=X.astype('float32')\n    X=(X-127.5)\/127.5\n    return X","981d1889":"def make_real_samples(dataset,samples=100):\n    ix=np.random.randint(0,dataset.shape[0],samples)\n    train=dataset[ix]\n    y=np.ones((samples,1))\n    return train,y","406f1d1a":"def make_random_latent_points(latent_dim,n=100):\n    latent=np.random.randn(latent_dim*n)\n    latent=latent.reshape(n,latent_dim)\n    return latent","a53a3ed8":"def make_fake_samples(g_model,latent_dim,n=100):\n    points=make_random_latent_points(latent_dim,n)\n    X=g_model.predict(points)\n    y=np.zeros((n,1))\n    return X,y ","f1d057ce":"def make_d_model(input_shape=(32,32,3)):\n    model=M.Sequential()\n    model.add(L.Conv2D(filters=128,kernel_size=(3,3),padding='same',activation=L.LeakyReLU(alpha=0.2)))\n    model.add(L.Dropout(0.4))\n    model.add(L.Conv2D(filters=128,kernel_size=(3,3),padding='same',activation=L.LeakyReLU(alpha=0.2)))\n    model.add(L.Dropout(0.4))\n    model.add(L.Conv2D(filters=128,kernel_size=(3,3),padding='same',activation=L.LeakyReLU(alpha=0.2)))\n    model.add(L.Dropout(0.4))\n    model.add(L.Flatten())\n    model.add(L.Dense(1,'sigmoid'))\n    opt=keras.optimizers.Adam(lr=0.0002,beta_1=0.5)\n    model.compile(loss='binary_crossentropy',metrics=['accuracy'],optimizer=opt)\n    return model","13bb6f4f":"def make_generator_model(latent_dim):\n    model=M.Sequential()\n    model.add(L.Dense(256*4*4,input_dim=latent_dim,activation=L.LeakyReLU(alpha=0.2)))\n    model.add(L.Reshape((4,4,256)))\n    model.add(L.Conv2DTranspose(filters=128,kernel_size=(4,4),strides=(2,2),padding='same',activation=L.LeakyReLU(alpha=0.2)))\n    model.add(L.Conv2DTranspose(filters=128,kernel_size=(4,4),strides=(2,2),padding='same',activation=L.LeakyReLU(alpha=0.2)))\n    model.add(L.Conv2DTranspose(filters=128,kernel_size=(4,4),strides=(2,2),padding='same',activation=L.LeakyReLU(alpha=0.2)))\n    model.add(L.Conv2D(3,(3,3),activation='tanh',padding='same'))\n    return model\n    ","087620f7":"def make_gan_model(d_model,g_model):\n    d_model.trainable=False\n    model=M.Sequential()\n    model.add(g_model)\n    model.add(d_model)\n    opt=keras.optimizers.Adam(lr=0.0008,beta_1=0.5)\n    model.compile(loss='binary_crossentropy',metrics=['accuracy'],optimizer=opt)\n    return model","c2bd7542":"def save_plot(examples, epoch, n=7):\n    # scale from [-1,1] to [0,1]\n    examples = (examples + 1) \/ 2.0\n    # plot images\n    for i in range(n * n):\n        # define subplot\n        plt.subplot(n, n, 1 + i)\n        # turn off axis\n        plt.axis('off')\n        # plot raw pixel data\n        plt.imshow(examples[i])\n    # save plot to file\n    filename = 'generated_plot_e%03d.png' % (epoch+1)\n    plt.savefig(filename)\n    plt.close()","d4a89f05":"def make_summarization(epoch,g_model,d_model,gan_model,latent_dim,batch_size,dataset):\n    X_real,y_real=make_real_samples(dataset,batch_size)\n    real_acc,_=d_model.evaluate(X_real,y_real,verbose=0)\n    X_fake,y_fake=make_fake_samples(g_model,latent_dim,batch_size)\n    fake_acc,_=d_model.evaluate(X_fake,y_fake,verbose=0)\n    print('The real data acc: ',real_acc,'  Fake Data Accuracy:',fake_acc)\n    save_plot(X_fake,epoch)\n    ","38512935":"def train_gan_model(g_model,d_model,gan_model,dataset,epochs=100,batch_size=128,latent_dim=100,n=100,n_epoch=5):\n    sizen=dataset.shape[0]\/\/batch_size\n    size=batch_size\/\/2\n    count=0\n    for i in range(epochs):\n        for j in range(sizen):\n            X_real,y_real=make_real_samples(dataset,size)\n            X_fake,y_fake=make_fake_samples(g_model,latent_dim,size)\n            X=np.vstack((X_real,X_fake))\n            y=np.vstack((y_real,y_fake))\n            d_loss,_=d_model.train_on_batch(X,y)\n            X_gan=make_random_latent_points(latent_dim,batch_size)\n            y_gan=np.ones((batch_size,1))\n            g_loss,_=gan_model.train_on_batch(X_gan,y_gan)\n        print('Epoch:',i,'  D_loss:',d_loss,'  G_Loss:',g_loss)\n        if i%n_epoch==0:\n            make_summarization(count,g_model,d_model,gan_model,latent_dim,batch_size,dataset)","08d9d079":"latent_dim=100\nd_model=make_d_model()\ng_model=make_generator_model(latent_dim)\ngan_model=make_gan_model(d_model,g_model)\ndataset=import_data()\ntrain_gan_model(g_model,d_model,gan_model,dataset,epochs=60)","9593ac62":"im=make_fake_samples(g_model,latent_dim,100)","ff52fec3":"plt.imshow(im[0][10])","8ca91b07":"plt.imshow(im[0][95])","66172917":"# Having a look at randomly generated image","14880c60":"# Importing Packages","d9b09437":"# Function to save the images","fb05e6da":"# Function to make GAN Model","2e0f138d":"# Thank you :)","8477509b":"it looks like a beautiful scenary of river during night :)","124d907c":"# Function to make Fake Samples","5734db35":"# Function to make Discriminator Model","720d3916":"# Function to make Real Samples of the data","c9b7aac6":"# Function to Summarize the Results","25ae78c1":"# Function to train the models","c7020dc8":"# Calling and training the models","27063f71":"# Function to make random latent points","e5a2ab5f":"# You can try to run it for more than 60 epochs and the results will get better :)","0fdf7fdf":"# Function to make Generator Model","9d8a66b9":"# Function to Load and import Data"}}