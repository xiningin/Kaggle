{"cell_type":{"66bcc12e":"code","98f0d3f0":"code","e117ea00":"code","952406d3":"code","157a7f00":"code","8b3a895b":"code","467ec81e":"code","6bd4e3e2":"code","9b31528e":"code","ec49f6ca":"markdown","caab53e4":"markdown","d8e9acda":"markdown","4373eee6":"markdown","9b049f29":"markdown","f0573359":"markdown"},"source":{"66bcc12e":"import os\nimport random\nimport itertools\nimport numpy as np\nimport pandas as pd\nfrom tqdm.contrib.concurrent import process_map\n\n!wget http:\/\/webhotel4.ruc.dk\/~keld\/research\/LKH-3\/LKH-3.0.7.tgz\n!tar xvfz LKH-3.0.7.tgz\n!cd LKH-3.0.7; make; cp LKH ..","98f0d3f0":"LETTERS = {\n    1: '\ud83c\udf85',  # father christmas\n    2: '\ud83e\udd36',  # mother christmas\n    3: '\ud83e\udd8c',  # reindeer\n    4: '\ud83e\udddd',  # elf\n    5: '\ud83c\udf84',  # christmas tree\n    6: '\ud83c\udf81',  # gift\n    7: '\ud83c\udf80',  # ribbon\n    8: '\ud83c\udf1f',  # star\n}\nINV_LETTERS = {v: k for k, v in LETTERS.items()}\n\nsolution = pd.read_csv('..\/input\/santasolutions\/submission_no_wildcards_2456_2455_2452.csv')\nstrings = [[INV_LETTERS[c] for c in s] for s in solution.schedule]\nstrings.sort(key=len, reverse=True)\nprint(f'Strings lengths are {[len(_) for _ in strings]}.')","e117ea00":"def find_strings_perms(strings, verbose=False):\n    all_perms = set(itertools.permutations(range(1, 8), 7))\n    perms = []\n    for s in strings:\n        perms.append([])\n        for i in range(len(s)-6):\n            p = tuple(s[i:i+7])\n            if p in all_perms:\n                perms[-1].append(p)\n    if verbose:\n        lens = [len(_) for _ in  perms]\n        print(f'There are {lens} permutations in strings, {sum(lens)} in total.')\n        lens = [len(set(_)) for _ in  perms]\n        print(f'There are {lens} unique permutations in strings, {sum(lens)} in total.')\n    return perms\n\nstrings_perms = find_strings_perms(strings, verbose=True)","952406d3":"def rebalance_perms(strings_perms, verbose=False):\n    # convert to dicts for fast lookup and to keep permutations order\n    strings_perms = [dict.fromkeys(_) for _ in strings_perms] \n    for p in strings_perms[0].copy():  # iterate over the copy to allow modification during iteration\n        if p[:2] != (1, 2) and (p in strings_perms[1] or p in strings_perms[2]):\n            strings_perms[0].pop(p)\n    for p in strings_perms[1].copy():\n        if p[:2] != (1, 2) and p in strings_perms[2]:\n            strings_perms[1].pop(p)\n    if verbose:\n        lens = [len(_) for _ in  strings_perms]\n        print(f'There are {lens} permutations left in strings after rebalancing, {sum(lens)} in total.')\n    return [list(_) for _ in strings_perms] \n\nstrings_perms = rebalance_perms(strings_perms, verbose=True)","157a7f00":"def perm_dist(p, q):\n    i = p.index(q[0])\n    return i if p[i:] == q[:7-i] else 7\n\ndef perms_to_string(perms):\n    perms = list(perms)\n    s = [*perms[0]]\n    for p, q in zip(perms, perms[1:]):\n        d = perm_dist(p, q)\n        s.extend(q[-d:])\n    return s\n\ndef distances_matrix(perms):\n    m = np.zeros((len(perms), len(perms)), dtype='int8')\n    for i, p in enumerate(perms):\n        for j, q in enumerate(perms):\n            m[i, j] = perm_dist(p, q)\n    return m\n\ndef write_params_file(uid):\n    with open('santa_%s.par' % uid, 'w') as f:\n        print('PROBLEM_FILE = santa_%s.atsp' % uid, file=f)\n        print('TOUR_FILE = best_tour_%s.txt' % uid, file=f)\n        print('INITIAL_TOUR_FILE = initial_tour_%s.txt' % uid, file=f)\n        print('PATCHING_C = 4', file=f)\n        print('PATCHING_A = 3', file=f)\n        print('GAIN23 = YES', file=f)\n        print('SEED = 42', file=f)\n        print('MAX_TRIALS = 100000', file=f)\n        print('TIME_LIMIT = 600', file=f) #seconds\n        print('TRACE_LEVEL = 1', file=f)\n\ndef write_problem_file(uid, distances):\n    with open('santa_%s.atsp' % uid, 'w') as f:\n        print('TYPE: ATSP', file=f)\n        print(f'DIMENSION: {len(distances)}', file=f)\n        print('EDGE_WEIGHT_TYPE: EXPLICIT', file=f)\n        print('EDGE_WEIGHT_FORMAT: FULL_MATRIX\\n', file=f)\n        print('EDGE_WEIGHT_SECTION', file=f)\n        for row in distances:\n            print(' '.join(str(_) for _ in row), file=f)\n\ndef write_initial_tour_file(uid, perms):\n    with open('initial_tour_%s.txt' % uid, 'w') as f:\n        print('TOUR_SECTION', file=f)\n        print(' '.join(str(_) for _ in range(1, len(perms)+1)), -1, file=f)\n\ndef read_output_tour(uid, perms):\n    perms = list(perms)\n    with open('best_tour_%s.txt' % uid) as f:\n        lines = f.readlines()\n    tour = lines[lines.index('TOUR_SECTION\\n')+1:-2]\n    return [perms[int(_) - 1] for _ in tour] \n    \ndef solve_atsp(perms, verbose=False):\n    uid = str(random.randint(1, 9999))\n    write_params_file(uid)\n    distances = distances_matrix(perms)\n    write_problem_file(uid, distances)\n    write_initial_tour_file(uid, perms)\n    \n    # Run LKH-3 to solve ATSP instance\n    if verbose:\n        os.system('.\/LKH santa_%s.par' % uid)\n    else:\n        os.system('touch lkh_%s.log' % uid)\n        os.system('.\/LKH santa_%s.par >> lkh_%s.log' % (uid, uid))\n    tour = read_output_tour(uid, perms)\n    return perms_to_string(tour)","8b3a895b":"improved, old_lens = True, [len(i) for i in strings]\nwhile improved:\n    print('='*91)\n    # new_strings = [solve_atsp(i) for i in strings_perms]\n    new_strings = list(process_map(solve_atsp, strings_perms))\n    new_strings.sort(key=len, reverse=True)\n    new_lens = [len(_) for _ in new_strings]\n    if new_lens < old_lens:\n        print(f'Improved strings lengths from {old_lens} to {new_lens}.')\n        strings, old_lens = new_strings, new_lens\n        strings_perms = find_strings_perms(strings, verbose=True)\n        strings_perms = rebalance_perms(strings_perms, verbose=True)\n    else:\n        improved = False","467ec81e":"all_perms = set(itertools.permutations(range(1, 8), 7))\nmandatory_perms = set((1, 2) +  _ for _ in itertools.permutations(range(3, 8), 5))\n\nstrings_perms = [set(_) for _ in find_strings_perms(strings)]\nfor i, s in enumerate(strings_perms):\n    if mandatory_perms - s:\n        print(f'String #{i} is missing {mandatory_perms - s}.')\nif all_perms - set.union(*strings_perms):\n    print(f'Strings are missing {all_perms - set.union(*strings_perms)}.')","6bd4e3e2":"sub = pd.DataFrame()\nsub['schedule'] = [''.join(LETTERS[x] for x in s) for s in strings]\nsub_name = f'submission_no_wildcards_{\"_\".join(str(len(_)) for _ in strings)}.csv'\nsub.to_csv(sub_name, index=False)","9b31528e":"import numpy as np\nimport pandas as pd\nimport itertools\n\nWRK_DIR = '\/kaggle\/working\/'\nDAT_DIR = '..\/input\/santa-2021\/'\nSRC_FILE = '..\/input\/st-21-a-minmax-ctsp\/submission_no_wildcards_2456_2455_2452.csv'\nRMV_FILE = WRK_DIR + 'removed.csv'\nADD_FILE = WRK_DIR + 'add.csv'\n\nRUN_RMV = True\nRUN_ADD = True\n\ndef check_if_good(a):\n    # Check if the submission is valid\n    global wildcard\n    global start\n    global other\n\n    # If all the combinations beginning with \ud83c\udf85\ud83e\udd36 are in the three submissions\n    for permu in start['Permutation'].tolist():\n        x=0\n        if permu in a[0]:\n            x+=1\n            if permu in a[1]:\n                x+=1\n                if permu in a[2]:\n                    continue\n        # For wildcards\n        permus_for_wild = wildcard[wildcard['Permutation']==permu].index.values\n        in_string = False\n        for p in permus_for_wild:\n            if wildcard.at[p, 'Factor'] in a[0]: in_string = True\n            if wildcard.at[p, 'Factor'] in a[1]: in_string = True\n            if wildcard.at[p, 'Factor'] in a[2]: in_string = True\n        if in_string: continue\n        print(\"Not all \ud83c\udf85\ud83e\udd36, missing:\", permu, str(permu).translate(str.maketrans(symbols, \"12345678\")), \"; string:\", x)\n        return False\n\n    # If all the combinations are in the submissions\n    for permu in other['Permutation'].tolist():\n        if permu in a[0]: continue\n        if permu in a[1]: continue\n        if permu in a[2]: continue\n\n        # For wildcards\n        permus_for_wild = wildcard[wildcard['Permutation']==permu].index.values\n        in_string = False\n        for p in permus_for_wild:\n            if wildcard.at[p, 'Factor'] in a[0]: in_string = True\n            if wildcard.at[p, 'Factor'] in a[1]: in_string = True\n            if wildcard.at[p, 'Factor'] in a[2]: in_string = True\n        if not in_string:\n            print(\"Not all the combinaison, missing:\", permu, str(permu).translate(str.maketrans(symbols, \"12345678\")))\n            return False\n\n    # If there are 2 stars or less\n    if a[0].count('\ud83c\udf1f') > 2:\n        print(\"Too many stars in string: 0\")\n        return False\n    if a[1].count('\ud83c\udf1f') > 2:\n        print(\"Too many stars in string: 1\")\n        return False\n    if a[2].count('\ud83c\udf1f') > 2:\n        print(\"Too many stars in string: 2\")\n        return False\n    return True\n\ndef hamming_distance(str1, str2):\n    return sum( (c1!=c2) for c1, c2 in zip(str1, str2))\n\ndef offset(s1, s2):\n    assert(len(s1)==len(s2))\n    ln = len(s1)\n    j = ln\n    for k in range(0,ln):\n        if hamming_distance(s1[k:],s2[:7-k])==0:\n            j=k\n            break\n    return j\n\ndef is_perm(s):\n    y = True\n    for k in range(1,8):\n        y = y&(str(k) in s)\n        if not y: break\n    return y\n\ndef str2perms(best):\n    gp = []\n    for k in range(len(best)-6):\n        s = best[k:k+7]\n        if (is_perm(s))&(s not in gp):\n            gp.append(s)\n    return gp\n\ndef rebalance_perms(strings_perms, verbose=False):\n    for p in strings_perms[0].copy():  # iterate over the copy to allow modification during iteration\n        if p[:2] != \"12\" and (p in strings_perms[1] or p in strings_perms[2]):\n            strings_perms[0].remove(p)\n    for p in strings_perms[1].copy():\n        if p[:2] != \"12\" and p in strings_perms[2]:\n            strings_perms[1].remove(p)\n    if verbose:\n        lens = [len(_) for _ in  strings_perms]\n        print(f'There are {lens} permutations left in strings after rebalancing, {sum(lens)} in total.')\n    return strings_perms\n\nsymbols = \"\ud83c\udf85\ud83e\udd36\ud83e\udd8c\ud83e\udddd\ud83c\udf84\ud83c\udf81\ud83c\udf80\ud83c\udf1f\"\nschedule = sub.schedule.tolist()\n\nstrings = [s.translate(str.maketrans(symbols, \"12345678\")) for s in schedule]\nprint(f'Strings lengths are {[len(_) for _ in strings]}.')\n\nperms = [str2perms(x) for x in strings]\nsize_perms = [len(x) for x in perms]\nprint(f'Size perms: {size_perms}')\n\nrb_perms = rebalance_perms(perms.copy(), True)\n\npermus = pd.read_csv(DAT_DIR + \"permutations.csv\") # Import of permutations\nwildcard = pd.read_csv(DAT_DIR + \"wildcards.csv\") # Import of wildcard permutations\n\nstart = permus[permus.Permutation.str[:2] =='\ud83c\udf85\ud83e\udd36'] # DataFrame of permutations starting with \ud83c\udf85\ud83e\udd36\nother = permus[permus.Permutation.str[:2] !='\ud83c\udf85\ud83e\udd36'].reset_index(drop=True) # DataFrame of all other permutations\n\ndef score_matrix(perm_list):\n    score_mat = []\n    for i in range(len(perm_list)):\n        if i == 0:\n            score_mat.append(7)\n        else:\n            score_mat.append(offset(perm_list[i - 1], perm_list[i]))\n    return score_mat\n\ndef fill_wildcard(p, p2, wi):\n    o = p + ''\n    o2 = p2 + ''\n    w2 = p2[wi:wi+1]\n    p2 = p2.replace(w2, '8')\n    a2 = p2[:wi]\n    b2 = p2[wi+1:]\n        \n    if a2 not in p:\n        return o, o2\n    \n    i = p.index(a2)    \n    w = p[i + len(a2):i + len(a2) + 1]\n    p = p.replace(w, '8')\n            \n    return p, p2\n\ndef add_wildcard(perm_list, pm):\n    new_perm_list = perm_list.copy()\n    for i in range(1, len(new_perm_list) - 1):\n        o = new_perm_list[i - 1]\n        p = new_perm_list[i]\n        q = new_perm_list[i + 1]\n        f, ro, rp, rq = lookup(pm, o, p, q)\n        if f:\n            new_perm_list[i - 1] = ro\n            new_perm_list[i] = rp\n            new_perm_list[i + 1] = rq\n            return new_perm_list\n    return None\n        \ndef add_wildcard_all(perm_list, pm):\n    result = []\n    new_perm_list = perm_list.copy()\n    for i in range(1, len(new_perm_list) - 1):\n        o = new_perm_list[i - 1]\n        p = new_perm_list[i]\n        q = new_perm_list[i + 1]\n        f, ro, rp, rq = lookup(pm, o, p, q)\n        if f:\n            new_perm_list2 = perm_list.copy()\n            new_perm_list2[i - 1] = ro\n            new_perm_list2[i] = rp\n            new_perm_list2[i + 1] = rq\n            result.append(new_perm_list2)\n            \n    return result\n    \ndef remove_perm(perm_list, p, equals = False):\n    score_mat = score_matrix(perm_list)\n    cur_score = sum(score_mat)\n    min_idx = -1\n    min_score = cur_score\n\n    new_perm_list = perm_list.copy()\n    new_perm_list.remove(p)\n    new_score_mat = score_matrix(new_perm_list)\n    new_score = sum(new_score_mat)\n    if equals:\n        if new_score <= min_score:\n            print(f'Removed {p} with {new_score} ...')\n            min_score = new_score\n            min_idx = 0\n    else:\n        if new_score < min_score:\n            print(f'Removed {p} with {new_score} ...')\n            min_score = new_score\n            min_idx = 0        \n    if min_idx < 0:\n        print(f'Not removed {p} with {cur_score} ...')\n        return None\n    new_perm_list = perm_list.copy()\n    new_perm_list.remove(p)\n    return new_perm_list\n\ndef perms2str(ngp):\n    result = ngp[0]\n    for k in range(len(ngp)):\n        if k == 0:\n            continue\n        s1 = ngp[k - 1]\n        s2 = ngp[k]\n        d = offset(s1,s2)\n        result += s2[-d:]\n    return result\n\ndef perms2str_w(ngp):\n    result = ngp[0]\n    for k in range(len(ngp)):\n        if k == 0:\n            continue\n        s1 = ngp[k - 1]\n        s2 = ngp[k]\n        if '8' not in s1 and '8' in s2:\n            fds = s2.split('8')\n            d = offset_wc(s1,s2)\n            i = len(result) - (7 - d - len(fds[0]))\n            if len(result[i+1:]) == 0 and len(s2.split('8')[1]) > 1:\n                result = result[:i] + result[i+1:]                \n            else:\n                result = result[:i] + '8' + result[i+1:]\n            result += s2[-d:]          \n        else:\n            if '8' in s1 or '8' in s2:\n                d = offset_wc(s1,s2)\n                result += s2[-d:]\n            else:\n                d = offset_wc(s1,s2)\n                result += s2[-d:]\n        \n    return result    \n    \ndef tostr(src):\n    src = str(src)\n    tag = ''.join([str(x) for x in src])\n    return tag\n\ndef offset_wc(p1, p2):\n    if '8' in p1 and '8' in p2:\n        return offset(p1, p2)\n    if '8' not in p1 and '8' not in p2:\n        return offset(p1, p2)\n    if '8' in p2:\n        fds = p2.split('8')\n        a2 = fds[0]\n        b2 = fds[1]\n        if a2 not in p1:\n            return 7\n        i1 = p1.index(a2)\n        i2 = i1 + len(a2) + 1\n        a1 = p1[:i2-1]\n        b1 = p1[i2:]\n        if b1 not in b2:\n            return 7\n        i3 = b2.index(b1)\n        if i3 > 0:\n            return 7\n        return i1\n    if '8' in p1:\n        for i in range(7):\n            c = str(i + 1)\n            p = p1.replace('8', c)\n            d = offset(p, p2)\n            if d < 7:\n                return d\n        return 7\n    \ndef offset_w(p1, p2, wp):\n    a2 = p2[:wp]\n    b2 = p2[wp + 1:]\n    if a2 not in p1:\n        return 7\n    i1 = p1.index(a2)\n    i2 = i1 + len(a2) + 1\n    a1 = p1[:i2-1]\n    b1 = p1[i2:]\n    if b1 not in b2:\n        return 7\n    i3 = b2.index(b1)\n    if i3 > 0:\n        return 7\n    return i1\n\ndef lookup(pm, o, p, q):\n    found = False\n    ro = o\n    rp = p\n    rq = q\n    rs = perms2str([o, p, q])\n    for j in range(len(rs)):\n        a = rs[0:j]\n        b = rs[j+1:]\n        c = a + '8' + b      \n        if '8' in rs:\n            c = rs\n        for i in range(7):\n            a = pm[0: i]\n            b = pm[i+1:]\n            d = a + '8' + b\n            if d in c:\n                found = True\n                for k in range(7):\n                    a = o[0: k]\n                    b = o[k+1:]\n                    e = a + '8' + b\n                    if e in c:\n                        ro = e\n                        break\n                for k in range(7):\n                    a = p[0: k]\n                    b = p[k+1:]\n                    e = a + '8' + b\n                    if e in c:\n                        rp = e\n                        break\n                for k in range(7):\n                    a = q[0: k]\n                    b = q[k+1:]\n                    e = a + '8' + b\n                    if e in c:\n                        rq = e\n                        break\n            if found:\n                break\n        if found:\n            break\n        if '8' in rs:\n            break\n            \n    return found, ro, rp, rq    \n\nif RUN_RMV:\n    rows = []\n    for i in range(len(rb_perms)):\n        group = i + 1\n        perm_list_a = rb_perms[i].copy()\n        rsa = perms2str(perm_list_a)\n        sa = len(rsa)\n        for p in perm_list_a:\n            if p[0:2] == '12':\n                continue\n            new_perm_list_a = remove_perm(perm_list_a, p, False)\n            if new_perm_list_a is None:\n                continue\n            nrsa = perms2str(new_perm_list_a)\n            nsa = len(nrsa)\n            rw = {'group': group, 'perm': p, 'score': nsa}\n            rows.append(rw)\n    if len(rows) > 0:\n        df = pd.DataFrame(rows)\n        df = df.sort_values(by=['perm'], ascending=[True])\n        df.to_csv(RMV_FILE, index=False)\n    rmv_df = pd.read_csv(RMV_FILE)\nelse:\n    rmv_df = pd.read_csv(RMV_FILE)\n    \nif RUN_ADD:\n    rows = []\n    for group in range(len(rb_perms)):\n        rdf = rmv_df[rmv_df['group'] == group + 1]\n        rdf = rdf.sort_values(by=['perm'], ascending=[True])\n        for i in range(len(rdf)):\n            p = tostr(rdf['perm'].iloc[i])\n            if p[0:2] == '12':\n                continue\n            for i2 in range(len(rdf)):\n                p2 = tostr(rdf['perm'].iloc[i2])\n                if p2[0:2] == '12':\n                    continue\n                if p == p2:\n                    continue\n                perm_list_a = rb_perms[group].copy()\n                rsa = perms2str_w(perm_list_a)\n                sa = len(rsa)\n                perm_list_a.remove(p)\n                perm_list_a.remove(p2)\n                \n                result = []\n                new_result = add_wildcard_all(perm_list_a, p)\n                if len(new_result) == 0:\n                    continue\n                for new_perm_list_a in new_result:\n                    new_result_2 = add_wildcard_all(new_perm_list_a, p2)\n                    if len(new_result_2) == 0:\n                        continue\n                    for npla in new_result_2:\n                        result.append(npla)\n                if len(result) == 0:\n                    continue\n\n                count = 0\n                for new_perm_list_a in result:\n                    count += 1\n                    nrsa = perms2str_w(new_perm_list_a)\n                    nsa = len(nrsa)\n                \n                    print(f'{p}, {p2}: {sa}, {nsa} <- {group + 1}, {count}')\n                    if nsa < sa:\n                        rw = {'group': group + 1, 'perm': p, 'perm_2': p2, 'part_no': count, 'score': nsa, 'string': nrsa}\n                        rows.append(rw)\n\n    if len(rows) > 0:\n        df = pd.DataFrame(rows)\n        df = df.sort_values(by=['group', 'score'], ascending=[True, True])\n        df.to_csv(ADD_FILE, index=False)\n    add_df = pd.read_csv(ADD_FILE)\nelse:\n    add_df = pd.read_csv(ADD_FILE)\n    \nadf1 = add_df[add_df['group'] == 1]\nadf1 = adf1.sort_values(by=['score'], ascending=[True])\n\nadf2 = add_df[add_df['group'] == 2]\nadf2 = adf2.sort_values(by=['score'], ascending=[True])\n\nadf3 = add_df[add_df['group'] == 3]\nadf3 = adf3.sort_values(by=['score'], ascending=[True])\n\ns1 = adf1['string'].iloc[0]\ns2 = adf2['string'].iloc[0]\ns3 = adf3['string'].iloc[0]\nschedule = [s1, s2, s3]\n\nreplace_dict = {\n '1': '\ud83c\udf85',\n '2': '\ud83e\udd36',\n '8': '\ud83c\udf1f',\n '3': '\ud83e\udd8c',\n '4': '\ud83e\udddd',\n '5': '\ud83c\udf84',\n '6': '\ud83c\udf81',\n '7': '\ud83c\udf80'}\n\nfor k,v in replace_dict.items():\n    schedule[0] = schedule[0].replace(k, v)\n    schedule[1] = schedule[1].replace(k, v)\n    schedule[2] = schedule[2].replace(k, v)\n    \ncheck_if_good(schedule)\n\nscores = [len(schedule[0]), len(schedule[1]), len(schedule[2])]\nnws = [len(schedule[0].split('\ud83c\udf1f')) - 1, len(schedule[1].split('\ud83c\udf1f')) - 1, len(schedule[2].split('\ud83c\udf1f')) - 1]\nprint(f'Number of wildcards: {nws}')\n\n# WRITE SUBMISSION CSV\nsub = pd.DataFrame()\nsub['schedule'] = schedule\nsub.to_csv(f'{WRK_DIR}submission_wildcards_{str(scores[0])}_{str(scores[1])}_{str(scores[2])}.csv',index=False)\nsub.head()","ec49f6ca":"As everything is ok, now we'll save the found solution and then try to improve it even more using wildcards.","caab53e4":"# **REFERENCES**\n* https:\/\/www.kaggle.com\/starohub\/st-21-a-minmax-ctsp\n*https:\/\/www.kaggle.com\/yamqwe\/permutations-rebalancing-multiprocessing","d8e9acda":"Wow, we improved the solution quite a bit. Let's check it's the correct one and we haven't lost any permutations along the way.","4373eee6":"If you find this helpful dont forget to upvote it!!\n\nIf you are simply forking it without giving an upvote this suggests your greedy quality. It takes just one push to hit the like so don't be self-centered. ","9b049f29":"# Wildcards optimization\n\nWe'll use the code from the [notebook](https:\/\/www.kaggle.com\/yosshi999\/wildcard-postprocessing-using-dynamic-programming) created by [Yosshi999](https:\/\/www.kaggle.com\/yosshi999) to improve our solution with wildcards.","f0573359":"# Peek closely at the permutations in each string"}}