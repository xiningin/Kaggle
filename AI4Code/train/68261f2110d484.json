{"cell_type":{"d685bf85":"code","bb23d963":"code","5e7c913a":"code","27f413ef":"code","e9522268":"code","283f823c":"code","2a033d55":"code","5a4b9777":"code","31a0f376":"code","9b51b191":"markdown","40c2d8c4":"markdown","fa52b12b":"markdown"},"source":{"d685bf85":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport sklearn.preprocessing as preprocessing\nfrom sklearn.metrics import r2_score\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","bb23d963":"df = pd.read_csv('\/kaggle\/input\/used-car-dataset-ford-and-mercedes\/bmw.csv')\nprint(\"Data shape:\")\nprint(df.shape)\nprint(\"\\n\\n\")\n\nprint(\"First 5 rows in df:\")\nprint(df.head())\nprint(\"\\n\\n\")\n\nprint(\"Checking if there is Null:\")\nprint(df.isnull().sum())\nprint(\"\\n\\n\")\n\nprint(\"df describing:\")\nprint(df.describe())\nprint(\"\\n\\n\")\n\nprint(\"Checking duplicates:\")\nprint(df.duplicated().sum())\n\n# Removing duplicates\ndf=df.drop_duplicates(keep='first')\nprint(\"Duplicates are removed.\\n\\n\")\n\n\nprint(\"Checking duplicates:\")\nprint(df.duplicated().sum())","5e7c913a":"# Scatter plots of each pair of features\nsns.pairplot(data = df, hue = 'transmission')\nplt.show()","27f413ef":"# Scatter plots of each pair of features\nsns.pairplot(data = df, hue = 'fuelType')\nplt.show()","e9522268":"# Looking for outliers\nplt.figure(figsize=(40,20))\nsns.boxplot(data=df[['price', 'mileage']])","283f823c":"# Looking for outliers\nplt.figure(figsize=(40,20))\nsns.boxplot(data=df[['tax', 'mpg']])","2a033d55":"# Finding outliers by Tukey\u2019s box plot method\nq1=df.quantile(0.25)\nq2=df.quantile(0.75)\nIQR=q2-q1\n\nprint(\"Number of outliers is:\")\nprint(df[((df<(q1-1.5*IQR))|(df>(q2+1.5*IQR))).any(axis=1)].shape[0])    \n\n# Tukey's method show that there are almost 50% of data is outliers, so let's try to remove outliers by our hands\ndf = df[(df['tax'] <= 400) & (df['mpg'] <= 300) & (df['price'] <= 100000) & (df['mileage'] <= 200000)]\n","5a4b9777":"# Creating Dummy variables (for more information use link below)\n# https:\/\/towardsdatascience.com\/the-dummys-guide-to-creating-dummy-variables-f21faddb1d40\ndummies = pd.get_dummies(df[['transmission', 'model', 'fuelType']])\ndf = pd.concat([df, dummies], axis = 1)\nprint(df.head())","31a0f376":"# Splitting data into X, y - features and predictible variable\n# X = df.loc[:,['volatile acidity','chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'pH', 'sulphates', 'alcohol']]\nX = df.drop(['transmission', 'model', 'fuelType', 'price'], axis = 1)\nscaler = preprocessing.StandardScaler().fit(X)\nX = scaler.transform(X)\ny = df['price']\n\n\n# Splitting X, y into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=12345)\n\n\n# Linear Regression\nfrom sklearn.linear_model import LinearRegression\nimport sklearn.metrics as sm\nreg = LinearRegression().fit(X_train, y_train)\ny_pred = reg.predict(X_test)\n\n# Evaluating model\nprint(\"Linear Regression:\")\nprint('Train success rate : %',reg.score(X_train, y_train)*100)\nprint('Validation success rate : %',r2_score(y_test, y_pred))\nprint(\"\\n\\n\")\n### !!!!! R2 score is negative. It is caused by some strange values in test set and means that my model is bad, can't predict value for some test rows. \n### There are two ways:\n### 1) try not to remove outliers\n### 2) don't use this model at all\n\n\n\n# Random Forest Regression\nfrom sklearn.ensemble import RandomForestRegressor\nrf_reg = RandomForestRegressor(n_jobs = -1, random_state = 42).fit(X_train, y_train)\ny_pred = rf_reg.predict(X_test)\n# Evaluating model\nprint(\"Random Forest Regression:\")\nprint('Train success rate : %',rf_reg.score(X_train, y_train)*100)\nprint('Validation success rate : %',r2_score(y_test, y_pred))\nprint(\"\\n\\n\")\n# It looks like this model is an overfitted on train data\n# Let's try to use Grid Search to improve model\n# Let's look at deths of trees in random forest\nprint(\"Tree's depths:\")\nprint(plt.hist([est.get_depth() for est in rf_reg.estimators_]))\n\n\n# Grid Search for Random Forest Regression. Let's try to use Grid Search\nfrom sklearn.model_selection import GridSearchCV\nreg = RandomForestRegressor()\ngrid_values = {'n_estimators': [50, 100, 150],'max_depth': [25, 29, 30, 31], 'bootstrap': [True, False], 'n_jobs': [-1], 'random_state': [4]}\ngrid_reg_acc = GridSearchCV(reg, param_grid = grid_values, scoring = 'r2')\ngrid_reg_acc.fit(X_train, y_train)\ny_pred_acc = grid_reg_acc.predict(X_test)\n# Evaluating model\nprint(\"Random Forest Regression with Grid Search:\")\nprint('Train success rate : %',grid_reg_acc.score(X_train, y_train)*100)\nprint('Validation success rate : %',r2_score(y_test, y_pred_acc))\nprint(\"\\n\\n\")\nprint(\"Best parameters wich was choosen:\")\nprint(grid_reg_acc.best_params_)\nprint(\"\\n\\n\")\n\n\n\n# Also let's look how R2 score depends on max_depth of trees\nrf_scores = []\nfor md in range(1,35):\n    rf_reg = RandomForestRegressor(n_jobs = -1, random_state = 42, max_depth = md).fit(X_train, y_train)\n    y_pred = rf_reg.predict(X_test)\n    rf_scores = rf_scores + [rf_reg.score(X_train, y_train)*100]\nplt.figure(figsize=(40,20))\nplt.plot(list(range(1,35)), rf_scores)\n# Let's choose max_depth = 12 to optimize calculation time and save good R2 score.\nrf_reg = RandomForestRegressor(n_jobs = -1, random_state = 42, max_depth = 12).fit(X_train, y_train)\ny_pred = rf_reg.predict(X_test)\nprint(\"Random Forest Regression with max_depth = 12:\")\nprint('Train success rate : %',rf_reg.score(X_train, y_train)*100)\nprint('Validation success rate : %',r2_score(y_test, y_pred))\nprint(\"\\n\\n\")\n\n\n\n\n\n# XGBoost Regression\nfrom xgboost import XGBRegressor\nxgb_reg = XGBRegressor(max_depth = 3, learning_rate = 0.1, n_estimators = 100, verbosity = 0, random_state = 42).fit(X_train, y_train)\ny_pred = xgb_reg.predict(X_test)\n# Evaluating model\nprint(\"XGBoost Regression:\")\nprint('Train success rate : %',rf_reg.score(X_train, y_train)*100)\nprint('Validation success rate : %',r2_score(y_test, y_pred))\nprint(\"\\n\\n\")\n# It looks like this model is an overfitted on train data\n\n\n","9b51b191":"**EDA**","40c2d8c4":"**Building a model REGRESSIONS**","fa52b12b":"**Conclusion**\nThe best model is Random Forest Regression.\nBy the Grid Search the best set of parameters is {'bootstrap': True, 'max_depth': 25, 'n_estimators': 150, 'n_jobs': -1, 'random_state': 4}, but even at {'bootstrap': True, 'max_depth': 12, 'n_estimators': 100, 'n_jobs': -1, 'random_state': 4} R2 score is almost the same. So to save calculation time I think should be better to use second parameters set."}}