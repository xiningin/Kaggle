{"cell_type":{"602b3307":"code","68301ead":"code","4fa9e277":"code","f6cef1ae":"code","770a1725":"code","b456734b":"code","d765da32":"code","15320617":"code","fbec6ee2":"code","ea8fa31f":"code","422e5778":"code","c5bf0c7d":"code","8d883167":"code","3bacb0ca":"code","2cc6e383":"code","5de4438b":"code","3209eb73":"code","8334c974":"code","780ace92":"code","7b4fa87d":"code","4a5d6048":"code","b97ad781":"code","4d5e867f":"code","2a0764c4":"code","2f7878ad":"code","5237aa53":"code","01a09404":"code","e20b02f0":"code","82504820":"code","bec1bda7":"code","972dbea5":"code","1f06fb07":"code","5f7de271":"code","290b0ccc":"code","2faa6457":"code","2ea5a056":"markdown","69e8b6b5":"markdown","d5207f01":"markdown","4d7d84fb":"markdown","980c3f0f":"markdown","98b35b1e":"markdown","c6779514":"markdown","9787f3fc":"markdown","787170a3":"markdown","bac32e73":"markdown","1461f75f":"markdown","6f837314":"markdown","541001d9":"markdown","30c31715":"markdown","b6f7984e":"markdown"},"source":{"602b3307":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\nSEED = 4121995\n\nnp.random.seed(SEED)","68301ead":"train_df = pd.read_csv('\/kaggle\/input\/feedback-prize-2021\/train.csv')\ntrain_df.head()","4fa9e277":"!ls '\/kaggle\/input\/feedback-prize-2021\/test' | wc -l","f6cef1ae":"!ls '\/kaggle\/input\/feedback-prize-2021\/train' | wc -l","770a1725":"def split_essays(train_df, n):\n    if isinstance(n, float):\n        n = int(len(train_df.id.unique()) * n)\n    val_ids = np.random.choice(train_df.id.unique(), n, False)\n    train_df, val_df = train_df[~train_df.id.isin(val_ids)], train_df[train_df.id.isin(val_ids)]\n    return train_df, val_df","b456734b":"train_df, val_df = split_essays(train_df, 100)\ntrain_df.shape, val_df.shape","d765da32":"# _, dev_df = split_essays(train_df, 10000)\ndev_df = train_df\ndev_df.shape","15320617":"# These functions are inspired by this amazing notebook \n# https:\/\/www.kaggle.com\/erikbruin\/nlp-on-student-writing-eda\n\ndef get_unique_ids(df):\n    return df.id.unique()\n\ndef filter_essay(df, essay_id):\n    return df.query('id == @essay_id').reset_index(drop=True)\n\ndef read_essay_txt(essay_id, path='train'):\n    essay_file_path = f\"..\/input\/feedback-prize-2021\/{path}\/{essay_id}.txt\"\n    with open(essay_file_path, 'r') as essay_file:\n        return essay_file.read()\n        \ndef add_gap_rows_essay(df, essay_id, path):\n    \n    essay_df = filter_essay(df, essay_id)\n    essay_txt = read_essay_txt(essay_id, path)\n    \n    for index, row in essay_df.iterrows():\n        if index == essay_df.index[0]: \n            continue\n            \n        current_discourse_start = int(row['discourse_start'])\n        current_discourse_end = int(row['discourse_end'])\n        previous_discourse_start = int(essay_df.loc[index - 1, 'discourse_start'])\n        previous_discourse_end = int(essay_df.loc[index - 1, 'discourse_end'])\n\n        if previous_discourse_end != current_discourse_start - 1 and previous_discourse_end != current_discourse_start:\n            current_predstring = row['predictionstring']\n            previous_predstring = essay_df.loc[index - 1, 'predictionstring']\n\n            current_predstring_first_token = int(current_predstring.split()[0])\n            previous_predstring_last_token = int(previous_predstring.split()[-1])\n            \n            gap_tokens_list = np.arange(previous_predstring_last_token + 1,\n                                        current_predstring_first_token).tolist()\n\n            gap_row = {}  \n            gap_row['id'] = row['id']\n            gap_row['discourse_id'] = row['discourse_id']\n            gap_row['discourse_start'] = previous_discourse_end + 1\n            gap_row['discourse_end'] = current_discourse_start - 1\n            gap_row['discourse_text'] = essay_txt[previous_discourse_end+1: current_discourse_start]\n            gap_row['discourse_type'] = 'Gap'\n            gap_row['discourse_type_num'] = 'Gap'\n            gap_row['predictionstring'] = ' '.join([str(token) for token in gap_tokens_list])\n            \n            essay_df = essay_df.append(pd.Series(gap_row), ignore_index=True)\n    \n    essay_df = essay_df.sort_values('discourse_start').reset_index(drop=True)\n    return essay_df\n\ndef add_gap_rows_df(df, path):\n    new_df = None\n    essay_ids = get_unique_ids(df)\n    \n    for essay_id in essay_ids:\n        essay_df = add_gap_rows_essay(df, essay_id, path)\n        new_df = pd.concat([new_df, essay_df], axis=0, ignore_index=True)\n    \n    return new_df           \n        ","fbec6ee2":"%%time\n\n# Testing on one discourse\nadd_gap_rows_essay(dev_df, dev_df.id.values[30], 'train')","ea8fa31f":"%%time\n\n# dev_df = add_gap_rows_df(dev_df, 'train')","422e5778":"%%time \n\n# val_df = add_gap_rows_df(val_df, 'train')","c5bf0c7d":"# Add starting token feature\ndev_df['start_token'] = dev_df['predictionstring'].str.split().str[-1].shift(1).fillna(0).astype(int) + 1\nval_df['start_token'] = val_df['predictionstring'].str.split().str[-1].shift(1).fillna(0).astype(int) + 1\n\ndev_df.head(5)","8d883167":"%%time\n\n# Add full text length feature\ntrain_essays = os.listdir('\/kaggle\/input\/feedback-prize-2021\/train\/')\ntest_essays = os.listdir('\/kaggle\/input\/feedback-prize-2021\/test\/')\n\ntrain_essays_length = {id_.rstrip('.txt'): len(read_essay_txt(id_.rstrip('.txt')).split()) for id_ in train_essays}\ntest_essays_length = {id_.rstrip('.txt'): len(read_essay_txt(id_.rstrip('.txt'), 'test').split()) for id_ in test_essays}","3bacb0ca":"dev_df['len_essay'] = dev_df['id'].map(train_essays_length)\nval_df['len_essay'] = val_df['id'].map(train_essays_length)\ndev_df.head(10)","2cc6e383":"from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.base import TransformerMixin, BaseEstimator\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.decomposition import TruncatedSVD\n\nclass ExtraFeatures(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        X['end_token'] = X['start_token'] + X['discourse_text'].str.split().str.len()\n        X['tokens_from_start_to_end'] = X['end_token'] - X['start_token'] + 1\n        X['tokens_from_start_to_finish'] = X['len_essay'] - X['start_token'] + 1\n        X['tokens_from_end_to_finish'] = X['len_essay'] - X['end_token'] + 1\n        X['percent_read_before'] = X['start_token'] \/ X['len_essay']\n        X['percent_read_now'] = X['end_token'] \/ X['len_essay']\n        X['percent_remaining'] = (X['len_essay'] - X['end_token']) \/ X['len_essay']\n        X['percent_sentence'] = (X['end_token'] - X['start_token'] + 1) \/ X['len_essay']\n        \n        feats = ['percent_read_before', 'percent_read_now', 'percent_remaining', 'percent_sentence']\n        return X[feats].values\n    \n\ndef preprocess_data(X, pipeline=None):\n    if not pipeline:\n        \n        vectorizer_pipeline = Pipeline([\n            ('vectorizer', CountVectorizer(ngram_range=(1, 3), max_features=100000)),\n#             ('tfidf', TfidfTransformer()),\n#             ('pca', TruncatedSVD(n_components=0.9))\n        ])\n                \n        pipeline = FeatureUnion([\n            ('extra_features', ColumnTransformer([('end_token', ExtraFeatures(), ['start_token', 'len_essay', 'discourse_text'])])),\n            ('vectorizer', ColumnTransformer([('vectorizer', vectorizer_pipeline, 'discourse_text')]))\n        ])\n\n        \n        pipeline.fit(X)\n        \n    X = pipeline.transform(X)\n    return X, pipeline\n\ndef encode_labels(y, encoder=None):\n    if not encoder:\n        encoder = LabelEncoder()\n        encoder.fit(y)\n        \n    y = encoder.transform(y)\n    return y, encoder","5de4438b":"dev_df.head(1)","3209eb73":"X_train, y_train = dev_df[['start_token', 'len_essay', 'discourse_text']], dev_df['discourse_type']\nX_val, y_val = val_df[['start_token', 'len_essay', 'discourse_text']], val_df['discourse_type']\n\nX_train, pipeline = preprocess_data(X_train)\nX_val, _ = preprocess_data(X_val, pipeline)\n\ny_train, encoder = encode_labels(y_train)\ny_val, _ = encode_labels(y_val, encoder)","8334c974":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB, MultinomialNB\nfrom sklearn.linear_model import LogisticRegression","780ace92":"%%time\n\nmodel = LogisticRegression(C=1, dual=True, solver='liblinear')\nmodel.fit(X_train, y_train)\n\n# if hasattr(model, 'oob_score_'): print(model.oob_score_)\n\n# model = MultinomialNB()\n# model.fit(X_train, y_train)","7b4fa87d":"model.score(X_train, y_train)","4a5d6048":"dev_df['next_discourse_type'] = dev_df['discourse_type'].shift(-1)\ndev_df['next_id'] = dev_df['id'].shift(-1)\n\ndev_df.loc[\n    dev_df['next_id'] != dev_df['id'],\n    'next_discourse_type'\n] = 'NaN'","b97ad781":"discourse_next = pd.pivot_table(data=dev_df, index='discourse_type', columns='next_discourse_type', aggfunc='size')\ndiscourse_next = discourse_next.apply(lambda x: x \/ discourse_next.sum(axis=1))\ndiscourse_next = discourse_next[encoder.classes_].fillna(0)\ndiscourse_next","4d5e867f":"expectations = {}\nfor discourse_type, row in discourse_next.iterrows():\n    expectations[discourse_type] = row.values","2a0764c4":"import nltk\n\ndef predict_text(model, data, pipeline):\n    return model.predict_proba(pipeline.transform(data))\n\ndef predict_essay(model, essay_id, path, pipeline, max_iter, print_results=False):\n    essay_txt = read_essay_txt(essay_id, path)\n    essay_sentences = nltk.sent_tokenize(essay_txt)\n    essay_preds = {}\n    essay_preds['id'] = essay_id\n    essay_preds['discourse_type'] = []\n    essay_preds['predictionstring'] = []\n    \n#     print(len(essay_sentences))\n#     print(len(essay_txt.split()))\n    \n    start_token = 0\n    end_token = 0\n    start_sent = 0\n    end_sent = 1\n    iter_bad = 0\n    max_pred = 0\n    \n    start_end_sents, max_preds, argmax_preds = [], [], [] \n    stop = False\n    \n    prev_type = None\n    \n    while not stop: \n        data = {}\n        data['start_token'] = [start_token + 1]\n        data['len_essay'] = train_essays_length[essay_id] if path == 'train' else test_essays_length[essay_id]\n        data['discourse_text'] = [' '.join(essay_sentences[start_sent:end_sent])]\n        data = pd.DataFrame(data)[['start_token', 'len_essay', 'discourse_text']]\n        preds = predict_text(model, data, pipeline)\n        \n#         print('Before update:', np.argmax(preds))\n        if prev_type:\n            preds = update_preds(preds, prev_type)\n            \n#         print('After update:', np.argmax(preds), prev_type)\n\n        if preds.max() >= max_pred:\n            max_pred = preds.max()\n            start_end_sents.append([start_sent, end_sent])\n            max_preds.append(max_pred)\n            argmax_preds.append(preds.argmax())\n\n        else:\n            iter_bad += 1\n        \n#         print(start_sent, end_sent, encoder.inverse_transform([preds.argmax()])[0], preds.max(), max_pred, iter_bad)\n        end_sent += 1\n            \n#         print(start_end_sents, max_preds)\n                         \n        if iter_bad >= max_iter or end_sent > len(essay_sentences):\n            best_pred = np.argmax(max_preds)\n            best_start_end = start_end_sents[best_pred]\n            merged_sentence = ' '.join(essay_sentences[best_start_end[0]: best_start_end[-1]])\n            end_token = len(merged_sentence.split()) + end_token\n            prediction_string = ' '.join([str(token) for token in range(start_token, end_token)])\n            \n            essay_preds['discourse_type'].append(encoder.inverse_transform([argmax_preds[best_pred]])[0])\n            essay_preds['predictionstring'].append(prediction_string)\n            \n            if print_results: print('MATCH ------- \\n', merged_sentence, '\\n\\n', encoder.inverse_transform([argmax_preds[best_pred]])[0], '\\n\\n')\n            \n            start_token = end_token\n            start_sent = best_start_end[-1]\n            \n#             end_token = start_token + 1\n            end_sent = start_sent + 1\n            \n            iter_bad = 0\n            max_pred = 0\n            \n            prev_type = encoder.inverse_transform([argmax_preds[best_pred]])[0]\n            \n            start_end_sents, max_preds, argmax_preds = [], [], []\n            \n            \n        if start_sent == len(essay_sentences):\n            stop = True\n    \n    return essay_preds\n\ndef update_preds(preds, prev_type):\n    prev_type_expec = expectations[prev_type]\n    return preds * prev_type_expec\n\ndef predict_df(model, df, path, pipeline, max_iter=5):\n    essay_ids = df['id'].unique()\n    preds_df = None\n    for essay_id in essay_ids:\n        essay_preds = predict_essay(model, essay_id, path, pipeline, max_iter)\n        preds_df = pd.concat([preds_df, pd.DataFrame(essay_preds)], axis=0)\n        \n    return preds_df","2f7878ad":"val_df.id.unique()","5237aa53":"%%time\n\n_ = predict_essay(model, '570D8769BE33', 'train', pipeline, 1, print_results=True)","01a09404":"%%time\n\nval_preds_df = predict_df(model, val_df, 'train', pipeline, 1)\nval_preds_df.head()","e20b02f0":"def evaluate_df(df, pred_df):\n    essay_ids = df['id'].unique()\n    f1_scores = []\n    for essay_id in essay_ids:\n        f1_score = evaluate_essay(df, pred_df, essay_id)\n        f1_scores.append(f1_score)\n    return np.mean(f1_scores)\n        \ndef evaluate_essay(df, pred_df, essay_id, print_results=False):\n    essay_df = filter_essay(df, essay_id)\n    pred_essay_df = filter_essay(pred_df, essay_id)\n    pred_essay_df = pred_essay_df.loc[pred_essay_df['discourse_type'] != 'Gap', :]\n    f1_scores = []\n    for class_ in df['discourse_type'].unique():\n        f1_score = evaluate_class(essay_df, pred_essay_df, class_, print_results)\n        f1_scores.append(f1_score)\n        \n    return np.mean(f1_scores)\n        \ndef evaluate_class(df, pred_df, class_, print_results):\n    class_df = filter_class(df, class_)\n    pred_class_df = filter_class(pred_df, class_)\n    truths = class_df['predictionstring'].str.split(' ').tolist()\n    predictions = pred_class_df['predictionstring'].str.split(' ').tolist()\n    true_positives = 0\n    false_positives = 0\n    false_negatives = 0\n    matched_truths_idx = []\n    for prediction in predictions:\n        for i, truth in enumerate(truths):\n            if test_overlap(prediction, truth):\n                true_positives += 1 \n                matched_truths_idx.append(i)\n            else:\n                false_positives += 1\n        truths = remove_from_list(truths, matched_truths_idx)\n        matched_truths_idx = []\n        \n    false_negatives = len(truths)\n    \n    f1_score = calculate_f1(true_positives, false_positives, false_negatives)\n    \n    if print_results: print(class_, f1_score)\n        \n    return f1_score\n\n\ndef filter_class(df, class_):\n    return df.query('discourse_type == @class_')\n                \n        \ndef test_overlap(prediction, truth):\n    prediction_set = set(prediction)\n    truth_set = set(truth)\n#     print(overlap_fraction(prediction_set, truth_set), overlap_fraction(truth_set, prediction_set))\n    if overlap_fraction(prediction_set, truth_set) >= 0.5 and overlap_fraction(truth_set, prediction_set) >= 0.5:\n        return True\n    \n    \ndef overlap_fraction(set1, set2):\n    return len(set1.intersection(set2)) \/ len(set1)\n    \n    \ndef remove_from_list(list_, idx):\n    return [x for i, x in enumerate(list_) if i not in idx]\n\ndef calculate_f1(true_positives, false_positives, false_negatives):\n    precision = calculate_precision(true_positives, false_positives)\n    recall = calculate_recall(true_positives, false_negatives)\n    return 2 * precision * recall \/ (precision + recall) if (precision + recall) > 0 else 0\n    \n    \ndef calculate_precision(true_positives, false_positives):\n    return true_positives \/ (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n\ndef calculate_recall(true_positives, false_negatives):\n    return true_positives \/ (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0","82504820":"%%time\n\n# Test one essay\nevaluate_essay(val_df, val_preds_df, '570D8769BE33', True)","bec1bda7":"%%time\n\nevaluate_df(val_df, val_preds_df)","972dbea5":"test_ids = !ls '\/kaggle\/input\/feedback-prize-2021\/test'\ntest_ids = [id_.rstrip('.txt') for id_ in test_ids]\ntest_df = pd.DataFrame({'id': test_ids})\ntest_df['len_essay'] = test_df['id'].map(test_essays_length)","1f06fb07":"%%time\n\nsubmission = predict_df(model, test_df, 'test', pipeline, 1)\nsubmission.head()","5f7de271":"submission.columns = ['id', 'class', 'predictionstring']","290b0ccc":"# Drop gaps\nsubmission = submission.loc[submission['class'] != 'Gap', :]","2faa6457":"submission.to_csv('submission.csv', index=False)","2ea5a056":"# Introduction\n\nThe approach I'll use in this notebook is to build the bare minimum training and validation set and an algorithm maximizing the likelihood of an n-gram of sentences (or words) to be one of a discourse types using a RandomForestClassifier or a NaiveBayesClassifier on TFIDF or CountVectorized datasets.\n\n#### I'll do this without exploring the dataset, as I'm more interested in making a validation pipeline and an algorithm that I have in mind.","69e8b6b5":"# Prediction\n\n## Designing The Algorithm\n\nThe algorithm should take a full text and then output a dataframe of classes and prediction strings (tokens). ","d5207f01":"One thing that we need to add to the training set is parapgraphs or blocks of text which have no classification, and then we should add a label to them in order to train the classifier to also predict gaps in the text.","4d7d84fb":"# The Algorithm\n\nWhat I have in a mind is a simple algorithm that maximizes the likelihood of a TFIDF or Bag of words of sequences of sentences (or words) of being one of the presented discourse types.\n\nI don't know much about NLP, but this is the easiest way I can think about. \n\nFor example, let's say that we an essay, the algorithm would split this essay into sentences, then it would classify the first sentence alone and take it's maximum prediction as a baseline. \n\nThe algorithm would then add another sentence classify the two sentences together, and then add another and another. Hypothetically, since I will be training the simple model on block of discourse types, the likelihood would increase with increasing sentences, until it starts decreasing, and then we can select the block which maximized the likelihood of correct prediction according to the model.\n\nThen the algorithm would iterate again from the sentence following the previously predicted block of text.\n\nThe core of this approach can be used with any complex model, but I don't know if it would be suitable or not, since probably deep learning models could be capable of more without this brute forcing attempt, but I could be wrong since I don't know much about NLP.\n\nAnd of course this approach is naive, since it won't learn about the context of the essay, and hence won't be able to predict two evidence sentences following each other for example, and might consider them as one.","980c3f0f":"Now of course I don't want to use the whole training dataset right now, so I'll make another function to sample a small part for development purposes. I can use the previous function that I made, but I'll discard the training set it creates.","98b35b1e":"Now I'll make a transformer which expects starting token feature and text, then it uses them to calculate the ending token.","c6779514":"## Training the core model\n\nSince I like Random Forests, I'll stick with a RF Classifier.","9787f3fc":"# Evaluation\n\nAccording to the competition evaluation page\n\n1. For each sample, all ground truths and predictions for a given class are compared.\n2. If the overlap between the ground truth and prediction is >= 0.5, and the overlap between the prediction and the ground truth >= 0.5, the prediction is a match and considered a true positive. If multiple matches exist, the match with the highest pair of overlaps is taken.\n3. Any unmatched ground truths are false negatives and any unmatched predictions are false positives.\n","787170a3":"# Creating training and validation set","bac32e73":"It seems that gaps aren't always sentences, so I think that dropping gap lines that aren't full sentences or paragraphs could be beneficial as the model will always be passed TFIDF or Vectorized sentences, unless the approach is used but with maximizing the likelihood of ngrams of words.","1461f75f":"## Preprocessing the dataset\n\nTFIDF or Bag of Words could be used, <s>but I'll use a simple Bag of Words right now.<\/s> and I'll use TFIDF.\n\nThe data provides two features regarding position of the text which is discourse_start and discourse_end. I want to use them, but I'm think it would be easier to another feature which is the start token, since my model uses Bag of Words, so it would be easier to implement it into the prediction pipeline of the algorithm.","6f837314":"The training data has 15594 essays, which means that we can possibly spare more than 5 essays. But I don't know if we should.\n\nThe regular approach would be to split the dataset into an 80\/20 training\/validation split. <s>but until now this notebook hasn't made any rigorous algorithm, so I'll stick with 5 essays just to make it run.<\/s> \n\n<s>After I make sure that the pipeline is working, I can look into making a robust validation set that reflects public leaderboard score, and indicates how well we can do in the private dataset.<\/s>\n\nEvaluation one essay takes around 113 ms, so in order to minimize waiting and still be able to evaluate results, I'll use around 50 essays so that evaluation doesn't exceed 10 seconds.","541001d9":"Let's test the algorithm now with one essay.","30c31715":"# Submission","b6f7984e":"I'll make a validation set with a number of essays that is equal to the number of essays in the test set."}}