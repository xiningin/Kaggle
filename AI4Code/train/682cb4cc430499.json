{"cell_type":{"2f7a0e29":"code","7f6e702c":"code","32b09964":"code","f4fc0d1f":"code","cbc213f9":"code","f052b012":"code","3bcb68e0":"code","71ab8bdc":"code","a352183b":"code","1fe5a8fa":"code","d2a422c8":"code","37f6084d":"code","7f34dc11":"code","610059e4":"code","1b7df916":"code","eeea5fc5":"code","4b5f6b1a":"code","ddb69f8c":"code","6e755d94":"code","754792ef":"code","dad06aa3":"code","df960890":"code","e083ff51":"code","910e0c10":"code","f159a14a":"code","b040c6ca":"markdown","14790b94":"markdown","648ab718":"markdown","16b0fd3e":"markdown","3651c368":"markdown","e4dddaa7":"markdown","67d205fa":"markdown","2dd6ee47":"markdown","701d95c3":"markdown","8c74cde5":"markdown","89708399":"markdown","f60d3f47":"markdown","5be3d0e4":"markdown","742acd81":"markdown","a946a875":"markdown","5371c8e9":"markdown","e30ef98c":"markdown","99ccc9a8":"markdown","7795e029":"markdown","40794608":"markdown","7163c716":"markdown","2e1030aa":"markdown","e665d0fd":"markdown","74e51985":"markdown","21c81287":"markdown","f387f3c2":"markdown","92d94bb7":"markdown"},"source":{"2f7a0e29":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm_notebook\nimport seaborn as sns\nimport gc\nimport plotly.graph_objects as go\n\n# \/kaggle\/input\/ashrae-energy-prediction\/weather_test.csv\n# \/kaggle\/input\/ashrae-energy-prediction\/building_metadata.csv\n# \/kaggle\/input\/ashrae-energy-prediction\/train.csv\n# \/kaggle\/input\/ashrae-energy-prediction\/test.csv\n# \/kaggle\/input\/ashrae-energy-prediction\/sample_submission.csv\n# \/kaggle\/input\/ashrae-energy-prediction\/weather_train.csv","7f6e702c":"# Import datasets For train\n\ntrain_df = pd.read_csv('\/kaggle\/input\/ashrae-energy-prediction\/train.csv')\nweather_train_df = pd.read_csv('\/kaggle\/input\/ashrae-energy-prediction\/weather_train.csv')\nbuilding_meta_df = pd.read_csv('\/kaggle\/input\/ashrae-energy-prediction\/building_metadata.csv')\n\n# Import datasets For test\n\n# test_df = pd.read_csv('\/kaggle\/input\/ashrae-energy-prediction\/test.csv')\n# weather_test_df = pd.read_csv('\/kaggle\/input\/ashrae-energy-prediction\/weather_test.csv')\n# sample_submission = pd.read_csv('\/kaggle\/input\/ashrae-energy-prediction\/sample_submission.csv')\n","32b09964":"from pandas.api.types import is_datetime64_any_dtype as is_datetime\nfrom pandas.api.types import is_categorical_dtype\n\ndef reduce_mem_usage_2(df, use_float16=False):\n    \"\"\"\n    Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.        \n    \"\"\"\n    \n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n    \n    for col in df.columns:\n        if col == 'timestamp': continue\n        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n            continue\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == \"int\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype(\"category\")\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df","f4fc0d1f":"train_df = reduce_mem_usage_2(train_df ,use_float16=True)\nweather_train_df = reduce_mem_usage_2(weather_train_df ,use_float16=True)\nbuilding_meta_df = reduce_mem_usage_2(building_meta_df ,use_float16=True)","cbc213f9":"train_df = train_df.merge(building_meta_df, on='building_id', how='left')\ntrain_df = train_df.merge(weather_train_df, on=['site_id', 'timestamp'], how='left')\ndel weather_train_df, building_meta_df\ngc.collect();","f052b012":"train_df.timestamp = pd.to_datetime(train_df.timestamp)","3bcb68e0":"train_df['date'] = train_df.timestamp.dt.date\ntrain_df ['hour'] = train_df.timestamp.dt.hour","71ab8bdc":"# just first Let's see 5 first rows. this is my habit.\nprint(f'shape is {train_df.shape}')\ntrain_df.head()","a352183b":"# check first hypothesis :\ncorr = train_df.corr()\n# Don;t show upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\nf, ax = plt.subplots(figsize=(11, 9))\nsns.heatmap(corr, mask=mask)","1fe5a8fa":"train_df.isnull().sum() * 100 \/ train_df.shape[0]","d2a422c8":"fig, axes = plt.subplots(figsize=(14,6))\ntrain_df[['timestamp', 'meter_reading']].set_index('timestamp').resample('H').mean()['meter_reading'].plot(ax=axes, label='By hour', alpha=0.8).set_ylabel('Meter reading', fontsize=14)","37f6084d":"ax = sns.barplot(train_df.groupby(['primary_use']).size().reset_index(name='counts')['primary_use'], train_df.groupby(['primary_use']).size().reset_index(name='counts')['counts'])\nax.set(xlabel='Primary Usage', ylabel='# of records', title='Primary Usage vs. # of records')\nax.set_xticklabels(ax.get_xticklabels(), rotation=50, ha=\"right\")\nplt.show()","7f34dc11":"ax = sns.barplot(train_df.groupby('primary_use').meter_reading.agg('sum').reset_index()['primary_use'],\n                train_df.groupby('primary_use').meter_reading.agg('sum').reset_index()['meter_reading'])\nax.set(xlabel='Primary Usage', ylabel='# of records', title='Primary Usage vs. # of records')\nax.set_xticklabels(ax.get_xticklabels(), rotation=50, ha=\"right\")\nplt.show()","610059e4":"train_df.groupby('primary_use').meter.agg(pd.Series.mode).reset_index()","1b7df916":"ax = sns.barplot(['electricity', 'chiledwater', 'steam', 'hotwater'], train_df.meter.value_counts().to_frame()['meter'])\nax.set(xlabel='meter Types', ylabel='How much is used', title='meter Types vs. # of usage')","eeea5fc5":"fig, axes = plt.subplots(nrows=4, ncols=4)\nfig.set_figheight(12)\nfig.set_figwidth(15)\n# fig.tight_layout()\nfig.subplots_adjust(wspace=0.5)\nfig.subplots_adjust(hspace=0.5)\nprimary_uses = train_df.primary_use.unique()\n\nfor i, primary_use in enumerate(primary_uses):\n    sns.countplot(x=\"meter\", data = train_df[train_df.primary_use  == primary_use],ax=axes[i\/\/4,i%4]).title.set_text(str(primary_use))\n\n","4b5f6b1a":"meter_types = { 0 : 'electricity', 1 : 'chilledwater', 2 : 'steam', 3 : 'hotwater' }\n\n\nfig, axes = plt.subplots(nrows=4, ncols=4)\nfig.set_figheight(12)\nfig.set_figwidth(15)\n# fig.tight_layout()\nfig.subplots_adjust(wspace=0.5)\nfig.subplots_adjust(hspace=0.5)\nprimary_uses = train_df.primary_use.unique()\n\nfor i, primary_use in enumerate(primary_uses):\n    sns.barplot(train_df[train_df.primary_use == primary_use].groupby('meter').meter_reading.sum(),\n               np.vectorize(meter_types.get)(train_df[train_df.primary_use == primary_use].groupby(['meter'])['meter_reading'].mean().keys()),\n                ax=axes[i\/\/4,i%4]).title.set_text(str(primary_use))\n","ddb69f8c":"train_df.groupby('primary_use').square_feet.agg(['mean'])","6e755d94":"train_df.groupby('primary_use').year_built.agg(['mean'])","754792ef":"train_df.groupby('primary_use').meter_reading.agg(['mean'])","dad06aa3":"fig, axes = plt.subplots(8,2,figsize=(14, 30), dpi=100)\n\nfor i in range(train_df['site_id'].nunique()):\n    train_df[train_df.site_id == i][['timestamp', 'meter_reading']].set_index('timestamp').resample('H').mean()['meter_reading'].plot(ax = axes[i%8][i\/\/8])\n    axes[i%8][i\/\/8].legend();\n    axes[i%8][i\/\/8].set_title('site_id {}'.format(i), fontsize=13);\n    plt.subplots_adjust(hspace=0.45)","df960890":"fig, axes = plt.subplots(8,2,figsize=(14, 30), dpi=100)\nfor i, use in enumerate(train_df['primary_use'].value_counts().index.to_list()):\n    try:\n        train_df[(train_df['site_id'] == 13) & (train_df['primary_use'] == use)][['timestamp', 'meter_reading']].set_index('timestamp').resample('H').mean()['meter_reading'].plot(ax=axes[i%8][i\/\/8], alpha=0.8, label='By hour', color='tab:blue').set_ylabel('Mean meter reading', fontsize=13);\n        train_df[(train_df['site_id'] == 13) & (train_df['primary_use'] == use)][['timestamp', 'meter_reading']].set_index('timestamp').resample('D').mean()['meter_reading'].plot(ax=axes[i%8][i\/\/8], alpha=1, label='By day', color='tab:orange').set_xlabel('');\n        axes[i%8][i\/\/8].legend();\n    except TypeError:\n        pass\n    axes[i%8][i\/\/8].set_title(use, fontsize=13);\n    plt.subplots_adjust(hspace=0.45)","e083ff51":"train_df[(train_df['site_id'] == 13) & (train_df['primary_use'] == 'Education')][['timestamp', 'meter_reading']].set_index('timestamp').resample('H').mean()['meter_reading'].plot()","910e0c10":"meter_types = { 0 : 'electricity', 1 : 'chilledwater', 2 : 'steam', 3 : 'hotwater' }\ncountry=train_df[(train_df.site_id == 13) & (train_df.primary_use == 'Education') ].groupby('meter')['meter_reading'].sum()\n\nfig = go.Figure(go.Treemap(\n    labels=np.vectorize(meter_types.get)(country.keys()),\n    parents = [\"Total Energy Usage Type \"]*len(country),\n    values =  country\n))\n\nfig.show()","f159a14a":"\nfig, axes = plt.subplots(9,2,figsize=(14, 36), dpi=100)\nfor i, building in enumerate(train_df[(train_df['site_id'] == 13) & (train_df['primary_use'] == 'Education') & (train_df['meter'] == 2)]['building_id'].value_counts(dropna=False).index.to_list()):\n    train_df[(train_df['site_id'] == 13) & (train_df['primary_use'] == 'Education') & (train_df['meter'] == 2) & (train_df['building_id'] == building)][['timestamp', 'meter_reading']].set_index('timestamp').resample('H').mean()['meter_reading'].plot(ax=axes[i%9][i\/\/9], alpha=0.8, label='By hour', color='tab:blue').set_ylabel('Mean meter reading', fontsize=13);\n    train_df[(train_df['site_id'] == 13) & (train_df['primary_use'] == 'Education') & (train_df['meter'] == 2) & (train_df['building_id'] == building)][['timestamp', 'meter_reading']].set_index('timestamp').resample('D').mean()['meter_reading'].plot(ax=axes[i%9][i\/\/9], alpha=1, label='By day', color='tab:orange').set_xlabel('');\n    axes[i%9][i\/\/9].legend();\n    axes[i%9][i\/\/9].set_title('building_id: ' + str(building), fontsize=13);\n    plt.subplots_adjust(hspace=0.45)","b040c6ca":"# **Different Type of building** ","14790b94":"# Energy_Type Count for each primary_use\n\ncheck type of energy each primary_use has for it's buildings.","648ab718":"Show primary uses of one site id","16b0fd3e":"For **TRAIN** : \nSo we see some columns have many Nan Values.<br>\nSo bad we don't have all floor_counts | year_built . these two variable are super important( At least I think )\n\n","3651c368":" Now we just choose, site_id 13.\n let's check ","e4dddaa7":"# Time affect on meter_reading","67d205fa":"Now let's see buildings in this site id and this special primary use","2dd6ee47":"# What we want to check? (Goals) : \n\n1- ) **Linear Corellation check** : At least there must be a linear correlation between meter_reading and other features.\n\n2-) **Nan Check** : this is not hypothesis but. There must be no so much NAN in train and test. But may have in metadata and weather.\n\n3-) **Time affect on meter_reading** : is monthes of the year affect the amount of energy they use?\n\n4-) **Different Type of building** :  Let's see different type of buildings. By the type we can use different Feature Engineerings.\n\n5-) **Energy Usage By Building Type** :  I think we must have most energy usage by Education buildings. Let's check what about others.\n\n6-) **Mode in Energy Meter Type**\n\n7-) **Energy_Type Usage Count** :  let's see which energy type is used in most buildings\n\n8-) **Energy_Type Usage Count for each primary_use** :  for each primary use, how many of that primary use buildings are using different energy types.\n\n8.1-) **meter_reading of different energy sources for each primary use** :  KWH energy usage by different energy types in each primary use.\n       \n       as we can see here steam is eating money and energy\n\n9-) **Mean Of primary_use And year_built and square feet**  :  check some numeric data\n\n10-) **Noise Detection by hand** :  Let's remove noises by hand\n\n\n","701d95c3":"Until here we have 2 suspect : EDUCATION AND STEAM\n","8c74cde5":"# Mean Of square_feet","89708399":"# meter_reading of different energy sources for each primary use \n\nKWH energy usage for each energy type for each primay_use","f60d3f47":"# Noise Detection By hand \n\nWe have noises in data. To detect these noises, we need to see buildings and check.\n\nI think when we have sequential zeros for meter_reading ( for example 15 days. ) that is noise.\n\nI'll show just one sample. I'll create another notebook for noise detection using EDA\n\nShow Site ids","5be3d0e4":"# What is it all about?\n\nin this kernel for this special competition, We are working on predicting the energy consumption in KwH<br>\n\nFor now We just check train data\n\n\n![shifting trends of global energy usage](https:\/\/cdn.borntoengineer.com\/2018\/07\/1-Header.jpg)\n\n[image source ](www.borntoengineer.com)","742acd81":"# Mode in Energy Meter Type","a946a875":"#  **Energy Usage By Building Type** ","5371c8e9":"We can see 2 peak here\n\nThis notebook ( https:\/\/www.kaggle.com\/nroman\/eda-for-ashrae ) shows why we have these 2 peaks.","e30ef98c":"# Mean Of meter_reading by primary_use","99ccc9a8":"## Linear Corellation check","7795e029":"Nothing for services. What a huge missing data.","40794608":"STEAM. reasonable but was amazing to know steam is using this much energy.","7163c716":"# Energy_Type Usage Count\n\nlet's see which energy type is used in most buildings","2e1030aa":"So. if you want to delete all the noises you must do these last parts for every site id and pirmary use. then remove those zeros.\n\nThat's it.","e665d0fd":"# Resuluts :\n\n1-) There was no meaningful relation .\n\n2-) That was right for train. that was more right in test :|. we may have challanges for feature engineering and data filling.\n\nOne usefull way is to find mean of each building type ( primary_ use ) and fill with them for Floor_count and others.\n\n3-) It seems time is not main reason for indcreasing and decreasing of energy  \n\n4-) becuase of memory problems I'll find this answer later.\n\n5-) Education has the most building. After education : Public Other Office Lodging residental.\n\n6- Education has most energy usage. after education we have Office Entertainment Service and Lodging residental\n\n7-) Most of the buildings has Electrity. But does electricity use most energy? ( NO!!! we will see later).\n\n8-) As we can see most of the buildings are using electricity in each primary use\n\n8.1-) Steam is dominating here. so We can see one very important feature here. STEAM.\n\n9-) we saw some statistic data.\n\n10-) we found that we have very very much noise in our data. and we can remove them by hand too. not so hard. but need some time.","74e51985":"weird!!!! No Sensible linear relation between columns.","21c81287":"# Nan check","f387f3c2":"# Mean Of year_built","92d94bb7":"check this special site id and primary use energy type usage"}}