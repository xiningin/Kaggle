{"cell_type":{"c96ad57d":"code","b83355f7":"code","35dcd314":"code","a14acebe":"code","1c4ff71c":"code","f63c2d53":"code","53b5dcf4":"code","00dc2e12":"code","3499f260":"code","03378d45":"code","2d414e35":"code","789d7272":"code","7edcd8c8":"code","673ce63e":"code","e90c738e":"code","a0d4d5e4":"code","e5ad5f94":"code","800316c0":"code","750b3130":"code","3ff7439d":"code","ade30193":"code","a48735e8":"code","20d202a2":"code","def77fe5":"code","02a1d502":"code","edcb98de":"code","fba405c2":"code","453eda08":"code","bfa54a92":"code","eb2d625b":"code","c4e21289":"code","07c1ef0c":"code","f6ad7fef":"code","8eb84374":"code","24c437cf":"code","f1f33d54":"code","7db32b46":"code","9b8a52fb":"code","f8201ad5":"code","c55c96de":"code","cc7e1d0f":"code","115a5ecd":"code","c31351f1":"code","6c248df1":"markdown","b8ede7e3":"markdown","f04b97f1":"markdown","f3b30222":"markdown","980e5e46":"markdown","085ad158":"markdown","5efbf306":"markdown","41d8d683":"markdown","7b8a1731":"markdown","df053d01":"markdown","b5fa0016":"markdown","9d88b79e":"markdown","a63ed0ab":"markdown","6e2be8e5":"markdown","6eb3cb93":"markdown","11267d4b":"markdown","08bc4a75":"markdown","3a28c6a7":"markdown","3e059aa9":"markdown","f8a88810":"markdown","40a6641d":"markdown","b785ed94":"markdown","2cecf49f":"markdown","29a5e3d3":"markdown","6085a61b":"markdown","6aa43c02":"markdown"},"source":{"c96ad57d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport glob\nimport csv\nimport nltk\nimport re\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b83355f7":"case_files = glob.glob('\/kaggle\/input\/irlegprec\/IR-LegPrec\/Object_casedocs\/*')\nwith open(\"object_casedocs.csv\", \"w\") as output_file:\n    writer = csv.writer(output_file)\n    for f in case_files :\n        with open(f,\"r\") as input_file:\n            writer.writerow([\" \".join([line.strip() for line in input_file])])\n            \ndoc_array = os.listdir('\/kaggle\/input\/irlegprec\/IR-LegPrec\/Object_casedocs\/')\ndf_filename = pd.DataFrame(doc_array, columns = ['docID'])\ndf_filename","35dcd314":"relevance_csv = pd.read_csv('\/kaggle\/input\/irlegprec\/IR-LegPrec\/relevance_judgements_train.txt', delimiter = \" \", header = None)\nrelevance_csv.columns = [\"Query Number\", \"Q0\", \"docID\", \"Relevance score\"]\nrelevance_csv = relevance_csv.drop(columns = [\"Q0\"])\nrelevance_csv","a14acebe":"df = pd.read_csv('object_casedocs.csv', header = None)\ndf.columns = [\"Text\"]\ndf = pd.concat([df_filename,df], axis = 1)\ndf","1c4ff71c":"df.shape","f63c2d53":"df.info","53b5dcf4":"CHARS_TO_REMOVE = list('''.()\"',-:;''')\nVOCAB = {}","00dc2e12":"def sanitize_line(line):\n    for char_to_remove in CHARS_TO_REMOVE:\n        line = line.replace(char_to_remove, ' ')\n    return(line)\n\ndef plot_most_freq(points):\n    x = [word[0] for word in points[:20]]\n    y = [count[1] for count in points[:20]]\n    df1 = pd.DataFrame(list(zip(x, y)), columns =['Word', 'Frequency'])\n    \n    sns.set_theme(style=\"darkgrid\")\n    sns.set(rc={'figure.figsize':(20,10)})\n    sns.barplot(data = df1, x = 'Word', y = 'Frequency')\n    plt.show()\n\ndef fetch_corpus_from_file(filename):\n    if filename.endswith(\".txt\"):\n        with open(\"\/kaggle\/input\/irlegprec\/IR-LegPrec\/Object_casedocs\/{}\".format(filename)) as f:\n            for line in f.readlines():\n                line = sanitize_line(line)\n                words = line.lower().split()\n                for word in words:\n                    word = word.strip()\n                # if len(word) > 3:\n                    if word in VOCAB:\n                        VOCAB[word] += 1\n                    else:\n                        VOCAB[word] = 1\n\ndef fetch_corpus():\n    cnt = 0\n    for filename in os.listdir(\"\/kaggle\/input\/irlegprec\/IR-LegPrec\/Object_casedocs\"):\n        cnt = cnt + 1\n        fetch_corpus_from_file(filename)\n    print(cnt)\n    ","3499f260":"fetch_corpus()\ncounter = 0\nSORTED_VOCAB = sorted(VOCAB.items(), key=lambda k: k[1], reverse=True)\nfor (word, count) in SORTED_VOCAB:\n    print(word, count)\n    counter += 1\n    if counter > 20:\n        break\nprint(len(VOCAB))\nplot_most_freq(SORTED_VOCAB)","03378d45":"def preprocess_text(text, flagStemm = True, flagLemmatize = True, list_of_stopwords = None):\n\n    processed_text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n    \n    # Tokenization(convert from string to List)\n    list_of_text = processed_text.split()\n    \n    # Remove all stopwords\n    if list_of_stopwords is not None:\n        list_of_text = [word for word in list_of_text if word not in\n                   list_of_stopwords]\n    \n    # Lemmatization\n    if flagLemmatize == True:\n        lem = nltk.stem.WordNetLemmatizer()\n        list_of_text = [lem.lemmatize(word) for word in list_of_text]\n    \n    # Porter Stemming\n    if flagStemm == True:\n        ps = nltk.stem.porter.PorterStemmer()\n        list_of_text = [ps.stem(word) for word in list_of_text]\n        \n    # back to string from list\n    processed_text = \" \".join(list_of_text)\n    return processed_text\n","2d414e35":"df['Processed Text'] = df['Text'].apply(lambda x: preprocess_text(x, list_of_stopwords= ['the', 'of', 'to', 'and', 'in' ,'that', 'a' ,'was', 'is' ,'by' ], flagStemm = False, flagLemmatize=True))","789d7272":"df","7edcd8c8":"clean_text = df[\"Processed Text\"]\nclean_text","673ce63e":"train = pd.read_csv(\"\/kaggle\/input\/irlegprec\/IR-LegPrec\/Query_doc_train.txt\",delimiter = \"|\",header=None)\ntrain.columns = [\"Query_Number\",\"None\", \"Query\"]\ntrain=train.drop(columns=[\"Query_Number\",\"None\"])\ntrain","e90c738e":"train['Processed Query'] = train['Query'].apply(lambda x: preprocess_text(x, list_of_stopwords= ['the', 'of', 'to', 'and', 'in' ,'that', 'a' ,'was', 'is' ,'by' ],flagStemm = False, flagLemmatize= True))\ntrain","a0d4d5e4":"!pip install rank_bm25","e5ad5f94":"processed_query_array = [0]*50\nprocessed_corpus_array = [0]*3257\n\n# Storing the preprocessed results in 1D arrays\ntraining_array=df.iloc[:,1:].values\n\nfor i in range(3257):\n    processed_corpus_array[i] = training_array[i][0]\n\nquery_array=train.iloc[:,1:].values\n\nfor i in range(50):\n    processed_query_array[i] = query_array[i][0]","800316c0":"ID = df[\"docID\"]\nID = ID.str.rstrip('.txt')\nID","750b3130":"relevance_csv = relevance_csv.loc[relevance_csv['Relevance score'] == 1]\nrelevance_csv","3ff7439d":"VOCAB = {}\n\n\ndef store_term_df_values_utility(filename):\n    per_file = set()\n    if filename.endswith(\".txt\"):\n        with open(\"\/kaggle\/input\/irlegprec\/IR-LegPrec\/Object_casedocs\/{}\".format(filename)) as f:\n            for line in f.readlines():\n                line = sanitize_line(line)\n                words = line.lower().split()\n                for word in words:\n                    word = word.strip()\n                    # if len(word) > 3:\n                    per_file.add(word)\n                    \n    for word in per_file:\n        if word in VOCAB:\n            VOCAB[word] += 1\n        else:\n            VOCAB[word] = 1\n            \ndef store_term_df_values():\n    for filename in os.listdir(\"\/kaggle\/input\/irlegprec\/IR-LegPrec\/Object_casedocs\"):\n        store_term_df_values_utility(filename)\n\nstore_term_df_values()","ade30193":"test = pd.read_csv(\"\/kaggle\/input\/irlegprec\/IR-LegPrec\/Query_doc_test.txt\",delimiter = \"|\",header=None)\ntest.columns = [\"Query_Number\",\"None\", \"Query\"]\ntest=test.drop(columns=[\"Query_Number\",\"None\"])\ntest","a48735e8":"test['Processed Query'] = test['Query'].apply(lambda x: preprocess_text(x, list_of_stopwords= ['the', 'of', 'to', 'and', 'in' ,'that', 'a' ,'was', 'is' ,'by' ],flagStemm = False, flagLemmatize=True))\ntest","20d202a2":"processed_test_query_array = [0]*10\nquery_array=test.iloc[:,1:].values\n\nfor i in range(10):\n    processed_test_query_array[i] = query_array[i][0]\n    ","def77fe5":"def jaccard_similarity(doc1, doc2):\n    # List the unique words in a document\n    words_doc1 = set(doc1.lower().split())\n    words_doc2 = set(doc2.lower().split())\n\n    # Find the intersection of words list of doc1 & doc2\n    intersection = words_doc1.intersection(words_doc2)\n\n    # Find the union of words list of doc1 & doc2\n    union = words_doc1.union(words_doc2)\n\n    # Calculate Jaccard similarity score\n    # using length of intersection set divided by length of union set\n    return float(len(intersection)) \/ len(union)","02a1d502":"from itertools import islice\numap = {}\ncount = 0 \nfor j in range(50):\n    i = 0\n    rank_list = []\n    relevant_doc = relevance_csv.loc[relevance_csv['Query Number'] == \"AILA_Q\"+str(j+1)][\"docID\"]\n    for doc in processed_corpus_array:\n        umap[ID[i]] = jaccard_similarity(processed_query_array[j], doc)\n        i = i + 1\n    sorted_umap = sorted(umap.items(), key = lambda k: k[1], reverse = True)\n    for key,value in islice(sorted_umap,10):\n        rank_list.append(key)\n    \n    print(rank_list)\n    for j in rank_list:\n        for k in relevant_doc:\n              if (j==k):\n                    count=count+1\ncount","edcb98de":"MAP = count\/(50*10)\nMAP","fba405c2":"from gensim.models.doc2vec import Doc2Vec, TaggedDocument\nfrom nltk.tokenize import word_tokenize","453eda08":"#corpus_array_processed\ntagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(processed_corpus_array)]","bfa54a92":"model = Doc2Vec(tagged_data, vector_size=20, window=2, min_count=1, workers=4, epochs = 50)","eb2d625b":"count = 0\nfor i in range(50):\n    for j in model.docvecs.most_similar(positive=[model.infer_vector(word_tokenize(processed_query_array[i]))],topn=10)[0][0]:\n        temp = relevance_csv.loc[relevance_csv['Query Number'] == \"AILA_Q\"+str(i+1)][\"docID\"]\n        for k in temp.str.replace('C', ''):\n            if (j==k):\n                count=count+1\n\nprint(count)","c4e21289":"Precision = count\/500\nRecall = count\/195\n\nprint(Precision)\nprint(Recall)","07c1ef0c":"tokenized_corpus_array = [doc.split(\" \") for doc in processed_corpus_array]\nfrom rank_bm25 import BM25L\nbm25L = BM25L(tokenized_corpus_array)\nbm25L","f6ad7fef":"count = 0\nfor i in range(50):\n    retrieved_docs = bm25L.get_top_n(processed_query_array[i].split(\" \"), ID, n=10)\n    relevant_doc = relevance_csv.loc[relevance_csv['Query Number'] == \"AILA_Q\"+str(i+1)][\"docID\"]\n    print(\"AILA_Q\"+str(i+1))\n    print(retrieved_docs)\n    for j in retrieved_docs:\n        for k in relevant_doc:\n              if (j==k):\n                    count=count+1\ncount","8eb84374":"mean_average_precision = count\/(50*10)\nprint(\"MAP : \", mean_average_precision)","24c437cf":"from rank_bm25 import BM25Plus\nbm25Plus = BM25Plus(tokenized_corpus_array)\nbm25Plus","f1f33d54":"count = 0\nfor i in range(50):\n    retrieved_docs = bm25Plus.get_top_n(processed_query_array[i].split(\" \"), ID, n=10)\n    relevant_doc = relevance_csv.loc[relevance_csv['Query Number'] == \"AILA_Q\"+str(i+1)][\"docID\"]\n    print(\"AILA_Q\"+str(i+1))\n    print(retrieved_docs)\n    for j in retrieved_docs:\n        for k in relevant_doc:\n              if (j==k):\n                    count=count+1\ncount","7db32b46":"mean_average_precision = count\/(50*10)\nprint(\"MAP : \", mean_average_precision)","9b8a52fb":"count = 0\nfor i in range(50):\n    list_of_terms = {}\n    for word in processed_query_array[i].split(\" \"):\n        if word in VOCAB.keys():\n            list_of_terms[word] = VOCAB[word]   \n    search_keywords =[key for key,value in sorted(list_of_terms.items(), key = lambda k: k[1])][:150]\n    retrieved_docs = bm25Plus.get_top_n(search_keywords, ID, n=10)\n    relevant_doc = relevance_csv.loc[relevance_csv['Query Number'] == \"AILA_Q\"+str(i+1)][\"docID\"]\n    print(\"AILA_Q\"+str(i+1))\n    print(retrieved_docs)\n    for j in retrieved_docs:\n        for k in relevant_doc:\n              if (j==k):\n                    count=count+1\ncount","f8201ad5":"mean_average_precision = count\/(50*10)\nprint(\"MAP : \", mean_average_precision)","c55c96de":"from collections import OrderedDict\nlist_of_docs = ID.values\nwith open(\"trec_top_file_bm25L.txt\", \"w\") as output_file:\n    for i in range(10):\n        counter = 1\n        map_doc_scores = {} \n        sorted_scores = {}\n        retrieved_scores = bm25L.get_scores(processed_test_query_array[i].split(\" \"))\n        for j in range(3257):\n            map_doc_scores[retrieved_scores[j]] = list_of_docs[j]\n            sorted_scores = OrderedDict(sorted(map_doc_scores.items(), reverse = True))\n        for key,value in sorted_scores.items():\n            output_file.write(\"AILA_Q\"+ str(i+1) + \" Q0 \" + value + \" \" + str(counter) + \" \" + str(key) + \" bm25L\\n\")\n            counter = counter + 1","cc7e1d0f":"with open(\"trec_top_file_bm25Plus.txt\", \"w\") as output_file:\n    for i in range(10):\n        counter = 1\n        map_doc_scores = {} \n        sorted_scores = {}\n        retrieved_scores = bm25Plus.get_scores(processed_test_query_array[i].split(\" \"))\n        for j in range(3257):\n            map_doc_scores[retrieved_scores[j]] = list_of_docs[j]\n            sorted_scores = OrderedDict(sorted(map_doc_scores.items(), reverse = True))\n        for key,value in sorted_scores.items():\n            output_file.write(\"AILA_Q\"+ str(i+1) + \" Q0 \" + value + \" \" + str(counter) + \" \" + str(key) + \" bm25Plus\\n\")\n            counter = counter + 1","115a5ecd":"with open(\"trec_top_file_doc2vec.txt\", \"w\") as output_file:\n    for i in range(10):\n        counter = 1\n        map_doc_scores = {} \n        sorted_scores = {}\n        retrieved_scores = model.docvecs.most_similar(positive=[model.infer_vector(word_tokenize(processed_test_query_array[i]))],topn=3257)\n        for j in range(3257):\n            map_doc_scores[retrieved_scores[j][0]] = retrieved_scores[j][1]\n        for key,value in map_doc_scores.items():\n            output_file.write(\"AILA_Q\"+ str(i+1) + \" Q0 \" + str(value) + \" \" + str(counter) + \" C\" + str(key) + \" doc2vec\\n\")\n            counter = counter + 1","c31351f1":"umap = {}\ncount = 0 \nwith open(\"trec_top_file_jaccard.txt\", \"w\") as output_file:\n    for j in range(10):\n        i = 0\n        counter = 1\n        relevant_doc = relevance_csv.loc[relevance_csv['Query Number'] == \"AILA_Q\"+str(j+1)][\"docID\"]\n        for doc in processed_corpus_array:\n            umap[ID[i]] = jaccard_similarity(processed_test_query_array[j], doc)\n            i = i + 1\n        sorted_umap = sorted(umap.items(), key = lambda k: k[1], reverse = True)\n        for key,value in sorted_umap:\n            output_file.write(\"AILA_Q\"+ str(i+1) + \" Q0 \" + str(value) + \" \" + str(counter) + \" \" + str(key) + \" jaccard\\n\")\n            counter = counter + 1\n\n        ","6c248df1":"### Jaccard Similarity","b8ede7e3":"# IR Project 2021\n\n## Legal Precedent Retrieval (LEGPREC)\n> In countries following the Common Law system (e.g., India, UK, Canada, Australia, andmany others), there are two primary sources of law -- (a) Statutes which are the written laws(e.g. IPC Section 302, Constitution Article 19) and (b)  Precedents or judgements of priorcases delivered by a court, which involve similar legal facts and issues are the current case,but are not directly indicated in the written law.While working on a new case a legal practitioner often relies on these statutes andprecedents to understand how the Court has discussed, argued and behaved in similarscenarios. This task is aimed at creating retrieval systems capable of addressing thisproblem\n\n\n### Team Members : \n\n1. Sarthak Johnson Prasad (18CS10049)\n1. Pankaj Kumar Agarwal (18CS30031)\n1. A Nithin Krishna (18CS30001)\n1. Narayan Gupta (18CS30030)","f04b97f1":"#### We return the top 10 relevant documents for each train query","f3b30222":"New data with processed text","980e5e46":"#### Before preprocessing text in docs let us see how our data looks like!","085ad158":"#### Creating a training dataframe from the train queries given","5efbf306":"# 2) Preprocessing Text in Docs","41d8d683":"#### We make a list of most frequent words that will enact as stop words in our case and we will remove them to make our model work more efficiently.","7b8a1731":"#### Next we store all the training query data and their relevant document data which is provided to us","df053d01":"# 3) Preprocessing Text in Queries","b5fa0016":"#### First we contain all the case files in a single csv (comma-seperated) file","9d88b79e":"### Doc2Vec","a63ed0ab":"### BM25Plus","6e2be8e5":"### BM25Plus (with rare terms as search keys)","6eb3cb93":"## Text preprocessing is done in following 4 steps:\n\n### 1) Convert all sentences to lowercase, remove punctuation and any special characters\n\n### 2) Remove all stopwords\n\n### 3) Stemming (Porter Stemming)\n\n### 4) Lemmatization","11267d4b":"\n\n#### First we show a result if in case one of the docs is searched as a query. BM25 returns top 10 relevant results,with the original doc being the first one","08bc4a75":"### First we define the function use to preprocess the text.\n\nHere we NLTK (Natural language toolkit) package for removing Stopwords, Stemming and Lemmatization.\n\nLater we will shift to Industrial level NLP toolkit named SpaCy","3a28c6a7":"#### Mean Average Precision (Considering for P@10)","3e059aa9":"#### All libraries required are written below","f8a88810":"### BM25L","40a6641d":"# 5) Generating relevant documents and trec_top_file for Test Queries","b785ed94":"#### Preprocessing the queries as same as we did for docs","2cecf49f":"# 4) Ranking Relevant Documents for Train Queries","29a5e3d3":"Removing the stopwords","6085a61b":"We next take into consideration the top 10 frequent words : \n\n**the, of, to, and, in, that, a , was, is, by**","6aa43c02":"# 1) Data Handling"}}