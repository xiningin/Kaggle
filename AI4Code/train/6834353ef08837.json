{"cell_type":{"20851851":"code","96ca3a0f":"code","bdfeb6f9":"code","a6fbf327":"code","41dc797f":"code","f9cc98e6":"code","0fd2d12c":"code","92405939":"code","eb036ad0":"code","333f768c":"code","7248b834":"code","513e4b4d":"code","74a95189":"code","1b39f5ae":"code","80898c99":"code","43f05c17":"code","0eba182e":"code","37fce917":"code","053cc20c":"code","38833710":"code","35742bba":"code","7e4bf3ae":"code","54f93f2c":"markdown","5e469eb1":"markdown","afa071be":"markdown","11fb8e53":"markdown","8bd87f07":"markdown","634b719c":"markdown","9570549e":"markdown","e333a192":"markdown","c3bb71a3":"markdown","4145e208":"markdown","e9ad81f6":"markdown","3e3dbc42":"markdown","23c79298":"markdown"},"source":{"20851851":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior() \nimport matplotlib.pyplot as plt","96ca3a0f":"df = pd.read_csv(\"\/kaggle\/input\/default-of-credit-card-clients-dataset\/UCI_Credit_Card.csv\", index_col=\"ID\")","bdfeb6f9":"df","a6fbf327":"# Kategorik veriler i\u00e7in kurallar\ncategoric_attribute_information = {\n    \"SEX\": [1,2],\n    \"EDUCATION\": [1, 2, 3, 4],\n    \"MARRIAGE\": [1, 2, 3]\n}\n\nfor column in categoric_attribute_information.keys():\n    unique_values = list(set(df[column].tolist()))\n    if unique_values == categoric_attribute_information[column]:\n        print(\"DO\u011eRU\", column, categoric_attribute_information[column], \"==\", unique_values, \"\\n\")\n    else:\n        print(\"HATA!\", column, categoric_attribute_information[column], \"!=\", unique_values, \"\\n\")","41dc797f":"print(\"En k\u00fc\u00e7\u00fck ya\u015f:\", min(df[\"AGE\"].tolist()), \"\\n\")\nprint(\"En b\u00fcy\u00fck ya\u015f:\", max(df[\"AGE\"].tolist()), \"\\n\")","f9cc98e6":"columns_starts_with_pay = [column for column in df.columns if column[:4] == \"PAY_\" and len(column) == 5]\n\nfor column in columns_starts_with_pay:\n    unique_values = list(set(df[column].tolist()))\n    for value in unique_values:\n        if not ((value == -1) or (value > 0)):\n            print(\"HATA!\", column, \"=\", value)","0fd2d12c":"def combine_categories(x):\n    if x in [4, 5, 6]:\n        return 0\n    else:\n        return x\n\ndf[\"EDUCATION\"] = df[\"EDUCATION\"].apply(\n    lambda x: combine_categories(x)\n)","92405939":"list(set(df[\"EDUCATION\"].tolist()))","eb036ad0":"df.info()","333f768c":"# E\u011fitim seviyesi kategorileri\neducation_categories = {\n    0: \"others\",\n    1: \"graduate_student\",\n    2: \"university\",\n    3: \"high_school\",\n}\n# Medeni durum kategorileri\n# Bu kategoriler yukar\u0131da linkini verdi\u011fim kayna\u011fa g\u00f6re veri sa\u011flay\u0131c\u0131s\u0131 taraf\u0131ndan sonradan d\u00fczeltilen kategorilerdir\nmarriage_categories = {\n    0: \"others\",\n    1: \"married\",\n    2: \"single\",\n    3: \"divorce\"\n}\n\nfor category in education_categories.keys():\n    df[\"EDUCATION\"][df[\"EDUCATION\"] == category] = education_categories[category]\n    \nfor category in marriage_categories:\n    df[\"MARRIAGE\"][df[\"MARRIAGE\"] == category] = marriage_categories[category]\n    \ndf","7248b834":"# One Hot Encoder\ncategoric_variables = df.select_dtypes(\n    include=[np.object]\n).columns.tolist()\ndf = pd.get_dummies(df, prefix=categoric_variables)\n\n# Hedef de\u011fi\u015fkeni say\u0131saldan kategorik tipe d\u00f6n\u00fc\u015ft\u00fcr\u00fcld\u00fc\ndf[\"default.payment.next.month\"][df[\"default.payment.next.month\"] == 1] = \"Yes\"\ndf[\"default.payment.next.month\"][df[\"default.payment.next.month\"] == 0] = \"No\"\n\ndf","513e4b4d":"# 0 - 1 Normalizasyon\nnumeric_variables = df.select_dtypes(\n    exclude=[np.object]\n).columns.tolist()\nfor variable in numeric_variables:\n    data = list(set(df[variable].tolist()))\n    min_value = min(data)\n    max_value = max(data)\n    df[variable] = df[variable].apply(\n        lambda x: (x-min_value)\/(max_value-min_value)\n    )\n    \ndf","74a95189":"count_yes = df[\"default.payment.next.month\"].tolist().count(\"Yes\")\ncount_no = df[\"default.payment.next.month\"].tolist().count(\"No\")\nprint(\"Yes say\u0131s\u0131:\", count_yes)\nprint(\" No say\u0131s\u0131:\", count_no)\nprint(\" Yes oran\u0131:\", count_yes \/ (count_yes+count_no))","1b39f5ae":"df = df.rename(columns={\"default.payment.next.month\": \"target\"})\n\nX = df.drop(columns=[\"target\"]).values\ny = df.filter([\"target\"])\ny = pd.get_dummies(y, prefix=[\"target\"]).values\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.33, random_state=42\n)","80898c99":"X_train.shape","43f05c17":"X_test.shape","0eba182e":"y_train.shape","37fce917":"y_test.shape","053cc20c":"split = int(len(y_test)\/2)\ninputX = X_train\ninputY = y_train\ninputX_valid = X_test[:split]\ninputY_valid = y_test[:split]\ninputX_test = X_test[split:]\ninputY_test = y_test[split:]","38833710":"input_nodes = inputX.shape[1]\n\nmultiplier = 3\n\nhidden_nodes1 = input_nodes\nhidden_nodes2 = round(hidden_nodes1 * multiplier)\nhidden_nodes3 = round(hidden_nodes2 * multiplier)\n\npkeep = tf.placeholder(tf.float32)\n\n# Input\nx = tf.placeholder(tf.float32, [None, input_nodes])\n\n# Layer 1\nW1 = tf.Variable(tf.truncated_normal([input_nodes, hidden_nodes1], stddev = 0.15))\nb1 = tf.Variable(tf.zeros([hidden_nodes1]))\ny1 = tf.nn.sigmoid(tf.matmul(x, W1) + b1)\n\n# Layer 2\nW2 = tf.Variable(tf.truncated_normal([hidden_nodes1, hidden_nodes2], stddev = 0.15))\nb2 = tf.Variable(tf.zeros([hidden_nodes2]))\ny2 = tf.nn.sigmoid(tf.matmul(y1, W2) + b2)\n\n# Layer 3\nW3 = tf.Variable(tf.truncated_normal([hidden_nodes2, hidden_nodes3], stddev = 0.15)) \nb3 = tf.Variable(tf.zeros([hidden_nodes3]))\ny3 = tf.nn.sigmoid(tf.matmul(y2, W3) + b3)\ny3 = tf.nn.dropout(y3, pkeep)\n\n# Layer 4\nW4 = tf.Variable(tf.truncated_normal([hidden_nodes3, 2], stddev = 0.15)) \nb4 = tf.Variable(tf.zeros([2]))\ny4 = tf.nn.softmax(tf.matmul(y3, W4) + b4)\n\n# Output\ny = y4\ny_ = tf.placeholder(tf.float32, [None, 2])\n\ntraining_epochs = 100\ntraining_dropout = 0.9\ndisplay_step = 10\nn_samples = y_train.shape[0]\nbatch_size = 2048\nlearning_rate = 0.01\n\n# Cross entropy\ncost = -tf.reduce_sum(y_ * tf.log(y))\n\noptimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n\ncorrect_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\naccuracy_summary = []\ncost_summary = []\nvalid_accuracy_summary = [] \nvalid_cost_summary = [] \nstop_early = 0","35742bba":"with tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    \n    for epoch in range(training_epochs):\n        for batch in range(int(n_samples\/batch_size)):\n            batch_x = inputX[batch*batch_size : (1+batch)*batch_size]\n            batch_y = inputY[batch*batch_size : (1+batch)*batch_size]\n            \n            sess.run([optimizer], feed_dict={\n                x: batch_x,\n                y_: batch_y,\n                pkeep: training_dropout\n            })\n            \n        if (epoch) % display_step == 0:\n            train_accuracy, newCost = sess.run([accuracy, cost], feed_dict={\n                x: inputX,\n                y_: inputY,\n                pkeep: training_dropout\n            })\n            \n            valid_accuracy, valid_newCost = sess.run([accuracy, cost], feed_dict={\n                x: inputX_valid,\n                y_: inputY_valid,\n                pkeep: 1\n            })\n            \n            print(\n                \"Epoch:\", epoch,\n                \"Acc =\", \"{:.5f}\".format(train_accuracy),\n                \"Cost =\", \"{:.5f}\".format(newCost),\n                \"Valid_Acc =\", \"{:.5f}\".format(valid_accuracy),\n                \"Valid_Cost = \", \"{:.5f}\".format(valid_newCost)\n            )\n            \n            accuracy_summary.append(train_accuracy)\n            cost_summary.append(newCost)\n            valid_accuracy_summary.append(valid_accuracy)\n            valid_cost_summary.append(valid_newCost)\n            \n            if valid_accuracy < max(valid_accuracy_summary) and epoch > 100:\n                stop_early += 1\n                if stop_early == 15:\n                    break\n            else:\n                stop_early = 0\n                \n    print(\"Optimization Finished!\")","7e4bf3ae":"fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n\naxes[0].set_ylabel(\"Cost\", fontsize=14)\naxes[0].plot(cost_summary, color='blue')\naxes[0].plot(valid_cost_summary, color='green')\n\naxes[1].set_ylabel(\"Accuracy\", fontsize=14)\naxes[1].set_xlabel(\"Epoch\", fontsize=14)\naxes[1].plot(accuracy_summary, color='blue')\naxes[1].plot(valid_accuracy_summary, color='green')\nplt.show()","54f93f2c":"## Model Ba\u015far\u0131s\u0131\nTest i\u00e7in olan cost ve accuracy mavi renkte, validasyon i\u00e7in g\u00f6sterilen cost ve accuracy ise ye\u015fil renktedir.","5e469eb1":"## Model","afa071be":"# Kontrol\n\n## Anormallikler\n\n\u0130\u00e7e aktar\u0131lan veri seti i\u00e7erisindeki g\u00f6zlemlerde de\u011fi\u015fkenlerin ald\u0131\u011f\u0131 de\u011ferlerin veri sa\u011flay\u0131c\u0131s\u0131 taraf\u0131ndan verilen bilgiler ile uyu\u015fup uyu\u015fmad\u0131\u011f\u0131n\u0131n kontrol\u00fc.","11fb8e53":"Veri sa\u011flay\u0131s\u0131 taraf\u0131ndan bu de\u011fi\u015fkenler i\u00e7in verilen al\u0131nabilecek de\u011ferler aras\u0131nda 0 ve -2 verilmemi\u015ftir. Bu de\u011ferlerin de ne anlama geldi\u011fini bilmiyoruz. A\u015fa\u011f\u0131daki linkte bu veri seti hakk\u0131nda veri sa\u011flay\u0131s\u0131ndan al\u0131nan ekstra bilgiler mevcuttur.\n\nhttps:\/\/www.kaggle.com\/uciml\/default-of-credit-card-clients-dataset\/discussion\/34608#latest-325928\n\nBu kayna\u011fa g\u00f6re anormallik tespit etti\u011fimiz de\u011fi\u015fkenler i\u00e7in veri sa\u011flay\u0131c\u0131s\u0131n\u0131n verdi\u011fi bilgiler a\u015fa\u011f\u0131daki gibidir;\n\n- X3: Education (1 = graduate school; 2 = university; 3 = high school; 0, 4, 5, 6 = others).\n- X4: Marital status (1 = married; 2 = single; 3 = divorce; 0=others).\n- X6 - X11: History of past payment (-2: No consumption; -1: Paid in full; 0: The use of revolving credit; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above).\nBurada e\u011fitim seviyesi de\u011fi\u015fkeninde 0, 4, 5, 6 kategorilerini tek kategori alt\u0131nda toplamak haricinde yap\u0131lacak bir\u015fey yok gibi g\u00f6r\u00fcn\u00fcyor.\n\nAyr\u0131ca bu veri seti i\u00e7erisindeki g\u00f6zlemlerin hem bireysel kredi kart\u0131 sahibi m\u00fc\u015fterilere hem de ek karta sahip m\u00fc\u015fterilere ait olabilece\u011fi bilgisi de verilmi\u015ftir bu durumda Taiwan da kredi kart\u0131 alma ko\u015fullar\u0131 aras\u0131nda minimum ya\u015f\u0131n ek kart i\u00e7in 16 oldu\u011fu bilgisine dayanarak veri seti i\u00e7erisindeki ya\u015f aral\u0131\u011f\u0131n\u0131 tekrardan do\u011frulam\u0131\u015f olduk.","8bd87f07":"## Eksik Veri\nVeri seti i\u00e7erisinde eksik de\u011fer i\u00e7eren bir de\u011fi\u015fken ve g\u00f6zlem yoktur.","634b719c":"Burada cinsiyet verisini i\u00e7eren de\u011fi\u015fkene ait g\u00f6zlemlerde bir anormallik olmad\u0131\u011f\u0131 tespit edildi fakat hem e\u011fitim seviyesi hem de medeni durum de\u011fi\u015fkenlerine ait g\u00f6zlemlerde ortak olarak 0 kategorisi veri sa\u011flay\u0131c\u0131s\u0131 taraf\u0131ndan verilen kategoriler aras\u0131nda yer almamaktad\u0131r. Bu kategori e\u011fitim seviyesi ve medeni durumun belirtilmedi\u011fini ifade ediyor olabilir.\n\nE\u011fitim durumunda ise di\u011fer diye bir kategori olmas\u0131na ra\u011fmen 5 ve 6 olmak \u00fczere fazladan iki kategori daha oldu\u011fu tespit edildi. Daha sonradan eklenmi\u015f kategoriler olabilir. Bunlar ile t\u00fcm anormallikleri tespit ettikten sonra ilgilenece\u011fim.\n<hr>\nVeri sa\u011flay\u0131s\u0131 taraf\u0131ndan ya\u015f de\u011fi\u015fkeninin alabilece\u011fi de\u011ferler hakk\u0131nda bir bilgi verilmemi\u015ftir. Fakat bu veri setinin Taiwanda kredi kart\u0131 sahibi insan oldu\u011funu bilerek basit\u00e7e m\u00fcmk\u00fcn olabilecek minimum ve maksimum ya\u015f\u0131 ara\u015ft\u0131rabiliriz. A\u015fa\u011f\u0131da linki verilmi\u015f kaynakta Taiwanda kredi kart\u0131 alabilmek i\u00e7in gerekli minimum ya\u015f kriterinin 20 oldu\u011fu belirtilmekte.\n\nhttps:\/\/www.hsbc.com.tw\/en-tw\/credit-cards\/faq\/","9570549e":"Tensorflow model inspired by [Ilias Siamplis](https:\/\/www.kaggle.com\/isiablis)","e333a192":"G\u00f6zlemler aras\u0131ndaki en k\u00fc\u00e7\u00fck ya\u015f kurala uydu\u011fundan burada bir problem yok. En b\u00fcy\u00fck ya\u015f i\u00e7in bir kural yok fakat 79 de\u011feri makul g\u00f6r\u00fcn\u00fcyor.\n<hr>\nVeri sa\u011flay\u0131s\u0131 taraf\u0131ndan PAY_0 - ... - PAY_6  de\u011fi\u015fkenleri i\u00e7in verilen kural a\u015fa\u011f\u0131daki gibidir:","c3bb71a3":"$$ \ntest(x) = \\left\\{\n\\begin{array}{}\n      True & x=-1 \\\\\n      True & x>0\\\\\n\\end{array} \n\\right.\n$$","4145e208":"# Modelleme\n## Hedef Kategorilerin Da\u011f\u0131l\u0131m\u0131\nHedef de\u011fi\u015fkenin kategorileri aras\u0131ndaki orana bak\u0131ld\u0131\u011f\u0131nda dengesiz bir da\u011f\u0131l\u0131m oldu\u011fu g\u00f6r\u00fclmektedir. Bu durum olu\u015facak modelin ba\u015far\u0131s\u0131n\u0131 negatif etkileyecektir.","e9ad81f6":"# \u00d6n i\u015fleme\n## Say\u0131salla\u015ft\u0131rma\n\nBu veri seti i\u00e7erisindeki t\u00fcm de\u011fi\u015fkenler say\u0131sald\u0131r yani bir say\u0131salla\u015ft\u0131rma gereksinimi yoktur. Fakat asl\u0131nda kategorik olan medeni hal de\u011fi\u015fkeni i\u00e7erisindeki verilerin birbiri \u00fczerinde bir b\u00fcy\u00fckl\u00fck durumu olmad\u0131\u011f\u0131ndan bu de\u011fi\u015fkeni ve ayr\u0131ca e\u011fitim seviyesi de\u011fi\u015fkenini say\u0131saldan kategori\u011fe d\u00f6n\u00fc\u015ft\u00fcr\u00fcp one hot encoder ile tekrar say\u0131salla\u015ft\u0131raca\u011f\u0131m.","3e3dbc42":"## Verinin E\u011fitim \u0130\u00e7in Haz\u0131rlanmas\u0131","23c79298":"## Normalizasyon"}}