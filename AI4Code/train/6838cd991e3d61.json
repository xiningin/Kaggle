{"cell_type":{"3185da36":"code","f7e359e4":"code","a0ad634e":"code","08bdd88b":"code","8602c02d":"code","9b81890c":"code","6ddb4c6c":"code","8b77bfe2":"code","f5584c82":"code","b6f6ef66":"code","d058f866":"code","ca100d6d":"code","02a0872e":"code","fbfff585":"code","5b616d3a":"code","e1c8975f":"code","42d1f588":"code","8a07903b":"code","4e661252":"code","bf128faf":"code","2fa07174":"markdown","29531d07":"markdown","6bcba673":"markdown","68ef0a0e":"markdown","6ac36a50":"markdown","aaff261f":"markdown","e5c9b014":"markdown","c5879f6f":"markdown","67b998c0":"markdown","f2fd837a":"markdown","29051f2e":"markdown","5f513859":"markdown","50654dd5":"markdown","2fe6322a":"markdown","3d1e843a":"markdown","78906577":"markdown","ab922122":"markdown","2ae43389":"markdown","2eb8b583":"markdown","fc358965":"markdown","1dcccab2":"markdown"},"source":{"3185da36":"import warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics.regression import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn.linear_model import LinearRegression, LassoCV, Lasso\nfrom sklearn.ensemble import RandomForestRegressor","f7e359e4":"data = pd.read_csv('..\/input\/winequality-white.csv')","a0ad634e":"data.head()","08bdd88b":"data.info()","8602c02d":"y = data['quality']\nX = data.drop('quality', axis=1)\n\nX_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size=0.3, \n                                                          random_state=17)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_holdout_scaled = scaler.transform(X_holdout)","9b81890c":"linreg = LinearRegression()\nlinreg.fit(X_train_scaled, y_train);","6ddb4c6c":"print(\"Mean squared error (train): %.3f\" % mean_squared_error(y_train, linreg.predict(X_train_scaled)))\nprint(\"Mean squared error (test): %.3f\" % mean_squared_error(y_holdout, linreg.predict(X_holdout_scaled)))","8b77bfe2":"linreg_coef = pd.DataFrame({'coef': linreg.coef_, 'coef_abs': np.abs(linreg.coef_)},\n                          index=data.columns.drop('quality'))\nlinreg_coef.sort_values(by='coef_abs', ascending=False)","f5584c82":"lasso1 = Lasso(alpha=0.01, random_state=17)\nlasso1.fit(X_train_scaled, y_train)","b6f6ef66":"lasso1_coef = pd.DataFrame({'coef': lasso1.coef_, 'coef_abs': np.abs(lasso1.coef_)},\n                          index=data.columns.drop('quality'))\nlasso1_coef.sort_values(by='coef_abs', ascending=False)","d058f866":"alphas = np.logspace(-6, 2, 200)\nlasso_cv = LassoCV(random_state=17, cv=5, alphas=alphas)\nlasso_cv.fit(X_train_scaled, y_train)","ca100d6d":"lasso_cv.alpha_","02a0872e":"lasso_cv_coef = pd.DataFrame({'coef': lasso_cv.coef_, 'coef_abs': np.abs(lasso_cv.coef_)},\n                          index=data.columns.drop('quality'))\nlasso_cv_coef.sort_values(by='coef_abs', ascending=False)","fbfff585":"print(\"Mean squared error (train): %.3f\" % mean_squared_error(y_train, lasso_cv.predict(X_train_scaled)))\nprint(\"Mean squared error (test): %.3f\" % mean_squared_error(y_holdout, lasso_cv.predict(X_holdout_scaled)))","5b616d3a":"forest = RandomForestRegressor(random_state=17)\nforest.fit(X_train_scaled, y_train)","e1c8975f":"print(\"Mean squared error (train): %.3f\" % mean_squared_error(y_train, forest.predict(X_train_scaled)))\nprint(\"Mean squared error (cv): %.3f\" % np.mean(np.abs(cross_val_score(forest, X_train_scaled, y_train, \n                                                                       scoring='neg_mean_squared_error'))))\nprint(\"Mean squared error (test): %.3f\" % mean_squared_error(y_holdout, forest.predict(X_holdout_scaled)))\n\n","42d1f588":"forest_params = {'max_depth': list(range(10, 25)), \n                  'max_features': list(range(6,12))}\n\nlocally_best_forest = GridSearchCV(RandomForestRegressor(n_jobs=-1, random_state=17), \n                                 forest_params, \n                                 scoring='neg_mean_squared_error',  \n                                 n_jobs=-1, cv=5,\n                                  verbose=True)\nlocally_best_forest.fit(X_train_scaled, y_train)","8a07903b":"locally_best_forest.best_params_, locally_best_forest.best_score_","4e661252":"print(\"Mean squared error (cv): %.3f\" % np.mean(np.abs(cross_val_score(locally_best_forest.best_estimator_,\n                                                        X_train_scaled, y_train, \n                                                        scoring='neg_mean_squared_error'))))\nprint(\"Mean squared error (test): %.3f\" % mean_squared_error(y_holdout, \n                                                             locally_best_forest.predict(X_holdout_scaled)))","bf128faf":"rf_importance = pd.DataFrame(locally_best_forest.best_estimator_.feature_importances_, \n                             columns=['coef'], index=data.columns[:-1]) \nrf_importance.sort_values(by='coef', ascending=False)","2fa07174":"**Tune the `max_features` and `max_depth` hyperparameters with GridSearchCV and again check mean cross-validation MSE and MSE on holdout set.**","29531d07":"# <center> Assignment #6 (demo).\n## <center>  Exploring OLS, Lasso and Random Forest in a regression task\n    \n<img src=\"https:\/\/habrastorage.org\/webt\/-h\/ns\/aa\/-hnsaaifymavmmudwip9imcmk58.jpeg\" width=30%>\n\n**Fill in the missing code and choose answers in [this](https:\/\/docs.google.com\/forms\/d\/1aHyK58W6oQmNaqEfvpLTpo6Cb0-ntnvJ18rZcvclkvw\/edit) web form.**","6bcba673":"**Train LassoCV with random_state=17 to choose the best value of $\\alpha$ in 5-fold cross-validation.**","68ef0a0e":"**Train a simple linear regression model (Ordinary Least Squares).**","6ac36a50":"## Random Forest","aaff261f":"**<font color='red'>Question 6:<\/font> What are mean squared errors of tuned RF model in cross-validation (cross_val_score with scoring='neg_mean_squared_error' and other arguments left with default values) and on holdout set?**","e5c9b014":"**Sort features by their influence on the target feature (wine quality). Beware that both large positive and large negative coefficients mean large influence on target. It's handy to use `pandas.DataFrame` here.**\n\n**<font color='red'>Question 2:<\/font> Which feature this linear regression model treats as the most influential on wine quality?**","c5879f6f":"**<font color='red'>Question 4:<\/font> What are mean squared errors of tuned LASSO predictions on train and holdout sets?**","67b998c0":"**Train a Random Forest with out-of-the-box parameters, setting only random_state to be 17.**","f2fd837a":"## Linear regression","29051f2e":"**Which feature is the least informative in predicting wine quality, according to this LASSO model?**","5f513859":"## Lasso regression","50654dd5":"**<font color='red'>Question 3:<\/font> Which feature is the least informative in predicting wine quality, according to the tuned LASSO model?**","2fe6322a":"**We are working with UCI Wine quality dataset (no need to download it \u2013 it's already there, in course repo and in Kaggle Dataset).**","3d1e843a":"<center>\n<img src=\"https:\/\/habrastorage.org\/files\/fd4\/502\/43d\/fd450243dd604b81b9713213a247aa20.jpg\">\n## Open Machine Learning Course\n<center>Author: [Yury Kashnitsky](https:\/\/www.linkedin.com\/in\/festline\/), Data Scientist at Mail.ru Group <br>\n    All content is distributed under the [Creative Commons CC BY-NC-SA 4.0](https:\/\/creativecommons.org\/licenses\/by-nc-sa\/4.0\/) license.\nYou may use this material for any purpose (you can edit, correct and use it as example) exept commercial use with mandatory citation of author.","78906577":"**Make conclusions about the perdormance of the explored 3 models in this particular prediction task.**\n\nThe depency of wine quality on other features in hand is, presumable, non-linear. So Random Forest works better in this task. ","ab922122":"**<font color='red'>Question 5:<\/font> What are mean squared errors of RF model on the training set, in cross-validation (cross_val_score with scoring='neg_mean_squared_error' and other arguments left with default values) and on holdout set?**","2ae43389":"**Output RF's feature importance. Again, it's nice to present it as a DataFrame.**<br>\n**<font color='red'>Question 7:<\/font> What is the most important feature, according to the Random Forest model?**","2eb8b583":"**<font color='red'>Question 1:<\/font> What are mean squared errors of model predictions on train and holdout sets?**","fc358965":"**Train a LASSO model with $\\alpha = 0.01$ (weak regularization) and scaled data. Again, set random_state=17.**","1dcccab2":"**Separate the target feature, split data in 7:3 proportion (30% form a holdout set, use random_state=17), and preprocess data with `StandardScaler`.**"}}