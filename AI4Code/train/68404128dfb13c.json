{"cell_type":{"90b6c7c9":"code","d740bc8b":"code","567ec6e4":"code","b85fcd6d":"code","eca70f19":"code","80a15694":"code","533e7d60":"code","fe7dcc79":"code","10b0704d":"code","5bd16eaa":"code","a9cd732a":"code","798edc99":"code","7eae6ef9":"code","e7a3169f":"code","d0a4e506":"code","52d176b7":"code","43505bd9":"code","e3fbd29f":"code","bc95f5a5":"code","b22f5a2a":"code","78f6cd7c":"code","5896313b":"code","e5d58694":"code","d96e66d3":"code","c83aeb7e":"code","48b4fab0":"code","b0557d06":"code","011e0cf1":"code","a4ca430e":"code","483853d0":"code","6fe2988c":"markdown","7b795bd5":"markdown","0662be3f":"markdown","ef964743":"markdown","e01a4288":"markdown","cce79cdf":"markdown","dd7b060d":"markdown","022f47e1":"markdown","84a2590d":"markdown","0fc2765b":"markdown","d856762d":"markdown","540e4637":"markdown","1091343a":"markdown","152934b3":"markdown","9f8f225f":"markdown","d509e3eb":"markdown","178ab9f7":"markdown","2db3b4a0":"markdown","434a41d4":"markdown","77554f90":"markdown","25a5cb79":"markdown","4b93399f":"markdown","66119b35":"markdown","babd7035":"markdown","239f2729":"markdown","26719804":"markdown","95bb07e5":"markdown","54f2c24c":"markdown","5a3cfc81":"markdown","e0d0f758":"markdown","0426ba45":"markdown"},"source":{"90b6c7c9":"# Importamos algunas librer\u00edas que vamos a utilizar a lo largo de este trabajo.\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\n# Importamos el dataset previamente descrito.\npath = \"..\/input\/league-of-legends-diamond-ranked-games-10-min\"\n\ndf = pd.read_csv(path + \"\/high_diamond_ranked_10min.csv\")\ndf.head()","d740bc8b":"# Eliminamos la columna 'gameId'\ndf = df.drop('gameId',  axis=1)","567ec6e4":"plt.figure(figsize=(20,15))\nsns.heatmap(round(df.corr(),1), cmap=\"coolwarm\", annot=True, linewidths=.5)\nplt.show()","b85fcd6d":"data = df\nsns.set(font_scale=1.5)\n\nplt.figure(figsize=(20,20))\nsns.set_style(\"whitegrid\")\n\n# Cantidad de kills de cada equipo\nplt.subplot(321)\nsns.scatterplot(x='blueKills', y='redKills', hue='blueWins', data=data)\nplt.title('KILLS totales de cada equipo')\nplt.xlabel('Equipo Azul')\nplt.ylabel('Equipo Rojo')\nplt.grid(True)\n\n# Cantidad de asistencias de cada equipo\nplt.subplot(322)\nsns.scatterplot(x='blueAssists', y='redAssists', hue='blueWins', data=data)\nplt.title('ASISTENCIAS totales de cada equipo')\nplt.xlabel('Equipo Azul')\nplt.ylabel('Equipo Rojo')\nplt.tight_layout(pad=1.5)\nplt.grid(True)\n\n# Cantidad total de oro de cada equipo\nplt.subplot(323)\nsns.scatterplot(x='blueTotalGold', y='redTotalGold', hue='blueWins', data=data)\nplt.title('ORO total de de cada equipo')\nplt.xlabel('Equipo Azul')\nplt.ylabel('Equipo Rojo')\nplt.tight_layout(pad=1.5)\nplt.grid(True)\n\n# Cantidad total de experiencia de cada equipo\nplt.subplot(324)\nsns.scatterplot(x='blueTotalExperience', y='redTotalExperience', hue='blueWins', data=data)\nplt.title('EXPERIENCIA total de de cada equipo')\nplt.xlabel('Equipo Azul')\nplt.ylabel('Equipo Rojo')\nplt.tight_layout(pad=1.5)\nplt.grid(True)\n\n# Cantidad total de Wards colocadas por cada equipo\nplt.subplot(325)\nsns.scatterplot(x='blueWardsPlaced', y='redWardsPlaced', hue='blueWins', data=data)\nplt.title('WARDs totales colocadas de cada equipo')\nplt.xlabel('Equipo Azul')\nplt.ylabel('Equipo Rojo')\nplt.tight_layout(pad=1.5)\nplt.grid(True)\n\n# Juntamos la cantidad total de minions por equipo\ndata['blueMinionsTotales'] = df['blueTotalMinionsKilled'] + df['blueTotalJungleMinionsKilled']\ndata['redMinionsTotales'] = df['redTotalMinionsKilled'] + df['redTotalJungleMinionsKilled']\n\n# Total de minions asesinados por cada equipo\nplt.subplot(326)\nsns.scatterplot(x='blueMinionsTotales', y='redMinionsTotales', hue='blueWins', data=data)\nplt.title('MINIONs totales asesinados de cada equipo')\nplt.xlabel('Equipo Azul')\nplt.ylabel('Equipo Rojo')\nplt.tight_layout(pad=1.5)\nplt.grid(True)\n\nplt.show()","eca70f19":"plt.figure(figsize=(20,20))\nsns.set_style(\"whitegrid\")\n\n# Diferencia de experiencia y oro\nplt.subplot(311)\nsns.scatterplot(x='blueExperienceDiff', y='blueGoldDiff', hue='blueWins', data=data)\nplt.title('Diferencia de ORO y EXPERIENCIA ')\nplt.xlabel('Diferencia de Experiencia')\nplt.ylabel('Diferencia de Oro')\nplt.grid(True)\n\nplt.show()","80a15694":"# Generamos las columnas de datos que vamos a utilizar de acuerdo a lo propuesto anteriormente.\ndf['blueKillsDiff'] = df['blueKills'] - df['redKills']\ndf['blueAssistsDiff'] = df['blueAssists'] - df['redAssists']\ndf['blueHeraldsDiff'] = df['blueHeralds'] - df['redHeralds']\ndf['blueDragonsDiff'] = df['blueDragons'] - df['redDragons']\ndf['blueTowersDestroyedDiff'] = df['blueTowersDestroyed'] - df['redTowersDestroyed']\n\n# Asignamos las columnas previamente generadas en una tabla nueva lista para ser usada por los clasificadores.\nX = df[['blueKillsDiff', 'blueAssistsDiff', 'blueHeraldsDiff', 'blueDragonsDiff', \n        'blueTowersDestroyedDiff', 'blueGoldDiff', 'blueExperienceDiff']]\n\n# Asignamos la variable objetivo.\ny = df['blueWins']\n\n# Imprimimos la tabla\nX.head()","533e7d60":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix\nfrom prettytable import PrettyTable\n\n# Creamos la tabla que nos permitir\u00e1 mostrar las m\u00e9tricas obtenidas.\nmetricas = PrettyTable()\nmetricas.field_names = ['Clasificador', 'Exactitud', 'Recall', 'Precisi\u00f3n']\n\n# Guardaremos los resultados en un vector para ser mostrados en la conclusi\u00f3n del trabajo.\nresultados = []\n\n# Normalizamos los datos\nX = StandardScaler().fit(X).transform(X)\n\n# Asignamos los valores de entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state = 4)","fe7dcc79":"from sklearn.linear_model import LogisticRegression\n\n# Instanciamos el clasificador\nLR = LogisticRegression()\n\n# Hacemos fit a los datos y realizamos la predicci\u00f3n.\ny_pred = LR.fit(X_train, y_train).predict(X_test)\n\n# M\u00e9tricas de evaluaci\u00f3n\nexactitud = accuracy_score(y_test,y_pred)\nrecall = recall_score(y_test,y_pred)\nprecision = precision_score(y_test,y_pred)\nLR_confusion_matrix = confusion_matrix(y_test,y_pred)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas.add_row(['Regresi\u00f3n Log\u00edstica', exactitud, recall, precision])","10b0704d":"from sklearn.neighbors import KNeighborsClassifier\n\n# Instanciamos el clasificador\nKNN = KNeighborsClassifier()\n\n# Hacemos fit a los datos y realizamos la predicci\u00f3n.\ny_pred = KNN.fit(X_train, y_train).predict(X_test)\n\n# M\u00e9tricas de evaluaci\u00f3n\nexactitud = accuracy_score(y_test,y_pred)\nrecall = recall_score(y_test,y_pred)\nprecision = precision_score(y_test,y_pred)\nKNN_confusion_matrix = confusion_matrix(y_test,y_pred)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas.add_row(['K-Nearest Neighbours', exactitud, recall, precision])","5bd16eaa":"from sklearn.tree import DecisionTreeClassifier\n\n# Instanciamos el clasificador\nDT = DecisionTreeClassifier()\n\n# Hacemos fit a los datos y realizamos la predicci\u00f3n.\ny_pred = DT.fit(X_train, y_train).predict(X_test)\n\n# M\u00e9tricas de evaluaci\u00f3n\nexactitud = accuracy_score(y_test,y_pred)\nrecall = recall_score(y_test,y_pred)\nprecision = precision_score(y_test,y_pred)\nDT_confusion_matrix = confusion_matrix(y_test,y_pred)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas.add_row(['Decision Tree', exactitud, recall, precision])","a9cd732a":"from sklearn.ensemble import RandomForestClassifier\n\n# Instanciamos el clasificador\nRF = RandomForestClassifier()\n\n# Hacemos fit a los datos y realizamos la predicci\u00f3n.\ny_pred = RF.fit(X_train, y_train).predict(X_test)\n\n# M\u00e9tricas de evaluaci\u00f3n\nexactitud = accuracy_score(y_test,y_pred)\nrecall = recall_score(y_test,y_pred)\nprecision = precision_score(y_test,y_pred)\nRF_confusion_matrix = confusion_matrix(y_test,y_pred)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas.add_row(['Random Forest', exactitud, recall, precision])","798edc99":"# Imprimimos el t\u00edtulo de la tabla.\nprint(\"Clasificadores Vanilla (Ordenados por Exactitud)\")\n\n# Ordenamos la tabla por la columna \"Exactitud\"\nmetricas.sortby = \"Exactitud\"\n\n# Colocamos las filas en orden descendiente.\nmetricas.reversesort = True\n\n# Imprimimos la tabla\nprint(metricas)","7eae6ef9":"plt.figure(figsize=(20,10))\n\n# Ploteamos la matriz de confusi\u00f3n de la 'Regresi\u00f3n Logistica'\nplt.subplot(221)\nsns.heatmap(LR_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('Regresi\u00f3n Logistica')\nplt.tight_layout(pad=1.5)\n\n# Ploteamos la matriz de confusi\u00f3n de la 'K-Nearest Neighbours'\nplt.subplot(222)\nsns.heatmap(KNN_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('K-Nearest Neighbours')\nplt.tight_layout(pad=1.5)\n\n# Ploteamos la matriz de confusi\u00f3n de la 'Decision Tree'\nplt.subplot(223)\nsns.heatmap(DT_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('Decision Tree')\nplt.tight_layout(pad=1.5)\n\n# Ploteamos la matriz de confusi\u00f3n de la 'Random Forest'\nplt.subplot(224)\nsns.heatmap(RF_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('Random Forest')\nplt.tight_layout(pad=1.5)\n\nplt.show()","e7a3169f":"# Importamos la clase de scikit-learn\nfrom sklearn.model_selection import GridSearchCV\n\n# Creamos la tabla que nos permitir\u00e1 mostrar las m\u00e9tricas obtenidas.\nmetricas_grid_search = PrettyTable()\nmetricas_grid_search.field_names = ['Clasificador', 'Exactitud', 'Recall', 'Precisi\u00f3n']\n\n# Guardaremos los resultados en un vector para ser mostrados en la conclusi\u00f3n del trabajo.\nresultados_grid_search = []","d0a4e506":"# Colocamos los valores de par\u00e1metros que queremos que GridSearchCV pruebe por nosotros\ngrid_values = {'penalty': ['l1', 'l2'],\n               'C':[.001,.009,0.01,.09,1,2,3,4,5,7,10,25],\n               'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n               'fit_intercept' : [True, False]}\n\n# Instanciamos la clase con los par\u00e1metros previamente asignados\ngrid_clf_acc = GridSearchCV(LogisticRegression(), param_grid = grid_values, scoring = 'accuracy', verbose=False, n_jobs=-1)\n\n# Seleccionamos la tabla entera, ya que el m\u00e9todo se encargar\u00e1 de realizar la t\u00e9cnica de Cross-Validation\ngrid_clf_acc.fit(X, y)\n\n# Imprimimos los mejores par\u00e1metros seleccionados por GridSearchCV\nprint(\"Par\u00e1metros elegidos: \" + str(grid_clf_acc.best_params_) + \"\\n\")\n\n# Predecimos los valores\ny_pred_acc = grid_clf_acc.predict(X)\n\n# M\u00e9tricas de evaluaci\u00f3n\nexactitud = accuracy_score(y,y_pred_acc)\nrecall = recall_score(y,y_pred_acc)\nprecision = precision_score(y,y_pred_acc)\nLR_confusion_matrix = confusion_matrix(y,y_pred_acc)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados_grid_search.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas_grid_search.add_row(['Regresi\u00f3n Log\u00edstica', exactitud, recall, precision])","52d176b7":"# Colocamos los valores de par\u00e1metros que queremos que GridSearchCV pruebe por nosotros\ngrid_values = {\"n_neighbors\": [3, 4, 5, 6, 7],\n                 \"weights\": [\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\"]}\n\n# Instanciamos la clase con los par\u00e1metros previamente asignados\ngrid_clf_acc = GridSearchCV(KNeighborsClassifier(), param_grid = grid_values, scoring = 'accuracy', verbose=False, n_jobs=-1)\n\n# Seleccionamos la tabla entera, ya que el m\u00e9todo se encargar\u00e1 de realizar la t\u00e9cnica de Cross-Validation\ngrid_clf_acc.fit(X, y)\n\n# Imprimimos los mejores par\u00e1metros seleccionados por GridSearchCV\nprint(\"Par\u00e1metros elegidos: \" + str(grid_clf_acc.best_params_) + \"\\n\")\n\n# Predecimos los valores\ny_pred_acc = grid_clf_acc.predict(X)\n\n# M\u00e9tricas de evaluaci\u00f3n\nexactitud = accuracy_score(y,y_pred_acc)\nrecall = recall_score(y,y_pred_acc)\nprecision = precision_score(y,y_pred_acc)\nKNN_confusion_matrix = confusion_matrix(y,y_pred_acc)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados_grid_search.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas_grid_search.add_row(['K-Nearest Neighbours', exactitud, recall, precision])","43505bd9":"# Colocamos los valores de par\u00e1metros que queremos que GridSearchCV pruebe por nosotros\ngrid_values = {'max_depth': np.arange(1, 21),\n               'min_samples_leaf': [1, 5, 10, 20, 50, 100]}\n\n# Instanciamos la clase con los par\u00e1metros previamente asignados\ngrid_clf_acc = GridSearchCV(DecisionTreeClassifier(), param_grid = grid_values, scoring = 'accuracy', verbose=False, n_jobs=-1)\n\n# Seleccionamos la tabla entera, ya que el m\u00e9todo se encargar\u00e1 de realizar la t\u00e9cnica de Cross-Validation\ngrid_clf_acc.fit(X, y)\n\n# Imprimimos los mejores par\u00e1metros seleccionados por GridSearchCV\nprint(\"Par\u00e1metros elegidos: \" + str(grid_clf_acc.best_params_) + \"\\n\")\n\n# Predecimos los valores\ny_pred_acc = grid_clf_acc.predict(X)\n\n# M\u00e9tricas de evaluaci\u00f3n\nexactitud = accuracy_score(y,y_pred_acc)\nrecall = recall_score(y,y_pred_acc)\nprecision = precision_score(y,y_pred_acc)\nDT_confusion_matrix = confusion_matrix(y,y_pred_acc)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados_grid_search.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas_grid_search.add_row(['Decision Tree', exactitud, recall, precision])","e3fbd29f":"# Colocamos los valores de par\u00e1metros que queremos que GridSearchCV pruebe por nosotros\ngrid_values = {'max_features': ['auto', 'sqrt', 'log2'],\n                'max_depth' : [4, 5, 6, 7, 8],\n                'criterion' :['gini', 'entropy']}\n\n# Instanciamos la clase con los par\u00e1metros previamente asignados\ngrid_clf_acc = GridSearchCV(RandomForestClassifier(), param_grid = grid_values, scoring = 'accuracy', verbose=False, n_jobs=-1)\n\n# Seleccionamos la tabla entera, ya que el m\u00e9todo se encargar\u00e1 de realizar la t\u00e9cnica de Cross-Validation\ngrid_clf_acc.fit(X, y)\n\n# Imprimimos los mejores par\u00e1metros seleccionados por GridSearchCV\nprint(\"Par\u00e1metros elegidos: \" + str(grid_clf_acc.best_params_) + \"\\n\")\n\n# Predecimos los valores\ny_pred_acc = grid_clf_acc.predict(X)\n\n# M\u00e9tricas de evaluaci\u00f3n\nexactitud = accuracy_score(y,y_pred_acc)\nrecall = recall_score(y,y_pred_acc)\nprecision = precision_score(y,y_pred_acc)\nRF_confusion_matrix = confusion_matrix(y,y_pred_acc)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados_grid_search.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas_grid_search.add_row(['Random Forest', exactitud, recall, precision])","bc95f5a5":"print(\"Clasificadores con GridSearchCV (Ordenados por Exactitud)\")\nmetricas_grid_search.sortby = \"Exactitud\"\nmetricas_grid_search.reversesort = True\nprint(metricas_grid_search)","b22f5a2a":"plt.figure(figsize=(20,10))\n\nplt.subplot(221)\nsns.heatmap(LR_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('Regresi\u00f3n Logistica')\nplt.tight_layout(pad=1.5)\n\nplt.subplot(222)\nsns.heatmap(KNN_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('K-Nearest Neighbours')\nplt.tight_layout(pad=1.5)\n\nplt.subplot(223)\nsns.heatmap(DT_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('Decision Tree')\nplt.tight_layout(pad=1.5)\n\nplt.subplot(224)\nsns.heatmap(RF_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('Random Forest')\nplt.tight_layout(pad=1.5)\n\nplt.show()","78f6cd7c":"# Calculamos la matriz de covarianza\nmatriz_covarianza = np.cov(X.T)\n\n# Calculamos los autovalores y autovectores de la matriz\nauto_valores, auto_vectores = np.linalg.eig(matriz_covarianza)\n                                  \n# A partir de los autovalores, calculamos la varianza explicada individual y la acumulada\ntotal = sum(auto_valores)\nvarianza_explicada = [(i \/ total) * 100 for i in sorted(auto_valores, reverse=True)]\nvarianza_explicada_acumulada = np.cumsum(varianza_explicada)\n\n# Graficamos la varianza explicada por cada autovalor, y la acumulada\nplt.figure(figsize=(20,10))\n\nplt.bar(range(7), varianza_explicada, alpha=0.5, align='center',label='Varianza individual explicada', color='b')\nplt.step(range(7), varianza_explicada_acumulada, where='mid', linestyle='-', label='Varianza explicada acumulada', color='r')\nplt.ylabel('Varianza Explicada')\nplt.xlabel('Componentes Principales')\nplt.legend(loc='best')\nplt.tight_layout()\n\nplt.show()","5896313b":"# Importamos la clase de scikit-learn\nfrom sklearn.decomposition import PCA\n\n# Creamos la tabla que nos permitir\u00e1 mostrar las m\u00e9tricas obtenidas.\nmetricas_pca = PrettyTable()\nmetricas_pca.field_names = ['Clasificador', 'Exactitud', 'Recall', 'Precisi\u00f3n']\n\n# Guardaremos los resultados en un vector para ser mostrados en la conclusi\u00f3n del trabajo.\nresultados_pca = []\n\n# Instanciamos una clase de PCA indicandole que utilizaremos 4 componentes principales\npca = PCA(n_components = 4)\nX_PCA = pca.fit(X).transform(X)","e5d58694":"# Colocamos los valores de par\u00e1metros que queremos que GridSearchCV pruebe por nosotros\ngrid_values = {'penalty': ['l1', 'l2'],\n               'C':[.001,.009,0.01,.09,1,2,3,4,5,7,10,25],\n               'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n               'fit_intercept' : [True, False]}\n\n# Instanciamos la clase con los par\u00e1metros previamente asignados\ngrid_clf_acc = GridSearchCV(LogisticRegression(), param_grid = grid_values, scoring = 'accuracy', verbose=False, n_jobs=-1)\n\n# Seleccionamos la tabla entera, ya que el m\u00e9todo se encargar\u00e1 de realizar la t\u00e9cnica de Cross-Validation\ngrid_clf_acc.fit(X_PCA, y)\n\n# Imprimimos los mejores par\u00e1metros seleccionados por GridSearchCV\nprint(\"Par\u00e1metros elegidos: \" + str(grid_clf_acc.best_params_) + \"\\n\")\n\n# Predecimos los valores\ny_pred_acc = grid_clf_acc.predict(X_PCA)\n\n# M\u00e9tricas de evaluaci\u00f3n\nexactitud = accuracy_score(y,y_pred_acc)\nrecall = recall_score(y,y_pred_acc)\nprecision = precision_score(y,y_pred_acc)\nLR_confusion_matrix = confusion_matrix(y,y_pred_acc)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados_pca.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas_pca.add_row(['Regresi\u00f3n Log\u00edstica', exactitud, recall, precision])","d96e66d3":"# Colocamos los valores de par\u00e1metros que queremos que GridSearchCV pruebe por nosotros\ngrid_values = {\"n_neighbors\": [3, 4, 5, 6, 7],\n                 \"weights\": [\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\"]}\n\n# Instanciamos la clase con los par\u00e1metros previamente asignados\ngrid_clf_acc = GridSearchCV(KNeighborsClassifier(), param_grid = grid_values, scoring = 'accuracy', verbose=False, n_jobs=-1)\n\n# Seleccionamos la tabla entera, ya que el m\u00e9todo se encargar\u00e1 de realizar la t\u00e9cnica de Cross-Validation\ngrid_clf_acc.fit(X_PCA, y)\n\n# Imprimimos los mejores par\u00e1metros seleccionados por GridSearchCV\nprint(\"Par\u00e1metros elegidos: \" + str(grid_clf_acc.best_params_) + \"\\n\")\n\n# Predecimos los valores\ny_pred_acc = grid_clf_acc.predict(X_PCA)\n\n# M\u00e9tricas de evaluaci\u00f3n\nexactitud = accuracy_score(y,y_pred_acc)\nrecall = recall_score(y,y_pred_acc)\nprecision = precision_score(y,y_pred_acc)\nKNN_confusion_matrix = confusion_matrix(y,y_pred_acc)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados_pca.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas_pca.add_row(['K-Nearest Neighbours', exactitud, recall, precision])","c83aeb7e":"# Colocamos los valores de par\u00e1metros que queremos que GridSearchCV pruebe por nosotros\ngrid_values = {'max_depth': np.arange(1, 21),\n               'min_samples_leaf': [1, 5, 10, 20, 50, 100]}\n\n# Instanciamos la clase con los par\u00e1metros previamente asignados\ngrid_clf_acc = GridSearchCV(DecisionTreeClassifier(), param_grid = grid_values, scoring = 'accuracy', verbose=False, n_jobs=-1)\n\n# Seleccionamos la tabla entera, ya que el m\u00e9todo se encargar\u00e1 de realizar la t\u00e9cnica de Cross-Validation\ngrid_clf_acc.fit(X_PCA, y)\n\n# Imprimimos los mejores par\u00e1metros seleccionados por GridSearchCV\nprint(\"Par\u00e1metros elegidos: \" + str(grid_clf_acc.best_params_) + \"\\n\")\n\n# Predecimos los valores\ny_pred_acc = grid_clf_acc.predict(X_PCA)\n\n# M\u00e9tricas de evaluaci\u00f3n\nexactitud = accuracy_score(y,y_pred_acc)\nrecall = recall_score(y,y_pred_acc)\nprecision = precision_score(y,y_pred_acc)\nDT_confusion_matrix = confusion_matrix(y,y_pred_acc)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados_pca.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas_pca.add_row(['Decision Tree', exactitud, recall, precision])","48b4fab0":"# Colocamos los valores de par\u00e1metros que queremos que GridSearchCV pruebe por nosotros\ngrid_values = {'max_features': ['auto', 'sqrt', 'log2'],\n                'max_depth' : [4, 5, 6, 7, 8],\n                'criterion' :['gini', 'entropy']}\n\n# Instanciamos la clase con los par\u00e1metros previamente asignados\ngrid_clf_acc = GridSearchCV(RandomForestClassifier(), param_grid = grid_values, scoring = 'accuracy', verbose=False, n_jobs=-1)\n\n# Seleccionamos la tabla entera, ya que el m\u00e9todo se encargar\u00e1 de realizar la t\u00e9cnica de Cross-Validation\ngrid_clf_acc.fit(X_PCA, y)\n\n# Imprimimos los mejores par\u00e1metros seleccionados por GridSearchCV\nprint(\"Par\u00e1metros elegidos: \" + str(grid_clf_acc.best_params_) + \"\\n\")\n\n# Predecimos los valores\ny_pred_acc = grid_clf_acc.predict(X_PCA)\n\n# M\u00e9tricas de evaluaci\u00f3n\nexactitud = accuracy_score(y,y_pred_acc)\nrecall = recall_score(y,y_pred_acc)\nprecision = precision_score(y,y_pred_acc)\nRF_confusion_matrix = confusion_matrix(y,y_pred_acc)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados_pca.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas_pca.add_row(['Random Forest', exactitud, recall, precision])","b0557d06":"print(\"Clasificadores con PCA + GridSearch + Cross Validation (Ordenados por Exactitud)\")\nmetricas_pca.sortby = \"Exactitud\"\nmetricas_pca.reversesort = True\nprint(metricas_pca)","011e0cf1":"plt.figure(figsize=(20,10))\n\nplt.subplot(221)\nsns.heatmap(LR_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('Regresi\u00f3n Logistica')\nplt.tight_layout(pad=1.5)\n\nplt.subplot(222)\nsns.heatmap(KNN_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('K-Nearest Neighbours')\nplt.tight_layout(pad=1.5)\n\nplt.subplot(223)\nsns.heatmap(DT_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('Decision Tree')\nplt.tight_layout(pad=1.5)\n\nplt.subplot(224)\nsns.heatmap(RF_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('Random Forest')\nplt.tight_layout(pad=1.5)\n\nplt.show()","a4ca430e":"plt.figure(figsize=(20,15))\nsns.set_style(\"whitegrid\")\n\nmodelos = [\"Regresi\u00f3n Log\u00edstica\", \"K-Nearest Neighbours\", \"Decision Tree\", \"Random Forest\"]\ngrafico_resultados = pd.DataFrame({\"Puntuaci\u00f3n\": resultados, \"Modelos\": modelos})\ngrafico_resultados_grid_search = pd.DataFrame({\"Puntuaci\u00f3n\": resultados_grid_search, \"Modelos\": modelos})\ngrafico_resultados_pca = pd.DataFrame({\"Puntuaci\u00f3n\": resultados_pca, \"Modelos\": modelos})\n\nplt.subplot(311)\nsns.barplot(\"Puntuaci\u00f3n\", \"Modelos\", data = grafico_resultados)\nplt.ylabel(\"\")\nplt.title('Clasificadores Vanilla')\nplt.tight_layout(pad=2)\n\nplt.subplot(312)\nsns.barplot(\"Puntuaci\u00f3n\", \"Modelos\", data = grafico_resultados_grid_search)\nplt.ylabel(\"\")\nplt.title('Clasificadores con GridSearch + Cross Validation')\nplt.tight_layout(pad=2)\n\nplt.subplot(313)\nsns.barplot(\"Puntuaci\u00f3n\", \"Modelos\", data = grafico_resultados_pca)\nplt.title('Clasificadores con PCA + GridSearch + Cross Validation')\nplt.ylabel(\"\")\n\nplt.show()","483853d0":"metricas.sortby = \"Clasificador\"\nmetricas_grid_search.sortby = \"Clasificador\"\nmetricas_pca.sortby = \"Clasificador\"\n\nprint(\"Clasificadores Vanilla\")\nprint(metricas)\nprint(\"\")\nprint(\"Clasificadores con GridSearch + Cross Validation\")\nprint(metricas_grid_search)\nprint(\"\")\nprint(\"Clasificadores con PCA + GridSearch + Cross Validation\")\nprint(metricas_pca)","6fe2988c":"### Matrices de Confusi\u00f3n","7b795bd5":"<a id=\"pca\"><\/a>\n# Aplicando PCA + GridSearch + Cross Validation\n\n## An\u00e1lisis de Componentes Principales (PCA)\n\nEs una t\u00e9cnica de selecci\u00f3n de caracter\u00edsticas, que utiliza una transformaci\u00f3n ortogonal para convertir un conjunto de observaciones de variables, posiblemente correlacionadas, en un conjunto m\u00e1s reducido de variables que ya no guardan correlaci\u00f3n y que se conocen como **componentes principales**. \n\nAl realizar este an\u00e1lisis, intentamos buscar cuantos par\u00e1metros m\u00ednimos son necesarios para explicar una cantidad significativa de variaci\u00f3n en los datos, es decir, valorar cu\u00e1nta informaci\u00f3n nos podemos permitir descartar al eliminar ciertos par\u00e1metros y, de esta manera, obtener un modelo m\u00e1s r\u00e1pido y eficiente. \n\nEn este caso, podemos deconstruir un conjunto de datos en:\n* **Autovectores:** es una direcci\u00f3n.\n* **Autovalores:**: es un n\u00famero que representa el valor de la varianza en esa direcci\u00f3n.\n\nPor lo tanto, el componente principal ser\u00e1 el autovector con mayor autovalor. En un conjunto de datos hay tantas parejas autovector\/autovalor como dimensiones. \n\n### Aplicado a nuestro caso\n\nEn nuestro caso en espec\u00edfico, tenemos 7 dimensiones, dadas por cada uno de los features que hemos elegido previamente. Por lo que vamos a proceder a calcular los **autovalores** y **autovectores** de los datos, ver cuanta covarianza explica cada uno y, de esta manera, buscar reducir la dimensionalidad del conjunto de datos para obtener un modelo m\u00e1s r\u00e1pido, eficiente y con la m\u00ednima perdida de informaci\u00f3n posible.","0662be3f":"### K-Nearest Neighbours","ef964743":"Una vez quitadas las columnas redundantes e innecesarias, una buena pr\u00e1ctica es generar una matriz de correlaci\u00f3n. Esta matriz nos permitir\u00e1 conocer el grado de correlaci\u00f3n que existe entre las diferentes variables que pueblan el dataset. Pero...\n\n### Qu\u00e9 significa esto? \n\nLa matriz de correlaci\u00f3n muestra los **valores de correlaci\u00f3n de Pearson**, que miden el grado de relaci\u00f3n lineal entre cada par de elementos o variables. Los valores de correlaci\u00f3n se pueden ubicar entre -1 y +1. Sin embargo, en la pr\u00e1ctica, los elementos por lo general tienen correlaciones positivas. Si los dos elementos tienden a aumentar o disminuir al mismo tiempo, el valor de correlaci\u00f3n es positivo.\n\n#### Interpretaci\u00f3n\n\n**Se utiliza la matriz de correlaci\u00f3n para evaluar la fuerza y direcci\u00f3n de la relaci\u00f3n entre dos variables.** Un valor de correlaci\u00f3n alto y positivo indica que los elementos miden la misma destreza o caracter\u00edstica. Si los elementos no est\u00e1n altamente correlacionados, entonces los elementos pudieran medir diferentes caracter\u00edsticas o no estar claramente definidos.\n\n### Aplicado a nuestro caso\n\nPor lo tanto, aplicaremos la matriz de correlaci\u00f3n para observar que variables del dataset son candidatas a salir del modelo, ya que explican o miden las mismas caracter\u00edsticas. Esto lo realizaremos con el siguiente c\u00f3digo:","e01a4288":"<a id=\"normalizacion-datos\"><\/a>\n# Normalizaci\u00f3n de los datos\n\nDado que existe una gran variaci\u00f3n dentro del dataset en los valores que pueden tomar las diferentes variables, procederemos a normalizar los datos. Normalizar significa, en este caso, comprimir o extender los valores de la variable para que est\u00e9n en un rango definido.\n\n## Escalado Est\u00e1ndar (Standard Scaler)\n\nEn este caso, utilizaremos el **Escalado Est\u00e1ndar**, en donde a cada dato se le resta la **media** de la variable y se le divide por la **desviaci\u00f3n t\u00edpica**, segun la siguiente formula:\n\n$$Xnormalized = \\frac{X - Xmean}{Xstddev}$$","cce79cdf":"### Random Forest","dd7b060d":"### Decision Tree","022f47e1":"<a id=\"resultados-vanilla\"><\/a>\n## Resultados\n\n<a id=\"metricas\"><\/a>\n### M\u00e9tricas \n\n* **Accuracy (Exactitud):** Es el porcentaje total de elementos clasificados correctamente. Es la medida m\u00e1s directa de la calidad de los clasificadores. Es un valor entre 0 y 1. Cuanto m\u00e1s alto, mejor.\n\n* **Recall (Tasa de True Positive):** Es el n\u00famero de elementos identificados correctamente como positivos del total de positivos verdaderos.\n\n* **Precision:** Es el n\u00famero de elementos identificados correctamente como positivo de un total de elementos identificados como positivos.\n\n* **Confusion Matrix (Matriz de Confusi\u00f3n):** Es una tabla que describe el rendimiento de un modelo supervisado de Machine Learning en los datos de prueba, donde se desconocen los verdaderos valores.","84a2590d":"### Conclusi\u00f3n de Matriz de Correlaci\u00f3n\n\nComo podemos observar en la matriz, existen variables que est\u00e1n altamente correlacionadas, es decir, explican las mismas cosas. Por lo tanto, no ayudan a clasificar mejor, si no que muestran los mismos datos que otra columna. Esto ocurre, por ejemplo, con las columnas:\n* **\"RedKills\":** cantidad de asesinatos del equipo rojo.\n* **\"BlueDeaths\":** cantidad de muertes del equipo azul.\nLa cantidad de asesinatos del equipo rojo son la cantidad de muertes que tiene el equipo azul. Por lo tanto, lo acertado seria eliminar una columna, ya que una explica la otra.\n> _**Aclaraci\u00f3n:** dentro del juego, un jugador puede morir sin haber sido asesinado por un miembro del otro equipo, es decir, no sumar\u00eda a la cantidad de kills, como por ejemplo, morir a causa de un **\"monstruo neutral\"**. Sin embargo, estamos hablando de partidas de **\"high elo\"**, en otras palabras, partidas con jugadores poseen un nivel muy alto de juego, por lo que es poco probable que ocurra. Cosas como estas deberian ser tomadas en cuenta para la selecci\u00f3n de variables._\n\n<a id=\"explicacion-variables\"><\/a>\n# Explicaci\u00f3n de Variables\n\n## Principales variables dentro del Juego\n\n### Experiencia\n\nDentro de **League of Legends** los jugadores utilizan a personajes, denominados **\"campeones\"**, los cuales poseen un nivel y determinadas habilidades y estad\u00edsticas. Un personaje puede subir de nivel obteniendo experiencia, y hacerlo le permite mejorar sus habilidades y stats, lo que le otorga una ventaja frente al enemigo.\n\n### Oro\n\nPor otro lado, tenemos el oro, que es \u00fanico en la partida y se usa para comprar objetos. Estos \u00faltimos permiten a los personajes incrementar a\u00fan m\u00e1s sus estad\u00edsticas, as\u00ed como obtener habilidades especiales.\n\n## Como obtenerlos?\n\nSe obtiene experiencia y oro asesinando o destruyendo diferentes objetos dentro del juego, como son:\n* **Creeps:** NPCs que pertenecen a ambos equipos. Dan oro cuando los jugadores los matan.\n* **Mostruos de Elite:** Monstruos con alto HP (Health Points) y da\u00f1o que otorgan una bonificaci\u00f3n masiva de oro, XP y estad\u00edsticas cuando son asesinados por un equipo, estos son:\n    * Dragones: Monstruo de \u00e9lite que otorga bonificaciones al equipo cuando es asesinado. El 4to drag\u00f3n asesinado por un equipo otorga una bonificaci\u00f3n de estad\u00edsticas masivas. El 5to drag\u00f3n (Elder Dragon) ofrece una gran ventaja para el equipo.\n    * Heraldos: Monstruo de \u00e9lite que otorga bonificaci\u00f3n de estad\u00edsticas cuando es asesinado por un jugador. Ayuda a empujar un carril y destruye estructuras.\n* **Jungle Creeps:** NPCs que no pertenecen a NING\u00daN EQUIPO. Dan oro y experiencia cuando los jugadores los matan.\n* **Estructuras enemigas:** Se deben destruir para llegar al \"Nexo\" enemigo. Otorgan oro al ser destruidas. Estas estructuras son:\n    * Torres\n    * Inhibidores.\n* **Campeones enemigos:** personajes del juego utulizados por los miembros del equipo opuesto.\n* **Wards:** Elemento que un jugador puede poner en el mapa para revelar el \u00e1rea cercana. Muy \u00fatil para el control de mapas y objetivos, ya que la visibilidad se ve afectada por la **\u201cniebla de guerra\u201d.**\n\n<a id=\"visualizaci\u00f3n-datos\"><\/a>\n# Visualizaci\u00f3n de Datos\n\nPara ver de una manera m\u00e1s clara que variables contribuyen menos o mas a la victoria del equipo azul, podemos realizar diferentes gr\u00e1ficos y observar como est\u00e1n distribuidos los datos:","0fc2765b":"<a id=\"bibliografia\"><\/a>\n# Bibliograf\u00eda\n\n## Uso de Herramientas y Clasificadores\n\n* [matplotlib](https:\/\/matplotlib.org\/3.2.1\/api\/index.html)\n* [numpy](https:\/\/numpy.org\/doc\/1.18\/reference\/index.html)\n* [pandas](https:\/\/pandas.pydata.org\/docs\/reference\/frame.html)\n* [seaborn](https:\/\/seaborn.pydata.org\/api.html)\n* [scikit-learn](https:\/\/scikit-learn.org\/stable\/modules\/classes.html)\n\n## Conceptos Teoricos\n* [Concepto y uso de GridSearchCV](https:\/\/www.analyticslane.com\/2018\/07\/02\/gridsearchcv\/)\n* [Matriz de Correlaci\u00f3n](https:\/\/support.minitab.com\/es-mx\/minitab\/18\/help-and-how-to\/modeling-statistics\/multivariate\/how-to\/item-analysis\/interpret-the-results\/all-statistics-and-graphs\/)\n* [Matriz de Confusi\u00f3n](https:\/\/empresas.blogthinkbig.com\/ml-a-tu-alcance-matriz-confusion\/)\n* [GitHub de la c\u00e1tedra](https:\/\/github.com\/inteligenciafrvm\/inteligenciafrvm)\n* [Normalizaci\u00f3n de los datos](https:\/\/empresas.blogthinkbig.com\/precauciones-la-hora-de-normalizar\/)\n* [M\u00e9tricas de Clasificaci\u00f3n](https:\/\/sitiobigdata.com\/2019\/01\/19\/machine-learning-metrica-clasificacion-parte-3\/#)\n* [An\u00e1lisis de Componentes Principales (PCA)](https:\/\/empresas.blogthinkbig.com\/python-para-todos-que-es-el-pca\/)","d856762d":"<a id=\"conclusion\"><\/a>\n# Conclusi\u00f3n","540e4637":"### Evaluaci\u00f3n del Gr\u00e1fico\n\nComo podemos advertir en el grafico anterior, las primeras 4 componentes explican, por lo menos, el 90% de la varianza de los datos. Por lo que procederemos a reducir la dimensionalidad de los datos utilizando estas 4 componentes.\n\n<a id=\"implementar-pca\"><\/a>\n## Implementando PCA de Scikit-Learn","1091343a":"![](https:\/\/i.imgur.com\/WEqQ4Cn.png)\n\n# \u00cdndice\n* [Introducci\u00f3n](#introduccion)\n* [Explicaci\u00f3n de Variables](#explicacion-variables)\n* [Visualizaci\u00f3n de Datos](#visualizaci\u00f3n-datos)\n    - [Conclusi\u00f3n](#conclusion-datos)\n    - [An\u00e1lisis de Datos](#analisis-datos)\n* [Selecci\u00f3n de Variables](#seleccion-variables)\n* [Normalizaci\u00f3n de los Datos](#normalizacion-datos) \n* [Clasificadores Vanilla](#clasificadores-vanilla)\n    - [Resultados](#resultados-vanilla)\n        + [Definici\u00f3n de M\u00e9tricas](#metricas)\n* [Aplicando GridSearch + Cross Validation](#grid-search)\n    - [Clasificadores](#clasificadores-grid)\n    - [Resultados](#resultados-grid)\n* [Aplicando PCA + GridSearch + Cross Validation](#pca)\n    - [Implementando PCA de Scikit-Learn](#implementar-pca)\n    - [Clasificadores](#clasificadores-pca)\n    - [Resultados](#resultados-pca)\n* [Conclusi\u00f3n](#conclusion)\n    - [Tabla de M\u00e9tricas](#tabla-metricas)\n* [Bibliograf\u00eda](#bibliografia)\n\n<a id=\"introduccion\"><\/a>\n# Introducci\u00f3n\n\n## Contexto\n\nEl presente dataset trata sobre un videojuego del g\u00e9nero MOBA (multijugador de arena de batalla en l\u00ednea) denominado **\"League of Legends\"**, abreviado **\"LoL\"**, en donde se enfrentan **2 equipos**, uno azul y otro rojo, en un mapa que contiene **3 carriles y una jungla**, que se encuentra entre los mismos. Cada equipo posee **5 integrantes** y cada uno ocupa un rol particular dentro del mismo, siendo el objetivo el destruir el **\"nexo\"**, un edificio cr\u00edtico, del otro equipo para ganar la partida.\n\n## Dataset\n\nEspec\u00edficamente, este dataset contiene diferentes estad\u00edsticas de los **primeros 10 minutos** de juego de alrededor **10 mil partidas** de jugadores con **\"High Elo\"**, es decir, jugadores que alcanzaron un nivel alto dentro de la clasificaci\u00f3n del juego. \n\n## Objetivo\n\nLa columna **'blueWins'** es el valor objetivo (el valor que estamos tratando de predecir). Un valor de 1 significa que el equipo azul gan\u00f3 partida, por otro lado, un valor de 0 indica que el equipo azul perdi\u00f3.","152934b3":"<a id=\"grid-search\"><\/a>\n# Aplicando GridSearch + Cross Validation\n\n## GridSearchCV\n\nEs una clase disponible en **scikit-learn** que permite evaluar y seleccionar de forma sistem\u00e1tica los par\u00e1metros de un modelo. Indic\u00e1ndole un modelo y los par\u00e1metros a probar, puede evaluar el rendimiento del primero en funci\u00f3n de los segundos mediante validaci\u00f3n cruzada. \n\n## Validaci\u00f3n Cruzada\n\nAl hacer uso de esta tecnica, el conjunto de datos de entrenamiento se divide en grupos de igual tama\u00f1o. Una vez realizada la partici\u00f3n se procede a entrenar el modelo una vez por cada uno de los grupos. Utilizando todos los grupos menos el de la iteraci\u00f3n para entrenar y este para validar los resultados. Como se aprecia en al siguiente imagen:\n\n![](https:\/\/www.analyticslane.com\/wp-content\/uploads\/2018\/07\/validacion_cruzada.jpeg.webp)","9f8f225f":"<a id=\"analisis-datos\"><\/a>\n## An\u00e1lisis de Datos\n\n### Oro y Experiencia\n\nSiguiendo estas explicaciones, podemos deducir que:\n\n> _A mayor cantidad de **kills** y **asistencias**_ \ud83e\udc72 _Mayor cantidad de oro y experiencia para el equipo_ \n\n> _A mayor cantidad de **oro** y **experiencia**_ \ud83e\udc72 _Mayor ventaja sobre el equipo enemigo_ \ud83e\udc72 _Mayor probabilidad de ganar la partida_\n\nPor lo tanto, podemos decir que el **oro** y la **experiencia** que posee un equipo respecto del otro, son variables **influyen enormemente** en las posibilidades de un equipo de ganar.  \n\n### Dragones y Heraldos\n\nComo se hab\u00eda descrito anteriormente, estos **monstruos de elite** otorgan **oro** y **experiencia** al equipo que los destruya, aunque tambi\u00e9n otorgan estad\u00edsticas permanentes que se van acumulando y potenciando a medida que el equipo destruya m\u00e1s, por lo que son un objetivo prioritario.\n\n> _A mayor cantidad de **dragones** y **heraldos** asesinados_ \ud83e\udc72 _Mejores estad\u00edsticas para el equipo_ \ud83e\udc72 _Mayor probabilidad de ganar la partida_\n\n### Torretas\n\nLas torretas, asi como los inhibidores, son estructuras criticas que el equipo debe destruir si quiere ganar la partida. Ademas de que otorgan **oro** y **experiencia**.\n\n### Wards\n\nComo se observaban en los gr\u00e1ficos de las variables, la cantidad de **wards** colocadas no tienen un impacto muy grande dentro de lo que son las probabilidades de un equipo de ganar.\n\n<a id=\"seleccion-variables\"><\/a>\n# Selecci\u00f3n de Variables\n\nDadas las conclusiones obtenidas en el apartado de an\u00e1lisis de datos, luego de haber observado los gr\u00e1ficos, incluiremos las siguientes variables dentro del modelo, ya que son las que mas afectan las posibilidades de un equipo de ganar:\n* **Diferencia de Kills.**\n* **Diferencia de Asistencias.**\n* **Diferencia de Heraldos.**\n* **Diferencia de Dragones.**\n* **Diferencia de Torres Destruidas.**\n* **Diferencia de Oro.**\n* **Diferencia de Experiencia.**","d509e3eb":"<a id=\"conclusion-datos\"><\/a>\n## Conclusi\u00f3n de visualizaci\u00f3n de datos\n\nDe los gr\u00e1ficos previamente visualizados podemos decir que:\n* A mayor cantidad de **kills** y **asistencias totales** se incrementan las posibilidades de ganar.\n* Esto tambi\u00e9n se verifica con la cantidad total de **experiencia** y **oro** por equipo, ya que a mayor cantidad de **kills** y **asistencias totales**, mayor cantidad de los primeros valores. La tendencia dice que mientras m\u00e1s **experiencia** y **oro** tenga un equipo, mayores ser\u00e1n sus posibilidades de ganar.\n* Las **wards** totales colocadas por equipo no parecen afectar tanto la posibilidad de que un equipo gane como las variables anteriores.\n* Lo mismo se repite con los **minions totales asesinados** por equipo.\n\n### Diferencias de Oro y Experiencia de un equipo\n\nPara ver de una manera m\u00e1s expl\u00edcita como contribuyen la **experiencia** y el **oro** a la victoria de un equipo podemos graficar la diferencia de estos valores en cada equipo:","178ab9f7":"### K-Nearest Neighbours","2db3b4a0":"## K-Nearest Neighbours\n\n### Definici\u00f3n\n\nEs un algoritmo usado como m\u00e9todo de clasificaci\u00f3n de elementos, basado en un entrenamiento mediante ejemplos cercanos en el espacio que existe entre estos.","434a41d4":"<a id=\"resultados-pca\"><\/a>\n## Resultados\n\n### M\u00e9tricas ","77554f90":"## Decision Tree\n\n### Definici\u00f3n\n\nDado un conjunto de datos, se fabrican diagramas de reglas, que sirven para representar y categorizar una serie de condiciones que ocurren de forma sucesiva, para la resoluci\u00f3n de un problema.","25a5cb79":"<a id=\"resultados-grid\"><\/a>\n## Resultados\n\n### M\u00e9tricas","4b93399f":"<a id=\"clasificadores-grid\"><\/a>\n## Clasificadores\n\n### Regresi\u00f3n Log\u00edstica","66119b35":"<a id=\"clasificadores-vanilla\"><\/a>\n# Clasificadores Vanilla\n\nEn primer lugar, utilizaremos los siguientes clasificadores usando los par\u00e1metros que vienen por defecto:\n* Regresi\u00f3n Log\u00edstica.\n* K-Nearest Neighbours.\n* Decision Tree.\n* Random Forest.\n\n## Regresi\u00f3n Log\u00edstica\n\n### Definici\u00f3n\n\nEs un tipo de an\u00e1lisis de regresi\u00f3n utilizado para predecir el resultado de una variable categ\u00f3rica (una variable que puede adoptar un n\u00famero limitado de categor\u00edas) en funci\u00f3n de las variables independientes o predictoras. Es \u00fatil para modelar la probabilidad de un evento ocurriendo como funci\u00f3n de otros factores. ","babd7035":"### Matrices de Confusi\u00f3n","239f2729":"## Observaci\u00f3n de los Gr\u00e1ficos\n\nGracias a los graficos previos, podemos observar que:\n* La **Regresi\u00f3n Log\u00edstica** tiene una mayor exactitud si lo comparamos al resto de clasificadores utilizando los par\u00e1metros por defecto.\n* Cuando aplicamos **Grid Search** y **PCA**, podemos observar que el algoritmo de **KNN** tiende a precedir mejor los resultados que el resto de los m\u00e9todos.\n* Tambien podemos notar que los dem\u00e1s metodos, como son **Decision Tree** y **Random Forest**, que antes tenian un porcentaje de exactitud menor, han aumentado dicha metrica y se han colocado por encima del algoritmo que antes se encontraba liderando, es decir, la **Regresi\u00f3n Log\u00edstica.**\n\n<a id=\"tabla-metricas\"><\/a>\n## Tabla de M\u00e9tricas","26719804":"Como no nos va a servir para el an\u00e1lisis de los datos, eliminamos la siguiente columna:\n* **'gameId':** identificador \u00fanico utilizado en la API del juego para acceder a los datos espec\u00edficos de una partida.","95bb07e5":"### Decision Tree","54f2c24c":"### Random Forest","5a3cfc81":"### Matrices de Confusi\u00f3n","e0d0f758":"<a id=\"clasificadores-pca\"><\/a>\n## Clasificadores\n\n### Regresi\u00f3n Log\u00edstica","0426ba45":"## Random Forest\n\n### Definici\u00f3n\n\nEs una combinaci\u00f3n de \u00e1rboles de decisi\u00f3n tal que cada \u00e1rbol depende de los valores de un vector aleatorio probado independientemente y con la misma distribuci\u00f3n para cada uno de estos."}}