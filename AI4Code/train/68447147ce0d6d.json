{"cell_type":{"0b20d867":"code","2bd7bf29":"code","1a480344":"code","6249b320":"code","a6e880e9":"code","db71ff07":"code","e48c209f":"code","ae946712":"code","337a2d50":"code","5f8ebe77":"code","e762a9f6":"code","4bcea839":"code","87e8b8fb":"code","544e75b6":"code","3f7e24bc":"code","47fadbea":"code","5be88793":"code","57f2bc73":"code","94b71697":"code","7b01d3b0":"code","de678b05":"code","d5c3b531":"code","dce0dee4":"code","0a90b28e":"code","65ff9cd1":"code","54e6acb9":"code","928420d6":"code","7ed01a70":"code","797ce1e3":"code","b63004e5":"code","2b90940b":"code","bf4d7f57":"markdown","169feef1":"markdown","38907cf2":"markdown","d2233716":"markdown","332d8a6b":"markdown","87526521":"markdown","12c74aa4":"markdown","af8ab7a9":"markdown","0e1d99b6":"markdown","4acaf210":"markdown","b76702e2":"markdown","e6891e92":"markdown"},"source":{"0b20d867":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport glob\nfrom datetime import datetime","2bd7bf29":"train = pd.read_csv('..\/input\/shigglecup-1st\/DATA\/train.csv')\nprint(train.shape)\ntrain.head()","1a480344":"files = []\nfor f in glob.glob('..\/input\/shigglecup-1st\/DATA\/pokemon_images\/*.png'):\n    files.append(f)\nprint(len(files))","6249b320":"_df = pd.DataFrame(files, columns=['file_path'])\n_df['ext_path'] = _df['file_path'].str.extract('(\/[0-9].*.png)', expand=True)\n_df['species_id'] = _df['ext_path'].str.extract('([0-9]+)', expand=True)\n_df['species_id'] = _df['species_id'].astype(int)\n_df[_df['file_path']=='..\/input\/shigglecup-1st\/DATA\/pokemon_images\/386-attack.png']","a6e880e9":"train = pd.merge(train, _df[['file_path', 'species_id']], on=['species_id'], how='left')","db71ff07":"train['image_exist'] = np.where(train['file_path'].isnull(), 0, 1)\ndisplay(train.head())\ndisplay(train[(train['image_exist']==0)&(~train['file_path'].isnull())])","e48c209f":"plt.figure(figsize=(10, 10))\nfor i in range(15):\n    image = Image.open(train.loc[i, 'file_path']) # (6, 273, 256)\n    image = np.array(image) # [256, 256, 4]\n    plt.subplot(5, 3, i + 1)\n    plt.imshow(image)\nplt.show()\nprint(image.shape)","ae946712":"train['target'].hist()","337a2d50":"train['target'] = train['target'].apply(lambda x: np.log1p(x))\ntrain['target'].hist()","5f8ebe77":"# \u7d4c\u9a13\u5024\u9ad8\u3044\u3084\u3064\nplt.figure(figsize=(10, 10))\nfor i, r in train.sort_values('target', ascending=False).head(15).reset_index(drop=True).iterrows():\n    image = Image.open(r['file_path'])\n    image = np.array(image) # [256, 256, 4]\n    plt.subplot(5, 3, i + 1)\n    plt.imshow(image)\nplt.show()","e762a9f6":"# \u7d4c\u9a13\u5024\u4f4e\u3044\u3084\u3064\nplt.figure(figsize=(10, 10))\nfor i, r in train.sort_values('target').head(15).reset_index(drop=True).iterrows():\n    image = Image.open(r['file_path'])\n    image = np.array(image) # [256, 256, 4]\n    plt.subplot(5, 3, i + 1)\n    plt.imshow(image)\nplt.show()","4bcea839":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\n\nOUTPUT_DIR = '.\/'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","87e8b8fb":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    def __init__(self):\n        self.debug=False\n        self.print_freq=100\n        self.num_workers=4\n        self.model_name='swin_base_patch4_window12_384_in22k'\n        self.size=384\n        self.scheduler='CosineAnnealingLR' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts', 'OneCycleLR]\n        self.epochs=20\n        self.T_max=self.epochs # CosineAnnealingLR\u3000\n        self.lr=5e-5 # 1e-5\n        self.max_lr=5e-5 # 1e-5\n        self.min_lr=1e-7 # 5e-7 \n        self.pct_start=0.1 # OneCycleLR\n        self.div_factor = 1e+1 # OneCycleLR\n        self.final_div_factor = 1e+3 # OneCycleLR\n        self.batch_size=8 # 16, 32\n        self.weight_decay=1e-5 # 5e-5\n        self.seed=42\n        self.target_size=1\n        self.target_col='target'\n        self.n_fold=5\n        self.trn_fold=[0, 1, 2, 3, 4] # [0, 1, 2, 3, 4]\n        self.train=True\n        self.mixup = False\n        self.alpha = 1\n        self.wandb = True\n\nCONFIG = CFG()","544e75b6":"!pip install wandb -q","3f7e24bc":"if CONFIG.wandb == True:\n    import wandb\n\n    config_dict = {key: value for key, value in CONFIG.__dict__.items()}\n\n    if CONFIG.debug==False:\n        wandb.init(project='shiggle_1',\n                   entity='shucray_6', \n                   name='006-swin_384-20epoch')\n        wandb.config.update(config_dict)\n        # 8cd3a4f0f587355d5848d2e7baeda29a6de3bcae\n        pass","47fadbea":"!pip install -U git+https:\/\/github.com\/albumentations-team\/albumentations -q\n!pip install -U git+https:\/\/github.com\/rwightman\/pytorch-image-models -q","5be88793":"# ====================================================\n# Library\n# ====================================================\nimport os\nimport math\nimport time\nimport random\nimport shutil\nimport gc\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau, OneCycleLR\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform\n\nimport timm\n\nfrom torch.cuda.amp import autocast, GradScaler\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","57f2bc73":"timm.list_models('*swin*', pretrained=True)","94b71697":"# ====================================================\n# Utils\n# ====================================================\ndef init_logger(log_file=OUTPUT_DIR+'train.log'):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = init_logger()\n\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CONFIG.seed)","7b01d3b0":"train.head()","de678b05":"Fold = KFold(n_splits=CONFIG.n_fold, shuffle=True, random_state=CONFIG.seed)\nfor n, (train_index, val_index) in enumerate(Fold.split(train)):\n    train.loc[val_index, 'fold'] = int(n)\ntrain['fold'] = train['fold'].astype(int)\ndisplay(train.groupby(['fold', 'target']).size())","d5c3b531":"# ====================================================\n# Dataset\n# ====================================================\nclass TrainDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        image = np.array(Image.open(self.df['file_path'][idx])) # [256,256,4]\n        target = self.df[CONFIG.target_col].values[idx]\n#         image = Image.open(image)\n#         image = np.array(image) # [256, 256, 4]\n#         image = image.transpose((2,0,1))[np.newaxis, ...] # [n,4,256,256] \n\n        if self.transform:\n            image = self.transform(image=image)['image']\n        else:\n            image = image[np.newaxis,:,:]\n\n        return torch.tensor(image, dtype=torch.float), torch.tensor(target, dtype=torch.float)\n        ","dce0dee4":"# ====================================================\n# Transforms\n# ====================================================\ndef get_transforms(*, data):\n    \n    if data == 'train':\n        return A.Compose([\n                          A.Resize(CONFIG.size, CONFIG.size, p=1.0),\n                        A.Blur(p=0.3),\n#                         A.RandomResizedCrop(p=0.3, height=CONFIG.size, width=CONFIG.size),\n#                           A.HorizontalFlip(p=0.5),\n#                           A.VerticalFlip(p=0.5),\n                          ToTensorV2(),\n        ])\n\n    elif data == 'valid':\n        return A.Compose([\n                          A.Resize(CONFIG.size, CONFIG.size),\n                          ToTensorV2(),\n        ])","0a90b28e":"# ====================================================\n# MODEL\n# ====================================================\nclass CustomModel(nn.Module):\n    def __init__(self, cfg, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        self.model = timm.create_model(self.cfg.model_name, pretrained=pretrained, in_chans=4)\n        self.n_features = self.model.head.in_features \n        self.model.head = nn.Linear(self.n_features, self.cfg.target_size)\n\n    def forward(self, x):\n        output = self.model(x)\n        return output","65ff9cd1":"# ====================================================\n# Helper functions\n# ====================================================\ndef train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n\n    # switch to train mode\n    model.train()\n    final_loss = 0\n    start = end = time.time()\n\n    for step, (images, labels) in enumerate(train_loader):\n\n        optimizer.zero_grad()\n\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        if CONFIG.mixup == True:\n            images, targets_a, targets_b, lam = mixup(images, labels.view(-1, 1))\n            y_preds = model(images)\n            loss = mix_criterion(criterion, y_preds, targets_a, targets_b, lam)\n        else:\n            y_preds = model(images)\n            loss = criterion(y_preds.view(-1), labels)\n        final_loss += loss.item()\n\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n        # measure elapsed time\n        batch_time = time.time() - end\n        elasped_time = time.time() - start\n        end = time.time()\n        if step % CONFIG.print_freq == 0 or step == (len(train_loader)-1):\n            print(f'Epoch: [{epoch+1}][{step}\/{len(train_loader)}] Batch_Time {batch_time:.4f} Elasped {elasped_time:.4f}')\n\n    final_loss \/= len(train_loader)\n    _ = gc.collect()\n\n    return final_loss\n\n\ndef valid_fn(valid_loader, model, criterion, epoch, device):\n\n    # switch to evaluation mode\n    model.eval()\n    final_loss = 0\n    preds = []\n    start = end = time.time()\n\n    for step, (images, labels) in enumerate(valid_loader):\n\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        \n        with torch.no_grad():\n            y_preds = model(images)\n        loss = criterion(y_preds.view(-1), labels)\n        final_loss += loss.item()\n\n        # record accuracy\n        preds.append(y_preds[:, 0].detach().cpu().numpy())\n\n        # measure elapsed time\n        batch_time = time.time() - end\n        elasped_time = time.time() - start\n        end = time.time()\n        if step % CONFIG.print_freq == 0 or step == (len(valid_loader)-1):\n            print(f'Val:[{step}\/{len(valid_loader)}] Batch_Time {batch_time:.4f} Elasped {elasped_time:.4f}')\n\n    final_loss \/= len(valid_loader)\n    predictions = np.concatenate(preds)\n\n    _ = gc.collect()\n\n    return final_loss, predictions","54e6acb9":"class RMSELoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.mse = nn.MSELoss()\n        \n    def forward(self,yhat,y):\n        return torch.sqrt(self.mse(yhat,y))","928420d6":"from sklearn.metrics import mean_squared_error\n\n# ====================================================\n# Train loop\n# ====================================================\ndef train_loop(folds, fold):\n    \n    LOGGER.info(f\"========== fold: {fold} training ==========\")\n    print(datetime.now())\n\n    # ====================================================\n    # loader\n    # ====================================================\n    trn_idx = folds[folds['fold'] != fold].index\n    val_idx = folds[folds['fold'] == fold].index\n\n    train_folds = folds.loc[trn_idx].reset_index(drop=True)\n    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n    valid_labels = valid_folds[CONFIG.target_col].values\n\n    train_dataset = TrainDataset(train_folds, \n                                 transform=get_transforms(data='train'))\n    valid_dataset = TrainDataset(valid_folds, \n                                 transform=get_transforms(data='valid'))\n\n    train_loader = DataLoader(train_dataset, \n                              batch_size=CONFIG.batch_size, \n                              shuffle=True, \n                              num_workers=CONFIG.num_workers, pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(valid_dataset, \n                              batch_size=CONFIG.batch_size, \n                              shuffle=False, \n                              num_workers=CONFIG.num_workers, pin_memory=True, drop_last=False)\n    \n    # ====================================================\n    # scheduler \n    # ====================================================\n    n_epoch = CONFIG.epochs * len(train_loader)\n    def get_scheduler(optimizer):\n        if CONFIG.scheduler=='ReduceLROnPlateau':\n            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CONFIG.factor, patience=CONFIG.patience, verbose=True, eps=CONFIG.eps)\n        elif CONFIG.scheduler=='CosineAnnealingLR':\n            scheduler = CosineAnnealingLR(optimizer, T_max=n_epoch, eta_min=CONFIG.min_lr, last_epoch=-1)\n        elif CONFIG.scheduler=='CosineAnnealingWarmRestarts':\n            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CONFIG.T_0, T_mult=1, eta_min=CONFIG.min_lr, last_epoch=-1)\n        elif CONFIG.scheduler=='OneCycleLR':\n            scheduler = OneCycleLR(optimizer,\n                                   epochs = CONFIG.epochs,\n                                   steps_per_epoch=len(train_loader),\n                                   max_lr = CONFIG.max_lr,\n                                   pct_start=CONFIG.pct_start,\n                                   anneal_strategy='cos',\n                                   div_factor=CONFIG.div_factor,\n                                   final_div_factor = CONFIG.final_div_factor,\n                                  )\n        return scheduler\n\n    # ====================================================\n    # model & optimizer\n    # ====================================================\n    model = CustomModel(CONFIG, pretrained=True)\n    model.to(device)\n\n    optimizer = torch.optim.AdamW(model.parameters(),\n                                  lr=CONFIG.lr,\n                                  weight_decay=CONFIG.weight_decay)\n    scheduler = get_scheduler(optimizer)\n\n    # ====================================================\n    # loop\n    # ====================================================\n    criterion = RMSELoss()\n\n    best_score = np.inf\n    best_loss = np.inf\n    \n    for epoch in range(CONFIG.epochs):\n        \n        start_time = time.time()\n        \n        # train\n        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n\n        # eval\n        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, epoch, device)\n        \n        # if isinstance(scheduler, ReduceLROnPlateau):\n        #     scheduler.step(avg_val_loss)\n        # elif isinstance(scheduler, CosineAnnealingLR):\n        #     scheduler.step()\n        # elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n        #     scheduler.step()\n\n        # scoring\n        score = mean_squared_error(valid_labels, preds) ** .5\n\n        elapsed = time.time() - start_time\n\n        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n        \n        if CONFIG.wandb == True:\n            wandb.log({\"avg_train_loss\": avg_loss})\n            wandb.log({\"avg_val_loss\": avg_val_loss})\n            wandb.log({\"Score\": score})\n            wandb.log({\"Learning Rate\": optimizer.param_groups[0][\"lr\"]})\n\n\n        if score < best_score:\n            best_score = score\n            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n            torch.save({'model': model.state_dict(), \n                        'preds': preds},\n                        OUTPUT_DIR+f'{CONFIG.model_name}_fold{fold}_best_score.pth')\n        \n        if avg_val_loss < best_loss:\n            best_loss = avg_val_loss\n            LOGGER.info(f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n            torch.save({'model': model.state_dict(), \n                        'preds': preds},\n                        OUTPUT_DIR+f'{CONFIG.model_name}_fold{fold}_best_loss.pth')\n\n    valid_folds['preds'] = torch.load(OUTPUT_DIR+f'{CONFIG.model_name}_fold{fold}_best_loss.pth', \n                                      map_location=torch.device('cpu'))['preds']\n\n    return valid_folds","7ed01a70":"# from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\n\ndef get_result(result_df):\n    # preds = np.argmax([pred for pred in result_df['preds']], axis=1).astype(int)\n    preds = result_df['preds'].values\n    labels = result_df[CONFIG.target_col].values\n    score = mean_squared_error(labels, preds) ** .5\n    LOGGER.info(f'Score: {score:<.4f}')\n\nif CONFIG.train:\n    # train\n    oof_df = pd.DataFrame()\n    for fold in range(CONFIG.n_fold):\n        if fold in CONFIG.trn_fold:\n            _oof_df = train_loop(train, fold)\n            oof_df = pd.concat([oof_df, _oof_df])\n            LOGGER.info(f\"========== fold: {fold} result ==========\")\n            get_result(_oof_df)\n    # CV result\n    LOGGER.info(f\"========== CV ==========\")\n    get_result(oof_df)\n    # save result\n    oof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)","797ce1e3":"oof_df.sort_values('target', ascending=False)[['pokemon','target', 'preds']].head(20)","b63004e5":"oof_df['target'].hist()","2b90940b":"oof_df['preds'].hist()","bf4d7f57":"# Utils","169feef1":"# Model","38907cf2":"# About this notebook\n- PyTorch swin-transformer code\n- KFold 5 folds\n- Only image data","d2233716":"# Direcroty setting","332d8a6b":"# Data Loading","87526521":"# Train loop","12c74aa4":"# CFG","af8ab7a9":"# Quick EDA","0e1d99b6":"# Dataset","4acaf210":"# Helper functions","b76702e2":"# CV split","e6891e92":"# Transforms"}}