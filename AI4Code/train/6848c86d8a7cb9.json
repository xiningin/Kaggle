{"cell_type":{"97b8bc2c":"code","9d93710c":"code","ca1cb116":"code","ca98244d":"code","4f0ae0d2":"code","da3afaef":"code","067dfbdf":"code","120dff78":"code","2faaa279":"code","c272ea69":"code","869ef05a":"markdown"},"source":{"97b8bc2c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport math\nimport random\nimport albumentations as A\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9d93710c":"!pip install keras","ca1cb116":"import matplotlib.pyplot as plt\n%matplotlib inline\nfrom PIL import Image\nfrom glob import glob\nimport cv2","ca98244d":"from PIL import Image\n\nimage = Image.open(\"..\/input\/data-for-image\/data\/HappyFish.jpg\")\nimage","4f0ae0d2":"#Code by Yvtsan Levy https:\/\/www.kaggle.com\/yvtsanlevy\/introduction-to-class-activition-map\n\nfrom __future__ import print_function, division\nfrom builtins import range, input\n# Note: you may need to update your version of future\n# sudo pip install -U future\n\nfrom keras.models import Model\nfrom tensorflow.keras import layers\n\nfrom tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\nfrom keras.preprocessing import image\n\nimport numpy as np\nimport scipy as sp\nimport matplotlib.pyplot as plt\n\nfrom glob import glob\nimport itertools\nimport warnings\nwarnings.filterwarnings(\"ignore\")","da3afaef":"#Code by Yvtsan Levy https:\/\/www.kaggle.com\/yvtsanlevy\/introduction-to-class-activition-map\n\nimage_path = '..\/input\/data-for-image\/data'\nimage_files = glob(image_path +  '\/*.jpg')# original was *.JP*G, then I changed to jpeg to avoid error \"ValueError: 'a' cannot be empty unless no samples are taken\"","067dfbdf":"#Code by Yvtsan Levy https:\/\/www.kaggle.com\/yvtsanlevy\/introduction-to-class-activition-map\n\n# look at an image for fun\n\nplt.imshow(image.load_img(np.random.choice(image_files)));","120dff78":"#Code by Yvtsan Levy https:\/\/www.kaggle.com\/yvtsanlevy\/introduction-to-class-activition-map\n\n# add preprocessing layer to the front of VGG\nresnet = ResNet50(input_shape=(224, 224, 3), weights='imagenet', include_top=True)\n\n# view the structure of the model\n# if you want to confirm we need activation_49\nresnet.summary()","2faaa279":"#Code by Yvtsan Levy https:\/\/www.kaggle.com\/yvtsanlevy\/introduction-to-class-activition-map\n\n# make a model to get output before flatten\nactivation_layer = resnet.get_layer('conv5_block3_out')\n\n# create a model object\nmodel = Model(inputs=resnet.input, outputs=activation_layer.output)","c272ea69":"#Code by Yvtsan Levy https:\/\/www.kaggle.com\/yvtsanlevy\/introduction-to-class-activition-map\n\n# get the feature map weights\nfinal_dense = resnet.get_layer('predictions')\nW = final_dense.get_weights()[0]\n\n\n#while True:\ni = 0\nfor i in range(10):\n  img = image.load_img(np.random.choice(image_files), target_size=(224, 224))\n  x = preprocess_input(np.expand_dims(img, 0))\n  fmaps = model.predict(x)[0] # 7 x 7 x 2048\n\n  # get predicted class\n  probs = resnet.predict(x)\n  classnames = decode_predictions(probs)[0]\n  print(classnames)\n  classname = classnames[0][1]\n  pred = np.argmax(probs[0])\n\n  # get the 2048 weights for the relevant class\n  w = W[:, pred]\n\n  # \"dot\" w with fmaps\n  cam = fmaps.dot(w)\n\n  # upsample to 224 x 224\n  # 7 x 32 = 224\n  cam = sp.ndimage.zoom(cam, (32, 32), order=1)\n\n  plt.subplot(1,2,1)\n  plt.imshow(img, alpha=0.8)\n  plt.imshow(cam, cmap='jet', alpha=0.5)\n  plt.subplot(1,2,2)\n  plt.imshow(img)\n  plt.title(classname)\n  plt.show()","869ef05a":"#Acknowledgment:\n\nYvtsan Levy https:\/\/www.kaggle.com\/yvtsanlevy\/introduction-to-class-activition-map"}}