{"cell_type":{"975ae3d6":"code","ace67a4c":"code","4190cc8a":"code","f3b0a68c":"code","ebd47b6f":"code","4785fe9f":"code","3e9cc5b9":"code","303e32eb":"code","10fa8952":"code","6e5e91e8":"code","591177c5":"code","647401a6":"markdown","6fb4f7e1":"markdown","69cf8d27":"markdown","2fe68c94":"markdown","64562311":"markdown","02b2579a":"markdown","d856e6dd":"markdown","adf4e3d3":"markdown","feb925a5":"markdown","c43f94bd":"markdown","7fb98560":"markdown"},"source":{"975ae3d6":"import os\nfrom shutil import copyfile as cp\n\nSCRIPTS = ['data.py', 'config.py', 'models.py']\nfor f in SCRIPTS:\n    cp(os.path.join('..\/input\/myinput', f), f)\nprint('Scripts loaded!')","ace67a4c":"print(' > Installing requirements...')\n!pip install --upgrade pip\n!pip install torch\n!pip install textgrid\n!apt-get install -y libsndfile-dev\n!pip install soundfile\n\nprint('\\033[1;32mDone!\\033[0m')","4190cc8a":"print(' > Importing...', end='')\nimport os\nimport data\nimport torch\nimport models\nimport pandas as pd\nimport soundfile as sf\nfrom config import *\nfrom tqdm import tqdm\nprint('\\033[1;32mdone!\\033[0m')","f3b0a68c":"def predict(wav):\n    signal, _ = sf.read(wav)\n    signal = torch.tensor(signal, device=device).float().unsqueeze(0)\n    label = model.decode_intents(signal)\n    return label\n\ndef set_label(category, intents):\n    category = intents.loc[intents.intent == category]\n    return UNSURE if category.empty else category.category.item()\nprint('Well defined!')","ebd47b6f":"UNSURE = 31\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nconfig = data.read_config('..\/input\/myinput\/no_unfreezing\/no_unfreezing.cfg'); _,_,_=data.get_SLU_datasets(config)\nmodel = models.Model(config).eval()\nmodel.load_state_dict(torch.load('..\/input\/myinput\/no_unfreezing\/model_state.pth', map_location=device)) # load trained model","4785fe9f":"TEST = '..\/input\/myinput\/test.csv'\nSPEAKERS = '..\/input\/myinput\/speakers'\ntest = pd.read_csv(TEST)\ndf, paths = list(), list()\nfiles = set(test['file'].apply(lambda f: f.replace('.png', '.wav')))\nfor i, speaker in enumerate(os.listdir(SPEAKERS)):\n    speaker = os.path.join(SPEAKERS, speaker)\n    for wav in os.listdir(speaker):\n        if wav not in files:\n            continue\n        wav = os.path.join(speaker, wav)\n        paths.append(wav)\n\ndf = pd.DataFrame({'file': paths})\ntqdm.pandas(desc='Predicting command labels')\ndf['category'] = df['file'].progress_apply(lambda f: predict(f))\n\ndf = pd.DataFrame(df, columns=['file', 'category'])\ndf['category'] = df['category'].apply(lambda l: ','.join(l[0]))","3e9cc5b9":"INTENTS = '..\/input\/myinput\/intents.csv'\nintents = pd.read_csv(INTENTS)\ntqdm.pandas(desc='Mapping intent to category ID', total=df.shape[0])\ndf['category'] = df['category'].progress_apply(lambda c: set_label(c, intents))","303e32eb":"df['file'] = df['file'].apply(lambda file: os.path.basename(file).replace('.wav', '.png'))\ntqdm.pandas(desc='Mapping files to category ID', total=test.shape[0])\ntest['category'] = test['file'].progress_apply(lambda file: df.loc[df.file == file]['category'].item())","10fa8952":"test['file'] = range(1, test['file'].shape[0] + 1)\ntest = test.rename(columns={'file': 'id'})\n\nSUBMISSION = 'submission.csv'\ntest.to_csv(SUBMISSION, index=False)\nprint('Submission ready!!!')","6e5e91e8":"# load our predictions as well as the ground truth and sort by id\nLABELS = '..\/input\/myinput\/1.csv'\nsub = pd.read_csv(SUBMISSION).sort_values(by='id')['category']\nlabels = pd.read_csv(LABELS).sort_values(by='id')['category']\n\n# compare\ncorrect = (sub == labels).sum()\ntotal = labels.shape[0]\nprint(f'\\033[1;32mAccuracy\\033[0m: {correct\/total:.6f}')","591177c5":"for f in SCRIPTS + [SUBMISSION]:\n    os.remove(f)\nprint('All clean!')","647401a6":"### Clean up","6fb4f7e1":"### Importing libraries","69cf8d27":"### Predicting labels for each test set command, using a pre-trained model","2fe68c94":"### Taking care of dependencies","64562311":"### Copying scripts necessary into our working directory","02b2579a":"### Function definitions","d856e6dd":"### Setting and reading configs","adf4e3d3":"### Mapping full .wav paths to relative .png paths in the test set\n\nFor example, the following row of `df` dataframe,\n\n| file                                                                                \t| category \t|\n|-------------------------------------------------------------------------------------\t|----------\t|\n| ..\/input\/myinput\/speakers\/R3mXwwoaX9IoRVKe\/b034cf00-454d-11e9-aa52-bf2189a03a60.wav \t| 25       \t|\n\n> \n\nwould lead to the following update in `test` dataframe\n\n| file                                      | category \t|\n|------------------------------------------\t|----------\t|\n| b034cf00-454d-11e9-aa52-bf2189a03a60.png \t| 25       \t|\n\n","feb925a5":"### Evaluate comparing to the ground truth\n\n`output\/1.csv` contains the ground truth for all 3530 commands of `test.csv`. We will use that to measure the accuracy of the model.","c43f94bd":"### Convert to the appropriate format & submit","7fb98560":"### Map from intent lists to category IDs\nFor example  `['activate', 'light', 'kitchen']` is associated with some numeric id from the `intents.csv` file."}}