{"cell_type":{"516cf9c4":"code","b24febbe":"code","4b12e929":"code","9835b3f5":"code","5d057c01":"code","707e6c78":"code","51bfb856":"code","f6063149":"code","ba67ed69":"code","ff15b60d":"code","e3bb334c":"code","626106bf":"code","0fbaf37f":"code","94ce0332":"code","3d4700fc":"code","69f9616f":"code","a621f4ae":"code","d26a6496":"code","e560f7d0":"code","1911cf50":"code","aa9de61b":"code","9f9e02c8":"code","b8e8a916":"code","22867ea9":"code","7d084841":"code","8047b134":"code","0151b3aa":"code","0b769b63":"code","eb170995":"code","b6ca4e33":"code","6e4d76b7":"code","970dbdb8":"code","6097be64":"code","71a01531":"code","978a17f2":"code","e7f60137":"code","4c5724a3":"code","d4130f0a":"code","bbfea13a":"code","4c1a51ad":"code","79839fcc":"code","c1f9aef4":"code","a1518028":"code","6c7b163f":"code","d623bb0f":"code","d6908041":"code","d96ea157":"code","613ca75d":"code","0c2c98cf":"code","d74863c4":"code","3825c7d5":"code","115f9b84":"code","b8c6ea66":"code","0001e3a1":"code","88724920":"code","7ff2d4ff":"code","5eca16c2":"code","dada7ef1":"code","ce1e96a9":"markdown","8189e844":"markdown","4ddcc3ad":"markdown","f92ce356":"markdown","12b76e47":"markdown","9e78da29":"markdown","781a6193":"markdown","944505de":"markdown","d9202283":"markdown","52ac0972":"markdown","fc8f14b8":"markdown","ae56736e":"markdown","c63b56f3":"markdown","33204d69":"markdown","daa56ef1":"markdown","a1b6368d":"markdown","375bb51e":"markdown","239a3493":"markdown","2496f335":"markdown","ea641838":"markdown","bfed72b5":"markdown","31329f60":"markdown","c54da511":"markdown","097bc08c":"markdown","3ecd7f3a":"markdown","be5b2944":"markdown","7fbe6b94":"markdown","aed49f03":"markdown","3cdaa95d":"markdown","8be86479":"markdown","efcf93cc":"markdown","61022514":"markdown","e6fb9e76":"markdown","cb918544":"markdown","f2fc8357":"markdown","2b324d68":"markdown"},"source":{"516cf9c4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\n\nimport gc\n\n# Any results you write to the current directory are saved as output.","b24febbe":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","4b12e929":"train.shape, test.shape","9835b3f5":"train.columns","5d057c01":"train.target.value_counts()","707e6c78":"train.target.value_counts() \/ len(train)","51bfb856":"train['target'].value_counts().plot(kind=\"pie\", figsize=(12,9), colormap=\"coolwarm\")","f6063149":"train.isna().sum().sum()","ba67ed69":"test.isna().sum().sum()","ff15b60d":"train.describe()","e3bb334c":"numerical_features = train.columns[2:]","626106bf":"print('Distributions - Histograms columns')\nplt.figure(figsize=(30, 200))\nfor i, col in enumerate(numerical_features):\n    plt.subplot(50, 6, i + 1)\n    plt.hist(train[col]) \n    plt.title(col)\ngc.collect();","0fbaf37f":"print('Distributions columns')\nplt.figure(figsize=(30, 200))\nfor i, col in enumerate(numerical_features):\n    plt.subplot(50, 6, i + 1)\n    plt.hist(train[train[\"target\"] == 0][col], alpha=0.5, label='0', color='b')\n    plt.hist(train[train[\"target\"] == 1][col], alpha=0.5, label='1', color='r')    \n    plt.title(col)\ngc.collect();","94ce0332":"plt.figure(figsize=(20, 8))\ntrain[numerical_features].mean().plot('hist');\nplt.title('Mean Frequency');","3d4700fc":"plt.figure(figsize=(20, 8))\ntrain[numerical_features].median().plot('hist');\nplt.title('Median Frequency');","69f9616f":"plt.figure(figsize=(20, 8))\ntrain[numerical_features].std().plot('hist');\nplt.title('Standard Deviation Frequency');","a621f4ae":"plt.figure(figsize=(20, 8))\ntrain[numerical_features].skew().plot('hist');\nplt.title('Skewness Frequency');","d26a6496":"plt.figure(figsize=(20, 8))\ntrain[numerical_features].kurt().plot('hist');\nplt.title('Kurtosis Frequency');","e560f7d0":"sns.set(rc={'figure.figsize':(20,28)})\n\n# Compute the correlation matrix\ncorr = train[train.columns[1:]].corr()\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nsns.heatmap(corr, mask=mask, \n            #annot=True, \n            #fmt=\".2f\", \n            cmap='coolwarm')","1911cf50":"s = corr.unstack().drop_duplicates()\nso = s.sort_values(kind=\"quicksort\")\nso = so.drop_duplicates()","aa9de61b":"s[\"target\"].sort_values()[:10]","9f9e02c8":"s[\"target\"].sort_values(ascending=False)[:10]","b8e8a916":"print(\"Top most highly positive correlated features:\")\nprint(so[(so<1) & (so>0.2)].sort_values(ascending=False))\n\nprint()\n\nprint(\"Top most highly megative correlated features:\")\nprint(so[(so < - 0.2)])","22867ea9":"train.shape, test.shape","7d084841":"# special thanks to https:\/\/www.kaggle.com\/gpreda\/santander-eda-and-prediction\n# also big help for feature engineering :https:\/\/www.kaggle.com\/hjd810\/keras-lgbm-aug-feature-eng-sampling-prediction\n# last but not least: https:\/\/www.kaggle.com\/c\/santander-customer-transaction-prediction\/discussion\/87486#latest-506429\n\nfs_params = dict()\nfs_params[\"descriptives\"] = False\nfs_params[\"standardization\"] = False\nfs_params[\"percentiles\"] = False\nfs_params[\"squared\"] = False\nfs_params[\"frequency\"] = False\n\ngc.collect();\nturn = 0\nfrom sklearn.preprocessing import StandardScaler\nfor df in [test, train]:\n    \n    \n    if turn == 0:\n        print(\"Train set\")\n        turn = 1\n    else:\n        print(\"Test set\")\n    \n    if (fs_params[\"descriptives\"] == True):\n        print('\\t*descriptive statistics Feature Engineering:')\n        df['sum'] = df[numerical_features].sum(axis=1)  \n        df['min'] = df[numerical_features].min(axis=1)\n        df['max'] = df[numerical_features].max(axis=1)\n        df['mean'] = df[numerical_features].mean(axis=1)\n        df['std'] = df[numerical_features].std(axis=1)\n        df['skew'] = df[numerical_features].skew(axis=1)\n        df['kurt'] = df[numerical_features].kurtosis(axis=1)\n        df['med'] = df[numerical_features].median(axis=1)\n        print('\\t*descriptive statistics Feature Engineering done!')\n    \n    if (fs_params[\"standardization\"] == True):\n        print('\\t*Standardizing the data:')\n        #inf values can result from squaring\n        scaler = StandardScaler()\n        df[numerical_features] = scaler.fit_transform(df[numerical_features])\n        print('\\t*Data Standardized!')\n    \n    if (fs_params[\"percentiles\"] == True):\n        print('\\t*percentiles Feature Engineering:')\n        perc_list = [1,2,5,10,25,50,60,75,80,85,95,99]\n        for i in perc_list:\n            df['perc_'+str(i)] =  df[numerical_features].apply(lambda x: np.percentile(x, i), axis=1)\n        print('\\t*Done percentiles Feature Engineering!')\n    \n    if (fs_params[\"squared\"] == True):\n        print('\\t*Loading Squared data:')\n        for i in numerical_features:\n            df['var_sq_'+str(i)] = np.square(df[str(i)])\n        print('\\t*Done squaring!')\n    \n    if (fs_params[\"frequency\"] == True):\n        #thanks to  https:\/\/www.kaggle.com\/c\/santander-customer-transaction-prediction\/discussion\/87486#latest-506429\n        print('\\t*Loading frequency:')\n        for var in numerical_features:\n            hist, bin_edges = np.histogram(df[var], bins=1000, density=True)\n            df['hist_'+var] = [ hist[np.searchsorted(bin_edges,ele)-1] for ele in df[var]]\n        print('\\t*Done Loading frequency!')\n    \ngc.collect();","8047b134":"train.columns","0151b3aa":"train.head(6)","0b769b63":"train.shape, test.shape","eb170995":"y = train['target']\nX = train.drop(['target', \"id\"], axis=1)\nxtest = test.drop(\"id\", axis=\"columns\")\n\nstd_scaler_flag = False\nrobust_scaler_flag = False\nmin_max_scalar_flag = False\n\nif std_scaler_flag == True:\n\n    print(\"StandardScaler!\")\n    from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n\n    sc0 = StandardScaler()\n    sc0.fit(X)\n    X = sc0.transform(X)\n    X = pd.DataFrame(X, columns=train.drop(['target', \"id\"], axis=1).columns)\n    xtest = sc0.transform(xtest)\n    xtest = pd.DataFrame(xtest, columns = test.drop(\"id\", axis=\"columns\").columns)\n    print(X.head(6))\n\nelse:\n    print(\"No scaling at all!\")","b6ca4e33":"clf_stats_df = pd.DataFrame(columns=[\"clf_name\", \"F1-score\", \"auc-score\"])","6e4d76b7":"def xgboost_all_purpose(X, y, type_of_training, name, num_of_folds=3, params=None, in_folds_sampling = False, max_early_stopping = 100):\n    \n    ####\n    #\n    # This is an all purpose xgboost function for all balanced, imbalanced and resampling cases\n    # please excuse me for its length\n    # The different types of training that the method supports are the following:\n    #\n    # baseline\n    # train_test_equal\n    # smote\n    # oversampling\n    # adasyn\n    # \n    #\n    ####\n    \n    \n    from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n    from collections import Counter\n    from sklearn.metrics import accuracy_score\n    from sklearn.metrics import precision_score\n    from sklearn.metrics import recall_score\n    from sklearn.metrics import f1_score\n    from sklearn.metrics import classification_report\n    from sklearn.metrics import roc_auc_score\n    import scikitplot as skplt\n    import time\n    import random\n    \n    import xgboost as xgb\n    \n    global clf_stats_df\n    \n    if params is None:\n        params = dict()\n        params[\"learning_rate\"] = 0.1\n        params[\"n_estimators\"] = 500\n        params[\"max_depth\"] = 3\n        params[\"min_child_weight\"] = 1\n        params[\"gamma\"] = 0\n        params[\"subsample\"] = 1\n        params[\"colsample_bytree\"] = 1\n        params[\"colsample_bylevel\"] = 1\n        params[\"reg_alpha\"] = 0\n        params[\"reg_lambda\"] = 1\n        params[\"scale_pos_weight\"] = np.round(y.value_counts()[0] \/ y.value_counts()[1],3)\n        #params[\"scale_pos_weight\"] = 1\n        #params[\"max_delta_step\"] = 0\n        params[\"max_delta_step\"] = 1\n    \n    print(\"params\", params)\n    print(\"max_early_stopping:\", max_early_stopping)\n    \n    if type_of_training == \"baseline\":\n        \n        print(\"baseline\")\n        \n        # create a 70\/30 stratified split of the data \n        xtrain, xvalid, ytrain, yvalid = train_test_split(X, y, stratify = y, random_state=42, test_size=0.3)\n    \n        import xgboost as xgb\n\n        start_time = time.time()\n        \n        predictions_probas_list = np.zeros([len(yvalid), 2])\n        predictions_test = np.zeros(len(test))\n        num_fold = 0\n        #feature_importance_df = pd.DataFrame()\n        \n        folds = StratifiedKFold(n_splits=num_of_folds, shuffle=False, random_state = 42)\n        \n        for train_index, valid_index in folds.split(xtrain, ytrain):\n            xtrain_stra, xvalid_stra = xtrain.iloc[train_index,:], xtrain.iloc[valid_index,:]\n            ytrain_stra, yvalid_stra = ytrain.iloc[train_index], ytrain.iloc[valid_index]\n            \n            print()\n            print(\"Stratified Fold:\", num_fold)\n            num_fold = num_fold + 1\n            print()\n            \n            clf_stra_xgb = xgb.XGBClassifier(learning_rate=params[\"learning_rate\"], \n                                    n_estimators=params[\"n_estimators\"], \n                                    max_depth=params[\"max_depth\"],\n                                    min_child_weight=params[\"min_child_weight\"],\n                                    gamma=params[\"gamma\"],\n                                    subsample=params[\"subsample\"],\n                                    colsample_bytree=params[\"colsample_bytree\"],\n                                    colsample_bylevel=params[\"colsample_bylevel\"],\n                                    objective= 'binary:logistic',\n                                    nthread=-1,\n                                    scale_pos_weight=params[\"scale_pos_weight\"],\n                                    reg_alpha = params[\"reg_alpha\"],\n                                    reg_lambda = params[\"reg_lambda\"],\n                                    max_delta_step = params[\"max_delta_step\"],\n                                    seed=42)\n\n            clf_stra_xgb.fit(xtrain_stra, ytrain_stra, eval_set=[(xtrain_stra, ytrain_stra), (xvalid_stra, yvalid_stra)], \n                        early_stopping_rounds=max_early_stopping, eval_metric='auc', verbose=100)\n            \n            #fold_importance_df = pd.DataFrame()\n            #fold_importance_df[\"feature\"] = pd.DataFrame.from_dict(data=clf_stra_xgb.get_fscore(), orient=\"index\", columns=[\"FScore\"])[\"FScore\"].index\n            #fold_importance_df[\"fscore\"] = pd.DataFrame.from_dict(data=clf_stra_xgb.get_fscore(), orient=\"index\", columns=[\"FScore\"])[\"FScore\"].values\n            #fold_importance_df[\"fold\"] = n_fold + 1\n            #feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n\n            predictions = clf_stra_xgb.predict(xvalid)\n            predictions_probas = clf_stra_xgb.predict_proba(xvalid)\n            predictions_probas_list += predictions_probas\/num_of_folds\n            \n            predictions_test += clf_stra_xgb.predict_proba(test[xtrain.columns])[:,1]\/num_of_folds\n            \n        \n        predictions = np.argmax(predictions_probas, axis=1)\n\n        print()\n        print(classification_report(yvalid, predictions))\n\n        print()\n        print(\"CV f1_score\", f1_score(yvalid, predictions, average = \"macro\"))\n        \n        print()\n        print(\"CV roc_auc_score\", roc_auc_score(yvalid, predictions_probas_list[:,1], average = \"macro\"))\n        \n        print()\n        print(\"elapsed time in seconds: \", time.time() - start_time)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_confusion_matrix(yvalid, predictions, normalize=True)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_roc(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_ks_statistic(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_precision_recall(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_cumulative_gain(yvalid, predictions_probas)\n\n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_lift_curve(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(12, 38)})\n        xgb.plot_importance(clf_stra_xgb, title='Feature importance', xlabel='F score', ylabel='Features')\n\n        clf_stats_df = clf_stats_df.append({\"clf_name\": name,\n                             \"F1-score\":f1_score(yvalid, predictions, average = \"macro\"),\n                             \"auc-score\": roc_auc_score(yvalid, predictions_probas_list[:,1], average = \"macro\")}, ignore_index=True)\n        \n        print()\n        gc.collect();\n        return clf_stra_xgb, predictions_test\n    \n    elif type_of_training == \"train_test_equal\":\n        \n        print(\"train_test_equal_flag\")\n        \n        # create a 70\/30 stratified split of the data \n        xtrain, xvalid, ytrain, yvalid = train_test_split(X, y, stratify = y, random_state=42, test_size=0.3)\n    \n        import xgboost as xgb\n\n        start_time = time.time()\n        \n        predictions_probas_list = np.zeros([len(yvalid), 2])\n        predictions_test = np.zeros(len(test))\n        num_fold = 0\n        #feature_importance_df = pd.DataFrame()\n        \n        print(\"resample xtrain set to be equal to the size of the test set\")\n        temp_df = pd.DataFrame(xtrain, columns=xtrain.columns)\n        temp_df[\"target\"] = ytrain\n        temp_df = temp_df.sample(frac = len(test) \/ len(xtrain), replace = True)\n        ytrain = temp_df['target']\n        xtrain = temp_df.drop(['target'], axis=1)\n        del temp_df;\n        print(xtrain.shape, test.shape)\n        \n        folds = StratifiedKFold(n_splits=num_of_folds, shuffle=False, random_state = 42)\n        \n        for train_index, valid_index in folds.split(xtrain, ytrain):\n            xtrain_stra, xvalid_stra = xtrain.iloc[train_index,:], xtrain.iloc[valid_index,:]\n            ytrain_stra, yvalid_stra = ytrain.iloc[train_index], ytrain.iloc[valid_index]\n            \n            print()\n            print(\"Stratified Fold:\", num_fold)\n            num_fold = num_fold + 1\n            print()\n            \n            clf_stra_xgb = xgb.XGBClassifier(learning_rate=params[\"learning_rate\"], \n                                    n_estimators=params[\"n_estimators\"], \n                                    max_depth=params[\"max_depth\"],\n                                    min_child_weight=params[\"min_child_weight\"],\n                                    gamma=params[\"gamma\"],\n                                    subsample=params[\"subsample\"],\n                                    colsample_bytree=params[\"colsample_bytree\"],\n                                    colsample_bylevel=params[\"colsample_bylevel\"],\n                                    objective= 'binary:logistic',\n                                    nthread=-1,\n                                    scale_pos_weight=params[\"scale_pos_weight\"],\n                                    reg_alpha = params[\"reg_alpha\"],\n                                    reg_lambda = params[\"reg_lambda\"],\n                                    max_delta_step = params[\"max_delta_step\"],\n                                    seed=42)\n\n            clf_stra_xgb.fit(xtrain_stra, ytrain_stra, eval_set=[(xtrain_stra, ytrain_stra), (xvalid_stra, yvalid_stra)], \n                        early_stopping_rounds=max_early_stopping, eval_metric='auc', verbose=100)\n            \n            #fold_importance_df = pd.DataFrame()\n            #fold_importance_df[\"feature\"] = pd.DataFrame.from_dict(data=clf_stra_xgb.get_fscore(), orient=\"index\", columns=[\"FScore\"])[\"FScore\"].index\n            #fold_importance_df[\"fscore\"] = pd.DataFrame.from_dict(data=clf_stra_xgb.get_fscore(), orient=\"index\", columns=[\"FScore\"])[\"FScore\"].values\n            #fold_importance_df[\"fold\"] = n_fold + 1\n            #feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n\n            predictions = clf_stra_xgb.predict(xvalid)\n            predictions_probas = clf_stra_xgb.predict_proba(xvalid)\n            predictions_probas_list += predictions_probas\/num_of_folds\n            \n            predictions_test += clf_stra_xgb.predict_proba(test[xtrain.columns])[:,1]\/num_of_folds\n            \n        \n        predictions = np.argmax(predictions_probas, axis=1)\n\n        print()\n        print(classification_report(yvalid, predictions))\n\n        print()\n        print(\"CV f1_score\", f1_score(yvalid, predictions, average = \"macro\"))\n        \n        print()\n        print(\"CV roc_auc_score\", roc_auc_score(yvalid, predictions_probas_list[:,1], average = \"macro\"))\n        \n        print()\n        print(\"elapsed time in seconds: \", time.time() - start_time)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_confusion_matrix(yvalid, predictions, normalize=True)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_roc(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_ks_statistic(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_precision_recall(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_cumulative_gain(yvalid, predictions_probas)\n\n        sns.set(rc={'figure.figsize':(8,8)})\n        skplt.metrics.plot_lift_curve(yvalid, predictions_probas)\n        \n        sns.set(rc={'figure.figsize':(12, 38)})\n        xgb.plot_importance(clf_stra_xgb, title='Feature importance', xlabel='F score', ylabel='Features')\n\n        clf_stats_df = clf_stats_df.append({\"clf_name\": name,\n                             \"F1-score\":f1_score(yvalid, predictions, average = \"macro\"),\n                             \"auc-score\": roc_auc_score(yvalid, predictions_probas_list[:,1], average = \"macro\")}, ignore_index=True)\n        \n        print()\n        gc.collect();\n        return clf_stra_xgb, predictions_test\n\n    \n    \n    else:\n        print(\"Please specify for the argument 'type_of_training'one of the following parameters: (baseline, oversampling, smote, undersampling, augmentation_by_fraction)\")","970dbdb8":"type_of_training = \"baseline\"\n    \nnum_of_folds = 4 ### must be more than 2\nin_folds_sampling = False\n\nclf_xgb, predictions_test_xgb = xgboost_all_purpose(X,y, num_of_folds = num_of_folds, \n                                                    type_of_training =type_of_training, \n                                                    in_folds_sampling = in_folds_sampling, \n                                                    max_early_stopping = 200, \n                                                    name=\"clf_xgb\")\n\ndel clf_xgb","6097be64":"gc.collect()\nimport eli5\nfeature_selection_flag = True\n\nif feature_selection_flag == True:\n    from sklearn.model_selection import train_test_split\n    from sklearn.ensemble import RandomForestClassifier\n    import xgboost as xgb\n\n    gc.collect();\n    xtrain, xvalid, ytrain, yvalid = train_test_split(X, y, stratify = y, test_size=0.3, random_state=42)\n\n\n    #rfc_model = RandomForestClassifier(random_state=42, \n    #                                   class_weight={0: 1, 1: np.round(y.value_counts()[0] \/ y.value_counts()[1],3)}\n    #                                  )\n    \n    fs_model = xgb.XGBClassifier(nthread = -1, \n                                  objective = 'binary:logistic', \n                                  eval_metric = 'auc', \n                                  silent=1, \n                                  tree_method='auto',\n                                  max_depth = 3,  \n                                  scale_pos_weight = np.round(y.value_counts()[0] \/ y.value_counts()[1],3))\n    \n    fs_model.fit(xtrain, ytrain)\n\n    import eli5\n    from eli5.sklearn import PermutationImportance\n\n    perm = PermutationImportance(fs_model, random_state=42).fit(xvalid, yvalid)","71a01531":"eli5.show_weights(perm, feature_names = xvalid.columns.tolist(), top=100)","978a17f2":"if feature_selection_flag == True:\n    from sklearn.feature_selection import SelectFromModel\n   \n    max_selected_features = 50\n    sel = SelectFromModel(perm, max_features = max_selected_features, prefit=True)\n\n    feature_idx = sel.get_support()\n    selected_feature_names = X.columns[feature_idx]\n\n    \n    X_fs_50 = X[selected_feature_names]\n    print(X_fs_50.shape)\n    \n    max_selected_features = 25\n    sel = SelectFromModel(perm, max_features = max_selected_features, prefit=True)\n\n    feature_idx = sel.get_support()\n    selected_feature_names = X.columns[feature_idx]\n\n    \n    X_fs_25 = X[selected_feature_names]\n    print(X_fs_25.shape)\n    \n    max_selected_features = 15\n    sel = SelectFromModel(perm, max_features = max_selected_features, prefit=True)\n\n    feature_idx = sel.get_support()\n    selected_feature_names = X.columns[feature_idx]\n\n    \n    X_fs_15 = X[selected_feature_names]\n    print(X_fs_15.shape)","e7f60137":"   fs_clf_xgb, predictions_test_fs_50_xgb = xgboost_all_purpose(X_fs_50,\n                                                              y,\n                                                              type_of_training =type_of_training, \n                                                              num_of_folds = num_of_folds, \n                                                              max_early_stopping= 100, \n                                                              name=\"fs_clf_50_xgb\")","4c5724a3":"    fs_clf_xgb, predictions_test_fs_25_xgb = xgboost_all_purpose(X_fs_25,\n                                                              y,\n                                                              type_of_training =type_of_training, \n                                                              num_of_folds = num_of_folds, \n                                                              max_early_stopping= 100, \n                                                              name=\"fs_clf_25_xgb\")","d4130f0a":"   fs_clf_xgb, predictions_test_fs_15_xgb = xgboost_all_purpose(X_fs_15,\n                                                              y,\n                                                              type_of_training =type_of_training, \n                                                              num_of_folds = num_of_folds, \n                                                              max_early_stopping= 100, \n                                                              name=\"fs_clf_15_xgb\")","bbfea13a":"clf_stats_df","4c1a51ad":"as_it_is = True\nsmote_flag = False\nadasyn_flag = False\noversampling_flag = False\naugment_flag = False\n\ndef prepare_for_tuning(X, y, type_of_training):\n    \n    from sklearn.model_selection import train_test_split\n\n    if type_of_training == \"baseline\":\n\n        print(\"no resampling at all!\")\n        from sklearn.model_selection import train_test_split\n        xtrain, xvalid, ytrain, yvalid = train_test_split(X, y, stratify = y, random_state=42, test_size=0.3)\n\n    elif type_of_training == \"train_test_equal\":\n\n            print(\"train_test_equal\")\n\n            # create a 70\/30 stratified split of the data \n            xtrain, xvalid, ytrain, yvalid = train_test_split(X, y, stratify = y, random_state=42, test_size=0.3)\n\n            print(\"resample xtrain set to be equal to the size of the test set\")\n            temp_df = pd.DataFrame(xtrain, columns=xtrain.columns)\n            temp_df[\"target\"] = ytrain\n            temp_df = temp_df.sample(frac = len(test) \/ len(xtrain), replace = True)\n            ytrain = temp_df['target']\n            xtrain = temp_df.drop(['target'], axis=1)\n            del temp_df;\n            print(xtrain.shape, test.shape)\n\n\n\n    elif type_of_training == \"oversampling\":\n\n        print(\"oversampling\")\n\n        from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n\n        # create a 70\/30 split of the data \n        xtrain, xvalid, ytrain, yvalid = train_test_split(X, y, stratify = y, random_state=42, test_size=0.3)\n\n        # RandomOverSampler\n        ros = RandomOverSampler(random_state=42)\n        X_resampled, y_resampled = ros.fit_resample(xtrain, ytrain)\n\n        from collections import Counter\n        print(sorted(Counter(y_resampled).items()))\n\n        xtrain=pd.DataFrame(X_resampled, columns = X.columns)\n        ytrain = y_resampled\n        del X_resampled\n        del y_resampled\n\n\n    elif type_of_training == \"augmentation_by_fraction\":\n\n        from sklearn.model_selection import train_test_split\n        # the main idea here is to reducing the imbalance ratio from 9:1 to 3:1\n        print(\"augmentation\")\n\n        from collections import Counter\n\n        # create a 70\/30 split of the data \n        xtrain, xvalid, ytrain, yvalid = train_test_split(X, y, stratify = y, random_state=42, test_size=0.3)\n\n        print(\"ytrain target values count before augmentation:\\n\", sorted(Counter(ytrain).items()))\n\n        # Augmenting both minority and majority classes via RandomOverSampler by 3 times\n        X_y = pd.DataFrame(xtrain, columns=X.columns)\n        X_y[\"target\"] = ytrain\n        X_y = X_y.sample(frac=3, replace=True)\n        X_y.target.value_counts()\n        ytrain = X_y['target']\n        print(\"ytrain target values count after oversampling:\\n\",sorted(Counter(ytrain).items()))\n        xtrain = X_y.drop(['target'], axis=1)\n        del X_y\n\n        from imblearn.under_sampling import RandomUnderSampler\n\n        # reducing the majority class almost back to its original form\n        rus = RandomUnderSampler(sampling_strategy=0.33, random_state=42)\n        X_resampled, y_resampled = rus.fit_resample(xtrain, ytrain)\n\n        print(\"ytrain target values count after Augmentation:\\n\",sorted(Counter(y_resampled).items()))\n\n        xtrain=pd.DataFrame(X_resampled, columns = X.columns)\n        ytrain = y_resampled\n\n        del X_resampled\n        del y_resampled\n        gc.collect();\n        \n    return xtrain, ytrain","79839fcc":"def bayesian_tuning(xtrain, ytrain):\n    \n    from skopt import BayesSearchCV\n    from sklearn.model_selection import StratifiedKFold\n    import xgboost as xgb\n\n    # Classifier\n    bayes_cv_tuner = BayesSearchCV(\n        estimator = xgb.XGBClassifier(\n            nthread = -1,\n            objective = 'binary:logistic',\n            eval_metric = 'auc',\n            silent=1,\n            tree_method='auto'\n        ),\n        search_spaces = {\n            'learning_rate': (0.01, 1.0, 'log-uniform'),\n            'min_child_weight': (0, 10),\n            'n_estimators': (50, 100),\n            'max_depth': (0, 12),\n            'gamma': (1e-2, 10, 'log-uniform'),\n            'subsample': (0.01, 1.0, 'uniform'),\n            'colsample_bytree': (0.01, 1.0, 'uniform'),\n            'colsample_bylevel': (0.01, 1.0, 'uniform'),\n            'scale_pos_weight': (0.01, 1.0, 'uniform'),\n            'reg_lambda': (1e-1, 10, 'log-uniform'),\n            'reg_alpha': (1e-2, 1.0, 'log-uniform'),\n            'max_delta_step': (0, 10, 'uniform'),\n            'scale_pos_weight': (1e-2, 1, 'uniform')\n        },    \n        scoring = 'roc_auc',\n        cv = StratifiedKFold(\n            n_splits=3,\n            shuffle=True,\n            random_state=42\n        ),\n        n_jobs = 1,\n        n_iter = 7,   \n        verbose = 0,\n        refit = True,\n        random_state = 42\n    )\n\n    def status_print(optim_result):\n        \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n\n        # Get all the models tested so far in DataFrame format\n        all_models = pd.DataFrame(bayes_cv_tuner.cv_results_)    \n\n        # Get current parameters and the best parameters    \n        best_params = pd.Series(bayes_cv_tuner.best_params_)\n        print('Model #{}\\nBest ROC-AUC: {}\\nBest params: {}\\n'.format(\n            len(all_models),\n            np.round(bayes_cv_tuner.best_score_, 4),\n            bayes_cv_tuner.best_params_\n        ))\n\n        ### Save all model results\n        #clf_name = bayes_cv_tuner.estimator.__class__.__name__\n        #all_models.to_csv(clf_name+\"_cv_results.csv\")\n        ###\n        \n    result = bayes_cv_tuner.fit(xtrain, ytrain, callback = status_print)\n    return result\n    \n# Fit the model\nxtrain, ytrain = prepare_for_tuning(X, y, type_of_training=type_of_training)\nresult = bayesian_tuning(xtrain, ytrain)","c1f9aef4":"gc.collect()\n\nresult.best_params_['n_estimators'] = 3000\n\nnum_of_folds = 4 ### must be more than 2\n\ntuned_clf_xgb, predictions_test_tuned_xgb = xgboost_all_purpose(X,\n                                                                y,\n                                                                type_of_training = type_of_training, \n                                                                num_of_folds=num_of_folds, \n                                                                params = result.best_params_, \n                                                                max_early_stopping = 200, \n                                                                in_folds_sampling = False,\n                                                                name=\"tuned_clf_xgb\")","a1518028":"clf_stats_df","6c7b163f":"xtrain, ytrain = prepare_for_tuning(X_fs_50, y, type_of_training=type_of_training)\nresult = bayesian_tuning(xtrain, ytrain)","d623bb0f":"gc.collect()\n\nresult.best_params_['n_estimators'] = 3000\n\nnum_of_folds = 4 ### must be more than 2\n\ntuned_clf_fs_50_xgb, predictions_test_tuned_fs_50_xgb = xgboost_all_purpose(X_fs_50,\n                                                                y,\n                                                                type_of_training = type_of_training, \n                                                                num_of_folds=num_of_folds, \n                                                                params = result.best_params_, \n                                                                max_early_stopping = 200, \n                                                                in_folds_sampling = False,\n                                                                name=\"tuned_clf_fs_50_xgb\")","d6908041":"clf_stats_df","d96ea157":"xtrain, ytrain = prepare_for_tuning(X_fs_25, y, type_of_training=type_of_training)\nresult = bayesian_tuning(xtrain, ytrain)","613ca75d":"gc.collect()\n\nresult.best_params_['n_estimators'] = 3000\n\nnum_of_folds = 4 ### must be more than 2\n\ntuned_clf_fs_25_xgb, predictions_test_tuned_fs_25_xgb = xgboost_all_purpose(X_fs_25,\n                                                                y,\n                                                                type_of_training = type_of_training, \n                                                                num_of_folds=num_of_folds, \n                                                                params = result.best_params_, \n                                                                max_early_stopping = 200, \n                                                                in_folds_sampling = False,\n                                                                name=\"tuned_clf_fs_25_xgb\")","0c2c98cf":"clf_stats_df","d74863c4":"xtrain, ytrain = prepare_for_tuning(X_fs_15, y, type_of_training=type_of_training)\nresult = bayesian_tuning(xtrain, ytrain)","3825c7d5":"gc.collect()\n\nresult.best_params_['n_estimators'] = 3000\n\nnum_of_folds = 4 ### must be more than 2\n\ntuned_clf_fs_15_xgb, predictions_test_tuned_fs_15_xgb = xgboost_all_purpose(X_fs_15,\n                                                                y,\n                                                                type_of_training = type_of_training, \n                                                                num_of_folds=num_of_folds, \n                                                                params = result.best_params_, \n                                                                max_early_stopping = 200, \n                                                                in_folds_sampling = False,\n                                                                name=\"tuned_clf_fs_15_xgb\")","115f9b84":"clf_stats_df","b8c6ea66":"gc.collect();\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['target'] = predictions_test_xgb\nsubmission.to_csv('clf_xgb.csv', index=False)\n\n\nif feature_selection_flag == True:\n    \n    gc.collect();\n    submission = pd.read_csv('..\/input\/sample_submission.csv')\n    submission['target'] = predictions_test_fs_50_xgb\n    submission.to_csv('fs_50_clf_xgb.csv', index=False)\n    \n    gc.collect();\n    submission = pd.read_csv('..\/input\/sample_submission.csv')\n    submission['target'] = predictions_test_fs_25_xgb\n    submission.to_csv('fs_25_clf_xgb.csv', index=False)\n    \n    gc.collect();\n    submission = pd.read_csv('..\/input\/sample_submission.csv')\n    submission['target'] = predictions_test_fs_15_xgb\n    submission.to_csv('fs_15_clf_xgb.csv', index=False)\n\n\ngc.collect();\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['target'] = predictions_test_tuned_xgb\nsubmission.to_csv('tuned_clf_xgb.csv', index=False)\n\ngc.collect();\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['target'] = predictions_test_tuned_fs_50_xgb\nsubmission.to_csv('tuned_clf_fs_50_xgb.csv', index=False)\n\ngc.collect();\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['target'] = predictions_test_tuned_fs_25_xgb\nsubmission.to_csv('tuned_clf_fs_25_xgb.csv', index=False)\n\ngc.collect();\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['target'] = predictions_test_tuned_fs_15_xgb\nsubmission.to_csv('tuned_clf_fs_15_xgb.csv', index=False)","0001e3a1":"from sklearn.model_selection import train_test_split, StratifiedKFold, KFold, RepeatedStratifiedKFold\nfrom collections import Counter\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score\nimport scikitplot as skplt\nimport time\nimport random\n\nfrom sklearn.linear_model import LogisticRegression, Lasso\n\n\n\n#print(\"baseline\")\n\n# create a 70\/30 stratified split of the data \nxtrain, xvalid, ytrain, yvalid = train_test_split(X, y, stratify = y, random_state=42, test_size=0.1)\n\nimport xgboost as xgb\n\nstart_time = time.time()\n\npredictions_probas_list = np.zeros([len(yvalid), 2])\npredictions_test = np.zeros(len(test))\nnum_fold = 0\nnum_of_folds = 10\n#feature_importance_df = pd.DataFrame()\n\nfolds = StratifiedKFold(n_splits=10, shuffle=False, random_state = 42)\n\nfor train_index, valid_index in folds.split(xtrain, ytrain):\n    xtrain_stra, xvalid_stra = xtrain.iloc[train_index,:], xtrain.iloc[valid_index,:]\n    ytrain_stra, yvalid_stra = ytrain.iloc[train_index], ytrain.iloc[valid_index]\n\n    print()\n    print(\"Stratified Fold:\", num_fold)\n    num_fold = num_fold + 1\n    print()\n\n    #fold_importance_df = pd.DataFrame()\n    #fold_importance_df[\"feature\"] = pd.DataFrame.from_dict(data=clf_stra_xgb.get_fscore(), orient=\"index\", columns=[\"FScore\"])[\"FScore\"].index\n    #fold_importance_df[\"fscore\"] = pd.DataFrame.from_dict(data=clf_stra_xgb.get_fscore(), orient=\"index\", columns=[\"FScore\"])[\"FScore\"].values\n    #fold_importance_df[\"fold\"] = n_fold + 1\n    #feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    clf_logit = LogisticRegression(random_state=42,\n                                   C=0.1,\n                                   solver='liblinear',\n                                   class_weight =\"balanced\",\n                                   penalty = 'l1',\n                                   multi_class='ovr').fit(xtrain_stra, ytrain_stra)\n\n    predictions = clf_logit.predict(xvalid)\n    predictions_probas = clf_logit.predict_proba(xvalid)\n    predictions_probas_list += predictions_probas\/num_of_folds\n\n    predictions_test += clf_logit.predict_proba(test[xtrain.columns])[:,1]\/num_of_folds\n\n\npredictions = np.argmax(predictions_probas, axis=1)\n\nprint()\nprint(classification_report(yvalid, predictions))\n\nprint()\nprint(\"CV f1_score\", f1_score(yvalid, predictions, average = \"macro\"))\n\nprint()\nprint(\"CV roc_auc_score\", roc_auc_score(yvalid, predictions_probas_list[:,1], average = \"macro\"))\n\nprint()\nprint(\"elapsed time in seconds: \", time.time() - start_time)\n\nsns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_confusion_matrix(yvalid, predictions, normalize=True)\n\nsns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_roc(yvalid, predictions_probas)\n\nsns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_ks_statistic(yvalid, predictions_probas)\n\nsns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_precision_recall(yvalid, predictions_probas)\n\nsns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_cumulative_gain(yvalid, predictions_probas)\n\nsns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_lift_curve(yvalid, predictions_probas)\n\nclf_stats_df = clf_stats_df.append({\"clf_name\": \"clf_logit\",\n                     \"F1-score\":f1_score(yvalid, predictions, average = \"macro\"),\n                     \"auc-score\": roc_auc_score(yvalid, predictions_probas_list[:,1], average = \"macro\")}, ignore_index=True)\n\nprint()","88724920":"clf_stats_df","7ff2d4ff":"from sklearn.model_selection import train_test_split, StratifiedKFold, KFold, RepeatedStratifiedKFold\nfrom collections import Counter\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score\nimport scikitplot as skplt\nimport time\nimport random\nfrom sklearn.feature_selection import RFE\n\nfrom sklearn.linear_model import LogisticRegression, Lasso\n\n\n\n#print(\"baseline\")\n\n# create a 70\/30 stratified split of the data \nxtrain, xvalid, ytrain, yvalid = train_test_split(X, y, stratify = y, random_state=42, test_size=0.1)\n\nimport xgboost as xgb\n\nstart_time = time.time()\n\npredictions_probas_list = np.zeros([len(yvalid), 2])\npredictions_test_rfe = np.zeros(len(test))\nnum_fold = 0\nnum_of_folds = 10\n#feature_importance_df = pd.DataFrame()\n\nfolds = StratifiedKFold(n_splits=10, shuffle=False, random_state = 42)\n\nfor train_index, valid_index in folds.split(xtrain, ytrain):\n    xtrain_stra, xvalid_stra = xtrain.iloc[train_index,:], xtrain.iloc[valid_index,:]\n    ytrain_stra, yvalid_stra = ytrain.iloc[train_index], ytrain.iloc[valid_index]\n\n    print()\n    print(\"Stratified Fold:\", num_fold)\n    num_fold = num_fold + 1\n    print()\n\n    #fold_importance_df = pd.DataFrame()\n    #fold_importance_df[\"feature\"] = pd.DataFrame.from_dict(data=clf_stra_xgb.get_fscore(), orient=\"index\", columns=[\"FScore\"])[\"FScore\"].index\n    #fold_importance_df[\"fscore\"] = pd.DataFrame.from_dict(data=clf_stra_xgb.get_fscore(), orient=\"index\", columns=[\"FScore\"])[\"FScore\"].values\n    #fold_importance_df[\"fold\"] = n_fold + 1\n    #feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    clf_logit = LogisticRegression(random_state=42,\n                                   C=0.1,\n                                   solver='liblinear',\n                                   class_weight =\"balanced\",\n                                   penalty = 'l1',\n                                   multi_class='ovr')\n    \n    #clf_logit.fit(xtrain_stra, ytrain_stra)\n    \n    selector = RFE(clf_logit, 21)\n    selector.fit(xtrain_stra, ytrain_stra)\n    \n    clf_logit_rfe = selector\n\n    predictions = clf_logit_rfe.predict(xvalid)\n    predictions_probas = clf_logit_rfe.predict_proba(xvalid)\n    predictions_probas_list += predictions_probas\/num_of_folds\n\n    predictions_test_rfe += clf_logit_rfe.predict_proba(test[xtrain.columns])[:,1]\/num_of_folds\n\n\npredictions = np.argmax(predictions_probas, axis=1)\n\nprint()\nprint(classification_report(yvalid, predictions))\n\nprint()\nprint(\"CV f1_score\", f1_score(yvalid, predictions, average = \"macro\"))\n\nprint()\nprint(\"CV roc_auc_score\", roc_auc_score(yvalid, predictions_probas_list[:,1], average = \"macro\"))\n\nprint()\nprint(\"elapsed time in seconds: \", time.time() - start_time)\n\nsns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_confusion_matrix(yvalid, predictions, normalize=True)\n\nsns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_roc(yvalid, predictions_probas)\n\nsns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_ks_statistic(yvalid, predictions_probas)\n\nsns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_precision_recall(yvalid, predictions_probas)\n\nsns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_cumulative_gain(yvalid, predictions_probas)\n\nsns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_lift_curve(yvalid, predictions_probas)\n\nclf_stats_df = clf_stats_df.append({\"clf_name\": \"clf_logit\",\n                     \"F1-score\":f1_score(yvalid, predictions, average = \"macro\"),\n                     \"auc-score\": roc_auc_score(yvalid, predictions_probas_list[:,1], average = \"macro\")}, ignore_index=True)\n\nprint()","5eca16c2":"from sklearn.model_selection import train_test_split, StratifiedKFold, KFold, RepeatedStratifiedKFold\nfrom collections import Counter\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score\nimport scikitplot as skplt\nimport time\nimport random\nfrom sklearn.feature_selection import RFE\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import VotingClassifier,BaggingClassifier, ExtraTreesClassifier, AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.linear_model import LogisticRegression, Lasso\n\n\n\n#print(\"baseline\")\n\n# create a 70\/30 stratified split of the data \nxtrain, xvalid, ytrain, yvalid = train_test_split(X, y, stratify = y, random_state=42, test_size=0.1)\n\nimport xgboost as xgb\n\nstart_time = time.time()\n\npredictions_probas_list = np.zeros([len(yvalid), 2])\npredictions_test_voting = np.zeros(len(test))\nnum_fold = 0\nnum_of_folds = 10\n#feature_importance_df = pd.DataFrame()\n\nfolds = StratifiedKFold(n_splits=10, shuffle=False, random_state = 42)\n\nfor train_index, valid_index in folds.split(xtrain, ytrain):\n    xtrain_stra, xvalid_stra = xtrain.iloc[train_index,:], xtrain.iloc[valid_index,:]\n    ytrain_stra, yvalid_stra = ytrain.iloc[train_index], ytrain.iloc[valid_index]\n\n    print()\n    print(\"Stratified Fold:\", num_fold)\n    num_fold = num_fold + 1\n    print()\n\n    #fold_importance_df = pd.DataFrame()\n    #fold_importance_df[\"feature\"] = pd.DataFrame.from_dict(data=clf_stra_xgb.get_fscore(), orient=\"index\", columns=[\"FScore\"])[\"FScore\"].index\n    #fold_importance_df[\"fscore\"] = pd.DataFrame.from_dict(data=clf_stra_xgb.get_fscore(), orient=\"index\", columns=[\"FScore\"])[\"FScore\"].values\n    #fold_importance_df[\"fold\"] = n_fold + 1\n    #feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    log_clf = LogisticRegression(C = 0.1, class_weight= 'balanced', penalty= 'l1', solver= 'liblinear',random_state=42)\n    rand_clf = RandomForestClassifier(max_depth=2,random_state=42)\n    svm_clf = SVC(gamma='auto',probability=True, random_state=42)\n    extra_clf = ExtraTreesClassifier(max_depth=2,random_state=42)\n    #ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=200,algorithm='SAMME.R', learning_rate=0.5, random_state=42)\n\n    voting_clf = VotingClassifier(\n        estimators = [('lr',log_clf),('rf',rand_clf),('ex',extra_clf),('sv',svm_clf)],\n        voting='soft')\n    \n    voting_clf.fit(xtrain_stra, ytrain_stra)\n\n    predictions = voting_clf.predict(xvalid)\n    predictions_probas = voting_clf.predict_proba(xvalid)\n    predictions_probas_list += predictions_probas\/num_of_folds\n\n    predictions_test_voting += voting_clf.predict_proba(test[xtrain.columns])[:,1]\/num_of_folds\n\n\npredictions = np.argmax(predictions_probas, axis=1)\n\nprint()\nprint(classification_report(yvalid, predictions))\n\nprint()\nprint(\"CV f1_score\", f1_score(yvalid, predictions, average = \"macro\"))\n\nprint()\nprint(\"CV roc_auc_score\", roc_auc_score(yvalid, predictions_probas_list[:,1], average = \"macro\"))\n\nprint()\nprint(\"elapsed time in seconds: \", time.time() - start_time)\n\nsns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_confusion_matrix(yvalid, predictions, normalize=True)\n\nsns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_roc(yvalid, predictions_probas)\n\nsns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_ks_statistic(yvalid, predictions_probas)\n\nsns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_precision_recall(yvalid, predictions_probas)\n\nsns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_cumulative_gain(yvalid, predictions_probas)\n\nsns.set(rc={'figure.figsize':(8,8)})\nskplt.metrics.plot_lift_curve(yvalid, predictions_probas)\n\nclf_stats_df = clf_stats_df.append({\"clf_name\": \"clf_voting\",\n                     \"F1-score\":f1_score(yvalid, predictions, average = \"macro\"),\n                     \"auc-score\": roc_auc_score(yvalid, predictions_probas_list[:,1], average = \"macro\")}, ignore_index=True)\n\nprint()","dada7ef1":"gc.collect();\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['target'] = predictions_test\nsubmission.to_csv('clf_logit.csv', index=False)\n\n\ngc.collect();\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['target'] = predictions_test_rfe\nsubmission.to_csv('clf_logit_rfe.csv', index=False)\n\n\ngc.collect();\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['target'] = predictions_test_voting\nsubmission.to_csv('clf_logit_voting.csv', index=False)","ce1e96a9":"## Exploratory Data Analysis\n<a id=\"eda\"><\/a>","8189e844":"### Soft Voting Classifier","4ddcc3ad":"## Table of Contents\n- Problem Definition and Objectives\n- [Exploratory Data Analysis](#eda)\n- Machine Learning Modeling\n    - Potential Resampling Techniques\n    - Feature Engineering\n    - ML Modeling\n    - Feature Selection\n    - Tuning\n    - DL Modeling\n    - Ensemble \/ Blend Models\n- Conclusion","f92ce356":"### Tuned XGBoost training with all the features","12b76e47":" ## Preparing Submissions","9e78da29":"### Logistic Regression","781a6193":"### Tuned XGBoost training with top 15 features","944505de":"#### In general there are no strong positive and negative correlations, only some upto +\/- 0.3 pearson correlation.","d9202283":"_________________________________________\n*I would be happy if my kernel helped you understand this problem and the data better.\nif this kernel is helpful to you a thumb up or follow would be much appreciated!*","52ac0972":"### Most correlated features with the target","fc8f14b8":"### Feature Selection\n<a id=\"fs\"><\/a>","ae56736e":"### Tuned XGBoost training with top 50 features","c63b56f3":"### Below is a personal train of thought on how to deal this problem and generally how to conduct a series of experiments","33204d69":"Most of the features seems to be standardized \/ normalized.","daa56ef1":"### Feature Engineering\nAdding more features to the dataset.","a1b6368d":"### Recursive Feature Elimination for Feature Selection","375bb51e":"## Machine Learning Modeling","239a3493":"## Pre-processing\nShould I scale the features.","2496f335":"### Plotting the mean, std, skewness and kurtosis for all the features","ea641838":"### ML Bayesian Tuning","bfed72b5":"### Experiment, Train of thought:\n\n#### EDA -> Resampling (as it is) -> ML Modeling \/ DL Modeling","31329f60":"<img src=\"data:image\/png;base64,iVBORw0KGgoAAAANSUhEUgAABDoAAAGSCAYAAAACWqGdAAAGa3pUWHRteEdyYXBoTW9kZWwAAE1Wx5KsuBL9mo6YWdwObAFLoPDem80Ehfe2cF\/\/VLd78RYSKeXJVErp+ELZ\/izqLv9CoH7M6qLOsy\/0+YUgCARTfyDsD4y7MPmF0ggKJpz6xikyBmyAr8Z1+8Eex\/GdLcnxXY8\/rKTMh1+eNt511yVfCI9\/Q4D1T1AP2XisgNRdMMEQ2EYZQAHGA\/shzwf2L\/jQ09TlQf5S6u0jjxLf6OOjQhFdTf1CWEB3dfuxXcjTdvyIsNUy9mCHJ9BvCMBJ9BuGUMBwkiJZ6v9T87Ez35Lyx0wOjeb\/Ig3C8yjxJDORDe4Xs+fLWo\/DDwxY+\/hGfhjbNeU\/u9uSd93fq6PcF8pmdVIuSQ8g9e9jOqOXXhWTh8fB8e5\/ewPVwo+SIel\/lZjg0f7AP0oIf3plXwgjIZyJwabyEnlILTXLcaj6XNXluU01idcNGiFbHSjkylFbhp5rVUZkYUEkIyeFTENCzeFyt+9Vq2\/GtaQi1wT5ZVbWxly3mtrpmm\/stSTo6+gsV+3S5zvrUtZFZVR2JbQsB\/BerD+NiTAooVcpdTtLlilgqmhzvCQ0TiP1U1huMwlzno7BcYV7DGOIjB9OInX6+5QkQ4b3WFeUwwwuhBLdGM5Yb+Hp8nBspXjnCiypiqgWm8LOfECQKs9bdvumjveMhuGLvN7PK6q8fQUhw6hJFN4f7465b37WEKz7eH+F6HDzOHVNBz+HRIk5klEJtnKxvvGUK+B2xiCvaOUuLOrAgltC7Y4NkmyYkouIR7OSz4x0AmkOG1kacRBcfD8Sxy4X2CStFju4jFtuvJsgRGxDU2M5leNmWvLEuKXMX2r20szRWLT48oVb+ogbYHT027ZnHDMm3eH2PXq97tV9EK0Ns\/WUw8EFJ89jmEF4Mh6iZ0nNeZtX7G7a3O6yrq5JzRrDEmWIhavoH1q++BTcFq9EVBzW9oQ2DKOnVDp+4BPmUurMSZKJO5O8LibwzZI0FJyLlGk2poDU4\/NDcwpFP8mSPKAHXuLlJe5YcLbSJIptMD5P96pliPO1jWUXRte2Z8x0fEi\/6BG6CL0Yd2zgBoOXbcun1ImAo3giS6vxR182CoNF2B7eGkmzE\/lpyLwhTDbXaKKIGN5iz9AGM2LPykV6OZ5DAC8MnKEAuxLynCWPLZFbcPQxXRnfy6zoWt5V55vn3pbXEwtat\/RlGm9O3rm0xErqABjl7JVsamk\/DDA2obqHLv2Ix+gLP8GTRhTQ3aZbM5RqmxurpfhYLc1cSsspxA8vhERTTtiyA8AExu1YFsFoHlpPM3VTrNxMSeZMnZJZRBYyvRkbK3rpqhk9O36aRYLxWGvC+TyGSiHxLnAg9SjcGJs0bsc\/zj9WtjKeU\/yghISWHcV\/NhY5Pbqqed6tFWsmidGNcjsPj1NphX4qG6hbDAHGo6Da4na3N5SJ6yRkF42bDX5im5jGAzlueE+x\/dsQgpdWy+rCyo2HuAnxFvzdPM0ttfVtgwtjU2IbD1R1NsQ68yagGJgFl2jSmZvusr5TqoZmSpZlV2lnqX\/5DAQXteAQjw82o7TsNZZp8I6UiyR8mkGOXWAf3iTsrM9J3Rp9kuk8dQ1UP96qMHDSJN+xdsIGluUlKfv2w+C7soYWgTrqsYaft+gArKQNiieyuHWF3LargsJo0sGL\/pLE0+35g6moOo01KbndE+zIC7OP6OlVGy3XVHkEtA8SuCxqV2vIPs7mrLD5e9Xesp8jrRdX4AQ67R1Vv\/dtX0ubBmlSkIvaNSJcbPeRcm+5T+CPJRzNWntjmel0mFzzcVyqDBRqjyfIJ2puHIojlEqIqABSuuY8Kc\/aHEn7FLNbyQNPjWkiHmlQS8UGmhapzjnBPGRTMCR20r2qaJlR7JA+BBL4ZrfFc81ea\/tm8Nw9QY\/hX8dmqZeT4dJdtFwum22GZCUbDKgXwejDR73xjVMPdrx3JOwvfCDxFIhBqE7k7xbfcZIapta\/dFiuFf+YTZdSeda4oW17oAeqnsiaw7PaBhPfowJ7VArnJBP74HZT6VuyNnLv1We7K1G4rVCrZbFLYl4DknAn1OB9RITIxaS+ip9tCAeojO3UO4mAq3Fi2SMIjfXbnUw7u2OT\/JTkqURBi0fVPCmm+pVkKNJm17PEUBPbZbwEbYBXX4pYHNqn8aHsJ9B+O+bf9vmpvT\/\/JCj3P52ze+YAACAASURBVHhe7L0N8HZVdd59ORo\/EVExGKkEURNqYmiNMcbAaDERTCZNS6zYKpoGjYkYglZftbZSsASNRJSASiNNjZiJpNrJmA8hkZjiV3mJjeNoRSP1RTEaJQooKGMm71z8z+JZz3r2Pt\/n3Pucc90zDM\/\/vs\/Ze+3f3vvsc66z9lp3gT4iIAIiIAIiIAIiIAIiIAIiIAJrI3A3AI8B8BAADwTwIAD3XFsj1Z7VE\/gGgL8B8CX3341Nrb5L0wH6XQREQAREQAREQAREQAREQAREYBEEDgHwHAAnAjgOwH0WYbWMFIFuBD4P4DUALgHw7dSpEjq6AdXRIiACIiACIiACIiACIiACIlAagfsDeD2Afw3gHncYd5e7AA84Cjj0kcBB3w0c\/D3Ad8mho7SOkz0NBG6\/FfjmV4Cbvgjc+Nm9\/\/Z9vgjgdQDeAuBb\/gcJHRpZIiACIiACIiACIiACIiACIrBcAkcB+FMA\/D\/wfT8JHHcG8LBjgXsevNxWyXIRSBH41s3Adf8TuOqNwGf+zI74OIAnAfg7+0JCh4aPCIiACIiACIiACIiACIiACCyTwCMBfPiOGBz02HjO\/wC+90eX2RJZLQJdCXzuw8Db\/iVwy5d55n5ih4SOrjB1vAiIgAiIgAiIgAiIgAiIgAjsngDdNT4G4Eg8+AeB510O3I9xR\/URgQ0RuOkG4LdOAL70if3EDgkdGxoDaqoIiIAIiIAIiIAIiIAIiMBqCLwBwK\/i3g8A\/t3HJXKsplvVkM4EKHb8xjHArXckY2G8jl+W0NGZok4QAREQAREQAREQAREQAREQgZ0SOBTA9QDuhV\/4Q+BRP71TY1S5COycwCf\/EPivP0MzvgngMAkdO+8RGSACIiACIiACIiACIiACIiACnQicC+Dl+N7HA7\/CEB36iIAI4A0\/AnzhGoJ4roQOjQcREAEREAEREAEREAEREAERWBaBzwB4BJ77x8DRT12W5bJWBKYi8In3AL\/9z1n61RI6poKsckVABERABERABERABERABERgfAL3A\/B13PW7gNfePn7pKlEElkzgZfcA\/v52SOhYcifKdhEQAREQAREQAREQAREQga0R+GcArsRDfwT41au31na1VwTqCVTbVyR0aKCIgAiIgAiIgAiIgAiIgAiIwHII\/DyA38YPPQ149u93svrP\/hXwuAcDp70PePsnDzy16fe2lZ3yKOCiJwOXXQs894oDzzr7CcAZPwy84S+BV32obantjmMbvuc+wA\/8t3bHT3lUE4chdZPhyx631485xnW\/N9XdpY\/8sSx3qr5tsvmO39\/2NODj75JHRytYOkgEREAEREAEREAEREAEREAEyiBwOoA34vG\/CDzt4k4WmZDxlduA510OXPn5fae\/9SnAqY8Gbrk9L4S0rWzKB\/wmG0oSOppsHfK7iQu3\/z3wpr\/aXzAy\/ve9O3DJx9NCSFPdfYWOsYWrJjsP+P33nwf8r7dK6OgMTieIgAiIgAiIgAiIgAiIgAiIwO4IvBLAf8bxrwB+6tc6WUER4OgHADd9G3jXp\/d\/OP4E\/UQAPPS++4SO4x8K\/M5PAYcftK+a910P\/ETlSOIfqHnEJ2\/c86Sw7z9\/C\/CoB+6d6wWU6AHwy\/8EuP5m4DGH7R17wzeAZ\/\/xPiEmV0+q8U1CR2xTrMs8Je5+173SKSS89uo9VvztmY\/a+\/6o++21l59vfQd45P0BCgv8mLgQBR8yzh3L83zd5PWZrwGH3Wd\/FtZmY\/jxrwK3fWdfn\/B3ilYnPgw4+O77e9WQzZOPOLA\/rEzaZ\/113U3Ag+61z+umjlvOo+MzXwde\/yTg018DnvCQdL0msFm\/f\/vv9xj19sj5o5cBf\/7rEjo6XRl0sAiIgAiIgAiIgAiIgAiIgAjslsB\/AnAmnnIm8BT+s\/3HhI6rvgA86N77CxbnHgd89MvAkx66J3TccMueyEFRxB46ef5xh+89+L\/\/83u\/f+rv9sqxB2H+\/bZP7G1dufn2vYd0fnxZ8cGYWyz++uv7iyRXf2mv3CgW+HpMcPEE6oSO1Lkm8LCNcTuIHc\/y2Q6yoa1X3bCPHc9\/xCH7xBC\/\/Yfn+S08bY61dpst9L7xok8UOrg96MceAvzK+\/YJQ6zns1\/fs9e2D8VtSfFvnnO\/e+zfXxQ6Un1NGyI3267C3+zfFDqaxoHfXmOihwlm7Ue2O\/KK\/wRccZaEjl7wdJIIiIAIiIAIiIAIiIAIiIAI7IbAYKHjN64BnvvofQ\/HfMDkw\/KHvwg8\/fvzW1e8QPGQg\/LHpraumMhigkHqwdi2PfiH6JRwQTvoBfLi9x8Ya6RO6DBPh+gtQq+DN4ftH9a1ObtTtvIcz8ge9E1s8O2Kx5InvTC8bV588NuM4rk\/fRTwR9fteZ2QPUUrepW86If3hI6\/+MKBMVNSwpSPqRL7OtrGeoybFzdSQocv1\/P894\/fP56K2eTFtc5TTEJHZ2Q6QQREQAREQAREQAREQAREQAR2TWCw0MGH6dc9cd\/DMR+oKXLwkxI6\/JYG28rxhMP3tsGkvA3GFDp83R58LpZIndDht274svz2FH4ft8rY9hZ6SMRAm3XiRRehgzxjEFUvCtQJHRRJjrzfnpeJiVavuXqfuPHFb6QDhNL2v\/km8KEbDvzdCxm0zba8pLj1FTp+88l79XvPnMiz82ST0NEZmU4QAREQAREQAREQAREQAREQgV0TGEXo+Df\/eM+Lgw\/E9AB4xVXAE\/\/R\/kKHiQypB\/05hQ4CbxuzoUnoyIkzUeCwWCRzeXQMETooqFgfvvxxe6KV9+IYQ+io41YXoyNm3\/E8JXTs+lKi+kVABERABERABERABERABESgDAKjCB2H33fv4ZhxOR5+yJ6QQG8A8+hgU+OWjl1tXal7yI5d0rR1pW5rTmpry1xCx5CtK9yyYnE5GNCVohU\/JjKMsXWl7ZYm1htjdGjrShkXDlkhAiIgAiIgAiIgAiIgAiIgAqUSGEXo4FYI89iwLCFR6PBv4207xz3u2hyg0m+beO4Vexj7xuiwei1IZywrbuloE4zUx4DwbY4eLRYcc46tK7bNpWsw0jf85V5sjhjIM24fagpG6vuHjBk8NgYjzXF75CH7xI0uQocFd337J\/dS4CoYaamXHNklAiIgAiIgAiIgAiIgAiIgAtMSGE3o8A\/5fNhM\/X3qo\/cawzgWPIZv9mNGFEuraoIAvUXqtiz4WBf+wbguwCezc1jK15gS1uPOxeGIqW\/N5hjrw8cEYT3MUHPSI\/fEnba25jwa6uJ5WPpaa6ell73n3dLbdrx3jQUhTQlT0ZuibXrZD30RePSh+9LLxrgldemC23p0UKRKpZf9vzftH7ej03RSjI5OuHSwCIiACIiACIiACIiACIiACJRAoLfQUYLxsqE9gTrvlPalLOtIC5CaSh3cqiUSOlph0kEiIAIiIAIiIAIiIAIiIAIiUBIBCR0l9cZItkRvmlTmmpGqKqaYmFUmeqn0MlRCRy9sOkkEREAEREAEREAEREAEREAEdklAQscu6U9Yd0yla7FTJqxyp0Uf\/9C9WCCHH7RnRkzz28s4CR29sOkkERABERABERABERABERABEdglAQkdu6SvussmIKGj7P6RdSIgAiIgAiIgAiIgAiIgAiKQICChQ8NCBHIEJHRobIiACIiACIiACIiACIiACIjA4ghI6Fhcl8ng2QhI6JgNtSoSAREQAREQAREQAREQAREQgbEISOgYi6TKWR8BCR3r61O1SAREQAREQAREQAREQAREYPUEJHSsvovVwN4EJHT0RqcTRUAEREAEREAEREAEREAERGBXBPaEjoc\/EXj4k3Zlg+oVgTIJfPb9wGf\/Ancp0zpZJQIiIAIiIAIiIAIiIAIiIAIikCBwBu52r5fjO7cdJjoiIAIJAne715cldGhkiIAIiIAIiIAIiIAIiIAIiMByCOx5dAB\/AeD9yzFblorALATo5vRECR2zsFYlIiACIiACIiACIiACIiACIjAKARM6zgLAf+sjAiKwj8Ad80NCh4aECIiACIiACIiACIiACIiACCyHgISO5fSVLJ2fgISO+ZmrRhEQAREQAREQAREQAREQAREYREBCxyB8OnnlBCR0rLyD1TwREAEREAEREAEREAEREIH1EZDQsb4+VYvGIyChYzyWKkkEREAEREAEREAEREAEREAEZiEgoWMWzKpkoQQkdCy042S2CIiACIiACIiACIiACIjAdglI6Nhu36vlzQQkdDQz0hEiIAIiIAIiIAIiIAIiIAIiUBQBCR1FdYeMKYyAhI7COkTmiIAIiIAIiIAIiIAIiIAIiEATgSFCx38EcHao4GMATgZwbVPFid8fCODCKs1tn\/ObqmT57wBwwog23wvA+QDeDuCDTQYM\/P37KzYvBHDjwLJ0ejsCEjracdJRIiACIiACIiACIiACIiACIlAMgaFCBxvy6pFaM5fQQXunFiVGQqJidkxAQseOO0DVi4AIiIAIiIAIiIAIiIAIiEBXAlMKHT8O4AOVQRcDeBGA2wBEz4pXATiv8ox4PgB6hTwbwAucp4QXQVjkBVW5\/wDgmQAOBfBOAMcAuLz6Lno9WL05ocM8Jm4CQDv4OdaJIqzn0sq+KwDc4uymR8dXK4+L3Pk5HqzHe8c8q\/I8oT2+nWcCOAMAPTqOrv7Pc59R2WSeNOZlwjb8XtUOespI3Ok6OwAJHd2Z6QwREAEREAEREAEREAEREAER2CmBqYQOe0g\/HcD1lYhxgxMGrgoP8zyOQoFtXbFzbEtIFDooapxWPbxHAYOiweFOWDHAbYQOlvu6yjZfzhGV6GB2cgsMhQMTaEzoaHO+50HRhQLKcZW9rMfaRh6+nX7rCoUOikgUYj7q+MbyHuOOk9DRfapJ6OjOTGeIgAiIgAiIgAiIgAiIgAiIwE4JDBU6YowO84DwD+\/04qA3wykZ8cHEjS5CBz0dKDowlgfLpijBOunFkYtlkYvRYd4mXsywcs3mkwAc5bbpsC7+HYWOaJc\/38QMz+MVAM4FYMIPBwPbch2Aa5y4Qnui0OHbnLKHwsacMUR2OpAnqlxCx0RgVawIiIAIiIAIiIAIiIAIiIAITEWgTujw2ym4vSTG4uDv\/KRidNg2D2+3bSkxbwT7zQKYdhE6aLcF5fRbQmKZPqhpG4+OWK4JFS8Jbc0JHbnzKZRw20vkcWolbNhWGfudvC8LwUej0OGFI7PnTZU3im3PkdAxbOZI6BjGT2eLgAiIgAiIgAiIgAiIgAiIwOwEhnp01Akd3gPCGhbFBr8lpU7o8FthWFZOUKC3RO4zROho69FRJ3SkeNQJEdEzpY3Q4T1M5NExfDpJ6BjOUCWIgAiIgAiIgAiIgAiIgAiIwKwEphI6vDBBrwqLd0FPg0sqLxA+iNMT4aVVStqU0MG4HhZ3wo6LQkcUMFgmvR1sK0tOZImgo7Dgt9u0jdGREzrithgf\/4Miim1ruXflkcGYH9y64strI3QoRse400dCx7g8VZoIiIAIiIAIiIAIiIAIiIAITE5gKqGDhvstJT4Tit\/Wwi0bDJjJB3sLqvn4SvhgGZZJ5cUAHlc9+Eehg39TBLBjbSuM37bCY3IxOvgbY4tY1hS\/JSZuD+H2E7aF\/x2UybqSOz\/Hg\/Wntgn18eig0OGzrjCw6sEue83kA2plFUjoWFmHqjkiIAIiIAIiIAIiIAIiIALrJzBE6Fg\/nXQLTUjwAURLZRE9a0q1s1S7JHSU2jOySwREQAREQAREQAREQAREQAQyBCR0tBsaMeBpKjhru5KmP8p7h7A2y4Qzfc3rq0FCx\/r6VC0SAREQAREQAREQAREQARFYOQEJHSvvYDVvEAEJHYPw6WQREAEREAEREAEREAEREAERmJ+AhI75mavG5RCQ0LGcvpKlIiACIiACIiACIiACIiACInAHAQkdGggikCcgoUOjQwREQAREQAREQAREQAREQAQWRqCv0GEZTJgt5R1Vmy1Ip6WE5dc+A4iheZY7x2dLsd99hpYxcdLmCytxJ2ZkGbMelbUeAhI61tOXaokIiIAIiIAIiIAIiIAIiMBGCPQVOognZvRg2tjjALwIwG0unesHATDtKT8mkPBvfp\/KCsJgmvzYOWN1hYSOsUhupxwJHdvpa7VUBERABERABERABERABERgJQSGCB1EYOLGWwC8FsDpAMxbIgofhozfH1UJGSmhgxlOTnGCic94crH7PnqL+OwiPvMIM6ScB+B8AM8H8DEAJzs7V9KVasYEBCR0TABVRYqACIiACIiACIiACIiACIjAlASGCh1ebPBbUuz7q9w2lVQ7ch4d11Xn2daW0wB8tBIrbGsMxYzDK+HjMQAuqgSMQ51QwjrPAnAJgK9q68qUQ2mVZUvoWGW3qlEiIAIiIAIiIAIiIAIiIAJrJjBU6CAbemi8NHhJmNDBGB7cosKP97Iwz4wjALwTwDEOsvfaSHl3sJxTq\/KsfC+sfC54hFjR2rqy5pE8TdskdEzDVaWKgAiIgAiIgAiIgAiIgAiIwGQE6oSOuP0jFTPDPDK4HeTgxLaSlEeHFy8odFwQtrzwd9ZNAeXEEPeD9dFm\/s7Aohbrw4QU8wThuZdW1MzTRELHZMNotQVL6Fht16phIiACIiACIiACIiACIiACayUwxKPDe1G8u9pW4oWNXIyOJqHDCxJ+GwoDnJoIUufRYVlg2Gfes+RT2rqy1mE8WbskdEyGVgWLgAiIgAiIgAiIgAiIgAiIwDQEhggdPkYGRYgYb8MyrKSyrnB7CbOzNHl0UOjg1pYuMToe64KdUuhQjI5pxs4WSpXQsYVeVhtFQAREQAREQAREQAREQARWRaCv0JGKy0Ew\/J4ZU\/j\/GytSfgsMv\/JBSy3YqI\/REbOidM26ErOxWH32\/eOVdWVVY3jKxkjomJKuyhYBERABERABERABERABERCBCQj0FTomMEVFikBxBCR0FNclMkgEREAEREAEREAEREAEREAE6glI6NAIEYE8AQkdGh0iIAIiIAIiIAIiIAIiIAIisDACEjoW1mEyd1YCEjpmxa3KREAEREAEREAEREAEREAERGA4AQkdwxmqhPUSkNCx3r5Vy0RABERABERABERABERABFZKQELHSjtWzRqFgISOUTCqEBEQAREQAREQAREQAREQARGYj8AQoYPZVPh5dcbcmFElZlOJ2VhYTJsMKczocmnI3jIfMdW0JQISOrbU22qrCIiACIiACIiACIiACIjAKghMJXRYSthjAXywIsXvKG5Y6tkolFAYuQDA6QCuB3A+gEMAvAfAO6oymCL2LABMR\/s77vtVdIYaURwBCR3FdYkMEgEREAEREAEREAEREAEREIF6AlMIHRQjKFJcFYQI+\/7tlfgRhQ7\/+0erMvj\/RwA4E8BtACiGnFo1iR4iJoCon0VgCgISOqagqjJFQAREQAREQAREQAREQAREYEICUwgd3jPj2hrbUx4dtOeFAG6thI4\/AfAMAPyeZdEbhJ+jAFwnoWPCkaGiSUBCh8aBCIiACIiACIiACIiACIiACCyMwFRChwkWNwJ4YCVInFCxsTgcqRgdttXFe3ccX4ka7662rVwC4OkSOhY20pZproSOZfabrBYBERABERABERABERABEdgwgTqhwwsRr0oEHc0FI63z6OA55omR27rCLS8UNbj9hdtc+KHYcVn1hp0eHy+Q0LHhUTtf0yV0zMdaNYmACIiACIiACIiACIiACIjAKASm8OjIxeigwXVCB3\/n1hRuSznPCR2fAnBOtXXloEpw8eWMAkKFiECCgIQODQsREAEREAEREAEREAEREAERWBiBKYQOIshlXfmASwvb1qPDApM+H4BtbZHQsbCBtlBzJXQstONktgiIgAiIgAiIgAiIgAiIwHYJDBU6zg7o\/BaXGJuDWVJOrjwzeFoqRoedHzO00NPjlJCaVsFItztu52q5hI65SKseERABERABERABERABERABERiJwBChYyQTVIwIFEtAQkexXSPDREAEREAEREAEREAEREAERCBNQEKHRoYI5AlI6NDoEAEREAEREAEREAEREAEREIGFEZDQsbAOk7mzEpDQMStuVSYCIiACIiACIiACIiACIiACwwlI6BjOUCWsl4CEjvX2rVomAiIgAiIgAiIgAiIgAiKwUgISOlbasWrWKAQkdIyCUYWIgAiIgAiIgAiIgAiIgAiIwHwEhggdqawpMbPK0JZY5pZXA\/jg0MLC+TErjP18MYAXAbht5Pp8cd8PgOxfCODGCetR0cMISOgYxk9ni4AIiIAIiIAIiIAIiIAIiMDsBIYKHTSYIoR9mAb2uBGFgjmEjilElKaOlNDRRKiM3yV0lNEPskIEREAEREAEREAEREAEREAEWhMYW+iID\/A\/DuADzppjK88Mfk9vBn6eAcB7gtwLwPkAng+A3hVHVmIKPTpY\/jsBHAPgcgAUVugRwfJOAXAzgJdWv1HAuKg69lkA3hGoNIko3g6earbThguqsv6hsuHQjF2xDNrx3sqWE0IbWneaDpyNgISO2VCrIhEQAREQAREQAREQAREQAREYh8DYQof36DiiEgROB3BtJQiYt8djKgGE4sFHK2HjhkrQ4JaYwyuvEH\/cpyqB4O3V\/3PHWXkUSGjP0QB4rIkiRq5J6IjlUzQ5uTqZYstplWgTy\/HnnQTgqKpdPO4cAK8EQGFEW1fGGcNTliKhY0q6KlsEREAEREAEREAEREAEREAEJiAwVOg4O9jkvSyiueZ1wfgXFDC8+EARgoLAeZXoQTGDHhzmEcG\/vxrEAfOsoJBC4cCXx39fVwkiuW0iqRgdZv+tGTuuAnBNEHDYLl+3r+9EJ3R4Htq6MsFgnqBICR0TQFWRIiACIiACIiACIiACIiACIjAlgTqhwwcbfVWIxUGb+Ds\/3CJiggSFAL9FJAYstUCfFDq41cSCfprQ8abqfIub4YUOq9M8MyhUXFiJHxQ6fHldhI5UjI6Ut4eVSaHDe2PE7Tm002\/F8Qz89hd5dEw5sscpW0LHOBxVigiIgAiIgAiIgAiIgAiIgAjMRmCoR4cJHfy\/xc+wLR3R0yF6dKSEjiEeHWMKHV5g8Z4l5tERhQ5fd67zvDDDYyR0zDbMe1ckoaM3Op0oAiIgAiIgAiIgAiIgAiIgArshMKbQwRb4GB1+e4ptBeExtnUlJXTQuyKWwWCm9IRoitExptBBO+tidHiRInp\/0H7awv+\/wG2hUYyO3YzxIbVK6BhCT+eKgAiIgAiIgAiIgAiIgAiIwA4IjC102EM\/Y2q822VP4VaOM6sMK8y2wgChOaEjZl1hJpU\/qGJ2NGVdsa0wQ7eusCvqsq5Ebwxvl9+2EuOA2NYV+97EIWaO0ac8AhI6yusTWSQCIiACIiACIiACIiACIiACtQSGCB1CKwJrJyChY+09rPaJgAiIgAiIgAiIgAiIgAisjoCEjtV1qRo0IgEJHSPCVFEiIAIiIAIiIAIiIAIiIAIiMAcBCR1zUFYdSyUgoWOpPSe7RUAEREAEREAEREAEREAENktAQsdmu14Nb0FAQkcLSDpEBERABERABERABERABERABEoiIKGjpN6QLaURkNBRWo\/IHhEQAREQAREQAREQAREQARFoIDBE6GBmk7MT5T8LwDtq6vUZUfp0UMyG4su4uEpfe1ufgnWOCAQCEjo0JERABERABERABERABERABERgYQSGCh1s7qs7tnmo0OGrY1rXCwCcDuDajnbocBFoIiCho4mQfhcBERABERABERABERABERCBwghMJXT8OIBTnHfFMwEcBeA6AJdWDOj58TkArwJwGICPVMef5I75GICTa0SMlNBBIeUHqvPMu8R7n3iPk+gdciyAD1b2+XNoY1dBp7Culjk9CEjo6AFNp4iACIiACIiACIiACIiACIjALglMJXSwTRQ3+HkvgBcAOA8At5R4jw4KIhc5MYN\/83eee2P1b5aRExlyQsfhQWQ5rvr7CADvBHBaJWiwLivf23KoE2r4+1kALpHXyC6H6k7qltCxE+yqVAREQAREQAREQAREQAREQAT6ExgqdMQYHd4Dg94SFAiOqWJ5eE8JenYwjkcUNmJLzBOkq9Bh4oV5bFzl4oaY0EIBhjawbNpmx769MsJ7pPQnrDOXTEBCx5J7T7aLgAiIgAiIgAiIgAiIgAhskkCd0NG0dcN7Q+TgxS0sPC56dHhBIRVotG7bSM6jw4SUXOBSlvmmSug4IRhvW1sosvhtNnUBVjc5eDbQaAkdG+hkNVEEREAEREAEREAEREAERGBdBIZ6dJBGztvigQDOqbZ7\/G3Co8I8OmIsD9tmwm0ufT06otBBLw3zKLEepH0XAiCDukCm3tMjlrGu0aDWRAISOjQmREAEREAEREAEREAEREAERGBhBKYUOui5cSWAj4YYF3UeHRQ2TOi4dyWOUFzounXFhA52R6pMCh8UWrxXCr1DLH7HkVXwVNZrW3AUo2Nhg3sEcyV0jABRRYiACIiACIiACIiACIiACIjAnASGCh0xRgdt57YQCg3MsmICBUUE1vVCACdWW0Is64r36KCXBQUIbie5HMCbATzVBRaNbJq2rtjxuW04cWuLbVvJfT9n36iu3ROQ0LH7PpAFIiACIiACIiACIiACIiACItCJwBCho1NFOlgEFkhAQscCO00mi4AIiIAIiIAIiIAIiIAIbJuAhI5t979aX09AQodGiAiIgAiIgAiIgAiIgAiIgAgsjICEjoV1mMydlYCEjllxqzIREAEREAEREAEREAEREAERGE5AQsdwhiphvQQkdKy3b9UyERABERABERABERABERCBlRKQ0LHSjlWzRiEgoWMUjCpEBERABERABERABERABERABOYjMETo8KlZh1psWU6Y9pXpZFMfZmS5sMrecj2A8wHUHR\/L8JlX7LePATgZwLVDGzDB+T5TzY0TxA+\/ogAAIABJREFUlK8imwlI6GhmpCNEQAREQAREQAREQAREQAREoCgCpQgdbaB4oaOPMJESZp4J4Lia9LVt7NIx6yUgoWO9fauWiYAIiIAIiIAIiIAIiIAIrJTAVEIHvRHeCeAYAJcDoKBgXgn896UA6E1xBYBbAJwXPDS898Wr3O\/Pr857NoAXOI8OiiDvAHBCoj7rupTQEb0m+tp9SOUZciyAj1Ztoa388DvzUontenV1TOr7aNuPA\/hAdfzFTpzhufcF8JSKt\/9tpcN2tmZJ6JgNtSoSAREQAREQAREQAREQAREQgXEITCF0mOjAbSUUH\/ggfnj1YH4EgAsAnA7gq9XvFAG80MGWnVIdz3+fBeCS6vjU1hUTFmwbC4WUowCYiFAndHiPjntX9vA82tTF7htcfV5QoThxUSWCHJppV+572s3+eSEAHkPh6DQnpFidrI\/1sC3+uNwWoHFGzjZKkdCxjX5WK0VABERABERABERABERABFZEYAqhI+UlYeLGY4MIYaJETui4zbHOxeigYGKCQF0si1SMDu9tQrGAx5j3iW\/HiQ12X1WJJCbymFjiY494Ace3i\/WasOO\/9\/UfHY7xttKzhR\/W2SbWyYqG7+RNkdAxOWJVIAIiIAIiIAIiIAIiIAIiIALjEqgTOnLbLMyCXDDSKBh4geLp7qGc\/0wJHfREsO0tPOZZTkRIeXTwGC9Q5Ah5e00QMIGC5\/itIVaGBStta7ffQuPtsDak2mUcuJ3HtzcKLT6WiP+NQsd1FSMJHRPMj7uMW6ZKEwEREAEREAEREAEREAEREAERmJBAiR4dfsuFf3D\/VCbrShePDqK0LS0Wj4PbQVhnzrPCCzJ2bk6gaRswNSdI+O99u5o8OiR0TDNJ5NExDVeVKgIiIAIiIAIiIAIiIAIiIAKTEZhC6Bgao+NIt02ED\/5NMToogDAWiG0XyWVSacq6EmN0sBxuKbHYF02xRXzAURNUvJiSa5ffzuPbyzLaxuiQ0DHNFJHQMQ1XlSoCIiACIiACIiACIiACIiACkxEYKnScHSxjhhQKDm2ylzA+Bv87KAQjjVlLbNuHeTs8HkDMulJXn5mYEjqiKOPLsW0rlsrWtp3k7Dahw+y0rCvR\/rbfd8m6IqFjmikioWMaripVBERABERABERABERABERABCYjMEToGGpUKk7G0DLnOH+pds\/BZm11dBY67gbgMQAeAoAq2oMA3HNtVNSewQQYdZiRk\/nfFwD8bwDfGVxq+QVofpTfR2u0cAvzTXNrjSN3\/DZpLozPVCWKQBcCW5iDXXhMfezcQkcM+GkeIFO3c2j5S7V7aLu3fn4roeMQAM8BwNQ8jBh7n61TU\/s7E\/gGAEZGfi+AtwG4qXMJ5Z6g+VFu32zVsrXMN82trY7g8dqtuTAeS5UkAn0IrGUO9mn7HOfMLXTM0SbVIQJjEagVOu4P4PUA\/jWAe9xR413uAjzgKODQRwIHfTdw8PcA3yWHjrF6YzXl3H4r8M2vADd9Ebjxs3v\/7ft8uwo69BIAX1twmzU\/Ftx5qzJ9ffNNc2tVA3TGxmguzAhbVYlAgsD65mAJ3fyTAP40Y4iEjhJ6SDaUSiArdBxVTSr+H\/i+nwSOOwN42LHAPQ8utTGyq1QC37oZuO5\/Ale9EfjMn5mVDLzDizf\/v7SP5sfSemxL9i57vmlubWmsTt1WzYWpCat8EagnsOw5WErv0guaL5z50PaaYJSEjlJ6SXaUSCApdDwSwIfviMFBj43n\/A\/ge3+0RONl0xIJfO7DwNv+JXDLl2k9c0xzcC1J7ND8WOK426rNy5pvmltbHadztFtzYQ7KqkME8gSWNQdL6kmGD7gIAGNV\/UOVrtUEjyFCRyqLCdsds4V4FrnUr314WcaUE8LJFwN4EQDGeyntw1gfTFlbqn2l8dq1PQcIHXTXYDqeI\/HgHwSedzlwP8Yd1UcERiRw0w3Ab50AfOkTLPTTAB63kLgdmh8jDgMVNROBZcw3za2ZhsOmq9Fc2HT3q\/EFEFjGHCwA1AEmfAXAodW33AJugse9AVCwOKvy+Ohie07oqCtjCqGD6WxjalfG9XtHl8boWBFIEDhA6HgDgF\/FvR8A\/LuPS+TQmJmOABe73zgGuJWJWfBGAGdMV9loJWt+jIZSBc1KoPz5prk164DYcGWaCxvufDW9CALlz8GI6UoA\/6wIdvsbcTuA\/wPgmJGFjujRYRlL+CL8CgB8MUGPBoosFCPokUEvjPtVYsu1lVfIOyvbLgdAgeSOG373MY8OL3TwZx7Lbaz8nh+fMcV7e3iPEF8\/z7mgOpeCEMujSJSyx1LNPr86\/llVm3LfR48OikVnh3ONH7ccWbnHOjGnwKG0WpP2Ezo4CK4HcC\/8wh8Cj\/rp1bZaDSuEwCf\/EPivP0Nj6J52eOHBSTU\/Chk2MqMngXLnm+ZWzy7VaT0JaC70BKfTRGAkAuXOwVQD+bB8l5Fa3reY6NHBcujFQbHhP0wodJhAcBqAjwI4v2oAhQ4mFeCHggTFhJcCOLnalk4BxAQMigG8x4\/bPVJChwkM5tFB0YCixenVMyrrv6Eq23uk+PppE0UN2kxPkViPt+ckJ6rwuHMAvLLKNGpii\/\/+aLd1hedyG4sXUlgnt+Wz\/tdVokmu\/X3Hgs5rT2A\/oeNcAC\/H9z4e+BWG6NBHBGYg8IYfAb5wDSvixYUX61I\/mh+l9ozsak+gzPmmudW+B3XkWAQ0F8YiqXJEoB+BMudgqi27Fjp8jA4TOLhu8jN1jA7\/YM+XkubRQBHjPOfBQTHgwupviiN8uDcvjlzMj1yMjlc5b464VaZN\/eRi4gi9S3hOzp4Tg\/eI9X\/0KrHvvUcHhR7GGLQtNia8XJaoX3E9+l0lhp61n9DxGQCPwHP\/GDj6qUML1vki0I7AJ94D\/PY\/57F\/DYDBCEv9aH6U2jOyqz2BMueb5lb7HtSRYxHQXBiLpMoRgX4EypyDJQod3AJxz0pEMIHD7KwTOvy2Ci8e2LltgpFSCDjOeWPYg\/6bKo8FelpQTIhCxwcCSG57obcHj7VP9LTw3ht2HAWHS0NZ3ApzZrVlJFU\/DyeXF1bbZfzWFyvK2+M5+S0mqe+t\/a8AwL7wsURMHKHQEeuX0NHvKjH0rDuFDu6r+jru+l3Aa7nlSx8RmJHAy+4B\/P0d4+4+AG6dsea2VWl+tCWl48onUNZ809wqf8Ss10LNhfX2rVq2DAJlzcEcs117dDylio2Rsq9Uj442D\/aprSsUC2w7CGN65DwrvLAShZaU0NHWHvNKiYKM91axsuo8OiR0lHEFulPoYJCdK\/HQHwF+9eoyTJMV2yGwz33xeAB\/XmDDNT8K7BSZ1JNAWfNNc6tnN+q0EQhoLowAUUWIwAACZc3BUoWOOsBTCx2s2+Jt9I3REcULa0\/XGB0UH3y8i1yMkCh0xHq8PS9w2098LI7c921jdEjoGHBZGPHUO4WOnwfw2\/ihpwHP\/v3W5b\/1KcCpjz7w8Bu+ATz7j4ErP9+uqOMfCvzOTwGHHwTccjtw8+3ATd8GfuC\/NZ\/\/CVqOdsc2l7Z3hLcndQ5tPO19wHN+ADj6Ad3a2taGoced8ijgoicDl10LPJcxksPn7CcAZ\/ww8Ia\/BF71oaG1DTz\/bU8DPv4uFvJvAbTo9YH1dT+99fz4s38FPPmIdAWfvHH4OGX5U405jpnXPwl4819NPybq5tglH0+P2RRVK+e9\/7f9OXXlHHz3vbn99k92HyS5M8boszHKuNO+suZb67k1Xo\/kS7Lr5n3vfuAxXcblHLbOXceoY3Bu43P1bWAu5Nak2\/8eeO3V01\/rx+5qf8831ZhkHY\/iI0\/iM4Tb0PuuKe53x+6fzuWVNQdz5u\/ao6MO61ChwzKGWB3c4pLaemFbUZhF5BHV1hGfdeXFAB6XybqS2rbC+nJZV7g95CK31cVvPfEZXHyMD18\/y\/ZCA\/\/mthjLuuLtiXFCbOtK7vsuWVf81pk2HiWdp49OaCRwp9DBPU5vxON\/EXgaM\/S0+1DoOPFhBz7o82J8v3u0FwB48f\/lfwK8+P3jPmC0a0XzUVxMv+c+Bz6kTrXINlvUfMSihI7ffx7wv97KRv1KFcyouYHzHtF6fuTGyljmTjnmdiF0RIGC14KXPW7vOpAS6CLHsYQOXst+lks3gI99BfiJ9npvY9dO2WeNlacOKGu+tZ5bvdra8aTcHOg6LjtWq8N3RWADc6Hu\/uVxDx5f2J26K+d+2M\/d5\/Zp51Cho0+dxZ9T1hzM4Vqr0DHm8IgBP8csu01Zu66\/jY06Zn4CdwodTKXzn3H8K4Cf+rXWZuQWAHv4+NTf7XtgiG\/K7O129Ap53\/V7ogI\/9OjgIv2w+wH3uOuexwc\/PMYeRPyix39\/6zvAI+8P2Bs5\/xYuvkX+0BeBRx\/a7NVQd6NwzIP2bDqUCZGCbfzbv02pexNgYs+Hvwj8zMP3yvIeAPz9mY\/a+\/6o++37zZdvniZ8SDTen79l35sJ72kTF9zIJh5LISra9q5P7z2U3v2ue544vd+E\/9HLgD\/\/dTaNwX1e03oAzndg6\/nRRujgOH3offfxsr66+kvAh27YE\/1y4yA+NPv5E8cXj73\/PfbNB86FL35jX58Rn53zma\/veQDFeRPnrZ97sfxrvwY85D77j4PcQ36dQME2Pf3795WT8v6gHb\/2kX2eYH7uxWtKm7HJPvmbb+4NqOgxY3Pz+puBxxy2d0z0Wqur0xhceT3wLx6x\/\/XGt5Xl+j7w8z9y9G8c27Rvv6lS1nxrPbfmmO51Yp+Nkbd9Ajj3OODL39wbDzYWDr9vff\/ZumZviv3axLK\/\/m3gsdX44pv2939+\/\/EdPcJMfOH1N649ufWWx\/X9zY\/BJz107zpVNyf8GP3ol\/euQzkPwzn6NlnHBuZCbk1KvQypu1+p+y2ORb8W5e5tcvcPZi\/7KzdX+JvdH9r1+t8\/vv5ese\/9X+o+t+5+ibbl5qbdd33ltr37uLiWdLnf5bl+jvF+9nsPBuzlQRSEutzzxbI7rzFdJnRZczBnuYSOA8lYGlh6ePCT89roMhq6HLvr+rvYqmN3R+BOoWPP9ekpZwJP4T\/bfeqUbr+4xgU1CiHRoyO6JnIrgN0Usk6WZy6XUeh4xCH7fqMN\/o2F9zRhC7ld5kH3anbfrBM66mxLPZT6BzhP2RZGLoDc9mP22RYe+\/2qG\/aJPLF9\/m+ez4cmfkyA8O3njaptXbEbai9Mea5W919\/fe\/mwv7+9t\/vlX3DLXss\/fntRlB11BX\/CbiC6cDvyAnefgB2qmTQwa3nRxuhI47\/FOvcOPBj6t\/84\/3nQpwbPPa4w\/eN7\/hW2uwgGY45Pqj5rStegKGwGP+O5efmeWpbSZ3Q4R82bWz6rWy+Xvvd6ogMvOCX2wrn6yOLuKUrjv\/IoalO67PXXwO8+LH7zxN7eDbRxuZQHCO+33lD78WYzh4jZc231nNr0AxueXJboYPXVorINqaa1jh7SDShMM7FKH5a\/9u4j3\/H+vzff\/GF\/bct+rFUN866jEGuHxS5bU1IXRvi2suH1uK2\/2xgLrQVOuruV574j\/YXn71A+8hD9vfCi+tKHCtN9w9t5gqnc0roaLpXNE\/jLvd\/8T439SLPr+F1c9NeNNTNm6Y2+LbXzbE6oaPpni+Ohc5rTMvr7R2HlTUHc5ZL6OjSpzpWBMohMJ3Q4RcH3pjHrR9e3OBC6beu1O3BjItIFDpsEeD\/vYLNN9Yx\/kB8QMn1S53Q4R844s1mKt6BPdhE1\/iUS2O8mfAPYKm3MX4B5lvHGKPD1+Ef6B5y0IFbkOoe\/lILfZsH\/Oy4L3+ha\/0w5t96xfb6m3wbe9d8ec+ryMSopnFgcWFSD82sr+v+ZX8DE4WO1M2NH5OpGDVRtMltSasTOpq2o3hGUehIjbEmV+eUt0TuOmLxbJrKzPWDFyk879SNp29LndDReT0pa761nlud29njhJzQ4dcK837y3gmp659f45rmShxP0asprmdPODwfq6fOlrd+fE+wTInSqet6bgx6oTzOiV95357w7QXOYrf+bGAu1N2\/2IMy+7nufuVzN+0vdDRNLX+9imOl6f4hte7k7vPqrotN92Nt7\/+i0JF6weevG3VzM7W+97nftTnm53FKPM2tY033fHVtaOr7zr+XNQcldHTuQJ0gAkUTmEfo+M0npwM7mTvcHEIHuyE+dLXdL9lH6IhbBPww8O7\/9n30aok3tl6Y4I1lznbvXh1vXPzCT\/tMOOGilgqgae6nse7Ug6iEjr2e7MLB3E69ANI0DuwG5O2fAE77pwe6gvv6c29houu6d733Yyb1MN\/08OZvAulx8mMPSQdg7SN0eDddG5s5oSO6DucCwabsiA+ZTTenfg7bVi5+Z3XGm367DvG6x+1oz7t8L3Cz3\/4St8ZEQcq2uPQKjFfWjWVxQoffPuSv2zZPUyKzH5v+HB+4Oor9vk+5RvqHktTc9Q9TP\/d9+x\/v62yyhW\/nLYh43RasujFYJ3S85uoDH5pTzIq4NdrAXMiJ7347QrxexvuVuE0w5ZmTW1dyQocXwuK61XautBU6eL\/T9\/4vChs5nnYtrpubTWtJnPe5F3ucY\/FFVlzL6jw6mu75\/FbWXmtMl8ld1hyU0NGl73SsCJRPYDqhwy9cTW8\/m7au5LwmGKywrUfHLoSOLllNmh5wpxY66jJ55PZ25m5UOo\/78he61g9jfYQOL3w1jYMhQoe\/EbU66zw6+ggd8WGMsUZSQUXbbl2hqGcPbvbgldp2ZWPR37DbzXjd9SfG1kgJkk03p011esYs3952H1nt0U55d5lgkhJLLJuV3yfeaQ91WfOt9dzqfF3pcULd1hUrLid0eKEiVp26LkwpdNTZkhLm6uJ\/5AS7uL7ZPJPQ0WPg7Z0yyVyIY8+uV34bbNuXPjTSrsep+E6pdWWNQkfd\/VLdetO0lswpdLTJ3tZ7jekyBcpaj7YmdDBVK4N4Mt3qjVXjmZ0kZixJcYnZR7r0ejyWdsTsL8+q0toOKVfnisA0Qkfd\/vJUytk5hI5dbF2pS+8ax17TlgW+\/Z1y60oudgjtlNDR\/ga0rdBhXgP0SDjhyP3jaMQHiNR2kT5bV1Iut3VCR+qtctPWFbsRZlDgw+4DvOKqdCaltsFIWV70TKrbupLiX3fjmfuN39t+7rq317ZPPL6BrHNHpo0MsMzPOz6ZT+\/YhjXL6Py2vKwby0ke7vqu7X2Fjpz3lNnRxR2f5wzdutLmIcZsS9WV+s1vv9HWlb4jrPa8SeZC6ppoAm+dl1Kdpf4ej9taYva96MXm17Qmj9Auc6WtRwfj1vTdupzaulJ3v1R3LRhL6EhtXanb1h3v47h1pa4Nse87rzFdpkdZ69EWhQ4KDF5UaCt0dOnlpmMpdPDz6ur\/tOECAMzKdm3TyfpdBGoITCN0+IcEChsxUBkNyrlzM2NInz2LfOCoc9WzN8N9glHlHl6b1Hf+7oNF1S0W9pbFglSlArbGB+BYvv+bjCm03Hx7PrhpDEbqAz7WxQdpulHpPOXKX+ha34C2ETpSNyT+odoH+asTDdsEI\/UPPPGBxm52c1tX4rxNBRxMPVBZubntIhwfOaEj7jPOBXZjFiafmcI8OuKcNDfjlC1N89HmB+3Nvb2OAfF4vYt1RpusjRZwluc0Bbiru6Gve1BNzsWy5lvrudX5utLjhL5CR9Max9gsPshgfOCJa1fXYKSp+EzM4mTeQjZ+cgFxiSr18JRbi9uIfwpG2nkATjIXcmsS+7YueLu\/PrIl\/sHYj9\/40BzXlT4eHW3nSluhw7x\/+9z\/5YKR5u6X7N7LYvj4ucmsal3WkjrxIl7341bYeH\/o+zsV5LtOWO+8xnQZ+mWtR1sUOu4L4BgnKkShg54bH3BgjgXwwcoT5BQA7wRwMoAXAbgNgD\/\/VgDnA7DMLHZu5ByFDsuo8vaqrgdW3h0nVCe+qhJFeN51zvODnin8vKOyg7axbZc7r5WYrUWeI13m6\/KOHS502F5f3\/bUQ0XcA5pKX\/ri9++9\/Z1K6PBueLSX6bi+7\/6A1Zvrv75CB8uL+6VzUeftxsGnHYvpZVNbYeyhinXF9LJ8g\/HprwFPeMhey+rSy8b9tXH\/bpc3Mp3nQfkLXesbUN8fkQOZXvRXe8IfP8x0EoVAuxHKjYP40Oy3XqTSy0Yhwo9HjoervgCc9Mj9sxgxO4K5IMdxEdPLpoSONm9\/4lw0Vqn9wLGNvEbwptse5LywYA9rloqac4hpY\/1Dl9UVbwR9f\/kHTaZBrLs5jW2JdcZAlLmgj3XXSN\/vtJPbX6yNnfdQlzXfWs+tzteVHif0FTpYVVP\/xVTkMb0sy\/CZgVLjyv9eF4emab31sWTiupD7re4tva11vg3+WsP0skccDLz5r\/IeTD26a\/gpG5gLufsXG18H333\/zGyW0pVw4xht81tcV1hOl\/sH2tt2rnQROvre\/+WCj\/pYPnHrYG5ujuXRYdcBf79B7uzLKLDYOvGez+7FzLI5WHfPF1l1XmO6zMyy5mDO8rVmXTGhgO0+qhIPvFBxaPCsoJBwXCVqPIYOpdU551XbXeh9wWOsLC9gUDC5qBJFopdGyqPDts+YWHKVEzDM24P20QaKLPwwc+MlAL5aHUsPEYoyLP\/w6riTnH0UUM4BwDT3tnWny+jVseUTGCZ0lN++egtT8RB21aYue2R3ZeNk9Za\/0M32MLaGccAbqHOPy29bmWwcLaRg3kT+1gn121YmbUpZ8222uTUp04bC69zZd2nXXHW3EZDmsmW\/ejQXdoK9rtK55kpJ939jdEKbFwxj1DN6GWXNwa0KHe91wgBFglyMDh+Xw4SOVwA4FwCFiHdXHhz0xPhUEBuil4ZnnYrRkfP+oDhxYWUjbTWhgqLHqQDOBEDbWKbFHvHizYlO6Bh9OKvA4ghsR+joE0Buzu5awwNub17lL3SzPYytYRzwDVgu20rvMbKiE9nHPtvK7E0ra77NNrdm5+wqnOvhbZdttLpz6UO7xA2ZrR2aC7OhblvRFHOl9Pu\/tmzqjpPQMQbFbBlL9ejwAoJt94gCg239MBHjLQBeBuCFlZdDFCEuDh4d9KYwL4nLnEjCeriFxLabWL2prSK5rSvmxRG3z3zMeYbw3CsBHFlVwDrj8fwpnmPBT3OCyqQDSoXPRmA7QgeRxgwLdTEEZuuCqqI1POD2ZlbWzWaqGbM9jC15HKRcoXuPiZWeGPfF76SZZc232ebWTlhXlU7x8LbL9jTVXbd1puncWX\/XXJgVd5vKpporJd\/\/teHSdIyEjiZCg35fqtDR1Ggf48I8Lm4G8NBK6Dg6eEakPDoodBxRCRy\/B+CHqu0s3vOiKaBoFDpot22BeVPwDInl0qafrRrKbSusq21GmC42NrHU72US2JbQUWYfyCqUdbO5U6FDo0EEJidQ1nzbhNAxeZ+qgn4ENBf6cdNZIjAWgbLmYK5VWxA62HZu8WAAzy9VQoMXOixWBo+juGFbVyw+hgUd9R4SXsCwsk+r4mZ41nUeHX5bDeNtUAB5qfPosECln3MBUe07i9HBcxjLg\/9\/gQtgqhgdY83jcsuR0FFu32zIsvIXOj2MbWg4rr6pZc03za3VD7iCG6i5UHDnyLRNEChrDm5d6GD7vSjgs6Zw6wfjXzzDeXtYIFBmW\/HnWWDPthlOUjE6\/FYbln1p1TnM4EKRxTKy8OuYfcWLNsy64retxAwu2rqy7guNhI519+9CWlf+QqeHsYUMJZnZgkBZ801zq0WX6ZCJCGguTARWxYpASwJlzcGtCR0tO6now7T9pOju2blxEjp23gUyANq6okEgAjMSKOvGUkLHjF2vqgIBzQUNCRHYLYGy5qCEjt2Ohq6123aY11VxPLqer+PXT0BCx\/r7eAEtLH+h08PYAoaRTGxJoKz5prnVstt02AQENBcmgKoiRaADgbLmoISODl2nQ0VgAQSC0PHwJwIPf9IC7JaJqyLw2fcDn\/0LNumsKnJzac3bexjT\/CitX2RPHwJlzTfNrT59qHPGIaC5MA5HlSICfQmUNQcldPTtR50nAmUSuFPoOAN3u9fL8Z3bDivTTlm1egJ3u9eX8Z3bXgPgDQW2VfOjwE6RSQMIlDPfNLcGdKNOHYGA5sIIEFWECAwgUM4clNAxoBt1qggUSCB4dAB8rf7+Ag2VSesmQDeiJxbv0aH5se5RuJ3WlTTf9jw6NLe2M\/rKaqnmQln9IWu2R6CkObhFoSNmRrm8yqBimVPqRmQq20nTCPb1+cwqPO\/HAXwgZEmJ5dn5PuuKHcPzaROztLSxv8nWPr\/71LZfrbzUX1hjD+OM8D6Ixxza4vg+Nm35nAOEjlK3Dmy5k7bQdnvYKXX8lW7fFsaI2jgegZLGc0m2jEdYJS2FQEnjryRbltJ\/snP5BJYw7v8BwF0KRT2Enz2UUzR4R9U+igUXATgZwLUNbe4jdLDOcwC8MvHwT4GCH7MlVf2ShI4PthgzXujYlTjTwszFHiKhY7Fdty7Dh1yo5yBRun1zMFAd6yFQ0nguyZb19LBa0pZASeOvJFva8tNxIjCUwBLG\/VqFDgoLRwF4dehE\/z2Fj1MAvAjAbZW3BM+5DsCl1XnPSogTlhHlGADmJWIixgkJrw3WaeWZp4d5ePC8iysb+O\/zAZhHh6+H5\/EclnVrddzzG2zk+LsawOuDTSyH5TGkw0equh9TeZx4e8jEe6nQziMrptGjw9vK48j9EgDkQUb0bj2j8u6g6JFqP+ujwHRfAE8BQL7Gxn47u2pz9JgZOleXeL6EjiX22gptLn2hK92+FQ4JNWlCAiWN55JsmRC5ii6UQEnjryRbCu0umbVCAksY92sUOtp6RhydETr4kJ7z6IieIjzu8EosuDeAC6stGtFjxAssJgqcBuCjlWhxA4DznNDxqUpgMY8U1mNCx4lOxMl5kVgd76pEB9Z\/nBM1vGcLj70AwOkArnf2GAcmGNivAAAgAElEQVRrn4khxwLwQgenrm+3sbsms3WF21jeCSC23+qzdvrjWIeJUvw3veQppDR55qzwsnJnkyR0rLl3F9S20he60u1bUFfL1AIIlDSeS7KlgK6RCTMTKGn8lWTLzN2g6jZMYAnjfmtCh99O0UfoiNsxvEjAh\/82Qkf0JLH4G6dWAgvFjZTHBMcT4114oSM3vbxdFAMoiJhtFBB8vA8vgtBzwux7BYBznYeJF5C8fZGj2ZSL0RGP9\/FHXlCdTNHD1+eFDtqoz178kzO572wJFxp12HoJlD7+SrdvvSNDLZuCQEnjuSRbpmCtMssmUNL4K8mWsntN1q2JwBLG\/VKFDj6o57Yx1Hl0DBU6YlBQLyC0FTqisGA2vcQJHZwHXoyIAotvPz0sYsyMeHwUOuKWHdtaY\/OP200oqlAcoejA8nNCB4UX8xbxIkRO6IjH++ModHDrEGOZxH70W4BSW4rWdO1o0xYJHW0o6ZjJCZS+0JVu3+QdpApWRaCk8VySLavqZDWmFYGSxl9JtrSCp4NEYAQCSxj3SxU6mrqnT4wOigf81G1dKcGjwwf29AKG38YRPTr83\/ToSMUmifFMotAwl0dHTuiwPq8TsprGxZp+l9Cxpt5ccFtKX+hKt2\/BXS\/Td0CgpPFcki076ApVuWMCJY2\/kmzZcbeo+g0RWMK4X6vQ0Sbris\/CQm8MehHQc6GEGB0Wu+Oqyi4fo8N7PTTF6HhddX6M0eGFjiiK+LgjJ4XYHkyRG2N0UDixGB8UW0wwuqxnjI6U0MEgqBZclkKHYnSMuHWlKQ9z3Gs1luKk\/MPrWA1LX+iG2Ncn\/dYYveoVbAuclMo73qeuqedddFlM2ZhT6Pu0J56z9nRfQ8bzGHx9GUNt8a6pLNe7p44996I7bh8WdmNpbq6xjLr2dK2vzv24a1lrPX7o+BuTSym2+Ps1uonbDXWurX3fHLKe40PGh7muvZobY47cYWWVMu7rWrFWoYNtbnp+4zG2LnGrBv87yAXv5HaOtllX6GVRd+8WPUy6Zl15MQDObaau5YeiDDOaxHsD62u7DtwEgNlZLDuMZTzxQgfP8fb4Y2PWlZsB\/EEihkiqPQzOaul0u2RdSQkdJvzUZZoZNluXd\/YoHh1tFcE4YMbANdeiOIatKiNPoPSFboh9Yz9stR1HcwkBVKnJh\/sUx8oBLqGjbS\/3O27IeO5X4zRz379R4Z5XH6Wdb5zGnntTCx1N7enKXutjM7G1zIXmlvY7Yuw55K1g2VeGffNzjdm56ulHfVtnlTQHc+TXLHRsa7Tt31pdB9bf+6MIHV32eFHleqlTzSzPcSofslfL2BV2E2s5g3P5h32gGgs84xfrXF7inFK3\/mGw+xaWvtANsS+OPQp+fh5wHDOFFce1qeL2Ri3OFwoJUX23N9jmVsfeZIBhpuH6+Sov+LMB0I3PR6k2BTsq3RbI6GMArgBwS3jjZsJmzPudykMeFXCf6zuOOpt\/Vu\/BIWe6KdQsw6Jc8zsef7JL9+WPs7zvuYBc\/pqSyvMer0G7nynjWDBkPI9jwb5S+tpi88BcVq1Ecwfl2w4LHGbzygfpiuOG8yUVtM2PEeakt5RunIt15R1SjUvOT\/+WheOX7qXRo6OpPbYvOBVczc9JcqCdPD731ppr5H0BPKW67vh56ddBlmMp89Yawb3v+Bt7HrC8IbbkxgDLrQtImGqHrT8fAfDb1QF1Qe2iR0eb+nJu1TZmc+tJas7RDbzNm1a\/1qXmhq0rba4Fa10bphjXTWUOGfdNZY\/1u4SOsUiWVY6EjrL6YwprBgsdXfIwc8+SLZZ2M5rKh2w3gHV5l5vyD8f8yZYuiBBTeZDfFNIdcTHlx9yJpoCvMoc\/7MzFcMhCnBLZ\/MMPH3o43phKyqJH89+p+ZLK1215vsnCcm5T4MttXeEeSx5nexL9PDvCzY+4F9OzjltX2pQX847H8mK+cP5OoYIPZfyw7d7tn\/nTY07y1HH8LpVX3NqXut6Qw9heKnON1Tb1DBnPbcrvcswQW+yhxx7sY71x7vno7HENsvH2mEp4pHhmY4QCIdcCv\/\/Xz1eKHrE8Pix5ccIEA5Zv+3djBPim9viXCjECvQk+fh8x22Tj2Keq45wywYYeWTb3OKfYTtpt4oxxkdDRZVT3O7bvXIgiWS6gHq1qs2d7yNaV3PXWBwDkMbSRaSLpqh0zEHA8vsu5xlumAs6d1Byuu3+zeckx7WMNpOaGCR1114LUerHWudFvFHc\/q++4715T\/zMkdPRnpzNFYJcEJhU6omLuF6h4k8YbSX5Sx9Alvk\/+Yf\/QaA86PmCMz4PMxYuiC4HEBXmXHbSVuktf6IbY1\/SwZfvsus4Xn8aKDznXhEBHdUKHD4jkb2o5PyyQEcdezlsrCh115fl0WrlYPal86amtbl5YjUKHnytt8orHbQhTxx0paS4PGc9jt2OoLU1vsnPxBWxsm9huQoGfN\/5hiGJG3dufXHl1Edmj0MH6cu1pGwchZ38UOlgX1726uZKbr2OPgV2WN3T8jWn7WLbUpUhsY+9YQkedAJB7meRFGt6LtdnPH4UOa2OMh9OUDcGEjtS1gIJg7v50rC2bbfpmjceMNe6nZCOhY0q6KlsEpiPQSuioc0Psm4c5J3TwTZf\/mHvxYzvmH2YZ9rb36S6Ylnd7tHrMBdHebNnWGHN7nw6\/SjYCpS90dfY1uemmtq74LRU5oSNGe6YNLMvn6zZxkGVQ6PBeCHVChz8u3tTaA1AXoSNXHoWTVN5xzkN\/cxhjcnib6F3BN3ycl\/ahR0wUOvwWA38cHyZTecW9q7Mdb9cb\/i2PjnmuT0PmVrQwvtn2cy9u+eK59ATxXoXRE6ru4ca2XdpWqbryzEvCi5NtAgP79rzXeVtEgSSO5dQ4jkJHLmJ7G2FynpExTy0lrT1D5kJuDFAsSF3\/6ugOETpy19tYXyo+B4+JYmJqHYtzzrZp2TphW7EsyJ8FIzQb6Fns10ubGyZ02NyMglHu\/lQvx4bN1ZLmYK4lEjqG9bHOFoFdEWgldDQZ1zZGh1fD7W0qXRf5vXl05AKW5t4s1b2FZblfBvAIAJdUnho5W2Mb2x7XxEa\/tyNQ+kI3xL6+QkfTfEl5dAwVOvp6dNQJHd5DJDcach4d8Q1bzqPDtsXYm7icANvG0yN1s91uFC\/nqCHjeexW9rUlly7OX7v93ItiWvTASD3cRMHLrzfcHulFgVx5bT06mtoTBRnrh\/jWuq1HR0roYJl+DZZHx9ijvb68IXPBi2k5L4i2XkFDhQ5rZa6+3Fi3a6\/3EPQeHvGFV9O9Z87TI17j2wodUwTUn3eElVlb33E\/Z2vWKnT4F3XG04TyPgLelEHw45pnAmbbeDlD1rMpsxjOOY63WNcoQkfbrCt+X3KbGB1cxLiw8P9d8w9baiDW6QOtRbdIi0\/ABZEPVZY5QjE65p0OpS90Q+zrK3Sk5ktTjI6hQkffGB05ocOXZ3nDU8EN\/cOajw0QhQ57axk9OqLQ4Y\/L5RWPMTri9UYeHfNcA4bOLVppsTDiWpQTOuxNL8XCOo+OOK58jA4vdNSVR\/u8yFIXo8PHE+B5qfZYe20to1cK4y5Y7ADWxYDfjDHihZo2Hh2K0THPmM\/V0ncuRLHLjwGKAyY25wKARnuGCB25661\/aGL5Ma2s2WCeeRZDys8dv\/XYz7nLggeev3\/zc8rKPi2kfWwjdNStF9q6Mmze9B33w2rtdvaahQ6\/hnajcuDRUwsdqedNf+9WNxfHEjr6CEBDuer8\/gRGETpYfVMe5phFwsQHnnt+5dHBm07vfh5VRe+aGV0TWU7MP5yaEDwuF53bu3fWZYfoj1tnjn2DNxfRIQtxX6GDohs\/zwhiXV3WFf9wbsc9HkAq64qJevHib\/Mg5kv3rG1upeZdyjvDXH7rlHc\/L+maTE8szml7MGRdfKjjh2+j311dO9g+PtRRDLV6Usel8ornrje+fXGbzVxjbsp6hoznse0aakt8I+WzQ9hY5ne29cOyBb0ZwFNdBp+URwdvaPwYeXH19ysrCHyL3lReXB+5tjCb0h+EtJrGta49ubnv1y6Oc84Zn2EpxrliMNKURwfXYJuHXH\/5AoBlrXkb59DxN+Z8GGJLbgz4jD+0tS57irUlxm3i9sO2WVfa1Ff3IilmXfFrho9fw+9tDnN8+m2S\/v4tzhlrR13WlTbXgiFvvcccM2soa8i4n6v9WxU6Us9djL2TiiVlLw0sG56\/74zbQtlv9Nzih2zthbZtP8vdK8aX1Tw\/Cr1+zfbl+Osaz+Ozp90XWvZCX56t7bbzINeuuvr8fbyuGXPN1v3rGU3o6Gt+W1fKvuXrvGUQKH2hm9u+IcrzWD2eS3c5VvkqZ3cE5h7PdS0tyZbd9UiZNUcPkzKtHGZVSeOvJFuGUdXZItCewBLG\/RaFDi8q+Kx5MYC3P46eTxYf0c7JbQuNWQL99jvzto8iuxcuvThhoy2KHr4civa2\/cxn8+P9tmUvjDbb9ji\/Dc4fY16QPjNbKsOaCcA+G1v7GaIjhxDYqdBhKhhzta\/5jdGQDtrKuaUvdHPbtyuhIwa0y6Xt3Mq4XGs75x7PEjqWMZJiQN8teDZucS6kAjfbCM31eSp4s52jdWIZ87tUK0uagzlGaxY6zg6NNgGhLki8z6jkt6t0ETpitr4uWY3i9chstviP5omb8tziNk\/GbbTtnrlsTH4bTNvg\/l70icHMFftxN1egnQodu2myai2RQOkLXen2ldinsqlcAiWN55JsKbfHZNlUBEoafyXZMhVvlSsCkcASxv1ShY42WQHZHxbnyveN3w5n39tWEMa18VmIbFtGF6HDb7Wuy4LXFBMjigu57EgUHujRYUJHKhvT50IaaWt3Tujg716gqUvtLaFjN9c+CR274a5aA4HSF7rS7dOAEoEuBEoazyXZ0oWhjl0HgZLGX0m2rKN31YolEFjCuF+q0NHU\/3XbE3MP5nWZvuqEDi9I0K4odLTJapQKZNw2m555SlPo4PYb1h9FlJjeuknoYHt9O6Lo4tskoaNpNE7zu4SOabiq1I4ESl\/oSrevI24dvnECJY3nkmzZ+LDYZPNLGn8l2bLJwaBG74TAEsb9FoWOXJbKuPXDZ3lKCR0WlyKXEYxbRFKZoyzrZtxC4mN5cMD6GBt12ZFi5jGey7b4bEw+8xgDqNr2HS+OdInRIaFjJ5eU\/SodRehI5WFum9fYW5NT0mwgt1H7+iBN2d92z6kPjPNGAIe5FLUpW7zyyAmVC9rTpx1LPqf0hW6IfUPGV92caOrv6Aroo+ZPFQNEwYWbeqWM34eM57FbMMSW1NxqG9l8zDnQlFJvzNgXbfYTj91Hay5vyPgbm8sQW3x2r7Z2jXG97lOvt2\/o+W3buqvj4rVh7e3tw3nIuO9TX59ztih02LNXKmteU5Yny4bHMiyTCrOWPa7ygOD33hOCf9dl3fR9FjO+xDU\/V05d1hV\/f5zKonKry\/IXs8m0yfLCmCby6Ogz84afM5rQYcqYmdSnQ3cpdHj7bfFvEx2XE+4cAEw32DWXetPN8fDuXU4JpS90Q+yLroFdxldfocMr3HTNixlUxnzIW84ok6VGYMh4HpviEFtSbrcxgFrO3jHnQN213L8t4hsifnIR5duwHePhtE09WzlmyPgbm9EQW3b1AD203qHnj90HY5en+7xmokPGfXPp4xyxVqFjHDoqRQTKJTCZ0GE3ka8AcC6AQwCcDICRcWOedYuWG\/One5WuTf7j1PmnVTeVDDqT89JI3SxHl62UYsdupQsVy6atLwfwnMqjgy5SqfzJ5vJEhZM8lJd5b3KUvtANsa\/N+EpFkDYXOsvlzQe4GAAqlV4rlxY2FX2a2Y74yeUTr4tsXTe+mWrL9i7elMlVbm8EOHeuAHBLJiBWuZfP5Vo2ZDyP3eohtuTmVtwza2+UvKehrSk3A3gpAPvN3tykUuJRNIzB3SzVnl3LeV33+35jFHjyq1tffNYL\/9bM1kPvNuv3B+fWHNri34Cx\/Ptl9ieP3bdLKG\/I+Bu7fX1t8eOEbyYZUI\/3O\/Qwtax2JwG4tDK4bizlrteptsZ6eT\/k1ww\/lv33NtdOdDb5N6qpulLne5d3Cyxo93ld7gdzb2Tr+pfXgR+o7uNo+7vDOsq22\/2vvzY8HcB11b1jn3rHHnMllNd33M9pu4SOOWmrLhEYj8BkQofdgNpNoPeOiHmNLX8xm8Ub0ndVDzz+zVyb\/Md2\/uuqRYT1\/Fy1EPE3n8rII0zdLMctJrn8zvd220\/sgZ0PgPZA6oUdMjAevInObV3ZYl7m0he6IfY1jS8+rPix6cf9Ec69jxGjc8f5VF\/xISp309iUTzzOmTgf6c5YN77ZLs5nPx8tvzjbZW2xPZV8252K\/D3e5U4lGYEh43lsikNsafLo4PWZ1+66HPf2gBXXrJTQYVHbTSA8q0pT5\/clx+BmJjI8uFqLUr\/bFkYTUvggFKO\/p+yLQkdqTnJOeU5+n3RTNPux+7rE8oaMv7HbM8QW7xkRPfqi2JYbS7nrtV9fYpt9vX7tMUGO9z1vcvdJHHMcg\/xwbrbx6IheEXa+iQtXOeHA1pW294NxT39bb6t4nJ9jPt6Av8\/z8\/u9NdemOt5jj7kSyhsy7ueyX0LHXKRVjwiMS2A0oSPmYTYln+bybbEtRNHt1r99viY8yKXS9DTlP44PgkdVD0917oNND6JsA49J5WXmb3aTGoUOf45t5WkjdDRF8U2Vu\/QHxNIXuiH2NY0vc2e3qe29l7zQEbdG5Vzv22x38dGnc\/nE6+yi8Ng0vqOA4+3l20Wbm2x3n61u414Kt1XakPE8NqkhtnjvCrPLe23EuVCX496OfUk1tpuEDv8w0sY9PeWdwQeftltoUmtIFDpSczI+ZLaxdew+Lrm8IeNv7HYNsSUKHX4sRDtzY8nfP7Udl77euG2sTZaDPkJHjrsf2zymzf0gxcvc\/V3dduTUum525WKxeaGD97vR8yz3Mm7scVZaeUPG\/VxtkdAxF2nVIwLjEmgldERX3fhQ3faCzwenGFnXRAS+wYoX\/jqhI5X\/OJ7vH566Ch3eTtqYy8vs3+RFoSMVbbeN0BGFlS3kZS59oauzr8\/8iPMgPrCZUBiFjtxxfT066vKJ29s2L2KaXd7DygdZ8uM7Cnb+xpkPk\/zYtURCx7gX9qbSSppvY82t1Jat+Ca77lraRuiwt9G2BcC8QbqKB94uuu8fB4BeIn4e+0DX1p90y8\/NMR9R3s\/Jy2peIMijo6xtk0Pngm2JiCJF17HEB\/y+QofNjSg8UlCwLWR+S0sboYNl+W0euS0xPM625fj7MbYndz9Iu3L3d3XzI9odAw6zfno85jw6osdW12tI0zV+Sb+XtB7luEnoWNKIkq0isI9AK6GjCVgXoaOLR0cqH3GX\/MdDhI66XMieR3yDYAp97qazjdDR5NGxxnRFpS90Q+xLzY+6N8s5jw6OKf\/mKXcjmovR4QPn2vism0\/xIdHXN1TokEdH01V12t+HjOexLRtiS5xbMfBnF48OG++nBo+O3Fawure2npF307fv6wQXOya+HW\/j0ZFaG+TRUT9ih4y\/0uZCTujoOpaGCB3eUy\/Hx9+btRU64pxiPRzbfltx7n6sSejok9HP2x3XXHl0dJsZJc3BLQkdMQabb3sq\/lubXu0zn9uUq2NEoC+B2YUOGur3NvKBKcbosD39bWJ0+BvbKBD0FTpiVoy6\/M5sT27rSl+PjqYYHRI6+g73\/ucNWYjjw1gcX15QsECItJRveL1Hhxc64nFxT2\/co52qMxWjw88nm6ucR7G+oUKHYnT0H4tjnDlkPI9Rvy9jiC0pEdGvG21idNgNnZUV40r5mBaPdVuuOKfaxOhICSUsk\/OP\/4+xd8wOPrSap4e1g16RXT06FKNDQkdqTtSNpb5CRxzrdq9HQYKBORm\/zEQH9krbGB1RsDTx0OJccIyzPX6usny\/NSR3PxhjdPi52bR1xYSlVFYzi5ejGB3NK8aQNaC59HGOWLtHR90L63EIqhQR2A2BnQgd0Y0yl3UlFSE\/lSXC3IdTi2HbGB0xxkjM0OLdEn02mCEeHZZ9hvmmt56XufSFboh9qTgCfnz5+cCxdSaAZ7isPbwZ5MfeNFsEd39c6oYsqvW+zrosRjaf6uxq47FUt3XFXOvp5sx5zv8OUjDS2VaBIeN5bCOH2JK6OTNh2gKQ5jIbxKwr3h3en\/NiAI+rHposwCLnID9xrvBaHrOu8Ljo1u7XNv6eylRh4oZlXXozgKe6TA4+s5EFwM6J4D7rim+Ptq4sZ+tK07yzGDCWdcWPBd\/\/HHtNY6mL0OHrjVlX\/Dj3MWpSmYWasq40nU8+nJcU4ePcqPPo4BzI3d\/VMY9vrv0c5lrLD4UQC5hq1wZlXTmQ6pA1oGlejPX71oSO6H2fetZJZWiyeWHjnsGI7fkq3oPaljF+b4HqtxaId6zxqXLyBEYROgRYBIYSKH2hK92+ofx3eX5uq80ubVp73SWN55JsWXu\/m6hSF6hyCwx8G0safyXZsrVxoPbujsASxr2Ejv2913MZmhh\/zQt8HFV8Qe29970Xlb3wteMkdOxuHq61Zgkda+3ZhbWr9IWudPsW1t37vcGm7dGDamntWZq9JY3nkmxZWj+2sTd6UHqPxDbnr\/2YksZfSbZYv9ft4x\/zuj1XPW3Hc2n2tLV7iceVOO4jRwkd+wsduQxNUeiwjJt1canaBj5e4tiWzbsnIKFj930gCyq3cG7F4J53DsrSPktYiEtjJnvKJVDSeC7JlnJ7TJZNRaCk8VeSLVPxVrkiEAksYdwvVehoygpofZGLJZdKs85zfPybmFHPe3SkzmesK59pTEKHrglTEpDQMSVdld2aQOkLXen2tQatA0WgMGFRc0tDcpcEShp\/Jdmyyz5R3dsisIRxv1Sho+1IahI6fKDhoUIHA3D7GEISOtr2ko7rQ0BCRx9qOmd0AqUvdKXbN3qHqMBVEyhpPJdky6o7XY1LEihp\/JVki4aLCMxFYAnjfqtCB4OJMqtRXUajrh4ditEx18xSPSbKnXmXwt7wqWu2R6D0hW6IfanMEDFDUK7Hx1S629Y5JA96TGM7ZCS3tTdVx5jchrSh1HOHjOex29TXFhtrqUwnPhOERX83F9o29lsWho9UgdQsQFpdnW3KnfIYG\/NM43lulXmCKTf1qSfQd\/xNwXWILUPWmdgWn4625OCAPjNEzPI1Rf+ozGkIDBn301h0YKlbEzpIIJd9zB4eLV10V6GDmY4sBg5jRjH9NIOVMmhpydebucaa6hmXgDw6xuWp0noSKH2hG2LfmDegPfF2Om2I0GELHit8JYBU2tu2xgwROtrWsdXjhoznsZn1tcUecg4B8B4AloaZ3zPWzzEAfsd938Vuc9P9WpXu2dKw8nuWfX8ApwMoKT2rxL0uPbzv2L7jr19t04kuY64zSxQ6JOpNMSLnKbOkOZhr8dqFjnl6Ol1L6tq1S3tU97oISOhYV38utjWlL3RD7Gu6AeV+RZafykluDy9M5XWyU7y9CMBO50PeCVXvWyR8e1jj11ykGez1DACmwttbb\/5umRgYJOrSqpxnVeX66PMXN6jubOuVAI6vUozZwyfLYL38PMPVxwdFRuPO2U8ujOLNcv0beavHUpM9P2Gz7QHlmwLL13555YI5RIBZ7CRzhg8Zz2O3v68tJnRwDDyiGt98G8Rxf2plJMe19+iwt76puebbZfPragB\/68QSzpnvBvC4as76N1N2\/rEAbFymArFFcSQXLM7PCz9uYzYI1seHvJRHR1N77RpATlcAuKVyUx67j0sur+\/4m6JNQ2wZss6wLf4NK8fCwdW1nr+dD8CusTbe4vrCsfQCAGeHdciX7eeIH7M3A3gpAI5zuslfVAmVfg3i9dwfx\/purWzjPPMeHUe3XG+4nt3PzeUp+lRlNhMYMu6bSx\/nCAkd43BkKd5ThH833VeOV7NK2iIBCR1b7PUC21z6QjfEvjY3oLmc5HxI5w0eb\/7OczdkvMk7qvqON6GWwisGjGK5p1UPQl4c4Y0g7WI5fOj3NnqPDl\/e9dVNpe3ZjMOID2bnVJ4cFG\/4sElxhQ+fdhPtHwJZDttUZz+5UyA5sWovOfh6ct+zfTlutNsEmAKnwiwmDRnPYxvY1xYTOv6kEs9YDkUEjml+OD9i9Hc+DOXmmneZtbnyewCe6h746M3xB9WYZH38+DR7\/k34vd184Dj9XDUPPT\/vhcHvWf4lAGyumVBi8\/2ymvrsWuG3rtS19whXlu2Z5sMn59iWPn3H3xSMhtgyZJ3hWLC1wkQ6to+u5BSa+eG44HilCEHRnR+\/vuTGct0cMRHarwtHVnPYr1H8N8VqEz6srbZ+pIQOHh\/XG7bBc\/JxB0ryzppibJVc5pBxP1e7JHTMRVr1iMC4BCR0jMtTpfUkUPpCN8S+NjeguZzk8eGFgkZdzAGfqzzeYNZtBbEHKbsR5AMixYDowlznHs\/f6MnBMmz7AB\/a7K23F1Z8fX7IRPtN6PDCCZlYPblyzM4oEPUcnqs7bch4HhtGX1v8\/nzzIOLcMLHg6RmhIzfXUkJHTHlN8Y7nvy7zFjjOD\/5NDyt6TJjolxM6UvWb91WOua8vJ3Tk2nuSEw9Zfm4ujd3fpZXXd\/xN0Y4htoyxztgeeX\/95DWc11GKYDEmRpu5FDnFMRsFd1t76oR5+817+0WPjtR6w1gAF7q569cbCR1TjOh2ZQ4Z9+1qGH6UhI7hDFWCCOyCgISOXVBXnQcQKH2hq7OvKU95mxtQe6Cnd0Xq4YU3oPZgwre68XjbmkGwtg2F\/\/bH+RtHc\/k1d2Qea1tevEeH395inZbb\/uE52LHR9dhupP1DVXTFT9lPe\/0DLLfH2J5sX29042d99raSMRvkIrnXMyXNt75zyz90sU0UO\/zcoBt9yqMjN9dyQgPL4Xjjm1nwosAAACAASURBVGZ6icSHpTju\/RjzNuZiCPg55ueLf1DzF8xcfTmhI9de\/6ZeQsfe9cW8dHa1RPedC7R3yDrDteU4ty0xCh22LdJf168J64uNobj10WyzLS382+aIjVlbF6I3oY1d89Cz49oIHT59Zc4jSkLHrkb6\/vWWtB7liEjoKGOsyAoR6EpAQkdXYjp+EgKlL3RD7Eu9KeWNpD3IWIyOVARrfyPIB3baQXf6H6restk+fnvjlvOIoIDihQ660vsb2zqPDj7cNbmz+y0uPnBj7kbV6uNDIz1H2thv8RFYVyrQqW97zNNug3arb63jpB0ynse+APS1xYsIn6q2iXDsHVSNJ3toSsXoSM21nNDBh6yfrWIW0EWeddlbYY4zL0hEj46mMetZtskg4a8bOVE0bl3JCR3y6FiW6Nc078ZaZ2yrYWrrn7ehzkMwipC5OdJF6Ihl8G96WFn8pujRkRI65NHRNIp283vfNWBOa9codLTNXMZ7tJSQmuJf98KrjfDfpU\/9\/a+yLnUht61jJXRsq7+LbW3pC90Q+\/y+Zj6IxRSs8YYx59HBzrOgcOa5EIWOulznOaGDsQS4kNn+\/FyMDtrO3w5PBCRNRen3ttH23I2nFzqa7Oee8Hc54cXb6mN32BtA3tjywc8HYKUtitGxt5Wi9LfYdRcsf9Pkg9La3BhL6KCYwXH3JRf\/IyV0mJcUbTZPIotT47db+Tb5h1O\/3ctiZpgAaPOLdryssiPW19WjQzE61iV0DFlnbA3geKuL0WFBBBn3KT5Y5MayFwNzY7aNR4fF3OA61SZGR2q9UYyOMm8Bh9xfzdWiNQsdbTKXdRE62Cf2ciwV561Lqve6\/o33v3ONBdWzLAISOpbVX6u1tvSFbqh9cXuGbRNhh7YVOvimjTeTvIGzIKI837u+cysKH3hicLbo0WEP+3RJ5laUN7ugi3zTS\/fjVNaV1LYVe+C0gKh+kJowErPG+Jvitvan3gbEjC2prSvWHtqlrSvrebiL4yHOjbGEDns4syC83nPIgoZy3lkcDmYVYt280eN1wzycvChnc8TaELMG2XWB84Zbrmze+S1nvj4KeSbutfXosOsJ5zrL53\/mDbPahSbRsKHX9jFZDbWl7zrjA0azPRyPlsnIC+z8t60Lcd3KjWX\/fW7MthE6fNYuu46bbalgpDmhw68ZLw4ZlMbsS5XVnsDQcd++pv5HrlnoaMpc1tWjwwsdqRcSJnT47Csxs1guS5+\/nvA6wC2lXGuVdan\/2F77mRI61t7DC2lf6Qtd6fYtpJsHmVnnKj2o4A2eXNJ4LsmWDQ6FO5pcJ1aunUlJ468kW0rq97og2EPsjFvBhpSlc\/sTWMK4X7PQ0ZS5bIjQkYoNZ1tAvTev9xZOZWOyFw2546LQoaxL\/efj2s6U0LG2Hl1oe0pf6Eq3b6Hd3tpsn542F9SxdWE6cDHBSNVV0xGoe\/s\/Xa3llVzStb0kW0rqqbGEjuh1YoGvlXFlt729hHG\/ZqGDwkNd5rKuQocPPMyRZZ62dbF76rIsmQewTyedygLlY8Ip69Ju53RJtUvoKKk3NmxL6Qtd6fZteOio6T0IlDSeS7KlB0qdsnACJY2\/kmxZeLfK\/AURWMK4X6rQUZcVsG3msq5CB4eexejw3oI+MDiP8dkC+bcJjzGYfC54fS6Ad8zSpKxLC7oYTGCqhI4JoKrI7gRKX+hKt687cZ2xZQIljeeSbNnymNhq20safyXZstXxoHbPT2AJ436pQkddb7bNXDZE6GD9KY8Mfu\/j6Hg7U9nLmP2vi0eHsi7NP49LrVFCR6k9szG7Sl\/oSrdvY8NFzR1IoKTxXJItA7Hq9AUSKGn8lWTLArtSJi+UwBLG\/dqFjrrMZUOEjpxHB9O0x4x7Fmg\/55FBLxGf4c\/H8miTXlpZlxZ6gRhotoSOgQB1+jgESljofhLAn2aaM8S+OfOKt9nL7LNG9NmbHNMYDhkBbexNlT92PvYhbVjiuUPGc5\/2TjW3+tiic0TAE1jTXIgxKFJZspbY+7ZO+IxCitW0xJ5M2zz3HOxDbu1CB+dTLnOZCR0x9obPHmhMU\/e7dly8b\/NZV3y8nJxHB4WKmHXlZgB\/kMi6oqxLfUb5Os+R0LHOfl1cq0pY6G4CcI8qJeRrAsEh9sX84z6veB+hYWjnDhE6uMicVRnAhYkL4JBPX6FjSJ06dy\/t6ZlVX\/LfU3+mmltT263y109gLXPB0qYysKBdl8cUpXc5ErRO7JL+9HXPPQf7tGiNQkcfDms6R1mX1tSb+bZI6NhGPxffyhIWuucAuAjA3QBwUeMDvQkeQ+yLQkcur7hFvbabVNvXSBU7ZkiwKNb8nmr5YQA+AuCdAE4G8CIA965ueE+oep\/H2R7H57vAT9cDOB8Av+PHyk4NGoo0pwL4XQAvA8Bc5zc6lZ0pwEz192p\/nf1U3r3dtwGwevgwbu6JtMfeUN5a2Wz52OsCbhU\/+Hdg4JDx3MfcqeZWH1t0jgh4AmuZC3698O3LZSzgMbxuXletE\/4afXG1hvAYrg2HVOsK1wZ+LIig9xgxocWvN1y7LJvC1QBeX607p1V181hbJ1LHcS3jy4CUR4e5qlNETa1dbPelVX1XALjFBUjUDCiLwNxzsE\/rJXT0oVbWOcq6VFZ\/zGWNhI65SKueWgKlLHRfAcCIz\/x82wkeFA14U0jxo+sb8JRHB8ugSOAf2FmnudvZDSYf5HlDdwGA06ubvrhHkeJM7obwquom1nuRsLwLq3bwJtLb1\/QGkHXzY66MVwLwab74G0UWihNmF7+rs59t5g0xRRhyoU1Wz3uDrfZ9jN7tubGPLqnK0bRLE9jFfJtibql\/RWAogTXMhbqtfP6t5YkAGNSP11vv2eev0SZ8U7Q2YZz\/juf467Rdj1PrDcumkP06t278XLVm+XrtuHdVdcV1jtd4v3WF61gs9\/Bq\/TnCrTk8jusV1ynLBDF0zOj8cQnsYg52bYGEjq7EdLwIlEFAQkcZ\/bB5K2yhKxHE7QD+D4BjBggdbfKKe0GDHEwMoceE\/3g3XgoKPl94zsXX39R6ocNuAnkDGPOSxz3Qtm3FRATWRS8Uv2\/SbnTrtsdE+02keAkACicMimViRRRljENMi5aL3l3ieCrBplLm29C5VQJL2bBsAmuYC3VCh3lKUFhnkD9bL3zAv5MAHFeJBPSoix4Uba7rfhTkRBQTR5rEFh7ny7B0k1Ho8AK6X1fYHquDduW8XZY9ctdjfSlzsI7o1wA8oFDkSxCKCkUnszZAQELHBjp5CU0s5UId3zqTHR+66dHxHzJCR9O2idzWFd48es8Ei3pNL44jw41aDPBkrsUUOvxDfhQRfJ5yC\/aUEjrM3djGyrMS8Td84Cg7LreVJAodbexnWyicXFZtj+G2FdvGwjd3FJqiS7VtXTE3ZdqVsn0Jc2BOG3cx3\/rMrTmZqK5tEljKXKhbZ9oKHexh8+Z7utu24q+f\/trObYqs166z\/M2vA3Y9NnEktd7wHC\/ae9EhCiL+uDZChz\/er30UzfkxDw4JHWXP7V3Mwa5E5NHRlZiOF4EyCEjoKKMfNm9FCQudjyNgAse5Vc8MsS8KHSwyt2\/avucxti0kBkzKeUT4N3G8waPnhXlq1Hl0+G0sdQMx1Q7b4+0FG3qCxJvUnNeJF2ooJp1TbTn520yg07r95rRd2VjaXUqGjOd2Nex\/1FRzq48tOkcEPIG1zIWmGB320M9r8ZcBPMJt8cud23Q9tfPeFFJF1gkYdUKH99Dw2y1zHh05oUMeHcua43PPwT50ShY6GC+N8eReC+DlfRqnc0RgxQQ4N152l0pxnzMK\/4qZqmk9CJSw0DGo2T2ruWAChzVliH1tPTooENjbsi9VYgi3rXihw2J60C6LhZHy6IhCB28uX1rti66L0WH1M1ic37pigeZMODEuto86pv3LCR1N9pOV7d+m+7J3uyaLVIwO7\/0St9f0GIqbOGXIeO4DaKq51ccWnSMCuxQ6ppoLbbOuWNBR740RM4HxOsx4F\/G6nrseM5YS42DY+uDXG7Ju69HhY260idGREzoUo2NZc3zu9agPnZKFDgbjfUvl8fpLfRqnc0RgxQT+C4DnSehYcQ8vpGklLHRPAcDo7KnPEPu65BW3N2gW\/I22+EjR3H5CQfIZVTBTv8\/ae3RQBOFbLUad54cLIb0n6IJsW2QeXwkfMetKautHLg2XCSOsjwFRzcXZCx2+\/C72sz38eLfq1NYVa49F3tfWleZJP2Q8N5d+4BFTza0+tugcEdil0DHlXIhZBXxWFGtzShDhbz7rSm5LYu56zGu1v0779cayo1iGrqatK5ZFxdtel3XFyo3xqcwelsP\/DlIw0mIn\/tzrUR8QJQsd3IZGkZDbfnkfpo8IiMA+Av+dL1AldGhI7JpA6Qtd6fbtuv\/Gqt+nOxyrTJVzIIGSxnNJtmisbI9ASeOvJFvmHgnRW2Ss+k38sYCqY5WrcsYjsIRxX7LQ8cMArgHwVwD+6XjdopJEYBUEPg7gByV0rKIvF92I0he60u1bdOc7rxW2g94h5s2x9HaVan9J47kkW0rtL9k1HYGSxl9JtkxHPF3ymEKH905hba+SN8fc3dmpviWM+5KFju8C8E0AdwVwfwA3d6Kvg0VgvQTua\/NBQsd6O3kpLSt9oSvdvqX0s+wsg0BJ47kkW8roHVkxJ4GSxl9JtszZB6pr2wSWMO5LFjo4ej4MgNuRGfj7d7Y9nNR6EbiTwC9UQbf\/UkKHRsWuCZS+0JVu3677T\/Uvi0BJ47kkW5bVi7J2DAIljb+SbBmDrcoQgTYEljDuSxc6\/p8q68r\/C+BxbaDrGBHYAIFPAHiUgpFuoKcX0MTSF7rS7VtAF8vEggiUNJ5LsqWgLpIpMxEoafyVZMtM+FWNCNyRlaf0rI+lCx0PAPBFAPcA8FgAf6lxJQIbJ\/BjAD4EgNkeHySPjo2PhgKaX\/pC19c+C4RmGU6YMtU+FhW+KUuI37t8qEvV5\/\/N1KtDPmanZU3JlTV0H7WlLRwah6Otval2DG3DEM6lnNt3PE9hf0m2TNE+lVk2gZLG31BbYoavY6s04V3XobrsLfE337vMimWpzU8I3c6MW8wI4dfAskeGrJuLwNBxP4edpQsdZPBWAKdWmfWeAODbc4BRHSJQIAEKftzOxeC8FzFLpYSOAntpYyaVvtD1tc9uCg8B8B4A76j6ld+fBeCYaj+lfd\/0YD6muNFniA0RCXguBQ5+zh94wztE6OjT7rWd03c8T8GhJFumaJ\/KLJtASeNviC1RRLbU36e5lOJt1qFU+lkG9+TNYhQqWMcFAE5313M7n4LHB8vuellXCIEh436uJixB6PhuAP8bwEOqVLOM1\/GtuQCpHhEohMA9q2etkwB8CgAF\/xsldBTSOxs2o\/SFrq999kD+UQCPqNwzmVGEN4hU3vnhm653Vw\/\/5lHBm8ULK+8NHsP6eSPL7\/im7PKqrDMAvKT6zXtj+DSt5jlidfFm9fqqPt748u\/jq\/9bGTFqPS8UvGBQkLH6WS6FF+Zvp2BDm\/hdzruEv9nnKBcF38STmwA8vzrA3kTyzzr7aS9tv86JSFYPbfVvOC3yvhdr6NJG0cXqbfKuWcsU7Tuep2h\/SbZM0T6VWTaBksZfX1tyKVR5\/ePnvOo617QO8ZrJ66e\/Plvvpb6X0FH22F6KdX3H\/ZztW4LQQR4\/AuDqCgzv2XhPo20sc44U1bVLAoxPcymARwL4\/wBw+8rf0CAJHbvsFtVtD\/Il79HsuxDbDeifAHhGJVjQddcexnlDyYf0NkLHCythgbbEf5\/obk69SEIhgje7JkDEG98bKsHBe0h8Nbyl47nHVd4YR7itM+w33hjbm7u6bSnmwXIJAJZ\/DoBXVqKIvXl8XVWeL+cxDfZT6ODnFOctQk8Z1sO2p7638UaGkZu3a80zs+94noJJSbZM0T6VWTaBksbfEFtMEE6lUu27Dvmeo\/jt1xL+JqGj7LG9FOuGjPu52rgUoYM8+HDHe8oHV3D+DMDrKw8rpZ6da8SonrkIHFw9o\/DF709Ulf4tAG7f+qwZIaFjru5QPTkCpS90fe3zAoJ5HnABsofxp48kdBztbkL5b3vAp\/eI\/9hbOXvDd1UlLtRtBeENrpXnhQ5fJ7046ra1mAcLxSzaxBvmK6uFN94s+\/qa7KfQwbcWJlBQ3KCnDOuhSJLi4O30QseWZmff8TwFo5JsmaJ9KrNsAiWNv6G22LYRi49hokffdcj3XOr6Xid0xBgdjN8xNDZT2SNJ1vUlMHTc9623y3lLEjrYrsMA\/DqAZ4dG8sXapwHwQZDBSxXHo8so0LElEDiIwUUBcKsW16CHOaO+DuA3q5e1fKl650dCRwldt20bSl\/o6uxLbY+w3vQ3mPyOYsdlziviBSMJHSzbtrqYeEJvi1TgON78mtBhW1Wi0BGD2tlNahQ6PhCGbS7gnN9+YqektpJQMPFCB4\/1W0v4d8p+E06OrAq3mCe+XtuWEm\/YfVv9lpk1z8iS5ltJtqy5z9W2NIGSxl\/fdSbVMr+dxXsMdlmHhggditGhGdeWQElzMGfz0oQOawe3J\/\/bassx72\/u07ZTdJwILIgAt6fQK\/wt1cvUA0yX0LGg3lypqaUvdH3t8wKCeR5w6woVSd4IWiyNuHXFvyljl6e2q8TApCzry1UsEG7dsC0ytu2E3hHRoyMldLA+76Jc59GR8xzxwzQVnC4Vg4RbSaLQwWBCbeynjT9bVWpt9zbErTnG08cT8TatPTNA3\/E8xeWnJFumaJ\/KLJtASeOvry28dqW23aWu93XrkGJ0lD1W12pd33E\/J4+lCh2R0Y8COBwA09HyusF7I31EYEkEvgHgS1XsDT7z8N\/7eW+kGiOhY0ldvE5bS1\/o+trnH7AZCM68E8xzIAodFjODN6gvrQKEthU6LICodxH28TXuXW1TYST8Oo8OL3RYsE5+R7fjuhgdrIvCRwxImtrb7d82XuOEnDqho85+E1M+59yjffA8HyPE8zSPGt7g5x4W1jjj+o7nKViUZMsU7VOZZRMoafwNscXiL1FA58dnT\/FCet06ZNdB\/p8iuHnGKetK2WN46dYNGfdztX0tQsdcvFSPCBRFQEJHUd2xSWNKX+j62he3hEQxwGdHsaCczGDyYgCMHsx6\/YM5\/203n4xDweA75gmRSgvo92wzK8qbATwVwCsAnFvdzFL4yAky3IrCehhIlfX4+mPWldy2lXgDbgPcWMR2eA8SEzcs00vOfhNnfPaVuG0ntXXF2mP7ybV1Zf7LT9+5Nb+lqnGNBEoaf0NtiVsO7ZrXZR1iH8drZy6jVpcYHSx3K9fXNc6TKds0dNxPaZuVLaFjDsqqQwQmIiChYyKwKrY1gdIXutLtaw16pQduadvJGF1Y0nguyZYx2KqMZREoafyVZMuyelHWLpnAEsa9hI4ljzDZvnkCEjo2PwR2DqD0ha50+3begTs0IKan3aEpi6m6pPFcki2L6UAZOhqBksZfSbaMBlgFiUADgSWMewkdGsYisGACEjoW3HkrMb30ha50+1YyDNSMmQiUNJ5LsmUm\/KqmIAIljb+SbCmoi2TKygksYdxL6Fj5IFTz1k1AQse6+3cJrSt9oSvdviX0sWwsh0BJ47kkW8rpIVkyF4GSxl9JtszFX\/WIwBLGvYQOjVMRWDABCR0L7ryVmF76Qle6fSsZBmrGTARKGs8l2TITflVTEIGSxl9JthTURTJl5QSWMO4ldKx8EKp56yYgoWPd\/buE1pW+0JVu3xL6WDaWQ6Ck8VySLeX0kCyZi0BJ428MW3KpYGNGFvJ9FQBLR+t589jDXapu+81n8eJ3lo3F0pBbenQ73rK38Ps3ufTmvk6fBnyuPlc9ZREYY9xP3SIJHVMTVvkiMCEBCR0TwlXRrQiUvtCVbl8ryDpIBCoCJY3nkmzRANkegZLG31BbKCycVXUh031bKnJ+FdN8exHCCw8M7vyiqozzAVxb\/TuVvtynS+dhrI9lMWU5P\/z9uKo8SxX+YAAnu3IldGxvzsUWDx33cxCU0DEHZdUhAhMRkNAxEVgV25pA6Qtd6fa1Bq0DRQBASeO5JFs0OLZHoKTxN9QWihSnAvhdAC8D8EIAN1ZdGoUOfs3jLwBwehAebBQc5Tw+Usea+GHiBr1JWA\/FC34urK41FEssBfjnARzsvEUkdGxvzknoUJ+LgAjMSkBCx6y4VVmCwNAbvKmhlm7f1O1X+esiUNJ4LsmWdfWyWtOGQEnjb6gtJjDQs4KCw5XOuyIldJhXx9ur48wj5BIAXwVwDoBXVmKJHft8AMe6cj1jO+YqABRJrnNeJSZ0vBbALwGwOiV0tBml6z5m6Lifg448OuagrDpEYCICEjomAqtiWxMofaEr3b7WoHWgCMijQ2NABO4kUNK1fYgtXqSgBwW9K453HhlthA7zCDkTwG0JsYTQWO4H3PiJogfLeCeAL1WeHeZRYkIH23io8\/w4sRJFUrFCNEy3QWDIuJ+LkISOuUirHhGYgICEjgmgqshOBEpf6Eq3rxNsHbx5AiWN55Js2fzA2CCAksZfnS0+mGgqiKgJDMe4PrRgoRQbUkJH3HpC74pLwxjIBSzlYantLPyedXlvDn7nhQ4KMXYMf\/NbZDY4BDff5JLmYK4zJHRsfpgKwJIJSOhYcu+tw\/bSF7rS7VvHKFAr5iJQ0nguyZa5+KuecgiUNP6G2JISMrzg0BSjg1tVYjDR6IXhPUTYg3Hri\/VqG6HDRBIGTb0lk\/2lnFEiS6YkMGTcT2mXL1tCx1ykVY8ITEBAQscEUFVkJwKlL3Sl29cJtg7ePIGSxnNJtmx+YGwQQEnjr68t0TPDutFnPXlJ9aVtEYlZV3wgUdtu4mNuvDchhNSlsm3y6KA55kFS5zWywSG5uSb3HfdzgpLQMSdt1SUCIxOQ0DEyUBXXmUDpC13p9nUGrhM2TaCk8VySLZseFBttfEnjr68tKZGC3WnbWU6r4nWcHfrYCwwpjw8TI05xmVTo9XFCVQ69MXyqWCu+jUcHj82luN3oUNxss\/uO+zmBSeiYk7bqEoGRCUjoGBmoiutMoPSFrnT7OgPXCZsmUNJ4LsmWTQ+KjTa+pPFXki0bHQ5q9g4ILGHcS+jYwcBQlSIwFgEJHWORVDl9CZS+0JVuX1\/uOm+bBEoazyXZss3RsO1WlzT+SrJl26NCrZ+TwBLGvYSOOUeE6hKBkQlI6BgZqIrrTKD0ha50+zoD1wmbJlDSeC7Jlk0Pio02vqTxV5ItGx0OavYOCCxh3Evo2MHAUJUiMBYBCR1jkVQ5fQmUvtCVbl9f7jpvmwRKGs8l2bLN0bDtVpc0\/kqyZdujQq2fk8ASxr2EjjlHhOoSgZEJSOgYGaiK60yg9IWudPs6A9cJmyZQ0nguyZZND4qNNr6k8VeSLRsdDmr2DggsYdxL6NjBwFCVIjAWAQkdY5FUOX0JlL7QlW5fX+46b5sEShrPJdmyzdGw7VaXNP7GsCWX8rW0XmZK3AsBsM3XBuOYLYbfvxDAoe7flvZ2qraQHTPMvAjAbSNU4ss7CcBRACy9b9\/iPZupefS1set5Y4z7rnV2PV5CR1diOl4ECiIgoaOgztioKaUvdKXbt9Fho2b3JFDSeC7Jlp44ddqCCZQ0\/obawnStZ1V9wdSvTAVb6qdEoWNKVs+U0JHFO3TcT9lvVraEjjkoqw4RmIiAhI6JwKrY1gRKX+hKt681aB0oAtUb0jOrhyKO7V1+NLd2SV91lzT+htrCt\/2nAvhdAC+rPCL41p8CyPkA3g7ggwCiyEDPgw9UQ+FVAA6vvBoeU3k43AzgpQAurzwSLgJwDIBnOTHFl3FxdT6LZL03ADjblX9e9f3zAVCQOdl5ddA2CjQnVPXxOnUGgKsBvD5xfKre6I1hnhVN7bDjXgHg3ITd5o1Bzu+sGJAJRQxy5vnkdxiAj1THsG089sqq\/eTA360v+PV\/rH5n3\/hPZMF6oocLv7u0Osmz9Da2+X6XV4Kh434O2yV0zEFZdYjARAQkdEwEVsW2JlD6Qle6fa1B60ARkNChMSACdxIo6do+1BY+9PJDocA\/PNcJHV+tjudD\/EcrAYJlcPsGhQ4KIMe6346sHuyPruqwh+8LAJwO4Honbpig4cujSMKHf9bbdusKhYLXuXaZEHMEgFS9cXuIiSFN7WCbuHXFhI6c3eRLocI4e2HI2sftOLmtK967g2LGOQBeWYklNjBjn9k5l7mtPL4PKLSwz\/kx7iam0I7ja74fup1m6OVk6LgfWn+b8yV0tKGkY0SgUAIUOqj+vwbAawG8vFA7ZdZ6CXDscQxy7HEMlvbR\/CitR2TPEAIlzTfNrSE9qXOHEljLXLBtK5dU3hH2cMuH2Dqhgx4CPi6Ffzin0MGHZ\/NY4L+vqx7wfayIEwEc52JbRM+Iq6pzvCdJF6HDxIyUeJCqN8bYoD1t2hGFjpTdHG8WP4TiAjmYfWTp68kJHeZ5Q28VMqYIEcWGXCyOuhgdJoZEoSMnngydO2OdX9IczLVJQsdYva1yRGAHBCh00IXwLQDocvhLO7BBVW6bwH8B8DwAvwjgtwpEoflRYKfIpN4ESppvmlu9u1EnjkBgKXOBD9B++0fqwdi2UxgW21Zxa83WlcdmRArz6PAiSJ3QYdsnfN3cRsNzUltmuggdXliI4kGqXhNmzJYYZDTXjih0pOyOYoYXb+pEIx+M1ItST89sW4nijLXFCx3Wr7yG2odbZzg2UtteKMzkvh9hKvUuoqQ5KKGjdzfqRBEolwCFDl5suUjSLY5uhfqIwJwE\/juAnwPwNADvmrPilnVpfrQEpcMWQaCk+aa5tYghs1oj1zIXbNuCF0Dsgf7dQeiIXgh1Hh1thY5URpGmLTNtt67UCR1tMpmMKXRwItR5dORYxqwrFGO+u\/IIidtWWEcbj47oSZMLeJrLy7OKfQAAIABJREFUJjN2lpm+F4mS5qCEjr69qPNEoGACFDp+GPj\/27sXYOvOuj7AvzSBJBASAoFEM5QkcpsUiJeSRiQjIhDQ6U1SoSMXy6VWUQzYFloqIXgBxCI4gqWCyq2jULUOaCVcCiIJjUBJM4kBSuoAiUCIGkIIZKTt\/HPW6lnf+vbZ55xvX85aaz97JpPvO3vt9\/K8ax3Yv7yXfCTJx5N824DbqmnTFLgqyYOTfGuz2djQeun5GNqIaM8iAkN63jxbi4ykzy4qMIVnof2v9BVydDe0rC++tbSju7lmXVM\/r81F270yaq+Jnfbo2EvQUTMZustLKmCpfSvaelc1o6O7R0cta2nrnbV0ZS\/92MuMjnZPk5326Nhr0NFuFlr\/YWfWHhn9MW3H8rWNax292w067tIsD6rxr2u6IVK7jGmnnx\/0Hh1DegYFHYv+RvV5AgMUqKDjTkluTXJ0kpOT1O7UXgTWIXC35n6rndJPSPJ\/1lHpPuvwfOwTzOWDFRja8+bZGuytMvmGTeVZmLfMoWbqPrvZ\/LNd2vK8JOc2MxPafS9q09E6naO+DNe+EftZutKeONKe3LKXJTPtpqXn9U5dqZuu\/ZJff25PXakv9m09\/TChX29d130tc0ZHec07dWXe7JhqZ7u0pD\/bZdbDNque7qkr9ZnuCTW\/muTxvY1k65r+yTC7ea3zwR\/aMyjoWOfoq4vAmgQq6KjX5Unqf3SeluRNa6pbNQSenqQ2UKv\/ElG7og\/15fkY6sho134Ehvi8ebb2M4KuXZaAZ+FwyVlLYJblrZxtgXmbim6S0xCfwVn+NiPdpLtSXycn0AYd\/7o58eJPm7R\/ch3VoUEKXJ3k7CQ\/leSVg2zhVqM8HwMeHE3bs8AQnzfP1p6Hz4VLFPAsHDo7oWhrQ\/r+0o8lkiuqOXa2Pba3u9RoE3GG+AwKOjbxTtTnSQu0Qcc9ktyQ5NgktRP3Ryfda50bgsB3JrksSe0eflqSW4bQqB3a4PkY8OBo2p4Ehvq8ebb2NHwuWqKAZ2GJmIoicAQCQ30GBR1HMJg+QmDIAm3QUW18fZI6EuxjSR6e5OtDbri2jVqgArWasl6b39bxYt0j0obaMc\/HUEdGu3YTGPrz5tnabQS9vywBz8KyJJVD4MgEhv4M9ntl6cqRjbNPERiEQDfoqOOu\/keSb26Omq39Or42iFZqxJQEjms20aoj1z7XbH524wg66PkYwSBp4mECY3jePFtu3HUIeBbWoawOAjsLjOEZFHS4gwlMSKAbdFS3HpbkiqZ\/1yZ5smUsExrtg+9K7fb+liT3b0K02oB0TMukPB8Hfw9pwd4FxvS8ebb2Pq6u3L+AZ2H\/Zj5BYJkCY3oGu\/02o2OZd4GyCKxZoB90VPW1du53m30T6u\/vaTaKrI2THD275gGaQHUnJjk\/yUVJHt30p\/aDeUKSD4+wf56PEQ7aBjV5zM+bZ2uDbtQ1dNWzsAZkVRCYIzDmZ7DtlqDDLU5gxAKzgo7qzqlJfiHJU3t9uy7JJ5N8sdm81D4eIx78FTX9hCT3SlLT0esYtTN79fx6khckGcNylZ2IPB8runkUu2+BqT1vnq193wI+0Ah4FtwKBA5WYGrPYGlOIeg4plkmXlsT3LP5\/+i1jMiLwJgEvpLkL5J8vvPPTbt1YKego\/3c3ZP8syQXJKllBnfdrUDvE+gJ3Jrkg0n+KMlvJrl5QkKejwkN5kS6MpXnzbM1kRvyALvhWThAfFUTSDKFZ3CsQUf9b2jttfi4Zla1728eySkKfDbJy5K8YadDVHYLOvoofy\/J6UnqSMBKBY+fopo+LSRwW5JK2Oqf6zt7vixU6Eg+7PkYyUBNqJmb8rx5tiZ0066oK56FFcEqlsAeBab4DI4t6Di52W7gnyapE26So45K7nFWcsr9kxPunZz4TcmdTOjY4z3tsqEI3P7V5NYbk5tvSG769NY\/26\/aEuEVSf5D\/yCV\/QYdQ+mudhAgQIAAAQIECBAgQGBVAmMKOs5K8u4k9e\/kAY9Jzr8oOfMRyXG1XYoXgQkJfO3LyXV\/nHzw1cmnajvRO15XJXlkkr9sfyDomNCY6woBAgQIECBAgAABAksRGEvQUacZXn7HbPuasfG030vuWxMhvQhsgMCfX5688R8nt3zhsLBD0LEB46+LBAgQIECAAAECBAjsS2AMQUdN17gyyRk57cHJs96VnFT7jnoR2CCBm69Pfu2C5PNXHxJ2CDo26B7QVQIECBAgQIAAAQIE9iQwhqDjVUl+Mne5R\/JTVwk59jSsLpqkQIUd\/\/6c5Kt3HMZS+3X8qKBjkiOtUwQIECBAgAABAgQILCAw9KDjlCSfueNwiKe\/Mzn7+xfoqo8SmIDANe9Mfv3vV0fq1KdTBR0TGFNdIECAAAECBAgQIEBgqQJDDzpemuQFue95yU\/UFh1eBAjkVQ9LPveRgnimoMP9QIAAAQIECBAgQIAAgUMFhh50fCrJ\/fLMP0we9HhjR4BACVz9juQ3\/kH96QpBh1uCAAECBAgQIECAAAEC4wk6Tkry1zn6TsnLbzduBAh0BZ5\/bPKN2yPocFsQIECAAAECBAgQIEBgPEHH9yR5X+7zsOQnrzBuBAh0BZrlK4IOtwUBAgQIECBAgAABAgTGE3T8cJLfyEMvTJ769pWM23v+SfK9f\/vwoq+5Kfk7v7mSKnct9PWPTR53ZvLUP0ze99ldL1\/5BWX0oHssvz1POTt5zfcmV3w+efSM4d3t\/d063n7+bZ9Innnp\/Ku7137gc1vt2svndmvDSt9\/44XJVb9jRsdKkRVOgAABAgQIECBAgMAYBYa8R8dzkrw65\/3z5MLXrcS2vsR\/010PDTUedZ\/kTd+X3Pz1gwk7hhZ0rAQ+SRsu3P6N5L\/8r0PDiHYMTj8hee9nZgchu7XrSIOO3UKR3epd2\/tvf1by318v6FgbuIoIECBAgAABAgQIEBiLwJCDjhcm+dk86t8k3\/fzK\/GcFXRURbO+JHdnf9SX85dfkbzosq1mdb+Y19+v\/8r2DIgq65WPTC6\/IbngjOTORx\/6fr9jewk69tOWKr8NC6otLz0\/+cKtybefutWO+vPdj0uOPTqpYKF7ff25O6Pj356XnHnSztf2HS67IXnIKcmrPrpt1fa3Nb7qS8lxRyff8ZZtiZc8PHn6Q7bqufLG7aCjbJ7xkK3r+mPQtrWdoVN9O\/HOh87M2Mlt3oyOq384+drfJPc\/ObnbnbfqfsNV28FMtfX5526N6y23J5\/6q+TUuy5\/BsxhD8AfPD\/5b78g6FjJbwaFEiBAgAABAgQIECAwZoEhBx0vTnJxHntx8tj64\/JfOwUdVVN9wf2LW7e+ZPeXb9QX7h98YPLs9ybX37I1A+Tav9z+Ql6frVctf2m\/RNff6\/o3X7NV9knHzv4yvFvQsZe2dGej1PXnn74VzHzqr7eWZXz2lu3ZKu2X\/\/bLe9VfbW6DnH7QUUHCTtd2+1X9LZd7HX9oKNSOYuvyB9clD71X8rIrtmzawOL4Y5L7nrjt2m\/XrHaee9qhxmffc7ut89yqzna5Sn\/pSvXpfnc\/1KOtp\/1cu\/ymDT1uvG0NQcelL04uvUTQsfxfC0okQIAAAQIECBAgQGDkAoKO3tKVdjzbEKS+gNeMjF\/9+KGzEtog5M9vPnxPjXYWR32mDRe6ez7UF+KLvmP2TId5QUe33HY2ST+U6d+P3bpmtaUfAPRns\/SDju5+Hf2ZEH2nfhjRbVv3s2eclJRjLRupWSG\/dkHyjk8nFz5gK+j4+Q8fHia1\/a5\/\/8R7D39\/t7Z13d549fygow2t6t9dz28+4fCxnxdiLfV3haBjqZwKI0CAAAECBAgQIEBgOgKCjl2Cjt\/55PbShP6w15KQes3a0LRdWlHhQj8AmLd\/xLygo7tMYlZbupt61hfumtFQr25b+httLivouOEryY9+a\/K892\/PzJgX6HQN6rPff9bW8pX6zA+dnbz4sq1lNhV0dIOI7h4a3TCq3692Gc0f\/e+kym+Xl8xyO9Kg4+GnH77Hy6o2bz3sV46gYzq\/hfWEAAECBAgQIECAAIGlCgg6dgg62hkbl12\/8+yLGondvtjOmoWxSNCx00yQ9q5oA452n5BH3me7\/auc0bFI0PGf\/mxrFsdbr0kqPKhXdxbHMoKOeW677dFR7WlP4emGN4KOpf4uUhgBAgQIECBAgAABAgSWIiDomBF07Oe40e5+He0eE92RmRVqLLJ0Zd7Rp7NClTEsXalZGhUY1b4cp911K\/B4\/2e3l6MsY+nKbm7z9ujYKeiwdGUpv4MUQoAAAQIECBAgQIAAgaUKCDr2cLxsfQnvbnTZDS9qNkL\/ONpu+FGjVV+iv3z79gaV3c1K+6O5l81Id2pLfyPNtp11ekl3M9LufiHLWrpSYcWRbEbatqW\/kWe5dDd53W0z0n7g1M5saTdOnTeGXbdZm5HuFHS0M2RsRrrU30kKI0CAAAECBAgQIECAwEICGx90zNpfoz2OtSvb3fOift49YrQNFNrjR+uY0faElfa9Oumk3TOje\/zsrKCjPUK1+173M\/Pa0j+CtWaZ1Akx9WV81hKQZQYds46XfcDJh+7b0fapP9Ol\/Wx7ek3\/7\/W5\/Rwv+7EvbB0J2w11dnI70qUrtSHsrONljztme6nLQk\/nvA\/bo2NltAomQIAAAQIECBAgQGDcAhsddKxj6Obtx7GO+g+yjgoB+huUHmR71lH3vCOLl1q\/oGOpnAojQIAAAQIECBAgQGA6AoKOFY\/lpgQds\/o5b4nOitnXUnx\/ucxax1rQsZYxVgkBAgQIECBAgAABAuMTEHSseMzW+uV3xX3Zrfju0pK69pqb1rCEY7dGrfj9ecuIVlq1oGOlvAonQIAAAQIECBAgQGC8AoKO8Y6dlm+ygKBjk0df3wkQIECAAAECBAgQmCMg6HB7EBijgKBjjKOmzQQIECBAgAABAgQIrEFA0LEGZFUQWLqAoGPppAokQIAAAQIECBAgQGAaAoKOaYyjXmyagKBj00ZcfwkQIECAAAECBAgQ2KOAoGOPUC4jMCgBQceghkNjCBAgQIAAAQIECBAYjsDwg45v+e7kWx45HDEtITAEgU+\/P\/n0B3LUENqiDQQIECBAgAABAgQIEBiQwJCDjotyzPEvyN\/cduqAvDSFwHAEjjn+C4KO4QyHlhAgQIAAAQIECBAgMAyBIQcdL05ycZIPJHn\/MLi0gsBgBGqa03cLOgYzHhpCgAABAgQIECBAgMBABMYQdFySpEIPLwIEtgXuCAIFHW4JAgQIECBAgAABAgQIHCog6HBHEBingKBjnOOm1QQIECBAgAABAgQIrFhA0LFiYMUTWJGAoGNFsIolQIAAAQIECBAgQGDcAoKOcY+f1m+ugKBjc8dezwkQIECAAAECBAgQmCMg6HB7EBingKBjnOOm1QQIECBAgAABAgQIrFhA0LFiYMUTWJGAoGNFsIolQIAAAQIECBAgQGDcAoKOcY+f1m+ugKBjc8dezwkQIECAAAECBAgQmCMw1aDjp5s+\/0yn7\/WzJyR5YpJPrOmueGCS307y4STPTXJbU+\/xSX4pyXlNe76U5K1Jqr0f6rWtLeOc3s+f3HxmTV1RzcAEBB0DGxDNIUCAAAECBAgQIEBgGAKbEnRUyHF6L2xYxwhUSPHLSf4qycWdgKV+fkmSk5M8J8luQUeVUde1Ac09k\/xKkvqyu67QZh1e6ti7gKBj71auJECAAAECBAgQIEBggwQ2Iej4oSTn7zCj4keasX5EM5OiDSbqx2VTn31Qkj\/p3BPtte2sjLaMWTMsqrz6QnpFki92ZmBUufdOcm7z\/n6DjrbuN8+YAbJBt+9Gd1XQsdHDr\/MECBAgQIAAAQIECOwkMPWg47okT2kCi5s6CN2lLd+V5DXNEpK6pJaaPLsXfLSzKbqhyQ8kOatZblIzLH4uyQuTdOtpg47fSvL4JmypOmo2x+8n+fEjDDraQKY7y8NdvlkCgo7NGm+9JUCAAAECBAgQIEBgjwJTDjpe0hi8qxd0VCjR3Q+jOzuiZlb0l4l0KSsUqeCk9tvoBh07cbdBRy1bqXCjvpzW6xlNPa\/YY9BR4Ut\/j452Zskeh9plExMQdExsQHWHAAECBAgQIECAAIHlCIw16KgZGW2Q8aJmVkVXpN6vUKJmYPxYb3+ONui4oEdYS08+0gQPNdOinZnRras+8rrOMpjue7OChzboqPKqHe9LckYzE+S1nX029rt0ZTmjr5QxCwg6xjx62k6AAAECBAgQIECAwMoExhp07AbSXZrSztj4YDOTY95Gnt1gooKOCkuqrApM2r+3MzraE1SqLTuV2S2v9vr4h0lOTFJ7a1wr6NhtGL0\/R0DQ4fYgQIAAAQIECBAgQIDADIFNCDqq2+0Rre3eG90gpPtezayoL5DtjI5u0PHV5kjYKq+WrvzLJLUHSC2D2W2PjirvlGb\/j883wUmV056cYkaHx3O\/AoKO\/Yq5ngABAgQIECBAgACBjRDYlKCjBrNmZbwlSS0x+VgTWvRPTOnP6OierHJlc0Tsk5ogpMqskKNdArPb0pU2KLm+s4FpP+joL6epMnfbN2QjblSdPExA0OGmIECAAAECBAgQIECAwAyBqQYdBpvA1AUEHVMfYf0jQIAAAQIECBAgQOCIBAQdR8TmQwQOXEDQceBDoAEECBAgQIAAAQIECAxRQNAxxFHRJgK7Cwg6djdyBQECBAgQIECAAAECGygg6NjAQdflSQgIOiYxjDpBgAABAgQIECBAgMCyBQQdyxZVHoH1CAg61uOsFgIECBAgQIAAAQIERiYw1aCjjo99SW8sXtScdlI\/ruNg68SUn0nyoRWP2U51tSe6nJfkiUk+0WlHe0LMk5t2do\/DndfcWf1uy2jre\/OS+tyW98EkH+kdy7tiUsU33hcfhYIAAQIECBAgQIAAAQIEDhGYctBRHa0go17tl\/Lu0a5DCTrunuQdTaDRtvWSJOckedMRBB3dftdxub+c5DlJPtMcqbuKoKMsvdYrYEbHer3VRoAAAQIECBAgQIDASAQ2Jeio4eh+6f\/SPmZ0fFeSP+mM5yOaGRH18x9vfv6kJFd2Zma0wcqPJHldkjNmzB5pr\/lYkvsluTjJbU07n9GUW2VWiLCfGR2zAp4KN6qeX0rSBh3l8dtNoPKuJDWL5KYk8\/pVZbezRn6raeM7ezM6HrRHl\/bzv7KkGSYjeeSW1kxBx9IoFUSAAAECBAgQIECAwJQENino6C7duHaPQUc3HKmlJRUGnJ\/kuUm+vQlAKvhoQ4R2xkiFAafPuK67TKZtz39NUkFJfXFt66h77Kwk1y0YdFT7q9wKZL7aCTr6\/d+pvf1+Vf+f0jic0gQlr5gRdFQwNMtlJ79VLx+a0jPb9kXQMcVR1ScCBAgQIECAAAECBBYWEHTsb4+Omu1QX\/TboKMCgnYmRP27wolf7M2c2GlvjO7PH9WEGr+bpJatvCHJDx5h0NHfm6SdgdKtr26cbtu7gUjNyJjVr1oGVD9vw5e2jPp7d4+OnT6\/V5eFb+oNKUDQsSEDrZsECBAgQIAAAQIECOxPYKxBR3fTze4mo23vZy316G4KutcZHe2X+W54UEtR2qCjDT1qyUkbdLy2N1tkL0FH1VNhx9s6MzB+7AiDjiqrvzdJbRhaIUq7dKWu6S7Hqb+3S29qpsasfrVBRZXV7snRBh\/9oGMRl\/3dwZt7taBjc8dezwkQIECAAAECBAgQmCMw1qBjt0GdFXQcyR4dNYOjO7uhP6NjXiDQ7oWxl6Cjgpefa5aunNAEFd3ZE0e6R0c5zZppUj\/vtr3r2e1jN8DZz4yORVx2G1vvbwkIOtwJBAgQIECAAAECBAgQmCGwKUHHkZ660g062j0uinHejI4KBPayF0U3AGn3wqjNS9ulJssIOrpHwHZndPRntHT33qilJ7OCiupX12PeHh07fX4vLh7UvQkIOvbm5CoCBAgQIECAAAECBDZMYMpBR3+viu4Sl3YZywW98W5DhvbH3dNTamlHnYxSG4fW5p7zAoH+qStfTvL7vdNF+jM9umFDnX7SDzrm9adtb3dJT\/uztt\/9+rqnrnRPjJk3o6PKbOuok1rqny\/O2KNjp6Cj61KbmJ7YOQVmwx69hbsr6FiYUAEECBAgQIAAAQIECExRYKpBxxTHamp96p9oM7X+rbo\/go5VCyufAAECBAgQIECAAIFRCgg6Rjlso210f8ZJfwbNaDt2AA0XdBwAuioJECBAgAABAgQIEBi+gKBj+GOkhQRmCQg63BcECBAgQIAAAQIECBCYISDocFsQGKeAoGOc46bVBAgQIECAAAECBAisWEDQsWJgxRNYkYCgY0WwiiVAgAABAgQIECBAYNwCgo5xj5\/Wb66AoGNzx17PCRAgQIAAAQIECBCYIyDocHsQGKeAoGOc46bVBAgQIECAAAECBAisWEDQsWJgxRNYkYCgY0WwiiVAgAABAgQIECBAYNwCgo5xj5\/Wb66AoGNzx17PCRAgQIAAAQIECBCYIyDocHsQGKeAoGOc46bVBAgQIECAAAECBAisWEDQsWJgxRNYkYCgY0WwiiVAgAABAgQIECBAYNwCgo5xj5\/Wb66AoGNzx17PCRAgQIAAAQIECBCYI3DQQcdjkrx7h\/bd8UUuySVJ6s9eBAhsCwg63A0ECBAgQIAAAQIECBCYIXDQQcfNSY5tgoyX9don6HDLEthZQNDh7iBAgAABAgQIECBAgMAAg46nJXlNkmOSVOhSszfawEPQ4ZYlIOhwDxAgQIAAAQIECBAgQGBfAgc9o6Mae2OSU5pWf70TeNwlyU9burKv8XTx5giY0bE5Y62nBAgQIECAAAECBAjsQ+B9Sb5nH9ev69Lbk\/xZknMEHesiV8\/IBAQdIxswzSVAgAABAgQIECBAYHME+jM6que1hKVmdPw7Qcfm3Ah6ui8BQce+uFxMgAABAgQIECBAgACB9Qh09+hoA46XNlXbo2M9Y6CWcQoIOsY5blpNgAABAgQIECBAgMDEBerUleOaU1fagKPtsqBj4oOvewsJCDoW4vNhAgQIECBAgAABAgQIrEbgsUku3aFoQcdqzJU6DQFBxzTGUS8IECBAgAABAgQIENggAUHHBg22ru5bQNCxbzIfIECAAAECBAgQIECAwMEKCDoO1l\/twxYQdAx7fLSOAAECBAgQIECAAAEChwkIOtwUBHYWEHS4OwgQIECAAAECBAgQIDAyAUHHyAZMc9cqIOhYK7fKCBAgQIAAAQIECBAgsLiAoGNxQyVMV0DQMd2x1TMCBAgQIECAAAECBCYqIOiY6MDq1lIEBB1LYVQIAQIECBAgQIAAAQIE1icg6FiftZrGJyDoGN+YaTEBAgQIECBAgAABAhsuIOjY8BtA9+cKCDrcIAQIECBAgAABAgQIEBiZgKBjZAOmuWsVEHSslVtlBAgQIECAAAECBAgQWFxA0LG4oRKmKyDomO7Y6hkBAgQIECBAgAABAhMVEHRMdGB1aykCgo6lMCqEAAECBAgQIECAAAEC6xMQdKzPWk3jExB0jG\/MtJgAAQIECBAgQIAAgQ0XEHRs+A2g+3MFBB1uEAIECBAgQIAAAQIECIxMQNAxsgHT3LUKCDrWyq0yAgQIECBAgAABAgQILC4g6FjcUAnTFRB0THds9YwAAQIECBAgQIAAgYkKCDomOrC6tRQBQcdSGBVCgAABAgQIECBAgACB9QkIOtZnrabxCQg6xjdmWkyAAAECBAgQIECAwIYLCDo2\/AbQ\/bkCgg43CAECBAgQIECAAAECBEYmIOgY2YBp7loFBB1r5VYZAQIECBAgQIAAAQIEFhcQdCxuqITpCgg6pju2ekaAAAECBAgQIECAwEQFBB0THVjdWoqAoGMpjAohQIAAAQIECBAgQIDA+gQEHeuzVtP4BAQd4xszLSZAgAABAgQIECBAYMMFBB0bfgPo\/lwBQYcbhAABAgQIECBAgAABAiMTEHSMbMA0d60Cgo61cquMAAECBAgQIECAAAECiwsIOhY3VMJ0BQQd0x1bPSNAgAABAgQIECBAYKICgo6JDqxuLUVA0LEURoUQIECAAAECBAgQIEBgfQKCjvVZq2l8AoKO8Y2ZFhMgQIAAAQIECBAgsOECgo4NvwF0f66AoMMNQoAAAQIECBAgQIAAgZEJCDpGNmCau1YBQcdauVVGgAABAgQIECBAgACBxQUEHYsbKmG6AoKO6Y6tnhEgQIAAAQIECBAgMFEBQcdEB1a3liIg6FgKo0IIECBAgAABAgQIECCwPgFBx\/qs1TQ+AUHH+MZMiwkQIECAAAECBAgQ2HABQceG3wC6P1dA0OEGIUCAAAECBAgQIECAwMgEBB0jGzDNXauAoGOt3CojQIAAAQIECBAgQIDA4gKCjsUNlTBdAUHHdMdWzwgQIECAAAECBAgQmKiAoGOiA6tbSxEQdCyFUSEECBAgQIAAAQIECBBYn4CgY33WahqfgKBjfGOmxQQIECBAgAABAgQIbLiAoGPDbwDdnysg6HCDECBAgAABAgQIECBAYGQCgo6RDZjmrlVA0LFWbpURIECAAAECBAgQIEBgcQFBx+KGSpiugKBjumOrZwQIECBAgAABAgQITFRA0DHRgdWtpQgIOpbCqBACBAgQIECAAAECBAisT0DQsT5rNY1PQNAxvjHTYgIECBAgQIAAAQIENlxA0LHhN4DuzxUQdLhBCBAgQIAAAQIECBAgMDIBQcfIBkxz1yog6Fgrt8oIECBAgAABAgQIECCwuMBzk7wyycuTvGDx4pRAYFICL0vy\/KMm1SWdIUCAAAECBAgQIECAwLQFLkzy9iSvS\/Ivpt1VvSOwb4H\/mORZgo59u\/kAAQIECBAgQIAAAQIEDkzgvCSXJ3lbkiceWCtUTGCYAv85yRMEHcMcHK0iQIAAAQIECBAgQIDALIHTk3wuycegtSn7AAACEUlEQVSTfBsiAgQOEbgqyYMFHe4KAgQIECBAgAABAgQIjEegvsN9I8n\/TXJyki+Pp+laSmClAndrnwdBx0qdFU6AAAECBAgQIECAAIGlC7w7yaOTPC3Jm5ZeugIJjFPg6UnekOR\/CjrGOYBaTYAAAQIECBAgQIDA5gr8oyS\/l+RPk5y7uQx6TuAQgauTnJ3kXwk63BkECBAgQIAAAQIECBAYl8DfSnJ9ktOS\/N0kHx1X87WWwNIFvjPJZc2SrlMFHUv3VSABAgQIECBAgAABAgRWLvDCJD+b5GNJHp7k6yuvUQUEhilwbHMSUW3O++okFwk6hjlQWkWAAAECBAgQIECAAIF5AscluTTJ+c1Rs7Vfx9eQEdgwgXoO3prkB5J8Msk59RwIOjbsLtBdAgQIECBAgAABAgQmI3BCkvc2+3Rcm+TJlrFMZmx1ZHeB2p\/mLUnu31z6sCQfqT8LOnbHcwUBAgQIECBAgAABAgSGKnBSkj9O8tCmge9J8sokH3L07FCHTLsWEDixmcV0UXPyUBX1pSRPakK\/O4oWdCwg7KMECBAgQIAAAQIECBAYiMAz67SJJA\/otOe6Zjr\/F5PcYB+PgYyUZuxHoGYt3SvJvZM8MMmZvQ9fnuTC5v7+\/28JOvZD7FoCBAgQIECAAAECBAgMW+BxSZ6X5DHDbqbWEThigSuTvCPJO5Nc0Zy0ckhh\/w8H0ExkvAb9NgAAAABJRU5ErkJggg==\" style=\"cursor:pointer;max-width:100%;\" onclick=\"(function(img){if(img.wnd!=null&&!img.wnd.closed){img.wnd.focus();}else{var r=function(evt){if(evt.data=='ready'&&evt.source==img.wnd){img.wnd.postMessage(decodeURIComponent(img.getAttribute('src')),'*');window.removeEventListener('message',r);}};window.addEventListener('message',r);img.wnd=window.open('https:\/\/www.draw.io\/?client=1&lightbox=1&edit=_blank');}})(this);\"\/>","c54da511":"### Tuned XGBoost training with top 25 features","097bc08c":"### Bayesian Tuning with 50 features","3ecd7f3a":"### Checking for number of NULL values.","be5b2944":"### Bayesian Tuning with 15 features","7fbe6b94":"### Bayesian Tuning with all the features","aed49f03":"#### In general, all the features seems to be normalized \/ standardized based on their mean and std deviation values. Moreover based on the Kurtosis and Skewness most of the distributions seems to be like a normal distribution.","3cdaa95d":"![](https:\/\/www.apixio.com\/wp-content\/uploads\/2017\/10\/classification-with-overfitting-2.png)\n[image-source](https:\/\/www.apixio.com\/wp-content\/uploads\/2017\/10\/classification-with-overfitting-2.png)","8be86479":"### Plotting all the distributions for all the features.","efcf93cc":"### reading the data","61022514":"### XGBoost\n<a id=\"base\"><\/a>\nI will use XGBoost as my ML model, ","e6fb9e76":"# Don't Overfit! II EDA + ML\n\nWe have 20,000 rows of continuous variables, and a mere handful of training samples. Once again, we challenge you not to overfit. Do your best, model without overfitting, and add, perhaps, to your own legend.\n\nIn addition to bragging rights, the winner also gets swag. Enjoy!","cb918544":"### the dataset size","f2fc8357":"### Bayesian Tuning with 25 features","2b324d68":"## Conclusion\n<a id=\"conclusion\"><\/a>\nWe can see from EDA and ML Modeling that class #1 is very unbalanced and difficult to identified and classified."}}