{"cell_type":{"39c1b710":"code","81615078":"code","46204059":"code","e9f7b972":"code","f1d02804":"code","a718cc99":"code","3e351132":"code","2023ebef":"code","12ebbd6c":"code","5b2e876a":"code","583b9874":"code","b2073f68":"code","3619b6fa":"code","3716c598":"code","fdb667a2":"code","b7a23eb1":"code","2319547d":"code","54e297bb":"code","6aef8b6e":"code","7458b27a":"code","922f9e57":"code","d87858e4":"code","c1ad2109":"code","6fdf1bc2":"code","f796dcca":"code","bd5d862f":"code","a7ba7d14":"code","895abc73":"code","c821382a":"code","576e0e2b":"code","94b97ce5":"code","71c8b8f0":"code","f2e9e1a8":"code","3a07e996":"code","b43da563":"code","e3ed1f31":"code","31f8d688":"code","ffd678f6":"markdown","8be2662c":"markdown","637d877c":"markdown","7d33e744":"markdown","b20f4e91":"markdown","d5ffef65":"markdown","34b7e2aa":"markdown","90c5ac31":"markdown","11b1ba83":"markdown","adf56b17":"markdown","1ab16611":"markdown","0bc5c266":"markdown","06e2e3d6":"markdown","d561ca57":"markdown","17798aeb":"markdown","3030251e":"markdown","fd645760":"markdown","80d12ec1":"markdown"},"source":{"39c1b710":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","81615078":"import seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly import tools\nfrom plotly.subplots import make_subplots\nimport matplotlib.pyplot as plt","46204059":"df = pd.read_csv('\/kaggle\/input\/factors-affecting-campus-placement\/Placement_Data_Full_Class.csv')\ndf.head()","e9f7b972":"df.shape","f1d02804":"df.info()","a718cc99":"df.describe()","3e351132":"df.isna().sum()","2023ebef":"df['salary'].fillna(df['salary'].mean(), inplace=True)","12ebbd6c":"categorical_feat = df.select_dtypes(include=['object'])\nnumerical_feat = df.select_dtypes(include=['float64'])","5b2e876a":"fig = px.scatter(numerical_feat, x='ssc_p', y='hsc_p', color='degree_p', size = 'etest_p', hover_data=['mba_p'])\nfig.show()","583b9874":"fig = px.scatter(numerical_feat, x='ssc_p', color=df['status'], height=500, width=600, title='SSC Percentage VS Status',trendline=\"ols\")\nfig.show()\n\nfig = px.scatter(numerical_feat, x='hsc_p', color=df['status'], height=500, width=600, title='HSC Percentage VS Status',trendline=\"ols\")\nfig.show()\n\nfig = px.scatter(numerical_feat, x='degree_p', color=df['status'], height=500, width=600, title='Degree Percentage VS Status',trendline=\"ols\")\nfig.show()\n\nfig = px.scatter(numerical_feat, x='etest_p', color=df['status'], height=500, width=600, title='Employability test Percentage VS Status',trendline=\"ols\")\nfig.show()\n\nfig = px.scatter(numerical_feat, x='mba_p', color=df['status'], height=500, width=600, title='MBA Percentage VS Status',trendline=\"ols\")\nfig.show()","b2073f68":"fig = px.scatter(x = numerical_feat['salary'].value_counts().index, y=numerical_feat['salary'].value_counts())\nfig.show()","3619b6fa":"colors=['mediumturquoise','lightgreen','seagreen','palegreen','olive']\n\nfor col in categorical_feat:\n    plt.figure()\n    categorical_feat[col].value_counts().plot.pie(wedgeprops={\"edgecolor\":\"k\",'linewidth': 2},textprops={'color':'k'}, pctdistance=0.7, autopct='%.2f%%',\n                                                 figsize=(5,5), labels=None, subplots=True, colors=colors)\n    plt.title('{} Distribution'.format(col), fontsize=17, ha='right')\n    plt.legend(labels=categorical_feat[col].value_counts().index, loc='best', bbox_to_anchor=(1, 0.25, 0.5, 0.5))\n    plt.show()","3716c598":"categorical_feat = categorical_feat.drop('status',1)","fdb667a2":"for col in categorical_feat:\n    sns.countplot(x = categorical_feat[col], hue=df['status'], palette =['salmon','lightblue'])\n    plt.show()","b7a23eb1":"# Using Label encoding to convert categorical values into numerical values as many algorithms can't handle categorical values.\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n \ngender = le.fit_transform(df['gender'])\nssc_b = le.fit_transform(df['ssc_b'])\nhsc_b = le.fit_transform(df['hsc_b'])\ndegree_t = le.fit_transform(df['degree_t'])\nworkex = le.fit_transform(df['workex'])\nspecialisation = le.fit_transform(df['specialisation'])\nstatus = le.fit_transform(df['status'])","2319547d":"# droping columns\n\ndf.drop(['sl_no','gender', 'ssc_b', 'hsc_b', 'hsc_s', 'degree_t', 'workex','specialisation','status'],1,inplace=True)","54e297bb":"from sklearn.preprocessing import StandardScaler\n#df[['ssc_p','hsc_p','degree_p','etest_p','mba_p','salary']] = StandardScaler().fit_transform(df[['ssc_p','hsc_p','degree_p','etest_p','mba_p','salary']])","6aef8b6e":"# Appending Label encoded columns to dataframe\n\ndf['gender'] = gender\ndf['ssc_b'] = ssc_b\ndf['hsc_b'] = hsc_b\ndf['degree_t'] = degree_t\ndf['workex'] = workex\ndf['specialisation'] = specialisation\ndf['status'] = status\ndf.head()","7458b27a":"fig, ax = plt.subplots(figsize=(10,10))\nfig.suptitle('Correlation between Status and features',fontsize=20)\nax=sns.heatmap(df.corr()[[\"status\"]].sort_values(\"status\"),vmax=1, vmin=-1, cmap=\"YlGnBu\", annot=True, ax=ax);\nax.invert_yaxis()","922f9e57":"from sklearn.model_selection import train_test_split\n\nx = df.iloc[:,:-1]\ny = df.iloc[:,-1]\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=0)","d87858e4":"print(x.shape)\nprint(y.shape)","c1ad2109":"accuracies = dict()","6fdf1bc2":"from sklearn.linear_model import LogisticRegression\n\nreg = LogisticRegression()\nreg.fit(x_train, y_train)\n\n#Make prediction\ny_pred = reg.predict(x_test)\n\nfrom sklearn.metrics import accuracy_score\naccuracies['Logistic Regression'] = accuracy_score(y_test, y_pred)\nprint('Accuracy is: '+str(accuracy_score(y_test, y_pred)))","f796dcca":"from sklearn.metrics import plot_confusion_matrix\n\nplot_confusion_matrix(reg, x_test, y_test, display_labels=['Placed','Not Placed'], cmap=plt.cm.PuRd, normalize='true')\nplt.title('Confusion Matrix Of Campus Placement')\nplt.show()","bd5d862f":"from sklearn.svm import SVC\n\n\nclassifier = SVC(kernel = 'rbf', random_state = 0)\nclassifier.fit(x_train, y_train)\n\ny_pred = classifier.predict(x_test)\n\nfrom sklearn.metrics import accuracy_score\naccuracies['Kernel SVM'] = accuracy_score(y_test, y_pred)\nprint('Accuray is: '+str(accuracy_score(y_test, y_pred)))","a7ba7d14":"from sklearn.metrics import plot_confusion_matrix\n\nplot_confusion_matrix(classifier, x_test, y_test, display_labels=['Placed','Not Placed'], cmap=plt.cm.Blues, normalize='true')\nplt.title('Confusion Matrix of Campus Placement')\nplt.show()","895abc73":"from sklearn.naive_bayes import GaussianNB\n\ngnb = GaussianNB()\ngnb.fit(x_train, y_train)\n\ny_pred = gnb.predict(x_test)\n\nfrom sklearn.metrics import accuracy_score\n\naccuracies['Naive Bayes'] = accuracy_score(y_test, y_pred)\nprint('Accuray is: '+str(accuracy_score(y_test, y_pred)))","c821382a":"from sklearn.metrics import plot_confusion_matrix\n\nplot_confusion_matrix(gnb, x_test, y_test, display_labels=['Placed','Not Placed'], cmap=plt.cm.Purples, normalize='true')\nplt.title('Confusion Matrix of Campus Placement')\nplt.show()","576e0e2b":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\nknn.fit(x_train, y_train)\n\ny_pred = knn.predict(x_test)\n\nfrom sklearn.metrics import accuracy_score\naccuracies['KNeighbors Classifier'] = accuracy_score(y_test, y_pred)\nprint('Accuracy is: '+str(accuracy_score(y_test, y_pred)))","94b97ce5":"from sklearn.metrics import plot_confusion_matrix\n\nplot_confusion_matrix(knn, x_test, y_test, display_labels=['Placed','Not Placed'], cmap=plt.cm.pink, normalize='true')\nplt.title('Confusion Matrix of Campus Placement')\nplt.show()","71c8b8f0":"from sklearn.tree import DecisionTreeClassifier\n\ndtc = DecisionTreeClassifier(criterion = 'entropy', random_state= 0)\ndtc.fit(x_train, y_train)\n\n#Make Prediction\ny_pred = classifier.predict(x_test)\n\nfrom sklearn.metrics import accuracy_score\n\naccuracies['Decision Tree Classification'] = accuracy_score(y_test, y_pred)\nprint('Accuracy is: ' + str(accuracy_score(y_test, y_pred)))","f2e9e1a8":"from sklearn.metrics import plot_confusion_matrix\n\nplot_confusion_matrix(dtc, x_test, y_test, display_labels=['Placed','Not Placed'], cmap=plt.cm.bone, normalize='true')\nplt.title('Confusion Matrix of Campus Placement')\nplt.show()","3a07e996":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(n_estimators= 2, random_state= 0)\nrfc.fit(x_train, y_train)\n\n#Make Prediction\ny_pred = classifier.predict(x_test)\n\nfrom sklearn.metrics import accuracy_score\n\naccuracies['Random Tree Classification'] = accuracy_score(y_test, y_pred)\nprint('Accuracy is: ' + str(accuracy_score(y_test, y_pred)))","b43da563":"from sklearn.metrics import plot_confusion_matrix\n\nplot_confusion_matrix(rfc, x_test, y_test, display_labels=['Placed','Not Placed'], cmap=plt.cm.copper, normalize='true')\nplt.title('Confusion Matrix of Campus Placement')\nplt.show()","e3ed1f31":"accuracy_df = pd.DataFrame(list(accuracies.items()), columns=['Model Name','Accuracy Score'])\naccuracy_df","31f8d688":"f, ax = plt.subplots(figsize=(8, 6))\nsns.set_color_codes('pastel')\nsns.barplot(y='Model Name', x='Accuracy Score', data=accuracy_df, color='pink')\nplt.show()","ffd678f6":"# Label Encoding","8be2662c":" Salary column has 67 null values. Using salary mean to fill the null values.  ","637d877c":"# Kernel SVM","7d33e744":"# Classification Models","b20f4e91":"**Splitting data in to two sets categorical and numerical for EDA.**","d5ffef65":"# Correlation with Heatmap","34b7e2aa":"# KNeighbors Classifier","90c5ac31":"# Feature Scaling\nI will use Standard Scaler","11b1ba83":"****Confusion Matrix Of Decision Tree Classifier","adf56b17":"# Bivariate Analysis Of Categorical Features","1ab16611":"# Numerical Feature Analysis","0bc5c266":"**Confusion Matrix** Of Random Forest Classifier","06e2e3d6":"# Univariate Analysis Of Categorical Features","d561ca57":"# Logistic Regression","17798aeb":"**Confusion Matrix Of KNeighbors Classifier**","3030251e":"**Confusion Matrix Of Naive Bayes**","fd645760":"** Confusion Matrix Of Logistic Regression**","80d12ec1":"**Confusion Matrix Of Kernel SVM**"}}