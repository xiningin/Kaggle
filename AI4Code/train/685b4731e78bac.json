{"cell_type":{"afb1dbf2":"code","c149fda2":"code","5ba5362c":"code","a5f7dc76":"code","c3566ee7":"code","66d1aef7":"code","bce0f78f":"code","26cad2f0":"code","7243cc85":"code","614ef82d":"code","c0499703":"code","e8a612e8":"code","522a9668":"code","e6b4fb88":"code","297e1b36":"code","8de18a4f":"code","c4841172":"code","75b4d25f":"code","ace361ab":"code","b53e601f":"code","4f3fe9d6":"code","61f8ba43":"code","85724074":"code","f94126af":"code","f3a2fb19":"code","50a59f17":"code","5f964c31":"code","025b8a9e":"code","b0395393":"code","b1374367":"code","6f2ecd0b":"code","8e480541":"code","add6ff0c":"code","99611e02":"code","3b5cde8f":"code","b783027f":"code","52c8ac38":"code","72a6d952":"code","d63fcac1":"code","45794755":"code","b29625fd":"code","30629eb9":"code","9a28209e":"code","9d0c202b":"code","08d9cf7d":"code","91b46831":"code","0f8322ac":"code","edb7b5c5":"code","88f4150a":"code","70adaf4e":"code","0b325796":"code","7ee3aef7":"code","2257afdc":"code","523d3af6":"code","8c1af334":"code","c774c42e":"code","2e769861":"code","b1af69b0":"code","6ea8e168":"code","0f1ebd23":"code","b213276c":"code","bce9d226":"code","68a24f8e":"code","9686f616":"code","85a724db":"code","b19b4bf7":"markdown","6003bd02":"markdown","7c43c93e":"markdown","5580b49f":"markdown","55914511":"markdown","8f159078":"markdown","1c0a7787":"markdown","84443d22":"markdown","ca8e56a9":"markdown","1fc47101":"markdown","958ce4b6":"markdown","528cd71e":"markdown","32026664":"markdown","32050b60":"markdown","c56dd7f8":"markdown","788ff048":"markdown","b1a47673":"markdown","0ca5d556":"markdown","bd0569fc":"markdown","1addc923":"markdown","b3d37ccd":"markdown","621a476e":"markdown","69c4f603":"markdown","37e6edab":"markdown","b50fb9f6":"markdown","bf22652e":"markdown","33dd6669":"markdown","52a2fd20":"markdown","c19a22b8":"markdown","b8c758e6":"markdown","6de6e3af":"markdown","80f99fa5":"markdown"},"source":{"afb1dbf2":"%matplotlib inline\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', None)\n#pd.set_option('display.max_rows', None)\n\nfrom glob import glob\n\nimport re\nimport gc\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import mean_squared_error\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import display\n\nfrom tqdm import tqdm, tqdm_notebook\ntqdm.pandas()\n\nimport plotly.express as px #Plotly Express\n\nfrom plotly.offline import iplot\n\n#to link plotly to pandas\nimport cufflinks as cf\ncf.go_offline()\ncf.set_config_file(offline = False, world_readable = True)\n\nimport plotly.io as pio\npio.templates.default = 'plotly_white'\n\nimport itertools\nimport collections\nfrom collections import Counter\n\nfrom nltk.corpus import stopwords\n\nimport re\nfrom wordcloud import WordCloud\n\nplt.rcParams[\"figure.figsize\"] = (12, 8)\nplt.rcParams['axes.titlesize'] = 16\nplt.style.use('seaborn-whitegrid')\nsns.set_palette('Set2')\n\nimport os\nprint(os.listdir('\/kaggle\/input\/actuarial-loss-estimation\/'))\n\nimport warnings\nwarnings.simplefilter('ignore')\n\nfrom time import time, strftime, gmtime\nstart = time()\nimport datetime\nprint(str(datetime.datetime.now()))","c149fda2":"train = pd.read_csv('\/kaggle\/input\/actuarial-loss-estimation\/train.csv')\nprint(train.shape)\ntrain.head()","5ba5362c":"test = pd.read_csv('\/kaggle\/input\/actuarial-loss-estimation\/test.csv')\nprint(test.shape)\ntest.head()","a5f7dc76":"sub = pd.read_csv('\/kaggle\/input\/actuarial-loss-estimation\/sample_submission.csv')\nsub","c3566ee7":"train.describe().T","66d1aef7":"train.info()","bce0f78f":"print(f\"No. of unique {train['ClaimNumber'].nunique()}\")","26cad2f0":"plt.figure(figsize = (16, 10))\nplt.subplot(1, 2, 1)\nsns.distplot(train['UltimateIncurredClaimCost'])\nplt.subplot(1, 2, 2)\nplt.title('Log Scale')\nsns.distplot(np.log1p(train['UltimateIncurredClaimCost']));","7243cc85":"sns.boxplot(train['UltimateIncurredClaimCost']);","614ef82d":"missing = train.isna().sum().reset_index()\nmissing.columns = ['features', 'total_missing']\nmissing['percent'] = (missing['total_missing'] \/ len(train)) * 100\nmissing.index = missing['features']\ndel missing['features']\n\nmissing['total_missing'].iplot(kind = 'bar', \n                               title = 'Missing Values Plot in Trainset',\n                               xTitle = 'Features',\n                               yTitle = 'Count')\nmissing.T","c0499703":"missing = train.isna().sum().reset_index()\nmissing.columns = ['features', 'total_missing']\nmissing['percent'] = (missing['total_missing'] \/ len(train)) * 100\nmissing.index = missing['features']\ndel missing['features']\n\nmissing['total_missing'].iplot(kind = 'bar', \n                               title = 'Missing Values Plot in Testset',\n                               xTitle = 'Features',\n                               yTitle = 'Count')\nmissing.T","e8a612e8":"plt.suptitle('Countplot of Marital Status: M - Married; S - Single; U - Unknown')\nplt.subplot(1, 2, 1)\ntrain['MaritalStatus'].value_counts(dropna = False).plot(kind = 'bar', rot = 0);\n\nplt.subplot(1, 2, 2)\ntrain['MaritalStatus'].value_counts(dropna = False).plot(kind = 'bar', rot = 0);","522a9668":"train[~train['MaritalStatus'].isin(['M', 'S', 'U'])]['Age'].plot(kind = 'hist')","e6b4fb88":"train['MaritalStatus'].fillna('U', inplace = True)\ntest['MaritalStatus'].fillna('U', inplace = True)\n#Check\ntrain.isna().any().sum(), test.isna().any().sum()","297e1b36":"train['DateTimeOfAccident'] = pd.to_datetime(train['DateTimeOfAccident'])\ntrain['DateReported'] = pd.to_datetime(train['DateReported'])\n\ntest['DateTimeOfAccident'] = pd.to_datetime(test['DateTimeOfAccident'])\ntest['DateReported'] = pd.to_datetime(test['DateReported'])","8de18a4f":"print('Train:')\nprint(f\"Max. Age: {train['Age'].max()}\")\nprint(f\"Min. Age: {train['Age'].min()}\")\nprint(f\"Avg. Age: {round(train['Age'].mean(), 2)}\")\n\nprint('Test:')\nprint(f\"Max. Age: {test['Age'].max()}\")\nprint(f\"Min. Age: {test['Age'].min()}\")\nprint(f\"Avg. Age: {round(test['Age'].mean(), 2)}\")","c4841172":"plt.suptitle('Distribution of Age')\n\nplt.subplot(1, 2, 1)\nsns.distplot(train['Age'], color = '#810f7c')\nplt.title('Train')\n\nplt.subplot(1, 2, 2)\nsns.distplot(test['Age'], color = '#8c96c6')\nplt.title('Test');","75b4d25f":"train['Gender'].value_counts().iplot(kind = 'bar', \n                                    yTitle = 'Count', \n                                    xTitle = 'Gender', \n                                    title = 'Count plot of Gender: M - Male; F- Female; U - Unknown\/Unspecified')","ace361ab":"train['DependentChildren'].max(), train['DependentChildren'].min(), train['DependentChildren'].median()","b53e601f":"plt.subplot(1, 2 , 1)\nsns.countplot(train['DependentChildren'])\nplt.subplot(1, 2 , 2)\nsns.countplot(train['DependentsOther']);","4f3fe9d6":"train['DependentsOther'].max(), train['DependentsOther'].min(), train['DependentsOther'].median()","61f8ba43":"train['PartTimeFullTime'].value_counts().iplot(kind = 'bar', \n                                    yTitle = 'Count', \n                                    xTitle = 'Type of Work', \n                                    title = 'Type of Work: F - Full Time;  P - Part Time')","85724074":"print(f\"Max. hours worked: {train['HoursWorkedPerWeek'].max()}\")\nprint(f\"Min. hours worked: {train['HoursWorkedPerWeek'].min()}\")\nprint(f\"Avg. hours worked: {round(train['HoursWorkedPerWeek'].mean(), 2)}\")\nsns.distplot(train['HoursWorkedPerWeek']);","f94126af":"print(f\"There are {train[train['HoursWorkedPerWeek'] == 1.0].__len__()} entries with HoursWorkedPerWeek 0.0 hours\\n\")\ntrain[train['HoursWorkedPerWeek'] == 0.0].head(2)","f3a2fb19":"train['DaysWorkedPerWeek'].value_counts().iplot(kind = 'bar', \n                                    yTitle = 'Count', \n                                    xTitle = 'No. of Days Worked', \n                                    title = 'Number of Days Worked Per Week')","50a59f17":"plt.figure(figsize = (16, 10))\nplt.subplot(1, 2, 1)\nsns.distplot(train['InitialIncurredCalimsCost'])\nplt.subplot(1, 2, 2)\nplt.title('Log Scale')\nsns.distplot(np.log1p(train['InitialIncurredCalimsCost']));","5f964c31":"sns.boxplot(train['InitialIncurredCalimsCost']);","025b8a9e":"print('Train:')\nprint(f\"Max. Initial Claim: {train['InitialIncurredCalimsCost'].max()}\")\nprint(f\"Min. Initial Claim: {train['InitialIncurredCalimsCost'].min()}\")\nprint(f\"Avg. Initial Claim: {round(train['InitialIncurredCalimsCost'].mean(), 2)}\")\n\nprint('Test:')\nprint(f\"Max. Initial Claim: {test['InitialIncurredCalimsCost'].max()}\")\nprint(f\"Min. Initial Claim: {test['InitialIncurredCalimsCost'].min()}\")\nprint(f\"Avg. Initial Claim: {round(test['InitialIncurredCalimsCost'].mean(), 2)}\")","b0395393":"print(f\"There are {train[train['InitialIncurredCalimsCost'] == 2000000].__len__()} entries with high Inital Claim\\n\")\ntrain[train['InitialIncurredCalimsCost'] == 2000000].head(2)","b1374367":"print(f\"There are {test[test['InitialIncurredCalimsCost'] == 725000].__len__()} entries with high Inital Claim\\n\")\ntest[test['InitialIncurredCalimsCost'] == 725000].head(2)","6f2ecd0b":"print(f\"There are {train[train['InitialIncurredCalimsCost'] == 1].__len__()} entries with Inital Claim $1.0\\n\")\ntrain[train['InitialIncurredCalimsCost'] == 1].head(2)","8e480541":"print(f\"There are {test[test['InitialIncurredCalimsCost'] == 1].__len__()} entries with Inital Claim $1.0\\n\")\ntest[test['InitialIncurredCalimsCost'] == 1].head(2)","add6ff0c":"plt.title('Distribution of Weekly Wages')\nsns.distplot(train['WeeklyWages']);","99611e02":"train['WeeklyWages'].max(), train['WeeklyWages'].min(), train['WeeklyWages'].mean()","3b5cde8f":"print(f\"There are {train[train['WeeklyWages'] == 1.0].__len__()} entries with WeeklyWages 1.0 \\n\")\ntrain[train['WeeklyWages'] == 1.0].head(2)","b783027f":"print(f\"There are {test[test['WeeklyWages'] == 1.0].__len__()} entries with WeeklyWages 1.0 \\n\")\ntest[test['WeeklyWages'] == 1.0].head(2)","52c8ac38":"train['TimeDiff_Hrs'] = (train['DateReported'] - train['DateTimeOfAccident']).astype('timedelta64[h]')\ntest['TimeDiff_Hrs'] = (test['DateReported'] - test['DateTimeOfAccident']).astype('timedelta64[h]')\n\ntrain['Acc_Day'] = train['DateTimeOfAccident'].dt.dayofweek\ntest['Acc_Day'] = test['DateTimeOfAccident'].dt.dayofweek\n\ntrain['Acc_Month'] = train['DateTimeOfAccident'].dt.month\ntest['Acc_Month'] = test['DateTimeOfAccident'].dt.month\n\ntrain['Acc_Year'] = train['DateTimeOfAccident'].dt.year\ntest['Acc_Year'] = test['DateTimeOfAccident'].dt.year","72a6d952":"#0 - Monday\ntrain['Acc_Day'].value_counts().iplot(kind = 'bar', \n                                    yTitle = 'Count', \n                                    xTitle = 'Days of Week', \n                                    title = 'Accidents Numbers by Day of Week')","d63fcac1":"train['Acc_Month'].value_counts().iplot(kind = 'bar', \n                                    yTitle = 'Count', \n                                    xTitle = 'Months', \n                                    title = 'Accidents Numbers by Month')","45794755":"train['Acc_Year'].value_counts().iplot(kind = 'bar', \n                                    yTitle = 'Count', \n                                    xTitle = 'Year', \n                                    title = 'Accidents Numbers by Year')","b29625fd":"print('Train:')\nprint(f\"Max. Time Diff in Hrs: {train['TimeDiff_Hrs'].max()}\")\nprint(f\"Min. Time Diff in Hrs: {train['TimeDiff_Hrs'].min()}\")\nprint(f\"Avg. Time Diff in Hrs: {round(train['TimeDiff_Hrs'].mean(), 2)}\")\n\nprint('Test:')\nprint(f\"Max. Time Diff in Hrs: {test['TimeDiff_Hrs'].max()}\")\nprint(f\"Min. Time Diff in Hrs: {test['TimeDiff_Hrs'].min()}\")\nprint(f\"Avg. Time Diff in Hrs: {round(test['TimeDiff_Hrs'].mean(), 2)}\")","30629eb9":"sns.distplot(train['TimeDiff_Hrs']);","9a28209e":"display(train[train['TimeDiff_Hrs'] < 0], test[test['TimeDiff_Hrs'] < 0] )","9d0c202b":"train['TimeDiff_Hrs'] = train['TimeDiff_Hrs'].apply(lambda x: 0.0 if x < 0 else x)\ntest['TimeDiff_Hrs'] = test['TimeDiff_Hrs'].apply(lambda x: 0.0 if x < 0 else x)","08d9cf7d":"#Check\nprint('Train:')\nprint(f\"Max. Time Diff in Hrs: {train['TimeDiff_Hrs'].max()}\")\nprint(f\"Min. Time Diff in Hrs: {train['TimeDiff_Hrs'].min()}\")\nprint(f\"Avg. Time Diff in Hrs: {round(train['TimeDiff_Hrs'].mean(), 2)}\")\n\nprint('Test:')\nprint(f\"Max. Time Diff in Hrs: {test['TimeDiff_Hrs'].max()}\")\nprint(f\"Min. Time Diff in Hrs: {test['TimeDiff_Hrs'].min()}\")\nprint(f\"Avg. Time Diff in Hrs: {round(test['TimeDiff_Hrs'].mean(), 2)}\")","91b46831":"px.scatter(train, x = 'Age', y = 'WeeklyWages', size = 'InitialIncurredCalimsCost', \n           color = 'Gender',\n          template = 'plotly_white')","0f8322ac":"px.scatter(train, x = 'WeeklyWages', y = 'InitialIncurredCalimsCost', size = 'Age', \n           color = 'PartTimeFullTime',\n          template = 'plotly_white')","edb7b5c5":"pd.pivot_table(data = train, index = 'Gender', \n               columns = ['MaritalStatus'], \n               values = ['InitialIncurredCalimsCost', 'UltimateIncurredClaimCost']).iplot(kind = 'bar', \n                                                                                         xTitle = 'Gender', \n                                                                                         yTitle = 'Claims Cost', \n                                                                                         title = 'Claims by MaritalStatus')","88f4150a":"#We don't need the datetime features\ntrain.drop(['DateTimeOfAccident', 'DateReported'], axis = 1, inplace = True)\ntest.drop(['DateTimeOfAccident', 'DateReported'], axis = 1, inplace = True)","70adaf4e":"numerical_features = [c for c in train.columns if train[c].dtype in ['float64', 'int64'] if c not in ['Acc_Day', 'Acc_Month', 'Acc_Year']]\ncategorical_features = [c for c in train.columns if c not in numerical_features]\nnumerical_features, categorical_features","0b325796":"corr1 = train[numerical_features].corr(method = 'pearson')\n\nfig = plt.figure(figsize = (10, 8))\n#mask = np.triu(np.ones_like(corr1, dtype = bool))\nsns.heatmap(corr1, mask = None, annot = True, cmap = 'PiYG', vmin = -1, vmax = +1)\nplt.title('Pearson Correlation')\nplt.xticks(rotation = 90)\nplt.show()","7ee3aef7":"#scatter plot - we pick pair having highest (Pearson) correlation\nsns.jointplot(data = train, x = 'DaysWorkedPerWeek', y = 'HoursWorkedPerWeek', hue = 'Gender');","2257afdc":"px.scatter(train, x = 'InitialIncurredCalimsCost', y = 'UltimateIncurredClaimCost', color = 'Gender')","523d3af6":"def plot_wordcloud(data, col, text = None):\n    stop = stopwords.words('english')\n    all_words = [word for each in data[col] for word in str(each).lower().split() if word not in stop]\n    word_freq = Counter(all_words)\n\n    wordcloud = WordCloud(width = 900,\n                          height = 500,\n                          max_words = 200,\n                          max_font_size = 100,\n                          relative_scaling = 0.5,\n                          background_color = \"rgba(255, 255, 255, 0)\", \n                          mode = \"RGBA\",\n                          normalize_plurals = True).generate_from_frequencies(word_freq)\n    plt.figure(figsize = (16, 12))\n    plt.imshow(wordcloud, interpolation = 'bilinear')\n    plt.title(text, fontsize = 16)\n    plt.axis(\"off\")\n    plt.show()","8c1af334":"plot_wordcloud(train, 'ClaimDescription', 'WordCloud of Claim Description')","c774c42e":"train['InitialIncurredCalimsCost'] = np.log1p(train['InitialIncurredCalimsCost'])\ntest['InitialIncurredCalimsCost'] = np.log1p(test['InitialIncurredCalimsCost'])\n\ntarget = np.log1p(train['UltimateIncurredClaimCost'])\n\ntrain.drop(['ClaimNumber', 'ClaimDescription', 'UltimateIncurredClaimCost'], axis = 1, inplace = True)\ntest.drop(['ClaimNumber', 'ClaimDescription'], axis = 1, inplace = True)\n\nnumerical_features.remove('UltimateIncurredClaimCost')\ncategorical_features.remove('ClaimNumber')\ncategorical_features.remove('ClaimDescription')\n\ntrain.shape, test.shape","2e769861":"lbl = LabelEncoder()\n\nfor c in train[categorical_features]:\n    print(f\"Label Encoding Categorical Feature - {c.upper()}\")\n    train[c] = lbl.fit_transform(train[c])\n    test[c] = lbl.fit_transform(test[c])\nprint('Label Encoding done...')\ntrain[categorical_features].head(2)","b1af69b0":"std = StandardScaler()\n\ntrain[numerical_features] = std.fit_transform(train[numerical_features])\ntest[numerical_features] = std.fit_transform(test[numerical_features])\nprint('Standardizing Numerical Features done...')\ntrain[numerical_features].head(2)","6ea8e168":"Xtrain, Xvalid, ytrain, yvalid = train_test_split(train, target, test_size = 0.2, random_state = 2021)\nprint(Xtrain.shape, ytrain.shape, Xvalid.shape, yvalid.shape)","0f1ebd23":"from lightgbm import LGBMRegressor\n\nlgbm = LGBMRegressor(\n               objective = 'regression', \n               num_leaves = 4,\n               learning_rate = 0.01, \n               n_estimators = 10000,\n               max_bin = 200, \n               bagging_fraction = 0.75,\n               bagging_freq = 5, \n               bagging_seed = 7,\n               feature_fraction = 0.2,\n               feature_fraction_seed = 7,\n               verbose = 1,\n            )\n\nlgbm_model = lgbm.fit(Xtrain, ytrain)\nlg_vpreds = lgbm_model.predict(Xvalid)\nprint((f\"LGBM RMSE: {np.sqrt(mean_squared_error(yvalid, lg_vpreds))}\"))","b213276c":"lg_preds = lgbm_model.predict(test)\nsub['UltimateIncurredClaimCost'] = np.expm1(lg_preds)\nsub.to_csv('submission.csv', index = False)\nsub.head()","bce9d226":"from xgboost import XGBRegressor\n\nxgb = XGBRegressor(\n                    learning_rate = 0.01, \n                    n_estimators = 10000,\n                    max_depth = 3, \n                    min_child_weight = 0,\n                    gamma = 0, \n                    subsample = 0.7,\n                    colsample_bytree = 0.7,\n                    objective = 'reg:squarederror', \n                    nthread = 1,\n                    scale_pos_weight = 1, \n                    seed = 27,\n                    reg_alpha = 0.00006\n                    )\nxgb_model = xgb.fit(Xtrain, ytrain)\nxg_vpreds = xgb_model.predict(Xvalid)\nprint((f\"XGBOOST RMSE: {np.sqrt(mean_squared_error(yvalid, xg_vpreds))}\"))","68a24f8e":"xg_preds = xgb_model.predict(test)\nsub['UltimateIncurredClaimCost'] = np.expm1(xg_preds)\nsub.to_csv('submission_xg.csv', index = False)\nsub.head()","9686f616":"sub['UltimateIncurredClaimCost'] = np.expm1(lg_preds) + np.expm1(xg_preds)\nsub.to_csv('submission_en.csv', index = False)\nsub.head()","85a724db":"finish = time()\nprint(strftime(\"%H:%M:%S\", gmtime(finish - start)))","b19b4bf7":"# Standardization and Label Encoding ","6003bd02":"__TimeDiff_Hrs__","7c43c93e":"# Features Correlation ","5580b49f":"# Target: 'UltimateIncurredClaimCost'\n# Evaluation Metric: Root Mean Squared Error (RMSE)","55914511":"# Interaction Plots","8f159078":"__CLAIMDESCRIPTION__","1c0a7787":"__Weekly Wages__","84443d22":"__Target Distribution__","ca8e56a9":"Distribution is same for train and test","1fc47101":"There are workers who have worked for 0 hours!!","958ce4b6":"__Date Features__","528cd71e":"__InitialIncurredCalimsCost__","32026664":"__Dependents: Children\/Others__","32050b60":"- This could be due to wrong entry or these could be namesake employees (who doesn't work in the firm but lend their names to be in payroll)","c56dd7f8":"# Feature Engineering","788ff048":"__Check the missing values in dataset__","b1a47673":"__Creating time difference from Accident to Reported date in hours is more relevent__","0ca5d556":"__PartTimeFullTime__","bd0569fc":"- Checking the data above shows, that these accidents were reported on the same day but time of reporting weren't registered.\n- These entries can be changed from negative to 0.0 ","1addc923":"- Ultimate Claim cost is always more than the Inital Claim","b3d37ccd":"__HoursWorkedPerWeek__","621a476e":" Imputing the NaNs with 'U' is better","69c4f603":"- Majority have 0 Dependents","37e6edab":"- These entries are most likely wrong entries and can be imputed","b50fb9f6":"# EDA","bf22652e":"__Gender__","33dd6669":"- Converting target to log1p of the cost may help the model (remember to convert the prediction using np.expm1)","52a2fd20":"__Marital Status__","c19a22b8":"__Age__","b8c758e6":"Let's check the claims that were reported before the accident happened!!","6de6e3af":"__DaysWorkedPerWeek__","80f99fa5":"- Weekly Wages at $1?!!"}}