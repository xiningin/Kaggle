{"cell_type":{"7987f823":"code","42b83e02":"code","98edde15":"code","04e06abd":"code","9ea5cf9f":"code","90a0b46e":"code","2c145665":"code","4fa56c7a":"code","7cc02710":"code","47d58089":"code","b3241668":"code","ec52b1e9":"code","81a2add0":"code","d3d1337b":"code","c943933d":"code","e925b73f":"code","fbad6066":"code","497f3ec4":"code","9138854e":"code","297eb61e":"code","1e4e0e9d":"code","be83a13d":"code","a7814e55":"code","7e6627e9":"code","0ff2250d":"code","4571a53f":"code","0dd8b5cc":"code","7d195ce5":"code","02615690":"code","6319ee45":"code","a2d1c4aa":"code","fe7adf73":"code","94b57514":"code","89d4f359":"code","601c881f":"code","a38c8207":"code","97cf4835":"code","eba9fc44":"code","6d8808df":"markdown","3327ae96":"markdown","d595db9f":"markdown","8c272942":"markdown","a4cc4411":"markdown","0f36a9b8":"markdown","d0422389":"markdown","48fcc96c":"markdown","3d3e1a2e":"markdown","5fd4b50a":"markdown","b506c803":"markdown","e712154f":"markdown","684a5e29":"markdown","872341a4":"markdown","2bd42096":"markdown","4bade8c6":"markdown","524886e7":"markdown","581946f6":"markdown","f27919e2":"markdown","d75b0f5e":"markdown","5a53d407":"markdown"},"source":{"7987f823":"import sklearn\nprint (sklearn.__version__)","42b83e02":"# Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression,Perceptron\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier\nfrom sklearn.linear_model.stochastic_gradient import SGDClassifier\n\nfrom sklearn.preprocessing import Imputer , Normalizer , scale\nfrom sklearn.model_selection import train_test_split , StratifiedKFold, cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.metrics import roc_curve, auc\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\n\nimport re\n\n# Configura\u00e7\u00f5es de visualiza\u00e7\u00e3o\n%matplotlib inline\nmpl.style.use( 'ggplot' )\nsns.set_style( 'white' )\npylab.rcParams[ 'figure.figsize' ] = 8 , 6\npd.set_option('display.max_rows', 20000)\npd.set_option('display.max_columns', 50)\n","98edde15":"import subprocess as sub\nprint(sub.check_output([\"pwd\"]).decode(\"utf8\"))\nprint(sub.check_output([\"ls\", \"..\"]).decode(\"utf8\"))","04e06abd":"#Carga dos arquivos\n\n#train_df = pd.read_csv(\"input\/SERPRO\/titanic-train.csv\"titanic-train.csv\")\n#test_df = pd.read_csv(\"input\/SERPRO\/titanic-test.csv\"titanic-test.csv\")\ntrain_df = pd.read_csv('\/kaggle\/input\/serpro-titanic\/titanic-train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/serpro-titanic\/titanic-test.csv')\n\n#obtem os id para usar na submiss\u00e3o\npersons = test_df.person\nprint(train_df.shape)\nprint(test_df.shape)\nprint(persons.shape)","9ea5cf9f":"# une os conjuntos de treino e teste\nfull = train_df.append(test_df, ignore_index=True)\n\n# cria indices para separa\u00e7\u00e3o entre os conjuntos, posteriormente\ntrain_idx = len(train_df)\nprint(len(full))\ntest_idx = len(full) - len(test_df) # 1309 - 437 =872\nprint(\"train_idx=\"+str(train_idx))\nprint(\"test_idx=\"+str(test_idx) + '\\n')\n\nprint(full.shape)\nfull.info()\n","90a0b46e":"def display_all(full):\n    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n        display(full)\n           \ndisplay_all(full.describe(include='all').T)","2c145665":"full['survived'].value_counts()","4fa56c7a":"# Fare n\u00e3o existentes: usada mediana da classe do passageiro\nclass_fares = dict(full.groupby('pclass')['fare'].median())\n\n# cria coluna com mediana dos pre\u00e7os\nfull['fare_med'] = full['pclass'].apply(lambda x: class_fares[x])\n\n# substitui as fares com os valores desta coluna\nfull['fare'].fillna(full['fare_med'], inplace=True, )\ndel full['fare_med']","7cc02710":"#Transforma survived e sex para num\u00e9rico\nfull['survived'] = full['survived'].map({'yes': 1, 'no': 0})\nfull['sex'] = full['sex'].map({'male': 1, 'female': 0}) \n\nfull.head()","47d58089":"# extraindo os t\u00edtulos de cada nome\nfull[ 'tratamento' ] = full[ 'name' ].map( lambda name: name.split( ',' )[1].split( '.' )[0].strip() )\n    ","b3241668":"# Mapeando t\u00edtulos em grupos categ\u00f3ricos\ntitle_dic = {\n                    \"Capt\":       \"Tripulacao\",\n                    \"Col\":        \"Tripulacao\",\n                    \"Major\":      \"Tripulacao\",\n                    \"Jonkheer\":   \"Nobreza\",\n                    \"Don\":        \"Nobreza\",\n                    \"Sir\" :       \"Nobreza\",\n                    \"Dr\":         \"Tripulacao\",\n                    \"Rev\":        \"Tripulacao\",\n                    \"the Countess\":\"Nobreza\",\n                    \"Dona\":       \"Nobreza\",\n                    \"Mme\":        \"Mrs\",\n                    \"Mlle\":       \"Miss\",\n                    \"Ms\":         \"Mrs\",\n                    \"Mr\" :        \"Mr\",\n                    \"Mrs\" :       \"Mrs\",\n                    \"Miss\" :      \"Miss\",\n                    \"Master\" :    \"Master\",\n                    \"Lady\" :      \"Nobreza\"\n\n                    }\n\n# mapeando os t\u00edtulos\nfull['title'] = full.tratamento.map( title_dic )\nfull['title'].shape","ec52b1e9":"# Cria variaveis numericas para cada title\ntitledummies = pd.get_dummies( full.title , prefix='title' )\nfull = pd.concat([ full, titledummies ], axis=1) \nfull.shape","81a2add0":"# Abordagem inicial, n\u00e3o utilizada!\n# Ages n\u00e3o existentes: uso mediana das idades dos passageiros\n#full['age'] = full['age'].fillna(full['age'].median())\n#display_all(full.describe(include='all').T)","d3d1337b":"# Ve a m\u00e9dia da idade de cada tipo de t\u00edtulo\nfull.groupby('title')['age'].mean()\n","c943933d":"# Tratando valores ausentes de idade com a media da idade de cada title\nfull.loc[(full.age.isnull())&(full.title=='Master'),'age']=8\nfull.loc[(full.age.isnull())&(full.title=='Miss'),'age']=23\nfull.loc[(full.age.isnull())&(full.title=='Mr'),'age']=31\nfull.loc[(full.age.isnull())&(full.title=='Mrs'),'age']=36\nfull.loc[(full.age.isnull())&(full.title=='Tripulacao'),'age']=45\nfull.loc[(full.age.isnull())&(full.title=='Nobreza'),'age']=43\n","e925b73f":"full['familysize'] = full['parch'] + full['sibsp']","fbad6066":"# Cria variaveis numericas para embarked\nembarked = pd.get_dummies( full.embarked , prefix='embarked' )","497f3ec4":"# Insere no dataset\nfull = pd.concat( [ full,embarked ] , axis=1)\nfull.head()\nfull.info()\n","9138854e":"full_bak = full.copy()\nfull_bak = full_bak.drop(['cabin','embarked','home_destination', 'name', 'person', 'ticket', 'title', 'tratamento' ], axis = 1)\nfull = full.drop(['cabin','embarked','home_destination', 'name', 'person', 'ticket', 'title', 'tratamento', 'parch', 'sibsp', 'title_Master', 'title_Miss',  'title_Mrs',  'title_Tripulacao',  'title_Nobreza',  'embarked_C',  'embarked_Q',  'embarked_S' ], axis = 1) \nfull.head()","297eb61e":"full.info()","1e4e0e9d":"# Separando dados de treino e teste para inicialmente explorar a import\u00e2ncia de features, antes de drops\ntrain = full_bak[ :train_idx]\ntest = full_bak[test_idx: ]\n\nprint(test_idx)\nprint(train.shape)\nprint(test.shape)","be83a13d":"# converte survived novamente para int\ntrain.survived = train.survived.astype(int)\nprint(train.survived.shape)","a7814e55":"# cria X e y de treino\n\n# Coloca survived como target\nX_train= train.drop('survived', axis=1).values\ny_train= train.survived.values\n\n# obs: X_test n\u00e3o tem valores para \"survived\" : NaN\nX_test = test.drop('survived', axis=1).values\n\nprint(X_train.shape, X_test.shape, y_train.shape)","7e6627e9":"#model = RandomForestClassifier(n_estimators=100)\nmodel = GradientBoostingClassifier(n_estimators=250)\nmodel.fit( X_train, y_train)\ny_pred = model.predict( X_test )","0ff2250d":"features = pd.DataFrame()\nfeatures['feature'] = (train.drop('survived', axis=1)).columns\nfeatures['importance'] = model.feature_importances_\nfeatures.sort_values(by=['importance'], ascending=True, inplace=True)\nfeatures.set_index('feature', inplace=True)","4571a53f":"features.plot(kind='barh', figsize=(5,5))","0dd8b5cc":"# cria dados de treino e teste\n# lembrete: em full.bak temos mais features, que foram usadas na estimativa geral das suas import\u00e2ncias\n\ntrain = full[ :train_idx]\ntest = full[test_idx: ]\n\nprint(test_idx)\nprint(train.shape)\nprint(test.shape)","7d195ce5":"# converte survived novament epara int\ntrain.survived = train.survived.astype(int)\nprint(train.survived.shape)","02615690":"# cria X e y de treino\n\n# Coloca survived como target\nX_train= train.drop('survived', axis=1).values\ny_train= train.survived.values\n\n# obs: X_test n\u00e3o tem valores para \"survived\" : NaN\nX_test = test.drop('survived', axis=1).values\n\nprint(X_train.shape, X_test.shape, y_train.shape)","6319ee45":"# prepara\u00e7\u00e3o dos modeloss\nseed = 7\nmodels = []\n\nmodels.append(('Logistic Regression', LogisticRegression()))\nmodels.append(('Decision Tree', DecisionTreeClassifier()))\nmodels.append(('K-Nearest Neighbours (3)', KNeighborsClassifier(n_neighbors=3)))\nmodels.append(('K-Nearest Neighbours (7)', KNeighborsClassifier(n_neighbors=7)))\nmodels.append(('K-Nearest Neighbours (11)', KNeighborsClassifier(n_neighbors=11)))\nmodels.append(('Random Forest', RandomForestClassifier()))\nmodels.append(('Random Forest (10)', RandomForestClassifier(n_estimators=10)))\nmodels.append(('Random Forest (100)', RandomForestClassifier(n_estimators=100)))\nmodels.append(('Gaussian Na\u00efve Bayes', GaussianNB()))\nmodels.append(('Stochastic Gradient Decent (SGD)', SGDClassifier(max_iter=50)))\nmodels.append(('Linear SVC', LinearSVC()))\nmodels.append(('Perceptron (5)', Perceptron(max_iter=5)))\nmodels.append(('Perceptron (10)', Perceptron(max_iter=10)))\nmodels.append(('Perceptron (50)', Perceptron(max_iter=50)))\n\nmodels.append(('Support Vector Machines (SVM)', SVC()))\n\nmodels.append(('GradientBoostingClassifier (GBC)',GradientBoostingClassifier()))\nmodels.append(('GradientBoostingClassifier (GBC20)',GradientBoostingClassifier(n_estimators=20)))\nmodels.append(('GradientBoostingClassifier (GBC40)',GradientBoostingClassifier(n_estimators=40)))\nmodels.append(('GradientBoostingClassifier (GBC70)',GradientBoostingClassifier(n_estimators=70)))\nmodels.append(('GradientBoostingClassifier (GBC100)',GradientBoostingClassifier(n_estimators=100)))\nmodels.append(('GradientBoostingClassifier (GBC150)',GradientBoostingClassifier(n_estimators=150)))\nmodels.append(('GradientBoostingClassifier (GBC180)',GradientBoostingClassifier(n_estimators=180)))\nmodels.append(('GradientBoostingClassifier (GBC200)',GradientBoostingClassifier(n_estimators=200)))\nmodels.append(('GradientBoostingClassifier (GBC220)',GradientBoostingClassifier(n_estimators=220)))\nmodels.append(('GradientBoostingClassifier (GBC250)',GradientBoostingClassifier(n_estimators=250)))\nmodels.append(('GradientBoostingClassifier (GBC280)',GradientBoostingClassifier(n_estimators=280)))\nmodels.append(('GradientBoostingClassifier (GBC300)',GradientBoostingClassifier(n_estimators=300)))\n\n# avaliar um modelo por vez\nresults = []\nnames = []\nscores = []\nscoring = 'accuracy'\n\nfor name, model in models:\n    kfold = sklearn.model_selection.KFold(n_splits=10, shuffle=False, random_state=seed)\n    cv_results = sklearn.model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    scores.append(cv_results.mean())\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)\n\nresultsdf = pd.DataFrame({'Model': names, 'Score': scores})\nprint(\"\\n\")\nresultsdf = resultsdf.sort_values(by='Score', ascending=False)\nprint(resultsdf)\n","a2d1c4aa":"# boxplot para compara\u00e7\u00e3o dos algoritmos\nfig = plt.figure(figsize = (15, 8))\nfig.suptitle('Compara\u00e7\u00e3o dos algor\u00edtmos')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.xticks(rotation=70)\nplt.show()","fe7adf73":"train.describe()","94b57514":"# Seleciona um modelo para estimar a import\u00e2ncia, usando as features selecionadas\n#model = RandomForestClassifier(n_estimators=100)\nmodel = GradientBoostingClassifier(n_estimators=220)\nmodel.fit( X_train, y_train)\ny_pred = model.predict( X_test )","89d4f359":"features = pd.DataFrame()\nfeatures['feature'] = (train.drop('survived', axis=1)).columns\nfeatures['importance'] = model.feature_importances_\nfeatures.sort_values(by=['importance'], ascending=True, inplace=True)\nfeatures.set_index('feature', inplace=True)","601c881f":"features.plot(kind='barh', figsize=(5,5))","a38c8207":"model =  GradientBoostingClassifier(n_estimators=250)\nmodel.fit(X_train, y_train)\n\ny_test = model.predict( X_test )\ny_test.shape","97cf4835":"submissiondf = pd.DataFrame( { 'person': persons , 'survived': y_test } )\nsubmissiondf['survived'] = submissiondf['survived'].map({1: 'yes', 0: 'no'})\n\nprint(submissiondf.shape)\nprint(submissiondf.head())","eba9fc44":"submissiondf.to_csv( 'RG_titanic_sub_09a.csv' , index = False )","6d8808df":"# Tratamento dos dados","3327ae96":"# **Serpro Titanic**\n\nColunas dispon\u00edveis\nAs colunas neste conjunto de dados s\u00e3o:\n\n - person: Identifica\u00e7\u00e3o \u00fanica do passageiro no conjunto de dados\n - pclass: Classe econ\u00f4mica do passageiro (1: primeira, 2: segunda ou 3: terceira)\n - survived: Indica se o passageiro sobreviveu (yes) ou n\u00e3o (no) ao naufr\u00e1gio\n - name: Um campo rico em informa\u00e7\u00f5es, pois cont\u00e9m t\u00edtulos e nomes de fam\u00edlia\n - sex: Masculino (male) ou feminino (female)\n - age: Idade (em anos) - estimada caso esteja na forma xx.5\n - sibsp: N\u00famero de irm\u00e3os \/ c\u00f4njuges a bordo\n - parch: N\u00famero de pais \/ filhos a bordo\n - ticket: N\u00famero do bilhete\n - fare: Tarifa paga pelo passageiro (em libras esterlinas)\n - cabin: Localiza\u00e7\u00e3o da cabine no navio\n - embarked: Porto de embarque (C: Cherbourg, Q: Queenstown ou S: Southampton)\n - home_destination: Resid\u00eancia e destino do passageiro\n","d595db9f":"### Sele\u00e7\u00e3o das features \/ vari\u00e1veis a permanecerem no dataset","8c272942":"### Tratando valores ausentes das idades dos passageiros","a4cc4411":"### Unindo os conjuntos de treino e teste","0f36a9b8":"### Faz a transposi\u00e7\u00e3o da descri\u00e7\u00e3o do conjunto para outra forma de  visualiza\u00e7\u00e3o (.T)","d0422389":"### Import\u00e2ncia das features\n","48fcc96c":"### --------------------------------------------------------------------------------------\n\n### Carregamento de arquivos e prepara\u00e7\u00e3o de subconjuntos\n","3d3e1a2e":"### Tratando local de embarque - convertendo para num\u00e9rico","5fd4b50a":"## --------------------------------------------------------------------------------------\n","b506c803":"### --------------------------------------------------------------------------------------\n\n# Modelagem\n\n\n### Levantamento dos scores usando v\u00e1rios modelos","e712154f":"# Inicializa\u00e7\u00e3o","684a5e29":"### Trata t\u00edtulos de tratamento dos passageiros, agrupando em classes e mapeando eventuais redund\u00e2ncias lingu\u00edsticas","872341a4":"### Estimando a quantidade de membros da fam\u00edlia","2bd42096":"## --------------------------------------------------------------------------------------\n# Deployment\n \n### Formato de arquivo de submiss\u00e3o\nVoc\u00ea deve enviar um arquivo CSV com exatamente 437 entradas mais uma linha de cabe\u00e7alho (header). Seu envio mostrar\u00e1 um erro se voc\u00ea tiver linhas ou colunas diferentes do esperado.\n\nO arquivo deve ter exatamente 2 colunas:\n\nperson: Identifica\u00e7\u00e3o do passageiro, classificado em qualquer ordem\nsurvived: A respectiva previs\u00e3o: yes para sobreviventes, no para mortos","4bade8c6":"### Estimando a import\u00e2ncia das diversas features para um dado modelo\n","524886e7":"### Criando os datasets de treino e testes iniciais\n","581946f6":"### Criando os datasets treino, testes, etc\n","f27919e2":"### Treinamento usando um modelo selecionado\n","d75b0f5e":"### Mapeando para num\u00e9rico as classes sobrevivente e sexo (0\/1)","5a53d407":"### Para valores ausentes de tarifa usa mediana das tarifas da classe do passajeiro"}}