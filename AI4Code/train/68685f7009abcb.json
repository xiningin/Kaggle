{"cell_type":{"6643b957":"code","86a2c85b":"code","9b57dc38":"code","b626966b":"code","9c844378":"code","30cb8ddc":"code","cf7e667f":"code","15153756":"code","01c5b8f9":"code","66dacb92":"code","bdb67fc8":"code","d01d6604":"code","ba2e5423":"code","cfcad6e6":"markdown","045ed82b":"markdown","d696db6f":"markdown","a5b24ae9":"markdown","ba72da9b":"markdown","c3c69a2d":"markdown","45cfb38e":"markdown"},"source":{"6643b957":"# Import the appropriate Keras modules\nfrom keras import applications\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.applications.mobilenet import preprocess_input\nfrom tensorflow.python.keras.applications import ResNet50\nimport tensorflow as tf\n\n%matplotlib inline\n","86a2c85b":"import os\n\n# Set path variable to the directory where the data is located\npath = os.path.join('..', 'input', 'hello-world-deep-learning-siim', 'data')\n\n# Command line \"magic\" command to show directory contents\n!ls {path}\/*\/*\n","9b57dc38":"# set variables for paths to directories for training & validation data\ntrain_dir = os.path.join(path, 'train')\nval_dir = os.path.join(path, 'val')\n\n\n# we'll need to import additional modules to look at an example image\nimport numpy as np    # this is a standard convention\nfrom keras.preprocessing import image\nimport matplotlib.pyplot as plt    # also by convention\n\n# set the path to a chest radiograph, then load it and show\nimg_path = os.path.join(train_dir, 'chst\/chst33.png')\nimg = image.load_img(img_path, target_size=(229, 229))\nplt.imshow(img)\nplt.title('Example chest radiograph')\nplt.show()\n\n# set the path to an abdominal radiograph, then load it and show\nimg2_path = os.path.join(train_dir, 'abd\/abd1.png')\nimg2 = image.load_img(img2_path, target_size=(229, 229))\nplt.imshow(img2)\nplt.title(\"Example abdominal radiograph\")\nplt.show()\n","b626966b":"\n\nimage_size = 224 #The default input size for this model is 224x224.\nnb_train_samples = 65 # number of files in training set\nnum_of_test_samples = 10 # number of files in test set\nbatch_size = 8 #the model will take 8 random batches of files at a time during training\n\nEPOCHS = 50 #we will run this model for 50 epochs(1 epoch = whole dataset traversion during training)\nSTEPS = nb_train_samples \/\/ batch_size #the model will take 326 steps to complete per batch training","9c844378":"resnet_weights_path = '..\/input\/keras-pretrained-models\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\nnum_classes = 2 \nfrom tensorflow.python.keras.layers import Dense, GlobalMaxPooling2D\nmodel = tf.keras.Sequential()\nmodel.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\n\nmodel.layers[0].trainable = False\n# Unfreeze the model backbone before we train a little more\n#for layer in model.layers[10:]:\n#    layer.trainable = True\n'''\nfor layer in model.layers[:10]:\n    layer.trainable=False\nfor layer in model.layers[10:]:\n    layer.add(Dropout(0.7))\n    layer.trainable=True\n'''\n    \nfrom tensorflow.python.keras import optimizers\n\nadamopt = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08,decay=0.0)\n\n    \n\n    \nmodel.add(Dense(num_classes, activation='sigmoid'))\n\nmodel.compile(optimizer=adamopt, loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel.summary()","30cb8ddc":"## Specify the values for all arguments to data_generator_with_aug.\ndata_generator_with_aug = ImageDataGenerator(preprocessing_function=preprocess_input,\n                                             horizontal_flip = True,\n                                             width_shift_range = 0.2,\n                                             height_shift_range = 0.2,\n                                             shear_range = 0.2,\n                                             zoom_range = 0.2\n                                            )","cf7e667f":"data_generator_no_aug = ImageDataGenerator(preprocessing_function=preprocess_input            \n                                          )","15153756":"train_generator = data_generator_with_aug.flow_from_directory(\n       directory = train_dir,\n       target_size = (image_size, image_size),\n       batch_size = batch_size,\n       class_mode = 'categorical')\n\nvalidation_generator = data_generator_no_aug.flow_from_directory(\n       directory = val_dir,\n       target_size = (image_size, image_size), \n       class_mode = 'categorical')\n\n","01c5b8f9":"# Early stopping & checkpointing the best model in ..\/working dir & restoring that as our model for prediction\nfrom tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n\ncb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = 3)\ncb_checkpointer = ModelCheckpoint(filepath = '..\/working\/best.hdf5', monitor = 'val_loss', save_best_only = True, mode = 'auto')","66dacb92":"#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nhistory = model.fit_generator(\n       train_generator, # specify where model gets training data\n       epochs = EPOCHS,\n       steps_per_epoch=STEPS,\n       validation_data=validation_generator,\n      callbacks=[cb_checkpointer, cb_early_stopper]\n       ) # specify where model gets validation data","bdb67fc8":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\n\n\nscores = model.evaluate_generator(validation_generator) \nprint(\"validation Accuracy = \", scores[1])\n\n","d01d6604":"Y_pred = model.predict_generator(validation_generator, num_of_test_samples \/\/ batch_size+1)\ny_pred = np.argmax(Y_pred, axis=1)\nprint('Confusion Matrix')\nprint(confusion_matrix(validation_generator.classes, y_pred))\nprint('Classification Report')\ntarget_names = ['abdominal', 'chest']\nprint(classification_report(validation_generator.classes, y_pred, target_names=target_names))","ba2e5423":"print(history.history.keys())\n\nfig, ax = plt.subplots(2, 1)\nax[0].plot(history.history['acc'], 'orange', label='Training accuracy')\nax[0].plot(history.history['val_acc'], 'blue', label='Validation accuracy')\nax[1].plot(history.history['loss'], 'red', label='Training loss')\nax[1].plot(history.history['val_loss'], 'green', label='Validation loss')\nax[0].legend()\nax[1].legend()\nplt.show()","cfcad6e6":"As you can see, the `data` directory contains subdirectories `train`, `val` and `test`, which contain the *training*, *validation* and *test* data for our experiment. `train` and `val` contain subdirectories `abd` and `chst` containing abdominal and chest radiographs for each data set. There are 65 training images and 10 validation images with *balanced distributions* over our *target classes* (i.e. approximately equal numbers of abdominal and chest radiographs in each data set).","045ed82b":"# Transfer Learning in Medical Imaging(X-ray image)\n**_Note: If you like this kernel and\/or choose to fork it, please help us out by up-voting the kernel with the <kbd>^<\/kbd> button above._**\n[Note : The model is badly overfitted,if you can solve this model from high variance problem,then please provide your kernels link in the comment box and it will be highly appreciated]\n","d696db6f":"## Reference : https:\/\/www.kaggle.com\/wfwiggins203\/hello-world-for-deep-learning-siim","a5b24ae9":"## 3. Setting up our generators & selecting hyperparameters\nA neural network model consists of:\n- An **architecture** defining the structure of the connections between **layers** of **artificial neurons (_units_)** in the network\n    - *Within a layer*, units are NOT connected to each other (with some exceptions, not relevant to this module)\n    - The connections that define the architecture are between neurons in *different layers* of the network\n- The **weights** (*or* parameters) that determine the strength of those connections.\n\n","ba72da9b":"## 2. Taking a look at the data\nI've preloaded the data that we'll be using into this kernel. Let's take a look at the directory structure and contents, then create some variables to help us as we proceed.","c3c69a2d":"## 4. Creating the model with transfer learning\nWe'll employ a technique called **transfer learning** with the `resnet50` model, using weights obtained by **pretraining** the model on the **ImageNet** data set.","45cfb38e":"## 1. Loading Python modules\n"}}