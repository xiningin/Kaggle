{"cell_type":{"292606aa":"code","784cea61":"code","ac86009e":"code","5a01c4a7":"code","268d5047":"code","c86a4b13":"code","7ec40caa":"code","6bef9ca1":"code","a98ab080":"code","120138f4":"code","d00fae22":"code","ac4beac7":"code","d9e87a85":"code","3784d027":"code","4177ba85":"code","cda6a618":"code","eb1d4bc3":"code","9bbcfe9b":"code","b216e6b9":"code","08d5c3eb":"code","30c4fde6":"code","c7e993bd":"code","a20eba20":"code","c0758480":"code","c4d8d827":"code","51aad9ba":"code","4db1659c":"code","39f954a3":"code","3e57f0b3":"code","0f0ca23a":"code","da652953":"code","94bc9fda":"code","2935ca14":"markdown","18afc57f":"markdown","583753d7":"markdown","949f7f23":"markdown","a6b32209":"markdown","22df5a16":"markdown","ca2b5273":"markdown","20a83987":"markdown","52fe4dcd":"markdown","b83875be":"markdown","492e6116":"markdown","b1520ab0":"markdown","a7396488":"markdown","3bfd9076":"markdown","0b559128":"markdown","69b8f566":"markdown","364e47a0":"markdown","7be202e0":"markdown","40dba0e2":"markdown","fa88d77a":"markdown","e8287d18":"markdown","d53b2b9f":"markdown","46828ed3":"markdown","4c91ed81":"markdown","bd5aab82":"markdown","0ee1bbad":"markdown","fe28581f":"markdown","ec7b672d":"markdown","53b48d6c":"markdown","68270692":"markdown","5696fe4b":"markdown","2e72835d":"markdown","70c38136":"markdown","07da0af2":"markdown","7a61a820":"markdown","78e84af8":"markdown","f7689328":"markdown","3e637b09":"markdown","8319569e":"markdown","caaaae8a":"markdown","50105528":"markdown","11bb4f81":"markdown","a95dab23":"markdown","c63df418":"markdown","434dfe17":"markdown","609d7719":"markdown","751af94b":"markdown","b7370128":"markdown","911f0b45":"markdown"},"source":{"292606aa":"![ -d \/kaggle\/input\/release-2021-v1\/augeropendata ] && [ ! -d augeropendata ] && ln -s \/kaggle\/input\/release-2021-v1\/augeropendata augeropendata  # kaggle specific linking dataset to augeropendata directory","784cea61":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport datetime\n\nimport ipywidgets as widgets\nfrom ipywidgets import  interactive\n\n# Jupyter\/ IPython formatting\nfrom IPython.display import Math, Latex, display","ac86009e":"# Default values for plots\nplt.rcParams[\"figure.figsize\"] = [14, 9] # figure width and height\nplt.rcParams[\"font.size\"] = 20","5a01c4a7":"# Data loading, encapsulated to make it less installation and OS dependant\nimport os.path\nfrom zipfile import ZipFile\ndef AugerOpen(fdir, file):\n    \"\"\"\n    Loads a file from the auger open data release. Can be either in the local directory,\n    in the parent directory or in the augeropendata directory.\n    File is identified by it directory *fdir* and filename *file* and can be found in the directory\n    or in a zip file.\n    \"\"\"\n    for loc in [\".\", \"..\", \"augeropendata\", \"data\"]:\n        fname = os.path.join(loc, fdir, file)\n        if os.path.isfile(fname):\n            return open(fname)\n        zname=os.path.join(loc, fdir + \".zip\")\n        if os.path.isfile(zname):\n            with ZipFile(zname) as myzip:\n                return myzip.open(os.path.join(fdir, file))\n    raise FileNotFoundError(os.path.join(fdir, file))","268d5047":"df = pd.read_csv(AugerOpen(\"summary\", \"dataSummary.csv\"))","c86a4b13":"df.columns","7ec40caa":"df.head(10)","6bef9ca1":"df[df['multiEye'] == 1].head(10)","a98ab080":"df_unique = df.drop_duplicates('id')\ndf_unique.head(10)","120138f4":"n_events = len(df)\nn_columns = len(df.columns)\nn_unique = len(df_unique)\nn_duplicates = n_events - n_unique\nLatex(f'''The dataframe contains {n_events} rows and {n_columns} columns.\n    There are {n_unique} different events, of which {n_duplicates} are multi-eye events.''')","d00fae22":"event_id = df.id\n\n# extract date and time from id using integer division \/\/ and modulus\nyear_factor = 10**10\nday_factor =  10**7\nday_modulus = 10**3\nsecond_factor = 100\nsecond_modulus = 10**5\n\nyears = event_id \/\/ year_factor\ndays = event_id \/\/ day_factor % day_modulus\nseconds = event_id \/\/ second_factor % second_modulus\nyears = years + 2000\n\n# generate a 'datetime' variable\n# NB: the Auger day starts at noon UTC\ndate = [datetime.datetime(year, 1, 1, 12, tzinfo=datetime.timezone.utc) + datetime.timedelta(days=day - 1, seconds=second - 1) \n        for year, day, second in zip(years, days, seconds)]\n# add the column 'date' to the dataframe\ndf['date']=date","ac4beac7":"df[['id', 'date']] ","d9e87a85":"gps0 = datetime.datetime(1980, 1, 6, tzinfo=datetime.timezone.utc) # The start of the gps counting of seconds","3784d027":"date_gps = gps0 + datetime.timedelta(seconds=int(df.gpstime.iloc[0]))\nleapseconds = (date_gps - df.iloc[0]['date']).total_seconds() # the difference is the number of leap seconds \n\ndisplay(Latex(f'gpstime:  {int(df.gpstime.iloc[0])}'))\ndisplay(Latex(f'date-time from gps: {date_gps}'))\ndisplay(Latex(f'date-time from id: {df.date.iloc[0]}'))\ndisplay(Latex(f'Difference (leapseconds):  {int(leapseconds)}'))\n","4177ba85":"#extract sd and hybrid subsets - test for NaN to see if field is present\n\ndf_unique = df.drop_duplicates('id') # re-calculate, since we added the date field\n\ndf_sd = df_unique[df_unique.sd_energy.notna()]\n#df_sd = df_unique[df_unique.sd_energy>2.5]  #this statement excludes events below full efficiency of the SD\n\ndf_fd = df[df.fd_totalEnergy.notna()]\n\n\ndisplay(Latex(f'Number of SD events:  {len(df_sd)}'))\ndisplay(Latex(f'Number of hybrid events:  {len(df_fd.groupby(\"id\"))}'))","cda6a618":"plt.hist(df_sd.sd_energy, bins=100)\nplt.yscale('log')\nplt.xlabel('$E_{SD}$ [EeV]')\nplt.ylabel('entries')\nplt.show()","eb1d4bc3":"plt.figure(figsize=(15, 5)) \nplt.subplot(121)\nplt.hist(df_sd.sd_theta, bins=60)\nplt.yscale('log')\nplt.ylabel('entries')\nplt.xlabel(r'$\\theta$ [deg]')\n\nplt.subplot(122)\nplt.hist(df_sd.sd_phi,bins=360)\nplt.xlabel(r'$\\phi$ [deg]')\nplt.ylabel('entries')\nplt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.25, wspace=0.35)\nplt.show()","9bbcfe9b":"#calculate mean values of the variable sd_theta, its standard error and the number of events per year   \ntheta_mean   = df_sd.groupby([(df_sd.date.dt.year)])['sd_theta'].mean()\ntheta_counts = df_sd.groupby([(df_sd.date.dt.year)])['sd_theta'].count()\ntheta_std    = df_sd.groupby([(df_sd.date.dt.year)])['sd_theta'].std()\ntheta_err    = theta_std\/np.sqrt(theta_counts)\n\n#calculate the mean value of the variable sd_theta for all events to plot the corresponding line\nline_x = [2004, 2018] \nline_y = [df_sd.sd_theta.mean(), df_sd.sd_theta.mean()] \n\nplt.errorbar(theta_mean.index, theta_mean.values, yerr=theta_err, linestyle='None', marker='o')\nplt.xlabel('year') \nplt.ylabel(r'$\\langle\\Theta\\rangle$ [deg]') \nplt.plot(line_x,line_y, c='red', label='mean value', linestyle='dotted') \nplt.ylim(34, 40)    \nplt.legend() \n\nplt.grid()\nplt.show()","b216e6b9":"#first count how many days are in each month and year\ndict_date = {'year': df_sd.date.dt.year, 'month': df_sd.date.dt.month, 'day': df_sd.date.dt.day}\ndf_date = pd.DataFrame(dict_date)\ndf_date = df_date.drop_duplicates()\ncounts_month_days = df_date.groupby([(df_date.year), (df_date.month)])['day'].count() #count days in each month\ncounts_year_days = df_date.groupby([(df_date.year)])['day'].count() #count days in each year\n\n#count the number of events per day, month, and year (you can the same calculation  using anyother variable)\ncounts_day = df_sd.groupby([(df_sd.date.dt.year), (df_sd.date.dt.month), (df_sd.date.dt.day)])['sd_energy'].count()\ncounts_month = df_sd.groupby([(df_sd.date.dt.year), (df_sd.date.dt.month)])['sd_energy'].count()\ncounts_year = df_sd.groupby([(df_sd.date.dt.year)])['sd_energy'].count()\n\n#the following instructons are useful to uniformize the x axis of the plots\nx_day = [datetime.datetime(year, month, day) for year, month, day in zip([item[0] for item in counts_day.index.values], \n                                                                         [item[1] for item in counts_day.index.values],\n                                                                         [item[2] for item in counts_day.index.values])]\nx_month = [datetime.datetime(year, month, 1) for year, month  in zip([item[0] for item in counts_month.index.values],\n                                                                     [item[1] for item in counts_month.index.values])]\nx_year = [datetime.datetime(year, 1, 1) for year in counts_year.index.values]\n\n\n#plot the day-normalized trends\nplt.plot(x_day, counts_day.values, linestyle='None', marker='.', markersize=1, label='daily')\nplt.plot(x_month, counts_month.values\/counts_month_days, label='monthly averaged')\nplt.plot(x_year, counts_year.values\/counts_year_days, label='yearly averaged')\nplt.legend()\nplt.title('Events per day')\nplt.xlabel('year')\nplt.ylabel('counts')\nplt.show()","08d5c3eb":"gps_to_unix0 = 315964782 # the difference between unix timestamps and GPS seconds at the beginning of the GPS epoch\n\ngps    = df_fd.gpstime\nxmax   = df_fd.fd_xmax\n\ndate_gps=[datetime.datetime.utcfromtimestamp(i + gps_to_unix0) for i in gps]\nframe = { 'date': date_gps, 'xmax': xmax} \ndataframe=pd.DataFrame(frame)\ndataframe['year'] = pd.DatetimeIndex(dataframe['date']).year\ndataframe['month'] = pd.DatetimeIndex(dataframe['date']).month\n\nmean_xmax=dataframe.groupby([(dataframe.year)])['xmax'].mean()\nsigma_xmax=dataframe.groupby([(dataframe.year)])['xmax'].std()\ncounts_xmax=dataframe.groupby([(dataframe.year)])['xmax'].count()\n\nmean_xmax.plot(ylabel=r'$\\langle X_{max} \\rangle$ [g\/cm${}^2$]', marker='o', ylim=[670, 800], \n               linestyle='none', yerr=sigma_xmax\/np.sqrt(counts_xmax))\nplt.grid()\nplt.show()","30c4fde6":"sdmap = pd.read_csv(AugerOpen(\"auxiliary\", \"sdMap.csv\"))\n\ndef augerArray(t):\n    timeMap = sdmap.loc[(sdmap['start']<t) & ((sdmap['stop']>t) | (sdmap['stop']==1))]\n    \n    display(Latex(f'Number of stations: {len(timeMap)} '))\n    display(Latex(f'Date: {datetime.datetime.utcfromtimestamp(t + gps_to_unix0).date()} '))\n\n    plt.figure(figsize=(12, 12))\n    plt.scatter(timeMap.easting, timeMap.northing, s=20)\n    plt.xlim(439000, 510000)\n    plt.ylim(6065000, 6140000)\n    plt.xlabel('UTM Easting [m]')\n    plt.ylabel('UTM Northing [m]')\n    \n    plt.show()\ninteractive(augerArray, t=widgets.IntSlider(description='gpstime ',value=1241890123, max=1241890123, min=735350400, step=1))","c7e993bd":"plt.scatter(df[\"sd_x\"], df[\"sd_y\"], c=df[\"sd_z\"], linestyle=\"None\", marker='.', cmap='brg')\nplt.axis('off')\nclb = plt.colorbar()\nclb.ax.set_title('Altitude [m]')\nplt.show()","a20eba20":"#define the UTM coordinate of FD sites\nLL= [6071871.5, 459208.3, 1416.2] # Norhing  Easting Altitude\nLM= [6094570.2, 498903.7, 1416.4]\nLA= [6134058.4, 480743.1, 1476.7]\nCO= [6114140.0, 445343.8, 1712.3]\n\n\nplt.figure(figsize=(10, 10))\n\nplt.scatter(LL[1], LL[0], marker='^', s=500, label='LL')\nplt.scatter(LM[1], LM[0], marker='^', s=500, label='LM')\nplt.scatter(LA[1], LA[0], marker='^', s=500, label='LA')\nplt.scatter(CO[1], CO[0], marker='^', s=500, label='CO')\nplt.annotate('Los Leones', xy=(LL[1]-4000, LL[0]-4000))\nplt.annotate('Los Morados', xy=(LM[1]-4000, LM[0]-5000))\nplt.annotate('Loma Amarilla', xy=(LA[1]-4000, LA[0]+4000))\nplt.annotate('Coihueco', xy=(CO[1]-8500, CO[0]+4000))\n\nplt.scatter(sdmap[\"easting\"], sdmap[\"northing\"], c='grey', alpha=0.5)\nplt.scatter(df[\"fd_easting\"], df[\"fd_northing\"], marker='.', c='blue')\nplt.axis('off')\nplt.show()","c0758480":"log_en = np.log10(df_sd.sd_energy*1e18)\n\ndef update(emin, emax, angle, alpha):    \n\n    lat = df_sd.sd_b[log_en.between(emin, emax)].values\n    longit = df_sd.sd_l[log_en.between(emin, emax)].values\n   \n    en = log_en[log_en.between(emin, emax)]\n \n    display(Latex(f'{emin} < Energy [Log(E\/eV)] <  {emax}'))\n    display(Latex(f'Angular resolution = {angle}\u00b0'))\n    display(Latex(f'Numbers of events = {len(en)}'))\n\n    lat_rad = np.radians(lat)\n    longit_tmp = []\n    for lon in longit:\n        if(lon < 180):\n            longit_tmp.append(lon)\n        else:\n            longit_tmp.append(lon - 360)\n    longit_rad =  np.asarray(np.radians(longit_tmp))\n\n    delta_longit = 360\/angle\n    delta_lat = 180\/angle\n    bins = [int(delta_longit), int(delta_lat)]\n\n    hh, locx, locy = np.histogram2d(longit_rad, lat_rad, bins=bins)\n    z = np.array([hh[np.argmax(a<=locx[1:]), np.argmax(b<=locy[1:])] for a, b in zip(longit_rad, lat_rad)])\n    idx = z.argsort() \n    x2, y2, z2 = longit_rad[idx], lat_rad[idx], z[idx] \n    fig = plt.figure(figsize=(14, 14)) \n    ax = fig.add_subplot(111, projection=\"aitoff\")\n    ax = plt.scatter(x2, y2, c=z2,  s=8, alpha=alpha) \n\n    plt.grid(True)\n    plt.show()\n    \nw = interactive(update, emin=widgets.FloatSlider(description='En. min. ',value=18.4, max=21, min=18.4, step=0.1), \n                emax=widgets.FloatSlider(description='En. max. ', value=19.5, max=21, min=18.4, step=0.1),\n                angle=widgets.IntSlider(description='Ang. Res. ', value=10, max=45, min=5, step=1),\n                alpha=widgets.FloatSlider(description='Opacity', value=0.3, max=1., min=0.1, step=0.1))\ndisplay(w)","c4d8d827":"plt.scatter(df_fd.fd_totalEnergy, df_fd.fd_dEdXmax)\nplt.xlabel('FD Energy [EeV]')\nplt.ylabel('dEdXmax [$PeV(g\/cm^2)$]')\nplt.grid()","51aad9ba":"#Select a subset of events for each analysis:\n\ndf_xmax = df_fd[df_fd.fd_hdXmaxEye==1]\ndf_spectrum = df_fd[df_fd.fd_hdSpectrumEye==1]\ndf_calib = df_fd[df_fd.fd_hdCalibEye==1]","4db1659c":"#Plot the value of Xmax as a function of the energy for the different sub-samples.\nplt.plot(np.log10(df_xmax.fd_totalEnergy)+18, df_xmax.fd_xmax, markersize=4, c='r', marker='o' ,linestyle='None', label='hdXmax') \nplt.plot(np.log10(df_spectrum.fd_totalEnergy)+18, df_spectrum.fd_xmax, markersize=3, c='b', marker='o' ,linestyle='None', label='hdSpectrum') \nplt.plot(np.log10(df_calib.fd_totalEnergy)+18, df_calib.fd_xmax, markersize=2, c='k', marker='o' ,linestyle='None', label='hdCalib') \nplt.ylabel('Xmax $[g\/cm^2]$')\nplt.xlabel('$Log_{10}$(E\/eV)')\nplt.legend()\nplt.grid()\nplt.show()","39f954a3":"sdmap = pd.read_csv(AugerOpen(\"auxiliary\", \"sdMap.csv\"))\n\ndisplay(sdmap.head(10))","3e57f0b3":"pixelmap = pd.read_csv(AugerOpen(\"auxiliary\", \"fdPixelMap.csv\"))\n\ndisplay(pixelmap.head(10))","0f0ca23a":"exposure = pd.read_csv(AugerOpen(\"auxiliary\", \"sdExposure.csv\"))\n\ndisplay(exposure.head(10))","da652953":"acceptance = pd.read_csv(AugerOpen(\"auxiliary\", \"fdXmaxAcceptance.csv\"))\n\ndisplay(acceptance.head(10))","94bc9fda":"resolution = pd.read_csv(AugerOpen(\"auxiliary\", \"fdXmaxResolution.csv\"))\n\ndisplay(resolution.head(10))","2935ca14":"Get multi-eye events:","18afc57f":"## Plot a variable distribution","583753d7":"Correlation between the FD reconstructed energy and the maximum energy deposit.\n","949f7f23":"## How to read auxiliary files ","a6b32209":"Compare the gps seconds in an event to the time difference between the event timestamp built from the event `id` and the beginning of the GPS time. We notice a small difference, since the system time does not take leap seconds into account, which occurred between the beginning of the GPS counting on January 6, 1980 at 0:00 UTC, and the date under consideration. The number difference in 2020 is 18 seconds. In 2004, the difference was 13 seconds. ","22df5a16":"## Correlation plots","ca2b5273":"Let's look at the number of unique and of duplicate event `id`s. A duplicate event `id` indicates a multi-eye event:","20a83987":"In the following example you can calculate the mean value of an observable, in this case the zenith angle, in a time period (year) and plot its trend.","52fe4dcd":"### sdMap.csv","b83875be":"This file contains the value of the integrated exposure of the surface detector at the time\nof each SD reconstructed event with energy > 2.5 EeV\n\n    gpstime: GPS \n    sd_exposure:  value of the exposure at the corresponding GPS normalized to 10%\n    sd_exposure_all:  value of the exposure at the corresponding GPS","492e6116":"![PierreAugerObservatoryLogo.jpg](attachment:PierreAugerObservatoryLogo.jpg)\n\n# Tutorial: how to read the summary files\n\n<i>Notebook released together with the Pierre Auger Observatory Open Data release 2021 (<a href=\"https:\/\/doi.org\/10.5281\/zenodo.4487613\">DOI 10.5281\/zenodo.4487613<\/a>). More information at the <a href=\"https:\/\/www.auger.org\/opendata\/\">Auger open data website<\/a>.<\/i>","b1520ab0":"Plot the map of the arrival direction of SD events in the Galactic coordinate system (Galactic longitude and latitude). \nThis example is meant to illustrate how to build a sky-map in Galactic coordinates and does not represent an analysis of the arrival direction of the SD events. Such analysis is available in the notebook \"The UHECR sky\"","a7396488":"Hybrid events contain some flags that indicate the analyses they are used for: 'fd_hdXmaxEye' , 'fd_hdSpectrumEye', 'fd_hdCalibEye'.\n","3bfd9076":"The FD-related \"fdXmaxAcceptance.csv\" file is a CSV version of the \nTable II in Appendix B of [Phys. Rev. D 90, 122005 (2014)](https:\/\/journals.aps.org\/prd\/abstract\/10.1103\/PhysRevD.90.122005), ([arXiv](https:\/\/arxiv.org\/pdf\/1409.4809.pdf)), and contains the energy-dependent properties of the acceptance of FD-reconstructed Xmax.\n\n    energyBin: index of energy bin\n    lgMinEnergy: start of energy bin [log10(E\/eV]\n    lgMaxEnergy: end of energy bin [log10(E\/eV]\n    Xacc1: the Xmax value below which acceptance effects become relevant [g\/cm2]\n    Xacc1err: statistical error of former [g\/cm2]\n    Xacc2: the Xmax value above which acceptance effects become relevant [g\/cm2]\n    Xacc2err:  statistical error of former [g\/cm2]\n    lambda1: exponential slope of acceptance for Xmax<Xacc1 [g\/cm2]\n    lambda1err:  statistical error of former [g\/cm2]\n    lambda2: exponential slope of acceptance for Xmax>Xacc2 [g\/cm2]\n    lambda2err: statistical error of former [g\/cm2]","0b559128":"## Energy trend","69b8f566":"Plot the map of the array using the core position at the ground of SD events in site coordinate system:","364e47a0":"List the fields (columns) of the dataframe:","7be202e0":"In the following example you can compare the daily number of SD reconstructed events to the monthly-averaged and yearly-averaged rate.","40dba0e2":"A row in the dataframe collects the reconstruction values of an event. \nIf an event is a _multi-eye Hybrid_, its row (with the same id) is duplicated and each one contains the reconstruction values of one _eye_, with the values for the SD repeated.\nIn *golden-hybrid* events, all fields are filled. In _SD only_ or _brass-hybrid_ events some fields are empty (NaN).","fa88d77a":"## Maps","e8287d18":"### fdPixelMap.csv","d53b2b9f":"If you want to plot two histograms in the same figure, you can use the method 'subplots'.\nIn the following example, you can find the distributions of zenith and azimuth angles for SD-reconstructed events.","46828ed3":"Import some standard python libraries that \ncontain basic functions used along the notebook:","4c91ed81":"### sdExposure.csv","bd5aab82":"Print the 'id' list and the corresponding date:","0ee1bbad":"Get unique event (for SD analysis):","fe28581f":"This is the kaggle version of a Pierre Auger Observatory Open Data notebook. You can run it by clicking on \"Copy and Edit\" in the top right corner.","ec7b672d":"Plot the map of the array using the UTM coordinates of the stations: using the interactive slider you can see the station-deployment process:","53b48d6c":"This file contains information about the position of a pixel in the FD telescopes and its pointing direction:\n\n    pixel:  identification number of the pixel[0-2639]\n    eye: identification number of the FD site [1-4]\n    pixelTel: identification number of the pixel in an FD telescope[1-440] \n    tel: identification number of the telescope [1-6]\n    elevation,azimuth: pointing direction of the pixel [deg]\n    col,row: number of column [1-20] and row [1-22] of the pixel in the telescope\n","68270692":"In the following examples the correlation between some observables from the hybrid dataset is shown.","5696fe4b":"## Select SD and hybrid subsets","2e72835d":"The event identification number is a 12-digit number:\n\nYYDDDSSSSSXX\n\n- YY : last 2 digits of year\n- DDD : day number between 1 and 366\n- SSSSS: Second of the current DAY between 0 and 86399\n- XX : order of the event at the current second\n","70c38136":"The FD-related  \"fdXmaxResolution.csv\" file is a CSV version of the \nTable III in Appendix B of [Phys. Rev. D 90, 122005 (2014)](https:\/\/journals.aps.org\/prd\/abstract\/10.1103\/PhysRevD.90.122005), ([arXiv](https:\/\/arxiv.org\/pdf\/1409.4809.pdf)), and contains the energy-dependent properties of the resolution of FD-reconstructed Xmax.\n\n    energyBin: index of energy bin\n    lgMinEnergy: start of energy bin [log10(E\/eV)]\n    lgMaxEnergy: end of energy bin [log10(E\/eV)]\n    sigma1: width of first Gaussian [g\/cm^2]\n    sigma1Err: statistical error of former [g\/cm^2]\n    sigma2: width of second Gaussian [g\/cm^2]\n    sigma2Err: statistical error of former [g\/cm^2]\n    f: relative weight between two Gaussians [1]","07da0af2":"## Temporal trend of an observable","7a61a820":"To plot an histogram use the method 'hist' from the library 'matplotlib.pyplot'.\nIn the following example, you can plot the distribution of the energy obtained from the SD reconstruction.","78e84af8":"In the following example you can calculate the mean Xmax value per year. In this example we use the variable fd_gpstime as temporal reference.","f7689328":"### fdXmaxAcceptance.csv","3e637b09":"The following example shows the Xmax as a function of energy for the different dataset","8319569e":"### fdXmaxResolution.csv","caaaae8a":"This file contains the position in UTC coordinate system of all stations of the surface detector and time period of activity:\n\n    id: identification number of the station\n    northing,easting,altitude: UTC coordinates\n    start: GPS time of the first event detected by the station\n    stop: GPS time of the last event detected by the station. The value is 1 if the station is still in operation","50105528":"Plot the map of the array using stations position (grey dots) and the core position at the ground of hybrid  events (blue dots) in UTM coordinate system.","11bb4f81":"As you can see, the energy-threshold is different for the different  analyses.","a95dab23":"A preview of the dataframe content:","c63df418":"In this example the variable `event_id` is initialized with the content of the field `id` in the dataframe, then it is converted in a `datetime` variable (UTC) and added to the dataframe as a new column called `date`.","434dfe17":"Upload the summary file as a pandas dataframe:","609d7719":"The aim of this notebook is to give basic knowledges of data handling with python in a step-by-step way.","751af94b":"The field `sd_energy` represents the SD reconstructed energy. Then we can use the condition \"`sd_energy` is not NaN\" to select reconstructed SD events.\nTo select only events where the efficiency of the SD is close to 100%, we have to require that the event energy is greater than 2.5 EeV.\n\nThe field `fd_totalEnergy` represents the total energy reconstructed in hybrid events.\nWe can use the condition \"`fd_totalEnergy` is not NaN\" to select reconstructed hybrid events.","b7370128":"## Extract date-time information from the event\n\n### Date from the event `id`","911f0b45":"### GPS time conversion"}}