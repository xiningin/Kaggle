{"cell_type":{"d15d9ce5":"code","2f4d3a1f":"code","9338d1d1":"code","add77d75":"code","319bc063":"code","6ad2b84c":"code","31272335":"code","dc1f167e":"code","a7b4d0af":"code","88e8a9de":"code","69135ab5":"code","f4bb4e7c":"code","0ab47de4":"code","7282cb7f":"code","8d205fe3":"code","17e24c63":"code","c7da9458":"code","d6908958":"code","3b69e31b":"code","136af0e3":"code","adcaa064":"code","32cb2615":"code","408e94b3":"code","3f05d638":"code","7adf6c86":"code","e86b2e55":"code","e7123de6":"code","11746e05":"code","775d0869":"code","80c5c66c":"code","171acb5f":"code","ed449375":"code","ad0f6d73":"code","aa8a2340":"code","747715b5":"code","57f8f7ff":"code","beec8e81":"code","999c0987":"code","036aa15f":"code","ab063df2":"code","14439cb8":"code","b6b66369":"code","1de2ee7d":"code","32dc6bf4":"code","67e32962":"code","6f97092c":"code","9ca6b40d":"code","53af2266":"code","d03b078c":"code","b4f329e7":"code","8056d6e7":"code","da028822":"code","4d86ca56":"code","17166f3e":"code","17341000":"code","975d3cf8":"code","05e8ca4b":"code","5a6ced0c":"code","3b089231":"code","135f2620":"code","32364554":"code","5a459b4a":"code","fde5eacc":"code","e12e690f":"code","e845ea99":"code","84b08e17":"code","3284fb4e":"code","2d54d51d":"code","66a623e0":"code","40c45da7":"code","3794a7ff":"code","34c572cb":"code","803534ec":"code","edb570fe":"code","f8f2c9e0":"code","9e11fadd":"code","c784e47b":"code","4eace2e9":"code","9ada9d14":"code","888aaeed":"code","3df65055":"code","51d3ff25":"code","74f89e2c":"code","42848acc":"code","b7cab87e":"code","c193c43e":"code","42081c33":"code","65d3632c":"code","08fd7255":"code","3a3c7293":"code","b7860dc3":"code","4a60f37d":"code","3594ec30":"code","40668625":"code","a3b65a55":"code","905a41a8":"code","db3c5ac6":"code","23f921a5":"code","cc9eabd1":"code","d6b5d3b6":"code","7256b0c4":"code","ce6539ce":"code","e6f47120":"code","7c1c1e44":"code","e8b2624a":"code","4866cc4a":"code","dd02e307":"code","68b5c2a3":"code","0436333e":"code","bfc271a1":"code","1cd89fc1":"code","5877dfd3":"code","40cbfbfe":"code","b536cde8":"code","dca72eea":"code","1775fc47":"code","f4ba8089":"code","b176b748":"code","d48ef8d2":"code","a8654579":"code","5d1ee7cb":"code","ce2a74d2":"code","2b69ed8c":"code","c89bc5e2":"code","bae60144":"code","0fe4fc69":"code","89cdee67":"markdown","46c860ac":"markdown","40a3ff13":"markdown","272879a0":"markdown","d76f1af4":"markdown","f0d46719":"markdown","1eda0152":"markdown","ba50fc5c":"markdown","da0a2d5b":"markdown","56f60392":"markdown","4a8f821f":"markdown","c1c7e1df":"markdown","725616d3":"markdown","25fd88cb":"markdown","e8b11811":"markdown","e2e1e185":"markdown","5f998d73":"markdown","5d2962fe":"markdown","3b2c9ee3":"markdown","26a2c4e2":"markdown"},"source":{"d15d9ce5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","2f4d3a1f":"\nimport pandas as pd\ndf = pd.read_csv(\"\/kaggle\/input\/Advertising.csv\")\ndf = df.iloc[:,1:len(df)]\ndf.head()","9338d1d1":"df.info","add77d75":"import seaborn as sns\nsns.jointplot(x=\"TV\", y=\"sales\", data=df, kind=\"reg\");","319bc063":"from sklearn.linear_model import LinearRegression","6ad2b84c":"X = df[[\"TV\"]]\nX.head()","31272335":"y = df[[\"sales\"]]\ny.head()","dc1f167e":"reg = LinearRegression()\nmodel = reg.fit(X,y)\nmodel","a7b4d0af":"#Let's learn the model\nstr(model)","88e8a9de":"dir(model)","69135ab5":"#beta 0 (n) in basic linear regression formul(mx+n)\nmodel.intercept_  ","f4bb4e7c":"#beta 1 (m) in basic linear regression formul(mx+n)\nmodel.coef_","0ab47de4":"#r2 \n#Percentage of change in dependent variable explained by independent variables\nmodel.score(X,y)\n#The change in the independent variable is about 60 percent explained.","7282cb7f":"#guess\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ng = sns.regplot(df[\"TV\"],df[\"sales\"], ci=None, scatter_kws= {\"color\":\"r\",\"s\":9})\n\n#set table\ng.set_title(\"Models: Sales = 7.03 + TV * 0.05\")  \ng.set_ylabel(\"Sales Number\")\ng.set_xlabel(\"TV expenditures\")\n\nplt.xlim(-10,310)\nplt.ylim(bottom=0);","8d205fe3":"#Real Value \n7.03+ 0.05*165","17e24c63":"#Predict Value\nmodel.predict([[165]])","c7da9458":"new_data = [[5],[150],[300],[450]]","d6908958":"model.predict(new_data)","3b69e31b":"#Expected 2D array, got 1D array instead\n#Value Error expected : model.predict([500])\nmodel.predict([[500]])\n#predict : ~30","136af0e3":"y.head()","adcaa064":"y.head()","32cb2615":"X.head()","408e94b3":"model.predict(X)[0:6]\n","3f05d638":"real_y = y[0:10]","7adf6c86":"predict_y = pd.DataFrame(model.predict(X)[0:10])","e86b2e55":"errors = pd.concat([real_y,predict_y], axis=1)\nerrors.columns = [\"real_y\",\"predict_y\"]\nerrors","e7123de6":"errors[\"error\"] = errors[\"real_y\"] - errors[\"predict_y\"]\nerrors","11746e05":"errors[\"mean_squared\"] = errors[\"error\"]**2","775d0869":"errors","80c5c66c":"import numpy as np\nMSE = np.mean(errors[\"mean_squared\"])\nprint(\"MSE : \", MSE)","171acb5f":"#Model\nimport numpy as np\nimport pandas as pd\ndf = pd.read_csv(\"\/kaggle\/input\/Advertising.csv\")\ndf = df.iloc[:,1:len(df)]\ndf.head()","ed449375":"X = df.drop(\"sales\",axis=1)\ny = df[[\"sales\"]]","ad0f6d73":"y.head()","aa8a2340":"X.head()","747715b5":"#Model : wtih Sklearn \nfrom sklearn.linear_model import LinearRegression\nlm = LinearRegression()","57f8f7ff":"model = lm.fit(X, y)","beec8e81":"# mx+n --> intercept = n\nmodel.intercept_","999c0987":"#mx+n --> coef = m\nmodel.coef_","036aa15f":"2.94 + (30 * 0.04) + (10 * 0.19) -(40 * 0.001)","ab063df2":"new_data = [[30],[10],[50]]","14439cb8":"import pandas as pd\nnew_data = pd.DataFrame(new_data).T\nnew_data","b6b66369":"model.predict(new_data)","1de2ee7d":"from sklearn.metrics import mean_squared_error","32dc6bf4":"y.head()","67e32962":"model.predict(X)[0:10]","6f97092c":"MSE = mean_squared_error(y,model.predict(X))\nMSE","9ca6b40d":"import numpy as np\nRMSE = np.sqrt(MSE)\nRMSE","53af2266":"X.head()","d03b078c":"y.head()","b4f329e7":"from sklearn.model_selection import train_test_split","8056d6e7":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state =99)","da028822":"#X_test.ndim\nX_test.shape","4d86ca56":"X_train.shape","17166f3e":"X_train.head()","17341000":"y_train.head()","975d3cf8":"y_test.head()","05e8ca4b":"lm = LinearRegression()\nmodel = lm.fit(X_train, y_train)","5a6ced0c":"#Error train value\ny_predict_train = model.predict(X_train)\nnp.sqrt(mean_squared_error(y_train,y_predict_train))","3b089231":"#Error test value\ny_predict_test = model.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_predict_test))","135f2620":"from sklearn.model_selection import cross_val_score","32364554":"model","5a459b4a":"# cv mse\ncross_val_score(model, X_train, y_train, cv=10, scoring = \"neg_mean_squared_error\")","fde5eacc":"np.mean(-cross_val_score(model, X_train, y_train, cv=10, scoring = \"neg_mean_squared_error\"))","e12e690f":"# cv root mse\nimport numpy as np\nRMSE = np.sqrt(np.mean(-cross_val_score(model, X_train, y_train, cv=10, scoring = \"neg_mean_squared_error\")))\nRMSE","e845ea99":"P = np.sqrt(np.mean(-cross_val_score(model, X, y, cv=10, scoring = \"neg_mean_squared_error\")))","84b08e17":"error =  P - RMSE \nerror","3284fb4e":"import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import RidgeCV","2d54d51d":"#Data Set\ndf = pd.read_csv(\"\/kaggle\/input\/Hitters.csv\")\ndf = df.dropna()\n\ndms = pd.get_dummies(df[['League','Division','NewLeague']])\n\ny = df[\"Salary\"]\nX_ = df.drop(['Salary','League','Division','NewLeague'], axis=1).astype('float64')\nX = pd.concat([X_, dms[['League_N','Division_W','NewLeague_N']]],axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X,\n                                                   y,\n                                                   test_size=0.25,\n                                                    random_state=42)","66a623e0":"df.head()","40c45da7":"df.shape","3794a7ff":"ridge_model = Ridge(alpha = 5).fit(X_train, y_train)","34c572cb":"ridge_model","803534ec":"ridge_model.coef_","edb570fe":"ridge_model.intercept_","f8f2c9e0":"# generating random numbers (from 10 to 2)\nnp.linspace(10,2,100)","9e11fadd":"lambdas = 10** np.linspace(10,2,100)*0.5\nlambdas","c784e47b":"ridge_model = Ridge()\nfactor = []\n\nfor i in lambdas:\n    ridge_model.set_params(alpha=i)\n    ridge_model.fit(X_train, y_train)\n    factor.append(ridge_model.coef_)","4eace2e9":"ax = plt.gca()\nax.plot(lambdas,factor)\nax.set_xscale(\"log\")","9ada9d14":"ridge_model = Ridge().fit(X_train, y_train)\ny_pred = ridge_model.predict(X_train)","888aaeed":"y_train[0:10]","3df65055":"y_pred[0:10]","51d3ff25":"RMSE = np.sqrt(mean_squared_error(y_train, y_pred))  \nRMSE","74f89e2c":"#cv rmse\nfrom sklearn.model_selection import cross_val_score \nnp.sqrt(np.mean(-cross_val_score(ridge_model, X_train, y_train, cv=10, scoring = \"neg_mean_squared_error\")))","42848acc":"#test eror\ny_pred = ridge_model.predict(X_test)\nRMSE = np.sqrt(mean_squared_error(y_test, y_pred))  \nRMSE","b7cab87e":"ridge_model= Ridge(alpha=1).fit(X_train, y_train)\ny_pred = ridge_model.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_pred))","c193c43e":"np.random.randint(0,1000,100)","42081c33":"lambda1 = np.random.randint(0,1000,100)\nlambda2 = 10** np.linspace(10,2,100)*0.5","65d3632c":"# pick one lambda 1 or lambda 2(you should try ) :)\nridgecv = RidgeCV(alphas = lambda1, scoring = \"neg_mean_squared_error\", cv=10, normalize=True )\nridgecv.fit(X_train, y_train)","08fd7255":"ridgecv.alpha_ #(i think optimuim alpha = 2 )","3a3c7293":"#final model\nridge_tuned = Ridge(alpha=ridgecv.alpha_).fit(X_train, y_train)\ny_pred = ridge_tuned.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_pred))","b7860dc3":"import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import Ridge, Lasso\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import RidgeCV, LassoCV","4a60f37d":"#Data Set\ndf = pd.read_csv(\"\/kaggle\/input\/Hitters.csv\")\ndf = df.dropna()\n\ndms = pd.get_dummies(df[['League','Division','NewLeague']])\n\ny = df[\"Salary\"]\nX_ = df.drop(['Salary','League','Division','NewLeague'], axis=1).astype('float64')\nX = pd.concat([X_, dms[['League_N','Division_W','NewLeague_N']]],axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X,\n                                                   y,\n                                                   test_size=0.25,\n                                                    random_state=42)","3594ec30":"df.head()","40668625":"df.shape","a3b65a55":"lasso_model = Lasso().fit(X_train, y_train)","905a41a8":"lasso_model","db3c5ac6":"lasso_model.intercept_ ","23f921a5":"lasso_model.coef_ ","cc9eabd1":"lasso = Lasso()\ncoefs = []\n#alphas = np.random.randint(0,100000,10) #lambdas\nalphas = lambdalar = 10** np.linspace(10,2,100)*0.5\nfor a in alphas:\n    lasso.set_params(alpha = a)\n    lasso.fit(X_train, y_train)\n    coefs.append(lasso.coef_)","d6b5d3b6":"ax = plt.gca()\nax.plot(alphas, coefs)\nax.set_xscale(\"log\")","7256b0c4":"lasso_model","ce6539ce":"lasso_model.predict(X_train)[0:5]","e6f47120":"lasso_model.predict(X_test)[0:5]","7c1c1e44":"y_pred = lasso_model.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_pred))","e8b2624a":"r2_score(y_test, y_pred)","4866cc4a":"alphas = lambdalar = 10** np.linspace(10,2,100)*0.5\nlasso_cv_model = LassoCV(alphas = alphas, cv=10, max_iter = 100000).fit(X_train, y_train)\nlasso_cv_model.alpha_","dd02e307":"lasso_tuned = Lasso().set_params(alpha = lasso_cv_model.alpha_).fit(X_train, y_train)\nlasso_tuned = Lasso(alpha = lasso_cv_model.alpha_).fit(X_train, y_train)\ny_pred = lasso_tuned.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_pred))","68b5c2a3":"pd.Series(lasso_tuned.coef_, index = X_train.columns)","0436333e":"#library\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import Ridge, Lasso, ElasticNet\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import RidgeCV, LassoCV, ElasticNetCV","bfc271a1":"#Data Set\ndf = pd.read_csv(\"\/kaggle\/input\/Hitters.csv\")\ndf = df.dropna()\n\ndms = pd.get_dummies(df[['League','Division','NewLeague']])\n\ny = df[\"Salary\"]\nX_ = df.drop(['Salary','League','Division','NewLeague'], axis=1).astype('float64')\nX = pd.concat([X_, dms[['League_N','Division_W','NewLeague_N']]],axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X,\n                                                   y,\n                                                   test_size=0.25,\n                                                    random_state=42)","1cd89fc1":"enet_model = ElasticNet().fit(X_train, y_train)","5877dfd3":"enet_model.coef_","40cbfbfe":"enet_model.intercept_","b536cde8":"enet_model.predict(X_train)[0:10]","dca72eea":"enet_model.predict(X_test)[0:10]","1775fc47":"y_pred = enet_model.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_pred)) ","f4ba8089":"r2_score(y_test, y_pred)","b176b748":"enet_cv_model = ElasticNetCV(cv=10).fit(X_train, y_train)","d48ef8d2":"enet_cv_model.alpha_","a8654579":"enet_cv_model.intercept_","5d1ee7cb":"enet_cv_model.coef_","ce2a74d2":"enet_tuned = ElasticNet(alpha = enet_cv_model.alpha_ ).fit(X_train, y_train)\ny_pred = enet_tuned.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_pred))","2b69ed8c":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import scale\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import model_selection\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn import neighbors\nfrom sklearn.svm import SVR","c89bc5e2":"from warnings import filterwarnings\nfilterwarnings('ignore')","bae60144":"#Data Set\ndf = pd.read_csv(\"\/kaggle\/input\/Hitters.csv\")\ndf = df.dropna()\n\ndms = pd.get_dummies(df[['League','Division','NewLeague']])\n\ny = df[\"Salary\"]\nX_ = df.drop(['Salary','League','Division','NewLeague'], axis=1).astype('float64')\nX = pd.concat([X_, dms[['League_N','Division_W','NewLeague_N']]],axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X,\n                                                   y,\n                                                   test_size=0.25,\n                                                    random_state=42)","0fe4fc69":"X_train.head()","89cdee67":"**Residues and Their Importance in Machine Learning**\n*  MSE : Mean squared error\n* RMSE : Root mean squared error","46c860ac":"### MSE\n**As you can see, the error values can be minus, and we will take the squaring process to  take care of it and we will take the average. In this way, we will have MSE**","40a3ff13":"## Model Tuning","272879a0":"## Predict","d76f1af4":"# Dogrusal Olmayan Regresyon Modelleri","f0d46719":"### Predict","1eda0152":"#  4- Lasso Regresyon","ba50fc5c":"### K-fold Cross Validation","da0a2d5b":"## Model Tuning","56f60392":"## Model & Predict","4a8f821f":"## 5-ElasticNet Regresyon Modeli","c1c7e1df":"# KNN","725616d3":"### Predict","25fd88cb":"## Predict\n** Sales = 2.94 + (TV * 0.04) + (radio * 0.19) -(newspaper*0.001) \n* 30  TV , 10  radio , 40 newspaper","e8b11811":"# 1- Linear Regression Model\nLinear Regression is a linear approach to modeling the relationship between a scaler response and one or more explanatory variables. The case of one explanatory variable is called simple *linear regression* .","e2e1e185":"### Required libraries","5f998d73":"# 4- Ridge Regression","5d2962fe":"### Model Tuning","3b2c9ee3":"# Model Tuning","26a2c4e2":"# 2 - Multiple Linear Regression"}}