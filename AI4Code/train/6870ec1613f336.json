{"cell_type":{"a5739df8":"code","183fc219":"code","7a2173d5":"code","a79776cb":"code","064322e1":"code","4e8e81cc":"code","4e1132ac":"code","40fbf127":"code","bca58ef2":"code","92283c10":"code","18f77af9":"code","d16d9a0f":"code","283d3667":"code","b38dd9bc":"code","ea15be92":"code","af93da5b":"code","e73a354e":"code","2384eec9":"code","421cc8e6":"code","35ade589":"code","bb7c4e2f":"code","6994eb8d":"code","62bc4b3b":"code","0c78d253":"code","7b0f7961":"code","02b0e571":"code","3101fe34":"code","1c483022":"code","9d63c4b8":"code","a7d81f43":"code","d481df69":"code","d2513697":"code","b1b775d9":"code","70218196":"code","da223343":"markdown","8a92d39c":"markdown","0f671ff7":"markdown","3f67dc1b":"markdown","75108339":"markdown","cc07014c":"markdown","a2db0d25":"markdown","71517148":"markdown","e9617b96":"markdown","068eb5ae":"markdown"},"source":{"a5739df8":"!pip install https:\/\/github.com\/uber\/ludwig\/archive\/master.zip","183fc219":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"..\/input\"))\nimport ludwig\nfrom ludwig.api import LudwigModel\nimport scipy as scipy\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","7a2173d5":"traindf = pd.read_csv(\"..\/input\/train.csv\")\ntestdf = pd.read_csv(\"..\/input\/test.csv\")","a79776cb":"print(traindf.shape)\nprint(testdf.shape)","064322e1":"traindf.head()","4e8e81cc":"testdf.head()","4e1132ac":"# Save the original for later\ntraindf_old = traindf \ntestdf_old = testdf","40fbf127":"all_data = pd.concat((traindf.loc[:,'MSSubClass':'SaleCondition'], testdf.loc[:,'MSSubClass':'SaleCondition']))","bca58ef2":"numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index","92283c10":"skewed_feats = traindf[numeric_feats].apply(lambda x: scipy.stats.skew(x.dropna()))\nskewed_feats = skewed_feats[skewed_feats > 0.75]\nskewed_feats = skewed_feats.index\nall_data[skewed_feats] = np.log1p(all_data[skewed_feats])\nfor col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    all_data[col] = all_data[col].fillna(0)\nfor col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n    all_data[col] = all_data[col].fillna(0)\nfor col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    all_data[col] = all_data[col].fillna('None')\nall_data[\"MasVnrType\"] = all_data[\"MasVnrType\"].fillna(\"None\")\nall_data[\"MasVnrArea\"] = all_data[\"MasVnrArea\"].fillna(0)\nall_data['MSSubClass'] = all_data['MSSubClass'].apply(str)\nall_data['OverallCond'] = all_data['OverallCond'].astype(str)\nall_data['YrSold'] = all_data['YrSold'].astype(str)\nall_data['MoSold'] = all_data['MoSold'].astype(str)\nall_data = all_data.fillna(all_data.mean())","18f77af9":"traindf = all_data.iloc[:len(traindf),:]\ntestdf = all_data.iloc[len(testdf)+1:,:]\ntraindf[\"SalePrice\"] = np.log1p(traindf_old['SalePrice'])\nprint(traindf.shape)\nprint(testdf.shape)\nprint(traindf_old.shape)\nprint(testdf_old.shape)\n# the ID columns is removed in the new traindf and testdf","d16d9a0f":"traindf[\"SalePrice\"].plot.hist()","283d3667":"traindf.head()","b38dd9bc":"columns = list(traindf.columns)","ea15be92":"dtypes = []\nfor c in columns:\n    dtypes.append(traindf[c].dtype)","af93da5b":"dtypes2 = []\nfor d in dtypes:\n    if d in ('int64', 'float64'):\n        dtypes2.append('numerical')\n    if d == object:\n        dtypes2.append('category')","e73a354e":"print(dtypes2)","2384eec9":"input_features = []\nfor col, dtype in zip(columns[:-1],dtypes2[:-1]):\n    input_features.append(dict(name=col,type=dtype))\nprint(input_features)","421cc8e6":"model_definition = {\n    'input_features':input_features,\n    'output_features':[\n        {'name': 'SalePrice', 'type':'numerical'}\n    ]\n}","35ade589":"model = LudwigModel(model_definition)\ntrainstats = model.train(traindf)","bb7c4e2f":"print(trainstats)","6994eb8d":"for i in trainstats.keys():\n    print(i)\n    for j in trainstats[i]:\n        print(' ',j)\n        for k in trainstats[i][j]:\n            print('  ',k)\n    print('--')","62bc4b3b":"print(trainstats['train'].keys())","0c78d253":"fig, axes = plt.subplots(1,2,figsize=(15,6))\naxes[0].plot(trainstats['train']['SalePrice']['loss'],label='train')\naxes[0].plot(trainstats['validation']['SalePrice']['loss'],label='validation')\naxes[0].plot(trainstats['test']['SalePrice']['loss'],label='test')\naxes[0].legend(loc='upper right')\naxes[0].set_title('Loss')\naxes[1].plot(trainstats['train']['SalePrice']['mean_absolute_error'],label='train')\naxes[1].plot(trainstats['validation']['SalePrice']['mean_absolute_error'],label='validation')\naxes[1].plot(trainstats['test']['SalePrice']['mean_absolute_error'],label='test')\naxes[1].legend(loc='upper right')\naxes[1].set_title('mean_absolute_error')\nplt.show()","7b0f7961":"pd.set_option('display.max_columns', 10)\nprint(traindf.head())\nprint(testdf.head())\nprint(traindf_old.head())\nprint(testdf_old.head())","02b0e571":"testdf.head()","3101fe34":"predictions = model.predict(testdf)","1c483022":"predictions.plot.hist()","9d63c4b8":"predictions.head(10)","a7d81f43":"predictions = np.expm1(predictions)","d481df69":"pd.options.display.float_format = '{:,.0f}'.format\npredictions.head(10)","d2513697":"submission = pd.DataFrame(testdf_old['Id'])\nsubmission['SalePrice'] = predictions\n","b1b775d9":"submission.head()","70218196":"submission.to_csv('submission.csv',index=False)","da223343":"# Create Ludwig Model and train the model","8a92d39c":"## Check the structure of the trainstats dictionary","0f671ff7":"# Input Features Dictionary\n\nWe need to create list of input feature dictionary as input into Ludwig. Here, I simply loop through all available columns, except for the target variable.","3f67dc1b":"# Import Ludwig\n\nWe need to pip install first. I'm installing from the repo, since there was an error when doing regular pip install (according to [this](https:\/\/www.mikulskibartosz.name\/ludwig-machine-learing-model-in-kaggle\/) article).","75108339":"## Check some performance metrics\n\nv1: It turned out to be not so great\n<a href=\"https:\/\/ibb.co\/zSv9yQx\"><img src=\"https:\/\/i.ibb.co\/br9wSQm\/Screen-Hunter-3150.jpg\" alt=\"Screen-Hunter-3150\" border=\"0\"><\/a>\n\nv2: Much improved performance after doing some basic feature engineering. (Need to review again what feature engineering is being done vs. not being done by Ludwig)\n<a href=\"https:\/\/ibb.co\/qBzCCwW\"><img src=\"https:\/\/i.ibb.co\/sjhCCr6\/Screen-Hunter-3151.jpg\" alt=\"Screen-Hunter-3151\" border=\"0\"><\/a>","cc07014c":"# Overview\n\n<a><img src=\"https:\/\/raw.githubusercontent.com\/uber\/ludwig\/master\/docs\/images\/og-image.jpg\" alt=\"luldwig\" border=\"0\" height=\"500\" width=\"500\" ><\/a>\n\nHere I want to try out Uber's auto-ML framework called Ludwig. As I do this exercise, it turned out to be quite simple and fast.\n\nv1 (commit v1, v2): In this notebook, I don't do any data cleaning or feature engineering. So the result is actually quite poor. Especially there are a few columns that has 0 for what is supposed to be null value. But nonetheless, the intent is to show what a Ludwig pipeline would look like.\n\nv2 (commit v3-v5): Since the performance is so bad, I will do some basic clean-up and data preprocessing first. The preprocessing steps will mainly be sourced from other kernels: [this one](https:\/\/www.kaggle.com\/apapiu\/regularized-linear-models) and [this one](https:\/\/www.kaggle.com\/serigne\/stacked-regressions-top-4-on-leaderboard). The result on train\/val becomes very good, but the output on dftest doesn't really makes sense, simply just looking by the distribution. Perhaps Ludwig is extremely overfitting for small sample?\n\n<a href=\"https:\/\/ibb.co\/ZLcCx4z\"><img src=\"https:\/\/i.ibb.co\/p04pdVj\/Screen-Hunter-3152.jpg\" alt=\"Screen-Hunter-3152\" border=\"0\"><\/a>\n<a href=\"https:\/\/imgbb.com\/\"><img src=\"https:\/\/i.ibb.co\/CwjzwQP\/Screen-Hunter-3153.jpg\" alt=\"Screen-Hunter-3153\" border=\"0\"><\/a><br \/>\n\n\n","a2db0d25":"Note: I'm hiding the output since it's very long. The following section will explain the structure of the dictionary.","71517148":"# Model training statistics","e9617b96":"# Do the predictions","068eb5ae":"# Data Preprocessing"}}