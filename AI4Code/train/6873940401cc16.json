{"cell_type":{"e3d518c2":"code","9e50b578":"code","4e27dde0":"code","1054dbd1":"code","fbc8df2a":"code","4ba9d8a0":"code","9adf79eb":"code","5dedaa12":"code","82db9886":"code","290408a9":"code","7f3d1d5f":"code","6db5c2c1":"code","457afb00":"code","5299c281":"code","5572fc60":"code","e4b61fcd":"code","894d81cc":"code","8176153d":"code","0e6c3ee7":"code","7e60760c":"code","49ffbb05":"code","015b7a61":"code","22a1d606":"code","4c5e03ce":"code","b98c91d4":"code","875d7805":"code","56b25233":"code","9bdaa205":"code","02fbe0aa":"code","cc4d6216":"code","ba4e2281":"code","833b91c9":"markdown","b15b6a9b":"markdown"},"source":{"e3d518c2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport random\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras import layers\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom keras.utils import plot_model\nfrom keras.callbacks import EarlyStopping\n    ","9e50b578":"pd_train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')","4e27dde0":"pd_train","1054dbd1":"print(f'Number of rows: {pd_train.shape[0]}; Number of columns: {pd_train.shape[1]}')","fbc8df2a":"pd_train.dtypes","4ba9d8a0":"pd_train.describe()","9adf79eb":"def pickSample(df_train):\n    ran = range(0, df_train.shape[0])\n    pick = random.choices(ran, k=9)\n    \n    return pick","5dedaa12":"def dataVisualization(x, labels):\n    fig = plt.figure(figsize=(15, 15))\n    \n    rows = 3\n    cols = 3\n\n    for i in range(9):\n        img = np.asarray(x.iloc[i])\n        img = np.reshape(img, (28, 28))\n        ax = fig.add_subplot(rows, cols, i + 1)\n        ax.imshow(img, cmap='gray', vmin=0, vmax=255)\n        ax.set_xlabel('label => '+ str(labels[i]), fontsize=15, fontweight=100)\n        ax.set_xticks([]), ax.set_yticks([])","82db9886":"x = pd_train.iloc[:, 1:]\ny = pd_train.iloc[:, 0]\n\ny = to_categorical(y, num_classes=10)\n\nX_train, X_val, Y_train, Y_val = train_test_split(x, y, test_size = 0.2)","290408a9":"model = Sequential()\nmodel.add(Dense(units=64, activation='relu'))\nmodel.add(Dense(units=10, activation='softmax'))","7f3d1d5f":"model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])","6db5c2c1":"model.fit(X_train, Y_train, epochs=10, batch_size=86)","457afb00":"print(model.summary())","5299c281":"df_test = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\nresult_sample = pickSample(df_test)\ny = model.predict(df_test.iloc[result_sample])\ndataVisualization(df_test.iloc[result_sample], np.argmax(y, axis = 1))","5572fc60":"X_img = pd_train.iloc[:, 1:]\nX_img = np.reshape(np.asarray(X_img), (-1, 28, 28, 1))\nX_img = X_img \/ 255.0\ny_img = pd_train.iloc[:, 0]\ny_img = to_categorical(y_img, num_classes=10)","e4b61fcd":"cnn_model = Sequential()\ncnn_model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\ncnn_model.add(layers.MaxPooling2D(2, 2))\ncnn_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\ncnn_model.add(layers.MaxPooling2D(2, 2))\ncnn_model.add(layers.Conv2D(64, (3, 3), activation='relu'))","894d81cc":"cnn_model.summary()","8176153d":"cnn_model.add(layers.Flatten())\ncnn_model.add(layers.Dense(64, activation='relu'))\ncnn_model.add(layers.Dense(10, activation='softmax'))","0e6c3ee7":"cnn_model.summary()","7e60760c":"plot_model(cnn_model, show_shapes=True, show_layer_names=False)","49ffbb05":"es = EarlyStopping(monitor='val_loss', mode='min', verbose = 1, patience=5)","015b7a61":"cnn_model.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","22a1d606":"cnn_model.fit(X_img, y_img, epochs=5,\n              callbacks=[es])","4c5e03ce":"losses = pd.DataFrame(cnn_model.history.history)\nlosses","b98c91d4":"y_dnn = model.predict(df_test.iloc[result_sample])\nx_cnn = np.reshape(np.asarray(df_test.iloc[result_sample]), (-1, 28, 28, 1))\ny_cnn = cnn_model.predict(x_cnn)","875d7805":"dataVisualization(df_test.iloc[result_sample], np.argmax(y_dnn, axis = 1))","56b25233":"dataVisualization(df_test.iloc[result_sample], np.argmax(y_cnn, axis = 1))","9bdaa205":"df_test = np.reshape(np.asarray(df_test), (-1, 28, 28, 1))\ny_test = cnn_model.predict(df_test)","02fbe0aa":"y_test = np.argmax(y_test, axis=1)","cc4d6216":"submission_dict = {\"ImageId\": [i + 1 for i in range(28000)],\n                   \"Label\": y_test}\n\nsub_df = pd.DataFrame(submission_dict)\n\nsub_df","ba4e2281":"sub_df.to_csv(\"submission.csv\", index=False)","833b91c9":"***This is result of DNN MODEL for MNIST***","b15b6a9b":"***DNN MODEL***"}}