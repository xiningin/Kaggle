{"cell_type":{"8b21883a":"code","c62a952f":"code","2235ffd4":"code","7d3ce671":"code","04c7161f":"code","6f20ef88":"code","0cbe8d4b":"code","cb6a719f":"code","40f6599f":"code","2305c691":"code","2157d5d2":"code","524656dd":"code","d04f0f92":"code","c4e11855":"code","cc737f0b":"code","0d952f06":"code","42562fe2":"code","6b816d51":"code","b607ab69":"markdown","e551b9b1":"markdown","3d3fe6fc":"markdown","9c7e1868":"markdown","9b05b701":"markdown","3e71d3a7":"markdown","e5c62a2d":"markdown","8298cfc7":"markdown","87977526":"markdown","15bfe8c9":"markdown","50da98ce":"markdown","9dbddda3":"markdown","a4ae9afc":"markdown","b5fd7708":"markdown"},"source":{"8b21883a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nfrom torch.utils.data import TensorDataset, DataLoader\n\nimport tensorflow.keras.datasets.mnist as MNIST\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport warnings\n","c62a952f":"cuda =  torch.cuda.is_available()\nprint(\"GPU available:\", cuda)","2235ffd4":"!pip install GPUtil\n\nimport torch\nfrom GPUtil import showUtilization as gpu_usage\nfrom numba import cuda\n\ndef free_gpu_cache():\n    print(\"Initial GPU Usage\")\n    gpu_usage()                             \n\n    torch.cuda.empty_cache()\n\n    cuda.select_device(0)\n    cuda.close()\n    cuda.select_device(0)\n\n    print(\"GPU Usage after emptying the cache\")\n    gpu_usage()\n\nfree_gpu_cache()           ","7d3ce671":"torch.manual_seed(1102)\nnp.random.seed(1102)","04c7161f":"(image_MNIST_train_set, label_MNIST_train_set), (image_MNIST_test_set, label_MNIST_test_set) = MNIST.load_data()\n\nindices_train, indices_validation = train_test_split(range(len(image_MNIST_train_set)), test_size = 0.2)\nimage_train = image_MNIST_train_set[indices_train, :, :]\nlabel_train = label_MNIST_train_set[indices_train]\nimage_validation = image_MNIST_train_set[indices_validation, :, :]\nlabel_validation = label_MNIST_train_set[indices_validation]\n\nimage_test = image_MNIST_test_set\nlabel_test = label_MNIST_test_set\nprint(\"test set number of samples:\", len(image_MNIST_test_set), \", maximum intensity:\",image_MNIST_test_set.max(), \", minimum intensitity:\",image_MNIST_test_set.min(),  \", and shape\", image_MNIST_test_set.shape)\nprint(\"train set number of samples:\", len(image_train), \", maximum intensity:\",image_train.max(), \", minimum intensitity:\",image_train.min(),  \", and shape\", image_train.shape)\nprint(\"validation set number of samples:\", len(image_validation), \", maximum intensity:\",image_validation.max(), \", minimum intensitity:\",image_validation.min(),  \", and shape\", image_validation.shape)","6f20ef88":"row = 4\ncol = 6\nfig = plt.figure(figsize = (12, 15))\n\nfor image_index in range(1, row * col + 1):\n    image = image_MNIST_test_set[image_index, :, :]\n    ax = fig.add_subplot(row, col, image_index)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.title.set_text(str(label_MNIST_test_set[image_index]))\n    plt.imshow(image, cmap = 'gray')","0cbe8d4b":"row = 4\ncol = 6\nfig = plt.figure(figsize = (12, 15))\n\nfor image_index in range(1, row * col + 1):\n    image = image_train[image_index, :, :]\n    ax = fig.add_subplot(row,col,image_index)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.title.set_text(str(label_train[image_index]))\n    plt.imshow(image, cmap = 'gray')","cb6a719f":"row = 4\ncol = 6\nfig = plt.figure(figsize = (12, 15))\n\nfor image_index in range(1, row * col + 1):\n    image = image_validation[image_index, :, :]\n    ax = fig.add_subplot(row,col,image_index)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.title.set_text(str(label_validation[image_index]))\n    plt.imshow(image, cmap = 'gray')","40f6599f":"image_train_torch = torch.from_numpy(image_train).type(torch.FloatTensor).view(-1, 1, 28, 28)\nlabel_train_torch = torch.from_numpy(label_train).type(torch.LongTensor)\n\nimage_validation_torch = torch.from_numpy(image_validation).type(torch.FloatTensor).view(-1, 1, 28, 28)\nlabel_validation_torch = torch.from_numpy(label_validation).type(torch.LongTensor)\n\nimage_test_torch = torch.from_numpy(image_MNIST_test_set).type(torch.FloatTensor).view(-1, 1, 28, 28)\nlabel_test_torch = torch.from_numpy(image_MNIST_test_set).type(torch.LongTensor)\n\ntrain_data = TensorDataset(image_train_torch, label_train_torch)\ntrain_loader = DataLoader(train_data, batch_size = 100)\n\ntest_data = TensorDataset(image_test_torch, label_test_torch)\ntest_loader = DataLoader(test_data, batch_size = 100)\n\nvalidation_data = TensorDataset(image_validation_torch, label_validation_torch)\nvalidation_loader = DataLoader(validation_data, batch_size = 100)\n\nprint(\"number of training batches:\", len(train_loader))\nprint(\"number of validation batches:\", len(validation_loader))\nprint(\"number of testing batches:\", len(test_loader))","2305c691":"class LeNet(nn.Module):\n    def __init__(self):\n        super(LeNet, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, 5, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n        self.conv3 = nn.Conv2d(64,128,2,1)\n        self.fc1 = nn.Linear(512, 128)\n        self.fc2 = nn.Linear(128, 64)\n        self.fc3 = nn.Linear(64, 10)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = F.relu(self.conv3(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = x.view(-1, 512)\n        x = F.relu(self.fc1(x))\n        x = F.sigmoid(self.fc2(x))\n        x = self.fc3(x)\n        return F.log_softmax(x, dim = 1)\n\nour_CNN = LeNet()\n\nif cuda:\n    our_CNN.cuda()\n\nprint(our_CNN)","2157d5d2":"optimizer = SGD(our_CNN.parameters(), lr = 0.001)\n\n!mkdir saved_models_CNN","524656dd":"# I keep getting a CUDA memory error and despite restarting the kernal multiple times, it won't run so there are no outputs past this point but I have still gone ahead and done the code for the rest of the problems\n\nEPOCHS = 50\ntrain_epoch_loss = []\nvalidation_epoch_loss = []\n\nfor epoch in range(EPOCHS):\n    train_loss = []\n    validation_loss = []   \n    \n    for batch_index, (train_image, train_label) in enumerate(train_loader):\n        if cuda:\n            our_CNN.train()\n            train_label_predicted = our_CNN(train_image.cuda())\n            loss = F.cross_entropy(train_label_predicted, train_label.cuda())\n            train_loss.append(loss.cpu().data.item())\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            our_CNN.eval()\n            validation_label_predicted = our_CNN(image_validation_torch.cuda())\n            loss = F.cross_entropy(validation_label_predicted, label_validation_torch.cuda())\n            validation_loss.append(loss.cpu().data.item())\n        else: \n            our_CNN.train()\n            train_label_predicted = our_CNN(train_image)\n            loss = F.cross_entropy(train_label_predicted, train_label)\n            train_loss.append(loss.cpu().data.item())\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            our_CNN.eval()\n            validation_label_predicted = our_CNN(image_validation_torch)\n            loss = F.cross_entropy(validation_label_predicted, label_validation_torch)\n            validation_loss.append(loss.cpu().data.item())\n           \n    \n    train_epoch_loss.append(np.mean(train_loss))\n    validation_epoch_loss.append(np.mean(validation_loss))\n    \n    torch.save(our_CNN.state_dict(), '.\/saved_models_CNN\/checkpoint_epoch_%s.pth' % (epoch))\n    \n    print(\"Epoch: {} | train_loss: {} | validation_loss: {}\".format(epoch, train_epoch_loss[-1], validation_epoch_loss[-1]))","d04f0f92":"plt.figure(figsize = (12, 8))\nplt.plot(train_epoch_loss, '-o', label = 'training loss', markersize = 3)\nplt.plot(validation_epoch_loss, '-o', label = 'validation loss', markersize = 3)\nplt.legend(loc = 'upper right');\n\nbest_epoch = np.argmin(validation_epoch_loss)\nprint('lowest validation loss', best_epoch)","c4e11855":"state_dict = torch.load('.\/saved_models_CNN\/checkpoint_epoch_%s.pth' % (best_epoch))\nprint(state_dict.keys())\nour_CNN.load_state_dict(state_dict)","cc737f0b":"def predict_with_pytorch(model, input_data):\n    model.eval()\n    label_predicted_all = []\n    \n    label_predicted_one_hot = model(input_data)\n    label_predicted_probability, label_predicted_index = torch.max(label_predicted_one_hot.data, 1)\n    \n    for current_prediction in label_predicted_index:\n        label_predicted_all.append(current_prediction.detach().cpu().numpy().item())\n        \n    return label_predicted_all\n\nif cuda:\n    test_label_predicted = predict_with_pytorch(our_CNN, image_test_torch.cuda())\nelse:\n    test_label_predicted = predict_with_pytorch(our_CNN, image_test_torch)\n","0d952f06":"def view_classify(image, probabilities, version = \"MNIST\"):\n    probabilities = probabilities.data.numpy().squeeze()\n    fig, (ax1,ax2) = plt.subplots(figsize = (6,9), ncols = 2)\n    ax1.imshow(image.resize_(1,28,28).numpy().squeeze(),cmap = 'gray')\n    ax1.set_title('Original Image')\n    ax1.axis('off')\n    ax2.bar(np.arange(10), probabilities)\n    ax2.set_aspect(10)\n    ax2.set_xticks(np.arange(10))\n    \n    ax2.set_title('Class Probability')\n    ax2.set_ylim(0, 1.1)\n    \n    plt.tight_layout()\n    \nour_CNN.eval()\nsample_test_image = image_test_torch[0, :, :, :][np.newaxis, :, :, :]\n\nif cuda:\n    sample_prediction = our_CNN(sample_test_image.cuda())\nelse:\n    sample_prediction = our_CNN(sample_test_image)\n\nwarnings.filterwarnings('ignore')\n\nif cuda:\n    view_classify(sample_test_image, 2** sample_prediction.cpu())\nelse:\n    view_classify(sample_test_image, 2** sample_prediction)","42562fe2":"j=0\nmatch = 0\n\nfor i in test_label_predicted:\n    if i== label_test[j]:\n        match = match + 1\n    j = j+1\n    \n    \nprint(\"Accuracy:\", round((match\/len(label_test) * 100),2) , \"%\")","6b816d51":"CM = confusion_matrix(label_test, test_label_predicted)\n\nplt.figure(figsize = (12,10))\nsns.heatmap(CM, annot = True, annot_kws = {\"size\": 10})\nplt.ylim([0, 10]);\nplt.ylabel('True labels');\nplt.xlabel('Predicted labels');","b607ab69":"#### <span style=\"color:red\">(5 pts.) Q8. <\/span> Plot the learning curve and indicate in which epoch the model achieved the lowest validation loss.\n**Note:** The learning curve is a plot that shows the training and validation loss for each epoch.","e551b9b1":"#### <span style=\"color:red\">(5 pts.) Q1. <\/span> \n#### a. Download the MNIST dataset using MNIST package. (Make sure the images and labels for both training set and test set are downloaded correctly)\n#### b. Using `train_test_split` function, split training set into a new training set and validation set by a ration of 20%.\n#### c. Print the number of samples, minimum and maximum intensity, and the shape of the images matrix for all three sets.","3d3fe6fc":"<span style=\"color:red\">1. (100, 32, 24, 24)\\\n    2. (100, 32, 12, 12)\\\n    3. (100, 64, 10, 10)\\\n    4. (100, 64, 5, 5)\\\n    5. (100, 128, 4, 4)\\\n    6. (100,128, 2, 2)\\\n    7. (100, 512)\\\n    8. (100, 128)\\\n    9. (100, 64)\\\n    10. (100, 10)<\/span>","9c7e1868":"<span style=\"color:red\">My architecture performed better on the MNIST classification rather than the LeNet model. Perhaps having a larger network (i.e. adding more layers) could increase the accuracy. <\/span>","9b05b701":"#### <span style=\"color:red\">(5 pts.) Q10. <\/span> Compare the performance of your architecture with the LeNet performance. Which one performs better on the MNIST classification? Can you suggest any method to improve either of the models?","3e71d3a7":"#### <span style=\"color:red\">(8 pts.) Q3. <\/span> \n#### a. Similar to the lecture, reformat all samples and create a `DataLoader` of batch size 100 for each set. \n#### b. Print the total number of batches in each `DataLoader`. (You can use `len()` function on `DataLoader`)\n**Note:** Do not forget to add one axis for channels. The Pytorch's tensor format is (BatchSize, Channel, Width, Height).","e5c62a2d":"#### <span style=\"color:red\">(0 pts.) Q0. <\/span> \n#### a. Import the packages you need similar to the notebook of the Lecture 3 - Part C. \n#### b. Check if the GPU is available.\n#### c. Set the random seed for both Pytorch and Numpy as 1102","8298cfc7":"#### <span style=\"color:red\">(12 pts.) Q4. <\/span> Using the lecture's notebook on LeNet, define a model as the following table:\n| Layer Number | Layer Type   | Number of kernels | Kernel size | Activation | Stride | Zero-Padding |\n| ------------ | ------------ | ----------------- | ----------- | ---------- | ------ | ------------ |\n| 1            | Conv2D       | 32                | 5x5         | ReLU       | 1      | 0            |\n| 2            | MaxPooling2D | NA                | 2x2         | NA         | 2      | 0            |\n| 3            | Conv2D       | 64                | 3x3         | ReLU       | 1      | 0            |\n| 4            | MaxPooling2D | NA                | 2x2         | NA         | 2      | 0            |\n| 5            | Conv2D       | 128               | 2x2         | ReLU       | 1      | 0            |\n| 6            | MaxPooling2D | NA                | 2x2         | NA         | 2      | 0            |\n| 7            | Faltten      | NA                | NA          | NA         | NA     | NA           |\n| 8            | FC (Linear)  | 128               | NA          | ReLU       | NA     | NA           |\n| 9            | FC (Linear)  | 64                | NA          | Sigmoid    | NA     | NA           |\n| 10           | FC (Linear)  | 10                | NA          | SoftMax    | NA     | NA           |\n**Note:** **NA** means not applicable.\n\n#### Then create an instance of the model and load it on the GPU by calling the `.cuda()` function.","87977526":"#### <span style=\"color:red\">(25 pts.) Q7. <\/span> Similar to the example on LeNet, train your network on a train set for 50 epochs. Use the \"Cross-Entropy\" (`F.cross_entropy`) as the loss function. \n#### At the end of each epoch, save the model, test the model on the validation set, and keep the training and validation loss for later. \n**Note:** Remember that the loss is calculated for each batch; thus, you need to take the average loss over all batches as the epoch loss for both training and validation phases.","15bfe8c9":"#### <span style=\"color:red\">(10 pts.) Q5. <\/span> Knowing the input shape of each image in the MNIST dataset is $28\\times28$, write the shape of the output tensor for each layer of the model.\n**Note:** You can use the following formula: \\\nAssuming the input shape is: $(B, Ch_{in}, W_{in}, H_{in})$, and the output shape is $(B, Ch_{out}, W_{out}, H_{out})$ \\\n1. For the `Conv2D` layers with $N$ number of $K\\times K$ kernels, zero-padding $P$, and stride $S$:\n$$\nW_{out} \\text{ or } H_{out} = \\lfloor {\\frac{W_{in} \\text{ or } H_{in} + 2P - K }{S}} + 1 \\rfloor\n$$\n$\\lfloor . \\rfloor$ means integer floor.\n\nAnd the number of channels for the output will be $Ch_{out} = N$\n\n2. Similarly for the `Maxpooling` layers of size $K \\times K$, zero-padding $P$, and stride $S$:\n$$\nW_{out} \\text{ or } H_{out} = \\lfloor {\\frac{W_{in} \\text{ or } H_{in} + 2P - K }{S}} + 1 \\rfloor\n$$\n\nThe only difference is that the number of channels for the output will be $Ch_{out} = Ch_{in}$\n\n3. For `Linear` (Also known as Fully-Connected) layers, the input is a vector of $(B, D_{in})$. Assuming the layer has $N$ number of neurons, the output is a vector of size $(B, N)$.\n\n**Note:** $B$ stands for the batch size.","50da98ce":"## Nicole Rosas -  nr2820","9dbddda3":"#### <span style=\"color:red\">(20 pts.) Q9. <\/span> \n#### a. Load the weights of the best epoch and test the model on the test set.\n#### b. Test the model on the first sample of the test set and plot the output probabilities.\n#### c. Print the overall accuracy of the model on the test set. Accuracy formula is $Accuracy=\\frac{\\text{Number of correct prediction}}{\\text{Total Number of samples}}$\n#### d. Plot the confusion matrix for the test set.\n\n**Note:** The testing phase is similar to the validation phase. You need to loop through batches of the test loader and keep the true labels and predicted labels for accuracy and confusion matrix.","a4ae9afc":"#### <span style=\"color:red\">(5 pts.) Q6. <\/span> Define an SGD optimizer with a learning rate of $10^{-3}$ on the parameters of the model.","b5fd7708":"#### <span style=\"color:red\">(5 pts.) Q2. <\/span> Display 24 first samples pulled from each set (train, validation, and test) and show the true labels as the title per each sample. \n**Note:** Display all 24 samples pulled from each set in one plot as in four rows and six columns. Thus, we will expect three plots for training, validation, and test set."}}