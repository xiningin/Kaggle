{"cell_type":{"18d17a77":"code","a8b5832e":"code","9ed04621":"code","d858c6d3":"code","3bfe77e6":"code","9f044d30":"code","f0d0fc0e":"code","9d4e31d0":"code","3ff788a8":"code","b30c8a3a":"code","d30ca70b":"code","29629257":"code","29d334cb":"code","6f57d7a6":"code","411e83a0":"code","c60162a4":"code","ff7b96c2":"code","494d4d0a":"code","c264e089":"code","f36703f3":"code","a12e9f49":"code","07139050":"code","b06d59e1":"code","18d3cc7e":"code","d23d92d7":"code","950d5732":"code","379eaf75":"code","9d52602e":"code","c5ca4256":"markdown","560dec31":"markdown","723d6fb6":"markdown"},"source":{"18d17a77":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","a8b5832e":"df_train = pd.read_csv('..\/input\/Train.csv')\ndf_test = pd.read_csv('..\/input\/Test.csv')\ndf_sample = pd.read_csv('..\/input\/Sample_submission.csv')","9ed04621":"df_train.head(2)","d858c6d3":"df_sample.head(3)","3bfe77e6":"df_test.head(3)","9f044d30":"train_reviews = df_train.review\ntest_reviews = df_test.review\nlabels = df_train.label","f0d0fc0e":"train_reviews[0]","9d4e31d0":"from nltk.tokenize  import RegexpTokenizer\nfrom nltk.stem import PorterStemmer\nfrom nltk.corpus import stopwords","3ff788a8":"def clean_view(text):\n    ps = PorterStemmer()\n    tokenizer = RegexpTokenizer('[a-zA-Z]+')\n    stopword = set(stopwords.words('english'))\n    text = text.lower()\n    tokens = tokenizer.tokenize(text)\n    new_token = [ps.stem(token) for token in tokens if token not in stopword] # stemming and stopword removing\n    return ' '.join(new_token)\n    ","b30c8a3a":"clean_train = [clean_view(each) for each in train_reviews]","d30ca70b":"clean_test = [clean_view(each) for each in test_reviews]","29629257":"from sklearn.feature_extraction.text import TfidfVectorizer","29d334cb":"tf = TfidfVectorizer(ngram_range=(2, 2))\ntf.fit(clean_train)\n","6f57d7a6":"x_train = tf.transform(clean_train)\nx_test = tf.transform(clean_test)","411e83a0":"from sklearn.preprocessing import LabelEncoder","c60162a4":"le = LabelEncoder()","ff7b96c2":"y = le.fit_transform(labels)","494d4d0a":"y","c264e089":"from sklearn.naive_bayes import MultinomialNB","f36703f3":"model = MultinomialNB()","a12e9f49":"model.fit(x_train, y)","07139050":"model.score(x_train, y)","b06d59e1":"pred = model.predict(x_test)","18d3cc7e":"pd.DataFrame?","d23d92d7":"x_test.shape","950d5732":"df = pd.DataFrame({\"Id\":[i for i in range(pred.shape[0])],\"label\":pred}, index=None)","379eaf75":"df['label'] = ['pos' if each == 1 else 'neg' for each in df.label ]","9d52602e":"df.to_csv('submission.csv', index=None)","c5ca4256":"### text  preprocessing","560dec31":"### vectorization","723d6fb6":"### Applying Naive Bayes Classifier"}}