{"cell_type":{"8b9b4e76":"code","99be98d5":"code","a06da789":"code","7e5ed6a6":"code","1b74b5d0":"code","3420e40f":"code","6416be0f":"code","bee02549":"code","6794fc85":"code","64e29fa5":"code","f1ded846":"code","5b44ca35":"code","edeca399":"markdown","457cfe34":"markdown"},"source":{"8b9b4e76":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport plotly.graph_objs as go\nimport plotly.offline as py\nimport plotly.express as px\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","99be98d5":"df = pd.read_csv(\"..\/input\/covid19-allresearchpapers-lemmatizedinformation\/COVID-19_AllResearchPapers_LemmatizedInformation.csv\")","a06da789":"df.head()","7e5ed6a6":"df.dtypes","1b74b5d0":"def pie_plot(labels, values, colors, title):\n    fig = {\n      \"data\": [\n        {\n          \"values\": values,\n          \"labels\": labels,\n          \"domain\": {\"x\": [0, .48]},\n          \"name\": \"Job Type\",\n          \"sort\": False,\n          \"marker\": {'colors': colors},\n          \"textinfo\":\"percent+label+value\",\n          \"textfont\": {'color': '#FFFFFF', 'size': 10},\n          \"hole\": .6,\n          \"type\": \"pie\"\n        } ],\n        \"layout\": {\n            \"title\":title,\n            \"annotations\": [\n                {\n                    \"font\": {\n                        \"size\": 25,\n\n                    },\n                    \"showarrow\": False,\n                    \"text\": \"\"\n\n                }\n            ]\n        }\n    }\n    return fig","3420e40f":"from collections import Counter\nimport json\nfrom IPython.display import HTML\nimport altair as alt\nfrom  altair.vega import v5","6416be0f":"##-----------------------------------------------------------\n# This whole section \nvega_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega@' + v5.SCHEMA_VERSION\nvega_lib_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-lib'\nvega_lite_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-lite@' + alt.SCHEMA_VERSION\nvega_embed_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-embed@3'\nnoext = \"?noext\"\n\npaths = {\n    'vega': vega_url + noext,\n    'vega-lib': vega_lib_url + noext,\n    'vega-lite': vega_lite_url + noext,\n    'vega-embed': vega_embed_url + noext\n}\n\nworkaround = \"\"\"\nrequirejs.config({{\n    baseUrl: 'https:\/\/cdn.jsdelivr.net\/npm\/',\n    paths: {}\n}});\n\"\"\"\n\n#------------------------------------------------ Defs for future rendering\ndef add_autoincrement(render_func):\n    # Keep track of unique <div\/> IDs\n    cache = {}\n    def wrapped(chart, id=\"vega-chart\", autoincrement=True):\n        if autoincrement:\n            if id in cache:\n                counter = 1 + cache[id]\n                cache[id] = counter\n            else:\n                cache[id] = 0\n            actual_id = id if cache[id] == 0 else id + '-' + str(cache[id])\n        else:\n            if id not in cache:\n                cache[id] = 0\n            actual_id = id\n        return render_func(chart, id=actual_id)\n    # Cache will stay outside and \n    return wrapped\n\n@add_autoincrement\ndef render(chart, id=\"vega-chart\"):\n    chart_str = \"\"\"\n    <div id=\"{id}\"><\/div><script>\n    require([\"vega-embed\"], function(vg_embed) {{\n        const spec = {chart};     \n        vg_embed(\"#{id}\", spec, {{defaultStyle: true}}).catch(console.warn);\n        console.log(\"anything?\");\n    }});\n    console.log(\"really...anything?\");\n    <\/script>\n    \"\"\"\n    return HTML(\n        chart_str.format(\n            id=id,\n            chart=json.dumps(chart) if isinstance(chart, dict) else chart.to_json(indent=None)\n        )\n    )\n\n\n\nHTML(\"\".join((\n    \"<script>\",\n    workaround.format(json.dumps(paths)),\n    \"<\/script>\")))","bee02549":"def word_cloud(df, pixwidth=6000, pixheight=350, column=\"index\", counts=\"count\"):\n    data= [dict(name=\"dataset\", values=df.to_dict(orient=\"records\"))]\n    wordcloud = {\n        \"$schema\": \"https:\/\/vega.github.io\/schema\/vega\/v5.json\",\n        \"width\": pixwidth,\n        \"height\": pixheight,\n        \"padding\": 0,\n        \"title\": \"Hover to see number of occureances from all the sequences\",\n        \"data\": data\n    }\n    scale = dict(\n        name=\"color\",\n        type=\"ordinal\",\n        range=[\"cadetblue\", \"royalblue\", \"steelblue\", \"navy\", \"teal\"]\n    )\n    mark = {\n        \"type\":\"text\",\n        \"from\":dict(data=\"dataset\"),\n        \"encode\":dict(\n            enter=dict(\n                text=dict(field=column),\n                align=dict(value=\"center\"),\n                baseline=dict(value=\"alphabetic\"),\n                fill=dict(scale=\"color\", field=column),\n                tooltip=dict(signal=\"datum.count + ' occurrances'\")\n            )\n        ),\n            \"transform\": [{\n            \"type\": \"wordcloud\",\n            \"text\": dict(field=column),\n            \"size\": [pixwidth, pixheight],\n            \"font\": \"Helvetica Neue, Arial\",\n            \"fontSize\": dict(field=\"datum.{}\".format(counts)),\n            \"fontSizeRange\": [10, 60],\n            \"padding\": 2\n        }]\n    }\n    wordcloud[\"scales\"] = [scale]\n    wordcloud[\"marks\"] = [mark]\n    \n    return wordcloud\n\nfrom collections import defaultdict\n\ndef wordcloud_create(df):\n    ult = {}\n    corpus = df.text.values.tolist()\n    final = defaultdict(int) #Declaring an empty dictionary for count (Saves ram usage)\n    for words in corpus:\n        for word in words.split():\n             final[word]+=1\n    temp = Counter(final)\n    for k, v in  temp.most_common(200):\n        ult[k] = v\n    corpus = pd.Series(ult) #Creating a dataframe from the final default dict\n    return render(word_cloud(corpus.to_frame(name=\"count\").reset_index(), pixheight=600, pixwidth=900))","6794fc85":"wordcloud_create(df)","64e29fa5":"cnt_srs = df['document_keyword'].value_counts().head()\ntrace = go.Bar(\n    y=cnt_srs.index[::-1],\n    x=cnt_srs.values[::-1],\n    orientation = 'h',\n    marker=dict(\n        color=cnt_srs.values[::-1],\n        colorscale = 'Blues',\n        reversescale = True\n    ),\n)\n\nlayout = dict(\n    title='Document Keyword distribution',\n    )\ndata = [trace]\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename=\"document_keyword\")","f1ded846":"fig = px.pie( values=df.groupby(['affiliations']).size().values,names=df.groupby(['affiliations']).size().index)\nfig.update_layout(\n    title = \"\",\n    font=dict(\n        family=\"Arial, monospace\",\n        size=15,\n        color=\"#7f7f7f\"\n    )\n    )   \n    \npy.iplot(fig)","5b44ca35":"fig = px.histogram(df[df.document_keyword.notna()],x=\"paper_id\",marginal=\"box\",nbins=10)\nfig.update_layout(\n    title = \"Paper ID\",\n    xaxis_title=\"paper_id\",\n    yaxis_title=\"Number of paper-ids\",\n    barmode=\"group\",\n    bargap=0.1,\n    xaxis = dict(\n        tickmode = 'linear',\n        tick0 = 0,\n        dtick = 10),\n    font=dict(\n        family=\"Arial, monospace\",\n        size=15,\n        color=\"#7f7f7f\"\n    )\n    )\npy.iplot(fig)","edeca399":"Kaggle Notebook Runner: Mar\u00edlia Prata  @mpwolke","457cfe34":"codes from Shivam Ralli @hoshi7"}}