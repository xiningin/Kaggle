{"cell_type":{"00aba10b":"code","f479b7d5":"code","07240c3b":"code","307b89ec":"code","48a397c8":"code","e2b04365":"code","02727324":"code","12f84692":"code","54626c65":"code","c603a044":"code","fd7f9bf9":"code","20414449":"code","95fc1838":"code","0504cc7a":"code","6b7b10fc":"code","474a109b":"code","e8c05c1c":"markdown","679e8658":"markdown","66ca60df":"markdown","3ce21e51":"markdown"},"source":{"00aba10b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","f479b7d5":"data=pd.read_csv(\"\/kaggle\/input\/echocardiogram-uci\/echocardiogram.csv\")\ndata.head()","07240c3b":"del data[\"name\"]\ndel data[\"group\"]","307b89ec":"data.dtypes","48a397c8":"from fancyimpute import KNN\ndeyta=KNN(k=2).fit_transform(data)\ndeyta.shape","e2b04365":"deyta=pd.DataFrame(deyta)\ndeyta.columns=data.columns","02727324":"deyta.head()","12f84692":"deyta.isnull().sum()","54626c65":"import seaborn as sns\nimport matplotlib.pyplot as plt\ncorrelation=deyta.corr()\nplt.figure(figsize=(16, 16))\nsns.heatmap(correlation,annot=True)","c603a044":"y=deyta[\"alive\"]\nx=deyta.loc[:,(deyta.columns!=\"alive\") & (data.columns!=\"aliveat1\")]","fd7f9bf9":"from sklearn.ensemble import RandomForestClassifier\nrfc=RandomForestClassifier()    \nfrom sklearn.model_selection import cross_val_score\nprint(cross_val_score(rfc,x, y, cv=4))","20414449":"from sklearn.tree import DecisionTreeClassifier\nprint(cross_val_score(DecisionTreeClassifier(),x, y, cv=4))","95fc1838":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.10, random_state=1923)\n\nfrom tpot import TPOTClassifier\ntpot = TPOTClassifier(verbosity=2,max_time_mins=40)\ntpot.fit(X_train, y_train)\nprint(tpot.score(X_test, y_test))","0504cc7a":"tpot.export(\"classifierpipeline.py\")","6b7b10fc":"ypred=tpot.predict(X_test)","474a109b":"import sklearn.metrics as metrik\nprint(metrik.accuracy_score(y_pred=ypred,y_true=y_test))\nprint(metrik.confusion_matrix(y_pred=ypred,y_true=y_test))","e8c05c1c":"### alive and aliveat1 has strong correlation.\n### aliveat1 and survival also have strong negative correlation \n### I use alive column as y but can't use aliveat1 column","679e8658":"Okay we handle null values with knn imputer. KNow we examine correlations.","66ca60df":"Work just fine.","3ce21e51":"Tree Based Algorithm looks fine in this dataset. What about tpot"}}