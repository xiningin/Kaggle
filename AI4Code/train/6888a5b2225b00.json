{"cell_type":{"1dc901e6":"code","0160e3ad":"code","08707303":"code","1a1a2400":"code","d864a94b":"code","b493d42c":"code","76508ff5":"code","f0201e09":"code","5f9de296":"code","02decc7e":"code","6da2fe27":"code","bd7db6de":"code","220b50eb":"code","6832dc7b":"code","ece8012a":"code","7de19e85":"code","e4331245":"code","466a5489":"code","311a187b":"code","38394266":"code","ef6d4be7":"code","4a703ec0":"code","d1f78afe":"code","bca90865":"code","4890de69":"code","a0d531fa":"code","8bfd82fe":"code","63a3b17a":"code","f555c444":"code","1cc78488":"code","aa77de7f":"code","54e20083":"code","39d0bdba":"code","8f4ce1e9":"code","06c748fd":"code","96f5fa36":"code","2f304a24":"code","e87d5b9c":"code","fd124d91":"code","83977433":"code","397cb74e":"code","0a14ab45":"code","a99312f5":"code","509f8ae8":"code","ccb03d4c":"code","9bdb2c01":"code","168fbb66":"markdown"},"source":{"1dc901e6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n","0160e3ad":"#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    i=0\n    #print(filenames)\n    #print(os.path.join(dirname, filenames))\n    #for filename in filenames:\n    #    if(i>10):\n    #        break\n    #    print(os.path.join(dirname, filename))\n    #    print(filename)\n    #    i+=1\n\n# Any results you write to the current directory are saved as output.","08707303":"bs = 250\n# bs = 16   # uncomment this line if you run out of memory even after clicking Kernel->Restart","1a1a2400":"def readJSONFile(path):\n    import json\n    with open(path) as f:\n        data = json.load(f)\n    return data","d864a94b":"from fastai.vision import *\nfrom fastai.metrics import error_rate","b493d42c":"dataPath=Path('\/kaggle\/input\/iwildcam-2020-fgvc7')\n#dataPath=Path('c:\/Users\/manoj\/PycharmProjects\/data\/iwildcam-2020\/')\ndataPath.ls()","76508ff5":"jsonFilePath=dataPath\/'iwildcam2020_train_annotations.json'","f0201e09":"data = readJSONFile(jsonFilePath)\n\nannotations = data[\"annotations\"]\nimages=data[\"images\"]\ncategories = data[\"categories\"]\ninfo = data[\"info\"]\n\n# Convert to Data frame\n\nannotations = pd.DataFrame.from_dict(annotations)\nimages = pd.DataFrame.from_dict(images)\ncategories = pd.DataFrame.from_dict(categories)\n\n\n#Remove data from memory\ndel data\n\n#Create column image_id to use for merging the two data frames\nimages[\"image_id\"]  = images[\"id\"]\n\n# Merge annotations and images on image_id\n\ntrainDf1 = (pd.merge(annotations, images, on='image_id'))\n#Remove Unnecessary fields\ntrainDf1.drop([\"id_y\",\"id_x\"], axis = 1, inplace=True)\n\n#print(trainDf1.columns)\n\ntrainDf1 = pd.merge(trainDf1, categories.rename(columns={\"id\":\"category_id\"}), on=\"category_id\" )\n# Unset annotations and images dataframe as they are no longer needed\ndel annotations\ndel images\n","5f9de296":"categories[categories[\"id\"]==115 ]","02decc7e":"categories","6da2fe27":"trainDf1[[\"name\",\"category_id\"]]","bd7db6de":"df=trainDf1[[\"file_name\",\"category_id\"]]\ndf=df.rename(columns={\"file_name\":\"name\",\"category_id\":\"label\"})\n\n#df=trainDf1[[\"file_name\",\"name\"]]\n#df=df.rename(columns={\"file_name\":\"name\",\"name\":\"label\"})","220b50eb":"df","6832dc7b":"minSamples=1000\nduplicateDf=pd.DataFrame()\n\nfor label in df[\"label\"].unique():\n    length=0\n    \n    x=min\n    y=len(df[df[\"label\"]==label])\n    multiplier=1\n    if(y<minSamples):\n        multiplier=int(minSamples\/y)\n        y=y*multiplier\n    #length=y\n    #print(\"{} {} {}\".format(y, multiplier, length))\n    duplicateDf=duplicateDf.append([df[df[\"label\"]==label]]*multiplier,ignore_index=True)\n\ndf=duplicateDf","ece8012a":"df","7de19e85":"tfms = get_transforms(do_flip=False)\n\nfilePath=str(dataPath\/\"train\")\n\nimport os\nprint(os.getcwd())\nprint(filePath)\ndf","e4331245":"## Just to make sure that the Image data bunch selected is proper\n'''\ni=0\nwhile 1:\n    try:\n        np.random.seed(i)\n        data=ImageDataBunch.from_df(filePath, df, ds_tfms=tfms, size=224, bs=100)\n    except:\n        i+=1\n        if(i%100==0):\n            print(str(i) + \" did not work\")\n        continue\n    else: \n        print('Seed '+str(i)+' works')\n        break\n    break\n'''    ","466a5489":"\nnp.random.seed(25)\n#data = ImageDataBunch.from_df(\"\/home\/manoj\/Documents\/data\/data\/iwildcam-2020\/train\/28X28\",df, \ndata = ImageDataBunch.from_df(filePath\n                              , pd.DataFrame(df)\n                              , ds_tfms=tfms\n                              , size=200\n                              , valid_pct=.2\n                              , bs=bs)","311a187b":"categories[categories[\"id\"].isin([257, 229, 420, 306, 296, 402, 408, 420, 412])]","38394266":"data.show_batch(rows=3, figsize=(15,15))","ef6d4be7":"print(data.classes)\nlen(data.classes),data.c","4a703ec0":"learn = cnn_learner(data, models.resnet34, metrics=error_rate)\n#learn = cnn_learner(data, models.resnet50, metrics=error_rate)","d1f78afe":"learn.model","bca90865":"learn.fit_one_cycle(1)","4890de69":"learn.recorder.plot_losses()","a0d531fa":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","8bfd82fe":"interp.plot_top_losses(9, figsize=(15,11))","63a3b17a":"interp.plot_confusion_matrix(figsize=(12,12), dpi=60)","f555c444":"learn.unfreeze()","1cc78488":"learn.fit_one_cycle(10)","aa77de7f":"#jsonTestFilePath='\/home\/manoj\/Documents\/data\/data\/iwildcam-2020\/iwildcam2020_test_information.json'\njsonTestFilePath=dataPath\/'iwildcam2020_test_information.json'\ntestData = readJSONFile(jsonTestFilePath)\n\ntestImages=testData[\"images\"]\ntestCategories = testData[\"categories\"]\ntestInfo = testData[\"info\"]\n\n# Convert to Data frame\n\ntestImages = pd.DataFrame.from_dict(testImages)\ntestCategories = pd.DataFrame.from_dict(testCategories)\n\n#Remove data from memory\ndel testData, testInfo\n\n# Remove Unnecessary fields from images\ntestDf1 = pd.DataFrame(testImages.file_name)","54e20083":"testImages","39d0bdba":"#testPath=Path(\"\/home\/manoj\/Documents\/data\/data\/iwildcam-2020\/test\/100X100\")\ntestPath=dataPath\/'test'","8f4ce1e9":"#df=[ {\"file_name\":str(file).replace(str(testPath)+'\/',''), \"name\": learn.predict(open_image(file))[0] }\ndf=[ {\"file_name\":str(file).replace(str(testPath)+'\/',''), \"Id\": learn.predict(open_image(file))[0] }\n    for file in testPath.ls()[:]\n]","06c748fd":"df=pd.DataFrame(df)","96f5fa36":"df[\"file_name\"]=list(map(lambda x: os.path.basename(x), df[\"file_name\"]))\n","2f304a24":"jsonSubmissionFilePath=dataPath\/'sample_submission.csv'\nsubmission=pd.read_csv(jsonSubmissionFilePath)","e87d5b9c":"submission.drop(columns=[\"Category\"], inplace=True)\nsubmission","fd124d91":"testXref=testImages[[\"file_name\",\"id\"]]","83977433":"len(testXref)","397cb74e":"df.merge(testXref, on='file_name')","0a14ab45":"#df1=df.merge(testImages, on='file_name')[[\"id\",\"name\"]]\ndf1=df.merge(testXref, on='file_name')[[\"id\",\"Id\"]]\n#df1=df1.rename(columns={\"id\":\"Id\"})\ndf1=df1.rename(columns={\"Id\":\"Category\", \"id\":\"Id\"})","a99312f5":"df1","509f8ae8":"#df2=submission.merge(df1, on=\"Id\")[[\"Id\",\"Category\"]]\ndf2=submission.merge(df1, on=\"Id\")","ccb03d4c":"df2","9bdb2c01":"df2.to_csv(\"submission.2020040217.csv\", index=False)","168fbb66":"# To see if creating Duplicates improves the model\nI dont think this will improve the model by a lot. But I'm placing this here anyway"}}