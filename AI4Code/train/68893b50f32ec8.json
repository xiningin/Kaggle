{"cell_type":{"260c394e":"code","dcdba26a":"code","19ad6469":"code","19ef0683":"code","6352af5a":"code","72118284":"code","56924da0":"code","8ad44f98":"code","f7094994":"code","ef870635":"code","6f6454c1":"code","1fcc8bbc":"code","248349ca":"code","c5bbc246":"code","cd27efb8":"code","b4b2fc44":"code","537da01f":"code","2a1e6d2d":"code","bc1f1df9":"markdown"},"source":{"260c394e":"import torch\nfrom torch.utils.data import Dataset, DataLoader# For custom data-sets\nimport torchvision.transforms as transforms\nimport cv2\nimport numpy as np\nimport torchvision\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport os\nfrom PIL import Image\nimport torch.nn.functional as F\n\nimport scipy.ndimage.morphology as morph","dcdba26a":"path = \"..\/input\/pascal-voc-2012\/VOC2012\/ImageSets\/Segmentation\/train.txt\"\n \n#print(os.listdir(\"..\/input\/pascal-voc-2012\/VOC2012\/JPEGImages\"))\nf = open(path, \"r\").read().split('\\n')\nf = f[:1464]\nfolder_data = \"..\/input\/pascal-voc-2012\/VOC2012\/JPEGImages\"\nfolder_mask = \"..\/input\/pascal-voc-2012\/VOC2012\/SegmentationClass\"","19ad6469":"tfs = transforms.Compose([transforms.Resize((256, 256)),\n                   transforms.ToTensor()])\n","19ef0683":"img = Image.open(folder_data + \"\/\" + f[21] + \".jpg\").convert('RGB')\nseg = Image.open(folder_mask + \"\/\" + f[21] + \".png\").convert('RGB')\nresize = transforms.Resize((256, 256))\nseg = resize(seg)\nimg = resize(img)\ns = np.asarray(seg).tolist()\ns[200][200]  == [0, 0, 0]\n#seg\ns[200][200]\n","6352af5a":"seg","72118284":"img","56924da0":"class Segdata(Dataset):\n    def __init__(self):\n        self.img_paths = os.listdir(folder_data)\n        self.seg_paths = os.listdir(folder_mask)\n        self.transform = transforms.Compose([\n                                    transforms.Resize((256, 256)),\n                                    transforms.ToTensor()])\n        #self.resize = transforms.Resize((256, 256))\n        self.data = len(f)\n    \n    def __len__(self):\n        return len(f)\n    \n    def __getitem__(self,idx):\n        img = Image.open(folder_data + \"\/\" + f[idx] + \".jpg\").convert('RGB')\n        img = self.transform(img)\n        \n        seg = Image.open(folder_mask + \"\/\" + f[idx] + \".png\").convert('RGB')\n        seg = self.transform(seg)\n        \n        return img,seg\n        \n    ","8ad44f98":"dataset = Segdata()\ni,seg = dataset[6]\nimg = i.permute((1,2,0))\nmask= seg.permute((1,2,0))","f7094994":"plt.imshow(img)","ef870635":"plt.imshow(mask)","6f6454c1":"!pip install -U segmentation-models-pytorch albumentations --user","1fcc8bbc":"import segmentation_models_pytorch as smp","248349ca":"ENCODER = 'resnet18'\nENCODER_WEIGHTS = 'imagenet'\nACTIVATION = 'sigmoid'# could be None for logits or 'softmax2d' for multicalss segmentation\nDEVICE = 'cuda'\n\n# create segmentation model with pretrained encoder,here FPN you can use UNET and others\nmodel = smp.FPN(\n    encoder_name=ENCODER, \n    encoder_weights=ENCODER_WEIGHTS, \n    activation=ACTIVATION,\n)\n\npreprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)","c5bbc246":"train_dataset = Segdata()\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,num_workers=10)","cd27efb8":"loss = smp.utils.losses.DiceLoss()\nmetrics = [\n    smp.utils.metrics.IoU(threshold=0.5),\n]\n\noptimizer = torch.optim.Adam([ \n    dict(params=model.parameters(), lr=0.001),\n])","b4b2fc44":"train_epoch = smp.utils.train.TrainEpoch(\n    model, \n    loss=loss, \n    metrics=metrics, \n    optimizer=optimizer,\n    device=DEVICE,\n    verbose=True,\n)","537da01f":"max_score = 0\n\nfor i in range(0,15): #epochs = 15\n    \n    print('\\nEpoch: {}'.format(i))\n    train_logs = train_epoch.run(train_loader)","2a1e6d2d":"dataset = Segdata()\ni,seg = dataset[10]\nmask = seg.permute((1,2,0))\nout= model.predict(i.to(DEVICE).unsqueeze(0))\nprint(\"Original mask image\")\nplt.imshow(mask)\nplt.show()\nprint(\"predicted mask\")\nplt.imshow((out.squeeze().cpu().numpy().round()))","bc1f1df9":"Segmentation in least number of lines of code, thanks to repo https:\/\/github.com\/qubvel\/segmentation_models.pytorch, see the examples and how differnt architectures can be used.\nYou can also add augmentations to the data, chanfe the Segdata class accordingly."}}