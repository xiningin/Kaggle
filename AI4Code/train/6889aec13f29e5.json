{"cell_type":{"b9e1fcc5":"code","b1682a1c":"code","ab009a07":"code","cb05fdd6":"code","c1cd522f":"code","f7611083":"code","779dc16c":"code","40ae3b32":"code","93688269":"code","579ad856":"code","cc8c9020":"code","6e8a995b":"code","4908437d":"code","0664d15f":"code","398cc4c7":"code","55af7ef6":"code","9140b06b":"code","fd4172f0":"code","2bb5b550":"code","39de2365":"markdown","bcb0f2e1":"markdown","2e04c0d3":"markdown"},"source":{"b9e1fcc5":"import json\nimport numpy as np\nimport pandas as pd\nimport requests","b1682a1c":"srcsm_json = requests.get('https:\/\/storage.googleapis.com\/laurencemoroney-blog.appspot.com\/sarcasm.json')","ab009a07":"print(srcsm_json.text[0:500])","cb05fdd6":"sentences = []\nlabels = []\nfor item in srcsm_json.json():\n    sentences.append(item['headline'])\n    labels.append(item['is_sarcastic'])","c1cd522f":"sentences","f7611083":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(sentences,labels,test_size=0.25,random_state=42)","779dc16c":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","40ae3b32":"tokenizer = Tokenizer(num_words=10000,oov_token='OOV')\ntokenizer.fit_on_texts(X_train)\nword_index = tokenizer.word_index\nprint(word_index)","93688269":"vocal_size = 10000\noov_tok = '<oov>'\nmax_length = 100\ntrunc_type = 'post'\npadding_type = 'post'\n\nX_train = tokenizer.texts_to_sequences(X_train)\nX_train_padd = pad_sequences(X_train,maxlen=80,padding='post',truncating='post')\n\n\nX_test = tokenizer.texts_to_sequences(X_test)\nX_test_padd = pad_sequences(X_test,maxlen=80,padding='post',truncating='post')","579ad856":"from tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM,Bidirectional,Dense,Dropout","cc8c9020":"embedding_dim = 16\nmodel = Sequential()\nmodel.add(Embedding(vocal_size,embedding_dim,input_length = max_length))\nmodel.add(Bidirectional(LSTM(60)))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(45,activation='relu'))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])","6e8a995b":"X_train_padd = np.array(X_train_padd)\nX_test_padd = np.array(X_test_padd)\ny_train = np.array(y_train)\ny_test = np.array(y_test)","4908437d":"model.fit(X_train_padd,y_train,epochs=30,validation_data=(X_test_padd,y_test))","0664d15f":"metrices = pd.DataFrame(model.history.history)","398cc4c7":"import matplotlib.pyplot as plt\n%matplotlib inline\nmetrices[['loss','val_loss']].plot()","55af7ef6":"metrices[['accuracy','val_accuracy']].plot()","9140b06b":"sentence = [\"granny starting to fear spiders in the garden might be real\",\"game of thrones season finale showing this sunday night\"]\nsentence = tokenizer.texts_to_sequences(sentence)\npadded = pad_sequences(sentence,maxlen=max_length,padding=padding_type,truncating=trunc_type)\nprint(np.argmax(model.predict(padded)))","fd4172f0":"sentence = [\"Even some of the best life lessons we learn are from the most sarcastic quotes we read over the internet or from our dearest friends and family\",\"Although some people find it difficult to understand the hidden meaning of our sarcastic messages, others have no problem in finding the sense of it at all.\"]\nsentence = tokenizer.texts_to_sequences(sentence)\npadded = pad_sequences(sentence,maxlen=max_length,padding=padding_type,truncating=trunc_type)\nprint(np.argmax(model.predict(padded)))","2bb5b550":"model_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights(\"model.h5\")","39de2365":"**Saving the Model**","bcb0f2e1":"**Creating a Padded Sequences**","2e04c0d3":"**Try Some Predictions**"}}