{"cell_type":{"81fe7ec1":"code","5e6c1c93":"code","97ee3a88":"code","537ca55e":"code","e6961c1d":"code","284ca731":"code","908246b1":"code","c7def9c7":"code","dab38cb2":"code","932d7bc0":"code","cee8856e":"code","906b4406":"code","085429ce":"code","70adddfa":"code","abd9c292":"code","5b36c279":"code","dbf4bf27":"code","c1546561":"code","910b5fb5":"code","edfec1cf":"code","57ae59fa":"code","f966e2ec":"markdown","8613682d":"markdown","e2fbc929":"markdown","67dc4f6a":"markdown","db4d5bd1":"markdown","e5ee3ef8":"markdown"},"source":{"81fe7ec1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5e6c1c93":"# imports\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Input\nfrom sklearn.model_selection import train_test_split\n\nprint(f'Tf version: {tf.__version__}')","97ee3a88":"URL = 'https:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/00242\/ENB2012_data.xlsx'\n\n# pandas excel reader\ndf = pd.read_excel(URL)\ndf = df.sample(frac=1).reset_index(drop=True)","537ca55e":"df.head()","e6961c1d":"df.describe()","284ca731":"def format_output(data):\n    '''\n    Returns targets\n    '''\n    y1 = data.pop('Y1')\n    y2 = data.pop('Y2')\n    # convert to arrays\n    y1, y2 = np.array(y1), np.array(y2)\n    return y1, y2\n\ndef norm(x):\n    '''Normalize data'''\n    return (x - train_stats['mean']) \/ train_stats['std']\n\ndef plot_diff(y_true, y_pred, title=''):\n    plt.scatter(y_true, y_pred)\n    plt.title(title)\n    plt.xlabel('True Values')\n    plt.ylabel('Predictions')\n    plt.axis('equal')\n    plt.axis('square')\n    plt.xlim(plt.xlim())\n    plt.ylim(plt.ylim())\n    plt.plot([-100, 100], [-100, 100])\n    plt.show()\n\n\ndef plot_metrics(metric_name, title, ylim=5):\n    plt.title(title)\n    plt.ylim(0, ylim)\n    plt.plot(history.history[metric_name], color='blue', label=metric_name)\n    plt.plot(history.history['val_' + metric_name], color='green', label='val_' + metric_name)\n    plt.show()","908246b1":"df.head()","c7def9c7":"df.shape","dab38cb2":"# split data into train and test sets with 80\/20 split\ntrain, test = train_test_split(df, test_size=0.2)","932d7bc0":"train.shape","cee8856e":"train_stats = train.describe()","906b4406":"train_stats.pop('Y1')\ntrain_stats.pop('Y2')\ntrain_stats = train_stats.transpose()\ntrain_stats","085429ce":"train_Y = format_output(train)\ntest_Y = format_output(test)\n\n# normalize\nnorm_train_X = norm(train)\nnorm_test_X = norm(test)","70adddfa":"norm_train_X.shape","abd9c292":"# define model layers\ninput_layer = Input(shape=[len(train.columns)])\nfirst_dense = Dense(128, activation='relu')(input_layer)\nsecond_dense = Dense(128, activation='relu')(first_dense)\n\n# Y1 output\ny1_output = Dense(1, name='y1_output')(second_dense)\n\n# Y2 output\nthird_dense = Dense(64, activation='relu')(second_dense)\ny2_output = Dense(1, name='y2_output')(third_dense)\n\nmodel = Model(inputs=input_layer, outputs=[y1_output, y2_output])\n\nprint(model.summary())","5b36c279":"tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True)","dbf4bf27":"optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n\nmodel.compile(optimizer=optimizer,\n              loss={'y1_output': 'mse', 'y2_output': 'mse'},\n              metrics={'y1_output': tf.keras.metrics.RootMeanSquaredError(),\n                       'y2_output': tf.keras.metrics.RootMeanSquaredError()})","c1546561":"tf.keras.backend.clear_session()","910b5fb5":"history = model.fit(norm_train_X, train_Y,\n                    epochs=500, batch_size=10, validation_data=[norm_test_X, test_Y])","edfec1cf":"loss, Y1_loss, Y2_loss, Y1_rmse, Y2_rmse = model.evaluate(x=norm_test_X, y=test_Y)\n\nprint(f\"Loss: {loss:.2f}, Y1_loss: {Y1_loss:.2f}, Y2_loss: {Y2_loss:.2f},\\nY1_rmse: {Y1_rmse:.2f}, Y2_rmse: {Y2_rmse:.2f}\")","57ae59fa":"# Plot the loss and mse\nY_pred = model.predict(norm_test_X)\nplot_diff(test_Y[0], Y_pred[0], title='Y1')\nplot_diff(test_Y[1], Y_pred[1], title='Y2')\nplot_metrics(metric_name='y1_output_root_mean_squared_error', title='Y1 RMSE', ylim=6)\nplot_metrics(metric_name='y2_output_root_mean_squared_error', title='Y2 RMSE', ylim=7)","f966e2ec":"## Evaluate Model and Plot Metrics","8613682d":"## Build the Model\n\nBuild the model using the functional API.","e2fbc929":"## Configure Parameters and Train Model","67dc4f6a":"### Prepare data","db4d5bd1":"## Utilities\n\nDefine a few utility functions for data conversion and plotting.","e5ee3ef8":"## Data\n\nEnergy efficiency Data Set (UCI)"}}