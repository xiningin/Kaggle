{"cell_type":{"0a47b7b1":"code","ecf004b7":"code","08b526af":"code","d4e2204d":"code","4662e3e5":"code","c8ebddbf":"code","b878d731":"code","7f42a2c9":"code","d597a089":"code","43c89f07":"code","900223f7":"code","ac44f8d9":"code","9b45b4d7":"code","6f0055da":"code","28c7d0b2":"code","033cd1be":"code","3be15d4e":"code","3d331a85":"code","7a8a05cb":"code","5e3ed83c":"markdown","20115fd8":"markdown","a8746f19":"markdown","0b3b7a59":"markdown","47bec16f":"markdown","009769b4":"markdown","9c7702d6":"markdown","98ad4dbc":"markdown","54c3ed61":"markdown","f79ac1c9":"markdown"},"source":{"0a47b7b1":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import norm, skew\n#\nimport torch\nfrom torch.autograd import Variable\nfrom sklearn.preprocessing import StandardScaler\nimport torch.nn as nn \nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ecf004b7":"data = pd.read_csv(\"\/kaggle\/input\/brasilian-houses-to-rent\/houses_to_rent_v2.csv\")\ndata.head()","08b526af":"data.info()","d4e2204d":"data = data[data.floor != \"-\"]\ndata.floor = data.floor.astype(np.int64)","4662e3e5":"data.info()","c8ebddbf":"data = data.sample(frac=1)","b878d731":"features = [\"floor\",\"bathroom\",\"rooms\",\"area\",\"parking spaces\",'hoa (R$)', 'rent amount (R$)', 'property tax (R$)', 'fire insurance (R$)','total (R$)']\nskew_list = []\nfor i in features:\n    skew_list.append(skew(data[i]))\n# So, features are good at skewness \nskew_list","7f42a2c9":"features = [\"floor\",\"bathroom\",\"rooms\",\"area\",\"parking spaces\",'hoa (R$)', 'rent amount (R$)', 'property tax (R$)', 'fire insurance (R$)','total (R$)']\nfor item in features:\n    data[item] = np.log1p(data[item])","d597a089":"features = [\"floor\",\"bathroom\",\"rooms\",\"area\",\"parking spaces\",'hoa (R$)', 'rent amount (R$)', 'property tax (R$)', 'fire insurance (R$)','total (R$)']\nskew_list = []\nfor i in features:\n    skew_list.append(skew(data[i]))\n# So, features are good at skewness \nskew_list","43c89f07":"f,ax = plt.subplots(figsize = (20,7))\nsns.distplot(data[\"total (R$)\"], fit=norm);","900223f7":"data = pd.get_dummies(data,drop_first=True)\ndata.head()","ac44f8d9":"y = data[[\"total (R$)\"]]\nx = data.drop([\"total (R$)\"],axis=1)","9b45b4d7":"# Creating Train and Test Datasets\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)","6f0055da":"sc_x = StandardScaler()\nx_train_scaled = sc_x.fit_transform(x_train)\nx_test_scaled = sc_x.transform(x_test)","28c7d0b2":"sc_y = StandardScaler()\ny_train_scaled = sc_y.fit_transform(y_train)\ny_test_scaled = sc_y.transform(y_test)","033cd1be":"x_train_scaled = np.array(x_train_scaled,dtype=np.float32)\ny_train_scaled = np.array(y_train_scaled,dtype=np.float32)","3be15d4e":"# Convert inputs and targets to tensors\ninputs = torch.from_numpy(x_train_scaled)\ntargets = torch.from_numpy(y_train_scaled)","3d331a85":"# create class\nclass LinearRegression(nn.Module):\n    def __init__(self,input_size,output_size):\n        # super function. It inherits from nn.Module and we can access everythink in nn.Module\n        super(LinearRegression,self).__init__()\n        # Linear function.\n        self.linear = nn.Linear(input_dim,output_dim)\n\n    def forward(self,x): # x:inputs\n        return self.linear(x)\n    \n# define model\ninput_dim = 15\noutput_dim = 1\nmodel = LinearRegression(input_dim,output_dim) # \n\n# MSE\nmse = nn.MSELoss()\n\n# Optimization (find parameters that minimize error)\nlearning_rate = 0.02   # how fast we reach best parameters\noptimizer = torch.optim.SGD(model.parameters(),lr = learning_rate)\n\n# train model\nloss_list = []\niteration_number = 500\nfor iteration in range(iteration_number):\n        \n    # optimization\n    optimizer.zero_grad() \n    \n    # Forward to get output\n    results = model(inputs)\n    \n    # Calculate Loss\n    loss = mse(results, targets)\n    \n    # backward propagation\n    loss.backward()\n    \n    # Updating parameters\n    optimizer.step()\n    \n    # store loss\n    loss_list.append(loss.data)\n    \n    # print loss\n    if(iteration % 50 == 0):\n        print('epoch {}, loss {}'.format(iteration, loss.data))\n\nplt.plot(range(iteration_number),loss_list)\nplt.xlabel(\"Number of Iterations\")\nplt.ylabel(\"Loss\")\nplt.show()","7a8a05cb":"input_x_test = torch.from_numpy(x_test_scaled)\npredicted = model(input_x_test.float()).data.numpy()","5e3ed83c":"## Houses to rent data\n\n<hr> \n\n<br>**Content:**\n1. [Load Libraries and Dataset](#1)\n1. [Feature Engineering](#2)\n1. [Linear Regression](#3)","20115fd8":"## Log Transformations","a8746f19":"## Split Dataset","0b3b7a59":"## Dataset Shuffle","47bec16f":"<a id=\"1\"><\/a> <br>\n## Load Libraries and Dataset","009769b4":"## One-Hot Encoder","9c7702d6":"## Prediction","98ad4dbc":"## Observe Normalization","54c3ed61":"<a id=\"3\"><\/a> <br>\n## Linear Regression","f79ac1c9":"<a id=\"2\"><\/a> <br>\n## Feature Engineering"}}