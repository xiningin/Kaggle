{"cell_type":{"b40ca797":"code","76570fd5":"code","7dc2ca67":"code","1678b269":"code","323924af":"code","e54c6ecb":"code","ec64b034":"code","b3a60b54":"code","78692433":"code","1e4275e9":"code","8b0a9988":"code","420dd057":"code","8df73a70":"code","9fa062cd":"code","c6e1d8e4":"code","f5cd04d1":"code","8ae8ecf3":"code","1a721823":"code","1947dcbc":"code","40d28be5":"code","a6896bb4":"code","2ce01bc8":"code","95d44503":"code","2fd8624c":"code","3d318c76":"code","2cd31f9c":"code","3c388a9f":"code","ab0b9a0a":"code","7c61bf8c":"code","a057ebc7":"code","c870e06b":"code","3241f6d2":"code","b84b995f":"code","1954ead2":"code","ec5ac1f6":"code","76eb27bd":"code","80dee57c":"markdown","869d728a":"markdown","74dc7dbc":"markdown","a707ac61":"markdown","dff92c2c":"markdown","d617f338":"markdown","2321d036":"markdown","c21495db":"markdown","b13efb66":"markdown"},"source":{"b40ca797":"#Import required python libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n","76570fd5":"data = pd.read_csv(\"..\/input\/data.csv\", index_col=0)","7dc2ca67":"data.head()","1678b269":"data.info()","323924af":"data = data.drop(['Unnamed: 32'], axis =1)","e54c6ecb":"data.head()","ec64b034":"data.shape","b3a60b54":"data.isna().any().head() #Check for Missing data ","78692433":"sns.countplot(x = 'diagnosis', data = data).set_title('Histogram plot for both type of diagnosis')","1e4275e9":"data.describe()","8b0a9988":"sns.pairplot(data, hue = 'diagnosis',palette='coolwarm')","420dd057":"dataM=data[data['diagnosis'] == \"M\"]\ndataB=data[data['diagnosis'] == \"B\"]","8df73a70":"sns.kdeplot(dataM.texture_mean, shade=True, label= \"M\");\nsns.kdeplot(dataB.texture_mean, shade=True, label= \"B\");","9fa062cd":"sns.kdeplot(dataM.radius_mean, shade=True, label= \"M\");\nsns.kdeplot(dataB.radius_mean, shade=True, label= \"B\");","c6e1d8e4":"sns.kdeplot(dataM.area_mean, shade=True, label= \"M\");\nsns.kdeplot(dataB.area_mean, shade=True, label= \"B\");","f5cd04d1":"sns.kdeplot(dataM.perimeter_mean, shade=True, label= \"M\");\nsns.kdeplot(dataB.perimeter_mean, shade=True, label= \"B\");","8ae8ecf3":"sns.kdeplot(dataM.smoothness_mean, shade=True, label= \"M\");\nsns.kdeplot(dataB.smoothness_mean, shade=True, label= \"B\");","1a721823":"sns.kdeplot(dataM.compactness_mean, shade=True, label= \"M\");\nsns.kdeplot(dataB.compactness_mean, shade=True, label= \"B\");","1947dcbc":"sns.kdeplot(dataM.concavity_mean, shade=True, label= \"M\");\nsns.kdeplot(dataB.concavity_mean, shade=True, label= \"B\");","40d28be5":"sns.kdeplot(dataM['concave points_mean'], shade=True, label= \"M\");\nsns.kdeplot(dataB['concave points_mean'], shade=True, label= \"B\");","a6896bb4":"sns.kdeplot(dataM['symmetry_mean'], shade=True, label= \"M\");\nsns.kdeplot(dataB['symmetry_mean'], shade=True, label= \"B\");","2ce01bc8":"sns.kdeplot(dataM['fractal_dimension_mean'], shade=True, label= \"M\");\nsns.kdeplot(dataB['fractal_dimension_mean'], shade=True, label= \"B\");","95d44503":"train_data = data[0:400]\ntrain_data.shape","2fd8624c":"test_data = data[400:]\ntest_data.shape","3d318c76":"from scipy import stats\nfrom sklearn import linear_model\nlogreg = linear_model.LogisticRegression(solver='liblinear')","2cd31f9c":"data.columns","3c388a9f":"logreg.fit(train_data[['radius_mean','texture_mean', 'perimeter_mean','area_mean', 'smoothness_mean', 'compactness_mean', \n                         'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']],\n         train_data['diagnosis']);\nslopes_list = logreg.coef_\nu = logreg.intercept_","ab0b9a0a":"print(slopes_list,u)","7c61bf8c":"predicted_diag = logreg.predict(test_data[['radius_mean','texture_mean', 'perimeter_mean', 'area_mean','smoothness_mean', 'compactness_mean', \n                         'concavity_mean', 'concave points_mean','symmetry_mean', 'fractal_dimension_mean']]);","a057ebc7":"data_predicted = test_data.copy()\ndata_predicted [\"Predicted_diagnosis\"] = predicted_diag.tolist()\ndata_predicted[['diagnosis','Predicted_diagnosis']].head()","c870e06b":"fig,ax =plt.subplots(1,2)\nsns.countplot(data_predicted['Predicted_diagnosis'], ax=ax[0]).set_title('Predictive modelling using all 10 mean parameters')\nsns.countplot(data_predicted['diagnosis'], ax=ax[1])","3241f6d2":"test_prediction_accuracy = (data_predicted[\"Predicted_diagnosis\"] == data_predicted['diagnosis']).sum()*100\/169\ntest_prediction_accuracy","b84b995f":"data1 = data.copy()\nlogreg.fit(train_data[['texture_mean', 'perimeter_mean', 'smoothness_mean', 'compactness_mean', \n                         'concavity_mean', 'symmetry_mean']],\n         train_data['diagnosis']);\nslopes_list1 = logreg.coef_\nu1 = logreg.intercept_\nprint(slopes_list1,u1)\n","1954ead2":"prediction2= logreg.predict(test_data[['texture_mean', 'perimeter_mean', 'smoothness_mean', 'compactness_mean', \n                                       'concavity_mean', 'symmetry_mean']]);\ndata_predicted [\"Predicted_diagnosis2\"] = prediction2.tolist()\ndata_predicted[['diagnosis','Predicted_diagnosis','Predicted_diagnosis2']].head()","ec5ac1f6":"test_prediction_accuracy2 = (data_predicted[\"Predicted_diagnosis2\"] == data_predicted['diagnosis']).sum()*100\/169\ntest_prediction_accuracy2","76eb27bd":"fig,ax =plt.subplots(1,2)\nsns.countplot(data_predicted['diagnosis'], ax=ax[0])\nsns.countplot(data_predicted['Predicted_diagnosis2'], ax=ax[1])\n","80dee57c":"# Problem\nThe data set contains diagnostic information of Stage of Breast Cancer (Malignant or Benign) of 569 patients.  \nIt has the following information: \n1. Patient ID\n2. Stage of Breast Cancer (M = Malignant, B = Benign)\n3. Columns 3-32 contain 10 real valued features listed below with their respective Mean (Cols 3-13), Standard Error(Cols 13-23) and Worst (Cols 23-32)\n\n    a) radius (mean of distances from center to points on the perimeter)\n    b) texture (standard deviation of gray-scale values)\n    c) perimeter\n    d) area\n    e) smoothness (local variation in radius lengths)\n    f) compactness (perimeter^2 \/ area - 1.0)\n    g). concavity (severity of concave portions of the contour)\n    h). concave points (number of concave portions of the contour)\n    i). symmetry\n    j). fractal dimension (\"coastline approximation\" - 1)\n\nI want to develop a basic Machine Learning model to predict the Stage of Breast Cancer based on these above mentioned 10 variables, visualize the known data along with predicted to check for accuracy of the model and test data predcition.  ","869d728a":"From the correlation of all the mean parameters and also from the visualiation of distribution of mean values of paramters (for both ``M`` and ``B`` cases), we can make the following observations:\n\n1. Strong correlation among radius_mean, perimeter_mean and area_mean, and also similar distribution of these three parameters clearly indicate that they have similar impact on the diagnosis. \n2. Also, same holds for concavity mean and concave points_mean. \n3. The distribution of fractal_dimension_mean almost overlaps for ``M`` and ``B`` cases, which indicates that diagnosis is hardly dependant on this particular parameter.","74dc7dbc":"# Analysis and modelling (Trial )\n\nFor the second trial, I am using all the mean values of texture, perimeter, smoothness, compactness, concavity, and symmtery. Again, LogisticRegression has been used to fit and predict the data.\n\nSimilarly the test and train data has 400 and 169 enteries as Trial 1. ","a707ac61":"# Result (Trial 1) \nAccuracy of prediction for Trial 1 is ~89.9%","dff92c2c":"Let's remove the empty column \"Unamed: 32'","d617f338":"# Analysis and modelling (Trial 1)\n\nFor the first trial, I am using all the mean values as parameter variables for predictional modelleing. \nLogisticRegression has been used to fit and predict the data.\n\nThere are 569 enteries in this data, I am using first 400 for predicition and the remaining 169 for testing the prediction. \nIn a similar way, as we did for the cryptocurrency example in the last class. \n\nThis problem has been done by hundreds of kaggle users, but my approach is very basic here. I am using all the 10 mean parameter values even though some of them are highly correlated among themselves (for eg. radius, perimeter and area .. so are concavity and concave points )","2321d036":"Steps I followed:\n1. Read the data, clean, sort and inspect.\n2. Analyzing correlation between variables.\n3. Apply ML methods\n    3.1 Split the test & train data\n    3.2 Trained a logistic regression model to build a classification model and fit  data\n    3.3 Visualize to compare the accuracy of the used method\n4. Test Dataset Prediction\n5. There are in all 30 features in the data Mean values of the above listed 10 parameters, their Std. errors, and worst values. How can one leverage all this information to develop a better model. Do we need a dimension reduction or the insights derived from correlation among features is good enough.  ","c21495db":"# Result (Trial 2) \nAccuracy of prediction for Trial 1 is ~91.1%","b13efb66":"Visualization distribution of each of the diagnostic image parameter mean values for ``M`` and ``B`` cases.  "}}