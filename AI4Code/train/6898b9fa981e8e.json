{"cell_type":{"2c13e1de":"code","26486caa":"code","898aea6f":"code","9390e4b2":"code","2d1cd27c":"code","48fbdd25":"code","f7610491":"code","60926271":"code","16aadde2":"code","f6ffb857":"markdown","54676187":"markdown","ce0b4990":"markdown","051282f5":"markdown","af1a9735":"markdown","b088e3ad":"markdown","a5e0e92e":"markdown","e19cbbe6":"markdown","f54a9651":"markdown","b4d2ee09":"markdown","8ad4175d":"markdown","7020f339":"markdown"},"source":{"2c13e1de":"import numpy as np # Linear Algebra\nimport pandas as pd \nimport matplotlib.pyplot as plt #Nice graphs\nfrom mpl_toolkits.mplot3d import Axes3D","26486caa":"observations=1000\nxs=np.random.uniform(low=-10,high=10,size=(observations,1))\nzs=np.random.uniform(low=-10,high=10,size=(observations,1))\n#size = n(no. of observations)*k(no. of variables)\ninputs=np.column_stack((xs,zs))\ninputs.shape","898aea6f":"noise=np.random.uniform(-1,1,(observations,1))\ntargets=2*xs-3*zs+5+noise\ntargets.shape","9390e4b2":"targets=targets.reshape(observations,)\nxs=xs.reshape(observations,)\nzs=zs.reshape(observations,)\nfig=plt.figure()\nax=fig.add_subplot(111,projection='3d')\nax.plot3D(xs,zs,targets)\nax.set_xlabel('xs')\nax.set_ylabel('zs')\nax.set_zlabel('Targets')\nax.view_init(azim=100)\nplt.show()\ntargets=targets.reshape(observations,1)","2d1cd27c":"init_range=0.1 #initial weights and biases will be picked randomly from interval [-0.1,0.1]\nweights=np.random.uniform(-init_range,init_range,size=(2,1))\nbiases=np.random.uniform(-init_range,init_range,size=1) #there are as many biases as there are outputs\n\n#Set Learning Rate\nlearning_rate=0.02","48fbdd25":"for i in range(100):\n    outputs=np.dot(inputs,weights)+biases\n    deltas=outputs-targets\n    \n    loss=np.sum(deltas**2)\/2\/observations\n    '''loss\/obser.=mean loss --> division by constant doesn't \n    change the logic of loss,as it is still lower for higher accuracy'''\n    print(loss) # to keep eye wheter it is decreasing\n    \n    delta_scaled=deltas\/observations\n    \n    weights=weights-learning_rate*np.dot(inputs.T,delta_scaled)\n    biases=biases-learning_rate*np.sum(delta_scaled)","f7610491":"print(weights,biases)\n# check with [w1,w2,w3]=[2,-3,5]","60926271":"plt.scatter(outputs,targets)\nplt.plot(outputs,targets,color='r')\nplt.xlabel('outputs')\nplt.ylabel('targets')\nplt.show()","16aadde2":"x=list((int(input(\"Enter x: \")),int(input(\"Enter z: \"))))\ny_predict=(weights[0]*x[0]+weights[1]*x[1]+np.ceil(biases))\ny=(2*x[0]-3*x[1]+5)\nprint('Y_predict: ',int(y_predict),' y:',y)\nprint('Error %:',(abs(y_predict-y)\/y)*100)","f6ffb857":"### Importing the relevant libraries","54676187":"**y_predict=2*x-3*z+5**","ce0b4990":"### Print weights and biases  \nto see if we have worked correctly","051282f5":"### Generate random input data to train","af1a9735":"### Initialize Variables  \nwe don't want to start from any arbitrary number. Rather, we randomly Select small initial weights.","b088e3ad":"### Plot Last Outputs vs Targets  \nsince they are the last ines at the end of the training they represent thje final model accuracy.  \nthe closer this plot is to 45**\u00b0** line,closer the target and output values are.","a5e0e92e":"2 variable linear model : f(x,z)=a*x+b*z+c","e19cbbe6":"### Train the Model \n  We will use (L2-norm loss)\/2   \n**runs for 100 iterations each time,** \n  _  \n  **\"more times we iterate this, more accurate the weights and biases become\"**  \n    \n  \n$$\n L(Output,targets)=\\left(\\frac{L_2~norm}{2} \\right)=\\frac{\\sum_i\\left({Outputs-targets} \\right)^2}{2}\\\\Delta=(Outputs-targets)\n$$\n  \n$$\nb_{i+1}=b_i-(Learning~rate*\\sum_i\\left({Outputs-targets}\\right)\\\\W_{i+1}=W_i-(Learning~rate*\\sum_i\\left({x_i*(Outputs-targets)}\\right)\n$$","f54a9651":"### Create the targets","b4d2ee09":"### Plot the training data  \nto see that there is a strong trend that the model should learn to reproduce.","8ad4175d":" we will aim at:  \n**targets=f(x,z)=2*x-3*z+5+noise**  \n  \n[w1,w2,b]=[2,-3,5]  \n  \nthis is chosen completely arbitrarily,noise is to randomise  \nConceptually,the algorithm must learn this is the function","7020f339":"### Making Predictions  \n  **y=2*x-3*z+5**  \n  $$\n  Error : \\frac{(y\\_predict-y)*100}{y} \n  $$"}}