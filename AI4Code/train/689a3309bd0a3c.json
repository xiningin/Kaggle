{"cell_type":{"16ae126e":"code","d67d8380":"code","8ebd401a":"code","ddb113aa":"code","87eda096":"code","4e5f635e":"code","2a4b9b81":"code","a20b8e06":"code","c9f0384e":"code","12e2bd34":"code","6fa358e1":"code","16fca9a0":"code","36a9ed09":"code","84d3ce02":"code","7670aad1":"code","15110cc4":"code","f93e518b":"code","960cba47":"code","3c94a600":"code","5be6e38f":"code","525aa0a0":"code","487c7de6":"code","94765d2c":"code","f1af58d2":"code","2f1751e8":"code","960a686f":"code","52dbc5f2":"code","ef343df8":"code","c91170c3":"code","31d9a7ac":"code","2c0252f1":"code","5857aa08":"code","337a4c6f":"code","92035ccd":"code","3946d9b3":"code","6b051a51":"code","21a1220f":"code","849f86be":"code","3362e997":"code","fd7388d3":"code","e683c2c5":"code","9eb2c3ed":"markdown","f61e281e":"markdown","95b5d9fa":"markdown","e0aee65c":"markdown","72ee4453":"markdown","6708b801":"markdown","56af8c4e":"markdown","805210b5":"markdown","8eae87a2":"markdown","6dedfd5e":"markdown","5b42133a":"markdown","b4552171":"markdown","19ccb4cb":"markdown","165c073c":"markdown","2c234ea5":"markdown","2f0ed703":"markdown","2ccd9e07":"markdown","c1fb2156":"markdown","0637d036":"markdown","7cef6c9f":"markdown","62f1e24d":"markdown","9483be0e":"markdown"},"source":{"16ae126e":"# For Data operations\nimport numpy as np\nimport pandas as pd\n\n# For Viz's\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# For removing warnings (if any)\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# For basic statistics\nfrom scipy import stats\n\n# For Machine Learning\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score","d67d8380":"co2data = pd.read_csv(\"..\/input\/FuelConsumption.csv\",index_col='MODELYEAR')","8ebd401a":"co2data.head()","ddb113aa":"co2data.describe(include='all')","87eda096":"#co2data.MAKE.value_counts()  \n## Quick look at MAKE variable. This doesn't sound a good variable for regression analysis","4e5f635e":"co2data.VEHICLECLASS.value_counts()  \n## This could be potential variable.  Perhaps, we can group the data by Mid Size, Large Size etc","2a4b9b81":"co2data.CYLINDERS.value_counts() ## Potential variable ","a20b8e06":"#co2data.TRANSMISSION.value_counts() \n## Not a potential variable","c9f0384e":"co2data.FUELTYPE.value_counts()  ## Potential variable","12e2bd34":"sns.swarmplot(x='FUELTYPE',y='CO2EMISSIONS',data=co2data)","6fa358e1":"sns.swarmplot(x='CYLINDERS',y='CO2EMISSIONS',data=co2data)","16fca9a0":"sns.boxplot(x='MAKE',y='CO2EMISSIONS',data=co2data)","36a9ed09":"sns.boxplot(x='VEHICLECLASS',y='CO2EMISSIONS',data=co2data)","84d3ce02":"sns.boxplot(x='TRANSMISSION',y='CO2EMISSIONS',data=co2data)","7670aad1":"sns.boxplot(x='FUELTYPE',y='CO2EMISSIONS',data=co2data)","15110cc4":"sns.boxplot(x='CYLINDERS',y='CO2EMISSIONS',data=co2data)","f93e518b":"df = co2data[['FUELTYPE','CYLINDERS','ENGINESIZE','FUELCONSUMPTION_COMB','CO2EMISSIONS']]","960cba47":"def categorise(a):\n    if a == 'Z':\n        return 1\n    elif a == 'D':\n        return 2\n    elif a == 'X':\n        return 3\n    else:\n        return 4","3c94a600":"df['FUELTYPE_CAT'] = df['FUELTYPE'].apply(lambda x : categorise(x))","5be6e38f":"sns.pairplot(df)","525aa0a0":"df.corr()","487c7de6":"sns.heatmap(co2data.corr(),annot=True,cmap='coolwarm')","94765d2c":"sns.lmplot('ENGINESIZE','CO2EMISSIONS',df,order=1)","f1af58d2":"sns.lmplot('FUELCONSUMPTION_COMB','CO2EMISSIONS',df)","2f1751e8":"sns.lmplot('ENGINESIZE','CO2EMISSIONS',hue='CYLINDERS',data=df)","960a686f":"sns.lmplot('FUELCONSUMPTION_COMB','CO2EMISSIONS',hue='CYLINDERS',data=df)","52dbc5f2":"sns.residplot('ENGINESIZE','CO2EMISSIONS',df,color='g')","ef343df8":"sns.residplot('FUELCONSUMPTION_COMB','CO2EMISSIONS',df,color='g')","c91170c3":"def thresh_pvalue(p_value):\n    if p_value <= 0.001:\n        print(\"The p_value is {:f} is less than threshold of 0.001 and is strong fit for regression analysis\".format(float(p_value)))\n    elif ((p_value > 0.001) & (p_value < 0.05)):\n        print(\"The p_value is {:f} is less than threshold of 0.05 and greater than 0.001 and is moderate fit for regression analysis\".format(float(p_value)))\n    elif ((p_value > 0.05) & (p_value < 0.1)):\n        print(\"The p_value is {:f} is less than threshold of 0.1  and greater than 0.05 abd is a weak fit for regression analysis\".format(float(p_value)))\n    else:\n        print(\"The p_value is {:f} is greater than 0.1 and is not a good fit for regression analysis\".format(float(p_value)))","31d9a7ac":"pearson_coef, p_value = stats.pearsonr(df['ENGINESIZE'], df['CO2EMISSIONS'])\nprint(\"The Pearson Correlation Coefficient is\", pearson_coef, \" with a P-value of P =\", p_value) \nthresh_pvalue(p_value)","2c0252f1":"pearson_coef, p_value = stats.pearsonr(df['CYLINDERS'], df['CO2EMISSIONS'])\nprint(\"The Pearson Correlation Coefficient is\", pearson_coef, \" with a P-value of P =\", p_value) \nthresh_pvalue(p_value)","5857aa08":"pearson_coef, p_value = stats.pearsonr(df['FUELCONSUMPTION_COMB'], df['CO2EMISSIONS'])\nprint(\"The Pearson Correlation Coefficient is\", pearson_coef, \" with a P-value of P =\", p_value) \nthresh_pvalue(p_value)","337a4c6f":"from sklearn import linear_model\nfrom sklearn.model_selection import train_test_split\n\n\n## Instantaniate linear regression constructor\nregr = linear_model.LinearRegression()\n\n## Define Predictors\nPredictors = ['FUELTYPE_CAT','ENGINESIZE','CYLINDERS','FUELCONSUMPTION_COMB']\nx = df[['FUELTYPE_CAT','ENGINESIZE','CYLINDERS','FUELCONSUMPTION_COMB']]\ny = df['CO2EMISSIONS']\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n\n\n## Fit the model\na = regr.fit (x_train, y_train)\n\n# The coefficients and intercept\nprint(\"The Y-Intercept is\",regr.intercept_, \" with the slope value of \", regr.coef_)\n\n## Run the prediction\ny_hat= regr.predict(x_test[Predictors])\n\n\n# Print residual errors\nprint(\"Mean absolute error: %.2f\" % np.mean(np.absolute(y_hat - y_test)))\nprint(\"Residual sum of squares (MSE): %.2f\" % np.mean((y_hat - y_test) ** 2))\nrmse = np.sqrt(mean_squared_error(y_test,y_hat))\nprint(\"Root Mean Squared Error: {}\".format(rmse))\n#print(\"R2-score: %.2f\" % r2_score(y_hat , y_test) )\nprint(\"R^2-score: %.2f\" % regr.score(x_test , y_test) )\n\n#print(a.summary())","92035ccd":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\n\n## Define Predictors\nPredictors = ['FUELTYPE_CAT','ENGINESIZE','CYLINDERS','FUELCONSUMPTION_COMB']\nx = df[['FUELTYPE_CAT','ENGINESIZE','CYLINDERS','FUELCONSUMPTION_COMB']]\ny = df['CO2EMISSIONS']\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n\n## Fit the model\npoly = PolynomialFeatures(degree=5)\ntrain_x_poly = poly.fit_transform(x_train)\n\nclf = LinearRegression()\ntrain_y_ = clf.fit(train_x_poly, y_train)\n\n# The coefficients\nprint ('Coefficients: ', clf.coef_)\nprint ('Intercept: ',clf.intercept_)\n\n## Run the prediction\ntest_x_poly = poly.fit_transform(x_test)\ntest_y_ = clf.predict(test_x_poly)\n\n# Print residual errors\nprint(\"Mean absolute error: %.2f\" % np.mean(np.absolute(test_y_ - y_test)))\nprint(\"Residual sum of squares (MSE): %.2f\" % np.mean((test_y_ - y_test) ** 2))\nprint(\"R2-score: %.2f\" % r2_score(test_y_ , y_test) )\n#print(\"R^2-score: %.2f\" % regr.score(x_test , y_test) )\n\n#rmse = np.sqrt(mean_squared_error(y_test,y_hat))\n#print(\"Root Mean Squared Error: {}\".format(rmse))\n#print(\"R2-score: %.2f\" % r2_score(y_hat , y_test) )\n","3946d9b3":"final_df = pd.DataFrame(x_test)\nfinal_df.columns = Predictors\nfinal_df['CO2EMISSIONS'] = y_test\nfinal_df['CO2EMISSIONS_PRE'] = test_y_  ## Replace yHat with test_y_ to enable polynomial values\nfinal_df.head()","6b051a51":"ax2 = sns.distplot(df['CO2EMISSIONS'],color='b',hist=True,label='Actual')\nsns.distplot(y_hat,color='r',label='Predicted',hist=True,ax=ax2)","21a1220f":"sns.distplot((y_hat-y_test), color='r')","849f86be":"sns.regplot(y_test, y_hat)","3362e997":"ax2 = sns.distplot(df['CO2EMISSIONS'],color='b',hist=True,label='Actual')\nsns.distplot(test_y_,color='r',label='Predicted',hist=True,ax=ax2)","fd7388d3":"sns.distplot((test_y_-y_test), color='r')","e683c2c5":"sns.regplot(y_test, test_y_)","9eb2c3ed":"### Quick look at box plots to confirm IQR for Catergorical variables","f61e281e":"#### Converting the fuel types to numerical categorical variabled","95b5d9fa":"#### A healthy correlation was noted on above graphs.  There is spread noted when Cylinder is added to the LMPLOT.  Given that Cylinder is impact the regression we should consider this for better prediction","e0aee65c":"#### Describe the data to check quick stats","72ee4453":"#### Import  Libraries","6708b801":"#### MODEL FITTING POLYNOMIAL REGRESSION","56af8c4e":"#### Looking at value counts , we can determine the categorical variables along with numerical cont variables that are requred\n#### CAT VARIABLES > CYLINDERS, FUELTYPE\n####  NUM CONT VARIABLES > ENGINESIZE, FUEL_CONSUMPTION_COMB\n#### All the variables above are independent variabled that can be used to predict CO2 Emissions of the given car\n\n** Because of large set of data points <b>FuelType<\/b> will add value in the anaylsis","805210b5":"#### Since the points are sparsely dispersed , Enginesize is a good canditate for linear regression analysis","8eae87a2":"#### Looking at the data above the key features can be determined \n#### 1) Categorical Variable and 2) Continous Variables\n#### Categorical Variables : Make, Vehicle Class , Cylinders, Transmission,  FuelType  (Make, Vehicle Class and Transmission will still need to analysed if these are required for regression analysis)\n#### Continous numerical variables : EngineSize, Fuel Consumption (City, Highway and Combined)","6dedfd5e":"#### Try looking at LM plots with HUE as Cylinders given that its a good categorical variable and would help further regression analysis","5b42133a":"#### Predicted values for test dataset","b4552171":"## Polynomial Regression Model Prediction","19ccb4cb":"#### A quick look at residual plots","165c073c":"### Subsetting the data frame","2c234ea5":"#### For cylinders there is no overlap on the IQR , hence this is potential variable that can be used. Remaining all are pretty much overalpping. There won't be a big difference if we add rest of tge varaibles for analysis","2f0ed703":" # Model fits very well for Polynomial regression","2ccd9e07":"#### Read the data set","c1fb2156":"#### MODEL FITTING MULTI LINEAR REGRESSION","0637d036":"#### Hence, all three are good for regression analysis to get correct picture\/model for prediction","7cef6c9f":"### Pearson's correlation (P-Values)","62f1e24d":"## Linear Regression Model Prediction","9483be0e":"## <font color='r'> Regression Model to PREDICT CO2 Emissions for Cars <\/font>"}}