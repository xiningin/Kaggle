{"cell_type":{"6bbcf268":"code","97d940ae":"code","c37be4e4":"code","6225bbda":"code","a8fd2df7":"code","1ee3c7b2":"code","efae4496":"code","a4724bd7":"code","b43bb2b0":"code","7061496f":"code","24b8226c":"code","21dea6f8":"code","7c93e187":"code","603d31a1":"code","3ad1811d":"code","30653f64":"code","ad8a7c41":"code","694a5162":"code","07e2f0cf":"code","52ea30f6":"code","dbbb5f79":"code","3a260bc2":"code","1bda98ca":"code","48b45ef7":"code","fb74d2a9":"code","eeaf6e7c":"code","005fda69":"code","3c977a9d":"code","4be04082":"code","c1375bf7":"code","6827512a":"code","a37cb515":"code","8debaf50":"code","61d67d49":"code","71537f79":"code","d5f62600":"code","01ef34c1":"code","8f63e8be":"code","dd017bf3":"code","02bd9fc4":"code","574464ec":"code","6cacd335":"code","4d9c64b4":"code","94da4edc":"code","cfd7ea02":"code","2f995417":"code","e19138c1":"code","426889e7":"markdown","7c993a01":"markdown","6893803b":"markdown","a6cb3615":"markdown","952ea0c5":"markdown","3b131de9":"markdown","b42df7ff":"markdown","fdb755ea":"markdown","0459c29d":"markdown","c32edbe4":"markdown","02cc3819":"markdown","03140892":"markdown","5444b154":"markdown","69e72976":"markdown","7e3b426e":"markdown","357ba8ad":"markdown","36934294":"markdown","422c39a1":"markdown","2ed8a310":"markdown","de7a358a":"markdown","86437db4":"markdown","8f0807e2":"markdown","2b02c4b7":"markdown"},"source":{"6bbcf268":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","97d940ae":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","c37be4e4":"data = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")","6225bbda":"data.head() #Display the first 5 rows","a8fd2df7":"data['Class'].value_counts() # count unique values in class clumns","1ee3c7b2":"data.columns #All columns of dataset","efae4496":"data.info() #Information about the dataset like number of null values and data types","a4724bd7":"data.isnull().sum() # Function return the total number of null values for each columns","b43bb2b0":"data[data.duplicated()] # Display all the duplicates rows","7061496f":"data.duplicated().sum() #Returns total number of duplicates rows of our dataset","24b8226c":"data = data.drop_duplicates(keep='first') #Keep the first rows and drop the duplicates rows","21dea6f8":"data.duplicated().sum()#Check for is still duplicates values are there or not","7c93e187":"data = data.drop(\"Time\",axis=1) #Drop the time columns, for this model time columns are not importance","603d31a1":"data.describe() #Function display the count,mean,std,min,max and quartiles values","3ad1811d":"plt.figure(figsize=(29,13))\ncor = data.drop(\"Class\",axis=1).corr()\nsns.heatmap(cor,annot = True)\nplt.show()","30653f64":"def correlation(dataset,threshold):\n    col_corr = set()\n    corr_matrix = dataset.corr()\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if abs(corr_matrix.iloc[i,j])>threshold:\n                colname = corr_matrix.columns[i]\n                col_corr.add(colname)\n    return col_corr","ad8a7c41":"corr_fea = correlation(data.drop(\"Class\",axis=1),0.8)\nprint(corr_fea)","694a5162":"x = data.drop(\"Class\",axis=1)\ny = data['Class']","07e2f0cf":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)","52ea30f6":"print(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","dbbb5f79":"from sklearn.linear_model import LogisticRegression","3a260bc2":"classifier = LogisticRegression(solver='liblinear',random_state = 0)","1bda98ca":"classifier.fit(x_train,y_train)","48b45ef7":"log_y_pred = classifier.predict(x_test)","fb74d2a9":"print(log_y_pred)","eeaf6e7c":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, log_y_pred)\nprint(cm)","005fda69":"from sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10)\nprint(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))","3c977a9d":"from sklearn.metrics import accuracy_score\nlog_acc_score = accuracy_score(y_test, log_y_pred)\nprint(log_acc_score)","4be04082":"from sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nclassifier.fit(x_train, y_train)","c1375bf7":"knn_y_pred = classifier.predict(x_test)","6827512a":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, knn_y_pred)\nprint(cm)\n","a37cb515":"plt.figure(figsize=(6,6))\nplt.title('Confusion matrix on test data')\nsns.heatmap(cm, annot=True, fmt='d', cmap=plt.cm.Greens, cbar=False)\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.show()","8debaf50":"acc_score = accuracy_score(y_test, knn_y_pred)\nprint(f\"Accuracy score by KNN model is: {acc_score}\")","61d67d49":"from sklearn.svm import SVC\nclassifier = SVC(kernel = 'rbf', random_state = 0)\nclassifier.fit(x_train, y_train)","71537f79":"svm_y_pred = classifier.predict(x_test)","d5f62600":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, svm_y_pred)\nprint(cm)","01ef34c1":"acc_score_svm = accuracy_score(y_test, svm_y_pred)\nprint(f\"Accuracy score by KNN model is: {acc_score_svm}\")","8f63e8be":"from sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(x_train, y_train)","dd017bf3":"naive_y_pred = classifier.predict(x_test)\nprint(naive_y_pred)","02bd9fc4":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, naive_y_pred)\nprint(cm)","574464ec":"acc_score_naive = accuracy_score(y_test, naive_y_pred)\nprint(f\"Accuracy score by KNN model is: {acc_score_naive}\")","6cacd335":"from sklearn.tree import DecisionTreeRegressor\nregressor = DecisionTreeRegressor(random_state = 0)\nregressor.fit(x_train,y_train)","4d9c64b4":"dtr_y_pred = regressor.predict(x_test)","94da4edc":"dtr_cm = confusion_matrix(y_test, naive_y_pred)\nprint(dtr_cm)","cfd7ea02":"dtr_acc =accuracy_score(y_test,dtr_y_pred)\nprint(f\"Accuracy score by DTR is: {dtr_acc}\")","2f995417":"mylist=[]\nmylist2=[]\nmylist.append(log_acc_score)\nmylist2.append(\"Logistic Regression\")\nmylist.append(acc_score)\nmylist2.append(\"KNN\")\nmylist.append(acc_score_svm)\nmylist2.append(\"SVM\")\nmylist.append(acc_score_naive)\nmylist2.append(\"Naive Bayes\")\nmylist.append(dtr_acc)\nmylist2.append(\"DTR\")","e19138c1":"plt.rcParams['figure.figsize']=8,6\nsns.set_style(\"darkgrid\")\nax = sns.barplot(x=mylist2, y=mylist, palette = \"rocket\", saturation =1.5)\nplt.xlabel(\"Regressor Models\", fontsize = 20 )\nplt.ylabel(\"Accuracy\", fontsize = 20)\nplt.title(\"Accuracy of different Regreesor Models\", fontsize = 20)\nplt.xticks(fontsize = 11, horizontalalignment = 'center', rotation = 8)\nplt.yticks(fontsize = 13)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(f'{height:.2%}', (x + width\/2, y + height*1.02), ha='center', fontsize = 'x-large')\nplt.show()","426889e7":"# Load the dataset","7c993a01":"# Making the Confusion Matrix","6893803b":"**By this correlation we give threshold value 0.8 and we trying to find is any columns are correlated with each other,if correlated then we drop any of this**","a6cb3615":"# Training the Naive Bayes model on the Training set","952ea0c5":"# Feature selection","3b131de9":"# confusion matrix","b42df7ff":"# Training the Kernel SVM model on the Training set","fdb755ea":"# Training the K-NN model on the Training set","0459c29d":"# import the dataset, here x is independent and y represented as dependent variable","c32edbe4":"# Predicting the Test set results","02cc3819":"# Computing the accuracy with k-Fold Cross Validation","03140892":"![](https:\/\/c.tenor.com\/eds_JFXceWoAAAAC\/aww-sweet.gif)","5444b154":"# Predicting the Test set results","69e72976":"# Training the Decision Tree Regression model on training dataset","7e3b426e":"# Logistic Regression","357ba8ad":"# Confusion matrix and accuracy","36934294":"# Making the Confusion Matrix","422c39a1":"# Visualization of all model that are applied in this dataset, by bar chart","2ed8a310":"![](https:\/\/www.debt.org\/wp-content\/uploads\/2012\/12\/Credit-Card.gif)","de7a358a":"# Import the libraries","86437db4":"# Predicting the Test set results","8f0807e2":"# Splitting the dataset into the Training set and Test set","2b02c4b7":"**Training the Logistic Regression model on the Training set**"}}