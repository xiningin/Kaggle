{"cell_type":{"ee7dfe24":"code","5ef07d57":"code","86eb904e":"code","2589e7c4":"code","e3c3cc72":"code","93e1d511":"code","0135967c":"code","b117cd9a":"code","4b117ba2":"code","b4d2b7db":"code","1a5ba873":"code","b250f080":"code","0c68b213":"code","5ab62fa1":"code","92d6f936":"code","07e39c4d":"code","245c6977":"code","bf5ce9cd":"code","adaa1628":"code","cf8fa69f":"code","d6721b8a":"code","928cb4ef":"code","da61d40e":"code","610317b6":"code","ca33359f":"code","77424e43":"code","5fa18004":"code","80dcb114":"code","d0d13118":"code","ecf9a001":"code","c6904bbe":"code","52d64315":"code","9a89b2f4":"code","735bc5c9":"code","2a238a43":"code","a5e9d9f8":"code","a5ce9759":"code","1ae45efb":"markdown","8b21de40":"markdown","44b79cf6":"markdown","10ead3d5":"markdown","db05f779":"markdown","ce3f954f":"markdown","069c5d1f":"markdown","0062eee5":"markdown","f504cecb":"markdown","803b624c":"markdown","fc47e33a":"markdown","97f4f7bc":"markdown","31c4dfc8":"markdown","15a1a2a0":"markdown","619d078b":"markdown","c6024632":"markdown","3816ad1f":"markdown","e31f481d":"markdown","1bf12853":"markdown","c5bac672":"markdown","d80efd1f":"markdown","64cb8390":"markdown","463e1f85":"markdown","d80c482a":"markdown","a42cd22c":"markdown","c719296b":"markdown","ea507922":"markdown"},"source":{"ee7dfe24":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfrom pathlib import Path\ndata = {}\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        data[filename] = Path(dirname) \/ filename\n\n# Any results you write to the current directory are saved as output.\ndata","5ef07d57":"from IPython.display import (\n    Markdown as md,\n    Latex,\n    HTML,\n)\nfrom tqdm.auto import tqdm","86eb904e":"tweets = pd.read_csv(data[\"twitter_sentiment_data.csv\"])","2589e7c4":"display(tweets.shape)","e3c3cc72":"value_counts = tweets[\"sentiment\"].value_counts()\nvalue_counts.name = \"Raw Number\"\n\nvalue_normd = tweets[\"sentiment\"].value_counts(normalize=True)\nvalue_normd.name = \"Percentage\"\n\ndisplay(pd.concat([value_counts, value_normd], axis=1))","93e1d511":"display(tweets.head())","0135967c":"from copy import deepcopy\neda = deepcopy(tweets)\n# tqdm.pandas()","b117cd9a":"sentiment_num2name = {\n    -1: \"Anti\",\n     0: \"Neutral\",\n     1: \"Pro\",\n     2: \"News\",\n}\neda[\"sentiment\"] = eda[\"sentiment\"].apply(lambda num: sentiment_num2name[num])\neda.head()","4b117ba2":"from matplotlib import pyplot as plt\nfrom matplotlib import style\n\nimport seaborn as sns\n\nsns.set(font_scale=1.5)\nstyle.use(\"seaborn-poster\")","b4d2b7db":"fig, axes = plt.subplots(1, 2, figsize=(20, 10), dpi=100)\n\nsns.countplot(eda[\"sentiment\"], ax=axes[0])\nlabels = list(sentiment_num2name.values())\n\naxes[1].pie(eda[\"sentiment\"].value_counts(),\n            labels=labels,\n            autopct=\"%1.0f%%\",\n            startangle=90,\n            explode=tuple([0.1] * len(labels)))\n\nfig.suptitle(\"Distribution of Tweets\", fontsize=20)\nplt.show()","1a5ba873":"import re\nimport nltk\nimport itertools","b250f080":"top15 = {}\n\nby_sentiment = eda.groupby(\"sentiment\")\nfor sentiment, group in tqdm(by_sentiment):\n    hashtags = group[\"message\"].apply(lambda tweet: re.findall(r\"#(\\w+)\", tweet))\n    hashtags = itertools.chain(*hashtags)\n    hashtags = [ht.lower() for ht in hashtags]\n    \n    frequency = nltk.FreqDist(hashtags)\n    \n    df_hashtags = pd.DataFrame({\n        \"hashtags\": list(frequency.keys()),\n        \"counts\": list(frequency.values()),\n    })\n    top15_htags = df_hashtags.nlargest(15, columns=[\"counts\"])\n    \n    top15[sentiment] = top15_htags.reset_index(drop=True)\n\ndisplay(pd.concat(top15, axis=1).head(n=10))","0c68b213":"fig, axes = plt.subplots(2, 2, figsize=(28, 20))\ncounter = 0\n\nfor sentiment, top in top15.items():\n    sns.barplot(data=top, y=\"hashtags\", x=\"counts\", palette=\"Blues_d\", ax=axes[counter \/\/ 2, counter % 2])\n    axes[counter \/\/ 2, counter % 2].set_title(f\"Most frequent Hashtags by {sentiment} (Visually)\", fontsize=25)\n    counter += 1\nplt.show()","5ab62fa1":"def cleaner(tweet):\n    tweet = tweet.lower()\n    \n    to_del = [\n        r\"@[\\w]*\",  # strip account mentions\n        r\"http(s?):\\\/\\\/.*\\\/\\w*\",  # strip URLs\n        r\"#\\w*\",  # strip hashtags\n        r\"\\d+\",  # delete numeric values\n        r\"U+FFFD\",  # remove the \"character note present\" diamond\n    ]\n    for key in to_del:\n        tweet = re.sub(key, \"\", tweet)\n    \n    # strip punctuation and special characters\n    tweet = re.sub(r\"[,.;':@#?!\\&\/$]+\\ *\", \" \", tweet)\n    # strip excess white-space\n    tweet = re.sub(r\"\\s\\s+\", \" \", tweet)\n    \n    return tweet.lstrip(\" \")","92d6f936":"eda[\"message\"] = eda[\"message\"].apply(cleaner)\neda.head()","07e39c4d":"from nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer \nfrom nltk.corpus import stopwords, wordnet  ","245c6977":"def lemmatizer(df):\n    df[\"length\"] = df[\"message\"].str.len()\n    df[\"tokenized\"] = df[\"message\"].apply(word_tokenize)\n    df[\"parts-of-speech\"] = df[\"tokenized\"].apply(nltk.tag.pos_tag)\n    \n    def str2wordnet(tag):\n        conversion = {\"J\": wordnet.ADJ, \"V\": wordnet.VERB, \"N\": wordnet.NOUN, \"R\": wordnet.ADV}\n        try:\n            return conversion[tag[0].upper()]\n        except KeyError:\n            return wordnet.NOUN\n    \n    wnl = WordNetLemmatizer()\n    df[\"parts-of-speech\"] = df[\"parts-of-speech\"].apply(\n        lambda tokens: [(word, str2wordnet(tag)) for word, tag in tokens]\n    )\n    df[\"lemmatized\"] = df[\"parts-of-speech\"].apply(\n        lambda tokens: [wnl.lemmatize(word, tag) for word, tag in tokens]\n    )\n    df[\"lemmatized\"] = df[\"lemmatized\"].apply(lambda tokens: \" \".join(map(str, tokens)))\n    \n    return df","bf5ce9cd":"eda = lemmatizer(eda)\neda.head()","adaa1628":"plt.figure(figsize=(15, 15))\nsns.boxplot(x=\"sentiment\", y=\"length\", data=eda, palette=(\"Blues_d\"))\nplt.title(\"Tweet Length Distribution for each Sentiment\")\nplt.show()","cf8fa69f":"from sklearn.feature_extraction.text import CountVectorizer","d6721b8a":"frequency = {}\n\nby_sentiment = eda.groupby(\"sentiment\")\nfor sentiment, group in tqdm(by_sentiment):\n    cv = CountVectorizer(stop_words=\"english\")\n    words = cv.fit_transform(group[\"lemmatized\"])\n    \n    n_words = words.sum(axis=0)\n    word_freq = [(word, n_words[0, idx]) for word, idx in cv.vocabulary_.items()]\n    word_freq = sorted(word_freq, key=lambda x: x[1], reverse=True)\n    \n    freq = pd.DataFrame(word_freq, columns=[\"word\", \"freq\"])\n    \n    frequency[sentiment] = freq.head(n=25)\n\nto_view = pd.concat(frequency, axis=1).head(n=25)\ndisplay(to_view)","928cb4ef":"words = {sentiment: \" \".join(frequency[sentiment][\"word\"].values) for sentiment in sentiment_num2name.values()}\n\ncmaps = {\n    \"Anti\": (\"Reds\", 110),\n    \"Pro\" : (\"Greens\", 73),\n    \"News\": (\"Blues\", 0),\n    \"Neutral\": (\"Oranges\", 10),\n}\n\nfrom wordcloud import WordCloud\n\nwordclouds = {}\nfor sentiment, (cmap, rand) in tqdm(cmaps.items()):\n    wordclouds[sentiment] = WordCloud(\n        width=800, height=500, random_state=rand,\n        max_font_size=110, background_color=\"white\",\n        colormap=cmap\n    ).generate(words[sentiment])\n    \nfig, axes = plt.subplots(2, 2, figsize=(28, 20))\ncounter = 0\n\nfor sentiment, wordcloud in wordclouds.items():\n    axes[counter \/\/ 2, counter % 2].imshow(wordcloud)\n    axes[counter \/\/ 2, counter % 2].set_title(sentiment, fontsize=25)\n    counter += 1\n    \nfor ax in fig.axes:\n    plt.sca(ax)\n    plt.axis(\"off\")\n\nplt.show()","da61d40e":"import spacy\nspacy_en = spacy.load('en')","610317b6":"def crude_entities(tweet):\n    as_words = tweet.apply(spacy_en)\n    \n    def by_label(words, label):\n        filtered = [word.text for word in words.ents if word.label_ == label]\n        return filtered\n    \n    def get_top(label, n=10):\n        thing = as_words.apply(lambda x: by_label(x, label))\n        flattened = itertools.chain(*thing.values)\n        \n        counter = Counter(flattened)\n        topN = counter.most_common(n)\n        \n        topN_things = [thing for thing, _ in topN]\n        \n        return thing\n    \n    entities = pd.DataFrame()\n    entities[\"people\"] = get_top(\"PERSON\", n=10)\n    entities[\"geopolitics\"] = get_top(\"GPE\", n=10)\n    entities[\"organizations\"] = get_top(\"ORG\")\n    \n    return entities","ca33359f":"from collections import Counter","77424e43":"entities = {}\n\nby_sentiment = eda.groupby(\"sentiment\")\n\nfor sentiment, group in tqdm(by_sentiment):\n    entities[sentiment] = crude_entities(group[\"lemmatized\"])\n    \ndisplay(pd.concat(entities, axis=1).head(n=10))","5fa18004":"# Preprocessing\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer \nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\n\n# Building classification models\nfrom sklearn.svm import LinearSVC\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n# Model evaluation\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score","80dcb114":"X_all = tweets[\"message\"]\ny_all = tweets[\"sentiment\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.25, random_state=1337)\n\nX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.25, random_state=1337)","d0d13118":"tfidf = TfidfVectorizer()\ntfidf.fit_transform(X_train)","ecf9a001":"def train(tfidf, model, train_data, train_labels, test_data):\n    model.fit(tfidf.transform(train_data), train_labels)\n    preds = model.predict(tfidf.transform(test_data))\n    \n    return preds","c6904bbe":"def grade(model, preds, test_labels):\n    print(metrics.classification_report(test_labels, preds))\n    \n    cm = confusion_matrix(test_labels, preds)\n    cm_normd = cm \/ cm.sum(axis=1).reshape(-1, 1)\n    \n    heatmap_kwargs = dict(\n        cmap=\"YlGnBu\",\n        xticklabels=model.classes_,\n        yticklabels=model.classes_,\n        vmin=0.,\n        vmax=1.,\n        annot=True,\n        annot_kws={\"size\": 10},\n    )\n    \n    sns.heatmap(cm_normd, **heatmap_kwargs)\n    \n    plt.title(f\"{model.__class__.__name__} Classification\")\n    plt.ylabel(\"Ground-truth labels\")\n    plt.xlabel(\"Predicted labels\")\n    plt.plot()","52d64315":"def train_and_grade(tfidf, model, train_data, train_labels, test_data, test_labels):\n    preds = train(tfidf, model, train_data, train_labels, test_data)\n    grade(model, preds, test_labels)","9a89b2f4":"rf = RandomForestClassifier(max_depth=5, n_estimators=100)\ntrain_and_grade(tfidf, rf, X_train, y_train, X_valid, y_valid)","735bc5c9":"nb = MultinomialNB()\ntrain_and_grade(tfidf, nb, X_train, y_train, X_valid, y_valid)","2a238a43":"knn = KNeighborsClassifier(n_neighbors=5, metric=\"minkowski\", p=2)\ntrain_and_grade(tfidf, knn, X_train, y_train, X_valid, y_valid)","a5e9d9f8":"logreg = LogisticRegression(C=1, class_weight=\"balanced\", max_iter=1000)\ntrain_and_grade(tfidf, logreg, X_train, y_train, X_valid, y_valid)","a5ce9759":"svm_lsvc = LinearSVC(class_weight=\"balanced\")\ntrain_and_grade(tfidf, svm_lsvc, X_train, y_train, X_valid, y_valid)","1ae45efb":"### Observations:\n\n- The top 3 buzzwords are **climate**, **change**, and **rt** (retweet). This seems to indicate that a lot of the same information is being shared\/viewed \u2013\u00a0this applies across all `sentiments`. While we can't conclude that's a result of the \"filter bubble\", it certainly seems like that might be a latent (hidden) cause.\n- Interestingly, **trump** occurs across all cases. This may not be surprising given his presidency during the timeframe the Tweets were recorded \u2013\u00a0this is something that likely warrants further investigation especially along the axes of **Neutral** and **Pro**.\n- Words like **real**, **believe**, **think**, and **fight** occur quite frequently in the **Pro** `sentiment`. Interestingly, both the **Pro** and **Anti** sentiment seem to be saying **science** and **scientist**, which seems indicative that both sides believe their quoting accurate, reproduced, research. \n- Take a look at the table above, you'll see the **http** actually shows up in the **Pro** `sentiment` quite frequently. This would imply that links are being shared alongside the Tweets quite frequently. Contrast that with the other `sentiment`s \u2013 particularly, **News**. Why might this be the case?","8b21de40":"### Observations:\n\n- SVM is able to quite successfully classify Tweets.\n- Based on the CM above, you can see there are pretty clear boundaries across all the `sentiments`.\n- Interestly, the SVM seems more confused about what should be classified as **Pro** than even Logistic Regression.\n- The trade-off of classifying **Pro** tweets, though, still leads to gains in properly classifying the majority of our data correctly.","44b79cf6":"### Observations:\n\n- From the Confusion Matrix above, you can see that the model strictly predicts the **Pro** `sentiment`. This is likely due to the balance of data, but since we haven't tested that, we can't quite conclude that.\n- Looking at the Precision\/Recall\/F1 Score, for the **Anti**, **Neutral**, and **News** `sentiment`s, you'll see they're all 0.\n- Tree-based methods are prone to overfitting on imbalanced data, like what we have. However, we could potentially re-sample so the training data has a more uniform spread of each `sentiment` to test if that's truly the problem with our `RandomForestClassifier`.\n- Our overall F1 score is 0.52, which if you recall from our earlier visualizations, matches the %-age of **Pro** `sentiment` Tweets.","10ead3d5":"`pd.DataFrame.head` gives us the first 5 (by default) rows of the `tweets` DataFrame. This gives us a preview of the kinds of data we have in `tweets`.","db05f779":"## The Buzzwords\n\nBelow, we'll compute the frequency of words for each `sentiment`. Following that, we'll build `WordCloud`s to visualize these words.\n\n`WordCloud`s convey importance through opacity, so the more translucent a word, the less frequently it appears.","ce3f954f":"`pd.DataFrame[\"column\"].value_counts` returns an enumeration over all the unique values and how many times that value appears in the `pd.DataFrame`.","069c5d1f":"# Cursory Analysis\n\nWe'll start out by loading up the Twitter Sentiment Data and doing a bit of exploration to get a feel for what's going on with the data.","0062eee5":"### Observations:\n\n- An improvement of Random Forests, but it still performs pretty poorly.\n- It still classifies most Tweets with the **Pro** `sentiment`.\n- Precision, Accuracy, and F1 Scores, though, have signifcantly improved across the other `sentiments`.\n- While Na\u00efve Bayes performs better, it's performance is likely hampered by the balance of data we have.","f504cecb":"First up, I have a strong aversion to keeping track of numeric keys. So let's replace all numeric values with the appropriate **labels**, given by the dataset.","803b624c":"## Support Vector Machines (Linear SVC)\n\nWith SVMs we plot our data in $n$-dimensional space ($n$ is the number of features) so that each feature is created as a coordinate on an axis. The goal of SVMs to create the best decision boundary between all the features (this gets hard to visualize past $n=3$. This decision boundary is also called the hyperplane.\n\nSVM typically uses extreme points\/vectors to help in creating the Hyperplane. These vectors are called \"Support Vectors\". Peep the image below for an idea of what's going on.\n\n![](https:\/\/static.javatpoint.com\/tutorial\/machine-learning\/images\/support-vector-machine-algorithm.png)","fc47e33a":"**What is TFIDF?** Essentially, it assigns word frequency scores. These scores _try_ to highlight words of greater interest \u2013 you can get at this idea by looking at in-document frequency vs across-document frequency. The `TFIDFVectorizer` will tokenize the documents, learn the vocabulary and \"inverse document frequency wegihtings\", and allow you to encode new documents.","97f4f7bc":"# Modeling!\n\nTime to build our sentiment classifiers! We'll be \"vectorizing\" our text data before passing it through to our model. We need to vectorize our data for similar reasons to why we have ASCII and Unicode. Machines don't understand letters and words, but numeric values are their bread-and-butter.\n\nWe'll start out by looking at 5 models:\n- Random Forests\n- Na\u00efve Bayes\n- K-Nearest Neighbors\n- Logistic Regression\n- Support Vector Machines (Linear SVC)","31c4dfc8":"Next, since Twitter uses Hashtags almost like a summarization feature (at least in the sense of highlighting core ideas). So let's look at some of top hashtags for each of the classes of `sentiment`. We'll then make \"word clouds\" to visualize their prominence.","15a1a2a0":"### Observations:\n\n- The most popular hashtags are, broadly, **climate** and **climatechange**. Which is expected, given the topic; but also, among the top 3 are relating to **trump** and his campaign slogan **maga**.\n- The **BeforeTheFlood** hashtag refers to a 2016 documentary where Leonardo DiCaprio met with scientists, activists, and word leaders to discuss the dangers of climate and and possible solutions.\n- **COP22**, **ParisAgreement**, and **Trump** in the **Pro** `sentiment` are likely related to the formal process Trump's administrastion began to exit the Paris Agreements, where north of 200 nations pledged to reduce greenhour gas emissions, assist developing nations, and assist [poor] nations struggling with the consequences of a warming Earth.\n- Interestingly, **auspol** (short for Australian Politics) made the shortlist of the **Pro** `sentiment`. This is likeyl attributed to an assessment published quantifying the role of climate change in Australian brushfires and their increaseed risk of occuring.","619d078b":"Now that we've computing the frequency, let's generate and plot the WordClouds for each `sentiment`.","c6024632":"# KnightHack 4 ~ Climate Change Tweets Sentiment Analysis\n## A Survey of Different Models to do Sentiment Analysis\n\nby: [John Muchovej](john.muchovej.com)","3816ad1f":"The following functions `train`, `grade`, and `train_and_grade` are helper functiosn to make life easier and practice DRY.","e31f481d":"## Na\u00efve Bayes\n\nNa\u00efve Bayes leverages Bayes Theorem to make classifications. This assumes that independent variables are statistically independent from one another.\n\n$$P(A | B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}$$\n\nLet's break this down:\n- $P(A|B)$ is the posterior \u2013 our prediction of the likelihood of $A$, given we've observed $B$\n- $P(A)$ is the likelihood of $A$\n- $P(B|A)$ is the likelihood of $B$, given we've observed $A$\n- $P(B)$ is the likelihood of $B$\n\nSo, in summary, we're taking a known, $P(B|A)$ combining it with the liklihood that $A$ even happens, then we're \"re-normalizing it\" in terms of $B$.\n\n### Na\u00efve Bayes' 3 Classification Methods\n- **Gaussian**: often used in classfication tasks and *assumes* a Normal Distribution (the \"bell curve\")\n- **Bernoulli**: a \"binomial\" model \u2013 this is useful if you have a binary classification (e.g. `True`\/`False`)\n- **Multinomial**: used for discrete counts. In our case, instead of looking at \"is the word in the document\" (a Bernoulli view), we instead cound the frequency of the word in the document.","1bf12853":"## K-Nearest Neighbors\n\nKNN uses \"feature similarity\" to predict the values of new data points. Basically, it looks at the $K$ nearest points of the data point given, and computes a similarity between them.\n\nYou can compute the similarity with a variety of measures, e.g. Euclidean, Manhattan (good for Continuous), and Hamming (good for Categorial) distances.\n\n![](https:\/\/adrianromano.com\/wp-content\/uploads\/2019\/02\/A-typical-example-of-a-KNN-classification-for-a-two-class-problem-ie-the-pink-and.png)","c5bac672":"`pd.DataFrame.shape` returns a tuple of (# rows, # columns, ...). This tells us that we have ~44K Tweets (or rows) and each Tweet has 3 features (or columns).","d80efd1f":"### Observations:\n\n- KNN improves over both Na\u00efve Bayes and Random Forests.\n- It still leans **Pro** on classification, but you'll notice that it actually has greater diversity in classification, overall.","64cb8390":"### Observations:\n\n- Logistic Regression does quite well, especially compared to the previous models.\n- The Precision, Recall, and F1-scores of all non-**Pro** classes is still trending upwards, which is good.","463e1f85":"## Your professors don't give you test answers, there's a reason\n\nAs with every Supervised Learning task, we need to split our data into (at least) Training and Validation sets. Typically, data will be given to you as a `Training` and `Testing` sets; but in our case, we have one massive CSV, so we need to make that split ourselves.\n\nThese splits allow us to train our model, but also give us the ability to test it's performance on data it _shouldn't have seen_. (This is a problem known as \"data leakage\" \u2013 try to avoid it.)","d80c482a":"## [Multinomial] Logistic Regression (Classification)\n\nMultinomial Logistic Regression is a generalization of Logistic Regression, so that it can handle multiple classes. Typically Logistic Regression does well when you linearly separate the classes in question. Like Na\u00efve Bayes and Random Forests, it's very sensitive to the class balance.","a42cd22c":"## Random Forests\n\nRandom Forests are a tree-based Machine Learning algorithm that leverages the power of multiple Decision Trees. Decision trees work essentially like `if-elif-else` control flow, but the metric for each decision boundary is \"information gain\". The Forest component is pretty lackluster, you're taking a bunch of Decision Trees and \"planting them together\" to build a Forest.\n\nA visual representation of Random Forests:\n\n![](https:\/\/kevintshoemaker.github.io\/NRES-746\/rf.png)\n\nRetrieved from [here](https:\/\/kevintshoemaker.github.io\/NRES-746).","c719296b":"## Some Crude Entity Extraction\n\nSo, this is an entire field of NLP \u2013\u00a0entity extraction. We're going to use `spacy`, a pretty great NLP library. We're to extract the following:\n- People\n- Geopolitical Regions\n- Organizations\n\nFor this particular dataset, we're looking to these factors as there's probably some causal relationship between them. Importantly, this might not tell us how these Tweeters would land on the spectrum of support, but it can tell us the most highly focused organizations, geopolitical regions, and influencers\/people in advocating for\/against \"Human-driven Climate Change\".","ea507922":"# EDA (Exploratory Data Analysis)\n\n**Before we pick up on our analysis, let's make a copy of the `pd.DataFrame` so we can feed `tweets` into our models later.**\n\nWe're going to start an Exploratory Data Analysis **(EDA)**. The first step of any Machine Learning project is to develop an understanding of your data, as that will help with model selection later on."}}