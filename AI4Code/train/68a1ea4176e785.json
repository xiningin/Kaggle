{"cell_type":{"b339fb93":"code","dff25024":"code","4b636382":"code","388107f7":"code","9118344f":"code","d6d43dbb":"code","af92586f":"code","8a18713f":"code","8874e92d":"code","c47aaf25":"code","f9bba406":"code","eab5c8d0":"code","80ce410d":"code","57f051e8":"code","3dfcf7d5":"code","01b1c8c2":"code","cbbf781a":"code","81f21495":"code","39e41344":"code","9dd36fd4":"code","ccff9167":"code","0925b73a":"code","197444f6":"code","88f311c6":"code","45797948":"code","e89b0e65":"code","f5eb7ea3":"code","88fc4ab2":"code","1efc2938":"code","1a6d06aa":"markdown"},"source":{"b339fb93":"%reset -sf","dff25024":"import numpy as np\n\naction_domain = np.linspace(0,1,100+1)\nrounding_err = 10**-9\n\n\ndef is_equal(a,b):\n    # to address float values\n    return abs(a-b) < rounding_err\n\n\ndef u_h(x):\n    # the amount impact given for spending x effort to help\n    # should be an increasing function with decreasing gradient\n    assert 0 <= x <= 1\n    return 2*x - x**2\n\n\ndef u_r(x):\n    # the amount impact retained after spending x effort to help\n    # should be an increasing function with nondecreasing gradient\n    assert 0 <= x <= 1\n    return 1-x\n\n\n# check functions\nfor x1,x3 in zip(action_domain, action_domain[1:]):\n    x2 = (x1 + x3) \/ 2\n    d1 = u_h(x2) - u_h(x1)\n    d2 = u_h(x3) - u_h(x2)\n    # check increasing\n    assert d1 > 0\n    assert d2 > 0\n    # check decreasing gradient\n    assert d1 > d2 - rounding_err\n\n\n# check functions\nfor x1,x3 in zip(action_domain, action_domain[1:]):\n    x2 = (x1 + x3) \/ 2\n    d1 = u_r(x2) - u_r(x1)\n    d2 = u_r(x3) - u_r(x2)\n    # check nonincreasing\n    assert d1 <= 0\n    assert d2 <= 0\n    # check nondecreasing gradient\n    assert d1 >= d2 - rounding_err","4b636382":"## Trigger Strategy for Taker-Taker \nimport matplotlib.pyplot as plt\nfrom shapely.geometry import LineString\n\ndef plot_intersection(x_range, y1_func, y2_func, plot=True, xlabel='', ylabel='', title='', savefig=''):\n    # input: horizontal axis values x_range\n    # input: functions to generate a y value for each x in x_range\n    y1_values = [y1_func(x) for x in x_range]\n    y2_values = [y2_func(x) for x in x_range]\n    \n    if plot:\n        plt.plot(x_range, y1_values, color='green')\n        plt.plot(x_range, y2_values, color='red')\n        plt.xlabel(xlabel)\n        plt.ylabel(ylabel)\n        plt.title(title)\n\n    # Solver\n\n    first_line = LineString(np.column_stack((x_range, y1_values)))\n    second_line = LineString(np.column_stack((x_range, y2_values)))\n    intersection = first_line.intersection(second_line)\n\n    point_type = intersection.geom_type\n    if point_type == 'MultiPoint':\n        if plot: plt.plot(*LineString(intersection).xy, 'o')\n        x_, y_ = LineString(intersection).xy\n#         print(point_type)\n#         print('x',x_)\n#         print('y',y_)\n    elif point_type == 'Point':\n        if plot: plt.plot(*intersection.xy, 'o')\n        x_, y_ = intersection.xy\n#         print(point_type)\n#         print('x',x_)\n#         print('y',y_)\n    else:\n        point_type = \"None\"\n#         print(point_type)\n    \n    def _extract(x_or_y):\n        value_ls = list(x_or_y)\n        return value_ls\n    \n    if plot and savefig: plt.savefig(savefig)\n    return _extract(x_), _extract(y_), intersection.geom_type","388107f7":"## Trigger Strategy for Taker-Taker \nx_range = np.arange(0, 1, 0.001) # agreed amount to give\n\ndef vc(x,y=0.1):\n    assert 0 <= y < 1\n    return (u_r(x) + u_h(x)) \/ (1-y)\n\ndef vd(x,y=0.1):\n    assert 0 <= y < 1\n    return (u_r(0) + u_h(x)) + y*((u_r(0) + u_h(0)) \/ (1-y))\n\ny=0.66667 # discount rate\nplot_intersection(x_range, lambda x: vc(x,y=y), lambda x: vd(x,y=y),\n                  savefig='\/kaggle\/working\/takertaker.png',\n                 xlabel='Effort Given',\n                 ylabel='Long-run Value') # create lambda function to lock in y\nplt.savefig(\"\/kaggle\/working\/trigger.png\")","9118344f":"## Trigger Strategy for Taker-Taker \n# this is the code used to find the discount rate required to support x* = 0.5\nfrom bayes_opt import BayesianOptimization\n\ndef find_indifference(y):\n    x_range = np.arange(0, 1, 0.001) # agreed amount to give\n    x_, y_, point_type = plot_intersection(x_range, lambda x: vc(x,y=y), lambda x: vd(x,y=y), plot=False)\n    indiff_x = max(x_)\n    goal_x = 0.5\n    deviation = abs(goal_x-indiff_x)\n    return -deviation # obj is to max -deviation or min deviation\n        \n# Bounded region of parameter space\npbounds = {'y':(0.001,1)}\n\noptimizer = BayesianOptimization(\n    f=find_indifference,\n    pbounds=pbounds,\n    random_state=42,\n)\n\ntry:\n    optimizer.maximize(\n    init_points=5,\n    n_iter=100)\nexcept: print(\"Optimizer done\")\n\nprint(optimizer.max)","d6d43dbb":"## Trigger Strategy for Taker-Taker \n# this is the code used to find the discount rate required to support x* = 0.5\ndef find_discount_rate():\n    x_range = np.arange(0, 1, 0.001) # agreed amount to give\n    y_range = np.arange(0,1,0.001) # discount rate\n    for y in y_range:\n        x_, y_, point_type = plot_intersection(x_range, lambda x: vc(x,y=y), lambda x: vd(x,y=y), plot=False)\n        ","af92586f":"## Team Performance Incentive\n\ndef team_performance_incentive_game(incentive_rate, k, profile1, profile2):\n    #a1,b1,c1 = (1,0,1) # taker\n    #a2,b2,c2 = (1,0,1) # taker\n    \n    a1,b1,c1 = profile1 # (0,1,1) # giver\n    a2,b2,c2 = profile2 # (0,1,1) # giver\n    \n    prod_to_utility_scale = k\n    \n    ## What x will each player give based on incentive rate?\n    def _normal_payoff(x1,x2,a,b,c,d=0,r=0):\n        # x1 refers to help given\n        # x2 refers to help taken\n        # a  refers to the coefficient on impact retained\n        # b  refers to the coefficient on impact given\n        # c  refers to the coefficient on impact received\n        # a*retained + b*given + c*received + d*attributed\n        q = a*u_r(x1) + b*u_h(x1) + c*u_h(x2) + d*r\n        return q\n    \n    def _impact_contributed(x1):\n        # this is what the company wants to optimise\n        return u_h(x1) + u_r(x1)\n    \n    def new_payoff(x1,x2,a,b,c,d=0,r=0, incentive=incentive_rate):\n        payoff = _normal_payoff(x1,x2,a,b,c,d=0,r=0)\n\n        payoff += 0.5*prod_to_utility_scale*incentive*(_impact_contributed(x1) + _impact_contributed(x2))\n        return payoff\n    \n    def controllable_payoff(x1,a,b,c,d=0,r=0, incentive=incentive_rate):\n        return new_payoff(x1,0,a,b,c,d=0,r=0, incentive=incentive)\n  \n    def optimise_x(a,b,c): # just iterate thru x and find the max payoff a player can get\n        x_range = np.arange(0,1,0.001)\n        u = [controllable_payoff(x,a,b,c,d=0,r=0, incentive=incentive_rate) for x in x_range]\n        return x_range[np.argmax(u)]\n    \n    # These are the amounts both players will give\n    x1_opt = optimise_x(a1,b1,c1)\n    x2_opt = optimise_x(a2,b2,c2)\n    \n    ## Given amounts both players will give, what is the new NE and company productivity?\n#     social = new_payoff(x1_opt,x2_opt,a1,b1,c1,d=0,r=0, incentive=incentive_rate)\n#     social += new_payoff(x1_opt,x2_opt,a2,b2,c2,d=0,r=0, incentive=incentive_rate)\n    \n    net_company_productivity = (1-incentive_rate) * (_impact_contributed(x1_opt) + _impact_contributed(x2_opt))\n    return net_company_productivity, (x1_opt, x2_opt)","8a18713f":"# ir_range = np.arange(0,1,0.01)\n# ncp_values = [team_performance_incentive_game(ir)[0] for ir in ir_range]\n# best_ir = ir_range[np.argmax(ncp_values)]\n# print(best_ir, max(ncp_values), team_performance_incentive_game(best_ir)[1])\n\n# plt.plot(ir_range, ncp_values, color='green')\n# # plt.plot(x_range, y2_values, color='red')\n# # plt.xlabel(xlabel)\n# # plt.ylabel(ylabel)\n# # plt.title(title)","8874e92d":"# k_ls = []\n# ir_ls = []\n# x_ls = []\n# ncp_ls = []\n# for k in tqdm(range(0,150)):\n#     ir_range = np.arange(0,1,0.01)\n#     ncp_values = [team_performance_incentive_game(ir,k)[0] for ir in ir_range]\n#     best_ir = ir_range[np.argmax(ncp_values)]\n#     k_ls.append(k)\n#     ir_ls.append(best_ir)\n#     ncp_ls.append(max(ncp_values))\n#     x_ls.append(team_performance_incentive_game(best_ir,k)[1][0])\n        ","c47aaf25":"# import matplotlib.pyplot as plt\n# fig, ax1 = plt.subplots()\n# ax1.plot(k_ls, ncp_ls, color='green')\n# plt.xlabel('k')\n# plt.ylabel('Net Company Productivity')\n\n# ax2 = ax1.twinx()\n# ax2.plot(k_ls, ir_ls, color='blue')\n# ax2.plot(k_ls, x_ls, color='red')\n# plt.ylabel('ir, x')\n\n# plt.savefig('NCPv2.png')","f9bba406":"from tqdm.notebook import tqdm\nk_ls = []\nir_ls = []\nx_ls = []\nncp_ls = []\nprofile1 = (1,0,1) # TODO\nprofile2 = (1,0,1) # TODO\nfor k in tqdm(np.arange(20,50,0.1)): # adjust this! 0 to 50 recommended\n    ir_range = np.arange(0,1,0.01)\n    ncp_values = [team_performance_incentive_game(ir,k,profile1,profile2)[0] for ir in ir_range]\n    best_ir = ir_range[np.argmax(ncp_values)]\n    k_ls.append(k)\n    ir_ls.append(best_ir)\n    ncp_ls.append(max(ncp_values))\n    x_ls.append(team_performance_incentive_game(best_ir,k,profile1,profile2)[1][0])\n        ","eab5c8d0":"import matplotlib.pyplot as plt\nfig, ax1 = plt.subplots()\nax1.plot(k_ls, ncp_ls, color='green')\nplt.xlabel('k')\nplt.ylabel('Net Company Productivity')\n\nax2 = ax1.twinx()\nax2.plot(k_ls, ir_ls, color='blue')\nax2.plot(k_ls, x_ls, color='red')\nplt.ylabel('ir, x')\n\n# plt.savefig('NCP-TT_v3.png')","80ce410d":"from tqdm.notebook import tqdm\nk_ls = []\nir_ls = []\nx_ls = []\nncp_ls = []\nprofile1 = (0,1,1) # TODO\nprofile2 = (0,1,1) # TODO\nfor k in tqdm(np.arange(0,50,0.1)): # adjust this! 0 to 50 recommended\n    ir_range = np.arange(0,1,0.01)\n    ncp_values = [team_performance_incentive_game(ir,k,profile1,profile2)[0] for ir in ir_range]\n    best_ir = ir_range[np.argmax(ncp_values)]\n    k_ls.append(k)\n    ir_ls.append(best_ir)\n    ncp_ls.append(max(ncp_values))\n    x_ls.append(team_performance_incentive_game(best_ir,k,profile1,profile2)[1][0])\n        ","57f051e8":"import matplotlib.pyplot as plt\nfig, ax1 = plt.subplots()\nax1.plot(k_ls, ncp_ls, color='green')\nplt.xlabel('k')\nplt.ylabel('Net Company Productivity')\n\nax2 = ax1.twinx()\nax2.plot(k_ls, ir_ls, color='blue')\nax2.plot(k_ls, x_ls, color='red')\nplt.ylabel('ir, x')\n\n# plt.savefig('NCP-GG_v3.png')","3dfcf7d5":"# viewer\nfor k,ncp, ir in zip(k_ls,ncp_ls, ir_ls):\n    print(k,ncp,ir)","01b1c8c2":"def payoff_maximising_action(a,b):\n    action_domain = np.linspace(0,1,500+1)\n    return action_domain[np.argmax([a*u_r(x) + b*u_h(x) for x in action_domain])]","cbbf781a":"plt.plot(np.arange(0,2,0.02), [payoff_maximising_action(1,b) for b in np.arange(0,2,0.02)])\nplt.axvline(x=1, linestyle=\":\")\nplt.axhline(y=0.5, linestyle=\":\")\nplt.xlabel(\"Value of b\/a\")\nplt.ylabel(\"Payoff Maximising Action\")\nplt.show()","81f21495":"def payoff(x1,x2,a,b,c,d=0,r=0):\n    # x1 refers to help given\n    # x2 refers to help taken\n    # a  refers to the coefficient on impact retained\n    # b  refers to the coefficient on impact given\n    # c  refers to the coefficient on impact received\n    \n    # a*retained + b*given + c*received + d*attributed\n    q = a*u_r(x1) + b*u_h(x1) + c*u_h(x2) + d*r\n    return round(q, 6)\n\n\ndef impact_assigned(x1,x2,a,b,c):\n    return payoff(x1,x2,1,0,1)\n\n\ndef impact_contributed(x1):\n    # this is what the company wants to optimise\n    return u_h(x1) + u_r(x1)\n\n\ndef find_maximum_impact():\n    maxres = [(-1,-1)]\n    maxval = -np.inf\n    for x1 in action_domain:\n        for x2 in action_domain:\n            val = impact_contributed(x1) + impact_contributed(x2)\n            if is_equal(val, maxval):\n                maxres.append((x1,x2))\n            elif val > maxval - rounding_err:\n                maxval = val\n                maxres = [(x1,x2)]\n    return maxval, maxres\n\n\ndef find_optimum_payoff(profile_1, profile_2):\n    a1,b1,c1 = profile_1\n    a2,b2,c2 = profile_2\n\n    maxres = [(-1,-1)]\n    maxval = -np.inf\n    for x1 in action_domain:\n        for x2 in action_domain:\n            val = payoff(x1,x2,a1,b1,c1) + payoff(x2,x1,a2,b2,c2)\n            if is_equal(val, maxval):\n                maxres.append((x1,x2))\n            elif val > maxval - rounding_err:\n                maxval = val\n                maxres = [(x1,x2)]\n    return maxval, maxres\n\n\ndef find_nash_equilibriums(profile_1, profile_2):\n    a1,b1,c1 = profile_1\n    a2,b2,c2 = profile_2\n    \n    best_response_1 = set()\n    for x1 in action_domain:\n        maxres = []\n        maxp2 = -np.inf\n        for x2 in action_domain:\n            p1 = payoff(x1,x2,a1,b1,c1)\n            p2 = payoff(x2,x1,a2,b2,c2)\n            if p2 == maxp2:\n                maxres.append((x1,x2,p1,p2))\n            elif p2 > maxp2:\n                maxp2 = p2\n                maxres = [(x1,x2,p1,p2)]\n        best_response_1.update(maxres)\n        \n    best_response_2 = set()\n    for x2 in action_domain:\n        maxres = []\n        maxp1 = -np.inf\n        for x1 in action_domain:\n            p1 = payoff(x1,x2,a1,b1,c1)\n            p2 = payoff(x2,x1,a2,b2,c2)\n            if p1 == maxp1:\n                maxres.append((x1,x2,p1,p2))\n            elif p1 > maxp1:\n                maxp1 = p1\n                maxres = [(x1,x2,p1,p2)]\n        best_response_2.update(maxres)\n    \n    nash_equilibriums = sorted(best_response_1 & best_response_2)\n    nash_equilibriums_with_info = []\n    for x1,x2,p1,p2 in nash_equilibriums:\n        i1,i2 = impact_contributed(x1), impact_contributed(x2)\n        nash_equilibriums_with_info.append((x1,x2,p1,p2,i1,i2))\n        \n    optimum_payoff = find_optimum_payoff(profile_1, profile_2)\n    return nash_equilibriums_with_info, optimum_payoff","39e41344":"# retained, given, received\ntaker_profile = 1,0,1\ngiver_profile = 0,1,1\nmatcher_profile = 1,0.75,0.25\n\n# policymaker want to maximise impact, whereas players want to maximise their payoff\n# impact may be different from the payoff unless retained == 1 and given + received == 1","9dd36fd4":"def generate_table(action_domain_subset, profile_1, profile_2):\n    matrix_1 = []\n    matrix_2 = []\n    for x1 in action_domain_subset:\n        row_1 = []\n        row_2 = []\n        for x2 in action_domain_subset:\n            v1,v2 = payoff(x1,x2,*profile_1), payoff(x2,x1,*profile_2)\n            row_1.append(v1)\n            row_2.append(v2)\n        matrix_1.append(row_1)\n        matrix_2.append(row_2)\n    return np.array(matrix_1), np.array(matrix_2)","ccff9167":"matrix_1, matrix_2 = generate_table([0,0.5,1], taker_profile, taker_profile)\nmatrix_1, None, matrix_2","0925b73a":"matrix_1, matrix_2 = generate_table([0,0.5,1], giver_profile, giver_profile)\nmatrix_1, None, matrix_2","197444f6":"matrix_1, matrix_2 = generate_table([0,0.33,0.5,1], matcher_profile, matcher_profile)\nmatrix_1, None, matrix_2","88f311c6":"def analyse_and_print(profile_1, profile_2):\n    max_impact_value, max_impact_acts = find_maximum_impact()\n    print(\"Maximum impact: {}\".format(max_impact_value))\n    x1,x2 = max_impact_acts[0]\n    i1_max, i2_max = impact_contributed(x1), impact_contributed(x2)\n    print(\"Actions for maximum impact: {}, {}\".format(x1,x2))\n    print(\"Payoffs at maximum impact: {}, {}\".format(payoff(x1,x2,*profile_1), payoff(x2,x1,*profile_2)))\n    print(\"Impacts at maximum impact: {}+{} = {}\".format(i1_max, i2_max, i1_max+i2_max))\n\n    print()\n    print(\"Profile 1 coefficients: {}\".format(profile_1))\n    print(\"Profile 2 coefficients: {}\".format(profile_2))\n    nes, (opt_val, opt_acts) = find_nash_equilibriums(profile_1, profile_2)\n\n    print()\n    print(\"Number of Nash Equilibriums: {}\".format(len(nes)))    \n    if nes:\n        x1,x2,p1,p2,i1,i2 = nes[0]\n        print(\"Actions: {}, {}\".format(x1,x2))\n        print(\"Payoffs: {:.4f}, {:.4f}\".format(p1,p2))\n        print(\"Impacts: {:.4f}+{:.4f} = {:.4f}\".format(i1,i2,i1+i2))\n        \n    print()\n    print(\"Maximum sum of payoff: {:.4f}\".format(opt_val))\n    print(\"Number of action combinations that provide maximum sum of payoff: {}\".format(len(opt_acts)))\n    x1,x2 = opt_acts[0]\n    print(\"Actions: {}, {}\".format(x1,x2))\n    print(\"Payoffs: {:.4f}, {:.4f}\".format(payoff(x1,x2,*profile_1),payoff(x2,x1,*profile_2)))\n    \n    if nes:\n        x1,x2,p1,p2,i1,i2 = nes[0]\n        print()\n        print(\"Price of Anarchy: {:.4f}\/{:.4f} - 1 = {:.4f}\".format(\n            opt_val,p1+p2,(opt_val)\/(p1+p2+rounding_err)-1))\n        print(\"Loss in impact efficiency: 1 - {:.4f}\/{:.4f} = {:.4f}\".format(\n            i1+i2, i1_max+i2_max, 1- (i1+i2)\/(i1_max+i2_max+rounding_err)))","45797948":"analyse_and_print(taker_profile,taker_profile)","e89b0e65":"analyse_and_print(giver_profile,giver_profile)","f5eb7ea3":"analyse_and_print(matcher_profile,matcher_profile)","88fc4ab2":"analyse_and_print(matcher_profile,taker_profile)","1efc2938":"analyse_and_print((1,0.5,-0.6),(1,0.6,-0.6))","1a6d06aa":"# -- End of KWT's changes --"}}