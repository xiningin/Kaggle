{"cell_type":{"4b73641f":"code","1be0c6cf":"code","f217a02c":"code","59ec028b":"code","fb30b1ed":"code","57bf51c0":"code","d2c87446":"code","bcac2c9c":"code","73d6684d":"code","9725c306":"code","9e77b01f":"code","8b3c99de":"code","a1473bf9":"code","2916698b":"code","6e706b48":"code","200a21ec":"code","e17b8e77":"code","1c532dda":"code","50be6c98":"code","c922c344":"code","e8142d53":"code","64c477dd":"code","d2d12c0f":"code","6a7ee863":"code","a50617cc":"code","ff9b1502":"markdown","fc63be8d":"markdown","06a19eb3":"markdown","121b2536":"markdown","589e61d8":"markdown","314422dc":"markdown","736c1ab2":"markdown","19ac141b":"markdown","140c8b48":"markdown","26609c59":"markdown","6254fc21":"markdown","04df63f3":"markdown","dd944f77":"markdown","930a4171":"markdown","c74ed5ce":"markdown","0ba08113":"markdown","53c6f9d9":"markdown","10c00d23":"markdown","7335c60b":"markdown","b4bdc7db":"markdown"},"source":{"4b73641f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom PIL import Image\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nimport tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\nfrom sklearn.ensemble import AdaBoostClassifier\nimport seaborn as sns","1be0c6cf":"dfc = pd.read_csv('\/kaggle\/input\/chinese-mnist\/chinese_mnist.csv')\nimages = np.array([np.asarray(Image.open('\/kaggle\/input\/chinese-mnist\/data\/data\/input_%d_%d_%d.jpg'%(x['suite_id'], x['sample_id'], x['code']))) for x in dfc.iloc])\npd.DataFrame(zip([9,10,100,1000,10000,100000000,0,1,2,3,4,5,6,7,8],dfc['character'].unique()), columns=['valor', 'caractere']).sort_values(by='valor')","f217a02c":"pd.DataFrame([[0, 'T-shirt\/top'],\n[1, 'Trouser'],\n[2, 'Pullover'],\n[3, 'Dress'],\n[4, 'Coat'],\n[5, 'Sandal'],\n[6, 'Shirt'],\n[7, 'Sneaker'],\n[8, 'Bag'],\n[9, 'Ankle boot']], columns=['classe', 'valor'])","59ec028b":"# Normaliza\u00e7\u00e3o e etiqueta\u00e7\u00e3o Chinese MNIST\n\nxc = images\/255.0\nxc = xc.reshape((-1, 64, 64, 1)) # Apenas para ficar no formado que a CNN prefere\n\nyc = np.array(dfc['value'])\nlec = preprocessing.LabelEncoder()\nyc_int=lec.fit_transform(yc)\nyc=to_categorical(yc_int)\nn_cclasses=len(yc[0])","fb30b1ed":"# Carregamento e normaliza\u00e7\u00e3o Fashion MNIST\n\ndata_train = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')\ndata_test = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv')\n\nimg_rows, img_cols = 28, 28\ninput_shape = (img_rows, img_cols, 1)\n\nxf_train = np.array(data_train.iloc[:, 1:], dtype='float32')\/255.0\nyf_train_int = np.array(data_train.iloc[:, 0])\nyf_train = to_categorical(yf_train_int)\n\nxf_test = np.array(data_test.iloc[:, 1:], dtype='float32')\/255.0\nyf_test_int = np.array(data_test.iloc[:, 0])\nyf_test = to_categorical(yf_test_int)\n\nxf_train = xf_train.reshape((len(xf_train), 28, 28, 1))\nxf_test = xf_test.reshape((len(xf_test), 28, 28, 1))","57bf51c0":"xc_train, xc_test, yc_train, yc_test, yc_train_int, yc_test_int = train_test_split(xc, yc, yc_int, test_size=0.2, random_state=8)","d2c87446":"xc_train_ada = xc_train.reshape((len(xc_train), -1))\nxc_test_ada = xc_test.reshape((len(xc_test), -1))\n\nxc_ada_fold = KFold(n_splits=5, random_state=9, shuffle=True)","bcac2c9c":"ada = AdaBoostClassifier(n_estimators=50)\n\nresults = []\nacc=[]\nfor train_index, val_index in xc_ada_fold.split(xc_train_ada):\n    print('Fold %d...' % (len(results)+1))\n    my_x_train = xc_train_ada[train_index]\n    my_y_train = yc_train_int[train_index]\n    my_x_val = xc_train_ada[val_index]\n    my_y_val = yc_train_int[val_index]\n    \n    ada.fit(my_x_train, my_y_train)\n    my_y_pred = ada.predict(my_x_val)\n    prfs = precision_recall_fscore_support(my_y_val, my_y_pred, average='micro')\n    facc = accuracy_score(my_y_val, my_y_pred)\n    results.append(prfs[:-1])\n    acc.append(facc)\n\nprint('Conclu\u00eddo. M\u00e9dia dos resultados no treino:')\nprint('precis\u00e3o, revoca\u00e7\u00e3o, fscore')\nresults = np.array(results).mean(axis=0)\nprint(results)\nprint('acur\u00e1cia: ', np.array(acc).mean());","73d6684d":"ada.fit(xc_train_ada, yc_train_int)\nyc_pred_ada = ada.predict(xc_test_ada)\nc_prfs_ada = precision_recall_fscore_support(yc_test_int, yc_pred_ada, average='micro')\nc_acc_ada = accuracy_score(yc_test_int, yc_pred_ada)\nprint('Resultados no teste')\nprint('precis\u00e3o, revoca\u00e7\u00e3o, fscore')\nprint(c_prfs_ada[:-1])\nprint('acur\u00e1cia: ', c_acc_ada);","9725c306":"modelc = models.Sequential()\nmodelc.add(layers.Conv2D(16, (3, 3), activation='relu', input_shape=(64, 64, 1)))\nmodelc.add(layers.Conv2D(16, (3, 3), activation='relu'))\nmodelc.add(layers.MaxPooling2D((2, 2)))\nmodelc.add(layers.Dropout(0.5))\nmodelc.add(layers.Conv2D(16, (3, 3), activation='relu'))\nmodelc.add(layers.Conv2D(16, (3, 3), activation='relu'))\nmodelc.add(layers.Dropout(0.5))\nmodelc.add(layers.Flatten())\nmodelc.add(layers.Dense(n_cclasses, activation='softmax'))\nmodelc.summary()\n\nmodelc.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","9e77b01f":"cepochs = 50\nhistoryc = modelc.fit(xc_train, yc_train, epochs=cepochs, batch_size=32,\n                    validation_split=0.2)","8b3c99de":"plt.plot(list(range(cepochs)), historyc.history['loss'], label='treino')\nplt.plot(list(range(cepochs)), historyc.history['val_loss'], label='valida\u00e7\u00e3o')\nplt.legend()\nplt.title('loss')\nplt.xlabel('n\u00famero da \u00e9poca')\nplt.show()\nplt.plot(list(range(cepochs)), historyc.history['accuracy'], label='treino')\nplt.plot(list(range(cepochs)), historyc.history['val_accuracy'], label='valida\u00e7\u00e3o')\nplt.title('accur\u00e1cia')\nplt.xlabel('n\u00famero da \u00e9poca')\nplt.legend()\nplt.show()","a1473bf9":"yc_pred_test = modelc.predict(xc_test)\n\nyc_pred_test_argmax = np.argmax(yc_pred_test, axis=1)\nprint('acur\u00e1cia no teste: ', accuracy_score(yc_test_int, yc_pred_test_argmax))","2916698b":"meus_x = xc_test[yc_pred_test_argmax == yc_test_int].reshape((-1,64,64))\nmeus_y = lec.inverse_transform(yc_test_int[yc_pred_test_argmax == yc_test_int])\n\nfig=plt.figure(figsize=(8, 8))\ncolumns = 5\nrows = 5\nfor i in range(1, columns*rows +1):\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(meus_x[i])\n    plt.title(meus_y[i])\n    plt.axis('off')\nplt.subplots_adjust(hspace=0.25)\nplt.show()","6e706b48":"print('Valores preditos (valores reais)')\nmeus_x = xc_test[yc_pred_test_argmax != yc_test_int].reshape((-1,64,64))\nmeus_y = lec.inverse_transform(yc_pred_test_argmax[yc_pred_test_argmax != yc_test_int])\nreais_y = lec.inverse_transform(yc_test_int[yc_pred_test_argmax != yc_test_int])\n\nfig=plt.figure(figsize=(8, 8))\ncolumns = 5\nrows = 5\nfor i in range(1, columns*rows +1):\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(meus_x[i])\n    plt.title(\"%d (%d)\" % (meus_y[i], reais_y[i]))\n    plt.axis('off')\nplt.subplots_adjust(hspace=0.25, wspace=0.5)\nplt.show()","200a21ec":"nf_classes = len(yf_train[0])\nmodelf = models.Sequential()\nmodelf.add(layers.Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)))\nmodelf.add(layers.Conv2D(16, (3, 3), activation='relu'))\nmodelf.add(layers.MaxPooling2D((2, 2)))\nmodelf.add(layers.Dropout(0.5))\nmodelf.add(layers.Conv2D(16, (3, 3), activation='relu'))\nmodelf.add(layers.Conv2D(16, (3, 3), activation='relu'))\nmodelf.add(layers.Dropout(0.5))\nmodelf.add(layers.Flatten())\nmodelf.add(layers.Dense(nf_classes, activation='softmax'))\nmodelf.summary()\n\nmodelf.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","e17b8e77":"fepochs = 50\nhistoryf = modelf.fit(xf_train, yf_train, epochs=fepochs, batch_size=32,\n                    validation_split=0.2, shuffle=True)","1c532dda":"plt.plot(list(range(fepochs)), historyf.history['loss'], label='treino')\nplt.plot(list(range(fepochs)), historyf.history['val_loss'], label='teste')\nplt.legend()\nplt.title('loss')\nplt.show()\nplt.plot(list(range(fepochs)), historyf.history['accuracy'], label='treino')\nplt.plot(list(range(fepochs)), historyf.history['val_accuracy'], label='teste')\nplt.title('accuracy')\nplt.legend()\nplt.show()","50be6c98":"yf_pred_test = modelf.predict(xf_test)\n\nyf_pred_test_argmax = np.argmax(yf_pred_test, axis=1)\nprint('acur\u00e1cia no teste: ', accuracy_score(yf_test_int, yf_pred_test_argmax))","c922c344":"my_lef = ['T-shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']","e8142d53":"meus_x = xf_test[yf_pred_test_argmax == yf_test_int].reshape((-1,28,28))\nmeus_y = yf_test_int[yf_pred_test_argmax == yf_test_int]\n\nfig=plt.figure(figsize=(8, 8))\ncolumns = 5\nrows = 5\nfor i in range(1, columns*rows +1):\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(meus_x[i])\n    plt.title(my_lef[meus_y[i]])\n    plt.axis('off')\nplt.subplots_adjust(hspace=0.25)\nplt.show()","64c477dd":"print('Valores preditos (valores reais)')\nmeus_x = xf_test[yf_pred_test_argmax != yf_test_int].reshape((-1,28,28))\nmeus_y = yf_pred_test_argmax[yf_pred_test_argmax != yf_test_int]\nreais_y = yf_test_int[yf_pred_test_argmax != yf_test_int]\n\nfig=plt.figure(figsize=(8, 8))\ncolumns = 5\nrows = 5\nfor i in range(1, columns*rows +1):\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(meus_x[i])\n    plt.title(\"%s\\n(%s)\" % (my_lef[meus_y[i]], my_lef[reais_y[i]]))\n    plt.axis('off')\nplt.subplots_adjust(hspace=0.6, wspace=0.5)\nplt.show()","d2d12c0f":"# Matriz de confus\u00e3o dataset Chinese MNIST adaboosting\ncf_matrix=confusion_matrix(yc_test_int, yc_pred_ada)\nfig, ax = plt.subplots(figsize=(12,10))\nsns.heatmap(cf_matrix\/np.sum(cf_matrix), annot=True, \n            fmt='.2%', cmap='Blues')\nplt.title('Matriz de confus\u00e3o das previs\u00f5es no conjunto de teste do dataset Chinese MNIST (AdaBoosting)')\nplt.show()","6a7ee863":"# Matriz de confus\u00e3o dataset Chinese MNIST cnn\ncf_matrix=confusion_matrix(yc_test_int, yc_pred_test_argmax)\nfig, ax = plt.subplots(figsize=(12,10))\nsns.heatmap(cf_matrix\/np.sum(cf_matrix), annot=True, \n            fmt='.2%', cmap='Blues')\nplt.title('Matriz de confus\u00e3o das previs\u00f5es no conjunto de teste do dataset Chinese MNIST (CNN)')\nplt.show()","a50617cc":"# Matriz de confus\u00e3o dataset Fashion MNIST\ncf_matrix=confusion_matrix(yf_test_int, yf_pred_test_argmax)\nfig, ax = plt.subplots(figsize=(8,7))\nsns.heatmap(cf_matrix\/np.sum(cf_matrix), annot=True, \n            fmt='.2%', cmap='Blues')\nplt.title('Matriz de confus\u00e3o das previs\u00f5es no conjunto de teste do dataset Fashion MNIST')\nplt.show()","ff9b1502":"# Treinamento dos modelos para o _Fashion MNIST_\n\nDiante dos resultados do dataset anterior, para este dataset apenas foi treinado o modelo CNN, j\u00e1 que ele obteve uma acur\u00e1cia muito maior que o AdaBoosting.\n\n## CNN\n\nPara treinar a CNN para o _Fashion MNIST_ foi utilizada a mesma arquitetura da CNN do _Chinese MNIST_ , com exce\u00e7\u00e3o do tamanho da camada de entrada e de sa\u00edda, que foram definidas de acordo com os dados deste dataset: (28, 28, 1) e 10, respectivamente.","fc63be8d":"O modelo da rede neural foi treinado utilizando 50 \u00e9pocas e dividindo o dado de treino em treino e valida\u00e7\u00e3o. Esta divis\u00e3o dos dados foi realizada automaticamente pelo Keras no momento do _fit_ , como pode ser visto na c\u00e9lula abaixo.","06a19eb3":"# Treinamento dos modelos para o _Chinese MNIST_\n\n## AdaBoosting\n\nA primeira abordagem utilizada foi utilizar uma t\u00e9cnica de boosting para a classifica\u00e7\u00e3o. Foram testados alguns algoritmos e, por fim, foi decidido utilizar o AdaBoosting, j\u00e1 que os outros facilmente ficavam com overfitting. Para usar este classificador, a imagem foi achatada em um vetor de $64*64=4096$ posi\u00e7\u00f5es. \n\nAtrav\u00e9s de experimenta\u00e7\u00e3o foi decidido definir o n\u00famero de estimadores usados pelo AdaBoosting como 50, pois o algoritmo ficava melhor com a adi\u00e7\u00e3o de mais estimadores. Para valida\u00e7\u00e3o foi utilizado k-fold com k=5.\n\nOs resultados s\u00e3o apresentados logo ap\u00f3s as c\u00e9lulas de implementa\u00e7\u00e3o.","121b2536":"#### Exemplos de classifica\u00e7\u00e3o incorreta\n\nNa imagem abaixo \u00e9 poss\u00edvel ver v\u00e1rios exemplos de classifica\u00e7\u00f5es incorretas do classificador. No t\u00edtulo de cada sub-figura tem-se a previs\u00e3o realizada e a correta, sendo que a correta est\u00e1 entre par\u00eanteses.","589e61d8":"#### Exemplos de classifica\u00e7\u00e3o incorreta\n\nNa imagem abaixo \u00e9 poss\u00edvel ver v\u00e1rios exemplos de classifica\u00e7\u00f5es incorretas do classificador. No t\u00edtulo de cada sub-figura tem-se a previs\u00e3o realizada e a correta, sendo que a correta est\u00e1 entre par\u00eanteses.","314422dc":"#### Exemplos de classifica\u00e7\u00e3o correta\n\nNa imagem abaixo \u00e9 poss\u00edvel ver v\u00e1rios exemplos de classifica\u00e7\u00f5es corretas do classificador. No t\u00edtulo de cada sub-figura tem-se a previs\u00e3o realizada.","736c1ab2":"# Conclus\u00e3o\n\nFoi poss\u00edvel implementar adequadamente todos os classificadores, assim como compar\u00e1-los. Os classificadores CNN obtiveram \u00f3tima performance, enquanto o classificador AdaBoosting teve uma performance ruim. Em geral, os resultados foram satisfat\u00f3rios e dentro do esperado.","19ac141b":"### Resultados\n\nComo \u00e9 poss\u00edvel notar na sa\u00edda das \u00faltimas duas c\u00e9lulas, os resultados nos conjuntos de treino e teste ficaram bem parecidos, e ambos ficaram ruins, apresentando uma acur\u00e1cia em torno de 20%. Apesar disto, o resultado ficou dentro do esperado, j\u00e1 que o dado de entrada (imagem) \u00e9 um dado n\u00e3o estruturado, e classificadores geralmente n\u00e3o funcionam bem nesse tipo de dado.","140c8b48":"# Projeto final de aprendizado de m\u00e1quina - classificador de imagens\n\n**Estudante:** Jo\u00e3o Gabriel de Oliveira Bicalho\n\n**Matr\u00edcula:** 2017015134","26609c59":"## Separa\u00e7\u00e3o de conjuntos de treino e teste\n\nAp\u00f3s o preprocessamento dos dados, o dataset _Chinese MNIST_ foi dividido em uma parte para treino e outra para teste. Foi decidido utilizar 20% dos dados para o teste e o restante para o treino. O dataset _Fashion MNIST_ j\u00e1 veio separado nestes dois conjuntos.","6254fc21":"## Introdu\u00e7\u00e3o\n\nO objetivo deste trabalho \u00e9 criar um classificador para dois datasets de imagens. O primeiro dataset (Chinese MNIST) cont\u00e9m imagens de 15 n\u00fameros chineses manuscritos. J\u00e1 o segundo (Fashion MNIST) cont\u00e9m imagens de 10 classes de produtos de moda. O objetivo do classificador \u00e9 atribuir corretamente essas labels \u00e0s imagens.\n\nNeste trabalho ser\u00e3o implementados dois classificadores: o primeiro utilizando um m\u00e9todo de boosting na imagem achatada, e o segundo utilizando uma CNN _(Convolutional Neural Network)_. O intuito \u00e9 utilizar a mesma CNN para ambos os datasets, apenas adequando o tamanho das camadas de entrada e sa\u00edda. No final os resultados dos dois classificadores ser\u00e3o comparados.","04df63f3":"### Resultados\n\nOs resultados obtidos da CNN foram muito bons, obtendo uma \u00f3tima acur\u00e1cia (pr\u00f3xima de 100%) tanto no conjunto de treino quanto no conjunto de valida\u00e7\u00e3o, e tamb\u00e9m mantendo a diminui\u00e7\u00e3o do loss durante o treinamento. O modelo n\u00e3o parece apresentar overfitting.\nAp\u00f3s a finaliza\u00e7\u00e3o da mudan\u00e7a dos par\u00e2metros e a gera\u00e7\u00e3o dos gr\u00e1ficos acima, foi realizado o teste do modelo no conjunto de teste, que manteve uma excelente acur\u00e1cia, conforme pode ser observado abaixo.","dd944f77":"# Datasets\n\n## Chinese MNIST\n\nEste dataset possui 15000 images de 64x64 pixels em escala de cinzas representando n\u00fameros em chin\u00eas. No total, o dataset possui 15 classes a serem categorizadas, e cada imagem possui apenas uma delas. As classes s\u00e3o mostradas na tabela abaixo, que apresenta os ideograma a serem identificados e os seus respectivos valores no sistema num\u00e9rico decimal:","930a4171":"### Resultados\n\nOs resultados obtidos da CNN foram muito bons, obtendo uma \u00f3tima acur\u00e1cia (pr\u00f3xima de 90%) tanto no conjunto de treino quanto no conjunto de valida\u00e7\u00e3o, e tamb\u00e9m mantendo a diminui\u00e7\u00e3o do loss durante o treinamento. O modelo n\u00e3o parece apresentar overfitting.\nAp\u00f3s a finaliza\u00e7\u00e3o da mudan\u00e7a dos par\u00e2metros e a gera\u00e7\u00e3o dos gr\u00e1ficos acima, foi realizado o teste do modelo no conjunto de teste, que manteve uma excelente acur\u00e1cia, conforme pode ser observado abaixo.","c74ed5ce":"## Fashion MNIST\n\nEste dataset possui 60000 images de treino e 10000 imagens de teste, cada uma com 28x28 pixels em escala de cinzas representando vestimentas ou acess\u00f3rios de moda. Cada imagem est\u00e1 associada a uma classe. Existem 10 classes dentro deste dataset, que s\u00e3o mostradas na tabela abaixo (coluna valor), junto com a sua label associada (coluna classe):","0ba08113":"## CNN\n\nEm busca de tentar obter um modelo com maior acur\u00e1cia foi criada uma Rede Neural Convolucional. Esse tipo de rede geralmente obt\u00e9m melhores resultados com imagens, j\u00e1 que ela consegue trabalhar com dados de mais de uma dimens\u00e3o e, atrav\u00e9s de convolu\u00e7\u00f5es, consegue extrair informa\u00e7\u00f5es dos pixels considerando localidade espacial.\n\nConforme j\u00e1 mencionado, para treinar esta rede as labels associadas \u00e0s imagens foram codificadas como um vetor one-hot-encoding.\n\nA rede criada recebe uma entrada de dimens\u00e3o (64, 64, 1) e possui 2 camadas de convolu\u00e7\u00e3o com 16 filtros (3, 3) cada, seguida por uma camada de MaxPooling (2, 2), uma camada de Dropout (com 50% de probabilidade), mais 2 camadas de convolu\u00e7\u00e3o com 16 filtros (3, 3) cada, mais uma camada de Dropout (0.5), uma camada de achatamento e uma camada densa com 15 perceptrons para sa\u00edda do vetor de classifica\u00e7\u00e3o. Em todas as camadas de convolu\u00e7\u00e3o foi utilizada a fun\u00e7\u00e3o de ativa\u00e7\u00e3o ReLU, j\u00e1 na camada densa de sa\u00edda foi utilizado softmax.\n\nAs camadas de Max Pooling foram introduzidas para diminuir a dimensionalidade da sa\u00edda das camadas anteriores atrav\u00e9s de um down-sampling. Dessa forma \u00e9 poss\u00edvel fazer assun\u00e7\u00f5es melhores sobre as caracter\u00edsticas contidas nas subregi\u00f5es agregadas pelo pooling. J\u00e1 as camadas de Dropout tentam evitar que o modelo criado sofra de overfitting, desabilitando aleatoriamente partes das outras camadas da rede.\n\nFoi utilizado o otimizador Adam, o loss foi calculado atrav\u00e9s de entropia cruzada categ\u00f3rica, e a m\u00e9trica de avalia\u00e7\u00e3o foi a acur\u00e1cia.\n","53c6f9d9":"## Tratamento dos dados\n\nAp\u00f3s o carregamento de cada um dos datasets, fez-se o tratamento de seus dados. As imagens de entrada foram normalizadas de forma que o valor de cada pixel esteja entre 0.0 e 1.0. Em seguida, foi atribu\u00eddo uma label num\u00e9rica para cada uma das classes de cada dataset. Para o dataset _Fashion MNIST_ estas labels j\u00e1 vieram do dataset. Para o dataset _Chinese MNIST_ as labels foram extra\u00eddas usando a classe _LabelEncoder_ do sklearn. Para o classificador com CNN as labels foram depois codificadas em um vetor categ\u00f3rico usando a t\u00e9cnica de one-hot-encoding (isto \u00e9, um vetor de dimens\u00e3o igual ao n\u00famero de classes com todas as posi\u00e7\u00f5es zeradas, exceto a que representa sua classe, que tem 1).","10c00d23":"# Discuss\u00e3o dos resultados\n\n\nComo p\u00f4de ser observado, a rede neural convolucional performou muito melhor do que o m\u00e9todo de boosting durantes os testes no dataset Chinese MNIST, possuindo uma acur\u00e1cia muito maior. Isso ajuda a demonstrar a capacidade de CNNs para classifica\u00e7\u00e3o de imagens, al\u00e9m de mostrar que classificadores cl\u00e1ssicos realmente n\u00e3o trabalham bem com dados n\u00e3o estruturados. Al\u00e9m disso, foi poss\u00edvel conferir que a arquitetura de CNN apresentada funcionou adequadamente para os dois datasets testados, n\u00e3o apresentando overfitting e tendo \u00f3tima acur\u00e1cia. O uso de uma rede relativamente pequena e de dropouts provavelmente colaborou para que isso fosse poss\u00edvel.\n\nAl\u00e9m disso, as entradas serem bem comportadas (apenas uma coisa na imagem, mesma dimens\u00e3o e bem consistentes) tamb\u00e9m foi excelente para fazer com que o classificador obtivesse acur\u00e1cia elevada.\n\nNas imagens abaixo \u00e9 poss\u00edvel ver as matrizes de confus\u00e3o do classificador AdaBoosting e CNN para o dataset _Chinese MNIST_ , e do CNN para o _Fashion MNIST_ , nesta ordem. \u00c9 poss\u00edvel perceber que os classificadores CNN conseguem separar as classes muito bem, ao passo que o AdaBoosting n\u00e3o \u00e9 bom, se confundindo muito em quase todas as classes.\n\n","7335c60b":"#### Exemplos de classifica\u00e7\u00e3o correta\n\nNa imagem abaixo \u00e9 poss\u00edvel ver v\u00e1rios exemplos de classifica\u00e7\u00f5es corretas do classificador. No t\u00edtulo de cada sub-figura tem-se a previs\u00e3o realizada.","b4bdc7db":"O modelo da rede neural foi treinado utilizando 50 \u00e9pocas e dividindo o dado de treino em treino e valida\u00e7\u00e3o. Esta divis\u00e3o dos dados foi realizada automaticamente pelo Keras no momento do _fit_ , como pode ser visto na c\u00e9lula abaixo."}}