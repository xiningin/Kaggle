{"cell_type":{"0515b328":"code","f76d8381":"code","9e6c4d00":"code","45e689d9":"code","8f1d127b":"code","14d6a6ef":"code","0f319295":"code","f8373f82":"code","a44877f1":"code","1d79ea2a":"code","7b829854":"code","ecd7fd6c":"code","5a04a89e":"code","44b6d75e":"code","62738dd3":"code","324875a3":"code","26c4e8fd":"code","63216312":"code","0edaefb2":"code","077cac56":"code","240275d2":"code","fd00c8d1":"code","3508a0ad":"code","2d01579d":"code","1b51be4f":"code","24552b30":"code","45cc8b02":"code","485b8e59":"code","8b203e5a":"code","33b6288a":"code","c2e6cff4":"code","82b77fad":"code","2bb1ae7a":"code","0693cf6a":"code","726905a0":"code","d1bc8b86":"code","9e5be965":"code","f5a6843e":"code","714175eb":"code","279db759":"code","fdd3f5d1":"code","8bc61dcf":"code","f605f4c6":"code","914ebdd4":"code","e60c9edf":"code","edba7089":"code","7050333e":"code","ea7b34f3":"code","8c8527c1":"code","30f6e62e":"markdown","abf1ec9b":"markdown","61b3fd1b":"markdown","9844b84d":"markdown","75a7b659":"markdown","542320d1":"markdown","77874443":"markdown","64cc9726":"markdown","e169ed44":"markdown","6e1d487c":"markdown","cc09d482":"markdown","a1f88893":"markdown","996a9590":"markdown","898d9593":"markdown","480ee742":"markdown","f85cb1d1":"markdown","e224814f":"markdown","c52973e1":"markdown","dc52adb1":"markdown","ac6f1b93":"markdown","ff7d248f":"markdown","9f0b4ef8":"markdown","411264e1":"markdown","81b2d57c":"markdown","cece1dd8":"markdown","beadab43":"markdown","c13c4112":"markdown","cb1f8302":"markdown","7672fc13":"markdown","da064559":"markdown","a6d79069":"markdown","8d0b4aa4":"markdown","88a5ce48":"markdown"},"source":{"0515b328":"import numpy as np\nimport pandas as pd","f76d8381":"train_data = pd.read_csv('\/kaggle\/input\/titanic-data\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/titanic-data\/testy.csv')","9e6c4d00":"train_data.head()","45e689d9":"train_data.info()","8f1d127b":"median = train_data.median()\ntrain_data.fillna(median, inplace= True)","14d6a6ef":"from sklearn.impute import SimpleImputer\nImputer = SimpleImputer(strategy= 'median')","0f319295":"train_numerical_data = train_data.drop(['Cabin','Name','Sex','Embarked','Ticket'], axis = 1)","f8373f82":"train_numerical_data","a44877f1":"X = Imputer.fit_transform(train_numerical_data)","1d79ea2a":"type(X)","7b829854":"train_numerical = pd.DataFrame(X, columns= train_numerical_data.columns)","ecd7fd6c":"train_numerical","5a04a89e":"train_numerical_data.median()","44b6d75e":"Imputer.statistics_","62738dd3":"train_text = train_data.drop(['PassengerId','Survived','Pclass','Age','SibSp','Parch','Fare' ], axis= 1)","324875a3":"train_text.describe()","26c4e8fd":"train_text.drop(['Name','Ticket','Cabin'],axis = 1, inplace = True)","63216312":"from sklearn.impute import SimpleImputer  \nImputer = SimpleImputer(strategy= 'most_frequent')","0edaefb2":"X = Imputer.fit_transform(train_text)","077cac56":"train_text_fulldata = pd.DataFrame(X, columns=['Sex', 'Embarked'])","240275d2":"train_text_fulldata.describe()","fd00c8d1":"from sklearn.preprocessing import OrdinalEncoder\nordinal_encoder = OrdinalEncoder()\ntrain_text_encoded = ordinal_encoder.fit_transform(train_text_fulldata)","3508a0ad":"ordinal_encoder.categories_","2d01579d":"train_data[['Pclass','Survived']].groupby(['Pclass']).mean()","1b51be4f":"combine =[train_data,test_data]","24552b30":"combine","45cc8b02":"train_data.columns.value_counts()","485b8e59":"test_data = pd.read_csv('\/kaggle\/input\/titanic-data\/testy.csv')\ntest_data.head()","8b203e5a":"women = train_data.loc[train_data.Sex == 'female']['Survived']","33b6288a":"rate_women = sum(women)\/len(women)","c2e6cff4":"rate_women","82b77fad":"men = train_data.loc[train_data.Sex == 'male']['Survived']","2bb1ae7a":"rate_men = sum(men)\/len(men)","0693cf6a":"rate_men","726905a0":"from sklearn.ensemble import RandomForestClassifier\ny = train_data['Survived']\nfeatures = ['Pclass','Sex','SibSp','Parch']\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\nmodel = RandomForestClassifier(n_estimators= 100, max_depth= 5, random_state= 1)\nmodel.fit(X,y)\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId':test_data.PassengerId, 'Survived':predictions})\noutput.to_csv('my_submission.csv', index = False)\n","d1bc8b86":"train_data.info()","9e5be965":"train_data['Cabin'].value_counts()","f5a6843e":"train_data.describe()","714175eb":"%matplotlib inline\nimport matplotlib.pyplot as plt\ntrain_data.hist(bins=50, figsize= (25,25))\nplt.show()","279db759":"correlation_data = train_data.corr()","fdd3f5d1":"correlation_data","8bc61dcf":"correlation_data['Survived'].sort_values(ascending = False)","f605f4c6":"correlation_data.sort_values(by='Survived',ascending=False)","914ebdd4":"traindata = train_data.copy()","e60c9edf":"traindata = pd.DataFrame({'Parch':train_data['Parch'],'Fare':train_data['Fare']})","edba7089":"from sklearn.linear_model import LinearRegression\nlinreg = LinearRegression()\nlinreg.fit(traindata,train_data['Survived'])","7050333e":"testset = pd.DataFrame({'Parch':test_data['Parch'],'Fare':test_data['Fare']})","ea7b34f3":"testset['Fare'].fillna(method = 'bfill')","8c8527c1":"linreg.predict(testset)","30f6e62e":"**We have to start by exploring our dataset**","abf1ec9b":"**Deleting datapoints is a tradeoff between prediction efficiency and class representation. With very little datapoints we cannot expect the model to give efficient predictions for new cases.**","61b3fd1b":"**To view the categories of the categorical variables, we can use the .categories_ instance variable**","9844b84d":"**Load train data and test data, and copy the data to individual dataframes**","75a7b659":"For modeling purpose, we need data from all the columns.","542320d1":"**Load the necessary libraries**","77874443":"You can cross check if median values have replaced the empty datapoints by ","64cc9726":"We have 12 columns with 2 in float, 5 in int, and 5 in object(Strings)","e169ed44":"**Now that we have all the missing data filled, we can now assign each category a digit and then proceed with the modeling process**","6e1d487c":"**As we can see from the above only 2 of the 5 are categorical features. They are Sex and Embarked. To easily identify this, have a look at the number of unique values per column. The ratio of Unique\/Count is good indicator of whether the feature is Categorical or plain text**","cc09d482":"**We can start with a basic polynomial regression that is based on Fare, Parch, and survived.** ","a1f88893":"Now let's have a look at the different categories present in columns of the **'object'** dtype","996a9590":"The above method of using median **does not apply to string objects**, so we'll have to handle them differently.","898d9593":"We are choosing **median** since it represents the data better than a random value. \n\nAlso, we aren't using **mean** since outliers can affect the value to a large extent.","480ee742":"**View the columns and get an idea about the data.**","f85cb1d1":"**Since our algorithms cannot work with text data, we'll have to represent the text data as numerical values.**\n\nThis is called **Encoding**","e224814f":"Plot histograms to see the data distribution as a function of its counts.","c52973e1":"We are able to see that the columns **Age** and **Cabin** do not have entries for all the PassengerId.","dc52adb1":"1) Delete datapoints in the remaining 10 columns that are not represented in the columns (**Age, Cabin, and Embarked **) \n\n2) Get rid of the columns **Age, Cabin, and Embarked**\n\n3) Add a new value to the missing datapoints","ac6f1b93":"**Exploring the dataset to yiled better accuracy**","ff7d248f":"We next view the statistical figures summarising train data.","9f0b4ef8":"Three techniques can be adopted for the same.","411264e1":"Find the correlations between different variables.","81b2d57c":"Another method that is provided by **Scikit Learn** to ease this process is **Imputer**","cece1dd8":"So instead we can add a new value representative of the data.","beadab43":"**But the fit_transform method transforms the dataframe into a numpy array. In order to overcome that, we should create a new dataframe with this Imputer transformed values**","c13c4112":"**Check the correaltion between variables and the variable Survived**","cb1f8302":"**.info** is a method that **outputs the type of data of each column and it gives us a count of the total available data.** \n\nThis is useful, since we'll know if the dataset has any missing values","7672fc13":"So we can drop the other three columns, **Name,Ticket, and Cabin.**","da064559":"**fit_transform is an SimpleImputer method by which the missing data is fixed and the entire dataset is transformed**","a6d79069":"**As we see here only Fare and Parch have positive correlation with survival rate**","8d0b4aa4":"Start by viewing the columns in the dataset.","88a5ce48":"As we can see there are 12 columns. \n\nOf the 12 columns, 10 columns have 891 datapoints and 3 columns **(Age, Cabin, Embarked)** have less than 891 datapoints."}}