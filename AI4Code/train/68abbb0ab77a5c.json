{"cell_type":{"88a64d2f":"code","7f0f586c":"code","953288bc":"code","67abb027":"code","67d81457":"code","05382e80":"code","b73400db":"code","753efcb0":"code","9f7a7d37":"code","e6a2f030":"code","12430a8f":"code","18a9a14a":"code","d175629d":"code","bab060ee":"code","82c23eee":"code","bc13f8f1":"code","56773475":"code","c839a7d8":"code","841826e8":"code","ee145c83":"code","10b4e55c":"code","3a70eb03":"code","0401ed4a":"code","db3cc5c6":"code","8e917590":"markdown","183c0907":"markdown","3cd21de6":"markdown","bfd75af3":"markdown","920f75e3":"markdown","efef2274":"markdown","3e4a6f04":"markdown","5ab2439d":"markdown","aba33fe8":"markdown","4bff6aec":"markdown","19225e63":"markdown","849ba037":"markdown","995d9391":"markdown","b9b44e15":"markdown","5e6aea6c":"markdown","f9bca55e":"markdown","ff3251ea":"markdown","ad635e2f":"markdown","efe575a2":"markdown","042a6389":"markdown","1c13ac07":"markdown","03e92d9d":"markdown","e7d46498":"markdown","f6692854":"markdown","e6e42bf6":"markdown","43dec3bf":"markdown","656342bd":"markdown"},"source":{"88a64d2f":"import numpy as np\nimport pandas as pd","7f0f586c":"import warnings\nwarnings.filterwarnings('ignore')","953288bc":"train = pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/train.csv\")\n#Stores the \"train.csv\" file read in the format of dataframe in the train variable.","67abb027":"test = pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/test.csv\")\n#Store the \"test.csv\" file read in dataframe format in the test variable.","67d81457":"sample = pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/sample_submission.csv\")\n#Store the \"sample_submission.csv\" file read in the format dataframe in the test variable.","05382e80":"train.shape\n#Train data for learning is said to consist of 250,000 rows and 102 columns.","b73400db":"test.shape\n#The test data to be predicted has 150000 rows and 101 columns, excluding the loss column, which is the value to be predicted.","753efcb0":"train.head(10)\n#The Pandas dataframe format allows you to view data from the top using .head().","9f7a7d37":"test.head()\n#The dataframe format allows you to easily view values using head() and has five default values.","e6a2f030":"sample.head()\n#You can view the type of data that needs to be submitted.","12430a8f":"X = train.drop([\"loss\",\"id\"],axis=1)\ny = train[\"loss\"]\n#Before entering, divide the training data by the feature to be used for learning and the target value for it.","18a9a14a":"from sklearn.model_selection import train_test_split\nX_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.2,random_state=38)\n#Create a valid dataset to check for problems such as overfitting and underfitting.","d175629d":"from sklearn.ensemble import RandomForestRegressor\nrandom_forest = RandomForestRegressor()\nrandom_forest.fit(X_train,y_train)","bab060ee":"from lightgbm import LGBMRegressor\nlightgbm = LGBMRegressor()\nlightgbm.fit(X_train,y_train)","82c23eee":"from sklearn.metrics import mean_squared_error\n#import mean_squared_error evaluation indicator in sklearn","bc13f8f1":"def rmse(y_true, y_pred):\n    from sklearn.metrics import mean_squared_error\n    from math import sqrt\n    return sqrt(mean_squared_error(y_true, y_pred))\n#The desired value is root applied, so the math library returns the value using root.","56773475":"random_forest_pred=random_forest.predict(X_val)\nrandom_forest_score = rmse(random_forest_pred,y_val)\nprint(\"random forest score:\",random_forest_score)","c839a7d8":"lightgbm_pred=lightgbm.predict(X_val)\nlightgbm_score = rmse(lightgbm_pred,y_val)\nprint(\"lightgbm score:\",lightgbm_score)","841826e8":"from sklearn.model_selection import GridSearchCV","ee145c83":"from lightgbm import LGBMRegressor\nlgbm = LGBMRegressor()\n\nlgbm_param = {\"learning_rate\" : [0.1, 0.038,0.003, 0.001]}\nlgbm_grid_search = GridSearchCV(lgbm,param_grid=lgbm_param)\n\nlgbm_grid_search.fit(X_train,y_train)\ny_pred=lgbm_grid_search.predict(X_val)\nlgbm_score = rmse(y_pred,y_val)\nprint(lgbm_score)\nprint(lgbm_grid_search.best_params_)","10b4e55c":"ids = sample[\"id\"]\n#Use the id value of sample_submission","3a70eb03":"preds = random_forest.predict(test.drop('id', axis=1))\noutput = pd.DataFrame({\"id\":ids, \"loss\":preds})\noutput.to_csv(\"random_forest.csv\", index=False)","0401ed4a":"preds = lightgbm.predict(test.drop('id', axis=1))\noutput = pd.DataFrame({\"id\":ids, \"loss\":preds})\noutput.to_csv(\"lightgbm.csv\", index=False)","db3cc5c6":"preds = lgbm_grid_search.predict(test.drop('id', axis=1))\noutput = pd.DataFrame({\"id\":ids, \"loss\":preds})\noutput.to_csv(\"lgbm_grid_search.csv\", index=False)","8e917590":"**Rather than implementing the model, we import and use RandomForestRegressor and LGBMRegressor.**\n\n**But for good performance, we need to understand how the model works.**","183c0907":"**In addition to tuning the model's hyperparameters, there are many ways to improve the model's performance.**\n\n**1. Perform feature engineering.**\n\n**2. It combines models such as model ensembles to produce better performance.**\n\n**3. We use methods such as pseudo labeling to access more data.**\n\n**I hope you get good grades using various methods.**","3cd21de6":"**Due to the characteristics of the tabular competition, there is little connection between features and data preprocessing, so I recommend you look at other people's notebooks for the eda part.**\n\n**Data preprocessing is critical in real-world data analysis. Therefore, I recommend you to participate in another competition to learn how to preprocess data.**\n\n----------","bfd75af3":"**This is the process of importing the library that will be used.**\n\n**numpy to help with mathematical operations,**\n\n**Imports pandas that help process data by default.**","920f75e3":"**Describes the process of dividing training data and validating it with a valid dataset.**","efef2274":"**Use the .head() and shape features that support the pandas dataframe format to see what data is in any format.**","3e4a6f04":"**The Tabular Playground Series is a competition aimed at dealing with and predicting data for beginners who have entered data analysis.**\n\n**I also experienced the tabular competition as a beginner, but I tried many ways and achieved the 14th place on the leader board of the May competition.**\n\n**In this process, I felt that the first people to learn data and make submission guidelines were necessary.**\n\n**Only covered lightgbm and random forest, which are frequently used by kaggle.**\n\n**As I'm a beginner, there are a lot of \"Huh?\" parts. Questions and comments are welcome.**\n\n-------","5ab2439d":"**Reads the csv file in pandas dataframe format for viewing and processing data.**\n\n**Enter a path in read_csv of pandas to receive data.** \n\n**Paths can be easily obtained by copying the data in input.**","aba33fe8":"# **Model Evaluation**","4bff6aec":"# **How to increase the performance of your model**","19225e63":"# **Library import**","849ba037":"**A train dataset is a dataset with values and actual values for each feature for learning.**\n\n**test dataset is a dataset for prediction, and you must predict the target value based on it.**\n\n**Sample_submission shows the type of submission that must be submitted.**\n\n----------","995d9391":"**There are many ways to maximize the model's performance.**\n\n**Typically, you set the model's hyperparameters to find the parameter values that fit your data first.**","b9b44e15":"# **Data load**","5e6aea6c":"# **Machine Learning Model Description**","f9bca55e":"**To help you understand, we have adjusted only simple parameters.**\n\n**There are many ways to tune hyperparameters. I want you to look it up.**\n\n**I hope to find a good AI model by adjusting various parameters.**","ff3251ea":"**GridSearchCV tests all specified cases and finds the best parameters.**","ad635e2f":"**Valid dataset to evaluate the performance of the model using.**\n\n**The root_mean_square_error evaluation indicator used in the actual competition was used.**","efe575a2":"https:\/\/www.kaggle.com\/songwonmin\/for-korean-tabular-aug-2021\n\n**This notebook is translated into a translator, so it may not be easy to understand.**","042a6389":"# **Before we go in,**","1c13ac07":"**In order to prevent unnecessary warnings from increasing scrolling, import the warning to ignore the warning.**","03e92d9d":"# **Tuning some hyperparameters for better performance**","e7d46498":"# **notice**","f6692854":"**Use the id of the sample_submission and the predicted values of test_data to make the result a csv file.**\n\n**The to_csv function in pandas allows you to convert values in the form of dataframes into csv.**","e6e42bf6":"# **Make Submission**","43dec3bf":"# **Viewing data**","656342bd":"**Outputs a core that calculates metrics by putting predictions and actual values in the function.**"}}