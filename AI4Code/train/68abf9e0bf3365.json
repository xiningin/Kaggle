{"cell_type":{"0fdc1162":"code","40444bfe":"code","c8adfc4d":"code","46d06d34":"code","23c6eaef":"code","01ede164":"code","a011add0":"code","a246cf70":"code","9870ac73":"code","a7834cb1":"code","cc07f18d":"code","9a0cf70b":"code","532c5029":"code","ce5daa51":"code","a119df1a":"code","4a1edf97":"code","8e23f7e5":"code","41d3959a":"code","d689ec9b":"code","42f8c777":"code","e1779032":"code","79412474":"code","145e2526":"code","b02ec2ea":"code","1f4a59f1":"code","fbcf883d":"code","317e2770":"code","617a39e1":"code","14889f85":"code","9de7e583":"code","192ab8c0":"code","e9666d95":"code","080adde3":"code","ee435913":"code","0d2ebfc1":"code","bf483127":"code","d0656b18":"code","76b34cf6":"code","016e9290":"code","480810be":"markdown","a9597312":"markdown","580c39d3":"markdown","f337b007":"markdown","7cfb2f37":"markdown","2df45a0b":"markdown","3172fbc4":"markdown","ce24085d":"markdown","5b749572":"markdown","1bc53981":"markdown","5bac92a7":"markdown","2c07408c":"markdown","04726342":"markdown","a171d087":"markdown","35aab359":"markdown","4fa23c78":"markdown","e84329e0":"markdown","846aa127":"markdown","37860637":"markdown","1274b88c":"markdown","4de80ea5":"markdown","758a6122":"markdown","a138fee6":"markdown"},"source":{"0fdc1162":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","40444bfe":"data = pd.read_csv(\"..\/input\/friends-tv-show-all-seasons-and-episodes-data\/friends_info.csv\")\ndata.head()","c8adfc4d":"data.info()","46d06d34":"data.describe()","23c6eaef":"data.Episode","01ede164":"# Date column\n\ndata[\"release_year\"] = pd.DatetimeIndex(data['Date']).year\ndata[\"release_month\"] = pd.DatetimeIndex(data['Date']).month\ndata[\"release_day\"] = pd.DatetimeIndex(data['Date']).day\ndata.drop(\"Date\", axis = 1, inplace = True)","a011add0":"data.Episode","a246cf70":"seasons = []\nepisodes = []\n\nfor i in data.Episode:\n    try:\n        seasons.append(i.split(\"-\")[0])\n    except:\n        seasons.append(\"Special\") \n    try:\n        episodes.append(i.split(\"-\")[1])\n    except:\n        episodes.append(\"Special\")\n\ndata[\"episode_number\"] = episodes\ndata[\"season_number\"] = seasons\ndata[\"episode-season\"] = data[\"Episode\"]\ndata.drop(\"Episode\", axis = 1, inplace = True)","9870ac73":"# written by column\n\nwritten_number = [] \nfor i in data[\"Written by\"]:\n    written_number.append(str(i).count('&') + 1)\n    \ndata[\"writtenby_number\"] = written_number\ndata[\"writtenby_number\"].value_counts()","a7834cb1":"# rating\/ share column\nrating_score = []\nfor i in data[\"Rating\/Share\"]:\n    rating_score.append(float(i.split(\"\/\")[0]) \/ float(i.split(\"\/\")[1]))\n\ndata[\"rating\"] = rating_score\ndata.drop(\"Rating\/Share\", axis = 1, inplace=True)","cc07f18d":"# remove the prod column\ndata.drop(\"Prod.\\ncode\", axis = 1, inplace=True)","9a0cf70b":"# US viewers change to float\nfor i in range(len(data[\"U.S. viewers\"])):\n    data[\"U.S. viewers\"].iloc[i] = float(data[\"U.S. viewers\"].iloc[i].replace(' million', ''))\n","532c5029":"data[\"U.S. viewers\"]","ce5daa51":"# rename some column with spaces\n\ndata.columns = data.columns.str.replace(' ', '_')\ndata.columns = data.columns.str.replace('.', '')","a119df1a":"data.head()","4a1edf97":"from pandas_profiling import ProfileReport\nProfileReport(data)","8e23f7e5":"# views vs ratings\n\nsns.relplot(x=\"US_viewers\", y=\"rating\", data=data);","41d3959a":"sns.heatmap(data.corr());","d689ec9b":"plt.hist(data.US_viewers);","42f8c777":"rachel = []\nmonica = []\nross = []\nchandler = []\njoey = []\nphoebe = []\n\nfor i in range(len(data)):\n    # there are still nan values (possibly i could've filled them with \"missing\" value, too)\n    try:\n        if \"Rachel\" in data.Summary.iloc[i]:\n            rachel.append((data.US_viewers.iloc[i], data.rating.iloc[i]))\n        if \"Monica\" in data.Summary.iloc[i]:\n            monica.append((data.US_viewers.iloc[i],data.rating.iloc[i]))\n        if \"Ross\" in data.Summary.iloc[i]:\n            ross.append((data.US_viewers.iloc[i], data.rating.iloc[i]))\n        if \"Chandler\" in data.Summary.iloc[i]:\n            chandler.append((data.US_viewers.iloc[i], data.rating.iloc[i]))\n        if \"Joey\" in data.Summary.iloc[i]:\n            joey.append((data.US_viewers.iloc[i], data.rating.iloc[i]))\n        if \"Phoebe\" in data.Summary.iloc[i]:\n            phoebe.append((data.US_viewers.iloc[i], data.rating.iloc[i]))\n    except:\n        pass","e1779032":"# viewers\nrachel_sum = sum([r[0] for r in rachel])\nmonica_sum = sum([r[0] for r in monica])\nross_sum = sum([r[0] for r in ross])\nphoebe_sum = sum([r[0] for r in phoebe])\nchandler_sum = sum([r[0] for r in chandler])\njoey_sum = sum([r[0] for r in joey])\n\n\n\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nax.axis('equal')\nnames = ['Rachel', 'Monica', 'Ross', 'Phoebe', 'Chandler', 'Joey']\nlist_sum = [rachel_sum, monica_sum, ross_sum, phoebe_sum, chandler_sum, joey_sum]\nax.pie(list_sum, labels = names,autopct='%1.2f%%')\nplt.show()","79412474":"# ratings\n\nrachel_sum = sum([r[1] for r in rachel])\nmonica_sum = sum([r[1] for r in monica])\nross_sum = sum([r[1] for r in ross])\nphoebe_sum = sum([r[1] for r in phoebe])\nchandler_sum = sum([r[1] for r in chandler])\njoey_sum = sum([r[1] for r in joey])\n\n\n\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nax.axis('equal')\nnames = ['Rachel', 'Monica', 'Ross', 'Phoebe', 'Chandler', 'Joey']\nlist_sum = [rachel_sum, monica_sum, ross_sum, phoebe_sum, chandler_sum, joey_sum]\nax.pie(list_sum, labels = names,autopct='%1.2f%%')\nplt.show()","145e2526":"x = []\n\nfor i in data.Summary:\n    try:\n        x.append(i.count(\"Rachel\"))\n    except:\n        x.append(0)\n        \ndata[\"rachel_count\"] = x","b02ec2ea":"data.shape","1f4a59f1":"data.info()","fbcf883d":"data.drop(\"episode-season\", axis = 1, inplace = True)","317e2770":"for i in range(len(data.episode_number)):\n    try:\n        if data.episode_number.iloc[i] == \"Special\":\n            data.episode_number.iloc[i] = 0\n        else:\n            data.episode_number.iloc[i] = int(i)\n    except:\n        data.episode_number.iloc[i] = int(i.str.replace('\\n', ''))\n","617a39e1":"for i in range(len(data.season_number)):\n    try:\n        if data.season_number.iloc[i] == \"Special\":\n            data.season_number.iloc[i] = 0\n        data.season_number.iloc[i] = int(data.season_number.iloc[i])\n    except:\n        data.season_number.iloc[i] = int(data.season_number.iloc[i].str.replace('\\n', ''))\n","14889f85":"data.drop(\"Summary\", axis = 1, inplace = True)","9de7e583":"data.season_number = pd.to_numeric(data.season_number)\ndata.episode_number = pd.to_numeric(data.episode_number)\ndata.US_viewers = pd.to_numeric(data.US_viewers)","192ab8c0":"cat_cols = list(set(data.columns) - set(data._get_numeric_data().columns))\ncat_cols","e9666d95":"dummies = pd.get_dummies(data[cat_cols])\ndata = data.drop(cat_cols, axis = 1)\ndata = pd.concat([data, dummies], axis = 1)","080adde3":"data.head()","ee435913":"len(data) * 0.8","0d2ebfc1":"# note that the data is already in ascending order in terms of release date\ntrain = data[:183]\ntest = data[183:]","bf483127":"train.isna().sum()","d0656b18":"train[\"Duration\"].fillna(train.Duration.mean(), inplace = True) ","76b34cf6":"test.isna().sum().sum()\ntest[\"Duration\"].fillna(test.Duration.mean(), inplace = True) ","016e9290":"X_train, y_train = train.drop(\"rating\", axis = 1), train[\"rating\"]\nX_test, y_test = test.drop(\"rating\", axis = 1), test[\"rating\"]","480810be":"I will also check if a character that is mentioned in the summary (such as Rachel or Monica) is somehow related to ratings or views.","a9597312":"\ud83e\udd2f At this point, we are done with tweaking the features (of course, we can always go back and iterate through different methods again). I will know **visualize** some of the columns to better understand the relation.\n\nI am currently reading **[The Data Science Handbook](https:\/\/jakevdp.github.io\/PythonDataScienceHandbook\/)**, so I will try to apply what I've learned in here. It is important to apply what you've recently learnt and it is one of things I really love about Kaggle: you can apply what you've learned in books or courses here \u2b50\ufe0f\n\n**Things that Caught My Eye During `Understanding Data` part:**\n1. views vs. number of writers\n2. views vs. date (month, day, year)\n3. views and writers (who wrote it)\n4. views and directors\n5. us viewers and ratings\n\n\nand whatever catches my attention during visualization :)\n\n","580c39d3":"## Train Test Split\n\nIt is important to split our data before filling the missing values to prevent data snooping.\n\ni will keep the test size as 0.2.","f337b007":"# Understanding Data","7cfb2f37":"## Fill Missing Values","2df45a0b":"# Define the Problem","3172fbc4":"![friends-tv-show-1542126105](https:\/\/user-images.githubusercontent.com\/66208179\/120125041-aa98ff80-c1bf-11eb-9e56-6b1990a1f720.jpeg)","ce24085d":"Feel free to discover what Pandas Profiling showed us. \n\nHere are some of my takes:\n\n\ud83c\udf0e**Correlation Matrix**: There isn't any correlation between numerical values.\n\n<img width=\"663\" alt=\"Screen Shot 2021-05-31 at 3 03 21 PM\" src=\"https:\/\/user-images.githubusercontent.com\/66208179\/120232412-3496a600-c25c-11eb-9a81-4f086cf12f38.png\">\n\n\ud83c\udf08**The directors** that appaeared the most:\n\n<img width=\"410\" alt=\"Screen Shot 2021-05-31 at 3 01 30 PM\" src=\"https:\/\/user-images.githubusercontent.com\/66208179\/120232414-35c7d300-c25c-11eb-90f2-cf52ab800652.png\">\n\n\ud83d\udc41The **views** in the US:\n\n<img width=\"556\" alt=\"Screen Shot 2021-05-31 at 3 02 08 PM\" src=\"https:\/\/user-images.githubusercontent.com\/66208179\/120232415-36606980-c25c-11eb-97e5-4df4e05ca2e4.png\">","5b749572":"On eof my favourite libraries is **Pandas Profiling**. You can check [this notebook](https:\/\/www.kaggle.com\/dtomruk\/commonlit-eda-modeling) to learn more about it.","1bc53981":"Not a huge difference on ratings either. Rachel seems to attract more viewers and ratings though! \ud83e\uddda\n\nThe \ud83d\udc51queen\ud83d\udc51  deserves her own column then :)","5bac92a7":"Check [*this tutorial*](https:\/\/www.tutorialspoint.com\/matplotlib\/matplotlib_pie_chart.htm#:~:text=Matplotlib%20API%20has%20a%20pie,array%20will%20not%20be%20normalized.) for pie charts.","2c07408c":"## Handling Categorical Data","04726342":"There doesn't seem to be a huge difference when it comes to viewers.","a171d087":"# Data Visualization","35aab359":"# Importing Libraries","4fa23c78":"### Test","e84329e0":"\ud83c\udf31 `Written by` column will **depend on the number of `&` characters** since it is the format the dataframe follows. If there is no `&`, we have one writer; if there is one `&`, there are 2 writers and so on.","846aa127":"Few things first:\n- `episode_number`, `season_number` and`US viewers` can be expressed as a float. Let's fix that.\n- we can drop `episode-season` since we already have those in separate columns.","37860637":"I will apply the following transformations:\n    \n- `Date`: get the date as year, day and month solely and add them as new columns\n\n- `Episode`: keep the episode column, but also create two other columns for episode and season separetely\n\n- `Title`: keep it like it is for EDA, but since this a categorical column we will need to transform it before modeling\n\n- `Directed by`: keep it like it is for EDA, but since this a categorical column we will need to transform it before modeling\n\n- `Written by`: add a column `written_by_numbers` to keep track of how many people have written the episode\n\n- `Duration`: keep it like it is\n\n- `Summary`:  keep it like it is for EDA, but since this a categorical column we will need to transform it before modeling\n\n- `Rating\/Share`: make the division and keep that value\n\n- `U.S. viewers`: change to float\n- `Prod. code`: can be removed","1274b88c":"### Train","4de80ea5":"## Can we predict the ratings of episodes based on other columns?\n\nThe approach will be based on time-series. Our model can learn from previous episodes and predict the rating of future episodes. This is a regression problem since the target is ratings, a continous value.\n\nBefore getting into modeling, we need to do several things:\n- categorical to numerical transformations\n- train test split \n- fill missing values\n- scaling if needed","758a6122":"Friends is one my favorite tv shows \u2764\ufe0f. I remember crying about the final for two days \ud83d\ude05 (it was so touching to see every character grow throughout the show \u2728).\n\nIn this project, I will be getting a bit nostalgic and will try to understand given data through Exploratory Data Analysis. I will also see if we can predict something (at this point, anything). It can be sentiment analysis based on summaries and titles, or classification for the number of episode contributers.\n\n# Data\n\nWe have the following columns:\n    \n- `Date`: the date of release for the episode\n\n- `Episode`: episode number (season - episode)\n\n- `Title`: episode title\n\n- `Directed by`\n\n- `Written by`\n\n- `Duration` \n- `Summary`\n\n- `Rating\/Share`\n\n- `U.S. viewers`: how many people viewed the episode in the US\n\n- `Prod. code`: unique values\n\n\n# Process:\n\n1. \u2705Tweak the data a bit to understand the data in detail.\n2. \u2705Try to understand any type of correlation.\n3. \u2705If there is - model!","a138fee6":"\ud83e\uddd0 As we can see, there are some special columns that do not follow the **episode-season** format. So I will create an exception to make sure we are keeping track of different formats and classify them as missing."}}