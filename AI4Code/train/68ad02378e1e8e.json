{"cell_type":{"6649072a":"code","b5f453b5":"code","61402499":"code","d3b1a92c":"code","da41aa72":"code","bc343298":"code","1e15451b":"code","354d9f36":"code","7f302cda":"code","26d5a4b5":"code","8eaa5488":"code","29d112c0":"code","db275136":"code","574f8619":"code","1b77c1b0":"code","880a1ad0":"code","fd00ae37":"code","d7610fa3":"code","ebefd77d":"code","796181e2":"code","b6796e27":"code","9f01cd6b":"code","5aa29c5a":"code","e1561dc3":"code","905cde83":"code","ad0b42ae":"code","58f24417":"code","f6f7db3b":"code","65c1b7e6":"code","58542cd3":"code","a13b8574":"code","877b0745":"code","a2142899":"code","45295bd3":"code","3f7c3a14":"code","57e1a963":"code","e96f5f1a":"code","f6e7e33e":"markdown","516f95c7":"markdown","bb50b170":"markdown","dd7a2681":"markdown","d650c53e":"markdown","3bf70a85":"markdown","73981f44":"markdown","d9f463f5":"markdown","f25b4f68":"markdown","023805ba":"markdown","6f7cb447":"markdown","c453da6e":"markdown","8951c383":"markdown","05d05ecb":"markdown","9473fd37":"markdown","72508c6c":"markdown","18d1fb2d":"markdown","c3518e5d":"markdown","aad5dbe3":"markdown","3913adb3":"markdown","57951ab3":"markdown","1183282f":"markdown","2b8bfdde":"markdown","6276e963":"markdown"},"source":{"6649072a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nfrom sklearn.preprocessing import StandardScaler # To standardize the data\nfrom sklearn.ensemble import IsolationForest # To find and eliminate the outliers.\nfrom keras.models import Sequential # Sequential Neural Network\nfrom keras.layers import Dense\nfrom keras.callbacks import EarlyStopping # Early Stopping Callback in the NN\nfrom keras.optimizers import Adam # Optimizer used in the NN\nfrom kerastuner.tuners import RandomSearch # HyperParameter Tunining\nimport warnings\nwarnings.filterwarnings('ignore')","b5f453b5":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\ny = train['SalePrice'].values\ndata = pd.concat([train,test],axis=0,sort=False)\ndata.drop(['SalePrice'],axis=1,inplace=True)\ndata.head()","61402499":"data.info()","d3b1a92c":"column_data_type = []\nfor col in data.columns:\n    data_type = data[col].dtype\n    if data[col].dtype in ['int64','float64']:\n        column_data_type.append('numeric')\n    else:\n        column_data_type.append('categorical')\nplt.figure(figsize=(15,5))\nsns.countplot(x=column_data_type)\nplt.show()","da41aa72":"missing_values = data.isnull().sum()\nmissing_values = missing_values[missing_values > 0].sort_values(ascending = False)\nmissing_values\nNAN_col = list(missing_values.to_dict().keys())\nmissing_values_data = pd.DataFrame(missing_values)\nmissing_values_data.reset_index(level=0, inplace=True)\nmissing_values_data.columns = ['Feature','Number of Missing Values']\nmissing_values_data['Percentage of Missing Values'] = (100.0*missing_values_data['Number of Missing Values'])\/len(data)\nmissing_values_data\n","bc343298":"data['BsmtFinSF1'].fillna(0, inplace=True)\ndata['BsmtFinSF2'].fillna(0, inplace=True)\ndata['TotalBsmtSF'].fillna(0, inplace=True)\ndata['BsmtUnfSF'].fillna(0, inplace=True)\ndata['Electrical'].fillna('FuseA',inplace = True)\ndata['KitchenQual'].fillna('TA',inplace=True)\ndata['LotFrontage'].fillna(data.groupby('1stFlrSF')['LotFrontage'].transform('mean'),inplace=True)\ndata['LotFrontage'].interpolate(method='linear',inplace=True)\ndata['MasVnrArea'].fillna(data.groupby('MasVnrType')['MasVnrArea'].transform('mean'),inplace=True)\ndata['MasVnrArea'].interpolate(method='linear',inplace=True)","1e15451b":"for col in NAN_col:\n    data_type = data[col].dtype\n    if data_type == 'object':\n        data[col].fillna('NA',inplace=True)\n    else:\n        data[col].fillna(data[col].mean(),inplace=True)","354d9f36":"data['Total_Square_Feet'] = (data['BsmtFinSF1'] + data['BsmtFinSF2'] + data['1stFlrSF'] + \n                                                                 data['2ndFlrSF'] + data['TotalBsmtSF'])\n\ndata['Total_Bath'] = (data['FullBath'] + (0.5 * data['HalfBath']) + data['BsmtFullBath'] + \n                                                                  (0.5 * data['BsmtHalfBath']))\n\ndata['Total_Porch_Area'] = (data['OpenPorchSF'] + data['3SsnPorch'] + \n                                                data['EnclosedPorch'] + data['ScreenPorch'] + data['WoodDeckSF'])\n\ndata['SqFtPerRoom'] = data['GrLivArea'] \/ (data['TotRmsAbvGrd'] + data['FullBath'] +\n                                                       data['HalfBath'] + data['KitchenAbvGr'])\n","7f302cda":"data = pd.get_dummies(data)\ndata.head()","26d5a4b5":"train = data[:1460].copy()\ntest = data[1460:].copy()\ntrain['SalePrice'] = y\ntrain.head()","8eaa5488":"top_features = train.corr()[['SalePrice']].sort_values(by=['SalePrice'],ascending=False).head(30)\nplt.figure(figsize=(5,10))\nsns.heatmap(top_features,cmap='rainbow',annot=True,annot_kws={\"size\": 16},vmin=-1)","29d112c0":"def plot_data(col, discrete=False):\n    if discrete:\n        fig, ax = plt.subplots(1,2,figsize=(14,6))\n        sns.stripplot(x=col, y='SalePrice', data=train, ax=ax[0])\n        sns.countplot(train[col], ax=ax[1])\n        fig.suptitle(str(col) + ' Analysis')\n    else:\n        fig, ax = plt.subplots(1,2,figsize=(12,6))\n        sns.scatterplot(x=col, y='SalePrice', data=train, ax=ax[0])\n        sns.distplot(train[col], kde=False, ax=ax[1])\n        fig.suptitle(str(col) + ' Analysis')\n    \nprint('Plot Function is ready to use')","db275136":"plot_data('OverallQual',True)","574f8619":"train = train.drop(train[(train['OverallQual'] == 10) & (train['SalePrice'] < 200000)].index)","1b77c1b0":"plot_data('Total_Square_Feet')","880a1ad0":"plot_data('GrLivArea')","fd00ae37":"plot_data('Total_Bath')","d7610fa3":"train = train.drop(train[(train['Total_Bath'] > 4) & (train['SalePrice'] < 200000)].index)","ebefd77d":"plot_data('TotalBsmtSF')","796181e2":"train = train.drop(train[(train['TotalBsmtSF'] > 3000) & (train['SalePrice'] < 400000)].index)","b6796e27":"train.reset_index()","9f01cd6b":"clf = IsolationForest(max_samples = 100, random_state = 42)\nclf.fit(train)\ny_noano = clf.predict(train)\ny_noano = pd.DataFrame(y_noano, columns = ['Top'])\ny_noano[y_noano['Top'] == 1].index.values\n\ntrain = train.iloc[y_noano[y_noano['Top'] == 1].index.values]\ntrain.reset_index(drop = True, inplace = True)\nprint(\"Number of Outliers:\", y_noano[y_noano['Top'] == -1].shape[0])\nprint(\"Number of rows without outliers:\", train.shape[0])","5aa29c5a":"X = train.copy()\nX.drop(['SalePrice'],axis=1,inplace=True)\ny = train['SalePrice'].values\nX.shape,y.shape","e1561dc3":"scale = StandardScaler()\nX = scale.fit_transform(X)","905cde83":"def build_model(hp):\n    model = Sequential()\n    for i in range(hp.Int('layers', 2, 10)):\n        model.add(Dense(units=hp.Int('units_' + str(i),\n                                            min_value=32,\n                                            max_value=512,\n                                            step=32),\n                               activation='relu'))\n    model.add(Dense(1))\n    model.compile(\n        optimizer=Adam(\n            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n        loss='mse',\n        metrics=['mse'])\n    return model","ad0b42ae":"tuner = RandomSearch(\n    build_model,\n    objective='val_mse',\n    max_trials=10,\n    executions_per_trial=3,\n    directory='model_dir',\n    project_name='House_Price_Prediction')\ntuner.search_space_summary()","58f24417":"# tuner.search(X[1100:],y[1100:],batch_size=128,epochs=200,validation_data=validation_data=(X[:1100],y[:1100]))\n# model = tuner.get_best_models(1)[0]\n\n# After implementing this and tuning further we get the below model that I have implemented separately.Won't be running this here.","f6f7db3b":"def create_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(320, input_dim=X.shape[1], activation='relu'))\n    model.add(Dense(384, activation='relu'))\n    model.add(Dense(352, activation='relu'))\n    model.add(Dense(448, activation='relu'))\n    model.add(Dense(160, activation='relu'))\n    model.add(Dense(160, activation='relu'))\n    model.add(Dense(32, activation='relu'))\n    model.add(Dense(1))\n    # Compile model\n    model.compile(optimizer=Adam(learning_rate=0.0001), loss = 'mse')\n    return model","65c1b7e6":"model = create_model()\nmodel.summary()","58542cd3":"early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\nhistory = model.fit(x=X,y=y,\n          validation_split=0.1,\n          batch_size=128,epochs=1000, callbacks=[early_stop])","a13b8574":"losses = pd.DataFrame(model.history.history)\nlosses.plot()","877b0745":"model = create_model() # Resetting the model.","a2142899":"history = model.fit(x=X,y=y,\n          batch_size=128,epochs=170)","45295bd3":"losses = pd.DataFrame(model.history.history)\nlosses.plot()","3f7c3a14":"model.evaluate(X,y)","57e1a963":"X_test = scale.transform(test)\nresult = model.predict(X_test)\nresult = pd.DataFrame(result,columns=['SalePrice'])\nresult.head()\nresult['Id'] = test['Id']\nresult = result[['Id','SalePrice']]\nresult.head()","e96f5f1a":"result.to_csv('submission.csv',index=False)","f6e7e33e":"## Loading the Dataset","516f95c7":"<h1><center>House Prices Predictions using Keras<\/center><\/h1>\n<img src=\"https:\/\/i.ytimg.com\/vi\/LvfbopVq-WE\/maxresdefault.jpg\" width=\"500\" height=\"600\">\n<br\/>\n\n<h2>References<\/h2>\n\n[House Prices EDA, Lasso & LightGBM](https:\/\/www.kaggle.com\/mviola\/house-prices-eda-lasso-lightgbm-0-11635)\n\n[ANN House Price Prediction](https:\/\/www.kaggle.com\/ppsheth91\/ann-keras-hyper-parameter-tuning-price-prediction)","bb50b170":"## Again no outliers that can be eliminated.","dd7a2681":"## Training the model with full training data and optimum number of epochs!!","d650c53e":"## After resetting the index,this is the final train data that we get","3bf70a85":"## This seems more or less appropriate distribution with no outliers whatsoever.","73981f44":"## Adding New Features","d9f463f5":"# One Hot Encoding for Categorical Features","f25b4f68":"<h2><center>In this notebook we are going to predict prices using Neural Network<\/center><\/h2>","023805ba":"# Prediction & Evaluation","6f7cb447":"# Descriptive Statistics","c453da6e":"## Her as well we see 1 clear outlier that has TotalBsmtSF more than 3000 but sale price less than 300000.","8951c383":"### We would use Random Algorithm from keras for hyper-parameter tuning of the model.","05d05ecb":"## Note: I would just like to say that Keras is not the most suitable model for this problem since the dataset given in this problem is not sufficient!!","9473fd37":"## We would be using early stopping callback and would use 1\/10th of the training data as validation to estimate the optimum number of epochs that would prevent overfitting","72508c6c":"## Scaling the features using Sklearn Standard Scalar","18d1fb2d":"## Here we clearly see two outliers that have Total_Bath more than 4 but with sale price less than 200000.","c3518e5d":"# Extracting Top Features","aad5dbe3":"# Splitting train and test data","3913adb3":"# MODELLING\n","57951ab3":"## Outlier elimination through Isolation Forest!!\n### We use this algorithm since it would be difficult to go through all the features and eliminate the outliers manually but it was important to do it for the features that have higher correlation with the SalePrice","1183282f":"### We see there are two outliers with 10 overall quality and price less than 200000.","2b8bfdde":"# Filling NAN Values","6276e963":"## Now that we have extracted the top features that influnces the SalePrice we would see their distribution to find outliers."}}