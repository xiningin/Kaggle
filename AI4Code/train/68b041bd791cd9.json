{"cell_type":{"ff3ac226":"code","c0528b73":"code","ecd24b39":"code","63baf007":"code","b64ffa9d":"code","c95ecabd":"code","bfef36ad":"code","c9b6d556":"code","7a53e69a":"code","96a2b0c1":"code","9ed7c747":"code","b725194c":"code","8835b8fb":"code","cfebd043":"code","36721789":"code","ec03d651":"code","5c078062":"code","39a8df54":"code","6fc261bb":"code","677d1c8d":"code","e1b21733":"code","9baeaac7":"markdown","572f0448":"markdown","b061d9bd":"markdown","527f2e64":"markdown","67fb788f":"markdown","6a4b8a7d":"markdown","dba9e6d7":"markdown","acaf36b0":"markdown","06ee7b97":"markdown","0f86c349":"markdown"},"source":{"ff3ac226":"#Import libraries\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import KMeansSMOTE\nfrom sklearn.cluster import MiniBatchKMeans as MiniKM\nimport numpy as np\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\nimport matplotlib.pyplot as plt","c0528b73":"#load dataset\nraw_data = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\") \nprint(raw_data.head())","ecd24b39":"#sample, features - row * column\nprint(raw_data.shape)\n#output- rows, columns","63baf007":"#Print the structure of the data\nprint(raw_data.apply(lambda x: [x.unique()]))","b64ffa9d":"# using the dtypes() method to display the different datatypes available\nprint(raw_data.dtypes)","c95ecabd":"X=raw_data.iloc[:,raw_data.columns!='Class']\nY=raw_data.iloc[:,raw_data.columns=='Class']\nprint(Y.Class.value_counts())","bfef36ad":"X.describe()","c9b6d556":"X['normalizedAmount'] = StandardScaler().fit_transform(X['Amount'].values.reshape(-1,1))\nX['normalizedTime']   = StandardScaler().fit_transform(X['Time'].values.reshape(-1,1))\nX = X.drop(['Amount'],axis=1)\nX = X.drop(['Time'],axis=1)","7a53e69a":"X.head()","96a2b0c1":"X_train,X_test,Y_train,Y_test=\\\ntrain_test_split(X,Y,shuffle=True, test_size = 0.2,random_state=1234)","9ed7c747":"print(X_train.shape)\nprint(Y_train.shape)\nprint(X_test.shape)\nprint(Y_test.shape)","b725194c":"print(Y_train.Class.value_counts())\nprint(Y_test.Class.value_counts())","8835b8fb":"print(Y_train.head())","cfebd043":"print(X_train.dtypes)","36721789":"clf = MiniKM(n_clusters = 100, random_state = 1234)\n\n[print('Class {} has {} instances'.format(label, count))\nfor label, count, in zip(*np.unique(Y_train, return_counts=True))]\n\nkmeans_smote = KMeansSMOTE (sampling_strategy = 0.538,random_state = 1234,k_neighbors=10,\n                            kmeans_estimator = clf,cluster_balance_threshold = \"auto\")\n\nY_train_reshape=np.ravel(Y_train)\nX_KM, Y_KM = kmeans_smote.fit_resample(X_train,Y_train_reshape)\n\n[print('Class {} has {} instances after resampling'.format(label, count))\nfor label, count, in zip(*np.unique(Y_KM, return_counts=True))]","ec03d651":"# Initialising the ANN\nclassifier = Sequential()\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(units =15 , kernel_initializer = 'uniform', activation = 'relu', input_dim = 30))\n# Adding the second hidden layer\nclassifier.add(Dense(units = 15, kernel_initializer = 'uniform', activation = 'relu'))\n# Adding the third hidden layer\nclassifier.add(Dense(units = 15, kernel_initializer = 'uniform', activation = 'relu'))\n# Adding the output layer\nclassifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n# Fitting the ANN to the Training set\nclassifier.fit(X_train, Y_train, batch_size = 32, epochs = 10, validation_split = 0.2, verbose = 2, shuffle = True)","5c078062":"Y_score = classifier.predict(X_test)\nY_pred = (Y_score > 0.5)\n\nclassifier.metrics_names\nscore = classifier.evaluate(X_test, Y_test)\nscore\n\n# model performence with f1-score and accuracy\nprint(classification_report(Y_test, Y_pred))\n\n# Confusion Matrix\ncm = confusion_matrix(Y_test, Y_pred) # rows = truth, cols = prediction\nprint(cm)\n\n# f1_score\nf1 = f1_score(Y_test, Y_pred)\nprint(f1)\n\n# Accuracy_sccore\nAcc = accuracy_score(Y_test, Y_pred)\nprint(Acc)","39a8df54":"# Initialising the ANN\nclf_KM = Sequential()\n# Adding the input layer and the first hidden layer\nclf_KM.add(Dense(units =15 , kernel_initializer = 'uniform', activation = 'relu', input_dim = 30))\n# Adding the second hidden layer\nclf_KM.add(Dense(units = 15, kernel_initializer = 'uniform', activation = 'relu'))\n# Adding the second hidden layer\nclf_KM.add(Dense(units = 15, kernel_initializer = 'uniform', activation = 'relu'))\n# Adding the output layer\nclf_KM.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n# Compiling the ANN\nclf_KM.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n# Fitting the ANN to the Training set\nclf_KM.fit(X_KM, Y_KM, batch_size = 32, epochs = 10, verbose=2, validation_split=0.2)","6fc261bb":"Y_KM_score = clf_KM.predict(X_test)\nY_KM_pred = (Y_KM_score > 0.5)\n\nclf_KM.metrics_names\nscore = clf_KM.evaluate(X_test, Y_test)\nscore\n\n# model performence with f1-score and accuracy\nprint(classification_report(Y_test, Y_KM_pred))\ncm_KM = confusion_matrix(Y_test, Y_KM_pred) # rows = truth, cols = prediction\nprint(cm_KM)\n\n## Accuracy_sccore\nAcc_KM = accuracy_score(Y_test, Y_KM_pred)\nprint(Acc_KM)","677d1c8d":"fpr, tpr, thresholds = roc_curve(Y_test, Y_score)\nroc_auc = auc(fpr, tpr)\n\nprint(fpr)\nprint(tpr)\nprint(thresholds)\nprint(roc_auc)","e1b21733":"plt.figure()\nlw = 2\nplt.plot(fpr, tpr, color='darkorange',\n         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","9baeaac7":"# **ANN with K-Means SMOTE**","572f0448":"# Thank You !\n# UpVote if you liked the Kernel :)","b061d9bd":"# **ANN with no resampling**","527f2e64":"The AUC score of 0.98 and the curve towards the upper left corner of the plot indicates that the prediction performance of the chosen model is good. That means, it is able to distinguish between CC fraud transactions and non-fraudulent transactions.","67fb788f":"# **Predicting the test results**","6a4b8a7d":"# **Predicting the test results**","dba9e6d7":"# **RESULTS**","acaf36b0":"I implemented and observed changes in F1 score varying the K-Means SMOTE ratio and no of hidden layers. The highest F1-score achieved was 0.79 which is a decent score. In future attempts, I could look into the effects of further reducing the FPR and FNR by varying the hyperparameters of ANN technique. Also, a comparison with other resampling techniques such as Gaussian Mixture Model would be interesting. \n\nAs most features in this use-case are hidden due to confidentiality issues, I could not make proper use of the association between the various features and target variable.","06ee7b97":"# **Resampling with K-Means SMOTE**\n\nAs a starting point, we will initiate K-Means SMOTE algorithm with default values for following parameters:\n\nSampling Strategy = 0.333 (#minority instances \/ #majority instances)\nK-neighbours = 5\nrandom_state = 1234\nKmeans_estimator = MiniBatchKMeans(random_state = None)\ncluster_balance_threshold = auto\n\nFor futher info about parameters, refer to this [link](https:\/\/imbalanced-learn.readthedocs.io\/en\/stable\/generated\/imblearn.over_sampling.KMeansSMOTE.html)","0f86c349":"# **CC Fraud Detection**\n\nThe dataset contains transactions made by credit cards in September 2013 by European cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions\n\nTraditionally, we could begin with any number of ways to explore and then decide on a particular technique to classify the fraud transactions and use a performance metric to justify the results. I have implemented K-Means SMOTE with ANN to classify the fraudulent transactions. Then, using confusion matrix, I estimate the f1-score and AUC using the ROC curve. \n\nI initiate with scaling the features followed by K-Means SMOTE to oversample the class samples. Then, I use Neural Networks to produce output with 'relu'  activation function in hidden layers and 'sigmoid' in output layers. In this particular use case, I decide on f1-score performance metric because of our primary focus on FP and FN rates. Also, AUC score is a common performance metric used in classification problems.\n\nNote- I applied the oversampling method only to the training set to avoid contaminating the test dataset. The test data set has been utilized to evaluate the F1 score on K-Means SMOTE applied dataset and without. "}}