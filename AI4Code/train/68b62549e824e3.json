{"cell_type":{"15a7dd6b":"code","5c02fda2":"code","93b0c9f0":"code","a5984f72":"code","4f02f709":"code","cfcdf3f7":"code","0e165b62":"code","d603b8ee":"code","8e20a696":"code","946b2cb7":"code","7f06bde3":"code","13ba9ea5":"code","6c849c43":"code","8333eda7":"code","25f3fb40":"code","9a641d50":"code","46e05999":"code","c085f80b":"code","17a2e543":"code","8d20147f":"code","5036822c":"code","931ad904":"code","9a912b8a":"code","d70e844d":"code","df68bbda":"code","3c03d499":"code","8831bb35":"code","5a2f30c8":"code","f31ea2ae":"code","a9c81f06":"code","5cade25f":"code","604b0f40":"code","ad5fd079":"markdown","edfa4084":"markdown","c932d2d3":"markdown","e0ddf657":"markdown","fd0cf7f9":"markdown","ff92c15a":"markdown","8343eb67":"markdown","d8c61691":"markdown","ddae3fb8":"markdown","a8667fba":"markdown","3cb0a13c":"markdown","ae55a278":"markdown","dd720b6f":"markdown","6e8475fa":"markdown","9202cff7":"markdown","21c95535":"markdown","bdb553a1":"markdown","4f06973a":"markdown","4b3297f4":"markdown","37285586":"markdown","bbb47cf7":"markdown","ae49c715":"markdown","4f6fd657":"markdown","968456dd":"markdown","c8b3eabc":"markdown","d740e521":"markdown","85f6af08":"markdown","757c24a7":"markdown","3166c968":"markdown"},"source":{"15a7dd6b":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns\ntrain_df=pd.read_csv('\/kaggle\/input\/human-activity-recognition-with-smartphones\/train.csv')\ntest_df=pd.read_csv('\/kaggle\/input\/human-activity-recognition-with-smartphones\/test.csv')","5c02fda2":"#train_df.info()\nprint('train dataset size:',test_df.shape)\ntrain_df.head()","93b0c9f0":"print('null values:',train_df.isnull().values.sum())\ntrain_df.dtypes","a5984f72":"print('Number of duplicates in train set:{}'.format(sum(train_df.duplicated())))\nprint('Number of duplicates in test set:{}'.format(sum(test_df.duplicated())))\n#print('Duplicated data',train_df.duplicated().values.sum())","4f02f709":"train_df['subject'].groupby(train_df['subject']).count()","cfcdf3f7":"train_df['subject'].groupby(train_df['Activity']).value_counts()","0e165b62":"# .size() and .count() provide the same answer\ntrain_df['Activity'].groupby(train_df['Activity']).size()","d603b8ee":"px.pie(train_df,names='Activity',title='Activity in database')","8e20a696":"px.histogram(data_frame=train_df,x='subject',color='Activity',barmode='group',title='Histogram of data in train set')","946b2cb7":"px.histogram(data_frame=test_df,x='subject',color='Activity',barmode='group',title='Histogram of data in test set')","7f06bde3":"px.histogram(train_df,x='Activity',color='Activity',title='Number of recordings per activity')\n","13ba9ea5":"corrmat=train_df.corr()\nf,ax=plt.subplots(figsize=(10,10))\nsns.heatmap(corrmat,vmax=0.8,square=True)","6c849c43":"px.histogram(train_df,x='tBodyAccMag-mean()',color='Activity')\n#sns.displot(train_df,x='tBodyAccMag-mean()',hue='Activity')","8333eda7":"px.box(train_df, x='Activity',y='tBodyAccMag-mean()')","25f3fb40":"from sklearn import preprocessing\nX=train_df.drop('Activity',axis=1)\nY=train_df['Activity']\nprint('X matrix size:',X.shape)\nX=preprocessing.StandardScaler().fit(X).transform(X)\n#X\nX_test=test_df.drop('Activity',axis=1)\nX_t=preprocessing.StandardScaler().fit(X_test).transform(X_test)","9a641d50":"import numpy as np\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\npca=PCA(n_components=200).fit(X)   # number of components\nprincipal_component=pca.transform(X)\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('principal component')\nplt.ylabel('explained variance')\n","46e05999":"principal_component=PCA(n_components=200).fit_transform(X)\nX_test_pca=pca.transform(X_t)\n#,columns=['Comp1','Comp2','Comp3']\npca_df=pd.DataFrame(data=principal_component)\npca_test_d=pd.DataFrame(data=X_test_pca)\npca_df.head()\npca_df.shape","c085f80b":"import plotly.express as px\npx.scatter(x=pca_df[3],y=pca_df[2],color=train_df['Activity'])","17a2e543":"from sklearn.manifold import TSNE\nimport seaborn as sns","8d20147f":"# perform t-sne with different preplexities and their plots\ndef perform_tsne(X_data, y_data, perplexities, n_iter=1000, img_name_prefix='t-sne'):\n        \n    for index,perplexity in enumerate(perplexities):\n        # perform t-sne\n        print('\\nperforming tsne with perplexity {} and with {} iterations at max'.format(perplexity, n_iter))\n        X_reduced = TSNE(verbose=2, perplexity=perplexity).fit_transform(X_data)\n        print('Done..')\n        \n        # prepare the data for seaborn         \n        print('Creating plot for this t-sne visualization..')\n        df = pd.DataFrame({'x':X_reduced[:,0], 'y':X_reduced[:,1] ,'label':y_data})\n        \n        # draw the plot in appropriate place in the grid\n        sns.lmplot(data=df, x='x', y='y', hue='label', fit_reg=False, size=8,\\\n                   palette=\"Set1\",markers=['^','v','s','o', '1','2'])\n        plt.title(\"perplexity : {} and max_iter : {}\".format(perplexity, n_iter))\n        img_name = img_name_prefix + '_perp_{}_iter_{}.png'.format(perplexity, n_iter)\n        print('saving this plot as image in present working directory...')\n        plt.savefig(img_name)\n        plt.show()\n        print('Done')","5036822c":"X_pre_tsne = train_df.drop(['subject', 'Activity'], axis=1)\ny_pre_tsne = train_df['Activity']\nperform_tsne(X_data = X_pre_tsne,y_data=y_pre_tsne, perplexities =[5,10,20])","931ad904":"X_train=train_df.drop('Activity',axis=1)\nY_train=train_df['Activity']\nX_test=test_df.drop('Activity',axis=1)\nY_test=test_df['Activity']\n","9a912b8a":"from sklearn.linear_model import LogisticRegression\nlr_clf=LogisticRegression(C=0.01,solver='liblinear')\nlr_clf.fit(X_train,Y_train)","d70e844d":"from sklearn.metrics import classification_report,accuracy_score\ny_hat=lr_clf.predict(X_test)\nprint('accuracy score(test data): \\n',accuracy_score(Y_test,y_hat))\nprint('Classification report(test dataset): \\n',classification_report(Y_test,y_hat))","df68bbda":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score,confusion_matrix,classification_report,ConfusionMatrixDisplay\ncm = confusion_matrix(Y_test,y_hat, labels=lr_clf.classes_)\ndisp= ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=lr_clf.classes_)\nfig, ax = plt.subplots(figsize=(20,20))\ndisp.plot(ax=ax)","3c03d499":"lr_pca=LogisticRegression(C=0.01,solver='liblinear')\nlr_pca.fit(pca_df,Y_train)\npca_pre=lr_pca.predict(pca_test_d)\nprint('Classification report (LR PCA features)\\n',classification_report(pca_pre,Y_test))\n","8831bb35":"cm = confusion_matrix(Y_test,pca_pre, labels=lr_pca.classes_)\ndisp= ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=lr_pca.classes_)\nfig, ax = plt.subplots(figsize=(20,20))\ndisp.plot(ax=ax)","5a2f30c8":"from sklearn import svm\n#SVM kernel: \u2018linear\u2019, \u2018poly\u2019, \u2018rbf\u2019, \u2018sigmoid\u2019, \u2018precomputed\u2019\nsvm_clf=svm.SVC(kernel='rbf')\nsvm_clf.fit(X_train,Y_train)\ny_hat=svm_clf.predict(X_test)\nprint('SVM accuracy score (test data):\\n',accuracy_score(Y_test,y_hat))\nprint('SVM classification report (test data): \\n',classification_report(Y_test,y_hat))","f31ea2ae":"cm = confusion_matrix(Y_test,y_hat, labels=svm_clf.classes_)\ndisp= ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=svm_clf.classes_)\nfig, ax = plt.subplots(figsize=(20,20))\ndisp.plot(ax=ax)","a9c81f06":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nLDA_clf = LinearDiscriminantAnalysis()\nLDA_clf.fit(X_train,Y_train)\ny_hat=LDA_clf.predict(X_test)\nprint('LDA accuracy score (test data):\\n',accuracy_score(Y_test,y_hat))\nprint('LDA classification report (test data): \\n',classification_report(Y_test,y_hat))\n","5cade25f":"cm = confusion_matrix(Y_test,y_hat, labels=LDA_clf.classes_)\ndisp= ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=LDA_clf.classes_)\nfig, ax = plt.subplots(figsize=(20,20))\ndisp.plot(ax=ax)","604b0f40":"from sklearn.tree import DecisionTreeClassifier","ad5fd079":"So we have 30 subjects and each perfomed different trials.\nNow lets look at how many trials of each activity exist in our train dataset:","edfa4084":"# Confusion matrix","c932d2d3":"**Based on the results, model is performing better on PCA data that colinearity is removed and all features are orthonormal.**","e0ddf657":"# LDA classifier:","fd0cf7f9":"# **Support Vector Machine:**","ff92c15a":"# overview of dataset:","8343eb67":"**Checking the database for null values:**","d8c61691":"based on the varibility explain, the first 50 components explain more that 90% of varability in the dataset. The first 50 componenets are chosen to use for classification:","ddae3fb8":"Now lets do logistic regression with PCA features:","a8667fba":"Histogram of mean magnitude of acceleration shows that dynamic activities are differnet from static activities","3cb0a13c":"The dataset has lost of feaures that are highly correlated with each other.\nShould we drop the features that are highly correlated?","ae55a278":"**Now with the knowledge we have we can go on using different classification techniques to classify the data. we will use:**\n\n**1) logestic regression**\n\n**2) SVM**\n\n**3) Decision tree**\n\n","dd720b6f":"**Logistic regression:**","6e8475fa":"# Data exploration","9202cff7":"We know that our featur space is huge and probably its better to find a manifold that is in lower dimention and easier to seperate groups from each other:\nLets start with PCA:","21c95535":"# Features\nBy using accelerometer and Gyroscope in the smartwatch, they have signals from 3 axial linear accelaration (tACC-XYZ) and 3-axial angular velocity (tGyro-XYZ)\nthe sensor signals were preprocessed with noise filters and windowed (2.56 s) with 50% overlap. For each window features from time and frequency domain are calculated.\nTime features are such as  mean, std,median, energy,..\n\n2) Accelerations signal was seperated in to two components body and gravity\n\n3) Body linear acceleration and angular velocity were derived in time to obtain jerk\n\n4) Magnitiude of these signals  in XYZ was calculated using euclidian distance\n\n5) For frequency  componnets, FFT was taken","bdb553a1":"From the visualization, standing and siting are the two acitivies that our model will have the most difficulty to seperate. \n","4f06973a":"The database does not include any missing values. Now we can move on to the next step, checking for duplicates in the data: ","4b3297f4":"# Problem framwork\n* We have 30 subjects. \n* In database each datapoint is one of the six activities.\n* Each subject repeated the activity several times\n\nNow given the dataset, can we predict the activity based on the featureset?","37285586":"# Confusion matrix","bbb47cf7":"# Decisiuon tree classifier","ae49c715":"As we can see we got almost same number of readings from all the subjects.","4f6fd657":"<a id=\"section-one\"><\/a>\n# Human activity recognition project\nThis project is to build a model that predicts the human activities such as walking, siting, exc.\nThis dataset is collected from 30 subjects, performing different tasks several times while wearing smartwatch to their wrist. The data is recorded with the help of sensors (acelerometer and gyroscope) in the smartwatch and they used video recorded to label the task performed manually. ","968456dd":"**Check for data imbalance:**","c8b3eabc":"So pie plot shows that the data is balanced.","d740e521":"# Apply t-sne on data","85f6af08":"Now let use t-SNE which is a non-linear dimentionaily reduction and visualization method to visualize our high dimentional data:","757c24a7":"**Checking the database for duplicates:**","3166c968":"Database has 30 subjects and each of them have performed the task several times."}}