{"cell_type":{"6a7801f0":"code","0d0c3a4d":"code","da83ecdd":"code","5dde83cb":"code","1e702439":"code","eed172f8":"code","5709b0ed":"code","bac0cafa":"code","6227fc14":"code","00bc2244":"code","e969403d":"code","80927a0e":"code","46ee0639":"code","d0a7ae8f":"code","865502cc":"code","f610ab47":"markdown","7e583a3b":"markdown"},"source":{"6a7801f0":"# Importar librerias\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Importar la base de informaci\u00f3n de las campa\u00f1as\ncampa\u00f1a = pd.read_csv(\"\/kaggle\/input\/datathon-belcorp-prueba\/campana_consultora.csv\")\ncampa\u00f1a = campa\u00f1a.iloc[:,1:]\ndel campa\u00f1a[\"codigocanalorigen\"]\ndel campa\u00f1a[\"codigofactura\"]\ndel campa\u00f1a[\"flagpasopedidoweb\"]\ndel campa\u00f1a[\"geografia\"]\ncampa\u00f1a = campa\u00f1a.sort_values(by=\"campana\",ascending=False)\ncampa\u00f1a.head()","0d0c3a4d":"# Conteo de filas por campa\u00f1a\ncampa\u00f1a[\"campana\"].value_counts()\n# vemos que no tenemos informaci\u00f3n de la campana 201907 ya que es la campana que nos piden predecir","da83ecdd":"# Vemos que existen muchas variables que tienen son flags 0 - 1\ncampa\u00f1a[\"flag_total\"]=campa\u00f1a[\"flagactiva\"]+campa\u00f1a[\"flagpasopedidocuidadopersonal\"]+campa\u00f1a[\"flagpasopedidomaquillaje\"]+campa\u00f1a[\"flagpasopedidotratamientocorporal\"]+campa\u00f1a[\"flagpasopedidotratamientofacial\"]+campa\u00f1a[\"flagpasopedidofragancias\"]                             \ncampa\u00f1a[\"segmentacion\"]=campa\u00f1a[\"segmentacion\"].astype('category').cat.codes\ncampa\u00f1a[\"evaluacion_nuevas\"]=campa\u00f1a[\"evaluacion_nuevas\"].astype('category').cat.codes","5dde83cb":"\n# Separar las campa\u00f1as\na1818=campa\u00f1a[campa\u00f1a[\"campana\"]==201818]    \na1815=campa\u00f1a[campa\u00f1a[\"campana\"]==201815]    \na1817=campa\u00f1a[campa\u00f1a[\"campana\"]==201817]    \na1813=campa\u00f1a[campa\u00f1a[\"campana\"]==201813]    \na1816=campa\u00f1a[campa\u00f1a[\"campana\"]==201816]    \na1812=campa\u00f1a[campa\u00f1a[\"campana\"]==201812]    \na1901=campa\u00f1a[campa\u00f1a[\"campana\"]==201901]   \na1814=campa\u00f1a[campa\u00f1a[\"campana\"]==201814]    \na1906=campa\u00f1a[campa\u00f1a[\"campana\"]==201906]  \na1905=campa\u00f1a[campa\u00f1a[\"campana\"]==201905]   \na1903=campa\u00f1a[campa\u00f1a[\"campana\"]==201903] \na1902=campa\u00f1a[campa\u00f1a[\"campana\"]==201902] \na1904=campa\u00f1a[campa\u00f1a[\"campana\"]==201904] \na1811=campa\u00f1a[campa\u00f1a[\"campana\"]==201811]    \na1810=campa\u00f1a[campa\u00f1a[\"campana\"]==201810]    \na1809=campa\u00f1a[campa\u00f1a[\"campana\"]==201809]    \na1808=campa\u00f1a[campa\u00f1a[\"campana\"]==201808]    \na1807=campa\u00f1a[campa\u00f1a[\"campana\"]==201807] \n\n\n#Formar la data de entrenamiento - TRAIN todo menos el 201906\ncampa\u00f1a_prueba = pd.concat([a1905,a1904,a1903,a1902,a1901,a1818,a1817,a1816,a1815,a1814,a1813,a1812,a1811,a1810,a1809,a1808,a1807])\n\n# \u00bfCual es el problema?\ncampa\u00f1a_prueba[campa\u00f1a_prueba[\"IdConsultora\"]==792524]","1e702439":"\nt1=campa\u00f1a_prueba.groupby([\"IdConsultora\"]).sum().add_prefix(\"SUM_\").reset_index()\nt1.head()\n# Cantidad de flags historicos por consultora de 17 campa\u00f1as","eed172f8":"# AHORA VAMOS A TENER UNA FILA UNA CONSULTORA\n\nt1[t1[\"IdConsultora\"]==792524]","5709b0ed":"# AHORA VAMOS A HACER UN JOIN CON LA INFORMACI\u00d3N HISTORICA \n\ndel t1[\"SUM_campana\"] #eliminar por que no tiene sentido para el an\u00e1lisis \na1906=a1906.iloc[:,:3].reset_index(drop=True)\n\ntrain_df=a1906.merge(t1,on=\"IdConsultora\",how=\"inner\")\ndel train_df[\"campana\"]\ntrain_df.head()\n# DE ESTA FORMA\n#TENEMOS:\n# IDCONSULTORA : Consultora de la campa\u00f1a 201906 \n# Flagpedido : Paso o paso pedido en la campa\u00f1a 201906 la cual queremos predecir \n# Infomaci\u00f3n historica desde el inicio hasta el 201905","bac0cafa":"# Formar la data de test que nos pide el concurso\n# Predecir el 201907 usando informaci\u00f3n desde el 201808 hasta el 201906\n\ncampa\u00f1a_test = pd.concat([a1906,a1905,a1904,a1903,a1902,a1901,a1818,a1817,a1816,a1815,a1814,a1813,a1812,a1811,a1810,a1809,a1808])\nt2 = campa\u00f1a_test.groupby([\"IdConsultora\"]).sum().add_prefix(\"SUM_\").reset_index()\ndel t2[\"SUM_campana\"]\nt2.head()","6227fc14":"# Importar submission\nsubmission=pd.read_csv(\"\/kaggle\/input\/datathon-belcorp-prueba\/predict_submission.csv\")\nsubmission.head()","00bc2244":"\n# Vamos a pegar la info de las campa\u00f1as hasta el 201906 a las consultoras que queremos predecir si har\u00e1n un pedido en el 201907\nconsultora_sub=submission.merge(t2, right_on='IdConsultora',left_on=\"idconsultora\",how=\"left\")\n\ndel consultora_sub[\"IdConsultora\"]\ndel consultora_sub[\"flagpasopedido\"]\nconsultora_sub.head()\n# DE ESTA FORMA TENEMOS:\n# Id Consultora: la cual queremos predecir si pasara un pedido en el 201907\n# Totales historicos desde el 201808 hasta el 201906","e969403d":"#Importar maestro consultoras\n# Tenemos informaci\u00f3n personal de las consultoras \nmaestro=pd.read_csv(\"\/kaggle\/input\/datathon-belcorp-prueba\/maestro_consultora.csv\").iloc[:,1:]\nmaestro=maestro.join(pd.get_dummies(maestro.estadocivil))\ndel maestro[\"estadocivil\"]\nmaestro","80927a0e":"# Crear variable - me falt\u00f3 imaginaci\u00f3n :c \n\nmaestro[\"ratio1\"]=((maestro.campanaultimopedido-maestro.campanaprimerpedido)-(maestro.campanaultimopedido-maestro.campanaprimerpedido).mean())\/pow((maestro.campanaultimopedido-maestro.campanaprimerpedido).var(),0.5)\n# Juntar con el train y test \ndel maestro[\"campanaingreso\"]\ndel maestro[\"campanaprimerpedido\"]\n","46ee0639":"# Pegamos toda la informaci\u00f3n personal en la tabla de campa\u00f1as  en train y test \n\ntrain_df1=train_df.merge(maestro,on=[\"IdConsultora\"])\nconsultora_sub1=consultora_sub.merge(maestro, right_on='IdConsultora',left_on=\"idconsultora\",how=\"left\")\ndel consultora_sub1[\"IdConsultora\"]","d0a7ae8f":"# MODELADO\nimport pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport gc\nimport os\nimport logging\nimport datetime\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport lightgbm as lgb\nfrom tqdm import tqdm_notebook\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import StratifiedKFold\nparam = {\n    'bagging_freq': 5, #5\n    'bagging_fraction': 0.4, #0.4\n    'boost_from_average':'false',\n    'min_child_samples': 30,\n    'boost': 'gbdt',\n    'feature_fraction': 0.5, #0.05\n    'learning_rate': 0.01, #0.01\n    'max_depth': -1,  \n    'metric':'auc',\n    'min_data_in_leaf': 80, #80\n    'min_sum_hessian_in_leaf': 10, #10\n    'num_leaves': 13, #13\n    'num_threads': 8, \n    'tree_learner': 'serial',\n    'objective': 'binary', \n    'verbosity': 1,\n    \"is_unbalance\":False,\n    \"random_state\":1234\n}\ntrain_df=train_df1\ntest_df=consultora_sub1\nfeatures = [c for c in train_df.columns if c not in [\"campanaultimopedido\",\"Flagpasopedido\",\"IdConsultora\",\"idconsultora\"]]#\"SUM_flagdigital\",\"SUM_flagpedidoanulado\",\"flagsupervisor\"]]\ntarget=train_df[\"Flagpasopedido\"]\ntrain_df.fillna(train_df.mean(), inplace=True) #reemplazar nan con media\ntest_df.fillna(test_df.mean(), inplace=True) \n\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=44000)\noof = np.zeros(len(train_df))\npredictions = np.zeros(len(test_df))\nfeature_importance_df = pd.DataFrame()\n\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, target.values)):\n    print(\"Fold {}\".format(fold_))\n    trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label=target.iloc[trn_idx])\n    val_data = lgb.Dataset(train_df.iloc[val_idx][features], label=target.iloc[val_idx])\n\n    num_round = 10000\n    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 1000)\n    oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"Feature\"] = features\n    fold_importance_df[\"importance\"] = clf.feature_importance()\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    predictions += clf.predict(test_df[features], num_iteration=clf.best_iteration) \/ folds.n_splits\n\nprint(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))   ","865502cc":"stock_test1=pd.read_csv(\"\/kaggle\/input\/datathon-belcorp-prueba\/predict_submission.csv\")\nsub_df = pd.DataFrame({\"idconsultora\":stock_test1[\"idconsultora\"].values})\nsub_df[\"flagpasopedido\"] = predictions\ntesteo=pd.concat([test_df[[\"campanaultimopedido\"]],sub_df],axis=1)\n\nfor i in range(0,len(testeo)):\n  if testeo.iloc[i,0] < 201907:\n    testeo.iloc[i,2]=0\n  elif testeo.iloc[i,0] == 201907:\n    testeo.iloc[i,2]=1\ndel testeo[\"campanaultimopedido\"]\ntesteo.to_csv(\"testeo.csv\",index=False)","f610ab47":"## ESTRATEGIA DEL MODELAMIENTO","7e583a3b":"![image.png](attachment:image.png)"}}