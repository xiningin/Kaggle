{"cell_type":{"7778b179":"code","fd0bb1e8":"code","73546b37":"code","d6a66984":"code","c723970a":"code","beab9910":"code","f208bb1b":"code","23271134":"code","58e4e8b6":"code","41692ae3":"code","c4c49acd":"code","9d2da66f":"code","42248f2b":"code","bd3d2768":"code","fd1746cf":"code","269fabe6":"code","e943ca0e":"markdown","91daf8f3":"markdown","3dbf5458":"markdown","627629b6":"markdown","83451df1":"markdown","8d5af814":"markdown","3e534d36":"markdown","e21342ba":"markdown","fd47d1cc":"markdown","8af1ab96":"markdown","e1a25f7e":"markdown","893a4c7b":"markdown","a47d4c0c":"markdown","232c7a9e":"markdown","b42264cc":"markdown","078dad56":"markdown"},"source":{"7778b179":"#import\nfrom kaggle.competitions import twosigmanews\nfrom datetime import datetime, date\nimport numpy as np\nfrom sklearn import model_selection","fd0bb1e8":"env = twosigmanews.make_env()\n\n(market_train_df, news_train_df) = env.get_training_data()\nmarket_train, news_train = market_train_df.copy(), news_train_df.copy()","73546b37":"def fill_in(data):\n    for i in data.columns:\n        if data[i].dtype == \"object\":\n            data[i] = data[i].fillna(\"\")\n        elif (data[i].dtype == \"int64\" or data[i].dtype == \"float64\"):\n            data[i] = data[i].fillna(data[i].mean())\n        else:\n            pass\n    return data\n\nmarket_train_df = fill_in(market_train_df)","d6a66984":"def data_other(market_train_df):\n    market_train_df.time = market_train_df.time.dt.date\n    lbl = {k: v for v, k in enumerate(market_train_df['assetCode'].unique())}\n    market_train_df['assetCodeT'] = market_train_df['assetCode'].map(lbl)\n    \n    market_train_df = market_train_df.dropna(axis=0)\n    \n    return market_train_df\n\nmarket_train_df = data_other(market_train_df)","c723970a":"market_train_df = market_train_df.loc[market_train_df['time']>=date(2009, 1, 1)]","beab9910":"green = market_train_df.returnsOpenNextMktres10 > 0\ngreen = green.values","f208bb1b":"fcol = [c for c in market_train_df if c not in ['assetCode', 'assetCodes', 'assetCodesLen', 'assetName', 'audiences', \n                                             'firstCreated', 'headline', 'headlineTag', 'marketCommentary', 'provider', \n                                             'returnsOpenNextMktres10', 'sourceId', 'subjects', 'time', 'time_x', 'universe','sourceTimestamp']]","23271134":"X = market_train_df[fcol].values\nmins = np.min(X, axis=0)\nmaxs = np.max(X, axis=0)\nrng = maxs - mins\nX = 1 - ((maxs - X) \/ rng)","58e4e8b6":"all_10day = market_train_df.returnsOpenNextMktres10.values","41692ae3":"X_train, X_test, green_train, green_test, all_train, all_test = model_selection.train_test_split(\n    X, green, all_10day, test_size=0.20, random_state=59)","c4c49acd":"import lightgbm as lgb\ntrain_data = lgb.Dataset(X_train, label=green_train.astype(int))\ntest_data = lgb.Dataset(X_test, label=green_test.astype(int))","9d2da66f":"# these are tuned params I found\nx_1 = [0.19000424246380565, 2452, 212, 328, 202]\nx_2 = [0.19016805202090095, 2583, 213, 312, 220]","42248f2b":"params_1 = {\n        'task': 'train',\n        'boosting_type': 'dart',\n        'objective': 'binary',\n        'learning_rate': x_1[0],\n        'num_leaves': x_1[1],\n        'min_data_in_leaf': x_1[2],\n        'num_iteration': x_1[3],\n        'max_bin': x_1[4],\n        'verbose': 1\n    }\n\nparams_2 = {\n        'task': 'train',\n        'boosting_type': 'dart',\n        'objective': 'binary',\n        'learning_rate': x_2[0],\n        'num_leaves': x_2[1],\n        'min_data_in_leaf': x_2[2],\n        'num_iteration': x_2[3],\n        'max_bin': x_2[4],\n        'verbose': 1\n    }\n\n\ngbm_1 = lgb.train(params_1,\n        train_data,\n        num_boost_round=100,\n        valid_sets=test_data,\n        early_stopping_rounds=5)\n        \ngbm_2 = lgb.train(params_2,\n        train_data,\n        num_boost_round=100,\n        valid_sets=test_data,\n        early_stopping_rounds=5)","bd3d2768":"days = env.get_prediction_days()\nn_days = 0\nprep_time = 0\nprediction_time = 0\npackaging_time = 0","fd1746cf":"import pandas as pd\nfor (market_obs_df, news_obs_df, predictions_template_df) in days:\n    n_days +=1\n    if (n_days%50==0):\n        print(n_days,end=' ')\n    market_obs_df = fill_in(market_obs_df)\n    market_obs_df = data_other(market_obs_df)\n    market_obs_df = market_obs_df[market_obs_df.assetCode.isin(predictions_template_df.assetCode)]\n    X_live = market_obs_df[fcol].values\n    X_live = 1 - ((maxs - X_live) \/ rng)\n    \n    lp = (gbm_1.predict(X_live) + gbm_2.predict(X_live))\/2\n    \n\n    confidence = lp\n    confidence = (confidence-confidence.min())\/(confidence.max()-confidence.min())\n    confidence = confidence * 2 - 1\n    preds = pd.DataFrame({'assetCode':market_obs_df['assetCode'],'confidence':confidence})\n    predictions_template_df = predictions_template_df.merge(preds,how='left').drop('confidenceValue',axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n    env.predict(predictions_template_df)","269fabe6":"env.write_submission_file()","e943ca0e":"Fill time, assetCodeType and drop nulls","91daf8f3":"**Model LightGB**\n\ncreate test and train data with X as datapoints and green as labels","3dbf5458":"Variable X will hold datapoints with the selected columns, normalized","627629b6":"selection of columns: assetCodeType, volume, close, open and returns Cl-Op for Raw1,Mktres1,PrevRaw10 and PrevMktres10","83451df1":"Variable all_10day will hold all 10day return values**","8d5af814":"Once it is trained, we will predict the values for submission\n\nFirst, some variables","3e534d36":"select only datapoints from 2009 (#3340144 from #4072956)","e21342ba":"Create datasets train and test","fd47d1cc":"Let's train the model","8af1ab96":"variable green will hold datapoints where the 10day return was positive\n\nreturnsOpenNextMktres10(float64) - 10 day, market-residualized return. This is the target variable used in competition scoring. The market data has been filtered such that returnsOpenNextMktres10 is always not null.","e1a25f7e":"Let's download the data","893a4c7b":"Kernel based on https:\/\/www.kaggle.com\/kazuokiriyama\/tuning-hyper-params-in-lgbm-achieve-0-66-in-lb\n\nFirst of all, import libraries","a47d4c0c":"Magic parameters","232c7a9e":"We start working with **market data**\n\nFill the data gaps","b42264cc":"For every day:","078dad56":"Send prediction"}}