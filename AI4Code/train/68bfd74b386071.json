{"cell_type":{"5630dc81":"code","69cc4e06":"code","15298742":"code","aa03efb6":"code","21ac99a6":"code","3cb2fdee":"code","97e03f19":"code","a3f5aa46":"code","d9634f33":"code","15374ece":"code","33f49311":"code","d2dedcf5":"code","7960a178":"code","d63dd11c":"code","9ca2617d":"code","efb5f2ec":"code","10a28964":"code","98ba3935":"code","4f071fa3":"code","55cca5b1":"markdown","7603878d":"markdown","0e082775":"markdown","956d261b":"markdown","608de201":"markdown","cdb3e350":"markdown","92277ae1":"markdown","19e3625e":"markdown","b4c97e5c":"markdown","fab9f2f3":"markdown","83342e12":"markdown","9acbdfa1":"markdown","3c6421c6":"markdown","61de5d8a":"markdown","07cd62cd":"markdown","6c9adbef":"markdown"},"source":{"5630dc81":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nimport matplotlib.pyplot as plt","69cc4e06":"import seaborn as sns\nsns.set(style=\"ticks\", color_codes=True)\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn import metrics\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')","15298742":"train = pd.read_csv('..\/input\/seleksidukungaib\/train.csv')\ntest = pd.read_csv('..\/input\/seleksidukungaib\/test.csv')","aa03efb6":"train.head()\n\ntrain.shape, test.shape\n\ntrain.loc[train['super'].isnull()==True]\n\ntrain.isnull().sum()","21ac99a6":"# drop kolom freak dan rendundan \ntrain=train.drop(['random_number','isUpgradedUser','date_collected'],axis=1)\ntest=test.drop(['random_number','isUpgradedUser','date_collected'],axis=1)","3cb2fdee":"# fix na values on train data\ntrain['max_recharge_trx']=(2*train['average_recharge_trx'])-train['min_recharge_trx']\ntrain['average_topup_trx']=(train['max_topup_trx']+train['min_topup_trx'])\/2\ntrain['average_transfer_trx']=(train['min_transfer_trx']+train['max_transfer_trx'])\/2\n\n# fix num_transaction\ntrain['num_transaction']=train['num_transfer_trx']+train['num_recharge_trx']+train['num_topup_trx']\ntest['num_transaction']=test['num_transfer_trx']+test['num_recharge_trx']+test['num_topup_trx']\n\n# fix total_transaction\ntest['total_transaction']=(test['num_transfer_trx']*test['average_transfer_trx'])+(test['num_recharge_trx']*test['average_recharge_trx'])+(test['num_topup_trx']*test['average_topup_trx'])\ntrain['total_transaction']=(train['num_transfer_trx']*train['average_transfer_trx'])+(train['num_recharge_trx']*train['average_recharge_trx'])+(train['num_topup_trx']*train['average_topup_trx'])\n\n# drop rows with 10 na values\ntrain=train.drop([21136,53090,119567,131149,134989,137572,158423,170093,175223,176886])\n\n# fix the rest of all na values\ntrain.fillna(0,inplace=True)\ntest.fillna(0,inplace=True)","97e03f19":"#check\n#train.loc[train['num_transaction']==(train['num_transfer_trx']+train['num_recharge_trx']+train['num_topup_trx'])]\n#test.loc[test['total_transaction']==(test['num_transfer_trx']*test['average_transfer_trx'])+(test['num_recharge_trx']*test['average_recharge_trx'])+(test['num_topup_trx']*test['average_topup_trx'])]\n#train.loc[train['total_transaction']==(train['num_transfer_trx']*train['average_transfer_trx'])+(train['num_recharge_trx']*train['average_recharge_trx'])+(train['num_topup_trx']*train['average_topup_trx'])]\n\n#train.loc[train['max_recharge_trx'].isnull()==True]\n#train.loc[train['average_topup_trx'].isnull()==True]\n#train.loc[train['average_transfer_trx'].isnull()==True]\n\n#test.loc[test['max_recharge_trx'].isnull()==True]\n#test.loc[test['average_topup_trx'].isnull()==True]\n#test.loc[test['average'].isnull()==True]\n\ntrain.head()\ntrain.isnull().sum()","a3f5aa46":"data = pd.concat([train,test],ignore_index=True)","d9634f33":"date = ['date']\nbin = ['premium','super','pinEnabled']\ncol = date + bin\nle = LabelEncoder()\nfor i in col: \n    data[i] = le.fit_transform(list(data[i].values))","15374ece":"train = data[~data.isChurned.isnull()]\ntest = data[data.isChurned.isnull()]\n\nX_train = train.drop(['isChurned','idx'], axis=1)\ny_train = train['isChurned']\ntest_X = test.drop(['isChurned','idx'], axis=1)","33f49311":"scaler = StandardScaler()\n\nX_train = scaler.fit_transform(X_train)\ntest_X = scaler.fit_transform(test_X)","d2dedcf5":"train_X, val_X, train_y, val_y = train_test_split(X_train, y_train, random_state=1)\nweights = {0:1.0, 1:100.0}\nmodel = LogisticRegression(class_weight=None)\n\nmodel.fit(train_X,train_y)\n\nval_predictions = model.predict(val_X)\nval_f1 = f1_score(val_predictions,val_y)","7960a178":"metrix = confusion_matrix(val_y, val_predictions)\nfig, ax = plt.subplots()\n\nsns.heatmap(pd.DataFrame(metrix), annot=True, cmap=\"viridis\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","d63dd11c":"print(val_f1)","9ca2617d":"print(\"Accuracy:\",metrics.accuracy_score(val_y,val_predictions))\nprint(\"Precision:\",metrics.precision_score(val_y,val_predictions))\nprint(\"Recall:\",metrics.recall_score(val_y,val_predictions))","efb5f2ec":"model.fit(X_train,y_train)\npred = model.predict(test_X)","10a28964":"submission = pd.DataFrame({'idx':test['idx'],'isChurned':pred.astype(int)})\nsubmission.to_csv('submission.csv',index=False)","98ba3935":"submission.loc[submission['isChurned']==True]","4f071fa3":"submission.head()","55cca5b1":"## Label Encoder","7603878d":"# **Preprocessing Data**","0e082775":"# **Modeling**","956d261b":"## Import Library","608de201":"## Scaler","cdb3e350":"## Model Validation","92277ae1":"## Check Data","19e3625e":"## Final Check ","b4c97e5c":"## Split Train Test","fab9f2f3":"## Concat Train & Test","83342e12":"## **Drop Column**","9acbdfa1":"## Fill Null Values","3c6421c6":"## Submission Check","61de5d8a":"# Make Submission","07cd62cd":"## Final Model","6c9adbef":"## Read Data"}}