{"cell_type":{"1dc42027":"code","8d00aadf":"code","902829c8":"code","973dda08":"code","4c8b0a76":"code","e1504a14":"code","c517e0d2":"code","f97a3e80":"code","11b536cf":"code","0fde4628":"code","3ffa77bd":"code","ae79d50e":"code","2d83d0eb":"code","2d4e5ca0":"code","e4d7af18":"code","9f3ab70b":"code","10f0eb19":"code","af46c9a6":"code","e50b734b":"code","5d631a2f":"code","d509a9b4":"code","32974aa9":"code","5803932a":"code","43a9f40f":"code","310dcf75":"code","619fd9b0":"code","2412d433":"code","1ec681b5":"code","694fd26a":"code","d7626bfd":"code","3147ee49":"code","ba2f7f5b":"code","d5cd1b7c":"code","d3335e40":"code","ad3ea36b":"code","74d9da91":"code","e84d8f5d":"code","234e74d7":"code","e8c28919":"code","aa592903":"code","278dc90a":"code","d9c90d37":"code","ce203c9e":"code","de6a547d":"code","dc459d8b":"code","fdde00e9":"code","78c85c76":"code","249bb747":"code","fa74bad2":"code","95b029d7":"code","c0eae9c9":"code","8fa163c9":"code","bd5c2433":"code","5f7117a0":"code","5d7f9274":"code","baf8d9af":"code","4da83bcc":"code","37cbf1c6":"code","94e073e8":"code","ffa216fa":"code","17845c28":"code","e100bc73":"markdown","6e1571cd":"markdown","d72e22cf":"markdown","2574bb46":"markdown","315a914d":"markdown","3752c711":"markdown","f43f4ddd":"markdown","75375140":"markdown","d36b59b3":"markdown","4c6b08ee":"markdown","620ab5bd":"markdown","9ee1d3d8":"markdown","4e54b43c":"markdown","552701ce":"markdown","3734ed2d":"markdown","a9f895f5":"markdown","8da7576f":"markdown","95102c61":"markdown","800f32d7":"markdown","0f9cb931":"markdown","936f8cf7":"markdown","8b582956":"markdown","945b4663":"markdown","5c6583d3":"markdown","4933de2c":"markdown","c95e197a":"markdown","f189fb51":"markdown","2ae84728":"markdown","274d70a5":"markdown","2494ac86":"markdown","41dbce89":"markdown","a4cad5a7":"markdown","3ef87261":"markdown","fb3f4a1f":"markdown","26a2a182":"markdown","5a2792db":"markdown","47aa00d6":"markdown","f893f030":"markdown","b0eef09c":"markdown","4d40277f":"markdown","2eb9f944":"markdown","c11841ee":"markdown"},"source":{"1dc42027":"# Importing the needed libraries\nimport numpy as np \nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\n# Loading the reponse Data\nres = pd.read_csv('\/kaggle\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv', low_memory=False)\n# res = pd.read_csv('.\/kaggle_survey_2020_responses.csv', low_memory=False)","8d00aadf":"# Formating the columns for comfortable access\ncolumn_dict = {}\n\n# Getting the dictionary needed to change the column names\nfor col in res.columns:\n    n_col = col.replace('_Part_', '.')\n    n_col = n_col.replace('_', '.')\n    n_col = n_col.replace('OTHER', '0')\n    column_dict[col] = n_col\n    \n# Rename the columns\nres.rename(columns=column_dict, inplace=True)\n\n# Getting the uni-option columns\/questions\nuo_cols = []\nfor col in res.columns[1:]:\n    if not '.' in col:\n        uo_cols.append(col)\n        \nres.drop([0], inplace=True)","902829c8":"def break_down(start_index: int, end_index: int):\n    \"\"\"\n        Subsetting the dataframe into questions and binarizing the columns\n        \n        input: \n            start_index: The start of the subset index\n            end_index: The end of the subset index\n            \n        return:\n            dataframe containing the reponses to a given question\n    \"\"\"\n    subset = res.iloc[1:, start_index:end_index].copy()\n    \n    return binary_formatting(subset)\n\ndef binary_formatting(df: pd.DataFrame):\n    \"\"\"\n        Binarizing the columns, changing the column names\n        \n        input:\n            df: Dataframe to binarize\n        \n        return:\n            A dataframe of binary columns with answers as their column names\n    \"\"\"\n    col_dict = {}\n    for col in df.columns:\n        val = np.nan\n        if pd.isna(df[col].unique()[0]):\n            val = df[col].unique()[1]\n        else:\n            val = df[col].unique()[0]\n        \n        \n        if val == np.nan:\n            df[col] = df[col].map({np.nan: 0})\n        else:\n            df[col] = df[col].map({val: 1, np.nan: 0})\n        \n        col_dict[col] = val\n\n    df.rename(columns=col_dict, inplace=True)\n    \n    return df","973dda08":"uo_cols # Uni-option columns","4c8b0a76":"# Mulit-Option Question Break downs\nlanguage = break_down(7, 20) # Q7\nide = break_down(21, 33) # Q9\nhost_prod = break_down(33, 47) # Q10\nspec_hardware = break_down(48, 52) # Q12: TPU, GPU\nviz_lib = break_down(53, 65) # Q14: Which data visualization lib do u use?\nml_lib =  break_down(66, 82) # Q16: Regularly used ML libraries\nalgo = break_down(83, 94) # Q17: Regularly used ML Algorithms\ncomp_vision = break_down(94, 101) # Q18: Algorithms related to Computer Vision\nnlp = break_down(101, 107) # Q19: Algorithms related to NLP\nwork_activity = break_down(110, 118) # Q23\ncloud_platform = break_down(120, 132) # 26.a","e1504a14":"def order_uni(q: str, title: str, start: int=0, end:int=-1, ax: np.ndarray=None):\n    \"\"\"\n        Plots horizontal bar chart of a uni-option question\n        \n        input:\n            q: question number\n            title: title of the bar chart\n            start: starting index for slicing\n            end: ending index for slicing\n        \n        return:\n            horizontal bar chart\n    \"\"\"\n    return (res.loc[:, q].value_counts(normalize=True)[start:end].sort_values(ascending=True) * 100).plot.barh(title=title, ax=ax)","c517e0d2":"order_uni('Q1', 'Age Frequencies')","f97a3e80":"order_uni('Q2', title='Age Distribution')","11b536cf":"# Shortening some of the names\ncountry_dict = {\n    'United Kingdom of Great Britain and Northern Ireland': 'UK',\n    'United States of America': 'US',\n    'Republic of Korea': 'Korea',\n    'United Arab Emirates': 'UAE',\n    'South Korea': 'Korea',\n    'Republic of Korea': 'Korea',\n    'Iran, Islamic Republic of...': 'Iran'\n}\nres['Q3'] = res['Q3'].replace(country_dict)\n\n# Number of differnet countries\nnum_countries = res.loc[:,'Q3'].unique().shape[0]\nprint('# of different countries: ', num_countries)","0fde4628":"order_uni('Q3', title='', end=10)","3ffa77bd":"fig, axes = plt.subplots(2, 3, figsize=(10,7))\nfig.tight_layout()\n\nax_index = 0\n\nfor i in range(0, 6):\n    if i == 3: ax_index += 1\n        \n    order_uni('Q3', title=f'{i}th', start=i * 10, end=(i+1)*10, ax=axes[ax_index][i%3])\n\nplt.subplots_adjust(left=0, bottom=None, right=2, top=None, wspace=None, hspace=0.2)","ae79d50e":"# Renaming the Values\nres.loc[:, 'Q4'].replace(inplace=True, to_replace={\n    'Doctoral degree': 'Phd',\n    'Master\u2019s degree': 'Msc',\n    'Bachelor\u2019s degree': 'Bsc',\n    'No formal education past high school': 'High School',\n    'Some college\/university study without earning a bachelor\u2019s degree': 'Dropout',\n    'I prefer not to answer': 'No Answer',\n    'Professional degree': 'Pro deg',\n    np.nan: 'No Answer' # Imputing the missing values\n})\n\n# Plotting the occurances\norder_uni('Q4', title='')","2d83d0eb":"fig, (c1, c2, c3, c4, c5) = plt.subplots(1, 5, figsize=(10,3))\nfig.tight_layout()\n\n(res[res['Q4'] == 'Msc']['Q1'].value_counts(normalize=True).sort_values(ascending=True) * 100).plot.barh(title='Msc', ax=c1)\n(res[res['Q4'] == 'Bsc']['Q1'].value_counts(normalize=True).sort_values(ascending=True) * 100).plot.barh(title='BS', ax=c2)\n(res[res['Q4'] == 'Phd']['Q1'].value_counts(normalize=True).sort_values(ascending=True) * 100).plot.barh(title='Phd', ax=c3)\n(res[res['Q4'] == 'Dropout']['Q1'].value_counts(normalize=True).sort_values(ascending=True) * 100).plot.barh(title='Dropout', ax=c4)\n(res[res['Q4'] == 'Pro deg']['Q1'].value_counts(normalize=True).sort_values(ascending=True) * 100).plot.barh(title='Professional degree', ax=c5)\n\nplt.subplots_adjust(left=0, bottom=None, right=2, top=None, wspace=0.7, hspace=0.2)","2d4e5ca0":"order_uni('Q5',title='% of roles')","e4d7af18":"fig, (r1, r2) = plt.subplots(2, 7, figsize=(10,7))\nfig.tight_layout()\n\n# Row 1:\nres[res['Q5'] == 'Student']['Q4'].value_counts(normalize=True).sort_values().plot.barh(title=\"Student\",ax = r1[0])\nres[res['Q5'] == 'Data Scientist']['Q4'].value_counts(normalize=True).sort_values().plot.barh(title=\"Data Scientist\", ax=r1[1])\nres[res['Q5'] == 'Software Engineer']['Q4'].value_counts(normalize=True).sort_values().plot.barh(title=\"Software Engineer\", ax=r1[2])\nres[res['Q5'] == 'Other']['Q4'].value_counts(normalize=True).sort_values().plot.barh(title=\"Other\", ax=r1[3])\nres[res['Q5'] == 'Currently not employed']['Q4'].value_counts(normalize=True).sort_values().plot.barh(title=\"Currently not employed\", ax=r1[3])\nres[res['Q5'] == 'Data Analyst']['Q4'].value_counts(normalize=True).sort_values().plot.barh(title=\"Data Analyst\", ax=r1[4])\nres[res['Q5'] == 'Research Scientist']['Q4'].value_counts(normalize=True).sort_values().plot.barh(title=\"Scientist\",ax = r1[5])\nres[res['Q5'] == 'Machine Learning Engineer']['Q4'].value_counts(normalize=True).sort_values().plot.barh(title=\"ML Engineer\", ax=r1[6])\n# Row 2:\nres[res['Q5'] == 'Business Analyst']['Q4'].value_counts(normalize=True).sort_values().plot.barh(title=\"Business Analyst\", ax=r2[0])\nres[res['Q5'] == 'Other']['Q4'].value_counts(normalize=True).sort_values().plot.barh(title=\"Other\", ax=r2[1])\nres[res['Q5'] == 'Product\/Project Manager']['Q4'].value_counts(normalize=True).sort_values().plot.barh(title=\"Product\/Project Manager\", ax=r2[2])\nres[res['Q5'] == 'Data Engineer']['Q4'].value_counts(normalize=True).sort_values().plot.barh(title=\"Data Engineer\", ax=r2[3])\nres[res['Q5'] == 'Statistician']['Q4'].value_counts(normalize=True).sort_values().plot.barh(title=\"Statitician\", ax=r2[4])\nres[res['Q5'] == 'DBA\/Database Engineer']['Q4'].value_counts(normalize=True).sort_values().plot.barh(title=\"DBA\", ax=r2[5])\nres[pd.isna(res['Q5'])]['Q4'].value_counts(normalize=True).sort_values().plot.barh(title=\"No Answer\", ax=r2[6])\n\nplt.subplots_adjust(left=0, bottom=None, right=2, top=None, wspace=0.5, hspace=0.2)","9f3ab70b":"fig, (r1, r2) = plt.subplots(2, 7, figsize=(10,7))\nfig.tight_layout()\n\n# Row 1:\nres[res['Q5'] == 'Student']['Q3'].value_counts(normalize=True)[:10].sort_values().plot.barh(title=\"Student\",ax = r1[0])\nres[res['Q5'] == 'Data Scientist']['Q3'].value_counts(normalize=True)[:10].sort_values().plot.barh(title=\"Data Scientist\", ax=r1[1])\nres[res['Q5'] == 'Software Engineer']['Q3'].value_counts(normalize=True)[:10].sort_values().plot.barh(title=\"Software Engineer\", ax=r1[2])\nres[res['Q5'] == 'Other']['Q3'].value_counts(normalize=True)[:10].sort_values().plot.barh(title=\"Other\", ax=r1[3])\nres[res['Q5'] == 'Currently not employed']['Q3'].value_counts(normalize=True)[:10].sort_values().plot.barh(title=\"Currently not employed\", ax=r1[3])\nres[res['Q5'] == 'Data Analyst']['Q3'].value_counts(normalize=True)[:10].sort_values().plot.barh(title=\"Data Analyst\", ax=r1[4])\nres[res['Q5'] == 'Research Scientist']['Q3'].value_counts(normalize=True)[:10].sort_values().plot.barh(title=\"Scientist\",ax = r1[5])\nres[res['Q5'] == 'Machine Learning Engineer']['Q3'].value_counts(normalize=True)[:10].sort_values().plot.barh(title=\"ML Engineer\", ax=r1[6])\n# Row 2:\nres[res['Q5'] == 'Business Analyst']['Q3'].value_counts(normalize=True)[:10].sort_values().plot.barh(title=\"Business Analyst\", ax=r2[0])\nres[res['Q5'] == 'Other']['Q3'].value_counts(normalize=True)[:10].sort_values().plot.barh(title=\"Other\", ax=r2[1])\nres[res['Q5'] == 'Product\/Project Manager']['Q3'].value_counts(normalize=True)[:10].sort_values().plot.barh(title=\"Product\/Project Manager\", ax=r2[2])\nres[res['Q5'] == 'Data Engineer']['Q3'].value_counts(normalize=True)[:10].sort_values().plot.barh(title=\"Data Engineer\", ax=r2[3])\nres[res['Q5'] == 'Statistician']['Q3'].value_counts(normalize=True)[:10].sort_values().plot.barh(title=\"Statitician\", ax=r2[4])\nres[res['Q5'] == 'DBA\/Database Engineer']['Q3'].value_counts(normalize=True)[:10].sort_values().plot.barh(title=\"DBA\", ax=r2[5])\nres[pd.isna(res['Q5'])]['Q3'].value_counts(normalize=True)[:10].sort_values().plot.barh(title=\"No Answer\", ax=r2[6])\n\nplt.subplots_adjust(left=0, bottom=None, right=2, top=None, wspace=0.5, hspace=0.2)","10f0eb19":"order_uni('Q6', title='freq of # programming years')","af46c9a6":"fig, r1 = plt.subplots(1, 7, figsize=(10,3))\nfig.tight_layout()\n\nfor index, val in enumerate(res['Q6'].unique()):\n    if index == 7: break\n    res[res['Q6'] == val]['Q4'].value_counts(normalize=True).sort_values().plot.barh(title=val, ax = r1[index])\n\nplt.subplots_adjust(left=0, bottom=None, right=2, top=None, wspace=0.9, hspace=0.2)","e50b734b":"fig, r1 = plt.subplots(1, 7, figsize=(8, 5))\nfig.tight_layout()\n\nfor index, val in enumerate(res['Q6'].unique()):\n    if index == 7: break\n    res[res['Q6'] == val]['Q5'].value_counts(normalize=True).sort_values().plot.barh(title=val, ax = r1[index], fontsize=12)\n\nplt.subplots_adjust(left=0, bottom=None, right=3, top=None, wspace=2.5, hspace=0.2)","5d631a2f":"(language.sum().sort_values(ascending=True)\/ language.shape[0] * 100).plot.barh()","d509a9b4":"(language[language['Python'] == 0].groupby(['Python']).sum()).iloc[0].sort_values().plot.barh()","32974aa9":"def average_lang_num(lang):\n    return language[language[lang] == 1].sum(axis=1).mean()\n\nfor lang in language.columns:\n    if lang == 'None' or lang == 'Other': continue # Other and None do not make sense\n    print(f'Average # of languages if [{lang}] is {round(average_lang_num(lang) - 1,2)}')","5803932a":"language","43a9f40f":"language.columns","310dcf75":"fig, (r1, r2) = plt.subplots(2, 5, figsize=(5, 5))\nfig.tight_layout()\n\nfor index, val in enumerate(['Python', 'R', 'SQL', 'C', 'C++']):\n    res.loc[language[language[val] == 1].index,:]['Q5'].value_counts(normalize=True).sort_values().plot.barh(title=val, ax = r1[index], fontsize=10)\n    \nfor index, val in enumerate(['Java', 'Javascript', 'Julia', 'Swift', 'MATLAB']):\n    res.loc[language[language[val] == 1].index,:]['Q5'].value_counts(normalize=True).sort_values().plot.barh(title=val, ax = r2[index], fontsize=10)\n    \nplt.subplots_adjust(left=0, bottom=None, right=3, top=None, wspace=1.5, hspace=0.3)","619fd9b0":"language[(language['Python'] == 0) & (language['R'] == 0) & (language['SQL'] == 0)].sum()","2412d433":"res['Q8'].value_counts(normalize=True).sort_values().plot.barh()","1ec681b5":"fig, r1 = plt.subplots(1, 10, figsize=(8, 5))\nfig.tight_layout()\n\nfor index, val in enumerate(res['Q5'].unique()[:10]):\n    res[res['Q5'] == val]['Q8'].value_counts(normalize=True).sort_values().plot.barh(title=val, ax = r1[index], fontsize=12)\n\nplt.subplots_adjust(left=0, bottom=None, right=3, top=None, wspace=2.5, hspace=0.2)","694fd26a":"res[res['Q5'] == 'Research Scientist']['Q8']","d7626bfd":"res[res['Q5'] == 'Research Scientist']['Q8'].value_counts(normalize=True).sort_values().plot.barh(title=\"Researchers\")","3147ee49":"# Renaming some of the columns for our own ease\nide.rename(columns={\n        'Jupyter (JupyterLab, Jupyter Notebooks, etc) ': 'Jupyter',\n        'Visual Studio Code (VSCode)': 'VSCode',\n        '  Vim \/ Emacs  ': 'Vim\/Emacs',\n    }, inplace=True)","ba2f7f5b":"# Plotting the number of occurances\nide.sum().sort_values(ascending=True).plot.barh()","d5cd1b7c":"res.loc[ide[ide['  Vim \/ Emacs  '] == 1].index, ['Q1']].value_counts().plot.barh()","d3335e40":"matlab_users= language[language['MATLAB'] == 1].shape[0]\nide_users = ide[ide[' MATLAB '] == 1].shape[0]\nprint(f'{matlab_users} claimed they use MATLAB (Language) regularly yet {ide_users} use MATLAB (Editor) as their editor!')","ad3ea36b":"host_prod.sum().sort_values(ascending=True).plot.barh()","74d9da91":"host_prod.isnull().sum()","e84d8f5d":"# Shortening the option values, for ease of Plotting.\nres['Q11'].replace(inplace=True,\n    to_replace = {\n        'A cloud computing platform (AWS, Azure, GCP, hosted notebooks, etc)': 'Cloud',\n        'A personal computer or laptop': 'Local',\n        'A deep learning workstation (NVIDIA GTX, LambdaLabs, etc)': 'DL Workstation',\n    }\n)","234e74d7":"res['Q11'].value_counts(normalize=True).sort_values(ascending=True).plot.barh()","e8c28919":"fig, r1 = plt.subplots(1, 3, figsize=(8,5))\nfig.tight_layout()\n\nres[res['Q11'] == 'Local']['Q3'].value_counts(normalize=True)[:15].sort_values(ascending=True).sort_values().plot.barh(title=\"Local\",ax = r1[0])\nres[res['Q11'] == 'Cloud']['Q3'].value_counts(normalize=True)[:15].sort_values(ascending=True).plot.barh(title=\"Cloud\", ax=r1[1])\nres[res['Q11'] == 'DL Workstation']['Q3'].value_counts(normalize=True)[:15].sort_values(ascending=True).plot.barh(title=\"Dl Workstation\", ax=r1[2])\n\nplt.subplots_adjust(left=0, bottom=None, right=2, top=None, wspace=.5, hspace=0.2)\n","aa592903":"res[res['Q4'] == 'Pro deg']['Q11'].value_counts()","278dc90a":"fig, r1 = plt.subplots(1, 3, figsize=(8,5))\nfig.tight_layout()\n\nres[res['Q11'] == 'Local']['Q5'].value_counts(normalize=True).sort_values().plot.barh(title=\"Local\",ax = r1[0])\nres[res['Q11'] == 'Cloud']['Q5'].value_counts(normalize=True).sort_values().plot.barh(title=\"Cloud\", ax=r1[1])\nres[res['Q11'] == 'DL Workstation']['Q5'].value_counts(normalize=True).sort_values().plot.barh(title=\"Dl Workstation\", ax=r1[2])\n\nplt.subplots_adjust(left=0, bottom=None, right=2, top=None, wspace=1.5, hspace=0.2)","d9c90d37":"res['Q13'].value_counts(normalize=True).sort_values(ascending=True).plot.barh()","ce203c9e":"fig, r1 = plt.subplots(1, 3, figsize=(8,5))\nfig.tight_layout()\n\nres[res['Q11'] == 'Local']['Q13'].value_counts(normalize=True).sort_values().plot.barh(title=\"Local\",ax = r1[0])\nres[res['Q11'] == 'Cloud']['Q13'].value_counts(normalize=True).sort_values().plot.barh(title=\"Cloud\", ax=r1[1])\nres[res['Q11'] == 'DL Workstation']['Q13'].value_counts(normalize=True).sort_values().plot.barh(title=\"Dl Workstation\", ax=r1[2])\n\nplt.subplots_adjust(left=0, bottom=None, right=2, top=None, wspace=.5, hspace=0.2)","de6a547d":"viz_lib.sum().sort_values(ascending=True).plot.barh()","dc459d8b":"res['Q15'].replace({'I do not use machine learning methods': '0'}, inplace=True)\nres['Q15'].value_counts(normalize=True).sort_values().plot.barh()","fdde00e9":"fig, r1 = plt.subplots(1, 3, figsize=(8,5))\nfig.tight_layout()\n\nres[res['Q11'] == 'Local']['Q15'].value_counts(normalize=True).sort_values().plot.barh(title=\"Local\",ax = r1[0])\nres[res['Q11'] == 'Cloud']['Q15'].value_counts(normalize=True).sort_values().plot.barh(title=\"Cloud\", ax=r1[1])\nres[res['Q11'] == 'DL Workstation']['Q15'].value_counts(normalize=True).sort_values().plot.barh(title=\"Dl Workstation\", ax=r1[2])\n\nplt.subplots_adjust(left=0, bottom=None, right=2, top=None, wspace=.5, hspace=0.2)","78c85c76":"(ml_lib.sum() \/ ml_lib.shape[0]).sort_values(ascending=True).plot.barh()","249bb747":"(algo.sum() \/ algo.shape[0]).sort_values(ascending=True).plot.barh()","fa74bad2":"(comp_vision.sum() \/ comp_vision.shape[0]).sort_values(ascending=True).plot.barh()","95b029d7":"(nlp.sum() \/ nlp.shape[0]).sort_values(ascending=True).plot.barh()","c0eae9c9":"res['Q20'].value_counts(normalize=True).sort_values(ascending=True).plot.barh()","8fa163c9":"res['Q21'].value_counts(normalize=True).sort_values(ascending=True).plot.barh()","bd5c2433":"res['Q22'].value_counts(normalize=True).sort_values(ascending=True).plot.barh()","5f7117a0":"(work_activity.sum() \/ work_activity.shape[0]).sort_values(ascending=True).plot.barh(figsize=(10, 8), fontsize=20)","5d7f9274":"res['Q24'].value_counts(normalize=True).sort_values(ascending=True).plot.barh(figsize=(10,10))","baf8d9af":"res['Q25'].value_counts(normalize=True).sort_values(ascending=True).plot.barh(figsize=(10,10))","4da83bcc":"(cloud_platform.sum() \/ cloud_platform.shape[0]).sort_values(ascending=True).plot.barh()","37cbf1c6":"res['Q30'].unique()","94e073e8":"res['Q32'].isnull().sum()","ffa216fa":"res['Q38'].value_counts(normalize=True).plot.barh()","17845c28":"res['Q38'].isnull().sum()","e100bc73":"# Q1: Age\n- Majority of Kagglers are between 25-29 age range\n- It is safe to say that the majority of the Kagglers are between 18-29 years old. The ranges above 30 are in order (30-34 followed by 35-39 and etc.)\n- Interestingly they are some 70+ participatin in Kaggle.","6e1571cd":"# Q30: Frequently used big data tool\n- Too many missing values","d72e22cf":"# Q22: Does your workplace use ML?","2574bb46":"There are more TPU users among Cloud and Workstation users, yet they majority in each of these setp users are `Never`. Workstation users probably don't need to use TPUs to icnrease their speed and the cloud users are probably satisfied by using GPUs (for speed-related reasons).","315a914d":"` Break down of uni-option questions`\n- Q1: Age \n- Q2: Geneder \n- Q3: Country \n- Q4: Education\n- Q5: Role\n- Q6: Programming years\n- Q8: Recommended Programming Language for a beginner\n- Q11: Most Common setup\n- Q13: # of TPU uses\n- Q15: # of years using ML algorithms\n- Q20: # of employees in ur company\n- Q21: # of DS people in ur company\n- Q22: Does your workplace use ML?\n- Q24: Salary\n- Q25: ML expenses\n- Q30: Most frequent used Big Data tool\n- Q32: Most frequent used BI tool\n- Q38: Primary tool for analyzing data","3752c711":"# Q4: Education\n- The Majority of Kagglers have a Masters and Bachelor. This kind of makes sense based on the age data. ages 18-25 are the range for these students.","f43f4ddd":"# Q38: Primary tools used for Data Analysis","75375140":"# Break Down\nFunctions below are used to format the data into a more readable format.","d36b59b3":"# Q25: ML Expenses","4c6b08ee":"- The majority of Kagglers are students and they use their local environment the most, so we can postualte that it is the students huge impact on the enormous number of Local users.\n- Students have a fewer use of DL Workstations which implies that it is not justified for them to invest in such a equipment.","620ab5bd":"# Q2: Gender\n- There is an obvious gender gap within the Kaggle community.\n- The are 4 times (almost) more men than women in the industry.","9ee1d3d8":"# Q11: Most Common setup\n- 3007 people did not answer this question which is relatively odd. They probably were confused by the wording or didn't think they should choose the None or Orher option.\n- Correlation between perfessional degree and Cloud usage?","4e54b43c":"# Strategy\n- Clean and reformating the data for the ease of analysis. \n- Analyzing questions seperatety and relate various components together in order to obtain a valuable conclusion.","552701ce":"# Q19: NLP algorithms","3734ed2d":"# Q16: Regularly used ML libraries","a9f895f5":"# Q20: # of employees in the company","8da7576f":"# Q32: Most Frequently used BI tools","95102c61":"- Research Scientist and Statistician are the only two roles where US takes over India.","800f32d7":"# Q9: IDE\n- Jupyter Products are widely used. It is important to note that this decision is affected by the popular programming languages. Also, Jupyter provides support for pretty much all the top used languages.\n- The interesting thing to see is that Python IDE users are diverse, some use Jupyter, code, Pycharm, and Spyder.\n- I postulate that people who use Vim\/Emacs and Visual Studio are older than others.","0f9cb931":"- It would be safe to assume that anyone that has used a TPU more than 25 times, is a regual user.","936f8cf7":"# Q7: Language\n- Python is the most used language, almost double the second language (SQL).\n- One important thing to note is that they are some languages in the listing which are not widely used in Data Science but participants have indicated that they use it. And alos some of these languages are more technical than the other ones, in a sense they can be a prerequiste for some other programming languages. For instance, if one knows C then he\/she knows C++ and possibly Python.\n- It might be worth while to analyze what are the alternative programming language for people who does not use the populer one. \n- I bielive, assumptions could be made just by counting the number of programming languages that poeple know. If they know more than a certain number then they are probably experts and they have been coding for a long time.","8b582956":"# Brain Storming\nI don't believe anyone knows if they are going to find something significant when they go through a dataset. I hypothesize that analysis techniques aside, Brain Storming on the data could help the creeative process. And by brainstorming, I mean going through data and trying to challenge your thoughts on the matter.","945b4663":"# Q21: # of Data Scientist in company","5c6583d3":"# Q26: Cloud platform","4933de2c":"# Q5: Role\nsome pre-analysis questions:\n- Does degree affect role?\n- What role does age play in one's role?\n\n1. Students have the majority:\n    - More than 50% percent of the student are working towards their Bs (or have a Bs).\n    - 2nd largest % goes to Msc (which is kind of predictable).\n    - Yet the third largest portion are dropouts.\n2. Data Scientist:\n    - Half (almost) of the Data Scientist have a Msc.\n    - The number of Bsc and Phd students are relatively close.\n    - The number of Msc students with Data Science title suggests that Msc is kind of a requirement to become a Data Scientist. And I say kind of because it is obviously possible to get a Data Science job with lower educational degree, yet based on the ovserved trend majority of technical roles are given to Msc.\n\n- By Looking at the graphs, we can see that Msc can be really helpful to get a job. Only Software Engineer role has more Bsc than Msc. This implies that Software engineering might not need a strong background and knowledge that a Data-related job might need.\n- Research Scientist role has Phd degree at the top with almost 60%. This implies that higher education has an important correlation with becoming a research Scientist. Also, Phd is only the first rank in this role, hence we can say that research scientist is the most technical role one can have in data-related jobs.","c95e197a":"## What is the alternative IDE for MATLAB users?\n- Octave, is a non-paid version of MATLAB and it is one of the possible ides used by Kagglers.\n- Jupyter has support for it yet there are only ~650 MATLAB programmers who use other products than MATLAB IDE.","f189fb51":"# Q24: Salary","2ae84728":"# Q14: Visualaztion tools\n- There is correlation between the visualization tools and the programming languages. Since Python is the most commonly used programming language, there is not surprise when mapltlib and seaborn.","274d70a5":"## Given that you know one language, what are the chances that you know multiple languages?\n- Based on the data, poeple who use swift regularly know almost 4 programming languages.\n- Julia Javascript, Java, and C\/C++ follow after swift in the average number of programming languages developers use.\n- Now thigns get interesting when it comes to Python, R, and SQL:\n    - Python has the lowest average among the programming languages. This shows that lots of people who have learned Python had not seen the point in learning another programming languages.\n    - Now between these three, SQL has the highest average, this is probably because of the fact that SQL is limited in the paradigm of things it can do (compared to OO languages R and Python). And people have seeked to learn another programming languages.\n    - Same logic apples to R as well, since it is not a general purpose programming language, Kagglers have learned alternatives.\n    - All these add up to say that Python is the most prefered choice for data-related projects based on the data sicne it has discouraged people from learning other technologies.","2494ac86":"# Q13: TPU usage","41dbce89":"# Loading and Cleaning the data\n- Column names are verbose and they do not help. Column names have been changed by replacing '_Part_' and '_' with '.', 'OTHER' with '0'.\n- Most columns are actually options for a question. It would help the analysis to break down the dataframe into subset of questions. This would mean that for each question we will have n columns representing n possible answers (to that question) in the binary format.\n- The majority of missing values are because of the multi optional questions but they are some uni-option question with missing values that need imputing. Yet we have to go through each question to find the feasible value to fill the missing values with.","a4cad5a7":"- 70% Majority has never use a TPU:\n    - The algorithms they use or their problem is not difficult enough to need such a high power.\n    - People who have not used are probably Data Analytics (kind job, less technical) or Data Scientist whom are focused on fields where TPUs are not required (not doing Deep Learning stuff).\n    - We could aslo explore this majority with the choice of setup since most Kagglers use Local Environmnets, they haven't seen it feasible to buy a TPU.\n    - Given the graph is is hard to make any assumption since there are lots of students in the data. But obviously students who have a lower understanding of various concepts (compared to other roles), use the least amount of TPU. This also implies they are participating in a fields where TPU might not be required (they are not doing anything Deep learning-related). Which again implies a lower level understangin.","3ef87261":"# Q8: Recommended Programming Language for a beginner\n- Could be interesting to see which language do each person (based on their role) recommend.","fb3f4a1f":"- Interestingly the majority of Kagglers use their own local environment:\n    - This means that the Kaggle Notebooks might not be as comfortable as their local environment.\n    \n","26a2a182":"Interestingly, most poeple who use Vim\/Emacs are between 25-29, yet my postulation is not necessarily wrong since most users are in their thirties. Also, the majority of surveyed people were in 22-24 age range and it is still 4th in the place.","5a2792db":"#### What is the alternative to Python?\n- Firstly, they is a minority who do not use Python on a regular basis.\n- And people who don't use Python, use SQL and R for Data-related projects.\n- Java is another alternative which is probably used because of its presence.","47aa00d6":"# Q17: Algorithms","f893f030":"# Q18: Computer Vision","b0eef09c":"# Q10: Host Prod\n- Majority use Google products (Colab and Kaggle Notebooks)\n- Followd by `None`, Which implies that a good portion of the Kagglers do not use hosted services.\n","4d40277f":"# Q6: Programming years\n- Role vs Programming years\n- Role vs Degree","2eb9f944":"# Q15: ML Algorithm years","c11841ee":"# Q3: Country\n- Kagglers are from 55 different countries (Counting the others).\n- In the first 10 countries with the most Kagglers, India is at the lead. Which is interesting since India and Nigeria are the only two non-first world countries in top 10. In future, we might change our definition of first and second world.\n- Based on China's economy and tech initiatives, one might expect to see China in top five. Yet, interestingly China is below US and India with a large difference.\n- Looking at the data, we can see that people from all over the world are participating\n\n## Relation between infrastructure and Kaggling:\nIt is logical to expect the `First-word` countries have a higher participation rate with in the Kaggle community. It is less likely for people in Syria (where a civil war is going on) to have the time to use Kaggle. I suspect there is also more value to doing Kaggle competitions in First-wolrd countries since the employers will acknowledge your talent given your participation level on Kaggle.\n- India has the most Kagglers. There several factors to consider:\n    - India has the 2nd largest population: Because of its large population, even if a smaller proportion of the society were involved on Kaggle still it would could still be at first rank.\n    - India is a development country (2nd world): This shows that given India is not a first-world country, it has the needed infrastructure (internet connection, educational resouces, and etc.) for individuals to participate on Kaggle. Same thing is true about Nigeria.\n- Nigeria: It is one of the two development countries in top 10. Which implies that Nigerians have the infrastructure and are motivated enough to participate on kaggle.\n- As we go down the list, we see less `First-World` countries and more development countries. We even come across some `Third-World` coutnries (Iran)."}}