{"cell_type":{"ca413abb":"code","f491a431":"code","cb12a489":"code","535c8576":"code","32c1e5bb":"code","6b52ada6":"code","e641779b":"code","b0d0d142":"code","a59d8f4f":"code","9d636aa5":"code","c1a2abe4":"code","ba5bd0d5":"code","822e3c41":"code","26465545":"code","51d68f40":"code","bff06afb":"code","6ea17c8a":"code","04195c03":"code","39025e54":"code","d2385343":"code","c71a9642":"code","da3fa85c":"code","463371d7":"code","de71db4d":"code","8ce5e1f1":"code","1e71579f":"code","8403c823":"code","625fab4d":"code","3dc7d87d":"code","7accf93a":"code","99007e16":"code","5052a8c9":"code","052295cd":"code","4b22dbdf":"code","e1927a10":"code","0afe9b36":"code","fdfd4869":"code","766b818d":"code","9f15fda2":"code","09a5d5b8":"code","5ee80ed6":"code","76924c4d":"code","b6f9729e":"code","039bfacb":"code","673ec5e5":"code","82ee69ea":"code","c8354717":"code","091eee9a":"code","fba4eec1":"code","5b2bf7da":"code","5d6b38aa":"code","5db511a3":"code","1bf31768":"code","fd22cb2c":"code","7afdb837":"code","44bba928":"code","8f076f16":"code","d8c03c25":"code","00748c10":"code","7599cdd6":"code","143e71c9":"code","c6243137":"code","0057010f":"code","aaecb26d":"code","6b575a3c":"code","52bda022":"markdown","f04b0b16":"markdown","81191e72":"markdown","547a7d11":"markdown","5e087886":"markdown","edaa0314":"markdown","81527ad1":"markdown","247a1307":"markdown","859f2a81":"markdown","6b8f7baf":"markdown","8dea1fdf":"markdown","d5dcc3fd":"markdown","e0d592cc":"markdown","7c86d208":"markdown","8dce612e":"markdown","bba1d6a3":"markdown","1f38babf":"markdown","1c6bbf34":"markdown"},"source":{"ca413abb":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nimport math\nfrom sklearn.preprocessing import StandardScaler\nwarnings.filterwarnings('ignore')","f491a431":"titanic_train = pd.read_csv('..\/input\/titanic\/train.csv')\ntitanic_test = pd.read_csv('..\/input\/titanic\/test.csv')","cb12a489":"train_length = len(titanic_train)\nprint(titanic_train.shape)\nprint(titanic_test.shape)","535c8576":"# Combining Train and Test Data-Sets\ntitanic_test[\"isTest\"] = -1","32c1e5bb":"full_data_set = pd.concat([titanic_train, titanic_test], axis= 0)","6b52ada6":"full_data_set.head(10)","e641779b":"titanic_train.head()","b0d0d142":"full_data_set.info()","a59d8f4f":"non_survived_count, survived_count = titanic_train.Survived.value_counts()","9d636aa5":"print(f\"Non Survived People Percentage : {round((non_survived_count\/train_length)*100,2)} %\")\nprint(f\"Survived People Percentage : {round((survived_count\/train_length)*100,2)} %\")","c1a2abe4":"ax = sns.countplot(x=titanic_train.Survived, data = titanic_train, hue='Survived')\nfor p in ax.patches:\n  x = p.get_x() + p.get_width() \/ 2 - 0.30\n  y = p.get_y() + p.get_height()\n  ax.annotate(y, (x, y), size = 12)\nplt.show()","ba5bd0d5":"titanic_train.columns","822e3c41":"titanic_train.describe()","26465545":"titanic_train.isnull().sum()","51d68f40":"#Finding Missing Values in given features\nmissing_cols = []\nmissing_percent = []\nfor col in titanic_train.columns:\n  missing_cols.append(col)\n  missing_percent.append(round(titanic_train[col].isnull().sum()\/(train_length),2) * 100)","bff06afb":"plt.figure(figsize=(10, 6))\nax = sns.barplot(x = missing_cols, y = missing_percent)\nfor p in ax.patches:\n  x = p.get_x() + p.get_width() \/ 2 - 0.30\n  y = p.get_y() + p.get_height()\n  ax.annotate(y, (x, y), size = 12)\nplt.show();","6ea17c8a":"titanic_train.Age.describe()","04195c03":"sns.boxplot(y=titanic_train.Age)\nplt.show()","39025e54":"# AGE\nsns.distplot(titanic_train.Age)\nplt.show()","d2385343":"titanic_train.Age.corr(titanic_train.Survived, method='spearman')","c71a9642":"titanic_train.Fare.describe()","da3fa85c":"sns.boxplot(y=titanic_train.Fare)\nplt.show()","463371d7":"sns.distplot(titanic_train.Fare)\nplt.show()","de71db4d":"sns.distplot(titanic_train.Fare.apply(lambda x: np.log2(1+x)))\nplt.show()","8ce5e1f1":"for i in range(0,100,10):\n  val = titanic_train.Fare.values\n  val = np.sort(val, axis=None)\n  print(f\"{i} Percentile Value is : {val[int(train_length*(i \/ 100))]}\")\nprint(\"100 Percentile Value is : \", val[-1])","1e71579f":"for i in range(90,100,1):\n  val = titanic_train.Fare.values\n  val = np.sort(val, axis=None)\n  print(f\"{i} Percentile Value is : {val[int(train_length*(i \/ 100))]}\")\nprint(\"100 Percentile Value is : \", val[-1])","8403c823":"for i in np.arange(0.0, 1.0, 0.1):\n  val = titanic_train.Fare.values\n  val = np.sort(val, axis=None)\n  print(f\"{round(99+i,3)} Percentile Value is : {val[int(train_length*(float(99+i)\/100))]}\")\nprint(\"100 Percentile Value is : \", val[-1])","625fab4d":"titanic_train.Fare.corr(titanic_train.Survived, method='spearman')","3dc7d87d":"categorical_columns = ['Sex', 'SibSp', 'Parch', 'Embarked','Pclass']","7accf93a":"fig, ax = plt.subplots(math.ceil(len(categorical_columns) \/ 3), 3, figsize=(20, 12))\nax = ax.flatten()\nfor ax, col in zip(ax, categorical_columns):\n  sns.countplot(x= col, data= titanic_train, hue='Survived', ax=ax)\n  ax.legend(title='Survived', labels=['No', 'Yes'],loc='upper right')","99007e16":"titanic_train.corr()","5052a8c9":"#titanic_train.drop(titanic_train[titanic_train['Fare']>300].index, inplace=True)","052295cd":"full_data_set.Age.fillna(titanic_train.Age.median(), inplace=True)","4b22dbdf":"full_data_set['family_size'] = full_data_set.Parch + full_data_set.SibSp","e1927a10":"full_data_set.family_size.describe()","0afe9b36":"full_data_set['is_alone'] = full_data_set.family_size.map(lambda a: 1 if a == 0 else 0)","fdfd4869":"bins = [0, 5, 20, 40, 60, 90]\nfull_data_set['age_bins'] = pd.cut(x=full_data_set.Age, bins= bins, labels=['0-5','5-20','20-40','40-60','60+'] )\nfull_data_set = pd.get_dummies(data=full_data_set, columns = ['age_bins'], prefix='age')","766b818d":"full_data_set.Embarked.fillna(value=titanic_train.Embarked.mode()[0], inplace=True)","9f15fda2":"titanic_train.Embarked.value_counts()","09a5d5b8":"titanic_train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False)\\\n      .mean().sort_values(by='Survived', ascending=False)","5ee80ed6":"full_data_set['Title'] = full_data_set.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)","76924c4d":"full_data_set.Title = full_data_set.Title.map(lambda a: a if a in ['Mr','Miss','Mrs','Master'] else 'Rare')","b6f9729e":"full_data_set.Title.value_counts()","039bfacb":"full_data_set = pd.get_dummies(data=full_data_set, columns=['Title'], prefix='Title')","673ec5e5":"full_data_set = pd.get_dummies(data=full_data_set, columns=['Embarked'], prefix='embarked')","82ee69ea":"full_data_set = pd.get_dummies(data=full_data_set, columns=['Sex'])","c8354717":"full_data_set = pd.get_dummies(data=full_data_set, columns=['Pclass'])","091eee9a":"std_fare = StandardScaler()\nstd_fare.fit(full_data_set.Fare.values.reshape(-1,1))","fba4eec1":"full_data_set['std_fare'] = std_fare.transform(full_data_set.Fare.values.reshape(-1,1))\nfull_data_set.std_fare.fillna(value=full_data_set.std_fare.mean(), inplace=True)","5b2bf7da":"full_data_set.drop(labels=['PassengerId','Name','Age','Ticket','Cabin','Fare'], axis=1, inplace=True)","5d6b38aa":"#Train and Test data Spliting\ntest_set = full_data_set[full_data_set.isTest == -1]\ntrain_set = full_data_set[full_data_set.isTest != -1]","5db511a3":"train_set.drop(labels=['isTest'],axis=1, inplace=True)","1bf31768":"test_set.drop(labels=['isTest', 'Survived'],axis=1, inplace=True)","fd22cb2c":"print(\"Test Data Shape : \", test_set.shape)\nprint(\"Train Data Shape : \", train_set.shape)","7afdb837":"y = train_set.Survived\nX = train_set.drop(labels=['Survived'], axis=1)","44bba928":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import auc, roc_auc_score, f1_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV","8f076f16":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)","d8c03c25":"knn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\nknn_valid_pred = knn.predict(X_test)\nprint(\"Train Score\", knn.score(X_train, y_train))\nprint(\"Validation Score\", knn.score(X_test, knn_valid_pred))","00748c10":"lrg = LogisticRegression()\nlrg.fit(X_train, y_train)\nlrg_valid_pred = lrg.predict(X_test)\nprint(\"Train Score\", lrg.score(X_train, y_train))\nprint(\"Validation Score\", lrg.score(X_test, lrg_valid_pred))","7599cdd6":"dtc = DecisionTreeClassifier()\ndtc.fit(X_train, y_train)\ndtc_valid_pred = dtc.predict(X_test)\nprint(\"Train Score\", dtc.score(X_train, y_train))\nprint(\"Validation Score\", dtc.score(X_test, dtc_valid_pred))","143e71c9":"rfc = RandomForestClassifier(n_estimators=300)\nrfc.fit(X_train, y_train)\nrfc_valid_pred = rfc.predict(X_test)\nprint(\"Train Score\", rfc.score(X_train, y_train))\nprint(\"Validation Score\", rfc.score(X_test, rfc_valid_pred))","c6243137":"xgc = XGBClassifier()\nxgc.fit(X_train, y_train)\nxgc_valid_pred = xgc.predict(X_test)\nprint(\"Train Score\", xgc.score(X_train, y_train))\nprint(\"Validation Score\", xgc.score(X_test, rfc_valid_pred))","0057010f":"titanic_test[\"Survived\"] = rfc.predict(test_set).astype(int)","aaecb26d":"output_file = titanic_test[[\"PassengerId\",\"Survived\"]]","6b575a3c":"output_file.to_csv(\"submission.csv\", index=False)","52bda022":"### Features Descirption\n* PassengerId - This feature is Unique for each Passenger in Titanic\n* PClass - A proxy for socio-economic status (SES)\n  * 1st = Upper\n  * 2nd = Middle\n  * 3rd = Lower \n* Name - Name of a Passenger\n* Sex - Gender of a Passenger,\n* Age - Age of a Passenger(In Years)\n* SibSp - The dataset defines family relations in this way.\n  * Sibling = brother, sister, stepbrother, stepsister\n  * Spouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n* Parch - The dataset defines family relations in this way.\n  * Parent = mother, father\n  * Child = daughter, son, stepdaughter, stepson\n  * Some children travelled only with a nanny, therefore parch=0 for them.\n* Ticket - Ticket Number [Unique for each passenger]\n* Fare - Fare of each Ticket.\n* Cabin - Cabin Number\n* Embarkation - Port of Embarkation\n  *\tC = Cherbourg\n  * Q = Queenstown\n  * S = Southampton\n\n* Unique Features: [PassengerId, Name, Ticket]\n* Numerical Features: [Age,Fare]\n* Categorical Features: [Pclass, Sex, SibSp, Parch, Cabin, Embarked]\n\nNote: Unique Features might not be useful much, so we can drop those features. But by using some feature engineering we can find insights in data.","f04b0b16":"#### Observations\n* Passengers which have 0 family size has very less survived ratio, so we can build one feature for is alone or not.","81191e72":"## Missing Values","547a7d11":"## Age","5e087886":"## Fare","edaa0314":"### Loading DataSet's By using pandas read_csv() function","81527ad1":"#### Train Data Set has 891 Rows and 12 Columns.\n#### Test Data Set has 418 Rows and 11 Columns.\n\nBussiness Problem is We do predict testing data Survival Value of Testing Data based on features.\n\n* For better prediction first we should understand data and find answers to our questions based on hidden insights of our data","247a1307":"#### Categorical Feature Observations\n* Training data has most of passengers are male and less percent of passengers were survied in titanic disaster, so Female passengers has high chance of survived chance.\n* Passenger Class First Class Passengers have high survival ratio compared to Second Class and Third Class Passengers. Most of passengers are traveling on Third class but they have very low survival rate compared to First and Second Class passengers.\n* Family size of a passenger[SibSp and ParCh] also has impcat on survival, family size 0 passengers has very low survival ratio.\n* Embarked S has very low srvival ratio.\n","859f2a81":"### Titanic Disaster Training Data \n* Most passengers(61%) didn't survived.\n* Only 39% of passengers survided.","6b8f7baf":"### Missing Values in Training Data\n* In Training Data set three features has missing values\n* Embarked has 2 missing values. It is categorical data, so we can replace missing values with mostly occured(Mode) value in training data set.\n* Age is numerical feature and 20% of values are missing in training data set. We have several ways of handle missing values. Eg: Replacing missing values by Mean value, Median value, Some other techniques. Mostly if data is normally distributed mean value is prefarable otherwise median value is preferable.\n* Cabin has 77% of missing values. This percentage is very high, mostly we can drop features has high percentage of missing values.","8dea1fdf":"## Numerical Features Analysis\n * Training Data has two numerical features Age and Fare.\n","d5dcc3fd":"### Categorical Features\n* Train Data has [Pclass, Sex, SibSp, Parch, Cabin, Embarked] categorical features.","e0d592cc":"#### Observations\n* Fare feature has outlier value 512. By using percentile we can put threshhold value 300, so we can remove which row has fare value morethen 300.\n* Data is not distributed normlly.\n* We don't have strong correlation between Fare and Survived features. corralation is = 0.32.","7c86d208":"### DecisionTreeClassifier and RandomForestClassifiers has higest Trining Accuracy Scores. I am taking RandomForestClassifier as a final Model to predict Test Data set.","8dce612e":"#### Observations\n* Age is looks like little right skewed distribution, This type of distribution mostly we prefer median value compared to mean to handle missing values.\n* According to Box plot we have very little outliers.\n* Age value doesn't much corralation with Survived feature.","bba1d6a3":"## Feature Engineering \n* Default Features are not much suffecient to decide is passenger survived or not. So we do create some features which are used for predicting is passenger is survived or not.","1f38babf":"Fare value seems skewed, wo do use some hack to fix this skewed distribution","1c6bbf34":"We did use some data tranformation technique to fix skewness of a data distribution."}}