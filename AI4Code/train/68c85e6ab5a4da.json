{"cell_type":{"20e854d9":"code","e1cbe724":"code","717132cf":"code","3057bf38":"code","0904253a":"code","4ce320b2":"code","ae090b2c":"code","be57f28a":"code","bfe75488":"code","e59e3413":"code","40da3c11":"code","fa8ed751":"code","689becc8":"code","3fd953bd":"code","4a0c7866":"code","ff44326e":"code","60523511":"code","851b8c67":"code","3fe9dc96":"code","67068fe0":"code","0d21df59":"code","05a0ee65":"code","ac57a4a0":"code","e2df764a":"code","a5ba2a8d":"code","7e3f9380":"code","dd3a2edf":"code","1f23b616":"code","12c91c93":"code","395a606d":"code","f06185e2":"code","ef0ddf98":"code","ddaa0ebd":"code","72297b6a":"code","114a2603":"markdown","464a9146":"markdown","e1704896":"markdown","788b40a4":"markdown","6db40191":"markdown","26f3fa54":"markdown","49b0d564":"markdown","dea6701b":"markdown","f5364ebd":"markdown","cf0c6bc4":"markdown","bf44cb4b":"markdown","f84bd57f":"markdown","df39f67e":"markdown","caabf4ae":"markdown","53e05f25":"markdown","29af2047":"markdown","2a08c81b":"markdown","2777a10b":"markdown","6d8a611b":"markdown","a271afb4":"markdown","adb2f6d3":"markdown","b1ff93dc":"markdown","8d8eb761":"markdown","a421c925":"markdown","5d0ba0f4":"markdown"},"source":{"20e854d9":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import confusion_matrix\nfrom mlxtend.plotting import plot_confusion_matrix\n\nfrom keras import models\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.utils import to_categorical","e1cbe724":"path = '\/kaggle\/input\/challenges-in-representation-learning-facial-expression-recognition-challenge\/'\nos.listdir(path)","717132cf":"data = pd.read_csv(path+'icml_face_data.csv')","3057bf38":"data.head()","0904253a":"def prepare_data(data):\n    \"\"\" Prepare data for modeling \n        input: data frame with labels und pixel data\n        output: image and label array \"\"\"\n    \n    image_array = np.zeros(shape=(len(data), 48, 48))\n    image_label = np.array(list(map(int, data['emotion'])))\n    \n    for i, row in enumerate(data.index):\n        image = np.fromstring(data.loc[row, ' pixels'], dtype=int, sep=' ')\n        image = np.reshape(image, (48, 48))\n        image_array[i] = image\n        \n    return image_array, image_label\n\ndef plot_examples(label=0):\n    fig, axs = plt.subplots(1, 5, figsize=(25, 12))\n    fig.subplots_adjust(hspace = .2, wspace=.2)\n    axs = axs.ravel()\n    for i in range(5):\n        idx = data[data['emotion']==label].index[i]\n        axs[i].imshow(train_images[idx][:,:,0], cmap='gray')\n        axs[i].set_title(emotions[train_labels[idx].argmax()])\n        axs[i].set_xticklabels([])\n        axs[i].set_yticklabels([])\n        \ndef plot_all_emotions():\n    fig, axs = plt.subplots(1, 7, figsize=(30, 12))\n    fig.subplots_adjust(hspace = .2, wspace=.2)\n    axs = axs.ravel()\n    for i in range(7):\n        idx = data[data['emotion']==i].index[i]\n        axs[i].imshow(train_images[idx][:,:,0], cmap='gray')\n        axs[i].set_title(emotions[train_labels[idx].argmax()])\n        axs[i].set_xticklabels([])\n        axs[i].set_yticklabels([])\n        \ndef plot_image_and_emotion(test_image_array, test_image_label, pred_test_labels, image_number):\n    \"\"\" Function to plot the image and compare the prediction results with the label \"\"\"\n    \n    fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharey=False)\n    \n    bar_label = emotions.values()\n    \n    axs[0].imshow(test_image_array[image_number], 'gray')\n    axs[0].set_title(emotions[test_image_label[image_number]])\n    \n    axs[1].bar(bar_label, pred_test_labels[image_number], color='orange', alpha=0.7)\n    axs[1].grid()\n    \n    plt.show()\n    \ndef plot_compare_distributions(array1, array2, title1='', title2=''):\n    df_array1 = pd.DataFrame()\n    df_array2 = pd.DataFrame()\n    df_array1['emotion'] = array1.argmax(axis=1)\n    df_array2['emotion'] = array2.argmax(axis=1)\n    \n    fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharey=False)\n    x = emotions.values()\n    \n    y = df_array1['emotion'].value_counts()\n    keys_missed = list(set(emotions.keys()).difference(set(y.keys())))\n    for key_missed in keys_missed:\n        y[key_missed] = 0\n    axs[0].bar(x, y.sort_index(), color='orange')\n    axs[0].set_title(title1)\n    axs[0].grid()\n    \n    y = df_array2['emotion'].value_counts()\n    keys_missed = list(set(emotions.keys()).difference(set(y.keys())))\n    for key_missed in keys_missed:\n        y[key_missed] = 0\n    axs[1].bar(x, y.sort_index())\n    axs[1].set_title(title2)\n    axs[1].grid()\n    \n    plt.show()","4ce320b2":"data[' Usage'].value_counts()","ae090b2c":"emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}","be57f28a":"train_image_array, train_image_label = prepare_data(data[data[' Usage']=='Training'])\nval_image_array, val_image_label = prepare_data(data[data[' Usage']=='PrivateTest'])\ntest_image_array, test_image_label = prepare_data(data[data[' Usage']=='PublicTest'])","bfe75488":"train_images = train_image_array.reshape((train_image_array.shape[0], 48, 48, 1))\ntrain_images = train_images.astype('float32')\/255\nval_images = val_image_array.reshape((val_image_array.shape[0], 48, 48, 1))\nval_images = val_images.astype('float32')\/255\ntest_images = test_image_array.reshape((test_image_array.shape[0], 48, 48, 1))\ntest_images = test_images.astype('float32')\/255","e59e3413":"train_labels = to_categorical(train_image_label)\nval_labels = to_categorical(val_image_label)\ntest_labels = to_categorical(test_image_label)","40da3c11":"plot_all_emotions()","fa8ed751":"plot_examples(label=0)","689becc8":"plot_examples(label=1)","3fd953bd":"plot_examples(label=2)","4a0c7866":"plot_examples(label=3)","ff44326e":"plot_examples(label=4)","60523511":"plot_examples(label=5)","851b8c67":"plot_examples(label=6)","3fe9dc96":"plot_compare_distributions(train_labels, val_labels, title1='train labels', title2='val labels')","67068fe0":"class_weight = dict(zip(range(0, 7), (((data[data[' Usage']=='Training']['emotion'].value_counts()).sort_index())\/len(data[data[' Usage']=='Training']['emotion'])).tolist()))","0d21df59":"class_weight","05a0ee65":"model = models.Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(7, activation='softmax'))","ac57a4a0":"model.compile(optimizer=Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])","e2df764a":"model.summary()","a5ba2a8d":"history = model.fit(train_images, train_labels,\n                    validation_data=(val_images, val_labels),\n                    class_weight = class_weight,\n                    epochs=12,\n                    batch_size=64)","7e3f9380":"test_loss, test_acc = model.evaluate(test_images, test_labels)\nprint('test caccuracy:', test_acc)","dd3a2edf":"pred_test_labels = model.predict(test_images)","1f23b616":"loss = history.history['loss']\nloss_val = history.history['val_loss']\nepochs = range(1, len(loss)+1)\nplt.plot(epochs, loss, 'bo', label='loss_train')\nplt.plot(epochs, loss_val, 'b', label='loss_val')\nplt.title('value of the loss function')\nplt.xlabel('epochs')\nplt.ylabel('value of the loss function')\nplt.legend()\nplt.grid()\nplt.show()","12c91c93":"acc = history.history['accuracy']\nacc_val = history.history['val_accuracy']\nepochs = range(1, len(loss)+1)\nplt.plot(epochs, acc, 'bo', label='accuracy_train')\nplt.plot(epochs, acc_val, 'b', label='accuracy_val')\nplt.title('accuracy')\nplt.xlabel('epochs')\nplt.ylabel('value of accuracy')\nplt.legend()\nplt.grid()\nplt.show()","395a606d":"plot_image_and_emotion(test_image_array, test_image_label, pred_test_labels, 106)","f06185e2":"plot_image_and_emotion(test_image_array, test_image_label, pred_test_labels, 40)","ef0ddf98":"plot_compare_distributions(test_labels, pred_test_labels, title1='test labels', title2='predict labels')","ddaa0ebd":"df_compare = pd.DataFrame()\ndf_compare['real'] = test_labels.argmax(axis=1)\ndf_compare['pred'] = pred_test_labels.argmax(axis=1)\ndf_compare['wrong'] = np.where(df_compare['real']!=df_compare['pred'], 1, 0)","72297b6a":"conf_mat = confusion_matrix(test_labels.argmax(axis=1), pred_test_labels.argmax(axis=1))\n\nfig, ax = plot_confusion_matrix(conf_mat=conf_mat,\n                                show_normed=True,\n                                show_absolute=False,\n                                class_names=emotions.values(),\n                                figsize=(8, 8))\nfig.show()","114a2603":"# <h1 style='background:#CCCCCC; border:0; color:black'><center><span style=\"color: royalblue;\"><span style=\"color: royalblue;\">Some Examples<\/span><\/span><\/center><\/h1> ","464a9146":"Reshape and scale the images:","e1704896":"# <h1 style='background:#CCCCCC; border:0; color:black'><center><span style=\"color: royalblue;\"><span style=\"color: royalblue;\">Distribution Of Labels<\/span><\/span><\/center><\/h1> ","788b40a4":"## Fear","6db40191":"# <h1 style='background:#CCCCCC; border:0; color:black'><center><span style=\"color: royalblue;\"><span style=\"color: royalblue;\">Load Data<\/span><\/span><\/center><\/h1> \nLoad the image data with labels.","26f3fa54":"Define training, validation and test data:","49b0d564":"# <h1 style='background:#CCCCCC; border:0; color:black'><center><span style=\"color: royalblue;\"><span style=\"color: royalblue;\">Analyse Results<\/span><\/span><\/center><\/h1> ","dea6701b":"# <h1 style='background:#CCCCCC; border:0; color:black'><center><span style=\"color: royalblue;\"><span style=\"color: royalblue;\">Model<\/span><\/span><\/center><\/h1> \nWe define a simple CNN model:","f5364ebd":"## Neutral","cf0c6bc4":"Encoding of the target value:","bf44cb4b":"## All Emotions","f84bd57f":"# <h1 style='background:#CCCCCC; border:0; color:black'><center><span style=\"color: royalblue;\"><span style=\"color: royalblue;\">Functions<\/span><\/span><\/center><\/h1> \nWe define some helper functions for preparing and ploting the data.","df39f67e":"# <h1 style='background:#CCCCCC; border:0; color:black'><center><span style=\"color: royalblue;\"><span style=\"color: royalblue;\">Intro<\/span><\/span><\/center><\/h1> \nWelcome to the [facial expression competition](https:\/\/www.kaggle.com\/c\/challenges-in-representation-learning-facial-expression-recognition-challenge).\n\n\n\n<table>\n    <tr>\n        <td><img src=\"https:\/\/i.ibb.co\/B394D0t\/12.png\" width=\"100%\" height=\"100%\"><\/td>\n        <td><img src=\"https:\/\/i.ibb.co\/5xV8MZj\/40.png\" width=\"100%\" height=\"100%\"><\/td>\n        <td><img src=\"https:\/\/i.ibb.co\/bFgXc43\/19.png\" width=\"100%\" height=\"100%\"><\/td>\n    <\/tr>\n<\/table>\nThe data consists of 48x48 pixel grayscale images of faces. The faces have been automatically registered so that the face is more or less centered and occupies about the same amount of space in each image. The task is to categorize each face based on the emotion shown in the facial expression in to one of seven categories:\n\n| categorie  | emotion  |\n|:---:|:---|\n| 0  | Angry  |\n| 1  |  Disgust |\n| 2  |  Fear |\n| 3  |  Happy |\n| 4  |  Sad |\n| 5  |  Surprise |\n| 6  | Neutral |\n\nWe define a simple CNN model and compare the predicted results with ge given labels.\n\nDo you need an idea to deploy your project? Look [here](https:\/\/www.kaggle.com\/drcapa\/facial-expression-telegram-bot).\n\n<font size=\"4\"><span style=\"color: royalblue;\">Please vote the notebook up if it is helpful.<\/span><\/font>\nFeel free to leave a comment above the notebook. Thank you. ","caabf4ae":"# <h1 style='background:#CCCCCC; border:0; color:black'><center><span style=\"color: royalblue;\"><span style=\"color: royalblue;\">Analyse Wrong Prediction<\/span><\/span><\/center><\/h1> \nThe accuracy score is about 54% on the test set. So it is obvious to take focus on the wrong predictions. We want to extract details to improve the model.","53e05f25":"# <h1 style='background:#CCCCCC; border:0; color:black'><center><span style=\"color: royalblue;\"><span style=\"color: royalblue;\">Overview<\/span><\/span><\/center><\/h1> ","29af2047":"# <h1 style='background:#CCCCCC; border:0; color:black'><center><span style=\"color: royalblue;\"><span style=\"color: royalblue;\">Analyse Convergence<\/span><\/span><\/center><\/h1> ","2a08c81b":"## Disgust","2777a10b":"## Angry","6d8a611b":"## Happy","a271afb4":"# <h1 style='background:#CCCCCC; border:0; color:black'><center><span style=\"color: royalblue;\"><span style=\"color: royalblue;\">Path<\/span><\/span><\/center><\/h1> \nDefine the input path and show all files.","adb2f6d3":"# <h1 style='background:#CCCCCC; border:0; color:black'><center><span style=\"color: royalblue;\">Libraries<\/span><\/center><\/h1> \nWe load some standard libraries and packages of sklearn and keras.","b1ff93dc":"# <h1 style='background:#CCCCCC; border:0; color:black'><center><span style=\"color: royalblue;\"><span style=\"color: royalblue;\">Prepare Data<\/span><\/span><\/center><\/h1> ","8d8eb761":"## Surprise","a421c925":"\n## Sad","5d0ba0f4":"# <h1 style='background:#CCCCCC; border:0; color:black'><center><span style=\"color: royalblue;\"><span style=\"color: royalblue;\">Class Weights<\/span><\/span><\/center><\/h1> \nCalculate the class weights of the label distribution:"}}