{"cell_type":{"bda018f6":"code","dc06fd4a":"code","61ef8e94":"code","f038155d":"code","3114f035":"code","2f49126f":"code","61e18490":"code","88609c89":"code","0d9da985":"code","0ce595c8":"code","1ba6c072":"code","ba747434":"code","387614d7":"code","712084d3":"code","da547527":"code","388c2930":"code","2607f407":"code","4bfdc6fa":"code","f4165062":"code","6405cbfa":"code","5f954381":"code","57b5eaec":"code","fa9efba4":"code","a13e0e2f":"code","ed7eef78":"code","4c68943a":"code","8b726ca5":"code","91ed285a":"code","d32f4f6e":"code","5c184a20":"code","cf0005cb":"code","9385ce39":"code","605008f3":"code","d9bd989c":"code","791fffad":"markdown","1745b694":"markdown","efc7eb86":"markdown","3f57def8":"markdown","ae3a0c57":"markdown","6d1fcf3e":"markdown","27ae19d1":"markdown","bce88b60":"markdown","c5cb924b":"markdown","1eca471d":"markdown","f18e6ff4":"markdown","9a03283d":"markdown","2114716a":"markdown","a48d2a85":"markdown","0d9c1ef5":"markdown","275f258a":"markdown","2ab0356a":"markdown","f5e425bd":"markdown","6c36e43c":"markdown"},"source":{"bda018f6":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nleetcode = pd.read_csv(\"\/kaggle\/input\/leetcode\/leetcode.csv\")\nleetcode.head()","dc06fd4a":"len(leetcode)","61ef8e94":"sns.countplot(leetcode[\"isPaid\"]);\n","f038155d":"sns.countplot(leetcode[\"difficulty\"]);","3114f035":"sns.countplot(\"difficulty\", hue='isPaid', data=leetcode);","2f49126f":"leetcode[\"accept_rate\"] = leetcode['total Accepted'] \/ leetcode['total Submitted']\nleetcode.head()","61e18490":"leetcode.groupby(\"difficulty\")\\\n.accept_rate.mean().plot(kind=\"bar\")","88609c89":"leetcode.groupby(\"difficulty\")['total Submitted']\\\n.mean().plot(kind=\"bar\")","0d9da985":"leetcode.groupby(\"difficulty\")['total Accepted']\\\n.mean().plot(kind=\"bar\")","0ce595c8":"leetcode[\"title_len\"] = leetcode[\"title\"].apply(len)\nleetcode.head()","1ba6c072":"leetcode.groupby(\"difficulty\")['title_len']\\\n.mean().plot(kind=\"bar\")","ba747434":"leetcode.describe()","387614d7":"from catboost import CatBoostClassifier","712084d3":"from sklearn.model_selection import train_test_split\ntrain, val = train_test_split(leetcode, test_size=0.1, random_state=42)","da547527":"train.head()","388c2930":"featrue_columns = [\"total Accepted\", 'total Submitted', \"accept_rate\", \"title_len\", \"isPaid\"]\nlabel_column = 'difficulty'\ncat_params = {\n    \"verbose\": 1000,\n    \"learning_rate\": 0.01, \n    \"od_wait\": 1000,\n    \"l2_leaf_reg\": 10,\n    \"iterations\": 10000,\n    \"eval_metric\": \"Accuracy\"\n}\nmodel = CatBoostClassifier(**cat_params)\nmodel.fit(train[featrue_columns], train[label_column], eval_set=(val[featrue_columns], val[label_column]))","2607f407":"import tensorflow as tf\nfrom tensorflow import keras","4bfdc6fa":"vocab_size = 1500\nsequence_length = 32\nvectorizer = keras.layers.TextVectorization(\n    max_tokens=vocab_size,\n    output_sequence_length=sequence_length,\n    standardize=\"lower_and_strip_punctuation\",\n)\nvectorizer.adapt(leetcode[\"title\"]);","f4165062":"vectorizer([\"hello world\"])","6405cbfa":"len(vectorizer.get_vocabulary())","5f954381":"train_features = train[featrue_columns]\ntrain_features.head()","57b5eaec":"val_features = val[featrue_columns]\nval_features.head()","fa9efba4":"for column in featrue_columns:\n    if column == \"isPaid\":\n        train_features.loc[:, column] =  train_features.loc[:, column].apply(lambda item: 1.0 if item == True else 0.0)\n        val_features.loc[:, column] =  val_features.loc[:, column].apply(lambda item: 1.0 if item == True else 0.0)\n    else:\n        mean_value = train_features[column].mean()\n        std_value = train_features[column].std()\n        train_features.loc[:, column] = (train_features[column] - mean_value) \/ std_value\n        val_features.loc[:, column] = (val_features[column] - mean_value) \/ std_value","a13e0e2f":"train_features.head()","ed7eef78":"val_features.head()","4c68943a":"\ndef get_model():\n    tabular_inputs = keras.Input((val_features.shape[1], ))\n    text_inputs = keras.Input((1, ), dtype=\"string\")\n    tabular_model = keras.Sequential([\n        tabular_inputs,\n        keras.layers.Dense(32, activation=\"relu\"),\n        keras.layers.Dense(32, activation=\"relu\")\n    ])\n    text_model = keras.Sequential([\n        text_inputs,\n        vectorizer,\n        keras.layers.Embedding(vocab_size, 64),\n        keras.layers.LSTM(16, recurrent_dropout=0.2, return_sequences=True),\n        keras.layers.LSTM(16, recurrent_dropout=0.2),\n        keras.layers.Dense(16, activation=\"relu\"),\n    ])\n    x = keras.layers.Concatenate()([tabular_model.output, text_model.output])\n    x = keras.layers.Dense(64, activation=\"relu\")(x)\n    x = keras.layers.Dropout(0.3)(x)\n    output =  keras.layers.Dense(3, activation=\"softmax\")(x)\n    model = keras.Model(inputs=[tabular_inputs, text_inputs], outputs=[output])\n    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n    return model, tabular_model, text_model","8b726ca5":"model, _, text_model  = get_model()\nmodel.summary()","91ed285a":"train_target = pd.get_dummies(train[\"difficulty\"])\ntrain_target.head()","d32f4f6e":"val_target = pd.get_dummies(val[\"difficulty\"])\nval_target.head()","5c184a20":"model_path = \"model.tf\"\ncheckpoint = keras.callbacks.ModelCheckpoint(model_path, monitor=\"val_accuracy\", save_best_only=True, save_weights_only=True) \nmodel.fit(\n    x=[train_features[featrue_columns], train[\"title\"]], y=train_target, epochs=10, \n    validation_data=([val_features[featrue_columns], val[\"title\"]], val_target),\n    callbacks=[checkpoint]\n)","cf0005cb":"model.load_weights(model_path)","9385ce39":"train_text_vector = text_model(train[\"title\"])\nval_text_vector = text_model(val[\"title\"])\ntrain_text_vector.shape, val_text_vector.shape","605008f3":"new_train_features = np.concatenate([train_text_vector.numpy(), train_features], axis=-1)\nnew_val_features = np.concatenate([val_text_vector.numpy(), val_features], axis=-1)\nnew_val_features.shape, new_train_features.shape","d9bd989c":"model = CatBoostClassifier(**cat_params)\nmodel.fit(new_train_features, train[label_column], eval_set=(new_val_features, val[label_column]))","791fffad":"### Average Submission for different difficulties","1745b694":"### Accept rate for different difficulties","efc7eb86":"### Build the Model","3f57def8":"## Leetcode Analysis","ae3a0c57":"## How many questions is paid?","6d1fcf3e":"### Text Vectorization","27ae19d1":"### Average Accepted Submission for different difficulities","bce88b60":"### Using Tensorflow","c5cb924b":"### Title Length for different difficulities","1eca471d":"## Modeling\nNow I want to build a Model to predict difficulty based on other information such as total Accepted submissions and total Submitted submissions and accept rate and so on.","f18e6ff4":"## Training","9a03283d":"### Using Catboot","2114716a":"## Difficulty of Leetcode","a48d2a85":"Recently I am applying for job in some large company. Algorithm Questions is an essential part of the interview. Leetcode is the most famous platform for progrmamers practicing Algorithms, some how less information is found in Kaggle. So I would like to have an analysis LeetCode quetions so it may help me better prepare for the interview.","0d9c1ef5":"### Tabular data preprocessing","275f258a":"### Total Number of  Questions","2ab0356a":"### Calculate Title Length","f5e425bd":"## Calcuate Accept rate","6c36e43c":"## Training CatBoost with Word Vector Information"}}