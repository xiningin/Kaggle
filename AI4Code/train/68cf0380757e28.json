{"cell_type":{"99a5393a":"code","465c055e":"code","fb27525a":"code","af15e7be":"code","a28e6867":"code","05eb1aa9":"code","03adeebd":"code","e27087cb":"code","bcbc801c":"code","076afb25":"code","bff7e6ec":"code","4b14cd11":"code","74a86915":"code","e4b95158":"code","b8231891":"code","cfcb0871":"markdown","f01b15b9":"markdown","32fc61ec":"markdown","68901656":"markdown","ae8a97ac":"markdown","d464faae":"markdown","67c0bca8":"markdown"},"source":{"99a5393a":"import cudf\n\nimport pandas as pd\nimport numpy as np\nimport random\nimport time\nimport os\nimport gc\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nimport xgboost as xgb\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.simplefilter('ignore')","465c055e":"N_SPLITS = 5\nN_ESTIMATORS = 20000\nEARLY_STOPPING_ROUNDS = 200\nVERBOSE = 1000\nSEED = 42\n\nCURRENT_PATH = os.getcwd().split(\"\/\")[-1]","fb27525a":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    \nseed_everything(SEED)","af15e7be":"%%time\n\ntrain = cudf.read_csv('..\/input\/tabular-playground-series-oct-2021\/train.csv')\ntest = cudf.read_csv('..\/input\/tabular-playground-series-oct-2021\/test.csv')\ntrain = train[train.columns[1:]]\ntest = test[test.columns[1:]]\n\nTARGET = 'target'","a28e6867":"features = [col for col in train.columns if 'f' in col]\n\ncont_features =[]\ndisc_features =[]\n\nfor col in features:\n    if train[col].dtype=='float64':\n        cont_features.append(col)\n    else:\n        disc_features.append(col)","05eb1aa9":"train[cont_features] = train[cont_features].astype('float32')\ntrain[disc_features] = train[disc_features].astype('uint8')\n\ntest[cont_features] = test[cont_features].astype('float32')\ntest[disc_features] = test[disc_features].astype('uint8')","03adeebd":"cols = disc_features.copy()\ncols.remove('f22')\ncols.remove('f43')\ntrain['disc_sum'] = train[cols].sum(axis=1)\ntest['disc_sum'] = test[cols].sum(axis=1)\n\ndisc_features += ['disc_sum']","e27087cb":"cols_ovr = [f'{col}_ovr' for col in cont_features]\ntrain[cols_ovr] = (train[cont_features] > train[cont_features].mean()).astype('uint8')\ntest[cols_ovr] = (test[cont_features] > test[cont_features].mean()).astype('uint8')\n\ndisc_features += cols_ovr","bcbc801c":"train = train.to_pandas()\ntest = test.to_pandas()\n\nfeatures = disc_features + cont_features","076afb25":"display(train.info())\ndisplay(train[features].head())","bff7e6ec":"display(test.info())\ndisplay(test[features].head())","4b14cd11":"xgb_params = {\n    'objective': 'binary:logistic',\n    'learning_rate': 8e-3,\n    'seed': SEED,\n    'subsample': 0.6,\n    'colsample_bylevel': 0.9,\n    'colsample_bytree': 0.4,\n    'n_estimators': N_ESTIMATORS,\n    'max_depth': 8,\n    'alpha': 64,\n    'lambda': 32,\n    'min_child_weight': 8,\n    'importance_type': 'total_gain',\n    'tree_method': 'gpu_hist',\n    'predictor': 'gpu_predictor',\n}","74a86915":"xgb_oof = np.zeros(train.shape[0])\nxgb_pred = np.zeros(test.shape[0])\nxgb_importances = pd.DataFrame()\n\nskf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n\nfor fold, (trn_idx, val_idx) in enumerate(skf.split(X=train, y=train[TARGET])):\n    print(f\"===== fold {fold} =====\")\n    X_train, y_train = train[features].iloc[trn_idx], train[TARGET].iloc[trn_idx]\n    X_valid, y_valid = train[features].iloc[val_idx], train[TARGET].iloc[val_idx]\n    X_test = test[features]\n    \n    start = time.time()\n    model = xgb.XGBClassifier(**xgb_params)\n    model.fit(\n        X_train, \n        y_train,\n        eval_set=[(X_valid, y_valid)],\n        eval_metric='auc',\n        early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n        verbose=VERBOSE\n    )\n\n    fi_tmp = pd.DataFrame()\n    fi_tmp['feature'] = X_train.columns\n    fi_tmp['importance'] = model.feature_importances_\n    fi_tmp['fold'] = fold\n    fi_tmp['seed'] = SEED\n    xgb_importances = xgb_importances.append(fi_tmp)\n\n    xgb_oof[val_idx] = model.predict_proba(X_valid)[:, -1]\n    xgb_pred += model.predict_proba(X_test)[:, -1] \/ N_SPLITS\n\n    elapsed = time.time() - start\n    auc = roc_auc_score(y_valid, xgb_oof[val_idx])\n    print(f\"fold {fold} - xgb auc: {auc:.6f}, elapsed time: {elapsed:.2f}sec\\n\")\n        \nprint(f\"oof xgb auc = {roc_auc_score(train[TARGET], xgb_oof)}\")\n\nnp.save(\"xgb_oof.npy\", xgb_oof)\nnp.save(\"xgb_pred.npy\", xgb_pred)","e4b95158":"order = list(xgb_importances.groupby('feature').mean().sort_values('importance', ascending=False).index)\n\nfig = plt.figure(figsize=(16, 32), tight_layout=True)\nsns.barplot(x=\"importance\", y=\"feature\", data=xgb_importances.groupby('feature').mean().reset_index(), order=order)\nplt.title(\"XGBoost feature importances\")","b8231891":"submission = pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/sample_submission.csv')\n\nsubmission[TARGET] = xgb_pred\nsubmission.to_csv(f\"{CURRENT_PATH}_submission.csv\", index=False)\nsubmission","cfcb0871":"# Submission\n---","f01b15b9":"# Parameters\n---","32fc61ec":"# Datasets\n---","68901656":"# Libraries\n---","ae8a97ac":"## Cross validation","d464faae":"# XGBoost\n---","67c0bca8":"## Feature importance"}}