{"cell_type":{"06b63185":"code","c9811958":"code","7a41f1da":"code","36ee0b43":"code","b96dbbb8":"code","f311422b":"code","164bb09c":"code","74b9d505":"code","3c00d63a":"code","d2af44df":"code","a62106e8":"code","65e85592":"code","ed0f959f":"code","c322d7ee":"code","f09868e4":"code","d0d7d15d":"code","5b56e058":"code","ab8ce985":"code","b0271d86":"code","5a265948":"code","c3302b01":"code","55c43522":"code","b93f5991":"code","69de4a7f":"markdown","8c662e97":"markdown","72e947ee":"markdown","ce79855f":"markdown","88747df3":"markdown","7050cbfc":"markdown"},"source":{"06b63185":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c9811958":"import zipfile\nimport random\nimport shutil\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n\nfrom shutil import copyfile\nfrom os import getcwd","7a41f1da":"# This code block unzips the full Cats-v-Dogs dataset to \/tmp\n# which will create a tmp\/PetImages directory containing subdirectories\n# called 'Cat' and 'Dog' (that's how the original researchers structured it)\npath_cats_and_dogs = \"\/kaggle\/input\/dogs-vs-cats\/train.zip\"\n\nlocal_zip = path_cats_and_dogs\nzip_ref = zipfile.ZipFile(local_zip, 'r')\nzip_ref.extractall()\nzip_ref.close()","36ee0b43":"path_cats_and_dogs = \"\/kaggle\/input\/dogs-vs-cats\/test1.zip\"\n\nlocal_zip = path_cats_and_dogs\nzip_ref = zipfile.ZipFile(local_zip, 'r')\nzip_ref.extractall()\nzip_ref.close()","b96dbbb8":"filenames = os.listdir(\"\/kaggle\/working\/train\")","f311422b":"len(filenames)","164bb09c":"base_dir = '\/kaggle\/working\/'\nsource_dir = '\/kaggle\/working\/train\/'\n\n\n\ncat_dir = os.path.join(base_dir, 'cat')\nos.mkdir(cat_dir)\ndog_dir = os.path.join(base_dir, 'dog')\nos.mkdir(dog_dir)\n\ntrain_dir = os.path.join(base_dir, 'train1')\nvalidation_dir = os.path.join(base_dir, 'validation1')\nos.mkdir(train_dir)\nos.mkdir(validation_dir)\n\n# Directory with our training cat\/dog pictures\ntrain_cats_dir = os.path.join(train_dir, 'cats')\ntrain_dogs_dir = os.path.join(train_dir, 'dogs')\nos.mkdir(train_cats_dir)\nos.mkdir(train_dogs_dir)\n\n\n# Directory with our validation cat\/dog pictures\nvalidation_cats_dir = os.path.join(validation_dir, 'cats')\nvalidation_dogs_dir = os.path.join(validation_dir, 'dogs')\nos.mkdir(validation_cats_dir)\nos.mkdir(validation_dogs_dir)\n\n","74b9d505":"for c in filenames:\n    category = c.split('.')[0]\n    if category == \"cat\":\n        temp_source = source_dir +'\/'+ c\n        temp_dest   = cat_dir +'\/'+ c\n        copyfile(temp_source,temp_dest)\n    else:\n        temp_source = source_dir +'\/' + c\n        temp_dest   = dog_dir +'\/'+ c\n        copyfile(temp_source,temp_dest)\n\ndef split_data(SOURCE, TRAINING, VALIDATION, SPLIT_SIZE):\n    f = os.listdir(SOURCE)\n    train_size   =  int(SPLIT_SIZE * len(f))\n    test_size    =  int(len(f) - train_size)\n    final_files  =  random.sample(f,len(f))\n    train_files  =  final_files[0:train_size] \n    test_files   =  final_files[-test_size:]\n    \n    for i in train_files:\n        temp_source = SOURCE +'\/'+ i\n        temp_dest   = TRAINING +'\/'+ i\n        copyfile(temp_source,temp_dest)\n        \n    for j in test_files:\n        temp_source = SOURCE + '\/'+ j\n        temp_dest   = VALIDATION +'\/'+ j\n        copyfile(temp_source,temp_dest)\n        \n\nsplit_size = .9\nsplit_data(cat_dir, train_cats_dir, validation_cats_dir, split_size)\nsplit_data(dog_dir, train_dogs_dir, validation_dogs_dir, split_size)\n","3c00d63a":"test_dir ='\/kaggle\/working\/test1'\nprint(\"Total images in cat directory\" , len(os.listdir(cat_dir)))\nprint(\"Total images in dog directory\" , len(os.listdir(dog_dir)))\nprint(\"Total images in train\/cat directory\" , len(os.listdir(train_cats_dir)))\nprint(\"Total images in train\/dog directory\" , len(os.listdir(train_dogs_dir)))\nprint(\"Total images in validation\/cat directory\" , len(os.listdir(validation_cats_dir)))\nprint(\"Total images in validation\/dog directory\" , len(os.listdir(validation_dogs_dir)))\nprint(\"Total images in test directory\" , len(os.listdir(test_dir)))\n","d2af44df":"train_cat_fnames = os.listdir( train_cats_dir )\ntrain_dog_fnames = os.listdir( train_dogs_dir )\ntest_names = os.listdir(test_dir)\n\nprint(train_cat_fnames[:10])\nprint(train_dog_fnames[:10])","a62106e8":"%matplotlib inline\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n\n# Parameters for our graph; we'll output images in a 4x4 configuration\nnrows = 4\nncols = 4\n\npic_index = 0 # Index for iterating over imag","65e85592":"# Set up matplotlib fig, and size it to fit 4x4 pics\nfig = plt.gcf()\nfig.set_size_inches(ncols*4, nrows*4)\n\npic_index+=8\n\nnext_cat_pix = [os.path.join(train_cats_dir, fname) \n                for fname in train_cat_fnames[ pic_index-8:pic_index] \n              ]\n\nnext_test_pix = [os.path.join(test_dir, fname) \n                for fname in test_names[ pic_index-8:pic_index]\n               ]\n\nfor i, img_path in enumerate(next_cat_pix+next_test_pix):\n  # Set up subplot; subplot indices start at 1\n  sp = plt.subplot(nrows, ncols, i + 1)\n  sp.axis('Off') # Don't show axes (or gridlines)\n\n  img = mpimg.imread(img_path)\n  plt.imshow(img)\n\nplt.show()","ed0f959f":"model = tf.keras.models.Sequential([\n    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n   # tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.BatchNormalization(),\n    \n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    #tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.MaxPooling2D(2,2), \n    tf.keras.layers.BatchNormalization(),\n\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'), \n    #tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.BatchNormalization(),\n    \n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'), \n    #tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.BatchNormalization(),\n          \n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(), \n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dropout(0.3),\n    \n    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n    tf.keras.layers.Dense(1, activation='sigmoid')  \n])","c322d7ee":"from tensorflow.keras.optimizers import RMSprop\n\nmodel.compile(optimizer=RMSprop(learning_rate=0.0001),\n              loss='binary_crossentropy',\n              metrics = ['accuracy'])","f09868e4":"train_datagen = ImageDataGenerator(\n      rescale=1.\/255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.1,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,  # This is the source directory for training images\n        target_size=(150, 150),  # All images will be resized to 150x150\n        batch_size=30,\n        # Since we use binary_crossentropy loss, we need binary labels\n        class_mode='binary')\n\n\nvalidation_datagen = ImageDataGenerator(rescale=1\/255)\n\n# NOTE: YOU MUST USE A BACTH SIZE OF 10 (batch_size=10) FOR THE \n# VALIDATION GENERATOR.\nvalidation_generator = validation_datagen.flow_from_directory(\n       validation_dir,  # This is the source directory for training images\n        target_size=(150, 150),  # All images will be resized to 150x150\n        batch_size=30,\n        # Since we use binary_crossentropy loss, we need binary labels\n        class_mode='binary')","d0d7d15d":"history = model.fit_generator(train_generator,\n                              epochs=30,\n                              verbose=1,\n                              validation_data=validation_generator)\n","5b56e058":"def plot_acc_loss():\n    \n#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\n    acc      = history.history[     'accuracy' ]\n    val_acc  = history.history[ 'val_accuracy' ]\n    loss     = history.history[    'loss' ]\n    val_loss = history.history['val_loss' ]\n\n    epochs   = range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\n    plt.plot  ( epochs,     acc )\n    plt.plot  ( epochs, val_acc )\n    plt.title ('Training and validation accuracy')\n    plt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\n    plt.plot  ( epochs,     loss )\n    plt.plot  ( epochs, val_loss )\n    plt.title ('Training and validation loss'   )","ab8ce985":"plot_acc_loss()","b0271d86":"test_files = os.listdir(\"\/kaggle\/working\/test1\")\ntest_df = pd.DataFrame({'filename' : test_files})    \nsamples = test_df.shape[0]","5a265948":"test_data = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_data.flow_from_dataframe(\n    test_df, \n    \".\/test1\/\", \n    x_col='filename',\n    y_col=None,\n    class_mode=None,\n    target_size=[150,150],\n    batch_size=30,\n    shuffle=False)\n\n\n","c3302b01":"predict = model.predict_generator(test_generator, steps=np.ceil(samples\/30))","55c43522":"test_df['category'] = np.argmax(predict, axis=-1)\ntest_df['category'] = test_df['category'].replace({ 'dog': 1, 'cat': 0 })","b93f5991":"submission_df = test_df.copy()\nsubmission_df['id'] = submission_df['filename'].str.split('.').str[0]\nsubmission_df['label'] = submission_df['category']\nsubmission_df.drop(['filename', 'category'], axis=1, inplace=True)\nsubmission_df.to_csv('submission.csv', index=False)","69de4a7f":"***Check the names of files in destination folders randomly *******","8c662e97":"**Move all the files from source to their respective training and validation folder**","72e947ee":"**Modelling Starts**\n\nSimple VGG3 baseline models give about 75-80% accuracy. After some iterations I have done VGG5 model with dropouts. ","ce79855f":"***Check the number of files in each directory***","88747df3":"**Setup some code to view the pictures using matplotlib**","7050cbfc":"**Make a proper directory structure for splitting training and validation images. \nThis will also help in using Keras Image generators for augmentation and preprocessing tasks**"}}