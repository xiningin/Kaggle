{"cell_type":{"ec9d9f06":"code","5628f8c9":"code","890c5d9d":"code","a21828e2":"code","e6fc00fe":"code","b5e8d321":"code","5b767fdf":"code","9c520528":"code","08def11a":"code","c0c32de7":"code","4f8115d4":"code","454a1703":"code","9bb08fea":"code","3678a79f":"code","3e885604":"code","5296a1fd":"code","4f403bd8":"code","db05251d":"code","d2ade1fa":"code","3e6361bd":"code","e12f0a02":"code","bc4e4592":"code","1eba6e40":"code","1e311819":"code","7aade11d":"markdown","b7eaf1ac":"markdown","4dfbf789":"markdown","c256a332":"markdown","01dc626e":"markdown","3004cc0d":"markdown","255925bd":"markdown","089937ba":"markdown","b2502adc":"markdown","1dcf2748":"markdown","8466b124":"markdown"},"source":{"ec9d9f06":"# importing necessary libraries \nimport numpy as np\nimport pandas as pd\nimport math\n\nfrom sklearn.metrics import mean_squared_error\nfrom shapely.geometry import Point\nimport os\nimport tensorflow as tf\nfrom tqdm import tqdm\nfrom sklearn.utils import shuffle\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\nfrom datetime import timedelta\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\n\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom sklearn.preprocessing import MinMaxScaler\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","5628f8c9":"# Importing Data\nData = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-2\/train.csv\")\nData.head()","890c5d9d":"Data.shape","a21828e2":"Data.Date.value_counts()","e6fc00fe":"# check null values in dataset\nData.isnull().sum()","b5e8d321":"# Checking number of data records under each country\nData.Country_Region.value_counts()","5b767fdf":"countries = Data['Country_Region'].unique()\nprint(f'{len(countries)} countries are in dataset:\\n{countries}')","9c520528":"group_date_max = Data.Date.value_counts().max()\ngroup_date_min = Data.Date.value_counts().min()\nprint(group_date_max,group_date_min)","08def11a":"min_date = Data.Date.min()\nmax_date = Data.Date.max()\nprint(min_date,max_date)","c0c32de7":"Data.describe()","4f8115d4":"confirmed_total_date_noChina = Data[Data['Country_Region']!='China'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_noChina = Data[Data['Country_Region']!='China'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_noChina = confirmed_total_date_noChina.join(fatalities_total_date_noChina)\n\nfig, (ax1) = plt.subplots(1, figsize=(10,5))\ntotal_date_noChina.plot(ax=ax1)\nax1.set_title(\"Global confirmed cases excluding China\", size=13)\nax1.set_ylabel(\"Number of cases\", size=13)\nax1.set_xlabel(\"Date\", size=13)\n","454a1703":"total_date_noChina.ConfirmedCases.min()","9bb08fea":"total_date_noChina","3678a79f":"total_date_noChina = total_date_noChina.sort_values('Date',ascending=True)\n\ntotal_date_noChina","3e885604":"# creating input data \ninput_data = total_date_noChina.iloc[:,0:1].values\n# getting total record count to create train and test data test\nrecords = total_date_noChina.count()\n# train data set which is 3 less than total data set\nrecords = records[0] - 7\ntrain = total_date_noChina.iloc[0:records,0:1].values\n\n# test data set with 10 records\ntest = total_date_noChina.iloc[records:,0:1].values\n#print(input_data.shape)\nprint(input_data.shape,train.shape,test.shape)","5296a1fd":"# multi-step data preparation\nfrom numpy import array\n# split a univariate sequence into samples\ndef split_sequence(sequence, n_steps_in, n_steps_out):\n    X, y1 = list(), list()\n    for i in range(len(sequence)):\n    # find the end of this pattern\n        end_ix = i + n_steps_in\n        out_end_ix = end_ix + n_steps_out\n    # check if we are beyond the sequence\n        if out_end_ix > len(sequence):\n            break\n        # gather input and output parts of the pattern\n        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n        X.append(seq_x)\n        y1.append(seq_y)\n    return array(X), array(y1)\n\n# define input sequence\nraw_seq = train\n# choose a number of time steps\nn_steps_in, n_steps_out = 3, 7\n# split into samples\nX, y1 = split_sequence(raw_seq, n_steps_in, n_steps_out)\n# summarize the data\nn_features = 1\nX = X.reshape((X.shape[0], X.shape[1], n_features))\ny1 = y1.reshape(y1.shape[0], y1.shape[1])","4f403bd8":"# Model Building\n\nmodel = Sequential()\nmodel.add(LSTM(50, activation='relu', return_sequences=True, input_shape=((X.shape[1],1))))\nmodel.add(LSTM(50, activation='relu', return_sequences=True,))\nmodel.add(LSTM(50, activation='relu'))\nmodel.add(Dense(n_steps_out))\nmodel.compile(optimizer='adam', loss='mse')\nmodel.fit(X, y1, epochs=1000, batch_size = 30, verbose = 0)","db05251d":"# Model testing to forcast 7 consecutive day wich will be compared with test data actuals\nx_input = train[(records - n_steps_in):records,0:1]\nx_input = x_input.reshape((1, n_steps_in, n_features))\ntest_predicted = model.predict(x_input, verbose=0)\ntest_predicted = test_predicted.reshape(n_steps_out,)\ntest_predicted1 = pd.Series(test_predicted)\ntest = test.reshape(n_steps_out,)\ntest1 = pd.Series(test)\npd.concat([test1,test_predicted1], axis=1)\n","d2ade1fa":"plt.plot(test, color= 'red', label = 'test_data')\nplt.plot(test_predicted, color= 'blue', label = 'predicted_test_data')\nplt.title('Test Data Forecast')\nplt.xlabel('time')\nplt.ylabel('Confirmed_Cases')\nplt.legend()","3e6361bd":"# Forcast Confirmed Cases for 7 consecutive days\n#x_input = input_data[-n_steps_in:]\nx_input = test[-3:]\nx_input = x_input.reshape((1, n_steps_in, n_features))\n\nforecast = model.predict(x_input, verbose=0)\n","e12f0a02":"#forecast = test_predicted.reshape(n_steps_in,1)\nforecast","bc4e4592":"# Plotting Forecast Data\nmaximum_date = Data.Date.max()\n","1eba6e40":"date = pd.date_range(maximum_date, periods=8, closed='right')\ndate","1e311819":"date = pd.Series(date)\nforecast1 = forecast.reshape(n_steps_out,)\nforecast2 = pd.Series(forecast1)\nforcast_data = pd.concat([date,forecast2], axis=1)\nforcast_data.columns = ['Date','Forecast_Corfirmed_Cases']\nplt.figure(figsize=(10,5))\nplt.plot(date,forecast2)\nplt.title('7 Days Forecast')\nplt.xlabel('Time')\nplt.ylabel('Confirmed_Cases')\nprint(forcast_data)","7aade11d":"It is seen above that only Province_State has null values","b7eaf1ac":"It is seen above that US and China has majority of the data records as it has data for various Province_State","4dfbf789":"# Great!! the plot shows predicted values are very  close to actual values","c256a332":"Plotting the Forcast for Test Data","01dc626e":"Let's Forecast Confirmed Cases for next 3 days from the input data","3004cc0d":"# 2. Model Building using multistep LSTM","255925bd":"# 1. Data Preparation and Understanding","089937ba":"Following code creates input data which is full data set, train data which 10 less than total dataset, test data has 10 records","b2502adc":"Following Code exclude China and group by on Date so create a dataset for global forcast.","1dcf2748":"### If you found this notebook helpful, please give it an upvote. It will be greatly appreciated!","8466b124":"# Covid-19 Global Forecasting using LSTM\n\nThe goal of notebook is to forecast Confirmed Cases globallly using LSTM modellimg technqiues.\nThe architechture is very simple to implement and gives close forecast to actuals"}}