{"cell_type":{"18e9afbf":"code","7bb69321":"code","3a1453ba":"code","a47a92f2":"code","f9735494":"code","3677fcfb":"code","d963f783":"code","d5430e65":"code","773ba85b":"code","3747e6a9":"code","d19b7271":"code","470ef2b4":"code","9b58a5d8":"code","eacaa87d":"code","de614f4c":"code","85dbafe7":"code","c21d3bbc":"code","ff524cf8":"markdown"},"source":{"18e9afbf":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","7bb69321":"audi_df =  pd.read_csv(\"..\/input\/used-car-dataset-ford-and-mercedes\/audi.csv\")\nbmw_df = pd.read_csv(\"..\/input\/used-car-dataset-ford-and-mercedes\/bmw.csv\")\ntoyota_df = pd.read_csv(\"..\/input\/used-car-dataset-ford-and-mercedes\/toyota.csv\")\nprint(audi_df.head(5))\nprint(\"----------------------------------------\")\nprint(bmw_df.head(5))\nprint(\"----------------------------------------\")\nprint(toyota_df.head(5))","3a1453ba":"df = pd.concat([audi_df, bmw_df, toyota_df], axis=0)\ndf.describe()","a47a92f2":"df.info()","f9735494":"corr = df.corr(method=\"spearman\")\nax = sns.heatmap(corr, square=True, linewidth=1, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\nax.figure.set_size_inches(14, 10)\nplt.show()","3677fcfb":"print(df[\"transmission\"].value_counts())\nprint(df[\"fuelType\"].value_counts())\ntop_10_models = df[\"model\"].value_counts()[:10].reset_index()\ncar_models = []\nfor car_model in top_10_models[\"index\"]:\n    car_models.append(car_model)\n    \nprint(car_models)","d963f783":"model_df = df[df['model'].isin(car_models)]","d5430e65":"# Check if there are correlations between the 3 categorical columns with price\nplt.figure(figsize=(30,10))\nplt.subplot(1,3,1)\nsns.violinplot(x=\"transmission\", y=\"price\", data=df, scale=\"area\", inner=\"quartile\")\nplt.title(\"Price vs Transmission\")\n\nplt.subplot(1,3,2)\nsns.violinplot(x=\"fuelType\", y=\"price\", data=df, scale=\"area\", inner=\"quartile\")\nplt.title(\"Price vs Fuel\")\n\nplt.subplot(1,3,3)\nsns.violinplot(x=\"model\", y=\"price\", data=model_df)\nplt.title(\"Price vs Top 10 Sold Model\")\nplt.show()","773ba85b":"from sklearn.preprocessing import OneHotEncoder\n\ncat_cols = [\"model\", \"transmission\", \"fuelType\"]\nOHE = OneHotEncoder(handle_unknown = \"ignore\", sparse = False)\ndf_OHE = pd.DataFrame(OHE.fit_transform(df[cat_cols]))\ndf_OHE.index = df.index\ndf_num = df.drop(cat_cols, axis=1)\ndf_concat = pd.concat([df_num, df_OHE], axis=1)","3747e6a9":"df_concat.head(5)","d19b7271":"drop_cols = [\"price\"]\nX = df_concat.drop(drop_cols, axis=1)\ny = df['price']","470ef2b4":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)","9b58a5d8":"from sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nimport xgboost as xgb\n\nlr_model = LinearRegression()\nlr_model.fit(X_train, y_train)\npred = lr_model.predict(X_val)\nerror = mae(pred, y_val)\nprint('MAE of Linear Regression is: {:,.0f}'.format(error))\n\ndt_model = DecisionTreeRegressor(max_leaf_nodes=900, random_state=1)\ndt_model.fit(X_train, y_train)\npred = dt_model.predict(X_val)\nerror = mae(pred, y_val)\nprint('MAE of Decision Tree is: {:,.0f}'.format(error))\n\nrf_model = RandomForestRegressor()\nrf_model.fit(X_train, y_train)\npred = rf_model.predict(X_val)\nerror = mae(pred, y_val)\nprint('MAE of Random Forest is: {:,.0f}'.format(error))\n\nxgb_model = xgb.XGBRegressor()\nxgb_model.fit(X_train, y_train)\npred = xgb_model.predict(X_val)\nerror = mae(pred, y_val)\nprint('MAE of XGBoost is: {:,.0f}'.format(error))","eacaa87d":"print(f\"Linear Regression Model Accuray: {(lr_model.score(X_val, y_val)*100):.2f}\")\nprint(f\"Decision Tree Model Accuray: {(dt_model.score(X_val, y_val)*100):.2f}\")\nprint(f\"Random Forest Model Accuray: {(rf_model.score(X_val, y_val)*100):.2f}\")\nprint(f\"XGBoost Model Accuray: {(xgb_model.score(X_val, y_val)*100):.2f}\")","de614f4c":"drop_cols = [\"price\", \"tax\", \"mpg\"]\nX = df_concat.drop(drop_cols, axis=1)\ny = df['price'] \nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)","85dbafe7":"lr_model = LinearRegression()\nlr_model.fit(X_train, y_train)\npred = lr_model.predict(X_val)\nerror = mae(pred, y_val)\nprint('MAE of Linear Regression is: {:,.0f}'.format(error))\n\ndt_model = DecisionTreeRegressor(max_leaf_nodes=100, random_state=1)\ndt_model.fit(X_train, y_train)\npred = dt_model.predict(X_val)\nerror = mae(pred, y_val)\nprint('MAE of Decision Tree is: {:,.0f}'.format(error))\n\nrf_model = RandomForestRegressor()\nrf_model.fit(X_train, y_train)\npred = rf_model.predict(X_val)\nerror = mae(pred, y_val)\nprint('MAE of Random Forest is: {:,.0f}'.format(error))\n\nxgb_model = xgb.XGBRegressor()\nxgb_model.fit(X_train, y_train)\npred = xgb_model.predict(X_val)\nerror = mae(pred, y_val)\nprint('MAE of XGBoost is: {:,.0f}'.format(error))","c21d3bbc":"print(f\"Linear Regression Model Accuray: {(lr_model.score(X_val, y_val)*100):.2f}\")\nprint(f\"Decision Tree Model Accuray: {(dt_model.score(X_val, y_val)*100):.2f}\")\nprint(f\"Random Forest Model Accuray: {(rf_model.score(X_val, y_val)*100):.2f}\")\nprint(f\"XGBoost Model Accuray: {(xgb_model.score(X_val, y_val)*100):.2f}\")","ff524cf8":"# "}}