{"cell_type":{"a68f03e7":"code","c5681537":"code","4cf18ee3":"code","c858280a":"code","e044d564":"code","085865ce":"code","69d0d13d":"code","3fa36f02":"code","ff4fe9b8":"code","1ab20bdd":"code","bad60d2c":"code","16c2f59e":"code","d5874bc2":"code","62722463":"code","7995daf5":"code","5ed28762":"code","ee9a349a":"code","262748d8":"code","3b88d21f":"code","6d538d12":"code","f627a1e3":"code","a9caec3d":"code","4de65088":"markdown","aacd1d33":"markdown","dccd81b3":"markdown","30874552":"markdown","f59dac1f":"markdown","2b599fd2":"markdown","6b04804a":"markdown","901ee295":"markdown","544ed6e2":"markdown","ab3a29ff":"markdown","30dfb33a":"markdown","87c1b71c":"markdown","a0716453":"markdown"},"source":{"a68f03e7":"import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom xgboost import XGBClassifier\nimport re\n%matplotlib inline","c5681537":"def data_preprocess(data, training=True):\n    data.loc[data['Fare'] == 0, 'Fare'] = np.NaN\n    # Filling NA values\n    data['Age'].fillna(data['Age'].median(), inplace=True)\n    data['Embarked'].fillna(data['Embarked'].mode(), inplace=True)\n    data['Fare'].fillna(data['Fare'].median(), inplace=True)\n\n    # Adding a column Family_Size\n    data['Family_Size'] = 0\n    data['Family_Size'] = data['Parch'] + data['SibSp']\n\n    # Adding a column Alone\n    data['Alone'] = 0\n    data.loc[data.Family_Size == 0, 'Alone'] = 1\n\n    # Define function to extract titles from passenger names\n    def get_title(name):\n        title_search = re.search(' ([A-Za-z]+)\\.', name)\n        # If the title exists, extract and return it.\n        if title_search:\n            return title_search.group(1)\n        return \"\"\n\n    # Create a new feature Title, containing the titles of passenger names\n    data['Title'] = data['Name'].apply(get_title)\n\n    # Group all non-common titles into one single grouping \"Rare\"\n    data['Title'] = data['Title'].replace(['Capt', 'Col', 'Don',\n                                           'Major', 'Sir', 'Jonkheer'], 'Mr')\n    data['Title'] = data['Title'].replace(['Mlle','Dona', 'Ms', 'Lady', 'Countess', 'Mme'], 'Mrs')\n\n    # Divide Fare into bins\n    categories = [1, 2, 3, 4]\n    data['Fare_Range'] = pd.qcut(\n        data['Fare'], len(categories), labels=categories)\n    data['Fare_Range'] = pd.Categorical(values=data['Fare_Range'], ordered=True,\n                                        categories=categories)\n#\n    # Divide Age into bins\n    data['Age_Range'] = pd.cut(\n        data['Age'], bins=[0, 15, 30, 45, 120], labels=[1, 2, 3, 4], ordered=True, right=False, include_lowest=True)\n#\n    # Categorical values encoding\n    data = pd.get_dummies(data=data, columns=['Sex', \"Title\", \"Embarked\"],\n                          prefix=['Sex', \"Title\", \"Embarked\"], drop_first=True)\n    data['Pclass'] = pd.Categorical(values=data.Pclass, ordered=True,\n                                    categories=[3, 2, 1])\n\n    data = data.loc[:, (data != 0).any(axis=0)]\n\n    drop_columns = ['Cabin', 'Ticket', 'PassengerId', 'Name',\n                    'SibSp', 'Parch', 'Age', 'Fare']  # , 'Family_Size'\n\n    if training:\n        y = data.loc[:, 'Survived']\n        X = data.drop(drop_columns + ['Survived'], axis=1)\n        return X, y\n    else:\n        X = data.drop(drop_columns, axis=1)\n        return X\n","4cf18ee3":"train_data = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('..\/input\/titanic\/test.csv')\ntrain_data.head()","c858280a":"train_data.info()","e044d564":"test_data.info()","085865ce":"X_train, y_train = data_preprocess(train_data)\nX_test = data_preprocess(test_data, training=False)","69d0d13d":"X_train.info()","3fa36f02":"X_test.info()","ff4fe9b8":"rf_clf = RandomForestClassifier(n_estimators=700,max_features='auto', max_depth=5,\n                                random_state=1, n_jobs=-1)\nrf_scores = cross_val_score(rf_clf, X_train, y_train, cv=10, scoring='accuracy', verbose=1, n_jobs=-1)\nrf_scores.mean()","1ab20bdd":"param_grid = [\n    {'C':[1.8, 1.83, 1.86, 1.89, 1.9, 1.93, 1.96, 1.99]}\n]\n\nlr_clf = LogisticRegression(max_iter=10000, n_jobs=-1, random_state=1)\nlr_grid_cv = GridSearchCV(lr_clf, param_grid=param_grid, scoring='accuracy', cv=10, n_jobs=-1)\nlr_grid_cv.fit(X_train, y_train)","bad60d2c":"lr_grid_cv.best_params_, lr_grid_cv.best_score_","16c2f59e":"param_grid = [\n    {'C':[0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29], \n     'gamma':[0.81, 0.82, 0.83, 0.84, 0.85],\n     'degree':[1, 2, 3, 4, 5]}\n]\nsvc = SVC(random_state=1, probability=True)\nsvc_grid_cv = GridSearchCV(svc, param_grid=param_grid, scoring='accuracy', cv=10, n_jobs=-1)\nsvc_grid_cv.fit(X_train, y_train)","d5874bc2":"svc_grid_cv.best_score_, svc_grid_cv.best_params_","62722463":"param_grid = [\n    {'n_estimators':[50, 75, 100, 125, 150], 'learning_rate':[0.03, 0.06, 0.09, 0.1, 0.13, 0.16, 0.19]}\n]\n\nada = AdaBoostClassifier(random_state=1)\nada_grid_cv = GridSearchCV(ada, param_grid=param_grid, scoring='accuracy', cv=10, n_jobs=-1)\nada_grid_cv.fit(X_train, y_train)","7995daf5":"ada_grid_cv.best_score_, ada_grid_cv.best_params_","5ed28762":"param_grid = [\n    {'n_estimators':[125, 150, 175, 200], \n     'learning_rate':[0.01, 0.02, 0.03, 0.04, 0.05],\n     'max_depth':[1, 2, 3, 4, 5]}\n]\n\ngbc = GradientBoostingClassifier(random_state=1)\ngbc_grid_cv = GridSearchCV(gbc, param_grid=param_grid, scoring='accuracy', cv=10, n_jobs=-1)\ngbc_grid_cv.fit(X_train, y_train)","ee9a349a":"gbc_grid_cv.best_score_, gbc_grid_cv.best_params_","262748d8":"named_estimators = [\n    ('rf', rf_clf),\n    ('lr', lr_grid_cv.best_estimator_),\n    ('svc', svc_grid_cv.best_estimator_),\n    ('ada', ada_grid_cv.best_estimator_),\n    ('gbc', gbc_grid_cv.best_estimator_)\n]\n\nvoting_clf = VotingClassifier(estimators=named_estimators, n_jobs=-1, voting='hard')\nvoting_scores = cross_val_score(voting_clf, X_train, y_train, cv=10, scoring='accuracy', verbose=1, n_jobs=-1)\nvoting_scores.mean()","3b88d21f":"# param_grid = [\n#     {'n_estimators':[125, 150, 175, 200], \n#      'learning_rate':[0.01, 0.02, 0.03, 0.04, 0.05],\n#      'max_depth':[1, 2, 3, 4, 5]}\n# ]\n# X_train = X_train.astype('float')\n# xgb_clf = XGBClassifier(random_state=1)\n# xgb_grid_cv = GridSearchCV(xgb_clf, param_grid=param_grid, scoring='accuracy', cv=10, n_jobs=-1)\n# xgb_grid_cv.fit(X_train, y_train)","6d538d12":"# xgb_grid_cv.best_score_, xgb_grid_cv.best_params_","f627a1e3":"final_model = svc_grid_cv.best_estimator_\n# final_model.fit(X_train, y_train)\npredictions = final_model.predict(X_test.astype('float'))\npredictions[:10]","a9caec3d":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","4de65088":"### Random Forest Clasifier","aacd1d33":"### Logistic Regression Classifier","dccd81b3":"### Voting Classifier","30874552":"### SVC Classifier","f59dac1f":"### Data Preprocessing","2b599fd2":"### Gradient Boosting Classifier","6b04804a":"### Final Model","901ee295":"### Submission","544ed6e2":"### XGBoost Classifier","ab3a29ff":"### Imports","30dfb33a":"### Reading Train and Test Data","87c1b71c":"### AdaBoost Clasifier","a0716453":"### Data Preprocessing Function"}}