{"cell_type":{"d44f1dcb":"code","90c7c4a0":"code","bb7499fd":"code","c3e4aef1":"code","3041fb5b":"code","f600ac82":"code","455e3b60":"code","b28f0fd9":"code","4e926db0":"code","d65af0d0":"code","cf82c713":"code","35ba8967":"code","8a6cc377":"code","cdda132f":"code","2d5e2465":"code","f7d7fd77":"code","abf8ff86":"code","59312fe2":"code","c6510e63":"code","0d968dc1":"code","7ae79288":"code","026ae172":"code","5ca2887f":"markdown","c801a434":"markdown","068c3ab0":"markdown","e9da052b":"markdown","555bfc04":"markdown","040c3e01":"markdown","4e920580":"markdown","2c373cf9":"markdown","01df1df8":"markdown","38abce4b":"markdown","67d21e6e":"markdown","30ddef09":"markdown","fd41a0b4":"markdown","5a11415a":"markdown","1fd25b98":"markdown","c8ca9a27":"markdown","69ed88a8":"markdown"},"source":{"d44f1dcb":"import pandas as pd","90c7c4a0":"X_test = pd.read_csv(\"\/kaggle\/input\/interbank-internacional-2019\/ib_base_inicial_test\/ib_base_inicial_test.csv\")\nsunat = pd.read_csv(\"\/kaggle\/input\/interbank-internacional-2019\/ib_base_sunat\/ib_base_sunat.csv\")\ntrain = pd.read_csv(\"\/kaggle\/input\/interbank-internacional-2019\/ib_base_inicial_train\/ib_base_inicial_train.csv\")\nrcc = pd.read_csv(\"\/kaggle\/input\/interbank-internacional-2019\/ib_base_rcc\/ib_base_rcc.csv\")\nreniec = pd.read_csv(\"\/kaggle\/input\/interbank-internacional-2019\/ib_base_reniec\/ib_base_reniec.csv\")\ndigital = pd.read_csv(\"\/kaggle\/input\/interbank-internacional-2019\/ib_base_digital\/ib_base_digital.csv\")\nvehicular = pd.read_csv(\"\/kaggle\/input\/interbank-internacional-2019\/ib_base_vehicular\/ib_base_vehicular.csv\")\ncampanias = pd.read_csv(\"\/kaggle\/input\/interbank-internacional-2019\/ib_base_campanias\/ib_base_campanias.csv\")","bb7499fd":"y_train = train[['codmes', 'id_persona', 'margen']].copy()\ny_train[\"prediction_id\"] = y_train[\"id_persona\"].astype(str) + \"_\" + y_train[\"codmes\"].astype(str)\n# y_train[\"target\"] = y_train[\"margen\"].astype(\"float32\")\ny_train = y_train.set_index(\"prediction_id\")\nX_train = train.drop([\"codtarget\", \"margen\"], axis=1)\nX_train[\"prediction_id\"] = X_train[\"id_persona\"].astype(str) + \"_\" + X_train[\"codmes\"].astype(str)\ndel train","c3e4aef1":"X_train[\"ratio\"] = X_train[\"linea_ofrecida\"] \/ X_train[\"ingreso_neto\"]\nX_test[\"ratio\"] = X_test[\"linea_ofrecida\"] \/ X_test[\"ingreso_neto\"]","3041fb5b":"rcc.clasif.fillna(-1, inplace=True)\nrcc.rango_mora.fillna(-1, inplace=True)\nrcc_clasif = rcc.groupby([\"codmes\", \"id_persona\"]).clasif.max().reset_index().set_index(\"codmes\").sort_index().astype(\"int32\")\nrcc_mora = rcc.groupby([\"codmes\", \"id_persona\", \"rango_mora\"]).mto_saldo.sum().unstack(level=2, fill_value=0).reset_index().set_index(\"codmes\").sort_index().astype(\"int32\")\nrcc_producto = rcc.groupby([\"codmes\", \"id_persona\", \"producto\"]).mto_saldo.sum().unstack(level=2, fill_value=0).reset_index().set_index(\"codmes\").sort_index().astype(\"int32\")\nrcc_banco = rcc.groupby([\"codmes\", \"id_persona\", \"cod_banco\"]).mto_saldo.sum().unstack(level=2, fill_value=0).reset_index().set_index(\"codmes\").sort_index().astype(\"int32\")\ndel rcc","f600ac82":"rcc_mora.columns = [\"mora_\" + str(c) if c != \"id_persona\" else c for c in rcc_mora.columns ]\nrcc_producto.columns = [\"producto_\" + str(c) if c != \"id_persona\" else c for c in rcc_producto.columns]\nrcc_banco.columns = [\"banco_\" + str(c) if c != \"id_persona\" else c for c in rcc_banco.columns]","455e3b60":"camp_canal = campanias.groupby([\"codmes\", \"id_persona\", \"canal_asignado\"]).size().unstack(level=2, fill_value=0).reset_index().set_index(\"codmes\").sort_index().astype(\"int32\")\ncamp_prod = campanias.groupby([\"codmes\", \"id_persona\", \"producto\"]).size().unstack(level=2, fill_value=0).reset_index().set_index(\"codmes\").sort_index().astype(\"int32\")\ndel campanias","b28f0fd9":"camp_canal.columns = [\"canal_\" + str(c) if c != \"id_persona\" else c for c in camp_canal.columns]\ncamp_prod.columns = [\"producto_campania_\" + str(c) if c != \"id_persona\" else c for c in camp_prod.columns]","4e926db0":"digital[\"codmes\"] = digital.codday.astype(str).str[:-2].astype(int)\ndigital = digital.drop(\"codday\", axis=1).fillna(0)\ndigital = digital.groupby([\"codmes\", \"id_persona\"]).sum().reset_index().set_index(\"codmes\").sort_index().astype(\"int32\")","d65af0d0":"sunat = sunat.groupby([\"id_persona\", \"activ_econo\"]).meses_alta.sum().unstack(level=1, fill_value=0).astype(\"int32\")\nvehicular1 = vehicular.groupby([\"id_persona\", \"marca\"]).veh_var1.sum().unstack(level=1, fill_value=0).astype(\"float32\")\nvehicular2 = vehicular.groupby([\"id_persona\", \"marca\"]).veh_var2.sum().unstack(level=1, fill_value=0).astype(\"float32\")\nreniec = reniec.set_index(\"id_persona\").astype(\"float32\")\ndel vehicular","cf82c713":"vehicular1.columns = [c + \"_v1\" for c in vehicular1.columns]\nvehicular2.columns = [c + \"_v2\" for c in vehicular2.columns]","35ba8967":"X_train = X_train.set_index(\"prediction_id\").astype(\"int32\").reset_index().set_index(\"id_persona\").join(vehicular1).join(vehicular2).join(reniec).join(sunat)\nX_test = X_test.set_index(\"prediction_id\").astype(\"int32\").reset_index().set_index(\"id_persona\").join(vehicular1).join(vehicular2).join(reniec).join(sunat)\ndel vehicular1, vehicular2, reniec, sunat","8a6cc377":"import gc\ngc.collect()","cdda132f":"meses = {\n    201901: slice(201808, 201810),\n    201902: slice(201809, 201811),\n    201903: slice(201810, 201812),\n    201904: slice(201811, 201901),\n    201905: slice(201812, 201902),\n    201906: slice(201901, 201903),\n    201907: slice(201902, 201904)\n}\n\nmeses_train = X_train.codmes.unique()\nmeses_test = X_test.codmes.unique()\ncomplementos = []\nfor mes in meses.keys():\n    print(\"*\"*10, mes, \"*\"*10)\n    res = pd.concat([\n        rcc_clasif.loc[meses[mes]].groupby(\"id_persona\").sum(),\n        rcc_mora.loc[meses[mes]].groupby(\"id_persona\").sum(),\n        rcc_producto.loc[meses[mes]].groupby(\"id_persona\").sum(),\n        rcc_banco.loc[meses[mes]].groupby(\"id_persona\").sum(),\n        camp_canal.loc[meses[mes]].groupby(\"id_persona\").sum(),\n        camp_prod.loc[meses[mes]].groupby(\"id_persona\").sum(),\n        digital.loc[meses[mes]].groupby(\"id_persona\").sum()\n        \n    ], axis=1)\n    res[\"codmes\"] = mes\n    res = res.reset_index().set_index([\"id_persona\", \"codmes\"]).astype(\"float32\")\n    complementos.append(res)\n\ngc.collect()\nprint(\"concatenando complementos\")\ncomplementos = pd.concat(complementos)\ngc.collect()\nprint(\"X_train join\")\nX_train = X_train.reset_index().join(complementos, on=[\"id_persona\", \"codmes\"]).set_index(\"prediction_id\")\ngc.collect()\nprint(\"X_test join\")\nX_test = X_test.reset_index().join(complementos, on=[\"id_persona\", \"codmes\"]).set_index(\"prediction_id\")\ngc.collect()\n\ndel rcc_clasif, rcc_mora, rcc_producto, rcc_banco, camp_canal, camp_prod, digital, complementos,res\ngc.collect()","2d5e2465":"for i, c in enumerate(X_train.columns[[not all(ord(c) < 128 for c in s) for s in X_train.columns]]):\n    X_train[\"non_ascii_\" + str(i)] = X_train[c]\n    X_train = X_train.drop(c, axis= 1)\n    X_test[\"non_ascii_\" + str(i)] = X_test[c]\n    X_test = X_test.drop(c, axis= 1)","f7d7fd77":"from lightgbm import LGBMRegressor\ngc.collect()","abf8ff86":"drop_cols = [\"codmes\"]\ntest_preds = []\ntrain_preds = []\ny_train[\"target\"] = y_train[\"margen\"].astype(\"float32\")\nfor mes in X_train.codmes.unique():\n    print(\"*\"*10, mes, \"*\"*10)\n    Xt = X_train[X_train.codmes != mes]\n    yt = y_train.loc[Xt.index, \"target\"]\n    Xt = Xt.drop(drop_cols, axis=1)\n\n    Xv = X_train[X_train.codmes == mes]\n    yv = y_train.loc[Xv.index, \"target\"]\n    \n    learner = LGBMRegressor(n_estimators=1000)\n    learner.fit(Xt, yt,  early_stopping_rounds=10, eval_metric=\"mae\",\n                eval_set=[(Xt, yt), (Xv.drop(drop_cols, axis=1), yv)], verbose=50)\n    gc.collect()\n    test_preds.append(pd.Series(learner.predict(X_test.drop(drop_cols, axis=1)),\n                                index=X_test.index, name=\"fold_\" + str(mes)))\n    train_preds.append(pd.Series(learner.predict(Xv.drop(drop_cols, axis=1)),\n                                index=Xv.index, name=\"probs\"))\n    gc.collect()\n\ntest_preds = pd.concat(test_preds, axis=1).mean(axis=1)\ntrain_preds = pd.concat(train_preds)","59312fe2":"from lightgbm import LGBMClassifier\ngc.collect()","c6510e63":"drop_cols = [\"codmes\"]\nfi = []\ntest_probs = []\ntrain_probs = []\ny_train[\"target\"] = (y_train[\"margen\"] > 0).astype(\"int32\")\nfor mes in X_train.codmes.unique():\n    print(\"*\"*10, mes, \"*\"*10)\n    Xt = X_train[X_train.codmes != mes]\n    yt = y_train.loc[Xt.index, \"target\"]\n    Xt = Xt.drop(drop_cols, axis=1)\n\n    Xv = X_train[X_train.codmes == mes]\n    yv = y_train.loc[Xv.index, \"target\"]\n    \n    learner = LGBMClassifier(n_estimators=1000)\n    learner.fit(Xt, yt,  early_stopping_rounds=10, eval_metric=\"mae\",\n                eval_set=[(Xt, yt), (Xv.drop(drop_cols, axis=1), yv)], verbose=50)\n    gc.collect()\n    test_probs.append(pd.Series(learner.predict_proba(X_test.drop(drop_cols, axis=1))[:, -1],\n                                index=X_test.index, name=\"fold_\" + str(mes)))\n    train_probs.append(pd.Series(learner.predict_proba(Xv.drop(drop_cols, axis=1))[:, -1],\n                                index=Xv.index, name=\"probs\"))\n    gc.collect()\n\ntest_probs = pd.concat(test_probs, axis=1).mean(axis=1)\ntrain_probs = pd.concat(train_probs)","0d968dc1":"test = pd.concat([test_probs.rename(\"probs\"), test_preds.rename(\"preds\")], axis=1)\ntrain = pd.concat([train_probs.rename(\"probs\"), train_preds.rename(\"preds\")], axis=1)","7ae79288":"from scipy.optimize import differential_evolution\n\ndef clasificar(res, c):\n    return ((res.probs > c[0]) | (res.preds > c[1])) * c[2] + ((res.probs > c[3]) & (res.preds > c[4])) * c[5] > c[6]\n\ndef cost(res, coefs):\n    return -((clasificar(res, coefs) * res.margen) \/ res.margen.sum()).sum()\n\nres = y_train.join(train)\noptimization = differential_evolution(lambda x: cost(res, x), [(-100, 100), (0, 1), (0, 1),\n                                                               (-100, 100), (0, 1), (0, 1),\n                                                               (0, 2)])\noptimization","026ae172":"test_preds = clasificar(test, optimization[\"x\"]).astype(int)\ntest_preds.index.name=\"prediction_id\"\ntest_preds.name=\"class\"\ntest_preds.to_csv(\"benchmark3.csv\", header=True)","5ca2887f":"### Creaci\u00f3n de Variables\n\nPrimero creamos una variable en base a las columnas que tenemos en nuestra base de train\n\nVamos a crear la variable \"ratio\" que va a ser el cociente entre la linea ofrecida y el ingreso neto","c801a434":"Vamos a trabajar luego con la base de **Digital**:\n* Renombramos la columna codday por codmes y la colocamos como \u00edndice\n* Agrupamos por mes y persona las distintas informaciones para poder sumarlas a nuestra base train","068c3ab0":"### Importamos las librer\u00edas que vamos a utilizar","e9da052b":"Agregamos despu\u00e9s las columnas calculadas a nuestra base de Train","555bfc04":"Vamos a trabajar luego con la base de **Campa\u00f1as**:\n* Agrupamos por mes y persona las distintas informaciones para poder sumarlas a nuestra base train","040c3e01":"### Optimizaci\u00f3n de punto de corte\nCon las probabilidades calculadas en validaci\u00f3n, calcularmos el punto de corte optimo para maximizar la ecuaci\u00f3n econ\u00f3mica de la empresa","4e920580":"### Lectura de las Bases\n\nObservamos los datos que tenemos disponibles en https:\/\/www.kaggle.com\/c\/interbank-internacional-2019\/data\n\nVamos a trabajar ahora con todas las bases disponibles","2c373cf9":"### Entrenamiento del Modelo\n\nPara entrenar nuestro modelo vamos a usar LightGBM","01df1df8":"Hacemos lo mismo que antes con las bases **Sunat**, **Vehicular** y **Reniec**","38abce4b":"### Guardado del modelo para hacer la presentaci\u00f3n\n\nFinalmente creamos el archivo CSV que podemos subir como nuestra Soluci\u00f3n a la competencia\n\nEmpez\u00e1 con este archivo y luego podes seguir mejorandolo a ver si subis en posiciones!","67d21e6e":"Renombramos las columnas para que sean m\u00e1s explicativas de lo que representan","30ddef09":"Agregamos las columnas de las dem\u00e1s bases en los meses correspondientes a nustra base de Train","fd41a0b4":"Vamos a trabajar ahora con la base de **RCC**:\n* Imputamos los valores perdidos con el valor \"-1\"\n* Agrupamos por mes y persona las distintas informaciones para luego agregarla a nuestra base central (train)","5a11415a":"### Creaci\u00f3n del Target de predicci\u00f3n\n\nConsutruimos un target continuo para detectar quienes son clientes rentables y, por tanto, es conveniente hacerles campa\u00f1a para atraerlos.","1fd25b98":"Renombramos las columnas para que sean m\u00e1s explicativas de lo que representan","c8ca9a27":"# Script para generar la soluci\u00f3n del Tercer Benchmark de la Competencia\n\n## Si no presentaste a\u00fan tu primera soluci\u00f3n, tenes la oportunidad de hacerlo en pocos Clicks!\n\n**Hola! **  \n  \nEste Script es un Ejemplo de Procesamiento de los Datos, Modelado y Generaci\u00f3n de una Soluci\u00f3n.\n\nAgregamos una peque\u00f1a explicaci\u00f3n de lo que se hace en cada paso para ayudar a los que est\u00e1n comenzando ahora","69ed88a8":"### Renombrado de Variables con nombre no ascii\nEl algoritmo que usamos no se lleva bien con cadenas de texto con caracteres especiales, las renombramos."}}