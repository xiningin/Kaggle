{"cell_type":{"f2d8af8d":"code","471bae8d":"code","5a95691b":"code","5adbfc09":"code","455165f7":"code","d5045a1c":"code","183cdfd6":"code","95faf3e3":"code","fcf747c9":"code","c8fa4cee":"code","3420b8a4":"code","379f0a7c":"code","82e4fcb7":"code","8c558b0e":"markdown"},"source":{"f2d8af8d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\npictures = os.listdir(\"..\/input\/Pictures\")\n\n","471bae8d":"def normalize(array):\n    #Convert this to a (0,1) range\n    array = (array - array.min())\/(255 - array.min())\n    #Now convert it into a range of (-1,1)\n    array = 2*array - 1\n    \n    return array","5a95691b":"dataset = []\n\n\nfor picture in pictures[:320]:\n    im = Image.open('..\/input\/Pictures\/'+picture)\n    pix_val = np.array(im.getdata())\n    pix_val = pix_val.reshape(64,64,-1)[:,:,:3]\n    normalized = normalize(pix_val)\n    dataset.append(normalized)\ndataset = np.array(dataset)\nprint(dataset.shape)\n","5adbfc09":"def batch_generator(dataset, index, batch_size):\n    data = dataset[(index*batch_size):((index+1)*batch_size)]\n    return data","455165f7":"def model_inputs(real_dim, z_dim):\n    input_real = tf.placeholder(tf.float32, shape = (None, *real_dim), name = \"real_input\")\n    input_z = tf.placeholder(tf.float32, shape = (None, z_dim), name = \"z_input\")\n    \n    return (input_real , input_z)","d5045a1c":"def generator(input_z, alpha = 0.2, reuse = False, training = True):\n    \n    with tf.variable_scope(\"generator\", reuse=reuse):\n        \n        input_x = tf.layers.dense(input_z, 16*16*1024)\n        input_x = tf.reshape(input_x, (-1, 16, 16, 1024))\n        input_x = tf.maximum(input_x, alpha*input_x)\n        \n        first_layer = tf.layers.conv2d_transpose(input_x, 512, 5, strides = 2, padding = 'same')\n        first_layer_normal = tf.layers.batch_normalization(first_layer, training = training)\n        first_layer_output = tf.maximum(first_layer_normal, alpha*first_layer_normal)\n        \n        second_layer = tf.layers.conv2d_transpose(first_layer_output, 256, 5, strides = 2, padding = 'same')\n        second_layer_normal = tf.layers.batch_normalization(second_layer, training = training )\n        second_layer_output = tf.maximum(second_layer_normal, alpha*second_layer_normal)\n        \n        logits = tf.layers.conv2d_transpose(second_layer_output, 3, 5, strides = 2, padding = 'same')\n        out = tf.tanh(logits)\n        return(out)  \n        ","183cdfd6":"def discriminator(input_x, alpha = 0.2, reuse = True):\n    \n    with tf.variable_scope(\"discriminator\", reuse=reuse):\n        \n        first_layer = tf.layers.conv2d(input_x, 128, 3, strides = 2, padding = 'same')\n        first_layer_output = tf.maximum(first_layer, alpha*first_layer)\n        \n        second_layer = tf.layers.conv2d(first_layer_output, 256, 3, strides = 2, padding = 'same')\n        second_layer_normal = tf.layers.batch_normalization(second_layer, training = True)\n        second_layer_output = tf.maximum(second_layer_normal, alpha * second_layer_normal)\n        \n        final_layer = tf.layers.conv2d(second_layer_output, 512, 3, strides=2, padding='same')\n        final_layer_normal = tf.layers.batch_normalization(final_layer, training = True)\n        final_layer_output = tf.maximum(final_layer_normal, alpha*final_layer_normal)\n        \n        final_layer_output = tf.reshape(final_layer_output, (-1,8*8*512))\n        logits = tf.layers.dense(final_layer_output, 1)\n        out = tf.sigmoid(logits)\n        \n        return (logits, out)","95faf3e3":"def model_loss(input_real, fake_input, alpha):\n    \n    g_out = generator(fake_input, alpha)\n    d_real_logits, d_real_out = discriminator(input_real, alpha, reuse = False)\n    d_fake_logits, d_fake_out = discriminator(g_out, alpha)\n    \n    d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = d_real_logits, labels = tf.ones_like(d_real_out)))\n    d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = d_fake_logits, labels = tf.zeros_like(d_fake_out)))\n    \n    g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = d_fake_logits, labels = tf.ones_like(d_fake_out)))\n    d_loss = d_loss_real + d_loss_fake\n    \n    return (g_loss, d_loss)","fcf747c9":"def model_optimizer(g_loss, d_loss, learning_rate, beta1):\n    \n    t_vars = tf.trainable_variables()\n    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n    d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n        g_opt = tf.train.AdamOptimizer(learning_rate = learning_rate, beta1 = beta1).minimize(g_loss, var_list = g_vars)\n        d_opt = tf.train.AdamOptimizer(learning_rate = learning_rate, beta1 = beta1).minimize(d_loss, var_list = d_vars)\n    \n    return g_opt, d_opt\n","c8fa4cee":"class Generator:\n    def __init__(self, real_dim, z_dim, learning_rate, alpha, beta1):\n        tf.reset_default_graph()\n        self.input_real , self.input_z = model_inputs(real_dim, z_dim)\n        self.g_loss, self.d_loss = model_loss(self.input_real, self.input_z, alpha)\n        self.g_opt , self.d_opt = model_optimizer(self.g_loss, self.d_loss, learning_rate, beta1)\n        ","3420b8a4":"def view_samples(epoch, samples, nrows, ncols, figsize=(8,8)):\n    fig, axes = plt.subplots(figsize=figsize, nrows=nrows, ncols=ncols, \n                             sharey=True, sharex=True)\n    for ax, img in zip(axes.flatten(), samples):\n        ax.axis('off')\n        img = ((img - img.min())*255 \/ (img.max() - img.min())).astype(np.uint8)\n        ax.set_adjustable('box-forced')\n        im = ax.imshow(img, aspect='equal')\n    plt.subplots_adjust(wspace=0, hspace=0)\n    return fig, axes","379f0a7c":"def train(net, data, batch_size, epochs):\n    sample_input = np.random.uniform(-1, 1,size=(36, 86))\n    loss = []\n    samples = []\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        for n_epoch in range(1, epochs+1):\n            for ii in range(int(len(data)\/batch_size)):\n                dataset = batch_generator(data, ii, batch_size)\n                random_input = np.random.uniform(-1, 1,size=(batch_size, 86))\n                \n                _ = sess.run(net.d_opt, feed_dict = {net.input_real:dataset, net.input_z:random_input})\n                _ = sess.run(net.g_opt, feed_dict = {net.input_real:dataset, net.input_z:random_input})\n                \n\n                if n_epoch%1 == 0:\n                    train_loss_g = net.g_loss.eval({net.input_z:random_input})\n                    train_loss_d = net.d_loss.eval({net.input_real:dataset, net.input_z: random_input})\n\n                    loss.append(train_loss_g)\n                    print(\"Epoch {}\/{} Discriminator Loss {:.4f} Generator Loss {:.4f}\".format(\n                            n_epoch, epochs, train_loss_d, train_loss_g))\n                if n_epoch%10 ==0 :\n                    gener_samples = sess.run(generator(net.input_z, reuse = True, training = False),feed_dict= {net.input_z:sample_input})\n                    fig, axes = view_samples(-1, gener_samples, 6, 6)\n                    plt.show()\n                    samples.append(gener_samples)\n    return samples    ","82e4fcb7":"real_dim = (64, 64, 3)\nz_dim = 86\nbatch_size = 64\nlearning_rate = 0.0002\nepochs = 100\nalpha = 0.2\nbeta1 =0.5","8c558b0e":"###### net = Generator(real_dim, z_dim, learning_rate, alpha, beta1)\nsamples = train(net, dataset, batch_size, epochs)"}}