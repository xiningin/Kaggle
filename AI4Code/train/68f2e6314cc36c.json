{"cell_type":{"3009918e":"code","4a93c0fd":"code","0eabb6cd":"code","fcb8f786":"code","c381b9b4":"code","21e56929":"code","58938eea":"code","71716ffc":"code","94ab697c":"code","85edbc28":"code","4d46b9ea":"code","0620dc99":"code","3069ab97":"code","f6fb6630":"code","6fb2536f":"code","20da2483":"code","ecdd1cce":"code","2d69016e":"code","ab67dc88":"code","ede068d5":"code","b8a1935b":"code","5603675c":"code","36731e05":"code","92a4b745":"code","fd836c76":"code","f5284a4e":"code","4932122f":"code","ee047d93":"code","89852733":"code","52d6a184":"code","4aec4b4c":"code","26af3ca8":"code","edf11ae6":"code","1cc93493":"markdown","ff48ab3c":"markdown","634dfaea":"markdown","e49de72d":"markdown","57d14db7":"markdown","d744dae2":"markdown","4e56705e":"markdown","363fb90d":"markdown","4cf7ebca":"markdown","c3014e14":"markdown","e1c5bcf5":"markdown","6de8613e":"markdown","514b02d8":"markdown","e1da899f":"markdown","5295bcfb":"markdown","d22e6c90":"markdown","28bbd4d2":"markdown","372e2f43":"markdown","bd0d4a92":"markdown","a1164c36":"markdown","ba3def26":"markdown","1abe7ab5":"markdown","2bf50f15":"markdown","8f529a57":"markdown","052029f0":"markdown","05e84c53":"markdown","0551a733":"markdown","31325647":"markdown","1a7d4c48":"markdown","e0a68282":"markdown","540964fa":"markdown","c0c9067e":"markdown"},"source":{"3009918e":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tqdm.notebook import tqdm\nfrom torch.nn import Parameter\nfrom torch.nn.init import xavier_uniform_\nimport pandas as pd\n\n# import utility code\nimport mrnn_utility\nfrom mrnn_utility import block_diag,unblock_diag","4a93c0fd":"# Use cuda (GPU) to train models if available\nif torch.cuda.is_available():\n    device = torch.device('cuda')\n    torch.set_default_tensor_type('torch.cuda.FloatTensor')\nelse:\n    device = torch.device('cpu')\n    torch.set_default_tensor_type('torch.FloatTensor')","0eabb6cd":"# Generate the dummy dataset\nnp.random.seed(123)\nf = np.array([1.5,2,2.5])\noffset = np.array([0,1,2]).reshape(-1,1)\nw = 2. * np.pi * f\nt = np.linspace(0, 1, 50)\nx = torch.tensor(np.sin(w.reshape(-1,1) * t)+offset).float()\nground_truth = x.detach().clone()\nmask = torch.ones_like(x)\ndelta = torch.ones_like(x).float()\ndelta[:,0] = 0\n\n# remove 5% of the data\nix = [(channel,t) for channel in range(x.shape[0]) for t in range(x.shape[1])]\nnp.random.shuffle(ix)\nto_replace = int(round(.05*len(ix)))\nix = ix[:to_replace]\nfor idx in ix:\n    x[idx[0],idx[1]] = np.nan\n    mask[idx[0],idx[1]] = 0","fcb8f786":"# Plot the dummy dataset\n%config InlineBackend.figure_format = 'svg'\nplt.figure(figsize=(12,4))\nplt.title(\"Dummy dataset\")\nplt.xlabel(\"t\")\nplt.ylabel(\"Measurement\")\nfor i in range(3):\n    plt.plot(t*50,x[i].cpu())\n    plt.plot(t*50,ground_truth[i].cpu(),alpha=0.4,c=\"grey\",linestyle='dashed')","c381b9b4":"# Forward estimate\nhf_t12_d3 = np.array([2,4,3]) # Forward Hidden state of t-1\n\nWf3 = np.array([[ 0.1546, -0.6600,  0.5753],\n        [-0.0077, -0.6195,  0.1414],\n        [ 0.2404,  0.1764,  0.7104]]) # 3x3 weight matrix W^1\nVf3 = np.array([[-0.5855, -0.5765,  0.9371],\n        [-0.5110,  0.3941,  0.5218],\n        [-0.5413,  0.4935, -0.2625]]) # 3x3 weight matrix V^1\ncf3 = np.array([-0.9524, -1.1768, -1.0417]) # 3x1 weight matrix V^1\n\nhf_t13_d3 = mrnn_utility.ReLU(Wf3.dot(hf_t12_d3) + Vf3.dot(np.array([1.6247,1,1])) + cf3) # Calculate result\n\nprint(\" The forward hidden state of t=13 and d=3 is: \",hf_t13_d3)","21e56929":"hb_t13_d3 = np.array([-1,1.5,2.75]) # Backward Hidden state of t\nU3 = np.array([ 0.2740,  0.6337,  0.8451, -1.1979,  0.4775, -0.4943]) # 1x6 Weight matrix U^1\nc_3_0 = np.array([-0.2885]) # 1x1 bias c_0^1\n\nx_tilde_t13_d3 = mrnn_utility.ReLU(U3.dot(np.concatenate((hf_t13_d3,hb_t13_d3))) + c_3_0) # compute result\nprint(\"Intermediate estimate for t=13 and d=3: \", x_tilde_t13_d3)","58938eea":"# Dummy dataset output\nplt.figure(figsize=(12,4))\nplt.title(\"Reconstructed sequence\")\nplt.ylabel(\"measurement\")\nplt.xlabel(\"t\")\nfor i in range(3):\n    plt.plot(t*50,x[i].cpu())\n    plt.plot(t*50,ground_truth[i].cpu(),linestyle=\"dashed\",c=\"grey\",alpha=0.6)\nplt.scatter(t[12]*50,x_tilde_t13_d3,c=\"green\",label=\"Predicted interpolation\")\nplt.legend()","71716ffc":"class interpolater(nn.Module):\n    '''Interpolater Module for the M-RNN model.'''\n    def __init__(self,nchannels,hidden_dim,seq_len,padding=\"replication\",act='relu'):\n        super(interpolater, self).__init__()\n        self.nchannels = nchannels\n        self.hidden_dim = hidden_dim\n        self.seq_len = seq_len\n        \n        # Activation function\n        if act == 'relu':\n            self.act = F.relu\n        elif act == 'tanh':\n            self.act = F.tanh\n        \n        # Forward RNN weights\n        self.Wf = Parameter(block_diag(xavier_uniform_(torch.FloatTensor(nchannels,hidden_dim,hidden_dim).to(device=device))))\n        self.Vf = Parameter(block_diag(xavier_uniform_(torch.FloatTensor(nchannels,hidden_dim,3).to(device=device))))\n        self.cf = Parameter(block_diag(xavier_uniform_(torch.FloatTensor(nchannels,hidden_dim,1).to(device=device))))\n\n        # Backward RNN weights\n        self.Wb = Parameter(block_diag(xavier_uniform_(torch.FloatTensor(nchannels,hidden_dim,hidden_dim).to(device=device))))\n        self.Vb = Parameter(block_diag(xavier_uniform_(torch.FloatTensor(nchannels,hidden_dim,3).to(device=device))))\n        self.cb = Parameter(block_diag(xavier_uniform_(torch.FloatTensor(nchannels,hidden_dim,1).to(device=device))))\n\n        # Hidden state weights (combine forward and backward)\n        self.U = Parameter(block_diag(xavier_uniform_(torch.FloatTensor(nchannels,1,hidden_dim*2).to(device=device))))\n        self.c0 = Parameter(block_diag(nn.init.normal_(torch.FloatTensor(nchannels,1,1),std=.1).to(device=device)))\n        \n        # Padding options\n        if padding == \"replication\":\n            self.pad = nn.ReplicationPad2d((1,1,0,0))\n        elif padding == \"zero\":\n            self.pad = nn.ZeroPad2d((1,1,0,0))\n            \n    def forward(self,x,m,d):\n        '''A forward pass through the interpolater. This function will go through all time steps.\n        Input:\n        x = Measurement\n        m = Mask (1=observed, 0=missing)\n        d = time elapsed since last observation\n        \n        Output:\n        Estimate x_est for every input time step.'''\n        \n        batchsize = x.shape[0]\n        # Initialize hidden states\n        hidden_forwards = [torch.zeros(batchsize,self.hidden_dim*self.nchannels,self.nchannels)]\n        hidden_backwards = [torch.zeros(batchsize,self.hidden_dim*self.nchannels,self.nchannels)]\n        \n        # Append zeros to beginning and end of input\n        x = self.pad(x.unsqueeze(0)).squeeze(0)\n        m = self.pad(m.unsqueeze(0)).squeeze(0)\n        d = self.pad(d.unsqueeze(0)).squeeze(0)\n        \n        # Iterate through time (backward and forward)\n        for t in range(self.seq_len):  \n            # forward RNN hidden states\n            hidden_f = self.act(torch.matmul(self.Wf,hidden_forwards[t]) + torch.matmul(self.Vf,\n                block_diag(torch.stack((x[:,:,t],m[:,:,t],d[:,:,t]),axis=2).view(-1,self.nchannels,3,1))) \n                +self.cf)\n            \n            # backward RNN hidden states\n            hidden_b = self.act(torch.matmul(self.Wb,hidden_backwards[t]) + \n                  torch.matmul(self.Vb,block_diag(torch.stack((x[:,:,self.seq_len+1-t],m[:,:,self.seq_len+1-t],\n                  d[:,:,self.seq_len+1-t]),axis=2).view(-1,self.nchannels,3,1))) \n                  + self.cb)\n            \n            hidden_forwards.append(hidden_f)\n            hidden_backwards.append(hidden_b)\n\n        hidden_forwards = hidden_forwards[1:] # delete state t=-1\n        hidden_backwards = hidden_backwards[1:][::-1] # delete state t=T+1 and reverse the list\n        \n        final_hidden=torch.empty(batchsize,self.nchannels,self.seq_len)\n        \n        # Iterate through time again and compute combined state\n        for t in range(self.seq_len):\n            hidden = self.act(torch.matmul(self.U,block_diag(torch.cat((\n                unblock_diag(hidden_forwards[t],n=self.nchannels,size_block=(self.hidden_dim,1)),\n                unblock_diag(hidden_backwards[t],n=self.nchannels,size_block=(self.hidden_dim,1))),axis=2))) \n                + self.c0)\n            \n            final_hidden[:,:,t]= unblock_diag(hidden,n=self.nchannels).flatten(1)\n            \n        return final_hidden","94ab697c":"U = np.array([[ 0.0000, -0.5917, -0.4022],\n        [ 0.0718,  0.0000,  0.7470],\n        [-0.1493,  0.0946,  0.0000]]) # 3x3 weight matrix with 0 on diagonal\nV1 = np.array([[-0.4108, -0.4928,  0.0758],\n        [ 0.1374,  0.1361, -0.1438],\n        [-0.5133, -0.5428, -0.0387]]) # 3x3 weight matrix\nV2 = np.array([[-0.2221, -0.6349, -0.4399],\n        [ 0.5302, -0.0099, -0.5198],\n        [-0.3753, -0.8754, -0.5621]]) # 3x3 weight matrix\nbeta = np.array([-0.2132,  0.6235, -0.1733]) # 3x1 bias matrix\n\nx_tilde_t13 = np.array((0.125,1.565,x_tilde_t13_d3.item())) # combined intermediate estimates\n\n# compute result\nh_13 = mrnn_utility.ReLU(U.dot(np.array([0.7403,1.0641,1.642])) + V1.dot(x_tilde_t13) + V1.dot(x_tilde_t13) + beta)\nprint(\"Imputer hidden state of t=13: \",h_13)","85edbc28":"W = np.array([[-0.1957, -0.0024, -0.3857],\n        [ 0.0047,  0.5593, -0.2730],\n        [-0.0396,  0.5180,  0.2218]]) # 3x3 weight matrix\nalpha = np.array([ 0.5846, 0.3176,  0.49670]) # 1x1 bias\n\n# compute result\nx_hat_13 = W.dot(h_13) + alpha\nprint(\"Final output of t=13: \",x_hat_13)","4d46b9ea":"# Dummy dataset output\nplt.figure(figsize=(12,4))\nplt.title(\"Reconstructed sequence\")\nplt.ylabel(\"measurement\")\nplt.xlabel(\"t\")\nfor i in range(3):\n    plt.plot(t*50,x[i].cpu())\n    plt.plot(t*50,ground_truth[i].cpu(),linestyle=\"dashed\",c=\"grey\",alpha=0.6)\nplt.scatter(t[12]*50,x_hat_13[2],c=\"green\",label=\"Predicted interpolation\/imputation\")\nplt.legend()","0620dc99":"class imputer(nn.Module):\n    '''Fully connected network that computes the imputation across data streams. We can use the time dimension\n    as the batch dimension here, as the linear layers are independent of time.'''\n    def __init__(self,n_channels,hidden_dim=3,act='relu'):\n        super(imputer, self).__init__()\n        if act == 'relu':\n            self.act = F.relu\n        elif act == 'tanh':\n            self.act = F.tanh\n        self.V1 = nn.Linear(n_channels,hidden_dim,bias=False)\n        self.V2 = nn.Linear(n_channels,hidden_dim,bias=False)\n        self.U = nn.Linear(n_channels,hidden_dim) # bias beta\n        self.W = nn.Linear(hidden_dim,n_channels) # bias alpha\n        \n    def forward(self,x,x_est,m):\n        '''x : true measurement\n        x_est : estimated measurement of the interpolater\n        m : mask'''\n        v1out = self.V1(x_est.permute(0,2,1))\n        v2out = self.V2(m.permute(0,2,1))\n        self.U.weight.data.fill_diagonal_(0) # diagonal to zero to prevent usage of x_t^d at for prediction x_hat_t^d\n        uout = self.U(x.permute(0,2,1)) \n        h = self.act(uout+v1out+v2out) # hidden layer\n        out = self.W(h) # output layer, linear activation here\n        return out.permute(0,2,1)","3069ab97":"class MRNN(nn.Module):\n    def __init__(self,nchannels,seq_len,hidden_dim_inter,hidden_dim_imp=3,verbose=False,padding=\"replication\",act='relu'):\n        super(MRNN, self).__init__()\n        self.inter = interpolater(nchannels,hidden_dim_inter,seq_len,padding=padding,act=act)\n        self.imp = imputer(nchannels,hidden_dim_imp,act=act)\n        self.verbose = verbose\n        \n    def forward(self,x,m,d):\n        '''x = measurements, m = mask, d = time delta between measurements'''\n        out = self.inter.forward(x,m,d)\n        out = self.imp.forward(x,out,m)\n        return out\n    \n    def fit(self,epochs,optimizer,loss_func,batch_size,x,m,d):\n        loss_hist = []\n        # Make initial interpolation\n        x = lin_interpolation(x)\n\n        # Iterate over epochs\n        pbar = tqdm(range(epochs))\n        for i in pbar:   \n            # shuffle dataset\n            indices = torch.randperm(x.shape[0])\n            x = x[indices]\n            m = m[indices]\n            d = d[indices]\n            \n            temp_loss_hist=[]\n            # Iterate over all batches\n            for batch in range(int(x.shape[0] \/ batch_size)):\n                x_b = x[batch*batch_size:(batch+1)*batch_size]\n                m_b = m[batch*batch_size:(batch+1)*batch_size]\n                d_b = d[batch*batch_size:(batch+1)*batch_size]\n                # Estimate all values (forward pass)\n                output = self.forward(x_b,m_b,d_b)\n                # Compute loss\n                loss = loss_func(m_b*output,m_b*x_b) # only use loss of actually observed measurements\n                # Backward the loss\n                optimizer.zero_grad()\n                loss.backward()\n                temp_loss_hist.append(loss)\n                # Update the weights\n                optimizer.step()\n            if self.verbose:\n                # print graph\n                x_hat = self.predict(x,m,d)\n                missing = (m!=1)\n                mrnn_utility.live_plot(x_hat[0],missing[0],x[0],title=i)\n                \n            loss_hist.append(torch.stack(temp_loss_hist).mean())\n            pbar.set_postfix({'loss': torch.stack(temp_loss_hist).mean()})\n             \n        return loss_hist\n    \n    def predict(self,x,m,d,replace=False):\n        with torch.no_grad():\n            # initial interpolation\n            x = lin_interpolation(x)\n            # Forward dataset\n            out = self.forward(x,m,d)\n            if replace:\n                observed = (m==1)\n                out[observed] = x[observed]\n                \n        return out        ","f6fb6630":"def lin_interpolation(x_in):\n    x = x_in.clone()\n    for sample in range(x.shape[0]): # for every sample\n        for stream in range(x.shape[1]): # for every stream\n            s = pd.Series(x[sample,stream])\n            s = s.interpolate().bfill().ffill() # linear interpolation, then backward and forward fill for first and last value\n            x[sample,stream] = torch.tensor(s.values) # replace in original tensor\n    return x","6fb2536f":"# create the model\ntorch.manual_seed(7)\ndummy_model = MRNN(3,50,32,32,verbose=True,act='tanh')\ndummy_optimizer = torch.optim.Adam(dummy_model.parameters(),lr=0.06)\nloss_func = nn.MSELoss()\nepochs = 40","20da2483":"# data preparation\nx_t = x.unsqueeze(0).float().to(device=device)\nm_t = mask.unsqueeze(0).float().to(device=device)\nd_t = delta.unsqueeze(0).float().to(device=device)","ecdd1cce":"%matplotlib inline\nlosses = dummy_model.fit(epochs,dummy_optimizer,loss_func,1,x_t,m_t,d_t) # start interactive training","2d69016e":"x_hat = dummy_model.predict(x_t,m_t,d_t,replace=True)","ab67dc88":"plt.figure(figsize=(12,4))\nplt.title(\"Interpolated\/imputed sequence\")\nplt.ylabel(\"measurement\")\nplt.xlabel(\"t\")\nfor i in range(3):\n    plt.plot(t*50,x_hat[0][i].cpu())\n    plt.plot(t*50,ground_truth[i].cpu(),linestyle=\"dashed\",c=\"grey\",alpha=0.6)","ede068d5":"# Load data\ndata = np.loadtxt(\"..\/input\/eeg-eye-state\/EEG Eye State.arff\",delimiter=\",\")\ndata = data[:,:-1].T","b8a1935b":"# Chunk it into sequences\nnchunks = 200\nchunksize = int(data.shape[1] \/ nchunks)\nchunked=[data[:,chunksize*i:chunksize*(i+1)] for i in range(nchunks)]\ndata = torch.tensor(np.array(chunked)).float()#.cuda() when on GPU","5603675c":"# Lets have a look at the shape\nprint(\"Number of samples: \",data.shape[0])\nprint(\"Number of channels: \",data.shape[1])\nprint(\"Length of time sequence: \",data.shape[2])","36731e05":"# lets just use the first 4 channels\ndata = data[:,:4,:]","92a4b745":"# Prepare mask and delta -> delta is not given in the dataset, hence we will use simple assumptions\nmask = torch.ones_like(data).float()\ndelta = torch.ones_like(data).float()\ndelta[:,:,0] = 0","fd836c76":"# Make a ground truth copy\nground_truth = data.detach().clone()\n# remove 5% of the data\nnp.random.seed(5)\nix = [(row,channel, step) for row in range(data.shape[0]) for channel in range(data.shape[1]) for step in range(data.shape[2])]\nnp.random.shuffle(ix)\nto_replace = int(round(.05*len(ix)))\nix = ix[:to_replace]\n\nfor idx in ix:\n    data[idx[0],idx[1],idx[2]] = np.nan\n    mask[idx[0],idx[1],idx[2]] = 0","f5284a4e":"# Plot some sequences\nplt.figure(figsize=(12,8))\nfor pl in range(4):\n    plt.subplot(221+pl)\n    plt.title(\"Sequence {}\".format(pl))\n    plt.xlabel(\"t\")\n    plt.ylabel(\"measurement\")\n    for dim in range(4):\n        plt.plot(np.arange(74),data[pl,dim,:].cpu())\n        plt.plot(np.arange(74),ground_truth[pl,dim,:].cpu(),c=\"grey\",linestyle=\"dashed\",alpha=0.6)","4932122f":"eye_model = MRNN(4,74,32,32,verbose=False,padding=\"replication\").to(device=device)\noptimizer = torch.optim.Adam(eye_model.parameters(),lr=0.005)\nloss_func = nn.MSELoss()\nepochs = 50","ee047d93":"# Fit the model\nlosses = eye_model.fit(epochs,optimizer,loss_func,80,data,mask,delta)","89852733":"# or load existing model\neye_model = MRNN(4,74,32,32).to(device=device)\neye_model.load_state_dict(torch.load(\"..\/input\/eeg-eye-state\/eye_state_model.pt\", map_location=device))","52d6a184":"# plot learning curve\nplt.plot(np.arange(len(losses)),losses)\nplt.yscale(\"log\")\nplt.title(\"Loss curve for EEG dataset\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epochs\")","4aec4b4c":"rec = eye_model.predict(data,mask,delta,replace=True)","26af3ca8":"# Plot result\nplt.figure(figsize=(10,20))\nfor row in range(5):\n    randidx = np.random.randint(0,rec.shape[0])\n    \n    plt.subplot(5,1,(row+1))\n    plt.title(\"Sequence {}\".format(randidx))\n    plt.xlabel(\"t\")\n    plt.ylabel(\"measurement\")\n    missing = (mask[randidx]==0).cpu()\n    for dim in range(4):\n        plt.plot(np.arange(74),ground_truth[randidx,dim,:].cpu(),linestyle=\"dashed\",c=\"grey\",alpha=0.6)\n        plt.plot(np.arange(74),rec[randidx,dim,:].cpu())\n        plt.scatter(np.arange(74)[missing[dim]],rec[randidx,dim,:][missing[dim]].cpu())\nplt.tight_layout()","edf11ae6":"# # Specify a path\n# PATH = \"eye_state_model.pt\"\n\n# # Save\n# torch.save(eye_model.state_dict(), PATH)","1cc93493":"Now we can fit the model using the training data. Unfortunately, the training takes a bit of time (depending on the batchsize, the chosen hidden dimension size and the number of channels), which is why I have a pretrained model available. Extensive training will most likely lead to memory overflow on kaggle. Therefore I have pretrained a model for 500 epochs locally. <b>Use the second cell to load the pretrained model<\/b>. In this notebook, the model will only train for 50 epochs.","ff48ab3c":"<a id=\"motivation\"><\/a>\n## Motivation\n\nThe goal of the M-RNN model is to estimate the missing values in time series data. To do that, the M-RNN solves a sequence to sequence problem, in that the input $x$ (that is potentially missing) should be reconstructed to $\\hat{x}$ with minimal loss as shown in the image below. \n\n![seq2seq.png](attachment:seq2seq.png)\n\nTypically, there are two main approaches to compute missing values in a time series:\n\n- <b>Interpolation<\/b>: These methods use the correlation between measurements at different time steps $t$ <b>within<\/b> one stream $d$ of the time series to predict the missing values. (Examples: [3] [4])\n- <b>Imputation<\/b>: Imputation methods on the other hand exploit information of measurements of the <b>same<\/b> time $t$ but across their different channels to estimate the missing values. (Examples: \\[2\\] \\[5\\]) \n\nWe can see here that both types only exploit a single dimension to estimate the missing values and hence potentially neglect valuable information. The M-RNN model wants to combine both interpolation and imputation to use all possible information to compute the missing values.","634dfaea":"From the formulas above, it looks like we have to compute the interpolater output for each time step and each channel individually. In order to speed this up, we can arrange the weight matrices in a blockdiagonal fashion, where the weights for the channels are one block each, like shown below. This way, we can compute the estimate for every channel at time $t$ for all channels at once. My implementation uses this trick. \n\n$$\\overrightarrow{W} =  \\begin{bmatrix} \\overrightarrow{W}^1 & 0 & ... & 0 \\\\ 0 & \\overrightarrow{W}^2 & ... & 0\\\\ 0&0&...&0 \\\\ ... & ... & ...& ...\\\\ 0&0&...& \\overrightarrow{W}^D\\end{bmatrix}$$\n\n\n\nSince we do not use a standard RNN but use inputs from different time steps, we can not use the RNN PyTorch module here. Instead, we have to implement this behavior ourselves. Because of that, all weights are implemented as \"PyTorch parameters\". A PyTorch implementation of the interpolater can look like the following:","e49de72d":"<a id=\"model\"><\/a>\n## Model\n\nTo do the above task, the authors introduce a novel model called M-RNN, which consists of two components, the interpolater and the imputer. The interpolater uses a Bi-directional Recurrent Neural Network (Bi-RNN) to interpolate missing values within each channel along the time dimension. Afterwards, the imputer will compute an estimate for each time step along all channels using a simple fully connected neural network (FCNN). The image below should show the idea. \n\n![inter-imput.png](attachment:inter-imput.png)\n\nNow the question may rise: <b> How does the model compute $\\hat{x}_{t=n}$ if $x_{t=n}$ is missing? Doesn't it need an input $x$ to compute the output?<\/b>  \nThis is where the contribution of this paper comes into play. \n\n\nLet's look at the interpolater first. In the standard Bi-RNN architecture, the hidden states are calculated by using the hidden state of the previous time step and the observation of the current time step (or the next hidden state and the current observation for the backward direction). In the M-RNN however, the hidden state is calculated using the previous hidden state and also the <b>previous<\/b> observation for the forward RNN, and the next hidden state and <b>next<\/b> observation for the backward RNN. The difference between the models is shown below. \n\n![birnn.png](attachment:birnn.png)\n\n![mrnn.png](attachment:mrnn.png)\n","57d14db7":"Now that the training is finished, we can plot the loss curve to see if the model converges. As we can see, the loss gradually goes down as he model learns how the sequences behave and is able to reconstruct them. (Note that only if you actually fitted the model you will be able to plot the loss. After 50 epochs, the model is not yet converged.)","d744dae2":"<a id=\"combined\"><\/a>\n### Combined Model\n\nWe have now implemented both components of the M-RNN model. We will combine them in a single PyTorch module so that we have a single model that handles the complete training and inference. This class implements a \"fit()\" and \"predict()\" function to train the model and to predict new sequences.","4e56705e":"### Save model\n\nWe could now save the model using the code below.","363fb90d":"<a id=\"real\"><\/a>\n## Train on real dataset\n\nNow that the model is implemented completely, we can train it on real data and see how it works. For this notebook, we use the EEG Eye State Dataset (https:\/\/archive.ics.uci.edu\/ml\/datasets\/EEG+Eye+State). This is a time series dataset that tracks 13 different measures of a person over a certain time, with a binary classification target that is either \"eyes closed\" (0) or \"eyes open\" (1). As we are trying to reconstruct the time series data, we do not need the target variable here.\n\n### Preparation\nFirst, we need to load the data. This will be a single, very long time series.","4cf7ebca":"When all hidden states for all timesteps and channels are computed, the intermediate estimate can be computed by combining the forward and backward hidden states:\n\nIntermediate estimate:  \n$$\\tilde{x}^d_t = ReLU(U^d  [\\overrightarrow{h}_t^d ; \\overleftarrow{h}_t^d ] + c^d_0)$$\n\nWith the weight matrices $U$,$c_0$.  \n\nHere is an example of how to compute the estimation $\\tilde{x}^3_{13}$. We have already computed the forward hidden state $\\overrightarrow{h}_{13}^3$ for this timestep and channel above. Let's assume the backward hidden state is $\\overleftarrow{h}_{13}^3 = \\begin{bmatrix} 0.3 \\\\1.5 \\\\2.75\\end{bmatrix}$. Then, the output of the interpolater is:  \n\n$$\\tilde{x}^3_{13} = ReLU(U^3 \\left[\\begin{pmatrix} 0\\\\0\\\\1.62744989 \\end{pmatrix} ; \\begin{pmatrix} 0.3 \\\\1.5 \\\\2.75\\end{pmatrix} \\right] + c^3_0)$$","c3014e14":"<a id=\"dummy\"><\/a>\n## Train on dummy dataset\n\nLet's try out the model on the dummy dataset from the beginning to the end, and test out how the algorithm works.  \n\nAs mentioned above, the loss will be the reconstruction loss between our estimated points $\\hat{x}$ and the ground truth $x$. If we minimize this loss, we are getting better and better at correctly estimating the points. As we can only learn from samples that we actually measured (if $x_t$ is missing, we have no ground truth and can't compute the loss), we use the mask to hide missing samples when computing the loss. This will result in the following loss function:\n\n$$ \\mathcal{L}(x,\\hat{x}) = \\frac{1}{N} \\sum_{n=1}^N m(n) * (\\hat{x}(n) - x(n))^2$$","e1c5bcf5":"This architecture makes sure that we <b>never use the current observation to compute its hidden state representation<\/b>. Hence, to compute the intermediate estimated value $\\tilde{x}_t$, we will never use information from $x_t$, so it does not matter whether we have actually measured this point or not. \n\nNext, we look at the imputer. As said above, we use a simple FCNN to implement this component. The imputer takes the intermediate estimations $\\tilde{x}_t$ and outputs the final point estimates $\\hat{x}$. The image below shows the intuition behind the imputer.\n\n![imputer.png](attachment:imputer.png)\n","6de8613e":"<a id=\"ref\"><\/a>\n## References \/ Literature\n\n[1] Z. Che, S. Purushotham, K. Cho, D. Sontag, and Y. Liu, \u201cRecurrent neural networks for multivariate time series with missing\nvalues\". 2016.\n\n[2] F. Gingras and Y. Bengio, \u201cRecurrent neural networks for missing or asynchronous data\u201d. 1996.\n\n[3] D. M. Kreindler and C. J. Lumsden, \u201cThe effects of the irregular sample and missing data in time series analysis\u201d. 2012.\n\n[4] S. Parveen and P. Green, \u201cSpeech recognition with missing data using recurrent neural nets\u201d.2001.\n\n[5] D. B. Rubin \"Multiple imputation for nonresponse in surveys\".1987.\n\n[6] J. Yoon, W. R. Zamey, M. van der Schaar , \"Estimating Missing Data in Temporal Data Streams Using Multi-directional Recurrent Neural Networks\". 2017.\n\n[7] https:\/\/github.com\/jsyoon0823\/MRNN, Original code of M-RNN by Yoon et al.\n\n[8] Wei Cao, Dong Wang, Jian Li, Hao Zhou, Lei Li and Yitan Li, \"BRITS: Bidirectional Recurrent Imputation for Time Series\". 2018.\n\n[9] Vincent Fortuin, Dmitry Baranchuk, Gunnar R\u00e4tsch and Stephan Mandt, \"GP-VAE: Deep Probabilistic Multivariate Time Series Imputation\". 2020.","514b02d8":"This dataset does not have any missing values. For training the model that does not matter, as the model acts as if the points were missing. Nonetheless, it would be nice to see how it fills missing values when there are some. So let's just delete some points.\n","e1da899f":"The code below will start an interactive training, showing how the predictions change over the course of the training.","5295bcfb":"<a id=\"inter\"><\/a>\n### Interpolater\n\nFirst, we implement the interpolater network. As said earlier, we use a Bi-RNN, but lag the input from $t-1$ for the forward RNN and from $t+1$ for the backward RNN. Because we interpolate independently within each channel, <b>we learn one set of weights for each channel<\/b>. This network can be described with the following formulas (taken from the paper):\n\nHidden states:  \n$$\\overrightarrow{h}_t^d = ReLU(\\overrightarrow{W}^d  \\overrightarrow{h}_{t-1}^d + \\overrightarrow{V}^d  z^d_{t-1} + \\overrightarrow{c}^d)$$ \n$$\\overleftarrow{h}_t^d = ReLU(\\overleftarrow{W}^d  \\overleftarrow{h}_{t+1}^d + \\overleftarrow{V}^d  z^d_{t+1} + \\overleftarrow{c}^d) $$\n\nWith the weight matrices $\\overleftarrow{W}$, $\\overrightarrow{W}$,$\\overleftarrow{V}$, $\\overrightarrow{V}$,$\\overleftarrow{c}$, $\\overrightarrow{c}$.  \nWhere $z^d_t = [x^d_t,m^d_t,\\delta^d_t]$ the concatenation of the input.  \n\n<br><br>\nUsing our dummy dataset, let's compute the forward hidden state for the time step $t=13$ in the third channel $d=3$. Let's assume we use a hidden dimension size of 3 and the previous hidden state of the third channel was $\\overrightarrow{h}_{12}^3 = \\begin{bmatrix} 2 \\\\4 \\\\3\\end{bmatrix}$. Then, the next hidden state is:\n\n$$\\overrightarrow{h}_{13}^3 = ReLU(\\overrightarrow{W}^3  \\overrightarrow{h}_{12}^3 + \\overrightarrow{V}^3  z^3_{12} + \\overrightarrow{c}^3) = ReLU (\\overrightarrow{W}^3 \\begin{bmatrix} 2 \\\\4 \\\\3\\end{bmatrix} + \\overrightarrow{V}^3 \\begin{bmatrix} 1.6247 \\\\1 \\\\1\\end{bmatrix} + \\overrightarrow{c}^3)$$ \n\n<b>Please note that I use hardcoded weighhts in the examples taken from a pretrained model.<\/b>","d22e6c90":"<a id=\"implementation\"><\/a>\n## Implementation\n\nNow that we have understood the idea of M-RNN, we can implement the model. In the implementation of the authors, GRU cells are used, but here we stick to vanilla RNN for simplicity purposes. We will use PyTorch to implement the model and make use of the autograd feature of PyTorch to train the model. In the end, we will have a ready to use PyTorch Module of the M-RNN method.","28bbd4d2":"### Plot the reconstruction\n\nWe can now plot examples of how the model reconstructs the input. In the plots, the circles are the esstimated measurements of the missing values in the series. The grey dashed lines are ground truth. We can see that even though the model was only trained on 4 channels, with limited capacity and with no hyperparameter optimization, the sequences are mostly reconstructed nicely.","372e2f43":"Throughout the implementation, I will try to demonstrate the computations with a very small example before we apply the method to a real dataset:","bd0d4a92":"Now we can have a look at how the data looks. Let's plot some sequenecs: ","a1164c36":"<a id=\"imp\"><\/a>\n### Imputer\n\nNow that the interpolater is implemented, we can implement the imputer module. This one is much easier, as we can use the standard Linear layers of PyTorch as our fully connected network. In formulas, the imputer looks as follows (again, taken and simplified from the paper):\n\n$$h_t = ReLU(U x_t + V^1 \\tilde{x}_t + V^2 m_t + \\beta)$$\n$$\\hat{x}_t = W h_t + \\alpha$$\n\nWith $z_t = [\\tilde{x}_t, m_t]$ the concatenation of the interpolater output and the mask.  \nWith weight matrices $U$, $V^1$, $V^2$ and $W$ and biases $\\beta$ and $\\alpha$.  \n\nAs we can see, we also use the observed measures $x$ here as well. To make sure we do <b> not <\/b>use $x_t^d$ to compute $\\hat{x}^d_t$, the weight matrix $U$ must have $0$'s on the diagonal. This makes sure that the estimated point again does not use any information of the ground truth, as this point might be missing.\n\nSo for example:\n\n$$ U * x_{t=1} = \\begin{bmatrix} 0 & U_{1,2}  & ... & U_{1,D} \\\\\n                                  U_{2,1} & 0 & ... & U_{2,D} \\\\  U_{3,1} & U_{3,2} & ... & U_{3,D}\\\\\n                                  ... & ... & ... & ...\\\\\n                                  U_{D,1} & U_{D,2} & ... & 0\\end{bmatrix}  * \\begin{bmatrix} x_1^1 \\\\ x_1^2 \\\\x_1^3 \\\\ ... \\\\x_1^D \\end{bmatrix} $$   \n                                  \n<br>           <br>                       \n                                  \nUsing our dummy example, we can compute the final output $\\hat{x}_{13}$ now. We have already computed the intermediate estimate $\\tilde{x}_{13}^3$ above. To compute the final output, we need the intermediate estimate of this timestep from all other channels. Let's assume $\\tilde{x}_{13}^1 = \\begin{bmatrix} 1.125\\end{bmatrix}$ and $\\tilde{x}_{13}^2 = \\begin{bmatrix} 0.565\\end{bmatrix}$. Then, the final hidden output will be:\n\n$$h_{13} = ReLU\\left( \\quad\\begin{bmatrix} 0 & U_{1,2} & U_{1,3} \\\\ U_{2,1} & 0 & U_{2,3}\\\\ U_{3,1} & U_{3,2} & 0\\end{bmatrix} \\begin{bmatrix} 2 \\\\ 4 \\\\ 3\\end{bmatrix} \\quad + \\quad\\begin{bmatrix} V^1_{1,1} & V^1_{1,2}& V^1_{1,3} \\\\ V^1_{2,1} & V^1_{2,2} & V^1_{2,3} \\\\ V^1_{3,1}& V^1_{3,2}& V^1_{3,3}\\end{bmatrix} \\begin{bmatrix}  1.125 \\\\ 0.565 \\\\1.642 \\end{bmatrix}\\quad + \\quad\\begin{bmatrix} V^2_{1,1} & V^2_{1,2}& V^2_{1,3} \\\\ V^2_{2,1} & V^2_{2,2} & V^2_{2,3} \\\\ V^2_{3,1}& V^2_{3,2}& V^2_{3,3}\\end{bmatrix} \\begin{bmatrix} 1\\\\1\\\\1 \\end{bmatrix}\\quad + \\quad\\begin{bmatrix} \\beta^1\\\\\\beta^2\\\\ \\beta^3 \\end{bmatrix}\\quad\\right)$$ \n\n","ba3def26":"Let's plot the reconstruction! (Keep in mind we highly overfit here)","1abe7ab5":"<a id=\"conclusion\"><\/a>\n## Conclusion and thoughts about further improvements\n\nThis notebook intended to show the idea of M-RNN and a way to implement a simple version of it. We saw how the model uses a bi-directional RNN and a fully connected network to estimate missing values in time series data. Here are some thoughts of mine on how to further improve the model shown here. If you are intereseted in the full model from the authors, have a look at \\[7\\].\n\n- Scale\/Normalize all features (we didnt do this for visibility purposes).\n- Add Regularization for better generalization (in the paper dropout is used).\n- Learn initial hidden state $h_{t=0}$ and $h_{t=T+1}$ as well as initial actual state $x_{t=0}$ and $x_{t=T+1}$. In normal RNN, we can also learn the initial hidden states, but in M-RNN, because we always use $x_{t-1}$ or $x_{t+1}$ as input (and not $x_t$ itself), we can treat those as learnable parameters as well. The authors don't mention how to deal with this. In my implementation, we simply use a replication padding that copies the first and last inputs.\n- Use GRU cells instead of RNN (as the authors do in their implementation).\n- Use more hidden layers (in our example, we only use one hidden layer in the interpolater, and one hidden layer in the imputer).\n- Use a different, more complex initial interpolation.\n\n<b>Thank you for reading! If you have any questions or feedback to the notebook and the method, feel free to drop a comment below.<\/b>\n","2bf50f15":"# From scratch: Estimating Missing Data in Temporal Data Streams Using Multi-directional Recurrent Neural Networks\n\nIn this notebook, I want to show a simple implementation of the method from the paper \"Estimating Missing Data in Temporal Data Streams Using Multi-directional Recurrent Neural Networks\" by Yoon et al. 2017. The authors use a custom version of Recurrent Neural Networks (RNN) to estimate missing values in time series data. Their model is called M-RNN.\n\nPaper by: Jinsung Yoon, William R. Zamey, and Mihaela van der Schaar  \nPublished in: IEEE Transactions on Biomedical Engineering  \nYear: 2017  \nArxiv link: https:\/\/arxiv.org\/abs\/1711.08742\n\n## Table of contents\n\n* [Notation](#notation)\n* [Motivation](#motivation)\n* [Model](#model)\n* [Implementation](#implementation)\n    - [Interpolater](#inter)\n    - [Imputer](#imp)\n    - [Combined Model](#combined)\n    - [Initial interpolation](#init)\n* [Training on dummy dataset](#dummy)\n* [Training on real dataset](#real)\n* [Conclustion and further improvements](#conclusion)\n* [References](#ref)\n\n\n<a id=\"notation\"><\/a>\n## Notation\n\nBefore we start, we need to define some notation that will be used throughout the notebook. I will try to stick to the same notation that the authors use in the paper.  \n\nA dataset consists of $N$ time series with $D$ channels and length $T$.  \n\n$$X_n = \\begin{bmatrix} 2 &4 &8 & \\ast \\\\ 5 & \\ast & 9 & 10 \\end{bmatrix} \\quad D= 2 , T=4$$\n\nMissing values:\n$$x_t^d = \\ast$$\n\nA binary mask is defined to mark missing values (1 if data is observed, 0 if missing):\n$$m =   \\begin{bmatrix} 1 &1 &1 & 0 \\\\ 1 & 0 & 1& 1 \\end{bmatrix}$$\n\nAlso, the time elapsed since the last measurement in this channel is defined:\n\n$$\\delta = \\begin{bmatrix} 0 &1 &1.2 & 1 \\\\ 0 & 1 & 3 & 1.4 \\end{bmatrix}$$","8f529a57":"Finally, the hidden state is forwarded a last time to compute the final estimate $\\hat{x}$:\n\n$$ \\hat{x}_{13} = \\begin{bmatrix} W_{1,1} & W_{1,2}& W_{1,3} \\\\ W_{2,1} & W_{2,2} & W_{2,3} \\\\ W_{3,1}& W_{3,2}& W_{3,3}\\end{bmatrix}  \\begin{bmatrix} h_{13}^1 \\\\ h_{13}^2 \\\\h_{13}^3 \\end{bmatrix} +  \\begin{bmatrix} \\alpha\\end{bmatrix} $$","052029f0":"Let's see what the output of the interpolater looks like on our dummy dataset:","05e84c53":"<a id=\"init\"><\/a>\n### Initial interploation needed\n\nBefore we can train a model and test the code, there is one last thing that we have to do. If we have missing data in $x_t$, then we have no input for the next point estimate $x_{t+1}$. The authors do not provide information on how to solve this, so there are two options:\n\n- if $x_t$ is missing, use the last actual observed measurement $x_{t-n}$ to compute $\\hat{x}_t$.\n- Use a simple initial interpolation method like linear interpolation to have a value to compute with.\n\nWe will use the second option for simplicity purposes, as the first method makes the implementation more complicated and less efficient. We can find that the authors also use the second option in their Tensorflow implementation [7] (from the best of my knowledge).","0551a733":"Again, we can see what the final imputer output looks like:","31325647":"### Training","1a7d4c48":"We can see that the imputer outputs the predicted reconstruction of all channels in one timestep (which is why we have 3 values in the output, because we have 3 channels). The complete implementation in PyTorch may look like this:","e0a68282":"As we can see, we have 200 samples with length 74 and 14 channels (+ target). For runtime and visualization purposes, let's just use the first 4 channels for this exercise.","540964fa":"Next, we will chop the time series into 200 chunks, so that we have 200 multivariate samples.","c0c9067e":"## More papers about missing values in time series\n\nIf you are interested in missing values in time series data, here are some other interesting papers that deal with this problem.\n\n- BRITS model, that also uses bi-RNN's to estimate missing values, but treat the missing values as learnable parameters \\[8\\].\n- GP-VAE, which use the idea of VAE's to capture temporal dynamics and correlations in a lower dimensional latent space and reconstruct missing values from there \\[9\\]."}}