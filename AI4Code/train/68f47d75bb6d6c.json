{"cell_type":{"2a874a47":"code","f9a26ce4":"code","4971c279":"code","220821c1":"code","11424d9a":"code","b9cc2af0":"code","6b93023f":"code","f78439e8":"code","fb6c78b8":"code","9d235d9f":"code","c2c981d5":"code","bf69dc6e":"code","5c392def":"code","124cf9d1":"code","4171a494":"code","9683a34d":"code","736b59c6":"code","d11b1ec3":"code","919bfec1":"code","4e8e35e0":"code","01082210":"code","7f8c7df4":"code","2a617ca2":"code","8fbacd17":"code","9f9f0552":"markdown","c529ff33":"markdown","04a20a90":"markdown"},"source":{"2a874a47":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\nfrom sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve\nfrom sklearn.preprocessing import StandardScaler , Binarizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\nimport time\nimport os, sys, gc, warnings, random, datetime\nimport math\nimport shap\nimport joblib\nwarnings.filterwarnings('ignore')\nimport gc\n","f9a26ce4":"# !pip install --upgrade git+https:\/\/github.com\/stanfordmlgroup\/ngboost.git\n    \n# from ngboost import NGBRegressor, NGBClassifier\n# from ngboost.ngboost import NGBoost\n# from ngboost.learners import default_tree_learner\n# from ngboost.scores import CRPS, MLE , LogScore\n# from ngboost.distns import LogNormal, Normal\n# from ngboost.distns import k_categorical, Bernoulli\n","4971c279":"df = pd.read_pickle(\"..\/input\/handling-imbalanced-data-eda-small-fe\/df_for_use.pkl\")\ndf_fe = pd.read_pickle(\"..\/input\/handling-imbalanced-data-eda-small-fe\/df_fe.pkl\")","220821c1":"lgbm_clf = joblib.load('..\/input\/handling-imbalanced-data-supervised-learning\/lgbm_clf.pkl')\nrf_clf = joblib.load('..\/input\/handling-imbalanced-data-supervised-learning\/rf_clf.pkl')\nxgb_clf = joblib.load('..\/input\/handling-imbalanced-data-supervised-learning\/xgb_clf.pkl')\n# ngb_clf = joblib.load('..\/input\/handling-imbalanced-data-supervised-learning\/ngb_clf.pkl')\n","11424d9a":"X = df.drop('loan_condition_cat', axis=1)\ny = df['loan_condition_cat']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2 , random_state = 2020, stratify = y)\n","b9cc2af0":"y_trainin = y_train.to_frame()\nfor_sample_train_df = pd.concat([X_train, y_trainin], axis=1)\ny_testet = y_test.to_frame()\nfor_sample_test_df = pd.concat([X_test, y_testet], axis=1)\n","6b93023f":"\n\nX_ = for_sample_train_df.drop('loan_condition_cat', axis=1)\ny_ = for_sample_train_df['loan_condition_cat']\n\nsample_train_x, sample_test_x, sample_train_y, sample_test_y = train_test_split(X_, y_, test_size = 0.8 , random_state = 2020, stratify = y_)\n\ndel X_train, X_test, y_train, y_test , y_trainin, y_testet, ","f78439e8":"gc.collect()","fb6c78b8":"## Make sample for faster computation\n\nX_ = for_sample_train_df.drop('loan_condition_cat', axis=1)\ny_ = for_sample_train_df['loan_condition_cat']\n\nsample_train_x, sample_test_x, sample_train_y, sample_test_y = train_test_split(X_, y_, test_size = 0.95 , random_state = 2020, stratify = y_)","9d235d9f":"## Make sample for faster computation\n\nX = for_sample_train_df.drop('loan_condition_cat', axis=1)\ny = for_sample_train_df['loan_condition_cat']\n\nsample_train_x_smaller, sample_test_x_smaller, sample_train_y_smaller, sample_test_y_smaller = train_test_split(X, y, test_size = 0.98 , random_state = 2020, stratify = y)","c2c981d5":"X_sampled = sample_train_x.copy()","bf69dc6e":"X_sampled_smaller = sample_train_x_smaller.copy()","5c392def":"#LightGBM\nimport shap\nshap.initjs()\n\n# (same syntax works for LightGBM, CatBoost, and scikit-learn models)\n\nexplainer = shap.TreeExplainer(lgbm_clf)\nshap_values = explainer.shap_values(X_sampled)","124cf9d1":"shap.force_plot(explainer.expected_value[1], shap_values[1][2,:], X_sampled.iloc[2,:])","4171a494":"shap.force_plot(explainer.expected_value[1], shap_values[1][3,:], X_sampled.iloc[3,:])","9683a34d":"shap.force_plot(explainer.expected_value[1], shap_values[1][4,:], X_sampled.iloc[4,:])","736b59c6":"shap.force_plot(explainer.expected_value[1], shap_values[1][5,:], X_sampled.iloc[5,:])","d11b1ec3":"shap.force_plot(explainer.expected_value[1], shap_values[1][1650,:], X_sampled.iloc[1650,:])","919bfec1":"shap.decision_plot(explainer.expected_value[1], shap_values[1][0,:], X_sampled.iloc[0,:])","4e8e35e0":"# summarize the effects of all the features\nshap.summary_plot(shap_values, X_sampled, plot_type=\"bar\")","01082210":"shap.dependence_plot(\"total_rec_prncp\",shap_values[1], X_sampled)","7f8c7df4":"shap.dependence_plot(\"interest_rate\",shap_values[1], X_sampled)","2a617ca2":"shap.dependence_plot(\"grade_cat\",shap_values[1], X_sampled)","8fbacd17":"# (same syntax works for LightGBM, CatBoost, and scikit-learn models)\nshap.initjs()\nexplainer = shap.TreeExplainer(lgbm_clf)\nshap_values = explainer.shap_values(X_sampled_smaller)\n\n\nshap.force_plot(base_value=explainer.expected_value[1], shap_values=shap_values[1], features=X_sampled_smaller.columns)","9f9f0552":"### LightGBM Report","c529ff33":"## SHAP","04a20a90":"#### Data fork from previous EDA kernel \nhttps:\/\/www.kaggle.com\/possiblemanjr\/handling-imbalanced-data-eda-small-fe\n\n#### trained model from following kernels\n\nhttps:\/\/www.kaggle.com\/possiblemanjr\/handling-imbalanced-data-supervised-learning"}}