{"cell_type":{"49821c4b":"code","45513033":"code","b681a42b":"code","115b08b9":"code","8b9afd21":"code","0e58d2c3":"code","31f02289":"code","7f2b97ec":"code","666361bb":"code","9a6ec5ae":"code","96904004":"code","ba3b98a4":"code","b40a5c5d":"code","e547d72e":"code","2140f871":"code","ab3036d0":"code","e01243dd":"code","a06a40b5":"code","e7bdf3e8":"code","bf81c3d8":"code","0cb75671":"code","ed60969f":"code","7f439093":"code","30dcb2a4":"code","9c2ab146":"code","0d0e4d89":"code","3bed5319":"code","86539589":"code","e3422fec":"code","31b53f49":"code","a38f1ecc":"code","7d9e89cc":"code","fd87ca8a":"code","fdb50533":"code","f5552270":"code","ff51e740":"code","4b12a2ce":"code","a492b64d":"markdown","da864a5c":"markdown","d7a0465f":"markdown","aab07e88":"markdown","07a2808c":"markdown","6f15a0da":"markdown","49e00b5a":"markdown","38abb70a":"markdown","964a2294":"markdown","9bdba1ea":"markdown","fe88684d":"markdown","422cd7f5":"markdown","583c447a":"markdown","e3177346":"markdown","0739acc5":"markdown","29b0ba11":"markdown","e1eaf782":"markdown","712d67db":"markdown","402876eb":"markdown","848f777b":"markdown","90bfa2d3":"markdown","715ba0d9":"markdown","a3f685c8":"markdown","230b1242":"markdown","3409a3e9":"markdown","bc5acd9b":"markdown","e75c3203":"markdown"},"source":{"49821c4b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport matplotlib.pyplot as plt # visualizations","45513033":"data = pd.read_csv('..\/input\/factors-affecting-campus-placement\/Placement_Data_Full_Class.csv')","b681a42b":"data.head(5)","115b08b9":"data.info()","8b9afd21":"data.gender.value_counts()","0e58d2c3":"data.ssc_b.value_counts()","31f02289":"data.hsc_b.value_counts()","7f2b97ec":"data.hsc_s.value_counts()","666361bb":"data.degree_t.value_counts()","9a6ec5ae":"data.workex.value_counts()","96904004":"data.specialisation.value_counts()","ba3b98a4":"data.status.value_counts()","b40a5c5d":"from sklearn.preprocessing import LabelEncoder","e547d72e":"label = LabelEncoder()\ndata[\"gender\"] = label.fit_transform(data[\"gender\"])\ndata[\"ssc_b\"] = label.fit_transform(data[\"ssc_b\"])\ndata[\"hsc_b\"] = label.fit_transform(data[\"hsc_b\"])\ndata[\"hsc_s\"] = label.fit_transform(data[\"hsc_s\"])\ndata[\"degree_t\"] = label.fit_transform(data[\"degree_t\"])\ndata[\"workex\"] = label.fit_transform(data[\"workex\"])\ndata[\"specialisation\"] = label.fit_transform(data[\"specialisation\"])\ndata[\"status\"] = label.fit_transform(data[\"status\"])","2140f871":"data.head()","ab3036d0":"data.hist(figsize = (20, 20))\nplt.show()","e01243dd":"import seaborn as sns","a06a40b5":"sns.heatmap(data.corr())\nplt.show()","e7bdf3e8":"import plotly.express as px","bf81c3d8":"data_original = pd.read_csv('..\/input\/factors-affecting-campus-placement\/Placement_Data_Full_Class.csv')","0cb75671":"fig = px.scatter(data_original, x=\"salary\", \n                 color=\"degree_p\",\n                 size='degree_p', \n                 hover_data=['gender', 'ssc_p', 'hsc_p', 'hsc_b', 'hsc_s', 'degree_t', 'workex', 'degree_p', \n                            'specialisation', 'mba_p', 'status', 'etest_p'], \n                 title = \"Salary Plot\")\nfig.show()","ed60969f":"fig = px.scatter(data_original, x=\"ssc_p\", \n                 color=\"degree_p\",\n                 size='degree_p', \n                 hover_data=['gender', 'hsc_p', 'hsc_b', 'hsc_s', 'degree_t', 'workex', 'degree_p', \n                            'specialisation', 'mba_p', 'status', 'etest_p'], \n                 title = \"ssc_p Plot\")\nfig.show()","7f439093":"data.info()","30dcb2a4":"X = data.iloc[:, 0:13].values\ny = data.iloc[:, 13].values","9c2ab146":"y","0d0e4d89":"X","3bed5319":"from sklearn.ensemble import ExtraTreesClassifier\nmodel = ExtraTreesClassifier()\nmodel.fit(X , y)","86539589":"print(model.feature_importances_) ","e3422fec":"feat_importances = pd.Series(model.feature_importances_)\nfeat_importances.nlargest(10).plot(kind='barh')\nplt.show()","31b53f49":"print(\"Maximum important feature index is : \", model.feature_importances_.argmax()) ","a38f1ecc":"from sklearn.tree import DecisionTreeClassifier","7d9e89cc":"clf = DecisionTreeClassifier()\nclf.fit(X, y)","fd87ca8a":"y_pred = clf.predict(X)","fdb50533":"y_pred","f5552270":"from sklearn.metrics import confusion_matrix","ff51e740":"cm = confusion_matrix(y, y_pred)","4b12a2ce":"cm","a492b64d":"We can see the accuracy by confusion matrix also lets do it ","da864a5c":"**YOUR UPVOTE IS MY ENCOURAGEMENT OF MAKING NOTEBOOKS**","d7a0465f":"We use DecisionTreeClassifier from sklearn library. As we see that it is a classification problem and we do it by this function.","aab07e88":"You can see our Classifier has great accuarcy. Just by the ssc_p we can predict the candidate is placed or not.\nIf you like this notebook please upvote.","07a2808c":"Let's first visualize the status of the candidate.","6f15a0da":"Divide the datset into our data and labels i.e X and y .","49e00b5a":"Till then **Enjoy Machine Learning**","38abb70a":"In this dataset we have to analyze and visualize the dataset and predict whether you are placed or not.","964a2294":"As we see in the dataset, there are some categorical features i.e. gender, ssc_b, hsc_s, status etc. So we have to do some preprocessing in that columns. And we can do this little bit of preprocessing by using **sklearn library( LabelEncoder )**.","9bdba1ea":"Let's start making model to predict whether a candidate is placed or not.","fe88684d":"Here is the new library for displaying the dataset to show which feature has more importance.","422cd7f5":"Let's see the graph and which has great importances?","583c447a":"If you do not know what is LabelEncoder so don't worry. I explain. LabelEncoder is in built function that converts the categories into some numerical values i.e. M in gender column so labelencoder converts this \"M\" into 0 and F into 1 so this is the real encoding of the categorical features in the datasets.","e3177346":"First we need to import some libraries that will help in visualizing and analyzing techniques on the given dataset.\nLibraries : \n* Numpy\n* Pandas\n* Matplotlib\n* Sklearn\n* Seaborn","0739acc5":"Here is the index of that column i.e 2","29b0ba11":"Oh its 2nd column i.e **ssc_p**","e1eaf782":"Here is one more type of showing which feature is more important. Using ExtraTreeClassifier it is easy to know which is best or having great importance.","712d67db":"**Why only gender ?** Have a look at all the categorical values in all columns.","402876eb":"Feature Selection is a process of extracting features from the dataset that have great importance of predicting our labels.","848f777b":"Let's have a look at all the values in columns i.e. categorical values( suppose in gender column there are two categories M or F ). By this **value_counts()** function we can see how many values of \"M\" are in the column and \"F\" are in the column of gender.","90bfa2d3":"# Campus Recruitment Visualizations","715ba0d9":"Have a look our predictions that have made by our decision tree classifier.","a3f685c8":"Now all done","230b1242":"A small visual of the dataset is to plot a histogram of all the columns of dataset. All the columns I mean that columns which have integers values. Have a look at the small visual part of our dataset. This can do simply by a matplotlib function i.e \"**your_data_name.hist()**\" and then write plt.show()","3409a3e9":"In this dataset our first question is which factor influenced a candidate of getting placed or not ? and the answer of this question is **FEATURE SELECTION** This is the part of Analyzing the dataset. So lets do the Feature Selection.","bc5acd9b":"Here I have finished this encoding.\nGood we have completed our first major step.\nHave a look at the dataset now after some preprocessing part.","e75c3203":"Have a look at all the feature's importances."}}