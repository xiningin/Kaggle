{"cell_type":{"80743c07":"code","62d9d09d":"code","27a197f6":"code","fbd6a2eb":"code","c4d154d6":"code","33109044":"code","f151084b":"code","72ac02a9":"code","4f789f49":"code","edf6c92f":"code","fc3f2ed0":"code","d849f333":"code","3049ecea":"code","3e375091":"code","c7a852df":"code","4fbe630d":"code","d0e5ee8a":"code","c36dd7af":"code","cc426e4b":"code","0bd5a62d":"code","354dc3a9":"code","fb8acb38":"code","cc13a19f":"code","ecadf129":"code","836bb6bf":"code","d9ff01d6":"code","ee7f751e":"code","d95d29c7":"code","885ca4a3":"code","21713936":"code","ad1069d0":"code","e79f399e":"code","11edfa8a":"code","7ba7d344":"code","b5a08350":"code","4a2f3cc7":"code","2069e0af":"code","438f8351":"code","ef7a7bd1":"code","7a63c2f7":"code","5c178e46":"code","e56fda5c":"code","221db19f":"code","375911af":"code","431ff1dd":"code","5146128b":"code","9200d924":"code","485e1c0c":"code","4afb3453":"code","889ee5ee":"code","1d533633":"code","b6addd02":"code","7a252c63":"code","450b2615":"code","b7f01ab9":"code","20feb79b":"code","74c0e2b5":"code","16e754d0":"markdown","1c43628e":"markdown","6a47ba78":"markdown","f1935382":"markdown","b60c2f71":"markdown","63d8978b":"markdown","caab3a64":"markdown","e20a36ac":"markdown","7eebfe24":"markdown","928628af":"markdown","d9606771":"markdown","67f8d41c":"markdown","ece804d3":"markdown","ef7eabf7":"markdown","616c1328":"markdown","148001eb":"markdown","5d003345":"markdown","edec5f68":"markdown","31d7b699":"markdown","73568825":"markdown","c3502e61":"markdown","966b0369":"markdown","1c60b278":"markdown","70c39bd9":"markdown","5aee7381":"markdown","098ef272":"markdown","9599bb34":"markdown","9ad6f67c":"markdown","a83e1984":"markdown","e6487d67":"markdown","9d259e8a":"markdown","816ab2ae":"markdown","5c3088af":"markdown","aa8e0e78":"markdown","856b0a1d":"markdown"},"source":{"80743c07":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","62d9d09d":"import pandas as pd\nimport numpy as np\nimport os\npd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n\nimport warnings\nwarnings.filterwarnings('ignore')","27a197f6":"posts = pd.read_csv('..\/input\/posts.csv')\nposts.rename(columns={'_id':'post_id', ' post_type':'post_type'}, inplace=True)\nposts.category.fillna(\"General\", inplace = True) \nposts.head()","fbd6a2eb":"print(posts.shape)\nposts.info()","c4d154d6":"users = pd.read_csv('..\/input\/users.csv')\nusers.rename(columns={'_id':'user_id'}, inplace=True)\nusers.head()","33109044":"print(users.shape)\nusers.info()","f151084b":"views = pd.read_csv('..\/input\/views.csv')\nviews.head()","72ac02a9":"print(views.shape)\nviews.info()","4f789f49":"df = views.merge(posts, on='post_id', how='left')\ndf.head()","edf6c92f":"df = df.merge(users, on='user_id', how='left')\ndf.head()","fc3f2ed0":"df.shape","d849f333":"df.info()","3049ecea":"df1 = df[df.isna().any(axis=1)]\ndf.shape","3e375091":"df = df.dropna(thresh=8)\ndf.shape","c7a852df":"# df.head()","4fbe630d":"df.category.value_counts()","d0e5ee8a":"# df = df.drop(columns=['name', 'timestamp'])\n# df = df.reset_index(drop=True)\n# df.head()","c36dd7af":"df.shape","cc426e4b":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# plot stylings\nplt.style.use('fivethirtyeight')\n%matplotlib inline","0bd5a62d":"pd.crosstab(df.title, df.gender, margins=True).style.background_gradient(cmap='summer_r')","354dc3a9":"fig, ax = plt.subplots(1,2,figsize = (10,6))\n\nsns.countplot('gender',data=df,ax=ax[0])\nax[0].set_title('Posts viewed by Gender')\n\ndf['gender'].value_counts().plot.pie(explode=[0,0.1,0],autopct='%1.1f%%',shadow=True,ax=ax[1])\nax[1].set_title('Posts viewed by Gender')\nax[1].axis('equal') \n\nfig.tight_layout()\nplt.show()","fb8acb38":"pd.crosstab(df.title, [df.academics, df.gender], margins=True).style.background_gradient(cmap='summer_r')","cc13a19f":"fig, ax = plt.subplots(figsize = (10,8))\nsns.countplot('academics',hue='gender',data=df)\nax.set_title('Gender and Academics')\n\nfig.tight_layout()\nplt.show()","ecadf129":"# Displaying top categories\nrest, keys, values = 0, [], []\nx = df.category.value_counts()\nfor i,j in x.items():\n    if j>=10:\n        keys.append(i)\n        values.append(j)\n    else:\n        rest += j\nkeys.append('Remaining')\nvalues.append(rest)\n# print(len(keys))\n# print(len(values))","836bb6bf":"fig, ax = plt.subplots(figsize = (10, 15))\ny_pos = np.arange(len(values))\nax.barh(y_pos, values[::-1], color = ['b'], alpha=0.99)\nax.set_yticks(y_pos)\nax.set_yticklabels(keys[::-1])\nax.set_xlabel('Number of posts')\nax.set_title('Top Categories')\n\nplt.show()","d9ff01d6":"fig, ax = plt.subplots(figsize = (10,8))\n\ndf['post_type'].value_counts().plot.pie(autopct='%1.1f%%',shadow=True)\nax.set_title('Popular post types')\nax.axis('equal') \n\nfig.tight_layout()\nplt.show()","ee7f751e":"# Importing required libraries\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel ","d95d29c7":"tf = TfidfVectorizer(analyzer='word', sublinear_tf=True, ngram_range=(1, 3), min_df=0, stop_words='english')\ntfidf_matrix = tf.fit_transform(posts['category'])\ntfidf_matrix.shape","885ca4a3":"tf.get_feature_names()[:-30:-1]","21713936":"cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)\ncosine_similarities[0]","ad1069d0":"postid = posts['post_id']\nindices = pd.Series(posts.index, index=posts['post_id'])\nindices.head()","e79f399e":"def item(id):\n    return posts.loc[posts['post_id'] == id]['title'].tolist()[0]","11edfa8a":"def get_recommendations(postid, num, indices):\n    idx = indices[postid]\n    sim_scores = list(enumerate(cosine_similarities[idx]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    sim_scores = sim_scores[1:num+1]\n    # print(sim_scores)\n    indices = [i[0] for i in sim_scores]\n    print(\"Recommending \" + str(num) + \" posts similar to \\\"\" + item(postid) + \"\\\" ...\")\n    return posts.iloc[indices]","7ba7d344":"# Attempt 1\nget_recommendations('5eac305f10426255a7aa9dd3', 10, indices)","b5a08350":"# Attempt 2\nget_recommendations('5d6d39567fa40e1417a4931c', 10, indices)","4a2f3cc7":"# posts.head()","2069e0af":"posts['soup'] = posts['title'] + \" \" +posts['category'] + \" \" +posts['post_type']\nposts.head()","438f8351":"tf = TfidfVectorizer(analyzer='word', sublinear_tf=True, ngram_range=(1, 8), min_df=0, stop_words='english')\ntfidf_matrix = tf.fit_transform(posts['soup'])\ntfidf_matrix.shape","ef7a7bd1":"cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)\ncosine_similarities[0]","7a63c2f7":"# posts.head()","5c178e46":"postid = posts['post_id']\nindices = pd.Series(posts.index, index=posts['post_id'])\n# indices.head()","e56fda5c":"# Attempt 3\nget_recommendations('5eac305f10426255a7aa9dd3', 10, indices)","221db19f":"# Attempt 4\nget_recommendations('5d6d39567fa40e1417a4931c', 10, indices)","375911af":"df.head()","431ff1dd":"df[df['user_id'] == '5df49b32cc709107827fb3c7']","5146128b":"df[df['post_id']=='5ec821ddec493f4a2655889e']","9200d924":"val = df.post_id.value_counts().tolist()\nr_dict = dict(df.post_id.value_counts())\n# r_dict","485e1c0c":"def ratings_norm(ratings_dict):\n    (a,b) = (1,5)\n    for key, value in ratings_dict.items():\n        ratings_dict[key] = (b-a)*((value-min(val))\/(max(val)-min(val))) + a\n\n    return ratings_dict\n\nratings = ratings_norm(r_dict)\n# print(ratings)","4afb3453":"df['rating'] = 0","889ee5ee":"for key, value in ratings.items():\n    df.loc[df.post_id==key, 'rating'] = value\ndf.head()","1d533633":"!pip install scikit-surprise\nfrom surprise import Reader, Dataset, SVD, accuracy\nfrom surprise.model_selection import cross_validate, KFold, GridSearchCV","b6addd02":"reader = Reader()\ndata = Dataset.load_from_df(df[['user_id', 'post_id', 'rating']], reader)\nkf = KFold(n_splits = 5)","7a252c63":"algo = SVD()\ncross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)","450b2615":"for trainset, testset in kf.split(data):\n\n    # train and test algorithm.\n    algo.fit(trainset)\n    predictions = algo.test(testset)\n\n    # Compute and print Root Mean Squared Error\n    accuracy.rmse(predictions, verbose=True)","b7f01ab9":"trainset = data.build_full_trainset()\nalgo.fit(trainset)","20feb79b":"df[df['user_id']=='5d60098a653a331687083238'].head()","74c0e2b5":"algo.predict('5d60098a653a331687083238', '5ed1ff0276027d35905cc60d', 3.588235)","16e754d0":"## Importing required libraries","1c43628e":"From the above results, we can definetly say that she's interested towards a particular field, which in this case is mixed arts. \n\nOur task is to recommend more posts to Niriksha Sharma.","6a47ba78":"### Users\n1. _id: a unique alphanumeric id of the user (string) \n2. name: Name of user (string)\n3. gender: Gender of user (male | female)\n4. academics: Education of the use (undergraduate | graduate) \n \n### Posts\n1. _id: a unique alphanumeric id of the post (string) \n2. title: Title of the post (string)\n3. category: Category of the post (string)\n4. post_type: Type of the post (blog | artwork | skill | project) \n\n###  Views \n \n1. user_id : a unique alphanumeric id of the user (string)\n2. post_id : a unique alphanumeric id of the post (string)\n3. time stamp: timestamp of when user viewed the post (ISO time format) ","f1935382":"**Conclusion of 'Category' based recommender**\n\nThe recommender works good enough and suggests post based on similar category. But, is that enough? \n\nWe'll use more metadata about the posts and feed it to the TfidfVectorizer.","b60c2f71":"### Collaborative Filtering","63d8978b":"#### Removing redundant features like 'name' and 'title'","caab3a64":"**Calculating Cosine Similarity**\n\nThe method of calculating the user\u2019s likes \/ dislikes \/ measures is calculated by taking the cosine of the angle between the user profile vector (Ui ) and the document vector; or in our case, the angle between two document vectors.\n\nThe ultimate reason behind using cosine is that the value of cosine will increase as the angle between vectors with decreases, which signifies more similarity.*italicized text*\n\n","e20a36ac":"Name: Viren Baria\n\nEmail: virenbaria17@gmail.com\n\nContact No: 9867144297\/8850914822\n\n[LinkedIn](https:\/\/www.linkedin.com\/in\/viren-baria-78806115b\/) || [Github](https:\/\/github.com\/bumblebee26)","7eebfe24":"### 'users.csv'","928628af":"## Data Description","d9606771":"#### Metadata based filtering of posts","67f8d41c":"## Compeleting the dataset by merging the csv files","ece804d3":"For the above user_id and post_id, we have obtained RMSE of 2.745555216076532.","ef7eabf7":"Lets have a look at which posts Niriksha Sharma [user_id: 5df49b32cc709107827fb3c7] have been viewing.  ","616c1328":"# The Social Comment - Machine Learning Test\n\n","148001eb":"### Content Based Filtering","5d003345":"#### 1. Post viewed by gender and their academics","edec5f68":"#### Removed the rows where more than 1 null values were found. After in depth analysis, there were two rows with more than 1 null values. In this rows, 'post_type', 'title' and 'category' were null. So, these data wouldn't have contributed effectively to the model. Hence, I removed this two rows.  ","31d7b699":"There are 493 posts with 4 features. There were a few Null values in 'category' column. These null values are in 'category' column, where 'post_type' is 'project'. I have replaced this null values with a 'post_type' : 'General'","73568825":"## Beginning with the Recommendation process","c3502e61":"## Exploratory Data Analysis","966b0369":"Since the given data is in implicit form, we require some form of rating system for the posts. Here, the number of views a post has got gives us a form of rating. ","1c60b278":"As mentioned in the instruction pdf we have  build a Recommendation System, recommending the items based on the following:\n1. Content Based Filtering \n2. Collaborative Filtering \n\nEnd result should be a system that: \n1. Recommend posts for the given user \n2. Recommend similar posts for the given post ","70c39bd9":"Here, we have obtained good enough RMSE for inital data, now lets consider the whole data.","5aee7381":"#### 2. Popular categories ","098ef272":"Content-based filtering algorithms are given user preferences for items and recommend similar items based on a domain-specific notion of item content. This approach also extends naturally to cases where item metadata is available (e.g., movie stars, book authors, and music genres).","9599bb34":"There are 118 users with 4 features. There are a no Null values in any columns so it is a clean dataset.","9ad6f67c":"#### Category based filtering of posts","a83e1984":"There are 1449 view pattens with 3 features. There are a no Null values in any columns so it is a clean dataset.","e6487d67":"### 'posts.csv'","9d259e8a":"### 'views.csv'","816ab2ae":"Here, we have created another column named 'soup' consisting of the metadata of the posts. Now we will use this column to give as input to the TfidfVectorizer.","5c3088af":"Collaborative filtering is perhaps the most well-known approach to recommendation, to the point that it\u2019s sometimes seen as synonymous with the field. The main idea is that you\u2019re given a matrix of preferences by users for items, and these are used to predict missing preferences and recommend items with high predictions. All you need to get started is user and item IDs and a notion of preference by users for items. ","aa8e0e78":"#### 3. Popular post_type","856b0a1d":"**Conclusion of Metadata based recommender**\n\nThe recommender works better as compared to our previous results and suggests posts with similar content.\n\nPoints to be noted-\n1. In the Attempt 3, the recommender suggested the posts with similar title name 'Chirag'(Another post consisting with similar post by 'Chirag' in same category was recommended) which is pretty good as compared to the results of Attempt 1.\n2. More related posts were recommended in Attempt 4 as compared to Attempt 2.\n\n#### Hence, we can suggest the point that more data is always better."}}