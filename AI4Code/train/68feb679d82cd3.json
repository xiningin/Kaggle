{"cell_type":{"7859c03f":"code","147b6369":"code","e07590ac":"code","7a3b2988":"code","1a0077c1":"code","44ea2750":"code","c41a34c5":"code","38ece4df":"code","ee56091e":"code","086ceba9":"code","05d58223":"code","e2b955c3":"code","ee2bec49":"code","41b5c355":"code","3c6ba38f":"code","75c06ad3":"code","56b91b70":"code","4162e3ed":"code","e98d7dea":"code","d92c6791":"code","6b5ec3fa":"code","35dca983":"code","d63cbd0e":"code","8ba70bad":"code","f5a390e2":"code","82f89819":"code","d525c145":"code","e8a3b578":"code","e59aa297":"code","799c1cc7":"code","5c51a3c4":"code","6a52a8d6":"code","31a29f5e":"code","92a42f1c":"code","82351203":"code","b53ab5ab":"code","df8318c0":"code","d71a88a6":"code","bdce217e":"code","4d8efe7b":"code","11e1b972":"code","dd9fadb2":"code","451e16c6":"markdown","c910b94d":"markdown"},"source":{"7859c03f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","147b6369":"df = pd.read_csv('\/kaggle\/input\/commonlitreadabilityprize\/train.csv')","e07590ac":"#!pip install pandas_profiling\n","7a3b2988":"#import pandas_profiling","1a0077c1":"#df.profile_report()","44ea2750":"from gensim.parsing.preprocessing import remove_stopwords\n\ndf['excerpt_applied_stop_words'] = df['excerpt'].apply(remove_stopwords)\n\ndf['word_count'] = df['excerpt_applied_stop_words'].apply(lambda x: len(x.replace('\\n', '').split(' ')))\ndf['words'] = df['excerpt_applied_stop_words'].apply(lambda x: x.replace('\\n', '').split(' '))","c41a34c5":"df","38ece4df":"df.describe()","ee56091e":"!pip install gensim","086ceba9":"from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n","05d58223":"words_list = df['words'].values.tolist()","e2b955c3":"import os\nfrom gensim.test.utils import get_tmpfile\n\nif not os.path.exists('my_doc2vec_model'):\n    \n    words_list = df['words'].values.tolist()\n    documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(words_list)]\n    model = Doc2Vec(documents, vector_size=10, window=5, min_count=1, workers=4)\nelse:\n    fname = get_tmpfile(\"my_doc2vec_model\")\n    model.save(fname)\n    model = Doc2Vec.load(fname)","ee2bec49":"vars(model)","41b5c355":"#model(df['excerpt_applied_stop_words'][0])","3c6ba38f":"vars(model.wv)","75c06ad3":"model.wv.vectors","56b91b70":"import matplotlib.pyplot as plt\n\nx = model.wv.vectors.T[0]\ny = model.wv.vectors.T[1]","4162e3ed":"plt.scatter(x, y)","e98d7dea":"from sklearn.decomposition import PCA\n\n\n\nX = model.wv.vectors\n\npca = PCA(n_components=2)\npca.fit(X)\nXd = pca.transform(X)\n\nprint(Xd)\n","d92c6791":"plt.scatter(Xd.T[0], Xd.T[1])","6b5ec3fa":"import torch\nimport numpy as np","35dca983":"df['vector'] = df['words'].apply(lambda x: (model.infer_vector(x).tolist()))","d63cbd0e":"df['vector'] = df['words'].apply(lambda x: (model.infer_vector(x).tolist()))\nfeatures = np.array(df['vector'].values.tolist()).astype(np.float32)","8ba70bad":"import torch.utils.data as data_utils\n\ndf['target'].values.reshape(-1,1).shape","f5a390e2":"\ntrain = data_utils.TensorDataset(torch.tensor(features), torch.tensor(df['target'].values.reshape(-1, 1).astype(np.float32)))","82f89819":"train","d525c145":"import torch.nn as nn\nimport torch.nn.functional as F\n\n\n# NOTE: pretty simple NN model\nclass SimpleNN(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n        self.l1 = nn.Linear(10, 100)\n        self.l2 = nn.Linear(100, 200)\n        self.l3 = nn.Linear(200, 50)\n        self.l4 = nn.Linear(50, 1)\n        self.relu = nn.ReLU()\n    \n    def forward(self, x):\n        x = self.relu(self.l1(x))\n        x = self.relu(self.l2(x))\n        x = self.relu(self.l3(x))\n        x = self.l4(x)\n        return x\n    ","e8a3b578":"torch.manual_seed(1)\n\ndev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\ntrain_model = SimpleNN()\nprint(train_model)\n\ntrain_model = train_model.to(dev)\n\noptimizer = torch.optim.Adam(train_model.parameters(), lr=0.01)\n\nloss_func = nn.MSELoss()","e59aa297":"BATCH_SIZE = 64\nEPOCH = 10000\n\nloader = torch.utils.data.DataLoader(\n    dataset=train, \n    batch_size=BATCH_SIZE, \n    shuffle=True, num_workers=2,)","799c1cc7":"from tqdm import tqdm\n\n# FIXME: some codes have an fatal error probably because loss wouldn't decrease..\nfor epoch in tqdm(range(EPOCH)):\n    losses = []\n    for step, (b_x, b_y) in enumerate(loader):\n        optimizer.zero_grad()   # clear gradients for next train\n        b_x, b_y = b_x.to(dev), b_y.to(dev)\n        prediction = train_model(b_x)     # input x and predict based on x\n        loss = loss_func(prediction, b_y)     # must be (1. nn output, 2. target)\n        losses.append(loss)\n        loss.backward()         # backpropagation, compute gradients\n        optimizer.step()        # apply gradients\n\n    print(sum(losses) \/ len(losses))","5c51a3c4":"torch.save(train_model.state_dict(), 'model.pth')","6a52a8d6":"test_df = pd.read_csv('\/kaggle\/input\/commonlitreadabilityprize\/test.csv')","31a29f5e":"test_df","92a42f1c":"test_df['excerpt_applied_stop_words'] = test_df['excerpt'].apply(remove_stopwords)\n\ntest_df['word_count'] = test_df['excerpt_applied_stop_words'].apply(lambda x: len(x.replace('\\n', '').split(' ')))\ntest_df['words'] = test_df['excerpt_applied_stop_words'].apply(lambda x: x.replace('\\n', '').split(' '))","82351203":"test_df","b53ab5ab":"test_df['vector'] = test_df['words'].apply(lambda x: (model.infer_vector(x).tolist()))\nfeatures = np.array(test_df['vector'].values.tolist()).astype(np.float32)","df8318c0":"test_df","d71a88a6":"for l in test_df['vector'].values:\n    print(np.array(l).astype(np.float32))","bdce217e":"test_data = torch.tensor([np.array(l).astype(np.float32) for l in test_df['vector'].values])\ntest_data","4d8efe7b":"test_result = train_model(test_data.to(dev)).reshape(1, -1)[0]\ntest_result.tolist()","11e1b972":"submission = pd.DataFrame({'id': test_df['id'],'target': test_result.tolist()})\nsubmission","dd9fadb2":"submission.to_csv('submission.csv',index=False)","451e16c6":"df = pd.read_csv('\/kaggle\/input\/commonlitreadabilityprize\/train.csv')","c910b94d":"words_list"}}