{"cell_type":{"8d5f8e4c":"code","240c3257":"code","684ca8bb":"code","6603ac38":"code","05791c76":"code","d82454f0":"code","2493309b":"code","d42205e2":"code","917d00b3":"code","8bfda9c9":"code","481352d5":"code","44de0f0a":"code","bf4b470d":"code","5db24f61":"code","58dcd8f8":"code","4019f138":"code","45d73d94":"code","446aa475":"code","8fd18bcf":"code","ddf0ca74":"code","752d07f2":"code","d07d6dbb":"code","752665e8":"code","592fc6a3":"code","fc2f2e0b":"code","5d98fc3b":"code","25e6a962":"code","f21027ae":"code","a9d23d5c":"code","d7a62e3a":"code","e1aa18b7":"code","7369ab9c":"code","007776b6":"code","db949e5a":"code","8f93af1a":"code","652abb8d":"code","94a23428":"code","63b6b83c":"code","33cd1b14":"code","4b0df1a4":"code","d94b8153":"code","842f465c":"code","b3a76357":"code","e30450c2":"code","5134d799":"code","8320703f":"code","21435982":"code","f232086f":"code","28835647":"code","e6704e72":"code","be049135":"code","6a34f0f0":"code","d29ab6bc":"code","df162884":"code","12112b09":"code","78e3625b":"code","5a586ae1":"code","1fdca950":"markdown","13c9d195":"markdown","e603eb3e":"markdown","ba7a4223":"markdown","103a51e8":"markdown","89379848":"markdown","ccd1fb19":"markdown","fc4fbebc":"markdown","d17c959d":"markdown","6bbb79f3":"markdown","9fcf40b5":"markdown","932e8342":"markdown","0842f23a":"markdown","8ddf245e":"markdown","d29b8ca0":"markdown","372f2600":"markdown","535e7ea4":"markdown","0b9402be":"markdown","cb2de459":"markdown","96f21329":"markdown","0839212f":"markdown","dafbfd79":"markdown","852d8c3a":"markdown","94f37c4c":"markdown","1926ded3":"markdown","632f033d":"markdown","cd969160":"markdown","bd2e5909":"markdown"},"source":{"8d5f8e4c":"import pandas as pd\nimport numpy as np\nfrom scipy import stats\nfrom scipy import stats, special\nfrom sklearn import model_selection, metrics, linear_model, datasets, feature_selection\n\nimport matplotlib.pyplot as plt\n%pylab inline\npylab.rcParams['figure.figsize'] = (12.0, 10.0)","240c3257":"tt = pd.read_csv('..\/input\/Travel_Times 16.csv',index_col=0,parse_dates=True)\ntt[tt['Destination Movement ID']==3582]","684ca8bb":"ttd = pd.read_csv('..\/input\/Travel_Times_Daily 16.csv',index_col=0,parse_dates=True)\nttd.sort_index(ascending=True)\n#90 rows x 23 columns","6603ac38":"ttda = pd.DataFrame(ttd)  \nttda['Above Mean'] = ttda['Daily Mean Travel Time (Seconds)'] > 924 \nttda1 = ttda.loc[:,('Daily Mean Travel Time (Seconds)','Above Mean')]","05791c76":"scatter(ttda1['Daily Mean Travel Time (Seconds)'],ttda1['Above Mean']);","d82454f0":"ttda1['Daily Mean Travel Time (Seconds)'].values.reshape(-1,1)","2493309b":"logreg = linear_model.LogisticRegression(solver='newton-cg')\n#X = cr['Hours Researched'].reset_index().values\n#Create model\nX = ttda1['Daily Mean Travel Time (Seconds)'].values.reshape(-1,1)\nY = ttda1['Above Mean']\n#Fit data to model\nlogreg.fit(X,Y)","d42205e2":"travel_time_slope = logreg.coef_[0][0]\nlogreg.coef_[0][0]\n#Note positive correlation and rate","917d00b3":"np.exp(logreg.coef_[0][0] - 1)\n#Rate of value increase for one additional hour researched","8bfda9c9":"travel_time_intercept = logreg.intercept_[0]\nlogreg.intercept_[0]","481352d5":"a = logreg.coef_[0][0]\nb = logreg.intercept_[0]\nx = x = np.arange(550,1447,0.01)\nplt.plot(x,special.expit(a*x+b))\nplt.grid()\nplt.xlim(500,1700)","44de0f0a":"Daily_Average = ttda1['Daily Mean Travel Time (Seconds)']\npr = pd.DataFrame({'Daily Average':Daily_Average,'Pr Above':[special.expit(a*x+b) for x in Daily_Average]})\npr.sort_index(ascending=True)","bf4b470d":"s16 = scatter(pr['Daily Average'],pr['Pr Above'])","5db24f61":"logreg.predict([[921]])[0]","58dcd8f8":"logreg.predict([[922]])[0]","4019f138":"tt17 = pd.read_csv('..\/input\/Travel_Times 17.csv',index_col=0,parse_dates=True)\ntt17.head()","45d73d94":"ttd17 = pd.read_csv('\/Users\/GLP\/Desktop\/DataScience\/UberMovement\/Travel_Times_Daily 17.csv',index_col=0,parse_dates=True)\nttd17.sort_index(ascending=True)\n#90 Rows, 22 Rows","446aa475":"Daily_Average = ttd17['Daily Mean Travel Time (Seconds)']\npr17 = pd.DataFrame({'Daily Average':Daily_Average,'Pr Above':[special.expit(a*x+b) for x in Daily_Average]})\npr17.sort_index(ascending=True).head()","8fd18bcf":"a = logreg.coef_[0][0]\nb = logreg.intercept_[0]\nx = arange(600,1550)\nplt.plot(x,special.expit(a*x+b))\nplt.grid()\nplt.xlim(500,1400);\nscatter(pr17['Daily Average'],pr17['Pr Above']);","ddf0ca74":"a = logreg.coef_[0][0]\nb = logreg.intercept_[0]\nx = np.arange(550,1447,0.01)\nplt.plot(x,special.expit(a*x+b),color='red')\nplt.grid()\nplt.xlim(729,1655);\ns17 = scatter(pr17['Daily Average'],pr17['Pr Above'])","752d07f2":"logreg.predict([[921]])[0]","d07d6dbb":"logreg.predict([[922]])[0]","752665e8":"scatter(pr['Daily Average'],pr['Pr Above']);\nscatter(pr17['Daily Average'],pr17['Pr Above']);","592fc6a3":"tt17 = pd.read_csv('..\/input\/Travel_Times 17.csv',index_col=0,parse_dates=True)\ntt17[tt17['Destination Movement ID']==3582]","fc2f2e0b":"ttdwd = ttd[ttd.index.weekday<5]\nttdwd.sort_index(ascending=True)","5d98fc3b":"ttdw = pd.read_csv('..\/input\/Travel_Times_time_of_day.csv')\nttdw","25e6a962":"ttdw.loc[1:1,:]","f21027ae":"ttdwd['Above AM Mean'] = ttdwd['AM Mean Travel Time (Seconds)'] > 1099\nttdwd1 = ttdwd.loc[:,('AM Mean Travel Time (Seconds)','Above AM Mean')]\nttdwd1.head()","a9d23d5c":"a = logreg.coef_[0][0]\nb = logreg.intercept_[0]\nx = np.arange(550,1447,0.01)\nplt.plot(x,special.expit(a*x+b),color='red')\nplt.grid()\nplt.xlim(729,1655);\nscatter(ttdwd1['AM Mean Travel Time (Seconds)'],ttdwd1['Above AM Mean']);","d7a62e3a":"ttdwd1['AM Mean Travel Time (Seconds)'].values.reshape(-1,1)\n#ttdwd1.dropna()","e1aa18b7":"ttda.sort_index(ascending=True)","7369ab9c":"ttda[ttda.index.weekday<5]","007776b6":"ttd2 = pd.read_csv('..\/input\/Travel_Times_Daily 16.csv',index_col=0,parse_dates=True)\nttda2 = pd.DataFrame(ttd2)  \nttda2['Above Mean'] = ttda2['Daily Mean Travel Time (Seconds)'] > 924 \nttda2.head()","db949e5a":"#ttda2['Date'] = pd.to_datetime(ttda2['Date'])\n#ttda2['Day of Week'] = ttda2['Date'].dt.weekday_name\n#ttda2.head()\n\nttda2['Weekend'] = ((pd.DatetimeIndex(ttda2.index).dayofweek) \/\/ 5 == 1).astype(float)\nttda2.sort_index(ascending=True)","8f93af1a":"ttda2[ttda2.index.weekday<5].sort_index(ascending=True).head()","652abb8d":"ttda3 = ttda2.loc[:,('Daily Mean Travel Time (Seconds)','Above Mean','Weekend')]\nttda3.sort_index(ascending=True)","94a23428":"ttda3.corr()","63b6b83c":"ttda3['Daily Mean Travel Time (Seconds)'].values.reshape(-1,1)","33cd1b14":"ttda3['Weekend'].values.reshape(-1,1)","4b0df1a4":"ttda3['Above Mean'].values.reshape(-1,1)","d94b8153":"lgrg = linear_model.LogisticRegression(solver='newton-cg')\nX = ttda3[['Daily Mean Travel Time (Seconds)','Weekend']]\n#Two Variables on the X axis\nY = ttda3['Above Mean']\n#One variable on the Y axis\nlgrg.fit(X,Y)","842f465c":"TT_Wknd_coeff17 = lgrg.coef_[0][0] #First row, first column of matrix\nTT_Wknd_coeff17\n#X-Value\n#Positive movement along the X-scale","b3a76357":"TT_Wknd_coeff17 = lgrg.coef_[0][1]\nTT_Wknd_coeff17","e30450c2":"TT_Wknd__intercept17 = lgrg.intercept_[0]\nTT_Wknd__intercept17","5134d799":"lgrg.intercept_","8320703f":"b1,b2 = lgrg.coef_[0]\nb0 = lgrg.intercept_[0]\nprint(b1)\nprint(b2)\nprint(b0)","21435982":"def TT_model(TT,Wknd): #building model\n    return special.expit(TT*b1+Wknd*b2+b0)\n#Takes trip time and Weekend values\n#Returns value along sigmoid function (x*b1 + y*b2 + e)","f232086f":"TT_model(922,1)","28835647":"lgrg.predict_proba([[922,1]])","e6704e72":"lgrg.predict_proba(ttda3[[\"Daily Mean Travel Time (Seconds)\",\"Weekend\"]])","be049135":"import mpl_toolkits.mplot3d as m3d","6a34f0f0":"tt = np.arange(589,1447,1)\nwk = np.arange(0,1,1)\nxx, yy = np.meshgrid(tt, wk)\nZ = TT_model(xx,yy)\nfig3d = m3d.Axes3D(plt.figure())\nfig3d.plot_wireframe(xx, yy, Z, rstride=10, cstride=10);\nfig3d.set_xlabel('Daily Mean Travel Time (Seconds)')\nfig3d.set_ylabel('Weekend')\nfig3d.set_zlabel('Probability of Above Mean Trip')\nfig3d.view_init(25, 140)\nplt.show();","d29ab6bc":"fig3d = m3d.Axes3D(plt.figure())\nfig3d.plot_wireframe(xx, yy, Z, rstride=10, cstride=10);\nfig3d.set_xlabel('Daily Mean Travel Time (Seconds)')\nfig3d.set_ylabel('Loan Amount ($100s)')\nfig3d.set_zlabel('Probability of Above Mean Trip')\nfig3d.view_init(30, 80)\nplt.show();","df162884":"lgrg.predict([[922,0]])[0]","12112b09":"lgrg.predict([[922,1]])[0]\n#Training data shows that ","78e3625b":"TT_model(922,0)\n#Predict probability of if trip is above Mean Travel Time","5a586ae1":"TT_model(922,1)\n#Shows that if it is the weekend, there is a lower probability that a trip will be over time","1fdca950":"Taking the newly assorted data, we look at the Quarterly Mean average time taken over Monday to Friday using basic arithmetic.","13c9d195":"# Further Testing: Time Bins (Mon-Fri)\nHere we test the same model using the conditions of Daily trips by restricting our original Test_Trips_Daily.csv file to weekdays only, and test using new averages (of AM\/PM Peak Times)\n\nUsing https:\/\/www.uber.com\/drive\/san-francisco\/where-to-drive\/ we want to observe the following peak time groups:\n\n <img src=\"https:\/\/i.imgur.com\/LJwko5m.png\",width=300,height=500>\n \n For this example, I will apply our model to the time grouping [Mon-Fri: 7am-10am].","e603eb3e":"Having shaped the new dataframe into three columns (Daily Mean, Above Mean, and Weekend), we check the correlation. While the result is low, we must take note that it is inverted as our higher travel time dates (mon-fri) give us a boolean value of 0.0. Therefore, we proceed in adding the second feature.","ba7a4223":"Once produced, I slice the columns of 'Daily Mean', 'Above Mean', and the newly generated 'Weekend' and begin to reformat the new columns in arrays.","103a51e8":"## Model Fitting & Testing\n\nOur next step is to convert reshape our Y variable ('Daily Mean Travel Time (Seconds) and to fit our logistic regression to the shape of a Sigmoid function.","89379848":"# Testing the Model with 2017 Data\n\nWhile our initial model is interesting, it performs the glorified task of telling us whether a number is higher or lower than our observed quarterly mean.\n\nHere we have the same sample size (subtracting the Leap Year days). Using the same Q1 dates in 2017, we apply the model to the same Origin and Destination IDs and see how accurate it can deduce if a trip is below or above the average Travel Time without knowing the true mean.","ccd1fb19":"From our TT_model, we deduce that adding the second factor, 'Weekend', does (in accordance to our model) lower the probability of being above the Quarterly Average Trip Time given a positive value. Again this might present a fairly obvious conclusion, that there is less traffic on the weekdays facilitating shorter trip times. \n\nMy earlier linear regressions, when applied to different time bins and different years, still follow the sigmoid function shape. While our 2016 model predicted a similar Quarterly Average Trip Time to 2017 under a minute, it cannot be labelled as definitive as it is held to only one variable.\n\nDue to time restrictions, I submit this not having tested the model using 2017 data. The hypothesis is that by adding the second factor, I predict a more accurate probability of whether a given daily trip mean will be larger than the Quarterly Mean using my 'TT model'. \n\nThe potential implications of this model are much farther reaching. In the future, I will look towards adding additional features to the model, such as classifying time groupings of the day into dummy variables. Other potential features could include the quarter of the year (not included largely due to Uber Movement's incomplete datasets). Lastly, nearby destination ID's could be compared to our intitial conditions. \n\nThe importance of this model could potentially apply to both Uber drivers and Uber riders. For Uber drivers, this model could help understand when to expect longer than average trip times. This could allow drivers to more accurately plan out their total expected trips and their input usage. For Uber riders, this model could potentially allow riders to avoid busier trip times, or potentially change their destination to somewhere nearby which has a shorter trip time. \n\nAgain, this model is exploratory and not explanatory. While the implications are vast, this model only touches the surface on a plethora of factors that Uber Movement does not capture. Looking to the future, as the Uber Movement project grows, so do the potential capabilities of its dataset.","fc4fbebc":"Now we trace along the generated probabilities from our model","d17c959d":"Repeating the same process we can reproduce the same model using the assorted daily weekday average times\n#### Above AM Peak Mean","6bbb79f3":"<img src=\"https:\/\/i.imgur.com\/xJuJL1A.png\">\n\nWe will now attempt to improve the accuracy of our model by adding a second feature, if it is a weekday or weekend. As we see above, the average weekday [mon-fri] trip times are always higher than weekend [sat-sun]. What my goal here is to add a second feature to the Travel Time curve, and try to show that during weekends, expected travel times are lower than weekdays.","9fcf40b5":"With our newly created parameters 'travel_time_slope' and 'travel_time_intercept', I now shape the data to the form of a Sigmoid function using the logreg function. ","932e8342":"#### First, we import the Quarter 1 (Jan-Mar) aggregate data from 2016. By slicing the unique column of our Origin ID (3843) and our destination ID (3582), we isolate the Mean Travel Time for the given Date Range. We will call this Q1 2016 Mean Travel Time.","0842f23a":"Once reshaped, we add 'Daily Mean' and 'Weekend' to the x-axis and the 'Above Mean' to the y-axis. Unlike before, we are creating a 3d plane using two distinct Boolean values and one integer value to determine the probability of whether a trip time will be above or below the average trip time.","8ddf245e":"#### As seen together, both curves demonstrate similar distributions","d29b8ca0":"So for a given Daily Average, the Probability in the far column shows the proportion of trips that were above the Quarterly Average with a difference of 3 seconds from the actual mean.","372f2600":"Here we add a new column, 'Weekend', giving us a boolean value 1.0 if the date in the index is of 0-5 (mon-fri), and 0.0 if the index is of 6-7 (sat-sun). ","535e7ea4":"## Initial Setup\nImport 'Travel_Times.csv' & Packages: ","0b9402be":"## Setting Up the Model\n#### Here we use the Daily Mean Travel Time and Plot it using a Sigmoid function to classify daily averages above or below the Quarterly Mean \n\nI have created a new column, which determines whether or not the Daily Mean Travel Time is above or below the Q1 Mean Travel Time called 'Above Mean'. Next I have sliced the columns 'Daily Mean Travel Time (Seconds)' and 'Above Mean', and plotted them on a scatterplot pictured below.","cb2de459":"## Conclusion and Next Steps","96f21329":"note: NaN values for given days","0839212f":"# Uber Movement: Creating a two-factor model","dafbfd79":"While not overly exciting, we can plot a 3-d plane of our newly generated probabilities. This plane is 2-dimensional as two of our variables ('Weekend' and 'Above Mean') are boolean values. We can see the plot below.","852d8c3a":"#### Next we import and Sort 'Travel_Times_Daily.csv':\n- Organize rows by descending date","94f37c4c":"Plotting our newly generated probabilities, we see the general shape of the Sigmoid function as expected. Using the newly generated curve, we can now use the logreg function to predict if given a Daily Mean Travel Time if it is above or below the Q1 Mean Travel Time.","1926ded3":"#### Logistic Regression with Multiple features","632f033d":"Next, we set up a logistic regression that fits the 'Daily Mean Travel Time' on the x-axis and our newly generated 'Above Mean' on the y-axis and generate a slope and y-intercept and fit it to our 2016 data","cd969160":"With our newly generated slope and coefficient, we can now make predictions and test probabilities of a trip time being above the mean given the day of the week and the trip time.","bd2e5909":"#### As we can see, our new model is less accurate and predicts a similar mean with a difference of under 60 seconds difference of the actual Mean Travel Time for 2017."}}