{"cell_type":{"31f9cb9f":"code","70d9003a":"code","d2a57485":"code","fdd0a945":"code","8c8488ac":"code","64ebec7f":"code","5c5f95d1":"code","767df98d":"code","5c55dce0":"code","1ba43d54":"code","40f0dba7":"code","7e8c5af8":"code","ac0011e7":"code","95f37db9":"code","9af4c29a":"code","544912ad":"code","6c149122":"code","d3145bdc":"code","cd41caa7":"code","93bcd987":"code","6cf62a04":"code","3e99fc38":"code","96543ebe":"code","d45e397e":"code","7cde60a9":"code","66254a52":"code","6ee6cbdb":"code","820c6b1f":"code","f97589ed":"code","c9a356aa":"code","40a6c26a":"code","7084d197":"code","83d821bf":"code","991e35df":"code","9baa70f5":"code","ad7dbfbd":"code","b2a73434":"code","b9d2859a":"code","6a51306d":"code","73fb669e":"code","9edeebf1":"code","b736fc15":"code","d11f8a00":"code","8f058cf8":"code","7cd8ff56":"code","b50eb440":"code","90ab5a5f":"code","fd62da87":"code","faf53174":"code","6bee1b21":"code","1a502674":"code","1f241ebf":"code","28ab54ca":"code","0f84764b":"code","81ed691d":"code","024a367f":"code","89762401":"code","91a6dd0b":"code","51499238":"markdown","83b26f94":"markdown","c9e7f3e3":"markdown","15f30090":"markdown","1a73f345":"markdown","530c0c34":"markdown","fc8e3bfd":"markdown","b107d538":"markdown","b17bc809":"markdown","6ae026d6":"markdown","70b2bf89":"markdown","4c9664d9":"markdown","9ee129a9":"markdown","b977458b":"markdown","7688f1f8":"markdown","e13cea50":"markdown","1630ea7a":"markdown","a67095e6":"markdown","80953a9d":"markdown","f99aaff6":"markdown","5b5ccdcd":"markdown","c42d8e66":"markdown","a708a6df":"markdown","18e1666d":"markdown","4abd5d51":"markdown","809e1ead":"markdown","5c97a116":"markdown","9ef75db0":"markdown","5efc418e":"markdown","fa9a8aa2":"markdown"},"source":{"31f9cb9f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport spacy\nimport textblob\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","70d9003a":"nlp = spacy.load('en_core_web_sm')","d2a57485":"data = pd.read_csv(\"..\/input\/amazon-review\/K8 Reviews v0.2.csv\")\ndata.sample(10)","fdd0a945":"data.shape","8c8488ac":"data['sentiment'].value_counts()","64ebec7f":"data['length_of_review'] = data['review'].apply(len)","5c5f95d1":"data.head()","767df98d":"data.groupby(['sentiment']).mean()['length_of_review']","5c55dce0":"data.isna().sum()","1ba43d54":"nlp.Defaults.stop_words |= {\"n't\", \"phone\", \"mobile\", \"lenovo\",\"note\", \"k8\",}","40f0dba7":"data['reviews_cleaned_sp'] = data['review'].apply(lambda x: ' '.join([(token.text).lower() for token in nlp(x.lower()) if not token.is_stop if token.pos_ in [\"NOUN\", \"PROPN\"] if len(token.text)>2]))","7e8c5af8":"data['reviews_cleaned_sp'].replace(regex=True, inplace=True, to_replace=r'[^a-zA-Z ]', value=r'')\ndata[['review','reviews_cleaned_sp']]","ac0011e7":"from wordcloud import WordCloud\nall_words = ''.join([word for word in data['reviews_cleaned_sp'][::]])\nall_words\nwordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words)\nplt.figure(figsize=(15, 8))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.title(\"Frequent Words\", weight='bold', fontsize=14)\nplt.show()\nplt.savefig(\"Wordcloud.png\")","95f37db9":"from sklearn.feature_extraction.text import TfidfVectorizer","9af4c29a":"tfidf_vectorizer = TfidfVectorizer(use_idf=True, \n                                   max_df=0.5,\n                                   min_df=0.01,\n                                  max_features=50000)\nvectorized_corpus = tfidf_vectorizer.fit_transform(data['reviews_cleaned_sp'])","544912ad":"vectorized_corpus.shape","6c149122":"corpus_array = vectorized_corpus.toarray()","d3145bdc":"sentiment = data['sentiment']","cd41caa7":"positive = corpus_array[np.where(sentiment==1)]\nnegative = corpus_array[np.where(sentiment==0)]","93bcd987":"feature_names = tfidf_vectorizer.get_feature_names()","6cf62a04":"type(positive.sum(0))","3e99fc38":"def get_top_features(arr, feature_names, n_top):\n    tple  = zip(feature_names,arr.sum(0).tolist())\n    sortedtpl = sorted(tple,key=lambda x: x[1], reverse=True)[:n_top]\n    feature_list = [x[0] for x in sortedtpl]\n    value_list = [x[1] for x in sortedtpl]\n    return (feature_list,value_list)","96543ebe":"top_pos = get_top_features(positive,feature_names,15)\ntop_neg = get_top_features(negative,feature_names,15)","d45e397e":"plt.rcParams['figure.figsize'] = (20,12)\nplt.bar(top_pos[0],top_pos[1])\nplt.savefig(\"positive.png\")","7cde60a9":"plt.bar(top_neg[0],top_neg[1])\nplt.savefig(\"negative.png\")","66254a52":"import gensim\nimport gensim.corpora as corpora\nfrom gensim.models import CoherenceModel\nfrom gensim.models import ldamodel","6ee6cbdb":"from nltk.tokenize import word_tokenize\ndata['reviews_token'] = [word_tokenize(sent) for sent in data.reviews_cleaned_sp]","820c6b1f":"data","f97589ed":"id2word = corpora.Dictionary(data.reviews_token)\ntexts = data.reviews_token\ncorpus = [id2word.doc2bow(text) for text in texts]","c9a356aa":"lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n                                           id2word=id2word,\n                                           num_topics=12, \n                                           random_state=20,\n                                           passes=15,\n                                           per_word_topics=True)","40a6c26a":"for index, topic in lda_model.show_topics(num_topics = 12, formatted=False, num_words= 15):\n    print('Topic #{}: {}'.format(index,'|'.join(w[0] for w in topic)))","7084d197":"type(texts)","83d821bf":"reviews = data['review']","991e35df":"def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=texts, original_text = reviews):\n    # Init output\n    sent_topics_df = pd.DataFrame()\n\n    # Get main topic in each document\n    for i, row in enumerate(ldamodel[corpus]):\n        row = sorted(row[0], key=lambda x: x[1], reverse=True)\n        # Get the Dominant topic, Perc Contribution and Keywords for each document\n        for j, (topic_num, prop_topic) in enumerate(row):\n            if j == 0:  # => dominant topic\n                wp = ldamodel.show_topic(topic_num)\n                topic_keywords = \", \".join([word for word, prop in wp])\n                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n            else:\n                break\n    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n\n    # Add original text to the end of the output\n    contents = original_text\n    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n    return(sent_topics_df)\n","9baa70f5":"df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=texts, original_text=reviews)","ad7dbfbd":"df_topic_sents_keywords","b2a73434":"# Format\ndf_dominant_topic = df_topic_sents_keywords.reset_index()\ndf_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n\n# Show\ndf_dominant_topic.head(10)","b9d2859a":"pd.set_option('display.max_colwidth', None) ","6a51306d":"def sort_df_by_topic_contrib(df_dominant_topic):\n    df_rep_doc = df_dominant_topic.sort_values(['Topic_Perc_Contrib'], ascending=False).groupby(['Dominant_Topic']).head(3)\n    df_rep_doc = df_rep_doc.sort_values(['Dominant_Topic'])\n    return df_rep_doc","73fb669e":"sort_df_by_topic_contrib(df_dominant_topic)","9edeebf1":"topicdict = {}\nfor index, topic in lda_model.show_topics(num_topics = 12, formatted=False, num_words= 15):\n    topicdict[index] = ', '.join(w[0] for w in topic)\nfinal_topics = pd.DataFrame(topicdict.items())\ntopic_dict = {0:\"Software\", \n              1:\"None\", \n              2:\"Camera and Sound\", \n              3:\"Battery and Overheating\", \n              4:\"Amazon Service\", \n              5:\"Value for money\", \n              6:\"Packaging and Screen cast\", \n              7:\"Sound sytem\", \n              8:\"Low Memory\/RAM and missing features\", \n              9:\"Network issue and heating\", \n              10:\"None\", \n              11:\"Price\"}\nfinal_topics.columns = [\"Topic Num\", \"Keywords\"]\nfinal_topics['topic_names'] = pd.Series(topic_dict).sort_index()\nfinal_topics","b736fc15":"# Compute Coherence Score\n\ncoherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=id2word, coherence='c_v')\ncoherence_lda = coherence_model_lda.get_coherence()\nprint('\\nCoherence Score: ', coherence_lda)","d11f8a00":"def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n    \n    coherence_values = []\n    model_list = []\n    for num_topics in range(start, limit, step):\n    \n        model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n                                           id2word=id2word,\n                                           num_topics=num_topics, \n                                           random_state=20,\n                                           passes=15,\n                                           per_word_topics=True)\n        model_list.append(model)\n        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n        coherence_values.append(coherencemodel.get_coherence())\n\n    return model_list, coherence_values","8f058cf8":"limit=20\nstart=2\nstep=1\nmodel_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=texts, start=start, limit=limit, step=step)\n","7cd8ff56":"# Show graph\nplt.rcParams['figure.figsize'] = (20,10)\nx = range(start, limit, step)\nplt.plot(x, coherence_values)\nplt.xlabel(\"Num Topics\")\nplt.ylabel(\"Coherence score\")\nplt.legend((\"coherence_values\"), loc='best')\nplt.show()\nplt.savefig(\"optimum_topics.png\")","b50eb440":"coherence_values","90ab5a5f":"best_model_index = coherence_values.index(max(coherence_values))\nnum_topics_best = best_model_index + 2\nlda_model_best = model_list[best_model_index]\nfor index, topic in lda_model_best.show_topics(num_topics = num_topics_best, formatted=False, num_words= 15):\n    print('Topic #{}: {}'.format(index,'|'.join(w[0] for w in topic)))","fd62da87":"lda_model_second_best = model_list[4]\nfor index, topic in lda_model_second_best.show_topics(num_topics = 6, formatted=False, num_words= 15):\n    print('Topic #{}: {}'.format(index,'|'.join(w[0] for w in topic)))","faf53174":"coh_score = coherence_values[best_model_index]\nprint(coh_score)","6bee1b21":"df_topic_keywords = format_topics_sentences(ldamodel=lda_model_best, corpus=corpus, texts=texts, original_text=reviews)\n# Format\ndf_dominant_topic_best = df_topic_keywords.reset_index()\ndf_dominant_topic_best.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\nsort_df_by_topic_contrib(df_dominant_topic_best)","1a502674":"df_rep_doc = df_dominant_topic_best.sort_values(['Topic_Perc_Contrib'], ascending=False).groupby(['Dominant_Topic']).head(15)\ndf_rep_doc = df_rep_doc.sort_values(['Dominant_Topic'])\ndf_rep_doc.loc[(df_rep_doc['Dominant_Topic']==2.0) | (df_rep_doc['Dominant_Topic']==4.0)]","1f241ebf":"topic_dict = {}\nfor index, topic in lda_model_best.show_topics(num_topics = 5, formatted=False, num_words= 15):\n    topic_dict[index] = ', '.join(w[0] for w in topic)\nfinal_topics_best = pd.DataFrame(topic_dict.items())\ntopic_best_dict = {0:\"Camera and Sound\", \n                   1:\"Missing common features\", \n                   2:\"Network and Camera\", \n                   3:\"Battery and overheating\", \n                   4:\"Defective piece and Amazon return policy\"}\n\nfinal_topics_best.columns = [\"Topic Num\", \"Keywords\"]\nfinal_topics_best['topic_names'] = pd.Series(topic_best_dict).sort_index()\nfinal_topics_best","28ab54ca":"import pyLDAvis\nimport pyLDAvis.gensim","0f84764b":"%matplotlib inline\npyLDAvis.enable_notebook()\nvis = pyLDAvis.gensim.prepare(lda_model_best, corpus, id2word, sort_topics=False)\npyLDAvis.save_html(vis, 'lda.html')\nvis","81ed691d":"df_dominant_topic_best['topic_name'] = df_dominant_topic_best['Dominant_Topic'].apply(lambda x: topic_best_dict[int(x)])\ndf_dominant_topic_best['sentiment'] = data['sentiment']\ndf_dominant_topic_best","024a367f":"plt.rcParams['figure.figsize'] = (16,10)\ndf_dominant_topic_best.groupby(['sentiment','topic_name']).count()['Dominant_Topic'].unstack().plot(kind='bar',stacked = True)\nplt.savefig(\"topic_sentiment_wise.png\")","89762401":"df_dominant_topic_best.groupby(['topic_name','sentiment']).count()['Dominant_Topic'].unstack().plot(kind='bar',stacked = True)\nplt.savefig(\"each_topic_sentiment.png\")","91a6dd0b":"plt.bar(df_dominant_topic_best['topic_name'].value_counts().index,df_dominant_topic_best['Dominant_Topic'].value_counts().values)\nplt.savefig(\"topic_freq_distr.png\")","51499238":"### Compute Coherence Score","83b26f94":"### View the topic which is most dominant in each document, get topic probability and attach topic keywords to dataframe","c9e7f3e3":"### Assign names to each topic for business usecase","15f30090":"#### Visualizing words","1a73f345":"### Assign topics to documents","530c0c34":"It can be seen that most of the people who rated negatively are talking about either battery and overheating problem or they are talking about camera quality and sound. But a large number of people who rated positively are also talking about camera and sound. It seems like, there is some subjectivity in judging the quality of camera and sound, but it remains the most talked about topic, regardless of whether people rated positively or negatively. There are people who faced problems regarding battery backup, charging and overheating, although the problem is not universal in all customers.","fc8e3bfd":"### What's the sentiment distribution for each topic?","b107d538":"### POS TAGGING, STOPWORD REMOVAL, NORMALIZE CASINGS","b17bc809":"### What's the distribution of these topics sentiment wise?","6ae026d6":"From this chart we can infer that battery, camera and heating are being talked negatively. So the phone probably has poor battery life, camera quality and overheating issues. ","70b2bf89":"#### What's the average length of review for negative sentiment vs positive sentiment?","4c9664d9":"#### Which of the topics can be merged?","9ee129a9":"### Visualizing topics","b977458b":"### View the three most relevant documents for each topic","7688f1f8":"The dataset is fairly balanced","e13cea50":"#### Show top terms for each topic","1630ea7a":"It seems like people tend to write more elaborate reviews when they are unhappy with the product. ","a67095e6":"### Frequency distribution of different topics","80953a9d":"### Top words in positive and negative sentiment","f99aaff6":"### Coherence score for best topic","5b5ccdcd":"## Building LDA model using Gensim","c42d8e66":"#### It can be observed that num_topics = 5 provide a better segmentation into topics than num_topics = 6","a708a6df":"### Print topics for the second best model (num_topics = 6)","18e1666d":"### View the 3 most relevant documents for each topic, along with topic probability, keywords and document number","4abd5d51":"### Print topics for the best model (num_topics = 5)","809e1ead":"#### Create model with 12 topics","5c97a116":"#### We need to look more closely into topic#2 and topic#4","9ef75db0":"### Assign names to each topic (best) for business usecase","5efc418e":"### Find the most optimum model","fa9a8aa2":"In the above table topic#4 and topic#6 can be merged, topic#7 and topic#2 can be merged and topic#1 and topic#10 can be merged"}}