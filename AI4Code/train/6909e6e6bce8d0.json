{"cell_type":{"49a9398d":"code","d4b50bdd":"code","38af1328":"code","ed0aacdb":"code","e02f141a":"code","d66f3f6b":"code","ea82445e":"code","25b07367":"code","61b54dac":"code","5798df33":"code","c44ad377":"code","7799b608":"code","0887e7fc":"code","39edd445":"code","9baf7c26":"code","992c7ab3":"code","1493d35e":"code","ca8c1059":"code","3aa0a798":"code","c73a19b2":"code","1e926465":"code","d7bedc34":"code","2aeb0791":"code","9aac7854":"code","338665e9":"markdown","39fd24e7":"markdown","9f6ff52a":"markdown","c2a0868b":"markdown","7082af43":"markdown","b8fe4946":"markdown","0394a0db":"markdown","8c364647":"markdown","44da1313":"markdown","d9d49bf4":"markdown","71963dc6":"markdown","9611a4f8":"markdown","48c65b79":"markdown","1a6a1ece":"markdown","0973cafa":"markdown","795b290f":"markdown"},"source":{"49a9398d":"#pip install apriori\n#pip install mlxtend\n#pip install seaborn","d4b50bdd":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom mlxtend.frequent_patterns import apriori, association_rules","38af1328":"#to check the directory of the file\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ed0aacdb":"# read csv \ndf = pd.read_csv('\/kaggle\/input\/the-bread-basket\/bread basket.csv')","e02f141a":"# first look\ndf.head()","d66f3f6b":"# check for null values\nprint(df.shape)\nprint('----------------------------')\nprint('There are no NULL values:')\nprint(df.isna().sum())\nprint('----------------------------')\nprint(df.info())","ea82445e":"# look at figures from categorical data\ndf.describe(include = ['O'])","25b07367":"df.Item.unique()","61b54dac":"df['Quantity'] = 1 #assign quantity bought for each row\ndf1 = df.copy() # create a copy of original data\ndf1 = df.groupby(['Transaction','Item','date_time','period_day','weekday_weekend']).sum()\n\n#pivot Items to columns to run Apriori Algorithm later. The new dataframe has 98 columns now.\ndf1 = df1.pivot_table('Quantity',['Transaction','date_time','period_day','weekday_weekend'],'Item').reset_index().rename_axis(None, axis=1).fillna(0)\ndf1.head(2)","5798df33":"# looks like customers will only buy maximum 3 items at once\nbought = df1['date_time'].value_counts()\nbought = pd.DataFrame(bought).reset_index().rename(columns = {'index': 'datetime', 'date_time':'number'})\n\n# items bought in 1 transaction\n# it looks like only less than 4% of people will buy more than 1 item\nprint(\"3 items:\", round(len(bought[bought['number'] == 3])\/len(bought['number'])*100,2),'%',sep='')\nprint(\"2 items:\", round(len(bought[bought['number'] == 2])\/len(bought['number'])*100,2),'%',sep='')\nprint(\"1 items:\", round(len(bought[bought['number'] == 1])\/len(bought['number'])*100,2),'%',sep='')","c44ad377":"# split the date_time into Date, Time, Month, Year and Date for easier analysis later\ndf1['date_time'] = pd.to_datetime(df['date_time'])\ndf1['Date'] = df1['date_time'].dt.strftime('%d-%m-%Y')\ndf1['Time'] = df1['date_time'].dt.strftime('%H:%M:%S')\ndf1['Month'] = df1['date_time'].dt.strftime('%b')\ndf1['Year'] = df1['date_time'].dt.strftime('%Y')\ndf1['Day'] = df1['date_time'].dt.strftime('%a')\n\n# drop date_time column as we don't need it anymore\n#df1 = df1.drop(columns='date_time') \n\n# move the date time columns to the front so that it is easier to visualise\ncol = df1.pop('Date')\ndf1.insert(1, col.name, col)\ncol = df1.pop('Time')\ndf1.insert(2, col.name, col)\ncol = df1.pop('Day')\ndf1.insert(3, col.name, col)\ncol = df1.pop('Month')\ndf1.insert(4, col.name, col)\ncol = df1.pop('Year')\ndf1.insert(5, col.name, col)\ndf1.head(2)","7799b608":"df1['Day'] = pd.Categorical(df1['Day'], categories= ['Mon','Tue','Wed','Thu','Fri','Sat', 'Sun'], ordered=True)\nday = df1['Day'].value_counts()\nday = day.sort_index().reset_index().rename(columns={'index':'Day','Day':'Transactions'})\nax = sns.barplot(x=\"Day\", y=\"Transactions\", data=day)","0887e7fc":"df1['Month'] = pd.Categorical(df1['Month'], categories= ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'], ordered=True)\nmonth = df1['Month'].value_counts()\nmonth = month.sort_index().reset_index().rename(columns={'index':'Month','Month':'Transactions'})\nax = sns.barplot(x=\"Month\", y=\"Transactions\", data=month)","39edd445":"df1['period_day'] = pd.Categorical(df1['period_day'], categories= ['morning','afternoon','evening','night'], ordered=True)\nperiod_day = df1['period_day'].value_counts()\nperiod_day = period_day.sort_index().reset_index().rename(columns={'index':'period_day','period_day':'Transactions'})\nax = sns.barplot(x=\"period_day\", y=\"Transactions\", data=period_day)","9baf7c26":"year = pd.DataFrame(df1.Year.value_counts())\nyear = year.reset_index().rename(columns={'index':'Year','Year':'Transactions'})\nax = sns.barplot(x=\"Year\", y=\"Transactions\", data=year)","992c7ab3":"# select data by year to for a new dataframe\ndf_2016 = df1[df1['Year'] == '2016']\ndf_2017 = df1[df1['Year'] == '2017']\n\n# extract number of transactions by month\nmonthly_sales_2016 = pd.DataFrame(df_2016['Month'].value_counts().reset_index().rename(columns = {'index': 'Month', 'Month':'2016'}))\nmonthly_sales_2017 = pd.DataFrame(df_2017['Month'].value_counts()).reset_index().rename(columns = {'index': 'Month', 'Month':'2017'})\n\n# merge sales data for both years\nmonthly_sales = pd.merge(monthly_sales_2016,monthly_sales_2017)\n\n# sort by month\nmonthly_sales['Month'] = pd.Categorical(monthly_sales['Month'], categories= ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'], ordered=True)\nmonthly_sales.sort_values(inplace=True, by='Month')\nmonthly_sales = monthly_sales.reset_index().drop('index', axis=1)\n\n# % change compared to previous year\nprint('% change compared to previous year:')\nmonthly_sales['% Change'] = round(((monthly_sales['2017']-monthly_sales['2016'])\/monthly_sales['2016']*100),2).astype(str) + '%'\nmonthly_sales","1493d35e":"# plot grouped bar plot to compare month-by-month for 2016 & 2017\nlabels = monthly_sales['Month']\nsales_2016 = monthly_sales['2016']\nsales_2017 = monthly_sales['2017']\n\nx = np.arange(len(monthly_sales['Month']))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots()\nrects1 = ax.bar(x - width\/2, sales_2016, width, label='2016')\nrects2 = ax.bar(x + width\/2, sales_2017, width, label='2017')\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('No. of Transactions')\nax.set_title('No. of Transactions by Month')\nax.set_xticks(x)\nax.set_xticklabels(labels)\nax.legend()\n\nfig.tight_layout()\n\nplt.show()","ca8c1059":"total_transactions = len(df1)\nsupport = 0.02\nmin_items = total_transactions*support\n\nitemset_1 = pd.DataFrame(df.Item.value_counts()).reset_index().rename(columns = {'index':'Item','Item':'Count'})\nitemset_1 = itemset_1[itemset_1['Count'] >= min_items]\nitemset_1","3aa0a798":"# Initialize the matplotlib figure\n#f, ax = plt.subplots(figsize=(6, 15))\n\n# Plot the total crashes\nsns.set_color_codes(\"pastel\")\nt = sns.barplot(x=\"Item\", y=\"Count\", data=itemset_1,\n            label=\"Item\", color=\"b\")\n\n# Add a legend and informative axis label\nax.legend(ncol=2, loc=\"lower right\", frameon=True)\n#ax.set(xlim=(0, 24), ylabel=\"\", xlabel=\"Popular Items Sold\")\nsns.despine(left=True, bottom=True)\nt.set_xticklabels(itemset_1['Item'],rotation=90)","c73a19b2":"def hot_encode(x): \n    if(x<= 0): \n        return 0\n    if(x>= 1): \n        return 1\n\nbasket = df1.iloc[:,9:]\nbasket_encoded = basket.applymap(hot_encode)\nbasket_encoded.head(1)","1e926465":"# Building the model \nfrequent_items = apriori(basket_encoded, min_support = 0.01, use_colnames = True) \n  \n# Collecting the inferred rules in a dataframe \nrules = association_rules(frequent_items, metric =\"lift\", min_threshold = 1) \nrules = rules.sort_values(['confidence', 'lift'], ascending =[True, True]) \nprint(pd.DataFrame(rules))","d7bedc34":"rules = association_rules(frequent_items, metric = \"lift\", min_threshold = 1)\nrules.sort_values('confidence', ascending = False, inplace = True)\nrules","2aeb0791":"# prepare data for 2016\n# sorting Month\nmonthly_sales_2016['Month'] = pd.Categorical(monthly_sales_2016['Month'], categories= ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'], ordered=True)\nmonthly_sales_2016 = monthly_sales_2016.rename(columns={'2016':'Transactions'})\nmonthly_sales_2016.sort_values(inplace=True, by='Month')\nmonthly_sales_2016['Month'] = monthly_sales_2016['Month'].astype(str) + '_2016'\n\n# prepare data for 2017\n# sorting Month\nmonthly_sales_2017['Month'] = pd.Categorical(monthly_sales_2017['Month'], categories= ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'], ordered=True)\nmonthly_sales_2017 = monthly_sales_2017.rename(columns={'2017':'Transactions'})\nmonthly_sales_2017.sort_values(inplace=True, by='Month')\nmonthly_sales_2017['Month'] = monthly_sales_2017['Month'].astype(str) + '_2017'\n\n# merge both datasets\nmerged = monthly_sales_2016.append([monthly_sales_2017])\nmerged = merged.reset_index().drop(['index'], axis=1)\nmerged","9aac7854":"# plot bargraph\nsns.set_style(style=\"whitegrid\")\ns = sns.barplot(x='Month',y='Transactions', data=merged)\ns.set_xticklabels(merged['Month'],rotation=90)","338665e9":"## Preparing data for analysis","39fd24e7":"## The number of transactions by year: Sales in 2017 seems to have plunged compared to 2016.","9f6ff52a":"## The number of transactions by period of day: Morning and Afternoon are the busiest.","c2a0868b":"## What are the popular items?","7082af43":"#### Drawing from the fact that only about 3% of customers buy more than 1 item, the association between items purchased are not expected to be high as shown in the lift, support and confidence figures. However, they are still worth noting for every opportunity to upsell to increase revenue. ","b8fe4946":"## Frequent Pattern Mining via Apriori Algorithm","0394a0db":"#### In 2016, business seemed to be pretty good and peaked at the end of the year. However, starting Feb 2017, number of transactions plunged to zero. There were some transactions in the subsequent months but never recovered to the level in 2016.","8c364647":"### Questions to Answer:\n1. What is the best time so sell?\n\n2. What are the popular items?\n\n3. What items are usually bought together? (Association Mining Rule) \n\n4. What is the trend?","44da1313":"## Compare month-by-month for 2016 & 2017","d9d49bf4":"### Although there is only a small amount of customers that would buy more than 1 item. However, it is still worthwhile to find any Associations on multiple items bought to upsell. Another benefit is to possibly create a 'deal' say, Coffee + Scone at a cheaper price. This will encourage customers to buy multiple items instead of just 1 item only.\n\n#### Apriori Algorithm reference: https:\/\/www.geeksforgeeks.org\/implementing-apriori-algorithm-in-python\/","71963dc6":"## The number of transactions by month: November and December are the busiest.","9611a4f8":"# Data Auditing","48c65b79":"## % change compared to previous year:","1a6a1ece":"## Visualisation on number of transactions over time","0973cafa":"## Visualise popular items on a barplot","795b290f":"## The number of transactions by day: Friday, Saturday and Monday are the busiest."}}