{"cell_type":{"78fdd238":"code","337bb031":"code","56b33d14":"code","06d52a2d":"code","c9fd6ec9":"code","ad6d55ce":"code","bbcc5c73":"code","64477f9e":"code","5c379301":"code","760fafb4":"code","8a2abf3b":"code","c2a076a0":"code","d4b23f09":"code","45d59f6f":"code","dbaf8765":"code","401bcada":"code","023a466c":"code","7f321d38":"code","1d3bc0ce":"code","0e9bbfe3":"code","97eaa050":"code","942d3d53":"code","fe2e4b82":"code","36ec211a":"code","0e5e2709":"code","e6832010":"code","add7d17c":"code","9a6f28de":"code","578eb6e8":"code","bd766a9b":"markdown","d184f2fc":"markdown","502cfdfd":"markdown","3f52d3dc":"markdown","3231f4c6":"markdown","7f885a4b":"markdown","93ce7b44":"markdown","15703a86":"markdown","f9fc5696":"markdown","3d1036cc":"markdown","8fcc5abe":"markdown","0bd5165c":"markdown","4554321f":"markdown","a59a821d":"markdown","63ddb068":"markdown","5b5960ca":"markdown","6dcd29e2":"markdown","9805dfe3":"markdown","ed8f8a44":"markdown","eafe200f":"markdown","456e7290":"markdown","336ea50f":"markdown","f2af0ae0":"markdown","72620029":"markdown","515ca904":"markdown","290120fd":"markdown","90d8f79a":"markdown","b227b75d":"markdown","126a8c1b":"markdown"},"source":{"78fdd238":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\nimport plotly.express as px\nimport seaborn as sns\nimport numpy as np #Data manipulation\nimport matplotlib.pyplot as plt # Visualization\nimport statsmodels.api as sm\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nimport math\nimport random\nfrom plotly.offline import plot, iplot, init_notebook_mode\ninit_notebook_mode(connected=True)","337bb031":"train = pd.read_csv(\"\/kaggle\/input\/cap-4611-2021-fall-assignment-1\/train.csv\")\ntrain.head()","56b33d14":"test = pd.read_csv(\"\/kaggle\/input\/cap-4611-2021-fall-assignment-1\/test.csv\")\ntest.head()","06d52a2d":"train = train.loc[~(train['HHS Region'].isin(['01', '02', '03', '04', '05', '06', '07', '08', '09', '10']))]\ntrain = train.loc[~((train['Group'].str.contains('By Month', case=False, regex=False, na=False)) | (train['Group'].str.contains('By Year', case=False, regex=False, na=False)))]\ntrain = train.drop(['id', 'Footnote', 'Year', 'Week-Ending Date', 'Data As Of', 'MMWR Week'], axis=1)\n\n","c9fd6ec9":"train = train.loc[~((train['Group'].str.contains('By Month', case=False, regex=False, na=False)) | (train['Group'].str.contains('By Year', case=False, regex=False, na=False)))]\ntrain = train.loc[~(train['Start Date'].isna())]\n\ntrain['Start Date'] = train['Start Date'].replace('12\/29\/2019', 1)\ntrain['Start Date'] = train['Start Date'].replace('01\/05\/2020', 2)\ntrain['Start Date'] = train['Start Date'].replace('01\/12\/2020', 3)\ntrain.loc[train['Start Date'].isin(['01\/19\/2020']), 'Start Date'] = 4\ntrain.loc[train['Start Date'].isin(['01\/26\/2020']), 'Start Date'] = 5\ntrain.loc[train['Start Date'].isin(['02\/02\/2020']), 'Start Date'] = 6\ntrain.loc[train['Start Date'].isin(['02\/09\/2020']), 'Start Date'] = 7\ntrain.loc[train['Start Date'].isin(['02\/16\/2020']), 'Start Date'] = 8\ntrain.loc[train['Start Date'].isin(['02\/23\/2020']), 'Start Date'] = 9\ntrain.loc[train['Start Date'].isin(['03\/01\/2020']), 'Start Date'] = 10\ntrain['Start Date'] = train['Start Date'].replace('03\/08\/2020', 11)\ntrain['Start Date'] = train['Start Date'].replace('03\/15\/2020', 12)\ntrain.loc[train['Start Date'].isin(['03\/22\/2020']), 'Start Date'] = 13\ntrain.loc[train['Start Date'].isin(['03\/29\/2020']), 'Start Date'] = 14\ntrain.loc[train['Start Date'].isin(['04\/05\/2020']), 'Start Date'] = 15\ntrain.loc[train['Start Date'].isin(['04\/12\/2020']), 'Start Date'] = 16\ntrain.loc[train['Start Date'].isin(['04\/19\/2020']), 'Start Date'] = 17\ntrain.loc[train['Start Date'].isin(['04\/26\/2020']), 'Start Date'] = 18\ntrain.loc[train['Start Date'].isin(['05\/03\/2020']), 'Start Date'] = 19\ntrain.loc[train['Start Date'].isin(['05\/10\/2020']), 'Start Date'] = 20\ntrain.loc[train['Start Date'].isin(['05\/17\/2020']), 'Start Date'] = 21\ntrain.loc[train['Start Date'].isin(['05\/24\/2020']), 'Start Date'] = 22\ntrain.loc[train['Start Date'].isin(['05\/31\/2020']), 'Start Date'] = 23\ntrain.loc[train['Start Date'].isin(['06\/07\/2020']), 'Start Date'] = 24\ntrain.loc[train['Start Date'].isin(['06\/14\/2020']), 'Start Date'] = 25\ntrain.loc[train['Start Date'].isin(['06\/21\/2020']), 'Start Date'] = 26\ntrain.loc[train['Start Date'].isin(['06\/28\/2020']), 'Start Date'] = 27\ntrain = train.loc[~(train['Start Date'].isin(['07\/05\/2020', '07\/19\/2020', '07\/12\/2020', '07\/26\/2020', '08\/02\/2020', '08\/09\/2020', '08\/16\/2020', '08\/23\/2020', '08\/30\/2020', '09\/06\/2020', '09\/13\/2020', '09\/20\/2020', '09\/27\/2020', '10\/04\/2020', '10\/11\/2020', '10\/18\/2020', '10\/25\/2020', '05\/23\/2021', '05\/16\/2021', '05\/09\/2021', '05\/02\/2021', '04\/25\/2021', '04\/18\/2021', '03\/28\/2021', '04\/04\/2021', '03\/14\/2021', '03\/07\/2021', '02\/14\/2021', '02\/07\/2021', '01\/24\/2021', '01\/17\/2021', '01\/10\/2021', '12\/06\/2020', '04\/11\/2021', '03\/21\/2021', '02\/21\/2021', '02\/28\/2021', '01\/03\/2021', '01\/31\/2021', '12\/13\/2020', '12\/20\/2020', '11\/22\/2020', '11\/15\/2020', '11\/29\/2020', '12\/27\/2020', '11\/01\/2020', '11\/08\/2020']))]\ntrain['Start Date'] = pd.to_numeric(train['Start Date'], downcast='integer', errors='coerce')\ntrain['COVID-19 Deaths'] = pd.to_numeric(train['COVID-19 Deaths'], downcast='integer', errors='coerce')\ntrain['Total Deaths'] = pd.to_numeric(train['Total Deaths'], downcast='integer', errors='coerce')\n","ad6d55ce":"train.head()","bbcc5c73":"test.head()","64477f9e":"\nfig = px.histogram(train, x='Start Date', y='COVID-19 Deaths')\nfig","5c379301":"\nfig = px.histogram(train, x='Start Date', y='Total Deaths')\nfig","760fafb4":"\nfig = px.histogram(train, x='Race and Hispanic Origin Group', y='COVID-19 Deaths')\nfig","8a2abf3b":"\nfig = px.histogram(train, x='COVID-19 Deaths', y='Age Group')\nfig\n","c2a076a0":"#OLS MODEL\nx=train['Start Date']\ny=train['Total Deaths']\ny2=train['COVID-19 Deaths']\nxtest=test['id']\nytest=test['Total Deaths']\n\n\n\n","d4b23f09":"x_1=sm.add_constant(x)\nx_2=sm.add_constant(ytest)\nmodel = sm.OLS(y,x_1)\n\nresults = model.fit()\n\nprint(results.params)\ny_hat=(results.predict(x_1)*(y2\/y))\nintegor=(22\/ytest)\nprediction=(results.predict(x_2)*.046755)\n\nplt.scatter(x,y2)\nplt.xlabel(\"Index of Weeks\")\nplt.ylabel(\"Covid Deaths\")\nplt.plot(x,y_hat, \"r\")\nplt.show()","45d59f6f":"print(prediction)","dbaf8765":"print(y_hat.describe())","401bcada":"MSE = np.square(np.subtract(ytest,y_hat)).mean() \n \nRMSE = math.sqrt(MSE)\nprint(\"Root Mean Square Error:\\n\")\nprint(RMSE)","023a466c":"\nfrom sklearn.linear_model import Ridge\nfrom sklearn.pipeline import Pipeline\n\nx=x.values.reshape(-1,1)\ny=y.values.reshape(-1,1)\nxtest=xtest.values.reshape(-1,1)\nclf = Ridge(alpha=1.0)\nclf.fit(x,y)\ny_hat2=clf.predict(x)\n\n\nRidge()\n","7f321d38":"plt.scatter(x,y)\nplt.xlabel(\"Index of Weeks\")\nplt.ylabel(\"Covid Deaths\")\nplt.plot(x,y_hat2, \"r\")\nplt.show()","1d3bc0ce":"MSE = np.square(np.subtract(y,y_hat2)).mean() \n \nRMSE = math.sqrt(MSE)\nprint(\"Root Mean Square Error:\\n\")\nprint(RMSE)","0e9bbfe3":"from sklearn.linear_model import Lasso\nmodel = Lasso(alpha=1.0)\nmodel.fit(x, y)\nyhat = model.predict(x)\n","97eaa050":"MSE = np.square(np.subtract(y,yhat)).mean() \n \nRMSE = math.sqrt(MSE)\nprint(\"Root Mean Square Error:\\n\")\nprint(RMSE)","942d3d53":"plt.scatter(x,y)\nplt.xlabel(\"Index of Weeks\")\nplt.ylabel(\"Covid Deaths\")\nplt.plot(x,yhat, \"r\")\nplt.show()","fe2e4b82":"from sklearn.linear_model import ElasticNet\nfrom sklearn.datasets import make_regression\nregr = ElasticNet(random_state=0)\nregr.fit(x, y)\nElasticNet(random_state=0)\nyhat2=regr.predict(x)\nprint()","36ec211a":"MSE = np.square(np.subtract(y,yhat2)).mean() \n \nRMSE = math.sqrt(MSE)\nprint(\"Root Mean Square Error:\\n\")\nprint(RMSE)","0e5e2709":"plt.scatter(x,y)\nplt.xlabel(\"Index of Weeks\")\nplt.ylabel(\"Covid Deaths\")\nplt.plot(x,yhat2, \"r\")\nplt.show()","e6832010":"Ridge_model=pd.DataFrame(y_hat2) \nLasso_model=pd.DataFrame(yhat) \nElastic_model=pd.DataFrame(yhat2) ","add7d17c":"print(\"OSL EVALUATION \\n\")\nprint(y_hat.describe())\nprint(\"Ridge EVALUATION \\n\")\nprint(Ridge_model.describe())\nprint(\"LASSO EVALUATION \\n\")\nprint(Lasso_model.describe())\nprint(\"Elastic Net EVALUATION \\n\")\nprint(Elastic_model.describe())","9a6f28de":"final_prediction=prediction\nprint(final_prediction)","578eb6e8":"output = pd.DataFrame({\n      \"id\": test[\"id\"],\n     \"COVID-19 Deaths\": final_prediction\n})\n\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","bd766a9b":"# **THIS IS THE OLS MODEL BEGINNING**","d184f2fc":"**NEXT LINE TURNS MY OTHER 3 PREDICTION FROM THE OTHER MODELS INTO 2D ARRAYS AFTER THEY WERE 1D**\n","502cfdfd":"**Truthfully the only good one was the OSL so will store it as predictions and submit**","3f52d3dc":"ACCORDING TO GRAPH BELOW:People didnt know how to stay at their house so as days went by they got COVID","3231f4c6":"# Above is the distribution of the scores using ols model","7f885a4b":"As expected old people died the most from COVID RIP grannies and grandpas","93ce7b44":"checking my new tables for train and test","15703a86":"**Value below is what we are going to see as predictions from ols the best model in existence**","f9fc5696":"# Why is the rmse below the same as on top but graph is not(Hint: idk what it is doing :) )","3d1036cc":"Unexpected I thought hispanics by a landslide would be the most Covid deaths but keep in mind im using small beginning data so that means first people to not care and die from COVID where the non-hispanic white","8fcc5abe":"**Elastic net distribution**","0bd5165c":"RMSE OF OSL","4554321f":"RMSE OF RIDGE","a59a821d":"# Evaluating the predicting scores","63ddb068":"# Ridge Model","5b5960ca":"RMSE OF LASSO","6dcd29e2":"ACCORDING TO GRAPH BELOW: A lot of people die everyday but Covid made it worse but once again appreciate ur life grader you are a survivor\n","9805dfe3":"predictions stores the predicted results using test data with ols","ed8f8a44":"Reading data and downloading","eafe200f":"#   Below is distribution of ridge model data as u can see it is a mess","456e7290":"**RMSE OF elastic**","336ea50f":"# Elastic Net model","f2af0ae0":"**Next lines will be train data trimming by getting rid of unneccesary features that dont have to relate to covid deaths,total deaths and dates.**","72620029":"**TAKE PREDICTIONS AND MULTIPLY BECAUSE IT IS RATIO OF COVID DEATHS\/TOTAL DEATHS TO GET VALUES FOR TEST DATA FOR SOME REASON WHEN I DO TIMES INTEGOR TOO MANY DECIMALS AND SAYS INF DOUBLE SO I DID IT BY MEAN OF THE RATIOS IN THAT COLUMN**","515ca904":"**I definitely did something wrong when building the other 3 models whether it was lack of knowledge or just didnt split data at all will have to improve on it sadly this makes my OSL model the best one**","290120fd":"# Lasso distribution model","90d8f79a":"# Above is description of values using train data","b227b75d":"# Lasso model","126a8c1b":"Wanted to add will group by week and only use a small sample of them to avoid too many outliers later in the data, also switch dates to ints to be able to work with them"}}