{"cell_type":{"ca3a79e3":"code","10124c50":"code","086755df":"code","5d8f4b25":"code","b16d6178":"code","9704ecaf":"code","68f8f367":"code","7e235870":"code","fd31a054":"markdown","52203e91":"markdown","1af7399a":"markdown","d26d3f0c":"markdown","a2358809":"markdown","190477cb":"markdown","900d76d7":"markdown","54278953":"markdown"},"source":{"ca3a79e3":"from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport datetime\nimport glob\nimport numpy\nimport os\nimport tensorflow\n\nfrom keras.callbacks import Callback\nfrom keras.callbacks import CSVLogger\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Concatenate\nfrom keras.layers import Input\nfrom keras.layers import LeakyReLU\nfrom keras.layers import MaxPooling2D\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import UpSampling2D\nfrom keras.models import Model\nfrom matplotlib import pyplot\nfrom PIL import Image","10124c50":"TIMESTAMP        = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n\nRANDOM_SEED      = 99999999\n\nARCHITECTURE     = 'colornet'\n\nTRAIN_IMAGES_DIR = '..\/input\/google-fonts-for-stefann\/colornet\/colornet\/train\/'\nVALID_IMAGES_DIR = '..\/input\/google-fonts-for-stefann\/colornet\/colornet\/valid\/'\nTEST_IMAGES_DIR  = '..\/input\/google-fonts-for-stefann\/colornet\/colornet\/test\/'\nOUTPUT_DIR       = 'output\/{}\/{}\/'.format(ARCHITECTURE, TIMESTAMP)\n\nIMAGE_FILE_EXT   = '.jpg'\n\nFUNCTION_OPTIM   = 'adam'\nFUNCTION_LOSS    = 'mae'\n\nINPUT_IMAGE_SIZE = (64, 64)\n\nSCALE_COEFF_IMG  = 1.\nBATCH_SIZE       = 64\nNUM_EPOCHS       = 10\n\nVERBOSE_LEVEL    = 2\n\nSAVE_IMAGES      = False\nSHOW_IMAGES      = True\nMAX_IMAGES       = 20","086755df":"class DataGenerator(object):\n    def __init__(self, image_dir_input1, image_dir_input2, image_dir_output,\n                 image_ext='.jpg', target_shape=(64, 64), rescale=1.,\n                 batch_size=1, shuffle=True, seed=None):\n        numpy.random.seed(seed)\n        self._imdir_in1 = image_dir_input1\n        self._imdir_in2 = image_dir_input2\n        self._imdir_out = image_dir_output\n        self._imext = image_ext\n        self._shape = target_shape\n        self._scale = rescale\n        self._batch = batch_size\n        self._shake = shuffle\n        self._files = sorted([os.path.split(path)[-1] for path in \\\n                              glob.glob('{}\/*{}'.format(image_dir_input1, image_ext))])\n        self._steps = int(len(self._files) \/ self._batch + 0.5)\n        self._index = 0\n        if shuffle:\n            numpy.random.shuffle(self._files)\n    \n    def flow(self):\n        while True:\n            x1 = []\n            x2 = []\n            y1 = []\n            endidx = self._index + self._batch\n            subset = self._files[self._index:endidx]\n            self._index = endidx if endidx < len(self._files) else 0\n            if self._shake:\n                numpy.random.shuffle(subset)\n            for file in subset:\n                file_input1 = os.path.join(self._imdir_in1, file)\n                file_input2 = os.path.join(self._imdir_in2, file)\n                file_output = os.path.join(self._imdir_out, file)\n                try:\n                    input1 = Image.open(file_input1).convert('RGB').resize(self._shape)\n                    input1 = numpy.asarray(input1, dtype=numpy.uint8)\n                    input1 = numpy.atleast_3d(input1)\n                    input2 = Image.open(file_input2).convert('L').resize(self._shape)\n                    input2 = numpy.asarray(input2, dtype=numpy.uint8)\n                    input2 = numpy.atleast_3d(input2)\n                    output = Image.open(file_output).convert('RGB').resize(self._shape)\n                    output = numpy.asarray(output, dtype=numpy.uint8)\n                    output = numpy.atleast_3d(output)\n                except:\n                    continue\n                x1.append(input1)\n                x2.append(input2)\n                y1.append(output)\n            x1 = numpy.asarray(x1, dtype=numpy.float32) * self._scale\n            x2 = numpy.asarray(x2, dtype=numpy.float32) * self._scale\n            y1 = numpy.asarray(y1, dtype=numpy.float32) * self._scale\n            yield [[x1, x2], y1]","5d8f4b25":"class Colornet(object):\n    def __new__(self, input_shapes, optimizer, loss, weights=None):\n        # build network\n        x1 = Input(input_shapes[0])\n        x2 = Input(input_shapes[1])\n        \n        y1 = Conv2D(filters=64, kernel_size=(3, 3), padding='same')(x1)\n        y1 = LeakyReLU(alpha=0.2)(y1)\n        y1 = BatchNormalization()(y1)\n        \n        y2 = Conv2D(filters=64, kernel_size=(3, 3), padding='same')(x2)\n        y2 = LeakyReLU(alpha=0.2)(y2)\n        y2 = BatchNormalization()(y2)\n        \n        y = Concatenate()([y1, y2])\n        \n        y = Conv2D(filters=64, kernel_size=(3, 3), padding='same')(y)\n        y = LeakyReLU(alpha=0.2)(y)\n        y = Conv2D(filters=64, kernel_size=(3, 3), padding='same')(y)\n        y = LeakyReLU(alpha=0.2)(y)\n        \n        y = MaxPooling2D(pool_size=(2, 2))(y)\n        \n        y = Conv2D(filters=128, kernel_size=(3, 3), padding='same')(y)\n        y = LeakyReLU(alpha=0.2)(y)\n        y = Conv2D(filters=128, kernel_size=(3, 3), padding='same')(y)\n        y = LeakyReLU(alpha=0.2)(y)\n        \n        y = MaxPooling2D(pool_size=(2, 2))(y)\n        \n        y = Conv2D(filters=256, kernel_size=(3, 3), padding='same')(y)\n        y = LeakyReLU(alpha=0.2)(y)\n        y = Conv2D(filters=256, kernel_size=(3, 3), padding='same')(y)\n        y = LeakyReLU(alpha=0.2)(y)\n        y = Conv2D(filters=256, kernel_size=(3, 3), padding='same')(y)\n        y = LeakyReLU(alpha=0.2)(y)\n        \n        y = UpSampling2D(size=(2, 2))(y)\n        y = Conv2D(filters=128, kernel_size=(3, 3), padding='same')(y)\n        y = LeakyReLU(alpha=0.2)(y)\n        \n        y = UpSampling2D(size=(2, 2))(y)\n        y = Conv2D(filters=64, kernel_size=(3, 3), padding='same')(y)\n        y = LeakyReLU(alpha=0.2)(y)\n        \n        y = Conv2D(filters=3, kernel_size=(3, 3), padding='same')(y)\n        y = LeakyReLU(alpha=0.2)(y)\n        \n        # compile network\n        model = Model(inputs=[x1, x2], outputs=y)\n        model.compile(optimizer=optimizer, loss=loss)\n        \n        # optionally load existing weights into network\n        try:\n            if not weights is None:\n                model.load_weights(weights)\n        except:\n            pass\n        \n        return model","b16d6178":"class ProgressMonitor(Callback):\n    def __init__(self, image_dir_input1, image_dir_input2, image_dir_output,\n                 save_to_dir, image_ext='.jpg', rescale=1.,\n                 thumbnail_size=(64, 64), save=True, show=False, max_images=10):\n        self._imdir_in1 = image_dir_input1\n        self._imdir_in2 = image_dir_input2\n        self._imdir_out = image_dir_output\n        self._imdir_dmp = save_to_dir\n        self._img_ext = image_ext\n        self._rescale = rescale\n        self._tn_size = thumbnail_size\n        self._im_save = save\n        self._im_show = show\n        self._max_img = max_images\n    \n    def on_epoch_end(self, epoch, logs):\n        images_all = []\n        images_in1 = sorted(glob.glob(self._imdir_in1 + '\/*' + self._img_ext))[:self._max_img]\n        images_in2 = sorted(glob.glob(self._imdir_in2 + '\/*' + self._img_ext))[:self._max_img]\n        images_out = sorted(glob.glob(self._imdir_out + '\/*' + self._img_ext))[:self._max_img]\n        for image_in1, image_in2, image_out in zip(images_in1, images_in2, images_out):\n            try:\n                img_in1 = Image.open(image_in1).convert('RGB')\n                img_in2 = Image.open(image_in2).convert('L')\n                img_out = Image.open(image_out).convert('RGB')\n                x1 = img_in1.resize(self.model.input_shape[0][1:3])\n                x1 = numpy.asarray(x1, dtype=numpy.float32) * self._rescale\n                x1 = numpy.atleast_3d(x1)\n                x1 = numpy.expand_dims(x1, axis=0)\n                x2 = img_in2.resize(self.model.input_shape[1][1:3])\n                x2 = numpy.asarray(x2, dtype=numpy.float32) * self._rescale\n                x2 = numpy.atleast_3d(x2)\n                x2 = numpy.expand_dims(x2, axis=0)\n                y1 = self.model.predict([x1, x2])\n                y1 = numpy.squeeze(y1)\n                y1 = numpy.asarray(y1 \/ self._rescale, dtype=numpy.uint8)\n                img_gen = Image.fromarray(y1)\n                img_gen = self._postprocess_image(img_gen, img_in2)\n                images_all.append([img_in1, img_in2, img_out, img_gen])\n            except:\n                continue\n        images_all = self._combine_images(images_all, self._tn_size, border_width=4, padding=20)\n        if self._im_save:\n            impath = self._imdir_dmp + '\/epoch_{}.jpg'.format(epoch + 1)\n            self._save_image(impath, images_all)\n        if self._im_show:\n            imdesc = 'Epoch {} - Top to Bottom: Source Color | Target Mask | Target Color | Generated Color'.format(epoch + 1)\n            self._show_image(images_all, imdesc)\n    \n    def _postprocess_image(self, image, mask):\n        image_pped = Image.new(image.mode, image.size)\n        image_mask = mask.convert('L').resize(image.size)\n        image_pped.paste(image, (0, 0), image_mask)\n        return image_pped\n    \n    def _combine_images(self, images=[], size=(64, 64), bg_color=(0, 0, 0),\n                        border_color=(255, 255, 255), border_width=0, padding=0):\n        for i, result in enumerate(images):\n            w1 = size[0] + 2 * border_width\n            h1 = size[1] * len(result) + 2 * border_width\n            bg = Image.new('RGB', (w1, h1), border_color)\n            for j, image in enumerate(result):\n                x1 = border_width\n                y1 = border_width + j * size[1]\n                fg = image.convert('RGB').resize(size, resample=Image.BILINEAR)\n                bg.paste(fg, (x1, y1))\n            images[i] = bg\n        w2 = len(images) * (w1 + padding) + padding\n        h2 = h1 + 2 * padding\n        bg = Image.new('RGB', (w2, h2), bg_color)\n        for k, image in enumerate(images):\n            x2 = k * (w1 + padding) + padding\n            y2 = padding\n            bg.paste(image, (x2, y2))\n        return bg\n    \n    def _save_image(self, filepath, image):\n        directory = os.path.dirname(filepath)\n        if not os.path.isdir(directory) and directory != '':\n            os.makedirs(directory)\n        image.save(filepath)\n    \n    def _show_image(self, image, title=None):\n        pyplot.figure(figsize=(image.width\/100, image.height\/100), dpi=100)\n        pyplot.axis('off')\n        if title:\n            pyplot.title(title)\n        pyplot.imshow(numpy.uint8(image))\n        pyplot.show()","9704ecaf":"def tensorflow_version():\n    return int(tensorflow.__version__.split('.')[0])","68f8f367":"def train():\n    # setup seed for random number generators for reproducibility\n    numpy.random.seed(RANDOM_SEED)\n    \n    if tensorflow_version() == 2:\n        tensorflow.random.set_seed(RANDOM_SEED)\n    else:\n        tensorflow.set_random_seed(RANDOM_SEED)\n    \n    # setup paths\n    mdl_dir = os.path.join(OUTPUT_DIR, 'models')\n    log_dir = os.path.join(OUTPUT_DIR, 'logs')\n    cpt_dir = os.path.join(OUTPUT_DIR, 'checkpoints')\n    pro_dir = os.path.join(OUTPUT_DIR, 'progress')\n    \n    setup_flag = True\n    for directory in [TRAIN_IMAGES_DIR, VALID_IMAGES_DIR]:\n        if not os.path.isdir(directory):\n            print('[INFO] Data directory not found at {}'.format(directory))\n            setup_flag = False\n    if not os.path.isdir(TEST_IMAGES_DIR):\n        print('[INFO] Data directory not found at {}'.format(directory))\n    for directory in [OUTPUT_DIR, mdl_dir, log_dir, cpt_dir, pro_dir]:\n        if not os.path.isdir(directory):\n            os.makedirs(directory)\n        elif len(glob.glob(os.path.join(directory, '*.*'))) > 0:\n            print('[INFO] Output directory {} must be empty'.format(directory))\n            setup_flag = False\n    if not setup_flag:\n        return\n    \n    mdl_file = os.path.join(mdl_dir, '{}.json'.format(ARCHITECTURE))\n    log_file = os.path.join(log_dir, '{}_training.csv'.format(ARCHITECTURE))\n    cpt_file_best = os.path.join(cpt_dir, '{}_weights_best.h5'.format(ARCHITECTURE))\n    cpt_file_last = os.path.join(cpt_dir, '{}_weights_last.h5'.format(ARCHITECTURE))\n    \n    # initialize train data generator\n    train_datagen = DataGenerator(image_dir_input1=TRAIN_IMAGES_DIR + '\/input_color\/',\n                                  image_dir_input2=TRAIN_IMAGES_DIR + '\/input_mask\/',\n                                  image_dir_output=TRAIN_IMAGES_DIR + '\/output_color\/',\n                                  image_ext=IMAGE_FILE_EXT,\n                                  target_shape=INPUT_IMAGE_SIZE,\n                                  rescale=SCALE_COEFF_IMG,\n                                  batch_size=BATCH_SIZE,\n                                  shuffle=True,\n                                  seed=RANDOM_SEED)\n    \n    # initialize valid data generator\n    valid_datagen = DataGenerator(image_dir_input1=VALID_IMAGES_DIR + '\/input_color\/',\n                                  image_dir_input2=VALID_IMAGES_DIR + '\/input_mask\/',\n                                  image_dir_output=VALID_IMAGES_DIR + '\/output_color\/',\n                                  image_ext=IMAGE_FILE_EXT,\n                                  target_shape=INPUT_IMAGE_SIZE,\n                                  rescale=SCALE_COEFF_IMG,\n                                  batch_size=BATCH_SIZE,\n                                  shuffle=True,\n                                  seed=RANDOM_SEED)\n    \n    # build and serialize network\n    print('[INFO] Building network... ', end='')\n    colornet = Colornet(input_shapes=[INPUT_IMAGE_SIZE + (3,), INPUT_IMAGE_SIZE + (1,)],\n                        optimizer=FUNCTION_OPTIM,\n                        loss=FUNCTION_LOSS,\n                        weights=None)\n    print('done')\n    colornet.summary()\n    \n    with open(mdl_file, 'w') as file:\n        file.write(colornet.to_json())\n    \n    # create callbacks\n    csv_logs = CSVLogger(filename=log_file, append=True)\n    cpt_best = ModelCheckpoint(filepath=cpt_file_best,\n                               monitor='val_loss',\n                               verbose=1,\n                               save_best_only=True,\n                               save_weights_only=True)\n    cpt_last = ModelCheckpoint(filepath=cpt_file_last,\n                               monitor='val_loss',\n                               verbose=0,\n                               save_best_only=False,\n                               save_weights_only=True)\n    progress = ProgressMonitor(image_dir_input1=TEST_IMAGES_DIR + '\/input_color\/',\n                               image_dir_input2=TEST_IMAGES_DIR + '\/input_mask\/',\n                               image_dir_output=TEST_IMAGES_DIR + '\/output_color\/',\n                               save_to_dir=pro_dir,\n                               image_ext=IMAGE_FILE_EXT,\n                               rescale=SCALE_COEFF_IMG,\n                               thumbnail_size=(64, 64),\n                               save=SAVE_IMAGES,\n                               show=SHOW_IMAGES,\n                               max_images=MAX_IMAGES)\n    \n    # train network\n    colornet.fit_generator(generator=train_datagen.flow(),\n                           steps_per_epoch=train_datagen._steps,\n                           epochs=NUM_EPOCHS,\n                           callbacks=[csv_logs, cpt_best, cpt_last, progress],\n                           validation_data=valid_datagen.flow(),\n                           validation_steps=valid_datagen._steps,\n                           verbose=VERBOSE_LEVEL)","7e235870":"train()","fd31a054":"## Train Colornet","52203e91":"## Imports","1af7399a":"## Get TensorFlow Version Number","d26d3f0c":"## Configurations","a2358809":"## Custom Callback - Progress Monitor","190477cb":"## Data Generator","900d76d7":"## Colornet - Color Transfer Neural Network\n\n![Colornet](attachment:colornet.svg)","54278953":"# STEFANN: Scene Text Editor using Font Adaptive Neural Network (CVPR 2020)\n\n>In this paper, we propose a generalized method for realistic modification of textual content present in a scene image at chracter-level. We approach the problem in two stages. At first, the unobserved character (target) is generated from an observed character (source) being modified. Next, we replace the source character with the generated target character maintaining both geometric and visual consistency with neighboring characters.\n\n[Project](https:\/\/prasunroy.github.io\/stefann) \u2022 [Paper](https:\/\/prasunroy.github.io\/static\/docs\/publications\/CVPR2020-8915.pdf) \u2022 [Video](https:\/\/www.youtube.com\/watch?v=HTVQXHPIKKo&list=PLfztDj7uiveWDLqGf41bheERg__t8JWWl) \u2022 [Code](https:\/\/github.com\/prasunroy\/stefann) \u2022 [CVF Open Access](http:\/\/openaccess.thecvf.com\/content_CVPR_2020\/html\/Roy_STEFANN_Scene_Text_Editor_Using_Font_Adaptive_Neural_Network_CVPR_2020_paper.html)\n\n![STEFANN](https:\/\/prasunroy.github.io\/static\/imgs\/publications\/CVPR2020-8915.png)\n\n## Starter \\#2: Color Transfer with Colornet\n\nOur generation pipeline involves two separate neural networks:\n- **FANnet** to achieve structural consistency with source font\n- **Colornet** to preserve color of source font\n\n### This kernel demonstrates the font color transfer by Colornet. The code is adopted from the [original implementation](https:\/\/github.com\/prasunroy\/stefann).\n\nFANnet is demonstrated in a separate kernel [Starter #1](https:\/\/www.kaggle.com\/prasunroy\/starter-1-font-generation-stefann-cvpr-2020).\n\n## Citation\n\n```\n@InProceedings{Roy_2020_CVPR,\n  title     = {STEFANN: Scene Text Editor using Font Adaptive Neural Network},\n  author    = {Roy, Prasun and Bhattacharya, Saumik and Ghosh, Subhankar and Pal, Umapada},\n  booktitle = {The IEEE\/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n  month     = {June},\n  year      = {2020}\n}\n```"}}