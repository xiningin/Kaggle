{"cell_type":{"8abcdd18":"code","3d29812a":"code","28a646e6":"code","336fd240":"code","bef124e7":"code","e44db521":"code","4ae40ec3":"code","4374be8c":"code","63b5db01":"code","6fd54981":"code","0d45162d":"code","703e4f62":"code","6e7645a6":"code","80685bfd":"code","3e73d5a7":"code","b910b2dd":"code","3b52b02a":"code","fdfa9f17":"code","ce163d03":"code","db889163":"code","195b7eb4":"code","5c4c6d35":"code","f312edd7":"code","a04cf500":"code","bead527c":"code","7fe45a5d":"code","2120a622":"code","d0dd864b":"code","e584941c":"code","2c025422":"code","564d9185":"code","bc50bed0":"code","2f7b8325":"code","930327d1":"code","2dcb6d5b":"code","00adfdff":"code","d2dec468":"code","b1e9675d":"code","0b11a15f":"code","ef5a0885":"code","026ae994":"code","b2bbc7a7":"code","cdfbf2d9":"code","15a8253b":"code","0c4995b0":"code","31d50312":"code","71260d82":"code","08a0fe29":"code","9a864cb3":"code","6f8b7c99":"code","c721dd84":"code","5b3f987c":"code","28c65943":"code","25f129f4":"code","2193673f":"code","69a99d62":"code","d18bbb92":"code","ccf47e2d":"code","5d7f7240":"code","a8e86198":"code","7470b4cf":"code","2925b063":"code","31dce780":"code","dd401259":"code","3ab8af9d":"code","da002aa2":"code","db68777d":"code","f615b916":"code","88b0b92d":"code","d7432a98":"code","57ebfa7e":"code","7c3e89bc":"code","0bf76aeb":"code","7a653c92":"code","6816a4bd":"code","9de435bd":"code","31bf1fff":"code","b6de705e":"code","70fe9c6c":"code","15b45da5":"code","75a1c75b":"code","269fe1c6":"code","be4f9aa1":"markdown","ffc47abf":"markdown","4547fec6":"markdown","a0e3526f":"markdown","b8b94543":"markdown","dcf3c397":"markdown","e7a7021b":"markdown","f78e00cc":"markdown","39779433":"markdown","5e33618f":"markdown","80cb37a3":"markdown","c6a415f5":"markdown","74ed1e67":"markdown","fd2133dd":"markdown","5aa5e8e5":"markdown","1ca44806":"markdown","7468a134":"markdown","b3017675":"markdown","2768a7ba":"markdown","76d2ce9d":"markdown","e6c8f764":"markdown","4c97deb4":"markdown","9c7dca57":"markdown","da119d4b":"markdown","7d6291d6":"markdown","37440d0b":"markdown","936b279a":"markdown","41b363a5":"markdown","d0f91dce":"markdown","8ee9e7f0":"markdown"},"source":{"8abcdd18":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport plotly.express as px # library for plotting\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3d29812a":"signals = pd.read_csv('\/kaggle\/input\/bearing-classification\/bearing_signals.csv', low_memory=False)","28a646e6":"labels = pd.read_csv('\/kaggle\/input\/bearing-classification\/bearing_classes.csv',sep=\";\")","336fd240":"id_experiment = 95\nexperiment = signals[signals['experiment_id']==id_experiment]","bef124e7":"experiment.info()","e44db521":"experiment.describe()","4ae40ec3":"fig = px.line(experiment, x=\"timestamp\", y=[\"a2_y\",\"a1_y\"], title='The vibration both accelerometers by axis y')\nfig.show()","4374be8c":"fig = px.line(experiment, x=\"timestamp\", y=[\"a2_z\",\"a1_z\"], title='The vibration both accelerometers by axis z')\nfig.show()","63b5db01":"fig = px.line(experiment, x=\"timestamp\", y=[\"hz\"], title='The speed motor ')\nfig.show()","6fd54981":"# get steady speed \nsteady_filter = (experiment['hz'] > 24) & (experiment['hz'] < 27)\nexperiment_steady_speed = experiment[steady_filter]","0d45162d":"fig = px.line(experiment_steady_speed, x=\"timestamp\", y=[\"hz\"], title='The speed motor ')\nfig.show()","703e4f62":"experiment_steady_speed['a2_y'].describe()","6e7645a6":"raw_signal_a1_y = experiment_steady_speed['a1_y']\nraw_signal_a2_y = experiment_steady_speed['a2_y']","80685bfd":"def get_current_rate(df, step):\n    time_step = df['timestamp'].iloc[step+1] - df['timestamp'].iloc[step]\n    sample_rate = 1.0 \/ time_step\n    cur_freq = df['hz'].iloc[step]\n    return cur_freq, sample_rate\n","3e73d5a7":"from scipy.fft import fft, fftfreq\n\ndef get_fft(df,fs):\n    N=len(df)\n    fs = fs\n    x_plot= fftfreq(N, 1\/fs)[:N\/\/2]\n    \n    df_fft = pd.DataFrame()\n    df_phase = pd.DataFrame()\n    for name in df.columns:\n        yf = fft(df[name].values) \n        y_plot= 2.0\/N * np.abs(yf[0:N\/\/2])\n        df_fft = pd.concat([df_fft,\n                            pd.DataFrame({'Frequency (Hz)':x_plot[1:],\n                                          name:y_plot[1:]}).set_index('Frequency (Hz)')],axis=1)\n    \n    return df_fft","b910b2dd":"import scipy.signal as signal\n\ndef get_psd(df,bin_width,fs):\n    fs = fs   \n    f, psd = signal.welch(df.to_numpy(), \n                          fs=fs, \n                          nperseg=fs\/bin_width,\n                          window='hanning',\n                          axis=0\n                         )\n\n    df_psd = pd.DataFrame(psd,columns=df.columns)\n    df_psd.columns\n    df_psd['Frequency (Hz)'] = f\n    df_psd = df_psd.set_index('Frequency (Hz)')\n    return df_psd[1:] #drop the first value because it makes the plots look bad and is effectively 0","3b52b02a":"def get_peak_acceleration(signal):\n    return pd.DataFrame.max(signal.abs())","fdfa9f17":"def get_rms_acceleration(signal):\n    N = len(signal)\n    return np.sqrt(1\/N * (signal**2).sum())","ce163d03":"def get_crest_factor(signal):\n    return get_peak_acceleration(signal)\/get_rms_acceleration(signal)\n","db889163":"def get_std(signal):\n    return signal.std()","195b7eb4":"def get_variance(signal):\n    return signal.var()\n","5c4c6d35":"def get_skewness(signal):\n    return signal.skew()\n","f312edd7":"def get_kurtosis(signal):\n    return signal.kurtosis()\n","a04cf500":"def get_shape_factor(signal):\n    N = len(signal)\n    return np.sqrt(((signal**2).sum()\/N) \/ ((signal.abs()).sum()\/N))","bead527c":"from math import log, e\n\ndef get_entropy(signal, base=None):\n  vc = signal.value_counts(normalize=True, sort=False)\n  base = e if base is None else base\n  return -(vc * np.log(vc)\/np.log(base)).sum()\n\n","7fe45a5d":"def get_impulse_factor(signal):\n    return signal.abs().max() \/ (signal.abs().sum() \/ len(signal))\n","2120a622":"def get_margin_factor(signal):\n    signal = signal.to_numpy()\n    return np.max(np.abs(signal)) \/ ((np.sum(np.sqrt(np.abs(signal)))\/ len(signal))**2)\n","d0dd864b":"def get_hjorts_parameters(signal):\n    first_diff = signal.diff()\n    first_diff_std = first_diff.std()\n    second_diff = signal.diff().diff()\n    std = signal.std()\n    \n    activity_hjorts_parameters = std**2\n    mobility_hjorts_parameters = first_diff.std()\/std\n    complexity_hjorts_parameters = (second_diff.std()\/first_diff_std )\/ (first_diff_std \/ std)\n    return [activity_hjorts_parameters, mobility_hjorts_parameters, complexity_hjorts_parameters]\n","e584941c":"def get_frequency_centre(signal):\n    return ((signal.diff()*signal).sum()) \/ (2 * np.pi * np.sum(signal**2))\ndef get_mean_square_frequency(signal):\n    return  np.sum(signal.diff()**2) \/ (4 * np.pi**2 * np.sum(signal**2))\ndef get_root_mean_square_frequency(signal):\n    return  np.sqrt(get_mean_square_frequency(signal))\ndef get_root_variance_frequency(signal):\n    return  np.sqrt(get_mean_square_frequency(signal) - get_frequency_centre(signal)**2)\n\n","2c025422":"import collections\n \nfrom scipy.stats import entropy\n  \ndef get_shannon_entropy(signal):\n    bases = collections.Counter([tmp_base for tmp_base in signal])\n    # define distribution\n    dist = [x\/sum(bases.values()) for x in bases.values()]\n \n    # use scipy to calculate entropy\n    entropy_value = entropy(dist, base=2)\n \n    return entropy_value\n\n# print(get_shannon_entropy(raw_signal_a2_y))","564d9185":"list_features_function = [get_peak_acceleration, get_rms_acceleration, get_crest_factor,get_std, get_variance,\n                          get_skewness, get_kurtosis, get_shape_factor, get_entropy, get_impulse_factor, get_margin_factor,\n                          get_hjorts_parameters, get_frequency_centre, get_mean_square_frequency, get_root_mean_square_frequency,\n                          get_root_variance_frequency]","bc50bed0":"experiments = signals['experiment_id'].unique()\ndata_stationary_feaures = []\nfor exp in experiments:\n    experiment = signals[(signals['experiment_id']==exp)]\n    steady_filter = (experiment['hz'] > 24) & (experiment['hz'] < 27)\n    experiment_steady = experiment[steady_filter]\n    feature_a1_y = []\n    feature_a2_y = []\n    for func in list_features_function:\n        a1 = func(experiment_steady['a1_y'])\n        a2 = func(experiment_steady['a2_y'])\n        if type(a1) == list:\n            feature_a1_y+=a1\n            feature_a2_y+=a2\n            \n        else:\n            feature_a1_y.append(a1)\n            feature_a2_y.append(a2)\n    data_stationary_feaures.append((feature_a1_y,feature_a2_y))\n\n    ","2f7b8325":"data_stationary_feaures = np.array(data_stationary_feaures,ndmin=3)\ndf_first = pd.DataFrame(data_stationary_feaures[:,0,:]) # df_first is dataframe of the features first bearing in each experiment\ndf_second = pd.DataFrame(data_stationary_feaures[:,1,:])# df_second is dataframe of the features second bearing in each experiment","930327d1":"fig =px.bar(df_first)\nfig.update_yaxes(range=[0,150])\nfig.show()\n","2dcb6d5b":"fig =px.bar(df_second)\nfig.update_yaxes(range=[0,150])\nfig.show()","00adfdff":"from sklearn.cluster import KMeans, Birch, DBSCAN,MeanShift, OPTICS, SpectralBiclustering\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA, TruncatedSVD\nfrom sklearn.manifold import Isomap\nfrom sklearn.preprocessing import StandardScaler\n\n# scaler = StandardScaler()\n# df_second = scaler.fit_transform(df_second)\nX_train = X_chunks.copy() # check only the second bearing\nN_classes = 3\n\nkmeans = KMeans(N_classes).fit(X_train)\nbirch = Birch(N_classes).fit(X_train)\ndbscan = DBSCAN(eps=3, min_samples=10).fit(X_train)\nmean_shift = MeanShift(bandwidth=5).fit(X_train)\noptics = OPTICS(min_samples=10).fit(X_train)\n\nclusters_algorithms = [kmeans, birch, dbscan, mean_shift, optics]\ndecomposition_algorithms = [TruncatedSVD, TSNE, PCA, Isomap]","d2dec468":"\ndef SetColor(x):\n    colors = [\"red\",\"blue\",\"green\",\"magenta\",\"yellow\",\"orange\", \n              \"pink\", \"cyan\", \"black\",\"#eee32ff\", \"#1eebff\", \"#fe2212\",\"#eee3211\", \"#1efbff\", \n              \"#fe2512\", \"#aae32a\", \"#22ebff\", \"#ef2212\"]\n    try:\n        return colors[int(x)]\n    except:\n        return \"red\"","b1e9675d":"import plotly.graph_objects as go\n\n\n\n\n\nfor cluster_alg in clusters_algorithms:\n    for dec_alg in decomposition_algorithms:\n        decomposition = dec_alg(n_components=2)\n        X_transformed = decomposition.fit_transform(X_train)\n        \n        x = X_transformed[:,0]\n        y = X_transformed[:,1]\n        \n        markers = dict(color=list(map(SetColor, cluster_alg.labels_)))\n        text_id = Y# id_bearing with 0 isn't participate on bearing second place \n        \n\n        fig = go.Figure()\n        fig.add_trace(go.Scatter(mode='markers',x=x,y=y, marker = markers , text=text_id))\n        \n        fig.update_layout(\n            title=str(cluster_alg) + \" \" + str(decomposition),\n            xaxis_title=\"X Axis Title\",\n            yaxis_title=\"Y Axis Title\",\n            legend_title=\"Legend Title\",\n            font=dict(\n                family=\"Courier New, monospace\",\n                size=18,\n                color=\"RebeccaPurple\"\n            )\n        )\n        \n        SMALL = 6\n        BIG = 22\n        \n        marker_size=[SMALL if status == 0 else BIG for status in Y ]\n        \n        fig.data[0].update(marker_size=marker_size)\n        fig.show()","0b11a15f":"from scipy import interpolate\n\nexperiments = signals['experiment_id'].unique()\n\ndata_fft_features = []\nfor exp in experiments:\n    experiment = signals[(signals['experiment_id']==exp)]\n    steady_filter = (experiment['hz'] > 24) & (experiment['hz'] < 26)\n    \n    experiment_steady_speed = experiment[steady_filter]\n    \n    signal = experiment_steady_speed['a2_y']\n    fft_ = get_fft(pd.DataFrame(signal), 3000)\n\n    freq = fft_['a2_y'].index.to_numpy()\n    val = fft_['a2_y'].to_numpy()\n    \n    mean_speed = experiment_steady_speed['hz'].mean()\n    val = val\/mean_speed\n\n    interpolate_function_fft = interpolate.interp1d(freq, val, kind = 'linear')\n\n    start_hz = 1\n    end_hz = 200\n    step = 1\n\n    freq_new = np.arange(start_hz,end_hz + 1,step)\n    val_new = interpolate_function_fft(freq_new)\n    data_fft_features.append(val_new[:end_hz])\n    \n\n#     fig = go.Figure()\n#     cutted_hz = end_hz\n#     fig.add_trace(go.Scatter(x=freq[freq<cutted_hz], y=val[freq<cutted_hz],mode='lines',name='Fft'))\n#     fig.add_trace(go.Scatter(x=freq_new[:cutted_hz], y=val_new[:cutted_hz],mode='lines',name='Fft after interpolation and get values with an interval of 1 hz'))\n#     fig.show()\n","ef5a0885":"data_fft_features = np.array(data_fft_features)\ndata_fft_features.shape","026ae994":"from sklearn.cluster import KMeans, Birch, DBSCAN,MeanShift, OPTICS, SpectralBiclustering\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA, TruncatedSVD\nfrom sklearn.manifold import Isomap\nfrom sklearn.preprocessing import StandardScaler\nimport plotly.graph_objects as go\nN_classes = 3\n\nX_train = np.array(X_fft).copy()\n\nkmeans = KMeans(N_classes).fit(X_train)\ndbscan = DBSCAN(eps=2, min_samples=20).fit(X_train)\nmean_shift = MeanShift(bandwidth=2).fit(X_train)\noptics = OPTICS(min_samples=3).fit(X_train)\n\nclusters_algorithms = [kmeans, dbscan, mean_shift, optics]\ndecomposition_algorithms = [TruncatedSVD, TSNE, PCA, Isomap]\n\n","b2bbc7a7":"for cluster_alg in clusters_algorithms:\n    for dec_alg in decomposition_algorithms:\n        decomposition = dec_alg(n_components=2)\n        X_transformed = decomposition.fit_transform(X_train)\n        \n        x = X_transformed[:,0]\n        y = X_transformed[:,1]\n\n        markers = dict(color=list(map(SetColor, cluster_alg.labels_)))\n        text_id = Y\n\n        fig = go.Figure()\n        fig.add_trace(go.Scatter(mode='markers',x=x,y=y, marker = markers , text=text_id))\n        fig.update_layout(\n            title=str(cluster_alg) + \" \" + str(decomposition),\n            xaxis_title=\"X Axis Title\",\n            yaxis_title=\"Y Axis Title\",\n            legend_title=\"Legend Title\",\n            font=dict(\n                family=\"Courier New, monospace\",\n                size=18,\n                color=\"RebeccaPurple\"\n            )\n        )\n        \n        small = 6\n        big = 22\n        \n        marker_size=[small if status == 0 else big for status in Y ]\n        \n        fig.data[0].update(marker_size=marker_size)\n        fig.show()","cdfbf2d9":"def get_one_turn_signal(signals):\n    time_step = b_data['Time'].iloc[1] - b_data['Time'].iloc[0]\n    sample_rate = 1.0 \/ time_step\n    cur_freq = b_data['Hz'].iloc[0]\n\n    n_rot = 3\n    num_pints = n_rot * int(sample_rate \/ cur_freq)\n","15a8253b":"from scipy import interpolate\nexperiments = signals['experiment_id'].unique()\nexperiments = experiments[experiments != 101]\nexperiments = experiments[experiments != 102]\nprint(experiments)\nX = []\nY = []\nX_fft = []\nX_chunks = []\nid_experience_test = np.random.choice(experiments[:100],size=20, replace=False)\nid_experience_test = np.append(id_experience_test,np.random.choice(experiments[100:],size=5, replace=False))\nprint(id_experience_test)","0c4995b0":"x_fft_validation = []\nx_chunks_validation = []\nx_validation = []\ny_validation = []\nfor exp in experiments:\n    # print(exp)\n    experiment = signals[(signals['experiment_id']==exp)]\n    steady_filter = (experiment['hz'] > 24) & (experiment['hz'] < 27)\n    experiment_steady = experiment[steady_filter]\n    sig = experiment_steady['a2_y']\n    y = int(labels[(labels['bearing_id'] == exp)]['status'])\n    \n    chunks = [sig[i:i + N] for i in range(0, len(sig), N)]\n    chunks.pop(-1)\n    \n    for chunk in chunks:\n        \n        features = []\n        for func in list_features_function:\n            a1 = func(chunk)\n            if type(a1) == list:\n                features+=a1\n            else:\n                features.append(a1)\n        \n        fft_ = get_fft(pd.DataFrame(chunk), 3000)\n\n        freq = fft_['a2_y'].index.to_numpy()\n        val = fft_['a2_y'].to_numpy()\n        mean_speed = experiment_steady['hz'].mean()\n        val_normalized = val\/mean_speed\n        \n        interpolate_function_fft = interpolate.interp1d(freq, val_normalized, kind = 'linear')\n\n        start_hz = 1\n        end_hz = 200\n        step = 1\n\n        freq_new = np.arange(start_hz,end_hz + 1,step)\n        val_new = interpolate_function_fft(freq_new)\n        \n        if exp not in id_experience_test:\n            X_fft.append(val_new[:end_hz])\n            X_chunks.append(chunk)\n            X.append(features)\n            Y.append(y)\n        else:\n            x_fft_validation.append(val_new[:end_hz])\n            x_chunks_validation.append(chunk)\n            x_validation.append(features)\n            y_validation.append(y)\n\n","31d50312":"np.array(X).shape","71260d82":"np.array(Y).shape","08a0fe29":"np.array(X_fft).shape","9a864cb3":"np.array(X_chunks).shape","6f8b7c99":"np.array(x_validation).shape","c721dd84":"from sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import plot_roc_curve\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import plot_det_curve\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\nimport matplotlib.pyplot as plt\n\n# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=15, shuffle=True)\nX_train, y_train = X_chunks, Y\n# X_train, X_test, y_train, y_test = train_test_split(X_fft, Y, test_size=0.33, random_state=15, shuffle=True)\nclassifiers = {\n    \"Linear SVM\": make_pipeline(StandardScaler(), SVC(gamma='auto', kernel=\"rbf\")),\n    \"Random Forest\": RandomForestClassifier(\n        max_depth=5, n_estimators=10, max_features=1, class_weight='balanced'\n    ),\n    \"DecisionTreeClassifier\": DecisionTreeClassifier(random_state=0),\n    \"AdaBoostClassifier\": AdaBoostClassifier(n_estimators=100, random_state=0),\n    \"KNeighbor\": KNeighborsClassifier(n_neighbors=6),\n    \"GradientBoostingClassifier\": GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0),\n    \"GaussianProcessClassifier\": GaussianProcessClassifier(kernel=1.0 * RBF(1.0),random_state=0),\n    \"LogisticRegression\": LogisticRegression(random_state=0, solver='lbfgs'),\n    'MLPCLassifier': MLPClassifier(random_state=1),\n    \"GaussianNB\":GaussianNB()\n    \n}\n\n\nfig, [ax_roc, ax_det] = plt.subplots(1, 2, figsize=(22, 7))\nfor name, clf in classifiers.items():\n    clf.fit(X_train, y_train)\n    y_predict = clf.predict(x_chunks_validation)\n    \n    print(\"\\n\\n\" + name + \"\\n\\n\")\n    print(\"\\n\" + \"Metrics:\" + \"\\n\")\n    print(classification_report(y_validation, y_predict))\n    print(\"\\n\")\n    print(\"\\n\" + \"Confusion Matrix:\" + \"\\n\")\n    print(confusion_matrix(y_validation, y_predict))\n    print(\"\\n____________________________________________\\n\")\n\n    plot_roc_curve(clf, x_chunks_validation, y_validation, ax=ax_roc, name=name)\n    plot_det_curve(clf, x_chunks_validation, y_validation, ax=ax_det, name=name)\nplt.show()","5b3f987c":"unique, counts = np.unique(Y, return_counts=True)\ndict(zip(unique, counts))","28c65943":"\nplot_det_curve(clf, X_test, y_test)\nplt.show()","25f129f4":"for i in y_predict:\n    print(i, end=\" \")","2193673f":"for i in y_test:\n    print(i, end=\" \")","69a99d62":"import matplotlib.pyplot as plt\n%matplotlib inline\nid_experiment = 54\npowerSpectrum, freqenciesFound, time, imageAxis = plt.specgram(signals[signals['experiment_id']==id_experiment]['a2_y'], Fs=3000)\n\nplt.xlabel('Time')\nplt.title('SpecGram Bearing #2 in experiment {}'.format(id_experiment))\nplt.ylabel('Frequency')\nplt.show()","d18bbb92":"powerSpectrum, freqenciesFound, time, imageAxis = plt.specgram(raw_signal_a1_y, Fs=3000)\n\nplt.xlabel('Time')\nplt.title('SpecGram Bearing #1 in experiment {}'.format(id_experiment))\nplt.ylabel('Frequency')\nplt.show()","ccf47e2d":"import scipy.signal as signal\nimport plotly.graph_objects as go\nid_experiment=92\nfreqs_first, psd_first = signal.welch(signals[signals['experiment_id']==id_experiment]['a2_y'],fs=3000)\nfreqs_second, psd_second = signal.welch(signals[signals['experiment_id']==id_experiment]['a1_y'],fs=3000)\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=freqs_first, y=psd_first,\n                    mode='lines',\n                    name='First bearing'))\nfig.add_trace(go.Scatter(x=freqs_second, y=psd_second,\n                    mode='lines',\n                    name='second_bearing'))","5d7f7240":"fft_second = get_fft(pd.DataFrame(raw_signal_a2_y), 3000)\nfft_first = get_fft(pd.DataFrame(raw_signal_a1_y), 3000)\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=fft_second.index, y=fft_second.iloc[:,0],\n                    mode='lines',\n                    name='Second bearing'))\nfig.add_trace(go.Scatter(x=fft_first.index, y=fft_first.iloc[:,0],\n                    mode='lines',\n                    name='First bearing'))","a8e86198":"df_psd_first = get_psd(pd.DataFrame(raw_signal_a1_y), 1, 3000)\ndf_psd_second = get_psd(pd.DataFrame(raw_signal_a2_y), 1, 3000)\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=df_psd_second.index, y=df_psd_second.iloc[:,0],\n                    mode='lines',\n                    name='Second bearing'))\nfig.add_trace(go.Scatter(x=df_psd_first.index, y=df_psd_first.iloc[:,0],\n                    mode='lines',\n                    name='First bearing'))","7470b4cf":"!pip install tftb","2925b063":"import tftb","31dce780":"sig = raw_signal_a2_y[0:300].to_numpy()\ntimestamps = experiment_steady_speed['timestamp'][0:300].to_numpy()\nwvd = tftb.processing.WignerVilleDistribution(sig, timestamps=timestamps)\ntfr_wvd, t_wvd, f_wvd = wvd.run()\n\n\ndt = 1 \/3000\nts = timestamps\nf_wvd = np.fft.fftshift(np.fft.fftfreq(tfr_wvd.shape[0], d=2 * dt))\ndf_wvd = f_wvd[1]-f_wvd[0]  # the frequency step in the WVT\nim = plt.imshow(np.fft.fftshift(tfr_wvd, axes=0), aspect='auto', origin='lower',\n       extent=(ts[0] - dt\/2, ts[-1] + dt\/2,\n               f_wvd[0]-df_wvd\/2, f_wvd[-1]+df_wvd\/2))\nplt.xlabel('time [s]')\nplt.ylabel('frequency [Hz]')\nplt.colorbar(im)\nplt.title('Wigner-Ville Transform')\nplt.show()","dd401259":"experiment[['a1_y','a2_y']].plot.hist(alpha=0.5, log=True)","3ab8af9d":"experiment[['a1_y','a2_y']].plot.kde()","da002aa2":"!pip install AntroPy","db68777d":"import antropy as ent\n# ent.spectral_entropy(raw_signal_a2_y, sf=3000, method='fft',normalize=True)\nent.spectral_entropy(raw_signal_a2_y, sf=3000, nperseg=10000)","f615b916":"def rolling_window(a, window):\n    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n    strides = a.strides + (a.strides[-1],)\n    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\nrolling_window_a2_y = rolling_window(raw_signal_a2_y.to_numpy(), 10000)\nrolling_window_a2_y.shape","88b0b92d":"spectral_entropy_list = []\nfor window in rolling_window_a2_y:\n    spectral_entropy_list.append(ent.spectral_entropy(window, sf=3000, method='welch'))\n\npx.line(spectral_entropy_list)","d7432a98":"from scipy import signal\nimport matplotlib.pyplot as plt\nf, t, Sxx = signal.spectrogram(raw_signal_a2_y, 3000)\nplt.pcolormesh(t, f[:15], Sxx[:15,:], shading='gouraud')\nplt.ylabel('Frequency [Hz]')\nplt.xlabel('Time [sec]')\nplt.show()","57ebfa7e":"f, t, Sxx = signal.spectrogram(raw_signal_a1_y, 3000)\nplt.pcolormesh(t, f[:15], Sxx[:15,:], shading='gouraud')\nplt.ylabel('Frequency [Hz]')\nplt.xlabel('Time [sec]')\nplt.show()","7c3e89bc":"import plotly.graph_objects as go\nfrom scipy import signal\nanalytic_signal = signal.hilbert(raw_signal_a2_y)\namplitude_envelope = np.abs(analytic_signal)\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=experiment_steady_speed['timestamp'], y=raw_signal_a2_y,\n                    mode='lines',\n                    name='lines'))\nfig.add_trace(go.Scatter(x=experiment_steady_speed['timestamp'], y=amplitude_envelope,\n                    mode='lines',\n                    name='lines'))\nfig.show()","0bf76aeb":"px.line(get_fft(pd.DataFrame(amplitude_envelope), 3000)[:500])","7a653c92":"px.line(get_psd(pd.DataFrame(amplitude_envelope), 1,3000)[:500])","6816a4bd":"experiments = signals['experiment_id'].unique()\ndata = []\nfor exp in experiments:\n    experiment = signals[(signals['experiment_id']==exp)]\n    steady_filter = (experiment['hz'] > 22) & (experiment['hz'] < 27)\n    experiment_steady_speed = experiment[steady_filter]\n    feature_a1_y = []\n    feature_a2_y = []\n    for func in list_features_function:\n        a1 = func(experiment['a1_y'])\n        a2 = func(experiment['a2_y'])\n        if type(a1) == list:\n            feature_a1_y+=a1\n            feature_a2_y+=a2\n            \n        else:\n            feature_a1_y.append(a1)\n            feature_a2_y.append(a2)\n    data.append((feature_a1_y,feature_a2_y))\n\n    ","9de435bd":"!pip install tftb","31bf1fff":"!pip install EMD-signal","b6de705e":"from PyEMD import EEMD\nimport numpy as np\nimport pylab as plt\n\n# Define signal\nt = np.linspace(0, 1, 200)\n\nsin = lambda x,p: np.sin(2*np.pi*x*t+p)\nS = 3*sin(18,0.2)*(t-0.2)**2\nS += 5*sin(11,2.7)\nS += 3*sin(14,1.6)\nS += 1*np.sin(4*2*np.pi*(t-0.8)**2)\nS += t**2.1 -t\n\n# Assign EEMD to `eemd` variable\neemd = EEMD()\n\n# Say we want detect extrema using parabolic method\nemd = eemd.EMD\nemd.extrema_detection=\"parabol\"\n# Execute EEMD on S\nS = experiment_steady_speed['a2_y'].to_numpy()[:3000]\nt = experiment_steady_speed['timestamp'].to_numpy()[:3000]\neIMFs = eemd.eemd(S, t)\nnIMFs = eIMFs.shape[0]\n\n# Plot results\nplt.figure(figsize=(20,15))\nplt.subplot(nIMFs+1, 1, 1)\nplt.plot(t, S, 'r')\n\nfor n in range(nIMFs):\n    plt.subplot(nIMFs+1, 1, n+2)\n    plt.plot(t, eIMFs[n], 'g')\n    plt.ylabel(\"eIMF %i\" %(n+1))\n    plt.locator_params(axis='y', nbins=5)\n\nplt.xlabel(\"Time [s]\")\nplt.tight_layout()\nplt.savefig('eemd_example', dpi=120)\nplt.show()","70fe9c6c":"px.line(get_fft(pd.DataFrame(eIMFs[2]), 3000))","15b45da5":"corr = signal.correlate(S, np.ones(128), mode='same') \/ 128\npx.line(y=[corr])","75a1c75b":"f, Cxy = signal.coherence(t, S, 300, nperseg=1024)\nplt.semilogy(f, Cxy)\nplt.xlabel('frequency [Hz]')\nplt.ylabel('Coherence')\nplt.show()","269fe1c6":"from scipy import signal\nfrom scipy.fft import fftshift\nf, t, Sxx = signal.spectrogram(raw_signal_a2_y, 3000, return_onesided=False)\nplt.pcolormesh(t, fftshift(f), fftshift(Sxx, axes=0), shading='gouraud')\nplt.ylabel('Frequency [Hz]')\nplt.xlabel('Time [sec]')\nplt.show()","be4f9aa1":"Estimate power spectral density using Welch\u2019s method.\n\nWelch\u2019s method computes an estimate of the power \nspectral density by dividing the data into overlapping segments, \ncomputing a modified periodogram for each segment and averaging the periodograms.","ffc47abf":"# Let's use dimensionality reduction techniques to visualize the resulting features on a plane.","4547fec6":"# Load dataset for processing","a0e3526f":"#  Get some distribution of signals","b8b94543":"# Let's see the spectral characteristics of the signal (doing at the moment)","dcf3c397":"Hjorts\u2019 parameters are calculated based on the first and the second derivatives of the vibration signal. \nIn the time series context, the numerical values for the derivatives are obtained as the differences \nbetween the current value and the prior value. There are three parameters: activity, mobility, complexity. \nThese parameters have been used in electroencephalography (EEG) signals to detect the epileptic seizures. \nThey have never been used in vibration bearing signal except for activity feature, which is similar to the \nvariance feature in the statistical time-domain features extraction.","e7a7021b":"A Power Spectral Density (PSD) is the measure of signal's power content versus frequency. \nA PSD is typically used to characterize broadband random signals. \nThe amplitude of the PSD is normalized by the spectral resolution employed to digitize the signal.\n","f78e00cc":"Shape factor is a value that is affected by an object\u2019s shape but is independent of its dimensions.","39779433":"Entropy is a calculation of the uncertainty and randomness of a sampled vibration data.","5e33618f":"Skewness quantifies the asymmetry behavior of vibration signal through its probability density function (PDF).","80cb37a3":"# Visualisation the same things but for one turn","c6a415f5":"Impulse Factor is used to measure how much impact is generated from the bearing defect.\nIF divides the maximum absolute value by the mean of absolute value.","74ed1e67":"# Some visualisation of experiment","fd2133dd":"RMS is by far my preference over peak because it is independent of the sample rate \nand it will more accurately let you compare the vibration levels of two signals. \nThe RMS value increase gradually as fault developed. However, RMS is unable to provide \nthe information of incipient fault stage while it increases with the fault development.\n","5aa5e8e5":"Crest factor (CF) calculates how much impact occur during the rolling element and raceway contact. \nCF is appropriate for \u201cspiky signals\u201d. Crest factor is simply the ratio of the peak acceleration \nto the RMS acceleration, so it is unitless which is always nice. It defines how \"peaky\" a signal is. \nA square wave could have a crest factor of 1 whereas a signal with occasional shock events may have \na very high crest factor. As crest factor increases, it tends to be an indicator of bearing failure.\n","1ca44806":"Standard deviation is a statistical metric defining the amount of variation in the signal\n","7468a134":"Other frequency-domain features such as frequency centre (FC), root mean square frequency (RMSF) \nand root variance frequency (RVF) are using in vibration feature extraction. When fault exists, the frequency \nelement changes, and the values of the FC, RMSF and RVF also change. The FC and RMSF indicate \nthe position changes of main frequencies, while the RVF shows the convergence of the power spectrum.","b3017675":"# Let's process all experiments and get features for each of them using the functions above","2768a7ba":"# There are the functions for feature extraction from vibration data","76d2ce9d":"Peak acceleration may be easy, but it is often very misleading. \nAnd you can see in the table above that although there is some correlation between \nthe significance of the fault and the peak acceleration, it isn't a perfect correlation. \nPeak acceleration values can be too dependent on a bit of chance with how the sampling lines up with the data. \nMeaning when you are comparing multiple signals to each other, any difference in sample rate or low-pass filters \nwill make the comparison between the peak accelerations inappropriate and even more misleading than normal.","e6c8f764":"Margin factor (MF) measures the level of impact between rolling element and raceway. The MF is\ncalculated by dividing the maximum absolute value of vibration signal to the RMS of absolute value\nof vibration signal","4c97deb4":"Variance measures the dispersion of a signal around their reference mean value.","9c7dca57":"The Wigner distribution (WD) is derived from the relationship between the power spectrum and the autocorrelation function for \ntime-variant and non-stationary processes. The WVD has been used for gear fault detection and it is recently used for rolling \nelement bearing to represent the time-frequency features of vibration signals.","da119d4b":"Get part of experiment where the speed motor was more stable","7d6291d6":"There is the example how to get the experiment by id","37440d0b":"Obviously, there are differences in bearing features.","936b279a":"Kurtosis quantifies the peak value of the PDF. \nThe kurtosis value for normal rolling element bearing is well-recognized as 3.","41b363a5":"A vibration FFT (Fast Fourier Transform) spectrum is an incredibly useful tool for machinery vibration analysis. \nFFT spectra allow us to analyze\nvibration amplitudes at various component frequencies on the FFT spectrum. \nIn this way, we can identify and track vibration occurring at specific frequencies.","d0f91dce":"Get main information about experiment","8ee9e7f0":"# Some additional functions for working with data"}}