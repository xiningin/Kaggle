{"cell_type":{"ac22a281":"code","76b4b5c8":"code","7775bb0e":"code","25973105":"code","79643e9f":"code","534b67de":"code","4aacb9ec":"code","4497927d":"code","fd47cc23":"code","5bf31bcb":"code","8363d346":"code","2f422f7e":"code","6f3ffa2c":"code","3af8b92e":"code","351459db":"code","102c3174":"code","a15671fd":"code","f665f99c":"code","be42b1db":"code","095aa854":"code","222b303c":"code","9d4a8ae4":"code","055adba7":"code","2144ac82":"code","2286166c":"code","b7e2db14":"code","929773b6":"code","9e0e83cb":"markdown","3da36298":"markdown","73dcf800":"markdown"},"source":{"ac22a281":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","76b4b5c8":"# Importaci\u00f3n de Bibliotecas adicionales\n\n# Graficos\nimport matplotlib.pyplot as plt # plotting\nimport seaborn as sns\n\n# Para visualizar imagenes\nfrom IPython.display import Image\nfrom IPython.core.display import HTML","7775bb0e":"# importaci\u00f3n de los datos de entrenamiento\n\ntrain_data_path = \"..\/input\/google-landmarks-dataset\/train.csv\"\ntrain_data = pd.read_csv(train_data_path)\n\n# importaci\u00f3n de los datos de prueba\n\ntest_data_path = \"..\/input\/google-landmarks-dataset\/test.csv\"\ntest_data = pd.read_csv(test_data_path)\n\n# Primera visualizaci\u00f3n de datos importados\n\ntrain_data.head()","25973105":"# Visualizando los datos de prueba\n\ntest_data.head()","79643e9f":"# Importaci\u00f3n de data BOXES\n\n#data_boxes_split1 = pd.read_csv('..\/input\/google-landmarks-dataset\/boxes_split1.csv')\n#data_boxes_split2 = pd.read_csv('..\/input\/google-landmarks-dataset\/boxes_split2.csv')\n#data_boxes = pd.concat([data_boxes_split1, data_boxes_split2])\n\n#print(data_boxes.head())\n\n# Debido a que vamos a hacer predicci\u00f3n de lugares por medio de las imagenes esta importaci\u00f3n no es necesaria.\n# Esta data esta orientada en deteccion de objetos dentro de imagenes.","534b67de":"# mezclar la data de entrenamiento con la data de boxes usando id?\n\n#train_data = pd.merge(train_data, df_boxes, on='id',  how='right')\n#train_data.head()\n\n# Esto tampoco es necesario, pero me pareci\u00f3 importante tomar en consideraci\u00f3n.","4aacb9ec":"# Explorando la forma de los datasets\n\nprint(\"Train data shape -  rows:\",train_data.shape[0],\" columns:\", train_data.shape[1])\nprint(\"Test data size -  rows:\",test_data.shape[0],\" columns:\", test_data.shape[1])","4497927d":"# Explorando la data de entrenamiento y su cantidad de filas\n\ntrain_data.info()","fd47cc23":"# identificaci\u00f3n de la cantidad de etiquetas diferentes en la data de entrenamiento\n\nlen(train_data[\"landmark_id\"].value_counts())","5bf31bcb":"# Visualizando la columna landmark_id para escoger 5 lugares espec\u00edficos\n# Se escogeran los 5 de mayor aparici\u00f3n en el dataset \n\ntrain_data[\"landmark_id\"].value_counts()","8363d346":"# Cantidad de apariciones de LandMark ID de forma decreciente (Categorias TOP 5)\n\ntemp = pd.DataFrame(train_data.landmark_id.value_counts().head(5))\ntemp.reset_index(inplace=True)\ntemp.columns = ['landmark_id','count']\ntemp","2f422f7e":"# graficando la cantidad de aparaciones de landmarks por id\n\nplt.figure(figsize = (9, 8))\nplt.title('Landmarks m\u00e1s frecuentes')\nsns.set_color_codes(\"pastel\")\nsns.barplot(x=\"landmark_id\", y=\"count\", data=temp,\n            label=\"Count\")\nplt.show()","6f3ffa2c":"# Eliminado las filas con landmark_id igual a None, esta informaci\u00f3n es totalmente innecesaria para lo que vamos a hacer.\n\ntrain_data = train_data.drop(train_data[(train_data['landmark_id'] == 'None')].index)","3af8b92e":"# Corroborando la eliminaci\u00f3n de los landmarks_id marcados con NONE\n\ntemp = pd.DataFrame(train_data.landmark_id.value_counts().head(5))\ntemp.reset_index(inplace=True)\ntemp.columns = ['landmark_id','count']\ntemp","351459db":"# Volvemos a graficar pero ahora si los \"NONE\"\nplt.figure(figsize = (9, 8))\nplt.title('Landmarks m\u00e1s frecuentes')\nsns.set_color_codes(\"pastel\")\nsns.barplot(x=\"landmark_id\", y=\"count\", data=temp,\n            label=\"Count\")\nplt.show()","102c3174":"#\n\nplt.figure(figsize = (8, 8))\nplt.title('Distribuci\u00f3n y densidad de Landmark id ')\nsns.distplot(train_data['landmark_id'],color='green', kde=True,bins=100)\nplt.show()","a15671fd":"# Visualizando la columna landmark_id para escoger 5 lugares especificos\n# Se escogeran los 4 de mayor aparici\u00f3n en el dataset \n\ntrain_data[\"landmark_id\"].value_counts()","f665f99c":"# Dimensionando cuanta informaci\u00f3n realmente tenemos\n\ntrain_data.shape","be42b1db":"# Explorando la cantidad de nulos del dataset de entrenamiento\n\ntrain_data.isnull().sum()","095aa854":"# Explorando datos con menos de 100 apariciones en el dataset\n\nprint(\"N\u00famero de clases con menos de 100 apariciones:\",(train_data['landmark_id'].value_counts() <= 100).sum(),', de un total de',len(train_data['landmark_id'].unique()))","222b303c":"# Ac\u00e1 vamos a sacar las llaves del dataframe acomodado por apariciones.\n\ntrain_data['landmark_id'].value_counts().keys()","9d4a8ae4":"# Funci\u00f3n para visualizar los lugares y conocer visualmente los sitios escogidos\n\ndef display_category(urls):\n    img_style = \"width: 180px; margin: 0px; float: left; border: 1px solid black;\"\n    images_list = ''.join([f\"<img style='{img_style}' src='{u}' \/>\" for _, u in urls.head(5).iteritems()])\n\n    display(HTML(images_list))","055adba7":"category = train_data['landmark_id'].value_counts().keys()[0]\nurls = train_data[train_data['landmark_id'] == category]['url']\ndisplay_category(urls)","2144ac82":"category = train_data['landmark_id'].value_counts().keys()[1]\nurls = train_data[train_data['landmark_id'] == category]['url']\ndisplay_category(urls)","2286166c":"category = train_data['landmark_id'].value_counts().keys()[2]\nurls = train_data[train_data['landmark_id'] == category]['url']\ndisplay_category(urls)","b7e2db14":"category = train_data['landmark_id'].value_counts().keys()[3]\nurls = train_data[train_data['landmark_id'] == category]['url']\ndisplay_category(urls)","929773b6":"category = train_data['landmark_id'].value_counts().keys()[4]\nurls = train_data[train_data['landmark_id'] == category]['url']\ndisplay_category(urls)","9e0e83cb":"De lo anterior se concluye que existen 14945 lugares diferentes y lo mejor es entrenar el modelo con una muestra m\u00e1s peque\u00f1a de esos datos, se van escojer los 5 sitios con m\u00e1s informaci\u00f3n o fotograf\u00edas.","3da36298":"## Como conclusi\u00f3n de este notebook se deciden los siguientes pasos para continuar:\n\n### 1) Se va a trabajar con los siguientes lugares para predicci\u00f3n de imagenes:\n\nEl Vaticano -> 9633\n\nColiseo de Roma -> 6051\n\nChicago -> 6599\n\nAlhambra -> 9779\n\nPraga -> 2061\n\n### 2) Debido a que el dataset no tiene las im\u00e1genes, sino las URL\u00b4s de las mismas se proceder\u00e1 a hacer un notebook de forma local y a bajar 300 fotos de cada una de las 5 categor\u00edas escogidas para finalmente entrenar una red neuronal para predecir sitios con estos datos.","73dcf800":"## De todo el analisis anterior se decide trabajar con los sitios marcados con los codigos: 9633, 6051, 6599, 9779 y 2061"}}