{"cell_type":{"094a91c7":"code","c2daad03":"code","f3396bec":"code","e2b5e09e":"code","6d3c69b8":"code","46e99208":"code","2abcb61c":"code","bc163343":"code","43503942":"code","9770e1b7":"code","6921be42":"code","a0a89c2c":"code","ced0ba17":"code","c21bf166":"code","237d95e1":"code","901b9999":"code","1c8b17ce":"code","bda59c22":"code","80da0808":"code","34fd4845":"code","100b2140":"code","ce4038f0":"code","310865d2":"code","d49381a5":"code","0020a430":"code","01e8bde2":"code","3ba6794b":"code","98f271f4":"code","f68fc77d":"code","e40bed2e":"code","0dfa1feb":"code","f4eaa599":"code","0c0241bf":"code","58badfcc":"code","527970b2":"code","2113f730":"code","2a3e281d":"code","36c265bf":"code","7b0fd024":"code","9d623f07":"code","72f380ae":"code","745c0cd7":"code","61c6057f":"code","14872803":"code","0a4650e6":"code","2d1ccc43":"code","5c551de7":"code","a0a07486":"code","6e68318a":"code","6c2477d8":"code","9aaaa334":"code","2b3be577":"code","f20fa3f4":"markdown","e3068a03":"markdown","a80bc86f":"markdown","9a4e9e27":"markdown","7d48a88a":"markdown","6c35d875":"markdown","8126e367":"markdown","d6211c57":"markdown","e1f33e20":"markdown","25b0bb03":"markdown","b78b0ed9":"markdown","3120a00f":"markdown","80409ffc":"markdown","7d113a05":"markdown","55b1a11b":"markdown","080f7057":"markdown","76e1d7eb":"markdown","4f8e8813":"markdown","de485868":"markdown","ca3c684f":"markdown","224e72ac":"markdown","d538bdbb":"markdown","1ede7e26":"markdown","3c3eeb93":"markdown","cfee815b":"markdown","d03dcfe8":"markdown","3af1688a":"markdown","60de72e1":"markdown","ff4f75cb":"markdown","0387e539":"markdown","dcd23c21":"markdown","5b028bad":"markdown","5fe8727d":"markdown","f829303e":"markdown","0959c04c":"markdown","cfbec083":"markdown","bbf7e267":"markdown","d1cf4c12":"markdown","47b1df23":"markdown","f82895f6":"markdown","b06934e9":"markdown","138bae86":"markdown","855e5c3e":"markdown","dc1abd4b":"markdown","68f4215d":"markdown","bea44f5e":"markdown","41c4b1b3":"markdown","8dda141c":"markdown","34369c99":"markdown","5cc3dc70":"markdown","eccb0f3f":"markdown","718fb5a5":"markdown","921b0145":"markdown","90c69424":"markdown","0a5420e5":"markdown","0b85f905":"markdown"},"source":{"094a91c7":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\nfrom sklearn import datasets, linear_model\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm\nfrom scipy import stats\n\nfrom geopy.geocoders import Nominatim\nimport folium\nimport ast\n\npd.options.display.max_rows = 4000\npd.options.display.max_columns = 4000\npd.options.display.max_seq_items = 2000","c2daad03":"#import data and show diminsions\ndata = pd.read_csv(\"..\/input\/data-science-for-good\/2016 School Explorer.csv\")\ndata.info()","f3396bec":"fig, ax = plt.subplots(figsize=(10,8)) \nsns.heatmap(data = data[data.columns[15:41]].corr(), cmap = 'coolwarm', ax=ax)","e2b5e09e":"# Columns 15-41 can be converted to floating numbers to increase the size of our heatmap. \n# I will try to move left to right in this section to make it as straightforward as possible. \n# Choosing columns manually also helps me begin I understanding what each one means.\n\nclean_data = data.copy()","6d3c69b8":"clean_data['Community School?'] = pd.Series(np.where(clean_data['Community School?'].values == 'Yes', 1, 0),\n                                  clean_data.index)","46e99208":"clean_data = clean_data.rename(columns = {'School Income Estimate': 'School Income Estimate ($)'})","2abcb61c":"clean_data['School Income Estimate ($)'].isnull().sum()","bc163343":"clean_data['School Income Estimate ($)'] = clean_data['School Income Estimate ($)']\\\n                                        .apply(lambda x: x if type(x) == float else x.replace('$',''))\\\n                                        .apply(lambda x: x if type(x) == float else x.replace(',',''))\\\n                                        .astype(float)","43503942":"#Converting the % Amounts to decimals\n\npercent_cols = ['Percent ELL', 'Percent Asian',\n                'Percent Black', 'Percent Hispanic', 'Percent Black \/ Hispanic',\n                'Percent White', 'Student Attendance Rate',\n                'Percent of Students Chronically Absent', 'Rigorous Instruction %',\n                'Collaborative Teachers %', 'Supportive Environment %', 'Effective School Leadership %',\n                'Strong Family-Community Ties %', 'Trust %']","9770e1b7":"clean_data[percent_cols] = clean_data[percent_cols]\\\n                            .apply(lambda x: x.apply(lambda x: x if type(x) == float else x.replace('%',''))\\\n                            .astype(float)\/100)","6921be42":"# Commented out due to relation to Percentage columns\n\n#likert_columns = ['Rigorous Instruction Rating', 'Collaborative Teachers Rating',\n#                 'Supportive Environment Rating', 'Effective School Leadership Rating',\n#                 'Strong Family-Community Ties Rating', 'Trust Rating', 'Student Achievement Rating']\n#clean_data[likert_columns].apply(pd.Series.value_counts)\n","a0a89c2c":"#These columns can be encoded to view the correlation as well. \n#pd.unique(clean_data[likert_columns].values.ravel())\n","ced0ba17":"#cat_type = pd.api.types.CategoricalDtype(categories=['Not Meeting Target','Approaching Target', 'Meeting Target', 'Exceeding Target'], \n#                            ordered=True)\n\n#temp = pd.DataFrame()\n#temp = data[likert_columns]\n\n#for col in likert_columns:\n#    temp[col] = temp[col].astype(cat_type)\n    \n#clean_data[likert_columns] = temp[likert_columns].apply(lambda x: x.cat.codes).replace(-1, np.nan)","c21bf166":"clean_data[clean_data.columns[15:44]].head(2)","237d95e1":"fig, ax = plt.subplots(figsize=(14,12)) \nsns.heatmap(data = clean_data[clean_data.columns[15:41]].corr(), cmap = 'coolwarm', ax=ax)","901b9999":"#Used to grab specific correlation numbers referenced in the section overview.\n#clean_data[clean_data.columns[15:41]].corr()","1c8b17ce":"#Import data and show dimensions\n\nshsat = pd.read_csv(\"..\/input\/data-science-for-good\/D5 SHSAT Registrations and Testers.csv\")\nshsat.info()","bda59c22":"shsat_clean = shsat[shsat['Grade level'] == 8]","80da0808":"shsat_locs = {\n    '05M046' : (40.831629, -73.936006), '05M123' : (40.820165, -73.944486), '05M129' : (40.815000, -73.952222),\n    '05M148' : (40.817322, -73.947338), '05M161' : (40.817755, -73.952468), '05M286' : (40.815478, -73.955556),\n    '05M302' : (40.817458, -73.947372), '05M362' : (40.810687, -73.956061), '05M367' : (40.815478, -73.955556), \n    '05M410' : (40.815681, -73.955774), '05M469' : (40.807063, -73.938829), '05M499' : (40.824398, -73.936545),\n    '05M514' : (40.819702, -73.956747), '05M670' : (40.815225, -73.944321), '84M065' : (40.810745, -73.949076),\n    '84M284' : (40.812433, -73.948153), '84M336' : (40.820126, -73.956664), '84M341' : (40.808695, -73.936839),\n    '84M350' : (40.814584, -73.944991), '84M384' : (40.805584, -73.935484), '84M388' : (40.815042, -73.945689),\n    '84M481' : (40.805976, -73.951846), '84M709' : (40.821182, -73.940665), '84M726' : (40.819764, -73.95724) \n    }","34fd4845":"print('2016: ' + str(shsat_clean[shsat_clean['Year of SHST'] == 2016]['School name'].unique().size))\nprint('2015: ' + str(shsat_clean[shsat_clean['Year of SHST'] == 2015]['School name'].unique().size))\nprint('2014: ' + str(shsat_clean[shsat_clean['Year of SHST'] == 2014]['School name'].unique().size))\nprint('2013: ' + str(shsat_clean[shsat_clean['Year of SHST'] == 2013]['School name'].unique().size))","100b2140":"this_map = folium.Map(prefer_canvas=True, tiles='Stamen Toner')\n\ndef plotDot(point):\n    '''input: series that contains a numeric named latitude and a numeric named longitude\n    this function creates a CircleMarker and adds it to your this_map'''\n    x = point['School name'] + '<br>' + \"Enrollment on 10\/31: \" + str(point['Enrollment on 10\/31']) + '<br>' + \\\n    \"Students who took SHSAT: \" + str(point['Number of students who took the SHSAT'])\n    iframe = folium.IFrame(html=x, width=500, height=90)\n    popup = folium.Popup(iframe)\n    folium.CircleMarker(location=[shsat_locs[point.DBN][0], shsat_locs[point.DBN][1]],\n                        radius=3, weight=5, color='red', popup=popup).add_to(this_map)\n\n#The red schools are schools contained in the SHSAT dataset. \nshsat_clean.apply(plotDot, axis = 1)\n\n#Set the zoom to the maximum possible\nthis_map.fit_bounds(this_map.get_bounds())\n\nthis_map","ce4038f0":"shsat_clean_2016 = shsat_clean[shsat_clean['Year of SHST'] == 2016].reset_index(drop=True)\nschools_shsat_data = clean_data[clean_data['Location Code'].isin(shsat_clean['DBN'].unique())].reset_index(drop=True)\nschools_shsat_data = schools_shsat_data.merge(shsat_clean_2016, left_on='Location Code', right_on='DBN')\n# I choose not to drop these extra columns because it is a nice sanity check to make sure the merge worked correctly. \n#schools_shsat_data.drop(columns=['School name', 'DBN', 'Year of SHST', 'Grade level'])","310865d2":"fig, ax = plt.subplots(figsize=(14,12)) \nsns.heatmap(data = schools_shsat_data[list(schools_shsat_data.columns[15:41]) + \n                                      list(schools_shsat_data.columns[-3:])].corr(), \n            cmap = 'coolwarm', ax=ax)","d49381a5":"#Used to grab specific correlation numbers referenced in the section overview.\n#schools_shsat_data[list(schools_shsat_data.columns[15:41]) + list(schools_shsat_data.columns[-3:])].corr()","0020a430":"train = schools_shsat_data[list(schools_shsat_data.columns[15:41]) + list(schools_shsat_data.columns[-3:])]\ntrain = train[train.select_dtypes(include='number').columns]\ntrain.dropna(inplace=True)\ntrain.info()","01e8bde2":"X = train[train.columns[:-10]]\ny1 = train[train.columns[-2]]\ny2 = train[train.columns[-1]]\n\nX2 = sm.add_constant(X)\nest = sm.OLS(y2, X2)\nest2 = est.fit()\nprint(est2.summary())","3ba6794b":"highschools = pd.read_csv(\"..\/input\/nyc-high-school-directory\/2014-2015-doe-high-school-directory.csv\")\nhighschools.info(verbose = False)","98f271f4":"highschools.head(2)","f68fc77d":"#hs['school_type'].unique()\n#hs[hs['school_type'].isnull()]","e40bed2e":"specialized_highschool_list = ['Bronx High School of Science', 'Brooklyn Latin School, The', \n                           'Brooklyn Technical High School', 'High School for Mathematics, Science and Engineering at City College',\n                           'High School of American Studies at Lehman College', 'Queens High School for the Sciences at York College', \n                           'Staten Island Technical High School', 'Stuyvesant High School', \n                           ]\n\n#Audition only schools = 'Fiorello H. LaGuardia High School of Music & Art and Performing Arts'\n\nspecialized_hs = highschools[highschools['school_name'].isin(specialized_highschool_list)].reset_index(drop=True)","0dfa1feb":"schools_shsat_data.head(2)","f4eaa599":"this_map = folium.Map(prefer_canvas=True, tiles='Stamen Toner')\n\ndef plotBlueDots(point):\n    '''input: series that contains a numeric named latitude and a numeric named longitude\n    this function creates a CircleMarker and adds it to your this_map'''\n    x = point['School Name'] + '<br>' + \"Grade 8 Students: \"\n    iframe = folium.IFrame(html=x, width=300, height=40)\n    popup = folium.Popup(iframe)\n    folium.CircleMarker(location=[point.Latitude, point.Longitude],\n                        radius=2, weight=5, popup=popup,\n                       color = 'blue').add_to(this_map)\n    \ndef plotRedDots(point):\n    '''input: series that contains a numeric named latitude and a numeric named longitude\n    this function creates a CircleMarker and adds it to your this_map'''\n    x = point['School name'] + '<br>' + \"Enrollment on 10\/31: \" + str(point['Enrollment on 10\/31']) + '<br>' + \\\n    \"Students who took SHSAT: \" + str(point['Number of students who took the SHSAT'])\n    iframe = folium.IFrame(html=x, width=500, height=90)\n    popup = folium.Popup(iframe)\n    folium.CircleMarker(location=[point.Latitude, point.Longitude],\n                        radius=2, weight=5, popup=popup, \n                       color = 'red').add_to(this_map)\n    \ndef plotMarker(point):\n    '''input: series that contains a numeric named latitude and a numeric named longitude\n    this function creates a CircleMarker and adds it to your this_map'''\n    folium.Marker(location=[float(ast.literal_eval(point['Location 1'])['latitude']), \n                          float(ast.literal_eval(point['Location 1'])['longitude'])],\n                          popup=point['school_name']).add_to(this_map)\n\n    \n    \n    \nclean_data.apply(plotBlueDots, axis = 1)\n#The red schools are schools contained in the SHSAT dataset. \nschools_shsat_data.apply(plotRedDots, axis = 1)\nspecialized_hs.apply(plotMarker, axis = 1)\n\n#Set the zoom to the maximum possible\nthis_map.fit_bounds(this_map.get_bounds())\n\nthis_map","0c0241bf":"district_demographics = pd.read_csv('..\/input\/nyc-school-district-breakdowns\/school-district-breakdowns.csv')","58badfcc":"district_demographics['COUNT PARTICIPANTS'].sum()","527970b2":"students = list([])\ntemp_cols = ['COUNT BLACK NON HISPANIC', 'COUNT HISPANIC LATINO', \n        'COUNT WHITE NON HISPANIC', 'COUNT ASIAN NON HISPANIC']\nfor col in temp_cols:\n    students.append(district_demographics[col].sum())\n\nremainder = district_demographics['COUNT PARTICIPANTS'].sum() - sum(students)\nstudents.append(remainder)","2113f730":"labels = ['Black', 'Hispanic', 'White', 'Asian', 'Other\/Unspecified']\ncolors = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue', 'grey']\ntested = np.array([5770, 6514, 5125, 8732, 2192])\noffered = np.array([207, 319, 1342, 2619, 580])\npass_rates = offered\/tested\n\ntitle_size = 25\nfont = {'family' : 'DejaVu Sans',\n        'weight' : 'normal',\n        'size'   : 18}\nplt.rc('font', **font)\n\nplt.figure(0, figsize = (20, 20))\nplt.subplot(2,2,1)\nplt.title('2018 SHSAT Testing', \n          fontdict = {'fontsize': title_size})\nplt.pie(tested, labels=labels, colors=colors,\n        autopct='%1.1f%%', startangle = 90)\nplt.axis('square')\n \n#plt.figure(1, figsize = (10, 10))\nplt.subplot(2,2,2)\nplt.title('2018 Specialized Schools Acceptances',\n         fontdict = {'fontsize': title_size})\nplt.pie(offered, labels=labels, colors=colors,\n    autopct='%1.1f%%', startangle = 90)\nplt.axis('square')\n\n#plt.figure(1, figsize = (10, 10))\nplt.subplot(2,2,3)\nplt.title('2018 Specialized Schools Pass Rates',\n         fontdict = {'fontsize': title_size})\nplt.barh(width = pass_rates, y=labels, align='center',\n        color='green', ecolor='black')\nplt.axis('tight')\n\n#plt.figure(2, figsize = (10, 10))\nplt.subplot(2,2,4)\nplt.title('2018 Student Survey',\n         fontdict = {'fontsize': title_size})\nplt.pie(students, labels=labels, colors=colors,\n    autopct='%1.1f%%', startangle = 90)\n\nplt.axis('square')\nplt.show()","2a3e281d":"this_map = folium.Map(prefer_canvas=True, tiles='Stamen Toner')\n\ndef plotBlueDots(point):\n    '''input: series that contains a numeric named latitude and a numeric named longitude\n    this function creates a CircleMarker and adds it to your this_map'''\n    folium.CircleMarker(location=[point.Latitude, point.Longitude],\n                        radius=2, weight=5,\n                       color = 'blue').add_to(this_map)\n    \ndef plotMarker(point):\n    '''input: series that contains a numeric named latitude and a numeric named longitude\n    this function creates a CircleMarker and adds it to your this_map'''\n    folium.Marker(location=[float(ast.literal_eval(point['Location 1'])['latitude']), \n                          float(ast.literal_eval(point['Location 1'])['longitude'])],\n                          popup=point['school_name']).add_to(this_map)\n\nclean_data[(clean_data['Grade 8 Math - All Students Tested'] > 0) &\n          (clean_data['Percent Black \/ Hispanic'] > .60)].apply(plotBlueDots, axis = 1)\n\n\n\n#use df.apply(,axis=1) to \"iterate\" through every row in your dataframe\nspecialized_hs.apply(plotMarker, axis = 1)\n\n\n#Set the zoom to the maximum possible\nthis_map.fit_bounds(this_map.get_bounds())\n\nthis_map","36c265bf":"high_qualifiers = ['Economic Need Index', 'Percent Black \/ Hispanic', 'Student Attendance Rate', \n                   'Average ELA Proficiency', 'Average Math Proficiency',\n                   'Grade 8 Math - All Students Tested', 'Grade 8 ELA - All Students Tested']\n\nlow_qualifiers = ['School Income Estimate ($)', 'Effective School Leadership %', \n                  'Collaborative Teachers %', 'Strong Family-Community Ties %', 'Trust %']\n\ntarget_cols = clean_data[['School Name', 'Latitude', 'Longitude', 'Grade High'] + high_qualifiers + low_qualifiers]\ntarget_cols = target_cols[target_cols['Grade 8 Math - All Students Tested'] > 0]\n#target_cols = target_cols[target_cols['Grade High'] == '08']\n#plt.figure(0, figsize = (20, 20))\n","7b0fd024":"target_cols.hist(figsize=(15,25),layout=(5,3))","9d623f07":"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n\ntarget_cols.select_dtypes(include=numerics).apply(np.log).drop(['Latitude', 'Longitude'], axis=1).describe()","72f380ae":"target_cols.select_dtypes(include=numerics).apply(np.log).drop(['Latitude', 'Longitude'], axis=1).describe()","745c0cd7":"target_cols.select_dtypes(include=numerics).apply(np.log).drop(['Latitude', 'Longitude'], axis=1).info()","61c6057f":"target_cols.quantile(q=0.75, axis='rows', numeric_only=True)","14872803":"target_cols.quantile(q=0.25, axis='rows', numeric_only=True)","0a4650e6":"high_qualifiers = ['Economic Need Index', 'Percent Black \/ Hispanic', 'Student Attendance Rate', \n                   'Average ELA Proficiency', 'Average Math Proficiency',\n                   'Grade 8 Math - All Students Tested', 'Grade 8 ELA - All Students Tested']\n\nlow_qualifiers = ['School Income Estimate ($)', 'Effective School Leadership %', \n                  'Collaborative Teachers %', 'Strong Family-Community Ties %', 'Trust %']\n\ndef filter_df_col(df, col, greater_flag):\n    if greater_flag == True:\n        df = df.loc[df[col] > target_cols.quantile(q=0.4, axis='rows', numeric_only=True)[col]]\n    else:\n        df = df.loc[df[col] < target_cols.quantile(q=0.6, axis='rows', numeric_only=True)[col]]\n    return df\n\nfiltered_targets = target_cols.copy()\n\nfor col in high_qualifiers:\n    filtered_targets = filter_df_col(filtered_targets, col, True)\n    \nfor col in low_qualifiers:\n    filtered_targets = filter_df_col(filtered_targets, col, False)\n    \nfiltered_targets.info()","2d1ccc43":"high_qualifiers = ['Economic Need Index', ]\nlow_qualifiers = ['School Income Estimate ($)']\n\nhigh_percentile = .5\nlow_percentile = .2\n\ndef filter_df_col(df, col, greater_flag):\n    if greater_flag == True:\n        df = df.loc[df[col] > target_cols.quantile(q=high_percentile, axis='rows', numeric_only=True)[col]]\n    else:\n        df = df.loc[df[col] < target_cols.quantile(q=low_percentile, axis='rows', numeric_only=True)[col]]\n    return df\n\nfiltered_targets1 = target_cols.copy()\n\nfor col in high_qualifiers:\n    filtered_targets1 = filter_df_col(filtered_targets1, col, True)\n    \nfor col in low_qualifiers:\n    filtered_targets1 = filter_df_col(filtered_targets1, col, False)\n    \nfiltered_targets1.info()","5c551de7":"color_threshold = .7\n\nthis_map = folium.Map(prefer_canvas=True, tiles='Stamen Toner')\n    \ndef plotTargets(point):\n    '''input: series that contains a numeric named latitude and a numeric named longitude\n    this function creates a CircleMarker and adds it to your this_map'''\n    percent_black_hispanic = point['Percent Black \/ Hispanic']\n    x = point['School Name'] + '<br>' + \\\n        \"Highest Grade: \" + str(point['Grade High']) + '<br>' + \\\n        \"Grade 8 Students: \" + str(point['Grade 8 Math - All Students Tested']) + '<br>' + \\\n        \"Percent Black \/ Hispanic: \" + str(percent_black_hispanic) + '<br>'\n    iframe = folium.IFrame(html=x, width=400, height=90)\n    popup = folium.Popup(iframe)\n    folium.Circle(location=[point.Latitude, point.Longitude],\n                  radius=400, fill = True, popup=popup, \n                  color = 'red' if percent_black_hispanic > color_threshold \n                                  else 'blue').add_to(this_map)\n\ndef plotMarker(point):\n    '''input: series that contains a numeric named latitude and a numeric named longitude\n    this function creates a CircleMarker and adds it to your this_map'''\n    folium.Marker(location=[float(ast.literal_eval(point['Location 1'])['latitude']), \n                          float(ast.literal_eval(point['Location 1'])['longitude'])],\n                          popup=point['school_name']).add_to(this_map)\n\nfiltered_targets1.apply(plotTargets, axis=1)\nspecialized_hs.apply(plotMarker, axis = 1)\n\n#Set the zoom to the maximum possible\nthis_map.fit_bounds(this_map.get_bounds())\n\nthis_map","a0a07486":"high_qualifiers = ['Grade 8 Math - All Students Tested']\n\nhigh_percentile = .9\nlow_percentile = 0\n\ndef filter_df_col(df, col, greater_flag):\n    if greater_flag == True:\n        df = df.loc[df[col] > target_cols.quantile(q=high_percentile, axis='rows', numeric_only=True)[col]]\n    else:\n        df = df.loc[df[col] < target_cols.quantile(q=low_percentile, axis='rows', numeric_only=True)[col]]\n    return df\n\nfiltered_targets2 = target_cols.copy()\n\nfor col in high_qualifiers:\n    filtered_targets2 = filter_df_col(filtered_targets2, col, True)\n\n    \nfiltered_targets2.info()","6e68318a":"color_threshold = .7\n\nthis_map = folium.Map(prefer_canvas=True, tiles='Stamen Toner')\n    \ndef plotTargets(point):\n    '''input: series that contains a numeric named latitude and a numeric named longitude\n    this function creates a CircleMarker and adds it to your this_map'''\n    percent_black_hispanic = point['Percent Black \/ Hispanic']\n    x = point['School Name'] + '<br>' + \\\n        \"Highest Grade: \" + str(point['Grade High']) + '<br>' + \\\n        \"Grade 8 Students: \" + str(point['Grade 8 Math - All Students Tested']) + '<br>' + \\\n        \"Percent Black \/ Hispanic: \" + str(percent_black_hispanic) + '<br>'\n    iframe = folium.IFrame(html=x, width=400, height=90)\n    popup = folium.Popup(iframe)\n    folium.Circle(location=[point.Latitude, point.Longitude],\n                  radius=400, fill = True, popup=popup, \n                  color = 'red' if percent_black_hispanic > color_threshold \n                                  else 'blue').add_to(this_map)\n\ndef plotMarker(point):\n    '''input: series that contains a numeric named latitude and a numeric named longitude\n    this function creates a CircleMarker and adds it to your this_map'''\n    folium.Marker(location=[float(ast.literal_eval(point['Location 1'])['latitude']), \n                          float(ast.literal_eval(point['Location 1'])['longitude'])],\n                          popup=point['school_name']).add_to(this_map)\n\nfiltered_targets2.apply(plotTargets, axis=1)\nspecialized_hs.apply(plotMarker, axis = 1)\n\n#Set the zoom to the maximum possible\nthis_map.fit_bounds(this_map.get_bounds())\n\n\nthis_map","6c2477d8":"filtered_targets3 = target_cols.copy()","9aaaa334":"color_threshold = .7\n\nthis_map = folium.Map(prefer_canvas=True, tiles='Stamen Toner')\n    \ndef plotTargets(point):\n    '''input: series that contains a numeric named latitude and a numeric named longitude\n    this function creates a CircleMarker and adds it to your this_map'''\n    percent_black_hispanic = point['Percent Black \/ Hispanic']\n    x = point['School Name'] + '<br>' + \\\n        \"Highest Grade: \" + str(point['Grade High']) + '<br>' + \\\n        \"Grade 8 Students: \" + str(point['Grade 8 Math - All Students Tested']) + '<br>' + \\\n        \"Percent Black \/ Hispanic: \" + str(percent_black_hispanic) + '<br>'\n    iframe = folium.IFrame(html=x, width=400, height=90)\n    popup = folium.Popup(iframe)\n    folium.Circle(location=[point.Latitude, point.Longitude],\n                  radius=400, fill = True, popup=popup, \n                  color = 'red' if percent_black_hispanic > color_threshold \n                                  else 'blue').add_to(this_map)\n\ndef plotMarker(point):\n    '''input: series that contains a numeric named latitude and a numeric named longitude\n    this function creates a CircleMarker and adds it to your this_map'''\n    folium.Marker(location=[float(ast.literal_eval(point['Location 1'])['latitude']), \n                          float(ast.literal_eval(point['Location 1'])['longitude'])],\n                          popup=point['school_name']).add_to(this_map)\n\nfiltered_targets3.apply(plotTargets, axis = 1)\nspecialized_hs.apply(plotMarker, axis = 1)\nthis_map.fit_bounds(this_map.get_bounds())\n\n\nthis_map","2b3be577":"schools1 = ['P.S. 161 PEDRO ALBIZU CAMPOS']\nschools2 = ['THE NEW SCHOOL FOR LEADERSHIP AND JOURNALISM']\n\nschools3 = ['INTERNATIONAL SCHOOL FOR LIBERAL ARTS',\n           'P.S.\/M.S. 280 MOSHOLU PARKWAY', 'J.H.S. 080 THE MOSHOLU PARKWAY', \n            'P.S.\/M.S. 20 P.O.GEORGE J. WERDANN, III', 'P.S. 095 SHEILA MENCHER'\n           ]\n\nspecialized_target_schools = ['High School for Mathematics, Science and Engineering at City College', \n                              'High School of American Studies at Lehman College',\n                              'Bronx High School of Science']\n\n\nthis_map = folium.Map(prefer_canvas=True, tiles='Stamen Toner')\n    \ndef plotTargets(point, color):\n    '''input: series that contains a numeric named latitude and a numeric named longitude\n    this function creates a CircleMarker and adds it to your this_map'''\n    percent_black_hispanic = point['Percent Black \/ Hispanic']\n    x = point['School Name'] + '<br>' + \\\n        \"Highest Grade: \" + str(point['Grade High']) + '<br>' + \\\n        \"Grade 8 Students: \" + str(point['Grade 8 Math - All Students Tested']) + '<br>' + \\\n        \"Percent Black \/ Hispanic: \" + str(percent_black_hispanic) + '<br>'\n    iframe = folium.IFrame(html=x, width=500, height=90)\n    popup = folium.Popup(iframe)\n    folium.Circle(location=[point.Latitude, point.Longitude],\n                  radius=400, fill = True, popup=popup, \n                  color = color).add_to(this_map)\n\n\n#use df.apply(,axis=1) to \"iterate\" through every row in your dataframe\nspecialized_hs[specialized_hs['school_name'].isin(specialized_target_schools)].apply(plotMarker, axis = 1)\ntarget_cols[target_cols['School Name'].isin(schools1)].apply(lambda x: plotTargets(x, 'blue'), axis=1)\ntarget_cols[target_cols['School Name'].isin(schools2)].apply(lambda x: plotTargets(x, 'red'), axis=1)\ntarget_cols[target_cols['School Name'].isin(schools3)].apply(lambda x: plotTargets(x, 'green'), axis=1)\n\n\n#Set the zoom to the maximum possible\nthis_map.fit_bounds(this_map.get_bounds())\n\n\nthis_map\n","f20fa3f4":"[Jump to Table of Contents](#contents)","e3068a03":"<a id='shsat'><\/a>","a80bc86f":"## Proposal 3: School Proximity\n***","9a4e9e27":"<a id='demographics'><\/a>","7d48a88a":"## General Demographics\n***\nBy analyzing the demographics of NYC students, test takers, and specialize high school students, we can determine where the breakdown in diversity occurs. Unsurprisingly, the black and hispanic students, who comprise the majority of underperforming schools in New York, also score poorly on the SHSAT at higher rates. ","6c35d875":"### Data Cleaning:\n** ~26 columns should be included in this matrix, but they must be cleaned first. **","8126e367":"# Exploratory Data Analysis","d6211c57":"<a id='schools'><\/a>","e1f33e20":"<a id='imports'><\/a>","25b0bb03":"Because the distribution for every column is skewed (determined through quick visual check above), either the log of the data should be used, or analyzing the data using quantiles would be more appropriate.","b78b0ed9":"<a id='summary'><\/a>","3120a00f":"Comparing the demographics from each of the charts reveals why specialized schools lack diversity. Students that take the test show a reasonable amount of diversity, but white and asian students score high enough to be accepted at a much higher rate. This reduces the diversity when the students begin their 9th grade year at the specialized schools.\n\nData obtained from: https:\/\/www.wsj.com\/articles\/who-got-into-stuyvesant-and-new-yorks-other-elite-public-high-schools-1520465259","80409ffc":"By plotting all of the schools with eighth graders onto the map, the scope of the problem is further revealed. There are a lot of schools in NYC, so a reasonable metric needs to be established to filter these.","7d113a05":"### Rating Columns (Likert Scale)","55b1a11b":"[Jump to Table of Contents](#contents)","080f7057":"## Proposal 2: Eighth Grade Size\n\n***","76e1d7eb":"<a id='specialized'><\/a>","4f8e8813":"# Imports and Configs\n***","de485868":"<a id='conclusion'><\/a>","ca3c684f":"[Jump to Table of Contents](#contents)","224e72ac":"There are too many underserved schools in New York to try and characterize them all at a microscopic level. A good starting metric would be to focus on underperforming schools that are close to these specialized schools. A short commute is an extremely important thing to consider when choosing where to attend high school, especially for students who may have to walk or take public transportation. ","d538bdbb":"It appears that 0's exist in several columns, which restricts the use of a log transformation to normalize the data. Fortunately, there is a large number of samples, so analyzing the quantiles is acceptable to determine how the schools rank within certain categories. ","1ede7e26":"[Jump to Table of Contents](#contents)","3c3eeb93":"### Community School","cfee815b":"## Closing Remarks\n***","d03dcfe8":"# Conclusion: Targeted Schools\n\n## Identifying the Schools in Need for SHSAT support\n***\nBecause every student in a public school must take the ELA and Math standardized tests (barring some rare circumstance), we can determine the effective student size of a school based on how many students took the test. \n\nAgain, accounting for size, location, and demographics should be sufficient enough to find a few schools to start a pilot tutoring program at; however, analyzing other variables might refine the avaiable options considered. There are justifications for choosing schools that have both positive and negative qualities, and it might be interesting to look for schools that lack funding but are still performing well on other metrics such as test scores, student attendance, or leadership.","3af1688a":"<a id='data'><\/a>","60de72e1":"This heatmap is really informative enough for analyzing the schools at such a broad context. Ultimately, everything that can be taken from this graph should be rather common knowledge for local residents of the town. This correlation is something I would expect even where I am from.\n\nPoor students and poor families struggle receiving equal opportunities in schools. This is no surprise, let's try and find some schools that are good candidates to kickstart this PASSNYC Program. ","ff4f75cb":"This data is really helpful, there are some interesting applications on other public kernels. One thing to note: 9th grade testing rates are low for a reason, specialized schools start at 9th grade. I am just going to drop 9th grade data because very few students are accepted in that range and they are basically considered transfer students. Most information online suggests that the vast majority of test takers are in the 8th grade, applying to the schools to start 9th grade.\n\nhttps:\/\/www.princetonreview.com\/k12\/shsat-information","0387e539":"[Jump to Table of Contents](#contents)","dcd23c21":"### Results","5b028bad":"<a id='map3'><\/a>","5fe8727d":"## 2016 Schools Data Exploration\n***\nThis section cleans the '2016 School Explorer.csv' by changing certain columns to numbers in order to create a large heatmap of the data. Many inferences can be made by studying the heatmap, but here are some important relationships:\n\n<br>\nAs 'Percent Asian' increases:\n - Economic Need Index decreases (r = -0.359294)\n - School Income Estimate ($) increases (r = 0.247352)\n - Student Attendance Rate increases (r = 0.182024)\n - Percent of Students Chronically Absent decreases (r = -0.403291)\n - Average ELA Proficiency increases (r = 0.462710)\n - Average Math Proficiency increases (r = 0.528597)\n \n<br>\nAs 'Percent Black \/ Hispanic' increases:\n - Economic Need Index increases (r = 0.775140)\n - School Income Estimate ($) decreases (r = -0.685344)\n - Student Attendance Rate decreases (r = -0.208507)\n - Percent of Students Chronically Absent increases (r = 0.520729)\n - Average ELA Proficiency decreases (r = -0.748990)\n - Average Math Proficiency decreases (r = -0.735648)\n \n<br>\nAs 'Percent White' increases:\n - Economic Need Index decreases (r = -0.771980)\n - School Income Estimate ($) increases (r = 0.716063)\n - Student Attendance Rate increases (r = 0.141135)\n - Percent of Students Chronically Absent decreases (r = -0.390038)\n - Average ELA Proficiency increases (r = 0.650427)\n - Average Math Proficiency increases (r = 0.579286)\n \n<br>\nr is <a href=\"https:\/\/en.wikipedia.org\/wiki\/Correlation_coefficient\">Pearson product-moment correlation coefficient<\/a>\n\nEnglish and Language Arts (ELA) and Math testing are standardized tests given to every student attending public schools in America. For more information, feel free to <a href=\"http:\/\/www.corestandards.org\/read-the-standards\/\">ELA and Math standards<\/a>.","f829303e":"<a id='map1'><\/a>","0959c04c":"### Percent Columns","cfbec083":"## SHSAT Data Exploration\n***\nThis section cleans the 'D5 SHSAT Registrations and Testers.csv' and combines it with the dataset above. More data from other schools from the Department of Education would be helpful, but data requests apparently take upwards of several months to be granted. Regardless, here are the important inferences from the new heatmap: \n\n<br>\nAs 'Percent Asian' increases:\n - Number of students who registered for the SHSAT increases (r = 0.197907) \n - Number of students who took the SHSAT increases (r = 0.434725)\n \n<br>\nAs 'Percent Black \/ Hispanic' increases:\n - Number of students who registered for the SHSAT decreases (r = -0.190516) \n - Number of students who took the SHSAT decreases (r = -0.513048)\n \n<br>\nAs 'Percent White' increases:\n - Number of students who registered for the SHSAT increases  (r = 0.254128) \n - Number of students who took the SHSAT increases (r = 0.586734)\n \n<br>\nr is <a href=\"https:\/\/en.wikipedia.org\/wiki\/Correlation_coefficient\">Pearson product-moment correlation coefficient<\/a>","bbf7e267":"[Jump to Table of Contents](#contents)","d1cf4c12":"## Proposal 1: Economic Need\n***\n\nIt appears that there are too many qualifiers being used to find schools that are poorly funded, but still performing acceptably. This is due mainly to the correlation between funding and performance observed in the earlier sections. Recall that the Percentage of Blacks and Hispanics attending a schools is highly correlated with the amount of funding and performance of the school. However, due to this correlation, finding a school that is deserving of PASSNYC's services should not be difficult. Picking a school with a high percentage of black and hispanic students would normally mean that the school needs extra services. Realistically, the only thing left to do is find a school with students that would be open to attending a specialized high school. \n\n\nFor the three proposals below, three different approaches are used to filter the list of schools. The filtered list is then plotted on the maps.\n\nThe considered categories within the different maps are:\n- Economic Need Index\n- Percent Black \/ Hispanic\n- Grade 8 Math - All Students Tested\n- School Income Estimate","47b1df23":"[Jump to Table of Contents](#contents)","f82895f6":"# Preface\n---\nThis is a public kernel submitted to the PASSNYC Data Science for Good Kaggle competition. <br>\nhttps:\/\/www.kaggle.com\/passnyc\/data-science-for-good\/home <br><br>\nAuthor: Jared Ucherek <br>\nSource: https:\/\/github.com\/jareducherek\/PassNYC-Kaggle <br>\n<br><br>\n\nThis kernel aims to provide PASSNYC with specific schools that would be a good target to start tutoring programs for the SHSAT. Each section begins with a brief description of its contents. \n\nIt is assumed that readers have a general understanding of American schooling and the SHSAT testing process for students in NYC. If you are unfamiliar with NYC, feel free to use the links below to briefly familiarize yourself. Many conclusions below simply reaffirm concepts commonly understood about the American education system. In large American cities across the nation, poor neighborhoods with underfunded schools typically have higher concentrations of minorities.\n<br><br><br><br>\nSHSAT testing description: <br>\nhttps:\/\/www.schools.nyc.gov\/school-life\/learning\/testing\/specialized-high-school-admissions-test\n\nInteractive maps of NYC income distributions by burrough: <br>\nhttps:\/\/ny.curbed.com\/2017\/8\/9\/16119400\/income-distribution-nyc-map\n\nPrevious studies that provide similar findings to this exploratory data analysis: <br>\nhttp:\/\/www.centernyc.org\/high-school-diversity-data\/\n\nAn interactive map that illustrates travel time in NYC: <br>\nhttps:\/\/project.wnyc.org\/transit-time\/#40.84135,-73.86692,12,1611","b06934e9":"# Summary and Approach\n***\nThe PASSNYC team is tasked with a few goals that may not be simultaneously accomplishable. Realistically, increasing testing diversity should increase the specialized high school diversity; however, these schools recruit solely based on test scores. Providing unprepared students with the opportunity to take the exam would result in higher rejection rates. \n\nTop-quality schools extensively prepare their students to take this exam throughout their education. Therefore,  helping more students to register to take the exam would most likely result in very little change. Moreover, the demographics of the test takers are shown to be relatively diverse. Due to the nature of standardized testing and the strict admittance criteria, white and asian students who are more prepared are accepted at higher rates, which mitigates the potential for diversity in specialized schools. \n\nOverall, the solution is to find balance between providing marginalized schools the opportunity to start registering students for the exam, and tutoring students who might be close to already being admitted into a specialized school. In one case, new schools are introduced into the testing pools, but the students will most likely not succeed with sufficient preparation; in the other case, students already intending to take the test might improve their ability to score well, but testing demographics would not change too much. \n\nThere are countless ways to begin increasing the diversity of eight specialized high schools. Due to the reasonable diversity of testing, yet lack of diversity in acceptance rates, it is apparent that schools registering mostly blacks and hispanics to take the exam do not have the resources to properly prepare them. Therefore, the targeted schools from this study will adhere to a small number of attributes: proximity to specialized high schools, percentage Hispanic and Black, and student size. \n\nThere are other factors that will be examined to provide information about a specific school's performance, but proximity, demographics, and size are most important. Students already attending schools nearby specialized high schools would not need to adapt to a new neighborhood, and their commute will not be too far to the specialized high schools. Additionally, as an untested program, it is more reasonable to experiment with the effectiveness of tutoring programs by offering services to larger schools. These programs could start up quickly, and utilize feedback received by interviewing students or possibly maintaining anonymous test results. This approach aims to equalize the acceptance rates between demographics, rather than blindly equalize the testing demographics, which are reasonably representative of the NYC student population. \n\nBy minimizing deployment time and focusing on a few large schools, hopefully the PASSNYC team can develop a viable program eventually offered to a profusion of underserved students.","138bae86":"[Jump to Table of Contents](#contents)","855e5c3e":"## NYC Specialized schools Data Exploration\n***\n\nThere are only 9 specialized schools in NYC. La Guardia uses auditions to accept students, which leaves 8 high schools that accept students based on SHSAT scores; because of this, comprehensive analysis of individual schools would not be difficult. Comparing the geographic location of each school and the diversity of each schools might help increase the granularity of this study. At the very least, noting the location of each specialized high schools helps provide additional context to the overall problem. \n\n<br><br>\nSpecialized High Schools: <br>\nhttp:\/\/schools.nyc.gov\/ChoicesEnrollment\/High\/specialized\/default.htm","dc1abd4b":"### School Income Estimate","68f4215d":"[Jump to Table of Contents](#contents)","bea44f5e":"Economic Need Index = (Percent Temporary Housing) + (Percent HRA-eligible * 0.5) + \n                      (Percent Free Lunch Eligible * 0.5)\n                      \nFor universal lunch schools, the percentage of free lunch eligible\ncomes from the last year the school collected lunch forms. \u201cHRAeligible\u201d\nrefers to students whose families have been identified by the\nHuman Resources Administration as receiving certain types of public\nassistance. HRA-eligible is based on current year data. Students\nare identified in temporary housing if they have been identified in\ntemporary housing anytime in the past four years. Students identified\nin temporary housing who are also HRA eligible count toward both\npercentages. Students who are HRA eligible also count toward\nPercent Free Lunch Eligible.\n\n\nhttp:\/\/schools.nyc.gov\/NR\/rdonlyres\/7B6EEB8B-D0E8-432B-9BF6-3E374958EA70\/0\/EducatorGuide_EMS_20131118.pdf","41c4b1b3":"## Finalized Map\n***\nBy interacting with the above maps, I selected a subset of schools that are within reasonable distances to specialized highschools, which are replotted below. Most of the schools near the two specialized high schools would be great choices to start tutoring programs, because they are grouped together nicely, and the students would have the chance to attend either high school without drastically changing their commute. ","8dda141c":"<a id='contents'><\/a>","34369c99":"<a id='map2'><\/a>","5cc3dc70":"The exploratory analysis, interactive maps, and final approach to this notebook should serve as a guide to understand the background and subjective nature of the problem. Although competitors have submitted a wide variety of analyses on this subject, it is important to start soon and begin receiving feedback from tutors, students, and schools in order to refine the process. With such a complex issue, overanalyzing the topic can only obfuscate the goal and stifle progress. The schools provided above would all be great candidates to start helping underprivileged kids prepare for the rigorous SHSAT test. \n\n<br><br><br>\n\nFeel free to contact me via Kaggle or Github in order to discuss this topic or suggest changes\/bug fixes to my kernel. Thank you for reading.\n<br>\nGithub: https:\/\/github.com\/jareducherek","eccb0f3f":"# Table of Contents\n---\n\n\n[1. Summary and Approach](#summary)<br>\n[2. Imports and Configs](#imports)  <br>\n[3. Exploratory Data Analysis](#data)  <br>\n-  [a. 2016 NYC Schools](#schools)  <br>\n-  [b. D5 SHSAT Registrations](#shsat)  <br>\n-  [c. Specialized Schools](#specialized)  <br>\n-  [d. General Demographics](#demographics)<br>\n\n[6. Conclusion: Targeted Schools](#conclusion)  <br>\n-  [a. Proposal 1: Economic Need](#map1)  <br>\n-  [b. Proposal 2: Eighth Grade Size](#map2)  <br>\n-  [c. Proposal 3: School Proximity](#map3)<br>\n-  [d. Finalized map and Closing Remarks](#map4)<br>\n\n","718fb5a5":"[Jump to Table of Contents](#contents)","921b0145":"[Jump to Table of Contents](#contents)","90c69424":"This section begins by generalizing the data provided in the '2016 School Explorer' CSV. The generalized analysis serves to contextualize the issue of diversity within specialized schools and should be widely accepted. Next, the D5 SHSAT Registrations and Testers' CSV is combined with the '2016 School Explorer' Data to determine any significant predictors of Number of Students that take the SHSAT. Lastly, the '2014-2015-doe-high-school-directory' CSV is filtered to show the 8 Specialized Schools in New York, and the 'school-district-breakdowns' CSV is used to help show the diversity within NYC Schools. \n\nGiven the subject of the data, and the current understanding of American schools, nothing found should be out of the ordinary. This analysis is not meant to draw erroneous conclusions; rather, this aims to plainly provide details of NYC schools, and familiarize those foreign to the characteristics of American schools which face socioeconomic discrimination.  \n\n\n","0a5420e5":"<a id='map4'><\/a>","0b85f905":"[Jump to Table of Contents](#contents)"}}