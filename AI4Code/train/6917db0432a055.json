{"cell_type":{"b4ebe43a":"code","d142900c":"code","616f2b62":"code","f70a3fcf":"code","84fb7e9c":"code","0caf5502":"code","7f29e6b8":"code","8cba96bc":"code","7dbe87dd":"markdown"},"source":{"b4ebe43a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom tqdm import tqdm\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nfrom pathlib import Path\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\n\nroot_path = Path(r'\/kaggle\/input\/santa-workshop-tour-2019')\n\n","d142900c":"fpath = root_path \/ 'family_data.csv'\ndata = pd.read_csv(fpath, index_col='family_id')\n\nfpath = root_path \/ 'sample_submission.csv'\nsubmission = pd.read_csv(fpath, index_col='family_id')","616f2b62":"n_people = data['n_people'].values\nm = data.iloc[:, :-1].values\nmat = np.zeros(shape=(5000, 100))\npenalties = {n: [0, 50, 50 + 9 * n, 100 + 9 * n, 200 + 9 * n, 200 + 18 * n, 300 + 18 * n, 300 + 36 * n, 400 + 36 * n, 500 + 36 * n + 199 * n] for n in np.unique(n_people)}\nfor f in np.arange(mat.shape[0]):\n    mat[f] = 500 + 36 * n_people[f] + 398 * n_people[f]\n    \nfor f in np.arange(m.shape[0]):\n    for c in np.arange(m.shape[1]):\n        mat[f, m[f, c]-1] = penalties[n_people[f]][c]","f70a3fcf":"family_size_dict = data[['n_people']].to_dict()['n_people']\n\ncols = [f'choice_{i}' for i in range(10)]\nchoice_dict = data[cols].T.to_dict()\n\nN_DAYS = 100\nMAX_OCCUPANCY = 300\nMIN_OCCUPANCY = 125\n\n# from 100 to 1\ndays = list(range(N_DAYS,0,-1))\n\nfamily_size_ls = list(family_size_dict.values())\nchoice_dict_num = [{vv:i for i, vv in enumerate(di.values())} for di in choice_dict.values()]\n\n# Computer penalities in a list\npenalties_dict = {\n    n: [\n        0,\n        50,\n        50 + 9 * n,\n        100 + 9 * n,\n        200 + 9 * n,\n        200 + 18 * n,\n        300 + 18 * n,\n        300 + 36 * n,\n        400 + 36 * n,\n        500 + 36 * n + 199 * n,\n        500 + 36 * n + 398 * n\n    ]\n    for n in range(max(family_size_dict.values())+1)\n} \n\ndef cost_function(prediction):\n    penalty = 0\n    violations = 0\n    # We'll use this to count the number of people scheduled each day\n    daily_occupancy = {k:0 for k in days}\n    \n    # Looping over each family; d is the day, n is size of that family, \n    # and choice is their top choices\n    for n, d, choice in zip(family_size_ls, prediction, choice_dict_num):\n        # add the family member count to the daily occupancy\n        daily_occupancy[d] += n\n\n        # Calculate the penalty for not getting top preference\n        if d not in choice:\n            penalty += penalties_dict[n][-1]\n        else:\n            penalty += penalties_dict[n][choice[d]]\n\n    # for each date, check total occupancy\n    #  (using soft constraints instead of hard constraints)\n    for v in daily_occupancy.values():\n        if (v > MAX_OCCUPANCY) or (v < MIN_OCCUPANCY):\n            violations += 1\n#             penalty += 100000000\n\n    # Calculate the accounting cost\n    # The first day (day 100) is treated special\n    accounting_cost = (daily_occupancy[days[0]]-125.0) \/ 400.0 * daily_occupancy[days[0]]**(0.5)\n    # using the max function because the soft constraints might allow occupancy to dip below 125\n    accounting_cost = max(0, accounting_cost)\n    \n    # Loop over the rest of the days, keeping track of previous count\n    yesterday_count = daily_occupancy[days[0]]\n    for day in days[1:]:\n        today_count = daily_occupancy[day]\n        diff = abs(today_count - yesterday_count)\n        accounting_cost += max(0, (daily_occupancy[day]-125.0) \/ 400.0 * daily_occupancy[day]**(0.5 + diff \/ 50.0))\n        yesterday_count = today_count\n\n    return penalty, accounting_cost, violations","84fb7e9c":"class Model(nn.Module):\n    def __init__(self, mat, n_people):\n        super().__init__()\n        self.mat = torch.from_numpy(mat).type(torch.float32)\n        self.n_people = torch.from_numpy(n_people).type(torch.float32)\n        self.weight = torch.nn.Parameter(data=torch.Tensor(5000, 100), requires_grad=True)\n        self.weight.data.uniform_(0, 5)   \n        \n    def forward(self):\n        x = (F.softmax(self.weight) * self.mat).sum()\n        y = ((torch.transpose(F.softmax(self.weight), 0 , 1)@ self.n_people - 200) ** 2).sum()\n        return  x, y","0caf5502":"model = Model(mat, n_people)\nbest_score = 10e10\nbest_pos = None\noptimizer = torch.optim.Adam(model.parameters())\nfor epoch in range(15000):  # loop over the dataset multiple times\n    # zero the parameter gradients\n    optimizer.zero_grad()\n    x, y = model()\n    loss = x + y\n    loss.backward()\n    optimizer.step()\n    \n\n    if epoch % 100 == 0:\n        pos = model.weight.argmax(1).numpy()\n        a, b, v = cost_function(pos+1)\n        score = a + b\n        if score < best_score:\n            best_score = score\n            best_pos = pos\n        x = np.round(x.item(),3)\n        y = np.round(y.item(),3)\n        print(f'{epoch}\\t{x}\\t{y}\\t{score}\\t{a}\\t{b}\\t{v}')","7f29e6b8":"best_score","8cba96bc":"submission['assigned_day'] = best_pos+1\nsubmission.to_csv(f'submission_{best_score}.csv')","7dbe87dd":"Although I believe, that is not even close to be a best way to solve this, I just was curious to try pytorch solution."}}