{"cell_type":{"cdc464a4":"code","23888aae":"code","98d4018e":"code","72e44fa7":"code","851385fd":"code","a36b5ae6":"code","df0d73d4":"code","fbd8fdd4":"code","307a5805":"code","5b571663":"code","152e9923":"code","a142e977":"code","93da4993":"code","b09963b6":"code","222cad0e":"code","db1965b4":"code","7650143e":"code","fda06678":"code","654d4c1f":"code","02425999":"code","f9be5b09":"code","98a165b0":"code","11d0463b":"code","b8bdaefd":"code","0618fbba":"code","0dc8f0b1":"code","e7449479":"code","df02eb9d":"code","7e8bfd1f":"code","f5459292":"code","e15f39df":"code","95a4cc72":"code","421266ef":"code","08cdc888":"code","df25b954":"code","8557168d":"code","dae544e4":"code","421776f9":"code","057ddfda":"code","c8533b37":"code","c7264be8":"code","6e3bc6c8":"code","045498c3":"code","51fe75f7":"code","4c42053b":"code","844ebe22":"code","d751e87f":"code","c8353d10":"code","4dbd4e9c":"code","2d8e5b58":"code","9134ebeb":"code","5e0055f0":"code","3760cd6e":"code","850f687b":"code","6391a30c":"code","fbb47041":"code","e94ca0dd":"code","993d2c5f":"code","6e21bd88":"code","1768c82a":"code","98d66641":"code","359dae79":"markdown","5ede1619":"markdown","0ee5edfa":"markdown","fbd1c6ce":"markdown","ace14b0e":"markdown","99888b66":"markdown","16ce2e56":"markdown","1564e9d4":"markdown","db49ebc8":"markdown","3d11b7d2":"markdown","f0add0b8":"markdown","ac2d1d95":"markdown","c48b5450":"markdown","096f167b":"markdown","27cf0b5a":"markdown","6b75084a":"markdown"},"source":{"cdc464a4":"import numpy as np\nimport pandas as pd\nimport os\nimport scipy\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.linear_model import LogisticRegression\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","23888aae":"train = pd.read_csv('\/kaggle\/input\/cat-in-the-dat\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/cat-in-the-dat\/test.csv')","98d4018e":"train.head()","72e44fa7":"test.head()","851385fd":"train.nunique()","a36b5ae6":"train.isna().sum()","df0d73d4":"bin_cols = [col  for col in train.columns.values if col.startswith('bin')]\nnom_cols = [col  for col in train.columns.values if col.startswith('nom')]\nord_cols = [col  for col in train.columns.values if col.startswith('ord')]","fbd8fdd4":"def ord_to_num(df, col):\n    keys=np.sort(df[col].unique())\n    values=np.arange(len(keys))\n    map = dict(zip(keys, values))\n    df[col] = df[col].replace(map)","307a5805":"ord_to_num(test, 'ord_3')\nord_to_num(train, 'ord_3')","5b571663":"ord_to_num(train, 'ord_4')\nord_to_num(test,'ord_4')","152e9923":"ord_to_num(train, 'ord_5')\nord_to_num(test,'ord_5')","a142e977":"keys_ord_1=train.ord_1.unique()\nkeys_ord_1","93da4993":"values_ord_1=[3,4,0,1,2]","b09963b6":"map_ord_1 = dict(zip(keys_ord_1, values_ord_1))\nmap_ord_1","222cad0e":"train['ord_1'] = train['ord_1'].replace(map_ord_1)\ntest['ord_1'] = test['ord_1'].replace(map_ord_1)","db1965b4":"keys_ord_2=train.ord_2.unique()\nkeys_ord_2","7650143e":"values_ord_2=[1,3,5,4,0,2]","fda06678":"map_ord_2 = dict(zip(keys_ord_2, values_ord_2))\nmap_ord_2","654d4c1f":"train['ord_2'] = train['ord_2'].replace(map_ord_2)\ntest['ord_2'] = test['ord_2'].replace(map_ord_2)","02425999":"train[ord_cols].head()","f9be5b09":"train[ord_cols].nunique()","98a165b0":"train['ord_4_band'] = pd.qcut(train['ord_4'], 6)\nbands=train.ord_4_band.unique()\nkeys_bands=np.sort(bands)\nvalues_bands=np.arange(len(keys_bands))\nmap_bands = dict(zip(keys_bands, values_bands))","11d0463b":"train['ord_4_band'] = train['ord_4_band'].replace(map_bands)\ntest['ord_4_band']=pd.cut(test.ord_4,pd.IntervalIndex(keys_bands))","b8bdaefd":"test['ord_4_band'] = test['ord_4_band'].replace(map_bands)\ntest.ord_4_band.head()","0618fbba":"train['ord_5_band'] = pd.qcut(train['ord_5'], 6)\nbands=train.ord_5_band.unique()\nkeys_bands=np.sort(bands)\nvalues_bands=np.arange(len(keys_bands))\nmap_bands = dict(zip(keys_bands, values_bands))","0dc8f0b1":"train['ord_5_band'] = train['ord_5_band'].replace(map_bands)\ntest['ord_5_band']=pd.cut(test.ord_5,pd.IntervalIndex(keys_bands))","e7449479":"test['ord_5_band'] = test['ord_5_band'].replace(map_bands)\ntest.ord_5_band.head()","df02eb9d":"train[nom_cols].nunique()","7e8bfd1f":"test[nom_cols].nunique()","f5459292":"for col in [\"nom_7\", \"nom_8\", \"nom_9\"]:\n    train_vals = set(train[col].unique())\n    test_vals = set(test[col].unique())\n   \n    ex=train_vals ^ test_vals\n    if ex:\n        train.loc[train[col].isin(ex), col]=\"x\"\n        test.loc[test[col].isin(ex), col]=\"x\"","e15f39df":"train[nom_cols].nunique()","95a4cc72":"test[nom_cols].nunique()","421266ef":"train[train.nom_7=='x']","08cdc888":"train=train[train.nom_7!='x']","df25b954":"train[train.nom_7=='x']","8557168d":"labelEnc=LabelEncoder()","dae544e4":"for col in nom_cols:\n    train[col]=labelEnc.fit_transform(train[col])\n    test[col]=labelEnc.fit_transform(test[col])\n","421776f9":"train[nom_cols].head()","057ddfda":"train[bin_cols].head()","c8533b37":"for col in ['bin_3', 'bin_4']:\n    train[col]=labelEnc.fit_transform(train[col])\n    test[col]=labelEnc.fit_transform(test[col])\n","c7264be8":"test[bin_cols].head()","6e3bc6c8":"X_temp=train.drop('target', axis=1)\nY=train.target","045498c3":"from sklearn.mixture import GaussianMixture","51fe75f7":"gm = GaussianMixture(n_components=4)\ngm.fit(X_temp)","4c42053b":"X_temp['Gaussian_Mixture']=gm.predict(X_temp)","844ebe22":"test['Gaussian_Mixture']=gm.predict(test)","d751e87f":"X_oh_temp=pd.get_dummies(X_temp.drop('id', axis=1), columns=X_temp.drop('id', axis=1).columns, drop_first=True, sparse=True)","c8353d10":"X_oh=scipy.sparse.csr_matrix(X_oh_temp.values)","4dbd4e9c":"X_oh","2d8e5b58":"test_oh_temp=pd.get_dummies(test.drop('id', axis=1), columns=test.drop('id', axis=1).columns, drop_first=True, sparse=True)","9134ebeb":"test_oh_temp.shape","5e0055f0":"test_oh=scipy.sparse.csr_matrix(test_oh_temp.values)","3760cd6e":"X_train, X_valid, Y_train, Y_valid = train_test_split(X_oh, \n                                                      Y, \n                                                      test_size = 0.20,\n                                                      random_state=42)\n","850f687b":"lr=LogisticRegression(C=0.125, solver=\"lbfgs\", max_iter=500)  \n\nlr.fit(X_train, Y_train)\n\n","6391a30c":"y_pred_lr=lr.predict_proba(X_valid)","fbb47041":"roc_auc_score(Y_valid.values, y_pred_lr[:,1])","e94ca0dd":"lr.fit(X_oh, Y)","993d2c5f":"y_pred=lr.predict_proba(X_oh)\nroc_auc_score(Y.values, y_pred[:,1])","6e21bd88":"test_pred_lr=lr.predict_proba(test_oh)","1768c82a":"output_dict = {'id': test.id,\n                       'target': test_pred_lr[:,1]}\n\n\noutput = pd.DataFrame(output_dict, columns = ['id', 'target'])\noutput.head(10)","98d66641":"output.to_csv('submission.csv', index=False)","359dae79":"We are going to stratify ord_4 and ord_5.","5ede1619":"## Binary Columns","0ee5edfa":"## Nominal Columns","fbd1c6ce":"We need to encode bin_3 and bin_4.","ace14b0e":"# Import and explore data","99888b66":"We see that the are columns with different number of values on the train and test set.  We will\nchange those values with the same one","16ce2e56":"Now we label encode the nom_cols.","1564e9d4":"## Ordinal Columns","db49ebc8":"We need to encode the data. The next functio converts the original data to integer using map from keys to values. The keys are generated by a sorted array of the unique strings of the column, the values by an array of integers from 0 to the length of the keys, or by a manually sorted array.","3d11b7d2":"We split X_oh into train and validation sets.","f0add0b8":"Now we create column classes defined by their type of data.","ac2d1d95":"Now we take a look at the bin_cols.","c48b5450":"## One-Hot Encoding","096f167b":"We do the same for the test set.","27cf0b5a":"# Logistic Regression","6b75084a":"We will one-hot encode all features."}}