{"cell_type":{"aeadf3e8":"code","0239e92d":"code","c248a88a":"code","51630d68":"code","87cb05e8":"code","033bc479":"code","628b3eed":"code","7a0a8e71":"code","db800d10":"code","ce9192fd":"code","5f27360f":"code","bcaab511":"code","e3a765e5":"code","55dba2c8":"markdown","937052d8":"markdown","37c4ec98":"markdown","779ac1dd":"markdown"},"source":{"aeadf3e8":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","0239e92d":"df = pd.read_csv('..\/input\/m5-forecasting-accuracy\/sales_train_evaluation.csv')","c248a88a":"df.head()","51630d68":"df['id'] = df['id'].str[:-11]","87cb05e8":"class MinMaxtransformer():\n    ''' A class to scale the time series data for each item_id'''\n    def __init__(self,d_x,d_y, info = None):\n        self.d_x = d_x\n        self.d_y = d_y\n        if info is None :\n            self.info = pd.DataFrame({'id': [],'min':[],'max':[]})\n        else :\n            self.info = info\n    \n    def fit(self, df):\n        '''Will store in min and max values of the rows in a info dataframe'''\n        self.info['id'] = df['id']\n        self.info['max']= df.loc[:,self.d_x:self.d_y].max(axis=1)\n        self.info['min']= df.loc[:,self.d_x:self.d_y].min(axis=1)\n        self.info['maxdiffmin'] = self.info['max'] - self.info['min']\n    \n    def transform(self , df, d_x = None ,d_y = None):\n        if d_x == None or d_y == None :\n            d_x = self.d_x\n            d_y = self.d_y\n        filt = self.info['id'].isin(df['id'].tolist())\n        info = self.info.loc[filt,:]\n        for col in df.loc[:,d_x:d_y].columns:\n            df[col] = (df[col] - info['min'])\/(info['maxdiffmin'])\n        return df\n    \n    def reverse_transform(self, df, d_x =None,d_y = None):\n        \n        filt = self.info['id'].isin(df['id'].tolist())\n        info = self.info.loc[filt,:]\n        if d_x == None or d_y == None :\n            d_x = self.d_x\n            d_y = self.d_y\n        for col in df.loc[:,d_x:d_y].columns:\n            df[col] = round(df[col] * info['maxdiffmin'] + info['min'])\n        \n        return df","033bc479":"mmt = MinMaxtransformer('d_1','d_1913')\nmmt.fit(df)\ndf = mmt.transform(df,'d_1','d_1941') # this takes a little time","628b3eed":"df.set_index('id', inplace = True)\ndf['std'] = df.loc[:,'d_1':'d_1913'].std(axis =1 )\ndf['mean'] = df.loc[:,'d_1':'d_1913'].mean(axis =1 )\ndf['median'] = df.loc[:,'d_1':'d_1913'].median(axis =1 )\ndf['skew'] = df.loc[:,'d_1':'d_1913'].skew(axis =1 )","7a0a8e71":"item_df = df.groupby('item_id').agg('mean').loc[:,'d_1':'d_1913']\nitem_df['std'] = item_df.loc[:,'d_1':'d_1913'].std(axis =1 )\nitem_df['mean'] = item_df.loc[:,'d_1':'d_1913'].mean(axis =1 )\nitem_df['median'] = item_df.loc[:,'d_1':'d_1913'].median(axis =1 )\nitem_df['skew'] = item_df.loc[:,'d_1':'d_1913'].skew(axis =1 )","db800d10":"df = df.loc[:,['item_id','dept_id','store_id','std','mean','median','skew']]\ndf.reset_index(inplace = True)\nitem_df = item_df.loc[:,['std','mean','median','skew']]\nitem_df.reset_index(inplace = True)\n","ce9192fd":"df2 = pd.merge( df, item_df, how = 'left' , on = 'item_id') ","5f27360f":"Ann_features = pd.concat([df2 , pd.get_dummies(df.loc[:,['store_id','dept_id']])],axis =1 ).drop(['item_id','dept_id','store_id'],axis =1)","bcaab511":"Ann_features","e3a765e5":"Ann_features.to_csv('ann_features.csv')","55dba2c8":"## M5 Encoder Decoder model - Generating ANN features\nThis is with reference to the Notebook M5 Encoder Decoder model with attention in which I feed a hidden state\/ embedding from an ANN to the Encoder\n\nLink : https:\/\/www.kaggle.com\/josephjosenumpeli\/m5-forecasting-encoder-decoder-with-attention\nThe features generated are fairly simple. Before generating the features we scaled the data using a transformer function called MinMaxTransformer, this is optional and features can be fed without scaling too. And the scaling is done individually for each time series.\n\nThis Notebook contains the basic approach and is just the start","937052d8":"**Individual time series Features**","37c4ec98":"**One Hot encoding** We did it on store_id and dept_id. It could have been done on state and category too but the former felt more convenient. As both variables include state and category information.","779ac1dd":"**Item level time series Features** \nIf you are familiar with mean encodings this approach is simmilar to that in which we are capturing the properties of the aggregated series at an item level and merging into our individual time series features.\n\nA similar approach can be adopted for store and category level."}}