{"cell_type":{"8f3e34a5":"code","7ab61bf2":"code","2689e50b":"code","37c9c275":"code","0daf4e1f":"code","e055d90f":"code","d4f2c2e0":"code","96bd82a3":"code","6a168c06":"code","de3589b2":"code","22b9e585":"code","ebcdcdf3":"code","16349773":"markdown","0106e438":"markdown","6a7503a7":"markdown"},"source":{"8f3e34a5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom lightgbm import LGBMRegressor\nimport lightgbm as lgb\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","7ab61bf2":"## \u8a13\u7df4\u30c7\u30fc\u30bf\u8aad\u307f\u8fbc\u307f\ntrain = pd.read_csv(\"..\/input\/ykc-cup-1st\/train.csv\")\ntrain.head()","2689e50b":"train.shape","37c9c275":"## \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u8aad\u307f\u8fbc\u307f\ntest = pd.read_csv(\"..\/input\/ykc-cup-1st\/test.csv\")\ntest.head()","0daf4e1f":"test.shape","e055d90f":"## submission\u30d5\u30a1\u30a4\u30eb\u8aad\u307f\u8fbc\u307f\nsample_submission = pd.read_csv(\"..\/input\/ykc-cup-1st\/sample_submission.csv\")\nsample_submission.head()","d4f2c2e0":"## label encode all categorical features\ncat = [\"store_id\", \"genre_name\", \"area_name\", \"day_of_week\"]\nfor c in cat:\n    le = LabelEncoder()\n    train[c] = le.fit_transform(train[c].fillna(\"na\"))\n    test[c] = le.transform(test[c].fillna(\"na\"))\ntrain.head()","96bd82a3":"# features = [\"store_id\", \"day_of_week\", \"genre_name\", \"area_name\", \"latitude\", \"longitude\"] ## \u4e88\u6e2c\u306b\u4f7f\u7528\u3059\u308b\u7279\u5fb4\u91cf\u306e\u540d\u524d\n# target = \"log_visitors\" ## \u4e88\u6e2c\u5bfe\u8c61\nn_split = 5 ## cross validation\u306efold\u6570","6a168c06":"train['is_test'] = 0\ntest['is_test'] = 1\ndata = pd.concat([train, test], sort=False)\ndata.reset_index(drop=True, inplace=True)\n\ntarget = ['is_test']\nfeatures = [\"store_id\", \"day_of_week\", \"genre_name\", \"area_name\", \"latitude\", \"longitude\"] \n\nprint(data.shape)\ndata.head()","de3589b2":"lgb_params = {\n    'boost': 'gbdt',\n    'objective': 'binary',\n    'metric': 'auc',\n    'verbosity': 1,\n}","22b9e585":"kfold = KFold(n_splits=n_split, shuffle = True, random_state=42)\nfor i_fold, (train_idx, valid_idx) in enumerate(kfold.split(data)):\n    print(f\"--------fold {i_fold}-------\")\n    \n    ## train data\n    x_tr = data.loc[train_idx, features]\n    y_tr = data.loc[train_idx, target]\n\n    ## valid data\n    x_va = data.loc[valid_idx, features]\n    y_va = data.loc[valid_idx, target]\n    \n    lgb_train = lgb.Dataset(x_tr, label=y_tr)\n    lgb_test = lgb.Dataset(x_va, label=y_va)\n\n    model = lgb.train(\n        lgb_params,\n        lgb_train,\n        valid_sets=[lgb_train, lgb_test],\n        valid_names=['train', 'test'],\n        num_boost_round=1000,\n        early_stopping_rounds=100,\n        verbose_eval=100\n    )\n\n    valid_preds = model.predict(x_va, num_iteration=model.best_iteration)\n    valid_metric = roc_auc_score(y_va, valid_preds)\n\n    print('Valid Metric: {:.5f}'.format(valid_metric))","ebcdcdf3":"def display_importances(feature_importance_df_):\n    cols = feature_importance_df_[[\"feature\", \"importance\"]]\\\n        .groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n        \n    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n\n    plt.figure(figsize=(8, 10))\n    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n    plt.title('LightGBM Features (avg over folds)')\n    plt.show()\n    \nimportance_df = pd.DataFrame()\nimportance_df[\"feature\"] = features\nimportance_df[\"importance\"] = model.feature_importance(importance_type='gain', iteration=model.best_iteration)\ndisplay_importances(importance_df)","16349773":"## Encode Categorical Features","0106e438":"## Train, evaluate, and pred","6a7503a7":"## load"}}