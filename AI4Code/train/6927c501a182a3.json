{"cell_type":{"34540bd7":"code","3c92371a":"code","c928616b":"code","46c02369":"code","42370f48":"code","45fde1be":"code","707e26fc":"code","b24f8618":"code","9cc6335a":"code","320c1940":"code","706f3bd5":"code","ac79f844":"code","a4ef3f6c":"code","de5d3829":"code","5d73f86d":"markdown","d898c415":"markdown","3557bf98":"markdown","f7c603d4":"markdown","fb1bcd54":"markdown","afe9532b":"markdown","813f25ef":"markdown","a42dadce":"markdown","d2f9a893":"markdown","555fd00f":"markdown","9df63d25":"markdown","673a1971":"markdown","e76893c3":"markdown"},"source":{"34540bd7":"import math\nimport re\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom matplotlib import pyplot as plt","3c92371a":"# constant labels\nSPAM = 'SPAM'\nNOT_SPAM = 'NOT_SPAM'\nMINIMUM_WORD_LENGTH = 0 # minimum controlled word length to exclude analysis of prepositions and articles\n\n\nclass SpamAnalizer():  \n    def __init__(self):\n        self.no_spam = {}  # dictionary with not spam words\n        self.spam = {}     # dictionary with spam words\n        self.pA = 0        # probability that the new mail is spam\n        self.pNotA = 0     # probability that the new mail is not spam \n        self.spam_mails_count = 0       # spam mail counter during fitting\n        self.notspam_mails_count = 0    # not spam mail counter during fitting\n        self.mails_count = 0            # all types mail counter during fitting\n#        self.fitting_word_counter = 0   # amount words in fitting dataset\n        \n    def calculate_word_frequencies(self, body, label):\n        '''function is used in fitting\n        function takes text labeled SPAM or NOT_SPAM and depending this label\n        fills dictionaries self.no_spam and self.spam\n        parameters: body - text, label - SPAM or NOT_SPAM\n        '''\n        \n        # choosing filling dictionary\n        if label == 'SPAM':\n            current_dict = self.spam\n        elif label == 'NOT_SPAM':\n            current_dict = self.no_spam\n        else:\n            raise ValueError('Label should be \"SPAM\" or \"NOT_SPAM\"')\n        \n        # each word in body converted to lower case\n        for word in body.lower().split():\n        # using MINIMUM_WORD_LENGTH if we want to avoid processing prepositions\n            if len(word) > MINIMUM_WORD_LENGTH:\n                current_dict[word] = current_dict.get(word, 0) + 1\n    \n    def train(self, train_data):\n        '''function is used in fitting\n        function takes list of text labeled SPAM or NOT_SPAM and \n        calls calculate_word_frequencies for each text\n        function fills values - different mail counters, self.pA, self.pNotA\n        parameters: train_data - list of text\n        '''\n        for mail in train_data:\n            self.mails_count += 1\n            \n            # deleting all characters except letters and spaces \n            pattern = re.compile('[^\\s\u0410-\u042f\u0430-\u044f\u0451\u0401A-Za-z]')\n            body = re.sub(pattern, '', mail[0])\n            \n            # filling self.spam_mails_count and self.notspam_mails_count\n            # calling calculate_word_frequencies(..) for each text\n            if str(mail[1]) == 'SPAM':\n                self.spam_mails_count += 1\n                self.calculate_word_frequencies(body, 'SPAM')\n            elif str(mail[1]) == 'NOT_SPAM':\n                self.notspam_mails_count += 1\n                self.calculate_word_frequencies(body, 'NOT_SPAM')\n            else:\n                raise ValueError('Label should be \"SPAM\" or \"NOT_SPAM\"')\n        \n        # calculation self.pA and self.pNotA\n        self.pA = self.spam_mails_count\/self.mails_count\n        self.pNotA = self.notspam_mails_count\/self.mails_count\n        \n    def calculate_P_Bi_A(self, word, label):\n        '''function considers for each word the probabilities that it is spam and that\n        it is not spam due to label\n        parameters: word - separate word, label - SPAM or NOT_SPAM\n        output: how many times the word appeared in the corresponding dictionary(self.spam or self.no_spam)\n        divided by the total number of unique words in the corresponding dictionary\n        '''\n        word_low = word.lower() # working with word only in lowcase\n        \n        # deciding wich dictionary we will use according label\n        if label == 'SPAM':\n            current_dict = self.spam\n        elif label == 'NOT_SPAM':\n            current_dict = self.no_spam\n        else:\n            raise ValueError('Label should be \"SPAM\" or \"NOT_SPAM\"')\n        \n       # counting probability that word is label category(SPAM or NOT_SPAM)\n       # if we haven't seen yet this word during fitting, word counter is assigned 1, not 0\n       # if we have seen this word during fitting, word counter is calculated in the corresponding dictionary\n\n        word_probability = current_dict.get(word_low, 0) + 1\n        \n        # dividing number of word appearing in label category during fitting to the \n        # total number of unique words in the corresponding dictionary\n        return(word_probability\/sum(current_dict.values()))\n    \n    def calculate_P_B_A(self, text, label):\n        '''function considers for text the probabilities that it is spam and that\n        it is not spam due to label.\n        According to Naive Bayes classifier probability that text belongs to label category is\n        the sum of logarithm of probabilities that each word belongs to label category and \n        logarithm of probability meeting this label category among all fitting texts.\n        \n        parameters: text, label - SPAM or NOT_SPAM\n        output: probability that text belongs to label category'''\n        probability = 0\n        \n        # counting sum of logarithm of probabilities that each word belongs to label category\n        # calling the function calculate_P_Bi_A for each word in text\n        for word in text.split():\n            if len(word) > MINIMUM_WORD_LENGTH:\n                probability += math.log10(self.calculate_P_Bi_A(word, label))\n        \n        # adding logarithm of probability meeting this label category among all fitting texts\n        if label == 'SPAM':\n            probability += math.log10(self.pA)\n        elif label == 'NOT_SPAM':\n            probability += math.log10(self.pNotA)\n        else:\n            raise ValueError('Label should be \"SPAM\" or \"NOT_SPAM\"')\n        \n        return probability\n    \n    def classify(self, email):\n        '''The function considers that email is SPAM or not calling the function calculate_P_B_A two \n        times with labels SPAM and NOT_SPAM and comparing results        \n        '''\n        # deleting all characters except letters and spaces\n        pattern = re.compile('[^\\s\u0410-\u042f\u0430-\u044f\u0451\u0401A-Za-z]')\n        text = re.sub(pattern, '', email)\n        \n        # comparing probability that text is spam or not_spam\n        if self.calculate_P_B_A(text, SPAM) > self.calculate_P_B_A(text, NOT_SPAM):\n            return SPAM\n        else:\n            return NOT_SPAM\n","c928616b":"train_data = [  \n    ['\u041a\u0443\u043f\u0438\u0442\u0435 \u043d\u043e\u0432\u043e\u0435 \u0447\u0438\u0441\u0442\u044f\u0449\u0435\u0435 \u0441\u0440\u0435\u0434\u0441\u0442\u0432\u043e', SPAM],   \n    ['\u041a\u0443\u043f\u0438 \u043c\u043e\u044e \u043d\u043e\u0432\u0443\u044e \u043a\u043d\u0438\u0433\u0443', SPAM],  \n    ['\u041f\u043e\u0434\u0430\u0440\u0438 \u0441\u0435\u0431\u0435 \u043d\u043e\u0432\u044b\u0439 \u0442\u0435\u043b\u0435\u0444\u043e\u043d', SPAM],\n    ['\u0414\u043e\u0431\u0440\u043e \u043f\u043e\u0436\u0430\u043b\u043e\u0432\u0430\u0442\u044c \u0438 \u043a\u0443\u043f\u0438\u0442\u0435 \u043d\u043e\u0432\u044b\u0439 \u0442\u0435\u043b\u0435\u0432\u0438\u0437\u043e\u0440', SPAM],\n    ['\u041f\u0440\u0438\u0432\u0435\u0442 \u0434\u0430\u0432\u043d\u043e \u043d\u0435 \u0432\u0438\u0434\u0435\u043b\u0438\u0441\u044c', NOT_SPAM], \n    ['\u0414\u043e\u0432\u0435\u0437\u0435\u043c \u0434\u043e \u0430\u044d\u0440\u043e\u043f\u043e\u0440\u0442\u0430 \u0438\u0437 \u043f\u0440\u0438\u0433\u043e\u0440\u043e\u0434\u0430 \u0432\u0441\u0435\u0433\u043e \u0437\u0430 399 \u0440\u0443\u0431\u043b\u0435\u0439', SPAM], \n    ['\u0414\u043e\u0431\u0440\u043e \u043f\u043e\u0436\u0430\u043b\u043e\u0432\u0430\u0442\u044c \u0432 \u041c\u043e\u0439 \u041a\u0440\u0443\u0433', NOT_SPAM],  \n    ['\u042f \u0432\u0441\u0435 \u0435\u0449\u0435 \u0436\u0434\u0443 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u044b', NOT_SPAM],  \n    ['\u041f\u0440\u0438\u0433\u043b\u0430\u0448\u0430\u0435\u043c \u043d\u0430 \u043a\u043e\u043d\u0444\u0435\u0440\u0435\u043d\u0446\u0438\u044e Data Science', NOT_SPAM],\n    ['\u041f\u043e\u0442\u0435\u0440\u044f\u043b \u0442\u0432\u043e\u0439 \u0442\u0435\u043b\u0435\u0444\u043e\u043d \u043d\u0430\u043f\u043e\u043c\u043d\u0438', NOT_SPAM],\n    ['\u041f\u043e\u0440\u0430\u0434\u0443\u0439 \u0441\u0432\u043e\u0435\u0433\u043e \u043f\u0438\u0442\u043e\u043c\u0446\u0430 \u043d\u043e\u0432\u044b\u043c \u043a\u043e\u0441\u0442\u044e\u043c\u043e\u043c', SPAM]\n]  \n\nspam_analizer_test = SpamAnalizer()\nspam_analizer_test.train(train_data)","46c02369":"example_mail_1 = '\u0420\u0430\u0437\u0432\u0438\u0432\u0430\u0439  \u043a\u0443\u043f\u0438\u0442\u0435 \u0431\u0438\u0437\u043d\u0435\u0441 \u043d\u0430 \u0434\u043e\u043c\u0443 \u0441 \u0443\u0441\u043b\u0443\u0433\u043e\u0439 \"\u0411\u0435\u0437\u043b\u0438\u043c\u0438\u0442\u043d\u044b\u0439 \u0418\u043d\u0442\u0435\u0440\u043d\u0435\u0442\"'\nexample_mail_2 = '\u041c\u044b \u043f\u043e\u043b\u0443\u0447\u0438\u043b\u0438 \u0432\u0430\u0448\u0435 \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u0435 \u043e \u043f\u0440\u043e\u043f\u0430\u0436\u0435 \u0431\u0430\u0433\u0430\u0436\u0430 \u0438 \u0434\u043e\u043c\u0430\u0448\u043d\u0435\u0433\u043e \u043f\u0438\u0442\u043e\u043c\u0446\u0430 \u0432 \u0437\u0434\u0430\u043d\u0438\u0438 \u0430\u044d\u0440\u043e\u043f\u043e\u0440\u0442\u0430. \u041a\u043e\u043d\u0435\u0447\u043d\u043e, \u043d\u0430\u043c \u0436\u0430\u043b\u044c. \u041d\u043e \u0447\u0442\u043e \u043c\u044b \u043c\u043e\u0436\u0435\u043c \u0441 \u044d\u0442\u0438\u043c \u0441\u0434\u0435\u043b\u0430\u0442\u044c?'\nexample_mail_3 = '\u041f\u0435\u0440\u0435\u0437\u0432\u043e\u043d\u0438 \u043f\u043e \u043d\u043e\u043c\u0435\u0440\u0443 +799999999 \u0432 \u0442\u0435\u0447\u0435\u043d\u0438\u0435 6 \u0441\u0435\u043a\u0443\u043d\u0434 \u0438 \u0432\u044b\u0438\u0433\u0440\u0430\u0439 \u043c\u0438\u043b\u043b\u0438\u043e\u043d \u0440\u0443\u0431\u043b\u0435\u0439!'\n\nprint('mail_1 :',spam_analizer_test.classify(example_mail_1))\nprint('mail_2 :',spam_analizer_test.classify(example_mail_2))\nprint('mail_3 :',spam_analizer_test.classify(example_mail_3))\nprint()\nprint('minimum controlled word length: ', MINIMUM_WORD_LENGTH)\nprint('pA:', spam_analizer_test.pA)\nprint('unique spam words:', len(spam_analizer_test.spam))\nprint('unique not spam words:', len(spam_analizer_test.no_spam))\n","42370f48":"# importing dataset https:\/\/www.kaggle.com\/ozlerhakan\/spam-or-not-spam-dataset\n# df = pd.read_csv('spam_or_not_spam.csv')\ndf = pd.read_csv(\"..\/input\/spam-or-not-spam-dataset\/spam_or_not_spam.csv\")\ndf = df.dropna()\ndf['label'] = df['label'].apply(lambda s: SPAM if (s == 1) else NOT_SPAM)\n\ndata_list = df.values.tolist()","45fde1be":"# Creating train and validation sets\ntrain, valid = train_test_split(df, test_size=0.15, shuffle=True, random_state=42)\n\nprint('Initial dataset size: {}\\nTrain set size: {}\\nValidation set size: {}'\n      .format(df.shape, train.shape, valid.shape)\n)","707e26fc":"def visualize_train_valid_counts(init_data, train, valid):\n    '''function create visualisation of splitted data\n    in comparison with the initial data set\n    '''\n    x = np.array([0, 1])\n    width = 0.2\n\n    plt.figure(figsize=(15, 8))\n    ax = plt.subplot(111)\n\n    # classes in this example - SPAM or NOT_SPAM\n    classes = list(init_data['label'].value_counts().index)\n\n    ax.bar(x - width, list(init_data['label'].value_counts()[classes]), \\\n           width, color='r', label='Initial data set')\n    ax.bar(x, list(train['label'].value_counts()[classes]), width, \\\n           color='g', label='Train set')\n    ax.bar(x, list(valid['label'].value_counts()[classes]), width, \\\n           bottom=list(train['label'].value_counts()[classes]), \\\n           color='b', label='Validation set')\n\n\n    plt.xticks(x - width \/ 2, classes, fontsize=20)\n    plt.yticks(fontsize=15)\n    plt.ylabel('Samples', fontsize=20)\n    plt.minorticks_on()\n    plt.grid(which='major', color='r')\n    plt.grid(which='minor', linestyle=':', color='k')\n    plt.legend(fontsize=15)","b24f8618":"# let's look at the splitted data\nvisualize_train_valid_counts(df,train,valid)","9cc6335a":"# fitting model with big dataset\ntrain_list = train.values.tolist()\n\nspam_analizer = SpamAnalizer()\nspam_analizer.train(train_list)","320c1940":"# creating information to analize accuracy score\nvalid['prediction'] = valid.apply(lambda row: spam_analizer.classify(row['email']), axis=1)","706f3bd5":"valid[valid['label'] != valid['prediction']]","ac79f844":"from sklearn.metrics import accuracy_score\nscore = accuracy_score(valid['label'], valid['prediction'])\nprint('accuracy of model prediction:', score)","a4ef3f6c":"spam_analizer = SpamAnalizer()\nspam_analizer.train(data_list)","de5d3829":"example_mail_1 = \"Hi, My name is Warren E. Buffett an American business magnate, investor and philanthropist. am the most successful investor in the world. I believe strongly in\u2018giving while living\u2019 I had one idea that never changed in my mind? that you should use your wealth to help people and i have decided to give {$1,500,000.00} One Million Five Hundred Thousand United Dollars, to randomly selected individuals worldwide. On receipt of this email, you should count yourself as the lucky individual. Your email address was chosen online while searching at random. Kindly get back to me at your earliest convenience before i travel to japan for my treatment , so I know your email address is valid. Thank you for accepting our offer, we are indeed grateful You Can Google my name for more information: God bless you. Best Regard Mr.Warren E. Buffett Billionaire investor !\"\nexample_mail_2 = \"Hi guys I want to build a website like REDACTED and I wanted to get your perspective of whether that site is good from the users' perspective before I go ahead and build something similar. I think that the design of the site is very modern and nice but I am not sure how people would react to a similar site? I look forward to your feedback. Many thanks! \"\nexample_mail_3 = \"As a result of your application for the position of Data Engineer, I would like to invite you to attend an interview on May 30, at 9 a.m. at our office in Washington, DC. You will have an interview with the department manager, Moris Peterson. The interview will last about 45 minutes. If the date or time of the interview is inconvenient, please contact me by phone or email to arrange another appointment. We look forward to seeing you. \"\n\nprint('mail_1 :',spam_analizer.classify(example_mail_1))\nprint('mail_2 :',spam_analizer.classify(example_mail_2))\nprint('mail_3 :',spam_analizer.classify(example_mail_3))\nprint()\nprint('minimum controlled word length: ', MINIMUM_WORD_LENGTH)\nprint('pA:', spam_analizer.pA)\nprint('unique spam words:', len(spam_analizer.spam))\nprint('unique not spam words:', len(spam_analizer.no_spam))\nprint('accuracy of model prediction:', score)","5d73f86d":"# How do spam filters work?\n\nLet's see how most spam filters work and how their work is related to probability theory.\n\nMost spam filters are based on the Bayesian theorem. It allows you to find the probability of one event, provided that another event has occurred. This is symbolically expressed as P(A|B), i.e. Probability of event A will occur given that event B has already occurred.\nIn our case, an event is the probability of meeting a text. Condition - the text is spam.\n","d898c415":"# Import","3557bf98":"# Fitting model and getting result","f7c603d4":"And then let's compute and compare the values of expressions. This inequality shows us, that given sentence is spam:\n$$P(A|B) > P(\\overline{A}|B)$$\n* $P(\\overline{A}|B)$ - probability that given sentence is not spam.\n\nOr we could rewrite formula \n$$P(A) \\cdot P(B|A) > P(\\overline{A}) \\cdot  P(B|\\overline{A})$$\n","fb1bcd54":"Reasons to use Bayes\u2019 Theorem:\n\n* Bayes\u2019 Theorem provides a useful perspective for understanding and evaluating many learning algorithms.\n* It calculates explicit probabilities for hypothesis and it is robust to noise in the input data.\n* In statistical classification, it minimizes the probability of misclassification.","afe9532b":"Thus, we calculate \n$$P(B|A) = \\prod_{i} P(B_{i}|A)$$\n* $\\prod_{i}$ - product of several elements,\n* $B$ - one sentence,\n* $B_{i}$ - one word in sentense.","813f25ef":"# Naive bayes spam classifier\n\nThe task is:\n\n* Write a model that will make predicts whether text is spam or not.\n* Wrap the model in a service so that other services can communicate with the model - send messages to it and receive \u201cspam \/ no spam\u201d in response.\n* Learn something new.","a42dadce":"# Validation\nI fitted model using dataset https:\/\/www.kaggle.com\/ozlerhakan\/spam-or-not-spam-dataset","d2f9a893":"![%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5.png](attachment:%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5.png)\n\n* P(A) - probability of spam\n* P(B) - probability of text\n* P(A|B) - probability that the text is spam\n* P(B|A) - probability of meeting this text among spam","555fd00f":"# First look\n\nLet's test our classifier on small dataset(train_data) and some mail examples","9df63d25":"Our final result has accuracy 0.9755555555555555","673a1971":"# How to count these probabilities?\n\nThe Bayesian classifier is based on the assumption that the attributes of a class are independent of each other. In reality, almost all attributes of anything depend on each other, and it is very naive to admit this. But with the classification of spam, the Bayesian algorithm is very effective (and this despite the fact that the words in the text always depend on each other). The fact is that in determining the \u201cspam\u201d nature of a text, we operate on probabilities. And if we believe that these probabilities are independent, we have a very powerful weapon - independent probabilities can be multiplied!\n\nTo calculate the probability that a given sentence is spam, we calculate the spam probability for each word in the sentence, and then simply multiply these probabilities. Thus, the likelihood that a given text is spam is the product of the probability of spam and the likelihood of encountering a given text among the set of all possible spam variants.\n","e76893c3":"# Model\nLet's create spam classificator"}}