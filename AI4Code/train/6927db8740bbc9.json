{"cell_type":{"aad145e5":"code","8d5c3190":"code","dbde079d":"code","fbd24af8":"code","922f07c1":"code","eb3da531":"code","087a1638":"code","1f6c08cd":"code","0dab2301":"code","ac439a4c":"code","7c5e1af3":"code","7692ec60":"code","36c5a2f3":"code","cb82cb50":"code","d17b3613":"code","02d0866f":"code","dba36e06":"code","bb7a5829":"code","1fff822e":"code","6eaddc17":"code","630eb1ae":"code","4dc1680a":"code","ffdca366":"code","9d841fd0":"code","f9235a07":"code","eeb5b8ae":"code","7c9513f3":"code","e4b07ba5":"markdown","9dfbbff9":"markdown","341570d9":"markdown","46a2ac84":"markdown","a5c274c2":"markdown","453958f7":"markdown","428188ef":"markdown","cb46ed24":"markdown","67b6b6c6":"markdown","c123d589":"markdown","210783a0":"markdown","8a1a7fe1":"markdown","1d0801e1":"markdown","e8829347":"markdown","f30cf4db":"markdown","2407f4ad":"markdown","c48fdc38":"markdown","35e0f47f":"markdown","10d2aab6":"markdown","d1ee9402":"markdown","3690b18e":"markdown","dab34e68":"markdown","624848fa":"markdown","0a665d0c":"markdown","296a2cc2":"markdown"},"source":{"aad145e5":"import numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow.keras import layers\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","8d5c3190":"# load training data\ntrain_data = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\", sep=\",\")\n\n\n\n# take a look at the data descriptoin\nf = open('\/kaggle\/input\/house-prices-advanced-regression-techniques\/data_description.txt', 'r')\nfile_contents = f.read()\nprint (file_contents)\nf.close()","dbde079d":"# The data contains categorical and numeric values.\n# Define which columns are categorical and which numeric.\n# Defining numeric columns is easier\nnum_cols = ['LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF',\n            '2ndFlrSF','LowQualFinSF','GrLivArea','GarageArea','WoodDeckSF','OpenPorchSF',\n            'EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MiscVal','SalePrice']\n\n#numerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n\n# Categorical columns are all remaining columns\ncat_cols = list(train_data.columns.drop(num_cols))\n\n\n# Double check dimensions\nif (len(train_data.columns) != (len(num_cols)+len(cat_cols))): print(\"Error\")\nelse: print('Ok')\n","fbd24af8":"def nan_columns(df):\n    '''\n    Functtion nan_columns takes DataFrame df\n    and returns a list of all columns in df,\n    that have at least one NaN\n    '''\n    nan_values = df.isna()\n    nan_columns = nan_values.any()\n\n    columns_with_nan = df.columns[nan_columns].tolist()\n    return(columns_with_nan)\n\n\n\n# Get column names of numeric features that have NaN values\nnum_cols_nan = nan_columns(train_data[num_cols])\n\nprint(\"The following numeric features have NaN entries: \" + str(num_cols_nan))\nprint(\"\\nThe following numeric features have NaN entries:\\n\" + str(train_data[num_cols_nan].isna().sum()))","922f07c1":"train_data.info()","eb3da531":"for col in num_cols_nan:\n    col_id_to_drop = train_data.index[train_data[col].isna()]\n    train_data = train_data.drop(col_id_to_drop)\n\n# Double check if all NaN rows in features have been dropped\nif nan_columns(train_data[num_cols]) == []: print(\"Ok\")\nelse: print(\"Error\")\n","087a1638":"train_data[num_cols].describe().transpose()","1f6c08cd":"# Get column names of numeric features that have NaN values\ncat_cols_nan = nan_columns(train_data[cat_cols])\n\nprint(\"The following numeric features have NaN entries: \" + str(cat_cols_nan))\nprint(\"\\nThe following numeric features have NaN entries:\\n\" + str(train_data[cat_cols_nan].isna().sum()))","0dab2301":"# Return Unique Tags for a specific Collumn\ndef get_unique_tags(dataset,col):\n    return set(dataset[col].explode().unique())","ac439a4c":"for col in cat_cols_nan:\n    cat = get_unique_tags(train_data,col)\n    print(str(col) + \" has the following tags\" + str(cat))","7c5e1af3":"na_cols = ['Alley','FireplaceQu','GarageType','GarageYrBlt','GarageFinish','GarageQual',\n                           'GarageCond','PoolQC','Fence','MiscFeature']\n\nfor to_replace in na_cols:\n    train_data[to_replace] = train_data[to_replace].replace(np.nan, \"NA\")\n    \nfor col in na_cols:\n    cat = get_unique_tags(train_data,col)\n    print(str(col) + \" has the following categories\" + str(cat))","7692ec60":"# Get column names of numeric features that have NaN values\ncat_cols_nan = nan_columns(train_data[cat_cols])\n\nprint(\"The following categoric features have NaN entries: \" + str(cat_cols_nan))\nprint(\"\\nThe following categoric features have NaN entries:\\n\" + str(train_data[cat_cols_nan].isna().sum()))","36c5a2f3":"index_bs = train_data['BsmtQual'].index[train_data['BsmtQual'].isna()]\nprint(index_bs)\n\n# Get all index where BsmtQual is nan\nindex_bs = train_data['BsmtQual'].index[train_data['BsmtQual'].isna()]\n\nfor bs_cat in ['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2']:\n    train_data.loc[index_bs,bs_cat] = \"NA\"\n\n    \n# Get column names of numeric features that have NaN values\ncat_cols_nan = nan_columns(train_data[cat_cols])\n\nprint(\"The following categoric features have NaN entries: \" + str(cat_cols_nan))\nprint(\"\\nThe following categoric features have NaN entries:\\n\" + str(train_data[cat_cols_nan].isna().sum()))\n\n","cb82cb50":"train_data.nunique()","d17b3613":"for col in cat_cols_nan:\n    col_id_to_drop = train_data.index[train_data[col].isna()]\n    train_data = train_data.drop(col_id_to_drop)\n\n# Double check if all NaN rows in features have been dropped\nif nan_columns(train_data[cat_cols]) == []: print(\"Ok\")\nelse: print(\"Error\")","02d0866f":"y_train = train_data['SalePrice']\nX_train = train_data.drop('SalePrice',axis=1)\nX_train = X_train.drop('Id',axis=1)","dba36e06":"cat_cols.remove('Id')\nX_train[cat_cols] = X_train[cat_cols].astype('str')","bb7a5829":"inputs = {}\n\nfor name, _ in X_train.items():\n    if str(name) in num_cols:\n        dtype = tf.float32\n    else:\n        dtype = tf.string\n    inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n\ninputs","1fff822e":"numeric_inputs = {name:input for name,input in inputs.items()\n                  if input.dtype==tf.float32}\n\nx = layers.Concatenate()(list(numeric_inputs.values()))\nnorm = layers.Normalization()\nnorm.adapt(np.array(train_data[numeric_inputs.keys()]))\nall_numeric_inputs = norm(x)\n\nall_numeric_inputs","6eaddc17":"preprocessed_inputs = [all_numeric_inputs]","630eb1ae":"for name, input in inputs.items():\n    if input.dtype == tf.string:\n        \n        print(name)\n        lookup = layers.StringLookup(vocabulary=np.unique(X_train[name]))\n        one_hot = layers.CategoryEncoding(max_tokens=lookup.vocab_size())\n\n        x = lookup(input)\n        x = one_hot(x)\n        preprocessed_inputs.append(x)","4dc1680a":"preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)\n\ntrain_data_preprocessing = tf.keras.Model(inputs, preprocessed_inputs_cat)","ffdca366":"train_data_features_dict = {name: np.array(value) for name, value in X_train.items()}","9d841fd0":"features_dict = {name:values[:1] for name, values in train_data_features_dict.items()}\ntrain_data_preprocessing(features_dict)","f9235a07":"def house_model(preprocessing_head, inputs):\n    body = tf.keras.Sequential([\n        layers.Dense(1024, activation='relu'),\n        layers.Dense(512, activation='relu'),\n        layers.Dense(256, activation='relu'),\n        layers.Dense(64, activation='relu'),\n        layers.Dense(1,activation='linear')\n    ])\n\n    preprocessed_inputs = preprocessing_head(inputs)\n    result = body(preprocessed_inputs)\n    model = tf.keras.Model(inputs, result)\n\n    model.compile(loss='mean_squared_error',optimizer=tf.optimizers.Adam(0.001))\n    \n    return model\n\nhouse_model = house_model(train_data_preprocessing, inputs)","eeb5b8ae":"history = house_model.fit(x=train_data_features_dict, y=y_train, validation_split=0.2,verbose=1, epochs=50)","7c9513f3":"import matplotlib.pyplot as plt\n\n\ndef plot_loss(history):\n    plt.plot(history.history['loss'], label='loss')\n    plt.plot(history.history['val_loss'], label='val_loss')\n    plt.ylim([0, 10])\n    plt.xlabel('Epoch')\n    plt.ylabel('mean_squared_error')\n    plt.legend()\n    plt.grid(True)\n\nplot_loss(history)","e4b07ba5":"### 3.1 Build the preprocessing model","9dfbbff9":"With the collection of inputs and processed_inputs, you can concatenate all the preprocessed inputs together, and build a model that handles the preprocessing:","341570d9":"# 2. Pre-Processing Data","46a2ac84":"### 2.5 Drop faulty categorical rows","a5c274c2":"# 3. Build the model","453958f7":"### 2.4 Replace correct columns with nan-entries with \"NA\"","428188ef":"### Double Check","cb46ed24":"### 2.3 Look at categorical columns individually","67b6b6c6":"### BsmtExposure and BsmtFinType2 have too many NaN entries. \n### First Replace all NaN entries with \"NA\", where BsmtQual is NaN","c123d589":"## 2.2 Pre-Process categorical values","210783a0":"This model just contains the input preprocessing. You can run it to see what it does to your data. Keras models don't automatically convert Pandas DataFrames because it's not clear if it should be converted to one tensor or to a dictionary of tensors. So convert it to a dictionary of tensors:","8a1a7fe1":"### 2.13 Drop SalePrice and Id from data","1d0801e1":"## 2.2 Pre-Process numerical values\n### 2.2.1 Check numerical values for NaN entries","e8829347":"### 3.2 Build the model","f30cf4db":"For the categorical inputs use the tf.keras.layers.StringLookup function to map from strings to integer indices in a vocabulary. Next, use tf.keras.layers.CategoryEncoding to convert the indexes into float32 data appropriate for the model.\n\nThe default settings for the tf.keras.layers.CategoryEncoding layer create a one-hot vector for each input. A layers.Embedding would also work. See the preprocessing layers guide and tutorial for more on this topic.","2407f4ad":"## 2.1 Split Data sets into categorical and nuemric values","c48fdc38":"### Concatenate the numeric inputs together, and run them through a normalization layer","35e0f47f":"* Alley: all nan should be \"NA\"\n* Bsmt* NaN-entries have mismatch, find mismatch by looking at index of nan-entries\n* Electrical should not have nan-entry. Drop!\n* FireplaceQu: all nana should be \"NA\"\n* All Garage* NaN-entries should have \"NA\"\n* PoolQC: all nan should be \"NA\"\n* Fence: all nan should be \"NA\"\n* MiscFeature: all nan should be \"NA\"\n\n","10d2aab6":"### Start by building a set of symbolic keras.Input objects, matching the names and data-types of the CSV columns.","d1ee9402":"### Collect all the symbolic preprocessing results, to concatenate them later.","3690b18e":"Slice out the first training example and pass it to this preprocessing model, you see the numeric features and string one-hots all concatenated together:","dab34e68":"### Drop NaN rows in the numeric features","624848fa":"### 2.2.2 Check numerical values outliers","0a665d0c":"### These categorical entries seem to be faulty","296a2cc2":"# 1. Load Data get familiar with it"}}