{"cell_type":{"f3b4a76c":"code","4f0faa94":"code","2a8a7f94":"code","fcf87be1":"code","a4663651":"code","ca02b988":"code","d447bd69":"code","f640f642":"code","0012eaec":"code","dc49b6dd":"code","61aa6fe1":"code","5da75795":"code","fa1ee112":"code","1455f4f6":"code","00a04de8":"code","286ca765":"code","4f9c766b":"code","9751cce4":"code","54632c6e":"code","2d99b413":"code","067552a9":"code","17f98dfb":"code","2f06f388":"code","9547d76e":"code","cacc580e":"code","a4b0a44b":"code","9c6eb0fd":"code","4d12f97b":"code","f4279b0c":"code","a7e0d481":"code","4590affe":"code","3ffe7118":"code","ea783256":"code","c94d5e5b":"code","899c38ea":"markdown","809a4c5b":"markdown","12479b01":"markdown","c4885538":"markdown","44c73385":"markdown","5882bc70":"markdown","142492d3":"markdown","f24a2f26":"markdown","fd56d1ff":"markdown","ea7f8834":"markdown","1269a257":"markdown","53f19c93":"markdown","60321986":"markdown","d2a7b6b6":"markdown"},"source":{"f3b4a76c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","4f0faa94":"data = pd.read_csv('\/kaggle\/input\/kolesa-dataset-2020\/clean_kolesa_dataset.csv')\ndata.tail()","2a8a7f94":"data = data[data['\u0426\u0435\u043d\u0430'] != 10000.0]","fcf87be1":"data.corr()['\u0426\u0435\u043d\u0430'].sort_values(ascending=False)","a4663651":"data.isnull().sum()","ca02b988":"col = ['\u041f\u0440\u0438\u0432\u043e\u0434', '\u0426\u0432\u0435\u0442', '\u0421\u0440\u0435\u0434\u043d\u043d\u044f \u0446\u0435\u043d\u0430']\ncars = data.copy()\ncars.drop(col, axis=1, inplace=True)\ncars.dropna(inplace=True)","d447bd69":"cars['\u0420\u0443\u043b\u044c'].value_counts()","f640f642":"cars.isnull().sum()","0012eaec":"from sklearn import preprocessing \n\n# label_encoder object knows how to understand word labels. \nlabel_encoder = preprocessing.LabelEncoder() \n\ncars['\u0412\u0438\u0434 \u0442\u043e\u043f\u043b\u0438\u0432\u0430'] = label_encoder.fit_transform(cars['\u0412\u0438\u0434 \u0442\u043e\u043f\u043b\u0438\u0432\u0430'])\ncars['\u041a\u043e\u0440\u043e\u0431\u043a\u0430 \u043f\u0435\u0440\u0435\u0434\u0430\u0447'] = label_encoder.fit_transform(cars['\u041a\u043e\u0440\u043e\u0431\u043a\u0430 \u043f\u0435\u0440\u0435\u0434\u0430\u0447'])\ncars['\u0420\u0430\u0441\u0442\u0430\u043c\u043e\u0436\u0435\u043d \u0432 \u041a\u0430\u0437\u0430\u0445\u0441\u0442\u0430\u043d\u0435'] = label_encoder.fit_transform(cars['\u0420\u0430\u0441\u0442\u0430\u043c\u043e\u0436\u0435\u043d \u0432 \u041a\u0430\u0437\u0430\u0445\u0441\u0442\u0430\u043d\u0435'])\ncars['\u0420\u0443\u043b\u044c'] = label_encoder.fit_transform(cars['\u0420\u0443\u043b\u044c'])\ncars['\u041a\u0443\u0437\u043e\u0432'] = label_encoder.fit_transform(cars['\u041a\u0443\u0437\u043e\u0432'])","dc49b6dd":"cars['\u0412\u0438\u0434 \u0442\u043e\u043f\u043b\u0438\u0432\u0430'].unique()","61aa6fe1":"cols = ['\u0411\u0440\u0435\u043d\u0434', '\u041c\u043e\u0434\u0435\u043b\u044c', '\u0413\u043e\u0434', '\u0413\u043e\u0440\u043e\u0434', '\u041a\u0443\u0437\u043e\u0432', '\u041e\u0431\u044a\u0435\u043c \u0434\u0432\u0438\u0433\u0430\u0442\u0435\u043b\u044f, \u043b',\n       '\u041f\u0440\u043e\u0431\u0435\u0433', '\u041a\u043e\u0440\u043e\u0431\u043a\u0430 \u043f\u0435\u0440\u0435\u0434\u0430\u0447', '\u0420\u0443\u043b\u044c', '\u0420\u0430\u0441\u0442\u0430\u043c\u043e\u0436\u0435\u043d \u0432 \u041a\u0430\u0437\u0430\u0445\u0441\u0442\u0430\u043d\u0435', '\u0426\u0435\u043d\u0430',\n       '\u0412\u0438\u0434 \u0442\u043e\u043f\u043b\u0438\u0432\u0430']\n\ncarprice = cars[cols]","5da75795":"carprice","fa1ee112":"corr = carprice.corr()\ncorr['\u0426\u0435\u043d\u0430'].sort_values(ascending=False)","1455f4f6":"plt.subplots(figsize=(20,9))\nsns.heatmap(corr)","00a04de8":"from scipy import stats\n\nplt.subplots(figsize=(12,9))\nsns.distplot(carprice['\u0426\u0435\u043d\u0430'], fit=stats.norm)\n\n(mu, sigma) = stats.norm.fit(carprice['\u0426\u0435\u043d\u0430'])\n\n# plot with the distribution\n\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)], loc='best')\nplt.ylabel('Frequency')\n\n#Probablity plot\n\nfig = plt.figure()\nstats.probplot(carprice['\u0426\u0435\u043d\u0430'], plot=plt)\nplt.show()","286ca765":"cars = carprice.copy()\ncarprice['\u0426\u0435\u043d\u0430'] = np.log1p(carprice['\u0426\u0435\u043d\u0430'])\nplt.subplots(figsize=(12,9))\nsns.distplot(carprice['\u0426\u0435\u043d\u0430'], fit=stats.norm)\n\n(mu, sigma) = stats.norm.fit(carprice['\u0426\u0435\u043d\u0430'])\n\n# plot with the distribution\n\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)], loc='best')\nplt.ylabel('Frequency')\n\n#Probablity plot\n\nfig = plt.figure()\nstats.probplot(carprice['\u0426\u0435\u043d\u0430'], plot=plt)\nplt.show()","4f9c766b":"from scipy import stats\n\nplt.subplots(figsize=(12,9))\nsns.distplot(carprice['\u041f\u0440\u043e\u0431\u0435\u0433'], fit=stats.norm)\n\n(mu, sigma) = stats.norm.fit(carprice['\u041f\u0440\u043e\u0431\u0435\u0433'])\n\n# plot with the distribution\n\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)], loc='best')\nplt.ylabel('Frequency')\n\n#Probablity plot\n\nfig = plt.figure()\nstats.probplot(carprice['\u041f\u0440\u043e\u0431\u0435\u0433'], plot=plt)\nplt.show()","9751cce4":"carprice['\u041f\u0440\u043e\u0431\u0435\u0433'] = np.log1p(carprice['\u041f\u0440\u043e\u0431\u0435\u0433'])\nplt.subplots(figsize=(12,9))\nsns.distplot(carprice['\u041f\u0440\u043e\u0431\u0435\u0433'], fit=stats.norm)\n\n(mu, sigma) = stats.norm.fit(carprice['\u0426\u0435\u043d\u0430'])\n\n# plot with the distribution\n\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)], loc='best')\nplt.ylabel('Frequency')\n\n#Probablity plot\n\nfig = plt.figure()\nstats.probplot(carprice['\u041f\u0440\u043e\u0431\u0435\u0433'], plot=plt)\nplt.show()","54632c6e":"top_10 = cars['\u0411\u0440\u0435\u043d\u0434'].value_counts().head(10)\ntop_10.plot.pie(figsize=(12,15), autopct='%1.0f%%')\nplt.legend(loc='upper left')","2d99b413":"plt.figure(figsize=(20, 8))\nsns.boxplot(x = '\u0411\u0440\u0435\u043d\u0434', y = '\u0426\u0435\u043d\u0430', data = cars)\nplt.xticks(rotation = 90)\nplt.show()","067552a9":"top_10.index.to_list()","17f98dfb":"cars_name = (cars['\u0411\u0440\u0435\u043d\u0434'] == 'Toyota') | (cars['\u0411\u0440\u0435\u043d\u0434'] == '\u0412\u0410\u0417 (Lada)') | (cars['\u0411\u0440\u0435\u043d\u0434'] == 'Mercedes-Benz') | (cars['\u0411\u0440\u0435\u043d\u0434'] == 'Volkswagen') | (cars['\u0411\u0440\u0435\u043d\u0434'] == 'Nissan') | (cars['\u0411\u0440\u0435\u043d\u0434'] == 'Hyundai') | (cars['\u0411\u0440\u0435\u043d\u0434'] == 'BMW') | (cars['\u0411\u0440\u0435\u043d\u0434'] == 'Mitsubishi') | (cars['\u0411\u0440\u0435\u043d\u0434'] == 'Audi') | (cars['\u0411\u0440\u0435\u043d\u0434'] == 'Lexus')\ncar = cars[cars_name]\ncar","2f06f388":"plt.figure(figsize=(20, 8))\nsns.boxplot(x = '\u0411\u0440\u0435\u043d\u0434', y = '\u0426\u0435\u043d\u0430', data = car)\nplt.xticks(rotation = 90)\nplt.show()","9547d76e":"top_10_model = car['\u041c\u043e\u0434\u0435\u043b\u044c'].value_counts().head(10)\ntop_10_model.plot.pie(figsize=(12,15), autopct='%1.0f%%')\nplt.legend(loc='upper left')","cacc580e":"df = car.copy()\ndf.drop(['\u0411\u0440\u0435\u043d\u0434', '\u041c\u043e\u0434\u0435\u043b\u044c', '\u0413\u043e\u0440\u043e\u0434'], inplace=True, axis=1)","a4b0a44b":"from sklearn.model_selection import train_test_split\ny = df['\u0426\u0435\u043d\u0430']\ndel df['\u0426\u0435\u043d\u0430']\nX = df.values\ny = y.values\nfrom sklearn.feature_selection import VarianceThreshold\nsel = VarianceThreshold(threshold=(.8 * (1 - .8)))\nX_sel = sel.fit_transform(X)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\nX_train_select, X_test_select, y_train_select, y_test_select = train_test_split(X, y, test_size=0.2, random_state=7)","9c6eb0fd":"from sklearn import linear_model\nmodel = linear_model.LinearRegression()\nmodel.fit(X_train, y_train)\n# Feature selected fit\nmodel_s = linear_model.LinearRegression()\nmodel_s.fit(X_train_select, y_train_select)","4d12f97b":"print('Accuracy of test--> ', model.score(X_test, y_test)*100)\nprint('Accuracy of test with Feature Selection--> ', model_s.score(X_test_select, y_test_select)*100)","f4279b0c":"from sklearn.linear_model import Ridge\nridge = Ridge().fit(X_train, y_train)\n# Feature selected fit\nridge_s = Ridge().fit(X_train_select, y_train_select)\nprint('Accuracy of test--> ', ridge.score(X_test, y_test)*100)\nprint('Accuracy of test with Feature Selection--> ', ridge_s.score(X_test_select, y_test_select)*100)","a7e0d481":"from sklearn.linear_model import Lasso\nlasso = Lasso().fit(X_train, y_train)\n# Feature selected fit\nlasso_s = Lasso().fit(X_train_select, y_train_select)\nprint('Accuracy of test--> ', lasso.score(X_test, y_test)*100)\nprint('Accuracy of test with Feature Selection--> ', lasso_s.score(X_test_select, y_test_select)*100)","4590affe":"from sklearn.ensemble import RandomForestRegressor\nrfr = RandomForestRegressor(n_estimators=200, max_depth=10)\nrfr.fit(X_train, y_train)\n# Feature selected fit\nrfr_s = RandomForestRegressor(n_estimators=200, max_depth=10)\nrfr_s.fit(X_train_select, y_train_select)\nprint('Accuracy of test--> ', rfr.score(X_test, y_test)*100)\nprint('Accuracy of test with Feature Selection--> ', rfr_s.score(X_test_select, y_test_select)*100)","3ffe7118":"from sklearn.ensemble import GradientBoostingRegressor\nGBR = GradientBoostingRegressor(n_estimators=200, max_depth=10)\nGBR.fit(X_train, y_train)\n# Feature selected fit\nGBR_s = GradientBoostingRegressor(n_estimators=200, max_depth=10)\nGBR_s.fit(X_train_select, y_train_select)\nprint('Accuracy of test--> ', GBR.score(X_test, y_test)*100)\nprint('Accuracy of test with Feature Selection--> ', GBR_s.score(X_test_select, y_test_select)*100)","ea783256":"from sklearn.neighbors import KNeighborsRegressor\nneigh = KNeighborsRegressor(n_neighbors=5)\nneigh.fit(X_train, y_train)\n# Feature selected fit\nneigh_s = KNeighborsRegressor(n_neighbors=5)\nneigh_s.fit(X_train, y_train)\nprint('Accuracy of test--> ', neigh.score(X_test, y_test)*100)\nprint('Accuracy of test with Feature Selection--> ', neigh_s.score(X_test_select, y_test_select)*100)","c94d5e5b":"from sklearn.tree import DecisionTreeRegressor\nd_tree = DecisionTreeRegressor(max_depth=10)\nd_tree.fit(X_train, y_train)\n# Feature selected fit\nd_tree_s = DecisionTreeRegressor(max_depth=10)\nd_tree_s.fit(X_train, y_train)\nprint('Accuracy of test--> ', d_tree.score(X_test, y_test)*100)\nprint('Accuracy of test with Feature Selection--> ', d_tree_s.score(X_test_select, y_test_select)*100)","899c38ea":"### Decision Tree Regression","809a4c5b":"### Linear Regression","12479b01":"### Random Forest","c4885538":"### Visualization","44c73385":"### Lasso Regression","5882bc70":"#### Top 10 Brand ","142492d3":"### Spliting Data into Training and Test Sets","f24a2f26":"### KNeighborsRegressor","fd56d1ff":"### Clean data from NA","ea7f8834":"* \u0411\u0440\u0435\u043d\u0434 ==> Brand\n* \u041c\u043e\u0434\u0435\u043b\u044c ==> Model\n* \u0413\u043e\u0434 ==> Year\n* \u0413\u043e\u0440\u043e\u0434 ==> City\n* \u041a\u0443\u0437\u043e\u0432 ==> Body\n* \u041e\u0431\u044a\u0435\u043c \u0434\u0432\u0438\u0433\u0430\u0442\u0435\u043b\u044f, \u043b ==> The volume of engine\n* \u041f\u0440\u043e\u0431\u0435\u0433 ==> Mileage\n* \u041a\u043e\u0440\u043e\u0431\u043a\u0430 \u043f\u0435\u0440\u0435\u0434\u0430\u0447 ==> Transmission\n* \u0420\u0443\u043b\u044c ==> Rudder\n* \u0426\u0432\u0435\u0442 ==> Color\n* \u041f\u0440\u0438\u0432\u043e\u0434 ==> Drive\n* \u0420\u0430\u0441\u0442\u0430\u043c\u043e\u0436\u0435\u043d \u0432 \u041a\u0430\u0437\u0430\u0445\u0441\u0442\u0430\u043d\u0435 ==> Customs clearance in Kazakhstan\n* \u0426\u0435\u043d\u0430 ==> Price\n* \u0421\u0440\u0435\u0434\u043d\u044f\u044f \u0426\u0435\u043d\u0430 ==> Mean price\n* \u0421\u0441\u044b\u043b\u043a\u0430 ==> Link\n* \u0412\u0438\u0434 \u0442\u043e\u043f\u043b\u0438\u0432\u0430 ==> Fuel type","1269a257":"### \u0413\u0440\u0435\u0431\u043d\u0435\u0432\u0430\u044f \u0420\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u044f or Ridge Regression","53f19c93":"### Preprocessing with LabelEncoder","60321986":"### Gradient Boosting Regressor","d2a7b6b6":"### Top 10 popular model of top 10 brand"}}