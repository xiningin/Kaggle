{"cell_type":{"01ef9508":"code","6dc7d787":"code","6e99d586":"code","dd9703a5":"code","ade616a6":"code","56dede1e":"code","27a88dd0":"code","86e9ae22":"code","35c1f5d2":"code","b73e4914":"code","0b06236a":"code","badba1f1":"code","a36b7a61":"code","13df7e34":"code","b68007f2":"code","c55c995f":"code","9c6c73fc":"code","97341d53":"code","515e7028":"code","f2fc150a":"code","a179292a":"markdown","2f75494d":"markdown","444379d3":"markdown","4ddc038e":"markdown","9273450b":"markdown","89147164":"markdown","aa2602eb":"markdown","59da190b":"markdown","e8a53232":"markdown","ccdf9240":"markdown","2792f9da":"markdown","0675d283":"markdown","d6f5df6a":"markdown"},"source":{"01ef9508":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms","6dc7d787":"input_size = [28, 28]\nnum_epochs = 10\nnum_classes = 10\nbatch_size = 100\nlearning_rate = 0.001","6e99d586":"traindata = torchvision.datasets.MNIST(root=\".\/data\", train = True, transform=transforms.ToTensor(), download = True)\ntestdata = torchvision.datasets.MNIST(root=\".\/data\", train=False, transform=transforms.ToTensor(), download = True)","dd9703a5":"print(traindata.train_data.size())\nprint(testdata.test_data.size())","ade616a6":"trainloader = torch.utils.data.DataLoader(dataset=traindata, batch_size=batch_size, shuffle=True)\ntestloader = torch.utils.data.DataLoader(dataset=testdata, batch_size=batch_size, shuffle=False)","56dede1e":"class ConvNet(nn.Module):\n    def __init__(self, num_classes):\n        super(ConvNet, self).__init__()\n        \n        self.conv1 = nn.Sequential(nn.Conv2d(1, 6, kernel_size=5, padding = 2),\n                                   nn.BatchNorm2d(6),\n                                   nn.ReLU(),\n                                   nn.MaxPool2d(kernel_size=2, stride=2))\n        \n        self.conv2 = nn.Sequential(nn.Conv2d(6, 16, kernel_size=3, padding = 2),\n                                   nn.BatchNorm2d(16),\n                                   nn.ReLU(),\n                                   nn.MaxPool2d(kernel_size=2, stride=2))\n        self.conv3 = nn.Sequential(nn.Conv2d(16, 32, kernel_size=3, padding = 1),\n                                   nn.BatchNorm2d(32),\n                                   nn.ReLU(),\n                                   nn.MaxPool2d(kernel_size=2, stride = 2))\n        self.output = nn.Linear(4 * 4 * 32, num_classes)\n        \n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.conv2(out)\n        out = self.conv3(out)\n        out = out.reshape(-1, 4 * 4 * 32)\n        out = self.output(out)\n        return out\n\nmodel = ConvNet(10)","27a88dd0":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)","86e9ae22":"for epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(trainloader):\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if (i + 1) % 200 == 0:\n            print ('Epoch [{}\/{}], Step [{}\/{}], Loss: {:.4f}' \n                   .format(epoch+1, num_epochs, i+1, len(trainloader), loss.item()))","35c1f5d2":"with torch.no_grad():\n    correct = 0\n    total = 0\n    for i, (image, labels) in enumerate(testloader):\n        outputs = model(image)\n        _, predicted = torch.max(outputs.data, 1)\n        correct += (predicted == labels).sum().item()\n        total = labels.size(0)\n        \nprint(\"Prediction accuracy of the above model is: {}\".format(float(correct) \/ float(total)))\n        ","b73e4914":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms","0b06236a":"num_epochs = 2\nlearning_rate = 0.001","badba1f1":"transform = transforms.Compose([transforms.Pad(4), transforms.RandomHorizontalFlip(), transforms.RandomCrop(32), transforms.ToTensor()])","a36b7a61":"# Download the CIFAR 10 dataset\ntrain_data = torchvision.datasets.CIFAR10(root=\".\/data\", train=True, transform=transform, download=True)\ntest_data = torchvision.datasets.CIFAR10(root='.\/data', train=False, transform=transforms.ToTensor())","13df7e34":"trainloader = torch.utils.data.DataLoader(dataset=train_data, shuffle=True, batch_size=100)\ntestloader = torch.utils.data.DataLoader(dataset=test_data, shuffle=False, batch_size=100)","b68007f2":"# Please note that the commented print statements were just to help figure out the dimensions properly. Remove the comment tag from the \n# print statements in order to see the actual dimensions of the tensors.\n\n\n\ndef conv3x3(in_channels, out_channels, stride = 1):\n    return nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride=stride, padding=1, bias=False)\n\nclass ResidualBlock(nn.Module):\n    \"\"\"This is the residual block class which will contain one block with the skip connections. Please keep in\n    mind the dimensions of the tensors.\n    Objects of this class will be called by the main ResNet class while initiating the network\"\"\"\n    \n    def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = conv3x3(in_channels, out_channels, stride) # Stride can be one or two. If one, downsampling is not done\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(out_channels, out_channels) # The stride is one irrespective of anything. No downsampling here.\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.downsample = downsample # The downsample layer as decided in the ResNet class\n        \n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n#         print(self.conv1)\n        out = self.bn1(out)\n        out = self.relu(out)\n#         print(out.shape)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        if self.downsample:\n#             print(\"Downsampling Done\")\n#             print(self.downsample)\n            residual = self.downsample(x)\n#         print(out.shape, \"\\t\", residual.shape)\n        out += residual # Adding the residual tensor to the main tensor\n        out = self.relu(out)\n        return out\n    \nclass ResNet(nn.Module):\n    def __init__(self, block, layers, num_classes = 10):\n        super(ResNet, self).__init__()\n        self.in_channels = 16\n        self.conv = conv3x3(3, 16)\n        self.bn = nn.BatchNorm2d(16)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self.make_layer(block, 16, layers[0]) # Residual Layer 1 is constructed\n        self.layer2 = self.make_layer(block, 32, layers[0], 2) # Residual layer 2 with 32 channels and stride 2 is constructed. Downsampling happens because of the stride\n        self.layer3 = self.make_layer(block, 64, layers[1], 2) # Residual layer 3 with 64 channels and stride 2 is constructed. Downsampling happens.\n        self.avg_pool = nn.AvgPool2d(8)\n        self.fc = nn.Linear(64, num_classes)\n        \n    def make_layer(self, block, out_channels, blocks, stride = 1):\n        downsample = None\n        if (stride != 1) or (self.in_channels != out_channels): # IF stride != 2 downsampling happens. \n            downsample = nn.Sequential(conv3x3(self.in_channels, out_channels, stride=stride), nn.BatchNorm2d(out_channels)) # Downsampling layer to downsample the residuals is constructed\n        layers = []\n        layers.append(block(self.in_channels, out_channels, stride, downsample)) # Residual blocks added with\/wiothout downsampling depending upon stride and channel sizes\n        self.in_channels = out_channels # The number of output channels of one block is the number of input blocks of the next\n        for i in range(1, blocks):\n            layers.append(block(out_channels, out_channels))\n        return nn.Sequential(* layers) # The layers list(with all the residual blocks are added to the sequence)\n        \n    def forward(self, x):\n        out = self.conv(x)\n        out = self.bn(out)\n        out = self.relu(out)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.avg_pool(out)\n        out = out.view(out.size(0), -1)\n        out = self.fc(out)\n        return out\n    \nmodel = ResNet(ResidualBlock, [2, 2, 2, 2])","c55c995f":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr = learning_rate)","9c6c73fc":"def update_lr(optimizer, lr):\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr","97341d53":"total_step = len(trainloader)\ncurr_lr = learning_rate","515e7028":"for epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(trainloader):\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if (i + 1) % 250 == 0:\n            print(\"Epoch: {}\/{};\\tStep: {}\/{};\\tLoss: {}\".format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n        \n    if (epoch + 1) % 4 == 0:\n        curr_lr = curr_lr \/ 3.\n        update_lr(optimizer, curr_lr)","f2fc150a":"model.eval()\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in test_loader:\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    print('Accuracy of the model on the test images: {} %'.format(100 * float(correct) \/ float(total)))","a179292a":"##### We will again start and implement a Residual Block network from scratch","2f75494d":"## A deeper ConvNet model with skip connections and residual blocks ","444379d3":"ResNets are advanced neyral network architectures with skip connections. ResNets were introduced because in 'Plain' neural networks, it was seen that incresing the depth of the neural network caused a saturation in the accuracy and then a decrease.\n\nResNets help avoid this problem in the following way. Suppose we add more layers to a network (with decent accuracy) which do not add anything of value to the network. Then there is a very high chance that these newly introduced networks would learn some spurious parameters and make the accuracy of the model fall. However, if we have skip\/residual connections, in which the network can easily learn identity functions for layers, it would be easy for the model to learn which parameters should be kept identical. Therefore the deeper model will perform at least as good as the original shallower model. Sometimes, they perform even better as they allow learning of more complex functions (due to deeper networks)\n\nThe above was a very simple\/unpolished attempt at explaining resnets. I would request the viewers to go through the following articles to learn more about residual networks\n\nA Blog post on ResNets: \nhttps:\/\/medium.com\/@14prakash\/understanding-and-implementing-architectures-of-resnet-and-resnext-for-state-of-the-art-image-cf51669e1624\n\n\nThe link to the paper:\nhttps:\/\/arxiv.org\/pdf\/1512.03385.pdf\n\nIn the below tutorial, you will learn how to implement a convnet with skip connections and residual blocks in PyTorch","4ddc038e":"### defining the network parameters\nThis network will have the following structure and hyperparameters:\nConv Layer 1 (6 channels) --> Max Pooling Layer 1 --> ReLu Activation 1 --> Conv Layer 2 (16 channels) --> Max Pooling Layer 2 --> ReLu Activation 2 --> Conv Layer 3(32 channels) --> Max Pooling Layer 3 --> Softmax Activation --> Output","9273450b":"### Image preprocessing modules","89147164":"### Evaluating the model\nSince we do not need the gradient calculation, we wont use it (with the torch.no_grad() method) in order to save memory","aa2602eb":"### Neural Net Code","59da190b":"## Defining the Model","e8a53232":"### Define Hyperparameters","ccdf9240":"## A simple ConvNet Model on MNIST","2792f9da":"# Foreword\nThis tutorial is part of a series of notebooks on PyTorch. It is primarily aimed towards people who are comfortable with deep learning concepts and Python in general but want to learn PyTorch. For the previous tutorials of this series, refer to these:\n\nTutorial 1: https:\/\/www.kaggle.com\/krishanudb\/pytorch-tutorial-for-beginners\n\nTutorial 2: https:\/\/www.kaggle.com\/krishanudb\/basic-computation-graph-using-pytorch\n\nThis will be a hands on tutorial for ConvNets on image data in PyTorch. Please note that we wont be going through the theory of ConvNets. It is assumed that you already know about ConvNets. This tutorial with teach you how to implement ConvNets in PyTorch","0675d283":"## The End\nThat brings us to the end of the third tutorial of the series. Next week, we will be back with a specific use case:\nUNet Model, which was specifically constructed for medical image segmentation and now used for segmentation tasks even outside the medical domain.\n\nWe will go through a step by step implementation of a UNet model in PyTorch and will use it for a specific image segmentation task","d6f5df6a":"## Importing the data and constructing DataLoaders"}}