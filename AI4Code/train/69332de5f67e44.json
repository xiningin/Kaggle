{"cell_type":{"8b6c1402":"code","0b32cfd8":"code","f6d67ecf":"code","13c7ddca":"code","0add99d6":"code","e8e7e832":"code","6f178531":"code","5ef33259":"code","e7792ce9":"code","7cc524aa":"code","9f39dc65":"code","f5ff31fe":"code","f5bb0aff":"code","737a2f26":"code","e722109a":"code","8158edff":"code","cd8023d3":"code","4c13cc73":"code","8aa45b83":"code","7db05323":"code","dfa84a57":"code","9012c7c3":"code","554e901a":"code","17b537bd":"code","6126986c":"code","183c4e8a":"code","35453f30":"code","17393332":"code","c6d77c4a":"code","5eede79c":"code","11adc7c9":"code","51e94d6a":"code","07dfffe8":"markdown","21b0b92a":"markdown","ffbf7e9f":"markdown","f8fd3078":"markdown","3bdfe658":"markdown","34f0cfb9":"markdown","87305f0c":"markdown","2d916757":"markdown"},"source":{"8b6c1402":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\n\n\n%matplotlib inline\n\nsns.set_style()\n\ncancer = load_breast_cancer()\n\nprint(cancer.DESCR) # Estat\u00edsticas","0b32cfd8":"cancer['feature_names']","f6d67ecf":"cancerdf = pd.DataFrame(cancer['data'], \n                        columns=cancer['feature_names'])\n\ncancerdf['target'] = cancer['target'].astype(float)\ncancerdf","13c7ddca":"cancerdf.describe().transpose().to_csv('stats.csv', float_format='%.2f')\ncancerdf.describe().transpose()","0add99d6":"X, y = cancerdf[cancer['feature_names']], cancerdf['target']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.33)","e8e7e832":"cols = ['params',\n        'split0_test_Recall',\n        'split1_test_Recall',\n        'split2_test_Recall',\n        'split3_test_Recall',\n        'split4_test_Recall',\n        'mean_test_Recall',\n        'std_test_Recall',\n        'rank_test_Recall',\n        'split0_test_Accuracy',\n        'split1_test_Accuracy',\n        'split2_test_Accuracy',\n        'split3_test_Accuracy',\n        'split4_test_Accuracy',\n        'mean_test_Accuracy',\n        'std_test_Accuracy',\n        'rank_test_Accuracy']\n\nscoring = {'Recall': 'recall', 'Accuracy': 'accuracy'}","6f178531":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier as KNC\n\n\nclf = KNC().fit(X_train, y_train)\ngrid_values = {'n_neighbors': np.arange(1, 11, 1)}\nknn_gs = GridSearchCV(clf, param_grid=grid_values, \n                  scoring=scoring, cv=5,\n                  refit='Recall')\nknn_gs.fit(X_train, y_train)\nresults = pd.DataFrame(knn_gs.cv_results_)\nresults[cols]","5ef33259":"print('Best parameter: ', knn_gs.best_params_)\nprint('Recall score for best parameter: ', knn_gs.best_score_)\n\nbest_acc = results[results['params'] == knn_gs.best_params_]['mean_test_Accuracy'].values[0]\nprint('Accuracy score for best parameter: ', best_acc)\n\nrecall_train_scores = {'KNN': knn_gs.best_score_}\naccuracy_train_scores = {'KNN': best_acc}","e7792ce9":"plt.figure()\n\nrecall_scores_mean = results['mean_test_Recall']\nrecall_scores_std = results['std_test_Recall']\naccuracy_scores_mean = results['mean_test_Accuracy']\naccuracy_scores_std = results['std_test_Accuracy']\nparam_name = list(grid_values.keys())[0]\nparam_range = list(grid_values.values())[0]\n\nplt.title('Validation Curve')\nplt.xlabel(f'{param_name}')\nplt.ylabel('Score')\nplt.ylim(0.8, 1)\nlw = 2\n\nplt.plot(param_range, recall_scores_mean, label='Recall',\n            color='darkorange', lw=lw)\n\nplt.fill_between(param_range, recall_scores_mean - recall_scores_std,\n                recall_scores_mean + recall_scores_std, alpha=0.2,\n                color='darkorange', lw=lw)\n\nplt.plot(param_range, accuracy_scores_mean, label='Accuracy',\n            color='navy', lw=lw)\n\nplt.fill_between(param_range, accuracy_scores_mean - accuracy_scores_std,\n                accuracy_scores_mean + accuracy_scores_std, alpha=0.2,\n                color='navy', lw=lw)\n\nplt.legend(loc='lower left');\nplt.show();","7cc524aa":"from sklearn.metrics import recall_score, accuracy_score\n\n\ny_predicted = knn_gs.predict(X_test)\n\nrecall = recall_score(y_test, y_predicted)\nacc = accuracy_score(y_test, y_predicted)\n\nprint('Test set recall score: ', recall)\nprint('Test set accuracy score: ', acc)\n\nrecall_test_scores = {'KNN': recall}\naccuracy_test_scores = {'KNN': acc}","9f39dc65":"from sklearn.naive_bayes import GaussianNB\n\n\nnb_clf = GaussianNB().fit(X_train, y_train)\ny_predicted = nb_clf.predict(X_test)\n\nrecall = recall_score(y_test, y_predicted)\nacc = accuracy_score(y_test, y_predicted)\n\nrecall_train = recall_score(y_train, clf.predict(X_train))\nacc_train = accuracy_score(y_train, clf.predict(X_train))\n\nprint('Train set recall score: ', recall_train)\nprint('Train set accuracy score: ', acc_train)\n\nprint('Test set recall score: ', recall)\nprint('Test set accuracy score: ', acc)\n\nrecall_test_scores['Na\u00efve Bayes'] = recall\naccuracy_test_scores['Na\u00efve Bayes'] = acc\n\nrecall_train_scores['Na\u00efve Bayes'] = recall_train\naccuracy_train_scores['Na\u00efve Bayes'] = acc_train","f5ff31fe":"from sklearn.tree import DecisionTreeClassifier as DTC\n\n\nclf = DTC(random_state=0).fit(X_train, y_train)\ngrid_values = {'max_depth': np.arange(1, 6, 1),\n               'min_samples_leaf': np.arange(7, 16, 1)}\ntree_gs = GridSearchCV(clf, param_grid=grid_values, \n                       scoring=scoring, cv=5,\n                       refit='Recall')\ntree_gs.fit(X_train, y_train)\nresults = pd.DataFrame(tree_gs.cv_results_)\nresults[cols].head()","f5bb0aff":"print('Best parameter: ', tree_gs.best_params_)\nprint('Recall score for best parameter: ', tree_gs.best_score_)\n\nbest_acc = results[results['params'] == tree_gs.best_params_]['mean_test_Accuracy'].values[0]\nprint('Accuracy score for best parameter: ', best_acc)\n\nrecall_train_scores['Decision Tree'] = tree_gs.best_score_\naccuracy_train_scores['Decision Tree'] = best_acc","737a2f26":"import graphviz\nfrom sklearn.tree import export_graphviz\n\n\nexport_graphviz(tree_gs.best_estimator_, \n                out_file=\"tree.dot\", \n                feature_names=cancer.feature_names, \n                class_names= cancer.target_names, \n                filled = True, impurity = False)\n\nwith open(\"tree.dot\") as f:\n    dot_graph = f.read()\n    \ngraphviz.Source(dot_graph)","e722109a":"y_predicted = tree_gs.predict(X_test)\n\nrecall = recall_score(y_test, y_predicted)\nacc = accuracy_score(y_test, y_predicted)\n\nprint('Test set recall score: ', recall)\nprint('Test set accuracy score: ', acc)\n\nrecall_test_scores['Decision Tree'] = recall\naccuracy_test_scores['Decision Tree'] = acc","8158edff":"from sklearn.neural_network import MLPClassifier as MLPC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\n\nhidden_layer_range = [(100), (100, 100), (100, 100, 100)]\n\nclf = MLPC(random_state=0, max_iter=1000)\nscaler = StandardScaler()\npipe = Pipeline(steps=[('scaler', scaler), ('clf', clf)]) \n        \ngrid_values = {'clf__hidden_layer_sizes': hidden_layer_range,\n               'clf__activation': ['identity', 'logistic', 'tanh', 'relu'],\n               'clf__solver': ['lbfgs', 'sgd', 'adam'],\n               'clf__alpha': [0.0001, 0.001, 0.01, 0.1, 1, 5]}\n\nmlp_gs = GridSearchCV(pipe, param_grid=grid_values, \n                      scoring=scoring, cv=5,\n                      refit='Recall',\n                      n_jobs=-1)\nmlp_gs.fit(X_train, y_train)\nresults = pd.DataFrame(mlp_gs.cv_results_)\nresults[cols].head()","cd8023d3":"print('Best parameter: ', mlp_gs.best_params_)\nprint('Recall score for best parameter: ', mlp_gs.best_score_)\n\nbest_acc = results[results['params'] == mlp_gs.best_params_]['mean_test_Accuracy'].values[0]\nprint('Accuracy score for best parameter: ', best_acc)","4c13cc73":"mlp_gs = GridSearchCV(pipe, param_grid=grid_values, \n                      scoring=scoring, cv=5,\n                      refit='Accuracy',\n                      n_jobs=-1)\nmlp_gs.fit(X_train, y_train)\nresults = pd.DataFrame(mlp_gs.cv_results_)\nresults[cols].head()","8aa45b83":"print('Best parameter: ', mlp_gs.best_params_)\nprint('Accuracy score for best parameter: ', mlp_gs.best_score_)\n\nbest_rec = results[results['params'] == mlp_gs.best_params_]['mean_test_Recall'].values[0]\nprint('Recall score for best parameter: ', best_rec)\n\nrecall_train_scores['MLP'] = best_rec\naccuracy_train_scores['MLP'] = mlp_gs.best_score_","7db05323":"y_predicted = mlp_gs.predict(X_test)\n\nrecall = recall_score(y_test, y_predicted)\nacc = accuracy_score(y_test, y_predicted)\n\nprint('Test set recall score: ', recall)\nprint('Test set accuracy score: ', acc)\n\nrecall_test_scores['MLP'] = recall\naccuracy_test_scores['MLP'] = acc","dfa84a57":"from sklearn.svm import SVC\n\n\nscaler = StandardScaler()\nclf = SVC(random_state=0)\npipe = Pipeline(steps=[('scaler', scaler), ('clf', clf)])\n\ngrid_values = {'clf__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n               'clf__degree': np.arange(1, 5),\n               'clf__gamma': ['scale', 0.0001, 0.001, 0.01, 0.1, 1],\n               'clf__C': [0.01, 0.1, 1, 10, 100, 200]}\n\nsvm_gs = GridSearchCV(pipe, param_grid=grid_values, \n                      scoring=scoring, cv=5,\n                      refit='Recall')\n\nsvm_gs.fit(X_train, y_train)\nresults = pd.DataFrame(svm_gs.cv_results_)\nresults[cols].head()","9012c7c3":"print('Best parameter: ', svm_gs.best_params_)\nprint('Recall score for best parameter: ', svm_gs.best_score_)\n\nbest_acc = results[results['params'] == svm_gs.best_params_]['mean_test_Accuracy'].values[0]\nprint('Accuracy score for best parameter: ', best_acc)","554e901a":"svm_gs = GridSearchCV(pipe, param_grid=grid_values, \n                      scoring=scoring, cv=5,\n                      refit='Accuracy')\n\nsvm_gs.fit(X_train, y_train)\nresults = pd.DataFrame(svm_gs.cv_results_)\nresults[cols].head()","17b537bd":"print('Best parameter: ', svm_gs.best_params_)\nprint('Accuracy score for best parameter: ', svm_gs.best_score_)\n\nbest_rec = results[results['params'] == svm_gs.best_params_]['mean_test_Recall'].values[0]\nprint('Recall score for best parameter: ', best_rec)\n\nrecall_train_scores['SVM'] = best_rec\naccuracy_train_scores['SVM'] = svm_gs.best_score_","6126986c":"y_predicted = svm_gs.predict(X_test)\n\nrecall = recall_score(y_test, y_predicted)\nacc = accuracy_score(y_test, y_predicted)\n\nprint('Test set recall score: ', recall)\nprint('Test set accuracy score: ', acc)\n\nrecall_test_scores['SVM'] = recall\naccuracy_test_scores['SVM'] = acc","183c4e8a":"recall_train_scores","35453f30":"accuracy_train_scores","17393332":"recall_test_scores","c6d77c4a":"accuracy_test_scores","5eede79c":"scores_df = pd.DataFrame(columns=['Classifier', 'Metric-Partition', 'Score'])\nscores_df","11adc7c9":"for classifier in recall_train_scores.keys():\n    scores_df = scores_df.append({'Classifier': classifier, \n                                  'Metric-Partition': 'Recall-Train', \n                                  'Score': recall_train_scores[classifier]}, ignore_index=True)\n    scores_df = scores_df.append({'Classifier': classifier, \n                                  'Metric-Partition': 'Accuracy-Train', \n                                  'Score': accuracy_train_scores[classifier]}, ignore_index=True)\n    scores_df = scores_df.append({'Classifier': classifier, \n                                  'Metric-Partition': 'Recall-Test', \n                                  'Score': recall_test_scores[classifier]}, ignore_index=True)\n    scores_df = scores_df.append({'Classifier': classifier, \n                                  'Metric-Partition': 'Accuracy-Test', \n                                  'Score': accuracy_test_scores[classifier]}, ignore_index=True)\n    \nscores_df","51e94d6a":"sns.catplot(x='Classifier', \n            y='Score', \n            hue='Metric-Partition', \n            data=scores_df, \n            kind='bar',\n            aspect=2)\nplt.ylim(0.85,1)\nsns.despine()\nplt.show()","07dfffe8":"## Decision-Tree","21b0b92a":"O Classificador Na\u00efve Bayes n\u00e3o possui par\u00e2metros especiais para controle da complexidade da curva, portanto n\u00e3o faremos a etapa de valida\u00e7\u00e3o.","ffbf7e9f":"## K-NN","f8fd3078":"Como pode-se observar, ao escolher `recall` como m\u00e9trica a otimizar, sacrifica-se demais a acur\u00e1cia. Portanto, a m\u00e9trica de otimiza\u00e7\u00e3o ser\u00e1 trocada para `accuracy` para o Multi-Layer-Perceptron.","3bdfe658":"## Support Vector Machine","34f0cfb9":"# Compara\u00e7\u00e3o de classificadores no dataset Breast Cancer Winsconsin\n\nTrabalho da disciplina de Intelig\u00eancia Artificial do meu curso de Engenharia da Computa\u00e7\u00e3o.","87305f0c":"## MLP","2d916757":"## Na\u00efve Bayes"}}