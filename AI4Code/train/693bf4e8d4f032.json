{"cell_type":{"02c98ae4":"code","031c3ef2":"code","53b9c6f0":"code","84468168":"code","d6a48106":"code","802276f1":"code","1cceabc3":"code","7f7feb9b":"code","94050b02":"markdown","c04bf4fc":"markdown","f7ce6ad1":"markdown","bb057cd6":"markdown","85dfe42c":"markdown","4ffbe327":"markdown"},"source":{"02c98ae4":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nfrom pandas.plotting import scatter_matrix\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\n\ndata = pd.read_csv('..\/input\/resume-dataset\/UpdatedResumeDataSet.csv' ,encoding='utf-8')\n\n# Inserting a blank column to store cleaned resume\ndata['cleaned_resume'] = ''\ndata.head()","031c3ef2":"print(\"Displaying the distinct categories of resume -\")\nprint(data['Category'].unique())","53b9c6f0":"import seaborn as sns\nplt.figure(figsize=(15,15))\nplt.xticks(rotation=90)\nsns.countplot(y=\"Category\", data=data)","84468168":"import re\ndef cleanResume(resumeText):\n    resumeText = re.sub('http\\S+\\s*', ' ', resumeText)  # remove URLs\n    resumeText = re.sub('RT|cc', ' ', resumeText)  # remove RT and cc\n    resumeText = re.sub('#\\S+', '', resumeText)  # remove hashtags\n    resumeText = re.sub('@\\S+', '  ', resumeText)  # remove mentions\n    resumeText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-.\/:;<=>?@[\\]^_`{|}~\"\"\"), ' ', resumeText)  # remove punctuations\n    resumeText = re.sub(r'[^\\x00-\\x7f]',r' ', resumeText) \n    resumeText = re.sub('\\s+', ' ', resumeText)  # remove extra whitespace\n    return resumeText\n    \ndata['cleaned_resume'] = data.Resume.apply(lambda x: cleanResume(x))\ndata.head()","d6a48106":"import nltk\nfrom nltk.corpus import stopwords\nimport string\nfrom wordcloud import WordCloud\n\noneSetOfStopWords = set(stopwords.words('english')+['``',\"''\"])\ntotalWords =[]\nSentences = data['Resume'].values\ncleanedSentences = \"\"\nfor i in range(0,160):\n    cleanedText = cleanResume(Sentences[i])\n    cleanedSentences += cleanedText\n    requiredWords = nltk.word_tokenize(cleanedText)\n    for word in requiredWords:\n        if word not in oneSetOfStopWords and word not in string.punctuation:\n            totalWords.append(word)\n    \nwordfreqdist = nltk.FreqDist(totalWords)\nmostcommon = wordfreqdist.most_common(50)\n\nwc = WordCloud().generate(cleanedSentences)\nplt.figure(figsize=(15,15))\nplt.imshow(wc, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","802276f1":"from sklearn.preprocessing import LabelEncoder\n\nvar_mod = ['Category']\nle = LabelEncoder()\nfor i in var_mod:\n    data[i] = le.fit_transform(data[i])\n    \ndata.head()","1cceabc3":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom scipy.sparse import hstack\n\nrequiredText = data['cleaned_resume'].values\nrequiredTarget = data['Category'].values\n\nword_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    stop_words='english',\n    max_features=1500)\nword_vectorizer.fit(requiredText)\nWordFeatures = word_vectorizer.transform(requiredText)\n\nX_train,X_test,y_train,y_test = train_test_split(WordFeatures,requiredTarget,random_state=0, test_size=0.3)","7f7feb9b":"clf = OneVsRestClassifier(KNeighborsClassifier())\nclf.fit(X_train, y_train)\nprediction = clf.predict(X_test)\nprint('Accuracy of KNeighbors Classifier on training set: {:.2f}'.format(clf.score(X_train, y_train)))\nprint('Accuracy of KNeighbors Classifier on test set: {:.2f}'.format(clf.score(X_test, y_test)))\n\nprint(\"\\n Classification report for classifier %s:\\n%s\\n\" % (clf, metrics.classification_report(y_test, prediction)))","94050b02":"**Plotting a wordcloud**","c04bf4fc":"**Training the model and displaying the results**","f7ce6ad1":"**Cleaning the resume column**","bb057cd6":"**Categories of resume present**","85dfe42c":"**Encoding the column \"Category\"**","4ffbe327":"**Vectorizing and splitting the dataset**"}}