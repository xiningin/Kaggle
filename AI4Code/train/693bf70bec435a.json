{"cell_type":{"0dd7fc18":"code","8494ea5c":"code","7bca28c2":"code","2d94f560":"code","ee40da6a":"code","96277ea3":"code","ae38d2f0":"code","b21c0bc2":"code","487235f9":"code","b6943fbc":"code","41fce621":"code","facb09e6":"code","a51b6f56":"code","3c08093d":"code","5a9688f5":"code","477633f4":"code","387d741c":"code","e71420a6":"code","5a45eb0b":"code","c3460ab6":"code","32e13296":"code","38c4fc0c":"code","0e444748":"code","d5faebf8":"markdown","f0f8c987":"markdown","6733d23c":"markdown","50b57625":"markdown","b31085e1":"markdown","46910964":"markdown","12cf8e24":"markdown","da995060":"markdown","01ca6f81":"markdown"},"source":{"0dd7fc18":"!pip --quiet install ..\/input\/treelite\/treelite-0.93-py3-none-manylinux2010_x86_64.whl","8494ea5c":"!pip --quiet install ..\/input\/treelite\/treelite_runtime-0.93-py3-none-manylinux2010_x86_64.whl","7bca28c2":"import numpy as np\nimport pandas as pd\n\nimport os, sys\nimport gc\nimport math\nimport random\nimport pathlib\nfrom tqdm import tqdm\nfrom typing import List, NoReturn, Union, Tuple, Optional, Text, Generic, Callable, Dict\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, QuantileTransformer\nfrom sklearn.decomposition import PCA\nfrom sklearn import linear_model\nimport operator\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom tqdm import tqdm\n\n# treelite\nimport treelite\nimport treelite_runtime \n\n# visualize\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nimport seaborn as sns\nfrom matplotlib_venn import venn2\nfrom matplotlib import pyplot\nfrom matplotlib.ticker import ScalarFormatter\nsns.set_context(\"talk\")\nstyle.use('fivethirtyeight')\npd.options.display.max_columns = None\n\nimport warnings\nwarnings.filterwarnings('ignore')","2d94f560":"SEED = 2021 # Happy new year!\n# INPUT_DIR = '..\/input\/jane-street-market-prediction\/'\nSTART_DATE = 85\nINPUT_DIR = '..\/input\/janestreet-save-as-feather\/'\nTRADING_THRESHOLD = 0.50 # 0 ~ 1: The smaller, the more aggressive","ee40da6a":"os.listdir(INPUT_DIR)","96277ea3":"%%time\n\ndef load_data(input_dir=INPUT_DIR):\n    train = pd.read_feather(pathlib.Path(input_dir + 'train.feather'))\n    features = pd.read_feather(pathlib.Path(input_dir + 'features.feather'))\n    example_test = pd.read_feather(pathlib.Path(input_dir + 'example_test.feather'))\n    ss = pd.read_feather(pathlib.Path(input_dir + 'example_sample_submission.feather'))\n    return train, features, example_test, ss\n\ntrain, features, example_test, ss = load_data(INPUT_DIR)","ae38d2f0":"print(train.shape)\ntrain.head()","b21c0bc2":"del features, example_test, ss\ngc.collect()","487235f9":"# reduce train\ntrain = train.query(f'date > {START_DATE}')","b6943fbc":"# remove weight = 0 for saving memory \noriginal_size = train.shape[0]\ntrain = train.query('weight > 0').reset_index(drop=True)\n\nprint('Train size reduced from {:,} to {:,}.'.format(original_size, train.shape[0]))","41fce621":"# feats\nfeats = train.columns[train.columns.str.startswith('feature')].values.tolist()\n\nprint('{} features used'.format(len(feats)))","facb09e6":"# target\ntrain['action'] = train['resp'] * train['weight']\n","a51b6f56":"%%time\n\n# same hyperparameters from https:\/\/www.kaggle.com\/hamditarek\/market-prediction-xgboost-with-gpu-fit-in-1min?scriptVersionId=48127254\nparams = {\n    'colsample_bytree': 0.72,                 \n    'learning_rate': 0.08,\n    'max_depth': 7,\n    'subsample': 0.8,\n    'seed': SEED,\n    'n_estimators': 480,\n#     'tree_method': 'gpu_hist' # Let's use GPU for a faster experiment\n}\nparams[\"objective\"] = 'binary:logistic'\nparams[\"eval_metric\"] = 'logloss'\ntrain['action'] = 1 * (train['action'] > 0) # binary classification\n# model = xgb.XGBClassifier(**params)\n# model.fit(train[feats], train['action'], verbose=100)","3c08093d":"# fit\ndtrain = xgb.DMatrix(train[feats].values, label=train['action'].values)\nbst = xgb.train(params, dtrain, 100, [(dtrain, 'train')])","5a9688f5":"# pass to treelite\nmodel = treelite.Model.from_xgboost(bst)","477633f4":"# generate shared library\ntoolchain = 'gcc'\nmodel.export_lib(toolchain=toolchain, libpath='.\/mymodel.so',\n                 params={'parallel_comp': 32}, verbose=True)","387d741c":"# predictor from treelite\npredictor = treelite_runtime.Predictor('.\/mymodel.so', verbose=True)","e71420a6":"# dummy data\nnp.random.seed(SEED)\nN = 10000\ndummy_data = np.random.rand(N, len(feats))","5a45eb0b":"%%time\n\n# normal xgb\npredicted_normal = bst.predict(xgb.DMatrix(dummy_data))","c3460ab6":"%%time\n\n# treelite\nbatch = treelite_runtime.Batch.from_npy2d(dummy_data)\npredicted_treelite = predictor.predict(batch)","32e13296":"predicted_normal == predicted_treelite","38c4fc0c":"import janestreet\nenv = janestreet.make_env() # initialize the environment\niter_test = env.iter_test() # an iterator which loops over the test set","0e444748":"for (test_df, pred_df) in tqdm(iter_test):\n    if test_df['weight'].item() > 0:\n        # inference with treelite\n        batch = treelite_runtime.Batch.from_npy2d(test_df[feats].values)\n        pred_df.action = (predictor.predict(batch) > TRADING_THRESHOLD).astype('int')\n    else:\n        pred_df.action = 0\n    env.predict(pred_df)","d5faebf8":"So, at least 2x (maybe 3x) faster with the same prediction results?","f0f8c987":"# Install treelite","6733d23c":"# Compile with Treelite\nSimply follow the tutorial: https:\/\/treelite.readthedocs.io\/en\/latest\/tutorials\/first.html","50b57625":"# Submit","b31085e1":"# Config","46910964":"<center><h2>Jane Street Market Prediction | fast inference by xgb with treelite | katsu1110 <\/h2><\/center><hr>\n\nFirst of all, sorry for those who have seen my previous kernel with very similar content. It was published unintentinally while I was experimenting, so I deleted the one.\n\nHere, the concept is the same: using [Treelite](https:\/\/treelite.readthedocs.io\/en\/latest\/index.html) for a faster inference with a GBDT model. \n\n![](https:\/\/treelite.readthedocs.io\/en\/latest\/_static\/benchmark_plot.svg)\n\nTreelite has been used in work or even kaggle when the inference time of a GBDT plays an important role in deployment. In my naive experiment, I can confirm that **using treelite boosts my XGB's inference speed 2-3x**\u3000(I noticed that how much faster varies everytime but consistently faster).\n\nSuch acceleration may be helpful for, say, model ensembles because the inference time in this competition is quite limited.\n\nThis notebook loads the feather data from [my another notebook](https:\/\/www.kaggle.com\/code1110\/janestreet-save-as-feather?scriptVersionId=47635784).\n\nThis notebook treats this task as a binary classification.\n","12cf8e24":"# Load data","da995060":"# Speed Test\nI use a dummy data to see how faster the inference with treelite can get.","01ca6f81":"# Model fitting\nFor now, let's use a simple XGBoost which is also used in the example in the Numerai Tournament."}}