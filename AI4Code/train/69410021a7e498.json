{"cell_type":{"4a77ae6a":"code","7bdd6b68":"code","9c0783ef":"code","a7ed16cb":"code","92b12332":"code","9f7fe6c9":"code","e16fd050":"code","2dabb676":"code","2a3a6ed3":"code","ec198e93":"code","34e35e40":"code","390edef9":"code","174dd81e":"code","ac834a04":"code","fd759513":"code","91467297":"code","f167b633":"code","ee83cbcc":"code","3fb987ce":"markdown","262cd915":"markdown","d3f3e39c":"markdown","57d405b8":"markdown","f7aaa62c":"markdown","8c13e42e":"markdown","19a2b9b1":"markdown","26bea49b":"markdown","ed7d7466":"markdown"},"source":{"4a77ae6a":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import Ridge, LinearRegression, Lasso\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\nfrom time import perf_counter\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom IPython.display import Markdown, display\n\ndef printmd(string):\n    # Print with Markdowns    \n    display(Markdown(string))\n\nimport warnings\nwarnings.filterwarnings(action='ignore')","7bdd6b68":"df = pd.read_csv('..\/input\/housesalesprediction\/kc_house_data.csv', index_col = 0)\ndf.head()","9c0783ef":"# Max price\ndf.price.max()","a7ed16cb":"df['price'].plot.box(by='price', color = '#ff8c8e')\nplt.title('Display all the price\\nInclusive outliers')\nplt.show()","92b12332":"df = df[df['price'] < 1000000]","9f7fe6c9":"fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n\ndf['price'].plot.hist(by='price',ax = axes[0], color = '#ff8c8e')\naxes[0].set_title('price\\'s histogram\\n', fontsize = 15)\n\ndf['price'].plot.box(ax = axes[1])\naxes[1].set_title('price\\'s Boxplot\\n', fontsize = 15)\n\nsns.violinplot(ax = axes[2], y = 'price', data = df, color = '#ff8c8e')\naxes[2].set_title('price\\'s distribution\\n(violinplot)', fontsize = 15)\n\nplt.show()","e16fd050":"printmd(f'### Number of rows in the dataset: {df.shape[0]}')","2dabb676":"# Add the column age\ndf['age'] = [2015 - x[0] if x[1]==0 else 2015 - x[1] for x in df[['yr_built','yr_renovated']].values]\n\n# Display the result\ndf[['yr_built','yr_renovated','age']].head()","2a3a6ed3":"# Select some columns, which will be used in the regression model\ncols = ['price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot',\n       'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n       'sqft_basement','sqft_living15', 'sqft_lot15', 'age']\n\ndf = df[cols]\ndf.head()","ec198e93":"# Visualization\nsns.pairplot(df[cols], \n             kind='reg', \n             plot_kws={'line_kws':{'color':'black'}, 'scatter_kws': {'alpha': 0.005}},\n             x_vars=['price'],\n             y_vars=cols[1:],\n             height = 4\n            )\nplt.show()","34e35e40":"def preprocessing(df):\n    df = df.copy()\n       \n    # Shuffle the data\n    df = df.sample(frac=1.0, random_state=0).reset_index(drop=True)\n    \n    X = df.drop('price', axis=1)\n    y = df['price']\n    \n    X = pd.DataFrame(X, index=X.index, columns=X.columns)\n    \n    return X, y\n\n# Preprocessing\nX,y = preprocessing(df)\n\n# Split into a training and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n\n# Scale the datasets\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Display the result\nX_train[:2], y_train[:2]","390edef9":"models = {\n    \"LinearRegression\":{\"model\":LinearRegression() },\n    \"Lasso\":{\"model\":Lasso() },\n    \"Ridge\":{\"model\":Ridge() },\n    \"DecisionTreeRegressor\":{\"model\":DecisionTreeRegressor() },\n    \"RandomForestRegressor\":{\"model\":RandomForestRegressor() },\n    \"MLPRegressor\":{\"model\":MLPRegressor() },\n    \"GradientBoostingRegressor\":{\"model\":GradientBoostingRegressor() },\n    \"AdaBoostRegressor\":{\"model\":AdaBoostRegressor() }\n}\n\n# Use the K-fold cross validation for each model\n# to get the mean validation accuracy and the mean training time\nk = 5\nfor name, m in models.items():\n    # Cross validation of the model\n    model = m['model']\n    result = cross_validate(model, X_train,y_train, cv = k, scoring='neg_mean_squared_error')\n    \n    # Mean accuracy and mean training time\n    result['test_score'] = result['test_score']\n    mean_RMSE = [(-x)**0.5 for x in result['test_score']] # Root Mean Square Error\n    mean_RMSE = sum(mean_RMSE)\/len(mean_RMSE)\n    mean_RMSE = int(mean_RMSE)\n    mean_fit_time = round( sum(result['fit_time']) \/ len(result['fit_time']), 4)\n    \n    # Add the result to the dictionary witht he models\n    m['mean_RMSE'] = mean_RMSE\n    m['Training time (sec)'] = mean_fit_time\n    \n    # Display the result\n    print(f\"{name:27} mean MSRE for {k}-fold CV: {mean_RMSE} - mean training time {mean_fit_time} sec\")","174dd81e":"# Create a DataFrame with the results\nmodels_result = []\n\nfor name, v in models.items():\n    lst = [name, v['mean_RMSE'],v['Training time (sec)']]\n    models_result.append(lst)\n\ndf_results = pd.DataFrame(models_result, \n                          columns = ['model','RMSE','Training time (sec)'])\ndf_results.sort_values(by='RMSE', ascending=True, inplace=True)\ndf_results.reset_index(inplace=True,drop=True)\ndf_results","ac834a04":"plt.figure(figsize = (15,5))\nsns.barplot(x = 'model', y = 'RMSE', data = df_results)\nplt.title(f'{k}-fold mean RMSE for each Model\\nSmaller is better', fontsize = 15)\n# plt.ylim(0.8,1.005)\nplt.xlabel('Model', fontsize=15)\nplt.ylabel('RMSE',fontsize=15)\nplt.xticks(rotation=90, fontsize=12)\nplt.show()","fd759513":"plt.figure(figsize = (15,5))\nsns.barplot(x = 'model', y = 'Training time (sec)', data = df_results)\nplt.title('Training time for each Model in sec\\nSmaller is better', fontsize = 15)\nplt.xticks(rotation=90, fontsize=12)\nplt.xlabel('Model', fontsize=15)\nplt.ylabel('Training time (sec)',fontsize=15)\nplt.show()","91467297":"# Get the model with the highest mean validation accuracy\nbest_model = df_results.iloc[0]\n\n# Fit the model\nmodel = models[best_model[0]]['model']\nmodel.fit(X_train,y_train)\n\n# Predict the labels with the data set\npred = model.predict(X_test)\n\nMSRE = mean_squared_error(y_test,pred)**0.5\nMSRE = int(MSRE)\n\n# Display the results\nprintmd(f'### Best Model: {best_model[0]} with a MSRE of {MSRE} on the test set')\nprintmd(f'### Trained in: {best_model[2]} sec')","f167b633":"# Concatenate the ratings of the test set\n# with the predictions of those ratings\npred_s = pd.Series(pred)\ny_test_s = y_test.reset_index(drop=True)\n\ndf_result = pd.concat([y_test_s,round(pred_s,0)], axis = 1)\ndf_result.columns = ['Real Rating', 'Predicted Rating']\ndf_result.head(10)","ee83cbcc":"df_result.plot.box()\nplt.title('Boxplot Real Rating VS Predicted Rating', fontsize = 12)\nplt.show()\n\ndf_result.plot.scatter(x='Real Rating', y='Predicted Rating', alpha = 0.1)\nplt.title('Scatterplot Real Rating VS Predicted Rating', fontsize = 12)\nplt.show()","3fb987ce":"# 1. Data Analysis & Data Processing<a class=\"anchor\" id=\"1\"><\/a><a class=\"anchor\" id=\"1\"><\/a>","262cd915":"### Add a column to the DataFrame: age\nThe data are from the year 2014 and 2015. We'll take 2015 to simplify the calculation.The age is whether the number of years since the house was built or if it has been\nrenovated, the number of years since the renovation.","d3f3e39c":"As we can see there are strong outliers. We'll filter them out and keep only the prices lower than 1.000.000.","57d405b8":"# 3. Prediction metrics of the best model using the test set<a class=\"anchor\" id=\"3\"><\/a>","f7aaa62c":"# 4. Visualization of the result<a class=\"anchor\" id=\"4\"><\/a>","8c13e42e":"# 2. Model comparison<a class=\"anchor\" id=\"2\"><\/a>","19a2b9b1":"# Predict House price\n## *Comparing 8 regression algorithms*\n\n![house](https:\/\/i.imgur.com\/HGsQXQS.png)\n\nThis dataset contains house sale prices for King County, which includes Seattle. It includes homes sold between May 2014 and May 2015.","26bea49b":"# Load the libraries","ed7d7466":"# Table of contents\n\n[<h3>1. Data Analysis & Data Processing<\/h3>](#1)\n\n[<h3>2. Model comparison<\/h3>](#2)\n\n[<h3>3. Prediction metrics of the best model using the test set<\/h3>](#3)\n\n[<h3>4. Visualization of the result<\/h3>](#4)\n"}}