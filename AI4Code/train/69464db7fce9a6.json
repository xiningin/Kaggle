{"cell_type":{"d01379ed":"code","c50b0a08":"code","e152c676":"code","04b9d684":"code","914f4df0":"code","cf779496":"code","4027ec69":"code","3b746b64":"code","99b313f2":"code","ac36579d":"code","ebcd4a11":"code","eb0bae58":"code","4ac37fab":"code","e389b67d":"code","6333817c":"code","4244de60":"code","d7def899":"code","2f32d414":"code","9761f5ee":"code","6d4900e4":"code","3eec588c":"code","cd2c1b6b":"code","0173df89":"code","63b74374":"markdown","dd476075":"markdown","5b839c5c":"markdown"},"source":{"d01379ed":"# Packages\nimport pandas as pd\nimport numpy as np\nimport os\n\n# Data\ndata_path = '..\/input\/vehicle-dataset-from-cardekho\/car data.csv'\ndata = pd.read_csv(data_path)","c50b0a08":"data.head()","e152c676":"data[['Fuel_Type']].head()","04b9d684":"data[['Car_Name']].head()","914f4df0":"print(len(data))","cf779496":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nscatplot = sns.scatterplot(x=data.Year, y=data.Selling_Price)","4027ec69":"data.groupby('Fuel_Type').count()","3b746b64":"catplot = sns.swarmplot(x=data.Fuel_Type, y=data.Selling_Price)","99b313f2":"_=sns.scatterplot(x=data.Kms_Driven, y=data.Selling_Price)","ac36579d":"_=sns.swarmplot(x=data.Seller_Type, y=data.Selling_Price)\nplt.figure()\n_=sns.swarmplot(x=data.Transmission, y=data.Selling_Price)","ebcd4a11":"from sklearn import linear_model\n\nx = data.Year.values\nx = x[:,np.newaxis]\ny = data.Selling_Price.values\n\nlm = linear_model.LinearRegression(fit_intercept = True)\n\nlm.fit(x,y)","eb0bae58":"y_pred = lm.predict(x)\nplt.plot(x, y_pred, color='red')\n\nplt.scatter(x,y)\nplt.xlabel('Year')\nplt.ylabel('Selling Price')\nplt.show()","4ac37fab":"print('Our m is %0.2f lahks\/year'%lm.coef_)\nprint('Our b is %0.2f lahks\/year'%lm.intercept_)","e389b67d":"m = lm.coef_\nb = lm.intercept_\nage = 5\nselling_price = m * age + b\nprint(selling_price)","6333817c":"# Transform Categorical variables into Numeric\ncar_data = data.copy()\ncar_data['TransmissionNumber'] = car_data.Transmission.replace({'Manual':1,'Automatic':0})","4244de60":"x2 = car_data[['Year', 'TransmissionNumber', 'Kms_Driven']]\n\nlm2 = linear_model.LinearRegression(fit_intercept = True, normalize = True)\n\nlm2.fit(x2, y)\n\ny_pred2 = lm2.predict(x)","d7def899":"print('Our linear model score was %0.4f'%lm.score(x[:,[0]], y))","2f32d414":"print('Our multiple linear model score was %0.4f'%lm2.score(x2,y))","9761f5ee":"# Categorical to numeric\ncar_data['Seller_TypeNumber'] = car_data.Seller_Type.replace({'Dealer':1,'Individual':0})\n\nx3 = car_data[['Year', 'TransmissionNumber','Seller_TypeNumber','Kms_Driven']].values\n\nlm3 = linear_model.LinearRegression(fit_intercept = True, normalize = True)\n\nlm3.fit(x3,y)\n\nprint('Our multiple linear score was %0.4f'%lm3.score(x3,y))\n","6d4900e4":"# Understand each Categorical Variable\ns = (data.dtypes == 'object')\ncat_cols = list(s[s].index)\n\nfor col in cat_cols:\n    des = data[col].describe()\n    print(des,'\\n\\n')","3eec588c":"# We introduce One-Hot encoding for Categorical variables: Car_Name, Fuel_Type, Seller_Type, and Transmission\n# Instead of converting each column into an Ordinal column, we convert them to Nominal. There may be an argument that\n# Car_Name could be turned into Ordinal since Ritz > Mitsubishi, but I lack the knowledge to make the necessary calls.\n\n# Load in sklearn\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\n\n# Separate target from predictors\ny = data.Selling_Price\nx4 = data.drop('Selling_Price', axis=1)\n\n# Apply one-hot encoder to each column with categorical data\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse = False)\nOH_cols_data = pd.DataFrame(OH_encoder.fit_transform(data[cat_cols]))\n\n# One-hot encoding removed index; put it back\nOH_cols_data.index = data.index\n\n# Remove categorical columns (will replace with one-hot encoding)\nnum_X_data = data.drop(cat_cols, axis=1)\n\n# Add one-hot encoded columns to numerical features\nOH_data = pd.concat([num_X_data, OH_cols_data], axis=1)\n\n# Build model\ny = OH_data.Selling_Price\nx4 = OH_data.drop('Selling_Price', axis=1)\n\nlm4 = linear_model.LinearRegression(fit_intercept = True, normalize = True)\n\nlm4.fit(x4,y)\n\nprint('Our multiple linear model with OH Encoding score was %0.4f'%lm4.score(x4,y))","cd2c1b6b":"# Check for patterns in data that were not captured with linear model\ny_pred4 = lm4.predict(x4)\n\nsns.regplot(y_pred4,[y-y_pred4])\nplt.xlabel('Fitted')\nplt.ylabel('Residuals')\nplt.show()","0173df89":"data_hp_pred = pd.DataFrame(data=y_pred4,columns=[\"Predictions\"])\ndata_hp_join = pd.concat([data, data_hp_pred], axis=1)\ndata_hp = data_hp_join[data_hp_join['Selling_Price'] > 10]\nprint(data_hp)","63b74374":"# Begin copying\n\nThis first segment belongs to [Aakrit Singhal](https:\/\/www.kaggle.com\/aakritsinghal). Thank you for the walk-through!","dd476075":"# END Copying - Begin new material\n\nI wanted to better understand how to take each of the categorical variables into consideration for an improved linear model.\n\nI noticed that each of the categorical variables were nominal as there was no indication of order. I learned in the Kaggle micro-course, [Intermediate Machine Learning](https:\/\/www.kaggle.com\/learn\/intermediate-machine-learning), that there are several ways to handle categoricals based on the type of information contained in them. I chose a OneHotEncoder for all since none, in my opinion, were ordinal. It would make sense to use a LabelEncoder if there were a variable that was ordinal.","5b839c5c":"This plot tells me that the model does well to predict the price of the car if the Selling_Price is between 0-12 lehks. Afterwards, the model becomes unreliable. This is curious."}}