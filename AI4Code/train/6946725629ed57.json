{"cell_type":{"eabc1925":"code","bd74ce99":"code","1819c986":"code","e68dc4f6":"code","e8b3f1c0":"code","6831d58d":"code","cf96fb9f":"code","faa28795":"code","cbf044e3":"code","d81fb2f5":"code","9fb154b9":"code","a2269bf8":"code","a1abc1c6":"code","35133884":"code","5a9327a6":"code","9784a2a2":"code","3bb4d00e":"code","0a08b832":"code","e9544ad5":"code","9d870d78":"code","36dc9560":"code","7a898fb8":"code","50b86020":"code","71a8bf7a":"code","9f5b0c9a":"code","0ad9cc56":"code","0a49a3e1":"code","295e01f9":"code","5b2c40e5":"code","6c559f25":"code","a6481a4c":"code","a667fa4a":"code","e0d2145e":"code","23d956a6":"code","d115d076":"code","3a339f5f":"code","da910696":"code","403d4a6c":"code","57644f7d":"code","266cc5f6":"markdown","30ac420b":"markdown","39107862":"markdown","4490bb0c":"markdown","ecd3d26c":"markdown","66db1950":"markdown","57e7e52d":"markdown","8726fff8":"markdown"},"source":{"eabc1925":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bd74ce99":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom time import time\nfrom scipy import stats\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import BayesianRidge\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import RandomizedSearchCV,cross_val_score, GridSearchCV\nfrom sklearn.metrics import accuracy_score, roc_auc_score,make_scorer, mean_squared_error\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import MinMaxScaler\n\n\n\n\n\ndf = pd.read_csv(\"..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv\")","1819c986":"df","e68dc4f6":"df.info()","e8b3f1c0":"df.describe()","6831d58d":"# Data looks cleans with no duplicates\ndf.drop_duplicates()","cf96fb9f":"df.isnull().sum().max()","faa28795":"df.corr()","cbf044e3":"df['DEATH_EVENT'].value_counts()","d81fb2f5":"sns.heatmap(df.corr())","9fb154b9":"# Strong correlation between smoking and sex\n\nplt.figure(figsize=(16, 6))\nheatmap = sns.heatmap(df.corr(), vmin=-1, vmax=1, annot=True, cmap='BrBG')","a2269bf8":"df.hist(figsize=(13,7),bins=20,layout=(5,3))\nplt.tight_layout()\nplt.show()","a1abc1c6":"from sklearn.model_selection import train_test_split\n\nX = df.drop('DEATH_EVENT', axis=1)\ny = df['DEATH_EVENT']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)","35133884":"X_train.shape","5a9327a6":"y_train.shape","9784a2a2":"scaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","3bb4d00e":"X_train_scaled.shape","0a08b832":"X_test_scaled.shape","e9544ad5":"X_train_scaled","9d870d78":"X_test_scaled","36dc9560":"lin_reg = LinearRegression()\nsvr_reg = SVR()\nrf_reg = RandomForestRegressor()\nbr_reg = BayesianRidge()\ndec_reg = DecisionTreeRegressor()","7a898fb8":"lin_reg.fit(X_train_scaled, y_train)\n\nsome_data = X_train_scaled[:5]\nsome_labels = y_train[:5]\nprint(\"Predictions:\", lin_reg.predict(some_data)) \nprint(\"Labels:\", list(some_labels))","50b86020":"df_predictions = lin_reg.predict(X_train_scaled)\nlin_mse = mean_squared_error(y_train, df_predictions)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse","71a8bf7a":"svr_reg.fit(X_train_scaled, y_train)\n\ndf_predictions = svr_reg.predict(X_train_scaled)\nlin_mse = mean_squared_error(y_train, df_predictions)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse","9f5b0c9a":"rf_reg.fit(X_train_scaled, y_train)\n\ndf_predictions = rf_reg.predict(X_train_scaled)\nlin_mse = mean_squared_error(y_train, df_predictions)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse","0ad9cc56":"br_reg.fit(X_train_scaled, y_train)\n\ndf_predictions = br_reg.predict(X_train_scaled)\nlin_mse = mean_squared_error(y_train, df_predictions)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse","0a49a3e1":"dec_reg.fit(X_train_scaled, y_train)\n\ndf_predictions = dec_reg.predict(X_train_scaled)\nlin_mse = mean_squared_error(y_train, df_predictions)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse","295e01f9":"scores = cross_val_score(rf_reg, X_train_scaled, y_train, scoring = \"neg_mean_squared_error\", cv=10)\nrf_rmse_scores = np.sqrt(-scores)","5b2c40e5":"def display_scores(scores):\n    print(\"Scores:\", scores)\n    print(\"Mean:\", scores.mean())\n    print(\"Standard Deviation:\", scores.std())\n\ndisplay_scores(rf_rmse_scores)","6c559f25":"lin_scores = cross_val_score(lin_reg, X_train_scaled, y_train, scoring = \"neg_mean_squared_error\", cv=10)\nlin_rmse_scores = np.sqrt(-lin_scores)\ndisplay_scores(lin_rmse_scores)","a6481a4c":"dec_scores = cross_val_score(dec_reg, X_train_scaled, y_train, scoring = \"neg_mean_squared_error\", cv=10)\ndec_rmse_scores = np.sqrt(-dec_scores)\ndisplay_scores(dec_rmse_scores)","a667fa4a":"br_scores = cross_val_score(br_reg, X_train_scaled, y_train, scoring = \"neg_mean_squared_error\", cv=10)\nbr_rmse_scores = np.sqrt(-br_scores)\ndisplay_scores(br_rmse_scores)","e0d2145e":"svr_scores = cross_val_score(svr_reg, X_train_scaled, y_train, scoring = \"neg_mean_squared_error\", cv=10)\nsvr_rmse_scores = np.sqrt(-svr_scores)\ndisplay_scores(svr_rmse_scores)","23d956a6":"param_grid = [\n    {'n_estimators': [3, 10, 30], 'max_features': [2,4,6,8]},\n    {'bootstrap': [False], 'n_estimators': [3,10], 'max_features': [2,3,4]}\n]\n\nrf_reg = RandomForestRegressor()\n\ngrid_search = GridSearchCV(rf_reg, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n\ngrid_search.fit(X_train_scaled, y_train)","d115d076":"grid_search.best_params_","3a339f5f":"grid_search.best_estimator_","da910696":"cvres = grid_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(np.sqrt(-mean_score), params)","403d4a6c":"final_model = grid_search.best_estimator_\n\nX_test_scaled = df.drop(\"DEATH_EVENT\", axis=1)\ny_test = df[\"DEATH_EVENT\"]\n\nfinal_predictions = final_model.predict(X_test_scaled)\n\nfinal_mse = mean_squared_error(y_test, final_predictions)\nfinal_rmse = np.sqrt(final_mse)","57644f7d":"final_rmse","266cc5f6":"# Model Picking","30ac420b":"# Train\/Test Split","39107862":"# Model Selection","4490bb0c":"# Model Tuning","ecd3d26c":"# Prepare for ML","66db1950":"# Import Data & Libraries","57e7e52d":"# Exploratory Data Analysis","8726fff8":"# Pick the Best Model"}}