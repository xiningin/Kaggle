{"cell_type":{"e629fe26":"code","dd1f4936":"code","1eed8481":"code","916339de":"code","0a5a2589":"code","181316be":"code","7a408966":"code","b3cbfe4f":"code","c9cc8e32":"code","50227f2a":"code","e41576fc":"code","9976af03":"code","c0121329":"code","f2cda5c8":"code","ff3a361b":"code","8a31f6d8":"code","7cde960d":"code","8ca45b47":"code","067ebd69":"code","f94c2f7d":"code","3376a82e":"code","92ee2364":"code","5af5df87":"code","b07964df":"code","10c97b79":"code","cf03e2d0":"code","d5c62ee3":"code","941e3480":"code","99c95aa7":"code","d7e1fd32":"code","63b00f53":"code","39a18192":"code","2e5022f5":"code","cef59c49":"code","95ce146a":"markdown","225f9cc4":"markdown","f4dfded9":"markdown","b8dc0635":"markdown","2b4a56b0":"markdown","5d1708dc":"markdown","4f67dabd":"markdown","020e1d4e":"markdown","cc22738c":"markdown"},"source":{"e629fe26":"from IPython.display import Image ","dd1f4936":"Image(\"..\/input\/kmeans\/kmeans.png\")","1eed8481":"from warnings import filterwarnings\nfilterwarnings(\"ignore\")\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport scipy as sp\nfrom sklearn.cluster import KMeans","916339de":"df = pd.read_csv(\"..\/input\/usarrests\/USArrests.csv\").copy()\ndf.head()","0a5a2589":"# Making Urban Names \u0130ndex\ndf.index = df.iloc[:,0]","181316be":"df= df.iloc[:,1:5]","7a408966":"del df.index.name","b3cbfe4f":"df.head()","c9cc8e32":"df.isnull().sum()","50227f2a":"df.info()","e41576fc":"df.describe().T","9976af03":"df.hist(bins=15,figsize=(10,10))","c0121329":"kmeans = KMeans(n_clusters=4)","f2cda5c8":"print(kmeans) # n_clusters: Cluster Numbers - n_init: Center Names(How many times will we fit?)","ff3a361b":"k_fit= kmeans.fit(df)","8a31f6d8":"k_fit.n_clusters","7cde960d":"# Centers of Clusters for each feature\nk_fit.cluster_centers_","8ca45b47":"# Which urban in whick class\nk_fit.labels_","067ebd69":"kmeans= KMeans(n_clusters=2)\nk_fit = kmeans.fit(df)","f94c2f7d":"clusters = k_fit.labels_","3376a82e":"plt.scatter(df.iloc[:,0],df.iloc[:,1],df.iloc[:,2],df.iloc[:,3],)","92ee2364":"plt.scatter(df.iloc[:,0],df.iloc[:,1],c=clusters,s=50,cmap=\"viridis\") # First 2 feature\ncenters = k_fit.cluster_centers_\nplt.scatter(centers[:,0],centers[:,1],c=\"black\",s = 200,alpha=0.5)","5af5df87":"from mpl_toolkits.mplot3d import Axes3D\n# !pip install --upgrade matplotlib\n# import mpl_toolkits","b07964df":"kmeans= KMeans(n_clusters=3)\nk_fit =kmeans.fit(df)\nclusters= k_fit.labels_\ncenters = kmeans.cluster_centers_","10c97b79":"plt.rcParams[\"figure.figsize\"] =(16,9)\nfig = plt.figure()\nax = Axes3D(fig)\nax.scatter(df.iloc[:,0],df.iloc[:,1],df.iloc[:,2])\nax.scatter(centers[:,0],centers[:,1],centers[:,2],c=\"black\",marker=\"*\",s = 1000);","cf03e2d0":"kmeans= KMeans(n_clusters=4)\nk_fit =kmeans.fit(df)\nclusters= k_fit.labels_","d5c62ee3":"pd.DataFrame({\"Urbans\": df.index,\"Clusters\": clusters})[:10]","941e3480":"## Adding to DF\ndf[\"Clusters\"] = clusters\ndf.head()","99c95aa7":"df.Clusters.unique()","d7e1fd32":"df[\"Clusters\"]=df[\"Clusters\"]+1","63b00f53":"df.head(10)","39a18192":"#!pip install yellowbrick\nfrom yellowbrick.cluster import KElbowVisualizer\nkmeans= KMeans()\nvisualizer = KElbowVisualizer(kmeans, k=(2,50)) # k: Number of cluster to be attempted\nvisualizer.fit(df)\nvisualizer.poof()","2e5022f5":"kmeans= KMeans(n_clusters=9)\nk_fit =kmeans.fit(df)\nclusters= k_fit.labels_","cef59c49":"pd.DataFrame({\"Urbans\": df.index,\"Clusters\": clusters})[:10]","95ce146a":"# Clusters and Observations","225f9cc4":"## ELBOW","f4dfded9":"## K-Means\n\nK-means is an unsupervised clustering algorithm designed to partition unlabelled data into a certain number (thats the \u201c K\u201d) of distinct groupings. In other words, k-means finds observations that share important characteristics and classifies them together into clusters. A good clustering solution is one that finds clusters such that the observations within each cluster are more similar than the clusters themselves.\n","b8dc0635":"## 3D Visualisation","2b4a56b0":"# Model","5d1708dc":"## Visualisation","4f67dabd":"There are countless examples of where this automated grouping of data can be extremely useful. For example, consider the case of creating an online advertising campaign for a brand new range of products being released to the market. While we could display a single generic advertisement to the entire population, a far better approach would be to divide the population into clusters of people who hold shared characteristics and interests displaying customised advertisements to each group. K-means is an algorithm that finds these groupings in big datasets where it is not feasible to be done by hand.","020e1d4e":"There is a cluster called \"0\". If we want to avoid it:","cc22738c":"# Optimization of Cluster Numbers - Finding Minimum Error - Model Tuning\n\nWe want high similarity(Max) inside clusters and low similarity interclusters(Min) to find omtimized sum of squared error(SSR)."}}