{"cell_type":{"e929ae59":"code","d0c52e8b":"code","9815ff66":"code","0f121542":"code","60662003":"code","30ae686a":"code","642a0bff":"code","48abb13e":"code","03cd22cf":"code","e880b902":"code","09f23b19":"code","7aac1f3e":"code","64e66881":"code","9183b79b":"code","771a91b2":"code","3fc73441":"code","232b1660":"code","0822254a":"code","8b0a4bbd":"code","69fd56cd":"code","38f8d9bc":"code","043f962b":"code","7d6e0209":"code","53407680":"code","e791fe72":"code","e658f8f7":"code","3887041c":"code","ce91c234":"code","0b1f3ca4":"code","c49ef8f0":"code","7d5c1318":"code","e8229cb6":"code","0543d4bf":"code","f23076a2":"code","8039716f":"code","515a0d41":"code","8be99559":"code","f5a039ab":"code","5f1816db":"code","1662bd4b":"code","aec3176c":"code","e8623c55":"code","285f6724":"code","7aebb651":"code","918c87e7":"code","9419fcf5":"code","488f7257":"code","3c476981":"code","8c62172e":"code","f46a9cab":"code","611e17bd":"code","d1384430":"code","ce7f8409":"code","2318cd6f":"code","8319593a":"code","a36d05d8":"code","86ece791":"code","2f6488d9":"code","80393a8a":"code","da84fae3":"code","f65b7523":"code","21cb2b29":"code","ddb84661":"code","daa1017e":"code","56d51b66":"code","7cd25c17":"code","b4977494":"code","f98b2c50":"code","80d48d7f":"code","409f90cb":"code","7ed80f65":"code","1ad002db":"code","2f27cc29":"code","9269c82e":"code","31e5d337":"code","1e8e7747":"code","916deec9":"code","3c9d488d":"code","6a408654":"code","c7e2846e":"code","3e76d00d":"code","f300928a":"code","1e917fc5":"code","8694b600":"code","3c674888":"code","d2f9f231":"code","8248350b":"code","932732c7":"code","1906fb61":"code","f9960651":"code","770c50cd":"code","a21e0692":"code","9c52881f":"code","1d9cf702":"code","e7fb1df8":"code","be50cabb":"code","ee459198":"markdown","43e28635":"markdown","0dd1b51c":"markdown","d58b51dd":"markdown","c1a06625":"markdown","abb4741e":"markdown","c4cc886f":"markdown","9ccca2ab":"markdown","61560700":"markdown","4361e6b5":"markdown","cea4ef0c":"markdown","4471b37e":"markdown","75090688":"markdown","f4720868":"markdown","4ac7544b":"markdown","5e423458":"markdown","500c4d3d":"markdown","fd3b0fa0":"markdown"},"source":{"e929ae59":"import numpy as np\nimport math\nimport re\nimport pandas as pd\nfrom bs4 import BeautifulSoup\nimport seaborn as sns\nimport spacy as sp\nimport string\nimport random\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nimport tensorflow_datasets as tfds\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode,iplot\nimport plotly.express as px\nfrom wordcloud import WordCloud\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split","d0c52e8b":"data = pd.read_csv('..\/input\/womens-ecommerce-clothing-reviews\/Womens Clothing E-Commerce Reviews.csv')","9815ff66":"data.head()","0f121542":"data.drop(['Unnamed: 0', 'Clothing ID'], axis = 1, inplace=True)","60662003":"data.head()","30ae686a":"data.info()","642a0bff":"sns.heatmap(data.isnull());","48abb13e":"data.isnull().sum(axis=0)","03cd22cf":"data.dropna(axis=0, inplace=True)","e880b902":"sns.heatmap(data.isnull());","09f23b19":"data = data.rename(columns = {'Review Text' : 'text', 'Recommended IND' : 'Recommended', 'Positive Feedback Count' : 'Feedback_Count',\n                          'Division Name' : 'Division', 'Department Name' : 'Department', 'Class Name' :'class'})","7aac1f3e":"data[~data.isnull()]","64e66881":"data.describe()","9183b79b":"correlations = data.corr()\nf, ax = plt.subplots(figsize = (10,10))\nsns.heatmap(correlations, annot=True)\ncorrelations.round(2);","771a91b2":"g1 = [go.Box(y=data.Rating,name=\"Rating\",marker=dict(color=\"rgba(0,102,102,0.9)\"),hoverinfo=\"name+y\")]\ng2 = [go.Box(y=data.Feedback_Count,name=\"Positive Feedback Count\",marker=dict(color=\"rgba(204,0,102,0.9)\"),hoverinfo=\"name+y\")]\nlayout1 = go.Layout(title=\"Positive Feedback Coun \/ Rating\",yaxis=dict(range=[0,13])) \nfig1 = go.Figure(data=g1+g2,layout=layout1)\niplot(fig1)","3fc73441":"fig2 = px.histogram(data,x='Recommended',color='Recommended',template='plotly_dark')\nfig2.show()","232b1660":"fig2 = px.histogram(data,x='Division',color='Division',template='plotly_dark')\nfig2.show()","0822254a":"fig2 = px.histogram(data,x='Rating',color='Rating',template='plotly_dark')\nfig2.show()","8b0a4bbd":"fig2 = px.histogram(data,x='Department',color='Department',template='plotly_dark')\nfig2.show()","69fd56cd":"fig2 = px.histogram(data,x='Feedback_Count',color='Feedback_Count',template='plotly_dark')\nfig2.show()","38f8d9bc":"fig2 = px.histogram(data,x='class',color='class',template='plotly_dark')\nfig2.show()","043f962b":"fig2 = px.histogram(data,x='Age',color='Age',template='plotly_dark')\nfig2.show()","7d6e0209":"data['Rating'] = data['Rating'].apply(lambda x: 1 if x >= 2 else 0) ","53407680":"posite = data[data['Rating'] == 1 ]\nnegative = data[data['Rating'] == 0]","e791fe72":"plt.rcParams['figure.figsize'] = (10, 10)\nplt.style.use('fast')\n\nwc = WordCloud(background_color = 'orange', width = 1500, height = 1500).generate(str(posite['text']))\nplt.title('Description Positive', fontsize = 15)\n\nplt.imshow(wc)\nplt.axis('off')\nplt.show()","e658f8f7":"plt.rcParams['figure.figsize'] = (10, 10)\nplt.style.use('fast')\n\nwc = WordCloud(background_color = 'orange', width = 1500, height = 1500).generate(str(negative['text']))\nplt.title('Description Negative', fontsize = 15)\n\nplt.imshow(wc)\nplt.axis('off')\nplt.show()","3887041c":"data = data.drop(['Age', 'Recommended', 'Feedback_Count', 'Division', 'Department', 'class'], axis = 1)","ce91c234":"data.head()","0b1f3ca4":"train, test = train_test_split(data, random_state = 0)","c49ef8f0":"print( train.shape, test.shape)","7d5c1318":"train.Rating.unique()","e8229cb6":"data = train","0543d4bf":"data.head()","f23076a2":"data.drop(['Title'], axis = 1, inplace=True)","8039716f":"data.head()","515a0d41":"X = data.iloc[:, 0].values","8be99559":"X","f5a039ab":"X.shape","5f1816db":"type(X)","1662bd4b":"y = data.iloc[:, 1].values\ny","aec3176c":"X, _, y, _ = train_test_split(X, y, test_size = 0.85, stratify = y)","e8623c55":"X.shape","285f6724":"y.shape","7aebb651":"unique, counts = np.unique(y, return_counts=True)\nunique, counts","918c87e7":"def clean_t(t):\n  t = BeautifulSoup(t, 'lxml').get_text()\n  t = re.sub(r\"@[A-Za-z0-9]+\", ' ', t)\n  t = re.sub(r\"https?:\/\/[A-Za-z0-9.\/]+\", ' ', t)\n  t = re.sub(r\"[^a-zA-Z.!?]\", ' ', t)\n  t = re.sub(r\" +\", ' ', t)\n  return t","9419fcf5":"text = \"@switchfoot http:\/\/twitpic.com\/2y1zl - Awww, that's a bummer.  2 You shoulda got David Carr of Third Day to do it. ;D\"","488f7257":"text = clean_t(text)\ntext","3c476981":"import spacy","8c62172e":"nlp = spacy.blank(\"en\")","f46a9cab":"nlp","611e17bd":"stop_words = sp.lang.en.STOP_WORDS","d1384430":"print(stop_words)","ce7f8409":"len(stop_words)","2318cd6f":"string.punctuation","8319593a":"def clean_t2(t):\n  tweet = t.lower()\n  document = nlp(t)\n\n  words = []\n  for token in document:\n    words.append(token.text)\n\n  words = [word for word in words if word not in stop_words and word not in string.punctuation]\n  words = ' '.join([str(element) for element in words])\n\n  return words","a36d05d8":"text2 = clean_t2(text)\ntext2","86ece791":"data_clean = [clean_t2(clean_t(t)) for t in X]","2f6488d9":"for _ in range(10):\n  print(data_clean[random.randint(0, len(data_clean) - 1)])","80393a8a":"data_labels = y","da84fae3":"data_labels[data_labels == 4] = 1","f65b7523":"data_labels","21cb2b29":"np.unique(data_labels)","ddb84661":"tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(data_clean, target_vocab_size=2**16)","daa1017e":"tokenizer.vocab_size","56d51b66":"print(tokenizer.subwords)","7cd25c17":"ids = tokenizer.encode('i am happy')\nids","b4977494":"data_inputs = [tokenizer.encode(sentence) for sentence in data_clean]","f98b2c50":"for _ in range(10):\n  print(data_inputs[random.randint(0, len(data_inputs) - 1)])","80d48d7f":"max_len = max([len(sentence) for sentence in data_inputs])\nmax_len","409f90cb":"data_inputs = tf.keras.preprocessing.sequence.pad_sequences(data_inputs,\n                                                            value = 0,\n                                                            padding = 'post',\n                                                            maxlen=max_len)","7ed80f65":"for _ in range(10):\n  print(data_inputs[random.randint(0, len(data_inputs) - 1)])","1ad002db":"train_inputs, test_inputs, train_labels, test_labels = train_test_split(data_inputs,\n                                                                        data_labels,\n                                                                        test_size=0.3,\n                                                                        stratify = data_labels)","2f27cc29":"train_inputs[0]","9269c82e":"train_inputs.shape","31e5d337":"train_labels.shape","1e8e7747":"test_inputs.shape","916deec9":"test_labels.shape","3c9d488d":"class DCNN(tf.keras.Model):\n\n  def __init__(self,\n               vocab_size,\n               emb_dim=128,\n               nb_filters=50,\n               ffn_units=512,\n               nb_classes=2,\n               dropout_rate=0.1,\n               training=True,\n               name=\"dcnn\"):\n    super(DCNN, self).__init__(name=name)\n    self.embedding = layers.Embedding(vocab_size, emb_dim)\n    self.bigram = layers.Conv1D(filters=nb_filters, kernel_size=2, padding='same', activation='relu')\n    self.trigram = layers.Conv1D(filters=nb_filters, kernel_size=3, padding='same', activation='relu')\n    self.fourgram = layers.Conv1D(filters=nb_filters, kernel_size=4, padding='same', activation='relu')\n    self.pool = layers.GlobalMaxPool1D()\n    \n#estrutura da rede neural\n    self.dense_1 = layers.Dense(units = ffn_units, activation = 'relu')\n    self.dropout = layers.Dropout(rate = dropout_rate)\n    if nb_classes == 2:\n      self.last_dense = layers.Dense(units = 1, activation = 'sigmoid')\n    else:\n      self.last_dense = layers.Dense(units = nb_classes, activation = 'softmax')\n\n  def call(self, inputs, training):\n    x = self.embedding(inputs)\n    x_1 = self.bigram(x)\n    x_1 = self.pool(x_1)\n    x_2 = self.trigram(x)\n    x_2 = self.pool(x_2)\n    x_3 = self.fourgram(x)\n    x_3 = self.pool(x_3)\n\n    merged = tf.concat([x_1, x_2, x_3], axis = -1)\n    merged = self.dense_1(merged)\n    merged = self.dropout(merged, training)\n    output = self.last_dense(merged)\n\n    return output","6a408654":"vocab_size = tokenizer.vocab_size\nvocab_size","c7e2846e":"emb_dim = 200\nnb_filters = 100\nffn_units = 256\nbatch_size = 64\nnb_classes = len(set(train_labels))\nnb_classes","3e76d00d":"dropout_rate = 0.2\nnb_epochs = 5  ","f300928a":"Dcnn = DCNN(vocab_size=vocab_size, emb_dim=emb_dim, nb_filters=nb_filters,\n            ffn_units=ffn_units, nb_classes=nb_classes, dropout_rate=dropout_rate)","1e917fc5":"if nb_classes == 2:\n  Dcnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nelse:\n  Dcnn.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","8694b600":"# Para salvar o arquivo quando fazemos o treinamento em grande escala;\n\n#checkpoint_path = \".\/\"\n#ckpt = tf.train.Checkpoint(Dcnn=Dcnn)\n#ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n#if ckpt_manager.latest_checkpoint:\n # ckpt.restore(ckpt_manager.latest_checkpoint)\n  #print('Latest checkpoint restored')","3c674888":"history = Dcnn.fit(train_inputs, train_labels,\n                   batch_size = batch_size,\n                   epochs = nb_epochs,\n                   verbose = 1,\n                   validation_split = 0.10)\n#ckpt_manager.save()","d2f9f231":"results = Dcnn.evaluate(test_inputs, test_labels, batch_size=batch_size)\nprint(results)","8248350b":"y_pred_test = Dcnn.predict(test_inputs)","932732c7":"y_pred_test","1906fb61":"y_pred_test = (y_pred_test > 0.5)","f9960651":"y_pred_test","770c50cd":"test_labels","a21e0692":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(test_labels, y_pred_test)\ncm","9c52881f":"sns.heatmap(cm, annot=True)","1d9cf702":"history.history.keys()","e7fb1df8":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss progress during training and validation')\nplt.xlabel('Epoch')\nplt.ylabel('Losses')\nplt.legend(['Training loss', 'Validation loss'])","be50cabb":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy progress during training and validation')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(['Training accuracy', 'Validation accuracy'])","ee459198":"* **Class Name: Categorical name of the product class name.**","43e28635":"# Analyzing","0dd1b51c":"# **Conclusion**\n\nInitially, at the beginning of the study I used the Recommended attribute, which has the values \u200b\u200b0 and 1, I imagined that if the person recommends there are positive comments, otherwise it will be negative, but the prediction of the algorithm based on this attribute in order to identify negative sentences was not very clonclusive .\n\nWith an unsatisfactory result from Recommended, I decided to use the Rating attribute in the database for the development of the algorithm, which has grades from 1 to 5, I used it as parameters if >= 2 will be positive otherwise it will be negative, the result was satisfactory as we can see, the hit level was more satisfactory.\n\nSuch a change was also noted in the word cloud.\n\nThe fact that the person recommends it or not does not mean that they made a negative or positive comment, they just didn't recommend it, it's just two options, do you recommend? not recommend? and ready, objectively!\n\nBut when it opens up the possibility for the customer to evaluate with grades, there is a more subjective side to the comments, \"feeling\", it makes the customer think more about how he or she felt about the product, if he was not satisfied or not with the product, as he cannot give a score of 0, he ends up giving a 1, which would be the minimum, and the fact of having to think about how he felt about the product seeks to express his feelings about the product through comments and why the note.","d58b51dd":"# Model building","c1a06625":"* **Positive Feedback Count: Positive Integer documenting the number of other customers who found this review positive.**","abb4741e":"# Training","c4cc886f":"# Import from Libraries","9ccca2ab":" * **Division Name: Categorical name of the product high level division.**","61560700":"* **Recommended IND: Binary variable stating where the customer recommends the product where 1 is recommended, 0 is not recommended.**","4361e6b5":"* **Department Name: Categorical name of the product department name.**","cea4ef0c":"# **Context**\n\nWelcome. This is a Women\u2019s Clothing E-Commerce dataset revolving around the reviews written by customers. Its nine supportive features offer a great environment to parse out the text through its multiple dimensions. Because this is real commercial data, it has been anonymized, and references to the company in the review text and body have been replaced with \u201cretailer\u201d.\n\n# **Content**\n\nThis dataset includes 23486 rows and 10 feature variables. Each row corresponds to a customer review, and includes the variables:\n\nClothing ID: Integer Categorical variable that refers to the specific piece being reviewed.\nAge: Positive Integer variable of the reviewers age.\nTitle: String variable for the title of the review.\nReview Text: String variable for the review body.\nRating: Positive Ordinal Integer variable for the product score granted by the customer from 1 Worst, to 5 Best.\nRecommended IND: Binary variable stating where the customer recommends the product where 1 is recommended, 0 is not recommended.\nPositive Feedback Count: Positive Integer documenting the number of other customers who found this review positive.\nDivision Name: Categorical name of the product high level division.\nDepartment Name: Categorical name of the product department name.\nClass Name: Categorical name of the product class name.\n\n# **Acknowledgements**\n\nAnonymous but real source\n\n# **Inspiration**\n\nI look forward to come quality NLP! There is also some great opportunities for feature engineering, and multivariate analysis.\n\n## Publications\n\nStatistical Analysis on E-Commerce Reviews, with Sentiment Classification using Bidirectional Recurrent Neural Network","4471b37e":"# Uploading files","75090688":"# Padding","f4720868":"* **Age: Positive Integer variable of the reviewers age.**","4ac7544b":"* **Rating: Positive Ordinal Integer variable for the product score granted by the customer from 1 Worst, to 5 Best.**","5e423458":"# Tokenization","500c4d3d":"# Model Evaluation","fd3b0fa0":"# Division of database into training and testing"}}