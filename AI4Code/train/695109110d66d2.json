{"cell_type":{"e0a7f3ea":"code","36d26418":"code","c08f8f24":"code","0738681b":"code","b775712e":"code","320e939d":"code","068c548f":"code","754fc042":"code","5d0d4366":"code","73688b5b":"code","709d7b55":"code","7d9a7434":"markdown","d7ad6654":"markdown","bf333d08":"markdown","13e4befb":"markdown","9f51d01c":"markdown","ffba9a3e":"markdown","1cdfba30":"markdown","44e89243":"markdown","23521fc1":"markdown","8b2f1fb2":"markdown","1e3c14a7":"markdown","b3065930":"markdown","a013be74":"markdown","8adfff3b":"markdown","28dcef58":"markdown","1986b05b":"markdown","61daea15":"markdown"},"source":{"e0a7f3ea":"import tensorflow as tf\nprint('Version of tensorflow :',tf.__version__)","36d26418":"from keras.layers import Input,Dense,Flatten\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.applications.vgg19 import VGG19,preprocess_input\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nimport numpy as np\nimport glob\nfrom matplotlib import pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore',category=FutureWarning)\nfrom datetime import datetime\nfrom keras.callbacks import ModelCheckpoint","c08f8f24":"# setting image size \nIMAGE_SIZE = [ 224 , 224 , 3 ]\n\n# Load the model \nvgg = VGG19( include_top = False,\n            input_shape = IMAGE_SIZE,\n            weights = 'imagenet')\n\n# Visualize the model\nvgg.summary()","0738681b":"for  layer in vgg.layers:\n    layer.trainable = False","b775712e":"# Flattened the last layer\nx = Flatten()(vgg.output)\n\n# Created a new layer as output\nprediction = Dense( 2 , activation = 'softmax' )(x)\n\n# Join it with the model\nmodel = Model( inputs = vgg.input , outputs = prediction )\n\n# Visualize the model again\nmodel.summary()","320e939d":"# defining adam\nadam=Adam()\n\n# compining the model\nmodel.compile( loss = 'categorical_crossentropy',\n              optimizer = adam,\n              metrics = ['accuracy'] )","068c548f":"# This will preprocces the data to make train data\n\ntrain_datagen = ImageDataGenerator(\n    preprocessing_function = preprocess_input ,\n    rotation_range = 40 ,\n    width_shift_range = 0.2 ,\n    height_shift_range = 0.2 ,\n    shear_range = 0.2 ,\n    zoom_range = 0.2 ,\n    horizontal_flip = True ,\n    fill_mode = 'nearest'\n)\n\n# Doing similar for the test data also\n\ntest_datagen = ImageDataGenerator(\n    preprocessing_function = preprocess_input ,\n    rotation_range = 40 ,\n    width_shift_range = 0.2 ,\n    height_shift_range = 0.2 ,\n    shear_range = 0.2 ,\n    zoom_range = 0.2 ,\n    horizontal_flip = True ,\n    fill_mode = 'nearest'\n)","754fc042":"train_path = '\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/train'\ntest_path = '\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/validation'\n","5d0d4366":"# train data\ntrain_set = train_datagen.flow_from_directory(train_path,\n                                            target_size = ( 224 , 224 ),\n                                            batch_size = 32,\n                                            class_mode = 'categorical')\n\n# test data\ntest_set = test_datagen.flow_from_directory(test_path,\n                                             target_size = ( 224 , 224 ),\n                                            batch_size = 32,\n                                            class_mode = 'categorical')","73688b5b":"from matplotlib import image as mpimg\nimport os\nfor link in os.listdir(train_path):\n  lk=train_path+'\/'+link\n  for lk1 in os.listdir(lk+'\/'):\n    path=lk+'\/'+lk1\n    img=mpimg.imread(path)\n    plt.imshow(img)\n    plt.title(link[:-1])\n    plt.show()\n    break","709d7b55":"checkpoint = ModelCheckpoint(filepath = 'vgg19.h5' , verbose = 2 , save_best_only = True )\ncallbacks = [checkpoint]\nstart = datetime.now()\nmodel_history = model.fit( train_set,\n                          validation_data = test_set,\n                          epochs = 10,\n                          steps_per_epoch = 5,\n                          validation_steps = 32,\n                          callbacks = callbacks,\n                          verbose = 2)\n\nduration = datetime.now() - start\n\nprint('Total elapsed time : ',duration)","7d9a7434":"## Training and Prediction :\n\nIn this phase the model will be trained and will be ready to predict. Checkpoints will also be set to track the performance of the model.","d7ad6654":"As the model will be using previous weights , it will remain untrained for now.","bf333d08":"As the tensorflow version is greater than 2.0.0 so, we do not have to import keras separately.\nNow  libraries what will be used in the whole process will be imported.","13e4befb":"## Visualizing the data :\n\nJust checkinh how the images of human and horses actually looks like in the dataset.","9f51d01c":"P.S : Change the accelerator to connect with GPU to make this process faster. It is demonstrated [here](https:\/\/www.kaggle.com\/sagnik1511\/animal-recognition-custom-cnn).","ffba9a3e":"# THANK YOU for visiting.\n\nIf you like this notebook do **upvote**,\n\nYou can visit my other works in [kaggle](kaggle.com\/sagnik1511\/code) or in [github](github.com\/sagnik1511).\n\n![](https:\/\/i.ytimg.com\/vi\/rU8ygyLuuIU\/maxresdefault.jpg)","1cdfba30":"## Processing Train & Test Data :\n\nNow the train and validation data will be processed to specifically trained on the VGG19 model.","44e89243":"Now we are going to customize the model to be trained on the selected dataset ( not imagenet ).","23521fc1":"Now processing the data","8b2f1fb2":"We can see that the model slightly overfitetd but predicted nicely over the train and validation.\n\nThus we can tell that this pretrained model really works up to mark :)","1e3c14a7":"We are going to do this task using [tensorflow 2](https:\/\/www.tensorflow.org\/). So, keras would be automatically imported with tensorflow.\nChecking the tensorflow version at first.","b3065930":"Now the model is being compiled with [adam optimizer](https:\/\/keras.io\/api\/optimizers\/adam\/) and other metrics.","a013be74":"Links of the data :","8adfff3b":"## Loading Model & Tuning :\n\nIn the process the model VGG19 will be loaded and then it will be tuned to predict over the dataset.\n","28dcef58":"We have to set the image size for making an input in the model.","1986b05b":"## Process of the Prediction:\n\nThe model **VGG19** is previously trained and saved on [imagenet](image-net.org). As the model is very deep , so it will need much time to train on this dataset. So, the main layers of the model will be using the weights when it was pretrained on *imagnet* thus will stay non-trainable.\n\n","61daea15":"# Binary Classification with Pretrained VGG-19 :\n\n![](https:\/\/miro.medium.com\/max\/1400\/1*6U9FJ_se7SIuFKJRyPMHuA.png)\n\nIn this notebook I am going to demonstrate simple process to use **Transfer Learning** with **VISUAL GEOMETRY GROUP -19 (VGG-19)**.\n\nLearn more about transfer learning [here](https:\/\/towardsdatascience.com\/what-is-transfer-learning-8b1a0fa42b4).\n\n* In this notebook I will a binary image classification task ( predict human or horse ) with VGG-19."}}