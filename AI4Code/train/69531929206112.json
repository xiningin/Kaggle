{"cell_type":{"8330217a":"code","b2e9bf6b":"code","fd5bd2e3":"code","e720f778":"code","eb2d2c22":"code","56abb2f4":"code","86b7f422":"code","319dd134":"markdown"},"source":{"8330217a":"import warnings\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom scipy.optimize import curve_fit\nfrom tqdm.notebook import tqdm","b2e9bf6b":"#%matplotlib notebook\nplt.style.use('ggplot')\nplt.rcParams['figure.figsize'] = [20, 8]\n\nwarnings.filterwarnings('ignore')","fd5bd2e3":"train = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-1\/train.csv',\n    parse_dates=['Date']).drop(['Lat', 'Long'], axis=1)\ntest = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-1\/test.csv',\n    parse_dates=['Date']).drop(['Lat', 'Long'], axis=1)\nsubmission = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-1\/submission.csv',\n    index_col='ForecastId')","e720f778":"# artifact(s) in the dataset:\n# https:\/\/www.kaggle.com\/marychin\/check-non-cumulative-confirmedcases-fatalities\ntrain.iloc[6425,4] = 0","eb2d2c22":"def sigmoid(x, m, alpha, beta):\n    \"\"\"\ud835\udd3c(\ud835\udc4c\ud835\udc61) = \ud835\udc40\/(1 + exp(\u2212\ud835\udefd(\ud835\udc61 \u2212 \ud835\udefc)), with\n    \ud835\udc4c\ud835\udc61 the accumulated observed number (of deaths or cases) at day \ud835\udc61 after a specific date,\n    \ud835\udc40 the expected maximum number,\n    \ud835\udefc the number of days at which the expected number of counts is half way the maximum, and\n    \ud835\udefd > 0 the growth parameter.\n    https:\/\/assets.tue.nl\/fileadmin\/content\/pers\/2020\/03%20March\/TUe%20-%20Technical_Report_Prediction_Corona_Virus.pdf\n    \"\"\"\n    return m \/ ( 1 + np.exp(-beta * (x - alpha)))\n  \n\ndef get_curve(covid, which):\n    covid['DaysPassed'] = covid['Date'].dt.dayofyear\n    curve = covid[covid[which] > 0].set_index('DaysPassed')[which]\n    if curve.index.size > 3:\n        return curve\n    \n\ndef plot_curve(curve, test, name, plot_n, popt, ax):\n    if curve is not None:\n        _ = curve.plot(ax=ax[plot_n % 5, plot_n \/\/ 5], title=name)\n        _.set_xlabel('')\n        x = np.append(curve[:-12].index.values, test['Date'].dt.dayofyear.values)\n        y = sigmoid(x, popt[0], popt[1], popt[2])\n        pd.Series(y, x).plot(ax=ax[plot_n % 5, plot_n \/\/ 5], style=':')\n    else:\n        pd.Series(0).plot(ax=ax[plot_n % 5, plot_n \/\/ 5], title=name)\n\n    \ndef predict_curve(covid, test, popt, which):\n    train_curve = get_curve(covid, which)\n    if train_curve is not None:\n        x_train = train_curve.index.values\n        y_train = train_curve.values\n        popt, _ = curve_fit(sigmoid, x_train, y_train, p0=popt, maxfev=1000000)\n        x_test = test['Date'].dt.dayofyear.values\n        y_test = sigmoid(x_test, popt[0], popt[1], popt[2])\n        test[which] = y_test\n        return test.set_index('ForecastId')[which].astype('int'), popt\n    return None, None\n\n\ndef append_predictions(train, test, popts):\n    cases_popt, fatalities_popt = popts\n    cases, cases_popt = predict_curve(train, test, cases_popt, 'ConfirmedCases')\n    if cases is not None:\n        CASES_ALL.append(cases)\n    fatalities, fatalities_popt = predict_curve(train, test, fatalities_popt, 'Fatalities')\n    if fatalities is not None:\n        FATALITIES_ALL.append(fatalities)\n    return cases_popt, fatalities_popt\n   \n    \ndef known_popt(country, region):\n    known = {}\n    known['cases'] = {\n        'Anhui': [993, 13.3, 0.28],\n        'Beijing': [411, 11.9, 0.22],\n        'Chongqing': [573, 11.2, 0.24],\n        'Fujian': [294, 10.7, 0.26],\n        'Gansu': [96, 11.7, 0.26],\n        'Guangdong': [1342, 11.7, 0.28],\n        'Guangxi': [252, 12.2, 0.22],\n        'Guizhou': [147, 14.9, 0.3],\n        'Hainan': [170, 12.6, 0.23],\n        'Hebei': [319, 14.9, 0.23],\n        'Heilongjiang': [482, 15.7, 0.27],\n        'Henan': [1270, 12.7, 0.28],\n        'Hubei': [67625, 18.7, 0.24],\n        'Hunan': [1018, 11.9, 0.29],\n        'Inner Mongolia': [76, 13.5, 0.22],\n        'Jiangsu': [635, 13.5, 0.26],\n        'Jiangxi': [937, 13.1, 0.29],\n        'Jilin': [92, 13.6, 0.34],\n        'Liaoning': [122, 10.3, 0.26],\n        'Ningxia': [74, 14.4, 0.21],\n        'Qinghai': [18, 9.1, 0.38],\n        'Shaanxi': [244, 11.6, 0.27],\n        'Shandong': [781, 17.5, 0.15],\n        'Shanghai': [336, 10.6, 0.28],\n        'Shanxi': [133, 11.6, 0.31],\n        'Sichuan': [535, 13.2, 0.21],\n        'Tianjin': [137, 13.9, 0.21],\n        'Xinjiang': [77, 15.6, 0.22],\n        'Yunnan': [172, 10.1, 0.27],\n        'Zhejiang': [1195, 10.5, 0.32],\n        'China': [680, 13.3, 0.265],\n    }\n    known['fatalities'] = {\n        'Heilonggjiang': [12.9, 18.6, 0.25],\n        'Henan': [21.7, 22.5, 0.25],\n        'Hubei': [3007, 23.6, 0.17],\n    }\n    if region in known['cases']:\n        cases_popt = known['cases'][region]\n    elif country in known['cases']:\n        cases_popt = known['cases'][country]\n    else:\n        cases_popt = [5000, 100, 0.2]\n        \n    if region in known['fatalities']:\n        fatalities_popt = known['fatalities'][region]\n    elif country in known['fatalities']:\n        fatalities_popt = known['fatalities'][country]\n    else:\n        fatalities_popt = [100, 150, 0.25]\n    \n    return cases_popt, fatalities_popt\n    \n    \ndef main():\n    n = -1\n    for country in tqdm(train['Country\/Region'].unique()):\n        country_train = train[train['Country\/Region'] == country].copy()\n        country_test = test[test['Country\/Region'] == country].copy()\n        if not country_train['Province\/State'].isna().all():\n            for region in country_train['Province\/State'].unique():\n                region_train = country_train[country_train['Province\/State'] == region].copy()\n                region_test = country_test[country_test['Province\/State'] == region].copy()\n                cases_popt, fatalities_popt = append_predictions(region_train, region_test, known_popt(country, region))\n                if region in ['Hubei', 'New York', 'Hunan', 'California', 'France', 'Netherlands']:\n                    n += 1\n                    plot_curve(get_curve(region_train, 'ConfirmedCases'), region_test, region, n, cases_popt, AX)\n                    plot_curve(get_curve(region_train, 'Fatalities'), region_test, region, n, fatalities_popt, AXX)\n        else:\n            cases_popt, fatalities_popt = append_predictions(country_train, country_test, known_popt(country, None))\n            if country in ['Italy', 'Spain', 'Mexico', 'Mongolia']:\n                n += 1\n                plot_curve(get_curve(country_train, 'ConfirmedCases'), country_test, country, n, cases_popt, AX)\n                plot_curve(get_curve(country_train, 'Fatalities'), country_test, country, n, fatalities_popt, AXX)","56abb2f4":"CASES_ALL = []\nFIG, AX = plt.subplots(5, 2)\nFIG.suptitle('Confirmed Cases')\n\nFATALITIES_ALL = []\nFIGG, AXX = plt.subplots(5, 2)\nFIGG.suptitle('Fatalities')\n\nmain()\n\nFIG.subplots_adjust(hspace=0.5)\nFIGG.subplots_adjust(hspace=0.5)","86b7f422":"final = pd.DataFrame(pd.concat(CASES_ALL).reindex(index=submission.index, fill_value=1))\nfinal = final.join(pd.DataFrame(pd.concat(FATALITIES_ALL).reindex(index=submission.index, fill_value=0)))\nfinal = final.where(final['Fatalities'] <= final['ConfirmedCases'], final['ConfirmedCases'] * 0.05, axis=0)\nfinal.to_csv('submission.csv')","319dd134":"# Sigmoid vs Polynomial Linear\nI initially started out with a polynomial linear regression model using `Ridge` ([here](https:\/\/www.kaggle.com\/jorijnsmit\/ridge-regression-of-confirmed-cases-and-fatalities)).\n\nHowever, these functions became too awkward and most importantly I could not 'guide' them in any way. Based on [this explainer on YouTube about exponential growth](https:\/\/www.youtube.com\/watch?v=Kas0tIxDvrg) I knew sigmoids were the true functions I was trying to fit. \n\nThrough [this notebook](https:\/\/www.kaggle.com\/group16\/sigmoid-per-country) I came in contact with [this research project at TU Eindhoven](https:\/\/www.tue.nl\/en\/news\/news-overview\/11-03-2020-eindhoven-data-scientists-take-on-corona-data-to-predict-growth-of-new-infections\/). Both this study and [Gilles Vandewiele](https:\/\/www.kaggle.com\/group16)'s notebook were the main inspiration sources for rewriting my linear notebook to sigmoid fitting.\n\nIf I would have had more time I would have tried to categorise continents\/countries\/etc according to what phase I believe they are currently in (early or late phase) and if I considered them 'high-risk' or outliers (e.g. Hubei, Italy, New York). A notebook which does this quite well already (automatically!) is [claudiu](https:\/\/www.kaggle.com\/casras)'s notebook: [COVID19 EDA and exponential curve fitting predict](https:\/\/www.kaggle.com\/casras\/covid19-eda-and-exponential-curve-fitting-predict)."}}