{"cell_type":{"c1386ffb":"code","5960cd42":"code","ed5b5c17":"code","66c8a7a2":"code","4980a247":"code","9b0b9b2c":"code","745d450d":"code","e33f4885":"code","b0bb162a":"code","293c9175":"code","7f6dba55":"code","78347428":"code","7341b8a1":"code","a3a81f2f":"code","40312541":"code","3f46fa39":"code","2a1ba73e":"code","6bc5e625":"code","143bba8e":"code","b1ed7f68":"code","31586f50":"code","e853755c":"code","659d358b":"code","24e4025e":"code","3daedf86":"code","0340ed45":"code","cb203983":"code","3908da67":"code","92ec9fb6":"code","593b69db":"code","94ed476f":"code","0f34629d":"markdown","9a58c9a1":"markdown","ceaf1a72":"markdown","91a624d2":"markdown","ea467a9a":"markdown","6b67c15d":"markdown","083d4219":"markdown","57fec4b8":"markdown","ca2eb827":"markdown","da4d6a64":"markdown","ea3a40aa":"markdown","50f39548":"markdown","b4604e95":"markdown"},"source":{"c1386ffb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_curve, auc\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5960cd42":"#import training data\nTrain = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_df = Train.drop(['PassengerId','Survived'], axis=1)\nlabel = Train['Survived']\nTrain.info()","ed5b5c17":"#Test data for Kaggle score\nTest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_df = Test.drop(['PassengerId'], axis=1)","66c8a7a2":"#map to numeric values\n#male: 1, female: 0\ntrain_df['Sex'] = train_df['Sex'].map(lambda x: 1 if(x=='male') else 0)\ntest_df['Sex'] = test_df['Sex'].map(lambda x: 1 if(x=='male') else 0)","4980a247":"train_df['Embarked'].fillna(train_df['Embarked'].mode(), inplace=True)\ntrain_df = pd.get_dummies(train_df, prefix=['Embarked'], columns=['Embarked'],drop_first=True)\ntrain_df","9b0b9b2c":"#fill empty value with mode\n#C:0, Q:1, S:2\ntrain_df['Embarked'].fillna(train_df['Embarked'].mode(), inplace=True)\ntrain_df['Embarked']=train_df['Embarked'].apply(lambda x: 0 if x=='C' else(1 if x=='Q' else 2) )\n\ntest_df['Embarked'].fillna(test_df['Embarked'].mode(), inplace=True)\ntest_df['Embarked']=test_df['Embarked'].apply(lambda x: 0 if x=='C' else(1 if x=='Q' else 2) )","745d450d":"train_df","e33f4885":"nonEmpty = train_df[train_df['Cabin'].isna()==False]['Cabin']\nnonEmpty = nonEmpty.apply(lambda x: x[0])\nnonEmpty.mode()\ntrain_df['Cabin'] = train_df['Cabin'].fillna('C')\ntrain_df['Cabin']=train_df['Cabin'].apply(lambda x: x[0])","b0bb162a":"train_df = pd.get_dummies(train_df, prefix=['Cabin'], columns=['Cabin'],drop_first=True)\ntrain_df","293c9175":"#extract the letter from Cabin and fill empty value with the mode('C')\nnonEmpty = train_df[train_df['Cabin'].isna()==False]['Cabin']\nnonEmpty = nonEmpty.apply(lambda x: x[0])\nnonEmpty.mode()\ntrain_df['Cabin'] = train_df['Cabin'].fillna('C')\ntrain_df['Cabin']=train_df['Cabin'].apply(lambda x: x[0])\ndict_1 = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4, 'F':5, 'G':6, 'T':7 }\ntrain_df['Cabin']=train_df['Cabin'].apply(lambda x: dict_1[x])","7f6dba55":"#mapping function to numeric values\n\ndict_1 = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4, 'F':5, 'G':6, 'T':7 }\ntest_df['Cabin'] = test_df['Cabin'].fillna('C')\ntest_df['Cabin']=test_df['Cabin'].apply(lambda x: x[0])\ntest_df['Cabin']=test_df['Cabin'].apply(lambda x: dict_1[x])","78347428":"#Fill na of Age with mean value\n\ntrain_df.loc[train_df['Sex']==1,'Age'] = train_df.loc[train_df['Sex']==1,'Age'].fillna(30.726645)\ntrain_df.loc[train_df['Sex']==0,'Age'] = train_df.loc[train_df['Sex']==0,'Age'].fillna(27.915709)\n\ntest_df.loc[test_df['Sex']==1,'Age'] = test_df.loc[test_df['Sex']==1,'Age'].fillna(30.272362)\ntest_df.loc[test_df['Sex']==0,'Age'] = test_df.loc[test_df['Sex']==0,'Age'].fillna(30.272732)\n","7341b8a1":"#Fill na of Fare with median\ntest_df['Fare'].fillna(test_df['Fare'].median(), inplace = True)","a3a81f2f":"train_df = pd.get_dummies(train_df, prefix=['Pclass'], columns=['Pclass'],drop_first=True)\ntrain_df","40312541":"title_series = train_df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntrain_df['Title'] = title_series\ntrain_df.drop('Name',axis=1,inplace=True)\n","3f46fa39":"train_df = pd.get_dummies(train_df, prefix=['Title'], columns=['Title'],drop_first=True)\ntrain_df","2a1ba73e":"#extract the title of name, and map to numeric values\ntitle_series = train_df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntitle_dict = {'Capt':5,\n 'Col':4,\n 'Countess':4,\n 'Don':4,\n 'Dona':4,\n 'Dr':4,\n 'Jonkheer':4,\n 'Lady':4,\n 'Major':4,\n 'Master':4,\n 'Miss':1,\n 'Mlle':1,\n 'Mme':2,\n 'Mr':0,\n 'Mrs':2,\n 'Ms':1,\n 'Rev':4,\n 'Sir':4}\ntitle_series=title_series.map(title_dict)\ntrain_df['Title'] = title_series\ntrain_df.drop('Name',axis=1,inplace=True)\n\ntitle_series = test_df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntitle_series=title_series.map(title_dict)\ntest_df['Title'] = title_series\ntest_df.drop('Name',axis=1,inplace=True)\n","6bc5e625":"#drop ticket number\ntrain_df.drop('Ticket', axis=1, inplace=True )\ntest_df.drop('Ticket', axis=1, inplace=True )\n","143bba8e":"train_df","b1ed7f68":"# Visualize the count of survivors for columns 'Pclass', 'Sex', 'Title','Sibsp', 'Parch', and 'Cabin'\ncols = ['Pclass', 'Sex', 'Title', 'SibSp', 'Parch', 'Cabin']\n\nn_rows = 2\nn_cols = 3\n\nfig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols*3.2,n_rows*3.2))\n\nfor r in range(0,n_rows):\n    for c in range(0,n_cols):  \n        \n        i = r*n_cols+ c      \n        ax = axs[r][c] \n        sns.countplot(train_df[cols[i]], hue=label, ax=ax)\n        ax.set_title(cols[i])\n        ax.legend(title=\"survived\", loc='upper right') \n        \nplt.tight_layout() ","31586f50":"#cross validation\nfrom sklearn.model_selection import cross_val_score\nclf = LogisticRegression(max_iter=10000)\nclf.fit(train_df, label)\nscores = cross_val_score(clf, train_df, label, cv=10, scoring = \"accuracy\")\nprint(\"Scores:\", scores)\nprint(\"Mean:\", scores.mean())\nprint(\"Standard Deviation:\", scores.std())","e853755c":"#cross validation\nfrom sklearn.model_selection import cross_val_score\nclf = LogisticRegression(max_iter=10000)\nclf.fit(train_df, label)\nscores = cross_val_score(clf, train_df, label, cv=10, scoring = \"accuracy\")\nprint(\"Scores:\", scores)\nprint(\"Mean:\", scores.mean())\nprint(\"Standard Deviation:\", scores.std())","659d358b":"#confusion matrix\ny_prob = clf.predict_proba(train_df)\ndf_matrix = pd.DataFrame({'True label': label,\n                    'Predicted label': y_prob[:,1] > 0.5})\n\ndf_matrix.replace(to_replace={0:'No', 1:'Yes', 'True':'Yes', 'False':'No'}, inplace=True)\ndf_matrix.groupby(['Predicted label','True label']).size().unstack('True label')","24e4025e":"#function to plot confusion matrix\ndef plot_confusion_matrix(cm, title='Confusion matrix (Normalized)',\n                          cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n    plt.title('Normalized confusion matrix')\n    plt.colorbar()\n    plt.tight_layout()\n    plt.xlabel('True label',rotation='horizontal', ha='right')\n    plt.ylabel('Predicted label')\n    plt.show()","3daedf86":"#plot confusion matrix of training data\ncm = confusion_matrix(label, y_prob[:,1] > 0.5)\ncm_normalized = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\nplot_confusion_matrix(cm_normalized.T)\ncm_normalized.T","0340ed45":"#calculate false positive and true positive rate for ROC curve\nfalse_pos_rate, true_pos_rate, _ = roc_curve(label, y_prob[:,1])\nroc_auc = auc(false_pos_rate, true_pos_rate)\n","cb203983":"#plot ROC curve\nfig, ax1 = plt.subplots(1, 1, figsize=(6,6))\nax1.plot(false_pos_rate, true_pos_rate, label='ROC curve (area = %0.2f)' % roc_auc, color='b')\n\nfor ax in fig.axes:\n    ax.plot([0, 1], [0, 1], 'k--')\n    ax.set_xlim([-0.05, 1.0])\n    ax.set_ylim([0.0, 1.05])\n    ax.set_xlabel('False Positive Rate')\n    ax.set_ylabel('True Positive Rate')\n    ax.legend(loc=\"lower right\")","3908da67":"from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(train_df, label)\n\n#generate cross validation score\nscores = cross_val_score(model, train_df, label, cv=10, scoring = \"accuracy\")\nprint(\"Scores:\", scores)\nprint(\"Mean:\", scores.mean())\nprint(\"Standard Deviation:\", scores.std())\n\n#Generate confusion matrix\ny_prob2 = model.predict_proba(train_df)\ndf_matrix = pd.DataFrame({'True label': label,'Predicted label': y_prob2[:,1] > 0.5})\ndf_matrix.replace(to_replace={0:'No', 1:'Yes', 'True':'Yes', 'False':'No'}, inplace=True)\ndf_matrix.groupby(['Predicted label','True label']).size().unstack('True label')","92ec9fb6":"#Plot confusion matrix\ncm2 = confusion_matrix(label, y_prob2[:,1] > 0.5)\ncm_normalized = cm2.astype('float') \/ cm2.sum(axis=1)[:, np.newaxis]\nplot_confusion_matrix(cm_normalized.T)\ncm_normalized","593b69db":"#calculate false positive rate, true positive rate for ROC curve\nfalse_pos_rate, true_pos_rate, _ = roc_curve(label, y_prob2[:,1])\nroc_auc = auc(false_pos_rate, true_pos_rate)","94ed476f":"#Plot ROC curve\nfig, ax1 = plt.subplots(1, 1, figsize=(6,6))\nax1.plot(false_pos_rate, true_pos_rate, label='ROC curve (area = %0.2f)' % roc_auc, color='b')\n\nfor ax in fig.axes:\n    ax.plot([0, 1], [0, 1], 'k--')\n    ax.set_xlim([-0.05, 1.0])\n    ax.set_ylim([0.0, 1.05])\n    ax.set_xlabel('False Positive Rate')\n    ax.set_ylabel('True Positive Rate')\n    ax.legend(loc=\"lower right\")","0f34629d":"Fare","9a58c9a1":"# Evaluation","ceaf1a72":"Embarked","91a624d2":"Ticket Number","ea467a9a":"# Data Preprocessing","6b67c15d":"Confusion Matrix","083d4219":"Age","57fec4b8":"# Model training - Logistic Regression","ca2eb827":"Cabin","da4d6a64":"Sex","ea3a40aa":"# Model Training - Random Forest","50f39548":"Name","b4604e95":"ROC curve"}}