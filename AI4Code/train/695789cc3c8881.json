{"cell_type":{"8c30a592":"code","03cd8f02":"code","5d8afd09":"code","0fc4d8e1":"code","48e7ac6e":"code","0b216363":"code","c955ab7c":"code","83c57201":"code","d55bee3c":"code","d3ebe78c":"code","67769e64":"code","8b94fd48":"code","54434d7b":"code","ee0c1dd2":"code","5b28b697":"code","453ae6bd":"code","50c64a5f":"code","eb1c0577":"markdown"},"source":{"8c30a592":"import pandas as pd\ndata = pd.read_csv(\"\/kaggle\/input\/petfinder-pawpularity-score\/train.csv\", sep=',')\ndata['Id'] = data['Id'] + '.jpg'\ndata = data.rename(columns={'Id': 'filename'})\ndata = data.drop(columns=['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'])\ndata","03cd8f02":"dataset_dir = '\/kaggle\/input\/petfinder-pawpularity-score\/train'\nwidth, height = 512, 512\nbatch_size = 32\nnb_classes = 5\n\nimport os\npath = \"\/kaggle\/working\/data\"\nif not os.path.exists(path):\n    os.mkdir(path)\n\nfrom shutil import copyfile\nfor i in range(nb_classes):\n    mini = i * int(100 \/ nb_classes)\n    maxi = (i + 1) * int(100 \/ nb_classes)\n    class_data = data[(data['Pawpularity'] > mini) & (data['Pawpularity'] <= maxi)]\n    class_dir = os.path.join(path, str(mini) + '-' + str(maxi))\n    os.mkdir(class_dir)\n    for filename in class_data['filename']:\n        src = os.path.join(dataset_dir, filename)\n        dst = os.path.join(class_dir, filename)\n        copyfile(src, dst)","5d8afd09":"from tensorflow.keras.utils import image_dataset_from_directory\ntrain_ds = image_dataset_from_directory(\n  path,\n  validation_split=0.2,\n  subset=\"training\",\n  seed=99,\n  image_size=(height, width),\n  batch_size=batch_size)\nval_ds = image_dataset_from_directory(\n  path,\n  validation_split=0.2,\n  subset=\"validation\",\n  seed=99,\n  image_size=(height, width),\n  batch_size=batch_size)","0fc4d8e1":"from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nearly_stopping_callback = EarlyStopping(\n    monitor=\"accuracy\",\n    min_delta=1,  # sous les 1% de mieux, on patiente\n    patience=10,  # on patiente max 10 epochs\n    verbose=2,\n    mode=\"min\",\n    restore_best_weights=True\n)\nmodel_checkpoint_callback = ModelCheckpoint(\n    'efficientNet_reg.h5',\n    monitor=\"accuracy\",\n    verbose=0,\n    save_best_only=True,\n    mode=\"min\",\n    save_freq=\"epoch\"\n)\ncallbacks = [early_stopping_callback, model_checkpoint_callback]","48e7ac6e":"import sys\nimport os\nsys.path.insert(0, \"\/kaggle\/input\/efnetv2src\/efficientnet-v2-keras-main\")\nsys.path.append('..\/input\/tfkeras-efficientnetsv2\/')\nfrom efficientnet_v2 import EfficientNetV2XL","0b216363":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom, RandomTranslation, RandomContrast\ndata_augmentation = Sequential([\n  RandomFlip(\"horizontal\", input_shape=(height, width, 3)),\n  RandomRotation(factor=0.4, fill_mode=\"wrap\"),\n  RandomZoom(0.2),\n  RandomTranslation(height_factor=0.2, width_factor=0.2, fill_mode=\"wrap\"),\n  RandomContrast(factor=0.2)\n])","c955ab7c":"from tensorflow.keras import Input, Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\nfrom tensorflow.keras.metrics import MeanAbsoluteError, MeanAbsolutePercentageError\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\nimport tensorflow_addons as tfa\n\nefficientnet = EfficientNetV2XL(\n    include_top=False,\n    weights='..\/input\/tfkeras-efficientnetsv2\/21_ft1k_notop\/efficientnetv2-xl-21k-ft1k_notop.h5', \n    input_shape=(height, width, 3),\n    classes=nb_classes\n)\nefficientnet.trainable = False\n\ninputs = Input(shape=(height, width, 3))\nx = data_augmentation(inputs)\nx = efficientnet(x, training=False)\nx = GlobalAveragePooling2D()(x)\nx = BatchNormalization()(x)\nx = Dropout(0.2)(x)\nclass1 = Dense(1920, activation='relu')(x)\noutputs = Dense(nb_classes, activation='softmax')(class1)\nefficientnet = Model(inputs, outputs)\n\nradam = tfa.optimizers.RectifiedAdam(learning_rate=0.01)\noptimizer = tfa.optimizers.Lookahead(radam, sync_period=6, slow_step_size=0.5)\n\nefficientnet.compile(optimizer=optimizer,\n              loss=SparseCategoricalCrossentropy(),\n              metrics=['accuracy'])","83c57201":"epochs = 100\nhistory_efficientnet = efficientnet.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=epochs,\n    callbacks=callbacks\n)","d55bee3c":"history_efficientnet.history","d3ebe78c":"import matplotlib.pyplot as plt\n\ndict1 = {\n    \"accuracy\": history_efficientnet.history[\"accuracy\"],\n    \"type\": \"training\"\n}\ndict2 = {\n    \"accuracy\": history_efficientnet.history[\"accuracy\"],\n    \"type\": \"validation\"\n}\ns1 = pd.DataFrame(dict1)\ns2 = pd.DataFrame(dict2)\ndf = pd.concat([s1, s2], axis=0).reset_index()\nimport seaborn as sns\ngrid = sns.relplot(\n    data=df,\n    x=df[\"index\"],\n    y=\"accuracy\",\n    col=\"type\",\n    kind=\"line\"\n)\nfor ax in grid.axes.flat:\n    ax.set(xlabel=\"Epoch\")\nplt.show()","67769e64":"import tensorflow as tf\ndef preprocess(image):\n    return (tf.cast(image, dtype=tf.float32) - 128.00) \/ 128.00","8b94fd48":"train_ds.class_names","54434d7b":"import os\nimport numpy as np\nfrom PIL import Image\ntest_dir = '\/kaggle\/input\/petfinder-pawpularity-score\/test'\nids = []\npawpularities = []\nfor test_image in os.listdir(test_dir):\n    image_path = os.path.join(test_dir, test_image)\n    id_image = test_image.split('.')[0]\n    ids.append(id_image)\n    img = Image.open(image_path) \n    img = img.resize((width, height))\n    img = preprocess(np.array(img).reshape(1, width, height, 3))\n    preds = efficientnet.predict(img)\n    top_indice = preds[0].argsort()[-1]\n    result = train_ds.class_names[top_indice]\n    pawpularities.append(result)","ee0c1dd2":"data = pd.read_csv(\"\/kaggle\/input\/petfinder-pawpularity-score\/train.csv\", sep=',')\nX = data.drop(columns=['Id', 'Pawpularity'])\ny = data['Pawpularity']\nfrom sklearn.model_selection import train_test_split, GridSearchCV, ParameterGrid\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, \n                                                    random_state=1)\nfrom catboost import CatBoostRegressor\nimport time\nstart = time.time()\n\ncb = CatBoostRegressor(depth=5,\n                       learning_rate=0.01,\n                       n_estimators=50,\n                       loss_function='RMSE',\n                       task_type='CPU',\n                       verbose=False)\n\ncb.fit(X_train, y_train)\ny_pred = cb.predict(X_test)\n\nimport numpy as np\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error as mse\n\ncb_rmse = np.sqrt(mse(y_test, y_pred))\nprint(\"RMSE for CatBoost: \", np.mean(cb_rmse))\n\nend = time.time()\ndiff = end - start\nprint('Execution time for CatBoost (in Seconds):', diff)\n\nprint(\"r2_score : {:.2f}\".format(r2_score(y_test, y_pred)))","5b28b697":"sub_df = pd.read_csv(\"\/kaggle\/input\/petfinder-pawpularity-score\/test.csv\", sep=',')\nX_sub = sub_df.drop(columns=['Id'])\n\ntest_dir = '\/kaggle\/input\/petfinder-pawpularity-score\/test'\nids = []\npawpularities = []\nfor test_image in os.listdir(test_dir):\n    image_path = os.path.join(test_dir, test_image)\n    id_image = test_image.split('.')[0]\n    ids.append(id_image)\n    img = Image.open(image_path) \n    img = img.resize((width, height))\n    img = preprocess(np.array(img).reshape(1, width, height, 3))\n    preds = efficientnet.predict(img)\n    top_indice = preds[0].argsort()[-1]\n    result = train_ds.class_names[top_indice]\n    pawpularities.append(result)\n\nimg_dict = {\n    'Id': ids,\n    'Pawpularity': pawpularities\n}\nimg_df = pd.DataFrame(img_dict)\nprint(img_df)\n\nprint(\"shape X_sub: \", X_sub.shape)\ny_sub = cb.predict(X_sub)\ny_sub = [round(x) for x in y_sub]\nsub_df['Pawpularity'] = y_sub\nsub_df = sub_df.drop(columns=['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'])","453ae6bd":"print(sub_df)\nfor id_img in sub_df['Id']:\n    result = img_df[img_df['Id'] == id_img]['Pawpularity']\n    result = result.values[0]\n    mini = int(result.split('-')[0])\n    maxi = int(result.split('-')[1])\n    p = sub_df[sub_df['Id'] == id_img]['Pawpularity'].values[0]\n    print(p, mini, maxi)\n    if p < mini:\n        p = int(round(p + (mini - p) \/ 2))\n    if p > maxi:\n        p = int(round(p - (p - maxi) \/ 2))\n    print(\"=>\", p)\n    sub_df.at[sub_df['Id'] == id_img, 'Pawpularity'] = p\n    \nprint(sub_df)\nsub_df.to_csv('submission.csv', index=False, sep=',')","50c64a5f":"import shutil\nimport os\n\nos.remove('efficientNet_reg.h5')\nshutil.rmtree(\"\/kaggle\/working\/data\")\nshutil.rmtree(\"catboost_info\")","eb1c0577":"Copying dataset files to form a classification directories structure"}}