{"cell_type":{"b919c4c5":"code","46427d3b":"code","61da3481":"code","ec8003f9":"code","a5215a98":"code","afc9a78c":"code","60321a16":"code","c65d14eb":"code","50fe8af6":"code","58185c87":"code","8aff6a4c":"code","14ae1698":"code","5db1c8a9":"code","30d384e7":"code","15090253":"code","01f76eb9":"code","a2a67dd3":"code","36a47509":"code","9a23599e":"code","447e6a0c":"code","05c9d716":"code","12969bd6":"code","0d69c3b5":"code","fde02bc4":"code","d2cfd64d":"code","62aa9e71":"code","2c302542":"code","153c3bc0":"code","9434dc4d":"code","1bdcd611":"code","302b674c":"code","c2a74604":"code","8091df0d":"markdown","81e27193":"markdown","9f04aaf0":"markdown","62a8d7eb":"markdown","7e83696e":"markdown","055145f6":"markdown","0f8b3745":"markdown","1405c9a2":"markdown","66343a08":"markdown","3028d3d4":"markdown","6f01ad3d":"markdown","ceb50f9d":"markdown","379634c3":"markdown","31cbe8c0":"markdown","39d242ad":"markdown","27730187":"markdown","366b7354":"markdown","445460bd":"markdown","a55571df":"markdown","fb0f4aa5":"markdown","63e6a3a9":"markdown","04bbb101":"markdown","049d090b":"markdown","d96ff352":"markdown","0cef77f3":"markdown","e39c6ecd":"markdown","35c13bf3":"markdown","bec2fd32":"markdown","ceeceb47":"markdown","d63af5b3":"markdown","f5e53095":"markdown","6182cda9":"markdown","f9be4f0e":"markdown"},"source":{"b919c4c5":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.plotly as py\nimport matplotlib.style as style\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nfrom scipy.stats import pearsonr\nfrom IPython.display import HTML\n\n# Init plotly\ninit_notebook_mode(connected=True)\n\n# Seaborn style\nsns.set(style=\"white\")\nstyle.use('seaborn-poster') #sets the size of the charts\nstyle.use('ggplot')\n\n# Filter warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\npd.set_option('display.max_columns', 7)","46427d3b":"from sklearn.utils.multiclass import unique_labels\n\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n    classes = classes[unique_labels(y_true, y_pred)]\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    fig, ax = plt.subplots()\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax\n","61da3481":"df = pd.read_csv(\"..\/input\/global.csv\")\ndf = df.dropna()\n\ndf.shape","ec8003f9":"df.head(10)","a5215a98":"df.info()","afc9a78c":"df.describe()","60321a16":"audio_feature_headers = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms']","c65d14eb":"sns.pairplot(df[audio_feature_headers].sample(1000))\nplt.show()","50fe8af6":"corr = df[audio_feature_headers].corr()\n\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nf, ax = plt.subplots(figsize=(11, 9))\n\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.6, vmin=-.4, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5});","58185c87":"g = sns.jointplot(x='loudness', y='energy', data=df.sample(1000), kind='reg');","8aff6a4c":"plt.tight_layout()\nplt.subplots_adjust(top=0.4)\n\nfig, ax = plt.subplots(2, 3, figsize=(25, 10), sharex=True)\n\nsample = df.sample(1000)\n\nfig.suptitle(\"Correlation between some of the audio features\", fontsize=20)\nsns.regplot(x='valence', y='danceability', data=sample, ax=ax[0, 0]);\nsns.regplot(x='valence', y='energy', data=sample, ax=ax[0, 1]);\nsns.regplot(x='valence', y='loudness', data=sample, ax=ax[0, 2]);\nsns.regplot(x='acousticness', y='energy', data=sample, ax=ax[1, 0]);\nsns.regplot(x='acousticness', y='loudness', data=sample, ax=ax[1, 1]);","14ae1698":"la_he = df[(df['energy'] > 0.8) & (df['acousticness'] < 0.2)][['artist', 'track_name', 'energy', 'acousticness', 'danceability']] # Low-acousticness - High-energy\nla_he.head(5)","5db1c8a9":"from IPython.display import HTML\nHTML(\"\"\"\n<iframe width=\"560\" height=\"315\" src=\"https:\/\/www.youtube.com\/embed\/ynlQ8Oz8Qmk?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen><\/iframe>\n<iframe width=\"560\" height=\"315\" src=\"https:\/\/www.youtube.com\/embed\/UqyT8IEBkvY?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen><\/iframe>\n\"\"\")","30d384e7":"songs_grouped_mean = df.drop(['day', 'month', 'year'], axis=1)\nsongs_grouped_mean = songs_grouped_mean.groupby('url').mean() # Group unique songs by its 'url' (unique identifier)\n\nsongs_grouped_mean.head(10)","15090253":"songs_grouped_mean_ranges = songs_grouped_mean.groupby(pd.cut(songs_grouped_mean[\"position\"], np.arange(0, 101, 10))).count()\n\nf, ax = plt.subplots(figsize=(15, 5))\nsns.barplot(x=songs_grouped_mean_ranges.index.values, y=songs_grouped_mean_ranges[\"position\"]);\n\nax.set(title=\"Number of songs that reached a top position\", ylabel=\"Count\");","01f76eb9":"songs_grouped_min = df.drop(['day', 'month', 'year'], axis=1)\nsongs_grouped_min = songs_grouped_min.groupby('url').min() # Group unique songs by its 'url' (unique identifier)\n\ngsongs = songs_grouped_min # Alias","a2a67dd3":"songs_grouped_min_ranges = gsongs.groupby(pd.cut(gsongs[\"position\"], np.arange(0, 101, 10))).count()\n\nf, ax = plt.subplots(figsize=(15, 5))\nsns.barplot(x=songs_grouped_min_ranges.index.values, y=songs_grouped_min_ranges[\"position\"]);\n\nax.set(title=\"Number of songs that reached a top position\", ylabel=\"Count\");","36a47509":"def tempo_to_rythm(tempo):\n    if(tempo < 66):\n        return 'lento'\n    if(66 <= tempo < 76):\n        return 'adagio'\n    if(76 <= tempo < 108):\n        return 'andante'\n    if(108 <= tempo < 168):\n        return 'allegro'\n    if(168 <= tempo):\n        return 'presto'\n\ngsongs['rythm'] = gsongs['tempo'].transform(tempo_to_rythm)","9a23599e":"fig, ax = plt.subplots(figsize=(8, 8))\nax.pie(gsongs[\"rythm\"].value_counts(), labels=gsongs['rythm'].value_counts().axes[0], autopct='%1.1f%%', shadow=True, textprops={'fontsize': 16});\nax.set_title(\"Rythm tag distribution\");","447e6a0c":"ax = sns.barplot(x='position', y='rythm', data=gsongs[gsongs['position'] <= 20])\nax.set(title=\"Rythm tag for the Top 20 songs\", xlim=(1,20));\n\n# Count the number of songs occurences on each group\nprint(gsongs[gsongs['position'] <= 20].groupby('rythm').count()['position'])","05c9d716":"keys = np.array(['Do', 'Do#\/Re\u266d', 'Re', 'Re#\/Mi\u266d', 'Mi', 'Mi#\/Fa\u266d', 'Fa', 'Fa#\/Sol\u266d', 'Sol', 'Sol#\/La\u266d', 'La', 'La#\/Si\u266d', 'Si', 'Si#\/Do\u266d'])\nkeys_top10_categorical = pd.Series(keys[gsongs[gsongs['position'] < 10]['key']])","12969bd6":"keys_count = keys_top10_categorical.value_counts()\n\nf, ax = plt.subplots(figsize=(15, 5))\nsns.barplot(x=keys_count.axes[0], y=keys_count.values)\nax.set(title=\"Most repeated keys on the top 10 songs\", ylabel=\"Number of songs\");","0d69c3b5":"from wordcloud import WordCloud, STOPWORDS\n\nt10_titles = gsongs[gsongs[\"position\"] <= 10][\"track_name\"].values\nwc = WordCloud(stopwords=STOPWORDS).generate(\" \".join(t10_titles))\n\nplt.figure(figsize=(20, 20))\n\nplt.subplot(1, 2, 2)\nplt.imshow(wc, interpolation='bilinear')\nplt.title('Most repeated words for Top 10 song titles', fontsize=25)\nplt.axis(\"off\");","fde02bc4":"gsongs[\"success\"] = gsongs[\"position\"] <= 30\ngsongs[\"success\"] = gsongs[\"success\"].astype(int)\n\nsns.countplot(x=\"success\", data=gsongs)","d2cfd64d":"from sklearn.model_selection import train_test_split\n\n\nfeature_headers = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms']\npredict_headers = ['success']\n\nX_all = gsongs[feature_headers]\nY_all = gsongs[predict_headers]\n\nX_train, X_test, Y_train, Y_test = train_test_split(X_all, Y_all, test_size=0.2, random_state=42);","62aa9e71":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nprediction = knn.predict(X_test)","2c302542":"from sklearn.metrics import confusion_matrix\n\nprint(\"La precisi\u00f3n de nuestro modelo es: \", knn.score(X_test, Y_test))\n\nplot_confusion_matrix(Y_test, prediction, np.array([0, 1]));","153c3bc0":"X_all = gsongs[feature_headers]\nX_all = X_all.drop([\"duration_ms\", \"mode\", \"loudness\", \"danceability\", \"acousticness\", \"liveness\", \"instrumentalness\"], axis=1)\n\nX_train, X_test, Y_train, Y_test = train_test_split(X_all, Y_all, test_size=0.2, random_state=42)\n\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nprediction = knn.predict(X_test)\n\nprint(\"La precisi\u00f3n de nuestro modelo es: \", knn.score(X_test, Y_test))\n\nplot_confusion_matrix(Y_test, prediction, np.array([0, 1]));","9434dc4d":"X_all = gsongs[feature_headers]\nX_all = X_all.drop([\"duration_ms\", \"mode\", \"loudness\", \"danceability\", \"acousticness\", \"liveness\", \"instrumentalness\"], axis=1)\n\nX_train, X_test, Y_train, Y_test = train_test_split(X_all, Y_all, test_size=0.2, random_state=42)\n\ntest_accuracy = []\nrg = np.arange(1, 25)\n\nfor i, k in enumerate(rg):\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train, Y_train)\n    test_accuracy.append(knn.score(X_test, Y_test))\n    \nplt.figure(figsize=[13,8])\nplt.plot(rg, test_accuracy, label = 'Precisi\u00f3n de test')\nplt.legend()\nplt.title('K VS Precisi\u00f3n')\nplt.xlabel('K')\nplt.ylabel('Precisi\u00f3n')\nprint(\"La mejor precisi\u00f3n que podemos obtener es {} con K = {}\".format(np.max(test_accuracy),1+test_accuracy.index(np.max(test_accuracy))))\n    ","1bdcd611":"from sklearn.ensemble import RandomForestClassifier\n\nX_all = gsongs[feature_headers]\n\nX_train, X_test, Y_train, Y_test = train_test_split(X_all, Y_all, test_size=0.2, random_state=42)\n\nrfc = RandomForestClassifier(max_depth=10, random_state=43)\nrfc.fit(X_train, Y_train)\n\ndf = pd.DataFrame({'group': X_train.columns, 'values': rfc.feature_importances_})\n\n# Reorder it following the values:\nordered_df = df.sort_values(by='values')\n\nmy_range=range(1,len(df.index)+1)\n\nplt.hlines(y=my_range, xmin=0, xmax=ordered_df['values'], color='skyblue')\nplt.plot(ordered_df['values'], my_range, \"o\", color=\"skyblue\")\n \n# Add titles and axis names\nplt.yticks(my_range, ordered_df['group'])\nplt.title(\"Importance of features for RandomForest\", loc='left')\nplt.xlabel('Importance')\nplt.ylabel('Feature');","302b674c":"useless_headers = df[df[\"values\"] < 0.10][\"group\"].tolist()\n\nfiltered_headers = [header for header in feature_headers if header not in useless_headers]\n\nfiltered_headers","c2a74604":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import make_classification\n\nX_all = gsongs[filtered_headers]\n\nX_train, X_test, Y_train, Y_test = train_test_split(X_all, Y_all, test_size=0.2, random_state=42)\n\ntest_accuracy = []\nrg = np.arange(1, 200)\n\nfor i, max_depth in enumerate(rg):\n    rfc = RandomForestClassifier(max_depth=max_depth, random_state=47)\n    rfc.fit(X_train, Y_train)\n    test_accuracy.append(rfc.score(X_test, Y_test))\n    \nplt.figure(figsize=[13,8])\nplt.plot(rg, test_accuracy, label = 'Precisi\u00f3n de test')\nplt.legend()\nplt.title('max_depth VS Precisi\u00f3n')\nplt.xlabel('max_depth')\nplt.ylabel('Precisi\u00f3n')\nprint(\"La mejor precisi\u00f3n que podemos obtener es {} con max_depth = {}\".format(np.max(test_accuracy),1+test_accuracy.index(np.max(test_accuracy))))","8091df0d":"> __Aclaraci\u00f3n__: Los valores de _loudness_ aparecen en decibelios, y toman valores __negativos__. En el contexto de sonido\/m\u00fasica, __0dB__ se refiere al nivel de ruido __m\u00e1s alto__. Por lo tanto, cuanto m\u00e1s cercano a 0dB m\u00e1s ruidosa es una canci\u00f3n.","81e27193":"## Distribuci\u00f3n de las claves en el top 100","9f04aaf0":"Separamos el DataFrame en los modelos de entrenamiento y testeo, y hacemos una primera prueba con el algoritmo KNN","62a8d7eb":"### 1. \u00bfEs posible predecir si una canci\u00f3n ser\u00e1 exitosa?","7e83696e":"Da un porcentaje de acierto del **0.57%**, que no estar\u00eda mal si no fuera porque clasifica muy mal `success = 1`. Podemos probar a eliminar algunos atributos:","055145f6":"Sin embargo, los atributos __valence__, __energy__, __acousticness__ y __speechiness__ tambi\u00e9n parecen tener cierta correlaci\u00f3n que merece la pena representar:","0f8b3745":"Vamos a probar si con otro algoritmo podemos conseguir mejores resultados. En este caso, utilizaremos **Random Forest**. Vamos a reestablecer los atributos eliminados y, esta vez, utilizar RandomForest para ver la importancia de cada uno.","1405c9a2":"# Spotify EDA and Classification\n\n## \u00cdndice\n1. [Introducci\u00f3n](#Introducci\u00f3n)\n2. [Informaci\u00f3n](#Informaci\u00f3n)\n3. [Analizando las canciones](#Analizando-las-canciones)\n4. [Aplicando algoritmos de predicci\u00f3n](#Aplicando-algoritmos-de-predicci\u00f3n)","66343a08":"Vamos a ver como se distribuyen las **claves** en el top 10 de canciones. Pero antes, transformaremos los valores de `key` a sus **s\u00edmbolos** correspondientes.","3028d3d4":"Y con una **matriz de correlaci\u00f3n**:","6f01ad3d":"## Introducci\u00f3n\n\nEn este kernel haremos un Exploratory Data Analysis (EDA) del Dataset [Top 100 Spotify Songs with audio features (2017-2018)](https:\/\/www.kaggle.com\/davafons\/top-100-spotify-songs-with-audio-feat-20172018]) con el objetivo de comprender si se pueden predecir tendencias en las canciones m\u00e1s escuchadas.","ceb50f9d":"Primero hay que definir que significa que una canci\u00f3n sea exitosa. En este caso, diremos que una canci\u00f3n tiene \u00e9xito (1) si alcanza el top 30. En otro caso, no tendr\u00e1 \u00e9xito (0).\n\nSe podr\u00eda haber escogido el top 10, pero las clases estar\u00edan muy desbalanceadas (200 instancias con `success = 1` frente a >1000 con `success = 0`)","379634c3":"### Descripci\u00f3n del dataset\n\n__NOTA__: Hay dos archivos _.csv_: __global.csv__ y __data.csv__.\n* __global.csv__ representa el ranking mundial por cada d\u00eda.\n* __data.csv__ contiene todos los rankings individuales para todas las regiones por cada d\u00eda.\n\nPrincipalmente utilizaremos __global.csv__ porque es m\u00e1s peque\u00f1o y facil de tratar, pero merece la pena probar los resultados tambi\u00e9n con __data.csv__","31cbe8c0":"# Aplicando algoritmos de predicci\u00f3n","39d242ad":"Hasta ahora todo parece tener sentido. Las canciones con mayor __valence (m\u00e1s alegres)__ son __m\u00e1s bailables__, __m\u00e1s en\u00e9rgicas__ y __m\u00e1s ruidosas__. Adem\u00e1s, es muy probable que debido a estas caracter\u00edsticas predomien en ellas los __instrumentos el\u00e9ctricos__, como sintentizadores, pads, etc.\n\nPor otra parte, las canciones __m\u00e1s ac\u00fasticas__ utilizar\u00e1n instrumentos como _guitarras ac\u00fasticas_ o _pianos_, que son __menos en\u00e9rgicos__ y __menos ruidosos__.\n\nPodemos comprobar nuestra teor\u00eda extrayendo algunas canciones que sigan estas correlaciones:","27730187":"Hay algunas que eran de esperar como **feat**, **Remix** o nombres de algunos artistas famosos por hacer muchas colaboraciones, pero otras como **Psycho**, **Spider** o **Look** son m\u00e1s reveladoras.","366b7354":"Seg\u00fan la gr\u00e1fica, las canciones m\u00e1s **lentas** llegan m\u00e1s alto en el top, pero no es un dato fiable ya que solo hay **2 canciones** en ese grupo.","445460bd":"Tenemos **72585 instancias** en nuestro dataset, con **22 atributos**. Vamos a visualizar los primeros elementos y la informaci\u00f3n b\u00e1sica del __DataFrame__:","a55571df":"Ahora hay muchas m\u00e1s canciones que consiguen llegar hasta el **top 10**, aunque luego no se mantengan en \u00e9l.","fb0f4aa5":"> Hecho como trabajo final para el curso de [Python Cient\u00edfico de la FGULL](https:\/\/sede.fg.ull.es\/es\/curso\/detalle\/a19030180\/python-cientifico)","63e6a3a9":"Vamos a agrupar las canciones en __rangos de 10 en 10__ y ver como se distribuyen a lo largo del Dataset","04bbb101":"Vamos a eliminar todos los audio features con una importancia < 0.10 y aplicar el **Random Forest**, escogiendo para el hiperpar\u00e1metro `max_depth` el valor que de mejor resultado.","049d090b":"## Informaci\u00f3n\n\n### Top 100 Spotify Songs with audio feat. (2017-2018)\n\nSe ha creado un dataset inspirado en la combinaci\u00f3n de los dos siguientes: [Spotify Worldwide Daily Song Ranking](https:\/\/www.kaggle.com\/edumucelli\/spotifys-worldwide-daily-song-ranking]), que contiene, para 53 pa\u00edses, los datos de las 200 canciones m\u00e1s reproducidas cada d\u00eda, y [Spotify Song Attributes](https:\/\/www.kaggle.com\/geomack\/spotifyclassification), que contienen __features__ asociadas a cada canci\u00f3n (_energy_, _danceability_, _key_...).\n\nEl dataset resultante es [Top 100 Spotify Songs with audio feat. (2017-2018)](https:\/\/www.kaggle.com\/davafons\/top-100-spotify-songs-with-audio-feat-20172018). Los datos se han extra\u00eddo directamente de [Spotify Charts](https:\/\/spotifycharts.com\/regional) y de la [API de Spotify](https:\/\/developer.spotify.com\/documentation\/web-api\/reference\/tracks\/get-audio-features\/). ","d96ff352":"Hay __muy pocas canciones__ entre la posici\u00f3n 1 y la 30 en comparaci\u00f3n con el resto de posiciones. Esto es debido a que es __complicado__ que una canci\u00f3n llegue a __escalar__ tanto en el top y se mantenga en posiciones altas. Este __desbalanceo__ entre las clases puede que nos de problema en un futuro cuando estemos aplicando algoritmos de __clasificaci\u00f3n__.\n\nPodemos probar otra alternativa, y es agrupar las canciones por la __mejor posici\u00f3n__ que han conseguido, en vez de la __posici\u00f3n media__.\nEn este caso, como tener una buena posici\u00f3n es est\u00e1r m\u00e1s cerca de 1, filtraremos por el __menor valor del atributo `position` conseguido__.","0cef77f3":"Parece que la mayor\u00eda de canciones utilizan `Do#` y `Sol`, mientras que las menos populares son `Re#` y `Mi`","e39c6ecd":"Lo que m\u00e1s salta a la vista es que hay una __fuerte relaci\u00f3n directa__ entre los atributos _loudness_ y _energy_.","35c13bf3":"Parece que tras eliminar un par de atributos, la precisi\u00f3n de nuestro modelo sube en un **0.066%** hasta **0.637%** de acierto. Vamos a probar tambi\u00e9n a escoger el hiperpar\u00e1metro K de manera m\u00e1s inteligent","bec2fd32":"## \u00bfC\u00f3mo se distribuye el \"tempo musical\" en las canciones?\nUno de nuestros atributos era el __tempo__ (beats per minute), que med\u00eda la velocidad de una canci\u00f3n. Podemos probar a redefinir este atributo agrup\u00e1ndolo en __rangos de tempo__, al igual que se hace en la m\u00fasica:\n  * __length__: Muy lento (20 bpm)\n  * __adagio__: Lento y majestuoso (66 a 76 bpm)\n  * __andante__: Ritmo tranquilo (76 a 108 bpm)\n  * __allegro__: Animado y r\u00e1pido (108 a 168 bpm)\n  * __presto__: Muy r\u00e1pido (168 a 200 bpm)","ceeceb47":"## Palabras m\u00e1s frecuentes en los nombres de canciones","d63af5b3":"Nos interesa profundizar en las __\"audio features\"__, como ver cuales est\u00e1n m\u00e1s relacionadas. Vamos a definir una nueva variable con los headers correspondientes a las audio features, y los representaremos en un __pair plot__.","f5e53095":"Una breve descripci\u00f3n de los __atributos__:\n* __position__: Posici\u00f3n en el ranking en ese d\u00eda.\n* __stream__: N\u00famero de reproducciones en ese d\u00eda.\n* __year__: A\u00f1o del ranking.\n* __month__: Mes del ranking.\n* __d\u00eda__: D\u00eda del ranking.\n* __danceability__: Que tan bailable es una canci\u00f3n (0.0 - 1.0)\n* __energy__: Medida de intensidad y actividad. Las canciones energ\u00e9ticas son r\u00e1pidas y ruidosas (Por ejemplo, Death Metal), mientras que un preludio de Bach tendr\u00eda una intensidad baja.\n* __key__: Clave de la canci\u00f3n. Los valores que toma son Do (0), Do#\/\u266d (1), Re (2) ... hasta Si(11). Si no se pudo detectar una clave, el valor es -1.\n* __loudness__: Media del ruido de una canci\u00f3n (en dB).\n* __mode__: Modalidad de la canci\u00f3n: Menor (0) o Mayor (1).\n* __speechiness__: Presencia de palabras habladas en la pista de audio. Por encima de 0.66 son audios donde solo hay casi exclusivamente voz. Entre 0.66 y 0.33 entran canciones que combinan tanto m\u00fasica como voz (por ejemplo, el rap). Por debajo de 0.33 estar\u00eda la m\u00fasica y otros audios sin voz.\n* __acousticness__: Confianza de que una canci\u00f3n sea m\u00e1s o menos ac\u00fastica (vs digital).\n* __instrumentalness__: Si una canci\u00f3n contiene o no voces.\n* __liveness__: Si una canci\u00f3n se ha grabado \"en vivo\" o no. Por encima de 0.8 es muy probable que sea en vivo.\n* __valence__: El positivismo de una canci\u00f3n. Cuando el valor es cercano a 1.0, la canci\u00f3n es m\u00e1s alegre, mientras que las canciones con valencia baja tienden a ser m\u00e1s tristes.\n* __tempo__: El tempo medio estimado en \"beats per minute\" (BPM). Es sin\u00f3nimo de la velocidad de una canci\u00f3n.\n* __duration_ms__: Duraci\u00f3n total del track.\n* __time_signature__: Comp\u00e1s medio del track. Mide las pulsaciones que hay por cada comp\u00e1s.","6182cda9":"# Analizando las canciones\n\nEn nuestro dataset tenemos la posici\u00f3n que va alcanzando una canci\u00f3n en el ranking cada d\u00eda, por lo que habr\u00e1n canciones que aparecer\u00e1n **repetidas** en d\u00edas diferentes.\n\nVamos a quedarnos con todas las **canciones \u00fanicas**. En caso de que una canci\u00f3n haya aparecido varios d\u00edas diferentes, para el valor del atributo **posici\u00f3n** nos quedaremos con la media de las posiciones que haya conseguido.\n\nTambi\u00e9n, eliminaremos los atributos **Year**, **Month** y **Day**, que ya no tienen sentido.","f9be4f0e":"Se puede ver como la mayor\u00eda de canciones tienen un tempo __allegro__ o __andante__. \n\nPodr\u00edamos coger solo las canciones que han llegado al top 10 y _agruparlas seg\u00fan el tempo_, por ver si predomina alg\u00fan grupo."}}