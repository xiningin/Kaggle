{"cell_type":{"e67c6adb":"code","fa2190f9":"code","f50c2bc8":"code","8cd8f8c9":"code","eda0a71d":"code","12c0a244":"code","25f61459":"code","f25d17c7":"code","c26cf3f7":"code","4231fe4d":"code","5a5f9b1b":"code","bce06e76":"code","121d86a3":"code","75de58d7":"code","1a665291":"markdown","fc429a54":"markdown","cf590190":"markdown","df1d9e59":"markdown","c504efab":"markdown"},"source":{"e67c6adb":"from tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.datasets import cifar10\nimport matplotlib.pyplot as plt\nimport cv2\nimport numpy as np","fa2190f9":"(x_train,y_train),(x_test,y_test) = cifar10.load_data()","f50c2bc8":"print(x_train.shape)\nprint(\"Train Sapmle\",x_train.shape[0]) ","8cd8f8c9":"numberOfClass = 10\ny_train = to_categorical(y_train, numberOfClass)\ny_test = to_categorical(y_test, numberOfClass)\nprint(y_train)","eda0a71d":"input_shape = x_train.shape[1:]\ninput_shape","12c0a244":"plt.imshow(x_train[6161].astype(np.uint8))\nplt.axis(\"off\")\nplt.show()\nold_image = x_train[6161]\nprint(x_train[5511].shape)","25f61459":"def resize_img(img):\n    numberOfImage = img.shape[0]\n    new_array = np.zeros((numberOfImage,48,48,3))\n    for i in range(numberOfImage):\n        new_array[i] = cv2.resize(img[i,:,:,:],(48,48))\n    return new_array\nx_train = resize_img(x_train)\nx_test = resize_img(x_test)\nprint(\"Increased dim x_train\",x_train.shape)","f25d17c7":"plt.figure()\nplt.axis(\"off\")\nplt.imshow(x_train[6161].astype(np.uint8))\nplt.figure()\nplt.imshow(old_image.astype(np.uint8))\nplt.axis(\"off\")\nplt.show()","c26cf3f7":"vgg = VGG19(include_top = False,#Fully connected layers not added # What is Fully connected layer: https:\/\/iq.opengenus.org\/fully-connected-layer\/\n            weights=\"imagenet\",#let my data be trained in imagenet\n            input_shape=(48,48,3))","4231fe4d":"vgg.summary()","5a5f9b1b":"vgg_layer_list = vgg.layers\nmodel = Sequential()\nfor layer in vgg_layer_list:\n    model.add(layer)\n    \nfor layer in model.layers: #Because we are doing Transfer Learning, we are not retraining the pre-trained layers of our model.\n    layer.trainable = False\n    \n#The layers we will train    \nmodel.add(Flatten())\nmodel.add(Dense(128))\nmodel.add(Dense(numberOfClass, activation=\"softmax\"))\nmodel.summary()","bce06e76":"model.compile(loss=\"categorical_crossentropy\",\n             optimizer = \"rmsprop\",\n             metrics = [\"accuracy\"])","121d86a3":"hist = model.fit(x_train,y_train,\n                 validation_split=0.2,\n                epochs = 25,\n                batch_size = 1000)","75de58d7":"plt.plot(hist.history[\"loss\"], label = \"Train loss\")\nplt.plot(hist.history[\"val_loss\"], label = \"Val loss\")\nplt.legend()\nplt.show()\nplt.plot(hist.history[\"accuracy\"], label = \"Train acc\")\nplt.plot(hist.history[\"val_accuracy\"], label = \"Val acc\")\nplt.legend()\nplt.show()","1a665291":"# **To_Categorical**\ny_train = [2]\n\ny_train = to_categorical(y_train, 5)\n\ny_train = [[0,1,0,0,0,]]","fc429a54":"# Visualize","cf590190":"# Increase the size of images\n\nSince our VGG model has an input size of (48,48), we need to increase the size of the images.","df1d9e59":"# Import necessary libraries","c504efab":"# VGG19"}}