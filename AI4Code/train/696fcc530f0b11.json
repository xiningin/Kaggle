{"cell_type":{"be50576a":"code","918aca26":"code","798c40e2":"code","cb9939ec":"code","fb013b54":"code","8af8a7c6":"code","d1f022bd":"code","dad081c0":"code","c63c4612":"code","415167bc":"code","d65954c8":"code","eead5ee8":"markdown","382b73d1":"markdown","3a6239aa":"markdown"},"source":{"be50576a":"import pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nimport transformers\nfrom transformers import AlbertTokenizer, AlbertModel\nfrom tqdm import tqdm\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.model_selection import train_test_split\nimport umap\nimport matplotlib.pyplot as plt\nimport time\ntqdm.pandas()","918aca26":"device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n\ntrain = pd.read_csv(\"..\/input\/data-science-winter-osaka2\/train.csv\")\ntest = pd.read_csv(\"..\/input\/data-science-winter-osaka2\/test.csv\")","798c40e2":"#\u6b63\u89e3\u30e9\u30d9\u30eb\u306e\u4ed8\u3051\u66ff\u3048\ntrain[\"user_reviews_int\"] = train[\"user_reviews\"].map({'c0':0, 'c1':1, 'c2':2})\ntrain['description'] = train['description'].fillna(\"NaN\")\ntest['description'] = test['description'].fillna(\"NaN\")\n\nprint(train.shape)\nprint(test.shape)","cb9939ec":"#\u8a13\u7df4\u7528loader\nclass Description_dataset(Dataset):\n    def __init__(self, df, \n                 features=\"description\",\n                 label=\"user_reviews_int\",\n                 model_name = 'albert-base-v1',\n                 max_len=512,\n                 for_train=False):\n        self.features_values = df[features].values\n        self.tokenizer = AlbertTokenizer.from_pretrained(model_name)\n        self.max_len = max_len\n        self.for_train = for_train\n        if self.for_train == True:\n            self.label = df[label]\n\n    # len()\u3092\u4f7f\u7528\u3059\u308b\u3068\u547c\u3070\u308c\u308b\n    def __len__(self):\n        return len(self.features_values)\n\n    # \u8981\u7d20\u3092\u53c2\u7167\u3059\u308b\u3068\u547c\u3070\u308c\u308b\u95a2\u6570    \n    def __getitem__(self, index):\n        text = self.features_values[index]#text\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u3080\n        inputs = self.tokenizer.encode_plus(\n              text,\n              add_special_tokens=True,\n              max_length=self.max_len,\n              padding='max_length',\n              truncation=True\n            )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n        \n        if self.for_train == True: \n            return {\n              'ids': torch.LongTensor(ids),\n              'mask': torch.LongTensor(mask),\n              'label': torch.tensor(self.label[index]),\n            }\n        else:\n            return {\n          'ids': torch.LongTensor(ids),\n          'mask': torch.LongTensor(mask)\n            }","fb013b54":"\"\"\"\n#\u52d5\u4f5c\u78ba\u8a8d for_train=True\u3067\u6b63\u89e3\u30e9\u30d9\u30eb\u3082\u8fd4\u3059\ndataset_train = Description_dataset(train, for_train=True)\ntrain_loader = DataLoader(dataset_train, batch_size=64)\nfor batch in train_loader:\n    print(batch[\"ids\"].shape, batch[\"mask\"].shape, batch[\"label\"].shape)\n    break\n\"\"\"","8af8a7c6":"\"\"\"\n#\u52d5\u4f5c\u78ba\u8a8d for_train=False\u3067\u6b63\u89e3\u30e9\u30d9\u30eb\u306f\u8fd4\u3055\u306a\u3044\ndataset_valid = Description_dataset(train, for_train=False)\nvalid_loader = DataLoader(dataset_valid, batch_size=64)\nfor batch in valid_loader:\n    print(batch[\"ids\"].shape, batch[\"mask\"].shape)\n    break\n\"\"\"","d1f022bd":"df_train, df_valid = train_test_split(train, stratify=train[\"user_reviews_int\"], random_state=100, test_size=0.1)#\u8a13\u7df4\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u8a55\u4fa1\u30c7\u30fc\u30bf\u306b\u5206\u5272\ndf_train.reset_index(inplace=True)#dataloader\u3067\u30a8\u30e9\u30fc\u3092\u5410\u304f\u306e\u3067\u3001index\u3092\u632f\u308a\u76f4\u3059\ndf_valid.reset_index(inplace=True)#dataloader\u3067\u30a8\u30e9\u30fc\u3092\u5410\u304f\u306e\u3067\u3001index\u3092\u632f\u308a\u76f4\u3059\ndataset_train = Description_dataset(df_train, for_train=True)#\u6b63\u89e3\u30e9\u30d9\u30eb\u3082\u53d6\u5f97\u3057\u305f\u3044\u306e\u3067\u3001for_train=True\ndataset_valid = Description_dataset(df_valid, for_train=True)\ntrain_loader = DataLoader(dataset_train, batch_size=16, shuffle=True)\nvalid_loader = DataLoader(dataset_valid, batch_size=16, shuffle=False)\n\n#\u8f9e\u66f8\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b\u307e\u3068\u3081\u308b\ndataloaders_dict = {\"train\":train_loader, \"val\":valid_loader}","dad081c0":"from transformers import AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"albert-base-v1\", num_labels=3).to(device)\nprint(model.classifier)#\u5148\u982d\u306bsoftmax\u5c64\u3092\u8ffd\u52a0\u3057\u305f\u30e2\u30c7\u30eb\u3092\u4f5c\u6210\u3092\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u5316","c63c4612":"criterion = torch.nn.CrossEntropyLoss()\n#\u30aa\u30d7\u30c6\u30a3\u30de\u30a4\u30b6\nfrom transformers import AdamW","415167bc":"# \u30e2\u30c7\u30eb\u3092\u5b66\u7fd2\u3055\u305b\u308b\u95a2\u6570\u3092\u4f5c\u6210\ndef train_model(net, dataloaders_dict, criterion, num_epochs):\n    # GPU\u304c\u4f7f\u3048\u308b\u304b\u3092\u78ba\u8a8d\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    print(\"\u4f7f\u7528\u30c7\u30d0\u30a4\u30b9\uff1a\", device)\n    print('-----start-------')\n\n    # \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092GPU\u3078\n    net.to(device)\n    \n    #optimizer\u306e\u8a2d\u5b9a\n    optimizer= AdamW(net.parameters(), lr=5e-5)\n\n    # \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u304c\u3042\u308b\u7a0b\u5ea6\u56fa\u5b9a\u3067\u3042\u308c\u3070\u3001\u9ad8\u901f\u5316\u3055\u305b\u308b\n    torch.backends.cudnn.benchmark=True\n\n    #\u30df\u30cb\u30d0\u30c3\u30c1\u306e\u30b5\u30a4\u30ba\u3092\u53d6\u5f97\n    batch_size = dataloaders_dict[\"train\"].batch_size\n\n    #epoch\u306e\u30eb\u30fc\u30d7\n    for epoch in range(num_epochs):\n        # epoch\u3054\u3068\u306e\u8a13\u7df4\u3068\u691c\u8a3c\u306e\u30eb\u30fc\u30d7\n        for phase in [\"train\", \"val\"]:\n            if phase == \"train\":\n                net.train() # \u30e2\u30c7\u30eb\u3092\u8a13\u7df4\u30e2\u30fc\u30c9\u306b\n            else:\n                net.eval() # \u30e2\u30c7\u30eb\u3092\u691c\u8a3c\u30e2\u30fc\u30c9\u306b\n\n            epoch_loss = 0.0 # epoch\u306e\u640d\u5931\u548c\n            epoch_corrects = 0 # epoch\u306e\u6b63\u89e3\u6570\n            iteration = 1\n\n            # \u958b\u59cb\u6642\u523b\u3092\u4fdd\u5b58\n            t_epoch_start = time.time()\n            t_iter_start = time.time()\n\n            # \u30c7\u30fc\u30bf\u30ed\u30fc\u30c0\u30fc\u304b\u3089\u30df\u30cb\u30d0\u30c3\u30c1\u3092\u53d6\u308a\u51fa\u3059\u30eb\u30fc\u30d7\n            for batch in (dataloaders_dict[phase]):\n                # GPU\u304c\u4f7f\u3048\u308b\u306a\u3089GPU\u306b\u30c7\u30fc\u30bf\u3092\u9001\u308b\n                batch = {k: v.to(device) for k, v in batch.items()}\n\n                # optimizer\u3092\u521d\u671f\u5316\n                optimizer.zero_grad()\n\n                # \u9806\u4f1d\u642c\uff08forward\uff09\u8a08\u7b97\n                with torch.set_grad_enabled(phase == \"train\"):\n\n                    outputs = model(batch[\"ids\"], batch[\"mask\"])\n                    loss = criterion(outputs.logits, batch[\"label\"])\n\n\n                    _, preds = torch.max(outputs.logits, 1)# \u30e9\u30d9\u30eb\u3092\u4e88\u6e2c\n\n                    # \u8a13\u7df4\u6642\u306f\u30d0\u30c3\u30af\u30d7\u30ed\u30d1\u30b2\u30fc\u30b7\u30e7\u30f3\n                    if phase == \"train\":\n                        loss.backward()\n                        optimizer.step()\n\n                        if (iteration % 50 == 0):# 50iter\u306b1\u5ea6\u3001loss\u3092\u8868\u793a\n                            t_iter_finish = time.time()\n                            duration = t_iter_finish - t_iter_start\n                            acc = (torch.sum(preds == batch[\"label\"])).double()\/batch_size\n                            print(f'\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3 {iteration} || Loss: {loss.item():.4f} || 50iter: {duration:.4f} sec. || \u672c\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u306e\u6b63\u89e3\u7387\uff1a{acc}')\n                            t_iter_start = time.time()\n\n\n                    iteration += 1\n                    # \u640d\u5931\u3068\u6b63\u89e3\u6570\u306e\u5408\u8a08\u3092\u66f4\u65b0\n                    epoch_loss += loss.item() * batch_size\n                    epoch_corrects += torch.sum(preds == batch[\"label\"])\n\n                    \n            # epoch\u3054\u3068\u306eloss\u3068\u6b63\u89e3\u7387\n            t_epoch_finish = time.time\n            epoch_loss = epoch_loss \/ len(dataloaders_dict[phase].dataset)\n            epoch_acc = epoch_corrects.double()\/len(dataloaders_dict[phase].dataset)\n            print(f'Epoch {epoch+1}\/{num_epochs} | {phase:^5} |  Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n            t_epoch_start = time.time()\n\n\n\n    return net","d65954c8":"tuned_model = train_model(net=model, \n            dataloaders_dict=dataloaders_dict, \n            criterion=criterion, \n            num_epochs=3)\n#\u5b66\u7fd2\u3057\u305f\u91cd\u307f\u306e\u4fdd\u5b58\ntorch.save(tuned_model.state_dict(), 'tuned_albert.pth')\nprint(\"all DONE!!!\")","eead5ee8":"## bert\u306efinetune","382b73d1":"## ALBERT\u3092\u5b66\u7fd2\u3055\u305b\u308b\n- \u5b66\u7fd2\u6e08\u307f\u306ealbert\u3067\u306f\u7dba\u9e97\u306bembed\u306e\u7d50\u679c\u304c\u5206\u304b\u308c\u306a\u304b\u3063\u305f\u306e\u3067\u3001finetune\u3092\u3092\u5b9f\u65bd\u3059\u308b\u3002\n- \u672cnotebook\u3067\u306f\u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\u307e\u3067\u3092\u5b9f\u65bd\u3059\u308b\u3002","3a6239aa":"### dataset\u306e\u4f5c\u6210"}}