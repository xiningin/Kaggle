{"cell_type":{"a6ffc0b2":"code","638f5c5a":"code","a1223dd0":"code","da378ff7":"code","7727cd9d":"code","d4f2cecf":"code","755a47db":"code","a6757e37":"code","be294906":"code","314a782b":"code","1722a4d0":"code","d3259fb6":"code","adebb73f":"code","d22c1b53":"code","980bfd2b":"code","5fab797f":"code","c9ec0a99":"code","ecbcd1c7":"code","af7c0baa":"code","417c1f4a":"code","3b826a35":"code","bccdd1fd":"code","0d506385":"code","ef4bd68a":"code","59888667":"code","920cac34":"code","f5c4c0da":"code","42333f1e":"code","eedcf012":"code","b4d3fa69":"code","d5deb670":"code","222118f1":"code","10b92e2b":"code","e3fb3816":"code","be7be6e3":"code","eeec3aa7":"code","0719d5d3":"code","4062c206":"code","70499e78":"code","04bbc537":"code","da099e28":"code","c2f6e0ad":"code","69b42161":"code","c1a6b5a1":"code","2bbfabc9":"code","615615c2":"code","7846e68e":"code","7dfba26e":"code","7b5925ba":"code","1daf5c44":"code","1b19b40d":"code","e39e035b":"code","54a058df":"code","ccf3c053":"code","1a1509b7":"code","d3a6de15":"code","d26bffcf":"code","dea8526b":"code","3c32e367":"code","bfec7cc9":"code","f75e84bc":"markdown","66489dbe":"markdown","188da198":"markdown","1672ebdb":"markdown","9ac6ee03":"markdown","ed98a391":"markdown","944239b7":"markdown","1bb676dd":"markdown","0b2cd092":"markdown","63cbe242":"markdown","c2334984":"markdown","4fb65c56":"markdown","d84fad35":"markdown","d349e0c9":"markdown","c318b90f":"markdown","78be4789":"markdown","84aaaef1":"markdown","27f72a9e":"markdown","1c8c1aa7":"markdown","d7e04f86":"markdown","08c1c560":"markdown","8511bd3e":"markdown","2f0999be":"markdown","cd6c09cf":"markdown","040cf8f3":"markdown","b608a923":"markdown","75d6b18c":"markdown"},"source":{"a6ffc0b2":"# Common lib\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n\n# Utils\nfrom tqdm import tqdm\n\n# Sklearn\nfrom sklearn.model_selection import train_test_split\n\n# Tensorflow\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Add, MaxPooling2D, Flatten, AveragePooling2D, Dense\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.metrics import AUC, TruePositives, TrueNegatives, FalsePositives, FalseNegatives\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img","638f5c5a":"input_path = '..\/input\/coronahack-chest-xraydataset'\nmetadata = pd.read_csv(os.path.join(input_path, 'Chest_xray_Corona_Metadata.csv'), index_col=0)\nsummary = pd.read_csv(os.path.join(input_path, 'Chest_xray_Corona_dataset_Summary.csv'), index_col=0)\n\nmetadata.sample(5)","a1223dd0":"# Split to train - test df\ntrain_df = metadata[metadata.Dataset_type == 'TRAIN'].reset_index(drop=True)\ntest_df = metadata[metadata.Dataset_type == 'TEST'].reset_index(drop=True)\nassert train_df.shape[0] + test_df.shape[0] == metadata.shape[0]\nprint(f'Train df shape: {train_df.shape}')\nprint(f'Test df shape: {test_df.shape}')","da378ff7":"# Count null values\nprint(f'Count of null values in train:\\n{train_df.isnull().sum()}')\nprint(f'Count of null values in test:\\n{test_df.isnull().sum()}')","7727cd9d":"# Fill null value by unknow \ntrain_df = train_df.fillna('unknow')\ntest_df = test_df.fillna('unknow')\n\ntrain_df.sample(5)","d4f2cecf":"col = ['Label', 'Label_1_Virus_category', 'Label_2_Virus_category']\n\nsns.set_theme(style='darkgrid')\nfig = plt.figure(figsize=(14, 14))\nfor i in range(3):\n    ax = plt.subplot(2, 2, i + 1)\n    ax = sns.countplot(x=col[i], data=train_df)\n    ax.set_title(f'Number of each value in {col[i]} column')\nfig.suptitle('Count value in train_df')\nplt.show()","755a47db":"pnemonia_df = train_df[train_df.Label == 'Pnemonia']\nprint(f'Number of pnemonia in training dataset: { len(pnemonia_df) }')","a6757e37":"fig = plt.figure(figsize=(15, 4))\nfor i in range(2):\n    ax = plt.subplot(1, 2, i+1)\n    ax = sns.countplot(x=col[i+1], data=pnemonia_df)\n    ax.set_title(f'Number of each value in {col[i + 1]} column')\nfig.suptitle('Count value in pnemonia_df')\nplt.show()","be294906":"pnemonia_without_unknow_df = pnemonia_df[pnemonia_df.Label_2_Virus_category != 'unknow']\nprint(f'Number of pnemonia without unknow value in Label_2_Virus_category: { len(pnemonia_without_unknow_df) }')","314a782b":"fig = plt.figure(figsize=(15, 4))\nfor i in range(2):\n    ax = plt.subplot(1, 2, i+1)\n    ax = sns.countplot(x=col[i+1], data=pnemonia_without_unknow_df)\n    ax.set_title(col[i+1])\nfig.suptitle('Count value in pnemonia_without_unknow_df')\nplt.show()","1722a4d0":"train_folder = os.path.join(input_path, 'Coronahack-Chest-XRay-Dataset', 'Coronahack-Chest-XRay-Dataset', 'train')\ntest_folder = os.path.join(input_path, 'Coronahack-Chest-XRay-Dataset', 'Coronahack-Chest-XRay-Dataset', 'test')\n\n# Make sure train and test folder existed\nassert os.path.isdir(train_folder)\nassert os.path.isdir(test_folder)","d3259fb6":"# Add column image path to dataframe\ntrain_img_path = pd.Series([os.path.join(train_folder, img_name) for img_name in train_df.X_ray_image_name], name='Image_path')\ntrain_df = pd.concat([train_df, train_img_path], axis=1)\n\ntest_img_path = pd.Series([os.path.join(test_folder, img_name) for img_name in test_df.X_ray_image_name], name='Image_path')\ntest_df = pd.concat([test_df, test_img_path], axis=1)\n\nprint(f'Shape of train_df after add column: { train_df.shape }')\nprint(f'Shape of test_df after add column: { test_df.shape }')","adebb73f":"normal_train_df = train_df[train_df.Label == 'Normal']\n# Make sure that normal_train_df doesnt have any virus category\nassert len(normal_train_df) == normal_train_df.Label_1_Virus_category.value_counts().unknow\nassert len(normal_train_df) == normal_train_df.Label_2_Virus_category.value_counts().unknow\nprint(f'Shape of normal_train_df: { normal_train_df.shape }')\n\ncovid19_train_df = train_df[(train_df.Label == 'Pnemonia') & (train_df.Label_2_Virus_category == 'COVID-19')]\nprint(f'Shape of covid19_train_df: { covid19_train_df.shape }')\n\nnormal_test_df = test_df[test_df.Label == 'Normal']\n# Make sure that normal_test_df doesnt have any virus category\nassert len(normal_test_df) == normal_test_df.Label_1_Virus_category.value_counts().unknow\nassert len(normal_test_df) == normal_test_df.Label_2_Virus_category.value_counts().unknow\nprint(f'Shape of normal_test_df: { normal_test_df.shape }')","d22c1b53":"covid19_test_df = test_df[(test_df.Label == 'Pnemonia') & (test_df.Label_2_Virus_category == 'COVID19')]\nprint(f'Number of sample in test_df: { len(covid19_test_df) }')","980bfd2b":"pnemonia_test_df = test_df[test_df.Label == 'Pnemonia']\n\nfig = plt.figure(figsize=(12, 5))\nfor i in range(2):\n    ax = plt.subplot(1, 2, i+1)\n    ax = sns.countplot(x=col[i + 1], data=pnemonia_test_df)\n    ax.set_title(f'Number of each value in { col[i + 1] } column')\nplt.suptitle('Count value in pnemonia_test_df')\nplt.show()","5fab797f":"print(f'Shape of covid19_train_df before split: { covid19_train_df.shape }')\nprint(f'Shape of covid19_test_df before split: { covid19_test_df.shape }')","c9ec0a99":"temp = covid19_train_df\ncovid19_train_df = temp[:48]\ncovid19_test_df = temp[48:]\n\nprint(f'Shape of covid19_train_df after split: { covid19_train_df.shape }')\nprint(f'Shape of covid19_test_df after split: { covid19_test_df.shape }')","ecbcd1c7":"print(f'Shape of normal_train_df: { normal_train_df.shape }')\nprint(f'Shape of covid19_train_df: { covid19_train_df.shape }')\nprint('-------------------------')\nprint(f'Shape of normal_test_df: { normal_test_df.shape }')\nprint(f'Shape of covid19_test_df: { covid19_test_df.shape }')","af7c0baa":"# Concatenate normal & covid19 df to form train & test dataset\ntrain_df = pd.concat([normal_train_df, covid19_train_df], axis=0).loc[:, ['Image_path', 'Label']]\ntest_df = pd.concat([normal_test_df, covid19_test_df], axis=0).loc[:, ['Image_path', 'Label']]\n\n# Change to 'negative' & 'positive' label\ntrain_df.Label = train_df.Label.map(lambda label: 'negative' if label == 'Normal' else 'positive')\ntest_df.Label = test_df.Label.map(lambda label: 'negative' if label == 'Normal' else 'positive')\n\n# Shuffle data\ntrain_df = train_df.sample(frac=1).reset_index(drop=True)\ntest_df = test_df.sample(frac=1).reset_index(drop=True)","417c1f4a":"# Split to validation dataset\ntrain_df, valid_df = train_test_split(train_df, test_size=0.2, shuffle=False)\nprint('Number of samples in training dataset: ', len(train_df))\nprint('Number of samples in validation dataset: ', len(valid_df))\nprint('Number of samples in test dataset: ', len(test_df))","3b826a35":"# Number of each label in dataset\ndatasets = [train_df, valid_df, test_df]\ntitles = ['Train set', 'Validation set', 'Test set']\nlabel = ['negative', 'positive']\n\nfig = plt.figure(figsize=(10, 10))\nfor i in range(3):    \n    dataset = datasets[i]\n    label_count = dataset.Label.value_counts()\n    count = [label_count[0], label_count[1]]\n    ax = plt.subplot(2, 2, i+1)\n    ax.bar(label, count, color=['b', 'r'])\n    ax.set_title('Number of each label in '+ titles[i])\n    for index, value in enumerate(count):\n        plt.text(index, value, value)\nplt.suptitle('Number of each label in dataset')\nplt.show()","bccdd1fd":"train_df.head()","0d506385":"# Plot first 6 image in train dataset\nfig = plt.figure(figsize=(15,20))\nfor i in range(6):\n    ax = plt.subplot(3, 2, i+1)\n    img_path = train_df.Image_path[i]\n    label = train_df.Label[i]\n    title = 'healthy'\n    img = load_img(img_path)\n    ax.axis('off')\n    ax.set_title(label)\n    ax.imshow(img)\n\nplt.tight_layout()","ef4bd68a":"# Plot 4 images and image histograms respectively of normal case\nfirst_four_normal_img_name = normal_train_df.X_ray_image_name.iloc[:4]\nfirst_four_normal_img_path = [os.path.join(train_folder, img_name) for img_name in first_four_normal_img_name]\n\nfig, ax = plt.subplots(4, 2, figsize=(15, 15))\nfor idx, img_path in enumerate(first_four_normal_img_path):\n    img = load_img(img_path)\n    # Plot image\n    ax[idx, 0].imshow(img)\n    ax[idx, 0].axis('off')\n    # Plot image histogram\n    img_arr = img_to_array(img)\n    ax[idx, 1].hist(img_arr.ravel(), 256, fc='b', ec='b') # ravel() flatten arr\n    if(idx == 0):\n        ax[idx, 0].set_title('Image')\n        ax[idx, 1].set_title('Image histograms')\nfig.suptitle('Normal Case')\nplt.show()","59888667":"# Plot 3 images and image histograms respectively of COVID19 case\nfour_covid19_img_name = covid19_train_df.X_ray_image_name.iloc[:4]\nfour_covid19_img_path = [os.path.join(train_folder, img_name) for img_name in four_covid19_img_name]\n\nfig, ax = plt.subplots(4, 2, figsize=(15, 15))\nfor idx, img_path in enumerate(four_covid19_img_path):\n    # Plot image\n    img = load_img(img_path)\n    ax[idx, 0].imshow(img)\n    ax[idx, 0].axis('off')\n    # Plot image histogram\n    img_arr = img_to_array(img)\n    ax[idx, 1].hist(img_arr.ravel(), 256, fc='b', ec='b')\n    if idx == 0:\n        ax[idx, 0].set_title('Images')\n        ax[idx, 1].set_title('Image histograms')\nfig.suptitle('COVID19 Case')\nplt.show()","920cac34":"train_batches = ImageDataGenerator().flow_from_dataframe(dataframe=train_df,\n                                                      x_col='Image_path',\n                                                      y_col='Label',\n                                                      target_size=(230, 230),\n                                                      class_mode='binary',\n                                                      batch_size=128,\n                                                      shuffle=True)\n\nvalid_batches = ImageDataGenerator().flow_from_dataframe(valid_df,\n                                                      x_col='Image_path',\n                                                      y_col='Label',\n                                                      target_size=(230, 230),\n                                                      class_mode='binary',\n                                                      batch_size=128,\n                                                      shuffle=True)\n\ntest_batches = ImageDataGenerator().flow_from_dataframe(test_df,\n                                                     x_col='Image_path',\n                                                     y_col='Label',\n                                                     target_size=(230, 230),\n                                                     class_mode='binary',\n                                                     batch_size=128,\n                                                     shuffle=False)","f5c4c0da":"# Create function to build 1 block of ResNet\ndef bottleneck_residual_block(X, kernel_size, filters, reduce=False, strides=1):\n    f1, f2, f3 = filters\n    X_shortcut = X\n    if reduce == True:\n        # Reduce shortcut\n        X_shortcut = Conv2D(filters=f3, kernel_size=1, strides=strides, padding='valid') (X_shortcut)\n        X_shortcut = BatchNormalization() (X_shortcut)\n        \n    # First component of main path\n    X = Conv2D(filters=f1, kernel_size=1, strides=strides, padding='valid') (X)\n    X = BatchNormalization() (X)\n    X = Activation('relu') (X)\n    \n    # Second component of main path\n    X = Conv2D(filters=f2, kernel_size=kernel_size, strides=1, padding='same') (X)\n    X = BatchNormalization() (X)\n    X = Activation('relu') (X)\n    \n    # Third component of main path\n    X = Conv2D(filters=f3, kernel_size=1, strides=1, padding='valid') (X)\n    X = BatchNormalization() (X)\n    \n    # Final step\n    X = Add() ([X, X_shortcut])\n    X = Activation('relu') (X)\n    \n    return X","42333f1e":"def ResNet50(input_shape):\n    X_input = Input(input_shape)\n    \n    # Stage 1\n    X = Conv2D(filters=64, kernel_size=7, strides=2, padding='valid', name='conv1') (X_input) # Output = (112, 112, 64)\n    X = BatchNormalization() (X)\n    X = Activation('relu') (X)\n    X = MaxPooling2D(pool_size=2, strides=2) (X) # Ouput = (56, 56, 64)\n    \n    # Stage 2\n    X = bottleneck_residual_block(X, 3, (64, 64, 256), True) # Ouput = (56, 56, 256)\n    X = bottleneck_residual_block(X, 3, (64, 64, 256)) \n    X = bottleneck_residual_block(X, 3, (64, 64, 256)) \n    \n    # Stage 3\n    X = bottleneck_residual_block(X, 3, (128, 128, 512), True, 2) # Ouput = (28, 28, 512)\n    X = bottleneck_residual_block(X, 3, (128, 128, 512)) \n    X = bottleneck_residual_block(X, 3, (128, 128, 512))\n    X = bottleneck_residual_block(X, 3, (128, 128, 512))\n    \n    # Stage 4\n    X = bottleneck_residual_block(X, 3, (256, 256, 1024), True, 2) # Ouput = (14, 14, 1024)\n    X = bottleneck_residual_block(X, 3, (256, 256, 1024))\n    X = bottleneck_residual_block(X, 3, (256, 256, 1024))\n    X = bottleneck_residual_block(X, 3, (256, 256, 1024))\n    X = bottleneck_residual_block(X, 3, (256, 256, 1024))\n    X = bottleneck_residual_block(X, 3, (256, 256, 1024))\n    \n    # Stage 5\n    X = bottleneck_residual_block(X, 3, (512, 512, 2048), True, 2) # Ouput = (7, 7, 2048)\n    X = bottleneck_residual_block(X, 3, (512, 512, 2048))\n    X = bottleneck_residual_block(X, 3, (512, 512, 2048))\n    \n    X = AveragePooling2D(pool_size=7) (X)\n    \n    X = Flatten() (X)    \n    X = Dense(units=1, activation='sigmoid', name='sigmoid') (X)\n    \n    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n    return model","eedcf012":"if not os.path.exists('models'):\n    os.mkdir('models')\nif not os.path.exists('models\/resnet50'):\n    os.mkdir('models\/resnet50')","b4d3fa69":"model_resnet50 = ResNet50((230, 230, 3))\n\nmetrics = [TruePositives(name='TP'),\n          FalsePositives(name='FP'),\n          TrueNegatives(name='TN'),\n          FalseNegatives(name='FN'),\n          AUC(curve='PR', name='AUC')]\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                             factor=np.sqrt(0.1),\n                             patience=5,\n                             min_lr=1e-7,\n                             min_delta = 1e-4,\n                             verbose=1)\n\nearly_stopping = EarlyStopping(monitor='val_loss',\n                              patience=10,\n                              min_delta=0,\n                              verbose=1,\n                              restore_best_weights=True)\n\"\"\"\ncheckpoint = ModelCheckpoint(filepath='models\/resnet50\/model-resnet50-{epoch:02d}.hdf5',\n                            monitor='val_loss',\n                            verbose=1,\n                            save_best_only=True,\n                            save_weights_only=False)\n\"\"\"\n\n\ncallbacks = [reduce_lr, early_stopping]","d5deb670":"model_resnet50.compile(loss='binary_crossentropy', optimizer='adam', metrics=metrics)\nhistory_resnet50 = model_resnet50.fit(train_batches, epochs=100, batch_size=128, verbose=1, validation_data=valid_batches,\n         callbacks=callbacks)","222118f1":"history_resnet50_df = pd.DataFrame(history_resnet50.history)","10b92e2b":"hist = [history_resnet50.history['AUC'], history_resnet50.history['val_AUC'],\n       history_resnet50.history['loss'], history_resnet50.history['val_loss']]\ntitle = ['Training AUC', 'Validation AUC', 'Training loss', 'Validation loss']\nylabel = ['auc value', 'auc value', 'loss value', 'loss value']\n\nfig = plt.figure(figsize=(10, 12))\nfor i in range(4):\n    ax = plt.subplot(2, 2, i+1)\n    ax = sns.lineplot(x=np.arange(len(hist[i])), y=hist[i])\n    ax.set_title(title[i])\n    ax.set_xlabel('epoch')\n    ax.set_ylabel(ylabel[i])\nplt.show()","e3fb3816":"history_resnet50_df.loc[:, ['loss', 'val_loss']].plot()\nplt.show()","be7be6e3":"history_resnet50_df.loc[:, ['AUC', 'val_AUC']].plot()\nplt.show()","eeec3aa7":"predict_resnet50 = model_resnet50.evaluate(test_batches, verbose=1)","0719d5d3":"tp, fp, tn, fn, auc = predict_resnet50[1], predict_resnet50[2], predict_resnet50[3], predict_resnet50[4], predict_resnet50[5]\nprint(f'True positive: { tp }')\nprint(f'False positive: { fp }')\nprint(f'True negative: { tn }')\nprint(f'False negative: { fn }')\nprint('AUC: %.2f' % auc)","4062c206":"!pip install git+https:\/\/github.com\/qubvel\/classification_models.git","70499e78":"from classification_models.tfkeras import Classifiers\n\n# Tensorflow\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam","04bbc537":"train_batches = ImageDataGenerator().flow_from_dataframe(dataframe=train_df,\n                                                      x_col='Image_path',\n                                                      y_col='Label',\n                                                      target_size=(224, 224),\n                                                      class_mode='binary',\n                                                      batch_size=128,\n                                                      shuffle=True)\n\nvalid_batches = ImageDataGenerator().flow_from_dataframe(valid_df,\n                                                      x_col='Image_path',\n                                                      y_col='Label',\n                                                      target_size=(224, 224),\n                                                      class_mode='binary',\n                                                      batch_size=128,\n                                                      shuffle=True)\n\ntest_batches = ImageDataGenerator().flow_from_dataframe(test_df,\n                                                     x_col='Image_path',\n                                                     y_col='Label',\n                                                     target_size=(224, 224),\n                                                     class_mode='binary',\n                                                     batch_size=128,\n                                                     shuffle=False)","da099e28":"ResNet34, preprocess_input = Classifiers.get('resnet34')\nbase_model = ResNet34((224, 224, 3), weights='imagenet', include_top=False)\nx = GlobalAveragePooling2D() (base_model.output)\noutput = Dense(1, activation='sigmoid') (x)\nmodel_resnet34 = Model(inputs=base_model.input, outputs=output)","c2f6e0ad":"if not os.path.exists('models'):\n    os.mkdir('models')\nif not os.path.exists('models\/resnet34'):\n    os.mkdir('models\/resnet34')","69b42161":"metrics = [TruePositives(name='TP'),\n          FalsePositives(name='FP'),\n          TrueNegatives(name='TN'),\n          FalseNegatives(name='FN'),\n          AUC(curve='PR', name='AUC')]\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                             factor=np.sqrt(0.1),\n                             patience=5,\n                             min_lr=1e-7,\n                             min_delta = 1e-4,\n                             verbose=1)\n\nearly_stopping = EarlyStopping(monitor='val_loss',\n                              patience=10,\n                              min_delta=0,\n                              verbose=1,\n                              restore_best_weights=True)\n\n\"\"\"\ncheckpoint = ModelCheckpoint(filepath='models\/resnet34\/model-resnet34-{epoch:02d}.hdf5',\n                            monitor='val_loss',\n                            verbose=1,\n                            save_best_only=True,\n                            save_weights_only=False)\n\"\"\"\n\n\ncallbacks = [reduce_lr, early_stopping]","c1a6b5a1":"model_resnet34.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-4), metrics=metrics)\nhistory_resnet34 = model_resnet34.fit(train_batches, epochs=100, batch_size=128, verbose=1, validation_data=valid_batches,\n         callbacks=callbacks)","2bbfabc9":"history_resnet34_df = pd.DataFrame(history_resnet34.history)","615615c2":"history_resnet34_df.loc[:, ['loss', 'val_loss']].plot()\nplt.show()","7846e68e":"history_resnet34_df.loc[:, ['AUC', 'val_AUC']].plot()\nplt.show()","7dfba26e":"hist = [history_resnet34_df['AUC'], history_resnet34_df['val_AUC'],\n       history_resnet34_df['loss'], history_resnet34_df['val_loss']]\ntitle = ['Training AUC', 'Validation AUC', 'Training loss', 'Validation loss']\nylabel = ['auc value', 'auc value', 'loss value', 'loss value']\n\nfig = plt.figure(figsize=(10, 12))\nfor i in range(4):\n    ax = plt.subplot(2, 2, i+1)\n    ax = sns.lineplot(x=np.arange(len(hist[i])), y=hist[i])\n    ax.set_title(title[i])\n    ax.set_xlabel('epoch')\n    ax.set_ylabel(ylabel[i])\nplt.show()","7b5925ba":"evaluate_resnet34 = model_resnet34.evaluate(test_batches, verbose=1)","1daf5c44":"tp, fp, tn, fn, auc = evaluate_resnet34[1], evaluate_resnet34[2], evaluate_resnet34[3], evaluate_resnet34[4], evaluate_resnet34[5]\nprint(f'True positive: { tp }')\nprint(f'False positive: { fp }')\nprint(f'True negative: { tn }')\nprint(f'False negative: { fn }')\nprint('AUC: %.2f' % auc)","1b19b40d":"from tensorflow.keras.applications import ResNet50","e39e035b":"base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\nX = AveragePooling2D(pool_size=7) (base_model.output)\nX = Flatten() (X)\nX = Dense(1, activation='sigmoid') (X)\nfine_tuning_resnet50 = Model(inputs=base_model.input, outputs=X)","54a058df":"metrics = [TruePositives(name='TP'),\n          FalsePositives(name='FP'),\n          TrueNegatives(name='TN'),\n          FalseNegatives(name='FN'),\n          AUC(curve='PR', name='AUC')]\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                             factor=np.sqrt(0.1),\n                             patience=5,\n                             min_lr=1e-7,\n                             min_delta = 1e-4,\n                             verbose=1)\n\nearly_stopping = EarlyStopping(monitor='val_loss',\n                              patience=10,\n                              min_delta=0,\n                              verbose=1,\n                              restore_best_weights=True)\n\n\ncallbacks = [reduce_lr, early_stopping]","ccf3c053":"fine_tuning_resnet50.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-4), metrics=metrics)\nhistory_ft_resnet50 = fine_tuning_resnet50.fit(train_batches, epochs=100, batch_size=128, verbose=1, validation_data=valid_batches,\n         callbacks=callbacks)","1a1509b7":"history_ft_resnet50_df = pd.DataFrame(history_ft_resnet50.history)","d3a6de15":"history_ft_resnet50_df.loc[:, ['loss', 'val_loss']].plot()\nplt.show()","d26bffcf":"history_ft_resnet50_df.loc[:, ['AUC', 'val_AUC']].plot()\nplt.show()","dea8526b":"hist = [history_ft_resnet50_df['AUC'], history_ft_resnet50_df['val_AUC'],\n       history_ft_resnet50_df['loss'], history_ft_resnet50_df['val_loss']]\ntitle = ['Training AUC', 'Validation AUC', 'Training loss', 'Validation loss']\nylabel = ['auc value', 'auc value', 'loss value', 'loss value']\n\nfig = plt.figure(figsize=(10, 12))\nfor i in range(4):\n    ax = plt.subplot(2, 2, i+1)\n    ax = sns.lineplot(x=np.arange(len(hist[i])), y=hist[i])\n    ax.set_title(title[i])\n    ax.set_xlabel('epoch')\n    ax.set_ylabel(ylabel[i])\nplt.show()","3c32e367":"evaluate_resnet50 = fine_tuning_resnet50.evaluate(test_batches, verbose=1)","bfec7cc9":"tp, fp, tn, fn, auc = evaluate_resnet50[1], evaluate_resnet50[2], evaluate_resnet50[3], evaluate_resnet50[4], evaluate_resnet50[5]\nprint(f'True positive: { tp }')\nprint(f'False positive: { fp }')\nprint(f'True negative: { tn }')\nprint(f'False negative: { fn }')\nprint('AUC: %.2f' % auc)","f75e84bc":"`covid19_test_df` doesnt have any `COVID-19` case in `Label_2_Virus_category`. So we handle this problem by move 10 `COVID19` data from `covid19_train_df` to `covid19_test_df` all values in `Label` column by 1","66489dbe":"# 1.1 Import libs","188da198":"# Version 1 - Build ResNet50 from scratch","1672ebdb":"> We just classify normal case with pnemonia caused by COVID-19 so we will split the dataset with labels normal and COVID-19","9ac6ee03":"# 1.3 Prepare data","ed98a391":"# 2.1 Import libs","944239b7":"# 1.6 Build model","1bb676dd":"# 1.2 Exploring data","0b2cd092":"![Screen Shot 2021-05-27 at 22.51.18.png](attachment:7d4265c9-6d63-4033-a1bc-d715224ee095.png)\n\n**ResNet architecture**","63cbe242":"# Version 3 - Fine tuning ResNet50","c2334984":"# 2.5 Evaluate","4fb65c56":"# 3.3 Compile model","d84fad35":"## 1.4.1 Image histogram","d349e0c9":"> An image histogram is a type of histogram that acts as a graphical representation of the tonal distribution in a digital image. It plots the number of pixels for each tonal value. By looking at the histogram for a specific image a viewer will be able to judge the entire tonal distribution at a glance.\n\nSource: [https:\/\/en.wikipedia.org\/wiki\/Image_histogram](http:\/\/)","c318b90f":"# 3.4 Evaluate model","78be4789":"# 1.4 Visualize images","84aaaef1":"# 2.2 Data augmentation","27f72a9e":"> From the chart above, we can see this is imbalanced dataset. So we will use AUC as a metric for evaluating our model","1c8c1aa7":"# 2.3 Fine tuning ResNet34","d7e04f86":"# 1.7 Evaluate","08c1c560":"# 1.5 Image data generator (not augmentation)","8511bd3e":"# 3.2 Build model","2f0999be":"# **Classify covid-19 and normal label from x-ray images**","cd6c09cf":"# Version 2 - Training on ResNet34","040cf8f3":"# 2.4 Train model","b608a923":"# 3.1 Import libs","75d6b18c":"**Version 1**\n\n* ResNet50 - create bottleneck residual block manually - dont use data augmentation\n\n**Version 2**\n\n* ResNet34 - fine tuning - dont use data augmentation\n\n**Version 3**\n\n* ResNet50 - fine tuning - dont use data augmentation\n\n**Version 4**\n* Change patience to 10 in EarlyStoppping\n"}}