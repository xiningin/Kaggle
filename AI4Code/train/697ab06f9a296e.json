{"cell_type":{"da8047d1":"code","927f0430":"code","1e4c0648":"code","e5103c9e":"code","f05575f4":"code","ce6857cd":"code","928b4d62":"code","68f94dc8":"code","231b78a6":"code","443d3cde":"code","f64ac94a":"code","07186320":"code","ad9b9fa5":"code","fad9e123":"code","c35fb7b3":"code","4cf02d21":"code","1b06638d":"code","4486cc52":"code","b7f48a83":"code","5272265e":"code","9f753f42":"code","939c72ed":"code","03d168db":"code","ddf5366b":"code","c82d00f5":"code","00c4d57b":"code","8d56978c":"code","cdc93772":"code","ce83987d":"code","ea5c77c9":"code","41f96350":"code","8baffdda":"code","7492f831":"code","3fea7e49":"code","fcba674e":"code","fda01ed1":"code","a4ffa333":"code","4fc7557f":"code","cd2ec41f":"code","4f9827f4":"code","b404c1df":"markdown","5a43709c":"markdown","ed22dfe1":"markdown","3ada6c49":"markdown","85954d43":"markdown","13a5d7ed":"markdown","9fc73b11":"markdown","7bda9615":"markdown","36305578":"markdown","0bd5eaf9":"markdown","53151462":"markdown","96eb8cec":"markdown","229292cd":"markdown","d6f4b4f3":"markdown","c3296486":"markdown"},"source":{"da8047d1":"import numpy as np \nimport pandas as pd\nimport matplotlib\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline \nfrom wordcloud import WordCloud, STOPWORDS\nimport warnings\nwarnings.simplefilter(\"ignore\")","927f0430":"tweets_df = pd.read_csv(\"\/kaggle\/input\/lionel-messi-tweets\/messi_tweets.csv\")","1e4c0648":"print(f\"data shape: {tweets_df.shape}\")","e5103c9e":"tweets_df.info()","f05575f4":"tweets_df.describe()","ce6857cd":"tweets_df.head()","928b4d62":"def missing_data(data):\n    total = data.isnull().sum()\n    percent = (data.isnull().sum()\/data.isnull().count()*100)\n    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    types = []\n    for col in data.columns:\n        dtype = str(data[col].dtype)\n        types.append(dtype)\n    tt['Types'] = types\n    return(np.transpose(tt))","68f94dc8":"missing_data(tweets_df)","231b78a6":"def unique_values(data):\n    total = data.count()\n    tt = pd.DataFrame(total)\n    tt.columns = ['Total']\n    uniques = []\n    for col in data.columns:\n        unique = data[col].nunique()\n        uniques.append(unique)\n    tt['Uniques'] = uniques\n    return(np.transpose(tt))","443d3cde":"unique_values(tweets_df)","f64ac94a":"def most_frequent_values(data):\n    total = data.count()\n    tt = pd.DataFrame(total)\n    tt.columns = ['Total']\n    items = []\n    vals = []\n    for col in data.columns:\n        itm = data[col].value_counts().index[0]\n        val = data[col].value_counts().values[0]\n        items.append(itm)\n        vals.append(val)\n    tt['Most frequent item'] = items\n    tt['Frequence'] = vals\n    tt['Percent from total'] = np.round(vals \/ total * 100, 3)\n    return(np.transpose(tt))","07186320":"most_frequent_values(tweets_df)","ad9b9fa5":"def plot_count(feature, title, df, size=1, ordered=True):\n    f, ax = plt.subplots(1,1, figsize=(4*size,4))\n    total = float(len(df))\n    if ordered:\n        g = sns.countplot(df[feature], order = df[feature].value_counts().index[:20], palette='Set3')\n    else:\n        g = sns.countplot(df[feature], palette='Set3')\n    g.set_title(\"Number and percentage of {}\".format(title))\n    if(size > 2):\n        plt.xticks(rotation=90, size=8)\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x()+p.get_width()\/2.,\n                height,\n                '{:1.2f}%'.format(100*height\/total),\n                ha=\"center\") \n    plt.show()    ","fad9e123":"plot_count(\"user_name\", \"User name\", tweets_df,4)","c35fb7b3":"plot_count(\"user_location\", \"User location\", tweets_df,4)","4cf02d21":"plot_count(\"source\", \"Source\", tweets_df,4)","1b06638d":"\nfrom wordcloud import WordCloud, STOPWORDS\ndef show_wordcloud(data, mask=None, title=\"\"):\n    text = \" \".join(t for t in data.dropna())\n    stopwords = set(STOPWORDS)\n    stopwords.update([\"t\", \"co\", \"https\", \"amp\", \"U\"])\n    wordcloud = WordCloud(stopwords=stopwords, scale=4, max_font_size=50, max_words=500,mask=mask, background_color=\"white\").generate(text)\n    fig = plt.figure(1, figsize=(16,16))\n    plt.axis('off')\n    fig.suptitle(title, fontsize=20)\n    fig.subplots_adjust(top=2.3)\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.show()","4486cc52":"from PIL import Image\nimport numpy as np","b7f48a83":"mask = np.array(Image.open('\/kaggle\/input\/lionel-messi-tweets\/football.jpg'))","5272265e":"show_wordcloud(tweets_df['text'], title = 'Prevalent words in tweets', mask=mask)","9f753f42":"india_df = tweets_df.loc[tweets_df.user_location==\"India\"]\nshow_wordcloud(india_df['text'], mask = mask, title = 'Prevalent words in tweets from India')","939c72ed":"us_df = tweets_df.loc[tweets_df.user_location==\"United States\"]\nshow_wordcloud(us_df['text'], mask=mask, title = 'Prevalent words in tweets from US')","03d168db":"uk_df = tweets_df.loc[tweets_df.user_location==\"United Kingdom\"]\nshow_wordcloud(uk_df['text'], mask = mask, title = 'Prevalent words in tweets from UK')","ddf5366b":"ca_df = tweets_df.loc[tweets_df.user_location==\"Canada\"]\nshow_wordcloud(ca_df['text'], mask = mask, title = 'Prevalent words in tweets from Canada')","c82d00f5":"sp_df = tweets_df.loc[tweets_df.user_location==\"Spain\"]\nshow_wordcloud(sp_df['text'], mask = mask, title = 'Prevalent words in tweets from Spain')","00c4d57b":"fr_df = tweets_df.loc[tweets_df.user_location==\"France\"]\nshow_wordcloud(fr_df['text'], mask = mask, title = 'Prevalent words in tweets from France')","8d56978c":"def plot_features_distribution(features, title, df, isLog=False):\n    plt.figure(figsize=(12,6))\n    plt.title(title)\n    for feature in features:\n        if(isLog):\n            sns.distplot(np.log1p(df[feature]),kde=True,hist=False, bins=120, label=feature)\n        else:\n            sns.distplot(df[feature],kde=True,hist=False, bins=120, label=feature)\n    plt.xlabel('')\n    plt.legend()\n    plt.show()\n","cdc93772":"tweets_df['hashtags'] = tweets_df['hashtags'].replace(np.nan, \"['None']\", regex=True)\ntweets_df['hashtags'] = tweets_df['hashtags'].apply(lambda x: x.replace('\\\\N',''))\ntweets_df['hashtags_count'] = tweets_df['hashtags'].apply(lambda x: len(x.split(',')))\nplot_features_distribution(['hashtags_count'], 'Hashtags per tweet (all data)', tweets_df)","ce83987d":"tweets_df['hashtags_individual'] = tweets_df['hashtags'].apply(lambda x: x.split(','))\nfrom itertools import chain\nall_hashtags = set(chain.from_iterable(list(tweets_df['hashtags_individual'])))\nprint(f\"There are totally: {len(all_hashtags)}\")","ea5c77c9":"tweets_df['hashtags_individual'].head()","41f96350":"tweets_df['datedt'] = pd.to_datetime(tweets_df['date'])","8baffdda":"tweets_df['year'] = tweets_df['datedt'].dt.year\ntweets_df['month'] = tweets_df['datedt'].dt.month\ntweets_df['day'] = tweets_df['datedt'].dt.day\ntweets_df['dayofweek'] = tweets_df['datedt'].dt.dayofweek\ntweets_df['hour'] = tweets_df['datedt'].dt.hour\ntweets_df['minute'] = tweets_df['datedt'].dt.minute\ntweets_df['dayofyear'] = tweets_df['datedt'].dt.dayofyear\ntweets_df['date_only'] = tweets_df['datedt'].dt.date","7492f831":"tweets_agg_df = tweets_df.groupby([\"date_only\"])[\"text\"].count().reset_index()\ntweets_agg_df.columns = [\"date_only\", \"count\"]","3fea7e49":"def plot_time_variation(df, x='date_only', y='count', hue=None, size=1, title=\"\", is_log=False):\n    f, ax = plt.subplots(1,1, figsize=(4*size,3*size))\n    g = sns.lineplot(x=x, y=y, hue=hue, data=df)\n    plt.xticks(rotation=90)\n    if hue:\n        plt.title(f'{y} grouped by {hue} | {title}')\n    else:\n        plt.title(f'{y} | {title}')\n    if(is_log):\n        ax.set(yscale=\"log\")\n    ax.grid(color='black', linestyle='dotted', linewidth=0.75)\n    plt.show() ","fcba674e":"plot_time_variation(tweets_agg_df, title=\"Number of tweets \/ day of year\",size=3)","fda01ed1":"plot_count(\"dayofweek\", \"tweets \/ day of week\", tweets_df, size=3, ordered=False)","a4ffa333":"plot_count(\"dayofyear\", \"tweets \/ day of year\", tweets_df, size=3, ordered=False)","4fc7557f":"plot_count(\"date_only\", \"tweets \/ date\", tweets_df,size=4, ordered=False)","cd2ec41f":"plot_count(\"hour\", \"tweets \/ hour\", tweets_df,size=4, ordered=False)","4f9827f4":"plot_count(\"minute\", \"tweets \/ minute\", tweets_df,size=5, ordered=False)","b404c1df":"# Data preparation\n\n## Load packages","5a43709c":"### User location","ed22dfe1":"### User name","3ada6c49":"### Hashtags analysis","85954d43":"### Extract date and time features","13a5d7ed":"### Unique values","9fc73b11":"## Load data","7bda9615":"# Data exploration\n\n\n## Glimpse the data","36305578":"### Missing data","0bd5eaf9":"### Time variation","53151462":"## Visualize the data distribution","96eb8cec":"### Text wordcloauds","229292cd":"### Most frequent values","d6f4b4f3":"<h1>Explore Lionel Messi Tweets<\/h1>\n\n\n# Introduction\n\n\nThe Dataset we are using here is collected using Twitter API, **tweepy** and Python package.\n","c3296486":"### Tweet source"}}