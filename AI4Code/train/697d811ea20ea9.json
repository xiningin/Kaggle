{"cell_type":{"b9df2e28":"code","406b42eb":"code","2e159507":"code","beed99ec":"code","831016b1":"code","2355c880":"code","b30fd430":"code","f59a309e":"code","a0203d05":"code","90a86b84":"code","e16fd23f":"code","39af40c4":"code","3dc6ec3a":"code","d056bc0a":"code","9058be43":"code","ab885f12":"code","01c3db01":"code","0e639657":"code","3924a238":"code","3ca4268e":"code","8da9c613":"code","45e017df":"code","9e1b7f4b":"code","cfdf736c":"code","b9a678ed":"code","7d97ceef":"code","2ca53344":"code","9758fc7d":"code","836345be":"code","97ae5f2d":"code","eb9a9a8a":"code","53fbe13f":"code","58d377aa":"code","1a05790b":"code","2f17adc2":"code","b74b6d55":"code","f49798d4":"code","974ce11b":"code","87eefcb2":"code","f8f39f5c":"code","02673899":"code","eb95732a":"markdown","dc83a4df":"markdown","32fca977":"markdown","4298aecb":"markdown","60446a12":"markdown","e6dfa96e":"markdown","b8e86b06":"markdown","f475ed90":"markdown","37863b07":"markdown","4f5b62eb":"markdown","2fe5895a":"markdown","7f619b2a":"markdown","72c81dff":"markdown","a610b72e":"markdown","bf63cf76":"markdown"},"source":{"b9df2e28":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","406b42eb":"#import libraries\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n#for jupyter notebook we use this line\n%matplotlib inline                                    \nsns.set_style('whitegrid')","2e159507":"# Read train data\nTitanicdata=pd.read_csv(\"..\/input\/titanic\/train.csv\")\nTitanictest=pd.read_csv(\"..\/input\/titanic\/test.csv\")","beed99ec":"#Check the 10 samples for data\nTitanicdata.head(10)","831016b1":"#check simple information like  columns names ,  columns datatypes and null values\nTitanicdata.info()","2355c880":"#check summary of numerical data  such as count , mean , max , min  and standard deviation.\nTitanicdata.describe()","b30fd430":"#check numbers of rows(samples) and columns(features)\nTitanicdata.shape","f59a309e":"#check count of values for each features\nTitanicdata.count()","a0203d05":"#Check total missing values in each feature of train data\nTitanicdata.isnull().sum()","90a86b84":"#Check total missing values in each feature of test data\nTitanictest.isnull().sum()","e16fd23f":"#Delete PassengerId,Cabin, Ticket  useless features.\n#Cabin has  a lot of missing values\nTitanicdata.drop([\"PassengerId\",\"Cabin\",\"Ticket\"],axis = 1, inplace = True)\n","39af40c4":"Titanictest.drop([\"PassengerId\",\"Cabin\",\"Ticket\"],axis = 1, inplace = True)\n","3dc6ec3a":"Titanicdata[\"Sex\"].value_counts()","d056bc0a":"groubBySurvived=Titanicdata.groupby(\"Survived\").size()\n","9058be43":"no_Survivors=groubBySurvived[1]\nno_Deaths=groubBySurvived[0]\nprint(\"Numbers of People Survivers: {} \\nNumbers of People Deaths: {}\".format(no_Survivors,no_Deaths))","ab885f12":"class_sex_grouping = Titanicdata.groupby(['Pclass','Sex']).count()\nclass_sex_grouping","01c3db01":"class_sex_grouping['Survived'].plot.pie()","0e639657":"Embarked_sex_grouping = Titanicdata.groupby(['Embarked','Sex',]).count()\nEmbarked_sex_grouping","3924a238":"Embarked_sex_grouping['Pclass'].plot.bar()","3ca4268e":"sns.pairplot(Titanicdata)","8da9c613":"sns.countplot(x=\"Sex\",data=Titanicdata)","45e017df":"sns.barplot('Embarked', 'Survived', data=Titanicdata)","9e1b7f4b":"sns.barplot('Pclass', 'Survived', data=Titanicdata)","cfdf736c":"Titanicdata.Sex=pd.Categorical(Titanicdata.Sex,['male','female'],ordered=True)\nTitanicdata.Sex=Titanicdata.Sex.cat.codes","b9a678ed":"Titanicdata.Embarked=pd.Categorical(Titanicdata.Embarked,['S','C','Q'],ordered=True)\nTitanicdata.Embarked=Titanicdata.Embarked.cat.codes","7d97ceef":"Titanictest.isnull().sum()","2ca53344":"#fill Age feature with  measure of mean or median\nTitanicdata[\"Age\"].fillna(Titanicdata[\"Age\"].mean(), inplace = True)\nTitanictest[\"Age\"].fillna(Titanictest[\"Age\"].mean(), inplace = True) ","9758fc7d":"#Titanicdata=Titanicdata.replace(\"\",np.nan)\nTitanictest=Titanicdata.replace(\"\",np.nan)","836345be":"#fill Fare feature with  measure of mode\nTitanicdata[\"Fare\"].fillna(Titanicdata[\"Fare\"].mode(), inplace = True)\nTitanictest[\"Fare\"].dropna()","97ae5f2d":"#fill Embarked feature with  measure of mode, Embarked has 2 missing values only.\n\nTitanicdata[\"Embarked\"].fillna(Titanicdata[\"Embarked\"].mode(), inplace = True)\n","eb9a9a8a":"Titanicdata['Sex']=Titanicdata['Sex'].replace('female',0)\nTitanicdata['Sex']=Titanicdata['Sex'].replace('male',1)\nTitanictest['Sex']=Titanictest['Sex'].replace('female',0)\nTitanictest['Sex']=Titanictest['Sex'].replace('male',1)","53fbe13f":"Titanicdata['Embarked']=Titanicdata['Embarked'].replace('S',0)\nTitanicdata['Embarked']=Titanicdata['Embarked'].replace('C',1)\nTitanicdata['Embarked']=Titanicdata['Embarked'].replace('Q',2)\nTitanictest['Embarked']=Titanictest['Embarked'].replace('S',0)\nTitanictest['Embarked']=Titanictest['Embarked'].replace('C',1)\nTitanictest['Embarked']=Titanictest['Embarked'].replace('Q',2)\n","58d377aa":"Cols=[\"Age\",\"Embarked\",\"Parch\",\"Pclass\",\"Sex\",\"Fare\",\"SibSp\"]\nX_train=Titanicdata[Cols]\nX_test=Titanictest[Cols]\ny=Titanicdata[\"Survived\"]\ny_test=Titanictest[\"Survived\"]\n","1a05790b":"from sklearn.preprocessing import LabelEncoder\nlabelencoder_y = LabelEncoder()\ny_train= labelencoder_y.fit_transform(y)\ny_test=labelencoder_y.fit_transform(y_test)\n","2f17adc2":"Titanictest.isnull().sum()","b74b6d55":"\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","f49798d4":"#KNeighborsClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nknc = KNeighborsClassifier(n_neighbors =13, metric = 'minkowski', p = 2)\nknc.fit(X_train, y_train)\ny_pred = knc.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\n#print(cm)\naccuracy= knc.score(X_test, y_test)\nprint(accuracy)","974ce11b":"#Support Vector classifier\nfrom sklearn.svm import SVC\nsvc = SVC(kernel = 'rbf', random_state = 42)\nsvc.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = svc.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy= svc.score(X_test, y_test)\nprint(accuracy)","87eefcb2":"#Support Vector classifier\nfrom sklearn.svm import SVC\nsvc = SVC(kernel = 'poly', random_state = 42)\nsvc.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = svc.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy= svc.score(X_test, y_test)\nprint(accuracy)","f8f39f5c":"#DecisionTreeClassifier\nfrom sklearn.tree import DecisionTreeClassifier\ndtc = DecisionTreeClassifier(random_state=0)\ndtc.fit(X_train,y_train)\ny_pred=dtc.predict(X_test)\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\n#print(cm)\naccuracy= dtc.score(X_test, y_test)\nprint(accuracy)","02673899":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(random_state=0)\nrfc.fit(X_train,y_train)\ny_pred=rfc.predict(X_test)\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\n#print(cm)\naccuracy= dtc.score(X_test, y_test)\nprint(accuracy)\n","eb95732a":"## Convert categorical data to numeric data in Sex and Embarked Features","dc83a4df":"## Feature Scaling\n","32fca977":"# Preprocessing  Data\n","4298aecb":"## SVM with RBF kernel","60446a12":"The final accuracy of survival of Titanic is 98.2 with Decision Tree classifier and Random Forest Classifier\n","e6dfa96e":" # Titanic-Analysis &Visualization ","b8e86b06":"## SVM with ploy kernel","f475ed90":"# Support vector machines classifier","37863b07":"# Random Forest Classifier","4f5b62eb":"* Thanks a lot for reading my kernel!, Feel free to any comments for improving.","2fe5895a":"# KNN classifier","7f619b2a":"# Train & Test Data","72c81dff":"### *Hello All*, Welcome to my first kernel in competitions.\n### I want to predict survival of Titanic with several classifiers like KNN and SVM","a610b72e":"* * # Decision Tree classifier","bf63cf76":"## Handling missing values"}}