{"cell_type":{"2ac020bf":"code","380b2910":"code","d29de4f4":"code","894cef11":"code","b9914aa3":"code","2fe74c18":"code","8d30a929":"code","799251a8":"code","2696780a":"code","dcdc00a5":"code","e88b8bc7":"code","d7de1270":"code","32475142":"code","e52e16f0":"code","3b9ca2c5":"code","9d77b684":"code","40d7b55a":"code","c4b78521":"code","17eac570":"code","f6066a2f":"code","7beda0a4":"code","2ecff6d8":"code","5748c2ec":"code","9d36189a":"code","fd55727c":"code","1e95d694":"code","da3257d7":"code","61913bfe":"code","5010ffb1":"code","f914f4db":"code","041b9e78":"code","92a841aa":"code","6c83c2a7":"code","dc49b204":"code","7cea119c":"code","52ebe38c":"code","22bb0c8b":"code","cbf34e85":"code","6e81ff7c":"code","7f752b03":"code","4d3bde40":"code","8dafbe6d":"code","d9e9bd0d":"code","bcff7309":"code","9b8178a9":"markdown","d0f9620a":"markdown","d02a270a":"markdown","8cc31c9f":"markdown","995c2cb0":"markdown","b4083075":"markdown","8aa29275":"markdown","7e24cc2b":"markdown","b838b763":"markdown","bd0c12c4":"markdown","85b9c948":"markdown","6a511c23":"markdown","be225715":"markdown","89b63145":"markdown","e0dd56f0":"markdown","2051cd1b":"markdown","f1f96202":"markdown","80e0767d":"markdown","4582bb75":"markdown","f6c423a9":"markdown","7925734d":"markdown","d7d093a0":"markdown","0c72baf0":"markdown","674adb11":"markdown"},"source":{"2ac020bf":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport datetime\nimport requests\nimport warnings\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport matplotlib.dates as mdates\nimport seaborn as sns\nimport plotly.express as px\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nfrom keras.preprocessing.sequence import TimeseriesGenerator\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras.models import model_from_json\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","380b2910":"df_covid19=pd.read_csv('\/kaggle\/input\/novel-corona-virus-2019-dataset\/covid_19_data.csv')\ndf_covid19.drop(['SNo','Last Update','Province\/State'],axis=1,inplace = True)\ndf_covid19['ObservationDate']=pd.to_datetime(df_covid19['ObservationDate'])","d29de4f4":"# Because there are several updates in the same day, we need a groupby function to merge the data in the same day \ndf_covid19 = df_covid19.groupby([\"ObservationDate\",\"Country\/Region\"],as_index = False).sum()\ndf_covid19_compare = df_covid19\ndf_covid19 = df_covid19.set_index('ObservationDate')\ndf_covid19.tail()","894cef11":"df_sars = pd.read_csv('..\/input\/sars-2003-complete-dataset-clean\/sars_2003_complete_dataset_clean.csv')\ndf_sars.rename(columns={'Date':'ObservationDate', 'Country':'Country\/Region', 'Cumulative number of case(s)':'Confirmed', 'Number of deaths':'Deaths','Number recovered':'Recovered' }, inplace=True)\ndf_sars['ObservationDate']=pd.to_datetime(df_sars['ObservationDate'])\ndf_sars_compare = df_sars\ndf_sars = df_sars.set_index('ObservationDate')","b9914aa3":"Sars_CA = df_sars[df_sars['Country\/Region'] == 'China']\nSars_CA.tail()","2fe74c18":"covid19_new=pd.read_csv('\/kaggle\/input\/novel-corona-virus-2019-dataset\/covid_19_data.csv')\ncovid19_new['Active'] = covid19_new['Confirmed'] - covid19_new['Deaths'] - covid19_new['Recovered']\ncovid19_new[\"ObservationDate\"] = pd.to_datetime(covid19_new[\"ObservationDate\"])\nprint(\"Active Cases Column Added Successfully\")\ncovid19_new.head()","8d30a929":"wep = covid19_new.groupby([\"ObservationDate\",\"Country\/Region\"])[\"Confirmed\",\"Deaths\",\"Recovered\"].max()\nwep = wep.reset_index()\nwep[\"ObservationDate\"] = wep[\"ObservationDate\"].dt.strftime(\"%m,%d,%Y\")\nwep[\"Country\"] = wep[\"Country\/Region\"]\n\nchoro_map = px.choropleth(wep, \n                          locations= \"Country\", \n                          locationmode = \"country names\",\n                          color = \"Confirmed\", \n                          hover_name = \"Country\/Region\",\n                          projection = \"natural earth\",\n                          animation_frame = \"ObservationDate\",\n                          color_continuous_scale = \"Blues\",\n                          range_color = [10000,200000])\nchoro_map.update_layout(\n    title_text = 'Global Spread of Coronavirus',\n    title_x = 0.5,\n    geo=dict(\n        showframe = False,\n        showcoastlines = False,\n    ))\n    \nchoro_map.show()","799251a8":"covid19_new.rename(columns={'ObservationDate':'Date', 'Country\/Region':'Country', 'Province\/State':'Province' }, inplace=True)\ncovid19_new['Date']=pd.to_datetime(covid19_new['Date'])\n\nmaxdate=max(covid19_new['Date'])\n\nfondate=maxdate.strftime(\"%Y-%m-%d\")\nprint(\"The last observation date is {}\".format(fondate))\nondate = format(fondate)","2696780a":"date_list1 = list(covid19_new[\"Date\"].unique())\nconfirmed = []\ndeaths = []\nrecovered = []\nactive = []\nfor i in date_list1:\n    x = covid19_new[covid19_new[\"Date\"] == i]\n    confirmed.append(sum(x[\"Confirmed\"]))\n    deaths.append(sum(x[\"Deaths\"]))\n    recovered.append(sum(x[\"Recovered\"]))\n    active.append(sum(x[\"Active\"]))\ndata_glob = pd.DataFrame(list(zip(date_list1,confirmed,deaths,recovered,active)),columns = [\"Date\",\"Confirmed\",\"Deaths\",\"Recovered\",\"Active\"])\ndata_glob.tail()","dcdc00a5":"import plotly.graph_objs as go \ntrace1 = go.Scatter(\nx = data_glob[\"Date\"],\ny = data_glob[\"Confirmed\"],\nmode = \"lines\",\nname = \"Confirmed\",\nline = dict(width = 2.5),\nmarker = dict(color = [0, 1, 2, 3])\n)\n\ntrace2 = go.Scatter(\nx = data_glob[\"Date\"],\ny = data_glob[\"Deaths\"],\nmode = \"lines\",\nname = \"Deaths\",\nline = dict(width = 2.5),\nmarker = dict(color = [0, 1, 2, 3])\n)\n\ntrace3 = go.Scatter(\nx = data_glob[\"Date\"],\ny = data_glob[\"Recovered\"],\nmode = \"lines\",\nname = \"Recovered\",\nline = dict(width = 2.5),    \nmarker = dict(color = [0, 1, 2, 3])\n)\n\ntrace4 = go.Scatter(\nx = data_glob[\"Date\"],\ny = data_glob[\"Active\"],\nmode = \"lines\",\nname = \"Active\",\nline = dict(width = 2.5),\nmarker = dict(color = [0, 1, 2, 3])\n)\n\ndata_plt = [trace1,trace2,trace3,trace4]\nlayout = go.Layout(title = \"Global Case States\",xaxis_title=\"Date\",yaxis_title=\"Number of Total Cases\",\n                   legend=dict(\n        x=0,\n        y=1,),hovermode='x')\nfig = go.Figure(data = data_plt,layout = layout)\n\nfig.show()","e88b8bc7":"labels = [\"Recovered\",\"Deaths\",\"Active\"]\nvalues = [data_glob.tail(1)[\"Recovered\"].iloc[0],data_glob.tail(1)[\"Deaths\"].iloc[0],data_glob.tail(1)[\"Active\"].iloc[0]]\n\nfig = go.Figure(data = [go.Pie(labels = labels, values = values,textinfo='label+percent',insidetextorientation='radial')],layout = go.Layout(title = \"Global Patient Percentage\"))\nfig.show()","d7de1270":"df_covid19_compare.info()","32475142":"df_sars_compare.info()","e52e16f0":"date_list_cov_compare = list(df_covid19_compare[\"ObservationDate\"].unique())\nconfirmed = []\ndeaths = []\nrecovered = []\nfor i in date_list_cov_compare:\n    x = df_covid19_compare[df_covid19_compare[\"ObservationDate\"] == i]\n    confirmed.append(sum(x[\"Confirmed\"]))\n    deaths.append(sum(x[\"Deaths\"]))\n    recovered.append(sum(x[\"Recovered\"]))\ndata_glob_cov = pd.DataFrame(list(zip(date_list_cov_compare,confirmed,deaths,recovered)),columns = [\"Date\",\"Confirmed\",\"Deaths\",\"Recovered\"])\ndata_glob_cov.tail()","3b9ca2c5":"date_list_sars_compare = list(df_sars_compare[\"ObservationDate\"].unique())\nconfirmed = []\ndeaths = []\nrecovered = []\nfor i in date_list_sars_compare:\n    x = df_sars_compare[df_sars_compare[\"ObservationDate\"] == i]\n    confirmed.append(sum(x[\"Confirmed\"]))\n    deaths.append(sum(x[\"Deaths\"]))\n    recovered.append(sum(x[\"Recovered\"]))\ndata_glob_sars = pd.DataFrame(list(zip(date_list_sars_compare,confirmed,deaths,recovered)),columns = [\"Date\",\"Confirmed\",\"Deaths\",\"Recovered\"])\ndata_glob_sars.tail()","9d77b684":"from plotly import subplots\ndeath_percent_sars = ((data_glob_sars[\"Deaths\"]*100)\/data_glob_sars[\"Confirmed\"])\ndeath_percent_cov = ((data_glob_cov[\"Deaths\"]*100)\/data_glob_cov[\"Confirmed\"])\n\ntrace_death_sars = go.Scatter(x=data_glob_sars[\"Date\"],\n                                  y = death_percent_sars,\n                                  mode = \"lines\",\n                                  name = \"Death Percentage for SARS\",\n                                  marker = dict(color = [0, 1, 2, 3]))\n    \ntrace_death_cov = go.Scatter(x=data_glob_cov[\"Date\"],\n                                  y = death_percent_cov,\n                                  mode = \"lines\",\n                                  name = \"Death Percentage for Covid-19\",\n                                  marker = dict(color = [0, 1, 2, 3]))\n    \ndeath_plt = [trace_death_sars,trace_death_cov]\n\nfig = subplots.make_subplots(rows=1,cols=2)\nfig.append_trace(trace_death_sars,1,1)\nfig.append_trace(trace_death_cov,1,2)\n\nfig.layout.width = 1000\nfig.layout.height = 600\nfig.show()","40d7b55a":"recover_percent_sars = ((data_glob_sars[\"Recovered\"]*100)\/data_glob_sars[\"Confirmed\"])\nrecover_percent_cov = ((data_glob_cov[\"Recovered\"]*100)\/data_glob_cov[\"Confirmed\"])\n\ntrace_recover_sars = go.Scatter(x=data_glob_sars[\"Date\"],\n                                  y = recover_percent_sars,\n                                  mode = \"lines\",\n                                  name = \"Recover Percentage for SARS\",\n                                  marker = dict(color = [0, 1, 2, 3]))\n    \ntrace_recover_cov = go.Scatter(x=data_glob_cov[\"Date\"],\n                                  y = recover_percent_cov,\n                                  mode = \"lines\",\n                                  name = \"Recover Percentage for Covid-19\",\n                                  marker = dict(color = [0, 1, 2, 3]))\n    \nrecover_plt = [trace_recover_sars,trace_recover_cov]\n\nfig = subplots.make_subplots(rows=1,cols=2)\nfig.append_trace(trace_recover_sars,1,1)\nfig.append_trace(trace_recover_cov,1,2)\nfig.layout.width = 1000\nfig.layout.height = 600\nfig.show()","c4b78521":"# load Sars data set, and set the country as China\nSars_CA.tail()","17eac570":"# data normalization\n\ntrain_num_sars = int(len(Sars_CA)*0.8)\n\nscaler_sars = MinMaxScaler()\n\ntrain_origin = pd.DataFrame(Sars_CA.iloc[:train_num_sars,1])\ntest_origin = pd.DataFrame(Sars_CA.iloc[train_num_sars:,1])\n\nscaler_sars.fit(train_origin)\nscaled_train_sars = scaler_sars.transform(train_origin)\nscaled_test_sars = scaler_sars.transform(test_origin)\n","f6066a2f":"# using 10 day lag to predict the model\nn_input = 15\nn_features = 1\ngenerator_sars = TimeseriesGenerator(scaled_train_sars, scaled_train_sars, length=n_input, batch_size=1)","7beda0a4":"# show the format of our input data\nfor i in range(3):\n    x, y = generator_sars[i]\n    print('%s => %s' % (x, y))","2ecff6d8":"# build 4-layer RNN model\n# define model\nmodel = Sequential([\n    layers.LSTM(256, activation='relu', input_shape=(n_input, n_features),return_sequences=True),\n    layers.LSTM(128, activation='relu', input_shape=(n_input, n_features),return_sequences=True),\n    layers.LSTM(64, activation='relu', input_shape=(n_input, n_features)),\n    layers.Dense(1)\n])\n\nmodel.compile(optimizer='adam', loss='mse')\nmodel.summary()","5748c2ec":"# train the model\nmodel.fit_generator(generator_sars,epochs=25)","9d36189a":"# plot the loss curve\nloss_per_epoch = model.history.history['loss']\nfig = plt.figure(dpi = 120,figsize = (6,4))\nax = plt.axes()\nax.set(xlabel = 'Number of Epochs',ylabel = 'MSE Loss',title = 'Sars Loss Curve')\nplt.plot(range(len(loss_per_epoch)),loss_per_epoch,lw = 1);","fd55727c":"# test our model in test set\ntest_predictions = []\n\nfirst_eval_batch = scaled_train_sars[-n_input:]\ncurrent_batch = first_eval_batch.reshape((1, n_input, n_features))\n\nfor i in range(len(test_origin)):\n    \n    # get prediction 1 time stamp ahead ([0] is for grabbing just the number instead of [array])\n    current_pred = model.predict(current_batch)[0]\n    \n    # store prediction\n    test_predictions.append(current_pred) \n    \n    # update batch to now include prediction and drop first value\n    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)","1e95d694":"# fill test table with prediction\ntrue_predictions = scaler_sars.inverse_transform(test_predictions)\ntest_origin['Predictions'] = true_predictions\nprint(test_origin)","da3257d7":"# plot the comparison between actual value and predicted value\nfig = plt.figure(dpi = 120)\nax=plt.axes()\ntest_origin.plot(legend=True,figsize=(6,4),lw = 2,ax=ax)\nplt.xlabel('Date')\nplt.ylabel('Count of Cases')\nplt.title('Comparision Test and Prediction')\nplt.show();","61913bfe":"# build complete SARS model with the whole data set (train+test)\nscaler_sars = MinMaxScaler()\n\ntrain_origin = pd.DataFrame(Sars_CA.iloc[:,1])\n\n\nscaler_sars.fit(train_origin)\nscaled_train_sars = scaler_sars.transform(train_origin)\n\nn_input = 15\nn_features = 1\ngenerator_sars = TimeseriesGenerator(scaled_train_sars, scaled_train_sars, length=n_input, batch_size=1)\n\n# define model\nmodel_whole = Sequential([\n    layers.LSTM(256, activation='relu', input_shape=(n_input, n_features),return_sequences=True),\n    layers.LSTM(128, activation='relu', input_shape=(n_input, n_features),return_sequences=True),\n    layers.LSTM(64, activation='relu', input_shape=(n_input, n_features)),\n    layers.Dense(1)\n])\nmodel_whole.compile(optimizer='adam', loss='mse')\n\n# fit model\nmodel_whole.fit_generator(generator_sars,epochs=25)","5010ffb1":"# plot loss curve for complete model\nloss_per_epoch = model_whole.history.history['loss']\nfig = plt.figure(dpi = 120,figsize = (6,4))\nax = plt.axes()\nax.set(xlabel = 'Number of Epochs',ylabel = 'MSE Loss',title = 'Loss Curve of Base Model')\nplt.plot(range(len(loss_per_epoch)),loss_per_epoch,lw = 2)\nfig.show()","f914f4db":"# save SARS model and its weights\njson_config = model_whole.to_json()\nwith open('model_config.json', 'w') as json_file:\n    json_file.write(json_config)\nmodel_whole.save_weights('path_to_my_weights.h5')","041b9e78":"# load COVID-19 dataset, and set country as Canada\nCovid_CA = df_covid19[df_covid19['Country\/Region'] == 'Canada']\nCovid_CA.head()","92a841aa":"# normalization\n\ntrain_num = int(len(Covid_CA)*0.8)\n\nscaler = MinMaxScaler()\n\ntrain = pd.DataFrame(Covid_CA.iloc[:train_num,1])\ntest = pd.DataFrame(Covid_CA.iloc[train_num:,1])\n\nscaler.fit(train)\nscaled_train = scaler.transform(train)\nscaled_test = scaler.transform(test)\n","6c83c2a7":"# show confirmation cases after normalization \nprint(\"Scaled Train Set:\", scaled_train[:3],\"\\n\")\nprint(\"Scaled Test Set:\", scaled_test[:3])","dc49b204":"# equally, we set 10 day lag for modelling\nn_input = 15\nn_features = 1\ngenerator = TimeseriesGenerator(scaled_train, scaled_train, length=n_input, batch_size=1)","7cea119c":"# show data format\nfor i in range(3):\n    x, y = generator[i]\n    print('%s => %s' % (x, y))","52ebe38c":"# load SARS model\nmodel_cov = model_from_json(open('model_config.json').read())\nmodel_cov.load_weights('path_to_my_weights.h5')\nmodel_cov.summary()","22bb0c8b":"# Let's take a look to see how many layers are in the base model\nprint(\"Number of layers in the base model: \", len(model_cov.layers))\n\n# Fine-tune from this layer onwards\nfine_tune_at = 1\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in model_cov.layers[:fine_tune_at]:\n  layer.trainable =  False","cbf34e85":"# now, we locked the first one layers of our network. The Non-trainable params is 66560+49408\nmodel_cov.summary()","6e81ff7c":"# compile the new model for training\nmodel_cov.compile(optimizer='adam', loss='mse')","7f752b03":"# fit model\nmodel_cov.fit_generator(generator,epochs=25)","4d3bde40":"# plot loss curve for new model\nloss_per_epoch = model_cov.history.history['loss']\nfig = plt.figure(dpi = 120,figsize = (6,4))\nax = plt.axes()\nax.set(xlabel = 'Number of Epochs',ylabel = 'MSE Loss',title = 'Loss Curve - Fine Tuning')\nplt.plot(range(len(loss_per_epoch)),loss_per_epoch,lw = 2);","8dafbe6d":"test_predictions = []\n\nfirst_eval_batch = scaled_train[-n_input:]\ncurrent_batch = first_eval_batch.reshape((1, n_input, n_features))\n\nfor i in range(len(test)):\n    \n    # get prediction 1 time stamp ahead ([0] is for grabbing just the number instead of [array])\n    current_pred = model_cov.predict(current_batch)[0]\n    \n    # store prediction\n    test_predictions.append(current_pred) \n    \n    # update batch to now include prediction and drop first value\n    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)","d9e9bd0d":"true_predictions = scaler.inverse_transform(test_predictions)\ntest['Predictions'] = true_predictions\ntest.head()","bcff7309":"fig = plt.figure(dpi = 120)\nax=plt.axes()\ntest.plot(legend=True,figsize=(6,4),lw = 2,ax=ax)\nplt.xlabel('Date')\nplt.ylabel('Count of Cases')\nplt.show();","9b8178a9":"# Introduction\n\n**Recently, Covid-19 is spreading around the globe. There is an outbreak in almost everywhere around the world. There are lots of researches focusing on analyzing and predicting the diffusing of this kind of fatal virus, the same as I did in this project. The whole project could be separated into two main parts, EDA (Exploratory Data Analysis) and Prediction.**\n\n**The first part includes data aggregation and data visualization. Because of the convenience of invoking, all the actions have been done in Pandas and Numpy. There is another type of data processing building in Pyspark at the top of Databricks.**\n\n**The second part is the biggest difference compared with other same kinds of work. Normally, if people want to involve deep learning, only the LSTM model will be picked. But I also drew on the experience of transfer learning and built my own LSTM base model for Covid-19 in terms of the SARS-2003 dataset.**\n\n**However, given that the lacks of data from both SARS and Covid-19 are irreversible, the final performance for transfer learning model is a little bit weak and it only shows the learning capacity from the base model, but the adjustable ability according to Covid-19 dataset is not enough. So there is quite a long way for this project to use transfer learning in a real prediction data science case.**\n\n\n>#  <font color='Blue'>Contents :<\/font>\n>1. [Necessary libraries](#0)\n>1. [Data Injection](#1)\n>1. [Data Aggregation & Data Visualization](#2)\n>>    1. [World Epidemic Progress ](#2.1)\n>>    1. [Global Case Map ](#2.2)\n>>    1. [Pie Chart of Global Distribution ](#2.3)\n>>    1. [Comparison between SARS and Covid-19 dataset ](#2.4)\n>>        1. [Confirmed Percentage](#2.41)\n>>        1. [Recovered Percentage](#2.42)\n>1. [Perdiction](#3)\n>>    1. [Base Model](#3.1)\n>>        1. [Feature Extraction](#3.11)\n>>        1. [Compile the Sars Model](#3.12)\n>>        1. [Train the Sars Model](#3.13)\n>>        1. [Learning Curves](#3.14)\n>>    1. [Fine Tuning](#3.2)\n>>        1. [Format the data](#3.21)\n>>        1. [Load the base model](#3.22)\n>>        1. [Freeze the bottom LSTM layers](#3.23)\n>>        1. [Re-train the model with Covid-19 dataset](#3.24)","d0f9620a":"<a id=\"2.1\"><\/a> <br>\n## World Epidemic Progress ","d02a270a":"<a id=\"3.1\"><\/a> <br>\n## Base Model","8cc31c9f":"<a id=\"3.11\"><\/a> <br>\n## Feature Extraction","995c2cb0":"<a id=\"3.2\"><\/a> <br>\n## Fine Tuning","b4083075":"<a id=\"2.4\"><\/a> <br>\n## Comparison between SARS and Covid-19 dataset","8aa29275":"<a id=\"3.24\"><\/a> <br>\n## Re-train the model with Covid-19 dataset","7e24cc2b":"<a id=\"2\"><\/a> <br>\n# Data Aggregation & Data Visualization","b838b763":"<a id=\"0\"><\/a> <br>\n# Necessary Libraries\n* **Numpy:** Linear algebra\n* **Pandas:** Data processing and aggregation\n* **Matplotlib:** Simple visualization\n* **Plotly:** Interactive plots - World Epidemic Progress \n* **Datetime:** Time data manuplation - Data Analysis, Predictions \n* **Sklearn:** Machine Learning\n* **Keras:** Deep learning - Predictions, LSTM","bd0c12c4":"**Take a look at the Trainable params.**\n\n**Up to now, we haven't freeze any layers of the model, so all of the params are trainable.**","85b9c948":"<a id=\"3.14\"><\/a> <br>\n## Learning Curves","6a511c23":"<a id=\"2.2\"><\/a> <br>\n## Global Case Map ","be225715":"<a id=\"3\"><\/a> <br>\n# Prediction","89b63145":"<a id=\"2.3\"><\/a> <br>\n## Pie Chart of Global Distribution ","e0dd56f0":"<a id=\"3.12\"><\/a> <br>\n## Compile the SARS model","2051cd1b":"<a id=\"3.22\"><\/a> <br>\n## Load the Base Model","f1f96202":"<a id=\"3.14\"><\/a> <br>\n## Train the SARS model","80e0767d":"**The main procedures for the prediction part has been shown below,**\n\n* Input SARS_2003 data set to build our base model\n* Because the outbreak for SARS was mainly located in China, I built an RNN prediction model for SARS in China instead of Canada\n* Save the base model and load COVID-19 dataset\n* Load previous model I built, and its corresponding weights and weights\n* Fine tune that model to predict the cases for Coronavirus in Canada\n\n\n\n\n\n","4582bb75":"<a id=\"3.23\"><\/a> <br>\n## Freeze the Bottom LSTM Layers","f6c423a9":"<a id=\"2.41\"><\/a> <br>\n## Confirmed Percentage","7925734d":"<a id=\"1\"><\/a> <br>\n# Data Injection","d7d093a0":"<a id=\"2.42\"><\/a> <br>\n## Recovered Percentage","0c72baf0":"**The recovered percentage explains the probability of using Sars dataset as a base model to analyze Covid-19, because the left graph could clearly show the Sars outbreak had been finished until July 2003 and the recovery rate was almost 90% back then. However, the Coronavirus is still spreading until now. As a result, we could learn some potential distribution from the closed Sars model to model for the new Covid-19.**","674adb11":"<a id=\"3.21\"><\/a> <br>\n## Format the data"}}