{"cell_type":{"2cbe20ff":"code","0aaa94a2":"code","4f7434f7":"code","8284598b":"code","32d9b8da":"code","7aa4327c":"code","adc38044":"code","d7836ae5":"code","81d7d0b1":"code","2a80cf10":"code","95392e67":"code","61a0f1bd":"code","12ba4d44":"code","a05f2ca0":"code","a296b7fc":"code","3d1d17a7":"code","7b5fdbfd":"code","e3efa784":"code","a6dae18f":"code","84e4f503":"code","df705050":"code","1003b4d6":"code","724c2e74":"code","3b9dad1c":"code","c44a55e9":"code","9aeb8461":"markdown","44608407":"markdown","0ad53f3e":"markdown","c70473cf":"markdown","400d49be":"markdown","d1079fab":"markdown","527bbe17":"markdown","721d264e":"markdown","0098eeef":"markdown","e82c599a":"markdown","3bb14174":"markdown","adeb3cea":"markdown","23b8760f":"markdown","5e14afbe":"markdown"},"source":{"2cbe20ff":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0aaa94a2":"import tifffile as tiff\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport json\nimport pandas as pd\n","4f7434f7":"def get_image_id(data): \n\n    if data == \"train\":\n        train = list({file[:9] for file in os.listdir('\/kaggle\/input\/hubmap-kidney-segmentation\/train')})\n        return train\n    \n    elif data == \"test\":\n        test = list({file[:9] for file in os.listdir('\/kaggle\/input\/hubmap-kidney-segmentation\/test')})\n        return test  \n    ","8284598b":"print(\"Training data sets \\n\")\ntrain_ids = get_image_id(\"train\")\nprint(train_ids)\n\nprint(\"\\n Testing data sets \\n\")\ntest_ids = get_image_id(\"test\")\n\nprint(test_ids)","32d9b8da":"# print(\"Training data sets \\n\")\n\n# for id_im in train_ids:\n#     image = tiff.imread('\/kaggle\/input\/hubmap-kidney-segmentation\/train\/{}.tiff'.format(id_im))\n#     print(str(image.shape) + '  ' + id_im)\n    \n# print(\"Testing data set \\n\")\n# for id_im in test_ids:\n#     image = tiff.imread('\/kaggle\/input\/hubmap-kidney-segmentation\/test\/{}.tiff'.format(id_im))\n#     print(str(image.shape) + ' ' + id_im)","7aa4327c":"def generate_mask(file_name, inv):\n    train_ids = ['2f6ecfcdf', 'cb2d976f4', '1e2425f28', '54f2eec69', '0486052bb', 'aaa6a05cc', 'e79de561c', '095bf7a1f']\n    test_ids = ['afa5e8098', 'c68fe75ea', 'b2dc8411c', 'b9a3865fc', '26dc41664']\n    \n    if file_name in train_ids:\n        train_or_test = \"train\"\n    elif file_name in test_ids:\n        train_or_test = \"test\"\n    else:\n        print(\"ID not available in dataset\")\n        return\n    \n    image = tiff.imread('\/kaggle\/input\/hubmap-kidney-segmentation\/{}\/{}.tiff'.format(train_or_test, file_name))\n    dim = image.ndim\n    \n    if dim == 5:\n        rgb_img = image[0, 0, :, :, :].transpose((1, 2, 0))\n        \n    elif dim == 3:\n        rgb_img = image\n    \n    if not inv:\n        return np.zeros((rgb_img.shape[0], rgb_img.shape[1]), dtype = np.uint8)\n    else:\n        return np.ones((rgb_img.shape[0], rgb_img.shape[1]), dtype = np.uint8)","adc38044":"def get_image(file_name, gray = True, display = False):\n    \n    train_ids = ['2f6ecfcdf', 'cb2d976f4', '1e2425f28', '54f2eec69', '0486052bb', 'aaa6a05cc', 'e79de561c', '095bf7a1f']\n    test_ids = ['afa5e8098', 'c68fe75ea', 'b2dc8411c', 'b9a3865fc', '26dc41664']\n    \n    if file_name in train_ids:\n        train_or_test = \"train\"\n    elif file_name in test_ids:\n        train_or_test = \"test\"\n    else:\n        print(\"ID not available in dataset\")\n        return\n    \n    image = tiff.imread('\/kaggle\/input\/hubmap-kidney-segmentation\/{}\/{}.tiff'.format(train_or_test, file_name))\n    dim = image.ndim\n    \n    if dim == 5:\n        rgb_img = image[0, 0, :, :, :].transpose((1, 2, 0))\n        \n    elif dim == 3:\n        rgb_img = image\n    \n    if gray:\n        result_unscaled = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2GRAY)\n        result = cv2.resize(result_unscaled, (2000, 2000))\n    else:\n        result = cv2.resize(rgb_img, (2000, 2000))\n    \n    \n    if display:\n        plt.figure(figsize=(20, 20))\n        plt.imshow(result, cmap='gray')\n        return result\n    else:\n        return result","d7836ae5":"image_tiff = get_image('b2dc8411c', gray=False, display=True)\n    \n","81d7d0b1":"def get_prop_shape(file_name):\n    \n    train_ids = ['2f6ecfcdf', 'cb2d976f4', '1e2425f28', '54f2eec69', '0486052bb', 'aaa6a05cc', 'e79de561c', '095bf7a1f']\n    test_ids = ['afa5e8098', 'c68fe75ea', 'b2dc8411c', 'b9a3865fc', '26dc41664']\n    \n    if file_name in train_ids:\n        train_or_test = \"train\"\n    elif file_name in test_ids:\n        train_or_test = \"test\"\n    else:\n        print(\"ID not available in dataset\")\n        return\n    \n    def flatten(iterable):\n        if len(iterable[0]) == 2:\n            return iterable\n        else:\n            return flatten(iterable[0])\n        \n    anatomy = open('\/kaggle\/input\/hubmap-kidney-segmentation\/{}\/{}-anatomical-structure.json'.format(train_or_test, file_name))\n    json_obj = json.load(anatomy)\n    \n    try:\n        \n        result = {}\n        for elem in json_obj:\n            key = elem['properties']['classification']['name']\n            value = np.array(flatten(elem['geometry']['coordinates']))\n            if key in result.keys():\n                key = str(key) + ' I'\n            result[key] = value\n        return result\n    \n    except IndexError:\n        print(\"Error occured on {} id\".format(file_name))\n        \n        ","2a80cf10":"    \nprint(\"Anatomical data found in Training data \\n\")\n\nfor _id in train_ids:\n    print(str(_id) + '      ' + str(get_prop_shape(_id).keys()) + '\\n')\n\nprint(\" \\nAnatomical data found in Testing data \\n\")\n\nfor _id in test_ids:\n    print(str(_id) + '      ' + str(get_prop_shape(_id).keys()) + '\\n')\n    \nprint(\"\\n \\nThere are certainly some irregularities in testing and training data \\n\")                    ","95392e67":"print(\"Medulla              Cortex           ID\")\n\nprint(\"\\n \\n Training data \\n \\n\")\nfor id_g in train_ids:\n    c = get_prop_shape(id_g)\n    print(str(c.get(\"Medulla\", np.array(None)).shape) + \"             \" + str(c.get(\"Cortex\", np.array(None)).shape) + \"        \" + id_g)\n    \nprint(\" \\n \\n Testing data \\n \\n \")\n\nfor id_g in test_ids:\n    c = get_prop_shape(id_g)\n    print(str(c.get(\"Medulla\", np.array(None)).shape) + \"             \" + str(c.get(\"Cortex\", np.array(None)).shape) + \"        \" + id_g)","61a0f1bd":"def extract_feature(file_name, gray = True, display = False):\n    \n    anatomy_dict = get_prop_shape(file_name)\n    anato_featu = [i for i in anatomy_dict.keys()]\n    \n    zeros = generate_mask(file_name, False)\n    \n    for anatomy in anato_featu:\n        coordinate = anatomy_dict[anatomy]\n        mask = cv2.fillPoly(zeros, pts = [coordinate], color = 255)\n    \n    mask_resized = cv2.resize(mask, (2000, 2000))\n    \n    if not gray:\n        img = get_image(file_name, gray)\n        r, g, b = cv2.split(img)\n        result_r = cv2.bitwise_and(r, r, mask = mask_resized)\n        result_g = cv2.bitwise_and(g, g, mask = mask_resized)\n        result_b = cv2.bitwise_and(b, b, mask = mask_resized)\n        result = cv2.merge((result_r, result_g, result_b))\n    \n    else:\n        img = get_image(file_name, gray)\n        result = cv2.bitwise_and(img, img, mask = mask_resized)\n    \n    \n    if display:\n        plt.figure(figsize=(20, 20))\n        plt.imshow(result)\n        return result\n    \n    else:\n        return result\n\n","12ba4d44":"subject = extract_feature('26dc41664', display= True)","a05f2ca0":"def get_glomerous_polygon_list(file_name):\n    try:\n        train_ids = ['2f6ecfcdf', 'cb2d976f4', '1e2425f28', '54f2eec69', '0486052bb', 'aaa6a05cc', 'e79de561c', '095bf7a1f']\n        test_ids = ['afa5e8098', 'c68fe75ea', 'b2dc8411c', 'b9a3865fc', '26dc41664']\n\n        if file_name in train_ids:\n            train_or_test = \"train\"\n        elif file_name in test_ids:\n            train_or_test = \"test\"\n        else:\n            print(\"ID not available in dataset\")\n            return\n        \n        glomerulus = open('\/kaggle\/input\/hubmap-kidney-segmentation\/{}\/{}.json'.format(train_or_test, file_name))\n        json_obj = json.load(glomerulus)\n        \n        polygon_list = []\n        \n        for elem in json_obj:\n            narr = np.array(elem['geometry']['coordinates'][0])\n            polygon_list.append(narr)\n        \n        return polygon_list\n          \n    except:  \n        print('Cannot load file {}'.format(file_name))\n        raise","a296b7fc":"def extract_glomerous(file_name, gray = True, display = False, inv = False):\n    poly_list = get_glomerous_polygon_list(file_name)\n    rgb = extract_feature(file_name, gray = not gray)\n    gray = extract_feature(file_name, gray = gray)\n    r, g, b = cv2.split(rgb)\n    \n    mask = generate_mask(file_name, inv)\n    color = 0 if inv else 255\n    \n    for coordinates in poly_list:\n        cv2.fillPoly(mask, pts=[coordinates], color= color)\n        \n    mask_resized = cv2.resize(mask, (2000, 2000))\n    \n    result_r = cv2.bitwise_and(r, r, mask = mask_resized)\n    result_g = cv2.bitwise_and(g, g, mask = mask_resized)\n    result_b = cv2.bitwise_and(b, b, mask = mask_resized)\n    \n    result_gray = cv2.bitwise_and(gray, gray, mask = mask_resized)\n    result_rgb = cv2.merge((result_r, result_g, result_b))\n    \n    if gray.any():\n        result = cv2.resize(result_gray, (2000, 2000))\n    else:\n        result = cv2.resize(result_rgb, (2000, 2000))\n    \n    if display:\n        plt.figure(figsize=(20, 20))\n        plt.imshow(result)\n        return result\n    \n    else:\n        return result","3d1d17a7":"glomorous = extract_glomerous('cb2d976f4', display=True, inv = False)","7b5fdbfd":"non_glomorous = extract_glomerous('cb2d976f4', display=True, inv = True)","e3efa784":"non_glomorous[0][0]","a6dae18f":"fig, (ax_g, ax_ng) = plt.subplots(2, 1, figsize=(10, 10))\n\nglomorous_flatten = glomorous.flatten()\nnon_glomourous_flatten = non_glomorous.flatten()\n\nax_g.hist(glomorous_flatten[glomorous_flatten != 0], bins=256)\nax_g.set_title('Glomorous Pixel distribution')\n\nax_ng.hist(non_glomourous_flatten[non_glomourous_flatten != 0], bins=256)\nax_ng.set_title('Non-Glomouros Pixel distribution')\n\n\nfig.tight_layout()\nplt.show()","84e4f503":"# making grid for the image and its corresponding glomorous mask\nGRID_SQUARE_SIZE = 25\nOVER_LAP = 8\ndef make_grid_img_vs_mask(file_name):\n    gray = extract_feature(file_name)\n    zeros = generate_mask(file_name, inv = False)\n    poly_list = get_glomerous_polygon_list(file_name)\n    \n    for coordinates in poly_list:\n        mask = cv2.fillPoly(zeros, pts=[coordinates], color= 255)\n        \n    mask_resized = cv2.resize(mask, (2000, 2000))\n    \n    gray_vs_mask = []\n    for row in range(0, 2000 - GRID_SQUARE_SIZE, GRID_SQUARE_SIZE - OVER_LAP):\n        for col in range(0, 2000 - GRID_SQUARE_SIZE, GRID_SQUARE_SIZE - OVER_LAP):\n            gray_grid = gray[row:row + GRID_SQUARE_SIZE, col:col+GRID_SQUARE_SIZE]\n            mask_grid = mask_resized[row:row + GRID_SQUARE_SIZE, col:col+GRID_SQUARE_SIZE]\n            gray_vs_mask.append(np.array([gray_grid, mask_grid]))\n            \n    return np.array(gray_vs_mask, dtype = 'uint8')","df705050":"t = make_grid_img_vs_mask('cb2d976f4')\nt.shape","1003b4d6":"#seperate grids into grids containg glomorous and not containing.\nREQ_GLOM = 10\nREQ_NON_GLOB = 50\ndef grid_admission_glob(mask):\n    \n    zero_check = mask.any()>0\n    \n    if zero_check:\n        unique, counts = np.unique(mask, return_counts=True)\n        unique_mask_elem = dict(zip(unique, counts))\n        no_not_zero = sum([unique_mask_elem[k] for k in unique_mask_elem if k != 0])\n#         no_255 = unique_mask_elem[255]\n        mask_size = np.size(mask)\n        perc_255 = (no_not_zero\/mask_size)*100\n        req_glom_check = perc_255>REQ_GLOM\n        return zero_check and req_glom_check\n    else:\n        return zero_check\n    \ndef grid_admission_non_glob(gray):\n    unique, counts = np.unique(gray, return_counts=True)\n    unique_gray_elem = dict(zip(unique, counts))     \n    if 0 in unique_gray_elem.keys():\n        no_zeros = unique_gray_elem[0]\n        gray_size = np.size(gray)\n        perc_zero = (no_zeros\/gray_size)*100\n        req_glom_check = perc_zero<REQ_NON_GLOB\n        return req_glom_check\n    else:\n        return True\n    \ndef seperate_glom_non_glom_grid(file_name):\n    glom_vs_non_glom = make_grid_img_vs_mask(file_name)\n    glom = []\n    non_glom = []\n    \n    for row in range(0, glom_vs_non_glom.shape[0]):\n        gray = glom_vs_non_glom[row][0]\n        mask = glom_vs_non_glom[row][1]\n        \n#         if mask.any()>0:\n        if grid_admission_glob(mask):\n            glom.append([gray, mask])\n        else:\n            if grid_admission_non_glob(gray):\n                non_glom.append([gray, mask])\n            \n    return {\n        \"glom\": np.array(glom),\n        \"non_glom\": np.array(non_glom)\n    }","724c2e74":"glom_vs_non_glom_cb2d976f4 = seperate_glom_non_glom_grid('cb2d976f4')\ngloms = glom_vs_non_glom_cb2d976f4[\"glom\"]\nnon_gloms = glom_vs_non_glom_cb2d976f4[\"non_glom\"]\nprint('Glomerous shape - ' + str(gloms.shape))\nprint('\\nNon-Glomerous shape - ' + str(non_gloms.shape))\nprint('\\nThere are {} number of Glomerous grids and {} number of non-glomorous grids'.format(str(gloms.shape[0]), str(non_gloms.shape[0])))","3b9dad1c":"NO_OF_GRIDS = 10\nSTART = 0\nfig, ax = plt.subplots(NO_OF_GRIDS, 4, figsize=(20, 20))\nfor row in range(NO_OF_GRIDS):\n    ax[row][0].imshow(gloms[row + START][0], 'gray')\n    ax[row][0].set_title('Glomorous Grid ' + str(row +1))\n    ax[row][1].imshow(gloms[row + START][1], 'gray')\n    ax[row][1].set_title('Glomorous Mask Grid ' + str(row +1))\n    ax[row][2].imshow(non_gloms[row + START][0], 'gray')\n    ax[row][2].set_title('Non - Glomorous Grid ' + str(row +1))\n    ax[row][3].imshow(non_gloms[row + START][1], 'gray')\n    ax[row][3].set_title('Non - Glomorous Grid - Mask ' + str(row +1))\n\nfig.tight_layout()\nplt.show()","c44a55e9":"fig, ax = plt.subplots(NO_OF_GRIDS, 3, figsize=(20, 20))\nfor row in range(NO_OF_GRIDS):\n    \n    hist_glm_and_non = cv2.calcHist([gloms[row + START][0]],[0],None,[256],[0,256])\n    ax[row][0].plot(hist_glm_and_non)\n    ax[row][0].set_title('Glomorous + Non-glomorous Grid ' + str(row +1))\n    \n    hist_glm_only = cv2.calcHist([gloms[row + START][0]],[0],gloms[row + START][1],[256],[0,256])\n    ax[row][1].plot(hist_glm_only)\n    ax[row][1].set_title('Glomorous only -masked- Grid ' + str(row +1))\n    \n    hist_non_glm = cv2.calcHist([non_gloms[row + START][0]],[0],None,[256],[0,256])\n    ax[row][2].plot(hist_non_glm)\n    ax[row][2].set_title('Non - Glomorous Grid ' + str(row +1))\n\nfig.tight_layout()\nplt.show()","9aeb8461":"## Analysising Pixel histogram of grids\nLets compare pixel densitities of glomorous and non glomorous grids and finds out if there is any difference between them. We can also check if there is any similarities in glomorous grids.","44608407":"## Comparing pixel densities of glomorous and non- glomorous region","0ad53f3e":"## Images minus glomerous","c70473cf":"## Images of glomerous","400d49be":"## Coordinate shapes for Medulla and Cortex for training and test ids","d1079fab":"This is good news. In the above figure, first column is grid with glomorous and 3rd column doesnt have glomorous. It can be seen that Non - Glomorous grids have most of there pixels concentrated at 200 - 250. But in the Glomorous Grid we can see a wide components of pixel in the range from 50 to 200 with a somewhat peak at 100 - 150. Now there is a component at 200 - 250 range too in that. That is Non - Glomorous part of the grid. ","527bbe17":"## Generate mask","721d264e":"## Slicing the image into grids for more analysis.\n\nThe above analyisis doesnt provide much information due to  very high pixel density in non-glomorous region. Hence analysing pixels in small grids of size 25x25  might make more sense.","0098eeef":"### Anatomical data found in training and test data set.","e82c599a":"### Not all images in training and test images have Medulla data","3bb14174":"## Extracting image IDs\nSome Images are 5 dimensional. Also height and width of the images are non uniform. We are rescaling all images as 2000x2000.\n","adeb3cea":"## Extracting Glomerous","23b8760f":"## Extracting differnt anatomical features","5e14afbe":"## Dimensions of all tiff images"}}