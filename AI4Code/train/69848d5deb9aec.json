{"cell_type":{"d50b4e1a":"code","c1381ee4":"code","764203d3":"code","189033b3":"code","40de7497":"code","a5d6c0ed":"code","8309b9ac":"code","ef08c308":"code","7c410e55":"code","62db18e5":"code","c07c4975":"code","a39bc8f8":"code","356aff15":"code","bc2b83f3":"code","d3520046":"code","adfb4cce":"code","6fe66e8e":"code","154b13bf":"code","46a5bf60":"code","504142db":"code","cec2fe52":"code","9e13598d":"code","dd9dcaab":"code","821bb77e":"code","e98b0185":"code","e736fed3":"code","4c968618":"code","1c8ab2a5":"code","4f8cc647":"code","6f0a8489":"code","9998ac6a":"markdown","e0e77b6e":"markdown","f33b51b4":"markdown","7495957e":"markdown","3a083d6a":"markdown","de8336a0":"markdown"},"source":{"d50b4e1a":"# Update to transformers 2.8.0\n!pip install -q transformers --upgrade\n!pip show transformers\n!pip install -q pandas --upgrade","c1381ee4":"import os\nimport pickle\nimport json\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, average_precision_score, roc_auc_score, f1_score, accuracy_score\nimport matplotlib.pyplot as plt\nimport transformers as trfm\nfrom transformers import AutoTokenizer, TFAutoModel, TFElectraModel, ElectraTokenizer\nfrom tqdm.notebook import tqdm\nfrom tokenizers import BertWordPieceTokenizer","764203d3":"def build_reranker(tokenizer, model):\n    tokenizer.enable_padding()\n    \n    def rerank(question, answers):\n        pairs = list(zip([question] * len(answers), answers))\n\n        encs = tokenizer.encode_batch(pairs)\n        input_ids = np.array([enc.ids for enc in encs])\n        scores = model.predict(input_ids).squeeze()\n\n        return scores\n    \n    return rerank","189033b3":"def touch_dir(dirname):\n    if not os.path.exists(dirname):\n        os.makedirs(dirname)\n        print(f\"Created directory {dirname}.\")\n    else:\n        print(f\"Directory {dirname} already exists.\")","40de7497":"def fast_encode(texts, tokenizer, chunk_size=256, maxlen=512, enable_padding=False):\n    \"\"\"\n    https:\/\/www.kaggle.com\/xhlulu\/jigsaw-tpu-distilbert-with-huggingface-and-keras\n    \n    ---\n    Inputs:\n        tokenizer: the `fast_tokenizer` that we imported from the tokenizers library\n    \"\"\"\n    tokenizer.enable_truncation(max_length=maxlen)\n    if enable_padding:\n        tokenizer.enable_padding(max_length=maxlen)\n    \n    all_ids = []\n    \n    for i in tqdm(range(0, len(texts), chunk_size)):\n        text_chunk = texts[i:i+chunk_size].tolist()\n        encs = tokenizer.encode_batch(text_chunk)\n        all_ids.extend([enc.ids for enc in encs])\n    \n    return np.array(all_ids)","a5d6c0ed":"def combine_qa_ids(q_ids, a_ids, tokenizer, maxlen=512):\n    \"\"\"\n    Given two arrays of IDs (questions and answers) created by\n    `fast_encode`, we combine and pad them.\n    Inputs:\n        tokenizer: The original tokenizer (not the fast_tokenizer)\n    \"\"\"\n    combined_ids = []\n\n    for i in tqdm(range(q_ids.shape[0])):\n        ids = []\n        ids.append(tokenizer.cls_token_id)\n        ids.extend(q_ids[i])\n        ids.append(tokenizer.sep_token_id)\n        ids.extend(a_ids[i])\n        ids.append(tokenizer.sep_token_id)\n        ids.extend([tokenizer.pad_token_id] * (maxlen - len(ids)))\n\n        combined_ids.append(ids)\n    \n    return np.array(combined_ids)","8309b9ac":"def encode_qa(questions, answers, tokenizer, maxlen=512):\n    \"\"\"\n    https:\/\/www.kaggle.com\/xhlulu\/jigsaw-tpu-distilbert-with-huggingface-and-keras\n    \"\"\"\n    tokenizer.enable_truncation(max_length=maxlen)\n    tokenizer.enable_padding(max_length=maxlen)\n    all_ids = []\n    \n    for i in tqdm(range(0, len(questions))):\n        q = questions[i]\n        a = answers[i]\n        \n        encs = tokenizer.encode(q, a)\n        all_ids.append(encs.ids)\n        if len(encs.ids) > 512:\n            return q, a\n    \n    return np.array(all_ids)","ef08c308":"def build_model(transformer, max_len=None):\n    \"\"\"\n    https:\/\/www.kaggle.com\/xhlulu\/jigsaw-tpu-distilbert-with-huggingface-and-keras\n    \"\"\"\n    input_ids = L.Input(shape=(max_len, ), dtype=tf.int32)\n    \n    x = transformer(input_ids)[0]\n    x = x[:, 0, :]\n    x = L.Dense(1, activation='sigmoid', name='sigmoid')(x)\n    \n    # BUILD AND COMPILE MODEL\n    model = Model(inputs=input_ids, outputs=x)\n    model.compile(\n        loss='binary_crossentropy', \n        metrics=['accuracy'], \n        optimizer=Adam(lr=1e-5)\n    )\n    \n    return model","7c410e55":"def load_model(sigmoid_dir, transformer_dir='transformer', architecture=\"electra\", max_len=None):\n    \"\"\"\n    Special function to load a keras model that uses a transformer layer\n    \"\"\"\n    sigmoid_path = os.path.join(sigmoid_dir,'sigmoid.pickle')\n    \n    if architecture == 'electra':\n        transformer = TFElectraModel.from_pretrained(transformer_dir)\n    else:\n        transformer = TFAutoModel.from_pretrained(transformer_dir)\n    model = build_model(transformer, max_len=max_len)\n    \n    sigmoid = pickle.load(open(sigmoid_path, 'rb'))\n    model.get_layer('sigmoid').set_weights(sigmoid)\n    \n    return model","62db18e5":"tokenizer = trfm.ElectraTokenizer.from_pretrained(\"google\/electra-small-discriminator\")\nfast_tokenizer = BertWordPieceTokenizer('\/kaggle\/input\/healthtap-joint-electra-small\/vocab.txt', lowercase=True, add_special_tokens=False)","c07c4975":"models = {}","a39bc8f8":"models['electra_ht_small'] = load_model(\n    sigmoid_dir='\/kaggle\/input\/healthtap-joint-electra-small',\n    transformer_dir='\/kaggle\/input\/healthtap-joint-electra-small\/transformer',\n    architecture='electra',\n    max_len=None\n)\n\nmodels['electra_ht_small'].summary()","356aff15":"models['electra_ht_base'] = load_model(\n    sigmoid_dir='\/kaggle\/input\/healthtap-joint-electra-base',\n    transformer_dir='\/kaggle\/input\/healthtap-joint-electra-base\/transformer',\n    architecture='electra',\n    max_len=None\n)\n\nmodels['electra_ht_base'].summary()","bc2b83f3":"models['electra_se_small'] = load_model(\n    sigmoid_dir='\/kaggle\/input\/stackexchange-finetune-electra-small\/transformer',\n    transformer_dir='\/kaggle\/input\/stackexchange-finetune-electra-small\/transformer',\n    architecture='electra',\n    max_len=None\n)\n\nmodels['electra_se_small'].summary()","d3520046":"models['electra_se_base'] = load_model(\n    sigmoid_dir='\/kaggle\/input\/stackexchange-finetune-electra-base\/transformer',\n    transformer_dir='\/kaggle\/input\/stackexchange-finetune-electra-base\/transformer',\n    architecture='electra',\n    max_len=None\n)\n\nmodels['electra_se_base'].summary()","adfb4cce":"df = pd.read_csv(\"\/kaggle\/input\/covidqa\/community.csv\")\n\nMAX_LEN = 512\n\nquestions = df.title + ' [SEP] ' + df.question","6fe66e8e":"q_ids = fast_encode(questions.values, fast_tokenizer, maxlen=MAX_LEN\/\/2 - 2)\na_ids = fast_encode(df.answer.values, fast_tokenizer, maxlen=MAX_LEN\/\/2 - 2)\nwa_ids = fast_encode(df.wrong_answer.values, fast_tokenizer, maxlen=MAX_LEN\/\/2 - 2)\n\ncorrect_ids = combine_qa_ids(q_ids, a_ids, tokenizer, maxlen=MAX_LEN)\nwrong_ids = combine_qa_ids(q_ids, wa_ids, tokenizer, maxlen=MAX_LEN)","154b13bf":"input_ids = np.concatenate([correct_ids, wrong_ids])\n\nlabels = np.concatenate([\n    np.ones(correct_ids.shape[0]),\n    np.zeros(correct_ids.shape[0])\n]).astype(np.int32)","46a5bf60":"score_df = pd.concat([df[['url', 'source']]]*2)\n\nfor model_name, model in models.items():\n    %time score_df[model_name] = model.predict(input_ids, batch_size=64)","504142db":"score_df['labels'] = labels","cec2fe52":"score_df.to_csv(\"community.csv\", index=False)","9e13598d":"overall = {}\n\nfor model_name in models.keys():\n    result = {}\n    labels = score_df['labels']\n    score = score_df[model_name]\n    pred = score.round().astype(int)\n    result['ap'] = average_precision_score(labels, score)\n    result['roc_auc'] = roc_auc_score(labels, score)\n    result['f1_score'] = f1_score(labels, pred)\n    result['accuracy'] = accuracy_score(labels, pred)\n    overall[model_name] = result\n\noverall_df = pd.DataFrame(overall).round(4)\noverall_df.to_csv(\"overall_results.csv\")\noverall_df","dd9dcaab":"print(overall_df.to_latex())","821bb77e":"print(overall_df.to_markdown())","e98b0185":"all_sources = {}\n\nfor source in df.source.unique():\n    source_results = {}\n    score_source_df = score_df[score_df.source == source]\n\n    for model_name in models.keys():\n        result = {}\n        labels = score_source_df['labels']\n        score = score_source_df[model_name]\n        pred = score.round().astype(int)\n        result['ap'] = average_precision_score(labels, score)\n        result['roc_auc'] = roc_auc_score(labels, score)\n        result['f1_score'] = f1_score(labels, pred)\n        result['accuracy'] = accuracy_score(labels, pred)\n        source_results[model_name] = result\n    \n    all_sources[source] = pd.DataFrame(source_results).round(4)","e736fed3":"all_sources['biomedical']","4c968618":"all_sources['general']","1c8ab2a5":"all_sources['expert']","4f8cc647":"print('biomedical')\nprint(\"-\"*40)\nprint(all_sources['biomedical'].to_latex())\nprint(\"=\"*40)\n\nprint('general')\nprint(\"-\"*40)\nprint(all_sources['general'].to_latex())\nprint(\"=\"*40)\n\nprint('expert')\nprint(\"-\"*40)\nprint(all_sources['expert'].to_latex())\nprint(\"=\"*40)","6f0a8489":"print('biomedical')\nprint(\"-\"*40)\nprint(all_sources['biomedical'].to_markdown())\nprint(\"=\"*40)\n\nprint('general')\nprint(\"-\"*40)\nprint(all_sources['general'].to_markdown())\nprint(\"=\"*40)\n\nprint('expert')\nprint(\"-\"*40)\nprint(all_sources['expert'].to_markdown())\nprint(\"=\"*40)","9998ac6a":"## Compute Scores","e0e77b6e":"## Load Models","f33b51b4":"## Load Data","7495957e":"## Helper functions","3a083d6a":"## Compute Prediction Results","de8336a0":"### Overall"}}