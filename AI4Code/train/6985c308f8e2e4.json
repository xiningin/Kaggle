{"cell_type":{"ee8d4bf6":"code","4d8f71e6":"code","9abd3d52":"code","b1d3117c":"code","c1a201b1":"code","c88fc1b8":"code","781a1c81":"code","0caa9956":"code","bd688740":"code","10a11347":"code","e9dc29bc":"code","49194b84":"code","3ad9a22f":"code","3629a766":"code","c520efc1":"code","cca26928":"code","e9d8f5b7":"code","0f471250":"code","08a95297":"code","0fb8b2ac":"code","39ba50a1":"code","880ff433":"code","cb0ca669":"code","6d1bb10a":"code","bfa6957d":"code","5032be94":"code","6099e46b":"code","55e01656":"code","3507016b":"code","5f194d59":"code","49409f65":"code","5fe0ed80":"code","2b9403b2":"code","e62f2648":"code","fa3a3f7d":"code","cd7bae0e":"code","cfeb76fc":"code","5a81698a":"code","ec99f23e":"code","1fd10b25":"code","b3ae1a13":"code","465247d3":"code","bc7f2f95":"code","9bcadd12":"code","3c7846cf":"markdown","d6463be4":"markdown","03a13f0f":"markdown","7eb337f1":"markdown","2a9c6a72":"markdown","61f77f2a":"markdown","428a94ab":"markdown","56af685b":"markdown","bb0f566f":"markdown","71a1227b":"markdown","939695c3":"markdown","03a88d15":"markdown","bbc901d0":"markdown","948dc5ad":"markdown","7299b943":"markdown","1ab5e372":"markdown","7237dc05":"markdown","5195ca02":"markdown","ae1b6e14":"markdown","5e1ee43a":"markdown"},"source":{"ee8d4bf6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4d8f71e6":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pandas.plotting import scatter_matrix","9abd3d52":"data = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')","b1d3117c":"data.head()","c1a201b1":"data.shape","c88fc1b8":"data.info()","781a1c81":"data.describe()","0caa9956":"print(\"Number of People Surveyed is equal to \" + str(len(data)))","bd688740":"data.groupby('Outcome').size()","10a11347":"data.columns","e9dc29bc":"data.drop('Outcome', axis = 1).plot(kind='box', subplots=True, layout=(4,3), sharex=False, sharey=False, figsize=(15,15))\nplt.show()","49194b84":"scatter_matrix(data.drop('Outcome', axis = 1), figsize=(12.5,12.5))\nplt.show()","3ad9a22f":"sns.set_theme(style=\"darkgrid\")\nsns.countplot(x= \"Outcome\", data = data).set(xticklabels=[\"Positive\", \"Negative\"])\nplt.xlabel(\"Positive vs Negative Comparison\")\nplt.ylabel(\"Number of People Surveyed\")\nplt.title(\"Comparison\")\nplt.show()","3629a766":"data.hist(figsize=(15,7.5))\nplt.show()","c520efc1":"data.isnull()","cca26928":"data.isnull().sum()","e9d8f5b7":"sns.heatmap(data.isnull(), yticklabels = False, cmap = \"plasma\")\nplt.show()","0f471250":"sns.set_theme(style=\"darkgrid\")\nsns.boxplot(x= \"Outcome\", y=\"Age\", data = data)\nplt.show()","08a95297":"from sklearn.model_selection import train_test_split","0fb8b2ac":"X = data.drop(\"Outcome\", axis = 1)\ny = data[\"Outcome\"]","39ba50a1":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1, test_size = 0.3)","880ff433":"len(X_train)","cb0ca669":"len(X_test)","6d1bb10a":"X_test.info()","bfa6957d":"X_train.info()","5032be94":"categorical = [var for var in data.columns if data[var].dtype=='O']\nprint('There are {} categorical variables\\n'.format(len(categorical)))","6099e46b":"numerical = [var for var in data.columns if data[var].dtype!='O']\nprint('There are {} numerical variables\\n'.format(len(numerical)))\nprint('The numerical variables are :', numerical)","55e01656":"X_train.shape, X_test.shape","3507016b":"X_train.dtypes","5f194d59":"# train a Gaussian Naive Bayes classifier on the training set\nfrom sklearn.naive_bayes import GaussianNB\n\n# instantiate the model\nmodel = GaussianNB()\n\n# fit the model\nmodel.fit(X_train, y_train)","49409f65":"y_pred = model.predict(X_test)\ny_pred","5fe0ed80":"from sklearn.metrics import accuracy_score\nprint('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))","2b9403b2":"from sklearn.metrics import classification_report\nclassification_report(y_test,y_pred)","e62f2648":"from sklearn.metrics import confusion_matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nfig, ax = plt.subplots(figsize=(7.5, 7.5))\nax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\nfor i in range(conf_matrix.shape[0]):\n    for j in range(conf_matrix.shape[1]):\n        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n \nplt.xlabel('Predictions', fontsize=18)\nplt.ylabel('Actuals', fontsize=18)\nplt.title('Confusion Matrix', fontsize=18)\nplt.show()","fa3a3f7d":"cm_matrix = pd.DataFrame(data=conf_matrix, columns=['Actual Positive:1', 'Actual Negative:0'], \n                                 index=['Predict Positive:1', 'Predict Negative:0'])\n\nsns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')","cd7bae0e":"TP = conf_matrix[0,0]\nTN = conf_matrix[1,1]\nFP = conf_matrix[0,1]\nFN = conf_matrix[1,0]","cfeb76fc":"classification_error = (FP + FN) \/ float(TP + TN + FP + FN)\nprint('Classification error : {0:0.4f}'.format(classification_error))","5a81698a":"y_pred_train = model.predict(X_train)\ny_pred_train","ec99f23e":"print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))","1fd10b25":"classification_report(y_train, y_pred_train)","b3ae1a13":"conf_matrix_2 = confusion_matrix(y_train, y_pred_train)\nfig, ax = plt.subplots(figsize=(7.5, 7.5))\nax.matshow(conf_matrix_2, cmap=plt.cm.Blues, alpha=0.3)\nfor i in range(conf_matrix_2.shape[0]):\n    for j in range(conf_matrix_2.shape[1]):\n        ax.text(x=j, y=i,s=conf_matrix_2[i, j], va='center', ha='center', size='xx-large')\n \nplt.xlabel('Predictions', fontsize=18)\nplt.ylabel('Actuals', fontsize=18)\nplt.title('Confusion Matrix', fontsize=18)\nplt.show()","465247d3":"cm_matrix_2 = pd.DataFrame(data=conf_matrix_2, columns=['Actual Positive:1', 'Actual Negative:0'], \n                                 index=['Predict Positive:1', 'Predict Negative:0'])\n\nsns.heatmap(cm_matrix_2, annot=True, fmt='d', cmap='YlGnBu')","bc7f2f95":"TP_2 = conf_matrix_2[0,0]\nTN_2 = conf_matrix_2[1,1]\nFP_2 = conf_matrix_2[0,1]\nFN_2 = conf_matrix_2[1,0]","9bcadd12":"classification_error = (FP_2 + FN_2) \/ float(TP_2 + TN_2 + FP_2 + FN_2)\nprint('Classification error : {0:0.4f}'.format(classification_error))","3c7846cf":"# Compare the train-set and test-set accuracy","d6463be4":"*Let us now describe the data*","03a13f0f":"# Data Analysis","7eb337f1":"*Check the shape of X_train and X_test*","2a9c6a72":"*Find categorical variables*","61f77f2a":"# Check accuracy scores","428a94ab":"*Ok, so it has 768 rows and 9 columns*","56af685b":"*Print classification error*","bb0f566f":"*Let us take a look at the shape of the data set*","71a1227b":"# Let's start predicting","939695c3":"*Now let us take a look at some information regarding this dataset*","03a88d15":"*We now have X_train dataset ready to be fed into the Gaussian Naive Bayes classifier*","bbc901d0":"*Find numerical variables*","948dc5ad":"*Split data into separate training and test set*","7299b943":"*Check data types in X_train*","1ab5e372":"*Now, I will compare the train-set and test-set accuracy to check for overfitting.*","7237dc05":"# Let us import the data set into the data variable","5195ca02":"*The training-set accuracy score and the test-set accuracy score values are quite comparable. So, there is no sign of overfitting.*","ae1b6e14":"*The first 5 rows of the data are*","5e1ee43a":"*Declare feature vector and target variable*"}}