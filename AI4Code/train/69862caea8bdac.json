{"cell_type":{"efdcb68f":"code","f7e36d3d":"code","594cee55":"code","b0eb77fd":"code","e4defd70":"code","fa0d3c6c":"code","c4ff7fa0":"code","d6aa6c1d":"code","a91053ea":"code","56135cf4":"code","14511edf":"code","86c842bb":"code","4da5eb8b":"code","a4b7dcdf":"code","43f90913":"code","18b2ac0d":"code","c25b202d":"code","953a5c58":"code","831f703d":"code","b4b329a5":"code","c8f7efe0":"code","8d5bda75":"code","a0f97374":"code","f2201e7c":"code","b1c07e2f":"code","703e3004":"code","ee674b5f":"code","8ee34b71":"code","0adeee4a":"code","e841373d":"code","5113cadd":"markdown","7b202599":"markdown"},"source":{"efdcb68f":"import pandas as pd\nimport numpy as np\nimport pickle\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom keras.layers.core import Dense, Activation, Dropout\nfrom keras.layers.recurrent import LSTM\nfrom keras.models import Sequential, load_model, save_model\nimport seaborn as sns\nfrom pylab import rcParams\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn import metrics\n\n%matplotlib inline\n\nsns.set(style='whitegrid', palette='muted', font_scale=1.5)\n\nrcParams['figure.figsize'] = 14, 8\n\nRANDOM_SEED = 42","f7e36d3d":"df = pd.read_csv('..\/input\/bajajcombined\/bajaj-2003-2020.csv')","594cee55":"df.columns","b0eb77fd":"plot_x = df['Date'].copy()\ndf.set_index(\"Date\", inplace = True)\ndf.index = pd.to_datetime(df.index)\ndf.head(2)","e4defd70":"print(type(plot_x))","fa0d3c6c":"dff = df[df['Symbol'] == 'BAJFINANCE']\n\ngoogle_stock = dff[dff['Series'] == 'EQ']\ngoogle_stock.head()","c4ff7fa0":"x_scaler = MinMaxScaler()\ny_scaler = MinMaxScaler()\ngoog_df = google_stock.copy()","d6aa6c1d":"goog_df.drop(['Symbol', 'Series', 'No. of Trades'], axis=1, inplace=True)","a91053ea":"goog_df.head()","56135cf4":"x = goog_df[['Prev Close', 'Open Price', 'High Price', 'Low Price', 'Last Price',\n        'Average Price', 'Total Traded Quantity', 'Turnover']].copy()\n\ny = goog_df['Close Price'].copy()\n\nx[['Prev Close', 'Open Price', 'High Price', 'Low Price', 'Last Price',\n        'Average Price', 'Total Traded Quantity', 'Turnover']] = x_scaler.fit_transform(x)\n\ny = y_scaler.fit_transform(y.values.reshape(-1, 1))","14511edf":"def load_data(X, seq_len, train_size=0.9):\n    amount_of_features = X.shape[1]\n    X_mat = X.values\n    sequence_length = seq_len + 1\n    data = []\n    \n    for index in range(len(X_mat) - sequence_length):\n        data.append(X_mat[index: index + sequence_length])\n    \n    data = np.array(data)\n    train_split = int(round(train_size * data.shape[0]))\n    train_data = data[:train_split, :]\n    \n    x_train = train_data[:, :-1]\n    y_train = train_data[:, -1][:,-1]\n    \n    x_test = data[train_split:, :-1] \n    y_test = data[train_split:, -1][:,-1]\n\n    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], amount_of_features))\n    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], amount_of_features))  \n\n    return x_train, y_train, x_test, y_test","86c842bb":"window = 22\nx['close'] = y\nX_train, y_train, X_test, y_test = load_data(x, window)\nprint(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\nprint (X_train[0], y_train[0])","4da5eb8b":"def build_model(input_shape):\n    d = 0.2\n    model = Sequential()\n    \n    model.add(LSTM(128, input_shape=input_shape, return_sequences=True))\n    model.add(Dropout(d))\n        \n    model.add(LSTM(128, input_shape=input_shape, return_sequences=False))\n    model.add(Dropout(d))\n        \n    model.add(Dense(32,kernel_initializer=\"uniform\",activation='relu'))        \n    model.add(Dense(1,kernel_initializer=\"uniform\",activation='linear'))\n    \n    model.compile(loss='mse',optimizer='adam', metrics=['accuracy'])\n    return model","a4b7dcdf":"goog_df.shape","43f90913":"model = build_model(input_shape=(window, 9))","18b2ac0d":"model.fit(X_train, y_train, batch_size=32, epochs=500, verbose=0)","c25b202d":"save_model(model, \"model.h5\")","953a5c58":"model = load_model(\"model.h5\")","831f703d":"trainPredict = model.predict(X_train)\ntestPredict = model.predict(X_test)","b4b329a5":"testPredict.shape","c8f7efe0":"trainPredict.shape","8d5bda75":"trainPredict = y_scaler.inverse_transform(trainPredict)\ntrainY = y_scaler.inverse_transform([y_train])\ntestPredict = y_scaler.inverse_transform(testPredict)\ntestY = y_scaler.inverse_transform([y_test])","a0f97374":"plot_predicted = testPredict.copy()\nplot_predicted = plot_predicted.reshape(241, 1)\nplot_actual = testY.copy()\nplot_actual = plot_actual.reshape(241, 1)\nprint(plot_actual.shape)\nprint(plot_predicted.shape)","f2201e7c":"plot_x = pd.to_datetime(plot_x.iloc[-174:])","b1c07e2f":"plt.plot(pd.DataFrame(plot_predicted), label='Predicted')\nplt.plot(pd.DataFrame(plot_actual), label='Actual')\nplt.legend(loc='best')\nplt.show()","703e3004":"trainScore = metrics.mean_squared_error(trainY[0], trainPredict[:,0]) ** .5\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = metrics.mean_squared_error(testY[0], testPredict[:,0]) ** .5\nprint('Test Score: %.2f RMSE' % (testScore))","ee674b5f":"google_stock.columns","8ee34b71":"google_stock_prices = google_stock['Close Price'].values.astype('float32')\ngoogle_stock_prices = google_stock_prices.reshape(len(google_stock_prices), 1)","0adeee4a":"trainPredictPlot = np.empty_like(google_stock_prices)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[window:len(trainPredict)+window, :] = trainPredict\n\ntestPredictPlot = np.empty_like(google_stock_prices)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[(len(google_stock_prices) - testPredict.shape[0]):len(google_stock_prices), :] = testPredict","e841373d":"plt.plot(pd.DataFrame(google_stock_prices, columns=[\"close\"], index=goog_df.index).close, label='Actual')\nplt.plot(pd.DataFrame(trainPredictPlot, columns=[\"close\"], index=goog_df.index).close, label='Training')\nplt.plot(pd.DataFrame(testPredictPlot, columns=[\"close\"], index=goog_df.index).close, label='Testing')\nplt.legend(loc='best')\nplt.show()","5113cadd":"# Predicting Closing price of Google stocks using LSTM","7b202599":"## Thank you all for reading\n**If you have any question or concern, please leave a comment. Otherwise, see you next time!**"}}