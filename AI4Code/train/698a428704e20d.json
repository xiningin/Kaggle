{"cell_type":{"8fbbcee2":"code","17b16dd1":"code","ee41c411":"code","0dca9843":"code","7ccf2701":"code","c74ebdb0":"code","a917c7f1":"code","af373cf3":"code","f8f7210b":"code","300e662b":"code","cd4d5fbb":"code","fb5141b6":"code","145ad0b6":"code","53262b53":"code","47766006":"code","7a84c156":"code","486baa7b":"code","49802452":"code","ef004451":"code","b8b11dfc":"code","28e7006d":"code","6712ffbb":"code","55847beb":"markdown","fcf4d7fa":"markdown","d1c483d9":"markdown","b4e7d2b0":"markdown","a8ba85e6":"markdown","0e6dba88":"markdown","031beaad":"markdown","b4ee283f":"markdown","fd6d9331":"markdown"},"source":{"8fbbcee2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","17b16dd1":"#importing libraries \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n","ee41c411":"#LOADING THE DATASET\npd.options.display.max_columns = 500\npd.options.display.max_rows = 500\nX = pd.read_csv('..\/input\/novel-corona-virus-2019-dataset\/covid_19_data.csv')","0dca9843":"print(X.shape)","7ccf2701":"print(X.dtypes)","c74ebdb0":"X.head(10)","a917c7f1":"#converting the columns into correct form \nX['ObservationDate'] = pd.to_datetime(X['ObservationDate'])\nX['Last Update'] = pd.to_datetime(X['Last Update'])\nprint(X.dtypes)","af373cf3":"#made a new dataset by extracting the obeservation date\n#by selecting the observation date as the end of each month the entire data for the month is selected \n#grouped them according to country of region \n#only the confirmed cases was extracted \n#sum of each month using .sum()\n#took only the first 10 countries and sorted the total no of confirmed cases in each country in non-ascending order \n\nFirst_Month = X[X['ObservationDate']=='01\/31\/2020'].groupby('Country\/Region')['Confirmed'].sum().head(10).sort_values(ascending = False)","f8f7210b":"Second_Month = X[X['ObservationDate']=='02\/29\/2020'].groupby('Country\/Region')['Confirmed'].sum().head(10).sort_values(ascending = False)","300e662b":"Third_Month = X[X['ObservationDate']=='03\/31\/2020'].groupby('Country\/Region')['Confirmed'].sum().head(10).sort_values(ascending = False)","cd4d5fbb":"Fourth_Month = X[X['ObservationDate']=='04\/30\/2020'].groupby('Country\/Region')['Confirmed'].sum().head(10).sort_values(ascending = False)","fb5141b6":"Fifth_Month = X[X['ObservationDate']=='05\/30\/2020'].groupby('Country\/Region')['Confirmed'].sum().head(10).sort_values(ascending = False)","145ad0b6":"Sixth_Month = X[X['ObservationDate']=='06\/30\/2020'].groupby('Country\/Region')['Confirmed'].sum().head(10).sort_values(ascending = False)","53262b53":"Seventh_Month = X[X['ObservationDate']=='07\/30\/2020'].groupby('Country\/Region')['Confirmed'].sum().head(10).sort_values(ascending = False)","47766006":"fig, ax = plt.subplots(nrows = 2, ncols = 4, figsize = (20,10))\n#fig.tight_layout uses to seperate each of the given subplots so that there is no overlapment \nfig.tight_layout(pad=5.0)\n\nax[0,0].bar(First_Month.index,First_Month)\nax[0,0].set_xticklabels(First_Month.index,rotation = 45)\nax[0,0].title.set_text('January')\n\nax[0,1].bar(Second_Month.index,Second_Month, color = 'g')\nax[0,1].set_xticklabels(Second_Month.index,rotation = 45)\nax[0,1].title.set_text('February')\n\nax[0,2].bar(Third_Month.index,Third_Month, color = 'c')\nax[0,2].set_xticklabels(Third_Month.index,rotation = 45)\nax[0,2].title.set_text('March')\n\nax[0,3].bar(Fourth_Month.index,Fourth_Month, color = 'r')\nax[0,3].set_xticklabels(Fourth_Month.index,rotation = 45)\nax[0,3].title.set_text('April')\n\nax[1,0].bar(Fifth_Month.index,Fifth_Month)\nax[1,0].set_xticklabels(Fifth_Month.index,rotation = 45)\nax[1,0].title.set_text('May')\n\nax[1,1].bar(Sixth_Month.index,Sixth_Month, color = 'g')\nax[1,1].set_xticklabels(Sixth_Month.index,rotation = 45)\nax[1,1].title.set_text('June')\n\nax[1,2].bar(Seventh_Month.index,Seventh_Month, color = 'c')\nax[1,2].set_xticklabels(Third_Month.index,rotation = 45)\nax[1,2].title.set_text('July')\n\nplt.show()\n","7a84c156":"Confirmed_cases = X[X['Country\/Region']=='India'].groupby('ObservationDate')['Confirmed'].sum()\nDeaths_cases = X[X['Country\/Region']=='India'].groupby('ObservationDate')['Deaths'].sum()\nRecovered_cases = X[X['Country\/Region']=='India'].groupby('ObservationDate')['Recovered'].sum()","486baa7b":"plt.figure(figsize = (20,10))\nplt.plot(Confirmed_cases,color = 'c',marker = 'v',label = 'Confirmed_cases')\nplt.plot(Deaths_cases,color = 'g',marker = 'x',label = 'Deaths')\nplt.plot(Recovered_cases,color = 'b',marker = 'o',label = 'Recovered')\nplt.xlabel('Covid-19 Cases count')\nplt.ylabel('total No of Affected people')\nplt.legend\nplt.show()","49802452":"#sorting out the data\nX_India = X[X['Country\/Region']=='India']\narranged_dataset = X_India.groupby(['ObservationDate']).agg({'Confirmed':'sum','Recovered':'sum','Deaths':'sum'})\n","ef004451":"arranged_dataset.tail(15)\narranged_dataset.shape","b8b11dfc":"training_set = arranged_dataset.iloc[:,0:1].values\n\n#Date Preprocessing\nfrom sklearn.preprocessing import MinMaxScaler\nsc = MinMaxScaler(feature_range=(0,1))\ntraining_set_scaled = sc.fit_transform(training_set)\n\n#Creating data structure with 45 timesteps \nX_train = []\ny_train = []\nfor i in range(45,180):\n    X_train.append(training_set_scaled[i-45:i, 0])\n    y_train.append(training_set_scaled[i, 0])\n    \nX_train, y_train = np.array(X_train) , np.array(y_train)   \n\n#Reshaping\nX_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n\n#Initialize the RNN\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\n\nregressor = Sequential()\n\n#Add first LSTM layer and Dropout regularisation\nregressor.add(LSTM(units =50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\nregressor.add(Dropout(0.2))\n\n#Adding second layer\nregressor.add(LSTM(units =50, return_sequences = True))\nregressor.add(Dropout(0.2))\n\n#Adding third layer\nregressor.add(LSTM(units =50, return_sequences = True))\nregressor.add(Dropout(0.2))\n\n#Adding fourth layer\nregressor.add(LSTM(units =50))\nregressor.add(Dropout(0.2))\n\n#Output layer\nregressor.add(Dense(units = 1))\n\nregressor.compile(optimizer = 'adam', loss = 'mse')\n\n#Training the model\n#Taking a small batch size because the number of data points to train on is limited\nregressor.fit(X_train, y_train, epochs = 50, batch_size = 5)","28e7006d":"#Prediction and visualization\nreal_confirmed_cases = arranged_dataset.iloc[170:213,0:1].values\n\nX_test = []\n\nfor i in range(170,213):\n    X_test.append(training_set_scaled[i-45:i, 0])\nX_test = np.array(X_test)\nX_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\npredicted_confirmed_cases = regressor.predict(X_test)\npredicted_confirmed_cases = sc.inverse_transform(predicted_confirmed_cases)","6712ffbb":"plt.figure(figsize = (12,8))\nplt.plot(real_confirmed_cases, color='c',marker = 'o', label = 'Real Confirmed Cases')\nplt.plot(predicted_confirmed_cases, color='g',marker = 'o', label = 'Predicted Number of Cases')\nplt.title('Coronavirus Forecasting Trend in Cases')\nplt.xlabel('Days')\nplt.ylabel('Number of Cases')\nplt.legend()\nplt.show()","55847beb":"Printing different attributes, just to visulaize them and see the details\n","fcf4d7fa":"**The RNN model is forecasting an exponential trend in the number of covid-19 cases which is quite simliar to the Real number of cases.**","d1c483d9":"# Introduction to COVID-19\n<hr>\n\n![COVID-19](https:\/\/techcrunch.com\/wp-content\/uploads\/2020\/02\/coronavirus.jpg)\n*Image Credits : [Scientific Animations](http:\/\/www.scientificanimations.com\/wiki-images\/) under a [CC BY-SA 4.0](https:\/\/creativecommons.org\/licenses\/by-sa\/4.0\/) license*\n\n> **Coronavirus** is a family of viruses that can cause illness, which can vary from *common cold* and *cough* to sometimes more severe disease. **Middle East Respiratory Syndrome (MERS-CoV)** and **Severe Acute Respiratory Syndrome (SARS-CoV)** were such severe cases with the world already has faced.<br> **SARS-CoV-2 (n-coronavirus)** is the new virus of the coronavirus family, which first *discovered* in 2019, which has not been identified in humans before. It is a *contiguous* virus which started from **Wuhan** in **December 2019**. Which later declared as **Pandemic** by **WHO** due to high rate spreads throughout the world. Currently (on the date 10 June 2020), this leads to a total of *500K+ Deaths* across the globe.<br>\nPandemic is spreading all over the world; it becomes more important to understand about this spread. This NoteBook is an effort to analyze the cumulative data of confirmed, deaths, and recovered cases over time. In this notebook, the main focus is to analyze the spread trend of this virus all over the world. \n\n\n### The following two curves shows why we need to flattern the curve and follow the social distancing measures<hr>\n\n\n<div style=\"\">\n    <div style=\"width:70%\"><img src=\"https:\/\/healthblog.uofmhealth.org\/sites\/consumer\/files\/2020-03\/Coronavirus_flattening_curve_1.jpg\"\/><\/div>\n    <div style=\"width:70%\"><img src=\"https:\/\/labblog.uofmhealth.org\/sites\/lab\/files\/2020-04\/flattening_curve_social_distancing.jpg\"\/><\/div>\n<\/div>\n    \n<hr>\n\n#### I will **update** this **notebook** *continuously* with new viz and updated data. \n\n\n**NOTE :** \n* **Since Dataset Structure has been changed and recovered dataset is no longer updated by Johns Hopkins University, Few Visualization has been dropped related to recovered cases and also active cases.**\n\n**<span style = \"color:#cc1616\">Update log:<\/span>**\n* <font style=\"color: rgba(107, 61, 35, 0.92) \"><b>01 Apr 2020 01:35 AM IST (Version 42) :<\/b> Indian Testing Data and Comparision with South Korea Added. <\/font>\n* <font style=\"color: rgba(107, 61, 35, 0.92) \"><b>03 Apr 2020 02:50 AM IST (Version 51) :<\/b> <a href=\"Calander-Map\">Calander-Map<\/a> Added and Visual updates. <\/font>\n* <font style=\"color: rgba(107, 61, 35, 0.92) \"><b>03 Apr 2020 03:40 PM IST (Version 52) :<\/b> Dataset Update and Bug fix. <\/font>\n* <font style=\"color: rgba(107, 61, 35, 0.92) \"><b>05 Apr 2020 01:10 AM IST (Version 54) :<\/b> 2 New section added <a href='#COVID-19-Daily-Analysis'>COVID-19 Daily Analysis<\/a> and <a href='#Testing-Analysis'>Testing Data Analysis<\/a>. Dataset Update and Bug fix. <\/font>\n* <font style=\"color: rgba(107, 61, 35, 0.92) \"><b>15 Apr 2020 02:50 AM IST (Version 61) :<\/b> Dataset Update and Prediction model update. <\/font>\n* <font style=\"color: rgba(107, 61, 35, 0.92) \"><b>02 May 2020 01:50 PM IST (Version 67) :<\/b> Prediction Model Updated. Dataset Update. <\/font>\n* <font style=\"color: rgba(107, 61, 35, 0.92) \"><b>03 May 2020 02:05 AM IST (Version 71) :<\/b> Testing Data Updated. <\/font>\n* <font style=\"color: rgba(107, 61, 35, 0.92) \"><b>16 June 2020 10:45 PM IST (Version 103) :<\/b> Dataset Updated. <\/font>\n* <font style=\"color: rgba(107, 61, 35, 0.92) \"><b>19 June 2020 11:00 PM IST (Version 105) :<\/b> Model Updatet. Some Improvements. Dataset Updated. <\/font>\n* <font style=\"color: rgba(107, 61, 35, 0.92) \"><b>03 July 2020 02:20 AM IST (Version 110) :<\/b> Dataset Updated. <\/font>\n* <font style=\"color: rgba(107, 61, 35, 0.92) \"><b>09 July 2020 01:00 AM IST (Version 112) :<\/b> Dataset Updated. <\/font>\n* <font style=\"color: rgba(107, 61, 35, 0.92) \"><b>12 July 2020 03:00 AM IST (Version 114) :<\/b> Dataset Updated. <\/font>\n* <font style=\"color: #cc1616 \"><b>24 August 2020 05:40 PM IST (Version 120) :<\/b> Dataset Updated. <\/font>\n\n<hr>\n\n### SOURCES:\nhttps:\/\/github.com\/CSSEGISandData\/COVID-19<br>\n2019 Novel Coronavirus COVID-19 (2019-nCoV) Data Repository by Johns Hopkins CSSE\n<br>\nThis dataset is updated on daily basis by Johns Hopkins CSSE\n<hr>\n\n# Please don't PANIC, stay safe, follow your nation and WHO guidelines. We all can defeat this together. Please don't spread rumors.","b4e7d2b0":"# Covid-19 Data Analysis in India ","a8ba85e6":"# **TEN MOST AFFECTED COUNTRIES DURING DIFFERENT MONTHS**","0e6dba88":"# India is now second most affected country in the world and the curve still has not peaked yet. With ~90,000 cases increasing per day, we need to take neccessary precautions and follow the basic guildlines suggested by the Government.\n\n\n\n> I have just begun exploring the field of Data Science and have still got a lot to learn. Will appreciate any kind of feedback or criticism. There is still a lot of things I could have tried with this dataset. Will surely come back and try to improve on this work.\n> \n> Thank You","031beaad":"Covid 19 ANAYLYSIS USING RNN AND PREDICTING EFFECTS OF IT ","b4ee283f":"# Forecasting Using RNN","fd6d9331":"The reason for not using ARIMA model is because ARIMA models are mainly used for linear models.\nBy using RNN models, we can predict more complex patterns from the dataset \n"}}