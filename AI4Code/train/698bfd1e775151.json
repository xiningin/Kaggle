{"cell_type":{"9cf3e24f":"code","8d798a19":"code","809784b7":"code","74d2daf7":"code","0ba89dae":"code","51426fc6":"code","0a683d16":"code","44b29fe9":"code","876d05c9":"code","e36fe3ac":"code","e8735ff2":"code","77717047":"code","90eea8e5":"code","87b99ad2":"code","39f4f8ea":"code","137fcf69":"code","cef2e092":"code","ce951e56":"code","ed33b90b":"code","d2f4febe":"code","0c8ee197":"code","87267257":"code","2ceeee0e":"code","93697939":"code","6044f38e":"code","c0abba41":"code","380f0fc0":"code","0ca5639d":"code","9f75b80f":"code","2b4afef9":"code","3652e36c":"code","5a852950":"code","a1840828":"code","69b9d77f":"code","1ed7a64e":"code","98d4bed3":"code","542e0d0d":"code","f6e452cb":"code","215c2a69":"code","be2de330":"code","62bf9852":"code","c079d319":"code","d5fbc3ff":"code","04cae924":"code","e22e2f1d":"code","71c606fe":"code","042c0be8":"code","fb623f26":"code","25f9e439":"code","6e5337fb":"code","1f85a2c8":"code","1d43a658":"code","0c8f80a7":"code","8e6cdad5":"code","60f62abc":"code","ce9be9ac":"code","de35adbf":"markdown","ae45c8d7":"markdown","ac9af5ce":"markdown","12e21f34":"markdown","2a9bcb44":"markdown","2051b796":"markdown","fe30e320":"markdown","4c1cce24":"markdown","6cd8a0db":"markdown","6731afaf":"markdown","956fe0d6":"markdown","14d252d4":"markdown","305f38ea":"markdown","a3aab7c3":"markdown","687d5818":"markdown","5735fec5":"markdown","de1a2389":"markdown","605bc3f8":"markdown","5ba78c3c":"markdown","0a5e4be2":"markdown","ee91f0d1":"markdown"},"source":{"9cf3e24f":"from tensorflow import keras\nimport numpy as np\nimport pandas as pd\nimport os\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imread\nfrom tensorflow.keras.preprocessing.image import load_img\nimport cv2\nimport gc\nimport random\nimport math\nfrom keras import backend as K\n\nfrom tensorflow.keras.layers import Conv2D,UpSampling2D,Input,LeakyReLU,Activation, add, Concatenate,Lambda\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.applications.vgg16 import VGG16","8d798a19":"def load_imgs(how_many):\n    \"\"\"\n        returns images in range of 'how_many'\n    \"\"\"\n    path = '..\/input\/pascal-voc-2007\/voctrainval_06-nov-2007\/VOCdevkit\/VOC2007\/JPEGImages\/'\n    imgs_path = os.listdir(path)\n    imgs = []\n    \n    for i,img in enumerate(imgs_path):\n        if(i >= how_many):\n            return imgs\n        imgs.append(load_img(path+img))\n    return imgs        ","809784b7":"def to_np_array(images):\n    new_images = []\n    for image in images:\n        new_images.append(np.array(image))\n    return (np.array(new_images)\/255.0)","74d2daf7":"def get_resized_images(images,size):\n    \"\"\"\n        returns 3 np.arrays of the resized images\n        the sizes are 72x72, 144x144, 288x288\n    \"\"\"\n    imgs = []\n    \n    for img in images:\n        img = img.resize((size,size))\n        imgs.append(img)\n        \n    return to_np_array(imgs)","0ba89dae":"# loading only the first 100 pictures\nimgs = load_imgs(100)\n\n# getting the images in 72X72, 144X144, 288X288 pixels\nimgs_72 = get_resized_images(imgs,72)\nimgs_144 = get_resized_images(imgs,144)\nimgs_288 = get_resized_images(imgs,288)\n\n# printing the images shape\nimgs_72.shape,imgs_144.shape,imgs_288.shape","51426fc6":"def plot_imgs(rows,cols,imgs,titles):\n    \"\"\"\n        plots images side by side\n    \"\"\"\n    fix,ax = plt.subplots(rows,cols,figsize=(20,12))\n    for i in range(len(imgs)):\n        if len(imgs)\/\/cols > 1:\n            ax[i\/\/cols,i%cols].set_title(titles[i])\n            ax[i\/\/cols,i%cols].imshow(imgs[i])\n        else:\n            ax[i].set_title(titles[i])\n            ax[i].imshow(imgs[i])","0a683d16":"titles_3 = [\"72x72_train\",\"144x144_train\",\"288x288_train\"]\ncurr_img = 5\nplot_imgs(1,3,[imgs_72[curr_img],imgs_144[curr_img],imgs_288[curr_img]],titles_3)","44b29fe9":"def get_gen_one(lower,upper,size,epochs=1):\n    for e in range(epochs):\n        path = '..\/input\/pascal-voc-2007\/voctrainval_06-nov-2007\/VOCdevkit\/VOC2007\/JPEGImages\/'\n        imgs_path = os.listdir(path)\n    \n        for i,img in enumerate(imgs_path):\n            if(i in range(lower,upper)):\n                curr_img = load_img(path+img)\n                curr_img = curr_img.resize((size,size))\n                curr_img = np.array(curr_img)\/255.0\n                yield np.expand_dims(curr_img,axis=0)","876d05c9":"def get_gen_two(lower,upper,size0,size1,epochs=1):\n    for e in range(epochs):\n        path = '..\/input\/pascal-voc-2007\/voctrainval_06-nov-2007\/VOCdevkit\/VOC2007\/JPEGImages\/'\n        imgs_path = os.listdir(path)\n    \n        for i,img in enumerate(imgs_path):\n            if(i in range(lower,upper)):\n                curr_img0 = load_img(path+img)\n                curr_img0 = curr_img0.resize((size0,size0))\n                curr_img0 = np.array(curr_img0)\/255.0\n            \n                curr_img1 = load_img(path+img)\n                curr_img1 = curr_img1.resize((size1,size1))\n                curr_img1 = np.array(curr_img1)\/255.0\n            \n                yield np.expand_dims(curr_img0,axis=0), np.expand_dims(curr_img1,axis=0)","e36fe3ac":"def get_gen_three(lower,upper,size0,size1,size2,epochs=1):\n    for e in range(epochs):\n        path = '..\/input\/pascal-voc-2007\/voctrainval_06-nov-2007\/VOCdevkit\/VOC2007\/JPEGImages\/'\n        imgs_path = os.listdir(path)\n    \n        for i,img in enumerate(imgs_path):\n            if(i in range(lower,upper)):\n                curr_img = load_img(path+img)\n                curr_img0 = curr_img.resize((size0,size0))\n                curr_img0 = np.array(curr_img0)\/255.0\n            \n                curr_img1 = curr_img.resize((size1,size1))\n                curr_img1 = np.array(curr_img1)\/255.0\n            \n                curr_img2 = curr_img.resize((size2,size2))\n                curr_img2 = np.array(curr_img2)\/255.0\n            \n                yield np.expand_dims(curr_img0,axis=0), [np.expand_dims(curr_img1,axis=0), np.expand_dims(curr_img2,axis=0)]","e8735ff2":"def get_simple_sr_model():\n    inp = Input(shape=(None,None,3))\n    x = Conv2D(64,3,activation=LeakyReLU(0.2),padding='same')(inp)\n    x = Conv2D(64,3,activation=LeakyReLU(0.2),padding='same')(x)    \n    x = UpSampling2D()(x)\n    x = Conv2D(3,1,activation='sigmoid',padding='same',name=\"output_144\")(x)\n    \n    return Model(inp,x)","77717047":"import tensorflow\nfrom PIL import Image\n\nclass Gif_Callback(tensorflow.keras.callbacks.Callback):\n    \n    def __init__(self,imgs,names,folder,two=True):\n        super().__init__()\n        self.imgs = imgs\n        self.preds = []\n        for i in range(len(self.imgs)):\n            self.preds.append([])\n        self.names = names\n        self.folder = folder\n        os.makedirs('.\/'+self.folder)\n        self.two = two\n        \n    def on_epoch_end(self, epoch, logs=None):\n        for i in range(len(self.imgs)):\n            pred = self.model.predict(self.imgs[i])\n            self.preds[i].append(pred)\n            \n    def save_gif(self,p,path,size):\n        mult = 30\n        imgs = []\n        for pi in p:\n            pi = np.array(pi)\n            pi = np.squeeze(pi)\n            img = Image.fromarray(np.uint8(pi*255))\n            img = img.resize((size,size))\n        \n            for i in range(mult):\n                imgs.append(img)\n                \n        imgs[0].save(path,\n               save_all=True, append_images=imgs[1:], optimize=False, duration=40, loop=0)\n        \n        \n    def on_train_end(self,logs=None):\n\n        for i in range(len(self.preds)):\n            p = self.preds[i]\n            path_0 = '.\/'+self.folder+'\/'+str(self.names[i])+'_144.gif'\n            path_1 = '.\/'+self.folder+'\/'+str(self.names[i])+'_288.gif'\n            if(self.two):\n                self.save_gif(p[0],path_0,144)\n                self.save_gif(p[1],path_1,288)\n            else:\n                self.save_gif(p,path_0,144)","90eea8e5":"names = np.arange(10)\nimgs_gif = imgs_72[:10]\nimgs_gif = list(map(lambda img : np.expand_dims(img,axis=0),imgs_gif))","87b99ad2":"first_sr_model = get_simple_sr_model()\nfirst_sr_model.compile(loss='mse',optimizer='adam')\n\nimgs_72_144_gen_train = get_gen_two(0,80,72,144,20)\nimgs_72_144_gen_val = get_gen_two(80,100,72,144,20)\n\nhistory_first = first_sr_model.fit_generator(imgs_72_144_gen_train,\n                              steps_per_epoch=80,\n                              validation_data=imgs_72_144_gen_val,\n                              validation_steps = 20,\n                              epochs=20,\n                              callbacks=[Gif_Callback(imgs_gif,names,\"model1\",two=False)])","39f4f8ea":"def plot_psnr(history,titles):\n    plt.figure(figsize=(10,5))\n    for title in titles:\n        plt.plot(history.history[title])\n    \n    plt.title('Model loss PSNR')\n    plt.ylabel('PSNR Loss')\n    plt.xlabel('Epoch')\n    plt.legend(titles, loc='lower right')\n    plt.show()","137fcf69":"def plot_losses(history,psnr=True):\n    \"\"\"\n        plot losses based on a given model history\n    \"\"\"\n    all_titles = [*history.history.keys()]\n    psnr_titles = list(filter(lambda t: \"PSNR\" in t,all_titles))\n    titles = list(filter(lambda t: \"PSNR\" not in t,all_titles))\n    \n    plt.figure(figsize=(10,5))\n    for title in titles:\n        plt.plot(history.history[title])\n    \n    plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(titles,loc=\"upper right\")\n    plt.show()\n    if(psnr):\n        plot_psnr(history,psnr_titles)","cef2e092":"plot_losses(history_first,psnr=False)","ce951e56":"def plot_predict_imgs(rows,cols,preds,stop,offset,titles):\n    for i in range(stop):\n        preds_lst = [preds[j][i] for j in range(len(preds))]\n        imgs_lst = [imgs_72[i+offset],imgs_144[i+offset],imgs_288[i+offset]]\n        plot_imgs(rows,cols,imgs_lst+preds_lst,titles)","ed33b90b":"# predicting on the last 20 images - validation_data\ntitles_4 = [\"72x72_train\",\"144x144_train\",\"288x288_train\",\"144x144_predict\"]\npreds_first_sr = first_sr_model.predict(imgs_72[80:])\nplot_predict_imgs(1,4,[preds_first_sr],10,80,titles_4)","d2f4febe":"def get_second_sr_model():\n    inp = Input(shape=(None,None,3))\n    x = Conv2D(64,3,activation='relu',padding='same')(inp)\n    x = Conv2D(64,3,activation='relu',padding='same')(x)    \n    x = UpSampling2D()(x)\n    y = UpSampling2D()(x)\n    y = Conv2D(3,1,activation='sigmoid',padding='same',name=\"output_288\")(y)   \n    x = Conv2D(3,1,activation='sigmoid',padding='same',name=\"output_144\")(x)\n    \n    return Model(inputs=inp,outputs=[x,y])","0c8ee197":"second_sr_model = get_second_sr_model()\nsecond_sr_model.compile(loss='mse',optimizer='adam',loss_weights=[0.2,0.8])\n\nimgs_72_144_288_gen_train = get_gen_three(0,80,72,144,288,20)\nimgs_72_144_288_gen_val = get_gen_three(80,100,72,144,288,20)\n\nhistory_second = second_sr_model.fit_generator(imgs_72_144_288_gen_train,\n                              steps_per_epoch=80,\n                              validation_data=imgs_72_144_288_gen_val,\n                              validation_steps = 20,\n                              epochs=20,\n                              callbacks=[Gif_Callback(imgs_gif,names,\"model2\")])","87267257":"plot_losses(history_second,psnr=False)","2ceeee0e":"titles_5 = [\"72x72_train\",\"144x144_train\",\"288x288_train\",\"144x144_predict\",\"288x288_predict\"]\npreds_second_sr = second_sr_model.predict(imgs_72[80:])\nplot_predict_imgs(1,5,preds_second_sr,10,80,titles_5)","93697939":"del preds_second_sr\ngc.collect()","6044f38e":"def PSNR(y_true, y_pred):\n    max_pixel = 1.0\n    return (10.0 * K.log((max_pixel ** 2) \/ (K.mean(K.square(y_pred - y_true), axis=-1)))) \/ 2.303","c0abba41":"imgs_72_144_gen_train = get_gen_three(1000,5012,72,144,288,4)\nimgs_72_144_288_gen_val = get_gen_three(0,1000,72,144,288,4)","380f0fc0":"third_sr_model = get_second_sr_model()\nthird_sr_model.compile(loss='mse',optimizer='adam',loss_weights=[0.2,0.8],metrics=[PSNR])\n\n# validating on the first 1000 images, training on the rest\nhistory_third = third_sr_model.fit_generator(imgs_72_144_gen_train,\n                                             steps_per_epoch=4011,\n                                             validation_data=imgs_72_144_288_gen_val,\n                                             validation_steps = 1000,\n                                             epochs=4,\n                                             callbacks=[Gif_Callback(imgs_gif,names,\"model3\")])","0ca5639d":"plot_losses(history_third)","9f75b80f":"imgs_72_144_288_gen_val = get_gen_three(0,1000,72,144,288)\npreds_third_sr = third_sr_model.predict_generator(imgs_72_144_288_gen_val,1000)\nplot_predict_imgs(1,5,preds_third_sr,10,0,titles_5)","2b4afef9":"del preds_third_sr\ngc.collect()","3652e36c":"def residual_block(h,w,num_cnl):\n    inp = Input(shape=(h,w,num_cnl))\n    x = Conv2D(num_cnl,3,padding='same',activation=LeakyReLU(0.2))(inp)\n    x = Conv2D(num_cnl,3,padding='same',activation=LeakyReLU(0.2))(x)\n    x = add([inp,x])\n    return Model(inp,Activation(LeakyReLU(0.2))(x))","5a852950":"def residual_sr_model(h=None,w=None):\n    inp = Input(shape=(h,w,3))\n    x = Conv2D(32,3,padding='same',activation=LeakyReLU(0.2))(inp)\n    x = residual_block(h,w,32)(x)\n    x = residual_block(h,w,32)(x)\n    x = UpSampling2D(size=(2,2))(x)\n    y = residual_block(h,w,32)(x)\n    y = UpSampling2D(size=(2,2))(y)\n    y = Conv2D(3,1,activation='sigmoid',padding='same',name=\"output_288\")(y)  \n    x = Conv2D(3,1,activation='sigmoid',padding='same',name=\"output_144\")(x)\n    return Model(inputs=inp,outputs=[x,y])","a1840828":"imgs_72_144_gen_train = get_gen_three(1000,5012,72,144,288,4)\nimgs_72_144_288_gen_val = get_gen_three(0,1000,72,144,288,4)","69b9d77f":"fourth_sr_model = residual_sr_model()\nfourth_sr_model.compile(loss='mse',optimizer='adam',metrics=[PSNR])\n\n# validating on the first 1000 images, training on the rest\nhistory_fourth = fourth_sr_model.fit_generator(imgs_72_144_gen_train,\n                                             steps_per_epoch=4011,\n                                             validation_data=imgs_72_144_288_gen_val,\n                                             validation_steps = 1000,\n                                             epochs=4,\n                                             callbacks=[Gif_Callback(imgs_gif,names,\"model4\")])","1ed7a64e":"plot_losses(history_fourth)","98d4bed3":"imgs_72_144_288_gen_val = get_gen_three(0,1000,72,144,288)\npreds_fourth_sr = fourth_sr_model.predict_generator(imgs_72_144_288_gen_val,1000)\nplot_predict_imgs(1,5,preds_fourth_sr,10,0,titles_5)","542e0d0d":"del preds_fourth_sr\ngc.collect()","f6e452cb":"def dilated_block(h,w,num_cnl):\n    inp = Input(shape=(h,w,num_cnl), name='input')\n    d1 = Conv2D(32, 3, padding='same', dilation_rate=(1,1), activation= LeakyReLU(0.2))(inp)\n    d2 = Conv2D(32, 3, padding='same', dilation_rate=(2,2), activation=LeakyReLU(0.2))(inp)\n    d3 = Conv2D(32, 3, padding='same', dilation_rate=(4,4), activation=LeakyReLU(0.2))(inp)\n    x = Concatenate()([d1,d2,d3])\n    x = Activation('relu')(x)\n    x = Conv2D(32, kernel_size=(3,3), padding='same', activation='relu')(x)\n    return Model(inp,x)","215c2a69":"def dilated_sr_model(h=None,w=None):\n    inp = Input(shape=(h,w,3))\n    x = Conv2D(32,3,padding='same',activation=LeakyReLU(0.2))(inp)\n    x = dilated_block(h,w,32)(x)\n    x = dilated_block(h,w,32)(x)\n    x = UpSampling2D(size=(2,2))(x)\n    y = dilated_block(h,w,32)(x)\n    y = UpSampling2D(size=(2,2))(y)\n    y = Conv2D(3,1,activation='sigmoid',padding='same',name=\"output_288\")(y)  \n    x = Conv2D(3,1,activation='sigmoid',padding='same',name=\"output_144\")(x)\n    return Model(inputs=inp,outputs=[x,y])","be2de330":"imgs_72_144_gen_train = get_gen_three(1000,5012,72,144,288,4)\nimgs_72_144_288_gen_val = get_gen_three(0,1000,72,144,288,4)","62bf9852":"fifth_sr_model = dilated_sr_model()\nfifth_sr_model.compile(loss='mse',optimizer='adam',metrics=[PSNR])\n\n# validating on the first 1000 images, training on the rest\nhistory_fifth = fifth_sr_model.fit_generator(imgs_72_144_gen_train,\n                                             steps_per_epoch=4011,\n                                             validation_data=imgs_72_144_288_gen_val,\n                                             validation_steps = 1000,\n                                             epochs=4,\n                                             callbacks=[Gif_Callback(imgs_gif,names,\"model5\")])","c079d319":"plot_losses(history_fifth)","d5fbc3ff":"imgs_72_144_288_gen_val = get_gen_three(0,1000,72,144,288)\npreds_fifth_sr = fifth_sr_model.predict_generator(imgs_72_144_288_gen_val,1000)\nplot_predict_imgs(1,5,preds_fifth_sr,10,0,titles_5)","04cae924":"del preds_fifth_sr\ngc.collect()","e22e2f1d":"def get_vgg_model(h=None,w=None):\n    vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(None,None,3))\n    vgg_layer = Model(inputs=vgg_model.input,outputs=vgg_model.get_layer(\"block1_conv2\").output)\n    \n    inp = Input(shape=(h,w,3))\n    x = Conv2D(64,3,padding='same',activation=LeakyReLU(0.2))(inp)\n    vgg = vgg_layer(inp)\n    x = Conv2D(64,3,padding='same',activation=LeakyReLU(0.2))(x)\n    x = Concatenate()([x,vgg])\n    x = UpSampling2D()(x)\n    z = Conv2D(3,1,activation='sigmoid',padding='same',name=\"output_144\")(x)\n    y = UpSampling2D()(z)\n    y = Conv2D(3,1,activation='sigmoid',padding='same',name=\"output_288\")(y)   \n    return Model(inputs=inp,outputs=[z,y])  ","71c606fe":"imgs_72_144_gen_train = get_gen_three(1000,5012,72,144,288,4)\nimgs_72_144_288_gen_val = get_gen_three(0,1000,72,144,288,4)","042c0be8":"sixth_sr_model = get_vgg_model()\nsixth_sr_model.compile(loss='mse',optimizer='adam',metrics=[PSNR])\n\n# validating on the first 1000 images, training on the rest\nhistory_sixth = sixth_sr_model.fit_generator(imgs_72_144_gen_train,\n                                             steps_per_epoch=4011,\n                                             validation_data=imgs_72_144_288_gen_val,\n                                             validation_steps = 1000,\n                                             epochs=4,\n                                             callbacks=[Gif_Callback(imgs_gif,names,\"model6\")])","fb623f26":"plot_losses(history_sixth)","25f9e439":"imgs_72_144_288_gen_val = get_gen_three(0,1000,72,144,288)\npreds_sixth_sr = sixth_sr_model.predict_generator(imgs_72_144_288_gen_val,1000)\nplot_predict_imgs(1,5,preds_sixth_sr,10,0,titles_5)","6e5337fb":"del preds_sixth_sr\ngc.collect()","1f85a2c8":"def get_depth_to_space_model(h=None,w=None):\n    vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(None,None,3))\n    vgg_layer = Model(inputs=vgg_model.input,outputs=vgg_model.get_layer(\"block1_conv2\").output)\n    \n    inp = Input(shape=(h,w,3))\n    x = Conv2D(64,3,padding='same',activation=LeakyReLU(0.2))(inp)\n    vgg = vgg_layer(inp)\n    x = Conv2D(64,3,padding='same',activation=LeakyReLU(0.2))(x)\n    x = Concatenate(name=\"cnt\")([x,vgg])\n    x = Lambda(lambda x:tf.nn.depth_to_space(x,2),name=\"lamb\")(x)\n    x = Conv2D(3,1,activation='sigmoid',padding='same',name=\"output_144\")(x)\n    z = Conv2D(64,3,activation='sigmoid',padding='same')(x)\n    y = Lambda(lambda x:tf.nn.depth_to_space(x,2),name=\"lamb2\")(z)\n    y = Conv2D(3,1,activation='sigmoid',padding='same',name=\"output_288\")(y)\n    return Model(inp,outputs=[x,y])\n    ","1d43a658":"imgs_72_144_gen_train = get_gen_three(1000,5012,72,144,288,4)\nimgs_72_144_288_gen_val = get_gen_three(0,1000,72,144,288,4)","0c8f80a7":"seventh_sr_model = get_depth_to_space_model()\nseventh_sr_model.compile(loss='mse',optimizer='adam',metrics=[PSNR])\n\n# validating on the first 1000 images, training on the rest\nhistory_seventh = seventh_sr_model.fit_generator(imgs_72_144_gen_train,\n                                             steps_per_epoch=4011,\n                                             validation_data=imgs_72_144_288_gen_val,\n                                             validation_steps = 1000,\n                                             epochs=4,\n                                             callbacks=[Gif_Callback(imgs_gif,names,\"model7\")])","8e6cdad5":"plot_losses(history_seventh)","60f62abc":"titles_5 = [\"72x72_train\",\"144x144_train\",\"288x288_train\",\"144x144_predict\",\"288x288_predict\"]\nimgs_72_144_288_gen_val = get_gen_three(0,1000,72,144,288)\npreds_seventh_sr = seventh_sr_model.predict_generator(imgs_72_144_288_gen_val,1000)\nplot_predict_imgs(1,5,preds_seventh_sr,10,0,titles_5)","ce9be9ac":"del preds_seventh_sr\ngc.collect()","de35adbf":"### We can see a major improvment from the previous model. Although the predictions are relativly blurry, they are much less pixelized especially in the 288x288 predictions. ","ae45c8d7":"# Deep Learning Workshop - Assignment 3 - Pascal VOC 2007\n\n### *Roy Levy - 313577611*\n---\n","ac9af5ce":"### We can see that our images looks pixelized. The improvment is noticeable but is minor.","12e21f34":"## Building Our Third Model\n---\n### After we got a better understanding on how to use our second model it's time to test it on the whole data.<br>First we will load the images and resize them as before, then test it on the second model.","2a9bcb44":"## Building Our Seventh Model\n---\n### Our final method before will be to replace the upsampling block with depth_to_space blocks. This will allow us to learn pixels that are relativly close to the actual ones, we are performing something like pixel shuffling.\n![image.png](attachment:image.png)","2051b796":"### We can see that the transition between the 72x72 train images to the other images are quite the same, in the case of 288x288 the colors are a bit off.","fe30e320":"### First we will define the following PSNR(peak signal to noise ratio) metric, which is relevant to our super-resolution task.","4c1cce24":"### We will use the following callback in order to present a GIF of this model predictions on each epoch","6cd8a0db":"## Building Our Fourth Model\n---\n### We will try to improve our model by adding a residual block.<br>We will construct our model based on the following architecture.\n![image.png](attachment:image.png)\n","6731afaf":"## Building Our First Model - ConvNN on 72x72 images\n---\n### We will start by building a simple convolutional model in the following architechture.<br>We will predict on the 144x144 images.\n\n![image.png](attachment:image.png)","956fe0d6":"### as we can see the loss based on 'mse' is around 0.01. we will try to improve this.<br>still we need to rememeber that this is just a small chunk of our data.<br><br> Now let's look on our predictions so far...","14d252d4":"# Loading the images\n---\n### We will start by loading the images, notice that we will use small amount of images first in order to check if our process works.<br>Once we will get a better understanding of the data we will load all of it and try to use it in our models.","305f38ea":"### We will use the following callback:<br> on each end of epoch our model will predict on all the images given to the callback.<br>The predictions will be later be save as GIF's.","a3aab7c3":"## Building Our Second Model\n---\n### We will try to get a better understanding where our model is more effecient.<br> In order to do so we will add another output layer of the 288x288 images and see the results.\n\n![image.png](attachment:image.png)\n\n### This model will be later used when we will train on the whole data.<br> We will continue to build modifications based on this model.","687d5818":"## Building Our Fifth Model\n---\n### We will try another approach. Instead on the residual block we will add a dialated block, this notion is because we wan't learn also big areas of the input.<br>We will construct our model based on the following architecture.\n![image.png](attachment:image.png)","5735fec5":"### In order to save memory we will define the image generators below","de1a2389":"## Building Our Sixth Model\n---\n### Another method that we will try is to use feature extractor, for instance VGG16.<br>The goal is to use a pretrained network with our model in order to learn better the transition from bad to better resolution of the images.<br>We will use the following architecture:\n![image.png](attachment:image.png)","605bc3f8":"### We can see a littile improvement from our previous models, the predictions are still quite pixelized.<br><br>Let's try another method","5ba78c3c":"## Conclusions\n---\n### We saw that different types of architecture yields different results in our quest to perform the task of Super-Resolutions.<br> We defined the metric of PSNR to test how much we lose in the 'compression' process, i.e. the task.<br>We saw that the although the PSNR stays very much the same, there are still significant results between model.<br> So far our seventh model was the best, we can take the task even further by trying to combine our different models in order to yield better results.","0a5e4be2":"### In this assignment we will try to build a fully-convolutional neural network in order to adress the technique of Super-Resolution<br>Our main goal is trying to improve details of images with bad resolution, the process in order to achieve this goal will be presented in the following article.","ee91f0d1":"### We will use the Pascal VOC 2007 dataset. This dataset is comprise of 5011 with 288x288 images, which we will consider as high resolution.<br> Our goal is to transform these images to low resolution and try to predict with these pictures the high resolution ones."}}