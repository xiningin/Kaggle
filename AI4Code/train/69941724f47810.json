{"cell_type":{"6eb025b3":"code","b9d9d0f5":"code","eabb6308":"code","b9710e6e":"code","11da9cbc":"code","08c0c659":"code","be8a4b30":"code","e92442ce":"code","bc6faa6d":"code","64cb7a98":"code","85eca754":"code","5c70b3d9":"code","5248b830":"markdown","ce292c5a":"markdown","2030d1ac":"markdown","f1580fc2":"markdown","2a250519":"markdown","3b7c0406":"markdown"},"source":{"6eb025b3":"!pip install ..\/input\/pretrainedmodels\/pretrainedmodels-0.7.4\/pretrainedmodels-0.7.4\/ > \/dev\/null\n# package_path = '..\/input\/resnetunetmodelcode'\npackage_path = '..\/input\/senetunetmodelcode'\nimport sys\nsys.path.append(package_path)","b9d9d0f5":"import pdb\nimport os\nimport cv2\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport torch.backends.cudnn as cudnn\nfrom torch.utils.data import DataLoader, Dataset\nfrom albumentations import (Normalize, Compose)\n# from albumentations.torch import ToTensor was renamed to:\nfrom albumentations.pytorch import ToTensor\nimport torch.utils.data as data\nfrom senet_unet_model_code import Unet","eabb6308":"os.listdir('..\/input')","b9710e6e":"!ls ..\/input\/pretrainedmodels\n!ls ..\/input\/resnetunetmodelcode\n!ls ..\/input\/resnetmodels\n!ls ..\/input\/senetunetmodelcode\n!ls ..\/input\/senetmodels","11da9cbc":"#https:\/\/www.kaggle.com\/paulorzp\/rle-functions-run-lenght-encode-decode\ndef mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","08c0c659":"class TestDataset(Dataset):\n    '''Dataset for test prediction'''\n    def __init__(self, root, df, mean, std):\n        self.root = root\n        df['ImageId'] = df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n        self.fnames = df['ImageId'].unique().tolist()\n        self.num_samples = len(self.fnames)\n        self.transform = Compose(\n            [\n                Normalize(mean=mean, std=std, p=1),\n                ToTensor(),\n            ]\n        )\n\n    def __getitem__(self, idx):\n        fname = self.fnames[idx]\n        path = os.path.join(self.root, fname)\n        image = cv2.imread(path)\n        images = self.transform(image=image)[\"image\"]\n        return fname, images\n\n    def __len__(self):\n        return self.num_samples","be8a4b30":"def post_process(probability, threshold, min_size):\n    '''Post processing of each predicted mask, components with lesser number of pixels\n    than `min_size` are ignored'''\n    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n    predictions = np.zeros((256, 1600), np.float32)\n    num = 0\n    for c in range(1, num_component):\n        p = (component == c)\n        if p.sum() > min_size:\n            predictions[p] = 1\n            num += 1\n    return predictions, num","e92442ce":"sample_submission_path = '..\/input\/severstal-steel-defect-detection\/sample_submission.csv'\ntest_data_folder = \"..\/input\/severstal-steel-defect-detection\/test_images\"","bc6faa6d":"# initialize test dataloader\nbest_threshold = 0.5\nnum_workers = 2\nbatch_size = 4\nprint('best_threshold', best_threshold)\nmin_size = 3500\nmean = (0.485, 0.456, 0.406)\nstd = (0.229, 0.224, 0.225)\ndf = pd.read_csv(sample_submission_path)\ntestset = DataLoader(\n    TestDataset(test_data_folder, df, mean, std),\n    batch_size=batch_size,\n    shuffle=False,\n    num_workers=num_workers,\n    pin_memory=True\n)","64cb7a98":"# Initialize mode and load trained weights\n# ckpt_path = \"..\/input\/resnetmodels\/resnet18_20_epochs.pth\"\n# ckpt_path = \"..\/input\/senetmodels\/senet50_20_epochs.pth\"\nckpt_path = \"..\/input\/senetmodels\/senext50_30_epochs.pth\"\ndevice = torch.device(\"cuda\")\n# change the encoder name in the Unet() call.\nmodel = Unet('se_resnext50_32x4d', encoder_weights=None, classes=4, activation=None)\nmodel.to(device)\nmodel.eval()\nstate = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\nmodel.load_state_dict(state[\"state_dict\"])","85eca754":"# start prediction\npredictions = []\nfor i, batch in enumerate(tqdm(testset)):\n    fnames, images = batch\n    batch_preds = torch.sigmoid(model(images.to(device)))\n    batch_preds = batch_preds.detach().cpu().numpy()\n    for fname, preds in zip(fnames, batch_preds):\n        for cls, pred in enumerate(preds):\n            pred, num = post_process(pred, best_threshold, min_size)\n            rle = mask2rle(pred)\n            name = fname + f\"_{cls+1}\"\n            predictions.append([name, rle])\n\n# save predictions to submission.csv\ndf = pd.DataFrame(predictions, columns=['ImageId_ClassId', 'EncodedPixels'])\ndf.to_csv(\"submission.csv\", index=False)","5c70b3d9":"df.head()","5248b830":"## Extension notes\n\nThis notebook is an extension of [Rishabh's](https:\/\/www.kaggle.com\/rishabhiitbhu) [inference kernel](https:\/\/www.kaggle.com\/rishabhiitbhu\/unet-pytorch-inference-kernel). <br>\nIf you find this notebook useful, don't forget to give his notebook an upvote as well. <br>\nI want to thank Rishabh for not only providing the original kernel, but also assisting me with my questions in the comments.\n\nThe notebook is configured to submit results of a U-net architecture with (1) resnet and (2) se_resnet encoders. <br>\nThe following encoders are supported in this notebook:\n\n* (1) resnet18, resnet34, resnet50, resnet101, resnet152\n* (2) senet154, se_resnet50, se_resnet101, se_resnet152, se_resnext50_32x4d, se_resnext101_32x4d\n\nYou can train a model offline with any of the above encoders and submit the results using this notebook.\n\nFour locally trained models are available in this notebook:\n\n1. resnet18_20_epochs.pth the model from the original notebook\n2. senet50_20_epochs.pth a U-net using a pretrained se_resnet50 encoder.\n3. senext50_30_epochs.pth a U-net using a pretrained se_resnext50_32x4d.\n4. senext50_30_epochs_high_threshold.pth a U-net using a pretrained se_resnext50_32x4d encoder where the base_threshold was set to 0.8.\n\nFor the U-net model with the senext50 encoder, setting the base_threshold from 0.5 to 0.8 <br>\nimproved the score from 0.88776 to 0.89648 leaving everything else the same. \n","ce292c5a":"Do upvote if you liked my kernel :)","2030d1ac":"### Model selection instructions\n\nIf you want to use a model included in this notebook:\n\n1. Uncomment the corresponding ckpt_path.\n2. Write the encoder name (see above) into the Unet() call.\n","f1580fc2":"### Refrences (from Rishabh's original notebook):\n\nFew kernels from which I've borrowed some code:\n\n* https:\/\/www.kaggle.com\/amanooo\/defect-detection-starter-u-net\n* https:\/\/www.kaggle.com\/go1dfish\/clear-mask-visualization-and-simple-eda\n\nA big thank you to all those who share their code on Kaggle, I'm nobody without you guys. I've learnt a lot from fellow kagglers, special shout-out to [@Abhishek](https:\/\/www.kaggle.com\/abhishek), [@Yury](https:\/\/www.kaggle.com\/deyury), [@Heng](https:\/\/www.kaggle.com\/hengck23), [@Ekhtiar](https:\/\/www.kaggle.com\/ekhtiar), [@lafoss](https:\/\/www.kaggle.com\/iafoss), [@Siddhartha](https:\/\/www.kaggle.com\/meaninglesslives), [@xhulu](https:\/\/www.kaggle.com\/xhlulu), and the list goes on..","2a250519":"### Available models\n\nThis notebook contains three model.pth files that were trained locally. ","3b7c0406":"### package_path instructions\n\nChange the *package_path*:\n\n* to *'..\/input\/resnetunetmodelcode'* if you use a (1) resnet encoder \n* to *'..\/input\/senetunetmodelcode'* if you use a (2) senet encoder."}}