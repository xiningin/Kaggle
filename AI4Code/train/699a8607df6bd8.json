{"cell_type":{"14c98041":"code","975471c5":"code","b508677e":"code","9c0fddf4":"code","70c4df8c":"code","539cedc6":"code","1e1ee7a0":"code","e2e4bb5f":"code","41ea39f6":"code","2674c810":"code","39c5e72a":"code","ad57e998":"code","4454d581":"code","35eb39ff":"code","4688c724":"code","7fcf9032":"code","a2321b3b":"code","b57e70ab":"code","68b1a41f":"code","d0874c97":"code","d8dd29bf":"code","78672520":"markdown","3c9f09a2":"markdown","d9e973c0":"markdown","23e7726e":"markdown","a18db537":"markdown","2b109bee":"markdown","77a03fcd":"markdown","14824410":"markdown","b5ce2b75":"markdown","5a9d1ac9":"markdown"},"source":{"14c98041":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# note: those to be used for classification will be imported as needed.\n\n# get the directory\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","975471c5":"import warnings\nwarnings.filterwarnings('ignore')","b508677e":"ad = pd.read_csv('\/kaggle\/input\/advertising\/advertising.csv')\nad.head()","9c0fddf4":"ad.info(memory_usage='deep')","70c4df8c":"# converting the datatype of 'timestamp'\nad.Timestamp = pd.to_datetime(ad.Timestamp)\n\n# confirming that there are no null values\nad.isna().sum()","539cedc6":"ad.describe()","1e1ee7a0":"sns.set_style('whitegrid')\n\nplt.figure(figsize=(10,8))\nsns.heatmap(ad.corr(), annot=True, cmap='coolwarm');\nplt.title('Dataset Correlation', loc='left', pad=20, fontsize=15);","e2e4bb5f":"plt.figure(figsize=(10, 7));\n\nsns.histplot(ad.Age,bins=30,kde=True, color='b');\nplt.title('Age Distribution', loc='left', fontsize=15, pad=20);","41ea39f6":"plt.figure(figsize=(10, 7));\n\nxplot = ad.Male.apply(lambda x: 'Female' if x == 0 else 'Male')\nsns.countplot(xplot, palette='coolwarm_r');\nplt.xlabel('Gender');\nplt.title('Distribution by Gender', loc='left', fontsize=15, pad=20);","2674c810":"# getting the most common words in the ad topic line. Using value_counts i\/o Counter for performance sake\n\nplt.figure(figsize=(18, 9))\npd.Series(' '.join(ad['Ad Topic Line']).lower().split()).value_counts()[:20].plot(kind='bar');\nplt.xticks(rotation=45);\nplt.title('Most common words in Ad Topic Line', loc='left', pad=20, fontsize=15);","39c5e72a":"y = ad.copy()\ny['Day of Week'] = y.Timestamp.dt.day_name()\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, sharex=True, figsize=(15, 8));\n\ny.groupby('Day of Week')['Daily Internet Usage'].mean().plot(kind='bar', ax=ax1)\ny.groupby('Day of Week')['Clicked on Ad'].sum().plot(kind='line', color='g', ax=ax2)\nax1.title.set_text('Average Internet Usage by Day of the Week');\nax2.title.set_text('Clicks per Day of the Week');\nax2.set_ylim([50,85]);","ad57e998":"# age vs. area income\nsns.jointplot(x='Age', y='Area Income', data=ad, kind='hex', color='blue');","4454d581":"# age vs. daily time spent on the website\nsns.jointplot(kind='kde', x='Age', y='Daily Time Spent on Site', data=ad, \n              color='darkcyan',shade=True, fill=True);","35eb39ff":"# daily time spent on the website vs. daily internet usage\nsns.jointplot(x='Daily Time Spent on Site', y='Daily Internet Usage', data=ad, \n              hue='Clicked on Ad', palette='inferno_r');","4688c724":"sns.pairplot(ad, hue='Clicked on Ad', palette='inferno_r');","7fcf9032":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nX = ad[['Daily Time Spent on Site', 'Age', 'Area Income','Daily Internet Usage', 'Male']]\ny = ad['Clicked on Ad']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","a2321b3b":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(X_train, y_train)\nlr_pred = lr.predict(X_test)\n\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nlr_acc = accuracy_score(y_test, lr_pred)\n\nprint(f'Model Accuracy: {lr_acc}')\nprint(f'\\nConfusion Matrix: \\n{confusion_matrix(y_test, lr_pred)}')\nprint(f'\\nClassification Report: \\n{classification_report(y_test, lr_pred)}')","b57e70ab":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=1)\nknn.fit(X_train, y_train)\nknn_pred = knn.predict(X_test)\n\nknn_acc = accuracy_score(y_test, knn_pred)\n\nprint(f'Model Accuracy: {knn_acc}')\nprint(f'\\nConfusion Matrix: \\n{confusion_matrix(y_test, knn_pred)}')\nprint(f'\\nClassification Report: \\n{classification_report(y_test, knn_pred)}')","68b1a41f":"# getting the error rate\nerror_rate = []\n\nfor i in range (1, 60):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train, y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))\n\n# plotting the results\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, 60), error_rate, color='darkcyan', linestyle='--',\n        marker='o', markersize=10, markerfacecolor='red')\nplt.title('Error Rate vs K. Value')\nplt.xlabel='K'\nplt.ylabel='Error Rate'\nplt.grid(False)\nplt.show()","d0874c97":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=26)\nknn.fit(X_train, y_train)\nknn_pred = knn.predict(X_test)\n\nknn_acc = accuracy_score(y_test, knn_pred)\n\nprint(f'Model Accuracy: {knn_acc}')\nprint(f'\\nConfusion Matrix: \\n{confusion_matrix(y_test, knn_pred)}')\nprint(f'\\nClassification Report: \\n{classification_report(y_test, knn_pred)}')","d8dd29bf":"models = pd.DataFrame({\n    'Model':['Logistic Regression','KNN'],\n    'Accuracy Score' :[lr_acc, knn_acc]\n})\n\nmodels.sort_values(by='Accuracy Score', ascending=False)","78672520":"# K-Nearest Neighbors","3c9f09a2":"# Model Comparison","d9e973c0":"# Import Libraries and Load the Dataset","23e7726e":"## Choosing a K-Value","a18db537":"### Thank you for your time!\n#### I appreciate you reading this far. If you have any comments and\/or tips for improvement, **please leave a comment!**\n#### Cheers! :)","2b109bee":"## Main ideas:\n* explore the dataset\n* preprocess the data\n* create a **logistic regression model**, use it for predictions and evaluate its performance\n* scale the dataset, build a **KNN model**, get and evaluate the performance. Find the best k-value based on the error rate, tune the model and re-run it\n* compare the performance of both models","77a03fcd":"# Exploratory Data Analysis","14824410":"## Retrain the new K-Value","b5ce2b75":"# Logistic Regression","5a9d1ac9":"# Preprocessing Data"}}