{"cell_type":{"e04dd0f1":"code","07b609bb":"code","940610b8":"code","3f3a5775":"code","c7b3cf3a":"code","005ee195":"code","e9651cda":"code","a790ff3e":"code","baf81560":"code","06c732f9":"code","2875b01d":"code","6f6dda58":"markdown","c4b9c838":"markdown","bd4550ff":"markdown","ffd8d899":"markdown","c9fdc92d":"markdown","2e6cbbd8":"markdown"},"source":{"e04dd0f1":"import numpy as np\nimport pandas as pd\npd.set_option('max_columns', None)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier","07b609bb":"data = pd.read_csv('..\/input\/employee\/train.csv')","940610b8":"data","3f3a5775":"data.info()","c7b3cf3a":"def onehot_encode(df, column):\n    df = df.copy()\n    dummies = pd.get_dummies(df[column], prefix=column)\n    df = pd.concat([df, dummies], axis=1)\n    df = df.drop(column, axis=1)\n    return df","005ee195":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Drop single-value columns and id columns\n    df = df.drop(['EmployeeCount', 'EmployeeNumber', 'Over18', 'StandardHours'], axis=1)\n    \n    # Binary-encode binary columns\n    df['Gender'] = df['Gender'].replace({'Female': 0, 'Male': 1})\n    df['OverTime'] = df['OverTime'].replace({'No': 0, 'Yes': 1})\n    \n    # Ordinal-encode the BusinessTravel column\n    df['BusinessTravel'] = df['BusinessTravel'].replace({'Non-Travel': 0, 'Travel_Rarely': 1, 'Travel_Frequently': 2})\n    \n    # One-hot encoding\n    for column in ['Department', 'EducationField', 'JobRole', 'MaritalStatus']:\n        df = onehot_encode(df, column=column)\n    \n    # Split df into X and y\n    y = df['Attrition']\n    X = df.drop('Attrition', axis=1)\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)\n    \n    # Scale X\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    X_train = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)\n    X_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)\n    \n    return X_train, X_test, y_train, y_test","e9651cda":"X_train, X_test, y_train, y_test = preprocess_inputs(data)","a790ff3e":"X_train","baf81560":"y_train","06c732f9":"models = {\n    \"                   Logistic Regression\": LogisticRegression(),\n    \"                   K-Nearest Neighbors\": KNeighborsClassifier(),\n    \"                         Decision Tree\": DecisionTreeClassifier(),\n    \"Support Vector Machine (Linear Kernel)\": LinearSVC(),\n    \"   Support Vector Machine (RBF Kernel)\": SVC(),\n    \"                        Neural Network\": MLPClassifier(),\n    \"                         Random Forest\": RandomForestClassifier(),\n    \"                     Gradient Boosting\": GradientBoostingClassifier()\n}\n\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    print(name + \" trained.\")","2875b01d":"for name, model in models.items():\n    print(name + \": {:.2f}%\".format(model.score(X_test, y_test) * 100))","6f6dda58":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/5VP00gcgyo8","c4b9c838":"# Preprocessing","bd4550ff":"# Task for Today  \n\n***\n\n## Employee Attrition Prediction  \n\nGiven *data about employees at a company*, let's try to predict whether a given employee will **leave the company** or not.\n\nWe will use a variety of classification models to make our predictions.","ffd8d899":"# Getting Started","c9fdc92d":"# Training","2e6cbbd8":"# Results"}}