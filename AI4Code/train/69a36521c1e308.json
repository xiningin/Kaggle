{"cell_type":{"f71682e2":"code","c8dbc620":"code","6f00da4e":"code","634316ba":"code","5df76178":"code","4bfa47b7":"code","2a3d0187":"code","4b0dec24":"code","85d85a32":"code","ac155e4c":"code","246ae5d6":"code","fe33f882":"code","4bb30718":"code","466fb6af":"code","6116fb96":"code","701f03a5":"code","4dfb7767":"code","593b6722":"code","84394611":"code","f5c0d5ae":"code","8d294b1b":"code","af6f2996":"code","9f59141a":"code","eb04b581":"code","ef162a4b":"code","4e635874":"code","7207e8b3":"code","d4ee15dd":"code","3257e175":"code","da4f266c":"code","0dcf1cba":"code","a2f1f059":"code","649b9847":"code","e5c21604":"code","31106e07":"code","1aa45153":"code","db4f2cf2":"code","726178bf":"markdown","41c14d2f":"markdown","a01b450e":"markdown","ddb715fe":"markdown","ef773bd2":"markdown","32ceb506":"markdown","74fd552b":"markdown","68ccdec1":"markdown","55247e29":"markdown","2084f30a":"markdown","0f7d26f9":"markdown","cf20355f":"markdown","7e64f5bd":"markdown","cbae2352":"markdown","3d2ea44d":"markdown","9fec9911":"markdown","7d8efc44":"markdown","57c7b943":"markdown","dcb39128":"markdown","42487dc5":"markdown","6d872783":"markdown","6c673097":"markdown","2690e7cb":"markdown","557f65a2":"markdown","1fadf604":"markdown","2f724854":"markdown","23f0bd02":"markdown","a6d87339":"markdown","61b85d3a":"markdown","ac3bea88":"markdown","50a55b1c":"markdown","4585354c":"markdown","8747ddae":"markdown","3ba6821f":"markdown","c33c0eec":"markdown","cf916818":"markdown","9100ed33":"markdown","58b14e25":"markdown","8fd82a3a":"markdown","c02573d0":"markdown","6618eae6":"markdown"},"source":{"f71682e2":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c8dbc620":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import tree,svm\nfrom sklearn.metrics import accuracy_score","6f00da4e":"train_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\n\n# Printing first 10 rows of the dataset\ntrain_data.head(10)","634316ba":"print('The shape of our training set: %s passengers and %s features'%(train_data.shape[0],train_data.shape[1]))","5df76178":"train_data.info()","4bfa47b7":"train_data.isnull().sum()","2a3d0187":"heatmap = sns.heatmap(train_data[[\"Survived\", \"SibSp\", \"Parch\", \"Age\", \"Fare\"]].corr(), annot = True)\nsns.set(rc={'figure.figsize':(12,10)})","4b0dec24":"# Finding unique values\ntrain_data['SibSp'].unique()","85d85a32":"bargraph_sibsp = sns.catplot(x = \"SibSp\", y = \"Survived\", data = train_data, kind=\"bar\", height = 8)","ac155e4c":"ageplot = sns.FacetGrid(train_data, col=\"Survived\", height = 7)\nageplot = ageplot.map(sns.distplot, \"Age\")\nageplot = ageplot.set_ylabels(\"Survival Probability\")","246ae5d6":"sexplot = sns.barplot(x=\"Sex\", y=\"Survived\", data=train_data)","fe33f882":"pclassplot = sns.catplot(x = \"Pclass\", y=\"Survived\", data = train_data, kind=\"bar\", height = 6)","4bb30718":"a = sns.catplot(x = \"Pclass\", y=\"Survived\", hue=\"Sex\", data=train_data, height = 7, kind=\"bar\")","466fb6af":"train_data[\"Embarked\"].isnull().sum()","6116fb96":"train_data[\"Embarked\"].value_counts()","701f03a5":"# Filling 2 missing values with most frequent value\ntrain_data[\"Embarked\"] = train_data[\"Embarked\"].fillna('S')","4dfb7767":"sns.catplot(x=\"Embarked\", y=\"Survived\", data=train_data, height = 5, kind=\"bar\")","593b6722":"sns.catplot(x=\"Pclass\", col=\"Embarked\", data = train_data, kind=\"count\", height=7)","84394611":"train_data.isnull().sum()","f5c0d5ae":"mean = train_data[\"Age\"].mean()\nstd = train_data[\"Age\"].std()\nprint(mean)\nprint(std)","8d294b1b":"rand_age = np.random.randint(mean-std, mean+std, size = 177)\nage_slice = train_data[\"Age\"].copy()\n\nage_slice[np.isnan(age_slice)] = rand_age\ntrain_data[\"Age\"] = age_slice\ntrain_data.isnull().sum()","af6f2996":"col_to_drop = [\"PassengerId\", \"Ticket\", \"Cabin\", \"Name\"]\ntrain_data.drop(col_to_drop, axis=1, inplace=True)\ntrain_data.head(10)","9f59141a":"genders = {\"male\":0, \"female\":1}\ntrain_data[\"Sex\"] = train_data[\"Sex\"].map(genders)\n\nports = {\"S\":0, \"C\":1, \"Q\":2}\ntrain_data[\"Embarked\"] = train_data[\"Embarked\"].map(ports)\n\ntrain_data.head()","eb04b581":"df_train_x = train_data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n\n# Target variable column\ndf_train_y = train_data[['Survived']]\n\nx_train, x_test, y_train, y_test = train_test_split(df_train_x, df_train_y, test_size=0.20, random_state=42)","ef162a4b":"clf1 = RandomForestClassifier()\nclf1.fit(x_train, y_train)\nrfc_y_pred = clf1.predict(x_test)\nrfc_accuracy = accuracy_score(y_test,rfc_y_pred) * 100\nprint(\"accuracy=\",rfc_accuracy)","4e635874":"clf2 = LogisticRegression()\nclf2.fit(x_train, y_train)\nlr_y_pred = clf2.predict(x_test)\nlr_accuracy = accuracy_score(y_test,lr_y_pred)*100\n\nprint(\"accuracy=\",lr_accuracy)","7207e8b3":"clf3 = KNeighborsClassifier(5)\nclf3.fit(x_train, y_train)\nknc_y_pred = clf3.predict(x_test)\nknc_accuracy = accuracy_score(y_test,knc_y_pred)*100\n\nprint(\"accuracy=\",knc_accuracy)","d4ee15dd":"clf4 = tree.DecisionTreeClassifier()\nclf4 = clf4.fit(x_train, y_train)\ndtc_y_pred = clf4.predict(x_test)\ndtc_accuracy = accuracy_score(y_test,dtc_y_pred)*100\n\nprint(\"accuracy=\",dtc_accuracy)","3257e175":"clf5 = svm.SVC()\nclf5.fit(x_train, y_train)\nsvm_y_pred = clf5.predict(x_test)\nsvm_accuracy = accuracy_score(y_test,svm_y_pred)*100\nprint(\"accuracy=\",svm_accuracy)","da4f266c":"print(\"Accuracy of Random Forest Classifier =\",rfc_accuracy)\nprint(\"Accuracy of Logistic Regressor =\",lr_accuracy)\nprint(\"Accuracy of K-Neighbor Classifier =\",knc_accuracy)\nprint(\"Accuracy of Decision Tree Classifier = \",dtc_accuracy)\nprint(\"Accuracy of Support Vector Machine Classifier = \",svm_accuracy)","0dcf1cba":"# Importing test.csv\ntest_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest_data.head(10)","a2f1f059":"test_data.info()","649b9847":"test_data.isnull().sum()","e5c21604":"# Replacing missing values of age column\nmean = test_data[\"Age\"].mean()\nstd = test_data[\"Age\"].std()\nrand_age = np.random.randint(mean-std, mean+std, size = 86)\nage_slice = test_data[\"Age\"].copy()\nage_slice[np.isnan(age_slice)] = rand_age\ntest_data[\"Age\"] = age_slice\n\n# Replacing missing value of Fare column\ntest_data['Fare'].fillna(test_data['Fare'].mean(), inplace=True)\n\ntest_data.isnull().sum()","31106e07":"col_to_drop = [\"PassengerId\", \"Ticket\", \"Cabin\", \"Name\"]\ntest_data.drop(col_to_drop, axis=1, inplace=True)\ntest_data.head(10)","1aa45153":"genders = {\"male\":0, \"female\":1}\ntest_data[\"Sex\"] = test_data[\"Sex\"].map(genders)\n\nports = {\"S\":0, \"C\":1, \"Q\":2}\ntest_data[\"Embarked\"] = test_data[\"Embarked\"].map(ports)\n\ntest_data.head()","db4f2cf2":"x_test = test_data\ny_pred = clf1.predict(x_test)\noriginaltest_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\nsubmission = pd.DataFrame({\n        \"PassengerId\": originaltest_data[\"PassengerId\"],\n        \"Survived\": y_pred\n    })\nsubmission.head(20)","726178bf":"# **Final Submission \u2714\ufe0f**","41c14d2f":"177 Missing values in Age column\n687 missing values in Cabin column. \nWe have to deal with these missing values in order to build a good ml model. ","a01b450e":"# **1. Importing Necessary Libraries \ud83d\udcda**","ddb715fe":"## **(D) Pclass**","ef773bd2":"Now we're going to visualise the correlation of each variable with the target variable i.e, Survived.","32ceb506":"# **Making Prediction for Test.csv \ud83d\udcdd**","74fd552b":"**Types of Variables:**\n1. Continuous: Age & Fare\n2. Categorical: Sex & Embarked\n3. Discrete: SibSp & Parch\n4. Alphanumeric: Cabin","68ccdec1":"* Ok so we have 177 null values in Age column.\n* 687 missing values in Cabin column.\n* 2 missing values in Embarked column.","55247e29":"## **Plotting Heat Map \ud83d\uddfa\ufe0f** \n* To see the correlation between target variable and other parameters.","2084f30a":"Since we're getting maximum accuracy score with Random Forest Classifier so we choose it for making predictions on test.csv.","0f7d26f9":"# **3. Exploratory Data Analysis \ud83d\udcc9**","cf20355f":"Passengers embarked from C station, majority of them was from 1st class. That's why we got survival probability of C embarked passengers higher.","7e64f5bd":"# **4. Data Preprocessing (Cleaning) \ud83e\uddf9**","cbae2352":"# **2. Loading Dataset \ud83d\udcca**","3d2ea44d":"## **(F) Embarked**","9fec9911":"## **(D) Converting Categorical Variables to Numeric**","7d8efc44":"## **(C) Sex**","57c7b943":"## **(C) K-Neighbor Classifier**","dcb39128":"# **Will You Survive on Titanic?** \ud83d\udea2","42487dc5":"## **(B) AGE**","6d872783":"## **(B) Dropping \ud83d\uddd1\ufe0f Columns**","6c673097":"**Conclusion:** \nOnly Fare feature seems to have a significant correlation with the survival probability.","2690e7cb":"## **(D) Decision Tree Classifier**","557f65a2":"## **(E) Support Vector Machine**","1fadf604":"**Higher class -> More chances of survival**","2f724854":"## **(A) Random Forest Classifier \ud83c\udf33\ud83c\udf33\ud83c\udf33\ud83c\udf33**","23f0bd02":"## **(G) Pclass vs Survived by Embarked**","a6d87339":"**Checking NULL Values**","61b85d3a":"**Conclusion:** \nMore age -> less chances of survival!","ac3bea88":"## **(A) Handling Missing Values of Age Column**","50a55b1c":"## **(A) SibSp - Number of Siblings \/ Spouses aboard the Titanic**","4585354c":"# **5. Building Machine Learning Model \ud83e\udd16**","8747ddae":"As you can see we have 891 entries in total but some of the columns have less than 891 entries so that means we have missing values in these columns Age, Cabin & Embarked. so we have to preprocess our data first before training our ml model. ","3ba6821f":"**Conclusion:** \n* Passengers having 1 or 2 siblings have good chances of survival\n* More no. of siblings -> Less chances of survival","c33c0eec":"**Conclusion:**\n* In each class females have much higher chances of survival in comparison to male passengers.","cf916818":"**Conclusion:** From the above graph it's quite obvious that females have more chances of survival in comparison to males. ","9100ed33":"## \ud83d\udd17 **[Read Full Blog - Complete ML Project Titanic Survival Prediction](https:\/\/copyassignment.com\/titanic-survival-prediction-machine-learning-project-part-1\/)**","58b14e25":"## **(B) Logistic Regression**","8fd82a3a":"## **Data Preprocessing for testing data**","c02573d0":"# **Accuracy of all 5 Classifiers**","6618eae6":"## **(E) Pclass vs Survived By Sex**"}}