{"cell_type":{"b71d1c3a":"code","1ac01bb0":"code","6e924d97":"code","0300cdee":"code","d3414bca":"code","3e26c728":"code","5b5e1a6d":"code","eab62e42":"code","078c6670":"code","cffd10eb":"code","6711be4e":"code","dd00bbad":"code","f9012686":"code","4d62e12e":"code","0c905a79":"markdown","dc291670":"markdown","ba663111":"markdown","a1804230":"markdown","8f79b04a":"markdown","410d2ef4":"markdown","1a887fe3":"markdown","8aeaf26e":"markdown","0608491e":"markdown","9ff2e1ec":"markdown","832959e9":"markdown","40b59a80":"markdown"},"source":{"b71d1c3a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\n# filter warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","1ac01bb0":"train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","6e924d97":"print(train.shape)\ntrain.head()","0300cdee":"y_train = train[\"label\"]\nx_train = train.drop([\"label\"],axis=1)\nprint(x_train.shape,y_train.shape)","d3414bca":"x_train = x_train\/255.0 # 0-255 colors\ntest = test\/255.0\n\nx_train = x_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)\nprint(x_train.shape,test.shape)","3e26c728":"from keras.utils.np_utils import to_categorical\ny_train = to_categorical(y_train,num_classes=10)","5b5e1a6d":"from sklearn.model_selection import train_test_split\nx_train , x_val, y_train, y_val = train_test_split(x_train,y_train,test_size=0.1,random_state=2)\nprint(x_train.shape,x_val.shape,y_train.shape,y_val.shape)","eab62e42":"from sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters=16,kernel_size=(3,3),padding='same',\n                activation ='relu', input_shape=(28,28,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(filters=16,kernel_size=(3,3),padding='same',\n                activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(1,1)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(filters=16,kernel_size=(3,3),padding='same',\n                activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n#fully connected layer\n\nmodel.add(Flatten())\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10,activation='softmax'))","078c6670":"optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)","cffd10eb":"model.compile(optimizer=optimizer,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])","6711be4e":"datagen = ImageDataGenerator(\n        featurewise_center=False, \n        samplewise_center=False,\n        featurewise_std_normalization=False,\n        samplewise_std_normalization=False,  \n        zca_whitening=False, \n        rotation_range=0.5, \n        zoom_range = 0.5, \n        width_shift_range=0.5,  \n        height_shift_range=0.5,  \n        horizontal_flip=False,  \n        vertical_flip=False)  \n\ndatagen.fit(x_train)","dd00bbad":"history = model.fit_generator(datagen.flow(x_train,y_train, batch_size=25),\n                              epochs = 10, validation_data = (x_val,y_val), steps_per_epoch=x_train.shape[0] \/\/ 25)","f9012686":"plt.plot(history.history[\"val_loss\"],label=\"validation loss\")\nplt.title(\"Test Loss\")\nplt.xlabel(\"Number of epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","4d62e12e":"import seaborn as sns\n\ny_pred = model.predict(x_val)\ny_pred_classes = np.argmax(y_pred,axis = 1) \ny_true = np.argmax(y_val,axis = 1) \nconfusion_mtx = confusion_matrix(y_true, y_pred_classes) \nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","0c905a79":"A you can see here there are 42000 images and every image has 785 column.First one is their labels which means which number they represent, and others are pixel values.","dc291670":"Now i will plot my loss and accuracy.","ba663111":"I have a test data but i need labeled test datas.So i will split my train data to train and validation.","a1804230":"In this kernel , i will implement a Convolutional Neural Network in order to classify my images.","8f79b04a":"It's time to encode my labels into a vector.","410d2ef4":"It is time for creating my model.\n\nconv -> maxpool -> dropout -> conv -> maxpool -> dropout -> conv -> maxpool -> dropout -> flatten -> fully connected layers","1a887fe3":"Now i will split labels and pixel values.","8aeaf26e":"I'll perform normalization because i want my network to work faster.In addition , i will reshape my data's because keras need 3 dimension images because of RGB by image will be gray-scale so it's third dimension will be one.","0608491e":"I will compile my model.","9ff2e1ec":"Optimizer : Adam ","832959e9":"Firstly, i will import my data.","40b59a80":"Now in order to prevent overfitting i will generate some data."}}