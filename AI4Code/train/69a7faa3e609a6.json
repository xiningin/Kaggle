{"cell_type":{"f837d770":"code","dfb9651e":"code","11fe7743":"code","6b83e30c":"code","f43c3d76":"code","98fd6d78":"code","96c329b5":"code","2074146f":"code","b6eaba47":"code","5a168c1d":"code","9f0f18c4":"code","824f3794":"code","511ab408":"code","708b48b6":"code","9dd6b4f1":"code","e08b905a":"code","41aba368":"code","0bd506dd":"code","eb9c5606":"code","20812c3b":"code","fc51c0c6":"code","fc683471":"code","6b810dfa":"code","7e277387":"code","5d219d04":"code","93e52345":"code","60556285":"code","5e516aaa":"code","7561e1f3":"code","2c64595e":"code","9cae82be":"code","bf89a44b":"code","e04d30a3":"code","0903deb3":"code","5de23f77":"code","038bf5ff":"code","6965fa43":"code","28948743":"code","ba760794":"code","4d6175c9":"code","49834a87":"markdown","75e019a3":"markdown","d1259ed5":"markdown","a3388a46":"markdown","c19de03a":"markdown","a930a0a7":"markdown","736b3d77":"markdown","dfbcc48d":"markdown","f1211a72":"markdown","fdc9c999":"markdown","986e54d2":"markdown","d0a7c9dd":"markdown","7e5a6060":"markdown","6a8ba685":"markdown","7935df1a":"markdown","df215b89":"markdown","3faf5acb":"markdown","29aef3c9":"markdown"},"source":{"f837d770":"import io\nimport random\nimport string # to process standard python strings\nimport warnings\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport nltk\nfrom nltk.tokenize import sent_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.stem import PorterStemmer\n\n# sklearn imports\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn import metrics\n\n# pandas\nimport pandas as pd\n\n# python imports\nimport re\nimport json\nfrom collections import Counter\nfrom matplotlib import pyplot as plt\n\n# Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import feature_extraction, linear_model, model_selection, preprocessing\nimport plotly.graph_objs as go\nimport plotly.offline as py\nimport plotly.express as px\n\nimport matplotlib.animation as animation\nfrom matplotlib.widgets import Slider\n\nfrom wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook\n\nimport matplotlib.patches as patches\nfrom matplotlib import rc\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\n\nrc('animation', html='jshtml')\nstopwords = set(STOPWORDS)\n\n\nimport pickle","dfb9651e":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","11fe7743":"#pip install nltk","6b83e30c":"#import nltk\n#from nltk.stem import WordNetLemmatizer\nnltk.download('popular', quiet=True) # for downloading packages\n#nltk.download('punkt') # first-time use only\n#nltk.download('wordnet') # first-time use only","f43c3d76":"f=open('..\/input\/chatbot\/chatbot.txt','r',errors = 'ignore')\n#f = pd.read_fwf('..\/input\/chatbot.txt',delimiter = \"\\t\")\nraw=f.read()\nraw = raw.lower()# converts to lowercase\nraw","98fd6d78":"raw =\"\"\"How dangerous is the coronavirus Covid-19 is deadly, although fatality rates skyrocket for the elderly and those with compromised immune systems.How has the coronavirus affected you Well if you ask me personally, the outbreak of novel Coronavirus, has affected me significantly. Both in respect of career and in respect of mental health. Is there a treatment for the Coronavirus They are experimenting with various medicines and it seems some anti-malarial drugs show promise. However, they help only a little bit, as evidenced by the mortality rate in places like Italy or Spain. They are best if administered early, before the lungs are damaged. Is there a vaccine for the coronavirus We don\u2019t \u201cfind\u201d vaccines. That\u2019s the language yellow media uses, but it\u2019s far from the truth.\nWe know the virus, and we know what it looks like. Now we need to produce a sufficient amount of attenuated virii. For that, we inject the virus into a foreign host, like a chicken embryo in an egg. Most viruses will die, because the host is so different from humans, that it can not work. Some will mutate to work, and those multiply.How did coronaviruses get their name The coronavirus family was discovered first in 1960s but we don\u2019t know where they come from. They get the name given their crown-like (\u201ccorona\u201d) shape. Following a December 2019 outbreak in China, the World Health Organization identified a new type called 2019 novel coronavirus (2019-nCoV).What are coronaviruses Coronavirus is a name for a group of viruses that target mammals, including cats, dogs, and humans. They\u2019re well known for causing potentially fatal conditions like kidney failure, pneumonia but also mundane things like some instances of the common cold.\nDoes coronavirus cause death Statistically speaking, you have a 98% chance of survival, and 80% chance that you won\u2019t need medical care at all even if you get infected, so stay positive, stay at home as much as possible, eat healthy, treat everyone as if they are infected, treat other as if you are infected. Many people get infected and get better without even knowing they had it.What can one do to prepare for the coronavirus? What should one buy or do regularly So, one thing you might do before it hits your region is to buy enough food for your freezer as well as canned goods and stock it so that, when the Virus hits, you won\u2019t be running out into a store crowded with infected people. When it hits, stay home for work and school and strictly avoid crowded places. Stock up on real bar soap (like Ivory Gold) and wash hands frequently. Avoid sanitizers. Try to avoid clinics or EDs unless your symptoms become an issue as you don\u2019t want to spread the disease beyond your home. Stock up on jello, G-Zero, plain decongestants like Mucinex, Bouillon or clear soups, lots of Kleenex and avoid solids and dairy products while you are symptomatic. The rest is just common sense.What should I buy to prepare for a coronavirus epidemic if I had to stay in my home for a very long time So, one thing you might do before it hits your region is to buy enough food for your freezer as well as canned goods and stock it so that, when the Virus hits, you won\u2019t be running out into a store crowded with infected people. When it hits, stay home for work and school and strictly avoid crowded places. Stock up on real bar soap (like Ivory Gold) and wash hands frequently. Avoid sanitizers. Try to avoid clinics or EDs unless your symptoms become an issue as you don\u2019t want to spread the disease beyond your home. Stock up on jello, G-Zero, plain decongestants like Mucinex, Bouillon or clear soups, lots of Kleenex and avoid solids and dairy products while you are symptomatic. The rest is just common sense.\nWhat are the symptoms of Coronavirus The symptoms of this virus include high fever, respiratory problems, shortness of breath and coughing. In extreme cases, it can even lead to pneumonia, kidney failure and death.To prevent infection from spreading, one should wash hands regularly, cover mouth and nose while coughing and sneezing and eat properly cook meat and eggs.\"\"\"","96c329b5":"sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences \nword_tokens = nltk.word_tokenize(raw)# converts to list of words","2074146f":"lemmer = nltk.stem.WordNetLemmatizer()\n#WordNet is a semantically-oriented dictionary of English included in NLTK.\ndef LemTokens(tokens):\n    return [lemmer.lemmatize(token) for token in tokens]\nremove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n\ndef LemNormalize(text):\n    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))","b6eaba47":"GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\", \"hi Babe\", \"how are you?\")\nGREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\",\"Thanks for asking\"]\ndef greeting(sentence):\n \n    for word in sentence.split():\n        if word.lower() in GREETING_INPUTS:\n            return random.choice(GREETING_RESPONSES)","5a168c1d":"def response(user_response):\n    robo_response=''\n    sent_tokens.append(user_response)\n    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n    tfidf = TfidfVec.fit_transform(sent_tokens)\n    vals = cosine_similarity(tfidf[-1], tfidf)\n    idx=vals.argsort()[0][-2]\n    flat = vals.flatten()\n    flat.sort()\n    req_tfidf = flat[-2]\n    if(req_tfidf==0):\n        robo_response=robo_response+\"I am sorry! I don't understand you\"\n        return robo_response\n    else:\n        robo_response = robo_response+sent_tokens[idx]\n        return robo_response","9f0f18c4":"flag=True\nprint(\"ROBO: My name is Robo. I will answer your queries about Chatbots. If you want to exit, type Bye!\")\nwhile(flag==True):\n    user_response = input()\n    user_response=user_response.lower()\n    if(user_response!='bye'):\n        if(user_response=='thanks' or user_response=='thank you' ):\n            flag=False\n            print(\"ROBO: You are welcome..\")\n        else:\n            if(greeting(user_response)!=None):\n                print(\"ROBO: \"+greeting(user_response))\n            else:\n                print(\"ROBO: \",end=\"\")\n                print(response(user_response))\n                sent_tokens.remove(user_response)\n    else:\n        flag=False\n        print(\"ROBO: Bye! take care..\")","824f3794":"!pip install allennlp","511ab408":"from allennlp.predictors.predictor import Predictor\npredictor = Predictor.from_path(\"https:\/\/s3-us-west-2.amazonaws.com\/allennlp\/models\/bidaf-model-2017.09.15-charpad.tar.gz\")","708b48b6":"passage =\"\"\"How dangerous is the coronavirus?\nCovid-19 is deadly, although fatality rates skyrocket for the elderly and those with compromised immune systems.\n\nHow has the coronavirus affected you?\nWell if you ask me personally, the outbreak of novel Coronavirus, has affected me significantly. Both in respect of career and in respect of mental health.\n\nIs there a treatment for the Coronavirus?\nThey are experimenting with various medicines and it seems some anti-malarial drugs show promise. However, they help only a little bit, as evidenced by the mortality rate in places like Italy or Spain. They are best if administered early, before the lungs are damaged.\n\nIs there a vaccine for the coronavirus?\nWe don\u2019t \u201cfind\u201d vaccines. That\u2019s the language yellow media uses, but it\u2019s far from the truth.\nWe know the virus, and we know what it looks like. Now we need to produce a sufficient amount of attenuated virii. For that, we inject the virus into a foreign host, like a chicken embryo in an egg. Most viruses will die, because the host is so different from humans, that it can not work. Some will mutate to work, and those multiply.\n\nHow did coronaviruses get their name?\nThe coronavirus family was discovered first in 1960s but we don\u2019t know where they come from. They get the name given their crown-like (\u201ccorona\u201d) shape. Following a December 2019 outbreak in China, the World Health Organization identified a new type called 2019 novel coronavirus (2019-nCoV).\n\nWhat are coronaviruses?\nCoronavirus is a name for a group of viruses that target mammals, including cats, dogs, and humans. They\u2019re well known for causing potentially fatal conditions like kidney failure, pneumonia but also mundane things like some instances of the common cold.\n\n\nDoes coronavirus cause death?\nStatistically speaking, you have a 98% chance of survival, and 80% chance that you won\u2019t need medical care at all even if you get infected, so stay positive, stay at home as much as possible, eat healthy, treat everyone as if they are infected, treat other as if you are infected. Many people get infected and get better without even knowing they had it.\n \nWhat can one do to prepare for the coronavirus? What should one buy or do regularly?\nSo, one thing you might do before it hits your region is to buy enough food for your freezer as well as canned goods and stock it so that, when the Virus hits, you won\u2019t be running out into a store crowded with infected people. When it hits, stay home for work and school and strictly avoid crowded places. Stock up on real bar soap (like Ivory Gold) and wash hands frequently. Avoid sanitizers. Try to avoid clinics or EDs unless your symptoms become an issue as you don\u2019t want to spread the disease beyond your home. Stock up on jello, G-Zero, plain decongestants like Mucinex, Bouillon or clear soups, lots of Kleenex and avoid solids and dairy products while you are symptomatic. The rest is just common sense.\n\nWhat should I buy to prepare for a coronavirus epidemic if I had to stay in my home for a very long time?\nSo, one thing you might do before it hits your region is to buy enough food for your freezer as well as canned goods and stock it so that, when the Virus hits, you won\u2019t be running out into a store crowded with infected people. When it hits, stay home for work and school and strictly avoid crowded places. Stock up on real bar soap (like Ivory Gold) and wash hands frequently. Avoid sanitizers. Try to avoid clinics or EDs unless your symptoms become an issue as you don\u2019t want to spread the disease beyond your home. Stock up on jello, G-Zero, plain decongestants like Mucinex, Bouillon or clear soups, lots of Kleenex and avoid solids and dairy products while you are symptomatic. The rest is just common sense.\n\nWhat are the symptoms of Coronavirus?\nThe symptoms of this virus include high fever, respiratory problems, shortness of breath and coughing. In extreme cases, it can even lead to pneumonia, kidney failure and death.\nTo prevent infection from spreading, one should wash hands regularly, cover mouth and nose while coughing and sneezing and eat properly cook meat and eggs.\"\"\"","9dd6b4f1":"result=predictor.predict(\n  passage=passage,\n  question=\"how are coronavirus?\"\n)\nresult['best_span_str']","e08b905a":"result=predictor.predict(\n  passage=passage,\n  question=\"what is symptoms\"\n)\nresult['best_span_str']","41aba368":"result=predictor.predict(\n  passage=passage,\n  question=\" death reason\"\n)\nresult['best_span_str']","0bd506dd":"result=predictor.predict(\n  passage=passage,\n  question=\"How dangerous is the coronavirus\"\n)\nresult['best_span_str']","eb9c5606":"pip install tweepy","20812c3b":"import tweepy as tw\nimport pandas as pd\nimport json\n\n# App Auth\nconsumer_key = 'XXX'\nconsumer_secret = 'XXX'\naccess_key = 'XXX'\naccess_secret = 'XXX'\n\n# Initialize API\nauth = tw.OAuthHandler(consumer_key, consumer_secret)\nauth.set_access_token(access_key, access_secret)\napi = tw.API(auth, wait_on_rate_limit=True)\n\n# Search terms\nsearch_words = [\"#coronavirus\", \"#COVID19\", \"#CoronavirusOutbreak\"]\ndate_since = \"2020-02-01\"\n\n# Collect tweets\ntweets = tw.Cursor(api.search,\n              q=search_words,\n              lang=\"en\",\n              since=date_since, tweet_mode='extended',\n              include_rts=True).items(1000)\n\ntweets_arr = []\n\n# Iterate and print tweets\nfor tweet in tweets:\n    tweets_arr.append(tweet._json)\nprint(\"Done\")\n\nwith open(\"data.json\", \"w+\") as output:\n    output.write(json.dumps(tweets_arr))","fc51c0c6":"# preprocessor data sources and instances\nnltk.download('stopwords')\nnltk.download('punkt')\nstop_words = set(stopwords.words(\"english\"))\nps = PorterStemmer()\ntf = TfidfVectorizer()\n","fc683471":"Y = []\nsentences = []\nsentences_processed = []\nsentences_processed_tw = []","6b810dfa":"# Reading data and creating sentences from data source\nwith open(\".\/data\/processed_stars_all\") as data:\n    all_data = data.read().strip().split(\"\\n\")\n    for n, line in enumerate(all_data):\n        line_data = line.split(\" \")[0:-1]\n        sentence = \"\"\n        for words_count in line_data:\n            words = words_count.split(\":\")[0].split(\"_\")\n            count = int(words_count.split(\":\")[1])\n            words = list(filter(\"<num>\".__ne__, words))\n            words = list(map(lambda x: re.sub(r'\\`|\\'|,|\\.|\\\"', '', x), words))","7e277387":"df_ny_tweet_overtime = None\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in sorted(filenames)[:-2]:\n        print(f\"processing {filename}\")\n        filepath = os.path.join(dirname, filename)\n        df = pd.read_csv(filepath,\n                         usecols=[\"created_at\", \"text\", \"place_full_name\"]\n                        )\n        df = df[df[\"place_full_name\"].str.contains(\"NY\", na=False)]\n        if df_ny_tweet_overtime is None:\n            df_ny_tweet_overtime = df\n        else:\n            df_ny_tweet_overtime = pd.concat([df_ny_tweet_overtime, df])","5d219d04":"df_ny_tweet_overtime.info()","93e52345":"df_ny_tweet_overtime[\"created_at\"] = pd.to_datetime(df_ny_tweet_overtime[\"created_at\"])\ndf_ny_tweet_overtime[\"creation_date\"] = df_ny_tweet_overtime[\"created_at\"].dt.date\n\ndf_ny_tweet_overtime = df_ny_tweet_overtime.reset_index()\ndf_ny_tweet_overtime = df_ny_tweet_overtime.drop(\"index\", axis=1)","60556285":"stopwords.update([\"Covid19\", \"Covid 19\", \"Covid_19\", \"CoronaVirus\", \"Coronavirus\", \"CoronavirusOutbreak\", \"https\"])\n               \ndef get_word_count(data):\n    return WordCloud(\n        background_color='white',\n        stopwords=stopwords,\n        max_words=50,\n        max_font_size=40, \n        scale=5,\n        random_state=1,\n        collocations=False\n    ).generate(str(data))","5e516aaa":"dates, snapshots = zip(*[ (date, get_word_count('\\n'.join(group[\"text\"]))) \\\n                  for date, group in df_ny_tweet_overtime.groupby(\"creation_date\") ])\nframes = np.arange(len(dates))\nfig = plt.figure(figsize=(15,15))\nax = fig.add_axes([0,0,1,1])\nax.axis('off')\na = snapshots[0]\nim = ax.imshow(a)\nttl = ax.set_title(dates[0], fontdict={\"fontsize\": 100, \"color\": \"r\"})\n\ndef animate_func(i):\n    im.set_array(snapshots[i])\n    ttl.set_text(dates[i])\n    return [im]\nanim = animation.FuncAnimation(\n                               fig, \n                               animate_func, \n                               frames = frames,\n                               interval = 1000,\n                               )\n","7561e1f3":"anim","2c64595e":"anim.save(\"anim.gif\", writer=\"imagemagick\")","9cae82be":"from subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))","bf89a44b":"df_ny_tweet_overtime.head()","e04d30a3":"from nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom nltk.sentiment.util import *\n\nfrom nltk import tokenize\n\nsid = SentimentIntensityAnalyzer()\n\ndf_ny_tweet_overtime['sentiment_compound_polarity']=df_ny_tweet_overtime.text.apply(lambda x:sid.polarity_scores(x)['compound'])\ndf_ny_tweet_overtime['sentiment_neutral']=df_ny_tweet_overtime.text.apply(lambda x:sid.polarity_scores(x)['neu'])\ndf_ny_tweet_overtime['sentiment_negative']=df_ny_tweet_overtime.text.apply(lambda x:sid.polarity_scores(x)['neg'])\ndf_ny_tweet_overtime['sentiment_pos']=df_ny_tweet_overtime.text.apply(lambda x:sid.polarity_scores(x)['pos'])\ndf_ny_tweet_overtime['sentiment_type']=''\ndf_ny_tweet_overtime.loc[df_ny_tweet_overtime.sentiment_compound_polarity>0,'sentiment_type']='POSITIVE'\ndf_ny_tweet_overtime.loc[df_ny_tweet_overtime.sentiment_compound_polarity==0,'sentiment_type']='NEUTRAL'\ndf_ny_tweet_overtime.loc[df_ny_tweet_overtime.sentiment_compound_polarity<0,'sentiment_type']='NEGATIVE'\ndf_ny_tweet_overtime.head()","0903deb3":"df_ny_tweet_overtime.to_csv('tweet.csv')","5de23f77":"df_ny_tweet_overtime.sentiment_type.value_counts().plot(kind='bar',title=\"sentiment analysis\")","038bf5ff":"pip install ggplot","6965fa43":"pip install torch","28948743":"pip install flask","ba760794":"pip install git+https:\/\/github.com\/huggingface\/pytorch-pretrained-BERT.git","4d6175c9":"python server.py","49834a87":"## Keyword matching\n\nNext, we shall define a function for a greeting by the bot i.e if a user\u2019s input is a greeting, the bot shall return a greeting response.ELIZA uses a simple keyword matching for greetings. We will utilize the same concept here.","75e019a3":"My Model - https:\/\/drive.google.com\/uc?id=15HOJmRizBrgoPPVDHKpvSO2tNf0k-d8f&export=download","d1259ed5":"### Switching to another Method to try the best process","a3388a46":"## Reading in the corpus\n\nFor our example,we will be using the Wikipedia page for chatbots as our corpus. Copy the contents from the page and place it in a text file named \u2018chatbot.txt\u2019. However, you can use any corpus of your choice.","c19de03a":"passage =\"\"\" Coronavirus disease 2019 (COVID-19) is an infectious disease caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2).[7] The disease was first identified in December 2019 in Wuhan, the capital of China's Hubei province, and has since spread globally, resulting in the ongoing 2019\u201320 coronavirus pandemic.[8][9] Common symptoms include fever, cough, and shortness of breath.[10] Other symptoms may include muscle pain, sputum production, diarrhea, sore throat, loss of smell, and abdominal pain.[4][11][12] While the majority of cases result in mild symptoms, some progress to viral pneumonia and multi-organ failure.[8][13] As of 28 March 2020, the overall rate of deaths per number of diagnosed cases is 4.7 percent; ranging from 0.2 percent to 15 percent according to age group and other health problems.[14] In comparison, the mortality rate of the 1918 flu pandemic was approximately 3% to 5%.[15]\nThe virus is spread mainly through close contact and via respiratory droplets produced when people cough or sneeze.[16][17] Respiratory droplets may be produced during breathing but the virus is not generally airborne.[16][18] People may also contract COVID-19 by touching a contaminated surface and then their face.[16][17] It is most contagious when people are symptomatic, although spread may be possible before symptoms appear.[17] The virus can survive on surfaces up to 72 hours.[19] Time from exposure to onset of symptoms is generally between two and fourteen days, with an average of five days.[10][20] The standard method of diagnosis is by reverse transcription polymerase chain reaction (rRT-PCR) from a nasopharyngeal swab.[21] The infection can also be diagnosed from a combination of symptoms, risk factors and a chest CT scan showing features of pneumonia.[22][23]\"\"\"","a930a0a7":"# ----------------------------------------------------------------------------","736b3d77":"## Tokenisation","dfbcc48d":"## Preprocessing\n\nWe shall now define a function called LemTokens which will take as input the tokens and return normalized tokens.","f1211a72":"## Generating Response\n\n### Bag of Words\nAfter the initial preprocessing phase, we need to transform text into a meaningful vector (or array) of numbers. The bag-of-words is a representation of text that describes the occurrence of words within a document. It involves two things:\n\n* A vocabulary of known words.\n\n* A measure of the presence of known words.\n\nWhy is it is called a \u201cbag\u201d of words? That is because any information about the order or structure of words in the document is discarded and the model is only **concerned with whether the known words occur in the document, not where they occur in the document.**\n\nThe intuition behind the Bag of Words is that documents are similar if they have similar content. Also, we can learn something about the meaning of the document from its content alone.\n\nFor example, if our dictionary contains the words {Learning, is, the, not, great}, and we want to vectorize the text \u201cLearning is great\u201d, we would have the following vector: (1, 1, 0, 0, 1).\n\n\n### TF-IDF Approach\nA problem with the Bag of Words approach is that highly frequent words start to dominate in the document (e.g. larger score), but may not contain as much \u201cinformational content\u201d. Also, it will give more weight to longer documents than shorter documents.\n\nOne approach is to rescale the frequency of words by how often they appear in all documents so that the scores for frequent words like \u201cthe\u201d that are also frequent across all documents are penalized. This approach to scoring is called Term Frequency-Inverse Document Frequency, or TF-IDF for short, where:\n\n**Term Frequency: is a scoring of the frequency of the word in the current document.**\n\n```\nTF = (Number of times term t appears in a document)\/(Number of terms in the document)\n```\n\n**Inverse Document Frequency: is a scoring of how rare the word is across documents.**\n\n```\nIDF = 1+log(N\/n), where, N is the number of documents and n is the number of documents a term t has appeared in.\n```\n### Cosine Similarity\n\nTf-idf weight is a weight often used in information retrieval and text mining. This weight is a statistical measure used to evaluate how important a word is to a document in a collection or corpus\n\n```\nCosine Similarity (d1, d2) =  Dot product(d1, d2) \/ ||d1|| * ||d2||\n```\nwhere d1,d2 are two non zero vectors.\n\n","fdc9c999":"To generate a response from our bot for input questions, the concept of document similarity will be used. We define a function response which searches the user\u2019s utterance for one or more known keywords and returns one of several possible responses. If it doesn\u2019t find the input matching any of the keywords, it returns a response:\u201d I am sorry! I don\u2019t understand you\u201d","986e54d2":"Finally, we will feed the lines that we want our bot to say while starting and ending a conversation depending upon user\u2019s input.","d0a7c9dd":"# Flash Animation of most used words regarding Coronavirus","7e5a6060":"#  Web Scraping \n##collecting some data from twitter","6a8ba685":"## Import necessary libraries","7935df1a":"Multidomain sentimental Data set - \nhttp:\/\/www.cs.jhu.edu\/~mdredze\/datasets\/sentiment\/","df215b89":"# QnA Model using Pytorch and Bert","3faf5acb":"### Installing NLTK Packages\n\n\n","29aef3c9":"# Sentiment Analysis"}}