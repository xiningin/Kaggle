{"cell_type":{"2a664603":"code","2f364929":"code","393bd33d":"code","3cee5b2e":"code","e0fd5ac8":"code","8935188c":"code","22250e95":"code","4b02d834":"code","c8e0e49e":"code","36203d01":"code","6b060df6":"code","ea1208fe":"code","8d7d844e":"markdown","159b03fa":"markdown","7cef38fd":"markdown","a8b295ed":"markdown","86e34b1e":"markdown","ea3d595b":"markdown","20656db6":"markdown","c0a8f112":"markdown","1818f32b":"markdown","4d03fbae":"markdown","5b6ba3eb":"markdown","d3290923":"markdown","095e5d40":"markdown"},"source":{"2a664603":"!pip install -q tensorflow-addons\n!pip install -q gdown","2f364929":"import gdown\nimport os\nimport shutil\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport numpy as np\nfrom glob import glob\nfrom tensorflow_addons.layers import InstanceNormalization","393bd33d":"input_image_size = (256, 256, 3)\n\nchosen_monet_file_id = \"1diLgk2a-snDTHI7_nbqjJjKEZR8kXjPQ\"\nphotos_zip_file_id = \"1HCYFybMEle_KQaL2KBKoOPjEVq2eA0dz\"\nmonet_generator_file_id = '1c5aILyVkbBj20zxV2tpIDBn2esh1Q4le'\n\nchosen_monet_filename = 'chosen_monet.tfrec'\nphotos_tfrec_folder_name = 'photo_tfrec'\nmonet_generator_filename = 'monet_generator_model.h5'","3cee5b2e":"def local_download_files_from_drive(id, filename, isZip=False):\n    file_url = f\"https:\/\/drive.google.com\/uc?id={id}\"\n    ext = '.zip' if isZip else ''\n    gdown.download(file_url, filename+ext, quiet=True)\n    if isZip is True:\n        shutil.unpack_archive(filename+ext, extract_dir=filename)\n        os.remove(filename+ext)","e0fd5ac8":"# Download all remote files to local memory:\nlocal_download_files_from_drive(monet_generator_file_id, monet_generator_filename)\nlocal_download_files_from_drive(chosen_monet_file_id, chosen_monet_filename)\nlocal_download_files_from_drive(photos_zip_file_id, photos_tfrec_folder_name, isZip=True)","8935188c":"# Map values in the range [-1, 1]\ndef normalize_img(img):\n    img = tf.cast(img, dtype=tf.float32)\n    return (img \/ 127.5) - 1.0\n\n# Map values in the range [0, 255]\ndef denormalize_img(img):\n    img = tf.cast(img, dtype=tf.float32)\n    return tf.cast((img + 1.0) * 127.5, tf.uint8)\n    \ndef decode_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = normalize_img(image)\n    image = tf.reshape(image, [*input_image_size])\n    return image\n\ndef read_tfrecord(example):\n    tfrecord_format = {\n        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_image(example['image'])\n    return image\n\ndef load_dataset(filenames):\n    dataset = tf.data.TFRecordDataset(filenames)\n    dataset = dataset.map(read_tfrecord)\n    return dataset\n\ndef visualize_dataset(dataset, rows, cols, images_normalized=True, imsize=3):\n    plt.figure(figsize=(cols*imsize,rows*imsize))\n    for i, im in enumerate(dataset.take(rows*cols)):\n        if images_normalized is True:\n            im = denormalize_img(im)\n        plt.subplot(rows, cols, i+1)\n        plt.imshow(im)\n        plt.axis(False)\n    plt.tight_layout()\n    plt.show()","22250e95":"filenames = glob(f\".\/{photos_tfrec_folder_name}\/*.tfrec\")\nphoto_dataset = load_dataset(filenames)\nvisualize_dataset(photo_dataset, rows=2, cols=6)","4b02d834":"chosen_monet_dataset = load_dataset(chosen_monet_filename)\nvisualize_dataset(chosen_monet_dataset, rows=5, cols=6)","c8e0e49e":"class ReflectionPadding2D(tf.keras.layers.Layer):\n\n    def __init__(self, padding=(1, 1), **kwargs):\n        self.padding = tuple(padding)\n        super(ReflectionPadding2D, self).__init__(**kwargs)\n\n    def call(self, input_tensor, mask=None):\n        padding_width, padding_height = self.padding\n        padding_tensor = [\n            [0, 0],\n            [padding_height, padding_height],\n            [padding_width, padding_width],\n            [0, 0],\n        ]\n        return tf.pad(input_tensor, padding_tensor, mode=\"REFLECT\")\n\n    def get_config(self):\n        config = super().get_config().copy()\n        config.update({\n            'padding': self.padding\n        })\n        return config","36203d01":"monet_generator = tf.keras.models.load_model('.\/' + monet_generator_filename, compile=False, custom_objects={'ReflectionPadding2D': ReflectionPadding2D})","6b060df6":"def visualize_predictions(model, images_dateset, rows, cols, imsize=3):\n    plt.figure(figsize=(cols*imsize, rows*imsize))\n    amount_to_show = rows*cols\n    for i, img in zip(range(1, amount_to_show, 2), images_dateset.take(amount_to_show).batch(1)):\n        input_img = denormalize_img(img[0]).numpy()\n        plt.subplot(rows, cols, i)\n        plt.title(\"Input image\")\n        plt.imshow(input_img)\n\n        prediction = model(img, training=False).numpy()\n        prediction = denormalize_img(prediction[0])\n        plt.subplot(rows, cols, i+1)\n        plt.title(\"Translated image\")\n        plt.imshow(prediction)\n\n    plt.tight_layout()\n    plt.show()\n\nvisualize_predictions(monet_generator, photo_dataset, rows=3, cols=6, imsize=4)","ea1208fe":"IN_KAGGLE = True\n\nif IN_KAGGLE is True:\n    !mkdir ..\/images\n    from PIL import Image\n    i = 1\n    for img in tqdm(photo_dataset.batch(1)):\n        prediction = monet_generator.predict(img)\n        prediction = denormalize_img(prediction)\n        im = Image.fromarray(prediction[0].numpy())\n        im.save(\"..\/images\/\" + str(i) + \".jpg\")\n        i += 1\n\n    shutil.make_archive(\"\/kaggle\/working\/images\", 'zip', \"\/kaggle\/images\")","8d7d844e":"## Read the non-Monet Photos","159b03fa":"# Load the Model and Visualize Predictions","7cef38fd":"# Global Parameters & Paths","a8b295ed":"# Generate All the Photos to Monet Images\n\nFor kaggle submissions, set IN_KAGGLE to True.","86e34b1e":"We must define the special reflection padding layer in order to load the model","ea3d595b":"# Visualize Predictions","20656db6":"As you can see we perform pretty well on nature images such as water, skies, mountains etc. and perform not quite as well on other stuff images e.g geometric objects, animals or people.\n\nWe believe this is due to the fact that Monet chose to focused mainly on nature in his paintings. You can see from our manually selected 30 Monet images that we chose focus on that part of his paintings to make the learning of the model more accurate.\n","c0a8f112":"# Load Required Libraries","1818f32b":"## Download Remote Data","4d03fbae":"# **Deep Learning Inference Notebook**\n### Authors: Simon Raviv, Adam Gavriely\n##### Deep Learning Course BIU, 2021.\n---\n<br\/>\n\nIn this project we were asked to train a Cycle GAN that can transfer style from images painted by Monet to 'regular' images using only 30 monet images.\n\nThe training notebook was submitted to the [Kaggle competition](https:\/\/www.kaggle.com\/c\/gan-getting-started) which use MiFID metric to evaluate the model performance.  \nOur best MiFID score was : **59.4**","5b6ba3eb":"## Utility Function for Image Processing","d3290923":"## Chosen Monet Files","095e5d40":"# Read the Data\n"}}