{"cell_type":{"0708f423":"code","0c872b83":"code","09d27819":"code","2a665ecd":"code","2cf6090c":"code","056a583f":"code","ed78797a":"code","294dfdcb":"code","6d750973":"code","feb98703":"code","07b9cf60":"code","4a43f535":"code","209e7c7c":"code","f8667ba3":"code","13c4d4cd":"code","781eddda":"code","fd0af075":"code","8fb5327a":"code","e903b861":"code","647b54d3":"code","761786da":"code","71b6e0fd":"markdown","198c1d0d":"markdown","315be500":"markdown","23a622cd":"markdown","0d2d10e0":"markdown","43dde38d":"markdown","e92c7c2b":"markdown","f89aa024":"markdown","be132ec3":"markdown","5d102749":"markdown","3635047d":"markdown","3127346e":"markdown","8050c88a":"markdown","fe5b1bda":"markdown","cdbd077d":"markdown"},"source":{"0708f423":"import pandas as pd\npd.set_option('display.max_columns', None)\npd.set_option('display.width', 500)\npd.set_option('display.expand_frame_repr', False)\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","0c872b83":"df = pd.read_csv(\"\/kaggle\/input\/movies-metadata2\/movies_metadata1.csv\", sep = \";\", encoding = 'unicode_escape', low_memory=False)\ndf.head()","09d27819":"df[\"overview\"].head()","2a665ecd":"from sklearn.feature_extraction.text import CountVectorizer\ncorpus = ['This is the first document.',\n          'This document is the second document.',\n          'And this is the third one.',\n          'Is this the first document?']","2cf6090c":"vectorizer = CountVectorizer()\nX = vectorizer.fit_transform(corpus)\nvectorizer.get_feature_names()\nX.toarray()","056a583f":"from sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer(analyzer='word')\nX = vectorizer.fit_transform(corpus)\nvectorizer.get_feature_names()\n\nX.toarray()","ed78797a":"df['overview'].head()","294dfdcb":"tfidf = TfidfVectorizer(stop_words='english')\ndf['overview'] = df['overview'].fillna('')\ntfidf_matrix = tfidf.fit_transform(df['overview'])\ntfidf_matrix.shape","6d750973":"cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n\ncosine_sim.shape","feb98703":"cosine_sim[1]","07b9cf60":"indices = pd.Series(df.index, index=df['title'])\n\nindices = indices[~indices.index.duplicated(keep='last')]\n","4a43f535":"indices.shape","209e7c7c":"indices[:10]","f8667ba3":"# showing the index number of the films\nindices[\"The American President\"]","13c4d4cd":"movie_index = indices[\"The American President\"]","781eddda":"cosine_sim[movie_index]","fd0af075":"# 1 den 11 e kadar gittim 0. index kendisi\nsimilarity_scores = pd.DataFrame(cosine_sim[movie_index], columns=[\"score\"])\nmovie_indices = similarity_scores.sort_values(\"score\", ascending=False)[1:11].index\n\ndf['title'].iloc[movie_indices]","8fb5327a":"def content_based_recommender(title, cosine_sim, dataframe):\n    # index'leri olusturma\n    indices = pd.Series(dataframe.index, index=dataframe['title'])\n    indices = indices[~indices.index.duplicated(keep='last')]\n    # title'\u0131n index'ini yakalama\n    movie_index = indices[title]\n    # title'a gore benzerlik skorlar\u0131n\u0131 hesapalama\n    similarity_scores = pd.DataFrame(cosine_sim[movie_index], columns=[\"score\"])\n    # kendisi haric ilk 10 filmi getirme\n    movie_indices = similarity_scores.sort_values(\"score\", ascending=False)[1:11].index\n    return dataframe['title'].iloc[movie_indices]","e903b861":"# Example 1\ncontent_based_recommender(\"The Matrix\", cosine_sim, df)","647b54d3":"# Example 2\ncontent_based_recommender(\"The Godfather\", cosine_sim, df)","761786da":"## Cosine Similarity Function, if you want to use it again.\n# def calculate_cosine_sim(dataframe):\n#    tfidf = TfidfVectorizer(stop_words='english')\n#    dataframe['overview'] = dataframe['overview'].fillna('')\n#    tfidf_matrix = tfidf.fit_transform(dataframe['overview'])\n#    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n#    return cosine_sim\n\n# cosine_sim = calculate_cosine_sim(df)\n\n# content_based_recommender('The Dark Knight Rises', cosine_sim, df)","71b6e0fd":"<a id = \"5\"><\/a><br>\n## 1.4 Libraries","198c1d0d":"# Introduction\n* Recommendations are developed based on the similarities of the contents\n* Represent texts mathematically (vectoring texts)\n* There are two methods of digitizing words. Count vector and tf-idf\n* Count Vector (word count): Count vector is based on frequency, there is a serious inaccuracy that high frequencies can introduce\n* TF-IDF: Normalized numbers\n\nThere are two important issues here. The first is to vectorize texts, that is, to represent them in a numerical way. Latter; How do we calculate similarity or closeness? If we want, we can calculate distance such as distance, proximity, Euclidean distance. If we want, we can calculate a similarity like correlation like cosine similarity.\n\n\nIn this content-based section, we will go through these steps below.\n* Creating the TF-IDF Matrix\n* Creating the Cosine Similarity Matrix\n* Making Suggestions Based on Similarities\n* Preparation of the Working Script\n\n\n<font color = 'blue'>\nContent: \n    \n1. [Data Preprocessing](#1)\n   * 1.1 [Business Problem](#2)\n   * 1.2 [Dataset Story](#3)\n   * 1.3 [Variables](#4)\n   * 1.4 [Libraries](#5)\n   * 1.5 [Load and Check Data](#6)    \n1. [Creating TF-IDF Matrix](#7)\n   * 2.1 [countvectorizer](#8)\n   * 2.1 [tf-idf](#9)\n    \n1. [Creating the Cosine Similarity Matrix](#10)\n1. [Making Suggestions Based on Similarities](#11)\n1. [Preparation of the Working Script](#12)\n1. [References](#13)\n    \n \n","315be500":"<a id = \"7\"><\/a><br>\n# 2. Creating TF-IDF Matrix\n<a id = \"8\"><\/a><br>\n## 2.1 CountVectorizer","23a622cd":"<a id = \"6\"><\/a><br>\n## 1.5 Load and Check Data","0d2d10e0":"As you can see above matrix, first columns has only 1 \"and\", second column, first row indicate \"document\". First row has one \"document\", second row has two \"document\" and so on. ","43dde38d":"<a id = \"9\"><\/a><br>\n## 2.2 tf-idf \ntf-idf is normalized numeric representations.\n\n* **STEP 1:** TF(t) = (Frequency of occurrence of a t term in the relevant document) \/ (Total number of terms in the document)(term frequency)\n* **Step 2:** IDF(t) = 1 + log_e(Total number of documents + 1) \/ (number of documents with t term + 1) (inverse document frequency)\n* **Step 3:** TF-IDF = TF(t) * IDF(t)\n* **Step 4:** L2 normalization to TF-IDF values","e92c7c2b":"Cosine similarities of The American President movie and other movies.","f89aa024":"<a id = \"13\"><\/a><br>\n# 6. References\n* https:\/\/github.com\/mvahit\n* https:\/\/www.veribilimiokulu.com\/\n* https:\/\/www.linkedin.com\/in\/vahitkeskin\/","be132ec3":"<a id = \"3\"><\/a><br>\n## 1.2 Dataset Story\n* The data has overviews ","5d102749":"<a id = \"1\"><\/a><br>\n# 1. Data Preprocessing\n<a id = \"2\"><\/a><br>\n## 1.1 Business Problem\nRecommendation system based on movie overviews","3635047d":"<a id = \"4\"><\/a><br>\n## 1.3 Variables\nWe only work on overviews columns","3127346e":"<a id = \"8\"><\/a><br>\nIn the Count operation, the number of times each word occurs in each document is counted. For instace; let's look at the example below. We have four sentences. We will convert all words to the matrix. If the word is in it, it will count 1 or more, othewise 0.","8050c88a":"<a id = \"12\"><\/a><br>\n# 5. Preparation of the Working Script","fe5b1bda":"<a id = \"11\"><\/a><br>\n# 4. Making Suggestions Based on Similarities","cdbd077d":"<a id = \"10\"><\/a><br>\n# 3. Creating Cosine Similarity Matrix\nCosine Similarity A metric focused on the similarity of two vectors."}}