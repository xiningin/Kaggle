{"cell_type":{"d7096d04":"code","c2db705e":"code","33079b90":"code","9478ea9b":"code","1dc72003":"code","2175b9a4":"code","28efe07b":"code","1c0466f5":"code","74a88810":"code","fbe98876":"code","7b4f8cf6":"code","698dfddc":"code","ba6c7ace":"code","0a716878":"code","17b7371b":"code","6a601608":"code","eab9a859":"code","f9cffd4e":"code","b2be2105":"code","220a78b6":"code","5bb7c067":"code","465a9cee":"code","bf80eba3":"code","492e0ef7":"code","a831eb71":"code","ad095636":"code","71fd8ff8":"code","c2b0732e":"code","69633832":"code","73859224":"code","5a613e0e":"code","bd66369a":"code","67b95b23":"code","e8a26959":"code","0bf52e23":"code","58612b88":"code","0eae7e8a":"code","62c5f461":"code","fdb9d986":"code","4d98b45f":"code","2c14c1e9":"markdown","119207e2":"markdown","95230b3f":"markdown","e62e2351":"markdown","26380205":"markdown","50c98569":"markdown","2299c4cf":"markdown","317a3f16":"markdown"},"source":{"d7096d04":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c2db705e":"#reading the data\ndata=pd.read_csv(\"\/kaggle\/input\/heart-disease-uci\/heart.csv\")\ndata.head()\n","33079b90":"#age,sex,cp,trestbps,chol,fbs,restecg,thalach,exang,oldpeak,slope,ca,thai columns are featurd array\n#target column is our target variable","9478ea9b":"data.describe()","1dc72003":"# checking null values\ndata.isnull().sum()\n#no null values present","2175b9a4":"#creating feature matrix and target array\ny=data[\"target\"]\nX=data.drop(\"target\",axis=1)","28efe07b":"X.head()","1c0466f5":"y.head()","74a88810":"#splitting the data\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42,test_size=0.3)","fbe98876":"#normalising the data\nfrom sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()\nscaler.fit(X_train)\nX_train_scaled=scaler.transform(X_train)\nX_test_scaled=scaler.transform(X_test)","7b4f8cf6":"from sklearn.linear_model import LogisticRegression","698dfddc":"#make model\nmodel=LogisticRegression()\nmodel.fit(X_train_scaled,y_train)","ba6c7ace":"#making predictions\ny_pred=model.predict(X_test_scaled)","0a716878":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test,y_pred)","17b7371b":"#accuracy using confusion matrix\naccuracy=(33+40)\/(33+40+8+10)\naccuracy","6a601608":"from sklearn.neighbors import KNeighborsClassifier\nknn=KNeighborsClassifier(n_neighbors=8)\nknn.fit(X_train_scaled,y_train)\n\n","eab9a859":"y_predict_knn=knn.predict(X_test_scaled)\ny_predict_knn","f9cffd4e":"confusion_matrix(y_predict_knn,y_test)","b2be2105":"acc_knn=69\/91\nacc_knn","220a78b6":"knn.score(X_test_scaled,y_test)","5bb7c067":"accuracy_knn=[]\nfor k in range(1,15):\n    knn=KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train_scaled,y_train)\n    accuracy_knn.append([k,knn.score(X_test_scaled,y_test)])\n    print(k,knn.score(X_test_scaled,y_test))\n\n    ","465a9cee":"accuracy_knn","bf80eba3":"from sklearn.tree import DecisionTreeClassifier\n","492e0ef7":"model=DecisionTreeClassifier()\nmodel.fit(X_train_scaled,y_train)","a831eb71":"y_pred=model.predict(X_test_scaled)\ny_pred","ad095636":"confusion_matrix(y_test,y_pred)","71fd8ff8":"66\/94","c2b0732e":"model.score(X_test_scaled,y_test)","69633832":"# decisiontreeclassifier uses various hyperparameters like max_depth,max_leaf_nodes,min_samples_leaf\n","73859224":"#using grid searchcv to find optimal max_depth\nfrom sklearn.model_selection import GridSearchCV\nparameters={\"max_depth\":[1,2,3,4,5,6,7,8,9,10]}\nmodel=DecisionTreeClassifier()\n\ngrid=GridSearchCV(model,parameters,cv=10)\ngrid.fit(X_train_scaled,y_train)\ngrid.best_params_\n# max_depth is found to be 5 for best accuracy","5a613e0e":"grid.score(X_test_scaled,y_test)","bd66369a":"from sklearn.ensemble import RandomForestClassifier\nmodel_rf = RandomForestClassifier(n_estimators=100,max_depth=5,max_features=12,oob_score=True,verbose=1,random_state=50)\nmodel_rf.fit(X_train_scaled,y_train)\ny_pred_rf=model_rf.predict(X_test_scaled)\n","67b95b23":"confusion_matrix(y_test,y_pred)","e8a26959":"acc=75\/91\nacc","0bf52e23":"model_rf.score(X_test,y_test)","58612b88":"#using grid searchcv to find optimal max_depth\nfrom sklearn.model_selection import GridSearchCV\nhyperparameters = {'max_features':np.arange(1,12),'max_depth':np.arange(1,6)}\n\n\nmodel_tune=GridSearchCV(model_rf,hyperparameters,cv=10)\nmodel_tune.fit(X_train_scaled,y_train)\n\n","0eae7e8a":"model_tune.best_params_","62c5f461":"y_pred_test_cv=model_tune.predict(X_test_scaled)     # predictions using tuned model","fdb9d986":"confusion_matrix(y_test,y_pred_test_cv)","4d98b45f":"76\/91  #acc with tuned model","2c14c1e9":"# random forest classifier","119207e2":"# using hyperparameter tuning in random forest","95230b3f":"# knn classifier","e62e2351":"# using different value of n_neighbors to find optimal value of n_neighbors","26380205":"# boosting","50c98569":"**logistic regression**\n****","2299c4cf":"# decision tree classifier","317a3f16":"# we can see that for k=9 , our accuracy is max i.e 81.3%"}}