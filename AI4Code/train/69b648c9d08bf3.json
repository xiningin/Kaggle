{"cell_type":{"ea95d792":"code","f161708c":"code","87b8db54":"code","e5635591":"code","62e8ad8c":"code","cf0fbd3c":"code","fdb5d5ce":"code","a69ea671":"code","209bfa7e":"code","4d6e8176":"code","1f7e30ca":"code","752b6324":"code","eecd2066":"code","0a933f03":"code","8dc5276a":"code","985bdab2":"code","156b2f47":"code","89e1f0a6":"code","7a1876e9":"code","fa7b7e03":"code","270feee0":"code","21cd876e":"code","b8c85abb":"code","2f0aa5a4":"code","fb00c5b3":"code","84af5f5d":"code","46a67560":"code","0260afa4":"code","8bf1580b":"code","4143f15d":"code","699045f4":"markdown","eb07cdb3":"markdown","463dd461":"markdown","1edc25a0":"markdown"},"source":{"ea95d792":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport os","f161708c":"test_data = pd.read_csv('..\/input\/test.csv')\ntrain_data = pd.read_csv('..\/input\/train.csv')\n\n# sizes of each doc\nprint(test_data.shape)\nprint(train_data.shape)","87b8db54":"train_data.head(10)","e5635591":"df_train = pd.DataFrame(train_data)\ndf_test = pd.DataFrame(test_data)","62e8ad8c":"df_train.describe(include='all')","cf0fbd3c":"cols_missed_train = df_train.isnull().sum()\ncols_missed_valid = df_test.isnull().sum()\n\nprint('Columns with NaN in df_train: ', len(cols_missed_train[cols_missed_train > 0]))\nprint(cols_missed_train[cols_missed_train > 0].sort_values(ascending = False))\n\nprint('Columns with NaN in df_test: ', len(cols_missed_valid[cols_missed_valid > 0]))\nprint(cols_missed_valid[cols_missed_valid > 0].sort_values(ascending = False))","fdb5d5ce":"df_train['PoolQC'] = df_train['PoolQC'].fillna('None')\ndf_train['MiscFeature'] = df_train['MiscFeature'].fillna('None')\ndf_train['Alley'] = df_train['Alley'].fillna('None')\ndf_train['Fence'] = df_train['Fence'].fillna('None')\ndf_train['FireplaceQu'] = df_train['FireplaceQu'].fillna('None')\ndf_train['LotFrontage'] = df_train['LotFrontage'].fillna(df_train['LotFrontage'].mode()[0])\nfor col in ('GarageYrBlt', 'GarageCars', 'GarageArea'):\n\tdf_train[col] = df_train[col].fillna(0)\nfor col in ('GarageType', 'GarageQual', 'GarageCond', 'GarageFinish'):\n\tdf_train[col] = df_train[col].fillna('None')\nfor col in ('BsmtFinType2', 'BsmtFinType1', 'BsmtExposure', 'BsmtCond', 'BsmtQual'):\n\tdf_train[col] = df_train[col].fillna('None')\ndf_train['MasVnrArea'] = df_train['MasVnrArea'].fillna(df_train['MasVnrArea'].mode()[0])\ndf_train['MasVnrType'] = df_train['MasVnrType'].fillna('None')\ndf_train['Electrical'] = df_train['Electrical'].fillna('None')\ndf_train['MSZoning'] = df_train['MSZoning'].fillna(df_train['MSZoning'].mode()[0])\n\ndf_train['Functional'] = df_train['Functional'].fillna(df_train['Functional'].mode()[0])\nfor col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n    df_train[col] = df_train[col].fillna(0)\ndf_train['SaleType'] = df_train['SaleType'].fillna(df_train['SaleType'].mode()[0])\ndf_train['Utilities'] = df_train['Utilities'].fillna(df_train['Utilities'].mode()[0])\ndf_train['Exterior1st'] = df_train['Exterior1st'].fillna(df_train['Exterior1st'].mode()[0])\ndf_train['Exterior2nd'] = df_train['Exterior2nd'].fillna(df_train['Exterior2nd'].mode()[0])\ndf_train['KitchenQual'] = df_train['KitchenQual'].fillna(df_train['KitchenQual'].mode()[0])\n\n# Checking nulls to be sure they are gone in df_train\nprint('Missed data in df_train: ', df_train.isnull().sum().sum())\n\n\n# Replacing missing data in df_test\ndf_test['PoolQC'] = df_test['PoolQC'].fillna('None')\ndf_test['MiscFeature'] = df_test['MiscFeature'].fillna('None')\ndf_test['Alley'] = df_test['Alley'].fillna('None')\ndf_test['Fence'] = df_test['Fence'].fillna('None')\ndf_test['FireplaceQu'] = df_test['FireplaceQu'].fillna('None')\ndf_test['LotFrontage'] = df_test['LotFrontage'].fillna(df_test['LotFrontage'].mode()[0])\nfor col in ('GarageYrBlt', 'GarageCars', 'GarageArea'):\n\tdf_test[col] = df_test['GarageYrBlt'].fillna(0)\nfor col in ('GarageType', 'GarageQual', 'GarageCond', 'GarageFinish'):\n\tdf_test[col] = df_test[col].fillna('None')\nfor col in ('BsmtFinType2', 'BsmtFinType1', 'BsmtExposure', 'BsmtCond', 'BsmtQual'):\n\tdf_test[col] = df_test[col].fillna('None')\ndf_test['MasVnrArea'] = df_test['MasVnrArea'].fillna(df_test['MasVnrArea'].mode()[0])\ndf_test['MasVnrType'] = df_test['MasVnrType'].fillna('None')\ndf_test['Electrical'] = df_test['Electrical'].fillna('None')\ndf_test['MSZoning'] = df_test['MSZoning'].fillna(df_test['MSZoning'].mode()[0])\ndf_test['Functional'] = df_test['Functional'].fillna(df_test['Functional'].mode()[0])\nfor col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n    df_test[col] = df_test[col].fillna(0)\ndf_test['SaleType'] = df_test['SaleType'].fillna(df_test['SaleType'].mode()[0])\ndf_test['Utilities'] = df_test['Utilities'].fillna(df_test['Utilities'].mode()[0])\ndf_test['Exterior1st'] = df_test['Exterior1st'].fillna(df_test['Exterior1st'].mode()[0])\ndf_test['Exterior2nd'] = df_test['Exterior2nd'].fillna(df_test['Exterior2nd'].mode()[0])\ndf_test['KitchenQual'] = df_test['KitchenQual'].fillna(df_test['KitchenQual'].mode()[0])\n\n# Checking nulls to be sure they are gone in df_train\nprint('Missed data in df_test: ', df_test.isnull().sum().sum())","a69ea671":"df_train.dtypes.value_counts()","209bfa7e":"numerical_cols = df_train.select_dtypes(include = ['float64', 'int64'])\nnumerical_cols.head(10)","4d6e8176":"# Histogram for SalePrice\ndf_train.select_dtypes(include = ['float64', 'int64'])['SalePrice'].hist(bins=50, color='purple')","1f7e30ca":"# Histogram with Density=1 to take analysis more accurate\nnumerical_cols['SalePrice'].hist(bins=50, density=1, color='DarkOrange')","752b6324":"# Let's take logarithm for more comfortable understandin our data\nnp.log(numerical_cols['SalePrice']).hist(bins=50, density=1, color='DarkCyan')\n# As we can see we have outliers. We will get rid of them a bit later","eecd2066":"for col in df_train.select_dtypes(include = ['object']):\n    df_train[col] = df_train[col].astype('category')","0a933f03":"# Histogram of SalePrice depending on MSZoning (normalized)\ndf_train.groupby('MSZoning')['SalePrice'].plot.hist(density=1, alpha=0.6)\nplt.legend()","8dc5276a":"# Boxplot for analyzing more the one bunch of data\nax = df_train.boxplot(column='SalePrice', by='MSZoning')\n# To make the title more readible\nax.get_figure().suptitle('')","985bdab2":"numerical_cols.describe()","156b2f47":"#Removing outliers (choosing data between first and third quartiles)\nfirst_q = df_train['SalePrice'].describe()['25%']\nthird_q = df_train['SalePrice'].describe()['75%']\ndiff = third_q - first_q\n\ncols_train = df_train[(df_train['SalePrice'] > (first_q - 3 * diff))&\n                     (df_train['SalePrice'] < (third_q + 3 * diff))]\nprint('Removed outliers: ' + str(len(df_train) - len(cols_train)) + ' objects')","89e1f0a6":"# Building correlation matrix for understanding how the characteristics influence to each other\nn_df = cols_train.copy()\ncorr_matrix = n_df.drop('Id', axis=1).corr()\nf, ax = plt.subplots(figsize=(16, 12))\nplt.title('Correlation Matrix',fontsize=22)\nsns.heatmap(corr_matrix, vmax=1, center=0, annot=True, fmt='.1f')","7a1876e9":"pos_cor = corr_matrix.SalePrice[corr_matrix.SalePrice.values > 0.40].sort_values(ascending=False)[1:]\nneg_cor = corr_matrix.SalePrice[corr_matrix.SalePrice.values < 0.0].sort_values(ascending=True)[1:]\nfeatures = pos_cor.append(neg_cor).index\nfeatures","fa7b7e03":"test_id = df_test['Id']","270feee0":"# Removing data with a high correlation level\ncols_train.drop(columns=['Id'], axis=1, inplace=True)\ndf_test.drop(columns=['Id'], axis=1, inplace=True)","21cd876e":"# Aggregation of number of houses by each of neighborhoods and mean prices per each neighborhood (for understanding of mean prices in common)\ncols_train.groupby('Neighborhood').agg({'Neighborhood':'size','SalePrice':'mean'}).rename(columns={'Neighborhood':'hous count','SalePrice':'mean price'})","b8c85abb":"cols_train['SalePrice'] = np.log(cols_train['SalePrice'])","2f0aa5a4":"SalePrice = cols_train['SalePrice']","fb00c5b3":"new_train = cols_train[['OverallQual', 'GrLivArea', 'TotalBsmtSF', '1stFlrSF', 'YearBuilt',\n       'FullBath', 'YearRemodAdd', 'TotRmsAbvGrd', 'Fireplaces', 'MasVnrArea',\n       'EnclosedPorch', 'MSSubClass', 'OverallCond', 'LowQualFinSF', 'YrSold',\n       'BsmtHalfBath', 'MiscVal', 'BsmtFinSF2']]\nnew_test = df_test[['OverallQual', 'GrLivArea', 'TotalBsmtSF', '1stFlrSF', 'YearBuilt',\n       'FullBath', 'YearRemodAdd', 'TotRmsAbvGrd', 'Fireplaces', 'MasVnrArea',\n       'EnclosedPorch', 'MSSubClass', 'OverallCond', 'LowQualFinSF', 'YrSold',\n       'BsmtHalfBath', 'MiscVal', 'BsmtFinSF2']]","84af5f5d":"print(new_train.shape)\nprint(new_test.shape)","46a67560":"y = SalePrice\nX = new_train\n\n# Split dataset to train and valid for training and testing\ntrain_X, valid_X, train_y, valid_y = train_test_split(X, y, random_state=1)","0260afa4":"train_model = RandomForestRegressor()\ntrain_model.fit(train_X, train_y)\n\nval_pred = train_model.predict(valid_X)\n\nrmse = np.sqrt(mean_squared_error(valid_y, val_pred))\nrmse","8bf1580b":"final_pred = train_model.predict(new_test.values)\nfinal_pred = np.exp(final_pred)","4143f15d":"df_pred = pd.DataFrame({\"id\":test_id, \"SalePrice\":final_pred})\ndf_pred.SalePrice = df_pred.SalePrice.round(0)\ndf_pred.to_csv('submission.csv', sep=',', encoding='utf-8', index=False)\n","699045f4":"Replacing missing data in df_train:","eb07cdb3":"It is more comfortable to work with datasets:","463dd461":"So as I mentioned before, we have outliers. So let's remove them to be sure our results will be more accirate.","1edc25a0":"But it is not that informative, so we need something else..."}}