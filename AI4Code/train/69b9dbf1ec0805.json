{"cell_type":{"c1309d09":"code","3791fd69":"code","621dd91b":"code","00d840df":"code","5f1f333d":"code","d51a4ffe":"code","a3135356":"code","d97dba2d":"code","85763360":"code","b8f44d66":"code","03fc1478":"code","b1a6e4c7":"code","f62b0d02":"markdown","de7fa205":"markdown","6d885628":"markdown","ed24bef3":"markdown"},"source":{"c1309d09":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport cv2\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3791fd69":"df = pd.read_csv('\/kaggle\/input\/super-ai-image-classification\/train\/train\/train.csv')\ndf","621dd91b":"Images = []\ndirectory = '\/kaggle\/input\/super-ai-image-classification\/train\/train\/images'\nfor file in df['id']:\n    image = cv2.imread(directory+'\/'+file) \n    image = cv2.resize(image,(224,224)) \n    Images.append(image)","00d840df":"Images = np.array(Images)\nImages.shape","5f1f333d":"import matplotlib.pyplot as plt\nplt.imshow(Images[1724], cmap='gray')\nplt.show()","d51a4ffe":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\nmodel = Sequential()\nmodel.add(Conv2D(64,(3,3), padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\nmodel.add(Conv2D(64,(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D())\nmodel.add(Conv2D(128, (3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(128, (3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D())\nmodel.add(Conv2D(256, (3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(256, (3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(256, (3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D())\nmodel.add(Conv2D(512, (3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(512, (3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(512, (3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D())\nmodel.add(Conv2D(512, (3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(512, (3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(512, (3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D())\nmodel.add(Flatten())\nmodel.add(Dense(4096,activation=\"relu\"))\nmodel.add(Dense(4096,activation=\"relu\"))\nmodel.add(Dense(2, activation=\"softmax\"))\nmodel.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), \n              loss=keras.losses.sparse_categorical_crossentropy)","a3135356":"model.summary()","d97dba2d":"datagen = keras.preprocessing.image.ImageDataGenerator()\nbatch = 6\ndatagen.fit(Images)\nnum_batch = len(Images) \/ batch\nProgbar = keras.utils.Progbar(num_batch)\nfor epoch in range(50):\n  batches = 0\n  for x, y in datagen.flow(Images, df['category'], batch_size=batch):\n    history = model.fit(x, y, verbose=0)\n    batches += 1\n    Progbar.update(batches, values=[('loss', history.history['loss'][0])])\n    if batches >= num_batch:\n      print(epoch)\n      break","85763360":"Xtest = []\nID = []\ndirectory = '\/kaggle\/input\/super-ai-image-classification\/val\/val\/images'\nfor file in os.listdir(directory):\n    image = cv2.imread(directory+'\/'+file)\n    image = cv2.resize(image,(224,224))\n    Xtest.append(image)\n    ID.append(file)\nXtest = np.array(Xtest)","b8f44d66":"Ztest = model.predict(Images[1500:])\nnp.sum(Ztest.argmax(axis=1) == df['category'][1500:])\/len(Ztest)","03fc1478":"Ztest = model.predict(Xtest)\nZtest = np.argmax(Ztest, axis=-1)\nprint(Ztest)","b1a6e4c7":"data2 = {'id':ID,'category':Ztest}\nval = pd.DataFrame(data2)\nval.to_csv(\"Submit.csv\",index=False)","f62b0d02":"# Prepare Data","de7fa205":"# Test Model","6d885628":"# 22p21n0179-\u0e2d\u0e18\u0e34\u0e20\u0e31\u0e17\u0e23\n\u0e01\u0e32\u0e23\u0e41\u0e02\u0e48\u0e07\u0e02\u0e31\u0e19 Super Ai \u0e01\u0e32\u0e23\u0e1a\u0e49\u0e32\u0e19 \u0e2a\u0e31\u0e1b\u0e14\u0e32\u0e2b\u0e4c\u0e17\u0e35\u0e48 3 \u0e02\u0e49\u0e2d\u0e17\u0e35\u0e48 1","ed24bef3":"# Training Model"}}