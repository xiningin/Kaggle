{"cell_type":{"59a03194":"code","0c4aa2a4":"code","0da96238":"code","73160cd3":"code","325f96d3":"code","5a0e864e":"code","ea85ee21":"code","42b70e85":"code","2b912624":"code","a735ee6b":"code","40190b27":"code","f36bbeeb":"code","f1a6f247":"code","b4f94fee":"code","ff128ace":"code","2b6909a4":"code","ec0e0f36":"code","f3e7c533":"code","d831a401":"code","fb25c906":"code","53f00f77":"code","2ec46b07":"code","6386927d":"code","f184757b":"code","32cee624":"code","eb4fab23":"markdown","bfc689ba":"markdown","1da2aa5b":"markdown","549d738a":"markdown","8fd374ee":"markdown","bae615c1":"markdown","f1b02ebb":"markdown","de5737ea":"markdown","1830509d":"markdown","ec3e0376":"markdown","cea5f294":"markdown","f5fb9982":"markdown","52f7b874":"markdown","e7a0924e":"markdown","eb31d843":"markdown","d8fb8e65":"markdown","d5b377d7":"markdown","72de99c7":"markdown","b7783afd":"markdown","7c1b9454":"markdown","f3f94782":"markdown","50da440c":"markdown","894026dd":"markdown","68c845a9":"markdown"},"source":{"59a03194":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0c4aa2a4":"train_data=pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\n\n#second activity: asign the second file to variable test_data and open the first one just writing \"train_data\" without quotes marks:\n#test_**=pd.**_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n#train_**","0da96238":"train_data.head()\n#third activity: write a number in the df.head() method to change the rows number\n#train_**.head(**)","73160cd3":"train_data.columns","325f96d3":"train_data.dtypes","5a0e864e":"train_data.shape","ea85ee21":"#fourth activity: show some columns\n#**_data.**\n#train_data[\"**\"]","42b70e85":"train_data.describe()","2b912624":"age=train_data.Age\npclass=train_data.Pclass\nadd=age+pclass\nadd\n\n#Activity: show the shape of \"add\" column","a735ee6b":"type(train_data.Age), type(train_data)\n#column-mean-sum-len","40190b27":"train_data.Age < 10","f36bbeeb":"np.sum(train_data.Age < 10)","f1a6f247":"np.mean(train_data.Age < 10)","b4f94fee":"(train_data.Age < 10).mean()","ff128ace":"train_data.query(\"Age <10\")","2b6909a4":"df[df.columns < 0]","ec0e0f36":"df[(df.column1 < 0) & (df.column2 > 4)]","f3e7c533":"train_data.dtypes","d831a401":"train_data['Age']=train_data.Age.astype(str)\n#df['name_column2']=df.name_column2.astype(int)\ntype(train_data.Age[1])","fb25c906":"#df[df.column.isnull()]\nnum=train_data.Cabin.isna().sum()\nnum\nnum\/len(train_data.Cabin)\n#train=df.query(\"Age!='Nan'\")","53f00f77":"df = df[df.column.notnull()]\ndf.shape","2ec46b07":"df['column_name']=df.column_name.astype(int)\ndf['column_name2']=df.column_name2.astype(int)\n\ndf.dtypes","6386927d":"women=train_data.loc[train_data.Sex==\"female\"][\"Survived\"]\nrate_women=sum(women)\/len(women)\nprint(\"% of women who survived:\",rate_women*100)","f184757b":"men=#complete code\nrate_men=#function(men)\/function(men)\nprint(\"% of men whon survived: \", rate_men*100)","32cee624":"from sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Sex\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","eb4fab23":"Now lets see the types of the columns...","bfc689ba":"Notice that you could just find the average since the Trues map to 1s.","1da2aa5b":"891 rows and 12 columns. A spredsheet is a table, a matrix. How can we access members of this tuple?\nNow we will show how to access to a column, we can do this with `df.name_column` or `df[\"name_column\"]`","549d738a":"finally we have a function that tells us the type of variable we are dealing with","8fd374ee":"# Querying\n\nA spreadsheet is useless if you cant dice\/sort\/etc it. Here we look for all books with a column less than 3.","bae615c1":"Oops we got an error. Something is not right. It's trying to convert some python datatype: None into an int. This usually means some data was missing,So, which data was missing?","f1b02ebb":"a very important method for data analysis is the statistics, fortunately, pandas has a method for that : `df.describe()`, let's see it ","de5737ea":"  \n\n\n\nwith this new ability we can do many things like operations in and between columns.\n\nTo make it clearer, we first assign the columns to a variable and with them we can do the mathematical operations","1830509d":"If you want to combine these conditions, use the second form and put '()' brackets around each condition. The query uses a boolean AND. Each condition creates a mask of trues and falses.","ec3e0376":"This gives us Trues and Falses. Such a series is called a mask. If we count the number of Trues, and divide by the total, we'll get the fraction of ratings  <  3. To do this numerically see this:","cea5f294":"# Kaggle default\n\nWhen you open a new notebook in a competition, what you can see in the cell below will appear by default. How can you see, pandas and numpy are imported, as well as the data which you are going to work with.\nI will not discuss the importance of pandas, but I will show you how you can use it to explore data, which will serve you well in whatever competition you participate in.\n\n**First activity:**\n \nRun the code below\n","f5fb9982":"Aha, we had some incomplete data. Lets get rid of it","52f7b874":"Suppose we try and fix this","e7a0924e":"The shape of the object is:","eb31d843":"Or directly, in Pandas, which works since df.column < 3 is a pandas Series.","d8fb8e65":"# My first submission","d5b377d7":"pandas has a method to see the columns in the dataFrame.","72de99c7":"Here we create a mask and use it to \"index\" into the dataframe to get the rows we want.","b7783afd":"Notice we have a table or a spreadsheetAnd it this one has indexed rows. Pandas (borrowing from R) calls it a DataFrame. For this reason, in many tutorials they assing the dataframe to the variable `df` \n\n`df`, in python parlance is an **instance** of the `pd.DataFrame` class, created by calling the `pd.read_csv` function, which calls the DataFrame constructor inside of it. If you dont understand this sentence, dont worry, it will become clearer later. What you need to take away is that `df` is a dataframe object, and it has **methods**, or functions belonging to it, which allow it to do things. For example `df.head()` is a method that shows the first 5 rows of the dataframe.\n\n![](http:\/\/i.imgur.com\/g54fgs0.png)\n\n# The basics","7c1b9454":"# Cleaning\n\nWe first check the datatypes. Notice that some columns are type object (which means they are either strings or Pandas couldn't figure what they are), while \"year\" is a float.","f3f94782":"We removed those rows. Lets try the type conversion again","50da440c":"You usually don\u00b4t care about all data on the first glance. So focus on the first few rows with the `df.head()` method,as I already said, if you write any number at all this method will show the first 5 rows, let\u00b4s try it. ","894026dd":"As you can see there are three files, each one of them with the extension **.csv**. In order to open those files, we will use pandas function `pd.read_csv` and asign this to a variable\n\nNote: **for some activities part of the code will be put and you must complete it, you must also remove the # symbol for python to read it**","68c845a9":"# Filtering\n\nHere are two ways to get a filtered dataframe"}}