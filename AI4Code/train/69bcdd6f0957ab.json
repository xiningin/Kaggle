{"cell_type":{"352d1835":"code","50fa48ff":"code","e82548a2":"code","a93b8dcd":"code","1b6d4e5c":"code","990c65a1":"code","160e175e":"code","841e509c":"code","8d4b2a99":"code","74ee9374":"code","054cc5cb":"code","81b29da5":"code","d6b86e44":"code","3c84c013":"code","8e129f24":"code","4aa94594":"code","8c10d69b":"code","e8664276":"markdown","0096c543":"markdown","e500b373":"markdown","e2bad3a4":"markdown","e17a0c00":"markdown","a37f0eb0":"markdown","5a44ff68":"markdown","16ed7099":"markdown","b6513949":"markdown","43fa3675":"markdown","8a30a6ad":"markdown","2330bfec":"markdown","7db74f57":"markdown","e24e0ace":"markdown","03fed756":"markdown"},"source":{"352d1835":"import numpy as np\nimport pandas as pd\nimport re\nimport io\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom nltk.stem.porter import PorterStemmer\nfrom fastcache import clru_cache as lru_cache\n\nprint( 'read data' )\ntrain_df = pd.read_csv( '..\/input\/train.csv' )\ntrain_size = len( train_df.index )\ntest_df = pd.read_csv( '..\/input\/test.csv' )\nids_test = test_df[ 'qid' ].values\nclazz_train = train_df[ 'target' ].values\n\nprint( 'training set' )\ntrain_df.head()","50fa48ff":"print( 'test set' )\ntest_df.head()","e82548a2":"df = pd.concat( [ train_df, test_df ], axis=0, sort=False, ignore_index=True )\n\nprint( 'training set size:', train_size )\nprint( 'test set size:', len(ids_test) )","a93b8dcd":"print( 'vectorize' )\n# stemmer\nstemmer = PorterStemmer()\n@lru_cache(2048)\ndef stem(s):\n\treturn stemmer.stem(s)\nwhitespace = re.compile(r'\\s+')\nnon_letter = re.compile(r'\\W+')\ndef tokenize(text):\n\ttext = text.lower()\n\ttext = non_letter.sub(' ', text)\n\ttokens = []\n\tfor t in text.split():\n\t\tt = stem(t)\n\t\ttokens.append(t)\n\treturn tokens\n\nvectorizer = TfidfVectorizer( use_idf=True, lowercase=True, tokenizer=tokenize )\nvecs = vectorizer.fit_transform( df[ 'question_text' ].values )\nvecs_train = vecs[ :train_size ]","1b6d4e5c":"vocabulary = {v:k for k,v in vectorizer.vocabulary_.items()}\nfor i,k in zip(range(20),vocabulary.keys()):\n    print( k,vocabulary[k] )","990c65a1":"# make weights for class\ncnum = np.sum(clazz_train == 1)\nweight = cnum \/ ( len(clazz_train) - cnum )\n# sum of each class\nindex = np.arange( train_size )\nindex_posi = index[ clazz_train == 0 ]\nindex_nega = index[ clazz_train == 1 ]\nvecs_posi = vecs_train[ index_posi ].sum( axis=0 ) * ( weight )\nvecs_nega = vecs_train[ index_nega ].sum( axis=0 ) * ( 1.0 - weight)\nprint(vecs_nega[:10])\nprint(vecs_posi[:10])","160e175e":"# class nega is class value 1\nvecs_score = np.array(vecs_nega - vecs_posi).reshape((-1,))\nprint(vecs_score[:10])","841e509c":"print( 'positive\/negative words in trainig set:' )\nrank = np.argsort( vecs_score )\n# 'positive word' is class 0\nprint( '  positive 20:' )\nfor r in rank[:20]:\n\tprint( vecs_score[ r ], vocabulary[ r ] )","8d4b2a99":"print( '  negative 20:' )\nfor r in rank[-20:]:\n\tprint( vecs_score[ r ], vocabulary[ r ] )","74ee9374":"print( 'find words only in test set' )\nvecs_test = vecs[ train_size: ]\ntrain_words = np.nonzero( vecs_train.sum( axis=0 ) )[1]\ntest_words = np.nonzero( vecs_test.sum( axis=0 ) )[1]\nonlytest_words = [ t for t in test_words if t not in train_words ]\nprint( '  words only in test:' )\nfor o in onlytest_words[:20]:\n\tprint( o, vocabulary[ o ] )","054cc5cb":"print( 'find nearest word' )\n# load word vector\ndef load_vectors(fname):\n\tfin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n\tn, d = map(int, fin.readline().split())\n\tdata = {}\n\tfor line in fin:\n\t\ttokens = line.rstrip().split(' ')\n\t\tif tokens[0] in vectorizer.vocabulary_:\n\t\t\tdata[tokens[0]] = np.array( list( map(float, tokens[1:]) ) )\n\treturn data\n\nword_vec = load_vectors( '..\/input\/embeddings\/wiki-news-300d-1M\/wiki-news-300d-1M.vec' )","81b29da5":"# find nearest word\ndef get_onlytest_words( o ):\n\tresult = 0.0\n\tif vocabulary[ o ] in word_vec:\n\t\tnmin = np.inf\n\t\tnidx = None\n\t\t# use 2000 negative words\n\t\tfor k in rank[-2000:]:\n\t\t\tif k not in onlytest_words and vocabulary[ k ] in word_vec:\n\t\t\t\tn = np.linalg.norm( word_vec[ vocabulary[ o ] ] - word_vec[ vocabulary[ k ] ] )\n\t\t\t\tif nmin > n:\n\t\t\t\t\tnmin = n\n\t\t\t\t\tnidx = k\n\t\tif nidx is not None:\n\t\t\t# use nearest word\n\t\t\tresult = vecs_score[ nidx ]\n\treturn o, result\n# use multiprocessing\nfrom multiprocessing import Pool\nwith Pool(4) as p:\n\tfor o, val in p.map(get_onlytest_words, onlytest_words):\n\t\tvecs_score[ o ] = val","d6b86e44":"print('predict for trainig data set')\nvecs_train_posi = vecs_train[ index_posi ]\nscore_posi = vecs_train_posi.multiply( vecs_score ).sum( axis=1 )\nscore_posi = np.array(score_posi).reshape((-1,))\nprint('posi:',score_posi.min(),score_posi.max(),score_posi.mean(),np.median(score_posi))\n\nvecs_train_nega = vecs_train[ index_nega ]\nscore_nega = vecs_train_nega.multiply( vecs_score ).sum( axis=1 )\nscore_nega = np.array(score_nega).reshape((-1,))\nprint('nega:',score_nega.min(),score_nega.max(),score_nega.mean(),np.median(score_nega))","3c84c013":"print('make split point:')\nscore_min = min(score_posi.min(),score_nega.max())\nscore_max = max(score_posi.max(),score_nega.max())\nscore_div = score_min\nscore_div_p = score_div\nscore_gain = score_max - score_min\ncount_true = -np.inf\nfor _ in range(10):\n\tc = len( score_posi[ score_posi<=score_div ] ) + len( score_nega[ score_nega>score_div ] )\n\tif c > count_true:\n\t\tcount_true = c\n\t\tscore_div_p = score_div\n\t\tscore_gain \/= 2.0\n\t\tscore_div += score_gain\n\telse:\n\t\tscore_gain \/= 2.0\n\t\tscore_div -= score_gain\nprint('split point is',score_div_p)","8e129f24":"print('scoreing for training data set')\nTP = len( score_posi[ score_posi<=score_div_p ] )\nFP = len( score_nega[ score_nega<=score_div_p ] )\nFN = len( score_posi[ score_posi>score_div_p ] )\nTN = len( score_nega[ score_nega>score_div_p ] )\nPR = TP \/ (TP+FP)\nRC = TP \/ (TP+FN)\nprint('F1 score of training data set is',2*RC*PR \/ (RC+PR))","4aa94594":"score = vecs_test.multiply( vecs_score ).sum( axis=1 )\nscore = np.array(score).reshape((-1,))\nprint(score[:20])","8c10d69b":"score[ score <= 0 ] = 0\nscore[ score > 0 ] = 1\nscore = score.astype( np.int )\nprint(score[:20])\nprint('class0 count:',len(score[ score == 0 ]))\nprint('class1 count:',len(score[ score == 1 ]))\ntest_df[ 'prediction' ] = score\ntest_df[ 'prediction' ] = test_df[ 'prediction' ].astype( np.int )\ntest_df[ [ 'qid','prediction'] ].to_csv( 'submission.csv', index=None )","e8664276":"**Find words that is only in test set**","0096c543":"*make negative score for each word*","e500b373":"**Make submission**","e2bad3a4":"**Vectorize Question Text**","e17a0c00":"*make score split point*","a37f0eb0":"*find nearest word in word vector*","5a44ff68":"*score to class*","16ed7099":"*get vocabulary*","b6513949":"*scoreing for training data set*","43fa3675":"*Concat all datas*","8a30a6ad":"**Read dataset**","2330bfec":"*make sum of positive\/negative TFIDVector*","7db74f57":"**Use nearest word for only in test words**","e24e0ace":"**Make predict for training data set**","03fed756":"**Show positive\/negative words in trainig set**"}}