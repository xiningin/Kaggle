{"cell_type":{"da024018":"code","67a78cb4":"code","500f7862":"code","734cbcc5":"code","0e969c2d":"code","ae077414":"code","54cd048c":"code","1d76b501":"code","5c924475":"code","c4814973":"code","35e2787f":"code","3a492f70":"code","aac70548":"code","98f0de3c":"code","a306ad7f":"code","178be3af":"code","eccee382":"code","457c2599":"code","ad860512":"code","87cd5b66":"code","49e36950":"markdown","d44d8ce7":"markdown","2f3559d7":"markdown","e52050d3":"markdown","3f208e03":"markdown","127bdab1":"markdown"},"source":{"da024018":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nnp.random.seed(0)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor, XGBClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import MinMaxScaler, minmax_scale, MaxAbsScaler, StandardScaler, RobustScaler, Normalizer, QuantileTransformer, PowerTransformer\nfrom sklearn.decomposition import PCA\n","67a78cb4":"trainData = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/train.csv')\ntestData = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/test.csv')\n\ntrainData.head()","500f7862":"trainDataCopy = trainData.copy()\ntrainDataCopy = trainDataCopy.drop( 'id', axis=1)","734cbcc5":"def score_dataset(X_train, X_valid, y_train, y_valid, est, lrate, model_type):\n    if model_type == 'classifier':\n        model = XGBClassifier(n_estimators=est, learning_rate=lrate, n_jobs=4, tree_method='gpu_hist')\n    else:\n        model = XGBRegressor(n_estimators=est, learning_rate=lrate, n_jobs=4, tree_method='gpu_hist')\n\n    model.fit(X_train, y_train)\n    preds = model.predict(X_valid)\n    score = roc_auc_score(y_valid, preds)\n    return score","0e969c2d":"X = trainDataCopy.drop(['claim'], axis=1)\ny = trainDataCopy['claim']","ae077414":"imputer = SimpleImputer(strategy='median')\nimputed_X = pd.DataFrame(imputer.fit_transform(X))\nimputed_X.columns = X.columns\n\nscl = QuantileTransformer(output_distribution='uniform') # Transforma\u00e7\u00e3o com melhores resultados\npca = PCA()\nX_scaled = scl.fit_transform(imputed_X)\nX_pca = pca.fit_transform(X_scaled)\n    \ncomponent_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\nX_pca = pd.DataFrame(X_pca, columns=component_names)\n\nX_train, X_valid, y_train, y_valid = train_test_split(X_pca, y, train_size=0.7, test_size=0.3,\n                                                        random_state=0)\n\nprint(score_dataset(X_train, X_valid, y_train, y_valid, 1500, 0.02, 'regressor')) ","54cd048c":"np.cumsum(pca.explained_variance_ratio_)\npca.n_components_","1d76b501":"X = trainDataCopy.drop(['claim'], axis=1)\ny = trainDataCopy['claim']","5c924475":"imputer = SimpleImputer(strategy='median') \nimputed_X = pd.DataFrame(imputer.fit_transform(X))\nimputed_X.columns = X.columns\n\nscl = QuantileTransformer(output_distribution='uniform') # Transforma\u00e7\u00e3o com melhores resultados\npca = PCA(0.95)\nX_scaled = scl.fit_transform(imputed_X)\nX_pca = pca.fit_transform(X_scaled)\n    \ncomponent_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\nX_pca = pd.DataFrame(X_pca, columns=component_names)\n\nX_train, X_valid, y_train, y_valid = train_test_split(X_pca, y, train_size=0.7, test_size=0.3,\n                                                        random_state=0)\n\nprint(score_dataset(X_train, X_valid, y_train, y_valid, 1500, 0.02, 'regressor')) ","c4814973":"np.cumsum(pca.explained_variance_ratio_)\npca.n_components_","35e2787f":"X = trainDataCopy.drop(['claim'], axis=1)\nX['n_missing'] = trainDataCopy.isnull().sum(axis=1)\ny = trainDataCopy['claim']\n","3a492f70":"imputer = SimpleImputer(strategy='median') \nimputed_X = pd.DataFrame(imputer.fit_transform(X))\nimputed_X.columns = X.columns\n\nscl = QuantileTransformer(output_distribution='uniform') # Transforma\u00e7\u00e3o com melhores resultados\npca = PCA()\nX_scaled = scl.fit_transform(imputed_X)\nX_pca = pca.fit_transform(X_scaled)\n    \ncomponent_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\nX_pca = pd.DataFrame(X_pca, columns=component_names)\n\nX_train, X_valid, y_train, y_valid = train_test_split(X_pca, y, train_size=0.7, test_size=0.3,\n                                                        random_state=0)\n\nprint(score_dataset(X_train, X_valid, y_train, y_valid, 1500, 0.02, 'regressor')) ","aac70548":"np.cumsum(pca.explained_variance_ratio_)\npca.n_components_","98f0de3c":"X = trainDataCopy.drop(['claim'], axis=1)\nX['n_missing'] = trainDataCopy.isnull().sum(axis=1)\ny = trainDataCopy['claim']\n","a306ad7f":"imputer = SimpleImputer(strategy='median') \nimputed_X = pd.DataFrame(imputer.fit_transform(X))\nimputed_X.columns = X.columns\n\nscl = QuantileTransformer(output_distribution='uniform') # Transforma\u00e7\u00e3o com melhores resultados\npca = PCA(0.95)\nX_scaled = scl.fit_transform(imputed_X)\nX_pca = pca.fit_transform(X_scaled)\n    \ncomponent_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\nX_pca = pd.DataFrame(X_pca, columns=component_names)\n\nX_train, X_valid, y_train, y_valid = train_test_split(X_pca, y, train_size=0.7, test_size=0.3,\n                                                        random_state=0)\n\nprint(score_dataset(X_train, X_valid, y_train, y_valid, 1500, 0.02, 'regressor'))","178be3af":"np.cumsum(pca.explained_variance_ratio_)\npca.n_components_","eccee382":"X = trainDataCopy.drop(['claim'], axis=1)\nX['n_missing'] = trainDataCopy.isnull().sum(axis=1)\ny = trainDataCopy['claim']\n\nimputer = SimpleImputer(strategy='median') \nimputed_X = pd.DataFrame(imputer.fit_transform(X))\nimputed_X.columns = X.columns\n\nscl = QuantileTransformer(output_distribution='uniform') # Transforma\u00e7\u00e3o com melhores resultados\npca = PCA()\nX_scaled = scl.fit_transform(imputed_X)\nX_pca = pca.fit_transform(X_scaled)\n    \ncomponent_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\nX_pca = pd.DataFrame(X_pca, columns=component_names)\n\nX_train, X_valid, y_train, y_valid = train_test_split(X_pca, y, train_size=0.7, test_size=0.3,\n                                                        random_state=0)\n\nprint(score_dataset(X_train, X_valid, y_train, y_valid, 1500, 0.02, 'regressor'))","457c2599":"testDataCopy = testData.copy().drop('id', axis=1)\ntestDataCopy['n_missing'] = testData.isnull().sum(axis=1)","ad860512":"imputer = SimpleImputer(strategy='median')\nimputed_X_test = pd.DataFrame(imputer.fit_transform(testDataCopy))\nimputed_X_test.columns = testDataCopy.columns\n\nscl = QuantileTransformer(output_distribution='uniform')\npca = PCA()\nX_test_scaled = scl.fit_transform(imputed_X_test)\nX_test_pca = pca.fit_transform(X_test_scaled)\ncomponent_names = [f\"PC{i+1}\" for i in range(X_test_pca.shape[1])]\nX_test_pca = pd.DataFrame(X_test_pca, columns=component_names)","87cd5b66":"model = XGBRegressor(n_estimators=1500, learning_rate=0.02, n_jobs=4, tree_method='gpu_hist')\nmodel.fit(X_train, y_train)\npreds = model.predict(X_test_pca)\nseries = pd.Series(preds, index=testData['id'].astype('int'), name='claim') \nseries.to_csv('output.csv')\nseries","49e36950":"# PCA sem a feature n_missing e todos os componentes\n","d44d8ce7":"# PCA com a feature n_missing e vari\u00e2ncia acumulada de 0.95","2f3559d7":"# Arquivo de submiss\u00e3o da melhor abordagem","e52050d3":"# Imports","3f208e03":"# PCA sem a feature n_missing e vari\u00e2ncia acumulada de 0.95\n","127bdab1":"# PCA com a feature n_missing e todos os componentes\n"}}