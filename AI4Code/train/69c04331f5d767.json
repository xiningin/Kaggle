{"cell_type":{"6f5eb590":"code","e99c7c6c":"code","b19bb73e":"code","749f0500":"code","769d7207":"code","18a8a581":"code","91e5d9b8":"code","fa1016bf":"code","dad01217":"code","877cbcdc":"code","f72a54d5":"code","5ec43467":"code","b9b008c3":"code","3ad021bf":"code","02d46b5e":"code","71fdceae":"code","9b0f7ba6":"markdown","388f2906":"markdown","24c20a8b":"markdown","82a08240":"markdown","ab6f8c69":"markdown","02b13def":"markdown","7387413e":"markdown","ee3b826a":"markdown","157fc10d":"markdown"},"source":{"6f5eb590":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","e99c7c6c":"train_file = r'..\/input\/rs6-attrition-predict\/train.csv';\ntest_file = r'..\/input\/rs6-attrition-predict\/test.csv';\ntrain_employee_data = pd.read_csv(train_file, index_col='user_id');\ntest_employee_data = pd.read_csv(test_file, index_col='user_id');\nprint(train_employee_data.head());","b19bb73e":"#check for the shortage of the data\nprint(train_employee_data.isnull().any())","749f0500":"#the relationship between predictors and target;\nsns.distplot(train_employee_data['Age'], kde=True);\nplt.show();\nsns.swarmplot(x=train_employee_data['Attrition'], y=train_employee_data['Age']);\nplt.show();","769d7207":"#the relationship between `EmployeeNumber` and `Attrition`.;\nsns.swarmplot(x=train_employee_data['Attrition'], y=train_employee_data['EmployeeNumber']);","18a8a581":"#the confusing relationship among `DailyRate`, `MonthlyRate`, and `MonthlyIncome`\nsns.scatterplot(x=train_employee_data['DailyRate'], y=train_employee_data['MonthlyRate']);\nplt.show();\nsns.scatterplot(x=train_employee_data['DailyRate'], y=train_employee_data['MonthlyIncome']);\nplt.show();\nsns.scatterplot(x=train_employee_data['MonthlyRate'], y=train_employee_data['MonthlyIncome']);\nplt.show();","91e5d9b8":"from sklearn.model_selection import train_test_split","fa1016bf":"#predictors and target\ny = train_employee_data['Attrition'];\nX = train_employee_data.drop(['Attrition'], axis=1);\n\n#training set and validation set\nX_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0);\n\n#numerical columns and categorical columns\nnumerical_cols = [col for col in X_train.columns if X_train[col].dtype in ['int64', 'float64']];\ncategorical_cols = [col for col in X_train.columns if X_train[col].dtype == 'object'];\n\n#count the unique items in each categorical columns\nprint(train_employee_data[categorical_cols].nunique());","dad01217":"from sklearn.preprocessing import OneHotEncoder","877cbcdc":"#Use one-hot encoder to encode the categorical columns\nOH_encoder = OneHotEncoder(sparse=False);\nOH_train_cols = pd.DataFrame(OH_encoder.fit_transform(X_train[categorical_cols]));\nOH_valid_cols = pd.DataFrame(OH_encoder.transform(X_val[categorical_cols]));\nOH_test_cols = pd.DataFrame(OH_encoder.transform(test_employee_data[categorical_cols]));\n\nOH_train_cols.index = X_train.index;\nOH_valid_cols.index = X_val.index;\nOH_test_cols.index = test_employee_data.index;\n\nnumerical_train_cols = X_train.drop(categorical_cols, axis=1);\nnumerical_valid_cols = X_val.drop(categorical_cols, axis=1);\nnumerical_test_cols = test_employee_data.drop(categorical_cols, axis=1);\n\nOH_train = pd.concat([OH_train_cols, numerical_train_cols], axis=1);\nOH_valid = pd.concat([OH_valid_cols, numerical_valid_cols], axis=1);\nOH_test = pd.concat([OH_test_cols, numerical_test_cols], axis=1);","f72a54d5":"from sklearn.preprocessing import LabelEncoder","5ec43467":"label_encoder = LabelEncoder();\ny_train = label_encoder.fit_transform(y_train);\nprint(y_val);\ny_val = label_encoder.transform(y_val);\nprint(y_val);","b9b008c3":"from sklearn.linear_model import LogisticRegression","3ad021bf":"#Use LR to fit the data\nlr = LogisticRegression(C=1e5);\nlr.fit(OH_train, y_train);\nmy_valid_predict = lr.predict(OH_valid);\n\n#error\nfalse_number = ((my_valid_predict - y_val) ** 2).sum();\ntotal_number = len(y_val);\nprint((total_number - false_number) \/ total_number);","02d46b5e":"import numpy as np","71fdceae":"test_preds = lr.predict(OH_test);\nprint(test_preds);\nprint(test_employee_data.index);\noutput = pd.DataFrame({'user_id': test_employee_data.index, 'Attrition': test_preds});\noutput.to_csv('submission.csv', index=False);\nprint(output)","9b0f7ba6":"## Step 4: Validation\nHere, we \n* Use LR to fit the data;\n* predict and print the correct rate; ","388f2906":"## Step 3: Preprocessing\nHere, we \n* Split `train_employ_data` into train set and valid set;\n* Use One-Hot Encoding to encode the categorical columns;\n* Use One-Hot Encoding to encode the target column.","24c20a8b":"We find that those who decide to quit generally have younger age.","82a08240":"As we could see here, `EmployeeNumber` performs no particular relationship with `Attrition`. ","ab6f8c69":"## Step 1: Load the Data\nRead the employees data file into `employee_data`. Use the `user_id` column to label the rows.","02b13def":"The income or the rate is considered to be the same indicator for the employees' income. So, they should perform linear relationship. Surprisingly, they are totally messy. I am quite confused.  ","7387413e":"## Step 5: Predict","ee3b826a":"In this notebook, I will give a baseline prediction for employees' resignation behavior.\n## Setup\nRun the next cell to import and configure the Python libraries that I need to complete the prediction. Specially, I will use \n* **Pandas** to read and operate the data;\n* **Seaborn** to plot and explore the data;\n* **Sklearn** to import ML models.\n","157fc10d":"## Step 2: Explore the Data\nTo explore the data, we could do the following things:\n* Check for the possible shortage of the data;\n* Take `Age` as an example to explore the relationship between predictors and target;\n* Drop `EmployeeNumber` or not: The relationship between `EmployeeNumber` and `Attrition`;\n* The confusing relationships among `DailyRate`, `MonthlyRate`, and `MonthlyIncome`.\n"}}