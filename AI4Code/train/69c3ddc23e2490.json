{"cell_type":{"e9bef2f7":"code","37cd5869":"code","f929beff":"code","ab396dab":"code","767ec488":"code","5dbd67b8":"code","ec920676":"code","b4a69425":"code","e8b57b5b":"code","3c9d1f20":"code","c93b6454":"code","fc898aaf":"code","f35d01d7":"code","9900eb55":"code","cc16d509":"markdown","47a89ff9":"markdown","0fc602dd":"markdown","b1472240":"markdown","d1344291":"markdown","eec4cbe0":"markdown","865e78b9":"markdown","f0d18dbc":"markdown","ff5330be":"markdown"},"source":{"e9bef2f7":"import numpy as np\nimport pandas as pd \nimport os\n","37cd5869":"df = pd.DataFrame({'key1' : ['a','a','b','b','a'],\n                    'key2' :['one','two','one','two','one'] ,\n                    'data1': np.random.rand(5),\n                    'data2':np.random.rand(5)\n                  })\ndf","f929beff":"grouped_by_key1 = df['data1'].groupby(df['key1'])","ab396dab":"\nprint(grouped_by_key1.mean())\nprint(grouped_by_key1.max())\nprint(grouped_by_key1.median())\nprint(grouped_by_key1.size())\nprint(grouped_by_key1.min())","767ec488":"grouped = df.groupby(['key1','key2'])","5dbd67b8":"print(grouped.mean())","ec920676":"grouped.mean().unstack()","b4a69425":"k1_means = df.groupby('key1').mean().add_prefix('mean_')\nk1_means","e8b57b5b":"pd.merge(df , k1_means, left_on='key1', right_index = True)","3c9d1f20":"df.groupby('key2').transform(np.mean)","c93b6454":"def demean(arr):\n    return arr - arr.mean() \ndf.groupby('key2').transform(demean)","fc898aaf":"train = pd.read_csv('..\/input\/train.csv')\ntrain.head()","f35d01d7":"def top(data, n, column):\n    return data.sort_index(by=column)[:n]\n\ntrain.groupby('Sex').apply(top, n=5, column='Fare')","9900eb55":"train.groupby('Embarked').apply(top, n=5, column='Fare')","cc16d509":"Use transform to mean and demean grouped data","47a89ff9":"Use apply function to selects top n rows with the largest values in particular column ","0fc602dd":"Thanks for reading!","b1472240":"Using unstack() to view unikey pairs of the keys observed\n","d1344291":"\n After loading, merging, and preparing dataset, a familiar task is to compute group statistics or possibly pivot table for reporting or visualization purposes. We have flexible and high perfomance groupby fancility in pandas, it anabling you to slice and sum data set in natural way\n\n### In this notebook we will learn to \n*   Split pandas dataframe in to pieces using one or more key\n*  Computing group summary statistics, like count, mean, or standard deviation, or a user-defined function\n\n\n Some content in this notebook you can see in Python for Data Analysis book\n\n","eec4cbe0":"In the same way, we can cumputes all column using groups both lable key1 and key.  You can pass column name as the group key","865e78b9":"Reading Titanic dataset\n","f0d18dbc":"If you want to caculate mean, max ,min,  median , size of columm data1 by using groups lable from key1, there are a way to do that\n","ff5330be":"Merge data and transform data"}}