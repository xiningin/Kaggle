{"cell_type":{"108950c7":"code","8b93a0a4":"code","b2c60143":"code","389abd73":"code","2eea3106":"code","a1cb851d":"code","3cd98a60":"code","553ac9ed":"code","f62aaf16":"code","d653cf2a":"code","92efe239":"code","26ab94e3":"code","578d18aa":"code","1aaff0dc":"code","cf02d241":"code","255e759c":"code","67db8eb0":"code","8f267d76":"code","aad13f80":"code","ea87c444":"code","d71731b4":"code","b714f3b9":"code","42e6fca2":"code","620e3ea7":"code","0a1579ac":"code","32d96f60":"code","8bac1d9f":"code","832a928f":"code","791ff9aa":"code","39a83eea":"code","702edd5a":"code","904dd19b":"code","72117441":"code","8cf55dd4":"code","ed45f12c":"code","16a6c03b":"code","ea87ec03":"code","15cf7588":"code","0d84e321":"code","bd9ce66f":"markdown","47df6970":"markdown","2f4eb93f":"markdown","80f0b721":"markdown","136ad712":"markdown","293b0862":"markdown","31b8c69d":"markdown"},"source":{"108950c7":"# packages\nimport pandas as pd\nimport numpy as np\nimport datetime\nimport warnings\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n    import sklearn\n\n# required machine learning packages\nfrom sklearn import model_selection\nfrom sklearn.feature_selection import RFE\nfrom sklearn.metrics import brier_score_loss, roc_auc_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.calibration import CalibratedClassifierCV as CCV\n\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\nimport xgboost as xgb","8b93a0a4":"# loading CSV files downloaded from Kaggle\npath = \"..\/input\/\"\ndf = pd.read_csv(path + \"nfl-scores-and-betting-data\/spreadspoke_scores.csv\")\nteams = pd.read_csv(path + \"nfl-scores-and-betting-data\/nfl_teams.csv\")\ngames_elo = pd.read_csv(path + \"fivethirtyeightnflpredict\/nfl_games.csv\")\ngames_elo18 = pd.read_csv(path + \"fivethirtyeightnflpredict\/nfl_games_2018.csv\")\ngames_elo = games_elo.append(games_elo18)","b2c60143":"# replacing blank strings with NaN\ndf = df.replace(r'^\\s*$', np.nan, regex=True)\n\n# removing rows from specific columns that have null values, resetting index and changing data types\ndf = df[(df.score_home.isnull() == False) & (df.team_favorite_id.isnull() == False) & (df.over_under_line.isnull() == False) &\n        (df.schedule_season >= 1979)]\n\ndf.reset_index(drop=True, inplace=True)\ndf['over_under_line'] = df.over_under_line.astype(float)\n\n# mapping team_id to the correct teams\ndf['team_home'] = df.team_home.map(teams.set_index('team_name')['team_id'].to_dict())\ndf['team_away'] = df.team_away.map(teams.set_index('team_name')['team_id'].to_dict())\n\n# fix team_favorite_id for Colts in 1969 and 1971 SB\ndf.loc[(df.schedule_season == 1968) & (df.schedule_week == 'Superbowl'), 'team_favorite_id'] = 'IND'\ndf.loc[(df.schedule_season == 1970) & (df.schedule_week == 'Superbowl'), 'team_favorite_id'] = 'IND'\n\n# creating home favorite and away favorite columns (fill na with 0's)\ndf.loc[df.team_favorite_id == df.team_home, 'home_favorite'] = 1\ndf.loc[df.team_favorite_id == df.team_away, 'away_favorite'] = 1\ndf.home_favorite.fillna(0, inplace=True)\ndf.away_favorite.fillna(0, inplace=True)\n\n# creating over \/ under column (fill na with 0's)\ndf.loc[((df.score_home + df.score_away) > df.over_under_line), 'over'] = 1\ndf.over.fillna(0, inplace=True)\n\n# stadium neutral and schedule playoff as boolean\ndf['stadium_neutral'] = df.stadium_neutral.astype(int)\ndf['schedule_playoff'] = df.schedule_playoff.astype(int)\n\n# change data type of date columns\ndf['schedule_date'] = pd.to_datetime(df['schedule_date'])\ngames_elo['date'] = pd.to_datetime(games_elo['date'])","389abd73":"# fixing some schedule_week column errors and converting column to integer data type\ndf.loc[(df.schedule_week == '18'), 'schedule_week'] = '17'\ndf.loc[(df.schedule_week == 'Wildcard') | (df.schedule_week == 'WildCard'), 'schedule_week'] = '18'\ndf.loc[(df.schedule_week == 'Division'), 'schedule_week'] = '19'\ndf.loc[(df.schedule_week == 'Conference'), 'schedule_week'] = '20'\ndf.loc[(df.schedule_week == 'Superbowl') | (df.schedule_week == 'SuperBowl'), 'schedule_week'] = '21'\ndf['schedule_week'] = df.schedule_week.astype(int)","2eea3106":"# removing extra columns that aren't necessary for analysis\ndf = df[['schedule_date', 'schedule_season', 'schedule_week', 'team_home',\n       'team_away', 'team_favorite_id', 'spread_favorite',\n       'over_under_line', 'weather_temperature',\n       'weather_wind_mph', 'score_home', 'score_away',\n       'stadium_neutral', 'home_favorite', 'away_favorite',\n       'over']]","a1cb851d":"# Cleaning games_elo and df to merge correctly\nwsh_map = {'WSH' : 'WAS'}\ngames_elo.loc[games_elo.team1 == 'WSH', 'team1'] = 'WAS' \ngames_elo.loc[games_elo.team2 == 'WSH', 'team2'] = 'WAS'\n\n# fix dates\ndf.loc[(df.schedule_date == '2016-09-19') & (df.team_home == 'MIN'), 'schedule_date'] = datetime.datetime(2016, 9, 18)\ndf.loc[(df.schedule_date == '2017-01-22') & (df.schedule_week == 21), 'schedule_date'] = datetime.datetime(2017, 2, 5)\ndf.loc[(df.schedule_date == '1990-01-27') & (df.schedule_week == 21), 'schedule_date'] = datetime.datetime(1990, 1, 28)\ndf.loc[(df.schedule_date == '1990-01-13'), 'schedule_date'] = datetime.datetime(1990, 1, 14)\ngames_elo.loc[(games_elo.date == '2016-01-09'), 'date'] = datetime.datetime(2016, 1, 10)\ngames_elo.loc[(games_elo.date == '2016-01-08'), 'date'] = datetime.datetime(2016, 1, 9)\ngames_elo.loc[(games_elo.date == '2016-01-16'), 'date'] = datetime.datetime(2016, 1, 17)\ngames_elo.loc[(games_elo.date == '2016-01-15'), 'date'] = datetime.datetime(2016, 1, 16)","3cd98a60":"# merge games_elo with df\ndf = df.merge(games_elo, left_on=['schedule_date', 'team_home', 'team_away'], right_on=['date', 'team1', 'team2'], how='left')\n\n# merge to fix neutral games where team_home and team_away are switched\ngames_elo2 = games_elo.rename(columns={'team1' : 'team2', 'team2' : 'team1', 'elo1' : 'elo2', 'elo2' : 'elo1'})\ngames_elo2['elo_prob1'] = 1 - games_elo2.elo_prob1\ndf = df.merge(games_elo2, left_on=['schedule_date', 'team_home', 'team_away'], right_on=['date', 'team1', 'team2'], how='left')","553ac9ed":"# separating merged columns into x and y cols\nx_cols = ['date_x', 'season_x', 'neutral_x', 'playoff_x', 'team1_x', 'team2_x', 'elo1_x', 'elo2_x', 'elo_prob1_x', 'score1_x',\n         'score2_x', 'result1_x']\ny_cols = ['date_y', 'season_y', 'neutral_y', 'playoff_y', 'team1_y', 'team2_y', 'elo1_y', 'elo2_y', 'elo_prob1_y', 'score1_y',\n          'score2_y', 'result1_y']\n\n# filling null values for games_elo merged cols\nfor x, y in zip(x_cols, y_cols):\n    df[x] = df[x].fillna(df[y]) \n\n# removing y_cols from dataframe    \ndf = df[['schedule_date', 'schedule_season', 'schedule_week', 'team_home',\n       'team_away', 'team_favorite_id', 'spread_favorite', 'over_under_line',\n       'weather_temperature', 'weather_wind_mph', 'score_home', 'score_away',\n       'stadium_neutral', 'home_favorite', 'away_favorite', 'over', 'neutral_x', 'playoff_x',\n         'elo1_x', 'elo2_x', 'elo_prob1_x']]\n\n# remove _x ending from column names\ndf.columns = df.columns.str.replace('_x', '')","f62aaf16":"# creating result column df.loc[(df.score_home > df.score_away), 'result'\ndf['result'] = (df.score_home > df.score_away).astype(int)","d653cf2a":"# all column names\ndf.columns","92efe239":"# snapshot of data\ndf.head(10)","26ab94e3":"# null values by column\ndf.isnull().sum(axis=0)","578d18aa":"# summary statistics\ndf.describe().transpose()","1aaff0dc":"# some percentages to take into consideration when betting\nhome_win = \"{:.2f}\".format((sum((df.result == 1) & (df.stadium_neutral == 0)) \/ len(df)) * 100)\naway_win = \"{:.2f}\".format((sum((df.result == 0) & (df.stadium_neutral == 0)) \/ len(df)) * 100)\nunder_line = \"{:.2f}\".format((sum((df.score_home + df.score_away) < df.over_under_line) \/ len(df)) * 100)\nover_line = \"{:.2f}\".format((sum((df.score_home + df.score_away) > df.over_under_line) \/ len(df)) * 100)\n\nfavored = \"{:.2f}\".format((sum(((df.home_favorite == 1) & (df.result == 1)) | ((df.away_favorite == 1) & (df.result == 0)))\n                           \/ len(df)) * 100)\n\ncover = \"{:.2f}\".format((sum(((df.home_favorite == 1) & ((df.score_away - df.score_home) < df.spread_favorite)) | \n                             ((df.away_favorite == 1) & ((df.score_home - df.score_away) < df.spread_favorite))) \n                         \/ len(df)) * 100)\n\nats = \"{:.2f}\".format((sum(((df.home_favorite == 1) & ((df.score_away - df.score_home) > df.spread_favorite)) | \n                           ((df.away_favorite == 1) & ((df.score_home - df.score_away) > df.spread_favorite))) \n                       \/ len(df)) * 100)","cf02d241":"# print all percentages\nprint(\"Number of Games: \" + str(len(df)))\nprint(\"Home Straight Up Win Percentage: \" + home_win + \"%\")\nprint(\"Away Straight Up Win Percentage: \" + away_win + \"%\")\nprint(\"Under Percentage: \" + under_line + \"%\")\nprint(\"Over Percentage: \" + over_line + \"%\")\nprint(\"Favored Win Percentage: \" + favored + \"%\")\nprint(\"Cover The Spread Percentage: \" + cover + \"%\")\nprint(\"Against The Spread Percentage: \" + ats + \"%\")","255e759c":"# creating 2 separate dataframes with the home teams \/ scores and the away teams \/ scores\nscore = df.groupby(['schedule_season', 'schedule_week', 'team_home']).mean()[['score_home', 'score_away']].reset_index()\naw_score = df.groupby(['schedule_season', 'schedule_week', 'team_away']).mean()[['score_home', 'score_away']].reset_index()\n\n# create total pts column\nscore['point_diff'] = score.score_home - score.score_away\naw_score['point_diff'] = aw_score.score_away - aw_score.score_home\n\n# append the two dataframes\nscore = score.append(aw_score, ignore_index=True, sort=True)\n\n# fill null values\nscore.team_home.fillna(score.team_away, inplace=True)\n\n# sort by season and week \nscore.sort_values(['schedule_season', 'schedule_week'], ascending = [True, True], inplace=True)\n\n# removing unneeded columns & changing column name \nscore = score[['schedule_season', 'schedule_week', 'team_home', 'point_diff']]\nscore.rename(columns={'team_home' : 'team'}, inplace=True)","67db8eb0":"# dictionary of dataframes - separate dataframe for each team\ntm_dict = {}\nfor key in score.team.unique():\n    tm_dict[key] = score[score.team == key].reset_index(drop=True)","8f267d76":"# dataframe to populate\npts_diff = pd.DataFrame()\n\n# for loop to create a rolling average of the previous games for each season\nfor yr in score.schedule_season.unique():\n    for tm in score.team.unique():\n        data = tm_dict[tm].copy()\n        data = data[data.schedule_season == yr]\n        \n        data.loc[:, 'avg_pts_diff'] = data.point_diff.shift().expanding().mean()\n        \n        pts_diff = pts_diff.append(data)","aad13f80":"# merging to df and changing column names\ndf = df.merge(pts_diff[['schedule_season', 'schedule_week', 'team', 'avg_pts_diff']], \n              left_on=['schedule_season', 'schedule_week', 'team_home'], right_on=['schedule_season', 'schedule_week', 'team'],\n              how='left')\n\ndf.rename(columns={'avg_pts_diff' : 'hm_avg_pts_diff'}, inplace=True)\n\ndf = df.merge(pts_diff[['schedule_season', 'schedule_week', 'team', 'avg_pts_diff']], \n              left_on=['schedule_season', 'schedule_week', 'team_away'], right_on=['schedule_season', 'schedule_week', 'team'],\n              how='left')\n\ndf.rename(columns={'avg_pts_diff' : 'aw_avg_pts_diff'}, inplace=True)","ea87c444":"# average point differential over entire season\ntotal_season = pts_diff.groupby(['schedule_season', 'team']).mean()['point_diff'].reset_index()","d71731b4":"# adding schedule week for merge and adding one to the season for predictions\ntotal_season['schedule_week'] = 1\ntotal_season['schedule_season'] += 1","b714f3b9":"# cleaning of columns\ndf = df[['schedule_date', 'schedule_season', 'schedule_week', 'team_home',\n       'team_away', 'team_favorite_id', 'spread_favorite', 'over_under_line',\n       'weather_temperature', 'weather_wind_mph', 'score_home', 'score_away', 'stadium_neutral', 'home_favorite',\n       'away_favorite', 'hm_avg_pts_diff','aw_avg_pts_diff', 'elo1', 'elo2', 'elo_prob1', 'over', 'result']]","42e6fca2":"# merge to have previous seasons average point differential\ndf = df.merge(total_season[['schedule_season', 'schedule_week', 'team', 'point_diff']], \n              left_on=['schedule_season', 'schedule_week', 'team_home'], right_on=['schedule_season', 'schedule_week', 'team'],\n              how='left')\n\ndf.rename(columns={'point_diff' : 'hm_avg_diff'}, inplace=True)\n\ndf = df.merge(total_season[['schedule_season', 'schedule_week', 'team', 'point_diff']], \n              left_on=['schedule_season', 'schedule_week', 'team_away'], right_on=['schedule_season', 'schedule_week', 'team'],\n              how='left')\n\ndf.rename(columns={'point_diff' : 'aw_avg_diff'}, inplace=True)\n\n# fill null values\ndf.hm_avg_pts_diff.fillna(df.hm_avg_diff, inplace=True)\ndf.aw_avg_pts_diff.fillna(df.aw_avg_diff, inplace=True)","620e3ea7":"# cleaning of columns\ndf = df[['schedule_date', 'schedule_season', 'schedule_week', 'team_home',\n       'team_away', 'team_favorite_id', 'spread_favorite', 'over_under_line',\n       'weather_temperature', 'weather_wind_mph', 'score_home', 'score_away', 'stadium_neutral', 'home_favorite',\n       'away_favorite', 'hm_avg_pts_diff','aw_avg_pts_diff', 'elo1', 'elo2', 'elo_prob1', 'over', 'result']]","0a1579ac":"# removing all rows with null values\ndf = df.dropna(how='any',axis=0) ","32d96f60":"# initial features possible for model\nX = df[['schedule_season', 'schedule_week', 'over_under_line', 'spread_favorite', 'weather_temperature', 'weather_wind_mph',\n        'home_favorite', 'hm_avg_pts_diff','aw_avg_pts_diff', 'elo1', 'elo2', 'elo_prob1']]\n\ny = df['result']","8bac1d9f":"# base model\nbase = LDA()\n\n# choose 5 best features\nrfe = RFE(base, 5)\nrfe = rfe.fit(X, y)\n\n# features\nprint(rfe.support_)\nprint(rfe.ranking_)","832a928f":"# best 5 features chosen by the RFE base model\nfinal_x = df[['spread_favorite', 'home_favorite', 'hm_avg_pts_diff', 'elo2', 'elo_prob1']]","791ff9aa":"# prepare models\nmodels = []\n\nmodels.append(('LRG', LogisticRegression(solver='liblinear')))\nmodels.append(('KNB', KNeighborsClassifier()))\nmodels.append(('GNB', GaussianNB()))\nmodels.append(('XGB', xgb.XGBClassifier(random_state=0)))\nmodels.append(('RFC', RandomForestClassifier(random_state=0, n_estimators=100)))\nmodels.append(('DTC', DecisionTreeClassifier(random_state=0, criterion='entropy', max_depth=5)))\n\n# evaluate each model by average and standard deviations of roc auc \nresults = []\nnames = []\n\nfor name, m in models:\n    kfold = model_selection.KFold(n_splits=5, random_state=0)\n    cv_results = model_selection.cross_val_score(m, final_x, y, cv=kfold, scoring = 'roc_auc')\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)","39a83eea":"# training and testing data (2017 and 2018)\ntrain = df.copy()\ntest = df.copy()\ntrain = train.loc[train['schedule_season'] < 2017]\ntest = test.loc[test['schedule_season'] > 2016]\nX_train = train[['over_under_line', 'spread_favorite', 'home_favorite', 'hm_avg_pts_diff', 'elo_prob1']]\ny_train = train['result']\nX_test = test[['over_under_line', 'spread_favorite', 'home_favorite', 'hm_avg_pts_diff', 'elo_prob1']]\ny_test = test['result']","702edd5a":"# calibrate probabilities and fit model to training data\nboost = xgb.XGBClassifier()\ndtc = DecisionTreeClassifier(max_depth=5, criterion='entropy')\nlrg = LogisticRegression(solver='liblinear')\nvote = VotingClassifier(estimators=[('boost', boost), ('dtc', dtc), ('lrg', lrg)], voting='soft')\n\nmodel = CCV(vote, method='isotonic', cv=3)\nmodel.fit(X_train, y_train)","904dd19b":"# predict probabilities\npredicted = model.predict_proba(X_test)[:,1]","72117441":"# ROC AUC Score higher is better while Brier Score the lower the better\nprint(\"Metrics\" + \"\\t\\t\" + \"My Model\" + \"\\t\" + \"Elo Results\")\nprint(\"ROC AUC Score: \" +  \"\\t\" + \"{:.4f}\".format(roc_auc_score(y_test, predicted)) + \"\\t\\t\" + \"{:.4f}\".format(roc_auc_score(test.result, test.elo_prob1)))\nprint(\"Brier Score: \" + \"\\t\" + \"{:.4f}\".format(brier_score_loss(y_test, predicted)) + \"\\t\\t\" + \"{:.4f}\".format(brier_score_loss(test.result, test.elo_prob1)))","8cf55dd4":"# creating a column with the models probabilities to analyze vs elo fivethirtyeight\ntest.loc[:,'hm_prob'] = predicted\ntest = test[['schedule_season', 'schedule_week', 'team_home', 'team_away', 'elo_prob1', 'hm_prob', 'result']]","ed45f12c":"# calulate bets won (only make a bet when probability is greater than \/ equal to 60% or less than \/ equal to 40%)\ntest['my_bet_won'] = (((test.hm_prob >= 0.60) & (test.result == 1)) | ((test.hm_prob <= 0.40) & (test.result == 0))).astype(int)\ntest['elo_bet_won'] = (((test.elo_prob1 >= 0.60) & (test.result == 1)) | ((test.elo_prob1 <= 0.40) & (test.result == 0))).astype(int)\n\n# calulate bets lost (only make a bet when probability is greater than \/ equal to 60% or less than \/ equal to 40%)\ntest['my_bet_lost'] = (((test.hm_prob >= 0.60) & (test.result == 0)) | ((test.hm_prob <= 0.40) & (test.result == 1))).astype(int)\ntest['elo_bet_lost'] = (((test.elo_prob1 >= 0.60) & (test.result == 0)) | ((test.elo_prob1 <= 0.40) & (test.result == 1))).astype(int)","16a6c03b":"# printing some quick overall results for my model\nprint(\"My Model Win Percentage: \" + \"{:.4f}\".format(test.my_bet_won.sum() \/ (test.my_bet_lost.sum() + test.my_bet_won.sum())))\nprint(\"Total Number of Bets Won: \" + str(test.my_bet_won.sum()))\nprint(\"Total Number of Bets Made: \" + str((test.my_bet_lost.sum() + test.my_bet_won.sum())))\nprint(\"Possible Games: \" + str(len(test)))","ea87ec03":"# printing some quick overall results for fivethirtyeight's ELO model\nprint(\"ELO Model Win Percentage: \" + \"{:.4f}\".format(test.elo_bet_won.sum()\/(test.elo_bet_lost.sum() + test.elo_bet_won.sum())))\nprint(\"Total Number of Bets Won: \" + str(test.elo_bet_won.sum()))\nprint(\"Total Number of Bets Made: \" + str((test.elo_bet_lost.sum() + test.elo_bet_won.sum())))\nprint(\"Possible Games: \" + str(len(test)))","15cf7588":"# creating week by week results\nresults_df = test.groupby(['schedule_season', 'schedule_week']).agg({'team_home' : 'count', 'my_bet_won' : 'sum', \n'elo_bet_won' : 'sum', 'my_bet_lost' : 'sum', 'elo_bet_lost' : 'sum'}).reset_index().rename(columns=\n                                                                                            {'team_home' : 'total_games'})\n\n# counting total bets for my model and the ELO model (prob >= 60% or prob <= 40%)\nresults_df['total_bets'] = results_df.my_bet_won + results_df.my_bet_lost\nresults_df['elo_total_bets'] = results_df.elo_bet_won + results_df.elo_bet_lost\n\n# creating accuracy columns based on bets made not on total games\nresults_df['bet_accuracy'] = round((results_df.my_bet_won \/ results_df.total_bets) * 100, 2)\nresults_df['elo_bet_accuracy'] = round((results_df.elo_bet_won \/ results_df.elo_total_bets) * 100, 2)\nresults_df = results_df[['schedule_season', 'schedule_week', 'bet_accuracy', 'elo_bet_accuracy',\n                         'total_bets', 'elo_total_bets', 'total_games']]","0d84e321":"results_df","bd9ce66f":"# Results","47df6970":"# Creating More Features\nFeatures that will help predict whether the home team will win (straight up win in the current version the line doesn't matter)","2f4eb93f":"# Data Exploration","80f0b721":"No Longer Maintained Here\n\nGo to [NFL Prediction Model -- Github](https:\/\/github.com\/TyWalters\/NFL-Prediction-Model) for updates.","136ad712":"# NFL Betting Model","293b0862":"# Loading and Cleaning Data","31b8c69d":"# Feature and Model Testing "}}