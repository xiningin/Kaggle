{"cell_type":{"6c9b3905":"code","3f86bbd9":"code","06b94d8c":"code","2e7e0f51":"code","8f18d7bc":"code","8851cfa9":"code","4ea0f1ff":"code","eead1647":"code","01f95370":"code","4c7afd48":"markdown","de495da6":"markdown","b9555321":"markdown","3664740f":"markdown","33fca69f":"markdown","d23d5ede":"markdown","7df29dfa":"markdown"},"source":{"6c9b3905":"import numpy as np\n\n# read data from text files\nwith open('data\/reviews.txt', 'r') as f:\n    reviews = f.read()\nwith open('data\/labels.txt', 'r') as f:\n    labels = f.read()","3f86bbd9":"print(reviews[:1000])\nprint()\nprint(labels[:20])","06b94d8c":"from string import punctuation\n\n# get rid of punctuation\nreviews = reviews.lower() # lowercase, standardize\nall_text = ''.join([c for c in reviews if c not in punctuation])\n\n# split by new lines and spaces\nreviews_split = all_text.split('\\n')\nall_text = ' '.join(reviews_split)\n\n# create a list of words\nwords = all_text.split()","2e7e0f51":"words[:30]","8f18d7bc":"# feel free to use this import \nfrom collections import Counter\n\n## Build a dictionary that maps words to integers\ncounts = Counter(words)\nvocab = sorted(counts, key=counts.get, reverse=True)\nvocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n\n## use the dict to tokenize each review in reviews_split\n## store the tokenized reviews in reviews_ints\nreviews_ints = []\nfor review in reviews_split:\n    reviews_ints.append([vocab_to_int[word] for word in review.split()])","8851cfa9":"# stats about vocabulary\nprint('Unique words: ', len((vocab_to_int)))  # should ~ 74000+\nprint()\n\n# print tokens in first review\nprint('Tokenized review: \\n', reviews_ints[:1])","4ea0f1ff":"# 1=positive, 0=negative label conversion\nlabels_split = labels.split('\\n')\nencoded_labels = np.array([1 if label == 'positive' else 0 for label in labels_split])","eead1647":"# outlier review stats\nreview_lens = Counter([len(x) for x in reviews_ints])\nprint(\"Zero-length reviews: {}\".format(review_lens[0]))\nprint(\"Maximum review length: {}\".format(max(review_lens)))","01f95370":"print('Number of reviews before removing outliers: ', len(reviews_ints))\n\n## remove any reviews\/labels with zero length from the reviews_ints list.\n\n# get indices of any reviews with length 0\nnon_zero_idx = [ii for ii, review in enumerate(reviews_ints) if len(review) != 0]\n\n# remove 0-length reviews and their labels\nreviews_ints = [reviews_ints[ii] for ii in non_zero_idx]\nencoded_labels = np.array([encoded_labels[ii] for ii in non_zero_idx])\n\nprint('Number of reviews after removing outliers: ', len(reviews_ints))","4c7afd48":"### Encoding the labels (start working here: think embeddings)\n\nOur labels are \"positive\" or \"negative\". To use these labels in our network, we need to convert them to 0 and 1.\n\n> **Exercise:** Convert labels from `positive` and `negative` to 1 and 0, respectively, and place those in a new list, `encoded_labels`.","de495da6":"### Removing Outliers\n\nAs an additional pre-processing step, we want to make sure that our reviews are in good shape for standard processing. That is, our network will expect a standard input text size, and so, we'll want to shape our reviews into a specific length. We'll approach this task in two main steps:\n\n1. Getting rid of extremely long or short reviews; the outliers\n2. Padding\/truncating the remaining data so that we have reviews of the same length.\n\nBefore we pad our review text, we should check for reviews of extremely short or long lengths; outliers that may mess with our training.","b9555321":"**Test your code**\n\nAs a text that you've implemented the dictionary correctly, print out the number of unique words in your vocabulary and the contents of the first, tokenized review.","3664740f":"---\n## Padding sequences (advise)\n\nTo deal with both short and very long reviews, we'll pad or truncate all our reviews to a specific length. For reviews shorter than some `seq_length`, we'll pad with 0s. For reviews longer than `seq_length`, we can truncate them to the first `seq_length` words. A good `seq_length`, in this case, is 200.\n\n> **Exercise:** Define a function that returns an array `features` that contains the padded data, of a standard size, that we'll pass to the network. \n* The data should come from `review_ints`, since we want to feed integers to the network. \n* Each row should be `seq_length` elements long. \n* For reviews shorter than `seq_length` words, **left pad** with 0s. That is, if the review is `['best', 'movie', 'ever']`, `[117, 18, 128]` as integers, the row will look like `[0, 0, 0, ..., 0, 117, 18, 128]`. \n* For reviews longer than `seq_length`, use only the first `seq_length` words as the feature vector.\n\nAs a small example, if the `seq_length=10` and an input review is: \n```\n[117, 18, 128]\n```\nThe resultant, padded sequence should be: \n\n```\n[0, 0, 0, 0, 0, 0, 0, 117, 18, 128]\n```\n\n**Your final `features` array should be a 2D array, with as many rows as there are reviews, and as many columns as the specified `seq_length`.**\n\nThis isn't trivial and there are a bunch of ways to do this. But, if you're going to be building your own deep learning networks, you're going to have to get used to preparing your data.","33fca69f":"Okay, a couple issues here. We seem to have one review with zero length. And, the maximum review length is way too many steps for our RNN. We'll have to remove any super short reviews and truncate super long reviews. This removes outliers and should allow our model to train more efficiently.\n\n> **Exercise:** First, remove *any* reviews with zero length from the `reviews_ints` list and their corresponding label in `encoded_labels`.","d23d5ede":"## Data pre-processing (TODO)\n\nThe first step when building a neural network model is getting your data into the proper form to feed into the network. Since we're using embedding layers, we'll need to encode each word with an integer. We'll also want to clean it up a bit.\n\nYou can see an example of the reviews data above. Here are the processing steps, we'll want to take:\n>* We'll want to get rid of periods and extraneous punctuation.\n* Also, you might notice that the reviews are delimited with newline characters `\\n`. To deal with those, I'm going to split the text into each review using `\\n` as the delimiter. \n* Then I can combined all the reviews back together into one big string.\n\nFirst, let's remove all punctuation. Then get all the text without the newlines and split it into individual words.","7df29dfa":"---\n### Load in and visualize the data"}}