{"cell_type":{"577d6521":"code","0dcc4dc6":"code","84f30e47":"code","1f3effa0":"code","34387018":"code","a3f28be4":"code","0f3627b7":"code","42e5055e":"code","93b4c485":"code","888fc279":"code","81f15402":"code","05e51611":"code","6e0de8b6":"code","3e79fd2b":"code","392c24a1":"code","671b798f":"code","86f266f9":"code","6016a3dc":"code","1fcea0b4":"code","93cda086":"code","da9715e9":"code","4b01558f":"code","ce1e6b4d":"code","813478c1":"code","d5be4113":"code","bba895cf":"markdown","81f39873":"markdown","3f6f4363":"markdown","0d12128a":"markdown","8b4b79aa":"markdown","f5327a8a":"markdown","8fdddb16":"markdown","05eba071":"markdown","f8104a6d":"markdown","03b845e7":"markdown","0fff3d83":"markdown","033e5af4":"markdown","9a3b23f9":"markdown","98b5c19a":"markdown","79b3c30b":"markdown","a86d140d":"markdown","b3df77e7":"markdown","d0263dbf":"markdown","7529a17c":"markdown","d062ba68":"markdown","a94cdd7b":"markdown","09d4f79b":"markdown","f7b0d0f9":"markdown","fb6b14fa":"markdown","a57509e9":"markdown","4bc1537b":"markdown","26f3df71":"markdown","6ee50cec":"markdown","1461f594":"markdown","9590d063":"markdown"},"source":{"577d6521":"#import libreries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#read datasets\nstudent=pd.read_table(\"..\/input\/student-alcohol-consumption\/student-por.csv\", sep=',')\n\nstudent","0dcc4dc6":"student.info()","84f30e47":"student.describe()","1f3effa0":"plt.figure(figsize=(15,15))\nsns.heatmap(student.corr(), annot=True)","34387018":"sns.countplot('age', data=student, hue='sex')\nplt.ylabel('Numeber of students')\nplt.title('Age of students by sex')","a3f28be4":"sns.boxplot('G3', 'sex', data=student)\nplt.title ('Better sex on G3')","0f3627b7":"plt.figure(figsize=(6,6))\nsns.boxplot(x=\"age\",y=\"G3\",data=student)\nplt.title('G3 Avarage based on age ')","42e5055e":"plt.figure(figsize=(6,6))\nsns.countplot('age', data=student, hue='failures')\nplt.ylabel('n students')\nplt.title('failures per age')","93b4c485":"plt.figure(figsize=(6,6))\nsns.barplot(x=\"age\",y=\"Walc\",data=student)\nplt.ylabel('Weekend alcohol consumption')\nplt.title('Alcohol consumption based on age')","888fc279":"plt.figure(figsize=(6,6))\nsns.lmplot(x=\"age\",y=\"goout\",data=student)\n\nplt.title('Go out based on age')","81f15402":"plt.figure(figsize=(6,6))\n\nsns.barplot(x=\"age\",y=\"goout\",data=student)\nplt.title('Go out based on age')","05e51611":"sns.boxplot('studytime', 'G3', data=student)\nplt.xlabel(\"Weekly study hours\")\nplt.title('Influence of weekly study hours')","6e0de8b6":"sns.violinplot('activities', 'G3', data=student, hue='romantic', color='r')\nplt.title('Influence of extracurricular activities and \\nromantic relationship on final grades.')","3e79fd2b":"sns.boxplot('Pstatus', 'G3', data=student, hue='famsize')\nplt.xlabel('Family Apart o Together')\nplt.title('Final grades based on family')","392c24a1":"student['walcool']= student['Dalc']+ student['Walc'] #create and sum (provvisory) alchol daily and weekend consuption\nsns.boxplot('walcool', 'G3', data=student)\nplt.title('Alcohol consumption influences')\nplt.xlabel('Alcohol consumption')","671b798f":"student= student.drop('walcool', axis=1) #deleting provvisory column","86f266f9":"sns.boxplot('G3', 'nursery', data=student)\nplt.title('G3 based on nursery')","6016a3dc":"#transform binary value in 0 and 1\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\nstudent.nursery = le.fit_transform(student['nursery'])\nstudent.internet = le.fit_transform(student['internet'])\nstudent.schoolsup = le.fit_transform(student['schoolsup'])\nstudent.activities = le.fit_transform(student['activities'])\nstudent.paid = le.fit_transform(student['paid'])\nstudent.higher = le.fit_transform(student['higher'])\nstudent.school=le.fit_transform(student['school'])\nstudent.address=le.fit_transform(student['address'])\nstudent.sex=le.fit_transform(student['sex'])\nstudent.Pstatus=le.fit_transform(student['Pstatus'])\nstudent.famsize=le.fit_transform(student['famsize'])\nstudent.famsup=le.fit_transform(student['famsup'])\nstudent.activities=le.fit_transform(student['activities'])\nstudent.romantic=le.fit_transform(student['romantic'])\n\n\n#now for other data not boolean we can do an one-hot encoding\nstudent = pd.get_dummies(student, columns = ['Mjob', 'Fjob', 'reason', 'guardian'])\nstudent\n\nstudent.head()","1fcea0b4":"#import models and metrics\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import KFold, GridSearchCV, StratifiedKFold\nfrom sklearn.metrics import r2_score, mean_absolute_error","93cda086":"#separating data\nX = student.drop (['school','failures', 'absences', 'G1', 'G2', 'G3'], axis=1)\ny = student.G3\n\n#splitting data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=10)\nskf = StratifiedKFold(n_splits=10, random_state=90, shuffle=True) #cross validation with 10 split","da9715e9":"#defining parameters for decision tree regressor\nparams= { 'max_features':[0.5], #[0.1,0.2,0.3,0.4,0.5],\n    'min_samples_split':[0.1], #5,6,7,8, 0.1,0.2\n    'min_samples_leaf':[0.1], #2,3,4,5,6,7,8,0.1,0.2,0.3\n        }\n\nreg_tree = DecisionTreeRegressor()\ngs = GridSearchCV(estimator=reg_tree, param_grid=params, cv=5, n_jobs=-1) #validate model with his parameters\ngs.fit(X_train, y_train) #fitting training set\n\nreg_tree = gs.best_estimator_\nprint(reg_tree) #printing best estimator values\n\npred_tree = reg_tree.predict (X_test)\n\n#printing scores\ndt_score = r2_score(y_test, pred_tree)\ndt_mae = mean_absolute_error(y_test, pred_tree)\nprint('MAE: %.2f' %dt_mae)\nprint('Score: %.2f' %dt_score)\n\nimportances = reg_tree.feature_importances_\nindices= np.argsort(importances)[::-1]\n# summarize feature importance\nfor i,v in enumerate(importances):\n    print(\"%d. Feature %s(%.3f)\" % (i + 1, X.columns.values[indices[i]], importances[indices[i]]))","4b01558f":"params = {'n_estimators':[1000],\n        'min_samples_leaf': [4], #2,3,4,5,6,7\n        'min_samples_split': [4], #2,3,4,5,6\n          'max_features': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n\n             }\n\n\nreg_forest = RandomForestRegressor()\ngs = GridSearchCV(reg_forest,params, cv=5, n_jobs=-1) #validation for Random Forest\ngs.fit (X_train, y_train)\nreg_forest=gs.best_estimator_\nprint(reg_forest)\n\npred_forest = reg_forest.predict (X_test)\nrf_score = r2_score(y_test, pred_forest) \nrf_mae = mean_absolute_error(y_test, pred_forest)\nprint('MAE: %.2f' %rf_mae)\nprint('Score: %.2f' %rf_score)\n\n#features importance\nimportances = reg_forest.feature_importances_\nindices= np.argsort(importances)[::-1]\n# summarize feature importance\nfor i,v in enumerate(importances):\n    print(\"%d. Feature %s(%.3f)\" % (i + 1, X.columns.values[indices[i]], importances[indices[i]]))","ce1e6b4d":"#scaling data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train) #fitting and transform training data\nX_test = scaler.transform(X_test) #transform test data","813478c1":"params= {\n    'kernel':['rbf'], #linear\n    'C':[0.9], #[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n    'epsilon':[1.2], #[0.01,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,2.0,3.0,1.1,1.2,1.3,1.4],\n    'gamma':[0.01], #[0.1,0.2,0.3,0.4,0.5]\n        }\n\nreg_svr = SVR()\ngs = GridSearchCV(reg_svr,params, cv=5, n_jobs=-1) #validation for Random Forest\ngs.fit (X_train, y_train)\nreg_svr=gs.best_estimator_\nprint(reg_svr)\n\npred_svr = reg_svr.predict (X_test)\nsvr_score = r2_score(y_test, pred_svr)\nsvr_mae = mean_absolute_error(y_test, pred_svr)\nprint('MAE: %.2f' %svr_mae)\nprint('Score: %.2f' %svr_score)\n\n\n#importeance only for linear kernel\n#importance = reg_svr.coef_\n#indices= np.argsort(importance)[::-1]\n# summarize feature importance\n#for i,v in enumerate(importance):\n#    print(\"%d. Feature %s(%.2f)\" % (i+1, X.columns.values[indices[i]], importance[indices[i]]))","d5be4113":"from tabulate import tabulate\ndata=[[svr_score, svr_mae],\n      [rf_score, rf_mae],\n      [dt_score, dt_mae ]]\nindex = ['SVR','Random Forest Regressor', 'Decision Tree Regressor']\ntab = pd.DataFrame(data, index=index, columns=['R2 score', 'MAE']).sort_values('R2 score',ascending = False).round(2)\n\n   \n\nprint(tabulate(tab, headers= ['Model', 'R2 score', 'MAE'],tablefmt='fancy_grid'))\n","bba895cf":"Family status don't influence school performance.","81f39873":"# Student Grades and Alcohol Consumption","3f6f4363":"### Cleaning data","0d12128a":"For our best prediction we have to clean the data, so transform the features.","8b4b79aa":"#### Important features","f5327a8a":"In this dataset there are the informations of students Portuguese courses.\nWhat we are going to do is to arrange these data, make a social analysis and then a prediction to know the final grade.","8fdddb16":"In our model the most important and influence feature is higher and age.","05eba071":"The hours of study per week influence the average grade of students. The greater the dedication, the greater the final grade.\n\nBut how is the average affected if we also consider extracurricular activities and a romantic relationship?","f8104a6d":"The average of the final grade, even if not by much, decreases with increasing age. This can be due to many factors that make students more mature and more free to do things.\n\nLet's do a check.\n\nFirst we check the number of students who have failed and for how many times.","03b845e7":"The boys have a lower average than girls. Now we will see if feature 'age' is relevant on G3.","0fff3d83":"Most students have an average of around 11, but also we can see that some students have slightly higher grades. The extra-curricular activities and romantic relationship does not affect G3.","033e5af4":"The alcohol consumption is not strictly related to the grades of the students, at least not as excessively as you might think. A student who drinks more tends to have a not so high G3.","9a3b23f9":"This graph gives us a general picture of how everything affects grades.\n\nBefore going for a more in-depth analysis, however, we note other things:\n- G1, G2, G3 are closely related each other. Which mean: If the average of the marks of G1 and G2 does not vary, these two features would be enough to predict G3. I could think to delete G1 and G2 as they are closely correlated with G3\n- Failures are also closely related to grades. It is obvious that with good grades the chances of failure decrease\n- Study time and weekend alcohol consumption also influence each other. A student who tends to drink (so go out more times) a lot reduces the hours of study and viceversa","98b5c19a":"What we are going to do is calculate the final grade of a student thanks to our machine learning models, evaluating which is the best.","79b3c30b":"Here is how we can see there is a slightly negative influence. Students between the ages of 16 and 19 are the ones most affected by outings. In fact, as you can see from the previous graph, there are more failures included in that age group.","a86d140d":"Before proceeding with an analysis it is useful to know what the columns and its values refer to.\n\n1. school - student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)\n2. sex - student's sex (binary: 'F' - female or 'M' - male)\n3. age - student's age (numeric: from 15 to 22)\n4. address - student's home address type (binary: 'U' - urban or 'R' - rural)\n5. famsize - family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3)\n6. Pstatus - parent's cohabitation status (binary: 'T' - living together or 'A' - apart)\n7. Medu - mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 \u2013 5th to 9th grade, 3 \u2013 secondary education or 4 \u2013 higher education)\n8. Fedu - father's education (numeric: 0 - none, 1 - primary education (4th grade), 2 \u2013 5th to 9th grade, 3 \u2013 secondary education or 4 \u2013 higher education)\n9. Mjob - mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n10. Fjob - father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n11. reason - reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other')\n12. guardian - student's guardian (nominal: 'mother', 'father' or 'other')\n13. traveltime - home to school travel time (numeric: 1 - 1 hour)\n14. studytime - weekly study time (numeric: 1 - 10 hours)\n15. failures - number of past class failures (numeric: n if 1<=n<3, else 4)\n16. schoolsup - extra educational support (binary: yes or no)\n17. famsup - family educational support (binary: yes or no)\n18. paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)\n19. activities - extra-curricular activities (binary: yes or no)\n20. nursery - attended nursery school (binary: yes or no)\n21. higher - wants to take higher education (binary: yes or no)\n22. internet - Internet access at home (binary: yes or no)\n23. romantic - with a romantic relationship (binary: yes or no)\n24. famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\n25. freetime - free time after school (numeric: from 1 - very low to 5 - very high)\n26. goout - going out with friends (numeric: from 1 - very low to 5 - very high)\n27. Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n28. Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n29. health - current health status (numeric: from 1 - very bad to 5 - very good)\n30. absences - number of school absences (numeric: from 0 to 93)\n\nThese grades are related with the course subject, Math or Portuguese:\n\n31. G1 - first period grade (numeric: from 0 to 20)\n32. G2 - second period grade (numeric: from 0 to 20)\n33. G3 - final grade (numeric: from 0 to 20, output target)","b3df77e7":"What we can initially see is that:\n- there are no NaN values\n- all the features are on different scales\n- many of these are categorical\n- the average of all students is constant throughout the period and is around 11\n- Moms and dads have an education between the 5th and 9th grade\n- The average that a student devotes to study is approximately 2 hours\n- Students are in excellent health and do not have excessive alcohol consumption throughout the week (according to a subjective opinion)\n- G1 and G2 is very similar to G3\n\nNow seeing the correlation between the values.","d0263dbf":"For my analysis, since the grades are closely related to each other, I will only consider G3.","7529a17c":"Average students alcohol consumption does not appear to be high, except for older students.\n\nWith these other 2 graphs we will see if with increasing age the outputs also increase.","d062ba68":"#### RandomForest Regressor","a94cdd7b":"#### Scaling ","09d4f79b":"##### Best scroring","f7b0d0f9":"This last graph compares G3 with nursery and non-nursery students. There is not a big difference between the two, except in the median of the grades. In nursery schools it is higher.","fb6b14fa":"#### DecisionTree","a57509e9":"Now let's see if the weekly study hours affect the final grade.","4bc1537b":"As we can see there are many students who fail and repeat the year. Students thus tend to finish school later and also lose concentration in their studies, so that they also have a lower average.","26f3df71":"To calculate the final grade I want to evaluate these three model of ML. I'm starting to use models that don't need to be scale like DecisionTree and RandomForestRegressor after that I'm going to take in consideration SVR.\n\nTo make more realistic my analysis I deleted G1 and G2 because is too close to G3 and school, failures and abseces because I want to predict G3 based on social status. So my prediction will based on other features.","6ee50cec":"Now I scaled data because I want to try with SVR","1461f594":"### Grades prediction","9590d063":"#### SVR"}}