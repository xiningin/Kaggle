{"cell_type":{"ae036c7b":"code","9bb5d7aa":"code","8d5852b1":"code","21613af1":"code","73317efe":"code","f71d1956":"code","01b709a8":"code","703d2b62":"code","f43d8be4":"code","1b09fdc1":"code","46e594e2":"code","c50da855":"code","0685dba3":"code","115117f7":"code","69cc38a9":"code","af14d67a":"code","a90de09a":"code","4716f1c4":"code","d571a872":"code","ece4d01b":"code","3e0f8377":"code","4cbd53b8":"code","73d269fd":"code","92fd4ef4":"code","b10000d8":"markdown","5d2f648a":"markdown","507ff8aa":"markdown","7f38a0be":"markdown","3ea4ddd1":"markdown","5aad6b45":"markdown","2e3de6f1":"markdown","0cd8c2d7":"markdown","6c5e4a14":"markdown","73a66e28":"markdown","86b75573":"markdown","b8caf31d":"markdown","5f0f7fe3":"markdown","c69fb1a6":"markdown","368d9e5f":"markdown","c3d54dce":"markdown","ce5d2cc8":"markdown","e264b27a":"markdown","9021b69e":"markdown","85db8e31":"markdown"},"source":{"ae036c7b":"# Libraries and dependencies needed for dicom visualation and model training\n# !pip install torchsummary\n# !pip install efficientnet_pytorch\n# !pip install pylibjpeg pylibjpeg-libjpeg\n# !conda install -c conda-forge gdcm -y\n# !pip install python-gdcm\n# !pip install pylibjpeg\n# import pydicom\n# !python -m pip uninstall numpy --yes\n# !pip install numpy==1.19.2\n","9bb5d7aa":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\n!pip install efficientnet_pytorch\n!pip install torchsummary\nfrom torchsummary import summary\nimport PIL\nimport sys\nimport torch\nfrom time import time\nimport torchvision\nfrom PIL import Image\nimport torch.nn as nn\nfrom torch.utils import data\nfrom torch.autograd import Variable\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\n# I have used Efficientnet3 pre-trained model for the classification task\nfrom efficientnet_pytorch import EfficientNet\n# !python -m pip uninstall numpy --yes\n# !python -m pip uninstall pydicom --yes\n# !pip install pydicom\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\nfrom torch.autograd import Variable\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nimport torch.optim as om\nimport torchvision as tv\nimport torch.utils.data as dat\n\n# I have used Efficientnet3 pre-trained model for the classification task\n\nif torch.cuda.is_available():     # Make sure GPU is available\n    dev = torch.device(\"cuda:0\")\n    kwar = {'num_workers': 8, 'pin_memory': True}\n    cpu = torch.device(\"cpu\")\nelse:\n    print(\"Warning: CUDA not found, CPU only.\")\n    dev = torch.device(\"cpu\")\n    kwar = {}\n    cpu = torch.device(\"cpu\")","8d5852b1":"training_set_study = pd.read_csv('..\/input\/siim-covid19-detection\/train_study_level.csv')\ntraining_set_image_level = pd.read_csv('..\/input\/siim-covid19-detection\/train_image_level.csv')\ntraining_set_study.head(100)","21613af1":"# looking at the image_level_training_set.\ntraining_set_image_level.head(100)","73317efe":"# Changing the column values to allow for merging of two tables. The merged tables can then be used to extract image data.\ntraining_set_image_level.id = training_set_image_level.id.str.replace('_image','')\ntraining_set_image_level.head()\ntraining_set_study.id = training_set_study.id.str.replace('_study','')\ntraining_set_study.head()\n# training_set_image_level.loc[training_set_image_level.StudyInstanceUID == '005057b3f880']","f71d1956":"combined_training_set = training_set_image_level.merge(training_set_study, left_on = 'StudyInstanceUID', right_on = 'id', how = 'inner', suffixes=('_image', 'study'))\ncombined_training_set.drop(columns = 'idstudy', inplace = True)\ncombined_training_set.head()\n","01b709a8":"# Creating function to get absolute path.\n\ndef get_absolute_file_paths(x):\n    path = '..\/input\/siim-covid19-detection\/train\/'\n    directory = os.path.join(path,x )\n    all_abs_file_paths = []\n    for dirpath,_,filenames in os.walk(directory):\n        for f in filenames:\n            all_abs_file_paths.append(os.path.abspath(os.path.join(dirpath, f)))\n    return all_abs_file_paths\n# get_absolute_file_paths(combined_training_set.StudyInstanceUID[0])","703d2b62":"combined_training_set['abs_image_path'] = combined_training_set.StudyInstanceUID.apply(get_absolute_file_paths) \ncombined_training_set.head()","f43d8be4":"# Function for reading .dicom files\n# ----------> Copid from 'siim-cov19 efnb7+yolov5 [infer]' :) ~~~~~~~~ Thanks\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    # Original from: https:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n    # \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data","1b09fdc1":"!pip install python-gdcm\n!pip install pylibjpeg pylibjpeg-libjpeg\nfig, axs = plt.subplots(nrows = 2, ncols = 5, sharex = True, sharey = True, figsize = (20, 10), tight_layout = True)\nfor ax, Index_num in zip(axs.reshape(-1), np.random.choice(range(len(combined_training_set)), 20, replace=False)):\n    data = read_xray(combined_training_set.abs_image_path[Index_num][0])\n    data = cv2.resize(data, (500,500))\n    ax.imshow(data, cmap = 'gray')\n    ax.set_title('{}'.format(combined_training_set[['Negative for Pneumonia', 'Typical Appearance',\n           'Indeterminate Appearance', 'Atypical Appearance']].idxmax(axis = 1)[Index_num]))","46e594e2":"# currently ignoring the dicom image errors --------------> need help on that, please leave a comment if you can find a solution to it. Thanks in advance.\ndef getNumpyArraysSet(combined_training_set, ImageSize = (128,128)):\n    X_temp = []\n    Y_temp = []\n    dicom_error_images_path = []\n    i = 0\n    for n in range(len(combined_training_set)):\n        print('Percentage task complete {}'.format(n\/len(combined_training_set) * 100))\n        try:\n            data = read_xray(combined_training_set.abs_image_path[n][0])\n            try:\n                Y_temp.append(combined_training_set[['Negative for Pneumonia', 'Typical Appearance',\n                   'Indeterminate Appearance', 'Atypical Appearance']].iloc[n].values)\n            except:\n                pass\n        except RuntimeError:\n            i = i+1\n            dicom_error_images_path.append(combined_training_set.abs_image_path[n][0])\n            print('The number of images not read because of pydicom library errors are {}'.format(i))\n    #     Get data and directory of images giving dicom error.\n            continue\n        data = cv2.resize(data, ImageSize)\n        X_temp.append(data)\n    # stacking up list in ndarray\n    print('stacking arrays in list started')\n    X = np.dstack(X_temp)\n    try:\n        y = np.dstack(Y_temp)\n    except:\n        print('y has no elemnts')\n    print('Stacking finished')\n    np.save('ImageArray'+str(ImageSize[0]), X)\n    try:\n        np.save('TargetArray'+str(ImageSize[0]), y)\n    except:\n        print('y has no elemnts')\n    # Saving path to images that were not analysed.....\n    df = pd.DataFrame(dicom_error_images_path)\n    df.to_csv('PathDicomErrorImages.csv')\n    print('All Done --------> Enjoy !!!!')\n    return X, y\n    \n##################### \n# Getting the numpy arrays for training data set. \nX, Y = getNumpyArraysSet(combined_training_set, ImageSize = (128,128))\n####################","c50da855":"X = np.load('ImageArray128.npy')\ny = np.load('TargetArray128.npy')","0685dba3":"directory = '..\/input\/siim-covid19-detection\/test'\n# getting all the image paths\nall_abs_file_paths = []\nfor dirpath,_,filenames in os.walk(directory):\n        for f in filenames:\n            all_abs_file_paths.append(os.path.abspath(os.path.join(dirpath, f)))\n\ntest_df = pd.DataFrame(all_abs_file_paths, columns = ['abs_image_path'])\ntest_df['id'] = test_df['abs_image_path'].apply(lambda x: x.split(\"\/\")[5])\ntest_df['abs_image_path'] = test_df['abs_image_path'].apply(lambda x: [x])\nX_final_test = getNumpyArraysSet(test_df) # test data by Kaggle","115117f7":"transform_train = transforms.Compose([transforms.ToPILImage(),\n                    transforms.RandomApply([torchvision.transforms.RandomRotation(10),transforms.RandomHorizontalFlip()],0.7), \n                    transforms.ToTensor()])","69cc38a9":"#upsampling the minority class\nnewX = []\nnewY = []\nfor j in range(X.shape[-1]):\n    if y[0,-1,j] == 1:\n        for k in range(8):\n            newX.append(transform_train(X[:,:,j]))\n            newY.append(y[0,:,j])\n    else:\n        newX.append(transform_train(X[:,:,j]))\n        newY.append(y[0,:,j])\nbalancedX = np.stack(newX)\nbalancedX = np.repeat(balancedX, repeats = 3, axis =1)\nbalancedY = np.stack(newY)","af14d67a":"# checking unique values in new dataset.\ntarget_df = pd.DataFrame(balancedY, columns = ['Negative for Pneumonia', 'Typical Appearance',\n           'Indeterminate Appearance', 'Atypical Appearance'])\ntarget_df.value_counts()","a90de09a":"## Splitting into training and validation set.\nvalidFrac = 0.1   # Define the fraction of images to move to validation dataset\ntestFrac = 0.1    # Define the fraction of images to move to test dataset\nvalidList = []\ntestList = []\ntrainList = []\n\nfor i in range(len(balancedX)):\n    rann = np.random.random() # Randomly reassign images\n    if rann < validFrac:\n        validList.append(i)\n    elif rann < testFrac + validFrac:\n        testList.append(i)\n    else:\n        trainList.append(i)\n        \nnTrain = len(trainList)  # Count the number in each set\nnValid = len(validList)\nnTest = len(testList)\nprint(\"Training images =\",nTrain,\"Validation =\",nValid,\"Testing =\",nTest)","4716f1c4":"trainIds = torch.tensor(trainList)    # Slice the big image and label tensors up into\nvalidIds = torch.tensor(validList) \ntestIds = torch.tensor(testList)       #       training, validation, and testing tensors\ntrainX = torch.tensor(balancedX[trainIds,:,:,:])\ntrainY = torch.tensor(balancedY[trainIds,:])\nvalidX = torch.tensor(balancedX[validIds,:,:,:])\nvalidY = torch.tensor(balancedY[validIds,:])\ntestX = torch.tensor(balancedX[testIds,:,:,:])\ntestY = torch.tensor(balancedY[testIds,:])","d571a872":"model = EfficientNet.from_pretrained('efficientnet-b2', num_classes=4) # loading model\nmodel.to(dev) # Sendeng the model to GPU","ece4d01b":"# Explore the model complexity\nprint(summary(model, input_size=(3, 128, 128)))","3e0f8377":"numClass = len(balancedY[:,0])\nlearnRate = 0.01          # Define a learning rate.\nmaxEpochs = 20            # Maximum training epochs\nt2vRatio = 1.5            # Maximum allowed ratio of validation to training loss\nt2vEpochs = 3            # Number of consecutive epochs before halting if validation loss exceeds above limit\nbatchSize = 128           # Batch size. Going too large will cause an out-of-memory error.\ntrainBats = nTrain \/\/ batchSize       # Number of training batches per epoch. Round down to simplify last batch\nvalidBats = nValid \/\/ batchSize       # Validation batches. Round down\ntestBats = -(-nTest \/\/ batchSize)     # Testing batches. Round up to include all\nopti = om.SGD(model.parameters(), lr = learnRate)   # Initialize an optimizer\nlossEval = nn.CrossEntropyLoss()\n\nfor i in range(maxEpochs):\n    model.train()                     # Set model to training mode\n    epochLoss = 0.\n    permute = torch.randperm(nTrain)  # Shuffle data to randomize batches\n    trainX = trainX[permute,:,:,:]\n    trainY = trainY[permute]\n    for j in range(trainBats):        # Iterate over batches\n        if j%20 == 0:\n          print('The batch num is {}'.format(j))\n        opti.zero_grad()              # Zero out gradient accumulated in optimizer\n        batX = trainX[j*batchSize:(j+1)*batchSize,:,:,:].to(dev)   # Slice shuffled data into batches\n        batY = trainY[j*batchSize:(j+1)*batchSize].to(dev)         # .to(dev) moves these batches to the GPU\n        yOut = model(batX)            # Evalute predictions\n        # print(yOut, batY)\n        loss = F.cross_entropy(yOut, torch.max(batY, 1)[1])        # Compute loss\n        epochLoss += loss.item()      # Add loss\n        loss.backward()               # Backpropagate loss\n        opti.step()                   # Update model weights using optimizer\n    validLoss = 0.\n    permute = torch.randperm(nValid)  # We go through the exact same steps, without backprop \/ optimization\n    validX = validX[permute,:,:,:]    # in order to evaluate the validation loss\n    validY = validY[permute]\n    model.eval()                      # Set model to evaluation mode\n    with torch.no_grad():             # Temporarily turn off gradient descent\n        for j in range(validBats):\n            opti.zero_grad()\n            batX = validX[j*batchSize:(j+1)*batchSize,:,:,:].to(dev)\n            batY = validY[j*batchSize:(j+1)*batchSize].to(dev)\n            yOut = model(batX)\n            validLoss += F.cross_entropy(yOut, torch.max(batY, 1)[1]).item()\n    epochLoss \/= trainBats            # Average loss over batches and print\n    validLoss \/= validBats\n    print(\"Epoch = {:-3}; Training loss = {:.4f}; Validation loss = {:.4f}\".format(i,epochLoss,validLoss))\n    if validLoss > t2vRatio * epochLoss:\n        t2vEpochs -= 1                # Test if validation loss exceeds halting threshold\n        if t2vEpochs < 1:\n            print(\"Validation loss too high; halting to prevent overfitting\")\n            break","4cbd53b8":"confuseMtx = np.zeros((numClass,numClass),dtype=int)    # Create empty confusion matrix\nmodel.eval()\npredictions = []\nwith torch.no_grad():\n    permute = torch.randperm(nTest)                     # Shuffle test data\n    testX = testX[permute,:,:,:]\n    testY = testY[permute]\n    for j in range(testBats):                           # Iterate over test batches\n        batX = testX[j*batchSize:(j+1)*batchSize,:,:,:].to(dev)\n        batY = testY[j*batchSize:(j+1)*batchSize].to(dev)\n        yOut = model(batX) # Pass test batch through model\n        for j in yOut:\n            print(j, len(j),np.zeros(len(j)), torch.max(j,0)[1])\n            b = np.zeros(len(j))\n            index = torch.max(j,0)[1]\n            b[index] = 1\n            predictions.append(b)\n        pred = yOut.max(1,keepdim=True)[1]              # Generate predictions by finding the max Y values\n        for j in torch.cat((batY.max(1,keepdim=True)[1], pred),dim=1).tolist(): # Glue together Actual and Predicted to\n            confuseMtx[j[0],j[1]] += 1                  # make (row, col) pairs, and increment confusion matrix\ncorrect = sum([confuseMtx[i,i] for i in range(numClass)])   # Sum over diagonal elements to count correct predictions\nprint(\"Correct predictions: \",correct,\"of\",nTest)\nprint(\"Confusion Matrix:\")\nprint(confuseMtx)\n# print(classNames)","73d269fd":"testX","92fd4ef4":"# Get confusion matrix using scikit-learn\nfrom sklearn.metrics import confusion_matrix\npredictions = np.stack(predictions)\nconfusion_matrix()","b10000d8":"## Minimal data augmentation for upsampling the minority class","5d2f648a":"# Getting Numpy Array From Test Data Set","507ff8aa":"# Visualisation\n### Reading 10 random images and showing there labels","7f38a0be":"## Function for reading dicom images","3ea4ddd1":"# Loading the EfficientNet Model","5aad6b45":"### Getting path of each image and adding it to the combined tables\n<!--     Assumptions -->\n1. Some image folders have multiple images however we have neglected that and instead only selected the first image in that folder.","2e3de6f1":"## Loading the training set image and study ids","0cd8c2d7":"# Testing the model on Test Data","6c5e4a14":"# Learning About Datasets","73a66e28":"## Converting numpy arrays into torch tensors......... Data that is understood by tensorflow and pytorch","86b75573":"# Training the Model","b8caf31d":"# Reading X-rays for image visualisation","5f0f7fe3":"# Data Preparation For Training the Model\n- Once you have have numpy arrays you canuse any model or train the data, We will be using efficientNet to train our first model. \n- Hoever before we move forward we must prepare the numpy arrays for the pretrained model.","c69fb1a6":"# Merging Two Training Set Tables\nThe StudyInstanceUID in train_image_level is same as the 'id' in train_study_level. Henceforth these two tables can be merged based on these two columns.","368d9e5f":"# Importing Libraries","c3d54dce":"# Introduction TO Covid-19 problem","ce5d2cc8":"# Reason Why This Notebook Exists","e264b27a":"# Getting numpy array from dicom images\n- This numpy array can then be used as an input to any tensorflow or pytorch deep learning model","9021b69e":"## Splitting into training, test and Validation set","85db8e31":"### There are various notebooks on Kaggle describing how to get started with the image classificatin using pyutorch or Tensorflow to detect Covid-19 by analysing X-rays. However most of them are highly complicated or least they are complicated to me. So I decided to help out everyone by creating this ver simple starte notebook. It shows how you can train an EfficientNet model using the Kaggle data set and pytorch library."}}