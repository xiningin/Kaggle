{"cell_type":{"f10fc187":"code","69221017":"code","090c07fd":"code","54d262e7":"code","20e8cd66":"code","e4ac6433":"code","259c64d4":"code","0946282f":"code","0e40c389":"code","00f8bd23":"code","c9f37ffc":"code","5effc2e3":"code","1c8eab70":"code","afdbf220":"code","3fd208f7":"markdown","784bd0a1":"markdown","b976de3f":"markdown","250af79f":"markdown","a6bdc19f":"markdown","3e0f3aed":"markdown","4bb73e23":"markdown","a18b2fcf":"markdown","f8cfe41b":"markdown","caaa0222":"markdown","80d7e94f":"markdown","0f71945b":"markdown","541c00f5":"markdown","492e25f6":"markdown","648c3c2b":"markdown","c3aa25ae":"markdown"},"source":{"f10fc187":"pneumonia_path = '..\/input\/chest_xray\/chest_xray\/test\/PNEUMONIA\/person103_bacteria_490.jpeg'\nnormal_path = '..\/input\/chest_xray\/chest_xray\/test\/NORMAL\/IM-0005-0001.jpeg'","69221017":"import matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimg = mpimg.imread(pneumonia_path)\n#imgplot = plt.imshow(img, cmap = 'gray')\nimgplot = plt.imshow(img)","090c07fd":"img = mpimg.imread(normal_path)\nimgplot = plt.imshow(img)","54d262e7":"#import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nIMG_SIZE = (64, 64)\ndatagen = ImageDataGenerator(samplewise_center=True, \n                              samplewise_std_normalization=True, \n                              horizontal_flip = True, \n                              vertical_flip = False, \n                              height_shift_range= 0.05, \n                              width_shift_range=0.1, \n                              rotation_range=5, \n                              shear_range = 0.1,\n                              fill_mode = 'reflect',\n                              zoom_range=0.15)","20e8cd66":"\ntrain_generator = datagen.flow_from_directory(\n        '..\/input\/chest_xray\/chest_xray\/train',\n        target_size=IMG_SIZE,\n        color_mode = 'grayscale',\n        batch_size=32,\n        class_mode='binary')\n\nx_val, y_val = next(datagen.flow_from_directory(\n        '..\/input\/chest_xray\/chest_xray\/val',\n        target_size=IMG_SIZE,\n        color_mode = 'grayscale',\n        batch_size=32,\n        class_mode='binary')) # one big batch\n\nx_test, y_test = next(datagen.flow_from_directory(\n        '..\/input\/chest_xray\/chest_xray\/test',\n        target_size=IMG_SIZE,\n        color_mode = 'grayscale',\n        batch_size=180,\n        class_mode='binary')) # one big batch","e4ac6433":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Dense, Flatten\n\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation=\"relu\", input_shape=x_test.shape[1:]))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Conv2D(32, (3, 3), activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation = 'relu'))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n                           metrics = ['binary_accuracy', 'mae'])\nmodel.summary()","259c64d4":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_weights.best.hdf5\".format('pneumonia_cnn')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=5)\ncallbacks_list = [checkpoint, early]","0946282f":"#First Round \nmodel.fit_generator(train_generator, \n                    steps_per_epoch=100, \n                    validation_data = (x_val, y_val), \n                    epochs = 1, \n                    callbacks = callbacks_list)\n\n   \n# Save the entire model as a SavedModel\nmodel.save('pneumonia_cnn') ","0e40c389":"scores = model.evaluate(x_test, y_test)\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\nprint(\"val_loss:\", scores[0])\nprint(\"val_mean_absolute_error:\", scores[2])","00f8bd23":"# Continued Training\nmodel.fit_generator(train_generator, \n                    steps_per_epoch=100, \n                    validation_data = (x_val, y_val), \n                    epochs = 11, \n                    callbacks = callbacks_list)","c9f37ffc":"model.load_weights(weight_path)\nscores = model.evaluate(x_test, y_test)\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\nprint(\"val_loss:\", scores[0])\nprint(\"val_mean_absolute_error:\", scores[2])","5effc2e3":"pred_Y = model.predict(x_test, batch_size = 32, verbose = True)\nprint(pred_Y[:15])","1c8eab70":"print(y_test[:15])","afdbf220":"from sklearn.metrics import roc_curve, auc\n# Compute ROC curve and ROC area for each class\n\nnum_classes = 0\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfpr, tpr, _ = roc_curve(y_test, pred_Y)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(11,8))\nlw = 2\nplt.plot(fpr, tpr, color='darkorange', \n         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.savefig('roc2.png')","3fd208f7":"Use The Trained Convolutional Neural Network for Clasification","784bd0a1":"Image of Normal X-Ray","b976de3f":"ModelCheckpoint To Save Best Weights and EarlyStopping to Stop Training When Training Stops Improving","250af79f":"**Using a Convolutional Neural Network to Diagnose Pneumonia (Radiology)**\n\n\nThis session on Computer Vision covers the training of a Convolutional Neural Network for Pneumonia X-Ray Image Classification. \nBy: Runmila AI Institute (https:\/\/runmilainstitute.com)\n\n\n\n\n**TensorFlow 2**\n![https:\/\/storage.ning.com\/topology\/rest\/1.0\/file\/get\/3628709184?profile=RESIZE_710x](https:\/\/storage.ning.com\/topology\/rest\/1.0\/file\/get\/3628709184?profile=RESIZE_710x)","a6bdc19f":"\n\n\n\n**Pooling Layer**\n\nReduces the spatial size of Captured Features (*Feature Maps*) by extracting dominant features. \n\n\n**Max Pooling** returns the maximum value from the portion of the image covered by the Filter.\n\n\n\n![https:\/\/developers.google.com\/machine-learning\/practica\/image-classification\/images\/maxpool_animation.gif](https:\/\/developers.google.com\/machine-learning\/practica\/image-classification\/images\/maxpool_animation.gif)","3e0f3aed":"Sample Images From Dataset","4bb73e23":"Training The Convolutional Neural Network with The Training Data (First Round)","a18b2fcf":"ROC Curve and Area Under ROC Curve for Evaluating The Trained Convolutional Neural Network","f8cfe41b":"Image of Pneumonia X-Ray","caaa0222":"Training The Convolutional Neural Network with The Training Data (Continuation)","80d7e94f":"![https:\/\/i0.wp.com\/vinodsblog.com\/wp-content\/uploads\/2018\/10\/CNN-2.png?resize=1300%2C479&ssl=1](https:\/\/i0.wp.com\/vinodsblog.com\/wp-content\/uploads\/2018\/10\/CNN-2.png?resize=1300%2C479&ssl=1)","0f71945b":"Evaluating The Convolutional Neural Network With Validation Data ","541c00f5":"Convolutional Neural Network Architecture","492e25f6":"**Multilayer Perceptrons**\n![https:\/\/miro.medium.com\/max\/3000\/1*BIpRgx5FsEMhr1k2EqBKFg.gif](https:\/\/miro.medium.com\/max\/3000\/1*BIpRgx5FsEMhr1k2EqBKFg.gif)\n\n\n\n\n\n\n\n**Convolutional Neural Networks**\n\nThey use filters to be able to successfully capture the Spatial and Temporal dependencies in an image. \n\n\n![https:\/\/cdn-images-1.medium.com\/max\/1600\/1*ZCjPUFrB6eHPRi4eyP6aaA.gif](https:\/\/cdn-images-1.medium.com\/max\/1600\/1*ZCjPUFrB6eHPRi4eyP6aaA.gif)\n\n\n![http:\/\/karpathy.github.io\/assets\/selfie\/gif2.gif](http:\/\/karpathy.github.io\/assets\/selfie\/gif2.gif)\n\n\n**Convolutional Layers**\n\nkeras.layers.Conv2D(number_of_filters, filter_size, activation=None)\n\n\n**Filters\/Kernels**\n\nThe feature capturing fields\/windows. During training, your ConvNet would learn the best filters necessary for accomplishing its objective.\n\nNot much different from the IG or other photo editing filters.  \n\n\n\n![https:\/\/s3-ap-south-1.amazonaws.com\/av-blog-media\/wp-content\/uploads\/2017\/06\/28011851\/conv.gif](https:\/\/s3-ap-south-1.amazonaws.com\/av-blog-media\/wp-content\/uploads\/2017\/06\/28011851\/conv.gif)\n\n\n![https:\/\/mlnotebook.github.io\/img\/CNN\/convSobel.gif](https:\/\/mlnotebook.github.io\/img\/CNN\/convSobel.gif)\n\n\n![https:\/\/ujwlkarn.files.wordpress.com\/2016\/08\/giphy.gif?w=364](https:\/\/ujwlkarn.files.wordpress.com\/2016\/08\/giphy.gif?w=364)\n\n\n\n","648c3c2b":"Peprocessing and Augmenting Dataset Images ","c3aa25ae":"Load the Best Weights and Evaluate The Trained Convolutional Neural Network"}}