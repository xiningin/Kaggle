{"cell_type":{"6d60319b":"code","18c7d0b5":"code","440d448f":"code","b86dffdd":"code","068c3580":"code","4026df88":"code","c316d4f6":"code","abcd6f73":"code","911f4b04":"code","4175c695":"code","a832220b":"code","d69899ce":"code","50555865":"code","3928ab26":"code","525fcbe8":"code","5f6e700c":"markdown","c01b0ba5":"markdown","b4754384":"markdown","f2249f78":"markdown","11531ead":"markdown","054098ee":"markdown","2bc50b66":"markdown","0faafb5d":"markdown","277d32db":"markdown","e6666012":"markdown","433a76a2":"markdown"},"source":{"6d60319b":"from tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import Reshape\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.layers import Concatenate\nfrom tensorflow.keras.layers import Conv2DTranspose\nfrom matplotlib import pyplot\nfrom tensorflow.keras.datasets.mnist import load_data\nimport numpy as np\nfrom IPython.display import display, clear_output","18c7d0b5":"def define_decriminator(in_shape=(28,28,1), n_classes=10):\n    in_label = Input(1,)\n    li = Embedding(n_classes, 50)(in_label)\n    li = Dense(in_shape[0] * in_shape[1])(li)\n    li = Reshape((in_shape[0], in_shape[1], 1))(li)\n    \n    in_image = Input(shape=in_shape)\n    \n    merge = Concatenate()([in_image, li])\n    \n    fe = Conv2D(64, (3,3), strides=(2, 2), padding='same')(merge)\n    fe = LeakyReLU(alpha=0.2)(fe)\n    fe = Conv2D(64, (3,3), strides=(2, 2), padding='same')(fe)\n    fe = LeakyReLU(alpha=0.2)(fe)\n    fe = Flatten()(fe)\n    fe = Dropout(0.4)(fe)\n    out_layer = Dense(1, activation='sigmoid')(fe)\n    \n    model = Model([in_image, in_label], out_layer)\n    opt = Adam(lr=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n    return model","440d448f":"d_model = define_decriminator()\nd_model.summary()","b86dffdd":"def define_generator(input_dim, n_classes=10):\n    label_input = Input(1,)\n    li = Embedding(n_classes, 50)(label_input)\n    li = Dense(7 * 7)(li)\n    li = Reshape((7, 7, 1))(li)\n    \n    noise_input = Input(shape=(input_dim,))\n    gen = Dense(128 * 7 * 7)(noise_input)\n    gen = LeakyReLU(alpha=0.2)(gen)\n    gen = Reshape((7, 7, 128))(gen)\n    \n    merge = Concatenate()([gen, li])\n    \n    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(merge)\n    gen = LeakyReLU(alpha=0.2)(gen)\n    \n    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n    gen = LeakyReLU(alpha=0.2)(gen)\n    \n    output_layer = Conv2D(1, (7,7), activation='sigmoid', padding='same')(gen)\n    \n    model = Model([noise_input, label_input], output_layer)\n    return model\n    ","068c3580":"g_model = define_generator(100, 10)\ng_model.summary()","4026df88":"def define_gan(generator, discriminator):\n    discriminator.trainable = False\n    gen_noise, gen_label = generator.input\n    gen_output = generator.output\n    \n    gan_outpout = discriminator([gen_output, gen_label])\n    \n    model = Model([gen_noise, gen_label], gan_outpout)\n    opt = Adam(lr=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt)\n    return model ","c316d4f6":"gan_model = define_gan(g_model, d_model)\ngan_model.summary()","abcd6f73":"def load_real_samples():\n    (trainX, trainY), (_, _) = load_data() # load mnist dataset\n    X = np.expand_dims(trainX, axis=-1) # add gray scale channel to image\n    X = X.astype('float32') # convert pixel from ints to floats\n    X = X \/ 255.0 # pixel to between\n    return X, trainY","911f4b04":"def generate_real_samples(dataset, n_samples):\n    images, labels = dataset\n    ix = np.random.randint(0, labels.shape[0], n_samples)\n    X = images[ix]\n    y_labels = np.expand_dims(labels[ix], axis=-1)\n    y_reals = np.ones((n_samples, 1)) # mark label to 'real' as 1 \n    return X, y_labels, y_reals","4175c695":"def generate_noise(noise_dim, labels):\n    n_samples = len(labels)\n    x_input = np.random.randn(noise_dim * n_samples) # generate random noise \n    x_input = x_input.reshape(n_samples, noise_dim)\n    return x_input","a832220b":"def generate_fake_samples(noise_dim, labels):\n  n_samples = len(labels)\n  x_input = generate_noise(noise_dim, labels) # generate by random noise\n  X = g_model.predict([x_input, labels]) # generate image from our model\n  y_fake = np.zeros((n_samples, 1)) # mark label to 'fake' as 0\n  return X, labels, y_fake","d69899ce":"fig = pyplot.figure(figsize=(12, 12))\nX, _, _ = generate_fake_samples(100, np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\nfor i in range(10):\n    pyplot.subplot(4, 4, 1 + i)\n    pyplot.axis('off')\n    pyplot.imshow(X[i, :, :, 0])\n    pyplot.draw()\n","50555865":"dataset = load_real_samples()\nn_epochs=500\nbatch_size=128\nhalf_batch = int(batch_size \/ 2)\nsteps = int(dataset[0].shape[0] \/ batch_size)\nnoise_dim = 100","3928ab26":"fig = pyplot.figure(figsize=(12, 12))\naxs = []\nfor i in range(10):\n    axs.append(pyplot.subplot(4, 4, 1 + i))\n    \nfor epoch in range(n_epochs):\n    for step in range(steps):\n        X_real, real_labels, y_real = generate_real_samples(dataset, half_batch)\n        X_fake, fake_labels, y_fake = generate_fake_samples(100, real_labels)\n        y = np.vstack((y_real, y_fake))\n        labels = np.vstack((real_labels, fake_labels))\n        X = np.vstack((X_real, X_fake))\n\n        d_loss, d_acurracy = d_model.train_on_batch([X, labels], y)\n\n        x_gan = generate_noise(noise_dim, labels)\n        y_gan = np.ones((batch_size, 1))\n        gan_model.train_on_batch([x_gan, labels], y_gan)\n\n    if epoch % 100 == 0: # evaluate every 100 epochs\n        fake_test, _, _ = generate_fake_samples(100, np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n        fig.suptitle('Result at epoch {}'.format(epoch), fontsize=16)\n        for i in range(10):\n            ax = axs[i]\n            ax.cla()\n            ax.axis('off')\n            ax.imshow(fake_test[i, :, :, 0])\n        fig.savefig(\"result_at_epoch_{}.png\".format(epoch))\n        display(fig)\n        clear_output(wait = True) ","525fcbe8":"fig = pyplot.figure(figsize=(12, 12))\nfake_result, _, _ = generate_fake_samples(100, np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\nfor i in range(10):\n    pyplot.subplot(4, 4, 1 + i)\n    pyplot.axis('off')\n    pyplot.imshow(fake_result[i, :, :, 0])\n    pyplot.draw()","5f6e700c":"Load sample data","c01b0ba5":"# Descriminator","b4754384":"# Import","f2249f78":"# Define cGan Model","11531ead":"# Generator","054098ee":"# See our result","2bc50b66":"# Training","0faafb5d":"Generate random sample data","277d32db":"We can see we just train our model only 500 epochs but we can generate better result and Normal Gan [here](https:\/\/www.kaggle.com\/uysimty\/get-start-with-gan)","e6666012":"Gerenrate fake sample ","433a76a2":"Assume that you already read [Get Start with GAN ](https:\/\/www.kaggle.com\/uysimty\/get-start-with-gan). It is an instruduction to GAN with generate random digit without condition"}}