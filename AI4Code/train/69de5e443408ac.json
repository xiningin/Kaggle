{"cell_type":{"47df4f0f":"code","8cfcd570":"code","11cb2c5f":"code","9ee15331":"code","2ba0e468":"code","4245bcf3":"code","a5b1e064":"code","035bcff2":"code","56c39ce9":"code","52ba29be":"code","b4a0de4a":"code","78e1ee9a":"code","f9393f4d":"code","e2b8e5f7":"code","393655d6":"code","c72a1fa8":"code","bf5e6e82":"code","607d638b":"code","b503e12a":"code","ef9c53c8":"code","1372674b":"code","f3584bfd":"code","818999c8":"code","858b7143":"code","11a840c0":"code","acd7a360":"code","41b0fa5c":"code","d0b01136":"code","a861acb1":"code","e4e81b7e":"code","9b68d6b2":"code","a30f331a":"code","0ce8a218":"code","9ccde627":"code","4c82b9cd":"code","5046c77f":"code","695f8075":"code","a8239c61":"code","b4e5da62":"code","dc187d0d":"code","1f69bd2b":"code","1269fc82":"code","31d3084c":"code","3e03d338":"code","9ca1b376":"code","3fd79cc1":"code","9ea3b288":"code","6293621c":"code","d61cb827":"code","42ebd02f":"code","df8bd666":"code","dbddcd84":"code","7223e880":"code","5407e46b":"code","24f0a9d2":"code","e577a030":"code","1d1f8c27":"code","d79fdbe7":"code","444e4d85":"code","cae23b3f":"code","af8e956d":"code","7ac70034":"code","8543675a":"code","e23d0048":"code","24a058c1":"code","bc1456d7":"code","8d62c34c":"code","d0c5ce5e":"code","e2eca7ca":"code","23804a70":"code","7a771f62":"code","6026d308":"code","7eb2cd18":"code","91690f36":"code","1cb9024a":"code","534e14dc":"code","d5ab8627":"code","dd5cdf53":"code","1dc489cf":"code","6bb68523":"code","79643455":"code","8137e8df":"code","5aaefde9":"code","e3e71cbb":"code","f31e5149":"code","f5301225":"code","ff8b1073":"code","afc2d831":"code","39a47ada":"code","49fe69ce":"code","4af24e0f":"code","e336007d":"code","ba56fb52":"code","271b76fb":"code","3ceeb58e":"code","0b86b3e4":"code","20105849":"code","4f334db0":"code","e2949ff0":"code","7d64f87a":"code","cf1027eb":"code","7c4333db":"code","6443f995":"code","7857fdf3":"code","d805f072":"code","58fdf0fd":"code","d50e7e7d":"code","572b01ff":"code","32af3f4f":"code","cf61da55":"code","dade6f3f":"code","a8508d62":"code","7eee8f56":"code","df3b8c91":"code","41e947b1":"code","01d565be":"code","a8aa195d":"code","f57a931f":"code","df705647":"code","6473c0fe":"code","e771e008":"code","d096487c":"code","924168be":"code","deb7a4dc":"code","b9b8b594":"code","b0305211":"code","bcacc802":"code","615d1d1e":"code","d064e074":"code","5bbbdca0":"code","d4a60975":"code","970bef01":"code","110e1369":"code","3c4f3fd9":"code","39682a82":"code","d389fbf9":"code","74b4be2c":"code","b8148fb5":"code","55b1843b":"code","3f87cf6b":"code","e8808a20":"code","ce6d5723":"code","560ac7d1":"code","3dd8481f":"code","6757d6fa":"code","5ac049c7":"code","63bd2418":"code","29ef4a30":"code","deea0541":"code","add2c38d":"code","41f4c163":"code","d46fa442":"code","ecc52633":"code","6cc24db2":"code","72516a00":"code","ebdd0824":"code","e448ebf8":"code","0dbca1d3":"code","b493ba87":"code","d1230de1":"code","e1685607":"code","6136c940":"code","628622fb":"code","f053c226":"code","a3469b44":"code","ed5b168c":"code","353660b7":"code","3cdd8d78":"code","a1f66818":"code","4634cbb7":"code","7db59998":"code","7df7494c":"code","bfc8c04e":"code","ec3be818":"code","109f72aa":"code","58194837":"code","83415708":"code","1aad9a31":"code","ca801d4c":"code","c57d48ec":"code","33fabc9b":"code","f910daa5":"code","5e8fa3be":"code","c9e1b5d6":"code","1ea90dbc":"code","c05c0c65":"code","61df63f2":"code","e46a71c8":"code","184d0575":"code","69fb1171":"code","05057518":"code","c357c080":"code","1ead68ca":"code","6d7431e4":"code","696bc36d":"code","dad032e8":"code","e2650d32":"code","96cfc026":"code","8f53df0b":"code","cce884d2":"code","e832e31c":"code","d7a36f53":"code","ec969f78":"code","792e8def":"code","f05d1b1c":"code","e9387bfe":"code","e65082df":"code","4282c942":"code","22937113":"code","33467396":"code","c2e8d0e0":"code","a2262b0c":"code","89489bc8":"code","440df6d8":"code","5e0ddf7e":"code","3f8bef51":"code","70163147":"code","f071c600":"code","65889e5e":"code","fd671304":"code","a46edc2e":"code","4226d436":"code","081cc061":"code","785e8f95":"code","9026d7ac":"code","b2735990":"code","d366b8d9":"code","41170cff":"code","56da2e18":"code","90d00904":"code","6379c03e":"code","dffd50ee":"code","74cd80ce":"code","ac97a149":"code","d1988d20":"code","f138bf38":"code","4cced1c2":"code","14b3d7f6":"code","985ebbe2":"code","df265690":"code","bf9900f4":"code","6b57da99":"code","b1a5d579":"code","29d86867":"code","3d11fdc9":"code","74f68acb":"code","f822ab16":"code","2c0b6534":"code","08f26e20":"code","1f3e8249":"code","d7026f26":"code","a70118f2":"code","bce5d3fa":"code","a6bafcbd":"code","bd14379b":"code","98735119":"code","82563c32":"code","b47158ba":"code","dc360b0f":"code","251d8560":"code","68d9b0ad":"code","00bbd2e7":"code","7a7b2dc4":"code","e1deaab3":"code","4d7fc691":"markdown","28fa877a":"markdown","7c36c8cf":"markdown","06eb1427":"markdown","66744203":"markdown","f06f2ac5":"markdown","9624aa34":"markdown","54081510":"markdown","9d734f64":"markdown","df616329":"markdown","b1fbb659":"markdown","d4111575":"markdown","4bc42e85":"markdown","709e0509":"markdown","9c2d347b":"markdown","096d90bc":"markdown","816bea71":"markdown","947bf6f1":"markdown","de8f0b4e":"markdown","f4f0ea4b":"markdown","e14e68cf":"markdown","6a5678b8":"markdown","03926363":"markdown","dc998bdf":"markdown","798b382a":"markdown","ada57c1c":"markdown","d03e7e43":"markdown","b0c2a8a7":"markdown","a09effdc":"markdown","6dc4a93a":"markdown","12eb1c68":"markdown","35811068":"markdown","06f2bab1":"markdown","1ee756f5":"markdown","d1995a36":"markdown","a7221128":"markdown","b247da33":"markdown","71630fe1":"markdown","ad675cc7":"markdown","22c4fd1f":"markdown","68294e3d":"markdown","357e48f3":"markdown","470958ef":"markdown","c47836ff":"markdown","d3005e18":"markdown","7d089bb9":"markdown","d6a3391d":"markdown","adefd69a":"markdown","1d9d611e":"markdown","f9dbfaa8":"markdown","d7b4cae7":"markdown","a81a2022":"markdown","a69e561f":"markdown","f97fda30":"markdown","70c173ec":"markdown","9d7a3f50":"markdown","0fe33439":"markdown","548ccbad":"markdown","897cfa31":"markdown","9cf076da":"markdown","836bc9e5":"markdown","237cb195":"markdown","c9209a8c":"markdown","6fb449c5":"markdown","9947e058":"markdown","5458ccc6":"markdown","f1fcc42c":"markdown","da780e93":"markdown","9cfd2728":"markdown","b8b02814":"markdown","500a603c":"markdown","60ff3d09":"markdown","98399698":"markdown","848cd381":"markdown","696d92b2":"markdown","9648f3a0":"markdown","d4e1331d":"markdown","323a6a76":"markdown","c192346a":"markdown","e5ed1a52":"markdown","c2569072":"markdown","3f3840e4":"markdown","c0095b36":"markdown","e7369e62":"markdown","ad9eaa46":"markdown","07e195c0":"markdown","7e4415ac":"markdown","b06782c2":"markdown","fef71a00":"markdown","7231f65b":"markdown","c4c2ee55":"markdown","305d1217":"markdown","3006fea7":"markdown","f3c9f488":"markdown","95e91903":"markdown","45e16b22":"markdown","b3144af9":"markdown","8e08d640":"markdown","42ca1469":"markdown"},"source":{"47df4f0f":"#!pip install feature_engine","8cfcd570":"import warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom category_encoders import *\nfrom feature_engine.encoding import CountFrequencyEncoder\nfrom matplotlib.lines import Line2D\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 15,15","11cb2c5f":"path = \"..\/input\/tabular-playground-series-feb-2021\/\"\ntrain = pd.read_csv(path + \"train.csv\", index_col=\"id\")\ntest = pd.read_csv(path + \"test.csv\", index_col=\"id\")\ntrain.head(5)","9ee15331":"# Check for duplicates:\n\nduplicates = train.duplicated()\nduplicates.sum()","2ba0e468":"numerical_columns = train[[\"cont0\", \"cont1\", \"cont2\", \"cont3\", \"cont4\", \"cont5\", \"cont6\", \"cont7\", \"cont8\", \"cont9\", \"cont10\", \"cont11\", \"cont12\"]]\nnumerical_columns.head(5)","4245bcf3":"numerical_columns.shape","a5b1e064":"numerical_columns.to_csv(\"numerical_columns.csv\")","035bcff2":"numerical_columns.hist(figsize=((20,20)), alpha=0.5, animated=True, edgecolor='blue', color='lightblue', grid=False);","56c39ce9":"numerical_columns.describe()","52ba29be":"numerical_columns.boxplot(showcaps=True, showfliers=True)\nplt.xticks(rotation=90);","b4a0de4a":"sns.violinplot(numerical_columns[\"cont0\"], color='lightblue', showcaps=True, showfliers=True)\nsns.stripplot(numerical_columns[\"cont0\"], color='red', alpha=0.01);","78e1ee9a":"# Find z-scores and put a threshold of 3 to determine which outliers\n# are too much and need to be cut:\nz=np.abs(stats.zscore(numerical_columns[\"cont0\"]))\nprint(z)\n\nprint(np.where(z > 3))","f9393f4d":"numerical_columns[\"cont0\"].iloc[[132579]]","e2b8e5f7":"#remove this outlier:\nnumerical_columns = numerical_columns.loc[numerical_columns[\"cont0\"] >= -0.093]","393655d6":"# check it is removed:\nnumerical_columns[\"cont0\"].sort_values(ascending=True)","c72a1fa8":"sns.violinplot(numerical_columns[\"cont2\"], color='lightblue', showcaps=True, showfliers=True)\nsns.stripplot(numerical_columns[\"cont2\"], color='red', alpha=0.01);","bf5e6e82":"# Find z-scores and put a threshold of 3 to determine which outliers\n# are too much and need to be cut:\nz=np.abs(stats.zscore(numerical_columns[\"cont2\"]))\nprint(z)\n\nprint(np.where(z > 3))","607d638b":"sns.violinplot(numerical_columns[\"cont6\"], color='lightblue', showcaps=True, showfliers=True)\nsns.stripplot(numerical_columns[\"cont6\"], color='red', alpha=0.01);","b503e12a":"# Find z-scores and put a threshold of 3 to determine which outliers\n# are too much and need to be cut:\nz=np.abs(stats.zscore(numerical_columns[\"cont6\"]))\nprint(z)\nprint(np.where(z > 3))","ef9c53c8":"# find where z is greater than three:\nx = z.tolist()\nx = sorted(x, reverse=True)\nprint(x[110:130])\nprint(\"Index of first value with z-score > 3: \", np.where(z == 3.0010249691534847))\nprint(\"Index of last value with z-score < 3: \", np.where(z == 2.999924948184652))","1372674b":"print(numerical_columns[\"cont6\"].iloc[[16410]])\nprint(numerical_columns[\"cont6\"].iloc[[254380]])","f3584bfd":"# remove the outliers with value greater than 1.055627:\nnumerical_columns = numerical_columns.loc[numerical_columns[\"cont6\"] <= 1.055627]","818999c8":"# check they are removed:\nnumerical_columns[\"cont6\"].sort_values(ascending=False).head(5)","858b7143":"sns.violinplot(numerical_columns[\"cont8\"], color='lightblue', showcaps=True, showfliers=True)\nsns.stripplot(numerical_columns[\"cont8\"], color='red', alpha=0.01);","11a840c0":"# Find z-scores and put a threshold of 3 to determine which outliers\n# are too much and need to be cut:\nz=np.abs(stats.zscore(numerical_columns[\"cont8\"]))\nprint(z)\nprint(np.where(z > 3))","acd7a360":"numerical_columns[\"target\"] = train[\"target\"]\ncorr = numerical_columns.corr()\nsns.heatmap(corr, annot=True);","41b0fa5c":"print(\"Numerical columns most correlated with target column:\\n\", abs(corr[\"target\"]).sort_values(ascending=False))","d0b01136":"numerical_columns.head(5)","a861acb1":"numerical_columns.to_csv(\"numerical_columns_NO.csv\")","e4e81b7e":"categorical_columns = train[[\"cat0\", \"cat1\", \"cat2\", \"cat3\", \"cat4\", \"cat5\", \"cat6\", \"cat7\", \"cat8\", \"cat9\"]]\ncategorical_columns.head(5)","9b68d6b2":"categorical_columns.describe(include='all')","a30f331a":"num_rows, num_cols = 3,4\nf, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(12, 12))\nfor index, column in enumerate(categorical_columns.columns):\n    i,j = (index \/\/ num_cols, index % num_cols)\n    sns.histplot(x=column, data=categorical_columns, ax=axes[i,j]);","0ce8a218":"target = train[\"target\"]\ntarget.to_csv(\"target.csv\")","9ccde627":"ax = sns.kdeplot(target, shade=True, color='red', edgecolor='black', alpha=0.5, zorder=3)\nplt.title('Target Distribution', fontsize=20);","4c82b9cd":"target.describe()","5046c77f":"plt.boxplot(target, showcaps=True, showfliers=True)\nplt.xticks(rotation=90);","695f8075":"# Find z-scores and put a threshold of 3 to determine which outliers\n# are too much and need to be cut:\nz=np.abs(stats.zscore(target))\nprint(z)\n\nprint(np.where(z > 3))","a8239c61":"# find where z is greater than three:\nx = z.tolist()\nx = sorted(x, reverse=True)\nprint(x[400:450])\nprint(\"Index of first value with z-score > 3: \", np.where(z == 3.0000214311993463))\nprint(\"Index of first value with z-score < 3: \", np.where(z == 2.9997811336456435))","b4e5da62":"print(target.iloc[[3882]])\nprint(target.iloc[[9720]])","dc187d0d":"# remove the outliers with value less than 4.794575:\ntarget = target.loc[target >= 4.794575]","1f69bd2b":"# check they are removed:\nplt.boxplot(target, showcaps=True, showfliers=True)\nplt.xticks(rotation=90);","1269fc82":"target.to_csv(\"target_NO.csv\")","31d3084c":"test.head(5)","3e03d338":"# Check for duplicates:\n\nduplicates = test.duplicated()\nduplicates.sum()","9ca1b376":"numerical_test = test[[\"cont0\", \"cont1\", \"cont2\", \"cont3\", \"cont4\", \"cont5\", \"cont6\", \"cont7\", \"cont8\", \"cont9\", \"cont10\", \"cont11\", \"cont12\"]]\nnumerical_test.head(5)","3fd79cc1":"categorical_test = test[[\"cat0\", \"cat1\", \"cat2\", \"cat3\", \"cat4\", \"cat5\", \"cat6\", \"cat7\", \"cat8\", \"cat9\"]]\ncategorical_test.head(5)","9ea3b288":"categorical_test.describe(include='all')","6293621c":"categorical_columns.head(5)","d61cb827":"enc = OrdinalEncoder()\nX = categorical_columns\nenc.fit(X)\nordinal_categorical_columns = enc.transform(categorical_columns)\nordinal_categorical_columns = pd.DataFrame(ordinal_categorical_columns)\nordinal_categorical_columns.head(5)","42ebd02f":"ordinal_categorical_columns.shape","df8bd666":"ordinal_categorical_columns.to_csv(\"ordinal_categorical_columns.csv\")","dbddcd84":"enc = OneHotEncoder(handle_unknown='ignore')\nenc.fit(categorical_columns)\nonehot_categorical_columns = enc.transform(categorical_columns)\nonehot_categorical_columns.head(5)","7223e880":"onehot_categorical_columns.shape","5407e46b":"onehot_categorical_columns.to_csv(\"onehot_categorical_columns.csv\")","24f0a9d2":"enc = BinaryEncoder().fit(categorical_columns)\nbinary_categorical_columns = enc.transform(categorical_columns)\nbinary_categorical_columns.head(5)","e577a030":"binary_categorical_columns.shape","1d1f8c27":"binary_categorical_columns.to_csv(\"binary_categorical_columns.csv\")","d79fdbe7":"encoder = CountFrequencyEncoder(encoding_method='frequency')\nencoder.fit(categorical_columns)\nfreq_categorical_columns = encoder.transform(categorical_columns)\nfreq_categorical_columns.head(5)","444e4d85":"freq_categorical_columns.shape","cae23b3f":"freq_categorical_columns.to_csv(\"freq_categorical_columns.csv\")","af8e956d":"numerical_columns = pd.read_csv(\"numerical_columns.csv\")\nnumerical_columns.head(5)","7ac70034":"log_numerical_columns = pd.DataFrame()\nlog_numerical_columns[\"id\"] = numerical_columns[\"id\"]\n\nlog_numerical_columns['cont0_log'] = np.log((1+ numerical_columns['cont0']))\ncont0_log_mean = np.round(np.mean(log_numerical_columns['cont0_log']), 2)\n\nlog_numerical_columns['cont1_log'] = np.log((1+ numerical_columns['cont1']))\ncont1_log_mean = np.round(np.mean(log_numerical_columns['cont1_log']), 2)\n\nlog_numerical_columns['cont2_log'] = np.log((1+ numerical_columns['cont2']))\ncont2_log_mean = np.round(np.mean(log_numerical_columns['cont2_log']), 2)\n\nlog_numerical_columns['cont3_log'] = np.log((1+ numerical_columns['cont3']))\ncont3_log_mean = np.round(np.mean(log_numerical_columns['cont3_log']), 2)\n\nlog_numerical_columns['cont4_log'] = np.log((1+ numerical_columns['cont4']))\ncont4_log_mean = np.round(np.mean(log_numerical_columns['cont4_log']), 2)\n\nlog_numerical_columns['cont5_log'] = np.log((1+ numerical_columns['cont5']))\ncont5_log_mean = np.round(np.mean(log_numerical_columns['cont5_log']), 2)\n\nlog_numerical_columns['cont6_log'] = np.log((1+ numerical_columns['cont6']))\ncont6_log_mean = np.round(np.mean(log_numerical_columns['cont6_log']), 2)\n\nlog_numerical_columns['cont7_log'] = np.log((1+ numerical_columns['cont7']))\ncont7_log_mean = np.round(np.mean(log_numerical_columns['cont7_log']), 2)\n\nlog_numerical_columns['cont8_log'] = np.log((1+ numerical_columns['cont8']))\ncont8_log_mean = np.round(np.mean(log_numerical_columns['cont8_log']), 2)\n\nlog_numerical_columns['cont9_log'] = np.log((1+ numerical_columns['cont9']))\ncont9_log_mean = np.round(np.mean(log_numerical_columns['cont9_log']), 2)\n\nlog_numerical_columns['cont10_log'] = np.log((1+ numerical_columns['cont10']))\ncont10_log_mean = np.round(np.mean(log_numerical_columns['cont10_log']), 2)\n\nlog_numerical_columns['cont11_log'] = np.log((1+ numerical_columns['cont11']))\ncont11_log_mean = np.round(np.mean(log_numerical_columns['cont11_log']), 2)\n\nlog_numerical_columns['cont12_log'] = np.log((1+ numerical_columns['cont12']))\ncont12_log_mean = np.round(np.mean(log_numerical_columns['cont12_log']), 2)","8543675a":"log_numerical_columns.head(5)","e23d0048":"log_numerical_columns.shape","24a058c1":"log_numerical_columns.to_csv(\"log_numerical_columns.csv\")","bc1456d7":"plt.hist(numerical_columns[\"cont0\"], color='green', alpha=0.5, edgecolor='black')\nplt.hist(log_numerical_columns['cont0_log'], bins=30, color='lightblue', edgecolor='black')\nplt.axvline(cont0_log_mean, color='red')\nplt.title('cont0 histogram before and after Log Transform', fontsize=20)\nplt.xlabel('cont0 (log scale)', fontsize=18)\nplt.ylabel('Frequency', fontsize=18)\nplt.xticks(fontsize=16)\nplt.yticks(fontsize=16)\n# custom legend\ncustom_lines = [Line2D([0], [0], color='blue', lw=4),\n                Line2D([0], [0], color='lightblue', lw=4),\n                Line2D([0], [0], color='red', lw=4)]\n\nplt.legend(custom_lines, ['cont0', 'cont0_log', 'cont0_log_mean']);","8d62c34c":"plt.hist(numerical_columns[\"cont1\"], color='green', alpha=0.5, edgecolor='black')\nplt.hist(log_numerical_columns['cont1_log'], bins=30, color='lightblue', edgecolor='black')\nplt.axvline(cont1_log_mean, color='red')\nplt.title('cont1 histogram before and after Log Transform', fontsize=20)\nplt.xlabel('cont1 (log scale)', fontsize=18)\nplt.ylabel('Frequency', fontsize=18)\nplt.xticks(fontsize=16)\nplt.yticks(fontsize=16)\n# custom legend\ncustom_lines = [Line2D([0], [0], color='blue', lw=4),\n                Line2D([0], [0], color='lightblue', lw=4),\n                Line2D([0], [0], color='red', lw=4)]\n\nplt.legend(custom_lines, ['cont1', 'cont1_log', 'cont1_log_mean']);","d0c5ce5e":"corr_test = log_numerical_columns.merge(target, on=\"id\")\ncorr_test = corr_test.iloc[::, 1:]\ncorr = corr_test.corr()\nsns.heatmap(corr, annot=True);","e2eca7ca":"print(\"Numerical columns most correlated with target column:\\n\", abs(corr[\"target\"]).sort_values(ascending=False))","23804a70":"numerical_columns_NO = pd.read_csv(\"numerical_columns_NO.csv\")\nnumerical_columns_NO.head(5)","7a771f62":"log_numerical_columns = pd.DataFrame()\nlog_numerical_columns[\"id\"] = numerical_columns_NO[\"id\"]\n\nlog_numerical_columns['cont0_log'] = np.log((1+ numerical_columns_NO['cont0']))\ncont0_log_mean = np.round(np.mean(log_numerical_columns['cont0_log']), 2)\n\nlog_numerical_columns['cont1_log'] = np.log((1+ numerical_columns_NO['cont1']))\ncont1_log_mean = np.round(np.mean(log_numerical_columns['cont1_log']), 2)\n\nlog_numerical_columns['cont2_log'] = np.log((1+ numerical_columns_NO['cont2']))\ncont2_log_mean = np.round(np.mean(log_numerical_columns['cont2_log']), 2)\n\nlog_numerical_columns['cont3_log'] = np.log((1+ numerical_columns_NO['cont3']))\ncont3_log_mean = np.round(np.mean(log_numerical_columns['cont3_log']), 2)\n\nlog_numerical_columns['cont4_log'] = np.log((1+ numerical_columns_NO['cont4']))\ncont4_log_mean = np.round(np.mean(log_numerical_columns['cont4_log']), 2)\n\nlog_numerical_columns['cont5_log'] = np.log((1+ numerical_columns_NO['cont5']))\ncont5_log_mean = np.round(np.mean(log_numerical_columns['cont5_log']), 2)\n\nlog_numerical_columns['cont6_log'] = np.log((1+ numerical_columns_NO['cont6']))\ncont6_log_mean = np.round(np.mean(log_numerical_columns['cont6_log']), 2)\n\nlog_numerical_columns['cont7_log'] = np.log((1+ numerical_columns_NO['cont7']))\ncont7_log_mean = np.round(np.mean(log_numerical_columns['cont7_log']), 2)\n\nlog_numerical_columns['cont8_log'] = np.log((1+ numerical_columns_NO['cont8']))\ncont8_log_mean = np.round(np.mean(log_numerical_columns['cont8_log']), 2)\n\nlog_numerical_columns['cont9_log'] = np.log((1+ numerical_columns_NO['cont9']))\ncont9_log_mean = np.round(np.mean(log_numerical_columns['cont9_log']), 2)\n\nlog_numerical_columns['cont10_log'] = np.log((1+ numerical_columns_NO['cont10']))\ncont10_log_mean = np.round(np.mean(log_numerical_columns['cont10_log']), 2)\n\nlog_numerical_columns['cont11_log'] = np.log((1+ numerical_columns_NO['cont11']))\ncont11_log_mean = np.round(np.mean(log_numerical_columns['cont11_log']), 2)\n\nlog_numerical_columns['cont12_log'] = np.log((1+ numerical_columns_NO['cont12']))\ncont12_log_mean = np.round(np.mean(log_numerical_columns['cont12_log']), 2)","6026d308":"log_numerical_columns.head(5)","7eb2cd18":"log_numerical_columns.shape","91690f36":"log_numerical_columns.to_csv(\"log_numerical_columns_NO.csv\")","1cb9024a":"plt.hist(numerical_columns[\"cont0\"], color='green', alpha=0.5, edgecolor='black')\nplt.hist(log_numerical_columns['cont0_log'], bins=30, color='lightblue', edgecolor='black')\nplt.axvline(cont0_log_mean, color='red')\nplt.title('cont0 histogram before and after Log Transform', fontsize=20)\nplt.xlabel('cont0 (log scale)', fontsize=18)\nplt.ylabel('Frequency', fontsize=18)\nplt.xticks(fontsize=16)\nplt.yticks(fontsize=16)\n# custom legend\ncustom_lines = [Line2D([0], [0], color='blue', lw=4),\n                Line2D([0], [0], color='lightblue', lw=4),\n                Line2D([0], [0], color='red', lw=4)]\n\nplt.legend(custom_lines, ['cont0', 'cont0_log', 'cont0_log_mean']);","534e14dc":"corr_test = log_numerical_columns.merge(target, on=\"id\")\ncorr_test = corr_test.iloc[::, 1:]\ncorr = corr_test.corr()\nsns.heatmap(corr, annot=True);","d5ab8627":"print(\"Numerical columns most correlated with target column:\\n\", abs(corr[\"target\"]).sort_values(ascending=False))","dd5cdf53":"test.head(5)","1dc489cf":"test.reset_index(level=0, inplace=True)\ntest.head(5)","6bb68523":"numerical_test = test[[\"id\", \"cont0\", \"cont1\", \"cont2\", \"cont3\", \"cont4\", \"cont5\", \"cont6\", \"cont7\", \"cont8\", \"cont9\", \"cont10\", \"cont11\", \"cont12\"]]\nnumerical_test.head(5)","79643455":"numerical_test.shape","8137e8df":"numerical_test.to_csv(\"numerical_test.csv\")","5aaefde9":"log_numerical_test = pd.DataFrame()\nlog_numerical_test[\"id\"] = numerical_test[\"id\"]\n\nlog_numerical_test['cont0_log'] = np.log((1+ numerical_test['cont0']))\ncont0_log_mean = np.round(np.mean(log_numerical_test['cont0_log']), 2)\n\nlog_numerical_test['cont1_log'] = np.log((1+ numerical_test['cont1']))\ncont1_log_mean = np.round(np.mean(log_numerical_test['cont1_log']), 2)\n\nlog_numerical_test['cont2_log'] = np.log((1+ numerical_test['cont2']))\ncont2_log_mean = np.round(np.mean(log_numerical_test['cont2_log']), 2)\n\nlog_numerical_test['cont3_log'] = np.log((1+ numerical_test['cont3']))\ncont3_log_mean = np.round(np.mean(log_numerical_test['cont3_log']), 2)\n\nlog_numerical_test['cont4_log'] = np.log((1+ numerical_test['cont4']))\ncont4_log_mean = np.round(np.mean(log_numerical_test['cont4_log']), 2)\n\nlog_numerical_test['cont5_log'] = np.log((1+ numerical_test['cont5']))\ncont5_log_mean = np.round(np.mean(log_numerical_test['cont5_log']), 2)\n\nlog_numerical_test['cont6_log'] = np.log((1+ numerical_test['cont6']))\ncont6_log_mean = np.round(np.mean(log_numerical_test['cont6_log']), 2)\n\nlog_numerical_test['cont7_log'] = np.log((1+ numerical_test['cont7']))\ncont7_log_mean = np.round(np.mean(log_numerical_test['cont7_log']), 2)\n\nlog_numerical_test['cont8_log'] = np.log((1+ numerical_test['cont8']))\ncont8_log_mean = np.round(np.mean(log_numerical_test['cont8_log']), 2)\n\nlog_numerical_test['cont9_log'] = np.log((1+ numerical_test['cont9']))\ncont9_log_mean = np.round(np.mean(log_numerical_test['cont9_log']), 2)\n\nlog_numerical_test['cont10_log'] = np.log((1+ numerical_test['cont10']))\ncont10_log_mean = np.round(np.mean(log_numerical_test['cont10_log']), 2)\n\nlog_numerical_test['cont11_log'] = np.log((1+ numerical_test['cont11']))\ncont11_log_mean = np.round(np.mean(log_numerical_test['cont11_log']), 2)\n\nlog_numerical_test['cont12_log'] = np.log((1+ numerical_test['cont12']))\ncont12_log_mean = np.round(np.mean(log_numerical_test['cont12_log']), 2)","e3e71cbb":"log_numerical_test.head(5)","f31e5149":"log_numerical_test.to_csv(\"log_numerical_test.csv\")","f5301225":"categorical_test = test[[\"id\", \"cat0\", \"cat1\", \"cat2\", \"cat3\", \"cat4\", \"cat5\", \"cat6\", \"cat7\", \"cat8\", \"cat9\"]]\ncategorical_test.head(5)","ff8b1073":"categorical_test.shape","afc2d831":"enc = OrdinalEncoder()\nX = categorical_test\nenc.fit(X)\nordinal_categorical_test = enc.transform(X)\nordinal_categorical_test = pd.DataFrame(ordinal_categorical_test)\nordinal_categorical_test.head(5)","39a47ada":"ordinal_categorical_test.to_csv(\"ordinal_categorical_test.csv\")","49fe69ce":"enc = OneHotEncoder(handle_unknown='ignore')\nenc.fit(categorical_test)\nonehot_categorical_test = enc.transform(categorical_test)\nonehot_categorical_test.head(5)","4af24e0f":"onehot_categorical_test.to_csv(\"onehot_categorical_test.csv\")","e336007d":"enc = BinaryEncoder().fit(categorical_test)\nbinary_categorical_test = enc.transform(categorical_test)\nbinary_categorical_test.head(5)","ba56fb52":"binary_categorical_test.to_csv(\"binary_categorical_test.csv\")","271b76fb":"encoder = CountFrequencyEncoder(encoding_method='frequency')\nencoder.fit(categorical_test)\nfreq_categorical_test = encoder.transform(categorical_test)\nfreq_categorical_test.head(5)","3ceeb58e":"freq_categorical_test.to_csv(\"freq_categorical_test.csv\")","0b86b3e4":"target = pd.read_csv(\"target.csv\")\ntarget.shape","20105849":"target.head(5)","4f334db0":"binary_categorical_columns = pd.read_csv(\"binary_categorical_columns.csv\")\nnumerical_columns = pd.read_csv(\"numerical_columns.csv\")\nbinary_num = binary_categorical_columns.merge(numerical_columns, on='id')\nbinary_num = binary_num.merge(target, on='id')\nbinary_num.to_csv(\"binary_num.csv\")","e2949ff0":"log_numerical_columns = pd.read_csv(\"log_numerical_columns.csv\")\nbinary_log = binary_categorical_columns.merge(log_numerical_columns, on='id')\nbinary_log = binary_log.merge(target, on='id')\nbinary_log.to_csv(\"binary_log.csv\")","7d64f87a":"numerical_columns_NO = pd.read_csv(\"numerical_columns_NO.csv\")\nbinary_num_NO = binary_categorical_columns.merge(numerical_columns_NO, on='id')\nbinary_num_NO = binary_num_NO.merge(target, on='id')\nbinary_num_NO.to_csv(\"binary_num_NO.csv\")","cf1027eb":"log_numerical_columns_NO = pd.read_csv(\"log_numerical_columns_NO.csv\")\nbinary_log_NO = binary_categorical_columns.merge(log_numerical_columns_NO, on='id')\nbinary_log_NO = binary_log_NO.merge(target, on='id')\nbinary_log_NO.to_csv(\"binary_log_NO.csv\")","7c4333db":"target_NO = pd.read_csv(\"target_NO.csv\")\ntarget_NO.shape","6443f995":"numerical_columns = pd.read_csv(\"numerical_columns.csv\")\nbinary_num_TNO = binary_categorical_columns.merge(numerical_columns, on='id')\nbinary_num_TNO = binary_num_TNO.merge(target_NO, on='id')\nbinary_num_TNO.to_csv(\"binary_num_TNO.csv\")","7857fdf3":"log_numerical_columns = pd.read_csv(\"log_numerical_columns.csv\")\nbinary_log_TNO = binary_categorical_columns.merge(log_numerical_columns, on='id')\nbinary_log_TNO = binary_log_TNO.merge(target_NO, on='id')\nbinary_log_TNO.to_csv(\"binary_log_TNO.csv\")","d805f072":"numerical_columns_NO = pd.read_csv(\"numerical_columns_NO.csv\")\nbinary_num_NO_TNO = binary_categorical_columns.merge(numerical_columns_NO, on='id')\nbinary_num_NO_TNO = binary_num_NO_TNO.merge(target_NO, on='id')\nbinary_num_NO_TNO.to_csv(\"binary_num_NO_TNO.csv\")","58fdf0fd":"log_numerical_columns_NO = pd.read_csv(\"log_numerical_columns_NO.csv\")\nbinary_log_NO_TNO = binary_categorical_columns.merge(log_numerical_columns_NO, on='id')\nbinary_log_NO_TNO = binary_log_NO_TNO.merge(target_NO, on='id')\nbinary_log_NO_TNO.to_csv(\"binary_log_NO_TNO.csv\")","d50e7e7d":"ordinal_categorical_columns = pd.read_csv(\"ordinal_categorical_columns.csv\")\nnumerical_columns = pd.read_csv(\"numerical_columns.csv\")\nordinal_num = ordinal_categorical_columns.merge(numerical_columns, on='id')\nordinal_num = ordinal_num.merge(target, on='id')\nordinal_num.to_csv(\"ordinal_num.csv\")","572b01ff":"log_numerical_columns = pd.read_csv(\"log_numerical_columns.csv\")\nordinal_log = ordinal_categorical_columns.merge(log_numerical_columns, on='id')\nordinal_log = ordinal_log.merge(target, on='id')\nordinal_log.to_csv(\"ordinal_log.csv\")","32af3f4f":"numerical_columns_NO = pd.read_csv(\"numerical_columns_NO.csv\")\nordinal_num_NO = ordinal_categorical_columns.merge(numerical_columns_NO, on='id')\nordinal_num_NO = ordinal_num_NO.merge(target, on='id')\nordinal_num_NO.to_csv(\"ordinal_num_NO.csv\")","cf61da55":"log_numerical_columns_NO = pd.read_csv(\"log_numerical_columns_NO.csv\")\nordinal_log_NO = ordinal_categorical_columns.merge(log_numerical_columns_NO, on='id')\nordinal_log_NO = ordinal_log_NO.merge(target, on='id')\nordinal_log_NO.to_csv(\"ordinal_log_NO.csv\")","dade6f3f":"numerical_columns = pd.read_csv(\"numerical_columns.csv\")\nordinal_num_TNO = ordinal_categorical_columns.merge(numerical_columns, on='id')\nordinal_num_TNO = ordinal_num_TNO.merge(target_NO, on='id')\nordinal_num_TNO.to_csv(\"ordinal_log_TNO.csv\")","a8508d62":"log_numerical_columns = pd.read_csv(\"log_numerical_columns.csv\")\nordinal_log_TNO = ordinal_categorical_columns.merge(log_numerical_columns, on='id')\nordinal_log_TNO = ordinal_log_TNO.merge(target_NO, on='id')\nordinal_log_TNO.to_csv(\"ordinal_log_TNO.csv\")","7eee8f56":"numerical_columns_NO = pd.read_csv(\"numerical_columns_NO.csv\")\nordinal_num_NO_TNO = ordinal_categorical_columns.merge(numerical_columns_NO, on='id')\nordinal_num_NO_TNO = ordinal_num_NO_TNO.merge(target_NO, on='id')\nordinal_num_NO_TNO.to_csv(\"ordinal_num_NO_TNO.csv\")","df3b8c91":"log_numerical_columns_NO = pd.read_csv(\"log_numerical_columns_NO.csv\")\nordinal_log_NO_TNO = ordinal_categorical_columns.merge(log_numerical_columns_NO, on='id')\nordinal_log_NO_TNO = ordinal_log_NO_TNO.merge(target_NO, on='id')\nordinal_log_NO_TNO.to_csv(\"ordinal_log_NO_TNO.csv\")","41e947b1":"freq_categorical_columns = pd.read_csv(\"freq_categorical_columns.csv\")\nnumerical_columns = pd.read_csv(\"numerical_columns.csv\")\nfreq_num = freq_categorical_columns.merge(numerical_columns, on='id')\nfreq_num = freq_num.merge(target, on='id')\nfreq_num.to_csv(\"freq_num.csv\")","01d565be":"log_numerical_columns = pd.read_csv(\"log_numerical_columns.csv\")\nfreq_log = freq_categorical_columns.merge(log_numerical_columns, on='id')\nfreq_log = freq_log.merge(target, on='id')\nfreq_log.to_csv(\"freq_log.csv\")","a8aa195d":"numerical_columns_NO = pd.read_csv(\"numerical_columns_NO.csv\")\nfreq_num_NO = freq_categorical_columns.merge(numerical_columns_NO, on='id')\nfreq_num_NO = freq_num_NO.merge(target, on='id')\nfreq_num_NO.to_csv(\"freq_num_NO.csv\")","f57a931f":"log_numerical_columns_NO = pd.read_csv(\"log_numerical_columns_NO.csv\")\nfreq_log_NO = freq_categorical_columns.merge(log_numerical_columns_NO, on='id')\nfreq_log_NO = freq_log_NO.merge(target, on='id')\nfreq_log_NO.to_csv(\"freq_log_NO.csv\")","df705647":"numerical_columns = pd.read_csv(\"numerical_columns.csv\")\nfreq_num_TNO = freq_categorical_columns.merge(numerical_columns, on='id')\nfreq_num_TNO = freq_num_TNO.merge(target_NO, on='id')\nfreq_num_TNO.to_csv(\"freq_log_TNO.csv\")","6473c0fe":"log_numerical_columns = pd.read_csv(\"log_numerical_columns.csv\")\nfreq_log_TNO = freq_categorical_columns.merge(log_numerical_columns, on='id')\nfreq_log_TNO = freq_log_TNO.merge(target_NO, on='id')\nfreq_log_TNO.to_csv(\"freq_log_TNO.csv\")","e771e008":"numerical_columns_NO = pd.read_csv(\"numerical_columns_NO.csv\")\nfreq_num_NO_TNO = freq_categorical_columns.merge(numerical_columns_NO, on='id')\nfreq_num_NO_TNO = freq_num_NO_TNO.merge(target_NO, on='id')\nfreq_num_NO_TNO.to_csv(\"freq_num_NO_TNO.csv\")","d096487c":"log_numerical_columns_NO = pd.read_csv(\"log_numerical_columns_NO.csv\")\nfreq_log_NO_TNO = freq_categorical_columns.merge(log_numerical_columns_NO, on='id')\nfreq_log_NO_TNO = freq_log_NO_TNO.merge(target_NO, on='id')\nfreq_log_NO_TNO.to_csv(\"freq_log_NO_TNO.csv\")","924168be":"binary_categorical_test = pd.read_csv(\"binary_categorical_test.csv\")\nnumerical_test = pd.read_csv(\"numerical_test.csv\")\nbinary_num_test = binary_categorical_test.merge(numerical_test, on='id')\nbinary_num_test.to_csv(\"binary_num_test.csv\")","deb7a4dc":"log_numerical_test = pd.read_csv(\"log_numerical_test.csv\")\nbinary_log_test = binary_categorical_test.merge(log_numerical_test, on='id')\nbinary_log_test.to_csv(\"binary_log_test.csv\")","b9b8b594":"ordinal_categorical_test = pd.read_csv(\"ordinal_categorical_test.csv\")\nnumerical_test = pd.read_csv(\"numerical_test.csv\")\nordinal_num_test = ordinal_categorical_test.merge(numerical_test, on='id')\nordinal_num_test.to_csv(\"ordinal_num_test.csv\")","b0305211":"log_numerical_test = pd.read_csv(\"log_numerical_test.csv\")\nordinal_log_test = ordinal_categorical_test.merge(log_numerical_test, on='id')\nordinal_log_test.to_csv(\"ordinal_log_test.csv\")","bcacc802":"freq_categorical_test = pd.read_csv(\"freq_categorical_test.csv\")\nnumerical_test = pd.read_csv(\"numerical_test.csv\")\nfreq_num_test = freq_categorical_test.merge(numerical_test, on='id')\nfreq_num_test.to_csv(\"freq_num_test.csv\")","615d1d1e":"log_numerical_test = pd.read_csv(\"log_numerical_test.csv\")\nfreq_log_test = freq_categorical_test.merge(log_numerical_test, on='id')\nfreq_log_test.to_csv(\"freq_log_test.csv\")","d064e074":"from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression","5bbbdca0":"binary_log = pd.read_csv(\"binary_log.csv\", index_col=\"Unnamed: 0\")\ntrain_id = binary_log[[\"id\", \"target\"]]\nbinary_log = binary_log.drop([\"Unnamed: 0.1\", \"id\"], axis=1)\nbinary_log_test = pd.read_csv(\"binary_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(binary_log_test[\"id\"])\nbinary_log_test = binary_log_test.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","d4a60975":"feature_train = binary_log.select_dtypes(include=['int64']).columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(binary_log[feature_train], binary_log['target'])\nX_cat_train = pd.DataFrame(X_cat_train)","970bef01":"feature_test = binary_log_test.select_dtypes(include=['int64']).columns\nX_cat_test = selector.transform(binary_log_test[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\nX_cat_test","110e1369":"feature_train = binary_log.select_dtypes(include=['float64']).columns.drop(\"target\")\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(binary_log[feature_train], binary_log['target'])\nX_num_train = pd.DataFrame(X_num_train)\nX_num_train","3c4f3fd9":"feature_test = binary_log_test.select_dtypes(include=['float64']).columns\nX_num_test = selector.transform(binary_log_test[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\nX_num_test","39682a82":"# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=binary_log.index, \n                                 columns=feature_train)\nselected_features_train","d389fbf9":"# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=binary_log_test.index, \n                                 columns=feature_test)\nselected_features_test","74b4be2c":"# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n\n# Get the valid dataset with the selected features.\nUNI_train_binary_log = binary_log[selected_columns_train]\nUNI_train_binary_log","b8148fb5":"# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n\n# Get the valid dataset with the selected features.\nUNI_test_binary_log = binary_log_test[selected_columns_test]\nUNI_test_binary_log","55b1843b":"UNI_train_binary_log = UNI_train_binary_log.merge(X_cat_train, left_index=True, right_index=True)\nUNI_train_binary_log","3f87cf6b":"UNI_test_binary_log = UNI_test_binary_log.merge(X_cat_test, left_index=True, right_index=True)\nUNI_test_binary_log","e8808a20":"UNI_train_binary_log = pd.merge(UNI_train_binary_log, train_id, left_index=True, right_index=True)\nUNI_train_binary_log","ce6d5723":"UNI_test_binary_log = pd.merge(UNI_test_binary_log, test_id, left_index=True, right_index=True)\nUNI_test_binary_log","560ac7d1":"UNI_train_binary_log.to_csv(\"UNI_train_binary_log.csv\")\nUNI_test_binary_log.to_csv(\"UNI_test_binary_log.csv\")","3dd8481f":"binary_log_NO = pd.read_csv(\"binary_log_NO.csv\", index_col=\"Unnamed: 0\")\nbinary_log_NO.rename(columns = {'target_y':'target'}, inplace = True)\ntrain_id = binary_log_NO[[\"id\", \"target\"]]\nbinary_log_NO = binary_log_NO.drop([\"Unnamed: 0.1\", \"id\"], axis=1)\nbinary_log_test_NO = pd.read_csv(\"binary_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(binary_log_test_NO[\"id\"])\nbinary_log_test_NO = binary_log_test_NO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","6757d6fa":"feature_train = binary_log_NO.select_dtypes(include=['int64']).columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(binary_log_NO[feature_train], binary_log_NO['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = binary_log_test_NO.select_dtypes(include=['int64']).columns\nX_cat_test = selector.transform(binary_log_test_NO[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = binary_log_NO.select_dtypes(include=['float64']).columns.drop(\"target\")\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(binary_log_NO[feature_train], binary_log_NO['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = binary_log_test_NO.select_dtypes(include=['float64']).columns\nX_num_test = selector.transform(binary_log_test_NO[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=binary_log_NO.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=binary_log_test_NO.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_train_binary_log_NO = binary_log_NO[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_binary_log_NO = binary_log_test_NO[selected_columns_test]\n\n# merges\nUNI_train_binary_log_NO = UNI_train_binary_log_NO.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_binary_log_NO = UNI_test_binary_log_NO.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_binary_log_NO = pd.merge(UNI_train_binary_log_NO, train_id, left_index=True, right_index=True)\nUNI_test_binary_log_NO = pd.merge(UNI_test_binary_log_NO, test_id, left_index=True, right_index=True)","5ac049c7":"UNI_train_binary_log_NO.to_csv(\"UNI_train_binary_log_NO.csv\")\nUNI_test_binary_log_NO.to_csv(\"UNI_test_binary_log_NO.csv\")","63bd2418":"binary_log_NO_TNO = pd.read_csv(\"binary_log_NO_TNO.csv\", index_col=\"Unnamed: 0\")\ntrain_id = binary_log_NO_TNO[[\"id\", \"target\"]]\nbinary_log_NO_TNO = binary_log_NO_TNO.drop([\"Unnamed: 0.1\", \"id\"], axis=1)\nbinary_log_test_NO_TNO = pd.read_csv(\"binary_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(binary_log_test_NO_TNO[\"id\"])\nbinary_log_test_NO_TNO = binary_log_test_NO_TNO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","29ef4a30":"feature_train = binary_log_NO_TNO.select_dtypes(include=['int64']).columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(binary_log_NO_TNO[feature_train], binary_log_NO_TNO['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = binary_log_test_NO_TNO.select_dtypes(include=['int64']).columns\nX_cat_test = selector.transform(binary_log_test_NO_TNO[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = binary_log_NO_TNO.select_dtypes(include=['float64']).columns.drop(\"target\")\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(binary_log_NO_TNO[feature_train], binary_log_NO_TNO['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = binary_log_test_NO_TNO.select_dtypes(include=['float64']).columns\nX_num_test = selector.transform(binary_log_test_NO_TNO[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=binary_log_NO_TNO.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=binary_log_test_NO_TNO.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_train_binary_log_NO_TNO = binary_log_NO_TNO[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_binary_log_NO_TNO = binary_log_test_NO_TNO[selected_columns_test]\n\n# merges\nUNI_train_binary_log_NO_TNO = UNI_train_binary_log_NO_TNO.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_binary_log_NO_TNO = UNI_test_binary_log_NO_TNO.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_binary_log_NO_TNO = pd.merge(UNI_train_binary_log_NO_TNO, train_id, left_index=True, right_index=True)\nUNI_test_binary_log_NO_TNO = pd.merge(UNI_test_binary_log_NO_TNO, test_id, left_index=True, right_index=True)","deea0541":"UNI_train_binary_log_NO_TNO.to_csv(\"UNI_train_binary_log_NO_TNO.csv\")\nUNI_test_binary_log_NO_TNO.to_csv(\"UNI_test_binary_log_NO_TNO.csv\")","add2c38d":"binary_num = pd.read_csv(\"binary_num.csv\", index_col=\"Unnamed: 0\")\nbinary_num.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = binary_num[[\"id\", \"target\"]]\nbinary_num = binary_num.drop(\"id\", axis=1)\nbinary_num_test = pd.read_csv(\"binary_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(binary_num_test[\"id\"])\nbinary_num_test = binary_num_test.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","41f4c163":"feature_train = binary_num.select_dtypes(include=['int64']).columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(binary_num[feature_train], binary_num['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = binary_num_test.select_dtypes(include=['int64']).columns\nX_cat_test = selector.transform(binary_num_test[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = binary_num.select_dtypes(include=['float64']).columns.drop(\"target\")\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(binary_num[feature_train], binary_num['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = binary_num_test.select_dtypes(include=['float64']).columns\nX_num_test = selector.transform(binary_num_test[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=binary_num.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=binary_num_test.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_train_binary_num = binary_num[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_binary_num = binary_num_test[selected_columns_test]\n\n# merges\nUNI_train_binary_num = UNI_train_binary_num.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_binary_num = UNI_test_binary_num.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_binary_num = pd.merge(UNI_train_binary_num, train_id, left_index=True, right_index=True)\nUNI_test_binary_num = pd.merge(UNI_test_binary_num, test_id, left_index=True, right_index=True)","d46fa442":"UNI_train_binary_num.to_csv(\"UNI_train_binary_num.csv\")\nUNI_test_binary_num.to_csv(\"UNI_test_binary_num.csv\")","ecc52633":"binary_num_NO = pd.read_csv(\"binary_num_NO.csv\", index_col=\"Unnamed: 0\")\nbinary_num_NO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = binary_num_NO[[\"id\", \"target\"]]\nbinary_num_NO = binary_num_NO.drop([\"target_x\", \"id\"], axis=1)\nbinary_num_test_NO = pd.read_csv(\"binary_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(binary_num_test_NO[\"id\"])\nbinary_num_test_NO = binary_num_test_NO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","6cc24db2":"feature_train = binary_num_NO.select_dtypes(include=['int64']).columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(binary_num_NO[feature_train], binary_num_NO['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = binary_num_test_NO.select_dtypes(include=['int64']).columns\nX_cat_test = selector.transform(binary_num_test_NO[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = binary_num_NO.select_dtypes(include=['float64']).columns.drop(\"target\")\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(binary_num_NO[feature_train], binary_num_NO['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = binary_num_test_NO.select_dtypes(include=['float64']).columns\nX_num_test = selector.transform(binary_num_test_NO[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=binary_num_NO.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=binary_num_test_NO.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_train_binary_num_NO = binary_num_NO[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_binary_num_NO = binary_num_test_NO[selected_columns_test]\n\n# merges\nUNI_train_binary_num_NO = UNI_train_binary_num_NO.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_binary_num_NO = UNI_test_binary_num_NO.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_binary_num_NO = pd.merge(UNI_train_binary_num_NO, train_id, left_index=True, right_index=True)\nUNI_test_binary_num_NO = pd.merge(UNI_test_binary_num_NO, test_id, left_index=True, right_index=True)","72516a00":"UNI_train_binary_num_NO.to_csv(\"UNI_train_binary_num_NO.csv\")\nUNI_test_binary_num_NO.to_csv(\"UNI_test_binary_num_NO.csv\")","ebdd0824":"binary_num_NO_TNO = pd.read_csv(\"binary_num_NO_TNO.csv\", index_col=\"Unnamed: 0\")\nbinary_num_NO_TNO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = binary_num_NO_TNO[[\"id\", \"target\"]]\nbinary_num_NO_TNO = binary_num_NO_TNO.drop([\"target_x\", \"id\"], axis=1)\nbinary_num_test_NO_TNO = pd.read_csv(\"binary_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(binary_num_test_NO_TNO[\"id\"])\nbinary_num_test_NO_TNO = binary_num_test_NO_TNO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","e448ebf8":"feature_train = binary_num_NO_TNO.select_dtypes(include=['int64']).columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(binary_num_NO_TNO[feature_train], binary_num_NO_TNO['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = binary_num_test_NO_TNO.select_dtypes(include=['int64']).columns\nX_cat_test = selector.transform(binary_num_test_NO_TNO[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = binary_num_NO_TNO.select_dtypes(include=['float64']).columns.drop(\"target\")\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(binary_num_NO_TNO[feature_train], binary_num_NO_TNO['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = binary_num_test_NO_TNO.select_dtypes(include=['float64']).columns\nX_num_test = selector.transform(binary_num_test_NO_TNO[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=binary_num_NO_TNO.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=binary_num_test_NO_TNO.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_train_binary_num_NO_TNO = binary_num_NO_TNO[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_binary_num_NO_TNO = binary_num_test_NO_TNO[selected_columns_test]\n\n# merges\nUNI_train_binary_num_NO_TNO = UNI_train_binary_num_NO_TNO.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_binary_num_NO_TNO = UNI_test_binary_num_NO_TNO.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_binary_num_NO_TNO = pd.merge(UNI_train_binary_num_NO_TNO, train_id, left_index=True, right_index=True)\nUNI_test_binary_num_NO_TNO = pd.merge(UNI_test_binary_num_NO_TNO, test_id, left_index=True, right_index=True)","0dbca1d3":"UNI_train_binary_num_NO_TNO.to_csv(\"UNI_train_binary_num_NO_TNO.csv\")\nUNI_test_binary_num_NO_TNO.to_csv(\"UNI_test_binary_num_NO_TNO.csv\")","b493ba87":"ordinal_num = pd.read_csv(\"ordinal_num.csv\", index_col=\"Unnamed: 0\")\nordinal_num.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = ordinal_num[[\"id\", \"target\"]]\nordinal_num = ordinal_num.drop(\"id\", axis=1)\nordinal_num_test = pd.read_csv(\"ordinal_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(ordinal_num_test[\"id\"])\nordinal_num_test = ordinal_num_test.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)    ","d1230de1":"feature_train = ordinal_num.select_dtypes(include=['int64']).columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(ordinal_num[feature_train], ordinal_num['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = ordinal_num_test.select_dtypes(include=['int64']).columns\nX_cat_test = selector.transform(ordinal_num_test[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = ordinal_num.select_dtypes(include=['float64']).columns.drop(\"target\")\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(ordinal_num[feature_train], ordinal_num['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = ordinal_num_test.select_dtypes(include=['float64']).columns\nX_num_test = selector.transform(ordinal_num_test[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=ordinal_num.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=ordinal_num_test.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_train_ordinal_num = ordinal_num[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_ordinal_num = ordinal_num_test[selected_columns_test]\n\n# merges\nUNI_train_ordinal_num = UNI_train_ordinal_num.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_ordinal_num = UNI_test_ordinal_num.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_ordinal_num = pd.merge(UNI_train_ordinal_num, train_id, left_index=True, right_index=True)\nUNI_test_ordinal_num = pd.merge(UNI_test_ordinal_num, test_id, left_index=True, right_index=True)","e1685607":"UNI_train_ordinal_num.to_csv(\"UNI_train_ordinal_num.csv\")\nUNI_test_ordinal_num.to_csv(\"UNI_test_ordinal_num.csv\")","6136c940":"ordinal_num_NO = pd.read_csv(\"ordinal_num_NO.csv\", index_col=\"Unnamed: 0\")\nordinal_num_NO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = ordinal_num_NO[[\"id\", \"target\"]]\nordinal_num_NO = ordinal_num_NO.drop([\"target_x\", \"id\"], axis=1)\nordinal_num_test_NO = pd.read_csv(\"ordinal_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(ordinal_num_test_NO[\"id\"])\nordinal_num_test_NO = ordinal_num_test_NO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","628622fb":"feature_train = ordinal_num_NO.select_dtypes(include=['int64']).columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(ordinal_num_NO[feature_train], ordinal_num_NO['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = ordinal_num_test_NO.select_dtypes(include=['int64']).columns\nX_cat_test = selector.transform(ordinal_num_test_NO[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = ordinal_num_NO.select_dtypes(include=['float64']).columns.drop(\"target\")\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(ordinal_num_NO[feature_train], ordinal_num_NO['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = ordinal_num_test_NO.select_dtypes(include=['float64']).columns\nX_num_test = selector.transform(ordinal_num_test_NO[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=ordinal_num_NO.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=ordinal_num_test_NO.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_train_ordinal_num_NO = ordinal_num_NO[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_ordinal_num_NO = ordinal_num_test_NO[selected_columns_test]\n\n# merges\nUNI_train_ordinal_num_NO = UNI_train_ordinal_num_NO.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_ordinal_num_NO = UNI_test_ordinal_num_NO.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_ordinal_num_NO = pd.merge(UNI_train_ordinal_num_NO, train_id, left_index=True, right_index=True)\nUNI_test_ordinal_num_NO = pd.merge(UNI_test_ordinal_num_NO, test_id, left_index=True, right_index=True)","f053c226":"UNI_train_ordinal_num_NO.to_csv(\"UNI_train_ordinal_num_NO.csv\")\nUNI_test_ordinal_num_NO.to_csv(\"UNI_test_ordinal_num_NO.csv\")","a3469b44":"ordinal_num_NO_TNO = pd.read_csv(\"ordinal_num_NO_TNO.csv\", index_col=\"Unnamed: 0\")\nordinal_num_NO_TNO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = ordinal_num_NO_TNO[[\"id\", \"target\"]]\nordinal_num_NO_TNO = ordinal_num_NO_TNO.drop([\"target_x\", \"id\"], axis=1)\nordinal_num_test_NO_TNO = pd.read_csv(\"ordinal_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(ordinal_num_test_NO_TNO[\"id\"])\nordinal_num_test_NO_TNO = ordinal_num_test_NO_TNO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","ed5b168c":"feature_train = ordinal_num_NO_TNO.select_dtypes(include=['int64']).columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(ordinal_num_NO_TNO[feature_train], ordinal_num_NO_TNO['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = ordinal_num_test_NO_TNO.select_dtypes(include=['int64']).columns\nX_cat_test = selector.transform(ordinal_num_test_NO_TNO[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = ordinal_num_NO_TNO.select_dtypes(include=['float64']).columns.drop(\"target\")\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(ordinal_num_NO_TNO[feature_train], ordinal_num_NO_TNO['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = ordinal_num_test_NO_TNO.select_dtypes(include=['float64']).columns\nX_num_test = selector.transform(ordinal_num_test_NO_TNO[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=ordinal_num_NO_TNO.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=ordinal_num_test_NO_TNO.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_train_ordinal_num_NO_TNO = ordinal_num_NO_TNO[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_ordinal_num_NO_TNO = ordinal_num_test_NO_TNO[selected_columns_test]\n\n# merges\nUNI_train_ordinal_num_NO_TNO = UNI_train_ordinal_num_NO_TNO.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_ordinal_num_NO_TNO = UNI_test_ordinal_num_NO_TNO.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_ordinal_num_NO_TNO = pd.merge(UNI_train_ordinal_num_NO_TNO, train_id, left_index=True, right_index=True)\nUNI_test_ordinal_num_NO_TNO = pd.merge(UNI_test_ordinal_num_NO_TNO, test_id, left_index=True, right_index=True)","353660b7":"UNI_train_ordinal_num_NO_TNO.to_csv(\"UNI_train_ordinal_num_NO_TNO.csv\")\nUNI_test_ordinal_num_NO_TNO.to_csv(\"UNI_test_ordinal_num_NO_TNO.csv\")","3cdd8d78":"ordinal_log = pd.read_csv(\"ordinal_num_NO_TNO.csv\", index_col=\"Unnamed: 0\")\nordinal_log.rename(columns = {'target_y':'target'}, inplace = True)\ntrain_id = ordinal_log[[\"id\", \"target\"]]\nordinal_log = ordinal_log.drop([\"target_x\", \"id\"], axis=1)\n \nordinal_log_test = pd.read_csv(\"ordinal_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(ordinal_log_test[\"id\"])\nordinal_log_test = ordinal_log_test.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","a1f66818":"feature_train = ordinal_log.select_dtypes(include=['int64']).columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(ordinal_log[feature_train], ordinal_log['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = ordinal_log_test.select_dtypes(include=['int64']).columns\nX_cat_test = selector.transform(ordinal_log_test[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = ordinal_log.select_dtypes(include=['float64']).columns.drop(\"target\")\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(ordinal_log[feature_train], ordinal_log['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = ordinal_log_test.select_dtypes(include=['float64']).columns\nX_num_test = selector.transform(ordinal_log_test[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=ordinal_log.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=ordinal_log_test.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_train_ordinal_log = ordinal_log[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_ordinal_log = ordinal_log_test[selected_columns_test]\n\n# merges\nUNI_train_ordinal_log = UNI_train_ordinal_log.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_ordinal_log = UNI_test_ordinal_log.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_ordinal_log = pd.merge(UNI_train_ordinal_log, train_id, left_index=True, right_index=True)\nUNI_test_ordinal_log = pd.merge(UNI_test_ordinal_log, test_id, left_index=True, right_index=True)","4634cbb7":"UNI_train_ordinal_log.to_csv(\"UNI_train_ordinal_log.csv\")\nUNI_test_ordinal_log.to_csv(\"UNI_test_ordinal_log.csv\")","7db59998":"ordinal_log_NO = pd.read_csv(\"ordinal_log_NO.csv\", index_col=\"Unnamed: 0\")\nordinal_log_NO = ordinal_log_NO.drop(\"Unnamed: 0.1\", axis=1)\nordinal_log_NO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = ordinal_log_NO[[\"target\", \"id\"]]\nordinal_log_NO = ordinal_log_NO.drop(\"id\", axis=1)\nordinal_log_test_NO = pd.read_csv(\"ordinal_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(ordinal_log_test_NO[\"id\"])\nordinal_log_test_NO = ordinal_log_test_NO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","7df7494c":"feature_train = ordinal_log_NO.select_dtypes(include=['int64']).columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(ordinal_log_NO[feature_train], ordinal_log_NO['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = ordinal_log_test_NO.select_dtypes(include=['int64']).columns\nX_cat_test = selector.transform(ordinal_log_test_NO[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = ordinal_log_NO.select_dtypes(include=['float64']).columns.drop(\"target\")\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(ordinal_log_NO[feature_train], ordinal_log_NO['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = ordinal_log_test_NO.select_dtypes(include=['float64']).columns\nX_num_test = selector.transform(ordinal_log_test_NO[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=ordinal_log_NO.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=ordinal_log_test_NO.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_train_ordinal_log_NO = ordinal_log_NO[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_ordinal_log_NO = ordinal_log_test_NO[selected_columns_test]\n\n# merges\nUNI_train_ordinal_log_NO = UNI_train_ordinal_log_NO.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_ordinal_log_NO = UNI_test_ordinal_log_NO.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_ordinal_log_NO = pd.merge(UNI_train_ordinal_log_NO, train_id, left_index=True, right_index=True)\nUNI_test_ordinal_log_NO = pd.merge(UNI_test_ordinal_log_NO, test_id, left_index=True, right_index=True)","bfc8c04e":"UNI_train_ordinal_log_NO.to_csv(\"UNI_train_ordinal_log_NO.csv\")\nUNI_test_ordinal_log_NO.to_csv(\"UNI_test_ordinal_log_NO.csv\")","ec3be818":"ordinal_log_NO_TNO = pd.read_csv(\"ordinal_log_NO_TNO.csv\", index_col=\"Unnamed: 0\")\nordinal_log_NO_TNO = ordinal_log_NO_TNO.drop(\"Unnamed: 0.1\", axis=1)\nordinal_log_NO_TNO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = ordinal_log_NO_TNO[[\"target\", \"id\"]]\nordinal_log_NO_TNO = ordinal_log_NO_TNO.drop(\"id\", axis=1)\nordinal_log_test_NO_TNO = pd.read_csv(\"ordinal_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(ordinal_log_test_NO_TNO[\"id\"])\nordinal_log_test_NO_TNO = ordinal_log_test_NO_TNO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","109f72aa":"feature_train = ordinal_log_NO_TNO.select_dtypes(include=['int64']).columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(ordinal_log_NO_TNO[feature_train], ordinal_log_NO_TNO['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = ordinal_log_test_NO_TNO.select_dtypes(include=['int64']).columns\nX_cat_test = selector.transform(ordinal_log_test_NO_TNO[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = ordinal_log_NO_TNO.select_dtypes(include=['float64']).columns.drop(\"target\")\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(ordinal_log_NO_TNO[feature_train], ordinal_log_NO_TNO['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = ordinal_log_test_NO_TNO.select_dtypes(include=['float64']).columns\nX_num_test = selector.transform(ordinal_log_test_NO_TNO[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=ordinal_log_NO_TNO.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=ordinal_log_test_NO_TNO.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_train_ordinal_log_NO_TNO = ordinal_log_NO_TNO[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_ordinal_log_NO_TNO = ordinal_log_test_NO_TNO[selected_columns_test]\n\n# merges\nUNI_train_ordinal_log_NO_TNO = UNI_train_ordinal_log_NO_TNO.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_ordinal_log_NO_TNO = UNI_test_ordinal_log_NO_TNO.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_ordinal_log_NO_TNO = pd.merge(UNI_train_ordinal_log_NO_TNO, train_id, left_index=True, right_index=True)\nUNI_test_ordinal_log_NO_TNO = pd.merge(UNI_test_ordinal_log_NO_TNO, test_id, left_index=True, right_index=True)","58194837":"UNI_train_ordinal_log_NO_TNO.to_csv(\"UNI_train_ordinal_log_NO_TNO.csv\")\nUNI_test_ordinal_log_NO_TNO.to_csv(\"UNI_test_ordinal_log_NO_TNO.csv\")","83415708":"freq_num = pd.read_csv(\"freq_num.csv\", index_col=\"Unnamed: 0\")\nfreq_num.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = freq_num[[\"target\", \"id\"]]\nfreq_num = freq_num.drop(\"id\", axis=1)\nfreq_num_test = pd.read_csv(\"freq_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(freq_num_test[\"id\"])\nfreq_num_test = freq_num_test.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","1aad9a31":"feature_train = freq_num.loc[:, \"cat0\":\"cat9\"].columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(freq_num[feature_train], freq_num['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = freq_num_test.loc[:, \"cat0\":\"cat9\"].columns\nX_cat_test = selector.transform(freq_num_test[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = freq_num.loc[:, \"cont0\":\"cont12\"].columns\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(freq_num[feature_train], freq_num['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = freq_num_test.loc[:, \"cont0\":\"cont12\"].columns\nX_num_test = selector.transform(freq_num_test[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=freq_num.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=freq_num_test.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_train_freq_num = freq_num[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_freq_num = freq_num_test[selected_columns_test]\n\n# merges\nUNI_train_freq_num = UNI_train_freq_num.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_freq_num = UNI_test_freq_num.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_freq_num = pd.merge(UNI_train_freq_num, train_id, left_index=True, right_index=True)\nUNI_test_freq_num = pd.merge(UNI_test_freq_num, test_id, left_index=True, right_index=True)","ca801d4c":"UNI_train_freq_num.to_csv(\"UNI_train_freq_num.csv\")\nUNI_test_freq_num.to_csv(\"UNI_test_freq_num.csv\")","c57d48ec":"freq_num_NO = pd.read_csv(\"freq_num_NO.csv\", index_col=\"Unnamed: 0\")\nfreq_num_NO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = freq_num_NO[[\"target\", \"id\"]]\nfreq_num_NO = freq_num_NO.drop([\"target_x\", \"id\"], axis=1)\nfreq_num_test_NO = pd.read_csv(\"freq_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(freq_num_test_NO[\"id\"])\nfreq_num_test_NO = freq_num_test_NO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","33fabc9b":"feature_train = freq_num_NO.loc[:, \"cat0\":\"cat9\"].columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(freq_num_NO[feature_train], freq_num_NO['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = freq_num_test_NO.loc[:, \"cat0\":\"cat9\"].columns\nX_cat_test = selector.transform(freq_num_test_NO[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = freq_num_NO.loc[:, \"cont0\":\"cont12\"].columns\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(freq_num_NO[feature_train], freq_num_NO['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = freq_num_test_NO.loc[:, \"cont0\":\"cont12\"].columns\nX_num_test = selector.transform(freq_num_test_NO[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=freq_num_NO.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=freq_num_test_NO.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_train_freq_num_NO = freq_num_NO[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_freq_num_NO = freq_num_test_NO[selected_columns_test]\n\n# merges\nUNI_train_freq_num_NO = UNI_train_freq_num_NO.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_freq_num_NO = UNI_test_freq_num_NO.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_freq_num_NO = pd.merge(UNI_train_freq_num_NO, train_id, left_index=True, right_index=True)\nUNI_test_freq_num_NO = pd.merge(UNI_test_freq_num_NO, test_id, left_index=True, right_index=True)","f910daa5":"UNI_train_freq_num_NO.to_csv(\"UNI_train_freq_num_NO.csv\")\nUNI_test_freq_num_NO.to_csv(\"UNI_test_freq_num_NO.csv\")","5e8fa3be":"freq_num_NO_TNO = pd.read_csv(\"freq_num_NO_TNO.csv\", index_col=\"Unnamed: 0\")\nfreq_num_NO_TNO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = freq_num_NO_TNO[[\"target\", \"id\"]]\nfreq_num_NO_TNO = freq_num_NO_TNO.drop([\"target_x\", \"id\"], axis=1)\nfreq_num_test_NO_TNO = pd.read_csv(\"freq_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(freq_num_test_NO_TNO[\"id\"])\nfreq_num_test_NO_TNO = freq_num_test_NO_TNO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","c9e1b5d6":"feature_train = freq_num_NO_TNO.loc[:, \"cat0\":\"cat9\"].columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(freq_num_NO_TNO[feature_train], freq_num_NO_TNO['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = freq_num_test_NO_TNO.loc[:, \"cat0\":\"cat9\"].columns\nX_cat_test = selector.transform(freq_num_test_NO_TNO[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = freq_num_NO_TNO.loc[:, \"cont0\":\"cont12\"].columns\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(freq_num_NO_TNO[feature_train], freq_num_NO_TNO['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = freq_num_test_NO_TNO.loc[:, \"cont0\":\"cont12\"].columns\nX_num_test = selector.transform(freq_num_test_NO_TNO[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=freq_num_NO_TNO.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=freq_num_test_NO_TNO.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_train_freq_num_NO_TNO = freq_num_NO_TNO[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_freq_num_NO_TNO = freq_num_test_NO_TNO[selected_columns_test]\n\n# merges\nUNI_train_freq_num_NO_TNO = UNI_train_freq_num_NO_TNO.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_freq_num_NO_TNO = UNI_test_freq_num_NO_TNO.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_freq_num_NO_TNO = pd.merge(UNI_train_freq_num_NO_TNO, train_id, left_index=True, right_index=True)\nUNI_test_freq_num_NO_TNO = pd.merge(UNI_test_freq_num_NO_TNO, test_id, left_index=True, right_index=True)","1ea90dbc":"UNI_train_freq_num_NO_TNO.to_csv(\"UNI_train_freq_num_NO_TNO.csv\")\nUNI_test_freq_num_NO_TNO.to_csv(\"UNI_test_freq_num_NO_TNO.csv\")","c05c0c65":"freq_log = pd.read_csv(\"freq_log.csv\", index_col=\"Unnamed: 0\")\nfreq_log.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = freq_log[[\"target\", \"id\"]]\nfreq_log = freq_log.drop([\"id\",\"Unnamed: 0.1\"], axis=1)\nfreq_log_test = pd.read_csv(\"freq_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(freq_log_test[\"id\"])\nfreq_log_test = freq_log_test.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","61df63f2":"feature_train = freq_log.loc[:, \"cat0\":\"cat9\"].columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(freq_log[feature_train], freq_log['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = freq_log_test.loc[:, \"cat0\":\"cat9\"].columns\nX_cat_test = selector.transform(freq_log_test[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = freq_log.loc[:, \"cont0_log\":\"cont12_log\"].columns\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(freq_log[feature_train], freq_log['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = freq_log_test.loc[:, \"cont0_log\":\"cont12_log\"].columns\nX_num_test = selector.transform(freq_log_test[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=freq_log.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=freq_log_test.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selectedfreq features.\nUNI_train_freq_log = freq_log[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_freq_log = freq_log_test[selected_columns_test]\n\n# merges\nUNI_train_freq_log = UNI_train_freq_log.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_freq_log = UNI_test_freq_log.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_freq_log = pd.merge(UNI_train_freq_log, train_id, left_index=True, right_index=True)\nUNI_test_freq_log = pd.merge(UNI_test_freq_log, test_id, left_index=True, right_index=True)","e46a71c8":"UNI_train_freq_log.to_csv(\"UNI_train_freq_log.csv\")\nUNI_test_freq_log.to_csv(\"UNI_test_freq_log.csv\")","184d0575":"freq_log_NO = pd.read_csv(\"freq_log_NO.csv\", index_col=\"Unnamed: 0\")\nfreq_log_NO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = freq_log_NO[[\"target\", \"id\"]]\nfreq_log_NO = freq_log_NO.drop([\"id\", \"Unnamed: 0.1\"], axis=1)\nfreq_log_test_NO = pd.read_csv(\"freq_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(freq_log_test_NO[\"id\"])\nfreq_log_test_NO = freq_log_test_NO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","69fb1171":"feature_train = freq_log_NO.loc[:, \"cat0\":\"cat9\"].columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(freq_log_NO[feature_train], freq_log_NO['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = freq_log_test_NO.loc[:, \"cat0\":\"cat9\"].columns\nX_cat_test = selector.transform(freq_log_test_NO[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = freq_log_NO.loc[:, \"cont0_log\":\"cont12_log\"].columns\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(freq_log_NO[feature_train], freq_log_NO['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = freq_log_test_NO.loc[:, \"cont0_log\":\"cont12_log\"].columns\nX_num_test = selector.transform(freq_log_test_NO[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=freq_log_NO.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=freq_log_test_NO.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selectedfreq features.\nUNI_train_freq_log_NO = freq_log_NO[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_freq_log_NO = freq_log_test_NO[selected_columns_test]\n\n# merges\nUNI_train_freq_log_NO = UNI_train_freq_log_NO.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_freq_log_NO = UNI_test_freq_log_NO.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_freq_log_NO = pd.merge(UNI_train_freq_log_NO, train_id, left_index=True, right_index=True)\nUNI_test_freq_log_NO = pd.merge(UNI_test_freq_log_NO, test_id, left_index=True, right_index=True)","05057518":"UNI_train_freq_log_NO.to_csv(\"UNI_train_freq_log_NO.csv\")\nUNI_test_freq_log_NO.to_csv(\"UNI_test_freq_log_NO.csv\")","c357c080":"freq_log_NO_TNO = pd.read_csv(\"freq_log_NO_TNO.csv\", index_col=\"Unnamed: 0\")\nfreq_log_NO_TNO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = freq_log_NO_TNO[[\"target\", \"id\"]]\nfreq_log_NO_TNO = freq_log_NO_TNO.drop([\"Unnamed: 0.1\", \"id\"], axis=1)\nfreq_log_test_NO_TNO = pd.read_csv(\"freq_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(freq_log_test_NO_TNO[\"id\"])\nfreq_log_test_NO_TNO = freq_log_test_NO_TNO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","1ead68ca":"feature_train = freq_log_NO_TNO.loc[:, \"cat0\":\"cat9\"].columns\n\n# Keep 5 categorical features\nselector = SelectKBest(mutual_info_regression, k=5)\nX_cat_train = selector.fit_transform(freq_log_NO_TNO[feature_train], freq_log_NO_TNO['target'])\nX_cat_train = pd.DataFrame(X_cat_train)\n\nfeature_test = freq_log_test_NO_TNO.loc[:, \"cat0\":\"cat9\"].columns\nX_cat_test = selector.transform(freq_log_test_NO_TNO[feature_test])\nX_cat_test = pd.DataFrame(X_cat_test)\n\n\nfeature_train = freq_log_NO_TNO.loc[:, \"cont0_log\":\"cont12_log\"].columns\n\n# Keep 5 numerical features\nselector = SelectKBest(f_regression, k=5)\nX_num_train = selector.fit_transform(freq_log_NO_TNO[feature_train], freq_log_NO_TNO['target'])\nX_num_train = pd.DataFrame(X_num_train)\n\nfeature_test = freq_log_test_NO_TNO.loc[:, \"cont0_log\":\"cont12_log\"].columns\nX_num_test = selector.transform(freq_log_test_NO_TNO[feature_test])\nX_num_test = pd.DataFrame(X_num_test)\n\n\n# Get back the features we've kept, zero out all other features\nselected_features_train = pd.DataFrame(selector.inverse_transform(X_num_train), \n                                 index=freq_log_NO_TNO.index, \n                                 columns=feature_train)\n\n# Get back the features we've kept, zero out all other features\nselected_features_test = pd.DataFrame(selector.inverse_transform(X_num_test), \n                                 index=freq_log_test_NO_TNO.index, \n                                 columns=feature_test)\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_train = selected_features_train.columns[selected_features_train.var() != 0]\n# Get the valid dataset with the selectedfreq features.\nUNI_train_freq_log_NO_TNO = freq_log_NO_TNO[selected_columns_train]\n\n# Dropped columns have values of all 0s, so var is 0, drop them\nselected_columns_test = selected_features_test.columns[selected_features_test.var() != 0]\n# Get the valid dataset with the selected features.\nUNI_test_freq_log_NO_TNO = freq_log_test_NO_TNO[selected_columns_test]\n\n# merges\nUNI_train_freq_log_NO_TNO = UNI_train_freq_log_NO_TNO.merge(X_cat_train, left_index=True, right_index=True)\nUNI_test_freq_log_NO_TNO = UNI_test_freq_log_NO_TNO.merge(X_cat_test, left_index=True, right_index=True)\nUNI_train_freq_log_NO_TNO = pd.merge(UNI_train_freq_log_NO_TNO, train_id, left_index=True, right_index=True)\nUNI_test_freq_log_NO_TNO = pd.merge(UNI_test_freq_log_NO_TNO, test_id, left_index=True, right_index=True)","6d7431e4":"UNI_train_freq_log_NO_TNO.to_csv(\"UNI_train_freq_log_NO_TNO.csv\")\nUNI_test_freq_log_NO_TNO.to_csv(\"UNI_test_freq_log_NO_TNO.csv\")","696bc36d":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA","dad032e8":"pd.set_option(\"display.max_columns\", None)","e2650d32":"binary_num = pd.read_csv(\"binary_num.csv\", index_col=\"Unnamed: 0\")\nbinary_num","96cfc026":"binary_num_test = pd.read_csv(\"binary_num_test.csv\", index_col=\"Unnamed: 0\")\nbinary_num_test = binary_num_test.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\"], axis=1)\nbinary_num_test","8f53df0b":"X_train = binary_num.loc[:, \"cat0_0\":\"cont12\"]\nX_test = binary_num_test.loc[:, \"cat0_0\":\"cont12\"]","cce884d2":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","e832e31c":"pca = PCA(n_components=10)\npca.fit(X_train)","d7a36f53":"PCA_train_binary_num = pca.transform(X_train)\nPCA_train_binary_num = pd.DataFrame(PCA_train_binary_num)\nPCA_train_binary_num","ec969f78":"PCA_test_binary_num = pca.transform(X_test)\nPCA_test_binary_num = pd.DataFrame(PCA_test_binary_num)\nPCA_test_binary_num","792e8def":"target = binary_num[[\"id\", \"target\"]]\ni_d = pd.DataFrame(binary_num_test[\"id\"])","f05d1b1c":"PCA_train_binary_num = pd.merge(PCA_train_binary_num, target, left_index=True, right_index=True)\nPCA_train_binary_num","e9387bfe":"PCA_test_binary_num = pd.merge(PCA_test_binary_num, i_d, left_index=True, right_index=True)\nPCA_test_binary_num","e65082df":"PCA_train_binary_num.to_csv(\"PCA_train_binary_num.csv\")\nPCA_test_binary_num.to_csv(\"PCA_test_binary_num.csv\")","4282c942":"binary_num_NO = pd.read_csv(\"binary_num_NO.csv\", index_col=\"Unnamed: 0\")\nbinary_num_NO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = binary_num_NO[[\"id\", \"target\"]]\nbinary_num_NO = binary_num_NO.drop([\"target_x\", \"id\"], axis=1)\nbinary_num_test_NO = pd.read_csv(\"binary_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(binary_num_test_NO[\"id\"])\nbinary_num_test_NO = binary_num_test_NO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","22937113":"X_train = binary_num_NO.loc[:, \"cat0_0\":\"cont12\"]\nX_test = binary_num_test_NO.loc[:, \"cat0_0\":\"cont12\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_binary_num_NO = pca.transform(X_train)\nPCA_train_binary_num_NO = pd.DataFrame(PCA_train_binary_num_NO)\n\nPCA_test_binary_num_NO = pca.transform(X_test)\nPCA_test_binary_num_NO = pd.DataFrame(PCA_test_binary_num_NO)\n\n# merge dataframes\nPCA_train_binary_num_NO = pd.merge(PCA_train_binary_num_NO, train_id, left_index=True, right_index=True)\nPCA_test_binary_num_NO = pd.merge(PCA_test_binary_num_NO, test_id, left_index=True, right_index=True)","33467396":"PCA_train_binary_num_NO.to_csv(\"PCA_train_binary_num_NO.csv\")\nPCA_test_binary_num_NO.to_csv(\"PCA_test_binary_num_NO.csv\")","c2e8d0e0":"binary_num_NO_TNO = pd.read_csv(\"binary_num_NO_TNO.csv\", index_col=\"Unnamed: 0\")\nbinary_num_NO_TNO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = binary_num_NO_TNO[[\"id\", \"target\"]]\nbinary_num_NO_TNO = binary_num_NO_TNO.drop([\"target_x\", \"id\"], axis=1)\nbinary_num_test_NO_TNO = pd.read_csv(\"binary_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(binary_num_test_NO_TNO[\"id\"])\nbinary_num_test_NO_TNO = binary_num_test_NO_TNO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","a2262b0c":"X_train = binary_num_NO_TNO.loc[:, \"cat0_0\":\"cont12\"]\nX_test = binary_num_test_NO_TNO.loc[:, \"cat0_0\":\"cont12\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_binary_num_NO_TNO = pca.transform(X_train)\nPCA_train_binary_num_NO_TNO = pd.DataFrame(PCA_train_binary_num_NO_TNO)\n\nPCA_test_binary_num_NO_TNO = pca.transform(X_test)\nPCA_test_binary_num_NO_TNO = pd.DataFrame(PCA_test_binary_num_NO_TNO)\n\n# merge dataframes\nPCA_train_binary_num_NO_TNO = pd.merge(PCA_train_binary_num_NO_TNO, train_id, left_index=True, right_index=True)\nPCA_test_binary_num_NO_TNO = pd.merge(PCA_test_binary_num_NO_TNO, test_id, left_index=True, right_index=True)","89489bc8":"PCA_train_binary_num_NO_TNO.to_csv(\"PCA_train_binary_num_NO_TNO.csv\")\nPCA_test_binary_num_NO_TNO.to_csv(\"PCA_test_binary_num_NO_TNO.csv\")","440df6d8":"binary_log = pd.read_csv(\"binary_log.csv\", index_col=\"Unnamed: 0\")\ntrain_id = binary_log[[\"id\", \"target\"]]\nbinary_log = binary_log.drop([\"Unnamed: 0.1\", \"id\"], axis=1)\nbinary_log_test = pd.read_csv(\"binary_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(binary_log_test[\"id\"])\nbinary_log_test = binary_log_test.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","5e0ddf7e":"X_train = binary_log.loc[:, \"cat0_0\":\"cont12_log\"]\nX_test = binary_log_test.loc[:, \"cat0_0\":\"cont12_log\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_binary_log = pca.transform(X_train)\nPCA_train_binary_log = pd.DataFrame(PCA_train_binary_log)\n\nPCA_test_binary_log = pca.transform(X_test)\nPCA_test_binary_log = pd.DataFrame(PCA_test_binary_log)\n\n# merge dataframes\nPCA_train_binary_log = pd.merge(PCA_train_binary_log, train_id, left_index=True, right_index=True)\nPCA_test_binary_log = pd.merge(PCA_test_binary_log, test_id, left_index=True, right_index=True)","3f8bef51":"PCA_train_binary_log.to_csv(\"PCA_train_binary_log.csv\")\nPCA_test_binary_log.to_csv(\"PCA_test_binary_log.csv\")","70163147":"binary_log_NO = pd.read_csv(\"binary_log_NO.csv\", index_col=\"Unnamed: 0\")\nbinary_log_NO.rename(columns = {'target_y':'target'}, inplace = True)\ntrain_id = binary_log_NO[[\"id\", \"target\"]]\nbinary_log_NO = binary_log_NO.drop([\"Unnamed: 0.1\", \"id\"], axis=1)\nbinary_log_test_NO = pd.read_csv(\"binary_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(binary_log_test_NO[\"id\"])\nbinary_log_test_NO = binary_log_test_NO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","f071c600":"X_train = binary_log_NO.loc[:, \"cat0_0\":\"cont12_log\"]\nX_test = binary_log_test_NO.loc[:, \"cat0_0\":\"cont12_log\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_binary_log_NO = pca.transform(X_train)\nPCA_train_binary_log_NO = pd.DataFrame(PCA_train_binary_log_NO)\n\nPCA_test_binary_log_NO = pca.transform(X_test)\nPCA_test_binary_log_NO = pd.DataFrame(PCA_test_binary_log_NO)\n\n# merge dataframes\nPCA_train_binary_log_NO = pd.merge(PCA_train_binary_log_NO, train_id, left_index=True, right_index=True)\nPCA_test_binary_log_NO = pd.merge(PCA_test_binary_log_NO, test_id, left_index=True, right_index=True)","65889e5e":"PCA_train_binary_log_NO.to_csv(\"PCA_train_binary_log_NO.csv\")\nPCA_test_binary_log_NO.to_csv(\"PCA_test_binary_log_NO.csv\")","fd671304":"binary_log_NO_TNO = pd.read_csv(\"binary_log_NO_TNO.csv\", index_col=\"Unnamed: 0\")\ntrain_id = binary_log_NO_TNO[[\"id\", \"target\"]]\nbinary_log_NO_TNO = binary_log_NO_TNO.drop([\"Unnamed: 0.1\", \"id\"], axis=1)\nbinary_log_test_NO_TNO = pd.read_csv(\"binary_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(binary_log_test_NO_TNO[\"id\"])\nbinary_log_test_NO_TNO = binary_log_test_NO_TNO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","a46edc2e":"X_train = binary_log_NO_TNO.loc[:, \"cat0_0\":\"cont12_log\"]\nX_test = binary_log_test_NO_TNO.loc[:, \"cat0_0\":\"cont12_log\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_binary_log_NO_TNO = pca.transform(X_train)\nPCA_train_binary_log_NO_TNO = pd.DataFrame(PCA_train_binary_log_NO_TNO)\n\nPCA_test_binary_log_NO_TNO = pca.transform(X_test)\nPCA_test_binary_log_NO_TNO = pd.DataFrame(PCA_test_binary_log_NO_TNO)\n\n# merge dataframes\nPCA_train_binary_log_NO_TNO = pd.merge(PCA_train_binary_log_NO_TNO, train_id, left_index=True, right_index=True)\nPCA_test_binary_log_NO_TNO = pd.merge(PCA_test_binary_log_NO_TNO, test_id, left_index=True, right_index=True)","4226d436":"PCA_train_binary_log_NO_TNO.to_csv(\"PCA_train_binary_log_NO_TNO.csv\")\nPCA_test_binary_log_NO_TNO.to_csv(\"PCA_test_binary_log_NO_TNO.csv\")","081cc061":"ordinal_num = pd.read_csv(\"ordinal_num.csv\", index_col=\"Unnamed: 0\")\nordinal_num.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = ordinal_num[[\"id\", \"target\"]]\nordinal_num = ordinal_num.drop(\"id\", axis=1)\nordinal_num_test = pd.read_csv(\"ordinal_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(ordinal_num_test[\"id\"])\nordinal_num_test = ordinal_num_test.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)    ","785e8f95":"X_train = ordinal_num.loc[:, \"cat0\":\"cont12\"]\nX_test = ordinal_num_test.loc[:, \"cat0\":\"cont12\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_ordinal_num = pca.transform(X_train)\nPCA_train_ordinal_num = pd.DataFrame(PCA_train_ordinal_num)\n\nPCA_test_ordinal_num = pca.transform(X_test)\nPCA_test_ordinal_num = pd.DataFrame(PCA_test_ordinal_num)\n\n# merge dataframes\nPCA_train_ordinal_num = pd.merge(PCA_train_ordinal_num, train_id, left_index=True, right_index=True)\nPCA_test_ordinal_num = pd.merge(PCA_test_ordinal_num, test_id, left_index=True, right_index=True)","9026d7ac":"PCA_train_ordinal_num.to_csv(\"PCA_train_ordinal_num.csv\")\nPCA_test_ordinal_num.to_csv(\"PCA_test_ordinal_num.csv\")","b2735990":"ordinal_num_NO = pd.read_csv(\"ordinal_num_NO.csv\", index_col=\"Unnamed: 0\")\nordinal_num_NO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = ordinal_num_NO[[\"id\", \"target\"]]\nordinal_num_NO = ordinal_num_NO.drop([\"target_x\", \"id\"], axis=1)\nordinal_num_test_NO = pd.read_csv(\"ordinal_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(ordinal_num_test_NO[\"id\"])\nordinal_num_test_NO = ordinal_num_test_NO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","d366b8d9":"X_train = ordinal_num_NO.loc[:, \"cat0\":\"cont12\"]\nX_test = ordinal_num_test_NO.loc[:, \"cat0\":\"cont12\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_ordinal_num_NO = pca.transform(X_train)\nPCA_train_ordinal_num_NO = pd.DataFrame(PCA_train_ordinal_num_NO)\n\nPCA_test_ordinal_num_NO = pca.transform(X_test)\nPCA_test_ordinal_num_NO = pd.DataFrame(PCA_test_ordinal_num_NO)\n\n# merge dataframes\nPCA_train_ordinal_num_NO = pd.merge(PCA_train_ordinal_num_NO, train_id, left_index=True, right_index=True)\nPCA_test_ordinal_num_NO = pd.merge(PCA_test_ordinal_num_NO, test_id, left_index=True, right_index=True)","41170cff":"PCA_train_ordinal_num_NO.to_csv(\"PCA_train_ordinal_num_NO.csv\")\nPCA_test_ordinal_num_NO.to_csv(\"PCA_test_ordinal_num_NO.csv\")","56da2e18":"ordinal_num_NO_TNO = pd.read_csv(\"ordinal_num_NO_TNO.csv\", index_col=\"Unnamed: 0\")\nordinal_num_NO_TNO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = ordinal_num_NO_TNO[[\"id\", \"target\"]]\nordinal_num_NO_TNO = ordinal_num_NO_TNO.drop([\"target_x\", \"id\"], axis=1)\nordinal_num_test_NO_TNO = pd.read_csv(\"ordinal_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(ordinal_num_test_NO_TNO[\"id\"])\nordinal_num_test_NO_TNO = ordinal_num_test_NO_TNO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","90d00904":"X_train = ordinal_num_NO_TNO.loc[:, \"cat0\":\"cont12\"]\nX_test = ordinal_num_test_NO_TNO.loc[:, \"cat0\":\"cont12\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_ordinal_num_NO_TNO = pca.transform(X_train)\nPCA_train_ordinal_num_NO_TNO = pd.DataFrame(PCA_train_ordinal_num_NO_TNO)\n\nPCA_test_ordinal_num_NO_TNO = pca.transform(X_test)\nPCA_test_ordinal_num_NO_TNO = pd.DataFrame(PCA_test_ordinal_num_NO_TNO)\n\n# merge dataframes\nPCA_train_ordinal_num_NO_TNO = pd.merge(PCA_train_ordinal_num_NO_TNO, train_id, left_index=True, right_index=True)\nPCA_test_ordinal_num_NO_TNO = pd.merge(PCA_test_ordinal_num_NO_TNO, test_id, left_index=True, right_index=True)","6379c03e":"PCA_train_ordinal_num_NO_TNO.to_csv(\"PCA_train_ordinal_num_NO_TNO.csv\")\nPCA_test_ordinal_num_NO_TNO.to_csv(\"PCA_test_ordinal_num_NO_TNO.csv\")","dffd50ee":"ordinal_log = pd.read_csv(\"ordinal_log.csv\", index_col=\"Unnamed: 0\")\nordinal_log.rename(columns = {'target_y':'target'}, inplace = True)\ntrain_id = ordinal_log[[\"id\", \"target\"]]\nordinal_log = ordinal_log.drop([\"Unnamed: 0.1\", \"id\"], axis=1)\n \nordinal_log_test = pd.read_csv(\"ordinal_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(ordinal_log_test[\"id\"])\nordinal_log_test = ordinal_log_test.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","74cd80ce":"X_train = ordinal_log.loc[:, \"cat0\":\"cont12_log\"]\nX_test = ordinal_log_test.loc[:, \"cat0\":\"cont12_log\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_ordinal_log = pca.transform(X_train)\nPCA_train_ordinal_log = pd.DataFrame(PCA_train_ordinal_log)\n\nPCA_test_ordinal_log = pca.transform(X_test)\nPCA_test_ordinal_log = pd.DataFrame(PCA_test_ordinal_log)\n\n# merge dataframes\nPCA_train_ordinal_log = pd.merge(PCA_train_ordinal_log, train_id, left_index=True, right_index=True)\nPCA_test_ordinal_log = pd.merge(PCA_test_ordinal_log, test_id, left_index=True, right_index=True)","ac97a149":"PCA_train_ordinal_log.to_csv(\"PCA_train_ordinal_log.csv\")\nPCA_test_ordinal_log.to_csv(\"PCA_test_ordinal_log.csv\")","d1988d20":"ordinal_log_NO = pd.read_csv(\"ordinal_log_NO.csv\", index_col=\"Unnamed: 0\")\nordinal_log_NO = ordinal_log_NO.drop(\"Unnamed: 0.1\", axis=1)\nordinal_log_NO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = ordinal_log_NO[[\"target\", \"id\"]]\nordinal_log_NO = ordinal_log_NO.drop(\"id\", axis=1)\nordinal_log_test_NO = pd.read_csv(\"ordinal_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(ordinal_log_test_NO[\"id\"])\nordinal_log_test_NO = ordinal_log_test_NO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","f138bf38":"X_train = ordinal_log_NO.loc[:, \"cat0\":\"cont12_log\"]\nX_test = ordinal_log_test_NO.loc[:, \"cat0\":\"cont12_log\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_ordinal_log_NO = pca.transform(X_train)\nPCA_train_ordinal_log_NO = pd.DataFrame(PCA_train_ordinal_log_NO)\n\nPCA_test_ordinal_log_NO = pca.transform(X_test)\nPCA_test_ordinal_log_NO = pd.DataFrame(PCA_test_ordinal_log_NO)\n\n# merge dataframes\nPCA_train_ordinal_log_NO = pd.merge(PCA_train_ordinal_log_NO, train_id, left_index=True, right_index=True)\nPCA_test_ordinal_log_NO = pd.merge(PCA_test_ordinal_log_NO, test_id, left_index=True, right_index=True)","4cced1c2":"PCA_train_ordinal_log_NO.to_csv(\"PCA_train_ordinal_log_NO.csv\")\nPCA_test_ordinal_log_NO.to_csv(\"PCA_test_ordinal_log_NO.csv\")","14b3d7f6":"ordinal_log_NO_TNO = pd.read_csv(\"ordinal_log_NO_TNO.csv\", index_col=\"Unnamed: 0\")\nordinal_log_NO_TNO = ordinal_log_NO_TNO.drop(\"Unnamed: 0.1\", axis=1)\nordinal_log_NO_TNO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = ordinal_log_NO_TNO[[\"target\", \"id\"]]\nordinal_log_NO_TNO = ordinal_log_NO_TNO.drop(\"id\", axis=1)\nordinal_log_test_NO_TNO = pd.read_csv(\"ordinal_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(ordinal_log_test_NO_TNO[\"id\"])\nordinal_log_test_NO_TNO = ordinal_log_test_NO_TNO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","985ebbe2":"X_train = ordinal_log_NO_TNO.loc[:, \"cat0\":\"cont12_log\"]\nX_test = ordinal_log_test_NO_TNO.loc[:, \"cat0\":\"cont12_log\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_ordinal_log_NO_TNO = pca.transform(X_train)\nPCA_train_ordinal_log_NO_TNO = pd.DataFrame(PCA_train_ordinal_log_NO_TNO)\n\nPCA_test_ordinal_log_NO_TNO = pca.transform(X_test)\nPCA_test_ordinal_log_NO_TNO = pd.DataFrame(PCA_test_ordinal_log_NO_TNO)\n\n# merge dataframes\nPCA_train_ordinal_log_NO_TNO = pd.merge(PCA_train_ordinal_log_NO_TNO, train_id, left_index=True, right_index=True)\nPCA_test_ordinal_log_NO_TNO = pd.merge(PCA_test_ordinal_log_NO_TNO, test_id, left_index=True, right_index=True)","df265690":"PCA_train_ordinal_log_NO_TNO.to_csv(\"PCA_train_ordinal_log_NO_TNO.csv\")\nPCA_test_ordinal_log_NO_TNO.to_csv(\"PCA_test_ordinal_log_NO_TNO.csv\")","bf9900f4":"freq_num = pd.read_csv(\"freq_num.csv\", index_col=\"Unnamed: 0\")\nfreq_num.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = freq_num[[\"target\", \"id\"]]\nfreq_num = freq_num.drop(\"id\", axis=1)\nfreq_num_test = pd.read_csv(\"freq_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(freq_num_test[\"id\"])\nfreq_num_test = freq_num_test.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","6b57da99":"X_train = freq_num.loc[:, \"cat0\":\"cont12\"]\nX_test = freq_num_test.loc[:, \"cat0\":\"cont12\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_freq_num = pca.transform(X_train)\nPCA_train_freq_num = pd.DataFrame(PCA_train_freq_num)\n\nPCA_test_freq_num = pca.transform(X_test)\nPCA_test_freq_num = pd.DataFrame(PCA_test_freq_num)\n\n# merge dataframes\nPCA_train_freq_num = pd.merge(PCA_train_freq_num, train_id, left_index=True, right_index=True)\nPCA_test_freq_num = pd.merge(PCA_test_freq_num, test_id, left_index=True, right_index=True)","b1a5d579":"PCA_train_freq_num.to_csv(\"PCA_train_freq_num.csv\")\nPCA_test_freq_num.to_csv(\"PCA_test_freq_num.csv\")","29d86867":"freq_num_NO = pd.read_csv(\"freq_num_NO.csv\", index_col=\"Unnamed: 0\")\nfreq_num_NO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = freq_num_NO[[\"target\", \"id\"]]\nfreq_num_NO = freq_num_NO.drop([\"target_x\", \"id\"], axis=1)\nfreq_num_test_NO = pd.read_csv(\"freq_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(freq_num_test_NO[\"id\"])\nfreq_num_test_NO = freq_num_test_NO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","3d11fdc9":"X_train = freq_num_NO.loc[:, \"cat0\":\"cont12\"]\nX_test = freq_num_NO.loc[:, \"cat0\":\"cont12\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_freq_num_NO = pca.transform(X_train)\nPCA_train_freq_num_NO = pd.DataFrame(PCA_train_freq_num_NO)\n\nPCA_test_freq_num_NO = pca.transform(X_test)\nPCA_test_freq_num_NO = pd.DataFrame(PCA_test_freq_num_NO)\n\n# merge dataframes\nPCA_train_freq_num_NO = pd.merge(PCA_train_freq_num_NO, train_id, left_index=True, right_index=True)\nPCA_test_freq_num_NO = pd.merge(PCA_test_freq_num_NO, test_id, left_index=True, right_index=True)","74f68acb":"PCA_train_freq_num_NO.to_csv(\"PCA_train_freq_num_NO.csv\")\nPCA_test_freq_num_NO.to_csv(\"PCA_test_freq_num_NO.csv\")","f822ab16":"freq_num_NO_TNO = pd.read_csv(\"freq_num_NO_TNO.csv\", index_col=\"Unnamed: 0\")\nfreq_num_NO_TNO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = freq_num_NO_TNO[[\"target\", \"id\"]]\nfreq_num_NO_TNO = freq_num_NO_TNO.drop([\"target_x\", \"id\"], axis=1)\nfreq_num_test_NO_TNO = pd.read_csv(\"freq_num_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(freq_num_test_NO_TNO[\"id\"])\nfreq_num_test_NO_TNO = freq_num_test_NO_TNO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","2c0b6534":"X_train = freq_num_NO_TNO.loc[:, \"cat0\":\"cont12\"]\nX_test = freq_num_NO_TNO.loc[:, \"cat0\":\"cont12\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_freq_num_NO_TNO = pca.transform(X_train)\nPCA_train_freq_num_NO_TNO = pd.DataFrame(PCA_train_freq_num_NO_TNO)\n\nPCA_test_freq_num_NO_TNO = pca.transform(X_test)\nPCA_test_freq_num_NO_TNO = pd.DataFrame(PCA_test_freq_num_NO_TNO)\n\n# merge dataframes\nPCA_train_freq_num_NO_TNO = pd.merge(PCA_train_freq_num_NO_TNO, train_id, left_index=True, right_index=True)\nPCA_test_freq_num_NO_TNO = pd.merge(PCA_test_freq_num_NO_TNO, test_id, left_index=True, right_index=True)","08f26e20":"PCA_train_freq_num_NO_TNO.to_csv(\"PCA_train_freq_num_NO_TNO.csv\")\nPCA_test_freq_num_NO_TNO.to_csv(\"PCA_test_freq_num_NO_TNO.csv\")","1f3e8249":"freq_log = pd.read_csv(\"freq_log.csv\", index_col=\"Unnamed: 0\")\nfreq_log.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = freq_log[[\"target\", \"id\"]]\nfreq_log = freq_log.drop([\"id\",\"Unnamed: 0.1\"], axis=1)\nfreq_log_test = pd.read_csv(\"freq_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(freq_log_test[\"id\"])\nfreq_log_test = freq_log_test.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","d7026f26":"X_train = freq_log.loc[:, \"cat0\":\"cont12_log\"]\nX_test = freq_log_test.loc[:, \"cat0\":\"cont12_log\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_freq_log = pca.transform(X_train)\nPCA_train_freq_log = pd.DataFrame(PCA_train_freq_log)\n\nPCA_test_freq_log = pca.transform(X_test)\nPCA_test_freq_log = pd.DataFrame(PCA_test_freq_log)\n\n# merge dataframes\nPCA_train_freq_log = pd.merge(PCA_train_freq_log, train_id, left_index=True, right_index=True)\nPCA_test_freq_log = pd.merge(PCA_test_freq_log, test_id, left_index=True, right_index=True)","a70118f2":"PCA_train_freq_log.to_csv(\"PCA_train_freq_log.csv\")\nPCA_test_freq_log.to_csv(\"PCA_test_freq_log.csv\")","bce5d3fa":"freq_log_NO = pd.read_csv(\"freq_log_NO.csv\", index_col=\"Unnamed: 0\")\nfreq_log_NO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = freq_log_NO[[\"target\", \"id\"]]\nfreq_log_NO = freq_log_NO.drop([\"id\", \"Unnamed: 0.1\"], axis=1)\nfreq_log_test_NO = pd.read_csv(\"freq_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(freq_log_test_NO[\"id\"])\nfreq_log_test_NO = freq_log_test_NO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","a6bafcbd":"X_train = freq_log_NO.loc[:, \"cat0\":\"cont12_log\"]\nX_test = freq_log_test_NO.loc[:, \"cat0\":\"cont12_log\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_freq_log_NO = pca.transform(X_train)\nPCA_train_freq_log_NO = pd.DataFrame(PCA_train_freq_log_NO)\n\nPCA_test_freq_log_NO = pca.transform(X_test)\nPCA_test_freq_log_NO = pd.DataFrame(PCA_test_freq_log_NO)\n\n# merge dataframes\nPCA_train_freq_log_NO = pd.merge(PCA_train_freq_log_NO, train_id, left_index=True, right_index=True)\nPCA_test_freq_log_NO = pd.merge(PCA_test_freq_log_NO, test_id, left_index=True, right_index=True)","bd14379b":"PCA_train_freq_log_NO.to_csv(\"PCA_train_freq_log_NO.csv\")\nPCA_test_freq_log_NO.to_csv(\"PCA_test_freq_log_NO.csv\")","98735119":"freq_log_NO_TNO = pd.read_csv(\"freq_log_NO_TNO.csv\", index_col=\"Unnamed: 0\")\nfreq_log_NO_TNO.rename(columns = {'target_y':'target'}, inplace = True) \ntrain_id = freq_log_NO_TNO[[\"target\", \"id\"]]\nfreq_log_NO_TNO = freq_log_NO_TNO.drop([\"Unnamed: 0.1\", \"id\"], axis=1)\nfreq_log_test_NO_TNO = pd.read_csv(\"freq_log_test.csv\", index_col=\"Unnamed: 0\")\ntest_id = pd.DataFrame(freq_log_test_NO_TNO[\"id\"])\nfreq_log_test_NO_TNO = freq_log_test_NO_TNO.drop([\"Unnamed: 0_x\", \"Unnamed: 0_y\", \"id\"], axis=1)","82563c32":"X_train = freq_log_NO_TNO.loc[:, \"cat0\":\"cont12_log\"]\nX_test = freq_log_test_NO_TNO.loc[:, \"cat0\":\"cont12_log\"]\n\n# scale data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# apply PCA\npca = PCA(n_components=10)\npca.fit(X_train)\n\nPCA_train_freq_log_NO_TNO = pca.transform(X_train)\nPCA_train_freq_log_NO_TNO = pd.DataFrame(PCA_train_freq_log_NO_TNO)\n\nPCA_test_freq_log_NO_TNO = pca.transform(X_test)\nPCA_test_freq_log_NO_TNO = pd.DataFrame(PCA_test_freq_log_NO_TNO)\n\n# merge dataframes\nPCA_train_freq_log_NO_TNO = pd.merge(PCA_train_freq_log_NO_TNO, train_id, left_index=True, right_index=True)\nPCA_test_freq_log_NO_TNO = pd.merge(PCA_test_freq_log_NO_TNO, test_id, left_index=True, right_index=True)","b47158ba":"PCA_train_freq_log_NO_TNO.to_csv(\"PCA_train_freq_log_NO_TNO.csv\")\nPCA_test_freq_log_NO_TNO.to_csv(\"PCA_test_freq_log_NO_TNO.csv\")","dc360b0f":"import xgboost as xgb\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import SGDRegressor                    \nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\nfrom sklearn.linear_model import Lars\nfrom sklearn.linear_model import LarsCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import LassoLars\nfrom sklearn.linear_model import LassoLarsCV\nfrom sklearn.linear_model import LassoLarsIC\nfrom sklearn.linear_model import OrthogonalMatchingPursuit\nfrom sklearn.linear_model import OrthogonalMatchingPursuitCV                        \nfrom sklearn.linear_model import ARDRegression\nfrom sklearn.linear_model import BayesianRidge                       \nfrom sklearn.linear_model import HuberRegressor\nfrom sklearn.linear_model import RANSACRegressor\nfrom sklearn.linear_model import TheilSenRegressor\nfrom sklearn.linear_model import TweedieRegressor\nfrom sklearn.linear_model import GammaRegressor\nfrom sklearn.linear_model import PassiveAggressiveRegressor\nfrom sklearn.linear_model import enet_path\nfrom sklearn.linear_model import lars_path\nfrom sklearn.linear_model import lars_path_gram\nfrom sklearn.linear_model import lasso_path\nfrom sklearn.linear_model import orthogonal_mp\nfrom sklearn.linear_model import orthogonal_mp_gram\nfrom sklearn.linear_model import ridge_regression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neighbors import RadiusNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.tree import ExtraTreeRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.isotonic import IsotonicRegression\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.svm import LinearSVR\nfrom sklearn.svm import NuSVR\nfrom sklearn.svm import SVR\n","251d8560":"from sklearn import pipeline \nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import model_selection # train_test_split\nfrom IPython.display import clear_output","68d9b0ad":"regressors = {\n    \"xgboost\": xgb.XGBRegressor(objective ='reg:linear', \n                  n_estimators = 10, seed = 123),\n    \"LinearRegression\": LinearRegression(),\n    \"Ridge\": Ridge(),\n    \"RidgeCV\": RidgeCV(),\n    \"SGDRegressor\": SGDRegressor(),              \n    \"ElasticNet\": ElasticNet(),\n    \"ElasticNetCV\": ElasticNetCV(),\n    \"Lars\": Lars(),\n    \"LarsCV\": LarsCV(),\n    \"Lasso\": Lasso(),\n    \"LassoCV\": LassoCV(),\n    \"LassoLars\": LassoLars(),\n    \"LassoLarsCV\": LassoLarsCV(),\n    \"LassoLarsIC\": LassoLarsIC(),\n    \"OrthogonalMatchingPursuit\": OrthogonalMatchingPursuit(),\n    \"OrthogonalMatchingPursuitCV\": OrthogonalMatchingPursuitCV(),                        \n    \"ARDRegression\": ARDRegression(),\n    \"BayesianRidge\": BayesianRidge(),                       \n    \"HuberRegressor\": HuberRegressor(),\n    \"RANSACRegressor\": RANSACRegressor(),\n    \"TheilSenRegressor\": TheilSenRegressor(),\n    \"TweedieRegressor\": TweedieRegressor(),\n    \"GammaRegressor\": GammaRegressor(),\n    \"PassiveAggressiveRegressor\": PassiveAggressiveRegressor(),\n    \"KNeighborsRegressor\": KNeighborsRegressor(),\n    \"RadiusNeighborsRegressor\": RadiusNeighborsRegressor(),\n    \"DecisionTreeRegressor\": DecisionTreeRegressor(),\n    \"ExtraTreeRegressor\": ExtraTreeRegressor(),\n    \"AdaBoostRegressor\": AdaBoostRegressor(),\n    \"BaggingRegressor\": BaggingRegressor(),\n    \"ExtraTreesRegressor\": ExtraTreesRegressor(),\n    \"GradientBoostingRegressor\": GradientBoostingRegressor(),\n    \"RandomForestRegressor\": RandomForestRegressor(),\n    \"IsotonicRegression\": IsotonicRegression(),\n    \"KernelRidge\": KernelRidge(),\n    \"LinearSVR\": LinearSVR(),\n    \"NuSVR\": NuSVR(),\n    \"SVR\": SVR(),\n}","00bbd2e7":"regressors = {name: pipeline.make_pipeline(model) for name, model in regressors.items()}","7a7b2dc4":"x = UNI_train_binary_num.drop(columns=[\"id\"]) # X DATA (WILL BE TRAIN+VALID DATA)\ny = UNI_train_binary_num[\"target\"]\n\nx_test = UNI_test_binary_num.drop(columns=['id']) # # X_TEST DATA (NEW DATA)","e1deaab3":"x_train, x_val, y_train, y_val = model_selection.train_test_split(\n    x, y,\n    test_size=0.2,\n    random_state=4  # Recommended for reproducibility\n)\n\nresults = pd.DataFrame({'Model': [], 'RMSE': []})\n\nfor model_name, model in regressors.items():\n\n    model.fit(x_train, y_train)\n    \n    pred = model.predict(x_val)\n    \n    results = results.append({\"Model\":    model_name,\n                              \"RMSE\": mean_squared_error(y_val, pred, squared=False)},\n                              ignore_index=True)\n    \n    results_ord = results.sort_values(by=['RMSE'], ascending=False, ignore_index=True)\n    results_ord.index += 1 \n    \n    clear_output(wait=True)\n    display(results_ord.style.bar(subset=['RMSE'], vmin=0, vmax=100, color='#5fba7d'))","4d7fc691":"Numerical columns dataframe with removed outliers:","28fa877a":"5. binary_log_NO","7c36c8cf":"## Test dataset","06eb1427":"9. ordinal_num_NO_TNO","66744203":"## Numerical columns","f06f2ac5":"15. freq_num_NO_TNO","9624aa34":"18. freq_log_NO_TNO","54081510":"13. freq_num","9d734f64":"6. binary_num_NO_TNO","df616329":"#### One-Hot Encoding:","b1fbb659":"## Numerical transformations:\n#### Log transformations:","d4111575":"We see that the log transformations are more correlated with the target when the outliers from the original numerical columns are **NOT REMOVED**.","4bc42e85":"1. binary_num","709e0509":"16. freq_log","9c2d347b":"## Univariate Feature Selection","096d90bc":"11. ordinal_log_NO","816bea71":"***","947bf6f1":"#### Check for outliers:","de8f0b4e":"18. freq_log_NO_TNO","f4f0ea4b":"We see the test set has the same features and range of values as the train set. So we do not make any changes to the train set in relation to the test set.","e14e68cf":"4. binary_num:","6a5678b8":"#### Check how the log transformations are correlated with target:","03926363":"7. ordinal_num","dc998bdf":"***","798b382a":"### Point for next step - modelling:\n- Try each different encoded set for the categorical_columns.\n- See which one gives best result in modelling.","ada57c1c":"***","d03e7e43":"***","b0c2a8a7":"4. binary_log","a09effdc":"# Feature Selection","6dc4a93a":"## Categorical Transformations:","12eb1c68":"In this notebook, I use several feature engineering and selection methods on the February Tabular Playground dataset. Due to this being synthetic data,feature engineering and selection produces lower accuracy results for prediction submissions than those without. However, I think it is worth sharing my approaches for others to learn from and potentially use in other competitions which use real data, where this appraoch would be appropriate.","35811068":"#### Frequency encoding","06f2bab1":"#### Binary Encoding:","1ee756f5":"16. freq_log","d1995a36":"# Test Dataset\n### Possible transformations","a7221128":"### Categorical columns:","b247da33":"1. binary_log:","71630fe1":"7. ordinal_num","ad675cc7":" - Requirements: feature_engine-1.0.2","22c4fd1f":"#### Ordinal Encoder:","68294e3d":"##### \"cont2\" outliers:","357e48f3":"14. freq_num_NO","470958ef":"#### Check how the log transformations are correlated with target:","c47836ff":"### Training datasets:","d3005e18":"## Numerical Columns without Outliers:","7d089bb9":"##### \"cont6\" outliers:","d6a3391d":"***","adefd69a":"***","1d9d611e":"### Target:","f9dbfaa8":"1. UNI_binary_num","d7b4cae7":"17. freq_log_NO","a81a2022":"#### Correlation matrix:","a69e561f":"## Exploratory Data Analysis","f97fda30":"8. ordinal_num_NO","70c173ec":"17. freq_log_NO","9d7a3f50":"***","0fe33439":"8. ordinal_num_NO","548ccbad":"10. ordinal_log","897cfa31":"2. binary_num_NO","9cf076da":"### Point:\nWhatever transformations we do to the train dataset, we must be consistent and do those changes to the test dataset too - to take as different csv's for the modelling step.\n\nFor example:\n- Binary encoded train set - must also have binary encoded test set.\n- Log transformed train set - must also have log transformed test set.","836bc9e5":"### Numerical Columns with Outliers:","237cb195":"6. binary_log_NO_TNO","c9209a8c":"## Test datasets:\n\n### **binary_categorical_test** with:\n- numerical_test\n- log_numerical_test\n\n### **ordinal_categorical_test** with:\n- numerical_test\n- log_numerical_test\n\n### **freq_categorical_test** with:\n- numerical_test\n- log_numerical_test","6fb449c5":"# Principle Component Analysis (PCA) Feature Selection","9947e058":"# Combining csv's accordingly:","5458ccc6":"### Training datasets:","f1fcc42c":"9. ordinal_num_NO_TNO","da780e93":"2. binary_log_NO","9cfd2728":"#### Check for outliers:","b8b02814":"#### Frequency encoding","500a603c":"# Put each of the full csv combinations through a pipeline like so. Not enough memory on this kaggle notebook to do this - continued on another notebook.\n\n# **Best result with train validation: 0.854**\n# **Best result with Kaggle test validation: 0.84186**","60ff3d09":"#### One-Hot Encoding:","98399698":"15. freq_num_NO_TNO","848cd381":"# Modelling","696d92b2":"##### \"cont0\" has outliers:","9648f3a0":"### Numerical columns:","d4e1331d":"#### Plots comparing original with log transformation","323a6a76":"#### Plots comparing original with log transformation","c192346a":"14. freq_num_NO","e5ed1a52":"***","c2569072":"***","3f3840e4":"#### Binary Encoding:","c0095b36":"3. binary_num_NO_TNO","e7369e62":"The outliers we see on the boxplot for \"cont2\" are not too bad according to the zscore, so we leave them in.","ad9eaa46":"The outliers we see on the boxplot for \"cont8\" are not too bad according to the zscore, so we leave them in.","07e195c0":"3. binary_log_NO_TNO","7e4415ac":"### **binary_categorical_columns** with:\n- numerical_columns\n- log_numerical_columns\n- numerical_columns_NO\n- log_numerical_columns_NO\n\n* ***target***\n* ***target_NO***\n\n### **ordinal_categorical_columns** with:\n- numerical_columns\n- log_numerical_columns\n- numerical_columns_NO\n- log_numerical_columns_NO\n\n* ***target***\n* ***target_NO***\n\n### **freq_categorical_columns** with:\n- numerical_columns\n- log_numerical_columns\n- numerical_columns_NO\n- log_numerical_columns_NO\n\n- ***target***\n* ***target_NO***","b06782c2":"12. ordinal_log_NO_TNO","fef71a00":"5. binary_num_NO","7231f65b":"##### \"cont8\" outliers:","c4c2ee55":"This shows that there is only one outlier that has a z-score greater than 3. We must locate this in order to remove it:","305d1217":"10. ordinal_log","3006fea7":"#### Ordinal Encoder:","f3c9f488":"# Feature Engineering Approach towards Tabular Playground Feb","95e91903":"11. ordinal_log_NO","45e16b22":"***","b3144af9":"13. freq_num","8e08d640":"# Feature Engineering\n## Categorical columns:","42ca1469":"12. ordinal_log_NO_TNO"}}