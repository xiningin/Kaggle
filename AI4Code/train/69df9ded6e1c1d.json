{"cell_type":{"643c85f0":"code","46a267a9":"code","0e975d38":"code","cb2a5377":"code","086ccf0e":"code","db7f2e86":"code","c59d1a1c":"code","b713a37d":"code","e9b78593":"code","d8743c1c":"code","e21a420f":"code","736f7522":"code","1c5edae0":"code","6e56ec2b":"markdown","59f5e181":"markdown","29368e80":"markdown","f436335b":"markdown","2edfe24a":"markdown","650cb232":"markdown","c0038e85":"markdown","947caa0f":"markdown","bb7ff21f":"markdown","baea9522":"markdown","f25cd646":"markdown","3451b2f6":"markdown","8c571406":"markdown"},"source":{"643c85f0":"!\/opt\/conda\/bin\/python3.7 -m pip install --upgrade pip\n! pip install -q efficientnet","46a267a9":"#Importing necessary Libraries\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport efficientnet.tfkeras as efn\nimport PIL\nfrom tensorflow.keras.layers import *","0e975d38":"# Creating necessary constants\nTRAIN_PATH = \"..\/input\/ml-hackathon\/seg_train\/seg_train\"\nVAL_PATH = \"..\/input\/ml-hackathon\/seg_test\/seg_test\"\nTEST_PATH = \"..\/input\/ml-hackathon\/seg_test\/seg_test\"\nPRED_PATH = \"..\/input\/ml-hackathon\/seg_pred\"\n\nBATCH_SIZE = 32\nHEIGHT,WIDTH = 150,150\nNUM_CLASSES = len(os.listdir(TRAIN_PATH))\nSEED = 143","cb2a5377":"def create_datagen(data_type = \"train\"):\n    if data_type == \"train\":\n        datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=40,\n    horizontal_flip=True,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range = 0.2, \n    zoom_range = 0.2\n   )\n    elif data_type == \"valid\":\n        datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255,\n   )\n    else:\n        print(\"Improper String given as input, Only one of ['train','valid'] should be given\")\n        datagen = None\n    return datagen\n\ndef create_dataset(datagen,path,data_type=\"train\"):\n    if data_type == \"train\":\n        dataset =datagen.flow_from_directory(\n                         path,\n                         target_size = (HEIGHT,WIDTH),\n                         batch_size = BATCH_SIZE,\n                         class_mode = \"categorical\",\n                         shuffle = True,\n                         seed = SEED\n                            )\n    elif data_type == \"valid\":\n        dataset = datagen.flow_from_directory(\n                      path,\n                      target_size = (HEIGHT,WIDTH),\n                      batch_size = BATCH_SIZE,\n                      shuffle = True,\n                      seed    =  SEED\n                       )\n    else:\n        print(\"Improper String given as input, Only one of ['train','valid'] should be given\")\n        dataset = None\n    return dataset\n\n\n\n\ntrain_datagen = create_datagen(\"train\")\nval_datagen = create_datagen(\"valid\")\n\ntrain_ds = create_dataset(train_datagen,TRAIN_PATH,\"train\")\nval_ds = create_dataset(val_datagen,VAL_PATH,\"valid\")\n\n#Preparing pred data for prediction\npred_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255,\n   )\npred_ds = pred_datagen.flow_from_directory(\n                      PRED_PATH,\n                      target_size = (HEIGHT,WIDTH),\n                      shuffle = False,\n                      batch_size = 32\n                       )\n\nclasses_dict = train_ds.class_indices\nclasses_dict = {v: k for k, v in classes_dict.items()}\nprint(\"Prediction to Label Matching: \", classes_dict)","086ccf0e":"path_train_ls = os.listdir(TRAIN_PATH)\nnum_train_ls = [len(os.listdir(os.path.join(TRAIN_PATH,folder))) for folder in path_train_ls]\n\npath_val_ls = os.listdir(VAL_PATH)\nnum_val_ls = [len(os.listdir(os.path.join(VAL_PATH,folder))) for folder in path_val_ls]\n\nplt.figure(figsize=(15,6))\nplt.subplot(1,2,1)\nplt.bar(path_train_ls,num_train_ls)\nplt.title(\"Training Data\")\nplt.xlabel(\"Class\")\nplt.ylabel(\"Number of Images present\")\n\nplt.subplot(1,2,2)\nplt.bar(path_train_ls,num_val_ls)\nplt.title(\"Validation Data\")\nplt.xlabel(\"Class\")\nplt.ylabel(\"Number of Images present\")\nplt.show()","db7f2e86":"plt.figure(figsize=(20,20))\n\nfor i,folder in enumerate(os.listdir(TRAIN_PATH)):\n    path = os.path.join(TRAIN_PATH,folder)\n    img_ls = os.listdir(path)\n    for j,im_name in enumerate(img_ls[:4]):\n        plt.subplot(6,4,4*i+j+1)\n        img_path = os.path.join(path,im_name)\n        img = PIL.Image.open(img_path)\n        plt.imshow(img)\n        plt.axis(\"off\")\n        plt.title(folder)","c59d1a1c":"def create_model():\n    pretrained = tf.keras.applications.DenseNet201(include_top=False,\n                                                      weights='imagenet',\n                                                      pooling=\"avg\",\n                                                      input_shape=[HEIGHT,WIDTH, 3])\n    \n    x = pretrained.output\n    x = tf.keras.layers.Dropout(0.3) (x)\n    x = tf.keras.layers.Dense(128) (x)\n    x = tf.keras.layers.LeakyReLU(alpha=0.2) (x)\n    x = tf.keras.layers.GaussianDropout(0.4) (x)\n    outputs = tf.keras.layers.Dense(NUM_CLASSES,activation=\"softmax\", dtype='float32')(x)\n        \n    model = tf.keras.Model(pretrained.input, outputs)\n    return model\n\nmodel = create_model()\n#model.summary() #It takes up more scrolling space. So commented it ","b713a37d":"def compile_model(model, lr=0.0001):\n    \n    optimizer = tf.keras.optimizers.Adam(lr=lr)\n    \n    loss = tf.keras.losses.CategoricalCrossentropy()\n        \n    metrics = [\n       tf.keras.metrics.CategoricalAccuracy(name='categorical_accuracy')\n    ]\n\n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n    return model","e9b78593":"def create_callbacks():\n    \n    cpk_path = '.\/best_model.h5'\n    \n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath=cpk_path,\n        monitor='val_categorical_accuracy',\n        mode='max',\n        save_best_only=True,\n        verbose=1,\n    )\n\n    reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor='val_categorical_accuracy',\n        mode='max',\n        factor=0.1,\n        patience=3,\n        verbose=0\n    )\n\n    earlystop = tf.keras.callbacks.EarlyStopping(\n        monitor='val_categorical_accuracy',\n        mode='max',\n        patience=10, \n        verbose=1\n    )\n    \n    callbacks = [checkpoint, reducelr, earlystop]         \n    \n    return callbacks","d8743c1c":"EPOCHS= 30\nVERBOSE =1\n\ntf.keras.backend.clear_session()\n\nwith tf.device('\/device:GPU:0'):\n    \n    model = create_model()\n    model = compile_model(model, lr=0.0001)\n   \n    callbacks = create_callbacks()\n    \n    history = model.fit(train_ds, \n                        epochs=EPOCHS,\n                        callbacks=callbacks,\n                        validation_data = val_ds,\n                        verbose=VERBOSE)","e21a420f":"acc = history.history['categorical_accuracy']\nval_acc = history.history['val_categorical_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(len(history.history['val_loss']))\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Categorical Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Categorical Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Categorical Accuracy')\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","736f7522":"MODEL_PATH = \".\/best_model.h5\"\n\nNUM_IMAGES = 0\n\nfor folder in os.listdir(TEST_PATH):\n    NUM_IMAGES+= len(os.listdir(os.path.join(TEST_PATH,folder)))\n\n#Preparing pred data for prediction\ntest_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255,\n   )\ntest_ds = test_datagen.flow_from_directory(\n                      TEST_PATH,\n                      target_size = (HEIGHT,WIDTH),\n                      shuffle = False,\n                      batch_size = NUM_IMAGES\n                       )\n\nclasses_dict = {0: 'buildings', 1: 'forest', 2: 'glacier', 3: 'mountain', 4: 'sea', 5: 'street'}\nmodel = tf.keras.models.load_model(MODEL_PATH)\n\n# predicting on test data\nfor batch in test_ds:\n    img_arr,labels = batch\n    labels = np.array(labels)\n    val_pred = model.predict(img_arr)\n    break\n\n# Accuracy calculation   \nval_predictions = [np.argmax(i) for i in val_pred]\nval_labels = [np.argmax(i) for i in labels]\nbool_arr = []\nbinary_ls = []\n\nfor i in range(NUM_IMAGES):\n    if val_predictions[i] == val_labels[i]:\n        bool_arr.append(1)\n        binary_ls.append('correct') \n    else:\n        bool_arr.append(0)\n        binary_ls.append(\"incorrect\")\n\ntest_accuracy = sum(bool_arr)\/len(bool_arr)\nprint(\"Test Accuracy: \",test_accuracy)\n\n#preparing csv file\npredictions = [classes_dict[i] for i in val_predictions]  #names of obtained labels\n\npred_df = pd.DataFrame(val_labels, columns=['original_label'])\npred_df[\"predicted_value\"]  = val_predictions\npred_df[\"result\"]  = binary_ls\npred_df.to_csv('.\/test.csv',index=False)","1c5edae0":"pred = model.predict(pred_ds)\npredictions = [classes_dict[np.argmax(i)] for i in pred]\n\n#preparing csv file\npred_df = pd.DataFrame(predictions, columns=['predictions'])\npred_df.to_csv('.\/prediction.csv',index=False)","6e56ec2b":"## I experimentd with many pretrained models including `EfficientNet`, but `DenseNet201` worked for me. I am still wondering how this happened\n\n### Happy coding\u2764","59f5e181":"# Callbacks\n\n* Callbacks are used to go through the results of train,valid after every epoch or evry run and make necessary changes or save the model etc.,\n* I used 3 callbacks in the model.\n1. `Model Checkpoint` to save the model with best `val_categorical_accuracy`.\n2. `Reduce ROn Plateau` to change the learning rate if the `val_categorical_accuracy` is not improving.\n3. `Early Stopping` is to stop model training if `val_categorical_accuracy` is not increasing or improving for certain `epochs` (10 here).","29368e80":"# Compiling the Model\n\n* Metric used for Training : **Categorical Accuracy**\n* Optimizer for Taining : **Adam**\n* Loss function for Training : **Categorical Cross Entropy**","f436335b":"# Prediction on unseen data","2edfe24a":"# Training","650cb232":"# Data Visualization","c0038e85":"# Creating Data Pipeline\n\n1. I used `Image Data Generator` of Tensorflow to add augmentations to the training data to make sure that the model is not overfitting.\n2. In case of `valid`,`test` datagen only rescaling is done.\n3. Next I used the `datagen` and `flow_from_directory` to create the dataset in batches.","947caa0f":"# Details of Hackathon\n* Competition Task : **Image Classification**\n* Library used : **TensorFlow**\n* Classes Present : **6 (Buildings,Forest,Glacier,Mountain,Street,Sea)**\n* Metric used for Testing : **Accuracy**\n* GPU used for Training : **NVIDIA TESLA P100**","bb7ff21f":"# Creating Model\n\n1. I used pretrained models for this task. **`ImageNet`** weights are used. \n2. I also added few FC layers at the top of pretrained model.\n3. Finally a softmax layer is added to get the probabilities of each class for a given Image.","baea9522":"## We can see that all the classes have almost same images in every class for both `training` and `validation` data. So **`Accuracy`** is the best metric for this `testing`.","f25cd646":"# Metrics Visualization\n### `history` saves all the metric values obtained throughout training","3451b2f6":"# Testing","8c571406":"#                 Techkriti ML Hackathon 2k21\n![Techkriti Logo](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/d\/d0\/Techkriti_logo.png\/220px-Techkriti_logo.png)\n\n### **Dataset will be made public soon** You can get the dataset [here](https:\/\/www.kaggle.com\/shanmukh05\/ml-hackathon)"}}