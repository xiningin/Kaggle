{"cell_type":{"a3fed5aa":"code","bc367646":"code","2b72eab7":"code","97f150eb":"code","50f9c7d3":"code","57d6b848":"code","e6746e32":"code","ca4f5049":"code","d5d03433":"code","4b8cf4fa":"code","d1e700dc":"code","e4876d7a":"code","9dc11c4c":"code","9e63c6c7":"code","ac5acabb":"code","434239da":"code","f7a7d73a":"code","c7357de4":"markdown","20d408ba":"markdown","b4f23d38":"markdown","a5419e6d":"markdown","f7a0ba34":"markdown","dc463dc2":"markdown","b29fec89":"markdown","cbbb8124":"markdown","b28fde53":"markdown","129ae5e3":"markdown","e39f0322":"markdown","37d75024":"markdown","44e6187a":"markdown","608d9281":"markdown","a207f4e6":"markdown","6de7d4ac":"markdown","54c89192":"markdown","678a842a":"markdown","7db6cdc8":"markdown","6cfc3382":"markdown","94490b10":"markdown","a99bd5fa":"markdown","b86ca6f8":"markdown","158ce8ac":"markdown"},"source":{"a3fed5aa":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom subprocess import check_output\n%matplotlib inline\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport os\nimport gc\n\nimport re\nfrom nltk.corpus import stopwords\n# import distance\nfrom nltk.stem import PorterStemmer\nfrom bs4 import BeautifulSoup","bc367646":"df = pd.read_csv(\"..\/input\/quora-question-pairs\/train.csv.zip\")","2b72eab7":"print(\"Number of data points:\",df.shape[0])\ndf.head()","97f150eb":"df.info()","50f9c7d3":"df.isna().sum()","57d6b848":"df[\"is_duplicate\"].value_counts().plot(kind='bar')\nplt.show()","e6746e32":"print(\"Question pairs are not Similar (is_duplicate = 0):  {}%\".format(100 - round(df[\"is_duplicate\"].mean()*100,2)))\nprint(\"Question pairs are Similar (is_duplicate =1):   {}%\".format(round(df[\"is_duplicate\"].mean()*100,2)))","ca4f5049":"qids = pd.Series(df[\"qid1\"].tolist() + df[\"qid2\"].tolist())\nunique_qs = len(np.unique(qids))\nprint ('Total number of  Unique Questions are: {}\\n'.format(unique_qs))\n\n\nqs_morethan_onetime = np.sum(qids.value_counts()>1)\n\nprint ('Number of unique questions that appear more than one time: {} ({}%)\\n'.format(qs_morethan_onetime,qs_morethan_onetime\/unique_qs*100))\n\nprint ('Max number of times a single question is repeated: {}\\n'.format(max(qids.value_counts()))) \n\nq_vals=qids.value_counts()\n\nq_vals=q_vals.values","d5d03433":"x = [\"Unique Questions\",\"Repeated Questions\"]\ny = [unique_qs,qs_morethan_onetime]\nplt.figure(figsize=(8,6))\nplt.title(\"Plot representing unique and repeated questions\")\nsns.barplot(x,y)\nplt.show()","4b8cf4fa":"#checking whether there are any repeated pair of questions\n\npair_duplicates = df[['qid1','qid2','is_duplicate']].groupby(['qid1','qid2']).count().reset_index()\n\nprint (\"Number of duplicate questions\",(pair_duplicates).shape[0] - df.shape[0])","d1e700dc":"plt.figure(figsize=(20, 10))\n\nplt.hist(qids.value_counts(), bins=160)\n\nplt.yscale('log', nonposy='clip')\n\nplt.title('Log-Histogram of question appearance counts')\n\nplt.xlabel('Number of occurences of question')\n\nplt.ylabel('Number of questions')\n\nprint ('Maximum number of times a single question is repeated: {}\\n'.format(max(qids.value_counts()))) ","e4876d7a":"#Checking whether there are any rows with null values\nnan_rows = df[df.isnull().any(1)]\nprint(nan_rows)","9dc11c4c":"# Filling the null values with ' '\ndf = df.fillna('')\nnan_rows = df[df.isnull().any(1)]\nprint(nan_rows)","9e63c6c7":"if os.path.isfile('df_fe_without_preprocessing_train.csv'):\n    df = pd.read_csv(\"df_fe_without_preprocessing_train.csv\",encoding='latin-1')\nelse:\n    df['freq_qid1'] = df.groupby('qid1')['qid1'].transform('count') \n    df['freq_qid2'] = df.groupby('qid2')['qid2'].transform('count')\n    df['q1len'] = df['question1'].str.len() \n    df['q2len'] = df['question2'].str.len()\n    df['q1_n_words'] = df['question1'].apply(lambda row: len(row.split(\" \")))\n    df['q2_n_words'] = df['question2'].apply(lambda row: len(row.split(\" \")))\n\n    def normalized_word_Common(row):\n        w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n        w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n        return 1.0 * len(w1 & w2)\n    df['word_Common'] = df.apply(normalized_word_Common, axis=1)\n\n    def normalized_word_Total(row):\n        w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n        w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n        return 1.0 * (len(w1) + len(w2))\n    df['word_Total'] = df.apply(normalized_word_Total, axis=1)\n\n    def normalized_word_share(row):\n        w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n        w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n        return 1.0 * len(w1 & w2)\/(len(w1) + len(w2))\n    df['word_share'] = df.apply(normalized_word_share, axis=1)\n\n    df['freq_q1+q2'] = df['freq_qid1']+df['freq_qid2']\n    df['freq_q1-q2'] = abs(df['freq_qid1']-df['freq_qid2'])\n\n    df.to_csv(\"df_fe_without_preprocessing_train.csv\", index=False)\n\ndf.head()","ac5acabb":"print (\"Minimum length of the questions in question1 : \" , min(df['q1_n_words']))\n\nprint (\"Minimum length of the questions in question2 : \" , min(df['q2_n_words']))\n\nprint (\"Number of Questions with minimum length [question1] :\", df[df['q1_n_words']== 1].shape[0])\nprint (\"Number of Questions with minimum length [question2] :\", df[df['q2_n_words']== 1].shape[0])","434239da":"plt.figure(figsize=(12, 8))\n\nplt.subplot(1,2,1)\nsns.violinplot(x = 'is_duplicate', y = 'word_share', data = df[0:])\n\nplt.subplot(1,2,2)\nsns.distplot(df[df['is_duplicate'] == 1.0]['word_share'][0:] , label = \"1\", color = 'red')\nsns.distplot(df[df['is_duplicate'] == 0.0]['word_share'][0:] , label = \"0\" , color = 'blue' )\nplt.show()","f7a7d73a":"plt.figure(figsize=(12, 8))\n\nplt.subplot(1,2,1)\nsns.violinplot(x = 'is_duplicate', y = 'word_Common', data = df[0:])\n\nplt.subplot(1,2,2)\nsns.distplot(df[df['is_duplicate'] == 1.0]['word_Common'][0:] , label = \"1\", color = 'red')\nsns.distplot(df[df['is_duplicate'] == 0.0]['word_Common'][0:] , label = \"0\" , color = 'blue' )\nplt.show()","c7357de4":"<h2 style=\"font-size:30px;background:#a9a799; border:0; color:black\" > 1.1 Description <\/h2>","20d408ba":"<p> The distributions of the word_Common feature in similar and non-similar questions are highly overlapping <\/p>","b4f23d38":"<p>Quora is a place to gain and share knowledge\u2014about anything. It\u2019s a platform to ask questions and connect with people who contribute unique insights and quality answers. This empowers people to learn from each other and to better understand the world.<\/p>\n<p>\nOver 100 million people visit Quora every month, so it's no surprise that many people ask similarly worded questions. Multiple questions with the same intent can cause seekers to spend more time finding the best answer to their question, and make writers feel they need to answer multiple versions of the same question. Quora values canonical questions because they provide a better experience to active seekers and writers, and offer more value to both of these groups in the long term.\n<\/p>\n<br>","a5419e6d":"- There are two rows with null values in question2 ","f7a0ba34":"- The distributions for normalized word_share have some overlap on the far right-hand side, i.e., there are quite a lot of questions with high word similarity\n- The average word share and Common no. of words of qid1 and qid2 is more when they are duplicate(Similar)","dc463dc2":"We are given a minimal number of data fields here, consisting of:\n\n- id:  Looks like a simple rowID\n- qid{1, 2}:  The unique ID of each question in the pair\n- question{1, 2}:  The actual textual contents of the questions.\n- is_duplicate:  The label that we are trying to predict - whether the two questions are duplicates of each other.","b29fec89":"Let us now construct a few features like:\n - ____freq_qid1____ = Frequency of qid1's\n - ____freq_qid2____ = Frequency of qid2's \n - ____q1len____ = Length of q1\n - ____q2len____ = Length of q2\n - ____q1_n_words____ = Number of words in Question 1\n - ____q2_n_words____ = Number of words in Question 2\n - ____word_Common____ = (Number of common unique words in Question 1 and Question 2)\n - ____word_Total____ =(Total num of words in Question 1 + Total num of words in Question 2)\n - ____word_share____ = (word_common)\/(word_Total)\n - ____freq_q1+freq_q2____ = sum total of frequency of qid1 and qid2 \n - ____freq_q1-freq_q2____ = absolute difference of frequency of qid1 and qid2 ","cbbb8124":"__ Problem Statement __\n- Identify which questions asked on Quora are duplicates of questions that have already been asked. \n- This could be useful to instantly provide answers to questions that have already been answered. \n- We are tasked with predicting whether a pair of questions are duplicates or not. ","b28fde53":"<h1 style=\"text-align:center;font-size:50px;background:#6D929B; border:0; color:black\" > Quora Question Pairs <\/h1>","129ae5e3":"<h3 style=\"font-size:25px;background:#a9a799; border:0; color:black\" >3.2.3 Checking for Duplicates <\/h3>","e39f0322":"<h1 style=\"text-align:center;font-size:30px;background:#a9a799; border:0; color:black\" > 1. Business Problem <\/h1>","37d75024":"<h3 style=\"font-size:25px;background:#a9a799; border:0; color:black\" > 3.2.4 Number of occurrences of each question <\/h3>","44e6187a":"**<span style=\"color:teal;\"> If you liked this Notebook, please do upvote.<\/span>**\n\n**<span style=\"color:teal;\"> If you have any suggestions or questions, I am all ears!<\/span>**\n\n**<span style=\"color:teal;\">Best Wishes!<\/span>**","608d9281":"<p> \n- Data will be in a file Train.csv <br>\n- Train.csv contains 5 columns : qid1, qid2, question1, question2, is_duplicate <br>\n- Size of Train.csv - 60MB <br>\n- Number of rows in Train.csv = 404,290\n<\/p>","a207f4e6":"<h3 style=\"font-size:25px;background:#a9a799; border:0; color:black\" > 2.1.1 Data Overview <\/h3>","6de7d4ac":"<h2 style=\"font-size:30px;background:#a9a799; border:0; color:black\" >3.3 Basic Feature Extraction (before cleaning) <\/h2>","54c89192":"<h4 style=\"font-size:20px;background:#a9a799; border:0; color:black\" > 3.3.1.2 Feature: word_Common <\/h4>","678a842a":"<h3 style=\"font-size:25px;background:#a9a799; border:0; color:black\" > 3.2.5 Checking for NULL values <\/h3>","7db6cdc8":"<h4> 3.3.1.1 Feature: word_share <\/h4>","6cfc3382":"<h3 style=\"font-size:25px;background:#a9a799; border:0; color:black\" > 3.2.1 Distribution of data points among output classes<\/h3>\n- Number of duplicate(smilar) and non-duplicate(non similar) questions","94490b10":"<h2 style=\"font-size:30px;background:#a9a799; border:0; color:black\" > 2.1 Data <\/h2>","a99bd5fa":"- Here are some questions have only one single words.","b86ca6f8":"<h3 style=\"font-size:25px;background:#a9a799; border:0; color:black\" > 3.2.2 Number of unique questions <\/h3>","158ce8ac":"<h3 style=\"font-size:25px;background:#a9a799; border:0; color:black\" > 3.3.1 Analysis of some of the extracted features <\/h3>"}}