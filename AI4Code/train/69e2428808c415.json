{"cell_type":{"99834304":"code","0d07e7df":"code","0f2ff6d9":"code","aaac77ad":"code","aa369520":"code","3c2ea673":"code","ff0599e2":"code","d0ad5818":"code","f6c541c8":"code","c370c982":"code","55f16c16":"code","3d363ed3":"code","ffaae929":"code","187f5648":"code","ecafa4c4":"code","3ab6aa9f":"code","0c930d56":"code","c74e7a14":"code","330f6e06":"markdown","b7cec199":"markdown","c3c5a584":"markdown","a329e45d":"markdown"},"source":{"99834304":"import numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nsns.set_style('whitegrid')","0d07e7df":"#loading dataset\n\ndf = pd.read_csv('..\/input\/titanic\/train.csv')","0f2ff6d9":"df.head(5)","aaac77ad":"#Checking for null values\n\ndf.isnull().sum()","aa369520":"#Tabular form of the datasets insights like mean,std,min,max\n\ndf.describe()","3c2ea673":"#to check for dtypes,null-values and columns\n\ndf.info()","ff0599e2":"#heatmap\n#to check null values\n\nsns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')\n#useful to check null values","d0ad5818":"#Box plot\n\nplt.figure(figsize=(12, 7))\nsns.boxplot(x='Pclass',y='Age',data=df,palette='winter')\n#here we used box plot so we can find mean of age w.r.t. Pclass","f6c541c8":"#Box plot\n\nplt.figure(figsize=(12, 7))\nsns.boxplot(x='Pclass',y='Fare',data=df,palette='winter')\n#here we used box plot so we can find mean of fare w.r.t. Pclass","c370c982":"#Hist plot\n\nsns.distplot(df['Age'].dropna(),kde=False,color='darkred',bins=30)","55f16c16":"#count plot\n\nsns.countplot(x='Survived',hue='Pclass',data=df,palette='rainbow')\n#here we used count plot to see how many people survived w.r.t. Pclass","3d363ed3":"#Now we will drop some cloumns which are not useful\n\ndf = df.drop(['Name','Cabin','Ticket'],axis=1)\n\n#You can also write above as\n#df.drop(['Name','Cabin','Ticket'],axis=1,inplace=True)","ffaae929":"#Computing Null values\n\n#df.fillna(method='bfill') \n#also inplce of 'bfill' you can use 'ffill'\n\n#Also you can create an specific function to fill NaN values by mean or any other value you want\n#these values we are using are the values we got from boxplot\n\ndef impute_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n\n        if Pclass == 1:\n            return 37\n\n        elif Pclass == 2:\n            return 29\n\n        else:\n            return 24\n\n    else:\n        return Age\n    \ndef impute_fare(cols):\n    Fare = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Fare):\n\n        if Pclass == 1:\n            return 92\n\n        elif Pclass == 2:\n            return 22\n\n        else:\n            return 12\n\n    else:\n        return Fare    \n    \ndf['Fare'] = df[['Fare','Pclass']].apply(impute_fare,axis=1)\n\ndf['Age'] = df[['Age','Pclass']].apply(impute_age,axis=1)","187f5648":"#Categorical data encoding\n\n#Label Encoder Encoding\n#it coverts categorical data to label in numeric\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nobjList = df.select_dtypes(include = \"object\").columns\nprint (objList)\n\nfor feat in objList:\n    df[feat] = le.fit_transform(df[feat].astype(str))\nprint (df.info())\n\n#One Hot Encoder Encoding\n#One hot encoding does is, it takes a column which has categorical data, which has been label encoded, \n#and then splits the column into multiple columns. \n#The numbers are replaced by 1s and 0s, depending on which column has what value\n\n#get_dummies encoding\n\n#objList = df.select_dtypes(include = \"object\").columns\n#print (objList)\n\n#for feat in objlist:\n#    dummy = pd.get_dummies(df[feat],drop_first=True,prefix=col)\n#    df = pd.concat([df,dummy], axis=1)\n#    del df[col]\n#while using get_dummies dont forget to do drop_first=True\n#Onehotencoding and get_dummies method are same but the difference is the use of library","ecafa4c4":"#to check null values\n\nsns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')","3ab6aa9f":"X = df.drop(['Survived'],axis=1) #features\ny = df['Survived'] #target","0c930d56":"#Splitting the dataset into train and test sets\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)","c74e7a14":"#feature scaling\n\n#Standard Scaler\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\n\n#MinMax Scaler\n#from sklearn.preprocessing import MinMaxScaler\n#msc = MinMaxScaler()\n#X_train = msc.fit_transform(X_train)\n#X_test = msc.transform(X_test)","330f6e06":" # Exploratory Data Analysis","b7cec199":"# Data Pre-processing","c3c5a584":"# Importing important libraries and dataset ","a329e45d":"Now we can see there are no null values and we completed are EDA and Data pre-processing."}}