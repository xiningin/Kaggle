{"cell_type":{"70215ca0":"code","a4341bf4":"code","c9584655":"code","7f4fcc1f":"code","1c6aec96":"code","13c3839e":"code","50d8d767":"code","00c6a0c6":"code","b8163de6":"code","ab5f4446":"code","9a3254d9":"code","2c4288f0":"code","8c48dc4e":"code","4ab040a3":"code","6062945f":"code","443556bb":"code","35620dc8":"code","6ec0560c":"code","451c1a66":"code","1ccdcc78":"code","a35efdb6":"code","69d539d0":"code","ef7b8793":"code","054fe94b":"code","b79a4243":"code","66b3d161":"code","28c733d1":"code","23d43181":"code","0aad0925":"code","acf4bba7":"code","3e8b4f6f":"code","0008cd94":"code","ae83e24a":"code","d150c21b":"markdown","aaa42699":"markdown","eaea0c28":"markdown","700bfea1":"markdown","2e37973c":"markdown","2887cb4c":"markdown","abd55e36":"markdown"},"source":{"70215ca0":"import cv2","a4341bf4":"f, axarr = plt.subplots(2,2)\nimg1 = cv2.imread('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train\/PNEUMONIA\/person1008_virus_1691.jpeg')\nimg2 = cv2.imread('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train\/PNEUMONIA\/person100_virus_184.jpeg')\nimg3 = cv2.imread('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train\/NORMAL\/IM-0131-0001.jpeg')\nimg4 = cv2.imread('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train\/NORMAL\/IM-0152-0001.jpeg')\naxarr[0,0].imshow(img1)\naxarr[0,1].imshow(img2)\naxarr[1,0].imshow(img3)\naxarr[1,1].imshow(img4)\n\n#img1.shape\n#img2.shape\n#img3.shape\n#img4.shape","c9584655":"import os\nimport pandas as pd","7f4fcc1f":"! pwd","1c6aec96":"path_train = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train'\npath_test = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/test'\npath_val = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/val'\n\nos.chdir(path_train)\nlists = os.listdir(path_train)\nlabels = []\nfile_lst = []\n\n#print(lists)\n\nfor folder in lists:\n    files = os.listdir(path_train +\"\/\"+folder)\n    for file in files:\n      path_file = path_train + \"\/\" + folder + \"\/\" + file\n      file_lst.append(path_file)\n      labels.append(folder)\n\ndictP_n = {\"path\": file_lst,\n           \"label_name\": labels,\n          \"label\": labels}   \n\ndata  = pd.DataFrame(dictP_n, index = None)\ndata = data.sample(frac=1)\ndata['label'] = data['label'].replace({\"NORMAL\": 0, \"PNEUMONIA\": 1 })\ndata.to_csv(\"\/kaggle\/working\/train.csv\", index =None)\n\n# ---------------------------------------------------------------------------\n\nos.chdir(path_test)\nlists = os.listdir(path_test)\nlabels = []\nfile_lst = []\n\n#print(lists)\n\nfor folder in lists:\n    files = os.listdir(path_test +\"\/\"+folder)\n    for file in files:\n      path_file = path_test + \"\/\" + folder + \"\/\" + file\n      file_lst.append(path_file)\n      labels.append(folder)\n\ndictP_n = {\"path\": file_lst,\n           \"label_name\": labels,\n          \"label\": labels}   \n\ndata  = pd.DataFrame(dictP_n, index = None)\ndata = data.sample(frac=1)\ndata['label'] = data['label'].replace({\"NORMAL\": 0, \"PNEUMONIA\": 1 })\ndata.to_csv(\"\/kaggle\/working\/test.csv\", index =None)\n\n# ------------------------------------------------------------------------------------\n\nos.chdir(path_val)\nlists = os.listdir(path_val)\nlabels = []\nfile_lst = []\n\n#print(lists)\n\nfor folder in lists:\n    files = os.listdir(path_val +\"\/\"+folder)\n    for file in files:\n      path_file = path_val + \"\/\" + folder + \"\/\" + file\n      file_lst.append(path_file)\n      labels.append(folder)\n\ndictP_n = {\"path\": file_lst,\n           \"label_name\": labels,\n          \"label\": labels}   \n\ndata  = pd.DataFrame(dictP_n, index = None)\ndata = data.sample(frac=1)\ndata['label'] = data['label'].replace({\"NORMAL\": 0, \"PNEUMONIA\": 1 })\ndata.to_csv(\"\/kaggle\/working\/val.csv\", index =None)","13c3839e":"data_train = pd.read_csv('\/kaggle\/working\/train.csv')","50d8d767":"data_train.tail(10)","00c6a0c6":"data_train.head(10)","b8163de6":"data_test = pd.read_csv('\/kaggle\/working\/test.csv')","ab5f4446":"data_test.tail(10)","9a3254d9":"data_test.tail(10)","2c4288f0":"data_val = pd.read_csv('\/kaggle\/working\/val.csv')","8c48dc4e":"data_val.shape","4ab040a3":"data_val.size","6062945f":"data_val.head(10)","443556bb":"data_val.tail(10)","35620dc8":"! pwd","6ec0560c":"os.chdir('\/kaggle\/working')","451c1a66":"! pwd","1ccdcc78":"! git clone https:\/\/github.com\/tueimage\/SE2CNN.git","a35efdb6":"! pip install tensorflow==1.13.1","69d539d0":"# Import tensorflow and numpy\nimport tensorflow as tf\nimport numpy as np\nimport math as m\nimport time\nimport glob\n\n# For validation\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\n# For plotting\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\n\n# Add the library to the system path\nimport os,sys\nse2cnn_source =  os.path.join(os.getcwd(),'\/kaggle\/working\/SE2CNN\/')\nif se2cnn_source not in sys.path:\n    sys.path.append(se2cnn_source)\n\n# Import the library\nimport se2cnn.layers","ef7b8793":"# help(se2cnn.layers.z2_se2n)\n# help(se2cnn.layers.se2n_se2n)\n# help(se2cnn.layers.spatial_max_pool)","054fe94b":"# Xavier's\/He-Rang-Zhen-Sun initialization for layers that are followed ReLU\ndef weight_initializer(n_in, n_out):\n    return tf.random_normal_initializer(mean=0.0, stddev=m.sqrt(2.0 \/ (n_in))\n    )","b79a4243":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","66b3d161":"def size_of(tensor) :\n    # Multiply elements one by one\n    result = 1\n    for x in tensor.get_shape().as_list():\n         result = result * x \n    return result","28c733d1":"data_train['path']","23d43181":"data_val['path']","0aad0925":"CANCERtraindata = data_train['path']\ntrain_data = np.array([np.array(Image.open(fname)) for fname in CANCERtraindata])\n\n# validation data\nCANCERtestdata = data_val['path']\neval_data = np.array([np.array(Image.open(fname)) for fname in CANCERtestdata])","acf4bba7":"data_train['label']","3e8b4f6f":"data_val['label']","0008cd94":"train_labels = data_train['label']\neval_labels = data_val['label']","ae83e24a":"print(\" Length of train_data \")\nprint(len(train_data))\nprint(\" Length of eval_data \")\nprint(len(eval_data))\n\nprint(\" Length of train_labels \")\nprint(len(train_labels))\nprint(\" Length of eval_labels \")\nprint(len(eval_labels))\n\n#print(' Train data ')\n#print(train_data)\n#print(' Test data ')\n#print(eval_data)\n\n#print(' Train labels ')\n#print(train_labels)\n#print(' Test labels ')\n#print(eval_labels)","d150c21b":"Confusion matrix plot","aaa42699":"Weight initialization For initialization we use the initialization method for ReLU activation functions as proposed in:\n\nHe, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 770-778).","eaea0c28":"Part 2: Load and format the dataset","700bfea1":"Size of a tf tensor","2e37973c":"Useful functions\n\nThe se2cnn layers\n\nFor useage of the relevant layers defined in se2cnn.layers uncomment and run the following:","2887cb4c":"Creating csv file for the dataset \n\nPNEUMONIA --> 1\n\nNORMAL    --> 0","abd55e36":"# Library used: The SE(2) group convolutional neural network library\n\n# Reference : Bekkers, E., Lafarge, M., Veta, M., Eppenhof, K., Pluim, J., Duits, R.:Roto-translation covariant convolutional networks for medical image analysis. Accepted at MICCAI 2018, arXiv preprint arXiv:1804.03393 (2018). \n\nAvailable at: https:\/\/arxiv.org\/abs\/1804.03393\n\nhttps:\/\/github.com\/tueimage\/SE2CNN"}}