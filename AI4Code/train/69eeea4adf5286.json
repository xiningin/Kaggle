{"cell_type":{"32964043":"code","b0e50405":"code","e86a61df":"code","1c633162":"code","50a5f2ca":"code","154b0cd7":"code","148ea2df":"code","ae400bd1":"code","6ec6a5ee":"code","6229372b":"code","cff4bf15":"code","230a92d5":"code","ca4958dc":"code","04c3c0ca":"code","b5998bdc":"code","39de0ced":"markdown"},"source":{"32964043":"####################################################################################################################################\n# Chest X-ray data stage 1 model - disease or no disease\n####################################################################################################################################\n\n# More than half the images in the dataset are labelled 'No Finding'.\n# The intent of this notebook is to create a model that can tell me, with some confidence, whether the X-ray has some pathology or not.\n# Once this is up and running, I can work with trying to figure out exactly what is wrong in the chest.\n\n\n# UPDATE: By the end of this notebook, I get an accuracy of about 64%, which is not good enough for me to move on to step 2.\n#         However, it can be used as a starting point for other beginners like me, so I guess its not totally wasted effort.\n#         Also, I looked at a lot of code examples from all over, and have totally lost track of my 'inspirations'. So here's\n#         a shout out to all those who have trodden this path before me.\n\n\nimport numpy as np \nimport pandas as pd\nfrom glob import glob \nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Concatenate, UpSampling2D, Conv2D, Reshape\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping , ModelCheckpoint , ReduceLROnPlateau\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom tensorflow.keras.backend import log, epsilon\nfrom tensorflow.keras.applications.mobilenet import preprocess_input\nfrom tensorflow.keras.layers import Dropout, BatchNormalization, Activation, Dense, Convolution2D\nfrom tensorflow.keras.layers import Flatten, MaxPooling2D, GlobalMaxPool2D, ZeroPadding2D\nfrom keras_preprocessing.image import ImageDataGenerator\n\nprint('Libraries loaded')","b0e50405":"# The images are in different folders. Let's get the path to all images into one column.\n\nmy_data = pd.read_csv('..\/input\/data\/Data_Entry_2017.csv')\nimage_paths = {os.path.basename(x): x for x in \n                   glob(os.path.join('..', 'input', 'data',  'images*', '*', '*.png'))}\nprint('Found:', len(image_paths), 'images')\nmy_data['Filepath'] = my_data['Image Index'].map(image_paths.get)\nmy_data.head(2)","e86a61df":"# Creating a list of all labels. There are 15 labels ('including No Finding'), so we'll use that information to stop the loop early.\n\nlist_of_labels = []\nfor idx in range(len(my_data)):\n    this_row_labels = my_data.loc[idx, 'Finding Labels']\n    split_labels    = this_row_labels.split('|') \n    for i in split_labels:\n        if i not in list_of_labels:\n            list_of_labels.append(i)\n    if len(list_of_labels) == 15:\n        print ('All labels gotten and stored in variable \"list_of_labels\"')         \n        break\nprint(list_of_labels)\n        ","1c633162":"# one-hot multilabel encoding\n\ndef clean_labels(text):\n    one_hot_labels = [0]*len(list_of_labels)\n    text_split = text.split('|')\n    for pos, t in enumerate(list_of_labels):\n        if t in (text_split):\n            one_hot_labels[pos] = 1\n    return pd.Series(one_hot_labels, index=list_of_labels)    \none_hot = pd.DataFrame(my_data['Finding Labels'].copy())\none_hot = one_hot['Finding Labels'].apply(clean_labels)\nprint(f'Variable \"one_hot\" now contains one hot multilabel values for target for {len(one_hot)} images') \ndisplay(one_hot.head())","50a5f2ca":"# Creating a dataframe for use in the \"flow_from_dataframe\" function\n\ncombined_df = one_hot.copy()\ncombined_df['Filepath'] = my_data['Filepath']","154b0cd7":"# Checking the value counts for \"No Finding\"\n\nprint('-'*120,'\\nValue Counts regarding \"No Finding\" \\n','-'*120)\nprint(combined_df['No Finding'].value_counts())\n# print(f'{c}{\" \"*pad}{100*combined_df[c].sum()\/len(combined_df):.2f} %\\timages')","148ea2df":"# train val test value creation and checking class balance\n\ncutoff_1 = int(0.94*len(combined_df))\ncutoff_2 = int(0.95*len(combined_df))\n\nbinary_df = combined_df[['No Finding','Filepath']]\ntraining_data = binary_df[:cutoff_1]\nval_data      = binary_df[cutoff_1:cutoff_2]\ntest_data     = binary_df[cutoff_2:]\n\nprint(training_data.shape, val_data.shape, test_data.shape)\nprint('Percentage of images with')\nfor i,j in zip([training_data, val_data, test_data], ['training_data', 'val_data', 'test_data']):\n    no_findings = np.round(100*i['No Finding'].sum()\/len(i),2)\n    print(f'{j} \\t{no_findings} %')\n\ntarget_cols = ['No Finding']    ","ae400bd1":"# THIS STEP TAKES A WHILE\n\nsize = (224,224) # choose as per pretrained model requirement\n\ndatagen_train = ImageDataGenerator(\n                                    rotation_range=2,\n                                    width_shift_range=0.05,\n                                    height_shift_range=0.05,\n                                    zoom_range=0.05,\n                                    fill_mode=\"nearest\",\n                                    rescale=1.\/255 )\n\ndatagen_test   = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator=datagen_train.flow_from_dataframe(dataframe  = training_data,\n                                            directory  = None,\n                                            x_col      = \"Filepath\",\n                                            y_col      = target_cols,\n                                            class_mode = \"raw\",\n                                            target_size= size,\n                                            seed       = 42,\n                                            batch_size = 32)\nval_generator  = datagen_test.flow_from_dataframe(dataframe  = val_data,\n                                            directory  = None,\n                                            x_col      = \"Filepath\",\n                                            y_col      = target_cols,\n                                            class_mode = \"raw\",\n                                            target_size= size,\n                                            seed       = 42,\n                                            batch_size = 32)\ntest_generator = datagen_test.flow_from_dataframe(dataframe  = test_data,\n                                            directory  = None,\n                                            x_col      = \"Filepath\",\n                                            y_col      = target_cols,\n                                            class_mode = \"raw\",\n                                            target_size= size,\n                                            seed       = 42,\n                                            batch_size = 32)\n\nprint('train_generator ,val_generator and test_generator are ready for use')","6ec6a5ee":"from keras.applications import VGG19 as pretrained_model\n# from keras.applications import ResNet152V2 as pretrained_model\n# from keras.applications import Xception as pretrained_model\n# from keras.applications import NASNetLarge as pretrained_model\n\nprint(f'pretrained model {pretrained_model} downloaded.')\ninput_shape = (size[0], size[1], 3)  # all images are 3 channel. I'm trying to keep the 'changeable' code to a minimum here.\nprint('input_shape', input_shape)    # just to be sure that this is what I want. Or rather, ensuring the model gets what the model wants.","6229372b":"# TRAINING FOR THE FIRST TIME\n\nconv_base         = pretrained_model(weights = 'imagenet', include_top = False, input_shape = input_shape)\nconv_base_length  = len(conv_base.layers)\nunfreeze_count    = 2 #  freeing up 2 layers\n\nfor pos, layr in enumerate(conv_base.layers):\n    layr.trainable = False\n    if pos+1  > conv_base_length - unfreeze_count:\n        print(pos+1, layr)\n        layr.trainable = True\nprint(f'Last {unfreeze_count} layers unfrozen.')        ","cff4bf15":"# Model Architecture\ntf.keras.backend.clear_session()\nmodel = Sequential()\nmodel.add(conv_base)\nmodel.add(Flatten())\nmodel.add(Dense(1, activation='sigmoid'))\nprint(model.summary())\n\n# basework for the callbacks\nmode = 'max'\nmonit = 'val_accuracy'\n\n# since I'm trying a binary classification with balanced classes, I'm happy to use accuracy as the metric.\n\n# The callbacks\neskb = EarlyStopping(monitor = monit, mode = mode, verbose = 1, patience = 4, restore_best_weights = True)\nmckb = ModelCheckpoint('stage_1_vgg19_model_02_layers.h5', monitor = monit, mode = mode, verbose=1, save_best_only=True)\n        # The model name in checkpointing reflects that I unfroze two layers, even if one is just maxpooling.\nrlkb = ReduceLROnPlateau(monitor = monit,  factor=0.1,    mode = mode, patience = 2, verbose = 1) \ncb   = [eskb, mckb, rlkb]","230a92d5":"#compile model\nmodel.compile(loss = 'binary_crossentropy',\n              optimizer  =  Adam(learning_rate=0.00001), metrics=['accuracy'])\n\nprint('Model compiled')  \nhistory = model.fit_generator(generator=train_generator,\n                    steps_per_epoch = 64,\n                    validation_data = val_generator,\n                    verbose=2, callbacks = cb,\n                    epochs=100)\nprint('All done !!')","ca4958dc":"# Now let us look at the effects of unfreezing another layer or two.\n# We will use the weights from our model as initialization, and keep a very low learning rate.\n\ntf.keras.backend.clear_session()\n# make sure to reload the right model !!\nour_trained_model  = keras.models.load_model('.\/stage_1_vgg19_model_02_layers.h5') # this loads our trained model\nour_weights        = our_trained_model.get_weights()    # this retrieves the weights\n\nconv_base          = pretrained_model(weights = 'imagenet', include_top = False, input_shape = input_shape)  # we reload the convbase with imagenet weights for now.\nconv_base_length   = len(conv_base.layers)\nprint('done')\n\n# since I want to possibly unlock more layers than 1, we split the cell here.\n# the next cell will let me iterate without reloading the model. Once I'm happy,\n# I'll load up the weights as planned.","04c3c0ca":"tf.keras.backend.clear_session()\nunfreeze_count    = 4                                # unfreeze count - COMPARE model summaries to see how many trainable parameters there are now\nfor pos, layr in enumerate(conv_base.layers):         # loop to unfreeze layers in the conv base.  \n    layr.trainable = False\n    if pos+1  > conv_base_length - unfreeze_count:\n        print(pos+1, layr)\n        layr.trainable = True\nprint(f'Last {unfreeze_count} layers unfrozen.')  \n\nmodel = Sequential()\nmodel.add(conv_base)\nmodel.add(Flatten())\nmodel.add(Dense(1, activation='sigmoid'))\nprint(model.summary())\nmodel.set_weights(our_weights)\n# Callbacks\neskb = EarlyStopping(monitor = monit, mode = mode, verbose = 1, patience = 4, restore_best_weights = True)\n# CHANGE MODEL SAVE NAME IN THE NEXT LINE\nsave_model_name = f'stage_1_NASNetLarge_model_{unfreeze_count}layers.h5'\nmckb = ModelCheckpoint(save_model_name, monitor = monit, mode = mode, verbose=1, save_best_only=True) \nrlkb = ReduceLROnPlateau(monitor = monit,  factor=0.1,    mode = mode, patience = 2, verbose = 1) \ncb   = [eskb, mckb, rlkb]\nprint(f'Model will be saved as {save_model_name}')","b5998bdc":"#compile model\nmodel.compile(loss = 'binary_crossentropy',\n              optimizer  =  Adam(learning_rate=0.00000001), metrics=['accuracy']) \n# Fitting with some layers unfrozen\nhistory = model.fit_generator(generator=train_generator,\n                    steps_per_epoch = 64,\n                    validation_data = val_generator,\n                    verbose = 2, callbacks = cb,\n                    epochs=100)\nprint('All done !!')","39de0ced":"So that did not seem to help. I can't seem to get beyond 64%, despite several experiments. Hopefully, you may be able to offer some suggestions. Please feel free to comment on this notebook and point out how and where I can do better. Thank you."}}