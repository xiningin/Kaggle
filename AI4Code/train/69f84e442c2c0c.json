{"cell_type":{"f99239c2":"code","90613a4b":"code","ed7323bc":"code","d3b64595":"code","1ca14f49":"code","bac1511d":"code","e6ed7360":"code","3ea3ff5d":"markdown","a8987c5d":"markdown","293d0072":"markdown","d7a5c425":"markdown"},"source":{"f99239c2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","90613a4b":"import pandas as pd\nfrom tqdm import tqdm\nimport threading\nimport requests \nfrom bs4 import BeautifulSoup as bs\nimport re\nfrom datetime import date\nimport datetime","ed7323bc":"main_url = 'https:\/\/economictimes.indiatimes.com'","d3b64595":"## New Approach :: Trying for O(n^2)\nf_date = date(1899,12,30)\ncurrent_datetime = datetime.datetime.today () ### End Date\nstart_date = date(2001,1,1) ### Hardcoded First day of  Archive News\nprint(start_date)\nprint(current_datetime)\ndata = []\nurls = []\nheadline = []\ncontent = []\ndateYear = []","1ca14f49":"##Find Range  and Start the loop\ndate_start_loop = date(2019,1,1) #any start date of your choice\nprint(date_start_loop)\ndate_end_loop = date(2019,1,2) #any end date\nprint(date_end_loop)\ncurrent_loop_date = date_start_loop","bac1511d":"while (current_loop_date <= date_end_loop):\n  try:\n    #print(\"hello IIMS\")\n    i= current_loop_date.year\n    j= current_loop_date.month\n    k= current_loop_date.day\n    l_date = date(i,j,k)\n    print(l_date)\n    delta = l_date - f_date\n    url = \"https:\/\/economictimes.indiatimes.com\/archivelist\/year-{},month-{},starttime-{}.cms\".format(i,j,delta.days)\n    #print(\"URL : \"+url)\n    req = requests.get(url).text\n    soup = bs(req, 'html.parser')\n    links = soup.find_all('table')[1].findAll('a')\n    #print(links)\n    for li in tqdm(links):\n      url = main_url+li.get('href')\n      #print(\":\",url)\n      req = requests.get(url).text\n      soup = bs(req, 'html.parser')\n      if len(soup.select('div.artText')) > 0:\n        headline.append(soup.h1.text)\n        content.append(soup.select('div.artText')[0].get_text().replace('\\r', '').replace('\\n', '').strip())\n        dateYear.append(l_date.strftime('%m\/%d\/%Y'))\n    \n    #n-=1\n    current_loop_date = current_loop_date+datetime.timedelta(days=1)\n  except Exception:\n    print(\"Exception\",Exception,\"ON : URL\", url)\n    current_loop_date = current_loop_date+datetime.timedelta(days=1)\n    \ndf = pd.DataFrame(list(zip(dateYear,headline,content)), \n               columns = ['Date','Headline', 'Content'])\n","e6ed7360":"df.to_csv(str(date_end_loop.year)+\"AllnLatestETNewsArchive.csv\")","3ea3ff5d":"This is a very simple and sweet wrapper for finding archive news from online portal of The Economic Times. Same code can be extended\/modified for other source as well. Folks who are doing NLP problems and are intrested in quality text data can use this notebook.","a8987c5d":"Source of the text data (News) Daily news!!","293d0072":"Finally save it, csv is all time favourite.","d7a5c425":"Magic happens with incrementing the date, that's all!!\nAlso, the way ET web portal is organized - that made the life easier."}}