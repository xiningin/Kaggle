{"cell_type":{"a59ec10a":"code","58848679":"code","6f1409f0":"code","9cda3b1c":"code","79038379":"code","108ae435":"code","9066e50b":"code","49db6130":"code","907bed8e":"code","c528fa3e":"code","3c50ccd6":"code","1fdd8d57":"code","3470cdce":"code","839cc09a":"code","2796caba":"code","a4aba8e0":"code","e25e3537":"code","45942031":"code","07e40c65":"code","8d872794":"code","fcd52721":"code","a911b874":"code","3f82ca2b":"markdown","76328479":"markdown","a24ad96e":"markdown","4aa67295":"markdown","10dc18cd":"markdown","e92899a5":"markdown","5f26c07f":"markdown","f9735307":"markdown","57a66d0a":"markdown","65108d2f":"markdown","c53f73a7":"markdown","0b1f902a":"markdown","4b170f23":"markdown","ee6ad6c2":"markdown"},"source":{"a59ec10a":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport keras\nimport warnings\n\nfrom os.path import join\nfrom keras import layers, Input, models\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.wrappers.scikit_learn import KerasClassifier \nfrom sklearn.model_selection import KFold \nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\n\ndatapath = join('data', 'wafer')\n\nprint(os.listdir(\"..\/input\"))\n\nwarnings.filterwarnings(\"ignore\")","58848679":" # image size drop\ndef find_dim(x):\n    dim0=np.size(x,axis=0)\n    dim1=np.size(x,axis=1)\n    return dim0,dim1\n\n # Data preprocessing process\ndef __Inputdf__(Hei, Wei):\n    sub_df = df.loc[df['waferMapDim'] == (Hei, Wei)]\n    sw = np.ones((1,  Hei, Wei))\n    label = list()\n\n    for i in range(len(sub_df)):\n        if len(sub_df.iloc[i, :]['failureType']) == 0:\n            continue\n        sw = np.concatenate((sw, sub_df.iloc[i,:]['waferMap'].reshape(1, Hei, Wei)))\n        label.append(sub_df.iloc[i, :]['failureType'][0][0])\n    \n    x = sw[1:]\n    y = np.array(label).reshape((-1,1))\n    \n    #add channel\n    x = x.reshape((-1, Hei, Wei, 1))\n    new_x = np.zeros((len(x), Hei, Wei, 3))\n\n    for w in range(len(x)):\n        for i in range(Hei):\n            for j in range(Wei):\n                new_x[w, i, j, int(x[w, i, j])] = 1\n    return new_x, y\n\n # Two ways to Scaling\ndef __InputTf1__(new_x):\n    new_result = tf.compat.v1.image.resize(new_x, (26,26),\n                                       method=tf.image.ResizeMethod.NEAREST_NEIGHBOR, \n                                       align_corners=True,\n                                       preserve_aspect_ratio=False, \n                                       name=None)\n    return new_result\ndef __InputTf2__(new_x):\n    new_result = tf.keras.preprocessing.image.smart_resize(new_x, \n                                                           (26,26),\n                                                           interpolation = 'nearest')\n    return new_result\n\n# augment function define\ndef gen_data(wafer, label):\n    # Encode input wafer\n    encoded_x = encoder.predict(wafer)\n    \n    # dummy array for collecting noised wafer\n    gen_x = np.zeros((1, 26, 26, 3))\n    \n    # Make wafer until total # of wafer to 2000\n    for i in range((2000\/\/len(wafer)) + 1):\n        noised_encoded_x = encoded_x + np.random.normal(loc=0, scale=0.1, size = (len(encoded_x), 13, 13, 64)) \n        noised_gen_x = decoder.predict(noised_encoded_x)\n        gen_x = np.concatenate((gen_x, noised_gen_x), axis=0)\n    # also make label vector with same length\n    gen_y = np.full((len(gen_x), 1), label)\n    \n    # return date without 1st dummy data.\n    return gen_x[1:], gen_y[1:]\n\n # Saving and loading new_x and new_y variables\ndef save_new_x(new_x):\n    f = open(\".\/save_new_x.csv\", \"w\")\n    for w in range(len(new_x)):\n        for i in range(26):\n            for j in range(26):\n                for o in range(3):\n                    f.write(str(new_x[w][i][j][o]))\n                \n    f.close()\n    return \n\n \"\"\" \n Save it as a csv file and \n take it out again to \n learn because of the lack of \n maximum memory inside Kaggle. \n \"\"\" ","6f1409f0":"df=pd.read_pickle(\"..\/input\/wm811k-wafer-map\/LSWMD.pkl\")\ndf.info()","9cda3b1c":"df.head()","79038379":"df.tail()","108ae435":"import matplotlib.pyplot as plt\n%matplotlib inline\n\n\nuni_Index=np.unique(df.waferIndex, return_counts=True)\nplt.bar(uni_Index[0],uni_Index[1], color='gold', align='center', alpha=0.5)\nplt.title(\" wafer Index distribution\")\nplt.xlabel(\"index #\")\nplt.ylabel(\"frequency\")\nplt.xlim(0,26)\nplt.ylim(30000,34000)\nplt.show()","9066e50b":"df = df.drop(['waferIndex'], axis = 1)","49db6130":"df['waferMapDim']=df.waferMap.apply(find_dim)\ndf.sample(5)","907bed8e":"%%time\nnew_x1, y1 = __Inputdf__(26, 26)\nnew_x2, y2 = __Inputdf__(25, 27)","c528fa3e":"%%time\nnew_Tf1_1 = __InputTf1__(new_x1)\nnew_Tf2_1 = __InputTf1__(new_x2)","3c50ccd6":"%%time\nnew_Tf1_2 = __InputTf2__(new_x1)\nnew_Tf2_2 = __InputTf2__(new_x2)","1fdd8d57":"# y = y1 + y2\ny = np.concatenate((y1, y2), axis=0)\n# new_x = new_x1 + new_x2\nnew_x= tf.concat([new_Tf1_1, new_Tf2_1], 0)","3470cdce":"# Using random sampling as a y array to put the none value into the none_idx variable\nnone_idx = np.where(y=='none')[0][np.random.choice(len(np.where(y=='none')[0]), size=11000, replace=False)]","839cc09a":"# delete the none value\nnew_x = np.delete(new_x, none_idx, axis=0)\nnew_y = np.delete(y, none_idx, axis=0)","2796caba":"faulty_case = np.unique(y)\n# make string label data to numerical data\nfor i, l in enumerate(faulty_case):\n    new_y[new_y==l] = i\n    \n# one-hot-encoding\nnew_y = to_categorical(new_y)","a4aba8e0":"# split data train, test\nx_train, x_test, y_train, y_test = train_test_split(new_x, new_y,\n                                                    test_size=0.33,\n                                                    random_state=2021)","e25e3537":"print('Train x : {}, y : {}'.format(x_train.shape, y_train.shape))\nprint('Test x: {}, y : {}'.format(x_test.shape, y_test.shape))","45942031":"# parameter\nepoch=15\nbatch_size=1024","07e40c65":"def create_model():\n    input_shape = (26, 26, 3)\n    input_tensor = Input(input_shape)\n\n    conv_1 = layers.Conv2D(16, (3,3), activation='relu', padding='same')(input_tensor)\n\n    flat = layers.Flatten()(conv_1)\n\n    dense_1 = layers.Dense(16, activation='relu')(flat)\n    output_tensor = layers.Dense(9, activation='softmax')(dense_1)\n\n    model = models.Model(input_tensor, output_tensor)\n    model.compile(optimizer='Adam',\n                 loss='categorical_crossentropy',\n                 metrics=['accuracy'])\n\n    return model","8d872794":"# Make keras model to sklearn classifier.\nmodel = KerasClassifier(build_fn=create_model, epochs=5, batch_size=2048, verbose=2) \n# 3-Fold Crossvalidation\nkfold = KFold(n_splits=3, shuffle=True, random_state=2019) \nresults = cross_val_score(model, x_train, y_train, cv=kfold)\n# Check 3-fold model's mean accuracy\nprint('Simple CNN Cross validation score : {:.4f}'.format(np.mean(results)))","fcd52721":"history = model.fit(x_train, y_train,\n         validation_data=(x_test, y_test),\n         epochs=epoch,\n         batch_size=batch_size,\n         )","a911b874":"# accuracy plot \nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\n# loss plot\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","3f82ca2b":"## Image Data Preprocessing","76328479":"- The dataset were collected from 47,543 lots in real-world fab. However, 47,543 lots x 25 wafer\/lot =1,157,325 wafer maps is larger than 811,457 wafer maps.\n\n- Let's see what happened.","a24ad96e":"### Simple 2D CNN Model\nThe data is ready. As wafer data is image. simply use cnn for classification.\n\nMake model\ndefine create model function, because we will validate model with sklearn kfold cross validation.","4aa67295":"**Target distribution**","10dc18cd":"- The figure shows that not all lots have perfect 25 wafer maps and it may caused by sensor failure or other unknown problems.\n\n- Fortunately, we do not need wafer index feature in our classification so we can just drop the variable.","e92899a5":"### Read data","5f26c07f":"- We can not get much information from the wafer map column but we can see the die size for each instance is different.\n\n- We create a new variable 'waferMapDim' for wafer map dim checking.","f9735307":"### Cross validate model\nUsing sklearn KFold Cross validation, we validate our simple cnn.","57a66d0a":"- Concatenated through datasets with two types of resolution","65108d2f":"- Two methods of TensorFlow library were used. \n- Wafers with different resolutions were resized to a resolution of (26x26). \n- Comparison of speed shows similar results.\n","c53f73a7":"### Resized using keras.preprocessing method","0b1f902a":"### Resized using compat.v1 method","4b170f23":"- The dataset comprises 811,457 wafer maps, along with additional information such as wafer die size, lot name and wafer index.\n\n- The training \/ test set were already split by domain experts, but in this kernel we ignore this info and we re-divided the dataset into training set and test set by hold-out mehtod which will be introduced in later section.","ee6ad6c2":"## Image Data Preprocessing\n\n### Get sub wafer with resolution.\nWafer is resized to have (26, 26) resolution. rearrange wafer nd-array with faulty case label.\nsome wafer has null label, skip it. \nFirst, let's create two types of resolution data by combining them."}}