{"cell_type":{"3ae2bdc5":"code","f9fb0236":"code","20716fd5":"code","04ef9c64":"code","b9b9716d":"code","910f3265":"code","4641a82a":"code","54b7e2bb":"code","e6051b87":"code","3b10c333":"code","1f03f73f":"code","0d181e28":"code","7baea60d":"code","a3ec8a7b":"code","4adfe6c0":"code","bc51f773":"code","63dafa6e":"code","12b0db8c":"code","22a6e0b7":"code","f2d8040f":"code","e9debd56":"code","4aa566c3":"code","bb946936":"code","00626f3a":"code","1aace714":"code","4b7bad2d":"code","34272773":"code","29431656":"code","eb412890":"code","8c52a0cc":"code","4de55736":"code","f1504e22":"code","c959ebe3":"code","c2c85082":"code","72d9063f":"code","82fad42d":"code","923f1028":"code","d30fdc81":"code","a934db92":"code","7a3f3884":"code","b4e2f187":"code","43954450":"code","bbe50510":"code","4d657e6c":"code","ef73d44c":"code","e773aa3d":"code","d80d39ff":"code","26818390":"code","7e340e49":"code","372e0d8f":"code","b481b96b":"code","0b92b684":"code","753f2e31":"code","0880ca9c":"code","577e4503":"code","3f45b1f9":"code","4c04d989":"code","90516063":"code","9e35a1e5":"code","ccb8d09b":"code","15a52e7a":"code","8f1af71d":"code","c3a9fe41":"code","c7ab0a0c":"code","bf6b42b0":"code","6bc5c2e0":"code","b96b606b":"code","4c7dcf4f":"code","53153f96":"code","b9daefb3":"code","7c595b15":"code","717b9929":"code","96b189f7":"code","e8e9c822":"code","8f111a42":"code","40e0c8e6":"code","2f421d68":"code","f7cfe949":"code","c9e88ee7":"code","1d661d8a":"code","3a2953f6":"code","a78dff8f":"code","d4c5663c":"code","f6c15b83":"code","4335cc1d":"code","6d30483e":"markdown","3d25c087":"markdown","54cd7411":"markdown","10b75885":"markdown","be7d6c2d":"markdown","2b4fb463":"markdown","a050a6f3":"markdown","1d9d634c":"markdown","2be31599":"markdown","321f6568":"markdown"},"source":{"3ae2bdc5":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","f9fb0236":"import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\nimport random\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, random_split, DataLoader\n\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nfrom torchvision.utils import make_grid","20716fd5":"DATA_DIR = '..\/input\/jovian-pytorch-z2g\/Human protein atlas\/'\nTRAIN_DIR = DATA_DIR + \"\/\" + \"train\"\nTEST_DIR = DATA_DIR + \"\/\" + \"test\"\nTRAIN_CSV = DATA_DIR +\"\/\" + \"train.csv\"","04ef9c64":"train_df = pd.read_csv(TRAIN_CSV)\ntrain_df.head()","b9b9716d":"labels = {\n    0: 'Mitochondria',\n    1: 'Nuclear bodies',\n    2: 'Nucleoli',\n    3: 'Golgi apparatus',\n    4: 'Nucleoplasm',\n    5: 'Nucleoli fibrillar center',\n    6: 'Cytosol',\n    7: 'Plasma membrane',\n    8: 'Centrosome',\n    9: 'Nuclear speckles'\n}","910f3265":"rev_labels = dict()\nfor key in labels.keys():\n    rev_labels[labels[key]] = key","4641a82a":"rev_labels","54b7e2bb":"def num_to_name(labels):\n    return [labels[i] for i in labels]","e6051b87":"def name_to_num(labels):\n    return [rev_labels[i] for i in labels]","3b10c333":"def set_seed(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True","1f03f73f":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","0d181e28":"set_seed(42)","7baea60d":"def encode_labels(label):\n    target = torch.zeros(10)\n    for l in str(label).split(' '):\n        target[int(l)] = 1.\n    return target","a3ec8a7b":"def decode_labels(target, thresh=0.5, return_label=False):\n    result = []\n    for i, tgt in enumerate(target):\n        if tgt > thresh:\n            if return_label:\n                result.append(str(i) + \":\" + labels[i] + \"\/\")\n            else:\n                result.append(str(i))\n            \n    return result","4adfe6c0":"class UnNormalize(object):\n    def __init__(self, mean, std):\n        self.mean = mean\n        self.std = std\n\n    def __call__(self, tensor):\n        \"\"\"\n        Args:\n            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n        Returns:\n            Tensor: Normalized image.\n        \"\"\"\n        for t, m, s in zip(tensor, self.mean, self.std):\n            t.mul_(s).add_(m)\n        return tensor","bc51f773":"def display_img(img, label=None, unnorm=False, unnorm_obj=None, invert=True, return_label=True):\n    if unnorm and unnorm_obj != None:\n        img = unnorm_obj(img)\n    \n    if invert:\n        plt.imshow(1 - img.permute((1, 2, 0)))\n    else:\n        plt.imshow(img.permute(1, 2, 0))\n    \n    if label != None:\n        plt.title(decode_labels(label, return_label=return_label))","63dafa6e":"def display_batch(batch, unnorm=False, unnorm_obj=None, invert=True):    \n    imgs, labels = batch\n    \n    if unnorm and unnorm_obj:\n        unnorm_imgs = []\n        for img in imgs:\n            if invert:\n                unnorm_imgs.append(1 - unnorm_obj(img))\n            else:\n                unnorm_imgs.append(unnorm_obj(img))\n        imgs = unnorm_imgs\n    else:\n        if invert:\n            imgs = 1 - imgs\n    \n    ig, ax = plt.subplots(figsize=(16, 8))\n    ax.set_xticks([]); ax.set_yticks([])\n    ax.imshow(make_grid(imgs, nrow=16).permute(1, 2, 0))","12b0db8c":"class ProteinDataset(nn.Module):\n    def __init__(self, root_dir, label_df, transforms=None):\n        assert(os.path.exists(root_dir))\n        self.root_dir = root_dir\n        self.label_df = label_df\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.label_df)\n    \n    def __getitem__(self, idx):\n        row = self.label_df.loc[idx]\n        img_id, label = row['Image'], row['Label']\n        img = Image.open(self.root_dir + \"\/\" + str(img_id) + \".png\")\n        if self.transforms:\n            img = self.transforms(img)\n        return img, encode_labels(label)","22a6e0b7":"'''\nThis code can be used to get mean and std of dataset\n\nmean = 0.\nstd = 0.\nnb_samples = 0.\nfor imgs, _ in loader:\n    batch_samples = imgs.size(0)\n    imgs = imgs.view(batch_samples, imgs.size(1), -1)\n    mean += imgs.mean(2).sum(0)\n    std += imgs.std(2).sum(0)\n    nb_samples += batch_samples\n\nmean \/= nb_samples\nstd \/= nb_samples\n'''","f2d8040f":"mean = [0.0793, 0.0530, 0.0545]\nstd = [0.1290, 0.0886, 0.1376]","e9debd56":"normalize = transforms.Normalize(mean=mean, std=std)\n\ntrain_tf = transforms.Compose([\n    transforms.RandomCrop(512, padding=8, padding_mode='symmetric'),\n    transforms.RandomHorizontalFlip(), \n    transforms.RandomRotation(10),\n    transforms.ToTensor(),\n    normalize,\n    transforms.RandomErasing(inplace=True)\n])\n\ntest_tf = transforms.Compose([\n    transforms.RandomCrop(512, padding=8, padding_mode='symmetric'),\n    transforms.ToTensor(),\n    normalize\n])","4aa566c3":"val_pct = 0.1","bb946936":"msk = np.random.rand(len(train_df)) < (1- val_pct)","00626f3a":"train_split_df = train_df[msk].reset_index()\nval_split_df = train_df[~msk].reset_index()","1aace714":"len(train_split_df), len(val_split_df)","4b7bad2d":"train_ds = ProteinDataset(TRAIN_DIR, train_split_df, train_tf)\nvalid_ds = ProteinDataset(TRAIN_DIR, val_split_df, test_tf)","34272773":"bs = 32","29431656":"train_loader = DataLoader(train_ds, bs, shuffle=True, num_workers=4, pin_memory=True)\nvalid_loader = DataLoader(valid_ds, bs, num_workers=4, pin_memory=True)","eb412890":"img, label = train_ds[0]","8c52a0cc":"display_img(img, label)","4de55736":"unnorm = UnNormalize(mean, std)","f1504e22":"display_img(img, label, unnorm=True, unnorm_obj=unnorm)","c959ebe3":"batch = next(iter(train_loader))","c2c85082":"display_batch(batch)","72d9063f":"def F_score(output, label, threshold=0.5, beta=1):\n    prob = output > threshold\n    label = label > threshold\n\n    TP = (prob & label).sum(1).float()\n    TN = ((~prob) & (~label)).sum(1).float()\n    FP = (prob & (~label)).sum(1).float()\n    FN = ((~prob) & label).sum(1).float()\n\n    precision = torch.mean(TP \/ (TP + FP + 1e-15))\n    recall = torch.mean(TP \/ (TP + FN + 1e-15))\n    F2 = (1 + beta**2) * precision * recall \/ (beta**2 * precision + recall + 1e-15)\n    return F2.mean(0)","82fad42d":"class AvgStats(object):\n    def __init__(self):\n        self.reset()\n        \n    def reset(self):\n        self.losses =[]\n        self.F1 =[]\n        self.its = []\n        \n    def append(self, loss, F1, it):\n        self.losses.append(loss)\n        self.F1.append(F1)\n        self.its.append(it)","923f1028":"import math\n\n\nclass CLR(object):\n    def __init__(self, optim, bn, base_lr=1e-7, max_lr=100):\n        self.base_lr = base_lr\n        self.max_lr = max_lr\n        self.optim = optim\n        self.bn = bn - 1\n        ratio = self.max_lr\/self.base_lr\n        self.mult = ratio ** (1\/self.bn)\n        self.best_loss = 1e9\n        self.iteration = 0\n        self.lrs = []\n        self.losses = []\n        \n    def calc_lr(self, loss):\n        self.iteration +=1\n        if math.isnan(loss) or loss > 4 * self.best_loss:\n            return -1\n        if loss < self.best_loss and self.iteration > 1:\n            self.best_loss = loss\n            \n        mult = self.mult ** self.iteration\n        lr = self.base_lr * mult\n        \n        self.lrs.append(lr)\n        self.losses.append(loss)\n        \n        return lr\n        \n    def plot(self, start=10, end=-5):\n        plt.xlabel(\"Learning Rate\")\n        plt.ylabel(\"Losses\")\n        plt.plot(self.lrs[start:end], self.losses[start:end])\n        plt.xscale('log')\n        \n        \n    def plot_lr(self):\n        plt.xlabel(\"Iterations\")\n        plt.ylabel(\"Learning Rate\")\n        plt.plot(self.lrs)\n        plt.yscale('log')","d30fdc81":"class OneCycle(object):\n    def __init__(self, nb, max_lr, momentum_vals=(0.95, 0.85), prcnt= 10, div=10, use_cosine=False):\n        self.nb = nb\n        self.div = div\n        self.high_lr = max_lr\n        self.low_mom = momentum_vals[1]\n        self.high_mom = momentum_vals[0]\n        self.use_cosine = use_cosine\n        if self.use_cosine:\n            self.prcnt = 0\n        else:\n            self.prcnt = prcnt\n        self.iteration = 0\n        self.lrs = []\n        self.moms = []\n        if self.use_cosine:\n            self.step_len =  int(self.nb \/ 4)\n        else:\n            self.step_len =  int(self.nb * (1- prcnt\/100)\/2)\n        \n    def calc(self):\n        if self.use_cosine:\n            lr = self.calc_lr_cosine()\n            mom = self.calc_mom_cosine()\n        else:\n            lr = self.calc_lr()\n            mom = self.calc_mom()\n        self.iteration += 1\n        return (lr, mom)\n        \n    def calc_lr(self):\n        if self.iteration ==  0:\n            self.lrs.append(self.high_lr\/self.div)\n            return self.high_lr\/self.div\n        elif self.iteration == self.nb:\n            self.iteration = 0\n            self.lrs.append(self.high_lr\/self.div)\n            return self.high_lr\/self.div\n        elif self.iteration > 2 * self.step_len:\n            ratio = (self.iteration - 2 * self.step_len) \/ (self.nb - 2 * self.step_len)\n            #lr = self.high_lr * ( 1 - 0.99 * ratio)\/self.div\n            lr = (self.high_lr \/ self.div) * (1- ratio * (1 - 1\/self.div))\n        elif self.iteration > self.step_len:\n            ratio = 1- (self.iteration -self.step_len)\/self.step_len\n            lr = self.high_lr * (1 + ratio * (self.div - 1)) \/ self.div\n        else :\n            ratio = self.iteration\/self.step_len\n            lr = self.high_lr * (1 + ratio * (self.div - 1)) \/ self.div\n        self.lrs.append(lr)\n        return lr\n\n    def calc_mom(self):\n        if self.iteration == 0:\n            self.moms.append(self.high_mom)\n            return self.high_mom\n        elif self.iteration == self.nb:\n            self.iteration = 0\n            self.moms.append(self.high_mom)\n            return self.high_mom\n        elif self.iteration > 2 * self.step_len:\n            mom = self.high_mom\n        elif self.iteration > self.step_len:\n            ratio = (self.iteration -self.step_len)\/self.step_len\n            mom = self.low_mom + ratio * (self.high_mom - self.low_mom)\n        else :\n            ratio = self.iteration\/self.step_len\n            mom = self.high_mom - ratio * (self.high_mom - self.low_mom)\n        self.moms.append(mom)\n        return mom\n\n    def calc_lr_cosine(self):\n        if self.iteration ==  0:\n            self.lrs.append(self.high_lr\/self.div)\n            return self.high_lr\/self.div\n        elif self.iteration == self.nb:\n            self.iteration = 0\n            self.lrs.append(self.high_lr\/self.div)\n            return self.high_lr\/self.div\n        elif self.iteration > self.step_len:\n            ratio = (self.iteration -self.step_len)\/(self.nb - self.step_len)\n            lr = (self.high_lr\/self.div) + 0.5 * (self.high_lr - self.high_lr\/self.div) * (1 + math.cos(math.pi * ratio))\n        else :\n            ratio = self.iteration\/self.step_len\n            lr = self.high_lr - 0.5 * (self.high_lr - self.high_lr\/self.div) * (1 + math.cos(math.pi * ratio))\n        self.lrs.append(lr)\n        return lr\n\n    def calc_mom_cosine(self):\n        if self.iteration == 0:\n            self.moms.append(self.high_mom)\n            return self.high_mom\n        elif self.iteration == self.nb:\n            self.iteration = 0\n            self.moms.append(self.high_mom)\n            return self.high_mom\n        elif self.iteration > self.step_len:\n            ratio = (self.iteration -self.step_len)\/(self.nb - self.step_len)\n            mom = self.high_mom - 0.5 * (self.high_mom - self.low_mom) * (1 + math.cos(math.pi * ratio))\n        else :\n            ratio = self.iteration\/self.step_len\n            mom = self.low_mom + 0.5 * (self.high_mom - self.low_mom) * (1 + math.cos(math.pi * ratio))\n        self.moms.append(mom)\n        return mom","a934db92":"def save_checkpoint(model, is_best, filename='data\/checkpoint.pth'):\n    \"\"\"Save checkpoint if a new best is achieved\"\"\"\n    if is_best:\n        torch.save(model.state_dict(), filename)  # save checkpoint\n    else:\n        print (\"=> Validation Accuracy did not improve\")","7a3f3884":"def load_checkpoint(model, filename = 'data\/checkpoint.pth'):\n    sd = torch.load(filename, map_location=lambda storage, loc: storage)\n    names = set(model.state_dict().keys())\n    for n in list(sd.keys()):\n        if n not in names and n+'_raw' in names:\n            if n+'_raw' not in sd: sd[n+'_raw'] = sd[n]\n            del sd[n]\n    model.load_state_dict(sd)","b4e2f187":"class AdaptiveConcatPool2d(nn.Module):\n    def __init__(self, sz=1):\n        super().__init__()\n        self.adavgp = nn.AdaptiveAvgPool2d(sz)\n        self.adamaxp = nn.AdaptiveMaxPool2d(sz)\n        \n    def forward(self, x):\n        x = torch.cat([self.adavgp(x), self.adamaxp(x)], 1)\n        x = x.view(x.size(0),-1)\n        return x","43954450":"class CustomClassifier(nn.Module):\n    def __init__(self, in_features, intermed_bn= 512, out_features=10, dout=0.25):\n        super().__init__()\n        self.fc_bn0 = nn.BatchNorm1d(in_features)\n        self.dropout0 = nn.Dropout(dout)\n        self.fc0 = nn.Linear(in_features, intermed_bn, bias=True)\n        self.fc_bn1 = nn.BatchNorm1d(intermed_bn, momentum=0.01)\n        self.dropout1 = nn.Dropout(dout * 2)\n        self.fc1 = nn.Linear(intermed_bn, out_features, bias=True)\n        \n    def forward(self, x):\n        x = self.fc_bn0(x)\n        x = self.dropout0(x)\n        x = F.relu(self.fc0(x))\n        x = self.fc_bn1(x)\n        x = self.dropout1(x)\n        x = self.fc1(x)\n        return x","bbe50510":"def update_lr(optimizer, lr):\n    for g in optimizer.param_groups:\n        g['lr'] = lr","4d657e6c":"def update_mom(optimizer, mom):\n    for g in optimizer.param_groups:\n        g['momentum'] = mom","ef73d44c":"def find_lr(model, loader, device):\n    t = tqdm(loader, leave=False, total=len(loader))\n    running_loss = 0.\n    avg_beta = 0.98\n    model.train()\n    for i, (ip, tgt) in enumerate(t):\n        ip, tgt = ip.to(device), tgt.to(device)\n        output = torch.sigmoid(model(ip))\n        loss = criterion(output, tgt)\n\n        running_loss = avg_beta * running_loss + (1-avg_beta) *loss.item()\n        smoothed_loss = running_loss \/ (1 - avg_beta**(i+1))\n        t.set_postfix(loss=smoothed_loss)\n\n        lr = clr.calc_lr(smoothed_loss)\n        if lr == -1 :\n            break\n        update_lr(optimizer, lr)   \n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()","e773aa3d":"# model = models.resnet34(pretrained=True)\nmodel = models.resnet50(pretrained=True)","d80d39ff":"model","26818390":"model.avgpool = AdaptiveConcatPool2d()\nmodel.fc = CustomClassifier(in_features=model.fc.in_features*2, out_features=10)","7e340e49":"for param in model.parameters():\n    param.require_grad = True\n    \nmodel = model.to(device)","372e0d8f":"criterion = nn.BCELoss()","b481b96b":"optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, weight_decay=1e-4)","0b92b684":"save_checkpoint(model, True, 'init.pth')","753f2e31":"clr = CLR(optimizer, len(train_loader))","0880ca9c":"find_lr(model, train_loader, device)","577e4503":"clr.plot()","3f45b1f9":"def train(epoch, model, optimizer, use_cycle=False, onecycle=None):\n    model.train()\n    global trn_F1, trn_losses, trn_time\n    running_loss = 0.\n    running_F1 = 0.\n    \n    start_time = time.time()\n    \n    t = tqdm(train_loader, leave=False, total=len(train_loader))\n\n    for i, (ip, tgt) in enumerate(t):\n        ip, tgt = ip.to(device), tgt.to(device)\n        \n        if use_cycle:    \n            lr, mom = onecycle.calc()\n            update_lr(optimizer, lr)\n            update_mom(optimizer, mom)\n                                    \n        output = torch.sigmoid(model(ip))\n        loss = criterion(output, tgt)\n        running_loss += loss.item()\n            \n        # Append outputs\n        running_F1 += F_score(tgt, output)\n        \n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n    trn_time = time.time() - start_time        \n    trn_F1 = running_F1\/len(train_loader)\n    trn_losses = running_loss\/len(train_loader)","4c04d989":"def test(model):\n    with torch.no_grad():\n        model.eval()\n        global best_F1\n        global val_F1, val_losses, val_time\n        running_loss = 0.\n        running_F1 = 0.\n        start_time = time.time()\n        \n        t = tqdm(valid_loader, leave=False, total=len(valid_loader))\n        \n        for i, (ip, tgt) in enumerate(t):\n            ip, tgt = ip.to(device), tgt.to(device)\n            output = torch.sigmoid(model(ip))\n            loss = criterion(output, tgt)\n            running_loss += loss.item()\n            running_F1 += F_score(tgt, output)\n            \n        val_time = time.time() - start_time\n        F1_score = running_F1\/len(valid_loader)\n        if F1_score > best_F1:\n            best_F1 = F1_score\n            save_checkpoint(model, True, '.\/best_model.pth')\n            \n        val_F1 = F1_score\n        val_losses = running_loss\/len(valid_loader)","90516063":"train_stats = AvgStats()\ntest_stats = AvgStats()","9e35a1e5":"best_F1 = 0\ntrn_time = 0\ntrn_losses = 0.0\ntrn_F1 = 0.0\nval_losses = 0.0\nval_F1 = 0.0\nval_time = 0","ccb8d09b":"def fit(model, optimizer, epochs, sched=None, use_cycle=False, onecycle=None):\n    print(\"Epoch\\tTrn_loss\\tVal_loss\\tTrn_F1\\t\\tVal_F1\")\n    for j in range(epochs):\n        train(j, model, optimizer, use_cycle=use_cycle, onecycle=onecycle)\n        train_stats.append(trn_losses, trn_F1, trn_time)\n        test(model)\n        test_stats.append(val_losses, val_F1, val_time)\n        if sched:\n            sched.step(j)\n        print(\"{}\\t{:06.8f}\\t{:06.8f}\\t{:06.8f}\\t{:06.8f}\"\n              .format(j+1, trn_losses, val_losses, trn_F1, val_F1))","15a52e7a":"epochs = 20","8f1af71d":"load_checkpoint(model, 'init.pth')","c3a9fe41":"optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, weight_decay=1e-4)","c7ab0a0c":"ocp = OneCycle(int(len(train_ds) * epochs \/bs), 1e-1, use_cosine=True)\n#sched = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.2)","bf6b42b0":"import time","6bc5c2e0":"fit(model, optimizer, epochs, use_cycle=True, onecycle=ocp)","b96b606b":"plt.xlabel(\"Epochs\")\nplt.ylabel(\"Losses\")\nplt.plot(train_stats.losses, 'r', label='train')\nplt.plot(test_stats.losses, 'g', label='valid')\nplt.legend()\nplt.show()","4c7dcf4f":"plt.xlabel(\"Epochs\")\nplt.ylabel(\"F1-score\")\nplt.plot(train_stats.F1, 'r', label='train')\nplt.plot(test_stats.F1, 'g', label='valid')\nplt.legend()\nplt.show()","53153f96":"def pred_single(img, return_label=True):\n    with torch.no_grad():\n        model.eval()\n        bs_img = img.unsqueeze(0)\n        bs_img = bs_img.to(device)\n        preds = torch.sigmoid(model(bs_img))\n        prediction = preds[0]\n        display_img(img, prediction, return_label)","b9daefb3":"TEST_CSV = '..\/input\/jovian-pytorch-z2g\/submission.csv'","7c595b15":"test_df = pd.read_csv(TEST_CSV)","717b9929":"test_ds = ProteinDataset(TEST_DIR, test_df, test_tf)","96b189f7":"img, label = test_ds[100]","e8e9c822":"pred_single(img)","8f111a42":"test_loader = DataLoader(test_ds, bs, num_workers=4, pin_memory=True)","40e0c8e6":"load_checkpoint(model, '.\/best_model.pth')","2f421d68":"def predict(loader):\n    with torch.no_grad():\n        torch.cuda.empty_cache()\n        model.eval()\n        preds = []\n        t = tqdm(loader, leave=False, total=len(loader))\n        for i, (ip, _) in enumerate(t):\n            ip = ip.to(device)\n            output = torch.sigmoid(model(ip))\n            preds.append(output.cpu().detach())\n        preds = torch.cat(preds)\n        return [\" \".join(decode_labels(pred)) for pred in preds]","f7cfe949":"preds = predict(test_loader)","c9e88ee7":"len(preds), len(test_df)","1d661d8a":"preds","3a2953f6":"sub_df = pd.read_csv(TEST_CSV)","a78dff8f":"sub_df.head()","d4c5663c":"sub_df['Label'] = preds","f6c15b83":"sub_df.head()","4335cc1d":"sub_df.to_csv('submission.csv', index=False)","6d30483e":"# Display Images","3d25c087":"# AdaptiveConcatPool and custom classifier","54cd7411":"# Save and load checkpoint","10b75885":"# Data Loading and some helper functions","be7d6c2d":"# One Cycle Policy\n\n(Github: https:\/\/github.com\/nachiket273\/One_Cycle_Policy)","2b4fb463":"# Dataset","a050a6f3":"# CLR\n\n(Github: https:\/\/github.com\/nachiket273\/One_Cycle_Policy)","1d9d634c":"# Set optimizer\/loss and find lr","2be31599":"# F1 Score\/Stats Function","321f6568":"# Train and Test"}}