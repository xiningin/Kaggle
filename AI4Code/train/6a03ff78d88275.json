{"cell_type":{"289ebb7f":"code","bce46bf1":"code","3171a29d":"code","bcda7870":"code","674c2ceb":"code","5fb25c95":"code","6420b097":"code","f047b6ba":"code","2bacdb99":"code","cb24f3e6":"code","7fc75f87":"code","13011000":"code","d81ee807":"code","a01bf397":"markdown","2ee62412":"markdown","2dd01bef":"markdown","8238000e":"markdown","83859b69":"markdown","8c3d55fd":"markdown","e781e01a":"markdown","c644838a":"markdown","94a24dd3":"markdown","b9434e5c":"markdown","0444725e":"markdown"},"source":{"289ebb7f":"import transformers\nimport pandas as pd\nimport re","bce46bf1":"data = pd.read_csv(\"..\/input\/pfizer-vaccine-tweets\/vaccination_tweets.csv\").head(100)\ndata.head()","3171a29d":"tweets = data['text'].values\ntweets[:5]","bcda7870":"def data_preprocess(words):\n    \n    # removing any emojis or unknown charcters\n    words = words.encode('ascii','ignore')\n    words = words.decode()\n    \n    # spliting string into words\n    words = words.split(' ')\n    \n    # removing URLS\n    words = [word for word in words if not word.startswith('http')]\n    words = ' '.join(words)\n    \n    # removing punctuations\n    words = re.sub(r\"[^0-9a-zA-Z]+\", \" \", words)\n    \n    # removing extra spaces\n    words = re.sub(' +', ' ', words) \n    return words","674c2ceb":"tweets = [data_preprocess(tweet) for tweet in tweets]\ntweets[:5]","5fb25c95":"sentiment = transformers.pipeline('sentiment-analysis')\nsummarizer = transformers.pipeline(\"summarization\")","6420b097":"sentiment(tweets[1])","f047b6ba":"sentiment(tweets[4])","2bacdb99":"sentiment(tweets[:5])","cb24f3e6":"tweet_sentiment_data = sentiment(tweets)\ntweet_sentiment_data = pd.DataFrame(tweet_sentiment_data)\ntweet_sentiment_data.head()","7fc75f87":"tweet_sentiment_data['label'].value_counts()","13011000":"summarizer(' '.join(tweets[:25]))","d81ee807":"summarizer(' '.join(tweets[-25:]))","a01bf397":"As observed above, the tweets are not complete and can be found on trailing URLs.  \nBefore begining with our task Let's first preprocess the data to remove URLs and Emojis.","2ee62412":"Sentiment for tweet at index 4\n> **Explain to me again why we need a vaccine BorisJohnson MattHancock whereareallthesickpeople PfizerBioNTech**","2dd01bef":"Many beginners might not be aware about this package but I believe it's G.O.A.T ( Greatest of All Times ).  \nIt's a handy package for beginners as well as experts due to simplicity of use.  \nIt has tonnes of [pretrained models](https:\/\/huggingface.co\/models) and also gives us access to train our own with both Tensorflow and PyTorch.  \n\nIt can be used for almost all NLP related tasks like\n- [Sequence Classification](https:\/\/huggingface.co\/transformers\/task_summary.html#sequence-classification) like Sentiment Analysis\n- [Question Answering](https:\/\/huggingface.co\/transformers\/task_summary.html#extractive-question-answering)\n- [Summarisation](https:\/\/huggingface.co\/transformers\/task_summary.html#summarization)\n- and many [more](https:\/\/huggingface.co\/transformers\/task_summary.html)\n\nIn this Notebook I'll brief you about Sentiment Analysis and Summarisation using pretrained model to get you started with Hugging Face. ","8238000e":"# [Hugging Face](https:\/\/huggingface.co\/)\n![](https:\/\/huggingface.co\/front\/assets\/huggingface_logo.svg)","83859b69":"Hence we observe the dataset has More **Negative** tweets than **Positive**.  \nAs the API is traind on large and standardised data we can trust our predictions to a great extend. However if you want to train for your own data, you can refer [here](https:\/\/huggingface.co\/transformers\/task_summary.html#sequence-classification)\n\nNOTE: The score here refers to te probability of the label.","8c3d55fd":"## [Pipelines](https:\/\/huggingface.co\/transformers\/main_classes\/pipelines.html)\nThe pipelines are a great and easy way to use models for inference. These pipelines are objects that abstract most of the complex code from the library, offering a simple API dedicated to several tasks.  \nThis will download the pretrained models one time and then can be reused when ever required.","e781e01a":"Sentiment for tweet at index 1\n> **While the world has been on the wrong side of history this year hopefully the biggest vaccination effort we ve ev**","c644838a":"We can easily use the same API for batches of data as given below.  \nThis might take some time.","94a24dd3":"As we're only focusing on tweets we'll extract the Text column.  \nLet's print first 5 tweets in the Dataset.","b9434e5c":"I hope the notebook helped you in getting started with NLP and Hugging Face.","0444725e":"Let's try summarization of some tweets. As tweet themselves are small entities we'll join first 25 and see the results. The methods can be extended just sentiment analysis."}}