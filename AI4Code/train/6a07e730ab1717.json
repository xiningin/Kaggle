{"cell_type":{"e4fced2d":"code","173a00af":"code","ea8415bc":"code","b41f98cf":"code","65b296f5":"code","a40bc9ae":"code","7bfa4fca":"code","e5ef9dd0":"code","a022a196":"code","4b94e883":"code","238b5bf6":"code","b938ccfa":"code","f7c0ab37":"code","f961553b":"code","f60474c4":"code","efcd69ab":"code","6870356a":"code","13ab86d2":"code","1c0ca712":"code","24a6515c":"code","02cfac84":"code","3b0570a4":"code","5a1e70a8":"code","6dec7950":"code","311ea2cb":"code","c6ff79ed":"code","4b97a262":"code","ecc44d3c":"code","e9d2199b":"code","2826e17d":"code","f4837ba0":"code","2d305a56":"code","6f46da94":"code","3b55f6ee":"code","98bf0c08":"code","6b334e41":"code","e57287f2":"code","629dda15":"code","f9de07b3":"code","c2dc1777":"code","8aa142ba":"code","f378756b":"code","b18afaba":"code","0ee882f5":"code","1dcad5cd":"code","d40bdcb8":"code","13cb7554":"code","93883254":"code","c25248c5":"markdown","68441cbe":"markdown","9957a5d9":"markdown","e9b9dd9f":"markdown","7ba65540":"markdown"},"source":{"e4fced2d":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nfrom sklearn.manifold import TSNE\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC  \nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import accuracy_score\nimport missingno\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","173a00af":"traindata = pd.read_csv(\"..\/input\/mymusicalprefrences\/train.csv\")\ntestdata = pd.read_csv(\"..\/input\/mymusicalprefrences\/test.csv\")\n\nmusic_dataset = pd.concat([traindata, testdata]).reset_index(drop=True)\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\npalette = ['#2596be',\"#e28743\",\"#80391e\"]\nsns.palplot(palette)","ea8415bc":"music_dataset.head()","b41f98cf":"music_dataset.size","65b296f5":"missingno.bar(music_dataset, color=palette, figsize=(30,6))","a40bc9ae":"testdata.columns = [i.strip() for i in testdata.columns]\ntraindata.columns = [i.strip() for i in traindata.columns]","7bfa4fca":"print(testdata.columns)","e5ef9dd0":"print(traindata.columns)","a022a196":"raw1 = traindata.drop(['Id'],axis=1)","4b94e883":"raw1.info()","238b5bf6":"testdata.info()","b938ccfa":"raw1.describe()","f7c0ab37":"raw2 = raw1.drop(['Album_type','Version'],axis=1)\ntestdata=testdata.drop(['Album_type','Version'],axis=1)\ntestdata['Vocal'].fillna('N',inplace=True)\nraw2 = raw2.reset_index(drop=True)","f961553b":"raw3 = raw2.dropna()\nraw3","f60474c4":"print(raw3.columns.values)","efcd69ab":"resort_columns=['Category','Duration','Release_year', 'BPM','Energy','Dancebility', 'Happiness','Artists', 'Track',  'Artists_Genres', 'Album',\n       'Labels', 'Key', 'Vocal', 'Country']\nresort_columns_t=['Duration','Release_year', 'BPM','Energy','Dancebility', 'Happiness','Artists', 'Track',  'Artists_Genres', 'Album',\n       'Labels', 'Key', 'Vocal', 'Country']\nraw4=raw3[resort_columns]\ntestdata=testdata[resort_columns_t]","6870356a":"y_train=raw4['Category']\nraw4=pd.concat([raw4.drop(['Category'],axis=1),testdata],axis=0)","13ab86d2":"print('Artists:',len(raw4['Artists'].unique()))\nprint('Track:',len(raw4['Track'].unique()))\nprint('Key:',len(raw4['Key'].unique()))\nprint('Artists_Genres:',len(raw4['Artists_Genres'].unique()))\nprint('Vocal:',raw4['Vocal'].unique())\nprint('Country:',len(raw4['Country'].unique()))","1c0ca712":"print(raw4['Track'].value_counts())\nprint(raw4['Artists'].value_counts())\nprint(raw4['Vocal'].value_counts())","24a6515c":"raw4 = raw4.drop(['Track'],axis=1)","02cfac84":"raw4[\"isMajor\"], raw4[\"Key\"] = raw4[\"Key\"].apply(lambda x: x.split(\" \")[1]), raw4[\"Key\"].apply(lambda x: x.split(\" \")[0])\nraw4.loc[:,\"Key\"] = raw4[\"Key\"].replace({\"D\u266d\": \"C#\", \"E\u266d\": \"D#\", \"G\u266d\": \"F#\", \"A\u266d\": \"G#\",\"B\u266d\":\"A#\"})\n\nraw4.loc[:,\"isMajor\"] = (raw4[\"isMajor\"]==\"Major\").astype(int)","3b0570a4":"keydum = pd.get_dummies(raw4[\"Key\"])\nkeydum = keydum.reset_index(drop=True)","5a1e70a8":"def key2dum(key):\n    list_h=[]\n    list_l=[]\n    list_M=[]\n    for i in range(len(key)):\n        if '#' in key[i]:\n            list_h.extend([1])\n        else:\n            list_h.extend([0])\n        if '\u266d' in key[i]:\n            list_l.extend([1])\n        else:\n            list_l.extend([0])\n        # see major or not\n        if 'Major' in key[i]:\n            list_M.extend([1])\n        else:\n            list_M.extend([0])\n    dummydummy=pd.DataFrame({'#':list_h,'b':list_l,'Major or not':list_M})   \n    return dummydummy","6dec7950":"raw4 = raw4.reset_index(drop=True)\nkeydum = key2dum(raw4['Key'])\nkeydum","311ea2cb":"raw4 = raw4.reset_index(drop=True)\ndef voc2dum(key):\n    list_F=[]\n    list_M=[]\n    list_N=[]\n    for i in range(len(key)):\n        if 'F' in key[i]:\n            list_F.extend([1])\n        else:\n            list_F.extend([0])\n        # see major or not\n        if 'M' in key[i]:\n            list_M.extend([1])\n        else:\n            list_M.extend([0])\n        if 'N' in key[i]:\n            list_N.extend([1])\n        else:\n            list_N.extend([0])\n    dummydummy=pd.DataFrame({'VF':list_F,'VM':list_M,'VM':list_N})   \n    return dummydummy","c6ff79ed":"vocdum=voc2dum(raw4['Vocal'])\nvocdum","4b97a262":"unique = []\nfor i in raw4.index:\n    unique.extend(raw4.loc[i,'Artists_Genres'].split(\"|\"))\n\nSuni = pd.Series(unique)\nprint(len(Suni.unique()))\nSuni = Suni.unique()","ecc44d3c":"def style2dum(form,col):\n    data=np.zeros((len(col),len(form)))\n    for i in range(len(form)):\n        for j in range(len(col)):\n            if form[i] in col[j]:\n                data[j][i]=1\n    quasidum = pd.DataFrame(data )\n    return quasidum","e9d2199b":"stydum = style2dum(Suni,raw4['Artists_Genres'])\nstydum.columns = Suni\nstydum.columns","2826e17d":"stydum","f4837ba0":"den = stydum.sum(axis=1)\nimport math\n\nfor i in range(946):\n    for j in Suni:\n        stydum.loc[i,j]\/=math.sqrt(den[i])","2d305a56":"embedding = TSNE(n_components = 2, init = \"pca\")\nesd = embedding.fit_transform(stydum)\nesd = pd.DataFrame(esd, columns = [\"sty_tsne1\",\"sty_tsne2\"])","6f46da94":"extdum = pd.get_dummies(raw4['Country'])\nembedding1 = TSNE(n_components=2, init=\"pca\")\nesd1 = embedding1.fit_transform(extdum)\nesd1 = pd.DataFrame(esd1,columns=[\"con_tsne1\",\"con_tsne2\"])\n","3b55f6ee":"namedum = pd.get_dummies(raw4['Artists'])\nembedding2 = TSNE(n_components=3, init=\"pca\")\nesd2 = embedding1.fit_transform(namedum)\nesd2 = pd.DataFrame(esd1,columns=[\"name_tsne1\",\"name_tsne2\"])","98bf0c08":"raw5 = pd.concat([raw4,esd,esd1,vocdum,keydum],axis=1)\nraw5 = raw5.drop(['Artists_Genres','Key','Vocal','Country','Artists','Album','Labels'],axis = 1)\nraw5","6b334e41":"scaler = MinMaxScaler()\nscaler.fit(raw5)\n\nraw5 = pd.DataFrame(data=scaler.transform(raw5),columns = raw5.columns,index=raw5.index)\n\nraw5.to_csv('clean_data.csv',index=0)\n\nX_train=raw5[raw5.index<len(y_train)]\nX_test =raw5[raw5.index>=len(y_train)]\n\nXt_train, Xt_test, yt_train, yt_test = train_test_split(X_train, y_train, test_size = 0.20,random_state=5467)","e57287f2":"svclassifier = SVC(kernel='poly')\nfitted = svclassifier.fit(Xt_train, yt_train)\ny_pred = svclassifier.predict(Xt_test)\n\nsvclassifierl = SVC(kernel='linear')\nfittedl = svclassifierl.fit(Xt_train, yt_train)\ny_predl = svclassifierl.predict(Xt_test)","629dda15":"KN = KNeighborsClassifier()\nKN.fit(Xt_train,yt_train)\nKN_pred = KN.predict(Xt_test)","f9de07b3":"rf = RandomForestClassifier()\nrf.fit(Xt_train,yt_train)\nrf_pred = rf.predict(Xt_test)","c2dc1777":"gd = GradientBoostingClassifier()\ngd.fit(Xt_train,yt_train)\ngd_pred = gd.predict(Xt_test)","8aa142ba":"decision_tree = DecisionTreeClassifier()\ndecision_tree.fit(Xt_train,yt_train)\ntree_pred = decision_tree.predict(Xt_test)","f378756b":"regr = LogisticRegression() \nregr.fit(Xt_train, yt_train)\nLog_pred = regr.predict(Xt_test)","b18afaba":"print('Logistic_Regression:',accuracy_score(yt_test, Log_pred)*100,'%')\nprint('Decision Tree:', accuracy_score(yt_test, tree_pred)*100,'%') # to summarize all\nprint('Random Forest:', accuracy_score(yt_test, rf_pred)*100,'%')\nprint('Gradient Boost:', accuracy_score(yt_test, gd_pred)*100,'%')\nprint('KNeighbors:',accuracy_score(yt_test, KN_pred)*100,'%')\nprint('SVM_p:',accuracy_score(yt_test, y_pred)*100,'%')\nprint('SVM_l:',accuracy_score(yt_test, y_predl)*100,'%')","0ee882f5":"gd_scored = cross_val_score(gd,X_train,y_train,cv=5)\nprint(gd_scored)\nprint(confusion_matrix(yt_test,gd_pred))\nprint(classification_report(yt_test,gd_pred))","1dcad5cd":"rf_scored=cross_val_score(rf,X_train,y_train,cv=5)\nprint(rf_scored)\nprint(confusion_matrix(yt_test,rf_pred))\nprint(classification_report(yt_test,rf_pred))","d40bdcb8":"final_pred = gd.predict(X_test)\nfinal_pred","13cb7554":"final_pred=pd.DataFrame({'Id':np.linspace(665,964,300,dtype=np.int16),'Category':final_pred})\nfinal_pred.to_csv('submission.csv',index=0)","93883254":"final_pred.head()","c25248c5":"Listing all unique Artists_Genres","68441cbe":"The same song with different key or other things is a problem \\\nWe assume that the name is less important than the other features, so we'll just drop it.","9957a5d9":"We can see that Random Forest and Gradient Boost. Let's go to see how good they are more precisely.\n","e9b9dd9f":"Then first I will make a linear model for testing, that is, assume that the effects are linearly added.","7ba65540":"We decide to drop irrelated columns, after that we will delete all line with null-value "}}