{"cell_type":{"d771a30f":"code","44e05c84":"code","2ddf5d0d":"code","3a1112e1":"code","31dff55f":"code","0bcbca3e":"code","45dfd64f":"code","8d56443e":"code","5edf3700":"code","9b754a2d":"markdown","0bd740dd":"markdown","06670cc3":"markdown","e360cc77":"markdown","03dfc1ab":"markdown","40a11755":"markdown","c2a94579":"markdown","852b5efb":"markdown"},"source":{"d771a30f":"!pip install transformers","44e05c84":"from __future__ import print_function\nimport ipywidgets as widgets\nfrom transformers import pipeline","2ddf5d0d":"nlp_sentence_classif = pipeline('sentiment-analysis')\nnlp_sentence_classif('Such a nice weather outside !')","3a1112e1":"nlp_token_class = pipeline('ner')\nnlp_token_class('Hugging Face is a French company based in New-York.')","31dff55f":"nlp_qa = pipeline('question-answering')\nnlp_qa(context='Hugging Face is a French company based in New-York.', question='Where is based Hugging Face ?')","0bcbca3e":"nlp_fill = pipeline('fill-mask')\nnlp_fill('Hugging Face is a French company based in <mask>')","45dfd64f":"import numpy as np\nnlp_features = pipeline('feature-extraction')\noutput = nlp_features('Hugging Face is a French company based in Paris')\nnp.array(output).shape   # (Samples, Tokens, Vector Size)\n","8d56443e":"task = widgets.Dropdown(\n    options=['sentiment-analysis', 'ner', 'fill_mask'],\n    value='ner',\n    description='Task:',\n    disabled=False\n)\n\ninput = widgets.Text(\n    value='',\n    placeholder='Enter something',\n    description='Your input:',\n    disabled=False\n)\n\ndef forward(_):\n    if len(input.value) > 0: \n        if task.value == 'ner':\n            output = nlp_token_class(input.value)\n        elif task.value == 'sentiment-analysis':\n            output = nlp_sentence_classif(input.value)\n        else:\n            if input.value.find('<mask>') == -1:\n                output = nlp_fill(input.value + ' <mask>')\n            else:\n                output = nlp_fill(input.value)                \n        print(output)\n\ninput.on_submit(forward)\ndisplay(task, input)","5edf3700":"context = widgets.Textarea(\n    value='Einstein is famous for the general theory of relativity',\n    placeholder='Enter something',\n    description='Context:',\n    disabled=False\n)\n\nquery = widgets.Text(\n    value='Why is Einstein famous for ?',\n    placeholder='Enter something',\n    description='Question:',\n    disabled=False\n)\n\ndef forward(_):\n    if len(context.value) > 0 and len(query.value) > 0: \n        output = nlp_qa(question=query.value, context=context.value)            \n        print(output)\n\nquery.on_submit(forward)\ndisplay(context, query)","9b754a2d":"## 5. Projection - Features Extraction ","0bd740dd":"## 2. Token Classification - Named Entity Recognition","06670cc3":"## 3. Question Answering","e360cc77":"## 1. Sentence Classification - Sentiment Analysis","03dfc1ab":"Newly introduced in transformers v2.3.0, **pipelines** provides a high-level, easy to use,\nAPI for doing inference over a variety of downstream-tasks, including: \n\n- Sentence Classification (Sentiment Analysis): Indicate if the overall sentence is either positive or negative. _(Binary Classification task or Logitic Regression task)_\n- Token Classification (Named Entity Recognition, Part-of-Speech tagging): For each sub-entities _(**tokens**)_ in the input, assign them a label _(Classification task)_.\n- Question-Answering: Provided a tuple (question, context) the model should find the span of text in **content** answering the **question**.\n- Mask-Filling: Suggests possible word(s) to fill the masked input with respect to the provided **context**.\n- Feature Extraction: Maps the input to a higher, multi-dimensional space learned from the data.\n\nPipelines encapsulate the overall process of every NLP process:\n \n 1. Tokenization: Split the initial input into multiple sub-entities with ... properties (i.e. tokens).\n 2. Inference: Maps every tokens into a more meaningful representation. \n 3. Decoding: Use the above representation to generate and\/or extract the final output for the underlying task.\n\nThe overall API is exposed to the end-user through the `pipeline()` method with the following \nstructure:\n\n```python\nfrom transformers import pipeline\n\n# Using default model and tokenizer for the task\npipeline(\"<task-name>\")\n\n# Using a user-specified model\npipeline(\"<task-name>\", model=\"<model_name>\")\n\n# Using custom model\/tokenizer as str\npipeline('<task-name>', model='<model name>', tokenizer='<tokenizer_name>')\n```","40a11755":"## 4. Text Generation - Mask Filling","c2a94579":"## How can I leverage State-of-the-Art Natural Language Models with only one line of code ?","852b5efb":"Alright ! Now you have a nice picture of what is possible through transformers' pipelines, and there is more\nto come in future releases. \n\nIn the meantime, you can try the different pipelines with your own inputs"}}