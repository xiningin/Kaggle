{"cell_type":{"dc17e091":"code","af1b86c6":"code","8660aa54":"code","d68a9387":"code","5a89aa95":"code","a22dfb46":"code","d456b04d":"code","9e66344f":"code","754241f6":"code","879444d6":"code","4b88b248":"code","afaf6077":"code","19267e60":"code","5af16fd7":"code","cd8e1548":"code","4bf03a93":"code","35ca5e44":"code","f2a402e9":"code","0e7633ff":"code","c45175eb":"code","4b985b12":"code","49d2ddff":"code","a5374a15":"code","aea3f59c":"code","18d7145d":"code","f0eb0998":"code","8ee5390c":"code","f7573d8c":"code","675784c6":"code","0670f0ae":"code","ba7c20b7":"code","d1f47c22":"code","bcb5f032":"code","25bb7e1e":"code","540a9ef8":"code","1c7db060":"code","0d2954fa":"code","2b4b29e2":"code","e2c05a21":"code","22e68f2d":"code","43afce4e":"code","7f6f2f70":"code","f99f10fe":"code","82247575":"markdown"},"source":{"dc17e091":"!pip install imutils","af1b86c6":"%matplotlib inline\nimport imp\nimport pandas as pd\nimport pickle\nimport time\nfrom matplotlib import cm, transforms\nimport zipfile\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\nfrom tensorflow import keras\n# Display\nfrom IPython.display import Image\nimport matplotlib.cm as cm\n# import the necessary packages\nfrom tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.layers import AveragePooling2D\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nimport numpy as np\nimport argparse\nimport cv2\nimport os\nfrom imutils import paths","8660aa54":"\ncorona_train_ImagePaths = list(paths.list_images('\/kaggle\/input\/covid19vsnormal\/Normal'))\nnormal_train_ImagePaths = list(paths.list_images('\/kaggle\/input\/covid19vsnormal\/COVID-19'))\ndata = []\nlabels = []\n\n\nfor imagePath in corona_train_ImagePaths:\n    image = cv2.imread(imagePath)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, (224, 224))\n    # update the data and labels lists, respectively\n    data.append(image)\n    labels.append('corona')\n\n\n\nfor imagePath in normal_train_ImagePaths:\n    image = cv2.imread(imagePath)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, (224, 224))\n    # update the data and labels lists, respectively\n    data.append(image)\n    labels.append('normal')\n\n\n\ndata = np.array(data) \/ 255.0\nlabels = np.array(labels)","d68a9387":"\nbase_dir = '..\/input\/covid19vsnormal'","5a89aa95":"lb = LabelBinarizer()\nlabels = lb.fit_transform(labels)\nlabels = to_categorical(labels)\n\ntrainX, testX, trainY, testY = train_test_split(data, labels,test_size=0.20, stratify=labels, random_state=42)\ntestAug = ImageDataGenerator(rotation_range=15,fill_mode=\"nearest\")\ntrainAug = ImageDataGenerator(rescale = 1.\/255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n","a22dfb46":"del data\ndel labels","d456b04d":"from tensorflow.keras.applications.vgg16 import VGG16\n\nbase_model = VGG16(input_shape = (224, 224, 3), # Shape of our images\ninclude_top = False, # Leave out the last fully connected layer\nweights = 'imagenet')\n\nfor layer in base_model.layers:\n    layer.trainable = False","9e66344f":"base_model.summary()","754241f6":"# Flatten the output layer to 1 dimension\nx = layers.Flatten()(base_model.output)\n\n# Add a fully connected layer with 512 hidden units and ReLU activation\nx = layers.Dense(512, activation='relu')(x)\n\n# Add a dropout rate of 0.5\nx = layers.Dropout(0.5)(x)\n\n# Add a final sigmoid layer for classification\nx = layers.Dense(2, activation='softmax')(x)\n\nmodel = tf.keras.models.Model(base_model.input, x)\n","879444d6":"model.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0001), loss = 'binary_crossentropy',metrics = ['acc'])","4b88b248":"model.summary()","afaf6077":"vgghist = model.fit_generator(trainAug.flow(trainX, trainY, batch_size=32),validation_data=testAug.flow(testX, testY, batch_size=32),validation_steps=64, steps_per_epoch = 64, epochs =16 ,shuffle = True)\n","19267e60":"vgghist.history","5af16fd7":"plt.plot(vgghist.history['acc'])\nplt.plot(vgghist.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\nplt.plot(vgghist.history['loss'])\nplt.plot(vgghist.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n","cd8e1548":"print(\"training_accuracy\", vgghist.history['acc'][-1])\nprint(\"validation_accuracy\", vgghist.history['val_acc'][-1])","4bf03a93":"for ilayer, layer in enumerate(model.layers):\n    print(\"{:3.0f} {:10}\".format(ilayer, layer.name))","35ca5e44":"\nprint(\"[INFO] evaluating network...\")\npredIdxs = model.predict(testX, batch_size=10)\npredIdxs = np.argmax(predIdxs, axis=1)\nprint(classification_report(testY.argmax(axis=1), predIdxs,target_names=lb.classes_))","f2a402e9":"cm = confusion_matrix(testY.argmax(axis=1), predIdxs)\ntotal = sum(sum(cm))\nacc = (cm[0, 0] + cm[1, 1]) \/ total\nsensitivity = cm[0, 0] \/ (cm[0, 0] + cm[0, 1])\nspecificity = cm[1, 1] \/ (cm[1, 0] + cm[1, 1])\n\nprint(cm)\nprint(\"acc: {:.4f}\".format(acc))\nprint(\"sensitivity: {:.4f}\".format(sensitivity))\nprint(\"specificity: {:.4f}\".format(specificity))","0e7633ff":"model.save(\"my_model.h5\")\n","c45175eb":"imgNormalized = cv2.imread(\"..\/input\/covid19vsnormal\/COVID-19\/COVID-19 (1).jpg\")\nimgNormalized = cv2.cvtColor(imgNormalized, cv2.COLOR_BGR2RGB)\nimgNormalized = cv2.resize(imgNormalized, (224, 224))\nimgNormalized=np.array(imgNormalized)\/ 255.0\nimgNormalizedlist=[]\nimgNormalizedlist.append(imgNormalized)","4b985b12":"pred = model.predict(np.array(imgNormalizedlist))\n\nclass_prob = pred.tolist()\nsoftMaxProb = class_prob[0]\n\nsoftMaxProb","49d2ddff":"from PIL import Image\n","a5374a15":"imgNormalized = cv2.imread(\"..\/input\/covid19vsnormal\/COVID-19\/COVID-19 (1).jpg\")\nimgNormalized = cv2.cvtColor(imgNormalized, cv2.COLOR_BGR2RGB)\nimgNormalized = cv2.resize(imgNormalized, (224, 224))\nimgNormalized=np.array(imgNormalized)\/ 255.0\nimgNormalizedlist=[]\nimgNormalizedlist.append(imgNormalized)\n","aea3f59c":"pred = model.predict(np.array(imgNormalizedlist))\n\nclass_prob = pred.tolist()\nsoftMaxProb = class_prob[0]\n\nsoftMaxProb","18d7145d":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Display\nfrom IPython.display import Image\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm","f0eb0998":"def make_gradcam_heatmap(\n    img_array, model, last_conv_layer_name, classifier_layer_names\n):\n    # First, we create a model that maps the input image to the activations\n    # of the last conv layer\n    last_conv_layer = model.get_layer(last_conv_layer_name)\n    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n\n    # Second, we create a model that maps the activations of the last conv\n    # layer to the final class predictions\n    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n    x = classifier_input\n    for layer_name in classifier_layer_names:\n        x = model.get_layer(layer_name)(x)\n    classifier_model = keras.Model(classifier_input, x)\n\n    # Then, we compute the gradient of the top predicted class for our input image\n    # with respect to the activations of the last conv layer\n    with tf.GradientTape() as tape:\n        # Compute activations of the last conv layer and make the tape watch it\n        last_conv_layer_output = last_conv_layer_model(img_array)\n        tape.watch(last_conv_layer_output)\n        # Compute class predictions\n        preds = classifier_model(last_conv_layer_output)\n        top_pred_index = tf.argmax(preds[0])\n        top_class_channel = preds[:, top_pred_index]\n\n    # This is the gradient of the top predicted class with regard to\n    # the output feature map of the last conv layer\n    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n\n    # This is a vector where each entry is the mean intensity of the gradient\n    # over a specific feature map channel\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    # We multiply each channel in the feature map array\n    # by \"how important this channel is\" with regard to the top predicted class\n    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n    pooled_grads = pooled_grads.numpy()\n    for i in range(pooled_grads.shape[-1]):\n        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n\n    # The channel-wise mean of the resulting feature map\n    # is our heatmap of class activation\n    heatmap = np.mean(last_conv_layer_output, axis=-1)\n\n    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n    heatmap = np.maximum(heatmap, 0) \/ np.max(heatmap)\n    return heatmap","8ee5390c":"\n# Print what the top predicted class is\npred = model.predict(np.array(imgNormalizedlist))\n\n","f7573d8c":"last_conv_layer_name = \"block5_pool\"\nclassifier_layer_names = [\n    \"flatten\",\n    \"dense\",\n    \"dropout\",\n    \"dense_1\"\n]\n","675784c6":"# Generate class activation heatmap\nheatmap = make_gradcam_heatmap(\n    np.array(imgNormalizedlist), model, last_conv_layer_name, classifier_layer_names\n)\n\n# Display heatmap\nplt.matshow(heatmap)\nplt.show()","0670f0ae":"# We load the original image\nimg_path=\"..\/input\/covid19vsnormal\/COVID-19\/COVID-19 (1).jpg\"\nimg = keras.preprocessing.image.load_img(img_path)\nimg = keras.preprocessing.image.img_to_array(img)\n","ba7c20b7":"# We rescale heatmap to a range 0-255\nheatmap = np.uint8(255 * heatmap)\n\n# We use jet colormap to colorize heatmap\njet = cm.get_cmap(\"jet\")\n\n# We use RGB values of the colormap\njet_colors = jet(np.arange(256))[:, :3]\njet_heatmap = jet_colors[heatmap]\n\n# We create an image with RGB colorized heatmap\njet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\njet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\njet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n\n# Superimpose the heatmap on original image\nsuperimposed_img = jet_heatmap * 0.4 + img\nsuperimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n\n# Save the superimposed image\nsave_path = \"first_try.jpg\"\nsuperimposed_img.save(save_path)\n\n# Display Grad CAM\ndisplay(Image(save_path))","d1f47c22":"imgNormalized = cv2.imread(\"..\/input\/covid19vsnormal\/Normal\/Normal (100).jpg\")\nimgNormalized = cv2.cvtColor(imgNormalized, cv2.COLOR_BGR2RGB)\nimgNormalized = cv2.resize(imgNormalized, (224, 224))\nimgNormalized=np.array(imgNormalized)\/ 255.0\nimgNormalizedlist=[]\nimgNormalizedlist.append(imgNormalized)\n","bcb5f032":"# Generate class activation heatmap\nheatmap = make_gradcam_heatmap(\n    np.array(imgNormalizedlist), model, last_conv_layer_name, classifier_layer_names\n)\n\n# Display heatmap\nplt.matshow(heatmap)\nplt.show()","25bb7e1e":"# We load the original image\nimg_path=\"..\/input\/covid19vsnormal\/Normal\/Normal (100).jpg\"\nimg = keras.preprocessing.image.load_img(img_path)\nimg = keras.preprocessing.image.img_to_array(img)\n","540a9ef8":"# We rescale heatmap to a range 0-255\nheatmap = np.uint8(255 * heatmap)\n\n# We use jet colormap to colorize heatmap\njet = cm.get_cmap(\"jet\")\n\n# We use RGB values of the colormap\njet_colors = jet(np.arange(256))[:, :3]\njet_heatmap = jet_colors[heatmap]\n\n# We create an image with RGB colorized heatmap\njet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\njet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\njet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n\n# Superimpose the heatmap on original image\nsuperimposed_img = jet_heatmap * 0.4 + img\nsuperimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n\n# Save the superimposed image\nsave_path = \"first_try.jpg\"\nsuperimposed_img.save(save_path)\n\n# Display Grad CAM\ndisplay(Image(save_path))","1c7db060":"dir()","0d2954fa":"import numpy as np\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras import Model\n\n\ndef grad_cam(model, img,\n             layer_name=\"block5_pool\", label_name=None,\n             category_id=None):\n    \"\"\"Get a heatmap by Grad-CAM.\n    Ars:\n        model: A model object, build from tf.keras 2.X.\n        img: An image ndarray.\n        layer_name: A string, layer name in model.\n        label_name: A list,\n            show the label name by assign this argument,\n            it should be a list of all label names.\n        category_id: An integer, index of the class.\n            Default is the category with the highest score in the prediction.\n    Return:\n        A heatmap ndarray(without color).\n    \"\"\"\n    img_tensor = np.expand_dims(img, axis=0)\n\n    conv_layer = model.get_layer(layer_name)\n    heatmap_model = Model([model.inputs], [conv_layer.output, model.output])\n\n    with tf.GradientTape() as gtape:\n        conv_output, predictions = heatmap_model(img_tensor)\n        if category_id == None:\n            category_id = np.argmax(predictions[0])\n        if label_name:\n            print(label_name[category_id])\n        output = predictions[:, category_id]\n        grads = gtape.gradient(output, conv_output)\n        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_output), axis=-1)\n    heatmap = np.maximum(heatmap, 0)\n    max_heat = np.max(heatmap)\n    if max_heat == 0:\n        max_heat = 1e-10\n    heatmap \/= max_heat\n\n    return np.squeeze(heatmap)\n\ndef grad_cam_plus(model, img,\n                  layer_name=\"block5_pool\", label_name=None,\n                  category_id=None):\n    \"\"\"Get a heatmap by Grad-CAM.\n    Ars:\n        model: A model object, build from tf.keras 2.X.\n        img: An image ndarray.\n        layer_name: A string, layer name in model.\n        label_name: A list,\n            show the label name by assign this argument,\n            it should be a list of all label names.\n        category_id: An integer, index of the class.\n            Default is the category with the highest score in the prediction.\n    Return:\n        A heatmap ndarray(without color).\n    \"\"\"\n    img_tensor = np.expand_dims(img, axis=0)\n\n    conv_layer = model.get_layer(layer_name)\n    heatmap_model = Model([model.inputs], [conv_layer.output, model.output])\n\n    with tf.GradientTape() as gtape1:\n        with tf.GradientTape() as gtape2:\n            with tf.GradientTape() as gtape3:\n                conv_output, predictions = heatmap_model(img_tensor)\n                if category_id==None:\n                    category_id = np.argmax(predictions[0])\n                if label_name:\n                    print(label_name[category_id])\n                output = predictions[:, category_id]\n                conv_first_grad = gtape3.gradient(output, conv_output)\n            conv_second_grad = gtape2.gradient(conv_first_grad, conv_output)\n        conv_third_grad = gtape1.gradient(conv_second_grad, conv_output)\n\n    global_sum = np.sum(conv_output, axis=(0, 1, 2))\n\n    alpha_num = conv_second_grad[0]\n    alpha_denom = conv_second_grad[0]*2.0 + conv_third_grad[0]*global_sum\n    alpha_denom = np.where(alpha_denom != 0.0, alpha_denom, 1e-10)\n    \n    alphas = alpha_num\/alpha_denom\n    alpha_normalization_constant = np.sum(alphas, axis=(0,1))\n    alphas \/= alpha_normalization_constant\n\n    weights = np.maximum(conv_first_grad[0], 0.0)\n\n    deep_linearization_weights = np.sum(weights*alphas, axis=(0,1))\n    grad_CAM_map = np.sum(deep_linearization_weights*conv_output[0], axis=2)\n\n    heatmap = np.maximum(grad_CAM_map, 0)\n    max_heat = np.max(heatmap)\n    if max_heat == 0:\n        max_heat = 1e-10\n    heatmap \/= max_heat\n\n    return heatmap","2b4b29e2":"import requests\nimport os\nimport cv2\nimport numpy as np\nfrom PIL import Image\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing import image\n\n\ndef preprocess_image(img_path, target_size=(224, 224)):\n    \"\"\"Preprocess the image by reshape and normalization.\n    Ars:\n        img_path:  A string.\n        target_size: A tuple, reshape to this size.\n    Return:\n        An image ndarray.\n    \"\"\"\n    img = keras.preprocessing.image.load_img(img_path, target_size=target_size)\n    img = keras.preprocessing.image.img_to_array(img)\n    img \/= 255\n\n    return img\n\n\ndef show_imgwithheat(img_path, heatmap, alpha=0.4, return_array=False):\n    \"\"\"Show the image with heatmap.\n    Ars:\n        img_path: string.\n        heatmap:  image array, get it by calling grad_cam().\n        alpha:    float, transparency of heatmap.\n        return_array: bool, return a superimposed image array or not.\n    Return:\n        None or image array.\n    \"\"\"\n    img = cv2.imread(img_path)\n    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n    heatmap = (heatmap*255).astype(\"uint8\")\n    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n    superimposed_img = heatmap * alpha + img\n    superimposed_img = np.clip(superimposed_img,0,255).astype(\"uint8\")\n    superimposed_img = cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB)\n\n    imgwithheat = Image.fromarray(superimposed_img)  \n    display(imgwithheat)\n\n    if return_array:\n        return superimposed_img","e2c05a21":"img_path = '..\/input\/covid19vsnormal\/Normal\/Normal (100).jpg'\nimg = preprocess_image(img_path)\n","22e68f2d":"heatmap =grad_cam(model,img)","43afce4e":"show_imgwithheat(img_path, heatmap)","7f6f2f70":"heatmap1 =grad_cam_plus(model,img)","f99f10fe":"show_imgwithheat(img_path, heatmap1)\n","82247575":"#Creating early stopping \nearlystop = EarlyStopping(monitor = 'val_accuracy', min_delta = 0, patience = 50, verbose = 1, mode = 'auto', restore_best_weights = True)       "}}