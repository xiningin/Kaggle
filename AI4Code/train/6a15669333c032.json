{"cell_type":{"ec2a5eea":"code","92f4f0ee":"code","f09a3dff":"code","bfdc1da1":"code","26e873b0":"code","6569f60f":"code","fa1991be":"code","36fb209d":"code","b7e1b700":"code","2e22942e":"code","790269c1":"markdown","2e8cd8be":"markdown","7c77262b":"markdown","8d91b090":"markdown","028e48b8":"markdown","fda906d2":"markdown","9a8c4ee8":"markdown","e32ad9c5":"markdown","48aefcb1":"markdown"},"source":{"ec2a5eea":"!pip install imageio-ffmpeg","92f4f0ee":"!git clone https:\/\/github.com\/AliaksandrSiarohin\/first-order-model\n%cd first-order-model","f09a3dff":"import os\nimport imageio\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom skimage.transform import resize\nfrom IPython.display import HTML","bfdc1da1":"def display(source, driving, generated=None):\n    fig = plt.figure(figsize=(8 + 4 * (generated is not None), 6))\n\n    ims = []\n    for i in range(len(driving)):\n        cols = [source]\n        cols.append(driving[i])\n        if generated is not None:\n            cols.append(generated[i])\n        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n        plt.axis('off')\n        ims.append([im])\n\n    ani = animation.ArtistAnimation(fig, ims, interval=50, repeat_delay=1000)\n    plt.close()\n    return ani","26e873b0":"from demo import load_checkpoints\ngenerator, kp_detector = load_checkpoints(config_path='config\/vox-256.yaml', \n                            checkpoint_path='..\/..\/input\/first-order-motion-model\/vox-cpk.pth.tar')","6569f60f":"## preprocess video file if needed\n# cut video from .mp4\n#!ffmpeg -i ..\/..\/input\/input-talking\/Tsai_IngWen.mp4 -map 0 -ss 00:00:00 -t 00:00:22.30 -vf fps=fps=30 ..\/Tsai_IngWen.mp4\n                    \n# convert frame-rate to 30 fps\n#!ffmpeg -i ..\/..\/input\/input-talking\/Tsai_IngWen.mp4 -vf fps=fps=30 ..\/rescaled.mp4","fa1991be":"from demo import make_animation\nfrom skimage import img_as_ubyte","36fb209d":"source_image = imageio.imread('..\/..\/input\/input-faces\/Taylor_Swift.jpg')\ndriving_video = imageio.mimread('..\/..\/input\/input-talking\/Tsai_IngWen.mp4', memtest=False)\n\nsource_image = resize(source_image, (256, 256))[..., :3]\ndriving_video = [resize(frame, (256, 256))[..., :3] for frame in driving_video]\n\npredictions = make_animation(source_image, driving_video, generator, kp_detector, relative=True)\nprint(len(predictions))\n\n#save resulting video\nimageio.mimsave('..\/generated.mp4', [img_as_ubyte(frame) for frame in predictions], fps=30)\n#video can be downloaded from \/content folder\n\nHTML(display(source_image, driving_video, predictions).to_html5_video())","b7e1b700":"!ffmpeg -i ..\/..\/input\/input-talking\/Tsai_IngWen.mp4 -map 0:1 -c:a libmp3lame ..\/generated.mp3","2e22942e":"!ffmpeg -i ..\/generated.mp4 -i ..\/generated.mp3 -vcodec copy -acodec copy ..\/result.mp4","790269c1":"## Load Model","2e8cd8be":"## Image Animation with Video","7c77262b":"## Merge Video with Audio","8d91b090":"### Approach : First-Order-Motion Model\n![First-Order-Motion-Model.JPG](attachment:First-Order-Motion-Model.JPG)","028e48b8":"### merge video with audio","fda906d2":"## Repro [GitHub](https:\/\/github.com\/AliaksandrSiarohin\/first-order-model)","9a8c4ee8":"## Paper: [First Order Motion Model for Image Animation](https:\/\/arxiv.org\/abs\/2003.00196)","e32ad9c5":"# Image Animation for Virtual Endorser","48aefcb1":"### extract audio from source video"}}