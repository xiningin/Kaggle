{"cell_type":{"9c571bb9":"code","ef4f79c4":"code","d8a7b13e":"code","2c39f9ae":"code","b9434687":"code","99605376":"code","a8d8265d":"code","cc3bf83b":"markdown","8d55bed3":"markdown"},"source":{"9c571bb9":"pip install pretrainedmodels","ef4f79c4":"import albumentations\nimport torch\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport pretrainedmodels\nimport torch.nn as nn\nfrom PIL import Image\nfrom PIL import ImageFile\nfrom tqdm import tqdm\nimport pandas as pd\nimport numpy as np","d8a7b13e":"# Class that read data in map-stype way \n# To read more https:\/\/pytorch.org\/docs\/stable\/data.html\n\nclass ClassificationDataset:\n    \"\"\"\n    A general classification dataset class\n    \"\"\"\n    def __init__(self, image_paths, targets, resize=None, augmentations=None):\n        \"\"\"\n         image_paths: list of path to images\n         targets: numpy array\n         resize: tuple. Will resizes image if not None\n         augmentations: albumentation augmentations of images\n        \"\"\"\n        self.image_paths = image_paths\n        self.targets = targets\n        self.resize = resize\n        self.augmentations = augmentations\n\n    def __len__(self):\n        \"\"\"\n        Return the total number of samples in the dataset\n        \"\"\"\n        return len(self.image_paths)\n\n    def __getitem__(self, item):\n        \"\"\"\n        Given an index will get image from dataset\n        \"\"\"\n        # PIL to open the image\n        image = Image.open(self.image_paths[item])\n        # convert image to RGB\n        image = image.convert(\"RGB\")\n        # get the from data targets\n        targets = self.targets[item]\n        # resize if Not None\n        if self.resize is not None:\n            image = image.resize((self.resize[1], self.resize[0]), resample=Image.BILINEAR)\n        # convert to numpy array\n        image = np.array(image)\n        # if albumentation not None\n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented[\"image\"]\n        # pytorch expects CHW instead of HWC\n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        # Return tensor of images and targets \n        return {\"image\": torch.tensor(image, dtype=torch.float), \"targets\": torch.tensor(targets, dtype=torch.long)}","2c39f9ae":"# function to get an model\n# more about pretrained models  https:\/\/pytorch.org\/vision\/stable\/models.html\n\ndef load_model_from():\n    # pretrained models from Pytorch with pretrainedmodels libs\n    model = pretrainedmodels.__dict__[\"resnet18\"](pretrained='imagenet')\n    # add final layers \n    model.last_linear = nn.Sequential(\n        nn.BatchNorm1d(512), # more here https:\/\/pytorch.org\/docs\/master\/generated\/torch.nn.BatchNorm1d.html#batchnorm1d\n        nn.Dropout(p=0.25), # \n        nn.Linear(in_features=512, out_features=2048),\n        nn.ReLU(),\n        nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1),\n        nn.Dropout(p=0.5),\n        nn.Linear(in_features=2048, out_features=1))\n\n    return model\n\n# You could play with BatchNorm1d, Dropout","b9434687":"# Prepare device, set the paths, initialize the data loaders of Dataset class\n\nEPOCHS = 10 # set number of epoch to run \nNUM_WORKERS = 12 # could increase the time to calculate the results \nRANDOM_STATE = 11 # to repproduce results\n\n# path to images\ndata_path = \"..\/input\/pneumothorax-binary-classification-task\/small_train_data_set\/small_train_data_set\"\n\n# cuda\/cpu device (depends on your settings)\nif torch.cuda.is_available():\n    device = \"cuda\"\nelse:\n    device = \"cpu\"\nprint(device)\n\n# load the dataframe of images path and targets \ndf = pd.read_csv(\"..\/input\/pneumothorax-binary-classification-task\/train_data.csv\")\n# add new column with full path\ndf['full_path_to_images'] = data_path + \"\/\" + df.file_name.values\n\n# image ids and targets values \nimages = df.full_path_to_images.values.tolist()\ntargets = df.target.values\n\n# get the pretrained model\nmodel = load_model_from()\nprint(model)\n\n# move model to device https:\/\/pytorch.org\/docs\/stable\/notes\/cuda.html\nmodel.to(device)\n# mean and std values of RGB channels for imagenet dataset\nmean = (0.485, 0.456, 0.406)\nstd = (0.229, 0.224, 0.225)\n# albumentations is an image augmentation library\naug = albumentations.Compose([albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True)])\n\n# train_test_split date \ntrain_images, valid_images, train_targets, valid_targets = train_test_split(images, targets, stratify=targets, random_state=RANDOM_STATE)\n\n# set train dataset with batch_size\ntrain_dataset = ClassificationDataset(image_paths=train_images, targets=train_targets, resize=(227, 227), augmentations=aug)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=NUM_WORKERS)\n\n# set test dataset with batch_size\nvalid_dataset = ClassificationDataset(image_paths=valid_images, targets=valid_targets, resize=(227, 227), augmentations=aug)\nvalid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=16, shuffle=False, num_workers=NUM_WORKERS)\n\n# simple Adam optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-4)","99605376":"# Train and evaluate functions \n\ndef train(data_loader, model, optimizer, device):\n    \"\"\"\n    training for one epoch with selected model and params\n     data_loader:  pytorch dataloader\n     model: pytorch model\n     optimizer: optimizer \n     device: cuda\/cpu\n    \"\"\"\n    # set training mode \n    model.train()\n    # go over every batch of data in data loader\n    for data in data_loader:\n        inputs = data[\"image\"]\n        targets = data[\"targets\"]\n        # move inputs\/targets to cuda\/cpu device\n        inputs = inputs.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.float)\n        # zero grad the optimizer\n        optimizer.zero_grad()\n        # do the forward step of model\n        outputs = model(inputs)\n        # calculate loss\n        loss = nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))\n        # backward step the loss\n        loss.backward()\n        # step optimizer\n        optimizer.step()\n        \ndef evaluate(data_loader, model, device):\n    \"\"\"\n    Evaluation for one epoch\n    data_loader: this is the pytorch dataloader\n    model: pytorch model\n    device: cuda\/cpu\n    \"\"\"\n    # put model in evaluation mode\n    model.eval()\n    # init lists to store targets and outputs\n    final_targets = []\n    final_outputs = []\n    # no_grad context\n    with torch.no_grad():\n        for data in data_loader:\n            inputs = data[\"image\"]\n            targets = data[\"targets\"]\n            inputs = inputs.to(device, dtype=torch.float)\n            targets = targets.to(device, dtype=torch.float)\n            # generate prediction\n            output = model(inputs)\n            # convert targets and outputs to lists\n            targets = targets.detach().cpu().numpy().tolist()\n            output = output.detach().cpu().numpy().tolist()\n            # extend the original list\n            final_targets.extend(targets)\n            final_outputs.extend(output)\n            \n    return final_outputs, final_targets","a8d8265d":"# train and print auc score for all epochs\nfor epoch in tqdm(range(EPOCHS)):\n    # train \n    train(train_loader, model, optimizer, device=device)\n    # predict \n    predictions, valid_targets = evaluate(valid_loader, model, device=device)\n    # metrics \n    roc_auc = metrics.roc_auc_score(valid_targets, predictions)\n    print(f\"Epoch={epoch}, Valid ROC AUC={roc_auc}\")","cc3bf83b":"# Pneumothorax binary classification with Pytorch \n\n### Tasks\n##### 1. With small sub sample of Pneumothorax dataset use pre trained Pytorch models to get Pneumothorax sufficient level of accuracy\n##### 2. Explore Pytorch API","8d55bed3":"##### Insipred by https:\/\/www.kaggle.com\/abhishek and his book *Approaching (Almost) Any Machine Learning Problem* https:\/\/www.amazon.com\/Approaching-Almost-Machine-Learning-Problem-ebook\/dp\/B089P13QHT"}}