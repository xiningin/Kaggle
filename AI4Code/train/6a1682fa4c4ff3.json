{"cell_type":{"1b6362c3":"code","d95d8c57":"code","44bebcf8":"code","331a0480":"code","de4108ad":"code","17a5b8d4":"code","1b85a4c2":"code","f9c1ddbc":"code","277aad46":"code","6827b540":"code","266f4d46":"code","ccb04f31":"code","9ebe205d":"code","b9030bb6":"code","0207042e":"code","195fd991":"code","8d9cec20":"code","f2d6b3ce":"code","c960e42b":"code","fee7d58a":"code","2ba14864":"code","43657af9":"code","809a48cb":"code","80ea41b3":"code","19887034":"code","4b9f3265":"code","e4528d2d":"code","e7437814":"code","9e026512":"markdown","5e94dae9":"markdown","0916faac":"markdown","8a86a8dd":"markdown","092c336a":"markdown","6ae5402c":"markdown","af393b8f":"markdown","91eb1fce":"markdown","014e44c1":"markdown","eb0417f0":"markdown","5b190b49":"markdown","5dda7738":"markdown","52a93829":"markdown","c70ffde5":"markdown","5d144624":"markdown","a885795e":"markdown"},"source":{"1b6362c3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d95d8c57":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","44bebcf8":"admission = pd.read_csv(\"\/kaggle\/input\/graduate-admissions\/Admission_Predict.csv\")\nadmission_new = pd.read_csv(\"\/kaggle\/input\/graduate-admissions\/Admission_Predict_Ver1.1.csv\")","331a0480":"print(admission.shape,admission_new.shape)","de4108ad":"admission.head()","17a5b8d4":"admission_new.head()","1b85a4c2":"'''Normaizing columns name as there are unnnecessary spaces at the end and we will also reove spaces between two words. It will help us while\naccessing columns'''\nadmission.columns = [\"_\".join(i.strip().split()) for i in admission.columns]\nadmission_new.columns = [\"_\".join(i.strip().split()) for i in admission_new.columns]","f9c1ddbc":"\nadmission.drop(['Serial_No.'],axis=1,inplace=True)\nadmission.info()","277aad46":"admission.describe()","6827b540":"if admission.drop_duplicates(subset=admission.drop(['Chance_of_Admit'],axis=1).columns).shape[0] == admission.shape[0]:\n    print(\"No duplicate entry!!\")\nelse:\n    print(\"Yes there are duplicacies in data!!\")","266f4d46":"sns.pairplot(admission.drop(['Chance_of_Admit'],axis=1),diag_kind='kde')\nplt.show()","ccb04f31":"fig,ax = plt.subplots(4,1,figsize=(14,20))\nfor i,j in enumerate(['University_Rating','SOP','LOR','Research']):\n    admission[j].value_counts().plot.bar(ax=ax[i-1],title=j)\nfig.tight_layout()","9ebe205d":"plt.figure(figsize=(14,8))\nsns.scatterplot(data=admission,x='CGPA',y='Chance_of_Admit',hue='University_Rating',legend='full')\nplt.show()","b9030bb6":"plt.figure(figsize=(14,8))\nsns.scatterplot(data=admission,x='GRE_Score',y='Chance_of_Admit',hue='University_Rating',legend='full')\nplt.show()","0207042e":"plt.figure(figsize=(14,8))\nsns.scatterplot(data=admission,x='TOEFL_Score',y='Chance_of_Admit',hue='University_Rating',legend='full')\nplt.show()","195fd991":"plt.figure(figsize=(14,8))\nsns.scatterplot(data=admission,x='CGPA',y='TOEFL_Score',hue='Chance_of_Admit',legend='brief')\nplt.show()","8d9cec20":"sns.pairplot(admission,hue='Chance_of_Admit',diag_kws={'bw': 0.2,'legend':'brief'})\nplt.show()","f2d6b3ce":"plt.figure(figsize=(14,8))\nsns.heatmap(admission.corr()[['Chance_of_Admit']],annot=True)\nplt.show()","c960e42b":"plt.figure(figsize=(12,6))\nsns.heatmap(admission[['CGPA','TOEFL_Score','GRE_Score']].corr(),annot=True)\nplt.show()","fee7d58a":"admission['GRE_TOEFL_CGPA_Combined'] = (admission.TOEFL_Score\/120) + (admission.GRE_Score\/340) + (admission.CGPA\/10)","2ba14864":"admission.GRE_TOEFL_CGPA_Combined.corr(admission.Chance_of_Admit) #Correlation of combined variable with target varible","43657af9":"validation = admission_new.iloc[-100:,1:] #Serial_No is not in admission dataframe.","809a48cb":"validation['GRE_TOEFL_CGPA_Combined'] = (validation.TOEFL_Score\/120)+(validation.GRE_Score\/340)+(validation.CGPA\/10)","80ea41b3":"validation.shape","19887034":"validation.tail()","4b9f3265":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.svm import SVR\nfrom xgboost import XGBRegressor","e4528d2d":"lr = LinearRegression()\nlr.fit(admission.drop(['GRE_TOEFL_CGPA_Combined','Chance_of_Admit'],axis=1),admission.Chance_of_Admit)\nprint(\"Last 100 observations RMSE :\",np.sqrt(mean_squared_error(validation.Chance_of_Admit,lr.predict(validation.drop(['GRE_TOEFL_CGPA_Combined','Chance_of_Admit'],axis=1)))))","e7437814":"lr = LinearRegression()\nlr.fit(admission.drop(['GRE_Score','CGPA','TOEFL_Score','Chance_of_Admit'],axis=1),admission.Chance_of_Admit)\nprint(\"Last 100 observations RMSE :\",np.sqrt(mean_squared_error(validation.Chance_of_Admit,lr.predict(validation.drop(['GRE_Score','CGPA','TOEFL_Score','Chance_of_Admit'],axis=1)))))","9e026512":"# Any Duplicates?","5e94dae9":"# As we can see that explanatory variables are highly correlated with target variable, So we can use linear regression easily. But there is multicollinearty among some explanatory variables. So we need to handle this case also. We will create both type of model by including all three multicollinear variable and by creating a single variable of all these three variable. In below cell we created a combine `GRE_TOEFL_CGPA_Combined` variable.","0916faac":"<h3>There are three continuous explanatory variable(CGPA,GRE and TOEFL) and four discrete explanatory variables. We can cleary see that continuous variables are cleary correlated while discrete variables are not. Distributions are approximate normal.<\/h3>","8a86a8dd":"# Checking Correlation of explanatory variables with target variable(Chance_of_Admit)","092c336a":"<h3>From above graph it is clear that if someone want good university with less CGPA then his\/her chances of admission will be less. Although there are some exceptions.<\/h3>","6ae5402c":"# Let's Do Some EDA","af393b8f":"# Check Distribution of All Explanatory Variable and Correlation B\/W Them","91eb1fce":"# Linear Regression Model Having All Three Multicollinear Features","014e44c1":"# Linear Regression Model excluding All 3 Multicollinear Features And Including Combined `GRE_TOEFL_CGPA_Combined` variable","eb0417f0":"# Checking Correlation Between Three Continuous features","5b190b49":"# Model Building","5dda7738":"# Visualizing Discrete Variables","52a93829":"<h3> `admission` dataframe is our training data.<\/h3>\n\n<h1 style=\"text-align:center;\">While<\/h1>\n\n<h3>Last 100 observations of `admission_new` dataframe will be for validation purpose.<\/h3>","c70ffde5":"# Meaning Of Each Column\n\n**GRE Scores ( out of 340 )**\n\n**TOEFL Scores ( out of 120 )**\n\n**University Rating ( out of 5 )**\n\n**Statement of Purpose and Letter of Recommendation Strength ( out of 5 )**\n\n**Undergraduate GPA ( out of 10 )**\n\n**Research Experience ( either 0 or 1 )**\n\n**Chance of Admit ( ranging from 0 to 1 )**","5d144624":"# Creating Multivarite plots using pairplot","a885795e":"# Multivariate Analysis"}}