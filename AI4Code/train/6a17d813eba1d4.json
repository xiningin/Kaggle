{"cell_type":{"6df99f27":"code","0902c7bd":"code","edae65ca":"code","b85e5737":"code","5bfb47c2":"code","a6dedaf3":"code","50cbd153":"code","eb2883ff":"code","ac506ea3":"code","e9b98615":"code","3f170074":"code","bcb073be":"code","67287645":"code","e19207a6":"code","8625c21e":"code","cba4dd41":"code","ce9bf431":"code","4c15ce47":"code","bd91666e":"code","c5c51df9":"code","0a9d8866":"code","5c86c1f4":"code","236bf33e":"code","9cf1b63b":"code","4ffe193c":"code","5a196fc3":"code","44a9a07f":"markdown","d87916fd":"markdown","41a1e51e":"markdown"},"source":{"6df99f27":"import numpy\nimport json\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\nfrom matplotlib.collections import PatchCollection\nfrom matplotlib.patches import Rectangle\nimport numpy as np\nmap_base_dir = '..\/input\/'\nmap_img_dir = '..\/input\/train\/images\/'","0902c7bd":"json_path = os.path.join(map_base_dir, 'annotation.json')\nwith open(json_path, 'r') as f:\n    annot_data = json.load(f)","edae65ca":"image_df = pd.DataFrame(annot_data['images'])\nimage_df.sample(3)\nfig, m_axs = plt.subplots(2, 2, figsize = (10, 10))\nfor c_ax, (_, c_row) in zip(m_axs.flatten(), image_df.sample(4).iterrows()):\n    img_data = imread(os.path.join(map_img_dir, c_row['file_name']))\n    c_ax.imshow(img_data)","b85e5737":"annot_df = pd.DataFrame(annot_data['annotations'])\nannot_df.sample(3)","5bfb47c2":"full_df = pd.merge(annot_df, image_df, how='left', left_on = 'image_id', right_on='id').dropna()\nprint(image_df.shape[0], '+', annot_df.shape[0], '->', full_df.shape[0])\nfull_df.sample(2)","a6dedaf3":"def create_boxes(in_rows):\n    #TODO: this seems to get a few of the boxes wrong so we stick to segmentation polygons instead\n    box_list = []\n    for _, in_row in in_rows.iterrows():\n        # bbox from the coco standard\n        (start_y, start_x, wid_y, wid_x) = in_row['bbox']\n        \n        box_list += [Rectangle((start_x, start_y), \n                         wid_y , wid_x\n                         )]\n    return box_list","50cbd153":"fig, m_axs = plt.subplots(2, 2, figsize = (10, 10))\nfor c_ax, (c_id, c_df) in zip(m_axs.flatten(), full_df.groupby('image_id')):\n    img_data = imread(os.path.join(map_img_dir, c_df['file_name'].values[0]))\n    c_ax.imshow(img_data)\n    #c_ax.add_collection(PatchCollection(create_boxes(c_df), alpha = 0.25, facecolor = 'red'))\n    for _, c_row in c_df.iterrows():\n        xy_vec = np.array(c_row['segmentation']).reshape((-1, 2))\n        c_ax.plot(xy_vec[:, 0], xy_vec[:, 1], label = c_df['id_x'])","eb2883ff":"from matplotlib.path import Path\nfrom skimage.color import label2rgb\ndef rows_to_segmentation(in_img, in_df):\n    xx, yy = np.meshgrid(range(in_img.shape[0]), \n                range(in_img.shape[1]),\n               indexing='ij')\n    out_img = np.zeros(in_img.shape[:2])\n    for _, c_row in in_df.iterrows():\n        xy_vec = np.array(c_row['segmentation']).reshape((-1, 2))\n        c_ax.plot(xy_vec[:, 0], xy_vec[:, 1], label = c_df['id_x'])\n        xy_path = Path(xy_vec)\n        out_img += xy_path.contains_points(np.stack([yy.ravel(), \n                                                     xx.ravel()], -1)).reshape(out_img.shape)\n    return out_img","ac506ea3":"fig, m_axs = plt.subplots(3, 3, figsize = (15, 20))\nfor (c_ax, d_ax, f_ax), (c_id, c_df) in zip(m_axs,\n                                      full_df.groupby('image_id')):\n    img_data = imread(os.path.join(map_img_dir, c_df['file_name'].values[0]))\n    c_ax.imshow(img_data)\n    out_img = rows_to_segmentation(img_data, c_df)\n    rgba_img = np.concatenate([img_data, \n                               np.clip(np.expand_dims(127*out_img+127, -1), 0, 255).astype(np.uint8)\n                              ], -1)\n    d_ax.imshow(rgba_img)\n    \n    f_ax.imshow(label2rgb(image=img_data, label=out_img, bg_label = 0))","e9b98615":"from sklearn.model_selection import train_test_split\ntrain_ids, valid_ids = train_test_split(image_df['id'], test_size = 0.25)\ntrain_df = full_df[full_df['image_id'].isin(train_ids)]\nvalid_df = full_df[full_df['image_id'].isin(valid_ids)]\nprint(train_df.shape[0], 'training boxes')\nprint(valid_df.shape[0], 'validation boxes')","3f170074":"def single_img_gen(c_df):\n    \"\"\"\n    function to get a single image from a part of a dataframe\n    \"\"\"\n    img_data = imread(os.path.join(map_img_dir, c_df['file_name'].values[0]))\n    out_seg = np.expand_dims(rows_to_segmentation(img_data, c_df), -1)\n    return (img_data\/255.0).astype(np.float32), out_seg.astype(np.float32)  ","bcb073be":"from skimage.util.montage import montage2d\nsingle_df = valid_df[valid_df['image_id'].isin([valid_df['image_id'].values[0]])]\nt_x, t_y = single_img_gen(single_df)   \nprint('x', t_x.shape, t_x.dtype, t_x.min(), t_x.max())\nprint('y', t_y.shape, t_y.dtype, t_y.min(), t_y.max())\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\nmontage_rgb = lambda x: np.stack([montage2d(x[:, :, :, i]) for i in range(x.shape[3])], -1)\nax1.imshow(t_x)\nax2.imshow(t_y[:, :, 0], cmap = 'bone_r')","67287645":"import dask.array as da\nimport dask\nimport dask.diagnostics as diag\nfrom multiprocessing.pool import ThreadPool\nimport h5py\nfrom bokeh.io import output_notebook\nfrom bokeh.resources import CDN\noutput_notebook(CDN, hide_banner=True)","e19207a6":"@dask.delayed\ndef dgen_as_alpha(in_df):\n    x, y = single_img_gen(in_df)\n    return np.concatenate([x, y], -1)\n\ndef dask_read_seg(in_df, max_items = 1000):\n    lazy_images = [dgen_as_alpha(c_df.copy()) for _, (_, c_df) in zip(range(max_items), \n                                                          in_df.groupby('image_id'))\n                  ]     # Lazily evaluate on each group\n    s_img = lazy_images[0].compute()\n    arrays = [da.from_delayed(lazy_image,           # Construct a small Dask array\n                              dtype=s_img.dtype,   # for every lazy value\n                              shape=s_img.shape)\n              for lazy_image in lazy_images]\n\n    return da.stack(arrays, axis=0)                # Stack all small Dask arrays into one","8625c21e":"# larger chunks are more efficient for writing\/compressing and make the paralellization more efficient\nbig_chunker = lambda x: x.rechunk({0: x.shape[0]\/\/32, 1: -1, 2: -1, 3: -1})","cba4dd41":"train_array = big_chunker(dask_read_seg(train_df, 5*750))\nprint(train_array)","ce9bf431":"valid_array = big_chunker(dask_read_seg(valid_df, 5*250))\nprint(valid_array)","4c15ce47":"!rm *.h5 # just make sure there are no files","bd91666e":"with diag.ProgressBar(), diag.Profiler() as prof, diag.ResourceProfiler(0.5) as rprof:\n    with dask.config.set(pool=ThreadPool(4)):\n        train_array.to_hdf5('train.h5', '\/images', compression = 'lzf')\n        valid_array.to_hdf5('valid.h5', '\/images', compression = 'lzf')\n!ls -lh *.h5","c5c51df9":"diag.visualize([prof, rprof])","0a9d8866":"@dask.delayed\ndef dgen_just_seg(in_df):\n    _, y = single_img_gen(in_df)\n    return y.astype(bool) # much smaller\n\ndef dask_read_just_seg(in_df, max_items = 1000):\n    lazy_images = [(c_id, dgen_just_seg(c_df.copy())) for _, (c_id, c_df) in zip(range(max_items), \n                                                          in_df.groupby('image_id'))\n                  ]     # Lazily evaluate on each group\n    s_img = lazy_images[0][1].compute()\n    arrays = [da.from_delayed(lazy_image,           # Construct a small Dask array\n                              dtype=s_img.dtype,   # for every lazy value\n                              shape=s_img.shape)\n              for _, lazy_image in lazy_images]\n    img_ids = [c_id for c_id, _ in lazy_images]\n\n    return img_ids, da.stack(arrays, axis=0)   # Stack all small Dask arrays into one","5c86c1f4":"all_ids, all_array = dask_read_just_seg(full_df, 10000)\nprint(all_array)","236bf33e":"with open('all_segmentations.json', 'w') as f:\n    json.dump({'image_id': all_ids}, f)","9cf1b63b":"big_chunker = lambda x: x.rechunk({0: x.shape[0]\/\/128, 1: -1, 2: -1, 3: -1})\nall_array = big_chunker(all_array)\nall_array","4ffe193c":"with diag.ProgressBar(), diag.Profiler() as prof, diag.ResourceProfiler(0.5) as rprof:\n    with dask.config.set(pool=ThreadPool(4)):\n        all_array.to_hdf5('all_segmentations.h5', '\/images', \n                          compression = 'lzf')\n!ls -lh *.h5","5a196fc3":"diag.visualize([prof, rprof])","44a9a07f":"# Overview\nThe notebook lets us extracts the segmentations quickly by utilizing `dask` from the PyData suite to parallelize the computation across the 4 cores Kaggle provides. The first task it to determine how the annotations file can be read and displayed on the images. The next step is to generate binary masks from the annotation data and then run this on as many images as possible (Kaggle limits output sizes to 1GB as of July 26 2018 and so we only export a portion of the data).\n\nThe main justification for this step is we can train models (neural-network or otherwise) much much quicker if we don't have to compute the segmentations first.","d87916fd":"# Convert Polygons to Segmentations\nWe can use the `Path` function of matplotlib on a `np.meshgrid` of $x,y$ values in order to convert the polygon into a binary image to use as the segmentation.","41a1e51e":"# Prepare for the big export"}}