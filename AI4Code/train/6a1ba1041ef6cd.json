{"cell_type":{"6f37a58f":"code","c6e6bcaf":"code","746de7da":"code","2512ae55":"code","7e3cb6a3":"code","3f53bcac":"code","2f50f15f":"code","bcee84b0":"code","1b8f18f4":"code","33ea0f7b":"code","58c348b3":"code","abc180b1":"code","23b489f4":"code","a2d10d4a":"code","2f5ab7e0":"code","467c16ac":"code","ea208097":"code","05e9afd0":"code","fe9153a8":"code","ce76eefb":"code","debd8af4":"code","d692c70b":"code","6737fc83":"code","c10995e8":"code","deaed20a":"code","429e32f1":"code","4bac08f3":"code","a126fe16":"code","1be4a1c1":"code","d3257a0c":"code","b0326562":"code","2f81af18":"code","c56f06eb":"code","770ebe0f":"code","7b05926d":"code","7c582ff9":"code","53ef28b1":"code","bbc8ee67":"code","cdc657b5":"code","2c0559c9":"code","df02567c":"markdown","ab6674a0":"markdown","3074b9f4":"markdown","cbde0648":"markdown","12b20186":"markdown","74f6c515":"markdown","2c2556a6":"markdown","c90f794b":"markdown","59542b6a":"markdown","81708d05":"markdown","8be2141b":"markdown","55273b02":"markdown","e76aa12f":"markdown","5789dd02":"markdown","b2bfc858":"markdown","7ad9539f":"markdown","18d2c1fd":"markdown","47308784":"markdown","47acb887":"markdown","e35ea1db":"markdown","585c359f":"markdown","4604010a":"markdown","c5b5a6b1":"markdown","615ce10f":"markdown","f717c150":"markdown"},"source":{"6f37a58f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport folium\nfrom folium.map import Icon\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c6e6bcaf":"df_trains = pd.read_csv('..\/input\/indiantrains\/All_Indian_Trains.csv')\ndf_cities = pd.read_csv(\"..\/input\/top-500-indian-cities\/cities_r2.csv\")\ndf_wcities = pd.read_csv(\"..\/input\/world-cities-database\/worldcitiespop.csv\")","746de7da":"sub_wcities = pd.concat([df_wcities[df_wcities['Country'] == 'in'], df_wcities[df_wcities['Country'] == 'bd'] ,df_wcities[df_wcities['Country'] == 'bt'],df_wcities[df_wcities['Country'] == 'np'],df_wcities[df_wcities['Country'] == 'pk']])","2512ae55":"df_trains.head(10)","7e3cb6a3":"len(df_trains)","3f53bcac":"sub_wcities.head(10)","2f50f15f":"len(sub_wcities[sub_wcities['Country'] == 'in'])","bcee84b0":"df_cities.head(10)","1b8f18f4":"''' Here we will correct some mispellings that had been discovered during the analysis, but deleted from the notebook,\n    for the sake of readibility. '''\n\ndef corr(name):\n    if name == 'Velankanni' or name == 'Vellankanni':\n        return 'Velanganni'\n    elif name == 'Raxual Junction':\n        return 'Raxaul Junction'\n    elif name == 'Alipur Duar Junction':\n        return 'Alipurduar Junction'\n    elif name == 'Chamarajanagar':\n        return 'Chamarajnagar'\n    elif name == 'Dehradun':\n        return 'Dehra Dun'\n    elif name == 'Eranakulam Junction':\n        return 'Ernakulam Junction'\n    elif name == 'Machelipatnam':\n        return 'Machilipatnam'\n    elif name == 'Metupalaiyam':\n        return 'Mettupalaiyam'\n    elif name == 'Mathura Junction':\n        return 'Vrindavan'               # This one is because the World Cities dataset provided Mathura in Andaman Islands first.\n    elif name == 'Murkeongselek':\n        return 'Murkong Selek'\n    elif name == 'Nagarsol':\n        return 'Nagarsul'\n    elif name == 'New Delhi':\n        return 'Newdelhi'\n    elif name == 'Tiruchchirapali':\n        return 'Tiruchchirappalli'\n    elif name == 'Villuparam Junction':\n        return 'Villupuram Junction'\n    elif name == 'Vishakapatnam':\n        return 'Vishakhapatnam'\n    else:\n        return name","33ea0f7b":"ds = df_trains['Starts'].apply(corr)\nde = df_trains['Ends'].apply(corr)\n\ndf_trains_aug = pd.DataFrame()      # Will be used to draw the map\ndf_trains_aug['Train no.'] = df_trains['Train no.']\ndf_trains_aug['Train name'] = df_trains['Train name']\ndf_trains_aug['Starts'] = ds\ndf_trains_aug['Ends'] = de\n\ndf_trains_aug.head(10)","58c348b3":"df_stations = pd.DataFrame()       # Will group info about all the stations\nsta_name = []\nsta_city = []\nsta_lat = []\nsta_long = []\nsta_starts = []\nsta_ends = []\nsta_trains = []\nsta_state = []\nsta_country = []\nunfound = []\nstations_set = set(df_trains_aug['Starts']).union(set(df_trains_aug['Ends']))","abc180b1":"#sub_wcities[sub_wcities['City'] == 'adirampatnam']['Latitude'].to_numpy()[0]","23b489f4":"for s in stations_set:\n    found = False\n    for w in sub_wcities['City']:\n        if not found:\n            if s.lower() in str(w).split(' ') or str(w) in s.lower().split(' ') or str(w) == s.lower():\n                sta_name.append(s)\n                sta_city.append(str(w))\n                sta_lat.append(sub_wcities[sub_wcities['City'] == str(w)]['Latitude'].to_numpy()[0])\n                sta_long.append(sub_wcities[sub_wcities['City'] == str(w)]['Longitude'].to_numpy()[0])\n                sta_starts.append(len(df_trains_aug[df_trains_aug['Starts'] == s]))\n                sta_ends.append(len(df_trains_aug[df_trains_aug['Ends'] == s]))\n                sta_trains.append(len(df_trains_aug[df_trains_aug['Starts'] == s]) + len(df_trains_aug[df_trains_aug['Ends'] == s]))\n                sta_state.append(sub_wcities[sub_wcities['City'] == str(w)]['Region'].to_numpy()[0])\n                sta_country.append(sub_wcities[sub_wcities['City'] == str(w)]['Country'].to_numpy()[0])\n                found = True\n    if not found:\n        unfound.append(s)","a2d10d4a":"sta_starts[:10]\nsta_ends[:10]","2f5ab7e0":"len(unfound)","467c16ac":"unfound","ea208097":"manual_handle = {'Chirmiri':'korea', 'Manduadih':'varanasi', 'Sadulpur Junction':'churu', 'Manuguru':'kothagudem', 'Mayiladuturai J':'mayuram', 'Sengottai':'tenkasi',\n                'Kochuveli':'thiruvananthapuram', 'Patliputra':'danapur', 'Chamarajnagar':'mysore', 'C Shahumharaj T':'kolhapur', 'Lokmanyatilak T':'kurla', 'Gevra Road':'korba',\n                'Singrauli':'churki', 'Shmata V D Ktra':'dudura', 'New Alipurdaur':'alipur duar', 'Alipurduar Junction':'alipur duar', 'Habibganj':'bhopal', 'Banaswadi':'bangalore', 'Jhajha':'jamui',\n                'Sawantwadi Road':'talavada', 'H Nizamuddin':'delhi', 'Naharlagun':'itanagar', 'Nilaje':'mumbai', 'Khairthal':'alwar', 'Udhna Junction':'surat', 'Kirandul':'dantewara',\n                'Kacheguda':'hyderabad', 'Belampalli':'mancherial', 'Radhikapur':'raiganj', 'Borivali':'mumbai', 'Dekargaon':'tezpur', 'Newdelhi': 'new delhi'}\n\nfor s in manual_handle.keys():\n    sta_name.append(s)\n    sta_city.append(manual_handle[s])\n    sta_lat.append(sub_wcities[sub_wcities['City'] == manual_handle[s]]['Latitude'].to_numpy()[0])\n    sta_long.append(sub_wcities[sub_wcities['City'] == manual_handle[s]]['Longitude'].to_numpy()[0])\n    sta_starts.append(len(df_trains_aug[df_trains_aug['Starts'] == s]))\n    sta_ends.append(len(df_trains_aug[df_trains_aug['Ends'] == s]))\n    sta_trains.append(len(df_trains_aug[df_trains_aug['Starts'] == s]) + len(df_trains_aug[df_trains_aug['Ends'] == s]))\n    sta_state.append(sub_wcities[sub_wcities['City'] == manual_handle[s]]['Region'].to_numpy()[0])\n    sta_country.append(sub_wcities[sub_wcities['City'] == manual_handle[s]]['Country'].to_numpy()[0])","05e9afd0":"df_stations['name'] = sta_name\ndf_stations['city'] = sta_city\ndf_stations['latitude'] = sta_lat\ndf_stations['longitude'] = sta_long\ndf_stations['nb_starts'] = sta_starts\ndf_stations['nb_ends'] = sta_ends\ndf_stations['nb_trains'] = sta_trains\ndf_stations['state'] = sta_state\ndf_stations['country'] = sta_country","fe9153a8":"df_stations.describe()","ce76eefb":"stations_map = folium.Map(location=[22.05, 78.94], zoom_start=4.5)\nfor idx, row in df_stations.iterrows():\n    c = 'mediumpurple'\n    if row['nb_ends'] == 0:\n        c = 'royalblue'\n    if row['nb_starts'] == 0:\n        c = 'deeppink'\n    folium.Circle(location=[row['latitude'], row['longitude']], radius=1 + 400 * row['nb_trains'], color = c, fill = True, popup = row['name']).add_to(stations_map)\nstations_map","debd8af4":"df_stations.sort_values('nb_trains',ascending=False).head(10)","d692c70b":"howrah_lines = folium.Map(location=[22.59,88.31], zoom_start=4.5)\nx0 = df_stations[df_stations['name'] == 'Howrah Junction']['latitude'].to_numpy()[0]\nx1 = df_stations[df_stations['name'] == 'Howrah Junction']['longitude'].to_numpy()[0]\nfolium.Marker(location=(x0, x1), icon=Icon(color='purple', icon='train')).add_to(howrah_lines)\nfor idx, row in df_trains_aug.iterrows():\n    if row['Starts'] == 'Howrah Junction':\n        y0 = df_stations[df_stations['name'] == [row['Ends']][0]]['latitude'].to_numpy()[0]\n        y1 = df_stations[df_stations['name'] == [row['Ends']][0]]['longitude'].to_numpy()[0]\n        folium.Marker(location=(y0, y1), icon=Icon(color='green', icon='train')).add_to(howrah_lines)\n    elif row['Ends'] == 'Howrah Junction':\n        y0 = df_stations[df_stations['name'] == [row['Starts']][0]]['latitude'].to_numpy()[0]\n        y1 = df_stations[df_stations['name'] == [row['Starts']][0]]['longitude'].to_numpy()[0]\n        folium.Marker(location=(y0, y1), icon=Icon(color='orange', icon='train')).add_to(howrah_lines)\nhowrah_lines","6737fc83":"foreign_lines = folium.Map(location=[22.05, 78.94], zoom_start=4.5)\nfor idx, row in df_trains_aug.iterrows():\n    if df_stations[df_stations['name'] == row['Starts']]['country'].to_numpy()[0] != 'in':\n        x0 = df_stations[df_stations['name'] == [row['Starts']][0]]['latitude'].to_numpy()[0]\n        x1 = df_stations[df_stations['name'] == [row['Starts']][0]]['longitude'].to_numpy()[0]\n        y0 = df_stations[df_stations['name'] == [row['Ends']][0]]['latitude'].to_numpy()[0]\n        y1 = df_stations[df_stations['name'] == [row['Ends']][0]]['longitude'].to_numpy()[0]\n        folium.PolyLine(locations=[(x0, x1),(y0, y1)], color='limegreen').add_to(foreign_lines)\n    elif df_stations[df_stations['name'] == row['Ends']]['country'].to_numpy()[0] != 'in':\n        x0 = df_stations[df_stations['name'] == [row['Starts']][0]]['latitude'].to_numpy()[0]\n        x1 = df_stations[df_stations['name'] == [row['Starts']][0]]['longitude'].to_numpy()[0]\n        y0 = df_stations[df_stations['name'] == [row['Ends']][0]]['latitude'].to_numpy()[0]\n        y1 = df_stations[df_stations['name'] == [row['Ends']][0]]['longitude'].to_numpy()[0]\n        folium.PolyLine(locations=[(x0, x1),(y0, y1)], color='darkorange').add_to(foreign_lines)\nforeign_lines","c10995e8":"df_cities_stations = pd.DataFrame()\ncs_name = []\ncs_nb_stations = []\ncs_nb_start_trains = []\ncs_nb_end_trains = []\ncs_nb_trains = []\ncs_population = []\ncs_literacy = []\ncs_literacy_gap = []\ncs_graduate = []\ncs_state = []\ncs_latitude = []\ncs_longitude = []","deaed20a":"stat_cities = set(df_stations['city'])\nlen(stat_cities)","429e32f1":"for sc in stat_cities:\n    for C in df_cities['name_of_city']:\n        if sc in C.lower().split(' ') or C.lower() in sc.split(' '):\n            subset = df_stations[df_stations['city'] == sc]\n            cs_name.append(C)\n            cs_nb_stations.append(len(subset))\n            cs_nb_start_trains.append(sum(subset['nb_starts']))\n            cs_nb_end_trains.append(sum(subset['nb_ends']))\n            cs_nb_trains.append(sum(subset['nb_trains']))\n            cs_population.append(df_cities[df_cities['name_of_city'] == C]['population_total'].to_numpy()[0])\n            cs_literacy.append(df_cities[df_cities['name_of_city'] == C]['effective_literacy_rate_total'].to_numpy()[0])\n            cs_literacy_gap.append(df_cities[df_cities['name_of_city'] == C]['effective_literacy_rate_male'].to_numpy()[0] - df_cities[df_cities['name_of_city'] == C]['effective_literacy_rate_female'].to_numpy()[0])\n            cs_graduate.append(df_cities[df_cities['name_of_city'] == C]['total_graduates'].to_numpy()[0])\n            cs_state.append(df_cities[df_cities['name_of_city'] == C]['state_name'].to_numpy()[0])\n            cs_latitude.append(df_cities[df_cities['name_of_city'] == C]['location'].to_numpy()[0].split(',')[0])\n            cs_longitude.append(df_cities[df_cities['name_of_city'] == C]['location'].to_numpy()[0].split(',')[1])\n\ndf_cities_stations['name'] = cs_name\ndf_cities_stations['nb_stations'] = cs_nb_stations\ndf_cities_stations['nb_start_trains'] = cs_nb_start_trains\ndf_cities_stations['nb_end_trains'] = cs_nb_end_trains\ndf_cities_stations['nb_trains'] = cs_nb_trains\ndf_cities_stations['population'] = cs_population\ndf_cities_stations['literacy'] = cs_literacy\ndf_cities_stations['literacy_gap'] = cs_literacy_gap\ndf_cities_stations['graduate'] = cs_graduate\ndf_cities_stations['state'] = cs_state\ndf_cities_stations['latitude'] = cs_latitude\ndf_cities_stations['longitude'] = cs_longitude","4bac08f3":"df_cities_stations.head(10)","a126fe16":"df_cities_stations.sort_values('nb_stations', ascending=False).head(20)","1be4a1c1":"df_cities_stations = df_cities_stations.drop([82,83,148,149])\ndf_cities_stations.sort_values('nb_stations', ascending=False)","d3257a0c":"df_stations[df_stations['city'] == 'new delhi']","b0326562":"for idx, row in df_cities.iterrows():\n    if 'new delhi' in row['name_of_city'].lower():\n        df_cities_stations = df_cities_stations.append(\n                                {'name':row['name_of_city'],\n                                'nb_stations':1,\n                                'nb_start_trains':120,\n                                'nb_end_trains':123,\n                                'nb_trains':243,\n                                'population':df_cities[df_cities['name_of_city'] == row['name_of_city']]['population_total'].to_numpy()[0],\n                                'literacy':df_cities[df_cities['name_of_city'] == row['name_of_city']]['effective_literacy_rate_total'].to_numpy()[0],\n                                'literacy_gap':df_cities[df_cities['name_of_city'] == row['name_of_city']]['effective_literacy_rate_male'].to_numpy()[0] - df_cities[df_cities['name_of_city'] == row['name_of_city']]['effective_literacy_rate_female'].to_numpy()[0],\n                                'graduate':df_cities[df_cities['name_of_city'] == row['name_of_city']]['total_graduates'].to_numpy()[0],\n                                'state':df_cities[df_cities['name_of_city'] == row['name_of_city']]['state_name'].to_numpy()[0],\n                                'latitude':df_cities[df_cities['name_of_city'] == row['name_of_city']]['location'].to_numpy()[0].split(',')[0],\n                                'longitude':df_cities[df_cities['name_of_city'] == row['name_of_city']]['location'].to_numpy()[0].split(',')[1]\n                                },\n                                ignore_index=True)\n","2f81af18":"df_cities_stations.describe()","c56f06eb":"df_cities_stations.hist(bins = 10 , figsize= (12,16))","770ebe0f":"fig, axs = plt.subplots(1,2)\naxs[0].scatter(df_cities_stations['nb_stations'],df_cities_stations['population'])\naxs[0].set_xlabel('Number of stations')\naxs[0].set_ylabel('Population')\naxs[1].scatter(df_cities_stations['nb_trains'],df_cities_stations['population'])\naxs[1].set_xlabel('Number of trains')\nplt.show()","7b05926d":"many_stations = df_cities_stations[df_cities_stations['nb_stations'] >= 3]\nmany_stations","7c582ff9":"df_cities_stations.sort_values('nb_trains', ascending=False).head(10)","53ef28b1":"fig, ax = plt.subplots()\nax.scatter(df_cities_stations['nb_start_trains'],df_cities_stations['nb_end_trains'])\nax.set_xlabel('Number of starting trains')\nax.set_ylabel('Number of ending trains')\nplt.show()","bbc8ee67":"fig, axs = plt.subplots(3,1,figsize=(12,12))\naxs[0].scatter(df_cities_stations['literacy'],df_cities_stations['nb_trains'])\naxs[0].set_ylabel('Number of trains')\naxs[0].set_xlabel('Literacy')\naxs[1].scatter(df_cities_stations['literacy_gap'],df_cities_stations['nb_trains'])\naxs[1].set_ylabel('Number of trains')\naxs[1].set_xlabel('Gender inequality against literacy')\naxs[2].scatter(df_cities_stations['graduate']\/df_cities_stations['population'],df_cities_stations['nb_trains'])\naxs[2].set_ylabel('Number of trains')\naxs[2].set_xlabel('Rate of graduated inhabitants')\nplt.show()","cdc657b5":"states = set(df_stations['state'])\nstations_by_state = {}\nfor s in states:\n    stations_by_state[s] = []\n    for idx,row in df_stations.iterrows():\n        if row['state'] == s:\n            #stations_by_state[s].append(row['city'])\n            c = row['city']\n            for C in df_cities['name_of_city']:\n                if c in C.lower() or C.lower() in c:\n                    S = df_cities[df_cities['name_of_city'] == C]['state_name'].to_numpy()[0]\n                    stations_by_state[s].append(S)\n            \nstations_by_state","2c0559c9":"stations_by_state.pop(8)\nstations_by_state.pop('02')\nstations_by_state.pop('04')\nstations_by_state.pop('06')\nstations_by_state.pop('07')\ntrad_table = {}\nfor sbs in stations_by_state:\n    threshold = 2 * len(stations_by_state[sbs]) \/ 3\n    sts = set(stations_by_state[sbs])\n    aux = {}\n    for s in sts:\n        aux[s] = stations_by_state[sbs].count(s)\n    trad_table[sbs] = ''\n    for t in sts:\n        if aux[t] >= threshold:\n            trad_table[sbs] = t\n            \ntrad_table","df02567c":"Here, we can see that our algorithm did not treat efficiently the city sharing a same name (Mumbai and Delhi\/New Delhi). Let's correct them manually.\nFor Mumbai, we will put everything into the 'Greater Mumbai' ensemble, as there is few doubt every Mumbai station is inside of it. We will as well drop the Delhi Cantonment, and distinguish Delhi from New Delhi.","ab6674a0":"The first information we extract from these quick views, is that there are very few cities with more than one station. The number of trains as well is quite low for most cities. It is also interesting to note that the shape of population hist looks like the number of train. We should explore if there is a correlation. The 'graduate' column is not very readible, as it is expressed in population rather than percentage.","3074b9f4":"There are 30 unfound stations. This is something we can handle by hand, by looking for information on the internet, althought it will not be very fun... The idea is to attribute them the closest city in the cities dataset.","cbde0648":"Our new dataset is now complete. So we will first look at a description of it.","12b20186":"The World Cities database contains much more entries than the Top 500 Indian Cities one. For India alone, it provides data on almost 40 000 cities, much than the top 500. Nonetheless, the Top 500 Indian Cities dataset provides much more information on each entry, so we will try to see later what can be found out of it.","74f6c515":"We see that there are four stations with more than 200 trains. Howrah Junction is the first one in number of trains, as well as in number of starting and ending trains. So, let's draw the map of Howrah Junction's trains !","2c2556a6":"Green markers show the trains starting from Howrah Junction. Orange markers for the trains ending at Howrah Junction. That station seems to cover quite all the territory.\nNow, let's look at the international lines.","c90f794b":"In this section, we want to make a study at the level of the state. In the World Cities dataset, there is a column called region, with digital values. In the Top 500 Indian Cities, there is a column call state_name, that contains the names of the states. We want to find a way to match those columns from both dataset, and ideally keep the complete name as reference. So first, let's look if it is perfectly matching.","59542b6a":"There is nothing absolutely obvious that comes out these graphs. It means that the number of trains is not a direct way to study demographics of a city. We can, nonetheless, find some interesting features:\n* The cities with the highest number of trains have a good literacy rate.\n* The shape of graduated inhabitants graph does not match perfectly the one of literacy. We can suppose that literacy is required in very frequented cities, but there are jobs for many kinds of people, so graduation is not as much necessary. Cities with highest rates of graduated people have few trains, and are probably cities where elites are living.\n* Cities with highest gender inequality toward literacy have few trains, whereas cities with most trains have a quite good score. So it seems that being connected is a good way to fight geneder inequality.\n","81708d05":"Delhi and Mumbai are the cities with most stations. 4 for Mumbai and 3 for Delhi.","8be2141b":"About cities, as the World Cities dataset is very big (more than 2 millions entries), we will focus on the cities from India and some neighbour countries, which should be enough.","55273b02":"The previous scatter is pretty linear, which indicates that the number of trains starting from a city is similar to number of trains ending in that same city. Thus, it will not be very useful to conduct separate studies on starting and ending trains. Trains must be enough.","e76aa12f":"## Datasets exploration and cleaning","5789dd02":"This map shows all the stations of the dataset. Circles radius depend on the number of train of the station. Stations in blue are start stations, stations in red are end stations, and purple stations can be start or end. We can see that blue and red stations are only small stations. Stations in foreing countries are small, because we show only their trains for India.  We can guess that are many internal trains as well. We also see that biggest stations are often to other big stations, in the big cities, like New Delhi, Kolkatta, Chennai or Bangalore.","b2bfc858":"Another interesting thing to do with maps would be to represent the trains themselves. It can be approximated by a line from the start station to the end station of the trains. We saw at the beginning of this notebook, that there are 4 024 trains on the dataset. Of course, such a high number of lines on a single map would be hideous, whatever the size of the map. But it can still be interesting to draw map that show a specific subset of trains. For example, the ones from the most frequented station. Let's look at the most frequented stations.","7ad9539f":"To be continued...","18d2c1fd":"In green: trains starting from outside, and coming to India.\nIn orange: trains starting from India, and going outside.\nMost of foreign stations are located in Pakistan, plus one in Bhutan.","47308784":"Nonetheless, Chennai, with 2 stations, and New Delhi, with only one station, have more trains than Mumbai or Delhi. We will focus on the number of trains, which seems to be more interesting than the bumber of stations.","47acb887":"Let's build a DataFrame focused on the train stations.","e35ea1db":"As we can see, some states seem to perfectly match, like (7.0 : NCT OF DELHI) or (25.0 : TAMIL NADU), whereas others are still very hard to determine, like the 8 or the 11. We can also note that there are three different formats in the regions \"names\" (keys): float, int and string. Float is the main type, and is probably for Indian regions. The int is unique, and there are 4 str. I guess str is for Pakistanese regions, as it is almost empty (except '04', which must be a homonymous), and there are 3 totally different values in the integer one (8), so maybe it is also a foreign country. In any case, we are not able to work with it, so it is going to be torn apart as well. Let's admit that when at least 2\/3 of the corresponding state for a region is the same, they designate the same thing.","585c359f":"## Map of the stations ","4604010a":"### Stations and trains by state","c5b5a6b1":"The two most populated cities have the most stations (3 and 4). It is less clear for less populated cities, as they can have 1 or 2 stations. The cloud about the number of trains is still more surprising. The city with most trains is far from being the most populated, and so has only 1 or 2 stations.","615ce10f":"We will now work with the subset of states we identified.","f717c150":"## Demographics analysis\n\n### Cities analysis"}}