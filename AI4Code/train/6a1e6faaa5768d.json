{"cell_type":{"389e1d1d":"code","e0f72402":"code","7ef5456c":"code","652dc598":"code","35ae0b4c":"code","5c7b7892":"code","81e461fb":"code","39848890":"code","e7a3ddbf":"code","b2d42abc":"code","f4c6c5b0":"code","d101da97":"code","2fc89346":"code","db0ce7e5":"code","7e9f7451":"code","ee374a2e":"code","8310d853":"code","eccd5418":"code","aa93621c":"code","29ca59fb":"code","c5d3b8ba":"code","f02f26f6":"markdown","aa49d46e":"markdown","894ef584":"markdown","9932f0e0":"markdown","c131e971":"markdown","3c70472b":"markdown","01d3077c":"markdown","bd70e4e5":"markdown","1f80c63a":"markdown","65647b21":"markdown","e006a34a":"markdown","c81c1099":"markdown","72f91fea":"markdown","4e39bd9a":"markdown"},"source":{"389e1d1d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e0f72402":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nfrom keras.layers import Dense, BatchNormalization, Dropout, LSTM\nfrom keras.models import Sequential\nfrom keras.utils import to_categorical\nfrom keras import callbacks\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score","7ef5456c":"#loading data\ndata = pd.read_csv(\"..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv\")\ndata.head()","652dc598":"data.info()","35ae0b4c":"#first of all let us evaluate the target and find out if our data is imbalanced or not\ncols= [\"#6daa9f\",\"#774571\"]\nsns.countplot(x= data[\"DEATH_EVENT\"], palette= cols)","5c7b7892":"#Examaning a corelation matrix of all the features \ncmap = sns.diverging_palette(275,150,  s=40, l=65, n=9)\ncorrmat = data.corr()\nplt.subplots(figsize=(18,18))\nsns.heatmap(corrmat,cmap= cmap,annot=True, square=True);","81e461fb":"#Evauating age distrivution \nplt.figure(figsize=(20,12))\n#colours =[\"#774571\",\"#b398af\",\"#f1f1f1\" ,\"#afcdc7\", \"#6daa9f\"]\nDays_of_week=sns.countplot(x=data['age'],data=data, hue =\"DEATH_EVENT\",palette = cols)\nDays_of_week.set_title(\"Distribution Of Age\", color=\"#774571\")","39848890":"# Boxen and swarm plot of some non binary features.\nfeature = [\"age\",\"creatinine_phosphokinase\",\"ejection_fraction\",\"platelets\",\"serum_creatinine\",\"serum_sodium\", \"time\"]\nfor i in feature:\n    plt.figure(figsize=(8,8))\n    sns.swarmplot(x=data[\"DEATH_EVENT\"], y=data[i], color=\"black\", alpha=0.5)\n    sns.boxenplot(x=data[\"DEATH_EVENT\"], y=data[i], palette=cols)\n    plt.show()","e7a3ddbf":"sns.kdeplot(x=data[\"time\"], y=data[\"age\"], hue =data[\"DEATH_EVENT\"], palette=cols)","b2d42abc":"data.describe().T","f4c6c5b0":"#assigning values to features as X and target as y\nX=data.drop([\"DEATH_EVENT\"],axis=1)\ny=data[\"DEATH_EVENT\"]","d101da97":"#Set up a standard scaler for the features\ncol_names = list(X.columns)\ns_scaler = preprocessing.StandardScaler()\nX_df= s_scaler.fit_transform(X)\nX_df = pd.DataFrame(X_df, columns=col_names)   \nX_df.describe().T","2fc89346":"#looking at the scaled features\ncolours =[\"#774571\",\"#b398af\",\"#f1f1f1\" ,\"#afcdc7\", \"#6daa9f\"]\nplt.figure(figsize=(20,10))\nsns.boxenplot(data = X_df,palette = colours)\nplt.xticks(rotation=90)\nplt.show()","db0ce7e5":"#spliting test and training sets\nX_train, X_test, y_train,y_test = train_test_split(X_df,y,test_size=0.25,random_state=7)","7e9f7451":"early_stopping = callbacks.EarlyStopping(\n    min_delta=0.001, # minimium amount of change to count as an improvement\n    patience=20, # how many epochs to wait before stopping\n    restore_best_weights=True)\n\n# Initialising the NN\nmodel = Sequential()\n\n# layers\nmodel.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu', input_dim = 12))\nmodel.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\nfrom keras.optimizers import SGD\n# Compiling the ANN\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Train the ANN\nhistory = model.fit(X_train, y_train, batch_size = 32, epochs = 500,callbacks=[early_stopping], validation_split=0.2)","ee374a2e":"val_accuracy = np.mean(history.history['val_accuracy'])\nprint(\"\\n%s: %.2f%%\" % ('val_accuracy', val_accuracy*100))","8310d853":"history_df = pd.DataFrame(history.history)\n\nplt.plot(history_df.loc[:, ['loss']], \"#6daa9f\", label='Training loss')\nplt.plot(history_df.loc[:, ['val_loss']],\"#774571\", label='Validation loss')\nplt.title('Training and Validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(loc=\"best\")\n\nplt.show()","eccd5418":"history_df = pd.DataFrame(history.history)\n\nplt.plot(history_df.loc[:, ['accuracy']], \"#6daa9f\", label='Training accuracy')\nplt.plot(history_df.loc[:, ['val_accuracy']], \"#774571\", label='Validation accuracy')\n\nplt.title('Training and Validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","aa93621c":"# Predicting the test set results\ny_pred = model.predict(X_test)\ny_pred = (y_pred > 0.5)\nnp.set_printoptions()","29ca59fb":"# confusion matrix\ncmap1 = sns.diverging_palette(275,150,  s=40, l=65, n=6)\nplt.subplots(figsize=(12,8))\ncf_matrix = confusion_matrix(y_test, y_pred)\nsns.heatmap(cf_matrix\/np.sum(cf_matrix), cmap = cmap1, annot = True, annot_kws = {'size':15})","c5d3b8ba":"print(classification_report(y_test, y_pred))","f02f26f6":"**About the data:**\n\n* age: Age of the patient\n* anaemia: If the patient had the haemoglobin below the normal range\n* creatinine_phosphokinase: The level of the creatine phosphokinase in the blood in mcg\/L\n* diabetes: If the patient was diabetic\n* ejection_fraction: Ejection fraction is a measurement of how much blood the left ventricle pumps out with each contraction\n* high_blood_pressure: If the patient had hypertension\n* platelets: Platelet count of blood in kiloplatelets\/mL\n* serum_creatinine: The level of serum creatinine in the blood in mg\/dL\n* serum_sodium: The level of serum sodium in the blood in mEq\/L\n* sex: The sex of the patient\n* smoking: If the patient smokes actively or ever did in past\n* time: It is the time of the patient's follow-up visit for the disease in months\n* DEATH_EVENT: If the patient deceased during the follow-up period","aa49d46e":"# **<span style=\"color:#6daa9f;\">LOADING DATA<\/span>**","894ef584":" # <h1 style='background:#6daa9f; border:0; color:black'><center>HEART FAILURE<\/center><\/h1> \n ![Yellow%20and%20Black%20Personal%20Trainer%20LinkedIn.png](attachment:Yellow%20and%20Black%20Personal%20Trainer%20LinkedIn.png)\n\nCardiovascular diseases are the most common cause of deaths globally, taking an estimated 17.9 million lives each year, which accounts for 31% of all deaths worldwide. Heart failure is a common event caused by Cardiovascular diseases. It is characterized by the heart\u2019s inability to pump an adequate supply of blood to the body. Without sufficient blood flow, all major body functions are disrupted. Heart failure is a condition or a collection of symptoms that weaken the heart. \n","9932f0e0":"# **<span style=\"color:#6daa9f;\">DATA PREPROCESSING<\/span>**\n\n**Steps involved in Data Preprocessing**\u00a0\n* Dropping the outliers based on data analysis\n* Assigning values to features as X and target as y\n* Perform the scaling of the features\n* Split test and training sets","c131e971":"Point to note is that there is an imbalance in the data.","3c70472b":"**Plotting training and validation loss over epochs**","01d3077c":"**Notable points:**\n* Time of the patient's follow-up visit for the disease is crucial in as initial diagnosis with cardiovascular issue and treatment reduces the chances of any fatality. It holds and inverse relation. \n* Ejection fraction is the second most important feature. It is quite expected as it is basically the efficiency of the heart.\n* Age of the patient is the third most correlated feature. Clearly as heart's functioning declines with ageing \n\n**Next, we will examine the count plot of age.**","bd70e4e5":"I spotted outliers on our dataset. I didn't remove them yet as it may lead to overfitting. Though we may end up with better statistics. In this case, with medical data, the outliers may be an important deciding factor.\n\nNext, we examine the kdeplot of time and age as they both are significant features.","1f80c63a":"\n# **<span style=\"color:#6daa9f;\">DATA ANALYSIS<\/span>**\n\nSteps in data analysis and visulisation:\n\nWe begin our analysis by plotting a count plot\u00a0of the targer attribute. \nA corelation matrix od the various attributes to examine the feature importance.\n\n","65647b21":"# **<span style=\"color:#6daa9f;\">CONCLUSIONS<\/span>**\n\n**Concluding the model with:**\n\n* Testing on the test set\n* Evaluating the confusion matrix\n* Evaluating the classification report","e006a34a":"**<span style=\"color:#b398af;\"> If you liked this Notebook, please do upvote.<\/span>**\n\n**<span style=\"color:#b398af;\"> If you have any suggestions or questions, feel free to comment!<\/span>**\n\n**<span style=\"color:#b398af;\">Best Wishes!<\/span>**\n\n\n# <h1 style='background:#6daa9f; border:0; color:black'><center>FIN<\/center><\/h1> ","c81c1099":"**Plotting training and validation accuracy over epochs**","72f91fea":"# **<span style=\"color:#6daa9f;\">MODEL BUILDING<\/span>**\n\nIn this project, we build an artificial neural network.\n\n**Following steps are involved in the model building**\n* Initialising the ANN\n* Defining by adding layers\n* Compiling the ANN\n* Train the ANN","4e39bd9a":" # **<span style=\"color:#6daa9f;\">TABLE OF CONTENTS<\/span>**\n \n\n**IMPORTING LIBRARIES**\n\n**LOADING DATA**\n\n**DATA ANALYSIS**\n\n**DATA PREPROCESSING**\n\n**MODEL BUILDING**\n\n**CONCLUSIONS**\n\n# **<span style=\"color:#6daa9f;\">IMPORTING LIBRARIES<\/span>**\n"}}