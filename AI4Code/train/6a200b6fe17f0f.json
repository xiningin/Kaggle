{"cell_type":{"aaf7febe":"code","e427b539":"code","d65206a4":"code","af590637":"code","15664955":"code","03dab22d":"code","afa4d7d2":"code","2f344859":"code","0d17d8d9":"code","da18029f":"code","b6acce06":"code","74d3a8e6":"code","5623ac0c":"code","16e55381":"code","33246b45":"code","8578e293":"code","2b5885be":"code","c8b2dea9":"code","58cb5432":"code","6f81fdb0":"code","94b2c3e7":"code","390ce8ec":"code","b1c8970c":"code","c181ec93":"code","5ed83f5f":"code","27743646":"code","cc3b58c9":"code","dd5d43a5":"code","0a5022d9":"code","1a5f88f1":"code","965e5735":"code","314d6708":"markdown","82b4c9fd":"markdown","a3bdc3a7":"markdown"},"source":{"aaf7febe":"import numpy as np\nimport pandas as pd\n\n# Visualization Library\nimport seaborn as sns\nimport plotly.express as px\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Machine Learning\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score\n\n# Deep Learning\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Embedding, LSTM\nfrom tensorflow.keras.layers import Conv1D, MaxPool1D,SpatialDropout1D\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nfrom tensorflow.keras.initializers import Constant\nfrom tensorflow.keras.optimizers import Adam\n\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport nltk\nfrom wordcloud import WordCloud\n\nimport re\n\nfrom tqdm import tqdm","e427b539":"fake = pd.read_csv('..\/input\/fake-and-real-news-dataset\/Fake.csv')\nfake.head()","d65206a4":"real = pd.read_csv('..\/input\/fake-and-real-news-dataset\/True.csv')\nreal.head()","af590637":"real['label'] = 1","15664955":"fake['subject'].unique()","03dab22d":"real['subject'].unique()","afa4d7d2":"fake['label']=0","2f344859":"data=real.append(fake,ignore_index=True)","0d17d8d9":"data.head()","da18029f":"data['title'][13]","b6acce06":"data['text'][0]","74d3a8e6":"text = data['text']","5623ac0c":"from nltk.corpus import stopwords","16e55381":"text1 = [word for word in text  if word not in stopwords.words('english')]\ntext1[0]","33246b45":"text2 =  [re.sub('@[\\w-]+','',word) for word in text1]\ntext3 = [re.sub('[^a-zA-Z0-9 \\n\\.]', '',word) for word in text2]\ntext4 = [word.lower() for word in text3]\n\n","8578e293":"text4[0]","2b5885be":"data['text']=text4","c8b2dea9":"y = data[\"label\"].values\n#Converting X to format acceptable by gensim, removing annd punctuation stopwords in the process\nX = []\nstop_words = set(nltk.corpus.stopwords.words(\"english\"))\ntokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\nfor par in data[\"text\"].values:\n    tmp = []\n    sentences = nltk.sent_tokenize(par)\n    for sent in sentences:\n        sent = sent.lower()\n        tokens = tokenizer.tokenize(sent)\n        filtered_words = [w.strip() for w in tokens if w not in stop_words and len(w) > 1]\n        tmp.extend(filtered_words)\n    X.append(tmp)\n\ndel data","58cb5432":"val1=sorted([len(word) for word in X ])\nval1[-1]","6f81fdb0":"MAX_LEN=100\n\ntokenizer_obj=Tokenizer()\ntokenizer_obj.fit_on_texts(X)\nsequences = tokenizer_obj.texts_to_sequences(X)\n\ntweet_pad=pad_sequences(sequences,maxlen=MAX_LEN,truncating='post',padding='post')","94b2c3e7":"tweet_pad","390ce8ec":"word_index=tokenizer_obj.word_index\nlen(word_index)","b1c8970c":"global_vectors={}\nwith open('..\/input\/glove-global-vectors-for-word-representation\/glove.6B.100d.txt') as f:\n    for line in f:\n        vectors=line.split()\n        word=vectors[0]\n        value=vectors[1:]\n        global_vectors[word]=value\n        \n        \n\n    ","c181ec93":"num_words=len(word_index)+1\nembedding_matrix=np.zeros((num_words,100))\n\nfor word,i in tqdm(word_index.items()):\n    if i > num_words:\n        continue\n    \n    emb_vec=global_vectors.get(word)\n    if emb_vec is not None:\n        embedding_matrix[i]=emb_vec\n            ","5ed83f5f":"model=Sequential()\n\nembedding=Embedding(num_words,100,embeddings_initializer=Constant(embedding_matrix)\n                    ,input_length=MAX_LEN, trainable=False)\n\nmodel.add(embedding)\nmodel.add(SpatialDropout1D(0.2))\nmodel.add(LSTM(64,dropout=0.2,recurrent_dropout=0.2))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.summary()","27743646":"optimizer = Adam(learning_rate=1e-5)\nmodel.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])","cc3b58c9":"\nX_train,X_test,y_train,y_test = train_test_split(tweet_pad,data['label'],\n                                                 random_state=0, test_size=0.2)","dd5d43a5":"history=model.fit(X_train,y_train,batch_size=4,epochs=15,validation_data=(X_test,y_test),verbose=2)","0a5022d9":"import pickle\nfrom tensorflow.keras.models import load_model","1a5f88f1":"model.save('model.h5')","965e5735":"model2 = load_model('model.h5')","314d6708":"#### To save a model","82b4c9fd":"#### To Load a model","a3bdc3a7":"### Global Vectors"}}