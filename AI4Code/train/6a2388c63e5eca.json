{"cell_type":{"7f500ea4":"code","3ac5a1ae":"code","37a2ec71":"code","167fc1be":"code","d919a3b7":"code","82e64e9b":"code","a21838bb":"code","7819db01":"code","855e9dc8":"code","eae8d622":"code","e2f7b3b3":"code","d5783515":"code","109e0a32":"code","7edfc95f":"code","72088dd9":"code","2381956d":"code","e4851100":"code","50e32243":"code","54bd84e8":"code","32b25cac":"code","ce99ae08":"code","82b2c17f":"code","7449392d":"code","6e4f6566":"code","21ec23d9":"code","ca773fc4":"code","5274809e":"markdown"},"source":{"7f500ea4":"import xgboost as xgb\nimport numpy as np\nimport pandas as pd\nimport random\nimport optuna\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error","3ac5a1ae":"train = pd.read_csv(\"..\/input\/tabular-playground-series-apr-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-apr-2021\/test.csv\")","37a2ec71":"train.head()","167fc1be":"train.columns.to_list()","d919a3b7":"train.info()","82e64e9b":"train['Survived'].value_counts()","a21838bb":"from sklearn.preprocessing import LabelEncoder\ndf=train\nfor c in df.columns:\n    if df[c].dtype=='object': \n        lbl = LabelEncoder()\n        df[c]=df[c].fillna('N')\n        lbl.fit(list(df[c].values))\n        df[c] = lbl.transform(df[c].values)\ntrain=df","7819db01":"df=test\nfor c in df.columns:\n    if df[c].dtype=='object': \n        lbl = LabelEncoder()\n        df[c]=df[c].fillna('N')\n        lbl.fit(list(df[c].values))\n        df[c] = lbl.transform(df[c].values)\ntest=df","855e9dc8":"target = train['Survived']\ndata = train.drop(['Survived','PassengerId','Name','Ticket'],axis=1)","eae8d622":"columns=data.columns.to_list()\nprint(columns)","e2f7b3b3":"def objective(trial,data=data,target=target):\n    \n    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.2,random_state=42)\n    param = {\n        'objective': trial.suggest_categorical('objective',['reg:logistic','reg:tweedie']), \n        'tree_method': trial.suggest_categorical('tree_method',['hist']),  # 'gpu_hist','hist'\n        'lambda': trial.suggest_loguniform('lambda',1e-3,10.0),\n        'alpha': trial.suggest_loguniform('alpha',1e-3,10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.01,0.012,0.014,0.016,0.018,0.02]),\n        'n_estimators': trial.suggest_categorical('n_estimators', [1000,2000,4000,8000]),\n        'max_depth': trial.suggest_categorical('max_depth', [5,7,9,11,13,15,17,20]),\n        'random_state': trial.suggest_categorical('random_state', [24,48,2020]),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1,300),\n        'use_label_encoder': trial.suggest_categorical('use_label_encoder',[False])\n    }\n    model = xgb.XGBClassifier(**param)      \n    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=100,verbose=False)\n    preds = model.predict(test_x)\n    rmse = mean_squared_error(test_y, preds,squared=False)\n    \n    return rmse","d5783515":"study = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=8)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)","109e0a32":"study.trials_dataframe()","7edfc95f":"# shows the scores from all trials\noptuna.visualization.plot_optimization_history(study)","72088dd9":"# interactively visualizes the hyperparameters and scores\noptuna.visualization.plot_parallel_coordinate(study)","2381956d":"# shows the evolution of the search\noptuna.visualization.plot_slice(study)","e4851100":"# parameter interactions on an interactive chart.\noptuna.visualization.plot_contour(study, params=['colsample_bytree','random_state'])","50e32243":"# Visualize parameter importances.\noptuna.visualization.plot_param_importances(study)","54bd84e8":"# Visualize empirical distribution function\noptuna.visualization.plot_edf(study)","32b25cac":"Best_trial=study.best_trial.params\nprint(Best_trial)","ce99ae08":"sample = pd.read_csv(\"..\/input\/tabular-playground-series-apr-2021\/sample_submission.csv\")\nprint(sample.shape)","82b2c17f":"test[columns]","7449392d":"preds = np.zeros((sample.shape[0]))\nkf = KFold(n_splits=5,random_state=48,shuffle=True)\nfor trn_idx, test_idx in kf.split(train[columns],target):\n    X_tr,X_val=train[columns].iloc[trn_idx],train[columns].iloc[test_idx]\n    y_tr,y_val=target.iloc[trn_idx],target.iloc[test_idx]\n    model = xgb.XGBClassifier(**Best_trial)\n    model.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=100,verbose=False)\n    preds+=model.predict(test[columns])\/kf.n_splits   ###### predict_proba\n    rmse=mean_squared_error(y_val, model.predict(X_val),squared=False)\n    print(rmse)","6e4f6566":"print(preds.shape)\nprint(preds[0])","21ec23d9":"subm = sample\nsubm['Survived'] = preds.astype(int)\nsubm.to_csv('submission.csv',index=False)\nsubm","ca773fc4":"subm['Survived'].value_counts()","5274809e":"# XGBoost with Optuna tuning\n* doc: \nhttps:\/\/github.com\/optuna\/optuna"}}