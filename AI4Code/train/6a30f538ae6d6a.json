{"cell_type":{"fe0b9087":"code","8105178f":"code","ab7b713c":"code","482e5796":"code","4a078994":"code","5b0ba458":"code","c5cf22b9":"code","d5177e45":"code","5e8590f2":"code","f22fc97a":"code","34af86fc":"code","cf59c432":"markdown","660f5f43":"markdown","40e83c21":"markdown","4f7097a8":"markdown","0e7c7d68":"markdown","acf72f16":"markdown","384f0c57":"markdown","82da7399":"markdown","8e992277":"markdown","a3a58c52":"markdown","33d0dfa8":"markdown"},"source":{"fe0b9087":"import os\nfrom operator import itemgetter\nfrom pathlib import Path\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import SGDRegressor, Ridge, Lasso\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom joblib import dump\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.kernel_ridge import KernelRidge\nimport matplotlib.pyplot as plt # Visualization\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold","8105178f":"df = pd.read_csv('..\/input\/krrproject\/DATA_1000.dat',sep=\"\\t\",header=None,skiprows=[0], names=['X','Y'])\ndf.head()","ab7b713c":"\nparams_grid={\n            'alpha':         [0.1,0.2,0.3,0.4],\n            'degree':        [1,5,10,15],\n            'gamma':         [0.1,0.2,0.3,0.4],\n            'coef0':         [2,5,10,30]\n}\n\nmodels = [\n    {   'name':     'KernelRidge_rbf',\n        'model':    KernelRidge(kernel='rbf'),\n        'param_grid': params_grid\n    },\n    {   'name':     'KernelRidge_polynomial',\n        'model':    KernelRidge(kernel='polynomial'),\n        'param_grid': params_grid\n    },\n    {   'name':     'KernelRidge_laplacian',\n        'model':    KernelRidge(kernel='laplacian'),\n        'param_grid': params_grid\n    },\n]\n","482e5796":"def tune_models_hyperparams(X, y, models):\n    grids = {}\n#GridSearchCV cv = 5 this mean kFolds=5 \n# https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.GridSearchCV.html\n    for model in models:\n        grids[model['name']] = (GridSearchCV( model['model'],param_grid=model['param_grid'],cv=5, verbose=0, n_jobs=-1)  \n                                .fit(X, y))\n    return grids\n","4a078994":"def get_best_model(grid, X_test, y_test):\n    res = {name : round(mean_absolute_error(y_test, model.predict(X_test)), 3)\n           for name, model in grid.items()}\n    print('Mean Absolute Error:', res)\n    best_model_name = min(res, key=res.get)\n    return grid[best_model_name]","5b0ba458":"colors=['red','yellow','green']\ncolors2=['black','indigo','gold']\n\ndef print_grid_results(grids):\n    i=0;\n    for name, model in grids.items():\n        print('{:*^70}'.format(' [' + name + '] '))\n        print('Score:\\t\\t{:.2%}'.format(model.best_score_))\n        print('Parameters:\\t{}'.format(model.best_params_))        \n        plt.plot(X,model.predict(X), color=colors[i], label=name,linewidth=4)\n        plt.scatter(X_test,model.predict(X_test), color=colors2[i], label=name+\" test\",s=2)\n        i+=1","c5cf22b9":"# fix chart size\nw = 1200\nh = 600\nfig, ax = plt.subplots()\nfig.set_size_inches(w\/fig.dpi, h\/fig.dpi)\n\n\nX = df.X.values.reshape(-1,1)\ny = df.Y.values.reshape(-1,1)\nX_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.25)\n\ngrid = tune_models_hyperparams(X_train, y_train, models)\n\nprint_grid_results(grid)    \n\nplt.scatter(X,y, color='blue', label='original data',s=2)\nplt.legend()\nplt.show() \n\nbest_model=get_best_model(grid, X, y)","d5177e45":"data={}\ndata[200] = pd.read_csv('..\/input\/krrproject\/DATA_200.dat',sep=\"\\t\",header=None,skiprows=[0], names=['X','Y'])\ndata[500] = pd.read_csv('..\/input\/krrproject\/DATA_500.dat',sep=\"\\t\",header=None,skiprows=[0], names=['X','Y'])\ndata[800] = pd.read_csv('..\/input\/krrproject\/DATA_800.dat',sep=\"\\t\",header=None,skiprows=[0], names=['X','Y'])\n\n","5e8590f2":"best_kernel = best_model.estimator.kernel","f22fc97a":"def tune_hyperparams_with_mse():\n    grids = {}\n    kf = KFold(n_splits=5)\n    for key,datum in data.items():\n        X = datum.X.values.reshape(-1,1)\n        y = datum.Y.values.reshape(-1,1)\n        X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.25)\n        model_key=f\"{best_kernel}_{key}\";  \n        grids[model_key]={}\n        grids[model_key]['model'] = (GridSearchCV(KernelRidge(kernel=best_kernel),param_grid=params_grid,cv=5, verbose=0, n_jobs=-1)  \n                                .fit(X_train, y_train))\n        grids[model_key]['mse_min']=round(mean_absolute_error(y_test, grids[model_key]['model'].predict(X_test)),3)\n        grids[model_key]['mse_points']= cross_val_score(grids[model_key]['model'].estimator, X_train,y_train, cv=kf,scoring='neg_mean_absolute_error')\n        print('{:*^70}'.format(f' [{best_kernel} {key}] '))\n        print('Score:\\t\\t{:.2%}'.format(grids[model_key]['model'].best_score_))\n        print('Parameters:\\t{}'.format(grids[model_key]['model'].best_params_))        \n    return grids\n","34af86fc":"grids=tune_hyperparams_with_mse()\n\nfor key,grid in grids.items():\n    plt.plot(np.arange(1,6),grid['mse_points'], color='blue', label=key+\" mae\",linewidth=4)\n    plt.legend()\n    plt.show() \n","cf59c432":"read `data_1000` file and ignore first line and set `X` `Y` name of columns data","660f5f43":"read  files for second question and set its in `data` array","40e83c21":"print and paint charts  ","4f7097a8":"this funcation calucate mae for every model and return best model","0e7c7d68":"* define parameters that mentioned in the question `alpha`, `degree` , `gamma` , `coef0` \n* define models that mentioned in the question with his kernels","acf72f16":"import required libs","384f0c57":"this funcation will select best hyperparams for  our `models` with `X` input and target of `y` by using gridSeearchCV funcation that work on models to select best parms    ","82da7399":"start project  from here and ","8e992277":"save best kernel from previos question in `best_kernel` variable","a3a58c52":"this funcation will get best best params and `mse` and return all result in `grid` variable","33d0dfa8":"print chart that returned from `tune_hyperparams_with_mse` funcation"}}