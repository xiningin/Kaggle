{"cell_type":{"8b5e75c5":"code","7ce05402":"code","343c718b":"code","2157a9d1":"code","4a78e573":"code","24ec0c13":"code","b835bc01":"code","646f476e":"code","c6666a72":"code","fa243691":"code","bf7e5b7d":"code","ad2a540a":"code","c846b26b":"code","0d729494":"code","6f2b8b93":"code","10581c11":"code","1cb8b1af":"code","56172767":"code","f0e87eee":"code","11a8ae09":"code","1f577d78":"code","b6ea1dbc":"code","af11152f":"code","0e5069ad":"code","88fb22df":"code","e9bcbd8c":"code","2ca62a07":"code","33a1f774":"code","26a50da6":"code","f679ee05":"code","3f110c28":"code","3ceea12b":"code","b02e1a16":"code","d4d77b3f":"code","2cd8bdd5":"code","6f0b5398":"code","608b9614":"code","064ff95c":"markdown","076ef53e":"markdown","2905f0b8":"markdown","f58655d4":"markdown","48d53254":"markdown","8eeebbea":"markdown","b7b3b5fe":"markdown","fe85f77a":"markdown","af3d9772":"markdown","0494d251":"markdown","aced7b33":"markdown","654df976":"markdown","be504ddf":"markdown","25272cdd":"markdown","5f46e612":"markdown","e63138f3":"markdown","ffadc27e":"markdown","3e1affa5":"markdown"},"source":{"8b5e75c5":"import pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt \nplt.rc(\"font\", size=14)\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nsns.set(style=\"white\")\nsns.set(style=\"whitegrid\", color_codes=True)\nimport warnings\nwarnings.filterwarnings('ignore')","7ce05402":"data = pd.read_csv('..\/input\/HR-Employee-Attrition.csv', header=0)\ndata = data.dropna()\nprint(data.shape)","343c718b":"print(list(data.columns))","2157a9d1":"data.head()","4a78e573":"data.drop(columns='Attrition').dtypes","24ec0c13":"print(data['Attrition'].dtype)","b835bc01":"data.isna().sum()","646f476e":"data.duplicated().sum()","c6666a72":"data['Attrition'].replace({'No':0,'Yes':1},inplace=True)","fa243691":"num_cols = data.select_dtypes(include = np.number)","bf7e5b7d":"a = num_cols[num_cols.columns].hist(bins=15, figsize=(15,35), layout=(9,3),color = 'red',alpha=0.6)","ad2a540a":"cat_col = data.select_dtypes(exclude=np.number)","c846b26b":"cat_col.columns","0d729494":"fig, ax = plt.subplots(4, 2, figsize=(15, 15))\nfor variable, subplot in zip(cat_col, ax.flatten()):\n    sns.countplot(data[variable], ax=subplot,palette = 'plasma')\n    for label in subplot.get_xticklabels():\n        label.set_rotation(90)\nplt.tight_layout()","6f2b8b93":"data[['StandardHours','EmployeeCount']].describe()","10581c11":"data[['StandardHours','EmployeeCount']].corr()","1cb8b1af":"corr = data.drop(columns=['StandardHours','EmployeeCount']).corr()\ncorr.style.background_gradient(cmap='YlGnBu')","56172767":"cols = ['Age', 'BusinessTravel', 'Department',\n       'DistanceFromHome', 'Education', 'EducationField', 'EmployeeCount',\n        'EnvironmentSatisfaction', 'Gender', \n       'JobInvolvement', 'JobLevel', 'JobRole', 'JobSatisfaction',\n       'MaritalStatus', 'NumCompaniesWorked',\n       'Over18', 'OverTime', 'PercentSalaryHike', 'PerformanceRating',\n       'RelationshipSatisfaction', 'StandardHours', 'StockOptionLevel',\n       'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance',\n       'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n       'YearsWithCurrManager']\nfor col in cols:\n    pd.crosstab(data[col],data.Attrition).plot(kind='bar',color = ('blue','red'),figsize=(10,5))","f0e87eee":"# Age Vs Attrition - From data, it appears that attrition is more at age group 18-23\n# % of attrition is more among people who travel frequently\n# % of attrition is more in sales department\n# %of attrition is more during 0-1 years of working in company\n# People in job role of Sales Representative tend to have more attrition %\n# From given data, overtime population has more attrition","11a8ae09":"data.columns.shape","1f577d78":"cat_col.columns.shape","b6ea1dbc":"num_cols.columns.shape","af11152f":"cat_col_encoded = pd.get_dummies(cat_col)","0e5069ad":"cat_col_encoded.head()","88fb22df":"df = pd.concat([num_cols,cat_col_encoded],sort=False,axis=1)","e9bcbd8c":"df.head()","2ca62a07":"X = df.drop(columns='Attrition')","33a1f774":"y = df['Attrition']","26a50da6":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)","f679ee05":"train_Pred = logreg.predict(X_train)","3f110c28":"metrics.confusion_matrix(y_train,train_Pred)","3ceea12b":"metrics.accuracy_score(y_train,train_Pred)","b02e1a16":"test_Pred = logreg.predict(X_test)","d4d77b3f":"metrics.confusion_matrix(y_test,test_Pred)","2cd8bdd5":"metrics.accuracy_score(y_test,test_Pred)","6f0b5398":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, test_Pred))","608b9614":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nlogit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\nfpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()","064ff95c":"# Null Values","076ef53e":"# Create Dummy Variables[One Hot Encoding on categorical variables]","2905f0b8":"# Output\/Target variable","f58655d4":"Attrition  - (Boolean) - Employee Attrition Y\/N","48d53254":"# Input variables","8eeebbea":"# Visualizing value counts of categorical columns through countplot","b7b3b5fe":"# Data Analysis","fe85f77a":"# Correlation between numerical columns","af3d9772":"The precision is the ratio tp \/ (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n\nThe recall is the ratio tp \/ (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n\nThe support is the number of occurrences of each class in y_test.","0494d251":"There are no null values in dataset","aced7b33":"# Duplicated data","654df976":"# Visualizing Distribution of numerical columns through histograms","be504ddf":"# ROC Curvefrom sklearn import metrics","25272cdd":"# Compute precision, recall, F-measure and support","5f46e612":"# Implementing the model","e63138f3":"There are no duplicated rows","ffadc27e":"Watson Analytics Sample Data\n\nUncover the factors that lead to employee attrition and explore important questions such as \n\u2018show me a breakdown of distance from home by job role and attrition\u2019 or \u2018compare average monthly \nincome by education and attrition\u2019. This is a fictional data set created by IBM data scientists.\n\nAlso available directly within Watson Analytics as Employee Performance\n\nSource : https:\/\/www.ibm.com\/communities\/analytics\/watson-analytics-blog\/hr-employee-attrition\/","3e1affa5":"# About the Data:"}}