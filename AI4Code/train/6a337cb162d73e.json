{"cell_type":{"785f27b6":"code","e3febee3":"code","ac93dc78":"code","ab391101":"code","55727bf8":"code","e93e599d":"code","9efc5944":"code","f60fe873":"code","bb50d020":"code","cf406f13":"code","2ff01dbe":"code","e735a7f8":"code","d2bb342c":"code","1e3d806a":"code","8d8b811c":"code","e27c759b":"code","fd1a9c14":"code","97146fc7":"code","5129406a":"code","58f8f537":"code","a9f88bde":"code","877c0060":"code","666d6548":"code","a2357b0e":"code","06c0a911":"code","6a883b76":"code","782c287a":"code","e5fad454":"code","c90dc903":"code","d09d9ff3":"code","17a42ed5":"code","a435b20a":"code","02fd4a1e":"code","f931acd8":"code","d71e7bce":"markdown","32cc7984":"markdown","04ecb133":"markdown","d397164b":"markdown","1af13130":"markdown","3ff6cbcb":"markdown","38166245":"markdown","063bbb25":"markdown","e311fea7":"markdown","d43babbb":"markdown","7e4f9e8e":"markdown","53ea9b2c":"markdown","5b1c8926":"markdown","cdb05a53":"markdown","ff45a5d1":"markdown","effc6145":"markdown","4dc5d9f9":"markdown","d4b467ca":"markdown","7062d926":"markdown","92e260e6":"markdown","9d79e1bb":"markdown","f3ffe70a":"markdown","8dfa5c86":"markdown","3a2c53b2":"markdown","e6b27002":"markdown","5e1d69c3":"markdown","df247b4e":"markdown","23469f3a":"markdown","fd509b89":"markdown","99809639":"markdown","fba011ca":"markdown","2b2aa5fb":"markdown","860e024e":"markdown","ef363913":"markdown","b91fe436":"markdown","5366b632":"markdown","9aac21a6":"markdown","6a8df205":"markdown","cd692f30":"markdown","9bccf0c9":"markdown"},"source":{"785f27b6":"!pip install pyspark","e3febee3":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","ac93dc78":"from pyspark.sql import SparkSession\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import CountVectorizer,StringIndexer, RegexTokenizer,StopWordsRemover\nfrom pyspark.sql.functions import col, udf,regexp_replace,isnull\nfrom pyspark.sql.types import StringType,IntegerType\nfrom pyspark.ml.classification import NaiveBayes, RandomForestClassifier, LogisticRegression, DecisionTreeClassifier, GBTClassifier\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator","ab391101":"spark = SparkSession.builder.appName('nlp').getOrCreate()","55727bf8":"filepath = '\/kaggle\/input\/nlp-getting-started'\nsdf_train = spark.read.csv(f'{filepath}\/train.csv', header = True, inferSchema = True)\nsdf_test = spark.read.csv(f'{filepath}\/test.csv', inferSchema=True, header=True)\n\nsdf_sample_submission = spark.read.csv(f'{filepath}\/sample_submission.csv', \n                                       inferSchema=True, header=True)\nsdf_train.printSchema()","e93e599d":"import pandas as pd\npd.DataFrame(sdf_train.take(5), columns=sdf_train.columns)","9efc5944":"print(\"Training Data Record Count:\",sdf_train.count())\nprint(\"Test Data Record Count:\",sdf_test.count())","f60fe873":"sdf_train.toPandas().groupby(['target']).size()","bb50d020":"ml_df = sdf_train.select(\"id\",\"text\",\"target\")\nml_df.show(5)","cf406f13":"ml_df = ml_df.dropna()\nml_df.count()","2ff01dbe":"ml_df = ml_df.withColumn(\"only_str\",regexp_replace(col('text'), '\\d+', ''))\nml_df.show(5)","e735a7f8":"regex_tokenizer = RegexTokenizer(inputCol=\"only_str\", outputCol=\"words\", pattern=\"\\\\W\")\nraw_words = regex_tokenizer.transform(ml_df)\nraw_words.show(5)","d2bb342c":"remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\nwords_df = remover.transform(raw_words)\nwords_df.select(\"id\",\"words\",\"target\",\"filtered\").show(5, truncate=False)","1e3d806a":"cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\")\nmodel = cv.fit(words_df)\ncountVectorizer_train = model.transform(words_df)\ncountVectorizer_train = countVectorizer_train.withColumn(\"label\",col('target'))\ncountVectorizer_train.show(5)","8d8b811c":"countVectorizer_train.select('text','words','filtered','features','target').show()","e27c759b":"(train, validate) = countVectorizer_train.randomSplit([0.8, 0.2],seed = 97435)","fd1a9c14":"trainData = countVectorizer_train\n\n#cleaning and preparing the test data\ntestData = sdf_test.select(\"id\",\"text\")#.dropna()\ntestData = testData.withColumn(\"only_str\",regexp_replace(col('text'), '\\d+', ''))\nregex_tokenizer = RegexTokenizer(inputCol=\"only_str\", outputCol=\"words\", pattern=\"\\\\W\")  #Extracting raw words\ntestData = regex_tokenizer.transform(testData)\nremover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\") #Removing stop words\ntestData = remover.transform(testData)\ncv = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\")\nmodel = cv.fit(testData)\ncountVectorizer_test = model.transform(testData)\ntestData = countVectorizer_test\ntestData.show(5)","97146fc7":"nb = NaiveBayes(modelType=\"multinomial\",labelCol=\"label\", featuresCol=\"features\")\nnbModel = nb.fit(train)\nnb_predictions = nbModel.transform(validate)","5129406a":"nbEval = BinaryClassificationEvaluator()\nprint('Test Area Under ROC', nbEval.evaluate(nb_predictions))","58f8f537":"evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\nnb_accuracy = evaluator.evaluate(nb_predictions)\nprint(\"Accuracy of NaiveBayes is = %g\"% (nb_accuracy))","a9f88bde":"from pyspark.ml.classification import LogisticRegression\nlr = LogisticRegression(featuresCol = 'features', labelCol = 'target', maxIter=10)\nlrModel = lr.fit(train)","877c0060":"import matplotlib.pyplot as plt\nimport numpy as np\n\nbeta = np.sort(lrModel.coefficients)\nplt.plot(beta)\nplt.ylabel('Beta Coefficients')\nplt.show()","666d6548":"trainingSummary = lrModel.summary\nlrROC = trainingSummary.roc.toPandas()\n\nplt.plot(lrROC['FPR'],lrROC['TPR'])\nplt.ylabel('False Positive Rate')\nplt.xlabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.show()\n\nprint('Training set areaUnderROC: ' + str(trainingSummary.areaUnderROC))","a2357b0e":"pr = trainingSummary.pr.toPandas()\nplt.plot(pr['recall'],pr['precision'])\nplt.ylabel('Precision')\nplt.xlabel('Recall')\nplt.show()","06c0a911":"lrPreds = lrModel.transform(validate)\nlrPreds.select('id','prediction').show(5)","6a883b76":"lrEval = BinaryClassificationEvaluator()\nprint('Test Area Under ROC', lrEval.evaluate(lrPreds))","782c287a":"evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\nlr_accuracy = evaluator.evaluate(lrPreds)\nprint(\"Accuracy of Logistic Regression is = %g\"% (lr_accuracy))","e5fad454":"from pyspark.ml.classification import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'target', maxDepth = 3)\ndtModel = dt.fit(train)\ndtPreds = dtModel.transform(validate)\ndtPreds.show(5)\n#dtPreds.select('age', 'job', 'label', 'rawPrediction', 'prediction', 'probability').show(10)","c90dc903":"dtEval = BinaryClassificationEvaluator()\ndtROC = dtEval.evaluate(dtPreds, {dtEval.metricName: \"areaUnderROC\"})\nprint(\"Test Area Under ROC: \" + str(dtROC))","d09d9ff3":"evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\ndt_accuracy = evaluator.evaluate(dtPreds)\nprint(\"Accuracy of Decision Trees is = %g\"% (dt_accuracy))","17a42ed5":"dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'target', maxDepth = 3)\ndtModel = dt.fit(trainData)\ndtPreds = dtModel.transform(testData)\ndtPreds.show(5)","a435b20a":"dtPreds.select('id','prediction').withColumnRenamed('prediction','target').toPandas().to_csv('dt_Pred.csv',index=False,header=True)","02fd4a1e":"#rfPreds.select('id', 'prediction').withColumnRenamed('prediction','target').toPandas()#.to_csv('rf_Preds.csv',index=False)","f931acd8":"#gbtPreds.select('id', 'prediction').withColumnRenamed('prediction','target').toPandas().to_csv('gbt_Preds.csv',index=False)","d71e7bce":"### Evaluate the Random Forest Classifier","32cc7984":"# Data Science for Good - Text classification using PySpark ML\n","04ecb133":"The data is well balanced.","d397164b":"#### Segregating the words from the tweet","1af13130":"from pyspark.ml.classification import GBTClassifier\n\ngbt = GBTClassifier(maxIter=10)\ngbtModel = gbt.fit(train)\ngbtPreds = gbtModel.transform(validate)\ngbtPreds.show(5)","3ff6cbcb":"We can obtain the coefficients by using <code>LogisticRegressionModel<\/code>\u2019s attributes.","38166245":"# Machine Learning Prediction Models\n## Naive Bayes Classifier","063bbb25":"## Decision Tree Classifier\n","e311fea7":"Let's take a look at how the data looks.  \nPandas data frame is better than Spark DataFrame show() function.","d43babbb":"## Logistic Regression Model\n","7e4f9e8e":"### Separate the Train and Validation Data","53ea9b2c":"### Make Predictions using the Model","5b1c8926":"rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'label')\nrfModel = rf.fit(trainData)\nrfPreds = rfModel.transform(testData)","cdb05a53":"### Validate the model","ff45a5d1":"gbt = GBTClassifier(maxIter=10)\ngbtModel = gbt.fit(trainData)\ngbtPreds = gbtModel.transform(testData)\ngbtPreds.select('id','prediction').show(5)","effc6145":"### Importing necessary libraries","4dc5d9f9":"from pyspark.ml.classification import RandomForestClassifier\n\nrf = RandomForestClassifier(featuresCol = 'features', labelCol = 'target')\nrfModel = rf.fit(train)\nrfPreds = rfModel.transform(validate)\nrfPreds.select('id', 'rawPrediction', 'prediction', 'probability').show(10)","d4b467ca":"### Evaluate the Decision Tree model\n\nOne simple decision tree performed poorly because it is too weak given the range of different features. The prediction accuracy of decision trees can be improved by Ensemble methods, such as Random Forest and Gradient-Boosted Tree.","7062d926":"### Evaluate the Logistic Regression model","92e260e6":"**Predictor variables:** id, keyword, location, text\n\n**Outcome variable:** target","9d79e1bb":"## Data Pre-processing\n","f3ffe70a":"This Notebook utilizes Machine Learning with <code>PySpark<\/code> to categorize disaster tweets. This is created for the [Kaggle competition](https:\/\/www.kaggle.com\/c\/nlp-getting-started).","8dfa5c86":"### Make Predictions based on Decision Tree Model","3a2c53b2":"#### Removing the stop words from raw words","e6b27002":"evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\ngb_accuracy = evaluator.evaluate(gbtPreds)\nprint(\"Accuracy of GBT is = %g\"% (gb_accuracy))","5e1d69c3":"## Gradient Boosting Classifier","df247b4e":"#### Create a features column from the words","23469f3a":"## Random Forest Classifier","fd509b89":"Summarize the model","99809639":"gbtEval = BinaryClassificationEvaluator()\ngbtROC = gbtEval.evaluate(gbtPreds, {gbtEval.metricName: \"areaUnderROC\"})\nprint(\"Test Area Under ROC: \" + str(gbtROC))","fba011ca":"### Evaluate the Gradient-Boosted Tree Classifier","2b2aa5fb":"rfEval = BinaryClassificationEvaluator()\nrfROC = rfEval.evaluate(rfPreds, {rfEval.metricName: \"areaUnderROC\"})\nprint(\"Test Area Under ROC: \" + str(rfROC))","860e024e":"evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\nrf_accuracy = evaluator.evaluate(rfPreds)\nprint(\"Accuracy of Random Forests is = %g\"% (rf_accuracy))","ef363913":"### Test Data","b91fe436":"### Cleaning the dataset\n#### Drop null values","5366b632":"#### Removing numbers from the tweets","9aac21a6":"**Thanks you for reading. I appreciate your time! I hope you find this useful.  \nIf you have any suggestions, please add them in the comments section or reach out to me on [LinkedIn.](https:\/\/www.linkedin.com\/in\/suraj-malpani\/)**","6a8df205":"### Create a Spark session","cd692f30":"## Exploring Data Analysis\n### Load the data files","9bccf0c9":"### Precision and recall"}}