{"cell_type":{"a3f37d3a":"code","5de025bf":"code","62b8971e":"code","0fb18995":"code","e8611dad":"code","68c034ba":"code","f0eb1b0c":"code","9d62f4bf":"code","0566c7be":"code","8f68ca00":"code","760093aa":"code","e9770bd1":"code","8dea907a":"code","e4d6bc8c":"code","1e98bb89":"code","29327e82":"code","4c44ed22":"code","18218409":"code","3977a163":"code","2860e2c5":"code","46a80f05":"code","b9eb570a":"code","99ddb827":"code","ba311523":"code","bc167b44":"code","09664755":"code","37cb6025":"code","4fede9a9":"code","83a7c76d":"code","06d0582c":"code","ee1718bf":"code","d2c822db":"code","0efcc674":"code","22b0e69b":"code","d193a074":"code","bf50a098":"code","96aab927":"code","93c488ce":"markdown","7030470c":"markdown","351e38dd":"markdown","0bd96b9d":"markdown","7b0a60da":"markdown","23147fab":"markdown","281b8ebd":"markdown","3b3fde32":"markdown","a44296dc":"markdown","1f8a6f99":"markdown","b7858959":"markdown","908505d2":"markdown","c6aa56de":"markdown","3bbfe9c0":"markdown","8ec35af1":"markdown","65059f02":"markdown","4025576c":"markdown","bf890fff":"markdown","4fa26e37":"markdown","0759cf1e":"markdown","5a7d5f73":"markdown","b030ecf2":"markdown","c70ed3a9":"markdown","d5d7d6b2":"markdown","51fbeefc":"markdown","9f801ee3":"markdown","093290a3":"markdown","38500bf3":"markdown","217cb390":"markdown","029691df":"markdown","2d6a0fd5":"markdown","ae4b9bc7":"markdown","df163230":"markdown","26ecf743":"markdown","b801c13d":"markdown","8bce9450":"markdown","e18e9415":"markdown","66b9af99":"markdown"},"source":{"a3f37d3a":"import os\nimport zipfile\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img","5de025bf":"import zipfile\nwith zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/train.zip\",'r') as z:\n    z.extractall(\".\")","62b8971e":"path = '\/kaggle\/working\/train\/'\nfilenames = os.listdir(path)\nfilenames[:5]","0fb18995":"label = []\nfor filename in filenames:\n    if filename.split('.')[0] =='cat':\n        label.append('cat')\n    else:\n        label.append('dog')","e8611dad":"df = pd.DataFrame({\n                   'name':filenames,\n                   'label':label\n                 })","68c034ba":"df.head()","f0eb1b0c":"print(df['label'].value_counts())\nsns.countplot(data=df, x=df['label']);","9d62f4bf":"load_img(path+'cat.10009.jpg')","0566c7be":"load_img(path+'dog.1283.jpg')","8f68ca00":"model = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))","760093aa":"model.summary()","e9770bd1":"model.compile(optimizer='Adam', loss='binary_crossentropy', metrics='acc')","8dea907a":"train, test_val = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=17)","e4d6bc8c":"test, val = train_test_split(test_val, test_size=0.5,  stratify=test_val['label'], random_state=17)","1e98bb89":"print('train size:', train.shape[0],\n      '\\nvalidation size:', val.shape[0],\n      '\\ntest size:', test.shape[0],     \n     )","29327e82":"print('train labels:\\n',train['label'].value_counts(),\n      '\\n\\nvalidataion labels:\\n',val['label'].value_counts(),\n      '\\n\\ntest labels:\\n',test['label'].value_counts(),\n      sep='')","4c44ed22":"train_gen = ImageDataGenerator(rescale=1.\/255)\ntrain_data = train_gen.flow_from_dataframe(train,\n                                           directory=path,\n                                           x_col='name',\n                                           y_col='label',\n                                           class_mode='binary',\n                                           seed=17                                          \n                                          )\n\nval_gen = ImageDataGenerator(rescale=1.\/255)\nval_data = val_gen.flow_from_dataframe(val,\n                                       directory=path,\n                                       x_col='name',\n                                       y_col='label',\n                                       class_mode='binary',\n                                       seed=17  \n                                      )","18218409":"history = model.fit(train_data,\n                    validation_data = val_data,\n                    epochs=10\n                   )","3977a163":"loss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(15,8))\nplt.plot(loss, label='Train loss')\nplt.plot(val_loss,'--', label='Val loss')\nplt.title('Training and validation loss')\nplt.xticks(np.arange(0,10))\nplt.yticks(np.arange(0, 0.7, 0.05));\nplt.grid()\nplt.legend();","2860e2c5":"aug_gen = ImageDataGenerator(rescale = 1.\/255,\n                               shear_range = 0.2,\n                               zoom_range = 0.2,\n                               rotation_range=40,\n                               width_shift_range=0.2,\n                               height_shift_range=0.2,\n                               horizontal_flip=True,\n                               fill_mode='nearest'\n                              )","46a80f05":"img_cat = load_img(path+'cat.10009.jpg')\nimg_dog = load_img(path+'dog.1283.jpg')\n\nimg_cat_arr = image.img_to_array(img_cat)\nimg_cat_arr = img_cat_arr.reshape((1,)+img_cat_arr.shape)\n\nimg_dog_arr = image.img_to_array(img_dog)\nimg_dog_arr = img_dog_arr.reshape((1,)+ img_dog_arr.shape)","b9eb570a":"aug_images_cat = aug_gen.flow(img_cat_arr, batch_size=1)\naug_images_dog = aug_gen.flow(img_dog_arr, batch_size=1)","99ddb827":"plt.figure(figsize=(15,8))\nplt.subplot(141)\nplt.imshow(img_cat)\nplt.title(\"original\")\ni=2\nfor batch in aug_images_cat:\n    plt.subplot(14*10+i)\n    plt.imshow(image.array_to_img(batch[0]))\n    plt.title(\"augmented\")\n    i += 1\n    if i % 5 == 0:\n        break","ba311523":"plt.figure(figsize=(15,8))\nplt.subplot(141)\nplt.imshow(img_dog)\nplt.title(\"original\")\ni=2\nfor batch in aug_images_dog:\n    plt.subplot(14*10+i)\n    plt.imshow(image.array_to_img(batch[0]))\n    plt.title(\"augmented\")\n    i += 1\n    if i % 5 == 0:\n        break","bc167b44":"train_data = aug_gen.flow_from_dataframe(train,\n                                         directory=path,\n                                         x_col='name',\n                                         y_col='label',\n                                         class_mode='binary',\n                                         target_size=(224,224),\n                                         seed=17\n                                        )\n\nval_data = val_gen.flow_from_dataframe(val,\n                                       directory=path,\n                                       x_col='name',\n                                       y_col='label',\n                                       class_mode='binary',\n                                       target_size=(224,224),\n                                       seed=17  \n                                      )","09664755":"model.summary()","37cb6025":"best_model = models.Sequential()\n\nbest_model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\nbest_model.add(layers.MaxPooling2D((2, 2)))\n\nbest_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\nbest_model.add(layers.MaxPooling2D((2, 2)))\n\nbest_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\nbest_model.add(layers.MaxPooling2D((2, 2)))\n\nbest_model.add(layers.Conv2D(128, (3, 3), activation='relu'))\nbest_model.add(layers.MaxPooling2D((2, 2)))\n\nbest_model.add(layers.Conv2D(128, (3, 3), activation='relu'))\nbest_model.add(layers.MaxPooling2D((2, 2)))\n\nbest_model.add(layers.Flatten())\nbest_model.add(layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\nbest_model.add(layers.Dropout(0.2))\nbest_model.add(layers.Dense(1, activation='sigmoid'))","4fede9a9":"best_model.summary()","83a7c76d":"best_model.compile(optimizer=optimizers.Adam(learning_rate=5e-4), loss='binary_crossentropy', metrics='acc')","06d0582c":"history_2 = best_model.fit(train_data,\n                           validation_data = val_data,\n                           epochs=60,\n                           callbacks=[EarlyStopping(monitor='val_acc', min_delta=0.001, patience=5, verbose=1)]\n                          )","ee1718bf":"loss = history_2.history['acc']\nval_loss = history_2.history['val_acc']\n\nplt.figure(figsize=(15,8))\nplt.plot(loss, label='Train acc')\nplt.plot(val_loss,'--', label='Val acc')\nplt.title('Training and validation accuracy')\nplt.yticks(np.arange(0.5, 1, 0.05))\nplt.xticks(np.arange(0, 26))\nplt.grid()\nplt.legend();","d2c822db":"best_model.save('best_model_cat_vs_dog.h5')","0efcc674":"test_data = val_gen.flow_from_dataframe(test,\n                                        directory=path,\n                                        x_col='name',\n                                        y_col='label',\n                                        class_mode='binary',\n                                        target_size=(224,224),\n                                        shuffle=False,\n                                        seed=17  \n                                       )","22b0e69b":"test_pred = best_model.predict(test_data)","d193a074":"pred_label = test_pred > 0.5\ntrue_label = test_data.classes","bf50a098":"ConfusionMatrixDisplay(confusion_matrix(true_label, pred_label), display_labels=test_data.class_indices).plot();","96aab927":"best_model.evaluate(test_data)","93c488ce":"The plot clearly shows that after the **5th** epoch, val loss stopped decreasing, but went up, we see the problem of **overfitting**\n\nFirst, let's start expanding our data with **augmentation**.","7030470c":"#  <center>Model tuning<\/center>","351e38dd":"Great, we have an equal number of cat and dog classes\n\nLet's extract a couple of images from the data (I manually looked at the images in the directory and chose the most presentable animals in the photos)","0bd96b9d":"# <center>Loading data<\/center>","7b0a60da":"Great, we have **95% on test data**\n\nIt is possible that the model could be trained for high accuracy results, however, the purpose of this notebook was to learn how to work with **Keras** and **CNN**\n\n\n-----------------","23147fab":"Let's increase the number of **epochs to 60**, most likely the model will need many more epochs than in the previous version\n\nWe will also add **callbacks** that will stop training if **val_loss** has not changed more than **0.001** over the past **5 epochs**","281b8ebd":"First, let's write the basic architecture of **CNN**\n\nIn this model, we use 5 consecutive blocks from **Conv2D** and **MaxPooling2d** with different filter depths\n\nSince we have a classification task, after 5 blocks we will transform our data into a 1D tensor and apply Dense layers,\n\nthe last **Dense layer** should have 1 layer and **activation='sigmoid'** since we have a binary classification task\n\n**input_shape** we will set **(256, 256, 3)** as the base for further use of the generator without resizing the image\n","3b3fde32":"First, we need to convert **test data** to the same form as **val** using a **generator**\n\n**IMPORTANT!!!** It is necessary to set **shuffle=False** in order to avoid data mixing!!!","a44296dc":"Let's try to directly set the **learning_rate** to the optimizer, take a value slightly less than the default.\n\nThus, we guarantee that our optimizer will not get stuck in the local minimum of the function, however, for this we reduce the **learning rate**","1f8a6f99":"#  <center>Tuned model training<\/center>","b7858959":"\nFirst we import the necessary libraries","908505d2":"# <center>Base model<\/center>","c6aa56de":"Great, now let's apply augmentation to our **train data**.\n\nIt is important to apply **augmentation only to train data**, not to val and test. We need to provide our model with a large sample of images so that it can learn to recognize patterns in images.\n\nAlso in the new network, I'm going to change the size of incoming images to **(224x224)**, this size is most often used as input in many CNN networks, let's do the same.\n\nSince we decided to change the input image size, we also need to change the generation for val_data","3bbfe9c0":"Since the competition has already ended and I will not be able to submit the test data that is attached to the dataset, so we will divide our sample into 3 parts: **train, test, val**.\n\nWe will use proportions **train:test:val** - **8:1:1**\n\nOn the **train** sample, we will train our model\n\nOn the **val** sample, we will check the ability of our model to generalize to unknown data\n\nOn the **test** sample, we will make the final prediction","8ec35af1":"# <center>Data preprocessing: splitting data into train, test, val<\/center>","65059f02":"Compared to our first model, we really got rid of the **overfitting** problem. Now our metrics on the chart grow in proportion to each other\n\nLet's save the model and apply it to the test data","4025576c":"\n----------------\n\nGreat, using **optimizer='Adam'** as the most basic and recommended\n\n**loss='binary_crossentropy'** since we have a binary classification\n\n**metrics='acc'** since we have the same number of classes and accuracy is a suitable metric","bf890fff":"Since in the future I will be converting our data to a **Dataframe**, we will create a target variable responsible for the picture class: **cat** and **dog**","4fa26e37":"#   <center>Result on test data<\/center>","0759cf1e":"![](https:\/\/pixelz.cc\/wp-content\/uploads\/2018\/10\/dogs-and-cats-uhd-4k-wallpaper-768x432.jpg)\n\n\n\n----------------------------","5a7d5f73":"#  <center>Data Preprocessing : Augmentation<\/center>","b030ecf2":"![](https:\/\/aurora.ekof.bg.ac.rs\/~s160748\/331.jpg)","c70ed3a9":"Okay, our network stopped after **38** epochs as the **callback** fired.\n\nPerhaps after a few epochs, **val_acc** would begin to grow, but this accuracy suits me, since this notebook was not written to find the best results, but to work out and understand working with CNN in Keras.\n\nLet's take a look at the accuracy plot","d5d7d6b2":"It is important to understand that a strong fight against an **overfitting** problem can turn into an **underfitting** problem.\n\nPerhaps the augmentation is already enough to solve the problem of overfitting our model, but I want to add some more examples of hyperparameter regularization:\n\n\n- Let's try to apply **l2 regularization** with a small coefficient to the Dense layer\n\n\n- Add a **Dropout layer** with a small value before the last output layer","51fbeefc":"-----------------\n\nTo get an equal number of classes when splitting the data, I will use **stratify**. With it, our classes will be related as **1:1**","9f801ee3":"As I wrote above, augmentation is the process of generating artificial images using rotations, mirroring, shifts and other methods based on existing data.\n\nLet me show examples of augmentation with photos of cats and dogs that I showed above.","093290a3":"##  <center>Thank you for watching this is my project, I will be grateful if you upvoted and give feedback about my work in the comments. I want to improve my skills, and if you find any mistakes in the work, please tell me about it.<\/center>","38500bf3":"Great, we see that all the data is split in a ratio of 8:1:1 and with the same ratio of classes","217cb390":"Let's see on the histogram whether the **label**  is correct sorted all the photos into classes","029691df":"To begin with, we will create a **path** variable that will be responsible for the path to our data. This is done for more convenient and faster path output.\n\nNext, using **listdir**, we will load the list of image names from the path directory","2d6a0fd5":"# <center>Base model training<\/center>","ae4b9bc7":"Our base model looked like this","df163230":"# <center>Cats Vs Dogs<\/center>\n\n\n","26ecf743":"Ok, now let's improve our model","b801c13d":"Let's apply an **ImageDataGenerator** to our data to make it look like an **input_shape** for our model.\n\nNeural networks need to receive scaled data as input, for this we apply **rescale=1.\/255**\n\nIn this case, the image size is not specified, because **flow_from_dataframe** creates **target_size=(256, 256)** and default **color_mode='rgb'**\n\nin case of changing the size of the input tensors and using other values, we would have to manually specify the dimensions and depth of the image\n\n----------------\n\nUsually at this stage, the process of image **augmentation** is done.\n\nAugmentation is the process of generating artificial images using rotations, mirroring, shifts and many other different methods based on existing ones.\n\nThis is one of the methods of dealing with overfitting of the model, if necessary, I will apply it in the future.\n\n","8bce9450":"### <center>In this notebook, we will write a convolutional neural network(CNN) to classify images containing a dog or a cat. It is easy for people, dogs and cats. However, the computer will be a little more difficult<\/center>","e18e9415":"#  <center>Data Preprocessing: Data normalization<\/center>","66b9af99":"I would also like to say about **batch_size**\n\nIn this case, I decided to use the standard **batch_size=32**, but at the expense of this, use fewer epochs for training.\n\nThe larger the batch_size value, the less time it takes to train one epoch and the more epochs are needed to get good results.\n\nThe number of iterations in one epoch is **train_size(20000)\/batch_size(32)=625**"}}