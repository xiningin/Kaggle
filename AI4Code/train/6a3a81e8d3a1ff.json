{"cell_type":{"2f834489":"code","1c2ca416":"code","768e8039":"code","d877603f":"code","5f7547d8":"code","dfaefe0e":"code","435153cc":"code","f8554530":"code","7775e685":"code","2c55d9ff":"code","376f5112":"code","c38764e9":"code","062b2eb6":"code","63dc7e53":"code","6c8eb84f":"code","b4fed9c4":"code","1b8c7a1d":"code","fae736eb":"code","1aa5e963":"code","e2a6f669":"code","2eb00fde":"code","517842db":"code","949acc5a":"code","c9b0a3e9":"code","981df8fb":"code","e335ce7f":"code","c0cf5738":"code","4612bc41":"code","3e11706c":"code","bb4f1d79":"code","ab082f56":"code","2642292b":"code","63f10c5d":"code","5623f7d6":"code","ab5ffdd9":"code","18081b3b":"code","1e40d2cd":"code","fbe8df1d":"code","2e8849b1":"code","3124be81":"code","194976be":"code","e2ac3dcd":"markdown","61e8e0b3":"markdown","04d3b18a":"markdown","3a5f5cdb":"markdown","4b3e261f":"markdown","afb616bc":"markdown","c6189c28":"markdown","fb3fa7b4":"markdown","887f5d7a":"markdown","e4f6ee1e":"markdown","105ac90a":"markdown","b0a87366":"markdown","d74299c0":"markdown","a1562466":"markdown","c48e1ff4":"markdown","64f539e3":"markdown","1fa501ba":"markdown","536de609":"markdown","8c1cdc02":"markdown","ddd67106":"markdown","7fae5f9b":"markdown","f2feb33f":"markdown","b8a2c177":"markdown","186509dd":"markdown","462fa09b":"markdown","85d23780":"markdown","62172e03":"markdown","8ab2b4d1":"markdown","0e86a3bf":"markdown","0e05e701":"markdown","0465aeb7":"markdown","c084f3d5":"markdown","e655ea3f":"markdown","c58539f3":"markdown","72c6ee83":"markdown","3e3d7d6c":"markdown","cb8a2ff4":"markdown","7ca49aba":"markdown","99651cf6":"markdown","d7e882e6":"markdown","534ebccb":"markdown","c7006931":"markdown","c6c60132":"markdown","a5f88a94":"markdown","36075c23":"markdown","d0976ff9":"markdown","39c6454a":"markdown","b074a901":"markdown","141d29cb":"markdown","be578a28":"markdown","1315877c":"markdown","6130bfc2":"markdown","1c9bc223":"markdown","482f24f9":"markdown","43fb85f4":"markdown","970e91af":"markdown"},"source":{"2f834489":"# import classes for Data Analysis\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_columns', None)\n\n# import classes for colors and front\nfrom colorama import Fore,Style\n\n# import classes for data visulation\nfrom sklearn.tree import plot_tree\nimport matplotlib.pyplot as plt\nimport seaborn           as sns\nsns.set()\n\n# import classes for widgets creation\nfrom ipywidgets      import HBox,Output,VBox,Layout\nfrom IPython.display import display\nimport ipywidgets as widgets\n    \n# import classes for data split\nfrom sklearn.model_selection import train_test_split\n\n# import classes for Feature engineering (encoding & standardization)\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler\n\n\n# import classes for Feature Selection\nfrom sklearn.feature_selection import f_classif, mutual_info_classif\n\n# import classes for Classification Model Training\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors    import KNeighborsClassifier\nfrom sklearn.svm          import SVC\nfrom sklearn.tree         import DecisionTreeClassifier\nfrom sklearn.ensemble     import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\nfrom xgboost              import XGBClassifier,XGBRegressor\nfrom catboost             import CatBoostClassifier\n\n\n# import classes for Hyperparameter tuning\nfrom sklearn.model_selection import GridSearchCV\n\n# import classes for Evaluating the Model Performance\nfrom sklearn.metrics import roc_auc_score,accuracy_score,recall_score,precision_score,f1_score,classification_report,plot_confusion_matrix, plot_roc_curve,plot_precision_recall_curve,log_loss,brier_score_loss,hamming_loss\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","1c2ca416":"data = pd.read_csv(\"..\/input\/heart-attack-analysis-prediction-dataset\/heart.csv\")\ndata.sort_values(\"age\").head()","768e8039":"# Labeling data fields to Text value for easy interpretation of Visualization\ndata_eda = data.copy()\n\ndata_eda[\"sex\"]     = data[\"sex\"]    .map({1: \"Male\",           0: \"Female\"})\ndata_eda[\"cp\"]      = data[\"cp\"]     .map({1: \"Typical\\nangina\", 2: \"Atypical\\nangina\", 3:\"Non-anginal\\npain\", 0: \"Asymptomatic\"})\ndata_eda[\"fbs\"]     = data[\"fbs\"]    .map({1: \"True\",           0: \"False\"})\ndata_eda[\"restecg\"] = data[\"restecg\"].map({1: \"Normal\",         2: \"Having\\nST-T wave\\nabnormality\",          0: \"Hypertrophy\"})\ndata_eda[\"exng\"]    = data[\"exng\"]   .map({1: \"Yes\" ,           0: \"No\"})\ndata_eda[\"slp\"]     = data[\"slp\"]    .map({2: \"Upsloping\",      1: \"Flat\" ,           0: \"Downsloping\"})\ndata_eda[\"caa\"]     = data[\"caa\"]    .map({0: \"0\",              1: \"1\" ,              2: \"2\",               3:\"3\" ,4:\"3\"})\ndata_eda[\"thall\"]   = data[\"thall\"]  .map({0: \"Normal\",         2: \"Normal\" ,         1: \"Fixed defect\" ,   3: \"Reversible\\ndefect\"})\ndata_eda[\"output\"]  = data[\"output\"] .map({1: \"Yes\" ,           0: \"No\"})","d877603f":"print(\"Imbalance Ratio    :\",data_eda[\"output\"].value_counts()[1]\/data_eda[\"output\"].value_counts()[0])\nprint(\"\\n\")\nprint(\"Heart Attack\\n____________\")\ndata_eda[\"output\"].value_counts()","5f7547d8":"# Percentage of missing data per Features\ndata_eda.isnull().mean()","dfaefe0e":"## cohort analysis of age with output\ndef age_cohort(age):\n    if age <= 45:\n        return \"0-45\"\n    elif age > 45 and age <= 55:\n        return \"45-55\"\n    elif age > 55 and age <= 60:\n        return \"55-60\"\n    elif age > 60:\n        return \"60+\"\n        \ndata_eda['age group'] = data_eda['age'].apply(age_cohort)\ndata_eda.sort_values(\"age group\",inplace=True)\n\n\ndef q(n):\n    def q_(x):\n        return x.quantile(n)\n    q_.__name__ = '{:2.0f}%'.format(n*100)\n    return q_\n\n\n\ndef ctab(var):\n    f, a = plt.subplots(1, 2,figsize=(8,3),dpi=200)\n    background_color = \"#F0F6FC\"\n    color = \"#000000\"\n    hue_colors = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue']\n    f.patch.set_facecolor(background_color)\n    temp=data_eda[var].value_counts()\n    a[1].pie(x=temp,labels=temp.index,autopct='%1.1f%%',textprops={'fontsize':9},colors=hue_colors);\n    a[1].set_xlabel(var)\n    a[0].axis(\"off\")\n    a[0].text(.55,0.5,\" Percentage( % ) \\n\", \n                              color   =color,   horizontalalignment = 'center',verticalalignment = 'center'  ,                          \n                              fontsize = 20,    fontfamily='serif');\n\n    a[0].text(.55,0.4,\"of Categorical Feature '\"+var+\"'\\n_________________________________\",\n                              color    = color, horizontalalignment = 'center',verticalalignment = 'center'  ,                          \n                              fontsize = 10,    fontfamily='serif');\n    plt.show()\n\n\nci        = [\"Categorical Features\", \"Numeric Features\"]\ncat_var   = [var for var in data_eda.columns if data_eda[var].dtype=='O' and var !='output']\nnum_var   = [var for var in data_eda.columns if data_eda[var].dtype!='O']\n\n\n# Create inner Tabs\ndef create_inner_tabs():        \n    inner_tabs_list=[widgets.Output() for i in range(len(cat_var))]\n    inner_tab = widgets.Tab(inner_tabs_list)\n    for i in range (len(cat_var)):\n        inner_tab.set_title(i,cat_var[i])\n\n        with inner_tabs_list[i]:      \n            ctab(cat_var[i]);\n    display(inner_tab)\n    \n\n# Create outer Tabs\nouter_sub_tabs_list=[widgets.Output() for i in range(len(ci))]\ntab = widgets.Tab(children=outer_sub_tabs_list)\nfor i in range (len(ci)):\n    tab.set_title(i,ci[i])\n                      \n    with outer_sub_tabs_list[i]:\n        if i ==0:\n            create_inner_tabs();\n        else:\n            plt.figure(figsize=(11,4),dpi=200)\n            df_n=data_eda[num_var].agg([\"count\",\"mean\",\"std\",\"skew\",\"kurt\",\"min\",q(.25),\"median\",q(.75),\"max\"]).T\n            df_n[\"range\"]=df_n[\"max\"]-df_n[\"min\"]\n            df_n[\"IQR\"]  =df_n[\"75%\"]-df_n[\"25%\"]\n            sns.heatmap(df_n , annot=True,cmap = \"Blues\", fmt= '.2f',linewidths = 5, cbar = False,annot_kws={\"size\": 10})\n            plt.xticks(size = 12);\n            plt.yticks(size = 12, rotation = 0);\n            plt.title(\"Descriptive Statistics\", size = 16)\n            plt.show()\n            \n                   \ndisplay(tab)    ","435153cc":"# analysis of all categorical feature with output (Heart Attack)\nf, a = plt.subplots(5, 2,figsize=(12,15),dpi=200)\nbackground_color = \"#F0F6FC\" #\"#ecebe9\" '#fbf4d3'  #ecebe9\ncolor = \"#000000\" #\"#FFFFFF\"\nhue_color=[\"#FF5003\",\"#428bca\"] #[\"#e1493a\",\"#5981ad\"] [\"#ed4d69\",\"#74ba65\"] [\"#6aac90\",\"#5833ff\"] [\"#5981ad\",#da8829\"]\nhue_order=['Yes','No']\nalpha=.8\nf.patch.set_facecolor(background_color)\n\nax=sum(a.tolist(), [])[1:]\n\na[0][0].axis(\"off\")\na[0][0].text(.5,0.4,\"Bar Plots (%)\\n\",color=color,horizontalalignment = 'center',verticalalignment = 'center'  ,                          \n                          fontsize = 31,\n                          #fontweight='bold',\n                          fontfamily='serif') \n\na[0][0].text(.5,0.3,\"of Categorical Features\\n________________________\",color=color,horizontalalignment = 'center',verticalalignment = 'center'  ,                          \n                          fontsize = 16.9,\n                          #fontweight='bold',\n                          fontfamily='serif')\n\nfor i in range(len(cat_var)): \n\n    new_df = data_eda.groupby(cat_var[i])[\"output\"].value_counts(normalize=True).mul(100).rename('Percent ( % )').reset_index()\n    g=sns.barplot(data=new_df,x=cat_var[i],y='Percent ( % )',hue='output', ax=ax[i],palette=hue_color,alpha=alpha,edgecolor=background_color,hue_order=hue_order)    \n\n    ax[i].set_facecolor(background_color)\n    ax[i].grid(color=background_color)\n    ax[i].grid(color=color, linestyle=':', axis='y', zorder=0,  dashes=(1,5))\n    ax[i].spines[\"top\"].set_visible(False)\n    ax[i].spines[\"right\"].set_visible(False)\n    ax[i].spines[\"left\"].set_visible(False)\n    ax[i].spines[\"bottom\"].set_color(color)\n    ax[i].xaxis.label.set_color(color)\n    ax[i].yaxis.label.set_color(color)\n    ax[i].tick_params(axis='x', colors=color)\n    ax[i].tick_params(axis='y', colors=color)\n    if i==1:       \n        l=ax[i].legend(loc=(.4,1.1),facecolor=background_color,edgecolor=background_color,title=\"Heart Attack\",fontsize =10,title_fontsize=14)\n        for text in l.get_texts():\n            text.set_color(color)\n        l._legend_title_box._text.set_color(color)\n    else:\n        ax[i].legend().set_visible(False)\n    plt.tight_layout()","f8554530":"# analysis of all Numeric feature with output (Heart Attack)\nf, a = plt.subplots(3,2,figsize=(13,7),dpi=200)\nbackground_color = \"#F0F6FC\" #\"#ecebe9\"\ncolor = \"#000000\" #\"#FFFFFF\"\nhue_color=[\"#FF5003\",\"#428bca\"] #[\"5981ad\",\"#175a83\"]\nalpha=.8\nhue_order=['Yes','No']\nf.patch.set_facecolor(background_color)\n\nax=sum(a.tolist(),[])\n\nax[0].axis(\"off\")\nax[0].text(.5,0.4,\"Distribution\\n\",color=color,horizontalalignment = 'center',verticalalignment = 'center',              \n                          fontsize = 31, fontfamily='serif') \n\nax[0].text(.5,0.3,\"Plots of Numeric Features\\n___________________________\",color=color,horizontalalignment = 'center',verticalalignment = 'center'  ,                          \n                          fontsize = 13.8,fontfamily='serif')  \n\nfor i in range(len(num_var)):\n    sns.histplot(data=data_eda,x=data_eda[num_var[i]],hue='output',kde =True,ax=ax[i+1],palette=hue_color,alpha=alpha,edgecolor=background_color,hue_order=hue_order)\n    ax[i+1].grid(color=background_color)\n    ax[i+1].set_facecolor(background_color)\n    ax[i+1].grid(color=color, linestyle=':', axis='y', zorder=0,  dashes=(1,5))\n    ax[i+1].spines[\"top\"].set_visible(False)\n    ax[i+1].spines[\"right\"].set_visible(False)\n    ax[i+1].spines[\"left\"].set_visible(False)\n    ax[i+1].spines[\"bottom\"].set_color(color) \n    ax[i+1].xaxis.label.set_color(color)\n    ax[i+1].yaxis.label.set_color(color)\n    ax[i+1].tick_params(axis='x', colors=color)\n    ax[i+1].tick_params(axis='y', colors=color)    \n    plt.tight_layout() ","7775e685":"# analysis of all numeric feature with output (Heart Attack)\nf, a = plt.subplots(3,2,figsize=(11,8),dpi=200)\nbackground_color = \"#F0F6FC\" #\"#ecebe9\"\ncolor = \"#000000\" #\"#FFFFFF\"\nhue_color=[\"#FF5003\",\"#428bca\"] #[\"#5981ad\",\"#175a83\"]\nalpha=.8\n\nf.patch.set_facecolor(background_color)\n\nax=sum(a.tolist(),[])\n\nax[0].axis(\"off\")\nax[0].text(.5,0.4,\"Box Plots\\n\",color=color,horizontalalignment = 'center',verticalalignment = 'center'  ,                          \n                          fontsize = 25, fontfamily='serif') \nax[0].text(.5,0.33,\"of Numeric Features\\n______________________\",color=color,horizontalalignment = 'center',verticalalignment = 'center'  ,                          \n                          fontsize = 11, fontfamily='serif')  \n\nfor i in range(len(num_var)):\n    sns.boxplot(data=data_eda,y=data_eda[num_var[i]],x=\"output\",orient=\"v\",ax=ax[i+1],palette=hue_color,boxprops=dict(alpha=alpha))\n    ax[i+1].set_frame_on(False)\n    ax[i+1].grid(color=background_color)\n    ax[i+1].grid(color=color, linestyle=':', axis='y', zorder=0,  dashes=(1,5))\n    ax[i+1].set_facecolor(background_color)\n    ax[i+1].spines[\"top\"].set_visible(False)\n    ax[i+1].spines[\"right\"].set_visible(False)\n    ax[i+1].spines[\"left\"].set_visible(False)\n    ax[i+1].spines[\"bottom\"].set_color(color)\n    ax[i+1].xaxis.label.set_color(color)\n    ax[i+1].yaxis.label.set_color(color)\n    ax[i+1].tick_params(axis='x', colors=color)\n    ax[i+1].tick_params(axis='y', colors=color)\n    plt.tight_layout() ","2c55d9ff":"sub_tab=[widgets.Output() for i in range(len(cat_var))]\ntab = widgets.Tab(sub_tab)\nfor i in range (len(cat_var)):\n    tab.set_title(i,cat_var[i])\n   \n    with sub_tab[i]:\n              \n        f, a = plt.subplots(3, 2,figsize=(12,10),dpi=200);\n        background_color = \"#F0F6FC\"\n        color = \"#000000\"\n        hue_color=[\"#FF5003\",\"#428bca\"]         \n        hue_order=['Yes','No']\n        alpha=.8\n        f.patch.set_facecolor(background_color) \n        ax=sum(a.tolist(), [])[1:]\n\n\n        a[0][0].axis(\"off\")\n        a[0][0].text(0.5,0.4,\"Visualization\\n\",\n                              color=color,\n                              horizontalalignment = 'center',\n                              verticalalignment = 'center'  ,                          \n                              fontsize = 31,\n                              #fontweight='bold',\n                              fontfamily='serif')\n        \n        a[0][0].text(0.5,0.3,\"Numeric Features with '\"+cat_var[i]+\"'\\n__________________________________\",\n                              color=color,\n                              horizontalalignment = 'center',\n                              verticalalignment = 'center'  ,                          \n                              fontsize = 14,\n                              #fontweight='bold',\n                              fontfamily='serif')\n\n        for j in range(len(num_var)):\n            ax[j].set_frame_on(False) \n            ax[j].grid(color=background_color)\n            ax[j].grid(color=color, linestyle=':', axis='y', zorder=0,  dashes=(1,5))\n            sns.boxplot(x=cat_var[i],y=num_var[j],data=data_eda,hue=\"output\",ax=ax[j],palette=hue_color,hue_order=hue_order);\n            ax[j].xaxis.label.set_size(15)   \n            ax[j].yaxis.label.set_size(15)\n            ax[j].tick_params(axis='both', which='major', labelsize=11)\n            ax[j].tick_params(axis='both', which='minor', labelsize=12)\n            \n            if j==1:       \n                l=ax[j].legend(loc=(.38,1.1),facecolor=background_color,edgecolor=background_color,title=\"Heart Attack\",fontsize =10,title_fontsize=14)\n                for text in l.get_texts():\n                    text.set_color(color)\n                l._legend_title_box._text.set_color(color)\n            else:\n                ax[j].legend().set_visible(False)\n        plt.tight_layout()\n        plt.show()\n        \ndisplay(tab)","376f5112":"# Labeling data fields to Text value for easy interpretation of Visualization\ndata_eda_sm = data_eda.copy()\ndata_eda_sm[\"restecg\"] = data_eda_sm[\"restecg\"].map({'Normal'          : 'Normal'     ,'Hypertrophy'       : 'Hypertrophy','Having\\nST-T wave\\nabnormality':'ST-T abnor.'})\ndata_eda_sm[\"thall\"]   = data_eda_sm[\"thall\"]  .map({'Normal'          : 'Normal'     ,'Reversible\\ndefect': 'Rev. defect','Fixed defect'                  :'Fix. defect'})\ndata_eda_sm[\"cp\"]      = data_eda_sm[\"cp\"]     .map({'Asymptomatic'    : 'Asymptomat.','Atypical\\nangina'  : 'Aty. angina','Typical\\nangina'               :'Typ. angina', 'Non-anginal\\npain': 'N-ang. pain'})\n\nci =[]\ncat_var_sel=['sex', 'cp', 'fbs', 'restecg', 'thall']\nfor i in cat_var_sel:\n    for j in cat_var_sel:\n        if i<j:\n            l=[i,j]\n            ci.append(l)\n\n            \n#Combining Features for Visualization\nfor i in range(len(ci)):\n    data_eda_sm[ci[i][0]+\"-\"+ci[i][1]]= \"[\"+ci[i][0]+\" = \"+data_eda_sm[ci[i][0]]+\"\\n\"+ci[i][1]+\" = \"+data_eda_sm[ci[i][1]]+\"]\"\n\n# Create Plotting function   \ndef plot_func(i,num):\n    f, a = plt.subplots(1,3,figsize=(14,2.8),dpi=200)\n    background_color = \"#F0F6FC\"\n    color = \"#000000\"\n    hue_color=[\"#FF5003\",\"#428bca\"]\n    hue_order=['Yes','No']\n    alpha=.8\n\n    f.patch.set_facecolor(background_color)\n\n    axes1 = f.add_axes([0.5, 1.7, 0.4, 0.8])\n    axes2 = f.add_axes([0.12,1.7, 0.37, 0.8])\n\n    ax=a.tolist()+[axes1]\n\n\n    axes2.axis(\"off\")\n    axes2.text(.5,0.5,\"Visualizing Features \\n['\"+ci[i][0]+\"' & '\"+ci[i][1]+\"']\\n together v\/s '\"+num+\"'\\n_________________________\",\n                          color=color,\n                          horizontalalignment = 'center',\n                          verticalalignment = 'center'  ,                          \n                          fontsize = 18,\n                          #fontweight='bold',\n                          fontfamily='serif')\n\n\n    axes1.set_title(\"Heart Attack (%) v\/s [\"+ci[i][0]+\" & \"+ci[i][1]+\"]\",fontdict={'fontsize': 18,'fontweight' : 18})\n    new_df = data_eda_sm.groupby(ci[i][0]+\"-\"+ci[i][1])[\"output\"].value_counts(normalize=True).mul(100).rename('Percent ( % )').reset_index()\n    sns.barplot  (data=new_df,x=ci[i][0]+\"-\"+ci[i][1],y='Percent ( % )',hue='output',palette=hue_color, ax=axes1, alpha=alpha,edgecolor=background_color,hue_order=hue_order) \n    axes1.legend(loc=(-.7,-0.5),facecolor=background_color,edgecolor=background_color,title=\"Heart Attack\",fontsize =15,title_fontsize=15)\n\n    sns.boxplot  (data=data_eda_sm,x=ci[i][0]+\"-\"+ci[i][1],y=num,hue='output',palette=hue_color, ax=a[0],boxprops=dict(alpha=alpha),hue_order=hue_order)\n    a[0].legend().set_visible(False)\n    a[0].set_title(\"[\"+ci[i][0]+\" & \"+ci[i][1]+\"] v\/s \"+num,fontdict={'fontsize': 15,'fontweight' : 15})\n\n    sns.stripplot(data=data_eda_sm,x=ci[i][0]+\"-\"+ci[i][1],y=num,hue='output',palette=hue_color, ax=a[1],jitter=True,alpha=alpha,edgecolor=color,hue_order=hue_order)\n    a[1].legend().set_visible(False)\n    a[1].set_title(\"[\"+ci[i][0]+\"-\"+ci[i][1]+\"] v\/s \"+num,fontdict={'fontsize': 15,'fontweight' : 15})\n\n    sns.barplot  (data=data_eda_sm,x=ci[i][0]+\"-\"+ci[i][1],y=num,hue='output',palette=hue_color, ax=a[2],estimator=np.max,alpha=alpha,edgecolor=background_color,hue_order=hue_order) \n    a[2].legend().set_visible(False)\n    a[2].set_title(\"[\"+ci[i][0]+\" & \"+ci[i][1]+\"] v\/s \"+num+\"(Max)\",fontdict={'fontsize': 15,'fontweight' : 15})\n\n    for x in range(len(ax)):\n        ax[x].tick_params(axis='both', which='major', labelsize=10,labelrotation=-90)\n        ax[x].set_xlabel(\"\")\n        ax[x].grid(color=background_color)\n        ax[x].grid(color=color, linestyle=':', axis='y', zorder=0,  dashes=(1,5))\n        ax[x].set_facecolor(background_color)\n        ax[x].spines[\"top\"].set_visible(False)\n        ax[x].spines[\"right\"].set_visible(False)\n        ax[x].spines[\"left\"].set_visible(False)\n        ax[x].spines[\"bottom\"].set_color(color)\n        ax[x].xaxis.label.set_color(color)\n        ax[x].yaxis.label.set_color(color)\n        ax[x].tick_params(axis='x', colors=color)\n        ax[x].tick_params(axis='y', colors=color)\n    plt.show()\n        \n        \n# Create inner Tabs\ndef create_inner_tabs(k):\n    inner_tabs_list=[widgets.Output() for i in range(len(num_var))]\n    inner_tab = widgets.Tab(inner_tabs_list)\n    for i in range (len(num_var)):\n        inner_tab.set_title(i,num_var[i])\n                 \n        with inner_tabs_list[i]:\n            plot_func(k,num_var[i])\n    display(inner_tab) \n    \n\n# Create outer Tabs\nouter_sub_tabs_list=[widgets.Output() for i in range(len(ci))]\ntab = widgets.Tab(outer_sub_tabs_list)\nfor i in range (len(ci)):\n    tab.set_title(i,ci[i][0]+\"-\"+ci[i][1])\n                      \n    with outer_sub_tabs_list[i]:\n        create_inner_tabs(i)\n    \n    \n    \ndisplay(tab)    ","c38764e9":"data_eda.replace('\\n', ' ', regex=True,inplace= True)\nli =[]\nfor i in num_var:\n    for j in num_var:\n        if i<j:\n            l=[i,j]\n            li.append(l)\n\n# Create Plotting function            \ndef plot_output(i,cat):        \n    fig = plt.figure(figsize=(18,15),dpi=200)\n    background_color = \"#F0F6FC\"\n    color = \"#000000\"\n    hue_color=[\"#FF5003\",\"#428bca\"]\n    hue_order=['Yes','No']\n    alpha=.8\n    marker=['o','s']\n    fig.patch.set_facecolor(background_color) \n\n    # Create Axes \n    axes1 = fig.add_axes([0.0, 0.37, 0.55, 0.55])\n    axes2 = fig.add_axes([0.6, 0.37, 0.55, 0.55])\n    axes3 =['axes31','axes32','axes33','axes34']\n    axes3[0] = fig.add_axes([0.0, 0.0, 0.25, 0.25])\n    axes3[1] = fig.add_axes([0.3, 0.0, 0.25, 0.25])\n    axes3[2] = fig.add_axes([0.6, 0.0, 0.25, 0.25])\n    axes3[3] = fig.add_axes([0.9, 0.0, 0.25, 0.25])\n\n    for a in [axes1,axes3[0],axes3[1],axes3[2],axes3[3]]:\n        a.set_facecolor(background_color)\n        a.grid(color=background_color)\n        a.grid(color=color, linestyle=':', axis='y', zorder=0,  dashes=(1,5))\n        a.spines[\"top\"].set_visible(False)\n        a.spines[\"right\"].set_visible(False)\n        a.spines[\"bottom\"].set_color(color)\n        a.spines[\"left\"].set_color(color)\n\n        a.xaxis.label.set_size(18)   \n        a.yaxis.label.set_size(18)\n        a.tick_params(axis='both', which='major', labelsize=15)\n        a.tick_params(axis='both', which='minor', labelsize=15)\n\n\n    axes2.axis('off')\n    axes2.text(0.5,.5,\"Visualizing Features\\n'\"+li[i][0]+\"' v\/s '\"+li[i][1]+\"'\\n on '\"+cat+\"'\\n--------------------------------------\",\n                color=color,horizontalalignment = 'center',verticalalignment = 'center', fontsize = 30,fontfamily='serif');\n    \n\n    sns.regplot(x=li[i][0], y=li[i][1], data=data_eda[data_eda.output == \"Yes\"],ax=axes1,label=\"Yes\", color=hue_color[0],marker=marker[0],scatter_kws={'s':80,'alpha':alpha})\n    sns.regplot(x=li[i][0], y=li[i][1], data=data_eda[data_eda.output == \"No\"] ,ax=axes1,label=\"No\" , color=hue_color[1],marker=marker[1],scatter_kws={'s':80,'alpha':alpha})\n    axes1.legend(loc=(1.5,0.1),facecolor=background_color,edgecolor=background_color,title=\"Heart Attack\",fontsize =22,title_fontsize=25)\n\n\n    for b, value in enumerate(data_eda[cat].unique()):\n        for c, values in enumerate(data_eda.output.unique()):\n            axes3[b].set_title(cat+\" = \"+ value,fontsize=18)\n            sns.regplot(x=li[i][0], y=li[i][1], data=data_eda[(data_eda.output == values) & (data_eda[cat] == value)] ,ax=axes3[b],color=hue_color[c],marker=marker[c],scatter_kws={'s':80,'alpha':alpha})\n\n\n    plt.show()\n\n    \n# Create inner Tabs    \ndef create_inner_tabs(k):\n    inner_tabs_list=[widgets.Output() for i in range(len(cat_var))]\n    inner_tab = widgets.Tab(inner_tabs_list)\n    for i in range (len(cat_var)):\n        inner_tab.set_title(i,cat_var[i])\n                 \n        with inner_tabs_list[i]:\n            plot_output(k,cat_var[i])\n    display(inner_tab) \n    \n    \n# Create outer Tabs     \ninner_sub_tabs_list=[widgets.Output() for i in range(len(li))]\ntab = widgets.Tab(inner_sub_tabs_list)\nfor i in range (len(li)):\n    tab.set_title(i,li[i][0]+\"-\"+li[i][1])\n                      \n    with inner_sub_tabs_list[i]:\n        create_inner_tabs(i)\n    \n    \n    \ndisplay(tab)    ","062b2eb6":"plt.figure(figsize=(14,8),dpi=200)\nsns.heatmap(data.corr(),cmap='Spectral'  ,annot=True,linecolor='black',linewidths=1,fmt=\".3f\",center=0);","63dc7e53":"cols = ['Corr (pearson)','Tree','F_scores','mutual_info']\n\nF_scores    = f_classif(data.drop('output',axis=1).values,data['output'])[0]\nmutual_inf  = mutual_info_classif(data.drop('output',axis=1).values,data['output'])\nfea_imp_DT  = DecisionTreeClassifier().fit(data.drop('output',axis=1).values,data['output']).feature_importances_\n\ncor_fea_imp=pd.concat([data.corr()[[\"output\"]][0:-1].rename(columns={'output':cols[0]}),\n                       pd.DataFrame(index=data.columns[0:-1],data=fea_imp_DT,columns=[cols[1]]),\n                       pd.DataFrame(index=data.columns[0:-1],data=F_scores  ,columns=[cols[2]]),\n                       pd.DataFrame(index=data.columns[0:-1],data=mutual_inf,columns=[cols[3]])]  , axis=1)\n\n# Putting all Feature Importance in same scale (MinMaxScaler min=0 and max=1)\nscaler = MinMaxScaler()\nscaled_cor_fea_imp_array = scaler.fit_transform(cor_fea_imp.values)\nscaled_cor_fea_imp =pd.DataFrame(data=scaled_cor_fea_imp_array,columns=cols,index=cor_fea_imp.index)\n\nf, a = plt.subplots(1,1,figsize=(12,5),dpi=200)\nbackground_color = \"#F0F6FC\"\ncolor = \"#000000\"\n#hue_color=[\"#e1493a\",\"#175a83\",\"#ed4d69\",\"#74ba65\"] \n#hue_color=['#FF3030','#FFD700','#836FFF','#00C78C']\nhue_color = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue']\nalpha=alpha=.6\n\nf.patch.set_facecolor(background_color)\na.set_title(\"Comparison of Different Feature Importance Techniques\")\nscaled_cor_fea_imp.sort_values(cols[0]).plot.bar(ax=a,color=hue_color,alpha=alpha)\na.grid(color=background_color)\na.set_facecolor(background_color)\na.grid(color=color, linestyle=':', axis='y', zorder=0,  dashes=(1,5))\na.spines[\"top\"].set_visible(False)\na.spines[\"right\"].set_visible(False)\na.spines[\"left\"].set_visible(False)\na.spines[\"bottom\"].set_color(color) \na.tick_params(axis='both', which='major', labelsize=10,labelrotation=0)\na.legend(loc=(0,1),facecolor=background_color,edgecolor=background_color,title=\"Feature Importance\",fontsize =10,title_fontsize=10);","6c8eb84f":"fea =data.drop('output',axis=1).values\ntar =data['output']\n\nx_train,x_test,y_train,y_test = train_test_split(fea,tar,test_size=0.2,random_state=65)","b4fed9c4":"scaler = StandardScaler()\nscaler.fit(x_train)\nX_train = scaler.transform(x_train)\nX_test = scaler.transform(x_test)","1b8c7a1d":"logit = LogisticRegression(penalty='none')\nlogit.fit(X_train,y_train)","fae736eb":"def all_metrics(estimator,x_train,x_test,y_train,y_test,metric,create_df=True):\n    from sklearn.metrics import roc_auc_score,accuracy_score,recall_score,precision_score,f1_score,classification_report,plot_confusion_matrix, plot_roc_curve,plot_precision_recall_curve,log_loss,brier_score_loss,hamming_loss\n\n    background_color = \"#F0F6FC\"\n    hue_color=[\"#FF5003\",\"#428bca\"]\n    color = \"#000000\"\n    \n    P_train  =estimator.predict(x_train)\n    P_test   =estimator.predict(x_test)\n    PB_train =estimator.predict_proba(x_train)[:,1]\n    PB_test  =estimator.predict_proba(x_test)[:,1]\n    global metrics_df\n    \n    if metric==\"raw_metric\":\n        f = plt.figure(figsize=(8,2.5),dpi=200)\n        f.patch.set_facecolor(background_color)\n        a= f.add_axes([0.0,0.0,1.0,0.5])\n\n        a.axis('off')\n        for i in np.arange(0,1,0.08):\n            a.text(0.50,i,\"|\"        ,verticalalignment=\"bottom\")\n            a.text(i,0.75,\"_________\",verticalalignment=\"bottom\")\n\n        a.text(0.13,0.75,  \" Training Data                                 Test Data\",family='monospace',verticalalignment =\"bottom\")\n\n        dic = {f1_score       :[\"f1_score   = \",(P_train,P_test)],recall_score :[\"Recall     = \",(P_train,P_test)],precision_score:[\"Precision  = \",(P_train,P_test)],\n               accuracy_score :[\"Accuracy   = \",(P_train,P_test)],roc_auc_score:[\"AUC        = \",(PB_train,PB_test)]}\n\n        g=0\n        for k,v in dic.items():\n            a.text(0.15,0.00+g,v[0]+str(round(k(y_train,v[1][0]),3)),horizontalalignment = 'left',family='monospace',fontsize=8)\n            a.text(0.70,0.00+g,v[0]+str(round(k(y_test ,v[1][1]),3)),horizontalalignment = 'left',family='monospace',fontsize=8)\n            g=g+0.15\n    \n    \n    elif metric==\"classification_report\":\n        f = plt.figure(figsize=(12,5),dpi=200)\n        f.patch.set_facecolor(background_color)\n        a= f.add_axes([0.0,0.0,1.0,0.5])\n\n        a.axis('off')\n        for i in np.arange(0,1,0.05):\n            a.text(0.50,i,\"|\"        ,verticalalignment=\"bottom\")\n            a.text(i,0.75,\"_________\",verticalalignment=\"bottom\")\n            a.text(i,0.64,\"_________\",verticalalignment=\"bottom\")\n\n        a.text(0.2,0.8,  \"Training Data                         Test Data\",family='monospace',verticalalignment =\"bottom\",fontsize=20)\n        a.text(1.00,0.05,classification_report(y_test , P_test  ),horizontalalignment = 'right',family='monospace');\n        a.text(0.45,0.05,classification_report(y_train, P_train ),horizontalalignment = 'right',family='monospace');\n\n\n    elif metric==\"confusion_matrix\":\n        f,a=plt.subplots(1,2,figsize=(12,4),dpi=200)\n        f.patch.set_facecolor(background_color)\n\n        ls =[[\"Training Data\",x_train,y_train],[\"Test Data\",x_test ,y_test]]\n\n        for i in range(len(ls)):\n            a[i].grid(False)\n            a[i].set_title(ls[i][0],fontsize=20)  \n            plot_confusion_matrix(estimator,ls[i][1],ls[i][2],ax=a[i],cmap=plt.cm.Blues)\n    \n    elif metric==\"Roc_Precision Recall\":\n        f,a=plt.subplots(1,2,figsize=(14,4),dpi=200)\n        f.patch.set_facecolor(background_color)\n        \n        ls =[[\"Train\",x_train,y_train],[\"Test.\",x_test ,y_test]]\n        ti =[\"Roc Curve\",\"Precision Recall Curve\"]\n\n        a[0].plot([0,1], [0,1],  \"r--\")\n        for i in range(len(ls)):\n            a[i].set_title(ti[i],fontsize=20)\n            a[i].set_frame_on(False)\n            a[i].grid(color=background_color)\n            a[i].grid(color=color, linestyle=':', axis='y', zorder=0,  dashes=(1,5))\n\n            plot_roc_curve             (estimator,ls[i][1],ls[i][2],ax=a[0],name=ls[i][0],color = hue_color[i])\n            plot_precision_recall_curve(estimator,ls[i][1],ls[i][2],ax=a[1],name=ls[i][0],color = hue_color[i]) \n    \n    if create_df==True:\n        ind =[\"roc_auc_score\",\"accuracy_score\",\"recall_score\",\"precision_score\",\"f1_score\",\"log_loss\",\"brier_score_loss\",\"hamming_loss\",\"No. of obs.\"]\n        metrics_df =pd.DataFrame(index=ind,data=[[roc_auc_score   (y_train,PB_train),roc_auc_score   (y_test,PB_test)],\n                                                 [accuracy_score  (y_train,P_train ),accuracy_score  (y_test,P_test) ],\n                                                 [recall_score    (y_train,P_train ),recall_score    (y_test,P_test) ],\n                                                 [precision_score (y_train,P_train ),precision_score (y_test,P_test) ],\n                                                 [f1_score        (y_train,P_train ),f1_score        (y_test,P_test) ],\n                                                 [log_loss        (y_train,PB_train),log_loss        (y_test,PB_test)],\n                                                 [brier_score_loss(y_train,PB_train),brier_score_loss(y_test,PB_test)],\n                                                 [hamming_loss    (y_train,P_train) ,hamming_loss    (y_test,P_test) ],\n                                                 [len(y_train)   ,len(y_test)]],columns=[\"Train\",\"Test\"]).round(3)\n        \n        def names_of_object(arg):\n            results = [n for n, v in globals().items() if v is arg and not n.startswith('_')]\n            return results[0] if len(results) is 1 else results if results else None\n        \n        metrics_df[\"Estimator Name\"]=names_of_object(estimator)\n    else:\n        metrics_df =\"File not created\" ","1aa5e963":"## Model Evaluation \nfor i in [\"raw_metric\",\"classification_report\",\"confusion_matrix\",\"Roc_Precision Recall\"]:\n    all_metrics(estimator=logit,x_train=X_train, x_test=X_test,y_train=y_train,y_test=y_test,create_df =True ,metric=i) \n    \n\nlogit_metrics = metrics_df.copy()","e2a6f669":"## Model Training\nlogit_l1 = LogisticRegression(penalty='l1',solver='liblinear',C=2.0,l1_ratio=None)\nlogit_l1.fit(X_train,y_train)\n\n\n## Model Evaluation \nfor i in [\"raw_metric\",\"classification_report\",\"confusion_matrix\",\"Roc_Precision Recall\"]:\n    all_metrics(estimator=logit_l1,x_train=X_train, x_test=X_test,y_train=y_train,y_test=y_test,create_df =True ,metric=i) \n    \nlogit_l1_metrics = metrics_df.copy()","2eb00fde":"## Model Training\nlogit_l2 = LogisticRegression(penalty='l2',C=2.0,l1_ratio=None)\nlogit_l2.fit(X_train,y_train)\n\n\n## Model Evaluation \nfor i in [\"raw_metric\",\"classification_report\"]:\n    all_metrics(estimator=logit_l2,x_train=X_train, x_test=X_test,y_train=y_train,y_test=y_test,create_df =True ,metric=i) \n\nlogit_l2_metrics = metrics_df.copy()","517842db":"## Model Training\nlogit_elstnet = LogisticRegression(penalty='elasticnet',solver='saga',C=2.0,l1_ratio=0.6)\nlogit_elstnet.fit(X_train,y_train)\n\n\n## Model Evaluation \nfor i in [\"raw_metric\",\"classification_report\"]:\n    all_metrics(estimator=logit_elstnet,x_train=X_train, x_test=X_test,y_train=y_train,y_test=y_test,create_df =True ,metric=i) \n\nlogit_elstnet_metrics = metrics_df.copy()","949acc5a":"penal =[\"l1- Regularization\",\"l2- Regularization\",\"elasticnet(ratio=0.2)\",\n        \"elasticnet(ratio=0.3)\", \"elasticnet(ratio=0.5)\",\"elasticnet(ratio=0.7)\"]\n             \nbackground_color,hue_color,color= \"#F0F6FC\",[\"#FF5003\",\"#428bca\"],\"#000000\"\n\ndef plot_by_penalty(penalty):\n    error_rates_tr,error_rates_ts = [],[]\n    p = \"elasticnet\"          if penalty[0:2] == \"el\" else penalty[0:2]\n    r = float(penalty[-3:-1]) if penalty[0:2] == \"el\" else None    \n    for n in np.arange(0.1,2.1,.01):\n        model = LogisticRegression(penalty=p,solver='saga',C=n,l1_ratio=r)      \n        model.fit(X_train,y_train)    \n        error_rates_tr.append(1 - accuracy_score(y_train,model.predict(X_train)))\n        error_rates_ts.append(1 - accuracy_score(y_test ,model.predict(X_test )))   \n    \n    fig, ax = plt.subplots(figsize=(12,5),dpi=200)\n    fig.patch.set_facecolor(background_color)\n    ax.set_frame_on(False)\n    ax.grid(color=background_color)\n    ax.grid(color=color, linestyle=':', axis='y', zorder=0,  dashes=(1,5))\n    ax.set_ylabel(\"Error\")\n    ax.set_xlabel(\"Regularization Parameter (C values)\")\n    fig.suptitle(\"Error v\/s Regularization Parameter (C values)\\n\\n\"+\"Penalty = \"+penalty.title(),y=1.05)\n    ax.set_yticks(np.arange(0,1,0.01))\n    ax.set_xticks(np.arange(0,5.1,.5))\n    ax.plot(np.arange(0.1,2.1,.01),error_rates_tr,label='Train')\n    ax.plot(np.arange(0.1,2.1,.01),error_rates_ts,label='Test ')\n    ax.legend(loc=(.91,1.05),facecolor=background_color,edgecolor=background_color,framealpha=.1);\n    plt.show()\n    \nsub_tab=[widgets.Output() for i in range(len(penal))]\ntab = widgets.Tab(sub_tab)\nfor i in range (len(penal)):\n    tab.set_title(i,penal[i].title())\n   \n    with sub_tab[i]:\n        plot_by_penalty(penal[i])\n\ndisplay(tab)","c9b0a3e9":"## Model Training\nknn = KNeighborsClassifier()\nknn.fit(X_train,y_train)\n\n\n## Model Evaluation \nfor i in [\"raw_metric\",\"classification_report\"]:\n    all_metrics(estimator=knn,x_train=X_train, x_test=X_test,y_train=y_train,y_test=y_test,create_df =True ,metric=i) \n\nknn_metrics = metrics_df.copy()","981df8fb":"error_rates_tr,error_rates_ts = [],[]\n\nfor n in range(1,64):    \n    model = KNeighborsClassifier(n_neighbors=n)\n    model.fit(X_train,y_train)    \n    error_rates_tr.append(1 - accuracy_score(y_train,model.predict(X_train)))\n    error_rates_ts.append(1 - accuracy_score(y_test ,model.predict(X_test )))\n    \n\nfig, ax = plt.subplots(figsize=(12,5),dpi=200)\nbackground_color = \"#F0F6FC\"\nhue_color=[\"#FF5003\",\"#428bca\"]\ncolor = \"#000000\"\nfig.patch.set_facecolor(background_color)\nax.set_frame_on(False)\nax.grid(color=background_color)\nax.grid(color=color, linestyle=':', axis='y', zorder=0,  dashes=(1,5))\nax.set_ylabel(\"Error\")\nax.set_xlabel(\"Number of Neighbors\")\nfig.suptitle(\"Error v\/s Number of Neighbors\")\nax.set_yticks(np.arange(0,1,0.02))\nax.set_xticks(list(range(0,64,5)))\nax.plot(range(1,64),error_rates_tr,label='Train')\nax.plot(range(1,64),error_rates_ts,label='Test ')\nax.legend(loc=(.91,1),facecolor=background_color,edgecolor=background_color,framealpha=.1);","e335ce7f":"## Model Training\nsvm = SVC(probability=True)\nsvm.fit(X_train,y_train)\n\n\n## Model Evaluation\nfor i in [\"raw_metric\",\"classification_report\"]:\n    all_metrics(estimator=svm,x_train=X_train, x_test=X_test,y_train=y_train,y_test=y_test,create_df =True ,metric=i) \n\nsvm_metrics = metrics_df.copy()","c0cf5738":"kernel_tabs =[\"rbf\",\"linear\",\"poly(degree=1)\",\"poly(degree=2)\",\"poly(degree=3)\",\"poly(degree=4)\",\"sigmoid\"]\nbackground_color = \"#F0F6FC\"\nhue_color=[\"#FF5003\",\"#428bca\"]\ncolor = \"#000000\"\n\ndef plot_by_kernel(kernel):\n    error_rates_tr,error_rates_ts = [],[]\n    deg = int(kernel[-2]) if kernel[0:4] == 'poly' else 3\n    ker = 'poly' if kernel[0:4] == 'poly' else kernel\n    for n in np.arange(0.1,5.1,.1):    \n        model = SVC(C=n,kernel=ker,degree=deg)\n        model.fit(X_train,y_train)    \n        error_rates_tr.append(1 - accuracy_score(y_train,model.predict(X_train)))\n        error_rates_ts.append(1 - accuracy_score(y_test ,model.predict(X_test )))   \n    \n    fig, ax = plt.subplots(figsize=(12,5),dpi=200)\n    fig.patch.set_facecolor(background_color)\n    ax.set_frame_on(False)\n    ax.grid(color=background_color)\n    ax.grid(color=color, linestyle=':', axis='y', zorder=0,  dashes=(1,5))\n    ax.set_ylabel(\"Error\")\n    ax.set_xlabel(\"L2 Regularization parameter (C values)\")\n    fig.suptitle(\"Error v\/s L2 Regularization Parameter (C values)\\n\\n\"+\"Kernel = \"+kernel.capitalize())\n    ax.set_yticks(np.arange(0,1,0.03))\n    ax.set_xticks(np.arange(0,5.1,.5))\n    ax.plot(np.arange(0.1,5.1,.1),error_rates_tr,label='Train')\n    ax.plot(np.arange(0.1,5.1,.1),error_rates_ts,label='Test ')\n    ax.legend(loc=(.91,1),facecolor=background_color,edgecolor=background_color,framealpha=.1);\n    plt.show()\n\n    \nsub_tab=[widgets.Output() for i in range(len(kernel_tabs))]\ntab = widgets.Tab(sub_tab)\nfor i in range (len(kernel_tabs)):\n    tab.set_title(i,kernel_tabs[i].capitalize())\n   \n    with sub_tab[i]:\n        plot_by_kernel(kernel_tabs[i])\n\ndisplay(tab)","4612bc41":"## Model Training\ndtree = DecisionTreeClassifier(ccp_alpha=.02)\ndtree.fit(X_train,y_train)\n\n\n## Model Evaluation\nfor i in [\"raw_metric\",\"classification_report\"]:\n    all_metrics(estimator=dtree,x_train=X_train, x_test=X_test,y_train=y_train,y_test=y_test,create_df =True ,metric=i) \n\ndtree_metrics = metrics_df.copy()","3e11706c":"plt.figure(figsize=(18,10),dpi=200)\nplot_tree(dtree,filled=True,feature_names=data.drop('output',axis=1).columns);","bb4f1d79":"clf = DecisionTreeClassifier()\npath = clf.cost_complexity_pruning_path(X_train, y_train)\nccp_alphas, impurities = path.ccp_alphas, path.impurities\nerror_rates_tr,error_rates_ts = [],[]\nbackground_color,hue_color,color= \"#F0F6FC\",[\"#FF5003\",\"#428bca\"],\"#000000\"\n\nfor n in ccp_alphas:\n    model = DecisionTreeClassifier(ccp_alpha=n)\n    model.fit(X_train,y_train);    \n    error_rates_tr.append(1 - accuracy_score(y_train,model.predict(X_train)))\n    error_rates_ts.append(1 - accuracy_score(y_test ,model.predict(X_test ))) \n    \nfig, ax = plt.subplots(figsize=(12,5),dpi=200)\nfig.patch.set_facecolor(background_color)\nax.set_frame_on(False)\nax.grid(color=background_color)\nax.grid(color=color, linestyle=':', axis='y', zorder=0,  dashes=(1,5))\nax.set_ylabel(\"Error\")\nax.set_xlabel(\"Cost Complexity Pruning\")\nfig.suptitle(\"Error v\/s ccp_alpha\",y=.9)\nax.set_yticks(np.arange(0,1,0.05))\nax.set_xticks(np.arange(0,1,0.01))\nax.plot(ccp_alphas,error_rates_tr,label='Train')\nax.plot(ccp_alphas,error_rates_ts,label='Test ')\nax.legend(loc=(.91,.5),facecolor=background_color,edgecolor=background_color,framealpha=.1);","ab082f56":"## Model Training\nrfc = RandomForestClassifier()\nrfc.fit(X_train,y_train)\n\n\n## Model Evaluation\nfor i in [\"raw_metric\",\"classification_report\"]:\n    all_metrics(estimator=rfc,x_train=X_train, x_test=X_test,y_train=y_train,y_test=y_test,create_df =True ,metric=i) \n\nrfc_metrics =  metrics_df.copy()","2642292b":"## Model Training\nadabst = AdaBoostClassifier()\nadabst.fit(X_train,y_train)\n\n\n## Model Evaluation\nfor i in [\"raw_metric\",\"classification_report\"]:\n    all_metrics(estimator=adabst,x_train=X_train, x_test=X_test,y_train=y_train,y_test=y_test,create_df =True ,metric=i) \n\n    \nadabst_metrics = metrics_df.copy()","63f10c5d":"## Model Training\nGradbst =GradientBoostingClassifier()\nGradbst.fit(X_train,y_train)\n\n\n## Model Evaluation\nfor i in [\"raw_metric\",\"classification_report\"]:\n    all_metrics(estimator=Gradbst,x_train=X_train, x_test=X_test,y_train=y_train,y_test=y_test,create_df =True ,metric=i) \n    \n    \nGradbst_metrics = metrics_df.copy()","5623f7d6":"## Model Training\nXGbst = XGBClassifier(verbosity=0)\nXGbst.fit(X_train, y_train)\n\n\n## Model Evaluation\nfor i in [\"raw_metric\",\"classification_report\"]:\n    all_metrics(estimator=XGbst,x_train=X_train, x_test=X_test,y_train=y_train,y_test=y_test,create_df =True ,metric=i) \n        \nXGbst_metrics = metrics_df.copy()","ab5ffdd9":"## Model Training\nCatBst = CatBoostClassifier(verbose=0)\nCatBst.fit(X_train, y_train)\n\n\n## Model Evaluation\nfor i in [\"raw_metric\",\"classification_report\"]:\n    all_metrics(estimator=CatBst,x_train=X_train, x_test=X_test,y_train=y_train,y_test=y_test,create_df =True ,metric=i)   \n    \n    \nCatBst_metrics = metrics_df.copy()","18081b3b":"algo =[RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier,XGBClassifier,CatBoostClassifier]\nname =[\"Random Forest\",\"Ada Boost\",\"Gradient Boost\",\"XG Boost\", \"Cat Boost\"]\n             \nbackground_color,hue_color,color= \"#F0F6FC\",[\"#FF5003\",\"#428bca\"],\"#000000\"\n\ndef plot_by_estimators(est,i):\n    error_rates_tr,error_rates_ts = [],[]    \n    for n in range(1,64):\n        if est==AdaBoostClassifier:\n            model = est(n_estimators=n)\n        elif est==XGBClassifier:\n            model = est(n_estimators=n,verbosity=0)\n        else:\n            model = est(n_estimators=n,verbose=0)\n                                 \n        model.fit(X_train,y_train);    \n        error_rates_tr.append(1 - accuracy_score(y_train,model.predict(X_train)))\n        error_rates_ts.append(1 - accuracy_score(y_test ,model.predict(X_test )))   \n    \n    fig, ax = plt.subplots(figsize=(12,5),dpi=200)\n    fig.patch.set_facecolor(background_color)\n    ax.set_frame_on(False)\n    ax.grid(color=background_color)\n    ax.grid(color=color, linestyle=':', axis='y', zorder=0,  dashes=(1,5))\n    ax.set_ylabel(\"Error\")\n    ax.set_xlabel(\"Number of Trees (n_estimators)\")\n    fig.suptitle(\"Error v\/s Number of Trees (n_estimators)\\n\\n Estimators = \"+name[i],y=1.05)\n    #ax.set_yticks(np.arange(0,1,0.01))\n    #ax.set_xticks(np.arange(0,5.1,.5))\n    ax.plot(range(1,64),error_rates_tr,label='Train')\n    ax.plot(range(1,64),error_rates_ts,label='Test ')\n    ax.legend(loc=(.91,1.05),facecolor=background_color,edgecolor=background_color,framealpha=.1);\n    plt.show()\n    \n    \nsub_tab=[widgets.Output() for i in range(len(name))]\ntab = widgets.Tab(sub_tab)\nfor i in range (len(name)):\n    tab.set_title(i,name[i])\n   \n    with sub_tab[i]:\n        plot_by_estimators(algo[i],i)\n\ndisplay(tab)","1e40d2cd":"all_models = { 'Logistic Reg.'  : logit_metrics,                 'XGBoost'        : XGbst_metrics,\n               'logit_l1_LASSO' : logit_l1_metrics,              'CAT Boost'      : CatBst_metrics,\n               'logit_l2_RIGE'  : logit_l2_metrics,              'Ada Boost'      : adabst_metrics ,\n               'logit_elstnet'  : logit_elstnet_metrics,         'Gradient Boost' : Gradbst_metrics, \n              \n               'Knn'            : knn_metrics,                   'Decision Tree'  : dtree_metrics,           \n               'SVM'            : svm_metrics,                   'Random Forest'  : rfc_metrics    }\n\nlis=[]\nfor names,dfs in all_models.items():          \n    lis.append(dfs[[\"Test\"]].rename(columns={'Test':names}))                       \n\nComparison_Table = pd.concat(lis ,axis=1).transpose()  \nComparison_Table","fbe8df1d":"def gradient_plot(df,metrics):\n    table  = df[[metrics]].sort_values(by=metrics, ascending=False)\n    return table.style.background_gradient(cmap='Blues').format(\"{:.3}\")\n\n\nfrom IPython.display import display, HTML\ncss = \"\"\"\ndiv.cell:nth-child(92).output {\n    flex-direction: row;\n}\n\"\"\"\nHTML('<style>{}<\/style>'.format(css))","2e8849b1":"display(gradient_plot(Comparison_Table,\"accuracy_score\"))\ndisplay(gradient_plot(Comparison_Table,\"roc_auc_score\"))\ndisplay(gradient_plot(Comparison_Table,\"f1_score\"))","3124be81":"#tuning the hyperparameters of best model (that is CATBoost)\nbase_CatBst = CatBoostClassifier(verbose=0)\n\nparam_grid = { 'depth'         : [4,5,6,7,8,9, 10],\n               'learning_rate' : [0.01,0.02,0.03,0.04],\n               'iterations'    : [20,30,40,50,60,70,80,90, 100,500],\n               'reg_lambda'    : [0.01,0.02]}\n\n\nGridCV_CatBst = GridSearchCV(estimator=base_CatBst,param_grid=param_grid,scoring=\"accuracy\",cv=3,n_jobs=4)\nGridCV_CatBst.fit(X_train,y_train);\n\nprint(\"* Best Parameters           | depth         = \"+ str(dict(GridCV_CatBst.best_params_)['depth']))\nprint(\"                            | iterations    = \"+ str(dict(GridCV_CatBst.best_params_)['iterations']))\nprint(\"                            | learning_rate = \"+ str(dict(GridCV_CatBst.best_params_)['learning_rate']))\nprint(\"                            | reg_lambda    = \"+ str(dict(GridCV_CatBst.best_params_)['reg_lambda']))\nprint('\\n')\nprint(\"* Cross Validation Accuracy | \"+ str(GridCV_CatBst.best_score_))","194976be":"for i in [\"raw_metric\",\"classification_report\",\"confusion_matrix\",\"Roc_Precision Recall\"]:\n    all_metrics(estimator=GridCV_CatBst.best_estimator_,x_train=X_train, x_test=X_test,y_train=y_train,y_test=y_test,create_df =True ,metric=i) ","e2ac3dcd":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\"> \n&emsp;7.1&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp; GridSearchCV<a id=55><\/a><\/p>\n<\/div>\n\n* Tuning the hyperparameters of best model (that is CATBoost)\n___","61e8e0b3":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: center;   font-size:28px; font-family  :cursive\">   \nTABLE OF CONTANTS <\/p>    \n<\/div>\n    \n>1. __[Introduction](#1)__<a id=1.1><\/a>\n>   - 1.1 [Data Description ](#2)\n>   - 1.2 [Objective ](#3)\n>2. __[Preparation ](#4)__<a id=2.2><\/a>\n>   - 2.1 [Importing the Libraries ](#5)\n>   - 2.2 [Importing the Dataset ](#6)\n>   - 2.3 [Data Preparation ](#7)\n>3. __[Exploratory Data Analysis ](#8)__<a id=8.8><\/a>\n>   - 3.1 [Imbalance Ratio of Target label ](#9)\n>   - 3.2 [Missing value Detection ](#10)\n>   - 3.3 [Descriptive Statistics ](#11)\n>   - 3.4 __[Visualization ](#12)__<a id=12.12><\/a>\n>     - 3.4.1 __[Univariate analysis ](#13)__\n>       - 3.4.1.1 [Categorical Feature (Bar Plots) ](#14)\n>       - 3.4.1.2 [Numeric Features (Histplot) ](#15)\n>       - 3.4.1.2 [Numeric Features (Boxplot) ](#16)\n>     - 3.4.2 __[Bivariate analysis ](#17)__<a id=17.17><\/a>\n>       - 3.4.2.1 [Numerical Features by Category (BOX Plots) ](#18)\n>     - 3.4.3 __[Multivariate Analysis ](#19)__<a id=19.19><\/a>\n>       - 3.4.3.1 [Two Categorical Features against Numerical Features ](#20)\n>       - 3.4.3.2 [Two Numerical Features against Categorical Features ](#21)\n>     - 3.4.4 __[Correlation Analysis (Heat Map) ](#22)__\n>     - 3.4.5 __[Feature Importance Analysis ](#23)__\n>4. __[Pre Modeling Steps](#24)__<a id=24.24><\/a>\n>    - 4.1 [Splitting the dataset Train|Test Split](#25)\n>    - 4.2 [Feature Engineering](#26)\n>      - 4.2.1 [Feature Scaling ](#27)\n>5. __[Modeling](#28)__<a id=28.28><\/a> \n>    - 5.1 __[Linear Classifiers ](#29)__\n>      - 5.1.1 [Logistic Regression](#30)\n>      - 5.1.2 [Logistic Regression (penalty='l1') - LASSO](#31)\n>      - 5.1.3 [Logistic Regression (penalty='l2') - RIDGE](#32)\n>      - 5.1.4 [Logistic Regression (penalty='elasticnet') - ELASTICNET](#33)\n>      - 5.1.5 [Impact of Regularization on Logistic Regression](#34)\n>    - 5.2 __[Neighbors Classifiers ](#35)__\n>      - 5.2.1 [KNN - K Nearest Neighbors](#36)\n>      - 5.2.2 [Comparing Error Rate with the K Value](#37)\n>    - 5.3 __[Kernel Classifiers ](#38)__\n>      - 5.3.1 [Support Vector Machines](#39)\n>      - 5.3.2 [Model Performance on Different Kernel](#40)\n>    - 5.4 __[Tree Classifiers](#41)__\n>      - 5.4.1 [Decision Trees](#42)\n>        - 5.4.2 [Visualize the Fitted Tree](#43)\n>        - 5.4.2 [Cost Complexity Pruning of Decision Tree](#44)\n>      - 5.4.3 [Random Forest (ENSEMBLE -Bagging) ](#45)\n>      - 5.4.4 [AdaBoost (ENSEMBLE -Boosting) ](#46)\n>      - 5.4.5 [Gradient Boost (ENSEMBLE -Boosting) ](#47)\n>      - 5.4.6 [XGBoost (ENSEMBLE -Boosting) ](#48)\n>      - 5.4.7 [CatBoost (ENSEMBLE -Boosting) ](#49)\n>      - 5.4.8 [Error v\/s No. of Trees (n_estimators)](#50)\n>6. __[Model Selection](#51)__<a id=51.51><\/a>\n>    - 6.1 [Best Performing Model](#52)\n>    - 6.2 [Accuracy, ROC_AUC, F1_Score](#53) \n>7. __[ Hyperparameter Tuning](#54)__<a id=54.54><\/a>\n>    - 7.1 [GridSearchCV](#55)\n>    - 7.2 [Grid Model performance](#56)\n>8. __[Conclusion](#57)__<a id=57.57><\/a>\n>    - 8.1 [Detailed Description](#58) \n>    - 8.2 [Thank You](#59)\n   ***","04d3b18a":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\">       \n&emsp;3.1&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;Imbalance Ratio of Target label  <a id=9><\/a>\n<\/p>  \n<\/div>","3a5f5cdb":"<div style=\"color:#000000          ; display  :fill; border-radius:90px;\n           background-color:#FF8000; font-size:20px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:24px; font-family  :cursive\">   \n&emsp;&nbsp;&nbsp;5.4.1.2&emsp;&emsp;&emsp;&nbsp;Cost Complexity Pruning of Decision Tree <a id=44><\/a><\/p>\n<\/div>","4b3e261f":"<h1 align=\"LEFT\" style=\"font-size:29px;\" > 5.3  Kernel Classifiers <\/h1> <a id=38><\/a>\n\n[back to top](#28.28)","afb616bc":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\">  \n&emsp;5.1.3 &emsp;&nbsp;Logistic Regression (penalty='L2') - RIDGE <a id=32><\/a><\/p>\n<\/div>","c6189c28":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\">  \n&emsp;6.2&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;Accuracy, Roc_Auc, F1_score <a id=53><\/a> <\/p> <\/div> ","fb3fa7b4":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\"> \n&emsp;6.1&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;&nbsp; Best Performing Model<a id=52><\/a><\/p>\n<\/div>","887f5d7a":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\">  \n&emsp;7.2&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;Grid Model Performance <a id=56><\/a><\/p>\n<\/div>","e4f6ee1e":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\"> \n&emsp;3.4.1 Univariate analysis <a id=13><\/a>  \n<\/p>\n    \n<p> <\/p>\n    \n<\/div>\n\n<div style=\"color:#000000          ; display  :fill; border-radius:90px;\n           background-color:#FF8000; font-size:20px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:24px; font-family  :cursive\">          \n&emsp;&nbsp;&nbsp;3.4.1.1&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;Categorical Feature (Bar Plots)  <a id=14><\/a>  \n<\/p>\n<\/div>","105ac90a":"***\n<h1 align=\"LEFT\" style=\"font-size:30px;\" > &nbsp;3. Exploratory Data Analysis <\/h1> <a id=8><\/a>\n\n[back to top](#8.8)","b0a87366":"<div style=\"color:#000000          ; display  :fill; border-radius:90px;\n           background-color:#FF8000; font-size:20px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:24px; font-family  :cursive\">    \n&emsp;&nbsp;&nbsp;3.4.3.2&nbsp;Two Numerical Features against  Categorical Features <a id=21><\/a><\/p>\n<\/div>","d74299c0":"<h1 align=\"LEFT\" style=\"font-size:29px;\" > 5.2  Neighbors Classifiers <\/h1> <a id=35><\/a>\n\n[back to top](#28.28)","a1562466":"<div style=\"color:#000000          ; display  :fill; border-radius:90px;\n           background-color:#FF8000; font-size:20px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:24px; font-family  :cursive\">     \n&emsp;&nbsp;&nbsp;3.4.1.3&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;Numeric Features (Boxplot)<a id=16><\/a><\/p>\n<\/div>","c48e1ff4":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\">   \n&emsp;5.3.1 &emsp;&emsp;&emsp;&emsp;&emsp; Support Vector Machines <a id=39><\/a><\/p>\n<\/div>","64f539e3":"<h1 align=\"LEFT\" style=\"font-size:30px;\" > 7. Hyperparameter Tuning  <\/h1> <a id=54><\/a>\n\n[back to top](#54.54)","1fa501ba":"\n<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: center;   font-size:29px; font-family  :cursive\">   Heart Attack- A Complete Case Study\n<\/p> <\/div> \n\n\n<img src=\"https:\/\/i.guim.co.uk\/img\/media\/f2b0671c5f3aa754f1f7c257e528aa15d2fd5d07\/0_717_7000_4200\/master\/7000.jpg?width=445&quality=45&auto=format&fit=max&dpr=2&s=372a5c5dff4523ec7c152183426d688c\" width=\"80%\" align=\"center\" hspace=\"4%\" vspace=\"4%\"\/>\n<p>A heart attack is a medical emergency that occurs when blood supply to part of the heart is suddenly cut off.A heart attack is a medical emergency that occurs when blood supply to part of the heart is suddenly cut off. <\/p> \n\n<p>The heart muscles are supplied by the coronary arteries, which branch off from a major artery called the aorta. Heart attack occurs when one or more of the coronary arteries becomes blocked. This lack of blood supply and oxygen can cause injury to the heart muscle and if supply is prevented for more than 20 minutes, the part of the muscle tissue failing to receive blood may die. The medical term for a heart attack is myocardial infarction or MI.<\/p> \n<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :PACIFICO\">\n    \n<p style=\"padding   : 2px;    color    :#FFFFFF; \n          text-align: center;   font-size:30px; \">      \n<\/p> <\/div> ","536de609":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\"> \n&emsp;5.4.6&emsp;&emsp;&emsp;&nbsp; XGBoost (ENSEMBLE -Boosting)<a id=48><\/a><\/p>\n<\/div>","8c1cdc02":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\">  \n&emsp;8.1&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;Detailed Description<a id=58><\/a><\/p>\n<\/div>\n \n<p> <li>It seems Hyperparameter  Tuning of the Best Model (Cat Boost) Dosen't Improve Model Accuracy Any Further.<\/li><\/p>\n<p> <li>However Judging Based on Training\/Test Accuracy,Roc Compared To Training\/Test Accuracy,Roc of Model Without Hyperparameter Tuned. <\/li><p>\n<p> <li>It seems Hyperparameter Tuned  Model Fit The Data Best To Achieve Low Bias & Low Variance Model.<\/li> <p>\n<p> <li>We Will Select Hypermater Tuned Model (Gridcv_catbst.Best_estimator_) As Best Final Model.<\/li> <p>","ddd67106":"&nbsp;&nbsp;[back to top](#19.19)\n\n\n<div style=\"color:#FFFFFF ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF;\n          text-align: Left;   font-size:28px; font-family  :cursive\">   \n&emsp;3.4.3 Multivariate Analysis <a id=19><\/a>  \n<\/p>\n<p> <\/p>\n<\/div>\n<div style=\"color:#000000          ; display  :fill; border-radius:90px;\n           background-color:#FF8000; font-size:20px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:24px; font-family  :cursive\">          \n&emsp;&nbsp;&nbsp;3.4.1.1&nbsp;&nbsp;Two Categorical Features against  Numerical Features<a id=20><\/a>     \n<\/p>\n<\/div>","7fae5f9b":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\">   \n&emsp;8.2&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;Thank You !!!!<a id=59><\/a><\/p>\n<\/div> \n\n[back to top](#1.1)\n\n###  \ud83d\udc4d\ud83c\udffb If you like the notebook, consider giving an upvote. \ud83d\udc4d\ud83c\udffb \n### \u270d\ufe0f If you have any doubts or suggestions, feel free to comment down below!\u270d\ufe0f\n\n                             \ud83d\udc47\ud83d\udc47\ud83d\udc47\ud83d\udc47\ud83d\udc47\ud83d\udc47\ud83d\udc47\ud83d\udc47","f2feb33f":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\">   \n&emsp;5.4.4 &emsp;&emsp;&emsp;AdaBoost (ENSEMBLE -Boosting)<a id=46><\/a><\/p>\n<\/div>","b8a2c177":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\">  \n&emsp;5.4.1 &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; Decision Tree <a id=42><\/a><\/p>\n<\/div>","186509dd":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\">   \n&emsp;1.2&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;&nbsp;Objective <a id=3><\/a> <\/p> <\/div>  \n<hr style='border-style: inset; margin-top: -1em; border-width: 1px;'><\/hr>\n<p><\/p>\n\n* To Perform Complete EDA. \n* Derive Insights from Data.\n* Built Different Classification Models.\n* Compare Different Classification Models.\n* Select Best Model.\n* Fine Tune and Optimize the Best Model.\n* Finally Predict a person is prone to Heart Attack or not.","462fa09b":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\">  \n&emsp;5.1.2 &emsp;&nbsp;Logistic Regression (penalty='L1') - LASSO <a id=31><\/a><\/p>\n<\/div>","85d23780":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\">  \n&emsp;5.1.4 &emsp;&emsp;&emsp; Logistic Regression - ELASTICNET <a id=33><\/a><\/p>\n<\/div>","62172e03":"___\n<h1 align=\"LEFT\" style=\"font-size:29px;\" > &nbsp;3.4 Visualization <\/h1> <a id=12><\/a> \n\n&nbsp;&nbsp;[back to top](#12.12)","8ab2b4d1":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\">   \n&emsp;5.3.2 &emsp;&emsp;&nbsp;&nbsp;Model Performance on Different Kernel <a id=40><\/a><\/p>\n<\/div>","0e86a3bf":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\"> \n&emsp;3.4.5&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;Feature Importance Analysis <a id=23><\/a><\/p>\n<\/div>","0e05e701":"  \n&nbsp;&nbsp;[back to top](#17.17)\n\n<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\">  \n&emsp;3.4.2 Bivariate analysis <a id=17><\/a>  \n<\/p>\n<p> <\/p>\n<\/div>\n\n<div style=\"color:#000000          ; display  :fill; border-radius:90px;\n           background-color:#FF8000; font-size:24px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:24px; font-family  :cursive\">          \n&emsp;&nbsp;&nbsp;3.4.1.1&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;Numerical Features by Category<a id=18><\/a>  \n<\/p>\n<\/div>","0465aeb7":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\"> \n&emsp;4.2 Feature engineering <a id=26><\/a>  \n<\/p>\n    \n<p> <\/p>\n    \n<\/div>\n\n<div style=\"color:#000000          ; display  :fill; border-radius:90px;\n           background-color:#FF8000; font-size:20px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:24px; font-family  :cursive\"> \n&emsp;&nbsp;&nbsp;4.2.1&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;Feature Scaling <a id=27><\/a> \n<\/p>\n   \n<\/div>","c084f3d5":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\">   \n&emsp;5.4.8 &emsp;&nbsp;&nbsp;&nbsp;&nbsp;Error v\/s No. of Trees (n_estimators) <a id=50><\/a><\/p>\n<\/div>","e655ea3f":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\">  \n&emsp;5.4.3 &emsp;&nbsp;&nbsp;&nbsp; Random Forest (ENSEMBLE -Bagging)<a id=45><\/a><\/p>\n<\/div>","c58539f3":"<h1 align=\"LEFT\" style=\"font-size:30px;\" > 8. Conclusion  <\/h1> <a id=57><\/a>\n\n[back to top](#57.57)","72c6ee83":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\">  \n&emsp;5.2.2&emsp;&emsp;&nbsp;Comparing Error Rate with the K Value<a id=37><\/a><\/p>\n<\/div>","3e3d7d6c":"<div style=\"color:#000000          ; display  :fill; border-radius:90px;\n           background-color:#FF8000; font-size:20px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:24px; font-family  :cursive\">      \n&emsp;&nbsp;&nbsp;3.4.1.2&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;Numeric Features (Histplot)<a id=15><\/a><\/p>\n<\/div>","cb8a2ff4":"<h1 align=\"LEFT\" style=\"font-size:30px;\" > 6. Model Selection  <\/h1> <a id=51><\/a>\n\n[back to top](#51.51)","7ca49aba":"<div style=\"color:#000000          ; display  :fill; border-radius:90px;\n           background-color:#FF8000; font-size:20px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:24px; font-family  :cursive\">   \n&emsp;&nbsp;&nbsp;5.4.1.1&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;Visualize the Fitted Tree <a id=43><\/a><\/p>\n<\/div>","99651cf6":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\">      \n&emsp;2.3&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;Data Preparation <a id=7><\/a><\/p>\n<\/div>","d7e882e6":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\">   \n&emsp;5.2.1 &emsp;&emsp;&emsp;&emsp;&emsp;K Nearest Neighbors (KNN) <a id=36><\/a><\/p>\n<\/div>","534ebccb":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\">       \n&emsp;2.1&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;Importing the Libraries<a id=5><\/a><\/p>\n<\/div>","c7006931":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\">  \n&emsp;5.1.5&emsp;Impact of Regularization on Logistic Regression<a id=34><\/a><\/p>\n<\/div>","c6c60132":"***\n<h1 align=\"LEFT\" style=\"font-size:30px;\" > 5. Model Building <\/h1> <a id=28><\/a>\n\n[back to top](#28.28)","a5f88a94":"<h1 align=\"LEFT\" style=\"font-size:29px;\" > 5.4  Tree Models <\/h1> <a id=41><\/a>\n\n[back to top](#28.28)","36075c23":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\">   \n&emsp;3.4.4&emsp;&emsp;&emsp;&emsp;Correlation Analysis (Heat Map) <a id=22><\/a><\/p>\n<\/div>","d0976ff9":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\">  \n&emsp;5.4.5 &emsp;&emsp;Gradient Boost (ENSEMBLE -Boosting)<a id=47><\/a><\/p>\n<\/div>","39c6454a":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\">    \n&emsp;1.1&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;&nbsp;Data Description <a id=2><\/a> <\/p> <\/div>  \n<hr style='border-style: inset; margin-top: -1em; border-width: 1px;'><\/hr>\n<p><\/p>\n\n\n1. **`age`**&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - Age in Years\n\n2. **`sex`**&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - Sex of the Patient\n      >>>> * 1 = Male              \n      >>>> * 2 = Female\n3. **`cp`**&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - Chest Pain Type\n      >>>> * 1 = Typical angina      \n      >>>> * 2 = Atypical angina   \n      >>>> * 3 = Non-anginal pain\n4. **`trestbps`** - Resting Blood Pressure (in mm Hg on admission to the hospital)\n\n5. **`chol`**&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - Serum Cholesterol in mg\/dl\n\n6. **`fbs`**&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - Fasting Blood sugar > 120 mg\/dl \n      >>>> * 0 = False                        \n      >>>> * 1 = True  \n7. **`restecg`**&nbsp;&nbsp; - Resting Electrocardiographic Results \n      >>>> * 0 = Hypertrophy                  \n      >>>> * 1 = Normal             \n      >>>> * 2 = Having ST-T wave abnormality\n8. **`thalach`**&nbsp;&nbsp; - Maximum Heart Rate Achieved\n\n9. **`exang`**&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - Exercise Induced Angina \n      >>>> * 0 = No                           \n      >>>> * 1 = Yes\n10. **`oldpeak`**&nbsp;&nbsp; - ST Depression Induced by Exercise Relative to Rest\n\n11. **`slope`**&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - The Slope of the Peak Exercise ST Segment   \n      >>>> * 0 = Downsloping                 \n      >>>> * 1 = Flat            \n      >>>> * 2 = Upsloping\n12. **`ca`**&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - Number of Major Vessels (0-3) Colored by Flourosopy\n\n13. **`thal`**&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - Thallium Stress Test Result\n      >>>> * 0 = Null                         \n      >>>> * 1 = Fixed defect        \n      >>>> * 2 = Normal                       \n      >>>> * 3 = Reversible defect\n14. **`output`**&nbsp;&nbsp;&nbsp;&nbsp; - The Predicted Attribute - Diagnosis of Heart Disease (angiographic disease status)\n      >>>> * 0 = < 50% Diameter Narrowing (Heart Attack= No )        \n      >>>> * 1 = > 50% Diameter Narrowing (Heart Attack= Yes)\n                 \n\n<hr style='border-style: inset; border-width: 0.0000001px;'>","b074a901":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\"> \n&emsp;5.4.7&emsp;&emsp;&emsp;CatBoost (ENSEMBLE -Boosting)<a id=49><\/a><\/p>\n<\/div>","141d29cb":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\">   \n&emsp;2.2&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp; Importing the Dataset <a id=6><\/a><\/p>\n<\/div>","be578a28":"<h1 align=\"LEFT\" style=\"font-size:30px;\" >1. Introduction <\/h1> <a id=1><\/a> \n\n[back to top](#1.1)","1315877c":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\">          \n&emsp;3.2&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp; Missing Value Detection  <a id=10><\/a>\n<\/p>\n<\/div>","6130bfc2":"<P> <li> By all Feature Importance Techniques <b>Chest Pain<\/b> (cp) seems to be the most important Feature.<\/li><\/P>\n<P> <li> <b>NOTE:<\/b> Y-AXIS does not represent actual values of Feature Importance, values were standardized (same scaling) for comparison of Different Feature Importance Techniques.<\/li><\/P>\n\n\n***\n\n<h1 align=\"LEFT\" style=\"font-size:30px;\" > &nbsp;4. Pre Modeling Steps <\/h1> <a id=24 ><\/a>\n\n[back to top](#24.24)","1c9bc223":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\">      \n&emsp;3.3&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;Descriptive Statistics <a id=11><\/a><\/p>\n<\/div>","482f24f9":"<div style=\"color:#FFFFFF          ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:28px; font-family  :cursive\">  \n&emsp;4.1&emsp;&emsp;&emsp;&nbsp;&nbsp;Splitting the dataset Train|Test Split <a id=25><\/a>\n<\/p>\n<\/div>","43fb85f4":"<div style=\"color:#FFFFFF ; display  :fill; border-radius:90px;\n           background-color:#13A4B4; font-size:10px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF;\n          text-align: Left;   font-size:28px; font-family  :cursive\">   \n&emsp;5.1 Linear Classifiers <a id=29><\/a>  \n<\/p>\n    \n<p> <\/p>\n    \n<\/div>\n\n<div style=\"color:#000000          ; display  :fill; border-radius:90px;\n           background-color:#FF8000; font-size:20px; font-family  :cursive\">\n    \n<p style=\"padding   : .1px;    color    :#FFFFFF; \n          text-align: Left;   font-size:24px; font-family  :cursive\"> \n&emsp;&nbsp;&nbsp;5.1.1&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; Logistic Regression<a id=30><\/a><\/p>\n<\/div>","970e91af":"***\n<h1 align=\"LEFT\" style=\"font-size:30px;\" >2. Preparation <\/h1> <a id=4><\/a>\n\n[back to top](#2.2)"}}