{"cell_type":{"a5dbe940":"code","9ba2d038":"code","59356a07":"code","9274e890":"code","84e4265a":"code","9a8bdaae":"code","13a538d8":"code","94d34653":"code","d4e4e639":"code","d6288a5d":"code","1f3195a0":"code","9ccab7a1":"code","08576d25":"code","473ca65e":"code","e38859a9":"code","1aef7b45":"code","f0f7e161":"code","750b4a07":"code","1fa5ca91":"code","8be087f9":"code","92a9fedc":"markdown"},"source":{"a5dbe940":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","9ba2d038":"import os\nos.mkdir(\"mydata\")\nos.mkdir(\"masks\")","59356a07":"import zipfile\nwith zipfile.ZipFile(\"..\/input\/finding-lungs-in-ct-data\/2d_masks.zip\", 'r') as zip_ref:\n    zip_ref.extractall(\".\/masks\")\nwith zipfile.ZipFile(\"..\/input\/finding-lungs-in-ct-data\/2d_images.zip\", 'r') as zip_ref:\n    zip_ref.extractall(\".\/mydata\")","9274e890":"import cv2\nimport matplotlib.pyplot as plt\nos.chdir(\"\/kaggle\/working\/mydata\")\n#print(os.getcwd())\nli = os.listdir()\nx_data = []\ny_data = []\ncnt = 0\nfor i in li:\n    img = cv2.imread(i,0)\n    #print(img.shape)\n    img = cv2.resize(img,(32,32),cv2.INTER_CUBIC)\n    norm = (img - np.min(img)) \/ (np.max(img) - np.min(img))\n    #norm = norm.flatten()\n    x_data.append(norm)\n    cnt = cnt+1\nprint(cnt)\ninput()\nos.chdir('..')\nos.chdir('masks')\nli = os.listdir()\nprint(os.getcwd())\ninput()\ncnt = 0\nfor i in li:\n    img = cv2.imread(i,0)\n    img = cv2.resize(img,(32,32),cv2.INTER_CUBIC)\n    norm = (img - np.min(img)) \/ (np.max(img) - np.min(img))\n    #norm.flatten()\n    y_data.append(norm)\n    cnt = cnt+1\nprint(cnt)","84e4265a":"import numpy as np\nx_data = np.asarray(x_data)\ny_data = np.asarray(y_data)\nprint(y_data.shape)\nprint(x_data.shape)","9a8bdaae":"#CNN accepting ndim=4 #\nx_data = x_data[:,:,:,np.newaxis]\nprint(y_data.shape)\ny_data = y_data[:,:,:,np.newaxis]","13a538d8":"print(x_data.shape)\nprint(y_data.shape)","94d34653":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.5)","d4e4e639":"print(x_train.shape)\nprint(y_train.shape)","d6288a5d":"from keras.models import Model\nfrom keras.layers import *\nfrom keras.optimizers import Adam\nfrom keras.regularizers import l2\nfrom keras.preprocessing.image import ImageDataGenerator\nimport keras.backend as K\nfrom keras.callbacks import LearningRateScheduler, ModelCheckpoint","1f3195a0":"\ninput_layer = Input(shape=x_train.shape[1:])\nc1 = Conv2D(filters=8, kernel_size=(3,3), activation='relu', padding='same')(input_layer)\nl = MaxPool2D(strides=(2,2))(c1)\nc2 = Conv2D(filters=16, kernel_size=(3,3), activation='relu', padding='same')(l)\nl = MaxPool2D(strides=(2,2))(c2)\nc3 = Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same')(l)\nl = MaxPool2D(strides=(2,2))(c3)\nc4 = Conv2D(filters=32, kernel_size=(1,1), activation='relu', padding='same')(l)\nl = concatenate([UpSampling2D(size=(2,2))(c4), c3], axis=-1)\nl = Conv2D(filters=32, kernel_size=(2,2), activation='relu', padding='same')(l)\nl = concatenate([UpSampling2D(size=(2,2))(l), c2], axis=-1)\nl = Conv2D(filters=24, kernel_size=(2,2), activation='relu', padding='same')(l)\nl = concatenate([UpSampling2D(size=(2,2))(l), c1], axis=-1)\nl = Conv2D(filters=16, kernel_size=(2,2), activation='relu', padding='same')(l)\nl = Conv2D(filters=64, kernel_size=(1,1), activation='relu')(l)\nl = Dropout(0.5)(l)\noutput_layer = Conv2D(filters=1, kernel_size=(1,1), activation='sigmoid')(l)\n                                                         \nmodel = Model(input_layer, output_layer)","9ccab7a1":"model.summary()","08576d25":"def my_generator(x_train, y_train, batch_size=8):\n    data_generator = ImageDataGenerator(\n            width_shift_range=0.1,\n            height_shift_range=0.1,\n            rotation_range=10,\n            zoom_range=0.1).flow(x_train, x_train, batch_size, seed=42)\n    mask_generator = ImageDataGenerator(\n            width_shift_range=0.1,\n            height_shift_range=0.1,\n            rotation_range=10,\n            zoom_range=0.1).flow(y_train, y_train, batch_size, seed=42)\n    while True:\n        x_batch, _ = data_generator.next()\n        y_batch, _ = mask_generator.next()\n        yield x_batch, y_batch","473ca65e":"image_batch, mask_batch = next(my_generator(x_train, y_train, 8))\nfix, ax = plt.subplots(8,2, figsize=(8,20))\nfor i in range(8):\n    ax[i,0].imshow(image_batch[i,:,:,0])\n    ax[i,1].imshow(mask_batch[i,:,:,0])\nplt.show()","e38859a9":"def dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + K.epsilon()) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())","1aef7b45":"model.build((32,32))\nmodel.compile(optimizer=Adam(2e-4), loss='binary_crossentropy', metrics=[dice_coef])","f0f7e161":"weight_saver = ModelCheckpoint('lung.h5', monitor='val_dice_coef', \n                                              save_best_only=True, save_weights_only=True)\nannealer = LearningRateScheduler(lambda x: 1e-3 * 0.8 ** x)","750b4a07":"print(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)","1fa5ca91":"hist = model.fit_generator(my_generator(x_train, y_train, 8),\n                           steps_per_epoch = 200,\n                           validation_data = (x_test, y_test),\n                           epochs=10, verbose=2,\n                           callbacks = [weight_saver, annealer])","8be087f9":"model.load_weights('lung.h5')","92a9fedc":"weight_saver = ModelCheckpoint('lung.h5', monitor='val_dice_coef', \n                                              save_best_only=True, save_weights_only=True)\nannealer = LearningRateScheduler(lambda x: 1e-3 * 0.8 ** x)"}}