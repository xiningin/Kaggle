{"cell_type":{"5e776795":"code","e2a2dc7a":"code","fd5a3298":"code","1f82dd05":"code","514d817f":"code","30924a24":"code","0c1b70c4":"code","c9b04436":"code","051f506d":"code","f44364b9":"code","82445fae":"code","5140e0c3":"code","3fa3eac9":"code","76afa6e0":"code","038bc154":"code","ba88a627":"code","cbc40be4":"code","a112e235":"code","bd16ab3b":"code","2494b0a5":"code","eaa0b79e":"code","71772d55":"code","3a17ba8b":"code","d46f856b":"code","fc73248b":"code","eb3cbe3a":"code","23d3b889":"code","b0f01372":"code","2c919b1e":"code","2af7d08e":"code","2159d3a7":"code","70c8ff57":"code","905b315a":"code","e4f78270":"code","90f30e5b":"code","77651cae":"markdown","1183c413":"markdown","a59add00":"markdown","b306b6e4":"markdown","00d1397c":"markdown","712d0b5c":"markdown","8aedcd5e":"markdown","0b1eca79":"markdown"},"source":{"5e776795":"# \u30e9\u30a4\u30d6\u30e9\u30ea\u8aad\u307f\u8fbc\u307f\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os, glob, pickle, time, gc, copy, sys\nimport pandas_profiling as pdp\nimport warnings\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import metrics\nimport tensorflow as tf\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', 100) # \u8868\u793a\u3067\u304d\u308b\u8868\u306e\u5217\u6570","e2a2dc7a":"# train\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u3080\ndf_train = pd.read_csv(\"..\/input\/ai-medical-contest-2021\/train.csv\")\nprint(\"df_train.shape\", df_train.shape) # \u30b7\u30a7\u30a4\u30d7 = (\u884c\u6570, \u5217\u6570)\u3092\u8868\u793a\u3059\u308b\ndf_train.head() # \u5148\u982d5\u884c\u3092\u8868\u793a\u3059\u308b","fd5a3298":"# test\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u3080\ndf_test = pd.read_csv(\"..\/input\/ai-medical-contest-2021\/\/test.csv\")\nprint(\"df_test.shape\", df_test.shape) # \u30b7\u30a7\u30a4\u30d7 = (\u884c\u6570, \u5217\u6570)\u3092\u8868\u793a\u3059\u308b\ndf_test.head() # \u5148\u982d5\u884c\u3092\u8868\u793a\u3059\u308b","1f82dd05":"# submission\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u3080\ndf_sub = pd.read_csv(\"..\/input\/ai-medical-contest-2021\/\/sample_submission.csv\")\nprint(\"df_sub.shape\", df_sub.shape) # \u30b7\u30a7\u30a4\u30d7 = (\u884c\u6570, \u5217\u6570)\u3092\u8868\u793a\u3059\u308b\ndf_sub.head() # \u5148\u982d5\u884c\u3092\u8868\u793a\u3059\u308b","514d817f":"# ECG\u30c7\u30fc\u30bf\u306epath\u306e\u5217\u3092\u8ffd\u52a0.\ndf_train['path'] = df_train['Id'].apply(lambda x: \"..\/input\/ai-medical-contest-2021\/ecg\/{}.npy\".format(x))\ndf_test['path'] = df_test['Id'].apply(lambda x: \"..\/input\/ai-medical-contest-2021\/ecg\/{}.npy\".format(x))\nprint(df_train['path'][0]) # path\u5217\u306e0\u884c\u76ee\u3092\u8868\u793a\ndf_train.head()","30924a24":"# train\u3068test\u3092\u9023\u7d50\u3059\u308b\ndf_traintest = pd.concat([df_train, df_test]).reset_index(drop=True) # reset_index: \u884c\u306eindex\u3092\u30ea\u30bb\u30c3\u30c8\u3059\u308b\nprint(df_traintest.shape)\ndf_traintest.head()","0c1b70c4":"# \u30bf\u30fc\u30b2\u30c3\u30c8\u306b\u3064\u3044\u3066\u89e3\u6790\ncol_target = 'target' # \u30bf\u30fc\u30b2\u30c3\u30c8\u306e\u5217\ncol_index = 'Id' # id\u306e\u5217\nprint(\"rate of positive: {:.6f}\".format(df_train[col_target].mean())) # target\u304c1\u3067\u3042\u308b\u5272\u5408","c9b04436":"# \u5404\u5217\u306e\u57fa\u672c\u60c5\u5831\u3092\u8868\u793a\n# \u89e3\u6790\u5bfe\u8c61\u306ftrain+test\n# \u5217\u540d, \u578b, nan\u306e\u6570, unique\u306a\u5024\u306e\u6570, \u5b9f\u969b\u306e\u5024\u306e\u4e00\u90e8, \u3092\u8868\u793a\u3059\u308b\ndf_tmp = df_traintest  # \u89e3\u6790\u3059\u308bDataFrame\u3092\u6307\u5b9a\nfor i, col in enumerate(df_tmp.columns): # \u5404\u5217(column)\u306b\u3064\u3044\u3066\n    col_name = col + \" \" * (22 - len(col)) # \u30ab\u30e9\u30e0\u540d, \u898b\u305f\u76ee\u4e0a\u306e\u6574\u5f62\u306e\u305f\u3081\u306b\u30b9\u30da\u30fc\u30b9\u3092\u52a0\u3048\u308b\n    type_name = \"{}\".format(df_tmp[col].dtype) # \u578b\u540d\n    type_name = type_name + \" \" * (8 - len(type_name)) # \u898b\u305f\u76ee\u4e0a\u306e\u6574\u5f62\u306e\u305f\u3081\u306b\u30b9\u30da\u30fc\u30b9\u3092\u52a0\u3048\u308b\n    num_unique = len(df_tmp[col].unique()) # \u30e6\u30cb\u30fc\u30af\u306a\u5024\u306e\u6570\n    num_nan = pd.isna(df_tmp[col]).sum() # nan\u306e\u6570\n    col_head = \"{}\".format(df_tmp[col].unique()[:5].tolist())[:40] # \u5b9f\u969b\u306e\u5024\u306e\u4e00\u90e8\n    print(\"{:4d}: {} dtype: {} unique: {:8d}, nan: {:6d}, \u5b9f\u969b\u306e\u5024: {}\".format(\n        i, col_name, type_name, len(df_tmp[col].unique()), num_nan, col_head)) # \u8868\u793a\u3059\u308b","051f506d":"# pandas profile \u3067\u30c7\u30fc\u30bf\u306e\u89e3\u6790\u3092\u884c\u3046\n# \u89e3\u6790\u5bfe\u8c61\u306ftrain+test\npdp.ProfileReport(df_traintest)","f44364b9":"# \u6570\u5024\u5909\u6570\u306b\u3064\u3044\u3066\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u3092\u8868\u793a\u3059\u308b\n# \u89e3\u6790\u5bfe\u8c61\u306ftrain+test\nfrom scipy.stats import norm\ncols_num = ['age'] # \u6570\u5024\u5909\u6570\u306e\u5217\u540d\u306e\u30ea\u30b9\u30c8, \u3053\u306e\u30c7\u30fc\u30bf\u306e\u5834\u5408 age \u306e\u307f\nfig = plt.figure(figsize=(20, int(4*int(np.ceil(len(cols_num)\/4)))))\nfor i, col in enumerate(cols_num[:]):\n    ax = fig.add_subplot(int(np.ceil(len(cols_num)\/4)),4,i+1)\n    sns.distplot(\n        df_traintest[col], # \u8868\u793a\u3059\u308b\u30c7\u30fc\u30bf\n        bins=20, # \u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u306e\u30d3\u30f3\u306e\u6570\n        color='black', label='data',\n        kde_kws={'label': 'kde','color':'r'},\n#         fit=norm, \n#         fit_kws={'label': 'norm','color':'red'},\n        rug=False\n    )","82445fae":"# \u30ab\u30c6\u30b4\u30ea\u5909\u6570\u306b\u3064\u3044\u3066\u68d2\u30b0\u30e9\u30d5\u3092\u8868\u793a\u3059\u308b\n# \u89e3\u6790\u5bfe\u8c61\u306ftrain+test\ncols_cat = ['sex', 'label_type'] # \u89e3\u6790\u3059\u308b\u5217\u540d\nfor i, col in enumerate(cols_cat):\n    g = sns.catplot(\n        x=col,  \n        kind=\"count\",\n        data=df_traintest, # \u89e3\u6790\u3059\u308bDataFrame\n        height=5, \n        palette=\"muted\"\n    )\n    g.fig.set_figwidth(16)\n    g.fig.set_figheight(2)\n    plt.show()","5140e0c3":"# \u30bf\u30fc\u30b2\u30c3\u30c8\u306e\u5024\u3054\u3068\u306b\u6570\u5024\u5909\u6570\u306e\u30d0\u30a4\u30aa\u30ea\u30f3\u30d7\u30ed\u30c3\u30c8\u3092\u8868\u793a\n# target=0\u306e\u5834\u5408\u306eage\u306e\u5206\u5e03\u3001target=1\u306e\u5834\u5408\u306eage\u306e\u5206\u5e03\u3092\u8868\u793a\u3059\u308b\n# 2\u3064\u306e\u5206\u5e03\u304c\u9055\u3046\u3068\u3044\u3046\u4e8b\u306f\u305d\u306e\u5909\u6570\u304c\u30bf\u30fc\u30b2\u30c3\u30c8\u306b\u5f37\u3044\u5f71\u97ff\u3092\u4e0e\u3048\u3066\u3044\u308b\u3053\u3068\u3092\u793a\u5506\u3059\u308b\n# \u89e3\u6790\u5bfe\u8c61\u306ftrain\u306e\u307f\nfig = plt.figure(figsize=(20, int(4*int(np.ceil(len(cols_num)\/4)))))\nfor i, col in enumerate(cols_num):\n    ax = fig.add_subplot(int(np.ceil(len(cols_num)\/4)),4,i+1)\n    sns.violinplot(\n        x=col_target,\n        y=col,\n        data=df_train,\n#         scale='count', # \u6d88\u3059\u3068\u6b63\u898f\u5316\u3059\u308b\n    )","3fa3eac9":"# \u6570\u5024\u5909\u6570\u306b\u3064\u3044\u3066 logistic regression plot\n# age \u3092\u8aac\u660e\u5909\u6570\u3068\u3057\u3066 target \u3092\u30a2\u30a6\u30c8\u30ab\u30e0\u3068\u3059\u308b\u30ed\u30b8\u30b9\u30c6\u30a3\u30c3\u30af\u56de\u5e30\u3092\u884c\u3063\u3066\u305d\u308c\u3092\u8868\u793a\n# \u89e3\u6790\u5bfe\u8c61\u306ftrain\u306e\u307f\nfig = plt.figure(figsize=(20, int(4*int(np.ceil(len(cols_num)\/4)))))\nfor i, col in enumerate(cols_num[:]):\n    ax = fig.add_subplot(int(np.ceil(len(cols_num)\/4)),4,i+1)\n    sns.regplot(x=col,\n                y=col_target,\n                data=df_train,\n                logistic=True, \n                scatter_kws={'s': 10, 'alpha':0.3,'color':'m'},\n    )","76afa6e0":"# \u30ab\u30c6\u30b4\u30ea\u5909\u6570\u306b\u3064\u3044\u3066\u7a4d\u307f\u4e0a\u3052\u68d2\u30b0\u30e9\u30d5\u3092\u8868\u793a\n# \u89e3\u6790\u5bfe\u8c61\u306ftrain\u306e\u307f\ndef stack_bar_plot(df_tmp, col, col_target, ax=None):\n    df_tmp[col][pd.isna(df_tmp[col])] = 'nan'\n    target_value = df_tmp[col].unique()\n    df_agg = df_tmp[df_tmp[col_target].duplicated()==False][[col_target]].sort_values(col_target).reset_index(drop=True)\n    for value in target_value:\n        col_value = \"{}\".format(value)\n        df_agg_tmp = df_tmp[df_tmp[col]==value].groupby(col_target)[col].agg(len).reset_index()\n        df_agg_tmp = df_agg_tmp.sort_values(col_target).reset_index(drop=True)\n        df_agg_tmp.columns = [col_target, col_value]\n        df_agg = pd.merge(df_agg, df_agg_tmp, on=col_target, how='left')\n    df_agg = df_agg.fillna(0)\n    col_new = \"{}\/{}\".format(col, col_target)\n    df_agg.columns = [col_new] + df_agg.columns[1:].values.tolist()\n    df_agg = df_agg.set_index(col_new)\n    df_agg.iloc[:] = df_agg.values \/ df_agg.values.sum(axis=1)[:,np.newaxis]\n    ax1 = df_agg.plot.bar(stacked=True, ax=ax)\n    ax1.legend(title=col)\n\n\ncols_cat = ['sex', 'label_type'] # \u89e3\u6790\u3059\u308b\u5217\u540d\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\nfor i, col in enumerate(cols_cat):\n    stack_bar_plot(df_train, col, col_target, ax=axes[i])","038bc154":"# train, test\u305d\u308c\u305e\u308c\u306elabel_type\u306e\u5206\u5e03\u3092\u78ba\u8a8d\u3059\u308b\ng = sns.catplot(\n        x='label_type',  \n        kind=\"count\",\n        data=df_train, # \u89e3\u6790\u3059\u308bDataFrame\n        height=5, \n        palette=\"muted\"\n)\ng.fig.set_figwidth(16)\ng.fig.set_figheight(2)\nplt.title(\"train data\", fontsize=16)\nplt.show()\n\ng = sns.catplot(\n        x='label_type',  \n        kind=\"count\",\n        data=df_test, # \u89e3\u6790\u3059\u308bDataFrame\n        height=5, \n        palette=\"muted\"\n)\ng.fig.set_figwidth(16)\ng.fig.set_figheight(2)\nplt.title(\"test data\", fontsize=16)\nplt.show()","ba88a627":"# \u5fc3\u96fb\u56f3\u6ce2\u5f62\u3092\u8868\u793a\u3059\u308b\nindex = 10 # \u8868\u793a\u3059\u308b\u884c\u3092\u6307\u5b9a\npath_tmp = df_train['path'][index] # \u8868\u793a\u3059\u308b\u5fc3\u96fb\u56f3\u30c7\u30fc\u30bf\u306epath\necg_tmp = np.load(path_tmp) # \u5fc3\u96fb\u56f3\u30c7\u30fc\u30bf\u306e\u3088\u307f\u3053\u307f\nprint(\"i: {}, id: {}\".format(index, df_train[col_index][index]))\nprint(\"ECG shape: {}\".format(ecg_tmp.shape))\nprint(\"target: {}\".format(df_train[col_target][index]))\nlead_list = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6'] # \u5404\u8a98\u5c0e\u306e\u540d\u79f0\nplt.figure(figsize=(20,16))\nfor i in range(12): # \u5404\u8a98\u5c0e\u3092\u53ef\u8996\u5316\n    if i<6:\n        plt.subplot(6,2,i*2+1)\n    else:\n        plt.subplot(6,2,i*2-10)\n    plt.plot(ecg_tmp[:,i])\n    plt.xticks(np.arange(0, 801, step=100))\n    plt.ylabel(lead_list[i]+\"  \", rotation=0, fontsize=16)\n    plt.minorticks_on()\n    plt.ylim(ecg_tmp.min(),ecg_tmp.max())\n    plt.grid(which=\"major\", color=\"black\", alpha=0.5)\n    plt.grid(which=\"minor\", color=\"gray\", linestyle=\":\")","cbc40be4":"# \u30ab\u30c6\u30b4\u30ea\u5909\u6570\u3092\u30e9\u30d9\u30eb\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u3059\u308b (\u6570\u5024\u306b\u7f6e\u304d\u63db\u3048\u308b).\ndf_traintest['sex'] = df_traintest['sex'].replace('female', 0) # female\u306b0\u3092\u4ee3\u5165\ndf_traintest['sex'] = df_traintest['sex'].replace('male', 1) # male\u306b1\u3092\u4ee3\u5165\ndf_traintest['sex'] = df_traintest['sex'].astype(int) # \u578b\u3092\u6574\u6570\u306b\u5909\u63db\n\ndf_traintest['label_type'] = df_traintest['label_type'].replace('human', 0) # human\u306b0\u3092\u4ee3\u5165\ndf_traintest['label_type'] = df_traintest['label_type'].replace('auto', 1) # auto\u306b1\u3092\u4ee3\u5165\ndf_traintest['label_type'] = df_traintest['label_type'].astype(int) # \u578b\u3092\u6574\u6570\u306b\u5909\u63db\ndf_traintest.head()","a112e235":"# train \u3068 test \u3092\u518d\u5ea6\u5207\u308a\u5206\u3051\u308b\ndf_train = df_traintest.iloc[:len(df_train)]\ndf_test = df_traintest.iloc[len(df_train):].reset_index(drop=True)\ndf_train.head()","bd16ab3b":"# \u5168\u3066\u306eECG\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u3080\necg_train = np.zeros([len(df_train), 800, 12], np.float32) # train\u306e\u5fc3\u96fb\u56f3\u30c7\u30fc\u30bf\u306e\u4ee3\u5165\u5148. shape=(\u30c7\u30fc\u30bf\u6570, \u6642\u9593\u65b9\u5411, 12\u8a98\u5c0e)\nfor i in range(len(df_train)): # \u5168\u3066\u306etrain data\u306b\u3064\u3044\u3066\n    path_tmp = df_train['path'][i] # i\u884c\u76ee\u306e\u5fc3\u96fb\u56f3\u30c7\u30fc\u30bf\u306epath\n    ecg_tmp = np.load(path_tmp) # i\u884c\u76ee\u306e\u5fc3\u96fb\u56f3\u30c7\u30fc\u30bf\n    ecg_train[i] = ecg_tmp # \u8aad\u307f\u8fbc\u3093\u3060\u5fc3\u96fb\u56f3\u30c7\u30fc\u30bf\u3092ecg_train\u306ei\u884c\u76ee\u306b\u4ee3\u5165\n\necg_test = np.zeros([len(df_test), 800, 12], np.float32) # test\u306e\u5fc3\u96fb\u56f3\u30c7\u30fc\u30bf\u306e\u4ee3\u5165\u5148. shape=(\u30c7\u30fc\u30bf\u6570, \u6642\u9593\u65b9\u5411, 12\u8a98\u5c0e)\nfor i in range(len(df_test)): # \u5168\u3066\u306etest data\u306b\u3064\u3044\u3066\n    path_tmp = df_test['path'][i] # i\u884c\u76ee\u306e\u5fc3\u96fb\u56f3\u30c7\u30fc\u30bf\u306epath\n    ecg_tmp = np.load(path_tmp) # i\u884c\u76ee\u306e\u5fc3\u96fb\u56f3\u30c7\u30fc\u30bf\n    ecg_test[i] = ecg_tmp # \u8aad\u307f\u8fbc\u3093\u3060\u5fc3\u96fb\u56f3\u30c7\u30fc\u30bf\u3092ecg_train\u306ei\u884c\u76ee\u306b\u4ee3\u5165\nprint(\"ecg_train.shape: {}\".format(ecg_train.shape))\nprint(\"ecg_test.shape: {}\".format(ecg_test.shape))","2494b0a5":"# target\u60c5\u5831\u3092numpy\u5f62\u5f0f\u306b\u5909\u63db\ntarget_train = df_train[col_target].values.astype(np.int) # pandas.Series\u304b\u3089np.ndarray\u3078\u5909\u63db\nprint(\"target_train.shape: {}\".format(target_train.shape))","eaa0b79e":"# \u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u3092\u884c\u3046\u305f\u3081\u306b\u30c7\u30fc\u30bf\u30925\u5206\u5272\u3059\u308b\n# 4\u3064\u3092\u5b66\u7fd2\u306b\u7528\u3044\u30011\u3064\u3092\u691c\u8a3c\u306b\u8981\u3059\u308b\u3002\u3053\u308c\u30925\u56de\u7e70\u308a\u8fd4\u3059\u3002\nfolds = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=42).split(\n    np.arange(len(df_train)), \n    y=df_train[col_target]) # \u5404fold\u30bf\u30fc\u30b2\u30c3\u30c8\u306e\u30e9\u30d9\u30eb\u306e\u5206\u5e03\u304c\u305d\u308d\u3046\u3088\u3046\u306b\u3059\u308b = stratified K fold\n)","71772d55":"# fold 0\u306e\u5b66\u7fd2\u30c7\u30fc\u30bf\u3068\u691c\u8a3c\u30c7\u30fc\u30bf\u306e\u5206\u5272\nfold = 0 # fold 0 \u306b\u3064\u3044\u3066\u306e\u5b66\u7fd2\u3092\u884c\u3046\n\n# \u3053\u306efold\u306b\u304a\u3051\u308b\u5b66\u7fd2\u30c7\u30fc\u30bf\u3068\u691c\u8a3c\u30c7\u30fc\u30bf\u306e\u5207\u308a\u5206\u3051\nX_train = ecg_train[folds[fold][0]] # \u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u5165\u529b\u30c7\u30fc\u30bf\u3092\u62bd\u51fa\ny_train = target_train[folds[fold][0]] # \u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u6b63\u89e3\u30c7\u30fc\u30bf\u3092\u62bd\u51fa\nX_valid = ecg_train[folds[fold][1]] # \u691c\u8a3c\u30c7\u30fc\u30bf\u306e\u5165\u529b\u30c7\u30fc\u30bf\u3092\u62bd\u51fa\ny_valid = target_train[folds[fold][1]] # \u691c\u8a3c\u30c7\u30fc\u30bf\u306e\u6b63\u89e3\u30c7\u30fc\u30bf\u3092\u62bd\u51fa\nprint(\"X_train.shape: {}, X_valid.shape: {}\".format(X_train.shape, X_valid.shape))\nprint(\"y_train.shape: {}, y_valid.shape: {}\".format(y_train.shape, y_valid.shape))","3a17ba8b":"# model\u306bdata\u3092\u6d41\u3059\u305f\u3081\u306edataset\u3092\u69cb\u7bc9\u3059\u308b\nBATCH_SIZE = 64 # \u30df\u30cb\u30d0\u30c3\u30c1\u306b\u542b\u3081\u308b\u30c7\u30fc\u30bf\u306e\u6570\ndef augment_fn(X, y):\n    \"\"\"\n    augmentation (\u30c7\u30fc\u30bf\u6c34\u5897\u3057)\u3092\u8a2d\u5b9a\u3059\u308b\n    \"\"\"\n    X_new = tf.image.random_crop(X, (700,12)) # \u6642\u9593\u65b9\u5411\u306b800 timepoint\u304b\u3089random\u306b700 timepoint\u3092\u5207\u308a\u51fa\u3059\n    return (X_new, y)\n    \n# train dataset\ntrain_dataset = tf.data.Dataset.from_tensor_slices(( # np\n    X_train, # \u5165\u529b\u30c7\u30fc\u30bf\n    y_train, # \u6b63\u89e3\u30c7\u30fc\u30bf\n))\ntrain_dataset = train_dataset.shuffle(len(train_dataset), reshuffle_each_iteration=True) # \u5b66\u7fd2\u4e2d\u306b\u30c7\u30fc\u30bf\u3092\u30b7\u30e3\u30c3\u30d5\u30eb\u3059\u308b\u3053\u3068\u3092\u6307\u5b9a\u3059\u308b\ntrain_dataset = train_dataset.map(augment_fn, num_parallel_calls=AUTOTUNE) # augmentation\u306e\u9069\u7528\ntrain_dataset = train_dataset.batch(BATCH_SIZE) # \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u30df\u30cb\u30d0\u30c3\u30c1\u5316\u3057\u3066\u30e2\u30c7\u30eb\u306b\u5165\u529b\u3059\u308b\u3053\u3068\u3092\u6307\u5b9a\u3059\u308b\n\n# valid dataset\nvalid_dataset = tf.data.Dataset.from_tensor_slices((\n    X_valid, # \u5165\u529b\u30c7\u30fc\u30bf\n    y_valid, # \u6b63\u89e3\u30c7\u30fc\u30bf\n))\nvalid_dataset = valid_dataset.batch(BATCH_SIZE) # \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u30df\u30cb\u30d0\u30c3\u30c1\u5316\u3057\u3066\u30e2\u30c7\u30eb\u306b\u5165\u529b\u3059\u308b\u3053\u3068\u3092\u6307\u5b9a\u3059\u308b (\u30b7\u30e3\u30c3\u30d5\u30eb\u306f\u3057\u306a\u3044)\n\n# test dataset\ntest_dataset = tf.data.Dataset.from_tensor_slices((\n    ecg_test, # \u5165\u529b\u30c7\u30fc\u30bf\n    np.zeros(len(ecg_test)), # \u6b63\u89e3\u30c7\u30fc\u30bf (test\u306b\u6b63\u89e3\u30c7\u30fc\u30bf\u306a\u3044\u305f\u3081\u30c0\u30df\u30fc\u30c7\u30fc\u30bf)\n))\ntest_dataset = test_dataset.batch(BATCH_SIZE) # \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u30df\u30cb\u30d0\u30c3\u30c1\u5316\u3057\u3066\u30e2\u30c7\u30eb\u306b\u5165\u529b\u3059\u308b\u3053\u3068\u3092\u6307\u5b9a\u3059\u308b (\u30b7\u30e3\u30c3\u30d5\u30eb\u306f\u3057\u306a\u3044)\n\n\n# dataset\u306e\u8aad\u307f\u8fbc\u307f\u30c6\u30b9\u30c8\necg_batch, target_batch = next(iter(train_dataset)) # \u8a66\u3057\u306b\u30df\u30cb\u30d0\u30c3\u30c1\u3092\u8aad\u307f\u8fbc\u3080\nprint(\"train ecg_batch.shape: {}\".format(ecg_batch.shape))\nprint(\"train target_batch.shape: {}\".format(target_batch.shape))\necg_batch, target_batch = next(iter(valid_dataset)) # \u8a66\u3057\u306b\u30df\u30cb\u30d0\u30c3\u30c1\u3092\u8aad\u307f\u8fbc\u3080\nprint(\"valid ecg_batch.shape: {}\".format(ecg_batch.shape))\nprint(\"valid target_batch.shape: {}\".format(target_batch.shape))","d46f856b":"# deep learning model\u306e\u4f5c\u6210\nos.environ['TF_CPP_MIN_LOG_LEVEL']='2'\ndef get_model(input_shape=(800, 12)):\n    model = tf.keras.models.Sequential([ # \u30ec\u30a4\u30e4\u30fc\u306e\u30ea\u30b9\u30c8\u304b\u3089\u30e2\u30c7\u30eb\u3092\u69cb\u7bc9\u3059\u308b\n        tf.keras.Input(shape=input_shape), # \u5165\u529b\u306e\u5f62\u72b6\u306e\u6307\u5b9a. shape=(\u6642\u9593\u8ef8, 12\u8a98\u5c0e)\n        # block1\n        tf.keras.layers.Conv1D(64, 7), # \u6642\u9593\u65b9\u5411\u306e1\u6b21\u5143\u7573\u307f\u8fbc\u307f\u30ec\u30a4\u30e4\u30fc. 32=\u51fa\u529b\u30c1\u30e3\u30cd\u30eb\u6570, 7=\u30ab\u30fc\u30cd\u30eb\u30b5\u30a4\u30ba\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Activation('relu'), \n        tf.keras.layers.MaxPool1D(2), \n        # block2\n        tf.keras.layers.Conv1D(128, 3, strides=2),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Activation('relu'), \n        # block3\n        tf.keras.layers.Conv1D(256, 3, strides=2),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Activation('relu'),\n        # pooling\n        tf.keras.layers.GlobalAveragePooling1D(), # \u6642\u9593\u65b9\u5411\u306eglobal pooling\n        # \u6700\u7d42\u30ec\u30a4\u30e4\u30fc\n        tf.keras.layers.Dense(1, activation='sigmoid')\n    ])\n    return model\n\nmodel = get_model()\nmodel.summary()","fc73248b":"# \u30e2\u30c7\u30eb\u306e\u30b3\u30f3\u30d1\u30a4\u30eb (\u5b66\u7fd2\u6761\u4ef6\u306e\u8a2d\u5b9a)\nmodel = get_model(input_shape=(None, 12)) # \u6642\u9593\u8ef8\u306e\u5165\u529b\u9577\u3055None=\u53ef\u5909\u306b\u3057\u3066\u518d\u5ea6model\u69cb\u7bc9\nmodel.compile(optimizer='adam', # \u30aa\u30d7\u30c6\u30a3\u30de\u30a4\u30b6\u30fc\u306bAdam\u3092\u6307\u5b9a\n              loss='binary_crossentropy', # \u640d\u5931\u95a2\u6570\u306bbinary crossentropy\u3092\u6307\u5b9a\n              metrics=['AUC'], # \u8a55\u4fa1\u95a2\u6570\u306bAUC\u3092\u6307\u5b9a\n             )\n# \u30e2\u30c7\u30eb\u306e\u4fdd\u5b58\u65b9\u6cd5\u306e\u6307\u5b9a\ncheckpoint_filepath = \"weight_fold{}.ckpt\".format(fold)\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath, # \u4fdd\u5b58path\n    save_weights_only=True, # \u91cd\u307f\u306e\u307f\u3092\u4fdd\u5b58\n    monitor='val_auc', # validataion\u306eAUC\u306e\u5024\u306b\u57fa\u3065\u3044\u3066\u91cd\u307f\u3092\u4fdd\u5b58\u3059\u308b\n    mode='max', # validataion\u306eAUC\u304c\u6700\u5927\u3068\u306a\u3063\u305f\u6642\u91cd\u307f\u3092\u4fdd\u5b58\u3059\u308b\n    save_best_only=True # AUC\u304c\u6539\u5584\u3057\u305f\u3068\u304d\u306e\u307f\u4fdd\u5b58\u3059\u308b\n)","eb3cbe3a":"# \u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\nmodel.fit(\n    train_dataset, # \u5b66\u7fd2\u306b\u7528\u3044\u308bdataset\n    validation_data=valid_dataset, # \u691c\u8a3c\u306b\u7528\u3044\u308bdataset\n    callbacks=[model_checkpoint_callback], # \u30e2\u30c7\u30eb\u4fdd\u5b58\u65b9\u6cd5\u306e\u6307\u5b9a\n    epochs=16, # epoch\u6570 (1epoch=\u3059\u3079\u3066\u306e\u753b\u50cf\u30921\u56de\u305a\u3064\u5b66\u7fd2\u306b\u5229\u7528\u3059\u308b)\n)","23d3b889":"# fold1-4\u306b\u3064\u3044\u3066\u3082\u5b66\u7fd2\u3092\u884c\u3046\n# for loop\u306e\u4e2d\u8eab\u306f\u4e0a\u8a18\u306efold 0\u3067\u306e\u51e6\u7406\u3068\u540c\u69d8\u3067\u3059\nfor fold in range(1,5):\n    print(\"fold: {}\".format(fold))\n    X_train = ecg_train[folds[fold][0]] # \u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u5165\u529b\u30c7\u30fc\u30bf\u3092\u62bd\u51fa\n    y_train = target_train[folds[fold][0]] # \u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u6b63\u89e3\u30c7\u30fc\u30bf\u3092\u62bd\u51fa\n    X_valid = ecg_train[folds[fold][1]] # \u691c\u8a3c\u30c7\u30fc\u30bf\u306e\u5165\u529b\u30c7\u30fc\u30bf\u3092\u62bd\u51fa\n    y_valid = target_train[folds[fold][1]] # \u691c\u8a3c\u30c7\u30fc\u30bf\u306e\u6b63\u89e3\u30c7\u30fc\u30bf\u3092\u62bd\u51fa\n    print(\"len train: {}. len valid: {}\".format(len(X_train), len(X_valid)))\n\n    # train dataset\n    train_dataset = tf.data.Dataset.from_tensor_slices((\n        X_train, # \u5165\u529b\u30c7\u30fc\u30bf\n        y_train, # \u6b63\u89e3\u30c7\u30fc\u30bf\n    ))\n    train_dataset = train_dataset.shuffle(len(train_dataset), reshuffle_each_iteration=True) # \u5b66\u7fd2\u4e2d\u306b\u30c7\u30fc\u30bf\u3092\u30b7\u30e3\u30c3\u30d5\u30eb\u3059\u308b\u3053\u3068\u3092\u6307\u5b9a\u3059\u308b\n    train_dataset = train_dataset.map(augment_fn, num_parallel_calls=AUTOTUNE) # augmentation\u306e\u9069\u7528\n    train_dataset = train_dataset.batch(BATCH_SIZE) # \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u30df\u30cb\u30d0\u30c3\u30c1\u5316\u3057\u3066\u30e2\u30c7\u30eb\u306b\u5165\u529b\u3059\u308b\u3053\u3068\u3092\u6307\u5b9a\u3059\u308b\n\n    # valid dataset\n    valid_dataset = tf.data.Dataset.from_tensor_slices((\n        X_valid, # \u5165\u529b\u30c7\u30fc\u30bf\n        y_valid, # \u6b63\u89e3\u30c7\u30fc\u30bf\n    ))\n    valid_dataset = valid_dataset.batch(BATCH_SIZE) # \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u30df\u30cb\u30d0\u30c3\u30c1\u5316\u3057\u3066\u30e2\u30c7\u30eb\u306b\u5165\u529b\u3059\u308b\u3053\u3068\u3092\u6307\u5b9a\u3059\u308b (\u30b7\u30e3\u30c3\u30d5\u30eb\u306f\u3057\u306a\u3044)\n\n    # model\u69cb\u7bc9\n    model = get_model(input_shape=(None, 12))\n    # \u30e2\u30c7\u30eb\u306e\u30b3\u30f3\u30d1\u30a4\u30eb (\u5b66\u7fd2\u6761\u4ef6\u306e\u8a2d\u5b9a)\n    model.compile(optimizer='adam', # \u30aa\u30d7\u30c6\u30a3\u30de\u30a4\u30b6\u30fc\u306bAdam\u3092\u6307\u5b9a\n                  loss='binary_crossentropy', # \u640d\u5931\u95a2\u6570\u306bbinary crossentropy\u3092\u6307\u5b9a\n                  metrics=['AUC'], # \u8a55\u4fa1\u95a2\u6570\u306bAUC\u3092\u6307\u5b9a\n                 )\n    # \u30e2\u30c7\u30eb\u306e\u4fdd\u5b58\u65b9\u6cd5\u306e\u6307\u5b9a\n    checkpoint_filepath = \"weight_fold{}.ckpt\".format(fold)\n    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n        filepath=checkpoint_filepath, # \u4fdd\u5b58path\n        save_weights_only=True, # \u91cd\u307f\u306e\u307f\u3092\u4fdd\u5b58\n        monitor='val_auc', # validataion\u306eAUC\u306e\u5024\u306b\u57fa\u3065\u3044\u3066\u91cd\u307f\u3092\u4fdd\u5b58\u3059\u308b\n        mode='max', # validataion\u306eAUC\u304c\u6700\u5927\u3068\u306a\u3063\u305f\u6642\u91cd\u307f\u3092\u4fdd\u5b58\u3059\u308b\n        save_best_only=True # AUC\u304c\u6539\u5584\u3057\u305f\u3068\u304d\u306e\u307f\u4fdd\u5b58\u3059\u308b\n    )\n    # \u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\n    model.fit(\n        train_dataset, # \u5b66\u7fd2\u306b\u7528\u3044\u308bdataset\n        validation_data=valid_dataset, # \u691c\u8a3c\u306b\u7528\u3044\u308bdataset\n        callbacks=[model_checkpoint_callback], # \u30e2\u30c7\u30eb\u4fdd\u5b58\u65b9\u6cd5\u306e\u6307\u5b9a\n        epochs=16, # epoch\u6570 (1epoch=\u3059\u3079\u3066\u306e\u753b\u50cf\u30921\u56de\u305a\u3064\u5b66\u7fd2\u306b\u5229\u7528\u3059\u308b)\n    )","b0f01372":"# \u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u306eAUC\u3092\u8a08\u7b97\u3059\u308b\npreds_valid = np.zeros(len(df_train), np.float32) # \u4e88\u6e2c\u7d50\u679c\u306e\u4ee3\u5165\u5148\nfor fold in range(5): # \u5404fold\u306b\u3064\u3044\u3066\n    print(\"fold: {}\".format(fold))\n    # valid dataset\n    X_valid = ecg_train[folds[fold][1]] # \u691c\u8a3c\u30c7\u30fc\u30bf\u306e\u5165\u529b\u30c7\u30fc\u30bf\u3092\u62bd\u51fa\n    y_valid = target_train[folds[fold][1]] # \u691c\u8a3c\u30c7\u30fc\u30bf\u306e\u6b63\u89e3\u30c7\u30fc\u30bf\u3092\u62bd\u51fa\n    valid_dataset = tf.data.Dataset.from_tensor_slices((\n        X_valid, # \u5165\u529b\u30c7\u30fc\u30bf\n        y_valid, # \u6b63\u89e3\u30c7\u30fc\u30bf\n    ))\n    valid_dataset = valid_dataset.batch(BATCH_SIZE) # \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u30df\u30cb\u30d0\u30c3\u30c1\u5316\u3057\u3066\u30e2\u30c7\u30eb\u306b\u5165\u529b\u3059\u308b\u3053\u3068\u3092\u6307\u5b9a\u3059\u308b (\u30b7\u30e3\u30c3\u30d5\u30eb\u306f\u3057\u306a\u3044)\n\n    # \u4e88\u6e2c\n    checkpoint_filepath = \"weight_fold{}.ckpt\".format(fold)\n    model.load_weights(checkpoint_filepath) # \u6700\u3082valid AUC\u304c\u9ad8\u304b\u3063\u305f\u30a8\u30dd\u30c3\u30af\u306e\u91cd\u307f\u3092\u8aad\u307f\u8fbc\u3080\n    pred_valid = model.predict(valid_dataset) # \u4e88\u6e2c\u306e\u5b9f\u884c\n    preds_valid[folds[fold][1]] = pred_valid[:,0] # \u4e88\u6e2c\u7d50\u679c\u306e\u4ee3\u5165\n\nvalid_auc = metrics.roc_auc_score(df_train[col_target], preds_valid)\nprint(\"CV: {:.6f}\".format(valid_auc))","2c919b1e":"# \u4e88\u6e2c\u7d50\u679c\u306e\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u3092\u8868\u793a\nidx_nega = df_train[col_target].astype(np.int)==0\nidx_posi = df_train[col_target].astype(np.int)==1\nplt.figure(figsize=(16,4))\nplt.subplot(1,2,1)\nplt.hist(preds_valid[idx_nega], bins=np.arange(101)\/100, alpha=0.3, label='negative')\nplt.hist(preds_valid[idx_posi], bins=np.arange(101)\/100, alpha=0.3, label='positive')\nplt.legend()\nplt.xlabel(\"predict\")\nplt.show()","2af7d08e":"# label\u304cpositive\u3067\u3042\u308a\u4e88\u6e2c\u304cpositive\u3060\u3063\u305f\u5fc3\u96fb\u56f3\u3092\u8868\u793a\ndf_tmp = copy.deepcopy(df_train)\ndf_tmp['pred'] = preds_valid\ndf_positive = df_tmp[df_tmp[col_target]==1]\ndf_positive = df_positive.sort_values('pred', ascending=False).reset_index(drop=True)\nindex = 0 # \u8868\u793a\u3059\u308b\u884c\u3092\u6307\u5b9a\npath_tmp = df_positive['path'][index] # \u8868\u793a\u3059\u308b\u5fc3\u96fb\u56f3\u30c7\u30fc\u30bf\u306epath\necg_tmp = np.load(path_tmp) # \u5fc3\u96fb\u56f3\u30c7\u30fc\u30bf\u306e\u3088\u307f\u3053\u307f\nprint(\"easiest positive case\")\nprint(\"id: {}\".format(df_positive[col_index][index]))\nprint(\"predict: {:.6f}\".format(df_positive['pred'][index]))\nlead_list = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6'] # \u5404\u8a98\u5c0e\u306e\u540d\u79f0\nplt.figure(figsize=(20,16))\nfor i in range(12): # \u5404\u8a98\u5c0e\u3092\u53ef\u8996\u5316\n    if i<6:\n        plt.subplot(6,2,i*2+1)\n    else:\n        plt.subplot(6,2,i*2-10)\n    plt.plot(ecg_tmp[:,i])\n    plt.xticks(np.arange(0, 801, step=100))\n    plt.ylabel(lead_list[i]+\"  \", rotation=0, fontsize=16)\n    plt.minorticks_on()\n    plt.ylim(ecg_tmp.min(),ecg_tmp.max())\n    plt.grid(which=\"major\", color=\"black\", alpha=0.5)\n    plt.grid(which=\"minor\", color=\"gray\", linestyle=\":\")","2159d3a7":"# label\u304cpositive\u3067\u3042\u308b\u306e\u306b\u4e88\u6e2c\u304cnegative\u3060\u3063\u305f\u5fc3\u96fb\u56f3\u3092\u8868\u793a\ndf_tmp = copy.deepcopy(df_train)\ndf_tmp['pred'] = preds_valid\ndf_positive = df_tmp[df_tmp[col_target]==1]\ndf_positive = df_positive.sort_values('pred').reset_index(drop=True)\nindex = 0 # \u8868\u793a\u3059\u308b\u884c\u3092\u6307\u5b9a\npath_tmp = df_positive['path'][index] # \u8868\u793a\u3059\u308b\u5fc3\u96fb\u56f3\u30c7\u30fc\u30bf\u306epath\necg_tmp = np.load(path_tmp) # \u5fc3\u96fb\u56f3\u30c7\u30fc\u30bf\u306e\u3088\u307f\u3053\u307f\nprint(\"most difficult positive case\")\nprint(\"id: {}\".format(df_positive[col_index][index]))\nprint(\"predict: {:.6f}\".format(df_positive['pred'][index]))\nlead_list = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6'] # \u5404\u8a98\u5c0e\u306e\u540d\u79f0\nplt.figure(figsize=(20,16))\nfor i in range(12): # \u5404\u8a98\u5c0e\u3092\u53ef\u8996\u5316\n    if i<6:\n        plt.subplot(6,2,i*2+1)\n    else:\n        plt.subplot(6,2,i*2-10)\n    plt.plot(ecg_tmp[:,i])\n    plt.xticks(np.arange(0, 801, step=100))\n    plt.ylabel(lead_list[i]+\"  \", rotation=0, fontsize=16)\n    plt.minorticks_on()\n    plt.ylim(ecg_tmp.min(),ecg_tmp.max())\n    plt.grid(which=\"major\", color=\"black\", alpha=0.5)\n    plt.grid(which=\"minor\", color=\"gray\", linestyle=\":\")","70c8ff57":"# label\u304cnegative\u3067\u3042\u308a\u4e88\u6e2c\u304cnegative\u3060\u3063\u305f\u5fc3\u96fb\u56f3\u3092\u8868\u793a\ndf_tmp = copy.deepcopy(df_train)\ndf_tmp['pred'] = preds_valid\ndf_negative = df_tmp[df_tmp[col_target]==0]\ndf_negative = df_negative.sort_values('pred').reset_index(drop=True)\nindex = 0 # \u8868\u793a\u3059\u308b\u884c\u3092\u6307\u5b9a\npath_tmp = df_negative['path'][index] # \u8868\u793a\u3059\u308b\u5fc3\u96fb\u56f3\u30c7\u30fc\u30bf\u306epath\necg_tmp = np.load(path_tmp) # \u5fc3\u96fb\u56f3\u30c7\u30fc\u30bf\u306e\u3088\u307f\u3053\u307f\nprint(\"easiest negative case\")\nprint(\"id: {}\".format(df_negative[col_index][index]))\nprint(\"predict: {:.6f}\".format(df_negative['pred'][index]))\nlead_list = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6'] # \u5404\u8a98\u5c0e\u306e\u540d\u79f0\nplt.figure(figsize=(20,16))\nfor i in range(12): # \u5404\u8a98\u5c0e\u3092\u53ef\u8996\u5316\n    if i<6:\n        plt.subplot(6,2,i*2+1)\n    else:\n        plt.subplot(6,2,i*2-10)\n    plt.plot(ecg_tmp[:,i])\n    plt.xticks(np.arange(0, 801, step=100))\n    plt.ylabel(lead_list[i]+\"  \", rotation=0, fontsize=16)\n    plt.minorticks_on()\n    plt.ylim(ecg_tmp.min(),ecg_tmp.max())\n    plt.grid(which=\"major\", color=\"black\", alpha=0.5)\n    plt.grid(which=\"minor\", color=\"gray\", linestyle=\":\")","905b315a":"# label\u304cnegative\u3067\u3042\u308b\u306e\u306b\u4e88\u6e2c\u304cpositive\u3060\u3063\u305f\u5fc3\u96fb\u56f3\u3092\u8868\u793a\ndf_tmp = copy.deepcopy(df_train)\ndf_tmp['pred'] = preds_valid\ndf_negative = df_tmp[df_tmp[col_target]==0]\ndf_negative = df_negative.sort_values('pred', ascending=False).reset_index(drop=True)\nindex = 0 # \u8868\u793a\u3059\u308b\u884c\u3092\u6307\u5b9a\npath_tmp = df_negative['path'][index] # \u8868\u793a\u3059\u308b\u5fc3\u96fb\u56f3\u30c7\u30fc\u30bf\u306epath\necg_tmp = np.load(path_tmp) # \u5fc3\u96fb\u56f3\u30c7\u30fc\u30bf\u306e\u3088\u307f\u3053\u307f\nprint(\"most difficult negative case\")\nprint(\"id: {}\".format(df_negative[col_index][index]))\nprint(\"predict: {:.6f}\".format(df_negative['pred'][index]))\nlead_list = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6'] # \u5404\u8a98\u5c0e\u306e\u540d\u79f0\nplt.figure(figsize=(20,16))\nfor i in range(12): # \u5404\u8a98\u5c0e\u3092\u53ef\u8996\u5316\n    if i<6:\n        plt.subplot(6,2,i*2+1)\n    else:\n        plt.subplot(6,2,i*2-10)\n    plt.plot(ecg_tmp[:,i])\n    plt.xticks(np.arange(0, 801, step=100))\n    plt.ylabel(lead_list[i]+\"  \", rotation=0, fontsize=16)\n    plt.minorticks_on()\n    plt.ylim(ecg_tmp.min(),ecg_tmp.max())\n    plt.grid(which=\"major\", color=\"black\", alpha=0.5)\n    plt.grid(which=\"minor\", color=\"gray\", linestyle=\":\")","e4f78270":"# test data\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\npreds_test = np.zeros([5, len(df_test)], np.float32) # \u4e88\u6e2c\u7d50\u679c\u306e\u4ee3\u5165\u5148\nfor fold in range(5): # \u5404fold\u306b\u3064\u3044\u3066\n    print(\"fold: {}\".format(fold))\n    # valid dataset\n    X_valid = ecg_train[folds[fold][1]] # \u691c\u8a3c\u30c7\u30fc\u30bf\u306e\u5165\u529b\u30c7\u30fc\u30bf\u3092\u62bd\u51fa\n    y_valid = target_train[folds[fold][1]] # \u691c\u8a3c\u30c7\u30fc\u30bf\u306e\u6b63\u89e3\u30c7\u30fc\u30bf\u3092\u62bd\u51fa\n    valid_dataset = tf.data.Dataset.from_tensor_slices((\n        X_valid, # \u5165\u529b\u30c7\u30fc\u30bf\n        y_valid, # \u6b63\u89e3\u30c7\u30fc\u30bf\n    ))\n    valid_dataset = valid_dataset.batch(BATCH_SIZE) # \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u30df\u30cb\u30d0\u30c3\u30c1\u5316\u3057\u3066\u30e2\u30c7\u30eb\u306b\u5165\u529b\u3059\u308b\u3053\u3068\u3092\u6307\u5b9a\u3059\u308b (\u30b7\u30e3\u30c3\u30d5\u30eb\u306f\u3057\u306a\u3044)\n\n    # \u4e88\u6e2c\n    checkpoint_filepath = \"weight_fold{}.ckpt\".format(fold)\n    model.load_weights(checkpoint_filepath) # \u6700\u3082valid AUC\u304c\u9ad8\u304b\u3063\u305f\u30a8\u30dd\u30c3\u30af\u306e\u91cd\u307f\u3092\u8aad\u307f\u8fbc\u3080\n    pred_test = model.predict(test_dataset) # \u4e88\u6e2c\u306e\u5b9f\u884c\n    preds_test[fold] = pred_test[:,0] # \u4e88\u6e2c\u7d50\u679c\u306e\u4ee3\u5165\nprint(\"preds_test.shape: {}\".format(preds_test.shape))\nprint(preds_test)","90f30e5b":"### submit\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\npreds_test_mean = preds_test.mean(axis=0) # \u5404fold\u306emodel\u306e\u4e88\u6e2c\u306e\u5e73\u5747\u5024\u3092\u6700\u7d42\u7684\u306a\u4e88\u6e2c\u7d50\u679c\u3068\u3057\u3066\u63a1\u7528\u3059\u308b\nprint(\"preds_test_mean.shape: {}\".format(preds_test_mean.shape))\ndf_sub[col_target] = preds_test.mean(axis=0) # \u63a8\u5b9a\u7d50\u679c\u3092\u4ee3\u5165\ndf_sub.to_csv(\"submission.csv\", index=None) # submit\u30d5\u30a1\u30a4\u30eb\u3092\u4fdd\u5b58\ndf_sub.head() # \u6700\u521d\u306e5\u884c\u3092\u8868\u793a","77651cae":"# \u5b66\u7fd2\u3057\u305f\u30e2\u30c7\u30eb\u3092\u8a55\u4fa1\u3059\u308b","1183c413":"# \u63d0\u51fa\u30d5\u30a1\u30a4\u30eb\u306e\u4f5c\u6210","a59add00":"# \u30d9\u30fc\u30b9\u30e9\u30a4\u30f3\u30e2\u30c7\u30eb\u3092\u4f5c\u6210\n### \u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\n![CV](https:\/\/jp.mathworks.com\/discovery\/cross-validation\/_jcr_content\/mainParsys\/image.adapt.480.medium.jpg\/1611249616013.jpg)\nhttps:\/\/jp.mathworks.com\/discovery\/cross-validation.html","b306b6e4":"# \u524d\u51e6\u7406","00d1397c":"### Convolutional neural networks\n![CNN](https:\/\/cdn-ak.f.st-hatena.com\/images\/fotolife\/a\/acro-engineer\/20180318\/20180318155516.png)\n(LeCun et al. 1998)  ","712d0b5c":"# \u6b21\u306b\u3059\u308b\u3053\u3068\n- model \u3092\u3055\u3089\u306b\u6df1\u304f\u3059\u308b\n- augmentation \u3092\u52a0\u3048\u308b (noise, amplify, etc)\n- \u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\uff65\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0 (epoch \u3092\u5897\u3084\u3059, learning rate \u3092\u6e1b\u3089\u3059, etc)\n- \u30e1\u30bf\u30c7\u30fc\u30bf\u3092\u6d3b\u7528\u3059\u308b (sex, age, label_type)\n- kaggle \u306e\u89e3\u6cd5\u3092\u53c2\u8003\u306b\u3059\u308b (e.g. https:\/\/www.kaggle.com\/shayanfazeli\/heartbeat)\n\n### \u53c2\u8003\u30ea\u30f3\u30af\n- [\u5fc3\u96fb\u56f3\u30c7\u30fc\u30bf\u00d7\u6a5f\u68b0\u5b66\u7fd2\u307e\u3068\u3081](https:\/\/medium.com\/micin-developers\/%E5%BF%83%E9%9B%BB%E5%9B%B3%E3%83%87%E3%83%BC%E3%82%BF-%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%81%BE%E3%81%A8%E3%82%81-ed702a0008d4)","8aedcd5e":"# EDA (Explanatory Data Analysis, \u63a2\u7d22\u7684\u30c7\u30fc\u30bf\u89e3\u6790)","0b1eca79":"# \u30c7\u30fc\u30bf\u8aad\u307f\u8fbc\u307f\n**\u30d5\u30a1\u30a4\u30eb**\n- `train.csv` - \u5b66\u7fd2\u7528\u30c7\u30fc\u30bf\n- `test.csv` - \u30c6\u30b9\u30c8\u7528\u30c7\u30fc\u30bf\n- `sample_submission.csv` - \u63d0\u51fa\u30d5\u30a1\u30a4\u30eb\u306e\u30b5\u30f3\u30d7\u30eb, 0 \u304b\u3089 1 \u306e\u9593\u306e\u5024\u306e\u4e88\u6e2c\u7d50\u679c\u3092 target \u5217\u306b\u4ee3\u5165\u3057\u3066\u63d0\u51fa\u3057\u3066\u304f\u3060\u3055\u3044.\n- `ecg\/` - \u5fc3\u96fb\u56f3\u30c7\u30fc\u30bf\u3092\u542b\u3080\u30c7\u30a3\u30ec\u30af\u30c8\u30ea. \u5404\u5fc3\u96fb\u56f3\u30c7\u30fc\u30bf\u306fnumpy\u5f62\u5f0f\u3067 `\u5fc3\u96fb\u56f3ID.npy`\u306e\u540d\u524d\u3067\u4fdd\u5b58\u3055\u308c\u3066\u3044\u307e\u3059. \u30c7\u30fc\u30bf\u306e\u5f62\u306f(800, 12)\u3067\u3059\u3002\n - \u7b2c1\u6b21\u5143 - \u6642\u9593\u89e3\u50cf\u5ea6: 100 Hz \u00d7 8 \u79d2 = 800 timepoint. \u5358\u4f4d: mV\n - \u7b2c2\u6b21\u5143 - 12\u8a98\u5c0e: I, II III, aVR, aVL, aVF, V1, V2, V3, V4, V5, V6  \n\n**\u30c7\u30fc\u30bf\u5185\u5bb9**\n- `Id` - \u533f\u540d\u5316\u3055\u308c\u305f\u5fc3\u96fb\u56f3ID. \u5168\u3066\u306e\u5fc3\u96fb\u56f3\u30c7\u30fc\u30bf\u306f\u305d\u308c\u305e\u308c\u7570\u306a\u308b\u60a3\u8005\u304b\u3089\u6e2c\u5b9a\u3055\u308c\u3066\u3044\u307e\u3059.\n- `target` - \u76ee\u7684\u5909\u6570. 0=\u6b63\u5e38, 1=\u5fc3\u7b4b\u6897\u585e (test.csv \u306b\u306f\u3042\u308a\u307e\u305b\u3093)\n- `age` - \u5e74\u9f62\n- `sex` - \u6027\u5225. 0=\u7537\u6027, 1=\u5973\u6027.\n- `label_type` \u30e9\u30d9\u30eb\u4f5c\u6210\u65b9\u6cd5. auto=\u81ea\u52d5\u89e3\u6790, human=\u533b\u5e2b\u306b\u3088\u308b\u8a3a\u65ad."}}