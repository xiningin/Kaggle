{"cell_type":{"e8a787b9":"code","31450866":"code","afb64140":"code","fbacda80":"code","48eb00cb":"code","2ed8cdb9":"code","e1e54f99":"code","9d0fa93c":"code","b37dc32e":"code","89751b08":"code","f13e9ca7":"code","30f06a92":"code","83634da3":"code","07c8a4a0":"code","41ab0910":"code","f357974d":"code","034134a7":"markdown","d86d1a9d":"markdown","2c1763e0":"markdown","1b33443e":"markdown","631e53a0":"markdown","af2c5979":"markdown","6306c5de":"markdown","cea24eef":"markdown","d6c21f43":"markdown","e75aef87":"markdown","27441bb9":"markdown","aac2c4e7":"markdown","f929654e":"markdown","987f7b60":"markdown","8b1f7090":"markdown","e72ff835":"markdown"},"source":{"e8a787b9":"import os\nimport cv2\nimport random\nimport itertools\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom keras.models import Sequential\nfrom keras.utils import to_categorical, plot_model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import layers, regularizers, optimizers, callbacks\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix","31450866":"img_size = 96\n\ndef load_data(path, train=True):\n    print(\"Loading data from: \", path)\n    data = []\n    for img in os.listdir(path):\n        imgname, ext = os.path.splitext(img)\n        ID, etc = imgname.split('__')\n        ID = int(ID) - 1 # to_categorical encodes starting from 0\n        if train:\n            _, lr, finger, _, _ = etc.split('_')\n        else:\n            _, lr, finger, _  = etc.split('_')\n        if lr=='Left':\n            base = 0 # left hand corresponding to 0-4\n        else: base  = 5 # right hand corresponding to 5-9\n        if finger==\"little\":\n            fingerNum = base + 0\n        elif finger=='ring':\n            fingerNum = base + 1\n        elif finger=='middle':\n            fingerNum = base + 2\n        elif finger=='index':\n            fingerNum = base + 3 \n        else: fingerNum = base + 4\n        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n        img_resize = cv2.resize(img_array, (img_size, img_size))\n        data.append([ID, fingerNum, img_resize])\n    return data","afb64140":"Altered_path = \"..\/input\/socofing\/SOCOFing\/Altered\/Altered-\"\nReal_path = \"..\/input\/socofing\/SOCOFing\/Real\"\n\nEasy_data = load_data(Altered_path+'Easy', train=True)\nMedium_data = load_data(Altered_path+'Medium', train=True)\nHard_data = load_data(Altered_path+'Hard', train=True)\nReal_data = load_data(Real_path, train=False)\n\nAltered_data = np.concatenate([Easy_data, Medium_data, Hard_data], axis=0)\ndel Easy_data, Medium_data, Hard_data # Free some memory","fbacda80":"X_Altered, y_SubjectID_Altered, y_fingerNum_Altered = [], [], []\n\nfor SubjectID, fingerNum, feature in Altered_data:\n    X_Altered.append(feature)\n    y_SubjectID_Altered.append(SubjectID)\n    y_fingerNum_Altered.append(fingerNum)\n\nX_Altered = np.array(X_Altered).reshape(-1, img_size, img_size, 1)\nX_Altered = X_Altered \/ 255.0 # Normalize to [0, 1]\ny_SubjectID_Altered = to_categorical(y_SubjectID_Altered, num_classes=600) # 600 persons in total\ny_fingerNum_Altered = to_categorical(y_fingerNum_Altered, num_classes=10) # 10 fingers per person\n\nX_SubjectID_train, X_SubjectID_val, y_SubjectID_train, y_SubjectID_val = train_test_split(\n    X_Altered, y_SubjectID_Altered, test_size=0.2, random_state=2)\nX_fingerNum_train, X_fingerNum_val, y_fingerNum_train, y_fingerNum_val = train_test_split(\n    X_Altered, y_fingerNum_Altered, test_size=0.2, random_state=2)","48eb00cb":"X_test, y_SubjectID_test, y_fingerNum_test = [], [], []\n\nfor SubjectID, fingerNum, feature in Real_data:\n    X_test.append(feature)\n    y_SubjectID_test.append(SubjectID)\n    y_fingerNum_test.append(fingerNum)\n\nX_test = np.array(X_test).reshape(-1, img_size, img_size, 1)\nX_test = X_test \/ 255.0\n\ny_SubjectID_test = to_categorical(y_SubjectID_test, num_classes=600)\ny_fingerNum_test = to_categorical(y_fingerNum_test, num_classes=10)","2ed8cdb9":"print(\"Shapes:                  Feature shape    label shape\")\nprint(\"----------------------------------------------------\")\nprint(\"full SubjectID data:  \", X_Altered.shape, y_SubjectID_Altered.shape)\nprint(\"SubjectID_Train:      \", X_SubjectID_train.shape, y_SubjectID_train.shape)\nprint(\"SubjectID_Validation: \", X_SubjectID_val.shape, y_SubjectID_val.shape)\nprint(\"SubjectID_Test:       \", X_test.shape, y_SubjectID_test.shape)\nprint(\"----------------------------------------------------\")\nprint(\"full fingerNum data:  \", X_Altered.shape, y_fingerNum_Altered.shape)\nprint(\"fingerNum_Train:      \", X_fingerNum_train.shape, y_fingerNum_train.shape)\nprint(\"fingerNum_Validation: \", X_fingerNum_val.shape, y_fingerNum_val.shape)\nprint(\"fingerNum_Test:       \", X_test.shape, y_fingerNum_test.shape)\n\ndel Altered_data, Real_data, y_SubjectID_Altered # Free some memory again","e1e54f99":"nets = 2\nmodel = [0] * nets\nfinal_Dense_units = [600, 10]\nmodel_name = ['SubjectID_Mod', 'FingerNum_Mod']\nfor i in range(nets):\n    model[i] = Sequential(name=model_name[i])\n\n    model[i].add(layers.Conv2D(32, (5, 5), activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape = (96, 96, 1)))\n    model[i].add(layers.BatchNormalization())\n    model[i].add(layers.MaxPool2D((2, 2)))\n    model[i].add(layers.Conv2D(64,(5, 5), activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n    model[i].add(layers.BatchNormalization())\n    model[i].add(layers.MaxPool2D((2, 2)))\n    model[i].add(layers.Conv2D(128,(3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n    model[i].add(layers.BatchNormalization())\n    model[i].add(layers.MaxPool2D((2, 2)))\n    model[i].add(layers.Dropout(0.3))\n    model[i].add(layers.Flatten())\n    model[i].add(layers.Dense(256, activation='relu'))\n    model[i].add(layers.Dropout(0.4))\n    model[i].add(layers.Dense(final_Dense_units[i], activation='softmax'))\n\n    # Complete with Adam optimizer and entropy cost\n    model[i].compile(optimizer=optimizers.Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    model[i].summary()","9d0fa93c":"#Plot Id model graph in layers\nplot_model(model[0], show_shapes=True, to_file='.\/model0.png')","b37dc32e":"# Plot finger model grapy in layers\nplot_model(model[1], show_shapes=True, to_file='.\/model1.png')","89751b08":"# Because of the RAM limitatiaon(Max 13GB), two dataset will cause overloaded problem\n# Thus no enougth remaining RAM for models fitting\n# So I delete the fingerNum dataset before the SubjectID model fitting, then reload it when needed.\ndel X_fingerNum_train, X_fingerNum_val, y_fingerNum_train, y_fingerNum_val","f13e9ca7":"history = [0] * nets\nCallBack = [0] * nets\nReduceLR_minlr = [1e-9, 1e-7]\nepochs = 20\nbatch_size = 64\nfor i in range(nets):\n    CallBack[i] = [\n        callbacks.EarlyStopping(monitor='val_accuracy', patience=10, mode='max', verbose=1),\n        callbacks.ReduceLROnPlateau(factor=0.1, patience=1, min_lr=ReduceLR_minlr[i], verbose=1),\n        callbacks.TensorBoard(log_dir=\".\/log_dir\/\"+model_name[i])]\nhistory[0] = model[0].fit(X_SubjectID_train, y_SubjectID_train,\n                    batch_size = batch_size,\n                    epochs = epochs, \n                    validation_data = (X_SubjectID_val, y_SubjectID_val),\n                    verbose = 1, callbacks= CallBack[0])","30f06a92":"# Delete the SubjectID dataset after it was used\ndel X_SubjectID_train, X_SubjectID_val, y_SubjectID_train, y_SubjectID_val\n# Then reload fingerNum dataset before model fitting\nX_fingerNum_train, X_fingerNum_val, y_fingerNum_train, y_fingerNum_val = train_test_split(\n    X_Altered, y_fingerNum_Altered, test_size=0.2, random_state=2)\n\ndel X_Altered, y_fingerNum_Altered\n\nhistory[1] = model[1].fit(X_fingerNum_train, y_fingerNum_train,\n                    batch_size = batch_size,\n                    epochs = epochs, \n                    validation_data = (X_fingerNum_val, y_fingerNum_val),\n                    verbose = 1, callbacks= CallBack[1])","83634da3":"# Load the TensorBoard notebook extension\n%load_ext tensorboard\n# Launch TensorBoard\n# Supervising the SubjectID model\n%tensorboard --logdir '.\/log_dir\/SubjectID_log'\n# or, supervising the fingerNum model\n# %tensorboard --logdir '.\/log_dir\/fingerNum_log'","07c8a4a0":"acc = [0] * nets\nval_acc = [0] * nets\nloss = [0] * nets\nval_loss = [0] * nets\nfor i in range(nets):\n    acc[i] = history[i].history['accuracy']\n    val_acc[i] = history[i].history['val_accuracy']\n    loss[i] = history[i].history['loss']\n    val_loss[i] = history[i].history['val_loss']\n\n    epochs = range(1, len(acc[i]) + 1)\n    # plot figures models\n    plt.figure()\n    plt.plot(epochs, acc[i], label='Training acc of '+model_name[i])\n    plt.plot(epochs, val_acc[i], label='Validation acc of '+model_name[i])\n    plt.title('Training and validation accuracy of '+model_name[i])\n    plt.legend()\n    plt.figure()\n    plt.plot(epochs, loss[i],  label='Training loss of '+model_name[i])\n    plt.plot(epochs, val_loss[i], label='Validation loss of '+model_name[i])\n    plt.title('Training and validation loss of '+model_name[i])\n    plt.legend()\n\ntesting_acc_Id = model[0].evaluate([X_test], [y_SubjectID_test], verbose=0)\nprint(\"Id recognition accuracy: \",testing_acc_Id[1]*100, \"%\")\ntesting_acc_finger = model[1].evaluate([X_test], [y_fingerNum_test], verbose=0)\nprint(\"Finger recognition accuracy: \",testing_acc_finger[1]*100, \"%\")","41ab0910":"# Visualize finger prediction with confusion matrix \ndef plot_confusion_matrix(conmat, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(conmat, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        conmat = conmat.astype('float') \/ conmat.sum(axis=1)[:, np.newaxis]\n\n    thresh = conmat.max() \/ 2.\n    for i, j in itertools.product(range(conmat.shape[0]), range(conmat.shape[1])):\n        plt.text(j, i, conmat[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if conmat[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('Real label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the test dataset\ny_fingerNum_pred = model[1].predict(X_test)\n# Convert predictions classes to one hot vectors \ny_fingerNum_pred_classes = np.argmax(y_fingerNum_pred, axis=1) \n# Convert test observations to one hot vectors\ny_fingerNum_real = np.argmax(y_fingerNum_test, axis=1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(y_fingerNum_real, y_fingerNum_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(10)) ","f357974d":"def show_fingername(fingernum):\n    if fingernum>=5:\n        fingername = \"right \"\n        fingernum -= 5\n    else: fingername = \"left \"\n    if fingernum==0:\n        fingername += \"little\"\n    elif fingernum==1:\n        fingername += \"ring\"\n    elif fingernum==2:\n        fingername += \"middle\"\n    elif fingernum==3:\n        fingername += \"index\"\n    else: fingername += \"thumb\"\n    return fingername\n\n# Randomly pick a fingerprint from test data to predict both its Id and fingername\nrand_fp_num = random.randint(0, X_test.shape[0]-1)\nplt.imshow(X_test[rand_fp_num].reshape((96, 96)), cmap ='gray')\ny_SubjectID_pred = model[0].predict(X_test)\nId_pred = np.argmax(y_SubjectID_pred[rand_fp_num])\nId_real = np.argmax(y_SubjectID_test[rand_fp_num])\nfingerNum_pred = np.argmax(y_fingerNum_pred[rand_fp_num])\nfingerNum_real = np.argmax(y_fingerNum_test[rand_fp_num])\nif Id_pred==Id_real and fingerNum_pred==fingerNum_real:\n    print(\"Infomation confirm! Fingerprint matches: person Id\",Id_pred, show_fingername(fingerNum_pred))\nelse:\n    print(\"Oops! Prediction is wrong!\")","034134a7":"### Visualize our models.","d86d1a9d":"### Build two models(set net=2). In these models, I introduce several methods to prevent overfitting, including L2 regularization, BatchNormalization, Dropout regularization, EarlyStopping and ReduceLROnPlateau.","2c1763e0":"### Each model reaches 99.75%+ accuracy, so eventually the kernel can predict with great confidence! I myself is a new learner of Deep Learning, this kernel might could be better, if you have any suggestions please do let me know! Hope this kernel could help you!","1b33443e":"### Adjust hyperparameters via TensorBoard.","631e53a0":"### Create two datasets, SubjectID datasets and fingerNum datasets. They will be used to train two different models in the next step.","af2c5979":"### Fit the models. Attention! Here the min_lr in ReduceLROnPlateau are different becasue of facts.","6306c5de":"### Delete the first datset and reload the second dataset. The fit the model.","cea24eef":"### Finally, randomly pick a fingerprint from test data to predict both its Id and fingername. When both the predictions are correct, then we can say this kernel works great with two models. Notice that the reason I choose ID and fingername as the labels of this kernel is that we usually verify a person's finger with his ID and the fingername. Of course you can choose others features as your label if you want!","d6c21f43":"### Delete the second dataset temporarily due to the overloading problem.","e75aef87":"### Visulize the predictions' of fingername to get a intuitional conclusion about how the model worked.","27441bb9":"### Visualize the training process with accuarcy and loss, so we can adjust hyperparameters incording to these feedbacks.","aac2c4e7":"### Load the raw dataset, and resize the images so that they can fit CNN's input_shape.","f929654e":"### Output the shapes of all datasets to confirm our previous work.","987f7b60":"## Based on CNN, this kernel uses the raw dataset to create two datasets(SubjectID and Fingername), then build two models and train the models with coresponding dataset. Finally, evaluate the kernel with a randomly picked fingerprint, when and only when both the predictions of ID and fingername are correct then we can say the kernel works.","8b1f7090":"### \u2014\u2014Brian Zhang,China, Shenzhen University, 2020","e72ff835":"### Totally speaking, this kernel is able to recognize the ID and fingername to any given fingerprint. And each model of this kernel reaches **99.75%+ accuracy**!!! So the kerenl works really great."}}