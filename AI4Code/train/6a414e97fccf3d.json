{"cell_type":{"29140418":"code","4a9f8c29":"code","0887d399":"code","c1dc3ea3":"code","90058db9":"code","0f47f989":"code","ba96613b":"code","05373d07":"code","133e77e7":"code","4aa54cef":"code","1e5bceff":"code","e752f2f3":"code","44fc5397":"code","a906543e":"code","b4a7de34":"code","2d056733":"code","9512cb80":"code","d395dffa":"code","410ea678":"code","cbeb5643":"code","8a115e5e":"code","bd595f74":"code","a6991720":"code","62148120":"code","a6e33677":"code","290cfb44":"code","ef81f2c3":"code","0879f4a5":"code","167845be":"code","c387b701":"markdown","2f48e460":"markdown","b6a3d7bf":"markdown","1da010f6":"markdown","08f131e6":"markdown","ef621157":"markdown","8806733c":"markdown","724a0f18":"markdown","d94976a9":"markdown","1eeac02f":"markdown","cece6b42":"markdown","4ff3b393":"markdown","d4603ab5":"markdown","e3df5b7e":"markdown","41d487f1":"markdown","8090e9a5":"markdown"},"source":{"29140418":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport librosa\nimport librosa.display\nfrom tqdm import tqdm\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport tensorflow.keras.models as models\nimport tensorflow.keras.layers as layers\n\n%matplotlib inline\n%load_ext tensorboard","4a9f8c29":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","0887d399":"CSV_FILE_PATH = \"..\/input\/environmental-sound-classification-50\/esc50.csv\"  # path of csv file\nDATA_PATH = \"..\/input\/environmental-sound-classification-50\/audio\/audio\/44100\/\" # path to folder containing audio files","c1dc3ea3":"#reading the csv file\ndf = pd.read_csv(CSV_FILE_PATH)\ndf","90058db9":"df_10 = df[df['esc10']==True]\ndf_10 = df_10.drop(['fold','esc10','src_file','take'], axis=1)\ndf_10","0f47f989":"classes = df_10['category'].unique()\nclasses","ba96613b":"class_dict = {i:x for x,i in enumerate(classes)}\nclass_dict","05373d07":"df_10['target'] = df_10['category'].map(class_dict)\ndf_10","133e77e7":"from IPython.display import HTML\n# Youtube\nHTML('<iframe width=\"663\" height=\"382\" src=\"https:\/\/www.youtube.com\/embed\/1RIA9U5oXro\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen><\/iframe>')","4aa54cef":"sample_df = df_10.drop_duplicates(subset=['target'])\nsample_df","1e5bceff":"signals = {}\nmel_spectrograms = {}\nmfccs = {}\n\nfor row in tqdm(sample_df.iterrows()):  # every row will be like [[index], [filename , target , category]]\n    signal , rate = librosa.load(DATA_PATH+ row[1][0])\n    signals[row[1][2]] = signal    # row[1][2] will be the category of that signal. eg. signal[\"dog\"] = signal of dog sound\n    \n    mel_spec = librosa.feature.melspectrogram(y=signal , sr=rate ,  n_fft=2048, hop_length=512)\n    mel_spec = librosa.power_to_db(mel_spec, ref=np.max)  #visualizing mel_spectrogram directly gives black image. So, coverting from power_to_db is required\n    mel_spectrograms[row[1][2]] = mel_spec\n    \n    mfcc = librosa.feature.mfcc(signal , rate , n_mfcc=13, dct_type=3)\n    mfccs[row[1][2]] = mfcc","e752f2f3":"def plot_signal(signal):\n    \"\"\"\n    this function will take the signal dictionary and plot the signals\n    \"\"\"\n    fig , axes = plt.subplots(nrows=5 , ncols=2 , sharex =False ,sharey=True,\n                             figsize=(40,20))\n    fig.suptitle('Time series',size=15)\n    i=0\n    for x in range(5):\n        for y in range(2):\n            axes[x,y].set_title(list(signal.keys())[i])\n            axes[x,y].plot(list(signal.values())[i])\n            axes[x,y].get_xaxis().set_visible(False)\n            axes[x,y].get_yaxis().set_visible(False)\n            i +=1","44fc5397":"def dis_feature(mfccs, cmap=None):\n    \"\"\"\n    this function will take the mfcc\/mel_spectrogram dictionary and plot the signals\n    \"\"\"\n    fig ,axes= plt.subplots(nrows=5 , ncols=2 , sharex=False, sharey=True , figsize=(40,20))\n    fig.suptitle('mel')\n    i=0\n    for x in range(5):\n        for y in range(2):\n            axes[x,y].set_title(list(mfccs.keys())[i])\n            axes[x,y].imshow(list(mfccs.values())[i], cmap=cmap,interpolation='nearest')\n            axes[x,y].get_xaxis().set_visible(False)\n            axes[x,y].get_yaxis().set_visible(False)\n            i+=1","a906543e":"plot_signal(signals)","b4a7de34":"dis_feature(mel_spectrograms)","2d056733":"dis_feature(mfccs, cmap='hot')","9512cb80":"X , y = [] , []\nfor data in tqdm(df_10.iterrows()):\n  sig , sr = librosa.load(DATA_PATH+data[1][0])\n  for i in range(3):\n    n = np.random.randint(0, len(sig)-(sr*2))\n    sig_ = sig[n : int(n+(sr*2))]\n    mfcc_ = librosa.feature.mfcc(sig_ , sr=sr, n_mfcc=13)\n    X.append(mfcc_)\n    y.append(data[1][1])\n\n# convert list to numpy array\nX = np.array(X) \ny = np.array(y)\n\n#one-hot encoding the target\ny = tf.keras.utils.to_categorical(y , num_classes=10)\n\n# our tensorflow model takes input as (no_of_sample , height , width , channel).\n# here X has dimension (no_of_sample , height , width).\n# So, the below code will reshape it to (no_of_sample , height , width , 1).\nX = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)","d395dffa":"X.shape\ny.shape","410ea678":"x_train , x_val , y_train , y_val = train_test_split(X , y ,test_size=0.2, random_state=2020)","cbeb5643":"INPUTSHAPE = (13,87,1)","8a115e5e":"model =  models.Sequential([\n                          layers.Conv2D(16 , (3,3),activation = 'relu',padding='valid', input_shape = INPUTSHAPE),\n                          layers.Conv2D(16, (3,3), activation='relu',padding='valid'),\n\n                          layers.Conv2D(32, (3,3), activation='relu',padding='valid'),\n                          layers.Conv2D(32, (3,3), activation='relu',padding='valid'),\n\n                          layers.Conv2D(64, (3,3), activation='relu',padding='valid'),\n                          layers.Conv2D(32, (3,3), activation='relu',padding='valid'),\n                          layers.GlobalAveragePooling2D(),\n\n\n                          layers.Dense(32 , activation = 'relu'),\n                          layers.Dense(10 , activation = 'softmax')\n])\n\nmodel.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = 'acc')","bd595f74":"model.summary()","a6991720":"%mkdir \"cpkt\"\n%mkdir \"logs\"","62148120":"LOGDIR = \"logs\"\nCPKT = \"cpkt\/\"","a6e33677":"#this callback is used to prevent overfitting.\ncallback_1 = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto',\n    baseline=None, restore_best_weights=False\n)\n\n#this checkpoint saves the best weights of model at every epoch\ncallback_2 = tf.keras.callbacks.ModelCheckpoint(\n    CPKT, monitor='val_loss', verbose=0, save_best_only=True,\n    save_weights_only=True, mode='auto', save_freq='epoch', options=None\n)\n\n#this is for tensorboard\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOGDIR)\n","290cfb44":"history = model.fit(x_train,y_train ,\n            validation_data=(x_val,y_val),\n            epochs=100,\n            callbacks = [callback_1 , callback_2 , tensorboard_callback])","ef81f2c3":"# %tensorboard --logdir=\"logs\"","0879f4a5":"# Download Ngrok to tunnel the tensorboard port to an external port\n!wget https:\/\/bin.equinox.io\/c\/4VmDzA7iaHb\/ngrok-stable-linux-amd64.zip\n!unzip ngrok-stable-linux-amd64.zip\n\n# Run tensorboard as well as Ngrox (for tunneling as non-blocking processes)\nimport os\nimport multiprocessing\n\n\npool = multiprocessing.Pool(processes = 10)\nresults_of_processes = [pool.apply_async(os.system, args=(cmd, ), callback = None )\n                        for cmd in [\n                        f\"tensorboard --logdir=\\\"logs\\\" --host 0.0.0.0 --port 6006 &\",\n                        \".\/ngrok http 6006 &\"\n                        ]]","167845be":"! curl -s http:\/\/localhost:4040\/api\/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","c387b701":"[](http:\/\/)","2f48e460":"## Step 5. Model","b6a3d7bf":"if running this in google colab use the following code:","1da010f6":"* Now we are going to take a three random 2 second clip from each audio file. this will increase the data size and also classification speed increases.\n* the following code iterate through every file and take three random clip from it.","08f131e6":"> Out of 50 classes we will be using 10 classes.\n> dataframe has column \"esc10\" which contains 10 classes. So, we will be using that 10 classes only.","ef621157":"if running in kaggle kernel use this code.\nthere are some error displaying tensorboard. So,the below code is taken from this amazing kernel.(https:\/\/www.kaggle.com\/shivam1600\/tensorboard-on-kaggle)","8806733c":"## Step 1. Importing Libraries","724a0f18":"## Step 2. Loading and Preprocessing","d94976a9":"## Step 4. Getting Data ready for training","1eeac02f":"## Step 3. Visualization\n\n* if you have little or no idea about mel-spectrogram and MFCC visit this site.\n[Introduction to feature extraction](https:\/\/towardsdatascience.com\/how-to-apply-machine-learning-and-deep-learning-methods-to-audio-analysis-615e286fcbbc)","cece6b42":"Taking one sample from each of the 10 classes for visualization","4ff3b393":"> Here we extracted two features mel-spectrogram and mfcc.\n> I had tried to use both feature for training and mfcc performed very well.\n> So, here we are going to use mfcc for training.","d4603ab5":"* editing target column according to the 10 classes.","e3df5b7e":"> use the link in the output of the following section to view in tensorboard.","41d487f1":">**Please upvote if you like my approach or if you learned something from this notebook.\nYour support gives me motivation to create interesting stuff.\nThank you.**","8090e9a5":"# Environmental Sound Classification\n\n* this kernel is useful for any audio classification task.\n* the following libraries are used in this kernel\n    1. Tensorflow (for model making and training)\n    2. sklearn (for splitting the data into trian,test,validation)\n    3. librosa (for loading and feature extraction of audio signals)\n    4. pandas (for reading csv file)\n    5. matplotlib (for plotting)"}}