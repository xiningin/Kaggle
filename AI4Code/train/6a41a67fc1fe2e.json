{"cell_type":{"d38bbb60":"code","3ba79e3d":"code","e8e45c64":"code","da4ee5cb":"code","70316dce":"code","0e3c22c7":"code","5dbca6c6":"code","f61d27bc":"code","a87f4565":"code","e34815ef":"code","7416bc31":"code","4169b9a4":"code","3ac5a823":"code","2c065dd9":"code","511103b8":"code","b284b3fa":"code","59886c9e":"code","24ec46e0":"code","26f8843d":"code","c8a9eee4":"code","9bc768e9":"code","15a8c53a":"code","bf051937":"code","fe7006dd":"code","c59c7b74":"code","1e13efe3":"code","006c9a93":"code","a4d9423b":"code","1ff4468c":"code","89a43c0b":"code","c0481810":"code","4828ad28":"code","06ed36e4":"markdown","aa4b9fad":"markdown","8949d460":"markdown","488dda50":"markdown","bf0a0885":"markdown"},"source":{"d38bbb60":"import matplotlib.pyplot as plt\nplt.style.use('ggplot') \nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom scipy import stats\nfrom xgboost import XGBRegressor\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","3ba79e3d":"#Realiza a leitura da base (csv) e carrega na m\u00e9moria\nenemTrain = pd.read_csv('..\/input\/codenation-enem2\/train.csv')\nenemTest = pd.read_csv('..\/input\/codenation-enem2\/test.csv')","e8e45c64":"#verificando o tamanho da Base\nenemTrain.shape","da4ee5cb":"#Verificando os nomes das colunas\nenemTrain.columns","70316dce":"import qgrid\nqgrid.show_qgri(enemTrain)","0e3c22c7":"import pandas_profiling\nprofile = enemTrain.profile_report(title=\"Enem Dataset\")","5dbca6c6":"profile","f61d27bc":"#vendo os 5 primeiros registros\nenemTrain.head()","a87f4565":"#verificando a tipagem dos dados\nenemTrain.dtypes","e34815ef":"#Verificando valores nulos\ntotal = enemTrain.isnull().sum().sort_values(ascending=False)\npercent = (enemTrain.isnull().sum()\/enemTrain.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","7416bc31":"#Verificando os valores nulos e mostrando a quantidade por coluna\nfor i in enemTrain.columns:\n    nulls_value = enemTrain[i].isna().sum()\n    message = \"Column {} has {} nulls\".format(i, nulls_value)\n    print(message)","4169b9a4":"#Realizando algumas analises\ndf = enemTrain.groupby('TP_SEXO').size()\n\ndf.plot(kind='pie', subplots=True, figsize=(8, 4))\nplt.title(\"Pie Chart Genero\")\nplt.ylabel(\"\")\nplt.show()\n\n\ndf = enemTrain.groupby('TP_ENSINO').size()\n\ndf.plot(kind='pie', subplots=True, figsize=(8, 4))\nplt.title(\"Pie Chart TP_ENSINO\")\nplt.ylabel(\"\")\nplt.show()\n\ndf = enemTrain.groupby('TP_COR_RACA').size()\n\ndf.plot(kind='pie', subplots=True, figsize=(8, 4))\nplt.title(\"Pie Chart TP_COR_RACA\")\nplt.ylabel(\"\")\nplt.show()","3ac5a823":"import squarify \n\ndf_raw = enemTrain\n\ndf = df_raw.groupby('SG_UF_RESIDENCIA').size().reset_index(name='counts')\nlabels = df.apply(lambda x: str(x[0]) + \"\\n (\" + str(x[1]) + \")\", axis=1)\nsizes = df['counts'].values.tolist()\ncolors = [plt.cm.Spectral(i\/float(len(labels))) for i in range(len(labels))]\n\nplt.figure(figsize=(12,8), dpi= 80)\nsquarify.plot(sizes=sizes, label=labels, color=colors, alpha=.8)\n\nplt.title('Treemap of Vechile Class')\nplt.axis('off')\nplt.show()","2c065dd9":"sns.set(rc={'figure.figsize':(9,4)})\nsns.distplot(enemTrain['IN_CEGUEIRA']);","511103b8":"sns.set(rc={'figure.figsize':(9,4)})\nsns.distplot(enemTrain['IN_SURDEZ']);","b284b3fa":"sns.set(rc={'figure.figsize':(9,4)})\nsns.distplot(enemTrain['IN_DEFICIENCIA_FISICA']);","59886c9e":"sns.set(rc={'figure.figsize':(9,4)})\nsns.distplot(enemTrain['IN_DEFICIENCIA_MENTAL']);","24ec46e0":"#An\u00e1lise estat\u00edstica\nenemTrain['NU_NOTA_MT'].describe()","26f8843d":"#Frequencia \nenemTrain.plot.hist(y='NU_NOTA_MT')","c8a9eee4":"#Rela\u00e7\u00e3o entre Nota de matem\u00e1ticas e outras mat\u00e9rias\nenemTrain.plot.scatter(x='NU_NOTA_CN', y='NU_NOTA_MT')\nenemTrain.plot.scatter(x='NU_NOTA_CH', y='NU_NOTA_MT')\nenemTrain.plot.scatter(x='NU_NOTA_LC', y='NU_NOTA_MT')\nenemTrain.plot.scatter(x='NU_NOTA_REDACAO', y='NU_NOTA_MT')","9bc768e9":"\ndf_counts = enemTrain.groupby(['NU_NOTA_MT', 'NU_IDADE']).size().reset_index(name='counts')\n\n# Desenhar Stripplot\nfig, ax = plt.subplots(figsize=(16,10), dpi= 80)    \nsns.stripplot(df_counts.NU_IDADE, df_counts.NU_NOTA_MT, size=df_counts.counts*2, ax=ax)\n\n\nplt.title('Rela\u00e7\u00e3o entre Idade e Nota em Matem\u00e1tica', fontsize=22)\nplt.show()","15a8c53a":"#Para vermos as colunas que possuem maior correla\u00e7\u00e3o\naux = enemTrain.copy()\naux2 = enemTrain.copy()\n\naux = aux.loc[:, enemTest.columns]\naux['NU_NOTA_MT'] = aux2.NU_NOTA_MT\n\nc = aux.corr()\nc.NU_NOTA_MT.sort_values()","bf051937":"#Separando para trabalhar s\u00f3 com o que importa - tem maior rela\u00e7\u00e3o\nnew_vector_training = [\n    'NU_NOTA_COMP1',\n    'NU_NOTA_COMP2',\n    'NU_NOTA_COMP4',\n    'NU_NOTA_COMP5',\n    'NU_NOTA_COMP3',\n    'NU_NOTA_REDACAO',\n    'NU_NOTA_LC',\n    'NU_NOTA_CH',\n    'NU_NOTA_CN',\n    'NU_NOTA_MT'\n]\n\nnew_vector_test = [\n    'NU_INSCRICAO',\n    'NU_NOTA_COMP1',\n    'NU_NOTA_COMP2',\n    'NU_NOTA_COMP4',\n    'NU_NOTA_COMP5',\n    'NU_NOTA_COMP3',\n    'NU_NOTA_REDACAO',\n    'NU_NOTA_LC',\n    'NU_NOTA_CH',\n    'NU_NOTA_CN'\n]\n\nenemTrain_data = enemTrain.copy()\nenemTrain_data = enemTrain_data.loc[:, new_vector_training]\nenemTrain_data.dropna(subset=['NU_NOTA_MT'], inplace=True)\nenemTrain_data.head()","fe7006dd":"y = enemTrain_data.NU_NOTA_MT\nX = enemTrain_data.drop(['NU_NOTA_MT'], axis=1)\n\nenem_validation_data = enemTest.copy()\nenem_validation_data_1 = enem_validation_data.loc[:, new_vector_test]\nenem_validation_data_2 = enem_validation_data.loc[:, new_vector_test]","c59c7b74":"enem_train_X, enem_validation_X, enem_train_y, enem_validation_y = train_test_split(X, y, random_state = 0)","1e13efe3":"model = XGBRegressor(n_estimators=200, learning_rate=0.1)\nmodel.fit(enem_train_X, enem_train_y, early_stopping_rounds=5, eval_set=[(enem_validation_X, enem_validation_y)], verbose=False)\n\n","006c9a93":"enem_validation_data_1.drop(['NU_INSCRICAO'], axis=1, inplace=True)","a4d9423b":"predicted_nota = model.predict(enem_validation_data_1)\nresult_df = pd.DataFrame({'NU_INSCRICAO': enem_validation_data_2['NU_INSCRICAO'], 'NU_NOTA_MT': predicted_nota})\n","1ff4468c":"result_df.head()","89a43c0b":"#Verifica se tem valores nulos no result\nresult_df.isnull().any().any()","c0481810":"result_df['NU_NOTA_MT'].describe()","4828ad28":"result_df_final = result_df.loc[: , ['NU_INSCRICAO', 'NU_NOTA_MT']]\nresult_df.to_csv('answer.csv', index=False)\n","06ed36e4":"<h1>Codenation ENEM<\/h1>\n<h2>Descubra as melhores notas de matem\u00e1tica do ENEM 2016<\/h2>\n\nModelo para prever a nota da prova de matem\u00e1tica de quem participou do ENEM 2016.\n\nMuitas universidades brasileiras utilizam o ENEM para selecionar seus futuros alunos e alunas. Isto \u00e9 feito com uma m\u00e9dia ponderada das notas das provas de matem\u00e1tica, ci\u00eancias da natureza, linguagens e c\u00f3digos, ci\u00eancias humanas e reda\u00e7\u00e3o.\n\nFeito por Alessandra Faria Abreu - ouvindo uma playlist de musicas dos anos 2000 durante a aula de banco 2","aa4b9fad":"<\/h2>An\u00e1lise da base sobre o atributo a ser previsto NU_NOTA_MT <\/h2>","8949d460":"<h3>Analisando a Base de Dados<\/h3>","488dda50":"<h2>Trabalhando a Base<\/h2>","bf0a0885":"<h1>Prevendo a Nota de Matem\u00e1tica<\/h1>"}}