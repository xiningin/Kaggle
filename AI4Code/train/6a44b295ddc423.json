{"cell_type":{"d4fc0d6d":"code","962af9ea":"code","f1980161":"code","43234f25":"code","7d358d31":"code","f92b63e4":"code","06e81d53":"code","6a270000":"code","fc951c58":"code","d8ae43f9":"code","d3039e54":"code","e406193a":"code","c82be0ff":"code","9169bd1c":"code","0e22b2dd":"code","49463301":"code","658acd21":"code","590a4de7":"code","7c030971":"code","24c9622d":"code","10a7e422":"code","0996f8ec":"code","4ab5651d":"code","51cf5613":"code","3bd91d13":"code","bc1582d9":"code","7a02ada6":"code","5c6632e2":"code","8885f2f7":"code","d7b53ae6":"code","d61d4850":"code","e863032c":"code","a6e60c64":"code","0de568a4":"code","052061db":"code","00fe613a":"code","4912884a":"code","721698e9":"code","6e367f14":"code","1d103448":"code","b0007b1b":"markdown","50b8eab0":"markdown","bb8428f3":"markdown","e024fce7":"markdown","6e71c769":"markdown","1f29014d":"markdown","fe468ca5":"markdown","11033994":"markdown","3141e443":"markdown","050aa235":"markdown","9d331bc9":"markdown","48eb744e":"markdown","ea0ce1d0":"markdown","99711ea4":"markdown","b26c18b9":"markdown","09c96071":"markdown","df33e7d1":"markdown","7e1094ba":"markdown","837dc49e":"markdown","e53a3033":"markdown","385182ec":"markdown","ea40418e":"markdown","dd4dc2aa":"markdown","90b402d2":"markdown","7c21aa97":"markdown","7637c96f":"markdown","c5bf1f0a":"markdown","c99e7cd4":"markdown"},"source":{"d4fc0d6d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","962af9ea":"import os\nos.getcwd()\nprint (os.listdir('\/kaggle\/input'))\n#print (os.scandir('\/kaggle\/input'))\nsubdirs, filenames = os.walk(\"\/kaggle\/input\/\")\nprint(subdirs,filenames)","f1980161":"data_path = '\/kaggle\/input\/titanic\/'\ntrain_df = pd.read_csv(data_path+'train.csv')\ntest_df = pd.read_csv(data_path+'test.csv')","43234f25":"combined_df = pd.concat([train_df,test_df])\n\ntrain_df.name = 'Training Dataset'\ntest_df.name = 'Test Dataset'\ncombined_df.name = 'Combined Dataset'","7d358d31":"train_df.info()\ntrain_df.describe()","f92b63e4":"test_df.describe()\ntest_df.info()","06e81d53":"def missing_columns(df):    \n    for col in df.columns.tolist():          \n        print('{} column missing values: {}'.format(col, df[col].isnull().sum()))\n    print('\\n')\n    \nfor df in [train_df,test_df]:\n    print('{}'.format(df.name))\n    missing_columns(df)","6a270000":"train_df.head()","fc951c58":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","d8ae43f9":"#g1 = sns.catplot(x=\"Sex\", y=\"Survived\", hue=\"Pclass\", kind=\"bar\", data=train_df)\n\ng = sns.catplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=train_df,\n                height=6, kind=\"bar\", palette=\"muted\")\ng.despine(left=True)\ng.set_ylabels(\"Survival probability\")","d3039e54":"g = sns.catplot(x=\"Pclass\", y='Survived', col='Embarked', data=train_df,\n                height=6, kind=\"bar\", palette=\"muted\")\ng.despine(left=True)\ng.set_ylabels(\"Survival Rate\")","e406193a":"plt.figure(figsize=(8,6))\ng = sns.swarmplot(data=train_df,y='Fare',x='Survived', hue='Sex')","c82be0ff":"# Let's bin the age variable for some visual analysis\n\nage_labels = ['Kids','9 to 17','18 to 35', '36 to 55', '55+']\nage_bins = [0,8,17,35,55,100]\ntrain_df['Age_group'] = pd.cut(train_df['Age'],bins=age_bins,labels=age_labels,include_lowest=True)\ntest_df['Age_group'] = pd.cut(test_df['Age'],bins=age_bins,labels=age_labels)","9169bd1c":"plt.figure(figsize=(6,2))\nsns.countplot(y='Sex',data=train_df)\nplt.ylabel(\"Gender\")\nplt.xlabel(\"Count\")\n#sns.catplot(x='Sex',y='Survived',data=train_df, kind='bar')","0e22b2dd":"plt.figure(figsize=(15,6))\nsns.catplot(x='Age_group',col='Sex',kind='count',color='g',data=train_df)","49463301":"sns.catplot(x='Age_group',y='Survived',kind='bar',data=train_df,color='b')","658acd21":"g2 = sns.catplot(x='Age_group',y='Survived',hue='Sex',data=train_df, kind='bar',aspect=2, height=6)\ng2.set_ylabels('Survival Rate')\ng2.set_xlabels('Age Groups')\ng2.despine(left=True)","590a4de7":"## Fill NaN age values with the median within the respective class and gender for training data\nmask_m1 = (train_df.Sex == \"male\") & (train_df.Pclass == 1)\nmask_m2 = (train_df.Sex == \"male\") & (train_df.Pclass == 2)\nmask_m3 = (train_df.Sex == \"male\") & (train_df.Pclass == 3)\n\nmask_f1 = (train_df.Sex == \"female\") & (train_df.Pclass == 1)\nmask_f2 = (train_df.Sex == \"female\") & (train_df.Pclass == 2)\nmask_f3 = (train_df.Sex == \"female\") & (train_df.Pclass == 3)\n\n# Median age of males in different passenger classes - we will be using the same in both train and test df\n# m_age_class1_male = train_df.query('Sex == \"male\" and Pclass == 1').Age.dropna().median()\nm_age_class1_male = combined_df.loc[(combined_df.Sex == \"male\") & (combined_df.Pclass == 1),'Age'].dropna().median()\nm_age_class2_male = combined_df.loc[(combined_df.Sex == \"male\") & (combined_df.Pclass == 2),'Age'].dropna().median()\nm_age_class3_male = combined_df.loc[(combined_df.Sex == \"male\") & (combined_df.Pclass == 3),'Age'].dropna().median()\n\n# Median age of females in different passenger classes\nm_age_class1_female = combined_df.loc[(combined_df.Sex == \"female\") & (combined_df.Pclass == 1),'Age'].dropna().median()\nm_age_class2_female = combined_df.loc[(combined_df.Sex == \"female\") & (combined_df.Pclass == 2),'Age'].dropna().median()\nm_age_class3_female = combined_df.loc[(combined_df.Sex == \"female\") & (combined_df.Pclass == 3),'Age'].dropna().median()\n\n\n# fill NaN with the above values\n# print(train_df.loc[(train_df.Sex == \"male\") & (train_df.Pclass == 1),'Age'])\n\ntrain_df.loc[mask_m1,'Age'] = train_df.loc[mask_m1,'Age'].fillna(m_age_class1_male)\ntrain_df.loc[mask_m2,'Age'] = train_df.loc[mask_m2,'Age'].fillna(m_age_class2_male)\ntrain_df.loc[mask_m3,'Age'] = train_df.loc[mask_m3,'Age'].fillna(m_age_class3_male)\n\ntrain_df.loc[mask_f1,'Age'] = train_df.loc[mask_f1,'Age'].fillna(m_age_class1_female)\ntrain_df.loc[mask_f2,'Age'] = train_df.loc[mask_f2,'Age'].fillna(m_age_class2_female)\ntrain_df.loc[mask_f3,'Age'] = train_df.loc[mask_f3,'Age'].fillna(m_age_class3_female)\n\n# train_df['Age'].fillna(train_df['Age'].dropna().median(), inplace=True)\n# test_df['Age'].fillna(test_df['Age'].dropna().median(), inplace=True)","7c030971":"## Fill NaN age values with the median within the respective class and gender for test datset\nmask_m1 = (test_df.Sex == \"male\") & (test_df.Pclass == 1)\nmask_m2 = (test_df.Sex == \"male\") & (test_df.Pclass == 2)\nmask_m3 = (test_df.Sex == \"male\") & (test_df.Pclass == 3)\n\nmask_f1 = (test_df.Sex == \"female\") & (test_df.Pclass == 1)\nmask_f2 = (test_df.Sex == \"female\") & (test_df.Pclass == 2)\nmask_f3 = (test_df.Sex == \"female\") & (test_df.Pclass == 3)\n\n# fill NaN with the above values\n# print(train_df.loc[(train_df.Sex == \"male\") & (train_df.Pclass == 1),'Age'])\n\ntest_df.loc[mask_m1,'Age'] = test_df.loc[mask_m1,'Age'].fillna(m_age_class1_male)\ntest_df.loc[mask_m2,'Age'] = test_df.loc[mask_m2,'Age'].fillna(m_age_class2_male)\ntest_df.loc[mask_m3,'Age'] = test_df.loc[mask_m3,'Age'].fillna(m_age_class3_male)\n\ntest_df.loc[mask_f1,'Age'] = test_df.loc[mask_f1,'Age'].fillna(m_age_class1_female)\ntest_df.loc[mask_f2,'Age'] = test_df.loc[mask_f2,'Age'].fillna(m_age_class2_female)\ntest_df.loc[mask_f3,'Age'] = test_df.loc[mask_f3,'Age'].fillna(m_age_class3_female)","24c9622d":"train_df[train_df.Embarked.isna()]","10a7e422":"sns.catplot(data=combined_df[combined_df.Pclass == 1], x='Embarked',kind='count',hue='Sex')","0996f8ec":"# Filling the missing values in Embarked with C\ntrain_df['Embarked'] = train_df['Embarked'].fillna('C')","4ab5651d":"median_class3_fare = combined_df.loc[(combined_df.Pclass == 3),'Fare'].dropna().median()\ntest_df.Fare.fillna(median_class3_fare,inplace=True)\n\n#print(median_class3_fare)\n#print (sum(test_df.Fare.isna()))","51cf5613":"train_df.head()","3bd91d13":"# Add new categorical variables for Siblings\/Spouse and Parents\/Children\n# Some of these variables may not be used in our final model\ntrain_df['SibSp_cat'] = (train_df['SibSp'] > 0) * 1\ntrain_df['Parch_cat'] = (train_df['Parch'] > 0) * 1\ntrain_df['Gender'] = (train_df['Sex'] == 'female') * 1 # Female = 1 and male = 0\ntrain_df['Class 1'] = (train_df['Pclass'] == 1) * 1\ntrain_df['Class 2'] = (train_df['Pclass'] == 2) * 1\ntrain_df['Class 3'] = (train_df['Pclass'] == 3) * 1\ntrain_df['IsAlone'] = ((train_df['SibSp'] == 0) & (train_df['Parch'] == 0)) * 1\ntrain_df['High_Fare'] = (train_df['Fare'] >= 200.0) * 1\ntrain_df['Family_Members'] = train_df.SibSp + train_df.Parch","bc1582d9":"# Add new categorical variables for Siblings\/Spouse and Parents\/Children in test dataset\ntest_df['SibSp_cat'] = (test_df['SibSp'] > 0) * 1\ntest_df['Parch_cat'] = (test_df['Parch'] > 0) * 1\ntest_df['Gender'] = (test_df['Sex'] == 'female') * 1\ntest_df['Class 1'] = (test_df['Pclass'] == 1) * 1\ntest_df['Class 2'] = (test_df['Pclass'] == 2) * 1\ntest_df['Class 3'] = (test_df['Pclass'] == 3) * 1\ntest_df['IsAlone'] = ((test_df['SibSp'] == 0) & (test_df['Parch'] == 0)) * 1\ntest_df['High_Fare'] = (test_df['Fare'] >= 200.0) * 1\ntest_df['Family_Members'] = test_df.SibSp + test_df.Parch","7a02ada6":"g4 = sns.catplot(x='Age_group',hue='IsAlone',data=train_df, kind='count',aspect=1.5)\ng4.set_ylabels('Count')\ng4.set_xlabels('Age Groups')\ng4.despine(left=True)","5c6632e2":"g3 = sns.catplot(x='Age_group',y='Survived',hue='IsAlone',data=train_df, kind='bar',aspect=1.5)\ng3.set_ylabels('Survival Rate')\ng3.set_xlabels('Age Groups')\ng3.despine(left=True)","8885f2f7":"sns.catplot(data=train_df,x='Family_Members',y='Survived',kind='bar')","d7b53ae6":"sns.swarmplot(data=train_df,x='Family_Members',y='Fare',hue='Pclass')","d61d4850":"#Target\ny_train = train_df['Survived']\n\n# Build attribute dataset\n#features = ['Gender','Age','Class 1','Class 2','Class 3','SibSp','Parch','Embarked','Fare']\nfeatures = ['Gender','Age','Class 1','Class 2','Class 3','Family_Members','Embarked','Fare']\n\nX_train = train_df[features]\nX_test = test_df[features]","e863032c":"X_train_1hot = pd.get_dummies(X_train)\nX_train_1hot","a6e60c64":"X_test_1hot = pd.get_dummies(X_test)\nX_test_1hot","0de568a4":"from sklearn.ensemble import RandomForestClassifier\n\nbase_model = RandomForestClassifier(random_state=42,n_estimators=100,max_depth=5)\n\n# Fit the dataset using the RF model\nfit = base_model.fit(X_train_1hot,y_train)","052061db":"fit.score(X_train_1hot,y_train)","00fe613a":"from sklearn.model_selection import RandomizedSearchCV\nimport pprint\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n\n# Maximum number of levels in tree\nmax_depth = [5,6,7,8,9,10]\nmax_depth.append(None)\n\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\n\npp = pprint.PrettyPrinter(indent=4)\npp.pprint(random_grid)","4912884a":"\n# Use the random grid to search for best hyperparameters\n# First create the base model to tune\nrf = RandomForestClassifier()\n# Random search of parameters, using 5 fold cross validation, \n# search across 100 different combinations, and use all available cores\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 200, cv = 4, verbose=2, random_state=42, n_jobs = -1)\n# Fit the random search model\nrf_random.fit(X_train_1hot, y_train)\n","721698e9":"rf_random.best_params_","6e367f14":"rf_best = rf_random.best_estimator_\n\nbest_fit = rf_best.fit(X_train_1hot, y_train)\nbest_fit.score(X_train_1hot,y_train)","1d103448":"predictions = base_model.predict(X_test_1hot)\n\noutput = pd.DataFrame({'PassengerId': test_df.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","b0007b1b":"#### We can observe from above that the survival probabilities are lower for males compared to females. Also, it goes down as you move from 1st class to 3rd class. So, it is amply clear that both gender and class are important attributes for survival here.\n\nLet's explore other relationships","50b8eab0":"#### Let's do 1 hot encoding on some of the categorical variables that we haven't already done","bb8428f3":"#### This shows the survival rate is high for young kids but sort of goes down as the age goes up. The next graph will show if this is true for both genders","e024fce7":"### Save your output and submit it!","6e71c769":"#### Understandably, there aren't very many kids and teenagers who are alone on the ship. Above 18 years of age, there are more \"alone\" folks than are people with family onboard. Let's see if this has any bearing on survival rates","1f29014d":"#### In several iterations, we have observed that the score on the training dataset has not gone beyong 84%. Since there is not enough datapoints, it appears we can't afford a training \/ validation \/ test split. But let's see if we can optimize the model to find the best model parameters using RandomizedSearchCV","fe468ca5":"### Did people who embarked from different ports have a different chance of survival based on which class they were in?","11033994":"There is one NaN for Fare in test_df - let's fix it as well","3141e443":"## Conclusion\n\n#### For the above random model, the prediction for the test dataset came out to be 77% compared to the 92% score on the training data set and 78% score from the base model. Classic case of overfitting. The HyperParameter Tuning didn't work all that well for this problem.","050aa235":"### Let's do some feature engineering now","9d331bc9":"## Relationship: Passenger Class, Gender and Survival Rates","48eb744e":"### Wow, that's a revelation. So, the survival rates are abysmal for males aged 9 and above while the same for females are relatively higher across age groups.\n\n#### This tells us that in addition to gender and passenger class, age is also an important attribute. We had earlier identified that Ticket Fare and Port of Embarkation have weak relationships to survival rates.","ea0ce1d0":"### Looks like we don't have age data for 177 people, and Cabin detail is not available for most of the data.\n\nSince cabin data is sparse, we will ignore it in our analysis. For age, we will try to do data imputation","99711ea4":"Load the training data into a dataframe","b26c18b9":"## Age vs Survival Rate by Gender","09c96071":"### Or did people who paid higher fare (higher fare might mean better class or deck??) survive more often?","df33e7d1":"There are two NaN values for Embarked - we will fix it by finding out what the Pclass and gender are for these two datapoints","7e1094ba":"### Before we proceed further, let's fill in the missing values for age\n\nWe are going to do some data imputation for Age variable since a lot of them are NaN and Age is an important attribute as we saw in above graphs","837dc49e":"Checking the path and the files","e53a3033":"### If you noticed, we added a new derived field \"IsAlone\" to distinguish people with and without family onboard the ship. Before we finalize the feature set, let's check if being alone makes any difference to the survival rates.","385182ec":"#### The swarm plot above doesn't seem to indicate ticket fare is an important variable but the combination of gender and ticket fare probably is!!","ea40418e":"### Age distribution of males and females","dd4dc2aa":"### Let's bin the age variable for some visual analysis\n","90b402d2":"### Let's do some exploratory data analysis","7c21aa97":"There is not a strong relationship here but you can tell that people that embarked from C are relatively slightly better off if they happen to be in Class 1 while people in Class 2 and Class 3 are better off had they embarked from Q","7637c96f":"#### There you go. If you are a kid under 9 with no family member onboard, you've a sure shot chance of surviving - maybe there's no hassle of having to stick with family :) but note that there were probably only 1 - 3 such kids onboard, so there is not a lot of data to back it up.\n\nBut in general, we see a trend where people with at least one family member onboard have higher survival rates than \"loners\".","c5bf1f0a":"Find out the missing values in each of the columns in training and test dataset","c99e7cd4":"Since the two passengers are in first Class, we will assume that they boarded from port C and fill the NaN values"}}