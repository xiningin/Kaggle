{"cell_type":{"08060915":"code","a8b1cb4b":"code","1f23a9d0":"code","803ddb56":"code","ed0aacb6":"code","6c77dbc8":"code","85304eb4":"code","ff8c732a":"markdown","3e62815e":"markdown","6f2ed4e7":"markdown","d8d86059":"markdown"},"source":{"08060915":"vqgan_clip_path = '\/kaggle\/working\/VQGAN-CLIP\/'\nnull = '\/dev\/null'\n!pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https:\/\/download.pytorch.org\/whl\/torch_stable.html > {null}\n!pip3 install ftfy regex tqdm omegaconf pytorch-lightning IPython kornia imageio imageio-ffmpeg einops torch_optimizer > {null}\n!pip3 install -U torchtext==0.6.0 > {null}","a8b1cb4b":"!git clone https:\/\/github.com\/nerdyrodent\/VQGAN-CLIP.git > {null}\n%cd {vqgan_clip_path}\n!git clone https:\/\/github.com\/openai\/CLIP > {null}\n!git clone https:\/\/github.com\/CompVis\/taming-transformers > {null}\n!mkdir checkpoints\n!curl -L -o checkpoints\/vqgan_imagenet_f16_16384.yaml -C - 'https:\/\/heibox.uni-heidelberg.de\/d\/a7530b09fed84f80a887\/files\/?p=%2Fconfigs%2Fmodel.yaml&dl=1' #ImageNet 16384\n!curl -L -o checkpoints\/vqgan_imagenet_f16_16384.ckpt -C - 'https:\/\/heibox.uni-heidelberg.de\/d\/a7530b09fed84f80a887\/files\/?p=%2Fckpts%2Flast.ckpt&dl=1' #ImageNet 16384\n!ls {vqgan_clip_path}","1f23a9d0":"def text_to_image(text: str, output_file_name: str):\n    '''\n    Text must be enclosed in quotation marks.\n    ex) (wrong) -> text = 'village'\n    ex) (right) -> text = '\\'village\\''\n    '''\n    !python3 {vqgan_clip_path}generate.py -p {text} -o {output_file_name} > {null}","803ddb56":"from IPython.display import Markdown\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg","ed0aacb6":"text1 = '\\' Magnificent Skyrim village \\''\noutput_file_name1 = 'output1.png'\n\n# Convert text to image\ntext_to_image(text1, output_file_name1)\n\n# Show image\nplt.imshow(mpimg.imread(vqgan_clip_path + output_file_name1))\nplt.axis('off')\nplt.show()\n\n# Download image link\nMarkdown(\"<a href='%s'> Download %s <\/a>\" % (vqgan_clip_path[16:] + output_file_name1, output_file_name1))","6c77dbc8":"text2 = '\\' Fresh and beautiful city of Irvine \\''\noutput_file_name2 = 'output2.png'\n\n# Convert text to image\ntext_to_image(text2, output_file_name2)\n\n# Show image\nplt.imshow(mpimg.imread(vqgan_clip_path + output_file_name2))\nplt.axis('off')\nplt.show()\n\n# Download image link\nMarkdown(\"<a href='%s'> Download %s <\/a>\" % (vqgan_clip_path[16:] + output_file_name2, output_file_name2))","85304eb4":"text3 = '\\' Dreamy and mysterious fantasy world \\''\noutput_file_name3 = 'output3.png'\n\n# Convert text to image\ntext_to_image(text3, output_file_name3)\n\n# Show image\nplt.imshow(mpimg.imread(vqgan_clip_path + output_file_name3))\nplt.axis('off')\nplt.show()\n\n# Download image link\nMarkdown(\"<a href='%s'> Download %s <\/a>\" % (vqgan_clip_path[16:] + output_file_name3, output_file_name3))","ff8c732a":"# 3. Examples\n\nEach conversion takes approximately 4 minutes and 30 seconds.","3e62815e":"# 2. Make function","6f2ed4e7":"# 0. VQGAN-CLIP usage\n\nReference: https:\/\/github.com\/nerdyrodent\/VQGAN-CLIP\n\n**Note: To keep the download link, you must use commit to save version.**","d8d86059":"# 1. Configuration"}}