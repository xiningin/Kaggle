{"cell_type":{"39fcec54":"code","af6f8cfc":"code","48e9b70a":"code","409cd45f":"code","0a1664bb":"code","4402dbb2":"code","080ef4c5":"code","5bd07db9":"code","cb004cda":"code","da473e71":"code","ccf0e2b5":"code","d2a23e12":"code","6da3fcdb":"code","06abf776":"code","f416533d":"code","ca0efd9a":"code","141ec29d":"code","46006d29":"code","d5320ae8":"markdown","71303919":"markdown","6408190c":"markdown","8845ecd1":"markdown","3e4c7526":"markdown","510ad17b":"markdown","79d5432d":"markdown","214e0c12":"markdown"},"source":{"39fcec54":"import tensorflow as tf\nfrom tensorflow.keras import layers\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport time\nfrom glob import glob\nimport cv2\n\nmain_path = \"..\/input\/cats-faces-64x64-for-generative-models\/cats\"\nimage_paths = glob(main_path+\"\/*\")","af6f8cfc":"images = []\nfor image_path in image_paths:\n    try:\n        img = cv2.imread(image_path)\n        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n        images.append(img)\n    except:\n        print(\"Something went wrong with this file:\\n{}\".format(image_path))\n    \nimages = np.array(images)\nimages = (images-127.5) \/ 127.5\nprint(images.shape)\n\nBATCH_SIZE = 256\ntraining_images = tf.data.Dataset.from_tensor_slices(images).shuffle(60000).batch(BATCH_SIZE)","48e9b70a":"fig = plt.figure(figsize=(6,6))\n\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    plt.imshow(images[i*213])\n    plt.axis(\"off\")\n\nplt.show()","409cd45f":"WEIGHT_INIT = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.2)\ndef make_generator():\n    \"\"\"\n    This function returns a generator model\n    \"\"\"\n    model = tf.keras.Sequential()\n    \n    # Noise with shape 100, to 8,8,256 image\n    model.add(layers.Dense(8*8*256,use_bias=False,input_shape=(100,)))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n    model.add(layers.Reshape((8,8,256)))\n    \n    assert model.output_shape == (None,8,8,256)\n    \n    model.add(layers.Conv2DTranspose(128,(5,5),strides=(1,1),use_bias=False,padding=\"same\",kernel_initializer=WEIGHT_INIT))\n    assert model.output_shape == (None,8,8,128)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n    \n    model.add(layers.Conv2DTranspose(128,(5,5),strides=(2,2),use_bias=False,padding=\"same\",kernel_initializer=WEIGHT_INIT))\n    assert model.output_shape == (None,16,16,128)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n    \n    model.add(layers.Conv2DTranspose(64,(5,5),strides=(2,2),use_bias=False,padding=\"same\",kernel_initializer=WEIGHT_INIT))\n    assert model.output_shape == (None,32,32,64)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n    \n    model.add(layers.Conv2DTranspose(3,(5,5),strides=(2,2),use_bias=False,padding=\"same\",kernel_initializer=WEIGHT_INIT))\n    assert model.output_shape == (None,64,64,3)\n    return model\n    ","0a1664bb":"generator = make_generator()","4402dbb2":"# we'll use cross entropy\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n\ndef generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output),fake_output)\n\n# we'll use adam\ngenerator_optimizer = tf.keras.optimizers.Adam(1e-4)\n","080ef4c5":"def make_discriminator():\n    \"\"\"\n    This function returns discriminator model\n    \"\"\"\n    \n    model = tf.keras.models.Sequential()\n    # Convolutional Block 1 \n    model.add(layers.Conv2D(64,(5,5),strides=(2,2),padding=\"same\",input_shape=(64,64,3)))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n    \n    # Convolutional Block 2\n    model.add(layers.Conv2D(128,(5,5),strides=(2,2),padding=\"same\"))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n    \n    # Fully Connected\n    model.add(layers.Flatten())\n    model.add(layers.Dense(1))\n    \n    return model","5bd07db9":"discriminator = make_discriminator()","cb004cda":"def discriminator_loss(real_output,fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output),real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output),fake_output)\n    \n    total_loss = real_loss + fake_loss\n    return total_loss","da473e71":"discriminator_optimizer = tf.keras.optimizers.Adam(lr=1e-4)","ccf0e2b5":"EPOCHS = 200\nnoise_dim = 100\n\n@tf.function\ndef train_step(images):\n    noise = tf.random.normal([BATCH_SIZE,noise_dim])\n    \n    with tf.GradientTape() as gen_tape,tf.GradientTape() as disc_tape:\n        generated_images = generator(noise,training=True)\n        \n        real_output = discriminator(images,training=True)\n        fake_output = discriminator(generated_images,training=True)\n        \n        gen_loss = generator_loss(fake_output)\n        disc_loss = discriminator_loss(real_output,fake_output)\n        \n    gradients_of_generator = gen_tape.gradient(gen_loss,generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss,discriminator.trainable_variables)\n    \n    generator_optimizer.apply_gradients(zip(gradients_of_generator,generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator,discriminator.trainable_variables))\n    ","d2a23e12":"def train(dataset,epochs):\n    \n    for epoch in range(epochs):\n        start = time.time()\n        \n        for image_batch in dataset:\n            train_step(image_batch)\n        \n        print(\"Epoch {}\/{} is finished. Process time: {}\".format(epoch+1,epochs,round(time.time()-start,2)))\n        print(\"==========================================================\")","6da3fcdb":"train(training_images,EPOCHS)","06abf776":"noise = tf.random.normal([16,100])\ngenerated_images = generator(noise,training=False)\n\nfig = plt.figure(figsize=(6,6))\nfor i in range(16):\n    plt.subplot(4,4,i+1)\n    plt.imshow((generated_images[i,:,:,:]*127.5+127.5))\n    plt.axis(\"off\")\n    \nplt.show()","f416533d":"noise = tf.random.normal([16,100])","ca0efd9a":"generated_images = generator(noise,training=False)\n\n\nfor i in range(16):\n    test_image = np.array(generated_images[i,:,:,:]*127.5+127.5).astype(np.uint8)\n    test_image = cv2.cvtColor(test_image,cv2.COLOR_RGB2BGR)\n    cv2.imwrite(os.path.join(\".\/epoch400_images\",f\"test{i}.jpg\"),test_image)","141ec29d":"import os\nos.mkdir(\".\/epoch400_images\")\n","46006d29":"os.listdir(\".\/epoch200_images\")","d5320ae8":"# Generating Some Cat Faces","71303919":"# Generator Model","6408190c":"# Training Model","8845ecd1":"# Loading Data","3e4c7526":"# Discriminator Model\n","510ad17b":"* There are 15747 images in the dataset.","79d5432d":"# Introduction\nHello people, welcome to this kernel. In this kernel I am going to generate cat images using Deep Convolutional Generative Adverserive Networks. Before starting, let's take a look at the content of the kernel\n\n# Kernel Content\n1. Importing Necessary Libraries\n1. Loading Data\n1. Generator Model \n1. Discriminator Model\n1. Training Model\n1. Generating Some Cat Faces\n1. Conclusion\n","214e0c12":"# Importing Necessary Libraries"}}