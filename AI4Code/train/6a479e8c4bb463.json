{"cell_type":{"78db60bf":"code","6477e373":"code","5f5cdebc":"code","63933926":"code","39f9cbc1":"code","916a8e83":"code","3134cce0":"code","f9c4345e":"code","af0e0b82":"markdown","0c5691e7":"markdown","4539b8c5":"markdown","72d7d54c":"markdown","180c88bc":"markdown","98a1c265":"markdown","f5f1b6f9":"markdown","f2f2790e":"markdown","2f235def":"markdown"},"source":{"78db60bf":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","6477e373":"dataset = pd.read_csv('..\/input\/restaurant-reviews\/Restaurant_Reviews.tsv',delimiter = '\\t', quoting = 3)","5f5cdebc":"import re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\ncorpus = []\nfor i in range(0, 1000):\n    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n    review = review.lower()\n    review = review.split()\n    ps = PorterStemmer()\n    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n    review = ' '.join(review)\n    corpus.append(review)","63933926":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features = 1500)\nX = cv.fit_transform(corpus).toarray()\ny = dataset.iloc[:, 1].values","39f9cbc1":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)","916a8e83":"from sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(X_train, y_train)","3134cce0":"y_pred = classifier.predict(X_test)","f9c4345e":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)","af0e0b82":"Predicting the Test set results","0c5691e7":" Natural Language Processing","4539b8c5":"Cleaning the texts","72d7d54c":"Importing the libraries","180c88bc":"Creating the Bag of Words model","98a1c265":"Importing the dataset","f5f1b6f9":"Training the Naive Bayes model on the Training set","f2f2790e":"Making the Confusion Matrix","2f235def":"Splitting the dataset into the Training set and Test set"}}