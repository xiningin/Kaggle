{"cell_type":{"e3091ae3":"code","da5fb8b9":"code","47ec7ede":"code","21580d64":"code","b7907afe":"code","2103998c":"code","ac2506c0":"code","84f43ed3":"code","c38e3b87":"code","0b4768a0":"code","da9e42ff":"code","aafe164e":"markdown","a9ed93ad":"markdown","31ca12a8":"markdown","07acad0d":"markdown","0f216040":"markdown","745bccd6":"markdown","0761d435":"markdown"},"source":{"e3091ae3":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, LSTM, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.metrics import MeanSquaredLogarithmicError\nfrom sklearn.model_selection import train_test_split","da5fb8b9":"df = pd.read_csv('..\/input\/daily-sun-spot-data-1818-to-2019\/sunspot_data.csv')\ndf.head()","47ec7ede":"missing_vals = df.isnull().sum()\nmissing_vals","21580d64":"df.describe()","b7907afe":"corr_df = df.corr()\ncorr_df","2103998c":"plt.figure(figsize=(17,10))\nsns.heatmap(corr_df, cmap='coolwarm')","ac2506c0":"df_train = df[df['Year']<2000]\ndf_test = df[df['Year']>=2000]\n\nspots_train = df_train['Number of Sunspots'].tolist()\nspots_test = df_test['Number of Sunspots'].tolist()\n\nprint(\"Training set has {} observations.\".format(len(spots_train)))\nprint(\"Test set has {} observations.\".format(len(spots_test)))","84f43ed3":"def create_sequence(seq, obs):\n    x = []\n    y = []\n    for i in range(len(obs)-size_sample):\n        #print(i)\n        window = obs[i:(i+size_sample)]\n        after_window = obs[i+size_sample]\n        window = [[x] for x in window]\n        #print(\"{} - {}\".format(window,after_window))\n        x.append(window)\n        y.append(after_window)\n        \n    return np.array(x),np.array(y)\n    \n    \nsize_sample = 15\nx_train,y_train = create_sequence(size_sample,spots_train)\nx_test,y_test = create_sequence(size_sample,spots_test)\n\nprint(\"Shape of training set: {}\".format(x_train.shape))\nprint(\"Shape of test set: {}\".format(x_test.shape))","c38e3b87":"x_train[0:10]","0b4768a0":"model = Sequential()\nmodel.add(LSTM(128, dropout=0.0, recurrent_dropout=0.0, input_shape = (None,1)))\nmodel.add(Dense(64, activation = 'relu'))\nmodel.add(Dense(32, activation = 'relu'))\nmodel.add(Dense(1, activation = 'softmax'))\n\n\nmodel.compile(optimizer = 'adam', loss = tf.keras.losses.MeanSquaredLogarithmicError())\nearly_stopping = EarlyStopping(monitor='val_loss', min_delta = 1e-3,\n                               patience = 5, verbose = 1, \n                               mode='auto', restore_best_weights=True)\n\nmodel.fit(x_train, y_train, validation_data = [x_test, y_test],\n         callbacks = [early_stopping],\n         epochs = 500, \n         verbose = 2)","da9e42ff":"from sklearn.metrics import mean_squared_log_error, mean_squared_error\n\ny_pred = model.predict(x_test)\nscore = np.sqrt(mean_squared_log_error(y_pred, y_test))\nmean_score = np.sqrt(mean_squared_error(y_pred, y_test))\nprint('The RMSLE value of {} is obtained '.format(score))\nprint('The RMSE value of {} is obtained '.format(mean_score))","aafe164e":"# Loading Dataset","a9ed93ad":"# Model Development","31ca12a8":"**In terms of accuracy RMSLE values are better than RMSE so our novice model is somewhat accurate**","07acad0d":"# Simple Feature Engineering","0f216040":"# Creating Sequences for Time Series Forecast","745bccd6":"# Error Estimation","0761d435":"# LSTM Based Model for predicting sunspots from 1818 to present year\nHope you like my work, This is my first implementation of RNN's so do upvote my notebook!!"}}