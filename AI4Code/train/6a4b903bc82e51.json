{"cell_type":{"2e19e459":"code","04033415":"code","6db34dd5":"code","c5ceba69":"code","5e244fea":"code","4df1e269":"code","96b997cd":"code","e55fb33c":"code","4e4818e3":"code","8086933d":"code","9593b15e":"code","43d4be0f":"code","1c760211":"code","419d05fa":"code","2aa23a24":"code","df2e2a73":"code","9f5999fd":"code","7b6f1fea":"code","05a0f263":"code","dac3b293":"code","8f83553c":"code","fd7ead8d":"code","a356dcb9":"code","9205251b":"code","4009ff5e":"code","5a1f9fc2":"code","33f5fb94":"code","3387ebc4":"code","8cb3940e":"code","3398f5a6":"code","f633491e":"code","242bf918":"code","8b34ad4c":"markdown","2ba50618":"markdown","a76e63c2":"markdown","c9434286":"markdown","d5a46ad4":"markdown","3c34a7d7":"markdown","b25cf835":"markdown","61dba42c":"markdown","1210f74b":"markdown","2824bab2":"markdown"},"source":{"2e19e459":"# import lightbgm as lab (you just import as follows instead of this code)\nfrom optuna.integration import lightgbm as lgb","04033415":"# from tutorial\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6db34dd5":"train=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\ntrain.head()","c5ceba69":"test.head()","5e244fea":"numeric_features = train.select_dtypes(include=[np.number])\nnumeric_features.columns","4df1e269":"categorical_features = train.select_dtypes(include=[np.object])\ncategorical_features.columns","96b997cd":"train_test['SaleCondition'].unique()","e55fb33c":"from sklearn.preprocessing import LabelEncoder\ncols = ('MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n       'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual',\n       'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature',\n       'SaleType', 'SaleCondition')\n\ncols_defaults = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n        'YrSold', 'MoSold')\n# process columns, apply LabelEncoder to categorical features\nfor c in cols:\n    lbl = LabelEncoder() \n    lbl.fit(list(train[c].values)) \n    train[c] = lbl.transform(list(train[c].values))\n\n# shape        \nprint('Shape train: {}'.format(train.shape))","4e4818e3":"# process columns, apply LabelEncoder to categorical features\nfor c in cols:\n    lbl = LabelEncoder() \n    lbl.fit(list(test[c].values)) \n    test[c] = lbl.transform(list(test[c].values))\n\n# shape        \nprint('Shape test: {}'.format(test.shape))","8086933d":"train_test['SaleCondition'].unique()","9593b15e":"train_test=pd.concat([train,test],axis=0,sort=False)\ntrain_test.head()","43d4be0f":"train.isnull().sum() ","1c760211":"train_test.groupby('SaleCondition').count()['Id']","419d05fa":"train['SalePrice'].hist(bins = 40)","2aa23a24":"import matplotlib.pyplot as plt\nimport seaborn as sb\ncorrelation_train=train.corr()\nsb.set(font_scale=2)\nplt.figure(figsize=(50,50))\nax = sb.heatmap(correlation_train, annot=True,annot_kws={\"size\": 25},fmt='.1f', linewidths=.5)","df2e2a73":"correlation_train.columns","9f5999fd":"corr_dict=correlation_train['SalePrice'].sort_values(ascending=False).to_dict()\nunimportant_columns=[]\nfor key,value in corr_dict.items():\n    if  ((value>=-0.1) & (value<=0)) | (value==0.1):\n        unimportant_columns.append(key)\nunimportant_columns","7b6f1fea":"train2= train.drop(['BsmtFinSF2',\n 'Utilities',\n 'BsmtHalfBath',\n 'MiscVal',\n 'Id',\n 'LowQualFinSF',\n 'YrSold',\n 'SaleType',\n 'LotConfig',\n 'OverallCond',\n 'MSSubClass',\n 'BldgType',\n 'Heating'],axis=1)","05a0f263":"correlation_train2=train2.corr()\nsb.set(font_scale=2)\nplt.figure(figsize=(50,50))\nax = sb.heatmap(correlation_train2, annot=True,annot_kws={\"size\": 25},fmt='.1f',cmap='PiYG', linewidths=.5)","dac3b293":"train2.columns","8f83553c":"train3= train.loc[:,['MSZoning', 'LotFrontage', 'LotArea', 'Street', 'Alley', 'LotShape',\n       'LandContour', 'LandSlope', \n        #'Neighborhood',\n        'Condition1', 'Condition2',\n       'HouseStyle', 'OverallQual', 'YearBuilt', 'YearRemodAdd', 'RoofStyle',\n       'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea',\n       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n       'BsmtUnfSF', 'TotalBsmtSF', 'HeatingQC', 'CentralAir', 'Electrical',\n       #'1stFlrSF', \n        '2ndFlrSF', 'GrLivArea', 'BsmtFullBath', 'FullBath',\n       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n       #'TotRmsAbvGrd',\n       'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n       #'GarageYrBlt',\n       'GarageFinish', \n       #'GarageCars', \n       'GarageArea', 'GarageQual',\n       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', \n       #'PoolArea', \n        'PoolQC',\n       'Fence', 'MiscFeature', \n       #'MoSold', \n       'SaleCondition', 'SalePrice']]\n","fd7ead8d":"correlation_train3=train3.corr()\nsb.set(font_scale=2)\nplt.figure(figsize=(50,50))\nax = sb.heatmap(correlation_train3, annot=True,annot_kws={\"size\": 25},fmt='.1f',cmap='PiYG', linewidths=.5)","a356dcb9":"corr_dict3=correlation_train3['SalePrice'].sort_values(ascending=False).to_dict()\nunimportant_columns_train3=[]\nfor key,value in corr_dict3.items():\n    if  ((value>=-0.1) & (value<=0)) | (value==0.1):\n        unimportant_columns_train3.append(key)\nunimportant_columns_train3","9205251b":"import seaborn as sns\nfrom sklearn.linear_model import LinearRegression\n\n%matplotlib inline ","4009ff5e":"\nsns.set()\ncols = ['SalePrice', 'OverallQual', 'GrLivArea','EnclosedPorch','BsmtUnfSF']\nsns.pairplot(train3[cols], size = 2.5)\nplt.show()","5a1f9fc2":"test= test.loc[:,['MSZoning', 'LotFrontage', 'LotArea', 'Street', 'Alley', 'LotShape',\n       'LandContour', 'LandSlope', \n        #'Neighborhood',\n        'Condition1', 'Condition2',\n       'HouseStyle', 'OverallQual', 'YearBuilt', 'YearRemodAdd', 'RoofStyle',\n       'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea',\n       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n       'BsmtUnfSF', 'TotalBsmtSF', 'HeatingQC', 'CentralAir', 'Electrical',\n       #'1stFlrSF', \n        '2ndFlrSF', 'GrLivArea', 'BsmtFullBath', 'FullBath',\n       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n       #'TotRmsAbvGrd',\n       'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n       #'GarageYrBlt',\n       'GarageFinish', \n       #'GarageCars', \n       'GarageArea', 'GarageQual',\n       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', \n       #'PoolArea', \n        'PoolQC',\n       'Fence', 'MiscFeature', \n       #'MoSold', \n       'SaleCondition'\n                 ]]","33f5fb94":"len(test)","3387ebc4":"len(train3)","8cb3940e":"X_train = train3.drop([ 'SalePrice'], axis=1)\ny_train = np.log1p(train3['SalePrice'])","3398f5a6":"from sklearn import preprocessing\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\n\ny_preds = []\nmodels = []\noof_train = np.zeros((len(X_train),))\ncv = KFold(n_splits=5, shuffle=True, random_state=0)\n\n\nparams = {\n    'objective': 'regression',\n        'metric': 'rmse',\n        'verbosity': -1,\n        'boosting_type': 'gbdt',\n}\n\nfor fold_id, (train_index, valid_index) in enumerate(cv.split(X_train)):\n    X_tr = X_train.loc[train_index, :]\n    X_val = X_train.loc[valid_index, :]\n    y_tr = y_train[train_index]\n    y_val = y_train[valid_index]\n\n    lgb_train = lgb.Dataset(X_tr,\n                            y_tr,\n                            #categorical_feature=categorical_cols\n                           )\n\n    lgb_eval = lgb.Dataset(X_val,\n                           y_val,\n                           reference=lgb_train,\n                           #categorical_feature=categorical_cols\n                          )\n\n    model = lgb.train(params,\n                      lgb_train,\n                      valid_sets=[lgb_train, lgb_eval],\n                      verbose_eval=10,\n                      num_boost_round=1000,\n                      early_stopping_rounds=10)\n\n\n    oof_train[valid_index] = model.predict(X_val,\n                                           num_iteration=model.best_iteration)\n    y_pred = model.predict(test,\n                           num_iteration=model.best_iteration)\n\n    y_preds.append(y_pred)\n    models.append(model)","f633491e":"print(f'CV: {np.sqrt(mean_squared_error(y_train, oof_train ))}')","242bf918":"sub = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\ny_sub = sum(y_preds) \/ len(y_preds)\ny_sub = np.expm1(y_sub)\nsub['SalePrice'] = y_sub\nsub.to_csv('submission.csv', index=False)\nsub.head()","8b34ad4c":"to confirm categorical variables has converted.","2ba50618":"# Categorical variables\nLabel Encoding some categorical variables that may contain information in their ordering set","a76e63c2":"# What is Optuna?\nLightGBM is one of powerful tool. And take a lot of time to tuning (for noob like me)\nOptuna LightGBM Tuner (https:\/\/github.com\/optuna\/optuna\/pull\/549) can find out the best parameter on LightGBM.\nHere I show you one of a cheap code using this powerful tool. thanks.","c9434286":"# Feature Engineering\n\npick up low-correlation elements, under 0.1 or over -0.1.","d5a46ad4":"I tried basical parameter, put train2( drop three features) previously.\nLightGBM Tuner was the highest score compare to them,\n# 0.13056:LightGBM on train3 with categorical valiables\n# 0.14281:LightGBM on train3 only numerical valiables\n# 0.14357:LightGBM with basical paremeter\n# 0.14498:LightGBM on train2 (autoparam and high-corelation features)\n\nThanks","3c34a7d7":"to check some categorical variables","b25cf835":"# Add non-AI knowledge\n\nSee heatmap, find high-correlations between features which seems to be same feature (i,e, 'GarageCars','GareageArea' they are have 0.9)\nI dropped three features (tagged # del).","61dba42c":"train3 has only important columns (val < 0.1 or val > 0.1)","1210f74b":"#  It's time to go","2824bab2":"# Drop'em up\n"}}