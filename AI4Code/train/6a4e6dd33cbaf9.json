{"cell_type":{"096b5286":"code","12100286":"code","43cb6ede":"code","82ff83ba":"code","c24935b0":"code","411807c2":"code","abe4f3c0":"code","0a1ad1af":"code","034a8b27":"code","fd3dd6e2":"code","19cc2881":"code","4ffbe088":"code","78c26790":"code","64978e0d":"code","ebb2747f":"code","0a1b04f2":"code","e41a0c5d":"code","8818e906":"code","4bd66937":"code","5892b609":"code","c6e12cfa":"code","83401228":"code","bde8ad49":"code","138bbebe":"code","18b15cc2":"code","7aecd951":"code","8077f686":"code","6f08dd1a":"code","205599d6":"code","ab336c27":"code","4a1bb09f":"code","c2378b7e":"code","352204a9":"code","89e3d119":"code","7f29abdf":"code","8c8f3415":"code","7d4dd844":"code","f6cedff7":"code","b257a2a1":"code","e4cf3dfc":"markdown","4d8a3385":"markdown","36a82ed7":"markdown","78bc15df":"markdown"},"source":{"096b5286":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","12100286":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom matplotlib.colors import LinearSegmentedColormap\nfrom plotly.subplots import make_subplots\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator","43cb6ede":"trump = pd.read_csv('..\/input\/all-trumps-twitter-insults-20152021\/trump_insult_tweets_2014_to_2021.csv')","82ff83ba":"trump.shape\ntrump.head()","c24935b0":"print('The different targets of trump in his tweets from the least cited to the most cited :')\nprint(trump.groupby(['target']).size().sort_values())\n","411807c2":"print('The distribution of the 5 main targets of D.Trumps tweets :')\ntrump['target'].value_counts()[:5].sort_values(ascending=False).plot(kind=\"pie\")","abe4f3c0":"print('The different insults used in his tweets :')\nprint(trump.groupby(['insult']).size().sort_values())","0a1ad1af":"print('The top 5 insults used in his tweets :')\ntrump['insult'].value_counts()[:5].sort_values(ascending=False).plot(kind=\"pie\")\n","034a8b27":"trump_media = trump.loc[trump['target']=='hillary-clinton']\nprint('Most insult word with Hillary was :')\n\ntweet_ALL = \" \".join(insul for insul in trump_media.insult)\n\nfig, ax = plt.subplots(1, 1, figsize = (12,10))\n\nwordcloud_ALL = WordCloud(max_font_size=50, max_words=100,colormap=\"PuBu\", background_color=\"white\").generate(tweet_ALL)\n\nax.imshow(wordcloud_ALL, interpolation='bilinear')\n\nax.axis('off');","fd3dd6e2":"trump_media = trump.loc[trump['target']=='democrats']\nprint('Most insult word against Democrats was :')\n\n\ntweet_ALL = \" \".join(insul for insul in trump_media.insult)\n\nfig, ax = plt.subplots(1, 1, figsize = (12,10))\n\nwordcloud_ALL = WordCloud(max_font_size=50, max_words=100,colormap=\"Blues\", background_color=\"white\").generate(tweet_ALL)\n\nax.imshow(wordcloud_ALL, interpolation='bilinear')\n\nax.axis('off');","19cc2881":"trump_media = trump.loc[trump['target']=='trump-russia']\nprint('Most insult word against Russia was :')\n\n\ntweet_ALL = \" \".join(insul for insul in trump_media.insult)\n\nfig, ax = plt.subplots(1, 1, figsize = (12,10))\n\nwordcloud_ALL = WordCloud(max_font_size=50, max_words=100,colormap=\"Reds\", background_color=\"white\").generate(tweet_ALL)\n\nax.imshow(wordcloud_ALL, interpolation='bilinear')\n\nax.axis('off');","4ffbe088":"trump_media = trump.loc[trump['target']=='the-media']\nprint('Most insult word against The Media was :')\n\ntweet_ALL = \" \".join(insul for insul in trump_media.insult)\n\nfig, ax = plt.subplots(1, 1, figsize = (12,10))\n\nwordcloud_ALL = WordCloud(max_font_size=50, max_words=100,colormap=\"gist_heat\", background_color=\"white\").generate(tweet_ALL)\n\nax.imshow(wordcloud_ALL, interpolation='bilinear')\n\nax.axis('off');","78c26790":"trump['date'] = pd.to_datetime(trump['date'])\ntrump['year'] = trump['date'].dt.year\ntrump['month'] = trump['date'].dt.month\ntrump['day'] =  trump['date'].dt.day\ntrump.head()","64978e0d":"print('The number of tweets posted with insults over the last few years :')\ntrump['date'].value_counts().resample('Y').sum()\n\nsns.displot(trump['date'])","ebb2747f":"import pandas as pd\nimport numpy as np\nimport re\nimport plotly.graph_objects as go\nimport pandas as pd\nimport nltk\nimport textblob\nimport plotly.express as px\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize \nfrom sklearn.cluster import MiniBatchKMeans\nimport seaborn as sns\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer as vad\nimport plotly\nplotly.offline.init_notebook_mode (connected = True)","0a1b04f2":"data = trump","e41a0c5d":"# Proprocessing the data\ndata['tweet']=data['tweet'].str.lower()\n# Code to remove the Hashtags from the text\ndata['tweet']=data['tweet'].apply(lambda x:re.sub(r'\\B#\\S+','',x))\n# Code to remove the links from the text\ndata['tweet']=data['tweet'].apply(lambda x:re.sub(r\"http\\S+\", \"\", x))\n# Code to remove the Special characters from the text \ndata['tweet']=data['tweet'].apply(lambda x:' '.join(re.findall(r'\\w+', x)))\n# Code to substitute the multiple spaces with single spaces\ndata['tweet']=data['tweet'].apply(lambda x:re.sub(r'\\s+', ' ', x, flags=re.I))\n# Code to remove all the single characters in the text\ndata['tweet']=data['tweet'].apply(lambda x:re.sub(r'\\s+[a-zA-Z]\\s+', '', x))\n# Remove the twitter handlers\ndata['tweet']=data['tweet'].apply(lambda x:re.sub('@[^\\s]+','',x))","8818e906":"data=data[['tweet']]\n","4bd66937":"# Invoking the TFIDFVectorizer\ntf_data=TfidfVectorizer()\n# Copying the data into a new dataframe called vader\nvader=data.copy()\n\nsentiment=vad()\n# Making additional columns for sentiment score in the vader dataframe\nsen=['Positive','Negative','Neutral']\nsentiments=[sentiment.polarity_scores(i) for i in vader['tweet'].values]\nvader['Negative Score']=[i['neg'] for i in sentiments]\nvader['Positive Score']=[i['pos'] for i in sentiments]\nvader['Neutral Score']=[i['neu'] for i in sentiments]\nvader['Compound Score']=[i['compound'] for i in sentiments]\nscore=vader['Compound Score'].values\nt=[]\nfor i in score:\n    if i >=0.05 :\n        t.append('Positive')\n    elif i<=-0.05 :\n        t.append('Negative')\n    else:\n        t.append('Neutral')\nvader['Overall Sentiment']=t","5892b609":"vader.head()","c6e12cfa":"fig=px.histogram(data_frame=vader,x='Compound Score',color='Overall Sentiment',template='plotly')\nfig.show()","83401228":"sns.countplot(vader['Overall Sentiment'])","bde8ad49":"vader_data=tf_data.fit_transform(vader['tweet'].values)\n","138bbebe":"pca = PCA(n_components=3).fit_transform(vader_data.todense())","18b15cc2":"px.scatter_3d(x=pca[:,0],y=pca[:,1],z=pca[:,2],color=vader['Overall Sentiment'].values)\n","7aecd951":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport nltk\nfrom nltk.corpus import stopwords\nimport re\nimport networkx\nfrom textblob import TextBlob\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","8077f686":"def clean_tweets(tweet):\n \n    tweet = re.sub(r':', '', str(tweet))\n    tweet = re.sub(r'\u201a\u00c4\u00b6', '', str(tweet))\n    tweet = re.sub('@[A-Za-z0\u20139]+', '', str(tweet))               \n    tweet = re.sub('#', '', str(tweet)) \n    tweet = re.sub('https?:\\\/\\\/\\S+', '', str(tweet)) \n    tweet = re.sub(r'[^\\x00-\\x7F]+',' ',str(tweet))\n    tweet = str(tweet).lower()\n    tweet = re.sub('\\[.*?\\]', '', tweet)\n    tweet = re.sub('https?:\/\/\\S+|www\\.\\S+', '', tweet)\n    tweet = re.sub('<.*?>+', '', tweet)\n    tweet = re.sub('\\n', '', tweet)\n    tweet = re.sub('\\w*\\d\\w*', '', tweet)\n    tweet = re.sub(r'#','',tweet)\n    tweet = re.sub(r'RT[\\s]+','',tweet)\n    tweet = re.sub(r'[^\\w]', ' ', tweet)\n    tweet = re.sub('https', '', tweet)\n    tweet = re.sub('https ', '', tweet)\n    tweet = re.sub('co', '', tweet)\n\n    return tweet","6f08dd1a":"def getSubjectivity(tweet):\n    try:\n        return TextBlob(tweet).sentiment.subjectivity\n    except:\n        return None","205599d6":"def getPolarity(tweet):\n    try:\n        return  TextBlob(tweet).sentiment.polarity\n    except:\n        return None","ab336c27":"def sentiment_calc(tweet):\n    try:\n        return TextBlob(tweet).sentiment\n    except:\n        return None","4a1bb09f":"data['cleaned_text']=data['tweet'].apply(clean_tweets)","c2378b7e":"data['subjectivity'] = data['cleaned_text'].apply(getSubjectivity)\ndata['polarity'] = data['cleaned_text'].apply(getPolarity)\ndata['sentiment'] = data['cleaned_text'].apply(sentiment_calc)","352204a9":"def getAnalysis(score):\n    if score < 0:\n      return 'Negative'\n    elif score == 0:\n      return 'Neutral'\n    else:\n      return 'Positive'","89e3d119":"data['analysis'] = data['polarity'].apply(getAnalysis)","7f29abdf":"data.head()","8c8f3415":"data.groupby('analysis')['analysis'].count().plot.bar()\nplt.title('Sentiment Analyisis  ')","7d4dd844":"x=data.groupby('analysis')['analysis'].count()\nneutral=data[data['analysis']=='Neutral']['cleaned_text'].count()\npositive=data[data['analysis']=='Positive']['cleaned_text'].count()\nnegative=data[data['analysis']=='Negative']['cleaned_text'].count()","f6cedff7":"import plotly.graph_objects as go","b257a2a1":"fig = go.Figure(data=[go.Pie(labels=[\"positivity\",\"negativity\",\"neutrality\"], values=[positive,negative,neutral])])\nfig.update_layout(title_text='Trumps tweet sentiment analysis')\nfig.show()","e4cf3dfc":"**TWEET ANALYSIS**","4d8a3385":"**SENTIMENT ANALYSIS**","36a82ed7":"1. Tweet Analysis\n2. Sentiment Analysis","78bc15df":"![](https:\/\/zupimages.net\/up\/21\/05\/om1a.jpg)"}}