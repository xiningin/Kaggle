{"cell_type":{"e2f630af":"code","0cf276a6":"code","68ec292a":"code","03f6684e":"code","59b6f5a4":"code","33e6a9f1":"code","8535d0d0":"code","d964b0f8":"code","14151261":"code","8d2b6e11":"code","16101e3e":"code","8f9a9d3f":"code","b38c373a":"code","1aee93f8":"code","9b169955":"code","ef00a4b1":"code","8e7fc33d":"code","95c5fb71":"code","7769824c":"code","a34e3c00":"code","e56116c2":"code","335bf4b1":"code","9a03b04f":"code","fe3f81ec":"code","2a2738bd":"code","8ba0c7d5":"code","b81162d8":"code","20b3f050":"code","13636ebc":"code","e453699a":"code","a71fef90":"code","f9ab5efb":"code","358d1d21":"code","f5e19823":"code","36051172":"code","a47270fc":"code","0b189802":"code","a63fa42b":"code","040d8289":"code","000efa83":"code","603ea01d":"code","49fd8d3c":"code","f1407b9b":"code","53d4771a":"code","ac2100b7":"code","7cf3fca7":"code","09ad6882":"code","c560b4f7":"code","11151bfe":"code","03c84c8c":"code","56b4cb18":"code","9ca2a8dc":"code","cce74d7b":"code","43b295d1":"code","58947040":"code","7d8671b2":"code","8e062ca3":"code","eb6f8481":"code","d0a82457":"code","3f594df9":"code","1bee0770":"code","b3b6322f":"code","f09541fc":"code","cb422f5a":"code","97c435f4":"code","8148b8e9":"code","5bd34ca2":"code","430a096e":"code","6ba79124":"code","1d9e6b35":"code","f5363400":"code","9c74f739":"code","7210dc48":"code","d4aa8e20":"code","f0884955":"code","e5699676":"code","0a38d581":"code","a3333183":"code","fa67430a":"code","f222b2a6":"code","a4b72cae":"code","09c2d588":"code","8992c43e":"code","9cb4780c":"code","594ac269":"code","cf751f7b":"code","7f036386":"code","3cd4ed1e":"code","de92df40":"code","1c43a017":"code","5935e34b":"code","1343fa69":"markdown","324a207f":"markdown","b0c30d83":"markdown","8061adfc":"markdown","08fbf528":"markdown","505f57c9":"markdown","b57027dd":"markdown","d57e05c9":"markdown","b5874f6c":"markdown","963c88cb":"markdown","9c4e7031":"markdown","19996d42":"markdown","a644eec6":"markdown","aaf467f9":"markdown","bbbdb4b1":"markdown"},"source":{"e2f630af":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0cf276a6":"from sklearn.feature_extraction.text import CountVectorizer\nimport re\n# Tutorial about Python regular expressions: https:\/\/pymotw.com\/2\/re\/ import string\nfrom nltk.corpus import stopwords\n\nfrom tqdm import tqdm\nimport os\nimport nltk\nimport spacy\nimport random\nfrom spacy.util import compounding\nfrom spacy.util import minibatch\nimport string\n\n#Importing all the needed libraries\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly as plt\nfrom matplotlib.pyplot import xticks\n\nfrom matplotlib import *\nimport sys\nfrom pylab import *\n\n%matplotlib inline\nplt.rcParams['figure.figsize']=10,6\nplt.rcParams['axes.grid']=True\nplt.gray()\n\nfrom io import BytesIO\n\nimport requests\n\n## https:\/\/python-graph-gallery.com\/wordcloud\/ \n\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\n\nuse_cuda = True\npd.set_option('display.max_columns', None)","68ec292a":"\nimport pandas as pd\n\n#r = requests.get('https:\/\/docs.google.com\/spreadsheets\/d\/1mU2brATV_fgd5MRGfT2ASOFepAI1pivwhGm0VCT22_U\/edit#gid=csv')\n#data = r.content","03f6684e":"### Import data from externe source \n## link to datset source : https:\/\/docs.google.com\/spreadsheets\/d\/1mU2brATV_fgd5MRGfT2ASOFepAI1pivwhGm0VCT22_U\/edit#gid=0\n## https:\/\/inventory.algorithmwatch.org\/\n## https:\/\/www.europarl.europa.eu\/RegData\/etudes\/STUD\/2020\/634452\/EPRS_STU(2020)634452_EN.pdf\n## https:\/\/papers.ssrn.com\/sol3\/papers.cfm?abstract_id=3518482\n## https:\/\/www.nature.com\/articles\/s42256-019-0088-2\n## https:\/\/blog.einstein.ai\/frameworks-tool-kits-principles-and-oaths-oh-my\/\n## https:\/\/fra.europa.eu\/en\/project\/2018\/artificial-intelligence-big-data-and-fundamental-rights\/ai-policy-initiatives\n## https:\/\/duckduckgo.com\/\n\n#dfs = pd.read_excel(\"\/kaggle\/input\/digital-policiers-frameworks\/Digital Policies Frameworks.xlsx\", sheetname=\"Database\")\n\ndfs = pd.ExcelFile('\/kaggle\/input\/digital-policiers-frameworks\/Digital Policies Frameworks.xlsx')\n\n## Data sources description \nDatabase = pd.read_excel(dfs, 'Database')","59b6f5a4":"nrow, ncol = Database.shape\nnrow, ncol","33e6a9f1":"Database.head()","8535d0d0":"#Database['fundamental rights'].unique()","d964b0f8":"for col in Database.columns:\n    print(col)","14151261":"#Define missing data function to identify the total number of missing data and associated percentage \ndef missing_data(data):\n    total = data.isnull().sum()\n    percent = (data.isnull().sum()\/data.isnull().count()*100)\n    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    types = []\n    for col in data.columns:\n        dtype = str(data[col].dtypes)\n        types.append(dtype)\n    tt['Types'] = types\n    return(np.transpose(tt))","8d2b6e11":"missing_data(Database)","16101e3e":"Database[Database.duplicated()== True]","8f9a9d3f":"Database.shape","b38c373a":"Database.describe()","1aee93f8":"Database.info()","9b169955":"from nltk.tokenize import RegexpTokenizer\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud\n\nstopWords = stopwords.words('english')\ntokenizer = RegexpTokenizer(r'\\w+')\n\ndef get_wordcloud(series): #simple function to tokenize and plot a said column\n    word_cloud = ''\n    \n    for job in series:\n        tokens = tokenizer.tokenize(job)\n        for token in tokens:\n            if token not in stopWords:\n                word_cloud += ''.join(token) + ' '\n\n    #wordcloud = WordCloud(height=800,margin=1,max_words=500, colormap='Set1').generate(word_cloud) \n    #wordcloud = WordCloud( width = 3000, height = 2000, random_state=1, background_color='salmon', colormap='Pastel1', collocations=False).generate(word_cloud) \n    \n    wordcloud = WordCloud(width = 3000, height = 2000, random_state=1,\n                          background_color='black', colormap='Set2', collocations=False).generate(word_cloud)\n\n    plt.imshow(wordcloud) \n    plt.axis(\"off\") \n    plt.tight_layout(pad = 0) \n    #plt.savefig('Plotly-World_Cloud.png')","ef00a4b1":"Database['Issuer'].unique()","8e7fc33d":"len(Database['Issuer'].unique())","95c5fb71":"Database['Issuer'].describe()","7769824c":"Database['Issuer'].nunique()","a34e3c00":"#plt.figure(figsize=(13, 4))\n#http:\/\/stackoverflow.com\/questions\/32891211\/limit-the-number-of-groups-shown-in-seaborn-countplot for odering\n#sns.countplot(Database.Issuer.dropna(), order = Database.Issuer.value_counts().index);\n#sns.violinplot(data=df, x='', y='')\n\n\nplt.figure(figsize=(13, 4))\nsns.countplot(Database.Issuer.dropna(), order = Database.Issuer.value_counts().iloc[:50].index)\nplt.xticks(rotation=90);","e56116c2":"\n#Source\n\nax = plt.subplots(figsize = (10, 8))\nsns.set_style('dark')\nplt.title('Number of Issuer available in dataset', fontweight='bold', fontsize=20)\nax = sns.countplot(y = 'Issuer', data = Database, order = Database['Issuer'].value_counts().index[0:20], palette='Set2')\nplt.savefig('Issuer.png')","335bf4b1":"Database['Issuer'].isnull().sum()\/ nrow\n\n#Let's multiple by 100 and keep only 1 decimal places\n(Database['Issuer'].isnull().sum()\/ nrow).round(3)*100","9a03b04f":"\n\nax = plt.subplots(figsize = (10, 8))\nsns.set_style('dark')\nplt.title('Distribution of explainability by Country or instition', fontweight='bold', fontsize=20)\n\nax = sns.boxplot(x='Source',y='explainability',data=Database,order = Database['Source'].value_counts().index[0:15],palette='Set2')\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)\nplt.savefig('histor.png')","fe3f81ec":"\nax = plt.subplots(figsize = (10, 8))\nsns.set_style('dark')\nplt.title('Distribution of transparency by Country or instition', fontweight='bold', fontsize=20)\n\nax = sns.boxplot(x='Source',y='transparency',data=Database,order = Database['Source'].value_counts().index[0:15],palette='Set2')\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)\nplt.savefig('histo2.png')","2a2738bd":"ax = plt.subplots(figsize = (10, 8))\nsns.set_style('dark')\nplt.title('Number of dataset available by Type', fontweight='bold', fontsize=20)\nax = sns.countplot(y = 'Type', data = Database, palette='tab10')\nplt.savefig('Type.png')","8ba0c7d5":"\n\nax = plt.subplots(figsize = (10, 8))\nsns.set_style('dark')\nplt.title('Distribution of explainability by Type', fontweight='bold', fontsize=20)\n\nax = sns.boxplot(x='Type',y='explainability',data=Database,palette='tab10')\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)\nplt.savefig('explainability_type.png')","b81162d8":"\nax = plt.subplots(figsize = (10, 8))\nsns.set_style('dark')\nplt.title('Distribution of transparency by Type', fontweight='bold', fontsize=20)\n\nax = sns.boxplot(x='Type',y='transparency',data=Database,palette='tab10')\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)\nplt.savefig('transparency_type.png')","20b3f050":"plus100 = Database['Type'].map(Database['Type'].value_counts()) > 100 # More than 100 \n\nax = plt.subplots(figsize = (10, 8))\nsns.set_style('dark')\nax = sns.countplot(x='Source',hue='Type',data=Database[plus100],order = Database['Source'].value_counts().index[0:20],palette='Set2')\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)\nplt.savefig('Source_type.png')","13636ebc":"Source = Database['Source'].apply(lambda x: x.lower())\n\nplt_source = get_wordcloud(Source)\n\nplt.savefig('plt_source.png')","e453699a":"\n\nReference = Database['Reference'].apply(lambda x: x.lower())\n\nplt_Reference = get_wordcloud(Reference)\n\nplt.savefig('plt_Reference.png')\n","a71fef90":"\n\nOrigin = Database['Origin'].apply(lambda x: x.lower())\n\nplt_origin = get_wordcloud(Origin)\n\nplt.savefig('plt_origin.png')\n\n","f9ab5efb":"Issuer = Database['Issuer'].apply(lambda x: x.lower())\n\nplt_Issuer = get_wordcloud(Issuer)\n\nplt.savefig('plt_Issuer.png')\n","358d1d21":"\n\nax = sns.countplot(Database['Type'])\nax.set_xticklabels(ax.get_xticklabels(),rotation=45)\nplt.savefig('Type1.png')\n","f5e19823":"numerical = ['fundamental rights','human agency','human rights','non discrimination','non maleficence',\n\n'rule of law','sustainable development','well being','accountability','autonomy','beneficence','democracy'\n ,'dignity' ,'diversity','explainability','fairness','freedom','inclusive','justice','liability','literacy','oversight'\n,'privacy','responsibility','robustness','safe','solidarity','sustainability','transparency','trust','trustworthy'\n  \n]\ncategorical = ['Issuer','Reference','Type','Link','Origin','Source','CoE MS','Update', 'Year'\n]\n\nDatabase = Database[numerical + categorical]\nDatabase.shape","36051172":"sns.set(style='whitegrid', palette=\"deep\", font_scale=1.1, rc={\"figure.figsize\": [8, 5]})\nsns.distplot(\n    Database['explainability'], norm_hist=False, kde=False, bins=20, hist_kws={\"alpha\": 1}\n).set(xlabel='Explainability', ylabel='Count');","a47270fc":"# Database[numerical].plot.barh(stacked=True);","0b189802":"fig, ax = plt.subplots(2, 4, figsize=(20, 10))\nfor variable, subplot in zip(categorical, ax.flatten()):\n    sns.countplot(Database[variable],order = Database[variable].value_counts().index[0:5], ax=subplot)\n    for label in subplot.get_xticklabels():\n        label.set_rotation(90)","a63fa42b":"# Plotly Libraris\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nDatabase['Type'].value_counts().plot.pie(autopct='%2.2f%%', colors = ['cyan','darkcyan','pink','#ff9999','#66b3ff','#99ff99','#ffcc99','#c2c2f0','#ffb3e6'])","040d8289":"import plotly.express as px\n\nfig = px.pie(Database['Type'], values=Database['Type'].value_counts().values, names=Database['Type'].value_counts().index)\nfig.update_traces(hoverinfo='label+percent', textinfo='value')\nfig.show()","000efa83":"#sns.catplot(x = 'Type',hue = 'Source',data = Database,order = Database['Source'].value_counts().index[0:5], kind = 'count')\n#sns.catplot(x = 'Type',col = 'Source',data = Database, order = Database['Source'].value_counts().index[0:5], kind = 'count')","603ea01d":"dfs = pd.ExcelFile('\/kaggle\/input\/digital-policiers-frameworks\/Digital Policies Frameworks.xlsx')\n\n## Data sources description \ndata = pd.read_excel(dfs, 'Database')","49fd8d3c":"#Database.head()\n\nfill_data = data.fillna(' ')\nfill_data.head()","f1407b9b":"# creating Countplot from Seaborn to show max available content in NETFLIX\n\nsns.set_style('dark')\nax = plt.subplots(figsize = (6, 6))\nplt.title('Countplot for Type for Issuer ', fontweight='bold')\nax = sns.countplot(x = 'Type', data=data, palette='Set1')\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)","53d4771a":"ax = plt.subplots(figsize = (10, 8))\nsns.set_style('dark')\nplt.title('Database available based year  Releasing', fontweight='bold', fontsize=20)\nax = sns.countplot(y = 'Year', data = data, order = data['Year'].value_counts().index[0:15], palette='Set2')\nplt.savefig('Year_release.png')","ac2100b7":"ax = plt.subplots(figsize = (10, 8))\nsns.set_style('dark')\nplt.title(' Data issuer  Reference', fontweight='bold', fontsize=20)\nax = sns.countplot(x = 'Reference', data = data, palette = 'Set2', order = data['Reference'].value_counts().index[0:15])\n#ax.set_xticklabels(labels, rotation=45)\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)","7cf3fca7":"ax = plt.subplots(figsize = (10, 8))\nsns.set_style('dark')\nplt.title('Data issuer  Reference', fontweight='bold', fontsize=20)\n#ax = sns.countplot(x = 'Reference', data = data, palette = 'Set2', order = data['Reference'].value_counts().index[0:15])\nax = sns.countplot(y = 'Reference', data = data, order = data['Reference'].value_counts().index[0:15], palette='Set2')","09ad6882":"#Source\n\nax = plt.subplots(figsize = (10, 8))\nsns.set_style('dark')\nplt.title('Data Source', fontweight='bold', fontsize=20)\nax = sns.countplot(y = 'Source', data = data, order = data['Source'].value_counts().index[0:15], palette='Set2')","c560b4f7":"# More Issuer content creating countries\n\ncountries = {}\ndata['Issuer'] = data['Issuer'].fillna('Unknown')\n\nlist_countries = list(data['Issuer'])\n\nfor i in list_countries:\n    i = list(i.split(','))\n    \n    if len(i) is 1:\n        if i in list(countries.keys()):\n            countries[i] += 1\n        else:\n            countries[i[0]] = 1\n    else:\n        for j in i:\n            if j in list(countries.keys()):\n                countries[j] += 1\n            else:\n                countries[j] = 1","11151bfe":"final_countries = {}\n\nfor country, no in countries.items():\n    country = country.replace(' ','')\n    \n    if country in list(final_countries.keys()):\n        final_countries[country] += no\n    else:\n        final_countries[country] = no\n        \nfinal_countries = {k : v for k, v in sorted(final_countries.items(), key = lambda item : item[1], reverse = True)}","03c84c8c":"plt.figure(figsize = (15, 15))\nplt.title(' Issuer Creating Countries', fontweight = 'bold', fontsize=15)\n\ny_ver = list(final_countries.keys())\nx_hor = list(final_countries.values())\nsns.barplot( y = y_ver[0:40], x = x_hor[0:40])\nplt.ylabel('Issuer in dataset')","56b4cb18":"data[data['Year'] == 2020].groupby('Type')['Year'].count()","9ca2a8dc":"## relationship between transparency and explainability\n\nsns.scatterplot(x=data['explainability'], y=data['transparency']);\nplt.savefig('explainability.png')","cce74d7b":"sns.jointplot(x=data['explainability'], y=data['transparency']);","43b295d1":"\n\n## relationship between democracy and explainability\n\nsns.scatterplot(x=data['explainability'], y=data['democracy']);","58947040":"sns.jointplot(x=data['explainability'], y=data['democracy']);","7d8671b2":"## relationship between sustainable development and explainability\n\nsns.scatterplot(x=data['explainability'], y=data['sustainable development']);","8e062ca3":"sns.jointplot(x=data['explainability'], y=data['sustainable development']);","eb6f8481":"\n\n## relationship between fundamental rights and explainability\n\nsns.scatterplot(x=data['explainability'], y=data['fundamental rights']);","d0a82457":"sns.jointplot(x=data['explainability'], y=data['fundamental rights']);","3f594df9":"#sns.pairplot(Database[numerical], kind=\"scatter\")\n#plt.show()","1bee0770":"pd.crosstab(Database.Type, Database.Source)","b3b6322f":"from scipy.stats import chi2_contingency\nchi2_contingency(pd.crosstab(Database.Type, Database.Source))\n\n","f09541fc":"sns.catplot(x=\"Type\", y=\"explainability\", data=Database)","cb422f5a":"from sklearn.cluster import KMeans","97c435f4":"categorical = Database[categorical]","8148b8e9":"categorical.describe()","5bd34ca2":"categorical.info()","430a096e":"categorical.isnull().sum()*100\/categorical.shape[0]","6ba79124":"categorical_copy = categorical.copy()","1d9e6b35":"from sklearn import preprocessing\nfrom kmodes.kmodes import KModes\nle = preprocessing.LabelEncoder()\ncategorical = categorical.apply(le.fit_transform)\ncategorical.head()\n","f5363400":"#Using K-Mode with \"Cao\" initialization\nkm_cao = KModes(n_clusters=2, init = \"Cao\", n_init = 1, verbose=1)\nfitClusters_cao = km_cao.fit_predict(categorical)","9c74f739":"# Predicted Clusters\nfitClusters_cao","7210dc48":"clusterCentroidsDf = pd.DataFrame(km_cao.cluster_centroids_)\nclusterCentroidsDf.columns = categorical.columns","d4aa8e20":"# Mode of the clusters\nclusterCentroidsDf","f0884955":"#Using K-Mode with \"Huang\" initialization\nkm_huang = KModes(n_clusters=2, init = \"Huang\", n_init = 1, verbose=1)\nfitClusters_huang = km_huang.fit_predict(categorical)","e5699676":"# Predicted clusters\nfitClusters_huang","0a38d581":"cost = []\nfor num_clusters in list(range(1,5)):\n    kmode = KModes(n_clusters=num_clusters, init = \"Cao\", n_init = 1, verbose=1)\n    kmode.fit_predict(categorical)\n    cost.append(kmode.cost_)","a3333183":"y = np.array([i for i in range(1,5,1)])\nplt.plot(y,cost)","fa67430a":"## Choosing K=2\n\nkm_cao = KModes(n_clusters=2, init = \"Cao\", n_init = 1, verbose=1)\nfitClusters_cao = km_cao.fit_predict(categorical)","f222b2a6":"fitClusters_cao","a4b72cae":"#Combining the predicted clusters with the original DF\ncategorical = categorical_copy.reset_index()\n","09c2d588":"clustersDf = pd.DataFrame(fitClusters_cao)\nclustersDf.columns = ['cluster_predicted']\ncombinedDf = pd.concat([categorical, clustersDf], axis = 1).reset_index()\ncombinedDf = combinedDf.drop(['index', 'level_0'], axis = 1)","8992c43e":"combinedDf.head()","9cb4780c":"cluster_0 = combinedDf[combinedDf['cluster_predicted'] == 0]\ncluster_1 = combinedDf[combinedDf['cluster_predicted'] == 1]","594ac269":"cluster_0.info()","cf751f7b":"cluster_1.info()","7f036386":"plt.subplots(figsize = (15,5))\nax = sns.countplot(x=combinedDf['Type'],order=combinedDf['Type'].value_counts().index,hue=combinedDf['cluster_predicted'])\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)\nplt.show()\nplt.savefig('cluster_type.png')","3cd4ed1e":"plt.subplots(figsize = (15,5))\nax = sns.countplot(x=combinedDf['Origin'],order=combinedDf['Origin'].value_counts().index,hue=combinedDf['cluster_predicted'])\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)\nplt.show()\nplt.savefig('cluster_origin.png')","de92df40":"plt.subplots(figsize = (15,5))\nax = sns.countplot(x=combinedDf['Source'],order=combinedDf['Source'].value_counts().index,hue=combinedDf['cluster_predicted'])\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)\nplt.savefig('Cluster_source.png')\nplt.show()","1c43a017":"f, axs = plt.subplots(1,3,figsize = (15,5))\nsns.countplot(x=combinedDf['CoE MS'],order=combinedDf['CoE MS'].value_counts().index,hue=combinedDf['cluster_predicted'],ax=axs[0])\nsns.countplot(x=combinedDf['Update'],order=combinedDf['Update'].value_counts().index,hue=combinedDf['cluster_predicted'],ax=axs[1])\nsns.countplot(x=combinedDf['Issuer'],order=combinedDf['Issuer'].value_counts().index[0:5],hue=combinedDf['cluster_predicted'], ax=axs[2])\n\nplt.tight_layout()\nplt.show()","5935e34b":"f, axs = plt.subplots(1,2,figsize = (15,5))\nsns.countplot(x=combinedDf['Year'],order=combinedDf['Year'].value_counts().index,hue=combinedDf['cluster_predicted'],ax=axs[0])\nplt.tight_layout()\nplt.show()","1343fa69":"### Issuer","324a207f":"## Data Inspection","b0c30d83":"OK,this is too much to inspect, let's see only the top 50. But the shape is very nice\\smooth, looks like an exponential decay.","8061adfc":"### Issuer","08fbf528":"## Problem Statement\n\nIt is necessary to explore the full ethical, social and legal aspects of AI systems if we are to avoid unintended, negative consequences and risks arising from the implementation of AI in society. \n\n\nsoftware-based AI and intelligent robots (i.e. robots with an embedded AI) when exploring ethical issues. \n\nArtificial intelligence refers to systems that can be designed to take cues from their environment and, based on those inputs, proceed to solve problems, assess risks, make predictions, and take actions. In the era predating powerful computers and big data, such systems were programmed by humans and followed rules of human invention, but advances in technology have led to the development of new approaches.\n\n### Objective\n\nObjective: Exploring ethical data and finding homogeneous subgroups such that variables in the same group (clusters) are more similar to each other than the others. Based on this clustering, we can assess the global ethic index of Issuer. \n\n- Aim 1: Clustering for Classification\n\n- Aim 2: assessment the global ethic index of Issuer\n\n\n\n### Data\n\n\nWho are the main producers? \n\nWhat are they? What are the principles?\n\nNavigate in this intense production\n\n\nOpen data available  on Google Sheets \u2013 Licence Creative Commons BY-NC-SA \n\nDigital Policies Frameworks Database  Data Set(UCI Repository: https:\/\/docs.google.com\/spreadsheets\/d\/1mU2brATV_fgd5MRGfT2ASOFepAI1pivwhGm0VCT22_U\/edit#gid=0) are used for this analysis.\n\n### Variables \n\n**Somes Attribute Information(Categorical & Numerical):** \n\n\n#### Categorical variable \n\n\n- Issuer('Berkman Klein Center (University of Harvard)','Cyberjustice Laboratory', 'ETH Zurich','Fraunhofer, Institute for Intelligent Analysis and Information Systems IAIS', 'Handelsblatt Research Institute')\n\n- Reference(Principled Artificial Intelligence','ACT Project - Projet AJC (Autonomisation des acteurs judiciaires par la Cyberjustice)','AI, the global landscape of ethics guidelines')\n\n- Type ('Meta-analysis', 'Research project', 'Academic paper','Report\/Study', 'Principles\/Guidelines\/Charters', 'Policy paper','Non binding instrument', 'Parliamentary proceeding','Binding instrument')\n\n- Link('https:\/\/ssrn.com\/abstract=3518482', 'https:\/\/www.ajcact.org', 'https:\/\/arxiv.org\/ftp\/arxiv\/papers\/1906\/1906.11668.pdf','https:\/\/arxiv.org\/abs\/1809.03400')\n\n- Origin(Academia', 'Civil Society', 'International Organisation','Multistakeholder', 'National Authorities', 'Private Sector','Professional association', 'Think Tank')\n\n- Source('United States', 'Canada', 'Switzerland', 'Germany', 'Slovenia','United Kingdom', 'Italy', 'China', 'Australia', 'Netherlands','Austria', 'France', 'Denmark', 'Sweden', 'Lithuania','EU - Article 29 Working Party', 'Council of Europe','EU - Council of the European Union', 'EU - European Union')\n\n- CoE MS('No', 'Yes')\n\n- Year (2018, 2019, 2020, 2015, 2017, 2014, 2011, 2016, 2010)\n\n- Comments('Updated', 'New')\n\n- Update('Data updated on 02 January 2021')\n\n\n\n#### Numerical variable \n\n- fundamental rights\n\n- solidarity\n\n- sustainability\n\n- transparency\n\n- explainability\n\n- fairness\n\n- freedom\n\n- ..........................\n\n","505f57c9":"## Univariate Analysis","b57027dd":"# The ethics of artificial intelligence: What talk data ? \n\n## Author : GARBA Moussa \n","d57e05c9":"# Model Building K-modes","b5874f6c":"### **Import dataset from Digital Policies Frameworks **","963c88cb":"# Exploratory Data Analysis","9c4e7031":"## Analyzing Relationships Between Numerical and Categorical Variables\n","19996d42":"## Choosing K by comparing Cost against each K","a644eec6":"## Analyzing Relationships Between Numerical Variables","aaf467f9":"## Cluster Identification","bbbdb4b1":"### Categorical Variables\n\n## Grouped bar charts\n## Stacked bar charts"}}