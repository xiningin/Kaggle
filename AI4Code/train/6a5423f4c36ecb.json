{"cell_type":{"662eb3d5":"code","1ee87af3":"code","93febb8f":"code","f118d340":"code","250e9c0f":"code","88fc4cfb":"code","cc9fd29a":"code","041cf8e8":"code","f59f4c80":"markdown","4102e38e":"markdown","f07da3be":"markdown","651badbd":"markdown","57c80464":"markdown","0fa1a2b7":"markdown","60c58ae2":"markdown","837701ff":"markdown"},"source":{"662eb3d5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1ee87af3":"data_set = pd.read_csv ('..\/input\/world-happiness\/2015.csv')\n","93febb8f":"data_set.info()\ndata_set.describe()\ndata_set.columns\ndata_set.head(10)","f118d340":"#Corelation is relationship between features\n\ndata_set.corr()\n\n#Corelation map\n\nf,ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(data_set.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\nplt.show()\n","250e9c0f":"\ndata_set.columns = [ each.lower() for each in data_set.columns] \n\ndata_set.columns = [each.split()[0]+\"_\"+each.split()[1] if(len(each.split())>1) else each for each in data_set.columns]\ndata_set.rename(columns={'economy_(gdp':'economy'}, inplace=True)\ndata_set.rename(columns={'trust_(government':'trust'}, inplace=True)\ndata_set.columns\n","88fc4cfb":"# Scatter Plot \n# x = attack, y = defense\ndata_set.plot(kind='scatter', x='freedom', y='happiness_score',alpha = 0.5,color = 'red')\nplt.xlabel('Freedom')              # label = name of label\nplt.ylabel('Happiness Score')\nplt.title('Freedom & Happiness Score Scatter Plot')     ","cc9fd29a":"# Histogram\n# bins = number of bar in figure\ndata_set.economy.plot(kind = 'hist',bins = 50,figsize = (12,12))\nplt.xlabel('Economy')\nplt.show()","041cf8e8":"data_set[np.logical_and(data_set['trust']>0.4, data_set['economy']>1.3 )]\n","f59f4c80":"Before the explain the data , we are supposed to manipulate the columns names because of the space \" \" between the words","4102e38e":"To explain the data the best way is visualization. Here we are looking for relationship between the freedom and happiness score in line plot.","f07da3be":"Understanding relationship between features help us how supposed to do data mining","651badbd":"Looking for the big economies and trust\n","57c80464":"How Many big economies in our data ?","0fa1a2b7":"First we have to import the libraries,which are we supposed to be use.","60c58ae2":"We can getting information about the data set to quick looking the data","837701ff":"Datasets  should call by pandas library"}}