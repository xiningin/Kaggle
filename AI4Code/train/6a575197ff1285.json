{"cell_type":{"eaa628d3":"code","7174b1ec":"code","0e9d26ee":"code","8e0c7640":"code","e4cca25f":"code","c23f6993":"code","c4ed0e3f":"code","9addc7bd":"code","d6dfb21d":"code","d45f99b6":"code","7b140d86":"code","5e5daef2":"code","8ea6dd8d":"code","a88c4393":"code","62897456":"code","33a55a12":"code","56658ad8":"code","e35f7a06":"code","cc9d1b47":"code","bad0cf0b":"code","54734c10":"code","eb0ac1e5":"markdown","cf2e330d":"markdown","972159ef":"markdown","a5ee8cfe":"markdown","28d23168":"markdown","71238fcc":"markdown","acdc754f":"markdown","7a1b08d5":"markdown","a9f8180d":"markdown"},"source":{"eaa628d3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7174b1ec":"train = pd.read_csv(\"\/kaggle\/input\/fashionmnist\/fashion-mnist_train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/fashionmnist\/fashion-mnist_test.csv\")","0e9d26ee":"train.head()","8e0c7640":"test.head()","e4cca25f":"img_row, img_col = 28, 28\ninput_shape = (img_row, img_col, 1)","c23f6993":"from keras.utils import to_categorical\nX = np.array(train.iloc[:, 1:])\ny = to_categorical(np.array(train.iloc[:, 0]))","c4ed0e3f":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, random_state=13, test_size=0.2)","9addc7bd":"X_test = np.array(test.iloc[:, 1:])\ny_test = to_categorical(np.array(test.iloc[:, 0]))","d6dfb21d":"X_train = X_train.reshape(X_train.shape[0], img_row, img_col, 1)\nX_val = X_val.reshape(X_val.shape[0], img_row, img_col, 1)\nX_test = X_test.reshape(X_test.shape[0], img_row, img_col, 1)","d45f99b6":"X_train = X_train.astype(\"float32\")\nX_val = X_val.astype(\"float32\")\nX_test = X_test.astype(\"float32\")\n\n\nX_train = X_train \/ 255.0\nX_val = X_val \/ 255.0\nX_test = X_test \/ 255.0","7b140d86":"len(X_val)","5e5daef2":"len(y_test)","8ea6dd8d":"from keras.models import Sequential\nfrom keras.layers import Conv2D, Activation, MaxPooling2D, Dense, Dropout, Flatten\nfrom keras.layers.normalization import BatchNormalization","a88c4393":"batch_size = 256\nnum_classes = 10\nepochs = 50\n\n#input image dimensions\nimg_rows, img_cols = 28, 28\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, kernel_size=(3, 3), input_shape=input_shape))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128, (3, 3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(0.4))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=\"categorical_crossentropy\",\n              optimizer=\"adam\",\n              metrics=['accuracy'])\n\nmodel.summary()\n\nhistory = model.fit(X_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(X_val, y_val))\nscore = model.evaluate(X_test, y_test, verbose=0)","62897456":"print('Test loss:', score[0])\nprint('Test accuracy:', score[1])","33a55a12":"import matplotlib.pyplot as plt\naccuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(accuracy))\nplt.plot(epochs, accuracy, 'b', label='Training accuracy')\nplt.plot(epochs, val_accuracy, 'r', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","56658ad8":"#get the predictions for the test data\npredicted_classes = model.predict_classes(X_test)\n\n#get the indices to be plotted\ny_true = test.iloc[:, 0]","e35f7a06":"y_true","cc9d1b47":"# Label names\nclass_names = ['T-shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']","bad0cf0b":"len(predicted_classes)","54734c10":"for index, value in enumerate(predicted_classes[:9]):\n    plt.subplot(3,3,index+1)\n    plt.imshow(X_test[value].reshape(28,28), cmap='gray', interpolation='none')\n    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[value], y_true[value]))\n    plt.xlabel(class_names[predicted_classes[value]])\n    plt.tight_layout()","eb0ac1e5":"# Noramize data","cf2e330d":"# Split data","972159ef":"## Plot trainning and validation accuracy and loss","a5ee8cfe":"**Load csv**","28d23168":"# One Hot Enconding","71238fcc":"# Split test data","acdc754f":"# Actual Vs Predictions","7a1b08d5":"# Reshape train, test, validation data","a9f8180d":"## Labels\n\n* 0 \t---T-shirt\/top\n* 1 \t---Trouser\n* 2 \t---Pullover\n* 3 \t---Dress\n* 4 \t---Coat\n* 5 \t---Sandal\n* 6 \t---Shirt\n* 7 \t---Sneaker\n* 8 \t---Bag\n* 9 \t---Ankle boot"}}