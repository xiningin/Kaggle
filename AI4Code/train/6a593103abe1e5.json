{"cell_type":{"96aad561":"code","a7bc9002":"code","d0e10ba2":"code","3272b5f9":"code","34504e0d":"code","826a416c":"code","a6246527":"code","b6661fe1":"code","9d2f97d2":"code","67ccc47e":"code","131ac566":"code","ddf49308":"code","0d7da7b0":"code","0483a150":"code","81c1ac4f":"code","c2b8b837":"code","fe331c24":"code","82e052c3":"code","837d2f3e":"code","a20f31bc":"code","55fe64ca":"code","df0c6ba1":"code","451dadb8":"code","65dca036":"code","0e18afed":"code","1b7be86b":"code","01be6ad4":"code","6eb13ebe":"code","93653f90":"code","34557157":"code","db9217da":"code","a4e83d6d":"code","cf035c96":"code","a07af561":"code","8f25f210":"code","38b1368f":"code","1b813063":"code","7fb47606":"code","55393015":"code","6c2aaa2f":"code","dd1feed0":"code","172f9cb7":"code","67dba81b":"code","1ad6764c":"code","b82f206c":"code","c3fb1159":"code","48c08fcc":"code","5eee4c78":"code","cd7d5be2":"code","2c6b9b82":"code","cbdf2475":"code","b5ecbc7f":"code","8a9b2094":"code","f9af0598":"code","1f8d840f":"code","9df67f38":"code","065a7861":"code","cf888156":"code","8019f69d":"code","cf78e83a":"code","5f5fbdc1":"code","ffff5f96":"code","b17840f8":"code","d954bb27":"code","adafb8a7":"code","8693a8d5":"code","b14dfd26":"code","2b4b3a65":"code","93ffa78f":"code","393cf068":"code","7e147ee9":"code","57b8d339":"code","9c50c456":"code","1e21c58e":"code","705e8697":"code","0402d9c9":"code","c55a749b":"markdown","feb3339b":"markdown","83fa0089":"markdown","b3afb1e3":"markdown","5b222889":"markdown","1e863014":"markdown","926dd6a0":"markdown","608c4ddf":"markdown","87ce64a1":"markdown","d9db7f75":"markdown","ca883e9e":"markdown","79365e72":"markdown"},"source":{"96aad561":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a7bc9002":"file = \"\/kaggle\/input\/digit-recognizer\/train.csv\"\ndf = pd.read_csv(file)","d0e10ba2":"df.head()","3272b5f9":"df.shape","34504e0d":"file = \"\/kaggle\/input\/digit-recognizer\/test.csv\"\ntest = pd.read_csv(file)","826a416c":"test.head()","a6246527":"test.shape","b6661fe1":"X = df.drop(['label'],axis=1)\ny = df['label']","9d2f97d2":"import matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(color_codes=True,style='darkgrid')","67ccc47e":"some_digit = np.array(X[25000:25001])\nsome_digit_image = some_digit.reshape(28,28)\nplt.imshow(some_digit_image,cmap=matplotlib.cm.binary,interpolation=\"nearest\")\nplt.axis(\"off\")\nplt.show()","131ac566":"y[25000:25001]","ddf49308":"from sklearn.model_selection import train_test_split","0d7da7b0":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)","0483a150":"X_train.shape","81c1ac4f":"X_test.shape\n","c2b8b837":"df.isnull().any().any()","fe331c24":"test.isnull().any().any()","82e052c3":"from sklearn.preprocessing import Normalizer,StandardScaler\nnormalizer = Normalizer()\nscaler = StandardScaler()","837d2f3e":"Xn_train = normalizer.fit_transform(X_train)\nXn_test = normalizer.fit_transform(X_test)\nXs_train = scaler.fit_transform(X_train)\nXs_test = scaler.fit_transform(X_test)","a20f31bc":"from sklearn.linear_model import SGDClassifier","55fe64ca":"sgd = SGDClassifier()","df0c6ba1":"model1 = sgd.fit(Xn_train,y_train)","451dadb8":"y_pred1 = model1.predict(Xn_test)","65dca036":"from sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score","0e18afed":"accuracy_score(y_test,y_pred1)","1b7be86b":"cross_val_score(sgd,Xn_train,y_train,scoring = \"accuracy\")","01be6ad4":"from sklearn.tree import DecisionTreeClassifier","6eb13ebe":"dtree = DecisionTreeClassifier(random_state=0)","93653f90":"model2 = dtree.fit(X_train,y_train)","34557157":"y_pred2 = model2.predict(X_test)","db9217da":"accuracy_score(y_test,y_pred2)","a4e83d6d":"X_pred = model2.predict(X_train)","cf035c96":"accuracy_score(y_train,X_pred)","a07af561":"from sklearn.ensemble import RandomForestClassifier","8f25f210":"rfc = RandomForestClassifier(n_estimators=100,max_features='auto',bootstrap=True,n_jobs=-1,random_state=0)","38b1368f":"model3 = rfc.fit(X_train,y_train)","1b813063":"y_pred3 = model3.predict(X_test)","7fb47606":"accuracy_score(y_test,y_pred3)","55393015":"from sklearn.ensemble import BaggingClassifier","6c2aaa2f":"bgcl = BaggingClassifier(dtree,n_estimators=100,max_features=0.3,n_jobs=-1)","dd1feed0":"model4 = bgcl.fit(X_train,y_train)","172f9cb7":"y_pred4 = model4.predict(X_test)","67dba81b":"accuracy_score(y_test,y_pred4)","1ad6764c":"from sklearn.ensemble import AdaBoostClassifier","b82f206c":"abcl = AdaBoostClassifier(DecisionTreeClassifier(max_depth=7),n_estimators=500,learning_rate=0.1)","c3fb1159":"model5 = abcl.fit(X_train,y_train)","48c08fcc":"y_pred5 = model5.predict(X_test)","5eee4c78":"accuracy_score(y_test,y_pred5)","cd7d5be2":"X_pred5 = model5.predict(X_train)","2c6b9b82":"accuracy_score(y_train,X_pred5)","cbdf2475":"from sklearn.ensemble import GradientBoostingClassifier","b5ecbc7f":"gbcl = GradientBoostingClassifier(random_state=1)","8a9b2094":"model6 = gbcl.fit(X_train,y_train)","f9af0598":"y_pred6 = model6.predict(X_test)","1f8d840f":"accuracy_score(y_test,y_pred6 )","9df67f38":"X_pred6 = model6.predict(X_train)","065a7861":"accuracy_score(y_train,X_pred6)","cf888156":"gb = GradientBoostingClassifier(n_estimators=30,learning_rate=0.3,max_depth=8,random_state=1)","8019f69d":"model7 = gb.fit(X_train,y_train)","cf78e83a":"y_pred7 = model7.predict(X_test)","5f5fbdc1":"accuracy_score(y_test,y_pred7)","ffff5f96":"X_pred7 = model7.predict(X_train)","b17840f8":"accuracy_score(y_train,X_pred7)","d954bb27":"import xgboost as xgb","adafb8a7":"xgbc = xgb.XGBClassifier(objective='multi:softprob',verbosity=3,n_jobs=-1,subsample=0.8,colsample_bytree=0.5)","8693a8d5":"model8 = xgbc.fit(X_train,y_train)","b14dfd26":"y_pred8 = model8.predict(X_test)","2b4b3a65":"accuracy_score(y_test,y_pred8)","93ffa78f":"sample_submission = model8.predict(test)","393cf068":"sample_submission","7e147ee9":"test_labels = pd.DataFrame(sample_submission,columns=['Label'])","57b8d339":"test_labels.reset_index(inplace=True)","9c50c456":"test_labels.columns = ['ImageId','Label']","1e21c58e":"test_labels.head()\n","705e8697":"test_labels.to_csv('Sample_submission.csv')","0402d9c9":"import os\nos.chdir(r'..\/working')\nfrom IPython.display import FileLink\nFileLink(r'Sample_submission.csv')","c55a749b":"The first column of the training sample indicates the label and rest indicates the pixel values. Hence, we need to split the train data into dependent and independent variables ","feb3339b":"Its is better to normalize data before training for faster convergence.","83fa0089":"we have 42000 data instances in the training set","b3afb1e3":"## Decision Tree Classifier ","5b222889":"testing on the train set shows that model fit perfectly for the training data in fact overfitting the training data.","1e863014":"In the provided dataset, images are represented as csv data where each entry indicates the intensity value of corresponding pixel.\nHence, for a  28\u00d728  image, there will be  28\u00d728=784  pixel values. So the first step is to prepare the data into appropriate form.","926dd6a0":"There are no missing values in the training set.","608c4ddf":"## Random Forest Classifier","87ce64a1":"## Bagging Classifier","d9db7f75":"splitting the training data into train and test set for testing our models performance on split test set.\nsplitting data into 80:20 ratio.","ca883e9e":"our testing sample contains 28000 data instances.\n","79365e72":"Test set also doesn't have any missing values."}}