{"cell_type":{"7cf2ed0c":"code","1d19296e":"code","fbd55376":"code","92f73115":"code","1b2c7b12":"code","273f5874":"code","0a826c85":"code","8b99cb09":"code","4bd81c4c":"code","8c3dc5d7":"code","ce1e8ab1":"code","bee9ce53":"code","420a471a":"code","e37b31e4":"code","2c008cfe":"code","7d2d9b52":"code","a4095128":"code","bcc05d89":"code","95c4c7cf":"code","32415855":"code","18f25812":"code","24ab7994":"code","c4a504c3":"code","a0a31b3e":"code","68d103d0":"code","96997e64":"code","a6d7a615":"code","838eedc6":"code","152c5547":"code","ccaf49cc":"code","2ddd67e0":"code","8367396e":"markdown","77377fa7":"markdown"},"source":{"7cf2ed0c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1d19296e":"# Load the Train set\n\ndf_train = pd.read_csv('\/kaggle\/input\/g-research-crypto-forecasting\/train.csv',nrows = 10000).astype(np.uint8,errors='ignore')\ndf_asset = pd.read_csv('\/kaggle\/input\/g-research-crypto-forecasting\/asset_details.csv')\ndf_sub = pd.read_csv('\/kaggle\/input\/g-research-crypto-forecasting\/example_sample_submission.csv')\n","fbd55376":"df_asset","92f73115":"df_train.shape","1b2c7b12":"df_train.head(5)","273f5874":"df_train.describe()","0a826c85":"df_train['Asset_ID'].value_counts()","8b99cb09":"assetnames = df_train['Asset_ID'].unique()\nassetnames = np.sort(assetnames,kind='quicksort')\nprint(assetnames)","4bd81c4c":"## Find missing data\ntotal = df_train.isnull().sum().sort_values(ascending = False)\npercent = (df_train.isnull().sum()\/ df_train.isnull().count()).sort_values(ascending = False)*100\nmissing_data = pd.concat([total,percent],axis=1, keys = ['Total','Percent'])\nmissing_data","8c3dc5d7":"## Drop Few missing values in target feature\ndf_train = df_train.drop(df_train.loc[df_train['Target'].isnull()].index)\n","ce1e8ab1":"df_train['Date'] = pd.to_datetime(df_train['timestamp'],format =\"%Y\/%m\/%d\")","bee9ce53":"btc = pd.read_csv('\/kaggle\/input\/g-research-crypto-forecasting\/train.csv')\n","420a471a":"from datetime import datetime\nbtc['timestamp'] = [datetime.fromtimestamp(x) for x in btc['timestamp']]\nbtc = btc.set_index('timestamp')\nbtc_daily = btc.resample(\"24H\").mean()","e37b31e4":"### function to impute missing values using interpolation ###\n\ndef fill_missing(df):\n    l = ['Count', 'Open', 'High', 'Low',\n       'Close', 'Volume', 'VWAP','Target']\n    for p in l:\n        df[p] = df[p].interpolate()\n\n    print(df.head())\n    print(df.isnull().sum())\n    \nfill_missing(btc_daily)","2c008cfe":"from statsmodels.tsa.seasonal import seasonal_decompose\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(15,12))\nseries = btc_daily.Target\nresult = seasonal_decompose(series, model='additive',period=1)\nresult.plot()","7d2d9b52":"# Renaming the column names accroding to Prophet's requirements\n\ndaily_data_fb = btc_daily.reset_index()[['timestamp','Target']].rename({'timestamp':'ds','Target':'y'}, axis=1)\ndaily_data_fb.head()","a4095128":"test_length = 365\nsplit_date = \"2020-11-01\"\ntrain_filt = daily_data_fb['ds'] <= split_date\ntest_filt = daily_data_fb['ds'] > split_date\n\ntrain_fb = daily_data_fb[train_filt]\ntest_fb = daily_data_fb[test_filt]\n\nprint(\"train data shape :\", train_fb.shape[0] \/ daily_data_fb.shape[0] * 100)\nprint(\"test data shape :\", test_fb.shape[0] \/ daily_data_fb.shape[0] * 100)","bcc05d89":"!pip install auto-ts\n","95c4c7cf":"!pip install dask-xgboost\nfrom auto_ts import auto_timeseries \n","32415855":"train_fb = train_fb\ntrain_fb.head()","18f25812":"train_fb['ds'] = train_fb['ds'].astype('str')\ntest_fb['ds'] = test_fb['ds'].astype('str')\n","24ab7994":"test_fb = test_fb\ntest_fb.head()","c4a504c3":"train_fb = train_fb.replace(to_replace='None', value=np.nan).dropna()","a0a31b3e":"# model = auto_timeseries(forecast_period=219, score_type='rmse', time_interval='D', model_type='best')\n# model.fit(traindata= train_fb, ts_column=\"ds\", target=\"y\")\n\nautoml_model = auto_timeseries(\n    score_type='rmse',\n    forecast_period=test_length, \n    model_type='best', verbose=0\n)\n\nts_column = 'ds'\ntarget = 'y'\nsep = ','\n\nautoml_model.fit(\n    traindata=train_fb,\n    ts_column=ts_column,\n    target=target,\n    cv=5,\n    sep=',')\n","68d103d0":"y_pred = automl_model.predict(test_fb,model='best')\npredf = pd.DataFrame([test_fb[target].values, y_pred['yhat'].values]).T\npredf.columns = ['Actual','Predicted']\npredf.head()","96997e64":"from auto_ts import print_ts_model_stats\nprint_ts_model_stats(test_fb[target].values, y_pred['yhat'].values,'Best')","a6d7a615":"# Using Best Model\nfuture_predictions = automl_model.predict(\n    testdata=test_fb\n)  \nfuture_predictions","838eedc6":"# Using specific model\nfuture_predictions = automl_model.predict(\n    testdata=test_fb,\n    model='ML',\n    simple=False\n\n)\nfuture_predictions","152c5547":"import copy\nsubm = test_fb[[target]]\nprint(subm.shape)\nsubm.head()","ccaf49cc":"subm['predictions'] = future_predictions['yhat'].values\nsubm[[target,'predictions']].plot(figsize=(15,8))","2ddd67e0":"df_sub['Target'] = test_fb[[target]]\ndf_sub.to_csv('submission.csv')","8367396e":"# Forecast Results","77377fa7":"# Evaluate Results"}}