{"cell_type":{"061833cd":"code","d27be9ed":"code","9b2fa039":"code","1cf667e7":"code","fb340c2c":"code","d24e496f":"code","28cc8b58":"code","ec070c94":"code","03d36153":"code","61b4342d":"markdown","c8d49bed":"markdown","f97f17d3":"markdown","bb5b2672":"markdown","04d0958d":"markdown","194ac799":"markdown","ad330c90":"markdown","e387540c":"markdown","d35fab3f":"markdown","ff695d95":"markdown","992e2ea8":"markdown","057b94ad":"markdown"},"source":{"061833cd":"import numpy as np\n# to read our csv file\nimport pandas as pd\n# matplotlib.pyplot is used for making graphs\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# to train our model\nfrom sklearn.ensemble import RandomForestClassifier\n# to match the predicted value and real value of the predicting variable\nfrom sklearn import metrics","d27be9ed":"dataset = pd.read_csv('..\/input\/wine-quality-selection\/winequality-white.csv')","9b2fa039":"dataset.head(5)","1cf667e7":"dataset.info()","fb340c2c":"data_train = dataset.head(3000)\ndata_test = dataset.tail(1898)","d24e496f":"# choose the columns you want to keep in training set\ncols = ['fixed acidity',\n 'volatile acidity',\n 'citric acid',\n 'residual sugar',\n 'chlorides',\n 'free sulfur dioxide',\n 'total sulfur dioxide',\n 'density',\n 'pH',\n 'sulphates',\n 'alcohol']\nX_train=data_train[cols]\ny_train=data_train.quality\nX_test=data_test[cols]\ny_test=data_test.quality","28cc8b58":"random_forest = RandomForestClassifier(n_estimators=50)  \nrandom_forest.fit(X_train,data_train.quality)\n# generate predictions on the training set\ny_train_pred = random_forest.predict(X_train)\n\n# generate predictions on the test set\ny_test_pred = random_forest.predict(X_test)\n\nmetrics.accuracy_score(y_train,y_train_pred)","ec070c94":"# calculate the accuracy of predictions on test data set\nmetrics.accuracy_score(y_test, y_test_pred)","03d36153":"plt.rc('xtick', labelsize=20)\nplt.rc('ytick', labelsize=20)\ntrain_accuracies = [0]\ntest_accuracies = [0]\n# iterate over a n_estimators values\nfor i in range(1, 25):\n    random_forest = RandomForestClassifier(n_estimators=i)\n    random_forest.fit(X_train, y_train)\n    y_train_pred = random_forest.predict(X_train)\n    y_test_pred = random_forest.predict(X_test)\n    train_accuracy = metrics.accuracy_score(data_train.quality, y_train_pred)\n    test_accuracy = metrics.accuracy_score(y_test, y_test_pred)\n    # append accuracies\n    train_accuracies.append(train_accuracy)\n    test_accuracies.append(test_accuracy)\n# create two plots using matplotlib\nplt.figure(figsize=(10, 5))\nplt.plot(train_accuracies, label=\"training accuracy\")\nplt.plot(test_accuracies, label=\"test accuracy\")\nplt.legend(loc=\"upper left\", prop={'size': 13})\nplt.xticks(range(0, 26, 5))\nplt.xlabel(\"n_estimators\", size=20)\nplt.ylabel(\"accuracy\", size=20)\nplt.show()\n","61b4342d":"## Predictive Modeling\nWe will now train a random forest model on the training set.","c8d49bed":"# Overfitting","f97f17d3":"## Import Necessary Libraries and Data Sets.","bb5b2672":"To explain overfitting, I think it\u2019s best if we look at a dataset and i am going to use a dataset which do not need any feature engineering because our main target is to see overfitting of ml model.\n\nMy dataset is winequality-white.csv and I am going to use random forest model to see overfitting.","04d0958d":"## Graph to see overfitting of ml model","194ac799":"## lets understand whats overfitting is and how it affect our ml model\n<h2 style=\"color:blue\"><center> Don't forget to upvote\ud83d\udcc8 if you like\ud83d\udc4d\ud83c\udffb it! It's free!","ad330c90":"## Now lets see bookish defination\n### Overfitting in Machine Learning\nOverfitting refers to a model that models the training data too well.\n\nOverfitting a model is a condition where a statistical model begins to describe the random error in the data rather than the relationships between variables. This problem occurs when the model is too complex. \n\n### Problems of overfitting in Machine Learning\nIn regression analysis, overfitting can produce misleading R-squared values, regression coefficients, and p-values. ","e387540c":"## Plz Upvote!","d35fab3f":"### This is what we do and stop\n### Therefore are unable to see overfitting of ml model but code below will produce a graph in which we can see overfitting of ml model","ff695d95":"## Divide or split data into training data and test data","992e2ea8":"### For n_estimators equal to 0 for training accuracy and test accuracy a value of 0 is set by me beacuse n_estimators value can not be equal to 0","057b94ad":"The best score for test data for any n_estimators depend on the dataset. As we keep increasing the value of this parameter, test accuracy remains the same or gets worse, but the training accuracy keeps increasing until it becomes 1. It means that our Random Forest Classifier model keeps learning about the training data better and better with an increase in n_estimators untill our training data accuracy becomes one, but the performance on test data does not improve at all after a certain value of n_estimators. \n\nThis is called overfitting."}}