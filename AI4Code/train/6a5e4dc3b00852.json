{"cell_type":{"a61a6486":"code","ff916963":"code","940f5d8e":"code","c0612450":"code","d89e926c":"code","8dcaee87":"code","5d7ca795":"code","87d56b83":"code","f29bd26b":"code","a193d41f":"code","4dbd631c":"code","380067e5":"code","f6fbdf3e":"code","c68589d1":"code","2da23e72":"code","b40645a5":"code","08b19404":"code","fd3dc111":"code","662818b2":"code","cb0d6517":"code","a11b87c0":"code","b7f090dc":"code","9f93afd8":"code","b0fc8444":"code","8b81c33c":"markdown","37bd022a":"markdown","1a6dd85f":"markdown","1543f2e6":"markdown","e30c36c3":"markdown","467dd947":"markdown","8939c7f3":"markdown","21136001":"markdown","a2f88283":"markdown","dd8a3a61":"markdown","61946a1f":"markdown","f1cedfc3":"markdown","efc5abb9":"markdown","7b0d40e6":"markdown","4f88164f":"markdown","86790249":"markdown","9c30af11":"markdown","c5b8fc54":"markdown","11608e63":"markdown","0797c1b9":"markdown","d5f123b4":"markdown","e937f4ad":"markdown","87972197":"markdown"},"source":{"a61a6486":"# load data libraries\nimport numpy as np # linear algebra library\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport zipfile # to read zip files\nfrom sklearn.model_selection import train_test_split\n\n\n# data understanding libraries\nimport matplotlib.pyplot as plt # ploting library\n%matplotlib inline\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom collections import Counter\n\n\n# data preparation\nimport re\nfrom nltk.stem import PorterStemmer\n\n\n# ADS Creation\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.preprocessing import StandardScaler\n\n# Modeling\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.naive_bayes import MultinomialNB\n\n# Evaluation and Model Selection\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\nfrom sklearn import metrics\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import GridSearchCV","ff916963":"pd.set_option('display.max_rows', 10000)\npd.set_option('display.max_columns', 500)\npd.set_option('display.precision',150)\npd.options.display.float_format = '{:,.3f}'.format","940f5d8e":"#unzip the files\narchive_train = zipfile.ZipFile('\/kaggle\/input\/whats-cooking\/train.json.zip')\n\n#read training json file \ntrain = pd.read_json(archive_train.read('train.json'))\n\n#output the frist 5 rows\ntrain.head()","c0612450":"train_data, test_data = train_test_split(train, test_size=0.4, random_state=1)\nval_data, test_data = train_test_split(test_data, test_size=0.5, random_state=1)\n\ntrain_data = train_data.reset_index(drop=True)\nval_data = val_data.reset_index(drop=True)\ntest_data = test_data.reset_index(drop=True)","d89e926c":"print(\"Train set size is \",len(train_data))\nprint(\"Val set size is \",len(val_data))\nprint(\"Test set size is \",len(test_data))","8dcaee87":"train_data.info()","5d7ca795":"# number of unique cuisines\nnum_cuisines = len(train_data['cuisine'].unique())\nprint(\"there are \",num_cuisines,\" unique cuisines.\")","87d56b83":"# let's save list of cuisine names we have\nlabels = train_data['cuisine'].unique()","f29bd26b":"# plot the graph\nfig, ax = plt.subplots(figsize=(15,10)) # create the plot and specify the figure size\nplt.xlabel('Cuisine Name') # specify the x labels\nplt.ylabel('Frequency') # specify the y labels\nplt.title('Frequency of Cuisines') # specify the plot title\nplt.bar(labels,train_data['cuisine'].value_counts()) # create a bar plot\nplt.xticks(rotation=80) # rotate the x labels\nplt.grid() # show the grid\nplt.show() # show the final plot","a193d41f":"# add column with num of ingredienrs per recipe\ntrain_data['ingredients_num'] = train_data[\"ingredients\"].apply(len)\n\n# save list of the unique numbers we have\nnumbers = train_data[\"ingredients\"].apply(len).unique()","4dbd631c":"fig, ax = plt.subplots(figsize=(15,10))\nplt.bar(numbers,train_data[\"ingredients_num\"].value_counts().sort_index())\nplt.xlabel('Ingredients Count')\nplt.ylabel('Number of Recipes')\nplt.title('Number of Recipes per Ingeredients Count')\nplt.xticks(np.arange(min(numbers), max(numbers)+1, 3.0)) # change x labels from the defult to the given range\nplt.grid()\nplt.show()","380067e5":"bins = range(0,70,5)\n\nfig, ax = plt.subplots(figsize=(15,10))\nplt.hist(train_data['ingredients_num'], bins=bins, edgecolor=\"k\") # output a histogram plot\nplt.xlabel('Ingredients Count')\nplt.ylabel('Number of Recipes')\nplt.title('Number of Recipes per Ingeredients Count')\nplt.xticks(bins) # change x labels from the defult to the given range\nplt.grid()\nplt.show()","f6fbdf3e":"print(\"There are \" ,len(train_data[train_data[\"ingredients_num\"]<2]), \" recipes with ingredients less than 2.\")\nprint(\"There are \" ,len(train_data[train_data[\"ingredients_num\"]>30]), \" recipes with ingredients more than 30.\")","c68589d1":"train_data[train_data[\"ingredients_num\"]<2][['ingredients']]","2da23e72":"fig, ax = plt.subplots(figsize=(10,8))\ntrain_data[train_data[\"ingredients_num\"]>=30].groupby(['cuisine']).size().sort_values().plot(kind='barh', ax=ax)\nplt.title('Distribution of Recipes with Ingredients >30 over Cuisines')\nplt.ylabel('Cusine')\nplt.xlabel('Number of Recipes')\nplt.grid()\nplt.show()","b40645a5":"# now let's split all recipes ti have list of ingredients\ningredients = pd.Series((','.join([','.join(row[\"ingredients\"]) for ind,row in train_data.iterrows()])).split(','))\n\nfig, ax = plt.subplots(figsize=(10,8))\nlst = Counter(ingredients).most_common(15)\ndf = pd.DataFrame(lst, columns = ['Ingredient', 'Count'])\ndf.plot.bar(x='Ingredient',y='Count', ax=ax)\nplt.title('15 Most Frequent Ingredient')\nplt.ylabel('Frequency')\nplt.xlabel('Ingredient')\nplt.show()","08b19404":"words = pd.Series(' '.join(ingredients).split())\n\nfig, ax = plt.subplots(figsize=(10,8))\nlst = Counter(words).most_common(15)\ndf = pd.DataFrame(lst, columns = ['Word', 'Count'])\ndf.plot.bar(x='Word',y='Count', ax=ax)\nplt.title('15 Most Frequent Words')\nplt.ylabel('Frequency')\nplt.xlabel('Word')\nplt.show()","fd3dc111":"# words = pd.Series((' '.join([' '.join(row[\"ingredients\"]) for ind,row in train_data.iterrows()])).split())\n# recipies = pd.Series([' , '.join(row[\"ingredients\"]) for ind,row in train_data.iterrows()])\n# ingredients = pd.Series((' '.join([','.join(row[\"ingredients\"]) for ind,row in train_data.iterrows()])).split(','))","662818b2":"wordcloud = WordCloud(width = 1000, height = 500).generate(' '.join(words))\nplt.figure(figsize=(15,8))\nplt.imshow(wordcloud)\nplt.title(\"Most Used Ingredients\")\nplt.axis(\"off\")\nplt.show()","cb0d6517":"counters = {}\nfor cuisine in train_data['cuisine'].unique():\n    counters[cuisine] = Counter()\n    indices = (train_data['cuisine'] == cuisine)\n    for ingredients in train_data[indices]['ingredients']:\n        counters[cuisine].update(ingredients)","a11b87c0":"fig, axes = plt.subplots(4, 5, figsize=(20, 9),sharex='col', sharey='row')\nfor cuisine, ax_index in zip(counters, range(1,21)): \n    wordcloud = WordCloud(background_color=\"white\")\n    wordcloud.generate_from_frequencies(frequencies=counters[cuisine])\n    fig.add_subplot(4, 5, ax_index)    \n    plt.title(cuisine)\n    plt.imshow(wordcloud, interpolation=\"bilinear\")\n    plt.axis(\"off\")","b7f090dc":"train_data['ingredients_txt'] = pd.Series([' , '.join(row[\"ingredients\"]) for ind,row in train_data.iterrows()])","9f93afd8":"top10 = pd.DataFrame([[items[0] for items in counters[cuisine].most_common(10)] for cuisine in counters],\n            index=[cuisine for cuisine in counters],\n            columns=['top{}'.format(i) for i in range(1, 11)])\n\nunique = np.unique(top10.values.ravel())\n\n\nfig, axes = plt.subplots(16, 4, figsize=(15, 80))\nfor ingredient, ax_index in zip(unique, range(64)):\n    indices = train_data['ingredients_txt'].str.contains(ingredient)\n    relative_freq = (train_data[indices]['cuisine'].value_counts() \/ train_data['cuisine'].value_counts())*100\n    relative_freq.plot(kind='bar', ax=axes.ravel()[ax_index], fontsize=7, title=ingredient)","b0fc8444":"choosen = ['avocado', 'cachaca','garam masala', 'ground ginger','sake']\n\nfig, axes = plt.subplots(1, 5, figsize=(20, 5))\nfor ingredient, ax_index in zip(choosen, range(5)):\n    indices = train_data['ingredients_txt'].str.contains(ingredient)\n    relative_freq = (train_data[indices]['cuisine'].value_counts() \/ train_data['cuisine'].value_counts())\n    relative_freq.plot(kind='bar', ax=axes.ravel()[ax_index], fontsize=7, title=ingredient)","8b81c33c":"# 2. Load Data\n### Let's load the data and have a look on it.\n1. data is provieded in a zip file, so we need to unzip it first using zipfile library.\n2. the traning\/ testing files available in json file format, to read it we use pd.read_json function.\n        we read the data into pandas dataframes which is a 2-dimensional labeled data structure with columns of\n        potentially different types. You can think of it like a spreadsheet or SQL table.\n3. to view some rows of the dataframe we use df_name.head() method which output the first 5 rows of the dataframe.","37bd022a":">  So we have multiple outcome from this graph:\n> - the data is skiwed (not balanced), more than half of the cuisines have 1k or less recipes.","1a6dd85f":"The main takeaway from this graph is:\n> tha most frequent ingredients are the assesstent mterials \"like salt, pepper, oil,...\"\n\nNow, let's build up on this information.\n## 2.5 What is the frequancy of the ingredients per cuisine?","1543f2e6":"## 2.2 How many cuisines are there?\n        - df[col].unique() method which returns list of unique values in the selected column.\n        - len(list) function which is simply output the len of any given list.","e30c36c3":"Let's choose the unique ingeredients we want to focus on.","467dd947":"let's see it in another way.","8939c7f3":"# 1. Important imports\n### let's start by importing needed libraries.","21136001":"## Before we start let's agree on some facts:\n1. I'm assuming that you don't have any experiance with python, so I'll add discription for each step in the notebook you can try it yourself later.\n2. Coding style is like a thumbprint everyone of us have his unique way of coding, and is notebook is writen in my style so feel free to use this or any other style you want as long as we are doing the same thing.","a2f88283":"Let's find some interesting takeaways:\n> Salt is the most frequent ingredients in almost all the countries.\n\n> for korea, chaina, japan the most frequent ingredient id the soy sauce.\n\n> for thiland and vietnam the fish sauce.","dd8a3a61":"> The main takeaways are: \n> - There is 23864 records.\n> - There is no nulls in all columns.\n> - only the id in an integer column.","61946a1f":"> There are only 3 columns: id, cuisine and ingredients","f1cedfc3":"> I'll assume that these are not recipes.","efc5abb9":"> Now this have a more obvious information. \n> The idea is not only about analysing the data, it's about how to best describe the data.\n\n> The main takeaways are:\n> - almost 17k out of the 23k recipe have between 5 to 15 ingredients. (~73% of the data)","7b0d40e6":"# What's Cooking?\n\n#### before we start with the problem itself there are some questions we need to answer:\n1. What is the business question?\n2. What each row represent?\n3. What is the evaluation method?\n\n#### for this problem (and all kaggle problems) the answers to these questions is always in the problem's overview page.\n1. What is the category of a dish's cuisine given a list of its ingredients? (Supervised ML Problem)\n2. Each row represent a recipe.\n3. Submissions are evaluated on the categorization accuracy (the percent of dishes that you correctly classify).","4f88164f":"so what are we seeing here?\n> There are some ingredients that's points to some cuisines.","86790249":"Now, let's build up on this information.","9c30af11":"## 2.3 What is the frequency of each cuisine?\n        - df[col].value_counts() returns number of rows for each unique value in the given column.","c5b8fc54":"# 2. Data Understanding\n### The first and most important step in any ML project is understanding the data, so let's try to do this together.\n## 2.1 What is the structure of the data?\n        - df.info() return the main info about the dataframe","11608e63":"## 2.4 How many ingredients per recipes we have?\n        - df[col].apply(funtion) used to apply the given function to all rows of the given column without need to loop.\n        - df.sort_index() sort the dataframe by it's label not it's value, there is another function df.sort_values() to do the opposite.","0797c1b9":"Let's try to view the graph in another way.","d5f123b4":"> So almost half of the reciepies with large number of ingreadients are mexican.","e937f4ad":"## 2.5 What is the frequancy of the \"top ingredients per cuisine\" across the other cuisines?","87972197":"## 2.5 What is the frequancy of the ingredients?"}}