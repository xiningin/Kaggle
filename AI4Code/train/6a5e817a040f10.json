{"cell_type":{"7711cf83":"code","ee4e4828":"code","f638449e":"code","ff92638f":"code","5f9745ff":"code","11637299":"code","12af6d43":"code","32f16658":"code","8a087f78":"code","57985812":"code","0f33a5d3":"code","19782ff1":"code","ea19671e":"code","6839c1aa":"markdown"},"source":{"7711cf83":"import os\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras import layers","ee4e4828":"class CustomDataset(tf.keras.utils.Sequence):\n    def __init__(self, df, directory, batch_size=32, random_state=42, shuffle=True, target=True):\n        np.random.seed(random_state)\n        \n        self.directory = directory\n        self.df = df\n        self.shuffle = shuffle\n        self.target = target\n        self.batch_size = batch_size\n        self.ext = '.npy'\n        \n        self.on_epoch_end()\n    \n    def __len__(self):\n        return np.ceil(self.df.shape[0] \/ self.batch_size).astype(int)\n    \n    def __getitem__(self, idx):\n        start_idx = idx * self.batch_size\n        batch = self.df[start_idx: start_idx + self.batch_size]\n        \n        signals = []\n\n        for fname in batch.id:\n            path = os.path.join(self.directory, fname[0], fname + self.ext)\n            data = np.load(path)\n            signals.append(data)\n        \n        signals = np.stack(signals).astype('float32')\n        \n        if self.target:\n            return signals, batch.target.values\n        else:\n            return signals\n    \n    def on_epoch_end(self):\n        if self.shuffle:\n            self.df = self.df.sample(frac=1).reset_index(drop=True)","f638449e":"def build_model():\n    inputs = layers.Input(shape=(6, 273, 256))\n\n    gru1 = layers.Bidirectional(layers.GRU(128, return_sequences=True))\n    gru2 = layers.Bidirectional(layers.GRU(128, return_sequences=True))\n    pool = layers.GlobalAveragePooling1D()\n\n    x = layers.TimeDistributed(gru1, name=\"bi_gru_1\")(inputs)\n    x = layers.TimeDistributed(gru2, name=\"bi_gru_2\")(x)\n    x = layers.TimeDistributed(pool, name=\"pool\")(x)\n    \n    x = layers.Flatten()(x)\n    x = layers.Dense(128, activation=\"relu\")(x)\n    x = layers.Dense(1, activation=\"sigmoid\", name=\"sigmoid\")(x)\n\n    model = tf.keras.Model(inputs=inputs, outputs=x)\n    \n    return model","ff92638f":"train = pd.read_csv('..\/input\/seti-breakthrough-listen\/train_labels.csv')\nsub = pd.read_csv('..\/input\/seti-breakthrough-listen\/sample_submission.csv')\ntrain.head()","5f9745ff":"sample_df = train.sample(frac=1).reset_index(drop=True)\n\nsplit = int(sample_df.shape[0] * 0.8)\ntrain_df = sample_df[:split]\nvalid_df = sample_df[split:]","11637299":"model = build_model()\nmodel.compile(\"adam\", loss=\"binary_crossentropy\", metrics=[tf.keras.metrics.AUC()])\nmodel.summary()","12af6d43":"train_dset = CustomDataset(\n    train_df, \"..\/input\/seti-breakthrough-listen\/train\", batch_size=64)\n\nvalid_dset = CustomDataset(\n    valid_df, \"..\/input\/seti-breakthrough-listen\/train\", batch_size=64, shuffle=False)\n\ntest_dset = CustomDataset(\n    sub, \"..\/input\/seti-breakthrough-listen\/test\", batch_size=64, target=False, shuffle=False)","32f16658":"ckpt = tf.keras.callbacks.ModelCheckpoint(\n    \"model_weights.h5\", save_best_only=True, save_weights_only=True,\n)\n\ntrain_history = model.fit(\n    train_dset, \n    use_multiprocessing=True, \n    workers=4, \n    epochs=10,\n    validation_data=valid_dset,\n    callbacks=[ckpt],\n)","8a087f78":"import plotly.express as px\npx.line(train_history.history, y=['auc', 'val_auc'], title=\"Training history\")","57985812":"model.load_weights('model_weights.h5')","0f33a5d3":"y_pred = model.predict(\n    test_dset, use_multiprocessing=True, workers=4, verbose=1\n)","19782ff1":"sub['target'] = y_pred","ea19671e":"sub.to_csv('submission.csv', index=False)","6839c1aa":"## Submission"}}