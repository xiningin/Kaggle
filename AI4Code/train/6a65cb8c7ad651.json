{"cell_type":{"7e83847c":"code","61c4e31d":"code","b59dfa0b":"code","c7137bb9":"code","dfa02525":"code","e74692a6":"code","c48c4ada":"code","1ac719fb":"code","0dcb4981":"code","f30837fe":"code","7bef14c6":"code","7e863e70":"code","b7c1e984":"code","b7cb2cef":"code","d4a6bdb9":"code","7749ca7c":"code","5eeb0921":"code","6c0fe4ea":"code","eeefe554":"code","4b312dfd":"code","e224e9fd":"code","3b47e343":"code","b133124b":"code","da6a8691":"code","00b57d70":"code","773d1b2d":"code","42ae1b31":"code","5dbfe7f7":"code","740fe29a":"code","42f34747":"code","101edddd":"code","4f749bed":"code","61e937ce":"code","11f58495":"markdown","b9c14d66":"markdown","5972fcde":"markdown","211c9a20":"markdown","7cb0cfb4":"markdown","56664a05":"markdown","6464448f":"markdown","e551f867":"markdown"},"source":{"7e83847c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport os\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras import layers,models,optimizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array, smart_resize\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\nfrom tensorflow.keras.applications import EfficientNetB7\nfrom tensorflow.keras.preprocessing import image","61c4e31d":"df = pd.read_csv('..\/input\/plant-pathology-2021-fgvc8\/train.csv')\ndf.head()","b59dfa0b":"class_name = df['labels'].value_counts().index\nclass_count = df['labels'].value_counts().values","c7137bb9":"df['labels'] = df['labels'].astype('category')","dfa02525":"df['label_num'] = df['labels'].cat.codes","e74692a6":"df.head()","c48c4ada":"plt.pie(class_count,\n        labels=class_name,\n        autopct='%1.1f%%')\nplt.axis('equal')\nplt.title('Proportion of each observed category')\nplt.show()","1ac719fb":"def load_data(df):    \n    datasets = ['..\/input\/plant-pathology-2021-fgvc8\/train_images', '..\/input\/plant-pathology-2021-fgvc8\/test_images']\n    output = []\n    \n    # Iterate through training and test sets\n    for dataset in datasets:\n        images = []\n        labels = []\n        \n        print(\"Loading {}\".format(dataset))\n        # Iterate through each image in our folder\n        for file in tqdm(os.listdir(dataset)):\n                # Get the path name of the image\n                img_path = os.path.join(dataset, file)\n                \n                # Open and resize the img\n                image = cv2.imread(img_path)\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                image = cv2.resize(image, IMAGE_SIZE) \n                \n                # labeling\n                label = df.loc[df['image']==file, 'label_num']\n                \n                # Append the image and its corresponding label to the output\n                images.append(image)\n                labels.append(label)\n                \n        images = np.array(images, dtype = 'float32')\n        labels = np.array(labels, dtype = 'int32')   \n        \n        output.append((images, labels))\n\n    return output","0dcb4981":"IMAGE_SIZE = (224, 224)\n# IMAGE_SIZE = (600, 600)","f30837fe":"def display_examples(df):\n    fig = plt.figure(figsize=(10,10))\n    fig.suptitle(\"Some examples of images of the dataset\", fontsize=16)\n    for i in range(25):\n        plt.subplot(5,5,i+1)\n        index = np.random.randint(df.shape[0])\n        img_path = df.loc[index,'image']\n        dataset = '..\/input\/plant-pathology-2021-fgvc8\/train_images'\n        img_path = os.path.join(dataset, img_path)\n        img = image.load_img(img_path, target_size=(224, 224))\n        x = image.img_to_array(img)       \n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(x\/255., cmap=plt.cm.binary)\n        plt.xlabel(df.loc[index,'labels'])\n    plt.show()","7bef14c6":"def display_examples_canny(df):\n    fig = plt.figure(figsize=(10,10))\n    fig.suptitle(\"Some examples of images of the dataset\", fontsize=16)\n    for i in range(25):\n        plt.subplot(5,5,i+1)\n        index = np.random.randint(df.shape[0])\n        img_path = df.loc[index,'image']\n        dataset = '..\/input\/plant-pathology-2021-fgvc8\/train_images'\n        img_path = os.path.join(dataset, img_path)\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n        edged = cv2.Canny(gray,30,200)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(edged)\n        plt.xlabel(df.loc[index,'labels'])\n    plt.show()","7e863e70":"def display_examples_mog2(df):\n    algo = 'MOG2'\n    \n    if algo == 'MOG2':\n        backSub = cv2.createBackgroundSubtractorMOG2()\n    else:\n        backSub = cv2.createBackgroundSubtractorKNN()\n    \n    fig = plt.figure(figsize=(10,10))\n    fig.suptitle(\"Some examples of images of the dataset\", fontsize=16)\n    for i in range(25):\n        plt.subplot(5,5,i+1)\n        index = np.random.randint(df.shape[0])\n        img_path = df.loc[index,'image']\n        dataset = '..\/input\/plant-pathology-2021-fgvc8\/train_images'\n        img_path = os.path.join(dataset, img_path)\n        image = cv2.imread(img_path)\n        fgMask = backSub.apply(image)\n        mask = cv2.cvtColor(fgMask, cv2.COLOR_BGR2RGB)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(mask)\n        plt.xlabel(df.loc[index,'labels'])\n    plt.show()","b7c1e984":"def display_examples_grabcut(df):\n    fig = plt.figure(figsize=(10,10))\n    fig.suptitle(\"Some examples of images of the dataset\", fontsize=16)\n    for i in range(25):\n        plt.subplot(5,5,i+1)\n        index = np.random.randint(df.shape[0])\n        img_path = df.loc[index,'image']\n        dataset = '..\/input\/plant-pathology-2021-fgvc8\/train_images'\n        img_path = os.path.join(dataset, img_path)\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, dsize=(600, 600), interpolation=cv2.INTER_AREA)\n        \n        rectangle = (0, 0, 500, 500)\n        mask = np.zeros(image.shape[:2], np.uint8)\n        bgdModel = np.zeros((1, 65), np.float64)\n        fgdModel = np.zeros((1, 65), np.float64)\n        cv2.grabCut(image, mask, rectangle, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n        mask_2 = np.where((mask==2) | (mask==0), 0, 1).astype('uint8')\n        image_nobg = image * mask_2[:, :, np.newaxis]\n\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(image_nobg)\n        plt.xlabel(df.loc[index,'labels'])\n    plt.show()","b7cb2cef":"# display_examples(df)","d4a6bdb9":"# display_examples_canny(df)","7749ca7c":"# display_examples_mog2(df)","5eeb0921":"# display_examples_grabcut(df)","6c0fe4ea":"train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/225,rotation_range=20,\n                                                                width_shift_range=0.2,height_shift_range=0.2,\n                                                                shear_range=0.2,zoom_range=0.2,horizontal_flip=True,\n                                                                validation_split=0.4)\n\ntest_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255)","eeefe554":"train_dir = '..\/input\/plant-pathology-2021-fgvc8\/train_images'","4b312dfd":"train_generator = train_datagen.flow_from_dataframe(dataframe=df,\n                                                    directory=train_dir,\n                                                    subset='training',\n                                                    x_col=\"image\",\n                                                    y_col=\"labels\",\n                                                    shuffle=True,\n                                                    target_size=IMAGE_SIZE,\n                                                    batch_size=64,\n                                                    class_mode='categorical')\n\nval_generator = train_datagen.flow_from_dataframe(dataframe=df,\n                                                    directory=train_dir,\n                                                    subset=\"validation\",\n                                                    x_col=\"image\",\n                                                    y_col=\"labels\",\n                                                    shuffle=True,\n                                                    target_size=IMAGE_SIZE,\n                                                    batch_size=64,\n                                                    class_mode='categorical')","e224e9fd":"def plot_hist(hist):\n    plt.plot(hist.history[\"accuracy\"])\n    plt.plot(hist.history[\"val_accuracy\"])\n    plt.title(\"model accuracy\")\n    plt.ylabel(\"accuracy\")\n    plt.xlabel(\"epoch\")\n    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n    plt.show()","3b47e343":"model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu', input_shape = (224, 224, 3)), \n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(12, activation=tf.nn.softmax)\n])\n\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])","b133124b":"def create_callbacks():\n    \n    cpk_path = '.\/best_model.h5'\n    \n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath=cpk_path,\n        monitor='val_accuracy',\n        mode='max',\n        save_best_only=True,\n        verbose=1,\n    )\n\n    reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor='val_accuracy',\n        mode='max',\n        factor=0.1,\n        patience=3,\n        verbose=0\n    )\n\n    earlystop = tf.keras.callbacks.EarlyStopping(\n        monitor='val_accuracy',\n        mode='max',\n        patience=3, \n        verbose=1\n    )\n    \n    callbacks = [checkpoint, reducelr, earlystop]         \n    \n    return callbacks","da6a8691":"epochs = 100\n\nhist = model.fit_generator(train_generator, epochs=epochs, steps_per_epoch=50,\n                           validation_data=val_generator, validation_steps=20,\n                           callbacks=create_callbacks())","00b57d70":"plot_hist(hist)","773d1b2d":"submission = pd.read_csv(\"..\/input\/plant-pathology-2021-fgvc8\/sample_submission.csv\")\nsubmission.head()","42ae1b31":"test_dir = '..\/input\/plant-pathology-2021-fgvc8\/test_images'\npred = []\nmodel = models.load_model('.\/best_model.h5')","5dbfe7f7":"for image in os.listdir(test_dir):\n    path = os.path.join(test_dir, image)\n    img = load_img(path)\n    img = img_to_array(img)\n    img = smart_resize(img, (600,600))\n    img = tf.reshape(img, (-1, 600, 600, 3))\n    temp = model.predict(img\/255.)\n    temp = np.argmax(temp)\n    pred = np.append(pred,temp)","740fe29a":"submission_result = pd.DataFrame({'image' : submission.image, 'labels' : pred})\nsubmission_result['labels'] = submission_result['labels'].astype(int)\nclass_map = dict(sorted(df[['label_num', 'labels']].values.tolist()))\nsubmission_result['labels'] = submission_result['labels'].map(class_map)\nsubmission_result.to_csv('submission.csv', index=False)","42f34747":"print(\"Competetion Complete!!\")","101edddd":"# inputs = layers.Input(shape=(600, 600, 3))\n# model = EfficientNetB7(weights='imagenet', input_tensor=inputs, include_top=False)\n# model.trainable = False\n# x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n# x = layers.Flatten(name=\"Flatten\")(model.output)\n# x = layers.Dense(64,activation='relu')(x)\n# x = layers.Dense(32,activation='relu')(x)\n# x = layers.Dense(16,activation='relu')(x)\n# outputs = layers.Dense(12, activation=\"softmax\", name=\"pred\")(x)\n# model = models.Model(inputs, outputs, name=\"EfficientB7\")\n# optimizer = optimizers.Adam(learning_rate=1e-2)\n# model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","4f749bed":"# epochs = 100\n\n# hist = model.fit_generator(train_generator, epochs=epochs, steps_per_epoch=10,\n#                            validation_data=val_generator, validation_steps=5, \n#                            callbacks=create_callbacks())","61e937ce":"# plot_hist(hist)","11f58495":"> Load data function... but this code is not use this code.","b9c14d66":"> I\u2019m working on it.","5972fcde":"## 1. Load library","211c9a20":"## 2.Read csv and EDA","7cb0cfb4":"> In this code, I want to find how to improve classification using opencv function. But I can't find....","56664a05":"## 4.Image data generate","6464448f":"## 3. Image display","e551f867":"## 3. Define function"}}