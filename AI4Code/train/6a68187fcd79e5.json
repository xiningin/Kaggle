{"cell_type":{"e81c1581":"code","59c25e68":"code","1b07cb09":"code","ff19ba83":"code","c2f3a54b":"code","f3b7a29e":"code","ab6c271d":"code","7a98e1be":"code","cfc1bcf8":"code","afa66670":"code","8c701124":"code","264cc8f7":"code","15c8a8f1":"code","0e94bcbd":"code","d00564bd":"code","5d24c5e8":"markdown","b9f1c12b":"markdown","1222b914":"markdown","18fe6978":"markdown","22579447":"markdown","a9cc7990":"markdown","0aea62bd":"markdown","86d3b20e":"markdown","18282e77":"markdown","ae472e81":"markdown"},"source":{"e81c1581":"!pip install transformers -q","59c25e68":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport os\nimport torch\nimport torch.optim as optim\nimport random\n\nimport fastai\nfrom fastai import *\nfrom fastai.text import *\nfrom fastai.callbacks import *\n\nimport transformers\nfrom transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\nfrom transformers import BertForSequenceClassification, BertTokenizer, BertConfig","1b07cb09":"def seed_all(seed_value):\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    torch.manual_seed(seed_value)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed_value)\n        torch.cuda.manual_seed_all(seed_value)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n        \nseed_all(42)","ff19ba83":"PATH = Path('..\/input\/jigsaw-multilingual-toxic-comment-classification')\ndf_train = pd.read_csv(PATH\/'jigsaw-toxic-comment-train.csv')\ndf_train = df_train.drop(['severe_toxic','obscene','threat','insult','identity_hate'], axis=1)\ndf_train['valid'] = False\n\ndf_valid = pd.read_csv(PATH\/'validation.csv')\ndf_valid = df_valid.drop(['lang'], axis=1)\ndf_valid['valid'] = True\n\ndf_test =  pd.read_csv(PATH\/'test.csv')\ndf_train_all = pd.concat([df_train, df_valid], axis=0)","c2f3a54b":"model_class     = BertForSequenceClassification\ntokenizer_class = BertTokenizer\nconfig_class    = BertConfig","f3b7a29e":"class TransformersBaseTokenizer(BaseTokenizer):\n    \"\"\"\n    Wrapper around PreTrainedTokenizer to be compatible with fastai.\n    \"\"\"\n    \n    def __init__(self, pretrained_tokenizer, **kwargs):\n        self._pretrained_tokenizer = pretrained_tokenizer\n        self.max_seq_len = pretrained_tokenizer.max_len\n        \n    def __call__(self, *args, **kwargs):\n        return self\n    \n    def tokenizer(self, t:str) -> List[str]:  # replace the `tokenizer` function in the parent class\n        \"\"\"\n        Limits the maximum sequence length and add the special tokens\n        \"\"\"\n        # Get the CLS and SEP tokens\n        CLS = self._pretrained_tokenizer.cls_token  # method found in `pretrained_tokenizer`\n        SEP = self._pretrained_tokenizer.sep_token\n        \n        # tokenize the string `t` pass into this function\n        tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n        \n        return [CLS] + tokens + [SEP]\n    \ntransformer_tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')\ntransformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer=transformer_tokenizer)\nfastai_tokenizer = Tokenizer(tok_func=transformer_base_tokenizer, pre_rules=[], post_rules=[])","ab6c271d":"class TransformersVocab(Vocab):\n    def __init__(self, tokenizer: PreTrainedTokenizer):\n        super().__init__(itos=[])\n        self.tokenizer = tokenizer\n        \n    def numericalize(self, t:Collection[str]) -> List[int]:\n        \"Convert a list of tokens `t` into their ids.\"\n        return self.tokenizer.convert_tokens_to_ids(t)\n    \n    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n        \"Convert a list of `nums` to their tokens.\"\n        nums = np.array(nums).tolist()\n        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums) \n    \n    def __getstate__(self):\n        return {'itos':self.itos, 'tokenizer':self.tokenizer}\n\n    def __setstate__(self, state:dict):\n        self.itos = state['itos']\n        self.tokenizer = state['tokenizer']\n        self.stoi = collections.defaultdict(int,{v:k for k,v in enumerate(self.itos)})","7a98e1be":"transformer_vocab      = TransformersVocab(tokenizer=transformer_tokenizer)\nnumericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)   # fastai\ntokenize_processor     = TokenizeProcessor(tokenizer=fastai_tokenizer,\n                                           include_bos=False,\n                                           include_eos=False)\ntransformers_processor = [tokenize_processor, numericalize_processor]","cfc1bcf8":"databunch = load_data(path='', file='..\/input\/fastai-dataloaders\/jigsaw_data.pkl', \n                      bs=32, pad_first=False, pad_idx=transformer_tokenizer.pad_token_id)","afa66670":"# databunch = (TextList.from_df(df_train_all, cols='comment_text', processor=transformers_processor)\n#              .split_from_df(col='valid')\n#              .label_from_df(cols=['toxic'])\n#              .add_test(df_test)\n#              .databunch(bs=32, pad_first=False, pad_idx=transformer_tokenizer.pad_token_id))","8c701124":"class CustomTransformerModel(nn.Module):\n    def __init__(self, transformer_model: PreTrainedModel):\n        super().__init__()\n        self.transformer = transformer_model\n        \n    def forward(self, input_ids):\n        logits = self.transformer(input_ids)[0] # first element of the output tuple: `last_hidden_state` - from the docs\n        return logits","264cc8f7":"config = BertConfig.from_pretrained('bert-base-multilingual-uncased')\nconfig.num_labels = 2\ntransformer_model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-uncased', config=config)\ncustom_transformer_model = CustomTransformerModel(transformer_model)","15c8a8f1":"from transformers import AdamW\nlearner = Learner(    data = databunch, \n                     model = custom_transformer_model, \n                  opt_func = lambda input:AdamW(input, correct_bias=False),\n                   metrics = AUROC())\nlearner.model_dir = '..\/input\/models\/'\nlearner.load('bert_fastai_unfrozen_last_12')","0e94bcbd":"def get_preds_as_nparray(ds_type) -> np.ndarray:\n    preds = learner.get_preds(ds_type)[0].detach().cpu().numpy()\n    sampler = [i for i in databunch.dl(ds_type).sampler]\n    reverse_sampler = np.argsort(sampler)\n    return preds[reverse_sampler, :]\n\ntest_preds = get_preds_as_nparray(DatasetType.Test)","d00564bd":"sample_submission = pd.read_csv(PATH\/'sample_submission.csv')\nsample_submission['toxic'] = test_preds[:,1] \nsample_submission.to_csv('submission.csv', index=False)","5d24c5e8":"### Import","b9f1c12b":"#### Custom processor","1222b914":"### **Data pre-processing**\n","18fe6978":"### Setting up the DataBunch","22579447":"### Prediction","a9cc7990":"#### Custom Numericalizer","0aea62bd":"### Custom Model","86d3b20e":"### Prepare everything","18282e77":"#### **Custom Tokenizer**","ae472e81":"### Learner : Custom Optimizer \/ Custom Metric"}}