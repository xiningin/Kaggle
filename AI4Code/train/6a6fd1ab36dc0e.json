{"cell_type":{"fa386c2e":"code","0c4ee1bb":"code","c5e14751":"code","d596aa6d":"code","282692d0":"code","ecf2da2c":"code","6788aef8":"code","99ebe9d2":"code","6471bea9":"code","e99841cb":"code","8c5f0e16":"code","cbfc4dc2":"code","5e01f78b":"code","5d4583c5":"code","d04ec8d6":"code","eb026693":"code","8e40566f":"code","1ce5b9af":"code","5019a360":"code","415bfbec":"code","4d346a1c":"code","72ca33f8":"code","0aefa1c0":"code","1b1a03fc":"markdown","2a4f4852":"markdown","9fd2deae":"markdown","49c319b2":"markdown","eb78550a":"markdown","ff7c93b8":"markdown","71bc8a7b":"markdown","6aab7e27":"markdown","f3be041a":"markdown","6506b5e6":"markdown","f08bd9c6":"markdown","fdcfc336":"markdown","0e5d377f":"markdown","aa9cfe8d":"markdown","7039d88a":"markdown","e1dc3533":"markdown","b32f2f9a":"markdown","a6c6e37a":"markdown","c27264c1":"markdown","c2bc1dd1":"markdown","4551e62e":"markdown","4ff8e349":"markdown","cd4bf5ca":"markdown","8c467b26":"markdown","b809f625":"markdown","fc77f605":"markdown","2d9a0658":"markdown","8cce6dd9":"markdown","9d4c92c1":"markdown","56a2241a":"markdown","5b60492d":"markdown"},"source":{"fa386c2e":"import pandas as pd\nimport numpy as np\nimport os\nimport seaborn as sns\nfrom tqdm import tqdm, tqdm_notebook\nimport matplotlib.pyplot as plt\nimport plotly_express as px\nimport seaborn as sns\nimport plotly.offline as py\nimport plotly.tools as tls\nfrom plotly.offline import init_notebook_mode\nimport plotly.graph_objs as go\nimport palettable\nfrom IPython.display import HTML\nimport json\nfrom  altair.vega import v5\nimport plotly.figure_factory as ff\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport altair as alt\nfrom collections import Counter","0c4ee1bb":"stop =[\"a\",\"about\",\"above\",\"after\",\"again\",\"against\",\"ain\",\"all\",\"am\",\"an\",\"and\",\"any\",\"are\",\"aren\",\"aren't\",\"as\",\"at\",\"be\",\"because\",\"been\",\"before\",\"being\",\"below\",\"between\",\"both\",\"but\",\"by\",\"can\",\"couldn\",\"couldn't\",\"d\",\"did\",\"didn\",\"didn't\",\"do\",\"does\",\"doesn\",\"doesn't\",\"doing\",\"don\",\"don't\",\"down\",\"during\",\"each\",\"few\",\"for\",\"from\",\"further\",\"had\",\"hadn\",\"hadn't\",\"has\",\"hasn\",\"hasn't\",\"have\",\"haven\",\"haven't\",\"having\",\"he\",\"her\",\"here\",\"hers\",\"herself\",\"him\",\"himself\",\"his\",\"how\",\"i\",\"if\",\"in\",\"into\",\"is\",\"isn\",\"isn't\",\"it\",\"it's\",\"its\",\"itself\",\"just\",\"ll\",\"m\",\"ma\",\"me\",\"mightn\",\"mightn't\",\"more\",\"most\",\"mustn\",\"mustn't\",\"my\",\"myself\",\"needn\",\"needn't\",\"no\",\"nor\",\"not\",\"now\",\"o\",\"of\",\"off\",\"on\",\"once\",\"only\",\"or\",\"other\",\"our\",\"ours\",\"ourselves\",\"out\",\"over\",\"own\",\"re\",\"s\",\"same\",\"shan\",\"shan't\",\"she\",\"she's\",\"should\",\"should've\",\"shouldn\",\"shouldn't\",\"so\",\"some\",\"such\",\"t\",\"than\",\"that\",\"that'll\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"there\",\"these\",\"they\",\"this\",\"those\",\"through\",\"to\",\"too\",\"under\",\"until\",\"up\",\"ve\",\"very\",\"was\",\"wasn\",\"wasn't\",\"we\",\"were\",\"weren\",\"weren't\",\"what\",\"when\",\"where\",\"which\",\"while\",\"who\",\"whom\",\"why\",\"will\",\"with\",\"won\",\"won't\",\"wouldn\",\"wouldn't\",\"y\",\"you\",\"you'd\",\"you'll\",\"you're\",\"you've\",\"your\",\"yours\",\"yourself\",\"yourselves\",\"could\",\"he'd\",\"he'll\",\"he's\",\"here's\",\"how's\",\"i'd\",\"i'll\",\"i'm\",\"i've\",\"let's\",\"ought\",\"she'd\",\"she'll\",\"that's\",\"there's\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"we'd\",\"we'll\",\"we're\",\"we've\",\"what's\",\"when's\",\"where's\",\"who's\",\"why's\",\"would\",\"able\",\"abst\",\"accordance\",\"according\",\"accordingly\",\"across\",\"act\",\"actually\",\"added\",\"adj\",\"affected\",\"affecting\",\"affects\",\"afterwards\",\"ah\",\"almost\",\"alone\",\"along\",\"already\",\"also\",\"although\",\"always\",\"among\",\"amongst\",\"announce\",\"another\",\"anybody\",\"anyhow\",\"anymore\",\"anyone\",\"anything\",\"anyway\",\"anyways\",\"anywhere\",\"apparently\",\"approximately\",\"arent\",\"arise\",\"around\",\"aside\",\"ask\",\"asking\",\"auth\",\"available\",\"away\",\"awfully\",\"b\",\"back\",\"became\",\"become\",\"becomes\",\"becoming\",\"beforehand\",\"begin\",\"beginning\",\"beginnings\",\"begins\",\"behind\",\"believe\",\"beside\",\"besides\",\"beyond\",\"biol\",\"brief\",\"briefly\",\"c\",\"ca\",\"came\",\"cannot\",\"can't\",\"cause\",\"causes\",\"certain\",\"certainly\",\"co\",\"com\",\"come\",\"comes\",\"contain\",\"containing\",\"contains\",\"couldnt\",\"date\",\"different\",\"done\",\"downwards\",\"due\",\"e\",\"ed\",\"edu\",\"effect\",\"eg\",\"eight\",\"eighty\",\"either\",\"else\",\"elsewhere\",\"end\",\"ending\",\"enough\",\"especially\",\"et\",\"etc\",\"even\",\"ever\",\"every\",\"everybody\",\"everyone\",\"everything\",\"everywhere\",\"ex\",\"except\",\"f\",\"far\",\"ff\",\"fifth\",\"first\",\"five\",\"fix\",\"followed\",\"following\",\"follows\",\"former\",\"formerly\",\"forth\",\"found\",\"four\",\"furthermore\",\"g\",\"gave\",\"get\",\"gets\",\"getting\",\"give\",\"given\",\"gives\",\"giving\",\"go\",\"goes\",\"gone\",\"got\",\"gotten\",\"h\",\"happens\",\"hardly\",\"hed\",\"hence\",\"hereafter\",\"hereby\",\"herein\",\"heres\",\"hereupon\",\"hes\",\"hi\",\"hid\",\"hither\",\"home\",\"howbeit\",\"however\",\"hundred\",\"id\",\"ie\",\"im\",\"immediate\",\"immediately\",\"importance\",\"important\",\"inc\",\"indeed\",\"index\",\"information\",\"instead\",\"invention\",\"inward\",\"itd\",\"it'll\",\"j\",\"k\",\"keep\",\"keeps\",\"kept\",\"kg\",\"km\",\"know\",\"known\",\"knows\",\"l\",\"largely\",\"last\",\"lately\",\"later\",\"latter\",\"latterly\",\"least\",\"less\",\"lest\",\"let\",\"lets\",\"like\",\"liked\",\"likely\",\"line\",\"little\",\"'ll\",\"look\",\"looking\",\"looks\",\"ltd\",\"made\",\"mainly\",\"make\",\"makes\",\"many\",\"may\",\"maybe\",\"mean\",\"means\",\"meantime\",\"meanwhile\",\"merely\",\"mg\",\"might\",\"million\",\"miss\",\"ml\",\"moreover\",\"mostly\",\"mr\",\"mrs\",\"much\",\"mug\",\"must\",\"n\",\"na\",\"name\",\"namely\",\"nay\",\"nd\",\"near\",\"nearly\",\"necessarily\",\"necessary\",\"need\",\"needs\",\"neither\",\"never\",\"nevertheless\",\"new\",\"next\",\"nine\",\"ninety\",\"nobody\",\"non\",\"none\",\"nonetheless\",\"noone\",\"normally\",\"nos\",\"noted\",\"nothing\",\"nowhere\",\"obtain\",\"obtained\",\"obviously\",\"often\",\"oh\",\"ok\",\"okay\",\"old\",\"omitted\",\"one\",\"ones\",\"onto\",\"ord\",\"others\",\"otherwise\",\"outside\",\"overall\",\"owing\",\"p\",\"page\",\"pages\",\"part\",\"particular\",\"particularly\",\"past\",\"per\",\"perhaps\",\"placed\",\"please\",\"plus\",\"poorly\",\"possible\",\"possibly\",\"potentially\",\"pp\",\"predominantly\",\"present\",\"previously\",\"primarily\",\"probably\",\"promptly\",\"proud\",\"provides\",\"put\",\"q\",\"que\",\"quickly\",\"quite\",\"qv\",\"r\",\"ran\",\"rather\",\"rd\",\"readily\",\"really\",\"recent\",\"recently\",\"ref\",\"refs\",\"regarding\",\"regardless\",\"regards\",\"related\",\"relatively\",\"research\",\"respectively\",\"resulted\",\"resulting\",\"results\",\"right\",\"run\",\"said\",\"saw\",\"say\",\"saying\",\"says\",\"sec\",\"section\",\"see\",\"seeing\",\"seem\",\"seemed\",\"seeming\",\"seems\",\"seen\",\"self\",\"selves\",\"sent\",\"seven\",\"several\",\"shall\",\"shed\",\"shes\",\"show\",\"showed\",\"shown\",\"showns\",\"shows\",\"significant\",\"significantly\",\"similar\",\"similarly\",\"since\",\"six\",\"slightly\",\"somebody\",\"somehow\",\"someone\",\"somethan\",\"something\",\"sometime\",\"sometimes\",\"somewhat\",\"somewhere\",\"soon\",\"sorry\",\"specifically\",\"specified\",\"specify\",\"specifying\",\"still\",\"stop\",\"strongly\",\"sub\",\"substantially\",\"successfully\",\"sufficiently\",\"suggest\",\"sup\",\"sure\",\"take\",\"taken\",\"taking\",\"tell\",\"tends\",\"th\",\"thank\",\"thanks\",\"thanx\",\"thats\",\"that've\",\"thence\",\"thereafter\",\"thereby\",\"thered\",\"therefore\",\"therein\",\"there'll\",\"thereof\",\"therere\",\"theres\",\"thereto\",\"thereupon\",\"there've\",\"theyd\",\"theyre\",\"think\",\"thou\",\"though\",\"thoughh\",\"thousand\",\"throug\",\"throughout\",\"thru\",\"thus\",\"til\",\"tip\",\"together\",\"took\",\"toward\",\"towards\",\"tried\",\"tries\",\"truly\",\"try\",\"trying\",\"ts\",\"twice\",\"two\",\"u\",\"un\",\"unfortunately\",\"unless\",\"unlike\",\"unlikely\",\"unto\",\"upon\",\"ups\",\"us\",\"use\",\"used\",\"useful\",\"usefully\",\"usefulness\",\"uses\",\"using\",\"usually\",\"v\",\"value\",\"various\",\"'ve\",\"via\",\"viz\",\"vol\",\"vols\",\"vs\",\"w\",\"want\",\"wants\",\"wasnt\",\"way\",\"wed\",\"welcome\",\"went\",\"werent\",\"whatever\",\"what'll\",\"whats\",\"whence\",\"whenever\",\"whereafter\",\"whereas\",\"whereby\",\"wherein\",\"wheres\",\"whereupon\",\"wherever\",\"whether\",\"whim\",\"whither\",\"whod\",\"whoever\",\"whole\",\"who'll\",\"whomever\",\"whos\",\"whose\",\"widely\",\"willing\",\"wish\",\"within\",\"without\",\"wont\",\"words\",\"world\",\"wouldnt\",\"www\",\"x\",\"yes\",\"yet\",\"youd\",\"youre\",\"z\",\"zero\",\"a's\",\"ain't\",\"allow\",\"allows\",\"apart\",\"appear\",\"appreciate\",\"appropriate\",\"associated\",\"best\",\"better\",\"c'mon\",\"c's\",\"cant\",\"changes\",\"clearly\",\"concerning\",\"consequently\",\"consider\",\"considering\",\"corresponding\",\"course\",\"currently\",\"definitely\",\"described\",\"despite\",\"entirely\",\"exactly\",\"example\",\"going\",\"greetings\",\"hello\",\"help\",\"hopefully\",\"ignored\",\"inasmuch\",\"indicate\",\"indicated\",\"indicates\",\"inner\",\"insofar\",\"it'd\",\"keep\",\"keeps\",\"novel\",\"presumably\",\"reasonably\",\"second\",\"secondly\",\"sensible\",\"serious\",\"seriously\",\"sure\",\"t's\",\"third\",\"thorough\",\"thoroughly\",\"three\",\"well\",\"wonder\"]\n","c5e14751":"df = pd.read_csv('..\/input\/netflix-shows\/netflix_titles.csv')","d596aa6d":"#Taken From: https:\/\/www.kaggle.com\/shivamb\/netflix-shows-and-movies-exploratory-analysis\n\ndf['date_added'] = pd.to_datetime(df.date_added)\ndf['year_added'] = df.date_added.dt.year\ndf['month_added'] = df.date_added.dt.month\n\ndf['season_count'] = df.apply(lambda x : x['duration'].split(\" \")[0] if \"Season\" in x['duration'] else \"\", axis = 1)\ndf['duration'] = df.apply(lambda x : x['duration'].split(\" \")[0] if \"Season\" not in x['duration'] else \"\", axis = 1)\n","282692d0":"df.head()","ecf2da2c":"#Finding Number of rows and columns\nprint(\"Dataset contains {} rows and {} columns\".format(df.shape[0], df.shape[1]))\n","6788aef8":"df.isnull().sum()","99ebe9d2":"##-----------------------------------------------------------\n# This whole section \nvega_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega@' + v5.SCHEMA_VERSION\nvega_lib_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-lib'\nvega_lite_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-lite@' + alt.SCHEMA_VERSION\nvega_embed_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-embed@3'\nnoext = \"?noext\"\n\npaths = {\n    'vega': vega_url + noext,\n    'vega-lib': vega_lib_url + noext,\n    'vega-lite': vega_lite_url + noext,\n    'vega-embed': vega_embed_url + noext\n}\n\nworkaround = \"\"\"\nrequirejs.config({{\n    baseUrl: 'https:\/\/cdn.jsdelivr.net\/npm\/',\n    paths: {}\n}});\n\"\"\"\n\n#------------------------------------------------ Defs for future rendering\ndef add_autoincrement(render_func):\n    # Keep track of unique <div\/> IDs\n    cache = {}\n    def wrapped(chart, id=\"vega-chart\", autoincrement=True):\n        if autoincrement:\n            if id in cache:\n                counter = 1 + cache[id]\n                cache[id] = counter\n            else:\n                cache[id] = 0\n            actual_id = id if cache[id] == 0 else id + '-' + str(cache[id])\n        else:\n            if id not in cache:\n                cache[id] = 0\n            actual_id = id\n        return render_func(chart, id=actual_id)\n    # Cache will stay outside and \n    return wrapped\n            \n@add_autoincrement\ndef render(chart, id=\"vega-chart\"):\n    chart_str = \"\"\"\n    <div id=\"{id}\"><\/div><script>\n    require([\"vega-embed\"], function(vg_embed) {{\n        const spec = {chart};     \n        vg_embed(\"#{id}\", spec, {{defaultStyle: true}}).catch(console.warn);\n        console.log(\"anything?\");\n    }});\n    console.log(\"really...anything?\");\n    <\/script>\n    \"\"\"\n    return HTML(\n        chart_str.format(\n            id=id,\n            chart=json.dumps(chart) if isinstance(chart, dict) else chart.to_json(indent=None)\n        )\n    )\n\n\n\nHTML(\"\".join((\n    \"<script>\",\n    workaround.format(json.dumps(paths)),\n    \"<\/script>\")))","6471bea9":"# Necessary Functions: \ndef pie_plot(labels, values, colors, title):\n    fig = {\n      \"data\": [\n        {\n          \"values\": values,\n          \"labels\": labels,\n          \"domain\": {\"x\": [0, .48]},\n          \"name\": \"Job Type\",\n          \"sort\": False,\n          \"marker\": {'colors': colors},\n          \"textinfo\":\"percent+label+value\",\n          \"textfont\": {'color': '#FFFFFF', 'size': 10},\n          \"hole\": .6,\n          \"type\": \"pie\"\n        } ],\n        \"layout\": {\n            \"title\":title,\n            \"annotations\": [\n                {\n                    \"font\": {\n                        \"size\": 25,\n\n                    },\n                    \"showarrow\": False,\n                    \"text\": \"\"\n\n                }\n            ]\n        }\n    }\n    return fig\n\n\ndef word_cloud(df, pixwidth=6000, pixheight=350, column=\"index\", counts=\"count\"):\n    data= [dict(name=\"dataset\", values=df.to_dict(orient=\"records\"))]\n    wordcloud = {\n        \"$schema\": \"https:\/\/vega.github.io\/schema\/vega\/v5.json\",\n        \"width\": pixwidth,\n        \"height\": pixheight,\n        \"padding\": 0,\n        \"title\": \"Hover to see number of occureances from all the sequences\",\n        \"data\": data\n    }\n    scale = dict(\n        name=\"color\",\n        type=\"ordinal\",\n        range=[\"cadetblue\", \"royalblue\", \"steelblue\", \"navy\", \"teal\"]\n    )\n    mark = {\n        \"type\":\"text\",\n        \"from\":dict(data=\"dataset\"),\n        \"encode\":dict(\n            enter=dict(\n                text=dict(field=column),\n                align=dict(value=\"center\"),\n                baseline=dict(value=\"alphabetic\"),\n                fill=dict(scale=\"color\", field=column),\n                tooltip=dict(signal=\"datum.count + ' occurrances'\")\n            )\n        ),\n        \"transform\": [{\n            \"type\": \"wordcloud\",\n            \"text\": dict(field=column),\n            \"size\": [pixwidth, pixheight],\n            \"font\": \"Helvetica Neue, Arial\",\n            \"fontSize\": dict(field=\"datum.{}\".format(counts)),\n            \"fontSizeRange\": [10, 60],\n            \"padding\": 2\n        }]\n    }\n    wordcloud[\"scales\"] = [scale]\n    wordcloud[\"marks\"] = [mark]\n    \n    return wordcloud\n\nfrom collections import defaultdict\n\ndef wordcloud_create(df):\n    ult = {}\n    corpus = df.description.values.tolist()\n    final = defaultdict(int) #Declaring an empty dictionary for count (Saves ram usage)\n    for words in corpus:\n        for word in words.split():\n             final[word]+=1\n    temp = Counter(final)\n    for k, v in  temp.most_common(200):\n        ult[k] = v\n    corpus = pd.Series(ult) #Creating a dataframe from the final default dict\n    return render(word_cloud(corpus.to_frame(name=\"count\").reset_index(), pixheight=600, pixwidth=900))\n\n","e99841cb":"value_counts = df['type'].value_counts()\nlabels = value_counts.index.tolist()\npy.iplot(pie_plot(labels, value_counts,['#1B9E77', '#7570B3'], \"Type Distribution\"))","8c5f0e16":"top_work_unitdf = df['country'].value_counts().rename_axis('Country').reset_index(name='counts')[:10]\n\nfig = px.bar(top_work_unitdf, y=\"Country\", x='counts', orientation='h', title = \"Country with the most number of titles\",color=  \"counts\", color_continuous_scale=px.colors.qualitative.Prism).update_yaxes(categoryorder=\"total ascending\")\n\nfig.show()","cbfc4dc2":"top_months = df['month_added'].value_counts().rename_axis('Month_Added').reset_index(name='counts')\n\nfig = px.bar(top_months, y=\"counts\", x='Month_Added', title = \"Country with the most number of titles\",color=  \"counts\", color_continuous_scale=px.colors.qualitative.D3).update_yaxes(categoryorder=\"total ascending\")\n\nfig.show()","5e01f78b":"mov = df[df.type =='Movie']\nmov_dur = mov['duration'].fillna(0.0).astype(float)\nff.create_distplot([mov_dur], ['y'], bin_size=0.5, colors=['#1B9E77']).show()","5d4583c5":"tv = df[df[\"type\"] == \"TV Show\"]\nmov = df[df[\"type\"] == \"Movie\"]\n\ncol = \"year_added\"\n\ndf1 = tv[col].value_counts().reset_index()\ndf1 = df1.rename(columns = {col : \"count\", \"index\" : col})\ndf1 = df1.sort_values(col)\n\ndf2 = mov[col].value_counts().reset_index()\ndf2 = df2.rename(columns = {col : \"count\", \"index\" : col})\ndf2 = df2.sort_values(col)\n\ntrace1 = go.Scatter(x=df1[col], y=df1[\"count\"], name=\"TV Shows\", marker=dict(color=\"#1B9E77\"), )\ntrace2 = go.Scatter(x=df2[col], y=df2[\"count\"], name=\"Movies\", marker=dict(color=\"#7570B3\"))\ndata = [trace1, trace2]\nlayout = go.Layout(title=\"Content added over the years\", legend=dict(x=0.8, y=1.2, orientation=\"h\"))\nfig = go.Figure(data, layout=layout)\nfig.show()","d04ec8d6":"wordcloud_create(df)","eb026693":"df['description']= df['description'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))","8e40566f":"wordcloud_create(df)","1ce5b9af":"\n#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\ntfidf = TfidfVectorizer(stop_words='english')\n\n#Replace NaN with an empty string\ndf['description'] = df['description'].fillna('')\n\n#Construct the required TF-IDF matrix by fitting and transforming the data\ntfidf_matrix = tfidf.fit_transform(df['description'])\n\n#Output the shape of tfidf_matrix\ntfidf_matrix.shape","5019a360":"cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)","415bfbec":"names = pd.Series(df.index, index=df['title']).drop_duplicates()","4d346a1c":"def get_recommendations(title, number=10, cosine_sim=cosine_sim):\n    # Get the index of the movie that matches the title\n    mov = names[title]\n\n    # Get the pairwsie similarity scores of all movies with that movie\n    score = list(enumerate(cosine_sim[mov]))\n\n    # Sort the movies based on the similarity scores\n    score = sorted(score, key=lambda x: x[1], reverse=True)\n\n    # Get the scores of the n most similar movies\n    score = score[1:number]\n\n    # Get the movie indices\n    movie_indices = [i[0] for i in score]\n\n    # Return the top n most similar movies\n    return df['title'].iloc[movie_indices]","72ca33f8":"get_recommendations('MINDHUNTER', 7)","0aefa1c0":"get_recommendations('3 Idiots', 10)","1b1a03fc":"#### Number of NULL values for the columns:","2a4f4852":"We can observe that the United States has the most number of Titles, followed by India and the United Kingdom.","9fd2deae":"We can observe that usually most content is added near the end of the year, taking the highest dip around the mid summer months, where the content is around the lowest. ","49c319b2":"Now that we have the cosine similarity scores, we will create a revese map to attach the programme from the user input and gives the rest 'n' programmes, where the user tells the number of shows he wants to see, where the default is 10. ","eb78550a":"During the past couple of years, Netflix has come forth as a pioneer in the field of online entertainment. Offering popular shows and movies, which can be accessed from any device in the world for a minimal fee, the history of Netflix shows that it revolutionized the industry with its radical method. \n\nThroughout the course of the few years many of us have asked the question, \"What to watch next?\"\n\nThis kernel is a foray into the world of basic recommender systems, their working and tries to answer the question ringing in all our minds. ","ff7c93b8":"## Usually Which Month has the most number of releases?\n","71bc8a7b":"1. [Loading required libraries, with installation](#1)\n2. [Getting basic ideas about the data](#2)\n3. [Exploratory Data Analysis](#3)\n4. [The Recommender Systems Age](#4)","6aab7e27":"# Exploratory Data Analysis<a id=\"3\"><\/a> <br>","f3be041a":"## Getting basic ideas about the data  <a id=\"2\"><\/a> <br>","6506b5e6":"This shows that nearly 67% or 2\/3 of the content of Netflix is Movies, rather than TV shows.","f08bd9c6":"### The growth of Netflix's library over the years.","fdcfc336":"![](http:\/\/media.foxbusiness.com\/BrightCove\/854081161001\/201910\/33\/854081161001_6093736038001_6093735925001-vs.jpg)","0e5d377f":"### The duration of a movie on average.","aa9cfe8d":"It can be observed that there ae a lot of words present which need to be removed, i.e, the stop words for the entire description text. The next step would be to remove them and create the final wordcloud. ","7039d88a":"#### Columns Description: \n\n- **show_id**     : Contains the unique ID for each movie\/series\n- **title**       : Contains the titles of the particular movie\/series\n- **director**    : Contains the director of the particular programme.\n- **case**        : The actors who took part in the movie\n- **country**     : The country of origin for the show.\n- **date_added**  : The date at which the programme was added on the platform\n- **release_year**: The year when the programme was released\n- **rating**      : The advised viewer rating for the given programmes\n- **duration**    : The running duration for a movie.\n- **listed_in**   : The popular platfors where the programme is listed as a must watch.\n- **description** : The short description of the show.\n- **type**        : The type of programme: Tv Show or a Movie.\n- **year_added**  : The year the programme was added on Netflix\n- **month_added** : The month the programme was added on Netflix\n- **season_count**: The number of seasons for the particular TV show.","e1dc3533":"We can observe that the recommendation system is working as intended, with MINDHUNTER being a show based around FBI and the recommendations also revolving crimnal and criminal cases. \n\nThis is the end of basic recommender systems, and will continue with FM based recommender systems in the upcoming versions. ","b32f2f9a":"## Content Based Filtering:\n\nWe will compute plot based content similarity of the descriptions and recommend the movies based on the similarity score. \n\nThe workflow of the recommender system would be as follows:\n- Convert the words into their respective Term Frequency - Inverse Document Frequency Score. \n\n     - Term Frequency: Term instances\/ Total instances\n     - IDF: log(number of documents\/documents with the term)\n      \n     - The overall importance of this comes into play as they tend to focus on the rare keywords more than the frequently occuring words, assigning a higher value to the particular rare keywords. The final formula would boil down to TF * IDF. It is usually also used to convert the text into sparse matrices, which could easily be feeded into models.","a6c6e37a":"### Which words are the most prevelant in the descriptions?","c27264c1":"### What kind of content does Netflix have the most?","c2bc1dd1":"The addition of TV shows seems to have been on a continuous rise, slowly increasing the number of shows present in the reportire of Netflix. ","4551e62e":"# Background:","4ff8e349":"**Upcoming** : Improving recommendation system to use other features such as cast, rating and duration. ","cd4bf5ca":"#### Adding basic new features:","8c467b26":"# What's in this kernel:","b809f625":"We can observe that over 15k words were used to describe the 5.8k unique programmes.\n\nNow, we can use a metric such as cosine similarity to gather the programmes closest to the movies entered. \n\n**Cosine Similarity**\n\nWe use it to calculate the numeric similarity between the various matrices, it is used in this kernel for the fast calculation for the basic recommender model. \n\n![image.png](attachment:image.png)","fc77f605":"Data has been growing at a rapid pace for the past few years. Video content in particular has savoured a particular boom. A regular person can't even begin to sent a dent in the humongous amount of videos present out there. \n\nUsually, people tend to watch shows which match the current show they are watching. Or something in particular. For the given dataset, the plan is to recommend shows\/movies based on the description of the programme. \n\nThis kind of information system engineering is termed as Recommender Systems.\n\nUsually, recommender systems are of three types:\n- **Demographic Filtering**:\n    - They offer generalized recommendations to every user, based on movie popularity and\/or genre. The System recommends the same movies to users with similar demographic features. Since each user is different , this approach is considered to be too simple. The basic idea behind this system is that movies that are more popular and critically acclaimed will have a higher probability of being liked by the average audience.\n    \n- **Content Based Filtering**:\n    - They suggest similar items based on a particular item. This system uses item metadata, such as genre, director, description, actors, etc. for movies, to make these recommendations. The general idea behind these recommender systems is that if a person liked a particular item, he or she will also like an item that is similar to it\n\n- **Collaborative Filtering**:\n    - This system matches persons with similar interests and provides recommendations based on this matching. Collaborative filters do not require item metadata like its content-based counterparts.\n    \n    \n    \nThe general idea for the recommender system for this particular dataset is to create a simple content based filtering based upon the descriptions, then building upon top of that in the upcoming versions.\n","2d9a0658":"We can observe the particular keywords now, where docuumentary, friends, family and comedy are some of the most popular words present in the description. ","8cce6dd9":"## Loading required libraries with installation. <a id=\"1\"><\/a> <br>","9d4c92c1":"\n### Which Country Releases the Most Number of Titles?","56a2241a":"It can be observed that most of the movies would be around 80-100 minutes, with the peak being around an hour and thirty six minutes, proclaiming that people don't prefer many movies above two hours.","5b60492d":"# The Recommender Systems Age: <a id=\"4\"><\/a> <br>"}}