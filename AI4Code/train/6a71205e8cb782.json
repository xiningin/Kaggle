{"cell_type":{"fee62eed":"code","9bbac60a":"code","4f789f17":"code","333ba8e6":"code","9f35a164":"code","bc78202a":"code","9c03c0a2":"code","52fbe143":"code","9e72db81":"code","08678124":"code","917e8879":"code","4fb9c388":"code","a893d710":"code","6eee3bd6":"code","ae64b03b":"code","fb1daa6e":"code","85c4fac2":"code","f9dce394":"code","a6dbcaa8":"code","c62243d4":"code","59305a45":"code","a86269e6":"code","9cfe7fb8":"code","1c733900":"markdown","de39df2e":"markdown","81cbcf9b":"markdown","d7c4ea40":"markdown","e8571041":"markdown"},"source":{"fee62eed":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport re\nimport string\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","9bbac60a":"train=pd.read_csv('..\/input\/nlp-getting-started\/train.csv')\ntest=pd.read_csv('..\/input\/nlp-getting-started\/test.csv')\nsample_submission=pd.read_csv('..\/input\/nlp-getting-started\/sample_submission.csv')","4f789f17":"train.head()","333ba8e6":"sns.countplot(train['target'])","9f35a164":"print('train shape : ', train.shape)\nprint('test shape : ', test.shape)","bc78202a":"print(train.isnull().sum(), '\\n', '-'*40)\nprint(test.isnull().sum())","9c03c0a2":"target_1_keyword=train.loc[train['target']==1]['keyword'].value_counts()[:20]\ntarget_0_keyword=train.loc[train['target']==0]['keyword'].value_counts()[:20]\n\nf, axes=plt.subplots(2,1, figsize=(25,10))\nax=axes.ravel()\nsns.barplot(x=target_1_keyword.index, y=target_1_keyword.values, ax=ax[0])\nsns.barplot(x=target_0_keyword.index, y=target_0_keyword.values, ax=ax[1])","52fbe143":"target_1_location=train.loc[train['target']==1]['location'].value_counts()[:20]\ntarget_0_location=train.loc[train['target']==0]['location'].value_counts()[:20]\n\nf, axes=plt.subplots(2,1, figsize=(25,10))\nax=axes.ravel()\nsns.barplot(x=target_1_location.index, y=target_1_location.values, ax=ax[0])\nsns.barplot(x=target_0_location.index, y=target_0_location.values, ax=ax[1])","9e72db81":"train=train.drop(columns='location')\ntest=test.drop(columns='location')","08678124":"train['keyword']=train['keyword'].fillna('unknown')\ntest['keyword']=test['keyword'].fillna('unknown')","917e8879":"train.head()","4fb9c388":"#first, lowercaste translation, remove number, remove punctutation. then tokenize\n\ndef lower(text):#lowercase translation\n    return text.lower()\n\ndef remove_number(text):#remove number\n    new_text=re.sub(r'[0-9]+','',text)\n    return new_text\n\ndef remove_punctuation(text):#remove punctutation\n    table=str.maketrans('', '', string.punctuation)\n    return text.translate(table)\n\ntrain['text']=train['text'].apply(lambda x:lower(x))\ntest['text']=test['text'].apply(lambda x:lower(x))\n\ntrain['text']=train['text'].apply(lambda x:remove_number(x))\ntest['text']=test['text'].apply(lambda x:remove_number(x))\n\ntrain['text']=train['text'].apply(lambda x:remove_punctuation(x))\ntest['text']=test['text'].apply(lambda x:remove_punctuation(x))\n\n#tokenzie\nfrom nltk.tokenize import word_tokenize\n\ntrain['text']=train['text'].apply(lambda x:word_tokenize(x))\ntest['text']=test['text'].apply(lambda x:word_tokenize(x))","a893d710":"train.head()","6eee3bd6":"test.head()","ae64b03b":"# After tokenize, remove stopword, remove special text, normalization(stemming or lemmatization)\n\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer, PorterStemmer\n\ndef remove_stopword(text):\n    new_text=[i for i in text if i not in stopwords.words('english')]\n    return new_text\n\ndef trans_Lemmatize(text):\n    return [WordNetLemmatizer().lemmatize(i) for i in text]\n\ndef trans_stem(text):\n    return [PorterStemmer().stem(i) for i in text]\n\n# In normalization, i just do lemmatize\ntrain['text']=train['text'].apply(lambda i:remove_stopword(i))\ntest['text']=test['text'].apply(lambda i:remove_stopword(i))\n\ntrain['text']=train['text'].apply(lambda i:trans_Lemmatize(i))\ntest['text']=test['text'].apply(lambda i:trans_Lemmatize(i))","fb1daa6e":"# for CountVectorize, join the list\ntrain['text']=train['text'].apply(lambda i:' '.join(i))\ntest['text']=test['text'].apply(lambda i:' '.join(i))","85c4fac2":"train.head()","f9dce394":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nct=ColumnTransformer([('onehotencoder', OneHotEncoder(), ['keyword']),\n                     ('dropout', 'drop', ['id','text'])])\n\nX_train_onehot=ct.fit_transform(train[['id','keyword','text']])\nX_test_onehot=ct.transform(test[['id','keyword','text']])\n\ncv=CountVectorizer(min_df=5)\n\nX_train_cv=cv.fit_transform(train['text'])\nX_test_cv=cv.transform(test['text'])","a6dbcaa8":"from scipy import sparse\n\nX_train=sparse.hstack((X_train_onehot, X_train_cv))\nX_test=sparse.hstack((X_test_onehot, X_test_cv))\n\ny_train=train['target']","c62243d4":"X_train","59305a45":"X_test","a86269e6":"from sklearn.ensemble import RandomForestClassifier\n\nforest=RandomForestClassifier()\nforest.fit(X_train, y_train)\n","9cfe7fb8":"sub=pd.DataFrame({'id':test['id'],\n                 'target':forest.predict(X_test)})\n\nsub.to_csv('submission.csv', index=False)","1c733900":"* I think location column is not usefull. so drop! ","de39df2e":"* train['keywords'] values\n* train['location'] values\n\n* when taget==1 and target==0","81cbcf9b":"* fill the Nan value of keyword feature to unknown","d7c4ea40":"## keyword -- OneHotEncoding\n## text -- CountVectorizing","e8571041":"## At NLP, process this works\n* lowercase translation\n* remove number\n* remove punctuation\n* remove stopword\n* remove special character\n* normalization(stemming or lemmatization)"}}