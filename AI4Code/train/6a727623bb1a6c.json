{"cell_type":{"88dbf8e7":"code","5ea03dbe":"code","3d636475":"code","1af87bd0":"code","75b203f0":"code","13e730ab":"code","760368a5":"code","3c37ebe7":"code","90b404c0":"code","0c0c1f9d":"code","3abe02d0":"code","7ce883eb":"code","a6e1dfd1":"code","b1e5688e":"code","e2aec709":"code","2e82974d":"code","4148be71":"code","ea84212f":"code","19f2affb":"code","ac11d116":"code","8f9e3dad":"code","dbbe59c3":"code","c8723ad0":"code","bcbecd41":"code","f5e3fa73":"code","36ad70bf":"code","0055018b":"code","049f8ca5":"code","56baca7a":"code","b7fb47bc":"code","93c6faa3":"code","e8ba3548":"code","105cfecc":"code","6d66dd82":"code","c396c7cb":"code","e9b97413":"code","c460994b":"code","2da79be9":"code","77d4ef65":"code","2bc1f081":"code","b97a146b":"code","1945a936":"code","f0f60919":"code","a88fac2e":"code","3483e1a7":"code","8e2d18fd":"code","82daf6dd":"code","800b03ea":"code","ed99e394":"code","4dc9fdb2":"code","bbeffe4b":"code","c18eedef":"code","551b1aed":"code","5bd433a5":"code","356dd926":"code","a4965eca":"code","1da0d1f4":"code","bc27137a":"code","1eb5bf33":"code","20a4c741":"code","603b07c9":"code","da2da199":"code","73fc52fb":"code","d530a20e":"code","c2ea07ca":"code","e2884f65":"code","f0acd903":"code","c0c19866":"code","5472efa5":"code","1402e47d":"code","fd16064a":"code","31569ea9":"code","0ae6d4c6":"code","c0722582":"code","c546601d":"code","2d9e5a3f":"code","c1753d1f":"code","eb7d6c83":"code","65bf4d03":"code","64230bf3":"code","8da2b0ce":"code","486cc85c":"code","a0261f1c":"code","62bd3d38":"code","5bcbb22a":"code","9a2e0780":"code","1a7fe5c8":"markdown","470817a4":"markdown","d5dccdcd":"markdown","1e2b5d6d":"markdown","6234dd78":"markdown","5dbae0c9":"markdown","b7c93c87":"markdown","5f071c32":"markdown","a3fcd5a3":"markdown","6bb9fb72":"markdown","500c4bf3":"markdown","fb2375c5":"markdown","1b487ee9":"markdown","7a57199e":"markdown","5959104c":"markdown","3d37bfce":"markdown","56e38e77":"markdown","1e0ebccb":"markdown","414a5f14":"markdown","2b5df741":"markdown","ae0483c5":"markdown","13e40b0d":"markdown","0fee0396":"markdown","9b7cf31f":"markdown","70311e4f":"markdown","e78cbe70":"markdown","c2a61242":"markdown","a1cbbb72":"markdown","8fa37c91":"markdown","b22ed172":"markdown"},"source":{"88dbf8e7":"import pandas as pd \nimport seaborn as sns\nfrom pandas_profiling import ProfileReport","5ea03dbe":"import numpy as np ","3d636475":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","1af87bd0":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest  = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","75b203f0":"#Some algorithms like XGBOOST and LightGBM can treat missing data without any preprocessing ","13e730ab":"train.head()","760368a5":"train.info()","3c37ebe7":"test.info()","90b404c0":"import sweetviz\nmy_report = sweetviz.compare([train, \"Train\"], [test, \"Test\"], \"Survived\")","0c0c1f9d":"my_report.show_html(\"Report.html\")","3abe02d0":"print('Shape of TRAIN DATA : ', train.shape)\nprint('Shape of TEST DATA : ', test.shape)","7ce883eb":"#Examining the target column \ntrain['Survived'].value_counts()","a6e1dfd1":"s = sns.countplot(x = 'Survived', data = train)\n# 0 - Did not Survive\n# 1 - Survived","b1e5688e":"def missing_values_table(df):\n    mis_val = df.isnull().sum()\n    mis_val_percent = 100 * df.isnull().sum() \/ len(df)\n    mis_val_table = pd.concat([mis_val,mis_val_percent],axis=1) \n    mis_val_table_rename = mis_val_table.rename(columns = {0:'Missing Values',\n                                                          1:'% of Total Missing Values'})\n    mis_val_table_rename_sort = mis_val_table_rename[mis_val_table_rename.iloc[:,1] !=0].sort_values('% of Total Missing Values',ascending = False).round(1)\n    print('Your selected dataframe has ' + str(df.shape[1]) + ' columns')\n    print('There are ' + str(mis_val_table_rename_sort.shape[0]) + ' columns have missing values')\n    return mis_val_table_rename_sort\n    ","e2aec709":"train_missing = missing_values_table(train)\ntrain_missing","2e82974d":"test_missing = missing_values_table(test)\ntest_missing","4148be71":"import missingno as msno","ea84212f":"msno.bar(train)","19f2affb":"msno.bar(test)","ac11d116":"msno.matrix(train)","8f9e3dad":"msno.matrix(test)","dbbe59c3":"msno.matrix(train)","c8723ad0":"sorted = train.sort_values('Age')\nmsno.matrix(sorted)","bcbecd41":"sorted1 = train.sort_values('Cabin')\nmsno.matrix(sorted1)","f5e3fa73":"msno.heatmap(train)","36ad70bf":"msno.dendrogram(train)","0055018b":"train.isnull().sum()","049f8ca5":"train_1 = train.copy()\nAge_mean= train_1['Age'].mean()\nAge_mean","56baca7a":"train_1['Age'] = train_1['Age'].fillna(value=Age_mean)","b7fb47bc":"msno.matrix(train_1)","93c6faa3":"from sklearn.impute import SimpleImputer\ntrain_mf = train.copy()\nmean_imputer = SimpleImputer(strategy='mean')\nmedian_imputer = SimpleImputer(strategy='median')\nmost_freq_imputer = SimpleImputer(strategy='most_frequent')\nconstant_imputer = SimpleImputer(strategy='constant')\ntrain_mf.iloc[:,:] = most_freq_imputer.fit_transform(train_mf)\nmsno.matrix(train_mf)","e8ba3548":"test.head()","105cfecc":"test.info()","6d66dd82":"test.shape","c396c7cb":"test_missing = missing_values_table(test)\ntest_missing","e9b97413":"msno.bar(test)","c460994b":"msno.matrix(test)","2da79be9":"msno.dendrogram(test)","77d4ef65":"msno.heatmap(test)","2bc1f081":"# CABIN HAS 77% MISSING VALUES IN TRAIN\n# CABIN HAS 78% MISSING VALUES IN TEST \n# THEREFORE DROPPING CABIN COLUMN WOULD BE BETTER FOR ANALYSIS","b97a146b":"test = test.drop(columns=['Cabin'])\ntrain_mf = train_mf.drop(columns=['Cabin'])","1945a936":"missing_values_table(test)","f0f60919":"from sklearn.impute import SimpleImputer\ntest_mf = test.copy()\nmean_imputer = SimpleImputer(strategy='most_frequent')\ntest_mf.iloc[:,:] = mean_imputer.fit_transform(test_mf)\nmsno.matrix(test_mf)","a88fac2e":"#Now both the training and testing data are cleaned","3483e1a7":"profile_train = ProfileReport(train_mf)\nprofile_train","8e2d18fd":"profile_test = ProfileReport(test_mf)\nprofile_test","82daf6dd":"import seaborn as sns \nimport matplotlib.pyplot as plt","800b03ea":"train_mf.columns","ed99e394":"sns.barplot(x='Sex',y='Survived',data=train_mf)\nplt.xlabel('Gender of the Passenger')\nplt.ylabel('Proportion survived')\nplt.title('Survival Based on Gender')","4dc9fdb2":"female_survived = train_mf[train_mf['Sex']=='female']['Survived'].sum()\nmale_survived   = train_mf[train_mf['Sex']=='male']['Survived'].sum()\nClass_1         = train_mf[train_mf['Pclass']==1]['Survived'].sum()\nClass_2         = train_mf[train_mf['Pclass']==2]['Survived'].sum()\nClass_3         = train_mf[train_mf['Pclass']==3]['Survived'].sum()\n\nprint('No. of females survived : ' , female_survived)\nprint('No. of male survived : ' , male_survived)\nprint('No. of Class 1 passengers survived : ' , Class_1)\nprint('No. of Class 2 passengers survived : ' , Class_2)\nprint('No. of Class 3 passengers survived : ' , Class_3)\nprint('Total no. of Survivors = ' , female_survived+male_survived)","bbeffe4b":"sns.barplot(x='Pclass',y='Survived',data=train_mf)\nplt.xlabel('Class of Passenger')\nplt.ylabel('Proportion Survived')\nplt.title('Survival Based on Passenger Class')","c18eedef":"sns.barplot(x='Pclass',y='Survived',hue='Sex',data=train_mf)\nplt.title('Survival Based on Gender and Passenger Class')","551b1aed":"survived_ages = train_mf[train_mf['Survived']==1]['Age']\nnot_survived_ages  = train_mf[train_mf['Survived']==0]['Age']\nplt.subplot(1,2,1)\nsns.distplot(survived_ages,kde=False)\nplt.ylabel('Proportion')\nplt.title('Survived')\nplt.subplot(1,2,2)\nsns.distplot(not_survived_ages,kde=False)\nplt.ylabel('Proportion')\nplt.title('Died')\nplt.show()","5bd433a5":"fare_survived = train_mf[train_mf['Survived']==1]['Fare']\nfare_died     = train_mf[train_mf['Survived']==0]['Fare']\nplt.subplot(1,2,1)\nsns.distplot(fare_survived,kde=False)\nplt.ylabel('Fare')\nplt.title('Fare of Survived')\nplt.subplot(1,2,2)\nsns.distplot(fare_died,kde=False)\nplt.ylabel('Fare')\nplt.title('Fare of Died')\nplt.show()","356dd926":"sns.stripplot(x='Survived',y='Age',data=train_mf,jitter=True)\nplt.title('Ages vs Survival')","a4965eca":"sns.pairplot(train_mf)","1da0d1f4":"train_mf.sample(5)","bc27137a":"test_mf.sample(5)","1eb5bf33":"# Changing Male = 1 and Female = 0\ndef label_encode(sex):\n    if sex == 'male':\n        label = 1\n    else:\n        label = 0\n    return label\n\ntrain_mf['Sex']=train_mf['Sex'].apply(label_encode)\ndef label_encode(sex):\n    if sex == 'male':\n        label = 1\n    else:\n        label = 0\n    return label\ntest_mf['Sex']=test_mf['Sex'].apply(label_encode)","20a4c741":"train_mf.head()","603b07c9":"train_mf['FamSize'] = train_mf['SibSp'] + train_mf['Parch'] + 1 \ntest_mf['FamSize'] = test_mf['SibSp'] + test_mf['Parch'] + 1","da2da199":"train_mf.head()","73fc52fb":"test_mf.head()","d530a20e":"train_mf['IsAlone'] = train_mf.FamSize.apply(lambda x: 1 if x==1 else 0)\ntest_mf['IsAlone'] = test_mf.FamSize.apply(lambda x: 1 if x==1 else 0)","c2ea07ca":"train_mf.sample(5)","e2884f65":"test_mf.sample(5)","f0acd903":"from sklearn.svm import SVC,LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\n","c0c19866":"from sklearn.metrics import make_scorer,accuracy_score","5472efa5":"from sklearn.model_selection import GridSearchCV","1402e47d":"def logic_encoder(embark):\n    if embark == 'S':\n        logic = 0\n    elif embark == 'C':\n        logic = 1\n    else:\n        logic = 2\n    return logic\ntrain_mf['Embarked'] = train_mf['Embarked'].apply(logic_encoder)","fd16064a":"def logic_encoder(embark):\n    if embark == 'S':\n        logic = 0\n    elif embark == 'C':\n        logic = 1\n    else:\n        logic = 2\n    return logic\ntest_mf['Embarked'] = test_mf['Embarked'].apply(logic_encoder)","31569ea9":"test_mf['Name'] = test_mf['Name'].astype('object')\ntrain_mf['Name'] = train_mf['Name'].astype('object')","0ae6d4c6":"features = ['Pclass','Sex', 'Age', 'SibSp','Parch','Fare','Embarked', 'FamSize', 'IsAlone']\nX_train = train_mf[features]\ny_train = train_mf['Survived']\nX_test  = test_mf[features]","c0722582":"from sklearn.model_selection import train_test_split","c546601d":"X_training,X_valid,y_training,y_valid = train_test_split(X_train,y_train,test_size=0.2,random_state=0)","2d9e5a3f":"svc_clf = SVC() \nsvc_clf.fit(X_training, y_training)\npred_svc = svc_clf.predict(X_valid)\nacc_svc = accuracy_score(y_valid, pred_svc)\n\nprint(acc_svc)","c1753d1f":"linsvc_clf = LinearSVC()\nlinsvc_clf.fit(X_training, y_training)\npred_linsvc = linsvc_clf.predict(X_valid)\nacc_linsvc = accuracy_score(y_valid, pred_linsvc)\n\nprint(acc_linsvc)","eb7d6c83":"rf_clf = RandomForestClassifier()\nrf_clf.fit(X_training, y_training)\npred_rf = rf_clf.predict(X_valid)\nacc_rf = accuracy_score(y_valid, pred_rf)\n\nprint(acc_rf)","65bf4d03":"logreg_clf = LogisticRegression()\nlogreg_clf.fit(X_training, y_training)\npred_logreg = logreg_clf.predict(X_valid)\nacc_logreg = accuracy_score(y_valid, pred_logreg)\n\nprint(acc_logreg)","64230bf3":"knn_clf = KNeighborsClassifier()\nknn_clf.fit(X_training, y_training)\npred_knn = knn_clf.predict(X_valid)\nacc_knn = accuracy_score(y_valid, pred_knn)\n\nprint(acc_knn)","8da2b0ce":"gnb_clf = GaussianNB()\ngnb_clf.fit(X_training, y_training)\npred_gnb = gnb_clf.predict(X_valid)\nacc_gnb = accuracy_score(y_valid, pred_gnb)\n\nprint(acc_gnb)","486cc85c":"dt_clf = DecisionTreeClassifier()\ndt_clf.fit(X_training, y_training)\npred_dt = dt_clf.predict(X_valid)\nacc_dt = accuracy_score(y_valid, pred_dt)\n\nprint(acc_dt)","a0261f1c":"xg_clf = XGBClassifier(objective=\"binary:logistic\", n_estimators=10, seed=123)\nxg_clf.fit(X_training, y_training)\npred_xg = xg_clf.predict(X_valid)\nacc_xg = accuracy_score(y_valid, pred_xg)\n\nprint(acc_xg)","62bd3d38":"model_performance = pd.DataFrame({\"Model\": [\"SVC\", \"Linear SVC\", \"Random Forest\", \"Logistic Regression\", \"K Nearest Neighbors\", \"Gaussian Naive Bayes\",\"Decision Tree\", \"XGBClassifier\"],\n                                  \"Accuracy\": [acc_svc, acc_linsvc, acc_rf, acc_logreg, acc_knn, acc_gnb, acc_dt, acc_xg]})\n\nmodel_performance.sort_values(by=\"Accuracy\", ascending=False)","5bcbb22a":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\n\nskf = StratifiedKFold(n_splits=10,random_state=23)\nscore = cross_val_score(rf_clf,X_training, y_training,cv = skf)\nprint(f'Accuracy Score After Cross Validation: {np.mean(score)*100:4.1f}%')","9a2e0780":"#accuracy\nscore = cross_val_score(rf_clf,X_training, y_training, cv=skf)\n#positive precision\nprecision_score = cross_val_score(rf_clf,X_training, y_training, cv=skf, scoring='precision')\n#positive recall\nrecall_score = cross_val_score(rf_clf,X_training, y_training, cv=skf, scoring='recall')\n#auc\nauc_score = cross_val_score(rf_clf,X_training, y_training, cv=skf, scoring='roc_auc')\n\nprint(f'Accuracy Score from Cross Validation: {np.mean(score)*100:4.1f}%')\nprint(f'Positive Precision Rate from Cross Validation: {np.mean(precision_score)*100:4.1f}%')\nprint(f'Positive Recall Rate from Cross Validation: {np.mean(recall_score)*100:4.1f}%')\nprint(f'Area Under Curve from Cross Validation: {np.mean(auc_score)*100:4.1f}%')","1a7fe5c8":"* XGBoost Model","470817a4":"* The heatmap shows that there is very low correlation between the missing values of different features and this low correlation indicate that its MAR ","d5dccdcd":"* From the above different plots we have seen that the survival rate is highly affected by the Passenger Class and the AGE of the Passenger","1e2b5d6d":"* Linear SVC Model","6234dd78":"# MODEL FITTING AND TEST USING SKLEARN ","5dbae0c9":"* This shows that there is no correlation between the missing ages and the missing cabin values \n* We can also compare this by sorting by Cabin","b7c93c87":"* Cabin values cannot be added as they are different for each row \n* Therefore we have to either delete the row or not consider it for analysis","5f071c32":"* Here the misssing values in embarked column are very less and this can be the case of MCAR \n* But Age and Cabin columns have lot of missing values - this could be MAR \n  Since we are not able to find the reason for missing \n* Now we will sort the values by AGE and check if it is related to missing in Cabin","a3fcd5a3":"# Detecting Missing Values Numerically\n* First count the percentages of missing values to understand the distribution\n* This method is detecting missing values numerically\n* This will prove that the missing values in test and train data are similar ","6bb9fb72":"* Decision Tree Model","500c4bf3":"## Using Cross Validation to Optimize the Model","fb2375c5":"# Visualising the locations of Missing Data","1b487ee9":"# Finding reason for missing data using HEATMAP","7a57199e":"# REASONS FOR MISSING VALUES \n* MCAR (Missing Completely at Random)\n- Here the missing is unrelated to observed and unobserved features\n* MAR (Missing at Random)\n- Here missing is related to observed features only \n* NMAR (Not Missing at Random)\n- Here the missing is related to unobserved features and possibly observed features also \n","5959104c":"* GaussianNB Model","3d37bfce":"# USING SIMILAR TECHNIQUES TO CLEAN THE TEST DATA ","56e38e77":"# Finding reasons for missing values using Dendrogram","1e0ebccb":"* We can further confirm that there is no relation between the missing values by using heatmap ","414a5f14":"* SVC MODEL ","2b5df741":"# Visualizing the Pre-Processed Data","ae0483c5":"# Imputation Techniques for Non-Time Series Problems\n* 1st method - By constant value \n* 2nd method - By statistical value - (mean,median,most frequent)\n* The above are done by importing SIMPLEIMPUTER from SKLEARN.IMPUTE","13e40b0d":"### StratifiedKFold","0fee0396":"* Random Forest Model","9b7cf31f":"* Logistic Regression Model","70311e4f":"# Finding reason for missing using Matrix graph","e78cbe70":"# TREATING MISSING VALUES \n* The first method can be deletion - Its of 3 types\n* Pairwise deletion - Deleting only the missing value \n* Listwise\/Row-wise deletiong - Dropping the rows containing missing values\n* Dropping an Entire Column - Only feaisable when more than 80% of the column is empty ","c2a61242":"# Detecting Missing Values Graphically using Missingno","a1cbbb72":"* This graph shows us that missing values in Embarked are more correlated to Age and Missing values in Age are more correlated to Cabin. But since the no. of missing values in Embarked are very few we cannot find any emerging cause. ","8fa37c91":"# FEATURE ENGINEERING FOR THE DATA","b22ed172":"* KNeighbors Model "}}