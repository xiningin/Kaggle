{"cell_type":{"9560b0d2":"code","796b792d":"markdown"},"source":{"9560b0d2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\n#!\/usr\/bin\/env python\n\nimport codecs\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport scipy\nfrom scipy.stats import norm\nfrom scipy.interpolate import UnivariateSpline\nimport pandas as pd\nimport matplotlib.backends.backend_pdf\nimport csv\nimport math\n\ndata = pd.read_csv(\"\/kaggle\/input\/general-titanic-dataset\/titanic.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\n#training set has labels and is usde to train our model\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")\n\ncombined = [train, test]\n# Family column\ndata['Family'] = (data['SibSp'] > 0) | (data['Parch'] > 0)\n#print (data[\"Family\"])\n\n# Age Analysis\n#classify as children and adults\ndata['AgeRange'] = pd.cut(data['Age'], [0, 15, 80], labels=['child', 'adult'])\n#print(data['AgeRange'])\n# remove missing ages\ndata_clean_age = data.dropna(subset=['Age'])\n#print(data_clean_age)\nf = data.groupby(\"Age\")\n#print(f)\nmean_age = f.mean()\nvar_age = f.var()\nstd_age = np.sqrt(np.var(data_clean_age))\n# print (\"Mean: \" + str(np.mean(data_clean_age)))\n# print (\"Variance: \" +str(np.var(data_clean_age)))\n# print (\"Standard deviation: \" +str(np.sqrt(np.var(data_clean_age))))\n# print(mean_age)\n# print(var_age)\n# print(std_age)\n\nplt.hist(data[\"Age\"], bins = 100, density = True)\nplt.ylabel('Count')\nplt.title('Histogram for Age in Titanic')\n#plt.savefig(\"figure3.pdf\")\nplt.show()\n\n\n\n#fare analysis\ndata_clean_fare = data.dropna(subset=['Fare'])\nf = data.groupby(\"Fare\")\nplt.hist(data[\"Fare\"], bins = 100, density = True)\nplt.ylabel('Count')\nplt.title('Histogram for fare in Titanic')\n#plt.savefig(\"figure4.pdf\")\nplt.show()\nmean_fare = f.mean()\nvar_fare = f.var()\nstd_fare = np.sqrt(np.var(data_clean_fare))\n# print (\"Mean: \" + str(np.mean(data_clean_fare)))\n# print (\"Variance: \" +str(np.var(data_clean_fare)))\n# print (\"Standard deviation: \" +str(np.sqrt(np.var(data_clean_fare))))\n\n# print(\"Mean fare: \"+str(mean_fare))\n# print(\"fare Variance:\"+str(var_fare))\n# print(\"Fare Standard Dev:\"+str(std_fare))\n\n\n\n# #Normal probability plot for age\n\n#counts, start= scipy.stats.probplot(data[\"Age\"],sparams=(), dist='norm', fit=True, plot=None, rvalue=False)\n#x = np.arange(counts.size) * 1 + start\n\n# data[\"Age\"].sort()\n# X = np.linspace(1.0\/len(data[\"Age\"]), 1, len(data[\"Age\"]))\n# Ppf_age = scipy.stats.norm.ppf(X, mean_age, var_age)\ncounts, start = scipy.stats.probplot(data[\"Age\"],sparams=(),dist = 'norm', fit = True, plot = plt)\n# plt.plot(Ppf_age, counts, 'ro')\nplt.xlabel('Value')\nplt.ylabel('Normalized count')\nplt.title('Probability plot for age in Titanic')\n#plt.savefig(\"figure5.pdf\")\nplt.show()\n\n\n# #Normal probability plot for fare\ncounts, start = scipy.stats.probplot(data[\"Fare\"],sparams=(),dist = 'norm', fit = True, plot = plt)\nplt.xlabel('Value')\nplt.ylabel('Normalized count')\nplt.title('Probability plot for Fare in Titanic')\n#plt.savefig(\"figure6.pdf\")\nplt.show()\n\n\n# Survival Rates Analysis\n\n\n\n# remove data not needed\ndata.drop(['PassengerId', 'Parch', 'Ticket', 'Cabin'], axis=1, inplace=True)\n#survival rates\nsurvived_by_class = data.groupby('Pclass')['Survived'].mean()\nprint(survived_by_class)\nsurvived_by_sex = data.groupby('Sex')['Survived'].mean()\nprint(survived_by_sex)\nsurvived_by_age = data.groupby('AgeRange')['Survived'].mean()\nprint(survived_by_age)\n\n# Survival by Gender\nprint(data.groupby(['Sex', 'Survived'])['Survived'].count())\n\n# Survival by Class and Gender\npd.crosstab([data.Sex, data.Survived], data.Pclass, margins= True).style.background_gradient(cmap='summer_r') \n\nfig, (axis1,axis2,axis3) = plt.subplots(1, 3, figsize=(16,6))\n\nax = survived_by_class.plot.bar(ax=axis1, color='#5975A4', title='Survival Rate by Class', sharey=True)\nax.set_ylabel('Survival Rate')\nax.set_ylim(0.0,1.0)\nax = survived_by_sex.plot.bar(ax=axis2, color='#5F9E6E', title='Survival Rate by Sex', sharey=True)\nax.set_ylim(0.0,1.0)\nax = survived_by_age.plot.bar(ax=axis3, color='#B55D60', title='Survival Rate by Age Range', sharey=True)\nax.set_ylim(0.0,1.0)\n\n\n#import Shallow Machine Learning library (i.e., sklearn)\n#import the Random Forest Algorithm\n\n## copied from https:\/\/www.kaggle.com\/diegogomez92\/titanic-diego\nfrom sklearn.ensemble import RandomForestClassifier\nimport pandas as pd\n#this data set has all females surviving and all males not surviving\n#get ball-park estimate about what feautures are important in the data set\ngender_submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\n\n#testing data has no labels (i.e., does not include 'Survived' variable)\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\n#training set has labels and is usde to train our model\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")\n#show top 5 rows of the data set \ntrain.head()\n#DEPENDENT VARIABLE\ny = train[\"Survived\"]\n\n#INDEPENDENT VARIABLES\n#the features we will include in our model\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train[features])\nX_test = pd.get_dummies(test[features])\n\n\nX_train = train.drop(\"Survived\", axis=1)\nY_train = train[\"Survived\"]\nx_test  = test.drop(\"PassengerId\", axis=1).copy()\n\n\n#More imports for analysis\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n# Logistic Regression courtesy of https:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions\/data\n\nlogreg = LogisticRegression()\nlogreg.fit(X, y)\nY_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X, y) * 100, 2)\nacc_log\n\n\n# Support Vector Machines\n\nsvc = SVC()\nsvc.fit(X, y)\nY_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X, y) * 100, 2)\nacc_svc\n\n\n# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X, y)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X, y) * 100, 2)\nacc_decision_tree\n\n# Random Forest version 1\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X, y)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X, y)\nacc_random_forest = round(random_forest.score(X, y) * 100, 2)\nacc_random_forest\n\n\noutput = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\noutput.to_csv('submission.csv', index=False)\nprint(\"Your first submission was successfully saved!\")\n\n\n#100 random forest trees\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y) #fit the model\npredictions = model.predict(X_test) \n\noutput = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","796b792d":"The third and fourth figures above is a histogram consisting of the ages and fares of people in the Titanic. The data has been cleaned to remove the null values. The fifth and sixth figures is a normal probability plot for the same data set\n\nThe age maximum likelihood of mean is 29.699118 and variance is 210.723580. The fare maximum likelihood of mean is 32.204208 and variance is 2466.665312.\n\nOverall Survival Rates :\n\nRaw Numbers:\n\n[] Everyone that survived:\n[] Women: 233\n[] Men:109\n[] First Class Passengers:\n[] Third Class Passengers:\n[] Men in First Class:\n[] Women in third class:\n[] Those whose fare exceeded 100:\n[] Those whose fare was less than 50:\n[] People travelling as Family: 1\/3\nWhen doing the analysis above, I realised that some gender were written as male and female, whereas others were written as M and F. I could not find a way to unify this data, so I let it stay and added them together.\n\nSex Survived F 0 9 1 22 M 0 48 1 12 female 0 72 1 211 male 0 420 1 97\n\nPclass 1 0.655914 2 0.479769 3 0.239437 Name: Survived, dtype: float64 Sex F 0.750000 M 0.204082 female 0.755365 male 0.205446 Name: Survived, dtype: float64 AgeRange child 0.590361 adult 0.381933 Name: Survived, dtype: float64"}}