{"cell_type":{"37ee5f71":"code","47f428aa":"code","a92dad1d":"code","f5086bd0":"code","b6d6db4c":"code","ef68d3cd":"code","91eb0d8b":"code","49dec8a1":"code","25261926":"code","a57b21e9":"code","2055db86":"code","d8421515":"code","9e0db0d3":"code","a3599645":"code","38a2b987":"code","537e5e4d":"code","1f32f091":"code","158644a6":"markdown","002813fd":"markdown","48472742":"markdown","831e5ad6":"markdown","4dd9cb87":"markdown","1c40822e":"markdown","ab9f8216":"markdown","539b8017":"markdown","8e460898":"markdown"},"source":{"37ee5f71":"!apt install -y ffmpeg\n!pip install eyed3\n!pip install pydub\n!pip install pyAudioAnalysis\n\nimport os\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom pyAudioAnalysis import audioBasicIO\nfrom pyAudioAnalysis import audioFeatureExtraction\nimport matplotlib.pyplot as plt","47f428aa":"def preProcess( fileName ):\n    # Extracting wav file data\n    [Fs, x] = audioBasicIO.readAudioFile(fileName);\n\n    # If double channel data then take mean\n    if( len( x.shape ) > 1 and  x.shape[1] == 2 ):\n        x = np.mean( x, axis = 1, keepdims = True )\n    else:\n        x = x.reshape( x.shape[0], 1 )\n    \n    # Extract the raw chromagram data, expected dimention is [ m,  ] not [ m, 1 ]\n    F, f_names = audioFeatureExtraction.stFeatureExtraction(\n        x[ :, 0 ], \n        Fs, 0.050*Fs, \n        0.025*Fs\n    )\n    \n    return (f_names, F)","a92dad1d":"def getChromagram( audioData ):\n    # chronograph_1\n    temp_data =  audioData[ 21 ].reshape( 1, audioData[ 21 ].shape[0] )\n    chronograph = temp_data\n    \n    # looping through the next 11 stacking them vertically\n    for i in range( 22, 33 ):\n        temp_data =  audioData[ i ].reshape( 1, audioData[ i ].shape[0] )\n        chronograph = np.vstack( [ chronograph,  temp_data ] )\n    \n    return chronograph","f5086bd0":"def getNoteFrequency( chromagram ):\n    \n    # Total number of time frames in the current sample\n    numberOfWindows = chromagram.shape[1]\n    \n    # Taking the note with the highest amplitude\n    freqVal = chromagram.argmax( axis = 0 )\n    \n    # Converting the freqVal vs time to freq count\n    histogram, bin = np.histogram( freqVal, bins = 12 ) \n    \n    # Normalizing the distribution by the number of time frames\n    normalized_hist = histogram.reshape( 1, 12 ).astype( float ) \/ numberOfWindows\n    \n    return normalized_hist","b6d6db4c":"def plotHeatmap( chromagraph, smallSample = True ):\n    \n    notesLabels = [ \"G#\", \"G\", \"F#\", \"F\", \"E\", \"D#\", \"D\", \"C#\", \"C\", \"B\", \"A#\", \"A\" ]\n    \n    fig, axis = plt.subplots()\n    \n    if smallSample:\n        im = axis.imshow( chromagram[ :, 0 : 25 ], cmap = \"YlGn\" )\n    else:\n        im = axis.imshow( chromagram )\n        \n    cbar = axis.figure.colorbar(im, ax = axis,  cmap = \"YlGn\")\n    cbar.ax.set_ylabel(\"Amplitude\", rotation=-90, va=\"bottom\")\n    \n    axis.set_yticks( np.arange( len(notesLabels) ) )\n    axis.set_yticklabels(notesLabels)\n    \n    axis.set_title( \"chromagram\" )\n    \n    fig.tight_layout()\n    _ = plt.show()","ef68d3cd":"def noteFrequencyPlot( noteFrequency, smallSample = True ):\n    \n    fig, axis = plt.subplots(1, 1, sharey=True )\n    \n    axis.plot( np.arange( 1, 13 ), noteFrequency[0, :] )\n    \n    _ = plt.show()","91eb0d8b":"feature_name, features = preProcess( \"..\/input\/c1_2.wav\" )","49dec8a1":"chromagram = getChromagram( features )\nplotHeatmap( chromagram )","25261926":"noteFrequency = getNoteFrequency( chromagram )\nnoteFrequencyPlot( noteFrequency )","a57b21e9":"fileList = []\n\ndef getDataset( filePath ):\n    X = pd.DataFrame(  )\n    \n    columns=[ \"G#\", \"G\", \"F#\", \"F\", \"E\", \"D#\", \"D\", \"C#\", \"C\", \"B\", \"A#\", \"A\" ]\n    \n    for root, dirs, filenames in os.walk( filePath ):\n        for file in filenames:\n            fileList.append( file )\n            feature_name, features = preProcess(filePath + file )\n            chromagram = getChromagram( features )\n            noteFrequency = getNoteFrequency( chromagram )\n            x_new =  pd.Series(noteFrequency[ 0, : ])\n            X = pd.concat( [ X, x_new ], axis = 1 )\n        \n    data = X.T.copy()\n    data.columns = columns\n    data.index = [ i for i in range( 0, data.shape[ 0 ] ) ]\n            \n    return data","2055db86":"data = getDataset( \"..\/input\/\" )","d8421515":"data","9e0db0d3":"# Number of cluster we wish to divide the data into( user tunable )\nk = 3\n\n# Max number of allowed iterations for the algorithm( user tunable )\nepochs = 2000","a3599645":"def initilizeCentroids( data, k ):\n    '''\n    Initilize cluster centroids( assuming random k data points to be centroid return them )\n    '''\n    centroids = data.values[ 0 : k ]\n    return centroids","38a2b987":"# utility to assign centroids to data points\ndef assignCentroids(X, C):  \n    expanded_vectors = tf.expand_dims(X, 0)\n    expanded_centroids = tf.expand_dims(C, 1)\n    distance = tf.math.reduce_sum( tf.math.square( tf.math.subtract( expanded_vectors, expanded_centroids ) ), axis=2 )\n    return tf.math.argmin(distance, 0)\n                                              \n# utility to recalculate centroids\ndef reCalculateCentroids(X, X_labels):\n    sums = tf.math.unsorted_segment_sum( X, X_labels, k )\n    counts = tf.math.unsorted_segment_sum( tf.ones_like( X ), X_labels, k  )\n    return tf.math.divide( sums, counts )                                              ","537e5e4d":"X = tf.Variable(data.values, name=\"X\")\nX_labels = tf.Variable(tf.zeros(shape=(X.shape[0], 1)),name=\"C_lables\")\nC = tf.Variable(initilizeCentroids( data, k ), name=\"C\")\n\nfor epoch in range( epochs ):\n    X_labels =  assignCentroids( X, C )\n    C = reCalculateCentroids( X, X_labels )","1f32f091":"final_labels = pd.DataFrame( { \"Labels\": X_labels, \"File Names\": fileList } )\nfinal_labels","158644a6":"## Driver function","002813fd":"## A peek into the dataset\nEach row represents a file and each column represents the frequency distribution of notes\n\nIn my case, I have 19 files in total.","48472742":"## K-means utility functions","831e5ad6":"## Dataset generator\nThis function iterates over all the available files and converts them into note frequency arrays which is out feature set for each audio file.","4dd9cb87":"## Running sample data on defined functions","1c40822e":"## Utility function to extract features from wav files\n* Pre-process data and transform double channel to single channel\n* Extract the chromagraph from the audio file\n* Find note frequency","ab9f8216":"## Hyper-parameters","539b8017":"## Utility function to plot a heat map and frequency of each note","8e460898":"## Adding necessary libraries"}}