{"cell_type":{"6d688b92":"code","a949dcdd":"code","17fd0965":"code","7c4c7667":"code","ef268f03":"code","09bcfd41":"code","99b4a388":"code","e3d5826f":"code","ccf1f838":"code","80e97d93":"code","8d7aa01d":"code","4bd18baa":"code","70c81a6b":"code","b58f073f":"code","44cf4b96":"code","6fa6062a":"markdown","98a98796":"markdown","cb86be13":"markdown","4e6b079a":"markdown","9b52849d":"markdown","f038d079":"markdown","98197c7e":"markdown","e43c7d97":"markdown","e62b6942":"markdown","8d50a6c1":"markdown","73736ff2":"markdown"},"source":{"6d688b92":"#importing the required libraries\n\nimport numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import GridSearchCV,train_test_split\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","a949dcdd":"# exploring the data\n\ndata = pd.read_csv(\"..\/input\/data.csv\")\n\ndata.head()","17fd0965":"data.drop([\"id\",\"Unnamed: 32\"],axis=1,inplace=True)   # dropping some un important fields \n\ndata.info()","7c4c7667":"data.describe()","ef268f03":"labeller = LabelEncoder()\nlabeller.fit(data.diagnosis)\ndata.diagnosis = labeller.transform(data.diagnosis)","09bcfd41":"y = data.diagnosis.values\ndata.drop([\"diagnosis\"],axis=1,inplace=True)\nx = data.values","99b4a388":"pca = PCA(n_components=2,whiten=True)\npca.fit(x)\nx_new = pca.transform(x)\n\nprint(\"variance ratio: \", pca.explained_variance_ratio_)\nprint(\"sum of variance percentage: \", sum(pca.explained_variance_ratio_))","e3d5826f":"train_x, test_x, train_y, test_y = train_test_split(x_new,y,test_size=0.2,random_state=99)","ccf1f838":"# default Logistic Regression\nlogreg_default = LogisticRegression()\nlogreg_default.fit(train_x,train_y)\nprint(\"Default Real Test Score: \",logreg_default.score(test_x,test_y))","80e97d93":"# GridSearch implemented on some fiels\nparameters = {\"C\":np.arange(0.1,2.0,0.1),\"penalty\":(\"l2\",\"l1\")\n             ,\"max_iter\":np.arange(100,2000,100)}\nlogreg_grid = LogisticRegression()\n\nlogreg_cv = GridSearchCV(logreg_grid,parameters)\nlogreg_cv.fit(train_x,train_y)\nprint(\"tuned hyperparameters: \",logreg_cv.best_params_)\nprint(\"tuned highest score: \",logreg_cv.best_score_)\n\nlogreg_grid = LogisticRegression(C=0.2,penalty=\"l1\",max_iter=100)\nlogreg_grid.fit(train_x,train_y)\nprint(\"Tuned Real Test Result: \",logreg_grid.score(test_x,test_y))","8d7aa01d":"# default KNN\nknn_default = KNeighborsClassifier()\nknn_default.fit(train_x,train_y)\nprint(\"Default Real Test Score: \",knn_default.score(test_x,test_y))","4bd18baa":"# GridSearch implemented KNN\nparameters = {\"algorithm\":(\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"), \"n_neighbors\":np.arange(1,20),\"p\":(2,1)}\nknn_grid = KNeighborsClassifier()\n\nknn_cv = GridSearchCV(estimator=knn_grid,param_grid=parameters)\nknn_cv.fit(train_x,train_y)\nprint(\"tuned hyperparameters: \",knn_cv.best_params_)\nprint(\"tuned highest score: \",knn_cv.best_score_)\n\nknn_grid = KNeighborsClassifier(algorithm=\"auto\",n_neighbors=7,p=1)\nknn_grid.fit(train_x,train_y)\nprint(\"Tuned Real Test Result: \",knn_grid.score(test_x,test_y))","70c81a6b":"# default SVC\nsvc_default = SVC()\nsvc_default.fit(train_x,train_y)\nprint(\"Default Real Test Score: \",svc_default.score(test_x,test_y))","b58f073f":"# GridSearch implemented Support Vector\nparameters = {\"C\":np.arange(0.1,2.0,0.1),\"kernel\":(\"linear\", \"poly\", \"rbf\", \"sigmoid\"),\"probability\":(False,True)}\nsvc_grid = SVC()\n\nsvc_cv = GridSearchCV(estimator=svc_grid,param_grid=parameters)\nsvc_cv.fit(train_x,train_y)\nprint(\"tuned hyperparameters: \",svc_cv.best_params_)\nprint(\"tuned highest score: \",svc_cv.best_score_)","44cf4b96":"svc_grid = SVC(C=0.9,kernel=\"rbf\",probability=False)\nsvc_grid.fit(train_x,train_y)\nprint(\"Tuned Real Test Result: \",svc_grid.score(test_x,test_y))","6fa6062a":"### ***Splitting***","98a98796":"### ***PCA***","cb86be13":"### ***Machine Learning Models***","4e6b079a":"### ***Logistic Regression***","9b52849d":"### ***SVC***","f038d079":"### ***EDA***","98197c7e":"### ***K Nearest Neighbors***","e43c7d97":"### ***Labelling***","e62b6942":"### ***Separeting***","8d50a6c1":"## Conclusion\n\n### GridSearch might be useful sometimes but mostly our Default models are good enough","73736ff2":"# **Introduction**\n\n### Grid Search is a way of tuning our models and I personally find it so useful because I don't have 100% deep knowledge about each and every parameter on whole models. So for me Grid Search is life saver.\n\n### in this kernel I will try to see and show difference between scores from Default models and tuned by Grid Search models.\n\n### My models will be KNearestNeighbor, LogisticRegression and RandomForest from sklearn.\n\n### dataset will be reduced by using PCA to make my life easier to produce good visuals."}}