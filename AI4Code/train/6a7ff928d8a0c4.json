{"cell_type":{"d1230be7":"code","7805f28e":"code","be0fd43d":"code","deb24253":"code","8e9ba45f":"code","b0e9f058":"code","d12170c2":"code","6912d2c9":"code","ff8bd6ac":"code","57e04c38":"code","5f97bac7":"code","6fbfaaf6":"code","85055728":"code","9937b8bc":"code","1eeb0f86":"code","7214630f":"code","c2c8be53":"code","138d8165":"code","519fac8d":"code","1bb455fb":"code","19d48c5d":"code","f50a9da4":"code","9b643f40":"code","c4d47b31":"code","cd73db61":"code","3d7d2994":"code","cb02adcc":"code","6e7e7264":"code","5e990539":"markdown","8954b4a6":"markdown","93e456cb":"markdown","e3ac010e":"markdown","434a3826":"markdown","bca2abb2":"markdown","66d4196d":"markdown","465b2f94":"markdown","e68b67c9":"markdown","728893c2":"markdown"},"source":{"d1230be7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7805f28e":"df = pd.read_csv('..\/input\/home-data-for-ml-course\/train.csv')\ndf.head()","be0fd43d":"df.info()","deb24253":"for col in df.columns:\n    if df[col].count()<1350:\n        df.drop(col,axis=1,inplace=True)\n\ndf = df.select_dtypes(exclude=['object'])\n\ndf.info()","8e9ba45f":"df.head()","b0e9f058":"from sklearn.metrics import mean_absolute_error \n\ndef get_mae(actual,predicted):\n    return mean_absolute_error(actual,predicted)","d12170c2":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.impute import SimpleImputer","6912d2c9":"X = df.loc[:,'Id':'YrSold']\ny = df['SalePrice']","ff8bd6ac":"train_X,valid_X,train_y,valid_y = train_test_split(X,y,train_size=0.8,test_size=0.2,random_state=42)\n\nimputer = SimpleImputer(strategy='mean')\nimputed_train_X = pd.DataFrame(imputer.fit_transform(train_X))\nimputed_valid_X = pd.DataFrame(imputer.transform(valid_X))\n\nimputed_train_X.columns = train_X.columns\nimputed_valid_X.columns = valid_X.columns","57e04c38":"for i in [10,25,50,75,100,250,500,750,1000,1250,1500,1750,2000,2500,3500,5000,10000]:\n    model = RandomForestRegressor(n_estimators=i,random_state=42)\n    model.fit(imputed_train_X,train_y)\n    preds = model.predict(imputed_valid_X)\n    print('MAE for',i,'trees is',get_mae(valid_y,preds))","5f97bac7":"plot_list = []","6fbfaaf6":"for i in range(500,1001):\n    model = RandomForestRegressor(n_estimators=i,random_state=42)\n    model.fit(imputed_train_X,train_y)\n    preds = model.predict(imputed_valid_X)\n    plot_list.append(get_mae(valid_y,preds))\n    print(i,'done')","85055728":"df_to_plot = pd.DataFrame({'mae':plot_list})\n\nplt.plot(list(range(500,1001)),df_to_plot['mae'])\n\nmin_mae_index = plot_list.index(min(plot_list))\nplt.annotate(\"({},{})\".format(500+min_mae_index,min(plot_list)),(500+min_mae_index,min(plot_list)),(500+min_mae_index+7,min(plot_list)))\n\nplt.plot(500+min_mae_index,min(plot_list),'o')\n\nplt.show()","9937b8bc":"train_X,valid_X,train_y,valid_y = train_test_split(X,y,train_size=0.8,test_size=0.2,random_state=42)\n\nimputer = SimpleImputer(strategy='median')\nimputed_train_X = pd.DataFrame(imputer.fit_transform(train_X))\nimputed_valid_X = pd.DataFrame(imputer.transform(valid_X))\n\nimputed_train_X.columns = train_X.columns\nimputed_valid_X.columns = valid_X.columns","1eeb0f86":"for i in [10,25,50,75,100,250,500,750,1000,1250,1500,1750,2000,2500,3500,5000,10000]:\n    model = RandomForestRegressor(n_estimators=i,random_state=42)\n    model.fit(imputed_train_X,train_y)\n    preds = model.predict(imputed_valid_X)\n    print('MAE for',i,'trees is',get_mae(valid_y,preds))","7214630f":"plot_list = []","c2c8be53":"for i in range(500,1001):\n    model = RandomForestRegressor(n_estimators=i,random_state=42)\n    model.fit(imputed_train_X,train_y)\n    preds = model.predict(imputed_valid_X)\n    plot_list.append(get_mae(valid_y,preds))\n    print(i,'done')","138d8165":"df_to_plot = pd.DataFrame({'mae':plot_list})\n\nplt.plot(list(range(500,1001)),df_to_plot['mae'])\n\nmin_mae_index = plot_list.index(min(plot_list))\nplt.annotate(\"({},{})\".format(500+min_mae_index,min(plot_list)),(500+min_mae_index,min(plot_list)),(500+min_mae_index+7,min(plot_list)))\n\nplt.plot(500+min_mae_index,min(plot_list),'o')\n\nplt.show()","519fac8d":"train_X,valid_X,train_y,valid_y = train_test_split(X,y,train_size=0.8,test_size=0.2,random_state=42)\n\nimputer = SimpleImputer(strategy='most_frequent')\nimputed_train_X = pd.DataFrame(imputer.fit_transform(train_X))\nimputed_valid_X = pd.DataFrame(imputer.transform(valid_X))\n\nimputed_train_X.columns = train_X.columns\nimputed_valid_X.columns = valid_X.columns","1bb455fb":"for i in [10,25,50,75,100,250,500,750,1000,1250,1500,1750,2000,2500,3500,5000,10000]:\n    model = RandomForestRegressor(n_estimators=i,random_state=42)\n    model.fit(imputed_train_X,train_y)\n    preds = model.predict(imputed_valid_X)\n    print('MAE for',i,'trees is',get_mae(valid_y,preds))","19d48c5d":"plot_list = []","f50a9da4":"for i in range(500,1001):\n    model = RandomForestRegressor(n_estimators=i,random_state=42)\n    model.fit(imputed_train_X,train_y)\n    preds = model.predict(imputed_valid_X)\n    plot_list.append(get_mae(valid_y,preds))\n    print(i,'done')","9b643f40":"df_to_plot = pd.DataFrame({'mae':plot_list})\n\nplt.plot(list(range(500,1001)),df_to_plot['mae'])\n\nmin_mae_index = plot_list.index(min(plot_list))\nplt.annotate(\"({},{})\".format(500+min_mae_index,min(plot_list)),(500+min_mae_index,min(plot_list)),(500+min_mae_index+7,min(plot_list)))\n\nplt.plot(500+min_mae_index,min(plot_list),'o')\n\nplt.show()","c4d47b31":"train_X,valid_X,train_y,valid_y = train_test_split(X,y,train_size=0.8,test_size=0.2,random_state=42)\n\ncols_with_missing = [col for col in train_X.columns\n                     if train_X[col].isnull().any()]\n\ntrain_X_m3 = train_X.copy()\nvalid_X_m3 = valid_X.copy()\n\nfor col in cols_with_missing:\n    train_X_m3[col + '_was_missing'] = train_X_m3[col].isnull()\n    valid_X_m3[col + '_was_missing'] = valid_X_m3[col].isnull()\n\n#Let's go with the mean as the strategy this time.\nimputer = SimpleImputer(strategy='mean')\nimputed_train_X = pd.DataFrame(imputer.fit_transform(train_X_m3))\nimputed_valid_X = pd.DataFrame(imputer.transform(valid_X_m3))\n\nimputed_train_X.columns = train_X_m3.columns\nimputed_valid_X.columns = valid_X_m3.columns","cd73db61":"for i in [10,25,50,75,100,250,500,750,1000,1250,1500,1750,2000,2500,3500,5000,10000]:\n    model = RandomForestRegressor(n_estimators=i,random_state=42)\n    model.fit(imputed_train_X,train_y)\n    preds = model.predict(imputed_valid_X)\n    print('MAE for',i,'trees is',get_mae(valid_y,preds))","3d7d2994":"plot_list = []","cb02adcc":"for i in range(500,1001):\n    model = RandomForestRegressor(n_estimators=i,random_state=42)\n    model.fit(imputed_train_X,train_y)\n    preds = model.predict(imputed_valid_X)\n    plot_list.append(get_mae(valid_y,preds))\n    print(i,'done')","6e7e7264":"df_to_plot = pd.DataFrame({'mae':plot_list})\n\nplt.plot(list(range(500,1001)),df_to_plot['mae'])\n\nmin_mae_index = plot_list.index(min(plot_list))\nplt.annotate(\"({},{})\".format(500+min_mae_index,min(plot_list)),(500+min_mae_index,min(plot_list)),(500+min_mae_index+7,min(plot_list)))\n\nplt.plot(500+min_mae_index,min(plot_list),'o')\n\nplt.show()","5e990539":"### 2. RandomForestRegressor - n_estimators = [10,25,50,75,100,250,500,750,1000,1250,1500,1750,2000,2500,3500,5000,10000]\n###    SimpleImputer strategy - median","8954b4a6":"#### So I see that around 750 trees is where the MAE went the lowest. I will see how the MAE changes from 500 trees to 1000 trees by plotting it","93e456cb":"### That's all for now folks!","e3ac010e":"### Let me first define a function to simply get the mean squared error between the predicted values of the models that I will use and the actual values in the validation set","434a3826":"#### Again, I see that around 750 trees is where the MAE went the lowest. I will see how the MAE changes from 500 trees to 1000 trees by plotting it","bca2abb2":"### Now I will get some things ready that I will be using for every variation of models","66d4196d":" ### 3. RandomForestRegressor - n_estimators = [10,25,50,75,100,250,500,750,1000,1250,1500,1750,2000,2500,3500,5000,10000]\n###    SimpleImputer strategy - most_frequent","465b2f94":"### In the Kaggle course, only a few columns were chosen so I will start with choosing all the columns (except sales price ofcourse) to train models. Let's see what happens \ud83d\ude09","e68b67c9":"### 1. RandomForestRegressor - n_estimators = [10,25,50,75,100,250,500,750,1000,1250,1500,1750,2000,2500,3500,5000,10000]\n###    SimpleImputer strategy - mean","728893c2":" ### 3. RandomForestRegressor - n_estimators = [10,25,50,75,100,250,500,750,1000,1250,1500,1750,2000,2500,3500,5000,10000]\n###    SimpleImputer strategy - mean (adding a column indicating which column was imputed)"}}