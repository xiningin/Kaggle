{"cell_type":{"a480592d":"code","a85af025":"code","33dfde63":"code","06fac5cc":"code","7cf4a3a0":"code","858a54b7":"code","83c9962a":"code","6bc3165e":"code","edc54606":"code","5e01b3dc":"code","47923153":"code","6f0f47d2":"code","9c111894":"code","9e4e8dac":"code","d444f63b":"code","1e33de22":"code","78897983":"code","5e9d6574":"code","eb66895e":"code","45232433":"code","97a0a7ea":"code","ee74ad68":"code","2c50e827":"code","26cf70c6":"code","5f910508":"code","0d480c4d":"code","f8edefea":"code","13ae378f":"code","d52ec2a9":"code","51a47bba":"code","2f1055ba":"code","a5704158":"code","a3680e19":"code","474bd082":"code","a95780aa":"code","4f6ca597":"code","5bedf04c":"code","e53c9c04":"code","3b84c9b8":"code","5bac1a71":"code","c835249b":"code","8d2f4773":"code","e26501bf":"code","03ba2b4b":"code","ffd2f4ee":"code","f0158394":"code","f1b734e8":"code","68090b0a":"code","2bb1ab15":"code","bc059589":"code","8d37499e":"code","0e3dda11":"code","9607a3ec":"code","571ad346":"code","434bba17":"code","5b28ef7d":"code","a8f6b190":"code","e5d740e1":"code","2b96c6c9":"code","ffd1f281":"code","b1d845fe":"code","738ac504":"code","d69625e6":"code","7fada8a3":"code","d48ff0f2":"code","088b7c8d":"code","47f7fc85":"code","158ba881":"code","6aa56996":"code","592cd44b":"code","48088663":"code","8808ea06":"code","a8884012":"code","3012dac1":"markdown","88a3ad63":"markdown","ea5e1919":"markdown","c6127d63":"markdown","47e25cda":"markdown","c70737c4":"markdown","c6dac2ca":"markdown","6390056d":"markdown","4959220b":"markdown","41dea322":"markdown","ec39056d":"markdown","f25e5fbe":"markdown","43fa406a":"markdown","a0590d47":"markdown","4c97df03":"markdown","03974574":"markdown","2dbd1e9d":"markdown","1b27deab":"markdown","51efea4e":"markdown","4710d714":"markdown","0f6204b0":"markdown","d3918537":"markdown","13cdafc8":"markdown","46253881":"markdown","f277e205":"markdown","3fe32af8":"markdown","808295fd":"markdown","346e952c":"markdown","be20b397":"markdown","4d0d3c97":"markdown","707d4356":"markdown","caeeefdb":"markdown","1f252088":"markdown","f24922ae":"markdown","7e2e8adb":"markdown","caade18c":"markdown","6edd13f8":"markdown","4a859c5b":"markdown","9eeabbec":"markdown","c5951179":"markdown","28af56aa":"markdown","b2380531":"markdown","da28e527":"markdown","98691283":"markdown","ab6c9edc":"markdown","067e21e9":"markdown","9086b3c0":"markdown","354b7ec3":"markdown","77779ea3":"markdown","12f8db42":"markdown","9d871a85":"markdown","c7f71c0e":"markdown","36e787ff":"markdown","dafc4510":"markdown","1c05b9b1":"markdown","6c9553b0":"markdown"},"source":{"a480592d":"import os \nimport torch  \nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import f1_score \nfrom PIL import Image\nfrom tqdm.notebook import tqdm\nfrom torch.utils.data import DataLoader, Dataset, random_split\nimport torchvision.models as models\nimport torchvision.transforms as T\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom torchvision.utils import make_grid\n\n%matplotlib inline","a85af025":"train_dataset_dir = '..\/input\/intel-image-classification\/seg_train\/seg_train'\ntest_dataset_dir = '..\/input\/intel-image-classification\/seg_test\/seg_test'\n\ndataset_dir = ['..\/input\/intel-image-classification\/seg_train\/seg_train',\n               '..\/input\/intel-image-classification\/seg_test\/seg_test']","33dfde63":"label_list=['buildings','forest','glacier','mountain','sea','street']\n\nlabels = {label_list:i for i,label_list in enumerate(label_list)}\nlabels","06fac5cc":"\ndef create_dataset(dataset_path,labels,file_name):\n    labelled_arr=np.array([])\n    for subdir, label in labels.items():\n        img_dir = os.path.join(dataset_path, subdir) \n        files = np.array(os.listdir(img_dir)).reshape(-1,1) \n        target = np.array([label for i in range(files.shape[0])]).reshape(-1,1) \n        data = np.concatenate((files, target), axis = 1) \n        labelled_arr = np.append(labelled_arr, data)\n    labelled_arr = labelled_arr.reshape(-1,2)\n\n    dataframe = pd.DataFrame(labelled_arr)\n    dataframe.columns = ['image', 'label']\n    dataframe['label'] = dataframe['label'].astype('int')\n    print (dataframe.head())\n    print (file_name)\n    dataframe.to_csv(file_name, index = False)\n    return dataframe\n    ","7cf4a3a0":"train_df = create_dataset(train_dataset_dir,labels,'.\/train.csv')\ntest_df = create_dataset(test_dataset_dir, labels,'.\/test.csv')","858a54b7":"class IntelImageDataset(Dataset):\n    def __init__(self, dataframe, data_dir, label_dict, transform = None):\n        self.df = dataframe\n        self.data_dir = data_dir\n        self.label_dict = label_dict\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        img_name, label = self.df.loc[idx]\n        class_labels = list(self.label_dict.keys())\n        img_path = self.data_dir + '\/' + class_labels[label] + '\/' + img_name\n        img = img = Image.open(img_path)\n        \n        if self.transform:\n            img = self.transform(img)\n        \n        return img, label ","83c9962a":"train_tfms = T.Compose([\n    T.Resize([256,256]),\n    T.ToTensor()\n#     T.RandomErasing()\n])\n\ntest_tfms = T.Compose([\n    T.Resize([256, 256]),\n    T.ToTensor(),\n])","6bc3165e":"train_ds = IntelImageDataset(train_df, train_dataset_dir, labels, transform = train_tfms)\n\n\ntest_ds = IntelImageDataset(test_df, test_dataset_dir, labels, transform = test_tfms)","edc54606":"len(train_ds), len(test_ds)","5e01b3dc":"def show_sample(img, target, invert=True):\n    if invert:\n        plt.imshow(1 - img.permute((1, 2, 0)))\n    else:\n        plt.imshow(img.permute(1, 2, 0))\n    print('Labels:', target)","47923153":"show_sample(*train_ds[14000],invert=False)","6f0f47d2":"val_size = 4000\ntrain_size = len(train_ds) - val_size\n\ntrain_ds, val_ds = random_split(train_ds, [train_size, val_size])\nlen(train_ds), len(val_ds)","9c111894":"batch_size=32\n\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True, \n                      num_workers=3, pin_memory=True)\nval_dl = DataLoader(val_ds, batch_size, \n                    num_workers=2, pin_memory=True)","9e4e8dac":"simple_model = nn.Sequential(\n    nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1),\n    nn.MaxPool2d(2, 2)\n)","d444f63b":"for images, labels in train_dl:\n    print('images.shape:', images.shape)\n    print (labels)\n    out = simple_model(images)\n    print('out.shape:', out.shape)\n    break","1e33de22":"def show_batch(dl, invert=True):\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize=(16, 16))\n        ax.set_xticks([]); ax.set_yticks([])\n        data = 1-images if invert else images\n        ax.imshow(make_grid(data, nrow=8).permute(1, 2, 0))\n        break","78897983":"show_batch(train_dl, invert=True)","5e9d6574":"show_batch(train_dl, invert=False)","eb66895e":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","45232433":"device = get_default_device()\ndevice","97a0a7ea":"train_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)","ee74ad68":"\ndef accuracy(outputs, target):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == target).item() \/ len(preds))","2c50e827":"class IntelImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, targets = batch \n        out = self(images)                      \n        loss = F.cross_entropy(out, targets)      \n        return loss\n    \n    def validation_step(self, batch):\n        images, targets = batch \n        out = self(images)                           # Generate predictions\n        loss = F.cross_entropy(out, targets)  # Calculate loss\n        score = accuracy(out, targets)\n        return {'val_loss': loss.detach(), 'val_score': score.detach() }\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_scores = [x['val_score'] for x in outputs]\n        epoch_score = torch.stack(batch_scores).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_score': epoch_score.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_score: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_score']))","26cf70c6":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","5f910508":"class FNNModel(IntelImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        # hidden layer1\n        self.linear1 = nn.Linear(3*256*256, 512)\n        # hidden layer2\n        self.linear2 = nn.Linear(512,256)\n        # hidden layer3\n        self.linear3 = nn.Linear(256,128)\n        # hidden layer4\n        self.linear4 = nn.Linear(128,64)\n        # output layer\n        self.linear5 = nn.Linear(64, 6)\n        \n    def forward(self, xb):\n        # Flatten images into vectors\n        out = xb.view(xb.size(0), -1)\n        # Apply layers & activation functions\n        \n        # Get intermediate outputs using hidden layer1\n        out = self.linear1(out)\n        # Apply activation function\n        out = F.relu(out)\n        \n        # Get intermediate outputs using hidden layer2\n        out = self.linear2(out)\n        # Apply activation function\n        out = F.relu(out)\n        \n        # Get intermediate outputs using hidden layer3\n        out = self.linear3(out)\n        # Apply activation function\n        out = F.relu(out)\n        \n        # Get intermediate outputs using hidden layer4\n        out = self.linear4(out)\n        # Apply activation function\n        out = F.relu(out)\n        \n        \n        # Get predictions using output layer\n        out = self.linear5(out)\n        return out","0d480c4d":"model = FNNModel()\nmodel","f8edefea":"model = to_device(model,device)","13ae378f":"for images, labels in train_dl:\n    print('images.shape:', images.shape)\n    out = model(images)\n    print (labels)\n    print('out.shape:', out.shape)\n    print('out[0]:', out[0])\n    break","d52ec2a9":"history = [evaluate(model, val_dl)]\nhistory","51a47bba":"history += fit(10, 0.001, model, train_dl, val_dl)","2f1055ba":"def plot_accuracies(history):\n#     print(history)\n    accuracies = [x['val_score'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');","a5704158":"plot_accuracies(history)","a3680e19":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');","474bd082":"plot_losses(history)","a95780aa":"def predict_image(img, model):\n    # Convert to a batch of 1\n    xb = to_device(img.unsqueeze(0), device)\n    # Get predictions from model\n    yb = model(xb)\n    # Pick index with highest probability\n    _, preds  = torch.max(yb, dim=1)\n    # Retrieve the class label\n    return label_list[preds[0].item()]","4f6ca597":"img,label = test_ds[0]\nprint (label)\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', label_list[label], ', Predicted:', predict_image(img, model))","5bedf04c":"img,label = test_ds[10]\nprint (label)\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', label_list[label], ', Predicted:', predict_image(img, model))","e53c9c04":"class CnnModel(IntelImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 64 x 128 x 128\n\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 128 x 64 x 64\n\n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 256 x 32 x 32\n\n            nn.Flatten(), \n            nn.Linear(256*32*32, 1024),\n            nn.ReLU(),\n            nn.Linear(1024, 512),\n            nn.ReLU(),\n            nn.Linear(512,6))\n        \n    def forward(self, xb):\n        return self.network(xb)","3b84c9b8":"model1 = CnnModel()\nmodel1","5bac1a71":"model1 = to_device(CnnModel(), device)","c835249b":"for images, labels in train_dl:\n    print('images.shape:', images.shape)\n    out = model1(images)\n    print (labels)\n    print('out.shape:', out.shape)\n    print('out[0]:', out[0])\n    break","8d2f4773":"evaluate(model1, val_dl)","e26501bf":"num_epochs = 10\nopt_func = torch.optim.Adam\nlr = 1e-4","03ba2b4b":"%%time\nhistory1 = fit(num_epochs, lr, model1, train_dl, val_dl, opt_func)","ffd2f4ee":"plot_accuracies(history1)","f0158394":"plot_losses(history1)","f1b734e8":"img,label = test_ds[0]\nprint (label)\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', label_list[label], ', Predicted:', predict_image(img, model1))","68090b0a":"img,label = test_ds[10]\nprint (label)\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', label_list[label], ', Predicted:', predict_image(img, model1))","2bb1ab15":"\ntrain_tfms = T.Compose([\n    T.Resize([256,256]),\n    T.RandomHorizontalFlip(), \n    T.RandomRotation(10),\n    T.ToTensor(), \n    T.RandomErasing(inplace=True)\n])\n\nvalid_tfms = T.Compose([\n    T.Resize([256,256]), \n    T.ToTensor(),\n])","bc059589":"train_ds2 = IntelImageDataset(train_df, train_dataset_dir, labels, transform = train_tfms)\n\n\ntest_ds2 = IntelImageDataset(test_df, test_dataset_dir, labels, transform = test_tfms)","8d37499e":"show_sample(*train_ds2[14000],invert=False)","0e3dda11":"show_sample(*train_ds2[14000],invert=False)","9607a3ec":"val_size = 4000\ntrain_size = len(train_ds2) - val_size\n\ntrain_ds2, val_ds2 = random_split(train_ds2, [train_size, val_size])\nlen(train_ds2), len(val_ds2)","571ad346":"batch_size = 32","434bba17":"train_dl2 = DataLoader(train_ds2, batch_size, shuffle=True, \n                      num_workers=3, pin_memory=True)\nval_dl2 = DataLoader(val_ds2, batch_size*2, \n                    num_workers=2, pin_memory=True)","5b28ef7d":"show_batch(train_dl2, invert=True)","a8f6b190":"class IntelImageResnet(IntelImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        # Use a pretrained model\n        self.network = models.resnet34(pretrained=True)\n        # Replace last layer\n        num_ftrs = self.network.fc.in_features\n        self.network.fc = nn.Linear(num_ftrs, 6)\n    \n    def forward(self, xb):\n        return torch.sigmoid(self.network(xb))\n    \n    def freeze(self):\n        # To freeze the residual layers\n        for param in self.network.parameters():\n            param.require_grad = False\n        for param in self.network.fc.parameters():\n            param.require_grad = True\n    \n    def unfreeze(self):\n        # Unfreeze all layers\n        for param in self.network.parameters():\n            param.require_grad = True","e5d740e1":"train_dl2 = DeviceDataLoader(train_dl2, device)\nval_dl2 = DeviceDataLoader(val_dl2, device)\nto_device(model, device);","2b96c6c9":"@torch.no_grad()\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\ndef fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache()\n    history = []\n    \n    # Set up cutom optimizer with weight decay\n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    # Set up one-cycle learning rate scheduler\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n                                                steps_per_epoch=len(train_loader))\n    \n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        lrs = []\n        for batch in tqdm(train_loader):\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            \n            # Gradient clipping\n            if grad_clip: \n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n            \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            # Record & update learning rate\n            lrs.append(get_lr(optimizer))\n            sched.step()\n        \n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","ffd1f281":"model2 = to_device(IntelImageResnet(), device)","b1d845fe":"history2 = [evaluate(model2, val_dl2)]\nhistory2","738ac504":"model2.freeze()","d69625e6":"epochs = 10\nmax_lr = 0.01\ngrad_clip = 0.1\nweight_decay = 1e-4\nopt_func = torch.optim.SGD","7fada8a3":"%%time\nhistory2 += fit_one_cycle(epochs, max_lr, model2, train_dl2, val_dl2, \n                         grad_clip=grad_clip, \n                         weight_decay=weight_decay, \n                         opt_func=opt_func)","d48ff0f2":"model2.unfreeze()","088b7c8d":"%%time\nhistory2 += fit_one_cycle(epochs, 0.01, model2, train_dl2, val_dl2, \n                         grad_clip=grad_clip, \n                         weight_decay=weight_decay, \n                         opt_func=opt_func)","47f7fc85":"plot_accuracies(history2)","158ba881":"plot_losses(history2)","6aa56996":"img,label = test_ds[0]\nprint (label)\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', label_list[label], ', Predicted:', predict_image(img, model2))","592cd44b":"img,label = test_ds[10]\nprint (label)\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', label_list[label], ', Predicted:', predict_image(img, model2))","48088663":"!pip install jovian --upgrade -q","8808ea06":"import jovian","a8884012":"project_name='intelimageclassification'\njovian.commit(project=project_name)","3012dac1":"moving model to GPU","88a3ad63":"To improve the accuarcy we can train the model with higher epochs and different learning rates","ea5e1919":"### Training and validation dataset","c6127d63":"Making the class to create dataset. This class will transform the dataset using given transformers","47e25cda":"So from feed forward neural network model we are getting accuracy of 50% also model could not able predict the given images correctly.","c70737c4":"### Testing with Individual images","c6dac2ca":"Initialy, both the training and validation loss decreasing but after certain point training loss continues to decreas while thevalidation loss stops decreasing and start to increase instead. This is the example of **Overfittng**.","6390056d":"Making a dicionary of labels which will be helpful to make labelcolumn in dataframe","4959220b":"I am using few tranform functions to transform the dataset\nResize() = Resize the input Image to the given size.\nRandomHorizontalFlip() = Horizontally flip the given image randomly.\nRandomRotation() = Rotate Image by given angle\nRandomErasing() = Randomly selects a rectangle region in an image and erases its pixels","41dea322":"Lets see the images after transformation","ec39056d":"So after 10 epochs we are getting accuracy around 50% for simple feed forward neural network.","f25e5fbe":"Here I am using pretrained ResNet34 Model to train this dataset","43fa406a":"### Convolutional Neural Network","a0590d47":"lets plot the accuracy of validation dataset to see howmodel improves over time","4c97df03":"We will maek a dataframe of image name and its label then store it in csv file.","03974574":"Creating dataset using transformations","2dbd1e9d":"lets get the initial accuracy of the model before traning","1b27deab":"## **ResNet & Regularization**","51efea4e":"After 10 epochs we are getting accuracy around 76%.","4710d714":"Lets plot the training lossesand validation losses to see if the model is overfitting or not.","0f6204b0":"### Simple Feed Forward Neural Network","d3918537":"Train the model using hyperparameters epchs, learning rate","13cdafc8":"We are getting 94% of accuracy","46253881":"To use a GPU, we have defined a couple of helper functions (get_default_device & to_device) and a helper class DeviceDataLoader to move our model & data to the GPU as required.","f277e205":"This Notebook is about building a powerful Neural networks that can classify Natural Scenes around the world. The Dataset is from **Intel Image classification challenge**\n\nThe goal is classify the images under the 6 caregories '**buildings**','**forest**','**glacier**','**mountain**','**sea**','**street**'.\n\nIn this notebook I have compared the performance 3 Models : **Feed forward neural network**,**Convolutional neural network**  and **Resnet34**. ","3fe32af8":"Define the hyperparameters to train the model","808295fd":"1. Learning rate scheduling = One Cycle Learning Rate Policy which start with lower learning rate, gradualy start increasing it batch by batch to the given high learning rate for about 30% of the epochs and then gradually decreasing to the lower value forthe remaining epochs\n\n2. Weight decay: Regularization technique which prevents the weights from becoming too large by adding an additional term to the loss function\n\n4. Gradient clipping: Apart from the layer weights and outputs, it also helpful to limit the values of gradients to a small range to prevent undesirable changes in parameters due to large gradient values. This simple yet effective technique is called gradient clipping.","346e952c":"Both the training loss and validation loss decreaseing gradualy so there is caseof overfitting","be20b397":"Lets define a simple feed forward neural network model FNNModel() by extending a IntelImageClassificationBase() classwhich contains helper methods","4d0d3c97":"creating model with 4 hidden leayers and ReLu activation ","707d4356":"### Import libraries","caeeefdb":"### Improving Fit function","1f252088":"### Data Augmentation","f24922ae":"Defining a function to look Images in batches using make_grid method from torchvision.","7e2e8adb":"So from Convolutional neural network model we are getting accuracy of 76% also model could able predict the given images correctly. But model is overfitted.","caade18c":"Splitting datset into 3 parts \n\n1. **Training set** - used to train the model i.e. compute the loss and adjust the weights of the model using gradient descent.\n2. **Validation set** - used to evaluate the model while training, adjust hyperparameters (learning rate etc.) and pick the best version of the model.\n3. **Test set** - used to compare different models, or different types of modeling approaches, and report the final accuracy of the model.","6edd13f8":"Lets train the CNN model with given hyperparameter","4a859c5b":"### Exploring the Data","9eeabbec":"# **Summary**","c5951179":"We can now wrap our training and validation data loaders using DeviceDataLoader for automatically transferring batches of data to the GPU (if available), and use to_device to move our model to the GPU ","28af56aa":"Creating DataLoaders for Training and Valiadation sets in batches","b2380531":"Using Sequential()to chain the layers and activations functions into a single network architecture.","da28e527":"As images are in dataset are of different shape using Resize transformer to resize allimages into one shape also conerting this images into tensors using ToTensor\n","98691283":"Lets define a function which predict label for a single image","ab6c9edc":"Here's a summary the different topics and models covered in this notebook\n\n\n1. Downloading, Extracting and  Creating a dataset using torchvision\n2. Show randombatched of images using make_grid function\n3. Creating a simple feed forward neural network with hidden layer\n4. Creating a Convolutional neural network\n5. ResNet and Data augmentation\n6. Training the models and Visualizing accuracies and losees\n7. Generating a predictions on single images\n8. ResNet model with (94%) accuracy out perform CNN (76%) and feedforward neurl network(49%)models ","067e21e9":"There are a few important changes we'll make while creating the datasets:","9086b3c0":"Creating traning and test dataset using IntelImagedataset class","354b7ec3":"Defining a evaluate function which willperform validation phase and fir function which will perform training process","77779ea3":"Defining accuracy function to get the accuracy","12f8db42":"### Preparing Dataset","9d871a85":"Creating a class IntelImageClassificationBase() which contain helper methods for training ad validation","c7f71c0e":"# Deep Learning with PyTorch","36e787ff":"Lets see thebatches of images after data augmentation","dafc4510":"Now lets unfreeze all the layers","1c05b9b1":"Lets define Convolutional neural network CnnModel() by extending a IntelImageClassificationBase()","6c9553b0":"Lets first train the model on the final layer which means we will not change the parameters of layers except final layer"}}