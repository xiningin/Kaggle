{"cell_type":{"c2913533":"code","2d8e1e83":"code","bd4050bf":"code","0984139e":"code","fb497251":"code","a67063a1":"code","72d34660":"code","e3288bcd":"code","5220f84c":"code","bf629d0d":"code","68e41ece":"code","1553bb1d":"code","12ea13d6":"code","41a478e4":"code","ee1f8872":"code","c0d51d8a":"code","f4fe05fa":"code","eb0f08eb":"code","e72f366d":"code","5f1ecad8":"code","3f108859":"code","863addc4":"code","619ee6cf":"code","50c41c87":"code","9db9d12c":"code","66e1bd04":"code","d0012e9e":"code","a8c268c6":"code","20efd899":"code","8e5b306e":"code","0863b94d":"code","d81174c1":"code","d6479c82":"code","7e9a4d88":"code","93893db2":"code","7e16a51e":"code","5603d5ea":"code","a146a9e0":"code","f1d872e6":"code","6bfc2f13":"code","24fdb503":"code","f8bd9f4a":"code","dbe280bf":"code","144422b6":"code","ead4f5e5":"code","c256a981":"code","dea2c8fd":"code","78fcd349":"code","a8dcb2e3":"code","d42ff9e0":"code","cbfec40b":"code","812c535e":"code","56bd1b43":"code","619055ca":"code","9addc927":"code","41d19bb0":"code","cd52d9f4":"code","4eda6567":"code","87dd40db":"code","206ebee6":"code","886bf807":"code","d8ce2594":"code","75edd5ec":"code","62cf5c13":"code","903497ce":"code","c66f404b":"code","06ce0169":"code","c95875bc":"code","3fd7a47c":"code","d7441297":"code","2d369d6a":"code","febbf7bc":"code","6fab11f7":"code","d83b3683":"code","09041204":"code","2b21deff":"code","dba5507d":"code","2178e044":"code","c3796552":"code","2640d744":"code","108973f5":"code","48e93d1b":"code","27b7855c":"code","a0f461d8":"code","d9978ef6":"code","fff1351e":"code","56e73611":"code","67ff1ca4":"code","0b93fc74":"code","bca2ee93":"code","e97da693":"code","2082c985":"code","8a888aa8":"code","038249db":"code","5251d572":"code","fe12d886":"code","73a64c4b":"code","9fb36c21":"code","c53ca511":"code","031a5f35":"code","95a6ccaf":"code","018685cc":"code","0fd0dcf7":"code","e6022fb2":"code","79abbaf3":"code","634887a6":"code","fa65d6e6":"code","93f23ca5":"code","a3a57508":"code","c7f1ac6d":"code","33bdbe47":"code","93702e96":"code","7f0942ea":"code","d9f9eec3":"code","9e0a4f39":"code","07ed5ab3":"code","2551973a":"code","cf80e219":"markdown","6cb2bcaf":"markdown","a0f07230":"markdown","8f0fcda4":"markdown","838393cf":"markdown","94d1feca":"markdown","db2babe0":"markdown","3af95a87":"markdown","8e978ef6":"markdown","3c10e2eb":"markdown","0f6351c2":"markdown","fc98626d":"markdown","6f9338a0":"markdown","3077e5de":"markdown","aec8c08a":"markdown","dbfee24b":"markdown","a77b2ef6":"markdown","3bdb6b50":"markdown","8d4a013e":"markdown","cf975bfb":"markdown","bffaa25a":"markdown","acb96d16":"markdown","efe0ea22":"markdown","3e2ce365":"markdown","4319bfe6":"markdown","ef5caa56":"markdown","e36fd6f5":"markdown","7316d9f0":"markdown","f0609f5b":"markdown","76c1a72b":"markdown","60e966ad":"markdown","e61b1d37":"markdown","046dc38b":"markdown","2bd8d972":"markdown","d75c70f0":"markdown","634f9d39":"markdown","314fb6d1":"markdown","e7007668":"markdown","523c65df":"markdown","98c4d45b":"markdown","5bc2a059":"markdown","0bc5ac07":"markdown","8a42c985":"markdown","747dbfd1":"markdown","8fb3513b":"markdown","4dece6eb":"markdown","05a9fbf2":"markdown","b3ba85f3":"markdown","28f883b0":"markdown","b4bf9c8e":"markdown","62f2c480":"markdown","aa1ce0a9":"markdown","cb5a7c5b":"markdown","974d8acd":"markdown","29731bd5":"markdown","7fa275ce":"markdown","6bac9f7c":"markdown","b4339f1d":"markdown","dad26bde":"markdown","ee73e9e4":"markdown","ed47cb74":"markdown","bfed7f9c":"markdown","6685ebb3":"markdown","e8d29968":"markdown","c0129716":"markdown","6647fe21":"markdown","6707805d":"markdown","fc414d8d":"markdown","19762dae":"markdown","582e81f8":"markdown","586a584f":"markdown","bb9c8dad":"markdown","54db5a5b":"markdown","f7fec6b1":"markdown","5afbe1d8":"markdown","30294b3b":"markdown","47010f1e":"markdown","a89b10a5":"markdown","7569b6ec":"markdown","a0c74ff5":"markdown","0aeb310b":"markdown","29dff2d1":"markdown","90f90918":"markdown","4a5624ea":"markdown","b3c2a726":"markdown","7659a56c":"markdown","3bdf3057":"markdown","ad555776":"markdown","4faf65dd":"markdown","811602e8":"markdown","11d71b0f":"markdown","92102839":"markdown","ced11655":"markdown","4f2fd14e":"markdown","34f97957":"markdown","949751c0":"markdown","84aa45eb":"markdown","b9ad248c":"markdown","318ad68a":"markdown","1084cfe9":"markdown","2be1eb98":"markdown","0002dda7":"markdown"},"source":{"c2913533":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.metrics import mean_squared_error\n\n\nplt.rcParams['figure.figsize'] = (16,8)","2d8e1e83":"df = pd.read_csv(\"..\/input\/delitos.csv\", parse_dates=['fecha'])","bd4050bf":"df","0984139e":"df.info()","fb497251":"df.drop(columns=[\"lugar\", \"origen_dato\"], inplace=True)","a67063a1":"df","72d34660":"# Cantidad de valores \ndf.uso_arma.value_counts()","e3288bcd":"# Cantidad de valores\ndf.uso_moto.value_counts()","5220f84c":"# Cantidad de valores \ndf.cantidad_vehiculos.value_counts()","bf629d0d":"# Cantidad de valores \ndf.cantidad_victimas.value_counts()","68e41ece":"# Se elimina la feature\ndf.drop(columns=[\"cantidad_vehiculos\"], inplace=True)","1553bb1d":"# Contabilizamos los valores nulos\ndf.barrio.isnull().sum()","12ea13d6":"df.comuna.isnull().sum()","41a478e4":"df[(df['comuna'].isna()) & (df['barrio'].isna())]","ee1f8872":"# Eliminamos las filas que tienen registros nulos en la comuna, por ende en barrio, latitud y longitud\ndf.drop(df[df['comuna'].isna()].index)","c0d51d8a":"df.comuna.value_counts()","f4fe05fa":"sns.barplot(x=df.comuna.value_counts().index, y=df.comuna.value_counts())","eb0f08eb":"df.barrio.value_counts()","e72f366d":"#\u00a0Veamos un gr\u00e1fico del top 10 de barrios con mayor cantidad de crimenes:\nsns.barplot(x=df.barrio.value_counts().head(10).index, y=df.barrio.value_counts().head(10))","5f1ecad8":"sns.boxplot(df.barrio.value_counts())","3f108859":"# En porcentaje\ndf.tipo_delito.value_counts()","863addc4":"# Pie chart\nlabels = df.tipo_delito.value_counts().index\nsizes = df.tipo_delito.value_counts(normalize=True).values.round(6)*100\n \n#colors\ncolors = ['#ff9999','#66b3ff','#99ff99','#ffcc99']\nplt.rcParams['figure.figsize'] = (14,8)\n\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, colors = colors, labels=labels, autopct='%1.1f%%', startangle=30)\n\n#draw circle\ncentre_circle = plt.Circle((0,0),0.70,fc='white')\nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\n\n# Equal aspect ratio ensures that pie is drawn as a circle\nax1.axis('equal')  \nplt.tight_layout()\nplt.show()","619ee6cf":"pd.crosstab(index=df.barrio, columns=df.tipo_delito, margins=True)","50c41c87":"plt.rcParams['figure.figsize'] = (16,8)\nsns.countplot(y=df['comuna'], hue=df['fecha'].dt.year)","9db9d12c":"df_comuna_1 = df[df[\"comuna\"]==\"Comuna 1\"]\nplt.rcParams['figure.figsize'] = (16,8)\nsns.countplot(y=df_comuna_1['barrio'], hue=df_comuna_1['fecha'].dt.year).set_title(\"Cantidad anual de delitos en la Comuna 1\")","66e1bd04":"df_comuna_3 = df[df[\"comuna\"]==\"Comuna 3\"]\nplt.rcParams['figure.figsize'] = (16,8)\nsns.countplot(y=df_comuna_3['barrio'], hue=df_comuna_3['fecha'].dt.year).set_title(\"Cantidad anual de delitos en la Comuna 3\")","d0012e9e":"df_comuna_4 = df[df[\"comuna\"]==\"Comuna 4\"]\nplt.rcParams['figure.figsize'] = (16,8)\nsns.countplot(y=df_comuna_4['barrio'], hue=df_comuna_4['fecha'].dt.year).set_title(\"Cantidad anual de delitos en la Comuna 4\")","a8c268c6":"plt.rcParams['figure.figsize'] = (16,8)\nsns.countplot(x=df['tipo_delito'], hue=df['fecha'].dt.year).set_title(\"Distribucion absoluta de los delitos seg\u00fan el a\u00f1o\")","20efd899":"df_robos = df[df.tipo_delito == \"Robo (Con violencia)\"]\ndf_hurtos = df[(df.tipo_delito == \"Hurto (Sin violencia)\") | (df.tipo_delito == \"Hurto Automotor\")]\ndf_les = df[df.tipo_delito == \"Lesiones Seg Vial\"]\ndf_robo_auto = df[df.tipo_delito == \"Robo Automotor\"]             \ndf_homicidio = df[(df.tipo_delito == \"Homicidio Doloso\") | (df.tipo_delito == \"Homicidio Seg Vial\")]           ","8e5b306e":"# Seteamos las configuraciones generales del gr\u00e1fico\nfig = plt.figure(figsize=(20,6))\n\n# Agrupamos los valores y le agregamos la cantidad de delito (en este caso robos) y gr\u00e1ficamos la l\u00ednea\ndf_group_robos = df_robos.groupby(df_robos.fecha).agg({'tipo_delito': 'count'})\nsns.lineplot(x=df_group_robos.index, y=df_group_robos['tipo_delito'], label=\"Robo (Con violencia)\").set_title(\"Comparaci\u00f3n de las cantidades de tipo de delitos a trav\u00e9s del tiempo\")\n\n# Agrupamos los valores y le agregamos la cantidad de delito (en este caso hurtos) y gr\u00e1ficamos la l\u00ednea\ndf_group_hurtos = df_hurtos.groupby(df_hurtos.fecha).agg({'tipo_delito': 'count'})\nsns.lineplot(x=df_group_hurtos.index, y=df_group_hurtos['tipo_delito'], label=\"Hurtos\")\n\n# Agrupamos los valores y le agregamos la cantidad de delito (en este caso lesiones) y gr\u00e1ficamos la l\u00ednea\ndf__group_lesiones = df_les.groupby(df_les.fecha).agg({'tipo_delito': 'count'})\nsns.lineplot(x=df__group_lesiones.index, y=df__group_lesiones['tipo_delito'], label=\"Lesiones Seg Vial\")\n\n# Agrupamos los valores y le agregamos la cantidad de delito (en este caso robo automotor) y gr\u00e1ficamos la l\u00ednea\ndf_group_roboauto = df_robo_auto.groupby(df_robo_auto.fecha).agg({'tipo_delito': 'count'})\nsns.lineplot(x=df_group_roboauto.index, y=df_group_roboauto['tipo_delito'], label=\"Robo Automotor\")\n\n# Agrupamos los valores y le agregamos la cantidad de delito (en este caso homicidios) y gr\u00e1ficamos la l\u00ednea\ndf_group_homicidios = df_homicidio.groupby(df_homicidio.fecha).agg({'tipo_delito': 'count'})\nsns.lineplot(x=df_group_homicidios.index, y=df_group_homicidios['tipo_delito'], label=\"Homicidios\")\n\nplt.show()","0863b94d":"df_2_filtered = df_group_robos.copy()\ndf_2_filtered\n\ndf_2_filtered[\"mes\"] = df_2_filtered.index.get_level_values(0).strftime('%m')\ndf_2_filtered[\"anio\"] = df_2_filtered.index.get_level_values(0).strftime('%Y')\ndf_2_filtered_my = df_2_filtered.groupby([\"mes\",\"anio\"]).agg({\"tipo_delito\":\"sum\"}).rename(columns={\"tipo_delito\":\"robos\"}).reset_index()","d81174c1":"sns.relplot(x=\"mes\", y=\"robos\", col=\"anio\", data=df_2_filtered_my, kind=\"line\")","d6479c82":"df_3_filtered = df_group_hurtos.copy()\ndf_3_filtered\n\ndf_3_filtered[\"mes\"] = df_3_filtered.index.get_level_values(0).strftime('%m')\ndf_3_filtered[\"anio\"] = df_3_filtered.index.get_level_values(0).strftime('%Y')\ndf_3_filtered_my = df_3_filtered.groupby([\"mes\",\"anio\"]).agg({\"tipo_delito\":\"sum\"}).rename(columns={\"tipo_delito\":\"hurtos\"}).reset_index()","7e9a4d88":"sns.relplot(x=\"mes\", y=\"hurtos\", col=\"anio\", data=df_3_filtered_my, kind=\"line\")","93893db2":"sns.pairplot(df)","7e16a51e":"#retornamos la correlacion del data frame\ncorr = df.corr() \n\n# Con esa variable removemos las variables superiores ya que estan repetidas\nbool_upper_matrix = np.tril(np.ones(corr.shape)).astype(np.bool)\ncorr = corr.where(bool_upper_matrix)\n\n#Dibujamos el heatmap\nsns.heatmap(corr,\n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values,\n            cmap='RdYlGn');\n\nfig=plt.gcf()\nfig.set_size_inches(15,10)\nplt.show()","5603d5ea":"# Hacemos una copia del dataframe antes de impactar el cambio directamente\ndf_engineering = df.copy()","a146a9e0":"# MUY IMPORTANTE, completar los valores nulos, ya que sin esto, en este caso, no funciona la funcion \"lambda\"\ndf_engineering.hora.fillna('00:00:00', inplace=True)\n\n# Armamos los bins (rangos)\nbins = [0, 6, 12, 20, 23]\n# Esta variable nos va a servir para poder identificar cada rango\nnames = ['Madrugada', 'Ma\u00f1ana', 'Tarde', 'Noche']\n\n# Asignamos a esta variable la serie con las nuevas columnas en base a los bins y label\n# La funcion lambda se encarga de cortar la hora ya que caso contrario no se puede binarizar al ser string\ncategory = pd.cut(df_engineering.hora.map(lambda x: int(x.split(':')[0])), bins, labels = names)","f1d872e6":"# Concatenamos al data frame a partir de una matriz dummie la variable category\ndf_engineering = pd.concat([df_engineering, pd.get_dummies(category)], axis=1)\ndf_engineering","6bfc2f13":"parte_del_dia = df_engineering.loc[:,['Madrugada', 'Ma\u00f1ana', 'Tarde', 'Noche']].sum().sort_values(ascending=False)","24fdb503":"sns.barplot(x=parte_del_dia.index, y=parte_del_dia.values)","f8bd9f4a":"parte_del_dia_porc = df_engineering.loc[:,['Madrugada', 'Ma\u00f1ana', 'Tarde', 'Noche']].mean()*100","dbe280bf":"# Pie chart\nlabels = parte_del_dia_porc.index\nsizes = parte_del_dia_porc.values\n \n#colors\ncolors = ['#ff9999','#66b3ff','#99ff99','#ffcc99']\nplt.rcParams['figure.figsize'] = (12,6)\n\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, colors = colors, labels=labels, autopct='%1.1f%%', startangle=30)\n\n#draw circle\ncentre_circle = plt.Circle((0,0),0.70,fc='white')\nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\n\n# Equal aspect ratio ensures that pie is drawn as a circle\nax1.axis('equal')  \nplt.tight_layout()\nplt.show()","144422b6":"# Importamos Scickit Learn\nfrom sklearn.preprocessing import OneHotEncoder\nonehot_encoder = OneHotEncoder(sparse = False)\n\n# Definimos la variable a realizar el onehotencoder\ndelito = df_engineering.tipo_delito.values.reshape(-1,1)\n\nonehot_encoder.fit(delito)\n\ndelito_encoded = onehot_encoder.transform(delito)","ead4f5e5":"# Mostramos las categorias que quedaron\nonehot_encoder.categories_","c256a981":"#\u00a0Lo agregamos al data set\n#\u00a0Primero armamos un data frame peque\u00f1o, con lo que queremos unir\ndelito_encoded_df = pd.DataFrame(delito_encoded, dtype=int,columns=(['Homicidio Doloso','Homicidio Seg Vial', 'Hurto (Sin violencia)','Hurto Automotor', 'Lesiones Seg Vial', 'Robo (Con violencia)','Robo Automotor']))\n\n#Le ponemos el mismo indice que el data frame donde queremos agregarlo\ndelito_encoded_df = delito_encoded_df.set_index(df_engineering.index)\ndf_engineering = pd.concat([df_engineering, delito_encoded_df], axis=1)\ndf_engineering","dea2c8fd":"#retornamos la correlacion del data frame\ncorr = df_engineering.corr() \n\n# Con esa variable removemos las variables superiores ya que estan repetidas\nbool_upper_matrix = np.tril(np.ones(corr.shape)).astype(np.bool)\ncorr = corr.where(bool_upper_matrix)\n\n#Dibujamos el heatmap\nsns.heatmap(corr,\n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values,\n            cmap='RdYlGn');\n\nfig=plt.gcf()\nfig.set_size_inches(15,10)\nplt.show()","78fcd349":"df_ml = df.copy()","a8dcb2e3":"df_ml.drop(columns=[\"id\",\"comuna\",\"fecha\",\"uso_arma\",\"uso_moto\",\"cantidad_victimas\"], inplace=True)","d42ff9e0":"df_ml.drop(columns=[\"latitud\",\"longitud\"], inplace=True)","cbfec40b":"df_ml.info()","812c535e":"df_ml.isnull().sum()","56bd1b43":"df_ml.dropna(inplace=True)","619055ca":"df_ml.isnull().sum()","9addc927":"hora = df_ml.hora.str.split(\":\",n=1,expand=True)","41d19bb0":"df_ml[\"hora\"] = hora[0].astype(int)","cd52d9f4":"from sklearn.preprocessing import LabelEncoder\n\ndf_encoder = df_ml.barrio.values\n\nle = LabelEncoder()\nle.fit(df_encoder)","4eda6567":"from sklearn.preprocessing import OneHotEncoder\n\nonehot_encoder = OneHotEncoder(sparse=False)\nbarrio_encoded = df_ml.barrio.values.reshape(len(df_ml.barrio.values), 1)\n#print(integer_encoded)\n\nonehot_encoded_barrio = onehot_encoder.fit_transform(barrio_encoded)","87dd40db":"#\u00a0probar con df_ml.barrio.unique()\ndf_barrio = pd.DataFrame(onehot_encoded_barrio, dtype=int, columns=le.classes_)","206ebee6":"df_barrio = df_barrio.set_index(df_ml.index)\n\ndf_ml = pd.concat([df_ml, df_barrio], axis=1)\ndf_ml","886bf807":"df_ml[\"tipo_delito_encode\"] = df_ml.tipo_delito.map({'Homicidio Doloso': '1','Robo (Con violencia)': '2','Hurto Automotor': '3','Hurto (Sin violencia)': '4','Robo Automotor': '5'\n           ,'Homicidio Seg Vial': '6','Lesiones Seg Vial': '7'})","d8ce2594":"df_ml[\"tipo_delito_encode\"] = df_ml[\"tipo_delito_encode\"].astype(int)","75edd5ec":"df_ml.info()","62cf5c13":"#retornamos la correlacion del data frame\ncorr = df_ml.corr() \n\n# Con esa variable removemos las variables superiores ya que estan repetidas\nbool_upper_matrix = np.tril(np.ones(corr.shape)).astype(np.bool)\ncorr = corr.where(bool_upper_matrix)\n\n#Dibujamos el heatmap\nsns.heatmap(corr,\n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values,\n            cmap='RdYlGn');\n\nfig=plt.gcf()\nfig.set_size_inches(15,10)\nplt.show()","903497ce":"X = df_ml.drop(columns=[\"barrio\", \"tipo_delito\", \"tipo_delito_encode\"])\ny= df_ml[\"tipo_delito_encode\"].values","c66f404b":"X.shape","06ce0169":"y.shape","c95875bc":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","3fd7a47c":"from sklearn.ensemble import RandomForestClassifier\n\ntrain_score = []\ntest_score = []\nprofundidad = np.arange(1,40,5)\n\nfor max_depth in profundidad:\n    rfc = RandomForestClassifier(max_depth=max_depth, n_jobs=-1, random_state=42)\n    rfc.fit(X_train, y_train)\n    \n    y_pred_train = rfc.predict(X_train)\n    y_pred_test = rfc.predict(X_test)\n    \n    train_score.append(rfc.score(X_train, y_train))\n    test_score.append(rfc.score(X_test, y_test))\n    ","d7441297":"plt.plot(profundidad, train_score, label=\"Training score\")\nplt.plot(profundidad, test_score, label=\"Testing score\")\nplt.legend()\nplt.ylabel('Score')\nplt.xlabel('Profundiad')\nplt.show()","2d369d6a":"df_ml_2 = df.copy()","febbf7bc":"df_ml_2.drop(columns=[\"id\",\"comuna\",\"hora\",\"uso_arma\",\"uso_moto\",\"cantidad_victimas\"], inplace=True)","6fab11f7":"df_ml_2.isna().sum()","d83b3683":"df_ml_2.dropna(inplace=True)","09041204":"df_ml_2.isna().sum()","2b21deff":"df_ml_2[\"dia_semana\"] = df_ml_2[\"fecha\"].dt.dayofweek.values","dba5507d":"df_ml_2","2178e044":"from sklearn.preprocessing import LabelEncoder\n\ndf_encoder = df_ml.barrio.values\n\nle = LabelEncoder()\nle.fit(df_encoder)","c3796552":"from sklearn.preprocessing import OneHotEncoder\n\nonehot_encoder = OneHotEncoder(sparse=False)\nbarrio_encoded = df_ml_2.barrio.values.reshape(len(df_ml_2.barrio.values), 1)\n#print(integer_encoded)\n\nonehot_encoded_barrio = onehot_encoder.fit_transform(barrio_encoded)","2640d744":"#\u00a0probar con df_ml.barrio.unique()\ndf_barrio = pd.DataFrame(onehot_encoded_barrio, dtype=int, columns=le.classes_)","108973f5":"df_barrio = df_barrio.set_index(df_ml_2.index)\n\ndf_ml_2 = pd.concat([df_ml_2, df_barrio], axis=1)\n","48e93d1b":"df_ml_2[\"tipo_delito_encode\"] = df_ml_2.tipo_delito.map({'Homicidio Doloso': '1','Robo (Con violencia)': '2','Hurto Automotor': '3','Hurto (Sin violencia)': '4','Robo Automotor': '5'\n           ,'Homicidio Seg Vial': '6','Lesiones Seg Vial': '7'})","27b7855c":"df_ml_2[\"tipo_delito_encode\"] = df_ml_2[\"tipo_delito_encode\"].astype(int)","a0f461d8":"#retornamos la correlacion del data frame\ncorr = df_ml_2.corr() \n\n# Con esa variable removemos las variables superiores ya que estan repetidas\nbool_upper_matrix = np.tril(np.ones(corr.shape)).astype(np.bool)\ncorr = corr.where(bool_upper_matrix)\n\n#Dibujamos el heatmap\nsns.heatmap(corr,\n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values,\n            cmap='RdYlGn');\n\nfig=plt.gcf()\nfig.set_size_inches(15,10)\nplt.show()","d9978ef6":"X = df_ml_2.drop(columns=[\"barrio\", \"fecha\", \"tipo_delito\", \"tipo_delito_encode\"])\ny = df_ml_2.tipo_delito_encode.values","fff1351e":"X.shape","56e73611":"y.shape","67ff1ca4":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","0b93fc74":"train_score = []\ntest_score = []\nprofundidad = np.arange(1,40,5)\n\nfor max_depth in profundidad:\n    rfc = RandomForestClassifier(max_depth=max_depth, criterion='gini', n_jobs=-1, random_state=42)\n    rfc.fit(X_train, y_train)\n    \n    y_pred_train = rfc.predict(X_train)\n    y_pred_test = rfc.predict(X_test)\n    \n    train_score.append(rfc.score(X_train, y_train))\n    test_score.append(rfc.score(X_test, y_test))    ","bca2ee93":"plt.figure(figsize=(12,10))\n\nfeat_imp_df = pd.DataFrame(sorted(zip(map(lambda x: round(x, 4), rfc.feature_importances_), X_train.columns), reverse=True))\n\nmapping = {feat_imp_df.columns[0]:'Importancia', feat_imp_df.columns[1]: 'Variable'}\nfeat_imp_df = feat_imp_df.rename(columns=mapping)\nsns.barplot(x=feat_imp_df['Importancia'],y=feat_imp_df['Variable'], palette=\"Greens_d\")\n\n#Otra forma\n#n_features = X.shape[1]\n#plt.barh(range(n_features),rfc.feature_importances_)\n#plt.yticks(np.arange(n_features),train_data.columns[1:])","e97da693":"from sklearn.metrics import balanced_accuracy_score\n\nbalanced_accuracy_score(y_train, y_pred_train)","2082c985":"balanced_accuracy_score(y_test, y_pred_test)","8a888aa8":"plt.plot(profundidad, train_score, label=\"Training score\")\nplt.plot(profundidad, test_score, label=\"Testing score\")\nplt.legend()\nplt.ylabel('Score')\nplt.xlabel('Profundiad')\nplt.show()","038249db":"np.argmax(test_score)","5251d572":"test_score","fe12d886":"rdm = RandomForestClassifier(max_depth=np.argmax(test_score)*5+1, n_jobs=-1, n_estimators=42)\nrdm.fit(X_train, y_train)\n\ny_pred_train = rdm.predict(X_train)\ny_pred_test = rdm.predict(X_test)","73a64c4b":"from sklearn.metrics import classification_report, confusion_matrix\n\ncm = confusion_matrix(y_test, y_pred_test)\ncm","9fb36c21":"pd.crosstab(y_test, y_pred_test, rownames=['True'], colnames=['Predicted'], margins=True)","c53ca511":"labels = ['Homicidio Doloso','Robo (Con violencia)','Hurto Automotor','Hurto (Sin violencia)','Robo Automotor','Homicidio Seg Vial','Lesiones Seg Vial']\nsns.heatmap(cm, annot=True, xticklabels= labels, yticklabels= labels, fmt='.2f')\nplt.show()","031a5f35":"print (classification_report(y_test, y_pred_test))","95a6ccaf":"from sklearn.model_selection import cross_validate","018685cc":"tree_train_scores_mean = []\ntree_train_scores_std = []\ntree_test_scores_mean = []\ntree_test_scores_std = []\n\nprofundidades = np.arange(1,40,5)\n\nfor profundidad in profundidades:\n    rdm = RandomForestClassifier(max_depth=profundidad, criterion='gini', random_state=42, n_jobs=-1)\n    cv_result = cross_validate(rdm, X_train, y_train, cv=10, return_train_score=True)\n    \n    tree_train_scores_mean.append(cv_result['train_score'].mean())\n    tree_train_scores_std.append(cv_result['train_score'].std())\n    \n    tree_test_scores_mean.append(cv_result['test_score'].mean())\n    tree_test_scores_std.append(cv_result['test_score'].std())\n    \ntree_train_scores_mean = np.array(tree_train_scores_mean)\ntree_train_scores_std = np.array(tree_train_scores_std)\ntree_test_scores_mean = np.array(tree_test_scores_mean)\ntree_test_scores_std = np.array(tree_test_scores_std)","0fd0dcf7":"plt.fill_between(profundidades, tree_train_scores_mean - tree_train_scores_std,\n                 tree_train_scores_mean + tree_train_scores_std, alpha=0.1,\n                 color=\"r\")\n\nplt.fill_between(profundidades, tree_test_scores_mean - tree_test_scores_std,\n                 tree_test_scores_mean + tree_test_scores_std, alpha=0.1, color=\"g\")\n\nplt.plot(profundidades, tree_train_scores_mean, 'o-', color=\"r\",\n         label=\"Training score\")\nplt.plot(profundidades, tree_test_scores_mean, 'o-', color=\"g\",\n         label=\"Test score\")\n\n\nplt.legend()\nplt.ylabel('Accuracy')\nplt.xlabel('Profundidad Arbol de Decision')\nplt.show()","e6022fb2":"cv_result","79abbaf3":"#Hacemos una copia del data frame utilizado en la clasificaci\u00f3n anterior ya que nos sirven casi todas sus features.\ndf_ml_3 = df_ml_2.copy()","634887a6":"df_ml_3.tail(3)","fa65d6e6":"dia_semana = pd.get_dummies(df_ml_3[\"dia_semana\"], prefix=\"dia_semana\")","93f23ca5":"df_ml_3 = pd.concat([df_ml_3, dia_semana], axis=1)","a3a57508":"#retornamos la correlacion del data frame\ncorr = df_ml_3.corr() \n\n# Con esa variable removemos las variables superiores ya que estan repetidas\nbool_upper_matrix = np.tril(np.ones(corr.shape)).astype(np.bool)\ncorr = corr.where(bool_upper_matrix)\n\n#Dibujamos el heatmap\nsns.heatmap(corr,\n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values,\n            cmap='RdYlGn');\n\nfig=plt.gcf()\nfig.set_size_inches(15,10)\nplt.show()","c7f1ac6d":"X = df_ml_3.drop(columns=[\"barrio\", \"fecha\", \"tipo_delito\", \"tipo_delito_encode\", \"dia_semana\"])\ny = df_ml_3.tipo_delito_encode.values","33bdbe47":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.20)","93702e96":"train_score = []\ntest_score = []\nprofundidad = np.arange(1,40,5)\n\nfor max_depth in profundidad:\n    rfc = RandomForestClassifier(max_depth=max_depth, criterion='gini', n_jobs=-1, random_state=42)\n    rfc.fit(X_train, y_train)\n    \n    train_score.append(rfc.score(X_train, y_train))\n    test_score.append(rfc.score(X_test, y_test))    ","7f0942ea":"plt.figure(figsize=(12,10))\n\nfeat_imp_df = pd.DataFrame(sorted(zip(map(lambda x: round(x, 4), rfc.feature_importances_), X_train.columns), reverse=True))\n\nmapping = {feat_imp_df.columns[0]:'Importancia', feat_imp_df.columns[1]: 'Variable'}\nfeat_imp_df = feat_imp_df.rename(columns=mapping)\nsns.barplot(x=feat_imp_df['Importancia'],y=feat_imp_df['Variable'], palette=\"Greens_d\")\n\n#Otra forma\n#n_features = X.shape[1]\n#plt.barh(range(n_features),rfc.feature_importances_)\n#plt.yticks(np.arange(n_features),train_data.columns[1:])","d9f9eec3":"from sklearn.metrics import balanced_accuracy_score\n\nbalanced_accuracy_score(y_train, y_pred_train)","9e0a4f39":"balanced_accuracy_score(y_test, y_pred_test)","07ed5ab3":"plt.plot(profundidad, train_score, label=\"Training score\")\nplt.plot(profundidad, test_score, label=\"Testing score\")\nplt.legend()\nplt.ylabel('Score')\nplt.xlabel('Profundiad')\nplt.show()","2551973a":"test_score","cf80e219":"Asignamos las variables de train y test, con un tama\u00f1o del 20% para test.","6cb2bcaf":"# Clasificaci\u00f3n en base a\u00a0Dia de la semana, barrio, latitud, longitud (pero con distinta estrateg\u00eda para los d\u00edas)\nVolvemos a cambiar nuestras features, en este caso se decide realizar un feature engineering distinto sobre los dias de la semana, en vez de darle un valor de 0 a 6, lo hacemos mediante variables dummies a ver si tenemos mejor resultado.","a0f07230":"    Se observa que Barracas es el barrio m\u00e1s inseguro con un pico de registros en el a\u00f1o 2017. Por otro lado sorprende que en el barrio de Constituci\u00f3n no hay ningun registro de delito \u00bfhabr\u00e1 algun error en los datos o es un barrio muy seguro?","8f0fcda4":"## Entrenamos el modelo\nSeleccionamos nuestra variable independiente y el target.","838393cf":"## 4. Graficando y cruzando variables para entender mejor.\nComenzemos a cruzar la informaci\u00f3n que tenemos para ver que podemos ir descubriendo.","94d1feca":"    Es interesante ver los tipos de delitos que tenemos por un lado los Robos, hurtos, lesiones de seguridad vial y por otro lado los Homicidios, por lo cual all\u00ed podr\u00edamos decir que hubo alguna\/as personas muertas, pero no podemos saber la cantidad.\n\n    Adem\u00e1s, claramente el dataset no toma como sin\u00f3nimo el Robo y el hurto, esto se debe a que para que sea calificado como un robo es por que hubo alg\u00fan tipo de violencia, sin embargo en el hurto no existe tal cosa. \u00bfPodr\u00edamos obtener una nueva feature que se llame \"Violencia\" (1= crimen con violencia, 0=crimen sin violencia)?\n    \n    De una cosa podemos estar seguros en base a este dataset y es que la mayor\u00eda de los crimenes son robos con violencia, lo cual es un tema preocupante y adem\u00e1s, supera al hurto en un 25%.","db2babe0":"#### Hora","3af95a87":"    Podemos observar lo siguiente:\n    * Durante los 4 a\u00f1os siempre hubo m\u00e1s robos (con violencia), teniendo un pico en el mes de Septiembre del a\u00f1o 2018.\n    * Las lesiones seg vial, solo sucedieron (o fueron registradas) desde el a\u00f1o 2017 a enero del 2018.","8e978ef6":"###\u00a0Matriz de confusi\u00f3n\nPresentamos la matriz de confusi\u00f3n de tres formas distintas.","3c10e2eb":"    Se puede observar que el barrio donde m\u00e1s delitos se registraron es San Nicolas y en el que menos Puerto Madero. \u00bfEra de esperarse?","0f6351c2":"    Es interensate ver como surgio una correlaci\u00f3n entre la cantidad de victimas y los homicidios, esto anteriormente no lo teniamos, pero gracias a la transformaci\u00f3n de datos pudimos lograrlos, ahora bien, \u00bfsirve para entrenar a nuetra ML?","fc98626d":"###\u00a0Cantidad de tipo de delito durante el a\u00f1o\nEn esta secci\u00f3n solo analizaremos los Robos y los hurtos en general durante los a\u00f1os por separado, as\u00ed podremos comparar por cada tipo de delito como se fue comportando en los distintos a\u00f1os.","6f9338a0":"**Tipo de delitos**","3077e5de":"##\u00a0Predicci\u00f3n y evaluaci\u00f3n","aec8c08a":"No se observa una mejora en el Score de TEST por lo que en este caso Cross Validate no nos ayudo a mejorar el modelo.","dbfee24b":"**COMUNA 1. Retiro, San Nicol\u00e1s, Puerto Madero, San Telmo, Montserrat y Constituci\u00f3n**","a77b2ef6":"    Comenzamos filtrando el data set por cada uno de los delitos, agrupando los del tipo hurto y los de tipo homicidio.","3bdb6b50":"## Limpieza del data set para la clasificaci\u00f3n\nSe eliminan las columnas que no nos sirven y tambi\u00e9n aquellas filas nulas.","8d4a013e":"**COMUNA 3. Balvanera y San Crist\u00f3bal**","cf975bfb":"### 2. Analizando y limpiando el data set.\n\nSe analizar\u00e1 el data set en base al punto anterior y se procedera a eliminar las filas\/columnas que no tienen relevancia para este caso.","bffaa25a":"Tal como se esperaba por tener el data set desbalanceado, lo que mejor pudo clasificar el modelo fue:\n* \"Robo (Con Violencia)\" - 36.388 de 39.671\n* Hurto (Sin violencia) - 4.929 de 22334\n\nEn el resto tuvo un muy mal desempe\u00f1o.","acb96d16":"###\u00a0Definimos las variables","efe0ea22":"    Como se observo en el apartado anterior, las features \"lugar\" y \"origen_dato\" no tienen registros por lo tanto se eliminan.","3e2ce365":"**Ademas en este punto tambi\u00e9n podr\u00edamos ver si existen valores Outliers con respecto a la cantidad de delitos por barrio.**","4319bfe6":"#### Tipo de variables\nVariables categoricas:\n* uso_arma.\n* uso_moto.\n* tipo_delito.\n    \nVariables numericas discretas:\n* id.\n* cantidad_vehiculos.\n* cantidad_victimas.\n* fecha\n* hora\n    \nVariables numericas continuas:\n* latitud.\n* longitud.\n\nLas features \"lugar\" y \"origen_dato\" no se van a analizar ya no tienen registros y ser\u00e1n eliminadas.","ef5caa56":"    Se intentar\u00e1 crear nuevas columnas \"Madrugada\", \"Ma\u00f1ana\", \"Tarde\", \"Noche\" en base a la hora registrada y de esta forma poder obtener informaci\u00f3n m\u00e1s clara respecto al horario del hecho.","e36fd6f5":"####\u00a0Robos","7316d9f0":"    Se observa lo siguiente:\n    * En el a\u00f1o 2016, se puede observar que existieron mayor cantidad de hurtos que el resto de los a\u00f1os, teniendo un pico a fin de a\u00f1o y en tendencia positiva desde el comienzo..\n    * En el a\u00f1o 2017, se puede observar que existieron menos cantidad de hurtos que el 2016, y el pico tambi\u00e9n estuvo al final del a\u00f1o. Se nota tambi\u00e9n una fuerte caida en el mes de Septiembre.\n    * En el a\u00f1o 2018, se puede observar que existieron muy parecida la cantidad de robos que el 2017, comenzo el a\u00f1o con m\u00e1s robos que el resto de los a\u00f1os, pero con una ca\u00edda en el mes de febrero como en el a\u00f1o 2017.","f0609f5b":"## Aplicando Cross validate\nVeamos si aplicando Cross Validate con K 10 cambia nuestro score. (\u00bfSe podr\u00eda aplicar alg\u00fan cv en particular en base al problema?)","76c1a72b":"### Comenzamos a entrenar el modelo","60e966ad":"####\u00a0Tipo de delito","e61b1d37":"# Clasificaci\u00f3n en base a\u00a0Dia de la semana, barrio, latitud, longitud\nCambiamos las variables para ver si podemos obtener mejores resultados.\n\nSe parte sabiendo que el data set esta desbalanceado respecto al tipo de delitos.\n\n* Robo (Con violencia)     200374\n* Hurto (Sin violencia)    112301\n* Hurto Automotor           18010\n* Lesiones Seg Vial          9833\n* Robo Automotor             9793\n* Homicidio Doloso            405\n* Homicidio Seg Vial          264","046dc38b":"## Importaci\u00f3n de librearias a utilizar","2bd8d972":"**Ahora que ya tenemos los valores discretizados veamos \u00bfEn que parte del d\u00eda ocurren la mayor parte de los delitos?**","d75c70f0":"##  An\u00e1lisis exploratorio de datos (EDA)","634f9d39":"**\u00bfA que profundidad se obtuvo el score m\u00e1s alto con los datos de TEST?**","314fb6d1":"###\u00a0Comparaci\u00f3n de las cantidades de \"tipo de delitos\" a trav\u00e9s del tiempo\nVeamos esta comparaci\u00f3n, que nos servira para analizar:\n* Si tenemos registros de todos los tipos de delitos en todos los a\u00f1os.\n* La variaci\u00f3n por delito a trav\u00e9s de los a\u00f1os.\n* Comparar las cantidades de los tipos de delitos.\n* \u00bfSe les ocurre algo m\u00e1s?","e7007668":"**Lo veamos a partir de porcentajes**","523c65df":"####\u00a0Barrio","98c4d45b":"####\u00a0Barrios\nVeamos la cantidad de valores que tiene cada barrio. Si recordamos, arriba, vimos las comunas por lo que se tendr\u00eda que correlacionar la Comuna que m\u00e1s crimenes tiene con el barrio que m\u00e1s crimenes tiene \u00bfser\u00e1 as\u00ed?","5bc2a059":"###\u00a05 Correlaciones\nVeamos si podemos encontrar alguna correlaci\u00f3n entre las features que tenemos.","0bc5ac07":"**Vemos que el modelo no mejora y se comporta de forma similar al anterior apartado. Por lo tanto, por el momento, se decide dejar hasta aqu\u00ed la clasificaci\u00f3n con Random Forest.**\n\n**Quedar\u00eda pendiente probar con otro modelo y\/o intentar balancear el data set con alguna t\u00e9cnica existente y ver los resultados.**","8a42c985":"    Pasemos a las \u00faltimas dos columnas que tambi\u00e9n llaman la atenci\u00f3n, veamos si vale la pena mantener esas features:","747dbfd1":"## Limpieza del data set para la clasificaci\u00f3n","8fb3513b":"# Clasificaci\u00f3n de tipo de delito en base a la hora y el barrio\nSe parte sabiendo que el data set esta desbalanceado respecto al tipo de delitos.\n\n* Robo (Con violencia)     200374\n* Hurto (Sin violencia)    112301\n* Hurto Automotor           18010\n* Lesiones Seg Vial          9833\n* Robo Automotor             9793\n* Homicidio Doloso            405\n* Homicidio Seg Vial          264","4dece6eb":"    \u00bfQu\u00e9 les parece? Tenemos m\u00e1s de 450.000 registros esto es una muy buena noticia para comenzar a trabajar.","05a9fbf2":"### 1. Analizando los tipos de variables (features)","b3ba85f3":"###\u00a0Tipos de crimenes por barrios\nVeamos mediante una tabla cruzada, la cantidad de tipos de delitos por barrio.","28f883b0":"Se puede obeservar que el modelo tanto con los datos de TESTING como de TRAINING llegan solamente a tener casi un Score del 59% lo cual es bastante bajo. Lo que se podr\u00eda rescatar es que con ambos set de datos se comparta de forma similar. ","b4bf9c8e":"    Claramente esto nos hace pensar que no tenemos una distribuci\u00f3n uniforme de los delitos respecto al barrio, y que existe una gran diferencia entre el barrio que m\u00e1s delitos tiene contra el que menos tiene.\n    Creo que en el contexto del an\u00e1lisis no es necesario quitar estos valores.","62f2c480":"## Pasamos todo a numeros","aa1ce0a9":"**Terminado el an\u00e1lisis hasta ac\u00e1 de las variables categoricas pasamos a las variables n\u00famericas.**","cb5a7c5b":"**Nuevamente los \"mejores valores\" se observan en:**\n\n2 -(Robo (Con violencia)) - El modelo identifica correctamente el 92% (Recall) de los Robos con violencia y acierta el 60% de las veces. Si miramos el F-Score para hacerlos comparables tenemos un 72%.\n\n**Dicho de otra forma:**\n\n\u00bfQu\u00e9 porcentaje de casos de Robo con violencia fueron capturados? => 92%. (TP\/[TP + FN])\n\n\u00bfQu\u00e9 porcentaje de predicciones de Robo con violencia fueron correctas? => 60% (TP\/[TP+FP])\n\n\nAdem\u00e1s se podr\u00eda considerar:\n* 4 (Hurto (Sin violencia)) - El modelo identifica correctamente el 22% (Recall) de los Hurtos sin violencia y acierta el 57% de las veces. Si miramos el F-Score para hacerlos comparables tenemos tan solo un 32%.","974d8acd":"    Corroboramos que los registros que no tienen comuna, tampoco tienen barrio, ni latitud, ni longitud, lo que nos habre el intorrogante de \u00bfqu\u00e9 hacemos con esos registros? \u00bfnos sirven para nuestro an\u00e1lisis? \u00bftiene sentido mantenerlos?\n\n    Debido a que no hay forma de poder saber donde ocurrieron esos hechos se decide descartar esos registros.","29731bd5":"### Correlaciones","7fa275ce":"### Comparaci\u00f3n de la cantidad anual de delitos en cada barrio seg\u00fan las Comunas con m\u00e1s delitos seg\u00fan a\u00f1o","6bac9f7c":"    En ambos casos se tiene la misma cantidad de valores nulos \u00bfser\u00e1 que corresponden a los mismos casos entre s\u00ed?, veamos:","b4339f1d":"**D\u00edas de la semana**","dad26bde":"### Distribuci\u00f3n de delitos por comuna seg\u00fan a\u00f1o\nLa idea del gr\u00e1fico siguiente es ver la comparaci\u00f3n por Comuna de la cantidad de delitos seg\u00fan el a\u00f1o. Esto nos ayuda a ver mejor que a\u00f1os son en los que m\u00e1s cantidad de delitos se realizaron como as\u00ed tambi\u00e9n en cada Comuna.","ee73e9e4":"### Precision, Recall, F1-Score","ed47cb74":"### Gr\u00e1fico con el comportamiento del modelo relacionado con el Score","bfed7f9c":"### Gr\u00e1fico con el comportamiento del modelo relacionado con el Score","6685ebb3":"###\u00a0Random Forest\nA partir de un ciclo for, vamos iterando en un arange que va de 5 en 5 desde 1 a 40. Esto nos sirve para acumular los scores y luego realizar un gr\u00e1fico de performance.","e8d29968":"    Se observa que en ambos casos, predomina un solo valor, por lo que nos podemos preguntar si el data set tiene alg\u00fan error en la entrada de datos o si esta orientado a crimenes donde no se haya utilizado ni arma ni moto. Por el momento se mantendr\u00e1n ambas columnas, en caso que en un futuro nos sirvan para algo.","c0129716":"    Sorprendentemente la mayor cantidad de delitos ocurre durante la tarde y la ma\u00f1ana, en contra parte quiz\u00e1s a lo que se piensa que son en la noche o en la madrugada.","6647fe21":"##\u00a0Paso todo a n\u00fameros","6707805d":"### Feature importances","fc414d8d":"**Bien ahora que tenemos un data set \"m\u00e1s limpio\", comencemos a realizar algunos calculos y gr\u00e1ficos.**","19762dae":"**Luego de estas transformaciones, veamos las correlaciones, \u00bfhay alguna correlaci\u00f3n ahora?**","582e81f8":"    Si lo graficamos:","586a584f":"   **Si bien en el punto 1 pudimos ver la cantidad de valores nulos que hay en cada feature lo analizaremos con mayor detalle las features comuna y barrio que eran las que tenian valores nulos:**","bb9c8dad":"###\u00a0Transformamos la fecha en variables dummies","54db5a5b":"    Otras columnas que llaman la atenci\u00f3n y merece ser analizado su contenido es uso_arma y uso_moto, veamos si vale la pena mantener esas features","f7fec6b1":"    Se observa que en el primer caso no hay vehiculos involucrados por lo que nos puede hacer pensar que hay un error al ingreso de datos o estos crimines no apuntaban a que esten involucrados. Se procede a la eliminaci\u00f3n de esta feature.\n    \n    En el segundo caso, la mayor\u00eda no tiene victimas fatales, pero en algunos casos si se registra, por lo que se decide dejar esta feature.","5afbe1d8":"### Discretizaci\u00f3n y Binning de la hora","30294b3b":"### Variables n\u00famericas\nEn este caso estas variables se analizaran en conjunto con las categoricas en el siguiente punto.","47010f1e":"        Claremente Balvanera es el barrio m\u00e1s inseguro de la Comuna 3.","a89b10a5":"###\u00a0Variables categoricas","7569b6ec":"## Vuelvo a predecir con la profundidad relacionada al mejor score en TEST","a0c74ff5":"## Importaci\u00f3n de dataset","0aeb310b":"###\u00a0Random Forest","29dff2d1":"####\u00a0Hurtos","90f90918":"**Veamos si hay correlaciones**","4a5624ea":"###\u00a0Random Forest","b3c2a726":"####\u00a0Tipo de delito\nVeamos la cantidad de hurtos que tenemos como as\u00ed tambien los tipos.","7659a56c":"**COMUNA 4. La Boca, Barracas, Parque Patricios y Nueva Pompeya**","3bdf3057":"### Distribuci\u00f3n absoluta de los delitos seg\u00fan a\u00f1o","ad555776":"    Se observa lo siguiente:\n    * En el a\u00f1o 2016, se puede observar que existieron mayor cantidad de robos que el resto de los a\u00f1os, teniendo un pico a fin de a\u00f1o.\n    * En el a\u00f1o 2017, se puede observar que existieron menos cantidad de robos que el 2016, y el pico al contrario, estuvo al principio pero tambi\u00e9n al final del a\u00f1o. Se nota tambi\u00e9n una fuerte caida en el mes de Julio.\n    * En el a\u00f1o 2018, se puede observar que existieron muy parecida la cantidad de robos que el 2016, comenzo el a\u00f1o con m\u00e1s robos que el resto de los a\u00f1os y tambi\u00e9n su pico fue a finales de a\u00f1o, con una fuerte ca\u00edda en el mes de Junio.","4faf65dd":"    En realidad, no necesariamente el barrio que m\u00e1s crimenes tiene va a concordar con la Comuna que m\u00e1s crimenes tiene, ya que, las Comunas como vimos arriba, no siempre tiene la misma cantidad de barrios. Es el caso de la Comuna 1, que tiene asociados 6 barrios y es por eso que estaba primero, tiene m\u00e1s registros en total, pero si nos fijamos en el caso del Barrio \"Palermo\" es el que m\u00e1s tiene individualmente, sin embargo si lo vemos desde la Comuna al ser un solo barrio en el total termina estando en el 4to lugar. Aqu\u00ed podemos ver la importancia de no generalizar desde un principio e ir al detalle en la informaci\u00f3n que tenemos.","811602e8":"    Vemos que la Comuna 1 (Retiro, San Nicol\u00e1s, Puerto Madero, San Telmo, Montserrat y Constituci\u00f3n), es la que m\u00e1s valores tiene en el dataset, por lo que es la Comuna en la que m\u00e1s crimenes se tienen registrados.","11d71b0f":"**Barrios**","92102839":"## Cantidades totales y estadisticas\n\nLa idea de esta secci\u00f3n es realizar algunos calculos y gr\u00e1ficos en base a las features que tenemos en el data set y al analisis realizado de los tipos de variable que contiene.\n\nSe comenzar\u00e1 por las features categoricas.","ced11655":"**Hasta ac\u00e1 como conclusi\u00f3n podemos decir que se nota el desbalanceo de las clases, ya que claramente algunas casi no fueron consideredas por el modelo, pero \nlas que fueron consideradas, como las que vimos arriba, solamente podr\u00edamos decir que serviria para el caso de Robo Con violencia, se deber\u00eda seguir mejorando la selecci\u00f3n de nuestro X, como as\u00ed tambi\u00e9n intentar con otro modelo.**","4f2fd14e":"    Armamos el gr\u00e1fico con cada uno de los filtros realizados anteriormente \u00bfse podr\u00eda haber realizado de una forma m\u00e1s simple?","34f97957":"#\u00a0Delitos en la Ciudad Autonoma de Buenos Aires (CABA)\n\nBasado en la informaci\u00f3n proveniente de: https:\/\/github.com\/ramadis\/delitos-caba y https:\/\/mapa.seguridadciudad.gob.ar\/\nOtras fuentes interesantes: Informe de seguridad de CABA \"informe_segunda_edicion seguridad CABA\", https:\/\/mapa.seguridadciudad.gob.ar\/, https:\/\/blogs.iadb.org\/seguridad-ciudadana\/es\/existe-un-algoritmo-para-explicar-el-crimen\/, https:\/\/www.iproup.com\/innovacion\/1648-inseguridad-robo-crimen-Inteligencia-Artificial-como-detecta-delitos-antes-de-que-ocurran, https:\/\/www.academia.edu\/25562805\/Utilizaci%C3%B3n_de_algoritmos_de_clasificaci%C3%B3n_para_la_predicci%C3%B3n_de_los_delitos_que_afectan_la_seguridad_ciudadana_en_Guayaquil\n\n\n**Problema - Insight**\n\n\u00bfC\u00f3mo se distribuyen los crimenes en CABA? \u00bfEs insegura CABA? \u00bfQu\u00e9 barrios son m\u00e1s peligrosos? \u00bfSe podr\u00eda realizar alguna soluci\u00f3n a partir de ML que prediga en que zona puede llegar a haber un delito? \u00bfSe podr\u00eda clasificar que delito es en base a ciertas variables?\n\n**Sobre este notebook**\n\nLa idea en este notbook, es solamente mostrar la parte del analisis, lo m\u00e1s completo posible, basado en los conocimientos adquiridos hasta el momento, siempre pensando en que esto sirva luego para poder predecir con Machine Learning y resolver el problema planteado.\n\nMi inspiraci\u00f3n para realizarlo fue el haber leido algunas notas sobre como predecian delitos a partir de ML, que incluso ya esta comenzandose a implementar en algunas partes del mundo.\n\n**Estructura**\n\nEl analisis se estructura de la siguiente forma:\n* Importaci\u00f3n de librerias.\n* Leyendo el data set.\n* An\u00e1lisis exploratorio de datos (EDA).\n * 1. Analizando los tipos de variables (features).\n * 2. Analizando y limpiando el data set.\n * 3. Cantidades totales y estadisticas.\n * 4. Graficando y cruzando variables para entender mejor.\n * 5. Correlaciones.\n* Feature Engineering.\n * 1. Cantidad de muertes por homicidios\n * 2. Discretizaci\u00f3n y Binning de la hora.\n * 3. Transformando datos con Scikit Learn\n* Clasificaci\u00f3n utilizando algoritmos de Machine Learning - Supervisado.","949751c0":"    Claramente no se observa ninguna correlaciones entre las variables (salvo la esperable latitud y longitud), luego de realizar Feature Engineering quizas podamos encontrar algo.","84aa45eb":"### Feature importances\nVeamos la importancia que le asigna el modelo a cada feature.","b9ad248c":"### Un poco de transformaci\u00f3n de datos con Scikit Learn\nVamos a realizar un OneHotEncoder sobre el tipo de delito, esto nos puede llegar a servir para la futura implementaci\u00f3n de ML.","318ad68a":"Con el cambio de los valores de nuestra X, se puede observar que este gr\u00e1fico es bastante distinto al anterior. Aqu\u00ed podemos ver que a partir de la profundidad 20 aproximademente los datos de training y testing se comienzan a separar respecto a su Score, donde pareciera que el modelo empieza a sufrir overffitting en los datos de entrenamiento.\n\nRespecto al Score, se observa muy similar al anterior que como m\u00e1ximo con los datos de testing, lo cual no parece un modelo muy fiable, pero a continuaci\u00f3n evaluaremos otras m\u00e9tricas.","1084cfe9":"## Feature Engineering","2be1eb98":"#### Comuna\nPrimero contemos la cantidad de registros que existen por cada valor, aunque antes de avanzar veamos que barrios tiene cada comuna:\n\n* COMUNA 1. Retiro, San Nicol\u00e1s, Puerto Madero, San Telmo, Montserrat y Constituci\u00f3n\n* COMUNA 2. Recoleta\n* COMUNA 3. Balvanera y San Crist\u00f3bal\n* COMUNA 4. La Boca, Barracas, Parque Patricios y Nueva Pompeya\n* COMUNA 5. Almagro y Boedo\n* COMUNA 6. Caballito\n* COMUNA 7. Flores y Parque Chacabuco\n* COMUNA 8. Villa Soldati, Villa Riachuelo y Villa Lugano\n* COMUNA 9. Liniers, Mataderos y Parque Avellaneda\n* COMUNA 10. Villa Real, Monte Castro, Versalles, Floresta, V\u00e9lez Sarfield y Villa Luro\n* COMUNA 11. Villa General Mitre, Villa Devoto, Villa del Parque y Villa Santa Rita\n* COMUNA 12. Coghlan, Saavedra, Villa Urquiza y Villa Pueyrred\u00f3n\n* COMUNA 13. N\u00fa\u00f1ez, Belgrano y Colegiales\n* COMUNA 14. Palermo\n* COMUNA 15. Chacarita, Villa Crespo, La Paternal, Villa Ort\u00fazar, Agronom\u00eda y Parque Chas\n\nAhora si, teniendo un poco m\u00e1s de contexto continuemos:","0002dda7":"##\u00a0Predicci\u00f3n y evaluaci\u00f3n"}}