{"cell_type":{"cdd613ed":"code","738fe8b5":"code","11452f39":"code","4aa91ba2":"code","8844dc1c":"code","89d1809f":"code","acf2d9e0":"code","4aa03171":"code","35a70681":"code","da39a822":"code","318361c8":"code","0d25705c":"code","ac185387":"code","d5f9f9e0":"code","fb71422c":"code","aff67218":"markdown","fc838871":"markdown","6fa5b337":"markdown","89dc0222":"markdown","eec88ab8":"markdown","ade929fa":"markdown","740fc90c":"markdown","14c53376":"markdown","5cc46c8e":"markdown","fcb60c24":"markdown","7883b156":"markdown","fb7fb200":"markdown","a929bd17":"markdown","d45b0eb9":"markdown","7368516a":"markdown"},"source":{"cdd613ed":"import numpy as np\nimport pandas as pd \nfrom matplotlib import pyplot\nfrom sklearn import datasets\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import scale #Need to scale things for clustering\nfrom seaborn import pairplot as pplot  #Lovely plot right here :)\nimport random\n\nrandom.seed(12) #While exploring, we shall keep our randoms not so random","738fe8b5":"irisData,irisTarget = datasets.load_iris(return_X_y=True,as_frame=True)\n\nirisData.columns = ['SepalL','SepalW','PetalL','PetalW']\nirisData['Type'] = irisTarget\n\nirisData.describe()","11452f39":"pplot(irisData, hue='Type')","4aa91ba2":"irisData.drop(columns=['SepalL', 'SepalW'], axis=1, inplace=True)\npplot(irisData, hue='Type')","8844dc1c":"#We take samples three times, 60% of each of the types we have, appending them all to a new dataframe that shall be our training set\nirisDataTrain = pd.DataFrame()\nfor num in range(3):\n    irisDataTrain = irisDataTrain.append(irisData.query('Type == @num').sample(random_state=12, frac=0.60))\n\n#As indexes will remain as they were, we can easly separate our testing set just by dropping indexes that are in the training set from the full set\nirisDataTest = irisData.drop(irisDataTrain.index)","89d1809f":"pyplot.figure(figsize=(8, 8))\npyplot.scatter(irisDataTest['PetalW'], irisDataTest['PetalL'],c='b')\npyplot.scatter(irisDataTrain['PetalW'], irisDataTrain['PetalL'],c='r')\npyplot.legend([\"Test set\", \"Train set\"])\npyplot.xlabel(\"Petal width\")\npyplot.ylabel(\"Petal height\")\npyplot.show()","acf2d9e0":"#We know that we need three clusters so we feed that to our K-means\nKmodel = KMeans(n_clusters=3, random_state=12)\nKmodel = Kmodel.fit(irisDataTrain[['PetalW','PetalL']]) \n#It is ussualy a good idea to scale our data, but as the dimension are not that distant, we should be ok\n#Try to scale the values and see if it makes any difference","4aa03171":"Kmodel.labels_","35a70681":"irisDataTrain['Type'].values","da39a822":"setosa = [irisDataTest.query('Type == 0')['PetalW'].mean(),irisDataTrain.query('Type == 0')['PetalL'].mean()]\nversicolor = [irisDataTrain.query('Type == 1')['PetalW'].mean(),irisDataTrain.query('Type == 1')['PetalL'].mean()]\nvirginica = [irisDataTrain.query('Type == 2')['PetalW'].mean(),irisDataTrain.query('Type == 2')['PetalL'].mean()]\n\nsetosaLabel = Kmodel.predict(np.array(setosa).reshape(1, -1))[0] #We are using reshape to spin the array as we've only one sample so it will think it's a 1D array if we do not\nversicolorLabel = Kmodel.predict(np.array(versicolor).reshape(1, -1))[0]\nvirginicaLabel = Kmodel.predict(np.array(virginica).reshape(1, -1))[0]","318361c8":"irisDataTrain['Kmean'] = Kmodel.labels_\nirisDataTrain['Kmean'] = irisDataTrain['Kmean'].map({setosaLabel:int(0),versicolorLabel:int(1),virginicaLabel:int(2)})\nirisDataTrain['Kmean'].values","0d25705c":"irisDataTrain['Type'].values","ac185387":"(len(irisDataTrain.query('Type != Kmean'))\/len(irisDataTrain))*100","d5f9f9e0":"irisDataTest['KMeansPredict'] = Kmodel.predict(irisDataTest[['PetalW','PetalL']])\n\n#We need to convert our symbols:\nirisDataTest['KMeansPredict'] = irisDataTest['KMeansPredict'].map({setosaLabel:int(0),versicolorLabel:int(1),virginicaLabel:int(2)})\n\n#And the final error:\n(len(irisDataTest.query('Type != KMeansPredict'))\/len(irisDataTest))*100","fb71422c":"irisErrors = irisDataTest.query('Type != KMeansPredict')\nirisCorrect = irisDataTest.query('Type == KMeansPredict')\npyplot.figure(figsize=(8, 8))\npyplot.scatter(irisCorrect['PetalW'], irisCorrect['PetalL'],c='g')\npyplot.scatter(irisErrors['PetalW'], irisErrors['PetalL'],c='r')\npyplot.legend([\"Correct\", \"Wrong\"])\npyplot.xlabel(\"Petal width\")\npyplot.ylabel(\"Petal height\")\npyplot.show()","aff67218":"If our model did not fail us, we should have the symbols. It is now easy to map them to the representations in our datasets, once we attach them to a dataframe:","fc838871":"We can notice two thigs. One, we can eyeball the error rate and it seems to be rather small (look for the out of place 1s and 2s in the first array). That is nice. But, before we celebrate we seem to have a huge issue. It seems that the K-means values have 1s and 2s mixed up. Why did this occur? <\/br>\nK-means is random. The cluster labels will depend on that randomness and we have no control over that. So, that is an issue, I can cluster the data, but I can't know what cluster label is indicating my setosas and where my versicolors are. So we have no use of the data in this state. Now, we built our testing and traning data from scratch, so we know it is ordered and I could just directly map the first symbol in the cluster labels to my first type and so on. But this is bad for two reasons: <br\/><br\/>\n1) If we did not set the random state, every time we run this we have to stop right here, check the outputs and reconfigure our mapping, because our setosas might be labelled 0 one run, and then 2 the next.<br\/>\n2) Was this a real model, I would not have the luxury of order with incoming data. Who is to say that I'm not gonna get a lovely set of 5000 virginicas to go thru. Let us work on this like it is a real life model and deal with that issue.  <br\/>\n\nI know I can be sure about two things. My training set is properly labelled, so I know the correct type symbols. My model is good enough that, should I supply it the means of petal length and width of a type, it will tell me how it labelled the type in the current run. So, that is my plan. I am gonna take the training data, get the means of each type and predict those with my model, letting me know how K-means labelled each of the types. Then, I can simply map the model cluster labels to the values I want them to be, so we can get usefull data out of the model.   ","6fa5b337":"Much nicer for our purposes. We have less crossover here, so, as far as the data we have, this should bring us a better model.  \nThe sepal situation is only the start of our problems tho. We have a very small dataset do begin with. Only 150 rows. And we must take a bite out of that so we can have a train\/test pair else we won't be able to judge how well our model is doing. If we take too much, we will be in danger of overfitting and not even know it as we lack enough test data. One thing we can do is try several splits into train\/test pairs of different proportions and see how they work with our model, *feel free to mess around with that split and see what you come up with*. My second concern is that, if we take a random amount of samples out of the full dataset, we have a very good chance of underrepresenting a category. To   alleviate that issue I have designed a method that will take a sample of each of the three types we have, and it will take 60% of each, leaving us with 40% to test our predictions with.    ","89dc0222":"A 6% error on our testing data. And, as we can see, all of the errors are in the crossover area, that much we expected starting off. Not the best, but not bad for a quick K-means implementation. Hope you had fun, and do experiment with the model :) .","eec88ab8":"We can see scatter plots for each and every possible combination of our attributes. The diagonal contains univariate distributions, that is to say, we can see a probability density function for our continuous data as far as that column goes. I can see, immediately, that anything having to do with sepals is a right mess (observe the massive crossover of the pdfs in the upper left quartile). That is a problem. We intend to do this by clustering. Clustering depends, well, it depends on clusters, not a big mixed bag of data.  \nI shall assume that, if anything, the sepal data will introduce errors into our predictions. <br\/> <br\/>\n*Am I right? Try to run thru this activity with sepal data included and see if you can get better results.*<br\/>  \nTo that end, I shall strip the data away, and just keep to the petals.","ade929fa":"Compare that to our type symbols:","740fc90c":"<center><h2>Data wrangling<\/h2><\/center>  \n<br\/><br\/>   ","14c53376":"Now that we have our model we actually have the biggest problem so far. K-means is gonna give us the predictions as an array of cluster labels, observe:","5cc46c8e":"The first goal for us is to get the actual data. Luckly, the iris dataset is included in sklearn, and we can easily turn it into a pandas dataframe so we can work on it.  As the dataset comes to us with long column names and the type column separated, we shall adjust those right away and attach the column so it is easier for us to work.","fcb60c24":"Our data seems to be good to go. We just need to figure out where it's gonna go. Now, I'm a visual type of guy so you can throw numbers at me all day, but until I see a plot it's not gonna help very much. That is why I love using the seaborn pairplot. It is an incredible tool to use while exploring the dataset. So, let us fire it up: ","7883b156":"For a sanity check we drop a nice little scatter so we can eyeball the distribution of our train\/test sets. ","fb7fb200":"<center><h2>Clustering<\/h2><\/center>  \n<br\/><br\/>   \nWe will use K-means for this task. It's good for small cluster numbers and should work nicely for us. The gist of the algorithm is:<br\/>  \n-It will plop down some centoids for a start<br\/>  \n-It will assign samples to the nearest centoid<br\/>  \n-It will make new centoids by calculating the means of the samples to their assigned old centoids, effectively moving the centoid to sit right on top of the cluster that belongs to it<br\/>  \n-It will repeat the last two steps until the centoids stop moving (designated by a threshold value)<br\/>  ","a929bd17":"A 2.2% error rate over our training set. I'm happy with that. Let us see how our model will fare with our testing data:","d45b0eb9":"<center><h1>The iris dataset and clustering<\/h1><\/center>  \n<br\/><br\/>   \nWe shall explore the iris dataset and try to use clustering in order to predict if an iris is one of the three related species. As the dataset is well known we already know that we will not be able to do so perfectly, with the virginica and versicolor mix-up, but we shall still try to do the best we can.","7368516a":"We have managed to set up the cluster labels so that they are referencing the data we have. The beauty of it is that now, should the model not break in a horrible fashion, this issue will be handled for us, and as long as we keep to the 0,1,2 for the types in our data we've no need to change a single thing. Since we have already attached the results to our training set, let us see how much of an error we have:"}}