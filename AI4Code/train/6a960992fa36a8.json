{"cell_type":{"e1ed67b0":"code","dec15ba6":"code","62028df7":"code","fb899142":"code","54a23b1d":"code","0022ccf0":"code","51d891ae":"code","a88af62a":"code","d0901ce0":"code","5ab18a81":"code","32302b4a":"code","4777f9d7":"code","4e566986":"code","ae590046":"code","16c78a1a":"code","8b89506f":"code","b5a7e7ec":"code","dde2c827":"code","c26fa7c9":"code","14ac0dfe":"code","16397654":"code","3751794f":"code","bac98f7d":"code","a2a0f784":"code","502b994f":"code","9dcca2f2":"code","bd5cf179":"code","1f0a3119":"code","97cf2e2f":"markdown","3790def1":"markdown","1881fb5f":"markdown","92b9f661":"markdown","a9c48ab1":"markdown"},"source":{"e1ed67b0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dec15ba6":"# Load the Datasets\ntrain = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/test.csv\")\nsubmission = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/sample_submission.csv\")","62028df7":"# First 5 row for train dataset\ntrain.head()","fb899142":"# First 5 row for test dataset\ntest.head()","54a23b1d":"print(f\"Train dataset shape {train.shape}\")\nprint(f\"Test dataset shape {test.shape}\")","0022ccf0":"print(f\"Null value for train dataset: {train.isna().sum()}\")\nprint(\"--------------------\")\nprint(f\"Null value for train dataset: {test.isna().sum()}\")","51d891ae":"# Function for drop columns\n\ndef drop_col(trainORtest, col_name):\n    trainORtest.drop(col_name, axis=1, inplace=True)","a88af62a":"# drop unnecessary column\n\ndrop_col(train, \"keyword\")\ndrop_col(train, \"location\")\n\ndrop_col(test, \"keyword\")\ndrop_col(test, \"location\")","d0901ce0":"text_message = train[\"text\"]\nprint(text_message)","5ab18a81":"def clean_data(name):\n    # Replace email addresses with 'email'\n    processed = name.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$',\n                                     'emailaddress')\n\n    # Replace URLs with 'webaddress'\n    processed = processed.str.replace(r'^http\\:\/\/[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(\/\\S*)?$',\n                                      'webaddress')\n\n    # Replace money symbols with 'moneysymb' (\u00a3 can by typed with ALT key + 156)\n    processed = processed.str.replace(r'\u00a3|\\$', 'moneysymb')\n\n    # Replace 10 digit phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\n    processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$',\n                                      'phonenumbr')\n\n    # Replace numbers with 'numbr'\n    processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')\n\n    # Remove punctuation\n    processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n\n    # Replace whitespace between terms with a single space\n    processed = processed.str.replace(r'\\s+', ' ')\n\n    # Remove leading and trailing whitespace\n    processed = processed.str.replace(r'^\\s+|\\s+?$', '')\n\n    # change words to lower case - Hello, HELLO, hello are all the same word\n    processed = processed.str.lower()\n    \n    return processed","32302b4a":"clean_train = clean_data(train[\"text\"])\nclean_test = clean_data(test[\"text\"])","4777f9d7":"from nltk.corpus import stopwords\n\nstop_words = set(stopwords.words(\"english\"))\n\nclean_train = clean_train.apply(lambda x:\" \".join(term for term in x.split() if term not in stop_words))\n\nclean_test = clean_test.apply(lambda x:\" \".join(term for term in x.split() if term not in stop_words))","4e566986":"clean_train","ae590046":"from nltk.stem import PorterStemmer\n\nps = PorterStemmer()\n\nclean_train = clean_train.apply(lambda x:\" \".join(term for term in x.split() if term not in stop_words))\n\nclean_test = clean_test.apply(lambda x:\" \".join(term for term in x.split() if term not in stop_words))","16c78a1a":"clean_train","8b89506f":"from nltk.stem import WordNetLemmatizer\n\nwl = WordNetLemmatizer()\n\nclean_train = clean_train.apply(lambda x:\" \".join(term for term in x.split() if term not in stop_words))\n\nclean_test = clean_test.apply(lambda x:\" \".join(term for term in x.split() if term not in stop_words))","b5a7e7ec":"clean_test","dde2c827":"train[\"text\"] = clean_train\ntest[\"text\"] = clean_test","c26fa7c9":"# Spliting train and test set\n\nfrom sklearn.model_selection import train_test_split\n\nseed = 42\n\nX = train.text\ny = train.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)","14ac0dfe":"# some important libraries\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import MultinomialNB, BernoulliNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC","16397654":"# accuracy score function\n\ndef acc_summary(pipeline, X_train, y_train, X_test, y_test):\n    sentiment_fit = pipeline.fit(X_train, y_train)\n    y_pred = sentiment_fit.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n   \n    print(\"-\"*30)\n    \n    print(\"accuracy score: {0:.2f}%\".format(accuracy*100))\n    \n    print(\"-\"*30)\n    \n    return accuracy","3751794f":"# some model and their performance\n\nnames = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"Bernouli\", \"PassiveAggressiveClassifier\",\n     \"Naive Bayes\", \"SVC\"]\n\nclassifiers = [\n    KNeighborsClassifier(n_neighbors=3),\n    DecisionTreeClassifier(random_state=0),\n    RandomForestClassifier(n_estimators=100),\n    LogisticRegression(),\n    MultinomialNB(),\n    BernoulliNB(),\n    PassiveAggressiveClassifier(max_iter=50),\n    SVC(kernel=\"linear\")\n]\n    \nzipped_clf = zip(names, classifiers)\ntvec = TfidfVectorizer()\n    \ndef compare_clf(classifier=zipped_clf, vectorizer=tvec, n_features=10000, ngram_range=(1, 1)):\n    result = []\n    vectorizer.set_params(stop_words=stop_words, max_features=n_features, ngram_range=ngram_range)\n    for n, c in classifier:\n        checker_pipeline = Pipeline([\n            (\"vectorizer\", vectorizer),\n            (\"classifier\", c)\n        ])\n        clf_acc = acc_summary(checker_pipeline, X_train, y_train, X_test, y_test)\n        print(\"Model result for {}\".format(n))\n        print(c)\n        result.append((n, clf_acc))\n    return result","bac98f7d":"trigram_result = compare_clf()","a2a0f784":"trigram_result","502b994f":"# prediction\n\ndef prediction(pipeline, testtext):\n    sentiment_fit = pipeline.fit(X_train,y_train)\n    y_pred = sentiment_fit.predict(testtext)\n    \n    return y_pred","9dcca2f2":"# Use TfidfVectorizer\n# use of pipeline\nvectorizer=TfidfVectorizer()\nchecker_pipeline = Pipeline([\n            ('vectorizer', vectorizer),\n            ('classifier', LogisticRegression())\n        ])\nvectorizer.set_params(stop_words=None, max_features=100000, ngram_range=(1,4))\nprediction=prediction(checker_pipeline,test['text'])","bd5cf179":"prediction","1f0a3119":"\nindex = test.id\nnewFrame = pd.DataFrame({\"id\":index, \"target\":prediction})\nnewFrame.to_csv(\"realnot.csv\", index=False)","97cf2e2f":"# Implement the best model","3790def1":"# Text processing","1881fb5f":"# If you like it, please upvote","92b9f661":"# The process of converting data to something a computer can understand is referred to as pre-processing. One of the major forms of pre-processing is to filter out useless data. In natural language processing, useless words (data), are referred to as stop words.","a9c48ab1":"# If you Like, please upvote"}}