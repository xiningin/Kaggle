{"cell_type":{"ab4cc294":"code","b15e8825":"code","43151b2c":"code","3f7dfde3":"code","e3d6f90b":"code","83fd861d":"code","f7035e24":"code","f03ed120":"code","aaa74b38":"code","6eae92e1":"code","1070b919":"code","87446898":"code","a90fb007":"code","d66efce4":"code","c05fcaf1":"code","501d1776":"code","80895681":"markdown","ad54eac2":"markdown","6b0e5269":"markdown","83217f43":"markdown","71f65b47":"markdown","759189f9":"markdown","8d4b43e2":"markdown","2363fedf":"markdown","d234eb0a":"markdown"},"source":{"ab4cc294":"import numpy as np \nimport pandas as pd \nimport sklearn\nimport os\nprint(os.listdir(\"..\/input\"))","b15e8825":"data = pd.read_csv(\"..\/input\/Wage.csv\")\nnum_rows = data.shape[0]\nprint(num_rows)","43151b2c":"data.head()","3f7dfde3":"data.describe()","e3d6f90b":"data_x = data['age']\ndata_y = data['wage']\nfrom sklearn.model_selection import train_test_split\ntrain_x, valid_x, train_y, valid_y = train_test_split(data_x, data_y, test_size=0.33, random_state=1)\n\nimport matplotlib.pyplot as plt\nplt.scatter(train_x, train_y, facecolor='None', edgecolor='k', alpha=0.3)\nplt.show()","83fd861d":"from sklearn.linear_model import LinearRegression\n\n# Fit linear regression model\nx = train_x.values.reshape(-1,1)\nmodel = LinearRegression()\nmodel.fit(x, train_y)\nprint(model.coef_)\nprint(model.intercept_)","f7035e24":"from sklearn.linear_model import LinearRegression\nx = train_x.values.reshape(-1,1)\nmodel = LinearRegression()\nmodel.fit(x, train_y)\nprint(model.coef_)\nprint(model.intercept_)","f03ed120":"# prediction on validation dataset\nvalid_x = valid_x.values.reshape(-1, 1)\npred = model.predict(valid_x)\n\n#visualization\nxp = np.linspace(valid_x.min(), valid_x.max(), 70)\nxp = xp.reshape(-1,1)\npred_plot = model.predict(xp)\n\nplt.scatter(valid_x, valid_y, facecolor='None', edgecolor='k', alpha=0.3)\nplt.plot(xp, pred_plot)\nplt.show()","aaa74b38":"from sklearn.metrics import mean_squared_error\nfrom math import sqrt\n\nrms = sqrt(mean_squared_error(valid_y, pred))\nprint(rms)","6eae92e1":"weights = np.polyfit(train_x, train_y, 25)\nprint(weights)","1070b919":"# generating model with the given weights\nmodel = np.poly1d(weights)\n\n#prediction on validation set\npred = model(valid_x)\n# plot the graph for 70 observations only\nxp = np.linspace(valid_x.min(), valid_x.max(), 70)\npred_plot = model(xp)\nplt.scatter(valid_x, valid_y, facecolor='None', edgecolor='k', alpha=0.3)\nplt.plot(xp, pred_plot)\nplt.show()","87446898":"# dividing the data into 4 bins \ndf_cut, bins = pd.cut(train_x, 4, retbins=True, right=True)\ndf_cut.value_counts(sort=False)","a90fb007":"df_steps = pd.concat([train_x, df_cut, train_y], keys=['age','age_cuts','wage'], axis=1)\n\n# create dummy variables for the age groups\ndf_steps_dummies = pd.get_dummies(df_cut)\ndf_steps_dummies.head()","d66efce4":"import statsmodels.api as sm\n\ndf_steps_dummies.columns = ['17.938-33.5','33.5-49.0','49.0-64.5','64.5-80.0']\n\n# fitting generalized linear models\nfit3 = sm.GLM(df_steps.wage, df_steps_dummies).fit()\n\n# binning validation set into same 4 bins\nbin_mapping = np.digitize(valid_x, bins).flatten()\n\nX_valid = pd.get_dummies(bin_mapping)\n\n# removing any outliers\nX_valid = pd.get_dummies(bin_mapping).drop([5], axis=1)\n\n# prediction\npred2 = fit3.predict(X_valid)\n\n# calculating RMSE\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nrms = sqrt(mean_squared_error(valid_y, pred2))\nprint(rms)\n","c05fcaf1":"# we sill plot the graph for the 70 observations only\nxp = np.linspace(valid_x.min(), valid_x.max()-1, 70)\nbin_mapping= np.digitize(xp, bins)\nX_valid_2 = pd.get_dummies(bin_mapping)\npred2 = fit3.predict(X_valid_2)\n\n# visualization\nfig, (ax1) =  plt.subplots(1,1, figsize=(12,5))\nfig.suptitle(\"Piecewise constant\", fontsize=14)\n\n# scatter plot with polynomial regression line\nax1.scatter(train_x, train_y, facecolor='None', edgecolor='k', alpha=0.3)\nax1.plot(xp, pred2, c='b')\n\nax1.set_xlabel('age')\nax1.set_ylabel('wage')\nplt.show()","501d1776":"from patsy import dmatrix \nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# generating cubic spline with 3 knots at 25, 40 and 60\ntransformed_x = dmatrix(\"bs(train, knots=(25,40,60), degree=3, include_intercept=False)\", {\"train\": train_x}, return_type='dataframe')\n\n# fitting generalized linear model on transformed dataset\nfit1 = sm.GLM(train_y, transformed_x).fit()\n\n# generating cubic spline with 4 knots\ntransformed_x2 = dmatrix(\"bs(train, knots=(25,40,50,65), degree=3, include_intercept=False)\", {\"train\": train_x}, return_type='dataframe')\n\n# fitting generalized linear model on transformed dataset\nfit2 = sm.GLM(train_y, transformed_x2).fit()\n\n# predictions on both splines\npred1 = fit1.predict(dmatrix(\"bs(valid, knots=(25,40,60), include_intercept=False)\", {\"valid\":valid_x}, return_type='dataframe'))\npred2 = fit2.predict(dmatrix(\"bs(valid, knots=(25, 40,50,65), degree=3, include_intercept=False)\", {\"valid\":valid_x}, return_type='dataframe'))\n\n# calculating rmse\nrms1 = sqrt(mean_squared_error(valid_y, pred1))\nprint(rms1)\n\nrms2 = sqrt(mean_squared_error(valid_y, pred2))\nprint(rms2)\n\n# we wil plot the graph for 70 observations only\nxp = np.linspace(valid_x.min(), valid_x.max(), 70)\n\n# make some predictions\npred1 = fit1.predict(dmatrix(\"bs(xp, knots=(25,40,60), include_intercept=False)\", {\"xp\":xp}, return_type='dataframe'))\npred2 = fit2.predict(dmatrix(\"bs(xp, knots=(25,40,50,60), include_intercept=False)\", {\"xp\":xp}, return_type='dataframe'))\n\n# plot the splines and error bands\nplt.scatter(data.age, data.wage, facecolor='None', edgecolor='k', alpha=0.1)\nplt.plot(xp, pred1, label='Specifying degree=3 with 3 knots')\nplt.plot(xp, pred2, label='Specifying degree=3 with 4 knots')\nplt.legend()\nplt.xlim(15,85)\nplt.ylim(0, 350)\nplt.xlabel('age')\nplt.ylabel('wage')\nplt.show()","80895681":"## Calculating RMSE (Root Mean Squared Error)","ad54eac2":"# Summarize Data","6b0e5269":"# Visualize age and wage","83217f43":"## Regression Splines","71f65b47":"## Cubic and Natural Cubic Splines","759189f9":"## Overview\nA transcription to working notebook of  [Introduction to Regression Splines (with Python codes)](https:\/\/www.analyticsvidhya.com\/blog\/2018\/03\/introduction-regression-splines-python-codes\/)\n\nThe purpose of this notebook is to test and have working code to understand regression splines method.","8d4b43e2":"## Simple Linear Regression","2363fedf":"## Calculating RMSE (Root Mean Squared Error)","d234eb0a":"## Generating weights for polynomial function with degree =2"}}