{"cell_type":{"0ea77a39":"code","49087891":"code","573b9d52":"code","3097360a":"code","8b8debae":"code","bf9393c2":"code","a280abbd":"code","c3c09940":"code","19d8b962":"code","b809bc65":"code","f706ae04":"code","9cd86959":"code","ea20f55e":"code","e90addbe":"code","f5536ad3":"code","4bbf704c":"code","05913af0":"code","854d2541":"code","2c1d51bb":"code","273cd871":"code","c1f4799e":"code","1f54b5d9":"code","8496c97c":"code","701bdd1e":"code","59f37920":"code","fcda1de7":"code","291f60f6":"code","f1096209":"code","c044258c":"code","092f26d8":"code","1c462a87":"markdown","74df2d60":"markdown","6dd05607":"markdown","59059af0":"markdown","6bb06af4":"markdown","206f3b52":"markdown","a3c63d87":"markdown","c3e5790e":"markdown","c4e71aa5":"markdown","3daae1ef":"markdown","5ec7e50e":"markdown","f86a5536":"markdown","c603eec4":"markdown","67f0f0e4":"markdown","1d32463b":"markdown","6104e1fa":"markdown","91b5652d":"markdown","82634245":"markdown","aca1c086":"markdown","16dfdb53":"markdown"},"source":{"0ea77a39":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\n\n# Model\nfrom sklearn.linear_model import LinearRegression\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","49087891":"# read in all data\ntrain = pd.read_csv('\/kaggle\/input\/dsn-ai-futa-challenge\/Train.csv')\ntest = pd.read_csv('\/kaggle\/input\/dsn-ai-futa-challenge\/Test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/dsn-ai-futa-challenge\/Sample_Submission.csv')","573b9d52":"#print out the shape of both Train and Test data\nprint('Train shape',train.shape)\nprint('Test shape',test.shape)","3097360a":"#Print the head of train\ntrain.head()","8b8debae":"#Print the head of test\ntest.head()","bf9393c2":"#Total number of entries that are missing in each column\ntrain.isna().sum()","a280abbd":"plt.figure(figsize=(10,6)) # Set the size of the plot\nsns.heatmap(train.corr(),annot=True) # Correlation Heatmap","c3c09940":"#scatterplot of all features\ncat_col = ['Product_Fat_Content','Product_Type','Supermarket_Location_Type','Supermarket_Type']#get categorical features of train data\n\nfor columns in cat_col: \n    sns.set()\n    cols = ['Product_Identifier', 'Supermarket_Identifier',\n           'Product_Fat_Content', 'Product_Shelf_Visibility', 'Product_Type',\n           'Product_Price', 'Supermarket_Opening_Year',\n           'Supermarket_Location_Type', 'Supermarket_Type',\n           'Product_Supermarket_Sales']\n    plt.figure()\n    sns.pairplot(train[cols], size = 3.0, hue=columns)\n    plt.show()\n","19d8b962":"# the columns contain missing value are 1.Product_Weight(Numerical) 2. Supermarket _Size (Categorical)\ntrain['Product_Weight'].fillna(train['Product_Weight'].mean(),inplace=True)\ntrain['Supermarket _Size'].fillna(train['Supermarket _Size'].mode()[0],inplace=True)\n\n# We will have to use the same strategy for out test data\ntest['Product_Weight'].fillna(test['Product_Weight'].mean(),inplace=True)\ntest['Supermarket _Size'].fillna(test['Supermarket _Size'].mode()[0],inplace=True)","b809bc65":"#Now we have no missing values in both train and test data\ntrain.isna().sum()","f706ae04":"test.isna().sum()","9cd86959":"# Concatenate train and test sets for easy feature engineering.\n# You can as well apply the transformations separately on the train and test data intead of concatenating them.\nntrain = train.shape[0]\nntest = test.shape[0]\n\n#get target variable\ny = train['Product_Supermarket_Sales']\n\nall_data = pd.concat((train,test)).reset_index(drop=True)\n\n#drop target variable\nall_data.drop(['Product_Supermarket_Sales'], axis=1, inplace=True)\n\nprint(\"Total data size is : {}\".format(all_data.shape))","ea20f55e":"# Let's Create the squarred root of Product_Price\nall_data['Product_Price_sqrt'] = np.sqrt(all_data['Product_Price'])\n\n#Create some cross features\nall_data['cross_Price_weight'] = all_data['Product_Price'] * all_data['Product_Weight']","e90addbe":"all_data.columns","f5536ad3":"one_hot_cols = ['Supermarket_Type','Supermarket _Size','Product_Type','Supermarket_Location_Type']\n\nlabel_cols = ['Product_Identifier','Supermarket_Identifier','Product_Fat_Content']","4bbf704c":"all_data = pd.get_dummies(all_data,prefix_sep=\"_\",columns=one_hot_cols)","05913af0":"for col in label_cols:\n    all_data[col] = all_data[col].factorize()[0]","854d2541":"# We are going to drop Product_Supermarket_Identifier' since it's just an ID and we don't need it.\nall_data.drop('Product_Supermarket_Identifier',axis=1,inplace=True)","2c1d51bb":"#Lets get the new train and test set\ntrain = all_data[:ntrain]\ntest = all_data[ntrain:]\n\nprint('Train size: ' + str(train.shape))\nprint('Test size: ' + str(test.shape))","273cd871":"train.head()","c1f4799e":"test.head()","1f54b5d9":"# Spllitting train data into training and validation set. We are using just 20%(0.2) for validation \nX_train,X_test,y_train,y_test = train_test_split(train,y,test_size=0.2,random_state=42)","8496c97c":"# Define the model\nlr = LinearRegression()","701bdd1e":"lr.fit(X_train,y_train)","59f37920":"y_hat = lr.predict(X_test)","fcda1de7":"print('Validation scores', np.sqrt(mean_squared_error(y_test, y_hat)))\n\nprint('Training scores', np.sqrt(mean_squared_error(y_train, lr.predict(X_train))))","291f60f6":"test_pred = lr.predict(test);test_pred","f1096209":"submission.head()","c044258c":"submission['Product_Supermarket_Sales'] = test_pred","092f26d8":"submission.to_csv('first_submission.csv',index=False)\n#If you submit this you should at least find a better position on the LeaderBoard","1c462a87":"At a glance we can see that the highest correlated feature to Product_Supermaket_Sales is Product_Price followed by Supermaket_Opening_Year. And that makes sense because the more a shop sells  expensive goods the higher their total sales get.\nAnother observation is that it seems the year of opening also has some correlation with product sales. Lets plot some one to one plot to see if this is a negative or positive trend .\n","74df2d60":"**Encoding some categorical features for easy usability by Machine Learning Algorithms**","6dd05607":"Applying One hot encoding to one_hot_cols","59059af0":"Seems We got a pretty good model...<br>\nAlso we did not overfit because our mean_squared_error is lower on Validation data compare to train data","6bb06af4":"Now Let's get our prediction for submission","206f3b52":"**Dealing with missing values**\n\n*Taking care of missing entries in the data set*\nThere are different strategies to fill missing value in the data.You can check online to know more.<br>\nIn this notebook I will use mode and mean strategy to fill both categorical features and numerical features respectively.","a3c63d87":"### 4. Features Engineering\nSimple rule: Same transformation or generation must be done to both train and test data","c3e5790e":"**Don't Forget to give this Notebook an upvote if you found its content helpful.**<br>\n***@Christomesh***","c4e71aa5":"### 1. Import the Necessary Libraries","3daae1ef":"The goal of this competition is to predict <b>Product_Supermarket_Sales<\/b>. If you look closely, you will realize that it is not provided in the test data.","5ec7e50e":"Now that we are done with feature engineering, Let's split our data back to train and test","f86a5536":"Applying Label encoding to label_cols","c603eec4":"**Improvement Tips.....**\n\n1. Generate more features\n2. Use other Cross-Validation Techniques\n3. Try Tree based models\n\nif you have any question, kindly drop it in the comment section below.","67f0f0e4":"You can do more feature engineering to improve your scores. You can also consider scalling too if you are using linear models.","1d32463b":"From the plot above, we can confirm that an increase in price of product really makes Total sales increase. Also there seems to be a very little trend in the Supermarket  opening year and the total sales, otherwise no other feature really correlates with Total sales","6104e1fa":"### 5. Modelling","91b5652d":"### 3. Exploratory Data Analysis (EDA)\n\nProduct_Supermarket_Sales is the target variable we are trying to predict, so lets explore it.","82634245":"### 2. Load the Datasets","aca1c086":"### 6. Submission File","16dfdb53":"**Check Validation Score and Training Score**\n\nWe are not expecting large difference in the values."}}