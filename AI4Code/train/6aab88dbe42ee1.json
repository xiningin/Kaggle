{"cell_type":{"60d014f4":"code","6c1ed2b8":"code","bd6b30f1":"code","cfcbacc6":"code","236291a9":"code","62da7723":"code","235478f9":"code","99d460d9":"code","f97d1050":"code","0486f068":"code","b2958e69":"code","e7841c10":"code","72ab4d19":"code","137aa546":"code","727ceb0a":"code","ee020551":"code","449261d5":"code","a6f9da53":"markdown","5cbee45a":"markdown","137ee4e4":"markdown","2cb45f35":"markdown"},"source":{"60d014f4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6c1ed2b8":"from sklearn.model_selection import StratifiedShuffleSplit\n\nhousing = pd.read_csv('..\/input\/housing-1\/train.csv')\n\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nfor train_index, test_index in split.split(housing, housing['OverallQual']):\n    strat_train_set = housing.loc[train_index]\n    strat_test_set = housing.loc[test_index]","bd6b30f1":"housing = strat_train_set.copy()","cfcbacc6":"corr_matrix = housing.corr()\n\ncorr_matrix['SalePrice'].sort_values(ascending=False)","236291a9":"housing = strat_train_set.drop(['SalePrice'], axis=1)\nhousing_labels = strat_train_set['SalePrice'].copy()","62da7723":"conv_attribs = ['MSSubClass']\n\nnum_attribs = list(housing.columns[(housing.dtypes == 'int64') | (housing.dtypes == 'float64')])\nnum_attribs.remove('MSSubClass')\n\ncat_attribs = list(housing.columns[housing.dtypes == 'object'])\ncat_attribs.append('MSSubClass')\n\ncat_attribs_OH = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n       'HouseStyle', 'Heating', 'CentralAir', 'Electrical', 'Functional', \n        'GarageType', 'PavedDrive', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']\n\ncat_attribs_OE = ['ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'HeatingQC', 'KitchenQual',\n                 'FireplaceQu', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC']","235478f9":"from sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer","99d460d9":"def to_object(x):\n  return pd.DataFrame(x).astype('object')","f97d1050":"num_pipeline = Pipeline([('imputer', SimpleImputer(strategy='median')),\n                         ('std_scaler', StandardScaler()),\n                        ])\n\nconv_pipeline = Pipeline([('conv', FunctionTransformer(to_object))])\n\ncat_OH_pipeline = Pipeline([('imputer', SimpleImputer(strategy='constant', fill_value='NA')),\n                            ('encoder', OneHotEncoder()),                            \n                           ])\n\ncat_OE_pipeline = Pipeline([('imputer', SimpleImputer(strategy='constant', fill_value='NA')),\n                            ('encoder', OrdinalEncoder()),                            \n                           ])","0486f068":"full_pipeline = ColumnTransformer([(\"num1\", num_pipeline, num_attribs),\n                                   (\"num2\", conv_pipeline, conv_attribs),\n                                   (\"cat1\", cat_OH_pipeline, cat_attribs_OH),\n                                   (\"cat2\", cat_OE_pipeline, cat_attribs_OE),\n                                  ])","b2958e69":"housing_prepared = full_pipeline.fit_transform(housing)","e7841c10":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\n\ntree_reg = DecisionTreeRegressor()\ntree_reg.fit(housing_prepared, housing_labels)\n\nscores = cross_val_score(tree_reg, housing_prepared, housing_labels, scoring='neg_mean_absolute_error', cv=10)\n\ntree_mae_scores = -scores","72ab4d19":"def display_scores(scores):\n    print('Scores:', scores)\n    print('Mean:', scores.mean())\n    print('Standard deviation:', scores.std())","137aa546":"display_scores(tree_mae_scores)","727ceb0a":"from sklearn.ensemble import RandomForestRegressor\n\nforest_reg = RandomForestRegressor()\nforest_reg.fit(housing_prepared, housing_labels)\n\nforest_mae = mean_absolute_error(housing_labels, forest_reg.predict(housing_prepared))\n\nprint('forest mae:', forest_mae)\n\nscores = cross_val_score(forest_reg, housing_prepared, housing_labels, scoring='neg_mean_absolute_error', cv=10)\n\nforest_mae_scores = -scores\n\ndisplay_scores(forest_mae_scores)","ee020551":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    {'bootstrap': [False], 'n_estimators': [500], 'max_features': [20]},\n]\n\nforest_reg = RandomForestRegressor()\n\ngrid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n                          scoring='neg_mean_absolute_error',\n                          return_train_score=True)\n\ngrid_search.fit(housing_prepared, housing_labels)\n\ncvres = grid_search.cv_results_\nfor mean_score, params in zip(cvres['mean_test_score'], cvres['params']):\n    print(-mean_score, params)","449261d5":"feature_importances = grid_search.best_estimator_.feature_importances_\n\ncat_encoder = full_pipeline.named_transformers_['cat1'][1]\ncat_one_hot_attribs = list(cat_encoder.categories_[0])\n\nattributes = num_attribs + conv_attribs + cat_one_hot_attribs + cat_attribs_OE\n\nsorted(zip(feature_importances, attributes), reverse=True)","a6f9da53":"Split the housing data set into train and test using stratified sampling","5cbee45a":"Grid Search","137ee4e4":"Data Exploration Analysis","2cb45f35":"Model Selection"}}