{"cell_type":{"910358fd":"code","a06d6d33":"code","8fc0fd25":"code","34d06f9e":"code","1642daca":"code","e5f44d3d":"code","d19f3ec5":"code","345539c2":"code","e337fbd1":"code","702ca096":"code","5b2f06e0":"markdown","e6bcb685":"markdown","a83bf925":"markdown","ed616009":"markdown","774eac4d":"markdown","92b77f76":"markdown"},"source":{"910358fd":"!pip install wtfml==0.0.2","a06d6d33":"import os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import model_selection\nfrom itertools import product\nfrom collections import OrderedDict\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nimport torchvision\nfrom torchvision import datasets, transforms\n\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.tensorboard import SummaryWriter\n\nfrom wtfml.data_loaders.image import ClassificationLoader\nimport albumentations\n\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n","8fc0fd25":"# create 5 stratified k-folds in training set\nmelanoma_path=\"..\/input\/siim-isic-melanoma-classification\/\"\nmelanoma_image_path=\"..\/input\/siic-isic-224x224-images\/\"\n\ndf = pd.read_csv(melanoma_path + \"train.csv\")\ndf[\"kfold\"] = -1    \ndf = df.sample(frac=1).reset_index(drop=True)\ny = df.target.values\nkf = model_selection.StratifiedKFold(n_splits=5)\n\nfor f, (t_, v_) in enumerate(kf.split(X=df, y=y)):\n    df.loc[v_, 'kfold'] = f\n\n# Create train and validation indices\ndf_train = df[df.kfold != 0].reset_index(drop=True)\ndf_valid = df[df.kfold == 0].reset_index(drop=True)","34d06f9e":"training_data_path=melanoma_image_path + \"train\/\"\nmean = (0.485, 0.456, 0.406)\nstd = (0.229, 0.224, 0.225)\n\ntrain_images = df_train.image_name.values.tolist()\ntrain_images = [os.path.join(training_data_path, i + \".png\") for i in train_images]\ntrain_targets = df_train.target.values\n\ntrain_aug = albumentations.Compose([\n    albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True),\n#     albumentations.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15),\n#     albumentations.Flip(p=0.5)\n])\n\ntrain_dataset = ClassificationLoader(\n    image_paths=train_images,\n    targets=train_targets,\n    resize=None,\n    augmentations=train_aug,\n)","1642daca":"valid_images = df_valid.image_name.values.tolist()\nvalid_images = [os.path.join(training_data_path, i + \".png\") for i in valid_images]\nvalid_targets = df_valid.target.values\n\nvalid_aug = albumentations.Compose([\n    albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True)\n])\n\nvalid_dataset = ClassificationLoader(\n    image_paths=valid_images,\n    targets=valid_targets,\n    resize=None,\n    augmentations=valid_aug,\n)","e5f44d3d":"test_data_path = melanoma_image_path + \"test\/\"\ndf_test = pd.read_csv(melanoma_path + \"test.csv\")\n\ntest_aug = albumentations.Compose([\n        albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True)\n])\n\ntest_images = df_test.image_name.values.tolist()\ntest_images = [os.path.join(test_data_path, i + \".png\") for i in test_images]\ntest_targets = np.zeros(len(test_images))\n\ntest_dataset = ClassificationLoader(\n    image_paths=test_images,\n    targets=test_targets,\n    resize=None,\n    augmentations=test_aug,\n)","d19f3ec5":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=9, padding=4)\n        self.conv3 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=7, padding=3)\n        self.conv5 = nn.Conv2d(in_channels=12, out_channels=18, kernel_size=5, padding=2)\n#         self.conv2 = nn.Conv2d(in_channels=6, out_channels=9, kernel_size=7, padding=3)\n#         self.conv4 = nn.Conv2d(in_channels=12, out_channels=15, kernel_size=5, padding=2)\n#         self.conv6 = nn.Conv2d(in_channels=18, out_channels=24, kernel_size=3, padding=1)\n        self.pool1 = nn.MaxPool2d(kernel_size=4, stride=4)\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.fc1 = nn.Linear(in_features=18*7*7, out_features=100)\n        self.fc2 = nn.Linear(in_features=100, out_features=20)\n        self.out = nn.Linear(in_features=20, out_features=2)\n        \n    def forward(self, x):\n        x = F.relu(self.pool1(self.conv1(x)))  # Layer 1\n        x = F.relu(self.pool1(self.conv3(x)))  # Layer 2\n        x = F.relu(self.pool2(self.conv5(x)))  # Layer 3\n        x = x.reshape(-1, 18*7*7)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.out(x)\n        \n        return x","345539c2":"shuffle=True\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\nparameters = OrderedDict(\n    batch_size=[100],\n    lr = [0.01],\n)\n\nparam_values = [v for v in parameters.values()]\nprint(param_values)","e337fbd1":"%%time\n\nfor batch_size, lr in product(*param_values):\n    \n    \n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n#     trainloader = DataLoader(dataset, batch_size=batch_size, num_workers=2, sampler = train_sampler)\n#     testloader = DataLoader(dataset, batch_size=batch_size, num_workers=2, sampler = valid_sampler)\n\n    net = Net().to(device)\n    optimizer = optim.Adam(net.parameters(), lr=lr)\n    criterion = nn.CrossEntropyLoss()\n\n    comment = f'melanoma batch_size={batch_size} lr={lr}'\n    print(comment)\n#     tb = SummaryWriter(comment=comment)\n#     tb_count=0\n\n    for epoch in range(4): \n        running_loss = 0.0\n        for i, data in enumerate(train_loader, 0):\n            inputs, labels = data['image'].to(device), data['targets'].to(device)\n            optimizer.zero_grad()\n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            if i % 50 == 49:   \n#                 tb_count += 1\n#                 tb.add_scalar('Running Loss', running_loss\/100, tb_count)\n                print('[%d, %5d] loss: %.5f' %(epoch + 1, i + 1, running_loss \/ 50))\n                running_loss = 0.0\n\n        if epoch % 2 == 1:\n            print('At the end of epoch %d' %(epoch+1))\n            correct = 0\n            total = 0\n            with torch.no_grad():\n                preds=[]\n                targets=[]\n                for data in train_loader:\n                    images, labels = data['image'].to(device), data['targets'].to(device)\n                    outputs = net(images)\n                    _, predicted = torch.max(outputs.data, 1)\n                    preds += list(predicted.cpu().detach().numpy().squeeze())\n                    targets += list(labels.cpu().detach().numpy().squeeze())\n                    total += labels.size(0)\n                    correct += (predicted == labels).sum().item()\n\n    #             tb.add_scalar('Train Accuracy', 100 * correct \/ total, epoch+1)\n            print('Accuracy of the network on the train images: %.3f %%' % (100 * correct \/ total))\n            print('Training Confusion Matrix:')\n            print(confusion_matrix(targets, preds))\n\n            preds=[]\n            targets=[]\n            for data in train_loader:\n                images, labels = data['image'].to(device), data['targets'].to(device)\n                outputs = net(images)\n                _, predicted = torch.max(outputs.data, 1)\n                preds += list(predicted.cpu().detach().numpy().squeeze())\n                targets += list(labels.cpu().detach().numpy().squeeze())\n                corrects = [i==j for (i,j) in zip(preds,targets)]\n            print('Accuracy of the network on train images: %.3f %%' % (100 * sum(corrects) \/ len(targets)))\n            print('Training Confusion Matrix:')\n            print(len(targets), len(preds), len(corrects), sum(corrects))\n            print(confusion_matrix(targets, preds))\n\n            preds=[]\n            targets=[]\n            with torch.no_grad():\n                for data in valid_loader:\n                    images, labels = data['image'].to(device), data['targets'].to(device)\n                    outputs = net(images)\n                    _, predicted = torch.max(outputs.data, 1)\n                    preds += list(predicted.cpu().detach().numpy().squeeze())\n                    targets += list(labels.cpu().detach().numpy().squeeze())\n                    total += labels.size(0)\n                    correct += (predicted == labels).sum().item()\n    #             tb.add_scalar('Test Accuracy', 100 * correct \/ total, epoch+1)\n            print('Accuracy of the network on validation images: %.3f %%' % (100 * correct \/ total))\n            print('Validation Confusion Matrix:')\n            print(confusion_matrix(targets, preds))\n\n            preds=[]\n            targets=[]\n            for data in valid_loader:\n                images, labels = data['image'].to(device), data['targets'].to(device)\n                outputs = net(images)\n                _, predicted = torch.max(outputs.data, 1)\n                preds += list(predicted.cpu().detach().numpy().squeeze())\n                targets += list(labels.cpu().detach().numpy().squeeze())\n                corrects = [i==j for (i,j) in zip(preds,targets)]\n            print('Accuracy of the network on the validation images: %.3f %%' % (100 * sum(corrects) \/ len(targets)))\n            print('Validation Confusion Matrix:')\n            print(len(targets), len(preds), len(corrects), sum(corrects))\n            print(confusion_matrix(targets, preds))\n\n\n#     tb.close()\n    print('Finished Training')","702ca096":"test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=200, shuffle=False, num_workers=4)\nwith torch.no_grad():\n    preds=[]\n    targets=[]\n    for data in train_loader:\n        images, labels = data['image'].to(device), data['targets'].to(device)\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        preds += list(predicted.cpu().detach().numpy().squeeze())\n        targets += list(labels.cpu().detach().numpy().squeeze())\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n# tb.add_scalar('Train Accuracy', 100 * correct \/ total, epoch+1)\nprint('Accuracy of the network on the train images: %d %%' % (100 * correct \/ total))\nprint(len(preds), len(targets))\nprint('Training Confusion Matrix:')\nprint(confusion_matrix(targets, preds))\n","5b2f06e0":"## CNN","e6bcb685":"## Creating Pytorch Train, Test and Validation Datasets","a83bf925":"## Training","ed616009":"Code has been borrowed from https:\/\/www.kaggle.com\/abhishek\/melanoma-detection-with-pytorch. Thanks to Abhishek!","774eac4d":"## Hyperparameters","92b77f76":"## Import Libraries"}}