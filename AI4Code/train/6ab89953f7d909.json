{"cell_type":{"c5e27ca6":"code","893b1edc":"code","f679e038":"code","3d2d2658":"code","e6bab10c":"code","b5a1a521":"code","c5f3d145":"code","2e65fd40":"code","4605adc4":"code","7a4d6a11":"code","12726dfa":"code","150e08b6":"code","1a8d59de":"code","3817bfcd":"code","23559a0b":"code","3d3bcd81":"code","f24e5b69":"code","0f0e45ad":"code","e45f946f":"code","231c4ab6":"code","aa662c89":"code","734e82f7":"code","d4316be6":"code","3f4aa675":"code","ed23599a":"code","d2282f4a":"code","186a37d0":"code","b7668886":"code","efee8f85":"code","3f425016":"code","48cbfc4e":"code","d8f30a7d":"code","4528f9db":"code","cac39a81":"code","68ea5686":"code","922021ec":"code","26b205f2":"code","26ea01d8":"markdown","263645a4":"markdown","9bdd5054":"markdown","94bfd1d2":"markdown","4484116c":"markdown","6d5b138c":"markdown","1bafdbbd":"markdown","fafb5cfb":"markdown","d7fbd8d4":"markdown","66651723":"markdown","cbef201f":"markdown","eaad241f":"markdown","9bb649b7":"markdown","7c825bf8":"markdown","c544f6c6":"markdown","b17d567a":"markdown","440c9ead":"markdown","61ef0443":"markdown","acc7b674":"markdown","cf3ac08d":"markdown","3cf75a15":"markdown","eb530312":"markdown","b2196b7c":"markdown","4d9aea78":"markdown","4265f9cd":"markdown"},"source":{"c5e27ca6":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom sklearn.svm import SVC\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_squared_log_error","893b1edc":"train_data = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')","f679e038":"train_data.info()","3d2d2658":"#Split the train_data as dtype : 'object'(train_data_object) and others\ndf_object = []\ndf_numberic = []\nfor i in range(len(train_data.columns)):\n    if train_data[train_data.columns[i]].dtype ==  'object':\n        df_object.append(train_data.columns[i])\n    else:\n        df_numberic.append(train_data.columns[i])\n\ntrain_data_object = train_data[df_object]\ntrain_data_numberic = train_data[df_numberic]\n\n#Fill NaN\ntrain_data_object = train_data_object.fillna('NO')\ntrain_data_numberic = train_data_numberic.fillna(0)\ntrain_data = pd.concat([train_data_object, train_data_numberic], axis = 1)","e6bab10c":"sns.set()\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\nfig.suptitle('The SalePrice analysis')\n\nsns.distplot(train_data['SalePrice'], ax = axes[0], norm_hist = True)\naxes[0].set_title('Distribution')\naxes[0].set_xlabel('SalePrice')\naxes[0].set_ylabel('Count')\n\n\nsns.boxplot(x = train_data['SalePrice'], ax = axes[1])\naxes[1].set_title('Boxplot')\naxes[1].set_xlabel('SalePrice')\n\n\nsns.scatterplot(y = train_data['SalePrice'],x = train_data.index, ax = axes[2])\naxes[2].set_title('Scatter')\naxes[2].set_ylabel('SalePrice')","b5a1a521":"fig, axes = plt.subplots(19, 2, figsize=(15, 80))\nfig.suptitle('The numeric feature')\nfor i in range(19):\n    for j in range(2):\n        sns.regplot(x = train_data_numberic[train_data_numberic.columns[2*i + j]], y = train_data_numberic['SalePrice'], ax = axes[i, j])","c5f3d145":"plt.figure(figsize = (20 , 20))\nsns.heatmap(train_data_numberic.corr()[(train_data_numberic.corr() >= 0.5) | (train_data_numberic.corr() <= - 0.5)], annot = True, center = 0)","2e65fd40":"highcor_columns = []\nfor i in pd.DataFrame(train_data_numberic.corr()[train_data_numberic.corr() >= 0.5]['SalePrice']).dropna().index:\n    highcor_columns.append(i)\nsns.pairplot(train_data_numberic.corr()[highcor_columns])","4605adc4":"sns.set()\nfig, axes = plt.subplots(1, 5, figsize=(25, 5))\nfig.suptitle('The highcor_columns')\nfor i in range(5):\n    sns.scatterplot(x = train_data[highcor_columns[i]], y = train_data['SalePrice'], ax = axes[i])\n    sns.regplot(x = train_data[highcor_columns[i]], y = train_data['SalePrice'], ax = axes[i], color = 'r')\n    axes[i].set_title(f'{highcor_columns[i]}')\n    axes[i].set_xlabel(f'{highcor_columns[i]}')\n    axes[i].set_ylabel('SalePrice')\nfig, axes = plt.subplots(1, 5, figsize=(25, 5))\nfig.suptitle('The highcor_columns')\nfor i in range(5):\n    sns.scatterplot(x = train_data[highcor_columns[i+5]], y = train_data['SalePrice'], ax = axes[i])\n    sns.regplot(x = train_data[highcor_columns[i+5]], y = train_data['SalePrice'], ax = axes[i], color = 'g')\n    axes[i].set_title(f'{highcor_columns[i+5]}')\n    axes[i].set_xlabel(f'{highcor_columns[i+5]}')\n    axes[i].set_ylabel('SalePrice')","7a4d6a11":"train_data_object['SalePrice'] = train_data_numberic['SalePrice']\ntrain_data_object['MSSubClass'] = train_data_numberic['MSSubClass'].apply(str)\nfig, axes = plt.subplots(9, 5, figsize=(30, 80))\nfig.suptitle('The object feature')\nfor i in range(9):\n    for j in range(5):\n        sns.boxplot(x = train_data_object[train_data_object.columns[5*i + j]], y = train_data_object['SalePrice'], ax = axes[i, j])\ntrain_data_object = train_data_object.drop(columns = ['SalePrice'])","12726dfa":"train_data_numberic = train_data_numberic.drop(columns = ['Id'])\ntrain_data_numberic['TotalFlrSF'] = train_data_numberic['1stFlrSF'] + train_data_numberic['2ndFlrSF']\ntrain_data_object['MSSubClass'] = train_data_numberic['MSSubClass'].apply(str)\ntrain_data_object_dum = pd.get_dummies(train_data_object)\ntrain_data = pd.concat([train_data_object_dum, train_data_numberic], axis = 1)","150e08b6":"test_data = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\n\n#Split the test_data as dtype : 'object'(test_data_object) and others\ndf_object = []\ndf_numberic = []\nfor i in range(len(test_data.columns)):\n    if test_data[test_data.columns[i]].dtype ==  'object':\n        df_object.append(test_data.columns[i])\n    else:\n        df_numberic.append(test_data.columns[i])\n\ntest_data_object = test_data[df_object]\ntest_data_numberic = test_data[df_numberic]\n\n#Fill NaN\ntest_data_object = test_data_object.fillna('NO')\ntest_data_numberic = test_data_numberic.fillna(0)\ntest_data = pd.concat([test_data_object, test_data_numberic], axis = 1)\n\n#dummies!\ntest_data_object['MSSubClass'] = test_data_numberic['MSSubClass'].apply(str)\ntest_data_numberic = test_data_numberic.drop(columns = ['Id'])\ntest_data_numberic['TotalFlrSF'] = test_data_numberic['1stFlrSF'] + test_data_numberic['2ndFlrSF']\ntest_data_object_dum = pd.get_dummies(test_data_object)\ntest_data = pd.concat([test_data_object_dum, test_data_numberic], axis = 1)","1a8d59de":"train_columns = []\nfor i in train_data.columns:\n    train_columns.append(i)\n\nfor i in test_data.columns:\n    train_columns.append(i)\n\n#Unique in list\ncombine_columns = set(list(train_columns))","3817bfcd":"df_train = pd.DataFrame(train_data, columns = combine_columns)\ndf_train = df_train.fillna(0)","23559a0b":"df_test = pd.DataFrame(test_data, columns = combine_columns)\ndf_test = df_test.fillna(0).drop(columns = ['SalePrice'])","3d3bcd81":"df_train.head()","f24e5b69":"df_test.head()","0f0e45ad":"from sklearn.model_selection import train_test_split\n\ndata = df_train.drop(columns = 'SalePrice')\ntarget = np.log(df_train['SalePrice'])\n\n\nx_train, x_test, y_train, y_test = train_test_split(data, target, train_size = 0.8, random_state = 5)","e45f946f":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import Normalizer\nNormalize = StandardScaler()\nx_train = Normalize.fit_transform(x_train)\nx_test = Normalize.transform(x_test)","231c4ab6":"from sklearn.tree import DecisionTreeRegressor\nDTR = DecisionTreeRegressor(max_depth = 10, min_samples_leaf = 2, max_features = 250).fit(x_train, y_train)\ny_pred_DTR = DTR.predict(x_test)\nplt.scatter(np.exp(y_test), np.exp(y_pred_DTR))\nplt.plot([100000*x for x in range(0, 8)], [100000*x for x in range(0, 8)], color = 'r')\nplt.xlabel(\"Reality Prices\")\nplt.ylabel(\"Predicted prices\")\nplt.title('DecisionTreeRegressor')\nplt.show()\nplt.clf()","aa662c89":"from sklearn.ensemble import RandomForestRegressor\nRFR = RandomForestRegressor(max_depth = 3, n_estimators = 1500).fit(x_train, y_train)\ny_pred_RFR = RFR.predict(x_test)\nplt.scatter(np.exp(y_test), np.exp(y_pred_RFR))\nplt.plot([100000*x for x in range(0, 8)], [100000*x for x in range(0, 8)], color = 'r')\nplt.xlabel(\"Reality Prices\")\nplt.ylabel(\"Predicted prices\")\nplt.title('RandomFroestRegressor')\nplt.show()\nplt.clf()","734e82f7":"from sklearn.ensemble import GradientBoostingRegressor\nGBR = GradientBoostingRegressor(learning_rate=0.015, max_depth= 5,\n                                min_samples_leaf=1,n_estimators=300, random_state=2,subsample = 0.2).fit(x_train, y_train)\ny_pred_GBR = GBR.predict(x_test)\nplt.scatter(np.exp(y_test), np.exp(y_pred_GBR))\nplt.plot([100000*x for x in range(0, 8)], [100000*x for x in range(0, 8)], color = 'r')\nplt.xlabel(\"Reality Prices\")\n\nplt.ylabel(\"Predicted prices\")\nplt.title('GradientBoostingRegressor')\nplt.show()\nplt.clf()","d4316be6":"from sklearn.svm import SVR\nsvr = SVR(kernel = 'rbf', gamma = 'auto', C = 0.7, degree = 3, epsilon=0.05, coef0=20).fit(x_train, y_train)\ny_pred_svr = svr.predict(x_test)\nplt.scatter(np.exp(y_test), np.exp(y_pred_svr))\nplt.plot([100000*x for x in range(0, 8)], [100000*x for x in range(0, 8)], color = 'r')\nplt.xlabel(\"Reality Prices\")\nplt.ylabel(\"Predicted prices\")\nplt.title('SVM')\nplt.show()\nplt.clf()\n","3f4aa675":"from sklearn.neighbors import KNeighborsRegressor\nsns.set()\nKNN = KNeighborsRegressor(n_neighbors = 5, weights = 'distance').fit(x_train, y_train)\ny_pred_KNN = KNN.predict(x_test)\nplt.scatter(np.exp(y_test), np.exp(y_pred_KNN))\nplt.plot([100000*x for x in range(0, 8)], [100000*x for x in range(0, 8)], color = 'r')\nplt.xlabel(\"Reality\")\nplt.ylabel(\"Predicted\")\nplt.title('KNeighborsRegressor')\nplt.show()\nplt.clf()","ed23599a":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nmodel = Sequential()\nmodel.add(Dense(512, input_shape = (x_train.shape[1], ), activation = 'sigmoid'))\nmodel.add(Dense(256, activation = 'sigmoid'))\nmodel.add(Dense(64, activation = 'relu'))\nmodel.add(Dense(8, activation = 'sigmoid'))\nmodel.add(Dense(1))\nmodel.compile(loss = 'mse', optimizer = 'adam', metrics= 'mse')\nhistory = model.fit(x_train, y_train, batch_size = 16, epochs = 300 , validation_split= 0.2, verbose = 0)","d2282f4a":"import seaborn as sns\nsns.set()\ndf_history = pd.DataFrame(history.history)\nsns.lineplot(x = df_history.index, y = df_history.loss)","186a37d0":"sns.set()\ny_pred_DL = model.predict(x_test)\nplt.scatter(np.exp(y_test), np.exp(y_pred_DL))\nplt.plot([100000*x for x in range(0, 8)], [100000*x for x in range(0, 8)], color = 'r')\nplt.xlabel(\"Reality\")\nplt.ylabel(\"Predicted\")\nplt.title('Deep Learning')\nplt.show()\nplt.clf()","b7668886":"from numpy.ma.core import shape\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.metrics import mean_squared_error\ndef model_fit(x_train, x_test, y_train, y_test):\n\n  from sklearn.ensemble import RandomForestRegressor\n  RFR = RandomForestRegressor(max_depth = 3, n_estimators = 1500).fit(x_train, y_train)\n\n  from sklearn.tree import DecisionTreeRegressor\n  DTR = DecisionTreeRegressor(max_depth = 10, min_samples_leaf = 2, max_features = 250).fit(x_train, y_train)\n\n  from sklearn.svm import SVR\n  svr = SVR(kernel = 'rbf', gamma = 'auto', C = 0.7, degree=4, epsilon=0.002, coef0=20).fit(x_train, y_train)\n  \n  from sklearn.ensemble import GradientBoostingRegressor \n  GBR = GradientBoostingRegressor(learning_rate=0.015, max_depth=3,\n                                min_samples_leaf=1,n_estimators=1500, random_state=2,subsample = 0.2).fit(x_train, y_train)\n  KNN = KNeighborsRegressor(n_neighbors = 5, weights = 'distance').fit(x_train, y_train)\n  \n  from tensorflow.keras.models import Sequential\n  from tensorflow.keras.layers import Dense, Dropout\n  model = Sequential()\n  model.add(Dense(512, input_shape = (x_train.shape[1], ), activation = 'sigmoid'))\n  model.add(Dense(256, activation = 'sigmoid'))\n  model.add(Dense(64, activation = 'relu'))\n  model.add(Dense(8, activation = 'sigmoid'))\n  model.add(Dense(1))\n  model.compile(loss = 'mse', optimizer = 'adam', metrics= 'mse')\n  history = model.fit(x_train, y_train, batch_size = 16, epochs = 300 , validation_split= 0.2, verbose = 0)\n    \n  return RFR, DTR, svr, GBR, KNN, model\n","efee8f85":"Model = model_fit(x_train, x_test, y_train, y_test)","3f425016":"ML_model = ['RandomForestRegressor', 'DecisionTreeRegressor', 'SVR-rbf', 'GradientBoostingRegressor','KNeighborsRegressor', 'DeepLearning']\nfor i in range(6):\n  plt.scatter(np.exp(y_test), np.exp(Model[i].predict(x_test)))\n  plt.plot([100000*x for x in range(0, 8)], [100000*x for x in range(0, 8)], color = 'r')\n  plt.xlabel(\"Reality Prices\")\n  plt.ylabel(\"Predicted prices\")\n  plt.title(ML_model[i])\n  plt.show()\n  plt.clf()","48cbfc4e":"sns.set()\nfrom sklearn.metrics import r2_score\nR_square_num = []\nfor i in range(6):\n  R_square = r2_score(y_test, Model[i].predict(x_test))\n  R_square_num.append(R_square)\nplt.figure(figsize = (10, 10))\nplt.xlabel('R Square Score')\nplt.ylabel('Model Type')\nplt.title('The R Square Score Comparsion')\nsns.barplot(x = R_square_num, y = ML_model)","d8f30a7d":"sns.set()\nfrom sklearn.metrics import mean_squared_error\nmse_num = []\nfor i in range(6):\n  mse = mean_squared_error(y_test, Model[i].predict(x_test))\n  mse_num.append(mse)\nplt.figure(figsize = (10, 10))\nplt.xlabel('mean_square_error')\nplt.ylabel('Model Type')\nplt.title('The mean_square_error Comparsion')\nsns.barplot(x = mse_num, y = ML_model)","4528f9db":"Model[3].score(x_test, y_test)","cac39a81":"df_test = Normalize.transform(df_test)\nprediction_price = np.exp(Model[3].predict(df_test))","68ea5686":"submi = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\nsubmi['SalePrice'] = prediction_price\nsubmi.to_csv('submission.csv', index=False)","922021ec":"sns.set()\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\nfig.suptitle('The SalePrice analysis')\n\nsns.distplot(submi['SalePrice'], ax = axes[0], norm_hist = True)\naxes[0].set_title('Distribution')\naxes[0].set_xlabel('SalePrice')\naxes[0].set_ylabel('Count')\n\n\nsns.boxplot(x = submi['SalePrice'], ax = axes[1])\naxes[1].set_title('Boxplot')\naxes[1].set_xlabel('SalePrice')\n\n\nsns.scatterplot(y = submi['SalePrice'],x = submi.index, ax = axes[2])\naxes[2].set_title('Scatter')\naxes[2].set_ylabel('SalePrice')","26b205f2":"submi","26ea01d8":"## 6-1. DecisionTreeRegressor","263645a4":"## 4-1. Test_data","9bdd5054":"## 7-2 Score comparsion","94bfd1d2":"## 3.3 Object feature columns analysis","4484116c":"## 6-4. SVR-rbf ","6d5b138c":"# **1. Read the Data**","1bafdbbd":"## 5-1. Split the train_data as x_train , x_test, y_train, y_test \n\n### ->The target I decide transform target = np.log(df_train['SalePrice])","fafb5cfb":"# **2. Data preprocessing**","d7fbd8d4":"## 7-3 Mean Squared Error Comparsion","66651723":"## 2-1. Split the 'onject' columns and 'numberic'","cbef201f":"# **4. Create the Combine DataFrame for each train.csv and test.csv (important!! for same dimension)**","eaad241f":"## 7-1. Relative reality and prediction","9bb649b7":"## 6-2. RandomForestRegressor","7c825bf8":"# **5. Data Preprocessing**","c544f6c6":"# **6. Four Machine Learning Model**","b17d567a":"# **7. Model's Comparsion**","440c9ead":"# 8. Prediction the df_test -> Choose Model[3] = GradientBoostRegressor to predict","61ef0443":"## 6-6. Deep Learning","acc7b674":"## 4-2. Combine the train and test columns","cf3ac08d":"## 6-3. GradientBoostRegressor","3cf75a15":"## 3-1. Numberic feature columns analysis","eb530312":"## 6-5. KNeighborsRegressor","b2196b7c":"# 9. Show the prediction of distribution","4d9aea78":"## 3-2. Heatmap with cor > 0.5 numberic columns","4265f9cd":"#  **3. EDA**"}}