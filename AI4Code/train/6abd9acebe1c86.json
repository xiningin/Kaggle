{"cell_type":{"9a577616":"code","94e710cb":"code","b4ebfa76":"code","9373dec6":"code","d3a05c57":"code","caa58261":"code","a2bc364b":"code","224b097b":"code","498dfcf0":"code","a1c53543":"code","2665c576":"code","5ed8ff0a":"markdown","61085e80":"markdown","5870a031":"markdown","612dedaa":"markdown"},"source":{"9a577616":"# Import necessary library\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer","94e710cb":"train_df = pd.read_csv(\"..\/input\/30-days-of-ml\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/30-days-of-ml\/test.csv\")\ntrain_df.head()","b4ebfa76":"# Check unique value in category column.\n\ndef print_unique(df):\n    \"\"\"To print all the unique values of all category columns.\n    \n    Parameters:\n        df : Pandas DataFrame.\n            The DataFrame is printed.            \n    \"\"\"\n    category_col_list = df.select_dtypes(include=['object']).columns\n    for col in category_col_list:\n        print(\"Category Column: \" + col )\n        print(sorted(df[col].unique()))\n\nprint(\"Check unique value of training data.\")        \nprint_unique(train_df)\nprint(\"Check unique value of testing data.\") \nprint_unique(test_df)","9373dec6":"# All columns as feature excluded target column.\nX = train_df.drop(['target'], axis=1)\n\n# Using target column as y.\ny = train_df.target\n\n# Split 30% to be validation data set.\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=0)","d3a05c57":"# List column with using One-Hot encoding.\none_hot_col = ['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat8']\n\n# Apply one-hot encoder to each column with categorical data\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[one_hot_col]))\nOH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[one_hot_col]))\n\n# One-hot encoding removed index; put it back\nOH_cols_train.index = X_train.index\nOH_cols_valid.index = X_valid.index\n\n# Remove categorical columns (will replace with one-hot encoding)\nX_train = X_train.drop(one_hot_col, axis=1)\nX_valid = X_valid.drop(one_hot_col, axis=1)\n\n# Add one-hot encoded columns to numerical features\nX_train = pd.concat([X_train, OH_cols_train], axis=1)\nX_valid = pd.concat([X_valid, OH_cols_valid], axis=1)\n\nX_train","caa58261":"# List column with using Ordinal encoding.\nordinal_col = ['cat6', 'cat7', 'cat9']\n\n# Apply ordinal encoder to each column with categorical data\nordinal_encoder = OrdinalEncoder()\nX_train[ordinal_col] = ordinal_encoder.fit_transform(X_train[ordinal_col])\nX_valid[ordinal_col] = ordinal_encoder.transform(X_valid[ordinal_col])\n\nX_train","a2bc364b":"# Grid Parameter.\nparam_grid = { 'n_estimators': [400, 500],\n               'learning_rate': [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]}","224b097b":"# Define Model.\nmodel = XGBRegressor(n_jobs=4, tree_method = 'gpu_hist')\n\n# Define GridSearch.\nmy_search = GridSearchCV(model, scoring='neg_mean_squared_error', cv=5, param_grid=param_grid)\n\n# Fit GridSearch.\nmy_search.fit(X_train, y_train, early_stopping_rounds=10, eval_set=[(X_valid,y_valid)], verbose=False)","498dfcf0":"print(my_search.best_params_, my_search.best_score_)","a1c53543":"# Defind model.\nxgb_model = XGBRegressor(n_estimators=500, learning_rate=0.5, n_jobs=4, tree_method = 'gpu_hist')\n\n# Fit model.\nxgb_model.fit(X_train, y_train, \n             early_stopping_rounds=30, \n             eval_set=[(X_valid, y_valid)], \n             verbose=False)","2665c576":"X_test = test_df\n# Apply one-hot encoder to test data\nOH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[one_hot_col]))\nOH_cols_test.index = X_test.index\nX_test = X_test.drop(one_hot_col, axis=1)\nX_test = pd.concat([X_test, OH_cols_test], axis=1)\n\n# Apply ordinal encoder to each column with categorical data\nX_test[ordinal_col] = ordinal_encoder.transform(X_test[ordinal_col])\n\ntest_preds = xgb_model.predict(X_test)\n\noutput = pd.DataFrame({'id': test_df.id,\n                       'target': test_preds})\noutput.to_csv('submission.csv', index=False)","5ed8ff0a":"# 30 Days of ML - 3rd Notebook\n\nPrevious experiment:\n1. Try to use RandomForestRegressor with Continuous Features only. [1st experiment](https:\/\/www.kaggle.com\/suttipop\/30-days-of-ml-1st)\n2. Try to use XGBRegressor and add categorical features by using One-Hot and Ordinal Encoding. [2nd experiment](https:\/\/www.kaggle.com\/suttipop\/30-days-of-ml-2nd)\n\nThis experiment is try to use GridSearchCV to run with sevaral parameters.","61085e80":"### Transform Category Column\n1. One-Hot Encoding for 'cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat8'\n2. Ordinal Encoding for 'cat6', 'cat7', 'cat9'","5870a031":"### Experiment\nUsing GridSearchCV to try XGBRegressor with sevaral parameters.","612dedaa":"### Define Model\nResult of Grid show that learning_rate=0.05 and n_estimators=500 got the best score.\nDefine model with this parameters. "}}