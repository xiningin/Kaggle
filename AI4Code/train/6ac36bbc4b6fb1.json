{"cell_type":{"6be91c08":"code","4bd2d9cb":"code","c166ed05":"code","43a8e19c":"code","926cd269":"code","978dfac3":"code","5f113fc2":"code","e79880b6":"code","a4cb7765":"code","27f540b8":"code","fc8a57f6":"code","d43fbd0d":"code","b450883d":"markdown","a775bd70":"markdown"},"source":{"6be91c08":"import os\nimport numpy as np\nimport pandas as pd\n\nSEED = 1380","4bd2d9cb":"df_train = pd.read_csv(\"..\/input\/tabular-playground-series-may-2021\/train.csv\")\n\ndata1 = df_train[df_train[\"target\"] == \"Class_1\"]\ndata2 = df_train[df_train[\"target\"] == \"Class_2\"]\ndata3 = df_train[df_train[\"target\"] == \"Class_3\"]\ndata4 = df_train[df_train[\"target\"] == \"Class_4\"]\n\nprint(\"Class_1:\", len(data1))\nprint(\"Class_2:\", len(data2))\nprint(\"Class_3:\", len(data3))\nprint(\"Class_4:\", len(data4))","c166ed05":"data1 = data1\ndata2 = data2.sample(n=len(data1), axis=0, random_state=SEED)\ndata3 = data3.sample(n=len(data1), axis=0, random_state=SEED)\ndata4 = data4.sample(n=len(data1), axis=0, random_state=SEED)\n\nprint(\"Class_1:\", len(data1))\nprint(\"Class_2:\", len(data2))\nprint(\"Class_3:\", len(data3))\nprint(\"Class_4:\", len(data4))\n\ndataset1 = pd.concat([data1, data2, data3, data4], axis=0).reset_index(drop=True)\nprint(\"dataset1 shape:\", dataset1.shape)","43a8e19c":"X = dataset1.drop([\"id\", \"target\"], axis=1)\ny = dataset1.target\n\nctoi = {\"Class_1\": 0, \"Class_2\": 1, \"Class_3\": 2, \"Class_4\": 3}\ny.replace(ctoi, inplace=True)\n\nX = np.array(X)\ny = np.array(y)\n\nprint(X.shape, y.shape)","926cd269":"df_test = pd.read_csv(\"..\/input\/tabular-playground-series-may-2021\/test.csv\")\nX_test = df_test.drop([\"id\"], axis=1)\nX_test = np.array(X_test)\n\nprint(X_test.shape)","978dfac3":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss\nimport xgboost as xgb","5f113fc2":"kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)","e79880b6":"params = {\n    \"tree_method\": \"gpu_hist\",\n    \"objective\": \"multi:softprob\",  # predict probability \/ \u78ba\u7387\u3092\u51fa\u529b\n    \"num_class\": 4,\n    \"eval_metric\": \"mlogloss\",\n    \"eta\": 0.006,\n    \"max_depth\": 4,\n    \"gamma\": 0.8481259071157187,\n    \"min_child_weight\": 0.5702096116340974,\n    \"colsample_bytree\": 0.2235888371622891,\n    \"subsample\": 0.6269307669980926,\n    \"lambda\": 0.05686076044791255,\n    \"alpha\": 9.971025438987308,\n    \"max_bin\": 900,\n    \"seed\": SEED\n}","a4cb7765":"preds = np.zeros((50000, 4))\nd_test = xgb.DMatrix(X_test)\n\nfor tr_id, vl_id in kf.split(X, y):\n    print(\"#\"*70)\n    \n    X_train, X_valid = X[tr_id, :], X[vl_id, :]\n    y_train, y_valid = y[tr_id], y[vl_id]\n\n    d_train = xgb.DMatrix(X_train, y_train)\n    d_valid = xgb.DMatrix(X_valid, y_valid)\n\n    model = xgb.train(params=params,\n                      dtrain=d_train,\n                      num_boost_round=100000,\n                      early_stopping_rounds=300,\n                      evals=[(d_train, \"train\"), (d_valid, \"valid\")],\n                      verbose_eval=1000)\n    pred = model.predict(d_test, ntree_limit=model.best_ntree_limit)\n    preds += pred\n    \npreds = preds \/ 5","27f540b8":"df_sub = pd.read_csv(\"..\/input\/tabular-playground-series-may-2021\/sample_submission.csv\")\ndf_sub[[\"Class_1\", \"Class_2\", \"Class_3\", \"Class_4\"]] = preds\n\ndf_sub.head()","fc8a57f6":"df_sub","d43fbd0d":"df_sub.to_csv(\"XGBoost_undersampling.csv\", index=False)","b450883d":"\u3010\u5b9f\u9a13\u3011  \n\u30a2\u30f3\u30c0\u30fc\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u305f\u30c7\u30fc\u30bf\u3067\u5b66\u7fd2\u30fb\u4e88\u6e2c\u3057\u3066\u307f\u305f\u3002  \n\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u306foptuna\u3067\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3057\u305f\u3002  \n  \npublic score: 1.3604  \n  \n\u4e88\u6e2c\u3055\u308c\u305f\u78ba\u7387\u306f\u3069\u306e\u30af\u30e9\u30b9\u3082\u307b\u307c\u540c\u3058\uff08\u3060\u3044\u305f\u30440.25\u4ed8\u8fd1\uff09<- df_sub\u53c2\u7167  \n\u30af\u30e9\u30b9\u3092\u4e88\u6e2c\u3059\u308b\u306e\u306f\u96e3\u3057\u3044\u306e\u3067\u306f\u306a\u3044\u304b\u3068\u601d\u3046\u3002  \n<- X\u304b\u3089y\u3092\u4e88\u6e2c\u3059\u308b\u3068\u3057\u3066\u3001y\u306e\u4e88\u6e2c\u306bX\u304c\u5168\u7136\u5bc4\u4e0e\u3057\u3066\u306a\u3044\u3002X\u3092\u4f7f\u3063\u3066\u3082\u5168\u7136\u4e88\u6e2c\u3067\u304d\u306a\u3044\u3002\u4e88\u6e2c\u3067\u304d\u3066\u3044\u306a\u3044\u3002","a775bd70":"Experiment  \ni tried to do undersampling.  \nhyper parameters were tuned by optuna for undersampled data.  \n  \npublic score: 1.36304  \n  \npredicted probabilities for each class are almost the same (about 0.25) <- df_sub  \ni suspect that it is difficult to predict class."}}