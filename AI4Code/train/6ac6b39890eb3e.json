{"cell_type":{"0f9cf20d":"code","f092bcde":"code","cfc20e62":"code","0aef9c91":"code","5dd3c199":"code","04fd7729":"code","b00bf525":"code","39252a24":"code","a67cce54":"code","ddb44cc5":"code","b1567c0d":"code","478a2475":"code","9e2997b1":"code","bd181506":"code","ec9fdec8":"code","c0637683":"code","ae348cc7":"code","3804b589":"code","8d3b0c24":"code","5dfd5409":"code","7fc360a3":"code","f1a6f51e":"code","cec268b9":"code","72d5dcd1":"code","fcbbb07b":"code","996162a5":"code","aca9d798":"code","ded4af3a":"code","ba8208a2":"code","8795a685":"code","8386f1e4":"code","58ec2de3":"code","4284f404":"code","7bb31efa":"code","dfd85fc7":"code","204b50f4":"code","3877b803":"code","a1f37b93":"code","74b79c85":"code","11eaf7a1":"code","8ec722b1":"code","d78ba88d":"code","145a1e78":"code","047fd5fd":"code","7c9c215b":"code","75c17512":"code","e974ec08":"code","7dc00a54":"code","08491ac0":"code","882afa31":"code","d2cb776d":"code","f69b062e":"code","398a6e64":"markdown","a5ba64cc":"markdown","790552b4":"markdown","c5eb3a1d":"markdown","82f9d046":"markdown","8dff8dd9":"markdown","f1b634a1":"markdown","3aff489a":"markdown","0642006f":"markdown","f36a95a2":"markdown","0f7e94aa":"markdown","a0c7f543":"markdown","1bfc8f5c":"markdown","a053c412":"markdown","5feed09a":"markdown","38b04828":"markdown","43cd857e":"markdown","571d7328":"markdown","81e18f97":"markdown","f764fca8":"markdown","8d766b03":"markdown","0f203bc9":"markdown","4d5c980b":"markdown","a936dd00":"markdown","a0fb0ea6":"markdown","5e8b2781":"markdown","535e1b25":"markdown","ec059086":"markdown","e999c366":"markdown","be88b948":"markdown","b46ef0d5":"markdown","d817283e":"markdown"},"source":{"0f9cf20d":"import pandas as pd\nfrom pandas import DataFrame\nfrom pandas.plotting import scatter_matrix\nimport matplotlib.pyplot as plt\nfrom matplotlib import rcParams\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.colors import n_colors\nimport numpy as np\nimport seaborn as sns\nimport pandas_profiling\n%matplotlib inline\nfrom matplotlib import rc\nimport scipy.stats","f092bcde":"newyork = pd.read_csv(\"\/kaggle\/input\/new-york-city-airbnb-open-data\/AB_NYC_2019.csv\") #reading the file","cfc20e62":"newyork.head(50)","0aef9c91":"newyork.shape","5dd3c199":"newyork.columns","04fd7729":"newyork.info()","b00bf525":"newyork.nunique(axis=0)","39252a24":"newyork.describe()","a67cce54":"newyork.neighbourhood_group.unique()","ddb44cc5":"newyork.room_type.unique()","b1567c0d":"newyork.neighbourhood.unique()","478a2475":"newyork.isnull().sum()","9e2997b1":"newyork.fillna({'name':\"NoName\"}, inplace=True)\nnewyork.fillna({'host_name':\"NoName\"}, inplace=True)","bd181506":"last_review = newyork.last_review\npercent_last_review = (last_review.isnull().sum()\/(len(newyork)*1.0))*100\npercent_last_review","ec9fdec8":"newyork.drop(['last_review','reviews_per_month'], axis=1, inplace=True)","c0637683":"newyork.isnull().sum()","ae348cc7":"sns.distplot(newyork['price'])","3804b589":"np.mean(newyork['price'])","8d3b0c24":"np.std(newyork['price'])","5dfd5409":"np.median(newyork['price'])","7fc360a3":"z_score_price = np.abs(scipy.stats.zscore(newyork['price']))\nprice_outliers = newyork.iloc[np.where(z_score_price>3)]\nprice_outliers.sort_values(['price'])","f1a6f51e":"def get_lower_upper_bound(my_data):\n    # Get first and third quartile\n    q1 = np.percentile(my_data, 25)\n    q3 = np.percentile(my_data, 75)\n    \n    # Calculate Interquartile range\n    iqr = q3 - q1\n    \n    # Compute lower and upper bound\n    lower_bound = q1 - (iqr * 6)\n    upper_bound = q3 + (iqr * 6)\n    \n    return lower_bound, upper_bound","cec268b9":"def get_outliers_iqr(my_data):\n    lower_bound, upper_bound = get_lower_upper_bound(my_data)\n    # Filter data less than lower bound and more than upper bound\n    return my_data[np.where((my_data > upper_bound) |\n                            (my_data < lower_bound))]","72d5dcd1":"outliers_price = get_outliers_iqr(newyork['price'].values)\noutliers_price","fcbbb07b":"newyork = newyork[newyork['price'] < 815]","996162a5":"newyork = newyork[newyork['price']>0]","aca9d798":"sns.distplot(newyork['price'])","ded4af3a":"sns.distplot(newyork['minimum_nights'])","ba8208a2":"z_score_nights = np.abs(scipy.stats.zscore(newyork['minimum_nights']))\nnights_outliers = newyork.iloc[np.where(z_score_nights>3)]\nnights_outliers.sort_values(['minimum_nights'])","8795a685":"newyork = newyork[newyork['minimum_nights'] < 999]","8386f1e4":"sns.distplot(newyork['number_of_reviews'])","58ec2de3":"newyork.loc[newyork['availability_365']==0,:]","4284f404":"newyork.shape","7bb31efa":"newyork.describe()","dfd85fc7":"sub_set = newyork[['price','availability_365','minimum_nights','number_of_reviews','longitude','latitude']]\nsns.pairplot(sub_set)","204b50f4":"sns.set(rc={'figure.figsize':(8,8)})\nhosts = newyork.host_id.value_counts().head(10)\nhosts\nfig = hosts.plot(kind='bar')\nfig.set_title(\"Busiest top 10 host\")\nfig.set_xlabel(\"Host Ids\")\nfig.set_ylabel(\"Counts\")","3877b803":"\nprint(newyork['neighbourhood_group'].value_counts())\nsns.countplot(x='neighbourhood_group',data=newyork,palette='viridis')\nplt.title('neightbourhood groups')","a1f37b93":"newyork.loc[newyork['host_id'] == 219517861,'neighbourhood_group'].values #Manhattan\nnewyork.loc[newyork['host_id'] == 107434423 ,'neighbourhood_group'].values #Manhattan\/Brooklyn\nnewyork.loc[newyork['host_id'] == 30283594  ,'neighbourhood_group'].values #Manhattan\nnewyork.loc[newyork['host_id'] == 12243051   ,'neighbourhood_group'].values #Manhattan\nnewyork.loc[newyork['host_id'] == 137358866   ,'neighbourhood_group'].values #Manhattan\/Queens\/Brooklyn\nnewyork.loc[newyork['host_id'] == 16098958   ,'neighbourhood_group'].values ##Manhattan\nnewyork.loc[newyork['host_id'] == 61391963   ,'neighbourhood_group'].values #Manhattan\nnewyork.loc[newyork['host_id'] == 22541573   ,'neighbourhood_group'].values #Manhattan\/Brooklyn\nnewyork.loc[newyork['host_id'] == 200380610   ,'neighbourhood_group'].values #Manhattan\nnewyork.loc[newyork['host_id'] == 1475015   ,'neighbourhood_group'].values  #Manhattan","74b79c85":"# top 10 neighborhoods with most number of listings per each neighbourhood group\nlisting_per_neighborhoodgroup = newyork.groupby(['neighbourhood_group','neighbourhood'],sort=False)['id'].agg([('count','count')]).reset_index().sort_values(by=['neighbourhood_group','count'],ascending=[True,False])\ntop_10 = listing_per_neighborhoodgroup.groupby(['neighbourhood_group']).apply(lambda x: x.nlargest(10,'count'))\nfig,axes = plt.subplots(nrows=1,ncols=3,sharey=True,figsize=(18,6))\nfig.suptitle('Top 10 neighborhoods per following three neighbourhood group', fontsize=16)\nfor ax in fig.axes:\n    plt.sca(ax)\n    plt.xticks(rotation=90)\nsns.barplot(x='neighbourhood',y='count',data=top_10[top_10['neighbourhood_group']=='Manhattan'],ax=axes[0],palette='viridis')\naxes[0].set_title('Manhattan')\nsns.barplot(x='neighbourhood',y='count',data=top_10[top_10['neighbourhood_group']=='Brooklyn'],ax=axes[1],palette='viridis')\naxes[1].set_title('Brooklyn')\nsns.barplot(x='neighbourhood',y='count',data=top_10[top_10['neighbourhood_group']=='Queens'],ax=axes[2],palette='viridis')\naxes[2].set_title('Queens')","11eaf7a1":"print(newyork['room_type'].value_counts())\nsns.countplot(x='room_type',data=newyork,palette='viridis')\nplt.title('Different room types')","8ec722b1":"neighbourhood_roomtype = newyork.groupby(by=['neighbourhood','room_type'],sort=False)['id'].agg([('count','count')]).reset_index().sort_values(by='count',ascending=False)\n\nlist = ['Bedford-Stuyvesant','Williamsburg','Bushwick','Crown Heights','Greenpoint','East Flatbush','East Village','Flatbush','Prospect-Lefferts Gardens','Clinton Hill','Park Slope','Harlem','Upper East Side','Upper West Side',\n        'Midtown','East Village','East Harlem','Chelsea','Financial District','Washington Heights','Astoria','Flushing','Long Island City','Ridgewood','Sunnyside','Ditmars Steinway','Elmhurst','Woodside','East Elmhurst','Hell\\'s Kitchen']\nneightbourhood_roomtype_top_30 = neighbourhood_roomtype[neighbourhood_roomtype.neighbourhood.str.contains('|'.join(list))]\n\npivot_df = neightbourhood_roomtype_top_30.pivot(index='neighbourhood', columns='room_type', values='count')\npivot_df\ncolors = [\"#8B0A50\", \"#EE1289\",\"#1E90FF\"]\n\npivot_df.loc[:,['Entire home\/apt','Private room', 'Shared room']].plot.barh(stacked=True, color=colors, figsize=(10,7))\n\n\n\n","d78ba88d":"neighbourhood_price = newyork.groupby(by=['neighbourhood'],sort=False)['price'].mean().reset_index().sort_values(by='price',ascending=False)\nneighbourhood_price\nneightbourhood_price_top_30 = neighbourhood_price[neighbourhood_price.neighbourhood.str.contains('|'.join(list))]\nneightbourhood_price_top_30\nfig = px.bar(neightbourhood_price_top_30,  x='neighbourhood', y='price',text='price')\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\nfig.show()","145a1e78":"price = newyork[newyork.price < 1000]\nplt.figure(figsize=(20,10))\n\n# The plot\nsns.boxplot(x = 'neighbourhood_group',\n            y = 'price', data = price, palette = \"viridis\", saturation = 1, width = 0.9, fliersize=4, linewidth=2)\n\n# Make pretty\nplt.title('Price distribution of neighbourhood_group', fontsize = 20)\nplt.xlabel('Neighbourhood_group', fontsize = 15)\nplt.ylabel('Price', fontsize = 15)\nplt.xticks(fontsize = 15)\nplt.yticks(fontsize = 15)","047fd5fd":"Manhattan = price.loc[price['neighbourhood_group']=='Manhattan','price']\nlist_manhattan = Manhattan.values.tolist()\nlist_manhattan.sort()\nnp.mean(list_manhattan)","7c9c215b":"Brooklyn = price.loc[price['neighbourhood_group']=='Brooklyn','price']\nlist_brooklyn = Brooklyn.values.tolist()\nlist_brooklyn.sort()\nnp.mean(list_brooklyn)","75c17512":"Queens = price.loc[price['neighbourhood_group']=='Queens','price']\nlist_queens = Queens.values.tolist()\nlist_queens.sort()\nnp.mean(list_queens)","e974ec08":"Staten_Island = price.loc[price['neighbourhood_group']=='Staten Island','price']\nlist_staten_island = Staten_Island.values.tolist()\nlist_staten_island.sort()\nnp.mean(list_staten_island)","7dc00a54":"Bronx = price.loc[price['neighbourhood_group']=='Bronx','price']\nlist_bronx = Bronx.values.tolist()\nlist_bronx.sort()\nnp.mean(list_bronx)","08491ac0":"plt.figure(figsize=(10,6))\nsns.scatterplot(newyork.longitude,newyork.latitude,hue=newyork.availability_365)\nplt.ioff()","882afa31":"top_reviewed_listings=newyork.nlargest(10,'number_of_reviews')\ntop_reviewed_listings","d2cb776d":"reviews = newyork[newyork.number_of_reviews < 630]\nsns.scatterplot(reviews.longitude,reviews.latitude,hue=reviews.number_of_reviews)\nplt.ioff()","f69b062e":"price_avrg=top_reviewed_listings.price.mean()\nprint('Average price per night: {}'.format(price_avrg))","398a6e64":"**Highest number of reviews are 629 followed by 607,597,594,and 576. Ten Places with highest reviews has average price of 65.4 dollars per night.**","a5ba64cc":"**The columns with null values are name,host_name, last_review, and reviews_per_month.**","790552b4":"**From the above box plot we can say that Manhattan has the highest range of prices with average 174 dollars, after that Brooklyn comes with average 116 dollars. Queens and Staten Island have similar distribution and Bronx has lowest average that means it is the cheapest among all. Manhattan has highest value of Q1 that means it is the most expensive place.**\n\n**Now we are left with columns availability_365, lontitude, latitude, minimum_nights, and number_of_reviews.**\n\n**Let's see what can we do with out longitude and latitude. I would like map availabiliy_365 with logtitude and latitude.**","c5eb3a1d":"**We can say that all hosts are not available 365 days.**","82f9d046":"### 2) Cleaning the dataset\n\n**let's check missing data individually.**","8dff8dd9":"**We can see that Entire home\/apt and private room are in more demand than shared room.**\n\n**We have already seen the price scenario and found most of the price is under 1000.**\n\n**Now let's find out our top 30 neighbourhoods are using which roomtype.**","f1b634a1":"**Above information shows number of unique values of each coulmn.**\n","3aff489a":"**Now let's check distribution of all significant columns.**\n\n**Price is numerical continous variable. As we already know minimum and maximum value of price are 0 and 10000.\nAn outlier is a value which is abnormally high or low as comapred to other values in dataset.**","0642006f":"**Let's check for minimum_nights which seems numerical continuos variable.**","f36a95a2":"**Here I have trippled the value and multiplied it by IQR range to find upper and lower bound because the range of the price vary in extremes.**\n\n**The reasons for finding outliers in dataset are error in recording or corrupted during transferring\/loading.**\n**Many a times data might actually have those high and low values. They are true values reflecting abnormal patterns in dataset and we simply can't ignore them. I would like to consider this scenario here because prices can vary according areas also. But some prices such as 10000 seems unreal to me for one night.**\n\n**I am going to remove all 419 rows that we found during IQR outlier detection method and raws with price zero since its not possible to stay for free.**\n","0f7e94aa":"**Above categorical variables don't require any reclassification or changes. So, we are going to keep them as it is.**","a0c7f543":"**Column name suggest description of the place that host is providing. There are only 16 values missing from 48895 which means we cannot drop the entire coulmn. And, if we delete 16 rows with missing value of names we will lose host_id(which will help to indentify busiest hosts) associated with it. Besides, this coulmn is not significant for our analysis.**\n\n**Same applies to host_name. Since we are going to consider host_id instead of host_name, there is no point to delete the whole cloumn or rows with missing values. Another reason being the question of ethicality to use name when we already have id.**\n\n**So I will impute missing values with NoName for both columns.**","1bfc8f5c":"**In order to find out why these neighbourhoods have more traffic let's check room type and price.**","a053c412":"**I have noticed the issue with price, and availability. For example the minimum and maximum price are 0 and 10000. I will deal with that later.**\n\n**let's check the discrete value of some significant categorical variables to have general idea.**","5feed09a":"**We can see descritpive stastics of our all 10 numeric columns.**\n\n","38b04828":"**Now I have 48461 rows.**","43cd857e":"**The reason being why these hosts are busiest is they all have houses in busiest neighbourhood group Manhattan, Brooklyn,and Queens.**\n\n**Now let's dig deep and check what areas have more traffic in all three busiest neighbourhood group.**","571d7328":"**The reasons behind the traffic of these neighbourhood are their price range between 77 and 260 dollars and they are providing mostly prive room or entire home\/apt.**\n**Since we have seen the average price of 30 busiest neighbourhood, let's take one step back and check price distribution in our 5 neighbourhood_group.**","81e18f97":"**Since 2008, guests and hosts have used Airbnb to expand on traveling possibilities and present more unique, personalized way of experiencing the world.** \n\n**This dataset describes the listing activity and metrics in NYC, NY for 2019.**\n\n**I want to perform EDA by following steps:**\n\n**1) Understanding your variable**\n\n**2) Cleaning your dataset**\n\n**3) Analyzing relationship between variables**\n\n\n\n### 1) Understanding the variables\n\n**This step is necessary in order to check later whether your insights make sense or not. To do that we need to understand each variable of datset, it's type, it'shape, it's mean etc.**\n\n**First I will import all libraries and conduct some preliminary analysis.**","f764fca8":"**Again we found 311 rows as outliers by doing Zscore method. I know that these values are affected by mean since distribution is skewed towards right. If I use any method related to median then rows will be increased and we don't want to go towards data lose. The values 999, 1000, and 1250 for minimum nights requirement for booking seem pretty high. I would like to remove them as a part of outlier detection.**","8d766b03":"**Since our graph for price is skewed towards right, mean is greater than medin.**\n\n**Below I have tried to use Z-score to find outliers.**","0f203bc9":"**We can see some good distribution of hosts from te above graph. The top host has over 300 listings.**\n\n**In order to find out why these hosts are busiest, let's check in which neighbourhood they lies.**","4d5c980b":"**Dataset has 48895 rows and 15 coulmns. All the column names are mentioned above and easy to unerstand the meaning as per name suggests.**\n\n\n**Let's check the datatype and non-null values of every coulmn.**","a936dd00":"### 3)Analyzing relationship between variables\n\n**Let's have general idea of distribution of our variables.**","a0fb0ea6":"**The column number of reviews shows total reviews given to place. The range of reviews are between 0 to 600. It is completely understandable that reviews can be vary according to place and there is nothing we can do about skewness.**\n\n**Let's move to availability_365 which seems numerical discrete variable.**","5e8b2781":"#### Univariate and bivariate Analysis\n\n**Busiest hosts.**","535e1b25":"**We are succeded to find 388 outliers in price. Here the value of the price has vast range, so these highest and lowest values(outliers) can affect the value of mean and standard deviation and hence the value of z-score.** \n**In that case it is better to consider median becuase it does not affected by outliers. I have used IQR to find outliers in price.**","ec059086":"**Here we can see that more than 17000 records have availability_365 = 0. Availability_365 = 0 means that the listing is not available at all or in other words 0 days out of the year (365) which can mean two things: 1) At the moment of collecting data for this dataset, those hosts had their listing availability set to 0 or 'Not available' 2)Bad data.**\n**Besides there are more than 12500 records among 17428 rows that have availability_365 = 0 but have number_of_reviews greater than 0.**\n**Deleting 17428 may lead to dataloss. That is why I will keep these records.**\n","e999c366":"# EDA of New York city Airbnb","be88b948":"**Above number shows percentage of missing value in column. Columns last_review and reviews_per_month have same amount of missing values that means both columns have around 21% missing values. I want to delete the columns because of two reasons. First one is both are insignificant to our analysis and second is presence of column number_of_reviews which gives information about total reviews of given places.**","b46ef0d5":"**As we can see from the above graph that most of our top 30 neighbourhoods are providing either Entire home\/apt or private room. Now let's check what is average price in our top 30 neighbourhood.**","d817283e":"**We can see that Manahattan and Brooklyn seem busiest neightbourhood.**\n\n**Now let's check out top 10 busiest hosts lies in which neighbour hood.**"}}