{"cell_type":{"9a5ad066":"code","f6466868":"code","30ef16d0":"code","07536a09":"code","0e286e51":"code","237799e5":"code","7332e9f5":"code","ccec3943":"code","303c3592":"code","09ecd783":"code","735a75d6":"code","2197654d":"code","b09a5771":"code","c87bd4d2":"code","f911b83f":"code","abda191a":"code","bd99447f":"markdown","0a0621cb":"markdown","b026f3dc":"markdown","e299f9c1":"markdown","ba9c3c94":"markdown","f1a7a556":"markdown","b9c9fbe0":"markdown","80a98853":"markdown"},"source":{"9a5ad066":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","f6466868":"from IPython.display import Image\nImage(url=\"https:\/\/www.kdnuggets.com\/wp-content\/uploads\/rapidminer-knn-image1.jpg\")","30ef16d0":"df = pd.read_csv('\/kaggle\/input\/biomechanical-features-of-orthopedic-patients\/column_2C_weka.csv')\ndf","07536a09":"df.info()","0e286e51":"df.describe().T","237799e5":"df[\"class\"] = [ 1 if each == \"Abnormal\" else 0 for each in df[\"class\"]]\ndf","7332e9f5":"abnormal = df[df[\"class\"] == 1]\nnormal = df[df[\"class\"] == 0]\n\n# scatter plot\nplt.scatter(abnormal.sacral_slope,abnormal.pelvic_radius,color=\"red\",label=\"Abnormal\",alpha=0.5)\nplt.scatter(normal.sacral_slope,normal.pelvic_radius,color=\"blue\",label=\"Normal\",alpha=0.5)\nplt.xlabel(\"sacral_slope\")\nplt.ylabel(\"pelvic_radius\")\nplt.show()","ccec3943":"y = df[\"class\"].values\ny","303c3592":"x_data = df.drop([\"class\"],axis=1) # axis=1 for columns\nx_data","09ecd783":"# normalization: I represent the data to a value between 0 and 1 for more accurate processing.\nx = (x_data - np.min(x_data))\/(np.max(x_data) - np.min(x_data))\nx","735a75d6":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=1)","2197654d":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=3) # n_neighbors => key value\nknn.fit(x_train,y_train)\nprediction = knn.predict(x_test)","b09a5771":"prediction","c87bd4d2":"print(\"{} nn score: {} \".format(3,knn.score(x_test,y_test)*100))","f911b83f":"# find k value\nscore_list = []\n\nfor each in range(1,15):\n    knn2 = KNeighborsClassifier(n_neighbors=each)\n    knn2.fit(x_train,y_train)\n    score_list.append(knn2.score(x_test,y_test))\n    \nplt.plot(range(1,15),score_list)\nplt.xlabel(\"k values\")\nplt.ylabel(\"accuracy\")\nplt.show()","abda191a":"print(\"{} KNN score: {} \".format(13,knn.score(x_test,y_test)*100))","bd99447f":"# Train Test Split","0a0621cb":"1- Choose K value <br>\n2- Find the nearest data points in K <br>\n3- Calculate how many of the class nearest neighbors in K <br>\n4- Determine which class of point or data we tested belongs to","b026f3dc":"# Normalization","e299f9c1":"As can be seen in the graph, the most accurate value is the number 13. So we write the value 13 in the n_neighbors section.","ba9c3c94":"# KNN Algorithm\nK nearest neighbors is a simple algorithm that stores all available cases and classifies new cases based on a similarity measure (e.g., distance functions). KNN has been used in statistical estimation and pattern recognition already in the beginning of 1970's as a non-parametric technique.","f1a7a556":"First of all, we need to represent the class line with 1-0. For this, I assigned 0 to normal data and 1 to abnormal data.","b9c9fbe0":"I said an estimated 3. Here, a method can be used to find the n_neighbors value.","80a98853":"# KNN Model"}}