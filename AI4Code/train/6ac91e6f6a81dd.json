{"cell_type":{"ca6a11ea":"code","bda82669":"code","53cd28ba":"code","0bb873de":"code","e0df44f8":"code","e39bfc45":"code","7921c757":"code","83285abb":"code","b54390d3":"markdown","9d86c239":"markdown","2f8a7b3e":"markdown","cd68fad3":"markdown","906992a0":"markdown","bcf9d700":"markdown","51bcd84b":"markdown","501babcb":"markdown"},"source":{"ca6a11ea":"INPUT_CSV_FILE = \"..\/input\/All-seasons.csv\"\nOUTPUT_TEXT_FILE = \".\/vector.txt\"\nOUTPUT_JSON_FILE = \".\/vector.json\"\nprint(\"Ready\")\n# Any results you write to the current directory are saved as output.","bda82669":"import pandas as pd\n\nsouthpark_df = pd.read_csv(INPUT_CSV_FILE)\nsouthpark_df.info()","53cd28ba":"unique_characters = southpark_df.Character.unique()\nprint(\"Found \",len(unique_characters),\" unique characters\")\nprint(unique_characters)","0bb873de":"grouped_by_character = southpark_df.groupby(['Character']).count().reset_index()\nsorted_characters = grouped_by_character.sort_values('Line', ascending=False)\nsorted_characters.head(4)","e0df44f8":"CHARACTER_NAME = \"Cartman\"\ncharacter_lines = southpark_df.loc[southpark_df.Character == CHARACTER_NAME][\"Line\"]\nprint(character_lines.describe())\ncharacter_lines.head()","e39bfc45":"import string\nimport re\ndef tokenize(s) :\n    lower_case = s.lower();\n    without_punctuation = re.sub(r'[^\\w\\s]','',lower_case)\n    return without_punctuation.split()\n\ntokenized_lines = character_lines.apply(lambda row: tokenize(row))\ntokenized_lines.tail(4)","7921c757":"from gensim.models import Word2Vec\nmodel = Word2Vec(tokenized_lines, size=100, window=5, min_count=5, workers=4)\nmodel.wv.save_word2vec_format(OUTPUT_TEXT_FILE, binary=False)\nimport os\nprint(os.listdir('.\/'))\n\n","83285abb":"import json\ndef to_json(input, output): \n    f = open(input)\n    v = {\"vectors\": {}}\n    for line in f:\n        w, n = line.split(\" \", 1)\n        v[\"vectors\"][w] = list(map(float, n.split()))\n    with open(output, \"w\") as out:\n        json.dump(v, out)\n\nto_json(OUTPUT_TEXT_FILE, OUTPUT_JSON_FILE)\nimport os\nprint(os.listdir('.\/'))","b54390d3":"Then we parse the csv file and store it in a Pandas Dataframe.\nThe info methods gives us a small summary of the Dataframe","9d86c239":"**Creating the Word2Vec model from our tokenized lines**","2f8a7b3e":"**Tokenzing **\n\nNow we want to split sentences to an array of lower cased words, to do that we apply a lambda to the dataframe","cd68fad3":"In our ouput we now have a vector.json that we can download and use from anywhere. \n\nExample usage in this sandbox : https:\/\/codesandbox.io\/s\/32n4w2kmz5","906992a0":"Let's start with Eric Cartman and get all the lines he has said","bcf9d700":"**Creating word2vec models for SouthPark characters**\n\nWe start by defining the input and output locations.","51bcd84b":"Next we need to convert the text output to a json file","501babcb":"Too many characters, let's get how many lines each has and grab the top 4 most prolific characters"}}