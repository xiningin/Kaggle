{"cell_type":{"f749b8f2":"code","d6e12264":"code","3029a7bf":"code","f22e1d05":"code","7bde3530":"code","9cab660a":"code","9ff310b2":"code","570236df":"code","4ef799d4":"code","059f9251":"code","16e64dee":"code","772b26d4":"code","47e9e13b":"code","ee5ff7b4":"code","00929737":"code","e61ef42d":"code","65eb93fd":"code","0068c3f4":"code","ee50d003":"code","fd2cd8db":"code","beab488d":"code","bacfdfee":"code","1bbaa323":"code","9942f86e":"code","e285abca":"code","617e4ae4":"code","b4039902":"code","31f7a4d5":"markdown","b33a2191":"markdown","ac62688e":"markdown","5207fc18":"markdown","6ea5f140":"markdown","c55f1e80":"markdown","9c3d3593":"markdown","4269db1f":"markdown","8f2b96c6":"markdown","4b5bd8f4":"markdown","ffa889aa":"markdown","cf272183":"markdown","b53a264c":"markdown","55d3cf42":"markdown","9b949f1f":"markdown","2603ae24":"markdown","aa1ab8f6":"markdown","eaa4d758":"markdown","0322bdad":"markdown","f5156aae":"markdown","4469b759":"markdown","1ff245e9":"markdown","d3764990":"markdown","1d94b4f3":"markdown","e6b0d9eb":"markdown"},"source":{"f749b8f2":"\nimport os\nimport pickle\nfrom PIL import Image\n\n# classes relativas ao PyTorch\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\n\nfrom albumentations import (\n    Compose, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip\n)\nfrom albumentations.pytorch import ToTensorV2\n\nimport cv2\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\n","d6e12264":"seed = 42\nnp.random.seed(42)\ntorch.cuda.manual_seed_all(seed)","3029a7bf":"class Config:\n    img_train_path = '..\/input\/ranzcr-clip-catheter-line-classification\/train'\n    img_test_path = '..\/input\/ranzcr-clip-catheter-line-classification\/test'\n    \n    batch_size = 64\n    img_width= 256\n    img_height = 256\n    \n    target_cols = ['ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal',\n                   'NGT - Abnormal', 'NGT - Borderline', 'NGT - Incompletely Imaged', 'NGT - Normal',\n                   'CVC - Abnormal', 'CVC - Borderline', 'CVC - Normal', 'Swan Ganz Catheter Present']\n    \n    n_classes = len(target_cols)\n    n_workers = 8","f22e1d05":"class ImageDataset(Dataset):\n    \n    def __init__(self, df, mode):\n        super().__init__()\n        self.filenames = df['StudyInstanceUID'].values\n        self.labels = df[Config.target_cols].values\n        self.len = len(df)\n        self.transform = self.train_transforms() if mode == 'train' else self.valid_transforms() if mode == 'valid' else None\n        \n    def __getitem__(self, idx):\n        filename = self.filenames[idx]\n        filepath = f'{Config.img_train_path}\/{filename}.jpg'\n        image = cv2.imread(filepath)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        \n        label = torch.tensor(self.labels[idx]).float()\n        return image, label\n    \n    def __len__(self):\n        return self.len\n    \n    def train_transforms(self):\n        # transforma\u00e7\u00f5es usadas no treino\n        return Compose([\n            Resize(Config.img_width, Config.img_height),\n            RandomResizedCrop(Config.img_width, Config.img_height, scale=(0.85, 1.0)),\n            HorizontalFlip(p=0.5),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n\n    def valid_transforms(self):\n        # transforma\u00e7\u00f5es usadas em valida\u00e7\u00e3o\n        return Compose([\n            Resize(Config.img_width, Config.img_height),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])","7bde3530":"class SimpleModel(nn.Module):\n    def __init__(self, n_classes=Config.n_classes):\n        super(SimpleModel, self).__init__()\n        self.conv = nn.Sequential(\n            # first\n            nn.Conv2d(in_channels=3, out_channels=128, kernel_size=4, stride=4, padding=2),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            # second\n            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=2, stride=2, padding=2),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            # third\n            nn.Conv2d(in_channels=256, out_channels=128, kernel_size=2, stride=2, padding=2),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            # fourth\n            nn.Conv2d(in_channels=128, out_channels=64, kernel_size=2, stride=2, padding=2),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        self.avgpool = nn.AdaptiveAvgPool2d((4, 4))\n        self.dense = nn.Sequential(\n            nn.Flatten(),\n            #first\n            nn.Dropout(p=0.05),\n            nn.Linear(64*4*4, 512),\n            nn.ReLU(),\n            # second\n            nn.Dropout(p=0.1),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            # third\n            nn.Dropout(p=0.3),\n            nn.Linear(512, 128),\n            nn.ReLU(),\n            # fourth\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            # fifth\n            nn.Linear(64, 32),\n            nn.ReLU(),\n            # output\n            nn.Linear(32, n_classes),\n            nn.Sigmoid()\n        )\n        \n    \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.avgpool(x)\n        x = self.dense(x)\n        return x","9cab660a":"# useful paths\ncatherer_path = '\/kaggle\/input\/ranzcr-clip-catheter-line-classification'\ntrain_path = os.path.join(catherer_path,'train')\ntest_path = os.path.join(catherer_path,'test')","9ff310b2":"# train\ntrain_csv_path = os.path.join(catherer_path,'train.csv')\ntrain_df = pd.read_csv(train_csv_path)\n\nclasses = [col for col in train_df.columns if col not in ['StudyInstanceUID','PatientID']]\nprint(f'There are {len(classes)} to predict')\n\nprint(f\"Shape of train dataframe : {train_df.shape}\")\nprint(f\"check for null values: {train_df.isnull().sum().sum()}\")\n\n# test\ntest_csv_path = os.path.join(catherer_path,'sample_submission.csv')\ntest_df = pd.read_csv(test_csv_path)\ntest_filenames = test_df.StudyInstanceUID\n\nprint(f\"Shape of test dataframe : {test_df.shape}\")\nprint(f\"check for null values: {test_df.isnull().sum().sum()}\")","570236df":"train_df.head()","4ef799d4":"img_path = Config.img_train_path + '\/' + train_df['StudyInstanceUID'].iloc[0] + '.jpg'\nimg_example = Image.open(img_path)\nprint(f\"Image size = {img_example.size}\")\nplt.figure(figsize=(12,8))\nplt.imshow(img_example,cmap='Greys');","059f9251":"img_example_red = img_example.resize((Config.img_width, Config.img_height))\nplt.figure(figsize=(12,8))\nplt.imshow(img_example_red,cmap='Greys');","16e64dee":"frac = 0.8\nlim = True\nif lim:\n    red_train_df = train_df.sample(frac=frac)\nelse:\n    red_train_df = train_df.copy()\nprint(red_train_df.shape)","772b26d4":"n_min = 1000\ncount_classes = red_train_df[classes].sum()\next_train_df = [red_train_df]\nfor pred_class in classes:\n    if count_classes[pred_class] < n_min:\n        new_df = red_train_df[red_train_df[pred_class]==1].sample(n_min,replace=True)\n        ext_train_df.append(new_df)\n        \next_train_df = pd.concat(ext_train_df)\nprint(ext_train_df.shape)","47e9e13b":"plt.figure(figsize=(10,6))\ngraph = sns.barplot(x=classes,y=ext_train_df[classes].sum())\ngraph.set_xticklabels(graph.get_xticklabels(), rotation=90);","ee5ff7b4":"# Dividindo em treino e valida\u00e7\u00e3o\nX_train, X_valid = train_test_split(ext_train_df, test_size=0.2, shuffle=True)\nprint(f' X_train shape: {X_train.shape} and X_valid shape: {X_valid.shape}')","00929737":"train_dataset = ImageDataset(df=X_train, mode='train')\nvalid_dataset = ImageDataset(df=X_valid, mode='valid')\ntest_dataset = ImageDataset(df=test_df, mode='valid')\n\n# A classe DataLoader \u00e9 necess\u00e1ria para o carregamento dos batches\ntrain_dataloader = DataLoader(train_dataset, pin_memory=True, batch_size=Config.batch_size, num_workers=Config.n_workers, shuffle=True)\nvalid_dataloader = DataLoader(valid_dataset, pin_memory=True, batch_size=Config.batch_size, num_workers=Config.n_workers, shuffle=False)\ntest_dataloader = DataLoader(test_dataset, batch_size=Config.batch_size, num_workers=Config.n_workers, shuffle=False)","e61ef42d":"model = SimpleModel()\n# Nosso otimizador, necess\u00e1rio para o treinamento da rede, junto com a fun\u00e7\u00e3o de custo\noptimizer = torch.optim.AdamW(model.parameters())\nloss = nn.BCELoss()","65eb93fd":"train_history = []\nvalid_history = []\n\ndef train(model, loss, optimizer, train_dataloader, valid_dataloader, device='cuda', epochs=50):\n    for e in range(1, epochs+1):\n        for train_values, train_target in train_dataloader:\n            train_values, train_target = train_values.to(device), train_target.to(device)\n            # loop principal\n            optimizer.zero_grad()   \n            model.train()\n            output = model(train_values.float())\n            loss_train = loss(output, train_target.float())\n            loss_train.backward()\n            optimizer.step()\n        \n        print(f'Epoch {e}: \\ttrain loss {loss_train.item():.2f}')\n        valid(model, loss, optimizer, valid_dataloader, device, epochs=1)\n        train_history.append(loss_train)\n            \ndef valid(model, loss, optimizer, valid_dataloader, device, epochs=50):\n    for e in range(1, epochs+1):\n        for val_values, val_target in valid_dataloader:\n            val_values, val_target = val_values.to(device), val_target.to(device)\n            \n            model.eval()\n            val_output = model(val_values.float())\n            loss_val = loss(val_output, val_target.float())\n        \n        valid_history.append(loss_val)\n        print(f'\\t\\tvalidation loss {loss_val.item():.2f}')\n            \ndef predict_probs(filenames, model, device='cuda'):\n    model.eval()\n\n    transform = test_dataset.valid_transforms()\n    \n    predictions = []\n    for filename in tqdm(filenames):\n        filepath = f'{Config.img_test_path}\/{filename}.jpg'\n        image = cv2.imread(filepath)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = transform(image=image)['image']\n        image = image.unsqueeze(0).to(device)\n        predictions.append(model(image).detach().cpu().numpy())\n    return predictions","0068c3f4":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\nprint(f'Current device is {device}')\nprint(model)","ee50d003":"# Treinamento do modelo\ntrain(model, loss, optimizer, train_dataloader, valid_dataloader, device, epochs=15)","fd2cd8db":"torch.save(model.state_dict(), 'simple_model.pt')","beab488d":"plt.plot(range(len(train_history)), train_history)\nplt.plot(range(len(valid_history)), valid_history)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.show();","bacfdfee":"predictions = predict_probs(test_filenames, model)\nprint(f'Predictions type = {type(predictions)}')\nprint(f'Predictions size = {len(predictions)}')\nwith open(\"preds.pkl\", \"wb\") as fp:\n    pickle.dump(predictions, fp)","1bbaa323":"# Carrega o arquivo pkl\n# with open('..\/input\/preds2\/preds.pkl', 'rb') as pickle_file:\n#     preds = pickle.load(pickle_file)","9942f86e":"# Exemplo de predi\u00e7\u00e3o\nprint(predictions[0])","e285abca":"preds_one_len = []\nfor pred in predictions:\n    preds_one_len.append(pred.squeeze())","617e4ae4":"pred_df = pd.DataFrame(columns=Config.target_cols, data=preds_one_len, index=test_df.index)\npred_df = pd.concat([test_df['StudyInstanceUID'],pred_df],axis=1)\npred_df","b4039902":"# Create the csv\npred_df.to_csv('submission.csv',index=False)","31f7a4d5":"# 1) M\u00f3dulos\/Classes\n\n## 1.1 Config class\nClasse que cont\u00e9m alguns par\u00e2metros de configura\u00e7\u00e3o, como tamanho da imagem, caminho (*path*) at\u00e9 a imagem, classes que queremos predizer.","b33a2191":"Observando o shape do dataset e valores nulos:","ac62688e":"Iremos carregar os dados direto do Kaggle.","5207fc18":"### Um ponto crucial para treinarmos a rede convolucional \u00e9 o uso da GPU\n\nPrecisamos verificar se a GPU est\u00e1 dispon\u00edvel, e posteriormente, passar o modelo para GPU (para que ele seja processado nessa unidade, e n\u00e3o na CPU)","6ea5f140":"### Criamos um DataFrame para submeter nossas predi\u00e7\u00f5es, com os respectivos nomes das categorias","c55f1e80":"# 4) Coletando um subset dos dados","9c3d3593":"# 3) Visualiza\u00e7\u00e3o dos dados","4269db1f":"Podemos verificar pelo shape da imagem que ela \u00e9 grande, e podemos diminuir as dimens\u00f5es dela sem muita perda de informa\u00e7\u00e3o.","8f2b96c6":"## 1.2 Dataset class\nPara carregarmos os dados para treinamento em Pytorch, \u00e9 recomendado a constru\u00e7\u00e3o de uma classe Dataset, que abstrai o carregamento dos dados, e permite que apliquemos transforma\u00e7\u00f5es dado o contexto (treino, valida\u00e7\u00e3o ou teste). Nela, \u00e9 necess\u00e1rio que implementemos os seguintes m\u00e9todos:\n- __init__\n- __getiitem__\n- __len__","4b5bd8f4":"# 5) Treino do modelo","ffa889aa":"Para garantir que a execu\u00e7\u00e3o use a mesma seed aleat\u00f3ria, configuramos para ser a mesma em qualquer execu\u00e7\u00e3o do notebook.","cf272183":"Observando um trecho do nosso conjunto:","b53a264c":"Verificando a curva de treino e de valida\u00e7\u00e3o:","55d3cf42":"# 6) Submiss\u00e3o","9b949f1f":"### Treinamento da rede\n\nAbaixo, temos a fun\u00e7\u00e3o com o loop de treinamento da nossa rede. \n\n1. Nele, fazemos um loop no dataloader, recuperando os dados de treino e o target. Aqui \u00e9 necess\u00e1rio chamar o m\u00e9todo .to(device) para passarmos os dados a GPU;\n2. Zeramos os gradientes previamente computados (necess\u00e1rio no Pytorch);\n3. Dizemos que o modelo est\u00e1 em modo de treinamento (```model.train()```);\n4. Passamos a imagem ao modelo (convertendo os valores para float) e temos o output;\n5. O output \u00e9 usado para calcularmos a loss, utilizando tamb\u00e9m nossos valores de target;\n6. Realizamos o backward propagation;\n7. Damos um passo em dire\u00e7\u00e3o a um m\u00ednimo local com o otimizador.\n\nUfa! Foram muitas etapas, mas s\u00e3o elas que possibilitam que nossa rede aprenda.\nTamb\u00e9m, ao fim do loop de treino, chamamos o fun\u00e7\u00e3o de valida\u00e7\u00e3o para verificar como a fun\u00e7\u00e3o de custo se comporta.","2603ae24":"# Introdu\u00e7\u00e3o\n\n### Notebook baseado em: [pierretihon notebook](https:\/\/www.kaggle.com\/pierretihon\/a-homemade-tensorflow-model).\n\n#### Esse notebook tem o prop\u00f3sito de mostrar como construir uma rede convolucional usando Pytorch.\n#### Iremos criar a rede, as classes necess\u00e1rias para carregar os dados, ver como utilizar uma GPU para o treinamento, e muito mais!\n\n\n#### O notebook est\u00e1 dividido em:\n\n1. M\u00f3dulos\/Classes\n    1. Config\n    2. Dataset\n    3. Modelo\n2. Carregamento dos dados\n3. Visualiza\u00e7\u00e3o dos dados\n4. Coletando um subset dos dados\n5. Treino do modelo\n6. Submiss\u00e3o\n\n","aa1ab8f6":"Para n\u00e3o precisarmos rodar o notebook todas as vezes para obter as sa\u00eddas do modelo, podemos salvar os pesos da rede.\nEm torch, a fun\u00e7\u00e3o save permita que fa\u00e7amos isso:","eaa4d758":"Agora o n\u00famero de classes em nosso DataFrame \u00e9:","0322bdad":"## 1.3 Model class\nAgora temos de construir a classe do modelo. Em Pytorch, o m\u00f3dulo ```torch.nn``` cont\u00e9m as abstra\u00e7\u00f5es de uma rede neural necess\u00e1rias para o aprendizado, como forward, ajuste dos pesos etc. Isso nos ajuda bastante, porque para definir uma rede, basta herdar o m\u00f3dulo em sua classe, e implementar 2 m\u00e9todos:\n\n- __init__\n- __forward__\n\n### Vamos a constru\u00e7\u00e3o da rede abaixo:\nEla \u00e9 uma rede neural convolucional bem simples com basicamente 3 pe\u00e7as: as convolu\u00e7\u00f5es, o average pooling ([mais informa\u00e7\u00f5es](https:\/\/pytorch.org\/docs\/stable\/generated\/torch.nn.AvgPool2d.html)) e a \u00faltima parte, uma rede densa.\n\nO average pooling at\u00e9 n\u00e3o seria necess\u00e1rio, j\u00e1 que a parte convolucional e a densa j\u00e1 iriam compor uma rede neural convolucional.\n\n#### Na parte convolucional\nS\u00e3o 4 camadas encadeadas de: Convolu\u00e7\u00e3o, fun\u00e7\u00e3o de ativa\u00e7\u00e3o (ReLU) e max pooling.\nVoc\u00ea pode encontrar mais informa\u00e7\u00f5es sobre essas opera\u00e7\u00f5es [aqui](https:\/\/cs231n.github.io\/convolutional-networks\/).\n\n#### Na parte densa\nS\u00e3o 5 camadas e uma de output, as 3 primeiras com [dropout](https:\/\/deeplearningbook.com.br\/capitulo-23-como-funciona-o-dropout\/), as duas \u00faltimas sem. Nossa sa\u00edda \u00e9 uma sigm\u00f3ide, com 11 classes.","f5156aae":"# Importando classes necess\u00e1rias","4469b759":"Podemos limitar a quantidade de dados utilizadas para treino, para acelerar o processo de verificar o comportamento do modelo:","1ff245e9":"Treinando o modelo:","d3764990":"Observando uma imagem:","1d94b4f3":"### Fazendo as predi\u00e7\u00f5es no conjunto de teste e salvando em formato pickle","e6b0d9eb":"# 2) Carregamento dos dados"}}