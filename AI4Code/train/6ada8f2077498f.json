{"cell_type":{"bec68dfb":"code","d6a31b77":"code","46e5677f":"code","0af35f34":"code","5781ee80":"code","0abd00e9":"code","2e7483c5":"code","f38afce0":"code","9a549619":"code","141f52a2":"code","c4141419":"code","5778de32":"code","defe1420":"code","5c228ee3":"code","2ae3671f":"code","79468ece":"code","04b80f62":"markdown","182f20d6":"markdown","ffb4929c":"markdown","54cf694b":"markdown","844cacf7":"markdown","58601650":"markdown","18b61f53":"markdown","ea9d9f41":"markdown","40cddfda":"markdown","512cc050":"markdown","63c7b5be":"markdown","9323757b":"markdown","2b9a0109":"markdown"},"source":{"bec68dfb":"import os\nimport cv2\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.models import Sequential\nfrom tensorflow.keras.optimizers import RMSprop, Adam\nfrom sklearn.metrics import confusion_matrix\nfrom tensorflow.keras import callbacks\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import classification_report, confusion_matrix","d6a31b77":"# Get the general directories\nprint(os.listdir('..\/input\/chest-xray-pneumonia\/chest_xray'))\n\n# the train, test, and val directories contain NORMAL and PNEUMONIA directories \ntrain_dir = '..\/input\/chest-xray-pneumonia\/chest_xray\/train\/'\ntest_dir = '..\/input\/chest-xray-pneumonia\/chest_xray\/test\/'\nval_dir = '..\/input\/chest-xray-pneumonia\/chest_xray\/val\/'\n\nprint(f'\\n{os.listdir(train_dir)}, {os.listdir(test_dir)}, {os.listdir(val_dir)}')","46e5677f":"# Useful train variables\ntrain_normal_path = '..\/input\/chest-xray-pneumonia\/chest_xray\/train\/NORMAL\/'\ntrain_normal_dir = os.listdir('..\/input\/chest-xray-pneumonia\/chest_xray\/train\/NORMAL')\nnormal_var_train = len(os.listdir('..\/input\/chest-xray-pneumonia\/chest_xray\/train\/NORMAL\/'))\n\ntrain_pneumonia_path = '..\/input\/chest-xray-pneumonia\/chest_xray\/train\/PNEUMONIA\/'\ntrain_pneumonia_dir = os.listdir('..\/input\/chest-xray-pneumonia\/chest_xray\/train\/PNEUMONIA')\npneumonia_var_train = len(os.listdir('..\/input\/chest-xray-pneumonia\/chest_xray\/train\/PNEUMONIA\/'))\n\n# Useful test variables\ntest_normal_path = '..\/input\/chest-xray-pneumonia\/chest_xray\/test\/NORMAL\/'\ntest_normal_dir = os.listdir('..\/input\/chest-xray-pneumonia\/chest_xray\/test\/NORMAL')\nnormal_var_test = len(os.listdir('..\/input\/chest-xray-pneumonia\/chest_xray\/test\/NORMAL\/'))\n\ntest_pneumonia_path = '..\/input\/chest-xray-pneumonia\/chest_xray\/test\/PNEUMONIA\/'\ntest_pneumonia_dir = os.listdir('..\/input\/chest-xray-pneumonia\/chest_xray\/test\/PNEUMONIA')\npneumonia_var_test = len(os.listdir('..\/input\/chest-xray-pneumonia\/chest_xray\/test\/PNEUMONIA\/'))\n\n# Useful val variables\nval_normal_path = '..\/input\/chest-xray-pneumonia\/chest_xray\/val\/NORMAL\/'\nval_normal_dir = os.listdir('..\/input\/chest-xray-pneumonia\/chest_xray\/val\/NORMAL')\nnormal_var_val = len(os.listdir('..\/input\/chest-xray-pneumonia\/chest_xray\/val\/NORMAL\/'))\n\nval_pneumonia_path = '..\/input\/chest-xray-pneumonia\/chest_xray\/val\/PNEUMONIA\/'\nval_pneumonia_dir = os.listdir('..\/input\/chest-xray-pneumonia\/chest_xray\/val\/PNEUMONIA')\npneumonia_var_val = len(os.listdir('..\/input\/chest-xray-pneumonia\/chest_xray\/val\/PNEUMONIA\/'))","0af35f34":"# Function that converts the images to \n\ndef create_df(var_control, path, direct):\n    df = pd.DataFrame() # When the function is called a new dataframe is created. \n    for i in range(var_control):\n        \n        img = cv2.imread(path + direct[i]) # Reads the image \n        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # converts the image to grayscale \n        img = cv2.resize(img, (100, 100)) # Resize the image to make plotting easier \n        img = -1 * img + 255 # Reverses the image's intensity, making it simpler to analyze medical images.\n        img = img\/255. # Normalizes the pixels\n        img = np.reshape(img, (10000, 1)) # Reshapes the 100 x 100 image into a 10000 x 1 array, making creating the dataframe easier \n        df[i] = pd.DataFrame(img, columns=[i]) # Creates the dataframe \n        \n    # Returns the transposed df \n    return df.T","5781ee80":"# Create train_df\npneumonia_train_df = create_df(pneumonia_var_train, train_pneumonia_path, train_pneumonia_dir)\npneumonia_train_df['label'] = 1\nnormal_train_df = create_df(normal_var_train, train_normal_path, train_normal_dir)\nnormal_train_df['label'] = 0\n# join the two datasets together\ntrain_df = pd.concat([normal_train_df, pneumonia_train_df])\n# Shuffle it\ntrain_df = train_df.sample(frac=1).reset_index(drop=True)\n\n\n# Create test_df\npneumonia_test_df = create_df(pneumonia_var_test, test_pneumonia_path, test_pneumonia_dir)\npneumonia_test_df['label'] = 1\nnormal_test_df = create_df(normal_var_test, test_normal_path, test_normal_dir)\nnormal_test_df['label'] = 0\n# join the two datasets together\ntest_df = pd.concat([normal_test_df, pneumonia_test_df])\n# Shuffle it\ntest_df = test_df.sample(frac=1).reset_index(drop=True)\n\n\n# Create val_df\npneumonia_val_df = create_df(pneumonia_var_val, val_pneumonia_path, val_pneumonia_dir)\npneumonia_val_df['label'] = 1\nnormal_val_df = create_df(normal_var_val, val_normal_path, val_normal_dir)\nnormal_val_df['label'] = 0\n# join the two datasets together\nval_df = pd.concat([normal_val_df, pneumonia_val_df])\n# Shuffle it\nval_df = val_df.sample(frac=1).reset_index(drop=True)","0abd00e9":"X_train = train_df.drop('label', axis=1)\ny_train = train_df.label\n\nX_test = test_df.drop('label', axis=1)\ny_test = test_df.label\n\nX_val = val_df.drop('label', axis=1)\ny_val = val_df.label\n\n# Reshape the data\nX_train = X_train.values.reshape(-1, 100, 100, 1)\nX_test = X_test.values.reshape(-1, 100, 100, 1)\nX_val = X_val.values.reshape(-1, 100, 100, 1)","2e7483c5":"y_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\ny_val = to_categorical(y_val)","f38afce0":"datagen = ImageDataGenerator(   featurewise_center=False,  # set input mean to 0 over the dataset\n                                samplewise_center=False,  # set each sample mean to 0\n                                featurewise_std_normalization=False,  # divide inputs by std of the dataset\n                                samplewise_std_normalization=False,  # divide each input by its std\n                                zca_whitening=False,  # dimesion reduction\n                                rotation_range=5,  # randomly rotate images in the range 5 degrees\n                                zoom_range = 0.1, # Randomly zoom image 10%\n                                width_shift_range=0.1,  # randomly shift images horizontally 10%\n                                height_shift_range=0.1,  # randomly shift images vertically 10%\n                                horizontal_flip=False,  # randomly flip images\n                                vertical_flip=False)  # randomly flip images\n\ndatagen.fit(X_train)\ndatagen.fit(X_test) # We are going to perform this method in the test_set as well, this will increase our accuracy and make the training process easier","9a549619":"model = Sequential([\n    layers.Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (100,100,1)),\n    layers.BatchNormalization(),\n    layers.MaxPool2D((2,2) , strides = 2 , padding = 'same'),\n    \n    layers.Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n    layers.MaxPool2D((2,2) , strides = 2 , padding = 'same'),\n    \n    layers.Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'),\n    layers.BatchNormalization(),\n    layers.MaxPool2D((2,2) , strides = 2 , padding = 'same'),\n    \n    layers.Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n    layers.MaxPool2D((2,2) , strides = 2 , padding = 'same'),\n    \n    layers.Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n    layers.MaxPool2D((2,2) , strides = 2 , padding = 'same'),\n    \n    layers.Flatten(),\n    layers.Dense(units = 128 , activation = 'relu'),\n    layers.Dropout(0.3),\n    layers.Dense(units = 2 , activation = 'softmax'),\n])\n\noptimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\nmodel.compile(optimizer = optimizer , loss = 'categorical_crossentropy' , metrics = ['accuracy'])","141f52a2":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3,  \n                                            factor=0.5, \n                                            min_lr=0.00001,\n                                            restore_best_weights=True,)\n\n\n# Fit the model\nhistory = model.fit(datagen.flow(X_train,y_train, batch_size = 5) ,epochs = 15, validation_data = datagen.flow(X_train,y_train, batch_size = 5),\n                    callbacks = [learning_rate_reduction])","c4141419":"history_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot()\nhistory_df.loc[:, ['accuracy', 'val_accuracy']].plot()","5778de32":"# Confusion matrix\n\nY_pred = model.predict(X_test)\n\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred, axis = 1) \n\n# Convert validation observations to one hot vectors\nY_true = np.argmax(y_test,axis = 1) \n\n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\n\nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01, cmap=\"Greens\", linecolor=\"gray\", fmt= '.1f', ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","defe1420":"# Classification report\n\nreport = classification_report(Y_true, Y_pred_classes)\nprint(report)","5c228ee3":"# Make predictions \n\ny_val_hat = model.predict(X_val)\ny_val_hat = np.argmax(y_val_hat, axis=1)\ny_val = np.argmax(y_val, axis=1)","2ae3671f":"# Plot the results \n\nplt.figure(figsize=(20,15))\nfor i,x in enumerate(X_val):\n    plt.subplot(4,4,i+1)\n    plt.imshow(x.reshape(100, 100), cmap='gray')\n    plt.axis('off')\n    plt.title('Predicted: {}, Real: {}'.format(y_val_hat[i], y_val[i]))","79468ece":"val_report = classification_report(y_val, y_val_hat)\nprint(val_report)","04b80f62":"#### The accuracy of our model depends on the run. Sometimes we get 94% of accuracy, sometimes 88% or even 66%","182f20d6":"## 5 - Convert the labels \n\nIn this step we are gonna convert our 1D array labels into a 2D array. If isn't done, our algorithm is not going to work properly and we will mess things up.","ffb4929c":"## 9 - Plot the results and confusion matrix","54cf694b":"## 3 - Create the train, test and val dataframes \n\nin this part, we are going to create the dataframes and assign a label: 1 for pneumonia and 0 for normal","844cacf7":"## 1 - Get the name of the directories \n\n\nThe first step we are going to take, is to get the name of the directories we are working on.","58601650":"## 2 - Create the function that is the heart of our code\n\n\nThe next step is to create a function that will convert the data contained in the folders into a dataframe. This function is slow but functional, that will suffice for now ","18b61f53":"All the directories contain \"PNEUMONIA\" and \"NORMAL\" folders. We will now create the path to the train, test and val folders and get access to the photos contained in them","ea9d9f41":"## 4 - Create and reshape the X and y variables\n\nHere we define and reshape the X and y variables for the 3 datasets.","40cddfda":"## 6 - Augment the dataset\n\nTo avoid the overfitting problem we augment artificially the dataset. By altering the training data with small transformations we are able to reproduce the variations occuring when someone is writing a digit.","512cc050":"\n#### When writing this kernel, I tried to use a different code to make predictions. Most of the kernels I took a look at used the \"flow_from_directory\" method. \n\n#### I did not invent the wheel in this kernel, my objective was to make something using the knowledge gained here, knowledge gathered studying your notebook guys. \n\n#### I'm immensely grateful to this platform, there is so much to learn here, so many excelent kernels and a lot of smart people.","63c7b5be":"## 7 - Create the CNN, define the optimizer and compile the model\n\n* The kernel size does not need to be 3 by 3 matrix. It can be 5 by 5 or 7 by 7.\n* kernels detects features like edges or convex shapes. Example, if out input is dog, feature detector can detect features like ear or tail of the dog.\n* feature map = conv(input image, feature detector). Element wise multiplication of matrices. feature map = convolved feature.\n* We create multiple feature maps bc we use multiple feature detectors(filters).\n* The ADAM optimizer will be used but we are gonna change the learning rate.","9323757b":"## 8 - Create an annealer and fit the model\n\nIn order to make the olgorithm converges to the global minimum of the loss fuction, we will define an annealing method to the learning rate, meaning that the LR will decrease during trainning reaching the global minimum instead of falling into the local minima.","2b9a0109":"## 10 - Test the model in the validation data"}}