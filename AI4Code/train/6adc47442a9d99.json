{"cell_type":{"201ab8c5":"code","0a9f129a":"code","aa3410c2":"code","1432c717":"code","fd08d641":"code","6aa75d65":"code","86ac7fd7":"code","0b11bf3d":"code","05eeff7a":"code","d835d126":"code","066cc47e":"code","c93f15f8":"code","9a35834e":"code","e434d6c4":"code","61d3d35b":"code","2d710ade":"code","48406894":"code","609bf746":"markdown","f1c9ab67":"markdown","b96c2263":"markdown","6025575b":"markdown","565c34c3":"markdown","fc3de832":"markdown","82e28b89":"markdown","4a0cafe6":"markdown","b1169852":"markdown"},"source":{"201ab8c5":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nimport json\n\nimport cv2\n\nfrom tensorflow import keras\nimport tensorflow as tf\nimport keras\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.losses import binary_crossentropy\nfrom keras.callbacks import Callback, ModelCheckpoint\nfrom keras.models import load_model\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf","0a9f129a":"train_df = pd.read_csv('..\/input\/sartorius-cell-instance-segmentation\/train.csv')\nprint(train_df.shape)\ntrain_df.head(4)","aa3410c2":"train_df=train_df.head(n=20000)\ntrain_df","1432c717":"def rle_decode(mask_rle, shape, color=1):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros((shape[0] * shape[1], shape[2]), dtype=np.float32)\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = color\n    return img.reshape(shape)\n\n\ndef build_masks(labels,input_shape, colors=True):\n    height, width = input_shape\n    if colors:\n        mask = np.zeros((height, width, 3))\n        for label in labels:\n            mask += rle_decode(label, shape=(height,width , 3), color=np.random.rand(3))\n    else:\n        mask = np.zeros((height, width, 1))\n        for label in labels:\n            mask += rle_decode(label, shape=(height, width, 1))\n    mask = mask.clip(0, 1)\n    return mask\n\ndef rle2maskResize(rle):\n    # CONVERT RLE TO MASK \n    if (len(rle)==0): \n        return np.zeros((256,256) ,dtype=np.uint8)\n    \n    height= 520\n    width = 704\n    mask= np.zeros( width*height ,dtype=np.uint8)\n\n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]-1\n    lengths = array[1::2]    \n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n    \n    return mask.reshape( (height,width), order='F' )[::2,::2]","fd08d641":"sample_filename = '0030fd0e6378'\nsample_image_df = train_df[train_df['id'] == sample_filename]\nsample_path = f\"..\/input\/sartorius-cell-instance-segmentation\/train\/{sample_image_df['id'].iloc[0]}.png\"\nsample_img = cv2.imread(sample_path)\nsample_rles = sample_image_df['annotation'].values\n\nsample_masks1=build_masks(sample_rles,input_shape=(520, 704), colors=False)\nsample_masks2=build_masks(sample_rles,input_shape=(520, 704), colors=False)\n\nfig, axs = plt.subplots(3, figsize=(20, 20))\naxs[0].imshow(sample_img)\naxs[0].axis('off')\n\naxs[1].imshow(sample_masks1)\naxs[1].axis('off')\n\naxs[2].imshow(sample_masks2)\naxs[2].axis('off')","6aa75d65":"class DataGenerator(tf.keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n                 base_path='..\/input\/sartorius-cell-instance-segmentation\/train',\n                 batch_size=32, dim=(256, 256), n_channels=3,\n                 n_classes=3, random_state=2019, shuffle=True):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.df = df\n        self.mode = mode\n        self.base_path = base_path\n        self.target_df = target_df\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.random_state = random_state\n        \n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) \/ self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n        \n        X = self.__generate_X(list_IDs_batch)\n        \n        if self.mode == 'fit':\n            y = self.__generate_y(list_IDs_batch)\n            return X, y\n        \n        elif self.mode == 'predict':\n            return X\n\n        else:\n            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n        \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.seed(self.random_state)\n            np.random.shuffle(self.indexes)\n    \n    def __generate_X(self, list_IDs_batch):\n        'Generates data containing batch_size samples'\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        \n        # Generate data\n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['id'].iloc[ID]\n            img_path = f\"{self.base_path}\/{im_name}.png\"\n            img = self.__load_grayscale(img_path)\n            \n            \n            # Store samples\n            X[i,] = img \n\n        return X\n    \n    def __generate_y(self, list_IDs_batch):\n        y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n        \n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['id'].iloc[ID]\n            image_df = self.target_df[self.target_df['id'] == im_name]\n            \n            rles = image_df['annotation'].values\n            masks = build_masks(rles,(520,704), colors=False)\n            masks = cv2.resize(masks, (256, 256))\n            #masks=masks.transpose(1,0)\n            masks=np.expand_dims(masks, axis=-1)\n            y[i, ] = masks\n\n        return y\n    \n    def __load_grayscale(self, img_path):\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        # resize image\n        dsize = (256, 256)\n        img = cv2.resize(img, dsize)\n        \n        img = img.astype(np.float32) \/ 255.\n        img = np.expand_dims(img, axis=-1)\n\n        return img\n    \n    def __load_rgb(self, img_path):\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = img.astype(np.float32) \/ 255.\n\n        return img","86ac7fd7":"BATCH_SIZE = 16\n\ntrain_idx, val_idx = train_test_split(\n    train_df.index, random_state=2019, test_size=0.2 # mask_count_df\n)\ntrain_generator = DataGenerator(\n    train_idx, \n    df=train_df,\n    target_df=train_df,\n    batch_size=BATCH_SIZE, \n    n_classes=3\n)\nval_generator = DataGenerator(\n    val_idx, \n    df=train_df,\n    target_df=train_df,\n    batch_size=BATCH_SIZE, \n    n_classes=3\n)\n\nplt.figure(figsize=(10,10))\nfor i in range(1):\n    images, mask = val_generator[i]\n    print(\"Dimension of image:\", images.shape)\n    print(\"Dimension of mask:\", mask.shape)\n    plt.imshow(images[0,:,:,0], cmap=\"gray\")\n    plt.imshow(mask[0,:,:,0],  alpha=0.6, cmap=\"Blues\")\n    plt.show()","0b11bf3d":"from keras import backend as K\nfrom keras.losses import binary_crossentropy\nimport tensorflow as tf\n\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef iou_coef(y_true, y_pred, smooth=1):\n  intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n  union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n  iou = K.mean((intersection + smooth) \/ (union + smooth), axis=0)\n  return iou\n\ndef dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2. * K.sum(intersection) + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1. - score\n\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(tf.cast(y_true, tf.float32), y_pred) + 0.5 * dice_loss(tf.cast(y_true, tf.float32), y_pred)","05eeff7a":"! pip install segmentation-models","d835d126":"! pip install git+https:\/\/github.com\/qubvel\/segmentation_models","066cc47e":"import segmentation_models as sm\nsm.set_framework('tf.keras')\nsm.framework()","c93f15f8":"from segmentation_models import Unet\nfrom segmentation_models.utils import set_trainable\n\n\nmodel = Unet('efficientnetb0',input_shape=(256, 256, 3), classes=3, activation='sigmoid',encoder_weights='imagenet')\n#inp = Input(shape=(512, 640, 1))\n#l1 = Conv2D(3, (1, 1))(inp) # map N channels data to 3 channels\n#out = base_model(l1)\n#model = Model(inp, out, name=base_model.name)\n\nmodel.compile(optimizer='adam', loss=bce_dice_loss,metrics=[dice_coef,iou_coef,'accuracy']) #bce_dice_loss binary_crossentropy\nmodel.summary()","9a35834e":"from keras.callbacks import Callback, ModelCheckpoint\ncheckpoint = ModelCheckpoint(\n    'model.h5', \n    monitor='val_loss', \n    verbose=0, \n    save_best_only=True, \n    save_weights_only=False,\n    mode='auto'\n)\n\n\nhistory = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    callbacks=[checkpoint],\n    use_multiprocessing=False,\n    workers=4,\n    epochs=1\n)","e434d6c4":"prediction=model.predect(train_generator)","61d3d35b":"hist_df = pd.DataFrame(history.history)\nhist_df.to_csv('history.csv')","2d710ade":"# PLOT TRAINING\nplt.figure(figsize=(15,5))\nplt.plot(range(history.epoch[-1]+1),history.history['val_iou_coef'],label='Val_iou_coef')\nplt.plot(range(history.epoch[-1]+1),history.history['iou_coef'],label='Trn_iou_coef')\nplt.title('IOU'); plt.xlabel('Epoch'); plt.ylabel('iou_coef');plt.legend(); \nplt.show()","48406894":"# PLOT TRAINING\nplt.figure(figsize=(15,5))\nplt.plot(range(history.epoch[-1]+1),history.history['val_dice_coef'],label='Val_dice_coef')\nplt.plot(range(history.epoch[-1]+1),history.history['dice_coef'],label='Trn_dice_coef')\nplt.title('DICE'); plt.xlabel('Epoch'); plt.ylabel('dice_coef');plt.legend(); \nplt.show()","609bf746":"## \u062a\u062d\u0645\u064a\u0644 \u0627\u0644  (U-Net)","f1c9ab67":"<a id=\"3.1\"><\/a>\n# <p style=\"background-color:#627D78;font-family:newtimeroman;color:#D5CABD;font-size:150%;text-align:center;border-radius:20px 60px;\">\u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0645\u0643\u062a\u0627\u0628\u0627\u062a \u0627\u0644\u0645\u0637\u0644\u0648\u0628\u0647<\/p>","b96c2263":"##### Referance:\n[here](https:\/\/www.kaggle.com\/ammarnassanalhajali\/sartorius-segmentation-keras-u-net-training)","6025575b":"## \u0628\u0646\u0627\u0621 \u0627\u0644\u0645\u0648\u062f\u064a\u0644","565c34c3":"<a id=\"3.1\"><\/a>\n# <p style=\"background-color:#627D78;font-family:newtimeroman;color:#D5CABD;font-size:150%;text-align:center;border-radius:20px 60px;\">\u0645\u0631\u062d\u0628\u0627 \u0628\u0643\u0645 \u062c\u0645\u064a\u0639\u0627<\/p>","fc3de832":"<a id=\"3.2\"><\/a>\n# <p style=\"background-color:#627D78;font-family:newtimeroman;color:#D5CABD;font-size:150%;text-align:center;border-radius:20px 60px;\">\u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0627\u0644 (U-NeT)<\/p>","82e28b89":"<a id=\"3.2\"><\/a>\n# <p style=\"background-color:#627D78;font-family:newtimeroman;color:#D5CABD;font-size:150%;text-align:center;border-radius:20px 60px;\">\u062a\u062f\u0631\u064a\u0628 \u0627\u0644\u0645\u0648\u062f\u064a\u0644<\/p>","4a0cafe6":"<a id=\"3.2\"><\/a>\n# <p style=\"background-color:#627D78;font-family:newtimeroman;color:#D5CABD;font-size:150%;text-align:center;border-radius:20px 60px;\">\u0642\u0631\u0627\u0621\u0647 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a<\/p>\n","b1169852":"<a id=\"3.2\"><\/a>\n# <p style=\"background-color:#627D78;font-family:newtimeroman;color:#D5CABD;font-size:150%;text-align:center;border-radius:20px 60px;\">\u0639\u0631\u0636 \u0627\u0644\u0635\u0648\u0631\u0647<\/p>"}}