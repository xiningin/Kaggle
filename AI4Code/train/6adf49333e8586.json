{"cell_type":{"21f59d90":"code","1be7b720":"code","4316f91e":"code","3bd9db57":"code","a5875701":"code","501c4daf":"code","aac9a7f2":"code","f6a6b2b4":"code","16744f18":"code","bfe083c4":"code","4f61077e":"code","efdf905b":"code","8b9931ee":"code","144949d1":"code","7adc4294":"code","37aed8ca":"code","91c2d8b9":"code","acd1a8a9":"code","15e09fba":"markdown","6aa8f5df":"markdown","ca2cfd92":"markdown","dd42b69d":"markdown","e5e3b7cf":"markdown","5f5301bb":"markdown","0f056851":"markdown","262df313":"markdown","42876c9e":"markdown","933d164e":"markdown","03eaec17":"markdown","8e2f4b46":"markdown","6621b97a":"markdown","f50b3b31":"markdown","6b32e9b7":"markdown","3cedc0f5":"markdown"},"source":{"21f59d90":"import os\nimport torch \nimport torchvision\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom torchvision import datasets\nfrom torch.utils.data import DataLoader\nfrom torchvision.utils import save_image\nfrom PIL import Image","1be7b720":"NUM_EPOCHS = 100\nLEARNING_RATE = 1e-3\nBATCH_SIZE = 128","4316f91e":"# image transformations\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])","3bd9db57":"trainset = datasets.MNIST(root='.\/data', train=True, download=True, transform=transform)\ntestset = datasets.MNIST(root='.\/data', train=False, download=True, transform=transform)\n\ntrainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\ntestloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=True)","a5875701":"print(trainset)","501c4daf":"print(trainset.classes)","aac9a7f2":"# utility functions\ndef get_device():\n    if torch.cuda.is_available():\n        device = 'cuda:0'\n    else:\n        device = 'cpu'\n    return device\n\ndef make_dir():\n    image_dir = 'MNIST_Images'\n    if not os.path.exists(image_dir):\n        os.makedirs(image_dir)\n\ndef save_decoded_image(img, epoch):\n    img = img.view(img.size(0), 1, 28, 28)\n    save_image(img, '.\/MNIST_Images\/linear_ae_image{}.png'.format(epoch))","f6a6b2b4":"class Autoencoder(nn.Module):\n    def __init__(self):\n        super(Autoencoder, self).__init__()\n\n        # encoder\n        self.enc1 = nn.Linear(in_features=784, out_features=256) # Input image (28*28 = 784)\n        self.enc2 = nn.Linear(in_features=256, out_features=128)\n        self.enc3 = nn.Linear(in_features=128, out_features=64)\n        self.enc4 = nn.Linear(in_features=64, out_features=32)\n        self.enc5 = nn.Linear(in_features=32, out_features=16)\n\n        # decoder \n        self.dec1 = nn.Linear(in_features=16, out_features=32)\n        self.dec2 = nn.Linear(in_features=32, out_features=64)\n        self.dec3 = nn.Linear(in_features=64, out_features=128)\n        self.dec4 = nn.Linear(in_features=128, out_features=256)\n        self.dec5 = nn.Linear(in_features=256, out_features=784) # Output image (28*28 = 784)\n\n    def forward(self, x):\n        x = F.relu(self.enc1(x))\n        x = F.relu(self.enc2(x))\n        x = F.relu(self.enc3(x))\n        x = F.relu(self.enc4(x))\n        x = F.relu(self.enc5(x))\n\n        x = F.relu(self.dec1(x))\n        x = F.relu(self.dec2(x))\n        x = F.relu(self.dec3(x))\n        x = F.relu(self.dec4(x))\n        x = F.relu(self.dec5(x))\n        return x","16744f18":"net = Autoencoder()\nprint(net)","bfe083c4":"criterion = nn.MSELoss()\noptimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)","4f61077e":"def train(net, trainloader, NUM_EPOCHS):\n    train_loss = []\n    for epoch in range(NUM_EPOCHS):\n        running_loss = 0.0\n        for data in trainloader:\n            img, _ = data\n            img = img.to(device)\n            img = img.view(img.size(0), -1)\n            optimizer.zero_grad()\n            outputs = net(img)\n            loss = criterion(outputs, img)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        loss = running_loss \/ len(trainloader)\n        train_loss.append(loss)\n        print('Epoch {} of {}, Train Loss: {:.3f}'.format(\n            epoch+1, NUM_EPOCHS, loss))\n\n        if epoch % 5 == 0:\n            save_decoded_image(outputs.cpu().data, epoch)\n\n    return train_loss\n\ndef test_image_reconstruction(net, testloader):\n     for batch in testloader:\n        img, _ = batch\n        img = img.to(device)\n        img = img.view(img.size(0), -1)\n        outputs = net(img)\n        outputs = outputs.view(outputs.size(0), 1, 28, 28).cpu().data\n        save_image(outputs, 'MNIST_reconstruction.png')\n        break","efdf905b":"# get the computation device\ndevice = get_device()\nprint(device)\n# load the neural network onto the device\nnet.to(device)\n\nmake_dir()\n\n# train the network\ntrain_loss = train(net, trainloader, NUM_EPOCHS)","8b9931ee":"plt.figure()\nplt.plot(train_loss)\nplt.title('Train Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.savefig('deep_ae_mnist_loss.png')","144949d1":"# test the network\ntest_image_reconstruction(net, testloader)","7adc4294":"Image.open('.\/MNIST_Images\/linear_ae_image0.png')","37aed8ca":"Image.open('.\/MNIST_Images\/linear_ae_image50.png')","91c2d8b9":"Image.open('.\/MNIST_Images\/linear_ae_image95.png')","acd1a8a9":"Image.open('.\/MNIST_reconstruction.png')","15e09fba":"Here, we will download the MNIST handwritten digits dataset.","6aa8f5df":"Visualizing the finally reconstructed images","ca2cfd92":"The below functions will:-\n1. Use the CUDA environment, if available, to accelarate the training process.\n2. Make a directory for MNIST images.\n3. Save the decoded images.","dd42b69d":"As we are going to use PyTorch model, so the below function will convert the input image data into tensor that is the basic unit of a PyTorch model.","e5e3b7cf":"Definning the training parameters.","5f5301bb":"# Deep Autoencoder in PyTorch to Reconstruct Images","0f056851":"# Visualizing reconstructed images at different instance","262df313":"# Defining training and image construction process","42876c9e":"In this implementation, we will demonstrate the implementation of a Deep Autoencoder in PyTorch for reconstructing images. This deep learning model will be trained on the MNIST handwritten digits and it will reconstruct the digit images after learning the representation of the input images. ","933d164e":"First of all, we will import all the reqired libraries","03eaec17":"Now, we will initialize the hyperparameters.","8e2f4b46":"Here, we will define the Autoencoder with all its components as a class and finally, we will instatitate this class to create an autoencoder object (net).","6621b97a":"# Visualizing the training performance","f50b3b31":"# Defining the Autoencoder","6b32e9b7":"# Testing the trained autoencoder to generate reconstructed images","3cedc0f5":"# Training the autoenocder to generate reconstructed images"}}