{"cell_type":{"11536229":"code","64d3d30e":"code","1931b5ae":"code","03adef88":"code","6d8223ba":"code","19c8a24d":"code","22a65a43":"code","111561ce":"code","7b347122":"code","6dcea9e5":"code","901d7589":"code","1f064178":"code","b8c3877b":"code","b56ec74d":"code","efe8b168":"code","d4ab9548":"markdown"},"source":{"11536229":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport sklearn\nimport seaborn as sns\nfrom sklearn import preprocessing\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score","64d3d30e":"adult = pd.read_csv(\"\/kaggle\/input\/adult-pmr3508\/train_data.csv\", skipinitialspace = True, na_values = \"?\")\nadult.set_index('Id',inplace=True)\nadult.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education.num', 'marital.status', 'occupation', \n                 'relationship', 'race', 'sex', 'capital.gain', 'capital.loss', 'hours.per.week', 'native.country', 'income']\ntreino = adult.dropna()\ntreino","1931b5ae":"testAdult = pd.read_csv(\"\/kaggle\/input\/adult-pmr3508\/test_data.csv\")\ntestAdult.set_index('Id',inplace=True)\nteste = testAdult.dropna()\nteste.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education.num', 'marital.status', 'occupation', \n                 'relationship', 'race', 'sex', 'capital.gain', 'capital.loss', 'hours.per.week', 'native.country']\nteste.shape","03adef88":"treino[\"native.country\"].value_counts().plot(kind=\"bar\")","6d8223ba":"del treino[\"native.country\"]\ndel teste[\"native.country\"]","19c8a24d":"treino","22a65a43":"\nsns.set\nsns.pairplot(treino, palette='dark')","111561ce":"xTreino = treino.iloc[:,0:14].apply(preprocessing.LabelEncoder().fit_transform)\nxTreino = xTreino[['age', 'workclass', 'fnlwgt', 'education', 'education.num', 'marital.status', 'occupation', 'relationship', \n                  'race', 'sex', 'capital.gain', 'capital.loss', 'hours.per.week']]\nyTreino = treino.income\n\nxTeste = teste.iloc[:,0:14].apply(preprocessing.LabelEncoder().fit_transform)","7b347122":"Tree = DecisionTreeClassifier(criterion = 'entropy', max_depth=15)\nxval_tree = cross_val_score(Tree, xTreino, yTreino, cv=15)\nTree.fit(xTreino, yTreino)\nyPred_Tree = Tree.predict(xTeste)\naccuracy_tree = xval_tree.mean()\naccuracy_tree","6dcea9e5":"id_index = pd.DataFrame({'Id' : list(range(len(yPred_Tree)))})\nincome = pd.DataFrame({'income' : yPred_Tree})\nresult = id_index.join(income)\nresult.to_csv(\"Tree.csv\", index = False)\nresult","901d7589":"Forest = RandomForestClassifier(n_estimators=700, criterion='entropy')\nxval_forest = cross_val_score(Forest, xTreino, yTreino, cv=15)\nForest.fit(xTreino, yTreino)\nyPred_Forest = Forest.predict(xTeste)\naccuracy_forest = xval_forest.mean()\naccuracy_forest","1f064178":"id_index = pd.DataFrame({'Id' : list(range(len(yPred_Forest)))})\nincome = pd.DataFrame({'income' : yPred_Forest})\nresult = id_index.join(income)\nresult.to_csv(\"Forest.csv\", index = False)\nresult","b8c3877b":"Boost = AdaBoostClassifier(n_estimators=100)\nxval_boost = cross_val_score(Boost, xTreino, yTreino, cv=15)\nBoost.fit(xTreino, yTreino)\nyPred_Boost = Boost.predict(xTeste)\naccuracy_boost = xval_boost.mean()\naccuracy_boost","b56ec74d":"id_index = pd.DataFrame({'Id' : list(range(len(yPred_Boost)))})\nincome = pd.DataFrame({'income' : yPred_Boost})\nresult = id_index.join(income)\nresult.to_csv(\"Boost.csv\", index = False)\nresult","efe8b168":"import graphviz\ngraph = tree.export_graphviz(Tree, out_file=None)\nteste = graphviz.Source(graph)\nteste","d4ab9548":"O objetivo deste trabalho foi testar tr\u00eas classificadores na base *Adult* e comparar os resultados obtidos em termos de acur\u00e1cia, dificuldade de gerar o classificador e tempo de processamento. Para isso, foram escolhidos o classificador *Decision Tree* e outros dois classificadores baseados nessa t\u00e9cnica, *Random Forest* e um algoritmo de *boosting*, o *AdaBoost*.\n\nPara analisar a acur\u00e1cia dos classificadores, foram feitas valida\u00e7\u00f5es cruzadas, testando diferentes n\u00fameros de parti\u00e7\u00f5es para cada classificador. Em cada caso, foi calculada a m\u00e9dia dos valores de acur\u00e1cia obtidos e foi esse o par\u00e2metro utilizado para compara\u00e7\u00e3o. Os melhores valores de acur\u00e1cia obtidos por cada classificador n\u00e3o foram muito diferentes, em primeiro lugar ficou o resultado alcan\u00e7ado pelo algoritmo *AdaBoost* (~86%), seguido pela *Random Forest* (~85%) e *Decision Tree* (~84%). Esses valores de acur\u00e1cia s\u00e3o consideravelmente sens\u00edveis aos par\u00e2metros de cada algoritmo, por exemplo, ao colocar um limite m\u00e1ximo de crescimento para a *decision tree* os resultados se aproximaram dos gerados pelos outros algoritmos ou, ao aumentar o n\u00famero de \u00e1rvores que comp\u00f5em a *random forest*, houve um ganho na acur\u00e1cia.\n\nComo os tr\u00eas classificadores s\u00e3o baseados mais ou menos nos mesmos conceitos, os par\u00e2metros utilizados em suas cria\u00e7\u00f5es s\u00e3o parecidos, muitas vezes s\u00e3o at\u00e9 os mesmos, portanto, n\u00e3o h\u00e1 grande diferen\u00e7a na dificuldade de implementa\u00e7\u00e3o, os tr\u00eas classificadores s\u00e3o relativamente simples de serem gerados. Teoricamente, existe diferen\u00e7a na explicabilidade de cada modelo, com as \u00e1rvores sendo mais intuitivas e f\u00e1ceis de serem entendidas, por\u00e9m, devido ao n\u00famero de atributos utilizados na classifica\u00e7\u00e3o, que por suas vezes possuem v\u00e1rias classes, e aos par\u00e2metros escolhidos na cria\u00e7\u00e3o do classificador, as \u00e1rvores geradas ficaram relativamente grandes e n\u00e3o s\u00e3o t\u00e3o simples de serem entendidas, mas, ainda assim, s\u00e3o mais f\u00e1ceis de serem interpretadas que os outros classificadores, j\u00e1 que estes s\u00e3o formados por centenas de \u00e1rvores cada.\n\nEm rela\u00e7\u00e3o ao tempo de processamento, o classificador *Decision Tree* foi o mais r\u00e1pido, os outros classificadores apresentaram tempo de execu\u00e7\u00e3o consideravelmente maior que o primeiro, j\u00e1 que esse tempo est\u00e1 associado ao n\u00famero de \u00e1rvores geradas, entretanto, neste trabalho, nenhum dos classificadores teve um tempo de execu\u00e7\u00e3o impratic\u00e1vel.\n\nAo submeter os resultados ao Kaggle, como apontado pelo teste de acur\u00e1cia, o melhor score foi obtido pelo algoritmo *AdaBoost* (~84,8%), seguido pelo *Random Forest* (~84,1%), por\u00e9m, o resultado do classificador *Decision Tree* foi pior que o esperado (~81%)."}}