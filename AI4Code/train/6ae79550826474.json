{"cell_type":{"015b5208":"code","850e145e":"code","3420b63a":"code","bc6d6e1c":"code","f7cf14a8":"code","1e81aae8":"code","58f219fb":"code","cab852c9":"code","9ad214f3":"code","ca0a053b":"code","5b654209":"code","d3b1a192":"markdown","d1b2d12a":"markdown","77cf8089":"markdown","70a949de":"markdown","b88fcfd2":"markdown","62a5440e":"markdown","34cdb654":"markdown","6611572c":"markdown"},"source":{"015b5208":"import torch\nimport torch.nn as nn\nimport torchvision.models.detection.rpn as rpn\nimport torchvision.models.detection.image_list as image_list\nfrom torchvision import transforms as T\nfrom torchvision.models.detection import fasterrcnn_resnet50_fpn\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# %config InlineBackend.figure_format = 'retina'\n\n# Retina display for figure\nfrom IPython.display import set_matplotlib_formats\nset_matplotlib_formats('retina')\n\n# display all outputs instead of last one\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","850e145e":"# show the feature maps\ndef show_features(img, features, ch_idx, save=False):\n    fig, axes = plt.subplots(2, 3, figsize=(16,9))\n\n    axes[0,0].imshow(img)\n    axes[0,0].set_title('Input image')\n\n    # axes[0,1].imshow(img.resize((img.size[0]\/\/4, img.size[1]\/\/4)), alpha=0.9)\n    axes[0,1].imshow(features['0'][0, ch_idx, :, :].detach().numpy(), cmap='jet')#, alpha=0.5)\n    axes[0,1].set_title('P2')\n\n    axes[0,2].imshow(features['1'][0, ch_idx, :, :].detach().numpy(), cmap='jet')\n    axes[0,2].set_title('P3')\n\n    axes[1,0].imshow(features['2'][0, ch_idx, :, :].detach().numpy(), cmap='jet')\n    axes[1,0].set_title('P4')\n\n    axes[1,1].imshow(features['3'][0, ch_idx, :, :].detach().numpy(), cmap='jet')\n    axes[1,1].set_title('P5')\n\n    axes[1,2].imshow(features['pool'][0, ch_idx, :, :].detach().numpy(), cmap='jet')\n    axes[1,2].set_title('P6')\n\n    if save:\n        plt.savefig('feature_results.png', bbox_inches='tight')\n\n\n# show the heat maps\ndef show_objectness(img, objectness, ch_idx, save=False):\n    # same extent needs to be defined for different images\n    # extent = 0, objectness[0][0, ch_idx, :, :].shape[1], 0, objectness[0][0, ch_idx, :, :].shape[0]\n    # (width, height) = (img.width \/\/ 4, img.height \/\/ 4)\n\n    fig, axes = plt.subplots(2, 3, figsize=(16,9))\n\n    axes[0,0].imshow(img)\n    axes[0,0].set_title('Input image')\n\n    # axes[0,1].imshow(img.resize((width, height)),  cmap='gray')#, extent=extent)\n    axes[0,1].imshow(objectness[0][0, ch_idx, :, :], cmap='jet', alpha=1.0)#, extent=extent)\n    axes[0,1].set_title('objectness on P2')\n\n    # axes[0,2].imshow(img.resize((width, height)),  cmap='gray')#, extent=extent)\n    axes[0,2].imshow(objectness[1][0, ch_idx, :, :], cmap='jet', alpha=1.0)#, extent=extent)\n    axes[0,2].set_title('objectness on P3')\n\n    # axes[1,0].imshow(img.resize((width, height)),  cmap='gray')#, extent=extent)\n    axes[1,0].imshow(objectness[2][0, ch_idx, :, :], cmap='jet', alpha=1.0)#, extent=extent)\n    axes[1,0].set_title('objectness on P4')\n\n    # axes[1,1].imshow(img.resize((width, height)),  cmap='gray')#, extent=extent)\n    axes[1,1].imshow(objectness[3][0, ch_idx, :, :], cmap='jet', alpha=1.0)#, extent=extent)\n    axes[1,1].set_title('objectness on P5')\n\n    # axes[1,2].imshow(img.resize((width, height)),  cmap='gray')#, extent=extent)\n    axes[1,2].imshow(objectness[4][0, ch_idx, :, :], cmap='jet', alpha=1.0)#, extent=extent)\n    axes[1,2].set_title('objectness on P6')\n\n    if save:\n        plt.savefig('objectness_results.png', bbox_inches='tight')","3420b63a":"# define an objectness class\nclass Objectness(nn.Module):\n    \"\"\"Ojbectness class, as a PyTorch nn.Module. Using a pre-trained faster-RCNN model\n    to obtain the objectness heat maps.\n\n    :param model: a pre-trained faster-rcnn model as initialization\n    :type : nn.Module\n    :input : a PIL image\n    :output : a dict data with 'feature maps' and 'objectness' inside\n    \"\"\"\n\n    def __init__(self, model):\n        super(Objectness, self).__init__()\n\n        layers = nn.ModuleList(list(model.children())[1:3])\n        self.feature = layers[0].eval()\n        self.objectness = layers[1].eval()\n\n    def forward(self, x):\n        results = {}\n\n        feature_out = self.feature(x)\n\n        objectness, _ = self.objectness.head(feature_out.values())\n        object_out = [self._process(obj) for obj in objectness]\n\n        results['features'] = feature_out\n        results['objectness'] = object_out\n\n        return results\n\n    def _process(self, objectness):\n        # apply sigmoid\n        objectness = torch.sigmoid(objectness)\n        # scale to [0,255]\n        objectness = torch.round(objectness * 255)\n        # convert to numpy\n        objectness = objectness.detach().numpy()\n\n        return objectness","bc6d6e1c":"# Get the whole FRCNN model\nmodel = fasterrcnn_resnet50_fpn(pretrained=True)\n\nmodel.eval()","f7cf14a8":"# Reconstruct the modules required for objectness heatmap\nnet = Objectness(model)","1e81aae8":"! wget -O test.jpeg https:\/\/miro.medium.com\/max\/1744\/1*EYFejGUjvjPcc4PZTwoufw.jpeg ","58f219fb":"from PIL import Image\nimg = Image.open('test.jpeg')\n# img = Image.open('new.jpg')\nimg.size\nimg","cab852c9":"# prepare for the input\ntransform = T.Compose([T.ToTensor()])\ninput_im = transform(img)\n\ninput_im = torch.unsqueeze(input_im, 0)\ninput_im.shape","9ad214f3":"# Get the results from class\nresults = net(input_im)","ca0a053b":"# Display feature maps\nshow_features(img, results['features'], 0, True)","5b654209":"# Display the heat maps\nshow_objectness(img, results['objectness'], 0, True)","d3b1a192":"## Construct the Objectness class with nn.ModuleList","d1b2d12a":"## Get the pre-trained model from torchvision","77cf8089":"## Display the results","70a949de":"# Objectness-Heat-Map\n\n### Obtain the objectness heat maps for a given image by Faster-RCNN from torchvision\n\n---\n\nInspired by this blog [Digging into Detectron 2](https:\/\/medium.com\/@hirotoschwert\/digging-into-detectron-2-part-4-3d1436f91266), the heat maps from the part 4 are interesting to reproduce. Though that blog used Detectron2, this repo reproduces the same results with **torchvision** only.","b88fcfd2":"### Find an image for test","62a5440e":"#### Some helper functions","34cdb654":"### Import and setting up","6611572c":"## Reference\n### Get the objectness heatmap\n\n> Figure 4. Visualization of objectness maps. Sigmoid function has been applied to the objectness_logits map. \\\n**The objectness maps for 1:1 anchor** are resized to the P2 feature map size and overlaid on the original image.\n\n### Method mentioned by author:\n>I just insert the following features here to save the objectness heatmap.\n>1. apply sigmoid and scale the tensor range to 0\u2013255\n>2. choose a map from the tensor\n>3. convert it to numpy array (uint8)\n>4. save it as an image file (or directly visualize it using matplotlib)\n> \n>If you use proper weights and proper input image, it should work :)"}}