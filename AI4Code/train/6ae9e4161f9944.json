{"cell_type":{"3a638b28":"code","0f3106c6":"code","db707693":"code","08525413":"code","f07b118d":"code","8067ea79":"code","7d183b20":"code","544ca1bb":"code","12539d0f":"code","7c9a1815":"code","5c4cebcd":"code","3dd1f8df":"code","4971bccf":"code","f33dfd07":"code","551de56f":"code","231ddaa6":"code","deca9bdf":"code","f778c0be":"code","c43f5527":"code","22270a6e":"markdown","ab836f49":"markdown","6f0fdfc9":"markdown"},"source":{"3a638b28":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfrom tensorflow.keras.applications import EfficientNetB0,Xception\nimport tensorflow as tf\nimport tensorflow.python.platform\nfrom tensorflow.python.platform import gfile\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Dropout, Dense, Flatten\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.losses import binary_crossentropy\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import f1_score\n\n\n\n\n\nimport sklearn\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0f3106c6":"train_dirs = [\"\/kaggle\/input\/withwithout-mask\/maskdata\/maskdata\/train\",\n             \"\/kaggle\/input\/withwithout-mask\/masks2.0\/masks\/train\",\n             \"\/kaggle\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train\",\n             \"\/kaggle\/input\/face-mask-detection\/dataset\"\n              \n             ]\n\ntest_dirs = [\"\/kaggle\/input\/withwithout-mask\/maskdata\/maskdata\/test\",\n            \"\/kaggle\/input\/withwithout-mask\/masks2.0\/masks\/test\",\n            \"\/kaggle\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test\",\n            ]\n\nvalidation_dirs = [\"\/kaggle\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Validation\"]\n","db707693":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_data_generator = ImageDataGenerator(rescale=1.\/255, \n                                          rotation_range=40, \n                                          zoom_range=0.15,\n                                          width_shift_range=0.1,\n                                          height_shift_range=0.1,\n                                          shear_range=0.1,\n                                          horizontal_flip=True,\n                                          fill_mode=\"nearest\")\n\ntest_data_generator = ImageDataGenerator(rescale=1.\/255)\n\nvalidation_data_generator = ImageDataGenerator(rescale=1.\/255, \n                                          rotation_range=10, \n                                          zoom_range=0.15,\n                                          width_shift_range=0.1,\n                                          height_shift_range=0.1,\n                                          shear_range=0.1,\n                                          horizontal_flip=True,\n                                          fill_mode=\"nearest\")","08525413":"print(\"Data image Train\")\ntrain_generator1 = train_data_generator.flow_from_directory(\n        train_dirs[0],\n        target_size=(155,155),\n        batch_size=77,\n        interpolation=\"nearest\",\n        class_mode='binary',\n        classes=[\"without_mask\",\"with_mask\"])\ntrain_generator2 = train_data_generator.flow_from_directory(\n        train_dirs[1],\n        target_size=(155,155),\n        batch_size=46,\n        interpolation=\"nearest\",\n        class_mode='binary',\n        classes=[\"0\",\"1\"])\ntrain_generator3 = train_data_generator.flow_from_directory(\n        train_dirs[2],\n        target_size=(155,155),\n        batch_size=80,\n        interpolation=\"nearest\",\n        class_mode='binary',\n        classes=[\"WithoutMask\",\"WithMask\"])\ntrain_generator4 = test_data_generator.flow_from_directory(\n        train_dirs[3],\n        target_size=(155,155),\n        batch_size=55,\n        interpolation=\"nearest\",\n        class_mode='binary',\n        classes=[\"without_mask\",\"with_mask\"])\n","f07b118d":"print(\"\\nData image Test\")\ntest_generator1 = test_data_generator.flow_from_directory(\n        test_dirs[0],\n        target_size=(155,155),\n        batch_size=66,\n        interpolation=\"nearest\",\n        class_mode='binary',\n        classes=[\"without_mask\",\"with_mask\"])\ntest_generator2 = test_data_generator.flow_from_directory(\n        test_dirs[1],\n        target_size=(155,155),\n        batch_size=11,\n        interpolation=\"nearest\",\n        class_mode='binary',\n        classes=[\"0\",\"1\"])\ntest_generator3 = test_data_generator.flow_from_directory(\n        test_dirs[2],\n        target_size=(155,155),\n        batch_size=62,\n        interpolation=\"nearest\",\n        class_mode='binary',\n        classes=[\"WithoutMask\",\"WithMask\"])","8067ea79":"print(\"\\nData image Validation\")\nvalidation_generator1 = validation_data_generator.flow_from_directory(\n        validation_dirs[0],\n        target_size=(155,155),\n        batch_size=80,\n        interpolation=\"nearest\",\n        class_mode='binary',\n        classes=[\"WithoutMask\",\"WithMask\"])\nwithWithoutMask = {\"0\":\"Without Mask\",\"1\":\"With Mask\"}","7d183b20":"def genToTuple(gen):\n    templist = []\n    templist2 = []\n    for i in range(gen.__len__()):\n        tempnext = gen.next()\n        templist.append(tempnext[0])\n        templist2.append(tempnext[1])\n    x=np.concatenate(templist)\n    y=np.concatenate(templist2)\n    return (x,y)\n\ndef combine_tuple(*tuples):\n    x=np.concatenate([tuples[i][0] for i in range(len(tuples))])\n    y=np.concatenate([tuples[i][1] for i in range(len(tuples))])\n    return (x,y.astype(int))\n    \n\ntrain_generator1_t = genToTuple(train_generator1)\ntrain_generator2_t = genToTuple(train_generator2)\ntrain_generator3_t = genToTuple(train_generator3)\ntrain_generator4_t = genToTuple(train_generator4)\n\ntest_generator1_t = genToTuple(test_generator1)\ntest_generator2_t = genToTuple(test_generator2)\ntest_generator3_t = genToTuple(test_generator3)\n\n\n\nx_train,y_train = combine_tuple(train_generator1_t,train_generator2_t,train_generator3_t,train_generator4_t)\nx_test,y_test = combine_tuple(test_generator1_t,test_generator2_t,test_generator3_t)\n\nx_val,y_val = genToTuple(validation_generator1)","544ca1bb":"print(x_train.shape,y_train.shape)\nprint(x_test.shape,y_test.shape)\nprint(x_val.shape,y_val.shape)","12539d0f":"import seaborn as sns\nsns.countplot(y_train)\nprint ( pd.DataFrame(y_train).value_counts())","7c9a1815":"sns.countplot(y_test)\nprint ( pd.DataFrame(y_test).value_counts())","5c4cebcd":"sns.countplot(y_val)\nprint ( pd.DataFrame(y_val).value_counts())","3dd1f8df":"plt.figure(figsize=(100,100))\ntempc = np.random.choice(x_train.shape[0],30,replace=False)\nd = 0\nfor i in tempc:\n    plt.subplot(7, 5, d+1)\n    d += 1\n    tempc = np.random.randint(x_train.shape[0])\n    plt.imshow(x_train[tempc])\n    plt.title({withWithoutMask[str(y_train[tempc])]},\n              fontsize=60)\n    plt.axis(\"off\")\nplt.subplots_adjust(wspace=-0.1, hspace=0.3)\nplt.show()","4971bccf":"xception = Xception(weights='imagenet',include_top=False,input_shape=((150,150,3)))\nfor layer in xception.layers:\n    layer.trainable = True \nmodel = Sequential()\nmodel.add(xception)\nmodel.add(Flatten())\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()","f33dfd07":"model.compile(optimizer=\"adam\",loss=binary_crossentropy, metrics =[\"accuracy\"])","551de56f":"batch_size = 32\ncheckpoint = ModelCheckpoint(\"mask_classification.h5\",monitor=\"val_accuracy\",save_best_only=True,verbose=1)\nsteps_per_epoch = x_train.shape[0] \/\/ batch_size\n\nhistory = model.fit(x_train,\n          y_train,\n          epochs=5,\n          validation_data=(x_val,y_val),\n          verbose=1,\n          batch_size=batch_size,\n          callbacks=[checkpoint],\n          steps_per_epoch = steps_per_epoch)\n","231ddaa6":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.xlabel('epochs')\nplt.ylabel('loss')\n \nplt.show()","deca9bdf":"y_pred = model.predict_classes(x_test)","f778c0be":"labels=[\"No Mask\",\"Mask\"]\nplt.subplots(figsize=(8,7))\nsns.heatmap(confusion_matrix(y_test,y_pred),xticklabels=labels,\n                                       yticklabels=labels, annot=True,fmt=\"1.0f\",cbar=False,annot_kws={\"size\": 20})\nplt.title(\"Confusion matrix\",fontsize=30)\nplt.xlabel(f\"Our model Accuracy: {f1_score(y_test,y_pred)}\",fontsize=30)\nplt.show()","c43f5527":"print(classification_report(y_test, y_pred, target_names = labels)) \n","22270a6e":"Plotting Our data after augumentation :","ab836f49":"# Data Preprocessing\n","6f0fdfc9":"Now we will make data augumention to  increase the diversity of data available for training models.\nI used the ImageDataGenerator to make it easer .\n\nHere you can see more details about this from keras documentation : \n[Image data preprocessing](https:\/\/keras.io\/api\/preprocessing\/image\/)"}}