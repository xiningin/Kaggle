{"cell_type":{"36827cd4":"code","3d2cc486":"code","ab83395a":"code","e68d7ac1":"code","a1d42aa8":"code","92254057":"code","8f4008e1":"code","add5841a":"code","0745f5f9":"code","1faee18e":"code","e95efb87":"code","98fad5e8":"code","3984ae5b":"code","5e2ab188":"code","0de82b1e":"code","6c90bd8b":"code","6483eb8d":"code","da4e14d8":"code","b360bbf1":"code","90fdf821":"code","29e563e1":"code","c5b5ca48":"code","2e074618":"code","24addf85":"code","c85d46df":"code","df481af0":"code","bcaa608c":"code","ca66b832":"code","abde123f":"code","42c6fdf9":"code","dcda3618":"code","6964b51b":"code","c0862cee":"markdown","62c8efba":"markdown","eb1595fe":"markdown","4306dd82":"markdown","566d4232":"markdown","5292f5cc":"markdown","12aab73c":"markdown","4fe4ac23":"markdown","4d4f8747":"markdown","f43edf4b":"markdown","1d6ba578":"markdown","c92e05aa":"markdown","bcca94c8":"markdown","07f8f0e1":"markdown","b1bf0f97":"markdown","f02ef90a":"markdown","b30d4dd8":"markdown","bb0b33ad":"markdown"},"source":{"36827cd4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n!pip install scikit-learn==0.24.1\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport sklearn\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import OrdinalEncoder\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nsklearn.show_versions()\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3d2cc486":"train = pd.read_csv(\"..\/input\/titanic\/train.csv\", index_col = \"PassengerId\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\",index_col = \"PassengerId\")\nX = train.copy()","ab83395a":"X.head()","e68d7ac1":"print(X.isnull().sum(axis = 0)\/X.shape[0])","a1d42aa8":"deal_with_missing_values = ColumnTransformer(\n    [\n        (\"Age\", SimpleImputer(strategy = \"median\"),[\"Age\"]),\n        (\"Embarked\", SimpleImputer(strategy = \"most_frequent\"),[\"Embarked\"]),\n    ]\n)","92254057":"X.pop(\"Cabin\")\nimputed_cols = deal_with_missing_values.fit_transform(X)\nX[\"Age\"] = imputed_cols[:,0]\nX[\"Embarked\"] = imputed_cols[:,1]","8f4008e1":"X[\"Title\"] = X[\"Name\"].str.split(\",\",expand = True)[1].str.split(\" \",expand = True)[1]\nX[\"Title\"].unique()\nX.pop(\"Name\")","add5841a":"digit_Ticket = X.Ticket.map(lambda p: \"\".join(list(filter(str.isdigit, p))[-2:]))\nX.Ticket = digit_Ticket\nX.Ticket = X.Ticket.replace('','-1')\nX.Ticket.unique()","0745f5f9":"fig, axes = plt.subplots(2, 3, figsize=(30, 15))\nsns.barplot(x = \"Sex\", y = \"Survived\", data = X, ax = axes[0,0])\nsns.boxenplot(x = \"Survived\", y = \"Age\", data = X, ax = axes[0,1])\nsns.barplot(x = \"SibSp\", y = \"Survived\", data = X, ax = axes[0,2])\nsns.barplot(x = \"Pclass\", y = \"Survived\", data = X, ax = axes[1,0])\nsns.boxenplot(x = \"Survived\", y = \"Fare\", data = X, ax = axes[1,1])\nsns.barplot(x = \"Title\", y = \"Survived\", data = X, ax = axes[1,2])","1faee18e":"fig,axes = plt.subplots(1,3, figsize=(12,4))\nsns.distplot(a = train.Age, ax = axes[0])\nsns.barplot(x = list(train.Sex.value_counts().index), y = list(train.Sex.value_counts().values), ax = axes[1])\nsns.barplot(x = list(train.Embarked.value_counts().index), y = list(train.Embarked.value_counts().values), ax = axes[2])","e95efb87":"def make_mi_scores(X, y, discrete_features):\n    mi_scores = mutual_info_classif(X, y, discrete_features=discrete_features)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores","98fad5e8":"X = X.astype({\"Age\": np.float, \"Ticket\": np.float, \"Fare\": np.float})\nfor colname in X.select_dtypes(\"object\"):\n    print(colname)\n    X[colname], _ = X[colname].factorize()\ny = X.pop(\"Survived\")  \ndiscrete_features = X.dtypes == int\nmi_score = make_mi_scores(X,y,discrete_features)\nX = X.join(y)\nprint(mi_score)\nX.head()","3984ae5b":"X.Ticket.dtype","5e2ab188":"def preprocess(X,features,column_transformer,transform):\n    X[\"Title\"] = X[\"Name\"].str.split(\",\",expand = True)[1].str.split(\" \",expand = True)[1]\n    y = None\n    if (\"Survived\" in list(X.columns)):\n        y = X.pop(\"Survived\")\n    X = X.loc[:,features]\n    if (transform):\n        temp_df = column_transformer.transform(X)\n        X[\"Title\"] = temp_df[:,0]\n        X[\"Sex\"] = temp_df[:,1]\n        X[\"Embarked\"] = temp_df[:,2]\n    else:\n        temp_df = column_transformer.fit_transform(X)\n        X[\"Title\"] = temp_df[:,0]\n        X[\"Sex\"] = temp_df[:,1]\n        X[\"Embarked\"] = temp_df[:,2]\n    return X,y","0de82b1e":"def search_best_estimator(X,y,n_estimators_list):\n    error_rate = list()\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n    for i in n_estimators_list:\n        model = xgb.XGBClassifier(random_state = 42, objective ='reg:squarederror', n_estimators = i, use_label_encoder = False, learning_rate = 0.005)\n        model.fit(X_train,y_train)\n        y_pred = model.predict(X_test)\n        ac = accuracy_score(y_test,y_pred)\n        error_rate.append(ac)\n    return pd.DataFrame({\"accuracy\":error_rate})","6c90bd8b":"def search_best_depth(X,y,n_estimators, depth_list):\n    error_rate = list()\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n    for i in depth_list:\n        model = xgb.XGBClassifier(random_state = 42, objective ='reg:squarederror', n_estimators = n_estimators, learning_rate = 0.005, use_label_encoder = False, max_depth = i)\n        model.fit(X_train,y_train)\n        y_pred = model.predict(X_test)\n        ac = accuracy_score(y_test,y_pred)\n        error_rate.append(ac)\n    return pd.DataFrame({\"accuracy\":error_rate})","6483eb8d":"def plot_accuracy(X):\n    sns.lineplot(x = X.index,y = X.accuracy)","da4e14d8":"data_transformer = ColumnTransformer(\n     [\n        (\"Title\",  OrdinalEncoder(handle_unknown = \"use_encoded_value\",unknown_value = -1),[\"Title\"]),\n        (\"Sex\", OrdinalEncoder(handle_unknown = \"use_encoded_value\",unknown_value = -1),[\"Sex\"]),\n        (\"Embarked\", OrdinalEncoder(handle_unknown = \"use_encoded_value\",unknown_value = -1),[\"Embarked\"]),\n    ]\n)","b360bbf1":"X_search = train.copy()\nimputed_cols = deal_with_missing_values.fit_transform(X_search)\nX_search[\"Age\"] = imputed_cols[:,0]\nX_search[\"Embarked\"] = imputed_cols[:,1]\nfeatures = [\"Title\",\"Sex\",\"Fare\",\"Pclass\", \"Embarked\"]\nX_search,y_search = preprocess(X_search,features,data_transformer,False)\nresult = search_best_estimator(X_search,y_search,range(1000,7000,1000))","90fdf821":"plot_accuracy(result)","29e563e1":"n_estimator = result.idxmax()\nn_estimator","c5b5ca48":"result = search_best_depth(X_search,y_search,4000,range(1,10))","2e074618":"plot_accuracy(result)","24addf85":"result.idxmax()","c85d46df":"X_train = train.copy()\nX_test = test.copy()\nX_test.isnull().any()","df481af0":"test_deal_with_missing_values = ColumnTransformer(\n    [\n        (\"Age\", SimpleImputer(strategy = \"median\"),[\"Age\"]),\n        (\"Fare\", SimpleImputer(strategy = \"most_frequent\"),[\"Fare\"]),\n    ]\n)\nimputed_X_test = test_deal_with_missing_values.fit_transform(X_test)\nX_test[\"Age\"] = imputed_X_test[:,0]\nX_test[\"Fare\"] = imputed_X_test[:,1]\nimputed_X_train = deal_with_missing_values.fit_transform(X_train)\nX_train[\"Age\"] = imputed_X_train[:,0]\nX_train[\"Embarked\"] = imputed_X_train[:,1]","bcaa608c":"X_train,y_train = preprocess(X_train,features,data_transformer,False)\nX_test,_ = preprocess(X_test,features,data_transformer,True)","ca66b832":"X_test.head()","abde123f":"model = xgb.XGBClassifier(learning_rate=0.005,\n                       n_estimators=6000,\n                       max_depth=4,\n                       min_child_weight=0,\n                       gamma=0.6,\n                       subsample=0.7,\n                       colsample_bytree=0.7,\n                       objective='reg:squarederror',\n                       nthread=-1,\n                       scale_pos_weight=1,\n                       seed=27,\n                       reg_alpha=0.00006,\n                       random_state=42)\nmodel.fit(X_train,y_train)\npredictions = model.predict(X_test)","42c6fdf9":"Submission = pd.DataFrame({\"PassengerId\":list(X_test.index),\"Survived\":predictions}).set_index(\"PassengerId\")","dcda3618":"Submission.head()","6964b51b":"Submission.to_csv(\"Submission.csv\",index = \"PassengerId\")","c0862cee":"Thus we Choose Categories Title, Sex, and Fare as our features","62c8efba":"Best Max depth = 6","eb1595fe":"From the graph, we know XGBoost reaches maximum accuracy at n_estimators = 15 (since starting from 0)","4306dd82":"We can find that the Cabin Category is missing 77% values. Thus we drop that category and impute the other 2 with most frequent value.","566d4232":"Extract the title of Passengers from the name variable to get useful information","5292f5cc":"Extract useful Information From Categorical Features","12aab73c":"Preview Data","4fe4ac23":"**4. Train and tune the model**","4d4f8747":"**5. Generate predictions**","f43edf4b":"**2 EDA Process**","1d6ba578":"**1. Data Preprocessing**","c92e05aa":"plot of distribution of certain variables","bcca94c8":"1.1 Plots of different categories versus survival rate","07f8f0e1":"Extract useful information from ticket Variable","b1bf0f97":"**0. Load Data**","f02ef90a":"Compute mutual information score between each variable and target","b30d4dd8":"**3. Feature Selection**","bb0b33ad":"Find Missing Values"}}