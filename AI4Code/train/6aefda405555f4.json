{"cell_type":{"e8a3edbb":"code","dfdb871b":"code","0b178149":"code","83797218":"code","5c8b2824":"code","b30934e8":"code","c72a8893":"code","079ce6c7":"code","110ae8f8":"code","4bdc7800":"code","9fb44c9a":"code","5ce922f2":"code","d0dde882":"code","8d07cff4":"code","94f063d6":"code","020a379b":"code","ced85749":"code","b819f60f":"code","9635a203":"code","27e82ba5":"code","da5b5827":"code","d9a5be99":"code","19738316":"code","adcb442b":"code","57a67a22":"code","497b666e":"markdown","4e9e70df":"markdown","c89907b7":"markdown","33c57c77":"markdown","d7549e00":"markdown","cef3bfb7":"markdown","042edd54":"markdown","1a90f302":"markdown","a8de5fd1":"markdown","a6d71b3e":"markdown","07dc6e0e":"markdown","50123c13":"markdown","3bdb2139":"markdown","2833920a":"markdown","34807cd0":"markdown","3af13d80":"markdown","f9f5728a":"markdown","aafb4df3":"markdown","bf70dd7f":"markdown","1e10763f":"markdown","1093b5e5":"markdown","db3151e5":"markdown","972177cf":"markdown","58ab762c":"markdown","f7fc2797":"markdown","4fefcfcd":"markdown","4a2bede6":"markdown","07121dfb":"markdown","b97f852a":"markdown","9c934acd":"markdown","bc97c702":"markdown","c6105f3a":"markdown","395088af":"markdown","f43168a5":"markdown"},"source":{"e8a3edbb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nfrom sklearn.cluster import KMeans\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dfdb871b":"df = pd.read_csv('\/kaggle\/input\/PM2.5 Global Air Pollution 2010-2017.csv')\ndf.head()","0b178149":"df.shape","83797218":"df.describe()","5c8b2824":"df.isnull().sum().sum()","b30934e8":"mean_val = pd.Series([],dtype='float')\n\n#The dataframe has 240 rows\nfor i in range(0,df.shape[0]):\n    mean = pd.Series(df.iloc[i][2:10].mean())\n    mean_val = mean_val.append(mean,ignore_index=True)","c72a8893":"df['mean_val'] = mean_val\ndf_pol = df.sort_values(['mean_val'],axis=0,ascending = False)\ndf_pol.reset_index(inplace=True)\ndf_pol.drop(\"index\",axis=1,inplace=True)\n\ndf_pol.astype( {'2010': 'float64' , '2011': 'float64' , '2012' : 'float64' , '2013': 'float64' , '2014': 'float64',\n                  '2015': 'float64' , '2016': 'float64' , '2017': 'float64' , 'mean_val': 'float64'}  ).dtypes\ndf_pol.head()","079ce6c7":"#Arranging the data\nc_names = pd.Series(['Years'],dtype='object')\nfor i in range (0,10):\n    ser = pd.Series(df_pol.iloc[i][0] + \" (\" + df_pol.iloc[i][1] + \")\")\n    c_names = c_names.append(ser)\n    \ndf_arr10 = pd.DataFrame( columns = c_names )\ndf_arr10['Years'] = pd.Series(['2010','2011','2012','2013','2014','2015','2016','2017'],dtype='int')\nfor i in range(0,10):\n    df_arr10[df_arr10.columns[i+1]] = df_pol.iloc[i][2:10].values\n\ndf_arr10 = df_arr10.apply(pd.to_numeric, errors='coerce')\ndf_arr10.head()","110ae8f8":"color_list = ['#e6b0aa','#78281f','#d7bde2','#4a235a','#196f3d','#3498db','#a3e4d7','#e74c3c','#f9e79f','#2c3e50']","4bdc7800":"#Running this code cell with Shift+Enter once might result in the axis labels being black. \n#Run this code cell again to observe the correct plot. \n\nplt.figure(figsize=(12,6))\nsns.set(font_scale=1.15)\n\nfor i in range(1,11):\n    ax = sns.lineplot(x = 'Years' , y = df_arr10.columns[i] , color = color_list[i-1], data = df_arr10)\n    \nax.set(xlabel = 'Years', ylabel = 'PM 2.5 mean annual exposure' , title = 'Air pollution in 10 most polluted countries')\nplt.legend(bbox_to_anchor=(1.01, 1), loc='upper left', borderaxespad=0,\n           labels=['Nepal','India','Qatar','Saudi Arabia','Egypt','Niger','Bahrain','Bangladesh','Cameroon','Iraq'])\n\nplt.show()","9fb44c9a":"df['Change in Pollution'] = df['2010'] - df['2017']\ndf.head()","5ce922f2":"df_ch = df.sort_values(['Change in Pollution'],axis=0,ascending = False)\ndf_ch.reset_index(inplace=True)\ndf_ch.drop(\"index\",axis=1,inplace=True)\ndf_ch.tail()","d0dde882":"world_avg = []\nfor i in range(2,10):\n    world_avg.append(df[df.columns[i]].mean())\n\ndf_world = pd.DataFrame(columns=['Years','World Average'])\ndf_world['Years'] = df.columns[2:10]\ndf_world['World Average'] = pd.Series(world_avg,dtype=float)\n\nsns.lineplot(x = 'Years', y = 'World Average', data=df_world, color='Red')","8d07cff4":"df_cluster = df.drop(['Country Name', 'Country Code'], 1)\n\nsse = []\nlist_k = list(range(1, 10, 1))\n\nfor k in list_k:\n    km = KMeans(n_clusters=k,random_state=0)\n    km.fit(df_cluster)\n    sse.append(km.inertia_)\n\nplt.figure(figsize=(8, 4))\nplt.plot(list_k, sse, '-o')\nplt.xlabel('Number of clusters')\nplt.ylabel('Sum of squared distance');","94f063d6":"kmeans = KMeans(n_clusters = 3, random_state = 0).fit(df_cluster)\ndf['Cluster Label'] = kmeans.labels_.astype(int)\ndf.head() ","020a379b":"df_cluster0 = df[df['Cluster Label'] == 0]\ndf_cluster1 = df[df['Cluster Label'] == 1]\ndf_cluster2 = df[df['Cluster Label'] == 2]\n\nprint(df_cluster0.shape)\nprint(df_cluster1.shape)\nprint(df_cluster2.shape)","ced85749":"#Cluster 0\nprint('Cluster0')\nprint(df_cluster0['mean_val'].min())\nprint(df_cluster0['mean_val'].max(),\"\\n\")\n\n#Cluster 1\nprint('Cluster1')\nprint(df_cluster1['mean_val'].min())\nprint(df_cluster1['mean_val'].max(),\"\\n\")\n\n#Cluster 2\nprint('Cluster2')\nprint(df_cluster2['mean_val'].min())\nprint(df_cluster2['mean_val'].max())","b819f60f":"features = ['2010','2011','2012','2013','2014','2015','2016','2017','mean_val','Change in Pollution']\nX = df[features]\ny = df['Cluster Label']","9635a203":"#Random Forest Classification\n\nfrom sklearn.metrics import f1_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\nRfc_model = RandomForestClassifier(n_estimators = 400,max_depth=10,n_jobs= -1,random_state=0)\nscores = cross_val_score(Rfc_model,X,y,cv=5,scoring='f1_macro')\nprint('macro average - ',scores.mean())\nscores = cross_val_score(Rfc_model,X,y,cv=5,scoring='f1_micro')\nprint('micro average - ',scores.mean())","27e82ba5":"#K-Nearest Neighbours (KNN)\n\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\n\nknn_model = KNeighborsClassifier(n_neighbors=5,leaf_size = 50,n_jobs=-1)\nscores_KNN = cross_val_score(knn_model,X,y,cv=5,scoring='f1_macro')\nprint('macro average - ',scores_KNN.mean())\nscores_KNN = cross_val_score(knn_model,X,y,cv=5,scoring='f1_micro')\nprint('micro average - ',scores_KNN.mean())","da5b5827":"#Logistic Regression\n\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\n\nLoReg_model = LogisticRegression(random_state = 3,n_jobs = -1)\nscores_LR = cross_val_score(LoReg_model,X,y,cv=5,scoring='f1_macro')\nprint('macro average - ',scores_LR.mean())\nscores_LR = cross_val_score(LoReg_model,X,y,cv=5,scoring='f1_micro')\nprint('micro average - ',scores_LR.mean())","d9a5be99":"final_model = LogisticRegression(random_state = 3,n_jobs = -1)\nfinal_model.fit(X,y);","19738316":"#Replace this data with the country data\ndata_dict = {'Country Name' : 'Vatican City',\n             'Country Code' : 'VCY',\n             '2010' : 25.4,\n             '2011' : 22.4,\n             '2012' : 21.3,\n             \"2013\" : 14.85,\n             '2014' : 13.6,\n             '2015' : 10.85,\n             '2016' : 9.45,\n             '2017' : 11.25}","adcb442b":"df_test = pd.DataFrame(columns = df.columns[:12])\ndf_test = df_test.append(data_dict,ignore_index=True)\ndf_test['Change in Pollution'] = df_test['2010'] - df_test['2017']\ndf_test['mean_val'] = df_test.iloc[0][2:10].mean()\ndf_test","57a67a22":"X_test = df_test[features]\nclu = final_model.predict(X_test)\nif(clu == 0):\n    print('Lowly Polluted Country')\nif(clu == 1):\n    print('Highly Polluted Country')\nif(clu == 2):\n    print('Averagely Polluted Country')","497b666e":"By observing the maximum and minimum annual average PM 2.5 release for the 3 clusters, the following inferences can be made - \n\n### Cluster 0 - Lowly Polluted Countries  \nCluster 0 has the smallest span between minimum and maximum average PM 2.5 release. The maximum average value in cluster 0 is 26.5 which is much smaller then the WHO certified safety level. Hence the countries in cluster 0 are the ones that the lowest amount of annual PM 2.5 outlet.\n\n### Cluster 1 - Highly Polluted Countries\nCluster 1 has the highest annual average of PM 2.5 release. The maximum value is way of limits. Even the minimum value is way more than the safety value set by WHO.  \n\n### Cluster 2 - Averagely Polluted Countries\nCluster 2 has the biggest span of average annual PM 2.5 release. While the minimum value is lower than the safety value, the maximum is way more then the safety value.","4e9e70df":"### Plotting the data","c89907b7":"The Clustering algorithm used is KMeans. This is because other algorithms like Agglomerative Clustering or DBSCAN performs well with Density based data and bad with condensed data like we have here. Using density based algorithms would result in incorrect clustering or in the worst case they might fail to cluster the data at all. Hence the KMeans algorithms is used.\n\nIdentifying optimal k value by elbow point method. The metric used is SSE i.e. Sum of Squared Error","33c57c77":"This data is a measure of mean annual exposure (micrograms per cubic meter) of PM2.5 across several countries from the year 2010 to 2017.\nPM2.5 also called as Particulate Matter 2.5, is  a mixture of solid, liquid and aerosol particles that are suspended in the air. The 2.5 refers to their diameter of 2.5 micrometer. PM 2.5 is probably the most important factor in air pollution detection. \n\nFor more information regarding PM 2.5 please visit - https:\/\/www.airveda.com\/blog\/what-is-pm2-5-and-why-is-it-important","d7549e00":"Choosing the optimal classification model","cef3bfb7":"WHO has officially set the safety value of annual PM 2.5 output as 35 micrograms per cubic metre of air ","042edd54":"From the data it can be inferred that **Sri Lanka** and **China** were succesful in reducing the pollution level by a huge margin which hints at a proper management of pollution.\nSimilarly, it can also be inferred that **Cameroon**, **Nigeria** and **Niger** were unsuccesful in maintaining their pollution levels","1a90f302":"The model has been fit with the test data. For a country not present in the data, if we have the annual PM 2.5 outlet for the country from 2010 - 2017, we can predict which Cluster it belongs to. ","a8de5fd1":"Dividing the dataframe into 3 separate cluster dataframes","a6d71b3e":"#### THANK YOU","07dc6e0e":"Setting up the final model","50123c13":"Preliminary EDA Conclusions - The data consists of 197 rows and 10 columns, 8 of which represent the mean pollution level from the year 2010 to 2017. The 197 rows indicate the 197 different countries the data has beem collected for. There is no missing data and since the mean of all the data is almost similar, no normalization is required. ","3bdb2139":"By observing the lineplot, we can deduce the following points - \n* **Nepal** is the most polluted country across the timespan of 2010-2017. \n* In 2015, **Saudi Arabia** caused more pollution than Nepal. However, the pollution level of Saudi Arabia decreased after 2015.\n* **Niger** and **Cameroon** faced the highest rise in pollution level from 2010 to 2017. The pollution of **Niger** rapidly increased to become the 2nd most polluted country in   2017.\n* **Bangladesh** and **Iraq** were able to reduce their annual pollution level accross the timespan of 2010 to 2017","2833920a":"### Clustering of countries to identify similar patterns\nClustering is a form of unsupervised learning that is used to detect patterns and clusters in data which generally can't be divided into groups or clusters. Here, clustering of the data is very important as it might help in grouping the data in multiple clusters and these clusters can give a generic idea of the conditon of the countries that fall in that cluster ","34807cd0":"From the above plot it can be identified that the elbow point rests at k = 3. Hence the number of clusters to be done is 3","3af13d80":"The data contains 200 rows i.e. 200 different countries. Plotting all of them would be horrendous use of space. Hence, plotting the pollution over the years for the 10 most polluted countries","f9f5728a":"### Cluster Labeling","aafb4df3":"From the above plot of the world average, it can be deduced that the average world air pollution has decreased in 2017 as compared to that of 2010. There was a steep decrease till 2014, but 2015 saw a spike in the average pollution level which was later maintained in 2016 and 2017. ","bf70dd7f":"### The Classification model","1e10763f":"### Exploring the data to find most polluted countries by mean","1093b5e5":"### Performing preliminary EDA ","db3151e5":"### Arranging the data to help in Visualization","972177cf":"### Cluster Exploration","58ab762c":"Cluster 0 has 119 elements whereas cluster 1 and cluster 2 have 16 and 62 respectively","f7fc2797":"Predicting cluster label","4fefcfcd":"### Reading the data","4a2bede6":"### Exploring the data to find changes in pollution level\n\nA country's growth can be identified by its change in pollution levels. Decrease in pollution level hints that the country is taking adequate steps to counter its pollution. While an increase or no change in its pollution level indicates that the country isn't taking adequate steps to counter pollution  ","07121dfb":"Setting up the prediction data","b97f852a":"### Hence, by using Unsupervised Learning and Classification models, we can cluster the World Air Pollution data into 3 clusters and for a new data, we can predict which group\/cluster it belongs to, using Classification. ","9c934acd":"## Global Air Pollution from 2010-2017 @Wealthy_Waste","bc97c702":"From the above models it can be seen that Random Forest performs very well with the data and KNN exactly fits the data. However, since both of them have such a high degree of accuracy, they are prone to over-fitting. This can be avoided by using Logistic Regression.","c6105f3a":"Credits to the dataset goes to - \"Karl Weinmeister\". Please find the dataset attached at - https:\/\/www.kaggle.com\/kweinmeister\/pm25-global-air-pollution-20102017. The data has been edited and modified to suit the purpose of the project. ","395088af":"### Plotting the world average across the years","f43168a5":"Defining the features and target variable"}}