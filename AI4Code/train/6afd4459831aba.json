{"cell_type":{"f0aae13a":"code","e4dd61a6":"code","3d4ad0a0":"code","b2dcee59":"code","ad72994e":"code","1063fbde":"code","f9591ccb":"code","6bc5da7e":"code","23511e8b":"code","d4de5b1b":"code","d5c5e764":"code","1871a0ed":"code","dbc19716":"code","abef4c07":"code","6be536f9":"code","e5fd2821":"code","4266140e":"code","47563ab8":"code","6ae97b15":"code","c94f214f":"markdown","81da26a1":"markdown","bfded513":"markdown","75046d2f":"markdown","4f44d868":"markdown","1ee669dd":"markdown"},"source":{"f0aae13a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport missingno as msno #missing data handling\nfrom matplotlib import pyplot as plt # graph plots\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import SGDClassifier\n#from sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingClassifier\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e4dd61a6":"data_train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ndata_test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","3d4ad0a0":"#basic exploration of the data\ndata_train_copy = data_train.copy()\nprint(f\"Head:\\n{data_train}\\n\")\nprint(f\"\\n{data_train.info()}\\n\")\nprint(f\"Describe:\\n{data_train.describe()}\\n\")","b2dcee59":"data_train.hist()\nplt.show()","ad72994e":"print(data_train.corr())","1063fbde":"# handle dup data\n# validate data\n# handle NaNs\n# hangle categorical features\n# find relationships between features\n# find useless features","f9591ccb":"# handle dup data\ndup_indices = data_train.duplicated(subset=\"PassengerId\", keep=False)\ndups = data_train[dup_indices].sort_values(by=\"PassengerId\")\nprint(dups)","6bc5da7e":"# validate data\nfor col in data_train.columns:\n    print(f\"{col}:\\n {data_train[col].value_counts()}\\n\")","23511e8b":"#Name would not work with the models without text processing\n#Most of the Cabin column had NaN entries\n#Ticket seems like a useless feature (also hard to parse)\ndata_train = data_train.drop([\"Name\", \"Cabin\", \"Ticket\"], axis=1)\ndata_test = data_test.drop([\"Name\", \"Cabin\", \"Ticket\"], axis=1)","d4de5b1b":"# handle NaNs\nprint(f\"Null: \\n{data_train.isnull().sum()}\\n\")\nmsno.matrix(data_train)\nplt.show()","d5c5e764":"#try to see if Age NaNs have a reason behind them\nprint(data_train[data_train[\"Age\"].isna()].describe())","1871a0ed":"#replace Age NaNs with the mean age\nage_mean = data_train[\"Age\"].mean()\nprint(age_mean)\n\ndata_train[\"Age\"] = data_train[\"Age\"].fillna(age_mean)\ndata_test[\"Age\"] = data_test[\"Age\"].fillna(age_mean)","dbc19716":"#replace Embarked NaNs with the most common category\nembarked_mode = data_train[\"Embarked\"].mode()[0]\nprint(embarked_mode)\n\ndata_train[\"Embarked\"] = data_train[\"Embarked\"].fillna(embarked_mode)\ndata_test[\"Embarked\"] = data_test[\"Embarked\"].fillna(embarked_mode)","abef4c07":"#replace Fare NaNs with the mean fare (got a NaN error for test set in Fare)\nfare_mean = data_train[\"Fare\"].mean()\nprint(fare_mean)\n\ndata_train[\"Fare\"] = data_train[\"Fare\"].fillna(age_mean)\ndata_test[\"Fare\"] = data_test[\"Fare\"].fillna(age_mean)","6be536f9":"#check for NaNs again (just to be sure)\nprint(f\"Null: \\n{data_train.isnull().sum()}\\n\")","e5fd2821":"#create dummies for the categorical columns (Sex and Embarked)\ndata_train = pd.get_dummies(data_train, drop_first=True, columns=[\"Sex\", \"Embarked\"])\ndata_test = pd.get_dummies(data_test, drop_first=True, columns=[\"Sex\", \"Embarked\"])\nprint(data_train)","4266140e":"# get X and y\nX = data_train.drop([\"Survived\"], axis=1)\ny = data_train[\"Survived\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=420)\n\n# build models\nlr = LinearRegression()\nlr.fit(X_train, y_train)\n\ntree = DecisionTreeClassifier()\ntree.fit(X_train, y_train)\n\nknn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\n\nsgdc = SGDClassifier()\nsgdc.fit(X_train, y_train)\n\ngrad = GradientBoostingClassifier(n_estimators=100)\ngrad.fit(X_train, y_train)","47563ab8":"# test models\nprint(lr.score(X_test, y_test))\nprint(tree.score(X_test, y_test))\nprint(knn.score(X_test, y_test))\nprint(sgdc.score(X_test, y_test))\nprint(grad.score(X_test, y_test))","6ae97b15":"#predict on the test set with the best model\ny_predict = grad.predict(data_test)\n\n#submit data\nsubmission_data = pd.DataFrame({\"PassengerId\": data_test[\"PassengerId\"].values, \"Survived\": y_predict})\nsubmission_data.to_csv(\"submission.csv\", index=False)","c94f214f":"# Assignment 0 (Titanic)\n### By Myles Caesar","81da26a1":"### Generating Submission Data","bfded513":"### Build Models","75046d2f":"### Loading Data","4f44d868":"### EDA","1ee669dd":"### Evaulating Models"}}