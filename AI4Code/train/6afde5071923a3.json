{"cell_type":{"2478405c":"code","21c11010":"code","83b91f67":"code","f41e6a9e":"code","eb0fafd3":"code","1cc9a303":"code","42f643e2":"code","f74df38c":"code","34fca7ec":"code","637dc652":"code","36277e22":"code","b01e5840":"code","935580d8":"code","cc348614":"markdown","d771e91e":"markdown","e5a82455":"markdown","5effd9c9":"markdown","f8ea3e3a":"markdown","aa073861":"markdown","4dfbafe6":"markdown","987165aa":"markdown","fe9ae870":"markdown","fb6373ad":"markdown"},"source":{"2478405c":"! cp -a \/kaggle\/input\/catalyst\/catalyst\/catalyst\/install.sh \/tmp\/install.sh && chmod 777 \/tmp\/install.sh && \/tmp\/install.sh \/kaggle\/input\/catalyst\/catalyst\/catalyst","21c11010":"! ls \/kaggle\/input\/mnistcatalyst","83b91f67":"cat \/kaggle\/input\/mnistcatalyst\/__init__.py","f41e6a9e":"cat \/kaggle\/input\/mnistcatalyst\/experiment.py","eb0fafd3":"cat \/kaggle\/input\/mnistcatalyst\/model.py","1cc9a303":"cat \/kaggle\/input\/mnistcatalyst\/dataset.py","42f643e2":"cat \/kaggle\/input\/mnistcatalyst\/train.yml","f74df38c":"cat \/kaggle\/input\/mnistcatalyst\/infer.yml","34fca7ec":"!head \/kaggle\/input\/mnistcatalyst\/fold.csv","637dc652":"! catalyst-dl run --config \/kaggle\/input\/mnistcatalyst\/train.yml --expdir \/kaggle\/input\/mnistcatalyst\/","36277e22":"! catalyst-dl run --config \/kaggle\/input\/mnistcatalyst\/infer.yml --expdir \/kaggle\/input\/mnistcatalyst\/","b01e5840":"! ls \/tmp\/log","935580d8":"import numpy as np\nimport pandas as pd\n\nprob = np.load('\/tmp\/log\/infer.logits.npy')\nargmax = prob.argmax(axis=1)\npd.DataFrame({\n    'ImageId': np.arange(1, len(argmax) + 1),\n    'Label': argmax\n}).to_csv('submission.csv', index=False)","cc348614":"1. __init__.py - import base parts which will be imported by catalyst\n2. experiment.py - file that provides the catalyst with the datasets\n3. model.py - model declaration. We use a very simple model for this notebook\n4. dataset.py - trivial Pytorch dataset for the task\n5. train.yml - configuration file for training\n6. infer.yml - configuration file for inference\n\nfold.csv - is a task-specific file with 5-Fold spliting. It is used in the dataset","d771e91e":"Let's read the predictions and make a submission","e5a82455":"**Install Catalyst**\n\nTypically, you just run `pip install catalyst`. \n\nBut in many competitions on Kaggle you will not be provided with the Internet connection when you will be doing the submission.\n\n\nTo cope with it, there is a Kaggle dataset with the requirements.\n\nMore about this dataset: https:\/\/www.kaggle.com\/lightforever\/catalyst","5effd9c9":"**Explore format of the files which are required by Catalyst**","f8ea3e3a":"![Catalyst](https:\/\/raw.githubusercontent.com\/catalyst-team\/catalyst-pics\/master\/pics\/catalyst_logo.png)","aa073861":"**Infer**","4dfbafe6":"**Train**","987165aa":"**This notebook aims to:**\n1. Show a base pipeline with Catalyst:\n    * declarative base structure that is required by the library\n    * training\n    * inference\n\n2. Create the submission\n\n**Catalyst** is a high-level library(based on Pytorch) that helps to train your neural network models.\n\nIt breaks a common training procedure into separate code blocks.\n\nTypically, you just need to declare your model and create simple configuration files. That is it!\n\nFrom the official site:\n\n>\nCatalyst helps you write compact but full-featured DL & RL pipelines in a few lines of code. \n\n>You get a training loop with metrics, early-stopping, model checkpointing and other features without the boilerplate.\n\n**Features**\n> \n> Universal train\/inference loop.\n> \n> Configuration files for model\/data hyperparameters.\n> \n> Reproducibility \u2013 even source code will be saved.\n> \n> Callbacks \u2013 reusable train\/inference pipeline parts.\n> \n> Training stages support.\n> \n> Easy customization.\n\n> PyTorch best practices (SWA, AdamW, 1Cycle, FP16 and more).\n\nMore info about Catalyst:\n\nhttps:\/\/github.com\/catalyst-team\/catalyst\n\nExamples:\n\nhttps:\/\/github.com\/catalyst-team\/catalyst\/tree\/master\/examples","fe9ae870":"**Conclusion**\n\nCatalyst helps you to create a new experiment rapidly! \n\nYou just need to include(or write if it does not exist) a new callback.\n\nOr you can change the runner. There are lots of tricks there!","fb6373ad":"catalyst has written the predictions into 'infer.logits.npy'"}}