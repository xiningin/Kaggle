{"cell_type":{"3a3db3cf":"code","36ec7997":"code","648a1664":"code","c93ebd5d":"code","a6ca5ef5":"code","024eb358":"code","ab38f202":"code","d311893c":"code","4674d442":"code","81825042":"code","b301770e":"code","2c8865e6":"code","8b7150ec":"code","8bf02bb8":"code","13f9015f":"markdown","5a131d5f":"markdown","4db3d128":"markdown","f7f12c8d":"markdown","0738c522":"markdown","f363e57b":"markdown","7a1a5800":"markdown","f4c7ffb1":"markdown","d372fe6e":"markdown"},"source":{"3a3db3cf":"!pip install timm","36ec7997":"# Preliminaries\nfrom tqdm import tqdm\nimport math\nimport random\nimport os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\n\n# Visuals and CV2\nimport cv2\n\n# albumentations for augs\nimport albumentations\nfrom albumentations.pytorch.transforms import ToTensorV2\n\n#torch\nimport torch\nimport timm\nimport torch\nimport torch.nn as nn\nfrom torch.nn import Parameter\nfrom torch.nn import functional as F\nfrom torch.utils.data import Dataset,DataLoader\n\nimport warnings\nwarnings.filterwarnings('ignore')","648a1664":"DIM = (512,512)\n\nNUM_WORKERS = 8\nTRAIN_BATCH_SIZE = 16\nVALID_BATCH_SIZE = 16\nEPOCHS = 20\nSEED = 42\n\ndevice = torch.device('cuda')\n\nmodel_name = 'efficientnet_b3' #efficientnet_b0-b7\nnum_ch = 1536","c93ebd5d":"def seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_torch(SEED)","a6ca5ef5":"def get_valid_transforms():\n\n    return albumentations.Compose(\n        [\n            albumentations.Resize(DIM[0],DIM[1],always_apply=True),\n            albumentations.Normalize(),\n        ToTensorV2(p=1.0)\n        ]\n    )","024eb358":"class ShopeeDataset(Dataset):\n    def __init__(self, csv, transforms=None):\n\n        self.csv = csv.reset_index()\n        self.augmentations = transforms\n\n    def __len__(self):\n        return self.csv.shape[0]\n\n    def __getitem__(self, index):\n        row = self.csv.iloc[index]\n        \n        text = row.title\n        \n        image = cv2.imread(row.filepath)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.augmentations:\n            augmented = self.augmentations(image=image)\n            image = augmented['image']       \n        \n        \n        return image,torch.tensor(row.label_group)","ab38f202":"class Net(nn.Module):\n\n    def __init__(self,\n                 model_name='efficientnet_b0'):\n        super(Net, self).__init__()\n        print('Building Model Backbone for {} model'.format(model_name))\n\n        self.backbone = timm.create_model(model_name, pretrained=True)\n        self.backbone.classifier = nn.Identity()\n        self.backbone.global_pool = nn.Identity()\n        \n        self.pooling =  nn.AdaptiveAvgPool2d(1)\n        \n    def forward(self, x, label):\n        feature = self.extract_feat(x)\n        return feature\n\n    def extract_feat(self, x):\n        batch_size = x.shape[0]\n        x = self.backbone(x)\n        x = self.pooling(x).view(batch_size, -1)\n\n        return x","d311893c":"def get_img_emb(data_loader,model,criterion,device):\n    model.eval()\n    tk0 = tqdm(enumerate(data_loader), total=len(data_loader))\n    outs = np.zeros([len(valid), num_ch])\n    with torch.no_grad():      \n        for i,(bi,d) in enumerate(tk0):\n            batch_size = d[0].size()[0]\n\n            image = d[0]\n            targets = d[1]\n\n            image = image.to(device)\n            targets = targets.to(device)\n            # Inference\n            output = model.extract_feat(image)\n            outs[i*batch_size:i*batch_size+batch_size] = output.cpu().detach().numpy()      \n    return outs","4674d442":"from sklearn.model_selection import GroupKFold\ndf_train = pd.read_csv(\"..\/input\/shopee-product-matching\/train.csv\")\nskf = GroupKFold(5)\ndf_train['fold'] = -1\nfor i, (train_idx, valid_idx) in enumerate(skf.split(X=df_train, groups=df_train['label_group'])):\n    df_train.loc[valid_idx, 'fold'] = i\ntrain_df = df_train\ndf_train.tail()\n\ndata = df_train\ndata['filepath'] = data['image'].apply(lambda x: os.path.join('..\/input\/shopee-product-matching\/train_images', x))\nlen(data)","81825042":"fold = 0\ntrain = data[data['fold']!=fold].reset_index(drop=True)\nvalid = data[data['fold']==fold].reset_index(drop=True)","b301770e":"valid_dataset = ShopeeDataset(\n    csv=valid,\n    transforms=get_valid_transforms(),\n)\n\nvalid_loader = torch.utils.data.DataLoader(\n    valid_dataset,\n    batch_size=VALID_BATCH_SIZE,\n    num_workers=NUM_WORKERS,\n    shuffle=False,\n    pin_memory=True,\n    drop_last=False,\n)","2c8865e6":"# Defining Device\ndevice = torch.device(\"cuda\")\n\n# Defining Model for specific fold\nmodel = Net(model_name)\nmodel = model.to(device)","8b7150ec":"def getMetric(col):\n    def f1score(row):\n        n = len( np.intersect1d(row.target,row[col]) )\n        return 2*n \/ (len(row.target)+len(row[col]))\n    return f1score\n\nfrom sklearn.preprocessing import normalize\nimport gc\n\ndef get_cv(df, outs):\n    thresholds = list(np.arange(0.2, 0.8, 0.1))\n    scores = []\n    \n    # set target\n    tmp = df.groupby('label_group').posting_id.agg('unique').to_dict()\n    df['target'] = df.label_group.map(tmp)\n\n    # Normalize\n    outsn = normalize(outs)\n\n    # to torch\n    outsn_torch = torch.from_numpy(outsn).cuda()\n    \n    # calculate cosine simularity with torch cuda()\n    distances = 1 - torch.matmul(outsn_torch, outsn_torch.T).cpu().T\n    \n    for threshold in thresholds:\n        predictions = []\n        for k in range(outs.shape[0]):\n            idx = np.where(distances[k,] < threshold)[0]\n            o = df.iloc[idx].posting_id.values\n            predictions.append(o)\n        df[\"preds\"] = predictions\n        #df['oof'] = df.apply(combine_for_cv,axis=1)\n        df['f1'] = df.apply(getMetric(\"preds\"),axis=1)\n        score = df['f1'].mean()\n        print(f'Our f1 score for threshold {threshold} is {score}')\n        scores.append(score)\n    thresholds_scores = pd.DataFrame({'thresholds': thresholds, 'scores': scores})\n    max_score = thresholds_scores[thresholds_scores['scores'] == thresholds_scores['scores'].max()]\n    best_threshold = max_score['thresholds'].values[0]\n    best_score = max_score['scores'].values[0]\n    print(f'Our best score is {best_score} and has a threshold {best_threshold}')\n    gc.collect()\n    torch.cuda.empty_cache()\n\n    return best_score","8bf02bb8":"# get embeddings\nouts = get_img_emb(valid_loader,model,None,device)\n\n# calculate CV\nbest = get_cv(valid, outs)","13f9015f":"# Utils","5a131d5f":"# Configuration","4db3d128":"![](https:\/\/i.imgflip.com\/561676.jpg)","f7f12c8d":"# Model","0738c522":"# Dataset","f363e57b":"# Get embeddings","7a1a5800":"# Calculate CV with only Pytorch\nI had trouble installing rapids to colab, which lead to calculating CV with torch.\n\nIn this notebook, we use pytorch cuda to calculate cosine simularity, which is quite fast!\n\nThe computaton is fast as cuml neighbors.\n\n(Wish that rapids were easy to install on remote machines as well..)","f4c7ffb1":"# Run CV","d372fe6e":"# Setup dataloader"}}