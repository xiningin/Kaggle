{"cell_type":{"6f966784":"code","23a7022e":"code","0954f141":"code","c10650e3":"code","1dfcd553":"code","ee7d521c":"code","c8405d40":"code","af83d465":"markdown"},"source":{"6f966784":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pickle as pkl\nimport gc\nimport librosa\nfrom librosa import display\nimport math\nfrom tqdm.notebook import tqdm, trange\nfrom hmmlearn.hmm import GMMHMM\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\npath = '\/kaggle\/input\/darpa-timit-acousticphonetic-continuous-speech\/'\ndata_path = path+\"data\/\"\nprint(path,data_path)\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","23a7022e":"class Feature_Collector():\n    __train_desc = 'train_data.csv'\n    __test_desc = 'test_data.csv'\n    __data_directory = '.\/data'\n    __main_directory = '.\/'\n    f_Path = 'path_from_data_dir' #field that contains file path in train_data.csv\n    f_IsAudio = 'is_converted_audio' #boolean field that tells that the record in train_data.csv contains the description of audio file we are interested in\n    f_IsWord = 'is_word_file'\n    f_IsPhon = 'is_phonetic_file'\n    f_IsSent = 'is_sentence_file'\n    # f_filename = 'filename' #field that contains filename\n    f_dr = 'dialect_region' #field that contains dialect_region information\n    _winlen = 0.025\n    _winstep = 0.01\n    \n    def __init__(self,path=None):\n        if path == None:\n            raise Exception(\"Directory path to the TIMIT Data set must be provided\")\n        if not os.path.isdir(path):\n            raise Exception(\"Directory doesn't exist\")\n        self.__main_directory = path\n        if path[len(path)-1] == '\/':\n            self.__data_directory = path+\"data\/\"\n        else:\n            self.__main_directory += \"\/\"\n            self.__data_directory = self.__main_directory+\"data\/\"\n      \n        # TimitBet 61 phoneme mapping to 39 phonemes\n        # by Lee, K.-F., & Hon, H.-W. (1989). Speaker-independent phone recognition using hidden Markov models. IEEE Transactions on Acoustics, Speech, and Signal Processing, 37(11), 1641\u20131648. doi:10.1109\/29.46546 \n        self.phon61_map39 = {\n            'iy':'iy',  'ih':'ih',   'eh':'eh',  'ae':'ae',    'ix':'ih',  'ax':'ah',   'ah':'ah',  'uw':'uw',\n            'ux':'uw',  'uh':'uh',   'ao':'aa',  'aa':'aa',    'ey':'ey',  'ay':'ay',   'oy':'oy',  'aw':'aw',\n            'ow':'ow',  'l':'l',     'el':'l',  'r':'r',      'y':'y',    'w':'w',     'er':'er',  'axr':'er',\n            'm':'m',    'em':'m',     'n':'n',    'nx':'n',     'en':'n',  'ng':'ng',   'eng':'ng', 'ch':'ch',\n            'jh':'jh',  'dh':'dh',   'b':'b',    'd':'d',      'dx':'dx',  'g':'g',     'p':'p',    't':'t',\n            'k':'k',    'z':'z',     'zh':'sh',  'v':'v',      'f':'f',    'th':'th',   's':'s',    'sh':'sh',\n            'hh':'hh',  'hv':'hh',   'pcl':'h#', 'tcl':'h#', 'kcl':'h#', 'qcl':'h#','bcl':'h#','dcl':'h#',\n            'gcl':'h#','h#':'h#',  '#h':'h#',  'pau':'h#', 'epi': 'h#','nx':'n',   'ax-h':'ah','q':'h#' \n        }\n        \n        self.phon61 = list(self.phon61_map39.keys())\n        self.phon39 = list(set(self.phon61_map39.values()))\n        self.phon61.sort()\n        self.phon39.sort()\n\n        self.label_p39 = {}\n        self.p39_label = {}\n        for i,p in enumerate(self.phon39):\n            self.label_p39[p] = i\n            self.p39_label[i] = p\n\n        self.phon39_map61 = {}\n        for p61,p39 in self.phon61_map39.items():\n            if not p39 in self.phon39_map61:\n                self.phon39_map61[p39] = []\n            self.phon39_map61[p39].append(p61)\n        \n        pkl.dump(self.label_p39,open('\/kaggle\/working\/phon_label_index.pkl','wb'))\n        pkl.dump(self.phon61_map39,open('\/kaggle\/working\/phon_map_61To39.pkl','wb'))\n        #-------------------------------------------------\n        #end __init__\n    \n    #------------------------------------------------------------------------\n    def get39EquiOf61(self,p):\n        return self.phon61_map39[self.removePhonStressMarker(p)]\n    \n    def get39Index(self,phon):\n        return self.label_p39[phon]\n\n    def get39Phon(self,index):\n        return self.p39_label[index] \n\n    def removePhonStressMarker(self,phon):\n        phon = phon.replace('1','')\n        phon = phon.replace('2','')\n        return phon\n    \n    def getWindow(self,sr):\n        nfft = 512\n        winlen = self._winlen * sr\n        winstep = self._winstep * sr\n        return nfft,int(winlen),int(winstep)\n        \n    def readTrainingDataDescriptionCSV(self):\n        file_path = self.__main_directory + 'train_data.csv' #check if train_data.csv is in correct path\n        self._Tdd = pd.read_csv(file_path)\n        # removing NaN entries in the train_data.csv file\n        dr = ['DR1','DR2','DR3','DR4','DR5','DR6','DR7','DR8']\n        self._Tdd = self._Tdd[self._Tdd['dialect_region'].isin(dr)]\n        return self._Tdd\n\n    def readTestingDataDescriptionCSV(self):\n        file_path = self.__main_directory + 'test_data.csv' #check if train_data.csv is in correct path\n        self._tdd = pd.read_csv(file_path)\n        # removing NaN entries in the train_data.csv file\n        dr = ['DR1','DR2','DR3','DR4','DR5','DR6','DR7','DR8']\n        self._tdd = self._tdd[self._tdd['dialect_region'].isin(dr)]\n        return self._tdd\n    \n    def getListAudioFiles(self,of='Train'):\n        if of == 'Train':\n            self.readTrainingDataDescriptionCSV()\n            return self._Tdd[self._Tdd[self.f_IsAudio] == True]\n        if of == 'Test':\n            self.readTestingDataDescriptionCSV()\n            return self._tdd[self._tdd[self.f_IsAudio] == True]\n        \n    def getListPhonemeFiles(self,of='Train'):\n        if of == 'Train':\n            self.readTrainingDataDescriptionCSV()\n            return self._Tdd[self._Tdd[self.f_IsPhon] == True]\n        if of == 'Test':\n            self.readTestingDataDescriptionCSV()\n            return self._tdd[self._tdd[self.f_IsPhon] == True]\n               \n    def readAudio(self,fpath=None,pre_emp = False):\n        if(fpath == None):\n            return np.zeros(1),0\n        \n        fpath = self.__data_directory+fpath\n        if os.path.exists(fpath):\n            S,sr = librosa.load(fpath,sr=None)\n            if pre_emp:\n                S = librosa.effects.preemphasis(S)\n            return S,sr   \n        else:\n            return np.zeros(1),0\n    #-----------------------end readAudio()\n    \n    def getPhonPathFromAudioPath(self,audio_path):\n        return audio_path.split(\".WAV\")[0]+\".PHN\"\n    \n    def readPhon(self,fpath=None):    \n        if(fpath == None):\n            raise Exception('phon file path not provided')\n\n        fpath = data_path+fpath\n        ph_ = pd.read_csv(fpath,sep=\" \")\n        first = ph_.columns\n        ph_.columns = ['start','end','phoneme']\n        ph_.loc[-1] = [int(first[0]),int(first[1]),first[2]]\n        ph_ = ph_.sort_index()\n        ph_.index = range(ph_.index.shape[0])\n        return ph_\n    #---------------end readPhon()\n        \n    def getFeatureAndLabel(self,ftype='mfsc',audio_path=None,phon_path=None,n_mels=128,delta=False,delta_delta=False):\n        if audio_path == None:\n            raise Exception(\"Path to audio (Wav) file must be provided\")\n        wav,sr = self.readAudio(fpath=audio_path,pre_emp=True)\n        nfft,winlen,winstep = self.getWindow(sr)\n        if(ftype == 'mfsc'):\n            melspec = librosa.feature.melspectrogram(wav,sr=sr,hop_length=winstep,win_length=winlen,n_fft=nfft,n_mels=n_mels)\n            db_melspec = librosa.amplitude_to_db(melspec,ref=np.max)\n        if(ftype == 'mfcc'):\n            db_melspec = librosa.feature.mfcc(wav,sr=sr,hop_length=winstep,win_length=winlen,n_fft=nfft,n_mfcc=n_mels)\n            \n        mD = None\n        mDD = None\n        if(delta):\n            mD = librosa.feature.delta(db_melspec)\n            db_melspec = np.concatenate([db_melspec,mD])\n            if(delta_delta):\n                mDD = librosa.feature.delta(mD)\n                db_melspec = np.concatenate([db_melspec,mDD])\n        \n        audio_phon_transcription = None\n        if phon_path == None:\n            phon_path = self.getPhonPathFromAudioPath(audio_path)\n            \n        audio_phon_transcription = self.readPhon(phon_path)     \n        \n        feature_vectors = []\n        db_melspec = db_melspec.T       \n        time = db_melspec.shape[0]\n        \n        prev = None\n        labels = []\n        for i in range(time):\n            #---collecting feature---\n            feature_vectors.append(db_melspec[i])\n            \n            #---collecting phoneme label ---\n            start = winstep * i\n            end = start+winlen\n            diff = start+400\n            phoneme = list(\n                        audio_phon_transcription[\n                            ((audio_phon_transcription['start']<=start) & \n                            ((audio_phon_transcription['end']-start)>=int(winlen\/2)))\n                            |\n                            ((audio_phon_transcription['start']<=end) & \n                                (audio_phon_transcription['end']>end))  \n                        ].to_dict()['phoneme'].values()\n            )\n            tmp = phoneme\n            try:\n                phoneme = self.get39EquiOf61(phoneme[0])\n                prev = phoneme\n                labels.append(phoneme)\n            except:\n                # if the phoneme file doesn't start from Zero, then assign 'h#' silent to the frames in those unlabeled segments\n                # or if the phoneme can't be determined as per logic above for a segment then assign silent 'h#'\n                labels.append('h#')\n             \n        return feature_vectors,labels\n                \n    #--------------------end getMelSpectrogramFeatureAndLabel()\n    def prepareLabelsForTraining(self,labels):\n        print('Preparing Labels')\n        label_vector = []\n        p_bar = tqdm(range(len(labels)))\n        c = 0\n        for l in labels:\n            label = [0 for i in range(39)]\n            label[self.label_p39[l]-1] = 1\n            label_vector.append(label)\n            c+=1\n            if c == 500:\n                p_bar.set_description(f'Working on phoneme {l}')\n                p_bar.update(c)\n                c = 0\n           \n        p_bar.set_description(f'Working on phoneme {l}')\n        p_bar.update(c) \n        return label_vector\n    \n    def collectFeatures(self,ft='Train',ftype='mfsc',n_mels=128,delta=False,delta_delta=False):\n        tddA = self.getListAudioFiles(ft)\n        tddA.index = range(tddA.shape[0])\n        feature_vectors = []\n        labels = []\n        \n        p_bar = tqdm(range(tddA.shape[0]))\n        silent_count = 0\n        for i in range(tddA.shape[0]):\n            fv,lv = self.getFeatureAndLabel(ftype=ftype,audio_path=tddA.loc[i][self.f_Path],n_mels=n_mels,delta=delta,delta_delta=delta_delta)\n            p_bar.set_description(f'Working on {tddA.loc[i][self.f_Path]} ,index: {i}  ')\n            p_bar.update()\n            feature_vectors += fv\n            labels += lv\n                   \n        print(f\"length of feature_vectors is {len(feature_vectors)} and length of labels is {len(labels)}\")\n        labels = np.asarray(np.array(self.prepareLabelsForTraining(labels),dtype=object)).astype(np.int16)\n        feature_vectors = np.asarray(np.array(feature_vectors,dtype=object)).astype(np.float32)\n        return feature_vectors,labels\n    #--------------------end collectFeatures  \n        \n    def collectHMMFeatures(self,ft='Train',ftype='mfsc',n_mels=128,delta=False,delta_delta=False):\n        tddA = self.getListAudioFiles(ft)\n        tddA.index = range(tddA.shape[0])\n        feature_vectors = [[] for i in range(39)]\n        lengths = [[] for i in range(39)]\n        \n        p_bar = tqdm(range(tddA.shape[0]))\n        for i in range(tddA.shape[0]):\n            p_bar.set_description(f'Working on {tddA.loc[i][self.f_Path]}')\n            fv,lv = self.getFeatureAndLabel(ftype=ftype,audio_path=tddA.loc[i][self.f_Path],n_mels=n_mels,delta=delta,delta_delta=delta_delta)\n            count = 0\n            prev = ''\n            for j in range(len(lv)):\n                if prev == '' or lv[j]==prev:\n                    prev = lv[j]\n                    count+=1\n                    feature_vectors[self.get39Index(prev)].append(fv[j])\n                elif lv[j]!=prev:\n                    lengths[self.get39Index(prev)].append(count)\n                    prev = lv[j]\n                    feature_vectors[self.get39Index(prev)].append(fv[j])\n                    count = 1\n                    \n            #inserting last length\n            lengths[self.get39Index(prev)].append(count)\n            #-----------------\n            p_bar.update()\n            if(i%100==0):\n                gc.collect()\n                \n        '''        \n        #feature vector may contains single vector instances for 16 phonemes which caused issue while training HMM\n        for i in range(39):\n            tmp_length = []\n            prev_size = 0\n            for size in lengths[i]:\n                if prev_size < 4:\n                    prev_size += size\n\n                if prev_size >= 4:\n                    tmp_length.append(prev_size)\n                    prev_size = 0\n            tmp_length.append(prev_size)\n            lengths[i] = tmp_length   \n        '''\n           \n        feature_vectors = [np.asarray(np.array(feature_vectors[i],dtype=object)).astype(np.float32) for i in range(39)]\n        print(f\"length of feature_vectors is {feature_vectors[0].shape}\")\n        return feature_vectors,lengths\n    #--------------------end collectFeatures   ","0954f141":"###-------------- Collecting Training Features -------------------\nfc = Feature_Collector(path)\nn_mels = 64\ndelta = False\ndelta_delta = False\nftype = 'mfcc'\nfeature_path = '\/kaggle\/input\/timit-{}{}-feature\/'.format(n_mels,ftype)#'\/kaggle\/input\/timit-{}mel-spectrogramdelta-features\/'.format(n_mels)\n# feature_path = '\/kaggle\/input\/timit-gmmhmm-asr\/' \n\nprint('Attempting to read features file',feature_path)\nif os.path.exists(feature_path+'features.pkl') or os.path.exists('\/kaggle\/working\/features.pkl'):\n    if os.path.exists(feature_path+'features.pkl'):\n        print(\"-from input\")\n        ffp = open(feature_path+'features.pkl','rb')\n        flp = open(feature_path+'lengths.pkl','rb')   \n    elif os.path.exists('\/kaggle\/working\/features.pkl'):\n        print(\"-from output\")\n        ffp = open('\/kaggle\/working\/features.pkl','rb')\n        flp = open('\/kaggle\/working\/lengths.pkl','rb')\n    features = pkl.load(ffp)\n    lengths = pkl.load(flp)\n    ffp.close()\n    flp.close()\n    print('---- success')\n    #-------\nelse:            \n    print('--- Failed')\n    print('Collecting Features from Audio Files')\n    features,lengths = fc.collectHMMFeatures(ftype=ftype,n_mels=n_mels,delta=delta,delta_delta=delta_delta)\n    # -------------\n    ffp = open(\"\/kaggle\/working\/features.pkl\",'wb')\n    pkl.dump(features,ffp)\n    flp = open(\"\/kaggle\/working\/lengths.pkl\",'wb')\n    pkl.dump(lengths,flp) \n    ffp.close()\n    flp.close()\n    print('--- Completed')\n    #-------\ngc.collect()","c10650e3":"#####------------ Initializing Models ---------------------\nmodels = [GMMHMM(n_components=1,n_mix=6,verbose=False,n_iter=10) for i in range(39)]\n\np_bar = tqdm(range(39))\n#### ----------- Training the models ----------------------\nfor i in range(39):\n    p_bar.set_description('{}. Training \"{}\" Phoneme Model'.format(i,fc.get39Phon(i)))\n    models[i].fit(features[i],lengths[i])\n    p_bar.update()\n\n#### ------------- Saving Models --------------\ngc.collect()\nfor i in range(39):\n    filename = \"Model{}-{}.pkl\".format(i,fc.get39Phon(i))\n    file_handle = open('\/kaggle\/working\/{}'.format(filename),'wb')\n    pkl.dump(models[i],file_handle)\n    file_handle.close()\ngc.collect()","1dfcd553":"###------------collecting test features -------------------\ngc.collect()\nif os.path.exists(feature_path+'test_features.pkl'):\n    test_features = pkl.load(open(feature_path+'test_features.pkl','rb'))\n    test_lengths = pkl.load(open(feature_path+'test_lengths.pkl','rb'))\nelif os.path.exists(\"\/kaggle\/working\/test_features.pkl\"):\n    test_features = pkl.load(open(\"\/kaggle\/working\/test_features.pkl\",'rb'))\n    test_lengths = pkl.load(open(\"\/kaggle\/working\/test_lengths.pkl\",'rb'))\nelse:\n    test_features,test_lengths = fc.collectHMMFeatures(ft='Test',ftype=ftype,n_mels=n_mels,delta=delta,delta_delta=delta_delta)\n    pkl.dump(test_features,open('\/kaggle\/working\/test_features.pkl','wb'))\n    pkl.dump(test_lengths,open('\/kaggle\/working\/test_lengths.pkl','wb'))\ngc.collect()   ","ee7d521c":"##### ------------ Testing Models ---------------\nfor i in range(39):\n    # --- adding missing length at end\n    tfeat_len = test_features[i].shape[0]\n    tlen_len = np.sum(test_lengths[i])\n    if tfeat_len != tlen_len:\n        test_lengths[i].append(tfeat_len-tlen_len)\n\n'''\nfor i in range(39):\n    # merging single vector sample instance\n    tmp_length = []\n    prev_size = 0\n    for size in test_lengths[i]:\n        if prev_size < 4:\n            prev_size += size\n\n        if prev_size >= 4:\n            tmp_length.append(prev_size)\n            prev_size = 0\n    tmp_length.append(prev_size)\n    test_lengths[i] = tmp_length  \n'''\n\npredictions = []\nfor i in range(39):\n    #for each phon data\n    count = 0\n    s = 0\n    p_bar = tqdm(range(len(test_lengths[i])))\n    p_bar.set_description('{}. Testing Data of phoneme \"{}\" against all models'.format(i,fc.get39Phon(i)))\n    for j in test_lengths[i]:\n        # test in each phon model\n        max_prediction = -999999999999\n        max_index = 0\n        t_feat = test_features[i][s:j+s]\n        for k in range(39):\n            try:\n                score = math.floor(models[k].score(t_feat)*1000)\n                if(score > max_prediction):\n                    max_prediction = score\n                    max_index = k\n                if max_index > i:\n                    break\n            except:\n                continue\n                \n        p_bar.update() \n        count+= 1 if max_index == i else 0      \n        s=j\n        \n    predictions.append((count,len(test_lengths[i])))\n    \n    p_bar.set_description('{}. Testing Data of phoneme \"{}\" against all models \\nResult: {}\/{} correct prediction;\\n accuracy: {:.2f}%'.format(\n        i+1,fc.get39Phon(i),count,len(test_lengths[i]),(count\/len(test_lengths[i]))*100)\n    )\n    print('{}. Testing Data of phoneme \"{}\" against all models \\nResult: {}\/{} correct prediction;\\n accuracy: {:.2f}%'.format(\n        i+1,fc.get39Phon(i),count,len(test_lengths[i]),(count\/len(test_lengths[i]))*100)\n    )","c8405d40":"t_correct = 0\nt_length = 0\nfor x,y in predictions:\n    t_correct+=x\n    t_length+= y\n\nprint(\"Mean Accuracy is {:2f}%\".format((np.sum([x\/y for x,y in predictions])\/39)*100))\nprint(\"Total Accuracy is {:2f}%\".format((t_correct\/t_length)*100))\nprint('Individual Accuracy:')\nfor i in range(39):\n    x = predictions[i][0]\n    y = predictions[i][1]\n    print(f\"Accuracy of \\\"{fc.get39Phon(i)}\\\" Model: \",(x\/y)*100)","af83d465":"# Testing GMM-HMM model on TIMIT\n1. **FeatureCollector** class is copied from [ASR on TIMIT dataset using DNN](https:\/\/www.kaggle.com\/reganmaharjan\/asr-on-timit-data-set-using-dnn\/notebook).\n2. Some of the workflows are optimized in this version of FeatureCollector. On previous Notebook, this class is named CNN_ASR_MODULE_BUILDER\n3. Some of the functions are changed to meet the feature requirement for HMM. Separate function collectHMMFeatures() is created.\n4. It was found that some of the phonemes only had a single sampled instances. It is thought that this caused issue during model training. Thus samples from its neighbors are appended to it."}}