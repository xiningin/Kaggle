{"cell_type":{"24e4a748":"code","ed32acc1":"code","df769124":"code","1e460a4b":"code","75e5fa91":"code","db4fe3de":"code","ef12e823":"code","e855808b":"code","bbb9bf91":"code","c74662e0":"code","23c42f9f":"code","d58182a9":"code","c96d6bb2":"code","cc09a2c2":"code","63449da6":"code","43e8cfe2":"code","35b05120":"code","1100ac2c":"code","03ed4e3f":"code","38334c2c":"code","35a5bc47":"code","c81e878d":"code","6af5c503":"code","aa786b73":"code","22e14107":"code","7f4c0ab2":"code","4b748ca3":"code","5f33d88e":"code","cc540545":"code","04e23258":"code","8637e631":"code","a9fa0e29":"code","e56825d6":"markdown","effb8909":"markdown","dc695d0b":"markdown","f0b10de9":"markdown","0a49a474":"markdown","8e270d90":"markdown","2964c244":"markdown","9241ec16":"markdown","02a19dd8":"markdown","48e338e0":"markdown","25ad00f7":"markdown","59760b40":"markdown","7b172f9e":"markdown","35c894c4":"markdown","cee0c656":"markdown"},"source":{"24e4a748":"import warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy.stats as stats\nfrom sklearn.preprocessing import StandardScaler, OrdinalEncoder, LabelEncoder, OneHotEncoder\nfrom sklearn.preprocessing import PolynomialFeatures, PowerTransformer, FunctionTransformer\nfrom sklearn.model_selection import cross_val_score, cross_val_predict, StratifiedKFold, RandomizedSearchCV, StratifiedShuffleSplit\nfrom sklearn.feature_selection import SelectFromModel, SelectKBest, VarianceThreshold\nfrom sklearn.metrics import roc_auc_score, roc_curve, f1_score, accuracy_score, classification_report\nfrom sklearn.decomposition import PCA, FactorAnalysis, TruncatedSVD\nfrom sklearn.manifold import TSNE\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier, VotingClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\npd.set_option('display.max_columns', None)","ed32acc1":"train = pd.read_csv(\"\/kaggle\/input\/av-janatahack-crosssell-prediction\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/av-janatahack-crosssell-prediction\/test.csv\")\ntrain.drop('id', axis=1, inplace=True)\ntest.drop('id', axis=1, inplace=True)\nsample = pd.read_csv(\"\/kaggle\/input\/av-janatahack-crosssell-prediction\/sample.csv\")","df769124":"train.info()","1e460a4b":"train.head()","75e5fa91":"train.isna().sum()","db4fe3de":"test.isna().sum()","ef12e823":"for col in train.columns:\n    print(f\"{col} : {train[col].nunique()}\")\n    print(train[col].unique())","e855808b":"#separating continuous and categorical variables\ncat_var = [\"Gender\",\"Driving_License\",\"Previously_Insured\",\"Vehicle_Age\",\"Vehicle_Damage\"]\ncon_var = list(set(train.columns).difference(cat_var+[\"Response\"]))","bbb9bf91":"train.Response.value_counts(normalize=True)","c74662e0":"sns.countplot(train.Response)\nplt.title(\"Class count\")\nplt.show()","23c42f9f":"#sns.pairplot(train, hue='Response', diag_kind='hist')\n#plt.show()","d58182a9":"def map_val(data):\n    data[\"Gender\"] = data[\"Gender\"].replace({\"Male\":1, \"Female\":0})\n    data[\"Vehicle_Age\"] = data[\"Vehicle_Age\"].replace({'> 2 Years':2, '1-2 Year':1, '< 1 Year':0 })\n    data[\"Vehicle_Damage\"] = data[\"Vehicle_Damage\"].replace({\"Yes\":1, \"No\":0})\n    return data\n\ntrain = map_val(train)\ntest = map_val(test)","c96d6bb2":"fig, ax = plt.subplots(2,3 , figsize=(16,6))\nax = ax.flatten()\ni = 0\nfor col in cat_var:\n    sns.pointplot(col, 'Response', data=train, ax = ax[i])\n    i+=1\nplt.tight_layout()\nplt.show()","cc09a2c2":"sns.catplot('Gender', 'Response',hue='Vehicle_Age', row = 'Previously_Insured',col='Vehicle_Damage',data=train, kind='point', height=3, aspect=2)\nplt.show()","63449da6":"fig, ax = plt.subplots(2,3 , figsize=(16,6))\nax = ax.flatten()\ni = 0\nfor col in con_var:\n    sns.boxplot( 'Response', col, data=train, ax = ax[i])\n    i+=1\nplt.tight_layout()\nplt.show()","43e8cfe2":"sns.catplot('Gender', 'Vintage',hue='Response', row = 'Previously_Insured',col='Vehicle_Damage',data=train, kind='box', height=3, aspect=2)\nplt.show()","35b05120":"sns.catplot('Gender', 'Age',hue='Response', row = 'Previously_Insured',col='Vehicle_Damage',data=train, kind='box', height=3, aspect=2)\nplt.show()","1100ac2c":"sns.catplot('Gender', 'Annual_Premium',hue='Response', row = 'Previously_Insured',col='Vehicle_Damage',data=train, kind='box', height=3, aspect=2)\nplt.show()","03ed4e3f":"plt.figure(figsize=(30,5))\nsns.heatmap(pd.crosstab([train['Previously_Insured'], train['Vehicle_Damage']], train['Region_Code'],\n                        values=train['Response'], aggfunc='mean', normalize='columns'), annot=True, cmap='inferno')\nplt.show()","38334c2c":"corr = train.corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)]=True\nplt.figure(figsize=(10,6))\nsns.heatmap(corr, annot=True, fmt='.2f', cmap='YlGnBu', mask=mask)\nplt.title(\"Correlation Heatmap\")\nplt.show()","35a5bc47":"train.skew()","c81e878d":"train['log_premium'] = np.log(train.Annual_Premium)\ntrain['log_age'] = np.log(train.Age)\ntest['log_premium'] = np.log(test.Annual_Premium)\ntest['log_age'] = np.log(test.Age)","6af5c503":"train.groupby(['Previously_Insured','Gender'])['log_premium'].plot(kind='kde')\nplt.show()","aa786b73":"train.groupby(['Previously_Insured','Gender'])['log_age'].plot(kind='kde')\nplt.show()","22e14107":"def feature_engineering(data, col):\n    mean_age_insured = data.groupby(['Previously_Insured','Vehicle_Damage'])[col].mean().reset_index()\n    mean_age_insured.columns = ['Previously_Insured','Vehicle_Damage','mean_'+col+'_insured']\n    mean_age_gender = data.groupby(['Previously_Insured','Gender'])[col].mean().reset_index()\n    mean_age_gender.columns = ['Previously_Insured','Gender','mean_'+col+'_gender']\n    mean_age_vehicle = data.groupby(['Previously_Insured','Vehicle_Age'])[col].mean().reset_index()\n    mean_age_vehicle.columns = ['Previously_Insured','Vehicle_Age','mean_'+col+'_vehicle']\n    data = data.merge(mean_age_insured, on=['Previously_Insured','Vehicle_Damage'], how='left')\n    data = data.merge(mean_age_gender, on=['Previously_Insured','Gender'], how='left')\n    data = data.merge(mean_age_vehicle, on=['Previously_Insured','Vehicle_Age'], how='left')\n    data[col+'_mean_insured'] = data['log_age']\/data['mean_'+col+'_insured']\n    data[col+'_mean_gender'] = data['log_age']\/data['mean_'+col+'_gender']\n    data[col+'_mean_vehicle'] = data['log_age']\/data['mean_'+col+'_vehicle']\n    data.drop(['mean_'+col+'_insured','mean_'+col+'_gender','mean_'+col+'_vehicle'], axis=1, inplace=True)\n    return data\n\ntrain = feature_engineering(train, 'log_age')\ntest = feature_engineering(test, 'log_age')\n\ntrain = feature_engineering(train, 'log_premium')\ntest = feature_engineering(test, 'log_premium')\n\ntrain = feature_engineering(train, 'Vintage')\ntest = feature_engineering(test, 'Vintage')","7f4c0ab2":"X = train.drop([\"Response\"], axis=1)\nY = train[\"Response\"]","4b748ca3":"dummy = [\"Vehicle_Age\"]\npassthru = con_var = list(set(X.columns).difference(dummy))\n\nonehot = OneHotEncoder(handle_unknown='ignore')\nlabel = OrdinalEncoder()\nscaler = StandardScaler()\n\nfeat_rf = RandomForestClassifier(n_jobs=4, random_state=1, class_weight='balanced_subsample')\nfeat_xgb = XGBClassifier(n_jobs=4, random_state=1, objective='binary:logistic')\nselector_rf = SelectFromModel(feat_xgb, threshold=0.001)\n\ntransformers_onehot = [('pass','passthrough',passthru),\n                       ('onehot', onehot, dummy) ]\nct_onehot = ColumnTransformer( transformers=transformers_onehot )\n\ntransformers_label = [('pass','passthrough',passthru),\n                      ('onehot', label, dummy) ]\nct_label = ColumnTransformer( transformers=transformers_label )\n\npipe = Pipeline([('ct', ct_onehot),\n                 ('scaler', scaler)])","5f33d88e":"poly = PolynomialFeatures(degree= 2, interaction_only=True)\npca = PCA(n_components=0.99)\nkbest = SelectKBest(k=10)\n\npipe_pca = Pipeline([('ct', ct_onehot),\n                      ('poly', poly),\n                      ('scaler', scaler),\n                      ('pca',pca)])\n\npipe_kbest = Pipeline([('ct', ct_onehot),\n                       ('poly', poly),\n                       ('scaler', scaler),\n                       ('kbest',kbest)])\n\npipe_union = FeatureUnion([('pca',pipe_pca),\n                           ('kbest',pipe_kbest)])","cc540545":"# merging the PCA components and KBest features from the data\npipe_union.fit(X, Y)\nX_union = pipe_union.transform(X)\ntest_union = pipe_union.transform(test)\n#np.cumsum(pipe_union.transformer_list[0][1].named_steps['pca'].explained_variance_ratio_)","04e23258":"ct_onehot.fit(X)\ncategories = ct_onehot.named_transformers_['onehot'].categories_\nonehot_cols = [col+\"_\"+str(cat) for col,cats in zip(dummy, categories) for cat in cats]\nall_columns = passthru + onehot_cols\n\nX_transform = pd.DataFrame(pipe.fit_transform(X), columns = all_columns)\ntest_transform = pd.DataFrame(pipe.transform(test), columns = all_columns)\n\nselector_rf.fit(X_transform, Y)\nrf_cols = [col for col, flag in zip(X_transform.columns, selector_rf.get_support()) if flag]\nprint(rf_cols)\nX_select = pd.DataFrame(selector_rf.transform(X_transform), columns = rf_cols)\ntest_select = pd.DataFrame(selector_rf.transform(test_transform), columns = rf_cols)","8637e631":"from tpot import TPOTClassifier\nsplit = StratifiedKFold(n_splits=3, random_state=1)\nmodel = TPOTClassifier(generations=5, population_size=50, scoring='roc_auc', cv=split, verbosity=2, random_state=1, n_jobs=-1)\n\nmodel.fit(X_select, Y)","a9fa0e29":"model.export('tpot_cross_sell.py')","e56825d6":"- Males or customers with license or not previously insured or the vehicle was previously damaged have better response rate\n- With increasing vehicle age response improved","effb8909":"### Onehot and Feature selection Pipeline","dc695d0b":"### We can easily identify the regions where the response rate is high compared to others","f0b10de9":"### we can see that the data is imbalanced classification, hence we will not use accuracy as scoring metric. Instead we will use f1-score or more preferrably roc-auc","0a49a474":"### PCA + KBest pipeline output","8e270d90":"## Current Age\/ Vintage\/ Annual Premium distributions are not helping very much so we will try mean transformation","2964c244":"## Missing values check","9241ec16":"## Importing the libraries","02a19dd8":"- No missing values in the data. Will confirm the same using unique values","48e338e0":"## Preparing the data for training","25ad00f7":"### Customers who were not previously insured and their vehicle has been damaged have shown much better response, as expected","59760b40":"### Around 12.26 % of customer have given a positive response","7b172f9e":"## Train data head","35c894c4":"## Correlation Heatmap","cee0c656":"## If you find my Kernel useful, please do upvote. Any suggestions are welcome."}}