{"cell_type":{"f712faa7":"code","3cfddf84":"code","fb2c7b1b":"code","7458ae04":"code","294ff4a4":"code","edbd66e2":"code","f509eefe":"code","524e7c33":"code","0a7c1e1b":"code","6f79c5ab":"code","35f2576e":"code","2c2bb001":"code","382f402c":"code","b49791f6":"code","bb62889d":"code","500cf440":"code","6b104eff":"code","fd5a770c":"code","b563bca2":"code","404d4dff":"code","ef995208":"markdown","e9141ec8":"markdown","c83b03b0":"markdown","c0e86bfe":"markdown","fd61ff31":"markdown","15faf5f1":"markdown","5c0e156e":"markdown","d24e1aab":"markdown","f38e95f3":"markdown","d0396251":"markdown"},"source":{"f712faa7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","3cfddf84":"#import packages needed for data load, analysis and vis\nimport pandas as pd\nimport numpy as np\nfrom pandas.plotting import scatter_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#Data Preprocessing and Feature Engineering\nfrom textblob import TextBlob\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer #for sentiment analysis\n\n#import packages needed for model building\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\n\n%matplotlib inline","fb2c7b1b":"#train data and test data\nimport pandas as pd\nsample_submission = pd.read_csv(\"..\/input\/nlp-getting-started\/sample_submission.csv\")\ndf_train = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/train.csv\", sep=\",\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/test.csv\", sep=\",\")","7458ae04":"df_train.dtypes","294ff4a4":"df_train.head()","edbd66e2":"fig = plt.figure(figsize=(12, 6))\nax = fig.add_subplot(111)\n\nsns.countplot(df_train.target)\n\nplt.show()","f509eefe":"def remove_punctions(tweet):\n    tweet_blob = TextBlob(tweet)\n    return ' '.join(tweet_blob.words)\ndf_train['text'] = df_train.text.apply(remove_punctions)","524e7c33":"def get_noun_count(tweet):\n    tweet_blob = TextBlob(tweet)\n    noun_count = tweet_blob.noun_phrases\n    \n    return len(noun_count)","0a7c1e1b":"df_train['noun_count'] = df_train.text.apply(get_noun_count)","6f79c5ab":"##visualize\n#the result validated the hypothesis above\nfig = plt.figure(figsize=(12,5))\nax = fig.add_subplot(111)\nsns.boxplot(y = df_train['noun_count'], x=df_train['target'], ax=ax)\n\nplt.show()","35f2576e":"def sentiment_negpos(tweet):\n    vader_analyzer = SentimentIntensityAnalyzer()\n    vader_res = vader_analyzer.polarity_scores(tweet)\n    \n    neg = vader_res['neg']\n    pos = vader_res['pos']\n    neu = vader_res['neu']\n    \n    return (neg, pos, neu)","2c2bb001":"negpos_info = df_train.text.apply(sentiment_negpos)\ndf_train['neg'] = [negpos_info.values[x][0] for x in df_train.index]\ndf_train['neu'] = [negpos_info.values[x][1] for x in df_train.index]\ndf_train['pos'] = [negpos_info.values[x][2] for x in df_train.index]","382f402c":"#take a look at the features generated\ndf_train.head()","b49791f6":"##visualize\n#the result validated the hypothesis above\nfig = plt.figure(figsize=(12,5))\nax1 = fig.add_subplot(131)\nsns.boxplot(y = df_train['neg'], x=df_train['target'], ax=ax1)\n\nax2 = fig.add_subplot(132)\nsns.boxplot(y = df_train['neu'], x=df_train['target'], ax=ax2)\n\nax3 = fig.add_subplot(133)\nsns.boxplot(y = df_train['pos'], x=df_train['target'], ax=ax3)\n\nplt.show()","bb62889d":"#model building and accuracy check\n\ncols = ['noun_count', 'neg','neu','pos'] \nx = df_train[cols]\ny = df_train['target']\n# Build a logreg and compute the feature importances\nmodel_multilog = LogisticRegression()\n#fit\nmodel_multilog.fit(x, y)\n#predict\npredicted_target = model_multilog.predict(x)\n#accuracy check\nprint(\"Accuracy: %.3f\" % metrics.accuracy_score(y, predicted_target))\nprint(\"Precision: %.3f\" % metrics.precision_score(y, predicted_target))\nprint(\"Recall: %.3f\" % metrics.recall_score(y, predicted_target))\n\n#parameters = model_multilog.coef_","500cf440":"#Model Evaluation using Confusion Matrix\ncnf_matrix = metrics.confusion_matrix(y, predicted_target)\nclass_names=[0,1] # name  of classes\nfig = plt.figure(figsize=(12, 6))\nax = fig.add_subplot(111)\n\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\n# create heatmap\nsns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","6b104eff":"##Model Evaluation using ROC Curve\ny_pred_proba = model_multilog.predict_proba(x)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y,  y_pred_proba)\nauc = metrics.roc_auc_score(y, y_pred_proba)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","fd5a770c":"df_test","b563bca2":"#features generated\ndf_test['text'] = df_test.text.apply(remove_punctions)\ndf_test['noun_count'] = df_test.text.apply(get_noun_count)\nnegpos_info = df_test.text.apply(sentiment_negpos)\ndf_test['neg'] = [negpos_info.values[x][0] for x in df_test.index]\ndf_test['neu'] = [negpos_info.values[x][1] for x in df_test.index]\ndf_test['pos'] = [negpos_info.values[x][2] for x in df_test.index]","404d4dff":"sample_submission[\"target\"] = model_multilog.predict(df_test[cols])\n\nsample_submission.to_csv(\"submission.csv\", index=False)","ef995208":"# 1. Load data","e9141ec8":"### get count of noun words\nThe theory is when people tweet about a disaster or bad thing, they are more inclined to use verb instead of noun","c83b03b0":"# 2. Text processing using TextBlob\nGetting features from tweet texts","c0e86bfe":"### Function for Sentiment analysis\n\nIt is easy to understand that people are inclined to be negative instead of positive when disaster happens","fd61ff31":"*the code above takes time*","15faf5f1":"AUC score for the case is 0.70. need improvement. ","5c0e156e":"### removal of punctions","d24e1aab":"# 4. Finish the submission","f38e95f3":"# 3. Model building and evaluate\n\nAs presented above, we generated several features from text and show the differences between target 1 and 0.\nLet's build a Multinomial logistic regression model here to predict the test data.","d0396251":"Ref: https:\/\/towardsdatascience.com\/twitter-sentiment-analysis-classification-using-nltk-python-fa912578614c"}}