{"cell_type":{"e1369133":"code","2b8cb82b":"code","962207a3":"code","698167c6":"code","7f18b59c":"code","c7cc99f3":"code","a550dd6c":"code","b3d635f4":"code","2a8c0338":"code","e21d8061":"code","e126b3fd":"code","72975032":"code","81e92812":"code","3661353f":"code","ba54f643":"code","2ad4529d":"code","14d7e2be":"code","277e818a":"code","5d848297":"code","3f9b055e":"code","51bfd482":"code","600f573c":"code","00409493":"code","a0529a3e":"code","88e09800":"code","490ef91a":"code","1edfab09":"code","dad40c52":"code","bff27ef1":"code","17466e23":"markdown"},"source":{"e1369133":"import numpy as np \nimport pandas as pd \n","2b8cb82b":"import glob\nimport torch\nimport torchvision\nimport matplotlib.pyplot as plt\nimport PIL","962207a3":"train_meta = pd.read_csv('\/kaggle\/input\/petfinder-pawpularity-score\/train.csv')","698167c6":"train_meta.head()","7f18b59c":"img = np.random.choice(glob.glob('\/kaggle\/input\/*\/train\/*'))","c7cc99f3":"image = PIL.Image.open(img)","a550dd6c":"image","b3d635f4":"import os\n\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader","2a8c0338":"class PawDataset(Dataset):\n    def __init__(self, img_dir, label_file, transform=None):\n        super().__init__()\n        self.labels = pd.read_csv(label_file)\n        self.img_dir = img_dir\n        self.transform = transform\n        \n        \n    def __len__(self):\n        return len(self.labels)\n    \n    \n    def __getitem__(self, ind):\n        img_name, label = self.labels.loc[ind, ['Id', 'Pawpularity']]\n        label = label[None].astype(np.float32)\n        img = PIL.Image.open(os.path.join(self.img_dir, img_name + '.jpg'))\n            \n        image = np.array(img, dtype=np.float32) \/ 255\n        image = np.transpose(image, [2, 0, 1])\n        \n        if self.transform:\n            image = self.transform(img)\n            \n        return dict(\n            sample=image,\n            label=label\n        )\n        \n        \n        \n        ","e21d8061":"from torchvision.transforms import Compose, Resize, ToTensor, Normalize","e126b3fd":"transforms = torchvision.transforms.Compose(\n    [\n            Resize((224, 224)), \n            ToTensor(), \n            Normalize((0.5, 0.5, 0.5), (1, 1, 1)), \n        ]\n)","72975032":"label_file = '\/kaggle\/input\/petfinder-pawpularity-score\/train.csv'\nimg_dir = '\/kaggle\/input\/petfinder-pawpularity-score\/train'","81e92812":"purr_dataset_not_transformed = PawDataset(img_dir, label_file, transform=None)\npurr_dataset = PawDataset(img_dir, label_file, transform=transforms)","3661353f":"plt.imshow(purr_dataset_not_transformed[10]['sample'].transpose(1, 2, 0))","ba54f643":"plt.imshow(purr_dataset[10]['sample'].numpy().transpose(1, 2, 0))","2ad4529d":"purr_dataset_not_transformed[0]['sample'].shape","14d7e2be":"purr_dataset[0]['sample'].shape","277e818a":"len_dataset = len(purr_dataset)\nlen_dataset","5d848297":"train_set, test_set = torch.utils.data.random_split(\n    purr_dataset, \n    [int(0.8 * len_dataset), len_dataset- int(0.8 * len_dataset)]\n)","3f9b055e":"train_dataloader = DataLoader(train_set, batch_size=64, shuffle=True, pin_memory=True)\ntest_dataloader = DataLoader(test_set, batch_size=64, shuffle=False, pin_memory=True)","51bfd482":"train_set[0]['sample'].shape","600f573c":"example = next(iter(test_dataloader))\nexample['sample'].shape","00409493":"from torchvision.models import resnet18\n\nmodel = resnet18(pretrained=True)","a0529a3e":"for param in model.parameters():\n    param.requires_grad = False","88e09800":"model.fc = torch.nn.Linear(512, 1)","490ef91a":"from tqdm.notebook import tqdm","1edfab09":"criterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.fc.parameters(), lr=0.01)","dad40c52":"def train_one_epoch(model, optimizer, criterion, train_loader):\n    pbar = tqdm(train_loader)\n    model.train()\n    for sample in pbar:\n        imgs = sample['sample']\n        labels = sample['label']\n        prediction = model(imgs)\n        loss = criterion(prediction, labels)\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        pbar.set_description(f'Loss: {loss.data.numpy()}')\n\ndef test(model, optimizer, criterion, test_loader):\n    predictions = []\n    labels_list = []\n    pbar = tqdm(test_loader)\n    model.eval()\n    with torch.no_grad():\n        loss = 0\n        for sample in pbar:\n            imgs = sample['sample']\n            labels = sample['label']\n            prediction = model(imgs)\n            loss += ((prediction - labels) ** 2).sum()\n            labels = labels.numpy()\n            prediction = prediction.numpy()\n            predictions.append(prediction)\n            labels_list.append(labels)\n        predictions = np.concatenate(predictions)\n        labels_list = np.concatenate(labels_list)\n        print(f'Loss {(loss \/ len(test_loader) \/ test_loader.batch_size) ** 0.5}')\n\n\ndef train(model, optimizer, criterion, train_loader, test_loader, n_epochs):\n    for epoch in range(n_epochs):\n        train_one_epoch(model, optimizer, criterion, train_loader)\n\n        test(model, optimizer, criterion, test_loader)\n","bff27ef1":"#train(model, optimizer, criterion, train_dataloader, test_dataloader, 1)","17466e23":"### \u041d\u0430 \u044d\u0442\u043e \u0437\u0430\u0431\u0435\u0439\u0442\u0435 \u043f\u043e\u043a\u0430"}}