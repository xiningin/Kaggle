{"cell_type":{"72d378de":"code","537a07fb":"code","6d1740bc":"code","ee578f1d":"code","e8877d38":"code","ae35a9fb":"code","64a1cc8c":"code","067accae":"code","fec0a1f2":"code","16007b29":"code","d58c0d9a":"code","a2d7c60f":"code","7db64b1e":"code","0f37d947":"code","b1ca8800":"code","c8798c2e":"code","4abdd292":"code","76d1cdb9":"code","9614eff2":"code","c57ce7c2":"code","2ab25514":"code","5404e0a2":"code","9c19aebc":"code","a9d43b30":"code","fda1ff68":"code","50c77776":"code","85ee4e7e":"code","061a8f1f":"code","88ec916b":"code","0540f470":"code","641a5d4a":"code","dfd87c5a":"code","6c9c12ff":"code","0a7f7bf3":"code","d24d4dae":"code","4511233c":"code","d9887179":"code","95f1f009":"code","ad945170":"code","d63b2363":"code","cd11be95":"code","7297c73c":"code","2980ca25":"code","f5a87919":"code","a7480340":"code","e2d1d1f2":"code","e047c9cf":"code","d7904763":"code","efc8dbcd":"code","8e206b96":"code","7bd87c33":"code","92813f54":"code","8691cfa8":"code","dd009448":"code","d80ff837":"code","48324128":"code","71ca2181":"code","c04ba872":"code","9d7751dc":"code","9a34de81":"code","7b4e852a":"code","b7f22bc2":"code","2e788895":"code","617df1a9":"code","f1d19553":"code","0d5b7a4c":"code","b94dcd39":"code","e9376a68":"code","8995681b":"code","75e412d4":"code","792b1a76":"markdown","8caced57":"markdown","72c508f6":"markdown","fbf104bc":"markdown","11363e85":"markdown","6cc8991e":"markdown","3086495c":"markdown","85ccb03d":"markdown","3dff09fd":"markdown","ea65a326":"markdown","ebe7ae08":"markdown","7155ac13":"markdown","e8d1c20c":"markdown","ff3c4e92":"markdown","f8c56f67":"markdown","a12fce11":"markdown","a4c3327a":"markdown","57d81c0e":"markdown","2de56bba":"markdown","165af61e":"markdown","a3a8a68a":"markdown","3a75ac6b":"markdown","988b87a5":"markdown","c62c3009":"markdown","c806b4c6":"markdown","2e12b59f":"markdown","6abf948c":"markdown","12bad26c":"markdown","46c4efaa":"markdown","66f8a6a8":"markdown","669d479b":"markdown","87a4ba04":"markdown"},"source":{"72d378de":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","537a07fb":"import seaborn as sns\nimport matplotlib.pyplot as plt","6d1740bc":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier","ee578f1d":"test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntrain = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')","e8877d38":"train.head()","ae35a9fb":"train.info()","64a1cc8c":"test.info()","067accae":"train.columns","fec0a1f2":"sns.barplot(x=train['Pclass'], y=train['Survived'])","16007b29":"sns.barplot(x=train['Sex'], y=train['Survived'])","d58c0d9a":"survived = train[train['Survived'] == 1]\nnot_survived = train[train['Survived'] == 0]\n\nprint (\"Survived: %i (%.1f%%)\"%(len(survived), float(len(survived))\/len(train)*100.0))\nprint (\"Not Survived: %i (%.1f%%)\"%(len(not_survived), float(len(not_survived))\/len(train)*100.0))\nprint (\"Total: %i\"%len(train))","a2d7c60f":"train.Pclass.value_counts()","7db64b1e":"pclass_survived=train.groupby('Pclass').Survived.value_counts()\npclass_survived","0f37d947":"pclass_survived.unstack(level=0).plot(kind='bar', subplots=False)","b1ca8800":"pclass_average=train[['Pclass','Survived']].groupby(['Pclass'],as_index=False).mean()\npclass_average","c8798c2e":"pclass_average.plot(kind='bar',subplots=False)","4abdd292":"sns.barplot(x='Pclass',y='Survived',data=train)","76d1cdb9":"sns.barplot(x='Sex',y='Survived',data=train)","9614eff2":"sex_average=train[['Sex','Survived']].groupby(['Sex']).mean()\nsex_average","c57ce7c2":"sns.factorplot('Sex', 'Survived', hue='Pclass', size=4, aspect=2, data=train)","2ab25514":"sns.factorplot(x='Pclass', y='Survived', hue='Sex', col='Embarked', data=train)","5404e0a2":"train[['Embarked','Survived']].groupby(['Embarked']).mean()","9c19aebc":"sns.barplot(x='Embarked',y='Survived',data=train)","a9d43b30":"train[['Parch','Survived']].groupby(['Parch']).mean()","fda1ff68":"sns.barplot(x='SibSp', y='Survived', ci=None, data=train)","50c77776":"sns.heatmap(train.drop('PassengerId',axis=1).corr(), annot=True)","85ee4e7e":"combine=[train,test]\nfor dataset in combine:\n    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.')","061a8f1f":"train.head()","88ec916b":"pd.crosstab(train['Title'],train['Sex'])","0540f470":"for dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col', \\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Other')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()\n","641a5d4a":"title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Other\": 5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)","dfd87c5a":"train.head()","6c9c12ff":"for dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map({'female':1,'male':2}).astype(int)","0a7f7bf3":"train.head()","d24d4dae":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')","4511233c":"train.head()","d9887179":"train = pd.get_dummies(data=train, columns=['Embarked'], drop_first=True)\ntest = pd.get_dummies(data=test, columns=['Embarked'], drop_first=True)","95f1f009":"combine = [test,train]","ad945170":"train.head()","d63b2363":"for dataset in combine:\n    age_avg = dataset['Age'].mean()\n    age_std = dataset['Age'].std()\n    age_null_count = dataset['Age'].isnull().sum()\n    \n    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n    dataset['Age'] = dataset['Age'].astype(int)\n    \ntrain['AgeBand'] = pd.cut(train['Age'], 5)\n\nprint (train[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean())\n","cd11be95":"for dataset in combine:\n    dataset.loc[dataset['Age'] <= 16, 'Age']=0\n    dataset.loc[(dataset['Age']>16) & (dataset['Age']<=32),'Age']=1\n    dataset.loc[(dataset['Age']>32) & (dataset['Age']<=48),'Age']=2\n    dataset.loc[(dataset['Age']>48) & (dataset['Age']<=60),'Age']=3\n    dataset.loc[dataset['Age'] >60 , 'Age']=4","7297c73c":"train.head()","2980ca25":"for dataset in combine:\n    dataset['Fare']=dataset['Fare'].fillna(dataset['Fare'].median())","f5a87919":"train['FareBand'] = pd.qcut(train['Fare'], 4)\nprint (train[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean())","a7480340":"for dataset in combine:\n    dataset.loc[ dataset['Fare'] <= 8, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 8) & (dataset['Fare'] <= 13), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 13) & (dataset['Fare'] <= 30), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 30, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)","e2d1d1f2":"train_family=pd.Series(train['SibSp'] + train['Parch'], name ='Family')\ntest_family=pd.Series(test['SibSp'] + test['Parch'], name ='Family')\ntrain['Family']=train_family\ntest['Family']=test_family\nsns.barplot(x=train['Family'],y=train['Survived'])","e047c9cf":"combine=[train,test]","d7904763":"train.head()","efc8dbcd":"test.head()","8e206b96":"train = train.drop(['Name', 'SibSp', 'Parch', 'Ticket', 'Cabin', 'Family','PassengerId', 'AgeBand', 'FareBand'], axis=1)\ntest=test.drop(['Name', 'SibSp', 'Parch', 'Ticket', 'Cabin', 'Family'], axis=1)","7bd87c33":"test.head()","92813f54":"x=train.drop('Survived',axis=1)\ny=train['Survived']","8691cfa8":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nx_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=42)","dd009448":"log_reg = LogisticRegression()\nlog_reg.fit(x_train, y_train)\npreds = log_reg.predict(x_valid)\nlr=accuracy_score(preds, y_valid)\nprint(lr)","d80ff837":"gauss = GaussianNB()\ngauss.fit(x_train, y_train)\npreds = gauss.predict(x_valid)\nNB=accuracy_score(preds, y_valid)\nprint(NB)","48324128":"svc = SVC()\nsvc.fit(x_train, y_train)\npreds = svc.predict(x_valid)\nsvc=accuracy_score(preds, y_valid)\nprint(svc)","71ca2181":"perc = Perceptron()\nperc.fit(x_train, y_train)\npreds = perc.predict(x_valid)\nperc=accuracy_score(preds, y_valid)\nprint(perc)","c04ba872":"dtc = DecisionTreeClassifier()\ndtc.fit(x_train, y_train)\npreds = dtc.predict(x_valid)\ndtc=accuracy_score(preds, y_valid)\nprint(dtc)","9d7751dc":"rfc = RandomForestClassifier()\nrfc.fit(x_train, y_train)\npreds = rfc.predict(x_valid)\nrfc=accuracy_score(preds, y_valid)\nprint(rfc)","9a34de81":"knn = KNeighborsClassifier()\nknn.fit(x_train, y_train)\npreds = knn.predict(x_valid)\nknn=accuracy_score(preds, y_valid)\nprint(knn)","7b4e852a":"sgd = SGDClassifier()\nsgd.fit(x_train, y_train)\npreds = sgd.predict(x_valid)\nsgd=accuracy_score(preds, y_valid)\nprint(sgd)","b7f22bc2":"models = pd.Series(['LogisticRegression', 'GaussianNB', 'SVM', 'Perceptron',\n                   'DecisionTree', 'RandomForest', 'KNN', 'SGDClassifier', 'GradientBoostingClassifier'])\naccuracies = pd.Series([lr, NB, svc, perc, dtc, rfc, knn, sgd])\nscores = pd.DataFrame({'Model':models, 'Accuracies':accuracies}).sort_values(['Accuracies'], ascending=False)\nscores","2e788895":"from sklearn.model_selection import RandomizedSearchCV\n","617df1a9":"criterion=['gini', 'entropy']\nn_estimators = [100, 250, 500 ,1000]\nmin_samples_split = [2, 5, 10, 15, 100]\nmin_samples_leaf = [1, 2, 5, 10]\nmax_depth = [5,10,15,20]\n\nparams = {'n_estimators':n_estimators,\n         'min_samples_split':min_samples_split,\n         'min_samples_leaf':min_samples_leaf,\n         'max_depth':max_depth,\n         'criterion':criterion}\n\n\nrfc = RandomForestClassifier()\ngrid_search = RandomizedSearchCV(estimator=rfc, param_distributions=params, scoring='accuracy', n_iter=10,\n                                 cv=5, verbose=2, random_state=42, n_jobs=4)\ngrid_search.fit(x_train, y_train)\nprint(grid_search.best_score_)\nprint(grid_search.best_params_)","f1d19553":"n_neighbors = [5,8,11,14]\n\n\nparams = {'n_neighbors':n_neighbors}\n\n\nknn = KNeighborsClassifier()\ngrid_search = RandomizedSearchCV(estimator=knn, param_distributions=params, scoring='accuracy', n_iter=10,\n                                 cv=5, verbose=2, random_state=42, n_jobs=4)\ngrid_search.fit(x_train, y_train)\nprint(grid_search.best_score_)\nprint(grid_search.best_params_)","0d5b7a4c":"from sklearn.ensemble import GradientBoostingClassifier","b94dcd39":"xgb = GradientBoostingClassifier()\nxgb.fit(x_train, y_train)\npreds = xgb.predict(x_valid)\nxgb_acc = accuracy_score(preds, y_valid)\nprint(xgb_acc)","e9376a68":"\nlearning_rates = [0.001, 0.01, 0.1, 1]\nn_estimators = [100, 250, 500 ,1000]\nmin_samples_split = [2, 5, 10, 15, 100]\nmin_samples_leaf = [1, 2, 5, 10]\nmax_depth = [5,10,15,20]\n\nparams = {'learning_rate':learning_rates,\n         'n_estimators':n_estimators,\n         'min_samples_split':min_samples_split,\n         'min_samples_leaf':min_samples_leaf,\n         'max_depth':max_depth}\n\n\ngbc = GradientBoostingClassifier()\ngrid_search = RandomizedSearchCV(estimator=gbc, param_distributions=params, scoring='accuracy', n_iter=10,\n                                 cv=5, verbose=2, random_state=42, n_jobs=4)\ngrid_search.fit(x_train, y_train)\nprint(grid_search.best_score_)\nprint(grid_search.best_params_)","8995681b":"best_gbc = GradientBoostingClassifier(n_estimators=500, min_samples_split=5,\n                                 min_samples_leaf=10, max_depth=10, learning_rate=0.01)\nbest_rfc = RandomForestClassifier(n_estimators= 500, min_samples_split= 15, min_samples_leaf=1,\n                                  max_depth= 5, criterion= 'gini')\nbest_knn = KNeighborsClassifier(n_neighbors=11)\n\nmodels = [best_gbc, best_rfc, best_knn]\nfor model in models:\n    model.fit(x_train, y_train)\n    preds = model.predict(x_valid)\n    print(f'Accuracy = {accuracy_score(y_valid, preds)}')","75e412d4":"best_gbc.fit(x, y)\nids = test['PassengerId']\npreds = best_gbc.predict(test.drop('PassengerId', axis=1))\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': preds })\noutput.to_csv('gender_submission.csv', index=False)","792b1a76":"we divide the fare bands into 4 ","8caced57":"plot betwwen the siblings and survivers","72c508f6":"**Random Forest Classifier**","fbf104bc":"Information about our dataset","11363e85":"higher class passenge has higher chance of survival","6cc8991e":"as we see fare column has some missing values we fill those missing values with median","3086495c":"**Support Vector Machine**","85ccb03d":"plotting a bar plot between embarked and survived column","3dff09fd":"Females have more chance of survival as compared to thhat of men as we see in above barplot.","ea65a326":"**Perceptron**","ebe7ae08":"class 1 has more number of survivals as more paying passengers are put in priority for saving","7155ac13":"we have create dummy variables in embarked column as it contains categorical data","e8d1c20c":"**Gaussian NaiveBayes**","ff3c4e92":"we have combined the dataset both train and test ","f8c56f67":"import our dataset into the notebbok","a12fce11":"Traveling alone and traveling with family having size more than 3 has less survival chance","a4c3327a":"1.  we get the number of survived and not survived passenger from the train dataset.\n2. we have marked survived passenger as 1 and not survived as 0","57d81c0e":"**KNearestNeighobour**","2de56bba":"heatmap between all the entities and droping passengr id column as it dosent provide useful information","165af61e":"1. Age should be informative for our model - younger ones should have higher survival rates. My assumption is that they may physically be more capable to survive or maybe their parents heroicly sacrificed themselves to help their children.\n\n2. Pclass should be informative for our model - High class people may have connections and people who can keep them alive. Also, maybe their cabins are located closer to lifeboats (We want to keep more paying customers alive..)\n\n3. Fare should be informative - Paying more for a ticket could imply higher survival rate (higher location on the ship, or maybe closer to lifeboats).\n4. Sex could be informative - We've all seen Titanic! It's intuitive to think that men would heroicly die in order to save their women (especially if they were pregnant, but we don't really know that for sure) and therefore women are more likely to survive.\n\n5. SibSp & Parch - This one may be tricky and therefore requires exploration. Having family members with you on board could imply that there might be someone who would help you survive, but on the other hand someone who you would die saving. There may be a slight effect on which kind of family member you're travelling with but I've decided to look on the number of family members, rather than their kind so both columns will be merged to a 'Family' column.\n\n6. Cabin - There are many missing values. I've seen several approaches to fill this value but since this is my first notebook I'll drop it for now and return to it on later edits.","a3a8a68a":"plot a bar plot between pclass and survived column to check the surviving rate","3a75ac6b":"**SGDClassifier**","988b87a5":"use our best model from above ","c62c3009":"we have filled the missing values in embarked column ","c806b4c6":"look at the data first five rows of train dataset","2e12b59f":"**Decision Tree Classifier**","6abf948c":"plot a bar between sex and survived passengers","12bad26c":"Now for feature selection we will drop columns that are less informative for us in determining the survival chance.","46c4efaa":"we have replaced some uncommon title with others","66f8a6a8":"**Logistic Regression**","669d479b":"now we map age according to the age band","87a4ba04":"we have added one new coulumn of title in the dataset which is the extract of the name."}}