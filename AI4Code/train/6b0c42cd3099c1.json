{"cell_type":{"11b178c4":"code","b1fc6db1":"code","79200b7d":"code","fd8dcb12":"code","654c95f3":"code","b54cf13f":"code","5cc0277c":"code","8e9ccfdc":"code","9910c4ee":"code","1492fbe2":"code","4f1293e1":"markdown","e9008502":"markdown","d65a0e96":"markdown","c6058f3c":"markdown"},"source":{"11b178c4":"import pandas as pd\n\ndf = pd.read_csv('..\/input\/flights.csv', low_memory=False)\nprint('Dataframe dimensions:', df.shape)\n#____________________________________________________________\n# gives some infos on columns types and number of null values\ntab_info=pd.DataFrame(df.dtypes).T.rename(index={0:'column type'})\ntab_info=tab_info.append(pd.DataFrame(df.isnull().sum()).T.rename(index={0:'null values (nb)'}))\ntab_info=tab_info.append(pd.DataFrame(df.isnull().sum()\/df.shape[0]*100)\n                         .T.rename(index={0:'null values (%)'}))\ndf.info()\n#df = df.dropna()\n#df = df[['YEAR', 'MONTH', 'DAY', 'AIRLINE', 'FLIGHT_NUMBER', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT' ]].dropna()\ntab_info","b1fc6db1":"airports = pd.read_csv(\"..\/input\/airports.csv\")\nairports","79200b7d":"airlines = pd.read_csv(\"..\/input\/airlines.csv\")\nairlines","fd8dcb12":"pd.set_option('display.max_columns', 500)\ndf.head(10)","654c95f3":"df_Jan = df[df['MONTH'] == 1]\ndf_Jan","b54cf13f":"df_Jan['DATE'] = pd.to_datetime(df_Jan[['YEAR','MONTH', 'DAY']])","5cc0277c":"df_Jan_nocan = df_Jan[df_Jan['CANCELLED'] == 0]","8e9ccfdc":"df_Jan['CANCELLED'].unique()","9910c4ee":"df_Jan_nocan.isnull().sum().sort_values()","1492fbe2":"df_Jan_nocan[df_Jan_nocan['DEPARTURE_TIME'].isnull() == True]","4f1293e1":"## Tasks\n\n### Cleaning\n1. Given the large dataset, let's just work with the flights from January 2015th.\n2. Transform **YEAR, MONTH, DAY, DAY_OF_WEEK ** to datetime\n3. In the **SCHEDULED_DEPARTURE** variable, the hour of the take-off is coded as a float where the two first digits indicate the hour and the two last, the minutes. This format is not convenient and you should thus convert it. Finally, merge the take-off hour with the flight date.\n\n### Exploration\n\n1. Visualize and compare flight count per airline\n2. Visualize the average delay(take-off or landing) per airline\n3. Find out if there is a relation between airport and delays\n4. Temporal variability of delays\n\n### Modelling\t\n\n1. Predicting flight delays - per airline and all airports \n2. Predicting flight delays - all airline and all airports\n3. Is there a risk of overfitting, how to handle it?\n4. Model accuracy calculation\n","e9008502":"Each entry of the `flights.csv` file corresponds to a flight and we see that more than 5'800'000 flights have been recorded in 2015. These flights are described according to 31 variables. A description of these variables can be found [here](https:\/\/www.transtats.bts.gov\/DL_SelectFields.asp?Table_ID=236&DB_Short_Name=On-Time) and I briefly recall the meaning of the variables that will be used in this notebook:\n\n- **YEAR, MONTH, DAY, DAY_OF_WEEK**: dates of the flight <br\/>\n- **AIRLINE**: An identification number assigned by US DOT to identify a unique airline <br\/>\n- **ORIGIN_AIRPORT** and **DESTINATION_AIRPORT**: code attributed by IATA to identify the airports <br\/>\n- **SCHEDULED_DEPARTURE** and **SCHEDULED_ARRIVAL** : scheduled times of take-off and landing <br\/> \n- **DEPARTURE_TIME** and **ARRIVAL_TIME**: real times at which take-off and landing took place <br\/> \n- **DEPARTURE_DELAY** and **ARRIVAL_DELAY**: difference (in minutes) between planned and real times <br\/> \n- **DISTANCE**: distance (in miles)  <br\/>\n\nAn additional file of this dataset, the `airports.csv` file, gives a more exhaustive description of the airports:","d65a0e96":"Also, the `airlines.csv` file, gives a more exhaustive description of the airlines:","c6058f3c":"# **Case Study: Predicting flight delays**\nOriginally developed by Fabien Daniel (September 2017)\n\n## Overview of the dataset\nLet's read the file that contains the details of all the flights that occured in 2015. I output some informations concerning the types of the variables in the dataframe and the quantity of null values for each variable:"}}