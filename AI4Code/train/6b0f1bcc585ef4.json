{"cell_type":{"37bfe7a7":"code","ce16c2c7":"code","90dcc638":"code","44df403c":"code","78888467":"code","9fe422d6":"code","ee02ab7d":"code","ce2e7690":"code","378294a9":"code","3a051466":"code","1a65a4ec":"code","624fbf1f":"code","7a747476":"code","6ddf2e8c":"code","7b22c5e7":"code","898fd22b":"code","64787fd3":"code","78c22efc":"code","6bfe507d":"code","85f37c58":"code","97ffd4a5":"code","f4c7af17":"code","3207b8c4":"code","c559f40c":"code","9224b323":"code","0666e77c":"code","2c7f1cb2":"code","f5a0a105":"code","a3ccff2c":"code","ff5e9f72":"code","cfe1f6ea":"code","465b1e94":"code","c842e5d8":"code","812f14c2":"code","5215f0d5":"code","82223eb6":"code","b7920cb3":"code","e9770a93":"code","86bab0e5":"code","72039bd7":"code","63a4c1b7":"code","946b0a2e":"code","052c80f4":"code","dd0f7696":"code","1b7d0d63":"code","7d846a13":"code","b5845059":"code","bd450626":"code","23d717b8":"code","7ed4ca4a":"code","b4599e7d":"code","bbdcd01d":"code","95bdc993":"code","1ad95b0b":"code","ad4968bf":"code","e67c5053":"code","cdae8645":"code","4aee9570":"code","62af2f0a":"code","a9bebe4e":"code","94c3f6cf":"code","92fbb5f9":"code","83723ba2":"code","42f3a1b8":"code","dbeeb628":"code","23ca92be":"code","03bb1aa7":"code","5bee8a77":"code","f7e63d46":"code","047c805c":"markdown"},"source":{"37bfe7a7":"# Let's get all the relevant libraries\n\n# Data Managment  \nimport numpy as np\nimport pandas as pd\nimport os\nimport cv2 \nimport json \nfrom glob import glob\nfrom PIL import Image\n\n# Dicom readers \nimport pydicom \nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\n# Plotting and Vizualization \nimport seaborn as sns \nimport matplotlib.pyplot as plt\n\n# Miscellaneous \nfrom tqdm.auto import tqdm\n\n#Torch \nimport torch ","ce16c2c7":"IMG_SIZE = 512\nBATCH_SIZE = 16\nEPOCHS = 40","90dcc638":"os.listdir('\/kaggle\/input\/siim-covid19-detection')","44df403c":"dataset = '\/kaggle\/input\/siim-covid19-detection'","78888467":"train_study_df = pd.read_csv(dataset + '\/train_study_level.csv')\ntrain_study_df ","9fe422d6":"train_image_df = pd.read_csv(dataset + '\/train_image_level.csv')\ntrain_image_df","ee02ab7d":"print(\"There are {} images with no bounding boxes in the dataset\"\n                      .format(train_image_df[\"boxes\"].isna().sum()))","ce2e7690":"train_image_df[\"label\"]\n\n# Let's have a look at the labels: the opacity or none class\n# opacity means that the image contains a bouding box, no means that there is no such box. \n# Then, the last 4 numbers correspond to the coordinates of the box, in the following format: \n# xmin ymin xmax ymax \n# and if the class is non, the values are 0 0 1 1 ","378294a9":"# Let's get an idea of what is asked in the submission file\n\nsubmission_df = pd.read_csv(dataset + '\/sample_submission.csv')\nprint(submission_df.shape)\nfor i in range(10): \n    print(submission_df.loc[i,:])\n    \n# We need to return, for each study in the test dataset, and Predicition String that include\n# the opaque or none label (or, disease or no disease) and if opaque, the values of all coordinates ","3a051466":"# The train_study file also fives use, for each study, which kind of Pneumonia is \n# associated with the patients.\n\n# Let's plot each subtypes \nsubtypes = train_study_df.groupby(['Negative for Pneumonia', 'Typical Appearance',\n       'Indeterminate Appearance', 'Atypical Appearance']).count().reset_index()\nsubtypes[\"label\"] = ['Atypical Appearance', 'Indeterminate Appearance',\n               'Typical Appearance', 'Negative for Pneumonia']\n\nax = plt.subplots(figsize=(21,10))\nax = sns.barplot(x=subtypes.label, y=subtypes.id, palette=\"deep\", orient='v')","1a65a4ec":"#Let's see the distribution between opacity and none \nclass_df = train_image_df[\"label\"].apply(lambda x: x.split(\" \")[0]).value_counts().reset_index()\nclass_df\nsns.barplot(x=class_df.label, y=[\"opacity\",\"none\"], palette=\"deep\", orient='h')","624fbf1f":"# Now let's create a column with the study_ids, to make life a bit easier \ntrain_study_df[\"study_id\"] = train_study_df[\"id\"].apply(lambda x: x.split(\"_\")[0])\ntrain_study_df","7a747476":"# Let's create a final train dataframe with all the information \ntrain = pd.merge(train_image_df, train_study_df, \n                 left_on=\"StudyInstanceUID\", right_on=\"study_id\")\ntrain.drop([ \"StudyInstanceUID\", \"id_y\"], axis=1, inplace=True)\ntrain","6ddf2e8c":"train.sort_values('study_id')","7b22c5e7":"train = train.rename(columns={\"id_x\":\"id\"})","898fd22b":"# Make a list of all the paths for all the images \ndicom_paths = glob(f'{dataset}\/train\/*\/*\/*.dcm')","64787fd3":"test_df = pd.read_csv(dataset + '\/sample_submission.csv')","78c22efc":"test_df","6bfe507d":"test_path = glob(f'{dataset}\/test\/*\/*\/*.dcm')","85f37c58":"test_dcm = pd.DataFrame({'dcm_path':test_path})\ntest_dcm['id']  = test_dcm.dcm_path.map(lambda x: x.split('\/')[-1].replace('.dcm','_image'))\ntest_dcm","97ffd4a5":"# Get a Dataframe that includes the path \ndcm_df = pd.DataFrame({'dcm_path':dicom_paths})\ndcm_df['id'] = dcm_df.dcm_path.map(lambda x: x.split('\/')[-1].replace('.dcm','_image'))\ndcm_df","f4c7af17":"# Merge both dataframe to have the paths in the train DataFrame \ntrain = train.merge(dcm_df, on='id', how='left')\ntrain","3207b8c4":"# Merge both dataframe to have the paths in the train DataFrame \ntest = test_df.merge(test_dcm, on='id', how='left')\ntest","c559f40c":"test = test.dropna()","9224b323":"test","0666e77c":"train_dev = train[:200]\ntrain_dev","2c7f1cb2":"valid_dev = train[-100:]\nvalid_dev","f5a0a105":"# The dicom to array function simply reads the dicom image, and returns a numpy array\n# Then, the plot_img and plot_imgs functions can plot one or several images\n\n\ndef dicom2array(path, voi_lut=True, fix_monochrome=True):\n    dicom = pydicom.read_file(path)\n    if voi_lut: \n        array = apply_voi_lut(dicom.pixel_array, dicom)\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        array = np.amax(array) - array\n    array = array - np.min(array)\n    array = array \/ np.max(array)\n    array = (array * 255).astype(np.uint8)\n    return array\n\ndef plot_img(img, size=(7, 7), is_rgb=True, title=\"\", cmap='gray'):\n    plt.figure(figsize=size)\n    plt.imshow(img, cmap=cmap)\n    plt.suptitle(title)\n    plt.show()\n\n\ndef plot_imgs(imgs, cols=4, size=7, is_rgb=True, title='',cmap='gray', img_size=(512,512)):\n    rows = len(imgs)\/\/cols + 1 \n    print(rows)\n    fig = plt.figure(figsize=(cols*size, rows*size))\n    for i, img in enumerate(imgs):\n        if img_size is not None: \n            img = cv2.resize(img, img_size)\n        fig.add_subplot(rows, cols, i+1)\n        plt.imshow(img, cmap=cmap)\n    plt.suptitle(title)\n    plt.show()\n","a3ccff2c":"# Let's look at one image \nimg = dicom2array(dicom_paths[20])\nplot_img(img)","ff5e9f72":"# Let's look at several images \n\nimgs = [dicom2array(path) for path in dicom_paths[:4]]\nplot_imgs(imgs)","cfe1f6ea":"# Let's make some bounding boxes, to visualize the task \n# The function plot_bboxes_with_label takes as imput a label, n images, and plots\n# n number of images from the corresping label with the boxes associated \n\n# while I know that in this project, the positive classes for COVID should be green, and every\n# thing else yellow. \n# I will keep it that was for development sake, and we will see later on\n\n# Credits to:  https:\/\/www.kaggle.com\/piantic\/siim-fisabio-rsna-covid-19-detection-basic-eda\n\nfrom colorama import Fore, Back, Style\n\nlabel2color = {\n    '[1, 0, 0]': [255,0,0], # Typical Appearance\n    '[0, 1, 0]': [0,255,0], # Indeterminate Appearance\n    '[0, 0, 1]': [0,0,255], # Atypical Appearance\n    '[0, 0, 0]': None, # negative\n}\n\nclass_names = ['Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']\n\ndef plot_bboxes_with_label(label_name, n): \n    print('Typical Appearance: ' + Fore.RED + 'Red',Style.RESET_ALL)\n    print('Indeterminate Appearance: '  + Fore.GREEN + 'Green',Style.RESET_ALL)\n    print('Atypical Appearance: ' + Fore.BLUE + 'Blue',Style.RESET_ALL)\n    \n    imgs = []\n    \n    thickness = 2 \n    scale = 5 \n    \n    if label_name == \"Negative for Pneumonia\": \n        flag = 0\n    else: \n        flag = 1\n    \n    for _, row in train[train[label_name]==flag].iloc[:n].iterrows():\n        # _ is the index, row is well, the row \n        study_id=row['study_id'] # get the study ids \n        img_path = glob(f'{dataset}\/train\/{study_id}\/*\/*')[0] # get all the path, \n        img = dicom2array(img_path)\n        img = cv2.resize(img, None, fx=1\/scale, fy=1\/scale)\n        img = np.stack([img, img, img], axis=-1)\n        \n        claz = row[class_names].values\n        color = label2color[str(claz.tolist())]\n\n        bboxes = []\n        bbox = []\n        \n        for i, l in enumerate(row['label'].split(' ')): \n            # i is index, l the label\n            if (i % 6 == 0) | (i % 6 == 1):\n                continue\n            bbox.append(float(l)\/scale)\n            if i % 6 == 5: \n                bboxes.append(bbox)\n                bbox = []\n        for box in bboxes: \n            img = cv2.rectangle(\n                img,\n                (int(box[0]), int(box[1])),\n                (int(box[2]), int(box[3])),\n                color, thickness\n            )\n        img = cv2.resize(img, (512,512))\n        imgs.append(img)\n    \n    plot_imgs(imgs, cmap=None)\n    \n    del img, imgs, bbox, bboxes","465b1e94":"# This cell will print several images with bounding box\n# You can change the label to print different images from differnt categories \nplot_bboxes_with_label(\"Negative for Pneumonia\", 4)","c842e5d8":"os.makedirs('\/kaggle\/working\/tmp\/', exist_ok=True)","812f14c2":"%cd \/kaggle\/working\/tmp","5215f0d5":"!git clone https:\/\/github.com\/ultralytics\/yolov5","82223eb6":"%cd yolov5\n!pip install -r requirements.txt","b7920cb3":"%ls","e9770a93":"os.makedirs('data\/images\/train', exist_ok=True)\nos.makedirs('data\/images\/valid', exist_ok=True)\n\nos.makedirs('data\/labels\/train', exist_ok=True)\nos.makedirs('data\/labels\/valid', exist_ok=True)\n","86bab0e5":"%cd data","72039bd7":"# Create .yaml file \nimport yaml\n\ndata_yaml = dict(\n    train = '\/kaggle\/working\/tmp\/yolov5\/data\/images\/train',\n    val = '\/kaggle\/working\/tmp\/yolov5\/data\/images\/valid',\n    nc = 2,\n    names = ['none', 'opacity']\n)\n\n# Note that I am creating the file in the yolov5\/data\/ directory.\nwith open('\/kaggle\/working\/tmp\/yolov5\/data\/data.yaml', 'w') as outfile:\n    yaml.dump(data_yaml, outfile, default_flow_style=True)\n    \n%cat \/kaggle\/working\/tmp\/yolov5\/data\/data.yaml","63a4c1b7":"from PIL import Image\ndim0 = []\ndim1 = []\ndef resize_and_save(end_path, df):\n    dim0 = []\n    dim1 = []\n    filenames = []\n    for index, row in tqdm(df[['study_id', 'dcm_path']].iterrows(), total = df.shape[0]):\n        try: \n            array = dicom2array(row['dcm_path'])\n            dim0.append(array.shape[0])\n            dim1.append(array.shape[1])\n            img = cv2.resize(array, (IMG_SIZE,IMG_SIZE))\n            img = Image.fromarray(img)\n   \n            filename = row['dcm_path'].split('\/')[-1].split('.')[0]\n            filenames.append(filename)\n            img.save(os.path.join(end_path, f'{filename}.png'))\n        except RuntimeError:\n            pass\n    return pd.DataFrame({'dim0':dim0, 'dim1': dim1, 'id': filenames})\n        #return filename.replace('dcm','') + '_image', array.shape[0], array.shape[1]","946b0a2e":"# Let's save the image in a new file for training \n\ndims_train = resize_and_save('\/kaggle\/working\/tmp\/yolov5\/data\/images\/train\/', train_dev)\ndims_valid = resize_and_save('\/kaggle\/working\/tmp\/yolov5\/data\/images\/valid\/', valid_dev)","052c80f4":"#Let's change the train dataframe to include the name with png\ntrain['id'] = train['id'].apply(lambda x: x.replace('_image','.png'))\n\ntrain_dev['id'] = train_dev['id'].apply(lambda x: x.replace('_image','.png'))\n\nvalid_dev['id'] = valid_dev['id'].apply(lambda x: x.replace('_image','.png'))\nvalid_dev","dd0f7696":"dims_valid['id'] = dims_valid['id'].astype(str) + '.png'\ndims_train['id'] = dims_train['id'].astype(str) + '.png'\ndims_train","1b7d0d63":"train_dev = train_dev.merge(dims_train, on='id', how='left')\nvalid_dev = valid_dev.merge(dims_valid, on='id', how='left')","7d846a13":"train_dev","b5845059":"# Get the raw bounding box by parsing the row value of the label column.\n# Ref: https:\/\/www.kaggle.com\/yujiariyasu\/plot-3positive-classes\ndef get_bbox(row):\n    bboxes = []\n    bbox = []\n    for i, l in enumerate(row.label.split(' ')):\n        if (i % 6 == 0) | (i % 6 == 1):\n            continue\n        bbox.append(float(l))\n        if i % 6 == 5:\n            bboxes.append(bbox)\n            bbox = []  \n            \n    return bboxes\n\n# Scale the bounding boxes according to the size of the resized image. \ndef scale_bbox(row, bboxes):\n    # Get scaling factor\n    scale_x = IMG_SIZE\/row.dim1\n    scale_y = IMG_SIZE\/row.dim0\n    \n    scaled_bboxes = []\n    for bbox in bboxes:\n        x = int(np.round(bbox[0]*scale_x, 4))\n        y = int(np.round(bbox[1]*scale_y, 4))\n        x1 = int(np.round(bbox[2]*(scale_x), 4))\n        y1= int(np.round(bbox[3]*scale_y, 4))\n\n        scaled_bboxes.append([x, y, x1, y1]) # xmin, ymin, xmax, ymax\n        \n    return scaled_bboxes\n\n# Convert the bounding boxes in YOLO format.\ndef get_yolo_format_bbox(img_w, img_h, bboxes):\n    yolo_boxes = []\n    for bbox in bboxes:\n        w = bbox[2] - bbox[0] # xmax - xmin\n        h = bbox[3] - bbox[1] # ymax - ymin\n        xc = bbox[0] + int(np.round(w\/2)) # xmin + width\/2\n        yc = bbox[1] + int(np.round(h\/2)) # ymin + height\/2\n        \n        yolo_boxes.append([xc\/img_w, yc\/img_h, w\/img_w, h\/img_h]) # x_center y_center width height\n    \n    return yolo_boxes","bd450626":"train_dev['image_level'] = train_dev.apply(lambda x: x.label.split(' ')[0], axis=1)\ntrain_dev['id'] = train_dev['id'].apply(lambda x: x.replace('.png', '.txt'))\n\nvalid_dev['image_level'] = valid_dev.apply(lambda x: x.label.split(' ')[0], axis=1)\nvalid_dev['id'] = valid_dev['id'].apply(lambda x: x.replace('.png', '.txt'))","23d717b8":"# Prepare the txt files for bounding box\n\n\nfor i in tqdm(range(len(train_dev))):\n    row = train_dev.loc[i]\n    # Get image id\n    img_id = row.id\n    # Get image-level label\n    label = row.image_level\n    \n\n    file_name = f'\/kaggle\/working\/tmp\/yolov5\/data\/labels\/train\/{row.id}'\n        \n    try: \n        if label=='opacity':\n            # Get bboxes\n            bboxes = get_bbox(row)\n            # Scale bounding boxes\n            scale_bboxes = scale_bbox(row, bboxes)\n            # Format for YOLOv5\n            yolo_bboxes = get_yolo_format_bbox(IMG_SIZE, IMG_SIZE, scale_bboxes)\n        \n        \n            with open(file_name, 'w') as f:\n                for bbox in yolo_bboxes:\n                    \n                    bbox = [1]+bbox\n                    bbox = [str(i) for i in bbox]\n                    bbox = ' '.join(bbox)\n                    f.write(bbox)\n                    f.write('\\n')\n    except ValueError: \n        pass","7ed4ca4a":"for i in tqdm(range(len(valid_dev))):\n    row = valid_dev.loc[i]\n    # Get image id\n    img_id = row.id\n    # Get image-level label\n    label = row.image_level\n    \n\n    file_name = f'\/kaggle\/working\/tmp\/yolov5\/data\/labels\/valid\/{row.id}'\n        \n    try: \n        if label=='opacity':\n            # Get bboxes\n            bboxes = get_bbox(row)\n            # Scale bounding boxes\n            scale_bboxes = scale_bbox(row, bboxes)\n            # Format for YOLOv5\n            yolo_bboxes = get_yolo_format_bbox(IMG_SIZE, IMG_SIZE, scale_bboxes)\n        \n        \n            with open(file_name, 'w') as f:\n                for bbox in yolo_bboxes:\n                    \n                    bbox = [1]+bbox\n                    bbox = [str(i) for i in bbox]\n                    bbox = ' '.join(bbox)\n                    f.write(bbox)\n                    f.write('\\n')\n    except ValueError: \n        pass","b4599e7d":"%cd \/kaggle\/working\/tmp\/yolov5\/data\/labels\/train\n%ls","bbdcd01d":"# Let's verify that this is what we want \n\nf = open('000a312787f2.txt', 'r')\ncontent = f.read()\nf.close\nprint(content)\n","95bdc993":"# Install W&B, login into your account and paste the API key \n\n# A note here: You can create and wandb account and login by uncommenting the last line of this \n# cell. This will save the run on your account, and allow you to vizualise the results very\n# easily, and give you access to several valuable options and tools \n!pip install -q --upgrade wandb\n# Login \nimport wandb\n#wandb.login()","1ad95b0b":"# If you are running the model while being logged in a wandb account, remove the \n# calling \"WANDB_MODE=\"dryrun\" \n%cd \/kaggle\/working\/tmp\/yolov5\n!WANDB_MODE=\"dryrun\" python train.py --img {IMG_SIZE} \\\n                 --batch {BATCH_SIZE} \\\n                 --epochs {EPOCHS} \\\n                 --data data.yaml \\\n                 --weights yolov5s.pt \\\n                # --save_period 1\\\n                 --project kaggle-siim-covid","ad4968bf":"plt.figure(figsize=(30,15))\nplt.axis('off')\nplt.imshow(plt.imread('\/kaggle\/working\/tmp\/yolov5\/runs\/train\/exp\/confusion_matrix.png'));","e67c5053":"%cd \/kaggle\/working\/tmp\/yolov5\/runs\/train\/exp\n%ls","cdae8645":"# This shows a batch of the validation data with the corresponding label \nplt.figure(figsize=(15,15))\nplt.imshow(plt.imread('val_batch0_labels.jpg'))","4aee9570":"plt.imshow(plt.imread('R_curve.png'))","62af2f0a":"plt.imshow(plt.imread('P_curve.png'))","a9bebe4e":"# This prints all the results curves \nplt.figure(figsize=(20,30))\nplt.imshow(plt.imread('results.png'))","94c3f6cf":"# The weights are stored here, and could be used for inference \n%cd \/kaggle\/working\/tmp\/yolov5\/kaggle-siim-covid\/exp\/weights\n%ls","92fbb5f9":"weights = '\/kaggle\/working\/tmp\/yolov5\/kaggle-siim-covid\/exp\/weights\/best.pt'","83723ba2":"%cd \/kaggle\/working\/tmp\/yolov5\/data\/images","42f3a1b8":"os.makedirs('test', exist_ok=True)","dbeeb628":"def save_test(end_path, df):\n\n    filenames = []\n    for index, row in tqdm(df[['id', 'dcm_path']].iterrows(), total = df.shape[0]):\n        try: \n            array = dicom2array(row['dcm_path'])\n            img = cv2.resize(array, (IMG_SIZE,IMG_SIZE))\n            img = Image.fromarray(img)\n   \n            filename = row['dcm_path'].split('\/')[-1].split('.')[0]\n            filenames.append(filename)\n            img.save(os.path.join(end_path, f'{filename}.png'))\n        except RuntimeError:\n            pass\n        #return filename.replace('dcm','') + '_image', array.shape[0], array.shape[1]","23ca92be":"# We save the test images in a new folder; not all the images are necessary, you can make this smaller by cutting the dataframe\nsave_test('test', test)","03bb1aa7":"%cd \/kaggle\/working\/tmp\/yolov5","5bee8a77":"# This makes all the necessary predicitions \n\n!python detect.py --weights \/kaggle\/working\/tmp\/yolov5\/kaggle-siim-covid\/exp\/weights\/best.pt \/kaggle\/working\/tmp\/yolov5\/kaggle-siim-covid\/exp\/weights\/last.pt --img 512 --source data\/images\/test","f7e63d46":"%cd \/kaggle\/working\/tmp\/yolov5\/runs\/detect\/\n%ls\ndirectory = os.listdir('exp')\nplt.figure(figsize=(15,15))\nfor i, file in enumerate((directory)[0:5]):\n    img = plt.imread('exp\/' + file)\n    plt.subplot(2, 3, i+1)\n    plt.imshow(img)\n    ","047c805c":"# Now let's clone the model and save the images in a different directories for future use "}}