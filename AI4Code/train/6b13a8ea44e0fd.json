{"cell_type":{"f18b71c9":"code","4be14c2e":"code","5de09f09":"code","11f061e2":"code","45447f8e":"code","e3b657a1":"code","a9120508":"code","8016cccf":"code","957739c5":"code","bd937c16":"code","0f9eb606":"code","7194b251":"code","96efe4e6":"code","f3adfe8e":"code","7174bad9":"code","32fbf6dd":"code","e4299dcf":"code","726e2985":"markdown","9fddc527":"markdown"},"source":{"f18b71c9":"# import packages\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport spacy\nimport nltk\nimport re\n\nimport string\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\n# print any variable\/statement on its own line (not just the last one!)\n#from IPython.core.interactiveshell import InteractiveShell\n#InteractiveShell.ast_node_interactivity = \"all\"\n\nnp.random.seed(27)","4be14c2e":"# setting up default plotting parameters\n%matplotlib inline\n\nplt.rcParams['figure.figsize'] = [20.0, 7.0]\nplt.rcParams.update({'font.size': 22,})\n\nsns.set_palette('viridis')\nsns.set_style('white')\nsns.set_context('talk', font_scale=0.8)","5de09f09":"# load in data and print shape\/head\/tail\nraw_data = pd.read_csv('..\/input\/train.csv')\nprint(raw_data.shape)\nraw_data.head()","11f061e2":"# using seaborns countplot to show distribution of questions in dataset\nfig, ax = plt.subplots()\ng = sns.countplot(raw_data.target, palette='viridis')\ng.set_xticklabels(['Sincere', 'Insincere'])\ng.set_yticklabels([])\n\n# function to show values on bars\ndef show_values_on_bars(axs):\n    def _show_on_single_plot(ax):        \n        for p in ax.patches:\n            _x = p.get_x() + p.get_width() \/ 2\n            _y = p.get_y() + p.get_height()\n            value = '{:.0f}'.format(p.get_height())\n            ax.text(_x, _y, value, ha=\"center\") \n\n    if isinstance(axs, np.ndarray):\n        for idx, ax in np.ndenumerate(axs):\n            _show_on_single_plot(ax)\n    else:\n        _show_on_single_plot(axs)\nshow_values_on_bars(ax)\n\nsns.despine(left=True, bottom=True)\nplt.xlabel('')\nplt.ylabel('')\nplt.title('Distribution of Questions', fontsize=30)\nplt.tick_params(axis='x', which='major', labelsize=15)\nfig.savefig('classes.png')\nplt.show()","45447f8e":"# print percentage of questions where target == 1\n(len(raw_data.loc[raw_data.target==1])) \/ (len(raw_data.loc[raw_data.target == 0])) * 100","e3b657a1":"# printing out a random sample of questions labeled insincere\nimport random\n\nindex = random.sample(raw_data.index[raw_data.target == 1].tolist(), 5)\nfor i in index:\n    print(raw_data.iloc[i, 1])","a9120508":"# taking a sample of the training data to speed up processing\ndf = raw_data.sample(frac=0.3)\ndf.shape","8016cccf":"# tokenize with spacy\nnlp = spacy.load('en')\n\ndf['tokens'] = [nlp(text, # disable parts of the language processing pipeline we don't need here to speed up processing\n                    disable=['ner', # named entity recognition\n                                   'tagger', # part-of-speech tagger\n                                   'textcat', # document label categorizer\n                                  ]) for text in df.question_text]\ndf.sample(5)","957739c5":"df['num_tokens'] = [len(token) for token in df.tokens]\ndf.sample(5)","bd937c16":"# using seaborns boxplot to visualize number of tokens per question\nfig, ax = plt.subplots()\ng = sns.boxplot(x=df.target, y=df.num_tokens, palette='viridis')\ng.set_xticklabels(['Sincere', 'Insincere'])\ng.set_yticklabels([])\n\nsns.despine(left=True, bottom=True)\nplt.xlabel('')\nplt.ylabel('')\nplt.title('Number of Tokens per Question', fontsize=30)\nplt.tick_params(axis='x', which='major', labelsize=15)\nfig.savefig('tokens.png')\nplt.show()","0f9eb606":"# get number of sentences per question\nprint(list(df.iloc[0,3].sents))\n\nsents = [list(x.sents) for x in df.tokens]\ndf['num_sents'] = [len(sent) for sent in sents]\ndf.sample(5)","7194b251":"# plotting number of sentences per question\nfig, ax = plt.subplots()\ng = sns.countplot(df.num_sents, hue=df.target, palette='viridis')\n#g.set_xticklabels(['Sincere', 'Insincere'])\ng.set_yticklabels([])\n\n# using log scale on y-axis so we can better see the questions with more sentences\nax.set(yscale='log')\n\nsns.despine(left=True, bottom=True)\nplt.xlabel('')\nplt.ylabel('')\nplt.title('Number of Sentences per Question', fontsize=30)\nplt.tick_params(axis='x', which='major', labelsize=15)\nfig.savefig('sentences.png')\nplt.show()","96efe4e6":"# Finding most common words\n# Define function to cleanup text by removing personal pronouns, stopwords, and puncuation\npunctuations = string.punctuation\nstop_words = set(stopwords.words(\"english\"))\n\ndef cleanup_text(docs):\n    texts = []\n    for doc in docs:\n        doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n        doc = nlp(doc, disable=['ner'])\n        tokens = [tok.lemma_.lower().strip() for tok in doc if tok.lemma_ != '-PRON-']\n        tokens = [tok for tok in tokens if tok not in stop_words and tok not in punctuations]\n        tokens = ' '.join(tokens)\n        texts.append(tokens)\n    return pd.Series(texts)","f3adfe8e":"# Grab all text associated with insincere questions\ninsincere_text = [text for text in df[df['target'] == 1]['question_text']]\ninsincere_clean = cleanup_text(insincere_text)\ninsincere_clean = ' '.join(insincere_clean).split()","7174bad9":"# Count all unique words\ninsincere_counts = Counter(insincere_clean)\n# get words and word counts\ninsincere_common_words = [word[0] for word in insincere_counts.most_common(20)]\ninsincere_common_counts = [word[1] for word in insincere_counts.most_common(20)]\n\n# plot 20 most common words in insincere questions\nsns.barplot(insincere_common_words, insincere_common_counts, palette='viridis')\nsns.despine(left=True, bottom=True)\nplt.xlabel('')\nplt.ylabel('')\nplt.title('Insincere Questions Common Words', fontsize=30)\nplt.tick_params(axis='x', which='major', labelsize=15)\nfig.savefig('insincere_words.png')\nplt.show()","32fbf6dd":"# Grab all text associated with sincere questions\nsincere_text = [text for text in df[df['target'] == 0]['question_text']]\nsincere_clean = cleanup_text(sincere_text)\nsincere_clean = ' '.join(sincere_clean).split()","e4299dcf":"# Count all unique words\nsincere_counts = Counter(sincere_clean)\n# get words and word counts\nsincere_common_words = [word[0] for word in sincere_counts.most_common(20)]\nsincere_common_counts = [word[1] for word in sincere_counts.most_common(20)]\n\n# plot 20 most common words in sincere questions\nsns.barplot(sincere_common_words, sincere_common_counts, palette='viridis')\nsns.despine(left=True, bottom=True)\nplt.xlabel('')\nplt.ylabel('')\nplt.title('Sincere Questions Common Words', fontsize=30)\nplt.tick_params(axis='x', which='major', labelsize=15)\nfig.savefig('sincere.png')\nplt.show()","726e2985":"# Quora Insincere Questions Exploratory Data Analysis\n\nWe will begin exploring the training data in order to come up with insights and a plan for modeling.","9fddc527":"### Class Imbalance\nImbalanced classes are a common problem in machine learning classification where there are a disproportionate ratio of observations in each class.  With just 6.6% of our dataset belonging to the target class, we can definitely have an imbalanced class!\n\nThis is a problem because many machine learning models are designed to maximize overall accuracy, which especially with imbalanced classes may not be the best metric to use.  Classification accuracy is defined as the number of correct predictions divided by total predictions times 100.  For example, if we simply predicted that all questions are sincere, we would get a classification acuracy score of 93%!\n\nThis competition uses the F1 score which balances precision and recall.\n - Precision is the number of true positives divided by all positive predictions.  Precision is also called Positive Predictive Value.  It is a measure of a classifier's exactness.  Low precision indicates a high number of false positives.\n - Recall is the number of true positives divided by the number of positive values in the test data.  Recall is also called Sensitivity or the True Positive Rate.  It is a measure of a classifier's completeness.  Low recall indicates a high number of false negatives."}}