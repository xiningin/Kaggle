{"cell_type":{"99c79734":"code","f2a23a3e":"code","62a62ab1":"code","07cc40a1":"code","13d68743":"code","27fbb39a":"code","0b67ad5e":"code","b0a718f7":"code","2ce3b4f3":"code","49f5c949":"code","6b3ebe16":"code","913ab324":"code","c248b454":"code","4aff5899":"code","64c0b1cd":"code","f388c481":"code","d60610e3":"code","2f2ba9e4":"code","b66c12d5":"code","40b1c68a":"code","8d0540ae":"code","e7293cba":"code","2eb17dd6":"code","5a5059ae":"code","0f14bcf3":"code","af4bc593":"markdown","74c378a8":"markdown","3357e888":"markdown","769f96da":"markdown","16940a0e":"markdown","e7b8ba90":"markdown","5ccaf3a3":"markdown","507c68a0":"markdown","e045b67d":"markdown"},"source":{"99c79734":"# This is a simple example of using pymc3 for Bayesian inference of the parameter distribution.\n# written by William F Basener\n# University of Virginia\n\nimport pymc3 as pm\nimport pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt","f2a23a3e":"print(pm.__version__)","62a62ab1":"def plot_traces(traces, retain=0):\n    '''\n    Convenience function:\n    Plot traces with overlaid means and values\n    '''\n\n    ax = pm.traceplot(traces[-retain:],\n                      lines=tuple([(k, {}, v['mean'])\n                                   for k, v in pm.summary(traces[-retain:]).iterrows()]))\n\n    for i, mn in enumerate(pm.summary(traces[-retain:])['mean']):\n        ax[i,0].annotate('{:.2f}'.format(mn), xy=(mn,0), xycoords='data'\n                    ,xytext=(5,10), textcoords='offset points', rotation=90\n                    ,va='bottom', fontsize='large', color='#AA0022')","07cc40a1":"data = pd.read_csv('..\/input\/iris-flower-dataset\/IRIS.csv')\ndata = data[['sepal_length','sepal_width','petal_length','petal_width','species']]\nprint(np.unique(data['species']))\ndata.describe()\n","13d68743":"data.loc[data['species'] == 'Iris-setosa',:].mean()*10","27fbb39a":"data.loc[data['species'] == 'Iris-setosa',:].cov()*10","0b67ad5e":"g = sns.pairplot(data, hue=\"species\", palette=\"husl\", markers=[\"o\", \"s\", \"D\"])","b0a718f7":"with pm.Model() as model:\n    pm.glm.GLM.from_formula(formula = 'species ~ sepal_length + sepal_width + petal_length + petal_width', \n                            data = data, \n                            family = pm.glm.families.Binomial())\n\n    trace = pm.sample(1000)","2ce3b4f3":"trace.varnames","49f5c949":"plot_traces(trace)","6b3ebe16":"pm.plots.forestplot(trace, figsize=(12, 5))\n# The creates a matplotlib plot, so we can modify with standard matplotlib commands\nplt.grid()  # add a grid to the plot","913ab324":"plt.figure(figsize=(9,7))\nsns.jointplot(trace['petal_length'], trace['petal_width'], kind=\"hex\", color=\"#4CB391\")\nplt.xlabel(\"petal_length\")\nplt.ylabel(\"petal_width\");\nplt.show()\n\nplt.figure(figsize=(9,7))\nsns.jointplot(trace['sepal_length'], trace['sepal_width'], kind=\"hex\", color=\"#4CB391\")\nplt.xlabel(\"sepal_length\")\nplt.ylabel(\"sepal_width\");\nplt.show()","c248b454":"chd_data = pd.read_csv(\"..\/input\/coronary-heart-disease\/CHDdata.csv\")\nchd_data.head()","4aff5899":"chd_data.describe()","64c0b1cd":"# Standardize the data (mean for each numerical variable of zero, standard deviation of one.)\nfor key in chd_data.keys()[0:9]:\n    try:\n        print(\"Standardizing \"+key+\".\")\n        chd_data[key] = chd_data[key] - np.mean(chd_data[key])\n        chd_data[key] = chd_data[key] \/ np.std(chd_data[key])\n    except:\n        print(\"Predictor \"+key+\" cannot be standardized (probably a categorical variable).\")\nchd_data.describe()","f388c481":"# Lets check the mean of each class to get a first look at the seperation\nprint(\"Mean for CHD Positive:\")\nprint(np.array([chd_data[chd_data.chd == 1].mean()[0:8]]))\nprint(\"Mean for CHD Negative:\")\nprint(np.array([chd_data[chd_data.chd == 0].mean()[0:8]]))","d60610e3":"chd_data.head()","2f2ba9e4":"my_priors = {\n    \n    'sbp':pm.Normal.dist(mu = 0,tau = 1),\n    'tobacco':pm.Normal.dist(mu = 0,tau = 1),\n    'ldl':pm.Normal.dist(mu = 0,tau = 1),\n    'adiposity':pm.Normal.dist(mu = 0,tau = 1),\n    'typea':pm.Normal.dist(mu = 0,tau = 1),\n    'obesity':pm.Normal.dist(mu = 0,tau = 1),\n    'alcohol':pm.Normal.dist(mu = 0,tau = 1),\n    'age':pm.Normal.dist(mu = 0,tau = 1),\n    'sbp':pm.Normal.dist(mu = 0,tau = 1),\n    'famhist':pm.Flat.dist()\n}\n","b66c12d5":"with pm.Model() as model:\n    pm.glm.GLM.from_formula(formula = 'chd ~ sbp + tobacco + ldl + adiposity + typea + obesity + alcohol + age + famhist', \n                            data = chd_data, \n                            family = pm.glm.families.Binomial(),\n                           priors = my_priors)\n\n    #trace = pm.sample(5000) \n    approx = pm.fit(50000, method = 'advi')","40b1c68a":"advi_elbo = pd.DataFrame(\n    {'ELBO': -approx.hist,\n     'n': np.arange(approx.hist.shape[0])})\n\n_ = sns.lineplot(y='ELBO', x='n', data=advi_elbo)","8d0540ae":"trace_VI = approx.sample(draws=5000)","e7293cba":"plot_traces(trace_VI)","2eb17dd6":"pm.plots.forestplot(trace_VI, figsize=(12, 5))\n# The creates a matplotlib plot, so we can modify with standard matplotlib commands\nplt.grid()  # add a grid to the plot","5a5059ae":"pm.summary(trace_VI).round(2)","0f14bcf3":"pm.summary(trace).round(2)","af4bc593":"# Bayesian Logistic Regression with PyMC3\n# Avinaash Pavuloori (akp8vy)\n\nIn this notebook we will be using pymc3 to examine posterior probability distributions for the parameters in logistic regression for classification.\n\nWe start by importing our required libraries.","74c378a8":"Now we perform our MCMC computaiton.  With pymc3, this is very easy.  We use the usual \"with\" declaration for pymc3, then use glm for our logistic model and just have to specidfy the formula, the data, and the family.  The family is what tells pymc3 that this will be logistic regression.\n\nWe are going to use the default priors for GLM coefficients from PyMC3, which is $p(\\theta)=N(0,10^{12}I)$.  These are very weak priors.","3357e888":"Now we can build our model in PYMC3 and examine the results:","769f96da":"Here is our nice custom traceplot using the function plot_traces we defined previously.","16940a0e":"We define a function that will be helpful for plotting.  This function does little mathematically, but will give us very nice trace plots.","e7b8ba90":"We are using the seaborn plottng library.  This enables a very nice pairs plot for our classes.","5ccaf3a3":"# Part 2. Logistic Regression for Predicting Coronary Heart Disease\n\nNow lets apply some Bayesian Regression techniques to a healthcare problem of determining risk for Coronary Heart Disease.  Logistic Regression is a great method for this problem because it provides esitmates of probability of heart disease and the Bayesian analysis provides insight into uncertainty and importance of the different predicotr variables.","507c68a0":"Load the data and look a the data frame.","e045b67d":"Here are the variable names in the output.  "}}