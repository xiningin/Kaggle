{"cell_type":{"5bff7a2f":"code","c5c9ac80":"code","00636423":"code","900031e6":"code","55838c5c":"code","82ae27dd":"code","69832169":"code","2086cd56":"code","77eec88f":"code","7851c8b0":"code","47b4aba4":"code","8c0c3f89":"code","502bdc91":"code","a1961e47":"code","733740be":"code","3026dc80":"code","6b577930":"code","c9dff46c":"code","c0492f2b":"code","c639293e":"code","4ee6ba3b":"code","610a502d":"code","9e0b311e":"code","85e25d98":"code","ec74f652":"code","a6d5ef90":"code","4e516ff5":"code","40d207b1":"code","fbb9af36":"code","9ee06bd2":"code","875fd3b6":"code","b5f3a217":"code","750747df":"code","d5dd7a3a":"code","c4fff9e8":"code","5dfe034c":"code","0be6b012":"code","407235ba":"code","1e40c49f":"code","b9717eca":"code","8e0cf665":"code","51132090":"code","17b6eb64":"code","06ec5ff5":"code","44f894de":"code","c7897765":"code","54100279":"code","edce2362":"code","8e9f4421":"code","e06f6d9d":"code","c66a0158":"code","d932cfff":"code","0a5cf768":"code","73d26efc":"code","8b451fd2":"code","c436aa57":"code","5c47fed6":"code","05fcb16d":"code","654cf0c4":"code","d3f7cdb2":"code","7c1f4a17":"code","66029da2":"code","511c0c91":"code","2f876165":"code","46efcda3":"code","e5e8aa66":"code","d45bcf5a":"code","934723c4":"code","9c0695a1":"code","77934673":"code","718f1505":"code","d993f99d":"markdown","b17b7700":"markdown","bb63f4d4":"markdown","98954b37":"markdown","8f964c94":"markdown","71ca43b2":"markdown","880f20b4":"markdown","a7035b0a":"markdown","96bb15dd":"markdown","c9cfe4b4":"markdown","548942f2":"markdown","ce882e04":"markdown","ac55b59b":"markdown","f408666b":"markdown","4221d992":"markdown","32e137de":"markdown","033e8828":"markdown","aab4c4a6":"markdown","d442fde7":"markdown","3811745b":"markdown","cd101511":"markdown","9e8e0c47":"markdown"},"source":{"5bff7a2f":"import pandas as pd\nfrom pandas.plotting import scatter_matrix\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns","c5c9ac80":"train_data = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntrain_labels = train_data['Survived']\ntest_data = pd.read_csv(\"..\/input\/titanic\/test.csv\")","00636423":"train_data.head(5)","900031e6":"train_data.info()\ntest_data.info()","55838c5c":"train_data.describe()","82ae27dd":"train_data[\"Sex\"].value_counts()","69832169":"ticket_counts = train_data[\"Ticket\"].value_counts()\nnot_unique_tickets = ticket_counts[ticket_counts!=1].keys()\ntrain_data[train_data[\"Ticket\"].isin(not_unique_tickets)].info()","2086cd56":"train_data[train_data[\"Ticket\"] == 'CA 2144']","77eec88f":"train_data[\"Cabin\"].value_counts()","7851c8b0":"train_data[\"Embarked\"].value_counts()","47b4aba4":"train_data[train_data[\"Embarked\"].isnull()]","8c0c3f89":"train_data[train_data['Ticket']=='113572']","502bdc91":"train_data[train_data['Cabin']=='B28']","a1961e47":"train_data[train_data['Fare']==80.0]","733740be":"attributes = [\"Pclass\", 'Fare',\"Embarked\"]\n#scatter_matrix(train_data[attributes], figsize=(20,15))\nsns.pairplot(data=train_data[attributes], hue=\"Embarked\")\nplt.show()","3026dc80":"attributes = [\"Survived\", \"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n#scatter_matrix(train_data[attributes], figsize=(20,15))\nsns.pairplot(data=train_data[attributes], hue=\"Survived\")\nplt.show()","6b577930":"train_data['Survived'].hist() # Unbalanced","c9dff46c":"# Remove the survived columns\ntrain_data = train_data.drop('Survived', axis=1)","c0492f2b":"from sklearn.base import BaseEstimator,TransformerMixin\nfrom nltk.tokenize.casual import casual_tokenize\n\nclass TitlesTransformer(BaseEstimator, TransformerMixin):\n    '''Replaces names with titles'''\n    def __init__(self):\n        # Alternative titles\n        self.mr_titles = ['Don', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col']\n        self.mrs_titles = ['Countess', 'Mme', 'Dona']\n        self.miss_titles = ['Mlle', 'Ms']\n        self.unisex_titles = ['Dr']\n        \n    def get_title(self, x):\n        x = x.Name.split(', ')[1]\n        x = casual_tokenize(x)\n        if x[0]!= 'the':\n            title = x[0]\n        else:\n            title = x[1]\n        return title\n\n    def title_reduction(self, x):\n        title = self.get_title(x)\n        if title in self.mr_titles:\n            title = 'Mr'\n        elif title in self.mrs_titles:\n            title = 'Mrs'\n        elif title in self.miss_titles:\n            title = 'Miss'\n        elif title in self.unisex_titles:\n            if x['Sex']=='male':\n                title = 'Mr'\n            else:\n                title = 'Mrs'\n        return title\n\n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, df, y=None):\n        titles = [self.title_reduction(row) for index, row in df.iterrows()]\n        X = pd.concat([df, pd.DataFrame(titles, columns={'Titles'})], axis=1)\n        return X","c639293e":"class TicketTransformer(BaseEstimator, TransformerMixin):\n    '''Replaces ticket with the number of ticket occurences'''\n    def __init__(self):\n        pass\n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, df, y=None):\n        dict_ticket_occurences = df['Ticket'].value_counts().to_dict()\n        ticket_occurences = [dict_ticket_occurences[row['Ticket']] for index, row in df.iterrows()]\n        X = pd.concat([df, pd.DataFrame(ticket_occurences, columns={'TicketOccurences'})], axis=1)\n        return X.drop('Ticket',axis=1)","4ee6ba3b":"class GroupImputer(BaseEstimator, TransformerMixin):\n    '''Replace missing Objective values, grouped by dependence attributes'''\n    def __init__(self, group_attrs, objective_attr, strategy='median'):\n        self.group_attrs = group_attrs\n        self.objective_attr  = objective_attr\n        self.strategy = strategy\n\n    def fit(self, df, y=None):\n        if self.strategy == 'mode':\n            self.dict_transform = df.groupby(self.group_attrs).agg(lambda x:x.value_counts().index[0])[self.objective_attr].to_dict()\n        else:# mean, median\n            self.dict_transform = df.groupby(self.group_attrs).agg(self.strategy)[self.objective_attr].to_dict()\n        return self\n    \n    def transform(self, df_o, y=None):\n        df = df_o.copy()\n        if len(self.group_attrs)==1:\n            df[self.objective_attr] = df[self.objective_attr].fillna(df[self.group_attrs].apply(lambda x: self.dict_transform.get(x[0]),axis=1) )\n        else:\n            df[self.objective_attr] = df[self.objective_attr].fillna(df[self.group_attrs].apply(lambda x: self.dict_transform.get(tuple(x)),axis=1) )\n        return df","610a502d":"class ColumnRemover(BaseEstimator, TransformerMixin):\n    '''Remove columns from dataframe'''\n    def __init__(self, objective_attrs):\n        self.objective_attrs  = objective_attrs\n\n    def fit(self, df, y=None):\n        return self\n    \n    def transform(self, df, y=None):        \n        return df.drop(self.objective_attrs, axis=1)","9e0b311e":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nattrs = list(train_data)\ncat_encoding = ColumnTransformer([(\"sex_1hot\", OneHotEncoder(), ['Sex'])], remainder='passthrough')","85e25d98":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\ncat_encoding = ColumnTransformer([(\"sex_1hot\", OneHotEncoder(), ['Sex']),\n                                  (\"sex_1hot\", OneHotEncoder(), ['Sex'])\n                                 ],\n                                 remainder='passthrough')\n\npipeline = Pipeline([\n    ('title_transform',  TitlesTransformer()), #Title Transform\n    ('ticket_transform', TicketTransformer()), #Ticket Transform\n    ('age_missing',      GroupImputer(group_attrs=['Sex', 'Pclass', 'Titles'],  # Age Imputer\n                                            objective_attr = 'Age', strategy='median')),\n    \n    ('embarked_missing', GroupImputer(group_attrs=['Sex', 'Pclass'],            # Embark Imputer\n                                            objective_attr = 'Embarked', strategy='mode')),\n    \n    ('fare_missing',     GroupImputer(group_attrs=['Pclass'],                   # Fare Imputer\n                                            objective_attr = 'Fare', strategy='mean')),\n    \n    ('attr_remove',      ColumnRemover(['PassengerId', 'Name', 'Cabin', 'Titles'])), # Column Remover\n    \n    (\"cat_encoding\",     ColumnTransformer([(\"sex_1hot\", OneHotEncoder(), ['Sex']),  # Category Encoding\n                                            (\"embarked_1hot\", OneHotEncoder(), ['Embarked']),\n                                            ], \n                                           remainder='passthrough')),         #Category Encoding\n    (\"minmax_scaler\", MinMaxScaler())\n])\npipeline.fit(train_data)","ec74f652":"transformed=pipeline.transform(train_data)","a6d5ef90":"pipeline['age_missing'].dict_transform","4e516ff5":"pipeline['embarked_missing'].dict_transform","40d207b1":"pipeline['fare_missing'].dict_transform","fbb9af36":"transformed.dtype #All numerical","9ee06bd2":"transformed[train_data.Age.isnull()][0]#not null","875fd3b6":"transformed[train_data.Embarked.isnull()][0]#not null","b5f3a217":"np.isnan(transformed).sum()#not a single null value","750747df":"pipeline['cat_encoding'].get_feature_names()","d5dd7a3a":"from sklearn.linear_model import SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC","c4fff9e8":"#Some Metrics\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import average_precision_score\nfrom sklearn.metrics import auc\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold","5dfe034c":"def metrics_eval(y_true, y_pred):\n    print('Accuracy:   \\t', accuracy_score(y_true, y_pred))\n    print('F1-Score:   \\t', f1_score(y_true, y_pred))\n    print('ROC-AUC:   \\t', roc_auc_score(y_true, y_pred))\n    precisions, recalls, thresholds = precision_recall_curve(y_true, y_pred)\n    print('PR-AUC: \\t', auc(recalls, precisions))\n    print('AvgPrecision: \\t', average_precision_score(y_true, y_pred))","0be6b012":"X_train = pipeline.transform(train_data)\ny_train = train_labels\nskfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)","407235ba":"sgd_clf = SGDClassifier()\ny_train_sgd_pred = cross_val_predict(sgd_clf,\n                                     X_train, y_train,\n                                     cv=skfolds)\nmetrics_eval(y_train, y_train_sgd_pred)","1e40c49f":"forest_clf = RandomForestClassifier()\ny_train_forest_pred = cross_val_predict(forest_clf,\n                                     X_train, y_train,\n                                     cv=skfolds)\nmetrics_eval(y_train, y_train_forest_pred)","b9717eca":"knn_clf = KNeighborsClassifier()\ny_train_knn_pred = cross_val_predict(knn_clf,\n                                     X_train, y_train,\n                                     cv=skfolds)\nmetrics_eval(y_train, y_train_knn_pred)","8e0cf665":"svm_clf = SVC()\ny_train_svm_pred = cross_val_predict(svm_clf,\n                                     X_train, y_train,\n                                     cv=skfolds)\nmetrics_eval(y_train, y_train_svm_pred)","51132090":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint #Distributions","17b6eb64":"forest_clf = RandomForestClassifier(n_jobs=-1)\nparam_grid = [{\n    'n_estimators': np.append(np.logspace(4,10,7, base=2, dtype=int), [100]),\n    'criterion' : [\"gini\", \"entropy\"]\n}]\ngrid_search = GridSearchCV(forest_clf, param_grid,\n                           cv=skfolds, scoring='accuracy',\n                           return_train_score=True,\n                           verbose=1)","06ec5ff5":"%%time\ngrid_search.fit(X_train, y_train)","44f894de":"grid_search.best_params_","c7897765":"cvres = grid_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(mean_score, params)","54100279":"forest_clf = grid_search.best_estimator_\ny_train_forest_pred = cross_val_predict(forest_clf,\n                                     X_train, y_train,\n                                     cv=skfolds)\nmetrics_eval(y_train, y_train_forest_pred)","edce2362":"#Lets try RandomizedSearchCV\nforest_clf = RandomForestClassifier(n_jobs=-1)\nparam_distribs = {\n    'n_estimators': randint(50,300),\n    'criterion' : [\"gini\", \"entropy\"]\n    }\nrnd_search = RandomizedSearchCV(forest_clf, param_distributions=param_distribs,\n                                n_iter=20, cv=skfolds, \n                                scoring='accuracy',\n                                return_train_score=True,\n                                verbose=3, random_state=42, n_jobs=-1)","8e9f4421":"%%time\nrnd_search.fit(X_train, y_train)","e06f6d9d":"rnd_search.best_params_","c66a0158":"forest_clf = rnd_search.best_estimator_\ny_train_forest_pred = cross_val_predict(forest_clf,\n                                     X_train, y_train,\n                                     cv=skfolds)\nmetrics_eval(y_train, y_train_forest_pred)","d932cfff":"knn_clf = KNeighborsClassifier(n_jobs=-1)\nparam_grid = [{\n    'weights':['uniform', 'distance'],\n    'n_neighbors':range(1,10)\n}]\ngrid_search = GridSearchCV(knn_clf, param_grid,\n                           cv=skfolds, scoring='accuracy',\n                           return_train_score=True,\n                           verbose=1)","0a5cf768":"%%time\ngrid_search.fit(X_train, y_train)","73d26efc":"grid_search.best_params_","8b451fd2":"cvres = grid_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(mean_score, params)","c436aa57":"knn_clf = grid_search.best_estimator_","5c47fed6":"y_train_knn_pred = cross_val_predict(knn_clf,\n                                     X_train, y_train,\n                                     cv=skfolds)\nmetrics_eval(y_train, y_train_knn_pred)","05fcb16d":"clf_pipeline = Pipeline([\n    ('clf', RandomForestClassifier(n_jobs=-1)),\n])\n\nparam_grid = [\n    { # First classifier\n        'clf': [RandomForestClassifier(n_jobs=-1)],\n        'clf__n_estimators': np.append(np.logspace(4,10,7, base=2, dtype=int), [100]),\n        'clf__criterion': [\"gini\", \"entropy\"],\n    }, {\n        'clf': [KNeighborsClassifier(n_jobs=-1)],\n        'clf__weights': ['uniform', 'distance'],\n        'clf__n_neighbors':range(1,10),\n    }\n]\n\ngrid_search = GridSearchCV(clf_pipeline, param_grid,\n                           cv=skfolds, scoring='accuracy',\n                           return_train_score=True,\n                           verbose=1)","654cf0c4":"grid_search.fit(X_train, y_train)","d3f7cdb2":"cvres = grid_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(mean_score, params)","7c1f4a17":"grid_search.best_params_","66029da2":"grid_search.best_params_['clf'].get_params()","511c0c91":"grid_search.best_estimator_","2f876165":"best_clf = grid_search.best_estimator_\nbest_clf.fit(X_train, y_train)","46efcda3":"attributes = pipeline['cat_encoding'].get_feature_names()\nattributes","e5e8aa66":"feature_importances = rnd_search.best_estimator_.feature_importances_","d45bcf5a":"sorted(zip(feature_importances, attributes), reverse=True)","934723c4":"X_test = pipeline.transform(test_data)","9c0695a1":"y_test_forest_pred = best_clf.predict(X_test)","77934673":"submission = pd.DataFrame({'PassengerId': test_data.PassengerId,\n                           'Survived': y_test_forest_pred})","718f1505":"submission.to_csv(\"submission.csv\", index=False)","d993f99d":"# Inspiration\nhttps:\/\/www.kaggle.com\/felipesanchezgarzon\/eda-feature-engineering-comparison-ml-accuracy\n\nhttps:\/\/triangleinequality.wordpress.com\/2013\/09\/08\/basic-feature-engineering-with-the-titanic-data\/\n\nhttps:\/\/www.kaggle.com\/gunesevitan\/titanic-advanced-feature-engineering-tutorial\n\nhttps:\/\/www.kaggle.com\/nicapotato\/titanic-feature-engineering","b17b7700":"Will it be possible to get the missing \"Embarked\" values?","bb63f4d4":"# Model exploration and selection","98954b37":"# Automating Finetuning\nAutomating classifier selection and finetuning","8f964c94":"# DataFeature Engineering","71ca43b2":"Finetuning individual classifiers","880f20b4":"### KNN","a7035b0a":"### RandomForest","96bb15dd":"- survival  Survival \t0 = No, 1 = Yes\n- pclass    Ticket class \t1 = 1st, 2 = 2nd, 3 = 3rd\n- sex       Sex \t\n- Age       Age in years \t\n- sibsp     # of siblings \/ spouses aboard the Titanic \t\n- parch     # of parents \/ children aboard the Titanic \t\n- ticket    Ticket number \t\n- fare      Passenger fare \t\n- cabin     Cabin number \t\n- embarked  Port of Embarkation \tC = Cherbourg, Q = Queenstown, S = Southampton","c9cfe4b4":"# Finetuning","548942f2":"No luck, maybe \"Pclass\" or \"Fare\" has some correlation with embarked","ce882e04":"Example of training and measuring classifiers ","ac55b59b":"## Winner","f408666b":"### Summary\nTypes of data\n- Ordered Categorical\n  +  Pclass\n- Unordered Categorical\n  +  Survived\n  +  Sex\n  +  Embarked  (missing values in training set 0.22%)\n- Numeric\n  +  Age   (missing values in training 19% and test set 20%)\n  +  SibSp\n  +  Parch\n  +  Fare  (missing values in test set 0.23%)\n- Other\n  +  PassengerId\n  +  Name\n  +  Ticket\n  +  Cabin (missing values in training 77% and test set 78%)","4221d992":"Conclusions from data exploration:\n\n- Ordered Categorical\n  + [X]  Pclass -> is ordered and already numeric, I will not encode it, but encoding it may improve accuracy.\n- Unordered Categorical\n  + [X]  Sex     -> **OneHotEncoding**\n  + [X]  Embarked  (missing values in training set 0.22%)  -> **OneHotEncoding** fix missing values with the mode of the values (the most frequent) with same *Sex* and *Pclass*.\n- Numeric\n  + [X]  Age (missing values in training 19% and test set 20%)  -> fix missing values with the median of the values with same *Sex*, *Titles* and *Pclass*.\n  + [X]  SibSp\n  + [X]  Parch\n  + [X]  Fare (missing values in test set 0.23%) -> fix missing values with the mean of the values with same *Pclass*.\n- Other\n  + [X]  PassengerId -> **No use**\n  + [X]  Name -> Titles -> **Drop It after fixin Age missing values**\n  + [X]  Ticket -> **Occurences**\n  + [X]  Cabin (missing values in training 77% and test set 78%) -> **Drop It** ","32e137de":"RandomForest and KNN is selected","033e8828":"## Feature Importance","aab4c4a6":"## Pipeline","d442fde7":"# Introduction\nScikit-Learn API allows to automate the preparation, transformation and cleaning of data.","3811745b":"# Test Evaluation\nThe final evaluation","cd101511":"Just two, lets explore more rows with the same Ticket, Cabin, or maybe Fare","9e8e0c47":"# Data Exploration"}}