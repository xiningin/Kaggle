{"cell_type":{"50d42127":"code","e3c34c71":"code","169d0c91":"code","5bc576c7":"code","48e6ef63":"code","fc50a5e9":"code","5633a455":"code","019ee62a":"code","758849f3":"code","d4099e22":"code","c138bac4":"code","27c701d2":"code","c0ccf9a6":"code","883d1e21":"code","82c64efa":"code","9cbb0bec":"code","c2a2a9cf":"code","a982187b":"code","44c3a149":"code","4abe69d1":"code","66affa20":"code","8d64bcc6":"code","7abe876a":"code","7f955cba":"code","3f10650e":"code","6756b42f":"code","3eddbe32":"code","71c73bc6":"code","a9ca3a18":"code","f31f5b08":"code","b5017b3e":"markdown","df44b3b9":"markdown","7e1bd14e":"markdown","db34038e":"markdown","d54ea1b9":"markdown","73c76a30":"markdown","f4c037a2":"markdown","2d4c7233":"markdown","ec0a637c":"markdown","c3ae909c":"markdown","4d127791":"markdown","580231dc":"markdown","a6ccd99b":"markdown","8ce83543":"markdown","da87c192":"markdown","ea36a13c":"markdown","2c7396ed":"markdown","c2ad3fb1":"markdown"},"source":{"50d42127":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e3c34c71":"import os\nimport random\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use(\"ggplot\")\n%matplotlib inline\n\nimport cv2\nfrom tqdm import tqdm_notebook, tnrange\nfrom glob import glob\nfrom itertools import chain\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom skimage.color import rgb2gray\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model, load_model, save_model\nfrom tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint","169d0c91":"DataPath = \"\/kaggle\/input\/lgg-mri-segmentation\/kaggle_3m\/\"\n\ndirs = []\nimages = []\nmasks = []\nfor dirname, _, filenames in os.walk(DataPath):\n    for filename in filenames:\n        if 'mask'in filename:\n            dirs.append(dirname.replace(DataPath, ''))\n            masks.append(filename)\n            images.append(filename.replace('_mask', ''))","5bc576c7":"# print(masks[:10], images[:10])","48e6ef63":"len(dirs), len(images), len(masks)","fc50a5e9":"imagePath_df = pd.DataFrame({'directory':dirs, 'images': images, 'masks': masks})","5633a455":"imagePath_df.head()","019ee62a":"def print_imShape():\n    idx = np.random.randint(0, len(imagePath_df))\n    \n    imagePath = os.path.join(DataPath, imagePath_df['directory'].iloc[idx], imagePath_df['images'].iloc[idx])\n    maskPath = os.path.join(DataPath, imagePath_df['directory'].iloc[idx], imagePath_df['masks'].iloc[idx])\n    \n    image = cv2.imread(imagePath)\n    mask = cv2.imread(maskPath)\n    \n    print(image.shape, mask.shape)","758849f3":"for i in range(5):\n    print_imShape()","d4099e22":"def plot_images():\n    idx = np.random.randint(0, len(imagePath_df))\n    \n    imagePath = os.path.join(DataPath, imagePath_df['directory'].iloc[idx], imagePath_df['images'].iloc[idx])\n    maskPath = os.path.join(DataPath, imagePath_df['directory'].iloc[idx], imagePath_df['masks'].iloc[idx])\n    \n    image = cv2.imread(imagePath)\n    mask = cv2.imread(maskPath)\n    \n    fig, axs = plt.subplots(1,3, figsize=[13,15])\n    \n    axs[0].imshow(image)\n    axs[0].set_title('Brain MRI')\n    \n    axs[1].imshow(mask)\n    axs[1].set_title('Mask')\n    \n    axs[2].imshow(image)\n    axs[2].imshow(mask, alpha=0.3)\n    axs[2].set_title('MRI with mask')\n    \n    plt.grid(False)\n    plt.show()","c138bac4":"for i in range(5):\n    plot_images()","27c701d2":"imagePath_df['image-path'] = DataPath + imagePath_df['directory'] + '\/' + imagePath_df['images']\nimagePath_df['mask-path'] = DataPath + imagePath_df['directory'] + '\/' + imagePath_df['masks'] ","c0ccf9a6":"train , test = train_test_split(imagePath_df, test_size=0.25, random_state=21)","883d1e21":"EPOCHS = 35\nBATCH_SIZE = 32\nImgHieght = 256\nImgWidth = 256\nChannels = 3","82c64efa":"data_augmentation = dict(rotation_range=0.2,\n                        width_shift_range=0.05,\n                        height_shift_range=0.05,\n                        shear_range=0.05,\n                        zoom_range=0.05,\n                        horizontal_flip=True,\n                        fill_mode='nearest')","9cbb0bec":"# image generator\nimagegen = ImageDataGenerator(rescale=1.\/255., **data_augmentation)\nmaskgen = ImageDataGenerator(rescale=1.\/255., **data_augmentation)\n\n\n# train generator\ntimage_generator=imagegen.flow_from_dataframe(dataframe=train,\n                                            x_col=\"image-path\",\n                                            batch_size= BATCH_SIZE,\n                                            seed=42,\n                                            class_mode=None,\n                                            target_size=(ImgHieght,ImgWidth),\n                                            color_mode='rgb')\n# validation data generator\ntmask_generator=maskgen.flow_from_dataframe(dataframe=train,\n                                            x_col=\"mask-path\",\n                                            batch_size=BATCH_SIZE,\n                                            seed=42,\n                                            class_mode=None,\n                                            target_size=(ImgHieght,ImgWidth),\n                                            color_mode='grayscale')    ","c2a2a9cf":"# image generator\nimagegen = ImageDataGenerator(rescale=1.\/255.)\nmaskgen = ImageDataGenerator(rescale=1.\/255.)\n\n\n# train generator\nvimage_generator=imagegen.flow_from_dataframe(dataframe=test,\n                                            x_col=\"image-path\",\n                                            batch_size= BATCH_SIZE,\n                                            seed=42,\n                                            class_mode=None,\n                                            target_size=(ImgHieght,ImgWidth),\n                                            color_mode='rgb')\n# validation data generator\nvmask_generator=maskgen.flow_from_dataframe(dataframe=test,\n                                            x_col=\"mask-path\",\n                                            batch_size=BATCH_SIZE,\n                                            seed=42,\n                                            class_mode=None,\n                                            target_size=(ImgHieght,ImgWidth),\n                                            color_mode='grayscale')    ","a982187b":"def data_iterator(image_gen, mask_gen):\n    for img, mask in zip(image_gen, mask_gen):\n        yield img, mask","44c3a149":"train_gen = data_iterator(timage_generator, tmask_generator)\nvalid_gen = data_iterator(vimage_generator, vmask_generator)","4abe69d1":"def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n    # first layer\n    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n    if batchnorm:\n        x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    # second layer\n    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n    if batchnorm:\n        x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    return x","66affa20":"def get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True):\n    \"\"\"Function to define the UNET Model\"\"\"\n    # Contracting Path\n    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n    p1 = MaxPooling2D((2, 2))(c1)\n    p1 = Dropout(dropout)(p1)\n    \n    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n    p2 = MaxPooling2D((2, 2))(c2)\n    p2 = Dropout(dropout)(p2)\n    \n    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n    p3 = MaxPooling2D((2, 2))(c3)\n    p3 = Dropout(dropout)(p3)\n    \n    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n    p4 = MaxPooling2D((2, 2))(c4)\n    p4 = Dropout(dropout)(p4)\n    \n    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n    \n    # Expansive Path\n    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n    u6 = concatenate([u6, c4])\n    u6 = Dropout(dropout)(u6)\n    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n    \n    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n    u7 = concatenate([u7, c3])\n    u7 = Dropout(dropout)(u7)\n    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n    \n    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n    u8 = concatenate([u8, c2])\n    u8 = Dropout(dropout)(u8)\n    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n    \n    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n    u9 = concatenate([u9, c1])\n    u9 = Dropout(dropout)(u9)\n    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n    \n    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n    model = Model(inputs=[input_img], outputs=[outputs])\n    return model","8d64bcc6":"input_img = Input((ImgHieght, ImgWidth, 3), name='img')\nmodel = get_unet(input_img, n_filters=16, dropout=0.2, batchnorm=True)\nmodel.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])","7abe876a":"model.summary()","7f955cba":"callbacks = [\n    EarlyStopping(patience=10, verbose=1),\n    ReduceLROnPlateau(factor=0.1, patience=5, min_lr=1e-5, verbose=1),\n    ModelCheckpoint('model-brain-mri.h5', verbose=1, save_best_only=True, save_weights_only=True)\n]","3f10650e":"STEP_SIZE_TRAIN = timage_generator.n\/BATCH_SIZE\nSTEP_SIZE_VALID = vimage_generator.n\/BATCH_SIZE","6756b42f":"results = model.fit(train_gen,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    batch_size=BATCH_SIZE,\n                    epochs=EPOCHS,\n                    callbacks=callbacks,\n                    validation_data=valid_gen,\n                   validation_steps=STEP_SIZE_VALID)","3eddbe32":"plt.figure(figsize=(8, 8))\nplt.title(\"Learning curve\")\nplt.plot(results.history[\"loss\"], label=\"loss\", color=sns.xkcd_rgb['greenish teal'])\nplt.plot(results.history[\"val_loss\"], label=\"val_loss\", color=sns.xkcd_rgb['amber'])\nplt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"log_loss\")\nplt.legend()\n# plt.grid(False)\nplt.show()","71c73bc6":"# load the best model\nmodel.load_weights('model-brain-mri.h5')","a9ca3a18":"eval_results = model.evaluate(valid_gen, steps=STEP_SIZE_VALID, verbose=1)","f31f5b08":"for i in range(10):\n    idx = np.random.randint(0, len(imagePath_df))\n    \n    imagePath = os.path.join(DataPath, imagePath_df['directory'].iloc[idx], imagePath_df['images'].iloc[idx])\n    maskPath = os.path.join(DataPath, imagePath_df['directory'].iloc[idx], imagePath_df['masks'].iloc[idx])\n    \n    image = cv2.imread(imagePath)\n    mask = cv2.imread(maskPath)\n    \n    img = cv2.resize(image ,(ImgHieght, ImgWidth))\n    img = img \/ 255\n    img = img[np.newaxis, :, :, :]\n    pred=model.predict(img)\n\n    plt.figure(figsize=(12,12))\n    plt.subplot(1,4,1)\n    plt.imshow(np.squeeze(img))\n    plt.title('Original Image')\n    plt.subplot(1,4,2)\n    plt.imshow(mask)\n    plt.title('Original Mask')\n    plt.subplot(1,4,3)\n    plt.imshow(np.squeeze(pred))\n    plt.title('Prediction')\n    plt.subplot(1,4,4)\n    plt.imshow(np.squeeze(pred) > 0.5)\n    plt.title('BinaryPrediction')\n    plt.show()","b5017b3e":"**Finally we come to UNet Architecture**\n\nFollowing picture gives a clear picture of What a UNet is. Since there are only convolution layers in this network, therefore its a FCN.","df44b3b9":"UNet is a fully convolutional neural-network. It got its name due to its U-shaped network architecture. It is currently SOTA in the sementic segmentation.\n\nWhat is semenctic segmentation?\n\nWell its a type of problem studied in computer vision just like image classification, object detection etc.\n\n*  **Image Classification:** We Iddentify what is present in an image. If it is present or not\n\n*  **Object Detection:** We identify what is present in the image and where it is present. Its sometimes also called object localization.\n\n*  **Image Segentation:** In object detection we identify position of an object by labeling a bounding box. In image segmentation we assign each pixel belongs to an image or not. There are two types of Image segmentation: Sementic segmentation and Instance segmentation.following image might help a little bit to visualize difference between these two","7e1bd14e":"## Data Generator","db34038e":"Given the MRI Images of Brain our task is to identify if a tumor is present in the image or not. This problem boils down to image segmentation, which is extensively studied in the field of computer vision. Most popular use case is self driving cars\n\nAbove figure shows a sneak peak of what the data looks like. We have Brain MRIs labeled with a mask which indicates the presence of abnormality","d54ea1b9":"## Prediction","73c76a30":"## Load Data","f4c037a2":"**Key aspects of UNet:**\n\n*  **Convolution Layers:** Convolution operation are used learn information from images which then can be used as features for mcahine learning problems\n\n*  **Down Sampling:** Sequence of convolution combined with max pooling results in down sampling. In down sampling Size of image is reduced which means we can observe larger portion of image in a single convolution operation. Down sampling is a good approach for identifying what is present in the image. but for identifying where the object is we need to use upsampling.\n\n*  **Up Sampling:** It is just opposite of down sampling. We go from low resolution to high resolution. For up sampling UNet uses transposed covolution which is achieved by taking transpose of filter kernels and reversing the process of convolution. If you want to learn more please check out [this](https:\/\/towardsdatascience.com\/understanding-semantic-segmentation-with-unet-6be4f42d4b47) and [this](https:\/\/naokishibuya.medium.com\/up-sampling-with-transposed-convolution-9ae4f2df52d0).","2d4c7233":"## Config","ec0a637c":"## UNet","c3ae909c":"## Image Shape","4d127791":"## Import Libraries","580231dc":"# Image Segmentation using UNet","a6ccd99b":"![](http:\/\/miro.medium.com\/max\/2400\/1*OkUrpDD6I0FpugA_bbYBJQ.png)","8ce83543":"## Train","da87c192":"### Train","ea36a13c":"![](https:\/\/miro.medium.com\/max\/2454\/1*cHtBw8yBhprNXj-CBQBx5g.png)","2c7396ed":"## Plot Images","c2ad3fb1":"### Validation"}}