{"cell_type":{"a57910bf":"code","75020542":"code","f2edc520":"code","b1b12588":"code","a6576d67":"code","a7541bd9":"code","c7f26c3c":"code","093b7e99":"code","647fb825":"code","79317650":"code","b877da96":"code","18b5bc50":"code","715ce676":"code","a157aebf":"code","f6cf598f":"code","0c8d8b93":"code","db0dffde":"markdown","ab6c22a8":"markdown","5e2cf1b4":"markdown","af9339a2":"markdown"},"source":{"a57910bf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","75020542":"\nfrom sklearn.model_selection import train_test_split\n\nimport seaborn as sns\n# sns.set()\nsns.set(rc={'figure.figsize':(11.7,8.27)})","f2edc520":"dat = pd.read_csv('\/kaggle\/input\/electionfinance\/CandidateSummaryAction1.csv',\n                 parse_dates=['cov_sta_dat','cov_end_dat'])\n\n# Convert dollars to floats\ndef convdollars2float(dfcol):\n    val = dfcol.str.replace('$','').str.replace(',','').str.replace('(','-').str.replace(')','').astype('float32')\n    return val\n\nfor colname in ['cas_on_han_beg_of_per','cas_on_han_clo_of_per','net_con','net_ope_exp','deb_owe_by_com','deb_owe_to_com']:\n    dat[colname] = convdollars2float(dat[colname])\n\n# Convert winner column to boolean\ndat['winner'] = dat['winner'].apply(lambda val: float(int(val=='Y')))\n\ndat.head(10)","b1b12588":"\n#\u00a0Add column: time length cov_end_dat - cov_sta_dat\ndat['cov_dat_len_days'] = (dat['cov_end_dat'] - dat['cov_sta_dat']).dt.days\n# Drop where this column has negative value\ndat = dat[ dat['cov_dat_len_days'] >= 0 ]\n","a6576d67":"# Add column: number of competitiors\n\n# First, construct lookup table of number of candidates running for each district\nnum_comp_lookup = dat.groupby(['can_off_sta','can_off_dis'])['can_id'].count().to_dict()\n\n#\u00a0Then perform lookup on this table to append number of competitors\ndef fcn(row):\n    key = (row.can_off_sta,row.can_off_dis)\n    if key in num_comp_lookup:\n        return num_comp_lookup[key]\n#     else:\n#        # Handling NaNs:\n#        num_competitors = 0\ndat['num_comp'] = dat.apply(lambda row: fcn(row), axis=1)\n\n# Drop rows where number of competitors couldn't be calculated (>0) and where uncontested (>1)\ndat = dat[ dat['num_comp'] > 1 ]\n","a7541bd9":"# Add column: fraction of spend for this district\n\n# First, construct lookup table of total spend for this district\ntotal_net_con_for_district = dat.groupby(['can_off_sta','can_off_dis'])['net_con'].sum().to_dict()\n\n# Add column giving this total of net contributions\ndef fcn(row):\n    key = (row.can_off_sta,row.can_off_dis)\n    if key in num_comp_lookup:\n        return total_net_con_for_district[key]\n#     else:\n#        # Handling NaNs:\n#        num_competitors = 0\ndat['total_net_con_for_district'] = dat.apply(lambda row: fcn(row), axis=1)\n\n# Calculate the fraction\ndat['fraction_net_con_for_district'] = dat['net_con'] \/ dat['total_net_con_for_district']","c7f26c3c":"# # Add column: tot_comp per vote\n# dat['net_con_per_vote'] = dat['net_con']\/dat['votes']","093b7e99":"dat.head()","647fb825":"# Winning probability is function of:\n# Number of competitors: num_comp\n# Number of days campaigning: cov_dat_len_days ???TBC TODO is this what this column refers to???\n# Fraction of total money available\/spent by the candidate: fraction_net_con_for_district ???TBC TODO is this what this column refers to???\n\n# COLS_TO_REGRESS = ['num_comp','cov_dat_len_days','fraction_net_con_for_district']\n# COLS_TO_REGRESS = ['fraction_net_con_for_district']\nCOLS_TO_REGRESS = ['num_comp','cov_dat_len_days']\n\n_ = dat[['winner']+COLS_TO_REGRESS].dropna()\n\ny = _['winner']\nX = _[COLS_TO_REGRESS]\n\nimport statsmodels.api as sm\nlogit_model=sm.Logit(y,X)\nresult=logit_model.fit()\nprint(result.summary2())","79317650":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)","b877da96":"# ROC Curve\n\nimport matplotlib.pyplot as plt \nplt.rc(\"font\", size=14)\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nlogit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\nfpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n\nplt.figure()\nplt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()","18b5bc50":"# Classification report\nfrom sklearn.metrics import classification_report\ny_pred = logreg.predict(X_test)\nprint(classification_report(y_test, y_pred))","715ce676":"# Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix = confusion_matrix(y_test, y_pred)\nprint(confusion_matrix)","a157aebf":"# Add column of predictions alongside each row\ndat_grp_preds = dat[['can_id']+COLS_TO_REGRESS].dropna(axis=0)\n\ndat_grp_preds['winner_prediction'] = logreg.predict( dat_grp_preds[COLS_TO_REGRESS] )\n\ndat_grp_preds = dat_grp_preds.set_index('can_id')\n\ndat_grp_preds.head()\n","f6cf598f":"# Join main data with predictions data on can_id\n_ = dat.set_index('can_id')\n_ = _.join(dat_grp_preds['winner_prediction'])","0c8d8b93":"# Group the data by district\n# dat_grp = dat.groupby(['can_off_sta','can_off_dis','can_inc_cha_ope_sea']).sum()\n_grp = _.set_index(['can_off_sta','can_off_dis']).sort_values(by=['can_off_sta','can_off_dis'])\n_grp","db0dffde":"### Full printout of results","ab6c22a8":"# Simple Logit Regression to Predict Election Candidate Winners\n\nRegression performed against:\n* Number of competitors\n* Number of days campaigning\n* Fraction of total money available\/spent by the candidate\n\nhttps:\/\/www.kaggle.com\/danerbland\/electionfinance","5e2cf1b4":"### Derive data (add new columns)","af9339a2":"### Load data and clean"}}