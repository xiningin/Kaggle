{"cell_type":{"788d77d3":"code","f63c1a14":"code","0cc1e9aa":"code","b340eee1":"code","00592d23":"code","38047cc4":"code","cede8d86":"code","3e49712d":"code","f4a82472":"code","bb63946e":"code","a175f37b":"code","a0a92db5":"code","0b4bfabd":"code","2b25b104":"code","5f77c808":"code","17f658d3":"code","8f96a73a":"code","8b58cece":"code","31bfa55a":"code","1eb0eb07":"code","61a5e5d1":"code","32f0e3c2":"code","a1a75460":"markdown","5b329bac":"markdown","ced0dfff":"markdown","597e3bad":"markdown"},"source":{"788d77d3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f63c1a14":"import matplotlib.pyplot as plt\nimport random\nimport tensorflow as tf","0cc1e9aa":"train_df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntrain_df.head(10)","b340eee1":"train_df.shape","00592d23":"test_df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\ntest_df.head()","38047cc4":"Y_train = train_df['label']\nY_train.head()","cede8d86":"X_train = train_df.drop(['label'], axis=1)\nX_train.head()","3e49712d":"# plot some samples\ndigit_extract = random.randint(0,420)\nimg = X_train.iloc[digit_extract].values\nimg = img.reshape((28,28))\nplt.imshow(img)","f4a82472":"from sklearn.model_selection import train_test_split\nx_train,x_val,y_train,y_val = train_test_split(X_train,Y_train,random_state = 2)","bb63946e":"#Training X_Train X_Validation\nprint(x_train.shape)\nprint(x_val.shape)\n#Training Y_Train Y_Validation\nprint(y_train.shape)\nprint(y_val.shape)","a175f37b":"#X_train reshape\nx_train = x_train.values.reshape(-1, 28, 28, 1)\nx_train = x_train \/ 255.0\n#Validation reshape\nx_val = x_val.values.reshape(-1, 28, 28, 1)\nx_val = x_val \/ 255.0","a0a92db5":"print(x_train.shape)\nprint(x_val.shape)","0b4bfabd":"from keras.utils.np_utils import to_categorical\ny_train = to_categorical(y_train, num_classes=10)\nprint(y_train.shape)\ny_val=to_categorical(y_val,num_classes=10)\nprint(y_val.shape)","2b25b104":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import to_categorical\n\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.optimizers import Adam\n\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.callbacks import EarlyStopping","5f77c808":"model = Sequential()\n\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same',input_shape=(28,28,1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid' ))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', strides=1, padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), strides=1, padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2), padding='valid', strides=2))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))\noptimizer = Adam(lr=0.001)\nmodel.summary()\n\n#Compiling the model\nmodel.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","17f658d3":"epochs=30\nbatch_size=60\nhistory = model.fit(x_train,y_train,epochs=epochs,batch_size=batch_size,validation_data=(x_val,y_val))","8f96a73a":"plt.figure(figsize=(13, 5))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title(\"Model Loss\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['Train', 'Test'])\nplt.grid()\nplt.show()","8b58cece":"plt.figure(figsize=(13, 5))\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(['Train','Test'])\nplt.grid()\nplt.show()","31bfa55a":"test_df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\ntest_df.head(10)","1eb0eb07":"img = test_df.iloc[1].values\nimg = img.reshape((28,28))\nplt.imshow(img)","61a5e5d1":"pred_test_data = np.array(test_df).reshape((-1,28,28,1))\npredictions = model.predict_classes(pred_test_data)\nprint(predictions)","32f0e3c2":"submit = pd.DataFrame({'ImageId':range(1,len(predictions)+1),'Label':predictions})\nsubmit.head(40)\n\nsubmit.to_csv('.\/answer.csv',index=False)","a1a75460":"Extracting X and Y From Train_df ","5b329bac":"Model Development","ced0dfff":"Visualization Of The Dataset","597e3bad":"Data-Analysis - Digit Recognizer"}}