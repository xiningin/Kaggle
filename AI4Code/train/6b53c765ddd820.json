{"cell_type":{"d218ce51":"code","d43a2d9c":"code","194bf08c":"code","d28daf0d":"code","d694d4e4":"code","229aaed4":"code","6fde39e6":"code","084004f0":"code","ba46b703":"code","25e217ac":"code","7b315c10":"code","281ff9b3":"code","b822ced9":"code","eeb2d6bc":"code","90c511ef":"code","55cd308e":"code","01e3a807":"markdown","acf12e9e":"markdown","3aa39986":"markdown","3254eaa8":"markdown","caa3ca80":"markdown","73488b06":"markdown","2660bbc2":"markdown","3e15c707":"markdown","33e1f270":"markdown","4d0b1cb2":"markdown","c4caeedf":"markdown","9de596c4":"markdown"},"source":{"d218ce51":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport folium\nfrom folium import plugins\nfrom folium.plugins import HeatMap\nfrom scipy.cluster.vq import kmeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn.manifold import TSNE\nfrom mpl_toolkits import mplot3d\n\n\n%matplotlib inline\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d43a2d9c":"df = pd.read_csv(\"..\/input\/us-weather-events\/WeatherEvents_Jan2016-Dec2020.csv\")\ndf.shape\ndf.info()","194bf08c":"df.head()","d28daf0d":"df.nunique()","d694d4e4":"df[\"StartTime(UTC)\"] = pd.to_datetime(df[\"StartTime(UTC)\"])\ndf[\"EndTime(UTC)\"] = pd.to_datetime(df[\"EndTime(UTC)\"])","229aaed4":"df = df[[\"State\", \"City\", \"AirportCode\",\"LocationLat\", \"LocationLng\", \"Type\", \"Severity\"]]\ndf = pd.get_dummies(df, columns=[\"Type\", \"Severity\"])\ndf = df.groupby([\"City\", \"AirportCode\",\"LocationLat\", \"LocationLng\"], as_index=False).sum()\ndf.shape","6fde39e6":"df_clus = df.drop([\"City\", \"AirportCode\",\"LocationLat\", \"LocationLng\"], axis = 1)","084004f0":"pca = PCA()\npca.fit(df_clus)\nfeatures = range(pca.n_components_)\n\nplt.bar(features, pca.explained_variance_)\nplt.xticks(features)\nplt.show()","ba46b703":"pca = PCA(n_components=3)\npca.fit(df_clus)\ndf_reduced = pca.transform(df_clus)","25e217ac":"disortions = []\nnum_clusters = range(2,11)\n\nfor i in num_clusters:\n    kmeans = KMeans(n_clusters=i, random_state=42)\n    kmeans.fit(df_reduced)\n    disortions.append(kmeans.inertia_)","7b315c10":"elbow_data = pd.DataFrame({\"num_clusters\": num_clusters, \"disortions\":disortions})\nsns.lineplot(x=\"num_clusters\", y=\"disortions\", data=elbow_data)\nplt.show()","281ff9b3":"kmeans = KMeans(n_clusters=4, random_state=42)\nkmeans.fit(df_reduced)\ncluster = kmeans.predict(df_reduced)","b822ced9":"tsne = TSNE(learning_rate=200)\ndf_tsne = tsne.fit_transform(df_reduced)\nxs = df_tsne[:,0]\nys = df_tsne[:,1]\nplt.scatter(xs, ys, c=cluster)\nplt.show()","eeb2d6bc":"fig = plt.figure(figsize=(10, 10))\nax = fig.add_subplot(projection='3d')\nax.scatter(xs=df_reduced[:,0], ys=df_reduced[:,1], zs=df_reduced[:,2], c=cluster)","90c511ef":"df[\"cluster\"] = cluster\ndf_map = df[[\"AirportCode\", \"City\", \"LocationLat\", \"LocationLng\", \"cluster\"]]","55cd308e":"color = {0:\"red\", 1:\"green\", 2:\"blue\", 3:\"yellow\", 4:\"purple\"}\n\ndf_map[\"color\"] = df_map[\"cluster\"].map(color)\n\nmap = folium.Map(location=[38, -92], zoom_start=4)\n\nfor index, row in df_map.iterrows():\n    folium.vector_layers.CircleMarker([row[\"LocationLat\"], row[\"LocationLng\"]],\n        radius=4,\n        color=row[\"color\"],\n        fill=True,\n        fill_color=row[\"color\"],\n        fill_opacity=1,\n        tooltip=row[\"AirportCode\"] + \" \" + row[\"City\"]).add_to(map)\nmap","01e3a807":"Merging resulting clusters into dataframe.","acf12e9e":"For K-Means clustering it is needed to know exact number of clusters so we use elbow method to find out how many clusters are relevant for the dataset","3aa39986":"Based on chart above only 3 variables are relevant enough so those 3 will be used in clustering","3254eaa8":"Now lets see if selected number of clusters makes sense with a help of T-SNE and 3D scatter plot.","caa3ca80":"Lets see how results of our clustering look on a map.","73488b06":"Selecting only relevant columns and grouping selected variables by facts so we can get count of occurences for individual events by Airport","2660bbc2":"Based on chart above it is not obvious how many clusters we shoud use so I will proceed with 5 and vizualize the data to see if it is relevant. Now performing K-Means clustering with 5 clusters.","3e15c707":"Generating df with input variebles only","33e1f270":"Performing PCA so we can select only variebles that are relevant and have informative value for the analysis","4d0b1cb2":"Importing CSV file into dataframe and performing basic checks.","c4caeedf":"Resulting clusters have visible outliers, but still can give us good starting point for the futher research.","9de596c4":"**We have the data consisting if weather events occurences on airports in the USA, lets look at if we can group those airports based on their weather conditions so we can have for example a baseline for setting up new guidelines for gven Airports**"}}