{"cell_type":{"5c89866f":"code","0ed2382a":"code","d3702f14":"code","574247e4":"code","ca9192b5":"code","9b744e3b":"code","bcd552b6":"code","5bbec452":"code","35f1ab46":"code","161f4d34":"code","56b0622d":"code","47ac9157":"code","36698f8b":"code","e0cadaf3":"code","414fc08f":"code","4dc988ce":"code","cbcfff50":"code","c51ff162":"code","a4ab29e4":"markdown","9db156b7":"markdown","a7526e42":"markdown","cf4a719f":"markdown","79c6507e":"markdown","9ba527ca":"markdown","d5aece54":"markdown","01dc38b0":"markdown","42a75167":"markdown","faa6766f":"markdown","aa3d399e":"markdown"},"source":{"5c89866f":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","0ed2382a":"df=pd.read_csv(\"..\/input\/iris-data\/Iris.csv\")","d3702f14":"df.head()","574247e4":"df.drop('Id', axis=1, inplace=True)","ca9192b5":"from sklearn import preprocessing\ndf_categorical = df.select_dtypes(include=['object'])\nle = preprocessing.LabelEncoder()\ndf_categorical = df_categorical.apply(le.fit_transform)\ndf_categorical.head()","9b744e3b":"df = df.drop(df_categorical.columns, axis=1)\ndf = pd.concat([df, df_categorical], axis=1)\ndf.head()","bcd552b6":"df.Species.value_counts()","5bbec452":"df_copy=df.copy()\n# Putting feature variable to X\nX = df.drop('Species',axis=1)\n\n# Putting response variable to y\ny = df['Species']","35f1ab46":"from sklearn.tree import DecisionTreeClassifier\n# Fitting the decision tree with default hyperparameters\ndt_1 = DecisionTreeClassifier()\ndt_1.fit(X, y)","161f4d34":"# !pip install dtreeviz","56b0622d":"from dtreeviz.trees import dtreeviz\n\nviz = dtreeviz(dt_1, X, y,\n                target_name=\"Species\",\n                feature_names=X.columns,\n                class_names=list(le.classes_))\n\nviz ","47ac9157":"# Putting feature variable to X\nX = df_copy.drop('Species',axis=1)\n\n# Putting response variable to y\ny = df_copy['Species']","36698f8b":"# Importing train-test-split \nfrom sklearn.model_selection import train_test_split","e0cadaf3":"# Splitting the data into train and test\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.30, \n                                                    random_state = 99)\nX_train.head()","414fc08f":"dt_2 = DecisionTreeClassifier()\ndt_2.fit(X_train, y_train)","4dc988ce":"# Importing classification report and confusion matrix from sklearn metrics\nfrom sklearn.metrics import accuracy_score\n\n# Making predictions\ny_pred = dt_2.predict(X_test)","cbcfff50":"print(accuracy_score(y_test,y_pred))","c51ff162":"# classification metrics\nfrom sklearn.metrics import classification_report,confusion_matrix\nprint(classification_report(y_test, y_pred))","a4ab29e4":"- We now proceed to build a decision tree","9db156b7":"- We can see that we have a very good accuracy score.","a7526e42":"#### Accuracy and Classification","cf4a719f":"- Merge the encoded variable back into the original data frame","79c6507e":"- We can see that we have a very good precision score as well.","9ba527ca":"### Importing and Understanding Data","d5aece54":"We can see that our final dependent variable i.e. Species is categorical we can encode it to 1,2 and 3 for simplicity.\n- 1 for Iris-setosa\n- 2 for Iris-versicolor\n- 3 for Iris-virginica\n- For this we use the label encoder.","01dc38b0":"- We drop the ID Variable since it is unique in nature and would not give us any insights.","42a75167":"#### Visualizing the Decision Tree","faa6766f":"- We can now feed any new\/test data to this classifer and it would be able to predict the right class accordingly.\n- We can check by building a new model and dividing the data set into test and train datasets.","aa3d399e":"## Prediction using Decision Tree Algorithm\n### By Rutwik V Jangam\n### GRIPDEC20\nDataset : https:\/\/bit.ly\/3kXTdox"}}