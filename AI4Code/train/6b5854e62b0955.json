{"cell_type":{"3687afcc":"code","18313da5":"code","bf8eca75":"code","ed552536":"code","3b0a9dfd":"code","55b4c390":"code","24fe37b3":"code","b3f9a570":"code","60a32d62":"code","e4f2a47c":"code","cc25c5d9":"code","d926f3c8":"code","56d912a5":"code","7993e79e":"code","514e09ce":"code","15823ccf":"code","66f75b6b":"code","4ecc5b50":"code","69376430":"code","3c7e435a":"code","6ca242dd":"code","793782e1":"code","f9606a44":"code","595bf46e":"code","2a9b9251":"code","75688508":"code","38ff5238":"code","1c1d1283":"code","2b86e859":"code","89fdc06e":"code","64ff7ed3":"code","6ace5dad":"code","417a283a":"code","8093ace1":"code","f309a575":"code","6f9307c0":"code","fa727264":"code","d1a02035":"code","ba829b41":"code","de9d4dde":"code","22668adf":"code","494792ef":"code","4f603748":"code","5f5d5eb8":"code","53e13e9b":"code","abd4590e":"code","7f05ae8a":"code","e478b78f":"code","a946db98":"code","48c9c1e5":"code","6ada9ea9":"code","09068f83":"code","08328c53":"markdown","055229c3":"markdown","72ed8191":"markdown","fe8c18ba":"markdown","191c3329":"markdown","ff44de98":"markdown","973fc6f9":"markdown","2aa76cd8":"markdown","161a8fae":"markdown","ab5b7e6b":"markdown","29389b4e":"markdown","4d61f3f4":"markdown","e598d871":"markdown","25ca1240":"markdown","3b7c669d":"markdown","283ac540":"markdown","6c2ddbce":"markdown","84c7cc96":"markdown","ac0e111c":"markdown","90c047dc":"markdown","4b8100c0":"markdown","752b5144":"markdown","86680326":"markdown","c290ed0a":"markdown","fb45e51c":"markdown","70bec3db":"markdown","8967e9a2":"markdown","bad8a240":"markdown","a1b9875d":"markdown","8c5d3bf0":"markdown","b4004e40":"markdown","29ff55e6":"markdown","f2bafb33":"markdown","3f676194":"markdown","5f8e1bb6":"markdown","53a1772e":"markdown","ac7be36d":"markdown","13684a6b":"markdown","9444f56d":"markdown","e79fdd5a":"markdown","b21757d9":"markdown","c8b0b37e":"markdown","58f3995f":"markdown","fc6a31a1":"markdown","67616b9d":"markdown","5cfb0769":"markdown"},"source":{"3687afcc":"from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_curve, auc\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\nimport string\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport seaborn as sns\nsns.set(style=\"darkgrid\")","18313da5":"def combine_dataframes(train_data, test_data):\n    \"\"\" Returns a combined dataframe containing testing and training datasets \"\"\"\n    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)\n\ndef divide_dataframes(combined_data):\n    \"\"\" Returns the divided testing and training dataframes from the combined dataset \"\"\"\n    return combined_data.loc[:890], combined_data.loc[891:].drop(['Survived'], axis=1)\n\n# import datasets and store within dataframes\ntrain_data = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('..\/input\/titanic\/test.csv')\n\n# combine datasets so that operations can be performed on both simultaneously\ncombined_data = combine_dataframes(train_data, test_data)\n\n# assign names to the dataframes\ntrain_data.name = 'Training Dataset'\ntest_data.name = 'Testing Dataset'\ncombined_data.name = 'Combined Dataset'\n\ndataframes = [train_data, test_data]","bf8eca75":"print('# of Training Entries: {}'.format(train_data.shape[0]))\nprint('# of Testing Entries: {}\\n'.format(test_data.shape[0]))\n\nprint('Training X Shape: {}'.format(train_data.shape))\nprint('Training y Shape: {}\\n'.format(train_data['Survived'].shape[0]))\n\nprint('Testing X Shape: {}'.format(test_data.shape))\nprint('Testing y Shape: {}\\n'.format(test_data.shape[0]))\n\nprint(train_data.columns)\nprint(test_data.columns)","ed552536":"# print five random samples from the training dataset\ntrain_data.sample(5)","3b0a9dfd":"# show descriptive statistics\ntrain_data.describe()\n\n\n# Arguments for each feature:\n#    * For 'Survived', use \"percentiles=[.61, .62]\"\n#    * For 'Parch', use \"percentiles=[.75, .80]\"\n#    * For 'SibSp', use \"percentiles=[.68, .69]\"\n#    * For 'Age' and 'Fare', use \"percentiles=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99]\"","55b4c390":"# show descriptive statistics for categorical features\ntrain_data.describe(include=['O'])","24fe37b3":"# show missing values in training data\nprint(\"Missing Values in Training Data\")\nprint(\"-\" * 31)\nprint(train_data.isnull().sum())\nprint(\"_\" * 31)","b3f9a570":"# show missing values in testing data\nprint(\"Missing Values in Testing Data\")\nprint(\"-\" * 30)\nprint(test_data.isnull().sum())\nprint(\"-\" * 30)","60a32d62":"# show correlations between 'age' and other features\ncorrelation_data = combined_data.corr().abs().unstack().sort_values(kind='quicksort', ascending=False).reset_index()\ncorrelation_data.rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\", 0: \"Correlation Coefficient\"}, inplace=True)\ncorrelation_data[correlation_data['Feature 1'] == 'Age']","e4f2a47c":"# show median 'age' for each 'Pclass'\/'Sex' group\nage_by_pclass_sex = combined_data.groupby(['Sex', 'Pclass']).median()['Age']\n\nfor pclass in range(1, 4):\n    for sex in ['female', 'male']:\n        print(\"Median 'Age' of Pclass {} {}s: {}\".format(pclass, sex, age_by_pclass_sex[sex][pclass]))\n\n# show median 'age' for all passengers\nprint(\"\\nMedian 'Age' of all passengers: {}\".format(combined_data['Age'].median()))","cc25c5d9":"# fill missing 'age' values with the shared median of the passengers 'pclass' and 'sex'\ncombined_data['Age'] = combined_data.groupby(['Sex', 'Pclass'])['Age'].apply(\n    lambda x: x.fillna(x.median()))","d926f3c8":"# show the most frequently occurring port\nprint(\"Most frequent value for 'Embarked': {}\".format(combined_data['Embarked'].dropna().mode()[0]))","56d912a5":"# show entries with missing values for 'embarked'\ncombined_data[combined_data['Embarked'].isnull()]","7993e79e":"# fill missing 'embarked' fields with 'S'\ncombined_data['Embarked'] = combined_data['Embarked'].fillna('S')","514e09ce":"# show entry with missing 'fare' value\ncombined_data[combined_data['Fare'].isnull()]","15823ccf":"# fill missing 'fare' field with the median 'fare' value for third-class males\ncombined_data['Fare'] = combined_data['Fare'].fillna(\n                    combined_data.groupby(['Pclass', 'Parch', 'SibSp'])['Fare'].median()[3][0][0])","66f75b6b":"# create 'deck' feature by extracting the first letter from the 'cabin' feature\ncombined_data['Deck'] = combined_data['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')\n\n# move passenger from 'deck' T to A\nindex = combined_data[combined_data['Deck'] == 'T'].index\ncombined_data.loc[index, 'Deck'] = 'A'","4ecc5b50":"# create dataframe consisting of a 'count' for each combination of 'deck' and 'pclass'\ndeck_pclass = combined_data.groupby(['Deck', 'Pclass']).count().drop(columns=['Survived', 'Sex',\n        'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Cabin', 'PassengerId', 'Ticket']).rename(\n        columns={'Name': 'Count'}).transpose()\n\ndef get_pclass_dist(dataframe):\n    \"\"\" Return the total passengers and class percentages per deck \"\"\"\n    \n    # create dict. containing passenger class count for each deck\n    deck_dict = {'A': {}, 'B': {}, 'C': {}, 'D': {}, 'E': {}, 'F': {}, 'G': {}, 'M': {}, 'T': {}}\n    \n    # create an index of decks\n    deck_index = dataframe.columns.levels[0]\n    \n    # count the number of passengers for each class, for each deck (ignore missing values)\n    for deck in deck_index:\n        for pclass in range(1, 4):\n            try:\n                count = dataframe[deck][pclass][0]\n                deck_dict[deck][pclass] = count\n            except KeyError:\n                deck_dict[deck][pclass] = 0\n\n    # convert deck_dict to dataframe and init. deck_percentages var\n    deck_counts = pd.DataFrame(deck_dict)\n    deck_percentages = {}\n    \n    # create dict. containing passenger class percentage for each deck\n    for col in deck_counts.columns:\n        deck_percentages[col] = [(count \/ deck_counts[col].sum()) * 100 for count in deck_counts[col]]\n    \n    print(deck_dict)\n    \n    return deck_dict, deck_percentages\n\ndef show_pclass_dist(percentages):\n    \"\"\" Show the passenger count distribution per deck \"\"\"\n    \n    # define class percentages and deck names\n    deck_percentages = pd.DataFrame(percentages).transpose()\n    deck_names = ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'M', 'T')\n    \n    # bar parameters\n    bar_count = np.arange(len(deck_names))\n    bar_width = 0.85\n    \n    # extract each deck's class distribution\n    pclass_1 = deck_percentages[0]\n    pclass_2 = deck_percentages[1]\n    pclass_3 = deck_percentages[2]\n    \n    # plot figure\n    plt.figure(figsize=(20, 10))\n    plt.bar(bar_count, pclass_1, color='#003f5c', edgecolor='white', width=bar_width, label='1st Class Passengers')\n    plt.bar(bar_count, pclass_2, bottom=pclass_1, color='#bc5090', edgecolor='white', width=bar_width, label='2nd Class Passengers')\n    plt.bar(bar_count, pclass_3, bottom=pclass_1+pclass_2, color='#ffa600', edgecolor='white', width=bar_width, label='3rd Class Passengers')\n    \n    # label figure\n    plt.xlabel('Deck', size=15, labelpad=20)\n    plt.ylabel('Passenger Class Percentage', size=15, labelpad=20)\n    plt.xticks(bar_count, deck_names)\n    plt.tick_params(axis='x', labelsize=15)\n    plt.tick_params(axis='y', labelsize=15)\n    \n    # figure title and legend\n    plt.legend(loc='upper left', bbox_to_anchor=(1,1), prop={'size': 15})\n    plt.title('Passenger Class Distribution by Deck', size=18, y=1.05)\n    \n    plt.show()\n\ndeck_count, deck_percentage = get_pclass_dist(deck_pclass)\nshow_pclass_dist(deck_percentage)","69376430":"# create dataframe consisting of the 'count' of the number of survivors\/perished for each deck\ndeck_survived = combined_data.groupby(['Deck', 'Survived']).count().drop(columns=['Sex', 'Age',\n    'SibSp', 'Parch', 'Fare', 'Embarked', 'Pclass', 'Cabin', 'PassengerId', 'Ticket']).rename(\n        columns={'Name':'Count'}).transpose()\n\ndef get_survived_dist(dataframe):\n    \"\"\" Return the no. of passengers and percentage of passengers that survived, per deck \"\"\"\n    \n    # create dict. containing survival count for each deck\n    deck_dict = {'A': {}, 'B': {}, 'C': {}, 'D': {}, 'E': {}, 'F': {}, 'G': {}, 'M':{}}\n    \n    # create an index of decks\n    deck_index = dataframe.columns.levels[0]\n    \n    # count the number of passengers that survived for each deck\n    for deck in deck_index:\n        for survive in range(0, 2):\n            deck_dict[deck][survive] = dataframe[deck][survive][0]\n    \n    # convert deck_dict to dataframe and init. deck_percentages var\n    deck_counts = pd.DataFrame(deck_dict)\n    deck_percentages = {}\n    \n    # create dict. containing survival percentage for each deck\n    for col in deck_counts.columns:\n        deck_percentages[col] = [(count \/ deck_counts[col].sum()) * 100 for count in deck_counts[col]]\n    \n    return deck_index, deck_percentages\n\ndef show_survived_dist(percentages):\n    \"\"\" Show the survival distribution per deck \"\"\"\n    \n    # define survival percentages and deck names\n    deck_percentages = pd.DataFrame(percentages).transpose()\n    deck_names = ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'M')\n    \n    # bar parameters\n    bar_count = np.arange(len(deck_names))\n    bar_width = 0.85\n    \n    # extract survival rate distribution\n    perished = deck_percentages[0]\n    survived = deck_percentages[1]\n    \n    # plot figure\n    plt.figure(figsize=(20, 10))\n    plt.bar(bar_count, perished, color='#003f5c', edgecolor='white', width=bar_width, label='Perished')\n    plt.bar(bar_count, survived, bottom=perished, color='#bc5090', edgecolor='white', width=bar_width, label='Survived')\n    \n    # label figure\n    plt.xlabel('Deck', size=15, labelpad=20)\n    plt.ylabel('Survival Percentage', size=15, labelpad=20)\n    plt.xticks(bar_count, deck_names)\n    plt.tick_params(axis='x', labelsize=15)\n    plt.tick_params(axis='y', labelsize=15)\n    \n    # figure title and legend\n    plt.legend(loc='upper left', bbox_to_anchor=(1,1), prop={'size': 15})\n    plt.title('Survival Percentage by Deck', size=18, y=1.05)\n    \n    plt.show()\n\ndeck_count, deck_percentage = get_survived_dist(deck_survived)\nshow_survived_dist(deck_percentage)","3c7e435a":"# group decks based on correlations and similarities\ncombined_data['Deck'] = combined_data['Deck'].replace(['A', 'B', 'C'], 'ABC')\ncombined_data['Deck'] = combined_data['Deck'].replace(['D', 'E'], 'DE')\ncombined_data['Deck'] = combined_data['Deck'].replace(['F', 'G'], 'FG')\n\ncombined_data.drop('Cabin', axis=1)\n\n# apply changes to both datasets\ntrain_data, test_data = divide_dataframes(combined_data)","6ca242dd":"# count number of passengers that survived and perished from the training dataset\nsurvived = train_data['Survived'].value_counts()[1]\nperished = train_data['Survived'].value_counts()[0]\n\n# calculate the survival\/perish percentage\nsurvived_percentage = survived \/ train_data.shape[0] * 100\nperished_percentage = perished \/ train_data.shape[0] * 100\n\n# print this information\nprint(\"{:.2f}% of passengers survived in the training dataset\".format(survived_percentage))\nprint(\"{:.2f}% of passengers perished in the training dataset\".format(perished_percentage))\n\n\n# init. figure and plot\nplt.figure(figsize=(10, 8))\nsns.countplot(train_data['Survived'], palette=[\"#003f5c\", \"#bc5090\"])\n\n# configure labels\nplt.xlabel('Outcome', size=15, labelpad=15)\nplt.ylabel('Passenger Count', size=15, labelpad=15)\nplt.xticks((0,1), ['Perished ({0:.2f}%)'.format(perished_percentage), 'Survived ({0:.2f}%)'.format(survived_percentage)])\nplt.tick_params(axis='x', labelsize=13)\nplt.tick_params(axis='y', labelsize=13)\n\nplt.title(\"Survival Distribution on Training Dataset\", size=15, y=1.05)\n\nplt.show()","793782e1":"# create dataframe containing correlations between features, sorted by ascending\ntraining_correlation = train_data.drop(['PassengerId'], axis=1).corr().abs().unstack().sort_values(\n    kind='quicksort', ascending=False).reset_index()\n\n# rename columns\ntraining_correlation.rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\",\n                                     0: \"Correlation Coefficient\"}, inplace=True)\n\n#  remove inverted instances of the same comparison (e.g. 'Pclass' & 'Fare' and 'Fare' & 'Pclass')\ntraining_correlation.drop(training_correlation.iloc[1::2].index, inplace=True)\n\n# drop entries where coefficient == 1.0 (comparing the same features)\ntraining_correlation = training_correlation.drop(training_correlation[training_correlation['Correlation Coefficient'] == 1.0].index)\n\n# show pairs with high correlation\ntraining_correlation[training_correlation['Correlation Coefficient'] > 0.1]","f9606a44":"# define figure\nfig, axs = plt.subplots(nrows=1, figsize=(20,20))\n\n# create heatmap\nsns.heatmap(train_data.drop(['PassengerId'], axis=1).corr(), annot=True, square=True,\n            cmap=(sns.light_palette(\"#bc5090\", as_cmap=True)), annot_kws={'size': 14})\n\n# label axis\naxs.tick_params(axis='x', labelsize=20)\naxs.tick_params(axis='y', labelsize=20)\naxs.set_title(\"Correlations in Training Dataset\", size=25)\n\nplt.show()","595bf46e":"# create dataframe containing correlations between features, sorted by ascending\ntesting_correlation = test_data.drop(['PassengerId'], axis=1).corr().abs().unstack().sort_values(\n    kind='quicksort', ascending=False).reset_index()\n\n# rename columns\ntesting_correlation.rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\",\n                                     0: \"Correlation Coefficient\"}, inplace=True)\n\n#  remove inverted instances of the same comparison (e.g. 'Pclass' & 'Fare' and 'Fare' & 'Pclass')\ntesting_correlation.drop(testing_correlation.iloc[1::2].index, inplace=True)\n\n# drop entries where coefficient == 1.0 (comparing the same features)\ntesting_correlation = testing_correlation.drop(testing_correlation[testing_correlation['Correlation Coefficient'] == 1.0].index)\n\n# show pairs with high correlation\ntesting_correlation[testing_correlation['Correlation Coefficient'] > 0.1]\n\n# show pairs with high correlation\ntesting_correlation[testing_correlation['Correlation Coefficient'] > 0.1]","2a9b9251":"# define figure\nfig, axs = plt.subplots(nrows=1, figsize=(20,20))\n\n# create heatmap\nsns.heatmap(test_data.drop(['PassengerId'], axis=1).corr(), annot=True, square=True,\n            cmap=(sns.light_palette(\"#bc5090\", as_cmap=True)), annot_kws={'size': 14})\n\n# label axis\naxs.tick_params(axis='x', labelsize=20)\naxs.tick_params(axis='y', labelsize=20)\naxs.set_title(\"Correlations in Testing Dataset\", size=25)\n\nplt.show()","75688508":"# store target and continuous variables\ncont_ftrs = ['Age', 'Fare']\nsurv_psgrs = train_data['Survived'] == 1\n\n# init. plot\nfig, axs = plt.subplots(ncols=2, nrows=2, figsize=(20,20))\nplt.subplots_adjust(right=1.5)\n\n# plot each feature against survival rate\nfor i, feature in enumerate(cont_ftrs):\n    # distribution of survival amongst features\n    sns.distplot(train_data[~surv_psgrs][feature], label='Perished', hist=True, color='#003f5c', ax=axs[0][i])\n    sns.distplot(train_data[ surv_psgrs][feature], label='Survived', hist=True, color='#bc5090', ax=axs[0][i])\n    \n    # distribution of features in the dataset\n    sns.distplot(train_data[feature], label='Training Dataset', hist=False, color='#003f5c', ax=axs[1][i])\n    sns.distplot( test_data[feature], label='Testing Dataset',  hist=False, color='#bc5090', ax=axs[1][i])\n    \n    # set labels and change their size\n    axs[0][i].set_xlabel('')\n    axs[1][i].set_xlabel('')\n    \n    for j in range(2):\n        axs[i][j].tick_params(axis='x', labelsize=20)\n        axs[i][j].tick_params(axis='y', labelsize=20)\n    \n    # add legend and titles\n    axs[0][i].legend(loc='upper right', prop={'size': 20})\n    axs[1][i].legend(loc='upper right', prop={'size': 20})\n    \n    axs[0][i].set_title('Distribution of Survival in {}'.format(feature), size=20, y=1.05)\n\naxs[1][0].set_title('Distribution of {}'.format('Age'), size=20, y=1.05)\naxs[1][1].set_title('Distribution of {}'.format('Fare'), size=20, y=1.05)\n    \nplt.show()","38ff5238":"# store categorical features\ncat_ftrs = ['Embarked', 'Parch', 'Pclass', 'Sex', 'SibSp', 'Deck']\n\n# define figure\nfig, axs = plt.subplots(ncols=2, nrows=3, figsize=(20,20))\nplt.subplots_adjust(right=1.5, top=1.25)\n\n# plot each feature against survival\nfor i, feature in enumerate(cat_ftrs, 1):\n    plt.subplot(2, 3, i)\n    sns.countplot(x=feature, hue='Survived', palette=[\"#003f5c\", \"#bc5090\"], data=train_data)\n    \n    # set up labels\n    plt.xlabel('{}'.format(feature), size=20, labelpad=15)\n    plt.ylabel('Passenger Count', size=20, labelpad=15)\n    plt.tick_params(axis='x', labelsize=20)\n    plt.tick_params(axis='y', labelsize=20)\n    \n    # add legend and title\n    plt.legend(['Perished', 'Survived'], loc='upper center', prop={'size': 18})\n    plt.title('Survival Rate wrt {}'.format(feature), size=20, y=1.05)\n\nplt.show()","1c1d1283":"# bin 'Fare'\ncombined_data['Fare'] = pd.qcut(combined_data['Fare'], 13)","2b86e859":"# define figure\nfig, axs = plt.subplots(figsize=(22,9))\nsns.countplot(x='Fare', hue='Survived', palette=[\"#003f5c\", \"#bc5090\"], data=combined_data)\n\n# set labels\nplt.xlabel('Fare', size=15, labelpad=20)\nplt.ylabel('Passenger Count', size=15, labelpad=20)\nplt.tick_params(axis='x', labelsize=10)\nplt.tick_params(axis='y', labelsize=15)\n\n# set legend and title\nplt.legend(['Perished', 'Survived'], loc='upper right', prop={'size': 15})\nplt.title('Survival Count wrt {}'.format('Fare', size=15, y=1.05))\n\nplt.show()","89fdc06e":"# bin 'Age'\ncombined_data['Age'] = pd.qcut(combined_data['Age'], 10)","64ff7ed3":"# define figure\nfig, axs = plt.subplots(figsize=(22,9))\nsns.countplot(x='Age', hue='Survived', palette=[\"#003f5c\", \"#bc5090\"], data=combined_data)\n\n# set labels\nplt.xlabel('Age', size=15, labelpad=20)\nplt.ylabel('Passenger Count', size=15, labelpad=20)\nplt.tick_params(axis='x', labelsize=10)\nplt.tick_params(axis='y', labelsize=15)\n\n# set legend and title\nplt.legend(['Perished', 'Survived'], loc='upper right', prop={'size': 15})\nplt.title('Survival Count wrt {}'.format('Fare', size=15, y=1.05))\n\nplt.show()","6ace5dad":"# create 'FamilySize' feature\ncombined_data['FamilySize'] = combined_data['SibSp'] + combined_data['Parch'] + 1","417a283a":"# define figure\nfig, axs = plt.subplots(figsize=(20,20), ncols=2, nrows=2)\nplt.subplots_adjust(right=1.5)\n\n# plot family size value counts before grouping\nsns.barplot(x=combined_data['FamilySize'].value_counts().index, y=combined_data['FamilySize'].value_counts().values, palette=[\"#003f5c\", \"#bc5090\"], ax=axs[0][0])\nsns.countplot(x='FamilySize', hue='Survived', palette=[\"#003f5c\", \"#bc5090\"], data=combined_data, ax=axs[0][1])\n\n# set titles\naxs[0][0].set_title('Family Size Feature Value Counts (Before Grouping)', size=20, y=1.05)\naxs[0][1].set_title('Survival Count wrt Family Size (Before Grouping)', size=20, y=1.05)\n\n# map 'FamilySize' into groups\nfamily_map = {1: 'Alone', 2: 'Small', 3: 'Small', 4: 'Small', 5: 'Medium', 6: 'Medium', 7: 'Large', 8: 'Large', 11: 'Large'}\ncombined_data['GroupedFamilySize'] = combined_data['FamilySize'].map(family_map)\n\n# plot family size value counts after grouping\nsns.barplot(x=combined_data['GroupedFamilySize'].value_counts().index, y=combined_data['GroupedFamilySize'].value_counts().values, palette=[\"#003f5c\", \"#bc5090\"], ax=axs[1][0])\nsns.countplot(x='GroupedFamilySize', hue='Survived', palette=[\"#003f5c\", \"#bc5090\"], data=combined_data, ax=axs[1][1])\n\n# set titles\naxs[1][0].set_title('Family Size Feature Value Counts (After Grouping)', size=20, y=1.05)\naxs[1][1].set_title('Survival Count wrt Family Size (After Grouping)', size=20, y=1.05)\n\n# set labels and legend\nfor i in range(2):\n    axs[i][1].legend(['Perished', 'Survived'], loc='upper right', prop={'size': 20})\n    \n    for j in range(2):\n        axs[i][j].tick_params(axis='x', labelsize=20)\n        axs[i][j].tick_params(axis='y', labelsize=20)\n        axs[i][j].set_xlabel('')\n        axs[i][j].set_ylabel('')\n\nplt.show()","8093ace1":"# create 'TicketFreq' feature\ncombined_data['TicketFreq'] = combined_data.groupby('Ticket')['Ticket'].transform('count')","f309a575":"# define figure\nfig, axs = plt.subplots(figsize=(12, 9))\n\n# plot survival rate based on ticket frequency\nsns.countplot(x='TicketFreq', hue='Survived', palette=[\"#003f5c\", \"#bc5090\"], data=combined_data)\n\n# set labels\nplt.xlabel('Ticket Frequency', size=15, labelpad=20)\nplt.ylabel('Passenger Count', size=15, labelpad=20)\nplt.tick_params(axis='x', labelsize=15)\nplt.tick_params(axis='y', labelsize=15)\n\n# set title and legend\nplt.legend(['Perished', 'Survived'], loc='upper right', prop={'size': 15})\nplt.title('Suruvival Count wrt {}'.format('TicketFreq'), size=15, y=1.05)\n\nplt.show()","6f9307c0":"# create 'Title' feature, extracted from 'Name'\ncombined_data['Title'] = combined_data['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n\n# create 'IsMarried' feature, where 'Title'=='Mrs'\ncombined_data['IsMarried'] = 0\ncombined_data['IsMarried'].loc[combined_data['Title'] == 'Mrs'] = 1","fa727264":"# define figure\nfig, axs = plt.subplots(nrows=2, figsize=(20,20))\n\n# plot title value counts before grouping\nsns.barplot(x=combined_data['Title'].value_counts().index, y=combined_data['Title'].value_counts().values, palette=[\"#003f5c\", \"#bc5090\"], ax=axs[0])\n\n# set labels\naxs[0].tick_params(axis='x', labelsize=10)\naxs[1].tick_params(axis='x', labelsize=15)\n\nfor i in range(2):\n    axs[i].tick_params(axis='y', labelsize=15)\n\n# set title\naxs[0].set_title('Title Value Counts (Before Grouping)', size=20, y=1.05)\n\n# replace female titles with 'Miss\/Mrs\/Ms'\ncombined_data['Title'] = combined_data['Title'].replace(['Miss', 'Mrs', 'Ms', 'Mlle', 'Lady', 'Mme', 'the Countess', 'Dona'], 'Miss\/Mrs\/Ms')\n\n# replace unique titles with 'Dr\/Military\/Noble\/Clergy'\ncombined_data['Title'] = combined_data['Title'].replace(['Dr', 'Col', 'Major', 'Jonkheer', 'Capt', 'Sir', 'Don', 'Rev'], 'Dr\/Military\/Noble\/Clergy')\n\n# plot title value counts after grouping\nsns.barplot(x=combined_data['Title'].value_counts().index, y=combined_data['Title'].value_counts().values, palette=[\"#003f5c\", \"#bc5090\"], ax=axs[1])\n\n# set title\naxs[1].set_title('Title Value Counts (After Grouping)', size=20, y=1.05)\n\nplt.show()","d1a02035":"def extractSurname(data):\n    \"\"\" Extract surnames from passenger entries using the 'Name' feature \"\"\"\n    \n    # store family names\n    families = []\n    \n    for i in range(len(data)):\n        # acquire passenger name\n        name = data.iloc[i]\n        \n        # remove brackets from name\n        if '(' in name:\n            name_no_bracket = name.split('(')[0]\n        else:\n            name_no_bracket = name\n        \n        \n        # the surname appears at the start of the passenger names, followed by a comma\n        family = name_no_bracket.split(',')[0]\n        title = name_no_bracket.split(',')[1].strip().split(' ')[0]\n        \n        # remove punctuation\n        for c in string.punctuation:\n            family = family.replace(c, '').strip()\n        \n        families.append(family)\n    \n    return families\n\n# create 'FamilyName' feature\ncombined_data['FamilyName'] = extractSurname(combined_data['Name'])\n\n# split combined data back into train\/test datasets\ntrain_data, test_data = divide_dataframes(combined_data)\ndataframes = [train_data, test_data]","ba829b41":"# get a list of family names that occur in both testing and training datasets\nnon_unique_families = [x for x in train_data['FamilyName'].unique() if x in test_data['FamilyName'].unique()]\n\n# get each family's median survival rate in the training dataset\nfamily_survival_rate = train_data.groupby('FamilyName')['Survived', 'FamilyName', 'FamilySize'].median()\n\n# store the median survival rate for each family in the training dataset\nfamily_rates = {}\n\n# store the median survival rate of each family that has more than one member across both datasets\nfor i in range(len(family_survival_rate)):\n    if family_survival_rate.index[i] in non_unique_families and family_survival_rate.iloc[i, 1] > 1:\n        family_rates[family_survival_rate.index[i]] = family_survival_rate.iloc[i, 0]","de9d4dde":"# calculate the mean survival rate across all passengers in training set\nmean_survival_rate = np.mean(train_data['Survived'])\n\n# store family survival rates\ntrain_family_survival_rate = []\ntrain_family_survival_rate_NA = []\ntest_family_survival_rate = []\ntest_family_survival_rate_NA = []\n\nfor i in range(len(train_data)):\n    # if the passenger's family name occurs in 'family_rates' (and thefore the training set)\n    if train_data['FamilyName'][i] in family_rates:\n        # store the family survival rate\n        train_family_survival_rate.append(family_rates[train_data['FamilyName'][i]])\n        # mark that the family does exist in the training set\n        train_family_survival_rate_NA.append(1)\n    else:\n        # store mean survival rate\n        train_family_survival_rate.append(mean_survival_rate)\n        # mark that the family doesn't exist in the training set\n        train_family_survival_rate_NA.append(0)\n\nfor i in range(len(test_data)):\n    # if the passenger's family name occurs in 'family rates' (and therefore the training set)\n    if test_data['FamilyName'].iloc[i] in family_rates:\n        # store the family survival rate\n        test_family_survival_rate.append(family_rates[test_data['FamilyName'].iloc[i]])\n        # mark that the family does exist in the training set\n        test_family_survival_rate_NA.append(1)\n    else:\n        # store mean survival rate\n        test_family_survival_rate.append(mean_survival_rate)\n        # mark that the family doesn't exist in the training set\n        test_family_survival_rate_NA.append(0)\n\n# add these new features to the datasets\ntrain_data['FamilySurvivalRate'] = train_family_survival_rate\ntrain_data['FamilySurvivalRateNA'] = train_family_survival_rate_NA\ntest_data['FamilySurvivalRate'] = test_family_survival_rate\ntest_data['FamilySurvivalRateNA'] = test_family_survival_rate_NA","22668adf":"# get a list of tickets that occur in both training and testing datasets\nnon_unique_tickets = [x for x in train_data['Ticket'].unique() if x in test_data['Ticket'].unique()]\n\n# get each ticket's median survival rate in the training dataset\nticket_survival_rate = train_data.groupby('Ticket')['Survived', 'Ticket', 'TicketFreq'].median()\n\n# store the median survival rate for each ticket in the training dataset\nticket_rates = {}\n\n# store the median survival rate of each ticket that has more than one member across both datasets\nfor i in range(len(ticket_survival_rate)):\n    if ticket_survival_rate.index[i] in non_unique_tickets and ticket_survival_rate.iloc[i, 1] > 1:\n        ticket_rates[ticket_survival_rate.index[i]] = ticket_survival_rate.iloc[i, 0]","494792ef":"# store ticket survival rates\ntrain_ticket_survival_rate = []\ntrain_ticket_survival_rate_NA = []\ntest_ticket_survival_rate = []\ntest_ticket_survival_rate_NA = []\n\nfor i in range(len(train_data)):\n    # if the passenger's ticket occurs in 'ticket_rates' (and thefore the training set)\n    if train_data['Ticket'][i] in ticket_rates:\n        # store the ticket survival rate\n        train_ticket_survival_rate.append(ticket_rates[train_data['Ticket'][i]])\n        # mark that the ticket does exist in the training set\n        train_ticket_survival_rate_NA.append(1)\n    else:\n        # store mean survival rate\n        train_ticket_survival_rate.append(mean_survival_rate)\n        # mark that the ticket doesn't exist in the training set\n        train_ticket_survival_rate_NA.append(0)\n\nfor i in range(len(test_data)):\n    # if the passenger's ticket occurs in 'ticket_rates' (and thefore the training set)\n    if test_data['Ticket'].iloc[i] in ticket_rates:\n        # store the ticket survival rate\n        test_ticket_survival_rate.append(ticket_rates[test_data['Ticket'].iloc[i]])\n        # mark that the ticket does exist in the training set\n        test_ticket_survival_rate_NA.append(1)\n    else:\n        # store mean survival rate\n        test_ticket_survival_rate.append(mean_survival_rate)\n        # mark that the ticket doesn't exist in the training set\n        test_ticket_survival_rate_NA.append(0)\n\n# add these new features to the datasets\ntrain_data['TicketSurvivalRate'] = train_ticket_survival_rate\ntrain_data['TicketSurvivalRateNA'] = train_ticket_survival_rate_NA\ntest_data['TicketSurvivalRate'] = test_ticket_survival_rate\ntest_data['TicketSurvivalRateNA'] = test_ticket_survival_rate_NA","4f603748":"for dataframe in [train_data, test_data]:\n    dataframe['SurvivalRate'] = (dataframe['TicketSurvivalRate'] + dataframe['FamilySurvivalRate']) \/ 2\n    dataframe['SurvivalRateNA'] = (dataframe['TicketSurvivalRateNA'] + dataframe['FamilySurvivalRateNA']) \/ 2","5f5d5eb8":"# list non-numeric features\nnon_numeric_features = ['Embarked', 'Sex', 'Deck', 'Title', 'GroupedFamilySize', 'Age', 'Fare']\n\n# label encode these features\nfor dataframe in dataframes:\n    for feature in non_numeric_features:\n        dataframe[feature] = LabelEncoder().fit_transform(dataframe[feature])","53e13e9b":"# list categorical features\ncategorical_features = ['Pclass', 'Sex', 'Deck', 'Embarked', 'Title', 'GroupedFamilySize']\nencoded_features = []\n\n# encode these features\nfor dataframe in dataframes:\n    for feature in categorical_features:\n        # one-hot encode features\n        encoded_feature = OneHotEncoder().fit_transform(dataframe[feature].values.reshape(-1, 1)).toarray()\n        # get the number of unique values in the feature\n        n = dataframe[feature].nunique()\n        # create new columns for each possible value for the feature\n        cols = ['{}_{}'.format(feature, n) for n in range(1, n + 1)]\n        # create dataframe containing these new columns\n        encoded_dataframe = pd.DataFrame(encoded_feature, columns=cols)\n        # ensure new dataframe rows share indexes with main dataframe\n        encoded_dataframe.index = dataframe.index\n        # store features\n        encoded_features.append(encoded_dataframe)\n\n# merge new features with training\/testing data\ntrain_data = pd.concat([train_data, *encoded_features[:6]], axis=1)\ntest_data = pd.concat([test_data, *encoded_features[6:]], axis=1)","abd4590e":"train_columns = ['Title', 'Cabin', 'Deck', 'Embarked', 'FamilyName', 'FamilySize', 'GroupedFamilySize', 'Survived', 'Name',\n               'Parch', 'PassengerId', 'Pclass', 'Sex', 'SibSp', 'Ticket', 'TicketSurvivalRate',\n               'FamilySurvivalRate', 'TicketSurvivalRateNA', 'FamilySurvivalRateNA']\n\ntest_columns = ['Title', 'Cabin', 'Deck', 'Embarked', 'FamilyName', 'FamilySize', 'GroupedFamilySize', 'Name',\n               'Parch', 'PassengerId', 'Pclass', 'Sex', 'SibSp', 'Ticket', 'TicketSurvivalRate',\n               'FamilySurvivalRate', 'TicketSurvivalRateNA', 'FamilySurvivalRateNA']","7f05ae8a":"# scale training\/testing data\nX_train = StandardScaler().fit_transform(train_data.drop(columns=train_columns))\ny_train = train_data['Survived'].values\nX_test = StandardScaler().fit_transform(test_data.drop(columns=test_columns))","e478b78f":"model = RandomForestClassifier(criterion='gini',\n                              n_estimators=1100,\n                              max_depth=5,\n                              min_samples_split=4,\n                              min_samples_leaf=5,\n                              max_features='auto',\n                              oob_score=True,\n                              random_state=42,\n                              n_jobs=-1,\n                              verbose=1)","a946db98":"model.fit(X_train, y_train)","48c9c1e5":"predictions = model.predict(X_test)","6ada9ea9":"def plot_roc_curve(fper, tper):\n    fig, axs = plt.subplots(figsize=(15,15))\n\n    axs.plot(fper, tper, color='#bc5090', label='ROC', lw=2, alpha=0.8)\n    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='#003f5c', alpha=0.8, label='Random Guessing')\n    axs.set_xlabel('False Positive Rate', size=15, labelpad=20)\n    axs.set_ylabel('True Positive Rate', size=15, labelpad=20)\n    axs.tick_params(axis='x', labelsize=15)\n    axs.tick_params(axis='y', labelsize=15)\n    axs.set_xlim([-0.05, 1.05])\n    axs.set_ylim([-0.05, 1.05])\n    \n    axs.set_title('Receiver Operating Characteristic (ROC) Curve', size=20, y=1.02)\n    axs.legend(loc='lower right', prop={'size': 13})\n    \n    plt.show()\n\nprobs = model.predict_proba(X_train)  \nprobs = probs[:, 1]  \nfper, tper, thresholds = roc_curve(y_train, probs) \nplot_roc_curve(fper, tper)","09068f83":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions.astype(int)})\noutput.to_csv('my_submission.csv', index=False)\n\noutput.head()","08328c53":"Next, we scale the data:","055229c3":"First, we specify which features are to be used during training and testing. The only difference between the two is that the `Survived` feature is not to be used during testing.","72ed8191":"## [3.5] Feature Transformation\n### [3.5.1] Label Encoding the Non-Numerical Features","fe8c18ba":"# [3] Feature Engineering\n## [3.1] Binning Continuous Features\n### [3.1.1] Fare\nBelow, we can see that the `Fare` feature is skewed positively, with the rate of survival increasing alongside the `Fare` price. Referring back to the distribution plot in section **2.5.1**, we have achieved a good amount of information gain. It's also worth noting that the group **(15.742, 23.25)** contains an unusual rate of survival.","191c3329":"### [2.2.4] Distribution of Numerical Features\n* The total number of samples is **891**. This is **40%** of the total number of passengers on board the Titanic *(2,224)*\n* Roughly **38%** of samples survived. This is representative of the actual survival rate of **32%**\n* The majority of passengers *(~75%)* did not travel with any parents and\/or children\n* Roughly **30%** of passengers travelled with a sibling and\/or spouse\n* There are few *(<1%)* elderly passengers, with an **Age** between **65** and **80**\n* **Fare** prices varied significantly, with few *(<1%)* passengers paying up to **$512**","ff44de98":"## [1.3] Initial Overview of the Data\n* The training dataset contains **891** rows *(entries)* and **12** columns *(features)*\n* The testing dataset contains **418** data entries and **11** features\n* The target feature, `Survived`, is only present in the training dataset","973fc6f9":"### [3.4.2] Ticket Survival Rate","2aa76cd8":"#### Implementation","161a8fae":"## [2.2] Missing Values   \n#### **...in the Training Data**:\n* `Age` contains **177** missing values\n* `Cabin` contains **687** missing values\n* `Embarked` contains **2** missing values","ab5b7e6b":"## [1.2] Importing Data","29389b4e":"Finally, we can create:\n* `SurvivalRate`: The average of `TicketSurvivalRate` and `FamilySurvivalRate`\n* `SurvivalRateNA`: The average of `TicketSurvivalRateNA` and `FamilySurvivalRateNA`","4d61f3f4":"...before creating two new features, similar to those created for family survival rates:\n* `TicketSurvivalRate`: The median rate of survival for the passenger's ticket\n* `TicketSurvivalRateNA`: Whether the passenger's ticket is unique to the testing set (`0`) or not (`1`)","e598d871":"### [2.2.4] Cabin\nThere is an extremely large number *(~77%)* of missing values for the `Cabin` feature. Initial thoughts may suggest simply dropping the feature entirely, however as shown below, there is a correlation between `Cabin` and `Survived`.\n\n***\n\n### Passenger Class Distribution by Deck\n\nUsing the distribution plot below, we can deduce that:\n* Decks `A`, **B**, and **C** consist **entirely** of 1st class passengers\n* Deck `D` consists of **87%** 1st class and **13%** 2nd class passengers\n* Deck `E` consists of **83%** 1st class, **10%** 2nd class, and **7%** 3rd class passengers\n* Deck `F` consists of **62%** 2nd class and **38%** 3rd class passengers\n* Deck `G` consists of **entirely** 3rd class passengers\n\nAdditionally, the console output below shows that deck `T` consists of only a single passenger. This individual shares the closest resemblance to passengers on deck `A`, so can therefore be grouped into deck `A`.\n\nEntries with missing values for `Cabin` can be assigned to `Deck 'M'` *(Missing)*.","25ca1240":"### [3.5.2] One-Hot Encoding the Categorical Features","3b7c669d":"## [2.5] Target Distribution amongst Features\n\n### [2.5.1] Continuous Features\n\nBelow, we see the correlation between features `Age` and `Fare`, against the target feature: `Survived`. While they both have significant split points suitable for a Decision Tree\/Random Forest Classifier, it's worth noting that both features appear to be more volatile in the training dataset when compared to the testing dataset - this might lead to the model being unable to generalize the testing dataset.","283ac540":"## [2.4] Feature Correlations\n\n### Significant Correlations in the Training Dataset","6c2ddbce":"### [2.2.1] Handling Missing Values for 'Age'\nWhile it would be straightforward to replace the missing values with the median age, this would be **far too general for any meaningful information gain**. Alternatively, the median age for each `Pclass` group can be used as they share a significant correlation:","84c7cc96":"## [3.2] Frequency Encoding\n### [3.2.1] Family Size\nWe can create a `FamilySize` feature by summing the values of `SibSp` and `Parch` and `1` *(the passenger in question)*. We can map the size of the family:\n* `FamilySize == 1` is classified as `Alone`\n* `FamilySize == 2`, `3`, and `4` are classified as `Small`\n* `FamilySize == 5 and 6` are classified as `Medium`\n* `FamilySize == 3`, `7`, and `11` are classified as `Large`","ac0e111c":"...fit the model:","90c047dc":"### [2.5.2] Categorical Features\nEach of the categorical features have at least one class with a higher mortality rate than the others, the most notable include: `Pclass` and `Sex` because their distributions are the most homogenous.","4b8100c0":"# [4] Modelling\n## [4.1] Creating the Random Forest Classifier","752b5144":"#### **...in the Testing Data**:\n* `Age` contains **86** missing values\n* `Cabin` contains **327** missing values\n* `Fare` contains **1** missing value","86680326":"## [2.3] Target Distribution\n* **38.38%** of the passengers in the training dataset survived\n* Conversely, **61.62%** of the passengers in the training dataset perished","c290ed0a":"# [1] Setting Up\n## [1.1] Importing Modules","fb45e51c":"...and define the model:","70bec3db":"### **Training Data Samples**","8967e9a2":"## [3.3] 'Title' and 'IsMarried'\nWe can create a `Title` feature by extracting passengers' titles from the `Name` feature. We can group all female titles under 'Miss\/Mrs\/Ms' and unique titles under 'Dr\/Military\/Noble\/Clergy'. The 'Master' title remains standalone as it is attributed to male passengers under the age of 26, who have the highest rate of survival amongst all male passengers.\n\nFurthermore, we can create a binary `IsMarried` feature based on whether a passenger holds the 'Mrs' title, as these individuals had the highest rate of survival amongst all female passengers.","bad8a240":"### **Survival Distribution by Deck**\n\nUsing the distribution plot below, we can deduce that:\n* Decks `B`, `C`, `D`, and `E` have the highest rate of survival. These decks mostly consist of 1st class passengers\n* Deck `M` had the lowest rate of survival, and mostly consists of 2nd and 3rd class passengers\n\nIt appears that **cabins housing 1st class passengers have a higher survival rate than those housing 2nd or 3rd class passengers**. Additionally, deck `M` likely has a low rate of survival due to the nature of that deck *(it contains all passengers with missing `Cabin` values)*.\n\nDue to the high cardinality of the `Deck` feature, it might prove advantageous to group entries based on similar `Deck` values:\n* Decks `A`, `B`, and `C` can be grouped as all three consist of only 1st class passengers\n* Decks `D` and `E` can be grouped as they share similar passenger\/class distributions and the same rate of survival. Decks `F` and `G` can be grouped for the same reason.\n* Deck `M` remains standalone due to its nature, and that it has the lowest rate of survival","a1b9875d":"We can extract the median rate of survival for each `Ticket`:","8c5d3bf0":"In order to further improve accuracy, the `Sex` feature can be incorporated as `Pclass` and `Sex` groups have distinct median `Age` values:","b4004e40":"While it wouldn't be a terrible idea to fill it with the median of all values that occurr within this feature, we can instead assume that `Fare` is related to family size (`Parch` + `SibSp`) and `Pclass`. This should result in a more appropriate value.\n\nBased on this assumption, the missing value can be substituted with the median `Fare` value of a **third-class male**:","29ff55e6":"## [4.2] ROC Curve\nNow, we assess the performance of the model by plotting a ROC curve:","f2bafb33":"Coincidentally, the two entries share values for `Pclass` *(`1`)* and `Sex` *(`female`)*. Further investigation confirms that the two did indeed travel together, and from the same port *(Southampton)*:\n\n> \"Mrs Stone boarded the Titanic in Southampton on 10 April 1912 and was travelling in first class with her maid Amelie Icard. She occupied cabin B-28\"   \n[Source](https:\/\/www.encyclopedia-titanica.org\/titanic-survivor\/martha-evelyn-stone.html)","3f676194":"## [4.3] Submitting to the Competition\nAll that's left to do is submit the results to the competition.","5f8e1bb6":"# [2] Exploratory Data Analysis\n## [2.1] Overview of Features\n\n* `PassengerId`: A unique identifier for each entry. This feature has no effect on the accuracy of a model, however it is required for submission to the competition\n\n### **[2.1.1] Categorical Features**:\n\n* `Survived`: Whether or not the passenger survived the incident. This is the target variable and can have a value of either **0** *(survived)* or **1** *(perished)*\n\n* `Sex`: The passenger's gender *(**male** or **female**)*\n* `Embarked`: The port through which the passenger embarked the vessel. It can have a value of **C** *(Cherbourg)*, **Q** *(Queenstown)*, or **S** *(Southampton)*\n* [Ordinal]`Pclass`: The passenger's ticket class, which is representitive of their socio-economic status. Possible values include: **1** *(first class)*, **2** *(second class)*, and **3** *(third class)*\n\n### **[2.2.2] Numerical Features**:\n\n* [Continuous] `Age`: The passenger's age\n* [Continuous] `Fare`: The cost of a passenger's fare\n* [Discrete]`SibSp`: The total siblings and\/or spouse of a passenger\n* [Discrete]`Parch`: The total parents and\/or children of a passenger\n\n### **[2.2.3] Features with Mixed Data Types**:\n\n* `Ticket`: The passenger's ticket number(s). A mix of numeric and alphanumeric entries\n* `Cabin`: The passenger's cabin number(s). Contains alphanumeric entries","53a1772e":"### Significant Correlations in the Testing Dataset ","ac7be36d":"Then, create two new features:\n* `FamilySurvivalRate`: The median rate of survival for a passenger's family\n* `FamilySurvivalRateNA`: Whether the passenger's family is unique to the testing set (`0`) or not (`1`)","13684a6b":"### [3.1.2] Age\nComparing the plot below with the distribution plot in section **2.5.1**, we can see that the `Age` feature has a normal distribution. Below, we see that the first bin has the highest rate of survival and the fourth bin has the lowest - this is reflected in the spikes in the distribution plot. Also note that group **(34.0, 40.0)** has an unusually high rate of survival.","9444f56d":"## [3.4] Target Encoding\n### [3.4.1] Family Survival Rate\n`extractSurname()` gathers passengers' surnames through the `Name` feature. We use this function to create the `FamilyName` feature, which can be used to group passengers in the same family.","e79fdd5a":"### [2.2.2] Embarked\nDue to the fact that there are only **2** missing values for the `Embarked` feature, the most commonly occurring value *(S)* can be substituted.","b21757d9":"Therefore, the missing values for `Embarked` can be filled with `S`:","c8b0b37e":"Using this new `FamilyName` feature, we can extract the median rate of survival for each family:","58f3995f":"### [2.2.5] Distribution of Categorical Features\n* `Name` entries are unique across the dataset\n* The majority of passengers *(65%)* are `male`\n* `Cabin` entries contain duplicates, likely due to passengers sharing cabins\n* `Southampton` was the most frequent port through which passengers `Embarked`\n* `Ticket` entries contain a significant number *(22%)* of duplicates","fc6a31a1":"### [3.2.2] Ticket Frequency\nThe issue with `FamilySize` is that people travelling together were not limited to those that were related to one another. Many passengers travelled in groups consisting of friends, maids, nannies, etc.\n\nUsing the graph below, we can see that groups consisting of`2`, `3`, or `4` members had an increased rate of survival when compared to the rest of the passengers on board. Furthermore, the rate of survival drops off after `4` group members.","67616b9d":"### [2.2.3] Fare\nThere is only a single missing value for `Fare`:","5cfb0769":"...before predicting on the testing set:"}}