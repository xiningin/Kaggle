{"cell_type":{"1510a619":"code","200e987b":"code","aab5a46b":"code","e823a972":"code","bb563f3c":"code","69c6c25c":"code","b17c34ca":"code","7a4208d1":"code","c68904eb":"code","da73dd6b":"code","313baf59":"code","48943194":"code","ca01bdbc":"code","02726d72":"code","a0374c76":"code","2d4f9c7e":"code","d9afcd00":"code","3554de23":"code","125e6609":"code","e451dbff":"code","1712d0c6":"code","ad34caea":"code","43e6eeeb":"code","c25463a2":"code","1a36b361":"code","7ed28e7a":"code","1eed6770":"code","27ad2a90":"code","c6018dca":"code","ea93125f":"code","f3eb77bd":"markdown","403ff7d3":"markdown","8750a2ed":"markdown","6e427292":"markdown","f7ffd954":"markdown","d13cc88d":"markdown","f11e0590":"markdown","2aea3272":"markdown","9f7ce00a":"markdown","c937fb89":"markdown"},"source":{"1510a619":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","200e987b":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","aab5a46b":"df = pd.read_csv(\"\/kaggle\/input\/creditcardfraud\/creditcard.csv\")\ndf.head()","e823a972":"print ((df[\"Class\"].value_counts()[1]\/df[\"Class\"].value_counts()[0] )* 100 , \"% of true fraud detected\")","bb563f3c":"df[\"Time\"].plot(figsize = (40,10))","69c6c25c":"# fraud\ndf[\"Amount\"][df[\"Class\"] == 1].plot(figsize = (40,10))\nplt.show()","b17c34ca":"df[\"Amount\"][df[\"Class\"] == 1].hist(figsize=(10,10))\nplt.show()","7a4208d1":"# normal\ndf[\"Amount\"][df[\"Class\"] == 0].plot(figsize = (40,10))","c68904eb":"df[\"Amount\"][df[\"Class\"] == 0].hist(figsize=(40,10), bins = 50)\nplt.show()","da73dd6b":"df.isnull().values.sum()","313baf59":"sns.distplot(df.loc[df['Class'] == 0][\"Time\"], hist=True)\nsns.distplot(df.loc[df['Class'] == 1][\"Time\"], hist=True)","48943194":"sns.boxplot(x=\"Class\", y=\"Amount\", data=df)","ca01bdbc":"sns.scatterplot(x=\"Amount\", y=\"V1\",hue=\"Class\",data=df)","02726d72":"X = df.drop([\"Class\", \"Time\"], axis = 1)\ny = df[\"Class\"]","a0374c76":"from sklearn.ensemble import IsolationForest\nfrom sklearn.metrics import classification_report,accuracy_score\nimport warnings  \nwarnings.filterwarnings('ignore')","2d4f9c7e":"fraction = df[\"Class\"].value_counts()[1]\/df[\"Class\"].value_counts()[0]","d9afcd00":"algorithm = IsolationForest(behaviour='new',contamination=fraction,random_state=42)\ny_pred = algorithm.fit(X).predict(X)\nscores_prediction = algorithm.decision_function(X)","3554de23":"(y_pred.min(), y_pred.max())","125e6609":"y_pred[y_pred == 1] = 0\ny_pred[y_pred == -1] = 1\nn_errors = (y_pred != y).sum()","e451dbff":"# Run Classification Metrics\nprint(\"error: {}\".format(n_errors))\nprint(\"Accuracy Score :\")\nprint(accuracy_score(y,y_pred))\nprint(\"Classification Report :\")\nprint( classification_report(y, y_pred))\n\n    ","1712d0c6":"# Importing KNN module from PyOD\n!pip install Pyod","ad34caea":"from pyod.models.knn import KNN\n\n# Train kNN detector\nclf = KNN(contamination=fraction, n_neighbors=3)\nclf.fit(X)","43e6eeeb":"# Get the prediction labels of the training data\ny_train_pred = clf.labels_ \n# Outlier scores\ny_train_scores = clf.decision_scores_","c25463a2":"plt.hist(y_train_pred)","1a36b361":"from pyod.utils import evaluate_print\n\n# Evaluate on the training data\nevaluate_print('KNN', y, y_train_scores)","7ed28e7a":"(y_train_pred.shape, y.shape)","1eed6770":"from sklearn.metrics import classification_report\nprint( classification_report(y, y_train_pred))","27ad2a90":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify = y)","c6018dca":"from sklearn.neighbors import KNeighborsClassifier\nneigh = KNeighborsClassifier(n_neighbors=3)\nneigh.fit(X_train, y_train)","ea93125f":"y_pred = neigh.predict(X_test)\nfrom sklearn.metrics import classification_report\nprint( classification_report(y_test, y_pred))","f3eb77bd":"* the proximity of an anomaly data point to its nearest neighboring data points largely deviates from the proximity of the data point to most of the other data points in the data set. \n* https:\/\/pyod.readthedocs.io\/en\/latest\/\n* contamination (float in (0., 0.5), optional (default=0.1)) \u2013 The amount of contamination of the data set, i.e. the proportion of outliers in the data set. Used when fitting to define the threshold on the decision function.\n\n","403ff7d3":"# X and y","8750a2ed":"# Anomaly Detection","6e427292":"* Isolation Forest = Return the anomaly score of each sample using the IsolationForest algorithm. The IsolationForest \u2018isolates\u2019 observations by randomly selecting a feature and then randomly selecting a split value between the maximum and minimum values of the selected feature. Since recursive partitioning can be represented by a tree structure, the number of splittings required to isolate a sample is equivalent to the path length from the root node to the terminating node. This path length, averaged over a forest of such random trees, is a measure of normality and our decision function. Random partitioning produces noticeably shorter paths for anomalies. Hence, when a forest of random trees collectively produce shorter path lengths for particular samples, they are highly likely to be anomalies.\n* LOF he anomaly score of each sample is called Local Outlier Factor. It measures the local deviation of density of a given sample with respect to its neighbors. It is local in that the anomaly score depends on how isolated the object is with respect to the surrounding neighborhood. More precisely, locality is given by k-nearest neighbors, whose distance is used to estimate the local density. By comparing the local density of a sample to the local densities of its neighbors, one can identify samples that have a substantially lower density than their neighbors. These are considered outliers.","f7ffd954":"* The Credit Card Fraud Detection Problem includes modeling past credit card transactions with the knowledge of the ones that turned out to be fraud. This model is then used to identify whether a new transaction is fraudulent or not. Our aim here is to detect 100% of the fraudulent transactions while minimizing the incorrect fraud classifications.\n* use the concepts of anomalies to detect the unusual transactions that may take place after the credit card theft. ","d13cc88d":"# Missing Values","f11e0590":"# Anomaly detection\n\nOutlier detection (also known as anomaly detection) is the process of finding data objects with behaviors that are very different from expectation. Such objects are called outliers or anomalies.\n\n* Global anomalies are the most common type of anomalies and correspond to those data points which deviate largely from the rest of the data points.\n* contextual anomalies where the deviation that leads to the anomaly depends on contextual information. These contexts are governed by contextual attributes and behavioral attributes. \n* collective anomalies is that the data points included in forming the collection may not be anomalies when considered individually.","2aea3272":"# Target","9f7ce00a":"### Plots","c937fb89":"## Anomaly detection as a classification problem"}}