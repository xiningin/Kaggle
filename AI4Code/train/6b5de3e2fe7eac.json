{"cell_type":{"5dfeb6ae":"code","bb1ba69f":"code","7864b881":"code","7b0ab0b4":"code","a31fd902":"code","d8f69d5c":"code","9e35221e":"code","d55b1fa2":"code","f6595c58":"code","fdf8e2be":"code","4c139be4":"code","ed5208db":"code","c24b2e93":"code","cb37a328":"code","606aad93":"code","76b40d33":"code","986e29fe":"code","69bc8808":"code","9a3840c1":"code","3207c798":"code","3be2a20e":"code","72ee8d85":"code","f6e31226":"code","90a33cd9":"code","886e5144":"code","a16912e8":"code","6ec6d3f2":"code","decef9e8":"code","d778a826":"code","e8885b57":"code","a5eb667c":"code","2be7aea5":"code","1c708c46":"markdown","87e1705c":"markdown","93427601":"markdown","f63adcdc":"markdown","b08205f1":"markdown"},"source":{"5dfeb6ae":"!mkdir -p \/root\/.cache\/torch\/hub\/checkpoints\n!cp -r ..\/input\/landmark-additional-packages\/rwightman_gen-efficientnet-pytorch_master\/rwightman_gen-efficientnet-pytorch_master \/root\/.cache\/torch\/hub\n!cp ..\/input\/landmark-additional-packages\/tf_efficientnet_b3_aa-84b4657e.pth \/root\/.cache\/torch\/hub\/checkpoints\/\n!cp ..\/input\/landmark-additional-packages\/tf_efficientnet_b5_ra-9a3e5369.pth \/root\/.cache\/torch\/hub\/checkpoints\/\n!cp ..\/input\/landmark-additional-packages\/se_resnext50_32x4d-a260b3a4.pth \/root\/.cache\/torch\/hub\/checkpoints\/\n!cp ..\/input\/landmark-additional-packages\/resnet50d_ra2-464e36ba.pth \/root\/.cache\/torch\/hub\/checkpoints\/","bb1ba69f":"!pip install -q ..\/input\/landmark-additional-packages\/timm-0.3.4-py3-none-any.whl\n!pip install -q ..\/input\/landmark-additional-packages\/geffnet-1.0.0-py3-none-any.whl\n!pip install -q ..\/input\/landmark-additional-packages\/EfficientNet-PyTorch\/EfficientNet-PyTorch-master\n!pip install -q ..\/input\/landmark-additional-packages\/pycocotools-2.0.2\/dist\/pycocotools-2.0.2.tar\n!pip install -q ..\/input\/landmark-additional-packages\/pretrainedmodels-0.7.4\/pretrainedmodels-0.7.4","7864b881":"!pip install \"\/kaggle\/input\/hpamisc\/pytorch_zoo-master\"\n!pip install \"\/kaggle\/input\/hpamisc\/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl\"\n!pip install \"\/kaggle\/input\/hpamisc\/faiss_gpu-1.7.0-cp37-cp37m-manylinux2014_x86_64.whl\"","7b0ab0b4":"! python ..\/input\/maozi-no-arcface\/maozi_no_arcface.py","a31fd902":"import sys\nsys.path.append('..\/input\/hpa-singlecell-e050f56\/hpa_singlecell-double_level_valid_all\/')\n\nfrom torch import nn\nimport torch\nimport torch.nn.functional as F\nimport torchvision\nimport timm\nfrom torch.nn.parameter import Parameter\nimport albumentations as A\n\nfrom utils import parse_args, prepare_for_result\nfrom torch.utils.data import DataLoader, Dataset\nfrom losses import get_loss, get_class_balanced_weighted\nfrom dataloaders import get_dataloader\nfrom utils import load_matched_state\nfrom configs import Config\nfrom models import get_model\nfrom dataloaders.transform_loader import get_tfms\n\ntensor_tfms = torchvision.transforms.Compose([\n            torchvision.transforms.ToTensor(),\n            torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406, 0.406], std=[0.229, 0.224, 0.225, 0.225]),\n        ])\n\ntta_tfms = A.Compose([\n    A.Resize(always_apply=False, p=1, height=256, width=256, interpolation=1),\n    A.HorizontalFlip(always_apply=False, p=0.5),\n    A.ShiftScaleRotate(always_apply=False, p=0.7, shift_limit_x=(-0.06, 0.06), shift_limit_y=(-0.06, 0.06), scale_limit=(-0.3, 0.3), rotate_limit=(-22.5, 22.5), interpolation=1, border_mode=2, value=None, mask_value=None),\n    A.RandomBrightnessContrast(always_apply=False, p=0.5, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), brightness_by_max=True),\n])\n\n\nimport base64\nimport zlib\nfrom pycocotools import _mask as coco_mask\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\nimport tqdm\nimport seaborn as sns","d8f69d5c":"def binary_mask_to_ascii(mask, mask_val=1):\n    \"\"\"Converts a binary mask into OID challenge encoding ascii text.\"\"\"\n    mask = np.where(mask==mask_val, 1, 0).astype(np.bool)\n    \n    # check input mask --\n    if mask.dtype != np.bool:\n        raise ValueError(f\"encode_binary_mask expects a binary mask, received dtype == {mask.dtype}\")\n\n    mask = np.squeeze(mask)\n    if len(mask.shape) != 2:\n        raise ValueError(f\"encode_binary_mask expects a 2d mask, received shape == {mask.shape}\")\n\n    # convert input mask to expected COCO API input --\n    mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n    mask_to_encode = mask_to_encode.astype(np.uint8)\n    mask_to_encode = np.asfortranarray(mask_to_encode)\n\n    # RLE encode mask --\n    encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n\n    # compress and base64 encoding --\n    binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n    base64_str = base64.b64encode(binary_str)\n    return base64_str.decode()\n\ndef process(x):\n    iid, msk, img, sz = x\n    img = cv2.resize(img, (2048, 2048))\n    enc_msk = cv2.resize(msk, (sz, sz))\n    cell_mask = msk\n    subs = {}\n    results = []\n    for i in range(1, cell_mask.max() + 1):\n        enc = binary_mask_to_ascii(enc_msk, i)\n        sub = cv2.resize((cell_mask == i).astype(np.float), (2048, 2048), cv2.INTER_LINEAR)\n        xr, yr = np.where(sub == 1)\n        xmin, xmax, ymin, ymax = xr.min(), xr.max(), yr.min(), yr.max()\n        subs[i] = (img * np.repeat((sub == 1).astype(np.int)[:, :, np.newaxis], 4, 2))[xmin:xmax, ymin: ymax]\n#         imsave(f'.\/seg_png_fix_test\/{iid}_{i}.png', (255 * subs[i]).astype(np.uint8))\n        results.append(((255 * subs[i]).astype(np.uint8), enc, sz, sz))\n    return results\n\ndef squarify(M,val):\n    (a,b,c)=M.shape\n    if a>b:\n        padding=((0,0),((a-b)\/\/2,a-b-(a-b)\/\/2),(0, 0))\n    else:\n        padding=(((b-a)\/\/2,b-a-(b-a)\/\/2),(0,0),(0, 0))\n    return np.pad(M,padding,mode='constant',constant_values=val)","9e35221e":"ckpt = {\n    0: 13, 1: 12, 2: 12, 3: 11, 4: 14\n}\n\nmodels = []\nfor i in range(5):\n    cfg = Config.load_json('..\/input\/hpa-single-cell-b3-philandrare-5f\/5f_double_sin_exp5_rare.yaml\/config.json')\n    model = get_model(cfg).cuda()\n    load_matched_state(model, torch.load(\n        f'..\/input\/hpa-single-cell-b3-philandrare-5f\/5f_double_sin_exp5_rare.yaml\/f{i}_epoch-{ckpt[i]}.pth'))\n    _ = model.eval()\n    models.append(model)","d55b1fa2":"ckpt = {\n    0: 18, 1: 14, 2: 14, 3: 15, 4: 15\n}\n\n# models = []\nfor i in range(5):\n    if i in [2, 3, 4]: continue\n    cfg = Config.load_json('..\/input\/hpa-b5-final-model\/b5_final_hpa_0504\/config.json')\n    model = get_model(cfg).cuda()\n    load_matched_state(model, torch.load(\n        f'..\/input\/hpa-b5-final-model\/b5_final_hpa_0504\/checkpoints\/f{i}_epoch-{ckpt[i]}.pth'))\n    _ = model.eval()\n    models.append(model)","f6595c58":"ckpt = {\n    0: 19, 1: 19, 2: 17, 3: 17, 4: 18\n}\n\nfor i in range(5):\n    if i in [0, 3, 4]: continue\n    cfg = Config.load_json('..\/input\/hpa-resnet50d-0508\/resnet50d_final\/config.json')\n    model = get_model(cfg).cuda()\n    load_matched_state(model, torch.load(\n        f'..\/input\/hpa-resnet50d-0508\/resnet50d_final\/checkpoints\/f{i}_epoch-{ckpt[i]}.pth'))\n    _ = model.eval()\n    models.append(model)","fdf8e2be":"!cp ..\/input\/landmark-additional-packages\/resnet200d_ra2-bdba9bf9.pth \/root\/.cache\/torch\/hub\/checkpoints\/","4c139be4":"ckpt = {\n    0: 15, 1: 15, 2: 13, 3: 13\n}\n\nfor i in range(4):\n    if i in [0, 1, 4]: continue\n    cfg = Config.load_json('..\/input\/hpa-jakiro-resnet200d\/double_sin_exp5_r200d_rarex2_upload\/config.json')\n    model = get_model(cfg).cuda()\n    load_matched_state(model, torch.load(\n        f'..\/input\/hpa-jakiro-resnet200d\/double_sin_exp5_r200d_rarex2_upload\/f{i}_epoch-{ckpt[i]}.pth'))\n    _ = model.eval()\n    models.append(model)","ed5208db":"ckpt = {\n    0: 19, 1: 16, 2: 16, 3: 17, 4:19\n}\n\nfor i in range(5):\n    if i in [0, 1, 2]: continue\n    print(i)\n    cfg = Config.load_json('..\/input\/hpa-se50-final-0509\/se50_final\/config.json')\n    model = get_model(cfg).cuda()\n    load_matched_state(model, torch.load(\n        f'..\/input\/hpa-se50-final-0509\/se50_final\/checkpoints\/f{i}_epoch-{ckpt[i]}.pth'))\n    _ = model.eval()\n    models.append(model)","c24b2e93":"len(models)","cb37a328":"df = pd.read_csv('submission.csv')\n\nimgs = []\nfor i, x in df.iterrows():\n    label = x.PredictionString.split(' ')[0::3]\n    prob = x.PredictionString.split(' ')[1::3]\n    encodes = x.PredictionString.split(' ')[2::3]\n    for idx, enc in enumerate(list(set(encodes))):\n        imgs.append({\n            'image_id': x.ID,\n            'cell_id': idx+1,\n            'enc': enc,\n            'fname': f'{x.ID}_{idx+1}',\n        })\n\ntm = pd.DataFrame(imgs)","606aad93":"probs = []\nfor i, x in df.iterrows():\n    label = x.PredictionString.split(' ')[0::3]\n    prob = x.PredictionString.split(' ')[1::3]\n    encodes = x.PredictionString.split(' ')[2::3]\n    for idx, enc in enumerate(encodes):\n        probs.append({\n            'enc': enc,\n            'predict': int(label[idx]),\n            'prob': float(prob[idx])\n        })\n\nprob = pd.DataFrame(probs)\ntm_pred = prob.groupby(['enc', 'predict']).mean().unstack()['prob']\ntm_pred.columns.name = ''\nteam = tm[['enc', 'fname']].merge(tm_pred.reset_index(), on='enc', how='inner').drop('enc', 1)","76b40d33":"sample_submission = pd.read_csv('..\/input\/hpa-single-cell-image-classification\/sample_submission.csv', index_col=0)","986e29fe":"team_pred = team.set_index('fname')","69bc8808":"class SliceInferenceDataset(torch.utils.data.Dataset):\n    def __init__(self, df, tta=16, cfg=None, tfms=None):\n        self.df = df\n        self.iids = self.df.image_id.unique()\n        self.tta = tta\n        \n    def __len__(self):\n        return len(self.iids)\n\n    def __getitem__(self, idx):\n        iid = self.iids[idx]\n        mt = f'..\/input\/hpa-single-cell-image-classification\/test\/{iid}_red.png'\n        er = f'..\/input\/hpa-single-cell-image-classification\/test\/{iid}_yellow.png'\n        nu = f'..\/input\/hpa-single-cell-image-classification\/test\/{iid}_blue.png'\n        pr = f'..\/input\/hpa-single-cell-image-classification\/test\/{iid}_green.png'\n        r = cv2.imread(mt, 0).astype(np.float) \/ 255.0\n        g = cv2.imread(pr, 0).astype(np.float) \/ 255.0\n        b = cv2.imread(nu, 0).astype(np.float) \/ 255.0\n        a = cv2.imread(er, 0).astype(np.float) \/ 255.0\n        sz = r.shape[0]\n        img = np.stack([r, g, b, a], -1)\n        sli = []\n        for i, x in self.df[self.df.image_id == iid].iterrows():\n            bd = base64.b64decode(x.enc)\n            zd = zlib.decompress(bd)\n            encoded = [{'counts': zd, 'size': (sz, sz)}]\n            ded = coco_mask.decode(encoded)[:, :, 0]\n\n            xr, yr = np.where(ded == 1)\n            sub = img[xr.min(): xr.max(), yr.min(): yr.max()]\n            crop_sub_mask = ded[xr.min(): xr.max(), yr.min(): yr.max()]\n            crop_sub_mask = np.repeat(crop_sub_mask[:, :, np.newaxis], 4, axis=2)\n            r = sub * crop_sub_mask\n            sli.append((cv2.resize(squarify(r, 0), (256, 256)).astype(np.float32), x.fname))\n        BS, tta=len(sli) + 1, self.tta\n        ipts = []\n        raw_ipt = [e[0] for e in sli]\n        for tt in range(tta):\n            ipts.append(torch.stack([tensor_tfms(tta_tfms(image=x)['image']) for x in raw_ipt]).float())\n        return ipts, BS, len(sli), tta, iid, [x[1] for x in sli]","9a3840c1":"# tm","3207c798":"sid = SliceInferenceDataset(tm, tta=8)\ndl = torch.utils.data.DataLoader(sid, batch_size=1, num_workers=2)","3be2a20e":"pdfs = []\nwhole_dfs = []\nfor ipts, BS, lsli, tta, iid, fnames_raw in tqdm.tqdm(dl):\n    BS, tta, iid, fnames, lsli = BS.item(), tta.item(), iid[0], [e[0] for e in fnames_raw], lsli.item()\n    predicted_ps = []\n    exp_ps = []\n    for i in range(0, lsli, BS):\n    #   ipt = torch.stack([tensor_tfms(cv2.resize(squarify(s[0], 0), (256, 256))) for s in ress[i: BS+i]]).cuda()\n        with torch.no_grad():\n            res = []\n            exp = []\n            for tt in range(tta):\n                ipt = ipts[tt][0].cuda()\n                for model in models:\n                    with torch.cuda.amp.autocast():\n                        ifr = model(ipt, len(ipt))\n                    res.append(ifr[0].float())\n                    exp.append(ifr[1].float())\n        predict_p = [torch.sigmoid(r.cpu()) for r in res]\n        exp_p = [torch.sigmoid(r.cpu()) for r in exp]\n        predict_p = np.stack(predict_p).mean(0)\n        exp_p = np.stack(exp_p).mean(0)\n        predicted_ps.append(predict_p)\n        exp_ps.append(exp_p)\n    p = np.concatenate(predicted_ps)\n    image_df = pd.DataFrame(p, index=fnames)\n    whole_df = pd.DataFrame(np.concatenate(exp_ps).mean(0).reshape(1, 19), index=[iid])\n    whole_dfs.append(whole_df)\n    pdfs.append(image_df) ","72ee8d85":"# tm = tm.reset_index('fname')","f6e31226":"image_level = pd.concat(whole_dfs)\nimage_pred = image_level.reset_index().merge(\n    tm[['image_id', 'fname']], left_on='index', right_on='image_id', how='left'\n).set_index('fname').drop(['index', 'image_id'], 1)","90a33cd9":"pub_pred = pd.concat(pdfs)\nmerge_pred = pub_pred * image_pred.loc[pub_pred.index]","886e5144":"merge_pred","a16912e8":"ensem = merge_pred + team_pred.loc[merge_pred.index]","6ec6d3f2":"merge_pred = ensem","decef9e8":"df = df.set_index('ID')\nmerge_pred.index.name = 'fname'\nmerge_pred = merge_pred.reset_index()\ntm = tm.set_index('fname')\n\nmerge_pred['ID'] = merge_pred['fname'].str.split('_', expand=True)[0]","d778a826":"j_pred = []\nfor iid in merge_pred.ID.unique():\n    enc = ''\n    sub_df = merge_pred[merge_pred.ID == iid]\n    for idx, row in sub_df.iterrows():\n        for i in range(19):\n            enc += f'{i} {row[i]} {tm.loc[row.fname].enc} '\n    j_pred.append({\n        'ID': iid,\n        'ImageWidth': df.loc[iid].ImageWidth,\n        'ImageHeight': df.loc[iid].ImageHeight,\n        'PredictionString': enc[:-1]\n    })","e8885b57":"fast_sub = pd.DataFrame(j_pred)\nfast_sub.to_csv('pub.csv')\nfast_sub = fast_sub.set_index('ID')","a5eb667c":"fast_sub.head(2)","2be7aea5":"sub2 = pd.concat([sample_submission.drop(fast_sub.index), fast_sub], 0)\nsub2 = sub2.loc[sample_submission.index]\nsub2.to_csv('submission.csv')","1c708c46":"## Save prediction","87e1705c":"## save","93427601":"## If any ensemble","f63adcdc":"## If we read from a csv","b08205f1":"## Loading models\n* b3\n* b5\n* r50d\n* r200d\n* se50"}}