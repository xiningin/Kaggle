{"cell_type":{"36f83a50":"code","8dc94a93":"code","de556020":"code","9870ab98":"code","a5344eef":"code","39e16f9e":"code","016f0f9d":"code","a74c287d":"code","b9f53d0e":"code","e0b57f16":"code","ac865434":"code","a5b148a1":"code","5006a786":"markdown","cd63d4ec":"markdown","d5076508":"markdown","a84a6c19":"markdown","25d7e47c":"markdown","128f5084":"markdown","fdf714fe":"markdown","66eb1a51":"markdown","b3a8b5bb":"markdown","3da2faa0":"markdown"},"source":{"36f83a50":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","8dc94a93":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n","de556020":"df_train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndf_test = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","9870ab98":"sns.distplot(df_train['SalePrice'])\n","a5344eef":"# Plot fig sizing. \n# style.use('ggplot')\nsns.set_style('whitegrid')\nplt.subplots(figsize = (30,20))\n## Plotting heatmap. \n\n# Generate a mask for the upper triangle (taken from seaborn example gallery)\nmask = np.zeros_like(df_train.corr(), dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n\nsns.heatmap(df_train.corr(), cmap=sns.diverging_palette(20, 220, n=200), mask = mask, annot=True, center = 0, );\n## Give title. \nplt.title(\"Heatmap of all the Features\", fontsize = 30);","39e16f9e":"missing_value = df_train.isnull().sum(axis = 0)\npercent = (df_train.isnull().sum(axis = 0)\/df_train.isnull().count(axis = 0)) * 100\nlabels = df_train.columns \nsummary_na = pd.DataFrame({'name' : labels, 'missing_values' : missing_value, 'percent_missing' : percent})\nsummary_na.sort_values(by=['percent_missing'], ascending=False).head(20)","016f0f9d":"df_train2 = df_train.drop(columns = [summary_na['name'][x] for x in range(len(summary_na)) if summary_na['percent_missing'][x] > 15])","a74c287d":"X = df_train2.iloc[:,0:79]\ny = df_train2.iloc[:,80].values","b9f53d0e":"from sklearn.impute import SimpleImputer\n\nimp = SimpleImputer(strategy=\"most_frequent\")\nX = pd.get_dummies(X)\nX = imp.fit_transform(X)\n","e0b57f16":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler_train = scaler.fit_transform(X)\nscaler_train","ac865434":"from sklearn.linear_model import LinearRegression\n\nreg = LinearRegression().fit(scaler_train, y)\nprint(\"Accuracy :\", reg.score(scaler_train, y))\ny_pred = reg.predict(scaler_train)\n\nfrom sklearn.metrics import r2_score, mean_squared_error\nprint(\"R2 :\" ,r2_score(y, y_pred))\nprint(\"RMSE :\", mean_squared_error(y, y_pred))","a5b148a1":"result = pd.DataFrame({'y_true' : y, 'y_pred' : y_pred})\nprint(result)\nplt.subplots(figsize=(12,9))\nplt.plot(result)","5006a786":"## Traiter les donnees manquantes ","cd63d4ec":"## Cibler les variables independantes (X) et la variable dependante (y)","d5076508":"## Visualiser les donnees ","a84a6c19":"## Visualiser les resultats","25d7e47c":"## Construire le modele de regression ","128f5084":"## Remplacer les valeurs NaN en utilisant la methode Imputer","fdf714fe":"## Faire le Standard Scaler","66eb1a51":"## Importer les bibliotheques ","b3a8b5bb":"## Supprimer les colonnes contenant plus de 15% de NaN","3da2faa0":"## Importer les datasets"}}