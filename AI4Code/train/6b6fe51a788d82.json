{"cell_type":{"d247e7ac":"code","da5d3af2":"code","02f8cd0e":"code","97a74b93":"code","3c11f593":"code","51a6946e":"code","74fa24ff":"code","cf81898f":"code","ec8eb7e8":"code","7379924b":"code","b4a4ddc0":"code","d3c4e0c0":"code","d7909900":"code","e1fe4809":"markdown","cb660f4c":"markdown","63aa6d07":"markdown","65b4611e":"markdown","77ca871d":"markdown","99864870":"markdown","49b38ceb":"markdown","03140ec4":"markdown","1cc8e1ba":"markdown","f3ecd992":"markdown"},"source":{"d247e7ac":"import numpy as np\nimport pandas as pd\nfrom fbprophet import Prophet\nimport datetime as dt\n%matplotlib inline\nfrom matplotlib.pylab import plt","da5d3af2":"ercot = pd.read_csv('..\/input\/ercot-outliers\/ercot_outliers.csv')","02f8cd0e":"ercot.insert(0,'ds', pd.to_datetime(ercot['date']).dt.tz_convert(None))","97a74b93":"ercotsplit = ercot[['ds', 'region', 'ercotNew', 'Date', \n       'humidityNew', 'FeelsLikeCNew']]","3c11f593":"region = ercotsplit.region.unique()\nregion","51a6946e":"# First we create 2 empty lists to save the forecasetd and acual values for the last 168 hours\nforecasts = []\ntests = []\n\n# Now we are going to loop through each region\nfor reg in region:\n    \n    # removing the last 168 hours from the training dataset and making sure there are no NaN's\n    train = ercotsplit[ercotsplit.region == reg][:-168]\n    train['FeelsLikeCNew'] = train['FeelsLikeCNew'].fillna(0)\n    train['humidityNew'] = train['humidityNew'].fillna(0)\n    \n    # saving a list of the actual values for the last 168 hours to use for validating our model\n    tests.append( [reg + '_true'] + list(ercotsplit[ercotsplit.region == reg][-168:]['ercotNew']))\n    \n    # creating a data frame with the additional features for the last 168 hours, \n    # this will later be added to the prediction to help forecasting\n    weather = ercotsplit[ercotsplit.region == reg][-168:][['humidityNew',\n                                                            'FeelsLikeCNew'\n                                                          ]].reset_index(drop=True)\n    \n    # FbProphet requires to have the input dataset in a specific format\n    current_data = pd.DataFrame({\n       'ds' : train['ds'],\n       'y' : train['ercotNew'],\n       'humidityNew' : train['humidityNew'],\n       'FeelsLikeCNew' : train['FeelsLikeCNew']\n    })\n    \n    # we tested a lot of different combonations for the parameters, a few parameters at a time, \n    # and we chose the best performing model\n    m = Prophet(seasonality_mode='multiplicative',\n                seasonality_prior_scale=20,\n                changepoint_prior_scale=0.095,\n                daily_seasonality=False,\n                weekly_seasonality=False,\n                yearly_seasonality=False\n                ).add_seasonality(\n                     name='daily',\n                     period=1,\n                     fourier_order=15\n                ).add_seasonality(\n                     name='weekly',\n                     period=7,\n                     fourier_order=25\n                ).add_seasonality(\n                     name='yearly',\n                     period=365.25,\n                     fourier_order=25\n                )\n       \n    # adding the additional features \n    m.add_regressor('humidityNew')\n    m.add_regressor('FeelsLikeCNew')\n    \n    # fitting the model\n    m.fit(current_data)\n    \n    # FbProphet let you create a future data frame, we are creating a data frame for the next 168 hours\n    future = m.make_future_dataframe(periods = 168,freq='H',include_history = False)\n    \n    # and we are connecting the previously defined data frame that has the weather info for those 168 hours \n    future = pd.concat([future, weather], axis=1)\n    \n    # we predict the last 168 hours using m.predict\n    forecast = m.predict(future)\n    \n    # and as with saving the actual data, we are saving now the predicted values as a list. \n    \n    forecasts.append( [reg + '_validation'] + list(forecast['yhat']))\n    \n    # now up to next region....\n    print('completed ' + reg + ' region')","74fa24ff":"plt.rcParams['figure.figsize'] = [30, 20]\nfig2 = m.plot_components(forecast)\nplt.show()\nforecast","cf81898f":"forecasts = pd.DataFrame(forecasts)\nforecasts = forecasts.set_index(0).T","ec8eb7e8":"tests = pd.DataFrame(tests)\ntests = tests.set_index(0).T","7379924b":"for r in np.arange(0, 8):\n    region[r]\n    plt.subplot(4, 2, r + 1)\n    plt.plot(forecasts[region[r] + '_validation'])\n    plt.plot(tests[region[r] + '_true'])\n    plt.title(region[r])\n","b4a4ddc0":"forecasting = forecasts.rename_axis(None, axis=1).unstack().reset_index()\nforecasting.insert(0,'id', forecasting['level_0'] + '_' + forecasting['level_1'].map(str))\nforecasting.drop(['level_0','level_1'],axis=1,inplace=True)","d3c4e0c0":"testing = tests.rename_axis(None, axis=1).unstack().reset_index()\ntesting.insert(0,'id', testing['level_0'] + '_' + testing['level_1'].map(str))\ntesting.drop(['level_0','level_1'],axis=1,inplace=True)","d7909900":"mse = ((forecasting[0] - testing[0]) ** 2).mean()\nprint('The Mean Squared Error of our forecasts is {}'.format(round(mse, 2)))\nprint('The Root Mean Squared Error of our forecasts is {}'.format(round(np.sqrt(mse), 2)))\nmae = (np.abs(forecasting[0] - testing[0])).mean()\nprint('The Mean Absolute Error of our forecasts is {}'.format(round(mae, 2)))","e1fe4809":"We need to get a distinct list of regions to loop through when doing the predictions","cb660f4c":"We are plotting the components of the last region that ran (West) to see how the model breaks down the seasons ","63aa6d07":"Reading the ercot dataset after removing outliers and adding the weather info.\nThe code on cleaning the data can be seen here https:\/\/www.kaggle.com\/alyssaannef\/datacleaning","65b4611e":"last, we pivot both the test and forecasted dataframes to get it in one column each to compare and measure the accuracy of the model","77ca871d":"And we plot our forecast vs actual per region","99864870":"Now we are ready to fit and predict using FbProphet","49b38ceb":"Adding a column converting the date column to remove the timezone suffix -- daylite savings was dealt with before","03140ec4":"# FbProphet","1cc8e1ba":"Cut the dataset to only columns we need","f3ecd992":"Now we have two lists, actuals and forecasted, we are adding it to a dataframe, \nand transpose it to have each region as a column instead of a row"}}