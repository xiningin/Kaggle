{"cell_type":{"9d27f31e":"code","589657be":"code","e8b79025":"code","384dea9c":"markdown","50690db3":"markdown","908e18c3":"markdown","86d70980":"markdown","917a40a5":"markdown"},"source":{"9d27f31e":"import os\nimport logging\nimport boto3\n\nimport tensorflow as tf\nimport numpy as np\nfrom object_detection.utils import label_map_util\n\nimport cv2\n\nfrom label_studio_ml.model import LabelStudioMLBase\nfrom label_studio_ml.utils import get_image_size, get_single_tag_keys, get_image_local_path\nfrom label_studio.core.utils.io import get_data_dir\nfrom label_studio.core.settings.base import DATA_UNDEFINED_NAME\nfrom botocore.exceptions import ClientError\nfrom urllib.parse import urlparse\n\nlogger = logging.getLogger(__name__)\n\nclass ODdetection(LabelStudioMLBase):\n\n    def __init__(self, image_dir=None, score_threshold=0.3, **kwargs):\n        \"\"\"\n        :param image_dir: Directory where images are stored (leadve it default when you use direct file upload into Label Studio instead of URLs)\n        :param score_threshold: score threshold to wipe out noisy results\n        :param kwargs:\n        \"\"\"\n        super(ODdetection, self).__init__(**kwargs)\n\n        self.image_dir = image_dir\n        \n        # Load the exported model from saved_model directory\n        PATH_TO_SAVED_MODEL ='FULL_PATH_TO\\saved_model'\n        \n        # Lead saved model and build detection fuction\n        self.detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n        print('Model loading done....')\n        \n        # Load label map data\n        PATH_TO_LABELS='FULL_PATH_TO\\*.pbtxt'\n        self.category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n\n        self.from_name, self.to_name, self.value, self.labels_in_config = get_single_tag_keys(\n            self.parsed_label_config, 'RectangleLabels', 'Image')\n        \n        # Create a list of labels from the label_config. We use category_index instead.\n        #schema = list(self.parsed_label_config.values())[0]\n        #self.labels_in_config = set(self.labels_in_config) \n        \n        self.score_thresh = score_threshold\n\n    def _get_image_url(self, task): # 'data' stores the fullpath of the img\n        image_url = task['data'].get(self.value) or task['data'].get(DATA_UNDEFINED_NAME)\n        if image_url.startswith('s3:\/\/'):\n            # presign s3 url\n            r = urlparse(image_url, allow_fragments=False)\n            bucket_name = r.netloc\n            key = r.path.lstrip('\/')\n            client = boto3.client('s3')\n            try:\n                image_url = client.generate_presigned_url(\n                    ClientMethod='get_object',\n                    Params={'Bucket': bucket_name, 'Key': key}\n                )\n            except ClientError as exc:\n                logger.warning(f'Can\\'t generate presigned URL for {image_url}. Reason: {exc}')\n        return image_url\n            \n    def load_image_into_numpy_array(self, path):\n        return np.array(cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB))\n\n    def predict(self, tasks, **kwargs):\n        assert len(tasks) == 1\n        task = tasks[0]   #looks like task (img) is dealt one by one\n        image_url = self._get_image_url(task)\n        print('image_url:', image_url)\n        image_path = self.get_local_path(image_url, project_dir=self.image_dir)\n        print('image_path:', image_path)\n        \n        image_np = self.load_image_into_numpy_array(image_path)\n        input_tensor = tf.convert_to_tensor(image_np)\n        input_tensor = input_tensor[tf.newaxis, ...]\n        detections = self.detect_fn(input_tensor)\n        \n        # All outputs are batches tensors.\n        # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n        # Only interested in the first num_detections.\n                \n        boxes = detections['detection_boxes'][0].numpy()    # Getting the list of box coordinates\n        max_boxes_to_draw = boxes.shape[0]                  # Getting the number of the list\n        scores = detections['detection_scores'][0].numpy()  # Getting scores for threshold evaluation\n        \n        results = []\n       \tall_scores = []\n                \n        img_width, img_height = get_image_size(image_path)  # This is not used either\n        \n        for i in range(boxes.shape[0]):\n                if scores is None or scores[i] >self.score_thresh:\n                    class_name = self.category_index[detections['detection_classes'][0,i].numpy().astype(int)]['name']\n                    results.append({\n                        \"from_name\": self.from_name,\n                        \"to_name\": self.to_name,\n                        \"type\": \"rectanglelabels\",\n                        \"value\": {\n                            \"rectanglelabels\": [class_name],\n                            \"x\": boxes[i,1]*100,\n                            \"y\": boxes[i,0]*100,\n                            \"width\": (boxes[0,3]-boxes[0,1])*100,\n                            \"height\": (boxes[0,2]-boxes[0,0])*100                          \n                            }                        \n                        })\n                    all_scores.append(scores[i])       \n        avg_score = sum(all_scores) \/ max(len(all_scores), 1)\n        print(\"results\", results)\n        print(\"each score:\", all_scores)\n        return [{\n\t\t\t\"result\": results,\n\t\t\t\"score\" : avg_score\n\t\t\t}]\n\n","589657be":"# This needs to be run only once. '--force' is needed when od_backend already exists.\n# At label-studio-ml-backend directory\nlabel-studio-ml init od_backend --script PATH_TO\/ODdetection.py --force","e8b79025":"# Start Label Studio\n# At label-studio-ml-backend directory\nlabel-studio-ml start .\\od_backend","384dea9c":"## 3.2 Initate the backend\n\n* **Save the above code as, for instance, 'ODdetect.py'.**\n* **Install the TF2 OD API in the same virtual environement as Label Studio Machine Learning Backend**\n* **Initialise the beckend with the following code. When initialised, a directory is created as specified (od_bakend) and ODdetect.py is copied to that directiory.**\n","50690db3":"**After connecting the backened to the running Lable Studio through the UI, I can see the connection status with green circle. It may take some time until the conncectin is established. Load the dataset to the Label Studio and I see pre-annotations.**","908e18c3":"## 3.3 Start the backend","86d70980":"## 3.1 Create an inference script\n\n**The code below is an example. It is based on the codes here and [here](https:\/\/github.com\/tensorflow\/models\/blob\/master\/research\/object_detection\/colab_tutorials\/inference_tf2_colab.ipynb) and [here](https:\/\/github.com\/heartexlabs\/label-studio-ml-backend\/tree\/master\/label_studio_ml\/examples\/mmdetection). The paths to the exported model directory (....\/saved_model) and the label map data (*.pbtxt) needs to be specified.** ","917a40a5":"# Semi-auto annotation of custom dataset using Label Studio and Tensorflow2 Obejct Detection API\n\n**Goal:**\n\n**Half automatize the annotation work using Label Studio's machine learing backend. I create a custom object detection model for the backend by using Tensorflow2 Obejct Detection API.**  \n\n**Steps:**\n1. Manually annotate data using Label Studio or other annotation tools. For example, 300 to 500 pictures.\n2. Train a model using the dataset based on one of the pre-trained models provided in [the TF2 detection model zoo](https:\/\/github.com\/tensorflow\/models\/blob\/master\/research\/object_detection\/g3doc\/tf2_detection_zoo.md).\n3. Use the trained model for a machine learning backend for Label Studio. The backend preannotates the new dataset and I only modify the predictions if necessary.**\n\n**In this notebook, I only focus on the step3. There are many notebooks about how to train custom dataset using TF2 object detection API. I trained a model in Colab environment.**\n\n"}}