{"cell_type":{"1a3644cb":"code","47d513bd":"code","336a4dde":"code","ec256039":"code","f380a727":"code","cc3bded8":"code","701b7f28":"code","e09754a2":"code","3165d844":"code","b9759847":"code","59137810":"code","b1a585be":"code","ef119389":"markdown","9aa86c73":"markdown","0bce87af":"markdown","57da67da":"markdown"},"source":{"1a3644cb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pystan as ps\n\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n# Any results you write to the current directory are saved as output.","47d513bd":"train = pd.read_csv('\/kaggle\/input\/dont-overfit-ii\/train.csv')\ntrain.head()","336a4dde":"train.isnull().any().sum()\n#no Null values in dataframe","ec256039":"sum(train.dtypes=='object')\n#all data are numerical","f380a727":"train['target'].unique()","cc3bded8":"train.info()","701b7f28":"X=train.drop(columns=['id','target'],axis=1)\ny=train['target']","e09754a2":"X_train,X_valid,y_train,y_valid=train_test_split(X,y,random_state=42)","3165d844":"model_linreg = LinearRegression()\n\n# linear regression model fit\nmodel_linreg.fit(X_train, y_train)\n\n# linear regression model prediction\nmodel_linreg_ypredict = model_linreg.predict(X_valid)\n\n# linear regression model metrics\nmodel_linreg_rocaucscore = roc_auc_score(y_valid, model_linreg_ypredict)\nmodel_linreg_cvscores = cross_val_score(model_linreg, X, y, cv=20, scoring='roc_auc')\nprint('linear regression\\n  roc auc score: %0.4f, cross validation score: %0.4f (+\/- %0.4f)' \n      %(model_linreg_rocaucscore, model_linreg_cvscores.mean(), 2 * model_linreg_cvscores.std()))","b9759847":"train.pop('id')                                                                                      \ntarget = train.pop('target').astype(int)                                                             \n                                                                                                     \ntest = pd.read_csv('\/kaggle\/input\/dont-overfit-ii\/test.csv')                                                              \nids = test.pop('id')  ","59137810":"code = \"\"\"                                                                                           \ndata {                                                                                               \n  int N; \/\/the number of training observations                                                       \n  int N2; \/\/the number of test observations                                                          \n  int K; \/\/the number of features                                                                    \n  int y[N]; \/\/the response                                                                           \n  matrix[N,K] X; \/\/the model matrix                                                                  \n  matrix[N2,K] new_X; \/\/the matrix for the predicted values                                          \n}                                                                                                    \nparameters {                                                                                         \n  real alpha;                                                                                        \n  vector[K] beta; \/\/the regression parameters                                                        \n}                                                                                                    \ntransformed parameters {                                                                             \n  vector[N] linpred;                                                                                 \n  linpred = alpha+X*beta;                                                                            \n}                                                                                                    \nmodel {                                                                                              \n  alpha ~ cauchy(0,10); \/\/prior for the intercept following Gelman 2008                              \n                                                                                                     \n  for(i in 1:K)                                                                                      \n    beta[i] ~ student_t(1, 0, 0.03);                                                                 \n                                                                                                     \n  y ~ bernoulli_logit(linpred);                                                                      \n}                                                                                                    \ngenerated quantities {                                                                               \n  vector[N2] y_pred;                                                                                 \n  y_pred = alpha+new_X*beta; \/\/the y values predicted by the model                                   \n}                                                                                                    \n\"\"\"               ","b1a585be":"data = {                                                                                             \n    'N': 250,                                                                                        \n    'N2': 19750,                                                                                     \n    'K': 300,                                                                                        \n    'y': target,                                                                                     \n    'X': train,                                                                                      \n    'new_X': test,                                                                                   \n}                                                                                                    \n                                                                                                     \nsm = ps.StanModel(model_code=code)                                                               \nfit = sm.sampling(data=data, seed=1234)                                                              \nex = fit.extract(permuted=True)                                                                      \ntarget = np.mean(ex['y_pred'], axis=0)                                                               \ndf = pd.DataFrame({'id': ids, 'target': target})                                                     \ndf[['id', 'target']].to_csv('submission.csv', index=False) ","ef119389":"## After Seeing some kernels use Pystan model so we 'll try it.","9aa86c73":"### Linear regression gives 0.627 on LB , so it seems Overfitting","0bce87af":"# Splitting Data","57da67da":"# Trying Linear Regression Model\n"}}