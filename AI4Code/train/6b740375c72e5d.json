{"cell_type":{"1d25e4bd":"code","72d3f601":"code","d533925e":"code","209ae25c":"code","5907b63e":"code","e121c517":"code","7a58a8d5":"code","89c9e530":"code","cc1a6a6d":"code","bef02bdf":"code","b133e5e1":"code","dda5c36b":"code","52df20f3":"code","e762e4de":"code","46df4d0a":"code","5ede6ce2":"code","c527b02e":"code","e3b96d82":"code","67fdb5a5":"markdown","edd830b2":"markdown","76273395":"markdown","1b7737c9":"markdown","2bcd8096":"markdown","22c955b1":"markdown","ed6cbe9d":"markdown","6cd5d7ad":"markdown","aadc09be":"markdown","b0cc070b":"markdown","a536052c":"markdown","06fe6c5d":"markdown","2b8effad":"markdown"},"source":{"1d25e4bd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","72d3f601":"df = pd.read_csv('..\/input\/song-popularity-dataset\/song_data.csv')\n\ndf.head(5)","d533925e":"df.describe()","209ae25c":"df.info()","5907b63e":"x = df['danceability'].values\ny = df['song_popularity'].values\nprint(f'Song Tempos: {x}')\nprint(f'Song Popularity: {y}')","e121c517":"x = x.reshape(-1, 1)\ny = y.reshape(-1, 1)\nx_train, x_test, y_train, y_test = train_test_split(x, y, train_size=.5, test_size=.5, random_state=100)","7a58a8d5":"print(f'x Train Data shape{x_train.shape}')\nprint(f'y Train Data shape{y_train.shape}')\nprint(f'x Test Data shape{x_test.shape}')\nprint(f'y Test Data shape{y_test.shape}')","89c9e530":"plt.rcParams['figure.figsize'] = [20, 12]\nplt.scatter(x_train, y_train, color='red')\nplt.xlabel('Danceable Songs')\nplt.ylabel('Song Popularity Rate')\nplt.title('Training Data')\nplt.show()","cc1a6a6d":"lm = LinearRegression()\nlm.fit(x_train, y_train)\ny_predict = lm.predict(x_test)\nprint(f'Train Accuracy {round(lm.score(x_train, y_train)* 100,2)}%')\nprint(f'Test Accuracy {round(lm.score(x_test, y_test)* 100,2)}%')","bef02bdf":"plt.scatter(x_train, y_train, color='red')\nplt.plot(x_test, y_predict)\nplt.xlabel('Danceable Songs')\nplt.ylabel('Song Popularity Rate')\nplt.title('Training Data')\nplt.show()","b133e5e1":"df = pd.read_csv('..\/input\/videogamesales\/vgsales.csv')\n\ndf.head(5)","dda5c36b":"x = df['Rank'].values\ny = df['Global_Sales'].values\n\nx = x.reshape(-1, 1)\ny = y.reshape(-1, 1)\nx_train, x_test, y_train, y_test = train_test_split(x, y, train_size=.1, test_size=.1, random_state=100)","52df20f3":"plt.rcParams['figure.figsize'] = [20, 12]\nplt.scatter(x_train, y_train, color='red')\nplt.xlabel('Game Ranking')\nplt.ylabel('Global Sales')\nplt.title('Training Data')\nplt.show()","e762e4de":"lm = LinearRegression()\nlm.fit(x_train, y_train)\ny_predict = lm.predict(x_test)\nprint(f'Train Accuracy {round(lm.score(x_train, y_train)* 100,2)}%')\nprint(f'Test Accuracy {round(lm.score(x_test, y_test)* 100,2)}%')\n\nplt.scatter(x_train, y_train, color='red')\nplt.plot(x_test, y_predict)\nplt.xlabel('Game Ranking')\nplt.ylabel('Global Sales')\nplt.title('Training Data')\nplt.show()","46df4d0a":"df = pd.read_csv('..\/input\/car-mpg\/mpg_raw.csv')\n\ndf.head(5)","5ede6ce2":"x = df['weight'].values\ny = df['mpg'].values\nx = x.reshape(-1, 1)\ny = y.reshape(-1, 1)\nx_train, x_test, y_train, y_test = train_test_split(x, y, train_size=.1, test_size=.1, random_state=100)","c527b02e":"# plt.rcParams['figure.figsize'] = [20, 12]\nplt.scatter(x_train, y_train, color='red')\nplt.xlabel('WEIGHT OF CAR')\nplt.ylabel('MPG')\nplt.title('Training Data')\nplt.show()","e3b96d82":"lm = LinearRegression()\nlm.fit(x_train, y_train)\ny_predict = lm.predict(x_test)\nprint(f'Train Accuracy {round(lm.score(x_train, y_train)* 100,2)}%')\nprint(f'Test Accuracy {round(lm.score(x_test, y_test)* 100,2)}%')\n\n\nplt.scatter(x_train, y_train, color='red')\nplt.plot(x_test, y_predict)\nplt.xlabel('Game Ranking')\nplt.ylabel('Global Sales')\nplt.title('Training Data')\nplt.show()","67fdb5a5":"## Conclusion 2\/3:\n- The best ranked games make the most revenue due to it's popularity and how much fun consumers have with them. Consumers are more enticed to purchase the best games out there because they assume it's worth the money.\n- **Hypothesis:** If games are top rated, then consumers are more enticed to purchase more affordable games, because it's easier on the wallet and the game has good credibilty. \n***\n***\n***","edd830b2":"## Load the data you receive into a Pandas DataFrame.\nAnd\n## Show the first five rows of the data set.","76273395":"## Reshape our data for easier interpretation","1b7737c9":"# Data frame 2 Below","2bcd8096":"## Conclusion 3\/3:\n- The heavier the car, bigger the negative effect on Miles Per Gallon. The more resistance, the harder the care has to work. Thus increases the amount of gas needed to drive.\n- **Hypothesis:** If the vehicle is heavy, then the vehicle's fuel economy will decrease, because it requires more power to move itself. ","22c955b1":"## Show the description and the info of the data set.","ed6cbe9d":"## Conclusion 1\/3:\n- Songs that are more compatible with dancing are **slightly** rated higher than songs aren't danceable.\n- **Hypothesis:** If songs are danceable, then humans will likely rate the songs higher than others, because of the psycological effects it has on our mood. \n***\n***\n***","6cd5d7ad":"# Data frame 3 Below","aadc09be":"# README - Linear Regression\n\n## **Author**: Ediberto Ponce\n\n## Overview\n\n- Select a Kaggle data set that is suitable for Linear Regression.\n  * Note make sure the data set is stored as csv file\/s.\n  * Data set must be continous values appropriate for a Linear Regression. If you\u2019re not sure then ask Instructor or TA.\n- Load the data you receive into a Pandas DataFrame.\n- Show the first five rows of the data set.\n- Show the description and the info of the data set.\n- Ensure that any date columns have been cast into a datetime object in your DataFrame.\n- Using a regression model, split your data into train and test portions.\n- Fit your training split to the regression model.\n- Show your regression model\u2019s score.\n- Draw at least three conclusions from your regression model.\n- Your notebook should be clutter free and polished.\n\n\n## Architecture\n\n- Python 3\n- numpy\n- matplotlib\n- from sklearn.linear_model import LinearRegression\n- from sklearn.model_selection import train_test_split\n\n\n## Credit and Collaborations\n- Roger\n  * Referenced his demo code for today's lab\n\n## Resources\n\n- [car-mpg](https:\/\/www.kaggle.com\/gauravsharma99\/car-mpg)\n- [song-popularity-dataset](https:\/\/www.kaggle.com\/yasserh\/song-popularity-dataset)\n- [videogamesales](https:\/\/www.kaggle.com\/gregorut\/videogamesales)\n\n## Name of feature: Linear Regression\n\n- Estimate of time needed to complete: 5 hours\n\n- Start time: 1:15pm\n\n- Finish time: 5:15pm\n\n- Actual time needed to complete: 4 hours\n\n","b0cc070b":"## Build Graph!","a536052c":"# Same steps repeated below with differnt data frames","06fe6c5d":"## Grab x and y values","2b8effad":"## Build Graph with Linear Regression Line"}}