{"cell_type":{"9ab3f2d8":"code","a69ef315":"code","678fc456":"code","29d44107":"code","5cde8ae1":"code","22169c21":"code","8829b88c":"code","373ac347":"code","3d07ab8a":"code","75ff2d72":"code","0cbb3158":"code","7fc45147":"code","ff2fcb78":"code","0d616dae":"code","945ddf53":"code","e8d522fd":"code","fee0236b":"code","36e895e7":"code","0ef7f04f":"code","628f2601":"code","07a98791":"code","73bf31fc":"code","651a91a3":"code","9044ee0e":"code","8ec354f7":"code","39f94ea6":"code","d72ae34e":"code","28382242":"code","7810ab62":"code","9c2c3b10":"code","b292dd6f":"code","e4d2d51d":"code","893bff0c":"code","9e32625c":"code","57a3788c":"markdown"},"source":{"9ab3f2d8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a69ef315":"train_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntrain_data['Age'] = train_data['Age'].fillna(train_data['Age'].mean())\ntrain_data.head()","678fc456":"test_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest_data['Age'].fillna(test_data[\"Age\"].median(),inplace = True)\ntest_data","29d44107":"women = train_data.loc[train_data.Sex == 'female']['Survived']\nprint(sum(women)\/len(women))\ntrain_data.drop(labels = [\"Name\",\"Ticket\",\"Cabin\"],axis=1,inplace = True)\ntest_data.drop(labels = [\"Name\",\"Ticket\",\"Cabin\"],axis=1,inplace = True)","5cde8ae1":"men = train_data.loc[train_data.Sex == 'male']['Survived']\nprint(sum(men)\/len(men))\n\n","22169c21":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.rcParams['figure.figsize'] = (15,8)\nsns.countplot(train_data[\"Survived\"],palette = 'dark')\nplt.xlabel(\"Survived or not\")\nplt.show()","8829b88c":"sns.boxplot(x = train_data[\"Survived\"],y = train_data[\"Fare\"],hue = train_data[\"Survived\"],palette = 'dark')","373ac347":"sns.boxplot(x = train_data[\"Survived\"],y = train_data[\"Age\"],hue = train_data[\"Survived\"],palette = 'dark')","3d07ab8a":"train_data","75ff2d72":"d1 = {'male':0 ,'female':1}\ntrain_data[\"Sex\"] = train_data[\"Sex\"].map(d1)\ntest_data[\"Sex\"] = test_data[\"Sex\"].map(d1)\nmap2 = {\"S\":0 , \"C\":1 , \"Q\":2}\ntrain_data[\"Embarked\"] = train_data[\"Embarked\"].map(map2)\nsns.heatmap(train_data[:].corr(),cmap = \"RdYlGn\",annot = True)","0cbb3158":"sns.scatterplot(train_data[\"Fare\"],train_data[\"Age\"],color='Green')","7fc45147":"sns.catplot(x=\"Survived\", y=\"Age\", hue=\"Sex\", kind=\"swarm\", data=train_data, aspect=1,height=8);","ff2fcb78":"sns.factorplot(x=\"Sex\",col=\"Survived\", data=train_data , kind=\"count\",size=7, aspect=.7,palette=['red','green'])","0d616dae":"sns.catplot(x=\"Survived\",hue=\"Pclass\", kind=\"count\",col='Sex', data =train_data,color='Violet',aspect=0.7,height=7);","945ddf53":"sns.catplot(x=\"Survived\", hue=\"SibSp\", col = 'Sex',kind=\"count\", data=train_data,height=7);\nsns.catplot(x=\"Survived\", hue=\"Parch\", col = 'Sex', kind=\"count\", data=train_data,height=7);","e8d522fd":"emb =train_data.groupby('Embarked').size()\n\nplt.pie(emb.values,labels = [\"Cherbourg\",\"Queenstown\",\"Southampton\"],startangle=90,autopct='%1.1f%%',shadow = True);","fee0236b":"sns.catplot(x=\"Embarked\",hue=\"Survived\", kind=\"count\",col='Sex', data=train_data,aspect=0.7,height=7);","36e895e7":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import mean_squared_error as mse\n\ny = train_data['Survived']\nfeat = ['Pclass','Sex','SibSp','Parch']\nX  =pd.get_dummies(train_data[feat])\nX_test = pd.get_dummies(test_data[feat])\n# models=[KNeighborsClassifier(n_neighbors=5)]\n\n# predictions = model.predict(X_test)\n# output = pd.DataFrame({'PassengerId':test_data.PassengerId,'Survived':predictions})\n# output.to_csv('my_submissions.csv',index = False)\n# print(\"Ho gaya\")\n# print(train_data.describe())\nprint(X.shape)\nprint(y.shape)\nXtrain,Xtest,ytrain,ytest = train_test_split(X,y,random_state=30,stratify = y)\nXtrain.shape\nytrain.shape","0ef7f04f":"def elbow(k):\n    test_error = []\n   \n    for i in k:\n        model = KNeighborsClassifier(n_neighbors = i)\n        model.fit(Xtrain,ytrain)\n        tmp = model.predict(Xtest)\n        tmp = f1_score(tmp,ytest)\n        error = 1-tmp\n        test_error.append(error)\n    return test_error    ","628f2601":"k = range(6,20,2)\ntest_e = elbow(k)\nplt.plot(k,test_e)\nplt.xlabel(\"K value\")\nplt.ylabel(\"Test Error\")\nplt.show()","07a98791":"def elbowm(k):\n    test_error = []\n   \n    for i in k:\n        model = KNeighborsClassifier(n_neighbors = i)\n        model.fit(Xtrain,ytrain)\n        tmp = model.predict(Xtest)\n        tmp = mse(tmp,ytest)\n        error = tmp\n        test_error.append(error)\n    return test_error","73bf31fc":"k = range(6,20,2)\ntest_e = elbowm(k)\nplt.plot(k,test_e)\nplt.xlabel(\"K value\")\nplt.ylabel(\"Test Error\")\nplt.show()","651a91a3":"from sklearn.model_selection import cross_val_score\nmodel = KNeighborsClassifier(n_neighbors=16)\nmodel.fit(Xtrain,ytrain)\npreds = model.predict(Xtest)\nprint(f1_score(preds,ytest))\n#     print(model)\n#     print('Accuracy of classifier on training set:{}%'.format(round(f1_score(X_train, y_train)*100)))\n#     print(\"Training data:\"+round(clf.cross_val_score(X_train,y_train)*100))","9044ee0e":"predictions =  model.predict(X_test)\npredictions\n","8ec354f7":"sample = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\nsample\nsub = pd.DataFrame({'PassengerId':sample.PassengerId,\n                   'Survived':predictions})\nsub\nsub.to_csv('Submiss.csv',index=False,header=True)","39f94ea6":"from xgboost import XGBClassifier\nimport time\n\nxgb = XGBClassifier(n_estimators=100)\ntraining_start = time.perf_counter()\nxgb.fit(Xtrain, ytrain)\ntraining_end = time.perf_counter()\nprediction_start = time.perf_counter()\npreds = xgb.predict(Xtest)\nprediction_end = time.perf_counter()\nacc_xgb = (preds == ytest).sum().astype(float) \/ len(preds)*100\nxgb_train_time = training_end-training_start\nxgb_prediction_time = prediction_end-prediction_start\nprint(\"XGBoost's prediction accuracy is: %3.2f\" % (acc_xgb))\nprint(\"Time consumed for training: %4.3f\" % (xgb_train_time))\nprint(\"Time consumed for prediction: %6.5f seconds\" % (xgb_prediction_time))","d72ae34e":"params = {\n        'min_child_weight': [1, 5, 10],\n        'gamma': [0.5, 1, 1.5, 2, 5],\n        'subsample': [0.6, 0.8, 1.0],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5]\n        }","28382242":"xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n                    silent=True, nthread=1)","7810ab62":"from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom datetime import datetime\n\nfolds = 5\nparam_comb = 5\n\nskf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n\nrandom_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=4, cv=skf.split(Xtrain,ytrain), verbose=3, random_state=1001 )\n\n# Here we go\n# start_time = timer(None) # timing starts from this point for \"start_time\" variable\nrandom_search.fit(Xtrain, ytrain)\n# timer(start_time)","9c2c3b10":"random_search.best_params_","b292dd6f":"predss = random_search.predict(X_test)","e4d2d51d":"random_search.best_score_","893bff0c":"sample = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\nsample\nsub = pd.DataFrame({'PassengerId':sample.PassengerId,\n                   'Survived':predss})\nsub\nsub.to_csv('Submiss1.csv',index=False,header=True)","9e32625c":"_","57a3788c":"XGB Classifier"}}