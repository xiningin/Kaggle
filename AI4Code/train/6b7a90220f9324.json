{"cell_type":{"ed1f4083":"code","c9be7f0c":"code","b376eec6":"code","04136a7d":"code","2e6f6e91":"code","ed5e080b":"code","9361b5ff":"code","e169c54e":"code","fa6ab525":"code","762919b1":"code","8927e598":"code","a7cccc56":"code","088c0f38":"code","c8b59e98":"code","72276051":"code","e4b5fe98":"code","9644616c":"code","e4404942":"code","4a1721cb":"code","460668bb":"markdown"},"source":{"ed1f4083":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib\nimport matplotlib.pyplot as plt","c9be7f0c":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as esw","b376eec6":"dir = \"\/kaggle\/input\/jmlr1\"\nos.chdir(dir)\nJMLR_docu = []\n\nfor file in os.listdir(dir):\n    with open(file, \"r\", encoding=\"utf-8\") as input:\n        for string in input:\n            JMLR_docu.append(string)","04136a7d":"len(JMLR_docu) # list of 20 abstracts from Journal of Machine Learning Research","2e6f6e91":"JMLR_docu[1] # just to check whether I correctly read the data","ed5e080b":"dir = \"\/kaggle\/input\/journalfe\"\nos.chdir(dir)\nJFE_docu = []\n\nfor file in os.listdir(dir):\n    with open(file, \"r\", encoding=\"cp949\") as input:\n        for string in input:\n            JFE_docu.append(string)","9361b5ff":"len(JFE_docu) # list of 20 abstracts from Journal of Financial Economics","e169c54e":"JFE_docu[1] # just to check whether I correctly read the data","fa6ab525":"dir = \"\/kaggle\/input\/journal_ijbs\" \nos.chdir(dir)\nIJBS_docu = []\n\nfor file in os.listdir(dir):\n    with open(file, \"r\", encoding=\"cp949\") as input:\n        for string in input:\n            IJBS_docu.append(string)","762919b1":"len(IJBS_docu) # list of 20 abstracts from International Journal of Biological Sciences","8927e598":"IJBS_docu[1] # just to check whether I correctly read the data","a7cccc56":"corpus = JMLR_docu + JFE_docu + IJBS_docu\nlabel = 20 * [\"ML\"] + 20 * [\"EC\"] + 20 * [\"BO\"]\n# ML label represents Machine Learning, EC label represents Economics, \n# and BO label represents Biological Sciences. ","088c0f38":"# split the dataset into training and test set\ncorpus_train, corpus_test, label_train, label_test = train_test_split(corpus, label, test_size=0.2)","c8b59e98":"# building term matrices\nvectorizer = CountVectorizer(tokenizer=str.split, stop_words=esw)\ncorpus_train_mat = vectorizer.fit_transform(corpus_train)\ncorpus_train_mat = corpus_train_mat.toarray()\n\ncorpus_test_mat = vectorizer.transform(corpus_test)\ncorpus_test_mat = corpus_test_mat.toarray()","72276051":"# building Naive Bayes Classifier\ndef fit_NBclassifier(trainset, trainlabel):\n    nbclassifier = MultinomialNB()\n    nbclassifier.fit(trainset, trainlabel)\n    \n    return nbclassifier","e4b5fe98":"NB_clf = fit_NBclassifier(corpus_train_mat, label_train) # train the classifier","9644616c":" # predict a label of the documents in the test set using the trained classifier\nlabel_predicted = NB_clf.predict(corpus_test_mat)","e4404942":"accuracy = accuracy_score(label_test, label_predicted) # accuracy rate of the classifier\naccuracy ","4a1721cb":"# visualize a heat map of confusion matrix to evaluate the quality of the output of the classifier \nconf_mat = confusion_matrix(label_test, label_predicted)\nlabels = sorted(set(label_predicted))\n\nplt.figure()\nplt.title(\"Heat Map Confusion Matrix\")\nplt.imshow(conf_mat, interpolation=\"nearest\", cmap=plt.cm.Reds)\nplt.xticks(np.arange(len(labels)), labels)\nplt.yticks(np.arange(len(labels)), labels)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.colorbar()\nplt.show()","460668bb":"Here I conducted a simple document classification using Naive Bayes Classifier. \n\n**Data**: To make a sample corpus, I randomly selected 20 research papers from Journal of Machine Learning Research, Journal of Financial Economics, and International Journal of Biological Sciences respectively and extracted only abstracts of the papers. Thus, the corpus I used here simply consists of 60 abstracts of research papers from three different journals. 80% of the corpus was used as a training set and 20% of it was used as a test set.\n\n**Method**: First, I built a term matrix of each document(abstract) using CountVectorizer. Next, I trained the Naive Bayes Classifier and use the classifier to classify the documents in the test set."}}