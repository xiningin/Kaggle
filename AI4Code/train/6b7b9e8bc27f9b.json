{"cell_type":{"f8c63ee4":"code","dfd8fd0f":"code","0490d5bc":"code","ec4f7c8d":"code","22e895b9":"code","eb8a570e":"code","ddfb3a05":"code","b9cdbb41":"code","7f841529":"code","1261d761":"markdown","5f5693a3":"markdown","2095f2f1":"markdown","6de22806":"markdown","9ca63fba":"markdown","b790578d":"markdown","dca76c7e":"markdown","43b013b7":"markdown","8dec6ae4":"markdown","eb2b94ed":"markdown"},"source":{"f8c63ee4":"import pandas as pd\nimport numpy as np\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision.transforms import ToTensor, Lambda, Compose\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport pylab as pl\nfrom IPython import display\n%matplotlib inline","dfd8fd0f":"from sklearn.model_selection import train_test_split\nimport torch.nn.functional as F\n\nclass CustomImageDataset(Dataset):\n    def __init__(self, df, data_type = 'train', model_type='ffnn'):\n        \"\"\"\n        :param df: data frame\n        :param rating_2014_file: 'train'\/'test'\n        :param model_type: 'ffnn'\/'cnn'\n        \"\"\"\n        if data_type == 'train':\n            self.X = df.drop('label', axis=1).values\/255.\n            self.Y = df['label'].values\n        else:\n            self.X = df.values\/255.\n            self.Y = None\n        self.X = torch.from_numpy(self.X.astype(np.float32)).reshape(len(df),28, 28)\n        self.data_type = data_type\n        self.model_type = model_type\n\n    def __len__(self):\n        return len(self.Y)\n\n    def __getitem__(self, idx):\n        image = self.X[idx]\n        if self.data_type == 'train':\n            label = self.Y[idx]\n        else:\n            label = None\n        \n        if self.model_type == 'ffnn':\n            return image, label\n        else:\n            # add additional dimension if we need dataset for cnn\n            return image.unsqueeze(0), label","0490d5bc":"BATCH_SIZE = 64\nEPOCHS = 30\n\n# load data\ndf = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ndf_train, df_val = train_test_split(df, test_size=0.2)\n\n# create Dataset\ntraining_data = CustomImageDataset(df_train)\nval_data = CustomImageDataset(df_val)\n\n# create Dataloader\ntrain_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True)\nval_dataloader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True)\n\n# Display image and label.\ntrain_features, train_labels = next(iter(train_dataloader))\nprint(f\"Feature batch shape: {train_features.size()}\")\nprint(f\"Labels batch shape: {train_labels.size()}\")\nimg = train_features[1].squeeze()\nlabel = train_labels[1]\nplt.imshow(img, cmap=\"gray\")\nplt.show()\nprint(f\"Label: {label}\")","ec4f7c8d":"\n# Define model, fully connected feed forward nn\nclass NeuralNetwork(nn.Module):\n    def __init__(self):\n        super(NeuralNetwork, self).__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(28*28, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10)\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits\n\n# convolutional nn\nclass CNN(nn.Module):\n\n    def __init__(self):\n        super(CNN, self).__init__()\n        # input torch.Size([64, 1, 28, 28])\n        # torch.Size([batch_size, channels, img_width, img_height])\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=4)\n        # torch.Size([64, 16, 28-kernel_size+1, 28-kernel_size+1])\n        # torch.Size([64, 16, 25, 25])\n        self.relu1=nn.ReLU()\n        \n        self.conv2 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=2)\n        \n        # torch.Size([64, 8, 24, 24])\n        self.relu2=nn.ReLU()\n        self.max_pool2=nn.MaxPool2d(kernel_size=2)\n        \n        # torch.Size([64, 8, 12, 12])\n        self.fc1 = nn.Linear(8*12*12, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        \n        out=self.conv1(x)\n        out=self.relu1(out)\n        \n        out=self.conv2(out)\n        out=self.relu2(out)\n        out=self.max_pool2(out)\n        \n        out = torch.flatten(out, 1)\n        out=self.fc1(out)\n        out=self.fc2(out)\n        return out","22e895b9":"class EarlyStopping():\n    \"\"\"\n    Early stopping to stop the training when the loss does not improve after\n    certain epochs.\n    \"\"\"\n    def __init__(self, patience=5, min_delta=0):\n        \"\"\"\n        :param patience: how many epochs to wait before stopping when loss is\n               not improving\n        :param min_delta: minimum difference between new loss and old loss for\n               new loss to be considered as an improvement\n        \"\"\"\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.best_loss = None\n        self.early_stop = False\n    def __call__(self, val_loss):\n        if self.best_loss == None:\n            self.best_loss = val_loss\n        elif self.best_loss - val_loss > self.min_delta:\n            self.best_loss = val_loss\n        elif self.best_loss - val_loss < self.min_delta:\n            self.counter += 1\n            print(f\"INFO: Early stopping counter {self.counter} of {self.patience}\")\n            if self.counter >= self.patience:\n                print('INFO: Early stopping')\n                self.early_stop = True\n\ndef train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    model.train()\n    for batch, (X, y) in enumerate(dataloader):\n        X, y = X.to(device), y.to(device)\n        \n        # Compute prediction error\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if batch % 100 == 0:\n            loss, current = loss.item(), batch * len(X)\n            print(f\"loss: {loss:>7f}  [{current:>5d}\/{size:>5d}]\")\n            \ndef test(dataloader, model, loss_fn, result_dict):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    test_loss \/= num_batches\n    correct \/= size\n    result_dict['avg_loss'].append(test_loss)\n    result_dict['acc'].append(correct)\n    #print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n    \ndef plot_results(axs, res_dict):\n    \n    axs[0].plot(res_dict['epoch'][-10:], res_dict['acc'][-10:], c='r')\n    axs[0].set_title('Validation accuracy {:.4f}'.format(res_dict['acc'][-1]))\n    \n    axs[1].plot(res_dict['epoch'][-10:], res_dict['avg_loss'][-10:], c='r')\n    axs[1].set_title('Average validation loss {:.4f}'.format(res_dict['avg_loss'][-1]))\n    display.clear_output(wait=True)\n    display.display(plt.gcf())","eb8a570e":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint('Using {} device'.format(device))\n\nmodel_fcnn = NeuralNetwork().to(device)\nprint(model_fcnn)\n\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model_fcnn.parameters(), lr=0.0005)\nearly_stop_callback = EarlyStopping()\n\nfig, axs = plt.subplots(1,2, figsize=(12,3))\nplt.suptitle('Fully connected neural network')\nresult = {'avg_loss':[], 'acc':[], 'epoch':[]}\n\nfor t in range(EPOCHS):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train(train_dataloader, model_fcnn, loss_fn, optimizer)\n    test(val_dataloader, model_fcnn, loss_fn, result)\n    result['epoch'].append(t)\n    early_stop_callback(result['avg_loss'][-1])\n    if early_stop_callback.early_stop:\n        break\n    plot_results(axs, result)","ddfb3a05":"# create Dataset for cnn\ntraining_data = CustomImageDataset(df_train, model_type='cnn')\nval_data = CustomImageDataset(df_val, model_type='cnn')\n# create Dataloader for cnn\ntrain_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True)\nval_dataloader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True)\n\nmodel_cnn = CNN().to(device)\nprint(model_cnn)\n\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model_cnn.parameters(), lr=0.0005)\nearly_stop_callback = EarlyStopping()\n\nfig, axs = plt.subplots(1,2, figsize=(12,3))\nplt.suptitle('Convolutional neural network')\nresult = {'avg_loss':[], 'acc':[], 'epoch':[]}\n\nfor t in range(EPOCHS):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train(train_dataloader, model_cnn, loss_fn, optimizer)\n    test(val_dataloader, model_cnn, loss_fn, result)\n    result['epoch'].append(t)\n    early_stop_callback(result['avg_loss'][-1])\n    if early_stop_callback.early_stop:\n        break\n    plot_results(axs, result)","b9cdbb41":"# save model\ntorch.save(model_cnn.state_dict(), \"model.pth\")\nprint(\"Saved PyTorch Model State to model.pth\")\n\n# load model\nmodel = CNN()\nmodel.load_state_dict(torch.load(\"model.pth\"))","7f841529":"# predictions\n\ndf_test = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\ntest_data = CustomImageDataset(df_test, data_type = 'test', model_type='cnn')\n\n# switch to evaluation, opposite to model.train()\nmodel.eval()\n\nwith torch.no_grad():\n    pred = model(test_data.X.unsqueeze(1))\n    \npred = pred.argmax(axis=1)\ndf_sub = pd.DataFrame({'ImageId':list(range(1,len(pred)+1)), 'Label':pred})\ndf_sub.to_csv(\"cnn_mnist_submission.csv\",index=False)","1261d761":"<a id =topic9> <\/a>\n# Make predictions and submission file using CNN model","5f5693a3":"<a id =topic4> <\/a>\n# Creating a Custom Dataset\n\n`Dataset` stores the samples and their corresponding labels, and `DataLoader` wraps an iterable around the Dataset to enable easy access to the samples.\n\nA custom Dataset class must implement three functions: __init__, __len__, and __getitem__\n\nAlso, data set can be created using `torchvision.datasets.ImageFolder` where the images are arranged as\n```\nroot\/dog\/xxx.png\n...\nroot\/cat\/yyy.png\n```","2095f2f1":"<a id =topic1> <\/a>\n# **Intro**\n\n\ud83d\udca1 PyTorch is an open source machine learning framework that accelerates the path from research prototyping to production deployment. **It is used for applications such as computer vision and natural language processing, primarily developed by Facebook's AI Research lab (FAIR).**\n\n<a id =topic2> <\/a>\n## **Comparation of PyTorch with TensorFlow and Keras.**\n\nBased on the monthly number of Stack Overflow questions, we can see that PyTorch becomes more and more popular while TensorFlow and Keras are stagnating. This is one additional reason to get more familiar with this package.\n![pytorch.png](attachment:1c10db6f-bb0d-4364-aa85-9d7c15e66428.png)\n<center><i>Source: Stack Overflow<\/i><\/center>\n\nAlso, PyTorch is fast outpacing TensorFlow in research papers. Of 20-35% of conferene papers that mention the framework they use, **75% cite the use of PyTorch but not TensorFlow**.\n![pytorch2.png](attachment:1b2e17c2-583e-4781-9d49-803af5494e06.png)\n<center><i>Source: https:\/\/www.stateof.ai\/<\/i><\/center>\n\nPyTorch is also more popular that TensorFlow in paper implementations on GitHub. **58% of these implementations are based on Pytorch vs 13% for TensorFlow.**\n![pytorch3.png](attachment:7fba6e71-8a08-4555-805b-0f3eda8c71d3.png)\n<center><i>Source: https:\/\/paperswithcode.com\/trends<\/i><\/center>\n","6de22806":"Also, we'll define EarlyStopping function that stops the training in case validation loss haven't decreased in the 5 consecutive epochs","9ca63fba":"<a id =topic3> <\/a>\n# Goal\n\nMost machine learning workflows involve working with data, creating models, optimizing model parameters, and saving the trained models. This tutorial introduces you to a complete ML workflow implemented in PyTorch. ","b790578d":"<a id =topic7> <\/a>\n# Train FCNN model","dca76c7e":"<a id =topic8> <\/a>\n# Train CNN model","43b013b7":"<a id =topic6> <\/a>\n# Create models\n\nTo define a neural network in PyTorch, we create a class that inherits from nn.Module. We define the layers of the network in the __init__ function and specify how data will pass through the network in the forward function.\n\nWe'll define **fully connected feed forward neural network** and **convolutional neural network**.","8dec6ae4":"# Content\n\n* [Intro](#topic1)\n* [PyTorch vs TensoFlow](#topic2)\n* [Goal](#topic3)\n* [Creating a Custom Dataset](#topic4)\n* [Load data](#topic5)\n* [Create models](#topic6)\n* [Train FCNN model](#topic7)\n* [Train CNN model](#topic8)\n* [Make predictions and submission file using CNN model](#topic9)","eb2b94ed":"<a id =topic5> <\/a>\n# Load data"}}