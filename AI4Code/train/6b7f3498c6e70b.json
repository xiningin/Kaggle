{"cell_type":{"e6f3fdd8":"code","17853c60":"code","fd4f325b":"code","fa9b9e2f":"code","7ecf3223":"code","1535051e":"code","b5a8679c":"code","306cf0de":"code","4888f026":"code","9f458c03":"code","9578d941":"code","9a4bbea7":"code","43fd80ca":"code","a93c29e1":"code","62458653":"code","6f4cb825":"code","0ff2b2c2":"code","bcc062df":"markdown","9e93bb5e":"markdown","a523de06":"markdown","f017afc0":"markdown","48148a80":"markdown","d9161a35":"markdown","5d8e09bf":"markdown","30f89bc3":"markdown","6a27d5b5":"markdown"},"source":{"e6f3fdd8":"import pandas as pd\nimport numpy as np\nimport matplotlib\nfrom matplotlib import pyplot as plt\nfrom sklearn.linear_model import LogisticRegression as LR\nfrom sklearn.feature_extraction import DictVectorizer as DV\nmatplotlib.style.use('ggplot')\n%matplotlib inline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_auc_score\nimport warnings\nwarnings.filterwarnings('ignore')","17853c60":"data = pd.read_csv('..\/input\/unimelb\/unimelb_training.csv')\nprint(data.info())\n\ntest = pd.read_csv('..\/input\/unimelb\/unimelb_test.csv')\ntest.shape","fd4f325b":"X = pd.concat([data, test], ignore_index= 'True').drop('Grant.Status', 1)\n#X= data.drop('Grant.Status', 1)\ny = data['Grant.Status']\nX.info()","fa9b9e2f":"ind,numeric_cols = X.select_dtypes(exclude=['object']).axes\n\nind,categorical_cols = X.select_dtypes(include=['object']).axes\n\nprint(numeric_cols.shape, categorical_cols.shape)","7ecf3223":"X_real_zeros = X[numeric_cols].fillna(0.0)\n\n\"\"\"X_real_mean = X[numeric_cols] \nfor col in numeric_cols:\n     X_real_mean[col]=X_real_mean[col].fillna(np.mean(X_real_mean[col]))\"\"\"\n        \nX_cat = X[categorical_cols].fillna('NA').astype(str)\nprint (X_cat.shape, X_real_zeros.shape)","1535051e":"encoder = DV(sparse = False)\nX_cat_oh = encoder.fit_transform(X_cat.T.to_dict().values())\n\nprint (X_cat_oh.shape)","b5a8679c":"from pandas.plotting import scatter_matrix\n\ndata_numeric = pd.DataFrame(X_real_zeros, columns=numeric_cols)\nlist_cols = ['Number.of.Successful.Grant.1', 'SEO.Percentage.2', 'Year.of.Birth.1']\nscatter_matrix(data_numeric[list_cols], alpha=0.5, figsize=(10, 10))\nplt.show()","306cf0de":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_real_scaled = scaler.fit_transform(X_real_zeros)\n#X_real_mean_scaled = scaler.fit_transform(X_real_means)","4888f026":"data_numeric_scaled = pd.DataFrame(X_real_scaled, columns=numeric_cols)\nlist_cols = ['Number.of.Successful.Grant.1', 'SEO.Percentage.2', 'Year.of.Birth.1']\nscatter_matrix(data_numeric_scaled[list_cols], alpha=0.5, figsize=(10, 10))\nplt.show()","9f458c03":"test_zeros=np.hstack((X_real_zeros[8708:] , X_cat_oh[8708:]))\n#test_mean=np.hstack((X_real_mean [8708:] , X_cat_oh[8708:]))\n\nX_real_zeros_cut = X_real_zeros [:8708]\n#X_real_mean_cut =X_real_mean [:8708]\nX_cat_oh_cut = X_cat_oh [:8708]\n\n\nprint(X_real_zeros.info())\nprint(test_zeros.shape)","9578d941":"from sklearn.model_selection import train_test_split\n\n(X_train_real_zeros, X_test_real_zeros, y_train, y_test) = train_test_split(X_real_zeros_cut, y, test_size=0.3, stratify=y, random_state=0)\n#(X_train_real_mean,  X_test_real_mean) = train_test_split(X_real_mean_cut, test_size=0.3, stratify=y, random_state=0)\n(X_train_cat_oh, X_test_cat_oh) = train_test_split(X_cat_oh_cut, test_size=0.3, random_state=0, stratify=y)\nprint (X_train_real_zeros.shape)\ny_train.shape","9a4bbea7":"print(np.sum(y_train==0))\nprint(np.sum(y_train==1))","43fd80ca":"param_grid = {'C': [0.01, 0.05, 0.1, 0.5, 1, 5, 10]}\n\nlearn_zeros=np.hstack((X_train_real_zeros,X_train_cat_oh))\n#learn_means=np.hstack((X_train_real_mean,X_train_cat_oh))\n\nestimator_lasso = LogisticRegression (solver='liblinear',  class_weight='balanced', penalty = 'l1')\noptimizer_zeros = GridSearchCV(estimator_lasso, param_grid,  cv=3, n_jobs=-1)                \noptimizer_zeros.fit(learn_zeros, y_train)\n\n#optimizer_means = GridSearchCV(estimator_lasso, param_grid,  cv=3, n_jobs=-1)                \n#optimizer_means.fit(learn_means, y_train)\n\n\nprint('score_lasso', optimizer_zeros.best_score_)\nprint('param _lasso', optimizer_zeros.best_params_)\n#print('score_zeros_Smb', optimizer_means.best_score_)","a93c29e1":"def plot_scores(optimizer):\n    scores=[]\n    for i in range(len(optimizer.cv_results_['params'])):\n        scores.append([optimizer.cv_results_['params'][i]['C'], \n                optimizer.cv_results_['mean_test_score'][i],\n                optimizer.cv_results_['std_test_score'][i]])\n    scores = np.array(scores)\n    plt.semilogx(scores[:,0], scores[:,1])\n    plt.fill_between(scores[:,0], scores[:,1]-scores[:,2], \n                                  scores[:,1]+scores[:,2], alpha=0.3)\n    plt.show()\n    print('param _zeros_Smb', optimizer.best_params_)\n\nplot_scores(optimizer_zeros)\n#plot_scores(optimizer_means)\n\n\nprint(optimizer_zeros.best_estimator_.coef_)","62458653":"Y = optimizer_zeros.best_estimator_.predict_proba(test_zeros)[:,0]","6f4cb825":"print(Y)\ny_ans = pd.read_csv('..\/input\/unimelb\/unimelb_example.csv')\nprint(y_ans.info)\ndel y_ans[\"Grant.Status\"]\ny_ans['Grant.Status']=Y\nprint(y)","0ff2b2c2":"y_ans.to_csv('.\/GrantStatus_answer.csv')","bcc062df":"Let's build the same graphs for the converted data:","9e93bb5e":"# One-hot encoding:","a523de06":"The university has provided a dataset containing 249 features, including variables that represent the size of the grant, the general area of study and de-identified information on the investigators who are applying for the grant. Participants train their models on 8,707 grant applications made between 2004 and 2008. They then make predictions on a further 2,176 applications made in 2009 and the first half of 2010.","f017afc0":"# Balancing classes\n\n\nGet look on classes in our train sample:","48148a80":"# Feature Selection Using Lasso Regression\n+class_weight='balanced'","d9161a35":"### Let's select the validation set:","5d8e09bf":"# Stratification ","30f89bc3":"## Data preprocessing and logistic regression for a binary classification problem","6a27d5b5":"# Features scaling"}}