{"cell_type":{"09b6f685":"code","e777790f":"code","43593b50":"code","eee04f92":"code","f18c3216":"code","802835af":"code","4d403867":"code","c7d950ae":"code","1fbd8c13":"code","c29c11cd":"code","6d7cf8b6":"code","37bab17c":"code","905eaa47":"code","876894f3":"code","e2e55921":"code","40802f77":"code","9c4d7270":"code","78412148":"code","f96d5d1b":"code","27202659":"code","b82b7f1e":"code","cc5a58c3":"code","bc7da7a8":"code","7b0b8480":"code","ec6b2102":"code","8dc19a08":"code","3b2fd41e":"code","7d6c6369":"code","f465fea2":"code","554705a8":"code","0c15f294":"code","7158441c":"code","acac00f1":"code","62bb4752":"code","23e52a81":"code","59d168ab":"markdown","3f1c90be":"markdown","9a311b4b":"markdown","7e6b2810":"markdown","c2f9e851":"markdown","1ac16725":"markdown","d32fcc79":"markdown","557b9f79":"markdown","ad74724d":"markdown","8d5fda79":"markdown","7d8da455":"markdown","7c3b3734":"markdown","67075f67":"markdown","834fd026":"markdown","4db01335":"markdown","79f3d109":"markdown","d346d436":"markdown","419cde8a":"markdown","c19f16c2":"markdown","12d64122":"markdown","8cb66e08":"markdown","46439ec0":"markdown","6211d205":"markdown","23d21142":"markdown","bd62931d":"markdown","d2c17d57":"markdown","4512c823":"markdown","36d90223":"markdown","0667fa9f":"markdown","adc4126d":"markdown","c4eb2a38":"markdown","08a2d642":"markdown","0b21f49c":"markdown"},"source":{"09b6f685":"#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n\n#Quelle: Tensorflow.org, Kommentare von T. Eisenhardt","e777790f":"import numpy as np\nimport time\n\nimport PIL.Image as Image\nimport matplotlib.pylab as plt\n\nimport tensorflow as tf\nimport tensorflow_hub as hub","43593b50":"classifier_model =\"https:\/\/tfhub.dev\/google\/tf2-preview\/mobilenet_v2\/classification\/4\" #@param {type:\"string\"}","eee04f92":"IMAGE_SHAPE = (224, 224)\n\nclassifier = tf.keras.Sequential([\n    hub.KerasLayer(classifier_model, input_shape=IMAGE_SHAPE+(3,))\n])","f18c3216":"grace_hopper = tf.keras.utils.get_file('image.jpg','https:\/\/storage.googleapis.com\/download.tensorflow.org\/example_images\/grace_hopper.jpg')\ngrace_hopper = Image.open(grace_hopper).resize(IMAGE_SHAPE)\ngrace_hopper","802835af":"grace_hopper = np.array(grace_hopper)\/255.0\ngrace_hopper.shape","4d403867":"result = classifier.predict(grace_hopper[np.newaxis, ...])\nresult.shape","c7d950ae":"predicted_class = np.argmax(result[0], axis=-1)\npredicted_class","1fbd8c13":"labels_path = tf.keras.utils.get_file('ImageNetLabels.txt','https:\/\/storage.googleapis.com\/download.tensorflow.org\/data\/ImageNetLabels.txt')\nimagenet_labels = np.array(open(labels_path).read().splitlines())","c29c11cd":"plt.imshow(grace_hopper)\nplt.axis('off')\npredicted_class_name = imagenet_labels[predicted_class]\n_ = plt.title(\"Prediction: \" + predicted_class_name.title())","6d7cf8b6":"data_root = tf.keras.utils.get_file(\n  'flower_photos','https:\/\/storage.googleapis.com\/download.tensorflow.org\/example_images\/flower_photos.tgz',\n   untar=True)","37bab17c":"batch_size = 32\nimg_height = 224\nimg_width = 224\n\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  str(data_root),\n  validation_split=0.2,\n  subset=\"training\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","905eaa47":"class_names = np.array(train_ds.class_names)\nprint(class_names)","876894f3":"normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1.\/255)\ntrain_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))","e2e55921":"AUTOTUNE = tf.data.AUTOTUNE\ntrain_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)","40802f77":"for image_batch, labels_batch in train_ds:\n  print(image_batch.shape)\n  print(labels_batch.shape)\n  break","9c4d7270":"result_batch = classifier.predict(train_ds)","78412148":"predicted_class_names = imagenet_labels[np.argmax(result_batch, axis=-1)]\npredicted_class_names","f96d5d1b":"plt.figure(figsize=(10,9))\nplt.subplots_adjust(hspace=0.5)\nfor n in range(30):\n  plt.subplot(6,5,n+1)\n  plt.imshow(image_batch[n])\n  plt.title(predicted_class_names[n])\n  plt.axis('off')\n_ = plt.suptitle(\"ImageNet predictions\")","27202659":"feature_extractor_model = \"https:\/\/tfhub.dev\/google\/tf2-preview\/mobilenet_v2\/feature_vector\/4\" #@param {type:\"string\"}","b82b7f1e":"feature_extractor_layer = hub.KerasLayer(\n    feature_extractor_model, input_shape=(224, 224, 3), trainable=False)","cc5a58c3":"feature_batch = feature_extractor_layer(image_batch)\nprint(feature_batch.shape)","bc7da7a8":"num_classes = len(class_names)\n\nmodel = tf.keras.Sequential([\n  feature_extractor_layer,\n  tf.keras.layers.Dense(num_classes)\n])\n\nmodel.summary()","7b0b8480":"predictions = model(image_batch)","ec6b2102":"predictions.shape","8dc19a08":"model.compile(\n  optimizer=tf.keras.optimizers.Adam(),\n  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['acc'])","3b2fd41e":"class CollectBatchStats(tf.keras.callbacks.Callback):\n  def __init__(self):\n    self.batch_losses = []\n    self.batch_acc = []\n\n  def on_train_batch_end(self, batch, logs=None):\n    self.batch_losses.append(logs['loss'])\n    self.batch_acc.append(logs['acc'])\n    self.model.reset_metrics()\n\nbatch_stats_callback = CollectBatchStats()\n\nhistory = model.fit(train_ds, epochs=2,\n                    callbacks=[batch_stats_callback])","7d6c6369":"plt.figure()\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Training Steps\")\nplt.ylim([0,2])\nplt.plot(batch_stats_callback.batch_losses)","f465fea2":"plt.figure()\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Training Steps\")\nplt.ylim([0,1])\nplt.plot(batch_stats_callback.batch_acc)","554705a8":"predicted_batch = model.predict(image_batch)\npredicted_id = np.argmax(predicted_batch, axis=-1)\npredicted_label_batch = class_names[predicted_id]","0c15f294":"plt.figure(figsize=(10,9))\nplt.subplots_adjust(hspace=0.5)\nfor n in range(30):\n  plt.subplot(6,5,n+1)\n  plt.imshow(image_batch[n])\n  plt.title(predicted_label_batch[n].title())\n  plt.axis('off')\n_ = plt.suptitle(\"Model predictions\")","7158441c":"t = time.time()\n\nexport_path = \"\/tmp\/saved_models\/{}\".format(int(t))\nmodel.save(export_path)\n\nexport_path","acac00f1":"reloaded = tf.keras.models.load_model(export_path)","62bb4752":"result_batch = model.predict(image_batch)\nreloaded_result_batch = reloaded.predict(image_batch)","23e52a81":"abs(reloaded_result_batch - result_batch).max()","59d168ab":"### Datensatz\n\n F\u00fcr dieses Beispiel verwenden wir das TensorFlow-Blumen-Dataset. Wir k\u00f6nnen alternativ auch direkt in Kaggle Datens\u00e4tze hinzuf\u00fcgen, das spart evtl. etwas Zeit, insbesondere wenn wir das Notebook teilen.","3f1c90be":" Die Konventionen von TensorFlow Hub f\u00fcr Bildmodelle sind, f\u00fcr jedes Pixel eine Zahl im Bereich von `[0, 1]` zu erwarten. Unsere Bilder haben eine Zahl von 0 bis 255, also ein Byte, pro Pixel. Zur Konvertierung benutzen wir `Rescaling`.\n \n *Note: you could also include the `Rescaling` layer inside the model. See this [guide](https:\/\/www.tensorflow.org\/guide\/keras\/preprocessing_layers) for a discussion of the tradeoffs.*","9a311b4b":"Okay, das Netz funktioniert also! Es kann milit\u00e4rische Uniformen und 1000 andere Klassen unterscheiden, aber viele Dinge kennt es nicht. Wir basteln daraus jetzt ein neues Netz, das keine Uniformen mehr erkennt, aber daf\u00fcr verschiedene Blumen unterscheiden kann.","7e6b2810":"It returns a 1280-length vector for each image:","c2f9e851":"### Ein kleiner Test: Wir halten ein einzelnes Bild an den Klassifikator\n\n Lade ein einzelnes Bild herunter, um das Modell anzuprobieren.","1ac16725":"## Learn more\n\nCheck out more [tutorials](https:\/\/www.tensorflow.org\/hub\/tutorials) for using image models from TensorFlow Hub.","d32fcc79":"###  Laden Sie den Klassifikator herunter\n\nNutze `hub.KerasLayer`, um das [MobileNetV2 model](https:\/\/tfhub.dev\/google\/tf2-preview\/mobilenet_v2\/classification\/2) von TensorFlow Hub herunterzuladen. Jedes [kompatible image classifier model](https:\/\/tfhub.dev\/s?q=tf2&module-type=image-classification) von TensorFlow Hub funktioniert ebenso.","557b9f79":"Now confirm that we can reload it, and it still gives the same results:","ad74724d":"Now use the `.fit` method to train the model.\n\nTo keep this example short train just 2 epochs. To visualize the training progress, use a custom callback to log the loss and accuracy of each batch individually, instead of the epoch average.","8d5fda79":"Let's make sure to use buffered prefetching so we can yield data from disk without having I\/O become blocking. These are two important methods you should use when loading data.\n\nInterested readers can learn more about both methods, as well as how to cache data to disk in the [data performance guide](https:\/\/www.tensorflow.org\/guide\/data_performance#prefetching).","7d8da455":"###  Entschl\u00fcssele die Vorhersagen\n\n Die Klassen-ID 653 sagt uns zun\u00e4chst nichts. Nimm die vorhergesagte Klassen-ID und rufe die `ImageNet`-Labels ab, um die Vorhersagen zu entschl\u00fcsseln.","7c3b3734":"### Attach a classification head\n\nNow wrap the hub layer in a `tf.keras.Sequential` model, and add a new classification layer.","67075f67":"### Download the headless model\n\nTensorFlow Hub also distributes models without the top classification layer. These can be used to easily do transfer learning.\n\nAny [compatible image feature vector model](https:\/\/tfhub.dev\/s?module-type=image-feature-vector&q=tf2) from TensorFlow Hub will work here.","834fd026":"##  Ein ImageNet-Klassifikator\n\nWir starten mit einem fertigen Klassifikator-Modell -- das ist ein Neuronales Netz, das bereits mit den Bildern aus ImageNet trainiert wurde. Das Training mit 14 Mio. Bildern dauert selbst auf leistungsf\u00e4higen GPUs einige Stunden und kostet etwa 20-30\u20ac f\u00fcr Rechenleistung (bei eigener Hardware sind die Stromkosten auch nicht viel geringer).\n\nWir greifen auf dieses m\u00e4chtige Werkzeug zur\u00fcck, ohne im Detail zu verstehen, warum es so komplex aufgebaut ist. Alles was wir tun, ist die Ausgabeschicht \"abzuschneiden\" und durch unsere eigene Schicht zu ersetzen; diese letzte Schicht m\u00fcssen wir dann noch mit unseren eigenen Bildern trainieren. Danach sollte das Netz schon halbwegs funktionieren! Sp\u00e4ter kann man das Netz noch optimieren (\"fine-tuning\").","4db01335":" Lass uns diese Daten in unser Modell laden, indem wir Bilder von der Festplatte mit image_dataset_from_directory verwenden.","79f3d109":"Now after, even just a few training iterations, we can already see that the model is making progress on the task.","d346d436":"#  Tranferlernen mit TensorFlow Hub \n\n<table class=\"tfo-notebook-buttons\" align=\"left\">\n  <td>\n    <a target=\"_blank\" href=\"https:\/\/www.tensorflow.org\/tutorials\/images\/transfer_learning_with_hub\"><img src=\"https:\/\/www.tensorflow.org\/images\/tf_logo_32px.png\" \/>View on TensorFlow.org<\/a>\n  <\/td>\n  <td>\n    <a target=\"_blank\" href=\"https:\/\/colab.research.google.com\/github\/tensorflow\/docs\/blob\/master\/site\/en\/tutorials\/images\/transfer_learning_with_hub.ipynb\"><img src=\"https:\/\/www.tensorflow.org\/images\/colab_logo_32px.png\" \/>Run in Google Colab<\/a>\n  <\/td>\n  <td>\n    <a target=\"_blank\" href=\"https:\/\/github.com\/tensorflow\/docs\/blob\/master\/site\/en\/tutorials\/images\/transfer_learning_with_hub.ipynb\"><img src=\"https:\/\/www.tensorflow.org\/images\/GitHub-Mark-32px.png\" \/>View on GitHub<\/a>\n  <\/td>\n  <td>\n    <a href=\"https:\/\/storage.googleapis.com\/tensorflow_docs\/docs\/site\/en\/tutorials\/images\/transfer_learning_with_hub.ipynb\"><img src=\"https:\/\/www.tensorflow.org\/images\/download_logo_32px.png\" \/>Download notebook<\/a>\n  <\/td>\n  <td>\n    <a href=\"https:\/\/tfhub.dev\/google\/tf2-preview\/mobilenet_v2\/feature_vector\/4\"><img src=\"https:\/\/www.tensorflow.org\/images\/hub_logo_32px.png\" \/>See TF Hub model<\/a>\n  <\/td>\n<\/table>","419cde8a":" Das Ergebnis ist ein Vektor mit 1001 Elementen, der die Wahrscheinlichkeit jeder Klasse f\u00fcr das Bild bewertet.\n\nSo l\u00e4sst sich die ID der wahrscheinlichsten Klasse mit argmax ermitteln:","c19f16c2":"##### Copyright 2018 The TensorFlow Authors.","12d64122":" Der Blumen-Datensatz hat f\u00fcnf Klassen.","8cb66e08":"## Setup","46439ec0":"Now check how these predictions line up with the images:","6211d205":"This SavedModel can be loaded for inference later, or converted to [TFLite](https:\/\/www.tensorflow.org\/lite\/convert\/) or [TFjs](https:\/\/github.com\/tensorflow\/tfjs-converter).\n","23d21142":"### Train the model\n\nUse compile to configure the training process:","bd62931d":"## Export your model\n\nNow that you've trained the model, export it as a SavedModel for use later on.","d2c17d57":"Create the feature extractor. Use `trainable=False` to freeze the variables in the feature extractor layer, so that the training only modifies the new classifier layer.","4512c823":"### Check the predictions\n\nTo redo the plot from before, first get the ordered list of class names:","36d90223":"### Run the classifier on a batch of images\n\nNow run the classifier on the image batch.","0667fa9f":"##  Einfaches Transferlernen\n\nAber was ist, wenn Sie einen Klassifikator f\u00fcr ein Dataset mit anderen Klassen trainieren m\u00f6chten? Wir k\u00f6nnen auch ein Modell von TFHub verwenden, um einen eigenen Bildklassifizierer zu trainieren. Dazu trainieren wir die oberste Schicht des Modells erneut, damit sie die Klassen in unserem Dataset erkennt.","adc4126d":"[TensorFlow Hub](https:\/\/tfhub.dev\/) ist ein Repository mit vortrainierten TensorFlow-Modellen.\n\nDieses Tutorial zeigt dir, wie du:\n\n    1. Modelle von TensorFlow Hub mit tf.keras verwendest\n    2. ein Bildklassifizierungsmodell von TensorFlow Hub benutzt\n    3. ein einfaches  Transferlernen durchf\u00fchrst, um ein Modell f\u00fcr deine eigenen Bildklassen zu verfeinern","c4eb2a38":"Hier gibt es einen kleinen Stolperstein: Normalerweise gibt man dem Klassifikator kein einzelnes Bild, sondern viele. Daher erwartet die Funktion `classifier.predict` Daten mit einer zus\u00e4tzlichen Dimension, die wir mit `np.newaxis` einf\u00fcgen m\u00fcssen.","08a2d642":"See the `LICENSE.txt` file for image attributions.\n\nThe results are far from perfect, but reasonable considering that these are not the classes the model was trained for (except \"daisy\").","0b21f49c":"Plot the result"}}