{"cell_type":{"36cb50da":"code","6c8699b6":"code","934cb50b":"code","75d757e7":"code","a35c424a":"code","576418b5":"code","409871f1":"code","d367ab21":"code","c9422a18":"code","5821b0b1":"code","7fe4aa32":"code","23b2d231":"code","630b59ac":"code","eef08d69":"code","a6b90d31":"code","d9dd4f29":"code","963cc35c":"code","9c4fe602":"code","bc1be626":"code","e3a76474":"code","85c01d63":"code","5f1f6fe4":"code","e4282c3c":"code","f8756ae2":"code","c462b6c5":"markdown","4a70cfc9":"markdown","81b1f253":"markdown","d0ff5c68":"markdown","58d3b2f0":"markdown","e766ae05":"markdown","99ea0211":"markdown","b07e5e88":"markdown","ed203d1f":"markdown","739faf9b":"markdown"},"source":{"36cb50da":"## Most Important\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom pathlib import Path\nimport cv2\n## less Important\nfrom functools import partial\nimport os\nimport joblib\nfrom sklearn.model_selection import train_test_split\n\n## tensorflow & Keras\nimport tensorflow as tf    \nimport warnings \nwarnings.filterwarnings('ignore')","6c8699b6":"train_labels = pd.read_csv('..\/input\/arabic-hwr-ai-pro-intake1\/train.csv')\ntrain_images = Path(r'..\/input\/arabic-hwr-ai-pro-intake1\/train')\n\n## read these all training images paths as Series\ntrain_images_paths = pd.Series(sorted(list(train_images.glob(r'*.png'))), name='Filepath').astype(str)","934cb50b":"img_key_value = {}\nfor value in train_labels['label'].unique():\n    img_key_value[value] = train_labels[train_labels['label']==value].index[0]\n    \nimg_index = list(img_key_value.values())\nimg_label = list(img_key_value.keys())\n\nfig, ax = plt.subplots(4, 7, figsize=(12, 8))\n\ni = 0\nfor row in range(4):\n    for col in range(7):\n        plt.sca(ax[row, col])\n        plt.title(f'label = {img_label[i]}')\n        img = plt.imread(train_images_paths.iloc[img_index[i]])\n        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n        plt.imshow(img)\n        plt.axis('off')\n        i+=1","75d757e7":"print('Number of Instances in train_set =>', len(train_images_paths))\nprint('Number of Instances in train_labels =>', len(train_labels))\n\nimg = plt.imread(train_images_paths.iloc[img_index[0]])\nprint('shape of each Image is =>', img.shape)","a35c424a":"train_full_labels = tf.keras.utils.to_categorical(train_labels['label'].values -1 ,num_classes=train_labels['label'].nunique())\n\ntrain_full_set = np.empty((13440, 32, 32, 1), dtype=np.float32)  \n\nfor idx, path in enumerate(train_images_paths):\n    img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n    img = np.expand_dims(img,axis=2)\n    train_full_set[idx] = img\n    \nprint('train_full_set.shape =>', train_full_set.shape)\nprint('train_full_labels.shape =>', train_full_labels.shape)","576418b5":"X_train, X_valid, y_train, y_valid = train_test_split(train_full_set, train_full_labels, \n                                                      test_size=0.2,stratify=train_full_labels, random_state=42)\n\nprint('X_train.shape =>', X_train.shape)\nprint('X_valid.shape =>', X_valid.shape)\nprint('y_train.shape =>', y_train.shape)\nprint('y_valid.shape =>', y_valid.shape)","409871f1":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndef add_noise(img):\n    '''Add random noise to an image'''\n    VARIABILITY = 50\n    deviation = VARIABILITY*np.random.random()\n    noise = np.random.normal(0, deviation, img.shape)\n    img += noise\n    np.clip(img, 0., 255.)\n    return \n\ndef rescale(img):\n    return img\/255.0\n\ntrain_datagen = ImageDataGenerator(\n        rotation_range=30\n        ,shear_range=0.1\n        ,zoom_range=0.15\n        ,width_shift_range=0.2\n        ,height_shift_range=0.2\n        ,preprocessing_function=rescale\n)\n\ntrain_gen = train_datagen.flow(x=X_train, y=y_train, batch_size=32,shuffle=True)\n\ntest_datagen = ImageDataGenerator(preprocessing_function=rescale)\ntest_gen = test_datagen.flow(x=X_valid, y=y_valid, batch_size=32)\n","d367ab21":"fig, axes = plt.subplots(3,3,figsize=(8,8))\nplt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.4, hspace=0.4)\naxes = axes.flatten()\nfor batch in train_gen:\n    imgs,labels = batch\n    for i in range(9):\n        plt.sca(axes[i])\n        plt.title(f\"label: {np.argmax(labels[i])+1}\")\n        plt.imshow(imgs[i])\n    break","c9422a18":"def skip_model():\n    inputs = tf.keras.layers.Input(shape=(32,32,1))\n    x = tf.keras.layers.Conv2D(filters=16, kernel_size=3,padding='same',activation='elu')(inputs)\n    x = tf.keras.layers.Conv2D(filters=16, kernel_size=5,padding='same',activation='elu')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    skip_conn_1 = tf.keras.layers.MaxPooling2D(pool_size=2)(x)\n\n    x = tf.keras.layers.Conv2D(filters=32, kernel_size=3,padding='same',activation='elu')(skip_conn_1)\n    x = tf.keras.layers.Conv2D(filters=32, kernel_size=5,padding='same',activation='elu')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Concatenate()([skip_conn_1,x])\n    skip_conn_2 = tf.keras.layers.MaxPooling2D(pool_size=2)(x)\n\n\n    x = tf.keras.layers.Conv2D(filters=64, kernel_size=3,padding='same',activation='elu')(skip_conn_2)\n    x = tf.keras.layers.Conv2D(filters=64, kernel_size=5,padding='same',activation='elu',name=\"feature_map\")(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Concatenate()([skip_conn_2,x])\n    x = tf.keras.layers.MaxPooling2D(pool_size=2)(x)\n\n\n    x = tf.keras.layers.Flatten()(x)\n\n    x = tf.keras.layers.Dense(64,activation='elu')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n    outputs = tf.keras.layers.Dense(28,activation='softmax')(x)\n\n    return tf.keras.Model(inputs=inputs,outputs=outputs)","5821b0b1":"def inception_model():\n    inputs = tf.keras.layers.Input(shape=(32,32,1))\n\n    ######################################################################################\n    conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=3,padding='same')(inputs)\n    conv1 = tf.keras.layers.BatchNormalization()(conv1)\n    conv_block_1 = tf.keras.layers.ELU()(conv1)\n\n    conv2 = tf.keras.layers.Conv2D(filters=32, kernel_size=5,padding='same')(inputs)\n    conv2 = tf.keras.layers.BatchNormalization()(conv2)\n    conv_block_2 = tf.keras.layers.ELU()(conv2)\n\n    feature_map_1 = tf.keras.layers.Concatenate()([conv_block_1,conv_block_2])\n    feature_map_1 = tf.keras.layers.MaxPooling2D(pool_size=2)(feature_map_1)\n\n    #######################################################################################\n    conv3 = tf.keras.layers.Conv2D(filters=64, kernel_size=3,padding='same')(feature_map_1)\n    conv3 = tf.keras.layers.BatchNormalization()(conv3)\n    conv_block_3 = tf.keras.layers.ELU()(conv3)\n\n    conv4 = tf.keras.layers.Conv2D(filters=64, kernel_size=5,padding='same')(feature_map_1)\n    conv4 = tf.keras.layers.BatchNormalization()(conv4)\n    conv_block_4 = tf.keras.layers.ELU()(conv4)\n\n    feature_map_2 = tf.keras.layers.Concatenate()([conv_block_3,conv_block_4])\n    feature_map_2 = tf.keras.layers.MaxPooling2D(pool_size=2)(feature_map_2)\n    ########################################################################################\n\n    conv5 = tf.keras.layers.Conv2D(filters=128, kernel_size=3,padding='same')(feature_map_2)\n    conv5 = tf.keras.layers.BatchNormalization()(conv5)\n    conv_block_5 = tf.keras.layers.ELU()(conv5)\n\n    conv6 = tf.keras.layers.Conv2D(filters=128, kernel_size=5,padding='same')(feature_map_2)\n    conv6 = tf.keras.layers.BatchNormalization()(conv6)\n    conv_block_6 = tf.keras.layers.ELU()(conv6)\n\n    feature_map_3 = tf.keras.layers.Concatenate()([conv_block_5,conv_block_6])\n    feature_map_3 = tf.keras.layers.MaxPooling2D(pool_size=2,name='feature_map')(feature_map_3)\n\n    x = tf.keras.layers.Flatten()(feature_map_3)\n\n    x = tf.keras.layers.Dense(256,activation='elu')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dropout(0.5)(x)\n    outputs = tf.keras.layers.Dense(28,activation='softmax')(x)\n\n    return tf.keras.Model(inputs=inputs,outputs=outputs)","7fe4aa32":"model = inception_model()\nmodel.summary()","23b2d231":"lr = 1e-2\ndef exponential_decay_fn(epoch):\n    return lr * 0.1**(epoch \/ 5)\nopt = tf.keras.optimizers.Adam(learning_rate=lr)\nmodel.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\nearly_stopp = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5, restore_best_weights=True)\nlr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)","630b59ac":"history = model.fit(train_gen, validation_data=test_gen, \n                              epochs=60,\n                              steps_per_epoch=336,\n                              validation_steps=84,\n                              callbacks=[early_stopp,lr_scheduler])","eef08d69":"import numpy as np\nfrom tensorflow.keras import backend as K\n\n# The local path to our target image\nimg_path = '..\/input\/arabic-hwr-ai-pro-intake1\/train\/00101.png'\n\nimg = cv2.imread(img_path,cv2.IMREAD_GRAYSCALE)\n\nimg = np.expand_dims(img, axis=2)\nimg = np.expand_dims(img, axis=0)\nimg = img\/255.0\n\nconv_layer = model.get_layer(\"feature_map\")\nheatmap_model = tf.keras.models.Model([model.inputs], [conv_layer.output, model.output])\n\n# Get gradient of the winner class w.r.t. the output of the (last) conv. layer\nwith tf.GradientTape() as gtape:\n    conv_output, predictions = heatmap_model(img)\n    loss = predictions[:, np.argmax(predictions[0])]\n    grads = gtape.gradient(loss, conv_output)\n    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n\nheatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_output), axis=-1)\nheatmap = np.maximum(heatmap,0)\nheatmap \/= np.max(heatmap)\n#print(heatmap.shape)\nheatmap = np.reshape(heatmap,(4,4))\nplt.matshow(heatmap)\nplt.show()","a6b90d31":"image = cv2.imread(img_path)\nplt.imshow(image)\nprint(image.shape)","d9dd4f29":"heatmap = cv2.resize(heatmap, (image.shape[0], image.shape[1]))\nheatmap = np.uint8(255 * heatmap)\nheatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\nprint(heatmap.shape)\nsuperimposed_img = heatmap * 0.4 + image\ncv2.imwrite('inspection.png', superimposed_img)\n\ninspect= cv2.imread(\".\/inspection.png\")\ninspect = cv2.cvtColor(inspect,cv2.COLOR_BGR2RGB)\nplt.imshow(inspect)\nplt.show()","963cc35c":"fig = plt.figure(figsize=(14,5))\nax_1 = fig.add_subplot(121)\nax_1.plot(history.history['accuracy'],label='Accuracy')\nax_1.plot(history.history['val_accuracy'],label='Validation Accuracy')\nplt.title('Accuracy',fontsize=16)\nplt.legend()\n\nax_2 = fig.add_subplot(122)\nax_2.plot(history.history['loss'],label='loss')\nax_2.plot(history.history['val_loss'],label='validation loss')\nplt.title('Losses',fontsize=16)\nplt.legend()\n\nplt.show()","9c4fe602":"loss_all_data, acc_all_data = model.evaluate(train_full_set\/255.0, train_full_labels, verbose=0)\nprint('loss_all_data =>', loss_all_data)\nprint('acc_all_data =>', acc_all_data)","bc1be626":"test_labels = pd.read_csv('..\/input\/arabic-hwr-ai-pro-intake1\/test.csv')\ntest_images = Path(r'..\/input\/arabic-hwr-ai-pro-intake1\/test')\n\n## read these all training images paths as Series\ntest_images_paths = pd.Series(sorted(list(test_images.glob(r'*.png'))), name='Filepath').astype(str)\n\ntest_images_paths.head()","e3a76474":"print('Number of Instances in test_set is', len(test_images_paths))","85c01d63":"test_full_set = np.empty((3360, 32, 32, 1), dtype=np.float32) \ntest_full_set = test_full_set\nfor idx, path in enumerate(test_images_paths):\n    img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n    img = np.expand_dims(img,axis=2)\n    test_full_set[idx] = img\n    \nprint('test_full_set.shape =>', test_full_set.shape)","5f1f6fe4":"y_preds_classes = np.argmax(model.predict(test_full_set\/255.0), axis=-1) + 1\ntest_labels['label'] = y_preds_classes\n","e4282c3c":"fig, ax = plt.subplots(4, 7, figsize=(12, 8))\n\ni = 0\nfor row in range(4):\n    for col in range(7):\n        plt.sca(ax[row, col])\n        plt.title(f'prediction = {y_preds_classes[i]}')\n        img = test_full_set[i]\n        plt.imshow(img)\n        plt.axis('off')\n        i+=1","f8756ae2":"test_labels[['id', 'label']].to_csv('\/kaggle\/working\/submission.csv', index=False)","c462b6c5":"## GradCamp HeatMap","4a70cfc9":"## Images Exploration","81b1f253":"## inception model meta arch","d0ff5c68":"## Model Accuracies and Losses","58d3b2f0":"## Model Training","e766ae05":"## skip connection meta arch model","99ea0211":"## Evaluation on Testing DataSet","b07e5e88":"## Generator Output debuging","ed203d1f":"### Model Evaluation over all dataset","739faf9b":"## Data Preprocessing"}}