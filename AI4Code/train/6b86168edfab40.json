{"cell_type":{"ddbeecca":"code","cfa82233":"code","bd8acc6c":"code","60f20fb7":"code","d38cd219":"code","e8bd1c50":"code","ef2341c7":"code","5ff18238":"code","d6d76a03":"code","2aea1406":"code","c8b7ba11":"code","01fdc92d":"code","055177e1":"code","b55f1940":"code","d6e5d1d2":"code","4d55c8d5":"code","6522f42d":"code","479520fd":"code","ed7a1675":"code","f44bc311":"code","a0303df2":"code","7523f713":"code","1655e9a0":"code","89e7fa44":"code","5f5d4919":"code","3df681c9":"code","6f2780f4":"code","ca0b61e4":"code","1e698c50":"code","69a92320":"code","9a8f685e":"code","98259722":"code","72dc181e":"code","7bf0a7a0":"code","a298c9c7":"code","fd8a5d03":"code","5782ca26":"code","fdfa639b":"code","b6300238":"markdown","eab9a66c":"markdown","c489bcc3":"markdown","c0ab7f37":"markdown","e978fcbe":"markdown","71c5e9e5":"markdown","366f6fe1":"markdown","eacd0361":"markdown","c0554ccf":"markdown","23f2407d":"markdown","fc1426aa":"markdown","d47efff1":"markdown","47de3428":"markdown"},"source":{"ddbeecca":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cfa82233":"# important packages\n\t\nimport pandas as pd\t\t\t\t\t# data manipulation using dataframes\nimport numpy as np\t\t\t\t\t# data statistical analysis\n\nimport seaborn as sns\t\t\t\t# Statistical data visualization\nimport matplotlib.pyplot as plt\t\t# data visualisation\n%matplotlib inline","bd8acc6c":"df = pd.read_csv(\"..\/input\/modified-urbansound8kcsv\/modified_URBANSOUND8K.csv\", index_col = 0)","60f20fb7":"df.head()","d38cd219":"### Define Features(X) & Target(y)\n\nX = df.iloc[:, :-1].values\ny = df.iloc[:, -1].values.reshape(-1,1)","e8bd1c50":"print(X.shape)\nprint(y.shape)","ef2341c7":"from tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\nlabelencoder=LabelEncoder()\ny=to_categorical(labelencoder.fit_transform(y))","5ff18238":"print(y.shape)","d6d76a03":"print(y)","2aea1406":"### Splitting Dataset ###\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split( X, y , test_size = 0.2, random_state = 0)","c8b7ba11":"print(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)","01fdc92d":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Input, Dense, Dropout","055177e1":"num_label = y.shape[1]","b55f1940":"model = Sequential()\nmodel.add(Input(shape = (40, ))) \nmodel.add(Dense(512, activation = 'relu'))\nmodel.add(Dense(256, activation = 'relu'))\nmodel.add(Dense(128, activation = 'relu'))\nmodel.add(Dense(num_label, activation = 'softmax'))","d6e5d1d2":"model.summary()","4d55c8d5":"from tensorflow.keras.optimizers import RMSprop, SGD, Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau","6522f42d":"## callbacks\n\nes = EarlyStopping(monitor='val_loss',\n                   mode='min',\n                   verbose=1,\n                   patience=10,\n                   min_delta=0.001)\n\ncp = ModelCheckpoint('.\/best_model.h5', \n                     monitor='val_loss', \n                     mode='min',\n                     save_best_only=True,\n                     verbose=1)","479520fd":"model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics = ['accuracy'])","ed7a1675":"num_epochs = 100\nnum_batch_size = 32\n\nhistory = model.fit(X_train,\n                    y_train,\n                    epochs = num_epochs,\n                    batch_size = num_batch_size,\n                    verbose = 2,\n                    validation_split = 0.2,\n                    callbacks = [es])","f44bc311":"history.history.keys()","a0303df2":"plt.plot(history.history['loss'], label='train_loss')\nplt.plot(history.history['val_loss'], label='val_loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid(True)","7523f713":"plt.plot(history.history['accuracy'], label='train_acc')\nplt.plot(history.history['val_accuracy'], label='val_acc')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.grid(True)","1655e9a0":"y_pred = model.predict(X_test)","89e7fa44":"y_pred.shape","5f5d4919":"y_pred[0]","3df681c9":"y_pred = y_pred > 0.5","6f2780f4":"print(y_pred[0], y_test[0])","ca0b61e4":"# Accuracy\n\nscore = model.evaluate(X_train, y_train, verbose=0)\nprint(\"Training Accuracy: \", score[1])\n\nscore = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Testing Accuracy: \", score[1])","1e698c50":"### Confusion Matrix ###\n\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n\nplt.figure(figsize=(10,6))\nsns.heatmap(cm, annot=True)\nplt.show()","69a92320":"### Classification report ###\n\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))","9a8f685e":"# load original dataframe\n\nraw_df = pd.read_csv(\"..\/input\/urbansound8k\/UrbanSound8K.csv\")","98259722":"# choose random audio file\n\nimport random\nimport os\n\ndir = \"..\/input\/urbansound8k\/\"\n\nrow = raw_df.sample()\n\nrow = row.reset_index(drop=True)\n\naudio_file = row['slice_file_name'][0]\naudio_path = dir + 'fold' + str(row['fold'][0]) + '\/' + row['slice_file_name'][0]\nclass_label = row['class'][0]\nprint(audio_path)","72dc181e":"# import librosa library\n\nimport librosa\t\t\t\t\t\t\t# package for music and audio analysis\nimport librosa.display\nimport IPython.display as ipd\t\t\t# public api for display tool in ipython","7bf0a7a0":"# feature engineering\n\ndef feature_extractor(audio_file):\n    data,sample_rate = librosa.load(audio_file, res_type='kaiser_fast')\n    mfccs_file = librosa.feature.mfcc(y=data, sr=sample_rate, n_mfcc=40)\n    return mfccs_file\n\nmfccs_audio = feature_extractor(audio_path)\nmfccs_audio = np.mean(mfccs_audio.T,axis=0)\nmfccs_audio = mfccs_audio.reshape(-1,1).T","a298c9c7":"print(mfccs_audio.shape)","fd8a5d03":"# class prediction\n\npredict_label = model.predict(mfccs_audio)\npredict_label = (predict_label > 0.5).T\npredict_class = labelencoder.inverse_transform(predict_label) ","5782ca26":"# check real and prediction class\n\nprint(predict_class, class_label)","fdfa639b":"# Now listen music od predicted class\n\nipd.Audio(audio_path)","b6300238":"!!yayyyy","eab9a66c":"## Accuracy","c489bcc3":"Our trained model obtained a Training accuracy of average 98%, Validatioon accuracy of 90% and a Testing accuracy of 88%.\nThe performance is very good and the model has generalised well, seeming to predict well when tested against new audio data.","c0ab7f37":"# Model Prediction","e978fcbe":"## Confusion Matrix","71c5e9e5":"# Model Testing","366f6fe1":"# Data Preprocessing","eacd0361":"# Conclusion","c0554ccf":"# Model Building","23f2407d":"# Metrices","fc1426aa":"# Importing Libraries","d47efff1":"## Classification Report","47de3428":"# Importing modified dataset"}}