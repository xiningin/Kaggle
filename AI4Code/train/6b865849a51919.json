{"cell_type":{"a709aa67":"code","5222ac4e":"code","cea19b88":"code","794d622a":"code","4614a106":"code","c69c4f9c":"code","d40d2819":"code","fc785416":"code","9de4ed24":"code","afa72ba6":"code","73268a22":"code","8587e2b3":"code","fb45c254":"code","daa7a79a":"code","7be48fb4":"code","961aebc1":"code","00bbbdc7":"code","2fe77049":"code","be26de8b":"code","d30eb255":"code","81a85f05":"code","2b9fe203":"code","96772126":"code","0609565b":"code","3056da58":"code","16e00f3f":"code","1bba85c3":"code","889a81a9":"code","10474a80":"code","ca27e213":"code","52a8e0bf":"code","11ccd279":"code","3223d3ec":"code","b3d014cc":"code","9b005fd0":"code","4228e3a3":"code","d781a8ee":"code","b97addf4":"code","48ba915c":"code","e5f9f199":"code","7e78957f":"markdown","9e35b940":"markdown","276d28cf":"markdown","9f1fce09":"markdown","ea48352c":"markdown","f48fb2f0":"markdown","465e913d":"markdown","d9017749":"markdown","b99c8bc9":"markdown","05950b43":"markdown","e2a8c5f2":"markdown","1b9e3e10":"markdown","2eef7b5f":"markdown","78d99a9e":"markdown","aca8ced8":"markdown","c258baf7":"markdown","d626c5e2":"markdown","80e38d95":"markdown","ae1dc836":"markdown","9456c267":"markdown","8b182715":"markdown","ed1d3e1c":"markdown","ed53c402":"markdown","b92945d7":"markdown"},"source":{"a709aa67":"import numpy as np\nimport pandas as pd\nimport string\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, LSTM, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom wordcloud import STOPWORDS\n\nfrom sklearn.model_selection import train_test_split\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","5222ac4e":"train = pd.read_csv('..\/input\/toxic-comments-train\/train.csv')\ntest = pd.read_csv('..\/input\/jigsaw-toxic-severity-rating\/validation_data.csv')\nsample = pd.read_csv('..\/input\/jigsaw-toxic-severity-rating\/sample_submission.csv')\ntarget = pd.read_csv('..\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv')","cea19b88":"train.head()","794d622a":"train['y'] = train[['toxic','severe_toxic','obscene','threat','insult','identity_hate']].sum(axis=1) > 0\ntrain.drop(['toxic','severe_toxic','obscene','threat','insult','identity_hate'], inplace=True, axis=1)","4614a106":"train.head()","c69c4f9c":"train.y.unique()","d40d2819":"train.y.value_counts().plot(kind='barh')","fc785416":"count_of_toxic_comments =  train[train.y != 0].shape[0]\ncount_of_toxic_comments","9de4ed24":"train_toxic = train[train.y != 0]\ntrain_non_toxic = train[train.y == 0].sample(count_of_toxic_comments)","afa72ba6":"df = pd.concat([train_toxic, train_non_toxic])\ndf","73268a22":"df.y.value_counts().plot(kind='barh')","8587e2b3":"# word_count\ndf['word_count'] = df['comment_text'].apply(lambda x: len(str(x).split()))\n\n# unique_word_count\ndf['unique_word_count'] = df['comment_text'].apply(lambda x: len(set(str(x).split())))\n\n# stop_word_count\ndf['stop_word_count'] = df['comment_text'].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS]))\n\n# mean_word_length\ndf['mean_word_length'] = df['comment_text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n\n# char_count\ndf['char_count'] = df['comment_text'].apply(lambda x: len(str(x)))\n\n# punctuation_count\ndf['punctuation_count'] = df['comment_text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))","fb45c254":"df.head()","daa7a79a":"METAFEATURES = ['word_count', 'unique_word_count', 'stop_word_count', 'mean_word_length','char_count', 'punctuation_count']\nTOXIC_COMMENTS = df['y'] == 1\n\nfig, axes = plt.subplots(ncols=2, nrows=len(METAFEATURES), figsize=(20, 50), dpi=100)\n\nfor i, feature in enumerate(METAFEATURES):\n    sns.countplot(df.loc[~TOXIC_COMMENTS][feature], label='Non Toxic', ax=axes[i][0], color='green')\n    sns.distplot(df.loc[TOXIC_COMMENTS][feature], label='Toxic', ax=axes[i][0], color='red')\n\n    sns.distplot(df[feature], label='Train', ax=axes[i][1])\n    \n    for j in range(2):\n        axes[i][j].set_xlabel('')\n        axes[i][j].tick_params(axis='x', labelsize=12)\n        axes[i][j].tick_params(axis='y', labelsize=12)\n        axes[i][j].legend()\n    \n    axes[i][0].set_title(f'{feature} Target Distribution in Training Set', fontsize=13)\n\nplt.show()","7be48fb4":"df.describe()","961aebc1":"# Remove stopwords & convert to lower case\ndf['comment_text'] = df['comment_text'].apply(lambda x: ' '.join([w for w in str(x).lower().split() if w not in STOPWORDS]))\n\n# Remove Punctuations\ndf[\"comment_text\"] = df['comment_text'].str.replace('[^\\w\\s]','')\ndf.tail()","00bbbdc7":"X = df.drop(['y'], axis=1)\ny = df['y']","2fe77049":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","be26de8b":"X_train.head()","d30eb255":"X_train = X_train.comment_text.values\nX_test = X_test.comment_text.values","81a85f05":"y_train.head()","2b9fe203":"OOV_TOKEN = '<OOV>'\nVOCAB_SIZE = 10000\nMAX_LEN = 100\nEMBEDDING_DIM = 100","96772126":"tokenizer = Tokenizer(\n    num_words=VOCAB_SIZE,\n    oov_token=OOV_TOKEN\n)\ntokenizer.fit_on_texts(X_train)","0609565b":"len(tokenizer.word_index)","3056da58":"train_seq = tokenizer.texts_to_sequences(X_train)\ntrain_padded = pad_sequences(\n    train_seq, maxlen=MAX_LEN, dtype='int32', padding='post',\n    truncating='post'\n)\n\ntest_seq = tokenizer.texts_to_sequences(X_test)\ntest_padded = pad_sequences(\n    test_seq, maxlen=MAX_LEN, dtype='int32', padding='post',\n    truncating='post'\n)","16e00f3f":"test_padded.shape","1bba85c3":"model = tf.keras.Sequential([\n  Embedding(VOCAB_SIZE, EMBEDDING_DIM, name=\"embedding\"),\n    LSTM(64),\n    Dropout(0.2),\n  Dense(16, activation='relu'),\n    Dropout(0.2),\n  Dense(1,activation='sigmoid')\n])","889a81a9":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])","10474a80":"model.summary()","ca27e213":"es = EarlyStopping(patience=3, \n                   monitor='loss', \n                   restore_best_weights=True, \n                   mode='min', \n                   verbose=1)","52a8e0bf":"hist = model.fit(\n    train_padded,\n    y = y_train,\n    validation_data=(test_padded, y_test),\n    epochs=15,\n    callbacks=es\n)","11ccd279":"plt.style.use('fivethirtyeight')\n\n# visualize the models accuracy\nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc = 'upper left')\nplt.show()  ","3223d3ec":"target.head()","b3d014cc":"df_target = target","9b005fd0":"# Remove stopwords & convert to lower case\ndf_target['text'] = df_target['text'].apply(lambda x: ' '.join([w for w in str(x).lower().split() if w not in STOPWORDS]))\n\n# Remove Punctuations\ndf_target[\"text\"] = df_target['text'].str.replace('[^\\w\\s]','')\ndf_target.head()","4228e3a3":"target_seq = tokenizer.texts_to_sequences(df_target.text.values)\ntarget_padded = pad_sequences(\n    target_seq, maxlen=MAX_LEN, dtype='int32', padding='post',\n    truncating='post'\n)","d781a8ee":"result = model.predict(target_padded)","b97addf4":"sample","48ba915c":"target['score'] = result","e5f9f199":"target[['comment_id','score']].to_csv('.\/submission.csv', index=False)","7e78957f":"# <a id=\"text-preprocessing\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:Purple; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Text Preprocessing<\/center><\/h2>","9e35b940":"1. [Imports](#imports)  \n2. [Load Datasets](#load-datasets)  \n3. [Exploratory Data Analysis](#eda)  \n4. [Handling Imbalanced Dataset](#handle-imbalanced-dataset) \n5. [Feature Engineering](#feature-engineering)   \n6. [Text Preprocessing](#text-preprocessing)\n7. [Model Definition](#model-definition)\n8. [Model Training](#model-training)\n9. [Prediction](#prediction)   \n10. [References](#references) ","276d28cf":"#### Imbalanced dataset issue sorted","9f1fce09":"# <a id=\"model-training\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:Purple; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Model Training<\/center><\/h2>","ea48352c":"### 1. Remove stopwords, Punctuations","f48fb2f0":"# <a id=\"load-datasets\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:Purple; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Load Datasets<\/center><\/h2>","465e913d":"# <a id=\"prediction\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:Purple; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Prediction<\/center><\/h2>","d9017749":"### 3. Convert text to padded sequences","b99c8bc9":"<h1><center>Jigsaw Toxic Comments Classification<\/center><\/h1>\n<h2><center>Simple EDA, Cleaning with Tensorflow Embedding Baseline!<\/center><\/h2>","05950b43":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:Purple; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Contents<\/center><\/h2>","e2a8c5f2":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:magents; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>If you find this notebook useful, Do Upvote and Feel free to share your feedback in comments<\/center><\/h2>","1b9e3e10":"#### Lets convert words to numbers","2eef7b5f":"# <a id=\"references\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:Purple; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>References<\/center><\/h2>","78d99a9e":"1. EDA - [NLP with Disaster Tweets - EDA, Cleaning and BERT](https:\/\/www.kaggle.com\/gunesevitan\/nlp-with-disaster-tweets-eda-cleaning-and-bert) \n2. Notebook formating - [[V7]Shopee InDepth EDA:One stop for all your needs\n](https:\/\/www.kaggle.com\/ishandutta\/v7-shopee-indepth-eda-one-stop-for-all-your-needs)  \n3. [Simple LSTM With Word2Vec](https:\/\/www.kaggle.com\/khkuggle\/simple-lstm-with-word2vec)  \n\nThank you :)","aca8ced8":"# <a id=\"handle-imbalanced-dataset\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:Purple; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Handling Imbalanced Dataset<\/center><\/h2>","c258baf7":"#### We can clearly see we have imbalanced dataset. Let's fix it","d626c5e2":"# <a id=\"imports\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:Purple; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Imports<\/center><\/h2>","80e38d95":"### Prepare test data","ae1dc836":"### Predict","9456c267":"![Toxic Comments](https:\/\/miro.medium.com\/max\/1400\/1*8BdmU3wYefT7vDZRWWOL1Q.png)","8b182715":"# <a id=\"model-definition\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:Purple; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Model Definition<\/center><\/h2>","ed1d3e1c":"### 2. Tokenization","ed53c402":"# <a id=\"eda\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:Purple; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Exploratory Data Analysis<\/center><\/h2>","b92945d7":"# <a id=\"feature-engineering\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:Purple; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Feature Engineering<\/center><\/h2>"}}