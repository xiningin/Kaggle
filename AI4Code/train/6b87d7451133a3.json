{"cell_type":{"1e3a0690":"code","3cd53dee":"code","868cf173":"code","761746c9":"code","6a1606f0":"code","87c329df":"code","dd4f757c":"markdown","22156e07":"markdown","0919dab1":"markdown","b7af78f6":"markdown","2c749128":"markdown"},"source":{"1e3a0690":"# Import necessary packages\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix","3cd53dee":"df = pd.read_csv('..\/input\/pulsar_stars.csv')\ndf.info()","868cf173":"plt.figure(figsize=(10, 7))\nsns.heatmap(df.corr(), annot=True, cmap=sns.color_palette('coolwarm', 15))\nplt.show","761746c9":"# Choos data set. Exclude the target set from the data\nX = df.drop('target_class', axis=1)\n# Choose target set\ny = df['target_class']\n\n# Split data into random training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y)\n\n# Create an object of the standard scaler from sklearn\nscaler = StandardScaler()\n# Fit the standard scalar to the training data\nscaler.fit(X_train)\n\n# Use the transform function to normalize the data sets\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","6a1606f0":"# Create the MLP model with 2 layers, and as many neurons as there are features in the data set\nmlp = MLPClassifier(hidden_layer_sizes=(8, 8))\n\n# Fit the training data to the MLP model\nmlp.fit(X_train, y_train)","87c329df":"# Make predictions on the data set using the MLP model\nprediction = mlp.predict(X_test)\n\n# Print results and analytics of the prediction\nplt.figure(figsize=(10,7))\nsns.heatmap(confusion_matrix(y_test, prediction), annot=True, fmt='.1f', cmap=sns.color_palette(\"Blues\", 25))\nplt.show()\n\nprint(confusion_matrix(y_test, prediction))\nprint(classification_report(y_test, prediction))","dd4f757c":"Fortunately, the data set is completly filled with numeric values, and no null entries. Our analysis can begin without data cleaning. First, plot a heatmap of the correlation between each of the features in the data frame. This tells us what features can be dropped from the predictive analysis because they aren't strongly correlated with the target feature.","22156e07":"This data comes from a study of pulsar stars: 'The High Time Resolution Universe Pulsar Survey - I. System Configuration and Initial Discoveries'. This particular set gives the physical characteristics of stars and states whether the star is a pulsar star or not.\n\nWe begin by loading the data into a pandas data frame. Then print the info of the data frame to see what kind of cleaning and organizing needs to be done to the data.","0919dab1":"With the training data fit to the model, we can predict the results.","b7af78f6":"We're interested in the row labeled 'target_class'. Each of the values shown gives the relative correlation between the given feature and the 'target_class' feature. The values range from -1.0 (negatively correlated) and 1.0 (positively correlated). We can choose our data set and target set from this. \nThe threshold for determining which features to drop is somewhat arbitrary. None of the features in this set are entirely uncorrelated with the 'target_class' feature (correlation = 0.0), so it's not necessary to drop any of them. The results of the predictive analysis are not significantly changed by dropping any of the features. Dropping the least correlated features results in roughly 0.98 precision, while not dropping any features still results in a 0.98 precision.\nHowever, this doesn't consider the physics of determining a non-pulsar star from a pulsar star. Some of the features may be more *physically* relevant than others, but that cannot be determined by playing with the model. I digress.\nContinuing with the predictive analysis, we can now choose the data set and target set. \n","2c749128":"Now the data is ready to be tested with a model. For the first example we use a multi-layer perceptron algorithm. In particular, we use the MLPClassifier class."}}