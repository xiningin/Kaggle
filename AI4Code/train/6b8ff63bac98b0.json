{"cell_type":{"d1031811":"code","45b2114c":"code","81a90dc7":"code","4aab440e":"code","9e6675f7":"code","49d57153":"code","1937771c":"code","74b76613":"code","bc438240":"code","0fd6dbcd":"code","f1e5a1f7":"code","40266e5f":"code","8623c6ef":"code","c0829f3b":"code","ba7d62ab":"code","82e17d2c":"code","61a6c4e6":"code","218153a6":"code","299ecd72":"code","cb3d5a93":"code","7c1fb4f5":"code","77ff369d":"code","3e523e84":"code","e4f078b9":"code","d84b1c0c":"code","a25ce922":"code","2c4e2478":"code","6f7ec88b":"code","c9ac943a":"code","c21026aa":"code","a321e34e":"code","eab35d49":"code","6e2f8c74":"code","c8601b2c":"code","78f08d96":"code","0ed16487":"code","55cdfd8d":"code","73de47f9":"code","c6034236":"code","77437344":"code","21eda905":"code","a9a3cca2":"code","67dad91e":"code","162fdc33":"code","a4e366c8":"code","bf26bd9b":"code","847fd7dd":"code","ae6e5422":"code","add53bb7":"code","5da9f63c":"code","96fb100d":"code","916e6131":"code","f9458125":"code","a0546971":"code","cfaff526":"code","8fdf016a":"code","667ad8c5":"code","bef46772":"code","2af4cc95":"code","13f8d422":"code","31df8215":"code","812bed3f":"code","4f0aa0c8":"code","8328625d":"code","93db34f6":"code","87474ff5":"code","a3a730cc":"code","7edfad30":"code","93b3907a":"code","f636d7bd":"code","5d0ad11d":"code","850fb00b":"code","a494212a":"markdown","02630ab4":"markdown","078a6a2c":"markdown","e1a540bd":"markdown","8b767cbb":"markdown","5226db08":"markdown","b1ff1bf5":"markdown","e688142f":"markdown","2e996fa2":"markdown","fac45399":"markdown","6b6bf0f0":"markdown","1eb35602":"markdown","3540ba1d":"markdown","b284fbf5":"markdown","fa67a507":"markdown","458b1f36":"markdown","1154774e":"markdown","79c548da":"markdown","9a79392b":"markdown","ac88e76e":"markdown","cb5da88d":"markdown","7de2845f":"markdown","1843ab02":"markdown","d1212350":"markdown","22ea6aa6":"markdown","2046e365":"markdown","2e60fbce":"markdown","79e8fab2":"markdown","af6cbddd":"markdown","e6b568c8":"markdown","1079ca3d":"markdown","4f8e32a4":"markdown","456ae7b9":"markdown","5820277d":"markdown","e7c583ad":"markdown","661732b5":"markdown","05492ca9":"markdown","cc8a4bd1":"markdown","8bbe87fc":"markdown","78214099":"markdown","dd734ad8":"markdown","a15f7472":"markdown","de6276f9":"markdown","85cc492d":"markdown","ac47005d":"markdown","199b5832":"markdown","76588404":"markdown","9cef7f67":"markdown","55605f29":"markdown","9dfae079":"markdown","5e6be9c2":"markdown","62ef2297":"markdown","8ad29319":"markdown","b86629da":"markdown","8c7c66f2":"markdown","2d2cc086":"markdown","dc2c4028":"markdown","7e68988b":"markdown","24134fe8":"markdown","f685f4db":"markdown","bc646481":"markdown","510534c4":"markdown","dd3e30d8":"markdown","00137fad":"markdown","b8e4837b":"markdown","24b1a45f":"markdown","07a1ae0b":"markdown","6229efb1":"markdown","6b3791fc":"markdown","bbdcb160":"markdown","b43bca9c":"markdown","034e43b8":"markdown","fc5d3174":"markdown","2ce27fac":"markdown","1613ac81":"markdown","1df7e4cb":"markdown","85dfbc16":"markdown","2390af9a":"markdown","019de311":"markdown","1eea93f1":"markdown"},"source":{"d1031811":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","45b2114c":"%matplotlib inline    \n# To make data visualisations display in Jupyter Notebooks \n\nimport numpy as np    # linear algebra \nimport pandas as pd    # Data processing, Input & Output load    \nimport matplotlib.pyplot as plt    # Visualization & plotting\nimport datetime\n\nimport xgboost as xgb\nfrom sklearn.ensemble import GradientBoostingClassifier    # GBM algorithm\nfrom sklearn.ensemble import RandomForestClassifier    # Random Forest Algorithm\nfrom sklearn.linear_model import LogisticRegression    # Logistic Regression Algorithm\n\nfrom xgboost.sklearn import XGBClassifier    # Extreme Gradient Boosting\nfrom xgboost import plot_importance    # Plotting Important Variables\n\nimport joblib  #Joblib is a set of tools to provide lightweight pipelining in Python (Avoid computing twice the same thing)\nfrom sklearn.model_selection import train_test_split as tts\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\n                                    # GridSearchCV - Implements a \u201cfit\u201d and a \u201cscore\u201d method\n                                    # train_test_split - Split arrays or matrices into random train and test subsets\n                                    # cross_val_score - Evaluate a score by cross-validation     \n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import f1_score, precision_score, accuracy_score, roc_auc_score, recall_score, roc_curve\nfrom sklearn.metrics import make_scorer, confusion_matrix, classification_report   # Differnt metrics to evaluate the model\nimport pandas_profiling as pp    # simple and fast exploratory data analysis of a Pandas Dataframe\n\nimport warnings    # To avoid warning messages in the code run\nwarnings.filterwarnings('ignore')","81a90dc7":"def plot_roc_auc_curve(y_train_actual, train_pred_prob, y_test_actual, test_pred_prob, *args):\n    '''\n    Generate train and test roc curve\n    '''\n      \n    AUC_Train = roc_auc_score(y_train_actual, train_pred_prob)\n    AUC_Test = roc_auc_score(y_test_actual, test_pred_prob)\n    \n    if len(args) == 0:\n        print(\"Train AUC = \", AUC_Train)\n        print(\"Test AUC = \", AUC_Test)\n        fpr_train, tpr_train, thresholds = roc_curve(y_train_actual, train_pred_prob)\n        fpr_test, tpr_test, thresholds = roc_curve(y_test_actual, test_pred_prob)\n        roc_plot(fpr_train, tpr_train, fpr_test, tpr_test)\n        \n    else:\n        AUC_Valid = roc_auc_score(args[0], args[1])\n        print(\"Train AUC = \", AUC_Train)\n        print(\"Test AUC = \", AUC_Test)\n        print(\"Validation AUC = \", AUC_Valid)\n        fpr_train, tpr_train, thresholds = roc_curve(y_train_actual, train_pred_prob)\n        fpr_test, tpr_test, thresholds = roc_curve(y_test_actual, test_pred_prob)\n        fpr_val, tpr_val, thresholds = roc_curve(args[0], args[1])\n        roc_plot(fpr_train, tpr_train, fpr_test, tpr_test, fpr_val, tpr_val)        ","4aab440e":"def roc_plot(fpr_train, tpr_train, fpr_test, tpr_test, *args):\n    '''\n    Generate roc plot\n    '''\n    \n    fig = plt.plot(fpr_train, tpr_train, label = 'Train')\n    fig = plt.plot(fpr_test, tpr_test, label = 'Test')\n    \n    if len(args) == 0:\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.0])\n        plt.title(\"ROC curve using \")\n        plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n        plt.ylabel(\"True Positive Rate (Sensitivity)\")\n        plt.legend(loc = 'lower right')\n        plt.grid(True)\n        plt.show()\n    \n    else:\n        fig = plt.plot(args[0], args[1], label = 'Validation')\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.0])\n        plt.title(\"ROC curve using \")\n        plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n        plt.ylabel(\"True Positive Rate (Sensitivity)\")\n        plt.legend(loc = 'lower right')\n        plt.grid(True)\n        plt.show()","9e6675f7":"data = pd.read_csv('..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv')\n\n# Copying the original data into a new python variable object data_new\ndata_new = data.copy()\n\nprint(\"Data Shape - \", data_new.shape)\n\ndata_new.head()","49d57153":"data_new.describe()","1937771c":"data_new.describe(include = np.object)","74b76613":"data_new.info()","bc438240":"pp.ProfileReport(data_new)","0fd6dbcd":"Target = 'stroke'\npd.crosstab(data_new[Target], columns = 'Normalized', normalize = True)","f1e5a1f7":"data_new.isnull().sum()","40266e5f":"print('Unique values gender count: ', data_new['gender'].nunique()) \nprint('gender values: ', data_new['gender'].unique())\npd.value_counts(data_new['gender'])","8623c6ef":"print('Unique values hypertension count: ', data_new['hypertension'].nunique()) \nprint('hypertension values: ', data_new['hypertension'].unique())\npd.value_counts(data_new['hypertension'])","c0829f3b":"print('Unique values heart_disease count: ', data_new['heart_disease'].nunique()) \nprint('hyper_disease values: ', data_new['heart_disease'].unique())\npd.value_counts(data_new['heart_disease'])","ba7d62ab":"print('Unique values ever_married count: ', data_new['ever_married'].nunique()) \nprint('ever_married values: ', data_new['ever_married'].unique())\npd.value_counts(data_new['ever_married'])","82e17d2c":"print('Unique values work_type count: ', data_new['work_type'].nunique())\nprint('work_type values: ', data_new['work_type'].unique())\npd.value_counts(data_new['work_type'])","61a6c4e6":"print('Unique values Residence_type count: ', data_new['Residence_type'].nunique())\nprint('Residence_type values: ', data_new['Residence_type'].unique())\npd.value_counts(data_new['Residence_type'])","218153a6":"print('Unique values smoking_status count: ', data_new['smoking_status'].nunique())\nprint('smoking_status values: ', data_new['smoking_status'].unique())\npd.value_counts(data_new['smoking_status'])","299ecd72":"print('Unique values stroke count: ', data_new['stroke'].nunique())\nprint('stroke values: ', data_new['stroke'].unique())\npd.value_counts(data_new['stroke'])","cb3d5a93":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['gender']), \n        labels = ['Female', 'Male','Other'],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage of Gender', fontsize = 18, fontweight = 'bold')\nplt.show()","7c1fb4f5":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['hypertension']), \n        labels = [0,1],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage of hypertension', fontsize = 18, fontweight = 'bold')\nplt.show()","77ff369d":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['heart_disease']), \n        labels = [0,1],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage of heart disease', fontsize = 18, fontweight = 'bold')\nplt.show()","3e523e84":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['ever_married']), \n        labels = ['Yes', 'No'],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage of people married', fontsize = 18, fontweight = 'bold')\nplt.show()","e4f078b9":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['work_type']), \n        labels = ['Private', 'Self-employed', 'children', 'Govt_job', 'Never_worked'],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage of people working in different sectors', fontsize = 18, fontweight = 'bold')\nplt.show()","d84b1c0c":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['Residence_type']), \n        labels = ['Urban', 'Rural'],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage of people staying in different areas', fontsize = 18, fontweight = 'bold')\nplt.show()","a25ce922":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['smoking_status']), \n        labels = ['never smoked', 'Unknown', 'formerly smoked', 'smokes'],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage of people of different smoking categories', fontsize = 18, fontweight = 'bold')\nplt.show()","2c4e2478":"plt.figure(figsize = (10, 8))\nplt.pie(pd.value_counts(data_new['stroke']), \n        labels = [0,1],\n        autopct = '%.2f%%',\n        textprops = {'size' : 'x-large',\n                     'fontweight' : 'bold', \n                     'rotation' : '30',\n                     'color' : 'w'})\n\nplt.legend()\nplt.title('Percentage of stroke', fontsize = 18, fontweight = 'bold')\nplt.show()","6f7ec88b":"num_cols = data_new.select_dtypes(include = [np.number]).columns.tolist()\nobj_cols = data_new.select_dtypes(exclude = [np.number]).columns.tolist()","c9ac943a":"num_cols = data_new.drop(['id', 'stroke'], axis = 1).select_dtypes(include = [np.number]).columns.tolist()","c21026aa":"print('Numeric Columns \\n', num_cols)\nprint('Non-Numeric Columns \\n', obj_cols)","a321e34e":"# We shall exclude the columns 'hypertension', 'heart_disease'\n\nnum_cols_viz = ['age', 'avg_glucose_level', 'bmi']\n\nfig, axes = plt.subplots(1, 1, sharex = False, sharey = False, figsize = (15, 15))\ndata_new.loc[:, [Target]+num_cols_viz].boxplot(by = Target, ax = axes, return_type = 'axes');","eab35d49":"obj_cols_viz = obj_cols + ['hypertension', 'heart_disease']\nfig, axes = plt.subplots(len(obj_cols_viz), sharex = False, sharey = False, figsize = (15, 50))\n\nfor i in range(0, len(obj_cols_viz)):\n    pd.crosstab(data_new[obj_cols_viz[i]], data_new[Target]).plot(kind = 'bar', stacked = True, grid = False, ax = axes[i])","6e2f8c74":"print(\"Missing Data Percentage: \", (201\/5112)*100, \"%\")","c8601b2c":"data_new = data_new.dropna(axis = 0)\ndata_new.head()","78f08d96":"data_new = data_new.drop(\"id\", axis = 1)\ndata_new.head()","0ed16487":"encoding_list = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n\nlabel_encoding_list = []\none_hot_encoding_list = []\n\nfor i in range (0, len(encoding_list)):\n    if(len(data_new[f'{encoding_list[i]}'].unique()) == 2):\n        label_encoding_list.append(encoding_list[i])\n    else:\n        one_hot_encoding_list.append(encoding_list[i])\n        \n    print(f'Unique Values for {encoding_list[i]}', data_new[f'{encoding_list[i]}'].unique())","55cdfd8d":"# Numerical columns data\ndata_new_num = data_new[num_cols + ['stroke']]\n\n# Categorical columns data\ndata_new_cat = data_new[obj_cols]\n\n# Creating dummies\ndata_new_cat_dummies = pd.get_dummies(data_new_cat)\nprint(data_new_cat_dummies.shape)\ndata_new_cat_dummies.head()","73de47f9":"data_new_final = pd.concat([data_new_num, data_new_cat_dummies], axis = 1)\nprint(data_new_final.shape)\ndata_new_final.head()","c6034236":"data_new_final.isnull().sum(axis = 0)","77437344":"X = data_new_final.drop(['stroke'], axis = 1)\ny = data_new_final['stroke']","21eda905":"X_train, X_test, y_train, y_test = tts(X, y, test_size = 0.3, random_state = 100) \n\nprint('Train Shape: ', X_train.shape)\nprint('Test Shape: ', X_test.shape)","a9a3cca2":"model_parameters = {'n_estimators': [10, 50, 100, 200, 500, 750, 1000], 'max_depth': [3, 5, 10],\n                    'min_samples_leaf': [np.random.randint(1,10)], 'max_features': [None, 'sqrt', 'log2']}","67dad91e":"model = GradientBoostingClassifier(random_state = 10)\ngscv_GBM = GridSearchCV(estimator = model, \n                        param_grid = model_parameters, \n                        cv = 5, \n                        verbose = 1, \n                        n_jobs = -1,\n                        scoring = 'roc_auc')\n\ngscv_GBM.fit(X_train, y_train)","162fdc33":"print('The best parameters are -', gscv_GBM.best_params_)","a4e366c8":"final_mod_GBM = GradientBoostingClassifier(**gscv_GBM.best_params_)\nfinal_mod_GBM.fit(X_train, y_train)","bf26bd9b":"train_pred = final_mod_GBM.predict(X_train)\ntest_pred = final_mod_GBM.predict(X_test)","847fd7dd":"print('Classification report for train data is : \\n',\n      classification_report(y_train, train_pred))\nprint('Classification report for test data is : \\n',\n      classification_report(y_test, test_pred))","ae6e5422":"final_mod_GBM.variables = X_train.columns","add53bb7":"joblib.dump(final_mod_GBM, 'best_model_GBM.joblib')","5da9f63c":"plt.subplots(figsize = (10, 5))\ntrain_prob = final_mod_GBM.predict_proba(X_train)[:, 1]\ntest_prob = final_mod_GBM.predict_proba(X_test)[:, 1]\n\nplot_roc_auc_curve(y_train, train_prob, y_test, test_prob)","96fb100d":"y_pred = final_mod_GBM.predict(X_test)\npredictions = [round(value) for value in y_pred]","916e6131":"accuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","f9458125":"log_reg = LogisticRegression(solver = 'liblinear')\nlog_reg.fit(X_train, y_train)","a0546971":"train_pred = log_reg.predict(X_train)\ntest_pred = log_reg.predict(X_test)","cfaff526":"print('Classification report for train data is : \\n',\n      classification_report(y_train, train_pred))\nprint('Classification report for test data is : \\n',\n      classification_report(y_test, test_pred))","8fdf016a":"log_reg.variables = X_train.columns","667ad8c5":"joblib.dump(log_reg, 'best_model_log_reg.joblib')","bef46772":"plt.subplots(figsize = (10, 5))\ntrain_prob = log_reg.predict_proba(X_train)[:, 1]\ntest_prob = log_reg.predict_proba(X_test)[:, 1]\n\nplot_roc_auc_curve(y_train, train_prob, y_test, test_prob)","2af4cc95":"y_pred = log_reg.predict(X_test)\npredictions = [round(value) for value in y_pred]","13f8d422":"accuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","31df8215":"model_parameters = {'n_estimators': [10, 50, 100, 200, 500, 750, 1000], 'max_depth': [3, 5, 10],\n                    'min_samples_leaf': [np.random.randint(1,10)], 'max_features': [None, 'sqrt', 'log2']}","812bed3f":"model = RandomForestClassifier(random_state = 10)\ngscv_randfor = GridSearchCV(estimator = model, \n                        param_grid = model_parameters, \n                        cv = 5, \n                        verbose = 1, \n                        n_jobs = -1,\n                        scoring = 'roc_auc')\n\ngscv_randfor.fit(X_train, y_train)","4f0aa0c8":"print('The best parameters are -', gscv_randfor.best_params_)","8328625d":"final_mod_randfor = GradientBoostingClassifier(**gscv_randfor.best_params_)\nfinal_mod_randfor.fit(X_train, y_train)","93db34f6":"train_pred = final_mod_randfor.predict(X_train)\ntest_pred = final_mod_randfor.predict(X_test)","87474ff5":"print('Classification report for train data is : \\n',\n      classification_report(y_train, train_pred))\nprint('Classification report for test data is : \\n',\n      classification_report(y_test, test_pred))","a3a730cc":"final_mod_randfor.variables = X_train.columns","7edfad30":"joblib.dump(final_mod_randfor, 'best_model_randfor.joblib')","93b3907a":"plt.subplots(figsize = (10, 5))\ntrain_prob = log_reg.predict_proba(X_train)[:, 1]\ntest_prob = log_reg.predict_proba(X_test)[:, 1]\n\nplot_roc_auc_curve(y_train, train_prob, y_test, test_prob)","f636d7bd":"y_pred = log_reg.predict(X_test)\npredictions = [round(value) for value in y_pred]","5d0ad11d":"accuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","850fb00b":"print('The best model is Logistic Regression model')","a494212a":"### a) Define model parameters to be tuned","02630ab4":"## 6.1) Univariate Analysis","078a6a2c":"## 8.1) Model 1 - GBM (Gradient Boosting)","e1a540bd":"### f) Residence_type","8b767cbb":"## 3. Analysis of each category of the categorical variables of obj_cols dataframe w.r.t Target variable - stroke.","5226db08":"### c) heart_disease","b1ff1bf5":"## 7.2) Creating Model Dataset","e688142f":"### Following are the insights gathered from the stacked bar charts\n\n* <b>Females are more prone to a stroke attack as compared to males<\/b>.\n* <b>Married persons are more prone to a stroke attack as compared to unmarried persons<\/b>.\n* <b>Private job persons are more prone prone to a stroke attack as compared to other work types<\/b>\n* <b>People living in Urban areas are more prone to a stroke attack as compared to persons living in Rural areas<\/b>.\n* <b>A person who has never smoked is more prone to a stroke attack as compared to person who is smoking or had earlier smoked<\/b>.\n* <b>A person who doesn't have hypertension or a heart disease is more prone to a stroke attack as compared to a person who suffers from any of these diseases<\/b>.\n* <b>So, overall we can say that a person who is a Female and is married and is a Private sector employee and stays in an Urban area and is a non-smoker and is free from any kind of hypertension or a heart disease is prone to a stroke attack<\/b>.","2e996fa2":"### c) Saving the variables used in the model","fac45399":"* We shall first do the <b>Univariate Analysis<\/b> by analysing the data w.r.t our <b>Target Variable - stroke<\/b>.","6b6bf0f0":"* Let's first plot the boxplot of each numerical variable w.r.t our target variable.","1eb35602":"### a) Finding unique values of each object variable of data_new dataframe","3540ba1d":"* The entire dataset contains <b>5110<\/b> rows and <b>12<\/b> columns.","b284fbf5":"### b) Creating Dummy Variables","fa67a507":"## 6.3) Missing Value Treatment","458b1f36":"## 1. Importing Necessary Libraries","1154774e":"### b) Performing Train, Test & Split","79c548da":"## 9) Displaying Best Model","9a79392b":"### c) Concatenating columns - numeric and dummies","ac88e76e":"## b) Analysis of percentage unique values  for categorical variables of the data_new dataset.","cb5da88d":"## 8.3) Model 3 - Random Forest Classifier","7de2845f":"### d) ever_married","1843ab02":"### j) Evaluating prediction accuracy for test data","d1212350":"2. Now, let's get the summary for categorical data ","22ea6aa6":"### e) Displaying model prediction and classification report","2046e365":"### Following are the insights gathered from the boxplots\n\n* <b>The \"age\" boxplot shows that greater the age, higher the chance of a person experiencing a stroke<\/b>.\n* <b>The \"avg_glucose_level\" boxplot shows that greater the average glucose level, higher the chance of a person experiencing a stroke<\/b>.\n* <b>The \"bmi\" boxplot shows that greater the bmi, higher the chance of a person experiencing a stroke<\/b>.","2e60fbce":"### a) Separating the target variable - stroke from the data_new_final dataframe","79e8fab2":"### h) stroke","af6cbddd":"## a) Analysis of unique values & their counts for categorical variables of the data_new dataset.","e6b568c8":"## 7.1) Dropping Least Important Variable","1079ca3d":"## 4. Let's Understand Our Data","4f8e32a4":"* Let's drop the columns which we won't be using.","456ae7b9":"### j) Evaluating prediction accuracy for test data","5820277d":"### d) Refitting the model with best parameters","e7c583ad":"* From the Data Profiling report, we got to know that only variable <b>bmi<\/b> has <b>201<\/b> missing values.\n* Let's find out how much percentage of data is missing.","661732b5":"## 7. Feature Engineering","05492ca9":"### h) Model Evaluation","cc8a4bd1":"### g) Evaluating prediction accuracy for test data","8bbe87fc":"## 5. Data Profiling Report","78214099":"* As variable <b>id<\/b> has no correlation with any other variables, we can drop this variable.","dd734ad8":"* We have approximately <b>95%<\/b> of <b>0's<\/b> and <b>5%<\/b> of <b>1's<\/b> in our data.","a15f7472":"### b) Using GridSearch Cross Validation to find out the best parameters","de6276f9":"### i) Making predictions for test data","85cc492d":"### g) Saving the best model","ac47005d":"## 7.3) Splitting the newly created model data into train and test data","199b5832":"## 6. EDA(Exploratory Data Analysis)","76588404":"### d) Null value check in the final dataset before model run","9cef7f67":"* Let's check if there are any null variables in the <b>data_new<\/b> dataset.","55605f29":"* As there's only 3.9% of the missing data, we can drop this missing data.","9dfae079":"## 8.2) Model 2 - Logistic Regression","5e6be9c2":"### c) Displaying the best parameters","62ef2297":"### f) Making predictions for test data","8ad29319":"### g) smoking_status","b86629da":"### a) gender","8c7c66f2":"### d) Refitting the model with best parameters","2d2cc086":"### e) Model Evaluation","dc2c4028":"## 6.2) Bivariate Analysis","7e68988b":"## 8) Applying Different Models On Train & Test Data","24134fe8":"1. First, let's get the summary of the numerical data","f685f4db":"* We would categorize the existing variables of our existing dataframe into <b>numerical<\/b> and <b>categorical<\/b> variables.","bc646481":"### b) Using GridSearch Cross Validation to find out the best parameters","510534c4":"### i) Making predictions for test data","dd3e30d8":"## 2. Defining Functions For Plotting ROC_AUC Curve & ROC_Plot ","00137fad":"### a) Applying logistic regression","b8e4837b":"## 2. Analysis of each category of the numerical variables of num_cols dataframe w.r.t Target variable - stroke.","24b1a45f":"### b) hypertension","07a1ae0b":"### g) Saving the best model","6229efb1":"### a) Define model parameters to be tuned","6b3791fc":"### Following are the insights gathered from the data_new dataframe\n\n1. <b>Maximum entries<\/b> are of <b>females<\/b> as compared to <b>males<\/b>.\n2. <b>66.62%<\/b> of the total population is <b>married<\/b>.\n3. <b>34.38%<\/b> of the total population is <b>unmarried<\/b>.\n4. <b>90.25%<\/b> of the total population is free from hypertension.\n5. <b>9.75%<\/b> of the total population suffers from hypertension.\n6. <b>94.60%<\/b> of the total population doesn't have any heart disease.\n7. <b>5.40%<\/b> of the total population has some sort of a heart disease.\n8. <b>57.24%<\/b> people are <b>Private<\/b> sector employees.\n9. <b>16.03%<\/b> people are <b>Self-employed<\/b>.\n10. <b>13.44%<\/b> of the total population comprises of <b>children<\/b>.\n11. <b>12.86%<\/b> people are <b>Government<\/b> job employees.\n12. <b>0.43%<\/b> of the population have <b>never worked<\/b> at all.\n13. People staying in <b>Urban<\/b> and <b>Rural<\/b> areas are <b>approximately same<\/b>.\n14. <b>37.03%<\/b> people have <b>never smoked<\/b> in their life.\n15. The <b>smoking status<\/b> of <b>30.22%<\/b> of the total population is <b>unknown<\/b>.\n16. <b>17.32%<\/b> people had <b>smoked earlier<\/b> in their life but then quit it afterwards.\n17. <b>15.44%<\/b> people are <b>currently smoking<\/b> atleast one cigarette a day on an average.\n18. <b>4.87%<\/b> of the total population has experienced a stroke.\n19. <b>95.13%<\/b> of the total population has never experienced a stroke.","bbdcb160":"### d) Saving the best model","b43bca9c":"## 1. Data Categorization","034e43b8":"### e) Displaying model prediction and classification report","fc5d3174":"### b) Displaying model prediction and classification report","2ce27fac":"### f) Saving the variables used in the model","1613ac81":"### f) Saving the variables used in the model","1df7e4cb":"### c) Displaying the best parameters","85dfbc16":"### e) work_type","2390af9a":"## 3. Importing Dataset","019de311":"### h) Model Evaluation","1eea93f1":"### a) bmi"}}