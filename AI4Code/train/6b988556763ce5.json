{"cell_type":{"5618c51c":"code","9084d066":"code","4cb4cde7":"code","d15bd588":"code","31f70dda":"code","4b816345":"code","a2243512":"code","854975e3":"code","9074d753":"code","60f8fc5f":"code","657633db":"code","9d611b5f":"code","677ac247":"code","aaabda74":"code","be2fb94b":"markdown","b2fc193b":"markdown","f07c07de":"markdown","2b038ff3":"markdown"},"source":{"5618c51c":"import pandas as pd\nimport numpy as np\nfrom sklearn.feature_selection import SelectKBest,chi2","9084d066":"df = pd.read_csv('..\/input\/mobile-price-classification\/train.csv')\ndf.head()","4cb4cde7":"X = df.iloc[:,:-1]\ny = df.iloc[:,-1]","d15bd588":"bestfeature = SelectKBest(score_func=chi2, k=10)\nbf = bestfeature.fit(X,y)","31f70dda":"score = pd.DataFrame(bf.scores_)\ncolnames = pd.DataFrame(X.columns)\nbf_result = pd.concat([colnames, score], axis='columns')\nbf_result.columns = ['Feature','Score']\nbf_result.nlargest(10,'Score')","4b816345":"from sklearn.ensemble import RandomForestClassifier","a2243512":"rf = RandomForestClassifier()","854975e3":"rf.fit(X,y)","9074d753":"rf.feature_importances_","60f8fc5f":"rf_feature = pd.Series(rf.feature_importances_, index=X.columns)\nrf_feature.nlargest(10).plot(kind='barh')","657633db":"import seaborn as sns\nimport matplotlib.pyplot as plt","9d611b5f":"cor_matrix = df.corr()","677ac247":"top_corr_feature = cor_matrix.index","aaabda74":"plt.figure(figsize=(20,20))\ng = sns.heatmap(df[top_corr_feature].corr(), annot=True, cmap='RdYlGn')","be2fb94b":"## 1.Univariate Selection\n#### Statistical tests can be used to select those features that have the strongest relationship with the output variable.","b2fc193b":"## 2.Feature Importance\n#### You can get the feature importance of each feature of your dataset by using the feature importance property of the model.","f07c07de":"## 3.Correlation Matrix with Heatmap\n#### Correlation states how the features are related to each other or the target variable.","2b038ff3":"![image.png](attachment:96af698a-6962-4b7d-97c6-b0e3863f877b.png)\n#### Feature Selection is one of the core concepts in machine learning which hugely impacts the performance of your model.\n#### Benefits of performing feature selection before modeling\n#####  1. Reduces Overfitting: Less redundant data means less opportunity to make decisions based on noise.\n#####  2. Improves Accuracy: Less misleading data means modeling accuracy improves.\n#####  3. Reduces Training Time: fewer data points reduce algorithm complexity and algorithms train faster."}}