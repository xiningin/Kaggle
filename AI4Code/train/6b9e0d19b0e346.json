{"cell_type":{"7b462a1f":"code","b4f30891":"code","c93a2430":"code","9c9bdb97":"code","df959fb9":"code","b1058c5c":"code","ea3235ee":"code","ecc98619":"code","b489f473":"code","4c047d77":"code","5af4fd17":"code","439de7b5":"code","26ece4a3":"code","e537f1ba":"code","7bc036bf":"code","0f0e9483":"code","15912685":"code","44507b4c":"code","b9d3b145":"code","97aefa14":"markdown"},"source":{"7b462a1f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","b4f30891":"import torch\nfrom torch import nn\nimport torchvision as tv\nimport time\nimport numpy as np","c93a2430":"transforms = tv.transforms.Compose([\n    tv.transforms.Grayscale(3),\n    tv.transforms.Resize((224,224)),\n    #tv.transforms.RandomHorizontalFlip(),\n    #tv.transforms.RandomVerticalFlip(),\n    #tv.transforms.RandomResizedCrop(\n    #    (224, 224), scale=(0.1, 1), ratio=(0.5, 2)),\n    tv.transforms.ToTensor()    \n])","9c9bdb97":"BATCH_SIZE=512\ntrain_dataset = tv.datasets.ImageFolder(\"\/kaggle\/input\/face-expression-recognition-dataset\/images\/train\", transform=transforms)\ntest_dataset = tv.datasets.ImageFolder(\"\/kaggle\/input\/face-expression-recognition-dataset\/images\/validation\", transform=transforms)\ntrain_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\ntest_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)","df959fb9":"labels = [td[1] for td in train_dataset]","b1058c5c":"lbs = np.array(labels)","ea3235ee":"np.unique(lbs)","ecc98619":"%matplotlib inline\nimport matplotlib.pyplot as plt","b489f473":"for X, y in train_iter:\n    break","4c047d77":"img_code = 198\nplt.imshow(X[img_code].permute(1,2,0))\nplt.title(str(y[img_code].item()))\nplt.show()","5af4fd17":"def evaluate_accuracy(data_iter, net, dev):\n    acc_sum, n = torch.Tensor([0]), 0\n    for X, y in data_iter:\n        X, y = X.to(dev), y.to(dev)\n        acc_sum += (net(X).argmax(axis=1) == y).sum()\n        n += y.shape[0]\n    return acc_sum.item() \/ n\n\ndef train(net, train_iter, test_iter, trainer, num_epochs, dev, show_batch_info=True):\n    loss = nn.CrossEntropyLoss(reduction='sum')\n    for epoch in range(num_epochs):\n        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n        for X, y in train_iter:\n            X, y = X.to(dev), y.to(dev)\n            trainer.zero_grad()\n            y_hat = net(X)\n            l = loss(y_hat, y)\n            l.backward()\n            trainer.step()\n            train_l_sum += l.item()\n            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n            n += y.shape[0]\n            if (show_batch_info):\n                print(\"Step. time since epoch: {:.3f}. Train acc: {:.3f}. Train Loss: {:.3f}\".format(time.time() -  start,\n                    (y_hat.argmax(axis=1) == y).sum().item() \/ y.shape[0], l.item()))\n        test_acc = evaluate_accuracy(test_iter, net, dev)\n        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n              'time %.1f sec'\n              % (epoch + 1, train_l_sum \/ n, train_acc_sum \/ n, test_acc,\n                 time.time() - start))","439de7b5":"model = tv.models.resnet18(pretrained=True)","26ece4a3":"model","e537f1ba":"for name, param in model.named_parameters():\n    if not (name.startswith('layer4')):\n        param.requires_grad = False","7bc036bf":"model.fc = nn.Linear(512, 7)","0f0e9483":"dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmodel = model.to(dev)","15912685":"print(\"Params to learn:\")\nparams_to_update = []\nfor name,param in model.named_parameters():\n    if param.requires_grad == True:\n        params_to_update.append(param)\n        print(\"\\t\",name)","44507b4c":"trainer = torch.optim.SGD(params_to_update, lr=0.05)\n\ntrain(model, train_iter, test_iter, trainer, 10, dev, show_batch_info=False)","b9d3b145":"trainer = torch.optim.Adam(params_to_update, lr=0.01)\n\ntrain(model, train_iter, test_iter, trainer, 10, dev, show_batch_info=False)","97aefa14":"## \u041c\u043e\u0434\u0435\u043b\u044c"}}