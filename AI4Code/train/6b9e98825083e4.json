{"cell_type":{"70b53bfe":"code","185dbebb":"code","3d642c8c":"code","c2d3faa4":"code","3d80b163":"code","d947716f":"code","30027f90":"code","16e40e41":"code","d38a5286":"code","9160f23c":"code","bfdb95b5":"code","bea89c28":"code","6fc1adcd":"code","98080a6a":"markdown"},"source":{"70b53bfe":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom keras.utils import to_categorical\nfrom keras.utils import plot_model\nfrom keras.callbacks import EarlyStopping\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.losses import categorical_crossentropy\nfrom sklearn.metrics import accuracy_score\nfrom keras.optimizers import Adam\nfrom keras.regularizers import l2\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","185dbebb":"data = pd.read_csv('..\/input\/fer2013csv\/fer2013.csv')\n#check data shape\ndata.shape\ndata.Usage.value_counts()","3d642c8c":"#check target labels\nemotion_map = {0: 'Angry', 1: 'Digust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\nemotion_counts = data['emotion'].value_counts(sort=False).reset_index()\nemotion_counts.columns = ['emotion', 'number']\nemotion_counts['emotion'] = [j for (i,j) in emotion_map.items()]\nemotion_counts","c2d3faa4":"def row2image(row):\n    pixels, emotion = row['pixels'], emotion_map[row['emotion']]\n    img = np.array(pixels.split())\n    img = img.reshape(48,48)\n    image = np.zeros((48,48,3))\n    image[:,:,0] = img\n    image[:,:,1] = img\n    image[:,:,2] = img\n    return np.array([image.astype(np.uint8), emotion])\n\nplt.figure(0, figsize=(16,10))\nfor i in range(1,8):\n    face = data[data['emotion'] == i-1].iloc[0]\n    img = row2image(face)\n    plt.subplot(2,4,i)\n    plt.imshow(img[0])\n    plt.title(img[1])\n\nplt.show()","3d80b163":"train_data = data[data['Usage'] == 'Training'].copy()\nval_data = data[data['Usage'] == 'PublicTest'].copy()\ntest_data = data[data['Usage'] == 'PrivateTest'].copy()\n\nprint('Training Data shape : ' + str(train_data.shape))\nprint('Validation Data shape : ' + str(val_data.shape))\nprint('Test Data shape : ' + str(test_data.shape))","d947716f":"num_classes = 7\nwidth, height = 48,48\nepochs = 100\nbatch_size = 64\nnum_features = 64","30027f90":"#CRNO - Convert, Reshape, Normalize, One hot Encoding\ndef crno(df, dataName):\n  df['pixels'] = df['pixels'].apply(lambda x: [int(px) for px in x.split()])\n  data_X = np.array(df['pixels'].to_list(), dtype='float32').reshape(-1,width, height,1)\/255.0   \n  data_Y = to_categorical(df['emotion'], num_classes)  \n\n  print(str(dataName)+\" _X shape: \"+str(data_X.shape), end =\"\")\n  print(\" _Y shape \" + str(data_Y.shape))\n  return data_X, data_Y\n\ntrain_X , train_Y = crno(train_data, \"train\")\nval_X, val_Y = crno(val_data, \"Validation\")\ntest_X, test_Y = crno(test_data, \"Test\")","16e40e41":"model = Sequential()\n#Layer1\nmodel.add(Conv2D(64, (3, 3), input_shape=(width,height,1),activation='relu', padding='same'))\nmodel.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n#Layer2\nmodel.add(Conv2D(128, (3, 3),activation='relu',padding='same'))\nmodel.add(Conv2D(128, (3, 3),activation='relu',padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n#Layer3\nmodel.add(Conv2D(256, (3, 3), activation = 'relu', padding = 'same'))\nmodel.add(Conv2D(256, (3, 3), activation = 'relu', padding = 'same'))\nmodel.add(Conv2D(256, (3, 3), activation = 'relu', padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n#Layer4\nmodel.add(Conv2D(512, (3, 3), activation = 'relu', padding = 'same'))\nmodel.add(Conv2D(512, (3, 3), activation = 'relu', padding = 'same'))\nmodel.add(Conv2D(512, (3, 3), activation = 'relu', padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n#FCC\nmodel.add(Flatten())\n#model.add(Dense(1024))\n#model.add(Activation('relu'))\n#model.add(Dropout(0.25))\nmodel.add(Dense(128))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.2))\n\n#Softmax\nmodel.add(Dense(7))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n\nmodel.summary()","d38a5286":"data_generator = ImageDataGenerator(\n                        featurewise_center=False,\n                        featurewise_std_normalization=False,\n                        rotation_range=10,\n                        width_shift_range=0.1,\n                        height_shift_range=0.1,\n                        zoom_range=.1,\n                        horizontal_flip=True)\n\n\nes = EarlyStopping(monitor='val_loss', patience = 10, mode = 'min', restore_best_weights=True)\n\nhistory = model.fit_generator(data_generator.flow(train_X, train_Y, batch_size),\n                                steps_per_epoch=len(train_X) \/ batch_size,\n                                epochs=epochs,\n                                verbose=2, \n                                callbacks = [es],\n                                validation_data=(val_X, val_Y))","9160f23c":"test_true = np.argmax(test_Y, axis=1)\ntest_pred = np.argmax(model.predict(test_X), axis=1)\nprint(\"CNN Model Accuracy on test set: {:.4f}\".format(accuracy_score(test_true, test_pred)))\nplot_model(model)","bfdb95b5":"def prediction(path):\n    img = image.load_img(path, color_mode = 'grayscale', target_size=(48, 48,1))\n    show_img=image.load_img(path, target_size=(200, 200))\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis = 0)\n\n    x \/= 255\n    pred = model.predict(x)\n    plt.gray()\n    plt.imshow(show_img)\n    plt.show()\n\n    ind = np.argmax(pred[0])\n\n    print('Expression Prediction:',emotion_map[ind])","bea89c28":"model.save('..\/output\/')","6fc1adcd":"#prediction('..\/input\/images\/sample1.png')\n#prediction('..\/input\/images\/sample2.png')\nprediction('..\/input\/images\/sample3.jpg')\nprediction('..\/input\/images\/sample4.jpeg')\nprediction('..\/input\/images\/sample6.jpg')\nprediction('..\/input\/images\/sample7.jpg')\nprediction('..\/input\/images\/sample5.jpg')\nprediction('..\/input\/images\/sample8.jpg')\nprediction('..\/input\/images\/sample9.jpeg')","98080a6a":"Let's look at some of the images."}}