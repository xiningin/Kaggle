{"cell_type":{"05f11138":"code","5beb70f5":"code","b88e0d5a":"code","0c159fe9":"code","9f765de0":"code","0608fd7e":"code","a7692ca8":"code","0eff696c":"code","821266a6":"code","261ff5de":"code","8cdcff0c":"code","97c5f33b":"code","e9ff2ee3":"code","b49d98cc":"code","81516a68":"code","612b5d53":"code","03c0f998":"code","11706ab5":"code","b700f505":"code","43812344":"code","a22e0cfc":"code","01898347":"code","a47adc2d":"code","ca90bd40":"code","e00cac5b":"code","9cf850f3":"code","9c76188a":"code","fbe84107":"code","3aee1118":"code","9c5c7d34":"code","febc2cfc":"code","d894ff88":"code","65b0f83c":"code","9bb10db6":"code","382bd2c7":"code","92f309c5":"code","0af748c9":"code","4a86975e":"code","fdadf557":"code","a8585191":"code","f88f0701":"code","725706de":"code","4d1314ad":"code","1d95a9bb":"code","26015cd8":"markdown","4d44652a":"markdown","5a40a141":"markdown","c86027cd":"markdown"},"source":{"05f11138":"#Getting Setup\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np","5beb70f5":"#Load the Data\ndf = pd.read_csv('..\/input\/housingvotes\/house-votes-84.csv',index_col=None,header=None,na_values = '?')\ndf.columns = ['Party',\n   'Infants', \n   'Water-project',\n   'Budget',\n   'Physician',\n   'El-salvador',\n   'Religion',\n   'Satellite',\n   'Nicaragua',\n   'Missile',\n   'Immigration',\n   'Synfuels',\n   'Education',\n   'Superfund',\n   'Crime',\n   'Duty-free',\n   'Export']","b88e0d5a":"#Describe the data\ndf.head()\n\n","0c159fe9":"df.info()","9f765de0":"df.shape","0608fd7e":"#View the count of Nans in each factor\n\ndf.isnull().sum().sort_values(ascending=False)\n","a7692ca8":"#Examining the datatypes\ndf.dtypes\n","0eff696c":"#Make a copy of the original dataset and work on the new copy\ndf1=df.copy(deep=True)","821266a6":"#Leaving this code in even though it is not required. This was to replace the missing values (?) with np.nan but giving the parameter 'na_values = ?' while loading the dataset will do #the job\n\n#df1.replace('?',np.nan,inplace=True)\n\n","261ff5de":"#Replace 'y' by 1 and'n' by 0 (By running the replace command, the data type of all the factors got converted from object to flaoatint64. \n\ndf1.replace({'n': 0,'y': 1},inplace=True)\nprint(df1.head())\ndf1.dtypes\n\n","8cdcff0c":"#As Export column has missing values for a large percentage of records this column will be dropped\ndf1.drop(['Export'],axis=1,inplace=True)","97c5f33b":"# Visualizing the highest predictors for each party\n\ndf1.head()\ndf2=df1.melt(id_vars = 'Party',\n         var_name = 'Predictors',\n         value_name = 'Vote'\n          )\ndf2.head()\n\ntable=df2.groupby(['Predictors','Party'])['Vote'].mean().unstack()\ntable\n\n\nax=table.plot(kind='bar',width=0.60,figsize=(15,10))\nplt.ylabel('Average Vote')\nplt.title('Probability of Voting')\nplt.grid(axis='x')\n\n#Got this from Stackoverflow, #Try this later )\n#sns.set()\n#df.set_index('App').T.plot(kind='bar', stacked=True)\n\n","e9ff2ee3":"#For the remaining factors with missing values I created a function that will display a countplot for each party. This will help with choosing what value to fill missing values in for each factor.For eg, here's a sample plot for the factor Duty-free. The Republican party is marked by Red and Democratic by blue. As you can see there is a resounding difference in the way each party voted for Duty-free. Similarly I've created count plots for all other factors\nplt.figure()\nsns.countplot(x='Duty-free', hue='Party', data=df1, palette='RdBu')\nplt.xticks([0,1], ['No', 'Yes'])\nplt.show()","b49d98cc":"# function to display countplot for a factor i.e Democrate Vs Republicans on each issue\/factor\n\ndef countplot(column, dataframe):\n    plt.figure()\n    sns.countplot(x=dataframe[column], hue='Party', data=dataframe, palette='RdBu')\n    plt.title(column)\n    plt.xticks([0,1], ['No', 'Yes'],rotation=45)\n    plt.show()","81516a68":"# I've taken out 'Party' from the list of columns to be plotted as that is our response vector\nfactor_cols = df1.columns[1:]\nfactor_cols","612b5d53":"# Iterate the countplot for every factor in the dataset\nfor col in factor_cols:\n      countplot(col,df1)","03c0f998":"#The countplot for Water Project shows that equal number of democrats and Republicans voted against and in favour and therefore is inconclusive. Therefore I'm taking this factor out of the dataframe for the predictive model and and reset factor_cols to get the list of column names from the latest modified dataset. \ndf1.drop(['Water-project'],axis=1,inplace=True)\nfactor_cols = df1.columns[1:]","11706ab5":"#Check to see if Water-project was removed\nprint(df1.head())","b700f505":"#For all other factors I've updated the missing values with the mode or the value that most people voted for. The function below \n#1. Reads every row of the dataset df1\n#2. Gets the corresponding 'Party' of that row\n#3. Calculates the mode of that column for rows pertaining to the party from step #2\n#4. Updates the value in that row with the mode obtained through step 3 if there is a missing value. Ideally, iterrows meathod does not allow to update the original dataframe, so I used the command 'dataframe.at' to do an inplace update\n\n#This function is then iterated over every column of the dataset\n","43812344":"# function to retrive and update the mode ( most frequent value) of the party for a factor\n\ndef fillpartymode(column,dataframe) :\n    for index,row in dataframe.iterrows():\n #      print(row)\n        party = row['Party']\n #      print (\"Party is \", party)\n        df1_subset = df1[df1['Party'] == party].reset_index() \n        value = df1_subset.loc[:,column].mode()\n        if pd.isna(row[column]):\n #          print(\"Filled Nan with \", value) \n            dataframe.at[index, column] = value\n            \n           ","a22e0cfc":"# Iterate the fillna module for every factor in the dataset\nfor col in factor_cols:\n      print('Column:',col)  \n      fillpartymode(col,df1)\n      print (df1[col].value_counts(dropna=False)) \n      \n","01898347":"#Check to see if there are still missing values. The function din't seem to work for the first column Infants ( odd !). So I had to update the missing value in Infants with the median value\ndf1.isnull().sum()\n#df1.loc[:, df1.isnull().any()] (lists the column with null values)","a47adc2d":"#Now that we've cleaned the dtaaset and filled the missing values, It is time to build the classifier.I've used a k-Nearest Neighbors classifier to the voting dataset, \n# Import KNeighborsClassifier from sklearn.neighbors\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split","ca90bd40":"#First let's train and test the entire dataset\n\n#1. Train the model on the entire dataset.\n#2. Test the model on the same dataset, and evaluate how well we did by comparing the predicted response values with the true response values.","e00cac5b":"# Create arrays for the features and the response variable\ny = df1['Party'].values\nX = df1.drop('Party', axis=1).values","9cf850f3":"#Create an instance of the estimator. \nknn = KNeighborsClassifier(n_neighbors=6)","9c76188a":"#Fit the model with the data\nknn.fit(X,y)","fbe84107":"# predict the response value for the observations in X\ny_pred = knn.predict(X)","3aee1118":"# check how many predictions were generated\nlen(y_pred)","9c5c7d34":"# compute classification accuracy for the knn classifier model (Known as training accuracy when you train and test the model on the same data)\nfrom sklearn import metrics\nprint(metrics.accuracy_score(y, y_pred))","febc2cfc":"# Split into training and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)","d894ff88":"# Create a k-NN classifier with 6 neighbors: knn\nknn = KNeighborsClassifier(n_neighbors = 6)","65b0f83c":"# Fit the classifier to the training data\nknn.fit(X_train,y_train)","9bb10db6":"#Make predictions on the training set\ny_pred = knn.predict(X_test)","382bd2c7":"# compute classification accuracy for the knn classifier model\nfrom sklearn import metrics\nprint(metrics.accuracy_score(y_test, y_pred))","92f309c5":"# Print the accuracy (Another way to get the Accuracy score)\nprint(knn.score(X_test, y_test))","0af748c9":"#Repeat for knn = 7","4a86975e":"# Create a k-NN classifier with 7 neighbors: knn\nknn = KNeighborsClassifier(n_neighbors = 7)\n\n# Fit the classifier to the training data\nknn.fit(X_train,y_train)\n\n#Make predictions on the training set\ny_pred = knn.predict(X_test)\n\n# compute classification accuracy for the knn classifier model\nprint(metrics.accuracy_score(y_test, y_pred))\n","fdadf557":"# try K=1 through K=25 and record testing accuracy\nk_range = list(range(1, 20))\nscores = []\nfor k in k_range:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train, y_train)\n    y_pred = knn.predict(X_test)\n    scores.append(metrics.accuracy_score(y_test, y_pred))\n\n# allow plots to appear within the notebook\n%matplotlib inline\n\n# plot the relationship between K and testing accuracy\nplt.plot(k_range, scores)\nplt.xlabel('Value of K for KNN')\nplt.ylabel('Testing Accuracy')","a8585191":"# Create a k-NN classifier with 12 neighbors: knn\nknn = KNeighborsClassifier(n_neighbors = 12)\n\n# Fit the classifier to the training data\nknn.fit(X_train,y_train)\n\n#Make predictions on the training set\ny_pred = knn.predict(X_test)\n\n# compute classification accuracy for the knn classifier model\nprint(metrics.accuracy_score(y_test, y_pred))\n","f88f0701":"#Evaluting the model using the Confusion matrix\nfrom sklearn.metrics import confusion_matrix, classification_report\n# Compute and print the confusion matrix and classification report\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n","725706de":"#Building a Logistic Regression Model\nfrom sklearn.linear_model import LogisticRegression\n\n# Create the classifier: logreg\nlogreg = LogisticRegression()\n\n# Fit the classifier to the training data\nlogreg.fit(X_train, y_train)\n\n# Predict the labels of the test set: y_pred\ny_pred = logreg.predict(X_test)\n\n# compute classification accuracy for the knn classifier model\nprint(metrics.accuracy_score(y_test, y_pred))\n\n# Compute and print the confusion matrix and classification report\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","4d1314ad":"# I tested with an out-of-sample observation. My sample is modeled on Republican votes.\nX_new = [[0,0,1,1,1,0,0,0,1,0,1,1,1,0]]\ny_pred = knn.predict(X_new)\ny_pred","1d95a9bb":"y_test.shape","26015cd8":"Project Overview\n\nWe are going to apply a predictive algorithm to a political dataset where you classify the party affiliation of United States congressmen based on their voting records.We'll be working with a dataset obtained from the UCI Machine Learning Repository consisting of votes made by US House of Representatives Congressmen. Our goal will be to predict their party affiliation ('Democrat' or 'Republican') based on how they voted on certain key issues. ","4d44652a":"#1. Training accuracy rises as model complexity increases\n#2. Testing accuracy penalizes models that are too complex or not complex enough\n#3. For KNN models, complexity is determined by the value of K (lower value = more complex). In this case 12 neighbours or more creates a simple model that neither underfits nor overfits #the data. I've tried once again with knn=12","5a40a141":"Citation\n\nI have added notes for my own learning as I worked through this dataset. These notes are from the learning videos of Data School and the instructor is Kevin Markham (@justmarkham)","c86027cd":"#The Accuracy score is 96%\n#Problems with training and testing on the same data\n#1. Goal is to estimate likely performance of a model on out-of-sample data\n#2. But, maximizing training accuracy rewards overly complex models that won't necessarily generalize\n#3. Unnecessarily complex models overfit the training data\n\n#Evaluation procedure #2: Train\/test split\n#1. Split the dataset into two pieces: a training set and a testing set.\n#2. Train the model on the training set.\n#3. Test the model on the testing set, and evaluate how well we did."}}