{"cell_type":{"fff39303":"code","f5e89eb2":"code","750dc09a":"code","a61a3388":"code","2fef8d99":"code","b1ac4df8":"code","39c8b24c":"code","84c58d58":"code","bf222bef":"code","cb8612b2":"code","7fb5f2bb":"code","9a38af8f":"code","d4da64b2":"code","ad7a2aa9":"code","1ab7cee0":"code","7b7a499f":"code","4b2d3fc9":"code","00c06a00":"code","21e8abfd":"code","af669648":"code","08da29ee":"code","b4bdaff3":"code","1c2457a4":"code","8aa2e4ab":"code","2a316d29":"code","46c74c81":"code","f67b824e":"code","13775794":"code","8053b958":"code","ec78ade3":"code","2746bb7b":"code","537f7036":"code","33acf9d1":"code","d8d78ebc":"code","d2c24ad3":"code","c60f17e0":"code","0c8a8d79":"code","fa72ed57":"code","8bcd3fb3":"code","6b3d1b8d":"code","b165e738":"code","2ebbb8d5":"code","37416dd1":"code","1521f82c":"code","800a2cd6":"code","8ff47346":"code","86608521":"code","50ee74f4":"code","ca117c6e":"code","44229e3c":"code","98ab3542":"code","da2354a9":"code","be42418f":"code","c3bf5cfa":"code","df283933":"code","9014b6cb":"code","9c8a4de2":"code","ed492e1e":"code","6cfeba92":"code","ca540244":"code","74d637a3":"code","1f890ec8":"code","77577128":"code","cd8468c9":"code","7c76a851":"markdown","f73c8cee":"markdown","e5e66771":"markdown","b24dbffa":"markdown","51eb4e6b":"markdown","977ecfcf":"markdown","d255e09c":"markdown","162287c7":"markdown","e6da136a":"markdown","807f1561":"markdown","18e9f44f":"markdown","2448697d":"markdown","ee96d17f":"markdown","98e32825":"markdown","c91b1bdf":"markdown","ec38f69e":"markdown","7b16b56e":"markdown","f1f1232a":"markdown","51d9845b":"markdown","945745f3":"markdown","8c7b24de":"markdown","c3e104f5":"markdown","ec582906":"markdown","a99f6483":"markdown","226519e8":"markdown","1dcce187":"markdown","70a5c5be":"markdown","48a73775":"markdown","6c979103":"markdown","6b8006e4":"markdown","7a13710a":"markdown","256b918f":"markdown","cbe7efe6":"markdown","1729a935":"markdown","e987ebc6":"markdown","d520d60d":"markdown","505a0ecb":"markdown","3384db58":"markdown","dff0e2f4":"markdown","0c06fe41":"markdown","7624ba9f":"markdown","276af378":"markdown","6552d2f0":"markdown","d4c52bd4":"markdown","92c3b128":"markdown","a128a825":"markdown","5c6c6782":"markdown","ab54a652":"markdown","b4099c4b":"markdown","9045d869":"markdown","1143ec9c":"markdown","93bff14e":"markdown"},"source":{"fff39303":"!pip install pmdarima","f5e89eb2":"import pandas as pd\nimport numpy as np\n%matplotlib inline\n\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom pmdarima import auto_arima\n\nimport seaborn as sns\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\nfrom scipy import stats\nfrom scipy.stats import skew\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","750dc09a":"train = pd.read_csv('\/kaggle\/input\/bike-sharing-demand\/train.csv', index_col='datetime', parse_dates=True)\ntest = pd.read_csv('\/kaggle\/input\/bike-sharing-demand\/test.csv', index_col='datetime', parse_dates=True)","a61a3388":"train.head()","2fef8d99":"test.head()","b1ac4df8":"Q1 = train.quantile(0.25)\nQ3 = train.quantile(0.75)\nIQR = Q3 - Q1\nprint(IQR)","39c8b24c":"train.shape","84c58d58":"train_without_outliers = train[~((train < (Q1 - 1.5*IQR)) | (train > (Q3 + 1.5*IQR))).any(axis=1)]","bf222bef":"train_without_outliers.shape","cb8612b2":"def wind(cols):\n    windspeed = cols[0]\n    season = cols[1]\n    \n    if(windspeed == 0):\n        if(season == 1):\n            return 14\n        elif(season == 2):\n            return 14\n        else:\n            return 13\n    else:\n        return windspeed","7fb5f2bb":"train_without_outliers['wind'] = train_without_outliers[['windspeed', 'season']].apply(wind, axis=1)\ntest['wind'] = test[['windspeed', 'season']].apply(wind, axis=1)","9a38af8f":"data = train_without_outliers.append(test)","d4da64b2":"data.tail(5)","ad7a2aa9":"data.dtypes","1ab7cee0":"data.shape","7b7a499f":"data.isnull().sum()","4b2d3fc9":"data['count'][0:250].plot(figsize=(16, 5))","00c06a00":"data['season'] = data['season'].replace({1: 'spring', 2: 'summer', 3: 'fall', 4: 'winter' })\ndata['weather'] = data['weather'].replace({1: 'Clear, Few clouds, Partly cloudy, Partly cloudy',\n                                        2: 'Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist',\n                                        3: 'Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds',\n                                        4: 'Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog' })","21e8abfd":"for i in data.columns:\n    print(i)\n    print(data[i].value_counts())\n    print('\\n')","af669648":"corr = data.corr()\ncorr['count'][:-1]","08da29ee":"for i in (data.select_dtypes(include ='object').columns):\n    if(i != 'count'):\n        data_crosstab = pd.crosstab(data[i], data['count'], margins = False)\n        stat, p, dof, expected = stats.chi2_contingency(data_crosstab)\n        prob=0.95\n        alpha = 1.0 - prob\n        if p <= alpha:\n            print(i, ' : Dependent (reject H0)')\n        else:\n            print(i, ' : Independent (fail to reject H0)')","b4bdaff3":"data.drop('casual', axis=1, inplace=True)\ndata.drop('registered', axis=1, inplace=True)","1c2457a4":"corr_matrix = data.corr().abs()\n\n# Select upper triangle of correlation matrix\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n\n# Find index of feature columns with correlation greater than 0.95\nto_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\ndata = data.drop(data[to_drop], axis=1)","8aa2e4ab":"data.head()","2a316d29":"import matplotlib.pyplot as plt\nfor i in (data.skew().index):\n    plt.figure(i)\n    sns.distplot(data[i], kde_kws={'bw':0.1})","46c74c81":"plt.scatter(data.index, data['count'])","f67b824e":"def fixing_skewness(df):\n    numeric_feats = df.dtypes[df.dtypes != object].index\n    \n    skew_feats = df[numeric_feats].apply(lambda x: skew(x)).sort_values(ascending=False)\n    \n    high_skew = skew_feats[abs(skew_feats) > 0.5].index\n    \n    for i in high_skew:\n        df[i] = boxcox1p(df[i], boxcox_normmax(df[i] + 1))\n#         print(i)\n        \nfixing_skewness(data)","13775794":"data.head()","8053b958":"data.dtypes","ec78ade3":"data.shape","2746bb7b":"def overfit_reducer(df):\n    overfit = []\n    for i in df.columns:\n        count = df[i].value_counts()\n        zero_index_value = count.iloc[0]\n        \n        if (((zero_index_value \/ len(df)) * 100) > 99.94):\n            overfit.append(i)\n            \n    overfit = list(overfit)\n    return overfit","537f7036":"#Finding the list of overfitted features using above user-defined function\noverfitted_features = overfit_reducer(data)\n#Dropping the overfitted columns from the final dataframes\ndata.drop(overfitted_features, axis=1, inplace=True)","33acf9d1":"data.shape","d8d78ebc":"data.dtypes","d2c24ad3":"data1 = data.dropna()","c60f17e0":"data1.shape","0c8a8d79":"data1.tail()","fa72ed57":"data1.head()","8bcd3fb3":"data1['count'] = data1['count'].astype('int64')","6b3d1b8d":"data1.head()","b165e738":"title = 'Count of bikes rented'\ndata1['count'].plot(figsize=(16,5), legend=True, title=title)","2ebbb8d5":"for i in (data1.dtypes[data1.dtypes == 'object'].index):\n    plt.figure(i)\n    sns.boxplot(x=i, y='count', data=data1)","37416dd1":"for i in (data1.dtypes[data1.dtypes == 'int64'].index):\n    if(i!='count'):\n        plt.figure(i)\n        sns.scatterplot(x=i, y='count', data=data1)","1521f82c":"title='Count of bikes rented'\n\nax = data1['count'][:1000].plot(figsize=(16,5),title=title)\nax.autoscale(axis='x',tight=True)\nfor x in data1[:1000].query('holiday==1').index:       \n    ax.axvline(x=x, color='k', alpha = 0.3);  ","800a2cd6":"title='Count of bikes rented'\n\nax = data1['count'][:1000].plot(figsize=(16,5),title=title)\nax.autoscale(axis='x',tight=True)\nfor x in data1[:1000].query('holiday==0').index:       \n    ax.axvline(x=x, color='k', alpha = 0.3);  ","8ff47346":"title='Count of bikes rented'\n\nax = data1['count'][:1000].plot(figsize=(16,5),title=title)\nax.autoscale(axis='x',tight=True)\nfor x in data1[:1000].query('workingday==1').index:       \n    ax.axvline(x=x, color='k', alpha = 0.3);  ","86608521":"title='Count of bikes rented'\n\nax = data1['count'][:1000].plot(figsize=(16,5),title=title)\nax.autoscale(axis='x',tight=True)\nfor x in data1[:1000].query('workingday==0').index:       \n    ax.axvline(x=x, color='k', alpha = 0.3);  ","50ee74f4":"result = seasonal_decompose(data1['count'], model='multiplicative', period=24)\nresult.plot();","ca117c6e":"from statsmodels.tsa.stattools import adfuller\n\ndef adf_test(series,title=''):\n    \"\"\"\n    Pass in a time series and an optional title, returns an ADF report\n    \"\"\"\n    print(f'Augmented Dickey-Fuller Test: {title}')\n    result = adfuller(series.dropna(),autolag='AIC') # .dropna() handles differenced data\n    \n    labels = ['ADF test statistic','p-value','# lags used','# observations']\n    out = pd.Series(result[0:4],index=labels)\n\n    for key,val in result[4].items():\n        out[f'critical value ({key})']=val\n        \n    print(out.to_string())          # .to_string() removes the line \"dtype: float64\"\n    \n    if result[1] <= 0.05:\n        print(\"Strong evidence against the null hypothesis\")\n        print(\"Reject the null hypothesis\")\n        print(\"Data has no unit root and is stationary\")\n    else:\n        print(\"Weak evidence against the null hypothesis\")\n        print(\"Fail to reject the null hypothesis\")\n        print(\"Data has a unit root and is non-stationary\")","44229e3c":"adf_test(data1['count'])","98ab3542":"# For SARIMA Orders we set seasonal=True and pass in an m value\n# auto_arima(data1['count'],seasonal=True,m=24, trace=True, n_jos=-1).summary()","da2354a9":"data_dummies = pd.get_dummies(data, drop_first=True)\ndata_dummies.columns","be42418f":"model = SARIMAX(data1['count'], exog=data_dummies[:7026][['holiday', 'workingday', 'temp','humidity', 'wind', \n                                           'season_spring', 'season_summer', 'season_winter',\n                                           'weather_Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog',\n                                           'weather_Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds',\n                                           'weather_Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist']],\n                                            order=(2, 1, 2), seasonal_order=(1, 0, 1, 24), enforce_invertibility=False)","c3bf5cfa":"results=model.fit()","df283933":"results.summary()","9014b6cb":"start = len(train_without_outliers)\nend = len(train_without_outliers) + len(test) - 1\n# exog_forecast = data[10886:][['holiday', 'workingday', 'temp','humidity', 'windspeed']]\nfcast = results.predict(start=start, end=end, exog=data_dummies[7026:][['holiday', 'workingday', 'temp','humidity', 'wind', \n                                           'season_spring', 'season_summer', 'season_winter',\n                                           'weather_Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog',\n                                           'weather_Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds',\n                                           'weather_Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist']]).rename('SARIMAX(1, 1, 1)x(2, 0, [1, 2], 2) Forecast')","9c8a4de2":"fcast = fcast.astype('int64')\nfcast = fcast.reset_index(drop=True)","ed492e1e":"fcast.index","6cfeba92":"fcast.max()","ca540244":"fcast.min()","74d637a3":"submission_df = pd.DataFrame()\nsubmission_df['datetime'] = test.index","1f890ec8":"submission_df['count'] = fcast","77577128":"submission_df.head()","cd8468c9":"submission_df.to_csv('\/kaggle\/working\/submission.csv', index=False)","7c76a851":"#### Test for stationarity","f73c8cee":"Appending train and test dataset and storing the resultant dataframe into data","e5e66771":"Again, displaying the head of the dataset","b24dbffa":"Displaying the tail of data","51eb4e6b":"#### SARIMAX\nSeasonal AutoRegressive Integrated Moving Average with eXogenous regressors\nThis model encompasses not only the non-seasonal (p,d,q) and seasonal (P,D,Q,m) factors, but also introduce the idea that external factors (environmental, economic, etc.), which can also influence a time series, and be used in forecasting.","977ecfcf":"Finding the correlation value of target column (count) with other numerical variables present in the dataset","d255e09c":"Finding the types of data in the dataset","162287c7":"Displaying top five rows of Train dataset","e6da136a":"Displaying the head of dataframe data1","807f1561":"### Perform standard imports","18e9f44f":"#### Run an ETS Decomposition","2448697d":"Finding the data types of different columns of the data set","ee96d17f":"Following function helps in reducing, if any overfitting is present in the dataset, that is if any variable in the dataset, contains only one value in  99.94 of the cases","98e32825":"Dropping the \"casual\" and \"registered\" columns from the dataset, as in test dataset these values are not present at all","c91b1bdf":"Plot boxplot between \"count\" traget column and columns having object data type","ec38f69e":"We can use matplotlib to shade workingday behind our bike sharing data","7b16b56e":"Changing the data type of forecast to integer and dropping the index","f1f1232a":"Converting the data type of \"count\" (target) column into integer from float","51d9845b":"Plotting distribution plot for the variables having skewness","945745f3":"Replacing the numerical values in Season and Weather column with the string values provided in the description of the dataset","8c7b24de":"Plot the target column (count)","c3e104f5":"Displaying the data types of different columns of data","ec582906":"Displaying the shape of data","a99f6483":"Displaying the tail of dataframe data1","226519e8":"Finding whether a variable of object data type is affecting the target variable (count)","1dcce187":"Displaying the head of dataframe data1","70a5c5be":"Install the pmdarima module to use its auto_arima to find the optimal value for p, d, q, and P, D, Q","48a73775":"#### Creating SARIMAX model","6c979103":"#### Obtain forecasted values","6b8006e4":"Plotting scatter plot between \"datetime index\" and \"count\" column","7a13710a":"Again displaying the head of the dataset","256b918f":"Displaying top five rows of test dataset","cbe7efe6":"### Load Datasets","1729a935":"Printing the summary of the result","e987ebc6":"Calculating quantiles to find and remove the outliers from the dataset","d520d60d":"Finding if multi collinearity is present in the data, if it is then drop that particular column from the dataset","505a0ecb":"As wind speed cannot be zero in any of the season, so I am assigning a particular value to windspeed column based on some situations","3384db58":"Dropping the null value from the dataset and storing the result in data1","dff0e2f4":"Plotting the first 250 rows of count (target) column to find the periodicity value (m) of the target column","0c06fe41":"Fitting the model","7624ba9f":"Finding the number of rows and columns in the dataset","276af378":"Plot scatterplot between \"count\" traget column and columns having integer data type","6552d2f0":"Finding the shape of data1","d4c52bd4":"Finding the count of unique values present in the different columns in the dataset","92c3b128":"#### Run pmdarima.auto_arima to obtain recommended orders\nThis may take awhile as there are a lot of combinations to evaluate.","a128a825":"Checking for null values in different columns of data","5c6c6782":"We can use matplotlib to shade holidays behind bike sharing data","ab54a652":"Creating dummies for object data type and storing the result in data_dummies dataframe","b4099c4b":"Finding if there is any skewness present in the entire dataset and if it is then fixing it through the boxcox1p transformation","9045d869":"Finding the shape of the dataset","1143ec9c":"Creating a new column named wind, and assigning the wind speed to it, after appying above function based on different season","93bff14e":"Set datetime column as index, and change its data type to datetime in both train and test dataset"}}