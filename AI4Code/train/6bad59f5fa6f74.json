{"cell_type":{"e5dd4105":"code","e567bb7f":"code","bc637297":"code","739bffe8":"code","d62593e1":"code","4f94fc1d":"code","9abbc0b0":"code","ca190176":"code","4ea5c03a":"code","ad2db8a6":"code","2a948550":"code","e08d2052":"code","5907bf48":"code","74e2f19b":"code","6c9593d5":"code","dabb1870":"code","e730737c":"code","26d58d96":"code","79fc3916":"code","645a4682":"code","fa2ce453":"code","898de2ee":"code","812079f9":"code","734aa15b":"code","b0332f5f":"code","8422c569":"code","96df4ffe":"code","cb7849d9":"code","a8f45b3f":"code","b7b32c3a":"code","085c177b":"code","d4d198b0":"code","3d1e8a11":"code","c388e53d":"code","f019ee28":"code","6b05bd98":"code","3a48d1c6":"code","bcec8a12":"code","b785ed9d":"markdown","fbbd1081":"markdown","bd1f24ab":"markdown","239e314d":"markdown","2534a149":"markdown","a6c5d79f":"markdown","cea1524d":"markdown","f170bf5c":"markdown","83ab74b8":"markdown","a270dc8b":"markdown","1be60822":"markdown"},"source":{"e5dd4105":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno","e567bb7f":"df = pd.read_csv('..\/input\/insurance\/insurance.csv')","bc637297":"df.head()","739bffe8":"msno.matrix(df)","d62593e1":"df[df.isnull()].count()","4f94fc1d":"df.info()","9abbc0b0":"df.describe()","ca190176":"df.head()","4ea5c03a":"Male = pd.get_dummies(df['sex'], drop_first=True)\ndf = pd.concat([df, Male], axis=1 )","ad2db8a6":"Smoker = pd.get_dummies(df['smoker'], drop_first=True)\ndf = pd.concat([df, Smoker], axis=1 )","2a948550":"df = df.rename(columns={'yes':'Smoker'})","e08d2052":"df['region'].unique()","5907bf48":"region = pd.get_dummies(df['region'])\ndf = pd.concat([df, region], axis=1 )\n#df.drop('region', axis=1,inplace=True)\n#df.drop(['sex','smoker'], axis=1, inplace=True)","74e2f19b":"df.head()","6c9593d5":"plt.figure(figsize=(12,6))\nsns.set_style('white')\nsns.countplot(x='sex', data = df, palette='GnBu')\nsns.despine(left=True)\n","dabb1870":"plt.figure(figsize=(14,10))\nsns.set_style('white')\nsns.boxplot(x='sex', y='charges', data = df, palette='OrRd', hue='Smoker')\nsns.despine(left=True)\n","e730737c":"fig, ax =plt.subplots(nrows= 1, ncols = 3, figsize= (14,6))\nsns.scatterplot(x='age', y='charges', data = df, palette='coolwarm', hue='sex', ax=ax[0])\nsns.scatterplot(x='age', y='charges', data = df, palette='GnBu', hue='Smoker', ax=ax[1])\nsns.scatterplot(x='age', y='charges', data = df, palette='magma_r', hue='region', ax=ax[2])\nsns.set_style('dark')\nsns.despine(left=True)\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)","26d58d96":"fig, ax =plt.subplots(nrows= 1, ncols = 2, figsize= (14,6))\nsns.boxplot(x='region', y='charges', data = df, palette='GnBu', hue='Smoker', ax=ax[0])\nsns.boxplot(x='region', y='charges', data = df, palette='coolwarm', hue='sex', ax=ax[1])","79fc3916":"fig, ax =plt.subplots(nrows= 1, ncols = 2, figsize= (14,6))\nsns.scatterplot(x='bmi', y='charges', data = df, palette='GnBu_r', hue='sex', ax=ax[0])\nsns.scatterplot(x='bmi', y='charges', data = df, palette='magma', hue='Smoker', ax=ax[1])\nsns.set_style('dark')\nsns.despine(left=True)\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)","645a4682":"df.drop(['sex', 'region', 'smoker', 'southwest'], axis=1, inplace=True)","fa2ce453":"df.head()","898de2ee":"plt.figure(figsize=(16,6))\nsns.heatmap(df.corr(), cmap='OrRd')","812079f9":"X=df.drop('charges', axis=1)\ny=df['charges']","734aa15b":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.4)","b0332f5f":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaled_x_train = scaler.fit_transform(X_train)\nscaled_x_test = scaler.transform(X_test)","8422c569":"from sklearn.ensemble import RandomForestRegressor\nrfr = RandomForestRegressor(n_estimators=300)\nrfr.fit(scaled_x_train, y_train)\npredict = rfr.predict(scaled_x_test)","96df4ffe":"from sklearn.metrics import mean_absolute_error, mean_squared_error\nmean_absolute_error(y_test, predict)\n","cb7849d9":"np.sqrt(mean_squared_error(y_test, predict))","a8f45b3f":"from sklearn.linear_model import LinearRegression\nlr=LinearRegression()\nlr.fit(scaled_x_train, y_train)\npredict2 = lr.predict(scaled_x_test)","b7b32c3a":"mean_absolute_error(y_test, predict2)","085c177b":"np.sqrt(mean_squared_error(y_test, predict2))","d4d198b0":"from sklearn.svm import SVR\nregressor = SVR(kernel = 'rbf')\nregressor.fit(scaled_x_train, y_train)\npredict3 = regressor.predict(scaled_x_test)","3d1e8a11":"mean_absolute_error(y_test, predict3)","c388e53d":"np.sqrt(mean_squared_error(y_test, predict3))","f019ee28":"fig, ax = plt.subplots(1,3, figsize=(16,6))\nsns.set_style('dark')\ng = sns.scatterplot(predict,y_test, ax=ax[0], color='red')\ng.set_title('Random Forest Regressor')\ng.set_xlabel('Predict')\n\nsns.set_style('dark')\nh = sns.scatterplot(predict2,y_test, ax=ax[1], color='green')\nh.set_title('Mutliple Linear Regression')\nh.set_xlabel('Predict')\n\n\nsns.set_style('dark')\nf = sns.scatterplot(predict3,y_test, ax=ax[2])\nf.set_title('Support Vector Regression')\nf.set_xlabel('Predict')\n\n","6b05bd98":"entry_1 = df[:][257:477].drop('charges', axis=1)\npred = rfr.predict(entry_1)\nnp.sqrt(mean_squared_error(df[:][257:477]['charges'], pred))","3a48d1c6":"entry_1 = df[:][257:477].drop('charges', axis=1)\npred = lr.predict(entry_1)\nnp.sqrt(mean_squared_error(df[:][257:477]['charges'], pred))","bcec8a12":"entry_1 = df[:][257:477].drop('charges', axis=1)\npred = regressor.predict(entry_1)\nnp.sqrt(mean_squared_error(df[:][257:477]['charges'], pred))","b785ed9d":"# Random Forest Regressor","fbbd1081":"# Support Vector Regressor","bd1f24ab":"* The data is just 1400 rows so it that is why the predicted values are drifted. \n* However the best results achieved from the data set were from Random Forest Regressor ","239e314d":"# Please Upvote if you like it! Reach me out to work on projects together! \n# Thank You!","2534a149":"# Hello Guys! \n* Hope you are doing well. This is my notebook where I have worked on predicting insurance cost based on the features provided in the data set\n* I wanted to test the dataset with different regression models\n* I have also done feature engineering initially and then exploratory analysis to build an understanding of the relationship between variables.\n* Hope you Enjoy!","a6c5d79f":"# Comparing all three models!","cea1524d":"# Data Cleaning and Feature Engineering ","f170bf5c":"Randomly conducted Test","83ab74b8":"# Predictive Analysis","a270dc8b":"# Multiple Linear Regression","1be60822":"* We will be keeping the categorical columns for now because we want to perform exploratory analysis on them\n* Will drop them before applying predictive models"}}