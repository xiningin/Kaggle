{"cell_type":{"ace13a9e":"code","506b81eb":"code","99dca760":"code","7aebdc9f":"code","049ecf8e":"code","39b16578":"code","70511547":"code","fc500875":"code","304a2ac7":"code","2fa71941":"code","43976d9a":"code","8c825895":"code","f6f5e568":"code","065549eb":"code","deadfd48":"code","3a9fac5f":"markdown","44d8fca4":"markdown","d8738c3a":"markdown","971538cc":"markdown","9734c7ac":"markdown","3ccd7783":"markdown","0e01de68":"markdown","ec6ae86b":"markdown","7a794643":"markdown","0f0a27f6":"markdown","9fa904e6":"markdown","d2cc5f30":"markdown","2e5edac0":"markdown","b7d99b59":"markdown","be8d93c0":"markdown","1ccbea62":"markdown","5cd58b40":"markdown","3d2d8260":"markdown","304ec850":"markdown","ebbc3bcb":"markdown","13c9ce97":"markdown","dae7fd29":"markdown"},"source":{"ace13a9e":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","506b81eb":"df=pd.read_csv('\/kaggle\/input\/titanic\/train_and_test2.csv')\ndf.head()","99dca760":"df.info()","7aebdc9f":"df.drop(['Passengerid','zero','zero.1','zero.2','zero.3','zero.4','zero.5','zero.6','zero.7','zero.8','zero.9','zero.10','zero.11','zero.12','zero.13','zero.14','zero.15','zero.16','zero.17','zero.18'],axis=1,inplace=True)\ndf.rename(columns={'2urvived':'Survived'},inplace=True) \ndf.head()","049ecf8e":"df.dropna(inplace=True)","39b16578":"plt.figure(figsize=(12,10))\n# we keep annot=True to make the values appear of df.corr() appear on the heatmap\nsns.heatmap(df.corr(),annot=True,cmap=plt.cm.plasma)","70511547":"sns.pairplot(df)","fc500875":"df.columns","304a2ac7":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nX=df.drop(['Survived'],axis=1)\nY=df['Survived']\nX_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.20,random_state=1)\n","2fa71941":"from sklearn.linear_model import LogisticRegression\nlr=LogisticRegression(max_iter=300)\nlr.fit(X_train,y_train)\nyhat_lr=lr.predict(X_test)\nprint(\"Accuracy of Logistic Model is:\",accuracy_score(yhat_lr,y_test))","43976d9a":"from sklearn.metrics import accuracy_score,confusion_matrix\nax=confusion_matrix(yhat_lr,y_test)\nsns.heatmap(ax,annot=True,cmap=plt.cm.plasma)\nplt.xlabel('Predict')\nplt.ylabel('Actual')","8c825895":"from sklearn.neighbors import KNeighborsClassifier\nKN=KNeighborsClassifier(n_neighbors=5)\nKN.fit(X_train,y_train)\nyhat=KN.predict(X_test)\nprint(\"Accuracy of K-Nearest Neighbor Model is:\",accuracy_score(yhat,y_test))","f6f5e568":"from sklearn.tree import DecisionTreeClassifier\ntree=DecisionTreeClassifier(random_state=0)\ntree.fit(X_train,y_train)\nyhat=tree.predict(X_test)\nprint(\"Accuracy of Decision Tree Classifier Model is:\",accuracy_score(yhat,y_test))","065549eb":"from sklearn.svm import SVC\nsvm=SVC(kernel='linear')\nsvm.fit(X_train,y_train)\nyhat=svm.predict(X_test)\nprint(\"Accuracy of Support Vector Machine Model is:\",accuracy_score(yhat,y_test))","deadfd48":"from sklearn.ensemble import RandomForestClassifier\nrfc=RandomForestClassifier(n_estimators=200,criterion='entropy')\nrfc.fit(X_train,y_train)\n\nyhat=rfc.predict(X_test)\nprint(\"Accuracy of Random Forest Classifier Model is:\",accuracy_score(yhat,y_test))","3a9fac5f":"<h3>1)Logistic Regression<\/h3>","44d8fca4":"<h4>Remove unnecessary columns like zero.1,zero.2..... using pandas dropna() method<br>\nWe will rename '2urvived' column as 'Survived' using rename method<\/h4>","d8738c3a":"# **Building and Training the Model**","971538cc":"<center><h3>Thank you for reading my notebook and don't forget to upvote the notebook<\/h3><\/center>","9734c7ac":"<h1>Data Preprocessing<\/h1>","3ccd7783":"<h1 style=\"text-align:center;color:blue\">Don't forget to Upvote if you like it.\ud83d\ude0a<\/h1>","0e01de68":"<h3>4)Support Vector Machine(SVM) <\/h3>","ec6ae86b":"<h3>3) Decision Tree<\/h3>","7a794643":"<center><h1>Importing Libraries<\/h1><\/center>","0f0a27f6":"**Remove the rows having null values**","9fa904e6":"**Let's see the various columns in df**","d2cc5f30":"<h1>Best Model<\/h1>","2e5edac0":"**Below we use pairplot method from seaborn library. It is used to plot graphs between the various features.**","b7d99b59":"**Numpy : Python Library used for working with arrays<br>\nMatplotlib : Used for data visualizations. ex: to plot the relations between various factors<br>\nSeaborn: used for data visualization like matplotlib<br>\nPandas: used for data analysis and manipulation<br>**\n\n\n\n\n\n","be8d93c0":"<h3 style=\"color:blue\">We see that the best model for the prediction is Support Vector Machine with a accuracy of 0.8396<\/h3>","1ccbea62":"<h3>2) K-Nearest Neighbor<\/h3>","5cd58b40":"<h1>Data Visualization<\/h1>","3d2d8260":"<h1>Importing Dataset<\/h1>","304ec850":"**We will split the data for training and testing using train_test_split**","ebbc3bcb":"**Heatmap of Co-Relation of various columns with each other\ndf.corr() shows the relation between various feature and we hence we can see the influence of the features on each other**","13c9ce97":"<h3>Let's visualize the data using confusion matrix<\/h3>\n<span style=\"color:red\"><b>For those who don't know about Confusion Matrix:<br><br> A Confusion matrix is an N x N matrix used for evaluating the performance of a classification model, where N is the number of target classes. The matrix compares the actual target values with those predicted by the machine learning model. This gives us a holistic view of how well our classification model is performing and what kinds of errors it is making.<\/b><\/span>","dae7fd29":"<h3>5)Random Forest Classifier<\/h3>"}}