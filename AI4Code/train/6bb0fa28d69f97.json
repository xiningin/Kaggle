{"cell_type":{"ca54e673":"code","a798cf58":"code","5512e4a9":"code","73c4ac35":"code","d90c29ed":"code","f4d2348b":"code","2d7e2ce4":"code","b709443b":"code","79500277":"code","f3ba6d43":"code","6b169806":"code","e732a4c8":"code","35ffc57f":"code","03b76a25":"code","337d8ef1":"code","d2e77563":"code","f8d339a9":"code","81ab3fe3":"code","3113a24f":"code","5e236159":"code","bf06f871":"code","b8811fee":"code","a008e6d9":"code","aa6f9209":"code","dcf73bfa":"code","6b3e5633":"code","62f4e938":"code","5573d22b":"code","7cdbb2f7":"code","1ca1718c":"code","f4239ce3":"code","6a3954e0":"code","d0ebb3a1":"code","186d9efd":"code","04cdf5ac":"code","b2c15744":"code","6e3ec2f2":"code","e97fe9b9":"code","f556d52f":"code","cb5d5740":"code","a7e175c5":"code","51ed16a4":"code","15007efc":"code","2ef15006":"code","b750daf1":"code","e90d8129":"code","4a1c5d80":"code","1d54c1fe":"code","35b1dfb4":"markdown","e4e3c95f":"markdown","d0db93f5":"markdown","d51c51f8":"markdown","17888251":"markdown","0c52764d":"markdown","5ab767b2":"markdown","e4a38241":"markdown","7d953f45":"markdown","23867487":"markdown","09ffdac6":"markdown","4f5c9b94":"markdown","dc16a368":"markdown","dcab650a":"markdown","e4702ada":"markdown","09b2cba3":"markdown","a0353d40":"markdown","ec69cbae":"markdown","5434c441":"markdown","946e909b":"markdown","319f6619":"markdown","cb303899":"markdown","719d3cdf":"markdown","24fa4e0f":"markdown","0b780bca":"markdown","b7224897":"markdown","bf804701":"markdown","ef22cdbd":"markdown"},"source":{"ca54e673":"import pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np","a798cf58":"dataset_path = '\/kaggle\/input\/seoul-bike-rental-ai-pro-iti\/'\n\ntrain_df = pd.read_csv(os.path.join(dataset_path, 'train.csv'))\n\ntest_df = pd.read_csv(os.path.join(dataset_path, 'test.csv'))","5512e4a9":"print(\"The shape of the dataset is {}.\\n\\n\".format(train_df.shape))\nprint(\"The shape of the dataset is {}.\\n\\n\".format(test_df.shape))","73c4ac35":"train_df.head()","d90c29ed":"train_df.info()","f4d2348b":"cols_to_rename = {'Temperature(\ufffdC)': 'temperature',\n                   'Humidity(%)': 'humidity',\n                  'Wind speed (m\/s)': 'windspeed',\n                  'Visibility (10m)': 'visibility',\n                  'Dew point temperature(\ufffdC)': 'dewpoint',\n                  'Solar Radiation (MJ\/m2)': 'solarradiation',\n                  'Rainfall(mm)': 'rainfall',\n                  'Snowfall (cm)': 'snowfall',\n                  'Functioning Day': 'functioningday'}\nfor df in [train_df, test_df]:\n    df.rename(columns= cols_to_rename, inplace=True)","2d7e2ce4":"train_df.info()","b709443b":"train_df.duplicated().sum()","79500277":"train_df.info()","f3ba6d43":"plt.hist(train_df['humidity'])","6b169806":"# ranges bins\nbins = [0, 20, 40, 60, 80,100]\n#categorized humidity\ncategorized_humidity = pd.cut(train_df['humidity'], bins)\ntrain_df['categorized_humidity'] = categorized_humidity\n\n#test_df\ncategorized_humidity = pd.cut(test_df['humidity'], bins)\ntest_df['categorized_humidity'] = categorized_humidity","e732a4c8":"train_df.windspeed = np.log1p(train_df.windspeed)\ntest_df.windspeed = np.log1p(test_df.windspeed)","35ffc57f":"for df in [train_df, test_df]:\n    df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)","03b76a25":"train_df.info()","337d8ef1":"train_df.head()","d2e77563":"train_df.describe()","f8d339a9":"#add month , day, year columns\nfor df in [train_df, test_df]:\n    df['month'] = df['Date'].dt.month\n    df['year'] = df['Date'].dt.year\n    df['day'] = df['Date'].dt.day","81ab3fe3":"train_df.day.value_counts() #day1 to day20","3113a24f":"train_df_copy = train_df.copy() #contains main columns without feature processing","5e236159":"for df in [train_df, test_df]:\n    df['dayofweek'] = df['Date'].dt.dayofweek","bf06f871":"for df in [train_df, test_df]:\n    df['weekend'] = (df['dayofweek'] >= 5 )*1","b8811fee":"train_df.head()","a008e6d9":"train_df.head()","aa6f9209":"for df in [train_df, test_df]:\n    df['Holiday'] = df['Holiday'].map({'Holiday': 1, 'No Holiday':0})\n    df['functioningday'] = df['functioningday'].map({'Yes': 1, 'No':0})","dcf73bfa":"print(train_df.Hour.describe())\n_ = plt.scatter(train_df['Hour'] ,train_df['y'])\n_ = plt.xlabel('Hours')\n_ = plt.ylabel('y Rental Prediction')\nplt.show()","6b3e5633":"# ranges bins\nbins = [0, 6, 12, 18, 24]\n#categorized hour\ncategorized_hour = pd.cut(train_df['Hour'], bins)\ntrain_df['categorized_hour'] = categorized_hour\n\n#test_df\ncategorized_hour = pd.cut(test_df['Hour'], bins)\ntest_df['categorized_hour'] = categorized_hour","62f4e938":"print(train_df.temperature.min())\nprint(train_df.temperature.max())\nplt.hist(train_df.temperature)\nplt.show()","5573d22b":"# ranges bins\nbins = [-20, -10, 0, 10, 20, 30, 40]\n#categorized temperature\ncategorized_temp = pd.cut(train_df['temperature'], bins)\ntrain_df['categorized_temp'] = categorized_temp\ntrain_df.categorized_temp\n\n#test_df\ncategorized_temp = pd.cut(test_df['temperature'], bins)\ntest_df['categorized_temp'] = categorized_temp\ntest_df.categorized_temp","7cdbb2f7":"print(train_df.dewpoint.min())\nprint(train_df.dewpoint.max())\nplt.hist(train_df.dewpoint)\nplt.show()","1ca1718c":"# ranges bins\nbins = [-35, -20, -10, 0, 10, 20, 28]\n#categorized temperature\ncategorized_dewpoint = pd.cut(train_df['dewpoint'], bins)\ntrain_df['categorized_dewpoint'] = categorized_dewpoint\n\n#test_df\ncategorized_dewpoint = pd.cut(test_df['dewpoint'], bins)\ntest_df['categorized_dewpoint'] = categorized_dewpoint","f4239ce3":"train_df.columns","6a3954e0":"train_df.info()","d0ebb3a1":"#transform to object to make getdummies\ntrain_df['year'] = train_df['year'].astype('object')\ntrain_df['month'] = train_df['month'].astype('object')\ntrain_df['dayofweek'] = train_df['dayofweek'].astype('object')\n\ncols_to_onehot = ['year','month','dayofweek','Seasons',\n                  'categorized_temp', 'categorized_dewpoint', 'categorized_hour',\n                  'categorized_humidity']\n\nonehot_columns = pd.get_dummies(train_df[cols_to_onehot])\ntrain_df = pd.concat([train_df, onehot_columns], axis=1)\n# drop columns\ntrain_df.drop(cols_to_onehot, axis=1, inplace=True)\n\n#onhot encoding for test_df\ntest_df['year'] = test_df['year'].astype('object')\ntest_df['month'] = test_df['month'].astype('object')\ntest_df['dayofweek'] = test_df['dayofweek'].astype('object')\n\nonehot_columns = pd.get_dummies(test_df[cols_to_onehot])\ntest_df = pd.concat([test_df, onehot_columns], axis=1)\n# drop columns\ntest_df.drop(cols_to_onehot, axis=1, inplace=True)","186d9efd":"train_df.info()","04cdf5ac":"test_df.info()","b2c15744":"cor_mx=train_df.corr()\nplt.figure(figsize=(10,10))\nsns.heatmap(cor_mx,fmt='0.01f',annot=True)","6e3ec2f2":"cor_mx['y'].sort_values(ascending=False)","e97fe9b9":"test_df.iloc[:,3:11] #try PCA on these columns","f556d52f":"# from sklearn.decomposition import PCA\n# df_for_pca = train_df.iloc[:,4:12]\n\n# pca = PCA(n_components=1)\n# principalComponents = pca.fit_transform(df_for_pca)\n# principalDf_train = pd.DataFrame(data = principalComponents)\n\n# #concatenate\n# frames = [principalDf_train, train_df['y'], train_df.iloc[:,12:]]\n# concat_train = pd.concat(frames, axis=1)\n# concat_train.head()\n\n# #repeat for test data\n# test_df_copy = test_df.copy()\n# df_for_pca = train_df.iloc[:,3:11]\n# pca = PCA(n_components=1)\n# principalComponents = pca.fit_transform(df_for_pca)\n# principalDf_test = pd.DataFrame(data = principalComponents)\n\n# frames = [principalDf_test, test_df.iloc[:,11:]]\n# principalDf_test = pd.concat(frames, axis=1)\n\n# concat_train.info()","cb5d5740":"# full_train_df = train_df.copy() #to be used for trainig with all data\n\n# train_df = full_train_df[full_train_df['day'] <= 15]\n# val_df = full_train_df[full_train_df['day'] >= 16]\n\n# X_train = train_df.drop(columns=['y', 'ID', 'Date', 'visibility'])\n# y_train = train_df['y']\n\n# X_val = val_df.drop(columns=['y', 'ID', 'Date', 'visibility'])\n# y_val = val_df['y']\n\n# print(len(train_df))\n# print(len(val_df))\n\n# X_train.head()","a7e175c5":"train_df = np.log1p(train_df.drop(['ID', 'Date'], axis=1))","51ed16a4":"train_df.head()","15007efc":"train_df.info()","2ef15006":"from sklearn.model_selection import train_test_split\n\nfull_train_df = train_df.copy() #to be used for trainig with all data\n\n#train_df = train_df.drop(['ID', 'Date', 'visibility'], axis=1)\n\ntrain_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n\nX_train = train_df.drop(columns=['y'])\ny_train = train_df['y']\n\nX_val = val_df.drop(columns=['y'])\ny_val = val_df['y']\ny_train.isna().sum()","b750daf1":"import math\nimport numpy as np\ndef RMSLE(predict, target):\n    total = 0 \n    for k in range(len(predict)):\n        LPred= np.log1p(predict[k]+1)\n        LTarg = np.log1p(target[k] + 1)\n        if not (math.isnan(LPred)) and  not (math.isnan(LTarg)): \n            total = total + ((LPred-LTarg) **2)\n        \n    total = total \/ len(predict)        \n    return np.sqrt(total)","e90d8129":"from catboost import CatBoostRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\n\ncat  = CatBoostRegressor(objective='Poisson',iterations=3000, learning_rate=0.03, depth=7,random_seed=45\n                         ,verbose=200,loss_function=\"Huber:delta=200\")\n\n\ncat.fit(X_train,np.expm1(y_train),eval_set=(X_val, np.expm1(y_val)),use_best_model=True)\n\nscore = cat.score(X_train, np.expm1(y_train))  \nprint(\"Training score: \", score)\nvald_score = cat.score(X_val, np.expm1(y_val)) \nprint(\"Validation score: \", vald_score)\n\ny_predicted = cat.predict(X_val)\n\nprint ('My RMSLE for vald: ' + str(RMSLE(cat.predict(X_val),np.array(np.expm1(y_val)))) )\nprint ('My RMSLE for train: ' + str(RMSLE(cat.predict(X_train),np.array(np.expm1(y_train)))) )","4a1c5d80":"X_test = test_df.copy()\n\nX_test = np.log1p(X_test.drop(['ID', 'Date'], axis=1))\n\n# You should update\/remove the next line once you change the features used for training\n#X_test = X_test.drop(columns=['ID', 'Date', 'visibility'])\n\ny_test_predicted = cat.predict(X_test)\n\ntest_df['y'] = y_test_predicted.astype(int)\n\ntest_df.head()","1d54c1fe":"test_df[['ID', 'y']].to_csv('\/kaggle\/working\/submission.csv', index=False)","35b1dfb4":"# Read Data","e4e3c95f":"# working with Date column","d0db93f5":"## split according to days","d51c51f8":"# Convert Date to datetime ","17888251":"# working with Hour column","0c52764d":"# Data Splitting","5ab767b2":"# Correlation matrix","e4a38241":"## bining hours","7d953f45":"## RMSLE Root mean squared logarithmic error","23867487":"# Submission File Generation","09ffdac6":"# working with temperature column","4f5c9b94":"# Import The Libraries","dc16a368":"## onehot encoding year, month, dayofweek, Seasons, categorized_temp, categorized_dewpoint, categorized_hour","dcab650a":"# CatBoost","e4702ada":"# work with humidity","09b2cba3":"# Windspeed","a0353d40":"# add day of week","ec69cbae":"## bining dewpoint","5434c441":"# add weekend","946e909b":"# Model Training","319f6619":"# working with dewpoint","cb303899":"## check duplicates","719d3cdf":"# try LOG","24fa4e0f":"## bining temperature into ranges","0b780bca":"## Rename columns","b7224897":"# Exploratory Data Analysis","bf804701":"## transform functioning day, holiday to 0,1","ef22cdbd":"## Try PCA"}}