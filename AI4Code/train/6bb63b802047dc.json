{"cell_type":{"74d98af1":"code","96a1af45":"code","044a4794":"code","fbc59401":"code","ef06e7ad":"code","8bb6a9b3":"code","7db7ec1b":"code","40923e6e":"code","fd6cf1de":"code","a20cbc61":"code","3a7f7c7d":"code","98aef9f9":"code","37e390b8":"code","f0776fcd":"code","4f199675":"code","4151bdc0":"code","c27e211d":"code","0b43f128":"code","8e42bbd6":"code","dcb96a18":"code","d16482bc":"code","a3c728d5":"code","c53b7262":"code","bf4f3567":"code","335559ab":"code","3a9e2095":"code","909d1fc5":"code","01e15b0f":"code","c8ba1ab5":"markdown","5ca5a217":"markdown","bf4eda5f":"markdown","3a92c102":"markdown","19e8ffb4":"markdown","5816eca9":"markdown","4f864500":"markdown","845dbb00":"markdown","5dfa7bcd":"markdown","ad69ac38":"markdown","b3904f88":"markdown","517e6bdc":"markdown","b81fa80e":"markdown","ac3ad576":"markdown","69b30f4a":"markdown","741f9b88":"markdown","7428ea86":"markdown","cf9fc582":"markdown","97e8bd79":"markdown","8cbd5810":"markdown","4d0e762e":"markdown","563abcfe":"markdown","3085e0ea":"markdown","952046cd":"markdown","a2936905":"markdown"},"source":{"74d98af1":"import pandas as pd\nimport numpy as np","96a1af45":"for k_value in range(1,30):\n    import numpy as np\n    import pandas as pd\n    votos = pd.read_csv('\/kaggle\/input\/congressional-voting-records\/house-votes-84.csv')","044a4794":"votos.head(10)","fbc59401":"ynmap = {'y':1,'n':0,'?':np.nan}\npartymap = {'republican':0,'democrat':1}\nvotos['republican'] = votos['Class Name'].map(partymap)\nvotos.drop('Class Name',axis=1,inplace=True)\nfor column in votos.columns.drop('republican'):\n    votos[column+'1'] = votos[column].map(ynmap)\n    votos.drop(column,axis=1,inplace=True)\npartymap = {'republican':1,'democrat':0}\ndata_col = votos.columns","ef06e7ad":"len(votos)","8bb6a9b3":"votos.isnull().sum()","7db7ec1b":"# identificando o detalhe de cada observa\u00e7\u00e3o e retornando true para dado perdido e false para dado completo num array\nvotos.isnull().values.ravel()","40923e6e":"#contagem do total de dados perdidos em toda a tabela (levando em conta observa\u00e7\u00f5e + vari\u00e1veis = extens\u00e3o total dos dados perdidos)\nvotos.isnull().values.ravel().sum()\n\n# obs: a diferen\u00e7a entre esta linha e a soma, \u00e9 que a soma retorna o n\u00famero de dados perdidos por vari\u00e1vel","fd6cf1de":"# eliminando os dados missing\nvotos = votos.dropna()","a20cbc61":"len(votos)","3a7f7c7d":"import pandas_profiling","98aef9f9":"relatorio_votos = pandas_profiling.ProfileReport(votos)","37e390b8":"relatorio_votos.to_file('relatorio_votos.html')","f0776fcd":"relatorio_votos","4f199675":"from sklearn.model_selection import train_test_split","4151bdc0":"# devinindo x e y\n#  x assumira todas as linhas [:] e as colunas de [a:17]\n# y assumira a vari\u00e1vel republican\nX = votos.iloc[:,1:17]\ny = votos.republican\n\n# aqui, defino os nomes das bases de treino e teste e o tamanho desta \u00faltima\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)","c27e211d":"print(X_train.shape)\nprint(X_test.shape)","0b43f128":"from sklearn.linear_model import LogisticRegression","8e42bbd6":"#criando a variavel votos_logistic que receber\u00e1 o m\u00e9todo de regress\u00e3o log\u00edstica\nvotos_logistic = LogisticRegression(C=10)\n#.fit \u00e9 o que aplica o modelo nas bases de treino inicialmente, geraldo as estat\u00edsticas iniciais\nvotos_logistic.fit(X_train, y_train)\n#.predict aplica o aprendido no treino na base de teste\nvotos_logistic_predictions = votos_logistic.predict(X_test)\n# criando a m\u00e9trica de acur\u00e1cia\nfrom sklearn.metrics import accuracy_score\nacc_votos_logistic = accuracy_score(y_test, votos_logistic_predictions)\nprint(\"accuracy_score: %4f\" % acc_votos_logistic)","dcb96a18":"from sklearn.model_selection import GridSearchCV","d16482bc":"tuned_parameters_votos_logistic = [{'C': [0.1,1,10]}]\nclf_votos_logistic = GridSearchCV(LogisticRegression (), tuned_parameters_votos_logistic, cv=3, scoring='accuracy')\nclf_votos_logistic.fit(X_train, y_train)","a3c728d5":"print (\"Melhores parametros encontrados:\")\nprint()\nprint(clf_votos_logistic)\nprint()\nprint(\"Grid scores:\")\nprint()\nmeans = clf_votos_logistic.cv_results_['mean_test_score']\nstds = clf_votos_logistic.cv_results_['std_test_score']\nfor mean, std, params in zip (means, stds, clf_votos_logistic.cv_results_['params']):\n    print(\"%0.3f (+\/-%0.03f) for %r\"\n        % (mean, std * 2, params))\nprint()\nprint(\"Detailed classification report:\")\nprint()\nprint(\"The model is trained on the full development set.\")\nprint(\"The scores are computed on the full evaluation set.\")\nprint()\nfrom sklearn.metrics import accuracy_score\nacc_votos_logistic = accuracy_score(y_test, votos_logistic_predictions)\nprint(\"accuracy_score: %4f\" % acc_votos_logistic)\n","c53b7262":"import sklearn.metrics as metrics","bf4f3567":"probs_votos_logistic = votos_logistic.predict_proba(X_test)\nfrom sklearn.metrics import roc_auc_score\nauc_votos_logistic = roc_auc_score(y_test, probs_votos_logistic[:,1])\nprint(\"AUC: %.4f\" % auc_votos_logistic)","335559ab":"import statsmodels.api as sm\nlogit_model=sm.Logit(y, X)\nresult=logit_model.fit(method='bfgs', full_output='bool')\nprint (result.summary())","3a9e2095":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import roc_curve, confusion_matrix, auc\nfrom sklearn import linear_model","909d1fc5":"def evalBinaryClassifierRL (model, x, y_test, labels=['Positives', 'Negatives']):\n\n# model predicts probabilities of positive class\n\n    p= votos_logistic.predict_proba(X_test)\n    if len(votos_logistic.classes_)!=2:\n        raise ValueError('A binary class problem is required')\n    if model.classes_[1] == 1:\n        pos_p = p[:,1]\n    elif model.classes_[0] == 1:\n        pos_p = p[:,0]\n        \n    #Figure\n    plt.figure(figsize=[15,4])\n    \n    \n    # 1 - Confusion matrix\n    cm_rl = confusion_matrix(y_test, votos_logistic_predictions)\n    plt.subplot(131)\n    ax = sns.heatmap(cm_rl, annot=True, cmap='Blues', cbar=False,\n                    annot_kws={\"size\": 14}, fmt='g')\n    cmlabels = ['Verdadeiros negativos', 'Falso Positivos', 'Falso Negativos', 'Verdadeiros Positivos']\n    \n    for i, t in enumerate(ax.texts):\n        t.set_text(t.get_text() + \"\\n\" + cmlabels[i])\n    plt.title('Matrix de confus\u00e3o', size =15)\n    plt.xlabel('Valores previstos', size = 13)\n    plt.ylabel('Valores verdadeiros', size=13)\n    \n    #2 - Distribui\u00e7\u00e3ode probabilidades para ambas as classes\n    df = pd.DataFrame({'probPos':pos_p, 'target':y_test})\n    plt.subplot(132)\n    plt.hist(df[df.target==1].probPos, density=True,\n            alpha=.5, color='blue', label=labels[0])\n    plt.hist(df[df.target==0].probPos, density=True,\n            alpha=.5, color='purple', label=labels[1])\n    plt.axvline(.5, color='red', linestyle=':', label='Boundary')\n    plt.xlim([0,1])\n    plt.title('Distribui\u00e7\u00e3o das previs\u00f5es', size=15)\n    plt.xlabel('Probabilidade positiva (previsto)', size=13)\n    plt.ylabel('Samples(escala normalizada)', size=13)\n    plt.legend(loc=\"upper right\")\n\n    #3 - Curva ROC\n    fp_rates, tp_rates, _ = roc_curve(y_test, p[:,1])\n    roc_auc = auc(fp_rates, tp_rates)\n    plt.subplot(133)\n    plt.plot(fp_rates, tp_rates, color = 'purple',\n             lw=1, label='Roc curve (area = %0.2f)'%roc_auc)\n    plt.plot([0,1], [0,1], lw=1, linestyle='--', color='red')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\n    plt.xlabel('Falso positivo', size=13)\n    plt.ylabel('Verdadeiro positivo', size=13)\n    plt.title('Curva ROC', size=15)\n    plt.legend(loc='lower right')\n    plt.subplots_adjust(wspace=.3)\n    plt.show()\n    \n    # Mostrar e retornar o f1 score\n    tn, fp, fn, tp = [i for i in cm_rl.ravel()]\n    precision = tp\/(tp+fp)\n    recall = tp\/(tp+fn)\n    F1 = 2*(precision*recall)\/(precision+recall)\n    printout=(\n        f'Precision: {round(precision,2)} | '\n        f'Recall: {round(recall,2)} | '\n        f'F1 Score: {round(F1,2)} | '\n    )\n    print(printout)\n    return F1\n","01e15b0f":"F1= evalBinaryClassifierRL(votos_logistic, X_test, y_test)","c8ba1ab5":"# VISUALIZA\u00c7\u00c3O GR\u00c1FICA DA QUALIDADE DO MODELO","5ca5a217":"Carregando a biblioteca","bf4eda5f":"Verificando o tamanho da base de treino e base de teste.\nBase de treino tem 162 linhas e 16 colunas\nbase de teste tem 70 linhas e 16 colunas","3a92c102":"Nesta \u00faltima etapa, constru\u00edmos a matriz de confus\u00e3o (gr\u00e1fico 1), distribui\u00e7\u00e3o de probabilidades (gr\u00e1fico 2) e Curva ROC (gr\u00e1fico3).\nEm resumo, verificamos na matriz de confus\u00e3o como o modelo performou nas previs\u00f5es. O verdadeiro negativo e o verdadeiro positivo s\u00e3o os mais importantes, pois representam as previs\u00f5es corretas.\nA distribui\u00e7\u00e3o de probabilidades mostra se nossas previs\u00f5es est\u00e3o claramente bem distribu\u00eddas (no nosso caso, beirou a perfei\u00e7\u00e3o). \nE a curva ROC \u00e9 a representa\u00e7\u00e3o gr\u00e1fica da \u00e1rea sob a curva.\nNoutro momento, explicarei em detalhes sobre cada um deles em nosso blog.","19e8ffb4":"# Divis\u00e3o em treino e teste","5816eca9":"# An\u00e1lise explorat\u00f3ria de dados\n\nExploratory analysis","4f864500":"Criando a tabela com os detalhes estat\u00edsticos (coeficientes, desvio padr\u00e3o, normaliza\u00e7\u00e3o, p-valor, percentil) e outras m\u00e9tricas como pseudo R, Raz\u00e3o e desigualdades, logit, dentre outros.","845dbb00":"## CONHE\u00c7A NOSSO BLOG: https:\/\/www.dadosedecisao.com\/blog\n\nEste notebook foi desenvolvido para trazer em termos pr\u00e1ticos o conhecimento sobre regress\u00e3o log\u00edstica mostrado no artigo: Regress\u00e3o Log\u00edstica: o essencial.\nThis notebook was developed to show in pratical terms the knowledge about logistic regression at paper: Logistic Regression: the essential.","5dfa7bcd":"Verificando a quantidade de missing por vari\u00e1vel\n\nMissing data by column","ad69ac38":"Vemos que tivemos uma redu\u00e7\u00e3o consider\u00e1vel no n\u00famero de observa\u00e7\u00f5es em nossa tabela. A representatividade perdida, ap\u00f3s a tratativa de missing excluindo todos os dados perdidos, \u00e9 de 53%. Para bases de dados com tamanha extens\u00e3o de dados perdidos, o ideal \u00e9 realizar uma an\u00e1lise mais profunda acerca dos padr\u00f5es aleat\u00f3rios ou n\u00e3o aleat\u00f3rios dos dados perdidos. Para os intuitos introdut\u00f3rios desse kernel, vamos optar pela elimina\u00e7\u00e3o total dos dados missing.\n\nWe using that form to treated missing data because the intention of this notebook is just only show how a logistic regression model works. We know wich the best way to treat missing data is MCAR or CAR analysis when we have a lot of missing values. ","b3904f88":"Configurando a biblioteca","517e6bdc":"Importando a base de dados online\nImporting the dataset","b81fa80e":"\u00c9 comum utilizarmos n\u00f3s \"tunarmos\" nosso modelo em busca dos melhores parametros. Fa\u00e7o isso abaixo. Esta parte \u00e9 opcional.","ac3ad576":"Importando a biblioteca pandas profiling para construir as visualiza\u00e7\u00f5es gr\u00e1ficas mais comuns em an\u00e1lise explorat\u00f3ria (histogramas, tabelas de correla\u00e7\u00e3o, dentre outros). \nA an\u00e1lise explorat\u00f3ria \u00e9 um dos passos mais importantes de qualquer modelo. Uma an\u00e1lise explorat\u00f3ria mal feita pode enviesar os dados, geralmente, resultando em performance reduzida do modelo.","69b30f4a":"Aqui chegamos no momento de separar nossas bases. O m\u00e9todo de divis\u00e3o de bases em treino e teste \u00e9 o mais utilizado na comunidade de data science. Geralmente, 70% dos dados v\u00e3o para a base de treino e 30% ficam na base de teste. O motivo dessa divis\u00e3o \u00e9 simples: 1) a base de treino serve para que o modelo execute previs\u00f5es com os dados brutos. Ele faz isso a partir de tentativa e erro, reduzindo o erro a cada tentativa. No treino ele pode chegar ao overfiting (previs\u00e3o perfeita) de tanto treinar. J\u00e1 a 2) base de teste \u00e9 a mais fundamental, pois nos revelar\u00e1 como o modelo se comporta ao receber novos dados. ","741f9b88":"Substituindo os valores y,n,? por 1,0,NaN (missing)\nCriando a vari\u00e1vel Republican\nSubstituindo os valores de da vari\u00e1vel Class Name (republican e democrat) por (1 e 0);\n\nChanging y,n,? values for 1,0,NaN\nInput a new column: Republican\nChanging class name values for 1,0","7428ea86":"Verificando o tamanho da base de dados (quantidade de linhas totais)\nThe length of dataset","cf9fc582":"C\u00e1lculo do indicador da area under the curve (\u00e1rea sob a curva) que mostra a qualidade da nossa previs\u00e3o. Tivemos um excelente desempenho, acertando 0,9913. \nObs: o fato de ter eliminado os missing e reduzido a extens\u00e3o da base tem impacto direto.","97e8bd79":"We using train and test division to make our model.","8cbd5810":"Temos um total de 203 linhas sem dados perdidos (47%), o que significa dizer que 53% da nossa amostra possui dados perdidos nas observa\u00e7\u00f5es. Al\u00e9m disso, 100% das vari\u00e1veis possui dados perdidos. ","4d0e762e":"# Tratamento de missing\n\nMissing data treatment ","563abcfe":"Verificando os 10 primeiros valores da base de dados\nThe 10 first value","3085e0ea":"Regress\u00e3o log\u00edstica","952046cd":"# Rodando modelos","a2936905":"Nesta primeira tentativa, vamos construir um modelo eliminando todos os missing da amostra.\n\nThis model will exlude all missing data."}}