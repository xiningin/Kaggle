{"cell_type":{"85e45d9b":"code","60e428c0":"code","79fa1595":"code","a0cae4b3":"code","a2f8c3b1":"code","eee7110c":"code","15bc4902":"code","fca0cfa1":"code","cb06b470":"code","b76ccf0d":"code","d36e7492":"markdown","65d69656":"markdown","2b943218":"markdown","888848ab":"markdown","3094eba3":"markdown","8019fe32":"markdown","9fb4f339":"markdown","1074712d":"markdown","0004b25b":"markdown"},"source":{"85e45d9b":"pip install nltk","60e428c0":"import nltk","79fa1595":"import re\n\n#start process_tweet\ndef processTweet(tweet):\n    # process the tweets\n\n    #Convert to lower case\n    tweet = tweet.lower()\n    #Convert www.* or https?:\/\/* to URL\n    tweet = re.sub('((www\\.[^\\s]+)|(https?:\/\/[^\\s]+))','URL',tweet)\n    #Convert @username \n    tweet = re.sub('@[^\\s]+','',tweet)\n    #Remove additional white spaces\n    tweet = re.sub('[\\s]+', ' ', tweet)\n    #Replace #word with word\n    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n    #trim\n    tweet = tweet.strip('\\'\"')\n    return tweet\n#end\n\n#Read the tweets one by one and process it\nfp = open('..\/input\/sentiment\/sampleTweetsID.xls', 'r')\nline = fp.readline()\n\nwhile line:\n    processedTweet = processTweet(line)\n    print(processedTweet)\n    line = fp.readline()\n#end loop\nfp.close()","a0cae4b3":"stopWords = []\n\n#start replaceTwoOrMore\ndef replaceTwoOrMore(s):\n    #look for 2 or more repetitions of character and replace with the character itself\n    pattern = re.compile(r\"(.)\\1{1,}\", re.DOTALL)\n    return pattern.sub(r\"\\1\\1\", s)\n#end\n\n#start getStopWordList\ndef getStopWordList(stopWordListFileName):\n    #read the stopwords file and build a list\n    stopWords = []\n    stopWords.append('')\n    stopWords.append('URL')\n\n    fp = open(stopWordListFileName, 'r')\n    line = fp.readline()\n    while line:\n        word = line.strip()\n        stopWords.append(word)\n        line = fp.readline()\n    fp.close()\n    return stopWords\n#end\n\n#start getfeatureVector\ndef getFeatureVector(tweet):\n    featureVector = []\n    #split tweet into words\n    words = tweet.split()\n    for w in words:\n        #replace two or more with two occurrences\n        w = replaceTwoOrMore(w)\n        #strip punctuation\n        w = w.strip('\\'\"?,.')\n        #check if the word stats with an alphabet\n        val = re.search(r\"^[a-zA-Z][a-zA-Z0-9]*$\", w)\n        #ignore if it is a stop word\n        if(w in stopWords or val is None):\n            continue\n        else:\n            featureVector.append(w.lower())\n    return featureVector\n#end\n\n#Read the tweets one by one and process it\nfp = open('..\/input\/sentiment\/sampleTweetsID.xls', 'r')\nline = fp.readline()\n\nst = open('..\/input\/sentiment\/stopwordsID.txt', 'r')\nstopWords = getStopWordList('..\/input\/sentiment\/stopwordsID.txt')\n\nwhile line:\n    processedTweet = processTweet(line)\n    featureVector = getFeatureVector(processedTweet)\n    print(featureVector)\n    line = fp.readline()\n#end loop\nfp.close()","a2f8c3b1":"import csv\n\ninpTweets = csv.reader(open('..\/input\/sentiment\/sampleTweetsID.xls', 'r'), delimiter=',', quotechar='|')\ntweets = []\nfeatureList = []\nfor row in inpTweets:\n    sentiment = row[0]\n    tweet = row[1]\n    processedTweet = processTweet(tweet)\n    featureVector = getFeatureVector(processedTweet)\n    tweets.append((featureVector, sentiment))\n    featureList = featureList + featureVector\n#end loop\nprint(tweets)\nprint(featureList)","eee7110c":"#start extract_features\ndef extract_features(tweet):\n    tweet_words = set(tweet)\n    features = {}\n    for word in featureList:\n        features['contains(%s)' % word] = (word in tweet_words)\n    return features\n#end","15bc4902":"# Remove featureList duplicates\nfeatureList = list(set(featureList))","fca0cfa1":"# Generate the training set\ntraining_set = nltk.classify.util.apply_features(extract_features, tweets)","cb06b470":"# Train the Naive Bayes classifier\nNBClassifier = nltk.NaiveBayesClassifier.train(training_set)","b76ccf0d":"# Test the classifier\ntestTweet = 'Hari yang mengecewakan. Menghadiri pameran mobil untuk mencari pendanaan, harganya malah lebih mahal'\nprocessedTestTweet = processTweet(testTweet)\nsentiment = NBClassifier.classify(extract_features(getFeatureVector(processedTestTweet)))\nprint(\"testTweet = %s, sentiment = %s\\n\" % (testTweet, sentiment))","d36e7492":"**Membaca tweet satu per satu dan memprosesnya**","65d69656":"# Instalasi dan Import NLTK","2b943218":"**Cleaning data teks tweet dan menghapus stopwords**","888848ab":"# Memproses data training menggunakan Naive Bayes","3094eba3":"# Import data tweet","8019fe32":"Hasil akhir pada proses ini yaitu dapat melakukan analisa sentimen atau memberi label sentimen dari tweet atau kalimat yang dibuat secara manual kemudian model yang sudah kita latih sebelumnya akan melakukan prediksi apakah kalimat tersebut termasuk sentimen yang positif atau negatif.","9fb4f339":"Pada notebook kali ini saya melakukan prediksi sentimen menggunakan library NLTK menggunakan Naive Bayes Classifier untuk melatih data dan melakukan prediksi analisa sentimen.","1074712d":"# Memproses data training","0004b25b":"# Menguji Hasil training"}}