{"cell_type":{"232fcce9":"code","825e84af":"code","b504c3f0":"code","dc6ddc39":"code","a40bc988":"code","c818ea98":"code","ccd28b82":"code","867ab673":"code","4f1394fd":"code","b77f4d75":"code","d3b1dcd3":"code","368afd51":"code","050a6d96":"code","b9679de9":"code","581ee3dc":"code","4e123841":"code","804236c7":"code","58da4244":"code","75171640":"code","61fce7f0":"code","f99012e4":"markdown","5b4b63b2":"markdown","91df69e4":"markdown","c51e3905":"markdown","1018f568":"markdown","09993039":"markdown","f1f3c3cb":"markdown","0ea262ed":"markdown","5923fab9":"markdown","ee177058":"markdown","32810464":"markdown","a2595e7e":"markdown","9f6254cd":"markdown","e8da1f9a":"markdown"},"source":{"232fcce9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","825e84af":"import matplotlib.pyplot as plt\nimport cv2\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\nfrom keras.optimizers import SGD, Adam\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom keras.utils import to_categorical\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle","b504c3f0":"data = pd.read_csv(\"\/kaggle\/input\/az-handwritten-alphabets-in-csv-format\/A_Z Handwritten Data.csv\").astype('float32')\n","dc6ddc39":"data.head()","a40bc988":"data.tail()","c818ea98":"X = data.drop('0',axis = 1) # axis=1 for dropping column\ny = data['0']","ccd28b82":"X.head()","867ab673":"y.head()","4f1394fd":"X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.2)\n\nX_train = np.reshape(X_train.values, (X_train.shape[0], 28,28))\nX_test = np.reshape(X_test.values, (X_test.shape[0], 28,28)) #0=> B&W, 28x28 matrix\n\nprint(\"Train data shape: \", X_test.shape)\nprint(\"Test data shape: \", X_test.shape)","b77f4d75":"word_dict = {0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',9:'J',10:'K',11:'L',12:'M',13:'N',14:'O',15:'P',16:'Q',17:'R',18:'S',19:'T',20:'U',21:'V',22:'W',23:'X', 24:'Y',25:'Z'}","d3b1dcd3":"y_int = np.int0(y) \ncount = np.zeros(26, dtype='int') #a vector of size 26 with all 0 values\nfor i in y_int:\n    count[i] +=1 #total count of each alphabet\n\nalphabets = []\nfor i in word_dict.values():\n    alphabets.append(i) #all alphabets\n\nfig, ax = plt.subplots(1,1, figsize=(10,10))\nax.barh(alphabets, count)\n\nplt.xlabel(\"Number of elements \")\nplt.ylabel(\"Alphabets\")\nplt.grid()\nplt.show()","368afd51":"shuff = shuffle(X_train[:100])\n\nfig, ax = plt.subplots(3,3, figsize = (10,10))\naxes = ax.flatten()\n\nfor i in range(9):\n    _, shu = cv2.threshold(shuff[i], 30, 200, cv2.THRESH_BINARY)\n    axes[i].imshow(np.reshape(shuff[i], (28,28)), cmap=\"Greys\")\nplt.show()","050a6d96":"X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1) #RGB =>Channel of 1\nprint(\"New shape of train data: \", X_train.shape)\n\nX_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2],1) #RGB =>Channel of 1\nprint(\"New shape of train data: \", X_test.shape)","b9679de9":"train_yOHE = to_categorical(Y_train, num_classes = 26, dtype='int')\nprint(\"New shape of train labels: \", train_yOHE.shape)\n\ntest_yOHE = to_categorical(Y_test, num_classes = 26, dtype='int')\nprint(\"New shape of test labels: \", test_yOHE.shape)","581ee3dc":"model = Sequential()\n#CNN\n# input -> conv -> maxpool -> conv -> maxpool ......->flattened vector-> \n#.                        hidden layer -> hidden layer -> softmax layer\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\nmodel.add(MaxPool2D(pool_size=(2, 2), strides=2))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\nmodel.add(MaxPool2D(pool_size=(2, 2), strides=2))\n\nmodel.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\nmodel.add(MaxPool2D(pool_size=(2, 2), strides=2))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(64,activation =\"relu\"))\nmodel.add(Dense(128,activation =\"relu\"))\n\nmodel.add(Dense(26,activation =\"softmax\"))","4e123841":"model.compile(optimizer = Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nhistory = model.fit(X_train, train_yOHE, epochs=1,  validation_data = (X_test,test_yOHE))","804236c7":"model.summary()\nmodel.save(r'model_hand.h5')","58da4244":"print(\"The validation accuracy is :\", history.history['val_accuracy'])\nprint(\"The training accuracy is :\", history.history['accuracy'])\nprint(\"The validation loss is :\", history.history['val_loss'])\nprint(\"The training loss is :\", history.history['loss'])","75171640":"fig, axes = plt.subplots(3,3, figsize=(8,9))\naxes = axes.flatten()\n\nfor i,ax in enumerate(axes):\n    img = np.reshape(X_test[i], (28,28))\n    ax.imshow(img, cmap=\"Greys\")\n    \n    pred = word_dict[np.argmax(test_yOHE[i])]\n    ax.set_title(\"Prediction: \"+pred)\n    ax.grid()","61fce7f0":"fig, axes = plt.subplots(3,3, figsize=(8,9))\naxes = axes.flatten()\n\nfor i,ax in enumerate(axes):\n    img = np.reshape(X_test[i], (28,28)) # reshaping it for displaying\n    ax.imshow(img, cmap=\"Greys\")\n    img_final =np.reshape(img, (1,28,28,1)) # reshapng it for passing into model for prediction\n    pred = word_dict[np.argmax(model.predict(img_final))]\n    ax.set_title(\"Prediction: \"+pred)\n    ax.grid()","f99012e4":"# Read The Dataset\n","5b4b63b2":"# Reshaping data to feed to CNN","91df69e4":"# Displaying few letters","c51e3905":"# Making Predictions","1018f568":"# Reshaping the data to display it as image and splitting the Dataset as Test and Train data","09993039":"# Splitting Dataset into Labels and Images","f1f3c3cb":"# Building CNN Model","0ea262ed":"It is a 28x28 image flattened to 784 pixels","5923fab9":"# Importing Necessary Libraries","ee177058":"# Compiling and Training the CNN","32810464":"# Plotting Count of Each Alphabet in Dataset","a2595e7e":"# Printing Model Summary","9f6254cd":"# Creating dictionary of column number to corresponding letter","e8da1f9a":"# Converting Single float value to Categorical Values"}}