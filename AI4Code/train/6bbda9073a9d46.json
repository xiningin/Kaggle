{"cell_type":{"b547d5b6":"code","9b5d0a2c":"code","9fe17d62":"code","04f655b6":"code","cab01385":"code","3e259fe2":"code","60102a69":"code","d618d552":"code","db63f69d":"code","dec37e5b":"code","18ea7874":"code","e8e5b1e4":"code","990d208e":"code","f593ba6a":"code","d3693e43":"code","570ea799":"code","7a5a6bf7":"code","10282da0":"code","86a4b30e":"code","1142305e":"code","c1625ac1":"code","fa2ea5d4":"code","b7b66397":"code","70961e2a":"code","665cba5d":"code","3f2df35e":"code","35dbbd2d":"code","77ce9c43":"code","273f7492":"code","9b25992a":"code","3e8c4683":"code","58e6afe8":"code","fcd7352b":"code","2bdb8aaa":"code","7d2b7d57":"code","96c98fff":"code","d25cc8a0":"code","6a032a30":"code","349d1549":"code","e2c4d4d6":"code","caf4aad7":"code","921af134":"code","0e567d8c":"code","bfc36451":"code","d359055f":"code","146f828b":"code","548c82c9":"code","7f55044c":"code","b83420f8":"code","9a0d56f6":"code","2168b23b":"code","c35361d9":"code","abf472f5":"code","d7ad46c4":"code","ef49cf7a":"markdown","62f6c51f":"markdown","62eb0b07":"markdown","68269ec2":"markdown","1f0a5e8b":"markdown","7ba8f513":"markdown","e6156592":"markdown","b1278c78":"markdown","c10bc4ce":"markdown","d6404fa9":"markdown","458258d3":"markdown","6ac5c12b":"markdown","8bc2e08b":"markdown","c06d3c8f":"markdown","4b5ee36c":"markdown","c461cee5":"markdown","f7561bb7":"markdown","db201848":"markdown","9d022e43":"markdown","c9feefa5":"markdown"},"source":{"b547d5b6":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","9b5d0a2c":"bank_customers = pd.read_csv(\"..\/input\/bank-customer-churn-modeling\/Churn_Modelling.csv\")","9fe17d62":"bank_customers.head(10)","04f655b6":"bank_customers.info()","cab01385":"# Drop RowNumber and CustomerId because it won't be useful in predictive task\nbank_customers.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1, inplace=True)","3e259fe2":"# Convert object dtype into category\ncat_features = ['Geography', 'Gender', 'HasCrCard', 'IsActiveMember', 'NumOfProducts', 'Tenure']\nfor colname in cat_features:\n    bank_customers[colname] = bank_customers[colname].astype('category')","60102a69":"bank_customers[cat_features].nunique()","d618d552":"sns.countplot(x='Geography', data=bank_customers)","db63f69d":"sns.countplot(x='Gender', data=bank_customers)","dec37e5b":"sns.countplot(x='HasCrCard', data=bank_customers)","18ea7874":"sns.countplot(x='IsActiveMember', data=bank_customers)","e8e5b1e4":"sns.countplot(x='NumOfProducts', data=bank_customers)","990d208e":"sns.countplot(x='Tenure', data=bank_customers, color='blue')","f593ba6a":"bank_customers.groupby('Geography').mean()","d3693e43":"bank_customers.groupby('Gender').mean()","570ea799":"bank_customers.groupby('HasCrCard').mean()","7a5a6bf7":"bank_customers.groupby('IsActiveMember').mean()","10282da0":"bank_customers.groupby(\"NumOfProducts\").mean()","86a4b30e":"bank_customers.groupby('Tenure').mean()","1142305e":"bank_customers.groupby(\"Exited\").mean()","c1625ac1":"sns.countplot(x='NumOfProducts', hue='Exited', data=bank_customers)","fa2ea5d4":"sns.countplot(x=bank_customers['IsActiveMember'], hue=bank_customers['Exited'])","b7b66397":"sns.countplot(x=bank_customers[\"Gender\"], hue=bank_customers['Exited'])","70961e2a":"sns.boxplot(x=bank_customers['Geography'], y=bank_customers['Balance'])","665cba5d":"sns.boxplot(x=bank_customers['Geography'], y=bank_customers['Balance'], hue=bank_customers['Gender'])","3f2df35e":"bank_customers.columns\nnum_features = ['CreditScore', 'Age', 'Balance', 'EstimatedSalary']","35dbbd2d":"bank_customers[num_features].nunique()","77ce9c43":"bank_customers['CreditScore'].hist(bins=30, grid=False)","273f7492":"bank_customers[bank_customers['CreditScore'] == bank_customers['CreditScore'].max()]['Exited'].value_counts()","9b25992a":"bank_customers['Age'].hist(bins=30, grid=False)","3e8c4683":"bank_customers['Balance'].hist(bins=30, grid=False)","58e6afe8":"bank_customers[bank_customers['Balance'] == 0]['Exited'].value_counts()","fcd7352b":"bank_customers['EstimatedSalary'].hist(bins=30, grid=False)","2bdb8aaa":"#num_df = bank_customers[num_features + ['Exited']] \nsns.pairplot(bank_customers[num_features + ['Exited']] , hue='Exited')","7d2b7d57":"from sklearn.model_selection import train_test_split\nX = bank_customers.drop(['Exited'], axis = 1)\ny = bank_customers['Exited']\nX_train_valid, X_test, y_train_valid, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size = 0.25, random_state=42)","96c98fff":"from sklearn.metrics import classification_report\nfrom sklearn.dummy import DummyClassifier\ntarget_names = ['Did not Exit', \"Exited\"]\ndummy_clf = DummyClassifier(strategy=\"most_frequent\")\ndummy_clf.fit(X_train, y_train)\npred = dummy_clf.predict(X_train)\nprint(classification_report(y_train, pred))","d25cc8a0":"from sklearn.preprocessing import StandardScaler\nss = StandardScaler()\nstandardized_df = pd.DataFrame(ss.fit_transform(bank_customers[num_features]), columns = num_features)\nstandardized_df['Exited'] = bank_customers['Exited']","6a032a30":"from sklearn.preprocessing import LabelEncoder\nle_geography = LabelEncoder()\nle_gender = LabelEncoder()\nle_HasCrCard = LabelEncoder()\nle_IsActiveMember = LabelEncoder()\nle_NumOfProducts = LabelEncoder()\nle_Tenure = LabelEncoder()\n\nle_df = pd.DataFrame()\n\nle_df['Geography'] = le_geography.fit_transform(bank_customers['Geography'])\nle_df['Gender'] = le_gender.fit_transform(bank_customers['Gender'])\nle_df['HasCrCard'] = le_HasCrCard.fit_transform(bank_customers['HasCrCard'])\nle_df['IsActiveMember'] = le_IsActiveMember.fit_transform(bank_customers['IsActiveMember'])\nle_df['NumOfProducts'] = le_NumOfProducts.fit_transform(bank_customers['NumOfProducts'])\nle_df['Tenure'] = le_Tenure.fit_transform(bank_customers['Tenure'])\n\nle_df.head()","349d1549":"model_df = pd.concat([standardized_df,le_df],axis=1)\nmodel_df.head()","e2c4d4d6":"X = model_df.drop(['Exited'],axis=1)\ny = model_df['Exited']\nX_train, x_test, y_train, y_test = train_test_split(X,y)","caf4aad7":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree\nfrom sklearn.metrics import mean_squared_error\n\ndt_clf = DecisionTreeClassifier(max_depth=5,max_features='sqrt')\n\ndt_clf.fit(X_train, y_train)\npred = dt_clf.predict(x_test)\nprint(classification_report(y_test, pred))\nfig, ax = plt.subplots(figsize=(20, 20))\ntree.plot_tree(dt_clf.fit(X_train, y_train), ax=ax, filled=True)\nplt.show()","921af134":"from sklearn.neighbors import KNeighborsClassifier\nneigh = KNeighborsClassifier(n_neighbors=3)\nneigh.fit(X_train, y_train)\npred = neigh.predict(x_test)\nprint(classification_report(y_test, pred))","0e567d8c":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=1800, min_samples_split=2, \n                             min_samples_leaf=1, max_features='auto', \n                             max_depth=10, bootstrap=True)\nrf.fit(X_train,y_train)\npred = rf.predict(x_test)\nprint(classification_report(y_test, pred))","bfc36451":"from sklearn.ensemble import AdaBoostClassifier\nada_clf = AdaBoostClassifier(n_estimators=1800)\nada_clf.fit(X_train, y_train)\npred = ada_clf.predict(x_test)\nprint(classification_report(y_test, pred))","d359055f":"from sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\n \ngpc = GaussianProcessClassifier().fit(X_train, y_train)","146f828b":"gpc.score(X_train, y_train)","548c82c9":"from sklearn.naive_bayes import GaussianNB\nGNB_clf = GaussianNB()\nGNB_clf.fit(X_train, y_train)\npred = GNB_clf.predict(x_test)\nprint(classification_report(y_test, pred))","7f55044c":"from sklearn.svm import SVC\nfrom sklearn.pipeline import make_pipeline\nsvc_clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\nsvc_clf.fit(X_train, y_train)\npred = svc_clf.predict(x_test)\nprint(classification_report(y_test, pred))","b83420f8":"from sklearn.neural_network import MLPClassifier\nMLP_clf = MLPClassifier(max_iter=3000).fit(X_train, y_train)\npred = MLP_clf.predict(x_test)\nprint(classification_report(y_test, pred))","9a0d56f6":"rf = RandomForestClassifier(n_estimators=1800, min_samples_split=2, \n                             min_samples_leaf=1, max_features='auto', \n                             max_depth=10, bootstrap=True)\nrf.fit(X_train,y_train)\npred = rf.predict(x_test)\nprint(classification_report(y_test, pred))","2168b23b":"from sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import uniform\n\n\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n\nmax_features = ['auto', 'sqrt']\n\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n\nmin_samples_split = [2, 5, 10]\n\nmin_samples_leaf = [1, 2, 4]\n\nbootstrap = [True, False]\n\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\n\n\nclf = RandomizedSearchCV(rf, random_grid)\nsearch = clf.fit(X_train,y_train)\nsearch.best_params_","c35361d9":"X_train, x_test, y_train, y_test = train_test_split(X,y,train_size=0.8)","abf472f5":"rf = RandomForestClassifier(n_estimators=2000, min_samples_split=2, \n                             min_samples_leaf=4, max_features='auto', \n                             max_depth=50, bootstrap=True)\nrf.fit(X_train,y_train)\npred = rf.predict(x_test)\nprint(classification_report(y_test, pred))","d7ad46c4":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test, pred)","ef49cf7a":"**Numerical Features**","62f6c51f":"## Now that we have our Data in the desired form, we will be testing alot of different models:","62eb0b07":"Interesting finding: \n\n~ Features ~\n\n- Out of all the customers who have the highest credit score, about 81% of them didn't exit.\n- A third of the customers didn't deposit any money. Out of all these customers, about 86% of them exit.\n\n~ Model ~\n\n- Since most of the data overlaps, it's better we choose a non-linear classifier (decision tree, random forest, kNN etc.)","68269ec2":"**Categorical Features**","1f0a5e8b":"# Final Model:","7ba8f513":"## Splitting into train\/test\/validation","e6156592":"### We also want to see how a GaussionProcessClassifier performs:","b1278c78":"### Now let's try a KNN Classifier:","c10bc4ce":"Interesting Findings:\n\n    1) ","d6404fa9":"## Hyperparameter tuning our Final Model and finalizing the tests","458258d3":"### Along with these we are going to test a SVC model:","6ac5c12b":"## Ultimately we are going to be moving forward with RandomForest:","8bc2e08b":"## Feature Engineering","c06d3c8f":"### Finally we are going to try a Neural Network model, MLPClassifier:","4b5ee36c":"### First, Let's do a DecisionTree:","c461cee5":"### Here we are seeing how a GaussianNB model performs on our Data:","f7561bb7":"## Exploratory Data Analysis (EDA)","db201848":"## Now that we have tried 8 different Models we evaluate the outputs.","9d022e43":"### Continuing with our Models, we are going to see how AdaBoost performs on our Data:","c9feefa5":"### Taking this further we develop a RandomForestClassifier:"}}