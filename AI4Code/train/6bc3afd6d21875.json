{"cell_type":{"5ccbf1df":"code","368c50f5":"code","9af76754":"code","bc6810aa":"code","053a7440":"code","c5f3a571":"code","1126a3e7":"code","b9104091":"code","ba0e2932":"code","fdaef541":"code","3cd18da6":"code","c79aa06b":"code","36171b61":"code","f54fe8c2":"code","bea321d1":"code","e5ae1ac4":"code","bc40bec9":"code","f814f2a7":"code","74001fe4":"code","70df0364":"code","4000d6ed":"code","1f18d921":"code","3eccae46":"code","2266875f":"code","17930c3b":"code","ed938f9f":"code","9fac99fc":"code","c7dcc791":"code","33de99e3":"code","99e12d89":"code","d4c21ac9":"code","ffe72029":"markdown","aeac5d6c":"markdown","45bb7ae5":"markdown","52941b5a":"markdown","81906093":"markdown","bc762c23":"markdown","869a7cb5":"markdown","bf930c7b":"markdown","c904e9d8":"markdown","91ebed7f":"markdown","3f838e07":"markdown","90c78d95":"markdown","e9e36720":"markdown","1f013188":"markdown","44fe2ae5":"markdown","dfe619c9":"markdown","4689c2e4":"markdown","338be7f1":"markdown","873d6b75":"markdown","155a509b":"markdown","240e3ad7":"markdown","771435d6":"markdown","331191a2":"markdown","1f1cff34":"markdown"},"source":{"5ccbf1df":"import os, shutil\n# our dataset (only the train folder)\n\noriginal_dataset_dir = \"..\/input\/dogs-vs-cats\/train\/train\"    # we were asked to work with train part only for practice.\n\nprint('total images in train folder: ', len(os.listdir(original_dataset_dir)))\n# Create a Directory where we\u2019ll store our dataset\nbase_dir = \"..\/dog-cat-small\"\nos.mkdir(\"..\/dog-cat-small\")\n\n# directories for the training, validation and test splits\ntrain_dir = os.path.join(base_dir, 'train')\nos.mkdir(train_dir)\nvalidation_dir = os.path.join(base_dir, 'validation')\nos.mkdir(validation_dir)\ntest_dir = os.path.join(base_dir, 'test')\nos.mkdir(test_dir)\n\n# directory with training cat pictures\ntrain_cats_dir = os.path.join(train_dir, 'cats')\nos.mkdir(train_cats_dir)\n\n# directory with training dog pictures\ntrain_dogs_dir = os.path.join(train_dir, 'dogs')\nos.mkdir(train_dogs_dir)\n\n# directory with validation cat pictures\nvalidation_cats_dir = os.path.join(validation_dir, 'cats')\nos.mkdir(validation_cats_dir)\n\n# directory with validation dog pictures\nvalidation_dogs_dir = os.path.join(validation_dir, 'dogs')\nos.mkdir(validation_dogs_dir)\n\n# directory with test cat pictures\ntest_cats_dir = os.path.join(test_dir, 'cats')\nos.mkdir(test_cats_dir)\n\n# directory with test dog pictures\ntest_dogs_dir = os.path.join(test_dir, 'dogs')\nos.mkdir(test_dogs_dir)\n\n# copies the first 8750 cat images to train_cats_dir\nfnames = ['cat.{}.jpg'.format(i) for i in range(8750)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(train_cats_dir, fname)\n    shutil.copyfile(src, dst)\n\n# copies the next 2500 cat images to validation_cats_dir\nfnames = ['cat.{}.jpg'.format(i) for i in range(8750, 11250)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(validation_cats_dir, fname)\n    shutil.copyfile(src, dst)\n\n# copies the next 1250 cat images to test_cats_dir\nfnames = ['cat.{}.jpg'.format(i) for i in range(11250, 12500)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(test_cats_dir, fname)\n    shutil.copyfile(src, dst)\n\n# copies the first 8750 dog images to train_dogs_dir\nfnames = ['dog.{}.jpg'.format(i) for i in range(8750)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(train_dogs_dir, fname)\n    shutil.copyfile(src, dst)\n\n# copies the first 2500 dog images to validation_dogs_dir\nfnames = ['dog.{}.jpg'.format(i) for i in range(8750, 11250)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(validation_dogs_dir, fname)\n    shutil.copyfile(src, dst)\n\n# copies the first 1250 dog images to test_dogs_dir\nfnames = ['dog.{}.jpg'.format(i) for i in range(11250, 12500)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(test_dogs_dir, fname)\n    shutil.copyfile(src, dst)","368c50f5":"# Seeing the content count of the splits\nprint('total training cat images:', len(os.listdir(train_cats_dir)))\nprint('total training dog images:', len(os.listdir(train_dogs_dir)))\nprint('total validation cat images:', len(os.listdir(validation_cats_dir)))\nprint('total validation dog images:', len(os.listdir(validation_dogs_dir)))\nprint('total test cat images:', len(os.listdir(test_cats_dir)))\nprint('total test dog images:', len(os.listdir(test_dogs_dir)))","9af76754":"# importing the dependencies\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","bc6810aa":"# Instantiating a small convnet for dogs vs. cats classification\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\n# checking dimensions of the feature maps changing with successive layers\nmodel.summary()","053a7440":"# Configuring the model for training\n# using RMSProp optimizer because of using sigmoid unit in the end and using binary cross entropy as loss\nmodel.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])","c5f3a571":"# rescaling all images by 255\ntrain_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\n# Resizing all images to 150 X 150 and using binary_crossentropy loss coz we need binary labels\ntrain_generator = train_datagen.flow_from_directory(train_dir, target_size=(150, 150), batch_size=20, class_mode='binary')\nvalidation_generator = test_datagen.flow_from_directory(validation_dir, target_size=(150, 150), batch_size=20, class_mode='binary')","1126a3e7":"# checking the output of one of the generators\nfor data_batch, labels_batch in train_generator:\n    print('data batch shape: ', data_batch.shape)\n    print('labels batch shape: ', labels_batch.shape)\n    break","b9104091":"history = model.fit_generator(train_generator,steps_per_epoch=100,epochs=30,validation_data=validation_generator,validation_steps=50)","ba0e2932":"model.save('cats_and_dogs_small_1.h5')","fdaef541":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","3cd18da6":"datagen = ImageDataGenerator(rotation_range=40, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')\n\n# Displaying randomly generated training images\n\nfnames =  [os.path.join(train_cats_dir, fname) for fname in os.listdir(train_cats_dir)]\nimg_path = fnames[3] # chooses an image to augment\nimg = image.load_img(img_path, target_size=(150, 150)) # Reads the image & resizes it\nx = image.img_to_array(img)  # converts img into an np array of shape (150, 150, 3)\nx = x.reshape((1, ) + x.shape)  # reshapes it to (1, 150, 150, 3)\ni=0\nfor batch in datagen.flow(x, batch_size=1):\n    plt.figure(i)\n    imgplot = plt.imshow(image.array_to_img(batch[0]))\n    i+=1\n    if i%4 == 0:\n        break # you need to break the loop at some pont bcoz the loop is indefinitely looping & generating batches of randomly transformed images infinitely\n\nplt.show()","c79aa06b":"model = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu',\n                        input_shape=(150, 150, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',optimizer=optimizers.RMSprop(lr=1e-4),metrics=['acc'])","36171b61":"train_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,)\n\n# Note that the validation data should not be augmented!\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        # This is the target directory\n        train_dir,\n        # All images will be resized to 150x150\n        target_size=(150, 150),\n        batch_size=50,\n        # Since we use binary_crossentropy loss, we need binary labels\n        class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n        validation_dir,\n        target_size=(150, 150),\n        batch_size=50,\n        class_mode='binary')\n\nhistory = model.fit_generator(\n      train_generator,\n      steps_per_epoch=350,\n      epochs=50,\n      validation_data=validation_generator,\n      validation_steps=50)","f54fe8c2":"model.save('cats_and_dogs_small_2.h5')","bea321d1":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","e5ae1ac4":"test_generator = test_datagen.flow_from_directory(test_dir,target_size=(150, 150),batch_size=20,class_mode='binary')\ntest_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\nprint('test acc: ', test_acc)","bc40bec9":"from keras.applications import VGG16","f814f2a7":"conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(150,150, 3))","74001fe4":"conv_base.summary()","70df0364":"pretrained_model = models.Sequential()\npretrained_model.add(conv_base)\npretrained_model.add(layers.Flatten())\npretrained_model.add(layers.Dense(256, activation='relu'))\npretrained_model.add(layers.Dense(1, activation='sigmoid'))\npretrained_model.summary()","4000d6ed":" print('This is the number of trainable weights before freezing the conv base:', len(pretrained_model.trainable_weights))","1f18d921":"conv_base.trainable=False\nprint('The number of trainable weights after freezing the conv base: ',len(pretrained_model.trainable_weights) )","3eccae46":"train_datagen = ImageDataGenerator(rescale=1.\/255,rotation_range=40,width_shift_range=0.2,height_shift_range=0.2,shear_range=0.2,zoom_range=0.2,horizontal_flip=True,fill_mode='nearest')\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\ntrain_generator = train_datagen.flow_from_directory(train_dir,target_size=(150, 150),batch_size=50,class_mode='binary')\nvalidation_generator = test_datagen.flow_from_directory(validation_dir,target_size=(150, 150),batch_size=50,class_mode='binary')\npretrained_model.compile(loss='binary_crossentropy',optimizer=optimizers.RMSprop(lr=2e-5),metrics=['acc'])\nhistory = pretrained_model.fit_generator(train_generator,steps_per_epoch=350,epochs=50,validation_data=validation_generator,validation_steps=50)","2266875f":"pretrained_model.save('\/kaggle\/working\/cats_and_dogs_small_3.h5')\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","17930c3b":"# our model currently looks like the following:\nconv_base.summary()","ed938f9f":"conv_base.trainable= True\nset_trainable = False\n\nfor layer in conv_base.layers:\n    if layer.name == 'block5_conv1':\n        set_trainable=True\n    if set_trainable:\n        layer.trainable=True\n    else:\n        layer.trainable = False","9fac99fc":"pretrained_model.compile(loss='binary_crossentropy',optimizer=optimizers.RMSprop(lr=1e-5),metrics=['acc'])\nhistory = pretrained_model.fit_generator(train_generator,steps_per_epoch=350,epochs=50,validation_data=validation_generator,validation_steps=50)","c7dcc791":"pretrained_model.save('\/kaggle\/working\/cats_and_dogs_small_4.h5')\n\n# Plotting the train and validation accuracy and lossed again\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","33de99e3":"def smooth_curve(points, factor=0.8):\n    smoothed_points = []\n    for point in points:\n        if smoothed_points:\n            previous = smoothed_points[-1]\n            smoothed_points.append(previous * factor + point * (1 - factor))\n        else:\n            smoothed_points.append(point)\n    return smoothed_points\n\nplt.plot(epochs,smooth_curve(acc), 'bo', label='Smoothed training acc')\nplt.plot(epochs,smooth_curve(val_acc), 'b', label='Smoothed validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs,smooth_curve(loss), 'bo', label='Smoothed training loss')\nplt.plot(epochs,smooth_curve(val_loss), 'b', label='Smoothed validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","99e12d89":"test_generator = test_datagen.flow_from_directory(test_dir,target_size=(150, 150),batch_size=20,class_mode='binary')\ntest_loss, test_acc = pretrained_model.evaluate_generator(test_generator, steps=50)\nprint('test acc: ', test_acc)","d4c21ac9":"# Do not run this code yet\n\n# from sklearn.metrics import accuracy_score, confusion_matrix\n# pred= pretrained_model.predict_generator(test_generator)\n# acc = accuracy_score(test_generator.labels, np.round(pred))*100\n# cm = confusion_matrix(test_generator.labels, np.round(pred))\n# tn, fp, fn, tp = cm.ravel()\n\n# print('\\n============TEST METRICS=============')\n# precision = tp\/(tp+fp)*100\n# recall = tp\/(tp+fn)*100\n# print('Accuracy: {}%'.format(acc))\n# print('Precision: {}%'.format(precision))\n# print('Recall: {}%'.format(recall))\n# print('F1-score: {}'.format(2*precision*recall\/(precision+recall)))","ffe72029":"**Importing the dependencies**","aeac5d6c":"The final feature map has shape (4, 4, 512). That\u2019s the feature on top of which you\u2019ll\nstick a densely connected classifier.\n At this point, there are two ways you could proceed:\n\uf0a1 Running the convolutional base over your dataset, recording its output to a\nNumpy array on disk, and then using this data as input to a standalone, densely\nconnected classifier similar to those you saw in part 1 of this book. This solution\nis fast and cheap to run, because it only requires running the convolutional\nbase once for every input image, and the convolutional base is by far the most\nexpensive part of the pipeline. But for the same reason, this technique won\u2019t\nallow you to use data augmentation.\n\nExtending the model you have (conv_base) by adding Dense layers on top, and\nrunning the whole thing end to end on the input data. This will allow you to use\ndata augmentation, because every input image goes through the convolutional\nbase every time it\u2019s seen by the model. But for the same reason, this technique is\nfar more expensive than the first.\n\nIn our case, we have a good GPU on our hands in both Colab and Kaggle. So, we will continue with the latter approach.","45bb7ae5":"begin fine-tuning the network. You\u2019ll do this with the RMSProp optimizer, using a very low learning rate. The reason for using a low learning rate is that\nyou want to limit the magnitude of the modifications you make to the representations\nof the three layers you\u2019re fine-tuning. Updates that are too large may harm these representations.\n\n**Fine-Tuning the model**","52941b5a":"The above plot shows that we need to regularize the model indicated by the spikes showing the fluctuation of validation set performance. We may want to use dropout regularization.\n\n**Using Data Augmentation**\n\nData augmentation takes the approach of generating more training data from existing training samples, by augmenting the samples via a number of random transformations that yield believable-looking images. The goal is that at training time, your model will never see the exact same picture twice. This helps expose the model to more aspects of the data and generalize better.\n\nthis can be done by configuring a number of random transformations to be performed on the images read by the ImageDataGenerator instance.\n\n**Setting up a data augmentation config via ImageDataGenerator**","81906093":"**Building the network**","bc762c23":"**Getting the data and copying into Train, Validation and Test Categories**","869a7cb5":"The above generator it yields batches of 150 \u00d7 150 RGB images (shape (20, 150, 150, 3)) and binary labels (shape (20,)). There are 20 samples in each batch (the batch size). Note that the generator yields these batches indefinitely: it loops endlessly over the images in the target folder. For this reason, you need to break the iteration loop at some point.\n\n**Fitting the model using a batch generator**\n\n fit the model to the data using the generator. do so using the fit_generator\nmethod, the equivalent of fit for data generators like this one. When using fit_generator, you can pass a validation_data argument, much as\nwith the fit method. It\u2019s important to note that this argument is allowed to be a data\ngenerator, but it could also be a tuple of Numpy arrays. If you pass a generator as\nvalidation_data, then this generator is expected to yield batches of validation data\nendlessly; thus you should also specify the validation_steps argument, which tells\nthe process how many batches to draw from the validation generator for evaluation.","bf930c7b":"**Smoothing the plots**","c904e9d8":"**Instantiating a VGG16 convolutional base**","91ebed7f":"**Configuring the model for training**","3f838e07":"Before compiling and training the model, , it\u2019s very important to freeze the convolutional base. Freezing a layer or set of layers means preventing their weights from being\nupdated during training. If you don\u2019t do this, then the representations that were previously learned by the convolutional base will be modified during training. Because\nthe Dense layers on top are randomly initialized, very large weight updates would be\npropagated through the network, effectively destroying the representations previously\nlearned.\n In Keras, you freeze a network by setting its trainable attribute to False.","90c78d95":"Feature Extraction with Data Augmentation: Much more slower and expensive than without data augmentation but allows data augmentation during training: extending the conv_base model and running it end to end on the inputs.","e9e36720":"**Saving the Model**","1f013188":"The validation accuracy curve look much cleaner and we see a slight improvement in the accuracy.\n\nNote that the loss curve doesn\u2019t show any real improvement (in fact, it\u2019s deteriorating). You may wonder, how could accuracy stay stable or improve if the loss isn\u2019t\ndecreasing? The answer is simple: what you display is an average of pointwise loss values; but what matters for accuracy is the distribution of the loss values, not their average, because accuracy is the result of a binary thresholding of the class probability\npredicted by the model. The model may still be improving even if this isn\u2019t reflected\nin the average loss.\n\nWe can now finally evaluate this model on the test data.\n\n**Result evaluation on test set**","44fe2ae5":"With this setup, only the weights from the two Dense layers that you added will be\ntrained. That\u2019s a total of four weight tensors: two per layer (the main weight matrix\nand the bias vector). Note that in order for these changes to take effect, you must first\ncompile the model. If you ever modify weight trainability after compilation, you\nshould then recompile the model, or these changes will be ignored.","dfe619c9":"**Data Preprocessing**\n\nData should be formatted into approximately preprocessed floating-point tensors before being fed into the network. Currently, the data sits on a drive as JPEG files, so the steps for getting it into the network are roughly as follows:\n\n1 Read the picture files.\n\n2 Decode the JPEG content to RGB grids of pixels.\n\n3 Convert these into floating-point tensors.\n\n4 Rescale the pixel values (between 0 and 255) to the [0, 1] interval (as you know, neural networks prefer to deal with small input values).\n\nKeras has utilities to take care of these steps automatically. Keras has a module with image-processing helper tools, located at keras.preprocessing.image. In particular, it contains the class ImageDataGenerator, which lets you quickly set up Python generators that can automatically turn image files on disk into batches of preprocessed tensors.\n\n**Using ImageDataGenerator to read images from directions**","4689c2e4":"**Training the ConvNet using Data-Augmentation Generation**","338be7f1":"Well, in comparison with the previous models, this one gains the highest accuracy. In some instances, this pretrained model, scores about 96.28% as well. The score differs because of the random intitialization each time. You can keep it fixed on every run passing a number to random.seed() in the beginning of the kernel if you want.","873d6b75":"**Freezing all layers up to a specific one**","155a509b":"**Plotting accuracy of train and validation set**","240e3ad7":"**Finally, if you like the kernel, please give it an upvote and show support which keeps us motivated. If you think of some potential improvements in the kernel, please provide feedback in the comment section down below.**","771435d6":"**Fine Tuning**\n\nAnother widely used technique for model reuse, complementary to feature\nextraction, is fine-tuning (see figure 5.19). Fine-tuning consists of unfreezing a few of\nthe top layers of a frozen model base used for feature extraction, and jointly training\nboth the newly added part of the model (in this case, the fully connected classifier)\nand these top layers. This is called fine-tuning because it slightly adjusts the more\nabstract representations of the model being reused, in order to make them more relevant for the problem at hand.\n\n\nstated earlier that it\u2019s necessary to freeze the convolution base of VGG16 in order to\nbe able to train a randomly initialized classifier on top. For the same reason, it\u2019s only\npossible to fine-tune the top layers of the convolutional base once the classifier on top\nhas already been trained. If the classifier isn\u2019t already trained, then the error signal\npropagating through the network during training will be too large, and the representations previously learned by the layers being fine-tuned will be destroyed. Thus the\nsteps for fine-tuning a network are as follow:\n\n1 Add your custom network on top of an already-trained base network.\n\n2 Freeze the base network.\n\n3 Train the part you added.\n\n4 Unfreeze some layers in the base network.\n\n5 Jointly train both these layers and the part you added\n","331191a2":"**Defining convnet that includes dropout**\n\nWe will use a dropout layer to the model, right before the densely connected classifier and see how that goes.","1f1cff34":"**Results on test set**"}}