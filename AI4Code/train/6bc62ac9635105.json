{"cell_type":{"76f44a10":"code","308d5fd1":"code","5143788c":"code","f3b7cda4":"code","fa534d3d":"code","2bdfc3bc":"code","3284fea3":"code","2fdc3619":"code","0f358560":"code","30630acc":"code","5e7bfbf6":"code","1b1853b1":"code","44d07846":"code","5d45f4e4":"code","9fc5d829":"code","f455583c":"code","a7b58965":"code","22294103":"code","e2fcbc5a":"code","4a9492ee":"code","cc50e1aa":"code","cbf616e7":"code","1a1b08ae":"code","96534730":"code","f306fb07":"markdown","4d0a8102":"markdown","eea15add":"markdown","ef72314b":"markdown","13aacc23":"markdown","e9be59b4":"markdown","f998c219":"markdown","89ce6fe9":"markdown","4760b6a1":"markdown","e849ac64":"markdown","75b4eaa3":"markdown"},"source":{"76f44a10":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","308d5fd1":"df = pd.read_csv('\/kaggle\/input\/heart-disease-uci\/heart.csv')\ndf.head()","5143788c":"df.info()","f3b7cda4":"df.describe()","fa534d3d":"df_eda = df.copy()\ndf_eda.head()","2bdfc3bc":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nsns.set()\nsns.set(rc={'figure.figsize':(15,10)})\nprint(df_eda.sex.value_counts())\n\nsns.catplot(x='sex', kind='count', data=df_eda)\nplt.show()","3284fea3":"sns.histplot(x='age', hue='sex', kde=True, data=df_eda)\nplt.show()\nplt.close()","2fdc3619":"# df_eda.target.value_counts()","0f358560":"from plotly.offline import init_notebook_mode, iplot, plot\n\nlabels = df_eda[df_eda['target'] == 1]['sex'].value_counts().index\npie1 = df_eda[df_eda['target'] == 1]['sex'].value_counts().values\n\n\nfig = {\n  \"data\": [\n    {\n      \"values\": pie1,\n      \"labels\": labels,\n      \"domain\": {\"x\": [0, .5]},\n      \"name\": \"\",\n      \"hoverinfo\":\"label+percent+name+value\",\n      \"hole\": .2,\n      \"type\": \"pie\"\n    },],\n  \"layout\": {\n        \"title\":\"Distribution of Target by Gender\",\n        \"annotations\": [\n            { \"font\": { \"size\": 25},\n              \"showarrow\": True,\n              \"text\": \"DEATH\",\n                \"x\": 1,\n                \"y\": 1,\n            },\n        ]\n    }\n}\niplot(fig)","30630acc":"df_eda.hist(figsize=(12,9))\nplt.show()","5e7bfbf6":"X = df.drop('target', axis=1)\ny = df['target']","1b1853b1":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nscaler.fit(X)\nX_scaled = scaler.transform(X)","44d07846":"X_scaled","5d45f4e4":"from sklearn.model_selection import train_test_split, GridSearchCV\n\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=42)\nX_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=1)\n\nprint(X_train.shape)\nprint(X_valid.shape)\nprint(X_test.shape)","9fc5d829":"from sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier","f455583c":"svc = SVC(C=100, kernel='linear')\nsvc.fit(X_train, y_train)\nprint(\"Score of Train : \", svc.score(X_train, y_train))\nprint(\"Score of Validation : \", svc.score(X_valid, y_valid))\n\ny_pred = svc.predict(X_test)\nsvc_accuracy = accuracy_score(y_pred, y_test)\nprint(\"Score of Test : \", svc_accuracy)\nprint(classification_report(y_pred, y_test))","a7b58965":"rf = RandomForestClassifier()\nrf.fit(X_train, y_train)\n\nprint(\"Score of Trained Model : \", rf.score(X_train, y_train))\nprint(\"Score of Validation Model : \", rf.score(X_valid, y_valid))\n\ny_pred = rf.predict(X_test)\nrf_accuracy = accuracy_score(y_pred, y_test)\nprint(\"Score of Test : \", rf_accuracy)\nprint(classification_report(y_pred, y_test))","22294103":"gbc = GradientBoostingClassifier()\ngbc.fit(X_train, y_train)\n\nprint(\"Score of Trained Model : \", gbc.score(X_train, y_train))\nprint(\"Score of Test Model : \", gbc.score(X_valid, y_valid))\n\ny_pred = gbc.predict(X_test)\ngbc_accuracy = accuracy_score(y_pred, y_test)\nprint(\"Score of Test : \", gbc_accuracy)\nprint(classification_report(y_pred, y_test))","e2fcbc5a":"dtc = DecisionTreeClassifier()\ndtc.fit(X_train, y_train)\n\nprint(\"Score of Trained Model : \", dtc.score(X_train, y_train))\nprint(\"Score of Test Model : \", dtc.score(X_test, y_test))\n\ny_pred = dtc.predict(X_test)\ndtc_accuracy = accuracy_score(y_pred, y_test)\nprint(classification_report(y_pred, y_test))","4a9492ee":"knn = KNeighborsClassifier(n_neighbors=10)\nknn.fit(X_train, y_train)\n\nprint(\"Score of Trained Model : \", knn.score(X_train, y_train))\nprint(\"Score of Test Model : \", knn.score(X_valid, y_valid))\n\ny_pred = knn.predict(X_test)\nknn_accuracy = accuracy_score(y_pred, y_test)\nprint(\"Score of Test : \", knn_accuracy)\nprint(classification_report(y_pred, y_test))","cc50e1aa":"label_model = ['SVC', 'Random Forest', 'Gradient Boosting', 'Decision Tree', 'KNN']\naccuracy = [svc_accuracy, rf_accuracy, gbc_accuracy, dtc_accuracy, knn_accuracy]\n\nfor i in range(len(label_model)):\n    print(\"{} accuracy : {}\".format(label_model[i], accuracy[i]))","cbf616e7":"plt.figure(figsize=(12,9))\nplt.bar(label_model, accuracy)\nplt.show()","1a1b08ae":"accuracy_val = []\nfor i in range(10,15,1):\n    model = KNeighborsClassifier(n_neighbors=i)\n    model.fit(X_train, y_train)\n    model_pred = model.predict(X_test)\n    accuracy = accuracy_score(model_pred, y_test)\n    accuracy_val.append(accuracy)\nplt.figure(figsize=(12,9))\nplt.plot(range(10,15,1), accuracy_val)\nplt.show()","96534730":"accuracy_val = []\nfor i in [100, 200, 300, 400, 500]:\n    model = SVC(C = i, kernel='linear')\n    model.fit(X_train, y_train)\n    model_pred = model.predict(X_test)\n    accuracy = accuracy_score(model_pred, y_test)\n    accuracy_val.append(accuracy)\nplt.figure(figsize=(12,9))\nplt.plot([100, 200, 300, 400, 500], accuracy_val)\nplt.show()","f306fb07":"## Column Information\n* Age (age) is the age of candidate\n* Sex (sex) has numeric values. 1 denotes male and 0 denotes female\n* Chest Pain (cp) pain has values between 0-3. The types of angina that are described in the research paper. The higher the number, the lesser are the odds of heart attack\n* Resting Blood Pressure (trtbps) is normal pressure with no exercise\n* Cholesterol (chol) means the blockage for blood supply in the blood vessels\n* Fasting Blood Pressure (fbs) is blood sugar taken after a long gap between a meal and the test. Typically, it's taken before any meal in the morning\n* Rest ECG (restecg) results means ECG values taken while person is on rest which means no exercise and normal functioning of heart is happening\n* Maximum Heart Rate (thalachh) achieved\n* Exercise Induced Angina (exng) is chest pain while exercising or doing any physical activity\n* ST Depression (oldpeak) is the difference between value of ECG at rest and after exercise\n* ST Slope (slp) is the tangent to the depression value\n* Number of Major Blood Vessels (caa) supplying blood to heart blocked\n* Types of Thalassemia (thall)\n* Heart Attack (target) where 1 denotes Heart Attack suffered and 0 where it did not take place","4d0a8102":"## SVM VS KNN ","eea15add":"## Model Prediction","ef72314b":"### Gradient Boosting","13aacc23":"### Random Forest Classifier","e9be59b4":"### KNN","f998c219":"### Decission Tree","89ce6fe9":"### SVC","4760b6a1":"## Splitting Data","e849ac64":"## EDA","75b4eaa3":"## Data Preprocessing"}}