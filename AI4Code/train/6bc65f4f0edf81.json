{"cell_type":{"aaf9c6f0":"code","6400f397":"code","6cfa2e27":"code","1bb0d502":"code","57f79637":"code","389525e1":"code","390dd85b":"code","6e0033b0":"code","37ff331c":"code","abe67514":"markdown"},"source":{"aaf9c6f0":"import torch\nimport numpy as np\nimport pandas as pd\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim\nfrom pathlib import Path\nfrom fastai.column_data import *\nfrom fastai.structured import *\nimport fastai\n\n","6400f397":"PATH = Path('..\/input')\n\ntrain_raw = pd.read_csv(PATH\/\"fashion-mnist_train.csv\")\ntest_raw = pd.read_csv(PATH\/\"fashion-mnist_test.csv\")","6cfa2e27":"labels_dict={\n'0': 'T-shirt\/top',\n'1': 'Trouser',\n'2': 'Pullover',\n'3': 'Dress',\n'4': 'Coat',\n'5': 'Sandal',\n'6': 'Shirt',\n'7': 'Sneaker',\n'8': 'Bag',\n'9': 'Ankle boot'\n}\n\ndef display_img(df, idx):\n    l = str(df.iloc[idx].values[0])\n    plt.imshow(df.iloc[idx][1:].values.reshape(28, 28))\n    plt.title(labels_dict[l])\n","1bb0d502":"class FashionNN(nn.Module):\n    def __init__(self, layers, dropout=0.5):\n        super().__init__()\n        # first layer must be of the image flatten size\n        self.layers = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i, l in enumerate(range(len(layers)-1))])\n        self.dropout = nn.Dropout(dropout)\n    \n    def forward(self, cat, cont):\n        # we assume there is no cat for simplicity\n        for l in self.layers:\n            cont = l(cont)\n            d = self.dropout(cont)\n            xs = F.relu(d)\n        return F.log_softmax(xs, dim=-1)","57f79637":"do_scale=True\ny_label = \"label\"\n\nbs, val_ratio, img_size = 64, 0.2, int(math.sqrt(train_raw.shape[1]-1))\n\ny_label = \"label\"\n\nif (do_scale):\n    train_x, train_y, nas, mapper = proc_df(train_raw, y_label, do_scale=True)\n    test_x, _, nas, mapper = proc_df(test_raw, y_label, do_scale=True, na_dict=nas, mapper=mapper)\nelse:\n    train_x, train_y, nas = proc_df(train_raw, y_label)\n    test_x, _, nas = proc_df(test_raw, y_label, na_dict=nas)\n\nval_idxs = get_cv_idxs(train_raw.shape[0], val_pct=val_ratio)","389525e1":"md = ColumnarModelData.from_data_frame(PATH, val_idxs, train_x, train_y.astype(np.int64), [], bs=bs, is_reg=False, is_multi=False, test_df=test_x)\n\nnet = FashionNN([1*img_size*img_size, 300, 200, 10], dropout=0.1).cuda()\n","390dd85b":"lr = 1e-3\noptim = torch.optim.Adam(net.parameters(), lr)\n\nfit(net, md, 20, optim, F.nll_loss, metrics=[accuracy])","6e0033b0":"# set learning rate to lower value and keep training!\nset_lrs(optim, 1e-4)\n\nfit(net, md, 30, optim, F.nll_loss, metrics=[accuracy])","37ff331c":"# predict\nnet.eval()\nx_vv = VV(test_x.values)\ny_vv = net(None, x_vv)\nnet.train()\n\ny = y_vv.cpu().data.numpy()\ny = np.argmax(y, axis=1)\n      \n","abe67514":"# This is a simple ANN approach for Fashion MNIST dataset. Please search my kernel using fastai library to see the differences in approach.\n## This kernel is a simple fully connected DL layer. As you can see, the accuracy of this appraoch is around ~85% while fastai library can achieve around 90% accuracy with similar lines of code"}}