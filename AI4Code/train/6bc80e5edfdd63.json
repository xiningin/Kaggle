{"cell_type":{"dc99a917":"code","a0f0df05":"code","4eacdfac":"code","56d6dba1":"code","56676e25":"code","437f382c":"code","b02aec75":"code","ffc9e848":"code","cd38ebd8":"code","ee35afcf":"markdown","948f9081":"markdown","2d0dc7c5":"markdown","2bbc8bd0":"markdown","9525b620":"markdown","5d092a65":"markdown","931bbba0":"markdown"},"source":{"dc99a917":"# Horses vs Humans Neural Network\n# Humberto Barrantes\n# 11-2020","a0f0df05":"from keras_preprocessing.image import ImageDataGenerator\n\nimport numpy as np\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\nimport matplotlib.pyplot as plt","4eacdfac":"TRAINING_PATH = \"\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/train\/\"\nVALIDATION_PATH = \"\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/validation\/\"\n\nIMAGE_SIZE = (64, 64)\n\ntraining_datagen = ImageDataGenerator(\n    rescale = 1.\/255,\n    #rotation_range=40,\n    #width_shift_range=0.2,\n    #height_shift_range=0.2,\n    #shear_range=0.2,\n    #zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\ntrain_generator = training_datagen.flow_from_directory(\n    TRAINING_PATH,\n    target_size=IMAGE_SIZE,\n    class_mode='categorical'\n)\n\nvalidation_datagen = ImageDataGenerator(rescale=1.\/255)\n\n# generador\nvalidation_generator = validation_datagen.flow_from_directory(\n        VALIDATION_PATH,\n        target_size=IMAGE_SIZE,\n        class_mode='categorical'\n)","56d6dba1":"model = keras.Sequential(\n    [\n        keras.Input(shape=(64, 64, 3)),\n        layers.Flatten(),\n        layers.Dense(512, activation=\"relu\"),\n        layers.Dropout(0.2),\n        layers.Dense(256, activation=\"relu\"),\n        layers.Dropout(0.2),\n        layers.Dense(128, activation=\"relu\"),\n        layers.Dropout(0.2),\n        layers.Dense(128, activation=\"relu\"),\n        layers.Dense(2, activation=\"softmax\"),\n    ]\n)\n\nmodel.build(IMAGE_SIZE)\nmodel.summary()\nmodel.compile(loss = 'categorical_crossentropy', optimizer='adamax', metrics=['accuracy'])","56676e25":"history = model.fit(\n    train_generator,\n    steps_per_epoch = train_generator.samples\/\/train_generator.batch_size,\n    epochs = 50, \n    verbose = 1,\n    validation_data=validation_generator,\n    validation_steps=validation_generator.samples\/\/validation_generator.batch_size,\n)","437f382c":"\ndef line_plot(series, legends, title, ylabel, xlabel):\n    for serie in series:\n        plt.plot(serie)\n    plt.title(title)\n    plt.ylabel(ylabel)\n    plt.xlabel(xlabel)\n    plt.legend(legends, loc='upper left')\n    #plt.ylim([0, 1.1])\n    plt.show()\n\n    \nline_plot(\n    [history.history['accuracy'], history.history['val_accuracy']],\n    ['train', 'test'],\n    'model accuracy',\n    'accuracy',\n    'epoch'\n)\n\nline_plot(\n    [history.history['loss'], history.history['val_loss']],\n    ['train', 'test'],\n    'model loss',\n    'loss',\n    'epoch'\n)","b02aec75":"x_test_batch, y_test_batch = next(validation_generator)","ffc9e848":"\nlabels = ['Horse', 'Human']\n\ndef predict(img):\n    y_pred = model.predict(np.array([img]))\n    y_class = y_pred.argmax(axis=-1)\n    return labels[y_class[0]]\n\nfor i in range (0,32):\n    image = x_test_batch[i]\n    plt.title(predict(image))\n    plt.imshow(image)\n    plt.show()\n","cd38ebd8":"images = [\n    'https:\/\/w.wallhaven.cc\/full\/q6\/wallhaven-q6y35l.jpg',\n    'https:\/\/w.wallhaven.cc\/full\/4x\/wallhaven-4xlppd.jpg',\n    'https:\/\/w.wallhaven.cc\/full\/43\/wallhaven-43xrj9.jpg',\n    'https:\/\/w.wallhaven.cc\/full\/4l\/wallhaven-4lg96y.jpg',\n    'https:\/\/w.wallhaven.cc\/full\/48\/wallhaven-485ee1.jpg',\n    'https:\/\/w.wallhaven.cc\/full\/gj\/wallhaven-gjyp53.jpg',\n    'https:\/\/w.wallhaven.cc\/full\/4g\/wallhaven-4g15jq.jpg',\n    'https:\/\/w.wallhaven.cc\/full\/zx\/wallhaven-zxyqzv.jpg',\n    'https:\/\/w.wallhaven.cc\/full\/43\/wallhaven-43w9yy.jpg'\n]\n\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\n\nfor url in images:\n    response = requests.get(url)\n    img = Image.open(BytesIO(response.content))\n    img = img.resize(IMAGE_SIZE) \n    arr = np.array(img)\n    \n    arr = arr\/255\n    \n    plt.title(predict(arr))\n    plt.imshow(img)\n    plt.show()","ee35afcf":"# Load data from disk","948f9081":"# Fit the model","2d0dc7c5":"# Neural Network Architecture","2bbc8bd0":"# Random Tests","9525b620":"# Accuracy Plots","5d092a65":"# What will happen in real life samples","931bbba0":"# Imports"}}