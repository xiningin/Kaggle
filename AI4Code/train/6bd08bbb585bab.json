{"cell_type":{"aa31af4e":"code","5f244504":"code","2a880c72":"code","bd0fc35b":"code","9c322a27":"code","0c1436aa":"code","781ed9d2":"code","346115a4":"code","eb701deb":"code","7abae4b4":"code","9c3c1c0c":"code","9607488b":"code","76f468fc":"code","b4fe7be2":"code","7b5ed522":"code","ba961459":"code","28c462a5":"code","a1a2e675":"code","3fec8168":"code","ab68a6e5":"code","d74f70f2":"code","9898ba7b":"code","4d6771a5":"code","b844c316":"code","e3a44cdf":"code","f9a92b03":"code","15dc16e8":"code","17d5f44c":"code","3e39ff49":"code","6206ab3f":"code","425f5780":"code","9cc6b264":"code","971cd241":"code","0b2b8675":"code","74c16a83":"code","93cf9495":"code","77733d26":"code","f0ed9da2":"code","01eeebe2":"code","1286ebc3":"code","d7155f7f":"code","a2d9f983":"code","a3b0af55":"markdown","faaaf931":"markdown","c5dfcb35":"markdown","9ffed29a":"markdown","35b1aba5":"markdown","81622620":"markdown","1e50e1b0":"markdown","7dbe484b":"markdown","63ca4bd3":"markdown","14b2141e":"markdown","7320fd45":"markdown","a108b117":"markdown","9e4361fc":"markdown","9ef86ecb":"markdown","24cadae6":"markdown","71b19763":"markdown","7f3e5aec":"markdown","4870c400":"markdown","db9c057b":"markdown","fafc636a":"markdown"},"source":{"aa31af4e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5f244504":"import seaborn as sns\nimport matplotlib.pyplot as plt","2a880c72":"import warnings\nwarnings.filterwarnings('ignore')","bd0fc35b":"df=pd.read_csv('\/kaggle\/input\/run-or-walk\/dataset.csv')","9c322a27":"df.head()","0c1436aa":"df.shape","781ed9d2":"df.info()","346115a4":"df = df.iloc[:,3:]","eb701deb":"df","7abae4b4":"df.describe().T","9c3c1c0c":"df.isna().sum()","9607488b":"plt.figure(figsize=(18,18))\ni=1\nfor x in df.columns:\n    plt.subplot(4,4,i)\n    sns.boxplot(y=df[x])\n    plt.title(x)\n    i+=1","76f468fc":"dfv = df.copy()","b4fe7be2":"dfv.activity=dfv.activity.map({0:'Walking',1:'Running'})\ndfv.wrist=dfv.wrist.map({0:'Left',1:'Right'})","7b5ed522":"sns.countplot(dfv.activity)","ba961459":"sns.countplot(y=dfv.wrist,hue=dfv.activity)","28c462a5":"df.drop('wrist',axis=1,inplace=True)","a1a2e675":"df['total_acceleration'] = np.sqrt((df.acceleration_x)**2 + (df.acceleration_y)**2 + (df.acceleration_z)**2)","3fec8168":"actdf = df.groupby([dfv.activity])['total_acceleration'].agg({'mean','max'})","ab68a6e5":"actdf","d74f70f2":"sns.barplot(y=actdf.max(),x=actdf.index)\nplt.title('Maximum Acceleration')\nplt.show()","9898ba7b":"sns.barplot(y=actdf.mean(),x=actdf.index)\nplt.title('Average Acceleration')\nplt.show()","4d6771a5":"df","b844c316":"X = df.iloc[:,1:]","e3a44cdf":"X","f9a92b03":"Y = df.activity","15dc16e8":"plt.figure(figsize=(18,18))\ni=1\nfor x in X.columns:\n    plt.subplot(4,4,i)\n    sns.distplot(X[x])\n    plt.title(x)\n    i+=1","17d5f44c":"# Taking Cuberoot Transformation\nX = np.cbrt(X)","3e39ff49":"plt.figure(figsize=(18,18))\ni=1\nfor x in X.columns:\n    plt.subplot(4,4,i)\n    sns.distplot(X[x])\n    plt.title(x)\n    i+=1","6206ab3f":"from sklearn.preprocessing import StandardScaler\ns = StandardScaler()\nX = s.fit_transform(X)\nX","425f5780":"from sklearn.model_selection import train_test_split\n\nX_train, X_test,Y_train, Y_test = train_test_split(X,Y,test_size=0.25,random_state=10) ","9cc6b264":"X_train.shape, X_test.shape,Y_train.shape, Y_test.shape","971cd241":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(X_train,Y_train)\nY_pred = lr.predict(X_test)","0b2b8675":"from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\nprint(confusion_matrix(Y_test,Y_pred))\nprint(classification_report(Y_test,Y_pred))\nlracc = accuracy_score(Y_test,Y_pred)\nprint(lracc)","74c16a83":"from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier(splitter='best',criterion='entropy',min_samples_split=3,min_samples_leaf=3)\ndt.fit(X_train,Y_train)\nY_pred = dt.predict(X_test)\nprint(confusion_matrix(Y_test,Y_pred))\nprint(classification_report(Y_test,Y_pred))\ndtacc = accuracy_score(Y_test,Y_pred)\nprint(dtacc)","93cf9495":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=200,min_samples_split=2,min_samples_leaf=1,max_features='sqrt',criterion='entropy')\nrf.fit(X_train,Y_train)\nY_pred = rf.predict(X_test)\nprint(confusion_matrix(Y_test,Y_pred))\nprint(classification_report(Y_test,Y_pred))\nrfacc = accuracy_score(Y_test,Y_pred)\nprint(rfacc)","77733d26":"from sklearn.ensemble import ExtraTreesClassifier\net = ExtraTreesClassifier(n_estimators=200,min_samples_split=2,min_samples_leaf=1,max_features='log2',criterion='gini')\net.fit(X_train,Y_train)\nY_pred = et.predict(X_test)\nprint(confusion_matrix(Y_test,Y_pred))\nprint(classification_report(Y_test,Y_pred))\netacc = accuracy_score(Y_test,Y_pred)\nprint(etacc)","f0ed9da2":"from xgboost import XGBClassifier\ngb = XGBClassifier()\ngb.fit(X_train,Y_train)\nY_pred = gb.predict(X_test)\nprint(confusion_matrix(Y_test,Y_pred))\nprint(classification_report(Y_test,Y_pred))\ngbacc = accuracy_score(Y_test,Y_pred)\nprint(gbacc)","01eeebe2":"models = pd.DataFrame([lracc,dtacc,rfacc,etacc,gbacc],\n             index=['Logistic Regression','Decision Tree','Random Forest','Extra Tree','XG Boost'],columns=['Accuracy'])","1286ebc3":"models","d7155f7f":"models.Accuracy.sort_values(ascending=False).values","a2d9f983":"sns.barplot(x=models.Accuracy.sort_values(ascending=False).values,y = models.Accuracy.sort_values(ascending=False).index)","a3b0af55":"# Checking Null Values","faaaf931":"# Import Libraries","c5dfcb35":"# Random Forest","9ffed29a":"Dropping wrist column as it is not that important","35b1aba5":"# Visualization","81622620":"# Data Inspection","1e50e1b0":"# Scaling","7dbe484b":"# XG Boost","63ca4bd3":"# Logistic Regression","14b2141e":"# Handling Skewness","7320fd45":"# Checking Outliers","a108b117":"# Decision Tree","9e4361fc":"# Model Comparision","9ef86ecb":"# Read data","24cadae6":"No Outliers, all data points looks in clusters","71b19763":"# Create X and Y","7f3e5aec":"# Extra Tree","4870c400":"Dropping date time and username column","db9c057b":"# Train","fafc636a":"No Null values "}}