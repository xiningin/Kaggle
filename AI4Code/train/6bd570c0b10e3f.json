{"cell_type":{"77eaa610":"code","22b2b220":"code","6da135bc":"code","eab809ae":"code","05d7423f":"code","23472523":"code","2782fc1b":"code","542e4c97":"code","ec46f010":"code","0f54c403":"code","6f6b304a":"code","8bdbfb90":"code","6fb9293e":"code","610da443":"code","b9ce67ff":"code","35684559":"code","487a9657":"code","1d4cfb62":"code","c28ab254":"code","dff34e0a":"code","9d886fc2":"code","d1a36460":"code","f7f8df6f":"code","980066df":"code","520ebd7d":"code","8d140554":"markdown","33c3123d":"markdown","27101782":"markdown","12f8d1fb":"markdown","5ef320e1":"markdown","5f521ed8":"markdown","d07e9aaa":"markdown"},"source":{"77eaa610":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm, skew\nfrom sklearn import ensemble, metrics\nfrom sklearn import linear_model, preprocessing\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\n#from sklearn.model_selection import GridSearchCV, KFold\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.preprocessing import LabelEncoder\nimport xgboost as xgb","22b2b220":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\n\nprint(train.shape, test.shape)","6da135bc":"train.head()","eab809ae":"sns.distplot(train['SalePrice'], fit=norm)\nmu, sigma = norm.fit(train['SalePrice'])\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)], loc='best')\nplt.ylabel('Frequency')\nprint('mu={:2f}, sigma={:.2f}'.format(mu,sigma))\nprint('skew={}'.format(skew(np.log1p(train['SalePrice']))))","05d7423f":"train.describe(include=['number']).loc[[\"mean\",\"min\",\"max\"]]","23472523":"# ref. https:\/\/github.com\/shan4224\/Kaggle_House_Prices\nn = train.select_dtypes(include=object)\nfor c in n.columns:\n    print(c, ':  ', train[c].unique())","2782fc1b":"fig, axes = plt.subplots(ncols=4, nrows=4, figsize=(4 * 4, 3 * 4), sharey=True)\naxes = np.ravel(axes)\ncols = ['OverallQual','OverallCond','ExterQual','ExterCond','BsmtQual','BsmtCond','GarageQual','GarageCond',\n        'MSSubClass','MSZoning','Neighborhood','BldgType','HouseStyle','Heating','Electrical','SaleType']\nfor i, c in zip(np.arange(len(axes)), cols):\n    sns.boxplot(x=c, y='SalePrice', data=train, ax=axes[i])","542e4c97":"all_data = train.append(test, sort=False).reset_index(drop=True)\nall_data.shape","ec46f010":"# to categorical feature\ncols = [\"MSSubClass\",\"BsmtFullBath\",\"BsmtHalfBath\",\"HalfBath\",\"BedroomAbvGr\",\"KitchenAbvGr\",\"MoSold\",\"YrSold\",\"YearBuilt\",\"YearRemodAdd\",\"LowQualFinSF\",\"GarageYrBlt\"]\nfor c in cols:\n    all_data[c] = all_data[c].astype(str)\n\n# encode quality\n# Ex(Excellent), Gd\uff08Good\uff09, TA\uff08Typical\/Average\uff09, Fa\uff08Fair\uff09, Po\uff08Poor\uff09\ncols = ['ExterQual','ExterCond','BsmtQual','BsmtCond','HeatingQC','KitchenQual','FireplaceQu','GarageQual','GarageCond','PoolQC']\nfor c in cols:\n    all_data[c].fillna(0, inplace=True)\n    all_data[c].replace({'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}, inplace=True)","0f54c403":"def pair_features_to_dummies(df, col1, col2, prefix):\n    d_1 = pd.get_dummies(df[col1].astype(str), prefix=prefix)\n    d_2 = pd.get_dummies(df[col2].astype(str), prefix=prefix)\n    for c in list(set(list(d_1.columns) + list(d_2.columns))):\n        if not c in d_1.columns: d_1[c] = 0\n        if not c in d_2.columns: d_2[c] = 0\n    return (d_1 + d_2).clip(0, 1)\n\ncond = pair_features_to_dummies(all_data,'Condition1','Condition2','Condition')\nexterior = pair_features_to_dummies(all_data,'Exterior1st','Exterior2nd','Exterior')\nbsmtftype = pair_features_to_dummies(all_data,'BsmtFinType1','BsmtFinType2','BsmtFinType') \n\nall_data = pd.concat([all_data, cond, exterior, bsmtftype], axis=1)\nall_data.drop(['Condition1','Condition2', 'Exterior1st','Exterior2nd','BsmtFinType1','BsmtFinType2'], axis=1, inplace=True)\nall_data.head()","6f6b304a":"n = all_data.drop('SalePrice', axis=1).loc[:,all_data.isnull().any()].isnull().sum()\nprint(n.sort_values(ascending=False))","8bdbfb90":"# fillna\nfor c in ['MiscFeature', 'Alley', 'Fence']:\n    all_data[c].fillna('None', inplace=True)\n    \nall_data['LotFrontage'] = all_data.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n\nall_data.loc[all_data.GarageYrBlt.isnull(),'GarageYrBlt'] = all_data.loc[all_data.GarageYrBlt.isnull(),'YearBuilt']\nall_data['GarageType'].fillna('None', inplace=True)\nall_data['GarageFinish'].fillna(0, inplace=True)\n\nfor c in ['GarageArea', 'GarageCars', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath']:\n    all_data[c].fillna(0, inplace=True)","6fb9293e":"for i, t in all_data.loc[:, all_data.columns != 'SalePrice'].dtypes.iteritems():\n    if t == object:\n        all_data[i].fillna(all_data[i].mode()[0], inplace=True)\n        all_data[i] = LabelEncoder().fit_transform(all_data[i].astype(str))\n    else:\n        all_data[i].fillna(all_data[i].median(), inplace=True)","610da443":"all_data['OverallQualCond'] = all_data['OverallQual'] * all_data['OverallCond']\nall_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\nall_data['Interaction'] = all_data['TotalSF'] * all_data['OverallQual']","b9ce67ff":"train = all_data[all_data['SalePrice'].notnull()]\ntest = all_data[all_data['SalePrice'].isnull()].drop('SalePrice', axis=1)","35684559":"corr = train.corr()\ncorr_price_abs = pd.DataFrame(corr.SalePrice.abs().sort_values(ascending=False))\nfor i, c in zip(np.arange(len(corr_price_abs)), corr_price_abs.index): print(i, ':', c)\n#train[corr_price_abs.index].describe().loc[['min','max']]","487a9657":"fig, axes = plt.subplots(ncols=4, nrows=9, figsize=(20, 30))\naxes = np.ravel(axes)\ncol_name = corr_price_abs[1:].index\nfor i in range(36):\n    train.plot.scatter(ax=axes[i], x=col_name[i], y='SalePrice', c='OverallQual', sharey=True, colorbar=False, cmap='GnBu')","1d4cfb62":"train = train[train['TotalSF'] < 6000]\ntrain = train[train['TotalBsmtSF'] < 4000]\ntrain = train[train['SalePrice'] < 700000]","c28ab254":"_ = '''\nfrom scipy.stats import skew\n\n#log transform skewed numeric features:\nnumeric_feats = all_data[test.columns].dtypes[all_data.dtypes != \"object\"].index\n\nskewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\nskewed_feats = skewed_feats[skewed_feats > 0.75]\nskewed_feats = skewed_feats.index\n\n#all_data[skewed_feats] = np.log1p(all_data[skewed_feats])\nfrom scipy.special import boxcox1p\nlam = 0.15\nfor feat in skewed_feats:\n    all_data[feat] = boxcox1p(all_data[feat], lam)\n    \nall_data = pd.get_dummies(all_data)\n'''","dff34e0a":"X_train = train.drop(['SalePrice','Id'], axis=1)\nY_train = train['SalePrice']\nX_test  = test.drop(['Id'], axis=1)\n\nprint(X_train.shape, Y_train.shape, X_test.shape)","9d886fc2":"def rmse_cv(model, X, y):\n    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=5))\n    return rmse.mean()","d1a36460":"reg = xgb.XGBRegressor(n_estimators=1000, max_depth=4, learning_rate=0.05, subsample=0.6, colsample_bytree=0.6)\n\nscore = rmse_cv(reg, X_train, np.log1p(Y_train))\nprint(score.mean())\n\n#col = X_test.columns\n#feature_imp = pd.DataFrame(reg.feature_importances_, index=col, columns=[\"importance\"])\n#print(feature_imp.sort_values(\"importance\", ascending=False).head(30))","f7f8df6f":"Y_train_s = np.log1p(Y_train)\n\nreg_1 = xgb.XGBRegressor(n_estimators=1000, max_depth=4, learning_rate=0.05, subsample=0.6, colsample_bytree=0.6)\nreg_1.fit(X_train, Y_train_s)\npred_1 = np.expm1(reg_1.predict(X_test))\n\nscaler = preprocessing.RobustScaler(); #StandardScaler\nscaler.fit(X_train)\n\nreg_2 = linear_model.ElasticNet(alpha=0.01, l1_ratio=0.5, max_iter=100000)\nreg_2.fit(scaler.transform(X_train), Y_train_s)\npred_2 = np.expm1(reg_2.predict(scaler.transform(X_test)))\n\nreg_3 = linear_model.Ridge(alpha=60)\nreg_3.fit(scaler.transform(X_train), Y_train_s)\npred_3 = np.expm1(reg_3.predict(scaler.transform(X_test)))\n\nreg_4 = linear_model.BayesianRidge()\nreg_4.fit(scaler.transform(X_train), Y_train_s)\npred_4 = np.expm1(reg_4.predict(scaler.transform(X_test)))\n\nresult = pred_1 * 0.5 + pred_2 * 0.2 + pred_3 * 0.2 + pred_4 * 0.1","980066df":"submission = pd.DataFrame({\n    \"Id\": test[\"Id\"],\n    \"SalePrice\": result\n})\nsubmission.to_csv(\"submission.csv\", index=False)","520ebd7d":"submission.head(10)","8d140554":"## Correlation","33c3123d":"## Prediction","27101782":"## Preparation","12f8d1fb":"### encode, fillna","5ef320e1":"## Preprocessing","5f521ed8":"## Evaluation","d07e9aaa":"### feature creation"}}