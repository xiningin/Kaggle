{"cell_type":{"30499301":"code","ab557211":"code","46b45b6e":"code","54e348f9":"code","98f6ebb9":"code","c35c3d3e":"code","07db3bb6":"code","3def6ac6":"code","61d782cc":"code","88340fa5":"code","7cf879a5":"code","8bf37ef7":"code","1183c76e":"code","6124c939":"code","990e93f2":"code","da59b2e3":"code","da17266c":"code","aaedb3b2":"code","4d9398cc":"code","f40d8781":"code","54af2bc3":"code","f5f153ba":"code","f84197d0":"code","6820493c":"code","cb950455":"code","3b5d8296":"code","851affc5":"markdown","add4cb2e":"markdown","f0afd516":"markdown","5947eb2b":"markdown","f677a1cb":"markdown","3b0dd708":"markdown","5c47de71":"markdown"},"source":{"30499301":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom nltk.corpus import stopwords\n\nimport re\nimport string\n\nfrom sklearn import feature_extraction, linear_model, model_selection, preprocessing\nfrom sklearn.metrics import accuracy_score","ab557211":"stop=set(stopwords.words('english'))","46b45b6e":"train = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/test.csv\")\n#train = pd.read_csv(\"train.csv\")\n#test = pd.read_csv(\"test.csv\")","54e348f9":"df = pd.concat([train, test], sort = False)\ndf.shape","98f6ebb9":"#Function for removing URL\ndef remove_URL(text):\n    url = re.compile(r'https?:\/\/\\S+|www\\.\\S+')\n    return url.sub(r'',text)","c35c3d3e":"#Function for removing HTML codes\ndef remove_html(text):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',text)","07db3bb6":"#Function for removing Emojis\ndef remove_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)","3def6ac6":"#Function for removing punctuations\ndef remove_punct(text):\n    table=str.maketrans('','',string.punctuation)\n    return text.translate(table)","61d782cc":"df['text']=df['text'].apply(lambda x : remove_URL(x))\ndf['text']=df['text'].apply(lambda x : remove_html(x))\ndf['text']=df['text'].apply(lambda x : remove_emoji(x))\ndf['text']=df['text'].apply(lambda x : remove_punct(x))","88340fa5":"df.head()","7cf879a5":"df_train = df[df['target'].notnull()]\ndf_train.head()","8bf37ef7":"df_test = df[df['target'].isnull()]\ndf_test.head()","1183c76e":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(df_train['text'], df_train['target'], test_size=0.30, random_state=101)","6124c939":"#Create instance\ncount_vectorizer = feature_extraction.text.CountVectorizer(analyzer = 'word', max_features = 5000)","990e93f2":"#Fit Transform train data\nX_train_fit = count_vectorizer.fit(X_train)\nX_test_fit = count_vectorizer.fit(X_test)","da59b2e3":"X_train_vectors = count_vectorizer.transform(X_train)\nX_test_vectors = count_vectorizer.transform(X_test)","da17266c":"X = pd.DataFrame(X_train_vectors.toarray())\nX.columns = count_vectorizer.get_feature_names()","aaedb3b2":"#X.to_csv('vector.csv', index = False)\nX.head()","4d9398cc":"clf = linear_model.RidgeClassifier()","f40d8781":"clf.fit(X, y_train)","54af2bc3":"scores = model_selection.cross_val_score(clf, X, y_train, cv=7, scoring=\"f1\")\ny_test_pred = clf.predict(X_test_vectors)\ntest_accuracy = accuracy_score(y_test_pred, y_test)\nprint('Train Accuracy : %0.3f' % scores.mean())\nprint('Test Accuracy : %0.3f' % test_accuracy.mean())","f5f153ba":"#get sample file for creating submission file\nsample_submission = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/sample_submission.csv\")\n#sample_submission = pd.read_csv(\"sample_submission.csv\")","f84197d0":"X_sub_vecttor = count_vectorizer.fit_transform(df_test['text'])","6820493c":"sample_submission[\"target\"] = clf.predict(X_sub_vecttor).astype(int)","cb950455":"sample_submission.head()","3b5d8296":"#Got to the Output section of this Kernel -> click on Submit to Competition\nsample_submission.to_csv(\"submission.csv\", index=False)","851affc5":"# Import Libraries","add4cb2e":"# Clean Data","f0afd516":"# Make Test and Train","5947eb2b":"# Predict","f677a1cb":"# Submit","3b0dd708":"# Model","5c47de71":"# Building Vectors"}}