{"cell_type":{"b60ca63f":"code","61feb743":"code","b6f4d61b":"code","d5e0d256":"code","b45e7523":"code","9ed2ee68":"code","cf3427ea":"code","29c28f12":"code","df79dee6":"code","f6c7e812":"code","b635680f":"code","306c3535":"code","33d9b186":"code","2cf84835":"code","86f6bdd2":"code","7ee1b7d7":"code","382c5d0a":"code","3750ac5e":"code","24e53df6":"code","1845328a":"code","46397c77":"code","90a31d15":"code","bb5ec5b7":"code","c8125b17":"code","b2ccf289":"markdown","2d55e4fd":"markdown","6ba9ae85":"markdown","2a239acc":"markdown","e70bb9e5":"markdown","f2586911":"markdown","7abf02f0":"markdown"},"source":{"b60ca63f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\nimport time\n\nimport matplotlib.pyplot as plt\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","61feb743":"from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\ndata_generator = ImageDataGenerator(rescale=1.\/255.,validation_split=0.2,\n                                   featurewise_center=True,\n        samplewise_center=True,\n        featurewise_std_normalization=True,\n        samplewise_std_normalization=True,\n        rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.15,\n        zoom_range=0.15,\n        fill_mode=\"nearest\",\n        horizontal_flip=True,\n        vertical_flip=True\n                        )\ntrain_generator = data_generator.flow_from_directory(directory= '..\/input\/cough-detection\/melspectrograms\/training',             \n                                                     target_size=(224, 224),\n                                                     class_mode='binary',\n                                                     subset='training',\n                                                     shuffle=True,\n                                                     seed=2,\n                                                     batch_size=32,\n                                                     color_mode='rgb'\n                                                     )\n\nvalid_generator = data_generator.flow_from_directory(directory= '..\/input\/cough-detection\/melspectrograms\/testing',\n                                                     target_size=(224, 224),\n                                                     class_mode='binary',\n                                                     subset='validation',\n                                                     shuffle=True,\n                                                     batch_size=32,\n                                                     color_mode='rgb'\n                                                    )\n\nclasses = ['cough', 'no_cough']","b6f4d61b":"plt.figure(figsize=(10,10))\nplt.subplot(2,2,1)\nplt.bar(classes, train_generator.labels.sum(axis = 0)\/train_generator.n * 100)\nplt.title('On training set')\nplt.subplot(2,2,2)\nplt.bar(classes, valid_generator.labels.sum(axis = 0)\/valid_generator.n * 100, color='rgb')\nplt.title('On validation set')","d5e0d256":"sample_training_images, _ = next(train_generator)","b45e7523":"def plotImages(images_arr):\n    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n    labels = sample_training_images\n    axes = axes.flatten()\n    for img, ax in zip(images_arr, axes):\n        ax.imshow(img)\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()","9ed2ee68":"plotImages(sample_training_images[:5])","cf3427ea":"model = tf.keras.models.Sequential()\nmodel.add(MobileNetV2(include_top=False, pooling='avg', weights='imagenet', input_shape=(224, 224, 3), classes=2))\nmodel.add(Dense(2, activation='softmax'))\nmodel.layers[0].trainable = False\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","29c28f12":"callbacks = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', patience = 2)\nhistory = model.fit_generator(train_generator,\n                              steps_per_epoch = len(train_generator),\n                              epochs=15,\n                              validation_steps = len(valid_generator),\n                              validation_data=valid_generator,\n                              callbacks = [callbacks]\n                              )","df79dee6":"def visualize_training(history, lw = 3):\n    plt.figure(figsize=(10,6))\n    plt.plot(history.history['accuracy'], label = 'training', marker = '*', linewidth = lw)\n    plt.plot(history.history['val_accuracy'], label = 'validation', marker = 'o', linewidth = lw)\n    plt.title('Training Accuracy vs Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend(fontsize = 'x-large')\n    plt.show()\n\n    plt.figure(figsize=(10,6))\n    plt.plot(history.history['loss'], label = 'training', marker = '*', linewidth = lw)\n    plt.plot(history.history['val_loss'], label = 'validation', marker = 'o', linewidth = lw)\n    plt.title('Training Loss vs Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend(fontsize = 'x-large')\n    plt.show()\nvisualize_training(history)","f6c7e812":"preds = model.predict_generator(valid_generator,steps=15)","b635680f":"label = valid_generator.classes","306c3535":"pred= model.predict(valid_generator)\npredicted_class_indices=np.argmax(pred,axis=1)\nlabels = (valid_generator.class_indices)\nlabels2 = dict((v,k) for k,v in labels.items())\npredictions = [labels2[k] for k in predicted_class_indices]\nprint(predicted_class_indices)\nprint (labels)\nprint (predictions)","33d9b186":"image_path = '..\/input\/cough-detection\/melspectrograms\/testing\/cough\/1-63679-A-24.png'\nimage = tf.keras.preprocessing.image.load_img(image_path)\ninput_arr = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr])  # Convert single image to a batch.\npredictions = model.predict(input_arr)","2cf84835":"predictions","86f6bdd2":"image_path = '..\/input\/cough-detection\/melspectrograms\/testing\/no_cough\/1-100032-A-0.png'\nimage = tf.keras.preprocessing.image.load_img(image_path)\ninput_arr = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr])  # Convert single image to a batch.\npredictions1 = model.predict(input_arr)","7ee1b7d7":"predictions1","382c5d0a":"image_path = '..\/input\/cough-detection\/melspectrograms\/training\/no_cough\/1-100038-A-14.png'\nimage = tf.keras.preprocessing.image.load_img(image_path)\ninput_arr = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr])  # Convert single image to a batch.\npredictions_nocough = model.predict(input_arr)","3750ac5e":"predictions_nocough","24e53df6":"from sklearn.metrics import confusion_matrix, classification_report, roc_curve\n\nrc = roc_curve(predicted_class_indices,label)\ncf_matrix = confusion_matrix(predicted_class_indices,label)\ncf_report = classification_report(predicted_class_indices,label)\nprint('Confusion matrix report of the model : \\n{}'.format(cf_matrix))","1845328a":"exp_series = pd.Series(label)\npred_series = pd.Series(predicted_class_indices)\npd.crosstab(exp_series, pred_series, rownames=['Actual'], colnames=['Predicted'],margins=True)","46397c77":"print('Classification report of the model : \\n{}'.format(cf_report))","90a31d15":"t = time.time()\nsave_path = '.'\nmodel_json = model.to_json()\nwith open(os.path.join(save_path,\"network.json\"), \"w\") as json_file:\n    json_file.write(model_json)\n\n# save neural network structure to YAML (no weights)\nmodel_yaml = model.to_yaml()\nwith open(os.path.join(save_path,\"network.yaml\"), \"w\") as yaml_file:\n    yaml_file.write(model_yaml)\n\n# save entire network to HDF5 (save everything, suggested)\nmodel.save(os.path.join(save_path,\"network.h5\"))","bb5ec5b7":"!ls","c8125b17":"from tensorflow.keras.models import load_model\nmodel2 = load_model(os.path.join(save_path,\"network.h5\"))\npred = model2.predict(input_arr)\npred","b2ccf289":"# Loading Libraries","2d55e4fd":"# Loading the Saved Model and Predictions","6ba9ae85":"# Predictions","2a239acc":"# Saving Model","e70bb9e5":"# Data Visualization","f2586911":"# Predicting Non Cough samples","7abf02f0":"# Data Augmentation"}}