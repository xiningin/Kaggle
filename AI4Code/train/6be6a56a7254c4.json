{"cell_type":{"b55c80c9":"code","e37c47f6":"code","03f3d728":"code","015ca371":"code","d49a5160":"code","74cc2d44":"code","fe6b462e":"code","c999d1f9":"code","2d633958":"code","78d96b48":"code","19517174":"code","06a418d8":"code","889574a4":"code","097d9ff3":"code","7ecb00c6":"code","f430b3a6":"code","c4073ab3":"code","8bae24c4":"code","d1e63a62":"code","b5671439":"code","5cb02f4d":"code","f5c6420a":"code","f00b48b3":"code","05367ff4":"code","3f487851":"code","b0f247e9":"code","076c89b9":"code","d3a84ce6":"code","5dd8607f":"code","e4f6ca4c":"code","7cfcc8ff":"code","21c51607":"markdown","822a9f37":"markdown","4159c74e":"markdown","6a3833ef":"markdown","1612c26f":"markdown","3802589a":"markdown","02088d11":"markdown","280e7cc3":"markdown","7f5df4e0":"markdown","bcb3a752":"markdown","93a115b7":"markdown","790c164a":"markdown","94bbd62f":"markdown","16d1f3a5":"markdown","f3c5336d":"markdown","8a2c02b8":"markdown","ed837958":"markdown","a291dfe7":"markdown","69e9877f":"markdown","da744e80":"markdown","4a132b54":"markdown","17cac50a":"markdown","99e23cde":"markdown","22d6239c":"markdown","f61107c5":"markdown","f9455da1":"markdown","4e9bb1a9":"markdown","86aabe0a":"markdown","aa3b981c":"markdown","34393f10":"markdown"},"source":{"b55c80c9":"import numpy as np\nimport pandas as pd","e37c47f6":"df=pd.read_csv('..\/input\/yelp.csv')","03f3d728":"df.head()","015ca371":"df.info()","d49a5160":"df.describe()","74cc2d44":"df['text length']=df['text'].apply(len)\ndf.head()","fe6b462e":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","c999d1f9":"g=sns.FacetGrid(df,col='stars')\ng.map(plt.hist,'text length')","2d633958":"sns.boxplot(x='stars',y='text length',data=df,palette='rainbow')","78d96b48":"sns.countplot(x='stars',data=df,palette='rainbow')","19517174":"stars=df.groupby('stars').mean()\nstars","06a418d8":"stars.corr()","889574a4":"sns.heatmap(stars.corr(),cmap='coolwarm',annot=True)","097d9ff3":"yelp_class=df[(df.stars==1)|(df.stars==5)]","7ecb00c6":"X=yelp_class['text']\ny=yelp_class['stars']\n","f430b3a6":"from sklearn.feature_extraction.text import CountVectorizer \ncv=CountVectorizer()","c4073ab3":"\nX=cv.fit_transform(X)","8bae24c4":"from sklearn.model_selection import train_test_split","d1e63a62":"    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=101)","b5671439":"from sklearn.naive_bayes import MultinomialNB\nnb=MultinomialNB()","5cb02f4d":"nb.fit(X_train,y_train)","f5c6420a":"prediction=nb.predict(X_test)","f00b48b3":"from sklearn.metrics import confusion_matrix,classification_report","05367ff4":"print(confusion_matrix(y_test,prediction))\nprint(classification_report(y_test,prediction))","3f487851":"from sklearn.feature_extraction.text import TfidfTransformer","b0f247e9":"from sklearn.pipeline import Pipeline","076c89b9":"pipeline=Pipeline([\n    ('bow',CountVectorizer()),\n   ( 'tfidf',TfidfTransformer()),\n    ('classifier',MultinomialNB())\n])","d3a84ce6":"X=yelp_class['text']\ny=yelp_class['stars']\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)","5dd8607f":"pipeline.fit(X_train,y_train)","e4f6ca4c":"prediction=pipeline.predict(X_test)","7cfcc8ff":"print(confusion_matrix(y_test,prediction),\n     classification_report(y_test,prediction))","21c51607":"## Predictions and Evaluations\n\nTime to see how our model did!\n\n**Use the predict method off of nb to predict labels from X_test.**","822a9f37":"**Use the corr() method on that groupby dataframe to produce this dataframe:**","4159c74e":"**Now fit nb using the training data.**","6a3833ef":"** Use groupby to get the mean values of the numerical columns, you should be able to create this dataframe with the operation:**","1612c26f":"**Now fit the pipeline to the training data. Remember you can't use the same training data as last time because that data has already been vectorized. We need to pass in just the text and labels**","3802589a":"**Use FacetGrid from the seaborn library to create a grid of 5 histograms of text length based off of the star ratings. Reference the seaborn documentation for hints on this**","02088d11":"** Use the fit_transform method on the CountVectorizer object and pass in X (the 'text' column). Save this result by overwriting X.**","280e7cc3":"**Create a new column called \"text length\" which is the number of words in the text column.**","7f5df4e0":"## The Data\n\n**Read the yelp.csv file and set it as a dataframe called yelp.**","bcb3a752":"## Train Test Split\n\nLet's split our data into training and testing data.\n\n** Use train_test_split to split up the data into X_train, X_test, y_train, y_test. Use test_size=0.3 and random_state=101 **","93a115b7":"**Great! Let's see what happens if we try to include TF-IDF to this process using a pipeline.**","790c164a":"** Import Pipeline from sklearn. **","94bbd62f":"**Import CountVectorizer and create a CountVectorizer object.**","16d1f3a5":"## NLP Classification Task\n\nLet's move on to the actual task. To make things a little easier, go ahead and only grab reviews that were either 1 star or 5 stars.\n\n**Create a dataframe called yelp_class that contains the columns of yelp dataframe but for only the 1 or 5 star reviews.**","f3c5336d":"** Create a confusion matrix and classification report using these predictions and y_test **","8a2c02b8":"Looks like Tf-Idf actually made things worse! That is it for this project. But there is still a lot more you can play with:\n\n**Some other things to try....**\nTry going back and playing around with the pipeline steps and seeing if creating a custom analyzer like we did in the lecture helps (note: it probably won't). Or recreate the pipeline with just the CountVectorizer() and NaiveBayes. Does changing the ML model at the end to another classifier help at all?","ed837958":"# Using Text Processing\n\n** Import TfidfTransformer from sklearn. **","a291dfe7":"## Training a Model\n\nTime to train a model!\n\n** Import MultinomialNB and create an instance of the estimator and call is nb **","69e9877f":"## Imports\n **Import the usual suspects. :) **","da744e80":"** Check the head, info , and describe methods on yelp.**","4a132b54":"**Create a boxplot of text length for each star category.**","17cac50a":"## Using the Pipeline\n\n**Time to use the pipeline! Remember this pipeline has all your pre-process steps in it already, meaning we'll need to re-split the original data (Remember that we overwrote X as the CountVectorized version. What we need is just the text**","99e23cde":"**Create a countplot of the number of occurrences for each type of star rating.**","22d6239c":"# Natural Language Processing Project\nIn this NLP project you will be attempting to classify Yelp Reviews into 1 star or 5 star categories based off the text content in the reviews. This will be a simpler procedure than the lecture, since we will utilize the pipeline methods for more complex tasks.\n\nWe will use the [Yelp Review Data Set from Kaggle](https:\/\/www.kaggle.com\/c\/yelp-recsys-2013).\n\nEach observation in this dataset is a review of a particular business by a particular user.\n\nThe \"stars\" column is the number of stars (1 through 5) assigned by the reviewer to the business. (Higher stars is better.) In other words, it is the rating of the business by the person who wrote the review.\n\nThe \"cool\" column is the number of \"cool\" votes this review received from other Yelp users. \n\nAll reviews start with 0 \"cool\" votes, and there is no limit to how many \"cool\" votes a review can receive. In other words, it is a rating of the review itself, not a rating of the business.\n\nThe \"useful\" and \"funny\" columns are similar to the \"cool\" column.\n\nLet's get started! Just follow the directions below!","f61107c5":"** Now create a pipeline with the following steps:CountVectorizer(), TfidfTransformer(),MultinomialNB()**","f9455da1":"### Predictions and Evaluation\n\n** Now use the pipeline to predict from the X_test and create a classification report and confusion matrix. You should notice strange results.**","4e9bb1a9":"** Create two objects X and y. X will be the 'text' column of yelp_class and y will be the 'stars' column of yelp_class. (Your features and target\/labels)**","86aabe0a":"### Train Test Split\n\n**Redo the train test split on the yelp_class object.**","aa3b981c":"**Then use seaborn to create a heatmap based off that .corr() dataframe:**","34393f10":"# EDA\n\nLet's explore the data\n\n## Imports\n\n**Import the data visualization libraries if you haven't done so already.**"}}