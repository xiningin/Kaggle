{"cell_type":{"e0355dd2":"code","bb08573e":"code","cf58d0a7":"code","698fa066":"code","7686f3ff":"code","2e7c4408":"code","7ee650dc":"code","29c179bf":"code","b1913f91":"code","4be2052f":"code","5d45b7ff":"code","9b7a382e":"code","3b999799":"code","4107fa1d":"code","d2e1f5ac":"markdown","928ec287":"markdown","30560e2c":"markdown","3de3677d":"markdown","5299332a":"markdown","aa676c0a":"markdown","febfe1b8":"markdown","4ed3cc97":"markdown","f18ce474":"markdown","337ce71c":"markdown","eed3ade2":"markdown","69d54fe7":"markdown","e9c52531":"markdown"},"source":{"e0355dd2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nimport warnings\nwarnings.simplefilter(\"ignore\", UserWarning)\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport torch\nimport matplotlib.pyplot as plt\nimport PIL\nfrom matplotlib import image\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom tqdm import tqdm\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bb08573e":"data = image.imread('\/kaggle\/input\/sign-language-mnist\/american_sign_language.PNG')\nplt.imshow(data)\nplt.show()","cf58d0a7":"data_train =pd.read_csv('\/kaggle\/input\/sign-language-mnist\/sign_mnist_train.csv')\ndata_train.shape","698fa066":"def showImage(row):\n    d = data_train.drop('label',axis = 1).loc[row,:]\n    print(data_train['label'][row])\n    plt.imshow(d.values.reshape(28,28))\n    plt.show()","7686f3ff":"showImage(15)","2e7c4408":"class Neural_Network(nn.Module):\n    def __init__(self):\n        super(Neural_Network, self).__init__()\n        self.conv1 = nn.Conv2d(1,6,kernel_size = 3,stride = 1,padding = 1) #input: (m,28,28,1) output: (m,28,28,6)\n        self.max1 = nn.MaxPool2d(kernel_size = (2,2),stride = 2) #input: (m,28,28,6) output: (m,14,14,6)\n        self.conv2 = nn.Conv2d(6,16,kernel_size = 5,stride = 1,padding = 0) #input: (m,14,14,6) output: (m,10,10,16)\n        self.max2 = nn.MaxPool2d(kernel_size = (2,2),stride = 2) #input: (m,10,10,16) output: (m,5,5,16)\n        self.fc1 = nn.Linear(400,120) #input: (m,400) output: (m,120)\n        self.fc2 = nn.Linear(120,84) #input: (m,120) output: (m,84)\n        self.fc3 = nn.Linear(84,25) #input: (m,84) output: (m,25)\n    def forward(self,x):\n        x = F.relu(self.conv1(x))\n        x = self.max1(x)\n        x = F.relu(self.conv2(x))\n        x = self.max2(x)\n        x = torch.flatten(x,start_dim = 1)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n            ","7ee650dc":"net = Neural_Network()\nnet\n","29c179bf":"print(torch.cuda.is_available())\ndevice = torch.device(\"cuda:0\")\nnet.to(device)","b1913f91":"#STORE THE LOSS AT EACH EPOCH\nloss_list = []\n\n#FUNCTION\ndef RUN_NETWORK(train,EPOCHS,test,batch_size):\n    # WE USE THE ADAM OPTIMIZER\n    optimizer = optim.Adam(net.parameters(),lr = 0.001)\n    # WE USE SCHEDULER SO THAT AT EVERY 10 EPOCHS LEARNING REDUCES BY A FACTOR OF 10\n    scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size = 10,gamma = 0.1)\n    # WE USE CROSS ENTROPY LOSS\n    loss = nn.CrossEntropyLoss()\n    \n    for epoch in (range(EPOCHS)):\n        scheduler.step()\n        print('Epoch:', epoch,'LR:', scheduler.get_last_lr())\n        \n        for i in (range(0,train.shape[0],batch_size)):\n            net.zero_grad()\n            \n            X_train = torch.from_numpy(train[i:i+batch_size].values).type(torch.float).view(-1,1,28,28)\n            y_train = torch.from_numpy(test[i:i+batch_size].values)\n            X_train, y_train = X_train.to(device),y_train.to(device)\n            \n            output = net(X_train)\n            l = loss(output,y_train)\n            \n            l.backward()\n            optimizer.step()\n        \n        print(\"train loss : \" + str(l))\n        loss_list.append(l)\n\n","4be2052f":"RUN_NETWORK(data_train.drop('label',axis = 1),50,data_train['label'],85)","5d45b7ff":"plt.plot(np.arange(50),list(map(torch.Tensor.item,loss_list)))\nplt.show()","9b7a382e":"data_test = pd.read_csv('\/kaggle\/input\/sign-language-mnist\/sign_mnist_test.csv')","3b999799":"y_pred_train = torch.argmax(net(torch.from_numpy(data_train.drop('label',axis = 1).values.reshape(-1,1,28,28)).type(torch.float).to(device)),dim = 1)\ny_pred_test = torch.argmax(net(torch.from_numpy(data_test.drop('label',axis = 1).values.reshape(-1,1,28,28)).type(torch.float).to(device)),dim = 1)","4107fa1d":"from sklearn.metrics import accuracy_score\nprint(\"The obtained test accuracy is \" + str(accuracy_score(data_test['label'],np.array(y_pred_test.cpu()))))","d2e1f5ac":"<h1>PRINTING ACCURACY<h1>","928ec287":"<h1>DEFINING OUR NEURAL NETWORK<h1>\n    \n<h4>The architecture is similar to LeNet- 5<\/h4>\n    \n<img src = \"https:\/\/i.ibb.co\/BPCvrY4\/Screenshot-50.png\">","30560e2c":"<h1>LOSS VS ITERATIONS GRAPH<\/h1>","3de3677d":"<h1> IMPORTING THE TEST DATA <\/h1>","5299332a":"<h1>CONFIGURING GPU<\/h1>","aa676c0a":"<h1>IMPORTING LIBRARIES<h1>","febfe1b8":"<h1> READING TRAIN DATA <\/h1>","4ed3cc97":"<h1>THE SIGN LANGUAGE<\/h1>","f18ce474":"<h1>USER DEFINED FUNCTION FOR SHOWING IMAGE<\/h1>","337ce71c":"<h1>RUNNING THE NETWORK<\/h1>","eed3ade2":"<h1>INITIALIZING THE NEURAL NETWORK<\/h1>","69d54fe7":"<h1>FUNCTION TO RUN THE NEURAL NETWORK<\/h1>","e9c52531":"<h1>PREDICTING ON TRAIN AND TEST SET<\/h1>"}}