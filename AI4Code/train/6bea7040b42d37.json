{"cell_type":{"6043fd39":"code","4fceffbd":"code","00f786b0":"code","7635cca7":"code","5ce1ff6e":"code","ef2e0e1a":"code","13cbf8dd":"code","2153beda":"code","10bd14f6":"code","3664b654":"code","ba47934d":"code","d60acc9b":"code","2ef60a7e":"code","7dabd2e5":"code","efc979db":"code","60294f63":"code","73603f53":"code","31a1a3bd":"code","b9561f46":"code","c1b5eeda":"code","4b2ecffc":"code","50349b7e":"code","b792a716":"code","3082c0af":"code","121b5d00":"code","bf5239f1":"code","74d2245f":"code","589cb41a":"code","037aba46":"code","dc1b040d":"code","bd412e64":"code","7a32f285":"code","78fff957":"code","023ed48b":"code","ecc21994":"code","5479b19b":"code","f4627d99":"code","dd888efa":"code","f538e3fe":"code","6dde853e":"code","b62229e0":"code","dd7930fb":"code","b56edb26":"code","89d1f5b9":"code","c3cfa561":"code","d5a90f05":"code","f6c65215":"code","5d1e1411":"code","2256ea07":"code","352e0439":"code","f2b79a4b":"code","df33830a":"code","4b38fbd0":"code","507ae301":"code","8a07efd6":"code","aa5c6cf6":"code","35c429f9":"code","3e1b6803":"code","13681b3a":"code","9994eb10":"code","5cf30083":"code","1b24257f":"code","f21daada":"code","471d752e":"code","b9256c0b":"code","7c346961":"code","5e5e8563":"code","e72eea4d":"markdown"},"source":{"6043fd39":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport sys\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4fceffbd":"!cp ..\/input\/icevisiondeps\/icevision-deps.tgz .\/","00f786b0":"!tar xvfz icevision-deps.tgz","7635cca7":"!ls","5ce1ff6e":"!python -m pip install icevision-deps.tgz --no-index --no-deps","ef2e0e1a":"os.chdir(\"icevision-deps\/\")","13cbf8dd":"!pip install icevision-0.5.2-py3-none-any.whl -f .\/ --no-index --no-deps","2153beda":"!apt update","10bd14f6":"!apt install gcc","3664b654":"x","ba47934d":"from icevision.all import *","d60acc9b":"!ls ","2ef60a7e":"os.getcwd()\nos.chdir(\"icevision-deps\/\")","7dabd2e5":"import glob\nall_packs = glob.glob(\"*.whl\")\nall_packs_tars = glob.glob(\"*tar.gz\")","efc979db":"all_packs","60294f63":"%%time\nfor i in all_packs:\n    cmd = \"pip install {} -f .\/ --no-index --no-deps\".format(i)\n    os.system(cmd)","73603f53":"cmd = \"pip install {} -f .\/ --no-index --no-deps\".format(\"pycocotools-2.0.2.tar.gz\")\ncmd\nos.system(cmd)","31a1a3bd":"%%time\nfor i in all_packs_tars:\n    cmd = \"pip install {} -f .\/ --no-index --no-deps\".format(i)\n    os.system(cmd)","b9561f46":"from icevision.all import *","c1b5eeda":"!ls","4b2ecffc":"!pip install -e . -f .\/ --no-index","50349b7e":"!python setup.py install develop","b792a716":"os.chdir(\"..\/input\/icevision\/icevision\")","3082c0af":"!ls","121b5d00":"!pip install icevision -f .\/ --no-index ","bf5239f1":"!ls","74d2245f":"!pip install pycocotools","589cb41a":"!ls icevision\/icevision","037aba46":"from icevision import *","dc1b040d":"os.chdir(\"\")","bd412e64":"class_map = ClassMap([\"no\", 'impact'])\nclass_map","7a32f285":"model_pr = efficientdet.model(model_name=\"tf_efficientdet_d5\", num_classes=len(class_map), img_size=512)","78fff957":"DATA_ROOT_PATH = 'test_images'","023ed48b":"import glob","ecc21994":"video_dir = '..\/input\/nfl-impact-detection\/test\/'\nuniq_video = [xx.split('\/')[-1] for xx in glob.glob(f'{video_dir}\/*.mp4')]\nuniq_video","5479b19b":"video_dir = '..\/input\/nfl-impact-detection\/test\/'\nuniq_video = [xx.split('\/')[-1] for xx in glob.glob(f'{video_dir}\/*.mp4')]","f4627d99":"!ls ..\/input\/nfl-impact-detection\/","dd888efa":"%%time\nout_dir = DATA_ROOT_PATH\nif not os.path.exists(out_dir):\n    !mkdir -p $out_dir\n    video_dir = '..\/input\/nfl-impact-detection\/test'\n    uniq_video = [xx.split('\/')[-1] for xx in glob.glob(f'{video_dir}\/*.mp4')]\n    for video_name in uniq_video:\n        mk_images(video_name, pd.DataFrame(), video_dir, out_dir, only_with_impact=False)","f538e3fe":"!ls ..\/input\/icevision-trainedmodels","6dde853e":"#model_path = Path('gdrive\/MyDrive\/DeepLearningCollabs\/NFL_collision\/lightning_logs\/')\n#print(class_map)\nmodel_pr = efficientdet.model(model_name=\"tf_efficientdet_d5\", num_classes=len(class_map), img_size=512)\n#state_dict = torch.load('..\/input\/icevision-trainedmodels\/model__2classd5_epoch40 (1).pth', map_location=torch.device('cuda')) \nstate_dict = torch.load('..\/input\/icevision-trainedmodels\/model__2classd5_epoch40 (1).pth', map_location=torch.device('cuda')) \n#load the model\nmodel_pr.load_state_dict(state_dict)","b62229e0":"#!ls test_images","dd7930fb":"class_map","b56edb26":"#!pip install -U git+https:\/\/github.com\/albu\/albumentations --no-cache-dir","89d1f5b9":"import glob \n#all_test_imgs_loc = glob.glob(\"test_images\/*.png\")","c3cfa561":"%%time\nall_imgs = glob.glob(\"test_images\/*.png\")\n#all_opened_imgs = [np.array(Image.open(x)) for x in all_imgs]","d5a90f05":"infer_tfms = tfms.A.Adapter([*tfms.A.resize_and_pad(size=512), tfms.A.Normalize()])","f6c65215":"type(all_opened_imgs[0])","5d1e1411":"#infer_ds = Dataset.from_images(all_opened_imgs, infer_tfms)","2256ea07":"#infer_dl = efficientdet.infer_dl(infer_ds, batch_size=6)","352e0439":"#infer_ds = Dataset.from_images(all_opened_imgs[:1000], infer_tfms)\n#batch, samples = efficientdet.build_infer_batch(infer_ds)","f2b79a4b":"#preds = efficientdet.predict(model=model_pr, batch=batch,\n#                                         detection_threshold=0.15, device = 'cuda')","df33830a":"#preds[0]","4b38fbd0":"#infer_dl = efficientdet.infer_dl(infer_ds, batch_size=12)\n#samples, preds = efficientdet.predict_dl(model=model_pr, infer_dl=infer_dl,\n#                                         detection_threshold=0.15, device = 'cuda')","507ae301":"#preds[0]","8a07efd6":"#all_imgs[0]","aa5c6cf6":"#all_impact_list = []\n#for idx in range(10):\n    ","35c429f9":"%%time\nall_impact_list = []\nfor img_loc in tqdm(all_imgs, total = int(len(all_imgs))):\n    gameKey = img_loc.split(\"\/\")[-1].split(\"_\")[0]\n    playID = img_loc.split(\"\/\")[-1].split(\"_\")[1]\n    view_ = img_loc.split(\"\/\")[-1].split(\"_\")[2]\n    frame_ = img_loc.split(\"\/\")[-1].split(\"_\")[-1].replace(\".png\", \"\")\n    video_ = f'{gameKey}_{playID}_{view_}.mp4'\n    img = np.array(Image.open(img_loc))\n    infer_ds = Dataset.from_images([img], infer_tfms)\n    batch, samples = efficientdet.build_infer_batch(infer_ds)\n    preds = efficientdet.predict(model=model_pr, batch=batch,  detection_threshold=0.15,\n                                device = 'cuda')\n    impact_dets = {}\n    for lab, bbox in zip(preds[0][\"labels\"], preds[0]['bboxes']):\n        if lab == 2:\n            box_formatted = [bbox.xmin, bbox.width, bbox.ymin, bbox.height]\n            inner_list = [gameKey, playID, view_, video_, frame_, int(bbox.xmin), int(bbox.width), int(bbox.ymin), int(bbox.height)]\n            all_impact_list.append(inner_list)","3e1b6803":"df = pd.DataFrame(all_impact_list, columns=['gameKey','playID','view','video','frame','left','width','top','height'])\ndf.head()","13681b3a":"!mv * \/tmp\/","9994eb10":"import nflimpact\nenv = nflimpact.make_env()\nenv.predict(df) # df is a pandas dataframe of your entire submission file","5cf30083":"#from icevision.all import *\n#from PIL import Image\n#presize = 512\n#size = 512\n\n# The model was trained with normalized images, it's necessary to do the same in inference\n#infer_tfms = tfms.A.Adapter([*tfms.A.resize_and_pad(size=size), tfms.A.Normalize()])","1b24257f":"#%%time\n#all_impact_list = []\n#for img_loc in tqdm(all_test_imgs_loc, total = int(len(all_test_imgs_loc))):\n#    gameKey = img_loc.split(\"\/\")[-1].split(\"_\")[0]\n#    playID = img_loc.split(\"\/\")[-1].split(\"_\")[1]\n#    view_ = img_loc.split(\"\/\")[-1].split(\"_\")[2]\n#    frame_ = img_loc.split(\"\/\")[-1].split(\"_\")[-1].replace(\".png\", \"\")\n#    video_ = f'{gameKey}_{playID}_{view_}.mp4'\n#    img = np.array(Image.open(img_loc))\n#    infer_ds = Dataset.from_images([img], infer_tfms)\n#    batch, samples = efficientdet.build_infer_batch(infer_ds)\n#    preds = efficientdet.predict(model=model_pr, batch=batch,  detection_threshold=0.15,\n#                               ,device = 'cuda')\n#    impact_dets = {}\n#    for lab, bbox in zip(preds[0][\"labels\"], preds[0]['bboxes']):\n#        if lab == 2:\n#            box_formatted = [bbox.xmin, bbox.width, bbox.ymin, bbox.height]\n#            inner_list = [gameKey, playID, view_, video_, frame_, int(bbox.xmin), int(bbox.width), int(bbox.ymin), int(bbox.height)]\n#            all_impact_list.append(inner_list)","f21daada":"#df = pd.DataFrame(all_impact_list, columns=['gameKey','playID','view','video','frame','left','width','top','height'])","471d752e":"#import nflimpact\n#env = nflimpact.make_env()\n#env.predict(df) # df is a pandas dataframe of your entire submission file","b9256c0b":"#from icevision.all import *\n#from PIL import Image\n#presize = 512\n#size = 512\n\n# The model was trained with normalized images, it's necessary to do the same in inference\n# The model was trained with normalized images, it's necessary to do the same in inference\n#infer_tfms = tfms.A.Adapter([*tfms.A.resize_and_pad(size=size), tfms.A.Normalize()])\n\n# Whenever you have images in memory (numpy arrays) you can use `Dataset.from_images`\n#infer_ds = Dataset.from_images([all_test_imgs], infer_tfms)\n\n\n#class_map = ClassMap([\"no\", 'impact'])\n#class_map","7c346961":"#batch, samples = efficientdet.build_infer_batch(infer_ds)\n#preds = faster_rcnn.predict(model=model, batch=batch)","5e5e8563":"# For any model, the prediction steps are always the same\n# First call `build_infer_batch` and then `predict`\n#preds = efficientdet.predict(model=model_pr, batch=batch,  detection_threshold=0.15)","e72eea4d":"### Installation\n\n- **Constraint 1**: No internet installation. Some competitions are code competitions where you have to run an inference notebook, and I've seen a couple that require the notebook to run without internet.\n\n    1. Downloading dependencies and installing one by one \n\n    [installing python packages without internet and using source code as .tar.gz and .whl](https:\/\/stackoverflow.com\/questions\/36725843\/installing-python-packages-without-internet-and-using-source-code-as-tar-gz-and)\n\n    1. Doing a download from `pip` and installing (locally):\n\n        ```bash\n        mkdir icevision-deps\n        cd icevision-deps\n        pip download icevision[all] \n        cd ..\n        tar cvfz icevision-deps.tgz icevision-deps\n        ```\n\n    - Upload the .tgz to kaggle as a Dataset, then on the kaggle notebook:\n\n    ```python\n    !tar xvfz icevision-deps.tgz\n    os.chdir(\"icevision-deps\/\")\n    !pip install icevision-0.5.2-py3-none-any.whl -f .\/ --no-index\n    ```\n\n    Returns:\n\n    ```python\n    ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n    fastai 2.2.5 requires fastcore<1.4,>=1.3.8, but you have fastcore 1.3.2 which is incompatible\n    ```\n\n    ```python\n    from icevision.all import *\n    NameError: name 'Stateful' is not defined\n    ```\n\n    2. Try adding `-no-deps` \n\n    ```python\n    !pip install icevision-0.5.2-py3-none-any.whl -f .\/ --no-index --no-deps\n    ```\n\n    But you get:\n\n    ```python\n    from icevision.all import *\n    ModuleNotFoundError: No module named 'pycocotools'\n    ```\n\n    I tried following the Troubleshooting step in the iceVision instructions, but the no internet part doesnt help here. (apt udpate and apt install gcc) \n\n    3. Try installing dependencies one by one:\n\n    ```python\n    import glob\n    all_packs = glob.glob(\"*.whl\")\n    all_packs_tars = glob.glob(\"*tar.gz\")\n\n    for i in all_packs:\n        cmd = \"pip install {} -f .\/ --no-index --no-deps\".format(i)\n        os.system(cmd)\n    ```\n\n    ```python\n    ModuleNotFoundError: No module named 'pycocotools'\n    ```\n\n    ```python\n    cmd = \"pip install {} -f .\/ --no-index --no-deps\".format(\"pycocotools-2.0.2.tar.gz\")\n    os.system(cmd)\n    ```\n\n    ```python\n    \/opt\/conda\/lib\/python3.7\/inspect.py in _signature_from_callable(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\n       2206 \n       2207     if not callable(obj):\n    -> 2208         raise TypeError('{!r} is not a callable object'.format(obj))\n       2209 \n       2210     if isinstance(obj, types.MethodType):\n\n    TypeError: None is not a callable object\n    ```"}}