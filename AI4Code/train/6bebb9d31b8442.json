{"cell_type":{"9517f5fc":"code","62adb1ba":"code","f2f51766":"code","4903dee9":"code","6467981b":"code","410f1ac9":"code","f49c64fb":"code","2b3606c4":"code","b3b4af58":"code","d5e0ff5a":"code","8a707704":"code","93a91dc9":"code","b5388e89":"code","955f661a":"code","6db2b791":"code","7f917238":"code","9bc7b6ce":"code","66c6bab0":"code","043067ed":"code","ecd8a0f4":"code","435118e2":"code","5d45a20d":"code","922e2244":"code","d1c0e190":"code","47632de4":"code","aac080aa":"code","f0e7d1c1":"code","73089f0d":"code","9466e7e9":"code","e7e88328":"code","236ec7e5":"code","c7d4c76f":"code","03a147d3":"code","ccd20560":"code","e248b382":"code","933d1639":"code","c9a2b644":"code","b6fbb5d8":"code","6f193b2a":"code","e33a1b80":"code","6e97e45e":"code","ec51b220":"code","3a676c1c":"code","0d98d9ce":"code","c0a3d064":"code","58e4dd39":"code","34376df0":"code","679c6163":"code","6adc631b":"code","29aef748":"code","29164f8c":"code","176ef4ab":"code","1759de6c":"code","2c508899":"code","d05ddf5e":"code","e6d12667":"code","7df1a724":"markdown","5f90da16":"markdown","ff496659":"markdown","ca0c93c0":"markdown","395928ee":"markdown","2601573c":"markdown","35ebd934":"markdown","cb538eed":"markdown","47efa58e":"markdown","a267609d":"markdown","cb68833c":"markdown","db62b767":"markdown","174d2d09":"markdown","8865cda7":"markdown","55fec342":"markdown","effa66a7":"markdown","25afd573":"markdown","de0ce3a0":"markdown","506f7ee9":"markdown","347e72f8":"markdown","2c5acfa4":"markdown"},"source":{"9517f5fc":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\nimport tensorflow as tf\nimport time\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model\nfrom keras.layers import Input, Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D, Conv2D, Conv2DTranspose, LeakyReLU, UpSampling2D\nfrom keras import optimizers\nfrom keras.layers.normalization import BatchNormalization as BN\n\nfrom keras.layers import Lambda, Reshape, Add, AveragePooling2D, MaxPooling2D, Concatenate, SeparableConv2D\nfrom keras.models import Model\nfrom keras.losses import mse, binary_crossentropy\nfrom keras.utils import plot_model\nfrom keras import backend as K\n\nfrom keras.callbacks import ModelCheckpoint\n\nfrom keras.regularizers import l2\n\nfrom keras.preprocessing.image import array_to_img, img_to_array, load_img\n\nfrom sklearn.model_selection import train_test_split\n\nfrom PIL import Image, ImageDraw, ImageFilter\nprint(os.listdir(\"..\/input\"))","62adb1ba":"train = pd.read_csv('..\/input\/train.csv')","f2f51766":"train['ImageId'] = train['ImageId_ClassId'].str[:-2]\ntrain['ClassId'] = train['ImageId_ClassId'].str[-1:]\ntrain = train[['ImageId','ClassId','EncodedPixels']]\ntrain","4903dee9":"train = train.fillna(0)","6467981b":"train","410f1ac9":"start = time.time()\n\nfilelist = os.listdir(\"..\/input\/train_images\/\")\n\ntrain_img = []\n\nfor i in filelist:\n    x = train[train[\"ImageId\"] == i]\n    if len(x[x[\"EncodedPixels\"] == 0]) == 4:\n        pass\n        \n    else:\n        train_img.append(i)\n        \ntrain_img = np.array(train_img)\n\nelapsed_time = time.time() - start\nprint (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")","f49c64fb":"train_img","2b3606c4":"img_name = train[\"ImageId\"][43212]\nimg_name","b3b4af58":"abs_path = \"..\/input\/train_images\/\"","d5e0ff5a":"seed_image = cv2.imread(abs_path+img_name)\nseed_image = cv2.cvtColor(seed_image, cv2.COLOR_BGR2GRAY)\nplt.figure(figsize=(15,15))\nplt.imshow(seed_image, \"gray\")","8a707704":"seed_image_resize = cv2.resize(seed_image, dsize=(1600, 256))\nplt.figure(figsize=(15,15))\nplt.imshow(seed_image_resize, \"gray\")","93a91dc9":"seed_image.shape","b5388e89":"df_exact = train[train[\"ImageId\"] == img_name]\ndf_exact","955f661a":"df_exact2 = df_exact[df_exact[\"ClassId\"] == \"1\"]\ndf_exact2","6db2b791":"segment_4 = []\nfor i in range(4):\n    x = train[train[\"ImageId\"] == img_name]\n    x2 = x[x[\"ClassId\"] == str(i+1)]\n    x3 = x2[\"EncodedPixels\"].values[0]\n    \n    if x3 ==0:\n        x4 = \"ok\"\n        \n    else:\n        x4 = x3.split()\n        \n    segment_4.append(x4)\n\nsegment_4 = np.array(segment_4)","7f917238":"segment_4[3]","9bc7b6ce":"#\u30bb\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u306e\u751f\u6210\nseg_img = np.ones([seed_image.shape[0], seed_image.shape[1],5], dtype=np.uint8)\n\nfor j in range(4):\n    \n    seg_np = np.ones([seed_image.shape[0]*seed_image.shape[1]], dtype=np.uint8)\n    \n    if segment_4[j]==\"ok\":\n        pass\n    \n    else:\n        for i in range(len(segment_4[j])\/\/2):\n            start = int(segment_4[j][2*i])\n            length = int(segment_4[j][2*i+1])\n            seg_np[start:start+length]=0\n\n    seg_img[:,:,j+1] = seg_np.reshape([seed_image.shape[1],seed_image.shape[0]]).T","66c6bab0":"seg_img[:,:,0] = seg_img[:,:,0]*4 - seg_img[:,:,1] - seg_img[:,:,2] - seg_img[:,:,3] - seg_img[:,:,4]","043067ed":"seed_image = cv2.resize(seed_image, dsize=(800, 128))\nseg_img = cv2.resize(seg_img, dsize=(800, 128))","ecd8a0f4":"plt.figure(figsize=(15,15))\nplt.imshow(seed_image, \"gray\",vmin=0,vmax=255)","435118e2":"plt.figure(figsize=(15,15))\nplt.imshow(seg_img[:,:,0],\"gray\",vmin=0,vmax=1)","5d45a20d":"def vertical_flip(image,fmap, rate=0.5):\n    if np.random.rand() < rate:\n        image = image[::-1, :, :]\n        fmap = fmap[::-1, :, :]\n    return image, fmap\n\n\ndef horizontal_flip(image,fmap, rate=0.5):\n    if np.random.rand() < rate:\n        image = image[:, ::-1, :]\n        fmap = fmap[:, ::-1, :]\n    return image, fmap\n\ndef image_translation(img,fmap):\n    params = np.random.randint(-50, 51)\n    if not isinstance(params, list):\n        params = [params, params]\n    rows, cols, ch = img.shape\n\n    M = np.float32([[1, 0, params[0]], [0, 1, params[1]]])\n    dst = cv2.warpAffine(img, M, (cols, rows))\n    fmap = cv2.warpAffine(fmap, M, (cols, rows))\n    return np.expand_dims(dst, axis=-1), fmap\n\ndef image_shear(img,fmap):\n    params = np.random.randint(-20, 21)*0.01\n    rows, cols, ch = img.shape\n    factor = params*(-1.0)\n    M = np.float32([[1, factor, 0], [0, 1, 0]])\n    dst = cv2.warpAffine(img, M, (cols, rows))\n    fmap = cv2.warpAffine(fmap, M, (cols, rows))\n    return np.expand_dims(dst, axis=-1), fmap\n\ndef image_rotation(img,fmap):\n    params = np.random.randint(-5, 6)\n    rows, cols, ch = img.shape\n    M = cv2.getRotationMatrix2D((cols\/2, rows\/2), params, 1)\n    dst = cv2.warpAffine(img, M, (cols, rows))\n    fmap = cv2.warpAffine(fmap, M, (cols, rows))\n    return np.expand_dims(dst, axis=-1),fmap\n\ndef image_contrast(img,fmap):\n    params = np.random.randint(7, 10)*0.1\n    alpha = params\n    new_img = cv2.multiply(img, np.array([alpha]))                    # mul_img = img*alpha\n    #new_img = cv2.add(mul_img, beta)                                  # new_img = img*alpha + beta\n  \n    return np.expand_dims(new_img, axis=-1), fmap\n\ndef image_blur(img,fmap):\n    params = params = np.random.randint(1, 21)\n    blur = []\n    if params == 1:\n        blur = cv2.blur(img, (3, 3))\n    if params == 2:\n        blur = cv2.blur(img, (4, 4))\n    if params == 3:\n        blur = cv2.blur(img, (5, 5))\n    if params == 4:\n        blur = cv2.GaussianBlur(img, (3, 3), 0)\n    if params == 5:\n        blur = cv2.GaussianBlur(img, (5, 5), 0)\n    if params == 6:\n        blur = cv2.GaussianBlur(img, (7, 7), 0)\n    if params == 7:\n        blur = cv2.medianBlur(img, 3)\n    if params == 8:\n        blur = cv2.medianBlur(img, 5)\n    if params == 9:\n        blur = cv2.blur(img, (6, 6))\n    if params == 10:\n        blur = cv2.bilateralFilter(img, 9, 75, 75)\n    if params > 10:\n        blur = img\n        \n    return blur.reshape([blur.shape[0],blur.shape[1],1]), fmap\n\ndef image_bitwise_not(image,fmap, rate=0.5):\n    if np.random.rand() < rate:\n        image = cv2.bitwise_not(image)\n        image = np.expand_dims(image, axis=-1)\n    return image, fmap","922e2244":"seed_image2 = np.expand_dims(seed_image, axis=-1)","d1c0e190":"dst, fmap = vertical_flip(seed_image2, seg_img)\n\nplt.subplot(2, 1, 1)\nplt.imshow(dst[:,:,0], \"gray\")\nplt.subplot(2, 1, 2)\nplt.imshow(fmap[:,:,0], \"gray\",vmin=0,vmax=1)","47632de4":"dst, fmap = horizontal_flip(seed_image2, seg_img)\n\nplt.subplot(2, 1, 1)\nplt.imshow(dst[:,:,0], \"gray\")\nplt.subplot(2, 1, 2)\nplt.imshow(fmap[:,:,0], \"gray\")","aac080aa":"dst, fmap = image_translation(seed_image2, seg_img)\n\nplt.subplot(2, 1, 1)\nplt.imshow(dst[:,:,0], \"gray\")\nplt.subplot(2, 1, 2)\nplt.imshow(fmap[:,:,0], \"gray\")","f0e7d1c1":"dst, fmap = image_shear(seed_image2, seg_img)\nplt.figure(figsize=(15,5))\nplt.subplot(2, 1, 1)\nplt.imshow(dst[:,:,0], \"gray\")\nplt.subplot(2, 1, 2)\nplt.imshow(fmap[:,:,0], \"gray\")","73089f0d":"dst, fmap = image_rotation(seed_image2, seg_img)\nplt.figure(figsize=(15,5))\nplt.subplot(2, 1, 1)\nplt.imshow(dst[:,:,0], \"gray\")\nplt.subplot(2, 1, 2)\nplt.imshow(fmap[:,:,0], \"gray\")","9466e7e9":"dst, fmap = image_contrast(seed_image2, seg_img)\nplt.figure(figsize=(15,5))\nplt.subplot(2, 1, 1)\nplt.imshow(dst[:,:,0], \"gray\")\nplt.subplot(2, 1, 2)\nplt.imshow(fmap[:,:,0], \"gray\")","e7e88328":"dst, fmap = image_blur(seed_image2, seg_img)\nplt.figure(figsize=(15,5))\nplt.subplot(2, 1, 1)\nplt.imshow(dst[:,:,0], \"gray\")\nplt.subplot(2, 1, 2)\nplt.imshow(fmap[:,:,0], \"gray\")","236ec7e5":"dst, fmap = image_bitwise_not(seed_image2, seg_img)\nplt.figure(figsize=(15,5))\nplt.subplot(2, 1, 1)\nplt.imshow(dst[:,:,0], \"gray\")\nplt.subplot(2, 1, 2)\nplt.imshow(fmap[:,:,0], \"gray\")","c7d4c76f":"np.random.seed(2019)\nnp.random.shuffle(train_img)\ntrain_num = int(len(train_img)*0.80)\ntrain_idx = train_img[:train_num]\nval_idx = train_img[train_num:]","03a147d3":"len(train_idx)","ccd20560":"len(val_idx)","e248b382":"img_width, img_height = 800, 128\nnum_train = len(train_idx)\nnum_val = len(val_idx)\nbatch_size = 8\nprint(num_train, num_val)\nabs_path = \"..\/input\/train_images\/\"","933d1639":"def get_segment_data(train, img_name, img_height, img_width):\n    segment_4 = []\n    for i in range(4):\n        x = train[train[\"ImageId\"] == img_name]\n        x2 = x[x[\"ClassId\"] == str(i+1)]\n        x3 = x2[\"EncodedPixels\"].values[0]\n\n        if x3 ==0:\n            x4 = \"ok\"\n\n        else:\n            x4 = x3.split()\n            \n        segment_4.append(x4)\n\n    segment_4 = np.array(segment_4)\n    \n    #\u30bb\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u306e\u751f\u6210\n    seg_img = np.zeros([img_height, img_width,5], dtype=np.uint8)\n\n    for j in range(4):\n\n        seg_np = np.zeros([img_height*img_width], dtype=np.uint8)\n\n        if segment_4[j]==\"ok\":\n            pass\n\n        else:\n            length=len(segment_4[j])\/\/2\n            for i in range(length):\n                start = int(segment_4[j][2*i])\n                length = int(segment_4[j][2*i+1])\n                seg_np[start:start+length]=1\n\n        seg_img[:,:,j+1] = seg_np.reshape([img_width,img_height]).T\n        \n    #seg_img[:,:,0] = np.ones([seed_image.shape[0], seed_image.shape[1]], dtype=np.uint8) - seg_img[:,:,1] - seg_img[:,:,2] - seg_img[:,:,3] - seg_img[:,:,4]\n                \n    return seg_img","c9a2b644":"def get_random_data(train_pd, img_index_1, abs_path, img_width, img_height, data_aug):\n    image_file = abs_path + img_index_1\n    \n    seed_image = cv2.imread(image_file)\n    seed_image = cv2.cvtColor(seed_image, cv2.COLOR_BGR2GRAY)\n    fmap = get_segment_data(train_pd, img_index_1, img_height*2, img_width*2)\n    seed_image = np.expand_dims(seed_image, axis=-1)\n    \n    if data_aug:\n        \n        r = np.random.rand()\n        \n        if r >= 0.5:\n    \n            seed_image, fmap = vertical_flip(seed_image, fmap)\n            seed_image, fmap = horizontal_flip(seed_image, fmap)\n            seed_image, fmap = image_shear(seed_image, fmap)\n            seed_image, fmap = image_rotation(seed_image, fmap)\n            seed_image, fmap = image_contrast(seed_image, fmap)\n            \n    seed_image_resize = cv2.resize(seed_image, dsize=(img_width, img_height))\n    seed_image_resize = np.expand_dims(seed_image_resize, axis=-1)\n    \n    seed_image = seed_image \/ 255\n    seed_image_resize = seed_image_resize \/ 255\n    \n    fmap[:,:,0] = np.ones([img_height*2, img_width*2], dtype=np.float32) - fmap[:,:,1] - fmap[:,:,2] - fmap[:,:,3] - fmap[:,:,4]\n    \n    return seed_image_resize, seed_image, fmap","b6fbb5d8":"def data_generator(train_pd, img_index, batch_size, abs_path, img_width, img_height, data_aug):\n    '''data generator for fit_generator'''\n    n = len(img_index)\n    i = 0\n    while True:\n        image_data_resize = []\n        image_data = []\n        fmap_data = []\n        for b in range(batch_size):\n            if i==0:\n                np.random.shuffle(img_index)\n            image_resize, image, fmap = get_random_data(train_pd, img_index[i], abs_path, img_width, img_height, data_aug)\n            image_data_resize.append(image_resize)\n            image_data.append(image)\n            fmap_data.append(fmap)\n            i = (i+1) % n\n        image_data_resize = np.array(image_data_resize)\n        image_data = np.array(image_data)\n        fmap_data = np.array(fmap_data)\n        yield [image_data_resize, image_data], fmap_data\n\ndef data_generator_wrapper(train_pd, img_index, batch_size, abs_path, img_width, img_height, data_aug):\n    n = len(img_index)\n    if n==0 or batch_size<=0: return None\n    return data_generator(train_pd, img_index, batch_size, abs_path, img_width, img_height, data_aug)","6f193b2a":"def resnet_en(data, filters, kernel_size, dilation_rate,option=False):\n    if option:\n        x=BN()(data)\n        x = Activation(\"relu\")(x)\n        x=Conv2D(filters=filters,kernel_size=kernel_size,dilation_rate=dilation_rate,strides=(1,1),padding=\"same\")(x)\n\n        x=BN()(x)\n        x = Activation(\"relu\")(x)\n        x=Conv2D(filters=filters,kernel_size=kernel_size,dilation_rate=(1,1),strides=(2,2),padding=\"same\")(x)\n        \n    else:\n        x=BN()(data)\n        x = Activation(\"relu\")(x)\n        x=Conv2D(filters=filters,kernel_size=kernel_size,dilation_rate=dilation_rate,strides=(1,1),padding=\"same\")(x)\n\n        x=BN()(x)\n        x = Activation(\"relu\")(x)\n        x=Conv2D(filters=filters,kernel_size=kernel_size,dilation_rate=dilation_rate,strides=(1,1),padding=\"same\")(x)\n\n    return x","e33a1b80":"def shortcut_en(x, residual):\n    '''shortcut connection \u3092\u4f5c\u6210\u3059\u308b\u3002\n    '''\n    x_shape = K.int_shape(x)\n    residual_shape = K.int_shape(residual)\n\n    if x_shape == residual_shape:\n        # x \u3068 residual \u306e\u5f62\u72b6\u304c\u540c\u3058\u5834\u5408\u3001\u306a\u306b\u3082\u3057\u306a\u3044\u3002\n        shortcut = x\n    else:\n        # x \u3068 residual \u306e\u5f62\u72b6\u304c\u7570\u306a\u308b\u5834\u5408\u3001\u7dda\u5f62\u5909\u63db\u3092\u884c\u3044\u3001\u5f62\u72b6\u3092\u4e00\u81f4\u3055\u305b\u308b\u3002\n        stride_w = int(round(x_shape[1] \/ residual_shape[1]))\n        stride_h = int(round(x_shape[2] \/ residual_shape[2]))\n\n        shortcut = Conv2D(filters=residual_shape[3],\n                          kernel_size=(1, 1),\n                          strides=(stride_w, stride_h),\n                          kernel_initializer='he_normal',\n                          kernel_regularizer=l2(1.e-4))(x)\n    return Add()([shortcut, residual])","6e97e45e":"def upsampling_unit(x, first_filter, number):\n    for i in range(number):\n        x = UpSampling2D((2,2))(x)\n        #16*100\n        x=Conv2D(filters=first_filter\/\/(2**i),kernel_size=(3,3),strides=(1,1),padding=\"same\")(x)\n        x = BN()(x)\n        x = Activation(\"relu\")(x)\n\n    return x","ec51b220":"def PSP_unit(x, filters):\n    x1 = MaxPooling2D((1,1),padding=\"same\")(x)\n    x1=Conv2DTranspose(filters=filters\/\/4,kernel_size=(1,1),strides=(1,1),padding=\"same\")(x1)\n    x1 = BN()(x1)\n    x1 = Activation(\"relu\")(x1)\n\n    x2 = MaxPooling2D((2,2),padding=\"same\")(x)\n    x2=Conv2DTranspose(filters=filters\/\/4,kernel_size=(1,1),strides=(2,2),padding=\"same\")(x2)\n    x2 = BN()(x2)\n    x2 = Activation(\"relu\")(x2)\n\n    x3 = MaxPooling2D((4,5),padding=\"same\")(x)\n    x3=Conv2DTranspose(filters=filters\/\/4,kernel_size=(1,1),strides=(4,5),padding=\"same\")(x3)\n    x3 = BN()(x3)\n    x3 = Activation(\"relu\")(x3)\n\n    x4 = MaxPooling2D((8,10),padding=\"same\")(x)\n    x4=Conv2DTranspose(filters=filters\/\/4,kernel_size=(1,1),strides=(8,10),padding=\"same\")(x4)\n    x4 = BN()(x4)\n    x4 = Activation(\"relu\")(x4)\n\n    return Concatenate()([x,x1,x2,x3,x4])","3a676c1c":"inputs = Input(shape=(img_height, img_width, 1))\n\n#128*800\nfx = resnet_en(inputs, 16, (3,3), (1,1))\nx = shortcut_en(inputs, fx)\nfx = resnet_en(x, 16, (3,3), (1,1), True)\nx = shortcut_en(x, fx)\n\n#64*400\nfx = resnet_en(x, 32, (3,3), (1,1))\nx = shortcut_en(x, fx)\nfx = resnet_en(x, 32, (3,3), (1,1), True)\nx = shortcut_en(x, fx)\n\n#32*200\nfx = resnet_en(x, 64, (3,3), (1,1))\nx = shortcut_en(x, fx)\nfx = resnet_en(x, 64, (3,3), (1,1))\nx = shortcut_en(x, fx)\n\nfx = resnet_en(x, 64, (3,3), (1,1))\nx = shortcut_en(x, fx)\nfx = resnet_en(x, 64, (3,3), (1,1), True)\nx = shortcut_en(x, fx)\n\n#16*100\nfx = resnet_en(x, 128, (3,3), (1,1))\nx = shortcut_en(x, fx)\nfx = resnet_en(x, 128, (3,3), (1,1))\nx = shortcut_en(x, fx)\n\nfx = resnet_en(x, 128, (3,3), (1,1))\nx = shortcut_en(x, fx)\nfx = resnet_en(x, 128, (3,3), (1,1))\nx = shortcut_en(x, fx)\n\nfx = resnet_en(x, 256, (3,3), (2,2))\nx = shortcut_en(x, fx)\nfx = resnet_en(x, 256, (3,3), (2,2))\nx = shortcut_en(x, fx)\n\nfx = resnet_en(x, 256, (3,3), (2,2))\nx = shortcut_en(x, fx)\nfx = resnet_en(x, 256, (3,3), (2,2))\nx = shortcut_en(x, fx)\n\nfx = resnet_en(x, 256, (3,3), (4,4))\nx = shortcut_en(x, fx)\nfx = resnet_en(x, 256, (3,3), (4,4))\nx = shortcut_en(x, fx)\n\nfx = resnet_en(x, 256, (3,3), (4,4))\nx = shortcut_en(x, fx)\nfx = resnet_en(x, 256, (3,3), (4,4))\nx = shortcut_en(x, fx)\n\nx=Conv2D(filters=512,kernel_size=(3,3),dilation_rate=(2,2),strides=(1,1),padding=\"same\")(x)\nx = BN()(x)\nx = Activation(\"relu\")(x)\n\nx=Conv2D(filters=512,kernel_size=(3,3),dilation_rate=(2,2),strides=(1,1),padding=\"same\")(x)\nx = BN()(x)\nx = Activation(\"relu\")(x)\n\nx=Conv2D(filters=512,kernel_size=(3,3),dilation_rate=(1,1),strides=(1,1),padding=\"same\")(x)\nx = BN()(x)\nx = Activation(\"relu\")(x)\n\nx=Conv2D(filters=512,kernel_size=(3,3),dilation_rate=(1,1),strides=(1,1),padding=\"same\")(x)\nx = BN()(x)\nx = Activation(\"relu\")(x)\n\nx = PSP_unit(x, 512)\n\nx1 = Conv2DTranspose(filters=256,kernel_size=(1,1),strides=(2,2),padding=\"same\",kernel_initializer='he_normal',\n                          kernel_regularizer=l2(1.e-4))(x)\n\nx = UpSampling2D((2,2))(x)\nx=Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding=\"same\")(x)\nx = BN()(x)\nx = Activation(\"relu\")(x)\n\nx = Add()([x,x1])\n\nx2 = Conv2DTranspose(filters=128,kernel_size=(1,1),strides=(2,2),padding=\"same\",kernel_initializer='he_normal',\n                          kernel_regularizer=l2(1.e-4))(x)\n\nx = UpSampling2D((2,2))(x)\nx=Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding=\"same\")(x)\nx = BN()(x)\nx = Activation(\"relu\")(x)\n\nx = Add()([x,x2])\n\nx3 = Conv2DTranspose(filters=64,kernel_size=(1,1),strides=(2,2),padding=\"same\",kernel_initializer='he_normal',\n                          kernel_regularizer=l2(1.e-4))(x)\n\nx = UpSampling2D((2,2))(x)\nx=Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding=\"same\")(x)\nx = BN()(x)\nx = Activation(\"relu\")(x)\n\nx = Add()([x,x3])\n\nx4 = Conv2DTranspose(filters=8,kernel_size=(1,1),strides=(2,2),padding=\"same\",kernel_initializer='he_normal',\n                          kernel_regularizer=l2(1.e-4))(x)\n\nx = UpSampling2D((2,2))(x)\nx=Conv2D(filters=8,kernel_size=(3,3),strides=(1,1),padding=\"same\")(x)\nx = BN()(x)\nx = Activation(\"relu\")(x)\n\nx = Add()([x,x4])\n\ninputs_2 = Input(shape=(256, 1600, 1))\nxa=Conv2D(filters=8,kernel_size=(3,3),strides=(1,1),padding=\"same\")(inputs_2)\nxa = BN()(xa)\nxa = Activation(\"relu\")(xa)\n\nx = Add()([x,xa])\n\nx=Conv2D(filters=5,kernel_size=(1,1),strides=(1,1),padding=\"same\")(x)\noutputs = Activation('softmax')(x)\n\n# instantiate decoder model\nmodel = Model([inputs, inputs_2], outputs)\nmodel.summary()\n\nmodel.compile(optimizer=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n             loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","0d98d9ce":"from IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\n\nSVG(model_to_dot(model).create(prog='dot', format='svg'))","c0a3d064":"modelCheckpoint = ModelCheckpoint(filepath = 'best_weight.h5',\n                                  monitor='val_acc',\n                                  verbose=1,\n                                  save_best_only=True,\n                                  save_weights_only=True,\n                                  mode='max',\n                                  period=1)","58e4dd39":"start = time.time()\n\nmodel.fit_generator(data_generator_wrapper(train,train_idx, batch_size, abs_path, img_width, img_height, True),\n        steps_per_epoch=max(1, num_train\/\/batch_size),\n        validation_data=data_generator_wrapper(train,val_idx, batch_size, abs_path, img_width, img_height, False),\n        validation_steps=max(1, num_val\/\/batch_size),\n        epochs=5,\n        initial_epoch=0,\n        callbacks=[modelCheckpoint])\n\nelapsed_time = time.time() - start\nprint (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")","34376df0":"model.load_weights(\"best_weight.h5\")","679c6163":"test_path = \"..\/input\/test_images\/\"\n\ntest_list = os.listdir(test_path)\n\nabs_name = test_path + test_list[3]\nseed_image = cv2.imread(abs_name)\nseed_image = cv2.cvtColor(seed_image, cv2.COLOR_BGR2GRAY)\nseed_image_resize = cv2.resize(seed_image, dsize=(img_width, img_height))\nseed_image_resize = np.expand_dims(seed_image_resize, axis=-1)\nseed_image_resize = np.expand_dims(seed_image_resize, axis=0)\nseed_image_resize = seed_image_resize\/255\n\nseed_image = np.expand_dims(seed_image, axis=-1)\nseed_image = np.expand_dims(seed_image, axis=0)\nseed_image = seed_image\/255\n\npred = model.predict([seed_image_resize, seed_image])[0]","6adc631b":"plt.figure(figsize=(15,15))\nplt.imshow(seed_image[0,:,:,0], \"gray\")","29aef748":"fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(5, 1, figsize=(15,15), sharey=True)\nsns.heatmap(pred[:,:,0],vmin=0, vmax=1, ax=ax1)\nsns.heatmap(pred[:,:,1],vmin=0, vmax=1, ax=ax2)\nsns.heatmap(pred[:,:,2],vmin=0, vmax=1, ax=ax3)\nsns.heatmap(pred[:,:,3],vmin=0, vmax=1, ax=ax4)\nsns.heatmap(pred[:,:,4],vmin=0, vmax=1, ax=ax5)","29164f8c":"def make_testdata(a):\n\n    data = []\n    c = 1\n\n    for i in range(a.shape[0]-1):\n        if a[i]+1 == a[i+1]:\n            c += 1\n            if i == a.shape[0]-2:\n                data.append(str(a[i-c+2]))\n                data.append(str(c))\n\n        if a[i]+1 != a[i+1]:\n            data.append(str(a[i-c+1]))\n            data.append(str(c))\n            c = 1\n\n    data = \" \".join(data)\n    return data","176ef4ab":"start = time.time()\n\ntest_path = \"..\/input\/test_images\/\"\n\ntest_list = os.listdir(test_path)\n\ndata = []\n\nfor fn in test_list:\n    abs_name = test_path + fn\n    seed_image = cv2.imread(abs_name)\n    seed_image = cv2.cvtColor(seed_image, cv2.COLOR_BGR2GRAY)\n    seed_image_resize = cv2.resize(seed_image, dsize=(img_width, img_height))\n    seed_image_resize = np.expand_dims(seed_image_resize, axis=-1)\n    seed_image_resize = np.expand_dims(seed_image_resize, axis=0)\n    seed_image_resize = seed_image_resize\/255\n\n    seed_image = np.expand_dims(seed_image, axis=-1)\n    seed_image = np.expand_dims(seed_image, axis=0)\n    seed_image = seed_image\/255\n\n    pred = model.predict([seed_image_resize, seed_image])[0]\n    \n    for i in range(4):\n        \n        pred_fi = pred[:,:,i+1].T.flatten()\n        pred_fi = np.where(pred_fi > 0.5, 1, 0)\n        pred_fi_id = np.where(pred_fi == 1)\n        pred_fi_id = make_testdata(pred_fi_id[0])\n        x = [fn + \"_\" + str(i+1), pred_fi_id]\n        data.append(x)\n\nelapsed_time = time.time() - start\nprint (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")","1759de6c":"columns = ['ImageId_ClassId', 'EncodedPixels']","2c508899":"d = pd.DataFrame(data=data, columns=columns, dtype='str')","d05ddf5e":"d.to_csv(\"submission.csv\",index=False)","e6d12667":"df = pd.read_csv(\"submission.csv\")\nprint(df)","7df1a724":"# indicate segment","5f90da16":"# for train index","ff496659":"ver27\n\u30e2\u30c7\u30eb -- Unet\u8981\u7d20\u3092\u5165\u308c\u3066\u307f\u308b\n\u30c7\u30fc\u30bf\u62e1\u5f35 -- \u753b\u50cf\u30cd\u30ac\u30dd\u30b8\u3092\u5ec3\u6b62\u2192\u7cbe\u5ea6\u51fa\u305a\uff08\uff1cUnet_elu 0.85\uff09","ca0c93c0":"ver30\u30e2\u30c7\u30eb\n--\u8a55\u4fa1\u65b9\u6cd5\u2192\u95be\u5024\u30920.25\n--ver27\u3092\u63a1\u7528\u2192\u7cbe\u5ea6\u51fa\u305a","395928ee":"ver36\u30e2\u30c7\u30eb--\n1. ver35\u3067\u30c7\u30fc\u30bf\u62e1\u5f35\u306e\u30cd\u30ac\u30dd\u30b8\u53cd\u8ee2\u3092\u3084\u3081\u308b\n2. relu\u2192elu\u306b\u5909\u66f4\n3. \u5168conv\u306e\u30ab\u30fc\u30cd\u30eb\u30b5\u30a4\u30ba\u30923*3\u306b\u5909\u66f4\n4.\u3000\u8907\u6570\u89e3\u50cf\u5ea6\u3067PSP\u8981\u7d20\u3092\u3084\u3081\u308b\n\u2192\u7cbe\u5ea6\u3067\u306a\u3044","2601573c":"# data load","35ebd934":"# indicate image","cb538eed":"ver25\n\u30e2\u30c7\u30eb -- \u8907\u6570\u89e3\u50cf\u5ea6\u3067upsampling\u3057\u3066\u6700\u5f8c\u306bconcat\n\u30c7\u30fc\u30bf\u62e1\u5f35 -- \u753b\u50cf\u30cd\u30ac\u30dd\u30b8\u3092\u8ffd\u52a0\n\u2192\u7cbe\u5ea6\u51fa\u305a","47efa58e":"ver36\u30e2\u30c7\u30eb--\n1. ver35\u3067\u30c7\u30fc\u30bf\u62e1\u5f35\u306e\u30cd\u30ac\u30dd\u30b8\u53cd\u8ee2\u3092\u3084\u3081\u308b\n2. relu\u2192elu\u306b\u5909\u66f4\n3. \u5168conv\u306e\u30ab\u30fc\u30cd\u30eb\u30b5\u30a4\u30ba\u30923*3\u306b\u5909\u66f4\n\u2192\u7cbe\u5ea6\u3067\u306a\u3044","a267609d":"ver28\u30e2\u30c7\u30eb\n--\u8a55\u4fa1\u65b9\u6cd5\u2192Unet_elu\u3067\u306f\u95be\u5024\u30920.25\u306b\u3057\u3066\u3044\u305f\u30fb\u30fb\u30fb\n--ver24 DRN_PSPnet\u306e\u30aa\u30ea\u30b8\u30ca\u30eb\u3067\u518d\u5ea6\u30c8\u30e9\u30a4","cb68833c":"ver34\u30e2\u30c7\u30eb--\u8a55\u4fa1\u65b9\u6cd5\u2192\u95be\u50240.25 ver33\u306e\u89e3\u50cf\u5ea6\u3092\u3055\u3089\u306b\u5897\u3084\u3059\u2192\u7cbe\u5ea6\u51fa\u305a0.71","db62b767":"# make model","174d2d09":"# Data Augmentation","8865cda7":"ver38\n\n1. \u753b\u50cf\u30b5\u30a4\u30ba\u3092\u534a\u5206\u3057\u3066\u901a\u5e38\u306eDRN+PSPnet\u3067\u518d\u5b66\u7fd2\n\nver39,40,41,42\n\n1. \u5165\u529b\uff1a128*800 \u51fa\u529b:256*1600\u306b\u5909\u66f4\u3057\u3066\u7279\u5fb4\u30de\u30c3\u30d7\u3092\u751f\u6210\u3059\u308b\u30de\u30c3\u30d7\u30b5\u30a4\u30ba\u306e\u5c64\u306b256*1600\u306e\u753b\u50cf\u30b5\u30a4\u30ba\u306e\u5165\u529b\u3092\u52a0\u3048\u308b","55fec342":"# import lib","effa66a7":"ver26\n\u30e2\u30c7\u30eb -- \u8907\u6570\u89e3\u50cf\u5ea6\u3067upsampling\u3057\u3066\u6700\u5f8c\u306bconcat\n\u30c7\u30fc\u30bf\u62e1\u5f35 -- \u753b\u50cf\u30cd\u30ac\u30dd\u30b8\u3092\u5ec3\u6b62\u2192\u7cbe\u5ea6\u51fa\u305a****","25afd573":"# train split","de0ce3a0":"ver29\u30e2\u30c7\u30eb\n--\u8a55\u4fa1\u65b9\u6cd5\u2192\u95be\u5024\u30920.25\n--ver25\u306e\u63a1\u7528","506f7ee9":"ver31,32,33\u30e2\u30c7\u30eb--\u8a55\u4fa1\u65b9\u6cd5\u2192\u95be\u50240.25 ver29\u306e\u89e3\u50cf\u5ea6\u3092\u5897\u3084\u3059\n\u89e3\u6790\u6642\u9593\u304c1\u6642\u9593\u3092\u8d85\u3048\u3066\u3057\u307e\u3063\u305f\u306e\u3067epoch\u6570\u3092\u5909\u66f4","347e72f8":"ver35\u30e2\u30c7\u30eb--ver34\u3067\u8a55\u4fa1\u65b9\u6cd5\u2192\u95be\u50240.5\u306b\u5909\u66f4","2c5acfa4":"# pred test"}}