{"cell_type":{"67324708":"code","22059ffb":"code","91655575":"code","ab754d54":"code","273a422c":"code","792bfaf7":"code","4324f7b4":"code","ae5d4817":"code","43b761c4":"code","2ba54c0e":"code","f7f2582d":"code","e273cdf7":"code","92b4eee4":"code","d06d096b":"code","63f16182":"code","0694b3c0":"code","87a5d025":"code","86cb037a":"code","e9acd937":"code","0f64e44a":"code","e778d8e6":"code","78648888":"code","a3ee7e69":"code","ef8eea68":"code","63e5b5c7":"code","63f4294d":"code","e17ffeca":"code","9ca71329":"code","9b59d8a0":"code","8e4d0fad":"code","e0675a6e":"code","fc3ad649":"code","fbe57c42":"code","643ee85a":"code","99622437":"code","037a9fcb":"code","e5d94863":"code","30b628f8":"code","82c34e41":"code","a075d339":"code","26d6584c":"code","346c365a":"code","bbce6f0e":"code","7213d5ce":"code","2b283b76":"code","afa1f694":"code","abd36a24":"code","3f998f35":"code","f53f5cb3":"code","f1e2e64d":"code","4a92ab59":"code","c9dd5b2c":"code","87b1cfc3":"code","a44855d0":"code","943d55e2":"code","10154677":"code","a8c6bd2c":"code","584c3a9b":"code","7c559934":"code","f128d821":"code","cc0f9d89":"code","d89b80b0":"code","4477293f":"code","06060ee3":"code","2df811ef":"code","04c35a5e":"code","97fb67f9":"markdown","ca5f4bc6":"markdown","817d8170":"markdown","20f2c678":"markdown","b302ca42":"markdown","3f3005e6":"markdown","c010072c":"markdown","b4761b53":"markdown","9e53198c":"markdown","d40c0257":"markdown","36b12b47":"markdown","f9c04880":"markdown","ac97b0e4":"markdown","f521f189":"markdown","af08cc15":"markdown","23c2a2bb":"markdown","2b8ea6b0":"markdown","331c81f3":"markdown","69ba8d80":"markdown","4679812d":"markdown","fd60f5c0":"markdown","54ed5b4d":"markdown","b9f39b17":"markdown","b762ab86":"markdown","9dd5abe6":"markdown","9d1a05ff":"markdown","7b09277f":"markdown"},"source":{"67324708":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom warnings import filterwarnings\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nimport os\nimport os.path\nfrom pathlib import Path\nimport cv2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nfrom keras.optimizers import RMSprop,Adam\nimport glob\nfrom PIL import Image\nfrom sklearn.preprocessing import StandardScaler\nfrom keras.preprocessing import image\nfrom keras.layers import SimpleRNN\nfrom keras.layers import LSTM","22059ffb":"filterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","91655575":"Flowers_All_Path = Path(\"..\/input\/flowers-recognition\/flowers\")","ab754d54":"Flowers_JPG_Path = list(Flowers_All_Path.glob(r\"*\/*.jpg\"))","273a422c":"Flowers_JPG_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],Flowers_JPG_Path))","792bfaf7":"JPG_Path_Series = pd.Series(Flowers_JPG_Path,name=\"JPG\").astype(str)","4324f7b4":"JPG_Labels_Series = pd.Series(Flowers_JPG_Labels,name=\"CATEGORY\")","ae5d4817":"print(JPG_Path_Series.head(-1))","43b761c4":"print(JPG_Labels_Series.head(-1))","2ba54c0e":"Main_Data = pd.concat([JPG_Path_Series,JPG_Labels_Series],axis=1)","f7f2582d":"print(Main_Data.head(-1))","e273cdf7":"print(Main_Data[\"JPG\"][1])\nprint(Main_Data[\"CATEGORY\"][1])\nprint(Main_Data[\"JPG\"][1398])\nprint(Main_Data[\"CATEGORY\"][1398])\nprint(Main_Data[\"JPG\"][355])\nprint(Main_Data[\"CATEGORY\"][355])\nprint(Main_Data[\"JPG\"][710])\nprint(Main_Data[\"CATEGORY\"][710])\nprint(Main_Data[\"JPG\"][1001])\nprint(Main_Data[\"CATEGORY\"][1001])\nprint(Main_Data[\"JPG\"][1501])\nprint(Main_Data[\"CATEGORY\"][1501])\nprint(Main_Data[\"JPG\"][2033])\nprint(Main_Data[\"CATEGORY\"][2033])","92b4eee4":"Main_Data = Main_Data.sample(frac=1).reset_index(drop=True)","d06d096b":"print(Main_Data.head(-1))","63f16182":"plt.style.use('dark_background')","0694b3c0":"sns.countplot(Main_Data[\"CATEGORY\"])\nplt.show()","87a5d025":"Main_Data['CATEGORY'].value_counts().plot.pie(figsize=(5,5))\nplt.show()","86cb037a":"sns.histplot(Main_Data['CATEGORY'].index)\nplt.show()","e9acd937":"figure = plt.figure(figsize=(10,10))\nx = plt.imread(Main_Data[\"JPG\"][0])\nplt.imshow(x)\nplt.xlabel(x.shape)\nplt.title(Main_Data[\"CATEGORY\"][0])","0f64e44a":"figure = plt.figure(figsize=(10,10))\nx = plt.imread(Main_Data[\"JPG\"][20])\nplt.imshow(x)\nplt.xlabel(x.shape)\nplt.title(Main_Data[\"CATEGORY\"][20])","e778d8e6":"figure = plt.figure(figsize=(10,10))\nx = plt.imread(Main_Data[\"JPG\"][4001])\nplt.imshow(x)\nplt.xlabel(x.shape)\nplt.title(Main_Data[\"CATEGORY\"][4001])","78648888":"fig, axes = plt.subplots(nrows=5,\n                        ncols=5,\n                        figsize=(10,10),\n                        subplot_kw={\"xticks\":[],\"yticks\":[]})\n\nfor i,ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(Main_Data[\"JPG\"][i]))\n    ax.set_title(Main_Data[\"CATEGORY\"][i])\nplt.tight_layout()\nplt.show()","a3ee7e69":"Train_Data,Test_Data = train_test_split(Main_Data,train_size=0.9,random_state=123,shuffle=True)","ef8eea68":"print(\"TRAIN SHAPE: \",Train_Data.shape)\nprint(\"TEST SHAPE: \",Test_Data.shape)","63e5b5c7":"print(Train_Data.head(-1))\nprint(\"----\"*20)\nprint(Test_Data.head(-1))","63f4294d":"Train_Generator = ImageDataGenerator(rescale=1.\/255,\n                                    validation_split=0.1,\n                                    zoom_range=0.2,\n                                    rotation_range=40,\n                                    shear_range=0.2,\n                                     channel_shift_range=0.2,\n                                     fill_mode=\"nearest\",\n                                    horizontal_flip=True)","e17ffeca":"Test_Generator = ImageDataGenerator(rescale=1.\/255)","9ca71329":"example_IMG = Train_Data[\"JPG\"][96]\nLoad_IMG = image.load_img(example_IMG,target_size=(200,200))\nArray_IMG = image.img_to_array(Load_IMG)\nArray_IMG = Array_IMG.reshape((1,) + Array_IMG.shape)\n\ni = 0\nfor batch in Train_Generator.flow(Array_IMG,batch_size=1):\n    plt.figure(i)\n    plot_IMG = plt.imshow(image.array_to_img(batch[0]))\n    i += 1\n    if i % 4 == 0:\n        break\nplt.show()","9b59d8a0":"example_IMG = Test_Data[\"JPG\"][909]\nLoad_IMG = image.load_img(example_IMG,target_size=(200,200))\nArray_IMG = image.img_to_array(Load_IMG)\nArray_IMG = Array_IMG.reshape((1,) + Array_IMG.shape)\n\ni = 0\nfor batch in Test_Generator.flow(Array_IMG,batch_size=1):\n    plt.figure(i)\n    plot_IMG = plt.imshow(image.array_to_img(batch[0]))\n    i += 1\n    if i % 4 == 0:\n        break\nplt.show()","8e4d0fad":"Train_IMG_Set = Train_Generator.flow_from_dataframe(dataframe=Train_Data,\n                                                   x_col=\"JPG\",\n                                                   y_col=\"CATEGORY\",\n                                                   color_mode=\"rgb\",\n                                                   class_mode=\"categorical\",\n                                                    subset=\"training\",\n                                                   batch_size=32,\n                                                   target_size=(200,200))","e0675a6e":"Validation_IMG_Set = Train_Generator.flow_from_dataframe(dataframe=Train_Data,\n                                                   x_col=\"JPG\",\n                                                   y_col=\"CATEGORY\",\n                                                   color_mode=\"rgb\",\n                                                   class_mode=\"categorical\",\n                                                    subset=\"validation\",\n                                                   batch_size=32,\n                                                   target_size=(200,200))","fc3ad649":"Test_IMG_Set = Test_Generator.flow_from_dataframe(dataframe=Test_Data,\n                                                   x_col=\"JPG\",\n                                                   y_col=\"CATEGORY\",\n                                                   color_mode=\"rgb\",\n                                                   class_mode=\"categorical\",\n                                                   batch_size=32,\n                                                   target_size=(200,200))","fbe57c42":"for data_batch,label_batch in Train_IMG_Set:\n    print(\"DATA SHAPE: \",data_batch.shape)\n    print(\"LABEL SHAPE: \",label_batch.shape)\n    break","643ee85a":"for data_batch,label_batch in Validation_IMG_Set:\n    print(\"DATA SHAPE: \",data_batch.shape)\n    print(\"LABEL SHAPE: \",label_batch.shape)\n    break","99622437":"for data_batch,label_batch in Test_IMG_Set:\n    print(\"DATA SHAPE: \",data_batch.shape)\n    print(\"LABEL SHAPE: \",label_batch.shape)\n    break","037a9fcb":"print(\"TRAIN: \")\nprint(Train_IMG_Set.class_indices)\nprint(Train_IMG_Set.classes[0:5])\nprint(Train_IMG_Set.image_shape)\nprint(\"---\"*20)\nprint(\"VALIDATION: \")\nprint(Validation_IMG_Set.class_indices)\nprint(Validation_IMG_Set.classes[0:5])\nprint(Validation_IMG_Set.image_shape)\nprint(\"---\"*20)\nprint(\"TEST: \")\nprint(Test_IMG_Set.class_indices)\nprint(Test_IMG_Set.classes[0:5])\nprint(Test_IMG_Set.image_shape)\nprint(\"---\"*20)","e5d94863":"Model = Sequential()\n\nModel.add(Conv2D(12,(3,3),activation=\"relu\",\n                 input_shape=(200,200,3)))\nModel.add(MaxPooling2D((2,2)))\n\n#\nModel.add(Conv2D(24,(3,3),\n                 activation=\"relu\",padding=\"same\"))\nModel.add(MaxPooling2D((2,2)))\n\n#\nModel.add(Conv2D(64,(3,3),\n                 activation=\"relu\",padding=\"same\"))\nModel.add(MaxPooling2D((2,2)))\n\n#\nModel.add(Conv2D(128,(2,2),\n                 activation=\"relu\",padding=\"same\"))\nModel.add(MaxPooling2D((2,2)))\n\n#\nModel.add(Conv2D(256,(2,2),\n                 activation=\"relu\",padding=\"same\"))\nModel.add(MaxPooling2D((2,2)))\n\n#\nModel.add(Flatten())\nModel.add(Dense(512,activation=\"relu\"))\nModel.add(Dropout(0.5))\nModel.add(Dense(5,activation=\"softmax\"))","30b628f8":"Model.compile(optimizer=RMSprop(lr=0.001),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])","82c34e41":"ANN_Model = Model.fit(Train_IMG_Set,\n                      validation_data=Validation_IMG_Set,\n                      epochs=50)","a075d339":"Model_Results = Model.evaluate(Test_IMG_Set,verbose=False)\nprint(\"LOSS:  \" + \"%.4f\" % Model_Results[0])\nprint(\"ACCURACY:  \" + \"%.2f\" % Model_Results[1])","26d6584c":"print(Model.summary())","346c365a":"plt.plot(ANN_Model.history[\"accuracy\"])\nplt.plot(ANN_Model.history[\"val_accuracy\"])\nplt.ylabel(\"ACCURACY\")\nplt.legend()\nplt.show()","bbce6f0e":"plt.plot(ANN_Model.history[\"loss\"])\nplt.plot(ANN_Model.history[\"val_loss\"])\nplt.ylabel(\"LOSS\")\nplt.legend()\nplt.show()","7213d5ce":"plt.plot(ANN_Model.history[\"loss\"])\nplt.plot(ANN_Model.history[\"accuracy\"])\nplt.ylabel(\"LOSS - ACCURACY\")\nplt.legend()\nplt.show()","2b283b76":"plt.plot(ANN_Model.history[\"val_loss\"])\nplt.plot(ANN_Model.history[\"val_accuracy\"])\nplt.ylabel(\"VAL LOSS - VAL ACCURACY\")\nplt.legend()\nplt.show()","afa1f694":"Dict_Summary = pd.DataFrame(ANN_Model.history)\nDict_Summary.plot()","abd36a24":"Any_IMG = Train_Data[\"JPG\"][6]\nIMG = image.load_img(Any_IMG,target_size=(200,200))\nArray_IMG = image.img_to_array(IMG)\nArray_IMG = np.expand_dims(Array_IMG,axis=0)\nArray_IMG \/= 255\n\nplt.imshow(Array_IMG[0])\nplt.title(\"ANY TARGET IMAGE\")\nplt.show()","3f998f35":"layer_out = [layer.output for layer in Model.layers[:8]]\nactivation_model = models.Model(inputs=Model.input,outputs=layer_out)\nactivations = activation_model.predict(Array_IMG)","f53f5cb3":"first_layer_act = activations[0]\nprint(first_layer_act.shape)","f1e2e64d":"plt.matshow(first_layer_act[0,:,:,4],cmap=\"viridis\")","4a92ab59":"plt.matshow(first_layer_act[0,:,:,7],cmap=\"viridis\")","c9dd5b2c":"plt.matshow(first_layer_act[0,:10,:10,7],cmap=\"viridis\")","87b1cfc3":"plt.matshow(first_layer_act[0,:5,:5,8],cmap=\"viridis\")","a44855d0":"Prediction = Model.predict(Test_IMG_Set)\nPrediction = Prediction.argmax(axis=-1)","943d55e2":"print(Prediction)","10154677":"fig, axes = plt.subplots(nrows=5,\n                         ncols=5,\n                         figsize=(20, 20),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(Test_Data[\"JPG\"].iloc[i]))\n    ax.set_title(f\"PREDICTION:{Prediction[i]}\")\nplt.tight_layout()\nplt.show()","a8c6bd2c":"Model_RCNN = Sequential()\n\nModel_RCNN.add(Conv2D(12,(3,3),activation=\"relu\",\n                 input_shape=(200,200,3)))\nModel_RCNN.add(BatchNormalization())\nModel_RCNN.add(MaxPooling2D((2,2)))\n\n#\nModel_RCNN.add(Conv2D(24,(3,3),\n                 activation=\"relu\",padding=\"same\"))\nModel_RCNN.add(BatchNormalization())\nModel_RCNN.add(MaxPooling2D((2,2)))\n\n#\nModel_RCNN.add(Conv2D(64,(3,3),\n                 activation=\"relu\",padding=\"same\"))\nModel_RCNN.add(BatchNormalization())\nModel_RCNN.add(MaxPooling2D((2,2)))\n\n#\nModel_RCNN.add(Conv2D(128,(2,2),\n                 activation=\"relu\",padding=\"same\"))\nModel_RCNN.add(BatchNormalization())\nModel_RCNN.add(MaxPooling2D((2,2)))\n\n#\nModel_RCNN.add(TimeDistributed(Flatten()))\nModel_RCNN.add(Bidirectional(LSTM(32,\n                                  return_sequences=True,\n                                  dropout=0.5,\n                                  recurrent_dropout=0.5)))\n\n#\nModel_RCNN.add(Flatten())\nModel_RCNN.add(Dense(512,activation=\"relu\"))\nModel_RCNN.add(Dropout(0.5))\nModel_RCNN.add(Dense(5,activation=\"softmax\"))","584c3a9b":"Model_RCNN.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])","7c559934":"RCNN_Model = Model_RCNN.fit(Train_IMG_Set,\n                      validation_data=Validation_IMG_Set,\n                      epochs=50)","f128d821":"Model_Results_RCNN = Model_RCNN.evaluate(Test_IMG_Set,verbose=False)\nprint(\"LOSS:  \" + \"%.4f\" % Model_Results_RCNN[0])\nprint(\"ACCURACY:  \" + \"%.2f\" % Model_Results_RCNN[1])","cc0f9d89":"print(Model_RCNN.summary())","d89b80b0":"plt.plot(RCNN_Model.history[\"accuracy\"])\nplt.plot(RCNN_Model.history[\"val_accuracy\"])\nplt.ylabel(\"ACCURACY\")\nplt.legend()\nplt.show()","4477293f":"plt.plot(RCNN_Model.history[\"loss\"])\nplt.plot(RCNN_Model.history[\"val_loss\"])\nplt.ylabel(\"LOSS\")\nplt.legend()\nplt.show()","06060ee3":"plt.plot(RCNN_Model.history[\"loss\"])\nplt.plot(RCNN_Model.history[\"accuracy\"])\nplt.ylabel(\"LOSS - ACCURACY\")\nplt.legend()\nplt.show()","2df811ef":"plt.plot(RCNN_Model.history[\"val_loss\"])\nplt.plot(RCNN_Model.history[\"val_accuracy\"])\nplt.ylabel(\"VAL LOSS - VAL ACCURACY\")\nplt.legend()\nplt.show()","04c35a5e":"Dict_Summary_CRNN = pd.DataFrame(RCNN_Model.history)\nDict_Summary_CRNN.plot()","97fb67f9":"#### SHUFFLING","ca5f4bc6":"# PREDICTION","817d8170":"#### FITTING","20f2c678":"#### COMPILE","b302ca42":"# CNN \/ Convolutional Neural Network","3f3005e6":"#### CHECKING","c010072c":"#### APPLYING GENERATOR AND TRANSFORMATION TO TENSOR","b4761b53":"#### STRUCTURE","9e53198c":"#### How Generator Applied Image Look Like","d40c0257":"#### LABEL","36b12b47":"# DETERMINATION TRAIN AND TEST DATA","f9c04880":"### Context\n* This dataset contains 4242 images of flowers.\n* The data collection is based on the data flicr, google images, yandex images.\n* You can use this dataset to recognize plants from the photo.\n\n### Content\n* The pictures are divided into five classes: chamomile, tulip, rose, sunflower, dandelion.\n* For each class there are about 800 photos. Photos are not high resolution, about 320x240 pixels. Photos are not reduced to a single size, they have different proportions","ac97b0e4":"#### ANY TARGET IMAGE","f521f189":"#### TRANSFORMATION SERIES ","af08cc15":"#### IGNORING WARNINGS","23c2a2bb":"# HISTORY","2b8ea6b0":"#### TRANSFORMATION DATAFRAME","331c81f3":"# LEARNING IN EACH LAYER","69ba8d80":"#### GENERAL","4679812d":"# PATH & DATA PROCESS","fd60f5c0":"* 'daisy': 0\n* 'dandelion': 1\n* 'rose': 2\n* 'sunflower': 3\n* 'tulip': 4","54ed5b4d":"#### LAYERS VISUALIZE PICTURES","b9f39b17":"#### IMAGE","b762ab86":"# IMAGE GENERATOR","9dd5abe6":"#### PATH","9d1a05ff":"# VISUALIZATION","7b09277f":"# PACKAGES AND LIBRARIES"}}