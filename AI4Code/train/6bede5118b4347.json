{"cell_type":{"dcce4022":"code","aac22f34":"code","889d5994":"code","84ac1a4c":"code","fb5f9f37":"code","cff8cce2":"code","734b3ac3":"code","b961bfbf":"code","61e3a3c5":"code","7f74440b":"code","1e6302bb":"code","9c1fb44b":"code","c9f48374":"code","ff224d44":"code","85a14c6b":"code","eab2c3c6":"code","b029f141":"code","e47d142f":"code","564ebf71":"code","a4509c5e":"code","8cf69a0c":"code","a9e7a772":"code","3f0bf880":"code","8c18d365":"code","0f7745bd":"code","440d53a2":"code","ecf12874":"code","941a833a":"code","9c1bbf31":"code","c1d997e7":"code","cd38d376":"code","4de685db":"code","38f7fa96":"code","dd7d6484":"code","a751f3c9":"code","dbe638f3":"code","1b08d10f":"code","1dd61666":"code","e06a1730":"code","c89cc692":"code","25d6bf59":"code","5899c41b":"code","ff8519f6":"code","7c9f0272":"code","6e68ff1c":"code","0afb40db":"code","dcb10adf":"code","35c771e4":"code","6e7abbf0":"code","88920ce6":"code","1f5e0f31":"code","aa2e7013":"code","7c8a3f56":"code","6a75b12d":"code","000a58f4":"code","97998915":"code","8025b354":"code","8fb0149d":"code","bfa2ef65":"code","182869ed":"code","fc907dc8":"code","1fd3cd67":"code","094de8f2":"code","90d8afec":"code","a5423655":"code","e3a3317a":"code","b4dd1878":"code","5d6cbebe":"code","c7f56f21":"code","096a3ec2":"code","0ace6787":"code","33a4a267":"code","baae13bb":"code","f0f6b679":"code","2e5d2cbb":"code","7101e642":"code","19ea80ab":"code","405ad0e2":"markdown","a3bf9903":"markdown","cf27e4a5":"markdown","1649526f":"markdown","a4e4789c":"markdown","42a73ea9":"markdown","ef558bc5":"markdown","8d95e7f4":"markdown","e96176f0":"markdown","edd88372":"markdown","94201566":"markdown","af8fced8":"markdown","1209c0e6":"markdown","0afc57f3":"markdown","a23542bb":"markdown","a856d632":"markdown","2f8fb6d4":"markdown","b752f109":"markdown","dd5ea512":"markdown","2a08ff2a":"markdown","2d256517":"markdown"},"source":{"dcce4022":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","aac22f34":"#importing the dataset\n\ndf = pd.read_csv('..\/input\/data-scientist-jobs\/DataScientist.csv')\ndf","889d5994":"print(df.isnull().sum()) #checking for null values in the dataset\nprint(df.info()) #checking the general information of the dataset: non-null count, d-type, etc","84ac1a4c":"df['Easy Apply'] = df['Easy Apply'].fillna(False).astype(bool) #As seen in dataset, Easy Apply column has -1 values, replacing them with boolean value False\ndf['Easy Apply'].value_counts() # Checking for value count of Easy Apply column","fb5f9f37":"df.replace(['-1'], [np.nan], inplace=True)\ndf.replace(['-1.0'], [np.nan], inplace=True)\ndf.replace([-1], [np.nan], inplace=True)","cff8cce2":"df.isnull().sum()  #After replacing -1 with nan, we can see that there are null values in the dataset","734b3ac3":"df_salary = df['Salary Estimate'].str.split(\"-\",expand=True,)\n\nminimum_salary = df_salary[0]\nminimum_salary = minimum_salary.str.replace('K',' ')\n\n\nmaximum_salary = df_salary[1].str.replace('(Glassdoor est.)', ' ')\nmaximum_salary = maximum_salary.str.replace('(', ' ')\nmaximum_salary = maximum_salary.str.replace(')', ' ')\nmaximum_salary = maximum_salary.str.replace('K', ' ')\nmaximum_salary = maximum_salary.str.replace('Employer est.', ' ')\nmaximum_salary = maximum_salary.str.replace('Per Hour', ' ')\n\nmaximum_salary = maximum_salary.str.replace('$', ' ').fillna(0).astype(int)\nminimum_salary = minimum_salary.str.replace('$', ' ').fillna(0).astype(int)","b961bfbf":"maximum_salary.value_counts()","61e3a3c5":"df['Minimum Salary'] = minimum_salary\ndf['Maximum Salary'] = maximum_salary\n\ndf.drop('Salary Estimate',axis = 1,inplace = True)","7f74440b":"df['Company Name'] = df['Company Name'].str.replace('\\n.*', ' ')","1e6302bb":"Location = df['Location'].str.split(\",\",expand=True,)\nLocation_City = Location[0]\nLocation_State = Location[1]\ndf['Location City'] = Location_City\ndf['Location State'] = Location_State\ndf.drop('Location',axis = 1, inplace = True)\n\nHQ = df['Headquarters'].str.split(\",\",expand=True)\nHeadquarters_City = HQ[0]\nHeadquarters_State = HQ[1]\ndf['Headquarters City'] = Headquarters_City\ndf['Headquarters State'] = Headquarters_State\ndf.drop('Headquarters',axis = 1, inplace = True)\n","9c1fb44b":"department = df['Job Title'].str.split(',', expand = True)\ndf['Job Title'], df['Department'] = department[0],department[1]","c9f48374":"df.drop('Department',1, inplace = True)","ff224d44":"df['Job Title'].value_counts()\n","85a14c6b":"df['Job Title'] = df['Job Title'].str.replace('Sr.', 'Senior')","eab2c3c6":"df.info()","b029f141":"df['Type of ownership'].value_counts()","e47d142f":"df['Industry'].value_counts()","564ebf71":"df['Sector'].value_counts()","a4509c5e":"df['Revenue'].value_counts()","8cf69a0c":"df['Revenue'] = df['Revenue'].replace('Unknown \/ Non-Applicable', None)\n# data['Revenue']=data['Revenue'].replace('Unknown \/ Non-Applicable', None)","a9e7a772":"df['Revenue'] = df['Revenue'].str.replace('$', ' ')\ndf['Revenue'] = df['Revenue'].str.replace('(USD)', ' ')\ndf['Revenue'] = df['Revenue'].str.replace('(', ' ')\ndf['Revenue'] = df['Revenue'].str.replace(')', ' ')\ndf['Revenue'] = df['Revenue'].str.replace(' ', '')","3f0bf880":"df['Revenue'].value_counts()","8c18d365":"df['Revenue'] = df['Revenue'].str.replace('2to5billion', '2billionto5billion')\ndf['Revenue'] = df['Revenue'].str.replace('5to10billion ', '5billionto10billion ')\n","0f7745bd":"df['Revenue'].value_counts()","440d53a2":"df['Revenue'] = df['Revenue'].replace('million', ' ')\ndf['Revenue'] = df['Revenue'].replace('10+billion', '10billionto11billion')\ndf['Revenue'] = df['Revenue'].str.replace('Lessthan1million', '0millionto1million')","ecf12874":"df['Revenue'].value_counts()","941a833a":"df['Revenue'] = df['Revenue'].str.replace('million', ' ')\ndf['Revenue'] = df['Revenue'].str.replace('billion', '000 ')\ndf['Revenue'] = df['Revenue'].replace('Unknown\/Non-Applicable', np.nan)","9c1bbf31":"df['Revenue'].value_counts()\n","c1d997e7":"Revenue = df['Revenue'].str.split(\"to\",expand=True)","cd38d376":"df['Revenue'].value_counts()","4de685db":"df['Minimum Revenue'] = Revenue[0]\ndf['Maximum Revenue'] = Revenue[1]\n","38f7fa96":"df['Maximum Revenue'] = pd.to_numeric(df['Maximum Revenue'])\ndf['Minimum Revenue'] = pd.to_numeric(df['Minimum Revenue'])","dd7d6484":"df.drop('Revenue',1,inplace=True)","a751f3c9":"df","dbe638f3":"df['Size'].value_counts()","1b08d10f":"df['Size'] = df['Size'].str.replace('employees', '')\n","1dd61666":"df['Size'] = df['Size'].str.replace('+', 'plus')\ndf['Size'] = df['Size'].replace('Unknown', None)\n\n","e06a1730":"df['Size'] = df['Size'].str.replace('10000plus', '10000 to 10001')","c89cc692":"size = df['Size'].str.split(\"to\",expand=True)","25d6bf59":"df['Minimum Size'] = size[0]\ndf['Maximum Size'] = size[1]\ndf","5899c41b":"df.drop('Size',1,inplace = True)","ff8519f6":"# def contains_word(s, w):\n#     return f' {w} ' in f' {s} '\n\n# # def rev(text):\n# #     #if contains_word(text,'billion') is True:\n# #     text.str.replace('billion','')\n         \n# #     return text\n\n# def revenue(text):\n#     if contains_word(text,'billion') is True:\n#         max_rev = float(data_analyst_jobs['Maximum Revenue'].replace(\"billion\", \" \").strip())*1000\n#         #revenue = float(maxRev[0].replace('+','').strip())*100\n#     return max_rev\n\n# data_analyst_jobs['Revenue'] = data_analyst_jobs['Revenue'].apply(lambda text: clean_revenue(text))","7c9f0272":"f, axes = plt.subplots(1, 2, figsize=(15, 7), sharex=True)\nsns.despine(left=True)\nsns.distplot(df['Minimum Salary'],color = 'r',ax = axes[0])\nsns.distplot(df['Maximum Salary'],ax = axes[1])\nplt.legend();","6e68ff1c":"sns.boxplot(x = df['Rating']);","0afb40db":"df['Minimum Size'] = df['Minimum Size'].astype('float')\ndf['Maximum Size'] = df['Maximum Size'].astype('float')\n\n","dcb10adf":"f, axes = plt.subplots(1, 2, figsize=(20, 5), sharex=True)\nsns.boxplot(x = df['Minimum Size'], ax = axes[0],palette='Set1');\nsns.boxplot(x = df['Maximum Size'], ax = axes[1],palette='Set2');","35c771e4":"plt.subplots(figsize=(10,10))\nsplot = sns.barplot(x=df['Job Title'].value_counts()[0:20].index,y=df['Job Title'].value_counts()[0:20], palette = 'winter_r')\nfor p in splot.patches:\n    splot.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() \/ 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 15), textcoords = 'offset points')\n\nplt.xlabel('Job Title',fontsize=15)\nplt.ylabel('Job Count',fontsize=15)\nplt.xticks(rotation=90)\nplt.yticks(fontsize=15)\nplt.title('Top 20 Job Title Counts',fontsize=25);\n\n# for index, row in data_analyst_jobs.iterrows():\n#     splot.text(row.name,row.tip, round('Job Title',2), color='black', ha=\"center\")\n","6e7abbf0":"plt.subplots(figsize=(15,15))\nsplot = sns.barplot(x = df['Company Name'][0:20], y = df['Maximum Revenue'][0:20], data = df, palette = 'spring')\nfor p in splot.patches:\n    splot.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() \/ 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 15), textcoords = 'offset points')\n\n\nplt.xlabel('Company Name',fontsize=15)\nplt.ylabel('Maximum revenue in million dollars',fontsize=15)\nplt.xticks(rotation=90)\nplt.yticks(fontsize=20)\nplt.title('Maximum Revenue of top 20 Companies',fontsize=25);","88920ce6":"df['Average Revenue'] = df[['Minimum Revenue','Maximum Revenue']].mean(axis=1)\n","1f5e0f31":"avg_rev = df['Average Revenue'][0:20]\navg_rev","aa2e7013":"plt.subplots(figsize=(20,15))\nsplot = sns.barplot(x = df['Company Name'][0:20], y = df['Average Revenue'][0:20], data = df, palette = 'summer')\nfor p in splot.patches:\n    splot.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() \/ 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 15), textcoords = 'offset points')\n\nplt.xlabel('Company Name')\nplt.ylabel('Average revenue in million dollars')\nplt.xticks(rotation=90)\nplt.yticks(fontsize=20)\nplt.title('Average Revenue of top 20 Companies',fontsize=25);\n","7c8a3f56":"data = df.groupby('Location City')[['Minimum Salary', 'Maximum Salary']].mean().sort_values(['Maximum Salary','Minimum Salary'],ascending=False).head(25)\ndata","6a75b12d":"import plotly.graph_objs as go\nfig = go.Figure()\nfig.add_trace(go.Bar(\n   x = data.index,\n   y = data['Minimum Salary'],\n   name = 'Minimum Salary'\n))\n\nfig.add_trace(go.Bar(\n   x = data.index,\n   y = data['Maximum Salary'],\n   name = 'Maximum Salary'\n))\n\n#data1 = [plot1,plot2]\nfig.update_layout(title = 'Minimum and Maximum salaries of top 25 cities', barmode = 'group')\n#fig = go.Figure(data = data, layout = layout)\n\nfig.show()","000a58f4":"data1 = df.groupby('Job Title')[['Minimum Salary', 'Maximum Salary']].mean().sort_values(['Maximum Salary','Minimum Salary'],ascending=False).head(25)\ndata1","97998915":"import plotly.graph_objs as go\nfig = go.Figure()\nfig.add_trace(go.Bar(\n   x = data1.index,\n   y = data1['Minimum Salary'],\n   name = 'Minimum Salary'\n))\n\nfig.add_trace(go.Bar(\n   x = data1.index,\n   y = data1['Maximum Salary'],\n   name = 'Maximum Salary'\n))\n\n#data1 = [plot1,plot2]\nfig.update_layout(title = 'Minimum and Maximum salaries of top 25 job titles', barmode = 'stack')\n#fig = go.Figure(data = data, layout = layout)\n\nfig.show()","8025b354":"df['Average Salary'] = df[['Minimum Salary', 'Maximum Salary']].mean(axis = 1)","8fb0149d":"import plotly.express as px\nfig = px.scatter(df, x=df['Rating'], y= df['Average Salary'])\nfig.update_layout(title = 'Relation between average salary and rating of companies')\nfig.show()\n","bfa2ef65":"data2 = df.groupby('Founded')[['Average Revenue']].mean().sort_values(['Average Revenue'],ascending=False).head(25)\ndata2","182869ed":"fig = px.line(x=data2['Average Revenue'], y=data2.index, labels={'x':'Average Revenue', 'y':'Year founded'})\nfig.update_layout(title = 'Relation between the average revenue and year the company was founded')\nfig.show()","fc907dc8":"data3 = df.groupby('Founded')[['Average Revenue']].mean().sort_values(['Average Revenue'],ascending=False).tail(25)\ndata3","1fd3cd67":"fig = px.line(x=data3['Average Revenue'], y=data3.index, labels={'x':'Average Revenue', 'y':'Year founded'})\nfig.update_layout(title = 'Relation between the average revenue and year the company was founded')\nfig.show()","094de8f2":"data4 = pd.DataFrame(df['Sector'].value_counts())\ndata4","90d8afec":"import plotly.express as px\nfig = px.pie(data4, values=data4['Sector'], names=data4.index)\nfig.update_layout(title = 'Percentage of Different Sectors with requirement of Data Scientist  Roles')\nfig.show()\n","a5423655":"data5 = pd.DataFrame(df['Industry'].value_counts().head(25))\ndata5","e3a3317a":"import plotly.express as px\nfig = px.pie(data5, values=data5['Industry'], names=data5.index)\nfig.update_layout(title = 'Percentage of top 25 Industries with requirement of Data Analyst Roles')\nfig.show()\n\n","b4dd1878":"data6 = pd.DataFrame(df['Type of ownership'].value_counts())\ndata6\n\nimport plotly.express as px\nfig = px.pie(data6, values=data6['Type of ownership'], names=data6.index)\nfig.update_layout(title = 'Type of ownership')\nfig.show()\n\n\n","5d6cbebe":"data7 = pd.DataFrame(df['Headquarters City'].value_counts().head(25))\ndata7\n\nimport plotly.express as px\nfig = px.pie(data7, values=data7['Headquarters City'], names=data7.index)\nfig.update_layout(title = 'Top 25 Headquarter City')\nfig.show()\n\n\n\n","c7f56f21":"data8 = pd.DataFrame(df['Location City'].value_counts().head(25))\ndata8\n\nimport plotly.express as px\nfig = px.pie(data8, values=data8['Location City'], names=data8.index)\nfig.update_layout(title = 'Top 25 Job Locations')\nfig.show()\n\n\n\n\n","096a3ec2":"from wordcloud import WordCloud, ImageColorGenerator\nfrom PIL import Image","0ace6787":"plt.subplots(figsize=(15,15))\nwc = WordCloud()\ntext = df['Job Title']\nwc.generate(str(' '.join(text)))\nplt.imshow(wc)\nplt.axis(\"off\")\nplt.show()","33a4a267":"# import nltk\n# from nltk.corpus import stopwords\n# import re\n# from nltk.stem.porter import PorterStemmer\n# print(stopwords.words('english'))\n\n# stop_words = set(stopwords.words('english'))\n# jobdes = data_analyst_jobs['Job Description'].to_csv()\n# jobdes = jobdes.split(' ')\n# jobdes = jobdes.lower()\n# jobdes","baae13bb":"\n# skills = ['python', 'java','c', 'r','c++', 'hadoop', 'communication']\n\n# for word in all_words:\n#     print(word)","f0f6b679":"usa_map = df.groupby('Location City')[['Minimum Salary', 'Maximum Salary']].mean().sort_values(['Maximum Salary','Minimum Salary'],ascending=False)\nusa_map = usa_map.reset_index()\nusa_map.head(20)\n","2e5d2cbb":"cities = usa_map['Location City']\ncities.head(20)\n\n['Daly City','Marin City', 'Los Gatos', 'Berkeley', 'San Jose', 'Cupertino','Santa Clara', 'Pico Rivera', 'Whittier','Far Rockaway', 'Secaucus', 'Sunnyvale', 'Menlo Park', 'Elk Grove Village', 'Glenview', 'Maywood', 'Northfield', 'Stanford', 'San Francisco', 'El Cajon']","7101e642":"usa_maps = df.groupby('Location State')[['Minimum Salary', 'Maximum Salary']].mean().sort_values(['Maximum Salary','Minimum Salary'],ascending=False)\nusa_maps = usa_maps.reset_index()\n\nusa_maps = usa_maps.drop([3, 0])\nusa_maps","19ea80ab":"import plotly.express as px\n\nfig = px.choropleth(locations= ['AZ','NJ','NY','CO','IL','NC','VA','SC','WA','PA','DE','TX','KS','FL','IN','OH','GA','UT'], \n                    locationmode=\"USA-states\", \n                    color=[94.494845, 90.232558, 89.026087, 89.022727, 88.829268,85.233333, 85.125000, 83.000000, 82.759259, 77.824561, 75.909091, 74.116751, 67.000000, 66.666667, 61.000000, 58.800000, 56.000000, 48.454545],\n                    labels={'color':'Maximum Salary', 'locations':'State'},\n                    scope=\"usa\") \n\n\nfig.update_layout(\n    \n    title_text = 'Top 20 States with Maximum Salary',\n    geo_scope='usa'\n)\nfig.show()","405ad0e2":"# **1. Data Cleaning**","a3bf9903":"**Creating separate columns of Salary Estimate as minimum and maximum salary**","cf27e4a5":"Checking values from the columns for cleaning","1649526f":"# 3. Data Visualization# ","a4e4789c":"**Replacing -1 with nan**","42a73ea9":"Checking for outliers in Company Ratings","ef558bc5":"**Cleaning the Size column**","8d95e7f4":"**Making city and state columns for both Location and Headquaters**","e96176f0":"Distribution of minimum and maximum salary of all Data Analyst job titles","edd88372":"Creating 'Average Revenue' column","94201566":"Creating a new DataFrame 'use_maps' consisting of 'Location State', 'Minimum Salary' and 'Maximum Salary' columns for ploting choropleth map for top 20 states with maximum salary.","af8fced8":"**Separating department and from job title column**","1209c0e6":"**Word Cloud of Job Titles**","0afc57f3":"**If you like my notebook, give it an upvote! Suggestions for improvements are welcomed!**","a23542bb":"**Creating two separate columns of Revenue as Minimum and Maximum Revenue**","a856d632":"**Creating separate columns of Size as minimum and maximum size**","2f8fb6d4":"Checking for outliers in company size","b752f109":"Since, department has too many missing values (2023\/2253), it can be dropped.","dd5ea512":"# 2. Statistics","2a08ff2a":"**Cleaning the Revenue column**","2d256517":"I have implemented some newly gained data analysis and visualization skills on 'Data Scientist Jobs'\n\nYou can also check my similar work on:\n1. [Analysis of Data Engineer Jobs](https:\/\/www.kaggle.com\/samruddhim\/analysis-of-data-engineer-jobs)\n2. [Analysis of Data Analyst Jobs](https:\/\/www.kaggle.com\/samruddhim\/analysis-of-data-analyst-jobs)\n\nData Ananlysis on 'Data Scientist Jobs' Data Set.\n\n1. Data Cleaning\n2. Statistics\n3. Data Visulization\n"}}