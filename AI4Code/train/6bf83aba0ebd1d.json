{"cell_type":{"3d05a246":"code","24282114":"code","d012e733":"code","f517ac6a":"code","ea2db239":"code","de7e8c5b":"code","bd9f6718":"code","6615bdfd":"code","3fa569c7":"code","d09381f6":"code","01ff759c":"code","10122218":"code","011b6695":"code","3ed53715":"code","f0008bfd":"code","412fb99e":"code","6d3eebc3":"code","999edfa4":"code","231559a0":"code","3bc1d420":"code","1c0c7404":"code","bf06765d":"code","387e6d60":"code","8df4b4b3":"code","96c2b34e":"code","925ca1f5":"code","cac2bfab":"code","02181582":"code","2addfd28":"code","ab86d987":"code","3c6bf0a7":"code","c96ecb1b":"code","3d2f26c4":"code","6644f3eb":"code","b9798017":"code","98a334af":"code","1086fa50":"code","8d8cd955":"code","65473d0e":"code","d93c7b06":"code","33d3b1a0":"code","8b5a3002":"markdown","7e4d8e5b":"markdown"},"source":{"3d05a246":"!pip install text_preprocessing","24282114":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport nltk\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm_notebook\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import TweetTokenizer\n\nfrom gensim.models.doc2vec import Doc2Vec, TaggedDocument\n\nfrom text_preprocessing import preprocess_text\nfrom text_preprocessing import to_lower, remove_punctuation, remove_number, remove_special_character, remove_stopword,expand_contraction ,normalize_unicode , tokenize_word\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d012e733":"train_data = pd.read_csv('\/kaggle\/input\/twitter-entity-sentiment-analysis\/twitter_training.csv',names=['id','entity','sentiment','text'])\ntest_data = pd.read_csv('\/kaggle\/input\/twitter-entity-sentiment-analysis\/twitter_validation.csv',names=['id','entity','sentiment','text'])","f517ac6a":"train_data.head()","ea2db239":"train_data['sentiment'].value_counts()","de7e8c5b":"test_data.iloc[12,-1]","bd9f6718":"stops = set(stopwords.words('english'))\ndef clean(doc):\n    preprocess_functions = [to_lower,expand_contraction,normalize_unicode,remove_punctuation, remove_number, remove_special_character, remove_stopword]\n    preprocessed_text = preprocess_text(doc, preprocess_functions)\n    preprocessed_text = tokenize_word(preprocessed_text)\n    return preprocessed_text","6615bdfd":"positive_words = []\nnegative_words = []\nneutral_words = []\nirrelevant_words = []\nfor i,tr in tqdm_notebook(train_data.iterrows(),total = len(train_data)):\n    if isinstance(tr['text'],str):        \n        words = clean(tr['text'])\n        if tr['sentiment'] == 'Positive': \n            for word in words:\n                if word not in positive_words:\n                    positive_words.append(word)\n        elif tr['sentiment'] == 'Negative':\n            for word in words:\n                if word not in negative_words:\n                    negative_words.append(word)\n        elif tr['sentiment'] == 'Irrelevant':\n            for word in words:\n                if word not in irrelevant_words:\n                    irrelevant_words.append(word)\n        else:\n            for word in words:\n                if word not in neutral_words:\n                    neutral_words.append(word)","3fa569c7":"test_string = test_data.iloc[25,-1]\ntest_sentiment = test_data.iloc[25,-2]","d09381f6":"test_sentiment","01ff759c":"score = 0\ntest_words = clean(test_string)\nfor word in test_words:\n    if word in positive_words:\n        score += 1\n    if word in negative_words:\n        score =score - 1\n    else:\n        score += 0","10122218":"print(score)","011b6695":"sentiments = []\nfor i,row in tqdm_notebook(test_data.iterrows(),total = len(test_data)):\n    score = 0\n    sentiment = ''\n    test_words = clean(row['text'])\n    for word in test_words:\n        if word in positive_words:\n            score += 1\n        if word in negative_words:\n            score = score - 1\n        else:\n            score += 0\n    if score < -1:\n        sentiment = 'Negative'\n    elif score > 1:\n        sentiment = 'Positive'\n    else:\n        sentiment = 'Neutral'\n    sentiments.append(sentiment)","3ed53715":"from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n\nprint(classification_report(test_data['sentiment'],sentiments))","f0008bfd":"confusion_matrix(test_data['sentiment'],sentiments)","412fb99e":"accuracy_score(test_data['sentiment'],sentiments)","6d3eebc3":"test_data['predictions'] = sentiments","999edfa4":"test_data.head(20)","231559a0":"stops = set(stopwords.words('english'))\ndef clean(doc):\n    preprocess_functions = [to_lower,expand_contraction,normalize_unicode,remove_punctuation, remove_number, remove_special_character, remove_stopword]\n    preprocessed_text = preprocess_text(doc, preprocess_functions)\n    return preprocessed_text","3bc1d420":"train_data.isnull().sum()","1c0c7404":"test_data.isnull().sum()","bf06765d":"train_data.dropna(inplace=True)\ntest_data.dropna(inplace=True)","387e6d60":"X_train = train_data.text\ny_train = train_data.sentiment\nX_test = test_data.text\ny_test = test_data.sentiment","8df4b4b3":"vect = CountVectorizer(preprocessor=clean)\nX_train_dtm = vect.fit_transform(X_train)\nX_test_dtm = vect.transform(X_test)","96c2b34e":"X_train.shape","925ca1f5":"X_train_dtm.shape","cac2bfab":"nb = MultinomialNB()\nnb.fit(X_train_dtm,y_train)\ny_pred_classes = nb.predict(X_test_dtm)","02181582":"print(classification_report(y_test,y_pred_classes))","2addfd28":"train_data.head()","ab86d987":"test_data.head()","3c6bf0a7":"test_string","c96ecb1b":"stops = set(stopwords.words('english'))\ndef clean_old(doc):\n    preprocess_functions = [to_lower,expand_contraction,normalize_unicode,remove_punctuation, remove_number, remove_special_character, remove_stopword]\n    preprocessed_text = preprocess_text(doc, preprocess_functions)\n    preprocessed_text = tokenize_word(preprocessed_text)\n    return preprocessed_text","3d2f26c4":"stops = set(stopwords.words('english'))\ntweeter = TweetTokenizer(strip_handles = True,preserve_case = False)\ndef clean(doc):\n    preprocess_functions = [to_lower,expand_contraction,normalize_unicode,remove_punctuation, remove_number, remove_special_character, remove_stopword]\n    preprocessed_text = preprocess_text(doc, preprocess_functions)\n    preprocessed_text = tweeter.tokenize(preprocessed_text)\n    return preprocessed_text","6644f3eb":"test_string = test_data.iloc[45,-2]\ntest_string","b9798017":"print(test_string)\nprint(clean_old(test_string))\nprint(clean(test_string))","98a334af":"X = train_data['text'].apply(clean)\ny = train_data['sentiment']","1086fa50":"for i,d in enumerate(X[:10]):\n    print(i,d)","8d8cd955":"d2vtrain = [TaggedDocument((d),tags=[str(i)]) for i,d in enumerate(X)]\nmodel = Doc2Vec(vector_size=50,alpha=0.025,min_count=10,dm = 1,epochs=100)\nmodel.build_vocab(d2vtrain)\nmodel.train(d2vtrain,total_examples=model.corpus_count,epochs=model.epochs)\n","65473d0e":"X_test = test_data['text'].apply(clean)","d93c7b06":"train_vectors = [model.infer_vector(tokens,steps=50) for tokens in tqdm_notebook(X,total = len(X) )]\ntest_vectors = [model.infer_vector(tokens,steps=50) for tokens in tqdm_notebook(X_test,total=len(X_test) )]","33d3b1a0":"classifier = LogisticRegression(class_weight='balanced')\nclassifier.fit(train_vectors,y)\n\ny_pred = classifier.predict(test_vectors)\ny_test = test_data.sentiment\nprint(classification_report(y_test,y_pred))","8b5a3002":"# Approach 2","7e4d8e5b":"# Naive Bayes Classifier"}}