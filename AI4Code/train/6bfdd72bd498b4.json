{"cell_type":{"8fac4f6e":"code","6440654d":"code","12f0cb9e":"code","8568d6e4":"code","8409d262":"code","86dd98e5":"code","099868e7":"code","9ba5ded6":"code","20932c55":"code","0a82f89e":"code","d149947d":"code","2011fa67":"code","d094fa6a":"code","908775c0":"code","c26844b2":"code","8af7936a":"code","83adb96c":"code","f0e63b28":"code","f668a758":"code","03b1d0c2":"code","418a8329":"code","6599c203":"code","71d1c039":"code","d9bfb07d":"code","9f717903":"code","07cb56d7":"code","52a116a9":"code","dae6bc15":"code","147d0f80":"code","e709dfdd":"code","71428d83":"code","095e4013":"code","ebeb4479":"code","00e33322":"code","82fdadfc":"code","0c9d7574":"markdown","359acd65":"markdown","3fd6356a":"markdown","de0f35e2":"markdown","7647c868":"markdown","28bbf678":"markdown","28c161de":"markdown","b9721d96":"markdown","6d5952bf":"markdown","cc900b6f":"markdown","73a6ecd0":"markdown","0cc73bd0":"markdown","8df6c0e8":"markdown","f43959ef":"markdown","b72d6451":"markdown","b7997d04":"markdown","734d2d91":"markdown","0863a814":"markdown","04ac0f1a":"markdown","b17b7cfa":"markdown","03b5aef3":"markdown","ab06c5da":"markdown"},"source":{"8fac4f6e":"import numpy as np \nimport pandas as pd \n\nimport os","6440654d":"# Basic library\nimport numpy as np \nimport pandas as pd \n\n# Data preprocessing\nimport cv2# Open cv\nfrom sklearn.model_selection import train_test_split\n\n# Visualization\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')","12f0cb9e":"sample = pd.read_csv(\"\/kaggle\/input\/alaska2-image-steganalysis\/sample_submission.csv\")","8568d6e4":"# path\npath_Test = \"\/kaggle\/input\/alaska2-image-steganalysis\/Test\/\"\npath_juni =  \"\/kaggle\/input\/alaska2-image-steganalysis\/JUNIWARD\/\"\npath_jmi =  \"\/kaggle\/input\/alaska2-image-steganalysis\/JMiPOD\"\npath_cov =  \"\/kaggle\/input\/alaska2-image-steganalysis\/Cover\/\"\npath_uer = \"\/kaggle\/input\/alaska2-image-steganalysis\/UERD\/\"","8409d262":"dir_name = os.listdir(\"\/kaggle\/input\/alaska2-image-steganalysis\/\")\ndir_name","86dd98e5":"# Drop csv from dir_name\ndir_name = ['Test', 'JUNIWARD', 'JMiPOD', 'Cover', 'UERD']\n\n# Create empty dataframe and list\ndf = pd.DataFrame({})\nlists = []\ncate = []\n\n# get the filenames\nfor dir_ in dir_name:\n    # file name\n    list_ = os.listdir(\"\/kaggle\/input\/alaska2-image-steganalysis\/\"+dir_+\"\/\")\n    lists = lists+list_\n    # category name\n    cate_ = np.tile(dir_,len(list_))\n    cate = np.concatenate([cate,cate_])\n    \n# insert dataframe\ndf[\"cate\"] = cate\ndf[\"name\"] = lists","099868e7":"df = df.sample(1000)","9ba5ded6":"# data loading\n# Define data size\nsize = 256\n\n# Create image data list\nimg_data = []\n\n# Data loading\nfor dir_ in dir_name:\n    for name in df[df[\"cate\"]==dir_][\"name\"]:\n        path = \"\/kaggle\/input\/alaska2-image-steganalysis\/\"+dir_+\"\/\"+name+\"\"\n        img = cv2.imread(path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Change to color array, BGR\u21d2RGB\n        image = cv2.resize(img, (size,size), interpolation=cv2.INTER_AREA)\n        img_data.append(image)\n\n# Add to dataframe\ndf[\"img\"] = img_data","20932c55":"df.head()","0a82f89e":"# image check\ncate_name = df[\"cate\"].value_counts().index\n\nfig, ax = plt.subplots(5,4, figsize=(20,30))\nfor i in range(5):\n    for j in range(4):\n        ax[i,j].imshow(df[df[\"cate\"]==cate_name[i]][\"img\"].values[j])\n        ax[i,j].set_title(cate_name[i])\n        ax[i,j].grid()","d149947d":"# 154631\n# sample image and Red,Green,Blue image\nsample_img = df.reset_index()[\"img\"][10]\n\nred = sample_img.copy()\nred[:,:,(1, 2)] = 0 #Cancel green and blue value to 0\ngreen = sample_img.copy()\ngreen[:,:,(0, 2)] = 0\nblue = sample_img.copy()\nblue[:,:,(0, 1)] = 0\n\n\n# imshow\nfig, ax = plt.subplots(1,4, figsize=(20,6))\nax[0].imshow(sample_img)\nax[0].set_title(\"row data\")\nax[1].imshow(red)\nax[1].set_title(\"red\")\nax[2].imshow(green)\nax[2].set_title(\"green\")\nax[3].imshow(blue)\nax[3].set_title(\"blue\")","2011fa67":"# Conversion list\nflags = [i for i in dir(cv2) if i.startswith('COLOR_')]\nprint( flags )","d094fa6a":"# gray, hsv, rgba, hls\ngray = cv2.cvtColor(sample_img, cv2.COLOR_RGB2GRAY)\nhsv = cv2.cvtColor(sample_img, cv2.COLOR_RGB2HSV)\nxyz = cv2.cvtColor(sample_img, cv2.COLOR_RGB2XYZ)\nhls = cv2.cvtColor(sample_img, cv2.COLOR_RGB2HLS)\n\n# imshow\nfig, ax = plt.subplots(1,5, figsize=(20,4))\nax[0].imshow(sample_img)\nax[0].set_title(\"sample_img\")\nax[1].imshow(gray, cmap=plt.get_cmap('gray'), vmin=0, vmax=255) # with gray scale, it need to specify color map.\nax[1].set_title(\"gray\")\nax[2].imshow(hsv)\nax[2].set_title(\"hsv\")\nax[3].imshow(xyz)\nax[3].set_title(\"xyz\")\nax[4].imshow(hls)\nax[4].set_title(\"hls\")","908775c0":"# to visualize hsv image with imshow, need to separate, and gray scale view\nh, s, v = cv2.split(hsv)\n\n# imshow\nfig, ax = plt.subplots(1,4, figsize=(20,6))\nax[0].imshow(hsv)\nax[0].set_title(\"total hsv image\")\nax[1].imshow(h, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[1].set_title(\"Hue\")\nax[2].imshow(s, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[2].set_title(\"Saturation\")\nax[3].imshow(v, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[3].set_title(\"Value\")","c26844b2":"# to visualize hls image with imshow, need to separate, and gray scale view\nh, l, s = cv2.split(hls)\n\n# imshow\nfig, ax = plt.subplots(1,4, figsize=(20,6))\nax[0].imshow(hls)\nax[0].set_title(\"total hls image\")\nax[1].imshow(h, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[1].set_title(\"Hue\")\nax[2].imshow(l, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[2].set_title(\"Lightness\")\nax[3].imshow(s, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[3].set_title(\"Saturation\")","8af7936a":"lower_blue = np.array([20,50,50])\nupper_blue = np.array([130,255,255])\n\nmask = cv2.inRange(hsv, lower_blue, upper_blue)\nres = cv2.bitwise_and(hsv,hsv, mask=mask)\n\nfig, ax = plt.subplots(1,4, figsize=(20,6))\nax[0].imshow(sample_img)\nax[0].set_title(\"sample_img\")\nax[1].imshow(hsv)\nax[1].set_title(\"hsv\")\nax[2].imshow(mask)\nax[2].set_title(\"mask\")\nax[3].imshow(res)\nax[3].set_title(\"res\")","83adb96c":"# Scaling \nscale = cv2.resize(sample_img, (64,64), interpolation=cv2.INTER_AREA)\n# Transformation\nM = np.float32([[1,0,100],[0,1,50]])\ntrans= cv2.warpAffine(sample_img, M, (128,128))\n# Rotation\nM = cv2.getRotationMatrix2D(((128-1)\/2.0,(128-1)\/2.0),90,1)\nrotation = cv2.warpAffine(sample_img, M, (128,128))\n# Affine Transformation 3point \u21d2 3point\npts1 = np.float32([[50,50],[128,50],[50,100]])\npts2 = np.float32([[10,100],[128,50],[70,128]])\nM = cv2.getAffineTransform(pts1,pts2)\nAffine = cv2.warpAffine(sample_img, M, (128,128))\n# Perspective Transformation 4point \u21d2 4point\npts1 = np.float32([[56,65],[128,52],[28,128],[128,128]])\npts2 = np.float32([[0,0],[128,0],[0,100],[100,100]])\nM = cv2.getPerspectiveTransform(pts1,pts2)\nperspec = cv2.warpPerspective(sample_img, M, (128,128))\n\n# imshow\nfig, ax = plt.subplots(1,5, figsize=(20,4))\nax[0].imshow(sample_img)\nax[0].set_title(\"sample_img\")\nax[1].imshow(scale)\nax[1].set_title(\"scale\")\nax[2].imshow(rotation)\nax[2].set_title(\"rotation\")\nax[3].imshow(Affine)\nax[3].set_title(\"Affine\")\nax[4].imshow(perspec)\nax[4].set_title(\"perspec\")","f0e63b28":"# binary\nret,th1 = cv2.threshold(gray, 164, 255, cv2.THRESH_BINARY)\n\n# mean_c\nth2 = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n\n# goussian_c\nth3 = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n\n# imshow\nfig, ax = plt.subplots(1,4, figsize=(20,6))\nax[0].imshow(gray, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[0].set_title(\"gray\")\nax[1].imshow(th1, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[1].set_title(\"binary\")\nax[2].imshow(th2, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[2].set_title(\"mean_c\")\nax[3].imshow(th3, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[3].set_title(\"goussian_c\")","f668a758":"# 2D Convolution ( Image Filtering )\nkernel = np.ones((5,5),np.float32)\/25\ndst = cv2.filter2D(sample_img, -1, kernel)\n\n# Averaging blur\nblur = cv2.blur(sample_img, (5,5))\n\n# Gaussian Blurring\nblur_g = cv2.GaussianBlur(sample_img, (5,5), 0)\n\n# Median Blurring\nmedian = cv2.medianBlur(sample_img, 5)\n\n# Bilateral Filtering\nblur_b = cv2.bilateralFilter(sample_img, 9, 75, 75)\n\n# imshow\nfig, ax = plt.subplots(2,3, figsize=(16,10))\nax[0,0].imshow(sample_img)\nax[0,0].set_title(\"sample_img\")\nax[0,1].imshow(dst)\nax[0,1].set_title(\"2D Convolution\")\nax[0,2].imshow(blur)\nax[0,2].set_title(\"Averaging blur\")\nax[1,0].imshow(blur_g)\nax[1,0].set_title(\"Gaussian Blurring\")\nax[1,1].imshow(median)\nax[1,1].set_title(\"Median Blurring\")\nax[1,2].imshow(blur_b)\nax[1,2].set_title(\"Bilateral Filtering\")","03b1d0c2":"# Erosion\nkernel = np.ones((5,5), np.float32)\nero = cv2.erode(gray, kernel, iterations=1)\n\n# Dilation\ndila = cv2.dilate(gray, kernel, iterations=1)\n\n# Opening\nopening = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)\n\n# Closing\nclosing = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)\n\n# Morphological Gradient\ngrad = cv2.morphologyEx(gray, cv2.MORPH_GRADIENT, kernel)\n\n# Top Hat\ntophat = cv2.morphologyEx(gray, cv2.MORPH_TOPHAT, kernel)\n\n# Black Hat\nblackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)\n\n# imshow\nfig, ax = plt.subplots(2,4, figsize=(20,10))\nax[0,0].imshow(gray, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[0,0].set_title(\"gray\")\nax[0,1].imshow(ero, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[0,1].set_title(\"Erosion\")\nax[0,2].imshow(dila, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[0,2].set_title(\"Dilation\")\nax[0,3].imshow(opening, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[0,3].set_title(\"Opening\")\nax[1,0].imshow(closing, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[1,0].set_title(\"Closing\")\nax[1,1].imshow(grad, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[1,1].set_title(\"Morphological Gradient\")\nax[1,2].imshow(tophat, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[1,2].set_title(\"Top Hatr\")\nax[1,3].imshow(blackhat, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[1,3].set_title(\"Black Hat\")","418a8329":"# Laplacian Derivatives\nlap = cv2.Laplacian(gray, cv2.CV_64F)\n\n# sobelx\nsobelx = cv2.Sobel(gray, cv2.CV_64F,1,0,ksize=5)\n\n# sobely\nsobely = cv2.Sobel(gray, cv2.CV_64F,0,1,ksize=5)\n\n# imshow\nfig, ax = plt.subplots(1,4, figsize=(20,6))\nax[0].imshow(gray, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[0].set_title(\"gray\")\nax[1].imshow(lap, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[1].set_title(\"Laplacian\")\nax[2].imshow(sobelx, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[2].set_title(\"sobelx\")\nax[3].imshow(sobely, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[3].set_title(\"sobely\")","6599c203":"# min_val100, max_val200\nedge1 = cv2.Canny(sample_img, 100, 200)\n\n# min_val50, max_val200\nedge2 = cv2.Canny(sample_img, 50, 200)\n\n# min_val100, max_val300\nedge3 = cv2.Canny(sample_img, 100, 300)\n\n# imshow\nfig, ax = plt.subplots(1,4, figsize=(20,4))\nax[0].imshow(gray, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[0].set_title(\"gray\")\nax[1].imshow(edge1, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[1].set_title(\"min_val100, max_val200\")\nax[2].imshow(edge2, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[2].set_title(\"min_val50, max_val200\")\nax[3].imshow(edge3, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[3].set_title(\"min_val100, max_val300\")","71d1c039":"# calculate histgrams\n# cv.calcHist(images, channels, mask, histSize, ranges[, hist[, accumulate]])\n# channels, if gray [0], if color [0] or [1] or [2]\nhist = cv2.calcHist([sample_img],[0],None, [256],[0,256])","d9bfb07d":"# Visualization\nfig, ax = plt.subplots(1,2,figsize=(15,6))\ncolor=[\"red\", \"green\", \"blue\"]\nax[0].imshow(sample_img)\nax[0].grid()\nfor i in range(3):\n    ax[1].plot(cv2.calcHist([sample_img],[i], None, [256],[0,256]), color=color[i])\nax[1].set_xlim([0,256])","9f717903":"# calculate histgrams for gray image\nhist = cv2.calcHist([gray],[0],None, [256],[0,256])","07cb56d7":"# Visualization\nfig, ax = plt.subplots(1,2,figsize=(15,6))\nax[0].imshow(gray, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[0].grid()\nax[1].hist(cv2.calcHist([gray],[0], None, [256],[0,256]), color=\"gray\", bins=128)\nax[1].set_xlim([0,256])","52a116a9":"# Equalization\nequ = cv2.equalizeHist(gray)\n\n# Visualization\nfig, ax = plt.subplots(1,2,figsize=(15,6))\nax[0].imshow(equ, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[0].grid()\nax[1].hist(cv2.calcHist([equ],[0], None, [256],[0,256]), color=\"gray\", bins=128)\nax[1].set_xlim([0,256])","dae6bc15":"# Equalization\nclahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\ncl1 = clahe.apply(gray)\n\n# Visualization\nfig, ax = plt.subplots(1,2,figsize=(15,6))\nax[0].imshow(cl1, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[0].grid()\nax[1].hist(cv2.calcHist([cl1],[0], None, [256],[0,256]), color=\"gray\", bins=128)\nax[1].set_xlim([0,256])","147d0f80":"# calculate histgram, after change to hsv\nhsv = cv2.cvtColor(sample_img, cv2.COLOR_RGB2HSV)\n\nhist = cv2.calcHist([hsv], [0,1], None, [180,256], [0,180,0,256])","e709dfdd":"# Visualization\nfig, ax = plt.subplots(1,2,figsize=(15,6))\nax[0].imshow(hsv)\nax[0].grid()\nax[1].imshow(hist) # X axis shows S values and Y axis shows Hue\nax[1].grid()","71428d83":"# preparing the image\nimg = np.float32(sample_img)\n\n# define criteria, number of cluster(K) and apply kmeans.\ncriteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1)\nK = 8\nret, label, center = cv2.kmeans(img, K, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n\n# cnvert bak into unit8, and make original image\ncenter = center.astype(\"uint8\")\nres = center[label.flatten()]\nres2 = res.reshape((img.shape))\n\nfig, ax = plt.subplots(1, 4, figsize=(20,6))\nax[0].imshow(sample_img)\nax[0].set_title(\"sample image\")\nax[1].imshow(img)\nax[1].set_title(\"convert float32 image\")\nax[2].imshow(res)\nax[2].set_title(\"center\")\nax[3].imshow(res2)\nax[3].set_title(\"result\")","095e4013":"# calculate dst\ndst = cv2.fastNlMeansDenoisingColored(sample_img, None, 10, 10, 7, 21)\n\n# visalization\nfig, ax = plt.subplots(1,2, figsize=(12,6))\n\nax[0].imshow(sample_img)\nax[0].set_title(\"sample_image\")\nax[1].imshow(dst)\nax[1].set_title(\"image denoising\")","ebeb4479":"# Library\nfrom sklearn.decomposition import PCA","00e33322":"# sample of gray image\nimg = gray.copy()\n\n# Create instance\npca = PCA()\n\n# Fitting, Holds 99% of variance\npca = PCA(0.99).fit(img)\n\n# components\ncomponents = pca.transform(img)\nfilterd = pca.inverse_transform(components)","82fdadfc":"# visalization\nfig, ax = plt.subplots(1,2, figsize=(12,12))\n\nax[0].imshow(gray, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[0].set_title(\"gray\")\nax[1].imshow(filterd, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[1].set_title(\"pca filtered\")","0c9d7574":"### Basis Library","359acd65":"## Sample image","3fd6356a":"# Notebook, Image preprocessing OpenCV library with ALASKA img","de0f35e2":"## CLAHE (Contrast Limited Adaptive Histogram Equalization)","7647c868":"# Image Thresholding\n\nhttps:\/\/docs.opencv.org\/master\/d7\/d4d\/tutorial_py_thresholding.html","28bbf678":"# Reference) Noise filtering by PCA","28c161de":"## Dataloading","b9721d96":"Create a summary of Image preprocessing OpenCV library and its application result susing ALASKA data as the subject.\n\nNotebooks<br>\nClassification method<br>\nhttps:\/\/www.kaggle.com\/urayukitaka\/notebook-classification-method<br>\nRegression method<br>\nhttps:\/\/www.kaggle.com\/urayukitaka\/notebook-regression-method<br>\nDimension reduction method<br>\nhttps:\/\/www.kaggle.com\/urayukitaka\/notebook-dimension-reduction","6d5952bf":"# Changing Colorspaces\nHow to convert images from one color-space to another, like BGR \u2194 Gray, BGR \u2194 HSV, etc.<br>\nIn addition to that, how to create an application to extract a colored object in a video\n\nFor OpneCV's HSV, hue range is [0,179], saturation range is [0,255], and value range is [0,255]. \n\nhttps:\/\/docs.opencv.org\/master\/df\/d9d\/tutorial_py_colorspaces.html","cc900b6f":"# Image Gradients\n\nhttps:\/\/docs.opencv.org\/master\/d5\/d0f\/tutorial_py_gradients.html","73a6ecd0":"## Image check","0cc73bd0":"# Histgrams\n\nhttps:\/\/docs.opencv.org\/master\/de\/db2\/tutorial_py_table_of_contents_histograms.html","8df6c0e8":"# Geometric Transformations of Images\n\n geometric transformations to images, like translation, rotation, affine transformation.\n \n https:\/\/docs.opencv.org\/master\/da\/d6e\/tutorial_py_geometric_transformations.html","f43959ef":"## Histogram Equalization","b72d6451":"## 2D Histogram in OpenCV","b7997d04":"# Image Denoising\n\nhttps:\/\/docs.opencv.org\/master\/d5\/d69\/tutorial_py_non_local_means.html","734d2d91":"Only the components of each color are extracted from the HSV image.","0863a814":"# Morphological Transformations\n\nhttps:\/\/docs.opencv.org\/master\/d9\/d61\/tutorial_py_morphological_ops.html","04ac0f1a":"# Smoothing images\n\nBlur images with various low pass filters\n\nhttps:\/\/docs.opencv.org\/master\/d4\/d13\/tutorial_py_filtering.html","b17b7cfa":"# Color Quantization by K-means clustering\n\nhttps:\/\/docs.opencv.org\/master\/d1\/d5c\/tutorial_py_kmeans_opencv.html","03b5aef3":"The following images were used as the library for confirming the image effect of each live.","ab06c5da":"# Canny edge detections\n\nhttps:\/\/docs.opencv.org\/master\/da\/d22\/tutorial_py_canny.html"}}