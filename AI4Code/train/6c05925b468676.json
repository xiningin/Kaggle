{"cell_type":{"35696c34":"code","811bd869":"code","a7eb1cc1":"code","d8e74bb5":"code","4daf011a":"code","fb90610f":"code","f15f2360":"code","e19c8cb7":"code","f6a65729":"code","6c00e122":"code","7f171070":"code","dfcfdb32":"code","060d47e2":"code","4d59fadb":"code","242d535e":"code","89cb8311":"code","1117b8a8":"code","2ce3e566":"code","41dab018":"code","8f126e44":"code","8d33e030":"code","75f02ac2":"code","efe76804":"markdown","3b947edc":"markdown","639576f4":"markdown","babd2f2c":"markdown","a1ffbd34":"markdown","aad688ac":"markdown","3aec2720":"markdown","9e7d2766":"markdown","eb95e124":"markdown","c00acb85":"markdown","3bba0e42":"markdown","c57fc624":"markdown","b6ca073f":"markdown","3382d115":"markdown","f8e69e67":"markdown","c7a5b5e5":"markdown","bff78ff7":"markdown","fdc7184e":"markdown"},"source":{"35696c34":"!pip install lightautoml -q","811bd869":"# Standard python libraries\nimport os\nimport time\nimport re\n\n# Installed libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n# Imports from LightAutoML package\nfrom lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\nfrom lightautoml.tasks import Task","a7eb1cc1":"DATA_DIR = '..\/input\/sf-dst-car-price-prediction-part2\/'\ntrain_data = pd.read_csv(DATA_DIR + 'train.csv')\ntest_data = pd.read_csv(DATA_DIR + 'test.csv')\nsample_submission = pd.read_csv(DATA_DIR + 'sample_submission.csv')\nsubmission = pd.read_csv(DATA_DIR+'sample_submission.csv')\n\nX_test = test_data.values","d8e74bb5":"train_data.sample(5)","4daf011a":"train_data.columns","fb90610f":"def engineDisplacement(row):\n    row = str(row)\n    engine = re.findall('\\d\\.\\d', row)\n    if engine == []:\n        return None\n    return float(engine[0])\n\ndef owner_age(value):\n    age = 0\n    if type(value) == str:\n        values = value.split(' ')\n        #print(values)\n        if len(values) > 3:\n            if \"\u043b\u0435\u0442\" in values[1]  or \"\u0433\u043e\u0434\" in values[1]:\n                age = age + (int)(values[0])\n            else:\n                age = age + (int)(values[0]) \/ 10\n            if \"\u043c\u0435\u0441\u044f\u0446\u0435\u0432\" in values[4] or \"\u043c\u0435\u0441\u044f\u0446\" in values[4]:\n                age = age + (int)(values[3]) \/ 10\n        else:\n            if \"\u043b\u0435\u0442\" in values[1]  or \"\u0433\u043e\u0434\" in values[1]:\n                age = age + (int)(values[0])\n            if \"\u043c\u0435\u0441\u044f\u0446\u0435\u0432\" in values[1] or \"\u043c\u0435\u0441\u044f\u0446\" in values[1]:\n                age = age + (int)(values[0]) \/ 10\n    else:\n        #print(value)\n        return -1\n    \n    return age\ndef owners_count(value):\n    if type(value) == str:\n        return (int)(value[0])\n    else:\n        return -1\ndef engine_displacement(value):\n    \n    value = value.split(' ')[0]\n    if value== 'undefined':\n        return 0\n    return (float)(value)","f15f2360":"train_data['sample'] = 1 # \u043f\u043e\u043c\u0435\u0447\u0430\u0435\u043c \u0433\u0434\u0435 \u0443 \u043d\u0430\u0441 \u0442\u0440\u0435\u0439\u043d\ntest_data['sample'] = 0 # \u043f\u043e\u043c\u0435\u0447\u0430\u0435\u043c \u0433\u0434\u0435 \u0443 \u043d\u0430\u0441 \u0442\u0435\u0441\u0442\ntest_data['price'] = 0 # \u0432 \u0442\u0435\u0441\u0442\u0435 \u0443 \u043d\u0430\u0441 \u043d\u0435\u0442 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f price, \u043c\u044b \u0435\u0433\u043e \u0434\u043e\u043b\u0436\u043d\u044b \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u0442\u044c, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u043f\u043e\u043a\u0430 \u043f\u0440\u043e\u0441\u0442\u043e \u0437\u0430\u043f\u043e\u043b\u043d\u044f\u0435\u043c \u043d\u0443\u043b\u044f\u043c\u0438\n\ndata = test_data.append(train_data, sort=False).reset_index(drop=True) # \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u044f\u0435\u043c\nprint(train_data.shape, test_data.shape, data.shape)","e19c8cb7":"data.loc[data['engineDisplacement'] == 'undefined LTR', 'engineDisplacement'] = '1.3 LTR'\ndata['engineDisplacement'] = data['engineDisplacement'].str.split().apply(\n    lambda s: s[0]\n)\n\ndata['engineDisplacement'] = data['engineDisplacement'].apply(\n    lambda s: float(s)\n)\n\ndata['engineDisplacement'] = data['engineDisplacement']*1000\n\ndata['enginePower'] = data['enginePower'].apply(lambda x : (int)(x.split(' ')[0]))\ndata['modelDate'] = 2021 - data['modelDate']\ndata.loc[data['model_info'] == '100', 'model_info'] = 'S4'\ndata.loc[data['model_info'] == 'COUPE', 'model_info'] = 'S2'\ndata.loc[data['model_info'] == 'None', 'model_info'] = 'C_KLASSE_AMG'\ndata['productionDate'] = 2021 - data['productionDate']\ndata['\u0412\u043b\u0430\u0434\u0435\u043b\u044c\u0446\u044b'] = data['\u0412\u043b\u0430\u0434\u0435\u043b\u044c\u0446\u044b'].apply(lambda x : owners_count(x))\ndata['\u0412\u043b\u0430\u0434\u0435\u043d\u0438\u0435'] = data['\u0412\u043b\u0430\u0434\u0435\u043d\u0438\u0435'].apply(lambda x : owner_age(x))\npassport_dict = {\n    '\u0414\u0443\u0431\u043b\u0438\u043a\u0430\u0442': 0,\n    '\u041e\u0440\u0438\u0433\u0438\u043d\u0430\u043b': 1,\n}\n\ndata['\u041f\u0422\u0421'] = data['\u041f\u0422\u0421'].map(passport_dict)","f6a65729":"train_data = data.query('sample == 1').drop(['sample'], axis=1)\ntest_data = data.query('sample == 0').drop(['sample'], axis=1)\n\ny = train_data.price.values     # \u043d\u0430\u0448 \u0442\u0430\u0440\u0433\u0435\u0442\nX = train_data.drop(['price'], axis=1).values\nX_sub = test_data.drop(['price'], axis=1)","6c00e122":"%%time\n\ntr_data, valid_data = train_test_split(train_data, test_size=0.2,random_state=42)","7f171070":"def mape_metric(y_true, y_pred):\n    return np.mean(np.abs((y_pred-y_true)\/y_true))\n\ntask = Task('reg', metric=mape_metric,greater_is_better=False,loss='mape')","dfcfdb32":"%%time\n\nroles = {'target': 'price',\n         'drop': ['sell_id', 'description', 'vehicleConfiguration']}","060d47e2":"automl = TabularAutoML(task = task, \n                       timeout = 600, # 600 seconds = 10 minutes\n                       cpu_limit = 4, # Optimal for Kaggle kernels\n                       general_params = {'use_algos': [['linear_l2', \n                                         'lgb', 'lgb_tuned']]})","4d59fadb":"oof_pred = automl.fit_predict(tr_data, roles = roles)","242d535e":"valid_pred = automl.predict(valid_data)","89cb8311":"print('OOF mape: {}'.format(mape_metric(tr_data['price'].values,      oof_pred.data[:, 0])))\nprint('VAL mape: {}'.format(mape_metric(valid_data['price'].values, valid_pred.data[:, 0])))","1117b8a8":"automl = TabularUtilizedAutoML(task = task, \n                       timeout = 600, # 600 seconds = 10 minutes\n                       cpu_limit = 4, # Optimal for Kaggle kernels\n                       general_params = {'use_algos': [['linear_l2', \n                                         'lgb', 'lgb_tuned']]})","2ce3e566":"oof_pred = automl.fit_predict(tr_data, roles = roles)","41dab018":"valid_pred = automl.predict(valid_data)","8f126e44":"print('OOF mape: {}'.format(mape_metric(tr_data['price'].values,      oof_pred.data[:, 0])))\nprint('VAL mape: {}'.format(mape_metric(valid_data['price'].values, valid_pred.data[:, 0])))","8d33e030":"automl = TabularUtilizedAutoML(task = task, \n                       timeout = 10800, # 3 hour,  default 3600 seconds\n                       cpu_limit = 4, # Optimal for Kaggle kernels\n                       general_params = {'use_algos': [['linear_l2', \n                                         'lgb', 'lgb_tuned']]})\noof_pred = automl.fit_predict(train_data, roles = roles)\ntest_pred = automl.predict(test_data)","75f02ac2":"submission['price'] = (test_pred.data[:, 0]).astype(int)\nsubmission.to_csv('automl_utilized_10800_mape_score.csv', index = False)","efe76804":"# Step 7. Retrain selected model on the full dataset and predict for the real test\nNow we know what model to use to receive good results on the dataset, so it\u2019s time to retrain it on the whole dataset","3b947edc":"As a result of fit_predict function, we receive Out-of-Fold (OOF for short) predictions. They are based on the inner CV of LightAutoML and can be used to calculate the model performance metrics on the train data.","639576f4":"## Credits to [source paper](https:\/\/towardsdatascience.com\/lightautoml-preset-usage-tutorial-2cce7da6f936)","babd2f2c":"It\u2019s time to fit and get the better result:","a1ffbd34":"# Step 5. Create LightAutoML model with time utilization\nBelow we are going to create specific AutoML preset for TIMEOUT utilization (try to spend it as much as possible inside TIMEOUT boundary):","aad688ac":"\u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u0442\u0438\u043f\u044b \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432:\n\n* bodyType - \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0439\n* brand - \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0439\n* color - \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0439\n* description - \u0442\u0435\u043a\u0441\u0442\u043e\u0432\u044b\u0439\n* engineDisplacement - \u0447\u0438\u0441\u043b\u043e\u0432\u043e\u0439, \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u043d\u044b\u0439 \u043a\u0430\u043a \u0442\u0435\u043a\u0441\u0442\n* enginePower - \u0447\u0438\u0441\u043b\u043e\u0432\u043e\u0439, \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u043d\u044b\u0439 \u043a\u0430\u043a \u0442\u0435\u043a\u0441\u0442\n* fuelType - \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0439\n* mileage - \u0447\u0438\u0441\u043b\u043e\u0432\u043e\u0439\n* modelDate - \u0447\u0438\u0441\u043b\u043e\u0432\u043e\u0439\n* model_info - \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0439\n* name - \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0439, \u0436\u0435\u043b\u0430\u0442\u0435\u043b\u044c\u043d\u043e \u0441\u043e\u043a\u0440\u0430\u0442\u0438\u0442\u044c \u0440\u0430\u0437\u043c\u0435\u0440\u043d\u043e\u0441\u0442\u044c\n* numberOfDoors - \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0439\n* price - \u0447\u0438\u0441\u043b\u043e\u0432\u043e\u0439, \u0446\u0435\u043b\u0435\u0432\u043e\u0439\n* productionDate - \u0447\u0438\u0441\u043b\u043e\u0432\u043e\u0439\n* sell_id - \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 (\u0444\u0430\u0439\u043b \u0434\u043e\u0441\u0442\u0443\u043f\u0435\u043d \u043f\u043e \u0430\u0434\u0440\u0435\u0441\u0443, \u043e\u0441\u043d\u043e\u0432\u0430\u043d\u043d\u043e\u043c\u0443 \u043d\u0430 sell_id)\n* vehicleConfiguration - \u043d\u0435 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0441\u044f (\u043a\u043e\u043c\u0431\u0438\u043d\u0430\u0446\u0438\u044f \u0434\u0440\u0443\u0433\u0438\u0445 \u0441\u0442\u043e\u043b\u0431\u0446\u043e\u0432)\n* vehicleTransmission - \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0439\n* \u0412\u043b\u0430\u0434\u0435\u043b\u044c\u0446\u044b - \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0439\n* \u0412\u043b\u0430\u0434\u0435\u043d\u0438\u0435 - \u0447\u0438\u0441\u043b\u043e\u0432\u043e\u0439, \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u043d\u044b\u0439 \u043a\u0430\u043a \u0442\u0435\u043a\u0441\u0442\n* \u041f\u0422\u0421 - \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0439\n* \u041f\u0440\u0438\u0432\u043e\u0434 - \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0439\n* \u0420\u0443\u043b\u044c - \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0439","3aec2720":"# Step 0.4. Data splitting for train-validation\nTo validate the models we are going to build, we need to split the dataset into train and validation parts:","9e7d2766":"# Step 2. Setup columns roles\nRoles setup here is to set target column called Price ","eb95e124":"# Step 1. Create Task object\nBelow this line we are ready to build the model for Price target variable prediction. First of all, we setup the type of model we need using LightAutoML Task class object, there the valid values can be:\n* \u2018binary\u2019 for binary classification\n* \u2018reg\u2019 for regression and\n* \u2018multiclass\u2019 for multiclass classification","c00acb85":"Base algorithms, which are currently available to be in general_params use_algos :\n* Linear model (called 'linear_l2')\n* LightGBM model with expert params based on dataset ('lgb')\n* LightGBM with tuned params using Optuna ('lgb_tuned')\n* CatBoost model with expert params ('cb') and\n* CatBoost with params from Optuna ('cb_tuned')\nAs you can see, use_algos are lists in the list \u2014 this is the notation to create ML pipelines with as many levels of algorithms as you want. For example, [['linear_l2', 'lgb', 'cb'], ['lgb_tuned', 'cb']] stands for 3 algorithms on the first level and 2 on the second. After the second level will be fully trained, predictions from the 2 algorithms are weighted averaged to construct the final prediction. The full set of parameters (not only general ones), which can be provided for the TabularAutoML customization, can be found in its YAML config.\n\n\nTo fit our TabularAutoML preset model on the train part of the dataset, we use the code below:","3bba0e42":"# Step 0.3. Additional expert features creation block\nThe cell below shows some user feature preparations, which can be helpful for LightAutoML.","c57fc624":"# Step 4. Predict to validation data and check scores\nNow we have a trained model and we want to receive predictions for the validation data:","b6ca073f":"# Step 3. Create AutoML model from preset","3382d115":"# Step 6. Predict to validation data and check scores for utilized model\n\nPrediction API for TabularUtilizedAutoML is also the same:","f8e69e67":"# Step 0.1. Import necessary libraries\nAt this step we import 3 standard python libraries, several libraries from the usual data scientist set, including numpy, pandas, and sklearn and 2 presets from LightAutoML \u2014 TabularAutoML and TabularUtilizedAutoML.","c7a5b5e5":"# Step 8. Prepare submission ","bff78ff7":"# Install [LightAutoML](https:\/\/lightautoml.readthedocs.io\/en\/latest\/)\nAt the end of 2020 open-source python library LightAutoML was released by the AutoML Team at Sber AI Lab as an Automated Machine Learning (AutoML) framework. It is designed to be lightweight and efficient for various tasks (binary\/multiclass classification and regression) on tabular datasets, which contains different types of features: numeric, categorical, dates, texts etc.","fdc7184e":"# Step 0.2. Datasets load\nNow we need to load the train and test dataset and the submission file"}}