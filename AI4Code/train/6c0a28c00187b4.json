{"cell_type":{"6164a113":"code","cd2dd473":"code","48aae365":"code","7eb3fb61":"code","0091e8fc":"code","4d9fe570":"code","52b21cad":"code","9952eb71":"code","486f2e3a":"code","8f943677":"code","7fe2fea8":"code","5829795e":"code","22d32a57":"code","01c519f0":"code","461455fc":"code","8a75bcb8":"code","d4259cf8":"code","70ebc418":"code","029b9cff":"code","f5858634":"code","e38d4cbe":"code","be915af5":"code","e1404c81":"code","a2476bda":"code","b873cb82":"code","5b0164a1":"code","6542fa5d":"code","72632a63":"code","37fa469a":"code","18ed48fd":"code","a8c963a2":"code","19975c1a":"markdown","c9a24925":"markdown","69c9d7c8":"markdown","5708c155":"markdown","318312e4":"markdown","56b4a970":"markdown","791973a1":"markdown","5909b043":"markdown"},"source":{"6164a113":"!pip install ..\/input\/python-datatable\/datatable-0.11.0-cp37-cp37m-manylinux2010_x86_64.whl","cd2dd473":"import pandas as pd\nimport datatable as dt\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport os\n\nimport riiideducation\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import BatchNormalization,Dropout,Dense,Flatten,Conv1D\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.metrics import BinaryAccuracy\nfrom keras import backend as K","48aae365":"import warnings\nwarnings.filterwarnings(\"ignore\")","7eb3fb61":"os.listdir('..\/input\/riiid-test-answer-prediction')","0091e8fc":"lectures_csv = pd.read_csv(\"..\/input\/riiid-test-answer-prediction\/lectures.csv\")\nexample_test_csv = pd.read_csv(\"..\/input\/riiid-test-answer-prediction\/example_test.csv\")\n#train_csv = pd.read_csv(\"..\/input\/riiid-test-answer-prediction\/train.csv\", low_memory=False)\ntrain_csv = dt.fread(\"..\/input\/riiid-test-answer-prediction\/train.csv\").to_pandas()\nquestions_csv = pd.read_csv(\"..\/input\/riiid-test-answer-prediction\/questions.csv\")\nexample_test_csv = pd.read_csv(\"..\/input\/riiid-test-answer-prediction\/example_test.csv\")","4d9fe570":"# 0 if the event was a question being posed to the user, 1 if the event was the user watching a lecture. So, let's keep just the questions\ntrain_csv = train_csv[train_csv.content_type_id == 0]\n# read -1 as null, for lectures\ntrain_csv = train_csv[train_csv.answered_correctly != -1]","52b21cad":"train_csv = train_csv.sort_values(['timestamp'], ascending=True).reset_index(drop = True)","9952eb71":"train_csv.head(5)","486f2e3a":"content_mean_final = train_csv[['content_id','answered_correctly']].groupby(['content_id']).agg(['mean'])\ncontent_mean_final.columns = [\"answered_correctly_content_mean\"]","8f943677":"user_mean_final = train_csv[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean', 'sum', 'count'])\nuser_mean_final.columns = [\"answered_correctly_user_mean\", 'sum_correct', 'count']","7fe2fea8":"#saving value to fillna\nelapsed_time_mean_final = train_csv.prior_question_elapsed_time.mean()","5829795e":"train_csv.drop(['timestamp', 'content_type_id'], axis=1, inplace=True)","22d32a57":"validation = pd.DataFrame()\nfor i in range(4):\n    last_records = train_csv.drop_duplicates('user_id', keep = 'last')\n    train_csv = train_csv[~train_csv.index.isin(last_records.index)]\n    validation = validation.append(last_records)","01c519f0":"X = pd.DataFrame()\nfor i in range(15):\n    last_records = train_csv.drop_duplicates('user_id', keep = 'last')\n    train_csv = train_csv[~train_csv.index.isin(last_records.index)]\n    X = X.append(last_records)","461455fc":"results_c = train_csv[['content_id','answered_correctly']].groupby(['content_id']).agg(['mean'])\nresults_c.columns = [\"answered_correctly_content_mean\"]\n\nresults_u = train_csv[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean', 'sum', 'count'])\nresults_u.columns = [\"answered_correctly_user_mean\", 'sum_correct', 'count']","8a75bcb8":"result_time_mean = train_csv.prior_question_elapsed_time.mean()","d4259cf8":"#clearing memory\ndel(train_csv)","70ebc418":"X = pd.merge(X, results_u, on=['user_id'], how=\"left\")\nX = pd.merge(X, results_c, on=['content_id'], how=\"left\")","029b9cff":"validation = pd.merge(validation, results_u, on=['user_id'], how=\"left\")\nvalidation = pd.merge(validation, results_c, on=['content_id'], how=\"left\")","f5858634":"y = X['answered_correctly']\nX = X.drop(['answered_correctly'], axis=1)\n\ny_val = validation['answered_correctly']\nX_val = validation.drop(['answered_correctly'], axis=1)","e38d4cbe":"X.columns","be915af5":"lencoder = LabelEncoder()\n\nX['prior_question_had_explanation'].fillna(False, inplace = True)\nX['prior_question_had_explanation_enc'] = lencoder.fit_transform(X['prior_question_had_explanation'])\nX['answered_correctly_user_mean'].fillna(0.5,  inplace=True)\nX['answered_correctly_content_mean'].fillna(0.5,  inplace=True)\nX['sum_correct'].fillna(0, inplace = True)\nX['count'].fillna(0, inplace = True)\nX['prior_question_elapsed_time'].fillna(result_time_mean, inplace = True)\n\nX_val['prior_question_had_explanation'].fillna(False, inplace = True)\nX_val['prior_question_had_explanation_enc'] = lencoder.fit_transform(X_val['prior_question_had_explanation'])\nX_val['answered_correctly_user_mean'].fillna(0.5,  inplace=True)\nX_val['answered_correctly_content_mean'].fillna(0.5,  inplace=True)\nX_val['sum_correct'].fillna(0, inplace = True)\nX_val['count'].fillna(0, inplace = True)\nX_val['prior_question_elapsed_time'].fillna(result_time_mean, inplace = True)","e1404c81":"X = X[['answered_correctly_user_mean', 'answered_correctly_content_mean', 'sum_correct', 'count',\n       'prior_question_elapsed_time','prior_question_had_explanation_enc']]\nX_val = X_val[['answered_correctly_user_mean', 'answered_correctly_content_mean', 'sum_correct', 'count',\n       'prior_question_elapsed_time','prior_question_had_explanation_enc']]","a2476bda":"scaler = StandardScaler()\nX = scaler.fit_transform(X)\nX_val = scaler.transform(X_val)","b873cb82":"K.clear_session()\nX_train = X.reshape(X.shape[0], X.shape[1], 1)\nX_test = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n    \nmodel=Sequential()\nmodel.add(Conv1D(32, 2, activation='relu', input_shape=X_train[0].shape))\nmodel.add(Conv1D(64, 2, activation='relu', padding='causal'))\nmodel.add(Dropout(0.1))\nmodel.add(Flatten())\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=[tf.keras.metrics.BinaryAccuracy()])","5b0164a1":"history = model.fit(X_train, y, epochs=35, verbose=2, batch_size=50000)","6542fa5d":"y_pred = model.predict(X_test)\ny_true = np.array(y_val)","72632a63":"roc_auc_score(y_true, y_pred)","37fa469a":"env = riiideducation.make_env()","18ed48fd":"iter_test = env.iter_test()","a8c963a2":"for (test_df, sample_prediction_df) in iter_test:\n    test_df = pd.merge(test_df, user_mean_final, on=['user_id'],  how=\"left\")\n    test_df = pd.merge(test_df, content_mean_final, on=['content_id'],  how=\"left\")\n    \n    test_df['answered_correctly_user_mean'].fillna(0.5,  inplace=True)\n    test_df['answered_correctly_content_mean'].fillna(0.5,  inplace=True)\n    test_df['sum_correct'].fillna(0, inplace=True)\n    test_df['count'].fillna(0, inplace=True)\n    test_df['prior_question_elapsed_time'].fillna(elapsed_time_mean_final, inplace = True)\n    test_df['prior_question_had_explanation'].fillna(False, inplace=True)\n    test_df[\"prior_question_had_explanation_enc\"] = lencoder.transform(test_df[\"prior_question_had_explanation\"])\n\n    # fit transform cnn\n    X = scaler.transform(test_df[['answered_correctly_user_mean', 'answered_correctly_content_mean', 'sum_correct', 'count',\n                                  'prior_question_elapsed_time', 'prior_question_had_explanation_enc']])\n    test_df['answered_correctly'] = model.predict(X.reshape(X.shape[0], X.shape[1], 1))\n    \n    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])","19975c1a":"## Import necessary libraries","c9a24925":"## Validation\/Train datasets","69c9d7c8":"## Prediction","5708c155":"Here, i did basic EDA https:\/\/www.kaggle.com\/yaroslavmavliutov\/riiid-answer-correctness-prediction-basic-eda","318312e4":"## Pre-Processing","56b4a970":"We have 4 datasets at our disposal","791973a1":"### Check data available","5909b043":"### cnn"}}