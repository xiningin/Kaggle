{"cell_type":{"f99f39b9":"code","d93bd64f":"code","3516ad5e":"code","4949ed79":"code","4009e740":"code","274345d6":"code","bd53d592":"code","b8d3d1db":"code","6b87c4a8":"code","2fdfbf83":"code","70ae4377":"code","75278dba":"code","a84dff83":"markdown","0621afc4":"markdown","cf785aae":"markdown","29744114":"markdown","5af8b84d":"markdown","1173f0cb":"markdown"},"source":{"f99f39b9":"from os.path import exists\n\ngit_repo_url = 'https:\/\/github.com\/fizyr\/keras-retinanet'\nretina_net_dir = 'keras-retinanet'\n\nif not exists(retina_net_dir):\n    # clone \"depth 1\" will only get the latest copy of the relevant files.\n    !git clone -q --recurse-submodules --depth 1 $git_repo_url\n    # build\n    !cd {retina_net_dir} && pip install .\n","d93bd64f":"import os, keras\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom os import listdir\nfrom keras_retinanet import models\nfrom keras_retinanet.utils.keras_version import check_keras_version\nfrom keras_retinanet.utils.tf_version import check_tf_version\nfrom keras_retinanet.utils.gpu import setup_gpu\nfrom keras_retinanet.preprocessing.generator import Generator\nfrom keras_retinanet.utils.image import read_image_bgr\nfrom keras_retinanet.utils.anchors import make_shapes_callback","3516ad5e":"class Args:\n    model = '..\/input\/lacmus-keras-retinanet-snapshot-v1\/resnet50_liza_alert_v1_interface.h5'\n    save_path = 'output'\n    config = None\n    gpu = None\n    backbone = 'resnet50'\n    data_dir = '..\/input\/lacmus-foundation'\n    threshold = 0.5\n    classes = {'Pedestrian': 0}\n    \nargs = Args()","4949ed79":"class MyGenerator(Generator):\n    def __init__(self, data_dir, preprocess_image, **kwargs):\n        \"\"\" Initialize a COCO data generator.\n\n        Args\n            data_dir: Path to where the COCO dataset is stored.\n        \"\"\"\n        self.data_dir  = data_dir\n        self.image_ids = os.listdir(data_dir)\n        self.classes = args.classes        \n        self.image_min_side=800\n        self.image_max_side=1333\n        self.no_resize=False\n        self.preprocess_image=preprocess_image\n        \n        super(Generator, self).__init__(**kwargs)\n    \n    def size(self):\n        return len(self.image_ids)\n    \n    def load_image(self, img_id):\n        path = os.path.join(self.data_dir, self.image_ids[img_id])\n        return read_image_bgr(path)","4009e740":"# make sure keras and tensorflow are the minimum required version\ncheck_keras_version()\ncheck_tf_version()\n\n# optionally choose specific GPU\nif args.gpu:\n    setup_gpu(args.gpu)\n\n# setup backbone\nbackbone = models.backbone(args.backbone)\ngenerator = MyGenerator(args.data_dir, backbone.preprocess_image)\n\n# setup model\nmodel = models.load_model(args.model, backbone_name=args.backbone)\ngenerator.compute_shapes = make_shapes_callback(model)","274345d6":"results = []\nimage_ids = []\nfor index in tqdm(range(generator.size())):\n    image = generator.load_image(index)\n    image = generator.preprocess_image(image)\n    image, scale = generator.resize_image(image)\n\n    if keras.backend.image_data_format() == 'channels_first':\n        image = image.transpose((2, 0, 1))\n\n    # run network\n    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n\n    # correct boxes for image scale\n    boxes \/= scale\n\n    # change to (x, y, w, h) (MS COCO standard)\n    boxes[:, :, 2] -= boxes[:, :, 0]\n    boxes[:, :, 3] -= boxes[:, :, 1]\n\n    # compute predicted labels and scores\n    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n        # scores are sorted, so we can break\n        if score < args.threshold:\n            break\n\n        # append detection for each positively labeled class\n        image_result = {\n            'ImageId'     : generator.image_ids[index],\n            'bbox'        : box.tolist(),\n        }\n\n        # append detection to results\n        results.append(image_result)\n\n    # append image to list of processed images\n    image_ids.append(generator.image_ids[index])","bd53d592":"# ahtung! dirty hack with x_max!\ndef bbox_to_rle(bbox):\n    x_max = 4000\n    rle = ''\n    rounded_bbox = [round(elem) for elem in bbox]\n    x, y, w, h = rounded_bbox\n    for i in range(y, y + h):\n        rle += str(i * x_max + x) + ' ' + str(w) + ' '\n    return rle","b8d3d1db":"df = pd.DataFrame(results)\ndf['EncodedPixels'] = df.bbox.apply(bbox_to_rle)\ndf1 = df.drop(['bbox'], axis=1)","6b87c4a8":"def get_mask(img_id, df, shape = (4000, 3000)):\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    px = df.loc[img_id]['EncodedPixels']\n    if(type(px) == float): return None\n    elif(type(px) == str): px = [px]\n    count = 1\n    for mask in px:\n        if(type(mask) == float):\n            if len(px) == 1: return None\n            else: continue\n        s = mask.split()\n        for i in range(len(s)\/\/2):\n            start = int(s[2*i]) - 1\n            length = int(s[2*i+1])\n            #keep previous prediction for overlapping pixels\n            img[start:start+length] = count*(img[start:start+length] == 0)\n        count+=1\n    return img.reshape(shape).T\n\ndef decode_mask(mask, shape=(4000, 3000)):\n    pixels = mask.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    if(len(runs) == 0): return np.nan\n    runs[runs > shape[0]*shape[1]] = shape[0]*shape[1]\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef set_masks(mask):\n    n = mask.max()\n    result = []\n    for i in range(1,n+1):\n        result.append(decode_mask(mask == i))\n    return result","2fdfbf83":"pred_df = df1.set_index('ImageId')\npred_df.head()","70ae4377":"names = list(set(pred_df.index))\nbox_list_dict = []\nfor name in tqdm(names):\n    mask = get_mask(name, pred_df)\n    if (not isinstance(mask, np.ndarray) and mask == None) \\\n      or mask.sum() == 0:# or name in test_names_nothing:\n        ship_list_dict.append({'ImageId':name,'EncodedPixels':np.nan})\n    else:\n        encodings = set_masks(mask)\n        if(len(encodings) == 0):\n            ship_list_dict.append({'ImageId':name,'EncodedPixels':np.nan})\n            continue\n        \n        buf =[]\n        for e in encodings:\n            if e == e: buf.append(e)\n        encodings = buf\n        if len(encodings) == 0 : encodings = [np.nan]\n        for encoding in encodings:\n            box_list_dict.append({'ImageId':name,'EncodedPixels':encoding})","75278dba":"OUTPUT='submission.csv'\npred_df_cor = pd.DataFrame(box_list_dict)\npred_df_cor.to_csv(OUTPUT, index=False)","a84dff83":"## Inference","0621afc4":"## Initial settings and imports","cf785aae":"## Remove overlap","29744114":"## Dump submission to disk","5af8b84d":"## Convert bboxes to rle","1173f0cb":"## Setup hyperparameters"}}