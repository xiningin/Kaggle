{"cell_type":{"8e65e8a6":"code","772fc082":"code","cac8e248":"code","a86bb177":"code","0a5429aa":"code","5a9f6dab":"code","b0879a54":"code","1ae49814":"code","100663bb":"code","312dad66":"code","9b4b7236":"code","d4b58dae":"code","73645e1b":"code","2dfbbb17":"code","306b6cd3":"code","5ab745ad":"code","69ac59f1":"code","b0ca5903":"code","ce1dd25f":"code","8e1c9fde":"code","9990028d":"code","598c1bb5":"code","fcc075a6":"code","877b3163":"code","885a1463":"code","4f48ed4a":"code","784c51cc":"code","2077b90a":"code","f5c5b54b":"code","554e2fa4":"code","a92790d8":"code","9ab311c1":"code","b3963aba":"code","64231411":"code","010f6278":"code","18b11880":"code","db9763af":"code","5ff6b82a":"code","c362242b":"code","34b5b47c":"code","af54ce5a":"markdown","b95bdf5f":"markdown","24f4d360":"markdown","841e2a21":"markdown","c37e8c20":"markdown","c66ee9a7":"markdown"},"source":{"8e65e8a6":"import numpy as np\nimport pandas as pd \nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn import metrics","772fc082":"train_data = pd.read_csv(\"..\/input\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/test.csv\")\nunchanged_data = test_data","cac8e248":"train_data.head()","a86bb177":"sns.countplot(x = \"Sex\", hue =\"Survived\",data = train_data, palette = \"Blues\")","0a5429aa":"sns.countplot(x = \"Pclass\", hue =\"Survived\",data = train_data, palette = \"Blues\");","5a9f6dab":"sns.countplot(x = \"Pclass\", hue =\"Sex\",data = train_data, palette = \"Blues\")","b0879a54":"sns.countplot(x = \"Parch\", hue =\"Survived\",data = train_data, palette = \"Blues\")","1ae49814":"sns.countplot(x = \"Embarked\", hue=\"Survived\", data = train_data)","100663bb":"train_data.describe()","312dad66":"train_data.isnull().sum()","9b4b7236":"Pclass_1_avg_age = train_data[train_data['Pclass']==1]['Age'].median()\nPclass_2_avg_age = train_data[train_data['Pclass']==2]['Age'].median()\nPclass_3_avg_age = train_data[train_data['Pclass']==3]['Age'].median()\n\ndef fill_age(age):\n    if str(age[5]).lower()=='nan':\n        if age[2]==1:\n            return Pclass_1_avg_age\n        elif age[2]==2:\n            return Pclass_2_avg_age\n        else:\n            return Pclass_3_avg_age\n    else:\n        return age[5]\n\ntrain_data['Age']=train_data.apply(fill_age,axis=1)","d4b58dae":"train_data['Embarked'].fillna(train_data['Embarked'].value_counts().index[0], inplace=True)","73645e1b":"train_data.isnull().sum()","2dfbbb17":"train_data[\"Sex\"].value_counts()","306b6cd3":"train_data[\"Family_Size\"] = train_data[\"SibSp\"] + train_data[\"Parch\"]\ny = train_data[\"Survived\"]","5ab745ad":"p = {1:'1st',2:'2nd',3:'3rd'} \ntrain_data['Pclass'] = train_data['Pclass'].map(p)","69ac59f1":"titles = set()\nfor name in train_data[\"Name\"]:\n    titles.add(name.split(\",\")[1].split(\".\")[0].strip())\ntitles","b0ca5903":"dict_of_title = {\n    \"Dr\": \"Officer\",\n    \"Rev\": \"Officer\",\n    \"Capt\": \"Officer\",\n    \"Col\": \"Officer\",\n    \"Major\": \"Officer\",\n    \"Mme\": \"Mrs\",\n    \"Mlle\": \"Miss\",\n    \"Ms\": \"Mrs\",\n    \"Mr\" : \"Mr\",\n    \"Mrs\" : \"Mrs\",\n    \"Miss\" : \"Miss\",\n    \"Master\" : \"Master\",\n    \"Jonkheer\": \"Royal\",\n    \"Lady\" : \"Royal\",\n    \"Don\": \"Royal\",\n    \"Sir\" : \"Royal\",\n    \"the Countess\":\"Royal\"\n}\n\ndef make_titles(data):\n    data[\"Title\"] = data[\"Name\"].map(lambda s:s.split(\",\")[1].split(\".\")[0].strip())\n    data[\"Title\"] = data[\"Title\"].map(dict_of_title)\n    return data\n\ntrain_data = make_titles(train_data)\n\n","ce1dd25f":"train_data","8e1c9fde":"features = [\"Pclass\",\"Age\",\"Sex\",\"Fare\",\"Title\"]\ntrain_data = train_data[features]\ncategorical_df = train_data[['Pclass',\"Sex\",\"Title\"]]\none_hot_encode = pd.get_dummies(categorical_df,drop_first=True) \ntrain_data = train_data.drop(['Pclass',\"Sex\",\"Title\"],axis=1)\ntrain_data = pd.concat([train_data,one_hot_encode],axis=1)","9990028d":"#X = train_data\n#train_X, test_X, train_y, test_y = train_test_split(X,y,random_state = 0)","598c1bb5":"# clf = RandomForestClassifier(random_state = 0)\n# clf.fit(train_X,train_y)","fcc075a6":"#pred = clf.predict(test_X)","877b3163":"#metrics.accuracy_score(test_y, pred)","885a1463":"#confusion_matrix(test_y,pred)","4f48ed4a":"test_data.head()","784c51cc":"test_data.isnull().sum()","2077b90a":"Pclass_1_avg_age_test = test_data[test_data['Pclass']==1]['Age'].median()\nPclass_2_avg_age_test = test_data[test_data['Pclass']==2]['Age'].median()\nPclass_3_avg_age_test = test_data[test_data['Pclass']==3]['Age'].median()\n\ndef fill_age_kaggle(age):\n    if str(age[4]).lower()=='nan':\n        if age[1]==1:\n            return Pclass_1_avg_age_test\n        elif age[1]==2:\n            return Pclass_2_avg_age_test\n        else:\n            return Pclass_3_avg_age_test\n    else:\n        return age[4]\n","f5c5b54b":"#test_data['Age'].fillna(test_data['Age'].median(),inplace=True)\ntest_data['Age']=test_data.apply(fill_age_kaggle,axis=1)\ntest_data['Fare'].fillna(test_data['Fare'].median(),inplace=True)\ntest_data[\"Family_Size\"] = test_data[\"SibSp\"] + test_data[\"Parch\"]\np = {1:'1st',2:'2nd',3:'3rd'} \ntest_data['Pclass'] = test_data['Pclass'].map(p)\ntest_data = make_titles(test_data)\ntest_data = test_data[features]\ncategorical_df = test_data[['Pclass',\"Sex\",\"Title\"]]\none_hot_encode = pd.get_dummies(categorical_df,drop_first=True) \ntest_data = test_data.drop(['Pclass',\"Sex\",\"Title\"],axis=1)\ntest_data = pd.concat([test_data,one_hot_encode],axis=1)","554e2fa4":"X = train_data\n#test_data = make_titles(test_data)\nroyal = np.zeros(418,dtype=int)\ntest_data[\"Title_Royal\"] = royal\ntest_data","a92790d8":"train_data","9ab311c1":"classifier = RandomForestClassifier(n_estimators=300, random_state=0)  \ngrid_param = {  \n    'n_estimators': [100, 300, 500, 800, 1000],\n    'criterion': ['gini', 'entropy'],\n    'bootstrap': [True, False]\n}","b3963aba":"gd_sr = GridSearchCV(estimator=classifier,  \n                     param_grid=grid_param,\n                     scoring='accuracy',\n                     cv=5,\n                     n_jobs=-1)","64231411":"#gd_sr.fit(X, y) ","010f6278":"#best_parameters = gd_sr.best_params_  \n#print(best_parameters) ","18b11880":"parameters = {\n    \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n    \"min_samples_split\": np.linspace(0.1, 0.5, 12),\n    \"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n    \"max_depth\":[3,5,8],\n    }\n#clf = GridSearchCV(GradientBoostingClassifier(), parameters, cv=5, n_jobs=-1)\n#clf.fit(X,y)\n#print(clf.best_params_)","db9763af":"kaggle_clf = GradientBoostingClassifier(learning_rate= 0.1, max_depth= 5, min_samples_leaf=0.1, min_samples_split = 0.1).fit(X,y)\nkaggle_pred = kaggle_clf.predict(test_data)","5ff6b82a":"kaggle_pred","c362242b":"my_submission = pd.DataFrame({'PassengerId': unchanged_data.PassengerId, 'Survived': kaggle_pred})","34b5b47c":"my_submission.to_csv('submission.csv', index=False)","af54ce5a":"# Random Forest","b95bdf5f":"# Gradient Boosting","24f4d360":"# Training Model","841e2a21":"# Exploratory Data Analysis","c37e8c20":"# Kaggle Submission","c66ee9a7":"## Some feature engineering"}}