{"cell_type":{"67eb173f":"code","1aebd2e4":"code","70e9f6d6":"code","cb438b8e":"code","aa39cbcb":"code","85e8ee0f":"code","81ca5a3e":"code","8c2a3249":"code","dbac2ec0":"code","8e8bf53c":"code","23c0e9a9":"code","cf9b368a":"code","4e551718":"code","5b85717d":"code","f0039fed":"code","6acb71bd":"code","876bcdb5":"code","42f2cef9":"code","1a50404d":"markdown","402312a0":"markdown","aa883f76":"markdown","8cd2f44c":"markdown","5bc1fef9":"markdown","5947a41e":"markdown","656512e9":"markdown","e47c2fa4":"markdown"},"source":{"67eb173f":"#Importing libraries\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os, random, shutil\nimport tensorflow as tf\nimport seaborn\nfrom tensorflow import keras\nfrom tensorflow.keras import preprocessing, layers\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras_preprocessing import image\n\n","1aebd2e4":"#Set the base paths\nbase_path = r'..\/input\/galaxy-zoo-the-galaxy-challenge\/'\ntraining_solutions = os.path.join(base_path, 'training_solutions_rev1.zip')\ntraining_images    = os.path.join(base_path, 'images_training_rev1.zip')","70e9f6d6":"\ndf = pd.read_csv(training_solutions, compression=\"zip\")\ncols = df.columns\nnew = list(map(lambda s: s.replace('Class','Q'), cols))\ndf.columns = new\ndf.head()","cb438b8e":"ellipticals = df[(df['Q1.1']>0.7) & (df['Q7.1']>0.4)]['GalaxyID'].tolist()\n\nlenticulars = df[(df['Q1.1']>0.7) & (df['Q7.2']>0.4)]['GalaxyID'].tolist()\n\nspirals = df[(df['Q1.2']>0.7) & (df['Q2.1']>0.4)]['GalaxyID'].tolist()\n\nprint('Total number of elliptical examples: ',  len(ellipticals))\nprint('Total number of lenticular examples: ',  len(lenticulars))\nprint('Total number of spiral examples: ',  len(spirals))\n\n","aa39cbcb":"def _proc_images(src, dst, label, arr, percent):\n    train_dir = os.path.join(dst, 'train')\n    val_dir = os.path.join(dst, 'validation')\n    \n    train_dest = os.path.join(train_dir, label)\n    val_dest   = os.path.join(val_dir, label)\n    \n    if not os.path.exists(train_dest):\n        os.makedirs(train_dest)\n\n    if not os.path.exists(val_dest):\n        os.makedirs(val_dest)\n    \n    random.shuffle(arr)\n    \n    idx = int(len(arr)*percent)\n    for i in arr[0:idx]:\n        shutil.copyfile(os.path.join(src, str(i)+'.jpg'), os.path.join(train_dest, str(i)+'.jpg'))\n    for i in arr[idx:]:\n        shutil.copyfile(os.path.join(src, str(i)+'.jpg'), os.path.join(val_dest, str(i)+'.jpg'))\n    \n    print(label, 'done!')\n    \n    \n","85e8ee0f":"_proc_images(training_images, '..\/input\/galaxy-zoo-clean\/data\/', 'elliptical', ellipticals, 0.80)\n_proc_images(training_images,'..\/input\/galaxy-zoo-clean\/data\/', 'lenticular', lenticulars, 0.80)\n_proc_images(training_images, '..\/input\/galaxy-zoo-clean\/data\/', 'spiral', spirals, 0.80)\n\n\nprint('Elliptical:', len(os.listdir(os.path.join(my_data, 'train', 'elliptical'))))\nprint('Total train lenticular:', len(os.listdir(os.path.join(my_data, 'train', 'lenticular'))))\nprint('Total train spiral:', len(os.listdir(os.path.join(my_data, 'train', 'spiral'))))\n\n\nprint('Total validation elliptical:', len(os.listdir(os.path.join(my_data, 'validation', 'elliptical'))))\nprint('Total validation lenticular:', len(os.listdir(os.path.join(my_data, 'validation', 'lenticular'))))\nprint('Total validation spiral:', len(os.listdir(os.path.join(my_data, 'validation', 'spiral'))))\n","81ca5a3e":"# elliptical class\nfor num, file in enumerate(os.listdir('..\/input\/galaxy-zoo-clean\/data\/train\/elliptical')[0:3]):\n    img = image.load_img(os.path.join(my_data, 'train', 'elliptical', file) , target_size=(150, 150))\n    plt.subplot(1, 3, num+1)\n    plt.axis('off')\n    plt.imshow(img)","8c2a3249":"# lenticular class\nfor num, file in enumerate(os.listdir('..\/input\/galaxy-zoo-clean\/data\/train\/lenticular')[0:3]):\n    img = image.load_img(os.path.join(my_data, 'train', 'lenticular', file) , target_size=(150, 150))\n    plt.subplot(1, 3, num+1)\n    plt.axis('off')\n    plt.imshow(img)","dbac2ec0":"# spiral class\nfor num, file in enumerate(os.listdir('..\/input\/galaxy-zoo-clean\/data\/train\/spiral')[0:3]):\n    img = image.load_img(os.path.join(my_data, 'train', 'spiral', file) , target_size=(150, 150))\n    plt.subplot(1, 3, num+1)\n    plt.axis('off')\n    plt.imshow(img)","8e8bf53c":"train_dir = '..\/input\/galaxy-zoo-clean\/data\/train'\nvalidation_dir = '..\/input\/galaxy-zoo-clean\/data\/validation'\n\n\n","23c0e9a9":"total_train = 0\nfor c in ['elliptical', 'lenticular', 'spiral']:\n  total_train += len(os.listdir(os.path.join(train_dir, c)))\nprint('Total train:', total_train)\n\ntotal_validation = 0\nfor c in ['elliptical', 'lenticular', 'spiral']:\n  total_validation += len(os.listdir(os.path.join(validation_dir, c)))\nprint('Total validation:', total_validation)","cf9b368a":"BS=32","4e551718":"\ntrain_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n                    rescale=1.0\/255,\n                    rotation_range=25,\n                    width_shift_range=.15,\n                    height_shift_range=.15,\n                    horizontal_flip=True,\n                    zoom_range=0.2)\nvalidation_datagen  = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0\/255.)\n\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                    target_size=(180,180),\n                                                    batch_size=BS,\n                                                    shuffle=True,\n                                                    class_mode='categorical')\nvalidation_generator = train_datagen.flow_from_directory(validation_dir,\n                                                         target_size=(180,180),\n                                                         batch_size=BS,\n                                                         shuffle=True,\n                                                         class_mode='categorical')","5b85717d":"#Net architecture\n\nmodel = tf.keras.models.Sequential([\n    # first convolution layer, input is an 150x150 image x3 colors\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(180, 180, 3)),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu',input_shape=(180, 180, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    # second convolution layer\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # third convolution layer\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # fourth convolution layer\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # flatten the image pixels\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.5),\n    # 512 neuron fully connected hidden layer\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(3, activation='softmax')\n])","f0039fed":"model.summary()","6acb71bd":"from tensorflow.keras import losses\nLOSS= tf.keras.losses.CategoricalCrossentropy(from_logits=False, label_smoothing=0, reduction=\"auto\", name=\"categorical_crossentropy\")\nmodel.compile(loss=LOSS,\n              optimizer='adam',\n              metrics=['accuracy'])\nearly_stop = EarlyStopping(monitor = 'val_accuracy', mode = 'max', patience=10, restore_best_weights=False)","876bcdb5":"EPOCHS = 100\n\nhistory = model.fit(train_generator,\n                    epochs=EPOCHS,\n                    steps_per_epoch=train_generator.samples\/\/train_generator.batch_size,\n                    validation_data=validation_generator,\n                    validation_steps=len(validation_generator)\/\/BS,\n                    verbose=1)","42f2cef9":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(len(acc))  # range for the number of epochs\n\nplt.figure(figsize=(16, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.savefig('.\/plots-v2.png')\nplt.show()","1a50404d":"# Galaxies Morphology Classification Using CNN\n\nUsing the Galaxy-Zoo dataset available on kaggle: https:\/\/www.kaggle.com\/c\/galaxy-zoo-the-galaxy-challenge\/data,\nwe will exploit a Convolutional Neural Network to train a model for galaxy morphology classification.\n","402312a0":"file:\/\/\/home\/ale\/Scrivania\/hubble_search_project\/download.png![image.png](attachment:image.png)","aa883f76":"Data Augmentation. \n\nGiven that from from ellipticals to cigars the galaxies shapes got a decreasing number of symmetry axis, we will preprocess the images with random flips and random rotations. ","8cd2f44c":"Defining a function that will randomly select the training and validation images for each class and create subfolders:\n","5bc1fef9":"## Introduction and data interpretation.\n\n\nThe dataset has been crowdsource-labeld and the data we are working on are labeled following that decision tree:\n\n![Schermata%20del%202020-09-08%2019-37-36.png](attachment:Schermata%20del%202020-09-08%2019-37-36.png)\n\n\n\n\n","5947a41e":"We will define 3 classes corresponding to galaxy morphologies sub-setting the decision tree:\n\n\nElliptical: Q1.1 > 0.8 and Q7.1 > 0.6 \n\n\nLenticular: Q1.1 > 0.8 and Q7.2 > 0.6  \n\nSpiral : Q1.1 > 0.8 and Q7.3  > 0.6  \n\n\nCigar-shaped: Q1.1 > 0.8 and Q7.3 > 0.6 and Q8.3 < 0.2 (A Cigar shape is not so far away from a disk with no bulge.)\n\n\n","656512e9":"Create the class-substet of the database and visualizing the lenghts:","e47c2fa4":"Create the dataset and updating the columns names to match our notation."}}