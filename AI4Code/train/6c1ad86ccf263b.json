{"cell_type":{"fc377c34":"code","bb0b1f2d":"code","3c6f2e18":"code","997e4d3d":"code","22d874cf":"code","84599e61":"code","48a6216f":"code","8b0ad8ac":"code","f8ed1455":"code","78ccdb8f":"code","74ba7ada":"code","23d1dd50":"code","a0bf0210":"code","8c392c2f":"code","8c5f1708":"code","0502c417":"code","e996eee5":"code","c2ec832b":"code","5ce1f7e6":"code","b7e4c123":"code","f112b497":"code","37a50781":"code","28b7a668":"code","a6385235":"markdown","0115fb0c":"markdown"},"source":{"fc377c34":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom torchvision.utils import make_grid\nfrom torchvision import datasets,models,transforms\nfrom PIL import Image\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bb0b1f2d":"use_gpu = torch.cuda.is_available()\nuse_gpu","3c6f2e18":"root = \"..\/input\/chest-xray-pneumonia\/chest_xray\/\"","997e4d3d":"img_names = []\nfor folder,subfolders,filenames in os.walk(root):\n    for img in filenames:\n        img_names.append(folder+'\/'+img)\nprint('images length:', len(img_names))","22d874cf":"img_sizes =[]\nrejected = []\nfor item in img_names:\n    try:\n        with Image.open(item) as img:\n            img_sizes.append(img.size)\n    except:\n        rejected.append(item)\nprint(f'images:{len(img_sizes)}')\nprint(f'rejected:{len(rejected)}')","84599e61":"df = pd.DataFrame(img_sizes)\ndf.describe()","48a6216f":"img1 = Image.open(\"..\/input\/chest-xray-pneumonia\/chest_xray\/test\/NORMAL\/IM-0007-0001.jpeg\")\ndisplay(img1)\nimg1.size","8b0ad8ac":"train_transform = transforms.Compose([\n    transforms.Resize(224),\n    transforms.CenterCrop(224),\n    transforms.ToTensor()\n])\ntest_transform = transforms.Compose([\n    transforms.Resize(224),\n    transforms.CenterCrop(224),\n    transforms.ToTensor()\n])","f8ed1455":"train_data = datasets.ImageFolder(os.path.join(root,'train'),transform  = train_transform)\ntest_data = datasets.ImageFolder(os.path.join(root,'test')  , transform = test_transform)\n\ntrain_loader = DataLoader(train_data,batch_size=10,shuffle = True,num_workers =4)\ntest_loader = DataLoader(test_data,batch_size =10,shuffle = False,num_workers =4)\n\nclass_names = train_data.classes\nprint(len(train_data))\nprint(len(test_data))\nprint(class_names)","78ccdb8f":"im","74ba7ada":"for images,labels in train_loader:\n    break\nprint('labels:',*labels.numpy())\nprint('images:',*np.array([class_names[i] for i in labels]))\nim= make_grid(images,nrow = 10)\nplt.figure(figsize =(10,8))\nplt.imshow(np.transpose(im.numpy(),(1,2,0)))\n\nprint(\"images.shape:\",images.shape)\nprint(\"labels.shape:\",labels.shape)\nprint(\"len(labels)\",len(labels))","23d1dd50":"class ConvolutionalNNetworks(nn.Module):\n    def __init__(self):\n        super(ConvolutionalNNetworks,self).__init__()\n        self.cnn_layers= nn.Sequential(\n            nn.Conv2d(3,32,kernel_size=3,stride= 1,padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace = True),\n            nn.Conv2d(32,32,kernel_size =3,stride = 1,padding = 1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace = True),\n            nn.MaxPool2d(kernel_size =2,stride = 2))\n        \n        self.linear_layers = nn.Sequential(\n            nn.Dropout(p = 0.5),\n            nn.Linear(32*112*112,128),\n            nn.BatchNorm1d(128),\n            nn.ReLU(inplace = True),\n            nn.Dropout(p = 0.5),\n            nn.Linear(128,2))\n    def forward(self,X):\n        X = self.cnn_layers(X)\n        X = X.view(-1,32*112*112)\n        X = self.linear_layers(X)\n        return F.log_softmax(X,dim=1)","a0bf0210":"CNN_model = ConvolutionalNNetworks()\n\noptimizer = torch.optim.Adam(CNN_model.parameters(),lr = 0.01)\ncriterion = nn.CrossEntropyLoss()\nif torch.cuda.is_available():\n    CNN_model = CNN_model.cuda()\n    criterion = criterion.cuda()\nprint(CNN_model)","8c392c2f":"########################\n## Training the model ##\n########################\ndef train(epoch):\n    CNN_model.train()\n    trn_loss =0\n    trn_corr =0\n    total = 0\n    for batch,(data,target) in enumerate(train_loader):\n        data,target = Variable(data),Variable(target)\n        if torch.cuda.is_available():\n            data = data.cuda()\n            target = target.cuda()\n        \n        y_pred = CNN_model(data)\n        \n        predicted = torch.max(y_pred.data,1)[1]\n        trn_corr +=(predicted == target).sum()\n        total += len(data)\n        \n        loss = criterion(y_pred,target)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if (batch+1)%100 ==0:\n            print(f'train epoch: {epoch} loss: {loss.item()} accuracy:{trn_corr.item()\/(len(data)*(batch+1))}')\n    train_losses.append(loss)\n    train_correct.append(trn_corr)\n    \n        \n        \n        \n        \n        ","8c5f1708":"########################\n## Testing the model ##\n########################\ndef test(test_loader):\n    CNN_model.eval()\n    tst_loss =0\n    tst_corr =0\n    \n    with torch.no_grad():\n        for data,target in test_loader:\n            if torch.cuda.is_available():\n                data = data.cuda()\n                target = target.cuda()\n            \n            y_eval = CNN_model(data)\n            predicted = torch.max(y_eval.data,1)[1]\n            tst_corr+=(predicted == target).sum()\n        \n        loss = criterion(y_eval,target)\n        test_losses.append(loss)\n        test_correct.append(tst_corr)\n    \n    \n    ","0502c417":"n_epochs = 1\ntrain_losses= []\ntest_losses = []\ntrain_correct= []\ntest_correct = []\nfor epoch in range(n_epochs):\n    train(epoch)\n    test(test_loader)","e996eee5":"pwd","c2ec832b":"# Saving trained model as .pt\ntorch.save(CNN_model.state_dict(),'\/kaggle\/working\/My_CNN_model.pt')","5ce1f7e6":"# Loading the trained model\nmodel_CNN = ConvolutionalNNetworks()\nmodel_CNN.load_state_dict(torch.load('\/kaggle\/working\/My_CNN_model.pt'))\nmodel_CNN.eval()","b7e4c123":"def plot_graph(epochs):\n    fig = plt.figure(figsize=(20,4))\n    ax = fig.add_subplot(1,2,1)\n    plt.title(\"Train - Validation Loss\")\n    plt.plot(list(np.arange(epochs) + 1) , train_losses, label='train')\n    plt.plot(list(np.arange(epochs) + 1), test_losses, label='validation')\n    plt.xlabel('num_epochs', fontsize=12)\n    plt.ylabel('loss', fontsize=12)\n    plt.legend(loc='best')\n    \n    ax = fig.add_subplot(1, 2, 2)\n    plt.title(\"Train - Validation Accuracy\")\n    plt.plot(list(np.arange(epochs) + 1) , train_correct, label='train')\n    plt.plot(list(np.arange(epochs) + 1), test_correct, label='validation')\n    plt.xlabel('num_epochs', fontsize=12)\n    plt.ylabel('accuracy', fontsize=12)\n    plt.legend(loc='best')","f112b497":"plot_graph(n_epochs)","37a50781":"with torch.no_grad():\n    out = CNN_model(train_data[2990][0].view(1,3,224,224).cuda()).argmax()\nprint('predicted:{}'.format(out.item()))\nprint('label:',train_data[2990][1])","28b7a668":"with torch.no_grad():\n    out = CNN_model(train_data[2990][0].view(1,3,224,224)).argmax()\nprint('predicted:{}'.format(out.item()))\nprint('label:',train_data[2990][1])","a6385235":"##  Testing the model","0115fb0c":"**"}}