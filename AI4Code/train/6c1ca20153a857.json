{"cell_type":{"8016c61a":"code","bd4dde05":"code","a916ed78":"code","9001e57c":"code","4522743e":"code","04ebbd45":"code","86fa3c60":"code","02904636":"code","667a0493":"code","43284e08":"code","8239b4f0":"code","a79813e2":"markdown","daf0d447":"markdown","85532ad2":"markdown","5598ee62":"markdown","3fb90e3c":"markdown","6b62fc45":"markdown","3d4ebf8e":"markdown","4442c413":"markdown","46f8a06a":"markdown","3a3580d7":"markdown"},"source":{"8016c61a":"import numpy as np\nimport pandas as pd\nfrom sklearn.datasets import make_classification \nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nimport plotly.plotly as py\nimport plotly.graph_objs as go\nimport plotly.io as pio\nfrom plotly.offline import init_notebook_mode, iplot\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.simplefilter('ignore')\ninit_notebook_mode()\nsns.set()\n%matplotlib inline","bd4dde05":"train, target = make_classification(1000, 2, n_redundant=0, flip_y=0.0, n_informative=2, n_clusters_per_class=1, random_state=47, class_sep=3)\ncols = ['Bohemian-rhapsody', 'Dont-stop-me-now']\ntrain = pd.DataFrame(train, columns=cols)\ntrain['target'] = target","a916ed78":"plt.figure(figsize=(14, 8))\nsns.scatterplot(train[train['target'] == 0]['Bohemian-rhapsody'], train[train['target'] == 0]['Dont-stop-me-now']);\nsns.scatterplot(train[train['target'] == 1]['Bohemian-rhapsody'], train[train['target'] == 1]['Dont-stop-me-now']);","9001e57c":"train, target = make_classification(500, 3, n_redundant=0, flip_y=0.0, n_informative=3, n_clusters_per_class=1, random_state=47, class_sep=3)\ncols = ['Bohemian-rhapsody', 'Dont-stop-me-now', 'Killer-Queen']\ntrain = pd.DataFrame(train, columns=cols)\ntrain['target'] = target\n\ntrace1 = go.Scatter3d(\n    x=train[train['target'] == 0]['Bohemian-rhapsody'],\n    y=train[train['target'] == 0]['Dont-stop-me-now'],\n    z=train[train['target'] == 0]['Killer-Queen'],\n    mode='markers',\n    marker=dict(\n        size=8,\n        line=dict(\n            color='rgba(217, 217, 217, 0.14)',\n            width=0.5\n        ),\n        opacity=1\n    )\n)\ntrace2 = go.Scatter3d(\n    x=train[train['target'] == 1]['Bohemian-rhapsody'],\n    y=train[train['target'] == 1]['Dont-stop-me-now'],\n    z=train[train['target'] == 1]['Killer-Queen'],\n    mode='markers',\n    marker=dict(\n        size=8,\n        line=dict(\n            color='rgba(100, 100, 100, 0.14)',\n            width=0.5\n        ),\n        opacity=1\n    )\n)\nlayout = go.Layout(\n    margin=dict(l=0, r=0, b=0, t=0),\n    scene = dict(\n        xaxis = dict(\n            title='Bohemian-Rhapsody'),\n        yaxis = dict(\n            title='Dont-stop-me-now'),\n        zaxis = dict(\n            title='Killer-Queen')\n    )\n)\nfig = go.Figure(data=[trace1, trace2], layout=layout);\niplot(fig, filename='simple-3d-scatter', image_width=1024, image_height=768);","4522743e":"X_train, X_test, y_train, y_test = train_test_split(train[cols], train['target'], test_size=0.2, random_state=47)\nclf = QuadraticDiscriminantAnalysis(reg_param=0.6)\nclf.fit(X_train, y_train)\nprint('ROC AUC:', roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]))","04ebbd45":"train, target = make_classification(1000, 2, n_redundant=0, flip_y=0.1, n_informative=2, n_clusters_per_class=1, random_state=47, class_sep=3)\ncols = ['Bohemian-rhapsody', 'Dont-stop-me-now']\ntrain = pd.DataFrame(train, columns=cols)\ntrain['target'] = target","86fa3c60":"plt.figure(figsize=(14, 8))\nsns.scatterplot(train[train['target'] == 0]['Bohemian-rhapsody'], train[train['target'] == 0]['Dont-stop-me-now']);\nsns.scatterplot(train[train['target'] == 1]['Bohemian-rhapsody'], train[train['target'] == 1]['Dont-stop-me-now']);","02904636":"train, target = make_classification(500, 3, n_redundant=0, flip_y=0.1, n_informative=3, n_clusters_per_class=1, random_state=47, class_sep=3)\ncols = ['Bohemian-rhapsody', 'Dont-stop-me-now', 'Killer-Queen']\ntrain = pd.DataFrame(train, columns=cols)\ntrain['target'] = target\n\ntrace1 = go.Scatter3d(\n    x=train[train['target'] == 0]['Bohemian-rhapsody'],\n    y=train[train['target'] == 0]['Dont-stop-me-now'],\n    z=train[train['target'] == 0]['Killer-Queen'],\n    mode='markers',\n    marker=dict(\n        size=8,\n        line=dict(\n            color='rgba(217, 217, 217, 0.14)',\n            width=0.5\n        ),\n        opacity=1\n    )\n)\ntrace2 = go.Scatter3d(\n    x=train[train['target'] == 1]['Bohemian-rhapsody'],\n    y=train[train['target'] == 1]['Dont-stop-me-now'],\n    z=train[train['target'] == 1]['Killer-Queen'],\n    mode='markers',\n    marker=dict(\n        size=8,\n        line=dict(\n            color='rgba(100, 100, 100, 0.14)',\n            width=0.5\n        ),\n        opacity=1\n    )\n)\nlayout = go.Layout(\n    margin=dict(l=0, r=0, b=0, t=0),\n    scene = dict(\n        xaxis = dict(\n            title='Bohemian-Rhapsody'),\n        yaxis = dict(\n            title='Dont-stop-me-now'),\n        zaxis = dict(\n            title='Killer-Queen')\n    )\n)\nfig = go.Figure(data=[trace1, trace2], layout=layout);\niplot(fig, filename='simple-3d-scatter', image_width=1024, image_height=768);","667a0493":"X_train, X_test, y_train, y_test = train_test_split(train[cols], train['target'], test_size=0.2, random_state=47)\nclf = QuadraticDiscriminantAnalysis(reg_param=0.6)\nclf.fit(X_train, y_train)\nprint('ROC AUC:', roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]))","43284e08":"train, target = make_classification(1000, 3, n_redundant=0, flip_y=0.08, n_informative=2, n_clusters_per_class=2, random_state=47, class_sep=1)\ncols = ['Bohemian-rhapsody', 'Dont-stop-me-now', 'Killer-Queen']\ntrain = pd.DataFrame(train, columns=cols)\ntrain['target'] = target\n\ntrace1 = go.Scatter3d(\n    x=train[train['target'] == 0]['Bohemian-rhapsody'],\n    y=train[train['target'] == 0]['Dont-stop-me-now'],\n    z=train[train['target'] == 0]['Killer-Queen'],\n    mode='markers',\n    marker=dict(\n        size=8,\n        line=dict(\n            color='rgba(217, 217, 217, 0.14)',\n            width=0.5\n        ),\n        opacity=1\n    )\n)\ntrace2 = go.Scatter3d(\n    x=train[train['target'] == 1]['Bohemian-rhapsody'],\n    y=train[train['target'] == 1]['Dont-stop-me-now'],\n    z=train[train['target'] == 1]['Killer-Queen'],\n    mode='markers',\n    marker=dict(\n        size=8,\n        line=dict(\n            color='rgba(100, 100, 100, 0.14)',\n            width=0.5\n        ),\n        opacity=1\n    )\n)\nlayout = go.Layout(\n    margin=dict(l=0, r=0, b=0, t=0),\n    scene = dict(\n        xaxis = dict(\n            title='Bohemian-Rhapsody'),\n        yaxis = dict(\n            title='Dont-stop-me-now'),\n        zaxis = dict(\n            title='Killer-Queen')\n    )\n)\nfig = go.Figure(data=[trace1, trace2], layout=layout);\niplot(fig, filename='simple-3d-scatter', image_width=1024, image_height=768);","8239b4f0":"fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(18, 8))\nsns.kdeplot(train[train['target'] == 0]['Bohemian-rhapsody'], ax=axes[0]);\nsns.kdeplot(train[train['target'] == 1]['Bohemian-rhapsody'], ax=axes[0]);\nsns.kdeplot(train[train['target'] == 0]['Dont-stop-me-now'], ax=axes[1]);\nsns.kdeplot(train[train['target'] == 1]['Dont-stop-me-now'], ax=axes[1]);\nsns.kdeplot(train[train['target'] == 0]['Killer-Queen'], ax=axes[2]);\nsns.kdeplot(train[train['target'] == 1]['Killer-Queen'], ax=axes[2]);","a79813e2":"## 2 Dimensions","daf0d447":"Now we can see that there are two clusters of points with some of them 'flipped' and any model would have a missclassifications.","85532ad2":"# Preamble\n\nAfter [mhviraf's](https:\/\/www.kaggle.com\/mhviraf) good guess of [how data for this competition was generated](https:\/\/www.kaggle.com\/mhviraf\/synthetic-data-for-next-instant-gratification) I have played with [sklearn.datasets.make_classification](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.datasets.make_classification.html) for a while.\n\nAnd the main reason why it is impossible (well, almost impossible) to reach AUC of 1.0 is it's parameter **flip_y**.\nHere is it's description:\n\n> flip_y : float, optional (default=0.01)\n>\n> The fraction of samples whose class are randomly exchanged. \n>\n> Larger values introduce noise in the labels and make the classification task harder.\n\nThe default values is 0.01, which means that 1% of data would be randomly flipped from 0 to 1 or vice versa.\n\nIt means that if sample was originaly generated to be in the cluster of 0's it's target would be changed to 1 and any model would missclassify it.","5598ee62":"It is easy to separate this two clusters and almost any model would gain an AUC of 1.0.","3fb90e3c":"# Introducing flip_y\nNow it's time to flip some of the the labels. \n\nParameter **flip_y** is going to be set to 0.1, so ~10% of the data would be misslabeled.","6b62fc45":"## 3 Dimensions","3d4ebf8e":"## 3 Dimensions","4442c413":"And at the end - something that mimic a dataset provided in this competition.","46f8a06a":"At first let's generate a 'perfect' dataset with 1000 samples and only 2 features so we can easily display it. Both of this features will be informative (n_informative=2). \n\nYou can find out what is the difference between informative features and noise in [this kernel](https:\/\/www.kaggle.com\/cdeotte\/support-vector-machine-0-925).\n\nAlso for the sake of visibility parameter **class_sep** will be set to 3, so two clusters would be far away from each other.","3a3580d7":"## 2 Dimensions"}}