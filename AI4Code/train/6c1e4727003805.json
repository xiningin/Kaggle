{"cell_type":{"fa2cb6c2":"code","8c82b470":"code","ef1fc53a":"code","c9322577":"code","6913ed7c":"code","f847ac85":"code","e5620979":"code","62f02ef4":"code","899e915b":"code","fdb0df3c":"code","6ad1884f":"code","31aa70e4":"code","8eac15b3":"code","6f531ce5":"code","e6ff28e2":"code","3a6b7a32":"code","6fb90a4e":"code","29b8eae8":"code","c48dbe61":"code","26f955f6":"code","adace7c7":"code","23cf328a":"code","583de0f4":"code","b68196aa":"code","0c0a0488":"code","3e341dbb":"markdown","b3cc2df5":"markdown","5ba7934e":"markdown","bf34f500":"markdown","f1e044ea":"markdown","47147460":"markdown","d655f4d4":"markdown","3524ebbb":"markdown","3d3e1816":"markdown"},"source":{"fa2cb6c2":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","8c82b470":"df = pd.read_csv('\/kaggle\/input\/janatahack-independence-day-2020-ml-hackathon\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/janatahack-independence-day-2020-ml-hackathon\/test.csv')\nsample_submission = pd.read_csv('\/kaggle\/input\/janatahack-independence-day-2020-ml-hackathon\/sample_submission_UVKGLZE.csv')\ndf","ef1fc53a":"sample_submission","c9322577":"columns = df.columns\ncolumns","6913ed7c":"df['No. of topics'] = (df['Computer Science'] + df['Physics'] + df['Mathematics'] + \n                       df['Statistics'] + df['Quantitative Biology'] + df['Quantitative Finance'])\n\ndf.head(3)","f847ac85":"df['No. of topics'].value_counts()","e5620979":"from collections import Counter\nresults = Counter()\ndf['ABSTRACT'].str.lower().str.split().apply(results.update)","62f02ef4":"one_timers = []\n\nfor k,v in results.items():\n    if v == 1:\n        one_timers.append(k)","899e915b":"from wordcloud import WordCloud, STOPWORDS\nnew_stopwords = ['based', 'paper', 'we', 'the', 'model', 'using', 'show', 'that' 'used', \n                 'use', '!', '$', '%', '&', ',', '.', 'we', 'method', 'problem', 'models']\nSTOPWORDS.update(new_stopwords)\nSTOPWORDS.update(one_timers)","fdb0df3c":"def remove_stopwords(text):\n    from nltk.tokenize import word_tokenize\n\n    text_tokens = word_tokenize(text)\n\n    tokens_without_sw = [word for word in text_tokens if not word in STOPWORDS]\n    \n    filtered_sentence = (\" \").join(tokens_without_sw)\n\n    return filtered_sentence","6ad1884f":"def data_clean(df):\n    df['text'] = df['TITLE'] + df['ABSTRACT']\n    df['text'] = df['text'].apply(remove_stopwords)\n    \n    return df","31aa70e4":"cleaned_data = data_clean(df)","8eac15b3":"from collections import Counter\nresults = Counter()\ncleaned_data['text'].str.lower().str.split().apply(results.update)\ncounter_df = pd.DataFrame.from_dict(results, orient='index')\ncounter_df['Total'] = counter_df[0]\ncounter_df","6f531ce5":"labels = ['Computer Science', 'Physics', 'Mathematics','Statistics', \n          'Quantitative Biology', 'Quantitative Finance']\n\n\n\nfor label in labels:\n    from collections import Counter\n    results = Counter()\n    cleaned_data[cleaned_data[label]==1]['text'].str.lower().str.split().apply(results.update)\n    temp_counter_df = pd.DataFrame.from_dict(results, orient='index')\n    temp_counter_df[label] = temp_counter_df[0]\n    counter_df = counter_df.merge(how='outer', left_index=True, right_index=True, right=temp_counter_df[label])\n\n    \ncounter_df.sort_values(by='Total', axis=0, ascending=False).head(15)","e6ff28e2":"counter_df","3a6b7a32":"import matplotlib.pyplot as plt\nword_string=\" \".join(cleaned_data['text'].str.lower())\nwordcloud = WordCloud(stopwords=STOPWORDS).generate(word_string)\n\nplt.subplots(figsize=(15,15))\nplt.clf()\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","6fb90a4e":"labels = ['Computer Science', 'Physics', 'Mathematics','Statistics', \n          'Quantitative Biology', 'Quantitative Finance']\n\nfor label in labels:\n    print(label)\n    word_string=\" \".join(cleaned_data[cleaned_data[label]==1]['text'].str.lower())\n    wordcloud = WordCloud(stopwords=STOPWORDS).generate(word_string)\n\n    \n\n    plt.subplots(figsize=(15,15))\n    plt.title(label)\n    plt.clf()\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()\n\n","29b8eae8":"df.head(3)","c48dbe61":"X = df[['ID','TITLE', 'ABSTRACT']]\ny = df[['Computer Science', 'Physics', 'Mathematics','Statistics', \n          'Quantitative Biology', 'Quantitative Finance']] \n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.33)\n\nsubmission = pd.DataFrame(X_test['ID'])\n\nX_train = data_clean(X_train)['text']\nX_test = data_clean(X_test)['text']\n\n","26f955f6":"from sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import LinearSVC\nfrom sklearn import metrics\n\nlabels = ['Computer Science', 'Physics', 'Mathematics','Statistics', \n          'Quantitative Biology', 'Quantitative Finance']\n\n\nfor label in labels:\n    \n    print(y_test[label].value_counts())\n    \n    text_clf = Pipeline([('tfidf', TfidfVectorizer(stop_words='english')),\n                         ('clf', LinearSVC(random_state=0)),\n    ])\n\n    text_clf.fit(X_train, y_train[label])  \n\n    predictions = text_clf.predict(X_test)\n\n    submission[label] = predictions\n\n    print('')\n    print(metrics.confusion_matrix(y_test[label],predictions))\n    print('')\n    print(metrics.classification_report(y_test[label],predictions))\n    print('')\n    print('')\n    print('')\n    print('')","adace7c7":"submission","23cf328a":"test","583de0f4":"X = df[['ID','TITLE', 'ABSTRACT']]\ny = df[['Computer Science', 'Physics', 'Mathematics','Statistics', \n          'Quantitative Biology', 'Quantitative Finance']] \n\n\nsubmission = pd.DataFrame(test['ID'])\n#submission = test\n\nX = data_clean(X)['text']\ntest = data_clean(test)['text']\n\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import LinearSVC\nfrom sklearn import metrics\n\nlabels = ['Computer Science', 'Physics', 'Mathematics','Statistics', \n          'Quantitative Biology', 'Quantitative Finance']\n\nfor label in labels:\n    \n    text_clf = Pipeline([('tfidf', TfidfVectorizer(stop_words='english')),\n                         ('clf', LinearSVC(random_state=0)),\n    ])\n\n    text_clf.fit(X, y[label])  \n\n    predictions = text_clf.predict(test)\n\n    submission[label] = predictions","b68196aa":"submission","0c0a0488":"filename = 'submission.csv'\nsubmission.to_csv(filename,index=False)\nprint('Saved file: ' + filename)","3e341dbb":"Researchers have access to large online archives of scientific articles. As a consequence, finding relevant articles has become more difficult. Tagging or topic modelling provides a way to give token of identification to research articles which facilitates recommendation and search process.\n\nGiven the abstract and title for a set of research articles, predict the topics for each article included in the test set.\n\nNote that a research article can possibly have more than 1 topic. The research article abstracts and titles are sourced from the following 6 topics:\n\n1. Computer Science\n2. Physics\n3. Mathematics\n4. Statistics\n5. Quantitative Biology\n6. Quantitative Finance","b3cc2df5":"# Six single label classification..\n\nThe initial approach I will use for this problem is to think of this as six single label classification. Will it work? Only one way to find out..","5ba7934e":"# Janatahack: Independence Day 2020 ML Hackathon\n## Topic Modeling for Research Articles","bf34f500":"I know that there is a lot and I can improve on.. But time to move on now..","f1e044ea":"I will combine Title and abstract into one column.","47147460":"# Data cleaning functions","d655f4d4":"There are many research articles with multiple topics. This is an example of multi-label classification. I am handling this type of a problem for the first time. \n\nNLP and a multi-label classification.. This will be fun!","3524ebbb":"# Some visualisations","3d3e1816":"Are there any rows which have multiple topics?"}}