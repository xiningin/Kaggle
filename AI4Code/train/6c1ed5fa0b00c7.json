{"cell_type":{"519d3d2b":"code","f00f86b9":"code","605cec7a":"code","c0fbacae":"code","6ba95649":"code","7c49976c":"code","f3ba8890":"code","8973aca1":"code","e3427356":"code","dc334bdd":"code","4a9804aa":"code","70bcbe91":"code","0a8ed120":"code","9dc86a71":"code","0009352d":"code","18a75c50":"code","395e0d9b":"code","ece305e1":"code","5364970c":"code","2a1a92eb":"code","85d53490":"code","a17b3f72":"code","cfa8a47c":"code","c6afb768":"code","c1298fac":"code","72e324c0":"code","7e2d5983":"code","7b65df93":"code","46590ec5":"code","27529cec":"code","f0ca4fec":"code","8b258476":"code","ef5a508e":"code","1757f4b2":"code","8285a5b1":"code","2665dfbf":"code","e2e54a63":"code","5c34c9c1":"code","79e6c95d":"code","ff2fd073":"code","0edde3c3":"code","f7602c6d":"code","386095f9":"code","a933ab46":"code","17c1452f":"code","a646ce4b":"code","c0e2314a":"code","82c37853":"code","f7cc6b2a":"code","a5cf26aa":"code","78f6d0b6":"code","d8a1e75b":"code","c88035dc":"code","367b94f3":"code","15236902":"code","2b8aa50a":"code","305d91d9":"code","ecd0f85e":"code","3873df03":"code","3d34e8c8":"code","279163d4":"code","6e8b4ad2":"code","d7f93f5a":"code","2070b7f2":"code","99071688":"code","3e866306":"code","ec6ef2e7":"code","bd6497b8":"code","ec28d491":"code","22841749":"code","77db119d":"code","dc9bf4b5":"code","4a6efe8f":"code","f96f66c2":"code","53137c72":"code","0e5415de":"code","bf727192":"code","6f68bc3f":"code","42f96d98":"code","e9d9188c":"code","2c9883fd":"code","5d6a220f":"code","65aa872f":"code","8259476e":"markdown","16fcf343":"markdown","4637a2f2":"markdown","f3aa93e6":"markdown","c4c86aeb":"markdown","12467b04":"markdown","450d0066":"markdown","ab297f0f":"markdown","a3bd4cde":"markdown","2978b334":"markdown","9fb5a902":"markdown","5150c4cd":"markdown","419d6aed":"markdown","c9db4969":"markdown","baa50ecd":"markdown","6fb83a0c":"markdown","151f59e3":"markdown","5ba2d334":"markdown"},"source":{"519d3d2b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f00f86b9":"import time\nt1 = time.time()\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nimport math\nimport random\nimport pandas as pd\nimport numpy as np\nimport cv2\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib\nfrom matplotlib import pyplot as plt\n%matplotlib inline","605cec7a":"#\uc7ac\ud604\uc774 \uac00\ub2a5\ud558\ub3c4\ub85d \ub79c\ub364 \uc2dc\ub4dc \uc124\uc815(NumPy, TensorFlow)\nnp_random_seed = 97\ntf_rand_seed = 82\nnp.random.seed(np_random_seed)","c0fbacae":"#test.json\ud30c\uc77c\uacfc train.json\uc774 .7z \ud30c\uc77c\ub85c \uc555\ucd95\ub418\uc5b4 \uc788\uc5b4\uc11c \uc774\ub97c \uc555\ucd95\ud574\uc81c\ud558\uae30 \uc704\ud55c library py7zr \uc124\uce58 \ud6c4 \uc555\ucd95\ud574\uc81c \uc2e4\ud589.\n!pip install py7zr\nimport py7zr\nimport os\n\nif not os.path.exists('\/kaggle\/train\/') :\n    os.makedirs('\/kaggle\/train\/')\n\nif not os.path.exists('\/kaggle\/test\/') :\n    os.makedirs('\/kaggle\/test\/')\n\nwith py7zr.SevenZipFile(\"\/kaggle\/input\/statoil-iceberg-classifier-challenge\/train.json.7z\", 'r') as archive:\n    archive.extractall(path=\"\/kaggle\/train\")\n\nwith py7zr.SevenZipFile(\"\/kaggle\/input\/statoil-iceberg-classifier-challenge\/test.json.7z\", 'r') as archive:\n    archive.extractall(path=\"\/kaggle\/test\")\n\nfor dirname, _, filenames in os.walk('\/kaggle'): \n    for filename in filenames: \n        print(os.path.join(dirname, filename))","6ba95649":"train = pd.read_json('\/kaggle\/train\/data\/processed\/train.json')\ntest = pd.read_json('\/kaggle\/test\/data\/processed\/test.json')","7c49976c":"train.head(5)","f3ba8890":"test.head(5)","8973aca1":"#train, test set\uc758 \ud06c\uae30 \ud655\uc778\nprint('Shape of train set:', train.shape)\nprint('Shape of test set:', test.shape)","e3427356":"#train set\uc758 band_1, band_2 feature\uc758 \ud06c\uae30 \ud655\uc778\nprint(\"Shape of band 1:\",  np.shape(train.band_1.iloc[0]))\nprint(\"Shape of band 2:\",  np.shape(train.band_2.iloc[0]))","dc334bdd":"#train set\uc758 band_1, band_2 feature\uc758 data type \ud655\uc778\nprint(\"Type of band 1:\",  type(train.band_1.iloc[0]))\nprint(\"Type of band 2:\",  type(train.band_2.iloc[0]))","4a9804aa":"#train set\uc758 inc_angle feature\uc5d0\uc11c \uacb0\uce21\uce58(na\uac12)\uc744 \uacb0\uce21\uce58\uac00 \uc5c6\ub294 \uac12\ub4e4\uc758 mean\uac12\uc73c\ub85c \ub300\uce58\ud55c\ub2e4.\ntrain[train['inc_angle']=='na'] = train[train['inc_angle']!='na']['inc_angle'].mean()","70bcbe91":"#inc_angle feature\ub294 \uac01\ub3c4(0~360)\uc73c\ub85c \ub418\uc5b4\uc788\ub294\ub370, \uc774\ub97c \ub77c\ub514\uc548 \uac12\uc73c\ub85c \ubcc0\ud658\ud55c\ub2e4.\ntrain['inc_angle'] = train['inc_angle'].apply(lambda x: math.radians(x))","0a8ed120":"train.inc_angle.head()\n#\ubc11\uc744 \ubcf4\uba74 inc_angle \uac12\uc774 \ub77c\ub514\uc548 \uac12\uc73c\ub85c \ubcc0\ud658\ub41c \uac83\uc744 \ubcfc \uc218 \uc788\ub2e4.","9dc86a71":"#band_1\/2 data\uc758 \ud06c\uae30\ub294 \uc6d0\ub798 (5625,)\uc778\ub370, \uba87 \uac1c \ube60\uc838\uc788\ub294 row\ub4e4\uc774 \uc874\uc7ac\ud55c\ub2e4. \uc774\ub97c \ucc3e\uc544\ub0b4\uae30 \uc704\ud55c \ud568\uc218 find_missing_data\ndef find_missing_data(series, shape):\n    count = 0\n    missing_list = []\n    \n    for i, x in enumerate(series):\n        if np.shape(series.iloc[i]) != shape:\n            missing_list.append(i)\n            count += 1\n    \n    return missing_list, count","0009352d":"missing_list1, count1 = find_missing_data(train.band_1, (5625,))\nprint(\"Count1: \", count1)\nprint(\"Missing data: \", missing_list1)\n\n#\ubc11\uc5d0 \ub098\uc628 \uac12\uc774 band_1 feature\uc5d0\uc11c shape\uac00 (5625,)\uac00 \uc544\ub2cc \uac12\ub4e4.","18a75c50":"missing_list2, count2 = find_missing_data(train.band_2, (5625,))\nprint(\"Count1: \", count2)\nprint(\"Missing data: \", missing_list2)","395e0d9b":"missing_list1 == missing_list2\n#\uac19\uc740 \ubc30\uc5f4\uc774\ub2e4. \ube60\uc9c4 \uac83\uc774 \ub098\ud0c0\ub098\ub294 row\uac00 \uac19\ub2e4.","ece305e1":"#index\uc5d0 \ub300\ud574 \ub370\uc774\ud130\ub97c \uc0ad\uc81c\ud574\uc8fc\ub294 \ud568\uc218 drop_data\ndef drop_data(df, index):\n    return df.drop(df.index[index])","5364970c":"train = drop_data(train, missing_list1)\n#\uc704\uc758 missing_list1\ub97c \uc774\uc6a9\ud574 train\uc5d0\uc11c \ud574\ub2f9 \uac12\uc744 \uc81c\uac70\ud55c\ub2e4.","2a1a92eb":"train.shape","85d53490":"print(\"Number of positive classes: \", len(train[train['is_iceberg'] == 1.0]))\nprint(\"Number of negative classes: \", len(train[train['is_iceberg'] == 0.0]))","a17b3f72":"#\uc815\uaddc\ud654(\uc815\uaddc\ubd84\ud3ec)\ndef standardise_vector(vector):\n    '''standardize vector'''\n    standardised_vector = (np.array(vector) - np.mean(vector)) \/ np.std(vector)\n    return standardised_vector.tolist()","cfa8a47c":"#\ud3c9\uade0\uc815\uaddc\ud654(?)\ndef mean_normalise_vector(vector):\n    '''mean normalize vector'''\n    normalised_vector = (np.array(vector) - np.mean(vector)) \/ (np.max(vector) - np.min(vector))\n    return normalised_vector.tolist()","c6afb768":"#\ucd5c\ub300 \ucd5c\uc18c \uc815\uaddc\ud654\ndef min_max_scaler(vector, minimum = 0, maximum = 1):\n    '''minmaxscaler'''\n    X_std  = (np.array(vector) - np.min(vector)) \/ (np.max(vector) - np.min(vector))\n    scaled_vector = X_std * (maximum - minimum) + minimum\n    return scaled_vector.tolist()","c1298fac":"#1\ubc88 \uae30\ubc95 standardise_vector \uc0ac\uc6a9\ntrain['band_1'] = train['band_1'].apply(standardise_vector)\ntrain['band_2'] = train['band_2'].apply(standardise_vector)","72e324c0":"train.head()","7e2d5983":"band_1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\nband_2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])","7b65df93":"print(\"Shape of band 1 image:\",band_1.shape)\nprint(\"Shape of band 2 image:\",band_2.shape)\n\n#(1471,5625)\uac00 (1471,75,75)\ub85c \ubcc0\ud654\ud558\uc600\ub2e4 -> 2D image\ub85c \ubcc0\ud658 (\ucd94\ud6c4 Conv2D \uc5f0\uc0b0\uc744 \uc704\ud574 N x Height x Width \uaf34\ub85c \ubcc0\ud658)\n#\uc6d0\ub798\ub294 N x Height x Width x Channel \uaf34\ub85c \ubcc0\ud658\ud574\uc57c \ud558\ub294\ub370, Channel\uc740 \ubc11\uc5d0\uc11c \ucd94\uac00\ud568.","46590ec5":"#2.2\uc640 \uac19\uc740 \uc791\uc5c5\uc744 \uc218\ud589\ud55c\ub2e4.\ntest['inc_angle'] = test['inc_angle'].apply(lambda x: math.radians(x))","27529cec":"test.inc_angle.head()","f0ca4fec":"missing_list3, count3 = find_missing_data(test.band_1, (5625,))\nprint(\"count: \", count3)\nprint(\"missing data: \", missing_list3)","8b258476":"missing_list4, count4 = find_missing_data(test.band_2, (5625,))\nprint(\"count: \", count4)\nprint(\"missing data: \", missing_list4)","ef5a508e":"test['band_1'] = test['band_1'].apply(standardise_vector)\ntest['band_2'] = test['band_2'].apply(standardise_vector)","1757f4b2":"band_1_test = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\nband_2_test = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])","8285a5b1":"print(\"Shape of test set band 1 image:\",band_1_test.shape)\nprint(\"Shape of test set band 2 image:\",band_2_test.shape)","2665dfbf":"type(train.is_iceberg)","e2e54a63":"#\ubcf8\ubb38 notebook\uc5d0\ub294 DataFrame.as_matrix() \uba54\uc11c\ub4dc\ub97c \uc0ac\uc6a9\ud558\ub77c\uace0 \ub418\uc5b4\uc788\uc73c\ub098, \ud310\ub2e4\uc2a4 0.23.0\ubd80\ud130 \uc774 \uba54\uc11c\ub4dc\ub294 \ub354 \uc774\uc0c1 \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uac8c \ub418\uc5b4 \ub3d9\uc77c\ud55c \uc77c\uc744 \uc218\ud589\ud558\ub294 \ub2e4\ub978 \uba54\uc11c\ub4dc\uc778 DataFrame.to_numpy()\ub97c \uc0ac\uc6a9\ud55c\ub2e4.\nlabels = train.is_iceberg.to_numpy()\nangles = train.inc_angle.to_numpy()","5c34c9c1":"#train \uc778\ub371\uc2a4\uc640 validation \uc778\ub371\uc2a4\ub97c \ub79c\ub364\ud558\uac8c \uace0\ub978\ub2e4.\ntrain_indices = np.random.choice(len(labels), round(len(labels)*0.75), replace=False)\nvalidation_indices = np.array(list(set(range(len(labels))) - set(train_indices)))\n\n# \uc704\uc5d0\uc11c \ub79c\ub364\ud558\uac8c \uace0\ub978 \uc778\ub371\uc2a4\ub97c \uc0ac\uc6a9\ud574 train set \uad6c\uc131\nband_1_train = band_1[train_indices]\nband_2_train = band_2[train_indices]\nangles_train = angles[train_indices]\nlabels_train = labels[train_indices]\n\n# \uc704\uc5d0\uc11c \ub79c\ub364\ud558\uac8c \uace0\ub978 \uc778\ub371\uc2a4\ub97c \uc0ac\uc6a9\ud574 validation set \uad6c\uc131\nband_1_validation = band_1[validation_indices]\nband_2_validation = band_2[validation_indices]\nangles_validation = angles[validation_indices]\nlabels_validation = labels[validation_indices]\n\n# \uc6d0\ubcf8 \ub370\uc774\ud130\ub85c\ubd80\ud130 test set \uad6c\uc131\nband_1_test = band_1_test\nband_2_test = band_2_test\nangles_test = test.inc_angle.to_numpy()\niD = test.id.to_numpy()","79e6c95d":"#\ubaa8\ub4e0 \ub370\uc774\ud130\ub97c float datatype\uc73c\ub85c \ubcc0\uacbd\nband_1_train = band_1_train.astype(np.float32)\nband_1_validation = band_1_validation.astype(np.float32)\nband_1_test = band_1_test.astype(np.float32)\nband_2_train = band_2_train.astype(np.float32)\nband_2_validation = band_2_validation.astype(np.float32)\nband_2_test = band_2_test.astype(np.float32)\nangles_train = angles_train.astype(np.float32)\nangles_validation = angles_validation.astype(np.float32)\nangles_test = angles_test.astype(np.float32)\nlabels_train = labels_train.astype(np.float32)\nlabels_validation = labels_validation.astype(np.float32)\niD = iD.astype(np.str)","ff2fd073":"#\uba54\ubaa8\ub9ac\uac00 \ucd08\uacfc\ub418\ub294 \ubd88\ud544\uc694\ud55c \ubcc0\uc218 \uc0ad\uc81c <- train\uc744 \uc120\uc5b8\ud588\uc5c8\ub294\ub370 \uc65c del\uc774 \uc548\ub420\uae4c???\ndel(train, test, band_1, band_2)","0edde3c3":"#\uac01 \ub370\uc774\ud130\ub4e4\uc758 shape \ucd9c\ub825\nprint(\"Shape of band_1_train:\",band_1_train.shape)\nprint(\"Shape of band_2_train:\",band_1_train.shape)\nprint(\"Shape of angles_train:\",angles_train.shape)\nprint(\"Shape of labels_train:\",labels_train.shape)\nprint(\"Shape of band_1_validation:\",band_1_validation.shape)\nprint(\"Shape of band_2_validation:\",band_2_validation.shape)\nprint(\"Shape of angles_validation:\",angles_validation.shape)\nprint(\"Shape of labels_validation:\",labels_validation.shape)\nprint(\"Shape of band_1_test:\",band_1_test.shape)\nprint(\"Shape of band_2_test:\",band_2_test.shape)\nprint(\"Shape of angles_test:\",angles_test.shape)\nprint(\"Shape of iD:\",iD.shape)","f7602c6d":"#\uc774\ubbf8\uc9c0 \ud68c\uc804\ndef rotate_image(img, angle = 20):\n    \n    # rotate image\n    original = img.copy()\n    \n    #2D \uc774\ubbf8\uc9c0\ub97c \uae30\ud558\ud559\uc801\uc73c\ub85c \ubcc0\ud615\ud558\uae30 -> \ud589\ub82c \ubcc0\ud658(\uac15\uccb4\ubcc0\ud658, \uc720\uc0ac\ubcc0\ud658, \uc120\ud615\ubcc0\ud658, Affine \ub4f1)\n    #\uc120\ud615\ubcc0\ud658\uc740 Vector \uacf5\uac04\uc5d0\uc11c\uc758 \uc774\ub3d9\uc744 \uc758\ubbf8.(\ud68c\uc804,\ud06c\uae30\ubcc0\uacbd, \ubc18\uc804 \ub4f1. but, \uc704\uce58\ubcc0\ud658\uc740 X)\n    #Affine \ubcc0\ud658\uc740 \uc218\ud3c9\uc131\uc744 \uc720\uc9c0\ud558\uba70 \uc120\ud615\ubcc0\ud658\uacfc \uc774\ub3d9\ubcc0\ud658\uc744 \ud3ec\ud568\ud558\ub294 \uac83.\n    #cv2.getRotationMatrix2D(\ud68c\uc804 \uc911\uc2ec \uc88c\ud45c, \ubc18\uc2dc\uacc4 \ubc29\ud5a5\uc758 \ud68c\uc804 \uac01\ub3c4, \ucd94\uac00\uc801\uc778 \ud655\ub300 \ube44\uc728)\n    M_rotate = cv2.getRotationMatrix2D((37,37),angle,1)\n    \n    #cv2.warpAffine(\ub300\uc0c1 \uc774\ubbf8\uc9c0, Affine Matrix, \uc774\ubbf8\uc9c0 \ud06c\uae30)\n    \n    img_new = cv2.warpAffine(img,M_rotate,(75,75))\n    \n    length_row = 0\n    length_column = 0\n    boundary_step = 5\n    \n    for i in range(len(img_new)):\n        if img_new[0,i]!=float(0.0):\n            length_row = i\n            break\n    for i in range(len(img_new)):\n        if img_new[i,0]!=float(0.0):\n            length_column = i\n            break\n    \n    # \uc774\ubbf8\uc9c0 \ubcc0\ud658 \ud6c4 \ub0a8\ub294 \ubd80\ubd84\uc744 \uc6d0\ub798 \uc774\ubbf8\uc9c0\uc5d0\uc11c \uac00\uc838\uc628\ub2e4.\n    img_new[:length_column+boundary_step,:length_row+boundary_step] = \\\n    original[:length_column+boundary_step,:length_row+boundary_step] \n    \n    img_new[-(length_row+boundary_step):,:length_column+boundary_step] = \\\n    original[-(length_row+boundary_step):,:length_column+boundary_step]\n    \n    img_new[:length_row+boundary_step,-(length_column+boundary_step):] = \\\n    original[:length_row+boundary_step,-(length_column+boundary_step):]\n    \n    img_new[-(length_column+boundary_step):,-(length_row+boundary_step):] = \\\n    original[-(length_column+boundary_step):,-(length_row+boundary_step):]\n    \n    return img_new","386095f9":"#\uc218\ud3c9 \ubc29\ud5a5\uc73c\ub85c \uc6c0\uc9c1\uc774\uae30(shift)\ndef translate_horizontal(image, shift_horizontal = 5):\n\n    \n    img = image.copy()\n    \n    shift_vertical = 0; \n    if shift_horizontal<0:\n        image_slice = img[:,shift_horizontal:].copy()\n    if shift_horizontal>0:\n        image_slice = img[:,:shift_horizontal].copy()\n    M_translate = np.float32([[1,0,shift_horizontal],[0,1,shift_vertical]])\n    img_new = cv2.warpAffine(img,M_translate,(75,75))\n    \n    # \uc774\ubbf8\uc9c0 \ubcc0\ud658 \ud6c4 \ub0a8\ub294 \ubd80\ubd84\uc744 \uc6d0\ub798 \uc774\ubbf8\uc9c0\uc5d0\uc11c \uac00\uc838\uc628\ub2e4.\n    if shift_horizontal<0:\n        img_new[:,shift_horizontal:] = image_slice\n    if shift_horizontal>0:\n        img_new[:,:shift_horizontal] = image_slice\n        \n    return img_new.reshape(75,75).astype(np.float32)","a933ab46":"#\uc218\uc9c1\uc73c\ub85c \uc6c0\uc9c1\uc774\uae30(vertical shift)\ndef translate_vertical(image, shift_vertical = 5):\n\n    \n    img = image.copy()\n    \n    shift_horizontal = 0;\n    if shift_vertical<0:\n        image_slice = img[shift_vertical:,:].copy()\n    if shift_vertical>0:\n        image_slice = img[:shift_vertical,:].copy()\n    M_translate = np.float32([[1,0,shift_horizontal],[0,1,shift_vertical]])\n    img_new = cv2.warpAffine(img,M_translate,(75,75))\n    \n    # \uc774\ubbf8\uc9c0 \ubcc0\ud658 \ud6c4 \ub0a8\ub294 \ubd80\ubd84\uc744 \uc6d0\ub798 \uc774\ubbf8\uc9c0\uc5d0\uc11c \uac00\uc838\uc628\ub2e4.\n    if shift_vertical<0:\n        img_new[shift_vertical:,:] = image_slice\n    if shift_vertical>0:\n        img_new[:shift_vertical,:] = image_slice\n        \n    return img_new.reshape(75,75).astype(np.float32)","17c1452f":"#\ub300\uac01\uc120\uc73c\ub85c \uc6c0\uc9c1\uc774\uae30(diagonal shift)\ndef translate_positive_diagonal(image, shift_diagonal = 5):\n\n    \n    img = image.copy()\n    \n    if shift_diagonal<0:\n        hor_slice = img[shift_diagonal:,:].copy()\n        ver_slice = img[:,shift_diagonal:].copy()\n    else:\n        hor_slice = img[:shift_diagonal,:].copy()\n        ver_slice = img[:,:shift_diagonal].copy()\n    M_translate = np.float32([[1,0,shift_diagonal],[0,1,shift_diagonal]])\n    img_new = cv2.warpAffine(img,M_translate,(75,75))\n    \n    # \uc774\ubbf8\uc9c0 \ubcc0\ud658 \ud6c4 \ub0a8\ub294 \ubd80\ubd84\uc744 \uc6d0\ub798 \uc774\ubbf8\uc9c0\uc5d0\uc11c \uac00\uc838\uc628\ub2e4.\n    if shift_diagonal<0:\n        img_new[shift_diagonal:,:] = hor_slice\n        img_new[:,shift_diagonal:] = ver_slice\n    else:\n        img_new[:shift_diagonal,:] = hor_slice\n        img_new[:,:shift_diagonal] = ver_slice\n    \n    return img_new.reshape(75,75).astype(np.float32)","a646ce4b":"#\ub300\uac01\uc120\uc73c\ub85c \uc6c0\uc9c1\uc774\uae302(diagonal shift) - \uc74c\uc758 \ubc29\ud5a5\ndef translate_negative_diagonal(image, shift_diagonal = 5):\n\n    \n    img = image.copy()\n    \n    if shift_diagonal<0:\n        hor_slice = img[:-shift_diagonal,:].copy()\n        ver_slice = img[:,shift_diagonal:].copy()\n    if shift_diagonal>0:\n        hor_slice = img[-shift_diagonal:,:].copy()\n        ver_slice = img[:,:shift_diagonal].copy()\n    M_translate = np.float32([[1,0,shift_diagonal],[0,1,-shift_diagonal]])\n    img_new = cv2.warpAffine(img,M_translate,(75,75))\n    \n    # \uc774\ubbf8\uc9c0 \ubcc0\ud658 \ud6c4 \ub0a8\ub294 \ubd80\ubd84\uc744 \uc6d0\ub798 \uc774\ubbf8\uc9c0\uc5d0\uc11c \uac00\uc838\uc628\ub2e4.\n    if shift_diagonal<0:\n        img_new[:-shift_diagonal,:] = hor_slice\n        img_new[:,shift_diagonal:] = ver_slice\n    if shift_diagonal>0:\n        img_new[-shift_diagonal:,:] = hor_slice\n        img_new[:,:shift_diagonal] = ver_slice\n        \n    return img_new.reshape(75,75).astype(np.float32)","c0e2314a":"#\uc774\ubbf8\uc9c0 \ud50c\ub9bd\ndef flip(image, direction = 0):\n    \n    img = image.copy()\n    return cv2.flip(img,direction)","82c37853":"#\uc774\ubbf8\uc9c0 \ud655\ub300\ndef zoom(image, zoom_shift = 5):\n\n    img = image.copy()\n\n    if zoom_shift>0:\n        img_new = cv2.resize(img, (75+zoom_shift*2,75+zoom_shift*2)) \n        img_new = img_new[zoom_shift:-zoom_shift,zoom_shift:-zoom_shift] \n    else:\n        zoom_shift *=-1\n        \n        hor_top = img[:zoom_shift,:]\n        hor_bottom =img[-zoom_shift:,:]\n        ver_left = img[:,:zoom_shift]\n        ver_right = img[:,-zoom_shift:]\n        \n        img_new = cv2.resize(img, (75-zoom_shift*2,75-zoom_shift*2)) \n        # \uc81c\ub85c \ud328\ub529\n        img_new = cv2.copyMakeBorder(img_new,zoom_shift,zoom_shift,zoom_shift,zoom_shift,\n                                     cv2.BORDER_CONSTANT,value=0.0)\n        # \uc774\ubbf8\uc9c0 \ubcc0\ud658 \ud6c4 \ub0a8\ub294 \ubd80\ubd84\uc744 \uc6d0\ub798 \uc774\ubbf8\uc9c0\uc5d0\uc11c \uac00\uc838\uc628\ub2e4.\n        img_new[:zoom_shift,:] = hor_top\n        img_new[-zoom_shift:,:] = hor_bottom\n        img_new[:,:zoom_shift] = ver_left\n        img_new[:,-zoom_shift:] = ver_right     \n        \n    return img_new.reshape(75,75).astype(np.float32)","f7cc6b2a":"matplotlib.rcParams['figure.figsize'] = (20.0, 14.0)\nimage = band_1_test[3].copy()\nplt.subplot(3, 5, 1)\nplt.title(\"Original Image\")\nplt.imshow(image)\nplt.subplot(3, 5, 2)\ngenerated_image = rotate_image(image,40)\nplt.title(\"Rotation by +ve degree\")\nplt.imshow(generated_image)\nplt.subplot(3, 5, 3)\ngenerated_image = rotate_image(image,-40)\nplt.title(\"Rotation by -ve degree\")\nplt.imshow(generated_image)\nplt.subplot(3, 5, 4)\ngenerated_image = translate_horizontal(image,10)\nplt.title(\"Horizonation translation to right\")\nplt.imshow(generated_image)\nplt.subplot(3, 5, 5)\ngenerated_image = translate_horizontal(image,-10)\nplt.title(\"Horizonation translation to left\")\nplt.imshow(generated_image)\nplt.subplot(3, 5, 6)\ngenerated_image = translate_vertical(image,10)\nplt.title(\"Vertical translation downward\")\nplt.imshow(generated_image)\nplt.subplot(3, 5, 7)\ngenerated_image = translate_vertical(image,-10)\nplt.title(\"Vertical translation upward\")\nplt.imshow(generated_image)\nplt.subplot(3, 5, 8)\ngenerated_image = translate_positive_diagonal(image,10)\nplt.title(\"SE translation\")\nplt.imshow(generated_image)\nplt.subplot(3, 5, 9)\ngenerated_image = translate_positive_diagonal(image,-10)\nplt.title(\"NW translation\")\nplt.imshow(generated_image)\nplt.subplot(3, 5, 10)\ngenerated_image = translate_negative_diagonal(image,10)\nplt.title(\"NE translation\")\nplt.imshow(generated_image)\nplt.subplot(3, 5, 11)\ngenerated_image = translate_negative_diagonal(image,-10)\nplt.title(\"SW translation\")\nplt.imshow(generated_image)\nplt.subplot(3, 5, 12)\ngenerated_image = flip(image,0)\nplt.title(\"Vertical flip\")\nplt.imshow(generated_image)\nplt.subplot(3, 5, 13)\ngenerated_image = flip(image,1)\nplt.title(\"Horizontal flip\")\nplt.imshow(generated_image)\nplt.subplot(3, 5, 14)\ngenerated_image = zoom(image,10)\nplt.title(\"Zoom in\")\nplt.imshow(generated_image)\nplt.subplot(3, 5, 15)\ngenerated_image = zoom(image,-10)\nplt.title(\"Zoom out\")\nplt.imshow(generated_image)\nplt.show()","a5cf26aa":"def augment_data(band1, band2, angles, labels):\n    \n    '''a function to augment band1 and band2 image'''\n    \n    # list to store the generated data\n    band1_generated = []\n    band2_generated = []\n    angles_generated = []\n    labels_generated = []\n    \n    # iterate through each point in train set\n    for i in range(labels.shape[0]):\n        \n        # rotate by positive degree\n        angle = np.random.randint(5,20)\n        band1_generated.append(rotate_image(band1[i],angle)) \n        band2_generated.append(rotate_image(band2[i],angle))\n        angles_generated.append(angles[i])\n        labels_generated.append(labels[i])\n        \n        # rotate by negative degree\n        angle = np.random.randint(5,20)\n        band1_generated.append(rotate_image(band1[i],-angle)) \n        band2_generated.append(rotate_image(band2[i],-angle))\n        angles_generated.append(angles[i])\n        labels_generated.append(labels[i])\n        \n        # positive horizontal shift\n        shift = np.random.randint(3,7)\n        band1_generated.append(translate_horizontal(band1[i],+shift)) \n        band2_generated.append(translate_horizontal(band2[i],+shift))\n        angles_generated.append(angles[i])\n        labels_generated.append(labels[i])\n        \n        # negative horizontal shift\n        shift = np.random.randint(3,7) \n        band1_generated.append(translate_horizontal(band1[i],-shift)) \n        band2_generated.append(translate_horizontal(band2[i],-shift))\n        angles_generated.append(angles[i])\n        labels_generated.append(labels[i])\n        \n        # positive vertical shift\n        shift = np.random.randint(0,7)  \n        band1_generated.append(translate_vertical(band1[i],+shift)) \n        band2_generated.append(translate_vertical(band2[i],+shift))\n        angles_generated.append(angles[i])\n        labels_generated.append(labels[i])\n        \n        # negative vertical shift\n        shift = np.random.randint(3,7) \n        band1_generated.append(translate_vertical(band1[i],-shift)) \n        band2_generated.append(translate_vertical(band2[i],-shift))\n        angles_generated.append(angles[i])\n        labels_generated.append(labels[i])\n        \n        # translate along positive diagonal in positive direction\n        shift = np.random.randint(3,7)  \n        band1_generated.append(translate_positive_diagonal(band1[i],+shift)) \n        band2_generated.append(translate_positive_diagonal(band2[i],+shift))\n        angles_generated.append(angles[i])\n        labels_generated.append(labels[i])\n        \n        # translate along positive diagonal in negative direction\n        shift = np.random.randint(3,7)  \n        band1_generated.append(translate_positive_diagonal(band1[i],-shift)) \n        band2_generated.append(translate_positive_diagonal(band2[i],-shift))\n        angles_generated.append(angles[i])\n        labels_generated.append(labels[i])\n        \n        # translate along negative diagonal in positive direction\n        shift = np.random.randint(3,7)   \n        band1_generated.append(translate_negative_diagonal(band1[i],+shift)) \n        band2_generated.append(translate_negative_diagonal(band2[i],+shift))\n        angles_generated.append(angles[i])\n        labels_generated.append(labels[i])\n        \n        # translate along negative diagonal in negative direction\n        shift = np.random.randint(3,7)   \n        band1_generated.append(translate_negative_diagonal(band1[i],-shift)) \n        band2_generated.append(translate_negative_diagonal(band2[i],-shift))\n        angles_generated.append(angles[i])\n        labels_generated.append(labels[i])\n        \n        # vertical flip\n        band1_generated.append(flip(band1[i],0)) \n        band2_generated.append(flip(band2[i],0))\n        angles_generated.append(angles[i])\n        labels_generated.append(labels[i])\n        \n        # horizontal flip\n        band1_generated.append(flip(band1[i],1)) \n        band2_generated.append(flip(band2[i],1))\n        angles_generated.append(angles[i])\n        labels_generated.append(labels[i])\n        \n        # zoom in image\n        zoom_shift = np.random.randint(2,5)\n        band1_generated.append(zoom(band1[i],zoom_shift)) \n        band2_generated.append(zoom(band2[i],zoom_shift))\n        angles_generated.append(angles[i])\n        labels_generated.append(labels[i])\n        \n        # zoom out image\n        zoom_shift = np.random.randint(2,5) \n        band1_generated.append(zoom(band1[i],-zoom_shift)) \n        band2_generated.append(zoom(band2[i],-zoom_shift))\n        angles_generated.append(angles[i])\n        labels_generated.append(labels[i])        \n        \n    # convert the generated data into numpy array\n    band1_generated = np.array(band1_generated)\n    band2_generated = np.array(band2_generated)\n    angles_generated = np.array(angles_generated)\n    labels_generated = np.array(labels_generated)\n    \n    # concatenate the generated data to original train set\n    band1_augmented = np.concatenate((band1, band1_generated),axis=0)\n    band2_augmented = np.concatenate((band2, band2_generated),axis=0)\n    angles_augmented = np.concatenate((angles, angles_generated),axis=0)\n    labels_augmented = np.concatenate((labels, labels_generated),axis=0)\n    \n    return band1_augmented, band2_augmented, angles_augmented, labels_augmented","78f6d0b6":"band_1_train, band_2_train, angles_train, labels_train = \\\n    augment_data(band_1_train, band_2_train, angles_train, labels_train)","d8a1e75b":"print(\"Shape of band_1_train:\",band_1_train.shape)\nprint(\"Shape of band_2_train:\",band_2_train.shape)\nprint(\"Shape of angles_train:\",angles_train.shape)\nprint(\"Shape of labels_train:\",labels_train.shape)","c88035dc":"image_train = np.concatenate([band_1_train[:, :, :, np.newaxis],\n                             band_2_train[:, :, :, np.newaxis],\n                             ((band_1_train+band_2_train)\/2)[:, :, :, np.newaxis]],\n                             axis=-1)","367b94f3":"image_validation = np.concatenate([band_1_validation[:, :, :, np.newaxis],\n                             band_2_validation[:, :, :, np.newaxis],\n                             ((band_1_validation+band_2_validation)\/2)[:, :, :, np.newaxis]],\n                             axis=-1)","15236902":"image_test = np.concatenate([band_1_test[:, :, :, np.newaxis],\n                             band_2_test[:, :, :, np.newaxis],\n                             ((band_1_test+band_2_test)\/2)[:, :, :, np.newaxis]],\n                             axis=-1)","2b8aa50a":"print(\"Shape of image_train:\",image_train.shape)\nprint(\"Shape of image_validation:\",image_validation.shape)\nprint(\"Shape of image_test:\",image_test.shape)","305d91d9":"import tensorflow as tf\nfrom tensorflow.python.framework import ops\nops.reset_default_graph()\ntf.compat.v1.set_random_seed(tf_rand_seed) #\uc6d0\ubcf8 \ub178\ud2b8\ubd81\uc740 TensorFlow 1.x \ubc84\uc804 \uae30\uc900\uc778\ub370, Kaggle Notebook\uc740 TensorFlow 2.x\ubc84\uc804\uc774\uae30 \ub54c\ubb38\uc5d0, 2.x\uc5d0\uc11c 1.x \ucf54\ub4dc\ub85c \ubcc0\ud658\ud588\ub2e4.\n#\uc774\ud558\ub85c compat.v1\uc774 \ubd99\ub294 \uba54\uc11c\ub4dc\ub294 \uc804\ubd80 2.x\uc5d0\uc11c 1.x \ucf54\ub4dc\ub97c \ub3cc\uc544\uac00\uac8c \ud558\ub294 \ubc29\ubc95\uc774\ub2e4.","ecd0f85e":"labels_train = pd.get_dummies(labels_train).to_numpy()\nlabels_validation = pd.get_dummies(labels_validation).to_numpy()","3873df03":"print(\"Shape of labels_train:\", labels_train.shape)\nprint(\"Shape of labels_validation:\", labels_validation.shape)","3d34e8c8":"#\uc774\ubbf8\uc9c0 \ucc28\uc6d0 \ubcc0\uc218 \uc9c0\uc815\nwidth = 75\nheight = 75\nnum_channels = 3\nflat = width * height\nnum_classes = 2","279163d4":"tf.compat.v1.disable_eager_execution() #TensorFlow 1.x\uc5d0\uc11c TensorFlow 2.x\ub85c \uc62c\ub77c\uac08 \ub54c \uc0dd\uae30\ub294 \uc624\ub958 \ubc29\uc9c0\n\n#tf.placeholder(TF 1.x) -> tf.compat.v1.placeholder(TF 2.x)\n\nimage = tf.compat.v1.placeholder(tf.float32, shape=[None, height, width, num_channels])\ny_true = tf.compat.v1.placeholder(tf.int32, shape=[None, num_classes])\nkeep_prob = tf.compat.v1.placeholder(tf.float32)","6e8b4ad2":"#\uac00\uc911\uce58 \ud150\uc11c \uc0dd\uc131\ndef create_weights(shape):\n    return tf.Variable(tf.random.truncated_normal(shape, stddev=0.05))\n\n#\ubc14\uc774\uc5b4\uc2a4 \ud150\uc11c \uc0dd\uc131 \ndef create_biases(size):\n    return tf.Variable(tf.constant(0.05, shape=[size]))","d7f93f5a":"#\ucee8\ubcfc\ub8e8\uc158 \uce35 \ub9cc\ub4dc\ub294 \ud568\uc218\ndef create_convolutional_layer(input, num_input_channels, conv_filter_size, max_pool_filter_size, num_filters):  \n\n    #\ucee8\ubcfc\ub8e8\uc158 \uce35\uc758 \ud544\ud130 \ub9cc\ub4e4\uae30\n    weights = create_weights(shape=[conv_filter_size, conv_filter_size, num_input_channels, num_filters])\n    \n    # \ubc14\uc774\uc5b4\uc2a4 \uac12 \ub9cc\ub4e4\uae30\n    biases = create_biases(num_filters)\n    \n    # \ucee8\ubcfc\ub8e8\uc158 \uce35 \uc0dd\uc131\n    layer = tf.nn.conv2d(input=input, filters=weights, strides=[1, 1, 1, 1], padding='SAME')\n    \n    # \ucee8\ubcfc\ub8e8\uc158 \uce35\uc5d0 \ubc14\uc774\uc5b4\uc2a4 \uac12 \ub354\ud558\uae30\n    layer += biases\n    \n    # ReLU \ud65c\uc131\ud568\uc218 \ud1b5\uacfc\n    layer = tf.nn.relu(layer)\n    \n    # \ub9e5\uc2a4 \ud480\ub9c1\uc744 \ud1b5\ud574 \uc774\ubbf8\uc9c0 \uc0ac\uc774\uc988\ub97c \uc808\ubc18\uc73c\ub85c \uc904\uc774\uae30\n    layer = tf.nn.max_pool2d(input=layer, ksize=[1, max_pool_filter_size, max_pool_filter_size, 1], strides=[1, 2, 2, 1], padding='SAME')\n        \n    # output layer return\n    return layer","2070b7f2":"#\ucee8\ubcfc\ub8e8\uc158 \uce35\uc744 \uc9c0\ub09c \uac83\uc744 flatten\ud558\uac8c \ud574\uc8fc\ub294 \ud568\uc218\ndef create_flatten_layer(layer):\n\n    # layer\uc758 size \uc800\uc7a5\n    layer_shape = layer.get_shape()\n    \n    #flatten layer\uac00 \uc5b4\ub5a4 shape\ub97c \uac00\uc838\uc57c\ud560\uc9c0 num_features\uc5d0 \uc800\uc7a5\n    num_features = layer_shape[1:4].num_elements()\n    \n    \n    # flatten layer \ub9cc\ub4e4\uae30\n    layer = tf.reshape(layer, [-1, num_features])\n    \n    return layer","99071688":"#fully connected layer \ub9cc\ub4dc\ub294 \ud568\uc218\ndef create_fc_layer(input, num_inputs, num_outputs, use_relu=True, dropout = False, keep_prob = 0.2):\n    \n\n    #\uac00\uc911\uce58\uc640 \ubc14\uc774\uc5b4\uc2a4\uac12 \ub9cc\ub4e4\uae30\n    weights = create_weights(shape=[num_inputs, num_outputs])\n    biases = create_biases(num_outputs)\n    \n    # Wx+b \ud568\uc218 \uc0dd\uc131 <- \uac00\uc7a5 \uae30\ubcf8 \uc801\uc778 \uac83\n    # matrix multiplication between input and weight matrix\n    layer = tf.matmul(input, weights) + biases\n    \n    # ReLU\n    if use_relu:\n        layer = tf.nn.relu(layer)\n        \n    # Dropout\n    if dropout:        \n        layer = tf.nn.dropout(layer, rate=1 - (keep_prob))\n    \n    return layer","3e866306":"# paramters for 1st convolutional layer\nconv1_features = 64\nconv1_filter_size = 3\nmax_pool_size1 = 2\n\n# paramters for 2nd convolutional layer\nconv2_features = 128\nconv2_filter_size = 3\nmax_pool_size2 = 2\n\n# paramters for 3rd convolutional layer\nconv3_features = 128\nconv3_filter_size = 3\nmax_pool_size3 = 2\n\n# paramters for 4th convolutional layer\nconv4_features = 64\nconv4_filter_size = 3\nmax_pool_size4 = 2\n\n# number of featuers of 1st fully connected layer\nfc_layer_size1 = 512\n\n# number of featuers of 2nd fully connected layer\nfc_layer_size2 = 256","ec6ef2e7":"#layer 1\nlayer_conv1 = create_convolutional_layer(input=image,\n                                         num_input_channels= num_channels,\n                                         conv_filter_size = conv1_filter_size,\n                                         max_pool_filter_size = max_pool_size1,\n                                         num_filters = conv1_features)\nlayer_conv1","bd6497b8":"#layer 2\nlayer_conv2 = create_convolutional_layer(input=layer_conv1,\n                                         num_input_channels= conv1_features,\n                                         conv_filter_size = conv2_filter_size,\n                                         max_pool_filter_size = max_pool_size2,\n                                         num_filters = conv2_features)\nlayer_conv2","ec28d491":"#layer 3\nlayer_conv3 = create_convolutional_layer(input=layer_conv2,\n                                         num_input_channels= conv2_features,\n                                         conv_filter_size = conv3_filter_size,\n                                         max_pool_filter_size = max_pool_size3,\n                                         num_filters = conv3_features)\nlayer_conv3","22841749":"#layer 4\nlayer_conv4 = create_convolutional_layer(input=layer_conv3,\n                                         num_input_channels= conv3_features,\n                                         conv_filter_size = conv4_filter_size,\n                                         max_pool_filter_size = max_pool_size4,\n                                         num_filters = conv4_features)\nlayer_conv4","77db119d":"#flatten layer\nlayer_flat = create_flatten_layer(layer_conv4)\nlayer_flat","dc9bf4b5":"#layer 5(FC)\nlayer_fc1 = create_fc_layer(input=layer_flat,\n                            num_inputs=layer_flat.get_shape()[1:4].num_elements(),\n                            num_outputs=fc_layer_size1,\n                            use_relu=True,\n                            dropout =True,\n                            keep_prob = keep_prob)\nlayer_fc1","4a6efe8f":"#layer 6(FC)\nlayer_fc2 = create_fc_layer(input=layer_fc1,\n                            num_inputs=fc_layer_size1,\n                            num_outputs=fc_layer_size2,\n                            use_relu=True,\n                            dropout =True,\n                            keep_prob = keep_prob)\nlayer_fc2","f96f66c2":"#layer 7(output)\noutput_layer = create_fc_layer(input=layer_fc2,\n                     num_inputs = fc_layer_size2,\n                     num_outputs = num_classes,\n                     use_relu=False)\noutput_layer","53137c72":"# \ub9c8\uc9c0\ub9c9 \ucd9c\ub825\uce35\uc5d0\uc11c \uc0ac\uc6a9\ub420 softmax\ud568\uc218\ny_pred = tf.nn.softmax(output_layer)\n\n# \uc608\uce21\uac12\ny_pred_cls = tf.argmax(y_pred, axis=1, output_type=tf.int32)\n\n# \uc2e4\uc81c\uac12\ny_true_cls = tf.argmax(y_true, axis=1, output_type=tf.int32)","0e5415de":"# \ub9de\uc558\ub294\uc9c0 \ud655\uc778\ncorrect_prediction = tf.equal(y_pred_cls, y_true_cls)\n\n# \uc815\ud655\ub3c4 \uacc4\uc0b0 \uba54\ud2b8\ub9ad\naccuracy = tf.reduce_mean(input_tensor=tf.cast(correct_prediction, tf.float32))","bf727192":"# \ud06c\ub85c\uc2a4\uc5d4\ud2b8\ub85c\ud53c(loss)\ncross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=output_layer,\n                                                    labels=y_true)\n\n# mean\uac12 -> loss\nloss = tf.reduce_mean(input_tensor=cross_entropy)","6f68bc3f":"# learning rate of optimizer\nlearning_rate = (1e-3)*0.30\n\n# train step\ntrain_step = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)","42f96d98":"# lists to store the train loss, validation loss, validation accuracy at each iteration\ntrain_loss = []\nvalid_loss = []\nvalid_acc = []\n\n# batch size\nbatch_size = 255\n# max iteration\nmax_iter = 700","e9d9188c":"# saver: model \uc911\uac04 \uc800\uc7a5\nsaver = tf.compat.v1.train.Saver(max_to_keep=1)\n\n# variables to store the accuracy, loss, iteration of our best model\nbest_accuracy = 0\nbest_loss = 1000000\nbest_iteration = None\n\niteration = 0\n\n# create a graph session and optimize under it\nwith tf.compat.v1.Session() as sess:\n    \n    # initialize variables\n    sess.run(tf.compat.v1.global_variables_initializer())\n\n    # while 57 minutes have not elapsed (to finish before the kernel is killed)\n    while (time.time()-t1) < 3420:\n        \n        # break if max iteration is reached\n        if iteration >= max_iter:\n            break\n\n        # randomly choosing the indices of the batch \n        rand_index = np.random.choice(labels_train.shape[0], size=batch_size)\n\n        # extract the batch image and labels\n        image_rand = image_train[rand_index]\n#         angles_rand = angles_train[rand_index]\n        labels_rand = labels_train[rand_index]\n\n        # feed dictionary for batch\n        feed_dict_batch =  {image: image_rand,\n#                             angle: np.transpose([angles_rand]),\n                            y_true: labels_rand,\n                            keep_prob: 0.7}\n        # feed dictionary for train\n        feed_dict_train =  {image: image_rand,\n#                             angle: np.transpose([angles_rand]),\n                            y_true: labels_rand,\n                            keep_prob: 1.0}\n        # feed dictionary for validation\n        feed_dict_validation =  {image: image_validation,\n#                                  angle: np.transpose([angles_validation]),\n                                 y_true: labels_validation,\n                                 keep_prob: 1.0}\n        \n        # \ucd5c\uc801\ud654 \uc791\uc5c5 \uc885\ub8cc\n        sess.run(train_step, feed_dict=feed_dict_batch)\n\n        # calculate temporary train loss and append it to the designated list\n        temp_train_loss = loss.eval(session=sess, feed_dict=feed_dict_train)\n        train_loss.append(temp_train_loss)\n        # calculate temporary validation loss and append it to the designated list\n        temp_validation_loss = loss.eval(session=sess, feed_dict=feed_dict_validation)\n        valid_loss.append(temp_validation_loss)\n        # calculate temporary validation accuracy and append it to the designated list\n        temp_validation_accuracy = accuracy.eval(session=sess, feed_dict=feed_dict_validation)\n        valid_acc.append(temp_validation_accuracy)\n        \n        #valid loss\uac00 best loss\uc640 \uac19\uace0 accuracy\uac00 best accuracy\ubcf4\ub2e4 \uc88b\uc73c\uba74 best model\uc758 \ud30c\ub77c\ubbf8\ud130 \uac31\uc2e0 \ud6c4 \uc800\uc7a5\n        if (temp_validation_loss == best_loss) and (temp_validation_accuracy > best_accuracy):\n            best_accuracy = temp_validation_accuracy\n            best_loss = temp_validation_loss\n            best_iteration = iteration           \n            saver.save(sess, '.\/my-model', global_step = best_iteration)\n        \n        # valid accuray\uac00 \ub354 \uc88b\uc73c\uba74 best accuracy \uac31\uc2e0\n        if temp_validation_accuracy > best_accuracy:\n            best_accuracy = temp_validation_accuracy\n        \n        # valid loss\uac00 best loss \ubcf4\ub2e4 \uc801\uc73c\uba74 \uc774\ub97c best_loss\uc5d0 \uc800\uc7a5\ud558\uace0 model \uc800\uc7a5.\n        # update the parameters of the best model and save the model\n        if temp_validation_loss < best_loss:\n            best_loss = temp_validation_loss\n            best_iteration = iteration          \n            saver.save(sess, '.\/my-model', global_step = best_iteration)\n\n        # \ud559\uc2b5\ud560 \ub54c\ub9c8\ub2e4 \ucd9c\ub825\ud560 \ubb38\uc7a5\n        print(\"iterations:\",iteration,\n              \"| train_loss:\", temp_train_loss,\n              \"| validation_loss:\", temp_validation_loss,\n              \"| valid_accuracy:\", temp_validation_accuracy)\n        \n        # iteration \uac12 \uc99d\uac00\n        iteration = iteration+1","2c9883fd":"# delete unnecessary variables out of memory\ndel(image_train, image_validation, angles_train, angles_validation, labels_train, labels_validation)","5d6a220f":"with tf.Session() as sess:    \n    \n    # restore the best model\n    model_path = \".\/\"+\"my-model-\"+str(best_iteration)\n    saver.restore(sess, model_path)\n    \n    # break the test set into k folds other wise kernel will be out of memory\n    n = len(iD)\n    k = 12\n    step = n\/\/k\n    \n    # array to store the prediction\n    preds = np.array([])\n\n    # iterate through each fold\n    for i in range(k):\n\n        # start and end indices of the fold\n        start = (step*i)\n        end = (step*(i+1)) \n    \n        # feed dictionary for the fold\n        feed_dict_test =  {image: image_test[start:end],\n#                            angle: np.transpose([angles_test[start:end]]),\n                           keep_prob: 1.0}\n\n        # evaluate predictions of the fold\n        fold_preds = y_pred.eval(session=sess, feed_dict = feed_dict_test)[:,1]\n        # append the predictions of the fold to the designated array\n        preds = np.append(preds, fold_preds)\n    \n    # save the submission csv file\n    submission_path = \".\/submission.csv\"\n    submission = pd.DataFrame({\"id\": iD, \"is_iceberg\": preds})\n    submission.to_csv(submission_path, header = True, index=False)\n    \n    # save the csv file containing performance metrics of the best model \n    results = pd.DataFrame([int(best_iteration),train_loss[best_iteration],\n                            valid_loss[best_iteration], valid_acc[best_iteration]],\n                           index=[\"iteration\", \"train loss\", \"valid loss\", \"accuracy\"],\n                           columns = [\"results\"])    \n    results_path = \".\/results.csv\"    \n    results.to_csv(results_path, header = True, index=True)","65aa872f":"plt.figure(figsize=(16, 8), dpi= 80, facecolor='w', edgecolor='k')\niterations = list(range(1,iteration+1))\nplt.plot(iterations, train_loss, label = \"train loss\")\nplt.plot(iterations, valid_loss, label = \"valid loss\")\nplt.title(\"Loss\")\nplt.xlabel(\"iter\")\nplt.ylabel(\"loss\")\nplt.legend()\nplt.grid()\nplt.show()","8259476e":"## 3. Train \/ Test \/ Validation Set \ub098\ub204\uae30","16fcf343":"# Convolutional Neural Net Tutorial (tensorflow)\n\n\uc6d0\ubb38: https:\/\/www.kaggle.com\/itratrahman\/convolutional-neural-net-tutorial-tensorflow  \n\ud574\ub2f9 Notebook\uc758 \ud55c\uad6d\uc5b4 \ud574\uc11d\ubcf8\uc785\ub2c8\ub2e4. \uc8fc\uc11d\uc744 \ub2ec\uc544\uc11c \ud574\uc11d\uc744 \ud588\uc2b5\ub2c8\ub2e4.","4637a2f2":"## 5. band1\uacfc band2\ub370\uc774\ud130\ub97c \ud569\uce58\uace0 \uc774\ub97c 3D image\ub85c \ubcc0\ud658\ud558\uae30","f3aa93e6":"### 6.5 \uc608\uce21 & \uc815\ud655\ub3c4 \uba54\ud2b8\ub9ad \uc0dd\uc131","c4c86aeb":"### \uc99d\uac15 \ud14c\ud06c\ub2c9\uc744 \uac00\uc838\uc624\ub294 \ud568\uc218 \uc0dd\uc131","12467b04":"### 4.2 \uc99d\uac15\ub41c \uc0d8\ud50c \uc0b4\ud3b4\ubcf4\uae30","450d0066":"## 2. Feature Engineering","ab297f0f":"### 6.4 ConvNet\uc758 \uce35 \ub9cc\ub4e4\uae30","a3bd4cde":"## 4. Train set Augmenting(\uc99d\uac15)","2978b334":"## 6. CNN \ub9cc\ub4e4\uae30","9fb5a902":"### 2.3 \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc5d0 \ub300\ud558\uc5ec FE","5150c4cd":"### 4.3 Train set\uc5d0 \ub300\ud574 \uc99d\uac15 \uae30\ubc95 \uc2dc\ud589","419d6aed":"### 6.3 \ub525\ub7ec\ub2dd \ub808\uc774\uc5b4\ub97c \ub9cc\ub4e4\uae30 \uc704\ud55c \ud568\uc218 \uc0dd\uc131","c9db4969":"#### 3\uac00\uc9c0 \uc815\uaddc\ud654 \ud14c\ud06c\ub2c9 \uc0ac\uc6a9","baa50ecd":"### 6.6 Optimizer \ub9cc\ub4e4\uae30","6fb83a0c":"## \ub370\uc774\ud130 \ub85c\ub4dc \ubc0f \ub370\uc774\ud130 \ud655\uc778 (Load and Inspect the Data)","151f59e3":"### 2.1 Train Set\uc5d0 \ub300\ud55c FE","5ba2d334":"## 7. \ubaa8\ub378 \ud6c8\ub828"}}