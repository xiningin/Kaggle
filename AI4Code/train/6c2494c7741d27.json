{"cell_type":{"92497f3f":"code","b325ceb6":"code","98d14b63":"code","2915240e":"code","9d79d724":"code","030049d6":"code","8f318eb3":"code","32486b96":"code","66c44267":"code","acc108cf":"code","aa0fec16":"code","84dd5bea":"code","00063201":"code","fa09108c":"code","538b4f66":"code","995cddae":"code","928edc89":"code","6eb626a9":"code","8e999753":"code","6e045e57":"code","65da1bb8":"code","7cc44a3c":"code","497a4658":"code","e1795c49":"code","10641ac9":"code","23973662":"code","793190ea":"code","c8b6da0a":"code","39ac7ca0":"code","58cc50c2":"code","a2c7946a":"code","d03fad57":"code","4784f3ff":"code","da884154":"code","a019cea2":"code","f4de1e01":"code","961f832c":"code","120b1c4d":"code","5f3d97c6":"code","93b1fe50":"code","7aee42a4":"markdown","14913606":"markdown","c82e4bba":"markdown","8d8a4e8a":"markdown","f2ce3e07":"markdown","2a4e5ae6":"markdown"},"source":{"92497f3f":"import numpy as np \nimport pandas as pd \n\n# text processing libraries\nimport re\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\n\n# XGBoost\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\n\n# sklearn \nfrom sklearn import model_selection\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import f1_score\nfrom sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\nfrom sklearn.model_selection import GridSearchCV,StratifiedKFold,RandomizedSearchCV\n\n# matplotlib and seaborn for plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# File system manangement\nimport os\n\n# Suppress warnings \nimport warnings\nwarnings.filterwarnings('ignore')\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","b325ceb6":"\nimport cufflinks as cf #importing plotly and cufflinks in offline mode  \nimport plotly.offline  \ncf.go_offline()  \ncf.set_config_file(offline=False, world_readable=True)","98d14b63":"import re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer","2915240e":"train_df=pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')\ntest_df=pd.read_csv('\/kaggle\/input\/nlp-getting-started\/test.csv')","9d79d724":"train_df.head()","030049d6":"test_df.head()","8f318eb3":"print(train_df.shape)\nprint(test_df.shape)","32486b96":"from pandas_profiling import ProfileReport\nprofile = ProfileReport(train_df, title='Pandas Profiling Report', html={'style':{'full_width':True}})","66c44267":"profile","acc108cf":"location = train_df['location'].value_counts()[:20]\nlocation.iplot(kind='bar', xTitle='Number of Location', title=\"Location's In The Given Data Set\")","aa0fec16":"target = train_df['target'].value_counts()\ntarget.iplot(kind='bar', title=\"Disaster or Not Distribution\")","84dd5bea":"# A disaster tweet\ndisaster_tweets = train_df[train_df['target']==1]['text']\ndisaster_tweets.values[1]","00063201":"# A Non disaster tweet\ndisaster_tweets = train_df[train_df['target']==0]['text']\ndisaster_tweets.values[1]","fa09108c":"def clean_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?:\/\/\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text","538b4f66":"train_df['text'] = train_df['text'].apply(lambda x: clean_text(x))\ntest_df['text'] = test_df['text'].apply(lambda x : clean_text(x))","995cddae":"train_df['text'].head()","928edc89":"test_df['text'].head()","6eb626a9":"tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\ntrain_df['text'] = train_df['text'].apply(lambda x: tokenizer.tokenize(x))\ntest_df['text'] = test_df['text'].apply(lambda x: tokenizer.tokenize(x))","8e999753":"train_df['text'].head()","6e045e57":"test_df['text'].head()","65da1bb8":"def remove_stopwords(text):\n    \"\"\"\n    Removing stopwords belonging to english language\n    \n    \"\"\"\n    words = [w for w in text if w not in stopwords.words('english')]\n    return words\n\ntrain_df['text'] = train_df['text'].apply(lambda x : remove_stopwords(x))\ntest_df['text'] = test_df['text'].apply(lambda x : remove_stopwords(x))","7cc44a3c":"train_df['text'].head()","497a4658":"test_df['text'].head()","e1795c49":"def combine_text(list_of_text):\n    '''Takes a list of text and combines them into one large chunk of text.'''\n    combined_text = ' '.join(list_of_text)\n    return combined_text\n\ntrain_df['text'] = train_df['text'].apply(lambda x : combine_text(x))\ntest_df['text'] = test_df['text'].apply(lambda x : combine_text(x))","10641ac9":"train_df.head()","23973662":"test_df.head()","793190ea":"def text_preprocessing(text):\n    \"\"\"\n    Cleaning and parsing the text.\n\n    \"\"\"\n    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n    \n    nopunc = clean_text(text)\n    tokenized_text = tokenizer.tokenize(nopunc)\n    remove_stopwords = [w for w in tokenized_text if w not in stopwords.words('english')]\n    combined_text = ' '.join(remove_stopwords)\n    return combined_text","c8b6da0a":"count_vectorizer = CountVectorizer()\ntrain_df_vectors = count_vectorizer.fit_transform(train_df['text'])\ntest_df_vectors = count_vectorizer.transform(test_df[\"text\"])\n\n## Keeping only non-zero elements to preserve space \nprint(train_df_vectors[0].todense())","39ac7ca0":"# TFIDF Features (Term Frequency-Inverse Document Frequency, or TF-IDF for short)\n\ntfidf = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1, 2))\ntrain_df_tfidf = tfidf.fit_transform(train_df['text'])\ntest_df_tfidf = tfidf.transform(test_df[\"text\"])","58cc50c2":"# Fitting a simple Logistic Regression on Counts\nclf = LogisticRegression(C=1.0)\nscores = model_selection.cross_val_score(clf, train_df_vectors, train_df[\"target\"], cv=5, scoring=\"f1\")\nscores","a2c7946a":"clf.fit(train_df_vectors, train_df[\"target\"])","d03fad57":"# Fitting a simple Logistic Regression on TFIDF\n\nclf_tfidf = LogisticRegression(C=1.0)\nscores = model_selection.cross_val_score(clf_tfidf, train_df_tfidf, train_df[\"target\"], cv=5, scoring=\"f1\")\nscores","4784f3ff":"# Fitting a simple Naive Bayes on Counts\n\nclf_NB = MultinomialNB()\nscores = model_selection.cross_val_score(clf_NB, train_df_vectors, train_df[\"target\"], cv=5, scoring=\"f1\")\nscores","da884154":"clf_NB.fit(train_df_vectors, train_df[\"target\"])","a019cea2":"# Fitting a simple Naive Bayes on TFIDF\n\nclf_NB_TFIDF = MultinomialNB()\nscores = model_selection.cross_val_score(clf_NB_TFIDF, train_df_tfidf, train_df[\"target\"], cv=5, scoring=\"f1\")\nscores","f4de1e01":"clf_NB_TFIDF.fit(train_df_tfidf, train_df[\"target\"])","961f832c":"import xgboost as xgb\nclf_xgb = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n                        subsample=0.8, nthread=10, learning_rate=0.1)\nscores = model_selection.cross_val_score(clf_xgb, train_df_vectors, train_df[\"target\"], cv=5, scoring=\"f1\")\nscores","120b1c4d":"import xgboost as xgb\nclf_xgb_TFIDF = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n                        subsample=0.8, nthread=10, learning_rate=0.1)\nscores = model_selection.cross_val_score(clf_xgb_TFIDF, train_df_tfidf, train_df[\"target\"], cv=5, scoring=\"f1\")\nscores","5f3d97c6":"def submission(submission_file_path,model,test_vectors):\n    sample_submission = pd.read_csv(submission_file_path)\n    sample_submission[\"target\"] = model.predict(test_df_vectors)\n    sample_submission.to_csv(\"submission.csv\", index=False)","93b1fe50":"submission_file_path = \"..\/input\/nlp-getting-started\/sample_submission.csv\"\ntest_df_vectors=test_df_tfidf\nsubmission(submission_file_path,clf_NB_TFIDF,test_df_vectors)","7aee42a4":"Building Model ","14913606":"**Profiling** is a process that helps us in understanding our data and PandasProfiling is python package which does exactly that. It is a simple and fast way to perform exploratory data analysis of a Pandas Dataframe. The pandas **df.describe()** and **df.info()** functions are normally used as a first step in the EDA process. However, it only gives a very basic overview of the data and doesn\u2019t help much in the case of large data sets. The Pandas Profiling function, on the other hand, extends the pandas DataFrame with **df.profile_report()** for quick data analysis. It displays a lot of information with a single line of code and that too in an interactive **HTML** report","c82e4bba":"XGBoost","8d8a4e8a":"**Train data set and Test data set**\n","f2ce3e07":"Bag of words","2a4e5ae6":"Making the submission"}}