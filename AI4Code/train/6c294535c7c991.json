{"cell_type":{"0ba4c342":"code","b0f1b8d4":"code","5681b08d":"code","232b6fdb":"code","aa90b3ec":"code","c57a5eae":"code","1713425e":"code","61d5b3c9":"code","a80f124c":"code","e4986e1f":"code","f914d8e9":"code","180fb55e":"code","5d946e74":"code","88ed15a0":"code","3d13c086":"code","2f7b64cc":"markdown","ec172397":"markdown","2aa473e3":"markdown"},"source":{"0ba4c342":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b0f1b8d4":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split, PredefinedSplit, GridSearchCV, cross_validate\nimport category_encoders as ce\n\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n\nimport lightgbm as lgb","5681b08d":"df = pd.read_csv('\/kaggle\/input\/talkingdata-adtracking-fraud-detection\/train_sample.csv')\nprint('This data frame has %d rows and %d columns.' % (df.shape[0], df.shape[1]))","232b6fdb":"df.head(5)","aa90b3ec":"pd.set_option('precision', 2)\ndf.describe()","c57a5eae":"counts = df['is_attributed'].value_counts()\nfraud = counts[0]\nclick = counts[1]\ntot = click+fraud\nprint('There are %d fraudulent clicks (%.2f%%) and %d normal clicks (%.2f%%)' % (fraud, fraud\/tot*100, click, click\/tot*100))\n\ncat_features = ['ip', 'app', 'device', 'os', 'channel']\navg_count = dict()\nfor col in cat_features:\n  n = len(df[col].value_counts())\n  avg_count[col] = tot \/\/ n\n  print('There are %d %s among %d examples, average count : %d.' % (n, col, tot, avg_count[col]))","1713425e":"df.isnull().sum()","61d5b3c9":"# only normal clicks has a valid attributed_time, this feature is dropped\ndf.drop(columns=['attributed_time'], inplace=True)\n# encode click time\ndf['click_time'] = pd.to_datetime(df['click_time'])\ndf['click_day'] = df['click_time'].dt.day.astype('uint8')\ndf['click_hr'] = df['click_time'].dt.hour.astype('uint8')\ndf['click_min'] = df['click_time'].dt.minute.astype('uint8')\ndf['click_sec'] = df['click_time'].dt.second.astype('uint8')\n\ndf.drop(columns=['click_time'], inplace=True)\n# train validate split\nx = df.drop('is_attributed', axis=1)\ny = df['is_attributed']\nx_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, stratify=y, random_state=2021)\ntrain = pd.concat([x_train, y_train], axis=1)\nval = pd.concat([x_val, y_val], axis=1)\ntrain.hist(figsize=(10,10))\nplt.show()\nsns.heatmap(train.corr(), vmin=-1, vmax=1, center= 0, cmap= 'coolwarm')\nplt.show()","a80f124c":"# load test\ntest = pd.read_csv('\/kaggle\/input\/talkingdata-adtracking-fraud-detection\/test.csv')\ntest['click_time'] = pd.to_datetime(test['click_time'])\ntest['click_day'] = test['click_time'].dt.day.astype('uint8')\ntest['click_hr'] = test['click_time'].dt.hour.astype('uint8')\ntest['click_min'] = test['click_time'].dt.minute.astype('uint8')\ntest['click_sec'] = test['click_time'].dt.second.astype('uint8')\n\ntest.drop(columns=['click_time'], inplace=True)","e4986e1f":"# count encoder\ncount_encode = ce.CountEncoder(cols=cat_features, handle_unknown=avg_count)\ncount_encode.fit(train[cat_features])\ntrain = train.join(count_encode.transform(train[cat_features]).add_suffix('_cnt'))\nval = val.join(count_encode.transform(val[cat_features]).add_suffix('_cnt'))\ntest = test.join(count_encode.transform(test[cat_features]).add_suffix('_cnt'))\n# target encoder\ntarget_encode = ce.TargetEncoder(cols=cat_features, handle_unknown='value')\ntarget_encode.fit(train[cat_features], train['is_attributed'])\ntrain = train.join(target_encode.transform(train[cat_features]).add_suffix('_target'))\nval = val.join(target_encode.transform(val[cat_features]).add_suffix('_target'))\ntest = test.join(target_encode.transform(test[cat_features]).add_suffix('_target'))","f914d8e9":"features = ['ip_cnt', 'app_cnt','device_cnt', 'os_cnt', 'channel_cnt', 'ip_target', 'app_target',\n       'device_target', 'os_target', 'channel_target', 'click_day', 'click_hr', 'click_min', 'click_sec']\nfig, axs = plt.subplots(2, 7, figsize=(21,6))\nfor i, ax1 in enumerate(axs):\n    for j, ax in enumerate(ax1):\n        f = features[i*7+j]\n        train.groupby('is_attributed')[f].plot(kind='hist', alpha=0.3, legend=True, ax=ax)\n        ax.set_xlabel(f)\nfig.tight_layout(pad=2)","180fb55e":"train2 = train[features+['is_attributed']]\nsns.heatmap(train2.corr(), vmin=-1, vmax=1, center= 0, cmap= 'coolwarm')\nplt.show()","5d946e74":"clf = DecisionTreeClassifier(class_weight={0:1, 1:400}, max_depth=2, min_samples_split=2000)\nfeat = ['ip_cnt', 'app_cnt', 'device_cnt', 'os_cnt', 'channel_cnt', 'ip_target', 'app_target','device_target', 'os_target', 'channel_target', 'click_day', 'click_hr','click_min', 'click_sec']\nx_train  = train[feat]\ny_train = train['is_attributed']\nclf.fit(x_train, y_train)\ntree.plot_tree(clf, feature_names=feat)\nplt.show()","88ed15a0":"x_test = test[feat]\nresult = test.loc[:, ['click_id']]\nresult['is_attributed'] = clf.predict(x_test)\nresult.to_csv('sample_wdt_ce.csv', index=False)","3d13c086":"!kaggle competitions submit -c talkingdata-adtracking-fraud-detection -f sample_wdt_ce.csv -m \"train wdt with sample data\"","2f7b64cc":"# Train with weighted decision tree","ec172397":"## encode categorical features","2aa473e3":"# Load, clean and visualize data"}}