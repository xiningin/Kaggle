{"cell_type":{"2ba98e78":"code","e5980b15":"code","02009728":"code","9b173e51":"markdown","411b0266":"markdown","4bbfd04b":"markdown"},"source":{"2ba98e78":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\naws_id = user_secrets.get_secret(\"aws_access_key_id\")\naws_key = user_secrets.get_secret(\"aws_secret_access_key\")\naws_region = user_secrets.get_secret(\"aws_region\")\n\n#If the Secrets Add-on works properly, we will see the current region here\n# By the way, we do not need a region, because S3 allows us to create Global buckets too\n\naws_region","e5980b15":"import boto3\nimport uuid\nimport os\n\ns3 = boto3.resource(\n    's3',\n    aws_access_key_id=aws_id,\n    aws_secret_access_key=aws_key,\n)\n\ns3_client = boto3.client(\n    's3',\n    aws_access_key_id=aws_id,\n    aws_secret_access_key=aws_key,\n)\nbucket_name = ''.join(['kaggle2021', str(uuid.uuid4())])\nbucket_response = s3_client.create_bucket(Bucket=bucket_name)\n\nresponse = s3_client.list_buckets()\n\n# Output the bucket names\n#print('Existing buckets:')\n#for bucket in response['Buckets']:\n#    print(f'  {bucket[\"Name\"]}')\n\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/'):\n    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n        file_name = os.path.join(dirname, filename)\n        response = s3_client.upload_file(file_name, bucket_name, filename)\n\n# Let us get some feedback: the list of the objects of our Bucket is very verbose and we can\n# check that everything is OK\n\ns3_client.list_objects_v2(Bucket=bucket_name)","02009728":"# Finally, we will delete the bucket to let everything as it was before\n\nbucket = s3.Bucket(bucket_name)\n# suggested by Jordon Philips \nbucket.objects.all().delete()\ns3_client.delete_bucket(Bucket=bucket_name)","9b173e51":"After running the notebook, the S3 bucket will look like this:","411b0266":"\n\n# Boto3 S3 access demo\nIt is interesting to try and get access to any of the services from AWS. In this case, we use boto3 to store some local files into an S3 bucket. The requirement to run this demo is to have credentials of an AWS account with S3 Access. We usually would store these credentials in a local file, but we have tried the Kaggle Secrets Add-on to see if it works.\n\nIf you fork this notebook, you will have to provide your keys in the Kaggle Secrets Add-on menu. Of course, you will have to toggle on the Internet option in the Settings menu to access AWS. We use a simple dataset named \"txisteak\", but you could try anything you want.\n\nMore info at this links:\n\nAWS S3 storage service: https:\/\/aws.amazon.com\/s3\/\n\nAWS boto3 library: https:\/\/aws.amazon.com\/sdk-for-python\/\n\nFeature launch: User secrets | Kaggle: https:\/\/www.kaggle.com\/product-feedback\/114053\n\n\"Txisteak\" dataset: https:\/\/www.kaggle.com\/aitzolezeizaramos\/txisteak\/\n","4bbfd04b":"![S3%20bucket%20contents.png](attachment:S3%20bucket%20contents.png)"}}