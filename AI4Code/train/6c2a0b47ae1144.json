{"cell_type":{"43e9b1f5":"code","cde7108b":"code","318e776c":"code","5567304b":"code","2b9057b2":"code","4cf73c21":"code","ac8a79ba":"code","976eb83b":"code","b2b199c3":"code","d8aded6e":"code","9387905a":"code","34dd6ab1":"code","60b715b1":"code","ba285b32":"code","62a50752":"code","79c7a96c":"code","4c4bf742":"code","c9d66496":"code","5d660871":"code","180ba630":"code","33ece1f1":"code","76402943":"code","f76a8732":"code","7d60de8d":"code","79d4f353":"code","ea4bcadd":"code","f4862afa":"code","b6a64936":"code","ced02ac7":"code","f1ad741c":"code","b5150d04":"code","8f24d87e":"code","13cf86c8":"code","5a27d8da":"code","a3cdde0b":"code","47d98601":"code","d68978ad":"code","909bfa09":"code","2b0a7b55":"code","4ab77989":"markdown"},"source":{"43e9b1f5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cde7108b":"df_train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/titanic\/test.csv\")","318e776c":"df_train.head()","5567304b":"df_train.shape\n","2b9057b2":"df_test.shape","4cf73c21":"df_test.head()","ac8a79ba":"df_train.info()","976eb83b":"train_df = df_train[[\"PassengerId\",\"Survived\",\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Ticket\",\"Fare\",\"Cabin\",\"Embarked\"]]\ntest_df = df_test[[\"PassengerId\",\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Ticket\",\"Fare\",\"Cabin\",\"Embarked\"]]","b2b199c3":"train_df.isnull().sum()","d8aded6e":"train_df.drop(\"Cabin\", inplace = True, axis = 1)\ntest_df.drop(\"Cabin\", inplace = True, axis = 1)\ntrain_df","9387905a":"train_df.drop(\"Ticket\", inplace = True, axis = 1)\ntest_df.drop(\"Ticket\", inplace = True, axis = 1)\ntrain_df","34dd6ab1":"train_df.groupby(\"Embarked\").size()","60b715b1":"def function(x):\n    if (x[\"Embarked\"] == \"C\"):\n        return int(1)\n    elif(x[\"Embarked\"] == \"Q\"):\n        return int(2)\n    elif(x[\"Embarked\"] == \"S\"):\n        return int(3)\ntrain_df1 = train_df.apply(function, axis = 1)\ntest_df1 = test_df.apply(function,axis = 1)","ba285b32":"train_df[\"Embarked\"] = train_df1\ntest_df[\"Embarked\"] = test_df1","62a50752":"train_df.head()","79c7a96c":"train_df[\"Age\"] = train_df[\"Age\"].fillna(train_df[\"Age\"].mean())\ntest_df[\"Age\"] = test_df[\"Age\"].fillna(test_df[\"Age\"].mean())\ntrain_df[\"Age\"] = train_df[\"Age\"].astype(int)\ntrain_df.shape","4c4bf742":"test_df.head()","c9d66496":"test_df.shape","5d660871":"test_df.isnull().sum()","180ba630":"train_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(train_df[\"Embarked\"].mean())\ntest_df[\"Fare\"] = test_df[\"Fare\"].fillna(test_df[\"Fare\"].mean())","33ece1f1":"train_df.info()\ntest_df.info()","76402943":"train_df.describe()","f76a8732":"def function(x):\n    if (x[\"Sex\"] == \"male\"):\n        return int(0)\n    elif(x[\"Sex\"] == \"female\"):\n        return int(1)\n   \ntrain_df2 = train_df.apply(function, axis = 1)\ntest_df2 = test_df.apply(function,axis = 1)\ntrain_df[\"Sex\"] = train_df2\ntest_df[\"Sex\"] = test_df2\ntrain_df.head()","7d60de8d":"test_df.head()","79d4f353":"x = train_df[[\"PassengerId\",\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Embarked\"]]\ny = train_df[\"Survived\"]","ea4bcadd":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error","f4862afa":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 0)\nx_train.info()","b6a64936":"def get_mae(max_leaf_nodes, x_train, x_test, y_train, y_test):\n    model = DecisionTreeRegressor(max_leaf_nodes= max_leaf_nodes , random_state=0)\n    model.fit(x_train, y_train,)\n    preds_val = model.predict(x_test)\n    mae = mean_absolute_error(y_test, preds_val)\n    r_square = (round(r2_score(y_test,preds_val)*100, 2))\n    return mae, r_square\n","ced02ac7":"for max_leaf_nodes in [5, 50, 500, 5000]:\n    my_mae, r_square = get_mae(max_leaf_nodes, x_train, x_test, y_train, y_test)\n    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d \\t\\t R-squared:  %d\" %(max_leaf_nodes, my_mae, r_square))","f1ad741c":"model = DecisionTreeRegressor(max_leaf_nodes= 5 , random_state=0)\nmodel.fit(x_train, y_train,)\npreds_val = model.predict(x_test)\nmae = mean_absolute_error(y_test, preds_val)\nprint(\"mae = \",mae, \"accuracy score = \" , model.score(x_test,y_test)*100)","b5150d04":"linear = LinearRegression()\nlinear.fit(x_train,y_train)","8f24d87e":"predict = linear.predict(x_test)\nmae = mean_absolute_error(y_test, predict)\nr_squared = (round(r2_score(y_test, predict)*100, 2))\nprint(\"mean squared error: \", mae, \"r_square: \", r_squared )\nprint(\"accuracy score = \", linear.score(x_test, y_test)*100)","13cf86c8":"logistic = LogisticRegression(max_iter = 10000)\nlogistic.fit(x_train,y_train)","5a27d8da":"predicted = logistic.predict(x_test)\nmae = mean_absolute_error(y_test, predicted)\nr_squared = (round(r2_score(y_test, predicted)*100, 2))\nprint(\"mean squared error: \", mae, \"r_square: \", r_squared )\nprint(\"accuracy score = \", logistic.score(x_test, y_test)*100)","a3cdde0b":"forest_model = RandomForestRegressor(random_state=16)\nforest_model.fit(x_train, y_train)\npreds = forest_model.predict(x_test)\nmae = mean_absolute_error(y_test, preds)\nr_squared = (round(r2_score(y_test, preds)*100, 2))\nprint(\"mean squared error: \", mae, \"r_square: \", r_squared )\nprint(\"accuracy score = \", forest_model.score(x_test, y_test)*100)\n","47d98601":"model2= GaussianNB(var_smoothing=1e-08)\nmodel2.fit(x_train, y_train)\nY_pred= model2.predict(x_test)\nmodel2.score(x_test, y_test)","d68978ad":"logistic_model = LogisticRegression(max_iter = 10000)\nlogistic_model.fit(x,y)","909bfa09":"predicted_values = logistic_model.predict(test_df)","2b0a7b55":"final_data = {'PassengerId': test_df.PassengerId, 'Survived': predicted_values}\nfinal_submission = pd.DataFrame(data=final_data)\nfinal_submission.to_csv('submission_file.csv',index =False)\n","4ab77989":"Training the Model (Since logistic regression has the highest accuracy. thus we are going to fit logistic regression model)"}}