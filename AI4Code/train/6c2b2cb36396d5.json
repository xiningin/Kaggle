{"cell_type":{"40351d44":"code","eed0aadc":"code","ad12344e":"code","5c3aec34":"code","020be87f":"code","365c19a6":"code","7d2427d4":"code","4b408ec8":"code","b99dc55d":"code","0f6f74bb":"code","5befc1c6":"code","3d8478f3":"code","d72587ae":"code","8d3b09fb":"code","20b36b54":"code","9b751a5e":"code","598e7c0c":"code","49b0717d":"code","f9bded11":"code","795fa82a":"code","049fe997":"code","e092aecc":"code","3cf56fb3":"code","d253b8cb":"code","e7c498f7":"code","4f667c68":"code","e7be93ad":"code","384eb9e1":"code","173eb5b8":"code","7567a243":"code","9449e7c9":"code","54851057":"code","193741be":"code","5908164d":"markdown","1560c347":"markdown","837d2c40":"markdown","fe64b7be":"markdown","ba57cd04":"markdown","33956409":"markdown","c7312152":"markdown","260c15a4":"markdown","e43edb7d":"markdown","80e8063b":"markdown","8e942ae3":"markdown","98d9eb1d":"markdown","1938b797":"markdown","694be259":"markdown","296fe674":"markdown","47e6c94a":"markdown","11668df8":"markdown","79d7709c":"markdown","7a261e2b":"markdown","3c6267e4":"markdown","149a70ef":"markdown","d1c14c10":"markdown","ed693d9c":"markdown","a3c49f01":"markdown","077a0cb7":"markdown","ae46641d":"markdown","264aa38f":"markdown","0d2fe6e8":"markdown","624a776e":"markdown","3a7f561f":"markdown","37d5e820":"markdown","dcfdbcec":"markdown","adbee4c8":"markdown","1ce723ed":"markdown","b233b0bd":"markdown","37d68df8":"markdown","dfe08eaa":"markdown","981c1611":"markdown","6ffb8a98":"markdown","d929bb8b":"markdown"},"source":{"40351d44":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","eed0aadc":"# Download image and class labels\n!wget https:\/\/raw.githubusercontent.com\/lukemelas\/EfficientNet-PyTorch\/master\/examples\/simple\/img.jpg\n!wget https:\/\/raw.githubusercontent.com\/lukemelas\/EfficientNet-PyTorch\/master\/examples\/simple\/labels_map.txt\n# Get EfficientNet PyTorch\n!pip install efficientnet_pytorch","ad12344e":"import sys\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom torch import optim\n\nimport torchvision.transforms as transforms\nimport torchvision\n\nfrom fastprogress import master_bar, progress_bar\n\nfrom PIL import Image","5c3aec34":"data = pd.read_csv(\"..\/input\/vietai-advance-course-retinal-disease-detection\/train.csv\")\ndata.head()","020be87f":"for label in data.columns[1:]:\n    print(\"Distribution of\", label)\n    print(data[label].value_counts())","365c19a6":"LABELS = data.columns[1:]\ndef build_label(row):\n    return \",\".join([LABELS[idx] for idx, val in enumerate(row[1:]) if val == 1])\n        \ndata.apply(lambda x: build_label(x), axis=1).value_counts()","7d2427d4":"len(LABELS)","4b408ec8":"train_data, val_data = train_test_split(data, test_size=0.2, random_state=2019)","b99dc55d":"IMAGE_SIZE = 224                              # Image size (224x224)\nIMAGENET_MEAN = [0.485, 0.456, 0.406]         # Mean of ImageNet dataset (used for normalization)\nIMAGENET_STD = [0.229, 0.224, 0.225]          # Std of ImageNet dataset (used for normalization)\nBATCH_SIZE = 128                              \nLEARNING_RATE = 0.001\nLEARNING_RATE_SCHEDULE_FACTOR = 0.1           # Parameter used for reducing learning rate\nLEARNING_RATE_SCHEDULE_PATIENCE = 4           # Parameter used for reducing learning rate\nMAX_EPOCHS = 50                              # Maximum number of training epochs\n\n\n############\nUSE_BCELOGIT = True\nUSE_NOTNORMAL_P = False\nUSE_AUGMENTATION = True\nUSE_WEIGHT = True\nMIXUP = True\n\n# LOSS WEIGHT\npos_w = None\nw = None\nif USE_WEIGHT:\n    pos_w=[1.3, 1.6, 4, 5.6, 5.2, 6, 5.6]\n    w = [3., 1, 1, 1, 1,1, 1]\n\n","0f6f74bb":"!pip install albumentations > \/dev\/null","5befc1c6":"\nfrom albumentations import (\n    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, RandomBrightnessContrast, IAAPiecewiseAffine,\n    IAASharpen, IAAEmboss, Flip, OneOf, Compose, Resize, GaussianBlur, Normalize\n)\nfrom albumentations.pytorch import ToTensor\ntrain_aug = Compose([\n    Resize(IMAGE_SIZE, IMAGE_SIZE),\n    ShiftScaleRotate(shift_limit=(-0.3, 0.3), scale_limit=0.3, rotate_limit=30, p=0.6),\n    HorizontalFlip(p=0.5),\n\n    Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n    ToTensor()\n    \n])\nval_aug = Compose([\n    Resize(IMAGE_SIZE, IMAGE_SIZE),\n    Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n    ToTensor()\n\n])","3d8478f3":"class FundusDataset(Dataset):\n    \n    def __init__(self, folder_dir, dataframe, image_size, normalization, is_train=False):\n        \"\"\"\n        Init Dataset\n        \n        Parameters\n        ----------\n        folder_dir: str\n            folder contains all images\n        dataframe: pandas.DataFrame\n            dataframe contains all information of images\n        image_size: int\n            image size to rescale\n        normalization: bool\n            whether applying normalization with mean and std from ImageNet or not\n        \"\"\"\n        self.image_paths = [] # List of image paths\n        self.image_labels = [] # List of image labels\n        self.is_train = is_train\n        # Define list of image transformations\n        image_transformation = [\n            transforms.Resize((image_size, image_size))\n        ]\n        \n        if is_train:\n            image_transformation.append(\n                torchvision.transforms.RandomAffine(30, translate=(0.1, 0.2), scale=(0.8, 1.2))\n            )\n            image_transformation.append(\n                torchvision.transforms.RandomHorizontalFlip(p=0.5)\n            )\n        \n        image_transformation.append(transforms.ToTensor())\n        if normalization:\n            # Normalization with mean and std from ImageNet\n            image_transformation.append(transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD))\n        \n        #self.image_transformation = transforms.Compose(image_transformation)\n        \n        if self.is_train:\n            self.image_transformation = train_aug\n        else:\n            self.image_transformation = val_aug\n        \n        # Get all image paths and image labels from dataframe\n        for index, row in dataframe.iterrows():\n            image_path = os.path.join(folder_dir, row.filename)\n            self.image_paths.append(image_path)\n            self.image_labels.append(row[1:])\n    \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, index):\n        \"\"\"\n        Read image at index and convert to torch Tensor\n        \"\"\"\n        \n        # Read image\n        image_path = self.image_paths[index]\n        image_data = Image.open(image_path).convert(\"RGB\") # Convert image to RGB channels\n        \n        # TODO: Image augmentation code would be placed here\n\n        # Resize and convert image to torch tensor \n        #image_data = self.image_transformation(image_data)\n        \n        image_data = np.array(image_data)\n        image_data = self.image_transformation(image=image_data)['image']\n        \n        return image_data, torch.FloatTensor(self.image_labels[index])","d72587ae":"train_dataset = FundusDataset(\"..\/input\/cleandata-vietai-caothang\/cleaned_data\/cleaned_data\/train\", train_data, IMAGE_SIZE, True, USE_AUGMENTATION)","8d3b09fb":"train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)","20b36b54":"for data, label in train_dataloader:\n    print(data.size())\n    print(label.size())\n    break","9b751a5e":"val_dataset = FundusDataset(\"..\/input\/cleandata-vietai-caothang\/cleaned_data\/cleaned_data\/train\", val_data, IMAGE_SIZE, True)\nval_dataloader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)","598e7c0c":"class ResNet50(nn.Module):\n    def __init__(self, num_classes, is_trained=True):\n        \"\"\"\n        Init model architecture\n        \n        Parameters\n        ----------\n        num_classes: int\n            number of classes\n        is_trained: bool\n            whether using pretrained model from ImageNet or not\n        \"\"\"\n        super().__init__()\n        \n        # Load the resnet50 from ImageNet\n        self.net = torchvision.models.resnet50(pretrained=is_trained)\n        \n        # Get the input dimension of last layer\n        kernel_count = self.net.fc.in_features\n        \n        # Replace last layer with new layer that have num_classes nodes, after that apply Sigmoid to the output\n        if not USE_BCELOGIT:\n            self.net.fc = nn.Sequential(nn.Linear(kernel_count, num_classes)\n                                       ,nn.Sigmoid()\n                                       )\n        else:\n            self.net.fc = nn.Sequential(nn.Linear(kernel_count, num_classes)\n                                       #,nn.Sigmoid()\n                                       )\n        \n    def forward(self, inputs):\n        \"\"\"\n        Forward the netword with the inputs\n        \"\"\"\n        output = self.net(inputs)\n        if USE_NOTNORMAL_P:\n            not_normal_p = 1 - output[:, 0:1]\n            output = torch.cat([output[:, 0:1], output[:, 1:] * not_normal_p], dim=1)\n        return output","49b0717d":"## Efficient net\nfrom efficientnet_pytorch import EfficientNet\nmodel_name = 'efficientnet-b0'\n\nclass EffNet(nn.Module):\n    def __init__(self, num_classes, is_trained=True):\n        \"\"\"\n        Init model architecture\n        \n        Parameters\n        ----------\n        num_classes: int\n            number of classes\n        is_trained: bool\n            whether using pretrained model from ImageNet or not\n        \"\"\"\n        super().__init__()\n        \n        # Load the resnet50 from ImageNet\n        self.net = EfficientNet.from_pretrained(model_name)\n\n        \n        # Get the input dimension of last layer\n        kernel_count = self.net._fc.in_features\n        \n        # Replace last layer with new layer that have num_classes nodes, after that apply Sigmoid to the output\n        if not USE_BCELOGIT:\n            self.net._fc = nn.Sequential(nn.Linear(kernel_count, num_classes)\n                                       ,nn.Sigmoid()\n                                       )\n        else:\n            self.net._fc = nn.Sequential(nn.Linear(kernel_count, num_classes)\n                                       #,nn.Sigmoid()\n                                       )\n        \n    def forward(self, inputs):\n        \"\"\"\n        Forward the netword with the inputs\n        \"\"\"\n        output = self.net(inputs)\n        if USE_NOTNORMAL_P:\n            not_normal_p = 1 - output[:, 0:1]\n            output = torch.cat([output[:, 0:1], output[:, 1:] * not_normal_p], dim=1)\n        return output","f9bded11":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","795fa82a":"model = EffNet(num_classes=len(LABELS)).to(device)\nmodel","049fe997":"sum(p.numel() for p in model.parameters() if p.requires_grad)","e092aecc":"# Loss function\nif pos_w is not None:\n    pos_w = torch.tensor(pos_w, device=device)\nif w is not None:\n    w = torch.tensor(w, device=device)\n\nif USE_BCELOGIT:\n    loss_criteria = nn.BCEWithLogitsLoss(weight=w, pos_weight=pos_w)\nelse:\n    loss_criteria = nn.BCELoss(weight=w)\nif device == 'cuda':\n    loss_criteria.cuda()\n\n\n# Adam optimizer\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999), eps=1e-8, weight_decay=1e-5)\n\n# Learning rate will be reduced automatically during training\nlr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = LEARNING_RATE_SCHEDULE_FACTOR, patience = LEARNING_RATE_SCHEDULE_PATIENCE, mode = 'max', verbose=True)","3cf56fb3":"def multi_label_f1(y_gt, y_pred, threshold=0.5):\n    \"\"\" Calculate F1 for each class\n\n    Parameters\n    ----------\n    y_gt: torch.Tensor\n        groundtruth\n    y_pred: torch.Tensor\n        prediction\n\n    Returns\n    -------\n    list\n        F1 of each class\n    \"\"\"\n    f1_out = []\n    gt_np = y_gt.to(\"cpu\").numpy()\n    pred_np = (y_pred.to(\"cpu\").numpy() > threshold) * 1.0\n    assert gt_np.shape == pred_np.shape, \"y_gt and y_pred should have the same size\"\n    for i in range(gt_np.shape[1]):\n        f1_out.append(f1_score(gt_np[:, i], pred_np[:, i]))\n    return f1_out","d253b8cb":"def mixup_data(x, y, alpha=1.0, use_cuda=True):\n    '''Returns mixed inputs, pairs of targets, and lambda'''\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1\n\n    batch_size = x.size()[0]\n    if use_cuda:\n        index = torch.randperm(batch_size).cuda()\n    else:\n        index = torch.randperm(batch_size)\n\n    mixed_x = lam * x + (1 - lam) * x[index, :]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\n\ndef mixup_criterion(criterion, pred, y_a, y_b, lam):\n    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n\ndef epoch_training(epoch, model, train_dataloader, device, loss_criteria, optimizer, mb, augment=True):\n    \"\"\"\n    Epoch training\n\n    Paramteters\n    -----------\n    epoch: int\n      epoch number\n    model: torch Module\n      model to train\n    train_dataloader: Dataset\n      data loader for training\n    device: str\n      \"cpu\" or \"cuda\"\n    loss_criteria: loss function\n      loss function used for training\n    optimizer: torch optimizer\n      optimizer used for training\n    mb: master bar of fastprogress\n      progress to log\n\n    Returns\n    -------\n    float\n      training loss\n    \"\"\"\n    # Switch model to training mode\n    model.train()\n    training_loss = 0 # Storing sum of training losses\n   \n    # For each batch\n    for batch, (images, labels) in enumerate(progress_bar(train_dataloader, parent=mb)):            \n\n        # Move X, Y  to device (GPU)\n        images = images.to(device)\n        labels = labels.to(device)\n        if MIXUP:\n            images, labels_a, labels_b, lam = mixup_data(images, labels)\n        # Clear previous gradient\n        optimizer.zero_grad()\n\n        # Feed forward the model\n        pred = model(images)\n        if MIXUP:\n            loss = mixup_criterion(loss_criteria, pred, labels_a, labels_b, lam)\n        else:\n            loss = loss_criteria(pred, labels)\n        # Back propagation\n        loss.backward()\n\n        # Update parameters\n        optimizer.step()\n\n        # Update training loss after each batch\n        training_loss += loss.item()\n\n        mb.child.comment = f'Training loss {training_loss\/(batch+1)}'\n\n    del images, labels, loss\n    if torch.cuda.is_available(): torch.cuda.empty_cache()\n\n    # return training loss\n    return training_loss\/len(train_dataloader)","e7c498f7":"def evaluating(epoch, model, val_loader, device, loss_criteria, mb):\n    \"\"\"\n    Validate model on validation dataset\n    \n    Parameters\n    ----------\n    epoch: int\n        epoch number\n    model: torch Module\n        model used for validation\n    val_loader: Dataset\n        data loader of validation set\n    device: str\n        \"cuda\" or \"cpu\"\n    loss_criteria: loss function\n      loss function used for training\n    mb: master bar of fastprogress\n      progress to log\n  \n    Returns\n    -------\n    float\n        loss on validation set\n    float\n        metric score on validation set\n    \"\"\"\n\n    # Switch model to evaluation mode\n    model.eval()\n\n    val_loss = 0                                   # Total loss of model on validation set\n    out_pred = torch.FloatTensor().to(device)      # Tensor stores prediction values\n    out_gt = torch.FloatTensor().to(device)        # Tensor stores groundtruth values\n\n    with torch.no_grad(): # Turn off gradient\n        # For each batch\n        for step, (images, labels) in enumerate(progress_bar(val_loader, parent=mb)):\n            # Move images, labels to device (GPU)\n            images = images.to(device)\n            labels = labels.to(device)\n\n            # Update groundtruth values\n            out_gt = torch.cat((out_gt,  labels), 0)\n\n            # Feed forward the model\n            ps = model(images)\n            loss = loss_criteria(ps, labels)\n\n            # Update prediction values\n            out_pred = torch.cat((out_pred, ps), 0)\n            \n            \n            # Update validation loss after each batch\n            val_loss += loss\n            mb.child.comment = f'Validation loss {val_loss\/(step+1)}'\n\n    # Clear memory\n    del images, labels, loss\n    if torch.cuda.is_available(): torch.cuda.empty_cache()\n    # return validation loss, and metric score\n    return val_loss\/len(val_loader), np.array(multi_label_f1(out_gt, out_pred)).mean()","4f667c68":"# Best F1 value during training\nbest_score = 0\nbest_loss = 10\nmodel_path = \"resnet50.pth\"\ntraining_losses = []\nvalidation_losses = []\nvalidation_score = []\n\n\n# Config progress bar\nmb = master_bar(range(MAX_EPOCHS))\nmb.names = ['Training loss', 'Validation loss', 'Validation F1']\nx = []\n\n# Training each epoch\nfor epoch in mb:\n    mb.first_bar.comment = f'Best F1 score: {best_score}'\n    x.append(epoch)\n\n    # Training\n    train_loss = epoch_training(epoch, model, train_dataloader, device, loss_criteria, optimizer, mb)\n    mb.write('Finish training epoch {} with loss {:.4f}'.format(epoch, train_loss))\n    training_losses.append(train_loss)\n\n    # Evaluating\n    val_loss, new_score = evaluating(epoch, model, val_dataloader, device, loss_criteria, mb)\n    mb.write('Finish validation epoch {} with loss {:.4f} and score {:.4f}'.format(epoch, val_loss, new_score))\n    validation_losses.append(val_loss)\n    validation_score.append(new_score)\n\n    # Update learning rate\n    lr_scheduler.step(new_score)\n\n    # Update training chart\n    mb.update_graph([[x, training_losses], [x, validation_losses], [x, validation_score]], [0,MAX_EPOCHS], [0,1])\n\n    # Save model\n    if best_score < new_score:\n        mb.write(f\"Improve F1 from {best_score} to {new_score}\")\n        best_score = new_score\n        best_loss = val_loss\n        # Saving model: https:\/\/pytorch.org\/tutorials\/beginner\/saving_loading_models.html\n        torch.save(model.state_dict(), model_path)\n    if new_score == 1.0 and best_loss > val_loss:\n        mb.write(f\"Improve score from {best_loss} to {val_loss}\")\n        best_score = new_score\n        best_loss = val_loss\n        # Saving model: https:\/\/pytorch.org\/tutorials\/beginner\/saving_loading_models.html\n        torch.save(model.state_dict(), model_path)","e7be93ad":"model.load_state_dict(torch.load(model_path))\nmodel.eval()\ndef eval_thres(model, val_loader, threshold=0.5):\n    \"\"\"\n    Validate model on validation dataset\n    \n    Parameters\n    ----------\n    epoch: int\n        epoch number\n    model: torch Module\n        model used for validation\n    val_loader: Dataset\n        data loader of validation set\n    device: str\n        \"cuda\" or \"cpu\"\n    loss_criteria: loss function\n      loss function used for training\n    mb: master bar of fastprogress\n      progress to log\n  \n    Returns\n    -------\n    float\n        loss on validation set\n    float\n        metric score on validation set\n    \"\"\"\n\n    # Switch model to evaluation mode\n    model.eval()\n\n    val_loss = 0                                   # Total loss of model on validation set\n    out_pred = torch.FloatTensor().to(device)      # Tensor stores prediction values\n    out_gt = torch.FloatTensor().to(device)        # Tensor stores groundtruth values\n\n    with torch.no_grad(): # Turn off gradient\n        # For each batch\n        for step, (images, labels) in enumerate(progress_bar(val_loader, parent=mb)):\n            # Move images, labels to device (GPU)\n            images = images.to(device)\n            labels = labels.to(device)\n\n            # Update groundtruth values\n            out_gt = torch.cat((out_gt,  labels), 0)\n\n            # Feed forward the model\n            ps = model(images)\n\n            # Update prediction values\n            out_pred = torch.cat((out_pred, ps), 0)\n            \n\n    # Clear memory\n    del images, labels\n    if torch.cuda.is_available(): torch.cuda.empty_cache()\n    # return validation loss, and metric score\n    return np.array(multi_label_f1(out_gt, out_pred, threshold)).mean()\n\nbest_score, best_threshold = 0, 0\nfor threshold in [0.2,0.25,0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6]:\n    score = eval_thres(model, val_dataloader, threshold)\n    if score > best_score:\n        best_score = score\n        best_threshold = threshold\n    print(f'{threshold} - {score}')","384eb9e1":"test_df = pd.read_csv(\"..\/input\/vietai-advance-course-retinal-disease-detection\/sample_submission.csv\")\ntest_df.head()","173eb5b8":"from torch.nn import functional as F\n# Define list of image transformations\nimage_transformation = [\n    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    transforms.ToTensor()\n]\n# Normalization with mean and std from ImageNet\nimage_transformation.append(transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD))\nimage_transformation = transforms.Compose(image_transformation)\n\ndef predict(image_path, model, device):\n    \"\"\" Predict image\n    \n    Parameters\n    ----------\n    image_path: str\n        image path to predict\n    model: nn.Module\n        model used to predict\n    device: str\n        'cpu' or 'cuda'\n        \n    Returns\n    -------\n    str\n        list of label indices\n    \"\"\"\n    global image_transformation\n    \n    # Read image\n    image_data = Image.open(image_path).convert('RGB')\n    image_data = image_transformation(image_data)\n    \n    predicted_label = []\n    with torch.no_grad():\n        ps = model(image_data.unsqueeze(0).to(device))\n        if USE_BCELOGIT:\n            ps = F.sigmoid(ps)\n        ps = ps[0]\n        for i in range(ps.size()[0]):\n            if ps[i].item() > best_threshold: # Threshold is 0.5\n                predicted_label.append(i)\n        if len(predicted_label) == 0:\n            predicted_label.append(0)\n    return \" \".join([str(label) for label in predicted_label])\n\n\n","7567a243":"model.load_state_dict(torch.load(model_path))\nmodel.eval()","9449e7c9":"test_df['predicted'] = test_df.filename.map(lambda x: predict(os.path.join(\"..\/input\/cleandata-vietai-caothang\/cleaned_data\/cleaned_data\/test\",x), model, device))","54851057":"test_df.to_csv(\"submission.csv\", index=False)","193741be":"print(model_path)","5908164d":"Write result to submission file","1560c347":"Read the test data","837d2c40":"# Inference","fe64b7be":"# Find threshold","ba57cd04":"Create model and check model architecture","33956409":"Import libraries","c7312152":"If you run on Google Colab, run the code below to download the dataset","260c15a4":"## Implement Dataset loader\nIn Pytorch, you need to subclass the `Dataset` of Pytorch to custom the data loading process. The **Image Augmentation** would be executed in this subclass","e43edb7d":"Load best model weights and switch to evaludation mode","80e8063b":"# Observations on the dataset\nThe dataset provided is extremely imbalanced. In this baseline model, by simply train the model the original dataset, we will easily get overfitting on the training set and the score on the test set is very low. With the proposed methods below, you will tweak the training process and improve the metric score on the test set:\n- **Image Augmentation**: By augmenting images, we will have more data and make the training set become more regularize. [imgaug](https:\/\/github.com\/aleju\/imgaug) is a very strong augmentation library that you can use in this assignment\n- **Data sampling**: the idea here is to make the distribution between classes in the dataset balance. There are 2 kinds: oversampling and undersampling\n- **Adjust loss function**: the current loss function becomes very small after several epochs. By adding weights, we adjust the loss function to make it suitable for this imbalanced dataset. You can check the [BCEWithLogitsLoss](https:\/\/pytorch.org\/docs\/stable\/nn.html#bcewithlogitsloss) and try applying it.","8e942ae3":"## Training each epoch\nThis function will be called to train on one epoch\n","98d9eb1d":"Besides, `DataLoader` also need to be created. For the training data loader, we need to shuffle the dataset.","1938b797":"<a href=\"submission.csv\">Download submission<\/a> <br> <a href='resnet50.pth'>Download model<\/a>","694be259":"# Read dataset","296fe674":"## Analyze combination of classes","47e6c94a":"## Analyze distribution of 0 and 1 for each label","11668df8":"# Split the dataset","79d7709c":"Let's check the size of data and label for each iteration","7a261e2b":"# album image aug","3c6267e4":"For the data provided, we will split the dataset to 80% for training and 20% for validation","149a70ef":"# Build and train baseline model","d1c14c10":"## Fully training\nFully training the model ","ed693d9c":"## Note on val results:\n- Clean data + BCELogit + MixUp + Loss Weight(pos_w\\[0\\]=1.3) = 0.78 \n- Unclean data + Augmentation + BCELogit + Loss Weight= 0.79 - Submission 09\n- Unclean data + BCELogit + MixUp + Loss Weight = 0.76\n- Clean data = 0.7546048370816062\n- Clean data + BCELogit = 0.7438\n- Clean data + Loss Weight = 0.7389\n- Clean data  + Not Normal P + Weight + MixUp = 0.721\n- Clean data  + Use_BCELogit + Weight +MixUp + Augment = 0.81\n- Like above + EffNetB0 = 0.8475 -> Tune thres = 0.8489\n- +Blur Augment = 0.8479","a3c49f01":"We need to train about 23 millions parameters","077a0cb7":"# Data analyzing","ae46641d":"## Evaluate model\nThis function is used to validate the model on the validation dataset","264aa38f":"## Define model\nIn the baseline, we use ResNet50 pretrained on ImageNet dataset. The classifier of model would be replaced with a new dense layer to make the output suit the problem.","0d2fe6e8":"## Define loss function, optimizer, and learning rate scheduler","624a776e":"Create training dataset","3a7f561f":"## Create model and get number of trainable parameters","37d5e820":"Predict test images","dcfdbcec":"As we can see, **opacity**, **normal** and **glaucoma** are diseases that share largest proportions in label distribution. The other diseases or combinations just account for small pieces.","adbee4c8":"## Compute F1-score \nBecause we have multi labels, we need to calculate F1-score for each class.","1ce723ed":"In this notebook, we will use Pytorch library to implement and train ResNet50 as a baseline model. With initial weights from ImageNet, we will retrain all layers for this problem.","b233b0bd":"Number of trainable parameters","37d68df8":"As can be observed, the number of label 0 is much more larger than label 1","dfe08eaa":"**To simplify the baseline model, the dataset is splited randomly. However, to improve the model, cross-validation techniques can be applied here**","981c1611":"Predict function","6ffb8a98":"## Check GPU available","d929bb8b":"We also need to create validation dataloader. Different from training dataloader, we don't shuffle the validation set"}}