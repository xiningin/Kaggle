{"cell_type":{"57962e04":"code","8f87f46f":"code","64e8d646":"code","3f36de45":"code","d3564807":"code","d4a93666":"code","67206886":"code","56a6bc07":"code","7b09a2f3":"markdown","ddd8118f":"markdown","99ef4581":"markdown","48ca2986":"markdown","60a10006":"markdown","5c6b6580":"markdown","e55b3e8a":"markdown","e68b500f":"markdown"},"source":{"57962e04":"import pandas as pd\nimport numpy as np\n\nimport operator\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\ndf = pd.read_csv('..\/input\/multipleChoiceResponses.csv')\ndf.drop([0],inplace=True)\n\n######\n# Start of time column\ndf['Time from Start to Finish (seconds)'] = df['Time from Start to Finish (seconds)'].apply(int)\n# Rejecting those who answered questions too fast:\ndf = df[df['Time from Start to Finish (seconds)']>60]\n# drop \"Time\" column\ndf.drop(['Time from Start to Finish (seconds)'],axis=1,inplace=True)\n# End of time column\n######\n\ndef rename_some_salaries(salary):\n    if (salary!=salary): return 'unknown'\n    elif (salary=='I do not wish to disclose my approximate yearly compensation'): \n        return 'unknown'\n    return salary\n\ndf['Q9']=df['Q9'].apply(lambda x: rename_some_salaries(x))\n\n# drop those who didn't disclose disclose their salary\ndf = df[(df['Q9']!='unknown')]\n\n# all valid salary ranges:\nall_salaries = ['0-10,000','10-20,000','20-30,000','30-40,000','40-50,000','50-60,000','60-70,000',\n                       '70-80,000','80-90,000','90-100,000','100-125,000','125-150,000','150-200,000',\n                       '200-250,000','250-300,000','300-400,000','400-500,000','500,000+']\n\n# remove students\ndf = df[df['Q6']!='Student']\ndf = df[df['Q7']!='I am a student']\n\n# def: plot salary distribution\ndef plot_salary_distribution(df,col='Q9',x_label='yearly compensation, [USD]',order=None):\n    fig, ax2 = plt.subplots(figsize=(18,6))\n    g2 = sns.countplot(x=col,data=df, order=order, ax=ax2)\n    g2.set_xticklabels(ax2.get_xticklabels(),rotation=90)\n    g2.set_title('Yearly compensation distribution',fontsize=20)\n    g2.set_ylabel('')\n    g2.set_xlabel(x_label,fontsize=16)\n    #ax2.set(yscale=\"log\")\n    for p in ax2.patches:\n        x=p.get_bbox().get_points()[:,0]\n        y=p.get_bbox().get_points()[1,1]\n        ax2.annotate(p.get_height(), (x.mean(), y), ha='center', va='bottom')\n        \n# plot salary distribution\nsmth0 = plot_salary_distribution(df,order=all_salaries)","8f87f46f":"# all valid salary ranges:\nall_salaries = ['0-10,000','10-20,000','20-30,000','30-40,000','40-50,000','50-60,000','60-70,000',\n                       '70-80,000','80-90,000','90-100,000','100-125,000','125-150,000','150-200,000',\n                       '200-250,000','250-300,000','300-400,000','400-500,000','500,000+']\n        \n# shorten names of some countries\ndef rename_some_countries(x):\n    if (x=='United States of America'): return 'USA'\n    if (x=='United Kingdom of Great Britain and Northern Ireland'): return 'United Kingdom'\n    if (x=='Iran, Islamic Republic of...'): return 'Iran'\n    if (x=='Hong Kong (S.A.R.)'): return 'Hong Kong'\n    return x\n\ndf['Q3']=df['Q3'].apply(lambda x: rename_some_countries(x))\n\ndf['country']=df['Q3']\n\n\n# distribution over salary ranges\ndf_for_plot = df[(df['country']=='USA') | (df['country']=='India')]\n\nfig, ax2 = plt.subplots(figsize=(18,6))\ng2 = sns.countplot(x='Q9',data=df_for_plot, \n                   order=all_salaries, ax=ax2, hue='country')\nsmth0 = g2.set_xticklabels(ax2.get_xticklabels(),rotation=90)\nsmth1 = g2.set_title('Yearly compensation distribution',fontsize=20)\nsmth2 = g2.set_ylabel('')\nsmth3 = g2.set_xlabel('yearly compensation [USD]',fontsize=16)","64e8d646":"import math\n\n# this dict is for 'quantify_average'\ndict_averages = {'0-10,000':5000,'10-20,000':15000,'20-30,000':25000,\n                '30-40,000':35000,'40-50,000':45000,'50-60,000':55000,\n                '60-70,000':65000,'70-80,000':75000,'80-90,000':85000,\n                '90-100,000':95000,'100-125,000':112500,'125-150,000':137500,\n                '150-200,000':175000,'250-300,000':275000,'200-250,000':225000,\n                '300-400,000':350000,'400-500,000':450000,'500,000+':650000}\n\ndef quantify_enumerate(x):\n    for i in range(1,len(all_salaries)+1):\n        if (x==all_salaries[i-1]): return int(i)\n    return -100\n\ndef quantify_average(x):\n    return dict_averages[x]\n\ndef quantify_log_average(x):\n    return math.log(dict_averages[x])\n\ndef order_subset(subset,whole_set):\n    ordered = ['']*len(subset)\n    i = 0\n    for s in whole_set:\n        if s in subset:\n            ordered[i]=s\n            i = i+1\n    return ordered\n\ndef ranges_to_numerical(df, col_name='Q9', whole_set = all_salaries):\n    subset = df[col_name].unique()\n    ordered_subset = order_subset(subset,whole_set)\n    dict_ranges = dict(df[col_name].value_counts())\n    N_tot = df.shape[0]\n    N_values = len(ordered_subset)\n    N_values1 = len(dict_ranges)\n    if (N_values!=N_values1):\n        print('In ranges_to_numerical: (N_values!=N_values1)')\n        return\n    Ns_given_range = [0]*N_values\n    percentile = 0\n    ordered_dict = {}\n    for key in ordered_subset:\n        N_i = dict_ranges[key]\n        percentile = percentile+100*N_i\/N_tot\n        ordered_dict[key] = percentile\n    return ordered_dict\n\ndef quantify_percentile(x, ordered_dict):\n    if (x in ordered_dict.keys()):\n        return round(ordered_dict[x],3)\n    else:\n        return -100\n    \n# calculate world wide percentile\nordered_dict = ranges_to_numerical(df, col_name='Q9', whole_set = all_salaries)\ndf['world_wide_percentile'] = df['Q9'].apply(lambda x: \n                                             quantify_percentile(x,ordered_dict))\n\ndf['enumerate_salary_ranges'] = df['Q9'].apply(lambda x: quantify_enumerate(x))\n\ndf['salary_averages'] = df['Q9'].apply(lambda x: quantify_average(x))\n\ndf['salary_log_averages'] = df['Q9'].apply(lambda x: quantify_log_average(x))\n\ndf_USA = pd.DataFrame(df[df['country']=='USA'])\ndf_India = pd.DataFrame(df[df['country']=='India'])\n\n# calculate country-wide (local) percentile\nordered_dict_USA = ranges_to_numerical(df_USA, col_name='Q9', whole_set = all_salaries)\ndf_USA['country_percentile'] = df_USA['Q9'].apply(lambda x: \n                                             quantify_percentile(x,ordered_dict_USA))\nordered_dict_India = ranges_to_numerical(df_India, col_name='Q9', whole_set = all_salaries)\ndf_India['country_percentile'] = df_India['Q9'].apply(lambda x: \n                                             quantify_percentile(x,ordered_dict_India))\n\ndf_USA_India = pd.concat([df_USA,df_India])","3f36de45":"#all_salaries = ['0-10,000','10-20,000','20-30,000','30-40,000','40-50,000','50-60,000','60-70,000',\n#                       '70-80,000','80-90,000','90-100,000','100-125,000','125-150,000','150-200,000',\n#                       '200-250,000','250-300,000','300-400,000','400-500,000','500,000+']\n\n# enumerate\n# the code to enumerate salary ranges is available above\nfig = plt.figure(figsize=(18,6))\nax = fig.add_subplot(111)\np1 = plt.hist(df_USA['enumerate_salary_ranges'],bins=18)\np2 = plt.hist(df_India['enumerate_salary_ranges'],bins=18,alpha=0.5)\np3 = plt.title('Distribution by compensation ranges enumerated',fontsize=20)\np4 = plt.xlabel('compensation range number',fontsize=16)\np5 = plt.xlim(1,18)\n","d3564807":"# salary averages\n# the code to compute salary range averages is available above\nfig = plt.figure(figsize=(18,6))\nax = fig.add_subplot(111)\np1 = plt.hist(df_USA['salary_averages'],bins=65)\np2 = plt.hist(df_India['salary_averages'],bins=65,alpha=0.5)\np3 = plt.title('Distribution by compensation range averages',fontsize=20)\np4 = plt.xlabel('compensation range average [USD]',fontsize=16)\np5 = plt.xlim(0,650000)","d4a93666":"# salary log averages\n# the code to compute salary range log-averages is available above\nfig = plt.figure(figsize=(18,6))\nax = fig.add_subplot(111)\np1 = plt.hist(df_USA['salary_log_averages'],bins=24)\np2 = plt.hist(df_India['salary_log_averages'],bins=24,alpha=0.5)\np3 = plt.title('Distribution by compensation range log averages',fontsize=20)\np4 = plt.xlabel('compensation range log average [log(USD)]',fontsize=16)\np5 = plt.xlim(8,14)","67206886":"# world-wide percentile\n# the code to compute world-wide percentile is available above\nfig = plt.figure(figsize=(18,6))\nax = fig.add_subplot(111)\np1 = plt.hist(df_USA['world_wide_percentile'],bins=50)\np2 = plt.hist(df_India['world_wide_percentile'],bins=50,alpha=0.5)\np3 = plt.title('Distribution by world-wide compensation percentile',fontsize=20)\np4 = plt.xlabel('world-wide compensation percentile',fontsize=16)\np5 = plt.xlim(10,100)","56a6bc07":"# country percentile\n# the code to compute local (country) percentile is available above\nfig = plt.figure(figsize=(18,6))\nax = fig.add_subplot(111)\np1 = plt.hist(df_USA['country_percentile'],bins=50)\np2 = plt.hist(df_India['country_percentile'],bins=50,alpha=0.5)\np3 = plt.title('Distribution by local compensation percentile',fontsize=20)\np4 = plt.xlabel('local compensation percentile',fontsize=16)\np5 = plt.xlim(0,100)","7b09a2f3":"## Compensation range log-average\n\nWhen the values differ from one another by almost two orders of magnitude, it may make sense to use a logarithmic rather than a linear scale to compare the values between each other.\n<br><br>\nThe plot below shows a rather nice distribution for USA respondents but this time there is a number of unpopulated bins for the Indian kaggles.","ddd8118f":"#### The dataset used to prepare this plot excludes:\n- students\n- people for whom it took less than a minute to complete survey\n- people who didn't disclose their compensation or for whom it was irrelevant\n<br><br>\nThe peak around '100-125,000' corresponds to the average compensation of USA data scientists while the peak at '0-10,000' indicates a large representation of kagglers from countries with lower salary standards.\n<br><br>\nTo illustrate the country effect, let us plot the yearly compensation distribution for two countries with the largest Kaggle populations and very different salary standards.\n<br>\n## The Yearly Compensation Distribution for USA vs India","99ef4581":"## World-wide and local compensation percentile\n\nThe last two quantifications I suggest to look at are world-wide and country-wide (local) compensation percentiles. The percentile for bin X is computed as a number of respondents in this and all smaller compensation bins divided over the all respondents in a given dataset.\n<br><br>\nBy this definition, '500,000+' bin correspond to a 1000-world-wide-percentile because this compensation range is the largest possible, while '0-10,000' one corresponds to a 17-world-wide-percentile because 17% of non-students respondents in the analyzed dataset claimed their compensation is within this range. Local percentiles are calculated separately for each country using the same definition.\n<br><br>\nThe distributions by any of these two percentiles do not look any better than the three discussed above","48ca2986":"## Conclusion\n\nFive methods to quantify the yearly compensation of USA and Indian kagglers are considered:\n- simple enumeration of compensation ranges\n- compensation range averages\n- compensation range log-averages\n- world-wide compensation percentile\n- local (country-wide) compensation percentile\n\n<br><br>\nSimple enumeration method maps compensation ranges into equidistant numerical values making it possible to create a distribution without unpopulated bin. If you decide to use this quantification method, you should realize the same disrance between ranges may mean a completely difference in terms of the amount of dollars. \n<br><br>\nA range boundaries average method maps ranges into numerical values the same way as a simple enumeration method for values of up to \\$100K, and may perform well if the intended study consentrates on a group of kaggles who mostly don't exceed this compensation range. Although one may want to note that an average of two range boundaries does not correspond to an average compensation for a given group of people. \n<br><br>\nIn contrary, a log-average quantification method shows a nicer distribution for people with yearly compensations above \\$40K, and might be helpful for work with USA non-student kagglers.\n<br><br>\nWorld-wide and country-wide percentile are interesting quantifications to look at but the populated bins are all at a different distance from one another which makes it not a very convinivent quantification for kaggler yearly compensation studies.\n\n- - -\n#### Upvote if found the kernel useful and tell me\n# How do you quantify compensation ranges?","60a10006":"## Compensation range average\n\nThe average of range is computed as (max+min)\/2, thus, for '0-10,000' the average is 5,000.\n<br>\nThe \"average\" for '500,000+' is taken to be 650,000\n<br>\n#### Please, note that the average value of two range boundaries DOES NOT correspond to an average compensation of a group of people in a given range. \n<br>\nE.g. if we could calculate an average compensation among all respondents in '0-10,000' range, the result could be 3,000 or 2,000 rather than 5,000.\n<br><br>\nNevertheless, at the plot below we see how the distributions over range boundaries averages among non-student American and Indian respondents look like. \n<br><br>\nFor the values about up to 110,000 the distributions by range boundary averages show very similar behavior as enumeration distributions discussed above because up to this point the compensation boundaries are equidistant. Yet once the ranges start to get broader, we have a large number of unpopulated bins.\n<br><br>\nTo make more sense out of this way of quantification, it may worth to combine high salary bins together as it is done in the proposed ranges and normalize all the frequencies to the bin width.","5c6b6580":"## Enumeration of compensation ranges\n\nThe simplest way to quantify the compensation ranges is to assign a range number for each range.\n<br><br>\n'0-10,000' -> 1, '10-20,000' -> 2, etc\n<br><br>\nIf using this way to quantify, a distance between '0-10,000' and '20-30,000' will be the same as the distance between '300-400,000' and '500,000+'\n<br><br>\n#### The distribution by this quantity is the same as the distribution by original compensation ranges.","e55b3e8a":"# Five Ways to Quantify Yearly Compensation\n\nIn the [2018 Kaggle ML & DS Survey Challenge](https:\/\/www.kaggle.com\/kaggle\/kaggle-survey-2018\/home) kagglers are asked to explore a dataset with survey results of themselves.\n<br><br>\nAmong tens of multiple choice questions, the survey takers were asked to disclose a range of their yearly compensation, and about 2\/3 respondents did. All possible compensations are split into 18 ranges, from '0-10,000' to '500,000+'.\n<br><br>\n## Here is how the yearly compensation distributed among the respondents","e68b500f":"The distribution for USA, while far away from the Gaussian, shows a peak, an increase and a descent. The distribution for India is descending rapidly with a peak somewhere in '0-10,000' USD range.\n<br><br>\nThe ranges are good for such comparison plots and are distributed fairly well for USA, but for more in-depth compensation studies the compensation needs to be quantified. It is essential to measure the difference in typical compensation for USA vs India, or between any other kaggler groups whether it is by an education, experience, main activities at work or a job title.\n<br><br>\nLet us consider five ways to quantify compensation ranges and draw a conclusion about each one:\n- simple enumeration of compensation ranges\n- compensation range averages\n- compensation range log-averages\n- world-wide compensation percentile\n- local (country-wide) compensation percentile\n\n<br><br>\n(The code to prepare all five quantifications is hidden right here)"}}