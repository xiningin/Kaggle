{"cell_type":{"22869ae4":"code","e9cdf7a6":"code","5264e7e9":"code","819ae066":"code","0432493a":"code","e50722a6":"code","3f25e7bb":"code","6b7b2d00":"code","4e6825b0":"code","04082453":"code","db3e30e5":"code","91a67ec3":"code","6a211ee9":"code","0bdeee86":"code","87e4f355":"code","3f1e72e2":"code","cf7744b7":"code","9ee0ced6":"code","63e3b955":"code","91f27d49":"code","971fa859":"code","170af8a7":"code","4d14c444":"markdown","ee4f2ca7":"markdown","e04cd4e7":"markdown","1eb9320f":"markdown","09cf975e":"markdown","d95b0bba":"markdown","1a845e27":"markdown","089be6a9":"markdown","5b20c868":"markdown","5a9eacf1":"markdown","e8d912a0":"markdown","5fd15266":"markdown","11d6b7e7":"markdown","5bcc6962":"markdown","d3806cc2":"markdown","9a4f9d30":"markdown","eea57dc5":"markdown","5f3f2f59":"markdown","d5ef0662":"markdown","c2448204":"markdown"},"source":{"22869ae4":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\ncop = ''","e9cdf7a6":"df1 = pd.read_csv(\"..\/input\/lish-moa\/train_features.csv\")\ndf2 = pd.read_csv(\"..\/input\/lish-moa\/train_targets_scored.csv\")\ndf3 = pd.read_csv(\"..\/input\/lish-moa\/train_targets_nonscored.csv\")\n\nprint(\"shape of train_features.csv: \", df1.shape)\nprint(\"shape of train_targets_scored.csv: \", df2.shape)\nprint(\"shape of train_targets_nonscored.csv: \", df3.shape)\n\nprint(\"Total number of datapoints: {:,}\".format(df1.shape[0]))\n\ndf1.head()","5264e7e9":"df1.describe()","819ae066":"# knowing the data types of each column of `train_features.csv`\ndata_types = df1.dtypes\nunique_dtypes = data_types.unique()\nprint(\"number of dtypes in `train_features.csv`: \", len(unique_dtypes),\n      \"\\nAnd these are: \", unique_dtypes)\n\nObj   = []\nInt   = []\nFloat = []\nfor col, data_type in zip(df1.columns, data_types):\n    if data_type == 'object':Obj.append(col)        \n    elif data_type == 'int64':Int.append(col)\n    elif data_type == 'float64':Float.append(col)\nprint(\"number of object data type: \", len(Obj))\nprint(\"number of int64 data type: \", len(Int))\nprint(\"number of float64 data type: \", len(Float))\n\nassert len(Obj)+len(Int)+len(Float) == df1.shape[1]","0432493a":"Obj, Int","e50722a6":"print(\"Number of unique values in `cp_type` col is: {} and these are: {}\"\n      .format(len(df1.loc[:, \"cp_type\"].unique()), df1.loc[:, \"cp_type\"].unique()))\n\nprint(\"Number of unique values in `cp_dose` col is: {} and these are: {}\"\n      .format(len(df1.loc[:, \"cp_dose\"].unique()), df1.loc[:, \"cp_dose\"].unique()))\n\nprint(\"Number of unique values in `cp_time` col is: {} and these are: {}\"\n      .format(len(df1.loc[:, \"cp_time\"].unique()), df1.loc[:, \"cp_time\"].unique()))","3f25e7bb":"import matplotlib.pyplot as plt\nimport seaborn as sns","6b7b2d00":"fig, axs = plt.subplots(1,3, figsize=(18,6))\n\nfig.suptitle(\"Count Plot of Categorical variables\", fontsize = 24)\nsns.countplot(x ='cp_type', data = df1, ax = axs[0])\naxs[0].set_title(\"For: cp_type\", fontsize= 16)\nsns.countplot(x ='cp_dose', data = df1, ax = axs[1])\naxs[1].set_title(\"For: cp_dose\", fontsize = 16)\naxs[1].set(ylabel = '')\nsns.countplot(x = 'cp_time', data = df1, ax = axs[2])\naxs[2].set_title(\"For: cp_time\", fontsize = 16)\naxs[2].set(ylabel = '')\n\nplt.show()","4e6825b0":"# cp_type, cp_time, cp_dose\ndef encode_cp_time(row):\n    val = None\n    if row == 24:val = 1\n    elif row == 48:val = 2\n    else:val = 3\n    return val\n        \ndf1[\"cp_type\"] = df1[\"cp_type\"].apply(lambda x: 0 if x=='trt_cp' else 1)\ndf1[\"cp_dose\"] = df1[\"cp_dose\"].apply(lambda x: 0 if x=='D1' else 1)\ndf1[\"cp_time\"] = df1[\"cp_time\"].apply(encode_cp_time)\n\ndf1.head()","04082453":"from sklearn.preprocessing import StandardScaler\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.decomposition import PCA","db3e30e5":"X = df1.iloc[:, 1:]\nx = StandardScaler().fit_transform(X)\nx = pd.DataFrame(data=x, columns = X.columns)\nx.head()","91a67ec3":"pca = PCA(n_components=None, svd_solver = 'full')\npca.fit_transform(x)\nvar = pca.explained_variance_ratio_","6a211ee9":"for i in range(1,9):\n    print(\"Variance explained by top {} components: {}\".format(i*100, var[:i*100].sum()))","0bdeee86":"corrmat = X.corr()","87e4f355":"f, ax = plt.subplots(1,1, figsize =(18, 8))\nsns.heatmap(corrmat, ax = ax)\nplt.show()","3f1e72e2":"cols = [col for col in corrmat.columns if col.startswith('c-')]\nf, ax = plt.subplots(1,1, figsize =(18, 8))\nsns.heatmap(corrmat.loc[cols, cols], ax = ax)\nplt.show()","cf7744b7":"from sklearn.metrics import log_loss\ndef total_loss(y_true, y_pred):\n    \"\"\"\n    y_true: numpy nd-array of shape (None , 206), None means any value\n    y_pred: numpy nd-array of shape (None , 206)\n    \"\"\"\n    losses = []\n    for i in range(y_true.shape[1]):losses.append(log_loss(y_true[:,i], y_pred[:,i], eps=1e-15))\n    return np.mean(losses)","9ee0ced6":"df_test = pd.read_csv(\"..\/input\/lish-moa\/test_features.csv\")\nprint(\"number of test datapoints: {:,}\".format(df_test.shape[0]))\n\ny_train = df2.iloc[:, 1:].values\ny_train_pred = np.random.random_sample(y_train.shape) \ny_test_pred = np.random.random_sample((df_test.shape[0], y_train.shape[1])) ","63e3b955":"tr_loss = total_loss(y_train, y_train_pred)\nprint(\"train loss: \", tr_loss)","91f27d49":"test_df = pd.DataFrame(data = y_test_pred, columns = df2.columns[1:])\ntemp = pd.DataFrame(data=df_test.loc[:, 'sig_id'])\ntest_df = pd.concat([temp, test_df], ignore_index=False, axis=1)\ntest_df['5-alpha_reductase_inhibitor'] = test_df['5-alpha_reductase_inhibitor']  + 1.2\ntest_df.head()","971fa859":"test_df.to_csv(\".\/submission.csv\",index=False)","170af8a7":"import numpy as np\nimport pandas as pd\ndf1 = pd.read_csv('..\/input\/moa-blending\/0.01832.csv')\ndf2 = pd.read_csv('..\/input\/mypredpublic\/my_predictions_0000001.csv')\ndf3 = pd.read_csv('..\/input\/moa-blending\/0.01833.csv')\ndef order_sub(sub) : \n    return sub.sort_values('sig_id').reset_index(drop=True)\ndf1 = order_sub(df1)\ndf2 = order_sub(df2)\ndf3 = order_sub(df3)\nBLEND=df1.copy()\nBLEND.iloc[:,1:] =  df1.iloc[:,1:]*0.6 +df2.iloc[:,1:]*0.2 +df3.iloc[:,1:]*0.2\nTARGET_COL = ['5-alpha_reductase_inhibitor', '11-beta-hsd1_inhibitor', 'acat_inhibitor', 'acetylcholine_receptor_agonist', 'acetylcholine_receptor_antagonist', 'acetylcholinesterase_inhibitor', 'adenosine_receptor_agonist', 'adenosine_receptor_antagonist', 'adenylyl_cyclase_activator', 'adrenergic_receptor_agonist', 'adrenergic_receptor_antagonist', 'akt_inhibitor', 'aldehyde_dehydrogenase_inhibitor', 'alk_inhibitor', 'ampk_activator', 'analgesic', 'androgen_receptor_agonist', 'androgen_receptor_antagonist', 'anesthetic_-_local', 'angiogenesis_inhibitor', 'angiotensin_receptor_antagonist', 'anti-inflammatory', 'antiarrhythmic', 'antibiotic', 'anticonvulsant', 'antifungal', 'antihistamine', 'antimalarial', 'antioxidant', 'antiprotozoal', 'antiviral', 'apoptosis_stimulant', 'aromatase_inhibitor', 'atm_kinase_inhibitor', 'atp-sensitive_potassium_channel_antagonist', 'atp_synthase_inhibitor', 'atpase_inhibitor', 'atr_kinase_inhibitor', 'aurora_kinase_inhibitor', 'autotaxin_inhibitor', 'bacterial_30s_ribosomal_subunit_inhibitor', 'bacterial_50s_ribosomal_subunit_inhibitor', 'bacterial_antifolate', 'bacterial_cell_wall_synthesis_inhibitor', 'bacterial_dna_gyrase_inhibitor', 'bacterial_dna_inhibitor', 'bacterial_membrane_integrity_inhibitor', 'bcl_inhibitor', 'bcr-abl_inhibitor', 'benzodiazepine_receptor_agonist', 'beta_amyloid_inhibitor', 'bromodomain_inhibitor', 'btk_inhibitor', 'calcineurin_inhibitor', 'calcium_channel_blocker', 'cannabinoid_receptor_agonist', 'cannabinoid_receptor_antagonist', 'carbonic_anhydrase_inhibitor', 'casein_kinase_inhibitor', 'caspase_activator', 'catechol_o_methyltransferase_inhibitor', 'cc_chemokine_receptor_antagonist', 'cck_receptor_antagonist', 'cdk_inhibitor', 'chelating_agent', 'chk_inhibitor', 'chloride_channel_blocker', 'cholesterol_inhibitor', 'cholinergic_receptor_antagonist', 'coagulation_factor_inhibitor', 'corticosteroid_agonist', 'cyclooxygenase_inhibitor', 'cytochrome_p450_inhibitor', 'dihydrofolate_reductase_inhibitor', 'dipeptidyl_peptidase_inhibitor', 'diuretic', 'dna_alkylating_agent', 'dna_inhibitor', 'dopamine_receptor_agonist', 'dopamine_receptor_antagonist', 'egfr_inhibitor', 'elastase_inhibitor', 'erbb2_inhibitor', 'estrogen_receptor_agonist', 'estrogen_receptor_antagonist', 'faah_inhibitor', 'farnesyltransferase_inhibitor', 'fatty_acid_receptor_agonist', 'fgfr_inhibitor', 'flt3_inhibitor', 'focal_adhesion_kinase_inhibitor', 'free_radical_scavenger', 'fungal_squalene_epoxidase_inhibitor', 'gaba_receptor_agonist', 'gaba_receptor_antagonist', 'gamma_secretase_inhibitor', 'glucocorticoid_receptor_agonist', 'glutamate_inhibitor', 'glutamate_receptor_agonist', 'glutamate_receptor_antagonist', 'gonadotropin_receptor_agonist', 'gsk_inhibitor', 'hcv_inhibitor', 'hdac_inhibitor', 'histamine_receptor_agonist', 'histamine_receptor_antagonist', 'histone_lysine_demethylase_inhibitor', 'histone_lysine_methyltransferase_inhibitor', 'hiv_inhibitor', 'hmgcr_inhibitor', 'hsp_inhibitor', 'igf-1_inhibitor', 'ikk_inhibitor', 'imidazoline_receptor_agonist', 'immunosuppressant', 'insulin_secretagogue', 'insulin_sensitizer', 'integrin_inhibitor', 'jak_inhibitor', 'kit_inhibitor', 'laxative', 'leukotriene_inhibitor', 'leukotriene_receptor_antagonist', 'lipase_inhibitor', 'lipoxygenase_inhibitor', 'lxr_agonist', 'mdm_inhibitor', 'mek_inhibitor', 'membrane_integrity_inhibitor', 'mineralocorticoid_receptor_antagonist', 'monoacylglycerol_lipase_inhibitor', 'monoamine_oxidase_inhibitor', 'monopolar_spindle_1_kinase_inhibitor', 'mtor_inhibitor', 'mucolytic_agent', 'neuropeptide_receptor_antagonist', 'nfkb_inhibitor', 'nicotinic_receptor_agonist', 'nitric_oxide_donor', 'nitric_oxide_production_inhibitor', 'nitric_oxide_synthase_inhibitor', 'norepinephrine_reuptake_inhibitor', 'nrf2_activator', 'opioid_receptor_agonist', 'opioid_receptor_antagonist', 'orexin_receptor_antagonist', 'p38_mapk_inhibitor', 'p-glycoprotein_inhibitor', 'parp_inhibitor', 'pdgfr_inhibitor', 'pdk_inhibitor', 'phosphodiesterase_inhibitor', 'phospholipase_inhibitor', 'pi3k_inhibitor', 'pkc_inhibitor', 'potassium_channel_activator', 'potassium_channel_antagonist', 'ppar_receptor_agonist', 'ppar_receptor_antagonist', 'progesterone_receptor_agonist', 'progesterone_receptor_antagonist', 'prostaglandin_inhibitor', 'prostanoid_receptor_antagonist', 'proteasome_inhibitor', 'protein_kinase_inhibitor', 'protein_phosphatase_inhibitor', 'protein_synthesis_inhibitor', 'protein_tyrosine_kinase_inhibitor', 'radiopaque_medium', 'raf_inhibitor', 'ras_gtpase_inhibitor', 'retinoid_receptor_agonist', 'retinoid_receptor_antagonist', 'rho_associated_kinase_inhibitor', 'ribonucleoside_reductase_inhibitor', 'rna_polymerase_inhibitor', 'serotonin_receptor_agonist', 'serotonin_receptor_antagonist', 'serotonin_reuptake_inhibitor', 'sigma_receptor_agonist', 'sigma_receptor_antagonist', 'smoothened_receptor_antagonist', 'sodium_channel_inhibitor', 'sphingosine_receptor_agonist', 'src_inhibitor', 'steroid', 'syk_inhibitor', 'tachykinin_antagonist', 'tgf-beta_receptor_inhibitor', 'thrombin_inhibitor', 'thymidylate_synthase_inhibitor', 'tlr_agonist', 'tlr_antagonist', 'tnf_inhibitor', 'topoisomerase_inhibitor', 'transient_receptor_potential_channel_antagonist', 'tropomyosin_receptor_kinase_inhibitor', 'trpv_agonist', 'trpv_antagonist', 'tubulin_inhibitor', 'tyrosine_kinase_inhibitor', 'ubiquitin_specific_protease_inhibitor', 'vegfr_inhibitor', 'vitamin_b', 'vitamin_d_receptor_agonist', 'wnt_inhibitor']\nNUM_TARGET = len(TARGET_COL)\nsubmission = pd.read_csv('\/kaggle\/input\/lish-moa\/sample_submission.csv')\ndf = pd.read_csv(\"\/kaggle\/input\/lish-moa\/sample_submission.csv\")\n\npublic_id = list(df['sig_id'].values)\n\ndf_test = pd.read_csv('\/kaggle\/input\/lish-moa\/test_features.csv')\ntest_id = list(df_test['sig_id'].values)\n\nprivate_id = list(set(test_id)-set(public_id))\n\ndf_submit = pd.DataFrame(index = public_id+private_id, columns=TARGET_COL)\ndf_submit.index.name = 'sig_id'\ndf_submit[:] = 0\ndf_predict = BLEND.copy()\ndf_submit.loc[df_predict.sig_id,:] = df_predict[TARGET_COL].values\ndf_submit.loc[df_test[df_test.cp_type=='ctl_vehicle'].sig_id]= 0\ndf_submit.to_csv(cop+ 'submission.csv',index=True)","4d14c444":"* There are `875` features, first let's reduce the dimension using **PCA**.","ee4f2ca7":"* One hot encoding for `cp_type` and `cp_dose`.\n* `D1` == `0`, `D2`==`1`.\n* `trt_cp`== `0`, `ctl_vehicle` ==`.\n* Label encoding for`cp_time`, `0` for 24, `1` for 48 and `2` for 72.","e04cd4e7":"# Random Model","1eb9320f":"## Encoding","09cf975e":"* The most of thefeatures that start with `c-` are highly correlated.\n\n**NOTE:** If you're using all features, use tree-based model or high dropout in first (just after input) in neural-network architecture.","d95b0bba":"* There is only one column for `int64` column and `3` for the `object` datatype.\n* `cp_dose` and `cp_type` are categorical variable.\n* `cp_time` has `int64` datatype, but this one is also categorical variable. \n* Let's see the number of unique values in these columns.","1a845e27":"* There are **876** columns in `train_features.csv` file and out of these there are **875** features. \n* There are **207** labels that we need to predict for each datapoint.\n* Most of features look real-valued (continuous) and few of them look are categorical type. We'll see them detail.","089be6a9":"* Let's normalise the features, first","5b20c868":"## PCA & Correlation","5a9eacf1":"### PCA","e8d912a0":"The scores on the LB is a little fishy. Don't worry :)\n\nPlease **Upvote**, **Fork the LATEST VERSION**, run, submit, and enjoy!","5fd15266":"### Correlation","11d6b7e7":"* From above plot, it can be see that the features that starts with `c-`  looks highly correlated to each other. These are also shwoing strong correaltion with other features also.\n* Let's see the heatmap of features that starts with `c-`.","5bcc6962":"# EDA","d3806cc2":"* This will predict the random value between 0 and 1 (inclusive, i.e. 0<=prob<=1) for each label of each datapoints.\n* We'll calculate `the worst model` performance. ","9a4f9d30":"**Splitting the data**\n\n```Python\nfrom sklearn.model_selection import train_test_split\nfrom scipy.sparse import hstack\n\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.calibration import CalibratedClassifierCV\ndf_train = df1.merge(df2, on = 'sig_id')\nprint(\"shape: \", df_train.shape)\ndf_train.head()\n\ntrain, val = train_test_split(df_train, test_size = 0.2, random_state=42,\n                             stratify = df_train[\"cp_type\"])\nX_train, Y_train = df_train.iloc[:, :-206], df_train.iloc[:, -206:]\nX_val, Y_val = val.iloc[:, :-206], val.iloc[:, -206:]\n\nprint(\"Number of datapoints in train-set: {:,}\".format(len(X_train)))\nprint(\"Number of datapoints in val-set: {:,}\".format(len(X_val)))\n```","eea57dc5":"**Source:** https:\/\/www.geeksforgeeks.org\/exploring-correlation-in-python\/","5f3f2f59":"* I would always prefer high variance explained (between 95-99%). But for that, I have to take atleast 600 components.\n* 800 components are explainig the 99.41% (approx) variance.\n* Now, one can select 100, 200, 300, .... any number of features and see the performance of model.","d5ef0662":"## Data-type of features ","c2448204":"* For both variables `cp_dose` and `cp_time` number of count is almost same for all unique values present in their columns.\n* But for `cp_type` there are very data points that corresponds to `ctl_vehicle`.\n\n**NOTE:** Use stratified spliting with `cp_type` column. This will maintain the `cp_type`'s uniques values count-ratio.  "}}