{"cell_type":{"4b210738":"code","6620ce95":"code","ce7ce024":"code","4dfe0543":"code","49b5f9cb":"code","602fabc8":"code","4ad19703":"code","694397a4":"code","35317ca5":"code","b64325ee":"code","ea856606":"code","2c7fa0cf":"code","e05ecc92":"code","a5035eea":"code","8320fcea":"code","d4a46fd4":"code","15d779af":"code","07f64e71":"code","06d0f4df":"code","43ae6f58":"code","7b69c207":"code","c86432a6":"code","abce69f7":"code","f3438619":"code","970f86c7":"code","2e821357":"code","8ef97084":"code","4122d6f6":"code","19d121be":"code","cff9e615":"code","94ae47d2":"markdown","ded53e24":"markdown","48eed536":"markdown","d7e2976b":"markdown","c0749a33":"markdown","8054d733":"markdown","ad5ae6ed":"markdown","04e1fe26":"markdown","f700338d":"markdown","be0d6fae":"markdown","09d62dd1":"markdown","e0679b9f":"markdown","5a50eefe":"markdown","8d3abea9":"markdown","69899457":"markdown","64b15b12":"markdown","be7564fe":"markdown","5c4fa087":"markdown","a8ec6c9f":"markdown","d434cb05":"markdown","5eebf8e8":"markdown","9eae60f2":"markdown","490d8866":"markdown"},"source":{"4b210738":"# Directive pour afficher les graphiques dans Jupyter\n%matplotlib inline","6620ce95":"# Pandas : librairie de manipulation de donn\u00e9es\n# NumPy : librairie de calcul scientifique\n# MatPlotLib : librairie de visualisation et graphiques\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nfrom sklearn.model_selection import train_test_split\n\nfrom IPython.core.display import HTML # permet d'afficher du code html dans jupyter","ce7ce024":"from sklearn.model_selection import learning_curve\ndef plot_learning_curve(est, X_train, y_train) :\n    train_sizes, train_scores, test_scores = learning_curve(estimator=est, X=X_train, y=y_train, train_sizes=np.linspace(0.1, 1.0, 10),\n                                                        cv=5,\n                                                        n_jobs=-1)\n    train_mean = np.mean(train_scores, axis=1)\n    train_std = np.std(train_scores, axis=1)\n    test_mean = np.mean(test_scores, axis=1)\n    test_std = np.std(test_scores, axis=1)\n    plt.figure(figsize=(8,10))\n    plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='training accuracy')\n    plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n    plt.plot(train_sizes, test_mean,color='green', linestyle='--',marker='s', markersize=5,label='validation accuracy')\n    plt.fill_between(train_sizes,test_mean + test_std,test_mean - test_std,alpha=0.15, color='green')\n    plt.grid(b='on')\n    plt.xlabel('Number of training samples')\n    plt.ylabel('Accuracy')\n    plt.legend(loc='lower right')\n    plt.ylim([0.6, 1.0])\n    plt.show()","4dfe0543":"def plot_roc_curve(est,X_test,y_test) :\n    probas = est.predict_proba(X_test)\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,probas[:, 1])\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    plt.figure(figsize=(8,8))\n    plt.title('Receiver Operating Characteristic')\n    plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.2f'% roc_auc)\n    plt.legend(loc='lower right')\n    plt.plot([0,1],[0,1],'r--')        # plus mauvaise courbe\n    plt.plot([0,0,1],[0,1,1],'g:')     # meilleure courbe\n    plt.xlim([-0.05,1.2])\n    plt.ylim([-0.05,1.2])\n    plt.ylabel('Taux de vrais positifs')\n    plt.xlabel('Taux de faux positifs')\n    plt.show","49b5f9cb":"df = pd.read_csv(\"..\/input\/mnist-in-csv\/mnist_test.csv\")","602fabc8":"df.shape","4ad19703":"df.head(10)","694397a4":"y = df['label']","35317ca5":"X = df.drop(['label'], axis=1)","b64325ee":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","ea856606":"X1 = np.array(X)","2c7fa0cf":"print(X1[0])","e05ecc92":"image = X1[0].reshape(28,28)\nprint(image)","a5035eea":"plt.imshow(image)","8320fcea":"plt.imshow(image, cmap=\"gray_r\")\nplt.axis('off')\nplt.title(y[0])","d4a46fd4":"n_samples = len(df.index)\nimages = X1.reshape(n_samples,28,28)","15d779af":"plt.figure(figsize=(10,20))\nfor i in range(0,49) :\n    plt.subplot(10,5,i+1)\n    plt.axis('off')\n    plt.imshow(images[i], cmap=\"gray_r\")\n    plt.title(y[i])","07f64e71":"from sklearn import ensemble\nrf = ensemble.RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_rf = rf.predict(X_test)","06d0f4df":"plot_learning_curve(rf, X, y)","43ae6f58":"print(classification_report(y_test, y_rf))","7b69c207":"cm = confusion_matrix(y_test, y_rf)\nprint(cm)","c86432a6":"# All imports\nimport xgboost as XGB\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_val_score, KFold\nimport pandas as pd\nimport numpy as np","abce69f7":"# \nxgb = XGB.XGBClassifier()","f3438619":"# Fit the regressor to the training set and make predictions on the test set\nxgb.fit(X_train, y_train)\ny_xgb = xgb.predict(X_test)","970f86c7":"pd.crosstab(y_test, y_xgb, rownames=['Reel'], colnames=['Prediction'], margins=True)","2e821357":"print(classification_report(y_test, y_xgb))","8ef97084":"scores = cross_val_score(xgb, X_train, y_train, cv = 2)\nprint(scores.mean())","4122d6f6":"#kfold = KFold(n_splits = 10, shuffle = True)\n#kf_cv_scores = cross_val_score(xgb, X_train, y_train, cv = kfold )\n#print(kf_cv_scores.mean())","19d121be":"y_pred = xgb.predict(X_test)\nprint(classification_report(y_test, y_pred))","cff9e615":"cm = confusion_matrix(y_test,y_pred)\nprint(cm)","94ae47d2":"et les caract\u00e9ristiques X :","ded53e24":"## Librairies et fonctions utiles","48eed536":"en niveaux de gris, sans graduation des axes, et avec le label comme titre :","d7e2976b":"## Random Forest Classifier","c0749a33":"Fonction pour tracer les courbes d'apprentissage sur l'ensemble d'apprentissage et l'ensemble de validation :","8054d733":"## Le dataset de chiffres manuscrits MNIST","ad5ae6ed":"On affiche les 50 premiers :","04e1fe26":"On charge le dataset MNIST :","f700338d":"## Xgboost","be0d6fae":"On peut maintenant afficher cette matrice :","09d62dd1":"On cr\u00e9e la cible y (colonne 'label') :","e0679b9f":"## Visualisation des images MNIST","5a50eefe":"Fonction pour tracer la courbe ROC :","8d3abea9":"# Reconnaissance de chiffres manuscrits : MNIST","69899457":"### Exercice : tester Xgboost","64b15b12":"# Machine learning","be7564fe":"On a 785 colonnes :\n* une colonne 'label' identifiant le chiffre  \n* et 784 colonnes de pixels (image de 28x28 pixels \"aplatie\")","5c4fa087":"On peut maintenant appliquer les m\u00e9thodes de machine learning, mais auparavant on va visualiser les images","a8ec6c9f":"On applique la m\u00e9thode **reshape** pour convertir cette ligne de 784 \u00e9l\u00e9ments en une matrice 28x28 :","d434cb05":"On redimensionne toutes les lignes :","5eebf8e8":"On s\u00e9pare les ensembles d'apprentissage et de test :","9eae60f2":"On affiche la premi\u00e8re ligne :","490d8866":"Pour visualiser les images, on va convertir une ligne de 784 pixels en une matrice 28x28  \nIl faut en premier transformer le dataframe X en un tableau :"}}