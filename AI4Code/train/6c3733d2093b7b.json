{"cell_type":{"9c5e2786":"code","5efb5df6":"code","82255ffb":"code","f7eda134":"code","deb941b9":"code","5de66ac8":"code","bc035810":"code","651f7a80":"code","fdd92c90":"code","4aebf985":"code","9157be0e":"code","c5d8e695":"code","488a4295":"code","f3c0e05d":"code","9fb944f6":"code","974078d1":"code","d064483d":"code","8d31523c":"code","648f4de8":"code","f0e889d5":"code","e32db404":"code","f8f703bd":"code","b01ac62c":"code","b33834e4":"code","6bf2dce2":"code","bf5e18a1":"code","de4a5354":"code","637c8c7c":"code","518cc49c":"code","1155b457":"code","3ca31059":"code","3573a92c":"code","4cf21f01":"code","6b56eb49":"code","0ea139ab":"code","f66ce26a":"code","a294645a":"code","90621664":"code","95dbb6ff":"code","afba0a62":"code","c32ae10a":"code","4e515b01":"code","942803c6":"markdown","76f6aff2":"markdown","ca064428":"markdown","2f6f9c98":"markdown","71cecb30":"markdown","999592c9":"markdown","1d5eabec":"markdown","e5abe6bc":"markdown","3186ec93":"markdown","41b157b3":"markdown","c328f3c8":"markdown","cb2e5255":"markdown","9a33515c":"markdown","661663a6":"markdown","690f245d":"markdown","cd1f7d7e":"markdown","4c93ba4c":"markdown","b8aa4c6a":"markdown"},"source":{"9c5e2786":"from glob import glob\nimport os\nimport pandas as pd\nimport numpy as np\nimport re\nfrom PIL import Image\nimport seaborn as sns\nfrom random import randrange\n\nfrom albumentations import (\n    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, RandomBrightnessContrast, IAAPiecewiseAffine,\n    IAASharpen, IAAEmboss, Flip, OneOf, Compose, PadIfNeeded, RandomGamma\n)\n#checnking the input files\nprint(os.listdir(\"..\/input\/rsna-intracranial-hemorrhage-detection\/\"))","5efb5df6":"#reading all dcm files into train and text\ntrain = sorted(glob(\"..\/input\/rsna-intracranial-hemorrhage-detection\/stage_1_train_images\/*.dcm\"))\ntest = sorted(glob(\"..\/input\/rsna-intracranial-hemorrhage-detection\/stage_1_test_images\/*.dcm\"))\nprint(\"train files: \", len(train))\nprint(\"test files: \", len(test))\n\npd.reset_option('max_colwidth')","82255ffb":"train_df = pd.read_csv('..\/input\/rsna-intracranial-hemorrhage-detection\/stage_1_train.csv')","f7eda134":"stage_1_sample_submission = pd.read_csv('..\/input\/rsna-intracranial-hemorrhage-detection\/stage_1_sample_submission.csv') ","deb941b9":"import pydicom\nimport matplotlib.pyplot as plt\n\n#displaying the image\nimg = pydicom.read_file(train[0]).pixel_array\nplt.imshow(img, cmap=plt.cm.bone)\nplt.grid(False)\n\n#displaying metadata\ndata = pydicom.dcmread(train[0])\nprint(data)","5de66ac8":"# visualize pie chart\nlabels = 'Train', 'Test'\nsizes = [len(train), len(test)]\nexplode = (0, 0.1)  # \"explode\" the 2nd slice\n\nfig, ax = plt.subplots(figsize=(7,7))\nax.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\nplt.title(\"Number of images in train\/test sets\")\nplt.show()","bc035810":"#train_df['ID'].str.find('_', 3) \ntrain_df['image'] = train_df['ID'].str.slice(stop=12)\ntrain_df['diagnosis'] = train_df['ID'].str.slice(start=13)","651f7a80":"train_df.head(6)","fdd92c90":"train_df.groupby('diagnosis').sum().plot(kind='bar',figsize = (10, 5));\nplt.title('Class counts');","4aebf985":"image_lable = train_df.groupby('image').sum()","9157be0e":"image_lable['Label'].value_counts().plot(kind='bar',figsize = (10, 5));\nplt.title('Number of people with different class of Hemorrhage');","c5d8e695":"image_lable = train_df.query('diagnosis!=\"any\"').groupby('image').sum()","488a4295":"image_lable['Label'].value_counts().plot(kind='bar',figsize = (10, 5));\nplt.title('Class with labels');","f3c0e05d":"TRAIN_IMG_PATH = \"..\/input\/rsna-intracranial-hemorrhage-detection\/stage_1_train_images\/\"\nTEST_IMG_PATH = \"..\/input\/rsna-intracranial-hemorrhage-detection\/stage_1_test_images\/\"\n\ndef view_images(images, title = '', aug = None):\n    width = 5\n    height = 2\n    fig, axs = plt.subplots(height, width, figsize=(15,5))\n    \n    for im in range(0, height * width):\n        image = pydicom.read_file(os.path.join(TRAIN_IMG_PATH,images[im]+ '.dcm')).pixel_array\n        i = im \/\/ width\n        j = im % width\n        axs[i,j].imshow(image, cmap=plt.cm.bone) \n        axs[i,j].axis('off')\n        \n    plt.suptitle(title)\n    plt.show()","9fb944f6":"view_images(train_df[(train_df['diagnosis'] == 'epidural') & (train_df['Label'] == 1)][:10].image.values, title = 'Images with epidural')","974078d1":"view_images(train_df[(train_df['diagnosis'] == 'intraparenchymal') & (train_df['Label'] == 1)][:10].image.values, title = 'Images with intraparenchymal')","d064483d":"view_images(train_df[(train_df['diagnosis'] == 'intraventricular')& (train_df['Label'] == 1)][:10].image.values, title = 'Images with intraventricular')","8d31523c":"view_images(train_df[(train_df['diagnosis'] == 'subarachnoid')& (train_df['Label'] == 1)][:10].image.values, title = 'Images with subarachnoid')","648f4de8":"view_images(train_df[(train_df['diagnosis'] == 'subdural') & (train_df['Label'] == 1)][:10].image.values, title = 'Images with subarachnoid')","f0e889d5":"def get_image_sizes(df, train = True):\n    if train:\n        path = TRAIN_IMG_PATH\n    else:\n        path = TEST_IMG_PATH\n        \n    widths = []\n    heights = []\n    \n    images = df.image.values\n    #print(images)\n    max_im = pydicom.read_file(os.path.join(path,images[0]+ '.dcm')).pixel_array\n    min_im = pydicom.read_file(os.path.join(path,images[0]+ '.dcm')).pixel_array\n        \n    for im in range(0, len(images)):\n        image = pydicom.read_file(os.path.join(path,images[im]+ '.dcm')).pixel_array\n        \n        width = image.shape[0]\n        height = image.shape[1]\n        \n        if len(widths) > 0:\n            if width > max(widths):\n                max_im = image\n\n            if width < min(widths):\n                min_im = image\n\n        widths.append(width)\n        heights.append(height)\n        \n    return widths, heights, max_im, min_im","e32db404":"stage_1_sample_submission['image'] = stage_1_sample_submission['ID'].str.slice(stop=12)\nstage_1_sample_submission['diagnosis'] = stage_1_sample_submission['ID'].str.slice(start=13)","f8f703bd":"stage_1_sample_submission.shape","b01ac62c":"train_df.shape","b33834e4":"train_df_d = train_df.drop_duplicates(subset='image')","6bf2dce2":"train_df_d.shape","bf5e18a1":"stage_1_sample_submission_d = stage_1_sample_submission.drop_duplicates(subset='image')","de4a5354":"stage_1_sample_submission_d.shape","637c8c7c":"train_widths, train_heights, max_train, min_train = get_image_sizes(train_df_d.sample(10000), train = True)\ntest_widths, test_heights, max_test, min_test = get_image_sizes(stage_1_sample_submission_d.sample(10000), train = False)","518cc49c":"print('Maximum width for training set is {}'.format(max(train_widths)))\nprint('Minimum width for training set is {}'.format(min(train_widths)))\nprint('Maximum height for training set is {}'.format(max(train_heights)))\nprint('Minimum height for training set is {}'.format(min(train_heights)))","1155b457":"print('Maximum width for test set is {}'.format(max(test_widths)))\nprint('Minimum width for test set is {}'.format(min(test_widths)))\nprint('Maximum height for test set is {}'.format(max(test_heights)))\nprint('Minimum height for test set is {}'.format(min(test_heights)))","3ca31059":"plt.figure(figsize=(14,6))\nplt.subplot(121)\nsns.distplot(train_widths, kde=False, label='Train Width')\nsns.distplot(train_heights, kde=False, label='Train Height')\nplt.legend()\nplt.title('Training Image Dimension Histogram', fontsize=15)\n\nplt.subplot(122)\nsns.kdeplot(train_widths, label='Train Width')\nsns.kdeplot(train_heights, label='Train Height')\nplt.legend()\nplt.title('Train Image Dimension KDE Plot', fontsize=15)\n\nplt.tight_layout()\nplt.show()","3573a92c":"plt.figure(figsize=(14,6))\nplt.subplot(121)\nsns.distplot(test_widths, kde=False, label='Test Width')\nsns.distplot(test_heights, kde=False, label='Test Height')\nplt.legend()\nplt.title('Test Image Dimension Histogram', fontsize=15)\n\nplt.subplot(122)\nsns.kdeplot(test_widths, label='Test Width')\nsns.kdeplot(test_heights, label='Test Height')\nplt.legend()\nplt.title('Test Image Dimension KDE Plot', fontsize=15)\n\nplt.tight_layout()\nplt.show()","4cf21f01":"plt.axis('off')\nplt.imshow(max_train, cmap=plt.cm.bone) #plot the data","6b56eb49":"plt.axis('off')\nplt.imshow(min_train, cmap=plt.cm.bone) #plot the data","0ea139ab":"# get some random image indices from the training set\nrand_indices = [randrange(len(train_df_d)) for x in range(0,10)]\nrand_indices","f66ce26a":"def view_aug_images(train, rand_indices, aug = None, title = ''):\n    width = 5\n    height = 2\n    counter = 0\n    fig, axs = plt.subplots(height, width, figsize=(15,5))\n    \n    for im in rand_indices:\n        image = pydicom.read_file(os.path.join(TRAIN_IMG_PATH,train.iloc[im].image+ '.dcm')).pixel_array\n        if aug is not None:\n            image = aug(image=np.array(image))['image']\n        \n        i = counter \/\/ width\n        j = counter % width\n        axs[i,j].imshow(image, cmap=plt.cm.bone) #plot the data\n        axs[i,j].axis('off')\n        \n        diagnosis = train[train['image'] == train.iloc[im].image].diagnosis.values[0]\n        \n        axs[i,j].set_title(diagnosis)\n        counter += 1\n\n    plt.suptitle(title)\n    plt.show()","a294645a":"view_aug_images(train_df_d, rand_indices, title = 'Original images')","90621664":"aug = GaussNoise(p=1)\nview_aug_images(train_df_d, rand_indices, aug, title= 'GaussNoise')","95dbb6ff":"aug = RandomBrightnessContrast(brightness_limit=1, contrast_limit=1, p = 1)\nview_aug_images(train_df_d, rand_indices, aug, title = 'RandomBrightnessContrast')","afba0a62":"aug = RandomGamma(gamma_limit=[80,120], p = 1)\nview_aug_images(train_df_d, rand_indices, aug, title = 'RandomGamma')","c32ae10a":"aug = GridDistortion(num_steps =5, distort_limit=[-0.3,0.3], interpolation=1, border_mode= 4, p = 1)\nview_aug_images(train_df_d, rand_indices, aug, title = 'GridDistortion')","4e515b01":"aug = OpticalDistortion(shift_limit =[-0.5, 0.5], distort_limit=[-2,2], interpolation=1, border_mode= 4, p = 1)\nview_aug_images(train_df_d, rand_indices, aug, title = 'OpticalDistortion')","942803c6":"Visualize Sample Images with different diagnosis","76f6aff2":"# Basic EDA + albumentations augs","ca064428":"A lot of images, let's take some sample - 10000","2f6f9c98":"## Explore Data","71cecb30":"Drop images duplicates ","999592c9":"## Load Data","1d5eabec":"## Conclusion","e5abe6bc":"## Augmentations by albumentations","3186ec93":"We see that we have some different distributions of image sizes for sample of train datasets.","41b157b3":"## Analyze Image Sizes","c328f3c8":"Explore the number of examples in train and test sets:","cb2e5255":"1. The dataset is imbalanced. \n1. Need to play with data augmentation\n1. The distribution of sizes of images from train and test sets is small different\n","9a33515c":"baseline model is ongoing ...","661663a6":"Transform the dataset to devote the number of diagnoses","690f245d":"\"Any\" occurs in anyone who has even one of the diagnoses. Remove it.","cd1f7d7e":"### Plot largest and smallest images","4c93ba4c":"This is very good, but let's look at the number of people with different class of Hemorrhage","b8aa4c6a":"## Visualize Sample Images"}}