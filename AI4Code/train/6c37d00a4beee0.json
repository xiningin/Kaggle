{"cell_type":{"48e28bea":"code","c0cdebc3":"code","0a265cf9":"code","e6ae8351":"code","b366738c":"code","fbb91df2":"code","7b4d4077":"code","d63bcf36":"code","031dee2a":"code","8fcc9324":"code","12d27a7f":"code","3de214a8":"code","8126d589":"code","affc63a1":"code","e09c25db":"code","12c8f77e":"code","e42fb638":"code","990ad15d":"code","09a1caf5":"code","d38952f0":"code","532fb5eb":"code","2d6c1558":"code","799bc612":"code","00d08d8d":"code","8dd106fd":"code","1e3ff1d0":"code","392154bd":"code","a8189d0f":"code","da204369":"code","4e5f390a":"code","cd26d57b":"markdown","33b3523d":"markdown"},"source":{"48e28bea":"import os\nimport cv2\nimport random\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, cohen_kappa_score\nfrom keras.models import Model\nfrom keras import optimizers, applications\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import InputLayer, BatchNormalization, Dropout, Flatten, Dense, Activation, MaxPool2D, Conv2D\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.utils import to_categorical\nfrom keras import optimizers\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.callbacks import Callback,ModelCheckpoint,ReduceLROnPlateau\nfrom keras.models import Sequential,load_model\nfrom keras.layers import Dense, Dropout\nfrom keras.wrappers.scikit_learn import KerasClassifier\nimport keras.backend as K\n#import tensorflow_addons as tfa\n#from tensorflow.keras.metrics import Metric\n#from tensorflow_addons.utils.types import AcceptableDTypes, FloatTensorLike\nfrom typeguard import typechecked\nfrom typing import Optional\n%matplotlib inline\nsns.set(style=\"whitegrid\")\nwarnings.filterwarnings(\"ignore\")","c0cdebc3":"train = pd.read_csv('..\/input\/aptos2019-blindness-detection\/train.csv')\ntest = pd.read_csv('..\/input\/aptos2019-blindness-detection\/test.csv')\nsubmission= pd.read_csv('..\/input\/aptos2019-blindness-detection\/sample_submission.csv')","0a265cf9":"print('Number of train samples: ', train.shape[0])\nprint('Number of test samples: ', test.shape[0])\ndisplay(train.head())","e6ae8351":"import pandas_profiling as pp\npp.ProfileReport(train)","b366738c":"f, ax = plt.subplots(figsize=(14, 5))\nax = sns.countplot(x=\"diagnosis\", data=train, palette=\"Set2\")\nsns.despine()\nplt.show()","fbb91df2":"sns.set_style(\"white\")\ncount = 1\nplt.figure(figsize=[15, 15])\nfor img_name in train['id_code'][:15]:\n    img = cv2.imread(\"..\/input\/aptos2019-blindness-detection\/train_images\/%s.png\" % img_name)[...,[2, 1, 0]]\n    plt.subplot(5, 5, count)\n    plt.imshow(img)\n    plt.title(\"Image %s\" % count)\n    count += 1\n    \nplt.show()","7b4d4077":"N_CLASSES = train['diagnosis'].nunique()\nN_CLASSES","d63bcf36":"# Preprocecss data\ntrain[\"id_code\"] = train[\"id_code\"].apply(lambda x: x + \".png\")\ntest[\"id_code\"] = test[\"id_code\"].apply(lambda x: x + \".png\")\ntrain['diagnosis'] = train['diagnosis'].astype('str')\ntrain.head()","031dee2a":"train_datagen=ImageDataGenerator(rescale=1.\/255, \n                                 validation_split=0.2,\n                                 horizontal_flip=True)\n\ntrain_generator=train_datagen.flow_from_dataframe(\n    dataframe=train,\n    directory=\"..\/input\/aptos2019-blindness-detection\/train_images\/\",\n    x_col=\"id_code\",\n    y_col=\"diagnosis\",\n    batch_size=16,\n    class_mode=\"categorical\",\n    target_size=(224, 224),\n    subset='training')\n","8fcc9324":"valid_generator=train_datagen.flow_from_dataframe(\n    dataframe=train,\n    directory=\"..\/input\/aptos2019-blindness-detection\/train_images\/\",\n    x_col=\"id_code\",\n    y_col=\"diagnosis\",\n    batch_size=16,\n    class_mode=\"categorical\",    \n    target_size=(224, 224),\n    subset='validation')\n","12d27a7f":"test_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntest_generator = test_datagen.flow_from_dataframe(  \n        dataframe=test,\n        directory = \"..\/input\/aptos2019-blindness-detection\/test_images\/\",\n        x_col=\"id_code\",\n        target_size=(224, 224),\n        batch_size=16,\n        shuffle=False,\n        class_mode=None)","3de214a8":"base_model = tf.keras.applications.ResNet152V2(input_shape=(224,224,3),include_top=False,weights=\"imagenet\")","8126d589":"# Freezing Layers\n\nfor layer in base_model.layers[:-10]:\n    layer.trainable=False","affc63a1":"# Building Model\n\nmodel=Sequential()\nmodel.add(base_model)\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dense(256,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(128,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(32,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dense(5,activation='softmax'))","e09c25db":"# Model Summary\n\nmodel.summary()\n","12c8f77e":"from tensorflow.keras.utils import plot_model\nfrom IPython.display import Image\nplot_model(model, to_file='convnet.png', show_shapes=True,show_layer_names=True)\nImage(filename='convnet.png')","e42fb638":"def f1_score(y_true, y_pred): #taken from old keras source code\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    recall = true_positives \/ (possible_positives + K.epsilon())\n    f1_val = 2*(precision*recall)\/(precision+recall+K.epsilon())\n    return f1_val\n","990ad15d":"METRICS = [\n      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n      tf.keras.metrics.Precision(name='precision'),\n      tf.keras.metrics.Recall(name='recall'),  \n      tf.keras.metrics.AUC(name='auc'),\n        f1_score,\n]","09a1caf5":"lrd = ReduceLROnPlateau(monitor = 'val_loss',patience = 2,verbose = 1,factor = 0.8, min_lr = 1e-6)\n\nmcp = ModelCheckpoint('ResNet152V2.h5')\n\nes = EarlyStopping(verbose=1, patience=2)","d38952f0":"model.compile(optimizer='Adam', loss=\"categorical_crossentropy\", metrics=METRICS)","532fb5eb":"STEP_SIZE_TRAIN = train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VALID = valid_generator.n\/\/valid_generator.batch_size","2d6c1558":"print(STEP_SIZE_TRAIN)\nprint(STEP_SIZE_VALID)","799bc612":"%time\nhistory = model.fit_generator(generator=train_generator,steps_per_epoch=STEP_SIZE_TRAIN,validation_data=valid_generator,validation_steps=STEP_SIZE_VALID,epochs=10,callbacks=[lrd,mcp,es])","00d08d8d":"complete_datagen = ImageDataGenerator(rescale=1.\/255)\ncomplete_generator = complete_datagen.flow_from_dataframe(  \n        dataframe=train,\n        directory = \"..\/input\/aptos2019-blindness-detection\/train_images\/\",\n        x_col=\"id_code\",\n        target_size=(224, 224),\n        batch_size=1,\n        shuffle=False,\n        class_mode=None)","8dd106fd":"STEP_SIZE_COMPLETE = complete_generator.n\/\/complete_generator.batch_size\ntrain_preds = model.predict_generator(complete_generator, steps=STEP_SIZE_COMPLETE)\ntrain_preds = [np.argmax(pred) for pred in train_preds]","1e3ff1d0":"labels = ['0 - No DR', '1 - Mild', '2 - Moderate', '3 - Severe', '4 - Proliferative DR']\ncnf_matrix = confusion_matrix(train['diagnosis'].astype('int'), train_preds)\ncnf_matrix_norm = cnf_matrix.astype('float') \/ cnf_matrix.sum(axis=1)[:, np.newaxis]\ndf_cm = pd.DataFrame(cnf_matrix_norm, index=labels, columns=labels)\nprint(df_cm.describe().T)\nplt.figure(figsize=(15, 8))\nsns.heatmap(df_cm, annot=True, fmt='.2f')\nplt.show()","392154bd":"df_cm.head(5)","a8189d0f":"print(\"Train Cohen Kappa score: %.3f\" % cohen_kappa_score(train_preds, train['diagnosis'].astype('int'), weights='quadratic'))","da204369":"test_generator.reset()\nSTEP_SIZE_TEST = test_generator.n\/\/test_generator.batch_size\npreds = model.predict_generator(test_generator, steps=STEP_SIZE_TEST)\npredictions = [np.argmax(pred) for pred in preds]\npredictions[:10]","4e5f390a":"filenames = test_generator.filenames\nresults = pd.DataFrame(['id_code',filenames, 'diagnosis',predictions])\nresults.to_csv('submission.csv',index=False)\nresults.head(5).T","cd26d57b":"### Files\nIn a synchronous Kernels-only competition, the files you can observe and download will be different than the private test set and sample submission. The files may have different ids, may be a different size, and may vary in other ways, depending on the problem. You should structure your code so that it returns predictions for the public test set images in the format specified by the public sample_submission.csv, but does not hard code aspects like the id or number of rows. When Kaggle runs your Kernel privately, it substitutes the private test set and sample submission in place of the public ones. You can plan on the private test set consisting of 20GB of data across 13,000 images (approximately).\n\n\n<img src=\"https:\/\/storage.googleapis.com\/kaggle-media\/competitions\/general\/public_vs_private.png\" width=\"700px\">\n\n\n\n\n\n* train.csv - the training labels\n* test.csv - the test set (you must predict the diagnosis value for these variables)\n* sample_submission.csv - a sample submission file in the correct format\n* train.zip - the training set images\n* test.zip - the public test set images\n\n#### Dataset Link \n\n##### [Here](https:\/\/www.kaggle.com\/c\/aptos2019-blindness-detection\/data)\n\n\n","33b3523d":"\n<h1 style='background-color:#D3D3D3; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;' > APTOS Blindness Detection with ResNet152V2 <\/h1>\n\n<img src=\"https:\/\/www.researchgate.net\/profile\/Ankan-Ghosh-Dastider\/publication\/347866283\/figure\/fig2\/AS:973637188321282@1609144603815\/Architecture-of-the-proposed-classification-network-ResCovNet-ResNet152V2-has-been-used.ppm\" width=\"800px\">\n"}}