{"cell_type":{"c2e1d568":"code","4f3c2a79":"code","2cb8d38d":"code","859fd563":"code","6133a8d6":"code","61a2e797":"code","18d8b491":"code","dee89993":"code","51e8a5df":"code","e68bd80c":"code","6a363e3b":"code","3461e732":"code","e2e457f0":"code","e2e5d807":"code","f7faae2c":"code","044f863c":"code","0672c082":"code","07632e4f":"code","a123f318":"code","e192a8be":"code","71a48e2e":"markdown","0bf30375":"markdown","e895d703":"markdown","29b93db4":"markdown","daf05c93":"markdown"},"source":{"c2e1d568":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport random\n\nfrom matplotlib.lines import Line2D\n\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.impute import SimpleImputer\n\nimport optuna\n\n# Pandas setting to display more dataset rows and columns\npd.set_option('display.max_rows', 100)\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_colwidth', None)\npd.set_option('display.float_format', lambda x: '%.5f' % x)\n\n# import warnings\n# warnings.simplefilter(action='ignore', category=UserWarning)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('..\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4f3c2a79":"# Read the data\ntrain = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/train.csv', index_col='id')\ntest = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/test.csv', index_col='id')\nsample = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv', index_col='id')","2cb8d38d":"print(\"(train, test) na --> \",(train.isna().sum().sum(), test.isna().sum().sum()))","859fd563":"is_na_train_df = train.drop(columns=\"claim\").isna().sum(axis = 1)\nprint(is_na_train_df.shape)\n\nis_na_test_df = test.isna().sum(axis = 1)\nprint(is_na_test_df.shape)","6133a8d6":"x_Mm_scaler = MinMaxScaler()\nX = pd.DataFrame(x_Mm_scaler.fit_transform(train.drop(\"claim\", axis=1)),\n                 columns=train.drop(\"claim\", axis=1).columns)\ny = train.claim\nX_test = pd.DataFrame(x_Mm_scaler.transform(test), columns=test.columns)","61a2e797":"imputer_zeros = SimpleImputer(strategy=\"median\")\nX = pd.DataFrame(imputer_zeros.fit_transform(train.drop(\"claim\", axis=1)),\n                 columns=train.drop(\"claim\", axis=1).columns)\nX_test = pd.DataFrame(imputer_zeros.transform(test), columns=test.columns)\nX = pd.DataFrame(x_Mm_scaler.fit_transform(X),\n                 columns=train.drop(\"claim\", axis=1).columns)\nX_test = pd.DataFrame(x_Mm_scaler.transform(X_test), columns=test.columns)\nprint(\"(train, test) na --> \",(X.isna().sum().sum(), X_test.isna().sum().sum()))","18d8b491":"X[\"isNA\"] =is_na_train_df\nprint(X.shape)\nX_test[\"isNA\"] = is_na_test_df\nprint(X_test.shape)","dee89993":"import matplotlib.pyplot as pyplt\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc","51e8a5df":"def train_model_optuna_xgb(trial, X_train, X_valid, y_train, y_valid):\n    \"\"\"\n    A function to train a model using different hyperparamerters combinations provided by Optuna. \n    Loss of validation data predictions is returned to estimate hyperparameters effectiveness.\n    \"\"\"\n    preds = 0\n       \n    #A set of hyperparameters to optimize by optuna\n    xgb_params = {\n                 \"n_estimators\": trial.suggest_categorical('n_estimators', [10000]),\n                 \"learning_rate\": trial.suggest_float('learning_rate', 0.01, 0.8),\n                 \"subsample\": trial.suggest_float('subsample', 0.5, 0.95),\n                 \"colsample_bytree\": trial.suggest_float('colsample_bytree', 0.5, 0.95),\n                 \"max_depth\": trial.suggest_int(\"max_depth\", 5, 16),\n                 \"booster\": trial.suggest_categorical('booster', [\"gbtree\"]),\n                 \"tree_method\": trial.suggest_categorical('tree_method', [\"gpu_hist\"]),\n                 \"reg_lambda\": trial.suggest_float('reg_lambda', 2, 100),\n                 \"reg_alpha\": trial.suggest_float('reg_alpha', 1, 50),\n                 \"random_state\": trial.suggest_categorical('random_state', [42]),\n                 \"n_jobs\": trial.suggest_categorical('n_jobs', [4]),\n                    }\n\n    # Model loading and training\n    model = XGBClassifier(**xgb_params)\n    model.fit(X_train, y_train,\n              eval_set=[(X_train, y_train), (X_valid, y_valid)],\n              eval_metric=\"rmse\",\n              early_stopping_rounds=100,\n              verbose=False)\n    \n    print(f\"Number of boosting rounds: {model.best_iteration}\")\n    oof = model.predict(X_valid)\n    oof[oof<0] = 0\n    \n    return np.sqrt(mean_squared_error(y_valid, oof))","e68bd80c":"%%time\n\nskf = StratifiedKFold(n_splits=6, shuffle=True, random_state=42)\n\nfor fold, (train_indicies, valid_indicies) in enumerate(skf.split(X,y)):\n    \n    X_train, X_valid = X.loc[train_indicies], X.loc[valid_indicies]\n    y_train, y_valid = y.loc[train_indicies], y.loc[valid_indicies]\n\n# Setting optuna verbosity to show only warning messages\n# If the line is uncommeted each iteration results will be shown\noptuna.logging.set_verbosity(optuna.logging.WARNING)\ntime_limit = 3600 * 2\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(lambda trial: train_model_optuna_xgb(trial, \n                                                X_train, \n                                                X_valid,\n                                                y_train, \n                                                y_valid),\n               n_trials = 100,\n               timeout=time_limit\n              )\n # Showing optimization results\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial parameters:', study.best_trial.params)\nprint('Best score:', study.best_value)\n","6a363e3b":"xgb_params = study.best_params","3461e732":"%%time\nsplits = 6\nskf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=42)\noof_preds = np.zeros((X.shape[0],))\npreds = 0\nmodel_fi = 0\ntotal_mean_rmse = 0\n\nfor fold, (train_indicies, valid_indicies) in enumerate(skf.split(X,y)):\n    \n    X_train, X_valid = X.loc[train_indicies], X.loc[valid_indicies]\n    y_train, y_valid = y.loc[train_indicies], y.loc[valid_indicies]\n    print(fold, f\"X_train = {X_train.shape} - y_train: {y_train.shape}\")\n    print(fold, f\"X_valid = {X_valid.shape} - y_valid: {y_valid.shape}\")\n    model = XGBClassifier(**xgb_params)\n    model.fit(X_train, y_train,\n              eval_set=[(X_train, y_train), (X_valid, y_valid)],\n              eval_metric=\"auc\",\n              early_stopping_rounds=100,\n              verbose=False)\n    print(\"fitted\")\n    preds += model.predict(X_test) \/ splits\n    print(preds.shape)\n    print(\"preds ok\")\n    model_fi += model.feature_importances_\n    print(\"model_fi ok\")\n    oof_preds[valid_indicies] = model.predict(X_valid)\n    print(oof_preds)\n    oof_preds[oof_preds < 0] = 0\n#     fold_rmse = np.sqrt(mean_squared_error(y_scaler.inverse_transform(np.array(y_valid).reshape(-1,1)), y_scaler.inverse_transform(np.array(oof_preds[valid_idx]).reshape(-1,1))))\n    fold_rmse = np.sqrt(mean_squared_error(y_valid, oof_preds[valid_indicies]))\n    print(f\"Fold {fold} RMSE: {fold_rmse}\")\n#         print(f\"Trees: {model.tree_count_}\")\n    total_mean_rmse += fold_rmse \/ splits\nprint(f\"\\nOverall RMSE: {total_mean_rmse}\")","e2e457f0":"# xgb public Score untuned and fast parameters: 0.76817\npredictions = pd.DataFrame()\npredictions[\"id\"] = test.index\npredictions[\"claim\"] = preds\n\npredictions.to_csv('submission_xgb_optimized.csv', index=False, header=predictions.columns)\npredictions.head()","e2e5d807":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n# Define the model\n","f7faae2c":"#Function for plotting Confusion Matrix\n\n\ndef plot_confusion_matrix(cm, classes,\n                        normalize=False,\n                        title='Confusion matrix',\n                        cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix')\n\n    print(cm)\n\n    thresh = cm.max() \/ 2.\n    for i in range (cm.shape[0]):\n        for j in range (cm.shape[1]):\n            plt.text(j, i, cm[i, j],\n            horizontalalignment=\"center\",\n            color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","044f863c":"#Feeding parameters in the CM Function\n\ncm = confusion_matrix(y_true=y, y_pred=oof_preds)","0672c082":"len(oof_preds)","07632e4f":"#Labels for the CM\n\ncm_plot_labels = ['Negative','Positive']","a123f318":"#Plotting the CM\n\nplot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')","e192a8be":"from sklearn.metrics import roc_curve, auc #for model evaluation\ny_true=y\ny_pred=oof_preds\nfpr, tpr, thresholds = roc_curve(y_true, y_pred)\n\nfig, ax = plt.subplots()\nax.plot(fpr, tpr)\nax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for TPS 09')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)","71a48e2e":"# NA values in train and test","0bf30375":"# Final considerations:\nThis are the results of the simulation :<br>","e895d703":"# Libraries and Data import","29b93db4":"## Data preparation: Siple Imputer + NA to median","daf05c93":"Hello everybody."}}