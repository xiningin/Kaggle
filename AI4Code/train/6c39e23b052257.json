{"cell_type":{"3ba33d2f":"code","a7f709f5":"code","d02b440d":"code","9f71a454":"code","f4b500a2":"code","59b26c39":"code","0504ccf1":"code","f1768aea":"code","99392a00":"code","52a48541":"code","72714792":"code","e3be22d6":"code","ca701ff0":"code","ac8996e0":"code","33059432":"code","2fe218af":"code","5335b6bd":"code","d35e0337":"code","979ab849":"code","0de46522":"code","53ed0c15":"code","4fd89f00":"code","5ecdcae8":"code","960cd83d":"code","526b0791":"code","c0ba1af9":"code","d1062eb9":"code","b0f35cc2":"code","a42ed0bf":"code","9a9b33ae":"code","0b95f069":"code","517160a8":"code","0b24603b":"code","4eb0d6f0":"code","c2d0e5a7":"code","d8617f8a":"code","79b3d790":"code","cb0908c4":"code","679dc474":"code","08ca40a1":"code","86231911":"code","76686fc0":"code","ddeccd5f":"code","efe8d30e":"code","705ec35b":"code","c3a859b4":"code","b687b29b":"code","495100da":"code","0c47e844":"markdown","a219f5f1":"markdown","58586574":"markdown","9f8bfab4":"markdown","afa3ce32":"markdown","b53e9b3f":"markdown","3d1adfc0":"markdown","1daf474c":"markdown","42129f1a":"markdown","9ecc66bb":"markdown","e798ba07":"markdown","a4076b32":"markdown","73006fb0":"markdown","92ce702c":"markdown","616bb34f":"markdown","8b605923":"markdown"},"source":{"3ba33d2f":"%pip install tensorflow","a7f709f5":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nimport seaborn as sns","d02b440d":"dataset = pd.read_csv(\"..\/input\/framingham-heart-study-dataset\/framingham.csv\")","9f71a454":"dataset.shape","f4b500a2":"dataset.dtypes","59b26c39":"dataset.info","0504ccf1":"fig = plt.figure(figsize = (8,8))\nax = fig.gca()\ndataset.hist(ax=ax)\nplt.show()","f1768aea":"fig, ax = plt.subplots()\nax.hist(dataset[\"TenYearCHD\"],color = \"yellow\")\nax.set_title(' To predict heart disease')\nax.set_xlabel('TenYearCHD')\nax.set_ylabel('Frequency')","99392a00":"data = np.random.random([100,4])\nsns.violinplot(data=data, palette=['r','g','b','m'])","52a48541":"X = dataset.iloc[:,:-1].values\ny = dataset.iloc[:,-1].values","72714792":"np.isnan(X).sum()","e3be22d6":"np.isnan(y).sum()","ca701ff0":"from sklearn.impute import SimpleImputer\nsi = SimpleImputer(missing_values = np.nan, strategy = 'mean')\nX = si.fit_transform(X)","ac8996e0":"y.shape","33059432":"np.isnan(X).sum()","2fe218af":"np.isnan(y).sum()","5335b6bd":"dataset.isna().sum()","d35e0337":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state = 0)","979ab849":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","0de46522":"X_train","53ed0c15":"y_train","4fd89f00":"np.isnan(X_train).sum()","5ecdcae8":"np.isnan(y_train).sum()","960cd83d":"ann = tf.keras.models.Sequential()","526b0791":"ann.add(tf.keras.layers.Dense(units = 6, activation = 'relu'))","c0ba1af9":"ann.add(tf.keras.layers.Dense(units = 6, activation='relu'))","d1062eb9":"ann.add(tf.keras.layers.Dense(units = 1,activation='sigmoid'))","b0f35cc2":"ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","a42ed0bf":"model = ann.fit(X_train,y_train,validation_data=(X_test,y_test), batch_size = 32,epochs=100)","9a9b33ae":"y_pred = ann.predict(X_test)\ny_pred = (y_pred > 0.5)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","0b95f069":"from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","517160a8":"plt.plot(model.history['accuracy'])\nplt.plot(model.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='lower right')\nplt.show()","0b24603b":"plt.plot(model.history['loss'])\nplt.plot(model.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper right')\nplt.show()","4eb0d6f0":"print(classification_report(y_test, y_pred))","c2d0e5a7":"from sklearn.neural_network import MLPClassifier\nclassifier = MLPClassifier(hidden_layer_sizes=(150,100,50), max_iter=300,activation = 'relu',solver='adam',random_state=1)","d8617f8a":"classifier.fit(X_train, y_train)","79b3d790":"y_pred = classifier.predict(X_test)\ny_pred = (y_pred > 0.5)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","cb0908c4":"from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","679dc474":"print(classification_report(y_test, y_pred))","08ca40a1":"from sklearn.decomposition import PCA\npca = PCA(n_components=2)\n\nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)","86231911":"classifier.fit(X_train, y_train)","76686fc0":"def visualization_train(model):\n    sns.set_context(context='notebook',font_scale=2)\n    plt.figure(figsize=(16,9))\n    from matplotlib.colors import ListedColormap\n    X_set, y_set = X_train, y_train\n    X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n    plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.6, cmap = ListedColormap(('red', 'green')))\n    plt.xlim(X1.min(), X1.max())\n    plt.ylim(X2.min(), X2.max())\n    for i, j in enumerate(np.unique(y_set)):\n        plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                    c = ListedColormap(('red', 'green'))(i), label = j)\n    plt.title(\"%s Model on training data\" %(model))\n    plt.xlabel('PC 1')\n    plt.ylabel('PC 2')\n    plt.legend()\ndef visualization_test(model):\n    sns.set_context(context='notebook',font_scale=2)\n    plt.figure(figsize=(16,9))\n    from matplotlib.colors import ListedColormap\n    X_set, y_set = X_test, y_test\n    X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                         np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n    plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n                 alpha = 0.6, cmap = ListedColormap(('red', 'green')))\n    plt.xlim(X1.min(), X1.max())\n    plt.ylim(X2.min(), X2.max())\n    for i, j in enumerate(np.unique(y_set)):\n        plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                    c = ListedColormap(('red', 'green'))(i), label = j)\n    plt.title(\"%s Test Set\" %(model))\n    plt.xlabel('PC 1')\n    plt.ylabel('PC 2')\n    plt.legend()","ddeccd5f":"visualization_train(model= 'MLP')","efe8d30e":"import joblib\njoblib.dump(ann, 'ann_model.pkl') \njoblib.dump(sc, 'sc_model.pkl') ","705ec35b":"knn_from_joblib = joblib.load('mlp_model.pkl') \nsc_model = joblib.load('sc_model.pkl') ","c3a859b4":"!pip install h5py","b687b29b":"ann.save('ann_model.h5')","495100da":"model = tf.keras.models.load_model('ann_model.h5')","0c47e844":"# Model Loss Visualisation","a219f5f1":"# Importing The Dataset","58586574":"# Visualizing the data","9f8bfab4":"# Calculating Different Metrics","afa3ce32":"# Separating the dependent and independent variables","b53e9b3f":"# Taking Care of Missing Values","3d1adfc0":"# Importing the libraries","1daf474c":"# Model Accuracy Visualisation","42129f1a":"# Saving a machine learning Model","9ecc66bb":"# Visualiaing The MLP Model After Apllying the PCA method","e798ba07":"# Normalising The data","a4076b32":"# Analysing The Data","73006fb0":"# Preparing ANN Model with two layers","92ce702c":"# Splitting into Training and test Data","616bb34f":"# Saving a tensorflow model","8b605923":"# Using MLP Classifier for Prediction"}}