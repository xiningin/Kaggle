{"cell_type":{"d363594e":"code","abcce33e":"code","c17582b9":"code","648909e2":"code","3f064c19":"code","df561e02":"code","d29b6ae0":"code","e6e5aaaa":"code","75d633d5":"code","0ffd31a5":"code","a8e4a9dd":"code","2de5346f":"code","9c3b1f96":"code","aaabc3c4":"code","40ed6fad":"code","e28ab6d3":"code","43f71284":"code","7eee59ec":"code","f75af09e":"code","1a6c6119":"code","b5bca9a9":"code","dbe61e22":"code","24de702e":"code","ebd0f785":"code","be8c0c9e":"code","be85de7c":"code","cc7312d8":"code","bbe54aee":"code","87f7845a":"code","ef3241b4":"code","84d7afe0":"code","6cd2c5c0":"code","b1ffc507":"code","82e11a56":"code","4eae1a60":"code","25049837":"code","2f8da4e2":"code","fc500e97":"code","d425cef1":"markdown"},"source":{"d363594e":"import os\n\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n\nimport cv2\nimport torch\nfrom tqdm import tqdm_notebook\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import models\nfrom sklearn.model_selection import train_test_split\nfrom torchvision import transforms\n\n%matplotlib inline","abcce33e":"def kaggle_commit_logger(str_to_log, need_print = True):\n    if need_print:\n        print(str_to_log)\n    os.system('echo ' + str_to_log)","c17582b9":"train_df_all = pd.read_csv('..\/input\/train.csv')\ntrain_df_all.head()","648909e2":"batch_size = 64\nIMG_SIZE = 64\nN_EPOCHS = 10\nID_COLNAME = 'file_name'\nANSWER_COLNAME = 'category_id'\nTRAIN_IMGS_DIR = '..\/input\/train_images\/'\nTEST_IMGS_DIR = '..\/input\/test_images\/'","3f064c19":"train_df, test_df = train_test_split(train_df_all[[ID_COLNAME, ANSWER_COLNAME]],\n                                     test_size = 0.15,                                     \n                                     shuffle = True\n                                    )","df561e02":"train_df.head(10)","d29b6ae0":"CLASSES_TO_USE = train_df_all['category_id'].unique()","e6e5aaaa":"CLASSES_TO_USE","75d633d5":"NUM_CLASSES = len(CLASSES_TO_USE)\nNUM_CLASSES","0ffd31a5":"CLASSMAP = dict(\n    [(i, j) for i, j\n     in zip(CLASSES_TO_USE, range(NUM_CLASSES))\n    ]\n)\nCLASSMAP","a8e4a9dd":"REVERSE_CLASSMAP = dict([(v, k) for k, v in CLASSMAP.items()])\nREVERSE_CLASSMAP","2de5346f":"model = models.densenet121(pretrained='imagenet')","9c3b1f96":"new_head = torch.nn.Linear(model.classifier.in_features, NUM_CLASSES)\nmodel.classifier = new_head","aaabc3c4":"model.cuda();","40ed6fad":"normalizer = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])\n\ntrain_augmentation = transforms.Compose([\n    transforms.Resize((IMG_SIZE,IMG_SIZE)),\n    transforms.ToTensor(),\n    normalizer,\n])\n\nval_augmentation = transforms.Compose([\n    transforms.Resize((IMG_SIZE,IMG_SIZE)),\n    transforms.ToTensor(),\n    normalizer,\n])","e28ab6d3":"class IMetDataset(Dataset):\n    \n    def __init__(self,\n                 df,\n                 images_dir,\n                 n_classes = NUM_CLASSES,\n                 id_colname = ID_COLNAME,\n                 answer_colname = ANSWER_COLNAME,\n                 label_dict = CLASSMAP,\n                 transforms = None\n                ):\n        self.df = df\n        self.images_dir = images_dir\n        self.n_classes = n_classes\n        self.id_colname = id_colname\n        self.answer_colname = answer_colname\n        self.label_dict = label_dict\n        self.transforms = transforms\n    \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, idx):\n        cur_idx_row = self.df.iloc[idx]\n        img_id = cur_idx_row[self.id_colname]\n        img_name = img_id # + self.img_ext\n        img_path = os.path.join(self.images_dir, img_name)\n        \n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = Image.fromarray(img)\n        \n        if self.transforms is not None:\n            img = self.transforms(img)\n        \n        if self.answer_colname is not None:              \n            label = torch.zeros((self.n_classes,), dtype=torch.float32)\n            label[self.label_dict[cur_idx_row[self.answer_colname]]] = 1.0\n\n            return img, label\n        \n        else:\n            return img, img_id","43f71284":"train_dataset = IMetDataset(train_df, TRAIN_IMGS_DIR, transforms = train_augmentation)\ntest_dataset = IMetDataset(test_df, TRAIN_IMGS_DIR, transforms = val_augmentation)","7eee59ec":"BS = 24\n\ntrain_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True, num_workers=2, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=BS, shuffle=False, num_workers=2, pin_memory=True)","f75af09e":"def cuda(x):\n    return x.cuda(non_blocking=True)","1a6c6119":"def f1_score(y_true, y_pred, threshold=0.5):\n    return fbeta_score(y_true, y_pred, 1, threshold)\n\n\ndef fbeta_score(y_true, y_pred, beta, threshold, eps=1e-9):\n    beta2 = beta**2\n\n    y_pred = torch.ge(y_pred.float(), threshold).float()\n    y_true = y_true.float()\n\n    true_positive = (y_pred * y_true).sum(dim=1)\n    precision = true_positive.div(y_pred.sum(dim=1).add(eps))\n    recall = true_positive.div(y_true.sum(dim=1).add(eps))\n\n    return torch.mean(\n        (precision*recall).\n        div(precision.mul(beta2) + recall + eps).\n        mul(1 + beta2))","b5bca9a9":"def train_one_epoch(model, train_loader, criterion, optimizer, steps_upd_logging = 250):\n    model.train();\n    \n    total_loss = 0.0\n    \n    train_tqdm = tqdm_notebook(train_loader)\n    \n    for step, (features, targets) in enumerate(train_tqdm):\n        features, targets = cuda(features), cuda(targets)\n        \n        optimizer.zero_grad()\n        \n        logits = model(features)\n        \n        loss = criterion(logits, targets)\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        \n        if (step + 1) % steps_upd_logging == 0:\n            logstr = f'Train loss on step {step + 1} was {round(total_loss \/ (step + 1), 5)}'\n            train_tqdm.set_description(logstr)\n            kaggle_commit_logger(logstr, need_print=False)\n        \n    return total_loss \/ (step + 1)","dbe61e22":"def validate(model, valid_loader, criterion, need_tqdm = False):\n    model.eval();\n    \n    test_loss = 0.0\n    TH_TO_ACC = 0.5\n    \n    true_ans_list = []\n    preds_cat = []\n    \n    with torch.no_grad():\n        \n        if need_tqdm:\n            valid_iterator = tqdm_notebook(valid_loader)\n        else:\n            valid_iterator = valid_loader\n        \n        for step, (features, targets) in enumerate(valid_iterator):\n            features, targets = cuda(features), cuda(targets)\n\n            logits = model(features)\n            loss = criterion(logits, targets)\n\n            test_loss += loss.item()\n            true_ans_list.append(targets)\n            preds_cat.append(torch.sigmoid(logits))\n\n        all_true_ans = torch.cat(true_ans_list)\n        all_preds = torch.cat(preds_cat)\n                \n        f1_eval = f1_score(all_true_ans, all_preds).item()\n\n    logstr = f'Mean val f1: {round(f1_eval, 5)}'\n    kaggle_commit_logger(logstr)\n    return test_loss \/ (step + 1), f1_eval","24de702e":"criterion = torch.nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\nsheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=3)","ebd0f785":"%%time\n\nTRAIN_LOGGING_EACH = 500\n\ntrain_losses = []\nvalid_losses = []\nvalid_f1s = []\nbest_model_f1 = 0.0\nbest_model = None\nbest_model_ep = 0\n\nfor epoch in range(1, N_EPOCHS + 1):\n    ep_logstr = f\"Starting {epoch} epoch...\"\n    kaggle_commit_logger(ep_logstr)\n    tr_loss = train_one_epoch(model, train_loader, criterion, optimizer, TRAIN_LOGGING_EACH)\n    train_losses.append(tr_loss)\n    tr_loss_logstr = f'Mean train loss: {round(tr_loss,5)}'\n    kaggle_commit_logger(tr_loss_logstr)\n    \n    valid_loss, valid_f1 = validate(model, test_loader, criterion)  \n    valid_losses.append(valid_loss)    \n    valid_f1s.append(valid_f1)       \n    val_loss_logstr = f'Mean valid loss: {round(valid_loss,5)}'\n    kaggle_commit_logger(val_loss_logstr)\n    sheduler.step(valid_loss)\n    \n    if valid_f1 >= best_model_f1:    \n        best_model = model        \n        best_model_f1 = valid_f1        \n        best_model_ep = epoch","be8c0c9e":"bestmodel_logstr = f'Best f1 is {round(best_model_f1, 5)} on epoch {best_model_ep}'\nkaggle_commit_logger(bestmodel_logstr)","be85de7c":"xs = list(range(1, len(train_losses) + 1))\n\nplt.plot(xs, train_losses, label = 'Train loss');\n# plt.plot(xs, valid_losses, label = 'Val loss');\nplt.plot(xs, valid_f1s, label = 'Val f1');\nplt.legend();\nplt.xticks(xs);\nplt.xlabel('Epochs');","cc7312d8":"SAMPLE_SUBMISSION_DF = pd.read_csv('..\/input\/sample_submission.csv')\nSAMPLE_SUBMISSION_DF.head()","bbe54aee":"SAMPLE_SUBMISSION_DF.rename(columns={'Id':'file_name','Predicted':'category_id'}, inplace=True)\nSAMPLE_SUBMISSION_DF['file_name'] = SAMPLE_SUBMISSION_DF['file_name'] + '.jpg'\nSAMPLE_SUBMISSION_DF.head()","87f7845a":"subm_dataset = IMetDataset(SAMPLE_SUBMISSION_DF,\n                           TEST_IMGS_DIR,\n                           transforms = val_augmentation,\n                           answer_colname=None\n                          )","ef3241b4":"SUMB_BS = 48\n\nsubm_dataloader = DataLoader(subm_dataset,\n                             batch_size=SUMB_BS,\n                             shuffle=False,\n                             pin_memory=True)","84d7afe0":"def get_subm_answers(model, subm_dataloader, need_tqdm = False):\n    model.eval();\n    preds_cat = []\n    ids = []\n    \n    with torch.no_grad():\n        \n        if need_tqdm:\n            subm_iterator = tqdm_notebook(subm_dataloader)\n        else:\n            subm_iterator = subm_dataloader\n        \n        for step, (features, subm_ids) in enumerate(subm_iterator):\n            features = cuda(features)\n\n            logits = model(features)\n            preds_cat.append(torch.sigmoid(logits))\n            ids += subm_ids\n\n        all_preds = torch.cat(preds_cat)\n        all_preds = torch.argmax(all_preds, dim=1).int().cpu().numpy()\n    return all_preds, ids","6cd2c5c0":"%%time\n\nbest_model.cuda();\n\nsubm_preds, submids = get_subm_answers(best_model, subm_dataloader, True)","b1ffc507":"len(subm_preds)","82e11a56":"ans_dict = dict(zip(submids, subm_preds.astype(str)))","4eae1a60":"df_to_process = (\n    pd.DataFrame\n    .from_dict(ans_dict, orient='index', columns=['Predicted'])\n    .reset_index()\n    .rename({'index':'Id'}, axis=1)    \n)\ndf_to_process['Id'] = df_to_process['Id'].map(lambda x: str(x)[:-4])\ndf_to_process.head()","25049837":"def process_one_id(id_classes_str):\n    if id_classes_str:\n        return REVERSE_CLASSMAP[int(id_classes_str)]\n    else:\n        return id_classes_str","2f8da4e2":"df_to_process['Predicted'] = df_to_process['Predicted'].apply(process_one_id)\ndf_to_process.head()","fc500e97":"df_to_process.to_csv('submission.csv', index=False)","d425cef1":"**Simple example of transfer learning from pretrained model using PyTorch.**\n* Metrics: f1_score"}}