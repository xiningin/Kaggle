{"cell_type":{"d492e524":"code","4e1418c6":"code","51e5c556":"code","369bd51a":"code","13a2f430":"code","b013df4a":"code","ccd393db":"code","34e61a30":"code","5f51d99b":"code","4cfe5c54":"code","7f3757f7":"code","cbbfd9f3":"code","aae34e63":"code","7c186c7e":"code","696f16fb":"code","ecfaafb9":"code","7faca968":"code","afc0f157":"code","e5f19914":"code","437fb737":"code","0c9998e4":"code","61a97fcc":"code","8489981d":"code","3655530f":"code","5fd80b2b":"code","fae9c655":"code","604d5ff6":"code","085aff28":"code","4f602136":"markdown","9a683af6":"markdown","a612a25c":"markdown","3746f72d":"markdown","c9fad9fb":"markdown","0cbc2351":"markdown","14090fa3":"markdown","44efba35":"markdown","ae4aedb4":"markdown","7ff3846f":"markdown","91657dbe":"markdown","f91d1d9c":"markdown","53188ef4":"markdown","79b475f1":"markdown","68f576d8":"markdown","6ea05a2d":"markdown","37bf52b0":"markdown","d8f23864":"markdown","8299aabf":"markdown","3eab7136":"markdown","f0db3dd7":"markdown","5c017210":"markdown","71fef295":"markdown","5785493d":"markdown","4e7432e9":"markdown","8e94e134":"markdown","56eb1282":"markdown"},"source":{"d492e524":"%matplotlib inline\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","4e1418c6":"train_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')","51e5c556":"# Show 5 random rows from dataset\ntrain_df.sample(5)","369bd51a":"test_df.sample(1)","13a2f430":"print('Number of Categories: ', train_df.Category.nunique())\nprint('Number of PdDistricts: ', train_df.PdDistrict.nunique())\nprint('Number of DayOfWeeks: ', train_df.DayOfWeek.nunique())\nprint('_________________________________________________')\n# Show some useful Information\ntrain_df.info()","b013df4a":"train_df = train_df.drop('Resolution', axis=1)\ntrain_df.sample(1)","ccd393db":"train_df.Dates.dtype","34e61a30":"assert train_df.Dates.isnull().any() == False\nassert test_df.Dates.isnull().any() == False","5f51d99b":"assert train_df.Dates.str.match('\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d').all() == True\nassert test_df.Dates.str.match('\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d').all() == True","4cfe5c54":"train_df['Date'] = pd.to_datetime(train_df.Dates)\ntest_df['Date'] = pd.to_datetime(test_df.Dates)\n\ntrain_df = train_df.drop('Dates', axis=1)\ntest_df = test_df.drop('Dates', axis=1)\ntrain_df.sample(1)","7f3757f7":"# Confirm that it was parsed to Datetime\ntrain_df.Date.dtype","cbbfd9f3":"train_df['IsDay'] = 0\ntrain_df.loc[ (train_df.Date.dt.hour > 6) & (train_df.Date.dt.hour < 20), 'IsDay' ] = 1\ntest_df['IsDay'] = 0\ntest_df.loc[ (test_df.Date.dt.hour > 6) & (test_df.Date.dt.hour < 20), 'IsDay' ] = 1\n\ntrain_df.sample(3)","aae34e63":"days_to_int_dic = {\n        'Monday': 1,\n        'Tuesday': 2,\n        'Wednesday': 3,\n        'Thursday': 4,\n        'Friday': 5,\n        'Saturday': 6,\n        'Sunday': 7,\n}\ntrain_df['DayOfWeek'] = train_df['DayOfWeek'].map(days_to_int_dic)\ntest_df ['DayOfWeek'] = test_df ['DayOfWeek'].map(days_to_int_dic)\n\ntrain_df.DayOfWeek.unique()","7c186c7e":"train_df['Hour'] = train_df.Date.dt.hour\ntrain_df['Month'] = train_df.Date.dt.month\ntrain_df['Year'] = train_df.Date.dt.year\ntrain_df['Year'] = train_df['Year'] - 2000 # The Algorithm doesn't know the difference. It's just easier to work like that\n\ntest_df['Hour'] = test_df.Date.dt.hour\ntest_df['Month'] = test_df.Date.dt.month\ntest_df['Year'] = test_df.Date.dt.year\ntest_df['Year'] = test_df['Year'] - 2000 # The Algorithm doesn't know the difference. It's just easier to work like that\n\ntrain_df.sample(1)","696f16fb":"train_df['HourCos'] = np.cos((train_df['Hour']*2*np.pi)\/24 )\ntrain_df['DayOfWeekCos'] = np.cos((train_df['DayOfWeek']*2*np.pi)\/7 )\ntrain_df['MonthCos'] = np.cos((train_df['Month']*2*np.pi)\/12 )\n\ntest_df['HourCos'] = np.cos((test_df['Hour']*2*np.pi)\/24 )\ntest_df['DayOfWeekCos'] = np.cos((test_df['DayOfWeek']*2*np.pi)\/7 )\ntest_df['MonthCos'] = np.cos((test_df['Month']*2*np.pi)\/12 )\n\ntrain_df.sample(1)","ecfaafb9":"train_df = pd.get_dummies(train_df, columns=['PdDistrict'])\ntest_df  = pd.get_dummies(test_df,  columns=['PdDistrict'])\ntrain_df.sample(2)","7faca968":"from sklearn.preprocessing import LabelEncoder\n\ncat_le = LabelEncoder()\ntrain_df['CategoryInt'] = pd.Series(cat_le.fit_transform(train_df.Category))\ntrain_df.sample(5)\n#cat_le.classes_","afc0f157":"train_df['InIntersection'] = 1\ntrain_df.loc[train_df.Address.str.contains('Block'), 'InIntersection'] = 0\n\ntest_df['InIntersection'] = 1\ntest_df.loc[test_df.Address.str.contains('Block'), 'InIntersection'] = 0","e5f19914":"train_df.sample(10)","437fb737":"train_df.columns","0c9998e4":"feature_cols = ['X', 'Y', 'IsDay', 'DayOfWeek', 'Month', 'Hour', 'Year', 'InIntersection',\n                'PdDistrict_BAYVIEW', 'PdDistrict_CENTRAL', 'PdDistrict_INGLESIDE',\n                'PdDistrict_MISSION', 'PdDistrict_NORTHERN', 'PdDistrict_PARK',\n                'PdDistrict_RICHMOND', 'PdDistrict_SOUTHERN', 'PdDistrict_TARAVAL', 'PdDistrict_TENDERLOIN']\ntarget_col = 'CategoryInt'\n\ntrain_x = train_df[feature_cols]\ntrain_y = train_df[target_col]\n\ntest_ids = test_df['Id']\ntest_x = test_df[feature_cols]","61a97fcc":"train_x.sample(1)","8489981d":"test_x.sample(1)","3655530f":"type(train_x), type(train_y)","5fd80b2b":"import xgboost as xgb\ntrain_xgb = xgb.DMatrix(train_x, label=train_y)\ntest_xgb  = xgb.DMatrix(test_x)","fae9c655":"params = {\n    'max_depth': 4,  # the maximum depth of each tree\n    'eta': 0.3,  # the training step for each iteration\n    'silent': 1,  # logging mode - quiet\n    'objective': 'multi:softprob',  # error evaluation for multiclass training\n    'num_class': 39,\n}","604d5ff6":"CROSS_VAL = False\nif CROSS_VAL:\n    print('Doing Cross-validation ...')\n    cv = xgb.cv(params, train_xgb, nfold=3, early_stopping_rounds=10, metrics='mlogloss', verbose_eval=True)\n    cv","085aff28":"SUBMIT = not CROSS_VAL\nif SUBMIT:\n    print('Fitting Model ...')\n    m = xgb.train(params, train_xgb, 10)\n    res = m.predict(test_xgb)\n    cols = ['Id'] + cat_le.classes_\n    submission = pd.DataFrame(res, columns=cat_le.classes_)\n    submission.insert(0, 'Id', test_ids)\n    submission.to_csv('submission.csv', index=False)\n    print('Done Outputing !')\n    print(submission.sample(3))\nelse:\n    print('NOT SUBMITING')","4f602136":"### The 'Dates' column type is String. It will be easier to work with by parsing it to Datetime.","9a683af6":"## Label Encoding of 'Category':","a612a25c":"# Imports <a name=\"imports\"><\/a>","3746f72d":"# Table of contents\n1. [Introduction](#introduction)\n2. [Imports](#imports)\n3. [Describe Dataset](#describe-dataset)\n4. [Quick Preprocessing & Feature Engineering](#preprocessing)\n5. [Feature Selection](#feature-selection)\n6. [Training with XGBoost (Cross Validation)](#training)","c9fad9fb":"## Dummy Encoding of 'PdDistrict':","0cbc2351":"# XGBOOST Training (Cross-Validation): <a name=\"training\"><\/a>","14090fa3":"## Fit & Make the predictions","44efba35":"## Parse the 'Dates' Column:","ae4aedb4":" ## Drop the Resolution Column:","7ff3846f":"# Introduction <a name=\"introduction\"><\/a>","91657dbe":"# Describe Dataset <a name=\"describe-dataset\"><\/a>","f91d1d9c":"## Show useful information (columns, types, number of rows)","53188ef4":"This is my solution ( *late submission* ) to the **San Francisco Crime Classification** competition.\n\nI found this Dataset to be very interesting for learning to deal with *slightly big* datasets, it contains *Spatial Coordinates*,  a *Datetime* column and *cyclic features*.\n\nIn this Kernel, I want to share my approach to this problem. I will focus on **Feature Engineering** & **Prediction** using **XGBoost**\n\n( **I wont' be going through the visualizations** ( you can check [my Github Repo](https:\/\/github.com\/hamzael1\/kaggle-san-francisco-crime-classification) )","79b475f1":"- Few important observations:\n    - We have **878049** Observations of **9** variables\n    - We have a **'Dates'** column which contains the date and time of the occurence of the crime, but it's a String.\n    - We have **spatial coordinates** ( Latitude and Longitude ) of the exact place of the crime.\n    - The Target column is **'Category'**, which is a Categorical Column ( 39 categories )\n    - The **'DayOfWeek'** column is also Categorical ( 7 days )\n    - The **'PdDistrict'** column is also Categorical ( 10 districts  )\n    - The **'Address'** column indicates whether the crime location was an intersection of two roads\n    - The **'Resolution'** column will be droped ( It won't help us with prediction )","68f576d8":"## Engineer a feature to indicate whether the crime was commited by day or by night :","6ea05a2d":"# Quick Preprocessing & Feature Engineering <a name=\"preprocessing\"><\/a>","37bf52b0":"## Play with the parameters and do Cross-Validation","d8f23864":"## Create 'Month', 'Year' and 'DayOfWeekInt' columns","8299aabf":"**Now let's get our dataset ready for training !**","3eab7136":"### Create Hour, Month and Year Columns: ","f0db3dd7":"### Now we proceed to parsing using the function `pandas.to_datetime` :\n( We will also change the column name to 'Date' singular ) ","5c017210":"### Encode 'DayOfWeek' to Integer:","71fef295":"## Import XGBoost and create the DMatrices","5785493d":"# Feature Selection <a name=\"feature-selection\"><\/a>","4e7432e9":"## Show Random rows:","8e94e134":"### Deal with the cyclic characteristic of Months and Days of Week:","56eb1282":"### Check if there are any missing values or typos:"}}