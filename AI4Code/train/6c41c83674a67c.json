{"cell_type":{"0f46a143":"code","dbee49d6":"code","4b01cb69":"code","ac32f486":"code","5fb4813d":"code","395e045a":"code","311c0aa3":"code","da671b7f":"code","8c9ffd3a":"code","f7572334":"code","72a267ce":"code","e521b4c7":"code","e7ac80f4":"code","b0f8be42":"code","598a15d5":"code","e9f451ce":"code","36d36a85":"markdown","06baa56c":"markdown","ba795b23":"markdown","0ab32307":"markdown","c5589188":"markdown","bbcc68b4":"markdown"},"source":{"0f46a143":"import numpy as np \nimport pandas as pd \nimport warnings\n\nwarnings.filterwarnings('ignore', category=FutureWarning)\n\ndata1 = pd.read_csv(\"..\/input\/letters.csv\")\nfiles1 = data1['file']\nletters1 = data1['letter']\nbackgrounds1 = data1['background']\n#data1.head()\n\ndata2 = pd.read_csv(\"..\/input\/letters2.csv\")\nfiles2 = data2['file']\nletters2 = data2['letter']\nbackgrounds2 = data2['background']\n#data2.head()\n\ndata3 = pd.read_csv(\"..\/input\/letters3.csv\")\nfiles3 = data3['file']\nletters3 = data3['letter']\nbackgrounds3 = data3['background']\ndata3.head()\n# Any results you write to the current directory are saved as output.","dbee49d6":"import h5py\n\n# Read the h5 file\nf = h5py.File('..\/input\/LetterColorImages_123.h5', 'r')\n# List all groups\nkeys = list(f.keys())\nkeys ","4b01cb69":"# Create tensors and targets\nbackgrounds = np.array(f[keys[0]])\ntensors = np.array(f[keys[1]])\ntargets = np.array(f[keys[2]])\nprint ('Tensor shape:', tensors.shape)\nprint ('Target shape', targets.shape)\nprint ('Background shape:', backgrounds.shape)","ac32f486":"# Concatenate series\nletters = pd.concat((letters1, letters2), axis=0, ignore_index=True)\nletters = pd.concat((letters, letters3), axis=0, ignore_index=True)\nlen(letters)","5fb4813d":"# Normalize the tensors\ntensors = tensors.astype('float32')\/255","395e045a":"import matplotlib.pylab as plt\nfrom matplotlib import cm\n%matplotlib inline\n\n# Read and display a tensor using Matplotlib\nprint('Label: ', letters[10])\nplt.figure(figsize=(3,3))\nplt.imshow(tensors[10]);","311c0aa3":"# Print the target unique values\nprint(set(targets))","da671b7f":"from keras.utils import to_categorical\n\n# One-hot encoding the targets, started from the zero label\ncat_targets = to_categorical(np.array(targets-1), 33)\ncat_targets.shape","8c9ffd3a":"from sklearn.model_selection import train_test_split\n\n# Split the data\nx_train, x_test, y_train, y_test = train_test_split(tensors, cat_targets, \n                                                    test_size = 0.2, \n                                                    random_state = 1)\nn = int(len(x_test)\/2)\nx_valid, y_valid = x_test[:n], y_test[:n]\nx_test, y_test = x_test[n:], y_test[n:]\n\n# Print the shape\nx_train.shape, y_train.shape, x_valid.shape, y_valid.shape, x_test.shape, y_test.shape","f7572334":"from keras.preprocessing import image as keras_image\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom keras.metrics import top_k_categorical_accuracy, categorical_accuracy\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, LSTM, GlobalAveragePooling1D, GlobalAveragePooling2D\nfrom keras.layers.advanced_activations import PReLU, LeakyReLU\nfrom keras.layers import Activation, Flatten, Dropout, BatchNormalization\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n\ndef top_3_categorical_accuracy(y_true, y_pred):\n    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n\nmodel = Sequential()\n\n# Define a model architecture    \nmodel.add(Conv2D(32, (5, 5), padding='same', input_shape=x_train.shape[1:]))\nmodel.add(LeakyReLU(alpha=0.02))\n\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(196, (5, 5)))\nmodel.add(LeakyReLU(alpha=0.02))\n\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(GlobalMaxPooling2D())\n\nmodel.add(Dense(1024))\nmodel.add(LeakyReLU(alpha=0.02))\nmodel.add(Dropout(0.5)) \n\nmodel.add(Dense(33))\nmodel.add(Activation('softmax'))\n\n# Compile the model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', \n              metrics=[categorical_accuracy, top_3_categorical_accuracy])\n","72a267ce":"# Create callbacks\ncheckpointer = ModelCheckpoint(filepath='weights.best.model.hdf5', \n                               verbose=2, save_best_only=True)\nlr_reduction = ReduceLROnPlateau(monitor='val_loss', \n                                 patience=5, verbose=2, factor=0.75)\n# Train the model\nhistory = model.fit(x_train, y_train, \n                    epochs=50, batch_size=512, verbose=2,\n                    validation_data=(x_valid, y_valid),\n                    callbacks=[checkpointer, lr_reduction])","e521b4c7":"# Plot the Neural network fitting history\ndef history_plot(fit_history, n):\n    plt.figure(figsize=(18, 12))\n    \n    plt.subplot(211)\n    plt.plot(fit_history.history['loss'][n:], color='slategray', label = 'train')\n    plt.plot(fit_history.history['val_loss'][n:], color='#4876ff', label = 'valid')\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.title('Loss Function');  \n    \n    plt.subplot(212)\n    plt.plot(fit_history.history['categorical_accuracy'][n:], color='slategray', label = 'train')\n    plt.plot(fit_history.history['val_categorical_accuracy'][n:], color='#4876ff', label = 'valid')\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Accuracy\")    \n    plt.legend()\n    plt.title('Accuracy');\n\n# Plot the training history\nhistory_plot(history, 0)","e7ac80f4":"# Load the model with the best validation accuracy\nmodel.load_weights('weights.best.model.hdf5')\n# Calculate classification accuracy on the testing set\nscore = model.evaluate(x_test, y_test)\nscore","b0f8be42":"# Create a list of symbols\nsymbols = ['\u0430','\u0431','\u0432','\u0433','\u0434','\u0435','\u0451','\u0436','\u0437','\u0438','\u0439',\n           '\u043a','\u043b','\u043c','\u043d','\u043e','\u043f','\u0440','\u0441','\u0442','\u0443','\u0444',\n           '\u0445','\u0446','\u0447','\u0448','\u0449','\u044a','\u044b','\u044c','\u044d','\u044e','\u044f']","598a15d5":"# Model predictions for the testing dataset\ny_test_predict = model.predict_classes(x_test)","e9f451ce":"# Display true labels and predictions\nfig = plt.figure(figsize=(14, 14))\nfor i, idx in enumerate(np.random.choice(x_test.shape[0], size=16, replace=False)):\n    ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n    ax.imshow(np.squeeze(x_test[idx]))\n    pred_idx = y_test_predict[idx]\n    true_idx = np.argmax(y_test[idx])\n    ax.set_title(\"{} ({})\".format(symbols[pred_idx], symbols[true_idx]),\n                 color=(\"#4876ff\" if pred_idx == true_idx else \"darkred\"))","36d36a85":"# Load the Data","06baa56c":"# Preprocess Data","ba795b23":"# Test Model","0ab32307":"# Train the model","c5589188":"# Display Predictions","bbcc68b4":"# Build Model"}}