{"cell_type":{"249ebb56":"code","e1665412":"code","8f66ac10":"code","6985f095":"code","73a9df91":"code","e2e155d4":"code","e9dd40fc":"code","7f3db9e5":"code","66d9638c":"code","6dfc78dc":"code","182eb56e":"code","4cb5f52a":"code","924fc52f":"code","795d89e9":"code","cefa85c3":"code","6e64bfbb":"code","8073c0dc":"code","3849d972":"code","fee1c75d":"code","f8915319":"code","5b23315c":"code","00ae2aa4":"code","99be52f4":"markdown","70ab78aa":"markdown","69f7aaec":"markdown","d546a903":"markdown","d7469844":"markdown","b5fdb833":"markdown"},"source":{"249ebb56":"import os\nos.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'","e1665412":"import tensorflow as tf\nimport numpy as np\n\nfrom tensorflow.keras import datasets, layers, activations, models\nfrom tensorflow.keras.layers import Input, Dense, Flatten, Conv2D,  Layer, Dropout, Conv2DTranspose\nfrom tensorflow.keras.layers import MaxPool2D, AveragePooling2D, BatchNormalization\nfrom tensorflow.keras.layers import ZeroPadding2D, Activation, Add, Concatenate\nfrom tensorflow.keras.layers.experimental.preprocessing import RandomCrop, RandomFlip, RandomRotation\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport tifffile as tiff\n\nimport pickle\n\n\nimport time\n# start_time = time.time()\n\nprint(os.getcwd())\n# tf.random.set_seed(sn)\nsn=10","8f66ac10":"# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","6985f095":"# Parameters\nIMG_WIDTH = 256\nIMG_HEIGHT = 256\nIMG_CHANNELS = 3\nIN_CHANNELS =  3                          # Number of input channels (e.g. RGB)\n\nMAIN_FOLDER  =    \"..\/input\/data-ecce-633\/patches\/\"   # Replace with your \"\/path\/to\/the\/Images\/folder\/\"\n\nLABELS = [\"roads\", \"buildings\", \"low veg.\", \"trees\", \"cars\", \"clutter\"] # Label names\n\n\nDATA_FOLDER = MAIN_FOLDER + 'Images\/Image_{}.tif'\nLABELS_FOLDER = MAIN_FOLDER + 'Labels\/Label_{}.tif'","73a9df91":"# Let's define the standard ISPRS color palette\npalette = {0 : (255, 255, 255), # Impervious surfaces (white)\n           1 : (0, 0, 255),     # Buildings (blue)\n           2 : (0, 255, 255),   # Low vegetation (cyan)\n           3 : (0, 255, 0),     # Trees (green)\n           4 : (255, 255, 0),   # Cars (yellow)\n           5 : (255, 0, 0),     # Clutter (red)\n           6 : (0, 0, 0)}       # Undefined (black)\ninvert_palette = {v: k for k, v in palette.items()}\ndef convert_from_color(arr_3d, palette=invert_palette):\n    \"\"\" RGB-color encoding to grayscale labels \"\"\" '(From 0 to 6)'\n    arr_2d = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.uint8)\n    for c, i in palette.items():\n        m = np.all(arr_3d == np.array(c).reshape(1, 1, 3), axis=2)\n        arr_2d[m] = i\n    return arr_2d","e2e155d4":"train_ids = list(range(0, 2000))\ntest_ids =  list(range(2000,2400))\nall_ids = list(range(0,2400))\n\ndata_files = [DATA_FOLDER.format(id) for id in all_ids]\nlabel_files = [LABELS_FOLDER.format(id) for id in all_ids]\n# data = 1\/255 * np.asarray(io.imread(data_files[idx]).transpose((2,0,1)), dtype='float32')\n# label = np.asarray(convert_from_color(io.imread(label_files[idx])), dtype='int64')\n# data_train, label_train = data,  label\n\ndata_test_files = [DATA_FOLDER.format(id) for id in test_ids]\nlabel_test_files = [LABELS_FOLDER.format(id) for id in test_ids]\n","e9dd40fc":"# def datagen_train():\n#     for id in list(range(0,2000)):\n#         data = np.array(plt.imread(data_files[id]), dtype='float32')\n#         data = tf.image.resize(data, [256, 256] ,\n#                                 method='nearest') #resizing    \n#         label = np.array(convert_from_color(plt.imread(label_files[id])), dtype='int8')\n#         label = tf.image.resize(np.expand_dims(label, axis=-1), [256, 256] ,\n#                                 method='nearest')\n#         yield data, label\n#         id += 1","7f3db9e5":"# data, label = next(datagen_train())\n# print(data.shape)\n# print(label.shape)","66d9638c":"# # check the generator\n# i=0\n# for data, label in datagen_train():  \n#     print(f\"data shape: {data.shape}; label shape: {label.shape}.\")\n#     plt.figure()\n#     plt.subplot(1,2,1)\n#     plt.imshow(data\/255)\n#     plt.subplot(1,2,2)\n#     plt.imshow(label[:,:,0])\n#     plt.show()\n#     print(f\"data: {data}.\")\n#     print(f\"label: {label}.\")\n#     i=i+1\n#     if i > 2:\n#         break","6dfc78dc":"# bt_size = 16\n\n# # train_dataset = tf.data.Dataset.from_generator(lambda: dataset_train(2000), output_types=(tf.float16, tf.int8),\n# #                                                output_shapes=([256,256,3], [256,256,1])) # must include shapes!\n\n# # train_dataset = tf.data.Dataset.from_generator(datagen_train, output_types=(tf.float16, tf.int8),\n# #                                                 output_shapes=([256,256,3], [256,256,1])) \n\n# # \"output_types\" and \"output_shapes\" will be archaic; use \"output_signature\"\n# train_dataset = tf.data.Dataset.from_generator(datagen_train, \n#                                                 output_signature=(\n#                                                     tf.TensorSpec(shape=(256,256,3), dtype=tf.float16),\n#                                                     tf.TensorSpec(shape=(256,256,1), dtype=tf.int8)))\n# train_dataset = train_dataset.shuffle(16)\n# train_dataset = train_dataset.batch(bt_size)\n# train_dataset = train_dataset.prefetch(2)","182eb56e":"# len(list(train_dataset.take(1))) #doesn't work in TPU @_@\n# list(train_dataset.take(1))","4cb5f52a":"# def datagen_test():\n#     for id in list(range(2000,2400)):\n#         data = np.array(plt.imread(data_files[id]), dtype='float16')\n#         data = tf.image.resize(data, [256, 256] ,\n#                                 method='nearest') #resizing    \n#         label = np.array(convert_from_color(plt.imread(label_files[id])), dtype='int8')\n#         label = tf.image.resize(np.expand_dims(label, axis=-1), [256, 256] ,\n#                                 method='nearest')\n#         yield data, label\n#         id += 1","924fc52f":"# data, label = next(datagen_test())\n# print(data.shape)\n# print(label.shape)","795d89e9":"# test_dataset = tf.data.Dataset.from_generator(datagen_test, output_types=(tf.float16, tf.int8),\n#                                                 output_shapes=([256,256,3], [256,256,1]))\n# test_dataset = test_dataset.batch(bt_size)\n# test_dataset = test_dataset.prefetch(2)","cefa85c3":"# len(list(test_dataset.take(1)))\n# list(test_dataset.take(1))","6e64bfbb":"def conv_block(x, num_filters):\n#     print(f\"input shape {x.shape}\")\n    x = Conv2D(num_filters, kernel_size=3, strides=1, padding='same')(x)\n    x = Activation(activations.relu)(x)\n#     x = Dropout(0.1)(x)\n    x = Conv2D(num_filters, kernel_size=3, strides=1, padding='same')(x)\n    x = Activation(activations.relu)(x)\n    return x\n\ndef conv_block_same(x, num_filters):\n#     print(f\"input shape {x.shape}\")\n    x = Conv2D(num_filters, kernel_size=3, strides=1, padding='same')(x)\n    x = Activation(activations.relu)(x)\n#     x = Dropout(0.1)(x)\n    x = Conv2D(num_filters, kernel_size=3, strides=1, padding='same')(x)\n    x = Activation(activations.relu)(x)\n    return x\n\n\ndef down_block(x, num_filters):\n    x = conv_block(x, num_filters)\n    p = MaxPool2D((2,2))(x)\n    return x,p\n\ndef up_block(x, s, num_filters):\n    x = Conv2DTranspose(num_filters, (2,2), strides=2, padding='same')(x)\n#     print(f\"upscaled shape {x.shape}\")\n    x = Concatenate()([s,x])\n    x = conv_block_same(x, num_filters)\n    return x","8073c0dc":"def U_Net():\n    in1 = tf.keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n    filt_start=16\n    # down\n    s1, in2 = down_block(in1, filt_start)\n    s2, in3 = down_block(in2, filt_start*2)\n    s3, in4 = down_block(in3, filt_start*4)\n    s4, in5 = down_block(in4, filt_start*8)\n\n    # bottom\n    ou5 = conv_block_same(in5, filt_start*16 ) \n\n    # up\n    ou4 = up_block(ou5, s4, filt_start*8)\n    ou3 = up_block(ou4, s3, filt_start*4)\n    ou2 = up_block(ou3, s2, filt_start*2)\n    ou1 = up_block(ou2, s1, filt_start)\n\n    # final output\n    output = Conv2D(7, 1, padding='same', activation='sigmoid')(ou1)\n\n    model= Model(in1, output, name='U-Net')\n    return model\n\nu_net= U_Net()    \nu_net.summary()","3849d972":"# opt = SGD(0.1 ,momentum=0.9,decay = 1e-04) #\nopt = Adam()\nwith tpu_strategy.scope():\n    model= U_Net()\n    #use categorical_crossentropy since the label is one-hot encoded\n    # model.compile(optimizer = opt,\n    #               loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), # False if softmaxed output .\n    #               metrics=[\"accuracy\"]) \n\n    # use SparseCategoricalCrossentropy if labels is not encoded\n    model.compile(optimizer = opt,\n            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), # use from_logits=True if no sotfmax\n            # metrics=[\"accuracy\"], # have bug for dataset from aug.flow\n            # metrics=[\"acc\"], # have bug for dataset from aug.flow\n            metrics=tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")\n            )\n\n# model.summary()","fee1c75d":"# i=0\n# print(f\"range: {[256*i, 256*(i+1)]}\")\n\n# # train dataset\n# data_origin = np.array([plt.imread(data_files[id]) for id in list(range(256*i, 256*(i+1)))], dtype='float16')\n# data_train = tf.image.resize(data_origin, [256, 256] ,\n#                             method='nearest')\n\n# label_origin = np.array([convert_from_color(plt.imread(label_files[id])) for id in list(range(256*i, 256*(i+1)))], dtype='int8')\n# label_train = tf.image.resize(np.expand_dims(label_origin, axis=3), [256, 256] ,\n#                             method='nearest')\n\n# bt_size=8\n# train_dataset = tf.data.Dataset.from_tensor_slices((data_train, label_train))\n# train_dataset = train_dataset.shuffle(32)\n# train_dataset = train_dataset.batch(bt_size)\n\n# # test dataset\n# data_origin = np.array([plt.imread(data_files[id]) for id in list(range(2000, 2400))],\n#                        dtype='float16')\n# data_test = tf.image.resize(data_origin, [256, 256] ,\n#                             method='nearest')\n\n# label_origin = np.array([convert_from_color(plt.imread(label_files[id])) for id in list(range(2000, 2400))],\n#                         dtype='int8')\n# label_test = tf.image.resize(np.expand_dims(label_origin, axis=3), [256, 256] ,\n#                             method='nearest')\n\n# test_dataset = tf.data.Dataset.from_tensor_slices((data_test, label_test))\n# test_dataset = test_dataset.shuffle(32)\n# test_dataset = test_dataset.batch(bt_size)\n\n# history = model.fit(  train_dataset,  \n#                         epochs=100,\n#                     validation_data=test_dataset, \n#                 )","f8915319":"# test dataset (fixed)\ndata_origin = np.array([plt.imread(data_files[id]) for id in list(range(2000, 2400))],\n                       dtype='float16')\ndata_test = tf.image.resize(data_origin, [256, 256] ,\n                            method='nearest')\n\nlabel_origin = np.array([convert_from_color(plt.imread(label_files[id])) for id in list(range(2000, 2400))],\n                        dtype='int8')\nlabel_test = tf.image.resize(np.expand_dims(label_origin, axis=3), [256, 256] ,\n                            method='nearest')\n\ntest_dataset = tf.data.Dataset.from_tensor_slices((data_test, label_test))\n# test_dataset = test_dataset.shuffle(32)\n# test_dataset = test_dataset.batch(8)#.prefetch(1)","5b23315c":"import random\nround=0\nbuffer_size=512\nwhile round<8:\n    round=round+1\n    i=0    \n    #shuffle the whole data and label\n    temp_lists = list(zip(data_files, label_files))\n    random.shuffle(temp_lists)\n    data_files, label_files = zip(*temp_lists)\n    \n    while i < 2000\/buffer_size:\n        start_id=buffer_size*i\n        if buffer_size*(i+1)>2000:\n            end_id=2000\n        else:\n            end_id=buffer_size*(i+1)\n            \n        print(f\"round:{round};   range: {[start_id, end_id]}\")\n        \n        data_origin = np.array([plt.imread(data_files[id]) \\\n                                for id in list(range(start_id, end_id))],\n                               dtype='float16')\n        data_train = tf.image.resize(data_origin, [256, 256] ,\n                                    method='nearest')\n\n        label_origin = np.array([convert_from_color(plt.imread(label_files[id])) \\\n                                 for id in list(range(start_id, end_id))], dtype='int8')\n        label_train = tf.image.resize(np.expand_dims(label_origin, axis=3), [256, 256] ,\n                                    method='nearest')\n\n        bt_size=16\n        train_dataset = tf.data.Dataset.from_tensor_slices((data_train, label_train))\n        train_dataset = train_dataset.shuffle(buffer_size, reshuffle_each_iteration=True)\n        train_dataset = train_dataset.batch(bt_size)#.prefetch(1)\n\n        history = model.fit(  train_dataset,  \n                                epochs=50,\n                            validation_data=test_dataset,\n                            validation_freq=10,\n                        )\n        i=i+1;\n\n#     print(f\"round:{round};   range: {[start_id, end_id]}\")\n#     data_origin = np.array([plt.imread(data_files[id]) \\\n#                             for id in list(range(buffer_size*i, 2000))], dtype='float16')\n#     data_train = tf.image.resize(data_origin, [256, 256] ,\n#                                 method='nearest')\n\n#     label_origin = np.array([convert_from_color(plt.imread(label_files[id])) \\\n#                              for id in list(range(buffer_size*i, 2000))], dtype='int8')\n#     label_train = tf.image.resize(np.expand_dims(label_origin, axis=3), [256, 256] ,\n#                                 method='nearest')\n\n#     bt_size=8\n#     train_dataset = tf.data.Dataset.from_tensor_slices((data_train, label_train))\n#     train_dataset = train_dataset.shuffle(buffer_size, reshuffle_each_iteration=True)\n#     train_dataset = train_dataset.batch(bt_size)\n\n#     history = model.fit(  train_dataset,  \n#                             epochs=50,\n#                         validation_data=test_dataset,\n#                         validation_freq=10,\n#                     )","00ae2aa4":"# history = model.fit(  train_dataset,  \n#                         epochs=200,\n# #                      validation_data=test_dataset,                    \n#                    )","99be52f4":"## 2.2 test dataset","70ab78aa":"# 1. Initialization","69f7aaec":"# 4. Compile Model","d546a903":"# 3. Build Model","d7469844":"## 2.1 train dataset","b5fdb833":"# 2. Data Preparation"}}