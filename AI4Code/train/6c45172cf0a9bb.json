{"cell_type":{"843f7f43":"code","81f4e2f7":"code","857e9961":"code","268da24a":"code","7e30e169":"code","5d06f71d":"code","675ba775":"code","5f1e3b29":"code","fa1271ab":"code","67d80c26":"code","015e6954":"code","d8206dd4":"code","8f231e17":"code","159f7932":"code","6cd89b2c":"code","c46f42b4":"code","70eba70b":"code","cb9bb5f6":"code","3f6d00cf":"code","072325d5":"code","151c59cb":"code","b28989af":"code","df42fa9b":"code","b7ccc2ae":"code","f2fd49db":"code","4d20e04a":"code","a8642f74":"code","5bc63345":"code","dbd9cf5e":"code","2cf42f4c":"code","cfaf9fa0":"code","019161b5":"code","d16ace29":"code","a1eef612":"code","fc8a5229":"code","474626e8":"code","b0719af0":"code","5f516525":"code","3e0786c5":"code","61ac0fb8":"code","d3a99984":"markdown","5c5b68cb":"markdown","196b91b8":"markdown","5af384d0":"markdown","592c1fe9":"markdown","e8fbaec0":"markdown","9a2385ef":"markdown","c825044a":"markdown","aa31d18f":"markdown","e1217c1a":"markdown","20c1bfaf":"markdown"},"source":{"843f7f43":"# NumPy\u306e\u8aad\u307f\u8fbc\u307f\nimport numpy as np\n# Pandas\u306e\u8aad\u307f\u8fbc\u307f\nimport pandas as pd \n# OS\u30e2\u30b8\u30e5\u30fc\u30eb:\u30d7\u30ed\u30b0\u30e9\u30e0\u306e\u4e2d\u3067OS\u306e\u6642\u9593\u3092\u5229\u7528\u3057\u305f\u308a\u3001\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u30a2\u30af\u30bb\u30b9\u3057\u3066\u30d5\u30a1\u30a4\u30eb\u306e\u4f5c\u6210\/\u7de8\u96c6\/\u524a\u9664\u306a\u3069\u304c\u3067\u304d\u308b\nimport os\n# OpenCV:\u753b\u50cf\u3092\u51e6\u7406\u3059\u308b\u306e\u306b\u5fc5\u8981\u306a\u69d8\u3005\u306a\u6a5f\u80fd\u3092\u63d0\u4f9b\u3059\u308b\u30e9\u30a4\u30d6\u30e9\u30ea\nimport cv2\n# matplotlib:NumPy\u306e\u305f\u3081\u306e\u30b0\u30e9\u30d5\u63cf\u753b\u30d1\u30c3\u30b1\u30fc\u30b8\n# pyplot:\u307b\u3057\u3044\u30d7\u30ed\u30c3\u30c8\u3092\u4f5c\u308b\u305f\u3081\u306b\u6697\u9ed9\u7684\u304b\u3064\u81ea\u52d5\u7684\u306b\u56f3\u5f62\u3084\u8ef8\u3092\u4f5c\u6210\u3059\u308b\u30e2\u30b8\u30e5\u30fc\u30eb\nfrom matplotlib import pyplot as plt\n# TPU\u306e\u5834\u5408\u3001\u30c7\u30fc\u30bf\u306fGoogle Cloud Storage\u306e\u307f\u30a2\u30af\u30bb\u30b9\u3067\u304d\u308b\u305f\u3081\u3001\u4f7f\u7528\nfrom kaggle_datasets import KaggleDatasets\n\n# tensorflow:\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u306e\u4e3b\u306a\u30e9\u30a4\u30d6\u30e9\u30ea\n# keras:\u5358\u4f53\u3067\u306f\u4f7f\u3046\u3053\u3068\u306e\u3067\u304d\u306a\u3044\u30e9\u30a4\u30d6\u30e9\u30ea\u3002tensorflow\u304c\u5fc5\u8981\nimport tensorflow as tf\n# Sequential:\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u69cb\u9020\u3092\u7c21\u7565\u5316\u3059\u308b\u30e2\u30c7\u30eb\u306e\u4e00\u3064\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers as L\nfrom tensorflow.keras.utils import to_categorical\n\n# train_test_split:train\u30c7\u30fc\u30bf\u3068test\u30c7\u30fc\u30bf\u306b\u5206\u3051\u308b\u30e2\u30b8\u30e5\u30fc\u30eb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn import metrics\n\n%matplotlib inline","81f4e2f7":"# \n# TPU\u306e\u521d\u671f\u5316\n# \n# \u4f8b\u5916\u51e6\u7406\u306etry\ntry:\n#     TPU\u306e\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u60c5\u5831\u3092\u7372\u5f97\u3002TPU\u304c\u5229\u7528\u3067\u304d\u306a\u3044\u74b0\u5883\u3067\u306f\u30a8\u30e9\u30fc\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n#     TPU\u5229\u7528\u53ef\u80fd\u5316\u306e\u78ba\u8a8d\n    print('Running on TPU:', tpu.master())\n# \u4e0a\u8a18\u3067\u30a8\u30e9\u30fc\uff08\u4f8b\u5916\uff09\u304c\u51fa\u305f\u5834\u5408\u306e\u51e6\u7406\nexcept ValueError:\n    tpu = None\n\n# tpu\u304c\u5229\u7528\u3067\u304d\u308b\u5834\u5408\uff08Accelerator TPU\uff09\n# \u4e0a\u8a18\u3067None\u3067\u306a\u3044\u3068\u304d\nif tpu:\n#   \u30ea\u30e2\u30fc\u30c8\u30af\u30e9\u30b9\u30bf\u306b\u63a5\u7d9a\u3057\u3066TPU\u3092\u521d\u671f\u5316\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n#   \u30c7\u30fc\u30bf\u306e\u4e26\u5217\u51e6\u7406\u3092\u4f7f\u7528\u3057\u3066\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3092\u5206\u6563\u3059\u308b\n#   TPU\u3067\u4e26\u5217\u51e6\u7406\u306e\u65b9\u6cd5\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n# TPU\u306a\u3057\u306e\u3068\u304d\uff08Accelerator None\uff09\nelse:\n    strategy = tf.distribute.get_strategy()\n\n# \u4e26\u5217\u51e6\u7406\u306e\u30ec\u30d9\u30eb\u306b\u95a2\u3059\u308b\u6c7a\u5b9a\u3092AUTO\u3067\u884c\u3046\nAUTO = tf.data.experimental.AUTOTUNE\n# TPU\u306fGCS(Google Cloud Storage)\u306b\u306e\u307f\u30a2\u30af\u30bb\u30b9\u3067\u304d\u308b\u3002\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()\n\n# \u30df\u30cb\u30d0\u30c3\u30c1\u52fe\u914d\u964d\u4e0b\u6cd5\u3092\u884c\u3046\u969b\u3001\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u5e7e\u3064\u304b\u306e\u30b5\u30d6\u30bb\u30c3\u30c8\u306b\u5206\u3051\u308b\n# \u30b5\u30d6\u30bb\u30c3\u30c8\u306e\u52fe\u914d\u306e\u5e73\u5747\u3067\u91cd\u307f\u3092\u66f4\u65b0\u3059\u308b\n# \u305d\u306e\u30b5\u30d6\u30bb\u30c3\u30c8\u306e\u5927\u304d\u3055\u3092Batch Size\u3068\u547c\u3076\n# strategy.num_replicas_in_sync\u306fstrategy\u306e\u5206\u5272\u3057\u305fTPU\u30ec\u30d7\u30ea\u30ab\u306e\u6570\u3092\u8868\u3059\u3002\n# TPU\u304c\u4f7f\u7528\u53ef\u80fd\u306a\u5834\u5408\u3001\u30ec\u30d7\u30ea\u30ab\u6570\u306f8\u3067\u3042\u308b\u304b\u30898\u500d\u3057\u305f\u6570\u3092\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u3068\u3059\u308b\u3002\n# TPU\u4f7f\u7528\u4e0d\u53ef\u306e\u6642\u3001\u30ec\u30d7\u30ea\u30ab\u6570\u306f1\u3068\u306a\u308a\u3001\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u306f8\nBATCH_SIZE = 8 * strategy.num_replicas_in_sync\nIMG_SIZE = 768\n\nprint('Batch size:', BATCH_SIZE)","857e9961":"train = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/test.csv')\nsub = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/sample_submission.csv')\n\nprint(train.head())\n\n# GCS\u3067image\u306e\u30d1\u30b9\u6307\u5b9a\ntrain_path = train.image_id.apply(lambda x: f'{GCS_DS_PATH}\/images\/{x}.jpg').values\ntest_path = test.image_id.apply(lambda x: f'{GCS_DS_PATH}\/images\/{x}.jpg').values\n# train\u306eimage_id\u3092\u524a\u9664\u3057\u3001array\u306b\ntrain_label = train.loc[:, 'healthy':].values\n\n# train_path, valid_path, train_label, valid_label = train_test_split(train_path, train_label,\n#                                                                     test_size=0.1, stratify=train_label)","268da24a":"# weight\u3092\u304b\u3051\u308b\u3068\u5168\u30c7\u30fc\u30bf\u6570\u306e1\/4\u306b\u306a\u308b\n# n_samples[1821] \/ (n_classes[4] * np.bincount(y)[healthy:516\/multi:91\/rust:622\/scab:592])\nclass_weight = compute_class_weight('balanced', np.unique(np.argmax(train_label, axis=1)), np.argmax(train_label, axis=1))\n# barplot\u306e\u4f5c\u6210\nplt.bar(range(4), class_weight)","7e30e169":"# 2\u00d72\u3067\u8868\u793a\nfig, ax = plt.subplots(2, 2)\n# \u30b5\u30f3\u30d7\u30eb\u8aad\u307f\u8fbc\u307f\nimg = cv2.imread('\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/Train_0.jpg')\nimg1 = cv2.imread('\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/Train_1.jpg')\nimg2 = cv2.imread('\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/Train_2.jpg')\nimg3 = cv2.imread('\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/Train_3.jpg')\n# \u5834\u6240\u6307\u5b9a\u3057\u305f\u66f8\u304d\u51fa\u3057\nax[0, 0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\nax[0, 1].imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\nax[1, 0].imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\nax[1, 1].imshow(cv2.cvtColor(img3, cv2.COLOR_BGR2RGB))","5d06f71d":"# \u30c7\u30b3\u30fc\u30c9\u306e\u5b9a\u7fa9\ndef decode_image(filename, label=None, image_size=(IMG_SIZE, IMG_SIZE)):\n#     \u751f\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u307f\n    bits = tf.io.read_file(filename)\n#     \u753b\u50cf\u306e\u30c6\u30f3\u30bd\u30eb\u306b\u30c7\u30b3\u30fc\u30c9\n    image = tf.image.decode_jpeg(bits, channels=3)\n#     0-255\u306eRGB\u30920-1\u306b\u3059\u308bnormalize\n    image = tf.cast(image, tf.float32) \/ 255.0\n#     1365\u00d72048\u306e\u753b\u50cf\u3092\u3001768\u00d7768\u306b\u3059\u308b\n    image = tf.image.resize(image, image_size)\n    \n#     \u6761\u4ef6\u5f0f\u306e\u610f\u5473\u306f\u308f\u304b\u308a\u307e\u305b\u3093\u304c\u5909\u63db\u3057\u305fimage\u3092return\n    if label is None:\n        return image\n    else:\n        return image, label\n\n# augment\u306e\u5b9a\u7fa9\ndef data_augment(image, label=None):\n#     \u30e9\u30f3\u30c0\u30e0\u306b\u6c34\u5e73\u65b9\u5411\u306b\u53cd\u8ee2\n    image = tf.image.random_flip_left_right(image)\n#     \u30e9\u30f3\u30c0\u30e0\u306b\u5782\u76f4\u65b9\u5411\u306b\u53cd\u8ee2\n    image = tf.image.random_flip_up_down(image)\n    \n#     image\u3092return\n    if label is None:\n        return image\n    else:\n        return image, label","675ba775":"# \u6559\u5e2b\u30c7\u30fc\u30bf\u3092\u30c7\u30b3\u30fc\u30c9\ntrain_dataset = (\n#     TFR\u5f62\u5f0f\u3067\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u66f8\u304d\u3059\u308b\n    tf.data.TFRecordDataset\n#     \u914d\u5217\u3092\u30b9\u30e9\u30a4\u30b9\u3057\u3066\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u69cb\u7bc9\u3059\u308b\n    .from_tensor_slices((train_path, train_label))\n#     \u30c7\u30fc\u30bf\u5909\u63db\uff08\u30c7\u30b3\u30fc\u30c9\uff09\u3092\u4e26\u5217\u5316\u3057\u3066\u884c\u3046\n    .map(decode_image, num_parallel_calls=AUTO)\n#     \u30c7\u30fc\u30bf\u5909\u63db\uff08\u5897\u5e45\uff09\u3092\u4e26\u5217\u5316\u3059\u308b\n    .map(data_augment, num_parallel_calls=AUTO)\n#     \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u30e1\u30e2\u30ea\u304b\u30ed\u30fc\u30ab\u30b9\u30b9\u30c8\u30ec\u30fc\u30b8\u306b\u30ad\u30e3\u30c3\u30b7\u30e5\u3067\u304d\u308b\n    .cache()\n#     \u7e70\u308a\u8fd4\u3057\u3002shuffle\u306e\u524d\u306b\u3042\u308c\u3070EPOCH\u306e\u5883\u754c\u3092\u8d8a\u3048\u3066\u8981\u7d20\u304c\u30b7\u30e3\u30c3\u30d5\u30eb\u3055\u308c\u306a\u3044\n    .repeat()\n#     \u30b7\u30e3\u30c3\u30d5\u30eb\u30d0\u30c3\u30d5\u30a1\u306e\u30b5\u30a4\u30ba\u306f\u5927\u304d\u3044\u307b\u3069\u5b8c\u5168\u306b\u30b7\u30e3\u30c3\u30d5\u30eb\u3055\u308c\u308b\u3002\u203b\u30e9\u30f3\u30c0\u30e0\u8981\u7d20\n    .shuffle(1024)\n#     \u30d0\u30c3\u30c1\u5316\n    .batch(BATCH_SIZE)\n#     CPU\u3068TPU\u3067\u305d\u308c\u305e\u308c\u4e26\u5217\u306b\u51e6\u7406\u3092\u5b9f\u884c\n    .prefetch(AUTO)\n)\n\n# valid_dataset = (\n#     tf.data.TFRecordDataset\n#     .from_tensor_slices((valid_path, valid_label))\n#     .map(decode_image, num_parallel_calls=AUTO)\n#     .map(data_augment, num_parallel_calls=AUTO)\n#     .cache()\n#     .batch(BATCH_SIZE)\n#     .prefetch(AUTO)\n# )\n\n# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u30c7\u30b3\u30fc\u30c9\ntest_dataset = (\n    tf.data.TFRecordDataset\n    .from_tensor_slices(test_path)\n    .map(decode_image, num_parallel_calls=AUTO)\n    .map(data_augment, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n)","5f1e3b29":"EPOCHS = 40\nLR_START = 0.0001\nLR_MAX = 0.00005 * strategy.num_replicas_in_sync\nLR_MIN = 0.0001\nLR_RAMPUP_EPOCHS = 10\nLR_SUSTAIN_EPOCHS = 4\nLR_EXP_DECAY = .8\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) \/ LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n    return lr\n\nlr = tf.keras.callbacks.LearningRateScheduler(lrfn)\n\ny = [lrfn(x) for x in range(EPOCHS)]\nplt.plot(y)","fa1271ab":"# EfficientNet\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n!pip install -q efficientnet","67d80c26":"# # EfficientNetB7\u306e\u8aad\u307f\u8fbc\u307f\n# from efficientnet.tfkeras import EfficientNetB7\n\n# # model\u306e\u4f5c\u6210\u306fstrategy.scope\u4e0b\u3067\u884c\u3046\n# with strategy.scope():\n# #     \u5168\u7d50\u5408\u5c64\u3092\u542b\u3081\u306a\u3044\/noisy-student\u3067self training\/average pooling\/\u753b\u50cf\u30b5\u30a4\u30ba\u3068RGB\n#     efn7 = EfficientNetB7(include_top=False, weights='noisy-student', pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n# #     Sequential\u30e2\u30c7\u30eb\u3092\u4f5c\u6210\u3001\u5f8c\u308d\u306b\u5c64\u3092\u8ffd\u52a0\n#     model_efn7 = Sequential()\n# #     EfficientNet\u5c64\u3092Model\u306b\u8ffd\u52a0\n#     model_efn7.add(efn7)\n# #     \u3053\u3061\u3089\u3067\u5168\u7d50\u5408\u5c64\u3092\u8ffd\u52a0\u30014\u5024\u5206\u985e\u3001\u5206\u985e\u554f\u984c\u306e\u305f\u3081\u6d3b\u6027\u5316\u95a2\u6570\u306fsoftmax\n#     model_efn7.add(L.Dense(4, activation='softmax'))\n# #     model\u304c\u3069\u306e\u3088\u3046\u306b\u5b66\u7fd2\u3059\u308b\u304b\u3092\u6c7a\u3081\u308b\n# #     \u6700\u9069\u5316\u95a2\u6570adam\/\u640d\u5931\u95a2\u6570\u306f\u591a\u30af\u30e9\u30b9\u5206\u985e\u306e\u305f\u3081\u30af\u30ed\u30b9\u30a8\u30f3\u30c8\u30ed\u30d4\u30fc\/\u8a55\u4fa1\u95a2\u6570\u306f\u6b63\u89e3\u7387\uff08\u5b66\u7fd2\u306b\u306f\u5f71\u97ff\u3057\u306a\u3044\uff09\n#     model_efn7.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_efn7.summary())","015e6954":"# from efficientnet.tfkeras import EfficientNetB6\n\n# with strategy.scope():\n#     efn6 = EfficientNetB6(include_top=False, weights='noisy-student', pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_efn6 = Sequential()\n#     model_efn6.add(efn6)\n#     model_efn6.add(L.Dense(4, activation='softmax'))\n#     model_efn6.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_efn6.summary())","d8206dd4":"# from efficientnet.tfkeras import EfficientNetB5\n\n# with strategy.scope():\n#     efn5 = EfficientNetB5(include_top=False, weights='noisy-student', pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_efn5 = Sequential()\n#     model_efn5.add(efn5)\n#     model_efn5.add(L.Dense(4, activation='softmax'))\n#     model_efn5.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_efn5.summary())","8f231e17":"# from efficientnet.tfkeras import EfficientNetB4\n\n# with strategy.scope():\n#     efn4 = EfficientNetB4(include_top=False, weights='noisy-student', pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_efn4 = Sequential()\n#     model_efn4.add(efn4)\n#     model_efn4.add(L.Dense(4, activation='softmax'))\n#     model_efn4.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_efn4.summary())","159f7932":"# from efficientnet.tfkeras import EfficientNetB3\n\n# with strategy.scope():\n#     efn3 = EfficientNetB3(include_top=False, weights='noisy-student', pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_efn3 = Sequential()\n#     model_efn3.add(efn3)\n#     model_efn3.add(L.Dense(4, activation='softmax'))\n#     model_efn3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_efn3.summary())","6cd89b2c":"# from efficientnet.tfkeras import EfficientNetB2\n\n# with strategy.scope():\n#     efn2 = EfficientNetB2(include_top=False, weights='noisy-student', pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_efn2 = Sequential()\n#     model_efn2.add(efn2)\n#     model_efn2.add(L.Dense(4, activation='softmax'))\n#     model_efn2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_efn2.summary())","c46f42b4":"# from efficientnet.tfkeras import EfficientNetB1\n\n# with strategy.scope():\n#     efn1 = EfficientNetB1(include_top=False, weights='noisy-student', pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_efn1 = Sequential()\n#     model_efn1.add(efn1)\n#     model_efn1.add(L.Dense(4, activation='softmax'))\n#     model_efn1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_efn1.summary())","70eba70b":"from tensorflow.keras.applications import DenseNet121\n\nwith strategy.scope():\n    dnn121 = DenseNet121(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n    model_dnn121 = Sequential()\n    model_dnn121.add(dnn121)\n    model_dnn121.add(L.GlobalAveragePooling2D())\n    model_dnn121.add(L.Dense(4, activation='softmax'))\n    model_dnn121.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    print(model_dnn121.summary())","cb9bb5f6":"from tensorflow.keras.applications import DenseNet169\n\nwith strategy.scope():\n    dnn169 = DenseNet169(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n    model_dnn169 = Sequential()\n    model_dnn169.add(dnn169)\n    model_dnn169.add(L.GlobalAveragePooling2D())\n    model_dnn169.add(L.Dense(4, activation='softmax'))\n    model_dnn169.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    print(model_dnn169.summary())","3f6d00cf":"from tensorflow.keras.applications import DenseNet201\n\nwith strategy.scope():\n    dnn201 = DenseNet201(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n    model_dnn201 = Sequential()\n    model_dnn201.add(dnn201)\n    model_dnn201.add(L.GlobalAveragePooling2D())\n    model_dnn201.add(L.Dense(4, activation='softmax'))\n    model_dnn201.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    print(model_dnn201.summary())","072325d5":"# # Epoch\u7d42\u4e86\u5f8c\u306e\u5404\u6570\u5024\u3092\u76e3\u8996\u3057\u3066\u6761\u4ef6\u304c\u63c3\u3063\u305f\u5834\u5408\u30e2\u30c7\u30eb\u3092\u4fdd\u5b58\u3059\u308b\n# # \u91cd\u307f\u306e\u30d5\u30a1\u30a4\u30eb\u540d\/\u76e3\u8996\u3059\u308b\u5024\/\u5224\u5b9a\u7d50\u679c\u304b\u3089\u4fdd\u5b58\u3092\u6c7a\u5b9a\/\u30e2\u30c7\u30eb\u306e\u91cd\u307f\u3092\u4fdd\u5b58\n# mc_efn7 = tf.keras.callbacks.ModelCheckpoint('weights_efn7.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# # \u8a13\u7df4\u306e\u5c65\u6b74\u306e\u53ef\u8996\u5316\n# history = model_efn7.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_efn7], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","151c59cb":"# mc_efn6 = tf.keras.callbacks.ModelCheckpoint('weights_efn6.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_efn6.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_efn6], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","b28989af":"# mc_efn5 = tf.keras.callbacks.ModelCheckpoint('weights_efn5.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_efn5.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_efn5], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","df42fa9b":"# mc_efn4 = tf.keras.callbacks.ModelCheckpoint('weights_efn4.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_efn4.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_efn4], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","b7ccc2ae":"# mc_efn3 = tf.keras.callbacks.ModelCheckpoint('weights_efn3.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_efn3.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_efn3], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","f2fd49db":"# mc_efn2 = tf.keras.callbacks.ModelCheckpoint('weights_efn2.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_efn2.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_efn2], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","4d20e04a":"# mc_efn1 = tf.keras.callbacks.ModelCheckpoint('weights_efn1.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_efn1.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_efn1], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","a8642f74":"mc_dnn121 = tf.keras.callbacks.ModelCheckpoint('weights_dnn121.h5', monitor='loss', save_best_only=True, save_weights_only=True)\nhistory = model_dnn121.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_dnn121], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","5bc63345":"mc_dnn169 = tf.keras.callbacks.ModelCheckpoint('weights_dnn169.h5', monitor='loss', save_best_only=True, save_weights_only=True)\nhistory = model_dnn169.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_dnn169], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","dbd9cf5e":"mc_dnn201 = tf.keras.callbacks.ModelCheckpoint('weights_dnn201.h5', monitor='loss', save_best_only=True, save_weights_only=True)\nhistory = model_dnn201.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_dnn201], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","2cf42f4c":"with strategy.scope():\n#     \u3042\u3089\u304b\u3058\u3081\u4fdd\u5b58\u3057\u3066\u304a\u3044\u305fweight\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u30ed\u30fc\u30c9\n#     model_efn7.load_weights('weights_efn7.h5')\n#     model_efn6.load_weights('weights_efn6.h5')\n#     model_efn5.load_weights('weights_efn5.h5')\n#     model_efn4.load_weights('weights_efn4.h5')\n#     model_efn3.load_weights('weights_efn3.h5')\n#     model_efn2.load_weights('weights_efn2.h5')\n#     model_efn1.load_weights('weights_efn1.h5')\n    model_dnn121.load_weights('weights_dnn121.h5')\n    model_dnn169.load_weights('weights_dnn169.h5')\n    model_dnn201.load_weights('weights_dnn201.h5')\n# valid_prob = model.predict(valid_dataset, verbose=1)\n# print(metrics.classification_report(np.argmax(valid_label, axis=1), np.argmax(valid_prob, axis=1)))\n# print(metrics.confusion_matrix(np.argmax(valid_label, axis=1), np.argmax(valid_prob, axis=1)))","cfaf9fa0":"# # test\u30c7\u30fc\u30bf\u3067\u306e\u4e88\u6e2c\/log\u306e\u51fa\u529bverbose\n# probs_efn7 = model_efn7.predict(test_dataset, verbose=1)\n# # probs\u306e\u5024\u3092sumple_submission\u306e\u5217healthy,multiple_diseases,rust,scab\u306b\u3042\u3066\u306f\u3081\n# sub_efn7 = sub\n# sub_efn7.loc[:, 'healthy':] = probs_efn7\n# # CSV\u30d5\u30a1\u30a4\u30eb\u306b\u66f8\u304d\u51fa\u3057\n# sub_efn7.to_csv('submission_efn7.csv', index=False)\n# # \u8868\u793a\n# sub_efn7.head()","019161b5":"# probs_efn6 = model_efn6.predict(test_dataset, verbose=1)\n# sub_efn6 = sub\n# sub_efn6.loc[:, 'healthy':] = probs_efn6\n# sub_efn6.to_csv('submission_efn6.csv', index=False)\n# sub_efn6.head()","d16ace29":"# probs_efn5 = model_efn5.predict(test_dataset, verbose=1)\n# sub_efn5 = sub\n# sub_efn5.loc[:, 'healthy':] = probs_efn5\n# sub_efn5.to_csv('submission_efn5.csv', index=False)\n# sub_efn5.head()","a1eef612":"# probs_efn4 = model_efn4.predict(test_dataset, verbose=1)\n# sub_efn4 = sub\n# sub_efn4.loc[:, 'healthy':] = probs_efn4\n# sub_efn4.to_csv('submission_efn4.csv', index=False)\n# sub_efn4.head()","fc8a5229":"# probs_efn3 = model_efn3.predict(test_dataset, verbose=1)\n# sub_efn3 = sub\n# sub_efn3.loc[:, 'healthy':] = probs_efn3\n# sub_efn3.to_csv('submission_efn3.csv', index=False)\n# sub_efn3.head()","474626e8":"# probs_efn2 = model_efn2.predict(test_dataset, verbose=1)\n# sub_efn2 = sub\n# sub_efn2.loc[:, 'healthy':] = probs_efn2\n# sub_efn2.to_csv('submission_efn2.csv', index=False)\n# sub_efn2.head()","b0719af0":"# probs_efn1 = model_efn1.predict(test_dataset, verbose=1)\n# sub_efn1 = sub\n# sub_efn1.loc[:, 'healthy':] = probs_efn1\n# sub_efn1.to_csv('submission_efn1.csv', index=False)\n# sub_efn1.head()","5f516525":"probs_dnn121 = model_dnn121.predict(test_dataset, verbose=1)\nsub_dnn121 = sub\nsub_dnn121.loc[:, 'healthy':] = probs_dnn121\nsub_dnn121.to_csv('submission_dnn121.csv', index=False)\nsub_dnn121.head()","3e0786c5":"probs_dnn169 = model_dnn169.predict(test_dataset, verbose=1)\nsub_dnn169 = sub\nsub_dnn169.loc[:, 'healthy':] = probs_dnn169\nsub_dnn169.to_csv('submission_dnn169.csv', index=False)\nsub_dnn169.head()","61ac0fb8":"probs_dnn201 = model_dnn201.predict(test_dataset, verbose=1)\nsub_dnn201 = sub\nsub_dnn201.loc[:, 'healthy':] = probs_dnn201\nsub_dnn201.to_csv('submission_dnn201.csv', index=False)\nsub_dnn201.head()","d3a99984":"# Import Libraries","5c5b68cb":"# Predict","196b91b8":"# Decode images","5af384d0":"# Define the parameters","592c1fe9":"# TPU setup","e8fbaec0":"# DenseNet 121\/169\/201","9a2385ef":"# Model","c825044a":"# Get train and test data","aa31d18f":"# Lets see some images","e1217c1a":"# EfficientNet B7-B1","20c1bfaf":"# Get class weights"}}