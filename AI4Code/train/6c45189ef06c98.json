{"cell_type":{"2ef5679e":"code","b7101a8e":"code","b0f825d4":"code","d637d00c":"code","453d49d1":"code","e29943d9":"code","6601dfab":"code","75ba3297":"code","2bbc1192":"code","2963bf6d":"code","5124f3c1":"code","4eeed4e4":"code","e61ef81c":"code","22916fc6":"code","d8c10214":"code","58aa66e9":"code","259a4245":"code","a034f4e5":"code","6986c71d":"code","2ffe578c":"code","3e24ac1d":"code","8611d0a7":"code","039eb520":"code","f2907822":"code","bfac0214":"code","a9ed7ede":"code","b9f805ca":"code","17098795":"code","d9aaddfb":"code","b251d822":"code","82093c4b":"markdown","798983cc":"markdown","774f5666":"markdown","1906147c":"markdown","09ee88cd":"markdown","f5ff29aa":"markdown","829bf698":"markdown","b0fba086":"markdown","3deecd7f":"markdown","88bce383":"markdown","1b52cdda":"markdown","1b2d7c9e":"markdown","cfb02f4b":"markdown","6d059ff9":"markdown","7aa0a4a6":"markdown","a3714ebe":"markdown","0f565283":"markdown","d9cd8590":"markdown"},"source":{"2ef5679e":"import numpy as np \nimport pandas as pd\nimport tensorflow as tf\nimport random\nimport os\n\nfrom PIL import ImageFile\nfrom tqdm import tqdm\nimport h5py\nimport cv2\n\nimport matplotlib.pylab as plt\nfrom matplotlib import cm\n%matplotlib inline\n\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n\nfrom keras.utils import to_categorical\nfrom keras.preprocessing import image as keras_image\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras import models\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.metrics import top_k_categorical_accuracy,categorical_accuracy\n\nfrom keras.models import Sequential, load_model, Model\nfrom keras.layers import Input, BatchNormalization\nfrom keras.layers import Dense, LSTM, GlobalAveragePooling1D, GlobalAveragePooling2D\nfrom keras.layers import Activation, Flatten, Dropout, BatchNormalization\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\nfrom keras.layers.advanced_activations import PReLU, LeakyReLU\n\nfrom keras.applications.inception_v3 import InceptionV3, preprocess_input\nimport scipy\nfrom scipy import misc\n\nimport warnings\nwarnings.filterwarnings('ignore')","b7101a8e":"#check version of library\nimport tensorflow as tf\ntf.__version__","b0f825d4":"disk_folder=\"\/kaggle\/working\/\"\nfolder='\/kaggle\/input\/classification-of-handwritten-letters\/'","d637d00c":"data_info =  ['letters.csv', 'letters2.csv', 'letters3.csv']","453d49d1":"def import_data(data_info):\n\n  \"\"\"Creates an additional column: the path to the image\"\"\"\n  data = pd.read_csv(folder + '\/' + data_info)\n  data['source'] = data_info[:-4]+'\/'\n  return data","e29943d9":"letters = [import_data(file) for file in data_info]\ndata = pd.concat(letters, ignore_index=True)","6601dfab":"# Shuffle the data \n\ndata = shuffle(data, random_state = 42)","75ba3297":"data.head(3)","2bbc1192":"# Get all labels in one string\nletters = '' \nfor letter in data.letter.unique():\n    letters += letter\n    \n# Which letter is written on each image\nlabels = data.label","2963bf6d":"def ohe_letter(label):\n    result = np.zeros(len(letters))\n    index = letters.index(label)\n    result[index] = 1\n    return result\n\ndef ohe_background(label):\n    result = np.zeros(len(data.background.unique()))\n    result[label] = 1\n    return result","5124f3c1":"data['enc_letter'] = data['letter'].apply(ohe_letter)\ndata['enc_background'] = data['background'].apply(ohe_background)\ndata.head()","4eeed4e4":"# set the image size\nimg_width, img_height = 32, 32\ninput_shape = (img_width, img_height, 3) # 3 - \u0447\u0438\u0441\u043b\u043e \u043a\u0430\u043d\u0430\u043b\u043e\u0432\n\n# let's look at one of the images\nimage_file_name = folder + 'letters2\/27_212.png'\nimg = image.load_img(image_file_name, target_size=(img_width, img_height))\nplt.imshow(img)","e61ef81c":"# Store all png images into one numpy array\nimages = []\n\n# Will be the target\nencoded_labels = []\n\nbackgrounds = []\nencoded_backgrounds = []\n\n# Want to be sure that every image is consitent\nfor i, row in data.iterrows():\n    img_name = row['file']\n    numpy_image = cv2.imread(os.path.join(folder + row['source'], img_name))\n    if numpy_image.shape == (32, 32, 3):\n        images.append(numpy_image)\n        encoded_labels.append(row['enc_letter'])\n        backgrounds.append(row['background'])\n        encoded_backgrounds.append(row['enc_background'])\n        \n# Normalize array of images\nimages = np.array(images)\/255","22916fc6":"len(images), len(encoded_labels)","d8c10214":"X = np.array(images.copy())\ny = np.array(encoded_labels.copy())\n\n# Stratified train_test split on labels\nX_train, X_val, y_train, y_val = train_test_split(X, y, \n                                                  test_size=.2, \n                                                  stratify = y, \n                                                  random_state=42)\n\nX_train.shape, X_val.shape, y_train.shape, y_val.shape","58aa66e9":"#create generators\ndatagen = ImageDataGenerator(rescale=1. \/ 255,\n                              rotation_range=40,\n                              width_shift_range=0.2,\n                              height_shift_range=0.2,\n                              zoom_range=0.2,\n                              horizontal_flip=True,\n                              fill_mode='nearest')\ndatagen.fit(X_train)","259a4245":"# The shape of input tensors\ninput_shape = (img_width, img_height, 3)\n\n# Number of classes to consider\nnum_classes = len(letters)\n\n# Group of training samples\nbatch_size = 64\n\n# Number of complete presentations of the dataset to be learned\nepochs = 100","a034f4e5":"# custom metric\ndef top_3_categorical_accuracy(y_true, y_pred):\n    return top_k_categorical_accuracy(y_true, y_pred, k=3)","6986c71d":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size = (3, 3), activation = 'relu', input_shape = input_shape))\nmodel.add(Conv2D(64, (3, 3), activation = 'relu'))\nmodel.add(Conv2D(128, (4, 4), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation = 'relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(num_classes, activation = 'softmax'))\n\n# Compile the model\nmodel.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy', top_3_categorical_accuracy])\nmodel.summary()\nplot_model(model, expand_nested=True, show_shapes=True, show_layer_names=False)","2ffe578c":"lr_reduction = ReduceLROnPlateau(monitor='val_loss', \n                                 patience=10, \n                                 verbose=2, \n                                 factor=.75)\n\n\nmodel_checkpoint= ModelCheckpoint(disk_folder+\"\/best_result_checkpoint\", monitor='val_loss', save_best_only=True, verbose=0)\n\n","3e24ac1d":"%%time\n\nhistory = model.fit(X_train, y_train,\n                    batch_size = batch_size,\n                    epochs = epochs,\n                    verbose = 1,\n                    validation_data = (X_val, y_val),\n                    callbacks = [model_checkpoint, lr_reduction])","8611d0a7":"print(history.history['accuracy'])\n\nplt.plot(history.history['accuracy'],'--', label='accuracy on training set')\nplt.plot(history.history['val_accuracy'], label='accuracy on validation set')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.legend()\nplt.show()","039eb520":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","f2907822":"plt.plot(history.history['lr'])\nplt.title('learning rate')\nplt.ylabel('lr')\nplt.xlabel('epoch')\nplt.show()","bfac0214":"cnn_model=models.load_model(disk_folder+\"\/best_result_checkpoint\",\n                            custom_objects={'top_3_categorical_accuracy':top_3_categorical_accuracy}) \ncnn_model.summary()\nplot_model(cnn_model, expand_nested=True, show_shapes=True, show_layer_names=False)","a9ed7ede":"loss, acc, top3_cat_acc = cnn_model.evaluate(X_val, y_val)\nprint(\"loss\", loss)\nprint(\"acc\", acc)\nprint(\"top 3 category acc\", top3_cat_acc)","b9f805ca":"def get_true_label(path_filename, dataframe, column_to_get):\n    filename = os.path.basename(os.path.normpath(path_filename))\n    index_row = data[data['file']==filename].index[0]\n    return data.loc[index_row, column_to_get]\n\n\ndef load_image(path_filename):\n\t# load the image\n\timg = load_img(path_filename, target_size=(32, 32))\n\t# convert to array\n\timg = img_to_array(img)\n\t# reshape into a single sample with 1 channel\n\timg = img.reshape(1, 32, 32, 3)\n\t# prepare pixel data\n\timg = img.astype('float32')\n\timg = img \/ 255.0\n\treturn img\n\ndef load_random_images(number_of_images_to_load = 9):\n    images = []\n    true_labels = []\n    true_backgrounds = []\n    \n    which_folder = [random.randint(1,3) for _ in range(number_of_images_to_load)]\n    for index_folder in which_folder:\n        if index_folder == 1:\n            path = folder +'letters\/'\n        else:\n            path = folder +'letters'+str(index_folder)+'\/'\n        nb_files = len(os.listdir(path))\n        \n        index_image = random.randint(0, len(os.listdir(path)))\n        \n        image = load_image(path + os.listdir(path)[index_image])\n        label = get_true_label(path + os.listdir(path)[index_image], data, 'letter')\n        background = get_true_label(path + os.listdir(path)[index_image], data, 'background')\n\n        images.append(image)\n        true_labels.append(label)\n        true_backgrounds.append(background)\n        \n    return images, true_labels, true_backgrounds\n\ndef classes_predictions(images_list_to_classify, true_labels, model):\n    \n    # plot first few images\n    plt.figure(figsize=(12,12))\n    for index, image in enumerate(images_list_to_classify):\n        \n        a_letter = model.predict_classes(image)\n        associated_letter = letters[a_letter[0]]\n        \n        # define subplot\n        plt.subplot(330 + 1 + index)\n        plt.title('Predicted Label: %s \\n'%associated_letter+\\\n                  'True Label: %s\\n'%true_labels[index],\n                 fontsize=18)\n        # plot raw pixel data\n        plt.imshow(image[0])\n        \n    plt.subplots_adjust(bottom = 0.001)  # the bottom of the subplots of the figure\n    plt.subplots_adjust(top = 0.99)\n        \n    # show the figure\n    plt.show()","17098795":"test_images, true_labels, true_backgrounds = load_random_images()","d9aaddfb":"classes_predictions(test_images, true_labels, cnn_model)","b251d822":"#save model\nmodel_json = cnn_model.to_json()\njson_file = open(disk_folder+\"\/my_model\" + \".json\", \"w\")\n#write structure\njson_file.write(model_json)\njson_file.close()\n# write wtights\nmodel.save_weights(disk_folder+\"\/my_model\"+\".h5\")\nprint(\"saving done\")","82093c4b":"## Creating train and test sets\n\nAs we are dealing with the classification problem, it's important to make sure that the class distribution is consistent in both train and test sets.\n\nIn order to control this, we will use `stratify` -- the parameter of `train_test_split` function.","798983cc":"## Saving the model\n\nWhen we are happy with the model's results, we can save the model to a file. We can also save weights and structure in different files.","774f5666":"Now let's restore model from the checkpoint it was saved to.","1906147c":"### In this notebook, we will use convolutional neural networks to classify letters written by hand.\n\nWe will see how to:\n- Preprocess images and metadata\n- Configure CNN\n- Use callbacks performing various actions during CNN training\n- Plot the training info \n- Plot the model's predictions on test images\n- Save the model to disk","09ee88cd":"### Target preprocessing \n\nSince we are going to use neural networks, it would be better to use One-hot encoding rather than ordinal. One-hot encoding means that each class (letter) will be represented by a separate column. The values will be either 0 or 1 depending on whether the image contains the letter.","f5ff29aa":"In the following cell, we define the callbacks that will make our life a bit easier:\n- `ReduceLROnPlateau` will automatically reduce learning rate when a metric has stopped improving\n- `ModelCheckpoint` will save the best model to disk so we can re-use it later.\n\n","829bf698":"## Plot the training info\n\nLet's look at the training process.\n\nThis plot shows how the accuracy changed over epochs on both train and val sets.","b0fba086":"Finally, we can also see the change of the learning rate.","3deecd7f":"### Loading the dataframe containing the information about the images","88bce383":"Now we define our neural network and print its structure as an image.","1b52cdda":"### Image preprocessing","1b2d7c9e":"### Plot the model's predictions on the test set\n\nAnd at last the most interesting part -- the model's predicitions!","cfb02f4b":"## Evaluating the model\n\nLet's evaluate the model performance on the test set.","6d059ff9":"We can also see how the loss was changing.","7aa0a4a6":"## That's it! Hope you find this quick notebook useful :)","a3714ebe":"## Configuring of CNN","0f565283":"Finally, it's time to train our CNN.\n\nMake sure you have enabled GPU, as the training will take a considerable amount of time!","d9cd8590":"We see that our dataset contains the following information: the letter, the encoded label, the filename, the background on the paper and the path to the file."}}