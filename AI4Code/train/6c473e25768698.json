{"cell_type":{"d7ab9bdb":"code","fff010f4":"code","04e05487":"code","49976b50":"code","9d1c2972":"code","ca060e70":"code","758f5e27":"code","29abd804":"code","25ebe83a":"code","e9901a2a":"code","769c6f8e":"code","d4f736ec":"code","a966de33":"code","eef39827":"code","726c7983":"code","8b64b45e":"code","100f18ac":"code","dc711646":"code","216ab2ac":"code","82de2437":"code","514a3429":"code","3f72ce2e":"code","c9c50ffe":"code","b28848a8":"code","ae942e6a":"code","d758beec":"code","fda4bf2e":"code","42f912fc":"code","002c16e2":"code","475c9ba8":"code","22689c62":"code","a84b4e35":"code","789a29d0":"code","2fdb1d02":"code","df6c9f9b":"code","a8e73894":"code","2e1be432":"code","c376dea2":"code","138d1df5":"code","ed230657":"code","a648f1e4":"code","2a6e327a":"code","9c006f19":"code","cceb9eef":"code","0e747c19":"code","d6665292":"code","9a796767":"code","ca3b37e2":"code","b8ec8a5b":"code","af30a87d":"code","0932bb1f":"code","7d9d9637":"code","63339603":"code","c24e554c":"code","d7497189":"code","e6225ba1":"code","9cb19b11":"code","d6fc9301":"code","d113062e":"markdown","24486e32":"markdown","ebe308d7":"markdown","2a1e4efb":"markdown","82232f80":"markdown","8ec8ca2c":"markdown","6902b777":"markdown","87145632":"markdown","aa5a95b6":"markdown","e3b9adda":"markdown","3371f683":"markdown","cecae24d":"markdown","bf0ce955":"markdown","429d5109":"markdown","29a719d1":"markdown","e0660d00":"markdown","de4b9c58":"markdown","5829b5db":"markdown","9c9e9f5f":"markdown","053d5d26":"markdown","b388aa94":"markdown","7ae05c6e":"markdown","dca967a4":"markdown","f6fc6135":"markdown","847ee3b0":"markdown"},"source":{"d7ab9bdb":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.manifold import TSNE \nfrom sklearn.decomposition import PCA \n\npd.set_option('display.max_columns', None)\n","fff010f4":"data = pd.read_excel(\"..\/input\/covid19\/Kaggle_Sirio_Libanes_ICU_Prediction.xlsx\")\ndata","04e05487":"print(data.dtypes)\ndata.select_dtypes(object)","49976b50":"without_ICU_column = data.drop('ICU', axis = 1)       #seperating the ICU lable column\nICU_column = data['ICU']\ncolums_to_convert = data.select_dtypes(object).columns   #finding columns that are not of type float or int\ncolums_to_convert","9d1c2972":"without_ICU_column = pd.get_dummies(without_ICU_column, columns = colums_to_convert)      #performing hotcoding\nwithout_ICU_column.head()","ca060e70":"data_expand = pd.concat([without_ICU_column, ICU_column], axis = 1)         #adding the ICU column again at the last position\ndata_expand.head(5)","758f5e27":"column_names = data_expand.columns\narr = data_expand.to_numpy()\nprint(arr)\ni=0\nICU_admitted_rows = []\nwhile(i<len(arr)):            #loop to record the rows in which patient is admitted to the ICU and adding 1 label to the previous rows.\n  for j in range(5):\n    if(arr[i+j][-1]==1):\n      for k in range(j):\n        arr[i+k][-1]=1\n      for toremove in range(i+j,i+5):\n        ICU_admitted_rows.append(toremove)\n      break\n  i+=5\nprint(ICU_admitted_rows)\ndeletedcount = 0\nfor rowToRemove in ICU_admitted_rows:             #removing the rows in which patient was admitted to the ICU\n  arr = np.delete(arr, rowToRemove-deletedcount, axis=0)\n  deletedcount+=1\ndf = pd.DataFrame(arr, columns = column_names)\ndf.head(10)","29abd804":"#Filling missing values\npd.options.mode.chained_assignment = None \nedited_dfs_list = []\nmax_patient_id = df['PATIENT_VISIT_IDENTIFIER'].max()\nfor i in range(int(max_patient_id)):                      #keeping only the first window that is 0-2 for every patient and filling NaN values with mean of all windows\n  tempdf = df[df['PATIENT_VISIT_IDENTIFIER']==i]\n  if(len(tempdf)!=0):\n    tempdf.fillna(tempdf.mean(), inplace=True)\n    tempdf = tempdf.iloc[[0]]\n    edited_dfs_list.append(tempdf)\n\n  \nfinal_data = pd.concat(edited_dfs_list)\nfinal_data.head(30)","25ebe83a":"final_data = final_data.drop(['GENDER','PATIENT_VISIT_IDENTIFIER','WINDOW_0-2',\t'WINDOW_2-4',\t'WINDOW_4-6',\t'WINDOW_6-12',\t'WINDOW_ABOVE_12'],axis = 1)\nfinal_data.head()","e9901a2a":"final_data.describe()","769c6f8e":"final_data = final_data.dropna(axis = 0)            #Now we must have to drop the rows having nan values as there is no data in any window to fill it.","d4f736ec":"final_data.describe()","a966de33":"ICU_admission_distribution = final_data['ICU'].value_counts()\nprint(\"Total Patients after pre processing: \", sum(ICU_admission_distribution))\nprint(\"Distribution of ICU admissions\")\nprint(\"Patients who were not admitted to ICU: \",ICU_admission_distribution[0])\nprint(\"Patients who were admitted to ICU: \",ICU_admission_distribution[1])\nlabels= ['Admitted to ICU', 'Not Admitted to ICU']\ncolors=['tomato', 'deepskyblue']\nsizes= [ICU_admission_distribution[1], ICU_admission_distribution[0]]\nplt.pie(sizes,labels=labels, colors=colors, startangle=90, autopct='%1.1f%%')\nplt.title(\"ICU Distribution of data\")\nplt.axis('equal')\nplt.show()","eef39827":"Age_distribution = final_data['AGE_ABOVE65'].value_counts()\nprint(\"Age Distribution\")\nprint(\"Patients below age 65: \",Age_distribution[0])\nprint(\"Patients above age 65: \",Age_distribution[1])\nlabels= ['Below 65', 'Above 65']\ncolors=['lightgreen', 'violet']\nsizes= [Age_distribution[0], Age_distribution[1]]\nplt.pie(sizes,labels=labels, colors=colors, startangle=90, autopct='%1.1f%%')\nplt.axis('equal')\nplt.title(\"Age Distribution of data\")\nplt.show()\n\n","726c7983":"ICU_Admitted_data = final_data[final_data['ICU']==1]\nAge_distribution = ICU_Admitted_data['AGE_ABOVE65'].value_counts()\nprint(\"Age Distribution\")\nprint(\"Patients below age 65: \",Age_distribution[0])\nprint(\"Patients above age 65: \",Age_distribution[1])\nlabels= ['Below 65', 'Above 65']\ncolors=['orange', 'cyan']\nsizes= [Age_distribution[0], Age_distribution[1]]\nplt.pie(sizes,labels=labels, colors=colors, startangle=90, autopct='%1.1f%%')\nplt.axis('equal')\nplt.title(\"Age Distribution of ICU Admitted patients\")\nplt.show()\n\nx = [[],[]]\nx[0].append(final_data['AGE_PERCENTIL_10th'].value_counts()[1])\nx[0].append(final_data['AGE_PERCENTIL_20th'].value_counts()[1])\nx[0].append(final_data['AGE_PERCENTIL_30th'].value_counts()[1])\nx[0].append(final_data['AGE_PERCENTIL_40th'].value_counts()[1])\nx[0].append(final_data['AGE_PERCENTIL_50th'].value_counts()[1])\nx[0].append(final_data['AGE_PERCENTIL_60th'].value_counts()[1])\nx[0].append(final_data['AGE_PERCENTIL_70th'].value_counts()[1])\nx[0].append(final_data['AGE_PERCENTIL_80th'].value_counts()[1])\nx[0].append(final_data['AGE_PERCENTIL_90th'].value_counts()[1])\nx[0].append(final_data['AGE_PERCENTIL_Above 90th'].value_counts()[1])\n\nx[1].append(ICU_Admitted_data['AGE_PERCENTIL_10th'].value_counts()[1])\nx[1].append(ICU_Admitted_data['AGE_PERCENTIL_20th'].value_counts()[1])\nx[1].append(ICU_Admitted_data['AGE_PERCENTIL_30th'].value_counts()[1])\nx[1].append(ICU_Admitted_data['AGE_PERCENTIL_40th'].value_counts()[1])\nx[1].append(ICU_Admitted_data['AGE_PERCENTIL_50th'].value_counts()[1])\nx[1].append(ICU_Admitted_data['AGE_PERCENTIL_60th'].value_counts()[1])\nx[1].append(ICU_Admitted_data['AGE_PERCENTIL_70th'].value_counts()[1])\nx[1].append(ICU_Admitted_data['AGE_PERCENTIL_80th'].value_counts()[1])\nx[1].append(ICU_Admitted_data['AGE_PERCENTIL_90th'].value_counts()[1])\nx[1].append(ICU_Admitted_data['AGE_PERCENTIL_Above 90th'].value_counts()[1])\n\na = []\nc=1\nfor i in x[0]:\n  a.extend([c*10]*i)\n  c+=1\nplt.hist(a, 20, label='Total')\nb = []\nc=1\nfor i in x[1]:\n  b.extend([c*10]*i)\n  c+=1\nprint(x)\nplt.hist(b, 20, label='ICU Admitted')\nplt.xticks([10,20,30,40,50,60,70,80,90,100],['AGE_PERCENTIL_10th','AGE_PERCENTIL_20th','AGE_PERCENTIL_30th','AGE_PERCENTIL_40th','AGE_PERCENTIL_50th','AGE_PERCENTIL_60th','AGE_PERCENTIL_70th','AGE_PERCENTIL_80th','AGE_PERCENTIL_90th','AGE_PERCENTIL_Above 90'], rotation = 70)\nplt.legend()\nplt.ylabel('Frequency')\nplt.title('Age Distribution Total and ICU Admitted')\nplt.show()","8b64b45e":"Diesease_Grouping_1 = final_data['DISEASE GROUPING 1'].value_counts()\nDiesease_Grouping_2 = final_data['DISEASE GROUPING 2'].value_counts()\nDiesease_Grouping_3 = final_data['DISEASE GROUPING 3'].value_counts()\nDiesease_Grouping_4 = final_data['DISEASE GROUPING 4'].value_counts()\nDiesease_Grouping_5 = final_data['DISEASE GROUPING 5'].value_counts()\nDiesease_Grouping_6 = final_data['DISEASE GROUPING 6'].value_counts()\nHTN_total = final_data['HTN'].value_counts()\nImmunocompromised_total = final_data['IMMUNOCOMPROMISED'].value_counts()\nOther_total = final_data['OTHER'].value_counts()\n\nICU_Diesease_Grouping_1 = ICU_Admitted_data['DISEASE GROUPING 1'].value_counts()\nICU_Diesease_Grouping_2 = ICU_Admitted_data['DISEASE GROUPING 2'].value_counts()\nICU_Diesease_Grouping_3 = ICU_Admitted_data['DISEASE GROUPING 3'].value_counts()\nICU_Diesease_Grouping_4 = ICU_Admitted_data['DISEASE GROUPING 4'].value_counts()\nICU_Diesease_Grouping_5 = ICU_Admitted_data['DISEASE GROUPING 5'].value_counts()\nICU_Diesease_Grouping_6 = ICU_Admitted_data['DISEASE GROUPING 6'].value_counts()\nHTN_ICU = ICU_Admitted_data['HTN'].value_counts()\nImmunocompromised_ICU = ICU_Admitted_data['IMMUNOCOMPROMISED'].value_counts()\nOther_ICU = ICU_Admitted_data['OTHER'].value_counts()\n\nx = np.array([[Diesease_Grouping_1[1],Diesease_Grouping_2[1],Diesease_Grouping_3[1],Diesease_Grouping_4[1],Diesease_Grouping_5[1],Diesease_Grouping_6[1],HTN_total[1], Immunocompromised_total[1]],[ICU_Diesease_Grouping_1[1],ICU_Diesease_Grouping_2[1],ICU_Diesease_Grouping_3[1],ICU_Diesease_Grouping_4[1],ICU_Diesease_Grouping_5[1],ICU_Diesease_Grouping_6[1],HTN_ICU[1], Immunocompromised_ICU[1]]])\na = []\nc=1\nfor i in x[0]:\n  a.extend([c]*i)\n  c+=1\nplt.hist(a, 15, label='Total')\nb = []\nc=1\nfor i in x[1]:\n  b.extend([c]*i)\n  c+=1\nprint(x)\nplt.hist(b, 15, label='ICU Admitted')\nplt.xticks([1,2,3,4,5,6,7,8,9],['Diesease_Grouping_1','Diesease_Grouping_2','Diesease_Grouping_3','Diesease_Grouping_4','Diesease_Grouping_5','Diesease_Grouping_6', 'Hypertension', 'Immunocompromised'], rotation = 70)\nplt.legend()\nplt.ylabel('Frequency')\nplt.title('Disease Distribution Total and ICU Admitted')\nplt.show()","100f18ac":"import seaborn as sns\ncorr = final_data.corr()\ncorr.shape\nplt.subplots(figsize=(100,100))\nax = sns.heatmap(\n    corr, \n    vmin=-1, vmax=1, center=0,\n    cmap=sns.diverging_palette(20, 220, n=200),\n    square=True\n)\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation=90,\n    horizontalalignment='right'\n);\ncorr.tail()\n","dc711646":"corr.shape\nICU_corr = corr.iloc[236]\nICU_corr.describe()\n","216ab2ac":"ICU_corr = np.array(ICU_corr)\nselection = []\nfor i in ICU_corr:\n  if(i):\n    if(i>0.11):\n      selection.append(True)\n    elif(i<-0.12):\n      selection.append(True)\n    else:\n      selection.append(False)\n  else:\n    selection.append(False)\n\nprint(len(selection), selection.count(True))\nselection = np.array(selection)\nselected_final_data = final_data.loc[:, selection]\nselected_final_data.head()\n\nselected_final_data = selected_final_data[['AGE_ABOVE65', 'DISEASE GROUPING 2', 'DISEASE GROUPING 3', 'DISEASE GROUPING 4',\n                                           'HTN', 'BIC_VENOUS_MEAN', 'CALCIUM_MEAN' , 'CREATININ_MEAN', 'GLUCOSE_MEAN', 'INR_MEAN',\n                                           'LACTATE_MEAN', 'LEUKOCYTES_MEAN', 'LINFOCITOS_MEAN', 'NEUTROPHILES_MEAN', 'PC02_VENOUS_MEAN',\n                                           'PCR_MEAN', 'PLATELETS_MEAN', 'SAT02_VENOUS_MEAN', 'SODIUM_MEAN', 'UREA_MEAN', 'BLOODPRESSURE_DIASTOLIC_MEAN',\n                                           'RESPIRATORY_RATE_MEAN', 'TEMPERATURE_MEAN', 'OXYGEN_SATURATION_MEAN', 'BLOODPRESSURE_SISTOLIC_MIN',\n                                           'HEART_RATE_MIN', 'RESPIRATORY_RATE_MIN', 'TEMPERATURE_MIN', 'BLOODPRESSURE_DIASTOLIC_MAX', 'BLOODPRESSURE_SISTOLIC_MAX',\n                                           'HEART_RATE_MAX', 'OXYGEN_SATURATION_MAX', 'BLOODPRESSURE_DIASTOLIC_DIFF', 'BLOODPRESSURE_SISTOLIC_DIFF', \n                                           'HEART_RATE_DIFF', 'RESPIRATORY_RATE_DIFF', 'TEMPERATURE_DIFF', 'OXYGEN_SATURATION_DIFF', \n                                           'AGE_PERCENTIL_10th', 'AGE_PERCENTIL_20th', 'AGE_PERCENTIL_80th', 'AGE_PERCENTIL_90th', 'ICU']]\n\nprint(selected_final_data.shape)\nselected_final_data.head()\n","82de2437":"corr = selected_final_data.corr()\ncorr.shape\nplt.subplots(figsize=(30,30))\nax = sns.heatmap(\n    corr, \n    vmin=-1, vmax=1, center=0,\n    cmap=sns.diverging_palette(20, 220, n=200),\n    square=True\n)\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation=90,\n    horizontalalignment='right'\n);\ncorr.tail()","514a3429":"selected_final_data.columns","3f72ce2e":"Non_ICU_Admitted_data = selected_final_data[selected_final_data['ICU']==0]\nICU_Admitted_data = selected_final_data[selected_final_data['ICU']==1]\n\nVital_Non_ICU_Admitted_data = Non_ICU_Admitted_data[['BLOODPRESSURE_DIASTOLIC_MEAN',\n       'RESPIRATORY_RATE_MEAN', 'TEMPERATURE_MEAN', 'OXYGEN_SATURATION_MEAN',\n       'BLOODPRESSURE_SISTOLIC_MIN', 'HEART_RATE_MIN', 'RESPIRATORY_RATE_MIN',\n       'TEMPERATURE_MIN', 'BLOODPRESSURE_DIASTOLIC_MAX',\n       'BLOODPRESSURE_SISTOLIC_MAX', 'HEART_RATE_MAX', 'OXYGEN_SATURATION_MAX',\n       'HEART_RATE_DIFF', 'RESPIRATORY_RATE_DIFF', 'TEMPERATURE_DIFF']]\n\nVital_ICU_Admitted_data = ICU_Admitted_data[['BLOODPRESSURE_DIASTOLIC_MEAN',\n       'RESPIRATORY_RATE_MEAN', 'TEMPERATURE_MEAN', 'OXYGEN_SATURATION_MEAN',\n       'BLOODPRESSURE_SISTOLIC_MIN', 'HEART_RATE_MIN', 'RESPIRATORY_RATE_MIN',\n       'TEMPERATURE_MIN', 'BLOODPRESSURE_DIASTOLIC_MAX',\n       'BLOODPRESSURE_SISTOLIC_MAX', 'HEART_RATE_MAX', 'OXYGEN_SATURATION_MAX',\n       'HEART_RATE_DIFF', 'RESPIRATORY_RATE_DIFF', 'TEMPERATURE_DIFF']]\n\n\nLab_Non_ICU_Admitted_data = Non_ICU_Admitted_data[['HTN', 'BIC_VENOUS_MEAN', 'CALCIUM_MEAN',\n       'CREATININ_MEAN', 'GLUCOSE_MEAN', 'INR_MEAN', 'LACTATE_MEAN',\n       'LEUKOCYTES_MEAN', 'LINFOCITOS_MEAN', 'NEUTROPHILES_MEAN',\n       'PC02_VENOUS_MEAN', 'PCR_MEAN', 'PLATELETS_MEAN', 'SAT02_VENOUS_MEAN',\n       'SODIUM_MEAN', 'UREA_MEAN']]\nLab_ICU_Admitted_data = ICU_Admitted_data[['HTN', 'BIC_VENOUS_MEAN', 'CALCIUM_MEAN',\n       'CREATININ_MEAN', 'GLUCOSE_MEAN', 'INR_MEAN', 'LACTATE_MEAN',\n       'LEUKOCYTES_MEAN', 'LINFOCITOS_MEAN', 'NEUTROPHILES_MEAN',\n       'PC02_VENOUS_MEAN', 'PCR_MEAN', 'PLATELETS_MEAN', 'SAT02_VENOUS_MEAN',\n       'SODIUM_MEAN', 'UREA_MEAN']]\n\n\n# set width of bar \nbarWidth = 0.25\nfig = plt.subplots(figsize =(20, 10)) \n   \nvital_non_ICU = np.array(Vital_Non_ICU_Admitted_data.mean(axis=0)) \nvital_ICU = np.array(Vital_ICU_Admitted_data.mean(axis=0)) \n   \n# Set position of bar on X axis \nbr1 = np.arange(len(vital_ICU)) + (barWidth*0.5)\nbr2 = [x + barWidth for x in br1]  \n   \n# Make the plot \nplt.bar(br2, vital_ICU, color ='r', width = barWidth, edgecolor ='grey', label ='ICU Admitted') \nplt.bar(br1, vital_non_ICU, color ='b', width = barWidth, edgecolor ='grey', label ='NOT Admitted') \n\n   \nplt.xlabel('Features', fontweight ='bold') \nplt.ylabel('Normalized Values', fontweight ='bold') \nplt.xticks([r + barWidth for r in range(len(vital_ICU))], ['BLOODPRESSURE_DIASTOLIC_MEAN',\n       'RESPIRATORY_RATE_MEAN', 'TEMPERATURE_MEAN', 'OXYGEN_SATURATION_MEAN',\n       'BLOODPRESSURE_SISTOLIC_MIN', 'HEART_RATE_MIN', 'RESPIRATORY_RATE_MIN',\n       'TEMPERATURE_MIN', 'BLOODPRESSURE_DIASTOLIC_MAX',\n       'BLOODPRESSURE_SISTOLIC_MAX', 'HEART_RATE_MAX', 'OXYGEN_SATURATION_MAX',\n       'HEART_RATE_DIFF', 'RESPIRATORY_RATE_DIFF', 'TEMPERATURE_DIFF'], rotation = 90) \n\nplt.legend()\nplt.title(\"Vital Signs of Covid19 Patients\")\nplt.show()\n\n\n# set width of bar \nbarWidth = 0.25\nfig = plt.subplots(figsize =(20, 10)) \n   \nlab_non_ICU = np.array(Lab_Non_ICU_Admitted_data.mean(axis=0)) \nlab_ICU = np.array(Lab_ICU_Admitted_data.mean(axis=0)) \n   \n# Set position of bar on X axis \nbr1 = np.arange(len(lab_ICU)) + (barWidth*0.5)\nbr2 = [x + barWidth for x in br1]  \n   \n# Make the plot \nplt.bar(br2, lab_ICU, color ='r', width = barWidth, edgecolor ='grey', label ='ICU Admitted') \nplt.bar(br1, lab_non_ICU, color ='b', width = barWidth, edgecolor ='grey', label ='NOT Admitted') \n\n   \nplt.xlabel('Features', fontweight ='bold') \nplt.ylabel('Normalized Value', fontweight ='bold') \nplt.legend()\nplt.xticks([r + barWidth for r in range(len(lab_ICU))], ['HTN', 'BIC_VENOUS_MEAN', 'CALCIUM_MEAN',\n       'CREATININ_MEAN', 'GLUCOSE_MEAN', 'INR_MEAN', 'LACTATE_MEAN',\n       'LEUKOCYTES_MEAN', 'LINFOCITOS_MEAN', 'NEUTROPHILES_MEAN',\n       'PC02_VENOUS_MEAN', 'PCR_MEAN', 'PLATELETS_MEAN', 'SAT02_VENOUS_MEAN',\n       'SODIUM_MEAN', 'UREA_MEAN'], rotation = 90) \nplt.title(\"Lab Test Results of Covid19 patients\")\nplt.show()","c9c50ffe":"X_data = np.array(selected_final_data.drop(['ICU'], axis = 1))\nY_data = np.array(selected_final_data[['ICU']])\nprint(X_data.shape)\nprint(Y_data.shape)\nfrom sklearn.decomposition import PCA \n\nlabels = []\nfor i in Y_data:\n  if(i[0]==0):\n    labels.append(0)\n  else:\n    labels.append(1)\nprint(X_data)\nY_data = np.array(labels)\n\n#pca = PCA(0.80)\n#X_data = pca.fit_transform(X_data)\nprint(\"pca \", X_data.shape)\nmodel = TSNE(n_components = 2, random_state = 0) \n  \ntsne_data = model.fit_transform(X_data) \n\n\n# creating a new data frame which \n# help us in ploting the result data \ntsne_data = np.vstack((tsne_data.T, Y_data)).T \ntsne_df = pd.DataFrame(data = tsne_data, \n     columns =(\"Dim_1\", \"Dim_2\",\"label\")) \n  \n# Ploting the result of tsne \nsns.FacetGrid(tsne_df, hue =\"label\", size = 6).map( \n       plt.scatter, 'Dim_1', 'Dim_2', s = 100).add_legend() \n  \nplt.show() \n","b28848a8":"selected_final_data.head()\n","ae942e6a":"print(X_data)\nprint(Y_data)","d758beec":"from sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import make_classification\nfrom sklearn import svm\nfrom sklearn import tree\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nimport matplotlib.pyplot as plt \nfrom sklearn.metrics import log_loss\nfrom sklearn import tree\nimport graphviz\nfrom sklearn.neural_network import MLPClassifier","fda4bf2e":"print(X_data.shape)\nprint(Y_data.shape)","42f912fc":"def ass(y_true,y_pred):\n  tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n  accuracy=(tp+tn)\/(tp+fp+fn+tn)\n  specificity = tn\/(tn+fp)\n  sensitivity=tp\/(tp+fn)\n  print(\"Accuracy:\",accuracy*100)\n  print(\"Sensitivity:\",sensitivity*100)\n  print(\"Specificity:\",specificity*100)\n  print(\"ROC_AUC_Score:\",roc_auc_score(y_true, y_pred)*100)\n  ","002c16e2":"X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.30, random_state=1)","475c9ba8":"lgc=make_pipeline(LogisticRegressionCV(cv=5,random_state=1,max_iter=5000))\nlgc.fit(X_train, Y_train)\ny_pred=lgc.predict(X_test)\nass(Y_test,y_pred)","22689c62":"gnb=make_pipeline(GaussianNB())\ngnb.fit(X_train,Y_train)\ny_pred=gnb.predict(X_test)\nass(Y_test,y_pred)","a84b4e35":"mx=-1\nri=-1\nfor i in range(1,10000):\n  sgd= make_pipeline(SGDClassifier(random_state=i))\n  sgd.fit(X_train,Y_train)\n  pmx=mx\n  mx=max(mx,sgd.score(X_test,Y_test))\n  if(pmx!=mx):\n    ri=i\nprint(ri)","789a29d0":"sgd= make_pipeline(SGDClassifier(random_state=ri))\nsgd.fit(X_train,Y_train)\ny_pred=sgd.predict(X_test)\nass(Y_test,y_pred)","2fdb1d02":"SVM_object = make_pipeline(svm.SVC(kernel='linear'))\nSVM_object.fit(X_train,Y_train)\ny_pred=SVM_object.predict(X_test)\nass(Y_test,y_pred)\n","df6c9f9b":"DT_object=tree.DecisionTreeClassifier(criterion='entropy',max_depth=4,max_leaf_nodes=10)\nDT_object.fit(X_train,Y_train)\ny_pred=DT_object.predict(X_test)\nass(Y_test,y_pred)","a8e73894":"from sklearn import tree\nimport graphviz\ntext_representation = tree.export_text(DT_object)\nprint(text_representation)\n","2e1be432":"features=['AGE_ABOVE65', 'DISEASE GROUPING 2', 'DISEASE GROUPING 3',\n       'DISEASE GROUPING 4', 'HTN', 'BIC_VENOUS_MEAN', 'CALCIUM_MEAN',\n       'CREATININ_MEAN', 'GLUCOSE_MEAN', 'INR_MEAN', 'LACTATE_MEAN',\n       'LEUKOCYTES_MEAN', 'LINFOCITOS_MEAN', 'NEUTROPHILES_MEAN',\n       'PC02_VENOUS_MEAN', 'PCR_MEAN', 'PLATELETS_MEAN', 'SAT02_VENOUS_MEAN',\n       'SODIUM_MEAN', 'UREA_MEAN', 'BLOODPRESSURE_DIASTOLIC_MEAN',\n       'RESPIRATORY_RATE_MEAN', 'TEMPERATURE_MEAN', 'OXYGEN_SATURATION_MEAN',\n       'BLOODPRESSURE_SISTOLIC_MIN', 'HEART_RATE_MIN', 'RESPIRATORY_RATE_MIN',\n       'TEMPERATURE_MIN', 'BLOODPRESSURE_DIASTOLIC_MAX',\n       'BLOODPRESSURE_SISTOLIC_MAX', 'HEART_RATE_MAX', 'OXYGEN_SATURATION_MAX',\n       'BLOODPRESSURE_DIASTOLIC_DIFF', 'BLOODPRESSURE_SISTOLIC_DIFF',\n       'HEART_RATE_DIFF', 'RESPIRATORY_RATE_DIFF', 'TEMPERATURE_DIFF',\n       'OXYGEN_SATURATION_DIFF', 'AGE_PERCENTIL_10th', 'AGE_PERCENTIL_20th',\n       'AGE_PERCENTIL_80th', 'AGE_PERCENTIL_90th']\nclasses=['Non-ICU','ICU']\ndot_data = tree.export_graphviz(DT_object, out_file=None, \n                                feature_names=features,  \n                                class_names=classes,\n                                filled=True)\ngraph = graphviz.Source(dot_data, format=\"png\") \ngraph","c376dea2":"KNN_object=make_pipeline(KNeighborsClassifier(n_neighbors=25,p=1))\nKNN_object.fit(X_train,Y_train)\ny_pred=KNN_object.predict(X_test)\nass(Y_test,y_pred)","138d1df5":"RF_object = RandomForestClassifier(criterion='gini',random_state=23,max_depth=6,bootstrap=True)\nRF_object.fit(X_train,Y_train)\ny_pred=RF_object.predict(X_test)\nass(Y_test,y_pred)","ed230657":"param_grid = {'criterion':['entropy','gini'],'max_depth':np.arange(1,30),'max_leaf_nodes':np.arange(3,20),'random_state':[1,2]}\nGS_DT=GridSearchCV(DecisionTreeClassifier(), param_grid,cv=5)\nGS_DT.fit(X_train,Y_train)\nGS_DT.best_params_","a648f1e4":"GS_DT.score(X_test,Y_test)","2a6e327a":"dt_train_score=[]\ndt_test_score=[]\nfor i in np.arange(1, 30):\n  param_grid = {'criterion':['entropy','gini'],'max_depth': [i],'max_leaf_nodes':np.arange(3,20),'random_state':[1,2]}\n  GS_DT=GridSearchCV(DecisionTreeClassifier(), param_grid,cv=5)\n  GS_DT.fit(X_train,Y_train)\n  y_train_pred=GS_DT.predict(X_train)\n  y_pred=GS_DT.predict(X_test)\n  dt_train_score.append(log_loss(Y_train,y_train_pred))\n  dt_test_score.append(log_loss(Y_test,y_pred))","9c006f19":"plt.title(\"Decision Tree Classifier : Error vs Depth\")\nplt.xlabel(\"Depth\")\nplt.ylabel(\"Error\")\nplt.plot(np.arange(1,30),dt_train_score,label=\"Training Error\")\nplt.plot(np.arange(1,30),dt_test_score,label=\"Testing Error\")\nplt.legend()\nplt.plot()","cceb9eef":"param_grid = {'kernel':['linear','poly','sigmoid','rbf'],'gamma':['scale','auto'],'random_state':[1,2,3]}\nGS_SVM=GridSearchCV(svm.SVC(), param_grid,cv=5)\nGS_SVM.fit(X_train,Y_train)\nGS_SVM.best_params_","0e747c19":"GS_SVM.score(X_test,Y_test)","d6665292":"dt_train_score=[]\ndt_test_score=[]\nfor i in ['linear','poly','sigmoid','rbf']:\n  param_grid = {'kernel':[i],'gamma':['scale','auto'],'random_state':[1,2,3]}\n  GS_SVM=GridSearchCV(svm.SVC(), param_grid,cv=5)\n  GS_SVM.fit(X_train,Y_train)\n  y_train_pred=GS_SVM.predict(X_train)\n  y_pred=GS_SVM.predict(X_test)\n  dt_train_score.append(log_loss(Y_train,y_train_pred))\n  dt_test_score.append(log_loss(Y_test,y_pred))","9a796767":"plt.title(\"SVM: Error vs kernel\")\nplt.xlabel(\"Kernel\")\nplt.ylabel(\"Error\")\nplt.plot(['linear','poly','sigmoid','rbf'],dt_train_score,label=\"Training Error\")\nplt.plot(['linear','poly','sigmoid','rbf'],dt_test_score,label=\"Testing Error\")\nplt.legend()\nplt.plot()","ca3b37e2":"param_grid = {'n_neighbors':[10,15,20,25,30,35,40],'leaf_size':np.arange(3,20),'p':[1,2]}\nGS_KNN=GridSearchCV(KNeighborsClassifier(), param_grid,cv=5)\nGS_KNN.fit(X_train,Y_train)\nGS_KNN.best_params_","b8ec8a5b":"GS_KNN.score(X_test,Y_test)","af30a87d":"knn_train_score=[]\nknn_test_score=[]\nfor i in [10,15,20,25,30,35,40]:\n  param_grid = {'n_neighbors': [i],'leaf_size':np.arange(3,20),'p':[1,2]}\n  GS_KNN=GridSearchCV(KNeighborsClassifier(), param_grid,cv=5)\n  GS_KNN.fit(X_train,Y_train)\n  y_train_pred=GS_KNN.predict(X_train)\n  y_pred=GS_KNN.predict(X_test)\n  knn_train_score.append(log_loss(Y_train,y_train_pred))\n  knn_test_score.append(log_loss(Y_test,y_pred))","0932bb1f":"plt.title(\"K-Neighbours Classifier: Error vs Number of Neighbors \")\nplt.xlabel(\"Number of Neighbors\")\nplt.ylabel(\"Error\")\nplt.plot([10,15,20,25,30,35,40],knn_train_score,label=\"Training Error\")\nplt.plot([10,15,20,25,30,35,40],knn_test_score,label=\"Testing Error\")\nplt.legend()\nplt.plot()","7d9d9637":"param_grid = {'criterion':['gini','entropy'],'max_depth': [6],'random_state':[23]}\nGS_RF=GridSearchCV(RandomForestClassifier(), param_grid,cv=5)\nGS_RF.fit(X_train,Y_train)\nGS_RF.best_params_","63339603":"GS_RF.score(X_test,Y_test)","c24e554c":"rf_train_score=[]\nrf_test_score=[]\nfor i in np.arange(1, 30):\n  param_grid = {'criterion':['gini','entropy'],'max_depth': [i],'random_state':[23]}\n  GS_RF=GridSearchCV(RandomForestClassifier(), param_grid,cv=5)\n  GS_RF.fit(X_train,Y_train)\n  y_train_pred=GS_RF.predict(X_train)\n  y_pred=GS_RF.predict(X_test)\n  rf_train_score.append(log_loss(Y_train,y_train_pred))\n  rf_test_score.append(log_loss(Y_test,y_pred))","d7497189":"plt.title(\"Random Forest Classifier : Error vs Max Depth\")\nplt.xlabel(\"Max Depth\")\nplt.ylabel(\"Error\")\nplt.plot(np.arange(1,30),rf_train_score,label=\"Training Error\")\nplt.plot(np.arange(1,30),rf_test_score,label=\"Testing Error\")\nplt.legend()\nplt.plot()","e6225ba1":"best=1\nacc=-1\nfor a in [\"identity\", \"logistic\", \"tanh\", \"relu\"]:\n    model = MLPClassifier(activation=a,max_iter=10000, batch_size=64,alpha=0.1,random_state=1).fit(X_train,Y_train)\n    y_pred = model.predict(X_test)\n    print(a)\n    ass(Y_test,y_pred)\n    score = model.score(X_test,Y_test)\n    if score>acc:\n      acc=score\n      best = a\n    #print(a,\" - \",model.score(X_test,Y_test))\nprint(best,acc)","9cb19b11":"rf_train_score=[]\nrf_test_score=[]\na=[0.001,0.01,0.1]\nfor i in range(len(a)):\n  param_grid = {'activation':[best],'max_iter': [10000],'batch_size':[64],'alpha':[0.1],'learning_rate_init':[a[i]],'random_state':[1]}\n  GS=GridSearchCV(MLPClassifier(), param_grid)\n  GS.fit(X_train,Y_train)\n  y_train_pred=GS.predict(X_train)\n  y_pred=GS.predict(X_test)\n  rf_train_score.append(log_loss(Y_train,y_train_pred))\n  rf_test_score.append(log_loss(Y_test,y_pred))","d6fc9301":"plt.title(\" MLPClassifier Error vs Learning rate\")\nplt.xlabel(\"Learning rate\")\nplt.ylabel(\"Error\")\nplt.plot([0.001,0.01,0.1],rf_train_score,label=\"Training Error\")\nplt.plot([0.001,0.01,0.1],rf_test_score,label=\"Testing Error\")\nplt.legend()\nplt.plot()","d113062e":"Shape of Datasets","24486e32":"##Libraries and Packages\nList of all the packages that is used in the notebook","ebe308d7":"Splitting Data into Training Data and Testing Data","2a1e4efb":"##Data Pre-Processing\nConverting the data into usable format.\nFollowing modifications has been done to the data to get most out of it:\n1. Binary hotcoding to convert not float columns.\n2. Marking Window 0-2 as 1 if the patient was admitted to ICU in any of the future windows. \n3. Removing all the records of the windows in which patients were actually admitted to the ICU (windows with ICU label 1 before the step 2).\n4. Filling the NaN values of window 0-2 with the help of mean of values in all the windows of that patient.\n5. Removing all the rows still having NaN values.\n","82232f80":"Grid Search on K nearest neighbour","8ec8ca2c":"Training model with different activation functions and finding model with best accuracy","6902b777":"Downloading Dataset\n","87145632":"Performing Decision tree classification\n","aa5a95b6":"Grid Search on Decision Tree","e3b9adda":"##Performing Grid Search on Various ML Algorithm","3371f683":" Best kernel Performance using Grid Search","cecae24d":"Performing SGD classifier with optimal Depth","bf0ce955":"Performing K-Nearest Neighbour Classifier \n","429d5109":"Performing SVM ( Supoort Vector Machine ) classification on the given data","29a719d1":"Finding Optimal Depth (SGD Classifier)","e0660d00":"#**Machine Learning Project**\n\n***Title: Predicting ICU admission of confirmed COVID-19 cases***\n\nThe COVID-19 pandemic has shown us the\nunpreparedness of our current healthcare system and\nservices. We need to optimize the allocation of medical\nresources to maximize the utilization of resources. We are\npreparing this Machine Learning model based on the\nclinical data of confirmed COVID-19 cases. This will help\nus to predict the need of ICU for a patient in advance. By\nthis information hospitals can plan the flow of operations\nand take critical decisions like shifting patient to another\nhospital or arrangement of resources within the time so\nthat the lives of patients can be saved.\n\n","de4b9c58":"Performing Logistic Regression with Cross Validation Estimator","5829b5db":"##Data Analysis\nVisualising the pre preoessed data and trying to get the intution about different characterstics.","9c9e9f5f":"Performing Random Forest Classifier","053d5d26":"Importing Libraries","b388aa94":"Performing Gaussian Naive Bayes ","7ae05c6e":"Performing Grid search on the model we got from the above","dca967a4":"## Training and Testing using various classifiers\n","f6fc6135":"Grid search on Random Forest Classifier","847ee3b0":"##Reading Dataset\nReading the dataset from the given CSV file."}}