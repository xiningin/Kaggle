{"cell_type":{"c7018a5f":"code","d4d29419":"code","ebbd165b":"code","4678a13d":"code","aa41b405":"code","6fd43496":"code","3354bae5":"code","b789c753":"code","aaef91ba":"code","fe43f8da":"code","2d78e42e":"code","682f9960":"code","82dfb5fe":"code","6dfd292b":"code","61aaf680":"code","6c5c24e5":"code","6bad8051":"code","41a53c0f":"code","94d0de40":"code","6c89f584":"code","c2081a46":"code","dd8aca45":"code","8aa2b34a":"code","621cc72d":"code","d9fb65d7":"code","e740fa38":"code","2b96bf8c":"code","f6cfe12e":"code","b0580775":"code","171b3b4e":"code","70d11ceb":"code","05242a43":"code","696c01a7":"code","36370c6f":"code","e0e1eb16":"code","aa65d910":"code","f17996df":"code","34671f71":"code","deb9d439":"code","111183c8":"code","48fe2a67":"code","43df2fdd":"code","37e6e814":"code","852a3941":"code","f76a871a":"code","c5767b5e":"code","8fb7e072":"code","7ab73417":"code","71576c1c":"code","b1ad7a31":"code","617c921c":"code","90135176":"code","a8bdd8ed":"code","6a251242":"code","ef46aefb":"code","7ba0eab2":"markdown","e17839f3":"markdown","eafad503":"markdown","ad184611":"markdown","94975439":"markdown"},"source":{"c7018a5f":"!conda install '\/kaggle\/input\/pydicom-conda-helper\/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y","d4d29419":"# ====================================================\n# Library\n# ====================================================\nimport sys\nsys.path.append('..\/input\/d\/kozodoi\/timm-pytorch-image-models\/pytorch-image-models-master')\n\nimport os\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport cv2\nfrom PIL import Image\n\nfrom matplotlib import pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\nfrom albumentations import (\n    Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n    RandomBrightness, RandomContrast, RandomBrightnessContrast, Rotate, ShiftScaleRotate, Cutout, \n    IAAAdditiveGaussianNoise, Transpose\n    )\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform\n\nimport timm\n\nfrom torch.cuda.amp import autocast, GradScaler\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","ebbd165b":"import os\n\nMODEL_DIR = '..\/input\/study-level-training\/'\nOUTPUT_DIR = '.\/'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n\n","4678a13d":"MODEL_DIR2 = '..\/input\/none-0-1-binary-training\/'","aa41b405":"import os\n\nfrom PIL import Image\nimport pandas as pd\nfrom tqdm.auto import tqdm","6fd43496":"df = pd.read_csv('..\/input\/siim-covid19-detection\/sample_submission.csv')\n# df = df.head(200)\n\n\nif df.shape[0] == 2477:\n    fast_sub = True\n    fast_df = pd.DataFrame(([['00086460a852_study', 'negative 1 0 0 1 1'], \n                         ['000c9c05fd14_study', 'negative 1 0 0 1 1'], \n                         ['65761e66de9f_image', 'none 1 0 0 1 1'], \n                         ['51759b5579bc_image', 'none 1 0 0 1 1']]), \n                       columns=['id', 'PredictionString'])\nelse:\n    fast_sub = False\n","3354bae5":"import numpy as np\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    # Original from: https:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n    # \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data","b789c753":"def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n    # Original from: https:\/\/www.kaggle.com\/xhlulu\/vinbigdata-process-and-resize-to-image\n    im = Image.fromarray(array)\n    \n    if keep_ratio:\n        im.thumbnail((size, size), resample)\n    else:\n        im = im.resize((size, size), resample)\n    \n    return im","aaef91ba":"\nsplit = 'test'\nsave_dir = f'\/kaggle\/tmp\/{split}\/'\n\nos.makedirs(save_dir, exist_ok=True)\n\nsave_dir = f'\/kaggle\/tmp\/{split}\/study\/'\nos.makedirs(save_dir, exist_ok=True)\nif fast_sub:\n    xray = read_xray('..\/input\/siim-covid19-detection\/train\/00086460a852\/9e8302230c91\/65761e66de9f.dcm')\n    im = resize(xray, size=512)  \n    study = '00086460a852' + '_study.png'\n    im.save(os.path.join(save_dir, study))\n    xray = read_xray('..\/input\/siim-covid19-detection\/train\/000c9c05fd14\/e555410bd2cd\/51759b5579bc.dcm')\n    im = resize(xray, size=512)  \n    study = '000c9c05fd14' + '_study.png'\n    im.save(os.path.join(save_dir, study))\nelse:   \n    for dirname, _, filenames in tqdm(os.walk(f'..\/input\/siim-covid19-detection\/{split}')):\n        for file in filenames:\n            # set keep_ratio=True to have original aspect ratio\n            xray = read_xray(os.path.join(dirname, file))\n            im = resize(xray, size=512)  \n            study = dirname.split('\/')[-2] + '_study.png'\n            im.save(os.path.join(save_dir, study))\n","fe43f8da":"image_id = []\ndim0 = []\ndim1 = []\nsplits = []\nsave_dir = f'\/kaggle\/tmp\/{split}\/image\/'\nos.makedirs(save_dir, exist_ok=True)\nif fast_sub:\n    xray = read_xray('..\/input\/siim-covid19-detection\/train\/00086460a852\/9e8302230c91\/65761e66de9f.dcm')\n    im = resize(xray, size=512)  \n    im.save(os.path.join(save_dir,'65761e66de9f_image.png'))\n    image_id.append('65761e66de9f.dcm'.replace('.dcm', ''))\n    dim0.append(xray.shape[0])\n    dim1.append(xray.shape[1])\n    splits.append(split)\n    xray = read_xray('..\/input\/siim-covid19-detection\/train\/000c9c05fd14\/e555410bd2cd\/51759b5579bc.dcm')\n    im = resize(xray, size=512)  \n    im.save(os.path.join(save_dir, '51759b5579bc_image.png'))\n    image_id.append('51759b5579bc.dcm'.replace('.dcm', ''))\n    dim0.append(xray.shape[0])\n    dim1.append(xray.shape[1])\n    splits.append(split)\nelse:\n    for dirname, _, filenames in tqdm(os.walk(f'..\/input\/siim-covid19-detection\/{split}')):\n        for file in filenames:\n            # set keep_ratio=True to have original aspect ratio\n            xray = read_xray(os.path.join(dirname, file))\n            im = resize(xray, size=512)  \n            im.save(os.path.join(save_dir, file.replace('.dcm', '_image.png')))\n            image_id.append(file.replace('.dcm', ''))\n            dim0.append(xray.shape[0])\n            dim1.append(xray.shape[1])\n            splits.append(split)\nmeta = pd.DataFrame.from_dict({'image_id': image_id, 'dim0': dim0, 'dim1': dim1, 'split': splits})","2d78e42e":"import numpy as np \nimport pandas as pd\nif fast_sub:\n    df = fast_df.copy()\nelse:\n    df = pd.read_csv('..\/input\/siim-covid19-detection\/sample_submission.csv')\n    \n# df = df.head(200)\nid_laststr_list  = []\nfor i in range(df.shape[0]):\n    id_laststr_list.append(df.loc[i,'id'][-1])\ndf['id_last_str'] = id_laststr_list\n\nstudy_len = df[df['id_last_str'] == 'y'].shape[0]","682f9960":"#load_dir = f\"\/kaggle\/input\/{COMPETITION_NAME}\/\"\nif fast_sub:\n    sub_df = fast_df.copy()\nelse:\n    sub_df = pd.read_csv('..\/input\/siim-covid19-detection\/sample_submission.csv')\n# sub_df = sub_df.head(200)\nsub_df = sub_df[:study_len]\ntest_paths = f'\/kaggle\/tmp\/{split}\/study\/' \n\nsub_df['negative'] = 0\nsub_df['typical'] = 0\nsub_df['indeterminate'] = 0\nsub_df['atypical'] = 0\n\n\nlabel_cols = sub_df.columns[2:]","82dfb5fe":"sub_df","6dfd292b":"import os\n\nfrom PIL import Image\nimport pandas as pd\nfrom tqdm.auto import tqdm","61aaf680":"import numpy as np\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    # Original from: https:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n    # \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data\n\n\ndef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n    # Original from: https:\/\/www.kaggle.com\/xhlulu\/vinbigdata-process-and-resize-to-image\n    im = Image.fromarray(array)\n    \n    if keep_ratio:\n        im.thumbnail((size, size), resample)\n    else:\n        im = im.resize((size, size), resample)\n    \n    return im","6c5c24e5":"class CFG:\n    debug=False\n    num_workers=4\n    model_name='tf_efficientnet_b7_ns'\n    model_name2='tf_efficientnet_b3'\n\n\n    size=512\n    batch_size=64\n    seed=42\n    target_size=4\n    target_cols=['Negative for Pneumonia','Typical Appearance','Indeterminate Appearance','Atypical Appearance']\n    n_fold=5\n    trn_fold=[0, 1, 2, 3,4]","6bad8051":"# ====================================================\n# Utils\n# ====================================================\ndef get_score(y_true, y_pred):\n    scores = []\n    for i in range(y_true.shape[1]):\n        score = roc_auc_score(y_true[:,i], y_pred[:,i])\n        scores.append(score)\n    avg_score = np.mean(scores)\n    return avg_score, scores\n\n\ndef get_result(result_df):\n    preds = result_df[[f'pred_{c}' for c in CFG.target_cols]].values\n    labels = result_df[CFG.target_cols].values\n    score, scores = get_score(labels, preds)\n    LOGGER.info(f'Score: {score:<.4f}  Scores: {np.round(scores, decimals=4)}')\n\n\n@contextmanager\ndef timer(name):\n    t0 = time.time()\n    LOGGER.info(f'[{name}] start')\n    yield\n    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n\n\ndef init_logger(log_file=OUTPUT_DIR+'inference.log'):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = init_logger()\n\n\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG.seed)","41a53c0f":"import glob\n#test = pd.read_csv('..\/input\/ranzcr-clip-catheter-line-classification\/sample_submission.csv')\ntest = sub_df\nprint(test.shape)\ntest.head()","94d0de40":"# file_path = glob.glob(f'..\/input\/siim-covid19-detection\/test\/' + {} +'\/*\/*')[0] \n# file_path","6c89f584":"class TestDataset(Dataset):\n    def __init__(self, df,study, transform=None):\n        self.df = df\n        self.file_names = df['id'].values\n        self.transform = transform\n        self.study = study\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        \n        file_name = self.file_names[idx]\n        if self.study:\n        #file_path = f'{TEST_PATH}\/{file_name}.jpg'\n            file_path = f'\/kaggle\/tmp\/{split}\/study\/' + file_name +'.png'   \n        else:\n            file_path = f'\/kaggle\/tmp\/{split}\/image\/' + file_name +'.png'  \n        #print(file_path.shape)\n\n\n        image = cv2.imread(file_path)\n        #print(image.shape)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        return image\n    \n    \n    \ndef get_transforms(*, data):\n    \n    if data == 'train':\n        return Compose([\n            Resize(CFG.size, CFG.size),\n\n            ToTensorV2(),\n        ])\n\n    elif data == 'valid':\n        return Compose([\n            Resize(CFG.size, CFG.size),\n\n            ToTensorV2(),\n        ])","c2081a46":"def inference(model, states, test_loader, device):\n    model.to(device)\n    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n    probs = []  \n    for i, images in tk0:\n        images = images.numpy()\n        images = images.astype(np.float32) \/ 255\n        images = torch.from_numpy(images)\n        images = images.to(device)\n        #print(images.shape)\n        avg_preds = []\n        for state in states:\n            model.load_state_dict(state['state_dict'])\n            model.eval()\n            with torch.no_grad():\n                y_preds = model(images)\n                probability = F.softmax(y_preds,-1)\n                #print(probability)\n                #print(y_preds)\n            #avg_preds.append(y_preds.sigmoid().to('cpu').numpy())\n            avg_preds.append(probability.to('cpu').numpy())\n        avg_preds = np.mean(avg_preds, axis=0)\n        probs.append(avg_preds)\n    probs = np.concatenate(probs)\n    return probs","dd8aca45":"def load_multigpu(model_path):\n    state_dict = torch.load(model_path)['model']\n    from collections import OrderedDict\n    new_state_dict = OrderedDict()\n    for k, v in state_dict.items():\n        name = k[7:] # remove `module.`\n        new_state_dict[name] = v\n    return new_state_dict","8aa2b34a":"def null_collate(batch):\n    collate = defaultdict(list)\n\n    for r in batch:\n        for k, v in r.items():\n            collate[k].append(v)\n\n    # ---\n    batch_size = len(batch)\n    image = np.stack(collate['image'])\n    image = image.reshape(batch_size, 3, CFG.size,CFG.size)#.repeat(3,1)\n    image = np.ascontiguousarray(image)\n    image = image.astype(np.float32) \/ 255\n    collate['image'] = torch.from_numpy(image)\n\n    return collate","621cc72d":"#model = CustomModel(CFG.model_name)\nstates = [torch.load(f'..\/input\/covid-models\/efficientnetv2_rw_s_512\/efficientnetv2_rw_s_512\/fold{fold}_model.pth') for fold in CFG.trn_fold]\ntest_dataset = TestDataset(test,study=True, transform=get_transforms(data='valid'))\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\n\n","d9fb65d7":"# model = Net(CFG.model_name)\nmodel = Net2()\n","e740fa38":"predictions = inference(model, states, test_loader, device)\n","2b96bf8c":"sub_df","f6cfe12e":"sub_df.iloc[:,2:] = predictions\n#test[['StudyInstanceUID'] + CFG.target_cols].to_csv(OUTPUT_DIR+'submission.csv', index=False)\nsub_df.head()","b0580775":"del test_dataset,test_loader,model,predictions,states\n","171b3b4e":"import gc\ngc.collect()","70d11ceb":"study_len","05242a43":"sub_df.columns = ['id', 'PredictionString1', 'negative', 'typical', 'indeterminate', 'atypical']\ndf = pd.merge(df, sub_df, on = 'id', how = 'left')","696c01a7":"for i in range(study_len):\n    negative = df.loc[i,'negative']\n    typical = df.loc[i,'typical']\n    indeterminate = df.loc[i,'indeterminate']\n    atypical = df.loc[i,'atypical']\n    df.loc[i, 'PredictionString'] = f'negative {negative} 0 0 1 1 typical {typical} 0 0 1 1 indeterminate {indeterminate} 0 0 1 1 atypical {atypical} 0 0 1 1'","36370c6f":"df_study = df[['id', 'PredictionString']]\n\n# df.to_csv('submission.csv',index=False)\n# df","e0e1eb16":"df","aa65d910":"import gc\ngc.collect()","f17996df":"def get_transforms(*, data):\n    \n    if data == 'train':\n        return Compose([\n            Resize(CFG.size, CFG.size),\n           Normalize(\n               mean=[0.485, 0.456, 0.406],\n               std=[0.229, 0.224, 0.225],\n           ),\n            ToTensorV2(),\n        ])\n\n    elif data == 'valid':\n        return Compose([\n            Resize(CFG.size, CFG.size),\n           Normalize(\n               mean=[0.485, 0.456, 0.406],\n               std=[0.229, 0.224, 0.225],\n           ),\n            ToTensorV2(),\n        ])","34671f71":"def inference(model, states, test_loader, device):\n    model.to(device)\n    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n    probs = []  \n    for i, images in tk0:\n\n        images = images.to(device)\n        #print(images.shape)\n        avg_preds = []\n        for state in states:\n            model.load_state_dict(state)\n            model.eval()\n            with torch.no_grad():\n                y_preds = model(images).sigmoid()\n\n            avg_preds.append(y_preds.to('cpu').numpy())\n        avg_preds = np.mean(avg_preds, axis=0)\n        probs.append(avg_preds)\n        \n    probs = np.concatenate(probs)\n    return probs","deb9d439":"class CustomModel2(nn.Module):\n    def __init__(self, model_name='resnet200d_320'):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=False)\n\n        n_features = self.model.classifier.in_features\n        self.model.global_pool = nn.Identity()\n        self.model.classifier = nn.Identity()\n        self.pooling = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(n_features, 1)\n\n    def forward(self, x):\n        bs = x.size(0)\n        features = self.model(x)\n        pooled_features = self.pooling(features).view(bs, -1)\n        output = self.fc(pooled_features)\n        return output","111183c8":"if fast_sub:\n    sub_df = fast_df.copy()\nelse:\n    sub_df = pd.read_csv('..\/input\/siim-covid19-detection\/sample_submission.csv')\n# sub_df = sub_df.head(200)\nsub_df = sub_df[study_len:]\ntest_paths = f'\/kaggle\/tmp\/{split}\/image\/' + sub_df['id'] +'.png'\nsub_df['none'] = 0\n\nlabel_cols = sub_df.columns[2]\n\n\n\n","48fe2a67":"test = sub_df","43df2fdd":"test","37e6e814":"model = CustomModel2(CFG.model_name2)\nstates = [torch.load(MODEL_DIR2+f'{CFG.model_name2}_fold{fold}_best_loss.pth')['model'] for fold in CFG.trn_fold]\ntest_dataset = TestDataset(test,study=False, transform=get_transforms(data='valid'))\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\npredictions = inference(model, states, test_loader, device)","852a3941":"predictions.shape","f76a871a":"sub_df[label_cols] = predictions","c5767b5e":"sub_df","8fb7e072":"\ndf_2class = sub_df.reset_index(drop=True)","7ab73417":"del test_dataset,test_loader,model,predictions,states\n\n","71576c1c":"gc.collect()","b1ad7a31":"from numba import cuda\nimport torch\ncuda.select_device(0)\ncuda.close()\ncuda.select_device(0)","617c921c":"import numpy as np, pandas as pd\nfrom glob import glob\nimport shutil, os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sns\nimport torch","90135176":"meta = meta[meta['split'] == 'test']\nif fast_sub:\n    test_df = fast_df.copy()\nelse:\n    test_df = pd.read_csv('..\/input\/siim-covid19-detection\/sample_submission.csv')\n# test_df = test_df.head(200)\n\n\ntest_df = df[study_len:].reset_index(drop=True) \nmeta['image_id'] = meta['image_id'] + '_image'\nmeta.columns = ['id', 'dim0', 'dim1', 'split']\ntest_df = pd.merge(test_df, meta, on = 'id', how = 'left')\n","a8bdd8ed":"dim = 512 #1024, 256, 'original'\ntest_dir = f'\/kaggle\/tmp\/{split}\/image'\nweights_dir = '\/kaggle\/input\/siim-cov19-yolov5-train\/yolov5\/runs\/train\/exp\/weights\/best.pt'\n\nshutil.copytree('\/kaggle\/input\/yolov5-official-v31-dataset\/yolov5', '\/kaggle\/working\/yolov5')\nos.chdir('\/kaggle\/working\/yolov5') # install dependencies\n\nimport torch\n#from IPython.display import Image, clear_output  # to display images\n\n#clear_output()\n#print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))\n\n\n!python detect.py --weights $weights_dir\\\n--img 512\\\n--conf 0.001\\\n--iou 0.5\\\n--source $test_dir\\\n--save-txt --save-conf --exist-ok\ndef yolo2voc(image_height, image_width, bboxes):\n    \"\"\"\n    yolo => [xmid, ymid, w, h] (normalized)\n    voc  => [x1, y1, x2, y1]\n\n    \"\"\" \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n\n    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n\n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]\/2\n    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n\n    return bboxes\nimage_ids = []\nPredictionStrings = []\n\nfor file_path in tqdm(glob('runs\/detect\/exp\/labels\/*.txt')):\n    image_id = file_path.split('\/')[-1].split('.')[0]\n    w, h = test_df.loc[test_df.id==image_id,['dim1', 'dim0']].values[0]\n    f = open(file_path, 'r')\n    data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n    data = data[:, [0, 5, 1, 2, 3, 4]]\n    bboxes = list(np.round(np.concatenate((data[:, :2], np.round(yolo2voc(h, w, data[:, 2:]))), axis =1).reshape(-1), 12).astype(str))\n    for idx in range(len(bboxes)):\n        bboxes[idx] = str(int(float(bboxes[idx]))) if idx%6!=1 else bboxes[idx]\n    image_ids.append(image_id)\n    PredictionStrings.append(' '.join(bboxes))\n\n\npred_df = pd.DataFrame({'id':image_ids,\n                        'PredictionString':PredictionStrings})","6a251242":"test_df = test_df.drop(['PredictionString'], axis=1)\nsub_df = pd.merge(test_df, pred_df, on = 'id', how = 'left').fillna(\"none 1 0 0 1 1\")\nsub_df = sub_df[['id', 'PredictionString']]\nfor i in range(sub_df.shape[0]):\n    if sub_df.loc[i,'PredictionString'] == \"none 1 0 0 1 1\":\n        continue\n    sub_df_split = sub_df.loc[i,'PredictionString'].split()\n    sub_df_list = []\n    for j in range(int(len(sub_df_split) \/ 6)):\n        sub_df_list.append('opacity')\n        sub_df_list.append(sub_df_split[6 * j + 1])\n        sub_df_list.append(sub_df_split[6 * j + 2])\n        sub_df_list.append(sub_df_split[6 * j + 3])\n        sub_df_list.append(sub_df_split[6 * j + 4])\n        sub_df_list.append(sub_df_split[6 * j + 5])\n    sub_df.loc[i,'PredictionString'] = ' '.join(sub_df_list)\nsub_df['none'] = df_2class['none'] \nfor i in range(sub_df.shape[0]):\n    if sub_df.loc[i,'PredictionString'] != 'none 1 0 0 1 1':\n        sub_df.loc[i,'PredictionString'] = sub_df.loc[i,'PredictionString'] + ' none ' + str(sub_df.loc[i,'none']) + ' 0 0 1 1'\nsub_df = sub_df[['id', 'PredictionString']]   \ndf_study = df_study[:study_len]\ndf_study = df_study.append(sub_df).reset_index(drop=True)\ndf_study.to_csv('\/kaggle\/working\/submission.csv',index = False)  \nshutil.rmtree('\/kaggle\/working\/yolov5')","ef46aefb":"df_study","7ba0eab2":"# 2 class","e17839f3":"# .dcm to .png","eafad503":"# yolov5 predict","ad184611":"# study string","94975439":"# study predict"}}