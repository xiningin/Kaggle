{"cell_type":{"2bda21c7":"code","baa98e06":"code","329d1ea4":"code","8e0dba69":"code","af0827bb":"code","966a2874":"code","3cfb4d53":"code","a0d286ab":"code","e8904867":"code","665676df":"code","f3dd52b6":"code","a857cbea":"code","7f1cdd80":"code","e5e48891":"code","f0b7dbed":"code","38987a2c":"code","57999778":"code","2d521fb8":"code","ca343cd5":"code","670c2f79":"code","25c85c4c":"code","2692e36f":"code","4563deab":"code","4b92640a":"code","c8272d91":"code","f472f495":"code","e929f46b":"code","33306c93":"code","d4c14860":"code","53608247":"code","e2b92a08":"code","ee2dc128":"code","1975dd9f":"code","bfede850":"code","89013ffa":"code","639277fc":"code","ebe4a0d9":"code","f84f8439":"code","fe05b12e":"code","c44b47ae":"code","1d31b03d":"code","a392a135":"code","d4ab117a":"code","f34dc810":"code","5aef7bd8":"code","8766e5b5":"code","7e74131b":"code","5d8a5ea8":"code","8fb2f7f6":"code","dc758266":"code","fb9afaa9":"code","83d56a0d":"code","a2519c5d":"code","9a341a04":"code","778af5d1":"code","3ac6fab7":"code","1883de15":"code","df70cf94":"code","87e5d51a":"code","8ab1980a":"code","0ab9949b":"code","eb579f89":"code","ca39bd86":"code","de667aa2":"code","9dca8690":"code","d2da282b":"code","b87fee6f":"code","12d790d5":"code","18484078":"code","b7b3f8be":"code","19f49130":"code","f707f575":"code","67d3ae6c":"code","65f3152f":"code","700e178d":"code","25738a20":"code","73fec157":"code","e9f7dcf1":"code","77042c56":"code","78494247":"code","b3254174":"code","98332f9a":"code","dab4354e":"code","7d0ac401":"code","5c434cb3":"code","0f0d3a41":"code","6062bcfe":"code","7e2c0495":"code","c9b0d937":"code","0fca0efe":"code","1b45a23c":"code","8e3a0cae":"code","f85226cc":"code","8e1fbb84":"code","34b60eaa":"code","e3981e34":"code","6b3cf6e5":"code","c900e089":"code","8f0fa768":"code","12904744":"code","59bbe6e8":"code","218402ae":"code","4c9c49cd":"code","4c2d0fbb":"code","43fae67c":"code","aaf242ba":"code","a24c3c08":"code","1e801ed1":"code","5197b486":"code","06a93f1d":"code","ee6b4c6c":"code","2b18b88b":"code","62b4a35d":"code","cdce79f7":"code","c482c89c":"code","f5da84b1":"code","26cfaa4c":"code","026db2d6":"code","416a6a41":"code","ee011323":"code","77133489":"code","e1e7f2fd":"code","1898bdc4":"code","484f82f2":"code","c88c9284":"code","5c0fa5b7":"code","cd68f965":"code","25bf6e27":"code","5797f27b":"code","1fe5ebca":"code","a0580287":"code","af879ae0":"code","248ca355":"code","d70600ab":"code","b98126c8":"code","8913b4a3":"code","a3206dd9":"code","f76bc528":"code","8c85cc4f":"code","5ab4984f":"code","06544519":"code","a730cf60":"code","b8983539":"code","49d8011d":"code","e7674fd0":"code","667c6d50":"code","1f05f358":"code","d86da6ed":"code","b7c0afc6":"code","c06ea340":"code","c9b7bec1":"code","c6eb2aa1":"code","6417aaf5":"code","d18469f1":"code","ac817b62":"code","e702928c":"code","04cbc971":"code","bed993f7":"code","eec8ed8e":"code","9440b2ec":"code","0d70f433":"code","4acd42a8":"code","3ec0c2d7":"code","4050d0fc":"code","82cc0e78":"code","5faf929f":"code","a3fb57bf":"code","a4db1a2d":"markdown","37dd1e5c":"markdown","36da0f73":"markdown","b5f5df15":"markdown","40901147":"markdown","f36ce683":"markdown","a5a03095":"markdown","2d679d3a":"markdown","57f963c9":"markdown","a5a51ae4":"markdown","d1513ef3":"markdown","15b19276":"markdown","d9c1c71f":"markdown"},"source":{"2bda21c7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\nimport seaborn as sns #for Data visualisation\nimport matplotlib.pyplot as plt #for Data visualisation\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","baa98e06":"#importing datasets \ntrain=pd.read_csv('\/kaggle\/input\/Train_v2.csv')\ntest=pd.read_csv('\/kaggle\/input\/Test_v2.csv')\nsubmission=pd.read_csv('\/kaggle\/input\/SubmissionFile.csv')\nvariables=pd.read_csv('\/kaggle\/input\/VariableDefinitions.csv')","329d1ea4":"#copying original datasets for future usage in the program\ntrain_copy=train.copy()\ntest_copy=test.copy()","8e0dba69":"#combining dataset for easy data impuation in all datasets\ncombine = [train,test]","af0827bb":"#view first five rows\ntrain.head()","966a2874":"#view last five rows\ntrain.tail()","3cfb4d53":"#display columns in train dataset\nprint(train.columns.values)","a0d286ab":"#display columns in test dataset\nprint(test.columns.values)","e8904867":"#display shape for all datasets\ntrain.shape,test.shape,submission.shape,variables.shape","665676df":"#checking data types in the datasets\ntrain.info(),test.info()","f3dd52b6":"#view variables with missing values from train data\ntrain.isna().sum()","a857cbea":"#view variables with missing values from test data\ntest.isna().sum()","7f1cdd80":"#getting variable data into seperate dataset\ndummy1=pd.get_dummies(train['bank_account'])\ndummy1.head()","e5e48891":"#summary of the data\ndummy1.describe()","f0b7dbed":"#Display total numbers of people qualifying for accounts and not in the train dataset\nprint(\"Number of people qualifying for bank accounts\",(dummy1['Yes'].sum()))\nprint(\"Number of people doesn't qualify for bank accounts\",(dummy1['No'].sum()))","38987a2c":"#bar graph\nnames = ['Yes', 'No']\nvalues = [3312,20212]\n\nplt.figure(figsize=(30, 5))\n\nplt.subplot(131)\nplt.bar(names, values)\nplt.title('bank_account')\nplt.show()","57999778":"#data summary for household sizes\ntrain['household_size'].describe()","2d521fb8":"#indepent Variable(Numerical)\nplt.figure(3) \nplt.subplot(121) \nsns.distplot(train['household_size']);\nplt.subplot(122) \ntrain['household_size'].plot.box(figsize=(16,5))\nplt.show()","ca343cd5":"#data summary for age of respondents\ntrain['age_of_respondent'].describe()","670c2f79":"#indepent Variable(Numerical)\nplt.figure(4) \nplt.subplot(131) \nsns.distplot(train['age_of_respondent']);\nplt.subplot(132) \ntrain['age_of_respondent'].plot.box(figsize=(16,5))\nplt.show()","25c85c4c":"cellphone_access=pd.crosstab(train['cellphone_access'],train['bank_account'])\ncellphone_access.div(cellphone_access.sum(1).astype(float),axis=0).plot(kind=\"bar\",stacked=True,figsize=(4,4))","2692e36f":"gender_of_respondent=pd.crosstab(train['gender_of_respondent'],train['bank_account'])\ngender_of_respondent.div(gender_of_respondent.sum(1).astype(float),axis=0).plot(kind=\"bar\",stacked=True,figsize=(4,4))","4563deab":"relationship_with_head=pd.crosstab(train['relationship_with_head'],train['bank_account'])\nrelationship_with_head.div(relationship_with_head.sum(1).astype(float),axis=0).plot(kind=\"bar\",stacked=True,figsize=(4,4))\nmarital_status=pd.crosstab(train['marital_status'],train['bank_account'])\nmarital_status.div(marital_status.sum(1).astype(float),axis=0).plot(kind=\"bar\",stacked=True,figsize=(4,4))\neducation_level=pd.crosstab(train['education_level'],train['bank_account'])\neducation_level.div(education_level.sum(1).astype(float),axis=0).plot(kind=\"bar\",stacked=True,figsize=(4,4))\njob_type=pd.crosstab(train['job_type'],train['bank_account'])\njob_type.div(job_type.sum(1).astype(float),axis=0).plot(kind=\"bar\",stacked=True,figsize=(4,4))\n","4b92640a":"#categorising data from numrical data into ordinal data\nfor dataset in combine:    \n   \n    dataset.loc[(dataset['age_of_respondent'] > 0) & (dataset['age_of_respondent'] <= 16), 'age_of_respondent'] = 0\n    dataset.loc[(dataset['age_of_respondent'] > 16) & (dataset['age_of_respondent'] <=200), 'age_of_respondent'] = 1\n \n\n","c8272d91":"#categorising data from numrical data into ordinal data\nfor dataset in combine:    \n    dataset.loc[(dataset['household_size'] > 0) & (dataset['household_size'] <= 3), 'household_size'] = 3\n    dataset.loc[(dataset['household_size'] > 3) & (dataset['household_size'] <= 6), 'household_size'] = 2\n    dataset.loc[(dataset['household_size'] > 6) & (dataset['household_size'] <=9), 'household_size'] = 1\n    dataset.loc[(dataset['household_size'] > 9) & (dataset['household_size'] <=21), 'household_size'] = 0","f472f495":"#getting gender_of_respondent data into seperate dataset\ndummy=pd.get_dummies(train['gender_of_respondent'])\ndummy.head()","e929f46b":"#categorical Variable(binary)\nplt.figure(4) \nplt.subplot(131) \nsns.distplot(dummy['Female']);\nplt.subplot(132) \ndummy['Female'].plot.box(figsize=(16,5))\n\nplt.show()","33306c93":"#categorical Variable(binary)\nplt.figure(4) \nplt.subplot(131) \nsns.distplot(dummy['Male']);\nplt.subplot(132) \ndummy['Male'].plot.box(figsize=(16,5))\n\nplt.show()","d4c14860":"#summary of the data\ndummy.describe()","53608247":"#Display total numbers of Females and Males in the train dataset\nprint(\"Number of Females\",(dummy['Female'].sum()))\nprint(\"Number of Males\",(dummy['Male'].sum()))","e2b92a08":"#bar graph\nnames = ['Female', 'Male']\nvalues = [13877,9647]\n\nplt.figure(figsize=(30, 5))\n\nplt.subplot(131)\nplt.bar(names, values)\nplt.title('gender_of_respondent')\nplt.show()","ee2dc128":"#getting variable data into seperate dataset\ndummytest1=pd.get_dummies(test['gender_of_respondent'])\ndummytest1.head()","1975dd9f":"#getting variable data into seperate dataset\ndummy3=pd.get_dummies(train['cellphone_access'])\ndummy3.head()","bfede850":"#summary data\ndummy3.describe()","89013ffa":"#categorical Variable(binary)\nplt.figure(4) \nplt.subplot(131) \nsns.distplot(dummy3['No']);\nplt.subplot(132) \ndummy3['No'].plot.box(figsize=(16,5))\n\nplt.show()","639277fc":"#categorical Variable(binary)\nplt.figure(4) \nplt.subplot(131) \nsns.distplot(dummy3['Yes']);\nplt.subplot(132) \ndummy3['Yes'].plot.box(figsize=(16,5))\n\nplt.show()","ebe4a0d9":"#display number of people having cellphones and not having cellphones\nprint(\"Number of people who doesn't cell phones\",(dummy3['No'].sum()))\nprint(\"Number of people who has cell phones\",(dummy3['Yes'].sum()))","f84f8439":"#bar graph\nnames = ['No','Yes']\nvalues = [6070,17454]\n\nplt.figure(figsize=(20, 5))\n\nplt.subplot(131)\nplt.bar(names, values)\nplt.title('cellphone_access')\nplt.show()","fe05b12e":"#getting variable data into seperate dataset\ndummytest3=pd.get_dummies(test['cellphone_access'])\ndummytest3.head()","c44b47ae":"#getting variable data into seperate dataset\ndummy4=pd.get_dummies(train['education_level'])\ndummy4.head()","1d31b03d":"#summary data\ndummy4.describe()","a392a135":"#display total numbers \nprint(\"Number of people with No formal education\",(dummy4['No formal education'].sum()))\nprint(\"Number of people with Other\/Dont know\/RTA\",(dummy4['Other\/Dont know\/RTA'].sum()))\nprint(\"Number of people with Primary education\",(dummy4['Primary education'].sum()))\nprint(\"Number of people with Secondary education\",(dummy4['Secondary education'].sum()))\nprint(\"Number of people with Tertiary education\",(dummy4['Tertiary education'].sum()))\nprint(\"Number of people with Vocational\/Specialised training\",(dummy4['Vocational\/Specialised training'].sum()))","d4ab117a":"#bar graph\nnames = ['No formal education','Other\/Dont know\/RTA','Primary education', 'Secondary education','Tertiary education','Vocational\/Specialised training']\nvalues = [4515,35,12791,4223,1157,803]\n\nplt.figure(figsize=(55, 5))\n\nplt.subplot(131)\nplt.bar(names, values)\nplt.title('Education level')\nplt.show()","f34dc810":"#getting variable data into seperate dataset\ndummytest4=pd.get_dummies(test['education_level'])\ndummytest4.head()","5aef7bd8":"#getting variable data into seperate dataset\ndummy5=pd.get_dummies(train['job_type'])\ndummy5.head()","8766e5b5":"#getting variable data into seperate dataset\ndummytest5=pd.get_dummies(test['job_type'])\ndummytest5.head()","7e74131b":"#sammary data\ndummy5.describe()","5d8a5ea8":"#display number totals\nprint(\"Number of people Dont Know\/Refuse to answer\",(dummy5['Dont Know\/Refuse to answer'].sum()))\nprint(\"Number of people with Farming and Fishing\",(dummy5['Farming and Fishing'].sum()))\nprint(\"Number of people with Formally employed Government\",(dummy5['Formally employed Government'].sum()))\nprint(\"Number of people with Formally employed Private\",(dummy5['Formally employed Private'].sum()))\nprint(\"Number of people with Government Dependent\",(dummy5['Government Dependent'].sum()))\nprint(\"Number of people with Informally employed\",(dummy5['Informally employed'].sum()))\nprint(\"Number of people with No Income\",(dummy5['No Income'].sum()))\nprint(\"Number of people with Other Income\",(dummy5['Other Income'].sum()))\nprint(\"Number of people with Remittance Dependent\",(dummy5['Remittance Dependent'].sum()))\nprint(\"Number of people with Self employed\",(dummy5['Self employed'].sum()))","8fb2f7f6":"#bar graph\nnames = ['Dont Know\/Refuse','Farming and Fishing','Formally employed Government', 'Formally employed Private','Government Dependent','Informally employed','No Income','Other Income','Remittance Dependent','Self employed']\nvalues = [126,5441,387,1055,247,5597,627,1080,2527,6437]\n\nplt.figure(figsize=(100,10))\n\nplt.subplot(131)\nplt.bar(names, values)\nplt.title('job_type')\nplt.show()","dc758266":"#getting variable data into seperate dataset\ndummy55=pd.get_dummies(train['marital_status'])\ndummy55.head()","fb9afaa9":"#getting variable data into seperate dataset\ndummytest55=pd.get_dummies(test['marital_status'])\ndummytest55.head()","83d56a0d":"#sammary data\ndummy55.describe()","a2519c5d":"#display totals\nprint(\"Number of people Divorced\/Seperated\",(dummy55['Divorced\/Seperated'].sum()))\nprint(\"Number of people Dont know\",(dummy55['Dont know'].sum()))\nprint(\"Number of people Married\/Living together\",(dummy55['Married\/Living together'].sum()))\nprint(\"Number of people Single\/Never Married\",(dummy55['Single\/Never Married'].sum()))\nprint(\"Number of people Widowed\",(dummy55['Widowed'].sum()))","9a341a04":"#bar graph\nnames = ['Dont know', 'Divorced\/Seperated', 'Widowed','Single\/Never Married','Married\/Living together']\nvalues = [2076,8,10749,7983,2708]\n\nplt.figure(figsize=(37, 7))\n\nplt.subplot(131)\nplt.bar(names, values)\nplt.title('marital_status')\nplt.show()","778af5d1":"#getting variable data into seperate dataset\ndummy6=pd.get_dummies(train['relationship_with_head'])\ndummy6.head()","3ac6fab7":"#sammary data\ndummy6.describe()","1883de15":"#display numbers totals\nprint(\"Number of children\",(dummy6['Child'].sum()))\nprint(\"Number of Head of Households\",(dummy6['Head of Household'].sum()))\nprint(\"Number of Other non-relatives\",(dummy6['Other non-relatives'].sum()))\nprint(\"Number of Other relatives\",(dummy6['Other relative'].sum()))\nprint(\"Number of Parent\",(dummy6['Parent'].sum()))\nprint(\"Number of Spouse\",(dummy6['Spouse'].sum()))","df70cf94":"#bar graph\nnames = ['Child', 'Head of Household', 'Other non-relatives','Other relative','Parent','Spouse']\nvalues = [2229,12831,190,668,1086,6520]\n\nplt.figure(figsize=(37, 7))\n\nplt.subplot(131)\nplt.bar(names, values)\nplt.title('relationship_with_head')\nplt.show()","87e5d51a":"#getting variable data into seperate dataset\ndummytest6=pd.get_dummies(test['relationship_with_head'])\ndummytest6.head()","8ab1980a":"#getting variable data into seperate dataset\ndummy7=pd.get_dummies(train['location_type'])\ndummy7.head()","0ab9949b":"#sammary data\ndummy7.describe()","eb579f89":"#display numbers totals\nprint(\"Number of people in Rural\",(dummy7['Rural'].sum()))\nprint(\"Number of of people in Urban\",(dummy7['Urban'].sum()))","ca39bd86":"#bar graph\nnames = ['Rural','Urban']\nvalues = [14343,9181]\n\nplt.figure(figsize=(20, 5))\n\nplt.subplot(131)\nplt.bar(names, values)\nplt.title('location_type')\nplt.show()","de667aa2":"#getting variable data into seperate dataset\ndummytest7=pd.get_dummies(test['location_type'])\ndummytest7.head()","9dca8690":"#concatinating datasets into one dataset\ntrain2=pd.concat((train,dummy,dummy3,dummy4,dummy5,dummy55,dummy6,dummy7),axis=1)","d2da282b":"#concatinating datasets into one dataset\ntest2=pd.concat((test,dummytest1,dummytest3,dummytest4,dummytest5,dummytest55,dummytest6,dummytest7),axis=1)","b87fee6f":"#view first five rows of data transformed\ntrain2.head().T","12d790d5":"#view first five rows of data transformed\ntest2.head().T","18484078":"\n#rename columns of interest \ntrain2=train2.rename(columns={\"Female\":\"gender_of_respondent_F\",\"Male\":\"gender_of_respondent_M\",\"Rural\":\"location_type_R\",\"Urban\":\"location_type_U\",\"Yes\":\"cellphone_access_Y\",\"No\":\"cellphone_access_N\"})\ntrain2.head()","b7b3f8be":"#rename columns of interest\ntest2=test2.rename(columns={\"Female\":\"gender_of_respondent_F\",\"Male\":\"gender_of_respondent_M\",\"Rural\":\"location_type_R\",\"Urban\":\"location_type_U\",\"Yes\":\"cellphone_access_Y\",\"No\":\"cellphone_access_N\"})\ntest2.head()","19f49130":"#view first five rows transformed\ntrain2.head().T","f707f575":"#view first five rows transformed\ntest2.head().T","67d3ae6c":"#display columns in the dataset\ntrain2.columns","65f3152f":"#drop unnecessary columns\ntrain2=train2.drop(['location_type','cellphone_access','gender_of_respondent', 'relationship_with_head', 'marital_status',\n       'education_level','job_type'], axis = 1) ","700e178d":"#drop unnecessary columns\ntest2=test2.drop(['location_type','cellphone_access','gender_of_respondent', 'relationship_with_head', 'marital_status',\n       'education_level','job_type'], axis = 1) ","25738a20":"#view first five rows\ntrain2.head()","73fec157":"#view last five rows\ntrain2.tail()","e9f7dcf1":"#view first five rows\ntest2.head()","77042c56":"#getting variable data into seperate dataset\ndummy1=pd.get_dummies(train2['bank_account'])\ndummy1.head()","78494247":"#concatinating datasets\ntrain2=pd.concat((train2,dummy1),axis=1)\ntrain2.head()","b3254174":"#drop unnecessary columns\ntrain2=train2.drop(['bank_account','No'], axis = 1)","98332f9a":"#rename column of interest\ntrain2=train2.rename(columns={\"Yes\":\"bank_account\"})\ntrain2.head().T","dab4354e":"import seaborn as sns;\nplt.subplots(figsize=(20,15))\nsns.heatmap(train2.corr(), annot = True, linewidths = 6, fmt= '.2g')\nplt.show()","7d0ac401":"#feature engineering\ntrain2['Education level']=train2['Secondary education']+train2['Tertiary education']+train2['Vocational\/Specialised training']\ntest2['Education level']=test2['Secondary education']+test2['Tertiary education']+test2['Vocational\/Specialised training']","5c434cb3":"#feature engineering\ntrain2['job_type']=train2['Farming and Fishing']+train2['Formally employed Government']+train2['Formally employed Private']+train2['Government Dependent']+train2['Other Income']+train2['Self employed']\ntest2['job_type']=test2['Farming and Fishing']+test2['Formally employed Government']+test2['Formally employed Private']+train2['Government Dependent']+test2['Other Income']+test2['Self employed']","0f0d3a41":"#feature engineering\ntrain2['marital status']=train2['Divorced\/Seperated']+train2['Married\/Living together']+train2['Single\/Never Married']+train2['Widowed']\ntest2['marital status']=test2['Divorced\/Seperated']+test2['Married\/Living together']+test2['Single\/Never Married']+test2['Widowed']","6062bcfe":"#feature engineering\ntrain2['relationship head']=train2['Head of Household']+train2['Other relative']+train2['Parent']+train2['Spouse']\ntest2['relationship head']=test2['Head of Household']+test2['Other relative']+test2['Parent']+test2['Spouse']","7e2c0495":"\n#feature engineering\ntrain2['gender']=train2['gender_of_respondent_F']+train2['gender_of_respondent_M']\ntest2['gender']=test2['gender_of_respondent_F']+test2['gender_of_respondent_M']","c9b0d937":"\n#feature engineering\ntrain2['location_type']=train2['location_type_R']+train2['location_type_U']\ntest2['location_type']=test2['location_type_R']+test2['location_type_U']","0fca0efe":"#feature engineering\n#train2['cellphone']=train2['cellphone_access_N']+train2['cellphone_access_Y']\n#test2['cellphone']=test2['cellphone_access_N']+test2['cellphone_access_Y']","1b45a23c":"train2.head().T","8e3a0cae":"# machine learning packages to be used\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import Pool, CatBoostClassifier, cv","f85226cc":"#drop unnecessary columns to be used in the models\ntrain2=train2.drop(\"uniqueid\", axis=1)\ntest2=test2.drop(\"uniqueid\", axis=1)","8e1fbb84":"#drop unnecessary columns to be used in the models\ntrain2=train2.drop(\"country\", axis=1)\ntest2=test2.drop(\"country\", axis=1)","34b60eaa":"#drop unnecessary columns to be used in models\ntrain2=train2.drop(\"year\", axis=1)\ntest2=test2.drop(\"year\", axis=1)","e3981e34":"#drop unnecessary columns to be used in models\ntrain2=train2.drop(['Other\/Dont know\/RTA','No formal education','Primary education','Secondary education','Tertiary education','Vocational\/Specialised training'], axis=1)\ntest2=test2.drop(['Other\/Dont know\/RTA','No formal education','Primary education','Secondary education','Tertiary education','Vocational\/Specialised training'], axis=1)","6b3cf6e5":"train2=train2.drop(['Dont Know\/Refuse to answer','Farming and Fishing','Formally employed Government', 'Formally employed Private','Government Dependent','Informally employed','No Income','Other Income','Remittance Dependent','Self employed'], axis=1)\ntest2=test2.drop(['Dont Know\/Refuse to answer','Farming and Fishing','Formally employed Government', 'Formally employed Private','Government Dependent','Informally employed','No Income','Other Income','Remittance Dependent','Self employed'], axis=1)","c900e089":"train2=train2.drop(['Child','Head of Household', 'Other non-relatives','Other relative','Parent','Spouse'], axis=1)\ntest2=test2.drop(['Child', 'Head of Household', 'Other non-relatives','Other relative','Parent','Spouse'], axis=1)","8f0fa768":"train2=train2.drop(['Dont know', 'Divorced\/Seperated', 'Widowed','Single\/Never Married','Married\/Living together'], axis=1)\ntest2=test2.drop(['Dont know', 'Divorced\/Seperated', 'Widowed','Single\/Never Married','Married\/Living together'], axis=1)","12904744":"\ntrain2=train2.drop(['gender_of_respondent_F','gender_of_respondent_M'], axis=1)\ntest2=test2.drop(['gender_of_respondent_F','gender_of_respondent_M'], axis=1)","59bbe6e8":"\ntrain2=train2.drop(['cellphone_access_N'], axis=1)\ntest2=test2.drop(['cellphone_access_N'], axis=1)\n","218402ae":"train2=train2.drop(['location_type_R','location_type_U'], axis=1)\ntest2=test2.drop(['location_type_R','location_type_U'], axis=1)","4c9c49cd":"#display shape for all datasets\ntrain2.shape,test2.shape","4c2d0fbb":"test2.head()","43fae67c":"test2.head().T","aaf242ba":"#calculate splitting data percentages\n#finding total count of datasets\nprint(\"Total population\",23524+10086)\n#finding test dataset percentage\nprint(\"test dataset\",10086\/33610*100,\"%\")\n#finding train dataset percentage\nprint(\"train dataset\",23524\/33610*100,\"%\")","a24c3c08":"#Model, predict and solve\nX_train = train2.drop(\"bank_account\", axis=1)\nY_train = train2.bank_account\n\nX_test  = test2\n\nX_train.shape, Y_train.shape, X_test.shape","1e801ed1":"LogisticRegression()","5197b486":"# Logistic Regression\n\nlogreg = LogisticRegression(n_jobs=100,random_state=30)","06a93f1d":"logreg.fit(X_train, Y_train)\nY_pred1 = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log","ee6b4c6c":"Y_pred1.sum()","2b18b88b":"coeff_df = pd.DataFrame(train2.columns.delete(0))\ncoeff_df.columns = ['Feature']\ncoeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n\ncoeff_df.sort_values(by='Correlation', ascending=False)","62b4a35d":"SVC()","cdce79f7":"# Support Vector Machines\n\nsvc = SVC(random_state=30)\nsvc.fit(X_train, Y_train)\nY_pred2 = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, Y_train) * 100, 2)\nacc_svc","c482c89c":"Y_pred2.sum()","f5da84b1":"KNeighborsClassifier()","26cfaa4c":"knn = KNeighborsClassifier(n_jobs=30,n_neighbors = 5)\nknn.fit(X_train, Y_train)\nY_pred3 = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nacc_knn","026db2d6":"Y_pred3.sum()","416a6a41":"GaussianNB()","ee011323":"# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\nY_pred4 = gaussian.predict(X_test)\nacc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\nacc_gaussian","77133489":"Y_pred4.sum()","e1e7f2fd":"Perceptron()","1898bdc4":"# Perceptron\n\nperceptron = Perceptron(n_jobs=30,random_state=100)\nperceptron.fit(X_train, Y_train)\nY_pred5 = perceptron.predict(X_test)\nacc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\nacc_perceptron","484f82f2":"Y_pred5.sum()","c88c9284":"LinearSVC()","5c0fa5b7":"# Linear SVC\n\nlinear_svc = LinearSVC(random_state=100)\nlinear_svc.fit(X_train, Y_train)\nY_pred6 = linear_svc.predict(X_test)\nacc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\nacc_linear_svc","cd68f965":"Y_pred6.sum()","25bf6e27":"SGDClassifier()","5797f27b":"# Stochastic Gradient Descent\n\nsgd = SGDClassifier(n_jobs=30,random_state=100)\nsgd.fit(X_train, Y_train)\nY_pred7 = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\nacc_sgd","1fe5ebca":"Y_pred7.sum()","a0580287":"DecisionTreeClassifier()","af879ae0":"# Decision Tree\n\ndecision_tree = DecisionTreeClassifier(random_state=100)\ndecision_tree.fit(X_train, Y_train)\nY_pred8 = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nacc_decision_tree","248ca355":"Y_pred8.sum()","d70600ab":"XGBClassifier()","b98126c8":"# XGBoost\n\nmodel_xgboost=XGBClassifier(n_estimators=100,n_jobs=30, random_state=100,max_depth=4)\nmodel_xgboost.fit(X_train, Y_train)\nY_pred9 = model_xgboost.predict(X_test)\nmodel_xgboost.score(X_train, Y_train)\nacc_xgboost = round(model_xgboost.score(X_train, Y_train) * 100, 2)\nacc_xgboost","8913b4a3":"Y_pred9.sum()","a3206dd9":"RandomForestClassifier()","f76bc528":"#Random forest\nrandom_forest = RandomForestClassifier(n_estimators=100,random_state=1)\nrandom_forest.fit(X_train, Y_train)\nY_pred10 = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","8c85cc4f":"Y_pred10.sum()","5ab4984f":"CatBoostClassifier()","06544519":"#Cat Boost\ncatboost= CatBoostClassifier(random_seed=100)","a730cf60":"catboost.fit(X_train, Y_train)\nY_pred11 = catboost.predict(X_test)\ncatboost.score(X_train, Y_train)\nacc_catboost= round(catboost.score(X_train, Y_train) * 100, 2)\nacc_catboost","b8983539":"Y_pred11.sum()","49d8011d":"#choose the features we want to train, just forget the float data\ncate_features_index = np.where(X_train.dtypes != float)[0]","e7674fd0":"#display models accuracy scores in descending order\nmodels = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree','XGBoost','Catboost'],\n    'Accuracy score': [acc_svc, acc_knn, acc_log, \n              acc_random_forest, acc_gaussian, acc_perceptron, \n              acc_sgd, acc_linear_svc, acc_decision_tree,acc_xgboost,acc_catboost]})\nmodels.sort_values(by='Accuracy score', ascending=False)","667c6d50":"#dividing train-test dataset to have validation part\nfrom sklearn.model_selection import train_test_split\nx_train,x_cv,y_train,y_cv=train_test_split(X_train,Y_train,test_size=0.3)","1f05f358":"#Applying dummy variable\nX_train=pd.get_dummies(X_train)\ntrain2=pd.get_dummies(train2)\ntest2=pd.get_dummies(test2)","d86da6ed":"#import Accuracy_score from sklearn \n\nfrom sklearn.metrics import accuracy_score","b7c0afc6":"from sklearn.model_selection import StratifiedKFold","c06ea340":"#Random Forest\ni=1 \nkf=StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\nfor train_index,test_index in kf.split(X_train ,Y_train):\n    print('\\n{} of kfold {}'.format(i,kf.n_splits))\n    xtr,xvl=X_train .loc[train_index],X_train .loc[test_index]\n    ytr,yvl=Y_train[train_index],Y_train[test_index] \n    model= RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=None, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=500,\n                       n_jobs=200, oob_score=False, random_state=500,\n                       verbose=0, warm_start=False)\n    model.fit(xtr,ytr)\n    pred_test=model.predict(xvl)\n    score=accuracy_score(yvl,pred_test)\n    print('accuracy_score',score) \n    i+=1\npred_test=model.predict(test2)\nprint(pred_test)\npred=model.predict_proba(xvl)[:,1]\nprint(pred)","c9b7bec1":"i=1 \nkf=StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\nfor train_index,test_index in kf.split(X_train ,Y_train):\n    print('\\n{} of kfold {}'.format(i,kf.n_splits))\n    xtr,xvl=X_train .loc[train_index],X_train .loc[test_index]\n    ytr,yvl=Y_train[train_index],Y_train[test_index] \n    model1= CatBoostClassifier(random_seed=100)\n    model1.fit(xtr,ytr)\n    pred_test1=model1.predict(xvl)\n    score1=accuracy_score(yvl,pred_test1)\n    print('accuracy_score',score1) \n    i+=1\npred_test1=model1.predict(test2)\nprint(pred_test1)\npred1=model1.predict_proba(xvl)[:,1]\nprint(pred1)","c6eb2aa1":"i=1 \nkf=StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\nfor train_index,test_index in kf.split(X_train ,Y_train):\n    print('\\n{} of kfold {}'.format(i,kf.n_splits))\n    xtr,xvl=X_train .loc[train_index],X_train .loc[test_index]\n    ytr,yvl=Y_train[train_index],Y_train[test_index] \n    model2= DecisionTreeClassifier()\n    model2.fit(xtr,ytr)\n    pred_test2=model2.predict(xvl)\n    score2=accuracy_score(yvl,pred_test2)\n    print('accuracy_score',score2) \n    i+=1\npred_test2=model2.predict(test2)\nprint(pred_test2)\npred2=model2.predict_proba(xvl)[:,1]\nprint(pred2)\n\n","6417aaf5":"i=1 \nkf=StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\nfor train_index,test_index in kf.split(X_train ,Y_train):\n    print('\\n{} of kfold {}'.format(i,kf.n_splits))\n    xtr,xvl=X_train .loc[train_index],X_train .loc[test_index]\n    ytr,yvl=Y_train[train_index],Y_train[test_index] \n    model3= DecisionTreeClassifier()\n    model3.fit(xtr,ytr)\n    pred_test3=model3.predict(xvl)\n    score3=accuracy_score(yvl,pred_test3)\n    print('accuracy_score',score3) \n    i+=1\npred_test3=model3.predict(test2)\nprint(pred_test3)\npred3=model3.predict_proba(xvl)[:,1]\nprint(pred3)","d18469f1":"i=1 \nkf=StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\nfor train_index,test_index in kf.split(X_train ,Y_train):\n    print('\\n{} of kfold {}'.format(i,kf.n_splits))\n    xtr,xvl=X_train .loc[train_index],X_train .loc[test_index]\n    ytr,yvl=Y_train[train_index],Y_train[test_index] \n    model4=XGBClassifier(n_estimators=100,n_jobs=30, random_state=100,max_depth=4)\n    model4.fit(xtr,ytr)\n    pred_test4=model4.predict(xvl)\n    score4=accuracy_score(yvl,pred_test4)\n    print('accuracy_score',score4) \n    i+=1\npred_test4=model4.predict(test2)\nprint(pred_test4)\npred4=model4.predict_proba(xvl)[:,1]\nprint(pred4)","ac817b62":" \ni=1 \nkf=StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\nfor train_index,test_index in kf.split(X_train ,Y_train):\n    print('\\n{} of kfold {}'.format(i,kf.n_splits))\n    xtr,xvl=X_train .loc[train_index],X_train .loc[test_index]\n    ytr,yvl=Y_train[train_index],Y_train[test_index] \n    model5=LinearSVC()\n    model5.fit(xtr,ytr)\n    pred_test5=model5.predict(xvl)\n    score5=accuracy_score(yvl,pred_test5)\n    print('accuracy_score',score5) \n    i+=1\npred_test5=model5.predict(test2)\nprint(pred_test5)\n","e702928c":"i=1 \nkf=StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\nfor train_index,test_index in kf.split(X_train ,Y_train):\n    print('\\n{} of kfold {}'.format(i,kf.n_splits))\n    xtr,xvl=X_train .loc[train_index],X_train .loc[test_index]\n    ytr,yvl=Y_train[train_index],Y_train[test_index] \n    model6= LogisticRegression(max_iter=50,n_jobs=100,random_state=50)\n    model6.fit(xtr,ytr)\n    pred_test6=model6.predict(xvl)\n    score6=accuracy_score(yvl,pred_test6)\n    print('accuracy_score',score6) \n    i+=1\npred_test6=model6.predict(test2)\nprint(pred_test6)\npred6=model6.predict_proba(xvl)[:,1]\nprint(pred6)","04cbc971":"# Gaussian Naive Bayes\nGaussianNB()","bed993f7":"i=1 \nkf=StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\nfor train_index,test_index in kf.split(X_train ,Y_train):\n    print('\\n{} of kfold {}'.format(i,kf.n_splits))\n    xtr,xvl=X_train .loc[train_index],X_train .loc[test_index]\n    ytr,yvl=Y_train[train_index],Y_train[test_index] \n    model7= GaussianNB()\n    model7.fit(xtr,ytr)\n    pred_test7=model7.predict(xvl)\n    score7=accuracy_score(yvl,pred_test7)\n    print('accuracy_score',score7) \n    i+=1\npred_test7=model7.predict(test2)\nprint(pred_test7)\npred7=model7.predict_proba(xvl)[:,1]\nprint(pred7)","eec8ed8e":"# Support Vector Machines\n\nsvc = SVC(random_state=30)\nsvc.fit(X_train, Y_train)\nY_pred2 = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, Y_train) * 100, 2)\nacc_svc","9440b2ec":"LogisticRegression(n_jobs=100,random_state=30)","0d70f433":"i=1 \nkf=StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\nfor train_index,test_index in kf.split(X_train ,Y_train):\n    print('\\n{} of kfold {}'.format(i,kf.n_splits))\n    xtr,xvl=X_train .loc[train_index],X_train .loc[test_index]\n    ytr,yvl=Y_train[train_index],Y_train[test_index] \n    model9=LogisticRegression(n_jobs=100,random_state=30)\n    model9.fit(xtr,ytr)\n    pred_test9=model9.predict(xvl)\n    score9=accuracy_score(yvl,pred_test9)\n    print('accuracy_score',score9) \n    i+=1\npred_test9=model9.predict(test2)\nprint(pred_test9)","4acd42a8":"i=1 \nkf=StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\nfor train_index,test_index in kf.split(X_train ,Y_train):\n    print('\\n{} of kfold {}'.format(i,kf.n_splits))\n    xtr,xvl=X_train .loc[train_index],X_train .loc[test_index]\n    ytr,yvl=Y_train[train_index],Y_train[test_index] \n    model8=SVC(random_state=30)\n    model8.fit(xtr,ytr)\n    pred_test8=model8.predict(xvl)\n    score8=accuracy_score(yvl,pred_test8)\n    print('accuracy_score',score8) \n    i+=1\npred_test8=model8.predict(test2)\nprint(pred_test8)\n","3ec0c2d7":"output = pd.DataFrame({'uniqueid':submission['uniqueid'],\n                       'bank_account':pred_test1})\noutput.to_csv('SubmissionFile.csv', index=False)\nprint(\"successfully saved!\")\n","4050d0fc":"print(pred_test.sum())\nprint(pred_test1.sum())\nprint(pred_test2.sum())\nprint(pred_test3.sum())\nprint(pred_test4.sum())\nprint(pred_test5.sum())\nprint(pred_test7.sum())\nprint(pred_test8.sum())\n","82cc0e78":"10086-748","5faf929f":"9338\/10086*100","a3fb57bf":"#bar graph\nnames = ['Yes', 'No']\nvalues = [748,9338]\n\nplt.figure(figsize=(10,6))\n\nplt.subplot(131)\nplt.bar(names, values)\nplt.title('bank_account')\nplt.show()","a4db1a2d":"* Data cleaning \n* We found no missing values or null values in the train and test datasets","37dd1e5c":"From the data we have more females than males from train dataset\nAround 59% is Females and around 41% is Males","36da0f73":"* Arournd 0.5% of people don't know\/refuse to answer\n* Around 23% of people are in farming and fishing\n* Around 1.6% of people are formally employed Government\n* Around 4.5% of people are formally employed private\n* Around 1.% of people are Government dependents\n* Around 24.% Are informally employed\n* Around 2.7% are with No Income\n* Around 4.6% are with other income\n* Around 10.7% are Remittance dependents\n* Around 27% are self employed ","b5f5df15":"***","40901147":"Looking at Education level, more people have primary education.","f36ce683":"* Looking at the bar graph the number of people who are self employed greater ","a5a03095":"* Around 19% of people have No formal Education\n* Around 0.1% of people is Other\/Don't Know\/ RTA\n* Around 54% of people have Primary Education\n* Around 18% of people have secondary education\n* Around Around 4% of people have Tertiary education\n* Around 3% of people have Vacational\/specialised training","2d679d3a":"improving the accuracy score ","57f963c9":"Now performing univariate analysis for numerical data for Household size and age respondents\n* The count of train data set is 23524 from popultion dataset\nlooking at variable household size \n1. We have mean of 1,standard deviation of 2.23 \n2. We have minimum household size of 1 and maximum household size of 21\n3. The data is skewed to the left with fair outliers\nlooking at variable age respondents\n1. We have mean of 38,81,standard deviation of 16 \n2. We have minimum 16 and maximum 100 of age respondents\n3. The data is skewed to the left \n\n","a5a51ae4":"* Looking at the bar graph more people have cellphones","d1513ef3":"Bivariate analysis","15b19276":"Around 26% does not have cellphones and 74% have cellphones","d9c1c71f":"* Now Doing Exploratory Data Analysis \n* Univariate Data analysis\n* There are 14% of people have  bank accounts\n* There are 86% of people who deosn't have bank accounts\n"}}