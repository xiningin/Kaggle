{"cell_type":{"005d5c24":"code","903800a0":"code","987af09d":"code","eb72046b":"code","2b30726c":"code","efbc5345":"code","2bb176bd":"code","75ad552e":"code","6bb8a675":"code","c9c6e5fd":"code","d9e3a29e":"code","e1de5add":"code","a1552313":"code","f84c3272":"code","98285199":"code","f9b5b423":"code","6fc9d88d":"code","295d6538":"code","8f1acc01":"code","443bfd63":"code","1e32bbcd":"code","2fdab1e0":"code","6fbb07ce":"code","99290d14":"code","66b4db97":"code","7fa654da":"code","e640548c":"code","f9fd9819":"code","8aab0657":"code","ff444059":"code","4929ced6":"code","44adf513":"code","fbbe9b82":"code","5c7b1fac":"code","7ac00015":"code","fac6d443":"code","a45c2ea5":"code","8929038a":"code","189e927e":"code","90921eb9":"code","6f60c904":"code","3f9dd881":"code","3cf042ba":"code","027d05b7":"code","6e5a91e5":"code","a27e259a":"code","fbf5d7b3":"code","48b90257":"code","f67908a3":"code","dab48069":"code","424cd293":"code","40f3c7ec":"code","be17aab6":"code","906942ec":"code","caed06d5":"code","86c57025":"code","0ea76ef4":"code","e5a3c255":"code","4acd1f4a":"code","bddffa90":"code","50eeffbd":"code","818f52d0":"code","d0e34df7":"code","64b4bf6f":"markdown","60160c3a":"markdown","06f7dd81":"markdown","3497b5ec":"markdown","9ac07630":"markdown","7ad3b29f":"markdown","3f334d19":"markdown","1f379246":"markdown","c774d17c":"markdown","049053cf":"markdown","3ed45a28":"markdown","6dea72d0":"markdown","6ea5b55d":"markdown","8724f60b":"markdown","12273d5f":"markdown","a7ea5f14":"markdown","73b0a313":"markdown","a6f45819":"markdown","b23db4eb":"markdown"},"source":{"005d5c24":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns # pretty plots\nimport matplotlib.pyplot as plt # plots\nfrom matplotlib import rcParams\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","903800a0":"# Load data\ndf_train = pd.read_csv('\/kaggle\/input\/widsdatathon2021\/TrainingWiDS2021.csv', index_col=0)\ndf_test = pd.read_csv('\/kaggle\/input\/widsdatathon2021\/UnlabeledWiDS2021.csv', index_col=0)\ndf_dict = pd.read_csv('\/kaggle\/input\/widsdatathon2021\/DataDictionaryWiDS2021.csv')","987af09d":"# Initial look at dataset\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\ndf_train.head()","eb72046b":"# Looks at class distribution to see if there is class imbalance\ntarget_count = df_train['diabetes_mellitus'].value_counts()\nprint(f'Class 0 (no diabetes): {target_count[0]}')\nprint(f'Class 1 (diabetes): {target_count[1]}')\nprint(f'Proportion: {round(target_count[0] \/ target_count[1], 2)} : 1')\nprint(f'Percentage of Majority Class: {round(target_count[1] \/ sum(target_count), 4)*100}')","2b30726c":"# Explore columns, null values and dtypes\nprint({df_train.info(verbose = True, null_counts = True)})","efbc5345":"# Percentage of null values per feature\nprint('% of null values per feature')\nprint(round(df_train.isnull().mean().mul(100).sort_values(ascending = False), 2))","2bb176bd":"def missing_zero_values_table(df):\n        mis_val = df.isnull().sum()\n        mis_val_percent = round(df.isnull().mean().mul(100), 2)\n        mz_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        mz_table = mz_table.rename(\n        columns = {df.index.name:'col_name', 0 : 'Missing Values', 1 : '% of Total Values'})\n        mz_table = mz_table[\n            mz_table.iloc[:,1] != 0 ].sort_values(\n        '% of Total Values', ascending=False)\n        return mz_table.reset_index()","75ad552e":"missing = missing_zero_values_table(df_train)\nmissing[:20].style.background_gradient(cmap='Reds')","6bb8a675":"# Data is anonymized already\n# Drop id columns, since these are only for identification purposes\ndf_train.drop(['encounter_id', 'hospital_id'], axis=1, inplace=True)\n\n# Drop other features that do not appear useful\ndf_train.drop(['icu_id','hospital_admit_source', 'icu_admit_source','icu_type'], axis=1)","c9c6e5fd":"# Create new table to explore continuous features\ncat_feat = ['ethnicity', 'gender', 'hospital_admit_source', 'icu_admit_source', 'icu_id', 'icu_stay_type', 'icu_type']\n\ncontin_eda = df_train.drop(cat_feat, axis=1)\ncontin_eda.head()","d9e3a29e":"# Describe continuous features\ncontin_eda.describe()","e1de5add":"# Find mean values for +diabetes\/-diabetes for each continuous variable column\ncontin_eda.groupby('diabetes_mellitus').mean()","a1552313":"for i in ['bmi', 'pre_icu_los_days', 'creatinine_apache', 'glucose_apache', 'pao2_apache', 'urineoutput_apache', 'd1_bilirubin_min', 'd1_bun_min', 'd1_glucose_max', 'd1_glucose_min', 'h1_glucose_max', 'h1_glucose_min', 'd1_pao2fio2ratio_max']:\n    has_diabetes = list(contin_eda[contin_eda['diabetes_mellitus'] == 0][i].dropna())\n    no_diabetes = list(contin_eda[contin_eda['diabetes_mellitus'] == 1][i].dropna())\n    xmin = min(min(has_diabetes), min(no_diabetes))\n    xmax = max(max(has_diabetes), max(no_diabetes))\n    width = (xmax - xmin) \/40\n    sns.distplot(has_diabetes, color='r', kde=False, bins=np.arange(xmin, xmax, width))\n    sns.distplot(no_diabetes, color='b', kde=False, bins=np.arange(xmin, xmax, width))\n    plt.legend(['+ Diabetes', '- Diabetes'])\n    plt.title('Overlaid historgram for {}'.format(i))\n    plt.show()","f84c3272":"## Create Correlation Matrix to look for redundancy of values \nfig = plt.subplots(figsize=(20,20)) \n\ncorrMatrix = contin_eda.corr()\nsns.heatmap(corrMatrix, annot=True)\n\nplt.show()","98285199":"# Investigate categorical variables and how many levels each one has in one bug dictionary\ntemp = {str(k): list(v) for k, v in df_train.groupby(df_train.dtypes, axis=1)}","f9b5b423":"for c in df_train:\n    if df_train[c].dtypes == 'object':\n        print(f'{c} : {df_train[c].unique()}\\n')\n        print(f'{df_train[c].value_counts()}\\n')\n        print(f'Missing count: {df_train[c].isnull().sum()}\\n')\n        print('================================\\n')","6fc9d88d":"df_train.groupby(['ethnicity'])['diabetes_mellitus'].mean()","295d6538":"df_train.groupby(['gender'])['diabetes_mellitus'].mean()","8f1acc01":"cat_feat = ['encounter_id', 'hospital_id', 'ethnicity', 'gender', 'hospital_admit_source', 'icu_admit_source', 'icu_id', 'icu_stay_type', 'icu_type']\ncat_eda = df_train[cat_feat]\ncat_eda.groupby([cat_feat])['diabetes_mellitus'].info()","443bfd63":"df_train.shape","1e32bbcd":"variable_names = list(df_train.columns)\nvariable_names","2fdab1e0":"df_train.groupby(['ethnicity'])['diabetes_mellitus'].mean()","6fbb07ce":"df_train.groupby(['gender'])['diabetes_mellitus'].mean()","99290d14":"df_train.groupby(['age'])['diabetes_mellitus'].mean()[:30]","66b4db97":"# Plots the distribution of ages\nfig, ax = plt.subplots(1, 1,figsize = (5,5), dpi = 100)\nsns.histplot(data=df_train, x='age');\n#plt.savefig('Error Distribution')","7fa654da":"# Plots the diabetes percentages for males and for females by age\nfig, ax = plt.subplots(1, 1,dpi = 100)\n\nsns.lineplot(data = df_train.groupby(['age'])['diabetes_mellitus'].mean().sort_values());\n\n\nax.set_ylabel('% with Diabetes');\nax.set_xlabel('Age');\nax.set_title('Diabetes Rates By Age');","e640548c":"# Plots the diabetes percentages for males and for females by age\nfig, ax = plt.subplots(1, 1,dpi = 100)\n\nsns.lineplot(data = df_train[(df_train['gender'] == 'M') & (df_train['age'] != 0)].groupby(['age'])['diabetes_mellitus'].mean().sort_values());\nsns.lineplot(data = df_train[(df_train['gender'] == 'F') & (df_train['age'] != 0)].groupby(['age'])['diabetes_mellitus'].mean().sort_values());\n\nax.set_ylabel('% with Diabetes');\nax.set_xlabel('Age');\nax.set_title('Diabetes Rates By Age');\nax.legend(['Male', 'Female'], framealpha=0);","f9fd9819":"df_train['rounded_bmi'] = round(df_train['bmi'])","8aab0657":"df_train['calculated_bmi'] = df_train['weight']\/(df_train['height']\/100)**2","ff444059":"df_train['rounded_calc_bmi'] = round(df_train['calculated_bmi'])","4929ced6":"# Plots the distribution of bmi\nfig, ax = plt.subplots(1, 1,figsize = (5,5), dpi = 100)\nsns.histplot(data=df_train, x='calculated_bmi');\n#plt.savefig('Error Distribution')","44adf513":"# Plots the distribution of bmi\nfig, ax = plt.subplots(1, 1,figsize = (5,5), dpi = 100)\nsns.histplot(data=df_train, x='calculated_bmi');\n#plt.savefig('Error Distribution')","fbbe9b82":"# Plots the diabetes percentages by BMI\nfig, ax = plt.subplots(1, 1,dpi = 100)\n\nsns.lineplot(data = df_train.groupby(['rounded_bmi'])['diabetes_mellitus'].mean().sort_values());\nsns.lineplot(data = df_train.groupby(['rounded_calc_bmi'])['diabetes_mellitus'].mean().sort_values());\n\n\nax.set_ylabel('% with Diabetes');\nax.set_xlabel('BMI');\nax.set_title('Diabetes Rates By BMI');\nax.legend(['Given', 'Calculated'], framealpha=0);","5c7b1fac":"df_train[df_train['age'] == 0]","7ac00015":"# Max Creatinine: First 24 Hours (d1_creatinine_max)\nsns.displot(df_train, x='d1_creatinine_max', hue='diabetes_mellitus', kde=True, multiple='stack', height= 10, aspect=10\/10)\nplt.title('Max Creatinine: First 24 Hours')\nplt.xlabel('d1_creatinine_max')\n\n\n# Max Creatinine: First Hour (h1_creatinine_max)\nsns.displot(df_train, x='h1_creatinine_max', hue='diabetes_mellitus', kde=True, multiple='stack', height= 10, aspect=10\/10)\nplt.title('Max Creatinine: First Hour')\nplt.xlabel('h1_creatinine_max')\n","fac6d443":"# Min Creatinine: First 24 Hour (d1_creatinine_min)\nsns.displot(df_train, x=\"d1_creatinine_min\", hue=\"diabetes_mellitus\", kde=True, multiple='stack', height= 10, aspect=10\/10)\nplt.title('Min Creatinine: First 24 Hour')\nplt.xlabel('d1_creatinine_min')\n\n# Min Creatinine: First Hour (h1_creatinine_min)\nsns.displot(df_train, x=\"h1_creatinine_min\", hue=\"diabetes_mellitus\", kde=True, multiple='stack', height= 10, aspect=10\/10)\nplt.title('Min Creatinine: First Hour')\nplt.xlabel('h1_creatinine_min')","a45c2ea5":"# Mean Max Blood Sugars\nprint(\"Mean 24 Hour Blood Sugar Max\")\nprint(df_train.groupby(['diabetes_mellitus'])['d1_glucose_max'].mean())\nprint(\"\\nMean 1 Hour Blood Sugar Max\")\nprint(df_train.groupby(['diabetes_mellitus'])['h1_glucose_max'].mean())\n\n# Mean Min Blood Sugars\nprint(\"\\nMean 24 Hour Blood Sugar Min\")\nprint(df_train.groupby(['diabetes_mellitus'])['d1_glucose_min'].mean())\nprint(\"\\nMean 1 Hour Blood Sugar Min\")\nprint(df_train.groupby(['diabetes_mellitus'])['h1_glucose_min'].mean())","8929038a":"# Create a max blood sugar dataframe\nd1_gluc_max = df_train.loc[df_train.d1_glucose_max > 300]\nh1_gluc_max = df_train.loc[df_train.h1_glucose_max > 300]\n\n# Max Blood Sugar: First 24 Hours (d1_glucose_max)\nsns.displot(df_train, x='d1_glucose_max', hue=\"diabetes_mellitus\", kde=True, multiple='stack', height= 10, aspect=10\/10)\nplt.title('Max Blood Sugar: First 24 Hours')\nplt.xlabel('d1_glucose_max')\n\n# Max Blood Sugar: First 24 Hours (d1_glucose_max > 300)\nsns.displot(d1_gluc_max, x='d1_glucose_max', hue=\"diabetes_mellitus\", kde=True, multiple='stack', height= 10, aspect=10\/10)\nplt.title('Max Blood Sugar (> 300): First 24 Hours')\nplt.xlabel('d1_glucose_max > 300')","189e927e":"# Max Blood Sugar: First 1 Hour (h1_glucose_max)\nsns.displot(df_train, x='h1_glucose_max', hue=\"diabetes_mellitus\", kde=True, multiple='stack', height= 10, aspect=10\/10)\nplt.title('Max Blood Sugar: First 24 Hours')\nplt.xlabel('h1_glucose_max')\n\n# Max Blood Sugar: First 1 Hour (h1_glucose_max > 300)\nsns.displot(h1_gluc_max, x='h1_glucose_max', hue=\"diabetes_mellitus\", kde=True, multiple='stack', height= 10, aspect=10\/10)\nplt.title('Max Blood Sugar (> 300): First Hour')\nplt.xlabel('h1_glucose_max > 300')","90921eb9":"# Max Blood Sugar: First 24 Hour (d1_glucose_max)\ndf_train.groupby('diabetes_mellitus')['d1_glucose_max'].mean().plot(kind=\"bar\",title=\"Max Glucose Levels in Hour 24\")\nplt.show()\n\n# Max Blood Sugar: First 1 Hour (h1_glucose_max)\ndf_train.groupby('diabetes_mellitus')['h1_glucose_max'].mean().plot(kind=\"bar\",title=\"Max Glucose Levels in Hour 1\")\nplt.show()\n","6f60c904":"# Identify categorical variables\ncategories = df_train.dtypes[df_train.dtypes == \"object\"].index","3f9dd881":"# Change categorical variables into dummy variables\nindicator_vars = pd.get_dummies(df_train[categories])\n\nindicator_vars.head()","3cf042ba":"# Produce cleaned df for processing\ntrain_copy = pd.concat([df_train, indicator_vars], axis = 1)\ntrain_copy = train_copy.drop(categories, axis = 1)\ntrain_copy.head()","027d05b7":"# Identify and drop features that have identical values\ncols_to_drop = []\nfor i, col_1 in enumerate(train_copy.columns):\n    for col_2 in train_copy.columns[(i+1):]:\n        if train_copy[col_1].equals(train_copy[col_2]):\n            print(f\"{col_1} and {col_2} are identical.\")\n            cols_to_drop.append(col_2)\n            \ntrain_copy.drop(cols_to_drop, axis=1, inplace = True)","6e5a91e5":"# Drop h1 cols\n# h1 columns have lot of missing values and h1 and d1 values are correlated\ndrop_columns = train_copy.columns[train_copy.columns.str.startswith('h1')]\n\ntrain_copy.drop(drop_columns, axis=1, inplace=True)","a27e259a":"train_copy.head()","fbf5d7b3":"# Impute mean gendered height for Nan\n# Determine mean value of height and weight for each gender\nmale_height_mean = int(train_copy[train_copy['gender_M']=='M']['height'].mean())\nfemale_height_mean = int(train_copy[train_copy['gender_F']=='F']['height'].mean())\nno_gender_height_mean  = int(train_copy[train_copy['gender'].isnull()]['height'].mean())\n\nmale_weight_mean = int(train_copy[train_copy['gender_M']=='M']['weight'].mean())\nfemale_weight_mean = int(train_copy[train_copy['gender_F']=='F']['weight'].mean())\nno_gender_weight_mean = int(train_copy[train_copy['gender'].isnull()]['weight'].mean())","48b90257":"# Impute mean gendered height for Nan\ntrain_copy['height'] = np.where((train_copy['height'].isnull() & train_copy['gender']=='M'), male_height_mean, train_copy['height'])\ntrain_copy['height'] = np.where((train_copy['height'].isnull() & train_copy['gender']=='F'), female_height_mean, train_copy['height'])\ntrain_copy['height'] = np.where((train_copy['height'].isnull() & train_copy['gender'].isnull()), no_gender_height_mean, train_copy['height'])\n\ntrain_copy['weight'] = np.where((train_copy['weight'].isnull() & train_copy['gender']=='M'), male_weight_mean, train_copy['weight'])\ntrain_copy['weight'] = np.where((train_copy['weight'].isnull() & train_copy['gender']=='F'), female_weight_mean, train_copy['weight'])\ntrain_copy['weight'] = np.where((train_copy['weight'].isnull() & train_copy['gender'].isnull()), no_gender_weight_mean, train_copy['weight'])","f67908a3":"# The names of the APACHE comorbidity variables\nvariable_names[172:]","dab48069":"# Number of null values for each variable\ntrain_copy[variable_names[172:]].isnull().sum()","424cd293":"# Correlation charts for the APACHE comorbidity variables.  \ntrain_copy[variable_names[172:]].corr()","40f3c7ec":"# The names of the lab blood gas variables\nprint(variable_names[156:172])","be17aab6":"# Percent of total values that are missing for each lab blood gas variable\nmissing_bloodgas = missing_zero_values_table(train_copy[variable_names[156:172]])\nmissing_bloodgas.style.background_gradient(cmap='Reds')","906942ec":"# Correlation charts for the lab blood gas variables.  \ntrain_copy[variable_names[156:172]+ ['diabetes_mellitus']].corr()","caed06d5":"print(variable_names[96:156])","86c57025":"# Percent of total values that are missing for each labs variable\nmissing_bloodgas = missing_zero_values_table(train_copy[variable_names[96:156]])\nmissing_bloodgas.style.background_gradient(cmap='Reds')","0ea76ef4":"# Correlation charts for the labs variables.  \ntrain_copy[variable_names[96:100]+ variable_names[126:130]+ ['diabetes_mellitus']].corr()","e5a3c255":"# Split original data into training (80%) and validation (20%)\n# Test set already accounted for\n\nfrom sklearn.model_selection import train_test_split\n\nlabels = train_copy['diabetes_mellitus']\nfeatures = train_copy.drop('diabetes_mellitus', axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=19)","4acd1f4a":"# Confirm training and validation data. \nfor dataset in [y_train, y_test]:\n    print(round(len(dataset) \/ len(labels), 2))","bddffa90":"# Write data to csv's\n\nX_train.to_csv('train_features.csv', index=False)\nX_test.to_csv('test_features.csv', index=False)\n\ny_train.to_csv('train_labels.csv', index=False)\ny_test.to_csv('test_labels.csv', index=False)","50eeffbd":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\n# Read in features and labels from training data\nX_tr_features = pd.read_csv('train_features.csv')\ny_tr_labels = pd.read_csv('train_labels.csv')","818f52d0":"# Five-fold cross validation\n\nrf_model = RandomForestClassifier()\n\nscores = cross_val_score(rf_model, X_tr_features, y_tr_labels.values.ravel(), cv=5)","d0e34df7":"randomForest_model = RandomForestClassifier(n_estimators=100, random_state=40, verbose = 1, n_jobs = -1)\ncv = cross_val_score(randomForest_model,x_train_uncorr,y_train.values.ravel(),cv=5, scoring='roc_auc')\nacc_random_forest=round(cv.mean() * 100, 2)\nprint(acc_random_forest)","64b4bf6f":"### Class Balance","60160c3a":"### Labs variables","06f7dd81":"### Plot continous features","3497b5ec":"# CLEAN DATA","9ac07630":"### Null Values","7ad3b29f":"# CREATE MODEL","3f334d19":"Based on the correlation chart, it doesn't seem like any of the variables in this category are strongly correlated with one another. Also, there are no null values for any of these variables. Thus for now, seems like it is reasonable to keep these variables in our model","1f379246":"### Explore categorical features","c774d17c":"### Explore Coninuous Features","049053cf":"Many of the first hour variables seem to have pretty high percentages of missing values. Some are extremely high. The correlation chart for the albumin and bilirubin variables is pretty indicative of the whole labs variables set in that generally, max and mins are highly correlated and the first day and first hour data are highly correlated. It would probably be reasonable to drop most of the first hour variables and several of the min and max variables.","3ed45a28":"# Variable Analysis","6dea72d0":"#### Correlation in Continuous Features","6ea5b55d":"### Apache Comorbidity variables","8724f60b":"All these variables seem to have a lot of missing values, especially the data from the first hour of the patients stay. Additionally, looking at the correlation chart, many of the first hour variables strongly correlate with their respective first day variables. Given this, it probably would be reasonable to drop the first hour data variables. Additionally, several of the first day max variables correlate with their respective min values. It may be reasonable to drop some of the max values (as the min values for these variables seem to correlate more strongly with the diabetes variables).","12273d5f":"# DATA EXPLORATION","a7ea5f14":"## Variables to Drop","73b0a313":"### Lab blood gas variables","a6f45819":"Creatinine can be an indicator of baseline renal function. Someone with a history of Diabetes might present with decreased renal function and lower levels of creatinine. ","b23db4eb":"Patients with Diabetes may present with a higher average blood glucose level. "}}