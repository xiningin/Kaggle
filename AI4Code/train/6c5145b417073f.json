{"cell_type":{"a579ae26":"code","0b3f4d12":"code","c7d51b50":"code","3da3316c":"code","0cf9cb15":"code","cb4de53d":"code","4b186261":"code","4f7e6ab5":"code","50b011e8":"code","36d5c174":"code","8184501c":"code","5081a9e2":"code","5e6e5381":"code","33a015b7":"code","ffb2131f":"code","a63f839f":"code","6a8a68cd":"code","6165fe71":"code","d0c12622":"code","a38b87e1":"code","98a9d51f":"code","a8d39f42":"code","13b1509d":"code","0d9a780c":"code","d00dad66":"code","a3f296ce":"code","65953cd3":"code","76bfa560":"code","28412896":"code","88ea9e9e":"code","ddee4180":"code","b7d8d0cc":"code","857eb8a9":"code","2015b0e3":"code","8b6036f1":"code","daaa76ee":"code","ed8ff26a":"code","74fddd31":"code","48e9673f":"code","b1f8c371":"code","86a56796":"code","d4b0e66f":"code","eb99b307":"code","4bde6af0":"code","de12fa6e":"code","790fdea4":"code","fa53e152":"code","38890d33":"code","f93f1f61":"code","5b7e7d25":"code","20e91e79":"code","13d91619":"code","ebc3c7f4":"code","e96ee41f":"code","95504079":"markdown","1e0e65dd":"markdown","95e94a5d":"markdown","f9d5052c":"markdown","d887ffc7":"markdown","8a6d000d":"markdown","a9bb077b":"markdown"},"source":{"a579ae26":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0b3f4d12":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport tensorflow \n\nfrom tensorflow import keras\nfrom keras.layers import Dense","c7d51b50":"sns.set(style='darkgrid',color_codes=True)\n%matplotlib inline","3da3316c":"eeg_df=pd.read_csv('..\/input\/confused-eeg\/EEG_data.csv')\ninfo_df=pd.read_csv('..\/input\/confused-eeg\/demographic_info.csv')","0cf9cb15":"eeg_df","cb4de53d":"info_df","4b186261":"info_df.rename(columns={'subject ID':'SubjectID'},inplace=True)","4f7e6ab5":"info_df #Now column in both the dataframes have same name","50b011e8":"data=info_df.merge(eeg_df, on='SubjectID')\ndata","36d5c174":"data.info()","8184501c":"data.isnull().sum()","5081a9e2":"data=data.drop(['SubjectID','VideoID','predefinedlabel'],axis=1)","5e6e5381":"data.columns","33a015b7":"#There are white spaces in the column names age ,ethinicity,gender\ndata.rename(columns={' age':'Age',' ethnicity':'Ethnicity',' gender':'Gender'},inplace=True)","ffb2131f":"data.columns","a63f839f":"data.rename(columns={'age':'Age','ethnicity':'Ethnicity','gender':'Gender'},inplace=True)","6a8a68cd":"data.columns","6165fe71":"data.rename(columns={'user-definedlabeln':'Label'},inplace=True)","d0c12622":"data.columns","a38b87e1":"data['Label']=data['Label'].astype(np.int)","98a9d51f":"data","a8d39f42":"print(\"Missing values:\",data.isna().sum().sum())","13b1509d":"data['Gender'].unique()","0d9a780c":"data['Gender']=data['Gender'].apply(lambda x:1 if x=='M' else 0) #just binary encoding\ndata['Gender']","d00dad66":"data['Ethnicity'].unique()","a3f296ce":"ethnicity_dummies=pd.get_dummies(data['Ethnicity'])\nethnicity_dummies","65953cd3":"data=pd.concat([data,ethnicity_dummies],axis=1)","76bfa560":"data=data.drop(['Ethnicity'],axis=1)","28412896":"data","88ea9e9e":"print(\"Non-Numeric columns:\",len(data.select_dtypes('object').columns))","ddee4180":"data.info()","b7d8d0cc":"features=data.drop('Label',axis=1).copy()","857eb8a9":"num_features=len(features.columns)","2015b0e3":"print(\"Features:\",num_features)","8b6036f1":"categorical_features=['Age','Gender','Han Chinese', 'English', 'Bengali']\ncontinous_features=['Attention', 'Mediation', 'Raw', 'Delta',\n       'Theta', 'Alpha1', 'Alpha2', 'Beta1', 'Beta2', 'Gamma1', 'Gamma2']\n\nprint(\"Categorical features:\",len(categorical_features))\nprint(\"Continuous features:\",len(continous_features))","daaa76ee":"features[continous_features]","ed8ff26a":"#For continuous features do box plot to know the distribution and outliers too\nfeatures[continous_features].plot(kind='box',figsize=(15,15),subplots=True,layout=(3,4))\nplt.show()\n#subplot=True means one plot for each column","74fddd31":"features[continous_features].plot(kind='hist',bins=25,figsize=(15,12),subplots=True,layout=(3,4))\nplt.show()","48e9673f":"#For categorical features pie charts of value points of each column are useful to know distribution\nplt.figure(figsize=(20,5))\nfor feature in categorical_features:\n    plt.subplot(1,5,categorical_features.index(feature)+1)\n    features[feature].value_counts().plot(kind='pie')\nplt.show()\n    ","b1f8c371":"plt.figure(figsize=(8,8))\ndata['Label'].value_counts().plot(kind='pie',autopct='%.1f%%')\nplt.show()","86a56796":"plt.figure(figsize=(20,20))\nsns.pairplot(features[continous_features])\nplt.show()","d4b0e66f":"corr=data.corr()\n\nplt.figure(figsize=(18,15))\nsns.heatmap(corr,annot=True,vmin=-1.0,cmap='mako')\nplt.show\n","eb99b307":"y=data['Label'].copy()\nX=data.drop(['Label'],axis=1).copy()","4bde6af0":"from sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\nX=scaler.fit_transform(X)\n","de12fa6e":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=123)","790fdea4":"inputs=tf.keras.Input(shape=(X_train.shape[1]))","fa53e152":"inputs","38890d33":"from sklearn.metrics import confusion_matrix,classification_report","f93f1f61":"from sklearn.metrics import confusion_matrix,classification_report\ninputs=tf.keras.Input(shape=(X_train.shape[1]))\nx=tf.keras.layers.Dense(512,activation='relu')(inputs)\nx=tf.keras.layers.Dense(512,activation='relu')(x)\noutputs=tf.keras.layers.Dense(1,activation='sigmoid')(x)\n\nmodel=tf.keras.Model(inputs,outputs)\n\nmodel.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=[\n        'accuracy',\n        tf.keras.metrics.AUC(name='auc')\n    ]\n)\nbatch_size=32\nepochs=50\nhistory= model.fit(\n    X_train,\n    y_train,\n    validation_split=0.2,\n    batch_size=batch_size,\n    epochs=epochs,\n    callbacks=[\n        tf.keras.callbacks.ReduceLROnPlateau()\n    ]\n\n)","5b7e7d25":"plt.figure(figsize=(16, 10))\n\nplt.plot(range(epochs), history.history['loss'], label=\"Training Loss\")\nplt.plot(range(epochs), history.history['val_loss'], label=\"Validation Loss\")\n\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.title(\"Loss Over Time\")\nplt.legend()\n\nplt.show()","20e91e79":"model.evaluate(X_test,y_test)\n#increasing neurons from 64 to 256 has led to increase in accuracy","13d91619":"y_true=np.array(y_test) # one dimension\ny_pred=np.squeeze(model.predict(X_test))#2dimension so write np.squeeze to amke it one dimension\ny_pred=np.array(y_pred>=0.5,dtype=np.int)","ebc3c7f4":"cm = confusion_matrix(y_true, y_pred)\n\nplt.figure(figsize=(4, 4))\n\nsns.heatmap(cm, annot=True, fmt='g', vmin=0, cbar=False)\n\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\n\nplt.show()","e96ee41f":"print(classification_report(y_true, y_pred))","95504079":"Cleaning - As there are two object columns ethinicity and gender","1e0e65dd":"Merging DataFrames","95e94a5d":"Multivariate Analysis #We do pair plots and correlation plots","f9d5052c":"Univariate Analysis.Let us look at each column individually","d887ffc7":"Splitting and Scaling","8a6d000d":"EDA","a9bb077b":"#Encoding features Ethinicity and Gender\n"}}