{"cell_type":{"46ab6319":"code","f93c7703":"code","5f6d4260":"code","7649cdcd":"code","d4acd5e2":"code","6a5dc5d1":"code","03858c6f":"code","a33150c1":"code","d4141b60":"code","52f74d34":"code","2d462130":"code","bcd225b2":"code","3ec2f308":"code","9ab86b4a":"code","c0494140":"code","8daf1018":"code","6d931346":"code","414a1964":"code","e1f54874":"code","e0ee9547":"code","8a996bdf":"code","c6f060d4":"code","28c02e38":"code","5736b244":"code","f26aef68":"code","210ee027":"code","aa28d013":"code","a2f609c1":"code","90696837":"code","b9da8c45":"code","7b27c281":"markdown","3da6f1fa":"markdown","1ae0a64a":"markdown","a809068b":"markdown","e5ce582c":"markdown"},"source":{"46ab6319":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom glob import glob\nimport os","f93c7703":"from tensorflow.keras.layers import Input, Lambda, Flatten, Dense\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input\nfrom tensorflow.keras.applications import vgg16, InceptionV3\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom keras.applications.vgg19 import preprocess_input","5f6d4260":"import random\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.model_selection import train_test_split","7649cdcd":"# IRO TFA CCFE","d4acd5e2":"IMAGE_SIZE = [224, 224]","6a5dc5d1":"vgg19 = VGG19(input_shape = IMAGE_SIZE + [3], weights = 'imagenet', include_top = False)","03858c6f":"# dont train the existing weights\nfor layer in vgg19.layers:\n    layer.trainable = False","a33150c1":"# useful for getting number of output classes\nfolders = glob('..\/input\/geological-image-similarity\/geological_similarity\/*')\nfolders","d4141b60":"# Converting images to dataframe to process it\ndef data_prep(andesite, gneiss, marble, quartzite, rhyolite, schist):\n\n    andesite = [\"..\/input\/geological-image-similarity\/geological_similarity\/andesite\" + '\/' +  a for a in andesite]\n    gneiss = [\"..\/input\/geological-image-similarity\/geological_similarity\/gneiss\" + '\/' +  b for b in gneiss]\n    marble = [\"..\/input\/geological-image-similarity\/geological_similarity\/marble\" + '\/' +  c for c in marble]\n    quartzite = [\"..\/input\/geological-image-similarity\/geological_similarity\/quartzite\" + '\/' +  d for d in quartzite]\n    rhyolite = [\"..\/input\/geological-image-similarity\/geological_similarity\/rhyolite\" + '\/' +  e for e in rhyolite]\n    schist = [\"..\/input\/geological-image-similarity\/geological_similarity\/schist\" + '\/' +  f for f in schist]\n\n    labels = len(andesite)*['andesite'] + len(gneiss)*['gneiss'] + len(marble)*['marble'] + len(quartzite)*['quartzite'] + len(rhyolite)*['rhyolite'] + len(schist)*['schist']\n    data = andesite + gneiss + marble + quartzite + rhyolite + schist\n\n    return pd.DataFrame({'Image_Path': data , 'Labels': labels})\n\n\ndf = data_prep(os.listdir('..\/input\/geological-image-similarity\/geological_similarity\/andesite\/'), os.listdir('..\/input\/geological-image-similarity\/geological_similarity\/gneiss\/'), os.listdir('..\/input\/geological-image-similarity\/geological_similarity\/marble\/'), os.listdir('..\/input\/geological-image-similarity\/geological_similarity\/quartzite\/'), os.listdir('..\/input\/geological-image-similarity\/geological_similarity\/rhyolite\/'), os.listdir('..\/input\/geological-image-similarity\/geological_similarity\/schist\/'))\ndf","52f74d34":"df['Labels'].value_counts().plot(kind = 'bar', color = ['red', 'green', 'yellow', 'grey', 'blue'])\nplt.title('Distribution of samples according to the categories')","2d462130":"from sklearn.model_selection import train_test_split\ntrain, test = train_test_split(df, test_size=0.2, random_state=1)","bcd225b2":"test.shape","3ec2f308":"# Time for data augmentation\n\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)","9ab86b4a":"x_train =  train_datagen.flow_from_dataframe(dataframe = train,  x_col='Image_Path', y_col='Labels',  class_mode='categorical',target_size=(224,224), shuffle=False, batch_size=10, seed=10)\nx_test = test_datagen.flow_from_dataframe(dataframe = test,  x_col='Image_Path', y_col='Labels',class_mode='categorical',  target_size=(224,224), shuffle=False, batch_size=10, seed=10)\nlen(x_train), len(x_test)","c0494140":"# Lets make the CNN for this\n# Create CNN\n\nimport tensorflow as tf\nmodel = tf.keras.Sequential(\n        [\n          tf.keras.layers.Conv2D(kernel_size=(3,3), input_shape=(224,224,3) ,filters=32, activation='relu', padding='same'),\n          tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n\n          tf.keras.layers.Conv2D(kernel_size=(3,3), input_shape=(224,224,3) ,filters=32, activation='relu', padding='same'),\n          tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n\n          tf.keras.layers.Conv2D(kernel_size=(3,3), input_shape=(224,224,3) ,filters=32, activation='relu', padding='same'),\n          tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n\n          tf.keras.layers.Conv2D(kernel_size=(3,3), input_shape=(224,224,3) ,filters=64, activation='relu', padding='same'),\n          tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n\n          tf.keras.layers.Flatten(),\n          tf.keras.layers.Dense(128, activation='relu'),\n          tf.keras.layers.Dropout(rate=0.5),\n          tf.keras.layers.Dense(6, activation='sigmoid')\n  ])","8daf1018":"model.compile(optimizer=tf.keras.optimizers.Adam(),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","6d931346":"model_history = model.fit_generator(generator = x_train, \n                   steps_per_epoch = 100,\n                   epochs = 10 ,\n                   validation_data = x_test,\n                   validation_steps = 100)\n","414a1964":"model.summary()","e1f54874":"\naccuracy = model_history.history['accuracy']\nloss = model_history.history['loss']\nvalidation_loss = model_history.history['val_loss']\nvalidation_accuracy = model_history.history['val_accuracy']\n\n\n\nplt.figure(figsize=(15, 7))\nplt.subplot(2, 2, 1)\nplt.plot(range(len(accuracy)), accuracy, label='Training Accuracy')\nplt.plot(range(len(accuracy)), validation_accuracy, label='Validation Accuracy')\nplt.legend(loc='upper left')\nplt.title('Accuracy : Training Vs Validation ')\n\n\n\nplt.subplot(2, 2, 2)\nplt.plot(range(len(accuracy)), loss, label='Training Loss')\nplt.plot(range(len(accuracy)), validation_loss, label='Validation Loss')\nplt.title('Loss : Training Vs Validation ')\nplt.legend(loc='upper right')\nplt.show()\n","e0ee9547":"from tensorflow.keras.preprocessing import image\nimg1=image.load_img('..\/input\/geological-image-similarity\/geological_similarity\/gneiss\/220Q5.jpg',target_size=(224,224,3))\nimg2=image.load_img('..\/input\/geological-image-similarity\/geological_similarity\/gneiss\/0THX1.jpg',target_size=(224,224,3))\nimg1 ","8a996bdf":"sim = cosine_similarity(\n    model.predict(preprocess_input(np.expand_dims(image.img_to_array(img1), axis=0))),\n    model.predict(preprocess_input(np.expand_dims(image.img_to_array(img2), axis=0)))\n)\nsim[0]","c6f060d4":"df['Image_Path'][:5]","28c02e38":"imagess = []\nfor img in df['Image_Path'][:]:\n\n    imgx = image.load_img(img,target_size=(224,224,3))\n    \n    similarities = cosine_similarity(model.predict(preprocess_input(np.expand_dims(image.img_to_array(img1), axis=0))), model.predict(preprocess_input(np.expand_dims(image.img_to_array(imgx), axis=0))))\n    imagess.append(similarities)\n#     break\nlen(imagess)","5736b244":"imagess[0]","f26aef68":"df1 = df\ndf1['Similarity'] = imagess\ndf1['Similarity'] = df1['Similarity'].astype(float)\ndf1","210ee027":"df1 = df1.sort_values('Similarity', ascending=False)\ndf1","aa28d013":"df1['Image_Path'][df1['Similarity'].idxmax()]","a2f609c1":"df1['Image_Path'][0]","90696837":"show_img = image.load_img(df1['Image_Path'][df1['Similarity'].idxmax()],\n                          target_size=(224,224,3))\nshow_img","b9da8c45":"for i in range(3):\n    show_img = image.load_img(df1['Image_Path'][i],\n                          target_size=(224,224,3))\n    print(show_img)","7b27c281":"# A brief walkthrough for this notebook:","3da6f1fa":"# The most similar image from the dataset to the chosen image is shown below :","1ae0a64a":"**The use is solved with tensorflow libraries to keep it simple for beginners as well**","a809068b":"# Here we see the 3(chosen K value for now) closest images to the selected image","e5ce582c":"The notebook is briefly divided into roughly 3 parts. (The 1st part is kinda not needed for the problem statement. Will update this part later.)\n\nThe first part is ML model building and applying it to the dataset after importing libraries and doing some train-test split.\n\nThe second part is to create images into vectors and feature selection for the said images. \n\nMoving onto the third part. After this is done a chosen image is matched to all the images we have to find the \"K\" most similar images to it.\n\nAnd after all this is done we try to display these closest images in our notebook.\n\nEdit : Thanks for the appreciation I am getting and will try to improve it further !"}}