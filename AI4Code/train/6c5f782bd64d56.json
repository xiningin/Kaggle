{"cell_type":{"fa28a015":"code","868c3dc5":"code","3743cd04":"code","6bdeb585":"code","3550b87b":"code","a9c7c927":"code","58c32f09":"code","8330fc6f":"code","2b13a45e":"code","41464f23":"code","a56420da":"code","a2d060cf":"code","4e5baa24":"code","d983238b":"code","ad47951a":"code","b9491857":"code","5328fcd4":"code","d1958712":"code","dae69df0":"code","5cbb1be0":"code","e17b672e":"code","7ae10c90":"code","7eedb874":"code","0c68c281":"code","ff859cca":"code","d9337cbd":"markdown","5488f6c6":"markdown","a2f87ddc":"markdown","60c880e9":"markdown","ad1b72a9":"markdown"},"source":{"fa28a015":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import norm, skew\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","868c3dc5":"#Drop ID as we dont need it for now\n\ntrain = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\ntrain.head()\ntrain_id = train['Id']\ntest_id = test['Id']\nfor i in [train,test]:\n    i.drop('Id',inplace=True,axis=1)","3743cd04":"#Checking and removing outliers for GrLivArea\nplt.scatter(x=train['GrLivArea'],y=train['SalePrice'])\ntrain = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)].index)","6bdeb585":"corrmat = train.corr()\ntop_f = corrmat.index[abs(corrmat['SalePrice'])>0.5]\ntop_f\nplt.figure(figsize=(10,10))\ng = sns.heatmap(train[top_f].corr(),annot=True,cmap=\"RdYlGn\")","3550b87b":"train.skew()","a9c7c927":"#Function to check the skewness of the data\ndef checkskew(col):\n    sns.distplot(train[col],fit=norm)\n    (mu, sigma) = norm.fit(train[col])\n    print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\ncheckskew('SalePrice')","58c32f09":"train['SalePrice'] = np.log1p(train['SalePrice'])\ncheckskew('SalePrice')","8330fc6f":"ntrain = train.shape[0]\nntest = test.shape[0]\ny_train = train.SalePrice.values\n\ndata = pd.concat((train,test)).reset_index(drop=True)\ndata.drop('SalePrice',axis=1,inplace=True)\ndata","2b13a45e":"data_na = (data.isnull().sum() \/ len(data))*100\ndata_na = data_na.drop(data_na[data_na==0].index).sort_values(ascending=False)\n\nplt.xticks(rotation='90')\nsns.barplot(data_na.index,data_na)\n","41464f23":"data[\"PoolQC\"] = data[\"PoolQC\"].fillna(\"None\")\ndata[\"MiscFeature\"] = data[\"MiscFeature\"].fillna(\"None\")\ndata[\"Alley\"] = data[\"Alley\"].fillna(\"None\")\ndata[\"FireplaceQu\"] = data[\"FireplaceQu\"].fillna(\"None\")\ndata[\"Fence\"] = data[\"Fence\"].fillna(\"None\")\nfor col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n    data[col] = data[col].fillna('None')\nfor col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    data[col] = data[col].fillna(0)\ndata['LotFrontage'] = data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x:x.fillna(x.median()))\nfor col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n    data[col] = data[col].fillna(0)\nfor col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    data[col] = data[col].fillna('None')\ndata[\"MasVnrType\"] = data[\"MasVnrType\"].fillna(\"None\")\ndata[\"MasVnrArea\"] = data[\"MasVnrArea\"].fillna(0)\ndata['MSZoning'] = data['MSZoning'].fillna(data['MSZoning'].mode()[0])\ndata.drop('Utilities',inplace=True,axis=1)\ndata['Functional'] = data['Functional'].fillna('Typ')\nmode_col = ['Electrical','KitchenQual', 'Exterior1st', 'Exterior2nd', 'SaleType']\nfor col in mode_col:\n    data[col] = data[col].fillna(data[col].mode()[0])","a56420da":"#Check if any more null values is present or not\ndata.isnull().sum().sum()","a2d060cf":"data.shape","4e5baa24":"#Now we want to convert the non-ordinal numerical data to string\ndata['MSSubClass'] = data['MSSubClass'].apply(str)\ndata['OverallCond'] = data['OverallCond'].astype(str)","d983238b":"from sklearn.preprocessing import LabelEncoder\ncols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n        'YrSold', 'MoSold')\n\n# process columns, apply LabelEncoder to categorical features\nfor i in cols:\n    lbl = LabelEncoder() \n    lbl.fit(list(data[i].values)) \n    data[i] = lbl.transform(list(data[i].values))\n\n# shape        \nprint('Shape all_data: {}'.format(data.shape))","ad47951a":"#Make one more new coloumn\ndata['TotalSF'] = data['TotalBsmtSF'] + data['1stFlrSF'] + data['2ndFlrSF']","b9491857":"#get all numeric data \nnum = data.dtypes[data.dtypes != 'object'].index\nskew_f = data[num].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nskewed = pd.DataFrame({'Skew':skew_f})\nskewed","5328fcd4":"skewed = skewed[abs(skewed) > 0.75]\nfrom scipy.special import boxcox1p\nskewed_features = skewed.index\nlam = 0.15\nfor feat in skewed_features:\n    data[feat] = boxcox1p(data[feat], lam)","d1958712":"data = pd.get_dummies(data)\ndata.shape","dae69df0":"train = data[:ntrain]\ntest = data[ntrain:]\ntrain.shape","5cbb1be0":"#First we'll make a validation fucntion\n#We'll use K-Fold Cross Validation\n\nn_folds=4\ndef vf(m):\n    kf = KFold(n_folds,shuffle=True,random_state=12).get_n_splits(train.values)\n    rmse= np.sqrt(-cross_val_score(m, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n    return(rmse)\n","e17b672e":"rr = KernelRidge(alpha=0.6,kernel='polynomial',degree=2,coef0=2.5)\nscore = vf(rr)\nprint(\"Ridge Regression Score : {:.4f}\".format(score.mean()))","7ae10c90":"GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n                                   max_depth=4, max_features='sqrt',\n                                   min_samples_leaf=15, min_samples_split=10, \n                                   loss='huber', random_state =5)\nscore = vf(GBoost)\nprint(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","7eedb874":"RidgeMd = rr.fit(train.values,y_train)\nGboostMd = GBoost.fit(train.values,y_train)","0c68c281":"finalMd = (np.expm1(RidgeMd.predict(test.values)) + np.expm1(GboostMd.predict(test.values)) ) \/ 2\nfinalMd","ff859cca":"ans = pd.DataFrame()\nans['Id'] = test_id\nans['SalePrice'] = finalMd\nans.to_csv('submission.csv',index=False)","d9337cbd":"Now we'll correct this skewness","5488f6c6":"Modelling","a2f87ddc":"**MISSING DATA**\n","60c880e9":"Ridge Regression","ad1b72a9":"We can see that features(OverallQual,GrLivArea and TotalBsmtSF) are highly correlated to sales price.\nGarageCars and GarageArea also seems to be correlated"}}