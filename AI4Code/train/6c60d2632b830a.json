{"cell_type":{"b064754c":"code","c31da6a8":"code","4597c844":"code","b9581c90":"code","1a3a1a02":"code","af7cc900":"code","87874f57":"code","233a7305":"code","5c8ada49":"code","f01a7382":"code","2ddcee09":"code","9bb83b86":"code","0cf8fdfc":"code","5bd33dde":"code","cbd45abb":"code","6f4d10b7":"code","331f8648":"code","07a6be52":"code","fef3cf0c":"code","7b238982":"code","f4d707e9":"code","9e818274":"code","a90b2512":"code","34b780f9":"code","f414e88c":"code","1967fc3e":"code","fa477ac7":"code","75c7f328":"code","45d3127c":"markdown","04fbcd5b":"markdown","14610723":"markdown","9ec789c6":"markdown"},"source":{"b064754c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport tensorflow.data as td\nimport matplotlib.pyplot as plt\nfrom imblearn.over_sampling import RandomOverSampler","c31da6a8":"AUTOTUNE = tf.data.experimental.AUTOTUNE","4597c844":"df = pd.read_csv('\/kaggle\/input\/aptos2019-blindness-detection\/train.csv')\ndf.sample(5)","b9581c90":"df.id_code.describe()","1a3a1a02":"df.isna().sum()","af7cc900":"df.plot.hist(by='diagnosis')\nplt.show()","87874f57":"oversampler = RandomOverSampler()","233a7305":"x,y = oversampler.fit_resample(df.id_code.values.reshape(-1,1),df.diagnosis.values)","5c8ada49":"df=pd.DataFrame({\"id_code\":x.flatten(),\"diagnosis\":y})","f01a7382":"df.plot.hist(by='diagnosis')\nplt.show()","2ddcee09":"imagePaths = df.apply(lambda x: '\/kaggle\/input\/aptos2019-blindness-detection\/train_images\/'+str(x[0])+'.png',axis=1).values\nclasses = df.iloc[:,1].values","9bb83b86":"imagePaths[:10]","0cf8fdfc":"classes[:10]","5bd33dde":"def load(path):\n    image = tf.image.decode_png(tf.io.read_file(path),channels=3)\n    return image\nwith tf.Session() as sess:\n    image,label = sess.run(load(imagePaths[0])),classes[0]\nplt.imshow(image)\nplt.title('Diagnosis: '+str(label))\nplt.show()","cbd45abb":"pathDS = td.Dataset.from_tensor_slices(imagePaths)","6f4d10b7":"labelDS = td.Dataset.from_tensor_slices(classes)","331f8648":"def oneHotter(label):\n    return tf.one_hot(label,5)\n\noneHotLabelDS = labelDS.map(oneHotter,num_parallel_calls=AUTOTUNE)","07a6be52":"imageDSIterator = pathDS.map(load,num_parallel_calls=AUTOTUNE).make_one_shot_iterator()\nelem = imageDSIterator.get_next()\nwith tf.Session() as sess:\n    plt.figure(figsize=(40,30))\n    for idx in range(12):\n        image=sess.run(elem)\n        plt.subplot(3,4,idx+1)\n        plt.imshow(image)\n        plt.grid(False)\n        plt.xticks([])\n        plt.yticks([])\n    plt.show()","fef3cf0c":"def transform_perspective(image):\n    def x_y_1():\n        x = tf.random_uniform([], minval=-0.3, maxval=-0.15)\n        y = tf.random_uniform([], minval=-0.3, maxval=-0.15)\n        return x, y\n     \n    def x_y_2():\n        x = tf.random_uniform([], minval=0.15, maxval=0.3)\n        y = tf.random_uniform([], minval=0.15, maxval=0.3)\n        return x, y       \n\n    def trans(image):\n        ran = tf.random_uniform([])\n        x = tf.random_uniform([], minval=-0.3, maxval=0.3)\n        x_com = tf.random_uniform([], minval=1-x-0.1, maxval=1-x+0.1)\n\n        y = tf.random_uniform([], minval=-0.3, maxval=0.3)\n        y_com = tf.random_uniform([], minval=1-y-0.1, maxval=1-y+0.1)\n\n        transforms =  [x_com, x,0,y,y_com,0,0.00,0]\n\n        ran = tf.random_uniform([]) \n        image = tf.cond(ran<0.5, lambda:tf.contrib.image.transform(image,transforms,interpolation='NEAREST', name=None), \n                lambda:tf.contrib.image.transform(image,transforms,interpolation='BILINEAR', name=None))\n        return image\n\n    ran = tf.random_uniform([])\n    image = tf.cond(ran<1, lambda: trans(image), lambda:image)\n\n    return image","7b238982":"def loadAndPreProcess(path):\n    image = tf.image.decode_png(tf.io.read_file(path),channels=3)\n    image = tf.image.resize(image,[299,299])\n    image = tf.image.random_brightness(image,0.5)\n    image = tf.image.random_hue(image,0.05)\n    image = tf.image.random_contrast(image,0.75,1.25)\n    image = tf.image.random_saturation(image,0.75,1.25)\n    image = tf.image.random_flip_left_right(image)\n    image = tf.contrib.image.rotate(image,tf.random_uniform(shape=[], minval=-15, maxval=15, dtype=tf.float32))\n    image = transform_perspective(image)\n    image \/= 255.\n    image-=0.5\n    image*=2.\n    return image\n    \naugImageDS = pathDS.map(loadAndPreProcess,num_parallel_calls=AUTOTUNE)\naugImageDSIterator = augImageDS.make_one_shot_iterator()\nelem = augImageDSIterator.get_next()\nwith tf.Session() as sess:\n    plt.figure(figsize=(40,30))\n    for idx in range(12):\n        image = sess.run(elem)\n        plt.subplot(3,4,idx+1)\n        plt.imshow(image\/2+0.5)\n        plt.grid(False)\n        plt.xticks([])\n        plt.yticks([])\n    plt.show()","f4d707e9":"dataset = td.Dataset.zip((augImageDS,oneHotLabelDS))","9e818274":"batchSize=2\nds = dataset.shuffle(buffer_size=len(imagePaths)\/\/10)\nds = ds.repeat()\nds = ds.batch(batchSize)\nds = ds.prefetch(buffer_size=AUTOTUNE)\nds = ds.make_one_shot_iterator()","a90b2512":"print(ds)","34b780f9":"base = tf.keras.applications.InceptionResNetV2(input_shape=(299,299,3),include_top=False,weights='imagenet')","f414e88c":"base.trainable=False\nbase.summary()","1967fc3e":"model = tf.keras.Sequential([base,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             tf.keras.layers.Dense(100,activation='relu'),\n                             tf.keras.layers.Dense(100,activation='relu'),\n                             tf.keras.layers.Dense(5)])\n\nmodel.compile(optimizer=tf.train.AdamOptimizer(),loss=tf.losses.softmax_cross_entropy,metrics=['accuracy'])","fa477ac7":"\n\nmodel.fit(ds,epochs=20,verbose=1,steps_per_epoch=len(imagePaths)\/\/batchSize)","75c7f328":"model.save('EyeClassifier')","45d3127c":"# Imports","04fbcd5b":"Simple class labels. Nothing is missing, and there is a slight class imbalance. Now, let's check out the images","14610723":"# Image Exploration\nWe'll define a dataset","9ec789c6":"# CSV Exploration\nLet's load up the csv and see what we got"}}