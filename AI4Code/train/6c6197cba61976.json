{"cell_type":{"4a71678b":"code","5cd8318f":"code","8e53c26e":"code","4eada46b":"code","8edf6a7f":"code","d6c000e5":"code","69b51e18":"code","b445aafb":"code","9adc5245":"code","36fa2d3a":"code","25a76ea8":"code","5fb8a08a":"code","5f8f1e05":"code","9f57aaad":"code","a8c37be7":"code","126c7c8c":"code","cb6f2e25":"code","be773e86":"code","d675e87d":"code","69b3e814":"code","2a8b708a":"code","81786367":"markdown","1c7ad8b7":"markdown","48fdaaf9":"markdown","729db71e":"markdown","f163b42c":"markdown","6c2b20d4":"markdown","2f22d81d":"markdown","0ae9a08d":"markdown","c1c79898":"markdown","ba7c9e4f":"markdown"},"source":{"4a71678b":"# General Libs\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, BatchNormalization, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\n%matplotlib inline\ntf.__version__","5cd8318f":"import os\n\ndef walk_on_dir(dir):\n    print(dir)\n    i = 0 \n    for path, dirs, files in os.walk(dir):\n        if len(dirs) > 0:\n            print(len(dirs))\n            print(dirs)\n            _dirs = dirs\n        else:\n            print(path)\n            print(_dirs[i])\n            print(files)\n            i+=1\n    print(i)","8e53c26e":"MAX_EPOCHS = 30\nPATIENCE = 4\n\ndef train_model(model_id, model, train_generator, val_generator):\n\n    # Salva o melhor modelo\n    cb_save_best_model = keras.callbacks.ModelCheckpoint(filepath=model_id,\n                                                         monitor='val_loss', \n                                                         save_best_only=True, \n                                                         verbose=1)\n\n    # Encerra o treino antecipadamente se n\u00e3o houver evolu\u00e7\u00e3o\n    cb_early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', \n                                                  patience= PATIENCE,\n                                                  verbose=1)\n\n\n    history = model.fit(\n            train_generator,\n            steps_per_epoch = train_generator.samples \/\/ BATCH_SIZE,\n            epochs=MAX_EPOCHS,\n            callbacks = [cb_save_best_model, cb_early_stop],\n            validation_data=val_generator,\n            verbose = 1,\n            validation_steps= val_generator.samples \/\/ BATCH_SIZE)\n    \n    return history","4eada46b":"def print_metrics(model, dataset_generator):\n    score = model.evaluate(test_generator)\n    print('Test loss:', score[0])\n    print('Test accuracy:', score[1])\n    print('Test ROC AUC:', score[2])","8edf6a7f":"def plot_training_curves(history):\n    # Training curves\n    import matplotlib.pyplot as plt\n\n    history_dict = history.history\n    loss_values = history_dict['loss']\n    val_loss_values = history_dict['val_loss']\n\n    epochs_x = range(1, len(loss_values) + 1)\n    plt.figure(figsize=(10,10))\n    plt.subplot(2,1,1)\n    plt.plot(epochs_x, loss_values, 'bo', label='Training loss')\n    plt.plot(epochs_x, val_loss_values, 'b', label='Validation loss')\n    plt.title('Training and validation Loss and Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.subplot(2,1,2)\n    acc_values = history_dict['accuracy']\n    val_acc_values = history_dict['val_accuracy']\n    plt.plot(epochs_x, acc_values, 'bo', label='Training acc')\n    plt.plot(epochs_x, val_acc_values, 'b', label='Validation acc')\n    #plt.title('Training and validation accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Acc')\n    plt.legend()\n    plt.show()","d6c000e5":"import itertools\n\n#Plot the confusion matrix. Set Normalize = True\/False\ndef plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize=(15,15))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        cm = np.around(cm, decimals=2)\n        cm[np.isnan(cm)] = 0.0\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","69b51e18":"from sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\n\ndef plot_confusion_matrix_and_classification_report(model, dataset_generator, classes):\n    Y_pred = model.predict(dataset_generator)\n    y_pred = np.argmax(Y_pred, axis=1)\n    \n    #Confution Matrix\n    #cm = confusion_matrix(test_generator.classes, y_pred)\n    #plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix')\n\n    #Classification Report\n    print('Classification Report')\n    print(classification_report(test_generator.classes, y_pred, target_names=classes))","b445aafb":"IMG_SHAPE = (244,244)\nINPUT_SHAPE = (IMG_SHAPE[0], IMG_SHAPE[1], 3)\n\nTRAIN_DIR = '..\/input\/100-bird-species\/train'\nTEST_DIR = '..\/input\/100-bird-species\/test'\nVAL_DIR = '..\/input\/100-bird-species\/valid'\n\nBATCH_SIZE = 16\n\nRANDOM_SEED = 33\n\nMAX_CLASSES = 300","9adc5245":"classes = os.listdir(TRAIN_DIR)\nnum_classes = len(classes)\nnum_classes","36fa2d3a":"# Para experimenta\u00e7\u00e3o, vamos escolher aleat\u00f3riamente N classes\n\nimport random\n\nrandom.Random(RANDOM_SEED).shuffle(classes)\n\nclasses = classes[:MAX_CLASSES]\nnum_classes = len(classes)\n\nclasses","25a76ea8":"# Visualizing some sample data\n\nsample_generator = ImageDataGenerator().flow_from_directory(TEST_DIR, shuffle=False)\n\nplt.figure(figsize=(15,15))\nfor i in range(9):\n    # 3x3 grid\n    plt.subplot(330 + 1 + i)\n    batch = sample_generator.next()[0]\n    image = batch[0].astype('uint8')\n    plt.imshow(image)\nplt.show()","5fb8a08a":"from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input","5f8f1e05":"generator_args = {\n    \"preprocessing_function\":preprocess_input,\n}\nflow_args = {\n    \"target_size\":IMG_SHAPE,\n    \"seed\":RANDOM_SEED,\n    \"batch_size\":BATCH_SIZE,\n    \"class_mode\":\"categorical\",\n    \"classes\":classes,\n}","9f57aaad":"img_generator = ImageDataGenerator(**generator_args)\naugmented_img_generator = ImageDataGenerator(rotation_range=20,\n                                             width_shift_range=0.1,\n                                             height_shift_range=0.1,\n                                             shear_range=0.1,\n                                             zoom_range=0.1,\n                                             horizontal_flip=True,\n                                             fill_mode='nearest',\n                                             **generator_args)","a8c37be7":"train_generator = augmented_img_generator.flow_from_directory(TRAIN_DIR, shuffle=True, **flow_args)\ntest_generator = img_generator.flow_from_directory(TEST_DIR, shuffle=False, **flow_args)\nval_generator = img_generator.flow_from_directory(VAL_DIR, shuffle=False, **flow_args)","126c7c8c":"# Visualizing some pre-processed examples\n\nplt.figure(figsize=(15,15))\nfor i in range(9):\n    # 3x3 grid\n    plt.subplot(330 + 1 + i)\n    batch = train_generator.next()[0]\n    image = batch[0].astype('uint8')\n    plt.imshow(image)\nplt.show()","cb6f2e25":"base_model = ResNet50(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n\nx = base_model.output\nx = Flatten()(x)\nx = Dense(120, activation='sigmoid')(x)\nx = Dropout(0.1)(x)\nx = Dense(60, activation='sigmoid')(x)\nx = Dropout(0.1)(x)\n\npredictions = Dense(num_classes, activation='softmax', kernel_initializer='random_uniform')(x)\n\nmodel = Model(inputs=base_model.input, \n              outputs=predictions)\nmodel.summary()\n\n# Freezing pretrained layers\nfor layer in base_model.layers:\n    layer.trainable=False\n    \nmodel.compile(optimizer=Adam(),\n              loss='categorical_crossentropy',\n              metrics=['accuracy', \"AUC\"])","be773e86":"MODEL_ID = 'resnet50.model.bruno.h5'\n\nhistory = train_model(MODEL_ID, model, train_generator, val_generator)","d675e87d":"plot_training_curves(history)","69b3e814":"print_metrics(model, test_generator)","2a8b708a":"plot_confusion_matrix_and_classification_report(model, test_generator, classes)","81786367":"# Pre-processing","1c7ad8b7":"## print_metrics","48fdaaf9":"# Dataset 300 Bird Species\n* Fonte: https:\/\/www.kaggle.com\/gpiosenka\/100-bird-species\n\n\nO dataset cont\u00e9m 45.622 imagens de p\u00e1ssaros de 300 esp\u00e9cies diferentes j\u00e1 distribu\u00eddas entre treino, valida\u00e7\u00e3o e teste.\n\nAs imagens possuem 224 x 224 pixels com 3 canais de cores RGB.","729db71e":"## train_model","f163b42c":"# Helper functions","6c2b20d4":"## plot_confusion_matrix_and_classification_report","2f22d81d":"# Transfer learning Model using ResNet50","0ae9a08d":"## plot_training_curves","c1c79898":"# Exploratory Analysis","ba7c9e4f":"## walk_on_dir"}}