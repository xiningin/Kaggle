{"cell_type":{"eed1db11":"code","25c2631d":"code","9a6a54bc":"code","de756b2c":"code","d43df03a":"code","2cb549ef":"code","420c7cf2":"code","c6938393":"code","18d1e21f":"code","f93a0172":"code","dca7ac3d":"code","482dbcdf":"code","dd76f093":"code","91f4d56b":"code","019c22a8":"code","afacbf25":"markdown","5a639330":"markdown","11223d7c":"markdown","9bf88d6c":"markdown","89bed2d3":"markdown","43a25393":"markdown","931eff25":"markdown","8491ab39":"markdown","aaa6fbc9":"markdown","b9fe26b2":"markdown"},"source":{"eed1db11":"from tqdm import tqdm\nimport numpy as np\nimport pandas as pd\nfrom sympy import sieve\nimport hvplot.pandas #custom\nimport colorcet as cc","25c2631d":"cities = pd.read_csv(\"..\/input\/cities.csv\", index_col=['CityId'])\npnums = list(sieve.primerange(0, cities.shape[0]))\ncities['isprime'] = cities.index.isin(pnums)\ndisplay(cities.head())\n\n# show all points and density of primes\nallpoints = cities.hvplot.scatter('X', 'Y',  width=380, height=350, datashade=True, \n                title='All Cities')\ncolors = list(reversed(cc.kbc))\nprimedensity = cities[cities.isprime].hvplot.hexbin(x='X', y='Y', width=420, height=350, \n                cmap=colors, title='Density of Prime Cities').options(size_index='Count', \n                min_scale=0.8, max_scale=0.95)\nallpoints + primedensity","9a6a54bc":"%%time\nfrom sklearn.mixture import GaussianMixture\n\nmclusterer = GaussianMixture(n_components=350, tol=0.01, random_state=66, verbose=1)\ncities['mclust'] = mclusterer.fit_predict(cities[['X', 'Y']].values)\nnmax = cities.mclust.max()\nprint(\"{} clusters\".format(nmax+1))","de756b2c":"histo = cities.hvplot.hist('mclust', ylim=(0,14000), color='tan')\n\ncustcolor = cc.rainbow + cc.rainbow\ngausses = cities.hvplot.scatter('X', 'Y',  by='mclust', size=5, width=500, height=450, \n                datashade=True, dynspread=True, cmap=custcolor)\ndisplay(histo, gausses)","d43df03a":"centers = cities.groupby('mclust')['X', 'Y'].agg('mean').reset_index()\ndef plot_it(df, dotsize, dotcolor, dotalpha):\n    p = df.hvplot.scatter('X', 'Y', size=dotsize, xlim=(0,5100), ylim=(0,3400), width=500,\n            height=450, hover_cols=['mclust'], color=dotcolor, alpha=dotalpha)\n    return p\n\ncents = plot_it(centers, 30, 'darkblue', 0.5)\nnpole = plot_it(cities.loc[[0]], 100, 'red', 1)\ncents*npole","2cb549ef":"#%% imports\nfrom scipy.spatial.distance import pdist, squareform\nfrom ortools.constraint_solver import pywrapcp\nfrom ortools.constraint_solver import routing_enums_pb2\n\n#%% functions\ndef create_mat(df):\n    print(\"building matrix\")\n    mat = pdist(locations)\n    return squareform(mat)\n\ndef create_distance_callback(dist_matrix):\n    def distance_callback(from_node, to_node):\n      return int(dist_matrix[from_node][to_node])\n    return distance_callback\n\nstatus_dict = {0: 'ROUTING_NOT_SOLVED', \n               1: 'ROUTING_SUCCESS', \n               2: 'ROUTING_FAIL',\n               3: 'ROUTING_FAIL_TIMEOUT',\n               4: 'ROUTING_INVALID'}\n\ndef optimize(df, startnode=None, stopnode=None, fixed=False):     \n    num_nodes = df.shape[0]\n    mat = create_mat(df)\n    dist_callback = create_distance_callback(mat)\n    search_parameters = pywrapcp.RoutingModel.DefaultSearchParameters()\n#     search_parameters.time_limit_ms = int(1000*60*numminutes)\n    search_parameters.solution_limit = num_iters \n    search_parameters.first_solution_strategy = (\n                                    routing_enums_pb2.FirstSolutionStrategy.SAVINGS)\n    search_parameters.local_search_metaheuristic = (\n                            routing_enums_pb2.LocalSearchMetaheuristic.GUIDED_LOCAL_SEARCH)\n\n    if fixed:\n        routemodel = pywrapcp.RoutingModel(num_nodes, 1, [startnode], [stopnode])\n    else:\n        routemodel = pywrapcp.RoutingModel(num_nodes, 1, startnode)\n    routemodel.SetArcCostEvaluatorOfAllVehicles(dist_callback)\n    \n    print(\"optimizing {} cities\".format(num_nodes)) \n    assignment = routemodel.SolveWithParameters(search_parameters)\n\n    print(\"status: \", status_dict.get(routemodel.status()))\n    print(\"travel distance: \",  str(assignment.ObjectiveValue()), \"\\n\")\n    return routemodel, assignment\n    \ndef get_route(df, startnode, stopnode, fixed): \n    routemodel, assignment = optimize(df, int(startnode), int(stopnode), fixed)\n    route_number = 0\n    node = routemodel.Start(route_number)\n    route = []\n    while not routemodel.IsEnd(node):\n        route.append(node) \n        node = assignment.Value(routemodel.NextVar(node))\n    return route\n","420c7cf2":"%%time\n#%% parameters\nnum_iters=100\n\n# main\nnnode = int(cities.loc[0, 'mclust'])\nlocations = centers[['X', 'Y']].values\nsegment = get_route(locations, nnode, 0, fixed=False)","c6938393":"opoints = centers.loc[segment]\ncentersline = opoints.hvplot.line('X', 'Y', xlim=(0,5100), ylim=(0,3400), color='green', width=500, \n                            height=450, hover=False) \ngausses*cents*npole*centersline","18d1e21f":"opoints.reset_index(drop=True, inplace=True) #recall ordered points\ncities['clustorder'] = cities.groupby('mclust').cumcount()","f93a0172":"from sklearn.neighbors import NearestNeighbors\n\nstartlist=[0]\nneigh = NearestNeighbors(n_neighbors=1, n_jobs=-1)\nfor i,m in enumerate(opoints.mclust[1:], 0):\n    neigh.fit(cities.loc[cities.mclust == m, ['X', 'Y']].values)\n    lastcenter = opoints.loc[i, ['X', 'Y']].values.reshape(1, -1)\n    closestart = neigh.kneighbors(lastcenter, return_distance=False)\n    start = cities.index[(cities.mclust == m) & (cities.clustorder == closestart.item())].values[0]\n    startlist.append(start)\nopoints['startpt'] = startlist    ","dca7ac3d":"stoplist = []\nfor i,m in enumerate(opoints.mclust, 1):\n    neigh.fit(cities.loc[cities.mclust == m, ['X', 'Y']].values)\n    if m != opoints.mclust.values[-1]:\n        nextstartnode = opoints.loc[i, 'startpt']\n    else: \n        nextstartnode = 0\n    nextstart = cities.loc[nextstartnode, ['X', 'Y']].values.reshape(1, -1)\n    closestop = neigh.kneighbors(nextstart, return_distance=False)\n    stop = cities.index[(cities.mclust == m) & (cities.clustorder == closestop.item())].values[0]\n    stoplist.append(stop)\nopoints['stoppt'] = stoplist \n\ndisplay(cities.head(), opoints.head())","482dbcdf":"coords = cities.loc[opoints.stoppt, ['X', 'Y', 'mclust']]\nstops = plot_it(coords, 30, 'darkblue', 0.5)\nstopsline = coords.hvplot.line('X', 'Y', xlim=(0,5100), ylim=(0,3400), color='green', width=500, \n                            height=450, hover=False) \nstopsline*npole*gausses*stops","dd76f093":"%%time \nnum_iters = 100\nseglist = []\ntotal_clusts = cities.shape[0]\nfor i,m in enumerate(opoints.mclust):\n    district = cities[cities.mclust == m]\n    print(\"begin cluster {}, {} of {}\".format(m, i, opoints.shape[0]-1))\n\n    clstart = opoints.loc[i, 'startpt']\n    nnode = district.loc[clstart, 'clustorder']\n    clstop = opoints.loc[i, 'stoppt']\n    pnode = district.loc[clstop, 'clustorder']\n    locations = district[['X', 'Y']].values\n    \n    segnodes = get_route(locations, nnode, pnode, fixed=False) #output is type list\n    ord_district =  district.iloc[segnodes]\n    segment = ord_district.index.tolist()\n    seglist.append(segment)\n\nseglist.append([0])\npath = np.concatenate(seglist)","91f4d56b":"bestpath = cities.loc[path, ['X', 'Y']]\nclustline = bestpath.hvplot.line('X', 'Y', xlim=(0,5100), ylim=(0,3400), width=500, \n                            height=450, datashade=True, dynspread=True) \nclustline*npole","019c22a8":"def score_it(path):\n    path_df = cities.reindex(path).reset_index()\n    path_df['step'] = np.sqrt((path_df.X - path_df.X.shift())**2 + (path_df.Y - path_df.Y.shift())**2)\n    path_df['step_adj'] = np.where((path_df.index) % 10 != 0, path_df.step, path_df.step + \n                            path_df.step*0.1*(~path_df.CityId.shift().isin(pnums)))\n    return path_df.step_adj.sum()\n\ndisplay(score_it(path))\n\nsub = pd.read_csv('..\/input\/sample_submission.csv')\nsub['Path'] = path\nsub.to_csv('submission.csv', index=False)\nsub.head()","afacbf25":"<img src=\"http:\/\/www.science4all.org\/wp-content\/uploads\/2013\/12\/Santas-Vehicle-Routing-Problem3.png\" alt=\"drawing\" width=\"600\"\/>\n\nThis solution uses [Google OR-Tools](https:\/\/developers.google.com\/optimization\/) to optimize the routing for Santa. OR-Tools include a \"vehicle routing library\" for solving TSPs and a convenient Python interface. Lucky for us, it's all included in Kaggle kernels!\n\nThe start point for the route comes from model-based clustering. You can see from the city plot how the density of points varies quite a bit across the grid. The right clustering approach may work better than starting with a grid or k-means clustering. Also, breaking the cities into clusters can scale to millions of points on a typical machine if the need arises. \n\nHere is the overall approach:\n\n* Divide cities into clusters\n* Get centers for each cluster\n* Find an optimal path across centers\n* Find start and stop points for each cluster\n* Find an optimal segment for each cluster and assemble","5a639330":"## Clustering \n\n#### First Look\nHexagonal binning is often a good way to quickly see the density of overlapping points. Below is a comparison of all points with a bin plot of prime cities. Prime and non-prime cities appear to be be similarly distributed with a few dark, dense areas.","11223d7c":"## Optimal Segments for each Cluster\nThe next step is to iterate through clusters with the solver. The closed form of the solver with start and stop points is being difficult. For now I'll use start points only and take the hit of doubling back to the next cluster.\n","9bf88d6c":"#### Model-based Clustering\n\nI first tried density-based clustering, but it left too many points that didn't belong to any cluster. In some cases it's ideal to separate out the sparse points, but for TSPs it's not so good. Model-based clustering seems to be a better choice. The number of clusters is set manually. Here I'll choose a relatively high number to ease the burden on the router.","89bed2d3":"## Cluster Centers\n\nHere are the geometric centers of all the clusters. The big red dot is the North Pole.","43a25393":" Here's what  the new path looks like. The points are all on cluster borders which makes sense.","931eff25":"The path looks reasonable... \n\n## Start and Stop Points\nThe next step is to find good start\/stop points for each cluster along the path.\n* Set the start point for cluster[n] as the point closest to the center of cluster[n-1].\n* Set the stop point for cluster[n] as the point closest to the start point of cluster[n+1].\n\nThis idea comes from [Proposed Algorithms to solve Big Data traveling salesman problem](https:\/\/www.researchgate.net\/publication\/326325068_Proposed_Algorithms_to_solve_Big_Data_traveling_salesman_problem). Thank you Research Gate!","8491ab39":"## Optimal Path across Centers\n\nOR-Tools can find an optimal path across the clusters. Here is a modified version of the code documented on [Google's TSP page](https:\/\/developers.google.com\/optimization\/routing\/tsp).","aaa6fbc9":"Clusters can be of different sizes with model-based clustering. Here's the distribution of cities per cluster and the scatterplot. ","b9fe26b2":"Not bad, even with the wasted moves although it does take a while to run. It would be interesting to see what improvements come with a fixed-route model, fewer clusters and\/or longer run times. \n\nP.S. Check out [this discussion](https:\/\/www.kaggle.com\/c\/traveling-santa-2018-prime-paths\/discussion\/73800) for a solid alternative to creating subproblems (clusters)!"}}