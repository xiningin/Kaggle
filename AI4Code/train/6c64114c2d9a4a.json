{"cell_type":{"38116293":"code","26727d04":"code","13110e36":"code","8bee9a7d":"code","28ea9e60":"code","72e8655c":"code","8586bf13":"code","7a70b484":"code","f04da507":"code","a14c4e2b":"code","ce8bf5d0":"code","1a173085":"code","48d2219e":"code","2d687264":"code","7878bf49":"code","357e626c":"code","2d98f8de":"code","3e15b389":"code","dea12b29":"code","22a8f8cb":"code","49392679":"code","7273e464":"code","655c153c":"code","008912ff":"code","f83ee683":"code","278455b7":"code","00e663b9":"code","2719e770":"code","6fe828ce":"code","69bcc52d":"code","6f2ab5a5":"code","5c947b61":"code","a0add09c":"code","237889f3":"code","3e372d2f":"code","bf2c185f":"code","f36f8f65":"code","ec716b56":"code","449854ec":"code","0ef5713e":"code","57d4491f":"code","da2ad0c8":"code","554c3df9":"code","1746065b":"markdown","7d4e3dcf":"markdown","3d346778":"markdown"},"source":{"38116293":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport seaborn as sns ","26727d04":"df = pd.read_csv('..\/input\/heart-failure-prediction\/heart.csv')\ndf.head().style.background_gradient(axis=0)","13110e36":"# Now as we see there are features it's Dtype is object so we should change it to int \ndf.info()","8bee9a7d":"df.isnull().sum()","28ea9e60":"df.describe().style.background_gradient(axis = 1)","72e8655c":"df.info()","8586bf13":"# now we are going to get dummies ('transform Str to numbers \" Dummies \")\n\ndf = pd.get_dummies(df,columns=['Sex','ChestPainType','RestingECG','ExerciseAngina','ST_Slope'],drop_first= True,prefix = 'Dumy',prefix_sep =\"*\" )\ndf","7a70b484":"# Now we are going to make some data visualizations :\nplt.figure(figsize=(6,4),dpi=150)\nsns.scatterplot(data = df , x = 'Age' , y='Cholesterol',hue ='HeartDisease',style ='HeartDisease')","f04da507":"plt.figure(figsize=(6,4),dpi=150)\nsns.boxplot(data = df , x = 'HeartDisease',y='Age',hue='HeartDisease')","a14c4e2b":"plt.figure(figsize=(8,6),dpi = 150)\nsns.histplot(data = df , x = 'Cholesterol', hue = 'HeartDisease',y='Age')","ce8bf5d0":"plt.figure(figsize=(8,6),dpi = 150)\nsns.histplot(data = df , x = 'Cholesterol', hue = 'HeartDisease')","1a173085":"# As we see there is no imbalnce data issue :\nsns.countplot(data = df , x = 'HeartDisease')","48d2219e":"X = df.drop('HeartDisease',axis=1)\ny = df['HeartDisease']","2d687264":"from sklearn.model_selection import train_test_split","7878bf49":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=101)","357e626c":"# Now we are going to scale the data we have : \nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()","2d98f8de":"scaler.fit(X_train)\nscaled_x_train = scaler.transform(X_train)\nscaled_x_test = scaler.transform(X_test)","3e15b389":"from sklearn.linear_model import LogisticRegression\nlog_model = LogisticRegression()","dea12b29":"log_model.fit(scaled_x_train,y_train)","22a8f8cb":"y_pred = log_model.predict(scaled_x_test)","49392679":"# Now we will import metrixes to see the model accuracy : \nfrom sklearn.metrics import accuracy_score , classification_report , plot_confusion_matrix , plot_roc_curve , plot_precision_recall_curve","7273e464":"accuracy_score(y_test,y_pred)","655c153c":"print(classification_report(y_test,y_pred))","008912ff":"plot_confusion_matrix(log_model,scaled_x_test,y_test)","f83ee683":"plot_roc_curve(log_model,scaled_x_test,y_test)","278455b7":"plot_precision_recall_curve(log_model,scaled_x_test,y_test)","00e663b9":"from sklearn.neighbors import KNeighborsClassifier","2719e770":"'''Now we want to know what is best value for k , so we are going to make for loop to see the best value of K '''\ntest_error_rate = []\nfor k in range(1,30):\n    knn_model = KNeighborsClassifier(n_neighbors=k)\n    knn_model.fit(scaled_x_train,y_train)\n    y_pred = knn_model.predict(scaled_x_test)\n    error = 1-accuracy_score(y_test,y_pred)\n    test_error_rate.append(error)","6fe828ce":"# The best k value is 5 because it has the lowest error rate by 0.12\nplt.plot(range(1,30),test_error_rate)\nplt.xlabel('Error rate')\nplt.ylabel('K Values')\nplt.title('Choose the best KNN value')","69bcc52d":"knn_model = KNeighborsClassifier(n_neighbors=5)\nknn_model.fit(scaled_x_train,y_train)\ny_pred = knn_model.predict(scaled_x_test)","6f2ab5a5":"accuracy_score(y_test,y_pred)","5c947b61":"plot_confusion_matrix(knn_model , scaled_x_test , y_test)","a0add09c":"print(classification_report(y_test,y_pred))","237889f3":"plot_roc_curve(knn_model,scaled_x_test,y_test)","3e372d2f":"plot_precision_recall_curve(knn_model,scaled_x_test,y_test)","bf2c185f":"from sklearn.svm import SVC\nsvc = SVC()\nfrom sklearn.model_selection import GridSearchCV\nparam_grid = {'C':[0.001,0.01,0.1,0.5,1]}\ngrid = GridSearchCV(svc,param_grid)\ngrid.fit(scaled_x_train,y_train)","f36f8f65":"grid.best_params_","ec716b56":"y_pred = grid.predict(scaled_x_test)","449854ec":"accuracy_score(y_test,y_pred)","0ef5713e":"print(classification_report(y_test,y_pred))","57d4491f":"plot_confusion_matrix(grid,scaled_x_test,y_test)","da2ad0c8":"plot_roc_curve(grid,scaled_x_test,y_test)","554c3df9":"plot_precision_recall_curve(grid,scaled_x_test,y_test)","1746065b":"Now we are going to use SVM Alghorithm : ","7d4e3dcf":"2 - Now we are going to use KNN Alghoritm :","3d346778":"Now we are going to use alghorithm (LogisticRegression)\n"}}