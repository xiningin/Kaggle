{"cell_type":{"0bfaf068":"code","a6d6c7e9":"code","b0633c3d":"code","40b2904d":"code","b510033c":"code","b94bb26b":"code","27ee2d3c":"code","ca16d174":"code","2ec55fff":"code","a5b6e4bf":"code","145c969c":"code","e7e3e1e5":"code","756de21d":"code","b0c8a36c":"code","ba740396":"code","541be994":"code","9a5a48ec":"code","435932a5":"code","cb680d32":"code","115798db":"code","f238fa2e":"code","ce2daae7":"code","e22828ca":"code","a79bdd6e":"code","e9181140":"code","4e64fcac":"code","0d58bc41":"code","8a434299":"code","c1623b96":"markdown","a6f03928":"markdown","117e7dfd":"markdown","3e03096a":"markdown","1fadcc12":"markdown","1c267d33":"markdown"},"source":{"0bfaf068":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# Any results you write to the current directory are saved as output.","a6d6c7e9":"!wget https:\/\/raw.githubusercontent.com\/Iamsdt\/DLProjects\/master\/utils\/Helper.py","b0633c3d":"root_train = '..\/input\/train_data\/train_data'\nroot_test = '..\/input\/test_data\/test_data'","40b2904d":"import Helper\nimport torch\nfrom torchvision import datasets, transforms,models\nfrom torch.utils.data import DataLoader\n\nmean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\n\ntrain_transform = transforms.Compose([\n                                transforms.Resize(255),\n                                transforms.RandomResizedCrop(224),\n                                transforms.RandomHorizontalFlip(),\n                                transforms.ColorJitter(),\n                                transforms.ToTensor(),\n                                transforms.Normalize(mean, std)])\n\ntest_transform = transforms.Compose([\n                                transforms.Resize(255),\n                                transforms.CenterCrop(224),\n                                transforms.ToTensor(),\n                                transforms.Normalize(mean, std)])\n\ntrain_loader, test_loader, classes, class_to_idx = Helper.prepare_loader(\n    root_train, root_test, train_transform, test_transform)\n\nprint(\"Total Class: \", len(classes))","b510033c":"Helper.visualize(test_loader, classes)","b94bb26b":"densenet = models.densenet161(pretrained=True)\ndensenet.classifier","27ee2d3c":"densenet = Helper.freeze_parameters(densenet)","ca16d174":"import torch.nn as nn\nfrom collections import OrderedDict\n\nclassifier = nn.Sequential(\n  nn.Linear(in_features=2208, out_features=1024),\n  nn.ReLU(),\n  nn.Dropout(p=0.4),\n  nn.Linear(in_features=1024, out_features=16),\n  nn.LogSoftmax(dim=1)  \n)\n    \ndensenet.classifier = classifier\ndensenet.classifier","2ec55fff":"import torch.optim as optim\nimport torch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndensenet.to(device)\n\ncriterion = nn.NLLLoss()\noptimizer = optim.Adam(densenet.classifier.parameters(), lr=0.003)\n# turn this off\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)","a5b6e4bf":"epoch = 5","145c969c":"densenet, train_loss, test_loss = Helper.train(densenet, train_loader, test_loader, epoch, optimizer, criterion)","e7e3e1e5":"Helper.check_overfitted(train_loss, test_loss)","756de21d":"resnet = models.resnet50(pretrained=True)\nresnet.fc","b0c8a36c":"resnet = Helper.freeze_parameters(resnet)","ba740396":"import torch.nn as nn\nfrom collections import OrderedDict\n\nclassifier = nn.Sequential(\n  nn.Linear(in_features=2048, out_features=1024),\n  nn.ReLU(),\n  nn.Dropout(p=0.4),\n  nn.Linear(in_features=1024, out_features=16),\n  nn.LogSoftmax(dim=1)  \n)\n    \nresnet.fc = classifier\nresnet.fc","541be994":"resnet.to(device)\noptimizer = optim.Adam(resnet.fc.parameters(), lr=0.003)\n# turn this off\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)","9a5a48ec":"resnet, train_loss, test_loss = Helper.train(resnet, train_loader, test_loader, epoch, optimizer, criterion)","435932a5":"Helper.check_overfitted(train_loss, test_loss)","cb680d32":"incept = models.inception_v3(pretrained=True)\n\nprint(incept.fc)\nincept.aux_logits = False\nprint(incept.aux_logits)","115798db":"incept = Helper.freeze_parameters(incept)","f238fa2e":"import torch.nn as nn\nfrom collections import OrderedDict\n\nclassifier = nn.Sequential(\n  nn.Linear(in_features=2048, out_features=1024),\n  nn.ReLU(),\n  nn.Dropout(p=0.4),\n  nn.Linear(in_features=1024, out_features=16),\n  nn.LogSoftmax(dim=1)  \n)\n\nclassifier2 = nn.Sequential(\n  nn.Linear(in_features=786, out_features=512),\n  nn.ReLU(),\n  nn.Dropout(p=0.4),\n  nn.Linear(in_features=512, out_features=16),\n  nn.LogSoftmax(dim=1)  \n)\n    \nincept.fc = classifier\n#incept.AuxLogits.fc = classifier2\n\nprint(incept.fc)\n#print(incept.AuxLogits.fc)","ce2daae7":"incept.to(device)\noptimizer = optim.Adam(incept.fc.parameters(),lr=0.003)\n# turn this off\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)","e22828ca":"incept, train_loss, test_loss = Helper.train(incept, train_loader, test_loader, epoch, optimizer, criterion)","a79bdd6e":"Helper.check_overfitted(train_loss, test_loss)","e9181140":"import torch.nn as nn\nimport torch\n\n\nclass MyEnsemble(nn.Module):\n\n    def __init__(self, modelA, modelB, modelC, input):\n        super(MyEnsemble, self).__init__()\n        self.modelA = modelA\n        self.modelB = modelB\n        self.modelC = modelC\n\n        self.fc1 = nn.Linear(input, 16)\n\n    def forward(self, x):\n        out1 = self.modelA(x)\n        out2 = self.modelB(x)\n        out3 = self.modelC(x)\n\n        out = out1 + out2 + out3\n\n        x = self.fc1(out)\n        return torch.softmax(x, dim=1)","4e64fcac":"model = MyEnsemble(densenet, resnet, incept, 16)","0d58bc41":"model.to(device)\noptimizer = optim.Adam(model.parameters(),lr=0.003)\n# turn this off\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)","8a434299":"model, train_loss, test_loss = Helper.train(model, train_loader, test_loader, epoch, optimizer, criterion)","c1623b96":"# Inception Model v3","a6f03928":"# Ensembling","117e7dfd":"# Prepare Data Loader","3e03096a":"# Train Resnet","1fadcc12":"# Train Densenet161","1c267d33":"# Load Helper classes"}}